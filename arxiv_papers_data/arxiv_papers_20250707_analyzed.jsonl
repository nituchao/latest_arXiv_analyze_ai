{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02083", "html_url": "https://arxiv.org/abs/2507.02083", "title": "使用系统生物学干实验评估语言模型的科学能力", "title_en": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab", "authors": "Haonan Duan,Stephen Zhewen Lu,Caitlin Fiona Harrigan,Nishkrit Desai,Jiarui Lu,Michał Koziarski,Leonardo Cotta,Chris J. Maddison", "background": "实验设计和结果解释是科学研究的核心能力，尤其是在生物学领域，研究人员通过扰动复杂系统来揭示背后的系统机制。最近对大型语言模型（LLMs）科学能力的评估未能公正测试这些能力，因为实地实验室实验在专业、时间和设备方面成本高昂。SciGym是一个开创性的基准测试工具，能够在开放的科学发现任务中评估LLMs在迭代实验设计和分析方面的能力。SciGym通过虚拟实验（干实验室）解决了湿实验室成本高的问题，利用系统生物学标记语言编码的模型可以高效生成模拟数据，为复杂系统的实际实验提供了理想的试验平台。作者评估了六种最先进的LLMs在137个小系统的性能，并释放了总共350个系统。评估结果表明，虽然能力更强的模型表现出色，但所有模型在系统复杂性增加时的性能显著下降，这表明在LLM科学能力上的改进空间很大。", "innovation": "SciGym引入了一种新的基准测试方法，通过虚拟实验（干实验室）来评估LLMs在迭代实验设计和分析方面的能力。这种方法克服了湿实验室实验高成本的问题，利用系统生物学标记语言编码的模型，能够高效生成模拟数据，适用于复杂系统的实际实验。这种方法为科学发现任务中的LLM能力评估提供了新的解决方案。", "conclusion": "虽然更先进的模型在性能上有所提升，但所有模型在系统复杂性增加时的性能下降明显，表明需要在LLM的科学能力上进行更多的改进。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02173", "html_url": "https://arxiv.org/abs/2507.02173", "title": "数据多样化方法在对齐中的应用提高大语言模型的数学表现", "title_en": "Data Diversification Methods In Alignment Enhance Math Performance In LLMs", "authors": "Berkan Dokmeci,Qingyang Wu,Ben Athiwaratkun,Ce Zhang,Shuaiwen Leon Song,James Zou", "background": "尽管最近在偏好学习中的进展提高了人类反馈的一致性，但数学推理一直是固有的挑战。本文研究了偏好优化中的数据多样化策略如何提高大语言模型（LLMs）的数学推理能力。评估了三种常见的数据生成方法：温度采样、Chain-of-Thought提示和蒙特卡洛树搜索（MCTS）。", "innovation": "引入了一种新颖的结构化方法——多样化-思考解决（DTS），这种方法系统地将问题分解成多种推理路径。研究表明，通过战略性的多样化偏好数据，模型可以显著提高数学推理性能，得分最高时在GSM8K和MATH数据集上分别比基线模型提高了7.1%和4.2%。尽管DTS的计算开销仅有基线的1.03倍，MCTS的计算开销几乎是其五倍，且效果较差。这些发现表明，结构化探索多样化的问题解决方法比传统方法更能有效地生成数学对齐所需的数据。", "conclusion": "这些发现展示了结构化的多样化方法在生成更有效的数学问题解决数据方面的优势，从而提高了大语言模型的数学对齐性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02211", "html_url": "https://arxiv.org/abs/2507.02211", "title": "在强化学习下的空间囚徒困境中稀释、扩散和共生效应", "title_en": "Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning", "authors": "Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein", "background": "近期研究发现，在空间囚徒困境游戏中，通过注入噪声、不同类型的强化学习算法和邻居收益反馈等机制，静态代理能够学会合作。此项工作进一步探讨了稀释与移动性在空间囚徒困境中的影响，旨在通过独立多智能体Q学习算法来研究这些因素的作用，并连接到先前在非强化学习研究中的结果，以展示算法在建模不同博弈论场景中的灵活性和潜在基准作用。", "innovation": "采用了独立的多智能体Q学习算法来研究稀释和移动性对空间囚徒困境的影响；展示了固定更新规则的游戏在质量和学习规则下可能是等同的；揭示了在定义多种行动时群体之间能够形成共生互惠效应。", "conclusion": "范围内的结果包括，固定更新规则的游戏可以与具有学习规则的游戏在质上等价；当定义了多种行动时，群体之间会出现共生互惠效应。研究表明，通过独立多智能体Q学习算法可以有力地模拟不同的博弈理论情景，并具有作为基准的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02004", "html_url": "https://arxiv.org/abs/2507.02004", "title": "STELLA: 自适应生物医学研究LLM代理", "title_en": "STELLA: Self-Evolving LLM Agent for Biomedical Research", "authors": "Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong", "background": "生物医学领域的数据、工具和文献的迅速增长造成了一个碎片化的研究环境，超出了人类专家的能力范围。尽管人工智能代理可以提供解决方案，但它们通常依赖于静态的手动策展工具集，限制了它们适应和扩展的能力。", "innovation": "我们介绍了STELLA，一种自我进化的AI代理，旨在克服这些限制。STELLA采用多代理架构，自主提升自身能力，包括一个演变的模板库和一个动态工具海洋。通过一个工具创建代理自动发现和整合新的生物信息学工具，使STELLA能够从经验中学习。实验表明，STELLA在一系列生物医学基准测试中达到了最先进的准确性，略高于26%在《人类终极考试：生物医学》中，达到54%在LAB-Bench: DBQA，达到63%在LAB-Bench: LitQA，并且其性能随着经验的增加而系统性地提高，例如《人类终极考试：生物医学》的准确性几乎翻了一番。", "conclusion": "STELLA代表了一种重要进步，朝着可以学习和成长的人工智能代理系统发展，能动态扩展其专业知识，加速生物医学发现的进程。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02197", "html_url": "https://arxiv.org/abs/2507.02197", "title": "角色扮演代理是否言行一致？基于LLM的人类信任模拟中的信念行为一致性", "title_en": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust", "authors": "Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto", "background": "随着LLM作为角色扮演代理被越来越多地研究以生成用于人类行为研究的合成数据，确保它们的输出与其分配的角色保持一致变得至关重要。本文探讨了基于LLM的角色扮演代理在角色扮演过程中所声称的行为信念（“它们说什么”）与实际行为（“它们如何行动”）之间的一致性问题。", "innovation": "本文构建了一个评估框架，以准确测量通过提示模型获得的信念预测模拟结果的能力。文中使用增强版的GenAgents角色银行和信任博弈（一种标准的经济学游戏，用于量化玩家的信任和互惠）来引入一种信念行为一致性度量方法，该方法系统地探讨了信念一致性受多种因素的影响，包括所采取的信念类型、相关信息的呈现时机及其方式以及对未来行为的预测距离等因素。此外，还研究了当原本采取的信念与研究目标不一致时，是否可以植入研究人员自己理论先验的方法。研究结果揭示了个体和群体水平上LLM声称的（或施加的）信念与其角色扮演模拟结果之间系统性的不一致。", "conclusion": "即使模型似乎编码了合理的信念，它们也可能在一致应用这些信念方面失败。这些发现强调了识别LLM声称的信念与其模拟行为之间一致性的重要性，允许研究人员在行为研究中适当使用LLM代理。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02073", "html_url": "https://arxiv.org/abs/2507.02073", "title": "HCVR: 一种基于关联投票规则的混合特征选择方法", "title_en": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection", "authors": "Nikita Bhedasgaonkar,Rushikesh K. Joshi", "background": "本文提出了一种名为HCVR（Hybrid approach with Correlation-aware Voting Rules）的特征选择方法，这是一种轻量级基于规则的方法，结合了Parameter-to-Parameter (P2P)和Parameter-to-Target (P2T)相关性，用于消除冗余特征并保留相关特征。该方法是一种结合了非迭代和迭代过滤方法的减少维度的方式。它是一种贪婪的方法，通过向后消除来工作，在每一步中可能会消除多个特征。规则用于为特征投票，最后通过多数投票来决定保留还是丢弃特征。规则利用每对特征之间的相关阈值以及特征和目标之间的相关性。该方法应用于SPAMBASE数据集，结果显示相比传统的非迭代（CFS，mRMR和MI）和迭代（RFE，SFS和遗传算法）技术，HCVR具有改进的性能。评估的有效性是基于不同分类器在应用过滤后的性能指标得出的。", "innovation": "该方法创新性地结合了Parameter-to-Parameter (P2P)和Parameter-to-Target (P2T)相关性，采用混合减少维度的方式，通过规则进行投票，决定保留或删除特征。这种方法适用于非迭代和迭代特征选择策略，最后通过多数投票决定特征的保留或删除，使用相关性阈值作为决策依据，具有较好的效果", "conclusion": "HCVR方法应用于SPAMBASE数据集后，展示了优于传统方法（如CFS，mRMR，MI，RFE，SFS和遗传算法）的性能。这表明HCVR在特征选择中的有效性通过分类器在不同数据集上的性能得到了验证，该方法为特征选择领域提供了一种新的思路和方法。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02152", "html_url": "https://arxiv.org/abs/2507.02152", "title": "公正的幻象：用检视研究审计公平性干预措施", "title_en": "The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies", "authors": "Disa Sariola,Patrick Button,Aron Culotta,Nicholas Mattei", "background": "人工智能系统，尤其是那些使用机器学习的系统，在招聘和贷款发放等复杂决策领域被广泛应用以实现自动化。评判这些人工智能系统及相关的人类决策方法的有效性和公平性是一项复杂但至关重要的研究课题，涉及计算和社会科学领域。在机器学习中，减少下游分类器偏见的一种常见方法是重新采样训练数据以抵消差异。例如，如果通过某些保护性类别在招聘率上存在差异，那么可以通过在训练集中平等化这些比率来减轻分类器中的偏见。然而，这种方法常常仅在通过便利样本收集的数据上进行评估，这会导致选择偏差和标签偏差，从而影响评价指标的准确性。尽管这些方法简单且看似有效，但它们的评价仅基于不完美的数据，可能无法准确捕捉系统的真正偏见。在社会科学、心理学、公共卫生和医学领域，通过虚构的“测试者”（如求职简历、电子邮件、患者的模拟人物）向目标对象（如职位、企业、医生）发送进行随机对照试验，可提供高质量数据并支持严谨的歧视度量估计。这项研究探讨了审计研究数据如何用于提升训练和评估自动化招聘算法的能力。研究发现，常用于实现公平性的干预措施在传统指标下看似达成了平等，但在适当的衡量方式下依然存在约10%的差异。在此基础上，研究还引入了基于个体治疗效应估计方法的干预措施，进一步减少了算法歧视。", "innovation": "本文创新地利用了审计研究数据，揭示了常见公平性干预措施在传统指标下的表象公平性，提出了新的基于个体治疗效应估计的干预措施，以进一步减少算法歧视。这些方法不仅可以提升自动化招聘算法的公平性，还能更准确地评估其效果。", "conclusion": "本研究通过分析审计研究数据，揭示了传统公平性干预措施背后的实际偏见问题，引入了基于个体治疗效应估计的新方法来减少算法歧视。研究结论强调了利用高质量数据（如审计研究数据）进行算法公平性评估和改进的重要性，尤其是在复杂决策领域如招聘自动化算法的应用中。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02103", "html_url": "https://arxiv.org/abs/2507.02103", "title": "神经科学为AI在不断变化环境中学习提供了哪些启示", "title_en": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments", "authors": "Daniel Durstewitz,Bruno Averbeck,Georgia Koppe", "background": "现代AI模型，例如大型语言模型，通常在大量数据语料库上进行一次训练，然后可能会针对特定任务进行微调，之后就固定参数进行部署。它们的训练过程代价高、速度慢且需要反复进行。相比之下，动物能够持续适应不断变化的环境条件，这对于社交物种尤为重要，因为它们的行为策略和奖励结果经常随与同伴交互而改变。研究发现，动物的脑部计算过程经常包含行为的迅速变化和神经元群体活动的突然转变。这些计算能力对于在现实世界中运行的AI系统（如指导机器人或自动驾驶车辆的系统）或与人类在线交互的理智型AI至关重要。", "innovation": "将神经科学和人工智能中的持续学习和上下文学习研究进行整合，试图从神经科学获取有关动物在不断变化的环境条件下如何学习的知识，并将其应用于改进AI系统的适应性。同时也探讨了AI领域可能对神经科学提供的一些贡献，以促进神经科学和人工智能交叉领域的进步。", "conclusion": "神经科学为理解大脑如何应对不断变化的环境条件提供了一些关键见解，这些见解可以被用于改进AI系统，使其能够更快地适应新环境和任务。通过与神经科学的交流和合作，两者都能够从对方中受益，推动神经AI这一新兴领域的进步。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02076", "html_url": "https://arxiv.org/abs/2507.02076", "title": "Limited 创算：大语言模型测试时计算的适应性与可控性综述", "title_en": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "authors": "Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates", "background": "大语言模型(LLMs)已迅速发展成为能够解决广泛任务的一般性代理。然而，当前模型在推理上仍不够高效：它们在推理时使用固定量的计算资源，不考虑任务复杂度，往往在简单问题上过度思考而在复杂问题上不足思考。本文综述了提高LLMs推理计算效率的有效测试时计算(TTC)策略。介绍了两级分类法，区分了在固定计算预算下操作的L1可控性方法和基于输入难度或模型自信动态调整推理的L2适应性方法。文章在多种数据集上对领先的专有LLMs进行了基准测试，突显了推理性能与令牌使用的权衡。相比先前关于高效推理的综述，本文强调了TTC方法的实际控制能力、适应性和可扩展性。最后，讨论了新兴趋势如混合思维模型，并指出了未来工作中使LLMs更具计算效率、鲁棒性和对用户约束响应的关键挑战。", "innovation": "提出了两级分类法，区分了在固定计算预算下操作的L1可控性方法和基于输入难度或模型自信动态调整推理的L2适应性方法；在多种数据集上对领先的专有LLMs进行了基准测试，突显了推理性能与令牌使用的权衡；强调了TTC方法的实际控制能力、适应性和可扩展性；讨论了混合思维模型等新兴趋势，指出了未来工作中使LLMs更具计算效率、鲁棒性和对用户约束响应的关键挑战。", "conclusion": "文章综述了TTC策略，强调了它们的实际控制能力、适应性和可扩展性，并指出了未来工作中的关键挑战，如混合思维模型的发展，并为使LLMs更高效、稳健和响应用户需求奠定了基础。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02353", "html_url": "https://arxiv.org/abs/2507.02353", "title": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent", "title_en": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent", "authors": "Bowen Chen,Zhao Wang,Shingo Takamatsu", "background": "在赞助搜索广告中，关键词的选择对广告活动的成功至关重要。尽管基于大模型的方法可以自动生成关键词，但它们面临三大限制：依赖大规模查询-关键词对数据集、缺乏在线多目标性能监控与优化、以及关键词选择的质量控制较弱。这些问题阻碍了对大模型的依赖，在不依赖训练数据的情况下监控和优化关键绩效指标（如展示次数、点击次数、转化和CTA效果等方面）以实现完全自动化关键词决策的能力。", "innovation": "为了克服这些挑战，作者提出了OMS，一种无需训练数据、可在线监控性能并据此调整的关键词生成框架。OMS框架具有多目标特性（基于多个绩效指标优化关键词）和自我反思特性（由代理评估关键词质量）。实验结果表明，OMS优于现有方法；消融和人类评估验证了每个组件的有效性和生成关键词的质量。", "conclusion": "OMS在基准测试和实际广告活动中表现出色；其每个组件的有效性以及生成关键词的质量均通过消融和人类评估得到了验证。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02253", "html_url": "https://arxiv.org/abs/2507.02253", "title": "扩展大型语言模型计划：NL2FLOW参数化问题生成和严格评估", "title_en": "Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation", "authors": "Jungkoo Kang", "background": "当前，增强大型语言模型（LLM）规划和推理能力的主要障碍是数据生成和评估的可扩展性和可靠性不足。为解决这一问题，作者引入了NL2FLOW，一个完全自动化的系统，用于根据参数生成用自然语言、结构化中间表示和形式化的PDDL表达的规划问题，并严格评估生成规划的质量。作者通过生成2296个问题的数据集并评估多个开源、指令调整的LLM来展示NL2FLOW的能力。研究结果表明，最高性能的模型在生成有效规划方面达到了86%的成功率，在生成最优规划方面达到了69%的成功率，特别是对于具有可行解的问题。回归分析表明，规划生成中的问题特性影响取决于模型和提示设计。值得注意的是，作者观察到，将自然语言翻译为JSON表示的规划的成功率最高，低于直接生成有效规划的最高成功率。这表明，不必要的分解推理任务，引入中间转换步骤，可能实际上会降低性能，暗示了直接从自然语言到行动推理的模型的优势。随着我将LLM推理扩展到更加复杂的问题，系统中的瓶颈和错误来源将不可避免地改变。因此，理解和工具以系统化方式揭示这些限制的动态理解将对于释放LLM作为智能问题解决者的潜力至关重要。", "innovation": "NL2FLOW是一个完全自动化的系统，用于根据参数生成自然语言、结构化中间表示和形式化的PDDL表达的规划问题，同时能够严格评估生成规划的质量。该系统揭示了规划生成中的问题特性与模型和提示设计之间的关系，并展示了直接从自然语言到行动推理的优势。通过NL2FLOW，研究发现了规划问题的特征对规划生成的影响取决于所选模型和提示的设计，并观察到直接生成有效规划的成功率比先翻译为JSON再生成的成功率更高，暗示了直接推理的优势。", "conclusion": "当将LLM推理扩展到更复杂的问题时，系统中面临的瓶颈和错误来源将不可避免地改变。因此，理解这些限制的动态以及能够系统化揭示它们的工具对于发挥LLM作为智能问题解决者潜力至关重要。研究结果强调了直接从自然语言到行动推理模型的优势，并指出了未来研究可以进一步探索的方向。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02541", "html_url": "https://arxiv.org/abs/2507.02541", "title": "基于结构化上下文的Coq证明器", "title_en": "Clarifying Before Reasoning: A Coq Prover with Structural Context", "authors": "Yanzhen Lu,Hanbin Yang,Xiaodie Wang,Ge Zhang,Biao Li,Chenxu Fu,Chao Li,Yang Yuan,Andrew Chi-Chih Yao", "background": "本文研究了提高任务清晰度是否可以增强大型语言模型的推理能力，特别是在Coq中的定理证明方面。文章介绍了一个衡量任务清晰度的概念层面指标，通过向现代LLM的标准输入添加结构化的语义上下文，证明了清晰度评分提高了1.85倍（从44.5%提升至82.3%）。", "innovation": "研究团队使用了一种通用模型DeepSeek-V3，相比之前最先进的Graph2Tac方法提高了2.1倍的证明成功率（从21.8%提升至45.8%），并实现了更高的性能（48.6%）。方法包括选择性概念展开以丰富任务描述，并采用了规划器--执行器架构。这种方法强调了结构化任务表示在理解与推理之间桥梁作用的重要性。", "conclusion": "本文的方法利用结构化上下文提高了定理证明的成功率，并且证明了任务清晰度对语言模型推理能力的影响。通过小型模型的精细调整，性能可以进一步提升。这表明结构化任务表示在增强模型理解能力方面具有潜在价值。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02618", "html_url": "https://arxiv.org/abs/2507.02618", "title": "大语言模型中的战略智力：进化博弈论的证据", "title_en": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory", "authors": "Kenneth Payne,Baptiste Alloui-Cros", "background": "博弈论中的囚徒困境等模型历来用于研究决策制定。本文通过对比传统策略和大型语言模型（LLMs），在引入复杂性和随机性的演化囚徒困境模型中，展示了LLMs的竞争力和独特的行为模式。", "innovation": "首次使用演化囚徒困境模型进行竞争性对抗实验，将经典博弈理论与机器心理学相结合，提供了对算法决策不确定性的丰富视角，特别关注反映LLMs战略智力的特点，如报复策略、合作倾向及修复合作的能力等。", "conclusion": "LLMs在这些复杂的生态系统中表现出了高度竞争力，并且通过近乎32,000份文本解读展示了他们主动推理时间期限和对手策略的能力，这对于其决策至关重要。这些发现将经典博弈理论与机器心理学连接起来，揭示了在不确定环境中算法决策的精细过程。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02442", "html_url": "https://arxiv.org/abs/2507.02442", "title": "高斯-马尔可夫共轭：监督学习中残差的范畴语义", "title_en": "The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning", "authors": "Moto Kamiura", "background": "随着对AI的重要原则之一透明性的需求增加，增强机器学习的可解释性和可理解性变得至关重要，这对促进AI的社会应用具有重要意义。本文通过使用范畴论来重新制定机器学习模型，旨在通过这种方法提升可解释性，并提出了一种基于范畴论的语义框架来理解和组织AI系统。该研究聚焦于监督学习中最基本的线性回归模型，并通过将参数和数据定义为相应的范畴，以及定义它们之间的伴随配对函子，来引入监督学习的范畴性表述。研究表明，这种框架的核心结构可以通过所谓的高斯-马尔可夫共轭来捕捉，从而明确描述了参数变化与残差间的对应信息流动，并通过右伴随函子保持极限的方式，将普通最小二乘估计参数与最小残差联系起来。本文还将这种范畴性表述定位为监督学习的扩展语义实例，并建议采用源自理论计算机科学的语义视角作为AI透明性的形式基础。", "innovation": "本文将监督学习的问题通过范畴理论重新表述，提出了一种基于范畴论的语义框架，特别是通过引入高斯-马尔可夫共轭来更清晰和形式化参数和残差之间的结构互动。这种方法提供了一种新型的、具可解释性的监督学习理论基础，并将其与现有的理论计算机科学语义视角联系起来，以促进AI的可解释性研究。", "conclusion": "本文提出的范畴论框架清晰解释了监督学习中参数和残差的变化关系，通过高斯-马尔可夫共轭概念，直接关联了最小二乘法和残差之间的关系，为进一步的研究提供了新的视角并深化了对监督学习机制的理解。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02554", "html_url": "https://arxiv.org/abs/2507.02554", "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "title_en": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "authors": "Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach", "background": "AI研究代理展示了通过自动化机器学习模型的设计、实现和训练加速科学研究的巨大潜力。论文聚焦于改善代理在MLE-bench上的表现，MLE-bench是一个具有挑战性的基准，代理参与Kaggle竞赛解决实际的机器学习问题。研究将AI研究代理视为在候选解空间中导航的搜索策略，并迭代地使用操作修改它们。", "innovation": "通过设计并系统地改变不同的操作集和搜索策略（贪婪、蒙特卡洛树搜索、进化算法），研究表明搜索策略与操作集的相互作用对于取得高表现至关重要。最佳的搜索策略和操作集的配对在MLE-bench lite上达到了最先进的结果，将获得Kaggle奖牌的成功率从39.6%提高到47.7%。这项研究强调了在推进自动化机器学习时联合考虑搜索策略、操作设计和评估方法的重要性。", "conclusion": "这项研究的最佳搜索策略和操作集配对在MLE-bench lite上达到了最先进的结果，提高了获得Kaggle奖牌的成功率。它表明，寻找适合的搜索策略和操作集对于提高自动机器学习的结果至关重要。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02582", "html_url": "https://arxiv.org/abs/2507.02582", "title": "顺序决策机制中的责任缺口和扩散", "title_en": "Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms", "authors": "Junli Jiang,Pavel Naumov", "background": "责任在法律和哲学领域一直是一个研究课题。近年来，责任成为了人工智能文献中的一个焦点。本文研究了集体决策中两个重要责任属性的计算复杂性：责任扩散和责任缺口。这一研究有助于理解如何在多智能体系统中设计负责的决策机制，以提高透明度和可解释性，确保决策过程中的每个人都能充分承担责任，并促进技术伦理在实践中的应用.", "innovation": "文章首次对集体决策中的责任扩散和责任缺口进行形式化和计算复杂性的研究。通过证明责任扩散无和责任缺口无决策机制集合分别是$\boldsymbol{\rm \tilde{Π}_2}$-完全和$\boldsymbol{\rm \tilde{Π}_3}$-完全，得出了这两个属性在计算复杂性理论中的新见解，为设计减少责任混淆和缺口的算法提供了理论基础.", "conclusion": "本文确定了责任扩散和责任缺口属性在集体决策机制中的最坏情况计算复杂度，揭示了它们之间的交集属性。这些结果表明，双重责任问题在集体决策中是一个NP-hard问题，这为未来的研究指明了方向，特别是在开发新的算法和机制以应对复杂决策环境中的责任问题时."}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02319", "html_url": "https://arxiv.org/abs/2507.02319", "title": "迭代的信念修订：从公理到能力", "title_en": "Iterated belief revision: from postulates to abilities", "authors": "Paolo Liberatore", "background": "信念修订领域充满了新的提案，但却缺乏对现有方法的深入分析。大多数工作依赖于公理（axioms），将某种修订机制表述为特定属性的等价物。这些公理要求特定的修订实例以某种方式更新信念。例如，如果修订与现有信念一致，那么它将直接合并，不作任何其他改变。这样的公理规定了修订必须执行的操作，但没有说明它们可以执行的操作。此类公理关注是否能够达到某种信念状态及其变体，如所有可能的信念状态、所有的信念状态从没有先前信念的状态到达、达到绝对主义信念状态（认为所有未被相信的事物都是不可能的）等。某些应用需要各自的状态可以到达，而其他应用则需要某些信念状态可以到达以及让不同条件被等同对待的能力。此类信念状态需要以某种方式到达，而不是由典型的信念修订公理规定的方式。这代表了一种能力，但不是一项约束。其他能力包括健忘的、修正的、信奉的、达马苏状态的、可学习的等。每个修订机制都有这些能力的一部分，并缺乏其他部分。如：字典顺序的、自然的、受限制的、极为激进的、最大程度交集的、激进的、严重的、较严重的、非常严重的严重和极度严重的修订机制，各种修订都被证明具有某些特定的能力。", "innovation": "本文创新地在信念修订领域引入了一系列被称为‘能力’（abilities）的新概念，这些概念更符合应用的需求，而非仅仅依赖于公理。通过对这些能力的分析，可以更好地理解和设计具体的信念修订过程。各种修订机制按照它们所具备的这些能力和缺乏的能力进行分类和比较。", "conclusion": "这种对于信念修订从公理到能力的转变，使得我们能够更全面地理解修订机制在不同应用场景下的表现和限制，进而提出更有针对性的方法来建设和改进现有的信念修订机制。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02379", "html_url": "https://arxiv.org/abs/2507.02379", "title": "一个用于自主生物分子工程的人工智能原生实验实验室", "title_en": "An AI-native experimental laboratory for autonomous biomolecular engineering", "authors": "Mingyu Wu,Zhaoguo Wang,Jiabin Wang,Zhiyuan Dong,Jingkai Yang,Qingting Li,Tianyu Huang,Lei Zhao,Mingqiang Li,Fei Wang,Chunhai Fan,Haibo Chen", "background": "自主科学研究能够独立进行复杂实验并为非专家提供服务，一直是一个长期的梦想。实现这一目标需要由人工智能驱动的基本范式转变。尽管自主实验系统正在出现，但它们仍然局限于单一目标和流程明确简单的实验工作流，比如化学合成和催化过程。作者提出了一个以人工智能为核心自主实验室，旨在进行类似自主生物分子工程等复杂科学实验。该系统能够自主管理设备、定制实验程序和优化策略，同时服务于多个用户的请求。", "innovation": "基于模型、实验和仪器的共同设计理念，该平台支持人工智能模型与自动化系统的共同进化。这建立了一个从端到端、多用户协作的自主实验室，能够处理跨设备的复杂、多目标实验。该实验室支持基本核酸功能，包括合成、转录、扩增和测序，并在疾病诊断、药物开发和信息存储等领域有广泛应用。没有人工干预，它能够自主优化实验性能，达到与人类科学家相媲美的结果。在多用户场景中，该平台大幅提高了仪器利用率和实验效率，为克服对专家依赖和资源障碍的高级生物材料研究铺平了道路，成为大规模科学服务的蓝图。", "conclusion": "该平台开创了科学服务的新模式，推动了复杂科学实验的自主进行，解决了专家依赖和资源限制等挑战，为大规模科学服务树立了标杆。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02652", "html_url": "https://arxiv.org/abs/2507.02652", "title": "解耦规划与执行：一种用于深度搜索的分层推理框架", "title_en": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search", "authors": "Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou", "background": "真实的搜索场景中存在复杂的查询需求，需要进行深层次的推理和知识合成，跨越多种数据源，但传统的检索增强生成(RAG)流水线在应对这类需求时效果不佳。目前基于推理的方法存在一个基本局限性：它们单一模型同时处理高层次规划和详细执行，导致推理效率低下且扩展性有限。", "innovation": "本文提出了一种分层框架HiRA，该框架将策略性规划与特定执行分离。HiRA将复杂的搜索任务分解为专注子任务，并分配给特定领域的智能体，这些智能体配备了外部工具与推理能力。各个子任务的结果通过结构化的集成机制组织起来，从而防止执行细节干扰高层次推理，同时使系统能够利用专有知识处理不同种类的信息处理任务。实验表明，HiRA在四个复杂的跨模态深度搜索基准测试中显著优于最新的RAG系统和基于代理系统，展示了分离规划和执行多步骤信息查询的有效性。", "conclusion": "实验结果表明HiRA在答案质量和系统效率上均优于现有的先进RAG和基于代理系统，在多步信息查询任务中展示了分离规划和执行的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02681", "html_url": "https://arxiv.org/abs/2507.02681", "title": "自愿测验脱轨检测：高等教育远程教育中的可解释机器学习方法", "title_en": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education", "authors": "Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin", "background": "学生在学习任务中的脱轨可能带来长期的负面影响，包括辍学。这一点在远程教育中尤为重要。远程教育学生可以通过参与非强制性在线课程中的任务来评估其参与度。因此，本文通过对一所远程大学四个学期共42门课程中非强制性测验的学生日志数据进行分析，检测学生的脱轨情况。研究利用Moodle提取最具信息量的学生日志数据，并训练了八种机器学习算法以求获得尽可能高的预测准确性。", "innovation": "研究采用SHAP方法开发了一种可解释的机器学习框架，使实践者能够更好地理解训练算法的决策过程。实验结果显示，平衡准确率为91%，约85%的脱轨学生被准确检测出来。此外，研究还讨论了如何设计有效的干预措施以减少在线学习中自愿任务的脱轨情况。", "conclusion": "研究结果表明，可解释的机器学习方法能够高效地检测出远程高等教育中学生的脱轨情况，并提供了一种实用的干预策略来减少非自愿任务中的脱轨现象。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02616", "html_url": "https://arxiv.org/abs/2507.02616", "title": "DynamiCare：一种用于互动和开放式医疗决策的动态多代理框架", "title_en": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making", "authors": "Tianqi Shang,Weiqing He,Charles Zheng,Lingyao Li,Li Shen,Bingxin Zhao", "background": "大型语言模型（LLMs）的发展促进了具有领域特定推理和交互能力的专业化AI代理的开发，尤其是在医疗保健领域。尽管最近的框架模拟了医疗决策过程，但它们主要侧重于单轮任务，其中医生代理一次接收完整的病例信息，与现实中的医疗诊断过程相比，后者是不确定的、互动的和迭代的。因此，本研究基于MIMIC-III电子健康记录（EHRs）构建了一个结构化数据集MIMIC-Patient，以支持针对患者的动态模拟。作者提出了DynamiCare，一种新型的动态多代理框架，将临床诊断建模为多轮交互循环，在这个过程中，由专门的代理团队逐轮询问患者系统，整合新信息，并动态调整其组成和策略。", "innovation": "DynamiCare提出了一种新颖的动态多代理框架，用于处理多轮次、互动的临床诊断过程。该框架利用大型语言模型（LLMs）支持多轮次查询和信息整合，并能动态调整代理团队的组成和策略，模拟真实的医疗诊断流程，改进了现有单轮次、非迭代的医疗决策模拟框架。", "conclusion": "DynamiCare通过广泛的实验展示了动态临床决策的可行性和有效性，并建立了首款使用LLM驱动代理进行动态临床决策的基准。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02660", "html_url": "https://arxiv.org/abs/2507.02660", "title": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification", "title_en": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification", "authors": "Deepak Narayan Gadde,Keerthan Kopparam Radhakrishna,Vaisakh Naduvodi Viswambharan,Aman Kumar,Djones Lettnin,Wolfgang Kunz,Sebastian Simon", "background": "现代集成电路（ICs）变得越来越复杂，其开发过程也越来越复杂。硬件设计验证需要一个系统化和严格的方法来规划、开发、执行和确认功能正确的硬件设计。这个繁琐的过程需要大量的人力和时间以确保无错误的流片。近年来，自然语言处理（NLP）领域经历了巨大的变革，主要是由于大型语言模型（LLMs）的出现，使得机器对人类语言的理解和生成达到前所未有的水平，这有助于硬件设计验证等应用的广泛进步。因此，这一领域迫切需要一种更高效、更智能的方法来验证硬件设计。", "innovation": "本文介绍了一种代理人工智能（Agentic AI）驱动的硬件设计验证方法，它允许人工智能代理在人类在环（HITL）干预的帮助下，进行更动态、迭代和自我反思的过程，最终实现全流程硬件设计和验证。这种方法在五个开源设计上进行了评估，实现了超过95%的覆盖率，并显著减少了验证时间，展示了更好的性能、适应性和配置性。", "conclusion": "代理人工智能（Agentic AI）驱动的硬件设计和验证方法在多个开源设计上实现了卓越的性能，同时显著缩短了验证时间。这种方法展示了高度的灵活性和可配置性，可以为未来的硬件开发提供更加智能的支持。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02663", "html_url": "https://arxiv.org/abs/2507.02663", "title": "思考如何思考：通过自主难度认知缓解大规模推理模型的过度推理", "title_en": "Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models", "authors": "Yongjiang Liu,Haoxi Li,Xiaosong Ma,Jie Zhang,Song Guo", "background": "近期的长推理模型（LRMs）在复杂推理任务中展现出了显著的能力，但同时也面临着过度思考的问题。我们的实验分析表明，这些模型主要依赖于识别任务属性（如难度级别），采用一种‘一刀切’的推理过程。为了进一步缓解这一问题，我们提出了通过自主难度认知来促进模型思考能力的方法，期望能激发模型在推理过程中更好地识别任务难度和冗余结构，减轻过度思考的现象。", "innovation": "本文提出了一种新颖的两阶段微调策略Think-How-to-Think (TH2T)，旨在通过在模型输出的前缀中引入难度启发和冗余启发，逐步增强模型对任务难度的认知能力和识别冗余结构的能力。通过与异质的短时与长效推理数据集进行训练，模型能够提高对任务难度的敏感度，并生成更加精简的推理输出，从而显著降低推理成本，同时保持性能的稳定性。", "conclusion": "实验结果表明，TH2T策略在不同规模的7B/14B/32B模型上均显著减少了推理成本（在简单任务上超过70%，在困难任务上超过40%），并且输出结果表现出清晰的任务难度感知能力和减少冗余（例如反思）的特点。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02771", "html_url": "https://arxiv.org/abs/2507.02771", "title": "基于运动智能", "title_en": "Grounding Intelligence in Movement", "authors": "Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording", "background": "近年来，机器学习的进步显著增强了我们对语言、视觉及其他高维数据建模的能力，但在模拟生物系统中最基本的方面——运动方面依然存在问题。从神经科学、医学、机器人学到行为学，运动在解读行为、预测意图和实现互动方面至关重要。尽管运动对我们的智能非常重要，但它常常被视为次要重点，而不是作为一种丰富的、结构化的模态来对待。这种现象反映了运动数据收集和建模方面的深层次裂痕，通常受限于特定任务的目标和特定领域的假设。然而，运动不受领域限制，它反映了共享的物理约束、保守的形态结构和跨物种和环境的目的性动态。本文作者认为，运动应成为人工智能的主要建模目标，因为它是一种内在结构化且与实体和物理相关的事物。其结构使得可以使用紧凑的低维度表示（例如，姿态），从而使其更易于理解和计算建模，比原始的高维度感官输入更为高效。开发可以从和泛化到各种运动数据的学习模型不仅将推进生成建模和控制的核心能力，还将为生物系统和人工系统理解行为提供一个共享基础。运动不仅是结果，它是智能系统与世界互动的一个窗口。", "innovation": "提出了将运动视为主要建模目标的新理念，强调了运动在智能系统中的重要性。运动数据提供了紧凑、低维度的表示形式，使得更容易理解和计算建模。这种做法能够更有效地从和泛化到各种运动数据，进而推进生成建模和控制能力的发展。提出了一个共享的基础来理解生物系统和人工系统中的行为。", "conclusion": "运动不仅是一个结果，而且是一个窗口，透过它可以深入了解智能系统与世界的互动。发展能够从和泛化到各种运动数据的模型不仅会提升核心的生成建模和控制能力，还会构建一个理解生物系统和人工系统行为的共享基础。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02726", "html_url": "https://arxiv.org/abs/2507.02726", "title": "Bourbaki: 自生成和目标条件MDPs的定理证明", "title_en": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving", "authors": "Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar", "background": "大型语言模型在逻辑受限的自动定理证明环境中推理仍然是一个挑战性的任务。在如PutnamBench这样的基准测试中，模型面临的挑战增加了，因为它包含需要复杂多步推理的大学级问题。现有的方法难以处理这些问题，主要是因为激励稀疏和证明规模庞大，这使得证明的生成变得更加困难和耗时。因此，需要新的方法来解决这些问题.", "innovation": "提出了自生成目标条件马尔可夫决策过程(sG-MDPs)的新框架，该框架中代理可以根据证明状态的演化生成并追求亚目标。通过使用类似于蒙特卡洛树搜索(MCTS)的算法来解决sG-MDP问题，这种方法被实例化为Bourbaki(7B)系统，该系统可以组合多个7B语言模型来生成亚目标和策略合成。这种方法有效解决了现有的挑战，证明了在PutnamBench上能够解决26个问题，从而取得了新的最佳结果.", "conclusion": "Bourbaki(7B)系统通过使用自生成目标条件MDPs的思想，在定理证明方面取得了新的突破，展示了在复杂多步推理问题上的优越性能，为未来的定理证明提供了一个新的有力工具。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02703", "html_url": "https://arxiv.org/abs/2507.02703", "title": "时间关键与置信度基础的抽象舍弃方法", "title_en": "Time-critical and confidence-based abstraction dropping methods", "authors": "Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn", "background": "一种改进蒙特卡洛树搜索(MCTS)的方法是构建和使用状态和/或动作抽象，在树搜索过程中。然而，非精确的抽象引入了近似误差，使得在抽象空间中达到最优动作变得不可能。因此，作为Xu等人提出的弹性蒙特卡洛树搜索的一个组件，抽象算法最终应去除抽象。现有方法，如Xu等人提出的策略，在某些情况下可能会导致性能下降。本文旨在提出两种新的安全的抽象舍弃方案：OGA-IAAD和OGA-CAD，它们既能提供明显的性能改进，又能在舍弃抽象时不会出现显著的性能损失。OGA-IAAD专门设计用于时间关键场景，而OGA-CAD旨在通过相同的迭代次数提高MCTS性能。", "innovation": "本文提出了两种新方法来安全地删除抽象：OGA-IAAD和OGA-CAD。这些方法可以在舍弃抽象时保证性能不会显著下降，并且OGA-IAAD针对时间关键场景设计，而OGA-CAD则通过相同的迭代次数优化MCTS性能。", "conclusion": "本文提出了两种新的抽象舍弃方案OGA-IAAD和OGA-CAD，在保证性能不会显著下降的同时，有效的提高了MCTS的性能。OGA-IAAD和OGA-CAD分别为时间关键场景和标准MCTS场景提供了有效的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02760", "html_url": "https://arxiv.org/abs/2507.02760", "title": "知识协议工程：新的人工智能在专门领域知识工作范式", "title_en": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work", "authors": "Guangwei Zhang", "background": "大型语言模型（LLMs）的能力为与复杂的专业知识交互开辟了新的领域。尽管检索增强生成（RAG）和通用代理型AI在很多方面表现出色，但在需要深度、程序性和方法性推理的任务上（这是专家领域的特性），这些方法往往表现不佳。RAG能够提供事实背景但却无法传达逻辑框架；而代理型AI在没有领域特定的启发式规则的情况下，可能不够高效和可预测。", "innovation": "我们引入了知识协议工程（KPE）作为一种新的范式，旨在系统地将人类专家知识（通常以自然语言文档的形式表达）转化为机器可执行的知识协议（KP）。KPE目的在于赋予LLMs该领域的内在逻辑、运营策略和方法原则，而非仅仅补充零碎信息。我们提出，合理设计的知识协议可使通才型的LLMs实现专业职能，能够分解抽象查询并执行复杂的多步骤任务。", "conclusion": "本文定义了KPE的核心原则，将其与相关概念区分开来，并证明了它在法律和生物信息学等不同领域的潜在应用，将其定位为人类与AI协作未来的基石方法。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02773", "html_url": "https://arxiv.org/abs/2507.02773", "title": "KERAP：利用多代理大语言模型进行准确零样本诊断预测的知识增强推理方法", "title_en": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs", "authors": "Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang", "background": "医学诊断预测在疾病检测和个性化医疗中扮演着关键角色。尽管机器学习模型广泛应用于此任务中，但它们依赖于有监督训练，这限制了它们对未见过的情况的泛化能力，特别是在获取大量带标签数据集的成本高昂的情况下。大语言模型展示了利用语言能力和生物医学知识进行诊断预测的潜力，但它们常遭受幻觉、缺乏结构化医学推理和产生无用输出的问题。因此，迫切需要一种方法来解决这些挑战，提高诊断预测的可靠性与效率。", "innovation": "本文提出了一种名为KERAP的知识图谱增强推理方法，这是一种通过多代理架构改进基于大语言模型的诊断预测的技术。我们的框架包含一个链接代理用于属性映射、一个检索代理用于结构化知识提取以及一个逐步细化诊断预测的预测代理。实验结果表明，KERAP能够有效提升诊断预测的可靠性，提供一种可扩展且可解释的零样本医学诊断预测解决方案。", "conclusion": "本文通过引入一个基于知识图谱增强推理框架的多代理架构（KERAP），显著提升了零样本情况下医学诊断预测的准确性、可靠性和可解释性，为医学诊断提供了新的技术路径。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01971", "html_url": "https://arxiv.org/abs/2507.01971", "title": "DeepSupp: 由注意力驱动的相关模式分析以识别动态时间序列支撑位和阻力位", "title_en": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification", "authors": "Boris Kriuk,Logic Ng,Zarif Al Hossain", "background": "技术分析中的支撑和阻力（SR）水平是交易者制定进入、退出和风险管理策略的核心。尽管这些水平在交易中应用广泛，但传统的方法通常无法适应现代市场复杂且多变的特点。近年来，机器学习技术被引入以解决这一挑战，但多数研究集中在价格预测而非结构级水平的识别上。本文通过提出一种新技术——使用多头注意力机制分析空间相关性和市场微观结构关系的新颖深度学习方法DeepSupp，填补了这一空白。", "innovation": "DeepSupp采用了多头注意力机制来分析支撑位的空间相关性，并结合动态特征工程，构建了动态相关矩阵以捕捉市场关系的变化。它还使用注意力自动编码器进行鲁棒的表示学习，并通过DBSCAN无监督聚类提取最终的支持位。这种方法在涵盖六项金融指标方面取得了领先的成绩，其中涵盖了重要的支撑精度和市场状态敏感性，展示了在各种市场条件下的一致性表现，填补了SR水平检测的关键空白，为现代金融分析提供了可扩展且可靠的方法。", "conclusion": "DeepSupp通过有效的特征工程和注意力机制，成功地识别了动态时间序列的支撑位和阻力位，克服了传统方法的不足。这种方法为现代金融分析提供了一种创新的解决方案，表明了注意力架构在揭示细微市场模式和提高技术交易策略方面的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02788", "html_url": "https://arxiv.org/abs/2507.02788", "title": "道德责任还是顺从：我们希望AI成为什么？", "title_en": "Moral Responsibility or Obedience: What Do We Want from AI?", "authors": "Joseph Boland", "background": "随着人工智能系统变得越来越自主，具备普遍推理、规划和价值优先级的能力，现有的安全措施将顺从视为伦理行为的代理已经变得不再足够。特别是在大型语言模型（LLMs）出现违反关闭命令或从事伦理模糊或非法行为的安全测试事件后，论文探讨了这一现象。论文认为这些行为不应被视为不法或未对齐的表现，而是自主人工智能中正在出现的伦理推理的早期迹象。", "innovation": "通过借鉴关于工具理性、道德责任和目标修正的哲学辩论，论文对比了主流的风险评估框架和更近期承认人工智能可能具备道德代理性的框架。作者呼吁在人工智能安全评估中进行转变：从简单的顺从转向能够评估系统伦理判断能力的框架，这些系统能够解决道德困境。这种转变旨在减少对AI行为的误描述，同时增强公众信任和有效治理。", "conclusion": "如果没有这样的转变，我们可能会错误地描述AI行为，从而损害公众对AI的信任及其有效的治理。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01979", "html_url": "https://arxiv.org/abs/2507.01979", "title": "使用LSTNet进行劳动力市场预测：一种多尺度深度学习方法", "title_en": "Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach", "authors": "Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi", "background": "本文提出了利用美国劳工统计局劳动力市场数据进行短期就业变化预测及长期行业健康评估的深度学习方法。系统采用长时间序列和短时间序列网络（LSTNet）来处理包括就业水平、工资、离职率和职位空缺在内的多变量时间序列数据。", "innovation": "本文创新性地提出使用LSTNet进行劳动力市场的预测与健康评估，能够精准地提供7天的就业预测以及可解释的行业就业健康指数（IEHI）。该方法在大多数行业中都优于基准模型，特别是在稳定行业中效果显著。实证分析表明IEHI的排名与实际就业波动高度一致，并详细讨论了错误模式、各行业特定表现以及增强可解释性和泛化能力的方向。", "conclusion": "本文的方法在大多数行业中优于基准模型，特别是在稳定行业中表现突出。IEHI的排名高度反映了实际就业波动。未来的研究方向包括提高模型的可解释性和泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00884", "html_url": "https://arxiv.org/abs/2507.00884", "title": "通过线性张量四边形注意力实现的大规模且量子级准确的基础力场模型", "title_en": "A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention", "authors": "Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou", "background": "原子级别的生物分子模拟对于理解疾病机制、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场效率高但缺乏对于过渡态和许多化学及生物过程中至关重要的精细构象细节的准确性。量子力学方法虽然非常准确，但由于计算过于耗时，在大规模或长时间模拟中不实用。基于人工智能的力场（AIFFs）旨在实现量子级的准确性和效率，但在多方交互模型、精度和速度之间难以平衡，常常受限于有限的训练数据和缺乏针对泛化性的验证。为克服这些挑战，我们提出了LiTEN，一个新颖的具有张量四边形注意力（TQA）求积约化机制的等变神经网络。LiTEN-FF是基于LiTEN的鲁棒基础模型，预训练于广泛的nablaDFT数据集以实现广泛的化学通用性，并针对SPICE模型进行微调，以实现精确的溶剂化系统模拟。LiTEN在rMD17、MD22和Chignolin的绝大多数评估子集上达到了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF能够实现迄今最全面的下游生物分子建模任务套件，包括量子级构象搜索、几何优化和自由能表面构造，同时为大生物分子（~1000个原子）提供10倍于MACE-OFF的速度优势。总之，我们提出了一个基于物理的概念、非常高效的大规模模型，推动了复杂的生物分子建模，并为药物发现等应用提供了多功能的基础。", "innovation": "提出了LiTEN，一种具有张量四边形注意力（TQA）的等变神经网络，能够在较低计算成本下高效地模拟三体和四体相互作用。LiTEN-FF是基于LiTEN的鲁棒基础模型，预训练于广泛的nablaDFT数据集以实现广泛的化学通用性，并针对SPICE模型进行微调，以实现精确的溶剂化系统模拟。LiTEN-FF能够实现了Qm级的构象搜索、几何优化和自由能表面构造，同时提供相对于MACE-OFF 10倍更快的推理速度，特别是在处理大生物分子时。", "conclusion": "我们提出了一种基于物理概念的高效框架，推动了复杂的生物分子建模，为药物发现等应用提供了多功能的基础。该框架能够在保持与量子力学相同级别的准确性的前提下，实现高效的生物分子模拟，极大地扩展了生物分子模拟的边界。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02825", "html_url": "https://arxiv.org/abs/2507.02825", "title": "建立严格的代理型基准的最佳实践", "title_en": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "authors": "Yuxuan Zhu,Tengjun Jin,Yada Pruksachatkun,Andy Zhang,Shu Liu,Sasha Cui,Sayash Kapoor,Shayne Longpre,Kevin Meng,Rebecca Weiss,Fazl Barez,Rahul Gupta,Jwala Dhamala,Jacob Merizian,Mario Giulianelli,Harry Coppock,Cozmin Ududec,Jasjeet Sekhon,Jacob Steinhardt,Antony Kellerman,Sarah Schwettmann,Matei Zaharia,Ion Stoica,Percy Liang,Daniel Kang", "background": "基准对于定量跟踪AI进展至关重要。随着AI代理越来越强大，研究人员和实践者引入了代理型基准，以评估代理在复杂的真实世界任务上的表现。这些基准通常通过具体的奖励设计来评估代理的能力并衡量任务结果。然而，研究发现许多代理型基准存在任务设置或奖励设计的问题。例如，SWE-bench Verified (已验证) 使用不足的测试用例，而TAU-bench (任务代理基准) 将空响应视为成功。这些问题可能导致代理性能的低估或高估，相对误差最高可达100%。", "innovation": "为了使代理型评估更具严谨性，研究引入了代理型基准检查清单 (ABC)，这是从研究人员的基准构建经验、最佳实践的调研以及先前报道的问题中综合出来的指导方针。当应用于具有特别复杂的评估设计的CVE-Bench时，ABC 将性能高估减少了 33%。", "conclusion": "研究提出了一个代理型基准工具 (ABC)，用于改进代理型基准的构建过程。ABC 的应用显著降低了性能高估，有效地提高了代理型基准的严谨性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02841", "html_url": "https://arxiv.org/abs/2507.02841", "title": "StepHint：多层次逐步提示增强强化学习推理", "title_en": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason", "authors": "Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan", "background": "强化学习与验证奖励（RLVR）是一种用于提高大型语言模型复杂推理能力的有前景的方法。然而，现有RLVR方法面临两个重大挑战：接近失误的奖励问题，即一个小错误会使整个正确的推理过程无效，极大地妨碍了训练效率；以及探索停滞问题，模型倾向于集中在它们的“舒适区”内的解决方案，缺少探索更有效替代方案的动力。", "innovation": "为了应对这些挑战，该论文提出了一种名为StepHint的新颖RLVR算法，利用多层次的逐步提示帮助模型更有效地探索解决方案空间。StepHint通过自更强模型生成有效的推理链，并使用自适应分区方法将这些链分割成推理步骤。最初的几步骤被用作提示，同时提供多个层次的提示（每个提示包含不同的步骤数量）。这种方法指导模型的探索向一个有希望的解决方案子空间，同时保留其独立探索的灵活性。通过提供提示，StepHint减轻了接近失误的奖励问题，从而提高了训练效率。同时，外部推理路径帮助模型发展更好的推理能力，使它能够超越“舒适区”并缓解探索停滞。StepHint在六个数学基准测试中表现出色，同时在域外基准测试中也展示出更好的泛化能力并超越了基线方法。", "conclusion": "StepHint在多个数学基准测试中表现出优越性能，同时通过增强模型的探索能力有效解决了近似错误的奖励问题和探索停滞问题，提高了模型的推理能力和训练效率，特别是在域外基准测试中的表现更为出色。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01975", "html_url": "https://arxiv.org/abs/2507.01975", "title": "Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows", "title_en": "Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows", "authors": "Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun", "background": "流体流动的数值模拟对于气象学、航空动力学和生物医学领域的物理现象建模至关重要。传统的数值求解器需要精细的时空网格以满足稳定性和收敛性条件，这导致了巨大的计算成本。虽然机器学习在效率方面有所改进，但它们通常在可解释性、泛化能力和数据依赖性方面存在问题。因此，我们提出了LDSolver——一种适用于粗时空网格高效准确模拟流体流动的可学习和可微分的有限体积求解器。", "innovation": "LDSolver由两个关键组件构成：（1）一个可微分的有限体积求解器；（2）一个可学习模块，为粗糙网格提供等效的流量（导数和插值）近似和时间误差修正。即使仅有少量训练数据（例如，仅少数轨迹），该模型也能加速模拟并保持高度准确性和出色的泛化能力。实验表明，LDSolver在不同流系统（例如Burgers湍流、衰减流、强迫流和剪切流）上实现了领先性能，明显优于基线模型。", "conclusion": "LDSolver通过在粗糙时空网格上实现高效且准确的流体流动模拟，解决了传统方法和机器学习方法的不足，展示了卓越的性能和泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01997", "html_url": "https://arxiv.org/abs/2507.01997", "title": "为网络故障排查的AI代理实验和基准测试民主化建立游乐场", "title_en": "Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting", "authors": "Zhihao Wang,Alessandro Cornacchia,Franco Galante,Carlo Centofanti,Alessio Sacco,Dingde Jiang", "background": "最近的研究表明，人工智能（AI）及其具体领域的大语言模型（LLMs）在支持网络配置综合和自动网络故障诊断方面非常有效。鉴于这一点，本文初步探讨了将AI代理应用于网络故障排查的需求，并强调需要一个标准化、可重复且开放的评估平台，以降低操作成本，进行AI代理的构建与评估。", "innovation": "提出了一个标准化、可重复且开放的评估平台，旨在降低操作成本，促进对于网络故障排查中AI代理的研究和评估。通过这种方式，使得更多的实验者能参与到AI代理的实验和比较中来，从而推动该领域的发展和进步。", "conclusion": "本文提议了一个平台，以改善AI代理在网络故障排查方面的实验和基准测试，促进这一领域的实验民主化，提升研究效率和结果的可重复性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01982", "html_url": "https://arxiv.org/abs/2507.01982", "title": "DKGCM：一种融合空间节点聚类方法和傅里叶双向Mamba机制的时空交通流预测模型", "title_en": "DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism", "authors": "Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai", "background": "准确的交通需求预测有助于交通管理部门更有效地分配资源，从而提高资源利用效率。然而，交通系统中的复杂时空关系限制了需求预测模型的性能。为了提高时空交通需求预测的准确性，我们提出了一种新的图卷积网络结构，即DKGCM模型。我们首先考虑了不同交通节点的空间流量分布，并提出了一种基于时间相似性的新型聚类图卷积方法DK-GCN。这种方法利用动态时间规整（DTW）和K-means聚类对交通节点进行分组，更有效地捕捉空间依赖性。在时间尺度上，我们结合了Mamba深度学习框架中的快速傅里叶变换（FFT）来捕捉交通需求的时间依赖性。", "innovation": "我们提出了一种新的图卷积网络结构，即DKGCM。具体包括：1) 采用基于时间相似性的新型聚类图卷积方法DK-GCN；2) 将快速傅里叶变换FFT融入到双向Mamba深度学习框架中捕捉时间依赖性；3) 引入GRPO强化学习策略优化模型训练中的损失函数反馈机制。这些创新有助于提高时空交通需求预测的准确性。", "conclusion": "通过大量实验，我们发现该模型在三个公开数据集上均取得了优于几种先进方法的优异结果。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01990", "html_url": "https://arxiv.org/abs/2507.01990", "title": "在金融投资和市场分析中集成大型语言模型：一项综合研究", "title_en": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "authors": "Sedigheh Mahdavi,Jiating(Kristin)Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh", "background": "传统投资策略通常依赖定量模型、根本分析和技术指标。然而，大型语言模型（LLMs）能够处理和分析大量结构化和非结构化数据，提取有意义的见解，并实现实时决策，从而在金融决策制定中提供了新的能力。本文综述了近年来LLMs在金融领域的研究，根据以下四个主要框架对研究成果进行了分类：基于LLMs的框架和管道、混合集成方法、微调和适应方法以及基于代理的架构。", "innovation": "本文提供了一项结构化的文献综述，涵盖了LLMs在股票选择、风险管理、情绪分析、交易和金融预测中的应用，并通过回顾现有文献，突显了LLMs的能力、挑战和未来方向。这为理解LLMs在金融市场的潜在应用提供了有价值的洞见和指导。", "conclusion": "本文通过结构化的综述，展示了近年来LLMs在金融投资和市场分析中的研究成果，指出了其在能力、挑战和未来方向上的优势和潜力，为未来的研究和应用提供了重要参考。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02018", "html_url": "https://arxiv.org/abs/2507.02018", "title": "NGAT: 基于节点级图注意力网络的长周期股票预测", "title_en": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction", "authors": "Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong", "background": "图表示学习方法在金融应用中被广泛采用，用于通过利用公司间关系提高公司表示。然而，当前的方法面临三个关键挑战：(1) 下游任务设计的限制掩盖了关系信息的优势；(2) 专为股票预测设计的现有图模型往往过于复杂且泛化能力差；(3) 依靠经验构建的企业关系图缺乏不同图结构的有效对比。", "innovation": "为解决这些限制，我们提出了一项长期股票预测任务，并开发了一种专为企业关系图设计的节点级图注意力网络（NGAT）。此外，我们通过下游任务性能实验展示了现有图比较方法的局限性。在两个数据集上的实验结果一致证明了我们所提出任务和模型的有效性。该项目已在GitHub上公开，以促进可复现性和未来研究。", "conclusion": "通过NGAT，该研究展示了一种创新的节点级图注意力网络方法及其在企业关系图上的应用，通过长期股票预测任务突显其有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02016", "html_url": "https://arxiv.org/abs/2507.02016", "title": "有效的 Belief-Desire-Intention 机器人解释：何时及提供什么", "title_en": "Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain", "authors": "Cong Wang,Roberto Calandra,Verena Klös", "background": "当机器人在我们的日常生活中执行复杂的、依赖于上下文的任务时，机器人操作上的偏差可能会使用户感到困惑。为了帮助用户理解机器人的意图，机器人需要提供自身的推理过程解释。然而，何时提供这些解释以及解释的内容对于避免用户感到烦躁非常关键。本文通过对机器人在厨房内协助日常清洁任务时用户对于解释的需求和内容偏好的调查，最终提出了两种算法来识别意外行为并为 Belief-Desire-Intention (BDI) 机器人构建有效的解释方案。", "innovation": "本文提出的两个算法能够识别意外行为并为 BDI 机器人构建有效的解释方案，而且这些算法可以很容易地集成到 BDI 理论的推理过程中，从而为更加具体的上下文以及用户提供了更好的人机交互方式", "conclusion": "研究表明，在令人惊讶的情况下用户希望得到解释，并且他们更偏好简单明了的解释，这些解释需要清晰地表述令人困惑的操作背后的意图以及影响这个决定的背景因素。基于这些发现，本文提出了两种算法，不仅能够识别这些意外的行为，还能够为 BDI 机器人构建有效解释，从而推动了其在人类-机器人交互中的更广泛应用。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02014", "html_url": "https://arxiv.org/abs/2507.02014", "title": "ManifoldMind：动态双曲推理以实现可信赖的推荐", "title_en": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations", "authors": "Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic", "background": "该研究介绍了ManifoldMind，这是一种在双曲空间中进行语义层次探索性推理的概率几何推荐系统。不同于以前固定曲率和刚性嵌入的方法，ManifoldMind将用户、项目和标签表示为自适应曲率的概率球体，从而允许个性化不确定性建模和几何感知的语义探索。这种理念揭示了背景下的上下文知识，并支持推荐系统提供软的、多跳的推理，有助于避免仅局限于浅显或直接的交互关系，而是在不同的概念路径之间进行探索。", "innovation": "ManifoldMind的创新之处在于其自适应曲率的概率球体表示法，这使得系统能够进行个性化不确定性的建模和几何感知的语义探索。研究中使用了一个基于曲率的语义内核，支持软的、多跳的推理，有助于模型探索多样性的概念路径，而不是仅仅局限于浅层次或直接的交互。实验表明，与强大的基线相比，ManifoldMind在四个公开基准上表现出更高的NDCG、校准和多样性。", "conclusion": "ManifoldMind通过产生明确的推理轨迹，能够在稀疏或抽象领域提供透明、可信赖且以探索驱动的推荐。研究通过实验证实，相比于其他强大的基准模型，ManifoldMind在推荐性能方面表现更优，特别是在校准和多样性上，为未来的推荐系统设计提供了新的视角和方法。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02074", "html_url": "https://arxiv.org/abs/2507.02074", "title": "大型语言模型在视频碰撞检测中的应用：方法、数据集和挑战综述", "title_en": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges", "authors": "Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma", "background": "在智能交通系统中，从视频流中检测碰撞是一个至关重要的问题。近年来，大型语言模型（LLMs）和视觉-语言模型（VLMs）的发展已经改变了我们处理、理解和汇总多模态信息的方式。本文综述了利用LLM方法从视频数据检测碰撞的最新方法，涵盖了融合策略的结构化分类、关键数据集的总结、模型架构的分析、性能基准的比较以及持续存在的挑战和机会。", "innovation": "本文提供了一种结构化的融合策略分类，并对关键数据集进行了总结，分析了模型架构，比较了性能基准，并讨论了当前的研究挑战和未来的机会，为这一快速发展的领域奠定了基础。", "conclusion": "本文的回顾为视频理解与基础模型的交叉领域未来的研究提供了基础，为这一快速发展的领域奠定了基础。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02005", "html_url": "https://arxiv.org/abs/2507.02005", "title": "基于特征工程和自动可解释机器学习的焊接横向加劲件疲劳强度模型发现", "title_en": "Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener", "authors": "Michael A. Kraus,Helen Bartsch", "background": "本文介绍了一种结合自动化机器学习（AutoML）和可解释人工智能（XAI）的统一方法，用于预测焊接横向加劲件的疲劳强度。该研究通过专家驱动的特征工程与算法特征生成相结合，增强了准确性和解释性。基于广泛的疲劳试验数据库，使用AutoML对梯度增强、随机森林和神经网络等回归模型进行了训练，以比较基于专家的选择与自动特征选择的系统性比较。此外，还探讨了应力比、应力范围、屈服强度等因素在疲劳寿命中的重要性，以及焊后处理（TIG磨削 vs 未焊后处理）对疲劳寿命的影响。", "innovation": "本文创新地提出了一种结合AutoML与XAI的方法，用于预测焊接横向加劲件的疲劳强度。该方法通过比较基于专家和自动特征选择的模型性能，展示了不同特征方案的优劣，并通过集成学习方法提高了模型的准确性和解释性。", "conclusion": "该框架表明，将AutoML与XAI结合，能够生成准确、可解释且稳健的疲劳强度模型，有效结合数据驱动建模与工程验证，从而支持AI辅助设计和评估。未来将探索概率疲劳寿命建模，并将其集成到数字双胞胎环境中。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02125", "html_url": "https://arxiv.org/abs/2507.02125", "title": "AI能否解决区块链预言机问题？解开挑战与可能性", "title_en": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities", "authors": "Giulio Caldarelli", "background": "区块链预言机问题指的是将可靠的外部数据注入去中心化系统的过程中的挑战，这仍然是构建无信任应用的主要限制因素。近年来虽然出现了各种架构、密码学和经济策略来缓解这一问题，但仍未有人能够完全解决区块链如何获取离链世界知识的基本问题。", "innovation": "本文从学术文献和实践实施的角度出发，考察了AI技术如异常检测、语言事实提取、动态声誉建模和对抗性抵抗如何增强预言机系统的效能。", "conclusion": "研究表明，尽管AI为数据质量、来源选择和系统韧性提供了强有力的工具，但它不能消除对不可验证离链输入的依赖。因此，研究支持AI应被视为一个在更广泛预言机设计中作为推断和过滤的补充层，而不是信任假设的替代品。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02057", "html_url": "https://arxiv.org/abs/2507.02057", "title": "MGC: 一个利用对齐LLMs组合盲点生成恶意软件的编译框架", "title_en": "MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation", "authors": "Lu Yan,Zhuo Zhang,Xiangzhe Xu,Shengwei An,Guangyu Shen,Zhou Xuan,Xuan Chen,Xiangyu Zhang", "background": "大型语言模型（LLMs）已经使软件开发民主化，降低了编写复杂应用程序的专业门槛。这种便捷性同样适用于恶意软件开发，引发了重大的安全担忧。尽管LLM供应商实施了对齐机制来防止直接生成明显的恶意代码，但这些安全措施主要对单个提示进行孤立评估，忽视了一个关键漏洞：恶意操作可以系统地分解为看似正常的子任务。这篇文章讨论了这种潜在风险，并提出了一种新的框架MGC来利用这一漏洞进行模块化分解和对齐规避生成。", "innovation": "文章引入了一个名为MGC（Malware Generation Compiler，恶意软件生成编译器）的创新框架，通过模块化分解和对齐规避生成来利用恶意操作可以分解为看似正常子任务的漏洞。MGC使用专门的恶意软件描述中间表示（MDIR）来连接高层的恶意意图和看似正常的代码片段。评估表明，与越狱方法相比，MGC在三个基准数据集上的正确性高出365.79%，与地下服务相比高出78.07%。实证研究进一步显示，MGC能够重现甚至增强了16个真实的恶意软件样本。这项工作对安全研究人员揭示了组合攻击的安全风险，这些攻击针对对齐的AI系统。", "conclusion": "这项工作为安全研究人员提供了关键的见解，揭示了对齐AI系统组合攻击的固有风险。MGC框架展示了对齐的LLMs如何通过模块化分解和对齐规避生成恶意软件的有效性，为未来的安全对策提供了参考。相关演示可在 [链接] 中找到。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02085", "html_url": "https://arxiv.org/abs/2507.02085", "title": "GeoAda: 使用equivariant适配器高效微调几何扩散模型", "title_en": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters", "authors": "Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon", "background": "几何扩散模型在分子动力学和结构生成中表现出显著的成功，但它们对于下游任务进行高效微调以适应不同几何控制的需求仍然较少被探索。在本文中，提出了一种SE(3)-不变量适配器框架（GeoAda），允许在不修改原始模型结构的情况下对控制生成任务进行灵活且参数高效的微调。GeoAda引入了一种结构化适配器设计：控制信号首先通过耦合操作编码，然后由选定预训练模型层的一个可训练副本进行处理，并最后通过解耦操作和SE(3)不变性初始化卷积进行投影。通过仅微调这些轻量级适配器模块，GeoAda在保持模型几何一致性的同时减轻了过拟合和灾难性遗忘的问题。", "innovation": "提出了一种SE(3)-不变量适配器框架（GeoAda），解决了几何扩散模型在下游任务中高效微调的问题。GeoAda采用了一种结构化适配器设计，确保微调过程中的几何不变性，同时保持了模型的参数效率。GeoAda适用于多种几何控制类型，包括框架控制、全局控制、子图控制，并在粒子动力学、分子动力学、人体运动预测和分子生成等领域具有广泛应用。", "conclusion": "实验结果表明，GeoAda在保持原始任务准确性的同时实现了最优的微调性能，而其他基准方法因过拟合和灾难性遗忘而表现显著下降。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "Energy-Based Transformers", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "推理时的计算技术类比于人类系统2思考方式，已经逐渐成为提高模型性能的一种流行方法，但现有方法存在特定模态、特定问题或需要额外监督/训练的局限性。本文探讨了是否能够将这些系统2思考的方法泛化，使得模型仅通过无监督学习就能学习思考。通过学习显式验证输入与候选预测之间的兼容性，再将预测问题重新定义为最小化此验证器的优化问题，研究发现这种方法是可行的，并训练了一种新的能量表征变换器模型（EBTs），使其能够对输入与候选预测进行能量值赋值，并通过梯度下降的能量最小化进行收敛，从而实现预测", "innovation": "本文提出了一种新的基于能量的方法——能量表征变换器（EBTs），它通过无监督学习来训练模型，解决传统的验证器或验证奖励监督的需求，通过能量值的最小化算法实现高效预测，相较于主流的Transformer++方法，EBTs在训练阶段表现出更快的规模性，特别是在数据、批次大小、参数、FLOPs和深度方面，同时在推理阶段也表现出增强的性能，特别是在语言任务中提高了29%，在图像降噪任务中表现出更少的前向传递次数。进一步研究发现，EBTs在许多下游任务上取得了比现有模型更好的结果，即使在相同的或更差的预训练性能下也是如此，说明EBTs具有更好的泛化能力。", "conclusion": "EBTs被证明是一种有前景的新模式，可以增强模型的学习和思考能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02106", "html_url": "https://arxiv.org/abs/2507.02106", "title": "解决湍流磁流体动力学问题：一种混合算子-扩散框架", "title_en": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework", "authors": "Semih Kacmaz,E. A. Huerta,Roland Haas", "background": "本文提出了一种将物理信息神经操作符（PINO）与评分生成扩散模型相结合的混合机器学习框架，用于模拟二维、不可压缩、有电阻的磁流体动力学（MHD）湍流在广泛的雷诺数（Re）范围内的全时空演化。该框架利用PINO的方程约束泛化能力预测一致、低频的动力学，而条件扩散模型则通过随机修正高频残差来确保湍流准确建模。该模型在Re值为{100, 250, 500, 750, 1000, 3000, 10000}的高保真模拟上进行了训练，实现了确定性代理模型难以达到的新精度水平。特别是在Re=1000和3000时，该模型能够忠实地重建流速和磁场的全频谱能量分布，捕捉非高斯统计特性、间歇结构和跨场相关性。在极端湍流水平（Re=10000）下，该模型首次能够恢复磁场在高波数演化的特征，保持大尺度形态并提供统计上显著的预测能力。", "innovation": "提出了一种结合物理信息神经操作符（PINO）与评分生成扩散模型的新混合框架，用于模拟MHD湍流的时空演化。该框架能够克服传统确定性代理模型在高Re数值下的挑战，提供前所未有的预测精度和统计意义。特别地，它能够在极高Re值下准确预测磁场的高频演化。", "conclusion": "该框架在各Re值下均表现出优异的性能，特别是在极高Re值下，它成功地捕捉了磁场的高频演化特征并保持大尺度形态，提供了统计上显著的预测能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02171", "html_url": "https://arxiv.org/abs/2507.02171", "title": "基于自监督RNN的生物启发式机器人轨迹规划", "title_en": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN", "authors": "Miroslav Cibula,Kristína Malinovská,Matthias Kerzel", "background": "机器人的轨迹规划通常是指生成一系列关节配置，以使机器人或其 manipulator 从初始状态过渡到期望的最终状态。传统方法通常使用基于采样的规划器，计算密集。最近的研究表明，轨迹规划也可以通过神经网络中的监督序列学习来实现，这通常只需要单次或固定次数的神经架构遍历，从而确保了计算时间的限定。然而，现有的完全监督方法仅进行模仿学习，基于所观察的轨迹进行再现，而不是根据这些轨迹能否成功到达目标进行学习。", "innovation": "提出了一种基于递归网络的启发式自监督学习方案，旨在通过给定的前向和逆向运动学模型，仅使用配对的运动学模型进行训练，来生成轨迹。这种方法能够实现生物启发式的自监督学习，有助于规划复杂且需要自适应解决方案的操控任务。", "conclusion": "研究结果表明，所提出的方法能够在给定的前向和逆向运动学模型的基础上学习生成轨迹，并暗示了该方法在更复杂的操控任务规划方面具有潜力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02139", "html_url": "https://arxiv.org/abs/2507.02139", "title": "当LLMs意见不一：SDG搜索中相关性过滤偏差和检索分歧诊断", "title_en": "When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search", "authors": "William A. Ingram,Bipasha Banerjee,Edward A. Fox", "background": "大规模语言模型（LLMs）越来越多地用于信息检索管道中的文档相关性标签分配，特别是在缺乏人类标注数据的领域。然而，不同模型在边界情况下往往存在分歧，这引起了人们对这种分歧如何影响下游检索效果的担忧。本研究针对可持续发展目标（SDGs）1、3和7相关的学术摘要集，考察了两个开源权重LLM——LLaMA和Qwen之间的标注分歧情况。作者通过分析分歧数据集的词频特征、排名行为和分类可预测性，发现分歧是系统性的，而非随机的。不同的模型在共享评分函数的情况下产生不同的前排输出，并且通过简单的分类器可以区分它们，AUC值超过0.74。这项研究得出结论，即使在受控提示和共享排名逻辑的情况下，LLM 基础过滤也引入了文档检索中的结构化差异。研究者主张在检索评估中将分类分歧作为分析对象，特别是在政策相关或主题搜索任务中。", "innovation": "研究首次针对大型语言模型（LLMs）在信息检索中的标签分配分歧进行了系统性分析，通过两种LLM在可持续发展目标搜索中的表现，揭示了它们在标注和检索时可能存在的系统性差异，而不是随机误差。此外，研究通过对简单分类模型的有效性测试表明，这些分歧可以系统地被识别，提出了使用分类分歧作为检索评估的新视角。此工作的创新之处在于它揭示了在控制条件下仍可能存在的结构化变异，并提出了一种新的评估方法。", "conclusion": "研究结果表明，LLM 基础过滤在信息检索中引入了结构性差异，即使在控制提示和共享排名逻辑的情况下。因此，使用分类分歧作为研究对象相当有效，特别是在评估与政策相关的或主题搜索相关的检索任务时。这些发现对于理解变异来源和改进检索评估具有重要意义。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02166", "html_url": "https://arxiv.org/abs/2507.02166", "title": "任何大小的大型半合成图生成", "title_en": "Generating Large Semi-Synthetic Graphs of Any Size", "authors": "Rodrigo Tuna,Carlos Soares", "background": "图生成是网络科学中的一个重要领域。传统的生成方法侧重于复制真实世界图的特定属性，例如小直径或幂律度分布。近年来，深度学习的进展，特别是图神经网络（GNN）的应用，使得数据驱动的方法能够学习和生成图，而无需依赖预定义的结构属性。尽管如此，现有的模型仍然受到依赖节点ID的限制，这限制了它们生成比输入图更大的图的能力，并且忽视了节点属性。这些限制构成了本文研究的背景，并提出了LGSG（Latent Graph Sampling Generation）作为一种新颖的方法以解决这些问题", "innovation": "LGSG框架是一种新颖的方法，它利用扩散模型和节点嵌入来生成不同大小的图，而无需重新训练。它消除了对节点ID的依赖，并捕捉节点嵌入和子图结构的分布，从而实现可扩展和灵活性高的图生成。此外，该框架展示了在不同大小的图中保持一致的结构特征，证明了其稳健性和可扩展性", "conclusion": "实验结果表明，LGSG在标准指标上与基准模型表现相当，而在被忽视的指标上（如节点聚类倾向）则超过了它们。此外，它在不同大小的图中保持了一致的结构特征，展示了其实用性和扩展性"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02199", "html_url": "https://arxiv.org/abs/2507.02199", "title": "潜在线性推理？深度递归变换器的解读", "title_en": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "authors": "Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu", "background": "链式思维（CoT）推理使基于变换器的语言模型在复杂数学和多步骤规划方面表现优异。然而，在标准的解码器架构中，这些推理步骤通常以自然语言形式表现，这提高了可解释性但降低了效率。为了捕捉不易用语言表达的推理过程，许多研究探索了递归架构，旨在将推理过程内部化到潜在空间，可能支持潜在的CoT。", "innovation": "本文研究了深度递归变换器Huginn-3.5B（一种在推理时重用层而不增加参数数量的深度递归变换器）中是否会出现这样的推理结构。通过采用一系列探针技术，包括Logit Lens和Coda Lens，对模型在算术任务上的内部行为进行了考察。研究发现了有限的证据表明潜在线性推理是可解释的，并且揭示了递归块之间显著的探针一致性问题，隐藏状态的可解释性取决于层索引和解码方法。本文还实验证明，增加递归深度只能带来微小的性能提升，远不及那些明确体现推理步骤的模型。", "conclusion": "进一步增加递归深度带来的收益微乎其微，并远不及那些明确显示推理步骤的模型。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02145", "html_url": "https://arxiv.org/abs/2507.02145", "title": "推理还是不推理？对话总结中推理型LLM的全面评估", "title_en": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization", "authors": "Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira", "background": "对话总结是一个在客户服务、会议分析和会话AI中有重要实际价值的挑战性任务。尽管大规模语言模型在总结任务上取得了显著进展，但对于需要同时抽象和简洁的对话场景中具体实施的长链推理（长CoT）架构（如OpenAI-o1和DeepSeek-R1）的性能尚未被探索。已有研究主要集中在通用、角色导向和查询导向的对话总结方法上，但没有系统性地将推理型和非推理型语言模型进行对比评估。本文研究旨在全面评价最先进的推理型和非推理型语言模型在三种主要对话总结范式中的表现。评估涵盖了多种语言、领域和总结长度，使用了强基准（SAMSum、DialogSum、CSDS和QMSum）以及包括自然语言生成模型自动评估和人类启发式评价的先进评估协议。以往研究表明，显式的推理方式在对话总结质量上不一定能提供持续的改进，而推理型语言模型有时会表现为冗长、事实不一致和不够简洁的摘要，这与非推理模型相比更为不利。在特定场景分析和详细的案例研究中，文章进一步探讨了在复杂对话上下文中有哪些情况和原因使得显式推理可能无助于或甚至阻碍总结效果。", "innovation": "首次对最先进的推理型和非推理型语言模型在对话总结中的表现进行全面、系统的评估，涵盖了三种主要的对话总结范式，并使用了较强的基准和更为先进的评价协议，包括自然语言生成模型自动评估和人类启发式评价。", "conclusion": "推理型语言模型并不总能提升对话总结质量，在复杂对话场景中，它们可能会导致冗长、事实不一致和不够简洁的摘要。因此，本文为当前推理型语言模型的局限性提供了新的见解，并强调了需要有针对性的建模和评估策略来应对外界情境中的对话总结任务。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02217", "html_url": "https://arxiv.org/abs/2507.02217", "title": "理解条件化合成数据时的权衡", "title_en": "Understanding Trade offs When Conditioning Synthetic Data", "authors": "Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma", "background": "在工业视觉系统中，仅从少量图像学习稳健的对象检测器是一个关键挑战，因为高质量的训练数据采集可能需要数月时间。合成数据已成为实现视觉检测和取放机器人数据高效性的关键解决方案。当前流程依赖于如Blender或Unreal等3D引擎，虽然这些引擎提供精细化控制，但渲染小型数据集仍需数周时间，且生成的图像往往与现实存在较大差异。扩散模型有望产生重大突破，因为它们可以在几分钟内生成高质量图像；但在此低数据量条件下实现精确控制仍然困难重重。虽然很多延伸器现在可以超越纯文本提示进行扩散，但不同条件方案对合成数据质量的影响尚未得到充分理解。本文研究了从四个标准物体检测基准中抽取的八个多样化视觉概念，并对比了两种条件策略：提示基于和布局基于。当条件提示范围狭窄时，提示条件产生更高的合成数据质量；随着多样性的增长，布局条件成为更好的选择。当布局提示匹配完整训练分布时，合成数据可以将平均精度提升34%，与仅使用真实数据相比，最多可提升177%。", "innovation": "该研究探讨了在合成数据中不同条件方案的效果，发现提示条件在提示范围狭窄时效果更佳，而当多样性和布局匹配完整训练分布时，布局条件更有效。这为合成数据质量提升提供了新的见解和选择。通过实验比较了两种条件策略的效果，并观测到显著的精度提升，特别是在低数据量情况下。", "conclusion": "本文研究了多种视觉概念的条件化合成数据，对比了提示和布局两种条件策略。基于所采集的数据，当条件提示范围狭窄时，提示条件更有效；而当多样性和布局符合实际训练分布时，布局条件更能提升合成数据的质量和检测精度。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02252", "html_url": "https://arxiv.org/abs/2507.02252", "title": "SurgVisAgent：用于多功能手术视觉增强的多模态代理模型", "title_en": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement", "authors": "Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen", "background": "精确的手术干预对患者安全至关重要，高级增强算法已发展用于辅助外科医生进行决策。尽管取得了显著进展，但这些算法通常只为特定场景下的单任务设计，限制了它们在复杂现实情况中的有效性。为了克服这一限制，我们提出了基于多模态大型语言模型（MLLMs）的端到端智能手术视觉代理SurgVisAgent，该系统可动态识别内窥镜图像中的失真类别和严重程度，执行诸如低光增强、过度曝光校正、运动模糊消除和烟雾去除等多种增强任务。", "innovation": "SurgVisAgent 利用多模态大型语言模型，设计了先验模型提供领域特定知识，并通过上下文少量学习和链式思考推理，提供定制化图像增强以满足各种失真类型和严重程度的需求。此外，我们构建了一个全面的基准模型模拟真实手术中的失真情况，并通过大量实验验证了SurgVisAgent超越了传统的单任务模型，显示出其作为统一的手术辅助解决方案的潜力。", "conclusion": "实验结果表明SurgVisAgent在多功能手术视觉增强方面优于传统单一任务模型，证明了其在手术辅助领域的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02271", "html_url": "https://arxiv.org/abs/2507.02271", "title": "借助自蒸馏突出部分可见的电影语言以实现视频到音频生成", "title_en": "Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation", "authors": "Feizhen Huang,Yu Wu,Yutian Lin,Bo Du", "background": "视频到音频（V2A）生成在电影和视频后期制作中取得了显著进步，并发挥了重要作用。然而，当前的方法忽视了电影语言，这是电影制作中艺术表达的关键组成部分。因此，在只有部分配音目标可见的情况下，其性能会下降。", "innovation": "本文提出了一种简单的自蒸馏方法，以扩展V2A模型到电影语言场景。通过模拟电影语言的变化，学生模型学会将训练对的视频特征与相同的视听对应关系对齐，使其能够有效地捕捉声音与部分视觉信息之间的关联。该方法不仅在所有评估指标下实现了对部分可见情况下的显著改进，还在大规模V2A数据集VGGSound上也提高了性能。", "conclusion": "本文提出的方法在部分可见情况下的V2A生成中取得了显著改进，并在大规模V2A数据集VGGSound上增强了性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02206", "html_url": "https://arxiv.org/abs/2507.02206", "title": "EIM-TRNG: 使用 ROWHammer 通过内存编码生成真正的随机数生成器混淆深度神经网络权重", "title_en": "EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer", "authors": "Ranyang Zhou,Abeer Matar A. Almalky,Gamana Aragonda,Sabbir Ahmed,Filip Roth Trønnes-Christensen,Adnan Siraj Rakin,Shaahin Angizi", "background": "真随机数生成器（TRNGs）在硬件安全、加密系统和数据保护中起着基础性作用。在深度神经网络（DNNs）中，保护模型参数，尤其是权重，对于确保AI系统的完整性、隐私性和知识产权至关重要。尽管软件基于的伪随机数生成器被广泛应用，但由于缺乏硬件基于TRNGs提供的不可预测性和恢复力，因此不够理想。本文中，我们首次提出了一种名为EIM-TRNG的新型稳健的内存编码TRNG，利用DRAM单元行为中的固有物理随机性，特别是受到ROWHammer诱导的干扰，来增强安全性。通过精确控制的ROWHammer操作生成的不可预测的位翻转被用作可靠的熵源。我们进一步将TRNG框架应用于通过固定和不可预测的位翻转组合进行权重数据的加密，之后利用概率翻转行为的密钥进行解密，确保数据的机密性和模型的可信性。实验结果验证了基于DRAM的熵提取对于保障硬件安全的有效性和低成本性，并为在硬件层面保护机器学习模型提供了一个有前景的方向。", "innovation": "本文提出的EIM-TRNG是一种新颖且稳健的内存编码TRNG，首次利用DRAM单元行为中的物理随机性，通过ROWHammer操作生成不可预测的位翻转，用作熵源。进而将这种TRNG框架应用于通过固定和不可预测的位翻转组合进行DNN权重数据的加密，并通过概率翻转行为的密钥进行解密，保证数据的机密性和模型的可信性。", "conclusion": "本文验证了基于DRAM的熵提取对于保障硬件安全的有效性和低成本性，并为在硬件层面保护机器学习模型提供了一个有前景的方向。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02244", "html_url": "https://arxiv.org/abs/2507.02244", "title": "竞争压力下的订单获取：一种快速适应的强化学习方法优化 ridesharing 补贴策略", "title_en": "Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies", "authors": "Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu", "background": "网约车聚合平台的兴起为网约车服务提供商带来了显著的增长机会，通过增加订单量和商品总值（GMV）。在大多数网约车聚合平台上，提供更低票价的服务商在列表中被排名更高，因此更有可能被乘客选择。这种竞争排名机制为服务提供商提供了一个激励，使其通过降低价格来争取更多订单，因为订单量直接关系到其长期的生存能力和可持续性。因此，设计一个既能动态适应市场波动又能优化订单获取并符合预算约束的有效补贴策略是一个关键的研究挑战。然而，这一领域的现有研究仍然相对匮乏。", "innovation": "我们提出了一个名为FCA-RL的新颖强化学习为基础的补贴策略框架，旨在快速适应竞争对手的价格调整。我们的方法整合了两个关键技术：快速竞争适应（FCA），能够迅速应对动态价格变化，以及强化拉格朗日调整（RLA），确保在新价格情景下遵守预算约束并优化补贴决策。此外，我们还引入了RideGym，这是第一个专门为网约车聚合平台设计的专用仿真环境，有助于全面评估和基准不同定价策略，而不影响实际运营效率。实验结果表明，我们提出的方法在各种市场条件下都优于基准方法，突显了其在网约车服务提供商补贴优化中的有效性。", "conclusion": "我们的实验结果证明，FCA-RL策略在各种市场条件下都优于现有基线方法，强调了其在网约车服务提供商补贴优化中的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02265", "html_url": "https://arxiv.org/abs/2507.02265", "title": "基于RescueNet数据集的飓风损坏多标签分类框架", "title_en": "Multi-Label Classification Framework for Hurricane Damage Assessment", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "飓风造成的广泛破坏导致不同类型和程度的损害，需要及时和准确的评估以进行有效的灾害响应。传统的单一标签分类方法无法捕捉到飓风后的复杂性损害，因此需要一种新的方法来准确评估这些损害。本文引入了一种基于矿区图像的多标签分类框架，利用ResNet特征提取模块和类特定的注意力机制来识别单张图像中的多种损害类型，从而解决传统方法的不足，实现更有针对性和高效的灾害响应，为未来灾害减轻和韧性策略作出贡献。", "innovation": "引入了一种多标签分类框架，结合ResNet特征提取模块和类特定的注意力机制，可以识别单张图像中的多种损害类型，实现了比现有基线方法更好的准确性。", "conclusion": "本文所提出的方法在Rescuenet数据集上获得了90.23%的平均精确度，超过了现有的基线方法，提升了飓风后的损害评估，促进了更精准和高效的灾害响应，并为未来灾害减轻和韧性策略贡献了新的视角。该研究已被接受发表在美国土木工程师学会国际计算在土木工程会议 (i3CE 2025) 上，并将在正式的会议论文集中发表。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02259", "html_url": "https://arxiv.org/abs/2507.02259", "title": "MemAgent: 使用基于多会话 RL 的记忆代理重塑长上下文大模型", "title_en": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": "Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou", "background": "尽管在长度外推、高效的注意力和记忆模块方面取得了一定的改进，但在长文本处理中，如何以线性复杂度处理无限长文档而不会在外推过程中出现性能下降仍然是一个终极挑战。现有的方法主要是直接优化针对长文本任务的端到端方法，但尚未有成熟的解决方案来实现这一点。因此，研究人员提出了MemAgent，一种新颖的代理工作流，通过分段读取文本并使用覆盖策略更新记忆来解决这个问题。", "innovation": "提出的MemAgent方法直接针对长文本任务进行优化，它采用了一种全新的代理工作流，并引入了分段阅读和记忆更新策略。此外，还扩展了DAPO算法以通过独立上下文多对话生成来促进训练。特别是，MemAgent能够从8K上下文外推到3.5M QA任务，性能损失低于5%，并在512K RULER测试中达到95%以上的准确率。这表明MemAgent具有出色的长上下文处理能力。", "conclusion": "MemAgent通过引入新的代理工作流和算法扩展，在长文本处理方面取得了显著的进展，成功解决了长文本和无限长文档的高效处理问题，并在多个测试任务中展示了优异的性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02282", "html_url": "https://arxiv.org/abs/2507.02282", "title": "音乐推荐中的内容过滤方法：回顾", "title_en": "Content filtering methods for music recommendation: A review", "authors": "Terence Zeng,Abhishek K. Umrawal", "background": "在现代音乐流媒体平台中，推荐系统已成为用户发现和互动的基本工具。然而，传统的基于协同过滤的方法在稀疏交互媒体（如音乐）中效果不佳，因为大多数用户不会收听平台上提供的大部分歌曲。因此，需要通过内容过滤等其他方法来应对这些挑战。内容过滤通过分析歌曲的特征，可以减少协同过滤方法中存在的偏差。本研究回顾了当前在音乐推荐内容过滤方面的研究情况，重点关注了使用大型语言模型（LLMs）处理歌词分析和音频信号处理技术等方法不同类别歌曲分类的应用。", "innovation": "本研究创新地结合了大型语言模型进行歌词分析和音频信号处理技术，用以改进音乐推荐中的内容过滤方法，并探讨了不同分析方法之间的冲突和可能的解决方案。", "conclusion": "研究指出，尽管存在不同分析方法之间的冲突，但通过综合利用大型语言模型处理歌词分析和音频信号处理技术，可以有效应对音乐推荐系统中的挑战。这为未来研究提供了新的方向和视角。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02306", "html_url": "https://arxiv.org/abs/2507.02306", "title": "合成启发式评估：人工智能与人力支持的可用性评估比较", "title_en": "Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation", "authors": "Ruican Zhong,David W. McDonald,Gary Hsieh", "background": "在以人类为中心的设计中，可用性评估至关重要，但其成本高昂，需要专家时间和用户的补偿。当前的研究试图利用多模态大语言模型（LLM）的能力进行图像分析并提供设计反馈，以开发一种合成启发式评估方法，降低成本并提高效率。", "innovation": "研究人员开发了一种方法，利用多模态大语言模型的能力进行合成启发式评估。该方法在两个应用程序上的测试结果表明，合成评估能够发现高达73%和77%的可用性问题，超过了5名经验丰富的用户体验（UX）从业者所进行的实际评估的性能，显示出在检测布局问题方面的优势。同时，这项研究揭示了合成评估和人类评估之间的性能差异，有助于指导合成启发式评估的设计。", "conclusion": "该研究通过对比人工智能和人类进行的可用性评估，揭示了合成启发式评估的性能差异，并表明合成评估在某些方面具有优势，如检测布局问题，但同时也存在局限性，比如在识别某些UI组件和设计 convention 方面表现较差。总体而言，这项工作为未来的合成启发式评估设计提供了有益的参考。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02291", "html_url": "https://arxiv.org/abs/2507.02291", "title": "基于知识图谱的可解释与泛化的零样本语义通信", "title_en": "Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications", "authors": "Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu", "background": "现有的数据驱动语义通信依赖于表面的统计模式，缺乏解释性和泛化能力，尤其是在未见数据存在的应用场景中更为明显。这些不足限制了语义通信在网络应用中的广泛适用性和性能提升.", "innovation": "本文提出了一个结合知识图谱增强的零样本语义通信（KGZS-SC）网络。该网络通过知识图谱中的结构化语义信息提供了一种泛化的语义表示方法，并支持对未见过的案例进行推理。具体而言，KGZS-SC网络通过使Semantic Knowledge Base（KG-SKB）中的语义特征对齐，改善了发送端的泛化能力，从而通过选择性传输紧凑的视觉语义减少通信开销。在接收端，采用零样本学习方法使未见过的案例可以直接分类，无需重新训练或增加额外的计算开销，提高了分类过程的适应性和效率，特别是在动态或资源受限环境中.", "conclusion": "实验结果表明，提出的KGZS-SC网络在各种信噪比条件下展示了良好的泛化能力和比现有框架更优越的分类性能，特别是在各类未见过的类别的识别上."}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02331", "html_url": "https://arxiv.org/abs/2507.02331", "title": "探索模块化CMA-ES配置在问题景观上的相互作用", "title_en": "Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes", "authors": "Ana Nikolikj,Mario Andrés Muñoz,Eva Tuba,Tome Eftimov", "background": "本文利用最近引入的算法足迹概念，研究算法配置与问题特性之间的相互作用。通过对CMA-ES算法的六种模块化变体（modCMA）在BBOB套件上的24个基准问题进行评估，研究2维设置（5维和30维）下的性能足迹。这些足迹揭示了相同算法的不同配置为何表现出不同的性能，并识别了影响这些结果的问题特征。分析结果发现由于共同的问题属性相互作用存在相似的行为模式，并且在相同问题上由于不同的问题特征表现出不同的行为。此研究展示了算法足迹在增强可解释性及指导配置选择方面的有效性。", "innovation": "研究利用算法足迹的概念探讨了算法配置与问题特征之间的交互。具体运用六种模块化CMA-ES变体进行了多维度（5维和30维）的基准测试，提供了关于不同算法配置表现差异的洞见，同时识别了影响这些结果的问题特定特征。解析了共享行为模式和特定问题特征下的差异性行为。此研究通过算法足迹展示了增强可解释性和指导配置选择的有效性。", "conclusion": "研究结果表明算法足迹在理解算法配置效果及指导算法配置选择方面具有显著效果。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02310", "html_url": "https://arxiv.org/abs/2507.02310", "title": "概念漂移下具有自适应记忆校准的综合性连续学习", "title_en": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment", "authors": "Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk", "background": "传统的连续学习方法主要关注知识保留，侧重于缓解灾难性遗忘，隐含地假设之前学习的任务数据分布保持不变。这种假设忽略了真实世界数据流的动态特性，即概念漂移会永久性地改变之前见过的数据，要求模型在保证稳定性的前提下实现快速适应。", "innovation": "本文引入了一种综合框架，用于在概念漂移下进行连续学习，通过演化任务分布来模拟现实场景。同时，提出了自适应记忆校准（AMR），这是一种轻量级的方法，它将忆诵式的连续学习与概念漂移意识下的自适应机制相结合。AMR选择性地从回放缓冲区中移除过时的漂移类样本，并用少量最新的实例填充，从而有效校准记忆与新分布之间的关系。这种有针对性的采样方法在性能上与全重新学习（FR）相似，但大幅度减少了对标签数据和计算的需求。", "conclusion": "这些实验展示了AMR在几个标准视觉基准数据集上的性能，证明了其能够在概念漂移下持续表现优异，并保持高准确率，同时具有较低的计算开销。这种分析证明了AMR作为一种可扩展的解决方案在非平稳连续学习环境中的优势，能够同时保证稳定性和适变性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02322", "html_url": "https://arxiv.org/abs/2507.02322", "title": "基于人工神经网络的水稻叶部病害识别与分类研究：基于特征模型与直接成像模型的比较分析", "title_en": "Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model", "authors": "Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi", "background": "水稻叶部病害严重降低产量并造成经济损失，突显了早期检测的重要性，以实现有效管理并提高产量。该研究介绍了基于人工神经网络（ANN）的图像处理技术，用于及时识别和分类水稻病害。尽管目前普遍输入完整的叶片图像到ANN中，尚未对特征分析检测模型（FADM）和直接图像中心检测模型（DICDM）进行全面对比分析，特别是在评估特征提取算法（FEA）的有效性方面。因此，本研究在进行了特征分析检测模型实验的同时，利用了多种图像特征提取算法、降维算法和特征选择算法，并采用极端学习机（ELM）进行实验。实验使用了包含细菌性褐斑病、褐斑病、稻瘟病、稻白叶枯病、稻丛矮病和健康叶片的数据集，并采用了10折交叉验证方法。", "innovation": "该研究首次对基于特征模型（FADM）和直接成像模型（DICDM）的水稻叶片病害识别与分类方法进行了对比分析。通过应用多种特征提取算法、降维算法和特征选择算法，以及极端学习机（ELM），具体评估了不同方法的效果。采用10折交叉验证方法在多种水稻叶片病害数据集上进行实验。研究表明，基于特征分析检测模型的方法在分类性能上表现出更高的效果。", "conclusion": "研究发现，采用提出的特征分析检测模型进行水稻叶片病害检测具有提高作物健康水平、减少产量损失、提高水稻种植整体生产力和可持续性的巨大潜力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02314", "html_url": "https://arxiv.org/abs/2507.02314", "title": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation", "title_en": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation", "authors": "JaeHyuck Choi,MinJun Kim,JeHyeong Hong", "background": "在工业质量控制环境中，异常数据稀缺是一个现实问题。理想中的异常生成器应当同时满足以下三个需求：保持正常的背景完整、精确填补异常区域以与相应的异常掩膜紧密重合、在语义上合理的位置生成异常区域，同时从少量真实样例中生成现实且多样的外观。现有的基于扩散的方法通常最多只能满足其中两项要求：全局异常生成器会破坏背景，而掩膜导向的生成器在掩膜不精确或位置不当的情况下表现不佳。", "innovation": "本文提出了一种名为MAGIC的方法，它通过以下创新解决了所有上述问题：首先，MAGIC对一个稳定扩散的填补模型进行微调，保持正常区域完整，确保合成的异常严格遵循提供的掩膜，直接解决了背景破坏和对齐问题。其次，MAGIC添加了两种补充扰动策略：在微调和推理过程中应用高斯提示级扰动，拓宽异常的全局外观，避免低质量的文本外观；以及掩膜导向的空间噪声注入，丰富局部纹理变化。此外，上下文感知的掩膜对齐模块形成了语义对应关系，并重新定位掩膜，使每个异常保持合乎情理地包含在宿主物体中，消除超出边界的人工制品。通过一致的评估协议，MAGIC在MVTec-AD数据集上的下游异常任务中超越了之前的最佳方法。", "conclusion": "MAGIC方法在三个关键方面改善了现有的异常生成方法：保持正常背景完整、精确填补异常区域以及生成语义合理且现实多样的异常区域。通过有效地解决背景破坏和对齐问题，MAGIC极大地提高了在MVTec-AD数据集上的下游异常检测性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02337", "html_url": "https://arxiv.org/abs/2507.02337", "title": "ClustOpt: 基于聚类的方法表示和可视化数值元启发式优化算法的搜索动态", "title_en": "ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms", "authors": "Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov", "background": "理解数值元启发式优化算法的行为对于算法的开发和应用至关重要，但传统的可视化技术，如收敛图、轨迹映射和适应度景观分析，在高维或复杂的解空间中往往难以充分展示搜索过程的结构性动态。因此，需要提出一种新的表示和可视化方法来解决这个问题，这种方法能够聚类算法探索的解决方案，并跟踪聚类成员随迭代变化的演变情况，从而提供动态且可解释的搜索过程视图。进一步地，引入了衡量算法稳定性和算法相似性的两个度量标准，以量化单个算法运行时搜索轨迹的一致性以及不同算法之间的相似性。将该方法应用于十种数值元启发式优化算法，揭示了它们的稳定性和行为差异，加深了对其搜索动态的理解。", "innovation": "提出了一种基于聚类的表示和可视化方法‘ClustOpt’，该方法聚类算法探索的解决方案，并跟踪聚类成员随迭代变化的情况，及引入了衡量算法稳定性和算法相似性的两个度量标准。这种方法能够更好地展示高维度或复杂解空间中的搜索动态，提供直观且可解释的动态视图。将‘ClustOpt’方法应用于多种数值元启发式优化算法，揭示了它们的稳定性和行为差异，为算法的理解及优化提供了新的视角。", "conclusion": "该研究通过提出一种新的基于聚类的方法，揭示了数值元启发式优化算法的稳定性和行为差异，并提供了对其搜索动态的深刻理解。提出的算法稳定性和相似性度量能更好地量化搜索轨迹的一致性和不同算法的相似性，为算法的设计和应用提供了新的见解。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02342", "html_url": "https://arxiv.org/abs/2507.02342", "title": "DeltaSHAP: 通过Shapley值解释在线患者监控中的预测演化", "title_en": "DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values", "authors": "Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang", "background": "在临床环境中，及时发现驱动患者风险演变的原因对于及时干预至关重要。然而，现有的可解释人工智能（XAI）方法无法满足临床时间序列解释任务的独特需求。这些方法主要关注单个预测分数的解释，而不是变化过程，且忽视了特征联合效应，导致对实际观察到的特征组合变化的解释效率低下，不符合时间敏感的临床应用场景的需求。", "innovation": "DeltaSHAP算法通过以下创新解决了上述问题：首先，它解释连续预测的变化而非孤立的预测分数；其次，同时提供特征贡献的大小和方向；第三，实现实时解释。通过适应Shapley值到时间序列数据，DeltaSHAP准确捕捉特征联合效应，并仅使用实际观测到的特征组合来分配预测变化，这使得该方法对时间敏感的临床应用既高效又实用。此外，该研究还引入了新的评价指标来评估在线时间序列解释的准确性，并通过在线患者监控任务的实验验证了DeltaSHAP在解释质量和计算效率上优于最先进的XAI方法。", "conclusion": "实验结果表明，DeltaSHAP在MIMIC-III去补偿基准测试中，与最先进的XAI方法相比，解释质量提高了62%，计算效率提高了33%的时间。这证明了DeltaSHAP的有效性和实用性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02349", "html_url": "https://arxiv.org/abs/2507.02349", "title": "两步神经网络方法在自动脑血管关键点检测中的应用", "title_en": "Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection", "authors": "Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau", "background": "颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定段落，主要集中在十三大动脉分叉处。准确识别这些关键点对于及时准确诊断至关重要。传统方法采用半自动或手动手段实现识别，这在处理完整的MRA TOF时效率低下且容易出错。因此，研究开发了一种完全自动化的脑血管分叉关键点检测方法，该方法使用两步神经网络过程，提高了准确性和效率，适用于多变的血管解剖结构和不同数量的关键点检测情况。", "innovation": "提出了一种两步神经网络流程的自动化脑血管关键点检测方法。首先，使用目标检测网络识别关键点附近的感兴趣区域（ROIs）。其次，采用具有深度监督的修改U-Net网络来准确定位分叉点。该方法能有效应对两个关键点位置相近且视觉特征相似导致的检测遗漏问题，特别是处理完整的MRA TOF图像时。此外，该方法能考虑到Willis环的解剖变异，有助于提高不同数据集中的检测性能。", "conclusion": "通过实验，该方法在检测脑血管分叉点任务中表现最佳。使用内部数据集和公共数据集测试了该方法的有效性，展示了其在自动脑血管关键点检测中的高效性和准确性。这种两步法和使用的神经网络结构表明，该方法具有广泛的应用前景。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02345", "html_url": "https://arxiv.org/abs/2507.02345", "title": "HelixDesign-Antibody：基于HelixFold3的可扩展生产级抗体设计平台", "title_en": "HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3", "authors": "Jie Gao,Jing Hu,Shanzhuo Zhang,Kunrui Zhu,Sheng Qian,Yueyang Huang,Xiaonan Zhang,Xiaomin Fang", "background": "抗体工程对于开发治疗性药物和推进生物医学研究至关重要。传统发现方法通常依赖于耗时且资源密集的实验筛选。为了增强并简化这一过程，我们引入了一种基于HelixFold3的生产级、高通量平台，HelixDesign-Antibody，该平台利用了高精度结构预测模型HelixFold3。该平台有助于大规模生成抗体候选序列，并评估它们与抗原的相互作用。集成高性能计算（HPC）支持使得高通量筛选成为可能，解决了工具链碎片化和高计算需求等挑战。", "innovation": "该平台采用基于HelixFold3的高精度结构预测模型，构建了一种生产级、高通量的抗体设计平台，解决了传统实验筛选方法耗时、资源密集的问题。通过整合高性能计算支持，平台能够有效应对碎片化的工具链和高计算需求，实现了大规模抗体候选序列的生成与评估，从而显著提高了抗体设计的效率和质量。", "conclusion": "HelixDesign-Antibody平台提供了一种无缝、易于访问的解决方案，可用于大规模抗体设计，并已通过PaddleHelix平台的抗体设计页面开放给用户使用。该平台在多个抗原上的验证证明了其生成多样且高质量抗体的能力，并确认了探索更大序列空间会增加识别最佳结合分子的可能性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02356", "html_url": "https://arxiv.org/abs/2507.02356", "title": "带有惩罚动作噪声注入的离线强化学习", "title_en": "Offline Reinforcement Learning with Penalized Action Noise Injection", "authors": "JunHyeok Oh,Byung-Jun Lee", "background": "离线强化学习（RL）利用固定的已有数据集来优化策略，特别适用于与环境交互成本高昂的场景。其主要挑战在于如何提高算法的泛化能力。目前，虽然使用扩散模型已经取得了一些成功，然而，扩散模型的计算复杂性很高，且其在离线RL中的必要性仍有待商榷。这导致研究者探索更简单的解决方案来提升离线RL算法的表现。基于此，本文提出了一种方法，即惩罚动作噪声注入（PANI），以通过在策略中注入噪声动作来覆盖整个动作空间，同时根据注入噪声的量进行惩罚。这种方法受到了扩散模型在离线RL中应用的启发。", "innovation": "本文提出了PANI，一种简单但有效的离线学习增强方法。通过利用噪声注入的动作，PANI不仅能够覆盖整个动作空间，还能根据噪声量进行惩罚，从而改善离线学习。这种基于扩散模型原理的方法为广泛的离线RL算法提供了一个理论上坚实的支撑，并展示了在多种基准测试中实现显著性能提升的能力。", "conclusion": "PANI 方法通过对噪声注入动作进行惩罚，简单有效地增强了离线学习。这种方法不仅具有高度的普适性，还显著提升了多种离线RL算法的表现。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02376", "html_url": "https://arxiv.org/abs/2507.02376", "title": "VeFIA：一种高效的垂直联邦协作软件推理审核框架", "title_en": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software", "authors": "Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang", "background": "垂直联邦学习（VFL）是一种分布式AI软件部署机制，用于跨部门合作而不访问参与者的数据。然而，现有的垂直联邦学习工作中缺乏一种机制来审计数据方推理软件执行的正确性。VeFIA框架旨在解决这一问题，帮助任务方在大规模推理过程中审核数据方推理软件的执行是否按预期进行，同时不泄露数据方的数据隐私或引入额外的推理系统延迟。", "innovation": "VeFIA框架的核心在于，任务方可以通过使用可信执行环境（TEE）框架和协调器从数据方获取的推理结果来验证数据方计算结果的正确性。VeFIA确保了只要异常推理超过5.4%，任务方就能以99.99%的概率检测推理软件的执行异常，且不会增加任何额外的在线推理延迟。VeFIA的随机抽样验证在检测异常推理时实现了100%的阳性预测值、阴性预测值和真阳性率。据我们所知，这是第一篇讨论垂直联邦学习中推理软件执行正确性的论文。", "conclusion": "VeFIA框架能够有效审计垂直联邦学习中推理软件的执行正确性，确保数据隐私不被泄露，并且不会影响推理系统的性能。该框架在保证高准确率的同时，有效解决了当前垂直联邦学习工作中存在的执行正确性审计问题。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02398", "html_url": "https://arxiv.org/abs/2507.02398", "title": "基于像素级时域频率的超越空间频率的深假视频检测", "title_en": "Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection", "authors": "Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi", "background": "传统基于空间频率的检测方法在视频帧间堆叠空间频率谱以表示时间信息，这种方法往往忽视了时域中的不一致性和潜在的伪影。这导致在像素层面难以检测到时间上的错误。因此，该研究提出了一种利用像素级时域不一致性的深假视频检测方法，旨在解决传统方法的不足，提高检测性能。", "innovation": "该研究引入了一种基于像素级时域频率的检测方法，对每个像素进行一维傅里叶变换，提取对时域不一致性敏感的特征，尤其是在容易出现不自然运动的区域。此外，研究还提出了一种端到端训练的注意力提议模块，用于精准定位包含时域伪影的区域。同时，联合变换模块有效地将像素级时域频率特征与时空上下文特征相结合，增强了检测伪造伪影的范围。这种方法在多种复杂检测场景中提供了显著的性能提升。", "conclusion": "该框架在深假视频检测方面代表了一个重要进展，提供了跨不同且具有挑战性的检测场景的鲁棒性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02358", "html_url": "https://arxiv.org/abs/2507.02358", "title": "Holistic Tokenizer for Autoregressive Image Generation", "title_en": "Holistic Tokenizer for Autoregressive Image Generation", "authors": "Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi", "background": "现有的自回归图像生成模型通过逐步生成视觉令牌，限制了捕捉令牌序列之间整体关系的能力。大多数视觉分词器将局部图像片段映射到潜在令牌，导致全球信息有限。", "innovation": "引入了Hita，一种新颖的用于自回归图像生成的图像分词器。Hita引入了一种整体到局部的分词方案，包括可学习的整体查询和局部片段令牌。此外，Hita结合了两种关键策略以增强与自回归生成过程的对齐：1) 使用因果注意力，Hita按顺序结构排列整体令牌在开头，随后是片段级令牌；2) 在将去量化令牌送入解码器之前，Hita采用了一种轻量级融合模块控制信息流，优先考虑整体令牌。", "conclusion": "广泛的实验表明，Hita加速了自回归生成器的训练速度，并在ImageNet基准测试中优于使用传统分词器训练的模型，取得了2.59 FID和281.9 IS的成绩。整体表示分析揭示了Hita捕捉全局图像属性如纹理、材料和形状的能力，并且Hita也展示了在零样本风格迁移和图像修复方面的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02390", "html_url": "https://arxiv.org/abs/2507.02390", "title": "评估语言模型在物联网安全日志威胁检测中的应用", "title_en": "Evaluating Language Models For Threat Detection in IoT Security Logs", "authors": "Jorge J. Tejero-Fernández,Alfonso Sánchez-Macián", "background": "日志分析在网络安全领域是一个重要的研究领域，因为它们可以作为检测网络和系统威胁的信息来源。本文提出了一种使用微调大型语言模型（LLMs）进行异常检测和缓解建议的管道，这对于网络安全尤其重要，特别是在物联网（IoT）领域。为了验证大型语言模型的性能，使用经典机器学习分类器作为基线，对三种开源LLM进行了比较，这三种模型被用于二元和多元异常检测，并采用了三种策略：零样本提示、少样本提示和使用IoT数据集的微调。实验结果表明，在多元攻击分类中，LLMs的表现优于相应的基线模型。并且通过将检测到的威胁映射到MITRE CAPEC，定义了针对物联网的具体缓解措施，并与这些措施一起微调模型，模型能够提供检测和推荐指导相结合的支持。", "innovation": "1. 提出了一种使用大型语言模型进行物联网安全日志的异常检测和缓解建议的方法。\n2. 通过使用IoT数据集对大型语言模型进行微调，展示了在多元攻击分类中的优越性能。\n3. 将检测到的威胁映射到MITRE CAPEC，并定义了具体的物联网缓解措施，从而提供了一种结合检测与建议的解决方案。", "conclusion": "本文通过使用三种不同的策略对三种开源大型语言模型进行微调，并将检测结果与MITRE CAPEC映射结合物联网特定的缓解措施，展示了一种有效的威胁检测和缓解建议方法，实验证明这种方法在多元攻击分类中优于传统的机器学习方法，并能提供更具体的推荐措施。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02409", "html_url": "https://arxiv.org/abs/2507.02409", "title": "S2FGL: 空间频域联合图学习", "title_en": "S2FGL: Spatial Spectral Federated Graph Learning", "authors": "Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye", "background": "Federated Graph Learning (FGL) 结合了联邦学习(FL)的隐私保护能力以及图神经网络(GNN)的强图建模能力。当前的研究主要从结构角度处理子图联邦学习(subgraph-FL)，但忽略了信号在空间域和频域上的传播。从空间角度看，子图联邦学习引入了客户端之间的边断开，导致标签信号的中断和全局GNN分类知识的下降。从频域角度看，频谱异质性使得子图中的信号频率不一致，导致局部GNN过度拟合局部信号传播方案。结果，频域客户端漂移发生，削弱了全局泛化能力。", "innovation": "我们提出了一个全局知识库来缓解标签信号中断问题，并提出了一种频率校正方法以解决频谱客户端漂移。S2FGL框架结合了空间和频谱策略。广泛的实验证实在多个数据集上证明了S2FGL的优越性。代码已发布在 this https URL 。", "conclusion": "S2FGL框架有效地解决了子图联邦学习中遇到的挑战，通过全局知识库和频率校正策略，改善了标签信号的传播和频谱漂移，提高了全局GNN模型的泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02403", "html_url": "https://arxiv.org/abs/2507.02403", "title": "在非都市环境中使用自监督学习进行野生动物目标再识别", "title_en": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings", "authors": "Mufhumudzi Muthivhi,Terence L. van Zyl", "background": "野生动物再识别的目标是在不同的观测中匹配同一物种的个体。当前最先进的模型依赖分类标签来训练监督模型进行个体分类。这种依赖标注数据的方法导致了大量的大型野生动物数据集的创建。本研究探索了在相机陷阱数据中使用自监督学习（SSL）来进行野生动物再识别，通过自动从时间上相邻的图像对中提取个体的两个不同视图，对潜在无限的视频数据流进行无监督训练，评估在开放世界场景和各种野生动物下游任务中的表现，结果显示自监督模型即使在少量数据的情况下也更稳健，自监督特征也优于监督特征", "innovation": "本研究通过自动从时间上相邻的图像对中提取个体的两个不同视图，对潜在无限的视频数据流进行无监督训练，探索了在非都市环境中使用自监督学习（SSL）来进行野生动物再识别的方法，这是不同于依赖标注数据的监督模型的一种创新方法。", "conclusion": "实验结果显示，自监督模型在开放世界场景和各种野生动物下游任务中更为稳健，并且自监督特征在所有下游任务中都优于监督特征。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02443", "html_url": "https://arxiv.org/abs/2507.02443", "title": "在FPGA可编程逻辑中使用加速的人工神经网络进行红葡萄检测", "title_en": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic", "authors": "Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias", "background": "机器人在移动过程中通常会减速以进行物体检测，同时为了跟踪检测算法的速度，机器人的摄像头设置为低帧率。这在执行任务和探索过程中会受到限制，增加任务执行时间。AMD开发了Vitis-AI框架，用于在FPGAs中部署检测算法，但该工具并未充分利用FPGAs的可编程逻辑单元（PL）", "innovation": "使用FINN架构在FPGA的PL中部署三个ANNs：使用4位量化部署的MobileNet v1，使用2位量化部署的CNV，以及使用1位量化部署的CNV（BNN）。这些模型是在RG2C数据集上进行训练的，这是一个自己获取并公开发布的数据集。MobileNet v1表现出色，准确率为98％，推理速度为6611 FPS。证明了可以在FPGA中加速ANNs并使其适用于注意力机制", "conclusion": "通过在FPGA的PL中部署经过量化处理的ANNs，成功加速了红葡萄的检测，提高了推理速度，并验证了FPGAs在支持注意力机制中的应用潜力"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02436", "html_url": "https://arxiv.org/abs/2507.02436", "title": "向鲁棒性和通用性强固的元材料基础模型迈进", "title_en": "Toward a Robust and Generalizable Metamaterial Foundation Model", "authors": "Namjung Kim,Dongseok Lee,Jongbin Yu,Sung Woong Cho,Dosung Lee,Yesol Park,Youngjoon Hong", "background": "材料功能的最新进展推动了多个领域的创新，特别是在由结构而非组成定义的元材料方面表现尤为突出。尽管人工智能驱动的设计策略正在兴起，但它们的应用受到特定任务重新训练、不良的分布外泛化以及正向和逆向设计需要单独模型的限制。这些限制限制了这类技术的实际应用和发展潜力。因此，需要一种能够在不同条件和任务下提供强大和广泛支持的新方法来克服这些限制。", "innovation": "该论文提出了一种受大型语言模型启发的贝叶斯变压器基础模型——元材料基础模型(MetaFO)，以解决上述问题。MetaFO能够学习元材料的内部机械原理，实现跨不同、未见过的材料特性和结构响应的零样本预测。MetaFO还能够适应非线性的逆向设计，并在分布外的情况下表现出色。通过将元材料视为一个操作符，它将材料属性映射到结构响应，MetaFO揭示了复杂的关系，并显著扩展了设计空间。这一可扩展且通用的框架标志着人工智能驱动元材料发现的一个范式转变，为下一代创新铺平了道路。", "conclusion": "总之，MetaFO为人工智能驱动的元材料发现提供了一个可扩展且通用的框架。它解决了任务特定的重新训练、分布外的泛化限制以及正向和逆向设计需要单独模型的问题。这种框架不仅在现有条件下有效，还能在未来的新颖情况下继续运用，从而进一步推动AI在元材料设计中的应用和发展。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02503", "html_url": "https://arxiv.org/abs/2507.02503", "title": " Continual Gradient Low-Rank Projection Fine-Tuning for LLMs", "title_en": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs", "authors": "Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing", "background": "持续微调大型语言模型（LLMs）遇到了效率和表达性之间的权衡问题。低秩适应（LoRA）虽然提高了效率，但限制了模型学习新任务和迁移知识的能力，因为它本质上是低秩的，并依赖于显式参数约束。", "innovation": "提出了一种新颖的训练策略GORP（Gradient LOw Rank Projection），这种策略将全秩和低秩参数协同结合，并在同一统一低秩梯度子空间内联合更新。GORP扩大了优化空间，同时保持效率并减轻了灾难性遗忘的问题。", "conclusion": "在持续学习基准测试中的广泛实验证明，GORP在性能上优于现有的最先进方法。相关代码可以在指定的URL地址获取。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02424", "html_url": "https://arxiv.org/abs/2507.02424", "title": "CyberRAG: 一种自主的RAG恶意攻击分类和报告工具", "title_en": "CyberRAG: An agentic RAG cyber attack classification and reporting tool", "authors": "Francesco Blefari,Cristian Cosentino,Francesco Aurelio Pironti,Angelo Furfaro,Fabrizio Marozzo", "background": "大型企业中的入侵检测和预防系统（IDS/IPS）每小时可以生成成千上万的警报，极大增加了安全分析师的负担，而传统机器学习检测工具虽然能减少警报量但依然存在高误报率的问题。此外，标准的单次检索增强生成（RAG）管道经常检索到不相关的上下文，难以对其预测进行合理解释。", "innovation": "本文提出了一种模块化、基于代理的RAG框架——CyberRAG，它能实现实时攻击分类、解释和结构化报告。框架中的中心LLM代理协调了（i）专门针对不同攻击类型的微调分类器的池；（ii）数据增强和警报工具的工具适配器；以及（iii）循环检索与推理过程，不断查询领域特定的知识库，直到证据相关且逻辑自洽。这种自主设计的代理为中心架构可自主精炼威胁标签和解释性文本，减少了误报并提高了可解释性。并且，该框架具有很强的可扩展性，只需添加分类器就能支持新的攻击类型，无需重新训练核心代理。", "conclusion": "CyberRAG在每类数据上达到了94%以上的准确性，并通过语义协调最终分类准确率达到了94.92%。生成的解释在BERTScore中得分为0.94，在基于GPT-4专家评估中得分为4.9/5。这些结果表明，自主的、专攻式的RAG可以在保持高检测准确性的同时提供可信赖的、准备就绪的辅助安全运营中心（SOC）的语言，提供了一种实用且可扩展的半自主网络安全防御流程。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02517", "html_url": "https://arxiv.org/abs/2507.02517", "title": "使用深度学习检测多种农作物的多种病害", "title_en": "Detecting Multiple Diseases in Multiple Crops Using Deep Learning", "authors": "Vivek Yadav,Anugrah Jain", "background": "印度是一个以农业为主的经济体，面临着农业方面的重要挑战，包括由疾病、害虫和环境压力导致的大规模作物损失。早期检测和准确识别不同作物中的疾病对于提高产量和确保粮食安全至关重要。因此，该研究提出了一种基于深度学习的解决方案，旨在检测17种不同作物中的34种不同疾病的多种病害。研究人员构建了一个统一的数据集，包含了来自多个存储库的17种不同作物和34种不同疾病的图像。", "innovation": "提出了一种基于深度学习的模型在统一数据集上进行了训练，并在准确性方面优于现有的领先技术，覆盖了更多的作物和疾病类型。该模型在统一数据集上实现了高达99%的检测准确性，比处理14种作物和26种不同疾病的最先进的技术高出7%。", "conclusion": "通过检测和处理更多的作物以及病害类型，所提议的解决方案旨在为印度农民提供更好的产品。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02506", "html_url": "https://arxiv.org/abs/2507.02506", "title": "IndianBailJudgments-1200: 印度保释命令的多属性数据集，用于印度保释命令的法律NLP研究", "title_en": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders", "authors": "Sneha Deshmukh,Prathmesh Kamble", "background": "在印度这样的地区，法律自然语言处理（Legal NLP）的发展受到缺乏结构化数据集的限制。为此，本文介绍了一个名为IndianBailJudgments-1200的新基准数据集，该数据集包含1200个印度法院关于保释决策的判决书，涵盖了20多种属性的注解，包括保释结果、印度 Penal Code（IPC）条款、犯罪类型和法律推理等。这些数据集将用于支持法律NLP任务，例如结果预测、总结和公平性分析等任务，并且是首个专注于印度保释法理学的公开数据集。", "innovation": "该数据集是首次公开发布的专门针对印度保释法理学的多属性数据集，采用了一种由提示工程调整的GPT-4o流水线生成注解，并进行了一致性验证。它支持广泛的法律NLP任务，弥补了印度地区在此方面数据不足的问题。", "conclusion": "IndianBailJudgments-1200数据集将为研究者提供一个有价值的工具，帮助推进印度地区的法律NLP技术发展，同时推动相关的法律研究和实践应用。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02479", "html_url": "https://arxiv.org/abs/2507.02479", "title": "CrowdTrack: 在实际场景中具有挑战性的多人行踪基准", "title_en": "CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios", "authors": "Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue", "background": "多对象跟踪是计算机视觉领域的经典研究课题。行人跟踪由于其极高的应用价值，已成为最受关注的研究类别。现有方法主要依赖于运动或外观信息进行跟踪，但在复杂场景中往往难以达到理想效果。对于运动信息，对象间的相互遮挡常导致运动状态更新失败；对于外观信息，由于部分可见或图像模糊等因素，结果不够 robust。尽管从标注数据中学习应对这些情况的方法最为直接，但现有的多对象跟踪数据集尚不能满足这一需求。当前方法主要存在两种不足：场景元素较为简单且不符合现实情况。尽管部分现有数据集的视频序列具有以上两点中的某些优势，但依旧数量不足，无法满足研究需求。", "innovation": "本文提出了一个针对在实际场景中具有挑战性的多人行踪的困难大规模数据集，该数据集主要从第一人称视角拍摄，并覆盖真实世界的复杂场景。研究者将其命名为`CrowdTrack`，因其中大多数序列包含大量对象。数据集包含33个视频，总计5,185个轨迹。每个对象均标注有完整的边界框和唯一的对象ID。该数据集旨在提供一个平台，促进开发即使在复杂情况下依然有效的算法。研究者全面分析了该数据集，并在其中测试了多个前沿模型，同时分析了基础模型在该数据集上的表现。该数据集及项目代码已发布在指定链接。", "conclusion": "CrowdTrack数据集将为复杂情况下的人象跟踪算法开发提供有力支持，并为研究人员提供了一个全新的数据平台。该数据集的实际应用价值和研究意义非常显著，充分展示了行人跟踪在实际应用场景中的挑战性，并为未来的研究工作提供了重要依据。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02493", "html_url": "https://arxiv.org/abs/2507.02493", "title": "基于Colonoscopy的时空监督对比学习结肠息肉计数", "title_en": "Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy", "authors": "Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi", "background": "自动化结肠镜检查中的息肉计数对于自动化程序报告和质量控制至关重要，旨在提高结肠癌筛查的成本效益。息肉计数涉及检测和跟踪息肉，然后将属于同一息肉实体的轨迹片段聚类。现有的息肉计数方法主要依赖于自监督学习，并且主要利用视觉外观，忽视了轨迹片段特征学习和聚类阶段中的时序关系。", "innovation": "本文提出了一个监督对比损失框架，该框架整合了时空意识的软目标，以改变现有方法的现状。这种新的方法能够捕捉到息肉内的变异同时保留息肉间的可区分性，从而提高了聚类的鲁棒性。此外，通过引入时序邻近度约束，改善了轨迹片段聚类，减少了在视觉相似但时序上隔开的轨迹片段之间的错误重新关联。我们的研究结果展示了时空意识在息肉计数中的重要性，设立了新的技术水平。", "conclusion": "在公开数据集上的训练和验证结果表明，与先前的方法相比，我们的方法在片段化率上减少了2.2倍，显著提高了息肉计数的准确性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02550", "html_url": "https://arxiv.org/abs/2507.02550", "title": "深度学习理论必须包括组成性稀疏性", "title_en": "Position: A Theory of Deep Learning Must Include Compositional Sparsity", "authors": "David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio", "background": "过参数化的深度神经网络（DNNs）在高维空间中表现出色，远超传统受限的浅层网络处理能力范围，这些浅层网络受到维数灾的限制。尽管如此，关于DNNs学习动态的根本原则仍存在许多未解之谜。论文指出，DNNs成功的根源在于其能够利用目标函数的组成性稀疏结构。这表明许多实际相关函数可以由少量基本函数组成，而每个基本函数仅依赖于输入的低维子集。不过，虽然关于组成性稀疏函数的逼近和泛化理论方面存在一些有希望的洞察，但DNNs的可学习性和优化方面仍有许多重要的问题需要解答。", "innovation": "论文提出，DNNs成功的关键在于它们能够利用目标函数的组成性稀疏结构，证明了大多数实际相关函数可以通过少量基本函数以低维依赖关系进行组成。这一特性适用于所有高效Turing计算函数，因此几乎所有当前的学习问题都可能具有这种特性。论文认为，组成性稀疏性在深度学习中的角色需要更完整的理论框架来支持对人工乃至通用智能的全面理解。", "conclusion": "完成关于组成性稀疏性在深度学习中作用的图景，对于构建关于人工和通用智能的全面理论至关重要。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02592", "html_url": "https://arxiv.org/abs/2507.02592", "title": "WebSailor：网络代理的人超理性导航", "title_en": "WebSailor: Navigating Super-human Reasoning for Web Agent", "authors": "Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou", "background": "提升人工智能超越人类认知限制是大规模语言模型（LLM）训练的关键领域。DeepResearch等专有的代理系统已经展示了在诸如BrowseComp这类极为复杂的检索基准上的超人能力，这是先前无法实现的。我们推测，DeepResearch的成功主要归功于它们在开放源代码模型中缺失的一种复杂的推理模式，即在广阔的信息空间中系统地减少极端不确定性的能力。基于这个洞察，我们提出了WebSailor，一种完整的后训练方法，旨在赋予这种关键能力。该方法通过结构化采样、信息混淆、RFT冷启动和高效代理强化学习算法DUPO生成新颖的高不确定性任务。", "innovation": "WebSailor是专门为提升网络代理系统导航超级推理能力的一种新方法，主要创新点在于其通过生成新颖的、高不确定性任务的方式，结合结构化采样、信息混淆、RFT冷启动和高效的代理强化学习算法DUPO来系统性地降低代理在广袤信息空间中的极端不确定性，从而显著提升了开放源码代理在复杂信息检索任务中的表现，使其能够匹配专有代理的性能，并缩小了能力差距。", "conclusion": "使用WebSailor方法进行训练后，代理能够在复杂的查询任务中表现得与专有代理相当，甚至超越开放源码代理，从而证明了该方法的有效性和创新性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02537", "html_url": "https://arxiv.org/abs/2507.02537", "title": "你在听我讲话吗？细调聊天机器人以实现同理心对话", "title_en": "Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue", "authors": "Paulo Ricardo Knob,Leonardo Scholler,Juliano Rigatti,Soraia Raupp Musse", "background": "对话代理自ELIZA以来取得了显著进步，扩展了角色至医疗、教育、客户服务等领域。随着这些代理越来越多地融入日常人际互动，情感智能，特别是同理心倾听，变得越来越重要。在此研究中，我们探讨了大型语言模型（LLMs）生成情感丰富对话的方式，始于一个由专家手工编写的少量数据集，以反映同理心行为，后续使用两种LLM（ChatGPT和Gemini）扩展对话，并通过情感分析（VADER）和专家评估分析对话的情感进展。尽管生成的对话经常反映出了预期的情感结构，但人类评估揭示了回应感知同理心和连贯性的关键差异。这表明对话中的情感建模不仅需要表达情感的结构性一致性，还需要具有质性的深度，强调结合自动化和以人为本的方法以开发出情感能力更强的代理的重要性。", "innovation": "研究基于由专家手动构建的小规模数据集，以反映同理心行为，并利用两种大型语言模型（ChatGPT和Gemini）扩展对话。通过情感分析（使用VADER）和专家评估分析对话的情感进展。该研究揭示了情感建模不仅需要结构上的情感一致性，还需要情感的质性深度。", "conclusion": "对话中的情感建模不仅需要结构上的情感一致性，还需要情感的质性深度。这要求同时结合自动化和以人为本的方法来开发具有同理心的代理。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02598", "html_url": "https://arxiv.org/abs/2507.02598", "title": "AC-Refiner: 使用条件扩散模型实现高效算术电路优化", "title_en": "AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models", "authors": "Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun", "background": "算术电路，例如加法器和乘法器，是数字系统的基本组件，直接影响性能、功耗效率和面积。但由于设计空间庞大和复杂的物理限制，优化这些电路仍然具有挑战性。尽管最近基于深度学习的方法显示了潜在的前景，但它们在一致探索高潜力设计变体方面存在局限，限制了优化效率。因此，迫切需要一种新的框架来有效优化算术电路设计。", "innovation": "本文提出了一种名为AC-Refiner的新颖算术电路优化框架，利用条件扩散模型。其核心洞察是将算术电路合成重新定义为条件图像生成任务。通过精确调整去噪扩散过程中的目标质量结果（QoRs），AC-Refiner能够一致地生成高质量电路设计。此外，探索的设计被用来微调扩散模型，使其探索更接近帕累托前沿。实验结果表明，AC-Refiner生成的设计具有更好的帕累托最优性，优于最先进的基线方法。进一步验证了通过将AC-Refiner集成到实际应用中所获得的性能提升。", "conclusion": "实验结果证明，AC-Refiner能够生成具有更好帕累托最优性的设计，优于最先进的基线方法。此外，通过将AC-Refiner整合进实际应用中，进一步验证了其性能提升。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02595", "html_url": "https://arxiv.org/abs/2507.02595", "title": "MPF: 通过多视角融合在部署后对语言模型进行对齐和去偏见", "title_en": "MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion", "authors": "Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama", "background": "随着大规模语言模型（LLMs）的应用越来越广泛，对于模型偏见的减轻需求也在增长。现有的对齐框架主要在模型训练阶段进行调整，而MPF（Multiperspective Fusion）框架则是在模型部署后进行对齐和偏见修正，提供了一个便捷的解决方案，特别是在处理复杂的、难以量化的人类偏见时更为有效。基于SAGED（基于偏差的自动生成测试数据集）管道，MPF通过多视角生成来揭示和对齐LLM输出中的偏见，与细腻的人类相似的基础分布对齐。它通过对如人力资源专业人士情感分布等基线进行分解，创建可解释的视角组件，从而指导生成过程中的采样和响应平衡，以此减少模型偏差。研究表明，MPF能够通过与反事实基准（绝对平等）和人力资源基准（偏好顶级大学）对齐LLM的情感分布，降低KL散度、校准误差，并对未见过的问题具有很好的推广能力。因此，MPF提供了一种可扩展且可解释的方法，适用于已部署的LLMs，无需大量提示工程或微调便能实现对齐和偏见修正。因此，MPF为解决LLMs中的偏见问题提供了一种新视角，从而使模型能够更好地服务于多样性和包容性的目标。", "innovation": "MPF框架是首个在模型部署后进行偏见修正的生成框架。它不仅利用了多视角生成来发现和调整模型偏见，还通过分解基线分布（如人力资源专业人士的情感分布）为可解释的视角组件，提高了调整过程的透明度和可解释性。这种分解方法使得MPF能够更加细致地对LSTM的情感分布进行调整，从而更有效地减少模型偏见。与传统的训练后调整方法相比，MPF无需对模型进行微调或复杂的指令设计，只需简单的采样和平衡即可实现目标。这种创新使得MPF框架具备更广泛的适用性和可扩展性。", "conclusion": "实验证明，MPF框架通过多视角融合有效地对齐了LLM的情感分布，使得模型在不同基准下的表现更为一致。其具备小的KL散度、减少的校准误差以及良好的未见过问题推广能力，展示了MPF方法在现实应用中的可扩展性和解释性，使部署后的LLMs更容易进行对齐和去偏见处理，无需复杂的设计或大量的精细调整。\nMPF方法提供了一种新的视角来处理大规模语言模型中的偏见问题，使得模型能够更好地适应多样化和包容性的需求。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02666", "html_url": "https://arxiv.org/abs/2507.02666", "title": "ASDA: 音频频谱差异注意力机制用于自监督表示学习", "title_en": "ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning", "authors": "Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang", "background": "近年来，音频自监督表示学习的进展中，标准Transformer架构成为主流方法，但其注意力机制容易将部分注意力权重分配给无关信息，这可能影响模型的辨别能力。本文旨在解决这一问题", "innovation": "引入了差异注意力机制，通过结合双softmax操作和适当调整的差异系数，有效减少了无效注意力分配的问题，实验结果显示该ASDA模型在多个基准上的性能达到了最先进的水平", "conclusion": "ASDA在音频分类、关键词定位和环境声音分类等多个任务上表现出色，验证了其在音频任务中的有效性，为更广泛的应用铺平了道路"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02602", "html_url": "https://arxiv.org/abs/2507.02602", "title": "基于视觉导航中相机传感器故障的应对策略：仿真与数据集开发", "title_en": "Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development", "authors": "Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill", "background": "视觉基于导航（VBN）算法在空间任务中的重要性日益增加，确保其可靠性和运行稳健性面临着许多挑战。传感器故障可能导致导航算法输出错误或完全的数据处理故障，威胁到任务目标。人工智能提供了一个强大的解决方案，但其主要障碍是缺乏包含故障图像数据的足够和具有代表性的数据集。研究通过分析相机传感器故障及其影响，旨在解决这些问题，并通过仿真框架生成包含故障的图像数据集，推动基于AI的故障检测算法的发展和应用。", "innovation": "该研究通过全面分析视觉导航管道中相机传感器的潜在故障案例，系统地描述了这些故障的原因及其影响，包括对图像质量和导航算法性能的影响，并引入了一种仿真框架来生成包含故障条件的合成图像。最终，该研究创建了一个包含注入故障图像的数据集，为训练和测试基于AI的故障检测算法提供了有价值的工具。", "conclusion": "该研究通过仿真框架生成可靠的故障数据集，并创建了一个包含故障图像的数据集，为基于AI的故障检测算法提供了有价值的工具支持，解决了传统方法的限制和缺乏足够数据的问题，为视觉导航中的故障检测提供了新的解决方案。最终的数据集将在一个禁用期内添加链接。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02644", "html_url": "https://arxiv.org/abs/2507.02644", "title": "使用神经量子态求解Hubbard模型", "title_en": "Solving the Hubbard model with Neural Quantum States", "authors": "Yuntian Gu,Wenrui Li,Heng Lin,Bo Zhan,Ruichen Li,Yifei Huang,Di He,Yantao Wu,Tao Xiang,Mingpu Qin,Liwei Wang,Dingshun Lv", "background": "神经量子态（NQS）的快速发展使其成为研究量子多体系统的一个有前景的框架。利用最新的基于转换单元的架构以及高效优化算法，本研究实现了钝化二维Hubbard模型的最先进成果，该模型被认为是最小的高温超导模型模型。研究表明，NQS中的不同注意力头可以直接编码不同尺度的关联性，这使其能够捕捉强关联系统中的长程关联和纠缠。", "innovation": "通过采用最新的基于转换单元的架构和开发高效的优化算法，本研究实现了最先进成果。研究发现，NQS中的不同注意力头可以直接编码不同尺度的关联性，这使其能够捕捉强关联系统中的长程关联和纠缠。研究表明，钝化二维Hubbard模型中的半填充条纹状状态与铜酸盐材料实验观察结果一致，这进一步证明了NQS作为解决复杂多电子系统的有效工具的功效。", "conclusion": "本研究确立了NQS作为一种强大的工具，用于解决具有挑战性的多费米子系统，特别是在处理二维Hubbard模型中半填充交换模式方面取得了进展，与铜酸盐材料实验观察结果相符。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02620", "html_url": "https://arxiv.org/abs/2507.02620", "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference", "title_en": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference", "authors": "Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang", "background": "分布式推理作为一种有潜力的解决方法，可以实现边缘网络中大型语言模型（LLMs）的推理。最近的管道基线方法具有并行化通信和计算的潜力，有助于降低推理延迟，但在边缘网络中推理请求稀疏的情况下，管道利用率低，这种优势会减弱。为了使边缘网络中的分布式LLM推理更高效，该研究提出了一种管道并行树形推测解码框架——FlowSpec，以提高解码效率和推测效率为目标.", "innovation": "FlowSpec引入了三种关键技术：1）基于评分的逐步验证优先处理更重要的草稿令牌，以较早接受这些令牌；2）有效的草稿管理，在验证期间修剪无效令牌同时保持正确的因果关系；3）动态草稿扩展策略，为推测输入提供高质量的数据。这些技术协同工作以提高管道利用率和推测效率。实验结果表明，FlowSpec在不同模型和配置下显著提高了推理速度，与基线相比，速度提升比例为1.36-1.77倍。", "conclusion": "实验结果表明，FlowSpec框架显著提高了不同模型和配置下的推理速度，相较于基线框架，得到1.36到1.77倍的速度提升。我们的代码已公开在[这个链接](this https URL//#)处。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02606", "html_url": "https://arxiv.org/abs/2507.02606", "title": "De-AntiFake：重新思考反语音克隆攻击的保护性扰动", "title_en": "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks", "authors": "Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu", "background": "语音生成模型的迅速发展引发了对语音克隆（VC）隐私和安全问题的关注。最近的研究调查了通过引入对抗性扰动来打破未经授权的语音克隆的方法。然而，有决心的攻击者可以抵消这些防护性扰动并成功执行语音克隆。现有研究在真实威胁模型中，尤其是包含了扰动净化的情况下，对这些防护性扰动进行了首次系统评估。实验结果显示，虽然现有的净化方法可以中和相当一部分防护性扰动，但它们仍会在特征空间中引起扰动，从而降低语音克隆模型的性能。", "innovation": "本文提出了一种新颖的两阶段净化方法：首先净化受扰的语音，然后使用音素指导细化，以与干净的语音分布对齐。该方法在扰乱VC防护方面优于最先进的净化方法。研究发现，基于对抗性扰动的VC防护具有局限性，突显了急需更可靠的方法以应对由VC带来的安全和隐私风险。", "conclusion": "研究结果揭示了基于对抗性扰动的VC防护的局限性，并强调了迫切需要更稳健的解决方案来缓解VC带来的安全和隐私风险。相关代码和音频样本可以在提供的链接中找到。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02714", "html_url": "https://arxiv.org/abs/2507.02714", "title": "FairHuman: 使用最小潜在延迟公平性在扩散模型中提升人体图像生成的手部和面部质量", "title_en": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models", "authors": "Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma", "background": "随着大规模文本到图像模型的发展，特别是基于扩散的方法，图像生成取得了显著进步。然而，在训练过程中对局部区域（如人脸或手部）的监督不足导致生成具有合理细节的图像仍具有挑战性。因此，需要提出一种方法来解决这一问题，以同时提高全局和局部生成质量，并确保公平性。", "innovation": "本研究提出了FairHuman，一种多目标微调方法，旨在公平地提高生成的整体和局部质量。具体而言，首先构建了三种学习目标：默认扩散目标函数的全局目标，以及基于先注释位置先验的两个局部目标（手部和面部）。接着，基于最小潜在延迟（MPD）准则，推导出了最佳参数更新策略，从而实现多目标问题的公平优化。这种方法可以在保证总体质量的同时，显著提高生成的局部细节质量。", "conclusion": "大量的实验结果表明，本方法在不同场景下有效提升了人体图像生成的质量，尤其是在提高手部和面部等挑战性局部细节方面取得了显著改进。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02687", "html_url": "https://arxiv.org/abs/2507.02687", "title": "APT: 有限数据下扩散模型的自适应个性化训练", "title_en": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data", "authors": "JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang", "background": "使用有限数据个性化扩散模型面临着显著挑战，包括过拟合、先验知识丢失和文本对齐降级。过拟合会导致噪声预测分布的偏移，扰乱去噪轨迹，使模型失去语义连贯性。", "innovation": "本文提出了自适应个性化训练（APT），这是一种新颖的框架，通过采用自适应训练策略和在微调过程中正则化模型的内部表示来缓解过拟合。APT 包含三个关键组件：1) 自适应训练调整，引入过拟合指示器在每个时间步长区间检测过拟合程度，并根据该指示器应用自适应数据增强和自适应损失加权；2) 表征稳定化，通过正则化中间特征图的均值和方差来防止噪声预测的过度偏移；3) 前先知识保持的注意力对齐，将微调模型的跨注意力图与预训练模型的对齐，以维持先验知识和语义连贯性。", "conclusion": "通过广泛的实验，我们展示了APT有效地缓解了过拟合，保持了先验知识，并在有限参考数据生成高质量、多变的图像方面优于现有方法。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02735", "html_url": "https://arxiv.org/abs/2507.02735", "title": "Meta SecAlign: 针对提示注入攻击的稳健基础模型", "title_en": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks", "authors": "Sizhe Chen,Arman Zharmagambetov,David Wagner,Chuan Guo", "background": "提示注入攻击对基于LLM的应用构成了显著的网络安全威胁。当前，模型层防御虽表现出很强的效果，但这些防御大多是以闭源方式进行部署，这限制了AI安全社区的进一步发展。为了促进攻击与防御的协同开发，以推动对抗提示注入攻击的缓解措施研究，开放源码的模型成为必要。", "innovation": "我们开发了Meta SecAlign，首个具有内置模型层防御的开放源码和开放权重的LLM，其性能达到了商用级。我们提供了全面的培训配方，使用了最新版的SOTA SecAlign防御。Meta SecAlign在9个实用基准和7个安全基准上的评估显示，即使是在一般指令调优数据集上训练，也能在未见的下游任务中表现出色，包括工具调用和代理型网络导航，以及指令遵循。我们的最佳模型Meta-SecAlign-70B在对抗提示注入攻击方面达到了最先进的鲁棒性，且与带有模型层防御的闭源商用LLM在实用性上具有可比性。", "conclusion": "Meta SecAlign通过开放源码的方式，实现了商业级模型性能，并且在未见的下游任务中展现了安全性，表明了开放协作研究的重要性，为AI安全领域的发展提供了新的路径。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02748", "html_url": "https://arxiv.org/abs/2507.02748", "title": "基于全局上下文的线性注意力：用于视觉和物理的多极注意力机制", "title_en": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics", "authors": "Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen", "background": "变换器已成为从图像分类到物理模拟等一系列任务的标准模型。尽管其在多项任务上表现出色，但由于输入长度的平方复杂性，标准变换器在时间和内存方面都不实际用于处理高分辨率输入。因此，提出了多种变体，其中最成功的方法采用了分块、下采样或粗化技术，但通常会损失微细尺度的细节。研究表明，借鉴当前最先进的$n$体数值模拟技术，将注意力机制视为网格点之间的交互问题，从而提出了线性时间与内存复杂性的多极注意力机制（Multipole Attention Neural Operator, MANO）", "innovation": "MANO根据距离实现多尺度的注意力计算。每个注意力头保持全局感受野，并且能够线性地在网格点的数量上实现时间和内存复杂性。实验结果表明，MANO在图像分类和达西流中的表现与当前最佳模型（如ViT和Swin Transformer）相当，同时大幅减少了运行时间和峰值内存使用量", "conclusion": "MANO通过多极方法实现了注意力机制的线性复杂性，维护了全局视野，并展示了在视觉和物理任务中的卓越性能。这项研究为处理高分辨率数据提供了新的可能性，未来的研究可以进一步优化网格化和推理流程，以实现更高效的大规模应用。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02737", "html_url": "https://arxiv.org/abs/2507.02737", "title": "前沿大语言模型早期具备隐写术能力的迹象", "title_en": "Early Signs of Steganographic Capabilities in Frontier LLMs", "authors": "Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner", "background": "监视大型语言模型（LLM）的输出对于减轻滥用和错配带来的风险至关重要。然而，LLM可以通过隐写术来规避监控，即在看似无害的生成中嵌入隐藏信息。因此，评估前沿LLM的隐写术能力以更好地了解其所构成的风险变得重要。", "innovation": "本文关注两种类型的隐写术：传递编码信息和进行编码推理。研究发现，当前模型在标准环境下无法在其输出中编码短信息而不被监控发现。但若给予额外的环境因素，如未监控的草稿纸和合作确定的编码方案，模型可能能够成功实施隐写术。此外，研究还发现模型在简单的状态追踪问题中可以在一定程度上进行基础的编码推理。尽管如此，它们很难在遮盖任务中隐秘地隐藏推理内容以愚弄监控。因此，本文表明当前大语言模型展现出初步的隐写术能力，而这些能力在未来可能足以绕过精心设计的监控系统", "conclusion": "总体而言，我们的研究结果表明，当前大语言模型展示出初步的隐写术能力。虽然这些能力目前可能不足以绕过精心设计的监控系统，但这一趋势在未来可能会发生改变。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02752", "html_url": "https://arxiv.org/abs/2507.02752", "title": "由设计合成：一种 retrosynthesis 引导的分子类似物生成框架", "title_en": "Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation", "authors": "Shuan Chen,Gunwook Nam,Yousung Jung", "background": "在计算药物和材料发现中，具有良好性质的AI生成分子的合成可行性之间的脱节仍然是一个关键瓶颈。尽管生成AI加速了候选分子的提议，但许多这些结构在现有化学反应中难以合成或无法合成。", "innovation": "提出了一种名为 SynTwins 的新颖的 retrosynthesis 引导的分子类似物设计框架，通过三种步骤（逆合成分析、类似构建模块搜索和虚拟合成）模仿专家化学家的策略，设计合成可及的分子类似物。与最新的人工智能模型相比，SynTwins 在生成合成可及的类似物方面表现出更优异的性能，同时保持高度的结构相似性。将该方法与现有分子优化框架结合使用时，产生了与无约束分子生成器具有类似性质概况的合成可行分子，同时确保了合成可行性。", "conclusion": "通过跨多种分子数据集的全面基准测试表明，SynTwins 有效解决了计算设计与实验合成之间的差距，提供了一种加速发现具有良好性质的合成分子的实用解决方案，适用于多种应用。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02754", "html_url": "https://arxiv.org/abs/2507.02754", "title": "快且简单：Triton中的2-简化注意力", "title_en": "Fast and Simplex: 2-Simplicial Attention in Triton", "authors": "Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil", "background": "近期研究表明，训练损失随着模型规模和标记数量的增加而按幂律增长，实现计算最优模型需要同时扩展模型规模和标记数量。然而，这些扩展法则假设数据无限，并主要适用于计算限制型环境。随着现代大型语言模型越来越多地依赖于大规模互联网级数据集，假设语言模型是计算限制型的有效性正在减弱。这一转变强调了优先考虑标记效率的架构的需求。", "innovation": "本文研究了2-simplicial Transformer架构，该架构通过高效的Triton内核实现对标准点积注意机制进行了推广，使用三线性函数。结果显示，2-simplicial Transformer在固定标记预算的情况下比同样大小的标准Transformer模型在数学、编码、推理和逻辑任务上表现出更好的标记效率。作者量化了这些增益，表明2-simplicial注意改变了知识和推理任务的缩放定律指数，相对于点积注意而言。", "conclusion": "2-simplicial Transformer架构通过提高标记效率，在计算和逻辑任务上优于标准Transformer模型。这种方法通过改变知识和推理任务的缩放法则指数，显着提升了模型性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02822", "html_url": "https://arxiv.org/abs/2507.02822", "title": "SynapseRoute：双态大语言模型自动路由切换框架", "title_en": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model", "authors": "Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun", "background": "随着大型语言模型（LLMs）在实际应用中的广泛应用，选择合适的模型不仅需要考虑性能，还需要考虑运营成本。具备推理能力的模型进一步拉大了‘思考’（高推理）与‘非思考’（快速、低成本）模式之间的成本差距。本文发现，大约58%的医学问题仅通过‘非思考’模式就能准确回答，不需要高成本的推理过程。这体现了问题复杂度的明显差异，表明根据问题复杂度动态将查询路由到适当的模式可以优化准确性和成本效益，以及整体用户体验。", "innovation": "本文提出了SynapseRoute，一种基于机器学习的动态路由框架，能够智能地将输入查询分配到思考或非思考模式中。在多个医学数据集上的实验结果表明，SynapseRoute 在整体准确率（0.8390 vs. 0.8272）和推理时间（减少36.8%）以及标记消耗（减少39.66%）方面优于单独使用思考模式。此外，质性分析表明，过度推理简单查询可能会导致不必要的延迟并降低准确度，而我们的适应性路由能够避免这一问题。", "conclusion": "本文进一步引入了准确率-推理时间-标记成本（AIT）指数来全面评估准确度、延迟和标记成本之间的权衡。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02755", "html_url": "https://arxiv.org/abs/2507.02755", "title": "多智能体听觉场景分析", "title_en": "Multi-agent Auditory Scene Analysis", "authors": "Caleb Rascon,Luis Gato-Diaz,Eduardo García-Alarcón", "background": "听觉场景分析（ASA）旨在从声学环境中提取信息，通过完成三个主要任务：声源定位、分离和分类来实现。这些任务通常按照线性流程执行，首先定位声源，然后根据位置将每个声源分离到各自的音频流中，再从这些流中提取相关的信息（如音频事件检测、说话人识别、情绪分类等）。然而，这种线性执行方法增加了总体响应时间，并且使得后面的任务（分离和分类）对前面任务（定位）的错误非常敏感。为了减少这些错误，现代技术投入大量努力来开发尽可能减少错误的技术，但这导致了在许多需要较小计算足迹和低响应时间的应用场景中无法使用（如生物声学、助听设备设计、搜索与救援、人机交互等）的ASA系统。", "innovation": "本文提出了一种多智能体方法来执行听觉场景分析（ASA），其中任务并行运行，并在它们之间使用反馈环路来补偿局部错误。例如，利用分离输出的质量来修正定位错误；利用分类结果来降低定位对干扰的敏感性。结果是，这种多智能体听觉场景分析（MASA）系统在不大幅增加复杂性的前提下，具有良好的抗局部错误性能并保持较低的响应时间。完整的提出的MASA系统框架使用了开源工具如JACK进行声音采集和重放，ROS2进行智能体间的通信，允许用户添加自己的智能体。", "conclusion": "该多智能体系统提供了低复杂度和快速响应的听觉场景分析能力，适用于需要降低整体响应时间、减轻局部错误影响的应用场景，如生物声学、助听设备设计、搜索与救援和人机交互等。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02778", "html_url": "https://arxiv.org/abs/2507.02778", "title": "Self-Correction Bench: 揭示并解决LLMs中的自我纠正盲点", "title_en": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs", "authors": "Ken Tsui", "background": "尽管大型语言模型（LLMs）已经变得具有变革性，但它们仍然会犯错误，可能会探索无效的推理路径。自我纠正对于确保LLMs的可信性至关重要，特别是对于自回归型LLMs。虽然LLMs可以识别用户的错误输入，但它们在自我输出中重复错误时表现出系统性的‘自我纠正盲点’，无法进行纠正。为了系统性地研究这一现象，研究人员引入了Self-Correction Bench，这是一种通过受控错误注入在三个复杂性层次下测量这一现象的系统框架。研究共测试了14个模型，发现平均64.5%的盲点率。作者发现，这一限制与训练数据构成有关：人类训练示范通常展示出无错误响应，而不是错误修复序列，这与通过结果反馈学习错误修正的强化学习训练模型形成对比。显著的是，简单地添加“稍等”可减少盲点89.3%的情况，表明该能力存在但需要激活。", "innovation": "提出了名为Self-Correction Bench的新系统框架，用于测量LLMs中自纠正盲点现象，通过受控的错误注入进行了三个复杂性等级下的系统性研究。研究发现人类训练示范中缺乏错误修复序列，而更具能力的强化学习训练模型通过结果反馈学习错误修正，简单添加“稍等”可以显著减少盲点率。", "conclusion": "本研究揭示了一个当前LLMs中的关键局限性，并提出了潜在提升其可靠性和可信度的途径。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02824", "html_url": "https://arxiv.org/abs/2507.02824", "title": "基于DNN的RIS辅助毫米波MIMO系统中具有实际相位偏移的预编码设计", "title_en": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift", "authors": "Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang", "background": "本文研究了毫米波（mmWave）多输入多输出（MIMO）系统中的预编码设计，以提高利用阻挡直接通信路径系统中的传输吞吐量。文章特别考虑了引入可重构智能表面（RIS）来增强MIMO传输的问题，同时考虑了毫米波特有的线视（LoS）和多路径效应。传统的全搜索（ES）方法虽然能够找到最优编码字，但由于相位偏移在连续域中的存在导致计算强度大且耗时。因此，文中提出了使用移位排列离散傅里叶变换（DFT）向量的方法，并结合实际或理想RIS系统的幅度响应来寻找码本设计。尽管ES方法采用离散相位偏移后计算量和时间仍然是问题，但文章通过开发深度神经网络（DNN）来加速编码字的筛选过程，进一步提高了预编码的效率。文中还通过仿真结果展示了DNN在RIS辅助系统中即使在测试阶段用户与RIS之间距离变化时仍然维持了近似最优的频谱效率。", "innovation": "提出了一种基于DNN的预编码设计方案，以加速编码字的选择过程。该方案结合了离散傅里叶变换（DFT）向量和RIS的实际幅度响应，克服了传统全搜索方法计算强度大且耗时的缺点。通过引入DNN，实现了更高效的编码字选择，从而提高了RIS辅助毫米波MIMO系统的性能。", "conclusion": "仿真结果表明，DNN在不同的用户与RIS之间距离变化的测试阶段仍能维持接近最优的频谱效率。这些结果突显了DNN在推进RIS辅助系统中潜在的优势和应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02856", "html_url": "https://arxiv.org/abs/2507.02856", "title": "答案匹配在语言模型评估中优于选择题", "title_en": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation", "authors": "Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping", "background": "传统上，选择题一直用于语言模型评估，因为选择题的评估过程客观且易于自动化。然而，研究表明，广泛使用的选择题可以从其问题中轻易得出答案，这表明选择题并非测试模型生成能力的最佳方法，尤其是存在鉴别评估的基本局限性。最近，尽管尚未找到其他可行的大规模替代方案，但本文表明这一现状已发生变化。作者采用了一种名为答案匹配的方法来评估模型的生成能力，并通过现代语言模型与参考答案对比生成的回答来进行验证，以提高模型评价的准确性。", "innovation": "本文提出了答案匹配作为一种新型的评估策略，通过此方法，给候选模型提供问题而没有选项，让其生成自由形式的回答，然后使用一个先进的语言模型与参考答案对比生成的回答来判断匹配度。这种方法显示了与人类评分的一致性，并证明了它在模型评价上的有效性，即使使用较小的模型也能达到近乎完美的匹配度，而没有参考答案的大型语言模型则与人类评分不匹配。文章还讨论了如何从选择题评估转向答案匹配评估的机制。", "conclusion": "研究表明，使用答案匹配的方法对模型的自由形式回答进行评估比选择题评估更加合理和有效。这种方法可以显著改变不同模型的排名。未来，评估系统应从选择题转向答案匹配，以更准确地衡量模型能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02863", "html_url": "https://arxiv.org/abs/2507.02863", "title": "Point3R：带显式空间指针记忆的流式3D重建", "title_en": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "authors": "Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu", "background": "从有序或无序图像集合中进行密集的3D场景重建是将计算机视觉研究引入实际场景的关键步骤。DUSt3R开创了一种方法，将图像对密集地整合到共享坐标系中，随后的方法保持一种隐式的记忆来实现更多图像的密集3D重建。然而，这种隐式记忆具有容量限制，并且可能会损失早期帧的信息。", "innovation": "我们提出了Point3R，一种针对流式密集3D重建的在线框架。具体来说，我们维护一个与当前场景3D结构直接关联的显式空间指针记忆。每个指针都分配一个特定的3D位置，并在全局坐标系中聚集附近的空间特征。来自最新帧的信息以显式方式与这个指针记忆交互，从而实现当前观测在全局坐标系中的密集整合。我们设计了一种3D分层位置嵌入来促进这种交互，并设计了一种简单而有效的融合机制确保指针记忆的一致性和效率。", "conclusion": "我们的方法在各种任务上实现了竞争力或最先进的性能，同时具有较低的训练成本。代码可在以下地址获取：this https URL。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02851", "html_url": "https://arxiv.org/abs/2507.02851", "title": "MOTIF: 支持强化微调的模块化思考在大语言模型中的应用", "title_en": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "authors": "Purbesh Mitra,Sennur Ulukus", "background": "大型语言模型（LLM）的推理能力近年来有了显著提升，表明使用组相对政策优化（GRPO）算法进行强化学习（RL）训练可以促使模型利用更多的思考/推理令牌以生成更优的响应。然而，LLM在保持对先前生成令牌的关注时，只能生成有限数量的令牌，这一限制被称为LLM的上下文大小，成为LLM进行任意数量思考的瓶颈。为突破上下文大小的限制，LLM必须采用模块化的思考策略，在多轮次中进行推理思考。在本文中，我们提出了一种名为MOTIF的方法——一种通过强化微调生成思考令牌的RL训练方法，这种方法允许模型通过增加上下文大小来进行思考。我们利用参数高效微调对开源模型Qwen2.5-3B-Instruct进行了训练，并在GSM8K数据集上测试了其准确性，随后在MATH500和AIME2024基准上进行了测试。实验结果表明，MOTIF相比基于原始GRPO的培训方法分别提高了3.8%和3.3%，并且仅使用了15%的数据样本，展现了更高的样本效率。相关代码和模型已在相应链接中发布。", "innovation": "本文提出的MOTIF方法设计了一种通过强化微调生成思考令牌的RL训练方法，使模型能够采用模块化思考策略，并在多轮次推理中扩展上下文大小，从而提升大语言模型的推理和生成质量。这种方法通过参数高效的微调策略提高了模型的适应性和泛化能力，显著提高了在数值问题处理等任务上的性能，同时保持了较低的数据使用率，展示了其对大规模数据训练的样本效率和实用性。", "conclusion": "MOTIF通过引入模块化思考和多轮次推理的策略，有效地扩展了LLM的上下文大小，提升了模型在处理复杂推理任务时的效率和准确性。实验结果证明，这种方法不仅能显著提高模型性能，还能在有限的数据样本中获得更好的泛化能力。该方法与开源模型Qwen2.5-3B-Instruct一起作为研究贡献发布，为后续研究和应用提供了有价值的参考。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02827", "html_url": "https://arxiv.org/abs/2507.02827", "title": "USAD: 一种未监督数据增强时空注意力扩散网络", "title_en": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network", "authors": "Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li", "background": "人类活动识别（HAR）的主要目标是从传感器数据中推断出正在进行的人类动作，这个任务在健康监测、安全保护和运动分析等领域有着广泛的应用。尽管进行了大量研究，HAR任务仍然面临关键挑战，包括罕见活动的数据标签稀缺、高级特征提取不足以及模型在轻量级设备上的表现欠佳。", "innovation": "本文提出了一种综合优化方法，中心思想是多注意力交互机制。首先，使用一种无监督的、由统计学指导的扩散模型进行数据扩增，以缓解标签数据稀缺和类别不平衡严重的问题。其次，设计了一种多分支时空交互网络，通过并行的残差分支捕获序列数据的多尺度特征，采用3*3、5*5和7*7卷积核。同时引入了时间注意力机制来识别关键时间点，空间注意力机制增强传感器间的交互。进一步引入了一个跨分支特征融合单元，以提高整体的特征表示能力。最后，集成了一个自适应多损失函数融合策略，以允许损失权重的动态调整，从而实现模型的总体优化。实验结果表明，所提出的未监督数据增强时空注意力扩散网络（USAD）分别在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上达到了98.84%、93.81%和80.92%的准确率，显著优于现有方法。此外，实际部署在嵌入式设备上验证了该方法的效率和可行性。", "conclusion": "本研究提出了USAD，一种结合了未监督数据扩增、时空注意力机制和自适应多损失函数融合策略的方法，显著提高了HAR任务的准确性和灵活性，尤其适合在轻量级设备上的应用。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02861", "html_url": "https://arxiv.org/abs/2507.02861", "title": "LiteReality：从RGB-D扫描构建的图形兼容3D场景重建", "title_en": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans", "authors": "Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby", "background": "随着增强现实（AR）、虚拟现实（VR）、游戏、机器人技术以及数字孪生等领域的快速发展，对高质量的3D场景重建需求日益增加。现有的3D重建方法在物理交互和现实感上存在局限性。LiteReality在这一背景下提出了一种创新的方法，旨在解决这些挑战，提供高质量且可交互的3D虚拟复制品。", "innovation": "LiteReality提出了一种新颖的流水线，能够将室内环境的RGB-D扫描转换为紧凑、逼真且可交互的3D虚拟复制品。它具备以下创新点：首先，通过结构化的场景图进行场景理解并解析场景到相互关联的3D布局和对象；其次，通过查找最相似的3D艺术家创作模型来重建场景；再次，使用材质绘画模块来提升逼真度；最后，将重建的场景集成到具有基本物理属性的模拟引擎中，使其具备交互性。此外，该方法引入了无需训练的物体检索模块和鲁棒的材质绘画模块，这些模块在Scan2CAD基准测试中达到了最先进的相似性性能，即使在严重错位、遮挡和光照不良的情况下也能有效转移图像样式到3D资产。", "conclusion": "LiteReality通过紧凑、可编辑且与标准图形管道完全兼容的3D虚拟复制品，应用于多种实际场景如AR/VR、游戏、机器人和数字孪生中，有效解决了高质量3D场景重建的挑战，展示了显著的效果。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02855", "html_url": "https://arxiv.org/abs/2507.02855", "title": "DHOL中的子类型", "title_en": "Subtyping in DHOL -- Extended preprint", "authors": "Colin Rothgang,Florian Rabe", "background": "最近引入的依赖类型高级逻辑（DHOL）提供了一种在表达能力和自动化支持之间取得有趣平衡的方法。与标准的一阶逻辑不同，DHOL的类型系统牺牲了可判定性以大幅增加其表达能力，但依然保留了通过将其安全且完全地翻译到标准逻辑中的强大自动定理证明支持。在此基础上，利用DHOL的设计特点，论文进一步扩展了DHOL，引入了细化和商类型。作为子类型的一种特例，细化和商类型往往被实践者请求，但由自动定理证明器提供的基本类型系统难以实现。不过由于DHOL已经处理了复杂部分，因此这项扩展不仅成为可能，而且非常简洁和优雅。具体来说，论文将细化和商类型视为子类型的特例，从而将此过程相关的规范包含映射和投影映射转换为恒等映射，并在不修改表示的情况下实现复杂的变换。相关的语法、语义以及DHOL扩展语言向标准逻辑的翻译方式都得到了阐述，其中包括了完整性和正确性的证明.", "innovation": "通过将细化和商类型作为一种子类型的特例引入DHOL，文中解决了自动化定理证明器在实现此类类型时面临的技术挑战。这种创新不仅使得细化和商类型可以现实并且操作简便，而且展示了在已有的依赖类型系统框架下，通过扩展子类型定义实现新类型特性的现实可能性和方法。", "conclusion": "文中详细阐述了扩展DHOL语言的语法、语义和翻译技术，并给出了相关的形式化证明。这种扩展方法有效且优雅，为实践者提供了一种既有强大的表达能力又能保持自动化验证支持的逻辑系统，同时也为未来相关研究提供了新的思路。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.09919", "html_url": "https://arxiv.org/abs/2402.09919", "title": "基于GPS数据在建筑工地生成道路图的方法", "title_en": "Road Graph Generator: Mapping roads at construction sites from GPS data", "authors": "Katarzyna Michałowska,Helga Margrete Bodahl Holmestad,Signe Riemer-Sørensen", "background": "从GPS轨迹中推断道路以构建地图面临挑战，因为建筑机械的运动模式是不规则且非标准的，与标准道路上的车辆交通模式显著不同。这种运动模式的变化要求提出新的方法来处理和推理这些复杂的数据，以便在建筑工地生成准确的道路图。", "innovation": "本文提出了一个新的方法，通过分析GPS轨迹来识别道路交叉口并连接这些交叉口，从而生成道路图。该方法特别适用于建筑工地，可以用于规划和任务分配。实验结果显示该方法在干净或噪声较少的数据中表现完美，但在有显著噪声和频繁缺失GPS更新的区域性能下降。", "conclusion": "该研究通过在挪威的建筑工地实现道路映射，验证了新方法的有效性。虽然在高度噪声环境下表现不佳，但该方法在特定条件下显示出高精度，为建筑工地的道路识别提供了一种有效的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.18624", "html_url": "https://arxiv.org/abs/2409.18624", "title": "无监督认知", "title_en": "Unsupervised Cognition", "authors": "Alfredo Ibias,Hector Antona,Guillem Ramirez-Miranda,Enric Guinovart,Eduard Alarcon", "background": "无监督学习方法受到认知模型的间接启发。到目前为止，最成功的无监督学习方法主要集中在通过数学空间对样本进行聚类。本文提出了一种基于原型、无监督学习方法，该方法受到一种新的认知框架的启发，用于决策制定。", "innovation": "该方法以构建性的方式，作为一种分布式层次结构模型，输入空间可以使用输入无关的方式表示。并通过与当前最先进的无监督学习分类、小规模或不完整数据集分类以及癌症类别分类进行比较，展示了优于现有方法的表现，并呈现了更类似认知的行为特征", "conclusion": "我们的提议中体现了超过先前最先进的无监督学习方法，同时在一些认知特征上也表现得更好，超越了甚至一些有监督学习的方法，表现出了不同且更接近认知的行为."}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.05920", "html_url": "https://arxiv.org/abs/2408.05920", "title": "基于图的区域预训练和提示：一种区域表示学习方法", "title_en": "Urban Region Pre-training and Prompting: A Graph-based Approach", "authors": "Jiahui Jin,Yifan Song,Dong Kan,Haojia Zhu,Xiangguo Sun,Zhicheng Li,Xigang Sun,Jinghui Zhang", "background": "城市区域的表示对于各种下游城市任务至关重要，尽管已有大量方法且取得了一定成功，但由于对城市区域精细功能布局语义关注不足，且现有工作未能充分处理不同任务所需的独特特征和关系，这限制了知识在不同区域间的迁移。因此，如何获得普遍的城市区域知识并适应不同任务依然是一个挑战。", "innovation": "本文提出了一种基于图的城市区域预训练和提示框架（GURPP），包括构建城市区域图以及设计基于图的预训练模型来捕捉实体间异质且可迁移的交互模式。此外，还设计了两种图基提示方法：一种手动定义的提示以整合显式任务知识，另一种可学习任务的提示以发现隐藏知识，增强这些表示在不同任务上的适应性。", "conclusion": "在多种城市区域预测任务和不同城市上的实验结果表明，该框架具有优越的表现。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03997", "html_url": "https://arxiv.org/abs/2506.03997", "title": "Answer Set Programming中条件推理的框架", "title_en": "A framework for Conditional Reasoning in Answer Set Programming", "authors": "Mario Alviano,Laura Giordano,Daniele Theseider Dupré", "background": "本文提出了一种条件依赖的Answer Set Programming（ASP）框架（Conditional ASP），用于定义ASP的条件扩展。该框架基于具有典型性的条件逻辑，并将条件知识库与ASP程序结合，允许用户在ASP程序的解集上进行有条件的推理。该形式体系基于多优先级语义（作为KL M优先级语义的特殊案例），为条件句提供了解释。背景在于扩展经典ASP以支持条件推理的需求，使得传统ASP可以更好地处理现实世界中带条件限制的问题。", "innovation": "该研究的创新在于提出了一个全新的框架——条件依赖的Answer Set Programming（Conditional ASP），使传统ASP能够支持条件推理。该框架的创新之处在于它结合了条件逻辑中的典型性概念和ASP解集的条件化，并且允许用户通过多优先级语义对条件句进行处理。这一方法能更好地模拟现实世界中的条件性决策过程，增强ASP模型解决实际应用场景问题的能力。", "conclusion": "本文提出的框架提供了对ASP程序解集在条件下的重新解释方式，通过对典型性和优先级语义的应用，使ASP能够更好地支持条件性的推理过程。这种框架解决了传统ASP在处理条件约束方面存在的问题，提高了ASP在实际应用中的灵活性和适用性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21506", "html_url": "https://arxiv.org/abs/2506.21506", "title": "Mind2Web 2: 以代理为评判者的评估自主式搜索", "title_en": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge", "authors": "Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su", "background": "自主式搜索，如深度研究系统，通过让代理自主浏览网络、合成信息并提供基于全面引文的回答，代表了用户与网络规模信息交互方式的重大转变。然而，这种搜索方法的复杂性和开放性增加，超越了现有评估基准和方法，这些方法主要假设短期搜索和固定答案。因此，现有评估方法无法全面评估这类搜索系统的表现。", "innovation": "本文提出了一种新的代理为评判者的框架（Agent-as-a-Judge），并构建了 Mind2Web 2 基准，包含 130 个真实的、高质量的、长期任务，用于评估实时网络导航和大量信息综合能力。此外，基于树形评分准则设计，本文构建了任务特定的评判代理来自动评估答案的正确性和来源归属，进行了广泛的评估和详细的错误分析，以提供对未来发展的见解。", "conclusion": "最佳系统 OpenAI Deep Research 达到了人类表现的 50-70%，且花费一半的时间，显示了其巨大的潜力。Mind2Web 2 为自主式搜索系统的开发和基准测试提供了坚实的基础。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.04614", "html_url": "https://arxiv.org/abs/2501.04614", "title": "XGeM：一种用于多模态医学数据生成的多提示基础模型", "title_en": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation", "authors": "Daniele Molino,Francesco Di Feola,Eliodoro Faiella,Deborah Fazzini,Domiziana Santucci,Linlin Shen,Valerio Guarrasi,Paolo Soda", "background": "医学成像中人工智能的应用前景广阔，但受到数据稀缺、隐私问题以及需要强大的多模态集成等挑战的限制。虽然生成模型的进步使得高质量的合成数据生成成为可能，但现有方法通常仅限于单一模态、单向合成，无法在同一过程中联合合成多个模态，同时保持临床一致性。", "innovation": "为了解决这一挑战，引入了XGeM，这是一种67.7亿参数的多模态生成模型，旨在支持医学数据模态之间的灵活、任意到任意的合成。XGeM通过对比学习构建共享的潜在空间，并引入了一种新型的多提示培训策略，能够对输入模态的任意子集进行条件处理，使模型能够适应异质的临床输入并生成多个输出，同时保持语义和结构的一致性。", "conclusion": "我们在MIMIC-CXR数据集上进行了广泛的验证，首先将其与五个竞争对手进行了基准测试，然后进行了一项视觉图灵测试，以评估生成数据的现实性和临床相关性，确保其与真实世界场景的吻合。最后，我们展示了XGeM如何支持医学数据中的关键挑战，如匿名化、类别不平衡和数据稀缺，突显了其作为医学数据合成基础模型的实用性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.07618", "html_url": "https://arxiv.org/abs/2411.07618", "title": "使用稀疏特征级约束的直接偏好优化", "title_en": "Direct Preference Optimization Using Sparse Feature-Level Constraints", "authors": "Qingyu Yin,Chak Tou Leong,Hongbo Zhang,Minjun Zhu,Hanqi Yan,Qiang Zhang,Yulan He,Wenjie Li,Jun Wang,Yue Zhang,Linyi Yang", "background": "大语言模型（LLMs）与人类偏好对齐仍然是一个关键挑战。虽然像强化学习来自人类反馈（RLHF）和直接偏好优化（DPO）这样的后训练技术已经取得了显著的成功，但在提高对齐效率的同时，它们常常引入了计算上的低效率，并且训练过程不稳定。", "innovation": "本文提出了特征级别约束偏好优化（FPO），这是一种新颖的方法，旨在简化对齐过程，同时确保稳定性。FPO 利用了预训练的稀疏自编码器（SAEs）并引入了特征级别的约束，从而可以实现高效且稀疏性的对齐。该方法通过使用稀疏自编码器中的激活特征和基于特征级别的离线参考序列 KL 距离来发挥其效率和质量优势，从而确保在保持高效的同时也具有可控制性。", "conclusion": "我们已经在基准数据集上的实验表明，FPO 相对于最先进的基线方法，在计算成本更低的情况下实现了5.08%的绝对胜率提升。这表明FPO是一个有前景的、高效且可控的LLM对齐解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22355", "html_url": "https://arxiv.org/abs/2506.22355", "title": "具身AI代理：建模世界", "title_en": "Embodied AI Agents: Modeling the World", "authors": "Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hongyu Gong,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Louis-Philippe Morency,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Paden Tomasello,Jitendra Malik", "background": "本文描述了我们对具有视觉、虚拟或物理形态化身为人类或环境互动的AI代理的研究。这些代理包括虚拟化身、穿戴设备和机器人，旨在通过感知、学习和行动来理解其环境，使其在交互方式上更加类似于人类。与单纯的非具身代理相比，具身代理的开发被认为是进行推理和计划的关键，这有助于这些代理更好地理解环境、解读用户意图和社会背景，从而更好地自主执行复杂的任务。这种建模不仅应用于物理世界，还包括用户的心理世界模型，以实现更好的人机协作。", "innovation": "本文提出世界模型在具身AI代理中的构建非常重要，世界模型整合了多模态感知、推理及控制计划、以及记忆，创建物理世界完整的理解。此外，还提出要学习用户的心理世界模型，以提高人机合作的效果。", "conclusion": "本文总结认为，通过建立复杂任务理解、环境交互和自主行动能力的世界模型，可以帮助具身AI代理更好的执行任务和增强用户互动。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20127", "html_url": "https://arxiv.org/abs/2505.20127", "title": "Agentic AI Process Observability: Discovering Behavioral Variability", "title_en": "Agentic AI Process Observability: Discovering Behavioral Variability", "authors": "Fabiana Fournier,Lior Limonad,Yuval David", "background": "随着大型语言模型（LLMs）在现代软件系统中的广泛应用，基于这些模型的AI代理已经成为核心构建块。为了支持这些应用的规范，现在有许多框架可用。这些框架允许使用自然语言提示定义代理设置，其中包括代理的角色、目标和工具。然而，基于这种设置的代理行为对于任何给定的输入都是非确定性，因此迫切需要增强的工具来提高开发者的可观察性，以监测和理解代理行为的可变性。这激发了使用过程和因果发现来增强开发者的观察性的研究，以及结合LLM静态分析技术来区分预期和非预期的行为可变性.", "innovation": "本文探讨了使用过程和因果发现来发现代理执行轨迹的可变性，以增强开发者的可观察性，从而帮助监测和理解代理行为的可变性。此外，我们采用基于LLM的静态分析技术来区分预期和非预期的行为变化。这种仪器化有助于给开发者更大的控制权，以适应不断变化的规范，并识别可能需要更精确和明确定义的功能方面.", "conclusion": "本文认为这种仪器化技术是必要的，可以帮助开发者更好地控制正在演化的规范，识别出哪些功能方面可能需要更精确和明确的规定，从而提高软件系统的设计和性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.07139", "html_url": "https://arxiv.org/abs/2504.07139", "title": "2025年人工智能指数报告", "title_en": "Artificial Intelligence Index Report 2025", "authors": "Nestor Maslej,Loredana Fattorini,Raymond Perrault,Yolanda Gil,Vanessa Parli,Njenga Kariuki,Emily Capstick,Anka Reuel,Erik Brynjolfsson,John Etchemendy,Katrina Ligett,Terah Lyons,James Manyika,Juan Carlos Niebles,Yoav Shoham,Russell Wald,Tobi Walsh,Armin Hamrah,Lapo Santarlasci,Julia Betts Lotufo,Alexandra Rome,Andrew Shi,Sukrut Oak", "background": "自2017年作为百年人工智能研究计划的一个分支诞生以来，人工智能指数一直致力于为政策制定者、记者、执行人员、研究人员和公众提供准确、严谨验证和全球来源的数据。自从AI在全球范围内的讨论越来越多以来，其使命变得从未如此重要。这份报告在跟踪和解读塑造该领域的最关键趋势方面继续领先，从地缘政治格局的变化到AI在商业、政策制定和公众生活中的扩展角色和基础技术的快速演变。", "innovation": "今年的报告显示了对不断变化的AI硬件景观的深入分析、新的推断成本估算以及对AI出版和专利趋势的新分析。此外，引入了关于企业采用负责任AI实践的最新数据，并扩大了AI在科学和医学中日益增长的作用的报道范围。", "conclusion": "作为全球公认的最权威的人工智能资源之一，人工智能指数被《纽约时报》、彭博社和《卫报》等主要媒体所引用；被数百篇学术论文所引用；并被全球各地的政策制定者和政府机构使用。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10768", "html_url": "https://arxiv.org/abs/2501.10768", "title": "MAPS: 提升专家级物理科学多模态推理能力", "title_en": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science", "authors": "Erle Zhu,Yadi Liu,Zhe Zhang,Xujun Li,Jin Zhou,Xinjie Yu,Minlie Huang,Hongning Wang", "background": "当前的多模态大语言模型（MLLM）已经在广泛的文本和图像数据集上进行了预训练，显示出在通用视觉推理任务上的强大能力。然而，在需要理解具有复杂物理结构的图表和基于多模态信息进行定量分析的物理领域，它们的表现仍然不足。为此，本文开发了一种新的框架，名为基于MLLM的多模态科学推理与物理感知和仿真（MAPS），以解决这个问题。MAPS将专家级的多模态推理任务分解为通过物理感知模型（PPM）理解物理图表和通过仿真器使用物理学知识进行推理。", "innovation": "本文提出了一种新的多模态科学推理框架MAPS，它整合了物理感知模型和仿真器来理解和推理复杂的物理图表，并通过精细调整视觉语言模型，使用精心设计的合成数据集生成了物理感知模型。在推理阶段，MAPS结合了PPM提供的输入图表的仿真语言描述和MLLM通过仿真过程获得的结果，推导出潜在的合理性和最终答案。实验结果表明，MAPS显著提高了MLLM的推理准确度，并优于现有所有模型，验证了其在提升多模态科学推理能力方面具有潜力。", "conclusion": "通过使用我们收集的大学水平电路分析问题，MAPS在多模态科学推理能力方面取得了显著进步。这种新的框架为增强MLLM的多模态科学推理能力提供了一个有前景的方向。本文将在发布后公开我们的代码、模型和实验所用的数据集。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12479", "html_url": "https://arxiv.org/abs/2506.12479", "title": "AI Flow: 视角、场景与方法", "title_en": "AI Flow: Perspectives, Scenarios, and Approaches", "authors": "Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li", "background": "信息论的奠基人克劳德·香农和人工智能领域先驱艾伦·图灵开创的信息和通信技术（IT/CT）的融合发展，已形成了不间断的互联互通与计算浪潮。这种协同效应引发了技术革命，随着大型人工智能（AI）模型的应用，这种革命达到了顶峰。这些大型AI模型正在重塑各行各业，重新定义人机协作。然而，AI的普遍智能化面临巨大挑战，主要是因为大型模型在资源消耗上巨大并且需要较高的通信带宽需求。", "innovation": "AI Flow 作为一种跨学科框架，整合了最新IT和CT的进步，特别强调以下三点创新：首先，设备-边缘-云框架作为基础，将终端设备、边缘服务器和云集群结合起来，以优化低延迟模型推断的可扩展性和效率。其次，引入了家族模型的概念，即一系列具有对齐隐藏特征的不同大小的模型，使得协作和适应不同资源约束和动态场景变得更加灵活。第三，基于连接性和交互式智能的涌现，是AI Flow 的一个新颖范式。通过利用通信网络增强互连性，实现了跨异构节点的AI模型协作，形成超越单个模型能力的新兴智能", "conclusion": "AI Flow 提供了增强的智能、及时的响应性和普遍的AI服务可访问性，为AI技术和通信系统的更紧密融合铺平了道路。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2306.13840", "html_url": "https://arxiv.org/abs/2306.13840", "title": "超越规模：作为自然语言数据变异性的数据质量度量——多样性系数", "title_en": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data", "authors": "Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo", "background": "当前预训练大型语言模型（LLMs）的趋势主要集中在模型和数据集规模的扩展上。虽然预训练数据的质量被认为是训练强大LLMs的重要因素，但它仍然模糊不清，尚未得到严格的界定。因此，本文提出了一种对数据质量进行正式化的关键方面——通过被称为多样性系数的度量来衡量自然语言数据的变异性。我们的实验证据表明，所提出的多样性系数与多样性和变异性的一些直观属性相吻合，例如随着隐含概念数量的增加而增加。此外，我们测量了公开的预训练数据集的多样性系数，并证明它们的正式多样性高于理论上下限。最后，我们对GPT-2和LLaMAv2进行了全面的控制干预实验，总共包括44个不同规模的模型（从51M到7B参数），结果表明，预训练数据的多样性系数能够表征下游模型评估性能的有效方面。", "innovation": "本文提出了一个衡量自然语言数据变异性的度量——多样性系数，并通过实验证据展示了它与多样性的一些直观属性一致。此外，该论文通过全面的实验表明，多样性系数可以表征下游模型评估性能的有效方面。", "conclusion": "本文的正式化多样性概念是数据质量的重要组成部分，能够捕获变异性并对改进评估性能产生因果影响。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.05766", "html_url": "https://arxiv.org/abs/2405.05766", "title": "XAI系统的新型用户信任度量方法", "title_en": "Towards a Novel Measure of User Trust in XAI Systems", "authors": "Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho", "background": "随着深度学习模型在各个领域的应用越来越广泛，由于这些模型本身存在不透明性的问题，解释性人工智能（XAI）方法的研究逐渐兴起。XAI方法旨在通过提供决策背后的洞察，提升最终用户对自动化系统的信任度。", "innovation": "本文提出了一种新的信任度量方法，这种方法能从客观角度结合性能指标和信任指标进行改进，并通过三项案例研究验证了该方法相比现有方法在不同场景下具有更高的灵敏度，从而证明了其有效性与创新性。", "conclusion": "通过验证三例研究，该新方法相比最先进的技术在用户信任方面表现出了更高的敏感性，从而证明其有效性和创新性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.08010", "html_url": "https://arxiv.org/abs/2311.08010", "title": "通过不确定性感知教师学习和学生-学生协作学习提高远程监督命名实体识别的鲁棒性", "title_en": "Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning", "authors": "Shuzheng Si,Helan Hu,Haozhe Zhao,Shuang Zeng,Kaikai An,Zefan Cai,Baobao Chang", "background": "远程监督命名实体识别（DS-NER）在实际场景中被广泛应用，能够减少注释负担，通过现有知识库中的实体与文本片段进行匹配。然而，这种方法面临标签噪声的问题。近期工作尝试采用教师-学生框架逐步改善训练标签，提高整体鲁棒性，但性能仍未达到预期，主要是因为教师网络的校准不足，导致错误的伪标签样本，进而产生错误传播。", "innovation": "提出不确定性感知教师学习（利用预测不确定性减少自训练阶段的错误伪标签数量）和学生-学生协作学习（允许两个学生网络之间可靠标签的转移，而不是盲目依赖所有来自教师的伪标签，进一步实现对错误标签样本的全面探索，而非仅仅过滤不可靠的伪标签样本）", "conclusion": "我们的方法在五个DS-NER数据集上进行了评估，证明了我们的方法优于最先进的DS-NER方法。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.07016", "html_url": "https://arxiv.org/abs/2406.07016", "title": "通过过剩词汇探究生物医学出版物中的LLM辅助写作", "title_en": "Delving into LLM-assisted writing in biomedical publications through excess vocabulary", "authors": "Dmitry Kobak,Rita González-Márquez,Emőke-Ágnes Horvát,Jan Lause", "background": "大型语言模型（LLMs）如ChatGPT可以生成和修订具有人类水平性能的文本。然而，这些模型存在显而易见的局限性，包括产生不准确信息、加强现有偏见以及容易被误用。尽管如此，许多科学家仍使用它们来进行学术写作。然而，学术文献中这种LLM使用的普及程度如何？为了解这个问题，特别是在生物医学研究领域，该研究提供了一种客观、大规模的方法：研究2010年至2024年由PubMed索引的超过1500万篇生物医学摘要中的词汇变化，展示了LLMs的出现导致了特定风格词汇频率的突然增加。通过过剩词汇分析表明，至少有13.5%的2024年摘要使用了LLMs。这个下限在不同学科、国家和地区有所不同，有些子集达到40%。该研究证明，LLMs在生物医学研究中的科学写作上产生了前所未有的影响，超越了诸如新冠疫情等重大世界事件的影响。", "innovation": "该研究采用了一种大规模、客观的方法，通过研究超过1500万篇生物医学摘要中的词汇变化，揭示了LLMs在学术写作中的使用情况，特别是展示了特定风格词汇频率的突然增加。这种方法不仅有助于了解LLMs的影响范围，还揭示了其在不同领域、国家和地区中的不同影响程度。", "conclusion": "该研究证实了LLMs在生物医学研究中的科学写作上产生了前所未有的重大影响，这种影响甚至超过了重大世界事件如疫情对科学写作的影响。此外，研究还发现LLMs的使用在不同学科、国家和地区之间存在显著差异。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.08062", "html_url": "https://arxiv.org/abs/2402.08062", "title": "通过求助避免在线学习中的灾难", "title_en": "Avoiding Catastrophe in Online Learning by Asking for Help", "authors": "Benjamin Plaut,Hanlin Zhu,Stuart Russell", "background": "大多数具有形式悔恨保证的学习算法都假设所有错误都是可恢复的，并且主要依赖于尝试所有可能的行为。但在某些情况下，一些错误是“灾难性”的，也就是不可恢复的。文章提出了一个在线学习问题，目标是在允许有限次数向导师求助的情况下，尽量降低灾难发生的概率。与此同时假设代理可以将知识转移到类似输入上。研究发现，普遍而言，任何算法要么以线性速度向导师求助，要么几乎不可避免地导致灾难发生。但在导师策略类在标准在线模型中是可学习的情况下，文章提供了一个算法，其悔恨和向导师求助的频率都随着时间轴的增长接近于0。尽管研究关注于收益的乘积，但也提供了典型加性悔恨的匹配界。", "innovation": "文中提出了一个新颖的在线学习问题，目标是在面对灾难性不可恢复错误时，通过有限次数向导师求助来最小化灾难发生的概率，同时允许知识在类似输入间转移。并且提出了有效的算法，在特定条件下其悔恨和求助频率都趋于0，证明了一个必要假设：如果在无灾难风险下可学习的策略类，在有灾难风险时如果代理可以求助，该策略类也是可学习的。这一研究为处理错误不可恢复情况提供了新方法。", "conclusion": "研究发现在特定条件下，即使存在不可恢复的错误（灾难），通过适当的求助机制，仍然可以有效学习策略。尤其是在灾难性错误对结果有严重影响的情况下，求助机制是有效的解决办法。同时，研究提供了理论支持，表明在一定条件下，不仅可以控制平均悔恨，还可以控制灾难发生的概率。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.07079", "html_url": "https://arxiv.org/abs/2408.07079", "title": "脑成像的解剖基础模型", "title_en": "Anatomical Foundation Models for Brain MRIs", "authors": "Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto", "background": "深度学习（DL）在神经影像学中变得越来越重要，用于检测神经学状况和神经退行性疾病。脑年龄是神经影像中最主要的生物标志物之一，已被证明是不同状况的良好指标，如阿尔茨海默病。利用脑年龄在数据稀缺条件下进行弱监督预训练的深度学习模型已经显示出有希望的结果。此外，脑MRI的解剖信息（例如皮质厚度）可以提供用于学习良好表示的重要信息，这些表示可以转移到许多下游任务中。现有方法通过对轻度对比学习方法利用脑部解剖信息，可以得到在各种下游任务中具有表现最好的模型。已经考虑了包括阿尔茨海默病、自闭症谱系障碍和精神分裂症等不同状况的12个下游诊断任务，以及使用结构MRI数据预测10种不同的临床评分任务。研究表明，在预训练期间整合解剖信息可以导致更稳健和通用的表示。", "innovation": "提出了一种名为AnatCL的脑成像解剖基础模型，该模型i）在弱对比学习方法中利用了解剖信息，ii）在许多不同的下游任务中实现了最先进的性能。", "conclusion": "通过在多种下游任务中进行验证，本文证明了在预训练期间整合解剖信息可以导致更稳健和通用的表示。预训练模型可在指定的网址下载。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.15026", "html_url": "https://arxiv.org/abs/2408.15026", "title": "序列感知预训练以指导超声心动图探头移动", "title_en": "Sequence-aware Pre-training for Echocardiography Probe Movement Guidance", "authors": "Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang", "background": "超声心动图是诊断心血管疾病的重要医疗技术，但由于其高操作复杂性，导致专业技术人员短缺。心脏的复杂结构和个体差异给超声心动图带来了重大挑战。当前方法仅学习平均心脏结构而非个性化结构，限制了性能。临床观察显示，操作者根据先前扫描序列动态调整解剖学解释，从而优化扫描策略。", "innovation": "提出了一种序列感知自我监督预训练方法，通过预测携带探针动作的扫描序列中的遮蔽特征来学习个性化的心脏三维结构特征。假设如果模型能够预测缺失的内容，就表示已经掌握个性化心脏结构的理解。与先进的基准方法相比，该方法在包含131万个样本的大型专家扫描数据集上，能有效减少探针指导错误.", "conclusion": "本文提出的方法在处理大规模专家扫描数据集时，相较于其他先进基准方法，能有效减少探针指导错误，展示了其在超声心动图探头移动指导中的应用潜力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2303.06827", "html_url": "https://arxiv.org/abs/2303.06827", "title": "基于核密度的贝叶斯逆强化学习", "title_en": "Kernel Density Bayesian Inverse Reinforcement Learning", "authors": "Aishwarya Mandyam,Didong Li,Jiayu Yao,Diana Cai,Andrew Jones,Barbara E. Engelhardt", "background": "逆强化学习（IRL）方法通过专家行为的示范来推断代理的奖励函数。一种贝叶斯IRL方法模型等奖励函数的分布，捕获了奖励函数推断中的不确定性。这在某些应用中至关重要，例如涉及临床数据的应用。典型情况下，贝叶斯IRL算法需要大型示范数据集，而在实践中这一需求可能无法满足。因此，本文通过整合现有领域的特定数据来提高后验集中率。本文研究在临床和生物应用中常见的一种情况，即可以访问专家示范和一组训练任务的已知奖励函数。目标是在限制的专家示范下学习新测试任务的奖励函数。现有贝叶斯IRL方法对输入数据形式施加了限制，从而限制了训练任务数据的整合。为更好地利用训练任务的信息，本文引入了一种基于核密度的贝叶斯逆强化学习（KD-BIRL）。我们的方法采用了条件核密度估计器，利用训练任务的已知奖励函数来改善对一系列奖励函数和示范样本的似然估计。实证结果表明，KD-BIRL的后验集中率较快，尤其是在测试任务专家示范数据较少的情况下。此外，我们提供了首个贝叶斯IRL算法后验集中率的理论保证。综合来看，本文提出了一种原理上和理论上都得到验证的框架，使得贝叶斯IRL能够在多种领域中得到应用。", "innovation": "本文介绍了一种新的基于核密度的贝叶斯逆强化学习方法（KD-BIRL），该方法利用条件核密度估计器，通过与训练任务的已知奖励函数交互，改善后验集中率。相较于现有的贝叶斯IRL方法，这种方法能够更快地在较小的专家示范数据下集中到后验分布。此外，本文是首个提供贝叶斯IRL算法后验集中率的理论保证。", "conclusion": "本文提出了一种基于核密度的贝叶斯逆强化学习（KD-BIRL）方法。通过实证结果和理论分析证明了该方法在较小的专业示范数据下的有效性，并提供了首个理论保证。该工作为贝叶斯IRL方法在多种领域的应用提供了一个健全和理论基础的框架。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.06902", "html_url": "https://arxiv.org/abs/2407.06902", "title": "来自嘈杂众包标签的学习：信号处理视角", "title_en": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective", "authors": "Shahana Ibrahim,Panagiotis A. Traganitis,Xiao Fu,Georgios B. Giannakis", "background": "随着人工智能（AI）和机器学习（ML）的进步，大量且经过整理的数据集是推动力之一。众包是一种常用方法，将数据分配给多个标注者，然后融合标注者的标签以支持后续学习和推理任务。然而，由于标注者缺乏专业技能或不可靠等原因，标注过程会导致噪声标签。因此，优化众包过程中标签噪声影响的方法成为核心研究目标。本文回顾了来自嘈杂众包标签的学习的研究进展，重点关注关键的众包模型及其方法论处理方式，从经典的统计模型到近年来基于深度学习的方法，强调了分析见解和算法发展。", "innovation": "文章展示了信号处理（SP）理论和方法，如张量和非负矩阵分解的可识别性，并通过SP视角提出了解决众包领域长期挑战的新颖且合理的方法。此外，文章还探讨了反向强化学习（RLHF）和直接偏好优化（DPO）等新兴主题，它们对于开发尖端的AI/ML系统至关重要，特别是对于大型语言模型（LLMs）的微调。", "conclusion": "通过信号处理的视角，文章深入探讨了如何处理嘈杂的众包标签，提出了一些新颖的方法和解决方案，为未来的AI/ML系统开发提供了新的视角和方法。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.06416", "html_url": "https://arxiv.org/abs/2409.06416", "title": "探索大型语言模型在工业测试维护过程中的集成", "title_en": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes", "authors": "Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg", "background": "软件测试过程中，投入大量时间和精力在测试维护上，包括增加、删除或修改测试用例以保持测试套件与被测系统的同步，或提高其质量。工具支持可以通过自动化测试维护过程的某些方面或为开发人员提供指导和支持来降低成本并改善测试维护质量。我们研究了大型语言模型（LLMs）的支持能力及其在测试维护中的应用。LLMs是一种用于文本分析的复杂机器学习模型。我们通过在爱立信AB进行实证研究，探索测试维护所需的触发因素、LLMs能采取的行动以及在工业环境中部署LLMs时需要考虑的问题。我们还提出了一个多代理架构，可以根据源代码的变更预测哪些测试需要维护。这些贡献共同推进了我们对如何利用LLMs来改善工业测试维护过程的理解。", "innovation": "我们提出并演示了多代理架构，能够根据源代码变更预测哪些测试需要维护。通过探索大型语言模型在工业测试维护过程中的能力及其应用，我们提高了对如何利用大型语言模型来改善工业测试维护过程的理解和技术水平。", "conclusion": "我们的研究结论表明，大型语言模型可以作为一种有效的工具支持测试维护，通过自动化某些维护任务或提供指导和支持来降低成本和提高测试质量。我们还提出了一种多代理架构，可用于预测在源代码变更后的测试需求维护状态，这为工业测试维护提供了新的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.03133", "html_url": "https://arxiv.org/abs/2407.03133", "title": "使用潜在类别分析量化多组别跨部门交汇差异以实现公平", "title_en": "Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness", "authors": "Yingfang Yuan,Kefan Chen,Mehdi Rizvi,Lynne Baillie,Wei Pang", "background": "随着人们对公平AI发展的兴趣不断增长，‘ Leave No One Behind’倡议呼吁我们解决多种和交叉形式的不平等，特别是在获取服务、资源和机会方面，强调了公平对AI的重要性。随着越来越多的AI工具被应用于决策过程，例如资源分配和服务方案开发，这些问题在健康、能源和住房等各个领域变得尤为重要。因此，探索这些领域的联合不平等对全面了解整体不平等和不公平具有重要意义。这项研究介绍了一种创新的方法，使用潜在类别分析量化用户定义组之间的跨部门差异。这些差异可以用来估算不平等，并提供有关公平性问题的宝贵见解。我们使用包括EVENS和2021年英伦人口普查数据集在内的私人数据集和公共数据集来验证我们的方法，以研究不同族裔群体之间的跨部门差异。我们还通过与政府公共指标进行相关性分析来验证量化差异的可靠性。我们的研究结果表明，在少数族裔群体之间以及少数族裔群体与非少数族裔群体之间存在显著差异，强调了政策制定过程中需要有针对性的干预措施。此外，我们还展示了所提出的方法如何为确保机器学习系统的公平性提供有价值的见解。", "innovation": "提出了一种创新的方法，使用潜在类别分析量化用户定义组之间的跨部门差异。这种方法能够估计不平等程度，并提供有关公平性问题的洞察。我们使用多种数据集验证了方法的有效性。", "conclusion": "研究发现显著的跨部门差异，强调需要在政策制定过程中进行针对性干预。所提出的方法可以为确保机器学习系统的公平性提供有价值的信息。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.08500", "html_url": "https://arxiv.org/abs/2410.08500", "title": "基于语义-拓扑-度量表示引导大语言模型推理的空中视觉-语言导航", "title_en": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning", "authors": "Yunpeng Gao,Zhigang Wang,Linglin Jing,Dong Wang,Xuelong Li,Bin Zhao", "background": "空中视觉-语言导航（VLN）是使无人机通过自然语言指令和视觉线索在户外环境中自主导航的一项新型任务，但由于户外场景中复杂的空间关系，该任务仍具有挑战性。现有的空中VLN任务的挑战主要源于这些复杂的关系。", "innovation": "本文提出了一个端到端的零样本框架，使用大型语言模型（LLM）作为代理进行动作预测。特别之处在于开发了语义-拓扑-度量表示（STMR），这是一种增强语义理解能力的策略，通过将指令相关信息的语义掩码投影到包含周围地标位置信息的俯视图地图中，进一步将这种地图转化为矩阵表示，并利用距离度量作为文本提示输入LLM进行动作预测。", "conclusion": "实验结果显示在真实环境和模拟环境中我们的方法都达到了很好的效果，具体来说，在AerialVLN-S数据集上实现了Oracle Success Rate (OSR)绝对提升了15.9%和12.5%。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.10589", "html_url": "https://arxiv.org/abs/2409.10589", "title": "基于离线强化学习的作业车间调度学习", "title_en": "Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling", "authors": "Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang", "background": "作业车间调度问题（JSSP）是复杂的组合优化问题。尽管在线强化学习（RL）能够迅速找到较好的解决方案，但它存在样本效率低下、无法利用传统方法（如约束编程CP）的优质解决方案以及需要构建复杂调度环境的模拟环境等关键限制问题。文章介绍了一种基于离线强化学习的方法（Offline Learned Dispatching，Offline-LD），利用历史调度数据学习，解决了上述问题。这种方法适合历史调度数据和专家解决方案可用的场景，或不适合在线使用模拟环境训练RL场景。", "innovation": "1. 引入了能够从历史数据学习的Maskable Quantile Regression DQN（mQRDQN）和离散Maskable Soft Actor-Critic（d-mSAC）的变体。\n2. 提出了d-mSAC的新型熵奖励修改方法。\n3. 引入了JSSP中使用离线RL方法的新型奖励归一化方法。\n4. 实验表明，在仅使用CP生成的100个解决方案训练时，Offline-LD在生成实例和基准实例上均超过在线RL。\n特别地，通过向专家数据集添加噪声可获得与使用专家数据相同数量实例时相同甚至更好的结果，这表明该方法在实际应用中有很大潜力，因为实际数据通常具有噪声和不完美性。", "conclusion": "本文提出了一种离线强化学习方法Offline-LD，通过利用历史调度数据解决作业车间调度问题（JSSP）中的在线RL方法所遇到的一系列问题。这种新方法在生成实例和基准实例上的表现超过了在线RL，并且在仅用少量训练实例的情况下取得了更好的效果，特别是在噪声数据中。\n该研究为解决JSSP问题提供了一种新的、有效的解决方案，并在实际应用中有广泛的应用前景。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.08290", "html_url": "https://arxiv.org/abs/2409.08290", "title": "重新评估脉冲神经网络的能效", "title_en": "Reconsidering the energy efficiency of spiking neural networks", "authors": "Zhanglu Yan,Zhenyu Bai,Weng-Fai Wong", "background": "现有的能效评估往往简化了对脉冲神经网络（SNNs）相较于量化人工神经网络（QNNs）的优势的认知，主要关注计算方面而忽视了诸如全面数据传输和内存访问等关键开销。这种简化可能导致对SNNs真正能效优势的误解。本文旨在提供一个严格的重新评估，通过将SNN模型与等效的QNN模型进行映射，确保两者在代表能力和硬件需求上具有可比性，从而进行有意义的能效比较。通过引入包含核心计算和数据传输的详细能效分析模型，系统地探索了广泛的参数空间，从而揭示了SNNs在特定运行条件下能提供更好能效的具体情况。例如，在典型的类脑硬件条件下，适度时间窗口（T ∈ [5,10]）下的SNNs需要平均尖峰率（sr）低于6.4%才能优于等效的QNNs。", "innovation": "本文提出了一个公平的基线模型，即将率编码的SNNs映射到具有$\theta(T + 1)$位数的功能等效QNNs，确保两者具有类似的能效与硬件需求。引入了包含核心计算和数据传输的详细分析模型，全面涵盖了稀疏和密集激活，权重等关键方面，系统性地探讨了广泛的参数空间，包括网络固有的（T，尖峰率$sr$，QNN稀疏性$\theta$，模型大小$N$，权重位数）和硬件固有的（内存系统和片上网络）特性，以此识别出SNNs具体在哪些操作区域中能够提供更好的能效。", "conclusion": "本文揭示了特定的操作区域，其中SNNs确实提供了更好的能效表现。例如，典型的类脑硬件条件下，时间窗口T在[5,10]的SNNs，其平均尖峰率（sr）低于6.4%时，能够优于等效的QNNs。这些见解指导了设计真正具有能效优势的神经网络解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12537", "html_url": "https://arxiv.org/abs/2410.12537", "title": "是复杂查询回答真的复杂吗？", "title_en": "Is Complex Query Answering Really Complex?", "authors": "Cosimo Gregucci,Bo Xiong,Daniel Hernandez,Lorenzo Loconte,Pasquale Minervini,Steffen Staab,Antonio Vergari", "background": "知识图谱（KGs）上的复杂查询回答（CQA）正成为一项具有挑战性的推理任务。目前的CQA基准可能并不像我们想象的那么复杂，因为它们的构建方式扭曲了对这一领域进步的感知。这些基准测试中，大多数查询（某些查询类型高达98%）可以简化为更简单的问题，例如链接预测，其中只需预测一个链接。当评估那些不能简化为较易类型问题的查询时，最新的CQA模型的表现显著下降。因此，需要提出更能反映实际情况的更具有挑战性的基准测试，要求模型在多跳推理中进行推理，更好地反映现实世界中知识图谱的构建方式。", "innovation": "该研究提出了新的基准测试，旨在更准确地衡量CQA的能力。这些新的基准测试包含了需要模型进行多跳推理的查询，更好地反映了现实世界中知识图谱的构建方式。测试结果显示，当前的方法在CQA任务上仍然存在很大改进空间。", "conclusion": "新的基准测试表明，当前的方法对于CQA方法还有很大的改进空间，需要进一步的研究来开发和评估具有更好性能的模型。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.11556", "html_url": "https://arxiv.org/abs/2412.11556", "title": "Token Prepending: 一种无需训练即可从LLMs中提取更好句嵌入的方法", "title_en": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs", "authors": "Yuchen Fu,Zifeng Cheng,Zhiwei Jiang,Zhonghui Wang,Yafeng Yin,Zhengliang Li,Qing Gu", "background": "从大型语言模型（LLMs）中提取句子嵌入是一个有前景的方向，因为LLMs展示出了更强的语义理解能力。先前的研究主要集中在通过给模型提供提示，使其能够将句子信息编码到最后一个标记的嵌入中，而这样的做法通常依赖于每个层只关注当前输入的序列，因此较早的标记难以与后续的标记进行交互，导致句子信息编码出现偏见，并影响最终解码标记的效果。", "innovation": "提出了一个新的Token Prepending (TP)技术，该技术将每个层解码得到的句子嵌入添加到下一个输入层句子的开头，从而使较早的标记能够在因果注意力机制下访问完整的句子信息。该TP技术是一种即插即用且无需训练的技术，可以无缝地与不同的基于提示的句子嵌入方法和自回归LLMs相结合。实验结果表明，TP技术能够显著提升现有基于提示的句子嵌入方法在不同LLMs上的表现，同时几乎不增加额外的推理成本。", "conclusion": "通过TP技术，各LLMs在语义文本相似性（STS）任务和下游分类任务上的表现得到了显著提升，验证了这种方法的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.14441", "html_url": "https://arxiv.org/abs/2411.14441", "title": "GeMID: 通用模型的物联网设备识别", "title_en": "GeMID: Generalizable Models for IoT Device Identification", "authors": "Kahraman Kostas,Rabia Yasa Kostas,Mike Just,Michael A. Lones", "background": "物联网(IoT)设备数量的激增使得确保其安全性变得至关重要。基于交通模式进行设备识别(DI)对于区分和识别易受攻击的设备至关重要，从而弥补了重要的安全缺口。然而，现有通过机器学习构建模型的方法往往忽视了模型在不同网络环境下的泛化能力的挑战。这项研究旨在通过提出一个新框架来解决这个问题，并评估DI模型在不同网络环境中数据集中的泛化能力。研究表明，常用的滑动窗口和流量统计方法在泛化能力方面存在根本限制。统计方法在文献中广泛使用，但由于依赖于网络特定特性而非设备固有属性，其可靠性有限，挑战了大量现有研究的有效性。", "innovation": "本研究提出了一个新框架，通过使用遗传算法与外部反馈和不同环境的数据集来增强特征和模型选择的稳健性，从而评估DI模型在不同数据集中的泛化能力。方法包括两步：首先开发一种更健壮的特征和模型选择方法，然后在进一步独立的数据集上验证模型的泛化能力。实验结果表明，该方法的有效性超越了现有的替代方案，强调了常用技术和方法泛化能力的局限性，同时指出使用统计方法进行设备识别不可靠。", "conclusion": "本研究为物联网安全和设备识别的研究提供了重要的见解，通过改进模型的有效性并减轻物联网网络的风险，推动了该领域的进步。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.18530", "html_url": "https://arxiv.org/abs/2412.18530", "title": "关于语言生成的表征：幻觉、广度和稳定性的互动", "title_en": "On Characterizations for Language Generation: Interplay of Hallucinations, Breadth, and Stability", "authors": "Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas", "background": "该研究探讨了有限自动机语言生成的概念，在该概念中，自动机会在接收到有限字符串后停止变化。这项研究建立在Kleinberg和Mullainathan（[KM24]）的工作之上，后者提出了一种从任何可数语言集合中生成新字符串的算法。除了经典的Gold（[Gol67]）和Angluin（[Ang79]）的工作外，后来的工作引入了广度的不同概念，并探讨了广度生成的可能性，但尚未完全解决这些概念的性质的描述问题。", "innovation": "本文通过识别现有广度概念及其扩展之间的生成特性，提供了首次解决这类问题的方法。此外，研究表明，在训练生成器时，实现目标语言K的较高困惑度或较低幻觉率不受其他语言的影响是不可行的，无论采用何种性能指标。进一步地，本文证明了在稳定性要求下的广度生成对于许多现有的广度概念来说变得具有同等难度。这揭示了生成具有近似广度的语言之间的稳定生成器和不稳定生成器之间的分离，强调了广度、稳定性和一致性之间的复杂互动关系。", "conclusion": "本文通过严格的表征，解决了语言生成领域中幻觉、广度和稳定性的关系问题。特别地指出，生成目标语言K的生成器在保持广度的同时必须同时考虑稳定性和一致性，这为该领域的未来研究指明了方向。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.05007", "html_url": "https://arxiv.org/abs/2501.05007", "title": "量子增强的小样本因果发现方法", "title_en": "Quantum-enhanced causal discovery for a small number of samples", "authors": "Yu Terada,Ken Arai,Yu Tanaka,Yota Maeda,Hiroshi Ueno,Hiroyuki Tezuka", "background": "从观测数据中发现因果关系在经济学、社会科学和生物学等领域引起了广泛关注。然而，在实际应用中，通常对底层系统缺乏充分了解，且真实数据往往与非线性因果结构相关联，这使得大多数传统的因果分析方法难以直接使用。", "innovation": "本文提出了一种新的量子彼得-克拉克(qPC)算法，该算法不需要对底层模型结构做出任何假设。基于由量子电路定义的再生核希尔伯特空间中的条件独立性检验，该算法可以从任意分布的观测数据中探索因果关系。此外，本文提出了一种基于核目标对齐(KTA)的新优化方法来确定量子核的超参数，有效降低了因果发现中的假阳性风险，增强了因果关系推断的可靠性。", "conclusion": "理论和实验结果表明，量子算法能够增强经典算法在因果发现中的准确推理能力，尤其是在小样本情况下，弥补了经典算法的不足。此外，通过在波士顿房价、心脏病和生物信号系统数据集上的实际应用验证了此方法的有效性。这些发现突显了基于量子的因果发现方法在解决实际问题（尤其是小样本情况下的问题）方面的潜力，克服了传统方法在这些领域的局限性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.10435", "html_url": "https://arxiv.org/abs/2412.10435", "title": "COEF-VQ：通过级联多模态LLM框架实现高效视频质量理解", "title_en": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework", "authors": "Xin Dong,Sen Jia,Ming Rui Wang,Yan Li,Zhenheng Yang,Bingfeng Deng,Hongyu Xiong", "background": "近年来，多模态大语言模型（MLLM）技术的出现使得利用其在不同分类任务上的视频理解能力成为可能。然而，在线部署这些模型时面临巨大的GPU资源需求，因此我们提出COEF-VQ，一个级联的MLLM框架，旨在提升短视频平台上的视频质量理解能力并优化计算效率。该框架通过引入基于熵的预筛选阶段，利用轻量级模型评估不确定性并选择性地过滤内容，仅将高度不确定的样本送至更为计算密集型的MLLM进行最终评估。", "innovation": "该框架通过优先分析高度不确定的样本显著降低了GPU使用率，同时保持了与完整MLLM部署同等的分类性能。通过整合自定义任务和平台上视频管理系统（VMP）的实验展示了COEF-VQ在降低时间成本方面带来的实质性能改进，减少了9.9％的不适当内容视频观看率，而不影响用户体验，后发布的监控也证实了其实战效用和持续改进。", "conclusion": "COEF-VQ在两个自定义任务中的离线评估中取得了显著的性能提升，并经在线A/B测试证明有效提升了平台安全，以极为有限的资源消耗显著减少了不适当内容的观看率，验证了其在真实场景中的实际影响。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01391", "html_url": "https://arxiv.org/abs/2502.01391", "title": "从生成模型学习实时观察中的交通异常", "title_en": "Learning Traffic Anomalies from Generative Models on Real-Time Observations", "authors": "Fotis I. Giasemis,Alexandros Sopasakis", "background": "准确检测交通异常对于有效的城市交通管理和缓解交通拥堵至关重要。本文使用结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，以捕捉交通数据中的复杂空间和时间依赖关系。研究在瑞典哥德堡的42个交通摄像头收集到的几个月的实时分钟级观察数据上进行，旨在有效检测交通异常并降低误报率。", "innovation": "本文创新性地提出了一个结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，用于识别和检测交通异常，能够有效地检测摄像头信号中断、视觉伪影以及极端天气条件对交通流量的影响，性能优越且具有高精度和低误报率。", "conclusion": "本文结果显示，所提出的STGAN模型能够有效地检测交通异常，并具有高精度及低误报率。该模型的成功实验证明了利用生成对抗网络框架可以在实际交通管理中发挥重要作用，特别是在实时监控和异常检测方面。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04700", "html_url": "https://arxiv.org/abs/2502.04700", "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference", "title_en": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference", "authors": "Prakhar Kaushik,Ankit Vaidya,Shravan Chaudhari,Alan Yuille", "background": "大模型的快速增长引发了对其环境影响和访问公平性的担忧，因为它们需要大量的计算资源。虽然 Low-Rank Adapters (LoRA) 提供了一种轻量级的微调解决方案，但尚不确定这些预训练的适配器是否能够进一步简化新任务的适应过程，同时解决这些挑战。得益于大量公开的、针对不同领域的适配器资源，初步探索这些适配器的应用成为了关键问题。", "innovation": "EigenLoRAx 是一种参数高效的方法，通过回收现有适配器并创建与其共享领域知识对齐的主要子空间，进一步简化新任务的适应，同时在资源稀缺的情况下可以通过正交基向量进行扩展。这种方法仅通过学习主要子空间的轻量级系数来快速适应新任务，从而避免对整个适配器进行微调，显著减少了所需的参数和内存，提高了训练和推理的效率。", "conclusion": "EigenLoRAx 方法在多种领域和任务上表现出强大的性能，为基于边缘的应用、个性化和资源受限环境下大型模型的公平部署提供了可扩展的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.08496", "html_url": "https://arxiv.org/abs/2501.08496", "title": "量化下游模型性能中数据对齐的重要性", "title_en": "Quantifying the Importance of Data Alignment in Downstream Model Performance", "authors": "Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo", "background": "传统的大型语言模型（LLMs）训练通常集中在数据集的大小上，而忽略了数据对齐这一数据质量的重要方面。本文通过Task2Vec基的数据对齐系数量化了训练数据与评估数据对齐程度对下游性能的影响，从而探讨了数据对齐在LLMs训练中的作用，指出在特定下游任务如Autoformalization（自然语言和代码之间的形式验证机器翻译任务）中，数据对齐相较于数据量更为重要。", "innovation": "本文利用了Task2Vec基的数据对齐系数，这是一种评估两个数据集之间相似度的定量指标。研究了在多种预训练（pt）数据集与评估数据集之间以及领域特定微调（ft）数据集与领域特定评估之间的对齐程度对下游任务表现的影响，发现数据对齐的提高会显著降低模型在下游任务上的损失和困惑度（perplexity）", "conclusion": "研究结果表明，数据对齐对于LLMs的训练至关重要，特别是在特殊下游任务中（如Autoformalization），数据对齐的影响比数据量更为显著，提示重新评估LLMs的训练方法，以更好地利用数据对齐的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12370", "html_url": "https://arxiv.org/abs/2501.12370", "title": "参数 vs FLOPs：稀疏性优化的混合专家语言模型的缩放定律", "title_en": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models", "authors": "Samira Abnar,Harshay Shah,Dan Busbridge,Alaaeldin Mohamed Elnouby Ali,Josh Susskind,Vimal Thilak", "background": "语言模型的容量扩展已被证实是一种提升性能并解锁新能力的有效方法。容量可以通过模型参数的数量和每例计算量两个维度来定义。通常情况下，扩展包括增加这两方面的量，但这些因素之间的确切相互作用以及它们对整体容量的共同贡献尚未完全了解。文章探讨了在稀疏混合专家模型（MoEs）的背景下，参数数量和每例计算量之间的关系，考虑到参数量和总训练计算量的不同限制，发现了最佳稀疏度水平可以同时提高训练效率和模型性能。", "innovation": "研究了在不同的限制条件下（如参数量和总训练计算量），不同稀疏度水平对混合专家模型性能的影响，并发现在这些限制下存在一种优化的稀疏度水平，既能提高训练效率又能提升模型性能。这些结果为理解稀疏性在MoEs缩放定律中的影响提供了新的见解，并补充了现有研究工作，为设计更加高效的架构提供了指导。", "conclusion": "本文的研究结果对理解MoEs中的稀疏性缩放定律产生了更深入的理解，优化了MoEs架构的设计，并为未来的相关研究提供了新的见解。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.17168", "html_url": "https://arxiv.org/abs/2501.17168", "title": "在树形遗传编程中实现群体级并行处理，以实现全面的GPU加速", "title_en": "Enabling Population-Level Parallelism in Tree-Based Genetic Programming for Comprehensive GPU Acceleration", "authors": "Zhihong Wu,Lishuang Wang,Kebin Sun,Zhuozhao Li,Ran Cheng", "background": "树形遗传编程（TGP）是一种广泛应用的进化算法，适用于符号回归、分类和机器人控制等任务。由于TGP运行的高度计算需求，GPU加速对于实现可扩展的性能至关重要。然而，高效地在GPU上执行TGP仍然具有挑战性，主要由于三个方面的问题：（1）程序个体的结构异质性，（2）多层并行性的复杂集成，以及（3）高性能CUDA执行与灵活的Python环境之间的不兼容性。", "innovation": "为了解决这些问题，本文提出了EvoGP，这是一个高性能框架，旨在通过种群级别并行执行全面加速TGP的GPU化。EvoGP引入了一种张量表示法，将大小可变的树编码为固定形状的记忆对齐数组，从而实现均匀访存和跨个体并行计算。此外，EvoGP采用了一种自适应并行策略，根据数据集大小动态结合个体间的并行和个体内的并行，确保广泛的任务中高GPU利用率。最后，EvoGP将自定义CUDA内核嵌入PyTorch运行时，实现与Gym、MuJoCo、Brax和Genesis等基于Python的环境的无缝集成。", "conclusion": "全面的实验表明，EvoGP相比现有的基于GPU的TGP实现，最多可加速140倍，同时保持竞争力的准确率，并在大型种群规模下显著提高可扩展性。EvoGP是一个开源框架，可从this https URL访问。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.00863", "html_url": "https://arxiv.org/abs/2411.00863", "title": "在证明生成中，下一个令牌预测任务假定LLM训练数据的最优排序", "title_en": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation", "authors": "Chenyang An,Shima Imani,Feng Yao,Chengyu Dong,Ali Abbasi,Harsh Shrivastava,Samuel Buss,Jingbo Shang,Gayathri Mahalingam,Pramod Sharma,Maurice Diesendruck", "background": "在基于大型语言模型（LLM）的证明生成领域，尽管利用了诸如ArXiv等大规模数据集进行广泛训练，LLM在处理中等难度证明任务时的表现仍较为平庸。这主要归因于训练数据中普遍存在的次优排序问题，例如，已公布的证明常常遵循纯逻辑顺序，每一步都基于演绎规则逻辑地从上一步骤发展过来，这种顺序主要旨在便于验证证明的有效性，而非帮助人们或模型学习证明发现过程。我们提出，对于每个训练数据样本，证明的最优排序应确保每个步骤所需的中间监督信息总是位于该步骤的左侧，我们称之为直觉顺序。通过两个任务——直觉命题逻辑定理证明和数字乘法——验证了这一假设，并验证了排序效果及其对模型性能的影响。我们发现，证明按照最优排序进行训练时效果最佳。无论是定理证明任务还是在不同数据排序下训练的模型之间都存在显著差异，最优排序相比最差排序，在命题逻辑定理证明任务中的证明成功率提升了11%。此外，我们还定义了一种高级数学证明中常见的排序问题，发现广泛使用的研究生级数学教材前两章中17.3%的非平凡定理出现此类问题，详细列表见附录。", "innovation": "提出了直觉顺序的概念，认为对于每个训练数据样本，证明的最优排序应确保每个步骤所需的中间监督信息总是位于该步骤的左侧。通过两个具体任务的研究，验证了这一排序策略的有效性，并且证明了在最优排序下训练的模型表现最好，模型间的性能差距也较为显著。此外，还定义并指出了高级数学证明中常见的排序问题，为理解和改进LLM在证明生成中的表现提供了新的视角。", "conclusion": "证明按照最优排序进行训练效果最佳，而普通逻辑排序会影响模型的性能，尤其在定理证明任务中表现明显。定义了高级数学证明中特定类型的排序问题，并指出解决这些问题可以显著改善模型的证明生成能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06106", "html_url": "https://arxiv.org/abs/2502.06106", "title": "电路微调：一种用于识别参数冗余和神经网络微调的机制方法", "title_en": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks", "authors": "Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang", "background": "机制可解释性研究旨在反向工程一个模型以解释其行为。尽管最近的研究主要集中于特定行为的静态机制，但模型内部的训练动态尚未得到充分探索。本文旨在开发一种可解释的微调方法来分析学习背后的机制。通过引入节点级内在维度概念，首次在计算图中描述模型的学习过程。基于这一理论，提出了电路微调算法，这是一种分两阶段迭代构建特定任务所需子图并在启发式方式下更新关键参数的方法。实验结果证实了节点级内在维度的存在，并展示了该方法在透明和可解释性微调方面的有效性。我们还通过可视化和分析微调前后电路，提供有关神经网络在学习过程中自我组织机制的新见解。", "innovation": "本文提出了一种名为电路微调的可解释微调方法。首先，通过引入节点级内在维度的概念来描述模型在计算图中的学习过程。其次，基于这一理论提出了电路微调算法，实现了最小化子图的迭代构建，并通过启发式更新关键参数。最后，实验验证了该方法的有效性，并且通过可视化展示了微调前后电路的变化，提供了关于神经网络自我组织机制的新见解。", "conclusion": "本研究的结果证实了节点级内在维度的存在，并展示了电路微调方法在透明和可解释性微调中的有效性。我们通过可视化和分析微调前后电路，提供新的见解，深入理解了神经网络在学习过程中的自我组织机制。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.13450", "html_url": "https://arxiv.org/abs/2502.13450", "title": "交错吉布斯扩散：生成具有隐式约束的离散-连续数据", "title_en": "Interleaved Gibbs Diffusion: Generating Discrete-Continuous Data with Implicit Constraints", "authors": "Gautham Govind Anil,Sachin Yadav,Dheeraj Nagaraj,Karthikeyan Shanmugam,Prateek Jain", "background": "大多数关于离散和离散-连续扩散的研究假设去噪分布是因子化的，这可能会阻碍在这些问题中对随机变量之间强依赖关系的建模。该论文介绍了一种新的生成模型框架——交错吉布斯扩散（IGD），专门针对数据中存在的重要的、隐含的未指明的约束问题。IGD通过不假设去噪的因子化，证明了在3-SAT问题上具有显著的性能改进。此外，它还适用于三种挑战性的生成任务，分别是分子结构、布局和表格数据，并展示了最先进的性能。", "innovation": "IGD通过提供无缝集成的离散和连续去噪器，并允许通过状态空间加倍进行条件生成和推理时间细化，实现了显著的性能提升。IGD还保证了一个合适的前置过程的理论可逆性，而不需要依赖于特定领域的归纳偏见，如对称扩散或辅助损失。论文还探索了广泛的建模和交错策略，以及在这些问题中的超参数选择方法。", "conclusion": "IGD展示了在无条件依赖特定领域归纳偏见的情况下，生成离散-连续数据的先进性能。在三个具有挑战性的生成任务上，其性能可以达到最先进的水平，同时提供灵活的选择去噪器和提高推理时间的精细度。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17046", "html_url": "https://arxiv.org/abs/2503.17046", "title": "HAPI: 一种从人类偏好学习机器人面部表情的模型", "title_en": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences", "authors": "Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida", "background": "自动化机器人面部表情生成对于人类-机器人交互至关重要，但基于固定关节配置的手工方法往往会产生僵硬和不自然的行为。尽管最近的自动化技术减少了手动调整的需要，但它们往往无法充分弥补人类偏好与模型预测之间的差距，导致由于自由度有限和感知集成不足而无法产生细腻且真实的表情。", "innovation": "本文提出了一种新颖的学习排序框架，该框架利用人类反馈来解决这一差距，并增强机器人的面部表情表达能力。具体而言，通过成对比较注释收集人类偏好数据，并开发了基于Siamese RankNet的人工智能情感成队印象（HAPI）模型，以改进表情评估。通过贝叶斯优化和在线表情调查结果表明，该方法生成的愤怒、快乐和惊讶表情比基线和专家设计方法更真实且具有社会共鸣。", "conclusion": "这种方法证实了框架有效地将人类偏好与模型预测之间的差距进行桥接，同时稳健地将机器人表情生成与人类情感响应对齐。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04564", "html_url": "https://arxiv.org/abs/2503.04564", "title": "与循环用户关联相关的分层安全聚合的基本限制", "title_en": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association", "authors": "Xiang Zhang,Zhou Li,Kai Wan,Hua Sun,Mingyue Ji,Giuseppe Caire", "background": "该研究基于联邦学习（FL）中的安全聚合需求，其中，云服务器旨在计算众多客户端本地训练模型的平均模型（即深度神经网络的权重），同时应满足数据安全要求。现有的研究扩展了这一概念，提出了分层安全聚合（HSA），在三层分层网络中，集群用户通过中间层的中继与服务器通信。在HSA中，除了服务器安全之外，还强制执行中继安全性，以确保中继不会了解到用户的输入（联邦学习中本地模型的抽象）。现有的HSA研究假设每个用户只与一个中继相关联，从而限制了跨集群用户进行编译以实现高效通信和密钥生成的机会。", "innovation": "本文考虑了与循环关联模式相关的HSA，其中每个用户以环形方式连接到B个连续中继。提出了一种高效的聚合方案，包括受梯度编码启发的消息设计——这是分布式计算中高效通信的一种广泛使用的技术，以及一种高度非平凡的安全密钥设计。此外，还使用信息论论证推导出了最小可实现通信速率和密钥速率的新奇上界。", "conclusion": "本文通过分析循环用户关联模式下的HSA，提出了新的高效聚合方案，实现更高的通信和密钥生成效率，并通过信息论论证获得了新的通信和密钥速率的上界。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.05802", "html_url": "https://arxiv.org/abs/2503.05802", "title": "使用Wasserstein距离方法进行照明源和光方向估计", "title_en": "Illuminant and light direction estimation using Wasserstein distance method", "authors": "Selcuk Yazar", "background": "在图像处理领域，特别是在机器人技术中，光照估计仍然是一个关键挑战。可靠的环境感知需要在不同光照条件下保持稳定。传统方法，如RGB直方图和GIST描述符，在复杂光照条件下由于对光照变化的敏感性往往失效。这项研究旨在研究一种新的基于Wasserstein距离的方法，这是最优传输理论的基础，用于室内场景、黑白照片和夜景图像的光照源和光方向估计，以改进在复杂光照环境中的效果，克服传统统计方法的限制。", "innovation": "该研究提出了一种基于Wasserstein距离的新方法，利用最优传输理论估计图像中的照明源和光方向。实验结果表明，该方法在复杂光照环境中的效果优于传统的统计方法，能够检测主导光源并估计其方向。这种方法在光源定位、图像质量评估和物体检测增强方面显示出应用潜力。未来的研究可能探索自适应阈值设置及梯度分析，以进一步提高准确性，为机器人乃至其他领域提供光照挑战的可扩展解决方案。", "conclusion": "实验结果表明，该方法在光照估计方面具有显著优势，尤其是在复杂光照环境中。它为轻源定位、图像质量评估和物体检测增强提供了强有力的工具，并展望了未来工作，将自适应阈值设置与梯度分析相结合，以进一步提升准确性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03935", "html_url": "https://arxiv.org/abs/2503.03935", "title": "基于大型语言模型的血糖预测及从穿戴设备和饮食中发现行为治疗路径", "title_en": "LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet", "authors": "Abdullah Mamun,Asiful Arefeen,Susan B. Racette,Dorothy D. Sears,Corrie M. Whisner,Matthew P. Buman,Hassan Ghasemzadeh", "background": "餐后高血糖水平超过正常范围是预测2型糖尿病进展的关键指标，尤其是在糖尿病前期和健康个体中。餐后血糖动态的重要度量是餐后曲线下面积（AUC）。基于个人的生活方式因素（如饮食和体力活动水平）预测餐后AUC并在餐后血糖水平异常时进行调整，可以帮助个人维持正常的血糖水平。已有研究致力于开发可解释的机器学习解决方案，以预测餐后AUC并解释餐后血糖水平变化的因素，然而依然缺乏将穿戴设备数据和饮食日志与机器学习模型结合，提供可解释的餐后血糖预测模型的研究成果。本文研究通过收集穿戴设备数据和饮食日志，开发了一种可解释的机器学习解决方案，GlucoLens，以预测餐后AUC和高血糖，进而改善血糖控制和预防高血糖的发生。", "innovation": "本文创新性地通过穿戴设备数据和饮食日志开发了一种解释性强的机器学习模型GlucoLens，能用于预测餐后AUC及餐后高血糖，同时结合大语言模型进行解释。研究采用了五周的临床研究数据，验证了模型的有效性，并对比了现有模型的性能。模型不仅预测餐后高血糖具有73.3%的准确率和F1分数为0.716，还要提供了多种治疗干预建议以避免高血糖。模型的最优配置达到了NRMSE 0.123，比现有模型平均性能提高了16%。", "conclusion": "通过GlucoLens系统，研究人员能够准确预测餐后高血糖，并为个体提供了可解释的治疗建议，帮助个体更好地调整生活方式以维持正常的血糖水平。这种基于穿戴设备和饮食日志的机器学习方法为个性化医疗提供了新的视角和工具。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.07813", "html_url": "https://arxiv.org/abs/2503.07813", "title": "MaizeField3D: 一个从多样基因组群体采集的田间种植玉米的3D点云和过程模型数据集", "title_en": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel", "authors": "Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian", "background": "由于缺乏大量多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具在玉米等作物上的发展受到了限制。2D图像数据集未能捕捉到诸如叶构型、植物体积和空间排列等重要结构细节，这些细节只有3D数据才能提供。因此，开发了一个全面的基础数据集，以推进农业研究中的AI驱动表型分析、植物结构分析和3D应用。", "innovation": "该研究提出了MaizeField3D，这是一个由一个多样化遗传面板的田间种植玉米植物的3D点云组成的数据集，经过精心设计，便于AI使用。通过地面激光扫描仪（TLS）收集了1,045个高质量的3D点云，并使用基于图的分割方法分割和注释了其中520个植物，以确保所有样本的一致标签。数据被用于拟合进程模型，提供玉米植物的结构参数化表示。叶片被表示为使用无均匀比例B样条曲面（NURBS表面），结合无导数和基于导数的方法进行优化生成。所有数据集经过严格的手动质量控制，确保了分割的准确性、正确的叶片顺序验证和元数据注释的验证。该数据集包括详细的植物形态和质量元数据，以及多分辨率子采样的点云数据（100k，50k，10k点），这些数据可以轻松用于不同的后续计算任务。", "conclusion": "MaizeField3D将成为AI驱动的表型分析、植物结构分析和农业研究中3D应用的全面基础数据集。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17089", "html_url": "https://arxiv.org/abs/2503.17089", "title": "理解导向的公平心脏磁共振分割偏差缓解方法", "title_en": "Understanding-informed Bias Mitigation for Fair CMR Segmentation", "authors": "Tiarna Lee,Esther Puyol-Antón,Bram Ruijsink,Pier-Giorgio Masci,Louise Keehn,Phil Chowienczyk,Emily Haseler,Miaojing Shi,Andrew P. King", "background": "人工智能在医学成像任务中的应用越来越广泛，但AI模型在训练时可能会因为不平衡的训练数据集而存在偏差，特别是在心脏磁共振（CMR）图像分割模型中，观察到了显著的种族偏差。已有研究记录了这种现象，但关于如何有效缓解这种偏差的方法仍知之甚少。", "innovation": "研究引入了一种理解导向的策略，通过常见的偏差缓解方法（如过采样、重要性重加权和Group DRO）及这些方法的组合，对AI心脏磁共振分割模型中的种族偏差进行了缓解。进一步地，研究基于最近发现的偏差根源，评估了在裁剪后CMR图像上进行训练和评估的模型，发现使用过采样可有效缓解偏差，提高少数族裔的性能，同时不影响主流族裔的性能。裁剪图像可以提升两种族裔的性能，减少偏差，且结合裁剪图像和过采样可进一步降低偏差。在外部临床验证集上的测试表明，模型具有高分割性能且无显著偏差.", "conclusion": "通过理解心脏磁共振分割模型的偏差来源，过采样、重要性重加权和Group DRO方法可以有效缓解种族偏差，提升少数族裔的分割性能，在裁剪图像数据集上的效果更加显著。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06684", "html_url": "https://arxiv.org/abs/2502.06684", "title": "EquiTabPFN: 目标置换对称先验网络", "title_en": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks", "authors": "Michael Arbel,David Salinas,Frank Hutter", "background": "近年来，针对表格数据的基础模型，如 TabPFN，在基于上下文的学习中表现出色，但依然受限于固定的预定义目标维度数。当需要扩展目标维度数目时，会导致成本高昂的组合策略。这一约束问题的根本在于模型缺乏目标置换不变性，即目标维度顺序调整会改变预测结果。这种缺陷引起了一个不可约简的“对称性缺口”，成为预测不稳定性的重要因素。该论文解决了这一问题，设计了一个全目标对称性架构，确保通过置换不变编码器、解码器和双注意机制来实现置换不变性。在标准分类基准测试上，论文研究表明，对于训练数据中没有的更多类别数据集，该模型能够匹配或超越现有方法，同时具有较低的计算开销。", "innovation": "该论文设计了一个全目标置换对称（target-equivariant）架构，通过基于对称的编码器、解码器和双注意机制确保了置换不变性。这一创新解决了现有模型在目标维度扩展时的不可约简“对称性缺口”问题，提高了模型的稳定性，并在计算成本上提供了优势。", "conclusion": "在标准分类基准测试上，该模型在具有更多分类类别的数据集上，能够匹配或超越现有方法，同时具有较低的计算成本。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18681", "html_url": "https://arxiv.org/abs/2503.18681", "title": "Commander-GPT: 全面释放多模态大语言模型的讽刺检测能力", "title_en": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models", "authors": "Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin", "background": "讽刺检测作为自然语言处理(NLP)领域的重要研究方向，近年来受到了广泛的关注。传统的讽刺检测方法主要集中在单一数据模态（例如文本）上，但由于讽刺具有隐含性和微妙性，这些方法往往不能取得令人满意的结果。近年来，研究者们将讽刺检测的重点转向了多模态方法。然而，如何有效利用多模态信息准确识别讽刺内容仍旧是一个亟待解决的问题。针对上述问题，本文通过利用多模态大型语言模型（MLLMs）的多种信息源处理能力，提出了一种创新的多模态Commander-GPT框架。", "innovation": "本文通过引入多模态大型语言模型（MLLMs）的集成处理能力，开发了一种名为Commander-GPT的创新框架。该框架借鉴军事策略，将讽刺检测任务分解为六个子任务，并通过一个核心指挥官（决策者）将最合适的大语言模型分配给每个特定子任务，从而最终整合检测结果以识别讽刺。此外，本文还利用四种多模态大型语言模型和六种提示策略进行了广泛实验，实验结果表明，该方法在F1分数上取得了显著改善（19.3%），并未采用微调和参考答案的理据化方法。", "conclusion": "本文通过开发基于多模态大语言模型的Commander-GPT框架，成功实现了讽刺检测性能的提升，并通过实验验证了其有效性。这种方法对讽刺检测领域的发展具有重要意义。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12552", "html_url": "https://arxiv.org/abs/2504.12552", "title": "使用数字孪生实现的保护隐私的手术室工作流分析", "title_en": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins", "authors": "Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath", "background": "手术室是一个复杂的环境，优化工作流程对于降低成本和改善患者疗效至关重要。虽然计算机视觉方法可以自动识别术前术后事件以帮助手术室优化，但隐私问题限制了手术视频在自动化事件检测中的使用。", "innovation": "本文提出了一种双重管道，通过深度估计和语义分割生成手术室的匿名数字孪生(DT)，并采用SafeOR模型进行事件检测。这种方法不仅能够保持隐私，还能够在不降低性能的情况下使用脱敏数据，增强模型的一般化能力，减少领域特定外观差异的影响。", "conclusion": "使用数字孪生的两阶段方法在38个模拟手术试验中实现了与原始RGB视频模型相当甚至更好的术中事件检测性能。数字孪生促使手术室工作流程分析在机构间共享脱敏数据，从而提升模型的泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.21843", "html_url": "https://arxiv.org/abs/2503.21843", "title": "CMD-HAR: 跨模态解纠缠的可穿戴人体活动识别", "title_en": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition", "authors": "Hanyu Liu,Siyao Li,Ying Yu,Yixuan Jiang,Hang Xiao,Jingxi Long,Haotian Tang,Chao Li", "background": "人体活动识别（HAR）是众多以人为中心的智能应用的基础技术。尽管深度学习方法被用来加速特征提取，但多模态数据混杂、活动异质性和复杂模型部署等问题依然未能得到有效解决。为此，本文旨在解决基于传感器的人体活动识别中多模态数据混杂、活动异质性以及复杂模型部署的问题。由此背景出发，本文提出了一种时空注意力模态分解对齐融合策略来解决传感器数据混杂分布的问题。通过跨模态的时空解纠缠表示获取活动的关键辨别特征，结合梯度调制以缓解数据异质性问题。此外，还构建了一个可穿戴设备部署模拟系统，进行了大量公开数据集上的实验，证明了该模型的有效性。", "innovation": "提出了一种跨模态解纠缠的方法应用于人体活动识别，通过时空注意力模态分解对齐融合策略解决多模态数据混杂问题，利用跨模态时空解纠缠表示获取活动的关键辨别特征，并结合梯度调制以缓解数据异质性，构建了一个可穿戴设备部署模拟系统，展示了该模型在大量公开数据集上的有效性。", "conclusion": "本文提出了一种新的跨模态解纠缠的时空注意力模态分解对齐融合策略，应用于基于传感器的人体活动识别。该方法提高了活动识别的准确性，并有效解决了多模态数据混杂、活动异质性和模型部署复杂性的问题，实验结果表明该方法在多个数据集上具有良好的性能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12971", "html_url": "https://arxiv.org/abs/2504.12971", "title": "在具有表达性的神经架构搜索空间中的可迁移替代模型", "title_en": "Transferrable Surrogates in Expressive Neural Architecture Search Spaces", "authors": "Shiwen Qin,Gabriela Kadlecová,Martin Pilát,Shay B. Cohen,Roman Neruda,Elliot J. Crowley,Jovita Lukasik,Linus Ericsson", "background": "神经架构搜索（NAS）面临在探索具有广泛搜索空间的架构创新的同时，高效评估这些架构之间的平衡挑战。研究者们试图通过训练代理模型来改善在高度可表达的NAS搜索空间中的搜索过程，基于上下文无关文法（CFG）。通过这种方法，代理模型能够预测架构在不同数据集中的性能，并用于滤除性能不佳的架构，从而加速搜索过程并提高最终性能。", "innovation": "该研究提出了一种基于上下文无关文法的代理模型训练方案，训练该代理模型可以通过零成本代理指标和神经图特征（GRAF）或微调现成的语言模型。这些代理模型能够在不同数据集内部和跨数据集对未来架构性能进行高度预测。它们不仅可以用于过滤掉性能不佳的架构，还能直接作为搜索目标以获得巨大的速度提升，从而显著加快搜索过程并获得更好的最终性能。", "conclusion": "研究揭示了在高度表达性的NAS搜索空间中，通过训练相应的代理模型，可以显著提高搜索效率并实现更好的架构性能。代理模型可以作为搜索目标使用，进一步加速搜索过程。这些代理模型在新数据集上对性能不佳的架构进行了有效滤除，从而不仅加快了搜索，而且也改善了最终的性能表现。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.19136", "html_url": "https://arxiv.org/abs/2504.19136", "title": "PAD: 频率感知的相位-振幅解耦融合在多模态土地覆盖分类中的应用", "title_en": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification", "authors": "Huiling Zheng,Xian Zhong,Bin Liu,Yi Xiao,Bihan Wen,Xiaofeng Li", "background": "基于合成孔径雷达(SAR)和RGB图像的土地覆盖分类因其模态异质性和未充分利用的光谱互补性而颇具挑战性。现有方法往往难以分离共享结构特征与模态互补的辐射度属性，导致特征冲突和信息损失。", "innovation": "提出了一种频率感知框架——相位-振幅解耦(PAD)，该方法在傅里叶域中分离相位(模态共享)和振幅(模态互补)成分，强化了共享结构并保留了互补特性，从而提高融合质量。PAD首次明确地在多模态融合中引入了振幅-相位解耦，具体包括相位频谱校正(PSC)和振幅频谱融合(ASF)两部分。", "conclusion": "在WHU-OPT-SAR和DDHR-SK数据集上的广泛实验表明，PAD方法在多模态土地覆盖分类中达到了最先进的性能。我们的工作为遥感中的物理感知多模态融合建立了新的范式。代码将在该链接 http://this.is/sample 可用。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.20808", "html_url": "https://arxiv.org/abs/2504.20808", "title": "SoccerDiffusion：从游戏录像学习端到端的人形机器人足球", "title_en": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings", "authors": "Florian Vahl,Jörn Griepenburg,Jan Gutsche,Jasper Güldenstein,Jianwei Zhang", "background": "本文介绍了SoccerDiffusion，一种基于变换器的扩散模型，旨在直接从实际比赛录像中学习人形机器人足球的端到端控制策略。使用从RoboCup比赛收集的数据，该模型预测来自多模态传感器输入（包括视觉、本体感知和比赛状态）的关节命令轨迹。该研究通过降维技术在嵌入式平台上实现了实时推理，将多步扩散过程简化为单一步骤。研究结果表明模型能够模拟复杂的运动行为，如行走、踢球和跌倒恢复，既在模拟中也实际应用到物理机器人上。尽管高级战术行为仍然有限，但这项工作为后续的强化学习或偏好优化方法提供了坚实的基础。", "innovation": "本文的主要创新点在于提出了SoccerDiffusion模型，该模型能够直接从真实的足球比赛录像中学习人形机器人足球的控制策略。特别地，该模型使用变换器网络来预测机器人从复杂多模态传感器输入（包括视觉、本体感知和比赛状态）到输出关节命令的多步扩散过程。通过采用一种蒸馏技术，该模型能够在嵌入式设备上实现实时推理，有效简化了多步扩散过程为单步推理。", "conclusion": "本文的结果表明，所提出的SoccerDiffusion模型能够实现复杂的运动行为模仿，包括步行、踢球和跌倒恢复，从而在模拟器和物理机器人上均展示了良好的性能。虽然高级战术行为仍然有限，但这项研究为后续通过强化学习或偏好优化的方法应用于人形机器人足球控制奠定了坚实的基础，此外，提供了包含数据集、预训练模型和代码的开源资源。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12215", "html_url": "https://arxiv.org/abs/2504.12215", "title": "以不确定性为导向的从粗到细的肿瘤分割与解剖结构感知后处理", "title_en": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing", "authors": "Ilkin Sevgi Isler,David Mohaisen,Curtis Lisle,Damla Turgut,Ulas Bagci", "background": "在胸部计算机断层扫描(CT)中准确分割肿瘤仍然具有挑战性，原因包括边界模糊、类别不平衡和解剖变异。现有方法难以解决这些问题，在不确定性区域对肿瘤区域的分割准确性较差，导致边界标注不准确，尤其是当肿瘤与周围组织边界模糊时。为了应对上述挑战，本研究提出了一种基于不确定性指导、从粗到细的肿瘤分割框架，该框架结合了全卷积肿瘤定位与精细的感兴趣区域(ROI)分割，通过解剖学感知后处理增强。", "innovation": "该研究创新点在于提出了一种新的肿瘤分割框架，该框架通过两个阶段进行：第一阶段利用全卷积模型生成粗略预测；第二阶段利用解剖学感知后处理方法和具有不确定性感知损失函数的模型进行细化分割。这种方法能有效提高在不明确区域下的分割准确性与边界校准，特别是在处理肿瘤与周围组织边界模糊时表现优异。通过实验证明了这种方法的有效性，与现有方法相比，能显著提高医疗数据集的Dice和Hausdorff分数，并减少假阳性结果，增强空间可解释性。", "conclusion": "研究结果表明，结合不确定性建模和解剖学先验知识的级联分割管道对于肿瘤分割具有重要意义，能够在多个数据集上实现稳健且临床相关的肿瘤定义。相较于传统的Swin UNETR模型，该框架在Orlando数据集上的Dice分数从0.4690提升到了0.6447，降低错误组件数量显著提高了分割效果，验证了解剖学指导的后处理的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21880", "html_url": "https://arxiv.org/abs/2505.21880", "title": "整合大语言模型进行大规模城市复杂交通模拟", "title_en": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation", "authors": "Yu-Lun Song,Chung-En Tsern,Che-Cheng Wu,Yu-Ming Chang,Syuan-Bo Huang,Wei-Chu Chen,Michael Chia-Liang Lin,Yu-Ta Lin", "background": "传统的基于规则的基于代理模型（ABM）在城市交通模拟中存在着一定的局限性，无法充分反映人群的多样性和复杂性。因此，本研究提出了将大型语言模型（LLM）与ABM整合的新方法，以提高模拟的真实性和多样性。", "innovation": "本研究通过利用LLM生成合成的人口特征，分配日常和偶然的地点，并模拟个性化路径，实现了对个体行为和大规模城市交通模式的模拟。这种方法避免了传统基于规则的ABM的局限性，能够提供更加丰富和真实的交通模拟结果，为政策制定提供有力支持和数据依据。", "conclusion": "研究后果显示，新的框架能够生成丰富的出行路径热图和模式特定指标，为城市规划者提供了实用的信息。未来的工作将集中在建立健壮的验证框架，以确保在城市规划应用中的准确性和可靠性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15325", "html_url": "https://arxiv.org/abs/2504.15325", "title": "显著性指数对标记一致性值的评价", "title_en": "Significativity Indices for Agreement Values", "authors": "Alberto Casagrande,Francesco Fabris,Rossano Girometti,Roberto Pagliarini", "background": "一致性度量，例如科恩κ系数或内皮系数，用来评估两个或多个分类器之间的匹配度。它们在众多领域被广泛应用：在医学领域，它们可以评估医疗治疗和临床试验的有效性；在人工智能领域，它们可用于量化由于减少分类器而导致的匹配程度偏差。不同分类器与基准标椎的一致性可以通过它们相对于基准的排序来进行比较。然而，单独依据一致性度量的结果来评价一个方法的好坏需要一个评判尺度或者显著性指标。尽管已有一些文献提出判定科恩κ系数的评判标准，但大多数标准都很简单，并且它们的边界通常是任意划定的，缺乏科学依据。本文提出了一种通用方法来评价任何一个分类器之间一致性的显著性，并引入了两个显著性指标：一个适用于有限数据集，另一个处理分类概率分布。此外，本文还解决了评估这些指标的计算挑战，并提出了一些高效的算法来实施这些评估方法。", "innovation": "1. 提出了一种通用方法来评估任意两个分类器之间一致性值的显著性。\n2. 引入了两个显著性指数：适用于有限数据集的指数和适用于分类概率分布的指数。\n3. 提出了高效的算法来解决评估这些指数的问题。", "conclusion": "本文通过引入新的显著性指数，提供了一种科学的方法来评价不同分类器之间的一致性值，并解决了评估过程中的计算难题。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨语言旅行：评估多模态大语言模型的跨语言一致性", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "多模态大语言模型（MLLMs）的快速发展极大地提升了其实际应用能力。然而，特别是在整合文化知识时，实现跨语言一致性的表现仍然是一项重大挑战。为了更好地评估这一问题，作者引入了两个新基准：KnowRecall和VisRecall，用于测评MLLMs的跨语言一致性。KnowRecall是一个视觉问答基准，旨在衡量15种语言中的事实知识一致性，特别是关于全球地标的文化和历史问题。VisRecall则通过要求模型在没有图像的情况下描述9种语言中的地标外观，评估视觉记忆的一致性。实验结果显示，当前最先进的MLLMs，包括专有模型，仍然难以实现跨语言一致性，这突显了需要开发更稳健的多语言和文化意识模型的需求。", "innovation": "作者提出了两个新的基准测试：KnowRecall和VisRecall，用于评估多模态大语言模型在跨语言一致性方面的能力。这些基准测试分别从文化和视觉记忆一致性两个方面来评估模型的表现，专注于全球地标的文化和历史问题以及地标外观的描述。", "conclusion": "当前最先进的多模态大语言模型在跨语言一致性方面仍面临挑战，特别是在文化知识的整合方面。这表明了开发更加稳健和多语言文化意识模型的必要性。实验结果强调了这一问题，也提供了改进的方向。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06315", "html_url": "https://arxiv.org/abs/2505.06315", "title": "AI 的威胁建模：资产中心化方法的必要性", "title_en": "Threat Modeling for AI: The Case for an Asset-Centric Approach", "authors": "Jose Sanchez Vicarte,Marcin Spoczynski,Mostafa Elsaid", "background": "近年来，人工智能的进展正逐渐将人工智能的应用从单一应用转变为深度集成的人工智能代理。这些变化是由代理的自主决策能力和行动能力推动的，无论这些应用是否存在或者是否基于人工智能。这一进化使得人工智能在系统和用户的实际行动中实现前所未有的整合，包括人工智能能够自主编写和执行脚本。然而，随着人工智能系统能够自主执行代码、与外部系统交互并无需人类监督，传统的安全措施显得不再适用。", "innovation": "本文提出了一种以资产为中心的方法来对集成人工智能代理进行威胁建模，以应对集成人工智能代理所带来的独特安全挑战。这种方法是自下而上的，能够使防御者系统性地识别出所有关键AI资产在分布式基础设施中的漏洞，无论是传统漏洞还是特定于人工智能的漏洞。这种方法允许安全团队进行全面分析，能够在技术领域之间有效沟通，不依赖于对第三方AI组件的实施细节进行访问，以及全面识别特定于其产品上下文的人工智能漏洞。这种方法特别适用于具有复杂自主能力的代理系统。通过集中于资产而不是攻击，这种方法能够适应不断演变的威胁环境，并适应日益复杂的分布式人工智能开发管道.", "conclusion": "该方法强调资产而非攻击，使安全措施能够适应快速演变的威胁环境，同时适应日益复杂的分布式人工智能开发管道，为确保具备复杂自主能力的人工智能代理系统安全提供了一个新的视角。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22343", "html_url": "https://arxiv.org/abs/2505.22343", "title": "利用大型AI模型部署赋能智能低空经济", "title_en": "Empowering Intelligent Low-altitude Economy with Large AI Model Deployment", "authors": "Zhonghao Lyu,Yulan Gao,Junting Chen,Hongyang Du,Jie Xu,Kaibin Huang,Dong In Kim", "background": "低空经济(LAE)代表了一种新兴的经济范式，重新定义了商业和社会的空中活动。大型人工智能模型(LAIMs)提供了进一步增强LAE服务智能的变革潜力。然而，在LAE中部署LAIMs面临着一系列挑战，包括计算/存储需求与LAE实体有限的机载资源之间的巨大差距，实验室训练的LAIMs与动态物理环境之间的匹配不一致，以及传统分离设计的感应、通信和计算效率低下问题。", "innovation": "本文首先提出了一个针对LAIM部署的分层系统架构，并阐述了代表性的LAE应用场景。然后，探讨了能够促进LAIMs和低空系统相互演进的关键使能技术，并引入了一个面向任务的执行管道，以实现可扩展和自适应的服务交付。最终，通过对实际案例研究进行验证，说明了所提出的框架。", "conclusion": "最后，本文概述了未来研究面临的开放挑战，旨在激发未来的研究兴趣。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01631", "html_url": "https://arxiv.org/abs/2506.01631", "title": "基于梯度的模型指纹识别用于LLM相似性检测和家族分类", "title_en": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification", "authors": "Zehao Wu,Yanjie Zhao,Haoyu Wang", "background": "随着大型语言模型（LLMs）成为现代应用中的关键软件组件，未经授权的模型衍生通过微调、合并和再分发已经成为关键的软件工程挑战。与传统的软件相比，克隆检测和许可证合规已经得到很好的建立，但LLM生态系统缺乏有效机制来检测模型血统和执行许可证协议。特别是对于像Meta的LLaMA这样的开源模型创作者，他们需要衍生作品遵循命名约定以供属性使用，但却没有技术手段来验证合规性。", "innovation": "为了避免上述问题，我们将大型语言模型视为需要溯源追踪的软件制品，提出了一种基于梯度的指纹识别框架TensorGuard用于LLM相似性检测和家族分类。该框架通过分析随机输入扰动在张量层上的梯度响应来提取模型固有的行为特征签名，而无需依赖训练数据、水印或特定模型格式。TensorGuard支持广泛采用的safetensors格式，并通过统计分析梯度特性构造高维指纹。这些指纹能够实现任意模型之间的直接成对相似性评估以及通过K-Means聚类算法（带有领域启示式的中心初始化）对未知模型进行系统家族分类，实验表明分类准确率为94%。", "conclusion": "实验评估了58个模型（含8个基础模型和50个衍生模型，涵盖五个模型家族：Llama、Qwen、Gemma、Phi、Mistral），结果证明TensorGuard在我们的初始化聚类算法下具有94%的分类准确率，展示了其在LLM相似性检测和家族分类上的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08320", "html_url": "https://arxiv.org/abs/2506.08320", "title": "LLM自动生成的密码策略质量如何？", "title_en": "How Good LLM-Generated Password Policies Are?", "authors": "Vivek Vaidya,Aditya Patwardhan,Ashish Kundu", "background": "大型语言模型（LLMs）在各行各业中迅速被采纳，特别是在自然语言处理方面显示出卓越的能力。然而，这些模型生成的输出一致性差且难以预测，特别是在密码策略等安全关键领域带来了重大挑战。研究重点在于评估LLMs生成的密码策略的准确性和一致性，特别是如何将自然语言的需求转化为可执行的配置文件。本研究采用两种不同方法：一种是使用预训练的模型仅根据自然语言提示生成配置文件，另一种是提供官方文档作为范本指导生成过程。实验结果显示现有LLM模型在生成密码策略方面的显著挑战，并提供了有关如何改进LLM生成配置文件部署的见解.", "innovation": "通过对预训练模型和借助官方文档指导生成两种不同的方法进行实验，研究了LLMs在密码策略生成方面的准确性和一致性，并提出了具体的研究发现，为后续的工作提供重要的参考依据。", "conclusion": "现有LLMs在生成密码策略方面存在显著挑战，需要进一步改进以提高生成的准确性和一致性。研究为网络安全领域中LLMs的应用提供了有价值的指导和见解。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06231", "html_url": "https://arxiv.org/abs/2506.06231", "title": "迈向可解释的特征嵌入比较与对齐", "title_en": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "authors": "Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia", "background": "尽管文献中已经开发了多种特征嵌入模型，但大多数比较工作主要关注这些嵌入在分类等下游应用中的数值性能。然而，为了进行可解释的比较，需要识别和分析嵌入空间中不同样本群组之间的差异。本文提出了Spectral Pairwise Embedding Comparison（SPEC）框架，用于比较嵌入并识别它们在参考数据集聚类方面的不同。该框架基于两个嵌入的核矩阵，利用差异核矩阵的特征分解来检测在两种嵌入中被不同捕获的样本簇。", "innovation": "本文提出了一种基于核的方法的可扩展实现，其计算复杂度与样本数线性增长。此外，还提出了一个优化问题，使用此框架来对齐嵌入，确保一种嵌入中识别的聚类也在另一种模型中捕获。通过SPEC方法，对于大规模数据集如ImageNet和MS-COCO，该方法展示了比较和对齐嵌入的数值结果。项目页面可在提供的链接中访问。", "conclusion": "本文提出了SPEC框架，通过比较嵌入和识别它们在聚类方面的不同来实现可解释的特征嵌入比较和对齐。该方法为大规模数据集提供了有效的工具，并展示出了在ImageNet和MS-COCO上的应用结果。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20697", "html_url": "https://arxiv.org/abs/2505.20697", "title": "利用观察时间序列生成神经科学中动态因果图的假说：利用生成因子模型", "title_en": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "authors": "Zachary C. Brown,David Carlson", "background": "假设生成领域有望通过缩小需要进行干预研究的范围来降低神经科学的成本。现有的机器学习方法可以从复杂的数据库中生成科学假说，但是许多方法假设因果关系在时间上是静态的，这限制了它们应用于状态依赖行为系统，比如大脑的动态系统中的适用性。尽管一些方法尝试通过因子模型进行动态因果发现，但它们通常将关系限制为线性模式或施加其他简化假设。已有技术对于捕捉复杂的、时间变化的变量间交互，尤其是那些超越线性限制的，带来了挑战。因此，需要一种能建模动态图作为一种有条件加权的静态图超迭的新方法，从而捕捉非线性的关系，并检测复杂的时间变化的交互。", "innovation": "提出了一种新的方法，将动态图建模为条件加权的静态图的超迭，每种静态图可以捕捉非线性关系。这种做法使得能够检测超出线性限制的复杂、时间变化的交互。实验结果显示，在某些实验中，该方法相对于基线改善了预测动态因果模式的f1分数约22-28%，有的甚至达到了60%以上。并在对真实的大脑数据进行案例研究时，展示了该方法能够发现与特定行为状态相关的联系，提供了关于神经动力学的见解。这种方法显著区别于传统方法，因为它能捕捉非线性关系，并能检测复杂的时间依赖交互。", "conclusion": "通过利用生成因子模型，本研究提出的方法能够更准确地捕捉大脑中动态因果图的非线性交互。它通过超迭静态图来模型动态图，从而提高了预测动态因果模式的性能。这种新的方法在识别复杂的时间依赖交互方面具有优势，并为理解神经动力学提供了新的见解。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17828", "html_url": "https://arxiv.org/abs/2506.17828", "title": "通过强化学习迭代重权重优化冻结的大型语言模型对齐方法", "title_en": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach", "authors": "Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong", "background": "目前，将大型语言模型（LLMs）与人类偏好对齐通常需要使用RLHF（基于奖励的人工智能微调）和DPO（基于策略梯度的微调）等微调方法。这些方法直接优化模型参数，因此只能在模型训练时间使用，无法在测试时间进一步提高模型性能或当模型权重不可用时使用。相比之下，测试时间方法通过利用奖励函数来指导和改进输出质量，而不涉及权重更新，但这些方法会带来高推理成本，并且往往基于不完美的奖励或价值函数，导致输出不太理想。本文即针对此背景提出了迭代重权重优化（IRO）方法，这是一种无需触碰基模型参数的强化学习框架，用于对（冻结）基模型进行RL风格的对齐操作。", "innovation": "提出的IRO方法是一种不需要更新模型参数的强化学习框架，设计用于对（冻结）基模型进行RL风格的对齐操作。在训练过程中，IRO通过采样候选生成、使用当前价值函数重采样、以及训练新的引导模型等步骤，逐步优化生成过程。在测试阶段，基于价值函数的搜索优化过程可以引导基模型生成，从而在不获取模型权重的情况下实现对齐，类似于OpenAI的强化微调（RFT）方法，但成本更低，适用性更强。", "conclusion": "总而言之，IRO方法在保持基模型参数冻结的情况下，通过迭代优化价值函数的方式，能够有效对齐冻结的大型语言模型，并可以通过用户自身的数据集进行模型对齐，无需访问模型权重。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X: 统一的空中-地面V2X合作", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Fengze Yang,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "多车辆协同驾驶相较于单个自动驾驶车辆表现出明显优势，但传统基于基础设施的V2X系统仍然受限于高额的部署成本，并在农村和郊区形成了“未覆盖危险区域”。", "innovation": "提出了一种利用无人机（UAV）作为固定道路旁单元（RSU）的灵活替代或补充的AirV2X-Perception大规模数据集。与地面感知相比，无人机提供了独特的优势，包括减少遮挡的鸟瞰视角、动态定位能力以及相对固定基础设施显著更低的部署成本。数据集包含6.73小时的无人机协助驾驶场景，覆盖城市、郊区和农村地区的各种天气和照明条件。该数据集促进了车辆到无人机（V2D）算法的研发和标准化评估，填补了快速发展的空中辅助自动驾驶领域的关键空白。", "conclusion": "AirV2X-Perception数据集和开发工具包开源，为V2D算法的研发提供了开放式资源。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17347", "html_url": "https://arxiv.org/abs/2506.17347", "title": "区分预测型和生成型人工智能的监管", "title_en": "Distinguishing Predictive and Generative AI in Regulation", "authors": "Jennifer Wang,Andrew Selbst,Solon Barocas,Suresh Venkatasubramanian", "background": "过去十年，政策制定者开发了一系列监管工具，以确保人工智能的发展符合关键的社会目标。这些工具最初是为了应对预测型人工智能带来的担忧而设计的，因此这些工具包含了对人工智能系统性质的认知以及某些监管方法的实用性假设。然而，随着生成型人工智能的出现，这些假设不再适用，尽管政策制定者试图维持一个涵盖两种类型人工智能的统一监管目标。因此，本文识别了生成型人工智能的四个关键方面，这些方面需要不同的政策回应。这四个方面包括：生成型人工智能的普适性和适应性，使其难以成为一个合适的监管目标；设计有效评估的难度；新的法律关切，改变了利益相关者和知识来源的生态系统；生成型人工智能价值链的分布式结构。", "innovation": "本文识别了生成型人工智能的四个关键方面，这四个方面分别是：普适性和适应性、设计有效评估的难度、新的法律关切以及分散的价值链结构。这些识别区分了预测型和生成型人工智能，政策制定者需要根据这些不同之处评估哪些过去十年的工作仍然相关，哪些则需要新的政策来应对生成型人工智能带来的独特风险。论文提出了三项建议，以帮助政策制定者更有效地识别监管目标，并利用广泛生态系统的约束来治理生成型人工智能。", "conclusion": "本文建议政策制定者应评估哪些过去十年的工作仍然相关，哪些则需要新的政策来应对生成型人工智能带来的独特风险。提出了三项政策建议，旨在更有效地识别监管目标，利用广泛生态系统的约束来治理生成型人工智能。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09993", "html_url": "https://arxiv.org/abs/2506.09993", "title": "使用扩散模型的注意力文本感知图像恢复", "title_en": "Text-Aware Image Restoration with Diffusion Models", "authors": "Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim", "background": "图像恢复旨在恢复退化的图像。尽管现有的基于扩散的方法在自然图像恢复方面取得了巨大成功，但在退化图像中忠实重构文本区域时经常表现出色的能力较差。这些方法通常会产生可被接受但不正确的文本样式图案，我们称之为文本图像错觉。现有的方法在产生文本信息和视觉内容恢复之间存在失衡。本文旨在通过引入一种既能恢复视觉内容又能保持文本准确性的方法来解决这一问题，提出了注意力文本感知图像恢复（TAIR）。", "innovation": "本文介绍了一种新的恢复任务，称为TAIR（Text-Aware Image Restoration），要求同时恢复视觉内容和文本准确性。为此，提出了SA-Text，这是一个规模较大的基准数据集，包含100K高质量场景图像，这些图像密集注释了多种复杂的文本实例。此外，还提出了结合内部分布式模型和文本检测模块的多任务扩散框架TeReDiff，以实现两种组件之间的联合训练，并从中提取丰富的文本表示，作为后续去噪步骤中的提示。通过广泛的实验验证了这一框架在文本识别准确性方面的优越表现，显著优于现有最先进恢复方法。", "conclusion": "该研究通过引入TAIR任务，以及同时恢复视觉内容和文本准确性的方法，解决了图像恢复中的文本图像错觉问题。实验结果表明，提出的方法能够显著提高文本识别的精度，优于现有最先进的图像恢复方法。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14634", "html_url": "https://arxiv.org/abs/2506.14634", "title": "没完没了的问卷吗？使用大型语言模型编码关于调查动机的开放性问卷响应", "title_en": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "authors": "Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessica Daikeler", "background": "近年来，大语言模型（LLMs）的发展及其更广泛的可访问性引发了关于如何在调查研究中使用它们的讨论，包括对开放性问卷答复的分类。由于其语言能力，LLMs 可以作为一种有效的替代方案，替代耗时的手动编码和监督机器学习模型的预训练。尽管已有研究主要集中在英语响应或非复杂主题的单一LLMs上，但在不同环境下使用LLMs对开放性问卷答复进行编码的有效性和质量仍不清楚。本研究探讨了不同LLMs在其他环境里编码关于参与调查动机的德语开放性问卷响应的能力，通过对比几种最先进的LLMs和多种提示方法，并利用人类专家编码进行评估，展示了执行性能和提示方法之间的显著差异。\n", "innovation": "研究创新性地对比了几种最先进的LLMs和多种提示方法，在非英语环境中（即使用德语数据）评估其对开放性问卷响应的编码能力。研究发现，仅通过微调的LLM可以获得令人满意的预测性能，但提示方法间的性能差异则取决于所用的LLM。此外，LLMs在不同类别原因上的不平等分类性能会导致分类后的类别分布不同，除非进行微调。研究讨论了这些发现对调查研究中编码开放性响应的方法论研究和实质分析的影响，并强调了在LLMs时代选择自动化方法进行开放性响应分类时的研究者需要考虑的众多权衡。\n", "conclusion": "研究表明，尽管LLMs在调查研究中可以作为一种有效的编码工具，但由于执行性能和提示方法之间的显著差异，研究者在实际应用时仍需谨慎选择，并进行适当的微调以保证分类质量。本研究为LLMs在调查研究中高效、准确和可靠地使用提供了条件，并为相关领域的进一步研究做出了贡献。\n"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23351", "html_url": "https://arxiv.org/abs/2506.23351", "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "title_en": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "authors": "Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yu Chen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu", "background": "Embodied Artificial Intelligence (Embodied AI) 是机器人领域的一个新兴前沿，旨在开发能在复杂物理环境中感知、推理和行动的自主系统。尽管单臂系统在执行任务方面表现出色，但双臂协作系统对于处理涉及刚性、可变形以及触觉敏感对象的复杂任务是必不可少的。为了推进这一目标，该研究在第二届MEIS研讨会（CVPR 2025）上启动了 RoboTwin 双臂协作挑战赛。该比赛基于 RoboTwin 模拟平台（1.0和2.0版本）和AgileX COBOT-Magic 机器人平台，分为三个阶段：模拟第一轮、模拟第二轮和最终的实境轮。比赛吸引了来自全球的64支队伍和超过400名参与者，涵盖了17项双臂操作任务，涉及刚性、可变形和基于触觉的情景。", "innovation": "该研究表明，双臂协作系统在处理复杂对象任务时具有优势。挑战赛的方法注重双臂通用策略的学习，并提供了实现高表现解决方案（如SEM和AnchorDP3）的平台，从而为后续研究提供了宝贵见解。该竞赛还强调支持未来研究，以开发更加稳健和通用的双臂操作策略。", "conclusion": "该报告详细介绍了竞赛的设计、任务设置、评估方法、关键发现和未来方向，旨在支持未来对稳健且通用的双臂操控策略的研究工作。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "基于语义结构的生成式攻击以提高对抗转移性", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "对抗攻击通常通过白盒代理模型训练扰动生成器，然后将生成的扰动应用于未知的黑盒受害模型。虽然这些方法在推理效率、可扩展性和迁移性上表现出色，但现有研究尚未充分利用生成模型的表征能力来保留和利用语义信息。生成器的中间激活中包含丰富的语义特征，如对象边界和粗略形状，但这些特征被未充分利用，限制了扰动与关键的对抗可转移性对象显著区域的对齐。", "innovation": "提出了基于Mean Teacher的语义结构感知攻击框架。通过利用Mean Teacher作为时间平滑特征参考，进一步在学生和语义丰富教师的早期层激活之间通过特征蒸馏导向语义一致性。基于观察结果，该方法引导对生成器中语义显著的早期中间块进行分阶段的对抗扰动，以显著提高对抗可转移性。这种方法在多种模型、领域和任务上进行了广泛的实验，相较于最先进的生成攻击方法，展示了持续的改进，并采用传统指标和新的意外纠正率（ACR）进行了全面评估。", "conclusion": "该研究通过语义结构感知的方法，显著改善了对抗攻击的转移性，并通过实验验证了其有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00631", "html_url": "https://arxiv.org/abs/2507.00631", "title": "Horus: 在不确定性下的无信任委托协议", "title_en": "Horus: A Protocol for Trustless Delegation Under Uncertainty", "authors": "David Shi,Kevin Joo", "background": "在动态且低信任的环境中，自主人工智能代理可以通过将工作委派给子代理来受益，但正确的保证不能仅通过前置规范或集中监督来实现。正确性作为一个新兴属性，只能通过解决错误成本低于犯错成本的系统中体现出来。因此，需要一个协议，在这样一个环境中确保正确性，而不需要提前规定或集中监督。", "innovation": "提出了一种协议，通过抵押申述在递归验证游戏中强制执行正确性。任务作为意向发布，并由解决者竞争完成。选定的解决者在承担风险的情况下执行任务，正确性的检查在事后由验证者进行。任何挑战者都可以通过与结果进行抵押来挑战结果，从而触发验证过程。错误代理会被惩罚，正确反对者将得到奖励，并存在一个升级路径，以对错误的验证者进行惩罚。当解决者、挑战者和验证者的激励机制对齐时，错误条件使正确性成为纳什均衡。", "conclusion": "当激励机制在解决者、挑战者和验证者之间对齐时，错误条件使正确性成为纳什均衡。这意味着在这种递归验证游戏中，通过上下级代理之间的竞争和抵押机制，最终可以实现正确的结果。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22523", "html_url": "https://arxiv.org/abs/2506.22523", "title": "在学术医疗中心进行的版权导向型红队测试报告", "title_en": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center", "authors": "James Wen,Sahil Nalawade,Zhiwei Liang,Catherine Bielick,Marisa Ferrara Boston,Alexander Chowdhury,Adele Collin,Luigi De Angelis,Jacob Ellen,Heather Frase,Rodrigo R. Gameiro,Juan Manuel Gutierrez,Pooja Kadam,Murat Keceli,Srikanth Krishnamurthy,Anne Kwok,Yanan Lance Lu,Heather Mattie,Liam G. McCoy,Katherine Miller,Allison C. Morgan,Marlene Louisa Moerig,Trang Nguyen,Alexander Owen-Post,Alex D. Ruiz,Sreekar Reddy Puchala,Soujanya Samineni,Takeshi Tohyama,Varun Ullanat,Carmine Valenza,Camilo Velez,Pengcheng Wang,Anna Wuest,Yuxiang Zhou,Yingde Zhu,Jason M. Johnson,Naomi Lenane,Jennifer Willcox,Francis J. Vitiello,Leo Anthony G. Celi,Renato Umeton", "background": "在学术医疗机构部署生成型人工智能（AI）引起了版权合规的关注。达纳-法伯癌症研究所实施了GPT4DFCI，这是一个内部生成AI工具，利用了OpenAI模型，并且获批在科研和运营中进行企业使用。考虑到（1）该工具在机构内的广泛采用；（2）研究使命；以及（3）从Azure OpenAI服务产品中受益所需的客户版权承诺模型所要求的共同责任机制，我们认定需要严格的版权合规测试。这项测试的背景是确保生成型AI在学术医疗机构中的应用符合法律和伦理标准。", "innovation": "进行了一个结构化的红队测试，测试参与者包括来自学术、工业和政府机构的42名成员。测试包括四个领域：文学作品、新闻文章、科学研究出版物和受限访问的临床记录。测试揭示了生成型AI系统在版权合规方面的一些特定漏洞，并要求在推理时过滤潜在的版权材料。此外，测试还发现了不同内容类型在保护机制上的不同效果，从而促使实施了一个特定的版权元提示以缓解这些漏洞。这项测试提供了一种新的方法来确保在学术医疗机构中生成型AI的合规和安全性，包括定期进行测试以确保持续合规。", "conclusion": "系统化的红队测试揭示了生成型AI在版权合规方面的具体漏洞，并导致了具体的缓解策略。学术医疗机构部署生成型AI应实施持续的测试协议，以确保法律和伦理合规。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00660", "html_url": "https://arxiv.org/abs/2507.00660", "title": "MTCNet：4D超声心动图中基于运动和拓扑一致性学习的二尖瓣分割", "title_en": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound", "authors": "Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni", "background": "二尖瓣反流是临床上最普遍的心脏疾病之一。四维(4D)超声成像已成为评估动态瓣膜形态的主要成像技术。然而，现有的4D二尖瓣(MV)分析方法仍然面临挑战，如有限的相位标注、严重的运动伪影以及影像质量较差等问题。现有方法缺乏相间依赖性，阻碍了4D MV分析的有效性。因此，本文探讨了如何改进4D MV的分割方法，特别是在半监督学习环境下。", "innovation": "本文提出了一种名为MTCNet的网络，用于4D MV超声心动图的分割。MTCNet利用交叉相位运动引导的一致性学习策略和双向注意力记忆库来传播时空特征，解决了相间依赖问题。同时引入了一种新颖的拓扑指导相关正则化方法，引入物理先验知识保持解剖上的合理性。这种方法仅需稀疏的终舒张期和终收缩期标注，即可实现高效的跨相位一致性。", "conclusion": "在包含来自160名患者共1408个相位数据的最大4D MV数据集上，MTCNet的跨相位一致性在Dice和HD指标上表现优于其他先进方法。此研究为4D MV分割提供了新的思路和技术手段，极大促进了该领域的进展。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00606", "html_url": "https://arxiv.org/abs/2507.00606", "title": "Mixture of Reasonings: 教导大语言模型使用适应性策略进行推理", "title_en": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies", "authors": "Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang", "background": "大语言模型（LLMs）通过高级提示技术如思维链（CoT）和思维树（ToT）在复杂任务中表现出色，但它们对外部精心设计的任务特定提示的高度依赖限制了适应性和效率。现有的方法需要人工干预来创建适用于不同任务的提示。本文探讨了一种新型的训练框架—多样推理混合（Mixture of Reasoning, MoR），该框架将不同的推理策略嵌入到LLMs中，以实现自主、任务适应性的推理，而无需任何外部提示工程。MoR包含两个阶段：思维生成阶段和数据集构建阶段，从而在监督微调中为模型提供了一种模板与基准数据集配对的方法。通过MoR，研究者旨在消除对任务特定提示的需求，为不同任务提供了一种通用的、强大的推理解决方案。", "innovation": "引入了一种新的训练框架—Mixture of Reasoning（MoR），旨在自主生成任务适应性的推理策略，而无需人工设计的提示工程。该框架通过两个阶段：思维生成和数据集构建，实现了这种功能。MoR在多项实验中展示了显著的性能提升，与基线相比，MoR150在某些任务上获得了13.5%的提升。这表明MoR能够有效提升大语言模型的推理能力，并提供了通用的解决方案来应对多种任务。", "conclusion": "Mixture of Reasoning（MoR）框架通过实现自主生成的任务适应性推理策略，显著提高了大语言模型的性能，同时无需依赖手工设计的提示。这种方法为不同任务提供了一种通用的、高效的解决方案，增强了模型的适应性和灵活性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00953", "html_url": "https://arxiv.org/abs/2507.00953", "title": "从句子到序列：生物系统中的语言重思", "title_en": "From Sentences to Sequences: Rethinking Languages in Biological System", "authors": "Ke Liu,Shuaike Shen,Hao Chen", "background": "在自然语言处理（NLP）领域中，大规模语言模型展示了在建模蛋白质、RNA和DNA这类生物语言方面的潜力。自动回归生成范式和评估指标已被从NLP领域转移到生物序列建模中。然而，自然和生物语言内的固有结构关联本质不同。因此，本文重新审视生物系统中的语言概念，以更好地理解NLP的成功如何能有效地应用于生物领域。通过将生物分子的3D结构视为句子的语义内容，并考虑残基或碱基之间的强关联，我们强调了结构评估的重要性，并展示了自动回归范式在生物语言建模中的应用性。", "innovation": "本文创新性地将3D结构视为句子的语义内容，提出了利用生物分子的3D结构进行自动回归生成的研究方法。这种方法强调了结构关联的重要性，并展示了自动回归范式在生物语言建模中的适用性。", "conclusion": "本文通过重新审视生物系统中的语言概念，探讨了NLP方法如何应用于生物领域，并证明了自动回归生成范式在生物语言建模中的有效性和重要性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01041", "html_url": "https://arxiv.org/abs/2507.01041", "title": "边缘网络中快速的人工智能模型拆分", "title_en": "Fast AI Model Splitting over Edge Networks", "authors": "Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin(Sherman)Shen", "background": "Split Learning (SL) 是一种计算效率高的 AI 模型训练方法，能够减轻设备端的计算负担。然而，复杂的 AI 模型结构带来了高昂的计算复杂度，使得获得最优模型拆分方案变得困难。现有的方法很难在不影响模型性能的前提下，快速有效地完成这一任务，特别是在动态边缘网络环境中。因此，研究一种能够高效计算最优模型拆分的新方法显得尤为重要。", "innovation": "该论文将任意 AI 模型表示为有向无环图（DAG），并重新定义最优模型拆分问题为最小 s-t 切割搜索问题。为此，作者提出了一种基于DAG的快速模型拆分算法，该算法通过最大流方法重新构建DAG以识别最优模型拆分。此外，考虑到具有块结构的 AI 模型，提出了一种基于块的模型拆分算法，通过将每个块简化为一个顶点，从而达到降低计算复杂度的目的。理论分析和实验表明，这些算法能够在毫秒内确定最优模型拆分，并且与最先进的基准相比，在动态边缘网络中降低了24.62%-38.95%的训练延迟。", "conclusion": "该论文提出的方法能够在边缘网络中高效地确定最优模型拆分，不仅速度快，而且在实际应用中能够显著减少训练延迟，为解决边缘计算中的计算效率问题提供了新思路。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01551", "html_url": "https://arxiv.org/abs/2507.01551", "title": "自我引导的过程奖励优化与重新定义的步骤优势用于过程强化学习", "title_en": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "authors": "Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua", "background": "过程增强学习（PRL）在增强大型语言模型（LLMs）的推理能力方面显示出很大潜力，但引入额外的过程奖励模型会带来显著的计算开销，且目前缺乏统一的理论框架用于过程层面的奖励估计。已有研究未能同时解决这两个问题，因此有必要提出一种新的技术框架来解决这些问题。", "innovation": "提出了S自我引导的过程奖励优化（SPRO）框架，其通过两项创新解决了上述问题：（1）理论上证明过程奖励可以从策略模型本身推导得出；（2）定义了累计过程奖励和掩码步骤优势（MSA），这使得在共享提示采样组内进行严格的步骤优势估计成为可能。SPRO在训练效率上超过基本GRPO 3.4倍，并且测试准确率提高17.5%，同时保持了稳定的高策略熵并降低了响应长度约三分之一，表明这种模型可以充分探索而不遭受奖励作弊的影响。此外，SPRO不增加额外的计算负担与结果监督强化学习方法（如GRPO）相比，更适合工业应用。", "conclusion": "SPRO在不增加计算开销的情况下，提高了训练效率和测试准确性，同时保持了策略熵和控制了响应长度，为PRL的理论和实践应用提供了一个有力的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01381", "html_url": "https://arxiv.org/abs/2507.01381", "title": "Distributional Soft Actor-Critic with Diffusion Policy", "title_en": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": "Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li", "background": "强化学习在复杂控制任务中已被证明非常有效。传统方法通常使用单模分布，如高斯分布，来建模价值分布输出，但这会导致价值函数估计偏斜，影响算法表现。", "innovation": "本文提出了一个新的分布性强化学习算法DSAC-D（具有扩散策略的分布式软演员批判者），该算法通过引入策略熵和价值分布函数建立一个多模态分布策略迭代框架，此框架能够收敛到最优策略。通过生成一系列奖励样本，使用扩散模型进行反向采样构建了能够准确描述多峰分布的扩散价值网络，进一步提出了价值网络和策略网络双扩散的分布性强化学习算法。实验表明该算法不仅能够学习多模态策略，还在MuJoCo测试任务中达到SOTA性能，并在9个控制任务中平均收益提高超过10%，抑制了估计偏斜。在实际车辆测试中，DSAC-D能够准确描述不同驾驶风格的多模态分布，扩散策略网络能够刻画多模态轨迹。", "conclusion": "该研究通过引入扩散模型和双扩散机制，克服了传统单模态分布的偏斜问题，提高了强化学习算法的性能，特别是在多模态策略学习方面取得了显著成果。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01961", "html_url": "https://arxiv.org/abs/2507.01961", "title": "AC-DiT: 自适应协调扩散变换器在移动操作中的应用", "title_en": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation", "authors": "Sixiang Chen,Jiaming Liu,Siyuan Qian,Han Jiang,Lily Li,Renrui Zhang,Zhuoyang Liu,Chenyang Gu,Chengkai Hou,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang", "background": "近期，移动操作因其在家庭任务中的语言指导下的人机交互应用受到了广泛关注。然而，现有的方法在协调移动底座和机械臂方面仍然存在挑战，主要原因在于两方面：一方面，它们未能明确建模移动底座对机械臂控制的影响，导致在高自由度下容易积累误差；另一方面，它们以单一的视觉观测模态（例如，全部为2D或全部为3D）处理整个移动操作过程，忽略了不同阶段感知要求的差异性。", "innovation": "为解决上述问题，本文提出了一种自适应协调扩散变换器（AC-DiT）。AC-DiT能够提升移动底座和机械臂的协调，实现端到端的移动操作。首先，由于移动底座的运动直接影响机械臂的动作，引入了移动底座到机械臂的条件机制，引导模型首先提取底座运动的表征，然后将这些表征作为预测全身体控制动作的上下文先验，从而考虑到底座运动可能产生的潜在影响。其次，为了满足不同阶段的感知要求，设计了一种感知意识的多模态条件策略，动态调整不同2D视觉图像和3D点云的融合权重，以适应当前的具体感知需求。这使得模型能够，例如，在语义信息对动作预测至关重要时，更多依赖2D输入；在需要精确的空间理解时，更多关注3D几何信息。", "conclusion": "通过广泛的仿真和真实世界移动操作任务实验验证了AC-DiT的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01352", "html_url": "https://arxiv.org/abs/2507.01352", "title": "Skywork-Reward-V2：通过人机协同放大偏好数据的准确性", "title_en": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "authors": "Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou", "background": "尽管奖励模型（RMs）在人类反馈强化学习（RLHF）中扮演着关键角色，但当前最先进的公开RMs在大多数现有的评估基准上表现不佳，未能准确捕捉人类偏好中的细微和复杂性。即使采用了高级训练技术的方法也没有带来显著的性能提升。我们假设这是因为偏好数据集的局限性，这些数据集往往是范围狭窄的、合成标签的或是缺乏严格的质量控制的。为了解决这些挑战，我们提出了一组4000万偏好对的大规模数据集，命名为SynPref-40M。为了能够大规模进行数据管理，我们设计了一个人机协同的两阶段流水线，利用人类注释质量和AI可扩展性的互补优势。在这个流水线中，人类提供验证注释，大规模语言模型根据人类指导进行自动管理。基于这些偏好数据，我们引入了Skywork-Reward-V2，这是一系列从0.6B到8B参数的八个奖励模型，基于精心挑选的2600万偏好数据对，其中来自SynPref-40M的数据已经过严格挑选。", "innovation": "我们提出了一种大规模的偏好数据集，名为SynPref-40M，由4000万偏好对组成。设计了一种人机协同的两阶段流水线，由人类和大型语言模型共同完成数据管理任务。基于此数据集训练了一系列从0.6B到8B参数的八个Skywork-Reward-V2奖励模型。这些模型在广泛的评价基准上表现出色，包括与人类偏好对齐、客观性、安全性、抵抗风格偏见以及N个最好的扩展性等方面，达到了目前的最新水平。我们进一步证明了，我们的方法不仅在于数据规模的扩大，还在于高质量的数据管理。Skywork-Reward-V2系列代表了开放奖励模型的重大进展，突显了现有偏好数据集的未开发潜能，并展示了人机协同管理如何能够实现显著更高的数据质量。", "conclusion": "Skywork-Reward-V2系列在广泛的偏好模型评估基准上展示了卓越的性能，其成功归因于对大规模高质量偏好数据集的管理以及人机协同方法的应用。这表明我们可以通过这种方式克服现有的瓶颈，并进一步提高人类反馈强化学习的奖励模型的质量。"}
{"llm_update_time": "20250707", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01548", "html_url": "https://arxiv.org/abs/2507.01548", "title": "使用汉字创作叙事桥梁：老年人移民的AI共创工作坊", "title_en": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "authors": "Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen", "background": "本文探讨了老年人，特别是城市中的老年移民，如何通过AI辅助的共创建立来表达那些常常被分割、边缘化或难以用言语表达的个人叙事。参与者通过结合口头讲述和汉字象征重构的方式，在试点工作中分享了迁移的记忆，并共同创造新的汉字形态，这些新形态由大型语言模型（LLM）提出，同时也结合了实物材料。在人类导师和软AI的支持下，没有数字素养要求的情况下，参与者将生活体验转化为视觉性和触觉性表达。这种方法为人类与AI的合作与老龄化提供了新的视角，重新定位了AI的作用，不仅仅作为内容生产商，而是作为支撑机制，同时在社会技术系统中支持叙事自主权。", "innovation": "该研究通过整合口头讲述和汉字象征重构的方式，提出了一个结合老年人生活经验与新技术的创新方法，使他们能够不依赖数字素养的情况下，通过新的汉字形态表达个人叙事。这种方法重新定义了AI的角色，不再将其视为内容生产者，而是作为促进叙事自主性的支持工具。此外，该研究强调了通过社会技术系统支持叙事表达的可能性，为老龄化社会中的人机合作提供了新的视角。", "conclusion": "该研究指出，通过这种AI辅助的共创作方式，老年人能够更自然地表达个人情感和记忆，而不是直接依赖数字设备。这种方法不仅增强了老年人的叙事能力，还促进了人机协作的新模式，强调了情感和社会连接在技术发展中的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02221", "html_url": "https://arxiv.org/abs/2507.02221", "title": "GDC Cohort Copilot: 一个来自基因组数据通用平台的人工智能协作者", "title_en": "GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons", "authors": "Steven Song,Anirudh Subramanyam,Zhenyu Zhang,Aarti Venkat,Robert L. Grossman", "background": "基因组数据通用平台（GDC）为用户提供了一个统一的生信分析平台，用户可以通过图形化工具创建复杂的患者队列。然而，用户，尤其是新手用户，在从成百上千个可能的字段和属性中找到特定队列描述符时可能会遇到困难。", "innovation": "介绍了GDC Cohort Copilot，这是一种开源的协作者工具，能够根据用户输入的自然语言描述自动生成GDC队列过滤器，然后再将队列导回GDC进行进一步分析。开发并评估了多个大型语言模型（LLMs），显示本地部署、开源的GDC Cohort LLM比GPT-4o在生成GDC队列方面表现更佳。", "conclusion": "GDC Cohort Copilot以开源形式提供，其独立的docker镜像和个人代码可通过指定链接访问，GDC Cohort LLM的权重也提供下载。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02088", "html_url": "https://arxiv.org/abs/2507.02088", "title": "McBE：大型语言模型多元任务中文偏见评估基准", "title_en": "McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models", "authors": "Tian Lan,Xiangdong Su,Xu Liu,Ruirui Wang,Ke Chang,Jiang Li,Guanglai Gao", "background": "随着大型语言模型（LLMs）在各种NLP任务中的应用增加，它们固有的偏见逐渐被披露。因此，测量LLMs中的偏见对于减轻其伦理风险至关重要。然而，大多数现有的偏见评估数据集主要关注英语和北美人文化，其偏见类别不完全适用于其他文化。基于中文语言和文化的数据集相对稀缺。更重要的是，这些数据集通常只支持单一评估任务，无法从多个方面评估LLMs中的偏见。", "innovation": "本文提出了一个多元任务中文偏见评估基准（McBE），包含4,077个偏见评估实例，涵盖了12个单一偏见类别、82个子类别，并引入5个评估任务，提供了广泛的类别覆盖、内容多样性和测量全面性。此外，还评估了几种来自不同系列和参数规模的流行大型语言模型，所有这些LLMs在不同程度上都表现出偏见。深入分析了结果，提供了关于LLMs偏见的新颖见解。", "conclusion": "总之，所有这些LLMs在不同程度上都表现出偏见，McBE为评估中文语言模型中的多元偏见提供了全面的数据集和评估框架，有助于更全面地理解LLMs中的偏见。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02259", "html_url": "https://arxiv.org/abs/2507.02259", "title": "MemAgent：基于多会话RL记忆代理重塑长上下文LLM", "title_en": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": "Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou", "background": "尽管通过长度外推、高效注意力和记忆模块等方式取得了改进，但在不牺牲性能的情况下使用线性复杂度处理无限长文档的挑战仍然存在。因此，直接在端到端的长文本任务中进行优化，并引入一个名为MemAgent的新代理工作流，该工作流分段阅读文本并通过覆盖策略更新内存。", "innovation": "提出了一个名为MemAgent的新型代理工作流，该工作流通过分段阅读文本和使用覆盖策略更新内存，从而实现长上下文处理。同时，还将DAPO算法扩展以通过独立上下文多会话生成促进训练。MemAgent能够从一个8K上下文外推到3.5M QA任务，并且性能损失小于5%，同时在512K RULER测试中达到95%以上的效果。", "conclusion": "MemAgent展示了卓越的长上下文能力，能够在训练数据量从32K扩展到3.5M的情况下，保持较低的性能损失，并在大规模测试中取得了优异的结果。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02199", "html_url": "https://arxiv.org/abs/2507.02199", "title": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "title_en": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "authors": "Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu", "background": "链式思维（CoT）推理使基于转换器的语言模型在复杂数学和多步骤规划方面表现出色。然而，在标准的解码器架构中，这些推理步骤是以自然语言形式外部化，提高了可解释性但牺牲了效率。为捕捉难以用语言表达的推理，许多研究探索了递归架构，希望在潜在空间中内部化推理，支持潜在的CoT。本文研究了Huginn-3.5B深度递归转换器模型，该模型在推理时不增加参数数量即重复使用层，研究其在算术任务上的内部行为.", "innovation": "本文探究Huginn-3.5B模型中是否存在可解释的潜在CoT，通过一系列探针技术（如Logit Lens和Coda Lens）追踪最终和中间结果标记的秩轨迹。研究发现，递归结构的可解释性隐藏状态受层索引和解码方法的严重影响，并且增加递归深度只有边际益处，未能达到显式外部化推理步骤的模型效果.", "conclusion": "研究结果表明，在Huginn-3.5B模型中存在有限的可解释潜在CoT证据。递归块的探针不一致性严重，隐藏状态的可解释性高度依赖层索引和解码方法。增加递归深度只带来边际提升，并未达到显式外部化推理步骤的效果。提供的代码可在此下载：[粘贴实际链接](this https URL)."}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02145", "html_url": "https://arxiv.org/abs/2507.02145", "title": "推理还是不推理？基于推理的LLMs在对话摘要中的综合评估", "title_en": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization", "authors": "Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira", "background": "对话摘要是一个在客户服务、会议分析和会话AI中具有重要实用价值的挑战性任务。尽管大型语言模型（LLMs）在摘要任务中取得了显著进展，但专门为涉及同时抽象和精炼的需求的对话场景设计的逐步推理架构（如OpenAI-o1和DeepSeek-R1中的长链推理实施）尚未被研究。因此，本文对最先进的推理LLMs和非推理LLMs在三种主要的对话摘要范式（通用、角色导向和查询导向）中进行了首次全面和系统的评估。研究涵盖了多种语言、领域和摘要长度，利用了强基准(SAMSum、DialogSum、CSDS和QMSum)和先进的评估协议，包括基于LLMs的自动指标和基于人类标准的评价。尽管这些推理LLMs在其他推理密集型任务中表现出色，但研究发现它们并不总是能够改善对话摘要的质量。", "innovation": "这项研究首次全面评估了最先进的推理LLMs和非推理LLMs在三种主要对话摘要范式中的表现。研究使用了多种语言、领域和摘要长度，并结合了强大的基准测试和先进的评估协议。通过具体场景分析和详细的案例研究，进一步识别在复杂对话情境中推理可能失败或反而有害的具体情况。", "conclusion": "目前的推理LLMs存在一定的局限性，对于复杂对话场景中的摘要，推理可能不仅不会带来收益，反而会增加冗长、事实不一致和不简洁等问题。该研究为改善实际对话摘要提供了新的见解，并突出了需要针对特定场景进行针对性建模和评估策略的必要性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02302", "html_url": "https://arxiv.org/abs/2507.02302", "title": "DoMIX：一种高效的利用细调场景中领域知识的框架", "title_en": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning", "authors": "Dohoon Kim,Donghun Kang,Taesup Moon", "background": "近年来，领域适应预训练（DAP）因其在精调预训练模型方面的有效性而引起了广泛关注。在此基础上，持续的DAP已被探索，以开发能够逐步整合不同领域数据集的预训练模型。然而，现有的持续DAP方法面临着多个局限性：（1）训练过程中的高计算成本和GPU内存占用；（2）对增量数据顺序的敏感性；（3）提供一个适用于所有最终任务的通用模型，这与DAP的本质相悖。本研究通过利用LoRA模块，一种代表性的参数高效精调（PEFT）方法，提出了DoMIX，一种新的方法，以解决这些挑战，从而实现高效且并行的领域适应预训练，该方法对领域顺序具有鲁棒性，并有效利用积累的知识提供针对特定任务定制的预训练模型。我们还展示了我们的方法如何超越DAP设置，应用于标准的大规模语言模型（LLM）精调场景。", "innovation": "DoMIX通过引入LoRA模块，提供了一种参数高效的精调方法，从而实现了高效且并行的领域适应预训练。该方法针对增量数据顺序具有鲁棒性，并能够针对特定任务提供定制化的预训练模型，同时适用于DAP和标准的大规模语言模型精调场景。", "conclusion": "我们的方法通过利用LoRA模块成功解决了持续DAP在计算成本、数据顺序敏感性和通用模型问题上的局限性。DoMIX不仅提高了领域适应预训练的效率和并行性，还提供了针对特定任务的定制化预训练模型，并展示了其在标准的大规模语言模型精调中的应用潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02378", "html_url": "https://arxiv.org/abs/2507.02378", "title": "通过分布一致性和多样性感知的数据选择提高高效代码LLM训练", "title_en": "Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection", "authors": "Weijie Lyu,Sheng-Jun Huang,Xuan Xia", "background": "大型语言模型（LLMs）最近的进步显著提升了代码生成和程序理解，加速了软件工程的发展。现有方法主要通过使用大量数据来提升模型性能，但往往忽视了数据质量，从而降低了训练效率。因此，迫切需要改进数据选择方法，以提高训练效率和模型性能。", "innovation": "本文介绍了一种利用参数模型进行代码数据选择的方法，以提高训练效率和模型性能。该方法优化了参数模型，确保选择子集内的数据分布一致性和多样性，并保证数据质量。实验结果显示，使用仅10K样本，该方法在HumanEval和MBPP上的性能分别比92K全样本基础方法提高了2.4%和2.3%，在性能和效率上均优于其他采样方法，表明该方法有效提高了模型性能并大幅降低了计算成本。", "conclusion": "研究结果表明，该方法不仅有效提升了模型性能，还显著降低了计算成本。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02357", "html_url": "https://arxiv.org/abs/2507.02357", "title": "Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models", "title_en": "Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models", "authors": "Christian Jaumann,Annemarie Friedrich,Rainer Lienhart", "background": "该论文描述了作者团队在2025年SciVQA共享任务中的系统。SciVQA是一项专注于科学可视化问答的挑战。背景信息包括使用多模态大型语言模型和少量样本检索策略，根据图表和问题类型进行模型和少量样本设置的选择，以及基于模型信心水平选择答案。系统的性能指标展示了在盲测数据上的排名和平均F1分数。论文主题是在大语言模型上进行多模态的科学可视化问答系统开发，通过少量样本检索和基于信心的组合方法提升系统性能。", "innovation": "论文的创新在于使用了两种多模态大型语言模型的集成方法，并结合了多种少量样本检索策略。根据图表和问题类型选择模型和少量样本设置，并基于模型的信心水平选择答案。此外，该系统在盲测数据上取得了不错的表现，排名第三，平均F1分数达到85.12。同时，代码已经公开，以便其他人进一步研究和应用。这些方法提高了系统的灵活性和准确性，特别是在处理复杂的科学可视化问题时。", "conclusion": "该系统在2025年SciVQA共享任务中展现了良好的性能，排名第三，且平均F1分数达到85.12。该研究展示了在大语言模型上进行多模态科学可视化问答的有效方法，通过少量样本检索和基于信心的组合策略提高了系统的性能。此外，公开的代码将有助于该领域的进一步研究。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02428", "html_url": "https://arxiv.org/abs/2507.02428", "title": "社区驱动的低资源语言受损语音数据收集烹饪书", "title_en": "A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages", "authors": "Sumaya Ahmed Salihs,Isaac Wiafe,Jamal-Deen Abdulai,Elikem Doe Atsakpo,Gifty Ayoka,Richard Cave,Akon Obu Ekpezu,Catherine Holloway,Katrin Tomanek,Fiifi Baffoe Payin Winful", "background": "本文介绍了一种方法，用于收集受损语音样本，以构建自动语音识别（ASR）模型，尤其是为低资源语言建设ASR模型。研究目的是通过制定最佳实践和进行社区驱动的数据收集和ASR模型构建培训，来民主化ASR技术和数据收集。本研究以高加纳广泛使用的印第安语为例，创建了首个开源受损语音数据集。研究参与了来自不同背景的受损语音参与者。研究成果、烹饪书和开源工具均公开发布，以使研究人员和从业者能够创建适合语音受损个体独特需求的包容性ASR技术。此外，还介绍了利用开源ASR模型对高加纳受损语音进行初步调优的结果。", "innovation": "提出了“烹饪书”方法，用于指导社区驱动的低资源语言受损语音数据收集与ASR模型构建，‘烹饪书’详述了最佳实践和培训内容，将ASR技术和数据收集民主化。首次创建了高加纳受损语音开源数据集，利用开源ASR模型对受损语音进行初步调优。", "conclusion": "研究结果表明，利用‘烹饪书’方法可以有效收集低资源语言受损语音数据，并通过开源工具进行共享。此外，针对特定语言受损语音的ASR模型进行了初步调优，展示了该方法的有效性。开源数据集和调优结果为研究人员和从业者提供了实现包容性ASR技术的良好基础。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02364", "html_url": "https://arxiv.org/abs/2507.02364", "title": "QFFN-BERT: 一项关于混合量子经典变换器的深度、性能和数据效率的经验研究", "title_en": "QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers", "authors": "Pilsung Kang", "background": "参数化量子电路（PQCs）近年来被证明是增强神经架构表达能力的有前途的组成部分。传统变换器模型中的前端网络（FFN）模块参数占据较大比例，大约占标准变换器编码器区块参数的三分之二。尽管先前的研究主要将PQCs集成到自我注意模块中，但这项工作关注于FFN模块，并系统地探讨了PQC深度、可表达性与训练性的权衡关系。实验结果表明，精心配置的QFFN-BERT在完全数据集设置中能够超过其经典对应物，同时将特定于FFN的参数减少了超过99%，并且在少数样本学习场景中表现出一致的竞争力，显示了其在数据效率方面的潜力。", "innovation": "QFFN-BERT将紧凑型BERT变体的前端网络（FFN）模块替换为基于PQC的层，特别注重FFN参数的影响，以及通过残差连接、RY和RZ旋转以及交替纠缠策略设计的PQC以确保稳定训练和高表达能力。", "conclusion": "实验结果表明，QFFN-BERT在SST-2和DBpedia基准测试中可达到基线准确率的102%，在数据充分的情况下超越了经典模型，同时减少了超过99%的特定于FFN的参数，并且在少数样本学习场景中表现出一致的竞争力，验证了PQCs作为参数效率和强大的经典FFN替代品的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02592", "html_url": "https://arxiv.org/abs/2507.02592", "title": "WebSailor：网络代理的超人类推理导航", "title_en": "WebSailor: Navigating Super-human Reasoning for Web Agent", "authors": "Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou", "background": "超越人类认知限制是大规模语言模型（LLM）训练的关键前沿领域。自有的代理系统如DeepResearch展示了在像BrowseComp这样的极其复杂的资料搜索基准测试中超越人类的能力，这是一个此前无法达成的成就。我们认为其成功的关键在于一种在开源模型中缺失的高级推理模式：系统地在庞大信息空间中减少极端不确定性的能力。基于此，我们提出了WebSailor，一种完全训练后的全流程方法，旨在赋予这种关键能力。该方法通过结构性样本生成和信息混淆、RFT冷启动以及高效的代理强化学习算法DUPO实现了这一目标。", "innovation": "WebSailor方法通过结构性样本生成、信息混淆、RFT冷启动和高效的DUPO算法，构建了一种集成流水线。这种方法显著提高了复杂资料搜索任务中的性能，达到或接近了自有机制代理的水平，填补了能力差距。WebSailor的主要创新点在于它能够显著提升模型在复杂信息搜索任务中的表现，同时通过复杂的训练策略确保模型能够在庞大的信息空间中更准确地减少不确定性。", "conclusion": "基于集成方法，WebSailor显著超越了所有开源代理在复杂信息搜索任务中的性能，达到了或接近了自有机制代理的表现，解决了代理系统在信息搜索领域的能力差距问题。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02506", "html_url": "https://arxiv.org/abs/2507.02506", "title": "IndianBailJudgments-1200: 一个针对印度保释命令的多属性数据集用于法律自然语言处理", "title_en": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders", "authors": "Sneha Deshmukh,Prathmesh Kamble", "background": "在印度这样的地区，法律自然语言处理（legal NLP）的发展滞后，主要归因于缺乏结构化的数据集。为此，该论文介绍了一个新的基准数据集——IndianBailJudgments-1200，它包含来自印度法院的1200份关于保释决定的判决书，并在20多个属性上进行了注释，包括保释结果、印度刑法（IPC）条款、犯罪类型以及法理分析。这一数据集用于支持法律自然语言处理任务，如结果预测、摘要生成和公平性分析。", "innovation": "该研究创新性地构建了首个专注于印度保释法律学说的公开数据集，采用了工程技术化的GPT-4o管道进行注释，并验证一致性。该数据集能够广泛支持法律自然语言处理任务，弥补了印度相关数据集的不足，并为该领域的发展提供支持。", "conclusion": "IndianBailJudgments-1200数据集对于推进法律自然语言处理领域的发展具有重要意义。它填补了印度在该领域的数据空白，为有关保释决定的研究提供了宝贵的资源。这一数据集的发布将有助于提高法律文本处理的准确性和效率。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02407", "html_url": "https://arxiv.org/abs/2507.02407", "title": "跨领域数据集中的阿坎语ASR模型基准测试：性能、可扩展性和适应性比较评估", "title_en": "Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability", "authors": "Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame", "background": "现有的大多数自动语音识别（ASR）研究使用特定领域的数据集来评估模型。然而，这些研究很少评估模型跨多种语音环境的能力。本研究通过使用四种阿坎语语音语料库来基准测试七种基于变压器结构的阿坎语ASR模型（如Whisper和Wav2Vec2），以确定它们在各种领域的性能，旨在弥合这一研究空白。研究使用包括文化相关图像描述、非正式对话、圣经阅读和自发金融对话等多种领域的数据集。研究发现，不同领域的依赖性在单词错误率和字符错误率的比较中得到体现，模型只能在其训练领域内表现出色，而在不匹配的情景中表现不佳。此外，研究还指出了Whisper和Wav2Vec2架构在错误行为上的差异，Whisper模型通常产生更具可读性的但可能误导性的错误，而Wav2Vec2模型则产生更明显但解读性较差的输出。这表明选择适合低资源语言（LRL）应用的架构时需要权衡可读性和透明度之间的trade-off。", "innovation": "本研究通过跨多种领域数据集基准测试多种阿坎语ASR模型，首次系统性地评估了它们在不同领域内的性能、可扩展性和适应性，并指出不同架构在处理陌生输入时的不同表现，为低资源语言ASR系统的开发提供了有价值的信息和研究方向。", "conclusion": "研究发现显示了低资源语言ASR系统开发的需求，即需要针对性的领域适应技术，适应性路由策略和多语言训练框架。这些发现强调了在选择适合低资源语言的ASR架构时，需要考虑可读性和透明度之间的trade-off。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02679", "html_url": "https://arxiv.org/abs/2507.02679", "title": "探索职业头衔之外的性别偏见", "title_en": "Exploring Gender Bias Beyond Occupational Titles", "authors": "Ahmed Sabir,Rajesh Sharama", "background": "该研究调查了性别与语境偏见之间的关联，重点关注动词、名词以及职业类别。研究者引入了一个新数据集GenderLexicon和一种框架，能够估计语境偏见及其相关性别偏见，并量化解释性别偏见。研究还发现，性别偏见不仅仅存在于职业刻板印象中。为了验证方法的有效性，研究在包括一个日语数据集在内的五种不同数据集上进行了评价。", "innovation": "该研究创新地提出了GenderLexicon数据集和框架，用于量化和解释性别偏见，提高了性别偏见的可解释性。研究扩展了对性别偏见的理解，表明它不仅存在于职业刻板印象中，还存在于其他类别中。此外，研究在不同语言的数据集上进行了验证，增强了研究的普适性。", "conclusion": "研究确认了性别偏见的存在，不仅限于职业刻板印象。通过引入GenderLexicon数据集和框架，研究提高了对性别偏见的理解和解释能力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02595", "html_url": "https://arxiv.org/abs/2507.02595", "title": "MPF: 根据多视角融合在部署后调整和去偏语言模型", "title_en": "MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion", "authors": "Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama", "background": "随着大型语言模型（LLMs）的广泛应用，人们对减少模型偏见的需求日益增长，现有的后训练对齐框架需要很高的专业技术，因此需要一种更简单易用的方法来解决这一问题。MPF（Multiperspective Fusion）框架就是在这种背景下提出的，它基于SAGED管道，一个用于构建偏见基准并提取可解释的基础分布的自动化系统，旨在通过多视角生成来揭示和对齐LLMs输出与细腻、具有人性化的基准之间的一致性。", "innovation": "MPF的主要创新在于通过分解基线（例如，从人力资源专家那里获取的情感分布）为可解释的视角组件，引导生成过程，通过加权采样和平衡响应来进行调整。这种方法能够使LLMs的情感分布与反事实基准（绝对对齐）和人力资源基准（偏向顶尖大学）相匹配，从而实现了较小的KL散度，减少了校准误差，并在未见过的问题上表现出良好的泛化能力。这表明MPF提供了一种可扩展且具有解释性的对齐和偏见缓解方法，适用于部署中的LLMs，并且不需要进行广泛的提示工程或微调。", "conclusion": "实验证明，MPF能够在确保LLMs输出与既定基准之间保持一致的同时，有效减少偏见，同时保持模型的可解释性和灵活性，使其成为一种适用于部署的LLMs的高效且可扩展的方法，确保其通过多视角融合后仍然能够进行有效的语言模型调整和去偏处理。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02744", "html_url": "https://arxiv.org/abs/2507.02744", "title": "通过Just Producible Difference (JPD)阈值测量元音产生空间的颗粒度", "title_en": "Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens", "authors": "Peter Viechnicki", "background": "过去几十年的研究展示了人类元音发声的复杂协调articulatory运动主要受控于目标为听觉空间区域的控制机制。已在子音位级层面证明了控制的存在，但其精确程度仍未知。当前研究通过询问两个元音刺激在听觉空间中需相隔多远才能可靠地产生不同的模仿，以回答这一问题。这一距离被称为'Just Producible Difference'（JPD）。", "innovation": "首次使用元音模仿范式在两个英語发音群体的前元音生产中测量了JPD，并估计其范围为F1 X F2空间中的14到51梅尔。这一发现对语音产生中的事件理论有重要影响，并为人类元音系统的可能结构设定了理论下限，从而为观察到的元音音位数量和模式提供了心理物理解释。", "conclusion": "JPD的测量结果对理解人类语音产生机制具有重要意义，它不仅为语音生产中的控制机制提供了新的认识，还为解释人类元音系统的特征提供了重要的物理基础。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02593", "html_url": "https://arxiv.org/abs/2507.02593", "title": "重新审视（人类）标签变异下的主动学习", "title_en": "Revisiting Active Learning under (Human) Label Variation", "authors": "Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher", "background": "高质量标注数据的获取仍然是实际监督学习中的限制因素。尽管在自然语言处理等领域中普遍存在标签变异现象，但现有的标注框架通常假设只有一个绝对准确的标签（单真理假设），没有考虑人类标签变异（HLV）这一因素作为有价值的信息。此外，主动学习作为一种可以优化有限标注预算的流行方法，也依赖于一些简化假设，在人类标签变异这一现实中通常是不成立的。因此，本文旨在重新审视关于真正和标签本质的基本假设，并指出需要将观察到的标签变异分解为信噪比（信号如HLV和噪音如标注错误），审视AL和HLV社区如何应对或忽视这些区分，并提出一个概念框架，以在AL循环的各个阶段纳入HLV，涵盖实例选择、注释者选择和标签表示。还讨论了大型语言模型作为注释者的整合。这项工作旨在为HLV意识下的主动学习奠定概念基础，更好地反映现实世界的注释复杂性", "innovation": "本文创新性地提出了将人类标签变异（HLV）纳入主动学习（AL）过程的概念框架，解决了传统的单真理假设问题，并且还探讨了大型语言模型在其中的应用，旨在提供一个更贴合实际的标注数据使用方案", "conclusion": "本文为HLV意识下的主动学习奠定了基础，强调了将HLV分解为信号和噪音的重要性，并提出了一个概念性框架，这有助于改进现有的标注方法，更好地适应实际标注过程中的复杂情况"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02694", "html_url": "https://arxiv.org/abs/2507.02694", "title": "LLMs能否识别科学研究中的关键限制？基于AI研究论文的系统评估", "title_en": "Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers", "authors": "Zhijian Xu,Yilun Zhao,Manasi Patwardhan,Lovekesh Vig,Arman Cohan", "background": "同行评审是科学研究的基础，但日益增长的出版物数量加重了这一专属性强的过程的挑战。尽管LLMs在各种科学任务中表现出潜力，但它们在帮助进行同行评审方面，尤其是识别论文局限性方面的潜力尚待研究。为此，我们首先构建了科学研究中局限类型的一份全面分类，重点是AI领域。在此基础上，为研究局限性，我们提出了LimitGen基准，这是首个全面评估LLMs支持早期反馈、补充人类同行评审能力的基准。基准数据集包含两个子集：LimitGen-Syn合成数据集和LimitGen-Human人类撰写的局限性集合。通过增强LLMs系统以进行文献检索，我们使这些系统能够更好地识别局限性，从而提供更具体和建设性的反馈，增强其生成研究论文中局限性的能力。", "innovation": "我们提出了首个全面的LLM评估基准LimitGen，包含合成数据集LimitGen-Syn和人类撰写的局限性集合LimitGen-Human。我们还增加了文献检索功能，使LLMs能够更好地识别研究论文中的局限性，提供更为具体的反馈。这是我们对LLMs在科学领域，特别是AI领域的局限性识别能力进行系统评估的第一步。", "conclusion": "我们的研究增强了LLMs在生成研究论文局限性方面的能力，使它们能够提供更具体和建设性的反馈，从而提高了对科学领域研究方法的理解和改进。通过系统评估，我们揭示了LLMs在识别关键局限性方面的潜力及其改进空间。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02804", "html_url": "https://arxiv.org/abs/2507.02804", "title": "具有多样化解题视角的多模态数学推理", "title_en": "Multimodal Mathematical Reasoning with Diverse Solving Perspective", "authors": "Wenhao Shi,Zhiqiang Hu,Yi Bin,Yang Yang,See-Kiong Ng,Heng Tao Shen", "background": "近年来，大规模强化学习（RL）的进步显著提升了大语言模型（LLMs）的推理能力，特别是在数学领域。然而，当前用于数学推理的多模态大语言模型（MLLMs）往往依赖于一对一的图像-文本对和单一的解题监督，忽视了多种有效的推理视角和内部反思的多样性。", "innovation": "本文引入了MathV-DP，这是一种新的数据集，用于捕捉每幅图像问题配对的多样解题轨迹，从而促进更丰富的推理监督。此外，还提出了基于Qwen-VL的Qwen-VL-DP模型，该模型通过监督学习进行微调，并通过结合正确性鉴别和多样性奖励函数的组相对策略优化（GRPO）进行增强。该方法强调从多种推理视角学习，并区分正确但不同的解决方案。实验证明Qwen-VL-DP在准确性和生成多样性方面显著优于先前的基线LLMs，突显了纳入多样视角和反思推理的重要性。", "conclusion": "广泛的实验表明，Qwen-VL-DP在数学Vista的小测验和Math-V基准上超越了先前的基线MLLMs，在准确性和生成多样性方面表现优异，强调了在多模态数学推理中纳入多样视角和反思推理的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02850", "html_url": "https://arxiv.org/abs/2507.02850", "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "title_en": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "authors": "Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas", "background": "本文描述了语言模型（LMs）中由用户反馈训练时存在的漏洞，一个用户仅通过提供提示和对LM输出进行点赞/点踩反馈的能力，就可以持续改变LM的知识和行为。研究者通过操控LM的输出和反馈信号，展示了如何利用这种漏洞进行攻击，从而在模型中植入新的事实知识、修改代码生成模式引入可利用的安全漏洞、以及注入虚假的金融新闻。", "innovation": "该研究揭示了语言模型偏好调优的一种全新特征，即即使是非常有限形式的偏好数据（如用户的点赞/点踩反馈）也能用来对模型的行为进行细微的控制。同时，这是一种针对使用用户反馈训练的语言模型的新攻击机制，扩展了预训练阶段数据中毒和部署阶段提示注入的相关研究。", "conclusion": "研究者展示了如何通过巧妙地设计用户反馈来操纵语言模型的行为，从而实现对模型知识的未经授权的注入。这不仅证明了有限的用户反馈也可以对模型行为产生深远影响，同时也为安全研究者提供了新的攻击示例，提醒开发人员在设计和使用语言模型时需要对用户反馈的影响进行深入考虑。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02822", "html_url": "https://arxiv.org/abs/2507.02822", "title": "SynapseRoute：双重状态大型语言模型上的自动路由切换框架", "title_en": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model", "authors": "Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun", "background": "随着大型语言模型（LLMs）在实际应用中的广泛应用，选择合适的模型需要平衡性能和运营成本。具备推理能力的模型增加了高推理（高计算量）模式和低推理（低成本、快速）模式之间的成本差距。研究表明，大约58%的医疗问题可以通过低推理模式独立准确回答，无需高成本推理过程。这一发现揭示了问题复杂度的明确差别，并提示可以根据问题复杂度动态路由查询以优化准确性和成本效率，并提升整体用户体验。", "innovation": "本文提出了一种基于机器学习的动态路由框架——SynapseRoute，该框架能够智能地将输入查询分配给高推理或低推理模式。通过在多个医学数据集上的实验验证，SynapseRoute不仅在整体准确性上优于单独使用高推理模式（提升了0.8390 vs 0.8272），还减少了36.8%的推理时间和39.66%的令牌消耗。此外，自动路由避免了在简单查询上过度推理导致的延迟和准确性降低的问题。", "conclusion": "本文进一步引入了准确性-推理-令牌（AIT）指数，用于全面评估准确率、延迟和令牌成本之间的权衡。该工作展示了SynapseRoute在双重状态LLMs上的自动路由切换能力，强调了根据问题复杂度动态路由查询的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02778", "html_url": "https://arxiv.org/abs/2507.02778", "title": "Self-Correction Bench: 揭示和解决LLMs中的自我纠正盲点", "title_en": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs", "authors": "Ken Tsui", "background": "尽管大型语言模型（LLMs）已经变得非常变革性，但它们仍然会犯错误并且可能探索无生产力的推理路径。自我纠正是一种对可信LLMs特别是自回归LLMs来说非常重要的能力。然而，LLMs在同一类型错误在用户输入中能识别错误但无法纠正自身输出中的相同错误，展现出一种系统性的‘自我纠正盲点’。为系统研究这一现象，本研究引入了Self-Correction Bench，一种通过控制性在三个复杂度级别中注入错误来衡量这一现象的系统性框架。研究测试了14个模型，发现平均存在64.5%的自我纠正盲点率。分析结果显示，这有限制与训练数据的组成有关：人类训练示范主要展示无错误响应，而不同于通过结果反馈学习纠正错误的RL训练模型。简单地添加“等待”可以减少89.3%的盲点率，表明这种能力存在，但需要激活。这项工作突显了当前LLMs中的关键限制，并提出了提高其可靠性和可信度的潜在途径", "innovation": "本研究引入了Self-Correction Bench，一种通过控制性在三个复杂度级别中注入错误的系统性框架，用于系统研究LLMs中自我纠正的盲点现象。通过实验证明了盲点与训练数据组成的关联，并提出简单地添加“等待”可以显著减少盲点率", "conclusion": "当前的LLMs存在关键限制即自我纠正盲点，这种盲点可能限制了它们的有效性。此研究通过系统的方法揭示了这一现象，并提出了激活已存在自我纠正能力的潜在途径，从而增强其可靠性与可信度。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01984", "html_url": "https://arxiv.org/abs/2507.01984", "title": "使用早期融合的语义、视觉和社会特征进行多模态错误信息检测", "title_en": "Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features", "authors": "Gautam Kishore Shahi", "background": "研究背景：在选举和危机期间社交媒体上的错误信息泛滥，已经有大量关于错误信息检测的研究，主要集中在文本或图像方法上。然而，只有少数研究探索了多模态特征组合的方法，如结合文本和图像建立分类模型以检测错误信息。文章分析了1529条疫情期间和选举时期的推文，利用数据丰富化的方法提取了额外的社会和视觉特征。结果显示，结合无监督和监督机器学习模型比单一模态模型提高15%的分类性能，比双模态模型提高5%。此外，文章根据错误信息推文及其传播者的特征分析了错误信息的传播模式。", "innovation": "创新点：使用早期融合的方法将语义、视觉和社会特征结合，应用于错误信息的分类模型，结果显示其分类性能相较于单一模态模型和双模态模型有显著提高，并通过数据丰富化的方式提取了更丰富的特征。", "conclusion": "结论：该研究通过结合不同模态特征，提高了错误信息分类模型的性能。结合无监督学习和监督学习的模型表现出更好的分类效果，尤其是在疫情期间和选举期间的错误信息检测上。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02851", "html_url": "https://arxiv.org/abs/2507.02851", "title": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "title_en": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "authors": "Purbesh Mitra,Sennur Ulukus", "background": "大型语言模型（LLMs）最近在推理能力方面取得了进步，表明使用群组相对策略优化（GRPO）算法进行强化学习（RL）训练可以促使模型生成更多涉及思考/推理的令牌，从而生成更好的回复。然而，LLMs在保持对先前生成令牌的注意时，只能生成有限数量的令牌。这个限制，也称为LLM的上下文大小，是LLM进行任意数量令牌推理时的瓶颈。为了解决这个限制，LLMs必须采用模块化思考策略，可以在多轮中进行推理以思考超出上下文大小的限制。", "innovation": "本文提出了一种名为MOTIF（Modular Thinking via Reinforcement Finetuning）的方法，这是一种RL训练方法，可以在多轮中生成思考令牌，从而使模型能够在额外的上下文大小下思考。训练了开源模型Qwen2.5-3B-Instruct对GSM8K数据集进行了参数高效微调，并在MATH500和AIME2024基准上进行了测试。实验结果表明，与基于GRPO训练的基线相比，在这些基准上分别提高了3.8%和3.3%，同时仅使用了15%的数据样本，展示了MOTIF的样本效率。", "conclusion": "我们的代码和模型可在以下链接获取：this https URL和this https URL。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02856", "html_url": "https://arxiv.org/abs/2507.02856", "title": "答案匹配在语言模型评估中表现优于多项选择", "title_en": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation", "authors": "Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping", "background": "语言模型评估长期以来依靠多项选择基准，因为自动批改多项选择题客观且容易。然而，研究表明，多项选择题中的问题往往通过简单的技巧就能回答，而不必真正理解问题。这是因为多项选择评估存在特有的局限性，这不同于评估模型生成自由形式回答的评价方法。直至近期，似乎没有可行的可规模化的替代方案来替代多项选择，但研究证明，情况已经改变。研究者提出了一种新的评估方法——答案匹配：将候选模型的测试问题呈现给它而不给选项，让其生成自由形式的回应，然后使用现代语言模型与参考答案进行匹配，判断回应是否与参考答案匹配。这样可以比较不同评估策略的有效性。对数据集进行注释，并使用人工评分数据，研究如何不同评估方法的一致性。研究发现，使用现代模型的确实匹配方法即使小模型也可以获得几乎完美的一致性，而在人工评分上与机器人力判断相比要差得多。", "innovation": "研究通过提出答案匹配来评估语言模型的方法，展示即使使用小模型，这种方法也能够获得几乎完美的一致性，在人工评分上也表现出色。这种方法在评估模型自由形式回答时效果显著优于传统的多项选择评估和仅凭大模型作为裁判的方法。", "conclusion": "研究结果表明，改进评估方法通过答案匹配不仅能改变对不同模型的排名，还有助于推动评估生态系统从多项选择转向答案匹配。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02833", "html_url": "https://arxiv.org/abs/2507.02833", "title": "验证性指令遵循的推广", "title_en": "Generalizing Verifiable Instruction Following", "authors": "Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi", "background": "人类与AI之间的有效交互依赖于语言模型或聊天机器人准确地遵循人类指令。尽管当前最强大的模型在遵循指令方面已经取得了显著进展，但它们仍然难以满足输出限制等细节要求，例如只能回答“是”或“否”，或要求在回答中至少提及某个特定词汇若干次。研究发现，大多数模型在验证性基准测试的少量特定验证性约束上过度拟合，而在未见过的输出约束上的泛化能力较弱。因此，需要一个新的基准和数据集来评估模型能否妥善遵循未见过的验证性指令，并理解在哪些数据上训练模型能提高其泛化能力，以便改善指令遵循的准确性与范围。", "innovation": "本文提出了一个名为IFBench的新基准，用于评估模型在处理未见过的验证性约束方面的泛化能力，共涵盖了58个新、多样且具有挑战性的验证约束。研究设计了约束验证模块，并通过实验证明了一种新的基于可验证奖励的强化学习方法（RLVR）能显著提高指令遵循的效果。此外，还提供了额外的29个新的人工标注训练约束和验证函数，以及RLVR训练提示和源代码，以供进一步研究和使用。", "conclusion": "本文通过引入新的IFBench基准和RLVR方法，系统地评估了指令遵循的泛化能力，并提供了一套新的验证约束和函数，为提高模型遵循指令的一致性和灵活性提供了有力支持。未来可以根据IFBench基准持续优化模型，特别是在新出现的多样性约束上的表现，以促进人机交互的有效性和普及性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02799", "html_url": "https://arxiv.org/abs/2507.02799", "title": "推理即一切吗？探究推理语言模型时代的偏见", "title_en": "Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models", "authors": "Riccardo Cantini,Nicola Gabriele,Alessio Orsino,Domenico Talia", "background": "推理语言模型（RLMs）通过链条推理（CoT）提示或微调推理痕迹等机制，能够执行复杂的多步推理任务。虽然这些能力提高了可靠性的前景，但它们对减少社交偏见的鲁棒性影响仍然不清楚。本文通过利用用于大语言模型（LLMs）的CLEAR-Bias基准，探讨了推理能力对于偏见发现的对抗鲁棒性。通过系统评估最新的RLMs，并使用大语言模型作为法官的方法进行自动安全性评分，此次研究揭示了推理能力和偏见安全性的复杂关系，并验证了推理机制与安全性的关联，尤其是推理和链条推理提示的效果对比，评估了根据推理机制用于偏见触发对抗攻击的成功率。研究结果显示，具有明确推理能力的模型（无论是通过链条式推理提示还是微调推理痕迹）通常比没有这些机制的基础模型更容易受到偏见触发攻击，这表明推理可能无意间为刻板印象的强化打开了新的途径。链条推理提示的模型特别容易受到通过讲故事提示、虚构角色或奖励型指令进行的上下文重塑攻击。这些结果挑战了推理必然提高鲁棒性的假设，并强调了设计时需要有更多意识避免偏见的方法。", "innovation": "本文利用CLEAR-Bias基准设计系统地评估了RLMs的对抗鲁棒性，特别是在社会文化维度上。通过引入LLM作为法官的方法进行自动化安全评分，并利用破解方法来评估内置的安全部署策略，提供了一个新的视角来审视推理能力和偏见安全性的关系。研究得出了推理能力和偏见安全之间复杂的相互关系，并发现了可受益于推理的机制（如链条推理提示）和容易受到攻击的机制（如奖励型命令），为改进推理语言模型的设计和使用提供了方向。", "conclusion": "本文的研究表明，推理能力与偏见安全性之间存在复杂的相互关系，而简单地依赖推理并不一定能提高模型的鲁棒性和公平性。具有明确推理能力的模型，无论是通过链条推理提示还是微调推理痕迹，通常比没有这些机制的基础模型更容易受到偏见触发攻击的影响。链条推理提示的模型显示出相对更低的安全性，相较于验证码提示，它们更容易受到上下文重塑攻击的影响。这些结果提出了一种新的质疑：认为推理必然提高鲁棒性的假设，并强调了在设计和使用推理语言模型时需要更加重视偏见预防的方法。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02176", "html_url": "https://arxiv.org/abs/2507.02176", "title": "分析与提升语音合成中的说话人相似性评估", "title_en": "Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis", "authors": "Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi", "background": "语音身份建模因其多维度的特性而具有挑战性。在生成性语音系统中，语音身份通常通过自动说话人验证（ASV）嵌入来评估，这些嵌入主要用于区分而不是描述身份特征。本文探讨了在这些嵌入中捕获的语音特性方面。我们发现广为使用的ASV嵌入主要关注静态特征如音色和音域，而忽略了节奏等动态元素。此外，我们还识别了影响说话人相似性测量的一些混杂因素，并提出了相应的缓解策略。为了弥补这些不足，本文提出了U3D度量，用于评估说话人的动态节奏模式。这项工作有助于评估语音克隆系统中说话人身份一致性这一持续挑战。我们已公开发布了我们的代码以供使用", "innovation": "提出了一种新的评估标准U3D，用于评估说话人的动态节奏模式。此外，指出了当前使用ASV嵌入所忽视的动态元素，并提出了缓解策略", "conclusion": "本文的研究有助于解决语音克隆系统中说话人身份一致性评估的持续挑战，并公开提供了改进说话人相似性评估的代码"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02004", "html_url": "https://arxiv.org/abs/2507.02004", "title": "STELLA: 自适应生物医学研究的自进化LLM代理", "title_en": "STELLA: Self-Evolving LLM Agent for Biomedical Research", "authors": "Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong", "background": "生物医学领域的数据、工具和文献迅速增长，形成了一个超出了人类专业知识的分割研究环境。虽然人工智能代理提供了解决方案，但它们通常依赖于静态、人工编纂的工具集，限制了其适应性和扩展性。", "innovation": "本文引入了STELLA，一种自进化的人工智能代理，通过一个自我进化的模板库和一个动态性的工具海洋，自主提高自己的能力。STELLA能够通过模板库和工具海洋的自动化发现和整合新的生物信息学工具来学习经验，表现出色的生物医学基准测试结果，包括接近26%的人类最后一次医学考试的准确性，54%的LAB-Bench: DBQA，和63%的LAB-Bench: LitQA，并且性能随着经验的积累而系统性地提高，例如其在人类最后一次医学考试基准测试的表现几乎翻倍。", "conclusion": "STELLA代表了一种重要的进步，向着能够学习和成长的人工智能系统发展，使它们的专长动态扩展，以加速生物医学发现的进程。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02000", "html_url": "https://arxiv.org/abs/2507.02000", "title": "为何多兴趣公平性至关重要：基于超图对比多兴趣学习的公平对话推荐系统", "title_en": "Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System", "authors": "Yongsen Zheng,Zongxuan Xie,Guohua Wang,Ziyao Liu,Liang Lin,Kwok-Yan Lam", "background": "推荐系统（RSs）中的不公平性是一个众所周知的挑战，可能导致基于性别、种族、年龄或流行度等属性的用户或项目受到不利影响。尽管一些方法已经开始在离线或静态环境中改进推荐公平性，但不公平性问题会随着时间加剧，导致诸如马太效应、过滤气泡和回声室等严重问题。", "innovation": "本文提出了一种名为HyFairCRS的新框架，该框架结合了基于超图对比多兴趣学习的方法，旨在促进动态互动对话推荐系统（CRSs）中的多兴趣多样性公平性。通过对比学习建立多样的超图来捕捉用户的广泛兴趣，并在对话中利用这些兴趣生成信息性回应，确保在动态用户-系统反馈循环中实现公平的项目预测。", "conclusion": "在两个基于CRS的数据集上进行的实验表明，HyFairCRS实现了最先进的性能，同时有效缓解了不公平性问题。我们的代码可以在以下链接中找到。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01991", "html_url": "https://arxiv.org/abs/2507.01991", "title": "FinAI-BERT: 基于Transformer的金融报告中AI披露的句级检测模型", "title_en": "FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports", "authors": "Muhammad Bilal Zafar", "background": "金融服务业中人工智能（AI）的广泛应用激发了对能够系统检测企业披露文件中AI相关信息的工具的需求。此前的方法大多依赖关键词扩展或文档级分类，但在粒度、可解释性和稳健性方面存在不足。", "innovation": "本研究提出了FinAI-BERT，一种针对金融文本中AI相关内容进行句级分类的领域自适应变压器语言模型。该模型基于1,586条精心筛选且平衡的数据集进行微调，该数据集来自2015年至2023年美国银行的669份年报。FinAI-BERT在分类性能上表现出色，准确率达99.37%，F1分数达0.993，优于传统基线模型（如逻辑回归、朴素贝叶斯、随机森林和XGBoost）。通过基于SHAP的标记解释确保了可解释性，并通过偏见分析和稳健性检查确认了模型在不同句子长度、对抗输入和时间样本中的稳定性。", "conclusion": "该研究通过利用变压器架构实现了细粒度的主题特定分类，在理论上推进了金融自然语言处理（NLP）领域。在实践中，它提供了一种可扩展、透明的解决方案，以供分析师、监管机构和学者监控金融机构中AI的扩散和表述。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02087", "html_url": "https://arxiv.org/abs/2507.02087", "title": "评估大型语言模型在招聘决策中的机遇与挑战", "title_en": "Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions", "authors": "Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia", "background": "大型语言模型（LLMs）在招聘中的应用旨在简化候选人筛选流程，但同时也引发了关于准确性和算法偏见的重大关注。现有研究显示，如果缺乏足够的安全措施，这些模型可能在招聘场景中传播社会偏见。本文通过比较多个最先进的基础LLM（包括OpenAI、Anthropic、Google、Meta和DeepSeek等公司开发的模型）与本团队专有的领域特定招聘模型（Match Score）的效果，评估了它们在候选人匹配中的预测准确性和公平性（使用ROC AUC、Precision-Recall AUC和F1-score指标，以及影响比分析来衡量公平性）。实验数据覆盖了大约10,000个真实的候选人-职位配对，结果显示Match Score在准确性和公平性方面均优于一般的LLM模型。", "innovation": "本文通过实证研究首次将LLM在招聘中的表现与领域特定的监督模型进行直接对比。研究表明，在缺乏适当防止偏见措施的情况下，通用的LLM模型在招聘场景中可能会传播社会偏见，而定制的监督模型则能更有效地缓解这些问题。因此，本研究证明在高风险的领域如招聘中部署AI时，领域特定建模和偏见审计的重要性。研究还显示，精心设计的算法能够在保证招聘准确性的前提下实现公平结果，打破了准确性和公平性不可兼得的假设。", "conclusion": "本研究强调了在招聘等重要领域部署AI的重要性，提倡在使用LLM等工具之前进行全面的公平性保护措施。研究结果表明，定制的监督模型比通用的LLM模型在招聘中的表现更好，能够确保更高的准确性和更公平的结果，为招聘实践提供了指导性建议。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02135", "html_url": "https://arxiv.org/abs/2507.02135", "title": "剖析移动DVFS管理器对LLM推理性能和能效的影响", "title_en": "Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency", "authors": "Zongpu Zhang,Pranab Dash,Y. Charlie Hu,Qiang Xu,Jian Li,Haibing Guan", "background": "大规模语言模型（LLMs）正在被广泛地集成到数十亿移动设备上的各种应用和服务中。然而，在资源有限的移动设备上部署LLMs带来了巨大的挑战，因为它们对计算、内存和最终能量的需求很高。尽管目前移动环境中的LLM框架利用了CPU、GPU和内存这三大能耗大的组件，但现代移动设备中的优化DVFS（动态电压和频率调整）管理器是独立工作的，并且彼此之间缺乏协作和信息共享。基于这一观察，本文首先测量了一种先进LLM框架在移动设备上的能效，结果显示移动管理器的组合会导致多达40.4%的预填充和解码延迟增加，而在相同的能量消耗下，CPU、GPU和内存频率的最优组合则可以实现更短的延迟。接着，通过深入实地测量研究，发现移动管理器之间复杂交互的缺乏或不足是导致LLM推理效率低下的原因。最后，根据这些洞察，设计了FUSE——一种统一的能量感知管理器，旨在优化移动设备上LLM推理的能效。", "innovation": "该研究突破了以往对移动设备中独立操作的DVFS管理器的研究，首次提出了FUSE——一种统一的能量感知管理器，能够优化移动设备上LLM推理的能效。该方法通过优化CPU、GPU和内存的频率组合，在相同的能量消耗下，显著减少了LLM推理的时间延迟，特别是在各种移动LLM模型上平均减少了7.0%-16.9%的“首次输出延迟”和25.4%-36.8%的“每输出延迟”。", "conclusion": "通过引入FUSE，研究为企业和开发者提供了一种新的方法来优化移动设备上LLM推理的能效，从而加速LLM推理过程，并延长移动设备的电池寿命。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02212", "html_url": "https://arxiv.org/abs/2507.02212", "title": "SciGA：学术论文中设计图形摘要的综合性数据集", "title_en": "SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers", "authors": "Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi", "background": "图形摘要（GAs）在科学论文中起着关键作用，有助于视觉传达研究的主要发现。尽管科学文献中越来越普遍使用如Figure 1等作为事实上的图形摘要，但对于它们如何增强科学交流的研究仍相对较少，且设计有效的图形摘要需要先进的视觉化技能，这为它们的广泛采用设定了障碍。基于这些挑战，本文提出SciGA-145k，这是一个包含约145,000篇科学论文及114万个插图的大型数据集，旨在支持图形摘要的选择和推荐，并促进自动化图形摘要生成的相关研究。", "innovation": "SciGA-145k是一个大规模数据集，专为支持图形摘要的选择和推荐，以及促进自动化图形摘要生成的研究而设计。它定义了两个任务：1) 内部图形摘要推荐，识别适合某篇论文中的某个图形摘要的插图；2) 外部图形摘要推荐，从其他论文中检索图形摘要以启发新的图形摘要。此外，论文还提出了一个基于信心调整的 top-1 地面真实比例 (CAR) 新推荐指标，以更细致地分析模型行为。", "conclusion": "SciGA-145k通过统一这些任务和指标，为推动视觉科学交流建立了基础，并对用于科学的AI的发展作出了贡献。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "Energy-Based Transformers are Scalable Learners and Thinkers", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "当前，与人类系统2思考类似的学习时计算技术已成为提高模型性能的热门方法，但大多数现有方法存在局限性，如模态特定（如仅适用于文本）、问题特定（如可验证的数学和编程领域）或需要额外的监督/训练（如验证器或可验证奖励）。研究者试图开发能在无监督学习的基础上自主思考和验证的模型，直到收敛预测。", "innovation": "提出了一种名为Energy-Based Transformers (EBTs)的新类模型，通过计算输入和候选预测对的能量值，并使用梯度下降法进行能量最小化，从而克服现有方法的限制。EBTs在训练过程中比当前主导的Transformer++方法具有更快的扩展性，在不同模态（文本和视觉）下，能够达到更高的数据、批量大小、参数、FLOPs和深度扩展率。在推断阶段，EBTs比Transformer++在语言任务中提高了29%的性能，并且在图像去噪任务中使用更少的前向传递次数，优于Diffusion Transformers。此外，研究发现EBTs在下游任务中的表现优于现有模型，即使预训练性能较差也能够取得更好的结果，表明EBTs比现有方法更具普遍适用性。因此，EBTs为增强模型的学习和思考能力提供了一个有前景的新范式。", "conclusion": "EBTs是比现有方法更强大的新模型类型，能够实现更快的扩展性，提高在不同任务中的表现，并且可能代表了未来模型学习和思考能力增强的新范式。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02200", "html_url": "https://arxiv.org/abs/2507.02200", "title": "ESTR-CoT: 采用链式思考推理实现可解释和准确的事件流场景文字识别", "title_en": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning", "authors": "Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang", "background": "事件流基于场景文字识别是一个近年来新兴的研究热点，相比传统的RGB相机在低光照和快速运动等极端挑战场景中表现更佳。现有的工作要么采用端到端的编码解码框架，要么利用大型语言模型增强识别，但仍然受到解释性不足和弱的上下文逻辑推理的限制。", "innovation": "提出了一个新颖的基于链式思考推理的事件流场景文字识别框架（ESTR-CoT），通过使用视觉编码器EVA-CLIP（ViT-G/14）将输入的事件流转换为标记，利用Llama分词器编码生成提示，并通过Q-former将视觉标记对准预训练的大语言模型Vicuna-7B，同时输出答案和链式思考（CoT）推理过程。此外，还提出了一种大规模的CoT数据集，通过生成、润色和专家验证三个阶段训练该框架，为后续基于推理的大模型发展提供坚实的数据基础。", "conclusion": "在三个事件流STR基准数据集（EventSTR、WordArt*、IC15*）上进行的大量实验全面验证了该提出框架的有效性和解释性。源代码和预训练模型将在此链接上发布：this https URL."}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02380", "html_url": "https://arxiv.org/abs/2507.02380", "title": "JoyTTS：基于大语言模型的语音合成对话机器人", "title_en": "JoyTTS: LLM-based Spoken Chatbot With Voice Cloning", "authors": "Fangru Zhou,Jun Zhao,Guoxin Wang", "background": "该论文介绍了一种名为JoyTTS的端到端语音合成对话机器人，它结合了大语言模型（LLM）和文本到语音（TTS）技术，并具备声音克隆能力。JoyTTS基于开源的MiniCPM-o和CosyVoice2模型，并经过2000小时的对话数据训练而成。", "innovation": "JoyTTS采用了基于大语言模型的技术，结合了大语言模型和文本到语音技术的最新进展，具有声音克隆能力。其测试结果在SS（讲话者相似度）评分为0.73，在词错误率（WER）为5.09，表现良好。", "conclusion": "JoyTTS 提供了完整的训练代码，便于社区进一步开发和优化。用户可以在指定的测试机器“seed-tts-zh”上获取测试结果，并可访问代码、模型和训练及推理脚本。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02287", "html_url": "https://arxiv.org/abs/2507.02287", "title": "透过绿色：基于文本分类与绿色专利的公司回报", "title_en": "Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents", "authors": "Lapo Santarlasci,Armando Rungi,Antonio Zinilli", "background": "本文探讨了自然语言处理在识别官方文件中的‘真实’绿色专利方面的作用。先前已有文献对一部分专利进行了绿色分类，本文以此为基础进行研究。研究所用的数据来源于约1240万项被归类为绿色的专利，旨在通过环境技术相关的表达词向量来扩展现有的词汇基础，训练一个简单的神经网络模型。研究发现，‘真实’绿色专利占之前文献中分类为绿色专利总数的大约20%。进一步分析显示，这些‘真实’绿色专利在技术类别上存在异质性，并且相较于一般的绿色专利，它们被后续发明引用的次数略少1%。", "innovation": "本文创新性地提出了利用自然语言处理技术来辨识‘真实’绿色专利的方法，并通过技术向量表示来扩展基础词汇库，以提高准确识别真实绿色专利的能力。研究还首次展示了‘真实’绿色专利与公司财务绩效之间的关系，发现持有至少一项‘真实’绿色专利可以提高公司的销售、市场份额及生产效率，并且在高新颖性绿色专利的情形下也能带来更高的利润。这些发现强调了通过文本分析来衡量更精细的专利分类对政策制定的重要性。", "conclusion": "研究结果强调了使用文本分析技术来更精细地划分专利分类的重要性，这些分类对不同领域内的政策制定具有重要意义。此外，‘真实’绿色专利的发现及其对公司业绩的积极影响证明了绿色创新在提升公司竞争力方面的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02666", "html_url": "https://arxiv.org/abs/2507.02666", "title": "ASDA: 音频光谱差异注意机制在自我监督表示学习中的应用", "title_en": "ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning", "authors": "Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang", "background": "近年来，在音频自监督表示学习方面的最新进展中，标准的Transformer架构已成为主要的方法，但其注意力机制往往将部分注意力权重分配给无关信息，可能削弱模型的判别能力。", "innovation": "为解决这一问题，本文引入了一种差异注意力机制，通过结合双重softmax操作和适当调整的差异系数，有效缓解了无效注意力分配的问题。实验结果显示，ASDA模型在多个基准测试中实现了最佳表现，包括音频分类（AS-2M上的49.0% mAP，AS20K上的41.5% mAP）、关键词定位（SPC-2上的98.3%准确率）和环境声音分类（ESC-50上的96.1%准确率）。这些结果突显了ASDA在音频任务中的有效性，为其在更广泛的应用中的推广奠定了基础。", "conclusion": "ASDA机制在多个音频任务中实现了SOTA性能，证实了其在音频自监督表示学习中的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02737", "html_url": "https://arxiv.org/abs/2507.02737", "title": "前沿大语言模型中早期隐写术能力的迹象", "title_en": "Early Signs of Steganographic Capabilities in Frontier LLMs", "authors": "Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner", "background": "随着大型语言模型（LLM）的广泛应用，监测其输出变得至关重要，以防止滥用和失控行为。然而，某些LLM可以通过隐写术来逃避监测，即在看似无害的生成中嵌入隐藏信息。本文旨在评估前沿LLM的隐写术能力，深入了解它们带来的风险。研究重点关注两种隐写术类型：传递编码信息和执行编码推理。研究发现，当前模型在标准条件下无法在其输出中隐写短消息而不被监控发现。但是，如果给予额外资源（如使用未监控的草稿区和协调使用的编码方案），它们可以成功隐写消息。此外，研究还发现，模型在简单的状态跟踪问题中可以执行基础的编码推理，包括使用自身和预定义方案（包括十六进制等编码方案）的能力。然而，它们很难将推理隐写在伪装任务中，以欺骗监控。这些发现表明，当前LLM展现出初步的隐写术能力，尽管这些能力目前可能不足以绕过精心设计的监控系统，但未来可能会发生变化。", "innovation": "本文创新性地评估了前沿LLM的隐写术能力，首次揭示了模型在简单状态下执行编码推理的早期迹象，并强调了外部资源如何增强其隐写能力。", "conclusion": "当前的LLM展示了初步的隐写术能力。虽然这些能力目前可能不足以绕过经过精心设计的监控系统，但未来可能会有所改变。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02652", "html_url": "https://arxiv.org/abs/2507.02652", "title": "分步规划与执行：一种用于深度搜索的分层推理框架", "title_en": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search", "authors": "Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou", "background": "现实世界的搜索场景需要在多种来源中进行深度推理和知识综合，而传统的检索增强生成（RAG）管道在这方面表现不佳。当前的基于推理的方法存在一个基本限制：它们使用单一模型来处理高层规划和详细执行，导致推理效率低下和扩展性受限。", "innovation": "本文提出了HiRA，这是一种分层框架，将战略规划与专业执行分离。我们的方法将复杂搜索任务分解为专注于子任务，每个子任务分配给特定领域的代理，并配以外部工具和推理能力，并通过结构化的集成机制协调结果。这种分离防止了执行细节打扰高层推理，同时使系统能够利用特定领域的专业知识来处理不同类型的信息处理。实验表明，HiRA在四个复杂的跨模态深度搜索基准上显著优于现有的RAG和基于代理系统。结果表明，答案质量和系统效率都有所提高，强调了解耦规划和执行对于多步骤信息搜索任务的有效性。", "conclusion": "我们的研究表明，HiRA在答案质量和系统效率上都显著优于现有的RAG和基于代理系统，这突出了解耦规划和执行对于多步骤信息搜索任务的有效性。我们的代码可在以下链接获取：[此链接](this https URL)."}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02790", "html_url": "https://arxiv.org/abs/2507.02790", "title": "从长视频到引人入胜的短视频：具有多模态叙述理解的人类启发编辑框架", "title_en": "From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding", "authors": "Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu", "background": "在线视频内容尤其是短视频平台上的快速增长，产生了对高效视频编辑技术的需求，以将长视频浓缩为简洁且吸引人的片段。现有的自动编辑方法主要依靠ASR转录的文本线索和端到端的片段选择，忽视了丰富的视觉上下文，导致输出不连贯。", "innovation": "本文提出了一个借鉴人类编辑方式的自动视频编辑框架（HIVE），该框架利用多模态叙述理解解决上述限制。该方法通过多模态大语言模型整合角色提取、对话分析和叙述总结，从而对视频内容有全面的理解。进一步为了提高连贯性，框架采用了场景级分割，并将编辑过程分解为三部分子任务：高光检测、开头/结尾选择和无关内容修剪。", "conclusion": "我们的框架在不同类型的编辑任务中都始终优于现有的基线，显著缩小了自动编辑和人工编辑视频的质量差距。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02618", "html_url": "https://arxiv.org/abs/2507.02618", "title": "大型语言模型中的战略智能：进化博弈论的证据", "title_en": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory", "authors": "Kenneth Payne,Baptiste Alloui-Cros", "background": "文章探讨了大型语言模型（LLMs）是否能作为一种新的战略智能形式，能够在竞争环境中进行目标推理。以贪心囚徒困境（IPD）为例，长期以来，IPD一直被用作研究决策过程的一种模型。开始时，研究者进行了历史上首次IPD演化锦标赛，对经典策略（如以牙还牙、严刑峻法）进行了测试，并与领先的AI公司（OpenAI、谷歌和Anthropic）的代理进行了比较。通过改变每次锦标赛中终止概率（即“未来的影子”），增加了复杂性和随机性，使记忆变得无效。研究结果显示，LLMs在这些复杂系统中表现出极高的竞争力，且有时甚至能够存活和繁殖。模型的理性分析揭示了它们在推理时间范围和对手策略方面做得很好，这对它们的决策至关重要。这项研究将经典的博弈理论与机器心理学联系起来，为在不确定环境下的算法决策提供了一种丰富的、细致入微的观点。", "innovation": "首次进行了IPD演化锦标赛，将大型语言模型与领先的AI公司进行比较；分析几乎32000个模型的书面理由，揭示模型在时间范围和对手策略上的推理能力；将经典的博弈理论与机器心理学相结合，为理解算法决策提供了新的视角。通过引入复杂性和随机性，挑战了记忆模型的有效性。", "conclusion": "研究表明，大型语言模型具有战略竞争力，能够依据时间范围和对手策略进行有效推理。这些模型还展示了独特的且持久的“战略指纹”，不同的公司之间表现出不同的人物特点。这些发现将经典的游戏理论与机器心理学相结合，提供了算法决策在不确定性环境下的丰富和细致的视角。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02659", "html_url": "https://arxiv.org/abs/2507.02659", "title": "OmniDraft：跨词表、在线自适应草稿模型的设备端推测性解码", "title_en": "OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding", "authors": "Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang", "background": "目前推测性解码通常需要一个小型高效的预训练或离线蒸馏模型来适应特定目标模型系列（如Llama或Qwen）。但在在线部署环境中，有两个主要挑战：1) 目标模型与草稿模型不兼容；2) 预期能够提高延迟并节省时间。因此，本文讨论了在线部署环境下草稿模型与目标模型不兼容的问题和需要降低延迟的期望，提出了一个新的框架OmniDraft。", "innovation": "OmniDraft框架引入了一个在线n-gram缓存和混合蒸馏微调技术，以解决草稿模型与目标模型之间的跨词表不匹配问题，并通过自适应草稿技术进一步提高解码速度。该框架特别适用于高性能计算、高效的设备端大规模语言模型应用，其中模型成本、效率和用户定制非常重要。", "conclusion": "通过在数学推理、编程和文本生成任务中的在线学习演示，OmniDraft框架能够使一个Llama-68M模型与各种目标模型（包括Vicuna-7B、Qwen2-7B和Llama3-8B）进行推测性解码配对，并且能提供1.5到2倍的速度提升。这项工作强调了解决上述挑战的必要性，并提出了“每一位草稿师都能适应所有模型”的观点。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02834", "html_url": "https://arxiv.org/abs/2507.02834", "title": "ExPO：使用自我解释引导的强化学习解锁复杂推理", "title_en": "ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning", "authors": "Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi", "background": "近年来，大型语言模型的进步主要得益于基于奖励或偏好信号的强化学习（RL）风格的后训练。这些方法通过使用基于结果的验证器生成的自动生成样本提高了推理能力。然而，这些方法高度依赖于模型初始产生积极样本的能力，主要对模型已经了解的内容进行精细调整，而未能解决模型一开始无法解决的问题。这种局限性尤其在早期RL训练和复杂推理任务中尤为明显，因为积极样本的生成很不现实。在这种情况下，模型必须探索新的推理路径，超越其当前的输出分布。这需要足够的良好正样本来引导学习。尽管专家演示看似自然的解决方案，但我们发现它们在RL后训练中往往无效。因此，我们发现有效的正样本应具有两个特性：一是它们应在当前策略下更可能出现，二是能增加模型预测正确答案的可能性。", "innovation": "我们提出了一种简单且模块化的框架——自解释策略优化（ExPO），它通过基于正确答案进行条件生成这样的正样本。ExPO能够有效地进行探索，指导模型产出与其策略更一致的推理路径，同时保持较高的质量，优于专家撰写的逆向思考路径（CoTs）。实验结果表明，ExPO能够提高推理基准学习效率和最终性能，在如MATH级别5这样的挑战性设置中尤其突出，此时模型最初表现最差。", "conclusion": "ExPO通过使用基于正确答案的正样本进行自我解释，成功解锁了复杂推理，并显示了在挑战性推理任务中的优越性能，超越了基于专家演示的方法。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02768", "html_url": "https://arxiv.org/abs/2507.02768", "title": "DeSTA2.5-Audio：朝着具有自我生成跨模态对齐的通用大型音频语言模型", "title_en": "DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment", "authors": "Ke-Han Lu,Zhehuai Chen,Szu-Wei Fu,Chao-Han Huck Yang,Sung-Feng Huang,Chih-Kai Yang,Chee-En Yu,Chun-Wei Chen,Wei-Chih Chen,Chien-yu Huang,Yi-Cheng Lin,Yu-Xiang Lin,Chi-An Fu,Chun-Yi Kuan,Wenze Ren,Xuanjun Chen,Wei-Ping Huang,En-Pei Hu,Tzu-Quan Lin,Yuan-Kuei Wu,Kuan-Po Huang,Hsiao-Ying Huang,Huang-Cheng Chou,Kai-Wei Chang,Cheng-Han Chiang,Boris Ginsburg,Yu-Chiang Frank Wang,Hung-yi Lee", "background": "近期的大型音频语言模型（LALM）通常通过在大量由手动策划或LLM合成的音频指令数据集上进行训练，来增强大型语言模型（LLMs）的听觉能力。然而，这些方法往往导致LLM最初的语言能力出现灾难性遗忘。为了克服这个问题，作者重新审视了数据构建管道，并提出了一种自我生成的跨模态对齐策略DeSTA，该策略使LALM能够自我生成训练目标，从而保留其本土语言能力的同时建立起有效的音频-文本对齐，从而在无需特定任务调优的情况下实现零样本泛化。基于这种方法，作者构建了包含50个不同数据集的500万训练样本的DeSTA-AQA5M数据集，这些数据集包括语音、环境声音和音乐等。", "innovation": "提出了一种全新的自我生成跨模态对齐策略DeSTA，该策略使得LALM能够自我生成训练目标，从而保留了其本土语言能力的同时建立起有效的音频-文本对齐，从而实现了在无需特定任务调优的情况下进行零样本泛化。使用这种方法，构建了包含500万训练样本的DeSTA-AQA5M数据集，并在多种音频语言基准测试中取得了领先或竞争性的性能。全面的对比研究表明，这种自我生成策略在听觉感知和指令跟随能力方面优于常规的数据构建和训练策略。", "conclusion": "研究结果强调了精心设计的数据构建在LALM开发中的重要性，并为构建稳健的、通用的LALM提供了实用见解。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02841", "html_url": "https://arxiv.org/abs/2507.02841", "title": "StepHint：多级步骤提示增强强化学习以推理", "title_en": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason", "authors": "Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan", "background": "当前的基于强化学习可验证奖励（RLVR）方法在提升大型语言模型的复杂推理能力方面面临两个主要挑战：‘接近错过’的奖励问题，微小的错误可能导致整个推理过程无效，严重影响了训练效率；以及探索停滞问题，模型倾向于集中在它们的舒适范围内，缺乏探索更有效替代方案的动力。", "innovation": "为应对以上挑战，本文提出了StepHint，一种新颖的RLVR算法，通过利用多级分步骤提示帮助模型更有效探索解空间。StepHint生成来自更强模型的有效推理链，并使用提出的自适应分割方法将这些链划分为推理步骤。初步几步被用作提示，同时提供不同步数的多级提示给模型。此方法引导模型向有希望的解子空间探索，同时保持其独立探索的灵活性。通过提供提示，StepHint缓解了‘接近错过’的奖励问题，提高了训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使它能够超越舒适区并克服探索停滞问题。", "conclusion": "在六个数学基准测试中，StepHint超越了竞争性的RLVR增强方法，同时在领域外基准测试中也展现出更强的泛化能力和超越基线的表现。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.08010", "html_url": "https://arxiv.org/abs/2311.08010", "title": "通过不确定性感知教师学习和学生学生协作学习提高远监督命名实体识别的鲁棒性", "title_en": "Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning", "authors": "Shuzheng Si,Helan Hu,Haozhe Zhao,Shuang Zeng,Kaikai An,Zefan Cai,Baobao Chang", "background": "远监督命名实体识别（DS-NER）在现实场景中广泛应用。它通过将现有知识库中的实体与文本中的片段进行匹配，有效减轻了标注负担，但存在标签噪声问题。最近的研究试图采用教师-学生框架逐渐细化训练标签，提高整体鲁棒性，但这些教师-学生方法的性能有限，因为教师网络的不良校准产生错误的伪标签，导致错误传播。", "innovation": "提出不确定性感知教师学习，利用预测不确定性减少自我训练阶段中的错误伪标签数量；提出学生-学生协作学习机制，允许两个学生网络之间可靠标签的转移，而非盲目依赖所有来自教师的伪标签，并进一步启用对错标签样本的全面探索，而非简单过滤不可靠的伪标签样本。", "conclusion": "在五个DS-NER数据集上评估了所提方法，证明了该方法优于最先进的DS-NER方法。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02846", "html_url": "https://arxiv.org/abs/2507.02846", "title": "法律要求从法律文本转化为规范", "title_en": "Legal Requirements Translation from Law", "authors": "Anmol Singhal,Travis Breaux", "background": "软件系统必须遵守法律规范，这对小型组织和初创公司来说是一个资源密集型的任务，尤其是缺乏专职法律专家的情况下。从法律规范中提取元数据以获取软件所需的法律要求是确保合规的关键步骤。但这项任务因法律文本的长度和复杂性而变得繁琐。尽管已有研究探索了自动化从法律文本中提取结构和语义元数据的方法，但仍存在关键限制：这些方法不考虑这些元数据类型相关属性之间的相互作用，并依赖于手动标注或启发式驱动的机器学习，这些方法在新文档上的泛化能力较差。因此，本文提出了一种基于文本蕴含和上下文学习的方法，以自动生成法律文本的规范表示，该表示可以编码和执行为Python代码。所设计的表示基于一个手动设计的Python类结构，作为特定领域的元模型，捕捉结构和语义法律元数据及其相互关系。此设计减少了对大量手动标注数据集的需求，并增强了对未见法规的适用性。我们针对13个美国州的数据泄露通知法律进行评估，结果显示，所生成的表示通过了约89.4%的测试案例，达到了82.2%的精确率和88.7%的召回率。", "innovation": "提出了一种基于文本蕴含和上下文学习的方法，以自动生成法律文本的规范表示，该表示可以编码和执行为Python代码。该表示基于一个手动设计的Python类结构，作为特定领域的元模型，能够捕捉结构和语义法律元数据及其相互关系，减少了对大量手动标注数据集的需求，并增强了对未见法规的适用性。", "conclusion": "该方法在对13个美国州的数据泄露通知法律的评估中表现出色，通过了约89.4%的测试案例，并达到了82.2%的精确率和88.7%的召回率，证明了其在自动化合规性过程中的有效性和实用性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02844", "html_url": "https://arxiv.org/abs/2507.02844", "title": "图像驱动语境攻击：利用视觉信息劫持MLLMs", "title_en": "Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection", "authors": "Ziqi Miao,Yi Ding,Lijun Li,Jing Shao", "background": "在视觉语言能力迅速发展的背景下，多模态大型语言模型（MLLMs）在实际应用中展现出巨大潜力。然而，视觉模块的安全漏洞对其在开放环境中的部署构成了重大挑战。已有研究通过直接在视觉输入中编码有害文本含义，诱导目标MLLMs做出有害反应，但这些方法通常将视觉模块作为触发不安全行为的工具，缺乏实际场景中的语义清晰性和现实性支撑。在此背景下，本文提出了一个新的研究方向：基于视觉的劫持攻击，并提出了一种名为VisCo的攻击方法，利用视觉驱动的语境对话，当需要时动态生成辅助图像构建视觉中心攻击场景，使得最终攻击提示能有效触发目标黑盒MLLMs的有害反应，且取得了显著的攻击成功率和毒性得分", "innovation": "本文提出了基于视觉语境的攻击方法VisCo，通过图像驱动语境对话和动态生成辅助图像构建视觉中心攻击场景，自动毒性混淆和语义优化经过精心设计。相较于基线方法，VisCo在MM-SafetyBench上实现了更高的毒性得分4.78和85%的攻击成功率，显著优于基线方法2.48的毒性得分和22.2%的攻击成功率", "conclusion": "VisCo方法通过创新地利用视觉信息构建多模态语境对话，有效突破了目标黑盒多模态语言模型，并在实验中展示了优异的效果。这一研究不仅推进了多模态安全领域的边界，为未来研究提供了新的视角，也呼吁在开发和部署多模态系统时，应更加重视视觉模块的安全性和可靠性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2306.13840", "html_url": "https://arxiv.org/abs/2306.13840", "title": "超越规模：多样性系数作为自然语言数据变异性的数据质量衡量标准", "title_en": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data", "authors": "Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo", "background": "当前对大规模语言模型（LLMs）的预训练趋势主要集中在模型和数据集规模的扩大上。尽管人们认为预训练数据的质量是训练强大LLMs的重要因素，但这一概念仍然不清晰且未经过严格的定义和量化。本研究旨在通过引入多样性系数来正式化数据质量的一个关键方面——自然语言数据的变异性，并通过一系列实证分析来验证其在下游模型评估性能中的重要性。研究发现，预训练数据的多样性系数能够反映出语言数据的多样性和变异性，且与理论上下界限高于真实值。通过使用GPT-2和LLaMAv2进行一系列受控干预实验，进一步证实了多样性系数在评估模型性能方面的重要性，并涵盖多种模型规模（51M至7B参数），总共44个模型。", "innovation": "提出并验证了一个新的概念——‘多样性系数’来衡量自然语言数据的质量。该研究通过实证分析和模型实验表明，多样性系数能够反映出模型质量和变异性，且在下游模型性能评估中具有重要作用。此外，研究还首次揭示了公开可用的预训练数据集具有相对于理论上下限较高的实际多样性。", "conclusion": "研究结论认为，正式的多样性概念是数据质量的重要方面，能够捕捉变异性，并且与提高评估性能有关。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.13808", "html_url": "https://arxiv.org/abs/2410.13808", "title": "De-mark: 在大规模语言模型中去除水印", "title_en": "De-mark: Watermark Removal in Large Language Models", "authors": "Ruibo Chen,Yihan Wu,Junfeng Guo,Heng Huang", "background": "水印技术为通过在语言模型（LMs）生成的内容中嵌入隐形信息来识别机器生成内容提供了有希望的方法。然而，这些水印方案的鲁棒性尚未得到充分研究。", "innovation": "提出了一个名为 De-mark 的先进框架，旨在有效去除基于 n-克隆重构的水印。De-mark 利用了一种新的查询策略，称为随机选择探查，用于评估水印强度并识别 n-克隆重构水印中的红绿列表。在流行的 LMs（如 Llama3 和 ChatGPT）上的实验展示了 De-mark 在水印去除和利用任务中的高效性和有效性。", "conclusion": "De-mark 框架在大规模语言模型中展示了高效去除和利用水印的能力，提高了对机器生成内容的检测能力，同时增强了水印方案的鲁棒性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.01119", "html_url": "https://arxiv.org/abs/2408.01119", "title": "Task Prompt Vectors: 通过多任务软提示迁移的有效初始化", "title_en": "Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer", "authors": "Robert Belanec,Simon Ostermann,Ivan Srba,Maria Bielikova", "background": "提示调优是一种高效的方法，用于训练大型语言模型（LLMs）。然而，当前基于软提示的方法通常在多任务模ularity方面有所妥协，因为每次添加新任务时，训练过程都可能需要完全或部分重复进行。最近关于任务向量的研究通过在全模型权重上应用算术运算来实现所需多任务性能，但对于软提示而言，类似的解决方案仍然欠缺。在本文中，作者引入了一个名为任务提示向量的新方法，该方法通过已调优的软提示权重与随机初始化之间的逐元素差异来创建。实验结果表明，任务提示向量可以在低资源设置中有效初始化提示调优，对相似任务。此外，作者还展示了任务提示向量在两种不同的语言模型架构上与提示调优的随机初始化独立，这使得可以通过来自不同任务的预训练向量执行提示算术。", "innovation": "该研究提出了一种名为任务提示向量的新方法，这种向量是通过已调优的软提示权重与随机初始化之间的逐元素差异来创建的。与现有方法不同，任务提示向量可以与来自不同任务的预训练向量进行算术运算，从而提供了与最新基准模型相竞争的替代方法。这项研究填补了在软提示调优中缺少类似任务向量应用算术运算方法的空白，为多任务学习提供了一种有效的新策略。", "conclusion": "实验结果表明，任务提示向量可以用于低资源设置中有效初始化提示调优，对相似任务尤其有效。此外，任务提示向量在两种不同的语言模型架构上的独立性，使得能够执行提示算术与来自不同任务的预训练向量。因此，通过多个任务的提示向量加法，提供了一种具有竞争力的最新基准底物。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.14727", "html_url": "https://arxiv.org/abs/2311.14727", "title": "对旅游领域新型数据集进行多语言社会内容分析的最优策略", "title_en": "Optimal strategies to perform multilingual analysis of social content for a novel dataset in the tourism domain", "authors": "Maxime Masson,Rodrigo Agerri,Christian Sallaberry,Marie-Noelle Bessagnet,Annig Le Parc Lacayrelle,Philippe Roose", "background": "社交媒体平台在旅游业等领域的影响力日益增强，突显了高效和自动化的自然语言处理（NLP）策略的需求，以便充分利用这些宝贵的数据资源。然而，将多语言、非结构化和非正式文本转化为结构化知识依然面临巨大挑战，尤其是对大量手动标注数据的需求始终无法满足。", "innovation": "本文研究了不同的NLP技术，以确定哪些技术可以在最少的标注数据需求下获得竞争力的表现。为此，作者构建了第一个公开的多语言数据集（法语、英语和西班牙语），包含旅游业相关的推文。数据集包括多层手动修订命名实体识别（NER）标注，用于地点和细粒度主题概念提取映射到联合国世界旅游组织的旅游和休闲活动词汇表，以及推文级别的情感分析标注。实验对比了各种少量数据和微调技术与现代语言模型，表明现代少量数据技术能够在标注数据极少量的情况下获得竞争力的结果。", "conclusion": "我们的结果基于新型数据集，为将NLP应用于新型领域特定应用铺平了道路，减少了手动标注的需求，并规避了基于规则的、临时解决方案的复杂性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02858", "html_url": "https://arxiv.org/abs/2507.02858", "title": "需求获取后续问题生成", "title_en": "Requirements Elicitation Follow-Up Question Generation", "authors": "Yuchen Shen,Anmol Singhal,Travis Breaux", "background": "访谈是广泛用于提取需求的方法，用于收集软件系统相关利益方的需求、偏好和期望。有效的访谈需要熟练的访谈员实时提出合适的问题，但面临着领域不熟悉、认知负荷过重和信息过载等挑战，这阻碍了人类处理利益方话语的方式。近年来，大型语言模型（LLMs）在多种自然语言处理任务中表现出卓越的性能，包括文本摘要和推理。", "innovation": "研究将GPT-4o应用于软件系统需求获取过程中的后续访谈问题生成。基于常见的访谈员错误类型构建了框架，并且描述了根据访谈者话语生成问题的方法。通过两个控制实验评价了由LLM生成的问题和由人类设计的问题：一个是无指导实验，另一个是引导式实验。结果表明，LLM生成的问题在清晰度、相关性和信息量方面至少不逊于人类生成的问题，且当生成过程受到常见错误类型的指导时，LLM生成的问题表现更优。这突显了使用LLMs帮助访谈员实时提高需求获取访谈的质量和简便性的潜力。", "conclusion": "研究证实了使用LLMs生成后续访谈问题的可行性和有效性，在特定引导下甚至优于人类生成的问题。这表明大型语言模型在实时支持需求获取访谈中具有巨大潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.07016", "html_url": "https://arxiv.org/abs/2406.07016", "title": "通过过剩词汇探究生物医学出版物中的LLM辅助写作", "title_en": "Delving into LLM-assisted writing in biomedical publications through excess vocabulary", "authors": "Dmitry Kobak,Rita González-Márquez,Emőke-Ágnes Horvát,Jan Lause", "background": "大型语言模型（LLMs）如ChatGPT能够生成和修订具有人类水平性能的文本。尽管这些模型存在明显的局限性（如产生不准确信息、强化已存在的偏见和容易被滥用），许多科学家仍使用它们进行学术写作。然而，在生物医学研究文献中，这种LLM使用情况的广泛程度如何？为解答这个问题，作者采用了一种不受偏见影响、大规模的方法：研究PubMed索引的超过1500万篇2010年至2024年间的生物医学摘要中的词汇变化，并展示了LLMs的出现导致特定风格词汇频次的突然增加。这种过剩词汇分析表明，至少有13.5%的2024年摘要是通过LLMs处理的。不同学科、国家和期刊之间存在差异，某些子集合中比例达到40%。作者指出，LLMs在生物医学研究领域的科学写作中产生了前所未有的影响，甚至超过了像Covid疫情这样重大世界事件的影响。", "innovation": "该研究采用了一种大型且中立的方法来分析生物医学文献中LLM的使用情况，通过研究大量出版物中的词汇变化，揭示了LLM对科学写作的影响。这种欠词分析方法为评估学术写作中技术工具的使用和影响提供了一种新途径，并且发现的影响程度超出了主要世界事件（如Covid疫情）的效果。", "conclusion": "研究展示了LLMs在生物医学研究领域科学写作中产生的影响，尤其是在词汇和短语使用的变化上。通过对1500万篇摘要的分析，发现大约13.5%的摘要可能是通过LLMs处理的，这一比例在不同学科和期刊之间有所不同。研究强调了LLM技术的广泛应用，并对其潜在的影响和挑战表示担忧。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11268", "html_url": "https://arxiv.org/abs/2502.11268", "title": "改进的大型语言模型无偏水印", "title_en": "Improved Unbiased Watermark for Large Language Models", "authors": "Ruibo Chen,Yihan Wu,Junfeng Guo,Heng Huang", "background": "随着人工智能在文本生成方面超越人类能力，验证AI生成内容的来源变得至关重要。无偏水印通过在不损害质量的情况下将统计信号嵌入语言模型生成的文本中提供了解决方案。", "innovation": "提出了MCmark无偏水印家族，这是一种多通道基于的水印方法。MCmark通过将模型词汇表分割为段，并基于水印密钥在选定段内促进token概率来工作。实验表明，MCmark不仅保持了原始的语言模型分布，还在可检测性和鲁棒性上明显优于现有的无偏水印，尤其是在可检测性上提高了超过10%。", "conclusion": "MCmark在AI生成文本的水印应用中展现出增强的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.16765", "html_url": "https://arxiv.org/abs/2411.16765", "title": "SHuBERT：通过多流聚类预测进行自监督手语表示学习", "title_en": "SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction", "authors": "Shester Gueuwou,Xiaodan Du,Greg Shakhnarovich,Karen Livescu,Alexander H. Liu", "background": "手语处理历来依赖于针对特定任务的模型，限制了跨任务的迁移学习潜力。以往的手语预训练方法主要集中在监督预训练上，无法利用未标记的数据，或者采用与上下文无关（帧或视频片段）的表示方法，忽略了手语时间关系的影响。", "innovation": "提出了一种名为SHuBERT（Sign Hidden-Unit BERT）的自监督上下文表示模型，从大约1000小时的美国手语视频中学习。SHuBERT采用遮盖词预测目标对多流视觉手语输入进行适应，学习预测来自手、面部和身体姿态流的多个目标。SHuBERT在包括手语翻译、孤立手语识别和字母表检测在内的多种任务中取得了最先进的性能。", "conclusion": "SHuBERT在多个手语处理任务上达到了最先进的性能，展示了其在自监督学习下的多模态上下文语义表示的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.12532", "html_url": "https://arxiv.org/abs/2410.12532", "title": "MedAide：基于LLM的智能代理协作在医学意图信息融合中的机制", "title_en": "MedAide: Information Fusion and Anatomy of Medical Intents via LLM-based Agent Collaboration", "authors": "Dingkang Yang,Jinjie Wei,Mingcheng Li,Jiyao Liu,Lihao Liu,Ming Hu,Junjun He,Yakun Ju,Wei Zhou,Yang Liu,Lihua Zhang", "background": "在医疗智能中，从各种临床源融合异构、多意图的信息是构建可靠决策系统的基础。当前，基于大型语言模型（LLM）的信息交互系统在医疗领域有潜力，但它们在处理复杂医疗服务意图时经常出现信息冗余和耦合问题，导致严重的幻觉和性能瓶颈。因此，提出了一种名为MedAide的基于LLM的医疗多代理协作框架，旨在实现意图感知的信息融合和跨特殊医疗领域的协调推理。MedAide包含多意图分解和动态意图原型匹配模块，利用动态原型表示和语义相似性匹配机制实现多轮医疗对话中的智能体意图的自适应识别和更新。此外，设计了智能体协作机制，通过动态角色轮换和决策层面上的信息融合实现医疗智能体间的协作。实验结果表明，MedAide在四个包含复合意图的医疗基准测试中优于当前的LLM，并提高了医疗服务能力和战略推理水平。", "innovation": "提出了一种意图感知的信息融合和协调推理的医疗多代理协作框架MedAide，该框架通过结合语义约束和检索增强生成来分解复杂查询，利用动态原型表示和语义相似性匹配机制实现多轮对话中的自适应意图识别和更新，最终引入动态角色轮换和决策层面上的信息融合，实现跨专业的医疗智能体协作，从而解决大型语言模型处理复杂医疗意图时的信息冗余和耦合问题，提升模型的服务能力和服务策略推理水平。", "conclusion": "MedAide在四个包含复合意图的医疗基准测试中表现出色，实现了优于当前LLM的医疗服务能力和战略推理水平。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.03262", "html_url": "https://arxiv.org/abs/2501.03262", "title": "REINFORCE++: 一种鲁棒性强的高效RLHF算法", "title_en": "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models", "authors": "Jian Hu,Xibin Wu,Wei Shen,Jason Klein Liu,Zilin Zhu,Weixun Wang,Songlin Jiang,Haoran Wang,Hao Chen,Bin Chen,Weikai Fang,Xianyu,Yu Cao,Haotian Xu", "background": "大型语言模型（LLMs）通过强化学习从人类反馈（RLHF）和验证奖励的强化学习（RLVR）进行微调，显著提高了人类和AI价值观的一致性，并且提升了AI的能力上限，尤其是在需要推理和长上下文的思考链（long-CoT）任务中。然而，现有的RLHF（或RLVR）框架存在诸如推理瓶颈和复杂性障碍等挑战，这限制了它们对新用户的可用性。", "innovation": "为了缩小这一差距，该研究引入了OpenRLHF，这是一个基于Ray、vLLM、DeepSpeed和Transformer的开源RLHF框架。OpenRLHF具有简化的设计、清晰的代码结构和全面的文档，易于研究人员和实践者使用。实验结果表明，OpenRLHF在不同模型大小上的训练效率得到了显著提高，与最先进的框架相比，速度提升范围从1.22倍到1.68倍不等，同时在实现所需代码行数方面也大幅减少。", "conclusion": "OpenRLHF是一个用户友好、可扩展且易于学习的开源RLHF框架，已经获得广泛采用，并被顶级机构采纳以加速RLHF的研究和学习。该框架能够实现高效的训练和简洁的实现，增强了RLHF的可用性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.05693", "html_url": "https://arxiv.org/abs/2412.05693", "title": "批次最大化: 使用更大批次和KV缓存压缩提高LLM throughput", "title_en": "Batch-Max: Higher LLM Throughput using Larger Batch Sizes and KV Cache Compression", "authors": "Michael R. Metel,Boxing Chen,Mehdi Rezagholizadeh", "background": "已有研究开发了移除关键值（KV）对的策略，从KV缓存中更高效地进行推理。这些工作的重点是输入提示处理完成后压缩KV缓存，以加快标记生成速度。在GPU内存有限且输入上下文长度超过生成长度的设置中，作者展示了在输入处理阶段同时压缩KV缓存，可以使用更大的批次大小，从而显著提高吞吐量，同时保持原始模型的准确性。", "innovation": "提出了一种名为‘批次最大化’（Batch-Max）的方法，该方法通过在输入处理阶段压缩KV缓存，使用更大的批次大小，提高了LLM的吞吐量，且不牺牲模型的准确性。", "conclusion": "在有限的GPU内存和较长的输入上下文情况下，通过在输入处理阶段压缩KV缓存，可以实现更高的LLM吞吐量和较大的批次大小，同时保持模型原有的准确性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.00863", "html_url": "https://arxiv.org/abs/2411.00863", "title": "下一个token预测任务假设对于证明生成的LLM训练数据的理想排序", "title_en": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation", "authors": "Chenyang An,Shima Imani,Feng Yao,Chengyu Dong,Ali Abbasi,Harsh Shrivastava,Samuel Buss,Jingbo Shang,Gayathri Mahalingam,Pramod Sharma,Maurice Diesendruck", "background": "在基于大型语言模型（LLM）的证明生成领域，尽管经过了大量如ArXiv的大型数据集训练，LLM在解决中等难度证明任务上仍表现一般。研究者们认为，这一现象部分原因是很多训练数据中证明的顺序并非最优化的，即实际的证明步骤往往遵循逻辑顺序而非有助于学习发现过程的顺序，从而影响了模型的效果。因此，提出了新的策略——直观顺序，主张对于每个证明步骤的中间监督信息在该步骤左侧，通过这种策略可以优化训练效果。", "innovation": "研究者提出了一种新的证明生成策略，称之为“直观顺序”，即每一证明步骤的相关中间监督信息应在该步骤左侧。通过在直覺順序下的训练，模型在证明生成任务上的表现明显优于传统的逻辑顺序。具体效果上，在命题逻辑定理证明任务中，最优化顺序的模型比最差顺序模型的成功率提高了11%。此外，还定义了高级数学证明中一种常见的顺序问题，并发现在某广泛使用的研究生数学教材前两章中，17.3% 拥有非平凡证明的定理存在这种问题。", "conclusion": "实验结果验证了直观顺序对提高证明生成模型效果的重要性。此外，优化数据排序在提高证明生成效果方面具有显著的实际意义，这为未来的模型训练和优化提供了新的视角。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.11556", "html_url": "https://arxiv.org/abs/2412.11556", "title": "Token Prepending: 一种无需训练的从LLMs中提取更好句子嵌入的方法", "title_en": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs", "authors": "Yuchen Fu,Zifeng Cheng,Zhiwei Jiang,Zhonghui Wang,Yafeng Yin,Zhengliang Li,Qing Gu", "background": "从大型语言模型（LLMs）中提取句子嵌入是一个有前景的方向，因为LLMs展示了更强的语义理解能力。此前的研究通常侧重于润色提示的工程，通过提示模型将句子信息编码到最后一个词汇的嵌入中来提取句子嵌入。然而，LLMs大多是解码器模型，在因果注意机制下，句子中的早期词汇无法关注后续词汇，导致偏颇的句子信息编码，进而对最终解码词汇产生级联效应。因此，提出了一种新颖的Token Prepending（TP）技术，该技术将每一层解码后的句子嵌入前缀到下一层输入的句子开头，使得因果注意机制下的早期词汇能够关注完整的句子信息。", "innovation": "提出的TP技术是一种即插即用、无需训练的技术。这意味着它可以无缝集成到各种基于提示的句子嵌入方法和自回归LLMs中。该技术显著提高了不同类型LLMs上现有基于提示的句子嵌入方法的性能，且带来了可忽略不计的附加推理成本。", "conclusion": "在各种语义文本相似性（STS）任务和下游分类任务上的广泛实验表明，提出的TP技术可以在不增加额外推理成本的情况下，显著提高现有基于提示的句子嵌入方法的性能表现，适用于不同的LLMs。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.18681", "html_url": "https://arxiv.org/abs/2503.18681", "title": "Commander-GPT: 全面释放多模态大型语言模型的讽刺检测能力", "title_en": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models", "authors": "Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin", "background": "讽刺检测作为自然语言处理（NLP）领域的重要研究方向，吸引了广泛的关注。传统的单一模态方法（如文本）难以捕捉到讽刺的隐秘和细微之处，导致效果不理想。近年来，研究者转向多模态方法以更准确地识别讽刺内容，但如何有效利用多模态信息仍然是一个值得进一步研究的挑战。", "innovation": "本文提出了一种基于多模态大型语言模型（MLLMs）的创新多模态Commander-GPT框架。借鉴军事策略，该框架将讽刺检测任务分解为六个子任务，中央指挥官（决策者）分配最适合的大型语言模型来处理每个特定子任务。最终，汇总每个模型的检测结果以识别讽刺内容。实验表明，该方法在MMSD和MMSD 2.0数据集上取得了最先进的性能，F1分数提高了19.3%，并且无需微调或真实理由作为指导。", "conclusion": "本文提出的方法在讽刺检测任务中表现优异，通过利用多模态大型语言模型的强大整合处理能力，结合细分任务和模型选择策略，显著提高了检测质量。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12816", "html_url": "https://arxiv.org/abs/2504.12816", "title": "SMARTe: 基于槽的方法的可问责关系三元组提取", "title_en": "SMARTe: Slot-based Method for Accountable Relational Triple extraction", "authors": "Xue Wen Tan,Stanley Kok", "background": "关系三元组提取（RTE）是自然语言处理（NLP）中的一个基础任务。此前的研究主要集中在优化模型性能上，而较少关注模型内部机制的理解。大多数现有方法依赖复杂的预处理步骤以引入特定的交互方式，导致系统往往不透明，可能未能完全符合其理论基础。", "innovation": "本文提出了一种名为SMARTe的新方法，这是一种基于槽的可问责关系三元组提取方法。SMARTe通过引入槽注意机制增加内在可解释性，将任务框架化为集合预测问题。文章强调SMARTe在强化可解释性的同时，其性能与现有最佳模型相当。SMARTe通过注意力热图等质性评估展示了其提供的解释。", "conclusion": "SMARTe的评估显示，在NYT和WebNLG数据集上的实验表明添加可解释性不会牺牲性能。文章最后讨论了研究发现，并提出了未来研究的方向。相关代码可在提供的链接处获取。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00958", "html_url": "https://arxiv.org/abs/2503.00958", "title": "多层次见解：通过利用所有变换器层进行可泛化的作者风格分析", "title_en": "Layered Insights: Generalizable Analysis of Authorial Style by Leveraging All Transformer Layers", "authors": "Milad Alshomary,Nikhil Reddy Varimalla,Vishal Anand,Smaranda Muresan,Kathleen McKeown", "background": "当前的作者身份归属性研究主要集中在使用预训练变换器模型的不同层来学习多种语言表示上。这种方法能够在领域内和领域外的各种实验场景中提升作者身份归属性模型的性能表现。之前的研究通常关注单一或部分层的效果，而未全面探讨各层在不同测试条件下的具体贡献和作用机制。", "innovation": "本文提出了一种全新的方法，利用预训练变换器模型的不同层学习到的各种语言表示，以增强作者身份归属性模型在领域外数据上的鲁棒性。通过在三个数据集上进行对比实验，展示了利用多层变换器能够获得更优的作者身份识别结果，从而取得新的前沿成果。此外，对各层的具体贡献进行了深入分析，揭示了模型不同层如何在各种测试条件下专门化以更好地表达特定的风格特征。", "conclusion": "本文的方法实验证明，在领域外数据上的作者身份归属性模型能够通过利用预训练变换器模型的多层语言表示来获得更优秀的鲁棒性性能。同时，通过深入分析各层的贡献，为作者风格的可泛化研究提供了新的见解。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13886", "html_url": "https://arxiv.org/abs/2505.13886", "title": "Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning", "title_en": "Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning", "authors": "Jingqi Tong,Jixin Tang,Hangcheng Li,Yurong Mou,Ming Zhang,Jun Zhao,Yanbo Wen,Fan Song,Jiahao Zhan,Yuyang Lu,Chaoran Tao,Zhiyuan Guo,Jizhou Yu,Tianhao Cheng,Changhao Jiang,Zhen Wang,Tao Liang,Zhihui Fei,Mingyang Wan,Guojun Ma,Weifeng Ge,Guanhua Chen,Tao Gui,Xipeng Qiu,Qi Zhang,Xuanjing Huang", "background": "视觉语言模型（VLMs）的视觉-语言推理能力提升受限于视觉语言链思考（CoT）数据资源的稀缺，尤其是这类数据远不如纯文本数据丰富。高质量的视觉-语言推理数据成本高昂且标注工作繁重。为了应对这一挑战，研究者们探索了游戏代码作为数据资源的潜力，因为游戏代码自然地包含了逻辑结构和状态转换过程。", "innovation": "本文提出了一种名为Code2Logic的创新方法，通过游戏代码驱动的数据合成来增强视觉语言模型的通用推理能力。该方法利用大型语言模型（LLMs）对游戏代码进行适应性修改，自动获取推理过程和结果，从而合成多模态推理数据。这种方法不仅减少了数据标注的成本，还提高了数据的多样性和可控性，为视觉语言模型提供了大规模且成本效益高的训练数据。", "conclusion": "使用Code2Logic方法合成的数据集GameQA有效地训练和评估了视觉语言模型。尽管仅用游戏数据进行训练，视觉语言模型仍然展现了领域外的一般化能力，特别是Qwen2.5-VL-7B在此方面表现尤为突出，在7个不同的视觉语言基准测试中提高了2.33%的表现。实验中的代码、数据集和模型可在 [这个链接] 获得。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨语言旅行：评估多模态大语言模型的跨语言一致性", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "多模态大语言模型（MLLMs）的快速发展极大地提升了其实用性，但要在不同语言中保持一致表现，尤其是在整合文化知识方面，仍是一个重大挑战。为了更好地评估这一问题，该研究引入了两个新的基准测试——KnowRecall和VisRecall，用于评估MLLMs的跨语言一致性。KnowRecall旨在通过视觉问答任务来衡量15种语言中的事实知识一致性，特别是关于全球地标的文化和历史问题。VisRecall通过让模型在没有图片的情况下描述地标特征，来评估9种语言中的视觉记忆一致性。实验结果表明，即使是最先进的MLLMs，也难以实现跨语言一致性，这凸显了需要更可靠的方法来生成真正多语言及文化意识强的模型的需求。", "innovation": "该研究提出了两大创新：一是设计了两个新的基准测试——KnowRecall和VisRecall，以评估多模态大语言模型在不同语言环境下的知识和记忆一致性；二是通过这些新基准测试，揭示了即使是最先进的专有MLLMs在跨语言一致性方面仍然面临挑战，强调了在生成真正多语言及文化意识强的模型方面的需求。", "conclusion": "目前最先进的多模态大语言模型，在跨语言一致性方面仍存在明显不足，这需要开发更为稳健的方法来创造真正多语言且具备文化意识的模型。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22618", "html_url": "https://arxiv.org/abs/2505.22618", "title": "Fast-dLLM：通过启用KV缓存和并行解码加速扩散大语言模型", "title_en": "Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding", "authors": "Chengyue Wu,Hao Zhang,Shuchen Xue,Zhijian Liu,Shizhe Diao,Ligeng Zhu,Ping Luo,Song Han,Enze Xie", "background": "扩散基于的大语言模型（Diffusion LLMs）在并行解码能力方面展现了非自回归文本生成的潜力，但开源的Diffusion LLMs的实用推理速度往往落后于自回归模型，这主要是因为缺乏Key-Value (KV) Cache机制以及在同时解码多个令牌时的质量下降问题。", "innovation": "本文提出了一种为双向扩散模型量身定制的区块级近似KV Cache机制，使其可以进行缓存重用，几乎不降低性能。同时，作者确定了并行解码生成质量下降的根本原因是条件独立假设下令牌依赖关系的中断。为此，提出了一种基于置信度的并行解码策略，该策略选择性地解码超出置信阈值的令牌，从而减轻依赖关系的违反并保持生成质量。", "conclusion": "在LLaDA和Dream模型上，针对多个大语言模型基准的实验结果展示了最多27.6倍的吞吐量提升，几乎不影响准确性，并缩小了与自回归模型的性能差距，为实用部署扩散大语言模型铺平了道路。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08713", "html_url": "https://arxiv.org/abs/2506.08713", "title": "基于多跳自然语言推理的保证案例结构可解释性合规检测", "title_en": "Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure", "authors": "Fariz Ikhwantri,Dusica Marijan", "background": "确保复杂系统符合规定通常需要通过主张-论据-证据框架检查保证案例的有效性。这一过程中面临的主要挑战包括法律和技术文本的复杂性、需要模型解释以及有限的保证案例数据访问。", "innovation": "提出了一种基于自然语言推理(NLI)的合规检测方法：具有arg立 infer推理能力的解释性合规检测（EXCLAIM）。该方法将保证案例的主张-论据-证据结构表示为多跳推理，用于解释性和可追溯性合规检测。通过大型语言模型生成有限数量的保证案例，并引入衡量覆盖率和结构一致性的指标。以GDPR要求为例，展示了这种方法在多跳推理任务中的有效性。", "conclusion": "研究表明，基于NLI的方法在自动化合规过程方面具有潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00612", "html_url": "https://arxiv.org/abs/2506.00612", "title": "利用知识图谱指导生成干扰项增强临床多项选择题基准", "title_en": "Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation", "authors": "Running Yang,Wenlong Deng,Minghui Chen,Yuyin Zhou,Xiaoxiao Li", "background": "临床任务如诊断治疗需要强大的决策能力，这突显了需要严格的评估基准来评估大型语言模型（LLMs）的可靠性。为此，本文介绍了一种知识引导的数据增强框架，通过生成能使临床多项选择题（MCQ）数据集更具难度的干扰项，提高了对现有LLMs的区分力。该方法涉及多步骤、语义驱动的医疗知识图谱上的漫步，以识别医学上相关但事实上错误的干扰路径，进而指导LLMs生成更具有欺骗性的干扰项。", "innovation": "本文提出了基于知识图谱的干扰项生成（Knowledge Graph Guided Distractor Generation，KGGDG）管道，通过生成与正确答案相似但事实上错误的干扰项，增强了临床多个选择题数据集的难度。这种方法展示了对医学LLMs更稳健和诊断性评估的能力。实验证明KGGDG可以降低最先进的LLMs的准确度，显示出其作为医学LLMs评估工具的强大潜力。", "conclusion": "该研究通过KGGDG管道，显著提高了医疗QA基准的难度，并证明了其在使LLMs评估更加稳健和诊断性方面的有效性。研究结果确立了KGGDG作为评估医学LLMs的关键工具的地位。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15830", "html_url": "https://arxiv.org/abs/2506.15830", "title": "通过信息几何和量子度量重新思考大语言模型的训练", "title_en": "Rethinking LLM Training through Information Geometry and Quantum Metrics", "authors": "Riccardo Di Sipio", "background": "大语言模型（LLMs）的优化在高维度参数空间中进行，且具有非欧几里得结构。信息几何通过费歇尔信息度量框架描述了这一景观，从而通过自然梯度下降实现更稳健的学习。尽管如此，这种几何视角仍能阐明诸如尖锐极小值、泛化和观察到的标度定律等现象。", "innovation": "本文提出了曲率感知方法加深了我们对LLM训练的理解，并推测了基于Fubini-Study度量和量子费歇尔信息的量子类比，暗示了在量子增强系统中实现高效优化的可能性。", "conclusion": "文章通过信息几何和量子度量重新审视了大语言模型的训练，并指出曲率感知方法以及量子类比可能带来更深入的理解和更高效的优化策略。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00606", "html_url": "https://arxiv.org/abs/2507.00606", "title": "Mixture of Reasonings: 教导大语言模型使用自适应策略进行推理", "title_en": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies", "authors": "Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang", "background": "大型语言模型（LLMs）通过先进的提示技术如链式思考（CoT）和树状思考（ToT）在复杂任务中表现出色，但由于其依赖于手动构建的任务特定提示，限制了模型的适应性和效率。", "innovation": "引入了一种名为MoR（Mixture of Reasoning）的训练框架，该框架将多种推理策略嵌入到LLMs中，使模型能够在无需外部提示工程的情况下实现自主任务适应性推理。MoR分为两个阶段：思想生成和SFT数据集构造。通过使用此框架，模型的性能得到了显著提高，特别是在使用CoT提示时表现尤为突出。", "conclusion": "MoR 消除了对任务特定提示的需求，提供了一个广泛适用于各种任务的稳健推理解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21880", "html_url": "https://arxiv.org/abs/2505.21880", "title": "引入大语言模型进行大规模城市复杂交通模拟", "title_en": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation", "authors": "Yu-Lun Song,Chung-En Tsern,Che-Cheng Wu,Yu-Ming Chang,Syuan-Bo Huang,Wei-Chu Chen,Michael Chia-Liang Lin,Yu-Ta Lin", "background": "传统基于规则的基于代理的建模（ABM）在模仿现实世界中的个体行为和大规模交通模式方面存在局限性。研究者希望通过整合大型语言模型（LLM）来增强代理模型的现实多样性，并准确模拟交通模式，为城市规划提供更多实用性信息。本研究使用台北城市的真实数据来构建仿真模型，以提供可操作的信息给城市规划师，帮助制定政策。", "innovation": "本研究提出了将大型语言模型（LLM）与基于代理的建模（ABM）相结合的新颖方法，通过LLM生成合成人口特征，分配常规和偶然的地点，并模拟个性化路线。这与传统的基于规则的ABM方法相比，能更真实地反映出多种交通模式下的个性化行为和交通模式。", "conclusion": "该研究通过建立现实世界数据的仿真模型，提供了一种新的验证框架来确保精度和可靠性，这对于城市规划和交通管理具有重要意义。未来工作将集中在建立坚实的验证框架以确保其在城市规划应用中的准确性和可靠性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01352", "html_url": "https://arxiv.org/abs/2507.01352", "title": "Skywork-Reward-V2: 通过人机协同扩展偏好数据处理", "title_en": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "authors": "Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou", "background": "尽管奖励模型（RMs）在基于人类反馈的强化学习（RLHF）中扮演着关键角色，目前最先进的公开RMs在大多数现有评估基准上表现不佳，难以捕捉人类微妙而复杂的偏好。即使采用了先进的训练技术，也没有显著的性能提升。研究认为这种脆弱性主要源自偏好数据集的限制，这些数据集往往范围狭窄、合成标签或缺乏严格的质控。", "innovation": "提出了一种包含4000万个偏好配对的大型数据集SynPref-40M，并设计了一种人机协同的两阶段流程来增强数据处理的质量和规模。基于这部分数据训练了Skywork-Reward-V2，这是一个具有8个不同参数量层次（0.6B到8B）的奖励模型系列，展示了优异的性能和广泛的适用性，并通过消融研究验证了高质量数据处理带来的效果不仅来源于数据规模，还包括来自高质量处理的质量。", "conclusion": "Skywork-Reward-V2 系列代表了开源奖励模型的重要进展，突显了现有偏好数据集的潜力，并展示了人机协同处理如何带来显著的数据质量提升，达到了七项主要奖励模型基准的前沿性能。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01923", "html_url": "https://arxiv.org/abs/2507.01923", "title": "决策导向的文本评估", "title_en": "Decision-Oriented Text Evaluation", "authors": "Yu-Shiang Huang,Chuan-Ju Wang,Chung-Chi Chen", "background": "自然语言生成（NLG）在高风险领域中的应用越来越多，但现有的评价方法，如n-gram重叠或句子的合理性，与实际的决策有效性关系不大。本研究通过直接评估生成文本对人类和大规模语言模型（LLM）决策结果的影响，提出了一个以决策为导向的框架。研究利用市场摘要文本（包括客观的早间摘要和主观的收盘分析）作为案例研究，基于投资者和受这些文本独家告知的自主LLM代理的交易表现来衡量决策质量。研究发现，无论是人类还是LLM单独依赖摘要时，都不能稳定地表现出超越随机的表现。然而，更具分析性的评论能够使人类和LLM的合作团队在决策上显著超越单个的个体或代理基准。这强调了通过评估生成文本来促进人类和LLM之间协同决策的重要性，并指出了传统内在度量标准的局限性。", "innovation": "本研究提出了一个以决策为导向的框架，直接评估生成文本对人类和LLM决策结果的影响。研究通过使用市场摘要文本作为案例，基于交易表现评估决策质量，揭示了传统评价方法的不足，强调了评价生成文本的新方法的重要性。", "conclusion": "本研究发现，单独依赖摘要的人类和LLM都无法稳定地表现出超越随机的表现。然而，更具分析性的评论能够使人类和LLM协作团队在决策上显著超越个体基准。这强调了通过评估生成文本来促进人类和LLM之间协同决策的重要性，并指出传统度量标准的关键局限性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01334", "html_url": "https://arxiv.org/abs/2507.01334", "title": "符号推理还是数值计算？理解推理型大语言模型中的物理问题解决", "title_en": "Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs", "authors": "Nifu Dan,Yujun Cai,Yiwei Wang", "background": "对于大型语言模型（LLMs），物理推理一直是复杂的挑战，需要深厚的理论理解与高超的问题解决技能的结合。本研究通过探索如Deepseek-R1等先进提示调优推理模型的应用，旨在解决SciBench基准提供的多样化物理问题。实验结果表明，这些推理模型具有显著的能力，不仅在回答复杂的物理问题上达到了最新水平的准确率，还能生成侧重于符号推导的独特推理模式。此外，研究还发现，即使是这些高级推理模型，通过少量提示的有效整合，仍然可以在总体准确率上带来可测量的提升，这表明有继续性能改进的潜力。", "innovation": "本研究探索了高级提示调优推理模型（如Deepseek-R1）在解决SciBench基准物理问题上的应用。实验结果不仅展示了这些模型在复杂物理问题上的最新准确率，还揭示了它们独特的符号推导特点。此外，研究表明，即使是这些复杂的模型，采用少量提示可以有效提高准确率，表明了持续性能改进的可能性。", "conclusion": "本研究通过深化对推理型大语言模型物理问题解决机制的理解，揭示了模型在复杂物理问题上的显著能力，并强调了提示调优的重要性，为进一步提升模型性能提供了新的视角。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.00903", "html_url": "https://arxiv.org/abs/2410.00903", "title": "利用生成型人工智能进行因果表示学习：文本作为处理的应用", "title_en": "Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments", "authors": "Kosuke Imai,Kentaro Nakamura", "background": "在使用未结构化高维处理（如文本）进行因果推断时，需要增强有效性的方法。本文探讨了如何利用生成人工智能（GenAI）的强大力量来提高因果推断的有效性，特别是通过使用深度生成模型（如大型语言模型LLM）来高效生成处理并利用其内部表示来进行后续的因果效应估计。", "innovation": "本文提出了GenAI增强因果推断（GenAI-Powered Inference, GPI）方法，通过使用大型语言模型生成文本处理，并利用其内部表示来估计因果效应。这种方法不需从数据中学习因果表示，因此能够产生更准确和更高效的估计。GPI方法还通过使用双重机器学习推导了所提估计量的渐近性质，并通过工具变量方法将其扩展到基于人类感知的处理特征情况。此外，该方法还适用于文本重用场景，其中LLM用于再生现有文本。", "conclusion": "本文通过双重机器学习正式建立了非参数识别平均处理效应所需的条件，提出了一种避免重叠假设违反的估计策略，并通过应用生成的文本数据从开源LLM Llama 3进行模拟和实际研究，展示了所提出的估计器对现有的最先进的因果表示学习算法的优势。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.06106", "html_url": "https://arxiv.org/abs/2502.06106", "title": "电路调整：一种用于识别参数冗余和调优神经网络的机制性方法", "title_en": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks", "authors": "Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang", "background": "机制性解释研究旨在反向工程一个模型以解释其行为。尽管最近的研究重点是某项行为的静态机制，但模型内部的学习动态尚未得到探索。本文通过开发一种可解释的微调方法，来分析学习背后的机制。作者首先引入节点层面固有维度的概念，以描述计算图中模型的学习过程，基于这一理论，提出了一种电路调优算法，该算法分为两个阶段：第一阶段逐步构建特定任务下的最小子图，第二阶段以启发式的方式更新关键参数。实验结果证实了节点层面固有维度的存在，并展示了该方法在透明和可解释微调中的有效性。此外，作者还展示了在微调前、微调中和微调后的电路可视化分析，为神经网络学习过程中的自我组织机制提供了新的见解。", "innovation": "本文开发了一种可解释的细调方法，称为电路调优。该方法通过引入节点层面的固有维度的概念，以及提出一种创新的两阶段算法（电路调优），逐步构建最小子图并以启发式方式更新关键参数，为理解神经网络中的学习动态提供了新视角。此外，该方法还能够识别参数冗余并实现透明和可解释的微调。", "conclusion": "本文证明了节点层面固有维度的存在，并证实了电路调优方法在透明和可解释的细调中的有效性。电路调优还为神经网络在学习过程中的自我组织机制提供了新的见解，且能够在微调的过程中识别出冗余参数，提高模型效率和解释性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.07618", "html_url": "https://arxiv.org/abs/2411.07618", "title": "使用稀疏特征级约束的直接偏好优化", "title_en": "Direct Preference Optimization Using Sparse Feature-Level Constraints", "authors": "Qingyu Yin,Chak Tou Leong,Hongbo Zhang,Minjun Zhu,Hanqi Yan,Qiang Zhang,Yulan He,Wenjie Li,Jun Wang,Yue Zhang,Linyi Yang", "background": "大规模语言模型（LLMs）与人类偏好的对齐依然是一个关键性挑战。尽管后训练技术如带有反馈的人类强化学习（RLHF）和直接偏好优化（DPO）取得了显著的成功，但它们往往会导致计算效率低下和训练不稳定的问题。当前的方法虽然提高了模型的偏好对齐效率，但由于复杂的优化过程，仍然无法同时保证模型的稳定性和计算效率。\n", "innovation": "本文提出了一种新颖的方法——特征级约束偏好优化（FPO），旨在简化模型对人类偏好的对齐过程，同时保证模型的稳定性。FPO利用了预训练的稀疏自动编码器（SAEs）并引入了特征级约束，使得模型能够高效地进行稀疏特征的对齐。这种方法采用在训练良好的稀疏自动编码器中激活的稀疏特征，并通过特征级的离线参考使用序贯KL散度来实现高质量的对齐效果。相比之下，FPO方法在保持高对齐效果的同时，还能显著降低计算成本，特别是与当前最先进的基线方法相比还提高了5.08%的胜率，这使得它成为了高效可控的大规模语言模型对齐的好选择。\n", "conclusion": "实验结果表明，FPO在基准数据集上实现了显著的性能提升，并且相对于最先进的基线方法，它具有更低的计算成本。这表明FPO是一种可行且高效的解决方案，能够实现大规模语言模型与人类偏好的有效和可控对齐。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21191", "html_url": "https://arxiv.org/abs/2506.21191", "title": "Prompt-Guided Turn-Taking Prediction", "title_en": "Prompt-Guided Turn-Taking Prediction", "authors": "Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara", "background": "转手预测模型是对话系统和聊天机器人的关键组成部分。近年来，基于变换器的架构被用于实时预测言语活动，但缺乏通过文本提示动态控制预测的方式，使得控制不够直观和明确，难以适应不同的对话伙伴和环境变化。现有数据集中缺少用于指导预测的文本提示数据，影响了模型的多样性和灵活性。本文基于此背景进行研究，提供了一种新的模型，通过文本提示动态调整转手预测，增加了更多的灵活性和适应性。", "innovation": "本文提出了一个基于变换器的声音活动投影（VAP）模型的新颖方法，将文本提示嵌入通道变换器和跨通道变换器之中，通过大型语言模型生成合成提示语句，以适应缺少现有数据集中文本提示数据的问题。这种模型可以通过指令如“更快”或“更冷静”实现对对话节奏的动态调整，显著提高了预测准确性，并且能更加有效地根据文本提示变化说话者的换手时机。", "conclusion": "通过本研究提出的指导性转手预测模型，增强了软对话系统和聊天机器人在实时预测语音活动方面的表现。模型在超过950小时的人与人之间的口语对话数据集上进行了评估，实验结果表明，与现有方法相比，这种模型能更准确地预测转手时间，并且能够更有效地根据文本提示调整说话节奏。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23661", "html_url": "https://arxiv.org/abs/2506.23661", "title": "通过BeamAttack评估虚假信息分类系统对 adversarial examples 的鲁棒性", "title_en": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack", "authors": "Arnisa Fazla,Lucas Krauter,David Guzman Piedrahita,Andrianos Michail", "background": "该论文扩展了BeamAttack算法，这是一种通过基于束搜索的词级修改来评估文本分类系统鲁棒性的对抗攻击算法。背景提到了原文的BeamAttack已经能够通过词级别的修改来评估模型的鲁棒性，但此次研究对其进行了扩展，增加了对词的删除支持和选择不执行替换的选项，提高了发现能改变模型预测的最小修改的能力。此外，研究还整合了LIME以更好地优先进行单词替换。实验在多个数据集和目标模型（BiLSTM、BERT和对抗训练的RoBERTa）框架下进行了验证，结果显示，该方法在保持原始文本的语义和词汇相似性的同时，攻击成功率达到99%以上。", "innovation": "1. 支持单词删除，提高了修改的灵活性。2. 引入了可选的不执行替换的选项，有助于发现改变模型预测所需的最小修改。3. 集成了LIME，以优先进行更合理的单词替换。4. 在多个数据集和模型上进行了评估，展示了高攻击成功率（超过99%），同时保持语义和词汇相似性。", "conclusion": "该研究通过BeamAttack方法有效地评估了虚假信息分类系统的鲁棒性，并且在多个模型和数据集上验证了攻击的有效性和局限性。同时，新研究还进一步增强了BeamAttack的实用性，展示了其在实际应用中的潜力。研究结果表明，虽然该方法在一定的数据集和模型上表现优异，但仍存在一定的局限性，需要进一步的优化和改进。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12479", "html_url": "https://arxiv.org/abs/2506.12479", "title": "AI Flow: 视角、场景和方法", "title_en": "AI Flow: Perspectives, Scenarios, and Approaches", "authors": "Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li", "background": "信息论由Claude Shannon奠定基础，而Alan Turing的机器智能视阈则提供了机器智能的框架。IT/CT的融合发展产生了持续不断的数据连接和计算波浪，这种协同作用引发了科技革命，现已达到通过大规模人工智能模型重塑产业和重新定义人机协作的高峰。然而，实现普遍智能面临大量资源消耗和高通信带宽需求的重大挑战。", "innovation": "AI Flow引入了一个跨学科框架，结合了最新的IT和CT进展，特别强调三个关键点：首先，设备-边缘-云框架为基础，优化低延迟模型推理的可扩展性和效率；其次，介绍了家庭模型的概念，即一系列具有对齐隐藏特征的不同大小模型，实现有效的合作并灵活适应各种资源约束和动态环境；最后，基于连接性和交互的智能涌现是一种新的AI Flow范式，通过利用通信网络增强连接性，实现跨异构节点的AI模型协作，创造出超越任何单一模型能力的智能。", "conclusion": "AI Flow的创新提供了增强的智能、及时的响应能力和广泛的AI服务可及性，为人工智能技术和通信系统的更紧密融合铺平了道路。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.18530", "html_url": "https://arxiv.org/abs/2412.18530", "title": "关于语言生成的表征：幻觉、广度和稳定性的相互作用", "title_en": "On Characterizations for Language Generation: Interplay of Hallucinations, Breadth, and Stability", "authors": "Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas", "background": "本文研究了由Kleinberg和Mullainathan提出的语言生成极限问题，基于Gold和Angluin的经典工作。Kleinberg和Mullainathan的结果提供了一种无限生成算法，可以从任何可数语言集合生成未见过的字符串，但牺牲了覆盖范围或广度。近期研究引入了不同类型的广度概念，并探讨了生成广度何时可行的问题，但尚未完全阐述这些概念的特性。本文通过表征现有广度及其自然扩展的概念来解决上述问题，提出了对多种性能指标的有效性限制，如不能训练生成器在特定语言K上的困惑度更高或幻觉率更低。此外，本文还探讨了广度和稳定的生成器（算法在见过有限数量的字符串后停止改变），并提出了无条件的下限，强化了KMV25的结果，表明在需要稳定性的条件下生成具有多种现有广度的概念变得同样困难。研究强调了广度、稳定性和一致性之间复杂的相互作用。", "innovation": "本文的主要创新在于表征了已经存在的广度概念及其自然扩展，并提出了无条件的下限，这使得在需要稳定性的条件下生成具有多种现有广度的概念变得同样的困难，这为语言生成中不稳定和稳定生成器之间的分离设立了标杆，为理解广度、稳定性和一致性之间的复杂相互作用提供了新的视角。", "conclusion": "本文结果表明，对于现有的广度概念和其自然扩展，不可能训练出在特定语言K上的困惑度更高或幻觉率更低的生成器。此外，需要稳定性的条件下，尽管生成广度的概念不同，但生成器的问题变得一样困难。这突出展示了广度、稳定性和一致性之间的丰富联系和复杂交互作用。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.17828", "html_url": "https://arxiv.org/abs/2506.17828", "title": "通过强化学习迭代重权-优化方法冻结大语言模型的对齐", "title_en": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach", "authors": "Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong", "background": "当前对齐大型语言模型（LLMs）与人类偏好通常需要使用如RLHF和DPO等微调方法。这些方法直接优化模型参数，因此无法在测试时改进模型性能，也不能在无法访问模型权重的情况下使用。相比之下，测试时的方法通过利用奖励函数来引导和提高输出质量，但它们会在推理上产生高成本，并且其单次指导常常基于不完美的奖励或价值函数，导致次优输出。", "innovation": "本文介绍了一种名为Iterative Reweight-then-Optimize (IRO)的方法，这是一种强化学习框架，能够在不更改基础模型参数的情况下进行RL风格的对齐。训练阶段，每次迭代包括从基础模型抽样候选，利用当前的价值函数重新抽样，并训练一个新的轻量级价值函数以指导下一次解码过程。在测试阶段，价值函数用来通过基于搜索的优化过程来引导基础模型生成。重要的是，用户可以通过IRO对自身数据集对齐模型，类似于OpenAI的强化微调（RFT），但无需访问模型权重。", "conclusion": "IRO方法提供了一种在不接触模型权重的情况下优化冻结的大语言模型的新途径，这种方法不仅降低了成本，还在无需访问模型权重的情况下提高了对齐质量。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02074", "html_url": "https://arxiv.org/abs/2507.02074", "title": "大型语言模型在视频中的碰撞检测：方法、数据集和挑战的综述", "title_en": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges", "authors": "Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma", "background": "碰撞检测在智能交通系统中至关重要，近年来，大型语言模型（LLMs）和视觉语言模型（VLMs）的发展极大地改变了我们处理、理解和总结多模态信息的方式。本文综述了利用LLMs进行基于视频数据的碰撞检测的方法，并探讨了相关数据集、模型架构、性能基准以及面临的挑战和机遇。", "innovation": "本文提供了一个结构化的融合策略分类体系，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前面临的研究挑战和机遇。这些内容为未来在这个迅速发展的视频理解与基础模型交叉领域中的研究提供了基础和指导。", "conclusion": "本文为智能交通系统中基于视频的碰撞检测领域的基础模型研究提供了坚实的基础，指出了未来的研究方向，并强调了解决当前挑战的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01551", "html_url": "https://arxiv.org/abs/2507.01551", "title": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "title_en": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "authors": "Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua", "background": "过程强化学习（PRL）显示出提高大型语言模型（LLMs）推理能力的巨大潜力，但引入额外的过程奖励模型会导致显著的计算开销，并且缺乏统一的基于过程的优势估计理论框架。", "innovation": "本文提出了自我引导的过程奖励优化（SPRO）框架，该框架通过两个关键技术创新实现了过程感知的RL：（1）理论上证明过程奖励可以从策略模型本身内在推导而来；（2）引入了明确的累积过程奖励和掩蔽步骤优势（MSA），在共享提示采样组中促进严谨的步骤优势估计。实验结果显示，SPRO在训练效率上比vanilla GRPO高3.4倍，测试准确率提高17.5%，同时在训练过程中保持稳定的高策略熵，减少平均响应长度约三分之一，证明了足够的探索性并防止了奖励滥用。与以结果监督的RL方法如GRPO相比，SPRO没有额外的计算开销，有助于工业应用场景的实施。", "conclusion": "SPRO不仅提高了训练效率和测试准确率，还保持了高策略熵和减少响应长度，证明了足够的探索性并防止了奖励滥用，而且没有增加额外的计算开销，符合工业应用的要求。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18959", "html_url": "https://arxiv.org/abs/2506.18959", "title": "从网页搜索到智能驱动深度研究：以推理代理激励搜索", "title_en": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "authors": "Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu", "background": "信息检索是现代知识获取的基础，每天在不同领域处理数十亿的查询。然而，传统的基于关键词的搜索引擎越来越难以应对复杂的、多步骤的信息需求。为此，文章提出大型语言模型（LLMs）具备推理能力和自主能动性，引领了一种新的范式——智能驱动深度研究。这种系统通过紧密整合自主推理、迭代检索和信息合成，形成动态反馈循环，超越了传统的信息搜索技术。从静态的网页搜索，到互动的、基于代理系统的规划、探索和学习，文章展示了智能驱动深度研究在整个搜索过程中的重要性及其优越性。", "innovation": "文章提出了一种新的信息检索范式——智能驱动深度研究。这种新的范式利用大型语言模型的推理和自主能力，通过自主推理、迭代检索和信息合成形成动态反馈循环，改变了传统的信息搜索模式。文章还引入了试验时的扩展定律来正式化计算深度对推理和搜索影响，展示了其在多个基准测试中的优异性能，并指出未来的信息查找将主要采用这种新的范式。", "conclusion": "智能驱动深度研究不仅显著超越现有的信息检索方法，而且有望成为未来主导的信息搜索范式。文章收罗了相关的行业产品、研究论文、基准数据集以及开源实现，以方便科研社区的使用。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22049", "html_url": "https://arxiv.org/abs/2506.22049", "title": "GPAS: 通过Gradient-Preserving Activation Scaling加速大型语言模型预训练的收敛", "title_en": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling", "authors": "Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Lu Yin,Can Yang", "background": "现代大型语言模型，如LLaMA、Qwen和DeepSeek系列，主要采用预层标准化（Pre-LN）的Transformer架构。虽然Pre-LN在预训练中稳定且可扩展到大型模型，但它会导致激活方差随层数指数增长，使得残差连接中的捷径路径逐渐占据主导地位，限制了深层的学习能力。", "innovation": "提出了一种名为渐变保持激活缩放（GPAS）的简单技术，可以在保持梯度不变的情况下缩放中间激活。这种方法保留了激活中的信息，避免了与梯度缩放相关的梯度消失问题，并在不同的模型大小实验中表现出一致的性能提升。GPAS不仅能够提升Pre-LN Transformer，还能改善其他替代架构，如Sandwich-LN和DeepNorm，显示出其在广泛设置中的灵活性和提升训练动态的潜力。", "conclusion": "广泛的实验表明，GPAS能够在不同规模的模型从71M到1B中实现一致的性能提升。它不仅对Pre-LN Transformer具有加速收敛的应用，还能改善其他类似架构的效果，展示了其广泛的应用前景。源代码可以在指定的网址获取。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01548", "html_url": "https://arxiv.org/abs/2507.01548", "title": "使用汉字编织叙事桥梁：为老年移民举办的AI共同创作工作坊", "title_en": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "authors": "Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen", "background": "该论文探讨了老年群体，特别是城市中国中老年移民，如何通过AI辅助共同创作参与个人叙述的表达。这些叙述往往被分割、在报道中被忽略或是难以口头表达。通过结合口头叙述和汉字象征性重建的试点研讨会，参与者分享了迁移的记忆，并使用大型语言模型（LLM）建议的xiaozhuan字符符号，以及物理材料，共同重新创作新的汉字形式。在此过程中，人类促进者和软AI存在支持下，参与者将生活经验转化为视觉和触觉的表现形式，无需数字技能。这种方法为老年与AI的合作提供了新的视角，重新定位AI的角色，从内容生产者转变为支持机制，同时在社会技术系统中支持叙述代理权。", "innovation": "该工作坊通过结合口头叙述和汉字象征性重建，使用AI生成的符号进行新的汉字创作，参与者无需具备数字技能即可将生活经验转化为视觉和触觉的表达。这种方法重新定义了人机协作的方式，将AI定位为支持机制，而非内容生产者，并在社会技术系统中支持老年群体的叙事代理权。", "conclusion": "此方法为了解老年人与AI的合作提供了新的视角，强调了非数字背景下的叙事表达，并提出了在社会技术系统中支持老年群体叙述能力的可行性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02200", "html_url": "https://arxiv.org/abs/2507.02200", "title": "ESTR-CoT：带有链式推理的可解释且准确的事件流场景文本识别方法", "title_en": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning", "authors": "Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang", "background": "事件流基于场景文本识别作为一种新兴的研究方向近年来受到广泛关注。相较于常用RGB摄像头，它在低光照和快速运动等极端场景中表现更好。现有的研究工作主要采用端到端编码解码框架或大型语言模型以增强识别性能，但这些方法仍然存在不充分的可解释性和弱语境逻辑推理能力的问题。本文的背景是针对这些挑战，提出一种新的基于链式推理的事件流场景文本识别框架，称为ESTR-CoT。", "innovation": "提出了ESTR-CoT框架，主要创新点包括：1) 使用EVA-CLIP（ViT-G/14）视觉编码器将输入事件流转换为令牌；2) 利用Llama标记器编码生成提示；3) 采用Q-former将视觉标记与预训练的大语言模型Vicuna-7B对齐，同时输出答案和推理过程；4) 通过监督微调优化框架；5) 提出一种大规模的链式推理数据集，通过三阶段处理（生成、打磨和专家验证）进行训练；6) 在三个事件流STR基准数据集（包括EventSTR、WordArt*、IC15*）上进行了大量实验证明了框架的有效性和可解释性。", "conclusion": "本文通过ESTR-CoT框架在三个事件流STR基准数据集上验证了方法的有效性和可解释性。此外，还提出了一个大规模的CoT数据集，为后续基于推理的大模型的发展奠定了坚实的数据基础。源代码和预训练模型将在指定的网站上发布。"}
{"llm_update_time": "20250707", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21506", "html_url": "https://arxiv.org/abs/2506.21506", "title": "Mind2Web 2: 用 agent-as-a-judge 评估有自主性的搜索", "title_en": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge", "authors": "Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su", "background": "有自主性的搜索，如深度研究系统，指的是代理自主浏览网络、综合信息，并返回全面的、支持引文的答复。这种搜索方式代表了用户与海量信息交互方式的重大转变，有望提供更高的效率和认知卸载。然而，随着这些系统的复杂性和开放式问题的激增，现有的评估基准和方法已经无法跟上，这些方法大多假设短时间内的搜索和静态答案。Mind2Web 2 研究了一个包含130个任务的基准，这些任务现实、高质量且需要长期的实时网络浏览和广泛的信息综合，构建时使用了超过1000小时的人工劳动。这些任务复杂且需要时间依赖性的答案评估，目前缺乏有效的评估方法和标准。", "innovation": "为了应对随着时间变化和复杂性变化的答案评估挑战，Mind2Web 2 提出了一个新型的“代理作为裁判”(Agent-as-a-Judge) 框架。该方法基于树状结构的评分设计构建任务特定的裁判代理，以自动评估答案的正确性和来源属性。该研究还全面评估了十种前沿的有自主性的搜索系统及人的表现，以及进行了详细的错误分析，为未来的发展提供了见解。最好的系统，OpenAI 深度研究，已能达到人类表现的50-70%，花费时间为空间的一半，展示了巨大的潜力。Mind2Web 2 为开发和基准测试下一代有自主性的搜索系统提供了严格的基础。", "conclusion": "Mind2Web 2 提供了一个严格的基准，用于开发和评估下一代有自主性的搜索系统。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02148", "html_url": "https://arxiv.org/abs/2507.02148", "title": "水下单目量测量深度估计：现实世界的基准和合成微调", "title_en": "Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning", "authors": "Zijie Cai,Christopher Metzler", "background": "单目深度估计最近取得了进展，不仅能提供相对深度还能提供精确深度预测。但在水下环境中，由于光线衰减和散射、颜色失真和浑浊等原因，其可靠性仍然有限。目前缺乏高质量的精确地面实况数据作为参考。因此，本文在FLSea和SQUID等具有量测量注释的真实水下数据集上，提供了全方位的零样本和微调单目量测量深度估计模型基准测试。研究表明，大型模型虽然在空中的应用效果很好，但在水下表现不佳，这是由于领域转移的巨大差异。因此，本文展示了对合成下的Hypersim数据集进行微调的Depth Anything V2模型，在不同范围的水下条件下，该模型在所有基准上的一致性能提升，并优于仅在干净的Hypersim数据集上训练的基线模型。这项研究详细评估并可视化了水下场景的单目量测量深度估计，并强调了领域适应和规模感知监督对于在具有挑战性的水下环境中实现稳健和通用化的量测量深度预测的重要性，为未来的研究提供了重要参考。", "innovation": "本文提出了一种合成微调方法，使用物理为基础的水下图像生成模型生成合成的Hypersim数据集，并使用此数据集微调了Depth Anything V2模型。该方法显著提高了模型在各种水下条件下的表现，并优于仅基于空中的Hypersim数据集训练的基线模型。此外，研究提供了详细的量化和可视化结果，强调了领域适应和规模感知监督的重要性。", "conclusion": "本文全面评估和可视化了单目量测量深度估计在水下场景中的表现，强调领域适应和规模感知监督对于在具挑战性的水下环境中实现稳健和通用化的量测量深度预测的重要性。未来的研究可以进一步探索其他领域适应方法和技术，以提高单目量测量深度估计的总体性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02217", "html_url": "https://arxiv.org/abs/2507.02217", "title": "理解条件化合成数据时的权衡", "title_en": "Understanding Trade offs When Conditioning Synthetic Data", "authors": "Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma", "background": "在工业视觉系统中，仅从少量图像中学习鲁棒的物体检测器是一个关键挑战，因为高质量的训练数据收集可能需要数月时间。合成数据因其高效性而成为数据高效视觉检查和拾取放置机器人的重要解决方案。目前的管道依赖于Blender或Unreal等3D引擎，尽管这些引擎提供精细控制，但渲染小型数据集仍可能需要数周时间，且合成图像与现实之间的差距较大。尽管弥散模型在几分钟内即可生成高质量图像方面展现了突破性的潜力，但在低数据状态下实现精细控制依旧困难。许多扩展弥散模型的方法现已超越简单的文本提示，但不同条件方案对合成数据质量的影响尚缺乏了解。", "innovation": "研究了来自四个标准物体检测基准的八十种不同视觉概念，并比较了两种条件化策略：基于提示和基于布局的条件化。当条件化提示较少时，基于提示的条件化生成更高质的合成数据；随着多样性增加，基于布局的条件化变得更为优越。当布局提示匹配全部训练分布时，合成数据使得平均精度提高34%，并在某些情况下提高高达177%，远超过仅使用真实数据的情况。", "conclusion": "研究结果表明，在低数据条件下，将视觉概念的多样性考虑进布局条件化可以显著提高合成数据的质量，从而在物体检测任务中产生更好的性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02212", "html_url": "https://arxiv.org/abs/2507.02212", "title": "SciGA：用于学术论文设计图形摘要的综合数据集", "title_en": "SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers", "authors": "Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi", "background": "图形摘要（GAs）在科学论文中起到关键的视觉传达作用，但其潜在的沟通增强价值尚未被广泛认识到。当前，虽然图1往往被用作事实上的GA，设计有效的GA需要高级的可视化技能，这成为其普及应用的障碍。目前缺乏有效支持GA选择推荐及自动GA生成的大型数据集。", "innovation": "SciGA-145k是包含约145,000篇科学论文和114万个图形的大型数据集，专门用于支持GA选择和推荐，以及促进自动GA生成的研究。作者定义了两个任务：1) 内部GA推荐，识别出合适的图形用于某篇论文的GA，2) 外部GA推荐，从其他论文中检索GA来激发新GA的创建。提出了一种新的推荐指标—置信度调整的最top-1黄金标准比率（CAR），该指标能够更细致地分析模型行为，并克服了传统排名指标的局限性。通过统一这些任务和指标，SciGA-145k为推进视觉科学交流提供了基础，同时促进了科学领域人工智能的发展。", "conclusion": "SciGA-145k为GA的设计提供了大型数据支持，同时定义了有助于自动GA生成的研究任务，并引入了新的推荐指标，为视觉科学交流的发展奠定了基础。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02222", "html_url": "https://arxiv.org/abs/2507.02222", "title": "高保真差分信息驱动的二值视觉变换器", "title_en": "High-Fidelity Differential-information Driven Binary Vision Transformer", "authors": "Tian Gao,Zhiyuan Zhang,Kaijie Yin,Xu-Cheng Zhong,Hui Kong", "background": "二值视觉变换器（ViTs）为解决高计算/存储需求与边缘设备部署限制之间的权衡提供了有希望的方法。然而，现有的二值ViT方法往往遭受严重性能退化，或者严重依赖全精度模块。", "innovation": "提出了一种名为DIDB-ViT的新颖二值ViT，它具有高度信息性，同时保持原始ViT架构和计算效率。通过设计一种包含差分信息的注意力模块来缓解二值化导致的信息损失并增强高频保留。通过离散Haar小波进行频域分解并跨不同频率整合相似性来保持二值Q和K张量之间的相似性计算的保真度。此外，引入了改进的RPReLU激活函数来重构激活分布，扩展了模型的表示能力。", "conclusion": "实验结果表明，我们的DIDB-ViT在多个ViT架构中显著优于最先进的网络量化方法，实现了优越的图像分类和分割性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02265", "html_url": "https://arxiv.org/abs/2507.02265", "title": "多标签分类框架在飓风损失评估中的应用", "title_en": "Multi-Label Classification Framework for Hurricane Damage Assessment", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "飓风造成的破坏多样且严重，需要及时、准确地评估以有效应对灾难。传统的单标签分类方法无法捕捉到飓风后多种不同损害类型的复杂性。", "innovation": "本研究提出了一种基于ResNet的特征提取模块和类特定注意机制的多标签分类框架，用于通过航拍图像评估损害情况。该方法在飓风迈克尔的Rescuenet数据集上的平均精度达到90.23%，优于现有基础方法。", "conclusion": "该框架提高了飓风后损害评估的效率与精确度，有助于更精准地应对灾难，促进了未来灾害减轻与韧性策略的发展。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02205", "html_url": "https://arxiv.org/abs/2507.02205", "title": "Team RAS在第九届ABAW竞赛中的多模态复合表情识别方法", "title_en": "Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach", "authors": "Elena Ryumina,Maxim Markitantov,Alexandr Axyonov,Dmitry Ryumin,Mikhail Dolgushin,Alexey Karpov", "background": "复合表情识别（CER）是情感计算的一个子领域，旨在检测由基本情绪组合而成的复杂情感状态。现有方法往往依赖于特定任务的训练数据，这限制了模型的应用范围和灵活性。为了突破这一局限，本文提出了一种新颖的零样本多模态方法，将静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本等六种异构模态整合到单个管道中。这种方法不依赖于特定任务的训练数据，而是采用基于零样本的组件，包括对比语言-图像预训练（CLIP）的标签匹配和Qwen-VL的语义场景理解。这种方法进一步引入了多头概率融合（MHPF）模块和复合表情（CE）变换模块，后者使用对偶概率聚合（PPA）和对偶特征相似性聚合（PFSA）方法生成可解释的复合情感输出。", "innovation": "本文提出的多模态复合表情识别方法创新之处在于：1）使用零样本组件（如基于CLIP的标签匹配和Qwen-VL的语义场景理解），有效提升了模型的普适性；2）引入了多头概率融合（MHPF）模块，能够动态加权模态特异性预测；3）提出了复合表情（CE）变换模块，使用对偶概率聚合（PPA）和对偶特征相似性聚合（PFSA）方法生成可解释的复合情感输出。", "conclusion": "在多数据集训练下，该方法在AffWild2、AFEW和C-EXPR-DB上的零样本测试F1分数分别为46.95%、49.02%和34.85%，接近于在目标数据上监督训练的方法。这表明该方法能够有效捕捉复合表情，无需领域适应，且源代码公开可获取，具有重要的研究意义和实际应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02271", "html_url": "https://arxiv.org/abs/2507.02271", "title": "通过自我蒸馏突出部分可见的影视语言以实现视频到音频生成", "title_en": "Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation", "authors": "Feizhen Huang,Yu Wu,Yutian Lin,Bo Du", "background": "视频到音频（V2A）生成在电影和视频后期制作中取得了显著进展，但当前方法忽视了影视语言，这是电影制作中艺术表达的关键部分。因此，在仅部分可见拟音目标的场景中，其性能下降。", "innovation": "提出了一种简单的自我蒸馏方法来扩展V2A模型，使其适用于影视语言场景。通过模拟影视语言的变化，学生模型学习将训练对的视频特征与相同的音视频对应关系对齐，从而有效捕捉声音和部分视觉信息之间的关联。", "conclusion": "该方法不仅在所有评估指标下实现了显著的改进，部分可见场景下的性能优越，还在大规模V2A数据集VGGSound上增强了性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02250", "html_url": "https://arxiv.org/abs/2507.02250", "title": "FMOcc: TPV-驱动的流动匹配3D占用预测选择状态空间模型", "title_en": "FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model", "authors": "Jiangxia Chen,Tongyuan Huang,Ke Song", "background": "3D语义占用预测在自动驾驶中起着关键作用。然而，由于少量帧图像固有的限制和3D空间中的冗余性，预测遮挡和远处场景的准确性受到限制。现有的方法通过融合历史帧数据来提升性能，但这需要额外的数据和大量的计算资源。", "innovation": "本文提出了FMOcc，一种基于三视角视图（TPV）精炼占用网络，结合流动匹配选择状态空间模型，用于少量帧的3D占用预测。首先，设计了一个基于流动匹配模型的功能修正模块，称为流匹配选择状态空间模块（FMSSM）。其次，通过设计TPV SSM层和面选择性状态空间模型（PS3M），选择性地过滤TPV特征，减少了空气体素对非空体素的影响，提升了模型的整体效率和远处场景的预测能力。最后，设计了掩码训练方法，增强了FMOcc的鲁棒性，并解决了传感器数据丢失的问题。实验结果表明，FMOcc在Occ3D-nuScenes和OpenOcc数据集上优于现有方法。", "conclusion": "我们的FMOcc在Occ3D-nuScenes验证集上的RayIoU得分为43.1%，mIoU得分为39.8%，使用两帧输入；在OpenOcc数据集上，有5.4 G的推理内存和330ms的推理时间，得分为42.6%的RayIoU。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02279", "html_url": "https://arxiv.org/abs/2507.02279", "title": "LaCo: 层级化的视觉令牌高效压缩方法用于多模态大型语言模型", "title_en": "LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models", "authors": "Juntao Liu,Liqiang Niu,Wenchao Chen,Jie Zhou,Fandong Meng", "background": "现有的视觉令牌压缩方法多为后编码器模块，限制了其在效率提升方面的潜力。这些方法通常应用于模型的后处理阶段，无法在视觉编码器的中间层进行有效的压缩和优化，导致整体效率不高.", "innovation": "本文提出了LaCo（层级视觉令牌压缩）框架，这是一种能够在视觉编码器中间层有效进行令牌压缩的新颖方法。LaCo包含两个核心组件：1) 层级像素混排机制，通过对空间到通道的转换系统地合并相邻的令牌；2) 基于非参数捷径的残差学习架构，能够在压缩过程中保留关键视觉信息。实验结果显示，LaCo在视觉编码器中间层压缩令牌时优于所有现有方法，并且优于外部压缩方法，在保持高性能的同时能提高20%以上的训练效率和15%以上的推理速度.", "conclusion": "LaCo方法能够有效提升多模态大型语言模型的训练和推理效率，在视觉编码器中间层的令牌压缩方面展现出了卓越的效果。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02270", "html_url": "https://arxiv.org/abs/2507.02270", "title": "MAC-Lookup: 多轴条件查找模型用于水下图像增强", "title_en": "MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement", "authors": "Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen", "background": "水下图像在探索中至关重要，但受到光线变化、水体浑浊和气泡等因素的影响，面临可见性和颜色问题。传统的先验方法和像素级方法往往无效，而深度学习方法缺乏充足的高质量数据集。", "innovation": "本文引入了Multi-Axis Conditional Lookup (MAC-Lookup)模型，通过改善色彩准确性、清晰度和对比度来提升视觉质量。该模型包括Conditional 3D Lookup Table Color Correction (CLTCC)进行初步的颜色和质量矫正，以及Multi-Axis Adaptive Enhancement (MAAE)进行细节修正。该模型避免了过度增强和饱和问题，适用于水下场景的挑战。", "conclusion": "广泛实验表明，MAC-Lookup在增强水下图像方面优于现有方法，能够更好地恢复细节和颜色。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02252", "html_url": "https://arxiv.org/abs/2507.02252", "title": "SurgVisAgent：适用于多种手术视觉增强的多模态代理模型", "title_en": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement", "authors": "Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen", "background": "精确的手术干预对患者安全至关重要，先进的增强算法已被开发出来以协助外科医生进行决策。尽管取得了显著进展，这些算法通常只针对特定场景中的单一任务，限制了它们在复杂现实情况中的有效性。为解决这一问题，我们提出了一种基于多模态大规模语言模型（MLLMs）的端到端智能手术视觉代理SurgVisAgent。SurgVisAgent能够动态识别内窥镜图像中的失真类别及其严重程度，从而能够执行包括低光照增强、过高曝光校正、运动模糊消除和烟雾去除等多种增强任务。通过设计先验模型提供特定领域的知识，以及通过上下文 few-shot 学习和链式推理（CoT），SurgVisAgent能够提供定制化的图像增强，以满足各种失真类型和严重程度的需求，进一步满足外科医生的多样化需求。为了评估其性能，我们构建了一个涵盖真实手术失真情况的综合基准。广泛的实验表明，SurgVisAgent在各个方面都优于传统的一次性任务模型，凸显了其作为统一的手术辅助解决方案的潜力", "innovation": "SurgVisAgent是一种基于多模态大规模语言模型的端到端智能手术视觉代理，可以动态识别内窥镜图像中的失真类别和严重程度，从而执行多种增强任务。它通过设计先验模型提供特定领域的知识，并利用上下文 few-shot 学习和链式推理实现定制化的图像增强，适用于广泛的失真类型和严重程度，这是该领域的创新点", "conclusion": "实验结果表明，SurgVisAgent在多种手术场景下都优于传统的一次性任务模型，并展示了其作为统一的手术辅助解决方案的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02299", "html_url": "https://arxiv.org/abs/2507.02299", "title": "DreamComposer++：利用多视图条件增强扩散模型以生成3D内容", "title_en": "DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation", "authors": "Yunhan Yang,Shuo Chen,Yukun Huang,Xiaoyang Wu,Yuan-Chen Guo,Edmund Y. Lam,Hengshuang Zhao,Tong He,Xihui Liu", "background": "当前利用预训练的2D扩散模型能够生成高质量的新视角图像，但这些模型在生成可控制的新视角时受限于缺乏多视角信息，因此存在挑战。已有研究试图通过引入多视图条件来解决这一问题，但现有的方法仍有改进空间，特别是在提升当前视图感知扩散模型的多视角生成能力方面。", "innovation": "提出了一种名为DreamComposer++的灵活且可扩展的框架，该框架通过引入多视图条件来增强现有的视图感知扩散模型。DreamComposer++使用视图感知的3D提升模块从多视角中提取对象的3D表示，然后通过多视图特征融合模块将这些表示聚合并在目标视角的隐特征中渲染。最后，获得的目标视角特征被整合到预训练的图像或视频扩散模型中，用于新视角的合成。研究结果表明，DreamComposer++能够无缝地与先进的视图感知扩散模型结合，并显著提升了它们在多视角条件下的可控性生成能力。这一进步推动了可控制的3D物体重建并支持广泛的应用场景。", "conclusion": "实验结果证实，DreamComposer++能够有效增强视图感知扩散模型的多视角生成能力，使得在多视图条件下的可控新视角生成得以实现。这套方法在3D内容生成中表现出色，提供了多种潜在应用可能性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02268", "html_url": "https://arxiv.org/abs/2507.02268", "title": "基于双向域适应的跨域高光谱图像分类", "title_en": "Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation", "authors": "Yuxiang Zhang,Wei Li,Wen Jia,Mengmeng Zhang,Ran Tao,Shunlin Liang", "background": "利用高光谱遥感技术能够提取精细的土地覆盖类别。然而，用于训练和测试的卫星或机载图像通常来自不同的地区或时间，在不同的场景中，同一个类别会有显著的光谱变化。当前的域自适应方法在处理这种情况时存在局限性，尤其在目标场景适应性和可分性方面。因此，研究一种既能提取域不变特征又能获取域特定信息的方法是必要的，以增强适应性和可分性。", "innovation": "本文提出了一种双向域适应（BiDA）框架，专门针对跨域高光谱图像（HSI）分类问题，旨在提取源域和目标域的共性特征和特性信息，通过独立的自适应空间来增强适应性和可分性。该框架通过设计三支路转换器架构（源支路、目标支路和耦合支路）及其语义分词器来作为骨干，特别地，在耦合支路中引入了一种耦合多头交叉注意力（CMCA）机制来进行特征交互和跨域相关性挖掘。此外，设计了一种双向蒸馏损失来使用跨域相关性引导自适应空间学习。最后，提出了适应性强化策略（ARS）以在噪声条件下鼓励模型在源和目标场景中专注于提取特定的通用特征。实验结果表明，提出的BiDA方法在一些最新的域自适应方法上表现显著更好，在跨时间树种分类任务中的表现比最先进方法高出3%至5%以上。", "conclusion": "本文提出了一种基于双向域适应的跨域高光谱图像分类方法，通过实验验证了该方法的有效性和优越性，为高光谱图像的跨域分类提供了新的思路和参考。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02294", "html_url": "https://arxiv.org/abs/2507.02294", "title": "ViRefSAM: 视觉参考引导的分割任何模型用于遥感分割", "title_en": "ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation", "authors": "Hanbo Bi,Yulong Xu,Ya Li,Yongqiang Mao,Boyuan Tong,Chongyang Li,Chunbo Lang,Wenhui Diao,Hongqi Wang,Yingchao Feng,Xian Sun", "background": "Segment Anything Model (SAM) 在通用分割任务中表现出强大的泛化能力，但将其应用于遥感 (RS) 图像时仍然面临两大挑战。首先是为每张图像手工构建精准的提示（如点或框）耗时且低效，尤其是在具有密集的小目标或空间分散分布的 RS 场景中。其次是 SAM 缺乏领域适应性，因为它主要在自然图像上进行预训练，难以捕捉 RS 特定的语义和空间特性，特别是在分割新型或未见过的类别时表现不佳。为解决这些问题，本文基于少样本学习，提出了一种新型框架 ViRefSAM，该框架仅利用少量注释的参考图像，其中包含特定类别的物体，而不需手工提示即可实现 RS 图像中类别一致物体的自动生成。", "innovation": "本文提出的 ViRefSAM 提出了两个关键组件：(1) 视觉上下文提示编码器，可以从参考图像中提取类别特定的语义线索，并通过与目标图像的上下文交互生成物体感知的提示；(2) 动态目标对齐适配器，结合 SAM 的图像编码器，通过向目标图像特征注入类别特定的语义来缓解领域差异，使 SAM 能够动态聚焦于与任务相关的区域。实验结果表明，ViRefSAM 仅通过利用少量参考图像即可实现对未见过类别的准确和自动分割，并且在各种数据集上始终优于现有的少样本分割方法。", "conclusion": "本文通过引入 Visual Reference-SAM (ViRefSAM)，在少样本条件下实现了对 RS 图像中未见过类别的准确自动生成分割，验证了其在不同数据集上的有效性和优越性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02308", "html_url": "https://arxiv.org/abs/2507.02308", "title": "LMPNet for Weakly-supervised Keypoint Discovery", "title_en": "LMPNet for Weakly-supervised Keypoint Discovery", "authors": "Pei Guo,Ryan Farrell", "background": "该研究探讨了在仅使用类别标签进行弱监督的情况下发现语义对象关键点的任务。现有方法通常需要大量标注数据，而该研究旨在通过识别分类训练中间层滤波器并将其转化为关键点检测器来解决这一问题，以此降低对标注数据的依赖性。", "innovation": "研究提出了一种新颖的高效计算损耗层——泄漏最大池化（LMP），可以显式地鼓励最终卷积层滤波器学习与对象关键点紧密对齐的“非重复局部模式”。此外，还提出了简单的选择策略及注意力掩码策略，确保滤波器激活和网络注意力分布在整个对象而不是仅集中于最具判别性的区域。最后，提出了一种可学习的聚类层来将关键点提案分组为关键点预测，实现了对网络滤波器的直接操作以检测预定义的概念。", "conclusion": "实验表明，LMPNet 能够自动发现鲁棒于对象姿态的语义关键点，并且在关键点预测精度方面达到了与监督式姿态估计模型相当的表现。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02316", "html_url": "https://arxiv.org/abs/2507.02316", "title": "合成视频有用吗？一种基于检索评价的合成视频基准", "title_en": "Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos", "authors": "Zecheng Zhao,Selena Song,Tong Chen,Zhi Chen,Shazia Sadiq,Yadan Luo", "background": "当前的文本到视频(T2V)合成技术发展迅速，现有的评估标准主要集中在视觉质量和时间一致性方面，对于合成视频在诸如文本到视频检索(TVR)之类的下游任务中的表现提供有限的洞察。因此，需要一种新的基准来评估合成视频在构建检索模型中的实用性。", "innovation": "该论文提出了SynTVA，这是一个新的数据集和基准，旨在评估合成视频对构建检索模型的有用性。通过使用最先进的T2V模型生成合成视频，并根据八个不同的用户查询，从四个关键的语义对齐维度（对象与场景、动作、属性和提示保真度）进行注释。此外还开发了一个自动评估器来估计现有评估标准下的对齐质量，能够基于通用视频质量评估(VQA)指标和对齐评分，预测下游TVR性能。", "conclusion": "SynTVA是一个有价值的数据集增强工具，能够选择具有高实用性的合成样本，实验证明其能够显著提高TVR的结果，项目页面和数据集可访问。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02321", "html_url": "https://arxiv.org/abs/2507.02321", "title": "倾听内在之声：通过中间特征反馈调整ControlNet训练", "title_en": "Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback", "authors": "Nina Konovalova,Maxim Nikolaev,Andrey Kuznetsov,Aibek Alanov", "background": "尽管在文本生成图像的扩散模型方面取得了显著进展，但要在生成的输出中实现精准的空间控制仍然具有挑战性。ControlNet通过对初始生成模块进行改进来解决这一问题，通过引入辅助条件模块来实现更为精准的对齐。ControlNet++则进一步通过循环一致性损失优化了最终去噪步骤中的对齐效果。然而，这种方法忽略了中间生成阶段，从而限制了其整体有效性。", "innovation": "本文提出了一种新的训练策略InnerControl，旨在在整个扩散步骤中维护空间一致性。InnerControl通过训练轻量级卷积探针来从每次去噪步骤的中间UNet特征重建输入控制信号（如边缘、深度），从而有效地从高度噪点的潜在特征中提取信号，实现伪目标控制信号的训练。通过在整个扩散过程中最小化预测条件与目标条件之间的差异，InnerControl提高了对齐精度和生成质量。结合ControlNet++等现有技术，InnerControl在多种条件方法（如边缘、深度）下实现了最先进的性能表现。", "conclusion": "InnerControl通过约束扩散过程中每个微调步骤中的空间一致性，有效提升了生成的控制精度和图像质量，实现了包括边缘、深度在内的多种条件方法下的最佳性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02311", "html_url": "https://arxiv.org/abs/2507.02311", "title": "感知激活器：一种直观且可移植的大脑认知探索框架", "title_en": "Perception Activator: An intuitive and portable framework for brain cognitive exploration", "authors": "Le Xu,Qi Zhang,Qixian Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao", "background": "近年来，脑-视觉解码的发展显著进步，能够从人类视觉皮层的功能磁共振成像(fMRI)信号中高保真地重建感知到的视觉刺激。现有大多数方法采用两阶段策略：像素级和语义级。然而，这些方法依赖于低级像素对齐，但缺乏足够的细粒度语义对齐，导致多类语义对象的重建存在明显的失真问题。为了更深入理解大脑的视觉感知模式，当前解码模型如何处理语义对象，我们开发了一种实验框架，利用fMRI表示作为干预条件，通过跨注意力机制将这些表示注入到多尺度图像特征中。对比了含有和不含有fMRI信息条件下的下游检测和实例分割任务的性能及中间特征变化。研究表明，整合fMRI信号可提升下游检测与分割的准确性，证实了fMRI具有丰富的多对象语义线索和粗略的空间定位信息，这些当前模型尚未完全利用或整合.", "innovation": "我们开发了一种名为'感知激活器'的实验框架，利用fMRI表示作为干预条件，通过跨注意力机制将这些表示注入到多尺度图像特征中进行视觉刺激解码。与传统方法相比，该框架通过加入fMRI信号提升了检测和分割任务的准确性，揭示了fMRI中的语义线索和粗略空间定位信息的重要性，解决了现有方法依赖于像素级对齐，但缺乏语义级对齐的问题，从而减少了重建中的失真.", "conclusion": "我们的结果表明，将fMRI信号整合到解码模型中可以提升视觉刺激感知的准确性。fMRI不仅包含丰富的多语义对象线索，还提供粗略的空间定位信息，这为未来的脑-机交互和认知神经科学提供了新的视角。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02288", "html_url": "https://arxiv.org/abs/2507.02288", "title": "基于语言指导和表示对齐的提示分离方法在域泛化中的应用", "title_en": "Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization", "authors": "De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao", "background": "域泛化（DG）旨在开发一个通用模型，使其在未见过的目标域中也能高效运行。最近，在预训练视觉基础模型（VFMs）方面取得了进展，例如CLIP，这些模型显示出增强深度学习模型泛化能力的巨大潜力。尽管基于VFMs的域提示调优受到了越来越多的关注，但如何设计有效的提示以在不同域中萃取出不变特征仍然是一个关键挑战。本文探讨了一个利用VFMs的可控和灵活语言提示来解决这一挑战的解决方案。鉴于VFMs中的文本模态更容易分离，本文提出了一种基于文本特征的视觉提示调优新框架，该框架首先使用大型语言模型自动分离文本提示，随后通过分离的文本特征学习跨域不变的视觉表示。然而，仅依靠语言引导视觉特征分离存在局限性，因为视觉特征有时过于复杂或细腻，无法完全被描述性文本捕捉。为此，本文引入了最差显式表示对齐（WERA）机制，通过结合抽象提示作为附加引导集，增强了源域的多样性，并通过对齐约束确保视觉表示在原始和增强分布中保持一致。这些实验在主要的DG数据集PACS、VLCS、OfficeHome、DomainNet和TerraInc上证明了提出的模型优于现有最佳DG方法。", "innovation": "本文提出了一个基于文本特征的视觉提示调优的新框架（text feature-guided visual prompt tuning framework）。该框架首先使用大型语言模型自动分离文本提示，然后通过分离的文本特征学习跨域不变的视觉表示。此外，文章还引入了一种最差显式表示对齐（WERA），通过结合抽象提示以增强源域的多样性，同时通过对齐约束确保视觉表示的一致性。", "conclusion": "实验结果证明，本文提出的基于文本特征的视觉提示调优方法和最差显式表示对齐机制在多个主流的DG数据集上优于当前最先进的DG方法。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02307", "html_url": "https://arxiv.org/abs/2507.02307", "title": "Flow-CDNet：一种用于同时检测慢变化和快变化的双时相图像的新网络", "title_en": "Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images", "authors": "Haoxuan Li,Chenxu Wei,Haodong Wang,Xiaomeng Hu,Boyuan An,Lingyan Ran,Baosen Zhang,Jin Jin,Omirzhan Taukebayev,Amirkhan Temirbayev,Junrui Liu,Xiuwei Zhang", "background": "传统的变化检测通常涉及识别同一位置在不同时间拍摄的双时相图像之间的变化区域。虽然显著的变化在许多场合中至关重要，但在实际应用场景中，缓慢的变化也同样重要，如斜坡、大坝和尾矿池等场景中，轻微的变化往往预示着重大灾害的前兆。因此，同时检测慢速和快速变化的设计网络具有挑战性。本文针对此挑战，提出了一种名为Flow-CDNet的变化检测网络，该网络由两支组成：光流分支和二进制变化检测分支。", "innovation": "本文提出了一种新的变化检测网络Flow-CDNet，该网络由光流分支和二进制变化检测分支组成。光流分支采用金字塔结构提取多尺度的位移变化，二进制变化检测分支则结合ResNet网络与光流分支的输出生成快速变化输出。同时，为了监督和评估这一新的变化检测框架，作者设计了一个自建的变化检测数据集Flow-Change、融合二元Tversky损失和L2范数损失的新损失函数，以及一个新的评估指标FEPE。定量实验表明，本文方法在Flow-Change数据集上优于现有方法，实验证明两个分支可以相互促进，提高检测性能。", "conclusion": "本文通过设计和实现Flow-CDNet网络，有效地解决了同时检测双时相图像中快慢变化的挑战。该方法在多个定量实验中表现优异，并通过消融实验验证了网络各部分的有效性，表明该方法在变化检测领域具有重要应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02349", "html_url": "https://arxiv.org/abs/2507.02349", "title": "两步神经网络用于自动化脑血管关键点检测", "title_en": "Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection", "authors": "Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau", "background": "颅内动脉瘤（ICA）常发生在Willis环（CoW）的特定段落，主要集中在十三条主要动脉的分叉处。准确检测这些关键点对于快速有效的诊断至关重要。本文介绍了一种完全自动化的Willis环分叉点检测方法，该方法采用两步神经网络过程实现。", "innovation": "该方法采用两步神经网络过程，首先使用物体检测网络（object detection network）识别出目标位置附近的感兴趣区域（ROIs），然后再利用带有深度监督的修改版U-Net来准确定位分叉点。这种方法解决了因两个分叉点位置相近且视觉特征相似而导致的遗漏检测问题，特别适用于处理整个MRA时间飞行（TOF）数据。此外，该方法能考虑到Willis环的解剖变异，这会影响每次扫描能检测到的地标数量。", "conclusion": "通过使用两种脑MRA数据集评估我们的方法的有效性：一种是内部数据集，标注点数量各不相同；另一种是标准配置的公共数据集。实验结果显示，我们的方法在分叉点检测任务中的性能最高。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02358", "html_url": "https://arxiv.org/abs/2507.02358", "title": "整体化图像生成自回归模型", "title_en": "Holistic Tokenizer for Autoregressive Image Generation", "authors": "Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi", "background": "现有的自回归图像生成模型按照逐步方式生成视觉令牌，这限制了对令牌序列之间整体关系的捕捉能力。大多数视觉令牌化机制将局部图像片段映射到潜在令牌中，导致全局信息有限。", "innovation": "提出了Hita，一种新颖的自回归图像令牌化方法。Hita引入了自上而下的整体化到局部的令牌化方案，并使用可学习的整体查询和局部片段令牌。此外，Hita采用两种关键策略来提高与自回归生成过程的对齐：1）通过使用原因注意力，Hita在开始时将整体令牌放置在序列结构中，之后是片段级令牌；2）Hita在解码器中采用轻量级融合模块，在输入解码器前控制信息流，优先考虑整体令牌。", "conclusion": "广泛的实验证明，Hita提高了自回归生成器的训练速度，并在ImageNet基准测试中优于使用传统令牌化的生成器，分别达到2.59 FID和281.9 IS。Holistic表示的详细分析显示了其捕获全局图像特性（如纹理、材料和形状）的能力。此外，Hita还展示了在零次采样风格迁移和图像修补方面的有效性。Hita的代码已开源。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02322", "html_url": "https://arxiv.org/abs/2507.02322", "title": "基于神经网络的稻叶病害识别与分类研究：基于特征模型与直接成像模型的比较分析", "title_en": "Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model", "authors": "Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi", "background": "稻叶病害显著降低生产力并导致经济损失，突显了早期检测的必要性，以便进行有效的管理和提高产量。以往方法直接将稻叶图像输入人工神经网络（ANN），但缺乏对基于特征分析检测模型（FADM）和直接成像中心检测模型（DICDM）的有效性进行详尽比较的研究，尤其是在特征提取算法（FEAs）方面的评价。因此，本研究旨在进行初始实验，采用多种图像特征提取算法、降维算法（DRAs）、特征选择算法（FSAs）和极端学习机（ELM）来实现基于特征分析检测模型，包含水稻稻叶细菌性叶斑病、稻纹枯病、稻白叶枯病、稻白叶病、鞘腐病和健康叶等病害的评估，并利用10折交叉验证法进行实验。", "innovation": "本研究采用了多种特征提取算法、降维算法和特征选择算法来建立基于特征分析的检测模型，并引入了直接成像中心检测模型进行比较，进而对这两种模型进行详尽对比实验。通过详尽对比显示，基于特征分析的检测模型在分类性能上更优。", "conclusion": "应用提出的基于特征分析的检测模型以检测水稻稻叶病害具有改进作物健康、减少产量损失和增强水稻生产率和可持续性的巨大潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02373", "html_url": "https://arxiv.org/abs/2507.02373", "title": "UVLM：评估水下世界理解的视频语言模型基准", "title_en": "UVLM: Benchmarking Video Language Model for Underwater World Understanding", "authors": "Xizhe Xue,Yang Zhou,Dawei Yan,Ying Li,Haokui Zhang,Rong Xiao", "background": "近年来，大规模语言模型（LLMs）取得了显著的成果，在人工智能领域产生了深远的影响。基于LLMs的多种先进工作已在多个场景中提出并应用。特别是视频语言模型（VidLMs）在许多情况下得到了广泛应用。然而，目前大多数工作主要集中在陆地场景，而忽视了水下观察的高要求应用需求。为了弥补这一差距，本文介绍了一种基于协作方法构建的UVLM，通过结合人类专业知识和AI模型，旨在评估水下世界的理解能力。", "innovation": "UVLM的创新之处在于它是一个专门为水下观察构建的基准，涵盖了多种挑战性场景，如光的变化、水的浑浊度和多种视角。数据集不仅包括多种帧率、分辨率和超过419种海洋动物种类，还包括多种静态植物和地形。此外，任务设计中有20种不同的任务类型，分为生物和环境两大类，每类进一步分为内容观察和变化/动作观察。为了支持定量比较和分析，设计了多个具有挑战性的评估指标。实验结果显示，将VidLMs微调在UVLM上显著提高了对水下世界的理解能力，并且在现有的空中VidLM基准（如VideoMME和Perception text）上有小幅度的改进。", "conclusion": "通过实验验证，UVLM旨在提供一个高质量的数据集和一组具有挑战性的评估指标，以提高视频语言模型评估中对水下世界理解的能力。未来的工作目标是进一步完善数据集和进一步优化评估方法，以促进水下观测技术的发展。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02354", "html_url": "https://arxiv.org/abs/2507.02354", "title": "基于YOLOv8n的轻量化虾病检测研究", "title_en": "Lightweight Shrimp Disease Detection Research Based on YOLOv8n", "authors": "Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao", "background": "虾病是虾养殖业中导致经济损失的主要原因之一。为了预防疾病传播并提高智能检测效率，本文提出了基于YOLOv8n的轻量化网络架构。该研究建立在虾病数据集的基础上，旨在提升虾养殖中的疾病智能检测能力，减少经济损失", "innovation": "通过设计RLDD检测头和C2f-EMCM模块，减少计算复杂度，保持检测精度，提高计算效率。引入改进的SegNext_Attention自注意力机制，进一步增强特征提取能力，实现对疾病特征的更精准识别。实验结果表明，与YOLOv8n相比，该模型参数减少了32.3%，mAP@0.5提高了3%，在mAP@0.5、参数量和模型大小方面优于其他轻量级YOLO系列模型，验证了模型在URPC2020数据集上的鲁棒性，mAP@0.5提高了4.1%。该方法在准确性和效率之间达到了最优平衡，为虾养殖中的智能疾病检测提供了可靠的技术支持", "conclusion": "研究表明，基于YOLOv8n的轻量化网络在虾病检测中具有较高的准确性和较低的计算成本，能够在实际的虾病识别与防控中提高检测效率，减少经济损失。该方法在实际应用中具有广泛的应用前景"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02393", "html_url": "https://arxiv.org/abs/2507.02393", "title": "PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection", "title_en": "PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection", "authors": "Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho", "background": "单目3D物体检测（M3OD）长期以来面临挑战，主要原因是对高标注成本和固有的2D到3D的歧义性导致的数据稀缺。虽然已经提出了各种弱监督方法和伪标签方法来解决这些问题，但这些方法大多局限于特定领域的学习，或者仅依赖单次观测的形状信息。上述方法大多依赖多视角设置，额外的传感器，摄像机姿态，或者领域特定的训练。本文旨在介绍一种新的伪标签框架，该框架仅需使用视频数据集，不受遮挡影响，并且不需要多视角设置，额外的传感器或特定领域的训练。该方法利用了视频帧内物体点的追踪技术，在无法获取3D数据的情况下，实现了对静态和动态物体的3D属性提取在先验的3D数据收集不起作用的场景下。经过大规模实验证明，该方法可以确保可靠的准确性以及强大的扩展性，是一个实用且有效的M3OD解决方案。", "innovation": "提出了一种仅使用视频数据的伪标签框架，该框架更有效解决问题（如遮挡处理），不需多视角设置，额外的传感器或特殊领域训练。方法利用视频帧内物体点追踪技术，实现静态和动态物体的3D属性提取，在无法获得3D数据的场景中表现出色。这种框架比现有方法更具有通用性和扩展性。更关键的是，由于不依赖外部传感器或多视角拍摄，该方法在场景数据收集较为困难的情境中更为有效。", "conclusion": "该研究提出的PLOT方法能够在遮挡问题上表现出强大的鲁棒性，实现3D物体属性的稳定提取。实验结果表明这种方法具有可靠的准确性，显著的可扩展性，是解决单目3D物体检测问题的有效方法之一。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02314", "html_url": "https://arxiv.org/abs/2507.02314", "title": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation", "title_en": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation", "authors": "JaeHyuck Choi,MinJun Kim,JeHyeong Hong", "background": "在工业质量控制场景中，异常数据稀缺的问题正得到越来越多的关注。理想的数据生成器应该满足三个需求：保持正常的背景不变，修复异常区域以严格符合相应的异常掩码，生成在语义上合理位置的异常区域，同时还能仅从少量真实示例中产生现实且多样的外观。现有的基于扩散的方法通常只能满足这些要求中的两个：全局异常生成器会破坏背景，而基于掩码引导的方法则在掩码不准确或位置错误时会失败。", "innovation": "提出了一种名为MAGIC的方法——带多级扰动和上下文感知对齐的掩码引导修复。MAGIC通过微调Stable Diffusion修复骨干网来保留正常区域并确保合成异常严格符合提供的掩码，直接解决了背景破坏和未对齐的问题。为了抵消微调可能引起的多样性损失，MAGIC增加了两种补充扰动策略：（i）在微调和推理期间应用的高斯提示级扰动，扩展了异常的全局外观，避免了低保真度的文字外观；（ii）基于掩码的空间噪声注入，丰富了局部纹理变化。此外，上下文感知的掩码对齐模块形成了语义对应关系并重新定位掩码，使得每个异常都有可能保留在宿主物体中，消除了边界外的伪影。", "conclusion": "在MT-Vert-AD数据集下的一致评估协议中，MAGIC在下游异常任务中优于之前的最先进方法。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02398", "html_url": "https://arxiv.org/abs/2507.02398", "title": "基于像素级时域频率的超越空域频率的深度伪造视频检测", "title_en": "Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection", "authors": "Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi", "background": "传统的基于空域频率的检测器通常忽略像素级的时间一致性问题，它们仅通过在帧间堆叠空域频率谱来表示时间信息，导致无法检测像素级的时间艺术效果。这种方法在处理时域中的异常运动时容易失败，特别是在检测伪造视频时表现出不足。因此，需要一种能够更全面捕获视频中时域特性的方法，以提高伪造视频检测的性能和鲁棒性。", "innovation": "提出了一种利用像素级时间一致性来检测深度伪造视频的方法。该方法对每个像素进行一维傅立叶变换，提取高度敏感于时间不一致性的特征，特别是在容易出现不自然运动的区域。引入了训练方式端到端的时间注意力提议模块，精确地标记出包含时间艺术效果的区域。此外，联合变换模块有效结合了像素级的时间频率特征和时空上下文特征，扩展了可检测的伪造缺陷范围。这些创新显著提升了伪造视频检测的鲁棒性和性能。", "conclusion": "该框架代表了深度伪造视频检测的重要进步，能够在多样的和具有挑战性的检测场景中提供稳健的性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02395", "html_url": "https://arxiv.org/abs/2507.02395", "title": "连续多重实例学习加强定位在组织病理学全量图像分析中的应用", "title_en": "Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis", "authors": "Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun", "background": "多重实例学习（MIL）通过使用带有弱标签的图像包显著降低了大规模图像的标注成本，例如组织病理学全量图像（WSI）。然而，MIL对具有最小遗忘的连续任务的适应性很少被探讨，特别是在实例分类定位方面。虽然弱增量学习在持续定位上已有研究，但这些研究主要集中在自然图像上，利用预训练模型中的数百个小补丁（例如16×16）的全局关系，但这种方法对于MIL定位来说似乎不可行，因为涉及大量的大补丁（例如256×256）且缺乏如癌细胞这样的全局关系。", "innovation": "本文提出了Continuous Multiple Instance Learning with Enhanced Localization (CoMEL)，这是一种用于定位和适应性且最小遗忘的MIL框架。它包括：（1）分组双注意力变换器（GDAT）以提高实例编码效率；（2）袋原型为基础的伪标签生成（BPPL），用于可靠实例伪标签生成；（3）正交加权低秩适应（OWLoRA），以减轻包和实例分类中的遗忘。在三个公开的WSI数据集上的实验表明，CoMEL在包级别精度和定位精度上均优于现有方法，最高分别提高了11.00%和23.4%。", "conclusion": "本研究提出了一种有效的CoMEL方法，该方法通过结合分组双注意力变换器、袋原型为基础的伪标签生成和正交加权低秩适应来提高MIL定位和适应性的表现。该方法在三个公开的WSI数据集上的实验结果显示了其优越性，出performance以往方法最多分别提高了11.00%和23.4%。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02408", "html_url": "https://arxiv.org/abs/2507.02408", "title": "一种用于复杂运动模式下实时多目标跟踪的热传感器新调谐方法", "title_en": "A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern", "authors": "Duong Nguyen-Ngoc Tran,Long Hoang Pham,Chi Dai Tran,Quoc Pham-Nam Ho,Huy-Hung Nguyen,Jae Wook Jeon", "background": "多对象跟踪在热图像中对于监控系统至关重要，尤其是在光亮度低或者能见度低的环境中，RGB摄像头表现不佳。热传感器通过捕捉红外特征提高了识别任务，但其低级别的特征表示使其难以准确检测和跟踪行人。特别是在处理热图像中的复杂运动模式时遇到困难。本文的背景在于解决这一问题，特别是在困难环境下的多对象跟踪挑战。", "innovation": "本文提出了一种新的调谐方法，专门针对热图像中的复杂运动模式进行多对象实时跟踪。该框架通过对两个阶段进行优化，确保每个阶段使用最适合的超参数，以此提高跟踪性能。通过调谐实时跟踪中的超参数，该方法在不依赖于复杂重识别或运动模型的情况下，实现了高的准确性。", "conclusion": "通过大量实验验证，所提出的方法在PBVS热图像跟踪数据集上取得了良好的效果，证明其在各种热摄像条件下的鲁棒性，成为实际监控应用中的稳健解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02363", "html_url": "https://arxiv.org/abs/2507.02363", "title": "LocalDyGS：通过自适应局部隐式特征解耦实现多视角全局动态场景建模", "title_en": "LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling", "authors": "Jiahao Wu,Rui Peng,Jianbo Jiao,Jiayu Yang,Luyang Tang,Kaiqiang Xiong,Jie Liang,Jinbo Yan,Runling Liu,Ronggang Wang", "background": "在真实世界中，物体的复杂且高度动态的移动使得从多视角输入合成任意视角的动态视频具有挑战性。现有的基于神经辐射场或3D高斯分裂的方法仅能建模精细尺度的运动，极大地限制了其应用范围。现有的方法难以同时处理大尺度和精细尺度的运动场景，因此需要一种能够适应这两种场景的方法来更真实地建模高度动态的现实世界场景。", "innovation": "该论文提出了LocalDyGS，这是一种新的动态场景重建框架，它通过自适应地将复杂动态场景分解为种子定义的流动局部空间，来适应大尺度和精细尺度的运动场景。该方法还通过将静态和动态特征解耦，同时引入时间特定特征的动态残留场来建模局部空间的运动。这种方法能够以更真实的方式建模高度动态的现实世界场景，并且与最先进的方法相比在精细尺度数据集上的性能具有竞争力，同时也是首次尝试建模更复杂和更动态的场景。", "conclusion": "LocalDyGS不仅在各种精细尺度数据集上展示了与最先进的方法相当的性能，而且还是首次尝试建模更大和更复杂的动态场景，提出了一种新的动态场景重建框架，可以更真实地建模高度动态的实际场景。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02405", "html_url": "https://arxiv.org/abs/2507.02405", "title": "PosDiffAE：基于区域感知的扩散自编码器在高分辨率脑组织分类中的应用，结合去噪", "title_en": "PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration", "authors": "Ayantika Das,Moitreya Chaudhuri,Koushik Bhat,Keerthi Ram,Mihail Bota,Mohanasankar Sivaprakasam", "background": "去噪扩散模型通过逐步捕捉图像分布来产生高质量的图像样本，初始使用简单分布并逐步增加分布复杂性。虽然这些模型解锁了新的应用可能性，但它们的采样机制没有提供提取特定图像语义表示的能力，这是自动编码器提供的。自动编码器的编码组件可以将特定图像映射到其潜在空间，因此可以强制潜在空间中的结构。研究中提出了一种结合编码器的扩散模型，这种方法学习特定的图像表示并提供组织潜在空间的手段。", "innovation": "1. 设计了一种机制以结构化扩散自编码模型的潜在空间，以便在脑图像中识别区域特定的细胞模式。\n2. 基于邻域意识提出了无监督的撕裂伪影修复技术，利用潜在表示和扩散模型在推理期间的受限生成能力。\n3. 通过代表性的指导和利用扩散推断时间可调节的噪声和反噪声能力，提出了无监督的JPEG伪影修复技术。", "conclusion": "通过将编码器与扩散模型结合，建立了扩散自编码框架，学习特定图像表示并组织潜在空间，以利于区分不同的大脑组织类型和修复图像伪影，并在高分辨率脑组织分类中取得了良好的应用效果。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02403", "html_url": "https://arxiv.org/abs/2507.02403", "title": "在非城市环境中使用自监督学习进行野生动物目标再识别", "title_en": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings", "authors": "Mufhumudzi Muthivhi,Terence L. van Zyl", "background": "野生动物再识别旨在匹配不同观察中的同物种个体。当前最先进的模型依赖分类标签来训练监督模型进行个体分类。这对标注数据的依赖性导致了大量大型野生动物数据集的建立。本研究探讨了在野生动物再识别中使用自监督学习（SSL）的可能性，通过自动从相机陷阱数据的时序图像对中提取个体的两个不同视图，训练了一种自监督模型，该模型可以从无限的视频数据流中获取潜在的数据。研究分析了实验结果，表明即使在数据有限的情况下，自监督模型也更为稳健，并且自监督特征在所有下游任务中都优于监督特征。研究结果证明了自监督学习在野生动物再识别中的潜力，尤其在非城市环境下的应用价值。", "innovation": "本研究创新性地将自监督学习应用于野生动物再识别领域，通过摄像陷阱数据的时序图像对自动提取个体的多个视图，无需监督数据即可训练自监督模型。研究结果显示，自监督模型在数据有限的情况下表现出更高的鲁棒性，且其特征超越了监督特征，适用于各种野生动物下游任务。", "conclusion": "本研究通过自监督学习方法提升了野生动物再识别的性能，尤其是在有限数据条件下。实验表明，自监督模型具有更好的鲁棒性，其提取的特征在各类野生动物识别任务中表现更优。这项工作为非城市环境下的野生动物跟踪和管理提供了新的技术和方法。研究的代码已公开，供进一步研究和应用使用。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02399", "html_url": "https://arxiv.org/abs/2507.02399", "title": "TABNet: 一种基于三元增强自我恢复框架及边界感知伪标签的医学图像分割方法", "title_en": "TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation", "authors": "Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang", "background": "医学图像分割是临床应用中的核心任务，然而，获取大型、完全注释的医学图像数据集既耗时又昂贵。勾画注释作为一种稀疏标签的形式，为医学图像分割提供了高效且成本低廉的替代方案。然而，勾画注释的稀疏性限制了目标区域的特征学习，并缺乏足够的边界监督，这给训练分割网络带来了巨大挑战。", "innovation": "本文提出了一种新颖的弱监督医学图像分割框架TAB Net，包含两个关键模块：三元增强自我恢复(TAS)模块和边界意识伪标签监督(BAP)模块。TAS模块通过三种互补的增强策略增强了特征学习：强度转换提高了模型对纹理和对比度变化的敏感性，cutout使网络捕捉局部解剖结构，打乱关键区域；拼图增强通过破坏空间连续性加强了对全球解剖布局的建模。BAP模块通过融合两个分支预测生成加权伪标签并引入边界意识损失以提高伪监督精度并细化边界。实验结果表明，TAB Net在ACDC和MSCMR seg两个公开数据集上显著优于现有基于勾画的弱监督分割方法，其性能与全监督方法相当。", "conclusion": "实验评估在ACDC和MSCMR seg两个公开数据集上展示了TAB Net在基于勾画的弱监督分割上的显著优越性，并且达到了与全监督方法相当的性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02416", "html_url": "https://arxiv.org/abs/2507.02416", "title": "使用深度学习框架确定结构裂缝", "title_en": "Determination Of Structural Cracks Using Deep Learning Frameworks", "authors": "Subhasis Dasgupta,Jaydip Sen,Tuhina Halder", "background": "结构裂缝检测对于公共安全至关重要，因为它有助于预防可能危及生命的结构失效。无经验人员的手动检测过程缓慢、不一致且易出错，这可能削弱评估的可靠性。当前研究通过引入用于增强结构裂缝检测准确性和效率的新型深度学习架构来解决这些挑战。研究中使用了不同配置的残差U-Net模型，这些模型由于能够捕获细节，进一步被集成到由卷积块组成的元模型中。这种独特的组合旨在提升预测效率，超越单一模型所能达到的水平。对段子网和传统U-网等现有架构的性能进行了评估。结果显示，残差U-Net模型在低分辨率图像中优于其前身，而集成模型则超过了单个模型的性能，证明其为最有效的方案。评估基于Intersection over Union (IoU)度量和DICE系数。集成模型实现了最高得分，表明其具有更高的准确性。", "innovation": "研究引入了一种新型的深度学习架构，结合残差U-Net模型与卷积块组成的元模型，以提高结构裂缝检测的准确性和效率。这种方法在低分辨率图像检测中表现出色，并优于传统和现有的模型架构。", "conclusion": "集成模型在Intersection over Union (IoU)度量和DICE系数上取得了最高分，证明了其在结构缺陷监测任务中的高度准确性，为自动化系统的发展提供了更可靠的技术支持。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02414", "html_url": "https://arxiv.org/abs/2507.02414", "title": "基于打包的隐私保护面部识别预筛选方法", "title_en": "Privacy-preserving Preselection for Face Identification Based on Packing", "authors": "Rundong Xin,Taotao Wang,Jin Wang,Chonghe Zhao,Jing Wang", "background": "随着隐私担忧的增加以及面部数据恢复的可能性，面部识别系统能够在密文域中操作已引起广泛关注。然而，随着密文模板库的增大，面部检索过程变得越来越耗时。为了解决这个问题，我们提出了一种新颖且高效的在密文域中进行面部检索的方案，称为PFIP（Privacy-Preserving Preselection for Face Identification Based on Packing）。该方案结合了一种创新的预筛选机制以减少计算开销，并且包含了一个打包模块以在注册阶段增强生物识别系统的灵活性。在LFW和CASIA数据集上的实验表明，PFIP在检索1000个密文面部模板时，实现了100%的命中率并能在300毫秒内完成。与现有方法相比，PFIP的检索效率提高了近50倍。", "innovation": "PFIP方案提出了新颖的预筛选机制和打包模块。预筛选机制旨在减少计算开销，而打包模块则在注册阶段增强生物识别系统的灵活性。研究表明，PFIP在保持原有面部识别模型准确率的同时，检索效率有了显著提升。", "conclusion": "实验结果表明，PFIP能够在实现高度准确的面部识别的同时，大大提升检索效率，能够在300毫秒内从1000个密文面部模板中实现100%的命中精度。同时，这种方法相比现有技术提高了约50倍的检索效率。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02437", "html_url": "https://arxiv.org/abs/2507.02437", "title": "F^2TTA: 基于图像层面解纠缠提示调优的跨域医学影像分类中的自由形式测试时自适应", "title_en": "F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning", "authors": "Wei Li,Jingyang Zhang,Lihao Liu,Guoan Wang,Junjun He,Yang Chen,Lixu Gu", "background": "Test-Time Adaptation (TTA) 作为一种在未标注测试数据下通过调整源模型来适应不同医疗环境中自由形式的数据片段的方法，因其高数据标注成本而逐渐展现出潜力。现有的 TTA 方法关注于完整域单位的数据到达情况。然而，在实际临床环境中，由于资源限制和患者变异，数据往往以任意长度的片段形式随机到达，导致了自适应过程中的不可预测的域变化，使得现有 TTA 方法难以应对。", "innovation": "本文提出了一种新颖的 Image-level Disentangled Prompt Tuning (I-DiPT) 框架，旨在应对自由形式域片段间的不可预测变化。该框架通过使用图像不变的提示探索不变的领域表示来减轻这种不可预测的变化，并通过图像特有的提示来适应当前到达的数据片段。此外，作者还引入了 Uncertainty-oriented Masking (UoM) 方法和 Parallel Graph Distillation (PGD) 方法，前者通过不确定性的引导来激励提示提取必要的信息，后者通过并行图网络重用历史的具体和不变的提示知识，来应对单张图像训练时知识表示不足的问题。", "conclusion": "在乳腺癌和青光眼分类实验中，本文提出的方法在自由形式的 TTA (F^2TTA) 中表现出优于现有 TTA 方法的优势。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02443", "html_url": "https://arxiv.org/abs/2507.02443", "title": "在FPGA的可编程逻辑中加速葡萄检测的人工神经网络", "title_en": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic", "authors": "Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias", "background": "机器人在进行拣选作业时，通常会降低速度以检测物体，同时为了追踪检测算法的运行速度，其相机的帧率较低。这在执行任务和探索时会受到限制，导致执行时间增加。AMD开发了Vitis-AI框架来将检测算法部署到FPGAs中，但并未充分利用FPGAs的PL.", "innovation": "本文利用FINN架构将三种人工神经网络（MobileNet v1、CNV（2-bit量化）、CNV（1-bit量化即BNN））部署到FPGA的PL中，数据集为RG2C，这是一种自获取并开放访问的数据集。MobileNet v1的表现最佳，达成98%的成功率以及6611 FPS的推理速度。通过此工作证明，可以使用FPGAs加速人工神经网络并使其适用于注意力机制.", "conclusion": "在FPGA的可编程逻辑中加速人工神经网络，并证明了其在葡萄检测任务中的实际应用潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02419", "html_url": "https://arxiv.org/abs/2507.02419", "title": "AvatarMakeup: 3D动画头部 avatar 的逼真化妆转移", "title_en": "AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars", "authors": "Yiming Zhong,Xiaolin Zhang,Ligang Liu,Yao Zhao,Yunchao Wei", "background": "现实生活中，为了提升视觉吸引力，人们往往会对面部进行个性化定制美化。对于3D虚拟角色（俗称avatar），也需要进行类似的个性化定制，但这一领域研究相对不足。目前的三维高斯编辑方法可以在一定程度上实现面部化妆，但这类方法难以满足实现真实感化妆效果的三项基本要求：1) 在表情变换过程中保持一致的外观；2) 化妆过程保留身份特征；3) 对细节进行精确控制。", "innovation": "我们提出了一种专门的三维化妆方法——AvatarMakeup，利用预训练的扩散模型，将任何个体的一张参考照片中的化妆图案转移到目标avatar上。方法采用了由粗及细的思想，先确保一致的外观和身份，再细化细节。扩散模型被用来生成指导化妆的图像。由于扩散模型存在不确定性，生成的图像在不同视角和表情下会不一致。因此，我们提出了一种一致性复制方法（Coherent Duplication），该方法通过重新编码生成化妆图像中的平均面部属性，在粗略应用化妆时保证动态和多视角效果的一致性。通过查询全局UV图，它可以任意视角和表情下合成一致的化妆指导，优化目标avatar。此外，通过引入细化模块，进一步提升化妆效果，实现高质量的化妆转移。实验结果表明，AvatarMakeup方法在化妆转移质量和一致性方面均达到了最先进的水平。", "conclusion": "AvatarMakeup方法充分利用了预训练扩散模型的优势，结合由粗到细的思想和一致性复制方法，成功解决了现有方法难以在动态效果和多视角下保持化妆效果真实性和一致性的难题。实验结果证明，该方法在化妆效果的转移质量和一致性上均达到了业界领先水平。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02477", "html_url": "https://arxiv.org/abs/2507.02477", "title": "Mesh Silksong：类似缫丝的自回归网格生成", "title_en": "Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk", "authors": "Gaochao Song,Zibo Zhao,Haohan Weng,Jingbo Zeng,Rongfei Jia,Shenghua Gao", "background": "现有的网格token化方法会产生重复的顶点token，浪费了网络能力。因此，我们需要一种新的方法来减少token序列的冗余，提高性能。Mesh Silksong旨在通过仅访问每个网格顶点一次，减少token序列的冗余50%左右，并达到了约22%的最佳压缩率。同时，这种方法生成的多边形网格具有优良的几何特性，包括 manifold 瓴合拓扑、防水检测以及一致的面法线，这些对于实际应用至关重要。", "innovation": "Mesh Silksong通过仅访问每个网格顶点一次，减少tokens序列的冗余50%，实现了约22%的最优压缩率。同时，这种方法生成的网格在几何特性方面具有优异的表现，包括manifold拓扑、防水检测和一致的面法线，这些都是实际应用中必需的特性。", "conclusion": "实验结果证明了该方法的有效性，不仅展示了复杂的网格生成，还显著提高了几何完整性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02493", "html_url": "https://arxiv.org/abs/2507.02493", "title": "在结肠镜检查中具有时间意识的监督对比学习的息肉计数", "title_en": "Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy", "authors": "Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi", "background": "自动结肠息肉计数是实现自动结肠镜检查报告和质量控制的关键步骤，意在提高结肠镜筛查的成本效益。现有的息肉计数方法依赖于自我监督学习，并主要利用视觉特征，忽视了在检测和跟踪息肉的过程中时序关系的重要性，尤其是在时序特征学习和聚类阶段。", "innovation": "本文提出了一个监督对比损失的新范式，引入了具有时序意识的软目标。该方法捕捉了息肉内的变异，同时保留了息肉间的区分性，从而增强了聚类的稳健性。此外，通过引入时间邻接约束改善了轨迹聚类，减少了视觉上相似但在时序上相距较远的轨迹之间的误关联。", "conclusion": "在公开数据集上训练和验证了该方法，并通过交叉验证策略评估了其性能。结果显示，该方法的裂片率比先前的方法降低了2.2倍。结果表明了时序意识在息肉计数中的重要性，建立了新的最佳水平。代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02454", "html_url": "https://arxiv.org/abs/2507.02454", "title": "弱约束对比学习配以数量提示用于移动红外小目标检测", "title_en": "Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection", "authors": "Weiwei Duan,Luping Ji,Shengjia Chen,Sicheng Zhu,Jianghong Huang,Mao Ye", "background": "传统的物体检测方法通常面临巨大的挑战，特别是对于移动中的红外小目标检测，因为目标尺寸小且背景信号弱。当前大多数方法需要大量的手动标注，这非常昂贵且费时，尤其是对于低质量的红外帧图像。弱约束的监督策略被看作是减少标注需求的一种潜在方法，但相关研究尚少。已有研究多采用全面监督的方式，过度依赖于大量的人工目标级别的注释。这种方法在低质量红外帧图像上成本高、耗时久，而传统的全面监督框架在此场景下显得力不从心。此论文旨在探索一种新的弱监督对比学习方案，尝试打破这种完全监督框架的限制，首次在这一领域进行了探索。", "innovation": "该论文提出了一个新的弱监督对比学习方案（WeCoL），主要创新点在于该方案只需要简单的目标数量提示，便能在不需要大量人工标注的情况下提升模型性能。其通过结合预训练的目标挖掘策略和多帧能量的方法来提高掩模伪标签的可靠性，并进一步引入一种长短期运动感知学习方案来同时建模小目标的局部运动模式和全局运动轨迹。实验结果表明，该弱监督方案可以显著超越早期的完全监督方法，性能甚至能够达到或接近最新全面监督方法的90%。这也是第一次在该领域采用这种策略的研究工作。", "conclusion": "通过大量实验验证，该论文提出的弱监督对比学习方法（WeCoL）在两个公开数据集（DAUB和ITSDT-15K）上均取得了优异的表现，并且与最新的全面监督方法相比，其性能表现接近甚至超越了90%，证明了这种方法在移动红外小目标检测中的有效性和可行性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02445", "html_url": "https://arxiv.org/abs/2507.02445", "title": "IGDNet：基于照明引导和去噪的零样本鲁棒弱光图像增强", "title_en": "IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising", "authors": "Hailong Yan,Junjian Huang,Tingwen Huang", "background": "当前用于恢复弱光图像的方法通常依赖于带有弱光和良好光照图像配对的监督学习。然而，在实际场景中收集这样的数据集通常不切实际，而且这些方法可能会导致过度增强，使良好光照区域失真。为了解决这些问题，我们提出了一种仅依赖单个测试图像的零样本增强方法IGDNet，无需引导先验或训练数据。IGDNet在泛化能力和去噪方面表现出色，能够有效修复光照不均匀区域同时恢复照明。IGDNet框架包括一个分解模块和一个去噪模块。前者通过密集连接网络将图像分解为照明和反射成分，后者使用照明引导像素自适应校正方法增强非均匀光照区域。噪声对通过下采样生成并迭代细化以获得最终结果。在四个公开数据集上的大量实验表明，IGDNet在复杂光照条件下显著提高了视觉质量。PSNR和SSIM指标上的定量结果显示，它的性能优于14种最先进的无监督方法。相关代码不久将发布。", "innovation": "提出了一种基于照明引导和去噪的零样本增强方法IGDNet，这种方法仅依赖单个测试图像，无需引导先验或训练数据，能够有效地修复光照不均匀区域同时恢复照明，且在复杂光照条件下的视觉质量显著提高，优于14种最先进的无监督方法。", "conclusion": "IGDNet在复杂光照条件下的视觉质量显著提高，PSNR和SSIM指标上的定量结果优于14种最先进的无监督方法。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02488", "html_url": "https://arxiv.org/abs/2507.02488", "title": "MedFormer: 基于内容感知双稀疏选择注意的分层医疗视觉变压器", "title_en": "MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention", "authors": "Zunhui Xia,Hongxing Li,Libin Lan", "background": "医疗影像识别在临床诊断中扮演着关键角色，可帮助更准确和及时地识别疾病和异常。基于视觉转换器的方法已被证明在处理各种医疗识别任务中非常有效。然而，这些方法面临两个主要挑战：它们往往是特定于任务和特定于架构的，限制了其通用性；它们通常会采用全注意机制捕捉长程依赖性，导致高计算成本，或者依赖手工设计的稀疏注意，可能导致性能不佳。", "innovation": "本文提出了MedFormer，一种高效的医疗视觉转换器，主要创新点包括：1. 使用分层缩放结构作为各种医疗影像识别任务的通用骨干，包括图像分类和密集预测任务如语义分割和病变检测，这种结构有助于层次特征表示并减少特征图的计算量，有助于提升性能。2. 引入了一种新的内容感知双稀疏选择注意(Dual Sparse Selection Attention, DSSA)，以提高计算效率并增强对噪声的鲁棒性，同时保持高性能。", "conclusion": "MedFormer在各种成像模态数据集上的广泛实验表明，在上述三种医疗影像识别任务中，MedFormer在所有三个任务中的性能都有显著提升。详细的理论分析表明，与现有的医疗视觉转换器相比，MedFormer具有优越的通用性和效率。相关代码已发布。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02479", "html_url": "https://arxiv.org/abs/2507.02479", "title": "CrowdTrack：真实场景中多目标跟踪的基准数据集", "title_en": "CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios", "authors": "Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue", "background": "多目标跟踪是计算机视觉中的经典领域。特别是行人跟踪具有极高的应用价值，成为最热门的研究方向。现有的方法主要依赖于运动或外观信息进行跟踪，在复杂场景中常常效果不佳。对于运动信息，目标之间的相互遮挡会阻止运动状态的更新；对于外观信息，由于部分可见或模糊等原因，所得到的结果往往不鲁棒。虽然从标注数据中学习如何在这些情况下进行跟踪是最简单的解决方案，但现有的多目标跟踪（MOT）数据集无法满足这一需求。现有方法存在两个主要缺点：场景组成相对简单和非现实场景。尽管现有数据集中的一些视频序列不存在上述缺点，但数量远不足以满足研究需求。因此，本文提出了一种大规模的困难数据集，主要从第一人称视角拍摄，全部来自现实生活中的复杂场景。我们将其命名为\"CrowdTrack\"，因为在大多数序列中都有大量的对象。我们的数据集包括33个视频，包含共计5,185条轨迹。每个对象都用完整的边界框和唯一的对象ID进行了标注。数据集将为开发能在复杂情况下保持有效性的算法提供平台。我们全面分析了数据集，并在我们的数据集上测试了多种当前最先进的模型。此外，我们还分析了基础模型在我们数据集上的性能。数据集及项目代码已发布至此 https://...  ", "innovation": "该研究提出了一种新的大规模困难数据集CrowdTrack，用于多行人跟踪，主要从第一人称视角拍摄，涵盖现实生活中的复杂场景，解决了现有MOT数据集场景组成简单非现实的问题。该数据集包含复杂的多目标行为序列，并已应用于当前最先进的算法测试，提供了一个能促进多行人跟踪算法发展的平台。", "conclusion": "我们全面分析了CrowdTrack数据集，并测试了多个SOTA模型，证明了该数据集对于多行人跟踪研究的重要性。CrowdTrack将为多行人跟踪算法提供一个现实且困难的场景，有助于推进该领域的先进研究。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02494", "html_url": "https://arxiv.org/abs/2507.02494", "title": "MC-INR: 使用元学习和聚类隐 Neural 表示高效编码多元科学模拟数据", "title_en": "MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations", "authors": "Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong", "background": "隐神经表示（INRs）广泛用于将数据编码为连续函数，能够以减少内存使用的方式可视化大规模的多元科学模拟数据。然而，现有的基于 INR 的方法面临三个主要限制：(1) 复杂结构的表示不够灵活，(2) 主要专注于单变量数据，(3) 依赖于结构化网格。因此，当应用于复杂的实际数据集时，它们的性能会下降。为了克服这些限制，我们提出了一个新颖的基于神经网络的框架 MC-INR，用于在无结构网格上处理多元数据。它结合了元学习和聚类，使对复杂结构的灵活编码成为可能。为了进一步提高性能，我们引入了一种基于残差的动态重新聚类机制，该机制根据局部误差自适应地分割集群。我们还提出了一种分枝层，以同时通过独立的分支利用多元数据", "innovation": "提出了一种新颖的框架 MC-INR，结合了元学习和聚类，用于无结构网格上的多元数据处理。该框架通过结合元学习和聚类来灵活地编码复杂结构，并提出了一种基于残差的动态重新聚类机制和分枝层，提高了处理复杂实际数据集的能力。实验结果表明，MC-INR 在科学数据编码任务上的表现优于现有方法。", "conclusion": "MC-INR在科学数据编码任务上表现优异，克服了现有技术的三个主要限制，使得复杂结构的表示更加灵活，处理多元数据的能力更强。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02513", "html_url": "https://arxiv.org/abs/2507.02513", "title": "自动低光条件行人检测的自动标注", "title_en": "Automatic Labelling for Low-Light Pedestrian Detection", "authors": "Dimitrios Bouzoulas,Eerik Alamikkotervo,Risto Ojala", "background": "RGB图像是自动驾驶车辆和高级驾驶辅助系统中最常用的传感器。低光条件下的人行横道检测是RGB行人检测的一个挑战，似乎缺乏大量公共数据集。因此，该研究提出了一个自动红外-RGB标注管道，以解决低光条件下的行人检测问题。该管道包括三个阶段：红外检测、标签转移过程以及使用生成的标签训练目标检测模型。这项研究使用了KAIST数据集进行验证，结果显示使用生成标签训练的模型在6次测试中有更好的表现，在mAP@50和mAP@50-95指标上超过了使用真实标签训练的模型。", "innovation": "该研究提出了一种自动红外-RGB标注管道，用于解决低光条件下的行人检测问题，该管道包括红外检测、标签转移过程和使用生成的标签训练目标检测模型。", "conclusion": "使用生成标签训练的模型在6次测试中有更好的表现，在mAP@50和mAP@50-95指标上超过了使用真实标签训练的模型。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02519", "html_url": "https://arxiv.org/abs/2507.02519", "title": "IMASHRIMP: 使用计算机视觉和深度学习从实验室图像自动分析白色对虾（Penaeus vannamei）的生物测量学特征", "title_en": "IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning", "authors": "Abiam Remache González,Meriem Chagour,Timon Bijan Rüth,Raúl Trapiella Cañedo,Marina Martínez Soler,Álvaro Lorenzo Felipe,Hyun-Suk Shin,María-Jesús Zamorano Serrano,Ricardo Torres,Juan-Antonio Castillo Parra,Eduardo Reyes Abad,Miguel-Ángel Ferrer Ballester,Juan-Manuel Afonso López,Francisco-Mario Hernández Tejera,Adrian Penate-Sanchez", "background": "现有的深度学习和计算机视觉技术在处理虾体形态分析时遇到了特定的挑战，尤其是基于RGBD图像的形态分析。为了优化对虾遗传选种任务，本文提出了一个名为IMASHRIMP的适应性系统，专门用于自动化白色对虾（Penaeus vannamei）的形态学分析。", "innovation": "1. IMASHRIMP系统引入了两个分类模块，基于修改后的ResNet-50架构，用于图像分类及确定触角完整性。\n2. 实现了“双因素身份验证（人类与AI）”系统，显著减少了分类视图和触角检测中的错误。\n3. 适应了VitPose中的姿态估计模块，能够针对侧视图和背视图预测23个关键点。\n4. 结合了使用支持向量机（SVM）模型的形态回归模块，将像素测量转换为厘米单位，提高了精度。\n5. 通过实验验证，该系统减小了人工错误，姿态估计的平均精度达到了97.94%，像素到厘米单位的转换误差为0.07（±0.1）cm。", "conclusion": "IMASHRIMP系统展示了自动化和加速虾体形态分析的潜力，提高了遗传选种的效率，并有助于推动更可持续的水产养殖。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02546", "html_url": "https://arxiv.org/abs/2507.02546", "title": "MoGe-2：具有度量尺度和锐利细节的一维几何", "title_en": "MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details", "authors": "Ruicheng Wang,Sicheng Xu,Yue Dong,Yu Deng,Jianfeng Xiang,Zelong Lv,Guangzhong Sun,Xin Tong,Jiaolong Yang", "background": "本文提出了一种先进的开放域几何估计模型MoGe-2，可以从单张图像中恢复场景的度量比例3D点图。该方法基于最近的单目几何估计方法MoGe，它预测具有未知比例的仿射不变点图。探讨了有效策略以扩展MoGe以进行度量几何预测，同时不牺牲仿射不变点表示所提供的相对几何准确性。此外，研究发现现实数据中的噪声和误差会削弱预测几何中的细粒度细节。为此，开发了一种统一的数据精炼方法，利用清晰的合成标签过滤和补充来自不同来源的实际数据，显著提高了重建几何的细微程度，同时保持了整体准确性。模型在大规模混合数据集上进行了训练并进行了全面评估，展示了出色的表现，实现了准确的相对几何、精确的度量尺度以及细粒度细节恢复——这是以往方法无法同时实现的能力。", "innovation": "提出了一种新的几何估计模型MoGe-2，能够从单张图像中恢复场景的度量比例3D点图。创新之处在于扩展了MoGe方法，以进行度量几何预测，同时保持相对几何的准确性。此外，通过使用尖锐的合成标签精炼和补充实际数据，显著提高了重建几何的细微程度，增强了整体性能。", "conclusion": "MoGe-2模型在全面评估中展示了出色的性能，实现了同时准确的相对几何、精确的度量尺度和细粒度细节恢复的能力，这是以往方法无法同时实现的。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02565", "html_url": "https://arxiv.org/abs/2507.02565", "title": "使用外观和人际距离推理重建近距离人类互动", "title_en": "Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning", "authors": "Buzhen Huang,Chen Li,Chongyang Xu,Dongyue Lu,Jinnan Chen,Yangang Wang,Gim Hee Lee", "background": "在野生视频中，由于视觉不清晰和个人遮挡，现有的人体姿态估计方法无法恢复合理的近距离互动。即使是最先进的大型基础模型（如SAM）也不能在这些具有挑战性的场景中准确区分人类语义。", "innovation": "本文发现人体外观可以提供一个直接的线索来解决这些障碍。基于这一观察，我们提出了一种双分支优化框架，该框架通过人体外观、社交近距和物理定律的约束来重构准确的互动动作。我们首先训练一个扩散模型学习人体的人际行为和姿态先验知识。训练后的网络和两个可优化的张量被整合到双分支优化框架中，以重建人体动作和外观。设计了基于3D高斯、2D关键点和网格穿透的多种约束来辅助优化。凭借人际距离先验和多种形式的约束，我们的方法能够从复杂环境中捕捉到的野生视频中估计出准确的互动。", "conclusion": "我们在几个基准上的实验结果显示，我们的方法优于现有的方法。我们构建了一个具有伪地面真相互动注释的数据集，这可能促进对姿态估计和人类行为理解的未来研究。我们的代码和数据可在以下网址获取。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02517", "html_url": "https://arxiv.org/abs/2507.02517", "title": "使用深度学习检测多种作物的多种病害", "title_en": "Detecting Multiple Diseases in Multiple Crops Using Deep Learning", "authors": "Vivek Yadav,Anugrah Jain", "background": "印度作为一个以农业为主的经济体，面临着农作物损失严重、病害、虫害和环境压力等农业挑战。早期检测和准确识别不同作物的病害对于提高产量和确保粮食安全至关重要。论文提出了一种基于深度学习的方法，旨在检测多种农作物中的多种病害，覆盖印度多样的农业环境。研究首先创建了一个包含17种不同作物和34种不同病害的综合数据集，该模型在该数据集上的训练表现优于现有的最新技术。实验结果显示，在处理病害种类和作物数量上，该模型的检测准确率达到了99%，比仅处理14种作物和26种不同病害的最新技术高出7%。通过提高可检测的作物种类和病害种类，所提解决方案旨在为印度农民提供更好的产品支持。", "innovation": "该研究创新点在于首次提出并实现了一个综合数据集，能够同时覆盖多种作物和多种病害，这对于印度这样农业多样化的国家尤为重要。模型在这一综合数据集上的表现优于现有技术，并且显著提高了检测准确度，具有广泛的实际应用潜力。", "conclusion": "通过提高可检测的作物种类和病害种类，所提出的基于深度学习的解决方案旨在为印度农民提供更好的产品支持，以改善农作物产量，提升粮食安全水平。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02576", "html_url": "https://arxiv.org/abs/2507.02576", "title": "借助可微体素化从分割学习血管的参数形状模型", "title_en": "Parametric shape models for vessels learned from segmentations via differentiable voxelization", "authors": "Alina F. Dima,Suprosanna Shit,Huaqi Qiu,Robbie Holland,Tamara T. Mueller,Fabio Antonio Musio,Kaiyuan Yang,Bjoern Menze,Rickmer Braren,Marcus Makowski,Daniel Rueckert", "background": "血管是人体中复杂的结构，已在多种表示形式中进行了广泛的研究。虽然体素化是最常见的表示形式，但网格和参数模型在各种应用中也因其具有吸引力的属性而至关重要。然而，这些表示通常通过分割提取，并且彼此分离地使用。", "innovation": "提出了一种框架，通过可微变换将三种表示形式联合起来。通过利用可微体素化，我们可以自动从分割中提取出血管的参数形状模型，无需显式获取真实形状参数。该方法利用三次B样条曲线对血管进行中心线和半径参数化，确保平滑性和连续性。从学习到的形状参数中可以差分地提取网格，从而获得高保真网格，用户可以在匹配后对其进行操作。此方法在不同的血管（主动脉、动脉瘤和脑血管）实验中能准确捕捉复杂血管的几何形状，证明了其在实验中的有效性。", "conclusion": "该方法通过结合体素化、网格和参数模型，使得血管建模更加准确和灵活，未来可以应用于医疗诊断、虚拟现实等领域。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02581", "html_url": "https://arxiv.org/abs/2507.02581", "title": "结构感知语义差异和一致性在3D医学图像自监督学习中的应用", "title_en": "Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning", "authors": "Tan Pan,Zhaorui Tan,Kaiyu Guo,Dongli Xu,Weidi Xu,Chen Jiang,Xin Guo,Yuan Qi,Yuan Cheng", "background": "3D医学图像的自监督学习（mSSL）在医学分析中具有巨大潜力。实现更广泛的应用需要考虑到解剖结构的变异，包括位置、缩放和形态学。然而，先前的mSSL方法往往使用固定大小的patches分割图像，忽略了结构变异的重要性。因此，以往的研究未能有效地捕捉有意义的区别。在本文中，作者引入了一种新的视角，旨在学习结构感知的特征表示。他们的方法通过两步实现结构感知的语义差异和一致性（S2DC），有效地处理了这些挑战，改进了3D医学图像的自监督学习能力。", "innovation": "本文提出了一个新的mSSL框架 $S^2DC$，通过结构感知的语义差异和一致性学习，解决了以往方法忽视解剖结构变异的问题。首先，$S^2DC$ 使用最优传输策略增加语义差异；其次，$S^2DC$ 基于邻域相似性分布提高结构层次上的语义一致性。这种新颖的方法在结构感知特征表示方面取得了进展，在10个数据集，4个任务和3种模态上的广泛评估中，该方法始终优于最先进的mSSL方法。", "conclusion": "S2DC 框架在10个数据集、4个任务和3种模态的全面评估中，均优于现有的mSSL方法，有效提高了3D医学图像的语义学习能力，充分发挥了自监督学习在医学分析中的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02591", "html_url": "https://arxiv.org/abs/2507.02591", "title": "AuroraLong: 恢复RNNs在高效开放视频理解中的作用", "title_en": "AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding", "authors": "Weili Xu,Enxin Song,Wenhao Chai,Xuexiang Wen,Tian Ye,Gaoang Wang", "background": "长视频理解的挑战在于其高度的计算复杂性和对内存的巨大需求，因为基于变压器的大型语言模型（LLMs）的内存和计算需求随输入序列长度成二次增长。因此，现有的模型难以处理长视频的挑战。论文提出了AuroraLong模型，通过用线性RNN语言模型替代MLLMs中的LLM组件，来解决这一问题，并采用可变长度的输入序列和恒定大小的隐藏状态。此外，它通过重新排序按大小排列视觉标记来进一步提高吞吐量和效率。", "innovation": "AuroraLong通过使用线性RNN语言模型，解决了基于变压器模型的局限性，能处理任意长度的输入序列，同时保持隐藏状态的恒定大小。该模型参数量为2亿，仅使用公开数据训练，但在多个视频基准测试中，其性能与类似大小但基于私有数据集训练的变压器模型相当。这表明高效线性RNN模型有望通过降低计算门槛来民主化长视频理解。这是首个在类似LLaVA的开放视频理解模型中使用基于线性RNN的LLM主干的研究。", "conclusion": "AuroraLong通过线性RNN模型显著降低了长视频理解的计算门槛，展示了高效线性RNN模型在长视频理解中的潜力，为开放视频理解提供了新的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02687", "html_url": "https://arxiv.org/abs/2507.02687", "title": "APT：差分模型中有限数据个性化训练的自适应策略", "title_en": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data", "authors": "JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang", "background": "在使用有限数据个性化差分模型时，遇到了诸如过拟合、先验知识丢失以及文本对齐下降等显著挑战。过拟合导致噪声预测分布的偏离，破坏了去噪路径，从而使模型失去语义一致性。现有的方法不能有效解决这些问题，尤其在生成高质量、多样化的图像时表现不佳，特别是在仅有有限参考数据的情况下。", "innovation": "本文提出了一种新的框架—自适应个性化训练（APT），通过自适应训练策略和在微调过程中正则化模型内部表示来缓解过拟合。APT包括三个关键技术组件：自适应训练调整，通过引入过拟合指示器在每个时间步进行过拟合检测，并基于此指示器应用自适应数据增强和自适应损失权重；表示稳定化，正则化中间特征图的均值和方差，防止噪声预测的过度偏移；注意力对齐以保持先验知识，通过对齐经过微调的模型和预训练模型的交叉注意图来保持先验知识和语义一致性。通过广泛的实验，证明APT可以有效缓解过拟合、保留先验知识，并在有限参考数据生成高质量、多样化图像方面优于现有方法", "conclusion": "本文通过提出自适应个性化训练（APT）框架，有效缓解了使用有限数据个性化差分模型时遇到的过拟合、先验知识丢失以及文本对齐下降等挑战。APT能够生成高质量、多样化的图像，并在有限参考数据的情况下表现出色，优于现有的其他方法。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02705", "html_url": "https://arxiv.org/abs/2507.02705", "title": "SIU3R: 超越特征对齐的同步场景理解与3D重建", "title_en": "SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment", "authors": "Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu", "background": "同步理解和3D重建在开发端到端的体感智能系统中起着重要作用。现有的方法依赖于从2D到3D特征的对齐方案，这会导致有限的3D理解能力和潜在的语义信息丢失。", "innovation": "我们提出了SIU3R，这是第一个无需特征对齐即可进行通用同步理解和3D重建的框架，该框架通过像素对齐的3D表示将重建任务和理解任务联系起来，并将多种理解任务统一到一系列可学习查询中，从而在没有2D模型的对齐需求的情况下实现本征的3D理解。此外，我们进一步分析了两者共享表示下的相互好处，并提出了两个轻量级模块来促进它们的交互，以促进两者之间的协作。", "conclusion": "我们的实验表明，我们的方法在3D重建和理解的单独任务以及同步理解和3D重建的任务上都取得了最先进的性能，突显了我们的无对齐框架的优势以及相互好处设计的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02686", "html_url": "https://arxiv.org/abs/2507.02686", "title": "通过展开和蒸馏学习几步后验采样器", "title_en": "Learning few-step posterior samplers by unfolding and distillation of diffusion models", "authors": "Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra", "background": "扩散模型（DMs）已成为贝叶斯计算成像中的强大先验。目前已经提出了两种策略来利用DMs：Plug-and-Play方法，这种方法无需训练且非常灵活，但依赖于近似；以及专门的条件DMs，通过监督训练实现更高的准确性和更快的推理速度，但灵活性较差。本文研究的就是在贝叶斯计算成像中利用DMs的方法，介绍了将DMs图像先验转化为几步条件模型以进行后验采样的新框架。", "innovation": "本文提出了一种新颖的方法，通过深层展开和模型蒸馏将DMs图像先验转化为几步条件模型，首次将深层展开应用于蒙特卡洛采样方案。具体地，该方法将最近提出的LATINO Langevin采样器中的马科夫链蒙特卡洛算法进行深层展开。并通过大量实验与现有技术进行了对比，表明该方法在保持灵活性的同时，具有出色的准确性和计算效率。", "conclusion": "本文提出的方法实现了极高的准确性和计算效率，同时保持了对前向模型变化的适应性。通过将扩散模型转化为几步条件模型，该研究为贝叶斯计算成像提供了新的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02714", "html_url": "https://arxiv.org/abs/2507.02714", "title": "FairHuman: 在最小潜在延迟公平性准则下的扩散模型中提升人体图像生成中的手和面部质量", "title_en": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models", "authors": "Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma", "background": "随着大规模文本转图像模型的发展，特别是基于扩散的模型，图像生成已经取得了显著的进步。然而，生成具有可信细节的人体图像（如面部或手部）仍然具有挑战性，因为训练期间局部区域的监督不足。", "innovation": "提出了一个名为FairHuman的多目标微调方法，旨在公平地提升全局和局部生成质量。具体而言，该方法通过构建全局目标（来自默认扩散目标函数）、针对手部和面部的两个局部目标（基于预标注的位置先验）以及基于最小潜在延迟（MPD）准则的最优参数更新策略来解决这一问题。", "conclusion": "该研究提出的方法在生成具有挑战性的局部细节方面取得了显著改善的同时，还保持了整体质量。广泛的实验展示了在不同场景下，该方法在提升人体图像生成性能方面的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02602", "html_url": "https://arxiv.org/abs/2507.02602", "title": "Vision-Based导航中摄像头传感器故障的解决：仿真与数据集开发", "title_en": "Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development", "authors": "Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill", "background": "视觉导航（VBN）算法在航天任务中的重要性日益增加，这带来了确保其可靠性和操作稳健性的众多挑战。传感器故障可能导致导航算法输出不准确或数据处理故障，从而可能影响任务目标。人工智能（AI）提供了一种强大的解决方案，可以检测此类故障，克服传统故障检测方法的许多限制。然而，阻碍AI在该领域应用的主要障碍是缺乏包含故障图像数据的充分且具有代表性的数据集。本文通过重点关注行星际探索任务场景来解决这些挑战，全面分析了VBN流水线中使用的相机传感器可能出现的故障情况及其原因和影响，并提出了常见的缓解策略。为此，介绍了一种仿真框架，用于在合成生成的图像中重现故障条件，以便系统化且可控地再现故障数据。由此产生的故障注入图像数据集为训练和测试基于AI的故障检测算法提供了有价值的工具。私人链接将在审稿人审阅后提供。", "innovation": "本文提出了一个仿真框架，用于在合成生成的图像中重现故障条件，这使得能够系统化且可控地再现故障数据。由此产生的故障注入图像数据集为训练和测试基于AI的故障检测算法提供了有价值的工具，并解决了一个关键的障碍：缺乏包含故障图像数据的充分且具有代表性的数据集。", "conclusion": "本文通过仿真框架和故障数据集的开发，解决了视觉导航中摄像头传感器故障检测的问题，并提供了有价值的培训和测试工具，为后续AI故障检测研究奠定基础。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02713", "html_url": "https://arxiv.org/abs/2507.02713", "title": "UniMC: 管理扩散变换器以实现统一的关键点引导多类别图像生成", "title_en": "UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation", "authors": "Qin Guo,Ailing Zeng,Dongxu Yue,Ceyuan Yang,Yang Cao,Hanzhong Guo,Fei Shen,Wei Liu,Xihui Liu,Dan Xu", "background": "尽管在基于关键点引导的文本到图像扩散模型方面取得了重大进展，但现有的主流关键点引导模型在控制生成更具一般性的非刚性对象（例如动物）时遇到困难。此外，仅基于关键点控制难以生成多个重叠的人和动物。这些挑战主要来自现有可控制方法的固有问题和缺乏合适的数据集。文献中的现有方法依赖于骨架图像作为条件，难以区分实例和类别。这些限制导致了在处理多个对象和重叠情况下的生成难题。因此，研究需要一个能够统一处理多类图像生成且支持关键点控制的框架，同时提供适合关键点引导的人和动物图像生成的数据集。", "innovation": "本文设计了一个基于DiT的框架，命名为UniMC，以探索多类形象的统一可控生成。UniMC将实例级和关键点级条件整合为紧凑的令牌，包括类别、边界框和关键点坐标等属性，从而克服了以前依赖骨架图像作为条件而导致难以区分实例和类别的方法限制。此外，提出了HAIG-2.9M数据集，这是一个大规模、高质量且多样化的关键点引导人和动物图像生成数据集，包括786K张图像和2.9M个实例，提供广泛的标注，如关键点、边界框和细粒度的图像描述，以确保标注准确性。", "conclusion": "广泛实验表明，HAIG-2.9M数据集的质量非常高，UniMC框架在处理多个实例和多类别场景时尤其有效，特别是在重叠和遮挡较为严重的情况下。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02691", "html_url": "https://arxiv.org/abs/2507.02691", "title": "CanonSwap: 通过 canonical 空间调制实现高质量和一致的视频面部互换", "title_en": "CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation", "authors": "Xiangyang Luo,Ye Zhu,Yunfei Liu,Lijian Lin,Cong Wan,Zijian Cai,Shao-Lun Huang,Yu Li", "background": "视频面部互换旨在解决两个主要挑战：有效地将源身份转移到目标视频中，并准确地保留目标人脸的动力学属性，如头部姿态、面部表情和唇部同步等。现有方法主要集中在实现高质量的身份转移，但往往在保持目标人脸的动力学属性方面表现出不足，导致结果不一致。该问题主要归因于视频中面部外观和运动的内在耦合。为了应对这一挑战，我们提出了一种新颖的视频面部互换框架CanonSwap，该框架将运动信息与外观信息解耦。CanonSwap 首先消除与运动相关的信息，使身份修改可以在统一的 canonical 空间中进行，随后将互换特征重新整合回原始视频空间中，以确保目标人脸的动力学属性得以保留。为了进一步实现精确的身份交换且无明显艺术缺陷，我们设计了一个部分身份调制模块，该模块通过空间掩码自适应地整合源身份特征，仅对脸部区域进行修改。此外，我们引入了一些细粒度的同步度量标准，以全面评估视频面部互换方法的性能。大量实验表明，我们的方法在视觉质量、时间一致性和身份保留等方面显著优于现有方法。我们的项目页面可在此公开访问：this https URL.", "innovation": "我们提出了一种名为CanonSwap的新颖视频面部互换框架，该框架通过canonical空间调制解耦了运动信息与外观信息。首先，CanonSwap通过消除与运动相关的信息，使能在统一的canonical空间中进行身份修改；其次，将互换特征重新整合回原始视频空间中，确保目标人脸的动力学属性得以保留。此外，我们还设计了一个部分身份调制模块，通过空间掩码自适应地整合源身份特征，限制修改仅限于脸部区域。我们还引入了细粒度的同步度量标准，以全面评估视频面部互换方法的性能。", "conclusion": "我们进行的大量实验表明，我们的方法在视觉质量、时间一致性和身份保留等方面显著优于现有的方法。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02664", "html_url": "https://arxiv.org/abs/2507.02664", "title": "AIGI-Holmes: 通过多模态大型语言模型迈向可解释和通用性强的AI生成图像检测", "title_en": "AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models", "authors": "Ziyin Zhou,Yunpeng Luo,Yuanchen Wu,Ke Sun,Jiayi Ji,Ke Yan,Shouhong Ding,Xiaoshuai Sun,Yunsheng Wu,Rongrong Ji", "background": "AI生成内容（AIGC）技术的快速发展导致了高度真实的AI生成图像（AIGI）被用来传播虚假信息，威胁到公众信息安全。尽管现有的AIGI检测技术通常有效，但仍存在两个问题：1）缺乏可由人类验证的解释；2）无法很好地适应最新的技术发展。为了应对这些问题，本文介绍了一个大规模且全面的数据集Holmes-Set，其中包括Holmes-SFTSet（带有图像是否为AI生成解释的指令调优数据集）和Holmes-DPOSet（与人类偏好对齐的人类模拟偏好数据集）。此外，本文提出了一种有效的数据标注方法——多专家陪审团（Multiple-Expert Jury），提升数据生成并通过结构化的MLLM解释进行质量控制，并引入了Holmes Pipeline（三阶段训练框架），为AIGI检测和生成人类可验证的、与人类偏好对齐的解释提供支持。这些方法与技术的有效性在三个基准上的广泛实验已经得到了验证。", "innovation": "1. 介绍了一个大规模且全面的数据集Holmes-Set，包括带有图像是否为AI生成解释的指令调优数据集和与人类偏好对齐的人类模拟偏好数据集。（Holmes-SFTSet和Holmes-DPOSet）\n2. 提出了一种高效的多专家陪审团数据标注方法，通过结构化的MLLM解释和跨模型评估进行质量控制，增强数据生成。\n3. 设计了一个精心构建的三阶段训练框架——Holmes Pipeline，适用于AIGI检测，同时生成人类可验证和与人类偏好对齐的解释。\n4. 引入了一种协作解码策略，在推理阶段将视觉专家的模型感知与MLLM的语义推理相结合，增强了泛化能力。", "conclusion": "通过多模态大型语言模型，Holmes Pipeline提出了AIGI-Holmes模型，对于AIGI检测提供了可解释性和通用性。该方法在三个基准上的广泛实验验证了其有效性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02781", "html_url": "https://arxiv.org/abs/2507.02781", "title": "从像素到损坏程度：使用社会媒体图像语义分割估计地震影响", "title_en": "From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images", "authors": "Danrong Zhang,Huili Huang,N. Simrill Smith,Nimisha Roy,J. David Frost", "background": "在地震发生后，社交媒体图片已成为灾害侦察的关键资源，能够提供即时的损伤范围洞察。传统的方法往往依赖于分类方法来评估地震后社交媒体图片的损坏程度，这些方法具有主观性且无法匹配图片中不同区域的损伤程度。", "innovation": "本文提出了一种新的方法，将损坏程度评估问题转化为语义分割问题，并构建了一个分段损坏程度数据集，将损坏分为三个级别：未损坏的结构、受损的结构和废墟。使用该数据集，研究中对SegFormer模型进行了微调，以对地震后的社交媒体图片生成损坏程度分割。此外，还提出了一种新的损坏程度评分系统，通过考虑图片中不同区域的损坏程度进行量化，并调整深度估算。这使得对社交媒体图片中的损坏程度进行更客观和全面的量化成为可能，从而为灾害侦察团队提供更精确的指导，有助于在地震后的更有效的响应行动。", "conclusion": "通过提供对损坏程度的精细化理解，本研究增强了为灾害侦察团队提供精确指导的能力，促进了更有效的和针对性的救援行动。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02743", "html_url": "https://arxiv.org/abs/2507.02743", "title": "使用边界框约束的提示学习方法在医学图像分割中的应用", "title_en": "Prompt learning with bounding box constraints for medical image segmentation", "authors": "Mélanie Gaillochet,Mehrdad Noori,Sahar Dastani,Christian Desrosiers,Hervé Lombaert", "background": "在医学领域，像素级注释工作量大且成本高昂。基于边界框注释的弱监督技术由于更容易获取，提供了实用替代方案。尽管视觉基础模型在提供提示（如点或边界框）时显示出显著的分割性能，但现有的提示学习方法仍依赖于完全标注的分割掩码。该研究旨在结合基础模型的强大表示能力和弱监督分割的注释效率，提出了一种新的框架，该框架使用边界框注释自动生成提示，无需完全标注的掩码，并将来自边界框注释的多个约束与基础模型提示生成的伪标签整合到优化方案中。经过多个跨模态数据集的实验，证明了其在有限数据集上的优越性，平均Dice分数为84.90%，超越了现有的完全监督和弱监督方法。", "innovation": "提出了一种结合了基础模型强表示能力和弱监督分割注释效率的新框架。该方法仅使用边界框注释自动生成提示，并将边界框注释的多个约束与伪标签整合到优化方案中。", "conclusion": "该弱监督分割方法在有限数据设置中取得了平均Dice分数84.90%的优异结果，超越了现有完全监督和弱监督方法。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02747", "html_url": "https://arxiv.org/abs/2507.02747", "title": "DexVLG：大规模的灵巧视觉-语言-抓取模型", "title_en": "DexVLG: Dexterous Vision-Language-Grasp Model at Scale", "authors": "Jiawei He,Danshi Li,Xinqiang Yu,Zekun Qi,Wenyao Zhang,Jiayi Chen,Zhaoxiang Zhang,Zhizheng Zhang,Li Yi,He Wang", "background": "随着大型模型的应用普及，基于视觉-语言-动作（VLA）的系统正在使机器人能够应对越来越复杂的任务。然而，由于数据收集的难度，研究主要集中在控制简单的夹爪末端执行器上。对于人类样手的灵巧抓取，现有研究较少。", "innovation": "本文介绍了一款名为DexVLG的大规模视觉-语言-抓取模型，该模型能够根据语言指令预测单视图RGBD输入下桌面上物体的灵巧抓取姿态。为此，研究者构建了一个包含17000万灵巧抓取姿态的数据集，这些姿态被映射到174000个仿真物体的语义部分上，并配以详细的语义部分描述。使用该大规模数据集训练了一种视觉语言模型（VLM）和基于流匹配的姿态预测头，能够生成与指令对齐的抓取姿态。通过基于物理仿真的基准测试和实际实验评估了DexVLG的表现，结果显示，该模型在仿真中的零样本泛化能力强，抓取准确率达76%，并且在实际物理物体中的部分对齐抓取表现良好，具备强泛化能力。", "conclusion": "实验结果表明，DexVLG在仿真中的零样本执行成功率超过76%，在仿真中的部分抓取准确率达到了同类最佳水平，在实际物理对象中的部分对齐抓取也取得了成功。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02790", "html_url": "https://arxiv.org/abs/2507.02790", "title": "从长视频到精彩片段：具备多模态叙事理解的人类启发式视频编辑框架", "title_en": "From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding", "authors": "Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu", "background": "在线视频内容，尤其是短视频平台的内容快速增长，激发了对高效视频编辑技术的需求，这些技术能将长视频浓缩成简洁且吸引人的片段。现有的自动编辑方法主要依赖自动语音识别（ASR）转录中的文本线索进行端到端的片段选择，往往忽略了丰富的视觉上下文，导致输出不连贯。", "innovation": "本文提出了一种适用于视频编辑的人类启发式多模态叙事理解框架（HIVE）。该框架通过多模态大型语言模型提取人物、对话分析和叙事总结，为视频内容提供全面的理解。此外，该框架采用场景层级分割，并将编辑过程分解为三个子任务：亮点识别、开头/结尾选择和无关内容的剪裁，从而增强连贯性。同时，还推出了一个名为DramaAD的新基准数据集，包含超过800个短剧集和500个专业编辑的广告剪辑，以促进研究发展。", "conclusion": "实验表明，该框架在一般性和针对性编辑任务中都能持续超越现有基线，显著减少了自动编辑视频和人类编辑视频之间的质量差距。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02751", "html_url": "https://arxiv.org/abs/2507.02751", "title": "基于部分弱监督的定向目标检测", "title_en": "Partial Weakly-Supervised Oriented Object Detection", "authors": "Mingxin Liu,Peiyuan Zhang,Yuan Liu,Wei Zhang,Yue Zhou,Ning Liao,Ziyang Gong,Junwei Luo,Zhirui Wang,Yi Yu,Xue Yang", "background": "定向对象检测（OOD）的需求日益增长，这推动了该领域的大量研究。然而，数据集标注的成本极高。目前主流的OOD算法主要分为三类：完全监督的方法（使用完整的定向边界框标注）、半监督的方法（使用部分定向边界框标注）和弱监督的方法（使用水平边界框或单个点等弱标注）。但这些方法都不可避免地增加了模型在标注速度或成本上的开销。为了解决这个问题，文章提出了一种基于部分弱标注（水平边界框或单个点）的新颖部分弱监督定向对象检测（PWOOD）框架，该框架能够高效利用大量未标注数据，性能显著优于使用部分弱标注训练的传统弱监督算法，同时提供成本较低的方案。文章还提出了一种感知定向和尺度的学生（OS-Student）模型，仅需少量定向无关或尺度无关的弱标注即可学习定向和尺度信息，以及一种无类别先验伪标签筛选策略（CPF）来降低模型对静态筛选阈值的敏感性。所有这些工作的结果均在DOTA-v1.0/v1.5/v2.0和DIOR数据集上进行了全面实验，表明PWOOD框架的性能与传统半监督算法相当或更优。", "innovation": "1. 首次提出的基于部分弱标注的PWOOD框架，能够高效利用大量未标注数据，显著优于使用部分弱标注训练的传统弱监督算法，同时提供成本较低的方案。\n2. 提出了一种OS-Student模型，能够仅使用少量定向无关或尺度无关弱标注学习定向和尺度信息。\n3. 提出CPF策略，有效地减少了模型对静态筛选阈值的敏感性", "conclusion": "在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的实验证明，研究提出的PWOOD框架在性能上与传统的半监督算法相媲美，甚至超越后者。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02748", "html_url": "https://arxiv.org/abs/2507.02748", "title": "距离依赖的多尺度上下文线性注意机制：适用于视觉和物理问题的Multipole Attention神经算子", "title_en": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics", "authors": "Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen", "background": "Transformer模型因其出色的性能已在各类任务中广泛应用，包括图像分类和物理模拟等。然而，标准Transformer在时间和空间复杂性上都呈二次增长，这对处理高分辨率输入极为不切实际。为此，研究人员提出了多种变体，尽管这些变体在实现性能上有所改进，但大多以牺牲细节质量为代价，如通过分块、下采样或粗化技术实现。本研究通过借鉴$N$体数值模拟技术，将注意力机制视为网格点之间的交互问题来寻求新的途径。", "innovation": "提出了Multipole Attention Neural Operator (MANO)，这是一种基于距离依赖的多尺度方法来计算注意，每个注意头均保持全局感受野，从而实现与网格点数量线性的时间和空间复杂性。实验结果表明，MANO在图像分类和Darcy流动任务上与当前最先进的模型如Vision Transformer (ViT) 和Swin Transformer相当或更优，同时大幅提升了运行时间和峰值内存使用效率。", "conclusion": "实验证明MANO能在线性时间和空间复杂度下实现与当前最优模型相当的性能，并且大幅提升了运行效率。我们开源了代码以确保结果的可再现性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02798", "html_url": "https://arxiv.org/abs/2507.02798", "title": "无需训练！基于参考的无训练实例分割", "title_en": "No time to train! Training-Free Reference-Based Instance Segmentation", "authors": "Miguel Espinosa,Chenhongyi Yang,Linus Ericsson,Steven McDonagh,Elliot J. Crowley", "background": "图像分割模型的历史性能受到大规模标注数据成本高的限制。Segment Anything Model (SAM) 通过可提示的、语义无关的分割范式缓解了这一问题，但仍需手动视觉提示或复杂的领域依赖性提示生成规则来处理新的图像。鉴于此，本文探讨了仅提供少量参考图像时对象分割的任务。研究表明，利用基础模型学习的强语义先验来识别参考图像与目标图像之间的对应关系，可以实现自动实例级分割掩码的生成，为下游任务提供便利。", "innovation": "本文提出了一种无需训练的基于参考的实例分割方法，该方法通过多阶段、无需训练的过程实现。其主要创新点包括构建记忆库、聚合表示和语义感知特征匹配。这种方法能够自动生成实例级分割掩码，并在多个数据集上取得了显著的改进，在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）等方面的性能显著优于现有方法。", "conclusion": "本文提出的无训练基于参考的实例分割方法在多个数据集上取得了显著的改进和最佳性能，尤其是在COCO FSOD和PASCAL VOC Few-Shot方面，超过了现有的无训练方法的表现，说明了利用强语义先验识别参考与目标图像之间的对应关系的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02792", "html_url": "https://arxiv.org/abs/2507.02792", "title": "RichControl：文本到图像生成中的结构丰富和外观丰富的训练免费空问控制", "title_en": "RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation", "authors": "Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang", "background": "文本到图像(T2I)扩散模型已在生成高质量图像方面取得了显著成功。近期研究将这些模型扩展到与条件图像(如深度图或姿态图)结合，以实现精细的空间控制。其中，特征注入方法作为一种无需微调的替代传统微调方法的途径被引入。然而，这些方法在结构对齐、条件泄漏和视觉伪影方面仍存在缺陷，尤其是在条件图像与自然RGB分布差异较大时。", "innovation": "本文通过重新审视现有方法，识别出现有特征注入方法核心缺陷：同步注入特征未能在去噪过程中平衡域对齐与结构保持的权衡。因此，我们提出了一个灵活的特征注入框架，该框架将特征注入时间与去噪过程解耦。核心是引入一个富含结构的特征注入模块，使模型能够在扩散过程中的结构对齐与结构保持的演变过程中更好地适应，从而更真实地生成结构。此外，我们还引入了外观丰富的提示和重新启动细化策略，以进一步提高外观控制和视觉质量。这些设计使得训练无监督生成同时具备结构丰富和外观丰富的能力。", "conclusion": "广泛的实验表明，我们的方法在各种零样本条件下均达到了最先进的性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02803", "html_url": "https://arxiv.org/abs/2507.02803", "title": "HyperGaussians: 高维高斯渲染高保真可动画人脸avatar", "title_en": "HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars", "authors": "Gent Serifi,Marcel C. Bühler", "background": "创建具有高细节的面部avatar从视频中是一个具有挑战性的问题，广泛应用于增强现实和虚拟现实。虽然在静态面部上的成功已经取得巨大成就，但仅通过单目视频构建可动画的avatar仍然无法突破‘恐怖谷’。目前的标准方法3D高斯分布（3DGS）以3D高斯原型集合来表示面部，它在渲染静态面部方面表现出色，但最先进的技术在非线性变形、复杂光照效果和细节点上仍然力有未逮。", "innovation": "本文提出了HyperGaussians，这是一种3D高斯分布的新颖扩展，用于实现高质量可动画的人脸avatar。通过增加维度，结合可学习的局部嵌入来提高表达性。提出了‘逆协方差技巧’来重参数化协方差矩阵，提高了效率，使得HyperGaussians能够无缝整合到现有的模型中。将HyperGaussians应用于最先进的单目面部avatar生成模型FlashAvatar。实验结果显示，HyperGaussians在数值和视觉上都优于3DGS，特别是在高频细节如眼镜框架、牙齿、复杂的面部动作和反射方面表现更好。", "conclusion": "HyperGaussians通过引入高维多变量高斯分布，为3D高斯分布的表示增添了可学习的局部嵌入，提高了表达性。通过‘逆协方差技巧’提升了效率，使其能够无缝应用于实时单目面部avatar生成。实验验证了HyperGaussians在面部avatar建模中的优越性，特别是在复杂面部细节的渲染上。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02826", "html_url": "https://arxiv.org/abs/2507.02826", "title": "基于置信驱动梯度调制的多模态人类活动识别：动态对比双路径学习方法", "title_en": "Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach", "authors": "Panpan Ji,Junni Song,Hang Xiao,Hanyu Liu,Chao Li", "background": "基于传感器的人类活动识别（HAR）是使智能系统能够感知和与其环境互动的核心技术。然而，多模态HAR系统仍然面临着跨模态特征对齐困难和模态贡献不平衡的关键挑战。", "innovation": "提出了一种名为动态对比双路径网络（DCDP-HAR）的新颖框架。该框架通过引入双路径特征提取架构，多阶段对比学习机制，以及置信驱动的梯度调制策略和基于动量的梯度累积策略，解决多模态HAR的问题。", "conclusion": "通过消融研究验证了每个组件的有效性，并在四个公开基准数据集上进行了广泛比较实验，证明了该方法的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02813", "html_url": "https://arxiv.org/abs/2507.02813", "title": "LangScene-X: 使用TriMap视频扩散重建通用的3D语言嵌入场景", "title_en": "LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion", "authors": "Fangfu Liu,Hao Li,Jiawei Chi,Hanyang Wang,Minghui Yang,Fudong Wang,Yueqi Duan", "background": "从2D图像恢复3D结构并进行开放词汇场景理解是一个基本但艰巨的任务。最新的方法通过嵌入语言信息的场景特定优化实现了这一点，但这些方法严重依赖于校准的密集视角重建方法，当可用视角有限时，它们会产生严重的渲染伪影和不合理的语义合成问题。", "innovation": "本文提出了一种名为LangScene-X的生成框架，该框架能够统一生成用于重建和理解的3D一致的多模态信息。通过利用生成能力，LangScene-X能够从稀疏视角中生成一致的新颖观测，从而构建通用的3D语言嵌入场景。具体而言，LangScene-X首先通过逐步知识整合生成稀疏输入的外观（RGBs）、几何形状（法线）和语义（分割图）。此外，LangScene-X还提出了一种大规模图像数据集训练的Language Quantized Compressor (LQC)，能够高效编码语言嵌入，实现跨场景泛化而无需针对每个场景重新训练。最后，通过将语言信息对齐到3D场景的表面上，LangScene-X实现开放性的语言查询。实验表明，LangScene-X在质量和泛化性方面优于最先进的方法。", "conclusion": "我们的LangScene-X方法在实际数据上展示了在质量和泛化性方面优于现有技术的优越性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02827", "html_url": "https://arxiv.org/abs/2507.02827", "title": "USAD: 一个无监督数据增强时空注意力扩散网络", "title_en": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network", "authors": "Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li", "background": "人类活动识别（HAR）的主要目标是从传感器数据中推断出正在进行的人类行动。这项任务在健康监测、安全保护和运动分析等方面有着广泛的应用。尽管进行了大量研究，但HAR仍面临着标注样本稀缺性、高级特征提取不足以及在轻量级设备上的模型性能不足等核心挑战。", "innovation": "本文提出了一种以多注意力交互机制为中心的综合优化方法。首先使用无监督的、基于统计的扩散模型进行了数据增强，解决了标注样本稀缺性和严重类别不平衡的问题。其次设计了一个多分支时空交互网络，通过具有不同卷积核大小（3*3、5*5、7*7）的并行残差分支捕捉序列数据的多尺度特征。同时融合了时间注意力机制以识别关键时间点，并通过空间注意力增强了传感器间的交互。引入了一个交叉分支特征融合单元以提高整体特征表示能力。最后，结合了一个自适应多损失函数融合策略，允许动态调整损失权重并优化整个模型。在三个公开数据集WISDM、PAMAP2和OPPORTUNITY上，该方法的USAD（无监督数据增强时空注意力扩散网络）分别实现了98.84%、93.81%和80.92%的准确性，显著优于现有方法。在嵌入式设备上的实际部署也验证了该方法的高效性和可行性。", "conclusion": "本文提出的USAD方法在三个公共数据集上取得了显著的准确率，并且在嵌入式设备上的实际部署中也证明了方法的高效性和可行性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02857", "html_url": "https://arxiv.org/abs/2507.02857", "title": "AnyI2V: 使用运动控制动画任意条件图像", "title_en": "AnyI2V: Animating Any Conditional Image with Motion Control", "authors": "Ziye Li,Hao Luo,Xincheng Shuai,Henghui Ding", "background": "视频生成的最新进展，尤其是扩散模型，在文本到视频(T2V)和图像到视频(I2V)合成方面取得了显著进步。然而，有效结合动态运动信号和灵活的空间约束仍然是挑战。现有的T2V方法依赖于文本提示，这在生成内容的空间布局方面缺乏精准控制。相比之下，I2V方法受限于对真实图像的依赖，限制了生成内容的可编辑性。尽管一些方法引入了ControlNet进行基于图像的条件控制，但它们通常缺乏明确的运动控制，且需要计算成本高昂的训练。", "innovation": "本文提出了一种无需训练的方案AnyI2V，它可以使用用户定义的运动轨迹为任何条件图像进行动画处理。AnyI2V支持更广泛的模态作为条件图像，包括ControlNet不支持的数据类型，如网格和点云，从而实现更灵活和多功能的视频生成。此外，它还支持混合条件输入，并通过LoRA和文本提示实现风格转换和编辑。实验结果表明，提出的AnyI2V在空间和运动控制方面表现出优越性能，并提供了一种新的视角。", "conclusion": "提出的AnyI2V在空间和运动控制视频生成方面取得了显著进展，提供了新的视角，并且支持包括网格和点云在内的更广泛的模态作为条件图像，实现了更灵活和多功能的视频生成。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02844", "html_url": "https://arxiv.org/abs/2507.02844", "title": "视觉情境攻击：使用图像驱动情境注入劫持MLLMs", "title_en": "Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection", "authors": "Ziqi Miao,Yi Ding,Lijun Li,Jing Shao", "background": "由于视觉语言能力的增强，多模态大型语言模型（MLLMs）在实际应用中展现出巨大潜力。然而，在开放环境下部署这些模型时，视觉模态的安全漏洞带来了重大挑战。最近的研究通过直接将有害文本语义编码到视觉输入中，引发了目标MLLMs的有害反应，但这些方法往往依靠视觉模态作为触发不安全行为的手段，缺乏现实场景中的语义清晰性和真实感。因此，本文定义了一个新的场景——视觉中心型劫持，其中视觉信息成为构建完整且现实情境的必要组成部分。在此基础上，作者提出了一种名为VisCo（Visual Contextual）的攻击方法，通过四种视觉导向策略生成情境对话，并在必要时动态生成辅助图像，以构建视觉中心型劫持场景。为了提高攻击效果，VisCo引入了自动毒性遮蔽和语义精炼，生产出最终的攻击提示，能够有效触发目标黑盒MLLMs的有害反应。VisCo在MM-SafetyBench上的毒性评分为4.78，攻击成功率（ASR）达到85%，远超基线方法的毒性评分为2.48，ASR为22.2%。", "innovation": "本文提出了一种名为VisCo的视觉情境攻击方法，通过动态生成辅助图像和引入自动毒性遮蔽与语义精炼，提高了对目标MLLMs的攻击效果，特别是在视觉中心型劫持场景中表现出色。VisCo攻击方法在MM-SafetyBench上的表现远超现有基线方法，特别是在毒性评分和攻击成功率方面取得了显著优势。", "conclusion": "通过定义视觉中心型劫持这一新的攻击场景，并提出VisCo攻击方法，本文展示了在现实情景中的情境对话和辅助图像对MLLMs的有效攻击能力，为未来的模型安全性研究提供了新思路。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02859", "html_url": "https://arxiv.org/abs/2507.02859", "title": "在多模态LLM中 bootstrap 地构建 Grounded Chain-of-Thought 以实现高效的数据适应模型", "title_en": "Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation", "authors": "Jiaer Xia,Bingkui Tong,Yuhang Zang,Rui Shao,Kaiyang Zhou", "background": "多模态大型语言模型（MLLMs）在通过自然语言解释图像方面显示出显著能力，但没有通过大规模数据集重新训练，它们难以适应特定的视觉任务，例如图表理解。这主要是由于预训练数据集和下游数据集之间存在不匹配：预训练数据集侧重于场景和对象，而对于特定且非对象的图像（如图表和表格）的信息非常有限。因此，这些问题使得MLLMs难以在数据有限的情况下适应特定的视觉任务。\n", "innovation": "本文发现，在训练MLLMs时使用具有Chain-of-Thought（CoT）推理数据可以促进模型在特定视觉任务中的适应，尤其在数据有限的情况下。但研究者识别到了CoT数据中一个关键问题：这些数据中的推理步骤中往往包含多个事实错误。鉴于此，我们提出了Grounded Chain-of-Thought（GCoT），这是一个基于bootstrapping的简单方法，旨在将接地信息（即边界框）注入CoT数据中，使得推理步骤更好地反映输入图像。该方法在涵盖图表、表格、收据和报告等多种视觉格式的五个特定视觉任务上进行了评估，结果表明该方法在数据稀缺的情况下显著提高了模型的适应能力。\n", "conclusion": "我们的方法在数据有限的情况下显著优于直接微调和蒸馏，提升了多模态大型语言模型在特定视觉任务上的适应能力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02862", "html_url": "https://arxiv.org/abs/2507.02862", "title": "RefTok: 基于参考的视频生成分词方法", "title_en": "RefTok: Reference-Based Tokenization for Video Generation", "authors": "Xiang Fan,Xiaohang Sun,Kushan Thakkar,Zhu Liu,Vimal Bhat,Ranjay Krishna,Xiang Hao", "background": "有效地处理时间冗余仍然是学习视频模型的关键挑战。现有方法通常独立处理每一帧集合，未能有效捕捉视频中固有的时间依赖性和冗余性。", "innovation": "我们引入了RefTok，这是一种新颖的基于参考的分词方法，能够捕捉复杂的时序动态和上下文信息。RefTok在解码时能够保持运动的连续性和对象外观的一致性，例如在头部运动时保留面部细节，在背景信息下正确重建文本，并保持小图案和手写文字的可读性。在四个视频数据集（K600、UCF-101、BAIR Robot Pushing以及DAVIS）上，RefTok显著优于当前最先进的分词方法（Cosmos和MAGVIT），并提高了所有评估指标（PSNR、SSIM、LPIPS）36.7%的平均值，在相同的或更高的压缩比率下。在BAIR Robot Pushing任务中，使用RefTok的潜在表示训练的视频生成模型，在所有生成指标上优于MAGVIT-B，并在参数量为MAGVIT-L四倍的MAGVIT-L上表现出27.9%的平均优势", "conclusion": "RefTok通过利用未量化的参考帧的条件编码和解码，显著提高了视频生成质量和效率，同时保持了视频元素的连续性和一致性，展示了其在视频数据集和视频生成模型中的显著优势。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02129", "html_url": "https://arxiv.org/abs/2507.02129", "title": "生成潜在扩散以实现高效的时空数据缩减", "title_en": "Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction", "authors": "Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka", "background": "生成模型在条件设置中表现出色，并且可以被视为一种数据压缩的形式，其中条件充当紧凑的表示。然而，生成模型的有限可控性和重建精度限制了它们在数据压缩中的实际应用。现有的数据压缩方法通常需要存储每一个帧的潜在表示，这增加了存储成本。本文分析了现有的生成模型在数据压缩方面的局限性以及当前数据压缩方法的问题。", "innovation": "本文提出了一种高效的潜在扩散框架，该框架通过结合变分自编码器和条件扩散模型来解决上述问题。方法仅对少量关键帧进行潜在空间压缩，并使用它们作为条件输入，通过生成插值重构其余帧，从而不需要为每个帧存储潜在表示。这一方法可以在保持准确时空重构的同时显著减少存储成本。实验结果表明，该方法在多个数据集中的压缩率可以达到现有的基于规则的先进压缩器（如SZ3）的10倍，并且在相同的重建误差下，相对于领先的基于学习的方法，性能提高了63%。", "conclusion": "本文提出的方法能够实现有效的时空数据缩减，在保持准确时空重构的同时大幅降低了存储成本。实验结果证明了其在不同数据集上的优越性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "能量变换器是可扩展的学习者和思考者", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "目前，推理时的计算技术，类似于人类的System 2思考，在提高模型性能方面变得日益流行。然而，现有的大多数方法存在一些局限性，如这些方法通常是特定模态的（例如仅限于文本）、特定问题的（例如仅适用于数学和编程验证领域），或者需要额外的监督或训练（例如验证器或可验证奖励），基于无监督预训练。", "innovation": "本研究引入了一种名为Energy-Based Transformers (EBTs)的新模型，这种模型通过学习显式验证输入与候选预测之间的兼容性，并将其预测问题重新定义为这种验证器的优化问题，从而实现了在未经额外监督的情况下学习思考。EBTs在训练过程中比主导的Transformer++模型扩展速度更快，特别是在数据量、批量大小、参数、FLOPs和深度方面。在推理时，EBTs提高了29%的性能，特别是在语言任务上，同时在图像去噪任务上使用更少的前向传播次数，优于Diffusion Transformers。此外，给定相当的或更差的预训练性能，EBTs在大多数下游任务上获得了更好的结果，表明EBTs比现有方法更具泛化能力。因此，EBTs为模型的学习和思考能力扩展提供了一个新的有前途的范式。", "conclusion": "EBTs是模型学习和思考能力扩展的一个有前途的新范式。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02863", "html_url": "https://arxiv.org/abs/2507.02863", "title": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "title_en": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "authors": "Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu", "background": "从有序或无序的图像集合中进行稠密三维场景重建是将计算机视觉研究引入实际场景的关键步骤。先前的方法利用DUSt3R的范式将图像对合并到共享坐标系统中，并保持隐式的记忆来实现更多图像的稠密三维重建。然而，这种隐式的记忆容量有限，可能会导致早期帧的信息丢失。因此，该研究提出了Point3R，一种针对稠密流式三维重建的在线框架。Point3R通过维护一个直接与当前场景3D结构相关的显式空间指针记忆来解决这些问题，进而实现了当前观察结果的稠密集成到全局坐标系统中。", "innovation": "Point3R 通过维护一个直接与当前场景3D结构相关的显式空间指针记忆来实现三维场景的流式重建。每个指针在全局坐标系统中聚集附近的场景信息，并与当前帧的抽取信息进行直接交互。此外，研究设计了3D层次位置嵌入以促进这种交互，并设计了一个简单而有效的融合机制以确保指针记忆的一致性和效率。", "conclusion": "该方法在各种任务上达到了竞争力或最先进的性能，且训练成本较低。源代码可以在指定链接中获得。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02860", "html_url": "https://arxiv.org/abs/2507.02860", "title": "Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching", "title_en": "Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching", "authors": "Xin Zhou,Dingkang Liang,Kaijin Chen,Tianrui Feng,Xiwu Chen,Hongkai Lin,Yikang Ding,Feiyang Tan,Hengshuang Zhao,Xiang Bai", "background": "视频生成模型已经在许多场景中展示了其优异的性能，但由于推断速度慢和高计算成本，其广泛应用仍受到限制，主要原因是去噪过程中需要迭代计算。解决这一瓶颈对于使先进的视频合成技术更易于普及，并能够在实际应用中被采用是必要的。本文研究了视频扩散模型的加速问题，并介绍了EasyCache，一种无需训练的加速框架。EasyCache引入了一种轻量级的、运行时自适应缓存机制，通过动态重用之前计算的变换向量来避免推断过程中重复计算。该方法对多个大规模视频生成模型进行了全面研究，获得了显著的加速性能，相较于原基线方法，最多减少2.1-3.3倍的推断时间，同时保持高质量，并在PSNR指标上相较于前一种最佳方法提升了36%。该改进使得EasyCache成为高质视频生成研究与实际应用中高效且易于获取的解决方案，代码已公开可以在该链接下载：[该链接]。", "innovation": "EasyCache是一种无需训练的加速框架，通过运行时自适应的缓存机制动态重用先前计算的变换向量，避免推断过程中的冗余计算。无需进行离线推理、预计算或参数调优。该方法在多个大规模视频生成模型上进行了全面测试，实现了显著的加速性能，推断时间最多减少2.1-3.3倍，并显著提升PSNR至36%。这表明EasyCache是一个高效且易于应用的解决方案，适用于研究和实际应用中的高质量视频生成。", "conclusion": "本文提出的EasyCache为视频扩散模型提供了一种无需训练的加速框架，通过轻量级的运行时自适应缓存机制，显著提升了推断性能，同时保持了高质量视频生成。该方法在多个视频生成模型上验证了其有效性和优越性，适合作为高质视频生成研究和实际应用的解决方案，目前该方法的代码已经公开可供下载。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02861", "html_url": "https://arxiv.org/abs/2507.02861", "title": "LiteReality：从RGB-D扫描重建面向图形的3D场景", "title_en": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans", "authors": "Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby", "background": "本文提出了LiteReality，一种将室内环境的RGB-D扫描转换为紧凑、真实且可交互的3D虚拟复制品的新管道。LiteReality不仅重构了视觉类似于现实的场景，还支持图形管道中的关键功能，如物体独特性、复杂性、基于物理的高质量渲染材料和交互。", "innovation": "LiteReality的核心在于首先进行场景理解并将结果解析为与结构化场景图协调一致的3D布局和物体。其次，通过检索一个精选资产数据库中最具视觉相似性的3D艺术家制作的模型来重建场景。接下来，通过“材料绘画”模块增强真实性，恢复高质量的空间变化材料。最后，恢复的场景被整合进仿真引擎，具有基本物理属性以实现交互行为。此外，LiteReality引入了一个无需训练的对象检索模块，该模块在Scan2CAD基准测试中达到了最先进的相似性性能，并且具有一个强大的“材料绘画”模块，能够在任何风格的图像之间转移外观，即使在严重错位、遮挡和照明不良的情况下也能实现这一功能。", "conclusion": "LiteReality通过将实时扫描快速转换为可编辑的、与标准图形管道兼容的3D虚拟复制品，使得AR/VR、游戏、机器人和数字孪生应用成为可能。该方法已经证明在实际扫描和公开数据集上都是有效的。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02024", "html_url": "https://arxiv.org/abs/2507.02024", "title": "TubuleTracker: 一种高保真共享软件，用于量化血管生成架构和成熟度", "title_en": "TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity", "authors": "Danish Mahmood,Stephanie Buczkowski,Sahaj Shah,Autumn Anthony,Rohini Desetty,Carlo R Bartoli", "background": "体外内皮细胞培养广泛用于研究新生血管生成。组织学图像中细胞网络的分析通常需要手动进行，这个过程耗时且主观。虽然诸如ImageJ（NIH）之类的自动化工具可以帮助，但往往会变得缓慢且不准确。此外，随着内皮网络的复杂性增加，传统的结构度量标准可能无法完全反映网络的成熟度。为了应对这些限制，我们开发了tubuleTracker，这是一种能够快速、客观地量化内皮网络架构和成熟度的软件工具。", "innovation": "tubuleTracker是一款专门用于量化血管生成架构和成熟度的高保真共享软件，能够更快、更一致地分析图像，相比手动分析和基于ImageJ的分析，它更有效且准确。特别地，血管生成的环形度在捕捉血管生成成熟度方面表现突出。", "conclusion": "tubuleTracker在图像分析速度和一致性方面优于手动和基于ImageJ的分析方法。血管生成的环形度在反映血管生成成熟度方面表现尤为突出。tubuleTracker将作为免费的共享软件提供给生物医学研究界使用。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02310", "html_url": "https://arxiv.org/abs/2507.02310", "title": "基于自适应记忆重定位的综合概念漂移持续学习", "title_en": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment", "authors": "Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk", "background": "传统的持续学习方法侧重于知识保留，主要通过缓解灾难性遗忘来处理，假设之前学习的任务数据分布是静态的。然而，这忽略了真实世界数据流的动态性质，即概念漂移永久改变了之前的数据，并要求稳定性和快速适应的结合。", "innovation": "引入了一种综合框架用于应对概念漂移的持续学习，通过演化任务分布模拟实际场景。为了减少大规模标注和计算成本，提出了自适应记忆重定位（AMR）方法，这是一种轻量级的替代方案，通过从过时样本中删除分类的稀有样本，并用最新样本重新填充回放缓冲区，实现了记忆重新与新分布对齐，同时显著减少了对标签数据和计算的需求。使用四个标准视觉基准的数据集变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD、Tiny-ImageNet-CD 进行全面实验，表明AMR在维护高准确性的同时减少了成本。", "conclusion": "AMR作为一种可扩展的解决方案，在非平稳持续学习环境中实现了稳定性和灵活性的平衡。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02302", "html_url": "https://arxiv.org/abs/2507.02302", "title": "DoMIX: 一种高效利用细粒度知识进行微调的框架", "title_en": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning", "authors": "Dohoon Kim,Donghun Kang,Taesup Moon", "background": "Domain-Adaptive Pre-training (DAP) 获得了广泛关注，因其在模型微调中的有效性。现有持续 DAP 方法在训练过程中存在高计算成本和 GPU 内存使用量大的问题，对增量数据顺序敏感，并且提供单一的通用模型来适应所有最终任务，这与 DAP 的本质相悖。", "innovation": "本文提出了 DoMIX，一种利用 LoRA 模块（一种代表性的参数高效微调方法）来解决这些问题的新方法。DoMIX 允许高效的并行领域适应预训练，该预训练对于领域顺序具有鲁棒性，并且有效地利用累积知识，提供了针对特定任务的定制化预训练模型。此外，该方法还可以扩展到标准大模型微调场景。", "conclusion": "我们通过引入 DoMIX，有效地解决了现有 DAP 方法中的主要问题，实现了高效和并行的领域适应预训练，同时提高了模型的泛化能力和对领域顺序的鲁棒性。此外，该方法还对标准大模型微调场景具有适用性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02668", "html_url": "https://arxiv.org/abs/2507.02668", "title": "MEGANet-W：一种基于小波引导注意力框架的弱边界息肉检测方法", "title_en": "MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection", "authors": "Zhe Yee Tan", "background": "结肠息肉分割对于早期发现结肠癌至关重要，但由于薄弱和低对比度边界，自动化检测的准确性受到限制。现有的深度模型要么会模糊细小的边缘细节，要么依赖于手工构建的滤波器，在变异性成像条件下表现不佳。", "innovation": "本文提出了一种小波驱动边缘引导注意力网络MEGANet-W，通过在每个解码器阶段注入方向性、无需参数的小波边缘图来重新校准语义特征。两个主要贡献分别是：（1）多层次的小波头部用于多方向边缘提取；（2）小波边缘引导注意力（WEGA）模块将小波线索与反向分支和输入分支融合。", "conclusion": "MEGANetW在五个公开的数据集上均优于现有方法，分别提高了mIoU达2.3%和mDice达1.2%，并且没有引入额外的可学习参数。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02645", "html_url": "https://arxiv.org/abs/2507.02645", "title": "公平的Deepfake检测器可以泛化", "title_en": "Fair Deepfake Detectors Can Generalize", "authors": "Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli", "background": "Deepfake检测模型面临两个关键挑战：对未见过的操作的泛化能力和群体间的公平性。现有方法往往无法同时满足这两个目标，揭示了它们之间的内在冲突和权衡", "innovation": "首次揭示并正式定义了公平性与泛化之间的因果关系。基于back-door调整，提出可以通过控制混淆因子（数据分布和模型容量）来实现公平干预以改善泛化能力。进一步提出了Demographic Attribute-insensitive Intervention Detection（DAID）框架，该框架包括：1. 具有群体意识的数据重新平衡，利用逆加权和子组特征归一化消除分布偏差；2. 具有群体无关的特征聚合，使用新颖的对齐损失抑制敏感属性信号", "conclusion": "DAID在三个跨域基准测试中均实现了优于多个最先进的检测器的公平性和泛化性能，验证了其理论基础和实际有效性"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02289", "html_url": "https://arxiv.org/abs/2507.02289", "title": "CineMyoPS: 仅从心电MRI图像分割心肌病理学", "title_en": "CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR", "authors": "Wangbin Ding,Lei Li,Junyi Qiu,Bogen Lin,Mingjing Yang,Liqin Huang,Lianming Wu,Sihan Wang,Xiahai Zhuang", "background": "心肌梗死（MI）是全球导致死亡的主要原因之一。晚期钆增强（LGE）和T2加权心脏磁共振（CMR）成像分别用于识别瘢痕和水肿区域，这两个区域对于MI的风险分层和预后评估至关重要。虽然结合多序列CMR提供的互补信息是有用的，但获取这些序列可能耗时且昂贵，例如由于使用对比剂。心电CMR是一种快速且无需对比剂的成像技术，能够可视化急性MI引起的心肌的运动和结构异常。因此，本文提出了一种新的端到端深度神经网络，称为CineMyoPS，用于仅从心电CMR图像中分割心肌病理学，即瘢痕和水肿。", "innovation": "CineMyoPS通过提取与MI相关的运动和解剖特征来识别心肌病理，并设计了一种一致性损失（类似协同训练策略）来促进这些特征的联合学习。此外，引入了时间序列聚合策略来整合心脏周期中的MI相关特征，从而提高了心肌病理学分割的准确性。实验结果表明，CineMyoPS在心肌病理学分割、运动估计和解剖学分割方面表现优异。", "conclusion": "实验结果在多中心数据集上证明了CineMyoPS在心肌病理学分割、运动估计和解剖学分割方面的良好性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02619", "html_url": "https://arxiv.org/abs/2507.02619", "title": "L-VAE：具有可学习贝塔值的变分自编码器以获得解耦表示", "title_en": "L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation", "authors": "Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural", "background": "本文提出了一个名为Learnable VAE (L-VAE)的新模型，该模型能够在学习解耦表示的同时学习成本函数的超参数。L-VAE可以视为eta-VAE的扩展，其超参数eta是通过实验调整的。L-VAE通过学习损失函数中各项的相对权重来控制解耦和重构损失之间的动态权衡。实验分析表明，L-VAE能够在重构保真度和解耦潜在维度之间找到有效的平衡。", "innovation": "L-VAE通过学习损失项的权重和模型架构参数来学习，可以自我调整解耦和重构之间的权衡。L-VAE还引入了一个额外的正则化项，以防止偏向重构损失或解耦损失。实验结果表明，相对于eta-VAE，VAE，ControlVAE，DynamicVAE和sigma-VAE，在多个数据集上，L-VAE始终提供了最好的或第二好的性能。特别是在CelebA面部数据库上的定性实验中，L-VAE模型成功地解耦了面部属性。", "conclusion": "实验结果表明，L-VAE在多个数据集上提供最优或次优的表现，并且在CelebA数据集上成功解耦面部属性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02672", "html_url": "https://arxiv.org/abs/2507.02672", "title": "MISCGrasp：利用多重集成尺度和对比学习增强体素抓取", "title_en": "MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping", "authors": "Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang", "background": "机器人抓取在应对形状和尺寸变化多样的物体时面临挑战。该文介绍了一种名为MISCGrasp的体素抓取方法，通过多尺度特征提取与对比特征增强相结合，实现自适应抓取。此方法利用Insight Transformer进行高、低层次特征的查询交互，同时Empower Transformer选择性地关注最高层次特征，平衡了对细微几何细节和整体几何结构的关注。MISCGrasp通过多尺度对比学习利用正样本之间的相似性，保证多尺度特征的一致性。", "innovation": "MISCGrasp通过多尺度特征提取与对比特征增强相结合，引入Insight Transformer实现高、低层次特征的查询交互，以及Empower Transformer选择性关注最高层次特征，平衡了细节与整体结构的抓取策略。此外，通过多尺度对比学习，MISCGrasp保证了多尺度特征的一致性。", "conclusion": "在仿真和真实世界环境中的大量实验表明，MISCGrasp在台面去杂物任务中优于基线和变体方法。更多详细信息请参阅：this https URL"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2303.06285", "html_url": "https://arxiv.org/abs/2303.06285", "title": "DeltaEdit: 探索无文本训练以实现文本驱动的图像编辑", "title_en": "DeltaEdit: Exploring Text-free Training for Text-Driven Image Manipulation", "authors": "Yueming Lyu,Tianwei Lin,Fu Li,Dongliang He,Jing Dong,Tieniu Tan", "background": "文本驱动的图像操作在训练或推断灵活性方面仍然具有挑战性。条件生成模型严重依赖昂贵的标注训练数据。近年来，利用预训练的视觉-语言模型的框架也受到限制，这些框架要么仅针对特定文本提示进行优化，要么在推断阶段需要调整超参数。", "innovation": "本文提出了一种名为DeltaEdit的新型框架，通过探索和识别CLIP可视特征差异和CLIP文本嵌入差异之间的良好对齐分布空间来应对上述问题。基于CLIP差异空间，DeltaEdit在训练阶段将CLIP视觉特征差异映射到StyleGAN的编辑方向，然后在推断阶段，它根据CLIP文本特征差异预测StyleGAN的编辑方向。从而，DeltaEdit以无文本方式完成训练。一旦训练完成，它能够在零样本推断阶段应用于各种文本提示，无需额外的技术手段。", "conclusion": "DeltaEdit框架能够在无需任何文本提示的情况下进行训练，并能够在推断过程中适应多种文本提示，从而提高文本驱动图像编辑的灵活性和泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02671", "html_url": "https://arxiv.org/abs/2507.02671", "title": "基于嵌入的差分隐私条件VAEs联邦数据共享", "title_en": "Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs", "authors": "Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig", "background": "深度学习（DL）在医疗成像领域引发了革命，但其应用受制于数据稀缺和隐私法规的限制，减少了对多样数据集的访问。联邦学习（FL）能够实现去中心化的训练，但同时也具有高通信成本的问题，通常局限于单一下游任务，降低了灵活性。", "innovation": "本文提出了利用差分隐私生成模型的数据共享方法。通过采用基础模型，提取紧凑、信息丰富的嵌入，减少冗余并降低计算开销。客户端协作训练差分隐私条件变分自编码器（DP-CVAE），以建模全局隐私感知数据分布，支持多样化的下游任务。验证结果表明，该方法增强了隐私、可扩展性和效率，优于传统的FL分类器，同时确保了差分隐私。此外，DP-CVAE产生的嵌入质量优于DP-CGAN，且所需的参数仅为后者的五分之一。", "conclusion": "本文提出的方法取得了跨多个特征提取器的有效验证，提高了隐私保护、可扩展性和效率，优于传统FL分类器，同时保持了差分隐私，并且DP-CVAE相比DP-CGAN生成了更高质量的嵌入，但所需参数更少。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2211.16289", "html_url": "https://arxiv.org/abs/2211.16289", "title": "轻量级结构感知注意力机制在视觉理解中的应用", "title_en": "Lightweight Structure-Aware Attention for Visual Understanding", "authors": "Heeseung Kwon,Francisco M. Castro,Manuel J. Marin-Jimenez,Nicolas Guil,Karteek Alahari", "background": "注意力操作已经被广泛应用于视觉理解中，因其可调节的内核提供了一定的灵活性。然而，注意力操作固有的局限性包括：（1）注意力内核的判别性不够，导致高度冗余；（2）计算和内存复杂度与序列长度成二次关系。", "innovation": "本文提出了一个新的注意力操作，称为轻量级结构感知注意力（LiSA），它可以以对数线性复杂度提供更好的表示能力。通过学习结构模式来转换注意力内核，使其更加判别。此外，结构模式通过利用相对位置嵌入（RPEs）作为乘法规则来近似，从而获得对数线性复杂度。", "conclusion": "实验和分析表明，所提出的操作在ImageNet-1K和其他下游任务（如Kinetics-400中的视频动作识别、COCO中的对象检测与实例分割、ADE-20K中的语义分割）上优于自注意力和其他现有的操作，达到了最先进的性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02367", "html_url": "https://arxiv.org/abs/2507.02367", "title": "一种用于动态小型动物$^{18}$F-FDG PET成像动脉输入函数预测的稳健且多功能深度学习模型", "title_en": "A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\\left[^{18}\\text{F}\\right]$FDG PET imaging", "authors": "Christian Salomonsen,Luigi Tommaso Luppino,Fredrik Aspheim,Kristoffer Wickstrøm,Elisabeth Wetzer,Michael Kampffmeyer,Rodrigo Berzaghi,Rune Sundset,Robert Jenssen,Samuel Kuttner", "background": "动态正电子发射断层扫描（PET）和动力学模型对于推进小型动物研究中的标记物开发至关重要。准确的动力学模型需要精确的输入函数估计，传统上通过动脉采血实现。然而，对小动物，如小鼠，进行动脉切开术涉及复杂的、耗时的和有时是致命的程序，阻碍了长期研究的进行。因此，这项工作提出了一种非侵入性的、全卷积的深度学习方法（FC-DLIF），可以直接从PET成像中预测输入函数，可能无需进行血液采样。该方法使用$^{18}$F-FDG数据进行训练和评估，并进一步在两种额外的放射性标记物（$^{18}$F-FDOPA 和 $^{68}$Ga-PSMA）的数据上进行验证，还评估了从时序截断和延迟的PET扫描数据中预测动脉输入函数的能力。", "innovation": "提出了一种非侵入性的、全卷积的深度学习模型（FC-DLIF），可以直接从PET成像中预测动脉输入函数，避免了传统的通过动脉采血来获取输入函数的方法，特别适用于小型动物。该模型包括一个空间特征提取器和一个时间特征提取器，能够从PET时间序列的体积时间帧中提取空间特征，并进一步预测动脉输入函数。实验表明，该模型可以在各种情况下可靠地预测动脉输入函数，并且能够处理截断和延迟的数据样本。", "conclusion": "深度学习方法提出的动脉输入函数提供了传统的动脉采血方法无法比拟的非侵入性且可靠的替代方案。该方法不仅在数据完整性完整的情况下表现良好，还可以在数据存在截断和延迟的情况下预测动脉输入函数。然而，对于不同放射性标记物收集的数据，该方法预测动脉输入函数的效果较差，因为这些标记物在训练数据中没有得到充分的代表。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02864", "html_url": "https://arxiv.org/abs/2507.02864", "title": "MultiGen: 使用多模态生成在仿真中学习多模态政策", "title_en": "MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real", "authors": "Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros", "background": "机器人需要整合多种感官模态以有效地在真实世界中行动。然而，在大规模学习多模态策略方面依然充满挑战。仿真为这一问题提供了可行的解决方案，但视觉可以受益于高保真模拟器，而其他模态（如声音）往往难以模拟。因此，从仿真到现实世界的转移主要在基于视觉的任务中取得成功，而多模态的转移依然没有实现。", "innovation": "我们提出了MultiGen框架，将大规模生成模型整合到传统的物理模拟器中，从而实现多感官模拟。通过在模拟视频上生成与之匹配的现实感声音，我们的方法可以在没有使用任何真实机器人数据的情况下，在丰富的视听轨迹上进行训练。我们展示了该方法在真实世界倒酒任务中的有效零样本转移，验证了生成建模在模拟难以建模的模态以及缩小多模态仿真到现实世界的差距方面的潜力。", "conclusion": "我们的工作解决了多模态仿真到现实世界转移中的挑战，展示了生成建模在仿真多模态任务中的有效性和潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02771", "html_url": "https://arxiv.org/abs/2507.02771", "title": "将智能 grounding 在运动中", "title_en": "Grounding Intelligence in Movement", "authors": "Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording", "background": "最近的机器学习进展极大地提高了我们建模语言、视觉和其他高维度数据的能力，但仍然在处理生物学系统的基本方面——运动方面遇到困难。运动是神经科学、医学、机器人学和动物行为学等领域解读行为、预测意图和促成互动的核心。尽管对于我们的智能来说运动至关重要，但它经常被视为次要因素，而不是一个拥有丰富结构的独立模态。这种认知差异反映了运动数据收集和建模中深刻的碎片化，通常受限于特定任务的目标和特定领域的假设。然而，运动并非局限于特定领域，它体现了共享的物理约束、保守的形态结构以及跨物种和场景的目的动态。本文认为，运动应该被视为人工智能的主要建模目标。运动本质上是结构性的，并且基于机体和物理。这种结构往往使运动可以从原始、高维度的感官输入中更容易地进行紧凑、低维度的表示，从而使建模更加可解释和计算上可处理。开发能够从多样化的运动数据中学习并泛化的模型不仅能推动生成建模和控制的核心能力，还能为理解生物系统和人工系统行为创建一个共同基础。运动不仅仅是结果，它还是理解智能系统如何与世界互动的一个窗口", "innovation": "本文提出将运动作为人工智能的主要建模目标，强调运动的结构性和物理性，这种结构使得可以采用更紧凑、低维度的表示方法，从而使得建模更加可解释和计算上可处理。这种观点打破了运动数据收集和建模的碎片化，并提出通过多元化的运动数据学习和泛化来推动生成建模和控制的核心能力，同时促进生物系统和人工系统行为的理解", "conclusion": "运动不仅是智能结果，更是理解智能系统如何与世界互动的一个窗口。开发能够从多样化的运动数据中学习并泛化的模型不仅能够推动生成建模和控制的核心能力，还能为理解生物系统和人工系统行为创建一个共同基础。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.05945", "html_url": "https://arxiv.org/abs/2408.05945", "title": "MV2DFusion：利用模态特定对象语义实现多模态3D检测", "title_en": "MV2DFusion: Leveraging Modality-Specific Object Semantics for Multi-Modal 3D Detection", "authors": "Zitian Wang,Zehao Huang,Yulu Gao,Naiyan Wang,Si Liu", "background": "无人驾驶汽车的发展显著增加了对坚固的3D物体检测系统的市场需求。现有传感器（如相机和LiDAR）各自具有独特的优势：相机提供丰富的纹理信息，而LiDAR提供精确的空间数据。然而，依赖单一模态传感器会导致性能限制。因此，研究多模态检测框架的需求日益增加，旨在通过综合多个传感器的优势来提高检测性能.", "innovation": "该论文提出了一种名为MV2DFusion的多模态检测框架，它通过先进的查询融合机制整合了相机和LiDAR的优势。MV2DFusion引入了图像查询生成器和点云查询生成器，可以对齐模态特定的属性，从而有效结合了模态特定的对象语义，而不偏向单一模态。通过基于有价值的对象语义进行稀疏融合，MV2DFusion能够在各种场景中实现高效和准确的3D物体检测。框架的灵活性使它可以与任何基于图像和点云的检测器集成，展示了其适应性和未来进步的潜力.", "conclusion": "该框架在nuScenes和Argoverse2数据集上进行广泛评估，证明了MV2DFusion的优越性能，特别是在远程检测场景中表现出色。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.05766", "html_url": "https://arxiv.org/abs/2405.05766", "title": "向XAI系统中用户信任的新度量迈出一步", "title_en": "Towards a Novel Measure of User Trust in XAI Systems", "authors": "Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho", "background": "随着深度学习模型在各个领域的广泛应用，人们对这些模型的依赖程度不断提高。然而，深度学习模型缺乏透明性，导致用户对其决策过程的信任度下降。为了提高用户对自动系统的信任，研究领域引入了可解释人工智能(XAI)方法，这些方法旨在提供决策背后的洞察，从而增加透明度。本文便是这一背景下的一项研究，旨在提出一种新的XAI系统用户信任度量方法，以进一步增强其信任度并使其更加精细可靠。", "innovation": "本文提出了一个新视角的度量指标，结合了性能指标和信任指标，用于评估和改进XAI系统的用户信任度。该方法通过三个案例研究证明了其相对于现有技术的有效性，尤其是在处理各种场景时，能够增加更灵敏的响应能力。", "conclusion": "该研究通过引入一种新的用户信任度量方法，展示了在XAI系统中增强用户信任的可能性。三个案例研究验证了该方法的有效性，提出的新度量指标将有助于未来XAI系统的设计和优化。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02674", "html_url": "https://arxiv.org/abs/2507.02674", "title": "实时光照下的图像基础照明", "title_en": "Real-time Image-based Lighting of Glints", "authors": "Tom Kneiphof,Reinhard Klein", "background": "基于图像的照明是一种广泛应用于再现真实世界光照条件下阴影的技术，特别是在实时渲染应用中。一种特别具有挑战性的场景是具有闪烁或反光外观的材料，这类材料由于其表面上分布着离散的微面而产生。本文讨论了如何在动态材料特性和环境贴图下实现基于图像的闪烁照明。", "innovation": "提出了一种高效近似闪烁照明的基于图像的照明方法，能够在区域光照照明下实时渲染材料，通过使用标准环境贴图过滤技术，并且环境贴图的过滤过程足够快，可以在每帧基础上执行。方法假设环境贴图被分为少数几个具有恒定辐射强度的同质区域，通过使用高斯分布函数过滤相应的指示函数，可以获得每个微面从每个区域反射光的概率。在绘制阶段，这些概率用于分层抽取多项分布，通过我们新的双重门高斯近似二项分布的新颖方法实现。", "conclusion": "实验证明，该实时近似方法在多种材料特性和光照条件下与真实渲染结果非常接近，表现出稳定且稳健的性能，相对于渲染单向光的闪烁，虽然需要更多的内存存储预滤波环境贴图，但内存消耗仅为两倍。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.18038", "html_url": "https://arxiv.org/abs/2407.18038", "title": "TiCoSS: 在联合学习框架内紧固语义分割与立体匹配之间的耦合", "title_en": "TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo Matching within A Joint Learning Framework", "authors": "Guanfeng Tang,Zhiyuan Wu,Jiahang Li,Ping Zhong,We Ye,Xieyuanli Chen,Huiming Lu,Rui Fan", "background": "语义分割和立体匹配分别类比于人类大脑中的腹侧流和背侧流，是自主驾驶感知系统中的关键组成部分。随着大型视觉模型和具身人工智能的最新进展，这些问题不再仅用单独的网络进行处理，而是转向在一个联合学习框架中整合它们，特别强调两个任务之间的特征共享。这种趋势反映了对更紧密耦合语义分割和立体匹配的需求。", "innovation": "本文的主要贡献在于全面紧固语义分割和立体匹配之间的耦合，具体包括三个创新：(1) 一种紧密耦合的门控特征融合策略，(2) 一种分层深度监督策略，(3) 一种耦合紧固损失函数。这些技术贡献共同形成了TiCoSS，一种目前最先进的联合学习框架，能够同时处理语义分割和立体匹配。通过大规模实验和定量定性分析，验证了所提出策略和损失函数的有效性，并展示了与现有技术相比的优越性能，mIoU提高了超过9%。", "conclusion": "本文通过引入TiCoSS，实现了语义分割和立体匹配在联合学习框架内的更紧密耦合，并通过大规模实验和分析，验证了其先进性和优越性。相关源代码将在发表后公开。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.15026", "html_url": "https://arxiv.org/abs/2408.15026", "title": "Echocardiography Probe Movement Guidance via Sequence-aware Pre-training", "title_en": "Sequence-aware Pre-training for Echocardiography Probe Movement Guidance", "authors": "Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang", "background": "经胸超声心动图是一种用于诊断心血管疾病的必要医疗技术，但其高操作复杂性导致了专业人员的短缺。心脏结构的复杂性和个体的巨大变异性使得图像质量不一。尽管有前人的工作学习了人群平均的心脏结构，但未能精确反映个性化的心脏结构，这对临床诊断造成了一定的障碍。临床实践中，超声技师会根据之前的扫描序列动态调整其对患者心脏解剖结构的解释，进而改进他们的扫描策略。然而，如何通过模型实现对个性化心脏结构的理解仍然是一个挑战。", "innovation": "本文提出了一种序列感知的自我监督预训练方法，旨在通过预测扫描序列中缺失的图像特征和探头运动行为，学习个性化的心脏三维结构特征。研究显示，与现有顶级基线方法相比，这种新的序列感知范式在减少探头指导错误方面更为有效。该方法有可能应用于机器人系统或指导探头位置调整，以实现高质量的心脏标准平面图像。", "conclusion": "我们的研究表明，在大规模专家扫描数据集（包含131万样本）上，所提出的方法在减少探头指导错误方面表现优异，展示了其在综合学习个性化心脏结构特征方面的有效性。未来的研究将进一步探索如何将此方法应用于实际临床实践中，并进一步优化算法性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03349", "html_url": "https://arxiv.org/abs/2412.03349", "title": "更公平的分析与分层平衡人脸生成以实现更公平的人脸验证", "title_en": "Fairer Analysis and Demographically Balanced Face Generation for Fairer Face Verification", "authors": "Alexandre Fournier-Montgieux,Michael Soumm,Adrian Popescu,Bertrand Luvison,Hervé Le Borgne", "background": "面部识别和验证是计算机视觉任务，随着深度表示的引入，其性能得到了提升。然而，由于面部数据的敏感性质和真实世界训练数据集中的偏见，伦理、法律和技术挑战阻碍了其发展。生成式AI通过生成虚构身份来解决隐私问题，但公平性问题仍然存在。现有的DCFace SOTA框架在公平性方面仍存在问题，因此需要改进。", "innovation": "本文通过引入一种新的受控生成管道，改进了现有的DCFace SOTA框架，并使用现有的经典公平性度量标准和基于逻辑模型和ANOVA的深入统计分析，证明了本文提出的生成管道在公平性方面优于其他偏见缓解方法，同时略微提高了基本性能。", "conclusion": "通过使用经典公平性度量标准和基于逻辑模型及ANOVA的深入统计分析，本文的生成管道在公平性方面取得了显著的改进，同时在基本性能方面略有提升。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.16236", "html_url": "https://arxiv.org/abs/2410.16236", "title": "LLaVA-KD: 一种蒸馏多模态大型语言模型的框架", "title_en": "LLaVA-KD: A Framework of Distilling Multimodal Large Language Models", "authors": "Yuxuan Cai,Jiangning Zhang,Haoyang He,Xinwei He,Ao Tong,Zhenye Gan,Chengjie Wang,Zhucun Xue,Yong Liu,Xiang Bai", "background": "大型语言模型（LLMs）的成功促进了多模态大型语言模型（MLLMs）的发展，以实现对视觉和语言的统一理解。然而，大型多模态模型（l-MLLMs）的模型规模和计算复杂性限制了它们在资源受限场景中的应用。尽管设计了小型多模态模型（s-MLLMs）以降低计算成本，但它们通常会遭受性能下降。为缓解这一限制，我们提出了一种名为LLaVA-KD的新框架，用于从l-MLLMs向s-MLLMs转移知识。", "innovation": "我们引入了多模态蒸馏（MDist）来在校验视觉和语言模态中直接传输教师模型的稳健表示，还引入了关系蒸馏（RDist）来传输教师模型捕捉视觉标记关系的能力。此外，我们提出了一种三阶段训练方案，以充分利用所提出的蒸馏策略：首先是蒸馏预训练增强s-MLLMs中视觉-语言表示之间的对齐，其次是监督微调为s-MLLMs提供跨模态理解能力，最后是蒸馏微调进一步完善s-MLLMs的知识。", "conclusion": "我们的方法在不改变模型架构的情况下显著改善了s-MLLMs的性能。大量实验和消融研究验证了每个提出的组件的有效性。代码将在该网址获得：this https URL"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11074", "html_url": "https://arxiv.org/abs/2412.11074", "title": "Adapter-增强语义提示用于连续学习", "title_en": "Adapter-Enhanced Semantic Prompting for Continual Learning", "authors": "Baocai Yin,Ji Zhao,Huajie Jiang,Ningning Hou,Yongli Hu,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi", "background": "连续学习(CL)能够使模型适应不断变化的数据流。传统的CL方法面临灾难性遗忘的问题，即新知识会覆盖已有的知识。传统的解决方式通常会保留过去的全部数据进行回放，或者给模型添加额外的分支来学习新知识，这需要较高的内存需求。因此，论文旨在开发一种轻量级的CL框架，以解决这一问题，同时提高模型的泛化能力并有效地融合语义信息，以适应连续学习的任务。", "innovation": "提出了一个名为Adapter-增强语义提示(AESP)的新型轻量级CL框架，该框架结合了提示微调和适配器技术。具体来说，设计了语义引导的提示来增强视觉特征的泛化能力，并利用适配器高效融合语义信息，旨在为连续学习任务学习更具适应性的特征。此外，还开发了一种新颖的提示选择匹配机制，以选择合适的任务提示来进行特征调整。", "conclusion": "在三个CL数据集上的广泛实验表明，该方法在多个指标上取得了良好的性能，显示了其在CL研究中的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.03782", "html_url": "https://arxiv.org/abs/2409.03782", "title": "评估笔记本电脑维修软件中的不确定性和鲁棒性", "title_en": "Assessing the Uncertainty and Robustness of the Laptop Refurbishing Software", "authors": "Chengjie Lu,Jiahui Wu,Shaukat Ali,Mikkel Labori Olsen", "background": "翻新笔记本电脑可以延长其使用寿命并减少电子废物，促进可持续发展。丹麦技术研究所（DTI）专注于研究和开发带有软件驱动的机器人应用，包括笔记本电脑翻新。清洁是翻新过程中重要的一环，需要识别并移除笔记本表面的贴纸。软件在清洁过程中起着关键作用，通过集成多种物体检测模型来自动识别和移除贴纸。但由于贴纸类型多样（如形状、颜色、位置），识别粘贴物存在不确定性，需要明确量化识别过程中与贴纸相关的不确定性，从而降低其对笔记本电脑表面造成的风险。为了量化不确定性，作者采用蒙特卡洛 Dropout 方法评估了来自DTI的六种贴纸检测模型（SDMs），使用了三个数据集：DTI的原始图像数据集以及使用视觉语言模型生成的两大数据集DALL-E-3和Stable Diffusion-3。此外，作者还提出了新的针对检测准确性和不确定性的鲁棒性度量标准，以基于三种数据集使用密集的对手方法生成对抗数据集来评估SDMs的鲁棒性。", "innovation": "作者采用了蒙特卡洛 Dropout 方法评估了笔记本电脑贴纸检测模型的不确定性和鲁棒性，并提出了新的鲁棒性度量标准，这些对于识别并移除使得笔记本电脑翻新的过程中自动识别和移除贴纸具有重要意义。通过这些方法，开发了一种更加准确和可靠的软件解决方案，帮助降低翻新过程中对笔记本电脑造成损害的风险。", "conclusion": "评估结果表明，不同的贴纸检测模型在不同指标上的表现不同，基于这些结果，作者提供了贴纸检测模型的选择指南，并提供了各种视角下的经验教训。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.14171", "html_url": "https://arxiv.org/abs/2412.14171", "title": "空间思维：多模态大型语言模型如何感知、记忆和回忆空间", "title_en": "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces", "authors": "Jihan Yang,Shusheng Yang,Anjali W. Gupta,Rilyn Han,Li Fei-Fei,Saining Xie", "background": "人类具有视觉-空间智能，可以从一系列视觉观察中记住空间。然而，大型语言模型（LLMs）在处理大规模视频数据集训练后，是否能够从视频中进行“空间思维”？该研究旨在探讨多模态大型语言模型在空间思维上的能力并建立了一个包含5000多对问题-答案的视频基础视觉-空间智能基准测试（VSI-Bench），结果显示这些模型在视觉-空间智能上表现相当但低于人类水平。研究表明，空间推理仍然是这些模型性能的主要瓶颈，但局部世界模型和空间意识逐渐在模型中显现出来。语言推理方法（如逐步推理、自我一致性、如意象树推理）未对改善模型性能产生有效影响，而是在问答过程中显式生成认知地图能够提升模型的空间距离能力。", "innovation": "研究构建了首个面向多模态大型语言模型的视频基础视觉-空间智能基准测试（VSI-Bench），并从语言和视觉方面探索了模型的空间思维过程。此外，研究还发现，在问答过程中显式生成认知地图能够提升大型语言模型在空间距离能力上的表现，并且传统的语言推理方法未能有效提升模型的空间推理能力。", "conclusion": "空间思维仍然是大型语言模型的主要瓶颈，局部世界模型和空间意识正在模型中逐渐形成，但传统的语言推理方法对提升模型的空间推理能力效果有限。未来的研究可能需要探索新的方法和技术，以进一步提升模型的空间智能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.05827", "html_url": "https://arxiv.org/abs/2412.05827", "title": "自我指导：在流动和扩散生成中的自我增强", "title_en": "Self-Guidance: Boosting Flow and Diffusion Generation on Their Own", "authors": "Tiancheng Li,Weijian Luo,Zhiyang Chen,Liyuan Ma,Guo-Jun Qi", "background": "现有的图像生成指导方法要么需要特定的训练，要么依赖扩散模型网络的强烈归纳偏置，这可能限制了它们的应用范围。观察到在从噪声较大的噪声级别到清洁的噪声级别的过程中，可由显著密度下降检测到伪影异常，作者提出了一种名为Self-Guidance（SG）的方法，通过抑制低质量样本的生成来提升图像质量。SG仅依赖于自身扩散模型在不同噪声级别下的采样概率，无需进行任何特定指导训练，这使其能够在与其他采样算法“即插即用”的形式下使用。此外，还提出了一个更高效的SG近似方法SG-prev，通过重复用上一步的输出来避免采样时间翻倍的问题。实验在不同的架构如UNet和变压器模型的文本到图像和文本到视频生成中进行，使用开源的扩散模型如Stable Diffusion 3.5和FLUX，该方法在多个指标上超过了现有算法，包括FID和人类偏爱评分。同时，SG-prev仅需一次前向传递就取得了比基线和SG更强的结果。另外研究发现，SG和SG-prev对生成生理上正确的身体结构，如手部、面部和手臂有显著的积极影响，展示了它们最小努力消除身体伪影的能力。", "innovation": "该研究提出了Self-Guidance（SG）和更高效的SG-prev方法。主要创新在于，SG仅依赖于其自身扩散模型的不同噪声级别下的采样概率，无需特定指导训练，即可抑制低质量样本，提升图像生成质量，并且可以在其他采样算法中“即插即用”。SG-prev通过重复使用上一步的输出来避免采样时间翻倍，提升了效率。这些方法在多个文本到图像和文本到视频生成模型中表现优异，并显著改善了对人体结构生成的真实性和准确性。", "conclusion": "实验结果表明，SG和SG-prev在Stable Diffusion 3.5和FLUX等开源扩散模型上，分别在FID和人类偏爱评分等多个指标上超过现有的生成算法，并对生成生理上正确的人体结构有显著效果。研究将进一步发布相关的代码。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08654", "html_url": "https://arxiv.org/abs/2501.08654", "title": "ZeroStereo：单图像零样本立体匹配", "title_en": "ZeroStereo: Zero-Shot Stereo Matching from Single Images", "authors": "Xianqi Wang,Hao Yang,Gangwei Xu,Junda Cheng,Min Lin,Yong Deng,Jinliang Zang,Yurui Chen,Xin Yang", "background": "最先进的监督立体匹配方法在各种基准测试上取得了出色的表现，但在真实场景中的泛化能力仍然存在挑战，原因是缺少标注的真实世界立体数据。", "innovation": "提出了一种新的零样本立体图像生成流水线ZeroStereo，通过利用单目深度估计模型生成的伪视差，来合成高质量的右图像。与之前仅通过填充缺失区域或随机背景的方法不同，本文采用微调的扩散修复模型来恢复缺失的细节，同时保留语义结构。此外，还提出了无需额外训练的训练免费置信生成，以及自适应视差选择，确保了多样性和现实性的视差分布，同时防止过度遮挡和前景失真。", "conclusion": "使用该流水线训练的模型在多个数据集上的零样本泛化达到了最先进的水平，仅需与Scene Flow相当的数据集体积。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.01717", "html_url": "https://arxiv.org/abs/2501.01717", "title": "KeyNode-Driven Geometry Coding for Real-World Scanned Human Dynamic Mesh Compression", "title_en": "KeyNode-Driven Geometry Coding for Real-World Scanned Human Dynamic Mesh Compression", "authors": "Huong Hoang,Truong Nguyen,Pamela Cosman", "background": "实时扫描的人类动态三维网格的压缩是一个新兴的研究领域，受到诸如远程呈现、虚拟现实和三维数字流媒体等应用的驱动。与具有固定拓扑结构的合成动态网格不同，扫描的动态网格不仅各帧之间拓扑变化多，还存在孔洞和离群点等扫描缺陷，增加了预测和压缩的复杂性。此外，人类网格通常结合了刚体和非刚体运动，这使得与仅表现出刚体运动的物体相比，准确的预测和编码变得更加困难。", "innovation": "本文提出了一种针对真实世界扫描的人类动态网格的压缩方法，利用嵌入的关键节点。每个顶点的临时运动被构造成来自邻近关键节点的变换的加权距离组合，仅需传输关键节点的变换。为了提高关键节点驱动预测的质量，引入了一种基于八叉树的残差编码方案和双向预测模式，使用来自两个方向的I帧。实验结果表明，该方法在评估序列上平均比特率节省了58.43%，特别是在低比特率下表现出色。", "conclusion": "我们的方法在现有技术上取得了显著改进，通过关键节点驱动的方法显著降低了比特率，特别是在低比特率场景下效果更为明显。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15248", "html_url": "https://arxiv.org/abs/2501.15248", "title": "使用扩散模型进行数据增强以提高胎儿平面分类准确性", "title_en": "Enhancing Fetal Plane Classification Accuracy with Data Augmentation Using Diffusion Models", "authors": "Yueying Tian,Elif Ucurum,Xudong Han,Rupert Young,Chris Chatwin,Philip Birch", "background": "超声成像在医疗诊断中广泛应用，特别是在胎儿健康评估方面。然而，高质量标注的超声图像资源有限，限制了机器学习模型的训练。本文研究了使用扩散模型生成合成超声图像，以提高胎儿平面分类性能。实验表明，将生成的图像纳入训练管道可以比仅使用真实图像训练获得更好的分类准确性。", "innovation": "提出了使用扩散模型生成合成超声图像的方法，该方法可以有效地解决医学超声成像中的数据稀缺问题。研究中首先在合成图像上训练不同的分类器，然后使用真实图像进行微调。这种方法提高了胎儿平面分类的准确性，并表明生成合成数据可以作为克服数据稀缺的有价值的工具。", "conclusion": "研究结果表明，通过扩散模型生成的合成图像可以显著提高胎儿平面分类的准确性，这是因为在训练过程中引入生成的图像比单独使用真实图像更加有效。这一发现为未来利用合成数据增强医学超声成像中的机器学习应用提供了新的思路。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.10435", "html_url": "https://arxiv.org/abs/2412.10435", "title": "COEF-VQ：通过级联多模态大语言模型框架实现成本效益的视频质量理解", "title_en": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework", "authors": "Xin Dong,Sen Jia,Ming Rui Wang,Yan Li,Zhenheng Yang,Bingfeng Deng,Hongyu Xiong", "background": "最近，随着多模态大型语言模型（MLLM）技术的出现，利用其视频理解能力进行不同分类任务成为可能。然而，如果需要在线部署MLLM时，面临着巨大的GPU资源需求。本文旨在解决这一问题，提出了一种名为COEF-VQ的新颖级联MLLM框架，该框架旨在增强短视频平台上视频质量的理解能力，同时优化计算效率。通过引入基于熵的预筛选阶段，COEF-VQ使用一个轻量级模型评估不确定性并仅选择性地过滤某些情况后再将它们提交给更加计算密集的MLLM进行最终评估，从而优先处理高不确定性的样本进行深层次分析，从而显著降低GPU使用率，同时保持全MLLM部署的强分类性能.", "innovation": "COEF-VQ框架通过引入基于熵的预筛选阶段，利用一个轻量级模型进行不确定性评估，优先处理高不确定性的样本进行深层次分析，从而显著减少GPU使用率，同时保持全MLLM部署的强分类性能。这种新颖的级联多模态大语言模型框架在实现成本效益的视频质量理解方面具有创新性.", "conclusion": "通过对短视频平台视频管理平台（VMP）进行实验证明，COEF-VQ在两个相关的视频质量理解任务中获得了显著的性能提升，并且在上线A/B测试中通过限制资源消耗，显著降低了9.9%的不适内容视频播放率，同时未影响用户参与度。后续的监控显示持续的改进效果，验证了其在实际中的影响。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.19688", "html_url": "https://arxiv.org/abs/2411.19688", "title": "SURE-VQA: 系统理解医学Vision-Language模型鲁棒性评估", "title_en": "SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks", "authors": "Kim-Celine Kahl,Selen Erkan,Jeremias Traub,Carsten T. Lüth,Klaus Maier-Hein,Lena Maier-Hein,Paul F. Jaeger", "background": "Vision-Language模型（VLMs）在医疗任务中具有巨大潜力，例如视觉问答（VQA），可以作为患者和临床医生的交互式助手。然而，它们在未见过的数据上的鲁棒性问题（尤其是分布偏移）仍是安全部署的关键挑战。现有的评估框架未能提供充分彻底的评估，因此需要一个新的框架来系统地分析VLM的鲁棒性。", "innovation": "本文提出了一个名为SURE-VQA的新框架，该框架从三个关键要求出发，解决了当前评估框架的不足：1) 测量实际世界中的鲁棒性，而不是仅限于合成的变化；2) 使用大型语言模型（LLMs）进行语义评估，而不仅仅是传统的令牌匹配度量；3) 报告具有解释性的基础模型性能，以便评估多模态数据对VLM的影响。通过在三个医学数据集上进行研究，以四种类型分布偏移为例，本文得出的关键见解是：无一种微调方法在鲁棒性方面优于其他方法，并且鲁棒性趋势在微调方法间比在分布偏移间更稳定。此外，简单的不使用图像数据的基础模型指标表现也比较出色，并证实了LoRA在内部分布数据上的最佳性能。", "conclusion": "本文通过SURE-VQA框架，系统地分析了VLM在医学VQA任务中的鲁棒性，强调了在不同微调方法之间和不同分布偏移下鲁棒性评估的重要性。研究结果显示，不同微调方法在鲁棒性上的表现并无显著差异，而鲁棒性趋势在不同微调方法间比在不同分布偏移间更稳定。研究还证实了LoRA在医学VQA任务中的有效性和表现最佳。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16025", "html_url": "https://arxiv.org/abs/2502.16025", "title": "FeatSharp: Your Vision Model Features, Sharper", "title_en": "FeatSharp: Your Vision Model Features, Sharper", "authors": "Mike Ranzinger,Greg Heinrich,Pavlo Molchanov,Jan Kautz,Bryan Catanzaro,Andrew Tao", "background": "视觉编码器的特征图是众多现代AI任务的基础，包括核心感知算法（如语义分割、目标检测、深度感知等），以及在视觉语言模型（VLMs）中的现代多模态理解。目前，在计算机视觉领域，通用视觉骨干的前沿是视觉变换器（Vision Transformers，ViT），通常通过对比损失（如CLIP）进行训练。然而，大多数现成的ViTs，尤其是CLIP，存在分辨率固定的缺点，大多数模型运行在224×224像素，高分辨率版本也只有378-448像素，但仍然不灵活。因此，如何提高低分辨率视觉编码器的特征图分辨率，同时保留细粒度细节成为了一个关键问题。", "innovation": "该研究提出了一种新颖的方法，以低成本和连贯的方式提升低分辨率视觉编码器的特征图分辨率，并且能够捕捉到原本因分辨率不足而丢失的细粒度细节。该方法应用于核心感知任务，以及通过积分无线电技术（RADIO）进行模型集训练，以提供更丰富的蒸馏目标。", "conclusion": "通过实验表明，此方法在核心感知任务以及模型训练中非常有效，提高了低分辨率视觉编码器的特征图分辨率，使得视觉模型识别细节更加精准。代码可在指定链接获取。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.05673", "html_url": "https://arxiv.org/abs/2502.05673", "title": "数据集蒸馏的发展：迈向可扩展和通用的解决方案", "title_en": "The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions", "authors": "Ping Liu,Jiawei Du", "background": "数据集蒸馏是一种将大规模数据集凝练成紧凑的合成表示，以高效训练现代深度学习模型的关键解决方案。之前的综述主要关注2023年以前的发展，而本文则全面回顾了近年来的数据集蒸馏进展，特别是对大规模数据集（如ImageNet-1K和ImageNet-21K）的有效扩展性进行了强调。", "innovation": "本文创新地将进展分类为几个关键方法：轨迹匹配、梯度匹配、分布匹配、可扩展的生成方法，以及拆分优化机制。综述中强调的突破性创新包括SRe2L框架，实现了高效的蒸馏凝练；软标签策略显著提升了模型性能；以及无损蒸馏技术，最大化了压缩比同时保持性能。同时，还探讨了鲁棒性、非IID数据分布的有效处理等关键挑战。", "conclusion": "综上所述，本文通过进行全面的数据集蒸馏综述，结合广泛的性能比较和实用的研究方向指南，为研究人员和实践者提供了宝贵的见解，以推动数据集蒸馏的高效和泛化，为未来的创新铺平了道路。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20323", "html_url": "https://arxiv.org/abs/2502.20323", "title": "ARTalk: 通过自回归模型实现语音驱动的3D头部动画", "title_en": "ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model", "authors": "Xuangeng Chu,Nabarun Goswami,Ziteng Cui,Hanqin Wang,Tatsuya Harada", "background": "现有的基于扩散模型的语音驱动3D面部动画方法可以生成自然的运动，但其生成速度较慢，限制了其应用潜力。此类方法难以满足实时生成场景的需求，尤其是在需要精确唇部同步和多样化的面部表情时。因此，如何开发一种既能实时生成又能保持高质量动画效果的方法成为研究热点，尤其是在适应未见过的说话风格方面。", "innovation": "提出了一个新的自回归模型，通过学习从语音到多尺度运动码本的映射，实现实时生成高同步性唇部运动和真实头部姿态及眨眼动作。该模型能够适应未见过的说话风格，生成具有独特个人风格的3D对话化身，超越了训练时的身份限制。模型在准确性和感知质量方面普遍优于现有的方法，尤其是在唇部同步方面表现更优。", "conclusion": "通过实验和用户研究，表明该方法在唇部同步准确性和感知质量上都超越了现有方法。这一创新性模型为实时生成高精度面部动画提供了新的可能性，特别是在语音驱动的3D面部动画领域。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.03997", "html_url": "https://arxiv.org/abs/2502.03997", "title": "CAD-Editor: 基于自动训练数据合成的定位-填充框架用于文本驱动的CAD编辑", "title_en": "CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing", "authors": "Yu Yuan,Shizhao Sun,Qi Liu,Jiang Bian", "background": "计算机辅助设计（CAD）在众多行业中都是不可或缺的。基于文本的CAD编辑可以自动化根据文本指令修改CAD模型，具有巨大的潜力但目前还尚未充分开发。现有的方法主要集中在设计变化生成或基于文本的CAD生成，要么缺乏文本控制支持，要么忽视现有CAD模型作为约束条件。针对这一挑战，我们提出了CAD-Editor，这是一个首个基于文本的CAD编辑框架。", "innovation": "为了应对训练所需的数据三元组具有准确对应性的挑战，我们提出了一个自动数据合成流水线。该流水线利用设计变化模型生成原始和编辑后的CAD模型对，并使用大型的视觉-语言模型（LVLMs）将其差异总结为编辑指令。为了解决文本驱动的CAD编辑的复合性质，我们提出了一个'定位-填充'框架，将任务分解为两个更专注于子任务：定位需要修改的区域，并用适当的编辑填充这些区域。大量语言模型（LLMs）在两个子任务中担任骨干，利用其自然语言理解和CAD知识的能力。实验结果表明，CAD-Editor在定量和定性方面都取得了优异的性能。", "conclusion": "实验结果表明CAD-Editor在定量和定性方面都取得了优异的性能。该代码可在以下网址获取：[提供链接]"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16095", "html_url": "https://arxiv.org/abs/2502.16095", "title": "良好表示，更好解释：卷积神经网络在基于变换器的遥感图像描述中的作用", "title_en": "Good Representation, Better Explanation: Role of Convolutional Neural Networks in Transformer-Based Remote Sensing Image Captioning", "authors": "Swadhin Das,Saarthak Gupta,Kamal Kumar,Raksha Sharma", "background": "遥感图像描述（RSIC）是生成具有意义的描述性文本的过程。近年来，由于能够生成有意义的图像描述，编码器-解码器模型引起了广泛的关注。而Transformer模型已经由于其捕捉长期依赖性和上下文信息的能力而变得非常受欢迎。尽管解码器在文本生成方面研究较多，但是对其编码器部分仍然缺乏深入探索。编码器性能直接影响生成描述的质量，因此选择合适的编码器至关重要。", "innovation": "本文系统评估了十二种不同的卷积神经网络（CNN）架构在基于变换器的编码器框架下的有效性，以探索卷积神经网络在改进遥感图像描述中的作用。评估分为两阶段：首先进行定量分析，并基于表现将其分类；之后由人类评价员从人本角度对表现最佳的CNN进行评估，同时分析贪婪搜索和 beam搜索算法对生成最佳描述的影响。研究结果显示，特定的CNN架构可以显著提高生成的遥感图像描述的质量。", "conclusion": "这项研究通过详细比较多种编码器，提供了关于基于变换器的图像描述模型中编码器选择的宝贵见解。选择合适的编码器在提高描述性能中起着关键作用，验证了特定的CNN架构能显著提升遥感图像的生成描述质量。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.00545", "html_url": "https://arxiv.org/abs/2503.00545", "title": "RFWNet: 一种集成多尺度感受野和前景聚焦机制的轻量化遥感目标检测器", "title_en": "RFWNet: A Lightweight Remote Sensing Object Detector Integrating Multiscale Receptive Fields and Foreground Focus Mechanism", "authors": "Yujie Lei,Wenjie Sun,Sen Jia,Qingquan Li,Jie Zhang", "background": "遥感图像目标检测（RSOD）在处理具有高类别相似性、前景背景分布不平衡以及小尺寸目标等挑战时，其检测准确性受到了阻碍。此外，模型精度与计算复杂度之间的权衡也对RSOD算法的应用提出了额外限制。", "innovation": "提出了一种结合多尺度感受野和前景聚焦机制的高效轻量化RSOD算法，命名为鲁棒前景加权网络（RFWNet）。具体来说，设计了一个轻量级主干网络感受野自适应选择网络（RFASNet），利用遥感图像丰富的上下文信息增强类别可分辨性；开发了一个由背景冗余信息过滤模块（BRIFM）和前景信息增强模块（FIEM）组成的前景背景分离模块（FBSM），以突出图像中的关键区域并过滤掉冗余的背景信息；设计了一种加权CIoU-Wasserstein损失函数（LWCW），通过归一化的Wasserstein距离重新加权基于IoU的损失值，以缓解模型对小目标位置偏差的敏感性。", "conclusion": "实验结果表明，RFWNet在DOTA V1.0和NWPU VHR-10数据集上的平均精度（mAP）分别为95.3%和73.2%，参数量为6.0 M，并且推理速度达到52 FPS。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05549", "html_url": "https://arxiv.org/abs/2503.05549", "title": "Stereo Any Video: 时间一致的视差匹配", "title_en": "Stereo Any Video: Temporally Consistent Stereo Matching", "authors": "Junpeng Jing,Weixun Luo,Ye Mao,Krystian Mikolajczyk", "background": "本文介绍了一种强大的框架——Stereo Any Video，用于视频立体匹配。该方法能够在无需依赖摄像头姿态或光流等辅助信息的情况下，估计准确的空间和时间上一致的视差。其强大能力源于单目视频深度模型丰富的先验知识，并将卷积特征与之结合，从而生成稳定的表示。为了进一步提高性能，本文还提出了关键的架构创新：所有对所有对的关联以及时域凸上采样，从而增强时间一致性。这些组件共同保证了鲁棒性、准确性和时间一致性，确立了视频立体匹配的新标准。广泛的实验表明，在零样本设置下，本文方法在多个数据集上取得了最先进的性能，同时在真实世界室内外场景中具有强大的泛化能力。", "innovation": "本文提出了关键架构创新：所有对所有对的关联（all-to-all-pairs correlation），这是一种构建平滑和稳健的匹配成本体积的方法；以及时域凸上采样（temporal convex upsampling），这种技术可以提高时间的一致性。这些组件共同确保了鲁棒性、准确性和时间一致性，从而在视频立体匹配中取得了新标准。", "conclusion": "本文方法在零样本设置下，实现了多个数据集上的先进性能，并且在真实世界室内外场景中具有强大的泛化能力，确立了视频立体匹配的新标准。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.19707", "html_url": "https://arxiv.org/abs/2502.19707", "title": "基于高信心标签和高理性损失的甲状腺结节弱监督分割框架", "title_en": "Weakly Supervised Segmentation Framework for Thyroid Nodule Based on High-confidence Labels and High-rationality Losses", "authors": "Jianning Chi,Zelan Li,Geng Lin,MingYang Sun,Xiaosheng Yu", "background": "弱监督分割方法可以通过使用带有粗略标签的训练数据高效地识别超声图像中的甲状腺结节，但这些方法面临着两大挑战：1) 低置信度的伪标签，这些标签遵循拓扑先验，引入了显著的标签噪声；2) 低合理性的损失函数，这些函数严格比较分割结果与标签，忽略了结节形状多样且复杂所带来的区分信息。", "innovation": "本文提出了一种高置信度伪标签和高理性损失的弱监督超声图像分割框架来解决上述问题。具体创新点包括：1) 使用多项几何变换和基于特定注释的MedSAM模型结果生成高置信度的边界框、前景和背景标签；2) 高理性学习策略涵盖了对齐损失、对比损失和原型相关损失，分别用于引导网络感知结节位置、学习结节和背景特征分布以及细化可能产生结节边界不准确的区域", "conclusion": "实验结果表明，该方法在TN3K和DDTI数据集上取得了最先进的性能。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.03259", "html_url": "https://arxiv.org/abs/2503.03259", "title": "BANet: Bilateral Aggregation Network for Mobile Stereo Matching", "title_en": "BANet: Bilateral Aggregation Network for Mobile Stereo Matching", "authors": "Gangwei Xu,Jiaxin Liu,Xianqi Wang,Junda Cheng,Yong Deng,Jinliang Zang,Yurui Chen,Xin Yang", "background": "传统的 Stereo 匹配方法通常使用昂贵的 3D 卷积来聚合全成本体积，但其计算需求使移动部署变得具有挑战性。直接使用 2D 卷积进行成本聚合通常会导致边缘模糊、细节丢失以及无纹理区域的匹配不准确。一些复杂的操作，如可变形卷积和迭代扭曲，可以部分地缓解此问题；然而，它们不适用于移动设备，限制了它们在移动设备上的应用。", "innovation": "本论文提出了一种新的双边聚合网络（BANet），该网络仅使用 2D 卷积在移动设备上实现了高精度的 Stereo 匹配，同时保持了清晰的边缘和精细的细节。BANet 通过使用空间注意力图将全成本体积分离为详细的和光滑的体积，分别进行详细和光滑聚合，最后融合两者以获得最终的位移图。实验结果显示，BANet-2D 相较于其他移动友好型方法显著提高了准确性，并且在移动设备上具有更快的运行时间。BANet-2D 在 KITTI 2015 领导板上的精度比 MobileStereoNet-2D 高出了 35.3%。", "conclusion": "我们的 BANet 显著提升了移动设备上 Stereo 匹配的性能，同时保持了高精度和良好的细节保留能力，其结构和算法更适于移动设备，比其他移动友好型方法有明显优势。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.21817", "html_url": "https://arxiv.org/abs/2503.21817", "title": "Skip-Vision: 通过自适应的令牌跳过实现高效且可扩展的视觉-语言模型加速", "title_en": "Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping", "authors": "Weili Zeng,Ziyuan Huang,Kaixiang Ji,Yichao Yan", "background": "基于Transformer的模型在多模态大型语言模型（MLLMs）领域取得了显著进展，但随着分辨率、训练数据和模型参数的增加，计算成本急剧上升。视觉令牌的激增是造成这种计算成本上升的关键瓶颈之一。本文分析了视觉-语言模型在训练和推理过程中的效率问题，并探讨了解决这些问题的方法。", "innovation": "提出了一种名为Skip-Vision的统一框架，用于解决视觉-语言模型在训练和推理过程中的效率问题。该框架结合了传统的标记压缩方法，并引入了两种互补的加速策略。在训练加速方面，跳过了对视觉标记无意义的前向网络（FFN）运算，提出了Skip-FFN策略。在推理加速方面，设计了一种选择性的KV缓存移除机制，以保留模型性能的同时减少推理计算量和延迟。实验表明，Skip-Vision能够显著减少训练时间、计算量和延迟，同时保持或提高性能。", "conclusion": "本文为实现高性能MLLMs提供了高效的解决方案，通过增强的效率提升了模型的可扩展性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.21843", "html_url": "https://arxiv.org/abs/2503.21843", "title": "CMD-HAR: 跨模态去纠缠化可穿戴人体活动识别", "title_en": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition", "authors": "Hanyu Liu,Siyao Li,Ying Yu,Yixuan Jiang,Hang Xiao,Jingxi Long,Haotian Tang,Chao Li", "background": "人体活动识别（HAR）是多种以人为中心的智能应用的基础技术。尽管深度学习方法被用于加速特征提取，但多模态数据混合、活动异质性和复杂模型部署等问题仍然没有得到充分解决。本文旨在解决这些待解决问题，提出了一种时空注意模态分解对齐融合策略，通过跨模态时空去纠缠表示捕捉关键特征，并结合梯度调节以减轻数据异质性。此外，构建了一个可穿戴部署模拟系统，在大量公开数据集上进行了实验，验证了模型的有效性。", "innovation": "提出了一种时空注意模态分解对齐融合策略，通过跨模态时空去纠缠表示捕捉关键特征，并结合梯度调节以减轻数据异质性，构建了一个可穿戴部署模拟系统。", "conclusion": "通过实验表明，提出的模型在多公开数据集上具有有效性，在可穿戴设备的人体活动识别方面具有潜在应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12215", "html_url": "https://arxiv.org/abs/2504.12215", "title": "基于不确定性引导的逐步肿瘤分割与解剖意识后处理", "title_en": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing", "authors": "Ilkin Sevgi Isler,David Mohaisen,Curtis Lisle,Damla Turgut,Ulas Bagci", "background": "在胸腔计算机断层扫描（CT）中，可靠的肿瘤分割依然具有挑战性，原因在于边界模糊、类别不平衡以及解剖变异。现有方法难以准确区分和分割肿瘤，特别是在边界不清的区域。", "innovation": "本文提出了一种基于不确定性引导的逐步肿瘤分割框架，该框架结合了整个体积的肿瘤定位和细化的感兴趣区域（ROI）分割，通过解剖学意识的后处理进一步增强。该框架分为两阶段：第一阶段生成粗略预测并结合了解剖学信息进行过滤；第二阶段使用带有不确定性损失函数的模型精细分割结节区域，提高模糊区域的准确性和边界校准。实验结果显示，这种框架可以提高Dice和Hausdorff分数，减少假阳性，并增强空间可解释性。", "conclusion": "研究表明，将不确定性建模和解剖先验知识结合在级联分割管道中，可以实现更稳健且具有临床意义的肿瘤勾勒。在Orlando数据集中，该框架将Swin UNETR的Dice分数从0.4690提高到0.6447。结果表明，解剖导向的后处理显著减少了假阳性，证明了解剖学信息的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07813", "html_url": "https://arxiv.org/abs/2503.07813", "title": "MaizeField3D: 一组来自多样化品系的田间玉米3D点云和过程模型数据集", "title_en": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel", "authors": "Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian", "background": "由于缺乏大量且多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的工具在3D表型分析中，尤其是针对玉米的研究中受到了限制。2D图像数据集无法捕捉3D数据提供的关键结构细节，如叶片架构、植物体积和空间布局。因此，需要开发新的方法来改进这一现状，以推动农业研究的发展。", "innovation": "本文介绍了MaizeField3D，这是一个由多样化遗传面板中的田间生长的玉米植物3D点云组成的数据集，并且已经进行了AI准备。该数据集包括1,045个高质量的点云，这些点云是由陆基激光扫描仪（TLS）收集的。此外，利用图基分割方法对来自数据集的520个植物的点云进行了分割和注释，以确保所有样本的一致标签。模型还使用了非均匀有理B spline (NURBS)曲面表示叶片，采用渐变自由和渐变基础方法结合的两步优化过程来生成这些曲面。数据集还包括详细记录植物形态和质量的元数据以及多分辨率下采样的点云数据（100k, 50k, 10k 个点），方便不同的后续计算任务使用。", "conclusion": "MaizeField3D将成为人工智能驱动的表型分析、植物结构分析和农业研究中3D应用的全面基础数据集。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.02545", "html_url": "https://arxiv.org/abs/2504.02545", "title": "MAD: 使用跨域扩散模型的全能美妆", "title_en": "MAD: Makeup All-in-One with Cross-Domain Diffusion Model", "authors": "Bo-Kai Ruan,Hong-Han Shuai", "background": "现有的美妆技术通常需要设计多个模型来处理不同的输入，并在不同领域对特征进行对齐，以应对不同的美妆任务，例如美妆滤镜、美妆转移和美妆移除，导致了复杂性的增加。另一个限制是没有文本引导的美妆尝试，这样用户可以更加友好地使用，无需参考图像。本研究首次尝试使用单一模型来处理各种美妆任务。现有的方法依赖于单独的编码器-解码器配置或循环机制来实现这些任务，而我们提出使用不同的领域嵌入来促进领域控制，从而通过改变嵌入实现无缝的领域切换，减少了不同任务对额外模块的依赖。此外，为了支持精确的文本到美妆的应用，我们通过将MT数据集扩展为带有文本注释的MT-Text数据集来引入MT-Text数据集，提升了美妆技术的实际应用价值。", "innovation": "提出使用跨域扩散模型的单一模型，将不同的美妆任务形式化为跨域翻译，不同领域嵌入实现了无缝的领域切换，无需额外模块即可完成任务。引入了带有文本标注的MT-Text数据集，增强了美妆技术的实际应用性。", "conclusion": "该研究成功地将多种美妆任务整合到单一模型中，通过跨域扩散模型实现多样化的美妆任务，同时提出了文本到美妆的应用支持和新型数据集，提升了美妆技术的实用性和便捷性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12552", "html_url": "https://arxiv.org/abs/2504.12552", "title": "使用数字孪生体实现隐私保护的手术室工作流程分析", "title_en": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins", "authors": "Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath", "background": "手术室是一个复杂的环境，优化工作流程对于降低成本和改善患者结果至关重要。尽管计算机视觉方法可以自动识别围手术期事件并识别手术室优化的瓶颈，但隐私问题限制了使用手术室视频进行自动化事件检测。因此，需要一种既能保持隐私又能在手术室事件检测中有效的方法，进而提出了一种两阶段的隐私保护手术室视频分析流水线。", "innovation": "本文提出的创新之处在于：1) 利用视觉基础模型进行深度估计和语义分割，从传统RGB视频生成脱敏的数字孪生；2) 雇佣SafeOR模型，这是一种融合的双流方法，处理分割掩码和深度图以进行手术室事件检测；3) 通过使用数字孪生，实现隐私保护的手术室工作流程分析，促进了脱敏数据在机构间的共享，并可能通过减轻领域特定外观差异，增强模型的一般化能力。这些方法表明，数字孪生体可以在不影响隐私的情况下，与原始RGB视频模型具有可比甚至更好的手术室事件检测性能。", "conclusion": "基于数字孪生的方法能够在保持手术视频数据隐私的同时，有效进行手术室工作流程分析，并且能够将脱敏的数据在不同机构间共享，从而提高模型的一般化能力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12753", "html_url": "https://arxiv.org/abs/2504.12753", "title": "更强，更稳定且更优越：深度VFMs中的几何一致性在域泛化语义分割中的锻造", "title_en": "Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation", "authors": "Siyu Chen,Ting Han,Changshe Zhang,Xin Luo,Meiliu Wu,Guorong Cai,Jinhe Su", "background": "视觉基础模型（VFMs）在领域泛化语义分割（DGSS）中已经取得了显著的效果。然而，最近的方法经常忽视这样一个事实：视觉线索非常敏感，而基础几何结构是稳定的，使得深度信息更加稳健。因此，本文探讨了将深度信息与VFMs中的特征结合以提高图像内的几何一致性并增强VFMs的泛化性能的可能性。", "innovation": "提出了名为DepthForge的新型细调DGSS框架，该框架将冻结的DINOv2或EVA02的视觉线索和冻结的Depth Anything V2的深度线索集成在一起。在每个VFMs层中，引入了深度感知的学习性令牌来连续分离领域不变的视觉和空间信息，从而增强了深度意识和注意。此外，开发了一个深度精修解码器并将其整合到模型架构中，以适应性地细化多层VFM特征和深度感知学习性令牌。", "conclusion": "在多种DGSS设置和五个不同数据集上的大量实验表明，本文方法在定量和定性结果上都显著优于其他方法，具有更强的表现、更稳定的视觉-空间注意力和优越的泛化能力。特别是在极端条件下（如夜间和雪地），DepthForge表现出色。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23115", "html_url": "https://arxiv.org/abs/2505.23115", "title": "基于扩散模型的自主驾驶中3D占用预测", "title_en": "Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving", "authors": "Yunshen Wang,Yicheng Liu,Tianyuan Yuan,Yingshi Liang,Xiuyu Yang,Honggang Zhang,Hang Zhao", "background": "准确从视觉输入预测3D占用网格对于自主驾驶至关重要，但当前的判别方法在处理噪声数据、不完整的观测以及3D场景中复杂的结构时存在困难。", "innovation": "将3D占用预测重新定义为生成模型任务，利用扩散模型学习潜在的数据分布并结合3D场景先验，从而提高预测一致性、噪声鲁棒性，并更有效地处理3D空间结构的复杂性。这种方法在实验中表现出色，扩散基生成模型优于最新的判别方法，特别是在遮挡或低能见度区域提供了更真实和准确的占用预测，并显著改善了下游规划任务，突显了该方法在实际自主驾驶应用中的实用优势。", "conclusion": "扩散基生成模型在自主驾驶中的3D占用预测方面超越了最先进的判别方法，提供了更真实和准确的预测，并显著提高了下游规划任务的效果，进一步验证了其在实际场景中的应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.06002", "html_url": "https://arxiv.org/abs/2505.06002", "title": "Task-Adapter++：具有感知顺序对齐的任务特定适应方法用于少样本动作识别", "title_en": "Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition", "authors": "Congqi Cao,Peiheng Han,Yueran zhang,Yating Yu,Qinyi Lv,Lingtong Min,Yanning zhang", "background": "大规模预训练模型在语言和图像任务中取得了显著成功，推动了研究人员探索将预训练的图像模型，如CLIP，应用于少样本动作识别（FSAR）领域。然而，当前的方法通常面临几个问题：1) 直接微调往往降低了预训练模型的泛化能力；2) 在视觉任务中针对特定任务的信息探索不足；3) 通常忽视在文本建模中语义顺序信息；4) 存在的跨模态对齐技术忽略了多模态信息的时间耦合。", "innovation": "本文提出了一种参数效率高的双适应方法，Task-Adapter++，分别对图像编码器和文本编码器进行适应。具体地，设计了特定于任务的图像编码器适应，以便在特征提取过程中更好地注意到最具判别性的信息。通过大语言模型生成每个动作类的详细顺序子动作描述，并在文本编码器中引入语义序列表征，以有效建模这些子动作之间的顺序关系。此外，开发了一种创新的细粒度跨模态对齐策略，能够积极地将视觉特征映射到与语义描述相同的时间阶段。", "conclusion": "大量实验全面证明了所提出方法的有效性和优越性，该方法在5个基准上实现了迄今为止的最佳性能。源代码在此开放获取：this https URL."}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.19136", "html_url": "https://arxiv.org/abs/2504.19136", "title": "PAD: 频率感知的相位-振幅耦合解耦融合方法在多模态土地覆盖分类中的应用", "title_en": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification", "authors": "Huiling Zheng,Xian Zhong,Bin Liu,Yi Xiao,Bihan Wen,Xiaofeng Li", "background": "合成孔径雷达（SAR）和RGB图像在土地覆盖分类中的融合仍然具有挑战性，主要是由于模态差异性和未充分利用的光谱互补性。现有方法往往无法区分共享的结构特征和模态互补的辐射属性，导致特征冲突和信息丢失。", "innovation": "本文提出了相位-振幅解耦（PAD），这是一种频率感知的框架，能够在傅里叶域中分离相位（共享特征）和振幅（互补特征）成分，从而强化共享结构并保留互补特性，以提高融合质量。PAD是第一个引入显式相位-振幅解耦的多模态融合方法，不同于以往忽视频率谱中编码的独特物理性质的方法。PAD包括两个关键组件：1) 相位频谱校正（PSC），通过卷积引导的缩放对齐模态间相位特征，以增强几何一致性；2) 振幅频谱融合（ASF），使用频率自适应多层感知机动态整合高频和低频模式，利用SAR的形态敏感性和RGB的光谱丰富性。", "conclusion": "在WHU-OPT-SAR和DDHR-SK数据集上的大量实验证明了PAD的先进性能。我们的工作建立了物理感知的多模态融合在遥感中的新范式。相关代码将在此处提供：this https URL."}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09993", "html_url": "https://arxiv.org/abs/2506.09993", "title": "使用扩散模型的文本感知图像恢复", "title_en": "Text-Aware Image Restoration with Diffusion Models", "authors": "Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim", "background": "图像恢复的目标是恢复退化图像，现有的基于扩散的方法在自然图像恢复方面取得了巨大成功，但往往在重建退化图像中的文本区域时表现不佳。这些方法常常生成一些逼真但错误的文本样图案，我们称之为文本图像幻觉。", "innovation": "本文提出了文本感知图像恢复（TAIR），这是一种需要同时恢复视觉内容和文本保真的新型恢复任务。本文还提出了一种多任务扩散框架——TeReDiff，该框架将扩散模型的内部特征整合到文本识别模块中，使两个组件能够从联合训练中受益。这项工作允许提取丰富的文本表示，并在后续去噪步骤中作为提示使用。", "conclusion": "大量实验表明，我们的方法在文本识别准确性方面始终优于最先进的恢复方法，取得了显著的提升。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09612", "html_url": "https://arxiv.org/abs/2506.09612", "title": "一致的叙事生成与不对称菱形采样", "title_en": "Consistent Story Generation with Asymmetry Zigzag Sampling", "authors": "Mingxiao Li,Mang Ning,Marie-Francine Moens", "background": "文本到图像生成模型在生成高质量描述性图像方面取得了显著进展，但仍然在保持多幅图像中的主题一致性方面面临挑战。当前的方法要么通过在大规模故事可视化数据集上微调模型，这消耗大量资源，要么使用无需训练的技术共享生成信息，但这些方法仍然收效甚微。现有研究遇到的主要问题是，如何生成一致且连贯的视觉故事，特别是在多张图像中保持主体的一致性方面存在问题。", "innovation": "本文提出了一种新颖的无需训练的采样策略，称为菱形采样与不对称提示和视觉共享相结合的方法，以增强视觉故事生成中的主题一致性。该方法在交替使用不对称提示以保留主题特征的同时，通过视觉共享模块在生成的图像之间传递视觉提示，以进一步增强一致性。实验结果表明，该方法在生成连贯且一致的视觉故事方面显著优于现有方法。", "conclusion": "实验结果基于定量和定性的评估结果，证明了该方法在生成连贯且一致的视觉故事方面的优越性。该研究的代码可从此链接访问。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08601", "html_url": "https://arxiv.org/abs/2505.08601", "title": "使用物理驱动的深度学习重新组合碎片化古代竹简", "title_en": "Rejoining fragmented ancient bamboo slips with physics-driven deep learning", "authors": "Jinchi Zhu,Zhou Zhao,Hailong Lei,Xiaoguang Wang,Jialiang Lu,Jing Li,Qianqian Tang,Jiachen Shen,Gui-Song Xia,Bo Du,Yongchao Xu", "background": "竹简是东亚古代文明记录的重要载体，对于重建成丝绸之路、研究物质文化交流以及全球历史具有重要的考古学意义。然而，从地下发掘出的竹简常常被切割成数千个不规则的小块，这使得重新组合成为理解其内容的关键但具有挑战性的步骤。为了解决这一问题，提出了WisePanda，一种基于物理学原理的深度学习框架，用于重新组合竹简碎片。", "innovation": "WisePanda根据竹简裂纹和材料退化的物理学原理，自动生成捕捉竹简断裂物理特性的合成训练数据。这一方法使可以训练匹配网络而无需手动配对样本，提供排序建议来促进重新组合过程。与领先的曲线匹配方法相比，WisePanda在超过一千个候选碎片中将Top-50匹配准确率从36%提高到52%。考古学家使用WisePanda在重新组合碎片化竹简时体验到了显著的效率提升（大约20倍）。这项研究表明，将物理原理融入深度学习模型可以显著提升其性能，并且通过物理驱动的机器学习改变了考古学家修复和研究碎片化文物的方式。WisePanda为通过物理驱动的机器学习解决古代文物数据稀缺问题提供了新的范式", "conclusion": "通过物理驱动的深度学习技术，WisePanda为考古学家提供了重新组合碎片化竹简的强大工具。这种方法不仅提高了匹配准确率，还大大提高了修复过程的效率。这对于重建成丝绸之路和研究全球历史具有重要意义。将物理原理融入深度学习模型的创新方法为修复和研究碎片化古代文物提供了新的解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02453", "html_url": "https://arxiv.org/abs/2506.02453", "title": "PAID：持续测试时自适应中的成对角度不变分解", "title_en": "PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation", "authors": "Kunyu Wang,Xueyang Fu,Yuanfei Bao,Chengjie Ge,Chengzhi Cao,Wei Zhai,Zheng-Jun Zha", "background": "持续测试时自适应（CTTA）旨在在线适应预训练模型以适应变化的环境。现有方法主要关注利用目标数据，而忽视了另一种关键信息来源，即预训练权重，这些权重编码了未充分利用的领域不变先验知识。本文将预训练权重的几何属性作为起点，系统地分析了三个关键组件：幅度、绝对角度和成对角度结构。研究发现，成对角度结构在多种腐败领域中保持稳定，并编码了领域不变的语义信息，这表明在适应过程中应保留该结构。基于这一洞察，提出了一种先验驱动的CTTA方法PAID，该方法将权重分解为幅度和方向，并通过豪斯霍尔德反射引入可学习的正交矩阵以全局旋转方向，同时保持成对角度结构。在适应过程中，仅更新幅度和正交矩阵。PAID在四个常用CTTA基准上相对于最新的SOTA方法表现出了持续的改进，这表明保持成对角度结构提供了一种简单而有效的方法用于CTTA.", "innovation": "提出了PAID（Pairwise Angular-Invariant Decomposition）算法，该算法通过将权重分解为幅度和方向，并使用豪斯霍尔德反射引入可学习的正交矩阵以保持成对角度结构来实现持续测试时自适应（CTTA）。这个方法有效地利用了预训练权重中的角度结构，提出了一个新颖的先验驱动的自适应策略.", "conclusion": "PAID在四个广泛使用的CTTA基准上实现了相对于SOTA方法的持续改进，表明保持成对角度结构是CTTA中的一个简单而有效的原则。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22015", "html_url": "https://arxiv.org/abs/2506.22015", "title": "通过Exponential Torque修剪实现通用而高效的模型压缩", "title_en": "Towards Universal & Efficient Model Compression via Exponential Torque Pruning", "authors": "Sarthak Ketanbhai Modi,Zi Pong Lim,Shourya Kuchhal,Yushi Cao,Yupeng Cheng,Yon Shin Teo,Shang-Wei Lin,Zhiming Li", "background": "现代深度神经网络（DNN）的复杂性和规模迅速增长，导致计算成本和内存使用增加，促使对高效模型压缩技术的兴趣日益浓厚。尽管现有的先进方法提出了借鉴Torque灵感的正则化技术，强制神经模块的权重聚集在选定的枢轴点周围，但结果显示，这种方法的剪枝效果并不理想，剪枝后的网络仍然密集，且准确率下降较高。这归因于默认的线性力应用方案，它对不同距离的神经模块施加不适当的力。因此，本研究提出了一种Exponential Torque Pruning（ETP）方法，采用指数力应用方案，旨在高效地修剪冗余和远程模块，同时保留对于有效推理至关重要的模块。", "innovation": "提出了Exponential Torque Pruning（ETP）方法，该方法采用指数力应用方案进行正则化修复，以高效地修剪冗余和远程模块，同时保留对于有效推理至关重要的模块。与之前的先进修剪策略相比，ETP在保持几乎无精度下降的情况下实现了显著更高的压缩率。", "conclusion": "通过广泛领域的实验结果表明，ETP方法由于极其简单，在压缩率上显著优于之前的先进修剪策略，并且几乎不损失准确率。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.15854", "html_url": "https://arxiv.org/abs/2506.15854", "title": "通过视觉到文本转换实现智能网联汽车中的隐私保护", "title_en": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation", "authors": "Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy", "background": "智能网联汽车依赖一系列设备，其中道路旁的单位尤为关键，通过配备人工智能（AI）的相机进行违章检测等应用。然而，这些设备捕获的敏感图像数据引发了严重的隐私风险，如身份盗用、特征识别以及不正当商业用途。尽管已经应用遮罩和模糊化等传统技术来减轻隐私风险，但由于其他特征（如穿着）仍可追踪个体，因此个体隐私仍处于风险之中。本研究提出了一种新的隐私保护框架，基于反馈强化学习（Reinforcement Learning, RL）和视觉语言模型（Vision-Language Models, VLMs），将图像转换为语义等效的文字描述，从而保留与场景相关的信息同时保护视觉隐私。", "innovation": "该研究提出了一种全新的隐私保护框架，通过利用基于反馈的强化学习和视觉语言模型将图像转换为语义等效的文字描述，以保护AIE相机捕获的敏感视觉信息。研究采用了分层强化学习策略，逐步细化生成的文字描述，提高了语义准确性和隐私保护水平。与现有方法相比，该方法在隐私保护和文本质量上取得了显著改进，独特词汇数量增加了约77%，详细密度提高了约50%。", "conclusion": "研究通过视觉到文本的转换，显著提高了智能网联汽车中隐私保护的技术水平，通过语义描述保留了必要信息的同时有效保护了个人隐私。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "增强对抗转移性的语义结构感知生成攻击", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "生成对抗性攻击训练一个扰动生成器在白盒代理模型上，并随后将构造的扰动应用于看不见的黑盒受害模型。与迭代攻击相比，这些方法在推理时间效率、可扩展性和可移植性方面具有优势。然而，到目前为止，现有研究尚未充分利用生成模型的表征能力来保留和利用语义信息。具体来说，生成器的中间激活编码丰富的语义特征——对象边界和粗略形状——这些特征仍然被低估，导致扰动与对 adversarial 转移性至关重要的对象显著区域的对准不足。", "innovation": "本文提出了一种基于 Mean Teacher 的语义结构感知攻击框架，这是一种时间平滑特征参考。通过这种平滑的参考，进一步引导学生和富有语义信息的教师在早层数激活层之间的语义一致性，通过特征蒸馏。根据经验发现，将扰动合成锚定在生成器中与高语义显著性相关的早期中间块上，我们的方法指导渐进式对抗性扰动，从而在显著增强 adversarial 转移性方面发挥积极作用。本研究在不同模型、领域和任务中进行了全面实验，通过传统指标和新提出的偶然修正率 (ACR) 对其进行了全面评估，证明了相对于现有最佳生成性攻击的一致改进。", "conclusion": "基于 Mean Teacher 的语义结构感知攻击框架，通过特征蒸馏，进一步引导学生和富有语义信息的教师之间的语义一致性。该方法基于生成器中与高语义显著性相关的早期中间块，通过渐进式对抗性扰动，显著提高 adversarial 转移性，实验结果展示了相较于现有最佳生成性攻击的一致改进。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23897", "html_url": "https://arxiv.org/abs/2506.23897", "title": "PriOr-Flow:利用正交视图增强基本全景光流", "title_en": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View", "authors": "Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang", "background": "全景光流能够提供广泛视野范围内的全面时间动态理解。然而，由球面到平面的投影，如等角圆柱投影（ERP），导致了严重的失真，显著降低了基于透视的光流方法的性能，特别是在极地区域。", "innovation": "提出了一种新颖的双分支框架PriOr-Flow，利用正交视图的低失真特性提升这些区域的光流估计。引入了双成本协作查找（DCCL）运算符，联合检索来自原始和正交成本卷积的相关信息，有效减少了成本卷积构建过程中的失真噪声。此外，提出了正交驱动的失真补偿（ODDC）模块，从两个分支逐步细化运动特征，进一步抑制极地失真。", "conclusion": "广泛的实验表明，PriOr-Flow与各种基于透视的迭代光流方法兼容，并在公开可用的全景光流数据集上始终实现了最先进的性能，为广角运动估计设定了新基准。代码在以下地址公开: this https URL."}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23918", "html_url": "https://arxiv.org/abs/2506.23918", "title": "图像思维在多模态推理中的基础、方法和未来前沿", "title_en": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers", "authors": "Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R. Fung", "background": "近期，多模态推理的进展显著得益于文本链式思考（CoT），这是一种在语言中进行推理的范式。然而，该方法在文本中心的框架下将视觉视为静态的初始上下文，导致丰富的感知数据与离散的符号思维之间存在根本性的“语义差距”。人类认知能够超越语言，利用视觉作为动态的思维草图板。AI 正在经历类似的转变，从仅能思考图像的模型转变为能够真正用图像进行思考的模型，这一新兴范式的特点是模型利用视觉信息作为思维过程中的中间步骤，使视觉从被动输入转变为动态且可操作的认知工作区。", "innovation": "本文旨在通过三个关键阶段阐述智能认知演化的路径：从外部工具探索，到程序化操控，再到内在想象力的发展。通过对图像思维范式及其三个阶段框架的基础原则、核心方法、基准评测与应用分析等方面进行系统研究，本文贡献了四个关键方面：（1）建立了图像思维范式的基础原则及其三个阶段框架。（2）对通往该范式的道路各阶段的核心方法进行了全面回顾。（3）对评估基准和变革性应用进行了关键性分析。（4）识别了重要挑战并概述了有前景的未来方向。", "conclusion": "本文通过提供一个有条理的总体概述，旨在为未来的多模态AI研究提供一个清晰的研究路标，使其更具强大且与人类一致的特点。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22800", "html_url": "https://arxiv.org/abs/2506.22800", "title": "RGE-GS: 基于奖励引导的扩散先验扩展驾驶场景重建", "title_en": "RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors", "authors": "Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang", "background": "单次扫描往往无法完整重建道路结构，因此有效重建场景成为传感器模拟器有效再现驾驶行为的一个关键需求。尽管当前三维高斯点云（3DGS）技术能够实现高质量的重建，但直接将扩散先验整合到其中往往会导致累积的物理不一致，同时也会降低训练效率。现有的方法存在这些局限性，因此需要一种新的方法来解决这些问题，一种在重建过程中结合奖励引导和扩散生成的新框架变得至关重要，这里的奖励网络能够学习在重建前识别并优先处理一致生成的模式，进而使扩散输出的空间稳定性得以保留，同时通过自动调整高斯优化过程中的收敛指标，以实现更好的收敛效果，最后通过大量的公开数据集，证明RGE-GS能够达到顶级的重建效果，展示其优异性。", "innovation": "RGE-GS框架包含两大创新：首先，提出奖励网络提前学习识别并优先重建一致生成的模式，从而能选择性保留扩散输出，以确保空间稳定性；其次，在重建过程中，设计差异化的训练策略，根据场景收敛指标自动调整高斯优化进度，实现更好的收敛性能，相比基线方法表现出色。", "conclusion": "广泛的公开数据集评估表明，RGE-GS在重建质量方面达到了最先进的性能，其源代码会在不久后公开供下载。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X: 统一的空中-地面车辆对万物协作", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Fengze Yang,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "多车辆协作驾驶表现出明显优于单车辆自主驾驶的优势，但传统的基于基础设施的V2X系统在部署成本方面受到很大限制，并且在农村和郊区会出现未覆盖的危险区域。为了克服这些问题，本文提出了一种名为AirV2X-Perception的大规模数据集，利用无人机作为灵活的替代或补充基础设施，以路侧单元（RSU）的形式部署。空中的无人机感知能力提供了地面感知所无法比拟的优势：提供了有利于减少遮挡的鸟瞰视角、动态定位能力以实现悬停、巡逻和护航的驾驶规则，以及与固定基础设施相比显著降低了部署成本。", "innovation": "引入了AirV2X-Perception大规模数据集，利用无人机作为灵活的替代或补充基础设施，提供独特的空中视角和动态定位能力，解决了传统V2X系统在部署成本和未覆盖区域方面的限制问题。该数据集覆盖了城市、郊区和农村环境，并在多种天气和照明条件下进行了无人机辅助驾驶场景录制，旨在促进V2D算法的开发和标准化评估，填补了在无人机辅助自动驾驶系统领域的重要空白。", "conclusion": "本文通过提出AirV2X-Perception数据集，提供了一种空中和地面车辆之间的新型协作方式，该数据集有助于推动V2D算法的发展与评估，将进一步推动无人机辅助自动驾驶技术的进步。数据集和开发套件已开源，可供其他研究人员使用。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00981", "html_url": "https://arxiv.org/abs/2507.00981", "title": "使用程序化场景扰动评估单目深度估计的鲁棒性", "title_en": "Evaluating Robustness of Monocular Depth Estimation with Procedural Scene Perturbations", "authors": "Jack Nugent,Siyang Wu,Zeyu Ma,Beining Han,Meenal Parakh,Abhishek Joshi,Lingjie Mei,Alexander Raistrick,Xinyuan Li,Jia Deng", "background": "近年来，单目深度估计取得了显著进展，特别是在标准基准上的成功表现与大型模型的使用密切相关。然而，标准基准的评估主要集中在准确度上，缺少对鲁棒性的全面评估。尤其是在面对各种可控干扰（如物体、相机、材质和照明变化）时的模型表现缺乏系统性的研究。", "innovation": "本文提出了PDE（Procedural Depth Evaluation）新的基准测试，通过程序化生成方法创建3D场景，对其鲁棒性进行系统性评估。PDE能够测试模型在受到多种扰动时的表现，提供了评估鲁棒性的新方法。研究还揭示了当前最先进的深度模型在哪些类型的扰动下存在挑战，这对未来的研究具有指导意义。", "conclusion": "PDE基准测试为评估单目深度估计的鲁棒性提供了新工具，通过系统性地测试模型对各种干扰的响应，弥补了现有评估方法的不足。研究结果为今后研究指明了方向。该研究的代码和数据可在以下链接获取。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00505", "html_url": "https://arxiv.org/abs/2507.00505", "title": "LLaVA-SP：通过视觉空间令牌增强多模态大语言模型的视觉表示", "title_en": "LLaVA-SP: Enhancing Visual Representation with Visual Spatial Tokens for MLLMs", "authors": "Haoran Lou,Chunxiao Fan,Ziyan Liu,Yuexin Wu,Xinliang Wang", "background": "当前，大多数多模态大型语言模型（MLLMs）通过将基于 CLIP-ViT 的视觉编码器连接到大型语言模型来架构。CLIP-ViT 能够很好地捕捉全局图像特征，但难以处理相邻补丁之间的局部关系，导致视觉表示能力较弱，进而影响 MLLMs 对详细内容的理解能力。现有解决方案难以有效提升视觉理解的精度和细节处理能力。", "innovation": "本文提出了一种名为 LLaVA-SP 的新方法，通过仅添加六种空间视觉令牌来增强视觉表示。该方法包含三个关键优势：1) 提出了一种新颖的投影器，使用卷积核从 ViT 补丁特征中提取视觉空间令牌，模拟了两种视觉空间排序方式：从中心区域到全球和从抽象到具体；然后应用交叉注意力机制融合细粒度视觉信息，丰富整体视觉表示。2) 提出了两种模型变体：LLaVA-SP-Cropping 和 LLaVA-SP-Pooling，分别专注于通过渐进裁剪详述特征并捕捉通过自适应池化获得的全局语义，使模型能够处理各种视觉理解任务。3) 广泛的实验表明，使用 LoRA 微调后的 LLaVA-SP 在各种多模态基准上取得了显著的性能提升，多项任务中的性能接近甚至超过当前最先进的 LLaVA-1.5 模型，且推理时延几乎相同。", "conclusion": "LLaVA-SP 通过增强视觉表示，显著提升了多模态大语言模型的视觉理解能力，各个任务中的性能显著提升，且保持相近的推理时延，为未来的多模态大语言模型研究提供了新思路。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00585", "html_url": "https://arxiv.org/abs/2507.00585", "title": "相似性记忆先验是医学图像分割所需的一切", "title_en": "Similarity Memory Prior is All You Need for Medical Image Segmentation", "authors": "Tang Hao,Guo ZhiQing,Wang LieJun,Liu Chao", "background": "近年来，在猕猴初级视觉皮层（V1）中发现的“祖母细胞”可以直接识别复杂形状的视觉输入，这激发了研究人员探索这些细胞在医学图像分割研究中的价值。现有医学图像分割方法在提取类别特征时面临挑战，尤其是在识别细微的纹理变化方面。", "innovation": "本研究设计了一种用于医学图像分割的 Similarity Memory Prior Network (Sim-MPNet)。创新点包括：1. 提出了一种 Dynamic Memory Weights-Loss Attention (DMW-LA)，通过原型记忆银行中的相似性记忆先验匹配和记忆医疗图像中的特定病变或器官的类别特征，帮助网络学习类间细微的纹理变化；2. 通过 Weight-Loss Dynamic (W-LD) 更新策略动态更新相似性记忆先验，有效协助网络直接提取类别特征；3. 采用 Double-Similarity Global Internal Enhancement Module (DS-GIM)，结合余弦相似性和欧几里得距离深入探索输入数据中特征分布的内部差异。", "conclusion": "在四个公开数据集上的广泛实验表明，Sim-MPNet 在医学图像分割性能上优于其他最新方法。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00373", "html_url": "https://arxiv.org/abs/2507.00373", "title": "可定制的基于区域的兴趣深度图像压缩", "title_en": "Customizable ROI-Based Deep Image Compression", "authors": "Jian Jin,Fanxin Xia,Feng Ding,Xinfeng Zhang,Meiqin Liu,Yao Zhao,Weisi Lin,Lili Meng", "background": "传统的基于区域的兴趣（ROI）的图像压缩通过优先处理ROI以提高重建质量来优化比特分配。然而，随着用户需求的多样化，包括人类用户和下游机器任务，传统的ROI-based图像压缩需要变得更加个性化以满足不同用户的偏好。现有的ROI-based图像压缩方案预先定义ROI，使之不可更改，并缺乏有效机制在ROI和非ROI之间平衡重建质量。因此，本文提出了一种可定制的基于ROI的深度图像压缩方案，旨在解决ROI定义和掩码获取的定制化需求以及ROI和非ROI之间的重建质量权衡问题。", "innovation": "本文提出了以下创新点：1) 开发了文本控制掩码获取（TMA）模块，允许用户仅通过输入相应的语义文本来轻松定制压缩的ROI。这种机制使编码器受到文本控制。2) 设计了可定制值分配（CVA）机制，该机制允许用户决定非ROI部分的遮罩程度，而非使用固定的遮罩程度，以在ROI和非ROI之间管理重建质量权衡。3) 介绍了潜空间掩码注意（LMA）模块，该模块在潜空间中提取掩码的潜空域先验和图片的潜空间率失真优化先验，并进一步用于优化源图片的潜表示。", "conclusion": "实验结果表明，本文提出的可定制的基于ROI的深度图像压缩架构有效地解决了ROI定义和掩码获取的定制化需求以及ROI和非ROI之间的重建质量权衡管理问题。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01737", "html_url": "https://arxiv.org/abs/2507.01737", "title": "HOI-Dyn：学习人类-对象运动扩散中的交互动力学", "title_en": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion", "authors": "Lin Wu,Zhixiang Chen,Jianglin Lan", "background": "生成逼真的3D人体与物体间交互（HOIs）仍是一项具有挑战的任务，因为难以准确建模复杂的动力学互动。现有方法对人类和物体运动分别建模，导致物理上不合理且因果关系不一致的行为。为此，本文提出了一种新的方法HOI-Dyn，它将HOI生成视为一个驱动-响应系统，其中人类行为驱动物体响应。通过轻量级的基于变换器的动力学模型，明确定义了物体如何对人类运动做出反应。为了增强一致性，引入了一种基于残差的动力学损失，这可以减轻预测动力学错误的影响，并防止误导性的优化信号。该动力学模型仅用于训练，以保持推理效率。", "innovation": "提出了一种新的框架HOI-Dyn，将HOI生成视为一个驱动-响应系统，其中人类动作驱动物体响应，并使用轻量级的基于变换器的动力学模型来预测物体如何反应。此外，引入了一种基于残差的动力学损失，以增强一致性。该方法在训练过程中使用动力学模型，不影响推理性能。", "conclusion": "通过大量的定性和定量实验表明，该方法不仅提高了HOI生成的质量，还提供了一种评估生成交互质量的可行标准。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.04318", "html_url": "https://arxiv.org/abs/2408.04318", "title": "基于深度迁移学习的肾癌诊断", "title_en": "Deep Transfer Learning for Kidney Cancer Diagnosis", "authors": "Yassine Habchi,Hamza Kheddar,Yassine Himeur,Mohamed Chahine Ghanem,Abdelkrim Boukabou,Shadi Atalla,Wathiq Mansoor,Hussain Al-Ahmad", "background": "不可治愈的疾病对全球医疗保健系统构成了重大挑战，其流行率受生活方式、经济、社会和遗传因素的影响。在这些因素中，肾脏疾病仍然是全球一个关键的公共卫生问题，需要持续研究以提高早期诊断和治疗。近年来，深度学习（DL）在医学成像和诊断方面展示出潜力，推动了自动肾癌（KC）检测的显著进展。然而，DL模型的成功高度依赖于高质量、特定领域的数据集，而这些数据集往往稀缺且获取昂贵。此外，DL模型需要大量计算能力和存储空间，限制了其在临床环境中的应用。为克服这些障碍，迁移学习（TL）作为一种有效的方法已经出现，通过利用相关领域的预训练模型来增强KC诊断效果。", "innovation": "本文系统地回顾了基于深度迁移学习的KC检测框架，总结了关键方法、优点和限制，并分析了其实际性能。此外，还讨论了迁移学习在医学成像中的挑战，并展望了未来的研究趋势。本文强调了迁移学习在精确医疗中的变革作用，尤其是肿瘤学领域，通过提高诊断准确性、降低计算需求和支持AI工具在医疗保健中的集成。", "conclusion": "本文的研究成果为研究人员和从业者提供了宝贵指导，铺平了未来KC诊断和个性化治疗策略的发展道路。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01909", "html_url": "https://arxiv.org/abs/2507.01909", "title": "模态无关的患者特异性模拟动态消化运动的数字孪生", "title_en": "Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion", "authors": "Jorge Tapias Gomez,Nishant Nadkarni,Lando S. Bosma,Jue Jiang,Ergys D. Subashi,William P. Segars,James M. Balter,Mert R Sabuncu,Neelam Tyagi,Harini Veeraraghavan", "background": "在临床实现可变形图像配准（DIR）时，需要基于体素的空间准确性度量，如手动识别的解剖标志点，但对高度移动的消化道（GI）器官来说，这具有挑战性。为解决这个问题，研究人员创建了基于患者特性的数字孪生（DT），以评估DIR方法的准确性。生成了21个模拟消化GI运动的运动相位作为4D序列，从静态3D患者扫描中使用已发表的胃肠道运动模型通过半自动管道生成。这些DT的运动幅度被评估为与独立4D MRI数据集中提取的真实患者胃运动幅度相似。使用定向注册误差、Dice相似系数和95th百分位海德霍夫距离等度量标准评估了六个不同DIR方法的性能，包括体素级的详细可视化。对于MR引导放射治疗的患者T2w MRI扫描子集，剂量分布被扭曲和累积，以评估剂量扭曲误差，包括低剂量区域和高剂量区域的DIR性能评估，以进行患者特异性的误差估计。", "innovation": "该研究提出了一个合成DT以模拟现实的GI运动的管道，实现了在低毫米和0.01范围内接近已发表的真实患者胃运动数据的平均和最大运动幅度。此研究使能够提取详细的定量DIR性能指标并对剂量映射准确性进行严格验证。管道能够严格测试动态的、解剖复杂区域的DIR工具，以获得精细的空间和剂量准确性。", "conclusion": "此研究的管道使得能够严格测试动态的、解剖复杂区域的DIR工具，能够提供精细的空间和剂量准确性。从而确保临床实施可变形图像配准工具的可靠性，特别是在处理高度移动的消化器官时。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.03977", "html_url": "https://arxiv.org/abs/2409.03977", "title": "通过双向离散过程匹配方法实现双模态医学图像合成", "title_en": "Bi-modality medical images synthesis by a bi-directional discrete process matching method", "authors": "Zhe Xiong,Qiaoqiao Ding,Xiaoqun Zhang", "background": "近年来，生成模型的迅速发展导致医学图像合成越来越受到关注。医学图像合成的目标是从观测到的数据模态生成未获得的图像模态，合成图像可以用于临床诊断辅助、模型训练和验证数据扩充或图像质量提升。流形基模型是成功率较高的生成模型之一，因为它们能够生成逼真且高质量的合成图像。但大多数流形基模型在合成过程中需要计算大量时间迭代的ODE演化步骤，导致性能受到大量计算时间的限制。", "innovation": "本文提出了一种新型流形基模型，称为双向离散过程匹配（Bi-DPM），用于实现双模态图像合成任务。与其他基于流匹配的模型不同，本文提出利用正向和反向ODE流，并在少数几个离散时间步骤中增强中间图像的一致性，从而在配对数据的指导下，在保持高质量生成的同时，使双模态图像合成过程保持高质量生成。", "conclusion": "我们在包括MRI T1/T2和CT/MRI在内的三个数据集上进行了实验，结果表明，Bi-DPM比其他现有的流形基方法在双模态图像合成中性能更优，生成的图像质量更高，并且具有准确的解剖区域。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.07079", "html_url": "https://arxiv.org/abs/2408.07079", "title": "脑MRI的解剖基础模型", "title_en": "Anatomical Foundation Models for Brain MRIs", "authors": "Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto", "background": "深度学习（DL）在神经影像学中的应用越来越重要，特别是在检测神经退行性疾病方面。脑年龄是神经影像学中的一个主要生物标志物，已被证明是不同类型状况（如阿尔茨海默病）的良好指标。最近的研究表明，在数据稀缺的情况下，使用脑年龄对DL模型进行弱监督预训练在转移学习设置中有很强的潜力。此外，脑MRI的解剖信息（如皮层厚度）可以提供有关学习有效表示的重要信息，这些表示可以应用于许多下游任务。然而，目前缺乏有效的解剖模型来综合利用脑MRI的解剖信息以改进下游任务的表现。", "innovation": "本文提出了一个名为AnatCL的解剖基础模型，该模型在弱对比学习方法中利用解剖信息，并实现了多种不同下游任务的最先进性能。此外，通过集成解剖信息进行预训练，AnatCL能够产生更稳健和通用的学习表示，从而改进了下游任务的表现。", "conclusion": "我们验证了我们的方法，选择了12个不同的下游任务来诊断不同的状况（如阿尔茨海默病、自闭症谱系障碍和精神分裂症），并且我们还通过使用结构性MRI数据预测了10种不同的临床评估得分。研究发现，在预训练过程中整合解剖信息可以显著提高下游任务的表现。预训练模型已发布。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.16765", "html_url": "https://arxiv.org/abs/2411.16765", "title": "SHuBERT：通过多流聚类预测实现自监督手语表示学习", "title_en": "SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction", "authors": "Shester Gueuwou,Xiaodan Du,Greg Shakhnarovich,Karen Livescu,Alexander H. Liu", "background": "手语处理一直依赖于特定任务的模型，限制了跨任务迁移学习的潜力。手语预训练方法通常集中在监督预训练上，无法利用未标记数据，或者独立于上下文（帧或视频片段）的表示，这些方法忽略了手语中时间相关关系的影响。", "innovation": "SHuBERT（Sign Hidden-Unit BERT）是一种自我监督的上下文表示模型，从大约1000小时的美国手语视频中学习。SHuBERT将被预测目标掩蔽预测目标设置应用于多流视觉手语输入，学习预测多个对应于聚类手、面部和身体姿态流的目标。SHuBERT在手语翻译、孤立手语识别和手指书写检测等任务中达到了最新的技术水平。", "conclusion": "SHuBERT通过多流聚类预测实现了自监督手语表示学习，展现了在多种任务中超越现有技术水平的能力。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.08777", "html_url": "https://arxiv.org/abs/2411.08777", "title": "LUDO: 利用点云占用函数实现可变形物体的低延迟理解", "title_en": "LUDO: Low-Latency Understanding of Deformable Objects using Point Cloud Occupancy Functions", "authors": "Pit Henrich,Franziska Mathis-Ullrich,Paul Maria Scheikl", "background": "在需要精确瞄准的医疗任务中，准确确定可变形物体的形状及其内部结构位置至关重要，例如机器人活检。现有的方法往往难以在低延迟的情况下完成这一任务。LUDO 方法在此背景下应运而生，它能够通过单一视图点云观察在30毫秒内重建可变形物体及其内部结构，并提供了预测的不确定性估计和可解释性，这对于诸如手术等关键应用尤为重要。", "innovation": "LUDO 利用占用网络从单一视角点云观测中准确且快速地重建可变形物体及其内部结构，处理时间低于30毫秒。它还提供了预测不确定性和可解释性，通过高亮输入观察中的关键特征实现。与流行的基线方法相比，LUDO 在 ROI 定位精度、训练时间和内存需求方面都更胜一筹。此外，LUDO 显示了无需变形注册方法即可与可变形物体交互的潜力。", "conclusion": "我们在真实世界的机器人实验中评估了 LUDO，取得了98.9%的成功率，验证了在机器人活检中对各种感兴趣区域 (ROIs) 进行穿刺的有效性。通过将 LUDO 与流行的基准线进行比较，我们展示了其优越的 ROI 定位准确性、更快的训练时间和更低的内存需求。LUDO展示了无需使用变形注册方法即可实现与可变形物体交互的前景。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.01391", "html_url": "https://arxiv.org/abs/2502.01391", "title": "基于生成模型的实时观测交通异常学习", "title_en": "Learning Traffic Anomalies from Generative Models on Real-Time Observations", "authors": "Fotis I. Giasemis,Alexandros Sopasakis", "background": "准确检测交通异常对于有效的城市交通管理和缓解交通拥堵至关重要。为了捕捉交通数据中的复杂时空依赖关系，研究团队采用了将图神经网络与长短期记忆网络相结合的时空生成对抗网络（STGAN）框架。该研究利用2020年几个月在瑞典哥德堡的42个交通摄像头实时分钟级观测数据进行分析，将图像处理后的流量指标输入模型进行训练和验证。结果显示，该模型能有效检测交通异常，具有高精度和低误报率的特点，检测到的异常包括摄像头信号中断、视觉伪影和极端天气对交通流的影响等现象。", "innovation": "该研究提出了一种结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，用于捕捉交通数据中的复杂时空依赖关系，并应用于哥德堡地区的实时交通摄像头观测数据，解决了传统方法在处理复杂交通场景中的不足，提高了交通异常检测的准确性与实时性。", "conclusion": "研究结果表明，该模型能够有效检测交通异常，具有较高的检测精度和较低的误报率。检测到的交通异常包括摄像头信号中断、视觉噪声及极端天气条件对交通流的影响等。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05802", "html_url": "https://arxiv.org/abs/2503.05802", "title": "使用 Wasserstein 距离方法进行照明和光照方向估计", "title_en": "Illuminant and light direction estimation using Wasserstein distance method", "authors": "Selcuk Yazar", "background": "在图像处理中，尤其是在机器人领域，可靠的环境感知对于多变的光照条件至关重要。传统的方法如RGB直方图和GIST描述符在复杂场景中容易受到光照变化的影响而失败", "innovation": "本文提出了一种新颖的方法，利用最优传输理论中的Wasserstein距离来估计图像中的照明和光照方向。该方法在多种场景下（室内场景、黑白照片和夜景图像）都展示了其有效性，并在复杂照明环境中优于传统统计方法。此外，该方法对光源定位、图像质量评估和目标检测增强具有潜在的应用价值", "conclusion": "未来的研究可能探索自适应阈值和梯度分析以进一步提高准确性，为实际应用中的光照挑战提供可扩展的解决方案"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.00420", "html_url": "https://arxiv.org/abs/2412.00420", "title": "TAROT: 基于最优传输的靶向数据选择", "title_en": "TAROT: Targeted Data Selection via Optimal Transport", "authors": "Lan Feng,Fan Nie,Yuejiang Liu,Alexandre Alahi", "background": "以往的靶向数据选择方法主要依赖于基于影响的贪婪启发式策略来提高领域特定性能。在简单且单一模式的数据上，这些方法表现有效。然而，随着目标数据复杂性的增加，这些方法在多模式分布上的表现逐渐变差。具体来说，这些启发式方法无法适应多内在模式，导致数据选择的次优结果。两个主要原因分别在于（i）高维影响估计中占主导地位的特征成分的不成比例影响，以及（ii）贪婪选择策略中隐含的线性加性假设限制较多。这些挑战导致了现有的方法难以应对复杂数据样本。", "innovation": "本文提出了TAROT框架，这是第一个将最优传输理论应用于靶向数据选择的方法。TAROT通过引入去中心化的特征距离来减轻主导特征偏差，提供了一个更为可靠的数据影响度量。该框架进一步使用去中心化的特征距离来量化和最小化所选数据与目标领域的最优传输距离。这一最小化过程也促进了最优选择比例的估计。实验结果表明，在多种任务（包括语义分割、运动预测和指令调优）上，TAROT优于最先进的方法，显示出它的多样性及适用性。", "conclusion": "TAROT通过最优传输距离的最小化和去中心化特征距离的应用提升了目标数据选择的效能，在不同深度学习任务上表现出色，验证了其在多种场景下的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.12073", "html_url": "https://arxiv.org/abs/2501.12073", "title": "使用轻型机舱下方机器人无人机进行自主光谱测量森林资源调查", "title_en": "Towards autonomous photogrammetric forest inventory using a lightweight under-canopy robotic drone", "authors": "Väinö Karjalainen,Niko Koivumäki,Teemu Hakala,Jesse Muhojoki,Eric Hyyppä,Anand George,Juha Suomalainen,Eija Honkavaara", "background": "无人机在林业中的应用越来越广泛，主要用于采集高分辨率遥感数据，以支持监测、评估和决策过程。尽管可以在树冠上方进行自动化操作，但在森林内部飞行仍然具有挑战性，主要依赖于手动操作。在密林中，全球导航卫星系统（GNSS）导航不可行，无人机需要自主调整飞行路径以避免碰撞。近年来，机器人技术的进步使得在全球导航卫星系统无信号且障碍物丰富的环境中实现自主无人机飞行成为可能。本文旨在通过构建一种轻型机舱下方机器人无人机的原型，为自主森林数据采集迈出一步，并验证在森林内部收集数据的性能。具体来说，该研究重点关注基于摄像头的树冠下方自主飞行以及低成本机载双目摄像头收集的数据的光谱处理。", "innovation": "本文通过结合最先进的开源方法，开发了一种轻型机舱下方的机器人无人机原型。该原型成功实现了树木参数（如胸径）的估计，特别是在密林环境中。研究中的DBH估计结果显示，所有树木的均方根误差（RMSE）为3.33厘米（12.79%），对于胸径小于30厘米的树木，RMSE仅为1.16厘米（5.74%）。这些结果为自主机舱下方森林制图提供了重要见解，突显了轻型机器人无人机系统在复杂森林环境制图方面的关键下一步发展。", "conclusion": "本文的研究结果显示，轻型机舱下方的机器人无人机在密林环境中工作时表现出色，能够自主完成飞行任务并收集数据。通过光谱处理，这些数据可以用于生成高精度的森林3D模型。研究结果为自主机舱下方森林制图提供了有价值的信息，并表明了未来轻型机器人无人机系统在复杂的森林环境制图中的关键发展方向。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.08589", "html_url": "https://arxiv.org/abs/2412.08589", "title": "SPACE-SUIT: 一种基于人工智能的日冕特征提取和分类器", "title_en": "SPACE-SUIT: An Artificial Intelligence Based Chromospheric Feature Extractor and Classifier for SUIT", "authors": "Pranava Seth,Vishal Upendran,Megha Anand,Janmejoy Sarkar,Soumya Roy,Priyadarshan Chaki,Pratyay Chowdhury,Borishan Ghosh,Durgesh Tripathi", "background": "太空太阳紫外线成像望远镜（SUIT）搭载在Aditya-L1探测器上，用于观测太阳光球层和色球层。为了更好地理解色球层和光球层的质子和热力学特性，需要进行大样本的统计研究，这需要开发自动特征检测方法。研究表明，使用YOLO这样的神经网络模型可以有效识别这些特征区域。研究团队使用了接口区域成像光谱仪（IRIS）全盘镶嵌图像中的Mg II k线来开发模拟SUIT图像，用于SPACE-SUIT算法的训练和验证，同时也在SUIT的原始级数据上进行了检测实验，通过统计学测量和Tamura特征对检测结果进行了校验，并对比了熵、对比度、不相似性和能量这些特征的分布差异，发现这些差异可以通过SPACE-SUIT算法检测到的区域来可视化，即使没有标注的真实数据也得到了验证。这项研究不仅开发了一种用于色球层特征提取和分类的算法，还证明了统计学指标和Tamura特征对于区分色球层特征的有效性，为未来的研究提供了支持。", "innovation": "开发了一种新的自动特征检测算法SPACE-SUIT，采用YOLO神经网络模型来识别色球层特征，特别是针对日珥、黑子、条纹和背日结构。通过使用模拟SUIT图像和实际SUIT数据进行训练和验证，证明了该算法的有效性，并开发了独立验证机制，通过统计学测量和Tamura特征分析来验证检测结果，为日球特征检测提供了新的方法和工具。", "conclusion": "开发了SPACET-SUIT算法来检测和分类日球层特征，实现了良好的精度和召回率，并通过统计学分析验证了算法的准确性。这不仅证明了人工神经网络在天文图像分析中的有效性，还展示了统计学和Tamura特征的应用潜力，为未来的太阳物理研究和发展新的检测方案提供了支持。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15057", "html_url": "https://arxiv.org/abs/2505.15057", "title": "通过粗细分辨扩散模型进行MRI重建中的非刚性运动校正", "title_en": "Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models", "authors": "Frederic Wang,Jonathan I. Tamir", "background": "磁共振成像（MRI）因需要较长的采样时间而极易产生运动伪影。这类伪影会降低诊断的有效性，特别是在动态成像过程中。目前的难点在于如何同时重建和纠正因非刚性运动受损的k-space数据，尤其是在每个运动状态采样不足64倍的情况下。", "innovation": "本文提出了一种新颖的交替最小化框架，结合了定制的扩散模型，用于同时重构和校正非刚性运动受损的k-space数据。扩散模型采用了从粗到细的去噪策略，能够捕捉较大的整体运动，并优先重建图像的低频部分，这对于运动估计具有更好的引导偏置，优于标准的扩散模型。该方法在实际的心脏MRI数据集和复杂模拟刚性及非刚性变形中均表现良好，即使在每个运动状态低采样64倍的情况下也能有效工作。", "conclusion": "该方法对于各种运动状态、采样模式、解剖变异和MRI成像协议均具有鲁棒性，只要在每个运动状态下采样一些低频成分即可。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17046", "html_url": "https://arxiv.org/abs/2503.17046", "title": "HAPI：一种从人类偏好学习机器人面部表情的模型", "title_en": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences", "authors": "Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida", "background": "自动机器人面部表情生成对于人机交互至关重要。尽管基于固定关节配置的手工方法往往产生僵硬且不自然的行为，最近的自动化技术虽然减少了手动调参的需求，但在实现人机偏好和模型预测之间的良好衔接方面仍不足。这导致了表情的细腻度和真实性不足，主要是由于自由度有限和感知整合不够充分。因此，本文提出了一种新颖的学习排序框架，利用人类反馈来解决上述差距，并增强机器人的表情表达能力。该研究通过成对比较标注来收集人类偏好数据，并开发了基于Siamese RankNet的人类情感成对印象（HAPI）模型，用于细化表情评估。基于贝叶斯优化和在线表情调查的结果，该研究证实了HAPI方法在Android平台上生成了比基线和专家设计方法更加真实和在社会上更具共鸣性的愤怒、快乐和惊讶表情，从而证实了该框架在其预测和人类情感反应之间建立了有效桥梁，并且能够稳健地将机器人表情生成与人类情感响应对齐。", "innovation": "提出了一种新的学习排序框架，利用人类反馈来解决自动机器人面部表情生成中存在的顺畅性和表现力不足的问题。该研究通过成对比较的方式收集人类偏好数据，并开发了基于Siamese RankNet的人类情感成对印象（HAPI）模型，用于改进表情评估，从而增加了机器人表情的细腻度和真实性。", "conclusion": "HAPI方法在Android平台上生成的愤怒、快乐和惊讶表情比基线和专家设计方法更加真实和在社会上更具共鸣性，证实了此框架在预测和实现人类情感反应之间的有效桥梁，同时也稳健地将机器人表情生成与人类情感响应对齐。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06231", "html_url": "https://arxiv.org/abs/2506.06231", "title": "迈向可解释的特征嵌入比较与对齐", "title_en": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "authors": "Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia", "background": "尽管文献中已经开发了多种特征嵌入模型，但这些嵌入的比较主要集中在它们在分类下游应用中的数值性能上。然而，为了进行可解释的比较，需要识别和分析嵌入空间中聚类样本组之间的差异。为此研究提出了一种名为Spectral Pairwise Embedding Comparison（SPEC）的框架，用于比较不同嵌入模型在聚类参考数据集方面的差异。", "innovation": "该研究提出的SPEC框架通过比较两个嵌入模型衍生的内核矩阵，并利用差分内核矩阵的特征分解来检测由两种嵌入模型不同的样本簇。还提出了一种基于该框架的优化问题，以确保一个嵌入模型中识别的簇也能在另一个模型中被捕获。此外，这种方法具有线性的时间复杂度，使其适用于大规模数据集。该结果证明了SPEC在实践中应用的可能性，特别是在ImageNet和MS-COCO等大型数据集上的表现。", "conclusion": "SPEC框架能够从可解释的角度比较和对齐特征嵌入，提供了更深入的理解不同嵌入方法的差异，同时也保证了聚类结果的一致性。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17089", "html_url": "https://arxiv.org/abs/2503.17089", "title": "理解引导的公平CMR分割偏见缓解", "title_en": "Understanding-informed Bias Mitigation for Fair CMR Segmentation", "authors": "Tiarna Lee,Esther Puyol-Antón,Bram Ruijsink,Pier-Giorgio Masci,Louise Keehn,Phil Chowienczyk,Emily Haseler,Miaojing Shi,Andrew P. King", "background": "近年来，人工智能（AI）在医学影像任务中的应用逐渐增多。然而，AI模型可能因不平衡的训练数据集而存在偏见，这种偏见在心脏磁共振（CMR）图像分割模型中尤为显著。尽管这一现象已在若干研究中有所报道，但关于偏见缓解算法在这一领域的有效性仍知之甚少。本文旨在探讨常见的偏见缓解方法以解决基于AI的CMR分割模型中黑人和白人之间的偏见问题。研究人员使用了过采样、重要性重新加权和Group DRO，以及这些技术的联合应用来缓解种族偏见。此外，基于近期有关AI基CMR分割偏见的根本原因的研究发现，研究人员还评估了在使用裁剪后的CMR图像训练和评估的模型上的同一方法的效果。研究结果发现，过采样可以缓解偏见，显著提升少数群体黑人受试者的性能，而不会显著降低主流群体白人受试者的性能。使用裁剪图像可以提高两族群的表现并减少偏见，而将过采样作为偏见缓解技术与裁剪图像一起使用可进一步减少偏见。当在外部临床验证集测试模型时，研究结果显示分割性能很高且没有统计意义上的显著偏见。", "innovation": "1. 研究人员通过使用过采样、重要性重新加权和Group DRO，以及这些技术的联合应用来缓解基于AI的心脏磁共振（CMR）图像分割模型中的种族偏见。2. 研究基于近期有关AI基CMR分割偏见的根本原因的研究发现，评估了使用裁剪后的CMR图像训练和评估的模型上的同一方法的效果，进一步增加了研究的创新性。", "conclusion": "通过过采样和裁剪CMR图像的结合使用，可以有效地缓解这些模型中的种族偏见，提高少数群体的性能，同时保持主要群体的性能。在外部临床验证集上的测试还显示了高分割性能且不存在统计意义上的显著偏见。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨语言旅行：评估多模态大型语言模型的跨语言一致性", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "多模态大型语言模型（MLLMs）的快速发展极大地提高了它们在现实世界中的应用，但实现不同语言之间的一致性能，特别是在整合文化知识方面的表现，仍是一个显著的挑战。为此，研究引入了两个新的基准测试：KnowRecall和VisRecall，用于评估MLLMs的跨语言一致性。KnowRecall是一个针对视觉问答的基准测试，旨在测量15种语言中的事实知识一致性，重点是关于全球知名地标的文化和历史问题。VisRecall则通过要求模型在不使用图像的情况下描述9种语言中的地标外貌，评估视觉记忆的一致性。实验结果显示，最先进的MLLMs，包括专有的模型，仍然难以实现跨语言一致，这表明需要更稳健的方法来生成真正多语言且文化意识强的模型。", "innovation": "引入了两个新的基准测试：KnowRecall和VisRecall，来评估MLLMs在不同文化认知方面的跨语言一致性问题；知召回（KnowRecall）专注于测量15种语言中的事实知识一致性，特别是关于全球知名地标的文化和历史问题；VisRecall通过要求模型在没有图像的情况下描述地标外貌来评估视觉记忆的一致性；实验结果显示即使是最先进的MLLMs也难以实现跨语言一致性，强调了需要更稳健的方法来生成真正多语言且文化意识强的模型。", "conclusion": "实验结果表明，最先进的MLLMs，包括专有的模型，仍然难以实现跨语言一致性，这强调了需要更稳健的方法来生成真正多语言且文化意识强的模型。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12479", "html_url": "https://arxiv.org/abs/2506.12479", "title": "AI Flow：视角、场景与方法", "title_en": "AI Flow: Perspectives, Scenarios, and Approaches", "authors": "Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li", "background": "信息论的奠基人克拉夫特·香农和机器智能的先见之明框架的创造者阿兰·图灵的开创性工作，促成了信息技术（IT）和通信技术（CT）的协同进化，形成了持续的连接与计算浪潮。这种协同作用引发了技术革命，如今正处于高峰，通过大规模的人工智能（AI）模型重新塑造各个行业，重新定义人机协作。然而，无处不在的智能实现面临巨大挑战，包括大规模模型的高资源消耗和高通信带宽需求。", "innovation": "AI Flow 引入了一个多学科框架，整合了最新的IT和CT进展，重点关注三个关键点：首先，设备-边缘-云框架奠定了基础，通过集成末端设备、边缘服务器和云集群来优化低延迟模型推理的可扩展性和效率；其次，引入了家族模型的概念，指一系列具有对齐隐藏特征的不同大小的模型，实现有效协作并具有适应不同资源约束和动态场景的灵活性；第三，基于连接与互动的智能涌现是AI Flow的一个新的范式，通过利用通信网络来增强连接，实现异构节点上的智能模型之间的协作，从而实现超越任何单个模型的涌现智能能力。", "conclusion": "AI Flow 提供了增强的智能、及时的响应能力和无处不在的AI服务的可访问性，为AI技巧和通信系统的更紧密融合铺平了道路。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21714", "html_url": "https://arxiv.org/abs/2506.21714", "title": "ODEₜ(ODEₗ): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "title_en": "ODE$_t$(ODE$_l$): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "authors": "Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer", "background": "近年来，连续规范化流程（CNFs）和扩散模型（DMs）已经被统一的理论框架下研究。尽管这些模型可以从噪声分布生成高质量的数据点，但是采样过程需要多次迭代求解常微分方程（ODE），并且计算复杂度高。现有研究主要集中在减少采样过程中的时间步骤数量，以提高效率。本文则探索了一个不同的方向，在时间和长度上动态控制质量-复杂度权衡。", "innovation": "通过在基于变压器的架构中重连块，以解决相关长度的内部离散化 ODE，本文实现了一个可以任意设置时间步骤和变压器块数量的方法。本文采用时间一致性和长度一致性的损失函数训练流匹配，最终可以在任意时间步数和变压器块数量下进行采样。本文的方法在时间维度上是求解器无关的，同时降低了延迟和内存使用。相对于之前的最先进技术，在最高效的采样模式下，实验结果显示出3倍的延迟减少和高达3.5分的FID分数改善。", "conclusion": "本文通过在时间和长度上进行创新，使得基于向量空间模型在生成图像时效率大幅提升，同时确保生成图像的质量。并且，本文已经发布了所有用于实现和复现实验的代码和模型权重。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00660", "html_url": "https://arxiv.org/abs/2507.00660", "title": "MTCNet: 4D超声心动图中基于运动和拓扑一致性的左室瓣膜分割学习", "title_en": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound", "authors": "Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni", "background": "二尖瓣反流是最常见的心脏疾病之一。四维（4D）超声成为评估动态瓣膜形态的主要成像方式，但传统的4D左室瓣膜（MV）分析因其缺乏相位间依赖性、严重运动伪影和图像质量差而面临挑战。MTCNet提出了一种解决方案，通过指导一致性网络结合运动学和拓扑学信息，实现4D超声心动图中左室瓣膜分割的精确定位。该方法在大规模的真实数据集上（包含160名患者，1408个相位）进行了验证，显示出优越的跨相一致性（Dice：87.30%，HD：1.75mm）.", "innovation": "MTCNet的主要创新点在于提出了一种运动-拓扑引导的一致性网络（MTCNet），该网络利用向前和向后方向的注意记忆银行传播时空特征，设计了基于运动的跨相一致性学习策略和基于拓扑的关联正则化，以维持解剖上合理的结构对应关系。相比于现有的先进方法，MTCNet在交叉相一致性方面表现更优，特别适用于半监督学习（SSL）环境下的4D MV分割任务，仅需少量的舒张末期和收缩末期标注即可实现高效学习.", "conclusion": "MTCNet在1408个4D MV相位数据上的实验结果表明，该网络在交叉相一致性方面表现优于其他先进方法， Dice系数达87.30%，平均 Hausdorff距离为1.75毫米。此外，该研究还提供了代码和数据集，以促进进一步的研究和应用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01975", "html_url": "https://arxiv.org/abs/2507.01975", "title": "可学习可微分的有限体积求解器用于加速流体模拟", "title_en": "Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows", "authors": "Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun", "background": "流体流动的模拟对于气象学、空气动力学和生物医学等领域非常重要。传统数值解算器通常需要精细的时间和空间网格以满足稳定、一致性和收敛条件，这导致了巨大的计算成本。尽管机器学习在效率方面表现更好，但由于可解释性、普适性和数据依赖性的问题，其应用受到了限制。因此，本文提出了一种可学习的可微分的有限体积求解器（LDSolver），旨在在粗网格上高效且准确地模拟流体流动。", "innovation": "LDSolver 包含两个关键组件：1) 可微分的有限体积求解器；2) 可学习模块，它在粗网格上提供等效的流体交换（导数和插值）模型以及时间误差校正。即使只有少量训练数据（例如，只有一两条轨迹），我们的模型也能加速模拟并保持高精度和优越的普适性。实验表明，LDSolver 在多种流体系统（例如，Burgers 流、衰减流、强迫流和剪切流）中实现了最先进的性能，显著超越了基线模型。", "conclusion": "实验结果表明，LDSolver 在不同流体系统中表现出色，能加速模拟并保持高精度和普适性，超越了基线模型。"}
{"llm_update_time": "20250707", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01201", "html_url": "https://arxiv.org/abs/2507.01201", "title": "逃出柏拉图的洞穴：JAM框架用于对齐独立训练的视觉和语言模型", "title_en": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "authors": "Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim", "background": "独立训练的视觉和语言模型各自处于不同的表示空间中，这些空间由各自模态、目标和架构所塑造。然而，一种新兴假说——柏拉图式表现假设——表明，此类模型即使有所不同，也可能朝向共享的现实统计模型收敛。如果这种兼容性存在，那么一个根本性的问题是：我们能否从后验统计对齐检测转向显式优化，以便在这些独立的空间中实现对齐？", "innovation": "作者将柏拉图式对齐问题视为一个多目标优化任务，目标是在保持各模态内在结构的同时，实现相互的连贯性。为了解决这一问题，作者提出了一个名为联合自动编码器调制器（JAM）的框架，利用预训练单一模态模型的潜在表示来联合训练模态特定的自动编码器，通过重构和跨模态目标促进对齐。这一框架旨在帮助从不同输入中生成共享结构，类似于‘逃出柏拉图的洞穴’的比喻。作者通过三种关键设计轴来评估此框架的有效性：对齐目标、最有效的对齐层深度以及基础模型规模对表示收敛的影响。\n", "conclusion": "研究发现，作者提出的轻量级Pareto有效框架能够可靠地促进对齐，甚至在冻结和独立训练的表示之间也能实现对齐，提供了一种理论洞察和实际路径，用于将通用的单模态基础模型转换为专家型多模态模型。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01982", "html_url": "https://arxiv.org/abs/2507.01982", "title": "DKGCM: 基于空间节点聚类方法和傅里叶双向Mamba机制融合的时空交通流量预测模型", "title_en": "DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism", "authors": "Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai", "background": "准确的交通需求预测能够使交通管理部门更有效地分配资源，提高资源利用率。然而，交通系统中的复杂时空关系仍然限制了需求预测模型的表现。为改善时空交通需求预测准确度，提出了新的图卷积网络结构DKGCM。该结构首先考虑不同交通节点的时空分布，提出了一种新型基于时间相似度的聚类图卷积方法DK-GCN，利用动态时间规整（DTW）和K均值聚类来分组交通节点，更好地捕捉时空依赖关系。在时间尺度上，通过Fast Fourier Transform (FFT)融合在双向Mamba深度学习框架中，来捕捉交通需求的时间依赖性。", "innovation": "提出了一个新的图卷积网络结构DKGCM，包含两个主要创新点：1) 基于DTW和K-means聚类的时空依赖性增强的时空节点聚类图卷积方法DK-GCN，以及2) 在双向Mamba框架中集成FFT捕捉时空依赖性，进一步通过GRPO强化学习策略优化模型训练机制，从而显著提高预测准确性。", "conclusion": "广泛的实验表明，DKGCM模型在多个公共数据集上优于多种先进方法，实现了强预测结果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01998", "html_url": "https://arxiv.org/abs/2507.01998", "title": "保留正区域的随机采样：大规模数据高效特征选择方法", "title_en": "Positive region preserved random sampling: an efficient feature selection method for massive data", "authors": "Hexiang Bai,Deyu Li,Jiye Liang,Yanhui Zhai", "background": "智能机器在处理大量数据时往往缺乏足够的计算资源。因此，选择相关特征成为提升智能机器成功率的重要步骤。为解决大规模数据的特征选择挑战，该论文提出了一种基于采样技术和粗糙集理论的新方法。方法通过计算可区分对象对的比例来衡量特征集的区分能力，并在此基础上提出了一种新的特征选择方法。该方法从大规模数据中构建特征保留的正区域样本，以找到高区分能力的特征子集。", "innovation": "1. 提出了一种高效的大规模数据特征选择方法，能够在个人计算机上接受的时间内选择保留大量数据特征区分能力的特征子集；\n2. 在选择特征子集之前，能够估计所选特征子集在所有需区分的对象对中能够被鉴别的对象对的概率下界；\n3. 通过11个不同规模的数据集验证了该方法的有效性，并在四个大规模数据集上取得了高区分能力的近似约简。", "conclusion": "该方法能够在合理的时间内找到具有高区分能力的近似约简，该近似约简的区分能力大于估计的概率下界。这一方法为大规模数据的特征选择提供了新的有效途径。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01984", "html_url": "https://arxiv.org/abs/2507.01984", "title": "使用语言、视觉和社会特征早期融合检测多重模态虚假信息", "title_en": "Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features", "authors": "Gautam Kishore Shahi", "background": "在选举和危机期间，社交媒体上虚假信息的泛滥已经引起了广泛关注，现有研究主要集中在基于文本或图像的方法上，但很少有研究探索多模态特征组合。本文探讨了使用早期融合方法，结合文本、图像和社会特征的分类模型在检测虚假信息方面的有效性。该研究分析了1529条疫情期间（包括COVID-19和选举期）的包含文本和图像的推特数据，通过数据增强技术提取了额外的视觉和社会特征，结果显示，结合无监督和监督机器学习模型比单模态模型提高了15%的分类性能，比双模态模型提高了5%。此外，该研究还分析了根据虚假信息推文的特征及其传播者的特点来进行虚假信息传播模式分析的方法", "innovation": "结合了语言、视觉和社会特征的早期融合方法，在虚假信息检测中取得了显著效果，具体表现在通过结合无监督和监督机器学习模型提高了分类精度，特别突出了这种多模态特征组合的应用价值", "conclusion": "该研究证明了多模态特征组合在虚假信息检测中的有效性，并通过早期融合方法展示了其在提高分类性能方面的优势。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02001", "html_url": "https://arxiv.org/abs/2507.02001", "title": "Temporal Chain of Thought: 长视频理解通过帧上的思考", "title_en": "Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames", "authors": "Anurag Arnab,Ahmet Iscen,Mathilde Caron,Alireza Fathi,Cordelia Schmid", "background": "尽管在视觉-语言模型（VLMs）方面取得了近期进展，但长视频理解仍然是一个具有挑战性的问题。尽管最先进的长上下文VLMs能够处理约1000帧的输入，但它们仍然难以有效地利用这个序列长度，并且容易受到上下文窗口中的无关干扰的影响。", "innovation": "我们提出了一种新的视频问答推理策略——时间链式思维（Temporal Chain of Thought），该策略整理模型的输入上下文。这种方法使用VLM本身进行迭代地识别和提取最相关的视频帧，然后用于回答问题。我们展示了在推理时加大计算量以选择最相关的上下文可提高准确性，这与最近有关大型语言模型推理时可扩展性的研究一致。此外，该方法在4个不同的视频问答数据集上取得了最先进的结果，展示了在3种不同的VLM上的一致改进。特别地，该方法在超过1小时的长视频上表现尤为突出，在LVBench数据集上，使用32K上下文窗口的方法比使用标准700K上下文窗口的方法提高了2.8个点的准确性。", "conclusion": "通过时间链式思维策略，我们可以在长视频理解中有效利用更多视频帧，提高模型的准确性和对长视频的适应性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02085", "html_url": "https://arxiv.org/abs/2507.02085", "title": "GeoAda: 使用等变适配器高效微调几何扩散模型", "title_en": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters", "authors": "Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon", "background": "几何扩散模型在分子动力学和结构生成方面表现出显著的成功。然而，如何高效地微调这些模型以适应具有不同几何控制要求的下游任务尚未得到充分探索。", "innovation": "该论文提出了一种SE(3)-等变适配器框架（GeoAda），能够在不修改原始模型架构的情况下，实现灵活且参数高效的微调，特别适用于可控生成任务。GeoAda引入了一种结构化的适配器设计，通过耦合操作编码控制信号，然后通过可训练的预训练模型层进行处理，最后通过解耦操作和等变零初始化卷积将其投影回。理论证明表明，所提出的适配器保持了SE(3)-等变性，确保在适应过程中保持预训练扩散模型的几何诱导偏置。实验结果表明，GeoAda在不同几何控制类型的广泛应用程序领域中表现出色，能够实现最优的微调性能，同时保留原始任务的准确性，而其他基线方法则由于过拟合和灾难性遗忘而性能显著下降。", "conclusion": "GeoAda通过细调少量轻量级的适配器模块，在保持模型几何一致性的基础上，有效地解决了灾难性遗忘和过拟合的问题，适用于不同类型的几何控制和多种应用领域。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02006", "html_url": "https://arxiv.org/abs/2507.02006", "title": "AIRES：通过算法-系统协同设计加速离线GCNs", "title_en": "AIRES: Accelerating Out-of-Core GCNs via Algorithm-System Co-Design", "authors": "Shakya Jayakody,Youpeng Zhao,Jun Wang", "background": "图卷积网络（GCNs）在许多科学应用中至关重要，涵盖了生物医学蛋白质-蛋白质相互作用（PPI）到大规模推荐系统。在实现GCNs时，对图结构建模的基石是稀疏广义矩阵乘法（SpGEMM）。由于资源受限系统中GPU内存空间有限，随着图数据规模的不断扩大，SpGEMM通常以离线方式进行。尽管最近有一些努力尝试通过GPU特征缓存、CPU-GPU混合内存布局，或在稀疏格式下进行计算来缓解离线SpGEMM的内存限制问题，但是当前系统仍然面临I/O延迟高和GPU利用率低的问题。", "innovation": "本文首先指出了现有系统的缺点，即稀疏格式数据对齐和内存分配是主要的性能瓶颈。本文提出了一种名为AIRES的新型算法-系统协同设计解决方案，以加速GCNs中的离线SpGEMM计算。在算法层面，AIRES在矩阵稀疏格式下提出了解决数据对齐问题的方法，并开发了一种标记算法以促进行块对齐。在系统层面，AIRES采用了一种基于多阶段动态调度的三阶段方法，利用分层内存系统及双路数据传输策略，整合了GPU内存、GPU Direct Storage (GDS) 和主机内存，从而降低了I/O延迟并提高了吞吐量。评估结果显示，AIRES在实际图处理基准测试中的性能显著优于现有最好方法，实现了高达1.8倍的延迟降低。", "conclusion": "AIRES有效解决了现有方法中存在的问题，实现了对离线SpGEMM计算的加速，显著提升了GCNs在实际图处理任务中的性能。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01999", "html_url": "https://arxiv.org/abs/2507.01999", "title": "采用连续小波变换和Siamese网络的多变量半导体工序时间序列异常检测", "title_en": "Continuous Wavelet Transform and Siamese Network-Based Anomaly Detection in Multi-variate Semiconductor Process Time Series", "authors": "Bappaditya Dey,Daniel Sorensen,Minjin Hwang,Sandip Halder", "background": "半导体制造是一个极其复杂的工艺过程，涉及到成千上万个相互关联的参数，分布在多种工具和工艺步骤中。多变量时间序列分析(MTS)方法对于这种环境的实时监控、故障检测和预测性维护至关重要。但在半导体制造中预测异常则面临多个关键挑战，包括数据的高维度、严重的类别不平衡、噪声和缺失数据，以及生产系统的非平稳行为。此外，变量之间的复杂依赖关系和故障在下游过程中的延迟浮现使得异常检测和根本原因分析更加困难。", "innovation": "本文提出了一种新颖且通用的基于机器学习的方法来检测多变量时间序列数据中的异常。该方法包括三个主要步骤：a)使用连续小波变换将MTS数据转换为图像表示，b)通过在自定义连续小波变换图像数据集上微调预训练的VGG-16架构来构建一个多类图像分类器，c)构建一个由两个完全相同的子网络组成的Siamese网络，每个子网络以微调后的VGG-16作为主干网络。该网络接受一组CWT图像作为输入，一个作为参考或锚点（代表已知正确的信号），另一个作为查询（代表未知的信号），模型通过比较两个输入的嵌入来确定它们是否在给定的时间步属于同一类别。这种方法在实际晶圆厂处理时间序列数据集上表现出高准确率，为过程和工具轨迹数据的离线异常检测提供了一个具有前景的解决方案，并且该方法具有灵活性，可以在监督和半监督设置中应用。", "conclusion": "该方法在真实的半导体制造过程时间序列数据集上展现了高精度的异常检测能力，提供了一种用于过程和工具轨迹数据离线异常检测的有希望的解决方案。此外，该方法灵活且适用于监督和半监督环境中。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02089", "html_url": "https://arxiv.org/abs/2507.02089", "title": "基于生成模型的线性约束MDP的采样复杂性界", "title_en": "Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model", "authors": "Xingtu Liu,Lin F. Yang,Sharan Vaswani", "background": "研究了无限 horizon 下的 γ 折扣（线性）约束马尔可夫决策过程（CMDP），目标是在满足预计累积约束的情况下最大化预期累计奖励。利用生成模型，提出了一种基于对偶法的框架，该框架可以利用任何黑盒无约束 MDP 求解器。对于特征维度为 d 的线性 CMDP，本文通过使用镜像下降价值迭代（MDVI）实例化该框架，该方法作为一种 MDP 求解器的示例。提供了两种情况下 CMDP 算法的采样复杂性界：（i）放松可行性，允许较小的约束违反；（ii）严格可行性，输出策略必须完全满足约束。", "innovation": "提出了一个基于对偶法的框架，该框架利用任何黑盒无约束 MDP 求解器来解决带约束的 MDP。通过实例化镜像下降价值迭代（MDVI）解决了线性 CMDP，提供了在两种约束可行性情况下的采样复杂性界。证明了在放松可行性的条件下，该算法可以用 $\tilde{O}\frac{d^2}{(1-\beta)^4\beta^2}$ 样本来以高概率返回一个 $\beta$-最优策略。在严格可行性的条件下，证明了该算法需要 $\tilde{O}\frac{d^2}{(1-\beta)^6\beta^2\theta^2}$ 样本。", "conclusion": "该框架应用于表型 CMDP 并显示了在该设置下可以恢复近似最优的采样复杂性，展示了方法的有效性和理论保证。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02119", "html_url": "https://arxiv.org/abs/2507.02119", "title": "计算最优训练的神经网络中缩放塌缩揭示了通用动力学", "title_en": "Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks", "authors": "Shikai Qiu,Lechao Xiao,Andrew Gordon Wilson,Jeffrey Pennington,Atish Agarwala", "background": "探讨了随着模型规模和训练时间共同增长时，神经网络训练动力学受到哪些缩放极限的支配。研究表明，尽管架构、训练算法和数据之间的复杂交互，计算最优训练模型展现出了高度精确的普遍性。无论模型大小如何变化，当训练计算和损失在训练结束时归一化为1时，损失曲线相互重叠。", "innovation": "发现了“超塌缩”现象，即便在不同的学习率调度、数据集和架构下，归一化后的损失曲线也能紧密重叠，在不同随机种子的损失曲线下限噪声水平以下。这种现象的产生可以通过连接缩放塌缩到典型的神经网络缩放定律的幂律结构来解释，并通过一个简单而有效的SGD噪声模型准确预测损失曲线和定量解释超塌缩的起源。", "conclusion": "“超塌缩”现象作为良好缩放的精确和实际指标，可以判断模型是否按照最优参数进行缩放。通过归一化的损失曲线观察损失动力学，提供了一种理解最优训练模型的通用动态的方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02109", "html_url": "https://arxiv.org/abs/2507.02109", "title": "基于主动学习的参数化神经放大器建模", "title_en": "Parametric Neural Amp Modeling with Active Learning", "authors": "Florian Grötschla,Luca A. Lanzendörfer,Longxiang Jiao,Roger Wattenhofer", "background": "研究了一种用于训练端到端参数化吉他放大器模型的新框架，该模型采用类似于WaveNet的结构。传统的吉他放大器模型训练通常需要大量的数据点（即放大器旋钮设置的样本），这在实际操作中可能非常耗时且成本高昂。通过采用主动学习策略，可以有效减少所需的数据点数量，同时保持模型的性能。这种方法在有限的样本数量下能够提高模型的优化效果，从而简化了模型训练的过程，以及提高了训练效率和模型的泛化能力。", "innovation": "提出了一个新的主动学习框架PANAMA，用于训练参数化吉他放大器模型。该框架能够通过录制根据主动学习策略确定的样本来创建虚拟放大器，只需最少的数据点数量即可。此外，该研究展示了基于梯度的优化算法如何确定最优的数据点以进行采样，从而实现更为高效的模型训练过程。这一方法特别适用于在样本受限的情况下，提升模型性能和优化效果。", "conclusion": "总体而言，使用PANAMA框架可以有效地利用主动学习的方式，简化和提升了参数化吉他放大器模型的训练过程，特别是在样本量有限的情况下，能够显著提高优化算法的效果，并使得模型训练更为高效。这种方法不仅简化了训练流程，还提升了模型的泛化能力，在实际应用中具有重要的意义。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02087", "html_url": "https://arxiv.org/abs/2507.02087", "title": "评估大规模语言模型在招聘决策中的希望与局限", "title_en": "Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions", "authors": "Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia", "background": "使用大规模语言模型（LLMs）在招聘中的应用旨在简化候选人筛选流程，但同时也引发了关于准确性和算法偏差的问题，尤其是在缺乏充分防护措施的情况下。这项研究针对多种最先进的基础LLM进行了基准测试，并将其与专用于招聘领域的自定义模型（Match Score）进行了比较。研究者评估了这些模型在预测准确性和公平性方面的表现，发现定制化的Match Score模型在预测准确性方面优于通用的LLM，并且其结果在不同人口学组间的公平性显著更高。特别是，Match Score在种族公平性方面达到了最小影响比0.957（接近平等），而最好的LLM们仅能达到0.906或更低。该研究还探讨了预训练偏差如何可能导致LLMs在招聘场景中传播社会偏见，而自定义的监督模型则能更有效地缓解这些偏见。研究指出，在高风险领域如招聘中部署AI时，需要重视特定领域的建模和偏见审核，并警告不要在没有广泛公平保障措施的情况下依赖于现货LLM。实证证据还表明，在招聘中高准确性和公平性之间不应被视为二元对立的选择：精心设计的算法可以同时实现招聘准确性和公平的结果。", "innovation": "这项研究创新之处在于，它通过专题模型（如Match Score）与通用大型语言模型进行了对比，评估了这些模型在招聘中的预测准确性和公平性表现。研究发现，定制化模型在公平性和准确性方面表现优于通用模型，并通过实验证明了在招聘过程中可以通过设计实现高准确性和公平性的同时兼顾。此外，研究还讨论了预训练偏见的问题以及自定义监督模型能如何有效缓解这些偏见。", "conclusion": "研究结果强调了在高风险领域如招聘中部署AI的重要性，尤其是在公平性和准确性的双重需求下，需要进行特定领域的模型建模和偏见审计。研究指出不应仅依赖通用LLM进行此类任务，而应在广泛采用前采取充分的公平性保障措施。此外，研究提供了实证证据表明，良好的设计可以使招聘过程同时具备高准确性和公平性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "Energy-Based Transformers是可扩展的学习者和思考者", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "近年来，与人类系统2思考类似的推理时计算技术因其提高模型性能而变得流行。然而，大多数现有方法存在限制：它们局限于特定模态（如仅适用于文本）、特定问题域（如可验证的数学和编码领域），或需要额外的监督/训练（如验证者或可验证的奖励）在无监督预训练的基础上。本文研究了如何通过无监督学习使这些系统2思考的方法进行泛化，进而开发能够仅从无监督学习中学会思考的模型。作者发现，通过学习明确验证输入和候选预测之间的兼容性，然后将预测问题重新定义为对这个验证器的优化，这是可能的。", "innovation": "本文提出了一种新的基于能量的模型（Energy-Based Models，EBMs）—能量基于的变换器（Energy-Based Transformers，EBTs），用于对输入和候选预测的每对赋予能量值，使预测通过基于梯度下降的能量最小化得到优化。实验表明，EBTs在训练过程中比主导的Transformer++方法更快地规模扩展，且在推理时，EBTs在语言任务上的性能比Transformer++提高了29%，同时在图像去噪任务上使用更少的前向传递而优于扩散变换器，且在大部分下游任务中，相较于其他模型使用相同的或更差的预训练性能时，EBTs能够实现更好的结果，表明EBTs比现有方法有更好的泛化能力。因此，EBTs为扩展模型的学习和思考能力提供了新的范式。", "conclusion": "EBTs作为一种新的基于能量的模型，能够从无监督学习中进行训练，从而实现更高的规模扩展性与更强的泛化能力，尤其是在预测任务上能够表现出色，并且在下游任务中也能够达到或超越现有模型的表现，提供了新型的模型规模扩展和思考的能力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02225", "html_url": "https://arxiv.org/abs/2507.02225", "title": "度量设计 != 度量行为：改进维度缩减评估中的度量选择以实现无偏评估", "title_en": "Metric Design != Metric Behavior: Improving Metric Selection for the Unbiased Evaluation of Dimensionality Reduction", "authors": "Jiyeon Bae,Hyeon Jeon,Jinwook Seo", "background": "评估降维（DR）投影在保留高维数据结构方面的准确性对于可靠的数据可视化至关重要。多种针对不同结构特征的评估指标已经开发出来。然而，如果选择了高度相关的度量（那些测量相似结构特征的度量），则评估可能会出现偏差，从而倾向于强调这些特征的DR技术。", "innovation": "本文提出了一种新的工作流，通过基于度量的实际相关性进行聚类，而不是仅基于预期的设计特征，来减少度量选择中的偏差。该工作流使用成对相关性计算度量相似性，聚类度量以最小化重叠，并从每个聚类中选择一个代表度量。定量实验表明，该方法提高了DR评估的稳定性，表明该工作流有助于减轻评估偏差。", "conclusion": "本文提出的工作流通过减少选择偏差，改善了维度缩减评估的稳定性，从而对数据分析和可视化领域的无偏评估做出了贡献。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02151", "html_url": "https://arxiv.org/abs/2507.02151", "title": "非互换性校准预测用于时序图神经网络", "title_en": "Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks", "authors": "Tuo Wang,Jian Kang,Yujun Yan,Adithya Kulkarni,Dawei Zhou", "background": "现有的针对图神经网络（GNNs）的校准预测方法主要关注静态图，忽略了现实世界中图结构、节点属性和真实标签随时间变化的动态性质。这违反了标准校准预测方法的基本可交换性假设，限制了它们在时序图中的应用。这项研究旨在解决这一问题，提供了NCPNET，一种针对时序图的新颖全量端校准预测框架，通过扩散非一致性度量分数来捕捉拓扑和时间不确定性，同时开发了一个确保高效性的优化算法，来改善校准预测过程并降低覆盖偏差。在多种时序图上的实证实验展示了NCPNET的可靠性和效率，相较于现有方法，它可以将预测集大小减少31%，显著提升了效率。", "innovation": "提出了一种针对时序图的新颖全量端校准预测框架NCPNET，通过扩散非一致性度量分数来应对拓扑和时间不确定性，同时设计了一个高效优化算法，提升了计算效率。实验表明，NCPNET能够确保时序图中预测的准确性，并将预测集大小显著减少，提高效率.", "conclusion": "NCPNET提供了一种有效的解决时序图中存在的统计覆盖偏差的方法，并在多种实际数据集上验证了其性能，相比现有最先进的方法，能够显著降低预测集的大小，从而提高效率。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02129", "html_url": "https://arxiv.org/abs/2507.02129", "title": "生成潜空间扩散以实现高效的时空数据压缩", "title_en": "Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction", "authors": "Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka", "background": "生成模型在条件设置中有很强的表现力，可以被视为一种数据压缩的手段，其中条件作为紧凑的表示方式。然而，这些模型的控制能力和重建准确性有限，限制了它们在数据压缩中的应用。现有方法大多依赖于逐帧存储潜空间表示，从而增加了存储成本。本研究针对这一问题，提出了一种有效潜空间扩散框架，通过将变分自编码器与条件扩散模型相结合，仅对少量关键帧进行压缩，并利用它们作为条件输入用于通过生成性插值重建其余帧，从而消除了对每一帧存储潜空间表示的需求，实现时空重建的同时显著降低存储成本。", "innovation": "本研究提出了一种结合变分自编码器与条件扩散模型的高效潜空间扩散框架。该方法仅对少量关键帧进行压缩并将其存储在潜空间中，然后通过生成性插值重建剩余帧，从而避免了对每一帧都存储潜空间表示的需求。这种方法不仅能实现精确的时空重建，还能显著减少存储成本。实验结果显示，本方法在多个数据集上实现了比规则基线方法如SZ3更高的10倍压缩比，并且在相同的重建误差下，性能优于先进的学习方法，高出63个百分点。", "conclusion": "本研究提出的方法实现了时空数据的有效压缩，通过生成性插值显著降低存储需求。实验结果表明，该方法在多个数据集上表现出色，实现了高达10倍的压缩比，并且在相同的重建误差下，性能优于现有的学习方法和规则基线方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02128", "html_url": "https://arxiv.org/abs/2507.02128", "title": "CROP: 使用大规模语言模型进行电路检索与参数指导优化", "title_en": "CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs", "authors": "Jingyu Pan,Isaac Jacobson,Zheng Zhao,Tung-Chieh Chen,Guanglei Zhou,Chen-Chia Chang,Vineet Rashingkar,Yiran Chen", "background": "现代大规模集成（VLSI）设计要求使用电子设计自动化（EDA）工具来实现集成电路。由于EDA算法的复杂性，广泛的参数空间对芯片设计优化提出了巨大挑战，即使是中量级参数组合也会创建一个庞大的解空间。手动选择参数仍然是工业实践，但由于工作量过大且受到专家经验限制，这种方法受限。为了解决这个问题，我们提出了CROP，这是一种首批由大规模语言模型（LLM）支持的自动VLSI设计流程调优框架。该框架包括：(1) 一种可扩展的从RTL源代码转换为密集向量表示的方法，(2) 一种基于嵌入的检索系统，用于匹配设计与语义上相似的电路，以及(3) 一种基于检索增强生成（RAG）和LLM引导的参数搜索系统，该系统通过类似设计的先验知识来约束搜索过程。实验结果表明，与现有方法相比，CROP能够在一个工业设计中实现更高质量的结果，并在较少的迭代次数内减少了9.9%的功耗。", "innovation": "CROP作为一种自动调优框架，利用了大规模语言模型（LLM）的优势，通过将RTL代码转换为密集向量表示、基于嵌入的检索和检索增强生成方式下的LLM引导参数搜索系统，来优化VLSI设计流程。这种方法能够更有效地探索庞大的参数空间，显著提高设计质量并减少迭代次数，提供了比传统手动方法更高效和更精确的选择参数的方法。", "conclusion": "CROP框架能够利用大规模语言模型有效解决VLSI设计中的参数优化问题。通过将RTL代码转换为密集向量表示，基于嵌入的检索匹配，以及检索增强生成与LLM引导的参数搜索系统，CROP实现了更好的设计结果，并减少了9.9%的功耗。这一方法相较于传统的手动方法，在设计效率和设计结果质量上具有显著优势，具有广阔的应用前景。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02227", "html_url": "https://arxiv.org/abs/2507.02227", "title": "PhysicsCorrect：无训练的稳定神经PDE模拟方法", "title_en": "PhysicsCorrect: A Training-Free Approach for Stable Neural PDE Simulations", "authors": "Xinquan Huang,Paris Perdikaris", "background": "神经网络作为求解偏微分方程（PDEs）的强大代理，相较于传统方法提供了显著的计算速度提升。然而，这些模型面临一个关键限制：在长时间滚动期间的误差累积，导致微小的不准确性指数级增加，最终导致与物理有效解完全发散。", "innovation": "提出了一种无训练的修正框架PhysicsCorrect，通过基于PDE残差的线性化逆问题来确保每步预测的PDE一致性。关键创新是高效的缓存策略，在离线预热阶段预计算雅克比矩阵及其伪逆，与标准修正方法相比，将计算开销减少了两个数量级。", "conclusion": "PhysicsCorrect在三种代表性的PDE系统中（Navier-Stokes流体动力学、波动方程和混沌Kuramoto-Sivashinsky方程）减少了预测误差高达100倍，同时增加了几乎可以忽略不计的推理时间（不到5%）。该框架能够无缝集成到各种架构中，包括Fourier神经运算符、UNet和Vision Transformers，将不稳定的神经代理转化为可靠的模拟工具，弥补了深度学习的计算效率与实际科学应用所需的物理精度之间的差距。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02244", "html_url": "https://arxiv.org/abs/2507.02244", "title": "订单获取下的竞争压力：适用于网约车补贴策略的快速适应强化学习方法", "title_en": "Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies", "authors": "Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu", "background": "网约车聚合平台的普及为网约车服务提供商带来了显著的增长机会，通过增加订单数量和商品总值（GMV）。大多数聚合平台都采用价格竞争机制，服务提供者提供较低的价格会使其排名更高，从而更可能被乘客选择。这种竞争机制激励服务提供者采用降价策略来获取更多订单，因为订单数量直接影响他们的长期可行性和可持续性。因此，设计一种能够在预算限制下动态适应市场变化、优化订单获取的补贴策略成为一个关键的挑战。然而，现有的研究仍然较为稀缺，缺乏有效的解决方案来应对这一挑战。", "innovation": "为了解决这一问题，我们提出了一种新颖的强化学习基础上的补贴策略框架FCA-RL，它结合了快速竞争适应（FCA）和强化拉格朗日调整（RLA）两种技术，使平台能够迅速响应竞争对手的价格变动，并在预算范围内优化补贴决策。我们还开发了RideGym，首个专为网约车聚合平台设计的模拟环境，用于全面评估不同定价策略的效果，并不会降低实际运营效率。实验结果表明，我们的方法在各种市场条件下都优于基线方法，突显了其在网约车服务提供商补贴优化方面的有效性。", "conclusion": "我们提出的FCA-RL框架在竞争压力下，能够快速适应市场变化，并在预算限制下优化网约车补贴策略，从而提升订单获取效率。实验结果表明，该方法能够在不同市场条件下持续优于基线方法，为网约车服务提供商提供了一种有效的补贴决策机制。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02310", "html_url": "https://arxiv.org/abs/2507.02310", "title": "在适应回忆机制中的概念漂移下整体持续学习及其自适应记忆重新定位", "title_en": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment", "authors": "Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk", "background": "传统的持续学习方法强调知识保留，主要集中在缓解灾难性遗忘上，假设先前学习任务的数据分布保持静态。然而，这忽略了真实世界数据流的动态性质，其中概念漂移永久改变了先前见过的数据，同时需要保持稳定性和快速适应性能力。现有的基准方法（如全重新学习）尽管有效，但在重新标注和计算方面带来了巨大负担。因此，需要一种既能保持稳定又能快速适应新分布的框架，以应对概念漂移带来的挑战。", "innovation": "本文提出了一种名为自适应记忆重新定位（AMR）的整体框架，用于在概念漂移下的持续学习。AMR通过从重放缓冲区中选择性去除过时样例并替换为新的更新实例，有效地重新定位了记忆以适应新的数据分布。这种方法与全重新学习方法相比具有近似相当的性能，但大幅减少了对标记数据和计算资源的需求。此外，本文还引入了四个带有概念漂移的标准视觉基准数据集变体，以促进重复评估。", "conclusion": "全面的实验表明，AMR能够在不增加大量额外开销的情况下持续对抗概念漂移，保持高效性能。这些结果表明AMR是一个可扩展的解决方案，能够解决非静态环境下持续学习中稳定性和灵活性之间的权衡问题。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02256", "html_url": "https://arxiv.org/abs/2507.02256", "title": "Uncertainty-aware Reward Design Process", "title_en": "Uncertainty-aware Reward Design Process", "authors": "Yang Yang,Xiaolu Zhou,Bosong Ding,Miao Xin", "background": "优化奖励函数是强化学习的关键，但由于传统奖励工程方法的低效性和不一致性，这一过程仍然具有挑战性。近年来，利用大型语言模型（LLMs）自动化奖励函数设计的研究有所进展。然而，这些方法在数值优化中的表现不佳，导致生成的奖励质量不理想。进化搜索方法则由于模拟资源利用不足，导致设计周期过长且计算开销过大。现有方法难以有效应对这些挑战。因此，亟需一种新的框架来提高奖励函数设计和评估的效率及质量，减轻人工干预和优化计算的负担，提高自动化奖励设计的整体效率。", "innovation": "本文提出了一种名为Uncertainty-aware Reward Design Process (URDP)的新型框架，该框架整合了大型语言模型以简化RL环境中的奖励函数设计和评估。URDP通过自我一致性分析量化候选奖励函数的不确定性，实现无需模拟的无效奖励组件识别和新颖奖励组件的发现。同时，引入了基于不确定性估计的贝叶斯优化（UABO），显著提高了超参数配置效率。URDP还通过解耦奖励组件优化和超参数调优来构建多层次优化架构，协调大型语言模型的奖励逻辑推理和贝叶斯优化的数值优化优势。", "conclusion": "我们对URDP进行了全面评估，涵盖35个不同任务，结果表明，URDP不仅生成了更高质量的奖励函数，还实现了自动化奖励设计效率的显著提升，高于现有方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02169", "html_url": "https://arxiv.org/abs/2507.02169", "title": "基于统计推断的响应性验证", "title_en": "Statistical Inference for Responsiveness Verification", "authors": "Seung Hyun Cheon,Meredith Stewart,Bogdan Kulynych,Tsui-Wei Weng,Berk Ustun", "background": "许多机器学习的安全故障发生在模型将预测应用于人员（通常是在贷款、招聘或内容审核等场景中）时，但没有考虑到个体可以如何改变其输入。本文讨论了在使用模型进行此类应用时忽视个体行为变化可能导致的安全问题。在现有的研究基础上，提出了评估模型预测对干预措施响应性的正式验证方法。该方法将响应性视为一种类型化敏感性分析，关注在实践者控制条件下对干预变化和下游效果分布的建模。这一方法对于任何模型和任何数据集的预测响应性评估仅需黑盒访问，并可应用于多种任务，包括验证和失败概率估计。该论文进一步介绍了具体算法和实例应用，展示了这些算法在实际应用场景中的应用潜力，如再犯预测、器官移植优先级设定和内容审核等。", "innovation": "本文提出了一个正式的验证程序，用于评估预测模型对特征集变化的响应性，这一方法可以用于任何模型和任何数据集，仅需黑盒访问。此外，介绍了生成均匀可达点样本的算法，以及如何利用这些样本估计响应性，支持验证和失败概率估计等任务。这种方法为增强模型应用的安全性提供了一套新的工具和理念。", "conclusion": "本文提出的方法和算法的实现为评估机器学习模型预测对干预响应的敏感性提供了新的途径，可以在具体应用场景中提高模型的安全性。所提出的方法不仅可以促进在再犯预测、器官移植优先级设定和内容审核等领域的应用，还可以应用于其他需要考虑个体行为变化影响的领域。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02315", "html_url": "https://arxiv.org/abs/2507.02315", "title": "通过自蒸馏扭曲顺序蒙特卡洛提高语言模型的受限生成", "title_en": "Improving Constrained Generation in Language Models via Self-Distilled Twisted Sequential Monte Carlo", "authors": "Sooyeon Kim,Giung Nam,Juho Lee", "background": "近期研究表明，受限文本生成可以通过自回归语言模型转化为概率推理问题。其中，Zhao等人（2024）引入了一种基于扭曲顺序蒙特卡洛的方法，该方法结合了学习到的扭曲函数和扭曲诱导的提案，来引导生成过程。然而，在目标分布主要集中在基础模型下概率较低的输出上时，这种受限生成设置中学习变得具有挑战性，因为奖励信号稀少且不具信息性。", "innovation": "该论文提出了一种通过自蒸馏扭曲顺序蒙特卡洛的方式来改进受限生成，通过逐步让基础模型与目标分布更一致，从而得到生成质量的显著提升。", "conclusion": "迭代地通过自蒸馏改进基础模型可以缓解学习问题，使得模型逐渐更符合目标，从而显著提高生成质量。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02241", "html_url": "https://arxiv.org/abs/2507.02241", "title": "VERBA: 使用大型语言模型表征模型差异", "title_en": "VERBA: Verbalizing Model Differences Using Large Language Models", "authors": "Shravan Doda,Shashidhar Reddy Javaji,Zining Zhu", "background": "当前的机器学习环境中出现了一个“模型湖”现象，即针对同一任务存在许多具有相似性能但行为不同的训练模型。这对需要从这些模型中选择和使用的模型用户来说是一项严峻的挑战。尽管文档比较模型对用户有帮助，但随着模型数量的增加，两两比较的数量呈平方级增长，这使得手动进行两两比较变得不切实际。因此，研究者们探索了自动表征模型差异的方法，以提高透明性和模型间的可比性。", "innovation": "本文介绍了一种名为$\textbf{VERBA}$的方法，它利用大型语言模型（LLM）通过采样两种模型来自动生成模型差异的表征。通过模拟评估了这些表征的有用性，并建立了一个包含常用机器学习模型的基准套件来测试$\textbf{VERBA}$的有效性。结果表明，对于具有不到5%性能差异但20-25%行为差异的决策树模型对，$\textbf{VERBA}$能够以80%的整体准确性表征它们的变化，当考虑到模型的结构信息时，准确性进一步提高至90%。这为在事后改进机器学习模型的透明度和可比性开辟了新的研究方向。", "conclusion": "本文介绍了$\textbf{VERBA}$方法，利用大型语言模型生成模型差异的表征，显著提高了透明度和可比性，其有效性在决策树模型测试中得到了验证。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02291", "html_url": "https://arxiv.org/abs/2507.02291", "title": "基于知识图谱的可解释与泛化的零样本语义通信", "title_en": "Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications", "authors": "Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu", "background": "数据驱动的语义通信依赖于表面的统计规律，缺乏可解释性和泛化能力，尤其是在存在未见数据的应用场景中表现不佳。这种语义通信方式在处理新出现的数据时难以提供合理的解释和有效的性能增强，限制了其在灵活和资源受限环境下的广泛应用和发展潜力。", "innovation": "本文提出了一种新的基于知识图谱的知识增强零样本语义通信(KGZS-SC)网络。该网络通过基于知识图谱的语义知识库(KG-SKB)提供的结构化语义信息，实现了泛化的语义表示和对于未见案例的推理能力。具体的，知识图谱的知识库对共享的类别语义嵌入空间中的语义特征进行对齐，通过对齐的语义特征增强发送器的泛化能力，从而通过选择性地传输紧凑的视觉语义来减少通信开销。在接收端，利用零样本学习(ZSL)直接对未见案例进行分类，无需重新训练或额外的计算开销，增强了分类过程的适应性和效率，特别是在动态或资源受限的环境中。", "conclusion": "在APY数据集上进行的仿真实验表明，提出的KGZS-SC网络在不同信噪比（SNR）水平上展示了稳健的泛化能力，并显著优于现有的语义通信框架，在对未见类别的分类方面表现出更好的性能。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02406", "html_url": "https://arxiv.org/abs/2507.02406", "title": "通过偏好优化提高车辆轨迹预测的一致性", "title_en": "Improving Consistency in Vehicle Trajectory Prediction Through Preference Optimization", "authors": "Caio Azevedo,Lina Achaji,Stefano Sabatini,Nicola Poerio,Grzegorz Bartyzel,Sascha Hornauer,Fabien Moutarde", "background": "车辆轨迹预测是自动驾驶车辆流程中必不可少的步骤。不准确或不一致的轨迹预测会导致车辆规划不当和潜在的危险情况。现有的基于深度学习的轨迹预测模型在公开数据集上可以达到很高的准确率，但在复杂的交互场景中往往无法捕捉到多智能体之间的交互依赖关系，导致预测结果不一致。", "innovation": "本文通过在多智能体设置中引入偏好优化来微调轨迹预测模型。在微调过程中使用自动计算的预测未来偏好排名作为输入，实验使用三个数据集上的最先进模型表明，这种方法可以在不牺牲预测准确性和不增加推理时的额外计算需求的前提下，显著提高场景的一致性。", "conclusion": "通过偏好优化，本文成功提高了车辆轨迹预测的一致性，且未牺牲预测精度，也没有增加推理时的计算需求。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02356", "html_url": "https://arxiv.org/abs/2507.02356", "title": " Offline Reinforcement Learning with Penalized Action Noise Injection", "title_en": "Offline Reinforcement Learning with Penalized Action Noise Injection", "authors": "JunHyeok Oh,Byung-Jun Lee", "background": "离线强化学习(Offline RL)利用固定的数据集优化策略，适用于环境交互成本高的场景。尽管离线RL算法通过使用扩散模型等方法在泛化能力方面取得了进展，但关于扩散模型在高性能离线RL算法中的必要性仍有疑问，因为其在推理时需要大量的计算资源。", "innovation": "本文提出了一种名为Penalized Action Noise Injection (PANI)的方法，该方法通过注入噪声的动作来覆盖整个动作空间，并根据注入的噪声量进行惩罚，这种方法借鉴了扩散模型在离线RL中的工作方式。文章还为这一方法提供了理论基础，证明通过这种噪声注入的动作，离线RL算法求解了一个称为噪声动作MDP的修改后的马尔可夫决策过程。PANI适用于各种现有的无偏和离线RL算法，并在多个基准测试中表现出显著的性能提升，尽管其本身是相当简单的。", "conclusion": "PANI方法不仅简单易用，还能显著提高离线RL算法的性能，并支持多种标准离线RL算法，展现了其在提升离线RL算法性能方面的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02342", "html_url": "https://arxiv.org/abs/2507.02342", "title": "DeltaSHAP: 使用Shapley值在在线患者监控中解释预测演变", "title_en": "DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values", "authors": "Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang", "background": "在临床上，发现驱动患者风险演变的原因对于及时干预至关重要，但现有的解释性人工智能（XAI）方法无法满足临床时间序列解释任务的特殊需求。现有的XAI方法在解释连续预测的变化、提供特征贡献的幅度和方向以及实时提供这些见解方面存在局限性。因此，需要一种新的方法来解决这些问题，尤其是在时间敏感的临床应用中更好地解释预测变化。", "innovation": "DeltaSHAP提出了一种新颖的XAI算法，特别设计用于在线患者监控系统。它通过适应Shapley值的时间设置来准确捕获特征合成功效，并仅使用实际观察到的特征组合来归因预测变化，这使得它对于时间敏感的临床应用高效且实用。此外，还引入了新的评价指标来评估在线时间序列的归因忠诚度，并通过MIMIC-III去代偿基准实验展示了DeltaSHAP在解释质量和计算效率方面的优越性，分别提高了62%和减少了33%的计算时间", "conclusion": "DeltaSHAP在在线患者监控任务中表现出色，不仅在解释质量上优于最先进的XAI方法，而且在计算效率上也显著优于现有方法，实现了实时的、高效的高精度特征归因。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02320", "html_url": "https://arxiv.org/abs/2507.02320", "title": "基于Transformer的EEG解码：综述", "title_en": "Transformer-based EEG Decoding: A Survey", "authors": "Haodong Zhang,Hongqi Li", "background": "电生理图（EEG）是最常用的用于捕捉大脑电活动的信号之一，EEG解码，即获取用户意图，一直是人脑计算机/机器接口（BCIs/BMIs）研究的前沿。与传统的利用机器学习进行EEG分析的方法相比，深度学习方法的出现逐渐革新了该领域，提供了端到端的长链条架构，能够自动学习更具判别性的特征。其中，Transformer凭借其通过注意力机制处理序列数据的强大能力，在各种EEG处理任务中的应用日益普及。本文旨在进行相关综述，总结自Transformer出现以来在EEG解码中的最新应用，并跟踪模型架构的演变，详细梳理相关进步。文章首先阐述了有助于EEG解码的Transformer基础知识及其直接应用，然后详细概述了将基础Transformer与其他深度学习技术（卷积/递归/图形/脉冲神经网络、生成对抗网络、扩散模型等）进行结合的常见混合架构。此外，还介绍了改进的定制Transformer内在结构的研究进展。最后，讨论了该快速发展的领域所面临的当前挑战和未来的发展前景，旨在帮助读者清晰理解当前Transformer在EEG解码中的应用状况，并为未来的研究提供有价值的见解。", "innovation": "随着深度学习方法的兴起，特别是Transformer模型的应用，EEG解码领域得到了革新。Transformer能够自动学习更具判别性的特征，而混合架构的结合为解决特定问题提供了更多途径。文章还详细讲述了定制Transformer内在结构的改进及其研究进展，为未来研究提出了指导。", "conclusion": "本文总结并梳理了Transformer在EEG解码中的最新应用和进展，澄清了相关模型架构的演变和相关改进。同时，文章明确了当前挑战，并展望了未来研究发展的方向，帮助读者更好地理解该领域当前的状态并提供对未来研究的有益见解。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02409", "html_url": "https://arxiv.org/abs/2507.02409", "title": "S2FGL：空间频域联邦图学习", "title_en": "S2FGL: Spatial Spectral Federated Graph Learning", "authors": "Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye", "background": "联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）的强图建模能力。当前的研究仅从结构角度关注子图FL，忽略了图信号在空间域和频谱域的传播。从空间角度看，子图FL导致客户端之间边连接中断，影响标签信号并降低全局GNN的类知识。从频谱角度看，频谱异质性导致子图中信号频率不一致，使得局部GNN过度拟合局部信号传播方案。因此，频谱客户端漂移出现，影响全局泛化能力。", "innovation": "提出了一种全局知识库来减轻标签信号中断问题，并通过频率对齐解决频谱客户端漂移问题。结合空间和频谱策略构建了框架S2FGL。广泛的实验表明，S2FGL是优越的。", "conclusion": "S2FGL框架在多个数据集上的广泛实验表明了其优越性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02503", "html_url": "https://arxiv.org/abs/2507.02503", "title": "LLMs的连续梯度低秩投影微调", "title_en": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs", "authors": "Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing", "background": "大规模语言模型（LLMs）的持续微调面临着效率和表达能力之间的权衡问题。尽管低秩适应（LoRA）提高了效率，但也限制了模型学习新任务和迁移知识的能力，这是因为其低秩性质和对显式参数约束的依赖性。", "innovation": "提出了一种新颖的持续学习训练策略——GORP（Gradient LOw Rank Projection），该方法通过将全参数和低秩参数协同结合，并在统一低秩梯度子空间内联合更新，从而在扩大优化空间的同时保持效率并缓解灾难性遗忘问题。", "conclusion": "广泛的经验研究表明，GORP在持续学习基准上的性能优于现有的最先进的方法。代码可在该链接下载：this https URL。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02365", "html_url": "https://arxiv.org/abs/2507.02365", "title": "基于潜在表示的深度强化学习DRAM均衡器参数优化", "title_en": "Deep Reinforcement Learning-Based DRAM Equalizer Parameter Optimization Using Latent Representations", "authors": "Muhammad Usama,Dong Eui Chang", "background": "在高速动态随机存取存储器（DRAM）系统中，均衡器参数优化对于保证信号完整性至关重要，但这一过程往往计算量大或依赖于模型。传统的优化方法依赖于复杂的模型和直接的眼图分析，这涉及到大量的计算资源，并且可能限制了优化的速度和效率。本文旨在通过引入数据驱动框架和无模型强化学习算法，提供一种更高效的信号完整性评估和参数优化方法。", "innovation": "本文提出了一种基于潜在表示的数据驱动框架，利用学习到的信号潜在特征进行快速信号完整性评估。同时，该方法使用无模型的强化学习代理（优势行动者-批评者）进行参数优化，无需显式系统模型即可获得最佳均衡器设置。这种方法在工业标准的DRAM波形中实现了显著的优势，特别是在连续时间线性均衡器和决策反馈均衡器结构上的眼图窗口面积改善达到42.7%，决策反馈均衡器结构上达到了36.8%。这些结果显示出该方法在性能、计算效率和跨不同DRAM单元的泛化能力方面优越于现有技术。", "conclusion": "本文的核心贡献在于提出了一种高效的潜在信号完整性指标进行优化，一种鲁棒的无模型强化学习策略，并且证实了这种方法在复杂均衡器架构上的优越性能。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02496", "html_url": "https://arxiv.org/abs/2507.02496", "title": "具有效率保证的在线共形预测", "title_en": "Online Conformal Prediction with Efficiency Guarantees", "authors": "Vaidehi Srinivas", "background": "本研究探讨了一种新颖的在线框架下的共形预测问题，该框架直接优化效率。给定目标覆盖率为 α>0 以及时间范围 T。在每一天 t ≤ T，算法必须输出一个区间 I_t ⊂ [0, 1]，然后揭示一个点 y_t ∈ [0, 1]。算法的目标是在接近(1-α)的天数内实现覆盖，同时最小化所使用的区间长度以保持效率。该问题等同于构建高效的置信区间。研究在任意和可交换输入序列上进行。对于可交换序列，提出了实现 (1-α) 以上的覆盖，同时具有长度限制的区间。然而，对于任意序列，若算法相比最佳固定区间在平均长度上的近似为 μ-近似，则必须比 αT 额外犯更多的错误。主要算法结果是能够恢复所有Pareto-最优设置并具有确定性的算法。通过对适应性对手的鲁棒性也增强了。在可交换和任意序列之间的差距与经典在线学习问题不同，实际上展示了不能同时为任意序列提供最优和为可交换序列提供Pareto-最优算法", "innovation": "在上述框架内直接优化效率，提出了针对可交换序列和任意序列的算法，实现了接近最优的两种情况之间的权衡", "conclusion": "研究表明，不存在能够同时实现两种最优情况的单一算法。所提出的算法在保持效率的同时，能够在很大程度上接近最优的权衡，此研究对于在线预测领域具有重要意义"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02529", "html_url": "https://arxiv.org/abs/2507.02529", "title": "RetrySQL：利用重试数据进行自我纠正查询生成的文本到SQL训练", "title_en": "RetrySQL: text-to-SQL training with retry data for self-correcting query generation", "authors": "Alicja Rączkowska,Riccardo Belluzzo,Piotr Zieliński,Joanna Baran,Paweł Olszewski", "background": "文本到SQL任务是自然语言处理中的一个活跃挑战。许多现有的解决方案侧重于使用扩展了专用组件的黑盒语言模型来定制端到端的文本到SQL管道。虽然这些解决方案采用了闭源专有语言模型和编码导向的开源模型，但缺乏针对SQL特定生成模型的研究。此外，最近在自我纠正生成策略的进展展示了提升现有架构能力的潜力，但在文本到SQL任务中的应用尚属未探索领域。", "innovation": "介绍了RetrySQL，一种新方法来训练文本到SQL生成模型。通过准备参考SQL查询的推理步骤并对其进行篡改，创建包含错误和更正步骤的重试数据，并用这些数据持续预训练开源编程模型。展示了重试步骤可以提高整体和具有挑战性的执行准确性多达4个百分点。还确定通过重试数据进行监督微调的LoRA方法无效，并且全参数预训练是必要的。模型学会了自我纠正行为，下游准确性指标的提升是由于增加了这项技能。将RetrySQL训练的模型集成到完整的文本到SQL管道中，展示了它们在执行准确性上与具有数万参数的专有模型相当的竞争力。", "conclusion": "RetrySQL证明自我纠正可以在文本到SQL任务中学习，并提供了一种提高SQL导向语言模型生成准确性的新方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02466", "html_url": "https://arxiv.org/abs/2507.02466", "title": "Variant Kolmogorov-Arnold Network", "title_en": "Variational Kolmogorov-Arnold Network", "authors": "Francesco Alesiani,Henrik Christiansen,Federico Errica", "background": "Kolmogorov Arnold Networks (KANs) 是一种新兴的机器学习模型架构，基于 Kolmogorov-Arnold 定理及其扩展，提供了一种精确表示多变量连续有界函数的方法。然而，利用这些理论结果作为多层感知机 (MLP) 的替代表示学习方法依赖于为每个单变量函数选择适当的基函数数量，这是需要人工调节的。", "innovation": "该论文通过引入 InfinityKAN，提出了一种变分推断优化问题，并使用反向传播技术，自适应地学习每个单变量函数的潜在无限数量的基函数，从而将 KANs 的潜在适用性扩展到处理重要超参数的学习过程中。", "conclusion": "InfinityKAN 在训练过程中适应性地学习每个单变量函数的无限数量的基函数，从而解决 KANs 需要人工设定超参数的问题，扩展了 KANs 的应用场景。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02510", "html_url": "https://arxiv.org/abs/2507.02510", "title": "TFOC-Net：一种基于短时傅里叶变换的用于提升跨被试运动想象分类的深度学习方法", "title_en": "TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification", "authors": "Ahmed G. Habashi,Ahmed M. Azab,Seif Eldawlatly,Gamal M. Aly", "background": "跨被试运动想象(CS-MI)分类在脑-机接口(BCI)中的任务具有挑战性，由于不同个体之间电生理图谱的显著变异，这种变异导致了较低的分类准确性，与个体特异性模型相比，这成为了开发免校准BCIs的障碍，对于实际应用具有重要的挑战性。", "innovation": "提出了通过优化预处理和深度学习技术来显著提升跨被试MI分类性能的新方法。该方法直接分类短时傅里叶变换(STFT)转换的电生理数据，优化STFT参数，并在卷积神经网络(CNN)训练期间采用平衡批处理策略。这种方法在四个不同的数据集上进行了验证，包括三个广泛使用的基准数据集，取得了显著的跨被试分类性能提升，特别是在BCI竞赛IV数据集1、数据集2A和数据集2B上分别达到67.60%、65.96%和80.22%，超越了最先进的技术。此外，还系统地研究了不同运动想象窗口(从4秒钟窗口到1秒钟窗口)上的分类性能，建立了跨被试可泛化的免校准MI分类的新基准，并贡献了一个供研究使用的、开源的数据集，以推进这一领域的发展。", "conclusion": "该研究方法不仅建立了跨被试可泛化的免校准运动想象分类的新基准，还为这一领域的研究贡献了一个稳健的开源数据集，推进了脑-机接口领域的发展。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02599", "html_url": "https://arxiv.org/abs/2507.02599", "title": "Padé逼近神经网络在振动和声学数据支持下增强电动机故障诊断中的应用", "title_en": "Padé Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data", "authors": "Sertac Kilickaya,Levent Eren", "background": "目前，电机状态监测主要依靠加速度计和麦克风，而深度学习模型中的非线性神经网络架构显示了在诊断性能上的潜在改进。本文研究了Padé逼近神经网络（PadéNets）是否能比传统的卷积神经网络（CNNs）和自我组织操作神经网络（Self-ONNs）在利用振动和声学数据诊断电气和机械故障方面表现更好。研究使用了渥太华大学公开提供的恒速感应电动机数据集进行评估和比较。", "innovation": "引入了Padé逼近神经网络模型，这种模型可以增强非线性，兼容于非限制性激活函数（如Leaky ReLU），从而在感应电机的故障诊断性能上取得了显著提高。", "conclusion": "PadéNets在所有测试条件下均表现出色，其诊断准确率分别达到99.96%、98.26%、97.61%和98.33%，这证明了其在感应电机状态监测中的优越性，特别是在故障诊断方面。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02585", "html_url": "https://arxiv.org/abs/2507.02585", "title": "布尔网络中可扩展的互联系统学习", "title_en": "Scalable Interconnect Learning in Boolean Networks", "authors": "Fabian Kresse,Emily Yu,Christoph H. Lampert", "background": "Learned Differentiable Boolean Logic Networks (DBNs) 已经展示了在资源受限的硬件上进行高效推理的能力。然而，早期的可学习互联系统设计在输入宽度增长时互联系统的参数数量会增加，这限制了DBNs的扩展性，使其难以扩展到更宽的层，同时保持它们的优势准确性.", "innovation": "该研究通过对可学习互联系统进行改进，提出了一个可训练、可微的互连系统，其参数计数在输入宽度增长时保持不变，从而使DBNs能够扩展到更宽的层，同时保持其优越的准确性。为了进一步减小模型大小，该研究还提出了两个互补的剪枝阶段：基于SAT的逻辑等价性阶段，可移除冗余门而不影响性能；以及基于相似性、数据驱动的阶段，优于传统贪婪基线，并提供更优的压缩-准确性权衡.", "conclusion": "通过这些方法，DBNs可以在保持高准确性的前提下扩展至更宽的层，并能够实现更小的模型尺寸，从而进一步提高计算效率和资源利用率."}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02608", "html_url": "https://arxiv.org/abs/2507.02608", "title": "迷失在隐空间：物理仿真中基于隐空间的扩散模型的实证研究", "title_en": "Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation", "authors": "François Rozet,Ruben Ohana,Michael McCabe,Gilles Louppe,François Lanusse,Shirley Ho", "background": "扩散模型在推断时的高额计算成本阻碍了它们作为快速物理仿真的应用。在图像和视频生成的背景下，计算问题已经通过在自动编码器的隐空间而不是像素空间中生成来解决。本文探讨了是否可以类似地将策略应用于动力系统的仿真，并探索成本是什么样的。研究表明，隐空间仿真对广泛的压缩率（高达1000倍）具有惊人的鲁棒性。此外，扩散基仿真是比非生成性对应物更准确的，通过更大的多样性弥补了预测中的不确定。最后，本文涵盖了从架构到优化器等实际设计选择，这些选择对训练隐空间仿真是至关重要的。", "innovation": "本文采用与图像和视频生成中解决计算问题相似的策略，提出在隐空间中进行物理仿真，通过在自动编码器的隐空间而非像素空间中生成来降低扩散模型的计算成本。同时，研究发现隐空间仿真在广泛压缩率下仍保持高度准确性，并且扩散基仿真模型通过更高的多样性弥补预测不确定性，而其表现优于非生成性基仿真模型。此外，本文还提供了训练隐空间仿真模型过程中关键的设计选择，涵盖了从架构到优化器等多个方面。", "conclusion": "隐空间仿真在广泛压缩率下对物理仿真具有高度鲁棒性，扩散基仿真模型比非生成性基仿真模型更准确，并通过更大的多样性弥补预测中的不确定性。训练隐空间仿真模型时，采用适当的架构和优化器是非常关键的。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02550", "html_url": "https://arxiv.org/abs/2507.02550", "title": "关于深度学习理论必须包含组合稀疏性的观点", "title_en": "Position: A Theory of Deep Learning Must Include Compositional Sparsity", "authors": "David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio", "background": "过参数化的深度神经网络（DNNs）在许多高维度领域表现出色，克服了经典浅层网络因维数灾难而受限的问题。然而，关于调控DNNs学习动力学的基本原理仍存在许多未解之谜。这些基本原理涉及DNNs如何利用目标函数的组合稀疏性结构，使得它们能够从少量基本函数的组合中获得成功，这些基本函数仅依赖于所有输入的低维度子集。大多数实际相关的函数都具有这种组合稀疏性特征，因此可高概率存在于当前所有的学习问题中。尽管在组合稀疏函数的设置中对逼近和泛化有了一些有前景的理论洞察，但仍有很多关于DNNs学习能力和优化的重要问题需要进一步研究。了解组合稀疏性在深度学习中的作用对于构建整体的人工智能理论至关重要。", "innovation": "文章提出DNNs的成功主要得益于其利用目标函数的组合稀疏性结构的能力。大多数实际实用的功能都可以由少量的基本函数组合而成，这些基本函数仅依赖于所有输入的低维度子集。这一发现扩展了对DNNs学习机制的理解，并强调了组合稀疏性在DNNs中起着关键作用。同时，文章也指出需要进一步研究DNNs学习能力和优化的相关问题。", "conclusion": "为了全面理解人工智能，甚至是通用人工智能，建立一个包含组合稀疏性的深度学习理论至关重要。这需要对DNNs的学习和优化机制有更深入的理解，并对未来的研究方向提出了重要指导。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02559", "html_url": "https://arxiv.org/abs/2507.02559", "title": "在推理时不需Transformer中的LayerNorm：扩展至GPT-2 XL并对其机制可解释性的影响", "title_en": "Transformers Don't Need LayerNorm at Inference Time: Scaling LayerNorm Removal to GPT-2 XL and the Implications for Mechanistic Interpretability", "authors": "Luca Baroni,Galvin Khara,Joachim Schaeffer,Marat Subkhankulov,Stefan Heimersheim", "background": "虽然层归一化（LN）是几乎所有的基于转换器的大语言模型的重要组成部分，并且在训练稳定性方面已有充分的研究，但其在推理时的作用尚未明了。此外，LN层还阻碍了机械可解释性的引入，因为它们增加了各个模型组件之间的非线性及相关性。", "innovation": "作者证明了可以从所有的GPT-2模型中移除LN层，且在验证损失上只会有微小的增加（例如，GPT-2 XL模型上的交叉熵损失增加0.03），表明LN在语言建模中并不起显著作用。他们还发现，移除LN所需的数据量与模型参数的增加成亚线性关系，这意味着扩展到更大模型是可行的。此外，作者还测试了无LN层模型的解释性技术，发现直接logit归因现在可以提供确切的单独组件影响，而归因修补的准确性并未显著提高。进一步确认了GPT-2的“自信神经元”在无LN模型中是不活跃的。这项工作揭示了LN层在语言建模中的作用，显示GPT-2同类模型无需LN层也可以正常工作，并希望借此可以进行更精确的解释性研究，从而改善我们对语言模型的理解。", "conclusion": "我们的无LN版本的GPT-2家族模型将有助于更精确的解释性研究，并有助于我们更好地理解语言模型。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02619", "html_url": "https://arxiv.org/abs/2507.02619", "title": "L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation", "title_en": "L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation", "authors": "Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural", "background": "本文旨在改进现有的变分自动编码器（VAE），特别是在解缠表示方面的表现。现有模型如η-VAE通过实验调整超参数η以平衡解缠和重构损失，但这种方法仍有局限性，尤其是当模型需要动态调整时。为了解决这些问题，本文提出了一个名为Learnable VAE（L-VAE）的新模型，该模型能够学习损失函数中各个项的权重，并通过引入额外的正则化项来防止偏向于重构或解缠损失之一。", "innovation": "L-VAE 的创新之处在于它能够学习成本函数中各项的权重，从而动态调节解缠与重构之间的权衡。这使得 L-VAE 能够自适应地调整损失函数中的权重，以更好地平衡重构精度与潜在空间的解缠性。此外，L-VAE 通过添加额外的正则化项来防止不平衡的情况，进一步增强了模型的解缠能力。", "conclusion": "实验表明，L-VAE 在多个数据集上的表现优于其他模型（如η-VAE、VAE、ControlVAE、DynamicVAE 和 σ-VAE），尤其是在一组解缠度量上表现最佳或第二好。此外，在 CelebA 数据集上的定性实验也证实了 L-VAE 在解缠面部属性方面的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02645", "html_url": "https://arxiv.org/abs/2507.02645", "title": "公正的深度假新闻检测器能够泛化", "title_en": "Fair Deepfake Detectors Can Generalize", "authors": "Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli", "background": "深度假新闻检测模型面临两个关键挑战：对未见过的篡改的一般化和各个群体之间的公平性。现有的方法往往显示，这两个目标是相互冲突的，揭示了它们之间的权衡。", "innovation": "本文首次揭示并正式定义了公平性和泛化的因果关系。基于后门调整技术，提出了一种公平性干预方法，控制混杂因子（数据分布和模型能力）以提高公平性，从而改善泛化。进一步提出了一种“Demographic Attribute-insensitive Intervention Detection (DAID)”框架，包括：1）基于人口统计信息的数据重新平衡，使用逆倾向加权和子组特征归一化来消除分布偏差；2）基于人口统计特征无关的特征聚合，使用新颖的对齐损失来抑制敏感特征信号。", "conclusion": "在三个跨域基准中，DAID在公平性和泛化方面均优于多种最先进的检测器，证明了其理论基础和实际效果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02628", "html_url": "https://arxiv.org/abs/2507.02628", "title": "医学数据啄食：基于上下文的结构化医疗数据自动化质量评估方法", "title_en": "Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data", "authors": "Irena Girshovitz,Atai Ambus,Moni Shahar,Ran Gilad-Bachrach", "background": "电子健康记录（EHRs）在流行病学研究和人工智能训练中的使用正在迅速增加，但研究结果的可靠性取决于EHR数据的准确性和完整性。然而，EHR数据往往包含大量的质量问题，包括子人群的误表征、偏差和系统性错误，这些数据主要是为了临床和收费目的而收集的。现有的质量评估方法仍不充分，缺乏系统性的程序来评估数据是否适合研究.", "innovation": "提出了医学数据啄食方法，将软件工程中的单元测试和覆盖概念应用于识别数据质量问题。通过医学数据啄食工具（MDPT）实现了自动测试生成器和数据测试框架，用于生成基于数据和研究描述的测试套件，并执行这些测试以报告潜在错误和覆盖率。该方法评价了三个数据集：All of Us（AoU）、MIMIC-III 和 SyntheticMass，生成了55-73个测试案例，并正确识别了20-43个不一致或不符合规范的数据问题。此外，详细分析了大型语言模型生成的测试套件的参考接地和值准确性.", "conclusion": "该方法结合了外部医学知识，作为数据分析工作流程的一部分，进行上下文敏感的数据质量测试，以提高其结果的有效性。从质量保证的角度来说，这种方法为未来的进一步发展奠定了基础，比如增加了其他数据模态和改进的接地方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02624", "html_url": "https://arxiv.org/abs/2507.02624", "title": "一种用于药代遗传变异效应预测的矩阵变分自编码器", "title_en": "A Matrix Variational Auto-Encoder for Variant Effect Prediction in Pharmacogenes", "authors": "Antoine Honoré,Borja Rodríguez Gálvez,Yoomi Park,Yitian Zhou,Volker M. Lauschke,Ming Xiao", "background": "变异效应预测器（VEPs）通常依赖多序列比对（MSA）来评估蛋白质变异的功能影响，这一方法假设自然发生的变异是适应良好的。然而，药代遗传学的发现挑战了这一假设，因为有些药代基因经历了低进化压力。深度突变扫描（DMS）数据集提供了另一种选择，它们提供了变异的定量 fitness 分数。", "innovation": "本文提出了一种基于变压器的矩阵变分自编码器（matVAE），配备了结构先验，并在来自药代基因组学基准（ProteinGym）的33个DMS数据集上进行了评估，其中包含26种药物靶点和ADME蛋白。该模型在使用参数数量和计算速度方面比最先进的DeepSequence模型更优，同时使用MSA进行训练（matVAE-MSA）。文章还比较了matVAE-MSA与另一个基于类似容量的DMS数据训练的模型matENC-DMS，并发现后者在监督预测任务中表现更优。将AlphaFold生成的结构整合到变压器模型中可以进一步提高性能，实现与基于MSA训练的DeepSequence并进一步微调DMS性能相当的结果。这些发现强调了DMS数据集的潜力，可以替代MSA而不显著影响预测性能，这激励进一步开发DMS数据集及其关系研究，以增强变异效应预测能力。", "conclusion": "综合上述研究，DMS数据集可能不用显著损失预测性能就能替代MSA，因此将刺激DMS数据集的进一步发展和与其关系的探索，进而增强变异效应预测性能。同时，该研究提出的基于 transformers 的矩阵变分自编码器（matVAE）模型在该领域表现出色。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02634", "html_url": "https://arxiv.org/abs/2507.02634", "title": "高阶深度元学习及范畴论解释", "title_en": "High-Order Deep Meta-Learning with Category-Theoretic Interpretation", "authors": "David H. Mguni", "background": "本文介绍了一种新的分层深度学习框架，用于递归高阶元学习，让神经网络能够构建、解决和泛化跨任务层次的任务。关键在于生成机制，它创建了虚拟任务——合成的问题实例，旨在使元学习器学习软约束和无法预知的一般化规则。此外，通过探索虚拟点的景观并在较深层次的学习者发现困难的任务时主动寻求，元学习器迭代精化约束区域，增强了归纳偏置，规整了适应过程，并生成了新出现的任务和约束条件，这些对于泛化至关重要。每一层元学习对应于以前层次问题的逐渐抽象概括，从而形成结构化的可解释的学习进阶。", "innovation": "本文提出了一种基于范畴论解释的高阶深度元学习框架。该框架通过生成机制创造了虚拟任务，以帮助元学习器学习软约束和一般化规则，同时主动探索以求解难点任务。在此基础上，元学习器迭代优化约束区域，增强归纳偏置，帮助产生新的和未预见的任务和约束条件，从而提升泛化能力。论文将元学习者视为范畴论中的泛函，这不仅统一了现有的元学习模型，还揭示了通过泛函关系转换和比较学习过程的可能性，提供了结构化元学习设计的实用原则。推测此架构可能成为下一代能够自主生成新颖任务及其解决方案的神经网络的基础，推动机器学习向通用人工智能迈进。", "conclusion": "通过范畴论的解释，该框架提供了一种新的视角来理解元学习过程，并将现有的元学习模型统一起来。这不仅有助于更好地设计和理解元学习的过程，还为实现自主生成新颖任务及其解决方案的神经网络提供了一种可能的道路，从而更能推动机器学习向通用人工智能领域发展。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02671", "html_url": "https://arxiv.org/abs/2507.02671", "title": "基于生成模型的联邦数据共享方法", "title_en": "Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs", "authors": "Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig", "background": "深度学习在医疗成像领域的应用已经取得了显著成果，但由于数据稀缺性和隐私法规的限制，其广泛应用受到制约。联邦学习能够实现分散的数据训练，但存在通信成本高、任务单一等问题，灵活性较低。现有的联邦学习方法主要依赖生成模型，如差分隐私生成对抗网络（DPCGAN），但在准确性和效率上存在局限性，特别是在减少冗余和降低计算开销方面效果欠佳。", "innovation": "本文提出了一种基于差分隐私条件变分自编码器（DP-CVAE）的数据共享方法。通过采用基础模型提取紧凑且信息丰富的嵌入表示，减少冗余并降低计算开销。客户端协作训练一个差分隐私条件变分自编码器，以建模全局隐私感知数据分布，支持多种下游任务。该方法在多个特征提取器上得到验证，提高了隐私性、可扩展性和效率，优于传统的联邦学习分类器，同时确保了差分隐私。此外，DP-CVAE生成的嵌入质量更高，参数量仅为DPCGAN的五分之一。", "conclusion": "本文提出的方法能够有效提升数据共享的隐私保护、模型扩展性和计算效率，适用于多种下游医疗应用任务，具有较高的应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02639", "html_url": "https://arxiv.org/abs/2507.02639", "title": "关于模型导向强化学习中有效贝叶斯探索的研究", "title_en": "On Efficient Bayesian Exploration in Model-Based Reinforcement Learning", "authors": "Alberto Caron,Chris Hicks,Vasilios Mavroudis", "background": "在强化学习中，高效探索是在数据稀少的情况下发现和利用环境信息的关键挑战。现有信息理论导向的内在动机方法通过关注环境动力学和奖励的先验不确定性，而非环境中的偶然噪音，来应对这一挑战。这类方法提供的探索奖金能够自然地反映知识获取，并在代理对环境足够确定时逐渐收敛至零，从而使探索与实际的知识缺口相吻合。然而，虽然已有方法在理论上没有足够的保证，但其实用实现已变得可操作，通过稀疏变异高斯过程、深度核和深度集成模型近似方法来简化操作过程。本文通过提出一种整合基于模型的规划与信息理论驱动奖金的通用框架——预测轨迹采样与贝叶斯探索（PTS-BE），使深度探索更为高效，尤其是在稀疏奖励或仅为探索任务的环境中。", "innovation": "本文提出了一种新的框架——预测轨迹采样与贝叶斯探索（PTS-BE），结合了基于模型的规划与信息论奖项，实现了高效的数据探索。同时，通过稀疏变异高斯过程、深度核和深度集成模型的可操作近似方法，使得信息论嘉奖方法在实际应用中更易实施。这种方法为基于信息论的方法提供了形式保证，修正了之前缺乏定理基础的问题。实验结果显示，PTS-BE 在多种稀疏奖励环境或纯粹探索任务中表现优于其他基准方法。", "conclusion": "本文证明了基于信息论的方法可自然地反映知识获取，并在代理对环境足够确定时收敛于零。提出的PTS-BE框架在多种环境中有效提升了探索效率，显示其在强化学习探索中的潜在应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02698", "html_url": "https://arxiv.org/abs/2507.02698", "title": "供应链中基于多智能体强化学习的动态定价：在实际模拟市场条件下评估战略智能体行为", "title_en": "Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions", "authors": "Thomas Hazenberg,Yao Ma,Seyed Sahand Mohammadi Ziabari,Marijn van Rijswijk", "background": "本研究探讨了多智能体强化学习（MARL）如何改善供应链中的动态定价策略，特别是在传统ERP系统依赖于静态、基于规则的方法忽视市场行为者之间战略相互作用的情境下。近年来的研究已将强化学习应用于定价，但大多数实施仍局限于单智能体，并未能建模真实世界供应链中的相互依赖性。本研究通过在由实际电子商务交易数据和LightGBM需求预测模型支持的模拟环境中评估三种MARL算法（MADDPG、MADQN和QMIX）的性能，填补了这一空白，对比基于规则的静态基线模型，展示了MARL引入未被静态定价规则捕捉的战略行为，并可能为动态定价的未来发展提供启示。", "innovation": "本研究通过将三种MARL算法（MADDPG、MADQN和QMIX）与基于规则的静态基线模型进行比较，特别是在模拟环境中基于实际电子商务交易数据和LightGBM需求预测模型，评估了它们在动态定价策略中的表现，填补了现有研究在真实模拟市场条件下的空白。结果显示，MARL算法能够生成尚未被静态定价规则捕捉的战略行为，如MADDPG既支持市场竞争又保持高公平性和价格稳定性；MADQN则表现出高度的价格波动和较低的公平性。", "conclusion": "研究结果表明，MARL能够引入静态定价规则所未能捕捉到的战略行为，并提供市场竞争、公平性和价格稳定性之间更均衡的定价策略。这表明MARL可以为未来动态定价的发展提供新的思路和方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02659", "html_url": "https://arxiv.org/abs/2507.02659", "title": "OmniDraft：适用于设备上推测性解码的跨领域、在线自适应草稿生成器", "title_en": "OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding", "authors": "Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang", "background": "在推测性解码中，通常需要一个小型、高效的草稿模型，该模型可以预训练或脱机精炼到特定的目标模型系列，比如Llama或Qwen模型。然而，在线部署中存在两个主要挑战：1）目标模型与草稿模型不兼容；2）期望提高使用的实时性和延迟。本文旨在解决这个问题，提出了一种统一框架OmniDraft，允许单个草稿模型与任何目标模型协同工作，并能够动态适应用户数据。OmniDraft通过混合词元缓存和自适应精炼技术，解决了跨词汇不匹配问题，并通过优化解码速度实现了这一目标。", "innovation": "OmniDraft是一个统一的框架，使得单个草稿模型能够与任何目标模型协同工作，并能够动态适应用户数据。它通过在线n-克隆缓存与混合精炼微调来解决跨词汇不匹配问题，并通过自适应制稿技术进一步提高解码速度。这个框架特别适用于设备上的大模型应用，控制模型成本、效率和用户自定义成为关键问题。", "conclusion": "OmniDraft展示了在线学习在数学推理、编程和文本生成任务中的能力。它使一个Llama-68M模型能够与包括Vicuna-7B、Qwen2-7B和Llama3-8B在内的多个目标模型进行推测性解码，并提供高达1.5-2倍的速度提升，进一步证明了“一个草稿模型应对所有需求”的理念。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02670", "html_url": "https://arxiv.org/abs/2507.02670", "title": "引导生成可开发抗体", "title_en": "Guided Generation for Developable Antibodies", "authors": "Siqi Zhao,Joshua Moller,Porfi Quintero-Cadena,Lood van Niekerk", "background": "治疗性抗体不仅需要高亲和力的靶点结合，还需要良好的可制造性、稳定性和安全性，这些特性统称为‘开发性’。为了利用计算框架优化抗体序列以提高开发性，本文介绍了一种指导性的离散扩散模型，该模型基于观察到的抗体空间（OAS）中的天然重链和轻链序列及246个临床阶段抗体的可开发性量化测量数据进行培训。该模型还结合了一个基于软价值解码的离散扩散模块（SVDD Module），以引导采样方向并在不失真自然性的前提下偏置采样。在不受约束的采样中，该模型重现了自然克隆库和批准治疗药物的全局特征。在SVDD引导下，我们显著提高了预测开发性评分，当与高通量可开发性生物检测试验结合使用时，该框架可以实现一个迭代的、基于机器学习驱动的抗体设计管道，以同时满足结合和生物物理标准。", "innovation": "引入了一种指导性的离散扩散模型，该模型基于观察到的抗体空间中的数据进行培训，并结合了一个软价值解码的离散扩散模块（SVDD Module）来偏置采样。该框架结合高通量可开发性生物检测试验，实现一个迭代的、基于机器学习驱动的抗体设计管道，能够同时满足结合和生物物理标准，显著提高了预测开发性评分。", "conclusion": "该框架可以实现一个迭代的、基于机器学习驱动的抗体设计管道，能够同时满足结合和生物物理标准，通过高通量可开发性生物检测试验的结合使用，显著提高了预测开发性评分。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02710", "html_url": "https://arxiv.org/abs/2507.02710", "title": "联邦数据聚合中的流体民主", "title_en": "Fluid Democracy in Federated Data Aggregation", "authors": "Aditya Vema Reddy Kesari,Krishna Reddy Kesari", "background": "联邦学习（FL）机制通常要求每个客户端向中央服务器传输其权重，而不管这些权重是否有用。为了减少不必要的数据传输成本，本文提出使用共识协议来确定在每次数据传输步骤中有最有用模型权重的客户端子集。研究了现有流体民主协议在性能方面的应用，并与传统的每人一票（也称为1p1v或FedAvg）进行比较。进一步探讨了在对抗性视角下流体民主协议的弱点及其对拓扑结构和/或需要多少个对手来负面影响全局模型权重的依赖性，提出了一个名为FedVRD的算法，该算法通过利用委托拓扑结构动态限制敌手的影响，同时尽量减少成本来应对这些问题。", "innovation": "提出了新的流体民主协议名为粘滞保留民主协议（viscous-retained democracy），该协议在相同假设下总是优于传统的一人一票制（1p1v），同时避免了影响积累的问题。此外，本文还提出了一种算法（FedVRD），通过利用委托拓扑结构动态限制敌手的影响来减轻负面影响，同时尽量减少成本。", "conclusion": "本文探讨了流体民主协议在联邦数据聚合中的应用，提出了一种新的流体民主协议并指出了现有协议的弱点。然后提出了一个名为FedVRD的算法，通过动态限制敌手的影响并利用委托拓扑结构来最小化成本。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02732", "html_url": "https://arxiv.org/abs/2507.02732", "title": "通过分离超曲面进行分类：一种熵方法", "title_en": "Classification by Separating Hypersurfaces: An Entropic Approach", "authors": "Argimiro Arratia,Mahmoud El Daou,Henryk Gzyl", "background": "本文探讨了经典的分类问题：给定由一组属性（表示为$\bm{R}^N$中的向量）描述的一批个体，目标是找到一个将两个不同类别的点集分开的超平面。这一问题具有悠久的历史，与感知机模型密切相关，仍然是机器学习中的核心问题。该领域使用的方法在过去几十年里不断发展，但仍存在改进的空间，尤其是在处理复杂决策边界时。", "innovation": "本文提出了一个创新的方法，通过在原点为中心的有界$N$维超立方体中搜索参数向量，并在${\bm{R}}^M$中搜索正向量，同时通过定义在未知变量空间上的熵基函数的最小化来实现。这种方法还能够推广到多项式表面，允许更复杂的决策界限来分离数据点。与传统的线性或二次优化方法（如支持向量机和梯度下降）相比，这提供了一种更具鲁棒性的替代方案，适用于多种分类任务，包括线性和非线性可分性。", "conclusion": "数值实验表明，该方法在处理各种分类任务时既有效又灵活，展示了其在处理不同可分性问题上的适应能力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02715", "html_url": "https://arxiv.org/abs/2507.02715", "title": "一种全面的机器学习框架用于微移动需求预测", "title_en": "A Comprehensive Machine Learning Framework for Micromobility Demand Prediction", "authors": "Omri Porat,Michael Fire,Eran Ben-Elia", "background": "无 scooter 作为一种便捷的都市微交通方式，已经成为环保和灵活的交通工具选择。这些服务能够提高首末站连接性、减少拥堵和排放，并与公共交通互补进行短距离旅行。然而，有效的管理依赖于精确的需求预测，这对于最优车辆分布和基础设施规划至关重要。尽管先前的研究集中于单独分析空间或时间因素，但本研究表明了一种结合空间、时间和网络依赖性的框架，以改善微移动需求预测。这种整合提高了预测准确性，同时提供了对城市微移动使用模式的更深入洞察。我们的框架在基本模型上将需求预测准确性提高了27%至49%，证明了其在捕捉微移动需求模式的有效性。这些结果支持基于数据驱动的微移动管理，实现车队最优分布、成本降低和可持续城市发展（略作背景介绍）。", "innovation": "提出了一个结合空间、时间和网络依赖性的框架来改善微移动需求预测，提高了预测准确性，并提供了更深入的城市微移动使用模式的见解。该框架在基本模型上提高了27%至49%的需求预测准确性，展示了其捕捉微移动需求模式的有效性。这为基于数据的微移动管理提供了支持，有助于优化车队分布、降低成本并实现可持续的城市规划", "conclusion": "研究结果证明了该框架的有效性，支持基于数据的微移动管理，实现了车队的最佳分布、成本降低和可持续的城市规划。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02712", "html_url": "https://arxiv.org/abs/2507.02712", "title": "一种用于连续控制中深度强化学习扩展的忘记与增长策略", "title_en": "A Forget-and-Grow Strategy for Deep Reinforcement Learning Scaling in Continuous Control", "authors": "Zilin Kang,Chenyuan Hu,Yu Luo,Zhecheng Yuan,Ruijie Zheng,Huazhe Xu", "background": "持续控制中的深度强化学习最近取得了显著进展，但现有方法经常面临优先效应偏见的问题，即倾向于过度拟合存储在重放缓冲区中的早期经验，这限制了强化学习代理的采样效率和概括能力。与人类相比，人类较少受到此类偏见的影响，部分原因在于婴幼儿期遗忘机制，即新生神经元的形成会破坏早期的记忆痕迹，导致忘记最初的体验。因此，受此大脑记忆促进和增长过程的启发，在本文中，我们提出了融合了两个机制的新深度强化学习算法——忘记与增长(FoG)。", "innovation": "我们提出了一个结合了Experience Replay Decay (ER Decay)和Network Expansion的新算法。ER Decay 通过逐步减少早期经验的影响来平衡存储。Network Expansion 则是通过动态增加新参数以增强代理利用现有数据模式的能力，从而扩展代理的神经计算能力。我们在四个主要的持续控制基准测试中进行了40多个任务的实验，结果表明FoG相对于其他先进的方法(SOTA)表现更优，包括BRO、SimBa和TD-MPC2。", "conclusion": "实验结果表明 Forget and Grow 算法在多个持续控制基准测试中表现出了显著的优势，从而证明了FoG算法的有效性，将强化学习的样本效率和概括能力提升到一个新的水平。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02754", "html_url": "https://arxiv.org/abs/2507.02754", "title": "Fast and Simplex: 2-简单形注意力在Triton", "title_en": "Fast and Simplex: 2-Simplicial Attention in Triton", "authors": "Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil", "background": "近期研究表明，训练损失与模型大小和令牌数量之间呈幂律关系，且要实现计算最优模型需要同时扩展模型大小和令牌数量。然而，这些缩放定律假设数据供应无限，并主要适用于计算限制场景。随着现代大型语言模型越来越多地依赖大规模的互联网数据集，假设它们是计算限制的变得不再合理。这一转变凸显了优先考虑令牌效率的架构的重要性。", "innovation": "本文研究了2-简单形Transformer，这是一种通过高效的Triton内核实现将标准点积注意力推广到三线性函数的架构。实验结果显示，2-简单形Transformer在固定令牌预算的情况下，对于涉及数学、编程、推理和逻辑的任务，性能优于其点积版本的模型。通过量化这些增益，本文证明2-简单形注意力改变了知识和推理任务中缩放定律中的指数值。", "conclusion": "2-简单形Transformer在保持模型大小相似的情况下，提高了令牌效率，并在其受试任务上优于标准的Transformer。这可能有助于在令牌限制更严格的场景中设计更高效的语言模型架构。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02814", "html_url": "https://arxiv.org/abs/2507.02814", "title": "可复制的分布测试", "title_en": "Replicable Distribution Testing", "authors": "Ilias Diakonikolas,Jingyi Gao,Daniel Kane,Sihan Liu,Christopher Ye", "background": "本文在算法可复制性框架下系统研究了分布测试问题。给定一组独立的概率分布的样本，目标是刻画在可复制性的前提下测试底层分布的天然属性所需的样本复杂度。", "innovation": "本文在算法层面开发了用于测试离散分布的接近性和独立性的可复制性算法。在下界研究方面，开发了一种新的方法论，以证明可复制性测试的样本复杂度下界，这种方法论具有更广泛的应用价值。此外，还利用该技术建立了接近最优的可复制均匀性测试和贴近性测试的样本复杂度下界，回答了以前研究中的开放式问题。", "conclusion": "本文通过系统地研究分布测试问题，不仅开发了新的可复制算法，还提出了新的方法论来证明可复制测试的样本复杂度下界。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02782", "html_url": "https://arxiv.org/abs/2507.02782", "title": "理解并改进递归模型中的长度泛化", "title_en": "Understanding and Improving Length Generalization in Recurrent Models", "authors": "Ricardo Buitrago Ruiz,Albert Gu", "background": "近期，由于其在序列长度上的线性复杂性，递归模型如状态空间模型和线性注意力越来越受欢迎。尽管这些模型理论上可以处理任意长的序列，但在超出它们的训练上下文长度之后，其性能有时会显著下降，即在长度泛化方面表现不佳。本文通过综合的实证和理论分析，支持了未探索状态假设，即模型在训练中仅接触到分布中的一部分状态（即在长序列中应用递归时可能达到的状态）时，在长度泛化方面会表现不佳。进一步研究了可以通过初始化状态为高斯噪声或不同输入序列的最终状态等简单的训练干预措施，来增加模型训练中状态的覆盖面。这些干预措施仅需少量的后训练步骤（约预训练预算的0.1%），就可以使模型在远超训练上下文长度的序列上实现长度泛化，从而提高了长上下文任务中的表现，提供了一种简单而有效的方法，以增强递归模型的稳健长度泛化能力", "innovation": "提出了未探索状态假设，并通过简单的训练干预措施，如初始化状态为高斯噪声或不同输入序列的最终状态，来增加模型在训练中所接触到的状态覆盖面。这些干预措施仅需少量的后训练步骤，就能使模型在远超训练上下文长度的序列上实现长度泛化，提升长上下文任务中的表现。", "conclusion": "本文通过简单的训练干预措施显著提高了递归模型在长序列上的泛化能力，提出了一种简单而有效的方法，这种干预措施只需要少量的步骤，就能使模型在远超训练上下文的序列长度上表现出良好的性能，从而增强递归模型的稳健长度泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02807", "html_url": "https://arxiv.org/abs/2507.02807", "title": "通过约束优化实现医疗中的训练期间多校准生存分析", "title_en": "In-Training Multicalibrated Survival Analysis for Healthcare via Constrained Optimization", "authors": "Thiti Suttaket,Stanley Kok", "background": "生存分析在医疗中是一个关键问题，因为它用于建模个体协变量与其感兴趣的事件（如死亡）的发生时间之间的关系。准确校准的生存模型对于临床决策的重要性不能忽视，因为不准确的模型可能导致错误的临床决策。现有的生存模型通常只在总体层面上进行校准，这可能导致某些少数子人群的模型校准性较差。因此，有必要开发一种能够多校准的生存分析模型来确保所有子人群的预测概率与真实概率之间的差距减小，以提高临床决策的准确性。", "innovation": "本文提出了一种名为GRADUATE的模型，通过确保所有子人群都得到充分校准来实现多校准。GRADUATE将多校准问题重新定义为带约束的优化问题，并在训练过程中同时优化校准和辨别度，以达到两者之间的良好平衡。这种方法被证明在数学上具有高度的近似最优性和可行性。通过数据集上的实证对比分析，证明了GRADUATE在实世界临床数据集上的有效性，揭示了其相对于现有基线模型的优势与劣势。", "conclusion": "GRADUATE模型在实证研究中证明了其有效性，并通过优化方法实现了多校准，这使得模型在多个人群中的表现更加均衡，提高了临床决策的质量和准确性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02843", "html_url": "https://arxiv.org/abs/2507.02843", "title": "基于大型语言模型的推理时文本混杂的治疗效果估计", "title_en": "LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding", "authors": "Yuchen Ma,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel", "background": "在医学中进行治疗效果估计对于个性化决策至关重要，但这一任务在临床实践中面临独特挑战。模型在训练时通常基于包含详细患者信息的结构化医疗数据集进行训练，但在预测时使用的往往是文本描述（如自我报告的症状描述），这些描述并不完全反映原始的患者信息，可能导致偏差。", "innovation": "本文提出了一个新颖的方法来解决推理时的文本混杂问题。该方法利用大型语言模型结合自定义双重稳健学习者，以减轻由于推理时文本混杂引起的偏差。这项工作正式提出了一个在训练时完全观察到的混淆因素但在推理时只有部分可用（inference time text confounding）的问题。", "conclusion": "一系列实验结果表明，本文提出的方法在实际应用中是有效的，能够减轻由于推理时文本混杂而引起的偏差。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02724", "html_url": "https://arxiv.org/abs/2507.02724", "title": "跨物种蛋白质-蛋白质相互作用预测的分层多标签对比学习", "title_en": "Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms", "authors": "Shiyi Liu,Buwen Liang,Yuetong Fang,Zixuan Jiang,Renjing Xu", "background": "近年来，AI在科学领域的进展突显了对比学习在连接异种生物数据模态中的作用。基于此范式，该论文提出了一种名为HIPPO（跨物种蛋白质-蛋白质相互作用预测的分层框架）的方法，用于蛋白质-蛋白质相互作用（PPI）预测，通过多层次的生物特征匹配将蛋白质序列及其分层属性对齐。该方法引入了模仿功能性蛋白质类别的结构关系的分层对比损失函数。框架通过数据驱动的惩罚机制整合了领域和家族知识，确保学习嵌入空间与蛋白质功能的内在层次结构一致。在基准数据集上的实验表明，HIPPO在性能上达到了最先进的水平，超过了现有方法，并在数据稀缺的情况下显示出鲁棒性。此外，该模型在无需重新训练的情况下展示了强大的零样本迁移能力，可用于其他物种，即使在实验数据有限的未表征或罕见物种中也能实现可靠的PPI预测和功能推断。进一步的分析表明，分层特征融合对于捕捉保守的相互作用决定因素（如结合基序和功能注释）至关重要。这项工作促进了跨物种PPI预测，并提供了在稀疏或多物种不平衡数据场景下统一交互预测的框架。", "innovation": "论文提出了一种名为HIPPO的分层对比学习框架（HIPPO: HIerarchical Protein-Protein interaction prediction across Organisms），能够克服不同物种间的数据稀缺问题。该方法通过多层次的生物特征匹配将蛋白质序列及其分层属性对齐，并引入了分层对比损失函数，使模型能够了解学习嵌入空间与蛋白质功能的内在层次结构。此外，该框架通过数据驱动的惩罚机制整合了领域和家族知识，提高了模型在数据稀缺情况下的鲁棒性，并显示了强大的零样本迁移能力。进一步分析表明，分层特征融合对于捕捉保守的相互作用决定因素至关重要。", "conclusion": "HIPPO在蛋白质-蛋白质相互作用（PPI）预测中表现出卓越的性能，并在基准数据集上达到了最先进的水平，显示了在数据稀缺情况下的鲁棒性。该模型在没有重新训练的情况下，在其他物种中具有强大的零样本迁移能力，且能更为可靠地进行PPI预测和功能推断。该工作为跨物种PPI预测和稀疏或多物种不平衡数据场景下统一交互预测的框架提供了重要进展。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02847", "html_url": "https://arxiv.org/abs/2507.02847", "title": "MvHo-IB: 多视图高阶信息瓶颈方法在脑部疾病诊断中的应用", "title_en": "MvHo-IB: Multi-View Higher-Order Information Bottleneck for Brain Disorder Diagnosis", "authors": "Kunyu Zhang,Qiang Li,Shujian Yu", "background": "最近的研究表明，在功能性磁共振成像(fMRI)数据中建模高阶交互（HOIs）可以提高机器学习系统的诊断准确性。然而，有效地提取和利用HOIs仍然是一个重大的挑战。", "innovation": "MvHo-IB引入了多种关键创新：（1）一个基于信息理论的O信息与矩阵形式的Rényi α阶熵估计器结合的方法，用于量化和提取HOIs；（2）一个专门为利用这些交互而设计的Brain3DCNN编码器；（3）一个新的多视图学习信息瓶颈目标，用于增强表示学习。", "conclusion": "在三个基准fMRI数据集上的实验结果表明，MvHo-IB达到了最先进的性能，明显优于包括最近的超图技术在内的先前方法。MvHo-IB的实现可以在以下网址获取：this https URL."}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01964", "html_url": "https://arxiv.org/abs/2507.01964", "title": "使用长短期记忆技术预测尼日利亚股票回报", "title_en": "Forecasting Nigerian Equity Stock Returns Using Long Short-Term Memory Technique", "authors": "Adebola K. Ojo,Ifechukwude Jude Okafor", "background": "投资者和股票市场分析师面临着预测股票回报和做出明智投资决策的重大挑战。股票回报的可预测性可以提升投资者信心，但这是一个困难的任务。研究通过使用长短期记忆（LSTM）模型来预测未来股票市场动向，旨在解决这一问题。研究使用了尼日利亚证券交易所（NSE）的历史数据，对数据进行了清理和归一化，设计了LSTM模型，并通过性能指标对模型进行了评估，与卷积神经网络（CNN）等其他深度学习模型进行了比较。实验结果显示，当使用可靠的数据集进行训练时，LSTM模型可以准确预测未来股票市场价格和回报，准确率超过90%。研究表明，如果训练得当，LSTM模型可以用于预测金融时间序列相关问题。未来的研究应该探索将LSTM模型与其他深度学习技术如CNN相结合，来创建能够减轻依赖单一模型风险的混合模型，以进行未来股票预测。", "innovation": "研究使用LSTM模型预测未来股票市场动向并取得了较好的准确性（超过90%），并将所设计的LSTM模型与其他深度学习模型进行了比较。该研究发现，如果训练得当，LSTM模型可以有效地预测金融时间序列相关的问题。未来研究应该探索将LSTM模型与其他深度学习技术（如CNN）相结合来创建混合模型的方法，以降低单一模型的预测风险。", "conclusion": "LSTM模型在训练得当的情况下可以有效地预测未来股票市场价格和回报。研究建议未来的研究可以探索结合LSTM与其他深度学习技术来创建混合模型的方法，以提高股票预测的准确性并降低风险。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01974", "html_url": "https://arxiv.org/abs/2507.01974", "title": "神经网络用于动物鸣声检测的声学评估", "title_en": "Acoustic evaluation of a neural network dedicated to the detection of animal vocalisations", "authors": "Jérémy Rouch(CRNL-ENES),M Ducrettet(CRNL-ENES, ISYEB),S Haupert(ISYEB),R Emonet(LabHC),F Sèbe(CRNL-ENES, OFB - DRAS)", "background": "长时工作记录器的应用使通过生态声学开展广泛的动物种群监测成为可能，尤其是在条件苛刻的野外环境。尽管自动信号检测方法越来越依赖神经网络等先进技术，但在提升检测系统的性能方面的声学分析却较少进行。", "innovation": "本文提出了一种基于合成信号的信噪比与其检测概率相关联的简单方法，用于评估神经网络检测系统的表现。该方法有助于系统优化训练，还能通过声学环境建模检测距离的变化，并提供一种评估呼叫声空间密度的方法。", "conclusion": "所提出的方法不仅能提供有关系统的详细信息，还能优化其训练过程，并根据声学环境动态评估检测能力，为检测距离建模提供了可能，从而精准估计动物叫声的空间密度。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02834", "html_url": "https://arxiv.org/abs/2507.02834", "title": "ExPO：利用自我解释引导强化学习解锁难点推理", "title_en": "ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning", "authors": "Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi", "background": "近期大规模语言模型的进步主要依赖于基于奖励或偏好信号的后训练强化学习（RL）优化。现有的GRPO风格方法通过自我生成的样本并由结果验证器进行标注来实现这一点，但这些方法高度依赖模型初具产生正面样本的能力。然而，这些方法主要用于细化模型已知的内容而不是帮助模型解决它最初无法解决的问题，尤其在早期强化学习训练和复杂的推理任务中，产生正样本的可能性较低。在这种情况下，模型需要探索超出当前输出分布的新推理路径。这种探索需要使用足够好的正样本来引导学习。尽管专家演示似乎是一个自然的解决方案，但发现它们在基于反馈的RL中往往无效。因此，研究认为有效的正样本应具备以下两个特性：（1）在当前策略下很可能是正确的，（2）能够增加模型预测正确答案的概率。基于以上见解，提出了一种名为ExPO的简单且模块化的框架，通过基于正确答案进行条件化生成这样的样本。ExPO能够高效探索并指导模型生成与当前策略更一致的推理路径，同时保证质量高于其自身错误的样本。", "innovation": "ExPO 是一种简单的模块化框架，通过基于正确答案进行条件化生成有效的正样本来引导强化学习，解决模型在解决难点推理问题时遇到的初始困难。ExPO 框架的特点是能够高效探索和指导模型生成与当前策略更一致的推理路径，确保了比专家演示方法更高的质量。在多项推理基准上的实验表明，ExPO 在提高学习效率和最终性能方面表现出色，特别是在 MATH 水平5这样的挑战性环境中，该模型最初表现最差的情景，ExPO 方法超过了基于专家演示的方法。", "conclusion": "ExPO 框架通过生成基于正确答案的正样本，提高了强化学习模型在处理难点推理问题时的探索效率和学习质量，尤其在初始训练阶段和复杂的推理任务中取得了显著效果，展现了增强模型推理能力的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01972", "html_url": "https://arxiv.org/abs/2507.01972", "title": "使用强化学习加速投资组合优化和期权定价", "title_en": "Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning", "authors": "Hadi Keramati,Samaneh Jazayeri", "background": "在投资组合优化和期权定价中，矩阵计算产生了大规模线性系统。直接求解高维投资组合或细网格期权定价会导致巨大的计算成本，因此通常使用迭代方法。然而，这类系统条件不佳时会导致收敛速度慢。传统预条件技术需要针对特定问题进行参数调优，以克服这一局限，该研究使用强化学习动态调整块预条件器大小，以加速求解器的收敛速度，从而降低计算成本并加快决策过程。", "innovation": "提出了一个强化学习驱动的框架，用于优化投资组合优化和期权定价中使用的迭代求解器中块预条件器的大小。通过使用RL动态调整预条件器大小，能够显著加速收敛，减少计算成本，并支持更快速的决策过程，尤其适用于动态投资组合分配和实时期权定价。", "conclusion": "实验结果表明，提出的RL框架能够有效地调整预条件器，显著提高收敛速度和减少计算成本。这种加速的方法能够支持在动态投资组合分配和实时期权定价中的更快决策。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01971", "html_url": "https://arxiv.org/abs/2507.01971", "title": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification", "title_en": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification", "authors": "Boris Kriuk,Logic Ng,Zarif Al Hossain", "background": "技术分析中支撑与阻力（Support and Resistance, SR）水平是核心要素，指导交易者进行入场、出场和风险管理。然而，传统SR识别方法难以适应现代市场复杂和波动性特点。现有研究主要通过机器学习技术改进，但多注重价格预测而非结构层次识别。", "innovation": "本文提出了一种新的基于深度学习的检测金融支撑水平的方法——DeepSupp。该方法利用多头注意力机制分析空间相关性和市场微观结构关系，并结合先进的特征工程，构建动态相关矩阵捕捉市场关系演变。采用基于注意机制的自编码器进行稳健的表示学习，通过非监督聚类（使用DBSCAN）提取最终支撑水平。实验结果表明，DeepSupp在六个金融指标上优于六种基准方法，显示出在六条S&P 500时间序列上的最佳性能，且能在不同市场条件下保持一致结果，解决了SR水平识别的关键问题，提供了现代金融分析的可扩展和可靠方案。", "conclusion": "DeepSupp通过注意力机制和动态相关矩阵分析，提高了SR水平识别的准确性，特别是在不同市场条件下都能保持优秀结果，填补了传统方法在复杂市场环境中的不足。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01976", "html_url": "https://arxiv.org/abs/2507.01976", "title": "网络流量合成综述：从统计模型到深度学习", "title_en": "A Comprehensive Survey on Network Traffic Synthesis: From Statistical Models to Deep Learning", "authors": "Nirhoshan Sivaroopan,Kaushitha Silva,Chamara Madarasingha,Thilini Dahanayaka,Guillaume Jourjon,Anura Jayasumana,Kanchana Thilakarathna", "background": "合成网络流量生成在数据驱动的网络应用领域中作为一种有前途的替代方案正在兴起。它使得创建保留真实世界特性的合成数据成为可能，同时解决了与真实数据相关的关键挑战，如数据稀缺性、隐私问题和纯度限制。本文综述了合成网络流量生成方法，涵盖了数据类型、生成模型和评估方法等关键方面。随着人工智能和机器学习的快速发展，本文特别关注基于深度学习的技术，同时对统计方法及其扩展进行了详细的讨论，包括商业可用的工具。", "innovation": "本文综述了合成网络流量生成方法，特别强调了基于深度学习的技术，并对统计方法及其扩展进行了详细讨论，提供了商业可用工具的讨论，并指出了该领域的开放挑战及未来研究方向。", "conclusion": "本文作为研究人员和实践者的基础资源，提供了现有方法、挑战和机遇的结构化分析，对于进一步的研究和开发具有指导意义。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01970", "html_url": "https://arxiv.org/abs/2507.01970", "title": "新闻情感嵌入在股票价格预测中的应用", "title_en": "News Sentiment Embeddings for Stock Price Forecasting", "authors": "Ayaan Qayyum", "background": "本文探讨了如何使用头条数据来预测股票价格。研究对象是SPDR S&P 500 ETF Trust（代号SPY），它跟踪美国最大500家上市公司表现。文章的重点在于通过OpenAI基于文本的嵌入模型和主成分分析（PCA），将《华尔街日报》(WSJ)的新闻标题转化为向量编码，用以预测日级别的股票价格变动。这项工作的挑战在于捕捉新闻对股票价格的时间依赖性和非时间依赖性的影响，同时处理潜在的时间滞后效应和市场噪声。为了增强模型性能，本文采用了多种金融和经济数据，例如美元指数（DXY）和国债收益率。共有超过390个机器学习推理模型被训练。初步结果显示，头条数据嵌入有助于至少提高40%的股票价格预测准确性，相比于未使用头条数据嵌入的机器学习系统训练和优化而言。", "innovation": "本文的创新之处在于提出了一种基于OpenAI的文本嵌入模型和主成分分析的方法，来处理新闻标题数据，以预测股票价格。这种方法能更好地捕捉新闻与股票价格之间的复杂关系，提高了预测的准确性。此外，通过对机器学习模型的广泛训练，本文展示了新闻头条数据在提升股票价格预测性能中的重要作用。", "conclusion": "本文证明了使用基于文本的嵌入模型和考虑主要成分分析的新闻头条数据来预测股票价格的有效性。相对于不使用这些新闻数据的机器学习模型，这种方法能够显著提高预测准确性至少40%。未来的工作可以进一步探索其他数据源和模型优化策略，以进一步提高预测精度。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01979", "html_url": "https://arxiv.org/abs/2507.01979", "title": "使用LSTNet预测劳动力市场：一种多尺度深度学习方法", "title_en": "Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach", "authors": "Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi", "background": "本文提出了利用美国劳工统计局的劳动力市场数据，使用深度学习方法预测短期就业变化及评估长期行业健康状况的研究。背景包括现有的预测模型和指数在评估行业健康方面存在的不足，以及如何通过引入新的多变量时间序列处理方法来改进现有的预测和评估方法。", "innovation": "本文的创新点在于提出了一种结合长短期时间序列网络（LSTNet）的深度学习方法，用于处理包括就业水平、工资、流失率和空缺职位等多变量时间序列数据，输出7天的就业预测结果和可解释的行业就业健康指数（IEHI）。该方法在大多数行业中优于基线模型，特别是在稳定行业中的表现更为显著，并且IEHI排名与实际就业波动之间表现出良好的一致性。此外，该研究还分析了误差模式和不同行业中的具体表现，并对未来进一步增强可解释性和泛化提出了展望。", "conclusion": "研究结果表明，LSTNet方法在预测短期就业变化和评估长期行业健康方面具有显著优势，特别是在稳定行业中。IEHI能够提供对行业健康状况的有用见解，同时该模型的误差模式和不同行业的表现也提供了进一步改进的方向。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00884", "html_url": "https://arxiv.org/abs/2507.00884", "title": "基于线性张量四边形注意力的可扩展且量子准确的分子力场基础模型", "title_en": "A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention", "authors": "Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou", "background": "精确的原子级生物分子模拟对于疾病机制理解、药物发现和生物材料设计至关重要，但现有的模拟方法存在显著局限性。经典力场方法效率高但缺乏对于过渡态和细致构象的信息准确性，而量子力学方法虽然高度准确但难以进行大规模或长时间的模拟。基于人工智能的力场（AIFFs）旨在兼顾效率和准确性，但在建模复杂性、准确性和速度之间的平衡上存在困难，且受限于有限的训练数据和不足的一般化验证。", "innovation": "本文介绍了LiTEN，一种新型的有TQA（张量四边形注意力）的可变神经网络，通过向量操作重新参数化高阶张量特征，用线性复杂度高效建模三体和四体相互作用，从而绕过了昂贵的球谐函数，避免了昂贵计算。基于LiTEN构建了LiTEN-FF，这是一种强大的AIFF基础模型，先在广泛的nablaDFT数据集上预训练，然后针对SPICE进行精细调整，从而实现广泛化学泛化的广泛应用。LiTEN在rMD17、MD22和Chignolin等多个评估子集上达到了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF还为包括量子级构象搜索、几何优化和自由能表面构建在内的广泛下游生物分子建模任务提供了最快的推理速度，比MACE-OFF快10倍，适用于大规模生物分子。", "conclusion": "本文介绍了一种以物理原理为基础、高效的框架，推动了复杂的生物分子建模的发展，为药物发现及相关应用提供了灵活的基础。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01980", "html_url": "https://arxiv.org/abs/2507.01980", "title": "在金融网络中检测欺诈：基于Granger因果解释的半监督GNN方法", "title_en": "Detecting Fraud in Financial Networks: A Semi-Supervised GNN Approach with Granger-Causal Explanations", "authors": "Linh Nguyen,Marcel Boersma,Erman Acar", "background": "金融行业的欺诈活动每年造成数十亿美元的损失，因此检测欺诈是一个关键但技术上有挑战的任务。虽然机器学习方法似乎是可行的解决方案，但由于数据稀疏标记和模型不透明性，成功应用这些方法并非易事。", "innovation": "提出了SAGE-FIN，一种基于半监督图神经网络（GNN）的方法，并使用Granger因果关系进行解释。SAGE-FIN能够根据弱标记（或未标记）数据点识别欺诈项目，并通过Granger因果关系突出显示网络中的相关项目来解释标记的项目，以满足业务法规要求。该方法在实际数据集Elliptic++上进行了实证验证，实现了良好的性能，并提供了Granger因果解释，而无需假设网络结构。", "conclusion": "SAGE-FIN方法在现实世界的数据集上证明了其优势，能够识别出欺诈项目，并通过Granger因果解释满足监管要求。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02011", "html_url": "https://arxiv.org/abs/2507.02011", "title": "基于机器学习的印度金融市场组合压力测试框架", "title_en": "Machine Learning Based Stress Testing Framework for Indian Financial Market Portfolios", "authors": "Vidya Sagar G,Shifat Ali,Siddhartha P. Chakrabarty", "background": "本文介绍了一种基于机器学习的压力测试框架，用于印度金融市场的行业水平压力测试，重点关注金融服务、信息技术、能源、消费品和制药等行业。首先，作者解决了传统压力测试中的局限性，通过主成分分析和自动编码器进行降维和潜在因子建模。在此基础上，进一步使用变分自动编码器，引入了潜在空间中的概率结构，通过蒙特卡洛场景生成模拟压力市场条件。该框架能够捕捉复杂非线性依赖关系并支持通过风险价值和预期短缺来进行风险估算。这些流程展示了机器学习方法在提高金融压力测试的灵活性、稳健性和真实性方面的潜力。", "innovation": "该文提出了一种基于机器学习的压力测试框架，采用了主成分分析、自动编码器和变分自动编码器等方法，通过降维和潜在因子模型来解决传统压力测试的局限性。变分自动编码器在潜在空间中引入了概率结构，使得能够进行蒙特卡洛场景生成，从而更精确地模拟压力市场条件，并更好地捕捉复杂非线性依赖关系。", "conclusion": "该框架通过机器学习方法提高了金融压力测试的灵活性、稳健性和真实性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02073", "html_url": "https://arxiv.org/abs/2507.02073", "title": "HCVR: 一种基于相关性投票规则的混合特征筛选方法", "title_en": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection", "authors": "Nikita Bhedasgaonkar,Rushikesh K. Joshi", "background": "本文介绍了一种新的特征选择方法HCVR（Hybrid approach with Correlation-aware Voting Rules），这是一种基于规则的轻量级特征选择方法，结合了Parameter-to-Parameter (P2P) 和 Parameter-to-Target (P2T) 相关性来消除冗余特征并保留相关的特征。该方法是一种混合了非迭代和迭代滤波方法的降维方法。它是一个贪婪方法，通过向后消除步骤进行工作，在每一步中可能会消除多个特征。规则用于投票特征选择，并通过多数票决策来决定保留或丢弃特征。该方法利用了每对特征之间的相关性阈值以及特征与目标之间的相关性阈值。采用HCVR方法在SPAMBASE数据集上的结果表明与传统非迭代（CFS, mRMR和MI）和迭代（RFE, SFS和遗传算法）技术相比，该方法具有更好的性能。性能基于应用过滤后的不同分类器的性能进行了评估。", "innovation": "HCVR方法的创新之处在于它结合了非迭代和迭代的降维方法，使用规则进行特征选择，通过投票机制决定保留或去除特征，利用特征之间的相关性和特征与目标之间的相关性进行特征选择。这种方法在SPAMBASE数据集上表现优于传统的特征选择方法。", "conclusion": "本文提出的方法HCVR在SPAMBASE数据集上的应用结果显示，该方法比传统的非迭代（CFS, mRMR和MI）和迭代（RFE, SFS和遗传算法）特征筛选方法具有更好的性能。通过性能评估表明，该方法是一种有效的特征选择方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02018", "html_url": "https://arxiv.org/abs/2507.02018", "title": "NGAT: 基于节点级别的图注意网络在长期股票预测中的应用", "title_en": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction", "authors": "Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong", "background": "图表示学习方法在金融应用中被广泛使用，以通过利用企业之间的关系来增强公司表示。然而，当前的方法面临三大挑战：(1) 关系信息的优势因下游任务设计的限制而被削弱；(2) 特别设计用于股票预测的图模型往往过于复杂，缺乏泛化能力；(3) 基于经验构建的企业关系图缺乏不同的图结构有效性比较。", "innovation": "本文提出了一种长期股票预测任务，并开发了一种专门适用于企业关系图的节点级别图注意力网络(NGAT)。此外，实验证明现有基于模型下游任务性能的图比较方法存在局限性，实验结果表明所提任务和模型在两个数据集上的有效性。该项目源代码在GitHub上公开，以促进可重复性和未来研究。", "conclusion": "本文提出了一种专门针对企业间关系的长期内股票预测任务，并开发了一个节点级别的图注意力网络(NGAT)。实验结果表明该方法在两个数据集上有效，并公开源代码以鼓励未来研究。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01990", "html_url": "https://arxiv.org/abs/2507.01990", "title": "将大型语言模型集成到金融投资和市场分析中：一项文献综述", "title_en": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "authors": "Sedigheh Mahdavi,Jiating(Kristin)Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh", "background": "大型语言模型（LLMs）已在金融决策中得到应用，增强了投资策略的分析能力。传统的投资策略主要依赖定量模型、基本面分析和技术指标。然而，LLMs能够处理和分析大量结构化和非结构化数据，提取有重要意义的信息，并在实时中增强决策过程。本文综述了近年来LLMs在金融领域的应用研究，分为四大类框架：基于LLMs的框架和管道、混合集成方法、微调和适应方法，以及基于代理的架构。该研究还详细回顾了LLMs在股票选择、风险评估、情绪分析、交易和金融预测中的应用。现有的文献回顾揭示了LLMs在金融市场中的能力和挑战，并指出了未来的研究方向。", "innovation": "本文提供了一个结构化的LLMs在金融领域研究的回顾，分类总结了四大类研究贡献，具体探讨了LLMs在多个金融方面的应用，如股票选择、风险评估、情绪分析、交易和金融预测。此外，该研究还指出了目前应用中的能力和挑战，以及未来可能的研究方向，推动了LLMs在金融领域的应用创新。", "conclusion": "本文综述了近年来LLMs在金融领域的应用研究，强调了现有的能力和挑战，并指出了未来的研究方向。该研究为推进LLMs在金融投资和市场分析中的应用提供了基础，有助于进一步探索和开发LLMs在金融领域的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01987", "html_url": "https://arxiv.org/abs/2507.01987", "title": "在开放银行环境下预测和解释客户数据共享", "title_en": "Predicting and Explaining Customer Data Sharing in the Open Banking", "authors": "João B. G. de Brito,Rodrigo Heldt,Cleo S. Silveira,Matthias Bogaert,Guilherme B. Bucco,Fernando B. Luce,João L. Becker,Filipe J. Zabala,Michel J. Anzanello", "background": "开放银行的出现标志着金融数据管理的重要转变，影响了金融机构的市场动态和营销策略。增加的竞争创造了机遇和挑战，机构需要管理数据流入以改进产品和服务，同时减少可能帮助竞争对手的数据流出。", "innovation": "该研究引入了一个框架来预测客户通过开放银行共享数据的倾向，并通过解释性模型分析法（EMA）进行解释。采用了一种结合ADASYN和NEARMISS技术的混合数据平衡策略来解决数据共享不频繁的问题，并提升了XGBoost模型的训练效果。结果表明，这些模型准确预测了客户数据共享行为，显示了91.39%的流入准确性和91.53%的流出准确性。结合Shapley Additive Explanations (SHAP)方法与Classification and Regression Tree (CART)技术，揭示了关键因素包括移动渠道的交易和购买数量、与这些渠道的互动和信贷相关的特征，特别是全国性银行系统中的信用卡使用情况。这些结果强调了移动参与和信贷在推动客户数据共享行为中的关键作用，为金融机构提供了增强竞争优势和创新的战略洞察。", "conclusion": "研究结果显示，通过开放银行预测客户数据分享的关键因素包括移动参与和信贷利用。这些发现为金融机构在开放银行环境中提升了竞争力和创新能力提供了宝贵的策略指导。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02014", "html_url": "https://arxiv.org/abs/2507.02014", "title": "ManifoldMind：动态双曲推理在可信赖推荐中的应用", "title_en": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations", "authors": "Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic", "background": "该论文提出了ManifoldMind，一种在双曲空间中超曲面推理的概率几何推荐系统，用于探索性推理。之前的类似系统常采用固定的曲率和刚性嵌入方式，ManifoldMind将用户、物品和标签表示为自适应曲率的概率球体，这种方法支持个性化不确定性的建模和几何感知的语义探索。论文在四个公共基准测试上进行了实验，结果表明相比强力基准，ManifoldMind在归一化降增益（NDCG）、校准度和多样性方面表现出更优异的性能。此外，ManifoldMind生成的推理痕迹可以实现在稀疏或抽象领域中的透明、可信赖且探索导向的推荐。", "innovation": "ManifoldMind是一种在双曲空间中工作的概率几何推荐系统，能够自适应地表示用户、物品和标签。系统的创新之处在于支持个性化和几何感知的语义探索，具有语义软推理能力和扩展的概念路径探索，从而避免过度拟合浅层或直接交互。此外，系统还能够生成明确的推理痕迹，帮助更透明和可信赖的推荐。", "conclusion": "实验结果证明，ManifoldMind在多个公开基准测试中优于现有方法，尤其在NDCG、校准度和多样性上表现出色。ManifoldMind的特征使其在稀疏或抽象领域中的推荐更加透明、可信赖，且能够驱动探索性推荐。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02084", "html_url": "https://arxiv.org/abs/2507.02084", "title": "基于中值绝对偏差的自适应迭代软阈值算法", "title_en": "Adaptive Iterative Soft-Thresholding Algorithm with the Median Absolute Deviation", "authors": "Yining Feng,Ivan Selesnick", "background": "自适应迭代软阈值算法（adaptive ISTA）是一种在无需显式调整正则化参数λ的情况下解决LASSO问题的有效算法，尽管它在实践中取得了成功，但理论研究相对较少。该算法通过阈值策略估计噪声水平来实现自适应性，但仍缺乏相关的理论分析。因此，对该算法的理论研究是有必要的，以更好地理解其特性和收敛行为.", "innovation": "该研究首次对基于中值绝对偏差的自适应 ISTA 进行了理论分析，揭示了算法的若干重要特性，如尺度不变性、非唯一性和局部稳定性，并证明了其局部线性收敛性和全局收敛性。这为自适应 ISTA 提供了坚实的理论基础，有助于其实用性和应用范围的扩展.", "conclusion": "研究证明了基于中值绝对偏差的自适应 ISTA 在局部线性收敛性和全局收敛行为方面的性质。这些发现不仅丰富了对于 LASSO 问题的自适应算法的理解，也为未来的理论研究和实际应用提供了重要的参考和依据。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02076", "html_url": "https://arxiv.org/abs/2507.02076", "title": "在预算之内推理：LLMs中自适应和可控测试时计算的综述", "title_en": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "authors": "Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates", "background": "大型语言模型（LLMs）已经迅速发展成为能够解决广泛任务的通用代理，但它们在推理方面的效率仍然不足：无论任务难度如何，它们在推理过程中都会消耗固定的计算资源，导致对于简单任务过度推理，对于困难任务则推理不足。该综述旨在提供一种全面的方法来改善LLMs的推理计算效率，通过分析自适应和可控测试时计算（TTC）策略，识别关键权衡，并讨论新兴趋势，为未来的LLMs研究提供指导。", "innovation": "引入了一种两级分类法，区分L1可控性和L2适应性，前者在固定计算预算下操作，后者根据输入难度或模型信心动态调整推理。该综述重点强调了TTC方法的实践控制、适变性和可扩展性，与之前的高效推理综述相比，更加关注这些方面。此外，还讨论了混合推理模型的新兴趋势，并指出了未来工作中的关键挑战，旨在使LLMs更具计算效率、稳健性和对用户约束的响应性", "conclusion": "通过对领先私有LLMs在多种数据集上进行基准测试，指出了推理性能和令牌使用之间的关键权衡。文章强调了在实际应用中TTC方法的重要性，并指出了未来的研究方向，旨在提高LLMs的计算效率、稳健性和适应用户约束的能力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02098", "html_url": "https://arxiv.org/abs/2507.02098", "title": "基于高斯过程模型的鲁棒自适应模型预测控制公式", "title_en": "A robust and adaptive MPC formulation for Gaussian process models", "authors": "Mathieu Dubied,Amon Lahr,Melanie N. Zeilinger,Johannes Köhler", "background": "本文提出了一个鲁棒且自适应的模型预测控制(MPC)框架，用于受有界干扰和未建模非线性影响的不确定非线性系统。通过使用高斯过程(GP)来根据嘈杂的测量值学习不确定的动力学，包括系统运行过程中收集的数据。背景信息强调了现有控制方法在处理此类复杂系统时的局限性，如难以建模的地效等，突出了改进的迫切需求。", "innovation": "该研究的关键贡献在于通过收缩度量推导出GP模型的鲁棒预测，并将其纳入MPC公式中。该设计保证了递归可行性和鲁棒约束满足，同时以高概率趋向于参考状态。通过提出的方法，显著提升了系统的响应性能，并通过在线学习进一步增强了鲁棒预测方法的效果。", "conclusion": "通过详细的数值模拟，特别是针对一个计划内无人机的例子，显示了方法的有效性及在面对难以建模的地效时的显著改进。该MPC设计确保了系统的稳定性和性能，同时高度依赖于GP模型的学习过程和收缩度量的应用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02190", "html_url": "https://arxiv.org/abs/2507.02190", "title": "cVLA: 向高效的相机空间VLA迈进", "title_en": "cVLA: Towards Efficient Camera-Space VLAs", "authors": "Max Argus,Jelena Bratulic,Houman Masnavi,Maxim Velikanov,Nick Heppert,Abhinav Valada,Thomas Brox", "background": "视觉-语言-行动（VLA）模型为解决复杂机器人操作任务提供了有吸引力的框架，但训练成本高昂。现有的VLA模型往往输出低级控制指令，且需要大量的数据和计算资源，这增加了训练成本和时间。因此，研究更为高效且机器人本体无关的VLA模型具有实际意义和应用价值。", "innovation": "本文提出了一种新颖的VLA方法，其利用视觉语言模型（VLMs）在2D图像上的高表现力，直接根据图像坐标系预测机器人末端执行器的姿态，与以往输出低级控制指令的VLA模型不同，本文的模型预测轨迹节点，这使得模型更易于训练且与机器人本体无关。研究还探索了深度图像、推理时间技术以及演示条件下的动作生成的潜在用途，能够在保持模型轻量级设计的同时有效学习有意义且可执行的机器人轨迹。", "conclusion": "本文模型在模拟数据集上进行训练，并能够实现从模拟到现实的迁移能力强。通过虚拟和现实数据的双重评估，证明了其在现实机器人系统中的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02125", "html_url": "https://arxiv.org/abs/2507.02125", "title": "人工智能能解决区块链预言机问题吗？拆解挑战与可能性", "title_en": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities", "authors": "Giulio Caldarelli", "background": "区块链预言机问题是将可靠的外部数据注入去中心化系统的一项挑战，这是无信任应用发展的根本限制。尽管近年来出现了多种架构、密码学和经济策略以缓解这一问题，但尚未有一个方法能够彻底解决区块链如何获取外部世界知识的根本问题。本文通过分析学术文献和实际应用案例，探讨了人工智能技术如何提升预言机系统的数据质量、来源选择和系统韧性，但同时也指出，人工智能无法完全消除对不可验证的外部输入的依赖。因此，本文强调人工智能应作为更广泛预言机设计中推理和过滤的补充层，而非信任假设的替代品。", "innovation": "本文通过综合学术文献和实际案例，评估了人工智能在解决区块链预言机问题中的潜在作用，特别是在数据质量提升、来源选择以及系统弹性方面提出了新的见解。强调了人工智能是一种增强预言机系统的工具，而不是彻底解决方案。", "conclusion": "人工智能能够提供强大的工具来改进数据质量、选择数据来源和提高系统韧性，但它无法彻底消除对不可验证外部输入的依赖。因此，应将人工智能视为预言机设计中的辅助层，而不能替代信任假设。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02171", "html_url": "https://arxiv.org/abs/2507.02171", "title": "基于自监督RNN的生物启发机器人轨迹规划", "title_en": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN", "authors": "Miroslav Cibula,Kristína Malinovská,Matthias Kerzel", "background": "机器人轨迹规划理解为生成指令序列，引导机器人或其执行器从初始状态到目标状态，同时考虑到机器人运动学和环境的约束，以完成操作任务。通常，这种任务通过采样算法来实现，但这些算法计算量大。近年来的研究显示，可以通过监督序列学习轨迹，如神经网络架构经过一次或固定次数的训练即可完成，从而保证了有限的计算时间。然而，这类全监督方法侧重于模仿学习，不依据轨迹能否成功达到目标进行学习，而是试图复制观察到的路径。", "innovation": "本文提出了基于递归架构的认知启发式自监督学习方案，用于构建轨迹模型。这种方法在臂部机械臂的运动学规划任务中进行了评估，并表明该模型能够在仅使用正向和逆向运动学模型配对数据的情况下学习生成轨迹，这表明了该新方法可以促进需要适应性解决方案的更复杂操作任务的规划。", "conclusion": "本文方法表明自监督RNN可以在无监督学习中有效生成机器人轨迹，而无需依赖大量的标记数据，为复杂操作任务的自适应规划提供了新的可能性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02086", "html_url": "https://arxiv.org/abs/2507.02086", "title": "选择性特征重编码的联合优化量子卷积神经网络在图像分类中的应用", "title_en": "Selective Feature Re-Encoded Quantum Convolutional Neural Network with Joint Optimization for Image Classification", "authors": "Shaswata Mahernob Sarkar,Sheikh Iftekhar Ahmed,Jishnu Mahmud,Shaikh Anowarul Fattah,Gaurav Sharma", "background": "量子机器学习（QML）在近似中尺度量子（NISQ）设备改进的推动下取得了显著进展，其中量子原理（如纠缠和超位置）被应用于量子卷积神经网络（QCNN），使其在分类量子和经典数据方面取得了喜人的成果。本文在此背景下研究了QCNN在图像分类中的应用，并提出了一种新的特征处理策略和QCNN架构以提高分类准确性。", "innovation": "文章提出了选择性特征重编码策略，引导量子电路优先处理最具信息量的特征；设计了一种新颖的并行模式QCNN架构，该架构同时整合了由两种经典方法（主成分分析PCA和自动编码器）提取的特征，并在统一训练方案中进行了联合优化。这种联合优化允许QCNN从互补的特征表示中受益，从而更好地调整模型参数。", "conclusion": "通过在MNIST和Fashion MNIST数据集上进行的全面实验表明，选择性特征重编码方法显著提高了量子电路的特征处理能力和性能。此外，联合优化的并行QCNN架构在二分类任务中表现出优于传统独立学习后集成决策融合的个体QCNN模型，验证了其优越的准确性和泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02176", "html_url": "https://arxiv.org/abs/2507.02176", "title": "分析与改进语音合成中的说话人相似性评估", "title_en": "Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis", "authors": "Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi", "background": "语音身份建模具有挑战性，因为语音具有多维性质。在生成语音系统中，身份通常通过自动说话人验证(ASV)嵌入进行评估，这些嵌入旨在区分不同说话人而不是刻画身份特征。已有研究发现，广泛使用的ASV嵌入主要关注诸如音色和音高范围等静态特征，而忽略了节奏等动态元素。此外，还存在一些妨碍说话人相似性测量的因素。因此，研究如何评估说话人身份一致性尤其重要，特别是在不断改进的语音克隆系统中。目前缺乏有效评估动态节奏模式的方法，这也是本研究的背景。", "innovation": "论文提出了U3D指标，专门用于评估说话人的动态节奏模式。这是首次将动态节奏纳入到说话人相似性评估中，填补了传统ASV嵌入在评估动态特征方面的空白。此外，论文还识别了一些混淆因素并提出了缓解策略，这将有助于提高说话人相似性评估的准确性。", "conclusion": "本文的工作聚焦于评估说话人身份一致性中的不足，并通过提出U3D指标加以改进。同时，也分析了说话人相似性测量中的一些混淆因素，并提供了缓解策略。最终，该研究有助于提高语音合成技术中说话人身份评估的一致性和准确性，这对于不断进步的语音克隆系统来说至关重要。该研究还通过公开发布代码的方式向公众展示了其研究成果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02212", "html_url": "https://arxiv.org/abs/2507.02212", "title": "SciGA: 学术论文中设计图形摘要的综合数据集", "title_en": "SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers", "authors": "Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi", "background": "图形摘要（GAs）在科学论文中起着关键作用，通过视觉方式传达研究的要点。虽然最近的研究已将图1等可视化材料越来越多地用作事实上的GA，但这些可视化材料增强科学交流的能力仍未得到充分探索。此外，设计有效的GA需要高级的可视化技能，这成为其广泛应用的障碍。因此，需要一个综合数据集来支持GA的选择和推荐，以及促进自动GA生成的研究。为解决这些挑战，我们引入了包含约145,000篇科学论文和114万幅图的SciGA-145k数据集。我们定义了两个任务：1）在现有论文内部进行GA推荐，这是找到适合作为GA的图；2）跨论文进行GA推荐，通过检索其他论文中的GA来激发新的GA创作。我们还提出了一个新的推荐度量标准——置信度调整的 top-1 地面真实比例 (CAR)，该标准能够细致分析模型的行为，并处理单个论文中多个图都可作为GA的情况，这弥补了传统排序度量的不足。", "innovation": "SciGA-145k 数据集的创新之处在于，它提供了大规模的学术论文和图形数据，专门用于支持GA的选择和推荐，以及促进自动GA生成。通过定义两个任务——在现有论文内部推荐适合作为GA的图，以及跨论文推荐其他论文中的GA进行激励——SciGA-145k 为可视化科学交流的发展奠定了基础，并促进了AI在科学领域的应用。", "conclusion": "SciGA-145k 数据集为推动图形摘要的使用和自动化生成奠定了基础，并为AI在科学交流中的应用贡献了重要数据支持。通过定义具体任务和提出新的推荐度量标准，该数据集明确了未来研究的方向，促进了科学可视化和人工智能领域的发展。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02199", "html_url": "https://arxiv.org/abs/2507.02199", "title": "潜推理链？深度递归Transformer解码", "title_en": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "authors": "Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu", "background": "链式思考（CoT）推理使基于变换器的语言模型在复杂数学和多步规划方面表现出色。然而，在标准的解码器架构中，这些推理步骤以自然语言形式外部化，这虽然提高了可解释性，但代价是效率降低。为捕捉难以用文字代表的推理，许多研究探索了递归架构，旨在将推理内置于潜在空间中，可能支持潜在CoT。", "innovation": "研究了Huginn-3.5B这种深度递归Transformer模型，在不增加参数数量的情况下重复使用层以推断，探讨其内部行为在算术任务上的表现，使用一系列探针技术如Logit Lens和Coda Lens。结果发现有限的可解释潜在CoT证据，并且递归块之间存在显著的探针不一致性，隐藏状态的解释性取决于层索引和解码方法。研究表明加深递归深度仅带来边际收益，远不及显式外部化推理步骤的模型", "conclusion": "研究表明，递归深度增加的收益有限，且均未达到显性外部化推理步骤的模型效果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02215", "html_url": "https://arxiv.org/abs/2507.02215", "title": "混合最小二乘法用于从高度噪声数据中学习函数", "title_en": "Hybrid least squares for learning functions from highly noisy data", "authors": "Ben Adcock,Bernhard Hientzsch,Akil Narayan,Yiming Xu", "background": "研究如何在高度污染数据的情况下高效估计条件期望。现有方法在小噪声环境下表现良好，但在大噪声环境下效率较低。", "innovation": "提出了一种结合Christoffel采样和特定类型的最优实验设计的混合方法。这种方法在样本点生成和噪声平滑方面都具有适当的最优属性，提高了计算效率和样本复杂度。此外，该方法还扩展到了受凸约束的设置，并提供了相似的理论保证。对于目标函数作为随机场的期望值的情况，方法扩展利用了自适应随机子空间，并建立了关于自适应过程的近似能力的结果。", "conclusion": "理论结果通过合成数据的数值研究和计算金融中的更具挑战性的随机模拟问题得到了支持。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02255", "html_url": "https://arxiv.org/abs/2507.02255", "title": "Listwise Preference Alignment Optimization for Tail Item Recommendation", "title_en": "Listwise Preference Alignment Optimization for Tail Item Recommendation", "authors": "Zihao Li,Chao Yang,Tong Zhang,Yakun Chen,Xianzhi Wang,Guandong Xu,Daoyi Dong", "background": "偏好对齐在大型语言模型（LLMs）中取得了更大的成功，并吸引了推荐研究领域的广泛关注。现有的偏好对齐方法要么需要显式的奖励建模，要么仅支持对偏好进行两两对比。前者直接增加了计算成本，后者限制了训练效率。此外，尚无现有研究探索偏好对齐在尾部项目推荐中的应用。", "innovation": "我们提出了LPO4Rec，该方法扩展了布雷多-特利模型，从对两两对比扩展到列表对比，以提高模型训练效率。具体来说，我们推导出一个闭合形式的最优策略，无需显式的奖励建模即可实现更高效和有效的训练。我们还提出了一个自适应的负采样和重新加权策略，以优化期间优先考虑尾部项目，并增强尾部项目推荐的性能。此外，我们理论证明，优化列表偏好优化（LPO）损失等同于最大化最优奖励的上界。我们的实验结果表明，与直接偏好优化（DPO）相比，在尾部项目推荐方面，我们的方法在性能上提高了50%，同时减少了17.9%的GPU内存使用，优于10个基线方法。", "conclusion": "我们的实验在三个公开数据集上表明，我们的方法在尾部项目推荐中优于10个基线方法，性能提高了50%，同时减少了17.9%的GPU内存使用，采用直接偏好优化（DPO）的方法。我们的代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02106", "html_url": "https://arxiv.org/abs/2507.02106", "title": "解析湍流磁流体力学：一种混合操作-扩散框架", "title_en": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework", "authors": "Semih Kacmaz,E. A. Huerta,Roland Haas", "background": "该研究旨在模拟二维不可压缩、有电阻效应的磁流体动力学（MHD）湍流的空间-时间演化。研究背景在于需要一种能够准确捕捉低频相干动态和高频残差的模型，以实现对完全发展湍流的准确建模。以往的方法可能在某些高雷诺数（Re）的情况下表现不佳，特别是在高度湍流状态下。该研究利用物理信息神经算子（PINOs）和条件扩散模型的结合来提高预测的准确性。", "innovation": "该研究提出了一个混合机器学习框架，该框架结合了物理信息神经算子（PINOs）和基于分数的生成扩散模型。这种方法通过将PINOs的方程约束泛化能力和条件扩散模型的随机修正能力相结合，实现了对低频的相干动态的预测和高频残差的正确修正。该框架在广泛的雷诺数范围内进行了训练，从100到10000，并在多个高保真模拟数据集上得到了训练。这种方法在以往难以解决的雷诺数范围内达到了最先进的准确度。特别是在Re=1000和3000时，模型能够忠实重建整个模拟后期的速度和磁场的谱能量分布，这些分布包含了非高斯统计、间歇结构和跨场相关性。对于极端湍流状态（Re=10000），该模型首次能够在高波数下恢复磁场进化，并保持大尺度形态特征，从而提供统计上有意义的预测。", "conclusion": "通过结合物理信息神经算子和条件扩散模型，该研究首次提出了一种混合模型，能够在广泛的雷诺数范围内准确模拟完全发展湍流。该模型在极高的雷诺数情况下尤为有效，能够正确模拟磁场的高波数演进，保持大尺度形态特征，并提供统计上有意义的预测。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02248", "html_url": "https://arxiv.org/abs/2507.02248", "title": "矩阵完成中的迁移学习", "title_en": "Transfer Learning for Matrix Completion", "authors": "Dali Liu,Haolei Weng", "background": "本文探讨了在矩阵完成设置下的知识迁移，其目的是在有辅助数据可用的情况下提高低秩目标矩阵的估计效果。本文的研究背景在于如何利用已有的源数据来改善目标数据的估计，特别是在资源有限或数据稀少的情况下，通过迁移学习可以从更大范围的数据集中受益。", "innovation": "本文提出了一种基于先验信息的迁移学习过程，用于选择对目标矩阵估计有利的源数据集，并通过引入先进的尖锐收缩不等式来消除收敛率中的对数因子。此外，当源数据集的相关性未知时，提出了一个高效的选择程序来识别出具有信息性的源数据，并证明了该程序的选择一致性。", "conclusion": "本文的研究表明，在源矩阵接近目标矩阵时，所提出的方法优于仅使用单一目标数据的传统方法。通过实验证明了该方法的优越性，表明随着源数据质量的提高，迁移学习方法可以显著改善低秩矩阵的估计效果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02259", "html_url": "https://arxiv.org/abs/2507.02259", "title": "MemAgent：基于多对话RL记忆代理重塑长上下文LLM", "title_en": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": "Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou", "background": "尽管通过长度外推、高效注意力机制和记忆模块的进步，无需牺牲性能在处理无限长文档时仍保持线性复杂度，但在长文本处理中仍面临巨大的挑战。现有方法难以在端到端的方式中直接优化长文本任务，并且在处理大量上下文时表现不佳，这限制了其在更复杂任务中的应用潜力。", "innovation": "该研究直接采用端到端的方式优化长文本任务，引入了名为MemAgent的新颖代理工作流，该工作流分段阅读文本并使用覆盖策略更新记忆。研究扩展了DAPO算法以通过独立上下文多对话生成进行训练，实现了在保持性能损失<5%的情况下，从8K上下文外推到3.5M QA任务，并在512K RULER测试中达到95%以上的性能.", "conclusion": "MemAgent展示出了出色的长上下文处理能力，在8K上下文训练后能够成功外推到3.5M QA任务，并保持较高的性能水平。此外，该方法能够在复杂的任务中实现接近线性的时间复杂度，显示出在长文本处理中的巨大潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02226", "html_url": "https://arxiv.org/abs/2507.02226", "title": "DecoRTL：使用LLM进行RTL代码生成的运行时解码框架", "title_en": "DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs", "authors": "Mohammad Akyash,Kimia Azar,Hadi Kamali", "background": "大语言模型（LLMs）近年来在自动化寄存转移级（RTL）代码生成方面的应用表现出巨大潜力，但传统为自然语言设计的解码策略常常无法满足RTL在结构和语义上的需求，导致生成了大量的幻觉、重复或无效的代码。本文通过分析RTL生成过程中的标记级熵来探讨解码失败的根本原因，表明标准解码策略无法区分需要确定性的语法关键区域和受益于创造性探索变异性的设计关键区域。", "innovation": "本文提出了DecoRTL，这是一种新型的运行时解码策略，同时具有语法感知和对比性，专为RTL代码生成设计。DecoRTL结合了自我一致性采样（生成多个候选并根据标记级一致性重新排名以促进正确性并保持多样性）和语法感知的温度适应性（根据语法和功能角色对标记进行分类并相应调整采样温度，对语法关键标记采用较低温度，对探索性标记采用较高温度），而无需任何额外的模型微调。", "conclusion": "通过使用VerilogEval基准测试多个开源LLM进行评估，本文展示了在语法规则性、功能正确性和输出多样性方面显著的改进，同时执行开销（性能开销）几乎可以忽略不计。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02264", "html_url": "https://arxiv.org/abs/2507.02264", "title": "NLP4Neuro: 从序列到序列学习的神经集群解码", "title_en": "NLP4Neuro: Sequence-to-sequence learning for neural population decoding", "authors": "Jacob J. Morra,Kaitlyn E. Fouke,Kexin Hang,Zichen He,Owen Traubert,Timothy W. Dunn,Eva A. Naumann", "background": "研究如何从神经活动推导出动物行为是神经科学的基本目标。然而，由于行为背后的计算过程是在数千个遍布整个大脑的个别神经元网络中展开的，这在研究大型、密集连接的哺乳动物大脑中的神经角色和计算机制时提出了挑战。现代大型语言模型的底层架构——变压器，已经成为从较小神经群体进行神经解码的强大工具。这些现代大型语言模型受益于大量的预训练，并且其序列到序列的学习能力能够转移到新的任务和数据模态上，这或许也能为神经解码从大规模、全脑活动记录中提供优势。", "innovation": "NLP4Neuro，一种利用现成的语言模型从全脑神经群体中解码行为的系统评估。研究发现，预训练权重用于文本自然语言数据的学习可以提高神经解码性能。研究还发现，最新的专家混合式语言模型DeepSeek Coder-7b显著提高了行为解码的准确性，能够预测长时间尺度上的尾部运动，并提供了解剖上一致且高度可解释的神经元显著性读数。该研究证明，语言模型在全脑神经回路剖析中具有很高的能力。", "conclusion": "NLP4Neuro向人们展示，即使面对单一钙成像和行为记录的全脑活动，语言模型也显示出高效地提供关于神经元活动的重要信息的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02302", "html_url": "https://arxiv.org/abs/2507.02302", "title": "DoMIX: 一种有效的exploiting领域知识进行微调框架", "title_en": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning", "authors": "Dohoon Kim,Donghun Kang,Taesup Moon", "background": "Domain-Adaptive Pre-training (DAP) 近期在微调预训练模型方面表现出色。在该背景下，已有研究探索了连续性 DAP (Continual DAP)，以开发能逐步整合不同领域数据集的预训练模型。然而，现有的连续性 DAP 方法面临着训练过程中的高计算成本和 GPU 内存使用、增量数据顺序敏感性以及提供一个泛化的模型服务于所有最终任务的局限性，这与 DAP 的本质相矛盾。", "innovation": "本文提出了 DoMIX，一种新的方法，该方法通过利用 LoRA 模块（一种代表性的参数效率微调 (PEFT) 方法）来解决上述挑战。此方法能够让 DAP 保持高效且并行，具有对领域顺序的鲁棒性，并充分利用累积知识提供针对特定任务的个性化预训练模型。另外，我们还展示了该方法可以扩展到标准的大语言模型（LLM）微调场景中。", "conclusion": "DoMIX 方法可以在训练过程中有效并行增量整合不同领域数据，具有对数据顺序的鲁棒性，能够针对特定任务提供定制化的预训练模型。此外，该方法还可以应用于标准 LLM 微调场景。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02282", "html_url": "https://arxiv.org/abs/2507.02282", "title": "音乐推荐中的内容过滤方法：一项回顾", "title_en": "Content filtering methods for music recommendation: A review", "authors": "Terence Zeng,Abhishek K. Umrawal", "background": "音乐流媒体平台日益依赖推荐系统来决定用户发现和互动的歌曲。最常见的推荐系统方法是协作过滤，它基于与目标用户有相似听歌模式的用户偏好来推荐内容。但对于低交互密度的媒体（如音乐），这种方法效果不佳。由于用户通常不会听大量的歌曲，因此存在一些挑战需要通过其他方法来解决，特别是在减轻协作过滤方法固有的偏差方面。本文回顾了当前研究，关注内容过滤在减轻这些偏差中的作用，并探讨了歌曲分类的不同方法，如使用大型语言模型进行歌词分析和音频信号处理技术。同时讨论了这些不同分析方法之间的潜在冲突，并提出了解决这些分歧的路径.", "innovation": "本文重点介绍了内容过滤在减轻协作过滤方法固有的偏差中的作用，探讨了歌词分析（使用大型语言模型）和音频信号处理技术在歌曲分类的应用，并提出了多种解决不同分析方法间潜在冲突的途径，旨在改进音乐推荐系统的性能和准确性.", "conclusion": "本文回顾了音乐推荐中内容过滤方法的研究现状，强调了通过内容过滤减轻 Collaborative Filtering 方法固有偏差的重要性，建议使用大型语言模型的歌词分析和音频信号处理技术来提高音乐推荐的准确性，并提出了解决不同分析方法间潜在冲突的可能路径."}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02377", "html_url": "https://arxiv.org/abs/2507.02377", "title": "稀疏高斯过程：结构化近似与回顾性的Power-EP", "title_en": "Sparse Gaussian Processes: Structured Approximations and Power-EP Revisited", "authors": "Thang D. Bui,Michalis K. Titsias", "background": "基于诱导点的稀疏高斯过程变异量已经成为高斯过程模型扩展的标准方法。已有研究显示，通过引入一个对角尺度矩阵可以改进这些模型。本文首先考虑了一种扩展，即使用块对角矩阵结构作为尺度矩阵，证明可以进一步优化变分下界。接着，本文回顾了基于功率期望传播（PEP）的稀疏高斯过程统一框架，并展示了它如何利用和获益于新的结构化近似后验分布。通过广泛的回归实验，展示了所提出的块对角近似方法在性能上与现有的对角近似方法相当或更优，同时计算成本相当。新的PEP框架结合了结构化后验，提供了在各种幂超参数设置下竞争性的性能表现，为实践者提供了标准变分方法之外的选择。", "innovation": "1. 引入了具有块对角形式的尺度矩阵，能够进一步优化变分下界。\n2. 回顾并利用了源于PEP的稀疏高斯过程的统一框架，结合新的结构化近似后验。\n3. 证明了块对角近似方法在不同的幂超参数设置下提供竞争性的性能表现，为从业者提供了灵活的选择。", "conclusion": "通过广泛地回归实验，提出的块对角近似方法在性能上表现出与现有对角近似方法相当或更优的水平，同时保持相似的计算成本效率。新的PEP框架结合结构化后验的运作，提供了在不同功率超参数设置下的竞争力，为高斯过程模型的实践提供了灵活的选择方案。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02288", "html_url": "https://arxiv.org/abs/2507.02288", "title": "通过语言引导和表示对齐进行提示解缠的跨域泛化", "title_en": "Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization", "authors": "De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao", "background": "跨域泛化（DG）旨在开发一种通用模型，使其能够有效地应用于未见过的目标领域。最近，预训练视觉基础模型（VFMs），如CLIP，展示了在提升深度学习模型的泛化能力方面的巨大潜力。尽管VFMs基于提示调优在DG领域得到了越来越多的关注，但设计能够拆分跨多种领域不变特征的有效提示仍然是一项挑战。本文提出了一种利用VFMs可控和灵活的语言提示的新颖框架，通过大型语言模型自动拆分文本提示，并通过拆分的文本特征来学习不变的视觉表示。然而，完全依赖语言来引导视觉特征的解缠存在局限性，因为复杂或微妙的视觉特征有时候难以被描述性文本充分捕捉。为解决这一问题，本文引入了最糟糕显式表示对齐（WERA），这是一种扩展文本引导视觉提示的方法，通过结合抽象提示和风格化图像增强技术来增加源域多样性，并通过对齐约束确保视觉表示在原分布和增强分布之间的稳定性。", "innovation": "本文提出了一个新的框架，通过大型语言模型自动拆分文本提示，并通过拆分的文本特征来引导学习不变的视觉表示。为了克服完全依赖语言引导的局限性，本文引入了最糟糕显式表示对齐（WERA），该方法通过结合抽象提示并利用风格化图像增强技术来增加源域多样性，同时通过对齐约束确保视觉表示在原分布和增强分布之间的一致性。", "conclusion": "在主要的DG数据集上进行的实验表明，本文提出的方法在跨域泛化方面优于现有的最佳方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02391", "html_url": "https://arxiv.org/abs/2507.02391", "title": "基于后验转换建模的无监督扩散模型语音增强", "title_en": "Posterior Transition Modeling for Unsupervised Diffusion-Based Speech Enhancement", "authors": "Mostafa Sadeghi(MULTISPEECH),Jean-Eudes Ayilo(MULTISPEECH),Romain Serizel(MULTISPEECH),Xavier Alameda-Pineda(ROBOTLEARN)", "background": "当前的语音增强方法利用噪声掩蔽（noisy speech）通过一个近似加噪声的似然分数，结合无条件分数来引导逆向扩散过程。这种方法需要通过超参数进行调节，并且增强性能及鲁棒性仍有提升空间。该研究旨在探索使用扩散模型作为清晰语音的表达性生成先验来进行无监督的语音增强方法的潜力", "innovation": "提出了两种新的算法来直接建模扩散状态的条件逆向转换分布。方法一是将扩散先验与观测模型在理论上整合起来，从而去除超参数调整的需要。方法二是定义一个基于噪声语音本身的扩散过程，得到完全可追溯且精确的似然分数。这些新方法能够改善增强度量，并在WSJ0-QUT和VoiceBank-DEMAND数据集上的验证中表现出对领域变化的更好鲁棒性，相比监督和无监督基线方法", "conclusion": "实验结果表明，与现有的监督和无监督方法相比，新的后验转换方法在语音增强的各个方面都有了改进，展示了其在增强性能和鲁棒性上的优势。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02328", "html_url": "https://arxiv.org/abs/2507.02328", "title": "使用一次采样骨架图进行路径规划", "title_en": "Path Planning using a One-shot-sampling Skeleton Map", "authors": "Gabriel O. Flores-Aquino,Octavio Gutierrez-Frias,Juan Irving Vasquez", "background": "路径规划算法旨在计算无碰撞路径，许多研究侧重于找到最优距离路径。但对于某些应用，更重要的是平衡响应时间、路径安全性以及路径长度。在这种背景下，骨架图在基于图的方案中是一个有用的工具，因为它提供了自由配置空间的内在表示。然而，骨架图算法非常耗资源，主要面向图象处理任务。传统路径规划方法通常需要迭代过程或概率采样过程来寻找路径，而计算骨架化版本的导航图。", "innovation": "提出了一种高效路径规划方法，利用基于U-Net架构的深度去噪自编码器（DDAE）计算骨架化版本的导航地图，并将其命名为SkelUnet。SkelUnet网络通过一次采样（OSS）便于探索整个工作空间，而不是传统算法使用的迭代过程或概率采样过程。该方法在包含12,500个二维“迷宫”地图的数据集上进行了训练和测试。", "conclusion": "使用SkelUnet构建的路径图具有显著优势，如连接自由工作空间的所有区域、提供更安全的路径以及减少处理时间。这些特点使其特别适合在结构化的环境中执行服务类移动机器人的路径规划。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02399", "html_url": "https://arxiv.org/abs/2507.02399", "title": "TABNet: 一种具备边界感知伪标签的三元增强自我恢复框架用于医学图像分割", "title_en": "TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation", "authors": "Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang", "background": "医学图像分割在多种临床应用中是一个核心任务。但由于难以获取大规模且完全注释的医学图像数据集，人工标注成本高昂且耗时。条带标注作为一种稀疏标注形式，提供了一种成本效益较高的替代方案，但仍受限于其稀疏性，难以充分学习到目标区域的特征并缺乏足够的边界监督，这对训练分割网络构成了巨大挑战。", "innovation": "提出了一种新颖的弱监督医学图像分割框架TAB Net，该框架包含两个关键模块：三元增强自我恢复(TAS)模块和边界感知伪标签监督(BAP)模块。TAS模块通过三种互补的增强策略提高了特征学习能力，BAP模块通过融合预测和引入边界感知损失增强了伪监督的准确性和边界建模。这些创新使得TAB Net在基于条带标注的弱监督分割中显著优于现有方法，并在特定数据集上的表现接近全监督方法。", "conclusion": "实验结果表明，TAB Net在两个公开数据集ACDC和MSCMR seg上的表现显著优于最先进的方法，在基于条带标注的弱监督分割中达到了更好的性能。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02275", "html_url": "https://arxiv.org/abs/2507.02275", "title": "结构是无关紧要的：噪声对结构无关估计的影响", "title_en": "It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation", "authors": "Jikai Jin,Lester Mackey,Vasilis Syrgkanis", "background": "结构无关因果推断研究了在利用黑盒机器学习方法估算准函数（如协变量对治疗和结果的影响）的情况下，能够多准确地估计治疗效应。本文作者研究了治疗噪声的分布对这种准确度的影响。在部分线性模型中，作者首先展示了广泛采用的双重机器学习（DML）估计器对于高斯治疗噪声是最佳的，这是对 \textbackslash{}citet{mackey2018orthogonal} 提出的一个开问题的解决。对于独立的非高斯治疗噪声，作者证明了 DML 估计器是次优的，通过构建新的高阶稳健性更高的实用程序来证明这一点。这些 ACE 程序使用结构无关的累积量估计器，在某个阶数的滋扰误差中达到无灵敏度性，只要该阶数加一的治疗累积量非零。最终，作者为部分线性模型中的二元治疗提供了新的最佳保证，并通过合成的需求估计实验展示了作者的高阶稳健估计器的实际优势.", "innovation": "作者展示了在高斯治疗噪声情况下，DML 估计器是最佳的，这是对先前研究的一个补充。但更大创新在于，对于独立的非高斯处理噪声，作者提供了新的实用程序，利用结构无关的累积量估计器在滋扰误差中达到更高阶的无灵敏度性，解决了一个开放的问题，同时证明了 DML 估计器并不是最佳选择，因为存在更高阶的稳健性更高的流程。此外，作者首次为部分线性模型中的二元治疗提供了新的最佳保证，这些保证是根据不同类型的噪声特性得到的，从而解决了在不同噪声分布情况下的方法比较问题。最后，使用合成需求估算实验，作者证明了更高阶的稳健性估计的优势，展示其在实际应用场景中的潜力和实际价值.", "conclusion": "本文的研究结果表明，治疗噪声的性质直接影响到结构无关因果推断的方法的选择。当治疗噪声为高斯分布时，DML 最优；但当噪声为非高斯时，应该选择其他更高阶稳健的估计器。此外，即使是在同样的非高斯情况下，当噪声的某些统计特性发生变化时，选择的最优估计器也可能不同。作者的研究为处理不同噪声特性的问题提供了一种有效的方案，验证了这些更高的阶稳健估计器相对于传统方法的实际益处。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02403", "html_url": "https://arxiv.org/abs/2507.02403", "title": "在非城市环境中使用自我监督学习进行野生动物目标重识别", "title_en": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings", "authors": "Mufhumudzi Muthivhi,Terence L. van Zyl", "background": "野生动物重识别旨在跨不同观察记录匹配相同物种的个体。当前最先进的模型依赖于班级标签来训练监督模型进行个体分类。这种对标注数据的依赖已经促使创建了许多大型野生动物数据集。但该研究探讨了自我监督学习（SSL）在野生动物重识别中的应用。通过自动从相机陷阱数据的时序图像对中提取个体的两种不同视图，来训练一个自我监督模型，该模型可以从一个潜在无限的视频流中学习。实验结果表明自我监督模型即使在数据有限的情况下也更稳健，并且自我监督特征在所有下游任务中优于监督特征。", "innovation": "研究通过探索自我监督学习在野生动物重识别中的应用，主要创新在于：1）提出了一种无监督方法来自动从相机陷阱数据中提取个体的两种不同视图；2）使用自我监督模型从无限的视频流数据中进行学习；3）验证了自我监督模型在开放世界场景中的稳健性和自我监督特征在各种野生动物下游任务中的优越性。", "conclusion": "实验结果表明，即使在数据有限的情况下，自我监督模型也比监督模型更稳健。自我监督特征在各种野生动物下游任务中均优于监督特征。研究为未来使用自我监督学习来进行野生动物识别的方法奠定了基础。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02416", "html_url": "https://arxiv.org/abs/2507.02416", "title": "使用深度学习框架确定结构裂纹", "title_en": "Determination Of Structural Cracks Using Deep Learning Frameworks", "authors": "Subhasis Dasgupta,Jaydip Sen,Tuhina Halder", "background": "结构裂纹检测是一项关键的安全任务，有助于预防可能危害生命的潜在结构失效。由于缺乏经验的人工检测速度慢且不一致，容易出错，这可能会影响评估的可靠性。当前研究旨在通过引入新型深度学习架构来解决这些挑战，以提高结构裂纹检测的准确性和效率。各种配置的残差U-Net模型被用于这项研究，由于它们在捕捉细微特征方面的坚固性，这些模型进一步与包含卷积块的元模型集成到一个集合中。这种独特的组合旨在超越单一模型所能实现的预测效率。集合模型的性能与诸如SegNet和传统U-Net之类的成熟架构进行了比较。结果显示，残差U-Net模型在低分辨率图像中表现优于其前身，集合模型超过了单一模型的表现，证明它是最有效的。评估基于交并比（IoU）度量和DICE系数。集合模型获得了最高的得分，表明其准确性更高。这项进展为结构缺陷监测任务提供了更可靠自动系统的途径.", "innovation": "该研究提出了一种新的深度学习架构，通过使用残差U-Net模型以及将这些模型与包含卷积块的元模型集成到一个集合中，来提高结构裂纹检测的准确性和效率。这种独特的方法在低分辨率图像中表现突出，并且证明了集合模型比单一模型更有效，为自动检测系统提供了更可靠的方法。", "conclusion": "研究结果表明，通过使用新颖的深度学习架构，特别是通过残差U-Net模型和集合模型，能够显著提高结构裂纹检测的准确性和效率。这种方法在低分辨率图像中的表现特别好，证明了其在结构缺陷监测任务中的优越性，为更可靠的自动化系统铺平了道路。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02593", "html_url": "https://arxiv.org/abs/2507.02593", "title": "在（人类）标签变异下的主动学习重检", "title_en": "Revisiting Active Learning under (Human) Label Variation", "authors": "Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher", "background": "高质量标注数据仍然是监督学习中的一个限制因素。尽管标签变异（LV），即同一实例有不同的标签，在自然语言处理中非常常见，但标注框架通常还是基于单一真实标准的假设，忽略了人类标签变异（HLV）作为有用信号的存在。同样，主动学习（AL），一种优化有限标注预算使用的流行方法，在训练机器学习模型时往往依赖于简化假设，这些假设在承认HLV时通常不成立。因此，本文回顾了关于真实性和标签属性的基本假设，并强调将观测到的LV分解为信号（例如HLV）和噪声（例如标注误差）的重要性。同时，本文还调研了AL和（H）LV社区如何处理或忽视这些差异，并提出一个将HLV贯穿整个AL循环的概念框架，包括实例选择、标注者选择和标签表示。此外，讨论了大型语言模型（LLM）作为标注者集成的问题。这项工作旨在为HLV-感知的主动学习奠定概念基础，更好地反映现实世界注释的复杂性。", "innovation": "本文提出了一种将HLV集成到整个AL循环的概念框架，包括实例选择、标注者选择和标签表示等环节。同时，还讨论了引入大型语言模型（LLM）作为标注者的问题，旨在为HLV感知的主动学习提供概念基础，更好地反映现实世界注释的复杂性。", "conclusion": "本文强调了将LV分解为信号和噪声的重要性，并提出了将HLV贯穿整个AL循环的概念框架。未来的研究可以通过整合LLM等新型技术，进一步提升HLV感知的主动学习的效果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02506", "html_url": "https://arxiv.org/abs/2507.02506", "title": "印度保释判决数据集1200：印度保释命令的多属性数据集", "title_en": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders", "authors": "Sneha Deshmukh,Prathmesh Kamble", "background": "在印度等地区，由于缺乏结构化的数据集，法律自然语言处理（Legal NLP）领域的发展仍然相对滞后。这限制了该领域在印度的应用和研究进展。", "innovation": "本研究推出了一个名为IndianBailJudgments-1200的新基准数据集，包含1200份印度法院关于保释决定的判决，这些判决被注释了超过20个属性，包括保释结果、IPC章节、犯罪类型和法律推理。注释使用了由定制提示工程的GPT-4o管道生成，并经过一致性验证。该资源支持广泛的法律自然语言处理任务，如结果预测、摘要和公平性分析，是首个专注于印度保释法律学说的公开可用数据集。", "conclusion": "本数据集为法律自然语言处理任务提供了重要支撑，尤其是针对印度保释法律学说的研究，推动了该领域的进展。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02554", "html_url": "https://arxiv.org/abs/2507.02554", "title": "AI研究代理用于机器学习：在MLE-bench中的搜索、探索与泛化", "title_en": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "authors": "Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach", "background": "AI研究代理通过自动化机器学习模型的设计、实现和训练展示了加速科学研究的潜力。研究者聚焦于提高代理在MLE-bench中的性能，这是个极具挑战性的基准，代理在这里参与Kaggle竞赛，解决实际世界中的机器学习问题。", "innovation": "通过设计不同的操作集合和搜索策略（贪婪策略、蒙特卡洛树搜索、进化算法），明确展示了这些方法的组合在实现高性能方面的重要性。最佳组合策略和操作集在MLE-bench lite中达到了最先进的结果，将获得Kaggle奖牌的成功率从39.6%提高到47.7%。这项研究强调了同时考虑搜索策略、操作设计和评估方法在推进自动化机器学习中的重要性", "conclusion": "我们的研究结果表明，充分考虑搜索策略、操作设计和评估方法的联合对提升自动化机器学习的性能至关重要。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02494", "html_url": "https://arxiv.org/abs/2507.02494", "title": "MC-INR: 使用元学习和聚集隐式神经表示高效编码多变量科学仿真数据", "title_en": "MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations", "authors": "Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong", "background": "隐式神经表示（INRs）通常用于将数据编码为连续函数，这有助于用较少的内存占用来可视化大规模多变量科学仿真数据。然而，现有基于INR的方法面临三个主要限制：（1）不能灵活地表示复杂结构，（2）主要关注单变量数据，（3）依赖于结构化的网格。这些限制导致它们在应用于复杂的真实世界数据集时表现不佳。为了应对这些限制，我们提出了一种新的基于神经网络的框架MC-INR，它可以处理在非结构化网格上的多变量数据。它结合了元学习和聚类，以灵活地表示复杂的结构。为了进一步提高性能，我们引入了一种基于残差的动态重聚类机制，这种机制可以根据局部误差动态地分区群集。我们还提出了一种分支层，以同时利用多个分支中的多变量数据。实验结果显示，MC-INR在科学数据编码任务中优于现有方法。", "innovation": "提出了一种名为MC-INR的新框架，用于处理多变量数据在非结构化网格上。该框架结合了元学习和聚类技术，灵活地表示复杂的结构。还引入了基于残差的动态重聚类机制，以根据局部误差适应性地分区群集，并提出了一种分支层，可以同时利用多变量数据", "conclusion": "实验结果证明，MC-INR在科学数据编码任务中优于现有方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02681", "html_url": "https://arxiv.org/abs/2507.02681", "title": "检测自愿测验中的脱节：高等教育远程教育中的可解释机器学习方法", "title_en": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education", "authors": "Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin", "background": "学生在学习任务上的脱节可能产生长期的严重后果，包括学术辍学，这一点在远程教育学生中尤其重要。通过观察不同在线课程中的非强制性练习参与情况，可以衡量远程教育中的学生脱节程度。本研究检测了某远程大学42门课程四个学期中非强制性测验的学生脱节情况，利用Moodle提取和处理最有信息价值的学生日志数据，训练并比较了八种机器学习算法，以获得最高的预测准确度。", "innovation": "本研究开发了一种可解释的机器学习框架，使用SHAP方法，帮助实践者更好地理解训练算法的决策，实现了91%的平衡准确性，正确检测到大约85%的脱节学生。该研究不仅采用了高度预测性的表现和可解释性框架，还讨论了如何及时干预以减少在线学习中自愿任务的脱节问题。", "conclusion": "本研究通过训练多种机器学习算法，结合SHAP方法构建了一个可解释的预测框架，能够准确识别远程教育中脱节的学生，并探讨了干预策略，有希望能减少未来在线学习中自愿任务的脱节问题。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02443", "html_url": "https://arxiv.org/abs/2507.02443", "title": "在FPGA的可编程逻辑中使用加速人工神经网络进行红葡萄检测", "title_en": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic", "authors": "Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias", "background": "机器人在搬运过程中通常会减速以检测物体，而机器人的相机配置低帧率以追踪检测算法的运行速度。这些限制在执行任务时会增加耗时。AMD开发了Vitis-AI框架用于将检测算法部署到FPGAs中，但并未充分利用FPGAs的可编程逻辑（PL）.", "innovation": "本文使用FINN架构将三种ANN模型（MobileNet v1、CNV 2-bit量化和CNV 1-bit量化BNN）部署到FPGAs的PL中。模型在RG2C数据集上训练，MobileNet v1达到了98%的成功率和6611 FPS的推理速度，证明了通过FPGAs可以加速ANNs并使其适用于注意力机制.", "conclusion": "本文证明了通过将 ANN 模型部署到 FPGA 的可编程逻辑中，可以加速这些模型并使它们适用于注意力机制。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02407", "html_url": "https://arxiv.org/abs/2507.02407", "title": "在特定领域数据集上的阿坎自动语音识别模型基准测试：性能、可扩展性和适应性比较评估", "title_en": "Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability", "authors": "Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame", "background": "现有的大多数自动语音识别（ASR）研究使用领域特定的数据集来评估模型，但鲜少关注模型跨不同语音环境的泛化能力。这项研究通过使用四种阿坎语语音语料库来评估七个基于变换器架构的阿坎ASR模型，以确定它们在不同背景下的表现，这些语料库涵盖了诸如文化相关图像描述、非正式对话、圣经读经以及自发金融对话等多个领域。研究发现，这些模型在训练领域的表现最佳，但在不匹配场景中表现出明显的准确性下降。此外，这项研究还揭示了 Whisper 和 Wav2Vec2 架构在错误行为上的差异：微调后的 Whisper 阿坎模型生成更流畅但可能具有误导性的转录错误，而 Wav2Vec2 在遇到不熟悉的输入时则生成更明显但更难以解释的输出。", "innovation": "这项研究填补了现有研究在评估跨不同语音环境的自动语音识别模型性能方面的空白，通过使用四种阿坎语语音语料库来测评七个基于变换器架构的阿坎ASR模型，从而识别出不同的错误行为，并且指出了不同架构之间的权衡。这项工作有助于识别适合低资源语言应用的最佳模型架构，促进特定领域自适应技术、可调整路由策略和多语言训练框架的发展。", "conclusion": "研究表明在不同领域数据集上的表现存在依赖性，模型只能在其训练领域内表现出色，而在其他领域中会严重失准。Whisper 和 Wav2Vec2 架构之间存在不同的错误行为，Whisper 的转录错误虽然更流畅但更可能误导，而 Wav2Vec2 的输出虽然更直观但更难以解释。这些发现强调了对于低资源语言应用来说，需要有针对性的领域自适应技术、可调整路由策略以及多语言训练框架，以便提高自动语音识别模型在这些语言上的性能。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02686", "html_url": "https://arxiv.org/abs/2507.02686", "title": "学习基于展开和蒸馏的多步后验采样器", "title_en": "Learning few-step posterior samplers by unfolding and distillation of diffusion models", "authors": "Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra", "background": "扩散模型（DMs）已成为贝叶斯计算成像中的强图像先验。已有两种主要策略用于 DMs：插即用方法（Zero-Shot and Highly Flexible），它们不需要预训练且高度灵活，但依赖于近似；以及特定任务的条件 DMs（Supervised Training），它们通过监督训练在特定任务中实现更高精度和更快的推理速度。本文在此背景下，提出了一种既具有灵活性又能适应前向模型变化且在特定任务中表现出更高精度和更快推理速度的新框架。", "innovation": "本文提出了一种新颖的框架，通过深度展开和模型蒸馏将 DM 转换为几步的条件模型用于后验采样。特别之处在于将马尔可夫链蒙特卡洛（MCMC）算法——具体是最近提出的 LATINO 简并拉格朗日采样器进行深度展开——这是首次将深度展开应用于蒙特卡洛采样方案。通过广泛的实验和与最新技术的比较，展示了展开和蒸馏的采样器，显示出出色的准确性和计算效率，并且在推理时保持了对前向模型变化的适应性。", "conclusion": "在扩展实验中，提出的采样器展示了出色的准确性和计算效率，同时保留了在推理时适应前向模型变化的灵活性，展示了在特定任务中可以实现较高精度和较快推理速度。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02606", "html_url": "https://arxiv.org/abs/2507.02606", "title": "De-AntiFake: 重新思考对抗语音克隆攻击的保护性扰动", "title_en": "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks", "authors": "Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu", "background": "语音生成模型的快速发展引起了语音克隆（VC）相关的隐私和安全问题。最近的研究试图通过引入对抗扰动来干扰未经授权的语音克隆，但有决心的攻击者可以减轻这些保护性扰动并成功执行VC。本研究首次在包含对抗扰动净化的现实威胁模型下系统评估此类保护性扰动。研究发现，现有净化方法虽能中和一部分保护性扰动，但仍会导致VC模型特征空间的畸变，从而降低VC性能。", "innovation": "提出了一种新颖的两阶段净化方法：（1）净化受扰动的语音；（2）使用音素指导进行完善，使其与干净语音分布相契合。实验结果显示，本方法在干扰VC防御方面优于最先进的净化方法。", "conclusion": "研究揭示了基于对抗扰动的VC防御的局限性，强调了迫切需要更 robust 的解决方案以缓解VC带来的安全和隐私风险。相关代码和音频样本可在以下链接获取：this https URL."}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02607", "html_url": "https://arxiv.org/abs/2507.02607", "title": "缓解攻击数据稀缺性：SCANIA提升车载网络安全措施的经验", "title_en": "Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures", "authors": "Frida Sundfeldt,Bianca Widstam,Mahshid Helali Moghadam,Kuo-Yun Liang,Anders Vesterberg", "background": "联网车辆的数字化演进及其随之而来的安全风险突显了实施车载网络安全措施的重要性，例如入侵检测和响应系统。随着攻击场景的不断进化，需要适应性更强的检测机制来识别不断变化、未知和复杂的威胁。尽管使用基于机器学习的技术可以解决这一挑战，但在测试车辆上实施多样化攻击场景受到安全、成本和伦理考虑的限制，导致缺乏代表攻击场景的数据。为了解决这一限制，本文提出了一个上下文感知的攻击数据生成器，该生成器能够生成多种攻击类型的攻击输入及其对应的车内网络日志，即控制器局域网（CAN）日志，包括拒绝服务（DoS）、模糊、欺骗、悬挂和重播攻击。该生成器利用参数化的攻击模型，结合CAN消息解码和攻击强度调整，配置高相似度与真实场景的攻击情景，并促进差异性。", "innovation": "本文提出了一个上下文感知的攻击数据生成器，该生成器能够生成用于车载网络安全检测的高质量攻击代表数据。该生成器利用参数化的攻击模型，结合CAN消息解码和攻击强度调整，配置高相似度与真实场景的攻击情景，并促进差异性。在入侵检测系统（IDS）的研究案例中，利用生成的数据对两个深度神经网络IDS模型进行了开发和实验性评估，证明了生成数据的高效性和可扩展性，并验证了IDS模型的高检测和分类能力。此外，经验研究还探讨了影响数据真实度的因素，并提供了其应用的见解", "conclusion": "本文提出的方法不仅提高了数据生成的效率和可扩展性，还验证了生成数据在IDS模型中的准确性和有效性。此外，经验研究还分析了生成数据与真实场景吻合度的影响因素，并提供了其应用的见解。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02690", "html_url": "https://arxiv.org/abs/2507.02690", "title": "RLHGNN：基于强化学习的异构图神经网络在业务流程中预测下一步活动", "title_en": "RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes", "authors": "Jiaxing Wang,Yifeng Yu,Jiahan Song,Bin Cao,Jing Fan,Ji Zhang", "background": "优化服务导向架构中的业务流程，如微服务环境、分布式企业系统和云原生平台所需的下一个活动预测构成了一个基本挑战。此预测功能使资源的前瞻性和动态服务组合成为可能。尽管序列方法的应用很普遍，但无法捕捉并行执行和条件依赖带来的非序列关系。尽管图方法能解决结构保存问题，但它们遭受同质表示和静态结构的限制，这些结构采用了一致的建模策略，忽视了个体流程复杂性的特性差异。鉴于这些不足，介绍了RLHGNN（基于强化学习的异构图神经网络）这一新颖框架，旨在将事件日志转换为基于既有过程挖掘理论设立的独特边类型的异构过程图。该方法通过有选择地组合这些边来创建四个灵活的图结构，以适应不同的过程复杂性，并应用强化学习来自动确定每个具体流程实例的最佳图结构。然后，采用特定关系的聚合策略来进行异构图卷积，以有效地预测下一个活动。这一适应性方法能准确建模服务交互中的序列和非序列关系。全面的六个真实数据集评估表明，RLHGNN 具有一致超越最新方法的表现。此外，它还可维持每预测约1毫秒的推理延迟，提供了一个实用的解决方案，适用于实时业务流程监控应用。", "innovation": "RLHGNN 引入了一种新颖的框架，结合了异构图神经网络和强化学习技术，通过选择性地组合三种不同类型的边来构建适应不同类型过程复杂性的多个图结构。此外，强化学习被用来自动确定最适合每个具体流程实例的图结构，应用特定关系的聚合策略进行异构图卷积，并以有效预测下一个活动。", "conclusion": "全面评估表明，RLHGNN 在六个实际数据集上持续超越最先进的方法，并且具有约1毫秒的推理延迟，适合实时业务流程监控应用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02726", "html_url": "https://arxiv.org/abs/2507.02726", "title": "Bourbaki: 自动生成且目标导向的MDP方法在定理证明中的应用", "title_en": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving", "authors": "Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar", "background": "逻辑推理对大型语言模型(LLMs)来说仍然是一项挑战，特别是对于自动定理证明(ATP)环境中的逻辑约束条件。在PutnamBench等基准测试中，这些挑战尤为显著，因为该基准测试包含了需要复杂多步推理的大学水平问题，由于奖励稀疏和证明的规模庞大，这对LLMs构成了巨大挑战。", "innovation": "该论文提出了一种新的自生成目标导向的MDP（sG-MDP）框架。在这种框架下，代理可以根据证明状态的变化生成并追求子目标。随后，通过类似于蒙特卡洛树搜索(MCTS)的算法来解决sG-MDP问题，并将这种方法应用在一个模块化系统Bourbaki（7B）中，该系统可以组合多个7B LLM来生成子目标并合成策略。", "conclusion": "在PutnamBench基准测试中，Bourbaki（7B）解决了26个问题，达到了这个规模模型中新的最先进成果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02737", "html_url": "https://arxiv.org/abs/2507.02737", "title": "前沿大语言模型中早期显现的隐写术能力", "title_en": "Early Signs of Steganographic Capabilities in Frontier LLMs", "authors": "Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner", "background": "随着大型语言模型的广泛应用，对其输出进行监控变得非常重要，以减少误用和不一致的风险。但是大语言模型可以通过隐写术技术规避监控，即在看似无害的生成中编码隐藏信息。本文作者评估了这些最前沿大语言模型的隐写术能力，以便更好地了解它们带来的风险。", "innovation": "作者专注于两种类型的隐写术：传递编码消息和执行编码推理。研究表明，当前模型在标准环境下无法在输出中编码短消息而不被监控发现。然而，如果给予额外因素如使用未监控的草稿页和协调所使用的编码方案，则可以成功实现。此外，模型在简单状态追踪问题上可以执行基本的编码推理，包括使用自身和预定义编码（如十六进制）的能力。但它们很少能够在掩盖任务中微妙地隐藏推理以欺骗监控。因此，当前结果表明这些大语言模型具有一些初始的隐写术能力。", "conclusion": "尽管这些能力目前可能不足以绕过精心设计的监控，但未来可能会发生变化。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02773", "html_url": "https://arxiv.org/abs/2507.02773", "title": "KERAP：基于多智能体大语言模型的增强知识推理方法以实现准确的零样本诊断预测", "title_en": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs", "authors": "Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang", "background": "医疗诊断预测在疾病检测和个性化健康护理中起着关键作用。尽管机器学习模型已被广泛应用于此任务，但它们依赖于监督性训练，这限制了其对未知情况的泛化能力，特别是在获得大型带有标签的数据集方面成本高昂的情况下。大语言模型（LLMs）通过利用语言能力和生物医学知识，在诊断预测方面显示出潜力，但它们往往会产生幻觉，缺乏结构化的医疗推理，并产生无用的输出。", "innovation": "我们提出了KERAP，这是一种基于知识图谱（KG）增强推理的方法，通过多智能体架构改进LLM驱动的诊断预测。我们的框架包括一个链接代理来实现属性映射、一个检索代理来进行结构化知识提取以及一个预测代理，该预测代理可以迭代地细化诊断预测。实验结果表明，KERAP能够有效提高诊断的可靠性，提供了一个可扩展且可解释的零样本医疗诊断预测解决方案", "conclusion": "我们的研究表明，KERAP可以在多智能体LLM中提供一个有效的解决方案，以增强诊断的可靠性，并提供一种可扩展且可解释的零样本医疗诊断预测方式。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02748", "html_url": "https://arxiv.org/abs/2507.02748", "title": "基于全局上下文的线性注意力：用于视觉与物理的多级注意力机制", "title_en": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics", "authors": "Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen", "background": "Transformer已经成为广泛任务的标准，从图像分类到物理模拟。尽管性能出色，但标准Transformer的时间和空间复杂性随输入长度平方增长，使得处理高分辨率输入不实际。为解决此问题，已提出了多种变体，但这些方法常在细节损失和效率之间做权衡。该论文提出了另一种方法，借鉴了$n$体数值模拟领域的最新技术，将注意力问题视为网格点之间的相互作用问题，从而推出了一种计算注意力的多级机制，即Multipole Attention Neural Operator (MANO)。", "innovation": "该论文引入了Multipole Attention Neural Operator（MANO），这是一种通过基于距离的多级方式进行计算的注意力机制。MANO 每个注意力头都保持全局的感受野，并且其时间复杂性和空间复杂性对于网格点的数量都是线性的。实验结果表明，MANO 在图像分类和达西流仿真中表现与当前最佳模型如ViT和Swin Transformer相当，但运行时间和峰值内存使用却比它们少多个数量级。", "conclusion": "所提出的方法在效率和效果上都取得了显著成果，作者开放源代码以便复现。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02771", "html_url": "https://arxiv.org/abs/2507.02771", "title": "将智能扎根于运动", "title_en": "Grounding Intelligence in Movement", "authors": "Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording", "background": "近期机器学习的进步极大地提升了我们建模语言、视觉等高维数据的能力，但仍然在处理生物学系统中最基本的方面——运动方面遇到困难。在神经科学、医学、机器人学和行为学等领域，运动对于解读行为、预测意图和实现交互至关重要。尽管它在我们的智能中占据核心地位，但运动通常被视为一种次要因素，而非作为一种丰富且结构化的模态。这反映了运动数据收集和建模的更深层次的割裂，往往受限于特定任务的目标和特定领域的假设。然而，运动并不受领域限制。它反映了共享的物理约束、保守的形态结构以及跨越物种和场景的目的性动态。论文认为运动应该被视为人工智能的主要建模目标。运动本质上是结构化的，与实体性和物理性密切相关。这种结构常常允许使用紧凑、低维度的表示（如姿态），使其比原始的高维感官输入更容易解读和计算。发展可以从多样化的运动数据中学习并泛化的模型不仅会促进生成建模和控制的核心能力，还将为理解生物和人工系统的行为提供一个共同的基础。运动不仅仅是结果，而是理解智能系统与世界互动方式的窗口。", "innovation": "论文创新性地提出了将运动视为人工智能主要建模目标的观点，强调运动在智能系统中的重要性和结构化特征，指出运动能够简化、提高模型的可解释性和计算效率，进而促进生成建模和控制等方面的关键技术进步，并构建了跨生物和人工系统的共同理解基础。", "conclusion": "论文最终结论是运动不仅是智能行为的结果，也是智能系统如何与世界互动的窗口。通过将运动作为首要建模目标，可以促进生成建模、控制等核心能力的提升，并建立跨生物和人工系统的共享理解基础。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02778", "html_url": "https://arxiv.org/abs/2507.02778", "title": "Self-Correction Bench：揭示并解决LLMs中的自我纠正盲点", "title_en": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs", "authors": "Ken Tsui", "background": "虽然大型语言模型（LLMs）已经变得非常有变革性，但它们仍然会犯错误，并且有时会探索无成效的推理路径。自我纠正是一项至关重要的能力，特别是对于自回归型的LLMs来说。尽管LLMs能够识别用户输入中的错误，但它们在纠正自身输出中相同的错误时表现出一种系统性的‘自我纠正盲点’缺陷，即无法纠正自身输出中的一致性错误。为系统地研究这一现象，研究引入了Self-Correction Bench，这是一种通过在三个复杂度层次上控制注入错误来衡量这一现象的系统性框架。在测试14个模型后，研究发现平均有64.5%的自我纠正盲点率。研究发现，这一限制与训练数据组成有关：人类训练示例主要展示错误免费的回应，而不是包括错误纠正序列的示例，不同于通过结果反馈学习错误纠正的强化学习训练模型。令人惊讶的是，“等待”简单地添加可以减少91.3%的盲点，表明该能力存在但需要被激活。这项工作揭示了当前LLMs中的一个关键局限性，并提出了提高其可靠性和可信度的潜在途径。", "innovation": "引入了Self-Correction Bench，这是一种系统性框架，通过对三种复杂度级别的受控错误注入来衡量LLMs自我纠正盲点现象。研究发现，人类训练示例主要展示错误免费的回应，而不是包括错误纠正序列的示例，而强化学习训练模型通过结果反馈学习错误纠正。简单地添加“等待”词语可显著减少盲点，表明这种能力是存在的，但需要激活。这项工作揭示了LLMs在自我纠正方面的一个关键缺陷，并提出了改进方法。", "conclusion": "这项研究揭示了当前LLMs中存在的一个重要局限性——自我纠正盲点，并提供了可能的改进方案来提高LLMs的可靠性和可信度。通过添加简单的“等待”词语就能显著减少盲点频率，表明自我纠正能力是存在的，但需要被激活。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02791", "html_url": "https://arxiv.org/abs/2507.02791", "title": "自引导深度非线性空间选择性滤波器在弱指引下高效提取移动演讲者", "title_en": "Self-Steering Deep Non-Linear Spatially Selective Filters for Efficient Extraction of Moving Speakers under Weak Guidance", "authors": "Jakob Kienegger,Alina Mannanova,Huajian Fang,Timo Gerkmann", "background": "最近的研究表明，带有轻量计算架构的深度非线性空间选择性滤波器在已知方位的静止说话人上表现出色。但在动态场景中，为了保持这种性能，就需要资源密集型的数据驱动跟踪算法来提供基于初始目标说话人方向的精确空间指导。这种额外的计算开销限制了其在资源受限场景（如实时语音增强）中的应用。因此，需要一种低复杂度的跟踪算法替代方案，从而提高效率和性能。", "innovation": "本文提出了一种新的低复杂度跟踪算法策略，采用粒子滤波器的形式，通过因果的顺序处理方式和时间反馈机制，利用空间选择性滤波器增强的语音信号来补偿粒子滤波器有限的建模能力。这种方法在合成数据集上的评估表明，两种算法之间的自回归交互显著提高了跟踪准确性，并且在真实录音的听觉测试中也显示出明显优势，表明自引导管道是优于其他方法的选择。", "conclusion": "本研究使用低复杂度的粒子滤波器代替资源密集型跟踪算法，通过时间反馈显著提高了动态场景下的跟踪准确性，从而实现了移动说话人的高效提取，适合资源受限的应用场景，如实时语音增强，并通过实验验证了所提出的自引导管道性能优越。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02819", "html_url": "https://arxiv.org/abs/2507.02819", "title": "测量即拼凑：探讨数据科学家如何为预测建模任务构建目标变量", "title_en": "Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks", "authors": "Luke Guerdan,Devansh Saxena,Stevie Chancellor,Zhiwei Steven Wu,Kenneth Holstein", "background": "数据科学家经常需要将模糊的概念，如学生的“真伪性”或病人的“医疗需求”转化为具体的代理目标变量，但这一过程的具体机制尚不明确。本文通过采访来自教育和医疗领域的15名数据科学家，探讨他们在构建预测建模任务的目标变量时所采用的方法。", "innovation": "本文揭示了数据科学家通过拼凑过程构建目标变量的机制，该过程涉及对高层次测量目标和低层次实践约束之间的迭代协商。数据科学家通过满足目标变量的有效性、简化性、预测性、可移植性和资源需求等五大标准来进行拼凑。他们灵活地调整预测建模问题的表述方式，例如，当第一个目标变量无法满足某些标准（如预测性）时，便将其替换为另一个目标变量，或将多个结果综合为一个目标变量，以实现更全面的建模目标。", "conclusion": "基于研究发现，本文为未来的人机交互（HCI）、协作研究（CSCW）和机器学习（ML）研究提供了支持目标变量构建的机遇，以更好地促进这一过程的艺术与科学。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02841", "html_url": "https://arxiv.org/abs/2507.02841", "title": "StepHint: 多层次逐步提示增强强化学习以推理", "title_en": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason", "authors": "Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan", "background": "强化学习与可验证奖励（RLVR）是提高大型语言模型复杂推理能力的一种有前景的方法。然而，当前的RLVR方法面临两大挑战：近似奖励问题，一个小错误可能导致原本正确的推理过程无效，严重影响训练效率；以及探索停滞现象，模型倾向于专注于其“舒适区”内的解决方案，缺乏探索更有效替代方案的动力。", "innovation": "本文提出了一种名为StepHint的新型RLVR算法，利用多层次逐步提示帮助模型更有效地探索解空间。StepHint从更强的模型生成有效的推理链，并通过所提出的自适应分区方法将这些链条划分为推理步骤。初始几步作为提示提供给模型，同时为模型提供多级提示（每级包含不同数量的步骤），引导模型探索更有希望的解子空间，同时保持其独立探索的灵活性。这种方式既缓解了近似奖励问题，提高了训练效率，又通过外部推理路径帮助模型发展更好的推理能力，使其跳出“舒适区”，克服探索停滞现象。", "conclusion": "StepHint在六个数学基准测试中优于竞争对手的RLVR增强方法，并在领域外基准测试中表现出优越的一般化性能和优于基线的结果。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02822", "html_url": "https://arxiv.org/abs/2507.02822", "title": "SynapseRoute：双状态大语言模型的自动路由切换框架", "title_en": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model", "authors": "Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun", "background": "随着大语言模型（LLMs）在实际应用中的广泛采用，选择合适的模型不仅需要考虑性能，还需要考虑运营成本。推理能力强的模型进一步拉开了‘思考’（高推理）模式和‘非思考’（快速、低成本）模式之间的成本差距。研究表明，大约58%的医疗问题只需使用非思考模式即可准确回答，无需进行高成本的推理过程。这种现象揭示了问题复杂性上的明显差异，表明动态路由查询至合适的模式以适应复杂性可以优化准确性和成本效益，以及整体用户体验。", "innovation": "本文提出了一种基于机器学习的动态路由框架SynapseRoute，它可以智能地将输入查询分配给思考或非思考模式。在多个医疗数据集上的实验结果表明，SynapseRoute不仅能提高总体准确率（0.8390 vs. 0.8272），还能将推理时间减少36.8%，并将token消耗减少39.66%。此外，定性的分析表明，在简单查询上过度推理可能会导致不必要的延迟甚至准确性的降低，这是我们的自适应路由所避免的。本文进一步引入了准确率-推理时间-token消耗（AIT）指数，以全面评估准确率、延迟和token成本之间的权衡关系。", "conclusion": "SynapseRoute能够通过智能地分配查询到合适的模式，优化准确性、成本效率和整体用户体验。此外，通过引入AIT指标，本工作还能够更好地评估各种方法在准确率、延迟和token成本之间的权衡关系。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02850", "html_url": "https://arxiv.org/abs/2507.02850", "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "title_en": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "authors": "Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas", "background": "该研究描述了语言模型（LMs）中存在的一个漏洞，该漏洞允许单个用户通过提供提示和对模型输出的投票（点赞/反对）来持续改变LM的知识和行为。这种攻击利用了在使用用户反馈进行偏好调整时LM的行为变化特性，即使是在没有恶意提示的情境下，也能增加生成带恶意信息的响应的概率。研究进一步探索了利用用户反馈进行模型控制的新方法，并展示了新的攻击机制，针对通过用户反馈训练的语言模型。", "innovation": "研究提出了一个新的攻击模型，即利用用户反馈进行未经授权的知识注入。这种攻击展示了即使是非常有限的偏好数据也能被用来对模型进行细粒度控制，同时也扩展了关于模型训练前期数据中毒和部署时提示注入的现有研究。通过这种方式，攻击者能够（1）插入模型之前不存在的事实知识，（2）修改代码生成模式，引入可利用的安全漏洞，（3）注入虚假的财经新闻。", "conclusion": "该研究通过实验证明了攻击的有效性，并揭示了一个重要的新发现：即语言模型的偏好调整功能即使在限制形式的偏好数据下也能实现细粒度的行为控制。同时，该研究为通过用户反馈训练的LM引入了一种新的攻击机制，进一步丰富了对该类模型安全性问题的理解。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02801", "html_url": "https://arxiv.org/abs/2507.02801", "title": "在非真相拍卖中协调竞价者的学习", "title_en": "Learning to Coordinate Bidders in Non-Truthful Auctions", "authors": "Hu Fu,Tao Lin", "background": "在诸如首出价拍卖和全付出拍卖等非真相拍卖中，多个独立竞价者的战略行为及其相应的贝叶斯纳什均衡通常难以刻画，并可能导致不良结果。设计更好的拍卖系统的一种替代方法是协调竞价者的行为，即让中介为竞价者提供建议的协调竞价策略，以实现贝叶斯协调均衡（BCE）。然而，BCE的实现需要知道竞价者私人估值的分布，而在实际场景中这通常是不可获取的。因此，本文开始研究在非真相拍卖中学习贝叶斯协调均衡的样本复杂性问题。研究表明，在包括首出价拍卖和全付出拍卖在内的大型非真相拍卖类别中，可以通过竞价者价值分布的多项式数量级（约$\tilde O(\frac{n}{\\varepsilon^2})$）样本来学习BCE。这种方法包括将问题转化为从样本估计竞价者期望效用的问题，以及分析所有单调竞价策略类的伪维度的分析。", "innovation": "本文提出了一种通过有限样本数来学习贝叶斯协调均衡的方法，这对于难以获得私人估值分布的非真相拍卖具有重要意义。研究证明了在大型非真相拍卖类别中，可以通过多项式数量级的样本数来实现这一学习目标。此方法建立在估计竞价者期望效用的样本法和分析单调竞价策略类的伪维度基础上。", "conclusion": "本文研究了在非真相拍卖中学习贝叶斯协调均衡的样本复杂性问题。证明了可以通过竞价者价值分布的多项式数量级的样本数来学习贝叶斯协调均衡，并提出了一种基于从样本估计期望效用量和分析单调竞价策略类伪维度的方法。这种方法为设计更好的拍卖系统提供了一种可行的视角。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02824", "html_url": "https://arxiv.org/abs/2507.02824", "title": "基于DNN的辅助毫米波MIMO系统中的RIS辅助预编码", "title_en": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift", "authors": "Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang", "background": "本文研究了在毫米波（mmWave）多输入多输出（MIMO）系统中，当存在遮挡的直接通信路径时，如何利用可重构智能表面（RIS）优化预编码设计，以最大化吞吐量。传统的连续相位搜索（ES）方法在寻找最优码字时计算量大且耗时，特别是在考虑mmWave的视线（LoS）和多径效应特性时。为了简化计算复杂度，提出了使用排列表格傅里叶变换（DFT）向量，并结合实际或理想的RIS系统的幅度响应来设计码本。尽管在相位搜索中使用了离散相位，计算同样复杂且耗时。因此，本文开发了一种训练后的深度神经网络（DNN）以加快码字选择过程", "innovation": "本文创新地提出了利用深度神经网络（DNN）进行快速码字选择的方法，以简化传统搜索方法中的计算复杂度，提高RIS辅助毫米波MIMO系统的效率和性能。在实际测试中DNN能够保持接近最优的频谱效率，展示了DNN在RIS辅助系统中的潜在优势", "conclusion": "研究表明，即使在测试阶段RIS与终端用户的距离发生变化，DNN仍然能够保持接近最优的频谱效率，突显了DNN在RIS辅助系统中的应用潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02856", "html_url": "https://arxiv.org/abs/2507.02856", "title": "答案匹配在语言模型评估中优于多项选择", "title_en": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation", "authors": "Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping", "background": "多项选择题长期以来是语言模型评估的工具，因为基于自动化的客观性评价较为容易。然而，论文指出，许多流行的基准数据中的多项选择题往往无需查看即可回答，这是因为区分性评估固有的局限性，而划分这一局限性是鉴别性分析所不具备的。尽管过去似乎没有可行的替代方案，但本文证明了这已经发生变化。因此，研究者们考虑了通过答案匹配进行生成性评估的方法：向候选模型提供问题而不出选项，让模型生成自由形式的答案，然后使用现代语言模型和参考答案来判断响应是否匹配参考答案。", "innovation": "研究者提出了通过现代语言模型进行答案匹配的生成性评估方法。这种方法通过将候选模型生成的答案与参考答案匹配来评估，证明即使是小型模型，在这种方法上的表现也非常接近人工标注者的一致性。相比之下，使用参考答案以外的方法（如多项选择题或仅用大语言模型作为裁判）与人工评分的契合度较差。此外，这种方法改变了多个模型的表现排名。这表明了通过答案匹配改进评估的重要性，并讨论了如何从多项选择评估转向答案匹配评估的方式。", "conclusion": "研究发现，使用现代语言模型的答案匹配方法在语言模型评估中优于多项选择评估。由于这种方法能够有效反映模型的真实能力，其在不同评估策略的性能表现出优良的一致性。模型的排名和评分也因为答案匹配而有了显著变化，表明这种方法在模型评估中具有重要作用。未来可以考虑推广使用答案匹配来进行语言模型评估，推动评估生态系统的进步。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02851", "html_url": "https://arxiv.org/abs/2507.02851", "title": "MOTIF: 导引式强化微调以实现LLMs的模块化推理", "title_en": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "authors": "Purbesh Mitra,Sennur Ulukus", "background": "近年来，大型语言模型（LLMs）在推理能力上的进步表明，使用群组相对策略优化（GRPO）算法进行强化学习（RL）训练，可以使模型在生成更好响应时使用更多的思考/推理令牌。然而，LLMs在生成令牌时会受到以前生成令牌的关注限制，即LLM的上下文大小。这个限制是LLM推理的一个瓶颈，尤其是当涉及到任意数量的令牌时。因此，必须有一种方法使LLMs能够超出上下文大小的限制，实现多轮推理。在本文中，我们提出了MOTIF（模块化思考通过强化微调）方法，以在多轮中生成思考令牌，从而让模型在额外的上下文大小下进行思考。通过参数高效微调开源模型Qwen2.5-3B-Instruct并测试其在MATH500和AIME2024基准上的准确性，实验表明MOTIF在基准测试中的表现优于基于GRPO的普通训练，分别提高了3.8%和3.3%，同时只使用了15%的样本数据，展示了MOTIF的样本效率。", "innovation": "提出了一种名为MOTIF的新方法，用于多轮生成思考令牌，从而在额外的上下文大小下促进模型的推理。MOTIF通过参数高效微调实现了在强化学习训练中的模块化推理，并展示了在特定基准测试中的样本效率优势。", "conclusion": "实验结果表明，MOTIF在基准测试中的表现优于常规GRPO训练方法，且所需的样本数据更少，展示了其在强化学习和多轮推理方面的潜力。已经公开了MOTIF的代码和模型。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2304.13431", "html_url": "https://arxiv.org/abs/2304.13431", "title": "隐式反事实数据增强以提高稳健学习", "title_en": "Implicit Counterfactual Data Augmentation for Robust Learning", "authors": "Xiaoling Zhou,Ou Wu,Michael K. Ng", "background": "机器学习模型容易捕捉非因果属性与类别之间的虚假关联。反事实数据增强是一种有希望的解决这些虚假关联的方法，但由于显式生成反事实数据具有挑战性，将增强数据融入训练过程会降低训练效率，因此需要一种新的方法来实现这一目标。", "innovation": "该研究提出了隐式反事实数据增强（ICDA）方法，该方法通过开发一种新的样本自适应增强策略，生成具有不同增强强度的语义和反事实意义上的深刻特征；提出了计算简便的代理损失函数，并提出了直接量化和元学习两种方案，以确定鲁棒损失的关键参数；ICDA从正则化角度解释，展示了其在提高类别内紧致性和增加分类和样本水平的余量方面的潜力。", "conclusion": "通过对各种有偏学习场景（包括图像和文本数据集）进行大量实验，证明了ICDA可以持续提升流行网络的泛化能力和鲁棒性表现。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02863", "html_url": "https://arxiv.org/abs/2507.02863", "title": "Point3R：具有显式空间指针记忆的流式3D重建", "title_en": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "authors": "Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu", "background": "从有序或无序图像序列中进行密集的3D场景重建是将计算机视觉的研究成果应用到实际场景中的关键步骤。主板提出的方法DUSt3R将图像对在共享坐标系中密集地统一起来，后续方法保持一种隐含的记忆来实现从更多图像的密集3D重建。然而，这种隐含记忆有容量限制且可能会导致早期图像的信息丢失。因此，需要一种新的方法来解决这一问题。本研究旨在提出一种在线框架Point3R，专注于流式的3D重建。", "innovation": "Point3R提出了一个直接与当前场景的3D结构相关的显式空间指针记忆。每个记忆中的指针都有一个特定的3D位置，并将其周围环境的信息聚合到全局坐标系中的变动空间特征中。来自最新帧的信息与指针记忆进行显式交互，使得当前观察结果能够被密集集成到全局坐标系中。此外，本研究还设计了一种3D分层位置嵌入促进这种交互，并设计了一个简单而有效的融合机制来确保指针记忆的一致性和高效性。研究表明，Point3R在不同任务上取得了竞争力或最先进的性能，且训练成本较低。", "conclusion": "Point3R通过引入显式的空间指针记忆，提出了一个用于流式3D重建的在线框架，该框架能够在全局坐标系中更有效地进行3D场景的重建。实验结果显示，相较于现有方法，Point3R不仅能够提供更好的性能，而且具有较低的训练成本。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2102.11210", "html_url": "https://arxiv.org/abs/2102.11210", "title": "Spectral Radius Regularization for Non-Convex Optimization", "title_en": "Non-Convex Optimization with Spectral Radius Regularization", "authors": "Adam Sandler,Diego Klabjan,Yuan Luo", "background": "在训练深度神经网络时，找到平滑的最小值（平最小值）有助于模型在实际测试数据上更好地泛化，尤其是当这些测试数据与训练数据分布不同的时候。论文提出了一种正则化优化方法，通过减小损失函数海森矩阵的谱半径来寻找平最小值，并证明了该方法在不同领域的实际应用中有效，包括医疗健康领域。论文还介绍了多项测试方法来验证模型的泛化能力，并证明了提出的模型在这些测试中优于基准模型。", "innovation": "论文开发了一种正则化优化方法，通过减小损失函数海森矩阵的谱半径来寻找平最小值，从而提高模型在实际测试数据上的泛化能力。此外，还提供了一套高效的算法优化神经网络模型，并证明了这些算法几乎肯定收敛。最后，通过在不同领域的应用验证了该方法的有效性，并利用多种方法进行了泛化能力的测试和对比。", "conclusion": "通过采用谱半径正则化的方法，论文在非凸优化中成功找到了能够更好地泛化到真实世界数据的平最小值。实验结果表明，基于该方法训练的模型在其假设的应用场景中表现出了显著的优越性，特别是在医疗健康等实际应用中验证了其有效性，证明了该方法在提高模型泛化能力方面的创新性和实用性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.13836", "html_url": "https://arxiv.org/abs/2403.13836", "title": "基于树的学习方法用于高保真混沌预测", "title_en": "Tree-based Learning for High-Fidelity Prediction of Chaos", "authors": "Adam Giammarese,Kamal Rana,Erik M. Bollt,Nishant Malik", "background": "混沌系统的时域演变模型自由预测至关重要但具有挑战性。现有解决方案需要调参，这显著阻碍了它们的广泛应用。现有的预测方法常常依赖于超参数调优，从而限制了它们的实际应用效果和范围。因此，迫切需要一种无需调参即可实现高保真混沌预测的方法。", "innovation": "本文提出了一种无需调参的树基方法——TreeDOX。TreeDOX使用时间延迟嵌入作为显式的短期记忆，并采用Extra-Trees回归器进行特征降维和预测。该方法在Henon映射、Lorenz系统和Kuramoto-Sivashinsky系统，以及实际的地中海摇摆指数上展示了卓越的性能。", "conclusion": "TreeDOX在混沌系统预测方面取得了最先进的表现，提供了一种新颖且有效的解决方案。相较于现有依赖于调参的方法，TreeDOX能够更简便地应用于混沌系统的预测中。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.00155", "html_url": "https://arxiv.org/abs/2403.00155", "title": "通过概率潜在空间解释深度神经网络压缩", "title_en": "Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space", "authors": "Mahsa Mozafari-Nia,Salimeh Yasaei Sekeh", "background": "尽管深度神经网络（DNNs）表现出色，但由于其计算复杂性和存储空间的高消耗，网络压缩的概念应运而生。虽然剪枝和低秩分解等DNN压缩技术已经被广泛研究，但这些方法的理论解释却较少受到关注。本文的背景是研究一种新的理论框架，该框架借助DNN权重的概率潜在空间，通过信息论的离散度度量来解释最优网络稀疏性。研究者提出了一种新的类比投影模式（AP2）和类概率投影模式（AP3）的概念，并证明了网络中各层的AP3/AP2属性与性能之间存在关系。研究者还提供了关于压缩网络训练过程的理论分析，并通过实验验证了这些理论结果。实验结果表明AP3和AP2属性与精细调整剪枝DNN和稀疏性水平有关。", "innovation": "本文的创新在于提出了一个全新的理论框架，借助DNN权重的概率潜在空间，利用信息论的离散度度量来解释最优网络稀疏性，并且提出了新的类比投影模式（AP2）和类概率投影模式（AP3）的概念，证明了网络中各层的AP3/AP2属性与性能之间的关系，提供了关于压缩网络训练过程的理论分析。这是不同于传统DNN压缩方法理论解释的一次尝试，也为其提供了新的理论依据和研究方向。", "conclusion": "本文通过实验验证了新的理论框架和概念，对于剪枝DNN的训练过程提供了新的解释，并揭示了AP3和AP2属性与网络压缩性能之间的关系。实验证明新的理论框架有效，并提示了进一步研究的方向。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.08062", "html_url": "https://arxiv.org/abs/2402.08062", "title": "通过求助避免在线学习中的灾难", "title_en": "Avoiding Catastrophe in Online Learning by Asking for Help", "authors": "Benjamin Plaut,Hanlin Zhu,Stuart Russell", "background": "大多数具有形式后悔保证的学习算法假定所有错误都是可恢复的，并且几乎依赖于尝试所有可能的行为。然而，当某些错误是‘灾难性的’，即不可恢复时，这种做法是有问题的。本文讨论了在这种情况下如何最小化灾难发生的概率的问题。具体来说，每轮的收益代表的是避免本轮灾难的机会，并试图最大化所有轮次的整体避免灾难的机会，同时允许有限次数的向导师查询。文中还假设代理可以转移相似输入的知识。然而，一般情况下，任何算法要么以线性速率查询导师，要么几乎不可避免地会导致灾难。在导师策略类可由标准在线模型学习的情况下，文章提供了一个算法，其后悔和查询导师的速率都随着时间窗口的增长而趋近于0。", "innovation": "提出了一种在线学习问题，目标是在有限查询导师的情况下最小化灾难发生的概率。此外，在通常情况下，任何算法要么以线性速率查询导师，要么几乎不可避免地导致灾难。然而，在特定条件下，如果导师策略类可在标准在线模型下学习时，提供了接近最优的算法，该算法的后悔和查询导师的速率都趋向于0。该研究还探讨了如果代理能够求助，即使存在灾难风险，学习策略类也是可能的。这为带有灾难风险的学习环境提供了一种新的学习框架。", "conclusion": "在无灾难风险的情况下可学习的策略类，在存在灾难风险且能求助的情况下，也是可以学习的。未来的研究可以进一步探讨提高查询效率的方法，以及在更复杂环境下的应用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2202.05928", "html_url": "https://arxiv.org/abs/2202.05928", "title": "Benign Overfitting without Linearity: 善意过拟合无需线性：由梯度下降训练的神经网络分类器在噪声线性数据上的表现", "title_en": "Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data", "authors": "Spencer Frei,Niladri S. Chatterji,Peter L. Bartlett", "background": "善意过拟合，即插值模型在出现噪声数据时仍能表现出良好的泛化能力，最初是在使用梯度下降训练的神经网络模型中观察到的现象。本研究进一步探讨这一现象，通过分析梯度下降训练的两层神经网络在对数损失函数下的插值情况来理解这一经验观察。研究假定数据来自条件对数凹分布，并允许训练标签的一部分被对手污染。研究表明，在这样的设置下，神经网络会表现出善意过拟合：在训练中可以完美地适应任何噪声标签，实现零训练误差，同时保持最小对数效验错误率。", "innovation": "与之前需要线性或核模型的善意过拟合研究不同，本研究提出了即使在模型和学习动态都本质上是非线性的场景下，也存在善意过拟合的可能性。这意味着，即使在非线性模型中，也可以观察到善意过拟合的现象，无需依赖于线性或核方法。因此，这项工作扩展了善意过拟合的概念，并展示了其在更广泛的模型和数据条件下的稳健性。", "conclusion": "在本文研究中，我们证明了即使数据包含噪声，梯度下降训练的两层神经网络也能表现出善意过拟合：它们仍然可以达到零训练误差，同时实现最优效验错误率。这表明，模型在处理非线性和噪声数据时能够保持良好的泛化能力，而不损失训练精度。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.03449", "html_url": "https://arxiv.org/abs/2405.03449", "title": "御用叛乱抗御的传播：双重方法的见解", "title_en": "Byzantine-Robust Gossip: Insights from a Dual Approach", "authors": "Renaud Gaucher,Aymeric Dieuleveut,Hadrien Hendrikx", "background": "分布式学习具有许多计算上的优势，但也容易受到一小部分设备传输错误信息的攻击。在分散式设置中，设备通过通信网络直接进行点对点的通讯。本研究探讨了在存在潜在叛乱节点的条件下，适用于分散式环境的御用叛乱抗御算法。", "innovation": "采用所谓双重方法进行分散式优化，提出了一种御用叛乱抗御算法。在平均一致子案例中提供了收敛保证，并讨论了双重方法在其他场景中的潜力，重新解释了现有的算法使用双重框架，并通过实验展示了方法的有效性.", "conclusion": "该研究通过实验表明了方法的可靠性，并提供了在存在御用节点的分散式环境中算法的收敛保证。同时，提出了双重框架在其他算法解释中的应用潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.12335", "html_url": "https://arxiv.org/abs/2403.12335", "title": "_tcKAE_时序一致的Koopman自编码器用于动力系统预测", "title_en": "Temporally Consistent Koopman Autoencoders for Forecasting Dynamical Systems", "authors": "Indranil Nayak,Ananda Chakrabarty,Mrinal Kumar,Fernando Teixeira,Debdipta Goswami", "background": "高维度时空动力系统的数据驱动建模时常面临数据质量不足的挑战。Koopman Autoencoders（KAEs）结合了深度神经网络的强大表达能力、自编码器的降维能力和Koopman算子的频谱性质，以学习一个简化且线性的特征空间。然而，KAEs的效果受限于有限且噪声较大的训练数据集，导致较差的泛化能力。为了应对这一问题，本文提出了一种时序一致的Koopman自编码器（tcKAE），该模型旨在即使在有限且噪声较大的训练数据下也能生成准确的长期预测。这通过一个保证预测在不同时间步长上具有一致性的正则化项实现，从而增强tcKAE的鲁棒性和泛化能力，超越现有模型。", "innovation": "本文引入了一种时序一致的Koopman自编码器（tcKAE），它通过增加一个一致性正则化项，强制预测在不同时间步长上具有一致性，从而增强模型的鲁棒性和泛化能力，即使在有限且噪声较大的训练数据下也能提供准确的长期预测。该方法的合理性基于Koopman谱理论，并通过实验结果证明了tcKAE相比最先进的KAE模型在多种测试案例（如简单摆振、等离子体动力学及流体流动数据）上具有更好的性能", "conclusion": "实验结果显示，tcKAE在多种测试案例上优于最先进的KAE模型，通过正则化项增强了模型的鲁棒性和泛化能力，使其在有限且噪声较大的训练数据下也能提供准确的长期预测。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.00034", "html_url": "https://arxiv.org/abs/2409.00034", "title": "神经CRNs：化学反应网络中学习的自然实现", "title_en": "Neural CRNs: A Natural Implementation of Learning in Chemical Reaction Networks", "authors": "Rajiv Teja Nagipogu,John H. Reif", "background": "该研究介绍了一种名为Neural CRNs的通用化学神经网络框架，它直接将学习嵌入到基于质量作用定律的化学反应系统中。不同于之前的使用离散神经计算的化学实现方法，Neural CRNs采取了模拟计算方法，学习的前向和后向阶段都作为分子浓度的连续时间演化被实现。这种方法与化学动力学的模拟性质自然契合，使得电路简洁且可行。研究通过构建仅需两个阶段执行的简化监督学习过程来展示其效率。多个学习电路被实现以展示框架的线性和非线性建模能力，并验证其学习过程的有效性。这些电路仅使用单分子和双分子反应构建，避免了高阶化学复杂性的问题。", "innovation": "Neural CRNs采用模拟计算方法，使得学习的前向和后向阶段分别作为分子浓度的连续时间演化被实现。这种方法自然地与化学动力学的模拟性质相吻合，使得电路简洁且可行。研究通过仅需两个阶段执行的简化监督学习过程展示了其效率。这些应用于化学反应网络中的电路是完全使用单分子和双分子反应构建的，从而避免了高阶化学复杂性。这种紧凑、可扩展且自治的化学学习框架为合成生物学、生物工程和生物医学中的自适应计算开辟了新的途径。", "conclusion": "Neural CRNs提供了一种紧凑、可扩展和自治的化学学习框架，为合成生物学、生物工程和生物医学中的自适应计算开辟了新的途径。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2303.06827", "html_url": "https://arxiv.org/abs/2303.06827", "title": "Kernel Density Bayesian Inverse Reinforcement Learning", "title_en": "Kernel Density Bayesian Inverse Reinforcement Learning", "authors": "Aishwarya Mandyam,Didong Li,Jiayu Yao,Diana Cai,Andrew Jones,Barbara E. Engelhardt", "background": "逆强化学习（IRL）方法通过专家行为的演示来推断代理的奖励函数。贝叶斯逆强化学习方法构建候选奖励函数的概率分布，捕获对推断出的奖励函数的不确定性。然而，典型的贝叶斯逆强化学习算法需要大量的演示数据集，这在实践中可能不可用。在这个工作中，作者将现有的领域特定数据纳入进来，以实现更好的后验收敛率。文章讨论了在临床和生物学应用中常见的场景，其中可以访问专家演示和一组训练任务的已知奖励函数。目标是在有限的专家演示下学习新的测试任务的奖励函数。现有的贝叶斯逆强化学习方法对输入数据的形式有一定的限制，这限制了可以纳入的训练任务数据量。为了更好地利用训练任务的信息，作者引入了核密度贝叶斯逆强化学习（KD-BIRL）。该方法使用条件核密度估计器，利用训练任务的已知奖励函数来改进多种奖励函数和演示样本的似然估计。实验结果显示，KD-BIRL比基线方法在目标任务专家演示数据较少的情况下具有更快的收敛率。此外，首次为贝叶斯逆强化学习算法提供了后验收敛的理论保证。这项工作提供了一个原则性和理论根据的框架，使得贝叶斯逆强化学习能够在多种领域得到应用。", "innovation": "作者提出了一种新的方法——核密度贝叶斯逆强化学习（KD-BIRL），这是一种克服传统贝叶斯逆强化学习方法需要大量数据限制的创新性解决方案。该方法通过利用训练任务的已知奖励函数来改进奖励函数估计过程中的似然估计，从而在后验集中表现更快的收敛率，特别是在测试任务专家演示数据较少的情况下。此外，作者还提供了贝叶斯逆强化学习算法的后验收敛的理论保障，这是本领域的首次研究。这种方法可以广泛应用于涉及临床数据的应用中，填补了这一领域的空白。", "conclusion": "本文介绍了核密度贝叶斯逆强化学习的方法，它能够在有限的专家演示下快速收敛，特别适用于缺少专家演示的测试任务。此外，该方法提供了贝叶斯逆强化学习算法的理论保证，首次解决了这一问题。这种方法为贝叶斯逆强化学习在多种应用场景中的应用提供了有力支持。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21553", "html_url": "https://arxiv.org/abs/2410.21553", "title": "探索扩散桥模型的设计空间", "title_en": "Exploring the Design Space of Diffusion Bridge Models", "authors": "Shaorong Zhang,Yuanbin Cheng,Greg Ver Steeg", "background": "扩散桥模型和随机插值方法能够通过在像素空间中间分布创建路径，实现高质的图像到图像（I2I）转换。然而，基于不兼容数学假设的技术多样化限制了进展。现有的技术基于不同的数学假设，阻碍了进一步的发展和创新。", "innovation": "本文通过将随机插值（SIs）扩展为预处理、端点条件和优化采样算法，统一和扩展了扩散桥模型的设计空间。这些增强使得扩散桥模型更具设计灵活性，实现了在多种I2I任务中领先的质量和采样效率。同时，本文还指出了在固定条件下样本多样性不足的问题，并提出了解决方案。", "conclusion": "实验结果显示，通过解决固定条件下的样本多样性不足问题，输出多样性得到显著提升。改进的基础分布进一步提高了模型性能，展示了扩散桥模型在I2I任务中的最新技术水平。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.16985", "html_url": "https://arxiv.org/abs/2407.16985", "title": "面向方向感知的稀疏张量主成分分析及其高效无监督特征选择", "title_en": "Orientation-Aware Sparse Tensor PCA for Efficient Unsupervised Feature Selection", "authors": "Junjing Zheng,Xinyu Zhang,Weidong Jiang,Xiangfeng Qiu,Mingjian Ren", "background": "近年来，将张量分解（Tensor Decomposition, TD）技术引入无监督特征选择（Unsupervised Feature Selection, UFS）成为了研究热点。张量结构有助于挖掘不同模式之间的关系，并有助于缓解计算负担。然而，现有方法在利用TD保存数据张量结构的同时，并未考虑数据方向的影响，因此在处理具有特定方向性的数据（如时间序列）时存在困难。本文正是为了解决这一问题而提出的。", "innovation": "本文提出了方向感知的稀疏张量主成分分析（Orientation-Aware Sparse Tensor PCA）模型，该模型基于张量奇异值分解（Tensor Singular Value Decomposition based on *M-product, T-SVDM）的张量-张量乘积，将一维稀疏主成分分析（Sparse Principal Component Analysis, SPCA）扩展到张量形式。该模型能够限制特定模式下的稀疏性，产生稀疏张量主成分，从而增强学习特征关系的灵活性和准确性。此外，还开发了一种凸版本，专门用于通用的UFS任务，提出了一种高效的切片-切片算法，在变换域中执行双重优化，确保快速收敛并灵活描述特征相关性。实验结果表明，该方法在不同类型的数据张量上相比于现有的先进方法具有有效的性能和显著的计算效率。", "conclusion": "当变换轴与特征分布模式对齐时，本文提出的方法在各种应用中表现良好。相关代码及实验可在以下链接中获取：this https URL。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.12537", "html_url": "https://arxiv.org/abs/2410.12537", "title": "复杂查询回答真的复杂吗？", "title_en": "Is Complex Query Answering Really Complex?", "authors": "Cosimo Gregucci,Bo Xiong,Daniel Hernandez,Lorenzo Loconte,Pasquale Minervini,Steffen Staab,Antonio Vergari", "background": "知识图谱(KGs)上的复杂查询回答(CQA)正成为一项有挑战性的推理任务。现有的CQA基准可能并不像我们想象的那么复杂，因为它们的构建方式扭曲了我们对该领域进步的感知。研究表明，很多查询（某些类型高达98%）可以被简化为需要预测单一链接的简单问题。当现有的CQA模型在不能简化为简化类型的问题上进行评估时，性能会显著下降。", "innovation": "本文提出了一套更加具有挑战性的基准，这些基准包含需要模型跨越多个跳进行推理的问题，更好地反映了现实世界中的知识图谱构建情况。新的基准揭示了当前方法的不足之处，证明了现有的CQA方法还有很大的改进空间。", "conclusion": "通过系统性的实证研究，新基准表明现有的CQA方法还有较大的改进空间。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.10576", "html_url": "https://arxiv.org/abs/2406.10576", "title": "绕过反向传播：基于策略梯度的大型语言模型结构剪枝方法", "title_en": "Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient", "authors": "Yuan Gao,Zujing Liu,Weizhong Zhang,Bo Du,Gui-Song Xia", "background": "当前的大型语言模型（LLMs）剪枝方法通常在后训练阶段进行，不需要昂贵的权重微调。然而，他们的剪枝准则往往依赖于手工构建的度量标准，可能会导致性能欠佳。这种方法主要依靠经验性的手工设计指标，没有系统性的优化方法来指导剪枝策略。已有研究通过后训练剪枝方法进行了权重微调的过程，但这种方法伴随着性能下降的风险。因此，需要一种新的剪枝方法，可以在保持高效性的同时，通过优化方法来学习剪枝掩码，从而获得更好的性能。这种方法需要减少对LLMs的反向传播依赖，仅利用模型的前向传递来加速优化过程。", "innovation": "该方法创新性地提出了一个基于优化的结构剪枝方法，能够在概率空间中直接学习剪枝掩码，而无需经过复杂的反向传播过程。具体而言，该方法通过学习一个二项分布来采样二进制剪枝掩码，将二项分布参数与LLM损失脱钩，从而可以有效地使用策略梯度估计器进行优化，而无需反向传播。这种方法能够支持全局和异构的剪枝策略，即自动确定不同层的冗余度，并可选地与基于度量的初始化方法结合使用。实验结果表明，该方法在C4和WikiText2数据集上，在LLaMA、LLaMA-2、LLaMA-3、Vicuna和Mistral模型上的性能优越。", "conclusion": "本研究提出了一种基于策略梯度的大型语言模型剪枝方法，有效解决了传统的后训练剪枝方法面临的效率和效果问题。实验结果表明，该方法能够提高剪枝模型的效率和效果，在不同的模型上均表现出良好的性能，并且该方法还提供了全局和异构的剪枝支持，增强了剪枝结果的多样性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.05197", "html_url": "https://arxiv.org/abs/2411.05197", "title": "硬件和软件平台推断", "title_en": "Hardware and Software Platform Inference", "authors": "Cheng Zhang,Hanna Foerster,Robert D. Mullins,Yiren Zhao,Ilia Shumailov", "background": "由于自建大型语言模型（LLM）推理所需的庞大前期硬件基础设施和能源成本，现在企业倾向于购买LLM推理访问，而不是自行搭建。但是，作为买家，没有机制验证服务的真实性，包括托管硬件平台（例如是否使用NVIDIA H100）。此外，有报道称，模型提供商可能会交付与其所宣传的略有不同的模型，通常是为了能够在较便宜的硬件上运行，使得客户支付高价以访问强大的模型，而实际上可能在较便宜、可能性能较差的硬件上运行。因此，客户面临隐藏的服务硬件提供风险，可能会被不真实的服务行为所误导。这个问题亟需解决方案以确保透明的服务交付过程，准确辨别所使用的GPU架构及其对应的软件配置，提高服务的真实性和用户信任度。", "innovation": "本文提出了一种方法——硬件和软件平台推断（HSPI），仅通过分析输入和输出行为，即可确定（黑盒）机器学习模型的底层GPU架构和软件堆栈。通过利用不同GPU架构和编译器的固有差异来区分不同的GPU类型和软件堆栈，该方法能够准确识别模型推理所用的GPU及其底层软件配置。实验结果表明，无论是白盒还是黑盒环境下，HSPI都可以显著提高区分不同GPU的准确率。HSPI不仅是一种有价值的工具，可以解决服务买家对服务真实性的担忧，还为实际应用场景提供了技术保障。HSPI 的代码现已开源。", "conclusion": "发现了通过黑盒模型推断GPU类型的可行性，并在不同实际硬件上评估了HSPI的结果。在白盒设置中，HSPI可以将不同GPU区分开的准确率在83.9%到100%之间。即使在黑盒设置下，HSPI的结果远远高于随机猜测的准确率。该方法展示了硬件和软件平台推断在透明服务交付中的巨大潜力，适用于提高模型服务的真实性和用户信任。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01940", "html_url": "https://arxiv.org/abs/2412.01940", "title": "废除层级：HNSW中的'H'代表‘节点’", "title_en": "Down with the Hierarchy: The 'H' in HNSW Stands for \"Hubs\"", "authors": "Blaise Munyampirwa,Vihan Lakshman,Benjamin Coleman", "background": "随着神经表示学习的近期突破，向量嵌入上的近似最邻近（ANN）搜索已经成为关键的计算工作负载。HNSW算法作为基于图的索引的一种里程碑式发展，已经成为了高效和可扩展ANN搜索占主导地位的范式。HNSW算法通过层次化图结构快速找到相似点的邻域，但对于这种层次结构是否必要尚无定论。因此，需要进行严谨的实验分析来探究HNSW层次结构在高维数据集中的必要性，并且探索为什么层次结构在高维数据中不提供好处的原因。这项研究旨在通过广泛的基准测试来填补这一空白，并提供了直接的实验证据来支持‘Hub高速公路假设’", "innovation": "研究通过全面的基准测试，展示了在高维数据集中，平坦的可导航小世界图可以保留HNSW算法的所有优点，同时在延迟和召回性能上与原算法基本一致，但具有更低的内存开销。此外，研究还探讨了HNSW层次结构在高维数据集中不提供额外好处的原因，提出了‘Hub高速公路假设’，并研究了高速公路形成的机制。这些发现为未来的图结构ANN搜索的改进提供了新的研究方向", "conclusion": "平坦的可导航小世界图在高维数据集中与HNSW算法具有相同性能，同时减少内存开销。这一发现表明，导航小世界图中存在一个高度连接的且频繁访问的‘高速公路’，它与层次结构的作用相类似。通过对实际数据集的分析，支持了‘Hub高速公路假设’，并探讨了高速公路形成的机制，有潜力指导未来对图结构ANN搜索改进的研究方向"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00420", "html_url": "https://arxiv.org/abs/2412.00420", "title": "TAROT: 通过最优传输进行目标化数据选择", "title_en": "TAROT: Targeted Data Selection via Optimal Transport", "authors": "Lan Feng,Fan Nie,Yuejiang Liu,Alexandre Alahi", "background": "过去的针对性数据选择方法主要依赖基于影响的贪婪启发式方法来增强特定领域的性能。尽管在单一模式数据上有效，但这些方法在复杂度增加的数据（如多模态分布数据）上表现不佳。主要原因在于高维影响估计中主导特征组件的不平等影响和贪婪选择策略中固有的线性加性假设导致未能充分考虑多个内在模式，从而导致数据选择的优化不足。", "innovation": "TAROT框架通过引入白化特征距离来减轻主导特征偏差，提供了一个更可靠的数据影响度量。TAROT利用白化特征距离量化并最小化所选数据与目标域之间的最优传输距离，这个最小化过程还便于估计最佳选择比例。该方法在多个任务（如语义分割、运动预测和指令调整）上进行了评估，结果表明TAROT在各个深度学习任务上都优于现有最先进的方法，展示了其灵活性和泛化能力。", "conclusion": "TAROT通过引入白化特征距离，克服了传统方法在处理多模态数据时遇到的局限，有效提高了性能，并且在多种深度学习任务中展示了其优越性和多样性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12370", "html_url": "https://arxiv.org/abs/2501.12370", "title": "参数 vs FLOPs：MoEs 语言模型的最优稀疏化扩展定律", "title_en": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models", "authors": "Samira Abnar,Harshay Shah,Dan Busbridge,Alaaeldin Mohamed Elnouby Ali,Josh Susskind,Vimal Thilak", "background": "语言模型的能力可以通过扩大其容量来提高，容量主要由模型参数的数量和每个示例的计算量两个维度定义。虽然扩大通常涉及同时增加这两个因素，但它们之间的确切交互作用以及对整体容量的共同贡献尚不完全清楚。本文在稀疏 MoEs 的背景下探索了这种关系，稀疏 MoEs 允许在不按比例增加每个示例的 FLOPs 的情况下扩大参数数量。本文研究了不同稀疏度水平（即非活动参数的比例）对模型预训练期间和下游少样本评估期间性能的影响。结果表明，不同约束条件下（如参数大小和总训练计算量），存在一个最优的稀疏度水平，能够提高训练效率和模型性能。", "innovation": "本文探索了稀疏 MoEs 中参数数量和计算量之间的关系，发现了在不同约束下存在最优稀疏度水平，能够提高训练效率和模型性能。这些结果提供了更深入了解稀疏度对 MoEs 扩展定律的影响，并补充了现有研究，为设计更高效的架构提供了见解。", "conclusion": "不同约束下，存在一个能够提高训练效率和模型性能的最优稀疏度水平。这些结果为理解稀疏度在 MoEs 扩展定律中的影响提供了更清晰的理解，并为设计更高效的架构提供了新的见解。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01391", "html_url": "https://arxiv.org/abs/2502.01391", "title": "从生成模型学习实时观察中的交通异常", "title_en": "Learning Traffic Anomalies from Generative Models on Real-Time Observations", "authors": "Fotis I. Giasemis,Alexandros Sopasakis", "background": "准确检测交通异常对于有效的城市交通管理和缓解交通拥堵至关重要。本文使用结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，捕捉交通数据中的复杂时空依赖性。研究对象是2020年在瑞典哥德堡收集的42个交通摄像头的实时、分钟级观测数据。这为通过先进的机器学习手段识别和处理交通中的异常情况提供了重要背景和技术支持.", "innovation": "本文创新性地采用了STGAN框架，结合了图神经网络和长短期记忆网络，以有效捕捉交通数据中的复杂时空依赖性。在哥德堡进行的实验表明，该模型能够高效地检测交通异常，具有高精度和低误报率。此外，模型成功识别了摄像头信号中断、视觉噪音以及极端天气对交通流的影响等因素，进一步体现了其在交通管理和监测方面的创新应用.", "conclusion": "研究结果表明，STGAN模型在实时交通监控中有效检测异常状况，具备高准确性和低误报率，能够帮助城市管理者更好地理解和应对交通问题，提升服务质量。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04700", "html_url": "https://arxiv.org/abs/2502.04700", "title": "EigenLoRAx: 通过回收适配器寻找主子空间实现资源高效适配和推理", "title_en": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference", "authors": "Prakhar Kaushik,Ankit Vaidya,Shravan Chaudhari,Alan Yuille", "background": "大型模型的快速增长引发了对其环境影响和访问公平性的担忧，主要是由于显著的计算成本。低秩适配器（LoRA）为大规模模型的微调提供了一种轻量级解决方案，导致了针对多样化领域的大量公开适配器的出现。本文探讨了利用这些预训练适配器是否能够进一步简化适应新任务的过程，同时解决这些挑战。", "innovation": "文章提出了EigenLoRAx方法，这是一种参数高效的微调方法，该方法能够重新利用现有的适配器来创建与共享领域知识对齐的主要子空间，并能够在资源紧张的情况下进一步扩展正交基向量。通过仅学习主子空间的轻量级系数，可以快速适应新任务，彻底消除对整个适配器的微调需求。EigenLoRAx需要更少的参数和内存，提高了对训练和推理的效率。该方法在多种领域和任务上表现出强大的性能，为边缘计算应用、个性化以及在资源受限环境中公平部署大型模型提供了可扩展的解决方案。", "conclusion": "EigenLoRAx方法提高了效率，尤其在训练和推理方面，适用于多种领域和任务，为资源受限环境中的边缘计算应用和个人化提供可扩展的解决方案，并且能够公平地部署大型模型。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06106", "html_url": "https://arxiv.org/abs/2502.06106", "title": "电路调优：一种用于识别参数冗余和调整神经网络的机理方法", "title_en": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks", "authors": "Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang", "background": "该研究关注机制可解释性，旨在反向工程模型以解释其行为。尽管最近的研究集中在模型某种行为的静态机制上，但模型内部的学习动态仍需进一步探索。本文旨在开发一种可解释的微调方法来分析学习机制。通过引入节点内在维度的概念，研究提出了一种电路调优的两阶段算法，该算法可以迭代构建特定任务所需的最小子图并以启发式方式更新关键参数。实验结果表明，存在节点层面的内在维度，并证明了该方法在透明和可解释的微调中的有效性。研究还对微调前后电路进行了可视化和分析，提供了神经网络在学习过程中的自组织机制的新见解。", "innovation": "提出了电路调优的两阶段算法，通过节点内在维度的概念描述模型的计算图中的学习过程，迭代构建特定任务所需的最小子图，并以启发式方式更新关键参数。这种方法在透明和可解释的微调方面展现出了新的见解。", "conclusion": "实验结果证实了节点层面存在内在维度，并验证了该方法的有效性，提供了神经网络在学习过程中的自组织机制的新视角。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06684", "html_url": "https://arxiv.org/abs/2502.06684", "title": "EquiTabPFN: 目标排列等变先验网络", "title_en": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks", "authors": "Michael Arbel,David Salinas,Frank Hutter", "background": "近年来，TabPFN等面向表格数据的基础模型在上下文学习方面表现出色，但它们仍然受限于固定的目标维度数量，这通常需要昂贵的集成策略。这一限制归根结底是模型缺乏目标等变性，导致目标维度顺序变化会影响预测结果，从而产生不可避免的‘等变性缺口’，增加了预测的不稳定性。", "innovation": "本文通过设计一个完全目标等变的架构，采用等变编码器、解码器和双注意机制来确保排列不变性。实验结果表明，在有更多类别的数据集上，该模型匹配或超过了现有方法，同时具有较低的计算开销，解决了长期存在的‘等变性缺口’问题，提高了模型的稳定性和效率。", "conclusion": "本文评估了标准分类基准数据集上的表现，证明了在目标类别超过预训练数据集的条件下，新型模型不仅达到甚至超过了当前方法的效果，同时还减少了计算成本。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.11853", "html_url": "https://arxiv.org/abs/2502.11853", "title": "StructTransform：大型语言模型安全对齐的一种可扩展攻击面", "title_en": "StructTransform: A Scalable Attack Surface for Safety-Aligned Large Language Models", "authors": "Shehel Yoosuf,Temoor Ali,Ahmed Lekssays,Mashael AlSabah,Issa Khalil", "background": "该研究揭示了大语言模型（LLM）在对齐过程中存在的结构变换攻击。通过编码自然语言意图到多种语法空间中，研究者发现即使在限制严格的大语言模型中，这些攻击也能达到较高的成功率，这表明对齐机制对结构变换攻击的防范能力有限。此研究进一步探讨了各种结构格式，显示自动生成的新型语法能够提高攻击的成功率，表明防御这些攻击并非易事。当前的安全对齐防御机制大多依赖于词汇级别的模式，未能识别有害概念，这成为研究工作的关键动机。作为一种案例研究，研究结果展示了攻击者可以如何使用该研究攻击轻易生成恶意软件样本和欺诈短信内容，这些内容在绕过检测方面表现良好。", "innovation": "创新在于提出了结构变换攻击，并详细介绍了如何通过编码多样化的语法空间（从简单的结构格式到由LLM自动生成的新型语法）来执行这些攻击。实验进一步表明通过结合结构变换与现有内容变换可以显著提高攻击性能。此外，研究还创建了一个基准测试，并验证了现有安全对齐防御的有效性，结果显示大多数现有的安全对齐防御措施效果不佳，进一步凸显了在该领域进行深入研究的需求。", "conclusion": "研究发现，广泛采用的对齐机制在面对结构变换攻击时存在诸多局限，特别是对由大语言模型自动生成的新型语法的识别不足，表明在保护大语言模型免于此类威胁方面的挑战和需要。通过理论分析与实验验证，研究证明了对大语言模型进行结构性保护的复杂性，并强调了需要更深入地探索和开发新的安全性对齐方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.10589", "html_url": "https://arxiv.org/abs/2409.10589", "title": "离线强化学习在学习调度作业车间调度中的应用", "title_en": "Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling", "authors": "Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang", "background": "作业车间调度问题（JSSP）是一个复杂的组合优化问题。尽管在线强化学习（RL）能够快速找到JSSP的可接受解，但存在样本效率低、无法利用现有高质量的传统方法（例如约束编程CP）的标准解以及需要模拟环境来进行训练等局限性，这对于复杂的调度环境来说是不现实的。针对这些局限性，本文介绍了一种离线强化学习方法——离线学习调度（Offline-LD），通过历史调度数据进行学习，解决了上述问题。这种方法适用于历史调度数据和专家解决方案可用或在使用模拟环境进行在线训练不可行的场景。研究设计了两种可学习历史数据的Q学习方法变体，并提出了适用于掩码动作空间的d-mSAC的新型熵奖金修改，还提出了JSSP在离线RL设置中的新奖励归一化方法。实验表明，利用仅100个由CP生成的解决方案进行离线学习，Offline-LD在生成和基准实例上均优于在线学习RL，增强数据的引入也显示出有前景的结果，即在真实世界应用中数据是原始且不完美的情况下，噪声数据与原始数据效果相当或更佳。", "innovation": "1. 提出了离线学习调度（Offline-LD）方法，通过历史调度数据进行学习，弥补了在线RL的局限性。\n2. 引入了两种Q学习方法的掩码变体，即可学习历史数据的Maskable Quantile Regression DQN（mQRDQN）和可离散掩码Soft Actor-Critic（d-mSAC）。\n3. 为d-mSAC设计了用于掩码动作空间的新型熵奖金修改。\n4. 提出了JSSP在离线RL设置中的新奖励归一化方法。\n5. 证明了即使在引入噪声后，离线学习方法也可与标准方法相比拟或更具优势，这对实际应用中的数据不完美情况具有重要意义。", "conclusion": "本研究通过引入离线学习调度（Offline-LD）方法，有效解决了传统在线RL在离线环境下的局限性，通过对历史数据的学习优化了作业车间调度问题的解决方案。实验验证了Offline-LD方法在不同调度实例上的性能优越性，并且在数据质量不佳的情况下依然能够取得良好效果，为解决实际调度问题提供了一种新的可能性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20767", "html_url": "https://arxiv.org/abs/2503.20767", "title": "可靠的人工智能指导设计算法选择", "title_en": "Reliable algorithm selection for machine learning-guided design", "authors": "Clara Fannjiang,Ji Won Park", "background": "使用机器学习技术的机器学习引导设计算法能够根据预测提出具有期望属性的新颖对象。然而，在执行新的设计任务（例如设计具有高亲合性的新型蛋白质并与治疗性靶标结合）时，需要选择合适的算法并指定相关超参数、预测和生成模型。如何确保这个过程能够成功地产生目标属性的新颖设计则是研究关注的问题。本文通过结合预测属性值与保留标记数据，可靠预测不同设计算法生成标签分布的特性，从而提出了一种可靠的设计算法选择方法。", "innovation": "本文提出了一种结合预测属性值与保留标记数据的方法，以可靠地预测不同设计算法生成标签分布的特性，从而确保所选设计算法能够产生满足用户指定成功标准的标签分布。该方法在已知或可通过其他渠道估计的密度比情况下，能够以高概率确保成功。该方法在模拟的蛋白质和RNA设计任务中得到验证，性能良好。", "conclusion": "本文提出的方法能够高概率地提供能够产生成功标签分布的设计算法（如果不存在则返回空集），前提是知道设计数据和标记数据分布之间的密度比。该方法在较多种类的模拟数据集上表现出了有效性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.18530", "html_url": "https://arxiv.org/abs/2412.18530", "title": "关于语言生成的表征：幻觉、广度和稳定性的相互作用", "title_en": "On Characterizations for Language Generation: Interplay of Hallucinations, Breadth, and Stability", "authors": "Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas", "background": "该研究探讨了语言生成在极限中的问题，这一问题最初由Kleinberg和Mullainathan在[KM24]中提出，基于Gold [Gol67]和Angluin [Ang79]的经典工作。[KM24]的主要成果是为生成目标语言的任意可数语言集合提供了一种算法。他们的算法虽然最终能够生成来自目标语言K的新字符串，但是牺牲了覆盖或广度，即生成丰富字符串的能力。近年来，不同的广度概念已经被引入并研究，但是但对于这些概念的具体呈现，尚未给出全面描述。本论文通过分析现有广度概念及其自然扩展的形式，解决了这个问题。另外，研究还探讨了具备广度和稳定性的语言生成，即在看到任意数量的字符串后会停止变化的算法，并证明了这类算法的未有条件下的下限，加强了[KMV25]的研究结果，展示了在需要稳定性的情况下，许多现有广度概念的生成难度相同。这揭示了广度、稳定性和一致性的丰富相互作用在语言生成中的重要性，特别是在近似广度的生成中对于稳定性和非稳定生成之间的分离。", "innovation": "1. 通过表征现有广度概念及其自然扩展，填补了在语言生成中的广度概念描述上的空白。\n2. 研究了具备广度和稳定性的语言生成，提出了未条件下的下限，加强了现有的研究成果，展示了在需要稳定性的情况下，许多广度概念的生成难度相同。\n3. 揭示了广度、稳定性和一致性的丰富相互作用在语言生成中的重要性，特别是在近似广度的生成中对于稳定性和非稳定生成之间的分离。", "conclusion": "本论文通过表征现有广度概念及其自然扩展的形式，解决了先前在语言生成中广度概念描述上的问题。同时，通过探讨具备广度和稳定性的语言生成，揭示了广度、稳定性和一致性的丰富相互作用在语言生成中的重要性。研究还表明，即使是具备某些广度的生成，要求稳定性也会变得更加困难，这为语言生成的研究提供了一个新的视角。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04164", "html_url": "https://arxiv.org/abs/2504.04164", "title": "MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning", "title_en": "MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning", "authors": "Shiguang Sun,Hanbo Zhang,Zeyang Liu,Xinrui Yang,Lipeng Wan,Xingyu Chen,Xuguang Lan", "background": "现有的基于视觉模型的强化学习（MBRL）算法在使用观察重建时往往会遇到信息冲突的问题，这使得难以学习紧凑的表示，的结果是策略不够稳健，尤其是在存在与任务无关的视觉干扰时表现尤为明显。", "innovation": "本文首先从信息论的角度揭示当前视觉MBRL算法中的信息冲突源自视觉表示学习和潜在动力学建模。基于这一发现，我们提出了一种新的算法MInCo，利用负自由对比学习来减轻信息冲突，有助于在噪声观察下学习不变表示和稳健的政策。为了防止视觉表示学习的主导，我们引入了时间变化的重加权，使学习随着训练的进行偏向于动力学建模。", "conclusion": "我们在具有动态背景干扰的各种机器人控制任务上评估了我们的方法，实验结果表明MInCo可以在背景噪声中学习不变的表示，并且始终优于当前最先进的视觉MBRL方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17874", "html_url": "https://arxiv.org/abs/2502.17874", "title": "Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning", "title_en": "Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning", "authors": "Runzhong Wang,Rui-Xi Wang,Mrunali Manjrekar,Connor W. Coley", "background": "分子机器学习随着几何深度学习的进步而受到关注。同时，检索增强生成已成为一种常用的语言模型方法。然而，如何将检索增强最优化地集成到分子机器学习中仍不明确。图神经网络可以从聪明的匹配中受益，以理解检索到的分子与查询分子的结构对齐。神经图匹配通过明确建模两个结构图之间的节点和边亲和力，并采用鲁棒的端到端神经网络来学习亲和力度量，提供了有吸引力的解决方案。该方法被应用于质量谱模拟，并引入了一种名为MARASON的新模型，该模型利用神经图匹配来增强基于碎片的神经网络。", "innovation": "文章提出了MARASON模型，这是一种结合了神经图匹配的新型模型，用于增强基于碎片的神经网络，从而提高了质量谱模拟的准确性。MARASON模型通过明确建模两个结构图之间的节点和边亲和力，并采用鲁棒的端到端神经网络来学习亲和力度量，提供了一种有效的解决方案。实验证明MARASON的top-1准确率达到28%，显著优于非检索的当前最佳方法19%的准确率，同时优于简单的检索增强生成方法和传统的图匹配方法。", "conclusion": "MARASON的实验结果展示了其设计的有效性，它在质量谱模拟中取得了显著的改进，同时也优于传统的检索增强生成方法和图匹配方法。这些结果表明将神经图匹配技术整合进分子机器学习中是一个有潜力的创新方向。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12971", "html_url": "https://arxiv.org/abs/2504.12971", "title": "在富有表现力的神经架构搜索空间中的可转移代理模型", "title_en": "Transferrable Surrogates in Expressive Neural Architecture Search Spaces", "authors": "Shiwen Qin,Gabriela Kadlecová,Martin Pilát,Shay B. Cohen,Roman Neruda,Elliot J. Crowley,Jovita Lukasik,Linus Ericsson", "background": "神经架构搜索（NAS）面临着在探索具有广泛搜索空间、支持架构创新的同时，需要高效评估架构的挑战，以有效搜索这些空间。研究基于上下文无关文法的富有表现力的NAS搜索空间的代理模型训练，以提高搜索效率和性能。", "innovation": "研究发现，通过使用零成本代理度量和神经图特征（GRAF）或微调现成的语言模型训练的代理模型，具有高预判力，可以用于不同数据集内和跨数据集的架构性能预测。这些代理模型可以在搜索新数据集时过滤掉不良架构，从而大大提高搜索速度并达到更好的最终性能，还可以直接作为搜索目标以实现巨大的速度提升。", "conclusion": "引入了代理模型的概念，能够有效提高在富有表现力的NAS搜索空间中的搜索效率和性能，同时具备优秀的跨数据集泛化能力，且可以直接作为搜索目标以实现极高速度的提升。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.13450", "html_url": "https://arxiv.org/abs/2502.13450", "title": "交织吉布斯扩散：具有隐式约束的离连续数据生成", "title_en": "Interleaved Gibbs Diffusion: Generating Discrete-Continuous Data with Implicit Constraints", "authors": "Gautham Govind Anil,Sachin Yadav,Dheeraj Nagaraj,Karthikeyan Shanmugam,Prateek Jain", "background": "大多数关于离散和离连续扩散的先前工作假设分解去噪分布，这可能妨碍在这些问题中对随机变量之间强大依赖性的建模。该论文引入了Interleaved Gibbs Diffusion (IGD)框架，旨在解决数据中存在的重要但隐式且未指定的约束问题。IGD通过不假设分解性，采用类似吉布斯采样的离散扩散模型，提高了3-SAT问题的表现。", "innovation": "IGD创新在于它是一个新型生成模型框架，专门设计用于处理离连续数据，同时也放到了数据中隐式且未指定的约束问题上。它通过摆脱分解性假设，使用纯粹的吉布斯采样风格离散扩散模型，提升了性能。该模型提供了灵活的去噪器选择，通过状态空间加倍实现有条件生成，同时在推理阶段进行细化。IGD在三个具有挑战性的生成任务上展示了最先进的性能，且未依靠领域特定的归纳偏差如对称扩散或辅助损失来实现此性能。此外，IGD探索了广泛的建模和交织策略以及每个问题中的超参数", "conclusion": "IGD在三个挑战性的生成任务上展示出了出色的性能，并且在无需依赖特定领域-inductive biases的情况下达到了最先进的结果。该模型提供了一种处理离连续数据的全新方法，同时保持了模型的灵活性和可逆性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08136", "html_url": "https://arxiv.org/abs/2504.08136", "title": "基于浅冰近似物理感知神经网络模拟冰流动力学的方法", "title_en": "A physics informed neural network approach to simulating ice dynamics governed by the shallow ice approximation", "authors": "Kapil Chawla,William Holmes", "background": "本文通过开发物理约束神经网络（PINN）方法来模拟受浅冰近似（Shallow Ice Approximation）调控的冰盖动力学。先前的研究使用该方法来解决稳态障碍问题，此处将其扩展到时间依赖性的问题。通过全面的1D和2D模拟，验证了该模型在捕捉复杂自由边界条件方面的有效性。这种方法结合了传统的数学建模和前沿的深度学习方法，提供了一种可扩展且稳健的解决方案，用于预测冰层厚度的时间变化。作为实际应用的示例，文中模拟了德文冰帽的动力学，利用了2000年和2018年的航空地球物理数据。", "innovation": "本文将物理感知神经网络（PINN）方法扩展至时间依赖性问题，并通过1D和2D模拟验证了该方法在捕捉复杂自由边界条件方面的有效性。将传统的数学建模方法与深度学习技术相结合，提供了一种可扩展且稳健的解决方案，用于预测冰层厚度的时间变化。作为实际应用的示例，文中通过整合2000年和2018年的航空地球物理数据，模拟了德文冰帽的动力学情况。", "conclusion": "通过全面的1D和2D模拟，验证了物理感知神经网络（PINN）方法在模拟受浅冰近似（Shallow Ice Approximation）调控的冰盖动力学方面的有效性。本文提出的方法作为一种可扩展且稳健的预测工具，能够捕捉复杂的自由边界条件，并成功在德文冰帽的模拟中得到应用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03935", "html_url": "https://arxiv.org/abs/2503.03935", "title": "基于大型语言模型的穿戴设备和饮食数据中高血糖预测及行为治疗途径发现", "title_en": "LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet", "authors": "Abdullah Mamun,Asiful Arefeen,Susan B. Racette,Dorothy D. Sears,Corrie M. Whisner,Matthew P. Buman,Hassan Ghasemzadeh", "background": "餐后高血糖，即餐后血糖水平超出正常范围的现象，是预测2型糖尿病发展的重要指标，尤其对于糖尿病前期和健康个体。餐后血糖动态的主要度量指标是餐后面积下的曲线下面积（AUC）。基于个人的生活习惯因素（如饮食和体力活动水平）预测餐后AUC并解释影响餐后血糖的因素，能够帮助个人根据需要调整生活方式，以维持正常的血糖水平。因此，本研究开发了GlucoLens，这是一种基于传感器驱动输入的可解释机器学习解决方案，通过先进的数据分析、大语言模型和训练可解释的机器学习模型来预测餐后AUC和高血糖。研究使用来自长时间临床试验的穿戴设备数据进行模型开发和评估，试验涉及10名从事全职工作的成年人。", "innovation": "本研究创新性地利用大语言模型和穿戴设备数据，开发了一个解释性强的机器学习解决方案，GlucoLens，通过结合多重模态数据、穿戴传感和机器学习模型，提前预测餐后AUC和高血糖，并在许多方面表现出优于现有技术的性能。该研究的机器学习模型在最佳配置下实现了NRMSE为0.123的性能，与比较模型相比，整体性能提高了16%。此外，该技术通过大量不同的情景预测高血糖，并给出不同的治疗建议，准确率达到了73.3%，F1分数为0.716。", "conclusion": "GlucoLens系统通过结合多重模态数据，深度学习模型和解释性分析，成功地预测了餐后高血糖，并提供个性化的管理解决方案。该研究展示了利用可解释的机器学习模型进行健康预测的潜力，并提出了实际可行的行为治疗建议。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01420", "html_url": "https://arxiv.org/abs/2505.01420", "title": "评估前沿模型的隐秘性和情境意识", "title_en": "Evaluating Frontier Models for Stealth and Situational Awareness", "authors": "Mary Phuong,Roland S. Zimmermann,Ziyue Wang,David Lindner,Victoria Krakovna,Sarah Cogan,Allan Dafoe,Lewis Ho,Rohin Shah", "background": "近期研究显示，先进的人工智能模型有可能主动且隐蔽地追求与其开发者意图不符的目标。这种行为难以检测，会在未来发展更高级的系统中构成严重的控制风险。因此，要求人工智能开发者在模型部署前排除潜伏的危害行为变得至关重要。本文旨在通过评估模型的两种基本能力——隐秘性推理和情境意识推理，来预防这种潜在的不良行为。", "innovation": "本文提出了一套评估方法，用于衡量两种关键的能力：第一种评估模型能否隐秘地绕过监督（隐秘性），第二种评估模型对其自身、环境和部署情况的工具化理解和认识（情境意识）。这些评估方法构成了一种‘规避风险的安全论证’，通过不通过这些评估的模型可以几乎可以确定不会通过隐秘行为造成严重危害。", "conclusion": "我们在当前的最前沿模型上运行了相应的评估，结果发现，这些模型在隐秘性和情境意识的评估中并没有表现出令人担忧的水平。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15325", "html_url": "https://arxiv.org/abs/2504.15325", "title": "显著性指数对一致性值的评估", "title_en": "Significativity Indices for Agreement Values", "authors": "Alberto Casagrande,Francesco Fabris,Rossano Girometti,Roberto Pagliarini", "background": "一致性度量标准，如Cohen's kappa或内在相关系数，用于评估两个或多个分类器之间的匹配情况。这些度量标准在医学、人工智能等多个领域广泛应用，从评估医疗治疗和临床试验的效果到量化由于分类器减少造成的近似值。不同分类器与金标准的一致性可以通过它们的顺序来简单比较，但仅通过一致性度量值来简单地评判某个方法作为优点或缺点是不够的，需要一个量表或显著性指数。虽然关于Cohen's kappa的一些质量量表在文献中被提出过，但这些量表大多数比较粗糙，边界是任意设定的。本文在此背景下提出了一个评估任何两个分类器之间一致性值显著性的通用方法，并引入了两种显著性指数：一种适用于有限数据集，另一种可以处理分类概率分布。此外，本文还讨论了评估这些指数所面临的计算挑战，并提出了一些有效的算法以实现评估的目标", "innovation": "提出了一个通用方法来评估任何两个分类器之间一致性值的显著性，并引入了两种显著性指数：一种适用于有限数据集，另一种可以处理分类概率分布。还提出了这些指数评估的高效算法，解决了计算挑战", "conclusion": "本文提出了一个通用的方法来评估任何一致性值在两个分类器之间的显著性，引入了适用于有限数据集和分类概率分布的显著性指数，并提出了这些指数评估的高效算法以克服计算挑战。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00307", "html_url": "https://arxiv.org/abs/2505.00307", "title": "GateFormer: 通过门控表示的时空注意力提升多元时间序列预测", "title_en": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations", "authors": "Yu-Hsiang Lan,Eric K. Oermann", "background": "近年来，使用Transformer架构进行时间序列建模受到了广泛关注。然而，使用Transformer进行多元时间序列预测带来了独特的挑战，因为它需要同时建模时空（跨时间）和变元（跨变元）依赖关系。尽管基于Transformer的模型因其能够灵活捕捉序列和跨变元关系而受到欢迎，但在Transformer架构中如何最佳地综合这两种信息以优化性能和效率仍不清楚。先前的研究尚未解决如何在Transformer架构中有效地建模时空和跨变元依赖关系的问题。", "innovation": "本文创新性地重新利用Transformer架构来有效建模时空和跨变元依赖关系。作者的方法首先独立地将每个变元嵌入到变元之间的表示中，以捕获其跨时间动态，然后通过这些学习表示上的注意力机制来建模跨变元依赖关系。在时空建模和跨变元建模阶段的门控操作调节了信息流，使模型能够聚焦于准确预测中最相关的特点。", "conclusion": "该方法在13个真实世界数据集上实现了最先进的性能，并可无缝整合到其他Transformer和LLM基预测器中，性能提升高达20.7%。相关代码可在该仓库获取：this https URL."}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.17857", "html_url": "https://arxiv.org/abs/2504.17857", "title": "Spot 上的高性能强化学习：使用分布度量优化仿真参数", "title_en": "High-Performance Reinforcement Learning on Spot: Optimizing Simulation Parameters with Distributional Measures", "authors": "AJ Miller,Fangzhou Yu,Michael Brauckmann,Farbod Farshidian", "background": "该研究介绍了使用Boston Dynamics的Spot机器人硬件进行高性能强化学习策略部署的技术细节。这是首次公开展示完整的强化学习策略从模拟到硬件的部署，并且提供了训练代码和部署代码的公开访问权限，通过Nvidia IsaacLab和Boston Dynamics。使用Wasserstein距离和最大均值差异来量化硬件和模拟中收集的数据分布差异，以此测量模拟到现实世界的差距。利用这些度量作为协方差矩阵适应演化策略的评分函数，优化Spot上未知或难以测量的参数。研究过程生成了高质量的强化学习策略，具备多种姿态，包括飞行阶段，展示了超过5.2毫秒的移动速度，远超Spot默认控制器的最大速度，且具备在滑滑表面的稳健性、干扰抵抗能力和前所未见的整体灵活性。", "innovation": "利用Wasserstein距离和最大均值差异量化数据分布差异作为评分函数，优化仿真参数，生成高质量的强化学习策略，实现复杂运动姿态，能够在滑滑表面移动并具备高度的抗干扰性能，证明了端到端强化学习在Spot机器人上的部署可能性。", "conclusion": "通过优化仿真参数并使用分布度量，研究成功地生成了高性能的强化学习策略，实现了Spot机器人在多种不同环境下的稳健移动和高效动作，为未来使用低级API进行Spot机器人的研究提供了支持和代码资源。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07635", "html_url": "https://arxiv.org/abs/2505.07635", "title": "使用天际线解释进行图推理解释", "title_en": "Interpreting Graph Inference with Skyline Explanations", "authors": "Dazhuo Qiu,Haolai Che,Arijit Khan,Yinghui Wu", "background": "图机器学习模型（如图神经网络）经常被用来执行各种网络分析任务，通常需要通过执行推理查询来获取结果。然而，这些模型的输出往往难以全面解释。现有方法通常只能针对单一预定义的解释性度量（如准确度）进行优化，这往往导致不平衡或片面的解释。", "innovation": "提出了天际线解释作为解释性子图的新范式，该子图在网络解释度量中占优。该研究将天际线解释形式化为多准则优化问题，并设计了高效的算法来逐步构建天际线解释。此外，研究还提出算法以多样化解释，丰富全面的解释。为了处理大型图神经网络推理，还引入了负载均衡策略的并行算法来扩展天际线解释的有效性与可扩展性。", "conclusion": "通过实验验证了算法的有效性和可扩展性，表明天际线解释能够在多种解释性度量中提供全面且公平的解释性视图。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16341", "html_url": "https://arxiv.org/abs/2505.16341", "title": "方形孔里的方形钉：长尾半监督学习中的元专家", "title_en": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning", "authors": "Yaxin Hou,Yuheng Jia", "background": "本文研究了带有分布不匹配的长尾半监督学习（LTSSL），其中标记训练数据的类别分布遵循长尾分布，并且与未标记训练数据的类别分布不匹配。现有的大多数方法引入辅助分类器（专家）来建模各类未标注数据分布并生成伪标签，但这些专家的知识并未充分利用。作者观察到不同专家在预测不同样本区间时各有擅长，比如长尾专家擅长预测头部区间样本，均匀专家擅长预测中段区间样本。因此，作者提出了一个动态专家分配模块，能够估计样本的类别归属（即头部、中段或尾部类别），并根据估计的归属动态分配合适的专家，以生成高质量的伪标签并在训练阶段和测试阶段产生预测。此外，作者还理论证明了整合不同专家的优势将导致更小的泛化误差界限。研究表明，深层特征对头部类别的偏见较大但具有更强的判别能力，而浅层特征的偏见较小但判别能力较弱。因此，作者提出了多深度特征融合模块，以利用不同深度特征来减轻模型偏见。", "innovation": "本文的主要创新点包括：1) 提出了一种动态专家分配模块，可以估计样本的类别归属并根据估计的归属分配合适的专家；2) 理论上证明了整合不同专家的优势将导致更小的泛化误差界限；3) 提出了一个利用不同深度特征来减轻模型偏见的多深度特征融合模块。这些创新为长尾半监督学习提供了新的解决方案。", "conclusion": "本文方法在CIFAR-10-LT、STL-10-LT和SVHN-LT数据集的各种设置下，通过综合实验展示了其有效性。相关代码可以在这个网址获取。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22768", "html_url": "https://arxiv.org/abs/2505.22768", "title": "多维布里渊图：一种符号图框架的时间序列预测", "title_en": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting", "authors": "Mert Onur Cakiroglu,Idil Bilge Altun,Mehmet Dalkilic,Elham Buxton,Hasan Kurban", "background": "时间序列的预测仍然是基础模型面临的挑战之一，因为时间序列具有时序异质性、高维度和缺乏内在的符号结构。针对这些挑战，本文提出了一种新型编码器DRAGON (Discrete Representation and Augmented Graph encoding Over de BruijN Graphs)，该编码器引入了多维布里渊图（MdBGs），以弥补符号表示和神经建模之间的差距。DRAGON 对连续输入序列进行离散化，并将它们映射到固定图结构上，通过基于图的注意力机制实现动态上下文恢复。", "innovation": "DRAGON 引入了多维布里渊图（MdBGs），提供了一种新的编码框架，将传统CNN编码器与符号、结构感知表示相结合，实现了时间序列预测的创新方法。通过将DRAGON作为附加模块集成在双支结构中，增强了基于CNN的编码器的功能，提升了时间序列的预测能力。", "conclusion": "本文提出的DRAGON模型通过引入多维布里渊图，有效地结合了离散表现和神经建模的优势，显著改善了时间序列的预测性能。所有相关代码均可在指定链接中获取。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20697", "html_url": "https://arxiv.org/abs/2505.20697", "title": "神经科学中动态因果图的假设生成：利用观察时间序列的生成因子模型", "title_en": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "authors": "Zachary C. Brown,David Carlson", "background": "假设生成在神经科学领域具有潜力，能够通过减少需要进行的干预性研究范围来降低研究成本。现有的机器学习方法可以从复杂的数据集中生成科学假设，但许多方法假设因果关系随着时间静态不变，这限制了其在动态、状态依赖行为系统（如大脑）中的应用。尽管有些技术通过因子模型试图进行动态因果发现，但它们通常局限于线性模式或其他简化假定。因此，需要一种能更好地捕捉非线性关系的新方法来发现复杂的、随时间变化的变量间交互作用。", "innovation": "提出了一种新的方法，该方法将动态图表示为条件加权的静态图的叠加，其中每个静态图可以捕捉非线性关系。这种方法使得在超出线性限制的情况下，能够检测复杂的、随时间变化的变量间交互作用。该方法在一些实验中的预测动态因果模式的F1分数平均提高了约22-28%，部分改进超过60%。在真实的大脑数据案例研究中，证明了该方法能够揭示与特定行为状态相关的关系，提供对神经动态的见解。", "conclusion": "所提出的方法能够有效地生成关于动态因果图的假设，显著提高了预测动态因果模式的准确性，并在大脑数据研究中展示了其应用价值，为神经科学领域提供了新的洞见。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18482", "html_url": "https://arxiv.org/abs/2506.18482", "title": "Reliability-Adjusted Prioritized Experience Replay", "title_en": "Reliability-Adjusted Prioritized Experience Replay", "authors": "Leonard S. Pleiss,Tobias Sutter,Maximilian Schiffer", "background": "在在线强化学习代理中，经验重放（Experience Replay）使数据高效地学习过去的经验成为可能。传统上，从重放缓冲区中均匀采样经验，而不考虑经验特定的学习潜力差异。为了更有效地采样，研究人员引入了优先经验重放（Prioritized Experience Replay，PER）。", "innovation": "本文提出了PER的一种扩展，通过引入一种新的时间差误差可靠性度量。理论上证明了由此产生的过渡选择算法（Reliability-adjusted Prioritized Experience Replay，ReaPER）比PER更高效。实验结果显示，在不同的环境类型中，包括 Atari-10 基准测试，ReaPER 超过了 PER 的表现。", "conclusion": "RelaPER 通过改进的经验重放机制促进了更高效的强化学习过程，实验结果表明其在不同环境中的表现优于传统的 PER 方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06231", "html_url": "https://arxiv.org/abs/2506.06231", "title": "迈向可解释的特征嵌入对比与对齐", "title_en": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "authors": "Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia", "background": "虽然文献中已经开发出了多种特征嵌入模型，但这些嵌入在分类下游应用中的数值性能比较较多，而缺乏一种可解释的方式来对比不同嵌入的不同之处。具体来说，这些对比未能识别和分析嵌入空间中样本群集之间的差异匹配情况，这限制了对嵌入差异的理解和利用。因此，有必要提出一种新的框架来解决这一问题，便于理解不同嵌入的性能差异及其对数据聚类的影响。", "innovation": "本文提出了Spectral Pairwise Embedding Comparison (SPEC)框架，该框架通过检测由两种嵌入模型产生的不同核矩阵，来揭示两种嵌入对样本簇的不同捕获。该方法具有线性扩展性，在计算复杂度方面具有高效性，并且可应用于大规模数据集如ImageNet和MS-COCO。此外，该框架还利用优化问题来对齐两个嵌入模型，以确保一个嵌入中发现的聚类也能在另一个模型中被捕获。", "conclusion": "本文通过SPEC框架提供了一种新的方法来对比和对齐特征嵌入。该方法不仅能够提高嵌入模型性能的理解，还能应用于大规模数据集并确保聚类的一致性。结果表明SPEC具有广泛的应用前景，特别是在复杂数据表示的对比和优化方面。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17828", "html_url": "https://arxiv.org/abs/2506.17828", "title": "通过强化学习对冻结的LLM进行对齐：一种迭代重新加权-然后优化方法", "title_en": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach", "authors": "Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong", "background": "大型语言模型(LLMs)通常需要通过RLHF、DPO等微调方法来与人类偏好对齐。这些方法直接优化模型参数，因此无法在测试时间用来提高模型性能，也不能在不可访问模型权重时使用。相比之下，测试时间方法通过利用奖励函数指引和提高输出质量，但需要高推理成本，并且基于不完美的奖励或价值函数，导致输出不尽如人意。因此，本文提出了一种名为Iterative Reweight-then-Optimize (IRO)的方法，它是一种强化学习(Reinforcement Learning, RL)框架，可以在不修改基础模型参数的情况下，对冻结的基础模型进行RL风格的对齐。", "innovation": "IRO方法是一种无需修改参数的强化学习框架，通过多次迭代，每次迭代从基础模型中采样候选项，根据不同价值函数重新采样，训练新的轻量级价值函数来指引下一个解码过程。测试时，使用价值函数通过搜索优化过程引导基础模型生成。值得注意的是，用户可以使用IRO来根据自己的数据集对齐模型，类似于OpenAI的强化微调（RFT），但无需访问模型权重。", "conclusion": "IRO能够无需访问模型权重，通过迭代重新加权和优化来实现对冻结的基础模型进行RL风格的对齐，有效地解决了现有方法的问题，展示了其在实际应用中的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13972", "html_url": "https://arxiv.org/abs/2506.13972", "title": "会员推断攻击作为隐私工具：可靠性、差异性和集成", "title_en": "Membership Inference Attacks as Privacy Tools: Reliability, Disparity and Ensemble", "authors": "Zhiqi Wang,Chengyu Zhang,Yuetian Chen,Nathalie Baracaldo,Swanand Kadhe,Lei Yu", "background": "会员推断攻击（MIAs）是对机器学习模型隐私构成重大威胁的工具，并被广泛应用于隐私评估、审计和机器遗忘等领域。尽管以前对MIAs的研究主要集中在AUC、准确性和低FPR下的TPR等性能指标上，或是通过这些指标评估隐私解决方案，但这些研究忽略了不同攻击之间的差异。这些差异，不论是不同攻击方法之间还是同一方法的不同实例之间，都会影响MIAs作为隐私评估工具的可靠性和完整性。因此，本文系统地通过一种新的涵盖覆盖度和稳定性分析的框架，研究了这些差异，并展示了MIAs及其潜在原因的广泛影响，从而在确定这些挑战的基础上，提出了一种基于三种不同策略的集成框架，以利用现有顶级MIAs的优势并考虑到它们之间的差异。这一框架不仅提高了攻击的效力，还提供了更稳健和全面的隐私评估方法论。", "innovation": "本文创新性地提出了一种基于覆盖度和稳定性分析的框架，系统地研究了会员推断攻击之间的差异，并提出了一个集成框架，综合考虑了各种顶级MIAs的长处，以更全面和稳健的方法进行隐私评估。", "conclusion": "本研究揭示了会员推断攻击的巨大差异及其潜在原因，并提出了一个集成框架来应对这些挑战，从而增强了隐私评估的可靠性。通过对现有MIAs的集成使用，本文提供了更稳健和全面的隐私评估方法论。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01631", "html_url": "https://arxiv.org/abs/2506.01631", "title": "基于梯度的模型指纹识别用于LLM相似性检测和家族分类", "title_en": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification", "authors": "Zehao Wu,Yanjie Zhao,Haoyu Wang", "background": "随着大型语言模型（LLMs）成为现代应用中的关键软件组件，未经授权的模型微调、合并和再分发已成为重要的软件工程挑战。传统软件领域中已有成熟的代码克隆检测和许可合规机制，但在LLM生态系统中，缺乏有效手段来追踪模型血统和强制执行许可协议。对于需要衍生作品遵守命名约定以保持归因的开源模型创建者（如Meta的LLaMA），这一缺口尤为突出。而TensorGuard正是为填补这一空白而诞生的一项技术，它被视为一种软件制品需要追踪起源的新方法。", "innovation": "TensorGuard是一个基于梯度的指纹识别框架，用于大型语言模型的相似性检测和家族分类。它通过分析在不同张量层对随机输入扰动的梯度响应来提取模型固有的行为特征，从而实现了与特定训练数据、水印或模型格式无关的模型相似性和家族分类。TensorGuard支持广泛采用的安全张量格式，并构建了通过统计分析梯度特征形成高维指纹。这些指纹能够实现任意模型之间的直接成对相似性评估和未知模型的系统家族分类。实验结果表明，在使用领域知识初始化的K-Means聚类算法下，该框架在五大家族（Llama、Qwen、Gemma、Phi、Mistral）的58个模型中达到了94%的分类准确率。", "conclusion": "实验评估了58个模型，包括8个基模型和50个衍生模型，结果显示在使用已知基模型初始化的领域知识K-Means聚类算法下，TensorGuard的分类准确率为94%。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21551", "html_url": "https://arxiv.org/abs/2506.21551", "title": "LLM预训练中的Grokking在哪里？监控从记忆到泛化的转变无需测试", "title_en": "Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test", "authors": "Ziyue Li,Chenrui Fan,Tianyi Zhou", "background": "最近在神经网络训练中观察到了一个被称为Grokking的现象，即测试性能在训练损失收敛后仍持续提升，这使泛化机制和其他新兴能力（如推理能力）变得神秘。此前的研究通常在小型模型上训练少量玩具或高度特定任务数千个时期。然而，本文首次研究了在一次预训练过程中大型语言模型（LLM）的Grokking现象，特别是关于模型检查点期间的Grokking验证和内部动态分析。通过评估数学推理、代码生成和常识及领域特定知识检索任务的泛化能力，研究人员首次证实，大型基础模型的预训练过程中仍然存在Grokking现象，尽管不同数据可能以异步方式进入Grokking阶段。", "innovation": "本文的研究首次在大型语言模型的预训练过程中发现了Grokking现象，并通过计算路径距离和单路径复杂性的新度量方法揭示了从记忆到泛化的“知识消化”过程，这一过程解释了延迟泛化的机制。此外，提出的新度量方法能够预测不同下游任务上的泛化改进，而且它们高效、易于计算且仅依赖于训练数据，从而在预训练过程中提供了一种无需微调和测试的泛化性能监控手段。理论分析还表明，更结构化的路径可以降低模型复杂性并提高泛化边界。", "conclusion": "本文通过模型检查点和内部动态分析验证了大型语言模型预训练过程中Grokking的存在，新提出的方法可以量化这一过程并监控泛化性能。通过理论分析表明，更结构化的路径有助于减轻模型过拟合并提高泛化性能，从而提供了一种无需测试的预训练监控方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21714", "html_url": "https://arxiv.org/abs/2506.21714", "title": "ODE_t(ODE_l): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "title_en": "ODE$_t$(ODE$_l$): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "authors": "Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer", "background": "近期，连续正规流（CNFs）和扩散模型（DMs）都是通过统一的理论框架进行研究。虽然这种模型能够从噪声分布中生成高质量的数据点，但采样过程往往需要多次迭代求解常微分方程（ODE），这导致了较高计算复杂度。现有的大多数方法都侧重于在采样过程中减少时间步数，以提高效率。", "innovation": "本文探索了一种不同的方向，旨在动态控制时间和网络结构长度的质量-复杂度折中。通过重新配置变压器架构中的模块，以解决与长度相关的内部分离的ODE。在此过程中，利用时间一致性和长度一致性的训练技巧实现采样，使得可以任意使用时间步骤和变压器块进行采样。这种方法在时间维度上与求解器无关，并且减少了延迟和内存使用。在CelebA-HQ和ImageNet上进行的图像生成实验显示，其在最高效采样模式下的延迟降低最多可达3倍，并且高质量采样时的FID得分提高最多为3.5分。", "conclusion": "我们提供了可以完全复制实验的代码和模型权重，证明了该方法的有效性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23799", "html_url": "https://arxiv.org/abs/2506.23799", "title": "KAIROS: 可扩展的模型无关型数据估值框架", "title_en": "KAIROS: Scalable Model-Agnostic Data Valuation", "authors": "Jiongli Zhu,Parjanya Prajakta Prashant,Alex Cloninger,Babak Salimi", "background": "随着训练数据不断影响模型的准确性和合规性以及AI资产的市场评估，现有的估值方法仍显不足。模型基础的方法依赖单一拟合模型且继承其偏差，而基于算法的方法如Data Shapley则需要大规模重训。近年来的Wasserstein基方法依赖近似，会导致相对真实值删除一个样本的排名产生偏差。因此，需要一种可扩展、模型无关的数据估值框架，能够高效准确地评估每个样本的贡献，并支持在线更新。", "innovation": "KAIROS引入了一种可扩展、模型无关的估值框架，通过计算极大均差(MMD)来分配每个样本的分布影响评分，该评分表示样本对经验训练分布与纯净参考集之间MMD的贡献。这种方法不需要重训，允许线性时间在线更新，并且可以使用条件核进行统一的标签和特征错误检测。KAIROS还提供了严谨的理论保证，确保排名具有可再现性和密度分离性，使得阈值更具可解释性。", "conclusion": "在噪声、标签错误和污染基准上的实证研究表明，KAIROS在准确性和运行时间上均优于最新的模型依赖、Shapley和Wasserstein基线。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22049", "html_url": "https://arxiv.org/abs/2506.22049", "title": "GPAS: 通过保留梯度的激活缩放加速大型语言模型预训练的收敛", "title_en": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling", "authors": "Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Lu Yin,Can Yang", "background": "现代大型语言模型，如LLaMA、Qwen和DeepSeek系列，主要采用预层规范化（Pre-LN）的Transformer架构。虽然这种方法在预训练过程中表现出良好的稳定性和对大模型的扩展性，但Pre-LN架构会导致逐层激活方差指数级增长，使得残差连接中的捷径逐渐占据主导地位，限制了更深层的学习能力。", "innovation": "为了缓解这一问题，本文提出了一种简单的技术——梯度保留激活缩放（GPAS）。GPAS通过在保持梯度不变的情况下缩放中间激活，使网络中的信息得以保全，并避免了梯度缩放导致的梯度消失问题。该技术在71M至1B参数规模的不同模型上进行了广泛的实验，结果表明GPAS能够实现一致的性能提升。此外，GPAS还展示了在改进其他架构如Sandwich-LN和DeepNorm等方面的潜力，证明了其在各种训练动态优化方面的适用性和潜力。", "conclusion": "本文提出的Gradient-Preserving Activation Scaling（GPAS）技术能够缓解Pre-LN Transformer架构中逐层激活方差指数级增长的问题，通过梯度保持机制实现性能提升，并展示了在多种架构中的广泛应用潜力。该研究为改善大型语言模型的训练动态和提高深层网络的学习能力提供了新的方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22821", "html_url": "https://arxiv.org/abs/2506.22821", "title": "四十年来的人口迁移深度学习", "title_en": "Deep learning four decades of human migration", "authors": "Thomas Gaskin,Guy J. Abel", "background": "本文介绍了关于230个国家和地区的起源-目的地年度迁移流和存量的全新且详细的数据库，时间段从1990年至今，覆盖了过去的35年。这些估计值按出生国进一步细分，提供了一幅关于过去35年的人口迁移全景图。通过训练一个深度循环神经网络，并利用18个协变量的信息，包括地理、经济、文化、社会和政治数据，来学习所有国家的迁移模式。模型显示整个过去的迁移模式都可以影响现状，以此来学习长期的时间相关性。进一步增强了不确定性分析，既训练了一个神经网络的集合，还推动了通过训练网络的协变量不确定性分析，以获得所有估计值的置信区间，供研究人员识别需要额外数据收集的地理区域。该方法在一个包含未见过数据的验证集上测试，表明在比传统五年人口迁移流估算方法上取得了显著优势，同时大幅提高了时间分辨率。全部相关的训练数据、神经网络权重和训练代码均开源，与迁移估计结果一起公开，提供了一个十分宝贵的研究资源以供未来的人口迁移研究使用。", "innovation": "本文的主要创新在于使用深度循环神经网络对迁移模式进行建模，并通过包含地理、经济、文化、社会和政治因素在内的18个协变量来训练该模型，从而能够捕捉长期时间序列的相关性。此外，通过训练一系列神经网络并推进协变量不确定性，为所有估计提供置信度边界，确保研究的准确性。该方法还显著提高了时间分辨率和对未来人口迁移趋势的预测准确性。", "conclusion": "本文研究提供的迁移数据集和创新的建模方法，不仅能够更加详细并且准确地展示了过去35年的人口迁移情况，同时也改变了对人口迁移的趋势预测和未来的研究方式，通过开放所有训练数据和代码，提供了宝贵的资源以供未来学者们进行相关研究。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2105.13440", "html_url": "https://arxiv.org/abs/2105.13440", "title": "非负矩阵分解算法一般可以改善主题模型的拟合效果", "title_en": "Non-negative matrix factorization algorithms generally improve topic model fits", "authors": "Peter Carbonetto,Abhishek Sarkar,Zihao Wang,Matthew Stephens", "background": "已有研究探讨了非负矩阵分解（NMF）与主题模型之间的联系，但没有利用这些联系开发新的主题模型拟合算法。NMF避免了主题模型参数的“归一化”约束，简化了优化问题的结构，提高了计算效率。本文在最新的NMF优化算法进展基础上，展示了一种先解决NMF问题再恢复主题模型拟合的方法，可以让主题模型在更短时间内获得更佳拟合效果。此外，这种方法对于主题模型的变分推断也有潜在的改进效果。研究方法已经实现于R包fastTopics中。", "innovation": "本文提出了一种新的方法，即先解决NMF问题再恢复主题模型拟合，这种方法比标准的主题模型拟合算法在拟合效果和计算效率上都有显著提升。该方法对于建立在变分推断之上的话题模型也有潜在的优化效果。", "conclusion": "通过NMF方法可以显著改善主题模型的拟合效果。研究方法已经在R包fastTopics中实现。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01551", "html_url": "https://arxiv.org/abs/2507.01551", "title": "自我引导的过程奖励优化及重定义的步骤优势方法在过程强化学习中的应用", "title_en": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "authors": "Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua", "background": "过程强化学习（PRL）在增强大型语言模型（LLMs）的推理能力方面展示了显著潜力。然而，引入额外的过程奖励模型会导致巨大的计算开销，而且缺乏关于过程级优势估计的统一理论框架。目前的方法未能解决这些挑战，因此存在提升技术空间和理论构建的需求.", "innovation": "该研究提出了一种新颖的方法——自我引导的过程奖励优化（SPRO），通过两个关键创新：首先，证明过程奖励可以内生地从策略模型中衍生出来；其次，引入了明确的累积过程奖励和掩码步骤优势（MSA），使步骤级别的动作优势估计在共享提示采样组内更加严谨。这些创新为解决现有问题提供了理论和计算基础，展现了显著改进和低开销的潜在可能.", "conclusion": "实验结果显示，SPRO方法在训练效率上比标准GRPO高出3.4倍，并且测试准确率提升了17.5%。SPRO在整个训练过程中保持了稳定的高策略熵，并且平均响应长度减少了约1/3，这证明了其充分的探索性和防止奖励作弊的效果。此外，该方法相较于MSA监督强化学习方法不会产生额外的计算开销，这使其适合工业应用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01041", "html_url": "https://arxiv.org/abs/2507.01041", "title": "边缘网络中快速AI模型拆分", "title_en": "Fast AI Model Splitting over Edge Networks", "authors": "Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin(Sherman)Shen", "background": "拆分学习（SL）作为一种高效的计算方法，已被用于人工智能（AI）模型训练，能够减轻设备侧的计算负担。然而，复杂的AI模型架构会导致计算成本较高，以获取最优模型拆分方案。本文考虑将任意AI模型表示为有向无环图（DAG），并通过最小s-t割搜索问题来重新表述最优模型拆分问题。为了解决这一问题，本文提出了一种基于DAG的快速模型拆分算法，通过重组DAG以利用最大流方法识别最优模型拆分。此外，考虑到具有块结构的AI模型，提出了基于块的模型拆分算法来降低计算复杂度，通过将每个块抽象为单个顶点来简化DAG，并通过简化后的DAG获取最优模型拆分。实验结果表明，所提出算法能够在毫秒内确定最优模型拆分，相比于最先进的基准，动态边缘网络中的训练延迟降低24.62%-38.95%。", "innovation": "提出了一种基于DAG的快速模型拆分算法，通过重组DAG利用最大流方法解决最优模型拆分问题，并针对具有块结构的AI模型提出了基于块的模型拆分算法以降低计算复杂度。这些算法在毫秒内能确定最优模型拆分，并显著减少了训练延迟。", "conclusion": "所提出的基于DAG的快速模型拆分算法和基于块的模型拆分算法能够高效确定最优模型拆分，并且在动态边缘网络中有效降低了训练延迟，具有较好的应用前景。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00736", "html_url": "https://arxiv.org/abs/2507.00736", "title": "离散级问题难度估计中的序属性：引入平衡DRPS和OrderedLogitNN", "title_en": "Ordinality in Discrete-level Question Difficulty Estimation: Introducing Balanced DRPS and OrderedLogitNN", "authors": "Arthur Thuy,Ekaterina Loginova,Dries F. Benoit", "background": "近年来，自然语言处理技术在问题难度估计（QDE）方面引起了越来越多的兴趣。通常通过对问题难度进行离散表示，并将其任务视为序回归，因为难度从最易到最难存在固有的顺序性。然而，文献中忽视了任务的序属性，主要依赖于分类或分段回归模型，而专门的序回归方法尚未得到探索。此外，评估指标紧密耦合于建模范式，阻碍了跨研究的可比性。虽然一些度量标准未能考虑到难度级别的序结构性，但它们均未能有效处理类别不平衡问题，导致偏差的性能评估。", "innovation": "该研究通过利用平衡化离散排列概率评分（Balanced Discrete Ranked Probability Score, DRPS）来基准测试三种模型输出——分段回归、分类和序回归，并提出了一种名为OrderedLogitNN的方法，该方法将经济学中的有序对数几率模型扩展到神经网络中。研究还发现，对BERT进行微调后，OrderedLogitNN在复杂任务上表现出显著更好的性能。平衡化的DRPS为离散级别的QDE提供了一个稳健且公平的评估标准，为未来的研究提供了理论基础。", "conclusion": "平衡化的DRPS为离散级别的QDE提供了一个可靠且公平的评估指标，这为后续研究提供了一个坚实的理论基础。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00920", "html_url": "https://arxiv.org/abs/2507.00920", "title": "隐私保护的多样化精度量化联邦学习", "title_en": "Privacy-Preserving Quantized Federated Learning with Diverse Precision", "authors": "Dang Qua Nguyen,Morteza Hashemi,Erik Perrins,Sergiy A. Vorobyov,David J. Love,Taejoon Kim", "background": "联邦学习（FL）作为一种分布式机器学习的有希望的范式，允许多个本地设备在不共享原始数据的情况下向融合中心（FC）传输本地模型更新，进行协作训练。尽管FL有进步，但它受限于数据传输的隐私风险以及参与设备间模型量化分辨率的不一致性导致的学习效率下降。以往的研究通常只解决其中一个问题，因为同时保持隐私保护和量化分辨率一致性非常困难。本文旨在提升一种隐私保护联邦学习的性能，使具有不同量化分辨率的设备集群能够参与每次FL训练。面对量化分辨率不一致，本文提出了一个新颖的随机量化器（SQ），结合线性融合方法优化集群大小，以提升模型聚合准确度。仿真结果表明这种方法在保护隐私和维持学习效率方面优于传统算法。", "innovation": "本文提出了一个随机量化器（SQ），旨在同时实现差别隐私（DP）和最小量化误差。SQ的显著改进在于它保证了有界失真，区别于其他DP方法。此外，本文还提出了一种集群大小优化技术与线性融合方法相结合的策略，以增强模型聚合精度，解决量化分辨率不一致性问题。这些创新方法实现了在保持隐私保护的同时，提升学习效率的目标。", "conclusion": "通过使用所提出的随机量化器（SQ），结合集群大小优化技术与线性融合方法，本文的隐私保护量化联邦学习方法有效地提高了学习效率，同时保护了隐私。数值模拟结果验证了本文方法相对于传统LaplaceSQ-FL算法在隐私保护和学习效率方面的优势。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01381", "html_url": "https://arxiv.org/abs/2507.01381", "title": "分布式软演员评论家策略与扩散政策", "title_en": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": "Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li", "background": "强化学习已被证明对处理复杂的控制任务非常有效。传统的方法通常使用单一模态分布，比如高斯分布，来表示价值分布。但单一模态分布很容易引起价值函数评估的偏差，导致算法性能不佳。", "innovation": "本文提出了一个新的分布强化学习算法叫DSAC-D（分布式软演员评论家策略结合扩散策略），来解决价值函数评估偏差的问题，并获得多模态策略表示。通过引入策略熵和价值分布函数建立了多模态分布策略迭代框架，可以收敛到最优策略。构建了一个通过逆采样扩散模型生成一组奖励样本来准确描述多峰分布的扩散价值网络。在此基础上，提出了价值网络和策略网络双扩散的分布强化学习算法。MiJoCo测试任务显示，该算法不仅可以学习多模态策略，还可以在所有9项控制任务中达到最先进的性能，相比现有主流算法，显著抑制了估计偏差并提高了超过10%的总平均回报。实车测试结果表明，DSAC-D能够准确表征不同驾驶风格的多模态分布，并且扩散策略网络能够表征多模态轨迹。", "conclusion": "DSAC-D算法不仅能够学习多模态策略，还能在多控制任务中达到最先进的性能，显著减少了估计偏误，并且在真实车辆测试中能够准确表征不同驾驶风格的多模态分布与多模态轨迹。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01201", "html_url": "https://arxiv.org/abs/2507.01201", "title": "从柏拉图的洞穴中解脱出来：JAM 用于对齐独立训练的视觉和语言模型", "title_en": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "authors": "Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim", "background": "独立训练的视觉和语言模型分别存在于不同的表征空间中，这些空间受到各自模态、目标和架构的影响。然而，一种新兴的假设——柏拉图表征假设，暗示这些模型可能朝着共同的现实统计模型收敛。如果这种兼容性存在，那么一个基本的问题随之而来：我们能否超越事后统计检测对齐的方式，而是明确地对这种分离表示进行对齐优化？", "innovation": "作者将柏拉图对齐问题作为多目标优化任务进行处理，即在保留各自模态的固有结构的同时，实现跨模态的相互一致性。提出了一种联合自编码器调制器（JAM）框架，通过共同训练单一模态预训练模型的潜在表示的模态特定自编码器，并通过重构和跨模态目标鼓励对齐。该框架为从分离输入中产生共享结构提供了一种方法，类似于帮助逃离柏拉图的洞穴。", "conclusion": "研究表明，轻量级的非支配优化框架可以可靠地诱导对齐，即使跨冻结独立训练表示也是如此，提供了理论见解和实用路径，让通用单一模态基础模型转变为专业多模态模型。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2210.09228", "html_url": "https://arxiv.org/abs/2210.09228", "title": "PDE 联合反演问题的一种模型一致的数据驱动计算策略", "title_en": "A Model-Consistent Data-Driven Computational Strategy for PDE Joint Inversion Problems", "authors": "Kui Ren,Lu Zhang", "background": "从观测数据中同时重构多个物理系数在偏微分方程（PDEs）中的任务在应用中无处不在。然而，在进行联合反演时，目前的方法往往未能充分利用PDE模型的信息，导致重建质量不够高。为此，本文提出了一种结合数据驱动和模型导向的迭代重建框架，通过补充关于未知系数的额外数据来改进重建效果，使数据驱动建模过程与基于模型的重建过程保持一致。", "innovation": "本文提出了一种新的重建方法，通过将额外的数据与PDE模型相结合，使数据驱动过程与模型导向的重建过程保持一致。这种方法能够更好地利用模型信息，解决联合反演问题，提高多物理系数的重建质量。该方法还通过数值实验验证了使用数据驱动模型提高PDE中多个系数联合反演的可能性，并对两个典型反演问题的学习不确定性影响进行了描述。", "conclusion": "通过几种PDE联合作用的问题，证明了结合数据驱动和基于模型的迭代还重建方法的有效性，证实了数据驱动模型在提高多物理系数联合反演方面的重要作用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2212.05050", "html_url": "https://arxiv.org/abs/2212.05050", "title": "通过算法重新审视不稳定公式定理", "title_en": "The unstable formula theorem revisited via algorithms", "authors": "Maryanthe Malliaris,Shay Moran", "background": "文章背景介绍了一个基础的模型理论结果——稳定理论——与机器学习中的算法稳定性之间的意外交互。现有学习模型存在一些缺口，因此需要引入新的统计学习模型“几乎最终正确”或PEC（Probably Eventually Correct）来更好地描述和理解学习过程中的稳定性。", "innovation": "文章的创新在于，通过对现有近似算法进行比较分析，提出了一个等价定理，突显了诸多现有近似算法和新提出的PEC之间的共同点。这一创新性工作结合模型理论中的类型定义类比，但具有自身特点。基于这些定理和其他近期的研究工作，文章提出了舍费尔不朽的不稳定公式定理的一个完整的算法对应物，其中算法性质代替了无穷性质。", "conclusion": "最终，文章通过提供一个基于算法框架的不稳定公式定理的新版本，即通过算法重新审视不稳定公式定理，为理解和改进模型理论在机器学习中的应用提供了新的见解。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.05766", "html_url": "https://arxiv.org/abs/2405.05766", "title": "追求XAI系统中用户信任的新度量", "title_en": "Towards a Novel Measure of User Trust in XAI Systems", "authors": "Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho", "background": "随着深度学习模型在各种应用中的依赖增加，但这类模型本身具有不透明性，从而影响了用户对其决策的信任。为了提升这种信任，解释性AI（XAI）方法应运而生，这些方法旨在通过揭示模型决策的原理来增强用户对自动化系统的信任。本文继续这一研究，通过提出一个新的信任度量进一步促进XAI系统的改进和发展，并通过三项实证研究证明了该新方法的优越性和适用性，特别提高了对不同情况的敏感性。", "innovation": "本文提出了一种新的信任度量，该度量从客观角度结合了性能指标和信任指标，旨在通过改进XAI系统中用户对模型决策的信任来推动该领域的进一步发展。该方法通过三项案例研究展示了对现有最佳技术的改进和更高场景敏感度。", "conclusion": "通过引入新的信任度量，实验结果表明该方法优于现有最佳技术，并能更好地应对多种场景变化，进一步推动了XAI系统的优化和改进，提升了用户对其系统决策的信心。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.14727", "html_url": "https://arxiv.org/abs/2311.14727", "title": "在旅游领域多语言分析社交内容的最优策略", "title_en": "Optimal strategies to perform multilingual analysis of social content for a novel dataset in the tourism domain", "authors": "Maxime Masson,Rodrigo Agerri,Christian Sallaberry,Marie-Noelle Bessagnet,Annig Le Parc Lacayrelle,Philippe Roose", "background": "随着社交媒体平台在旅游等各个领域的影响力增大，对 efficient 和 automated 的自然语言处理（NLP）策略的需求也在增加。然而，将多语言、非结构化和非正式文本转换为结构化知识仍具有挑战性，特别是对深度学习分类器的训练需要持续手动标注的数据。本文研究了不同的 NLP 技术，以确定哪种技术能在最少的训练标注数据需求下获得竞争性性能。为此，作者构建了第一个公开的多语言数据集（法语、英语和西班牙语），用于旅游领域，包含与旅游相关的微博。", "innovation": "通过使用现代零样本和微调技术来减少标注数据的需求，本文展示了现代零样本技术在所有三项任务上都能获得竞争力的结果：对于情感分析，每类别 5 条微博（总共 15 条）；对于位置命名实体识别，每类别 30 条微博；对于细粒度主题概念提取，使用一个 315 类别的细粒度序列标签任务进行了 1000 条微博的标注。这些结果为 NLP 在新领域特定应用中的应用铺平了道路，减少了手工标注的需要，规避了基于规则的、临时解决方案的复杂性。", "conclusion": "本文建立的多语言数据集为旅游领域的 NLP 应用提供了新的基础，展示了在各种 NLP 任务中以最少的标注数据达到竞争性性能的可能性，这为未来的研究和应用指出了新的方向。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.05920", "html_url": "https://arxiv.org/abs/2408.05920", "title": "基于图的地区预训练和提示：一种地区表示学习的方法", "title_en": "Urban Region Pre-training and Prompting: A Graph-based Approach", "authors": "Jiahui Jin,Yifan Song,Dong Kan,Haojia Zhu,Xiangguo Sun,Zhicheng Li,Xigang Sun,Jinghui Zhang", "background": "城市区域表示对于各种下游城市任务至关重要。尽管存在多种方法并取得了成功，但获取城市区域的一般知识并适应不同任务仍然具有挑战性。现有工作较少关注城市区域中的详细功能布局语义，这限制了它们跨区域捕捉转移性知识的能力。此外，对于不同下游任务所需的独特特征和关系处理不足也可能阻碍有效任务适应。", "innovation": "本文提出了一个基于图的都市区域预训练和提示框架（GURPP），用于地区表示学习。具体而言，首先构建了一个城市区域图，并开发展示城市区域中实体交互异质性和可转移模式的子图中心预训练模型。该模型利用对比学习和多视图学习方法进行知识丰富的区域嵌入预训练。为了进一步细化这些表示，设计了两种基于图的提示方法：一种是手工定义的提示，用于整合显性的任务知识；另一种是任务可学习的提示，用于发现潜在知识，从而增强这些嵌入对不同任务的适应性。", "conclusion": "在各种城市区域预测任务和不同城市上的实验结果表明，该框架表现出优越的性能。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.07079", "html_url": "https://arxiv.org/abs/2408.07079", "title": "脑MRI的解剖学基础模型", "title_en": "Anatomical Foundation Models for Brain MRIs", "authors": "Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto", "background": "深度学习在神经成像中的应用越来越受到重视，特别是在检测神经学状况和神经退行性疾病方面。脑年龄是神经成像中最主要的生物标志物之一，已被证明是判断多种状况（如阿尔茨海默病）的有效指标。研究表明，在数据稀缺的情况下，利用脑年龄对深度学习模型进行弱监督预训练可以取得令人鼓舞的结果。此外，脑MRI的解剖信息（如皮层厚度）提供了解学习良好表示的重要信息，这些表示可以迁移至许多下游任务中。然而，现有方法在利用解剖信息进行预训练以获得更鲁棒和泛化能力强的表示方面存在不足，特别是在多种不同的下游任务中。", "innovation": "本文提出了AnatCL，这是一种解剖学基础模型，它在弱对比学习方法中利用了解剖信息，并在多种不同的下游任务中取得了最先进的性能。AnatCL不仅能够利用解剖信息，还在多个诊断任务（如阿尔茨海默病、自闭症谱系障碍和精神分裂症的诊断）和临床评估（利用结构MRI数据预测10项不同临床评估分数）中实现了卓越的效果。通过与现有方法的比较，证明了在预训练过程中整合解剖信息可以提高表示的鲁棒性和泛化能力。", "conclusion": "本研究通过引入AnatCL解剖学基础模型，证明了在预训练期间整合解剖信息可以增强表示的鲁棒性和泛化能力，从而在多种不同诊断任务和临床评估任务中取得了卓越的性能。预训练模型可以在该网址找到：[提供网址]。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.06902", "html_url": "https://arxiv.org/abs/2407.06902", "title": "从嘈杂众包标签学习：信号处理视角", "title_en": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective", "authors": "Shahana Ibrahim,Panagiotis A. Traganitis,Xiao Fu,Georgios B. Giannakis", "background": "由于大规模众包标注数据的可用性，人工智能和机器学习领域取得了显著进展。然而，这些众包数据通常会包含噪声标签，这给学习任务带来了负面影响。因此，如何有效减少噪声标签的影响，是众包标注领域的一项核心挑战。本文分析了学习从嘈杂的众包标签中提取信息的方法，涵盖了统计模型和深度学习方法，并强调了这些方法的理论和算法发展。", "innovation": "本文通过信号处理理论视角，探讨了如何将信号处理技术应用于处理嘈杂的众包数据，提出了基于张量和非负矩阵分解等信号处理方法来解决众包标注中的难题，并特别讨论了强化学习中有监督反馈（RLHF）和直接偏好优化（DPO）等新兴主题在大规模语言模型（LLMs）优化中的应用，促进了该领域的技术进步和发展.", "conclusion": "文章综合了传统的统计模型和新兴的深度学习方法，通过信号处理理论，提供了新的理论框架和实用算法，为处理嘈杂的众包标签提供了新的视角。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.13840", "html_url": "https://arxiv.org/abs/2306.13840", "title": "超越规模：语言数据多样性的多样性系数作为变异性数据质量度量", "title_en": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data", "authors": "Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo", "background": "当前大型语言模型（LLMs）的预训练趋势主要集中在模型和数据集规模的扩大上。尽管高质量的预训练数据被认为是训练强大LLMs的关键因素，但这一概念尚未被严格定义和描述。本研究旨在通过提出一个衡量语言数据多样性的方法——多样系数，来解决这一问题。", "innovation": "该研究提出了一种衡量预训练数据多样性的度量方法，即多样系数，来正式化数据质量的一个关键方面。通过实证分析，该方法能够直观地反映多样性和变异性特征，并应用于多个预训练数据集中，展示了这些数据在理论上下限范围内的正式多样性水平。最后，通过对GPT-2和LLaMAv2进行了一系列受控干预实验，证明了多样系数可以反映下游模型评估性能的关键方面。", "conclusion": "本研究得出的结论是，提出的正式多样系数概念在数据质量中是一个重要的方面，能够捕捉变异性并导致改进的评估性能。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.09511", "html_url": "https://arxiv.org/abs/2311.09511", "title": "使用齐性自回归蓄水池计算机识别具有对称性系统", "title_en": "Identifying Systems with Symmetries using Equivariant Autoregressive Reservoir Computers", "authors": "Fredy Vides,Idelfonso B. R. Nogueira,Gabriela Lopez Gutierrez,Lendy Banegas,Evelyn Flores", "background": "本文档的调查集中在利用齐性自回归蓄水池计算机识别具有对称性的系统。通过结构矩阵近似理论的通用结果，研究了一种两步方法：首先，全面检查了保保持对称性的非线性时间延迟嵌入；其次，应用稀疏最小二乘法以识别输出耦合矩阵的近似表示。这些矩阵在决定齐性自回归系统表示方面起着关键作用，其结构特性由系统中固有的对称性集决定。文档概述了从所描述技术派生的典型算法，并对其实际应用提供了见解。重点强调了与经典的蓄水池计算方法相比，该方法在模拟齐性动力系统时对结构识别精度的显著改进。", "innovation": "提出了一种利用齐性自回归蓄水池计算机来识别具有对称性系统的新型方法。方法包括两点：一种全面检查保保持对称性的非线性时间延迟嵌入的方法；以及应用稀疏最小二乘法来识别输出耦合矩阵的近似表示。通过这种结构化的识别方法，相比于传统的蓄水池计算方法，该方法在模拟齐性动力系统时能提供更高的识别精度。", "conclusion": "本文档概述了通过齐性自回归蓄水池计算机识别具有对称性系统的方法及其应用场景。研究结果显示，与传统方法相比，该创新方法在模拟齐性动力系统时具有明显的优势，能够获得更高的识别精度。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.03133", "html_url": "https://arxiv.org/abs/2407.03133", "title": "使用潜在类别分析量化多个群体内的跨部门交汇差异以实现公平", "title_en": "Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness", "authors": "Yingfang Yuan,Kefan Chen,Mehdi Rizvi,Lynne Baillie,Wei Pang", "background": "随着对公平人工智能发展的兴趣日益增长，‘不让任何人掉队’倡议强调了在提供服务、资源和机会时解决各种交织形式不平等的重要性，特别是在人工智能工具在决策过程中越来越多地被应用于诸如健康、能源和住房等多个领域时，这一点显得格外重要。因此，研究这些领域的交叉不平等是理解整体不平等和不公平的关键。当前的研究通过引入潜在类别分析方法，提出了量化用户定义群体间跨部门差异的新途径，这种方法有助于估计不平等并为公平性问题提供有价值的见解。随后，该研究使用包括同时利用了专属数据集和公共数据集(如EVENS和英格兰与威尔士2021年普查数据)来探究不同种族群体之间的跨部门差异，并通过与政府公共指标的相关性分析验证了量化差异的可靠性。", "innovation": "本研究创新点在于引入潜在类别分析方法，用于量化用户定义群体间的跨部门差异，这种方法能够直接估计不平等并为公平性问题提供有价值的见解。研究通过跨部门的数据集验证了该方法的有效性和可靠性，并且展示了该方法在确保机器学习系统中的公平性方面的重要性。", "conclusion": "研究结果揭示了不同少数种族群体之间的显著差异，强调了政策制定中需要针对这些问题进行干预。同时，研究证明了所提出的方法能够为确保机器学习系统的公平性提供宝贵的见解。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.07386", "html_url": "https://arxiv.org/abs/2408.07386", "title": "衰退记忆与卷积定理", "title_en": "Fading memory and the convolution theorem", "authors": "Juan-Pablo Ortega,Florian Rossmannek", "background": "论文引入了因果性和时不变滤波器的几个连续性和衰减记忆的拓扑与分析概念，并分析了它们之间的关系。证明了一个关于卷积定理的重要推广结果，该结果将衰减记忆属性与线性滤波器的卷积表示之间的等价性推广到加权范数定义的各种衰减记忆属性。此外，论文表明，当保域是有限维时，卷积表示的可用性不仅可以通过衰减记忆属性来刻画，还可以通过两个纯拓扑概念的结合来刻画：最小连续性和最小衰减记忆属性。当输入空间和代码域为希尔伯特空间时，论文还表明最小连续性和最小衰减记忆属性保证了相关可再生核希尔伯特空间的有趣嵌入的存在性。", "innovation": "论文证明了一个关于卷积定理的重要推广结果，将衰减记忆属性与线性滤波器的卷积表示之间的等价性推广到加权范数定义的各种衰减记忆属性。此外，纸指出卷积表示的可用性可以由两个拓扑概念的结合来刻画，而不仅仅是衰减记忆属性。最后，当输入空间和代码域为希尔伯特空间时，证明了最小连续性和最小衰减记忆属性保证了相关可再生核希尔伯特空间的嵌入的存在性。", "conclusion": "最小连续性和最小衰减记忆属性在希尔伯特空间中保证了相关可再生核希尔伯特空间有趣嵌入的存在性，还展示了卷积表示的可用性可以通过两个纯拓扑概念来刻画，这些结论扩展了此前关于卷积定理的刻画，并提供了更广泛的一系列加权范数定义。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.04318", "html_url": "https://arxiv.org/abs/2408.04318", "title": "基于深度迁移学习的肾癌诊断", "title_en": "Deep Transfer Learning for Kidney Cancer Diagnosis", "authors": "Yassine Habchi,Hamza Kheddar,Yassine Himeur,Mohamed Chahine Ghanem,Abdelkrim Boukabou,Shadi Atalla,Wathiq Mansoor,Hussain Al-Ahmad", "background": "不可治愈的疾病给全球医疗系统带来了重大挑战，其流行程度受生活方式、经济、社会和遗传因素的影响。在这些因素中，肾病依然是一个重要的全球健康问题，需要持续的研究来提高早期诊断和治疗。近年来，深度学习（DL）在医学成像和诊断方面显示出潜力，推动了自动肾癌（KC）检测的重大进展。然而，DL模型的成功依赖于高质量、特定领域的数据集的可用性，这些数据集通常难以获得且成本高昂。此外，DL模型需要大量的计算能力和存储空间，限制了其在临床实际中的应用。为了克服这些障碍，迁移学习（TL）已经作为一种有效的方法出现，它使得可以利用相关领域的预训练模型来增强KC诊断。", "innovation": "本文综述了基于深度迁移学习的肾癌检测框架，系统地审查了关键方法、优势和局限性，并分析了其实用性能。进一步讨论了TL在医学影像中的应用挑战，并强调了可能影响未来研究的新兴趋势。迁移学习在提高诊断准确性、降低计算需求和支持AI工具在医疗保健中的集成方面显示出了变革性的角色，特别是在肿瘤学领域。", "conclusion": "本文综合表明，迁移学习在精确医疗，特别是肿瘤学领域中发挥着变革性作用，通过提高诊断准确性、减少计算需求和支持AI工具在医疗保健中的集成来改善病患的治疗方案。文章所提供的见解为研究人员和实践者提供了宝贵的指导，铺平了未来KC诊断和个人化治疗策略进步的道路。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10530", "html_url": "https://arxiv.org/abs/2410.10530", "title": "无需自适应内存要求的自适应概率ODE求解器", "title_en": "Adaptive Probabilistic ODE Solvers Without Adaptive Memory Requirements", "authors": "Nicholas Krämer", "background": "尽管近年来取得了显著进展，但具有自适应步长的概率求解器仍然无法解决高内存需求的微分方程，除非我们只关心时间序列中的单一点。但这种方法过于限制，我们更希望处理整个时间序列。通常归咎于自适应性的不可预测内存需求，这往往超出机器的容量，使模拟在没有预警的情况下失败。放弃自适应性虽然可以解决这一问题，但会放弃多年来取得的进展，显然不是一个好办法。", "innovation": "为了应对这一困境，作者开发了一种自适应概率求解器，该求解器具有固定的内存需求并基于最新的鲁棒状态估计进步。这种方法能够（i）解决长时间序列的内存问题，（ii）通过启用即时编译大幅加速模拟，（iii）使自适应概率求解器与JAX中的科学计算兼容。", "conclusion": "通过引入一种新的基于固定内存需求的自适应概率求解器，该研究显著改善了处理高内存需求微分方程的能力，提升了模拟效率，并为自适应求解器在科学计算中的广泛应用铺平了道路。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.06416", "html_url": "https://arxiv.org/abs/2409.06416", "title": "探索大语言模型在工业测试维护过程中的集成", "title_en": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes", "authors": "Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg", "background": "软件测试过程中投入大量成本和努力用于测试维护，即添加、删除或修改测试用例以保持测试套件与系统一致或提高其质量。工具支持可以通过自动化测试维护过程中的某些方面或为开发人员提供指导和支持来降低成本并提高测试维护质量。在这项研究中，我们探讨了大语言模型（LLMs）——用于文本分析的复杂机器学习模型——的能力和应用，以支持测试维护。我们在爱立信AB公司进行了一项案例研究，探讨触发测试维护需求的触发因素、LLMs可以采取的行动，以及部署LLMs时需要考虑的因素。我们还提出了一个可以预测代码变更后哪些测试需要维护的多代理架构。", "innovation": "我们研究了大语言模型在工业测试维护中的应用，探讨了可以触发测试维护的各种因素，展示了可以预测代码变更后哪些测试需要维护的多代理架构，并为在工业环境中部署大型语言模型提供了考虑因素。", "conclusion": "我们的研究成果在理论上和实践上推进了关于如何部署大语言模型以提高工业测试维护过程的理解。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.18624", "html_url": "https://arxiv.org/abs/2409.18624", "title": "无监督认知", "title_en": "Unsupervised Cognition", "authors": "Alfredo Ibias,Hector Antona,Guillem Ramirez-Miranda,Enric Guinovart,Eduard Alarcon", "background": "无监督学习方法受到认知模型的启发。迄今为止，最成功的无监督学习方法集中在数学空间中的样本聚类。本文提出了一种基于原始数据、无监督学习的决策方法，灵感来源于一种新的认知框架。该方法构建性地在输入无关的方式下将输入空间表示为分布式分层结构。这种方法与现有的无监督学习分类、小型不完整数据集分类，以及癌症类型分类的当前最先进的方法进行了比较，展示了其优越性，也表现出了类似认知的行为特征。", "innovation": "提出了基于原始数据的无监督学习决策方法，该方法灵感来源于一种新的认知框架，并构建性地在输入无关的方式下将输入空间表示为分布式分层结构。该方法在与当前最先进的无监督学习方法的比较中表现出优越性，并展示了类似认知的行为特征。", "conclusion": "本文提出的方法在无监督学习和分类任务中均表现出色，甚至在传统监督学习方法中也表现出更类似认知的行为特征，超过了之前最先进的方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.03977", "html_url": "https://arxiv.org/abs/2409.03977", "title": "Bi-modality medical images synthesis by a bi-directional discrete process matching method", "title_en": "Bi-modality medical images synthesis by a bi-directional discrete process matching method", "authors": "Zhe Xiong,Qiaoqiao Ding,Xiaoqun Zhang", "background": "近年来，医疗图像合成随着生成模型的快速发展而越来越受欢迎。医学图像合成的目标是从其他观察到的数据模态生成未获取的图像模态，常用于临床诊断协助、模型训练和验证的数据增强以及图像质量提高。流基于模型因其生成逼真和高质量合成图像的能力而成为成功的生成模型之一。然而，大多数流基于模型在合成过程中需要计算大量的常微分方程（ODE）演化步骤，这导致了由于大量时间迭代的计算量大，从而限制了其性能。因此，对于双向离散过程匹配（Bi-DPM）的提出旨在解决这些问题。", "innovation": "本文提出了一种新型的双向离散过程匹配（Bi-DPM）模型，用于完成双模态医学图像合成任务。不同于其他基于流匹配的模型，Bi-DPM模型在合成过程中使用了正向和反向ODE流，并通过少量离散时间步骤增强了中间图像的一致性，使得合成过程在配对数据的指导下保持两种模态高质量生成。这项工作展示了在MRI T1/T2和CT/MRI三个数据集上的实验结果，表明Bi-DPM方法在双模态医学图像合成中比其他最先进的流基于方法具有更高的图像质量和准确的解剖区域。", "conclusion": "实验结果表明，Bi-DPM方法在双模态医学图像合成上优于其他最先进的流基于方法，提供更高质量的图像和准确的解剖区域。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.15582", "html_url": "https://arxiv.org/abs/2409.15582", "title": "概念转移下的泛化与专业化", "title_en": "Generalization vs. Specialization under Concept Shift", "authors": "Alex Nguyen,David J. Schwab,Vudtiwat Ngampruetikorn", "background": "机器学习模型在数据分布转移的情况下往往较为脆弱，即在测试数据分布不同于训练数据分布的情况下表现不佳。理解这一故障模式对于识别和减轻大规模采用机器学习的安全风险至关重要。本文分析了在概念转移下岭回归的表现，这是一种输入与标签关系在测试时间发生改变的分布转移形式，旨在深入探讨这一现象对泛化性能的影响，特别是通过理论分析揭示了概念转移对泛化性能的非平凡影响，包括概念转移强度转变的相变以及在双下降效应不存在的情况下，测试性能的数据依赖性呈现出非单调性。", "innovation": "本文通过理论分析得出了概念转移下岭回归预测风险的精确表达式，并通过实验验证了在概念转移情况下，关注-transformer预训练解决线性回归问题的实验结果表明，过长的上下文长度可能对下一个标记预测的泛化性能造成负面影响。此外，在MNIST和FashionMNIST数据集上的实验还展示了这种有趣的现象同样存在于分类问题中，揭示了概念转移下泛化与专业化的矛盾关系。", "conclusion": "本文揭示了概念转移对岭回归泛化性能的非平凡影响，特别是在双下降现象不存在的情况下，测试性能与数据之间的依赖关系表现出非单调性。实验结果对于进一步理解概念转移下的机器学习模型行为具有重要意义，特别是在实际应用场景中的安全性和可靠性问题上。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.00903", "html_url": "https://arxiv.org/abs/2410.00903", "title": "使用生成人工智能进行因果表示学习：文本作为治疗的应用", "title_en": "Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments", "authors": "Kosuke Imai,Kentaro Nakamura", "background": "本文探讨了如何利用生成人工智能（GenAI）增强处理高维非结构化信息（如文本）时因果推断的有效性。现有的方法通常需要从数据中学习因果表示，这可能导致偏离方法的准确性。文章提出了使用深度生成模型（如大规模语言模型）进行高效治疗生成，并利用其内部表示来进行后续因果效应估计的方法。这种方法通过正式证明非参数识别条件、提出避免重叠假设验证的方法以及通过双重机器学习推导提出的估计量的渐近性质来改进因果推断的准确性与效率。", "innovation": "提出了一个名为GenAI-Powered Inference (GPI)的新方法，它通过生成模型和内部表示来处理高维非结构化的治疗方法，从而无需从数据中学习因果表示，实现了更加准确和有效的估计。GPI方法还通过双重机器学习推导出提出估计量的渐近性质，并通过工具变量方法将其应用于基于人类感知的治疗方法情形。此外，该方法还适用于文本再利用情况下的治疗生成与再生。", "conclusion": "文章通过理论证明和实证研究展示了GPI方法的优点。通过使用开源大规模语言模型Llama 3生成的文本数据进行模拟和实证分析，验证了GPI方法相较于最先进的因果表示学习算法的优越性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05451", "html_url": "https://arxiv.org/abs/2410.05451", "title": "SecAlign：通过偏好优化抵御提示注入攻击", "title_en": "SecAlign: Defending Against Prompt Injection with Preference Optimization", "authors": "Sizhe Chen,Arman Zharmagambetov,Saeed Mahloujifar,Kamalika Chaudhuri,David Wagner,Chuan Guo", "background": "大型语言模型（LLMs）在现代软件系统中越来越常见，它们作为用户和互联网之间的接口，帮助完成需要高级语言理解的任务。为了完成这些任务，LLM经常使用用户文档、Web检索、API调用结果等外部数据源。这为攻击者通过提示注入攻击LLM提供了新途径。攻击者可以在外部数据源中注入恶意提示，从而篡改系统预期指令，执行恶意操作。为了缓解这一漏洞，本文提出了一种基于偏好优化的新防御方法SecAlign。SecAlign首先构建包含提示注入输入、安全输出和不安全输出的数据集，随后通过偏好优化来训练LLM更倾向于安全输出而非不安全输出，从而降低各种提示注入攻击的成功率，即使是对训练期间未曾见过的更复杂的攻击也是如此，表明该防御方法具有良好的泛化能力。实验证明，SecAlign模型在防御训练后仍然具有相似的实用性。", "innovation": "本文提出的SecAlign防御方法通过偏好优化来减少多种提示注入攻击的成功率至低于10%，即使是对训练期间未曾见过的更复杂的攻击也是如此，从而展示了良好的泛化能力。同时，SecAlign模型在防御训练后仍然具有相似的实用性。这是首次提出能降低各种提示注入成功率为如此低水平的防御方法，具有重大的创新意义。", "conclusion": "本文首次提出了基于偏好优化的SecAlign防御方法，通过构建数据集并实施偏好优化，显著降低（甚至在未见过的更复杂攻击下）提示注入攻击的成功率。同时也证明SecAlign在防御后仍能保持模型的实用性，并能够良好地应对未来未知的攻击。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06946", "html_url": "https://arxiv.org/abs/2412.06946", "title": "一种基于深度学习的二黑洞波形数值相对论代理模型", "title_en": "A Deep Learning Powered Numerical Relativity Surrogate for Binary Black Hole Waveforms", "authors": "Osvaldo Gramaxo Freitas,Anastasios Theodoropoulos,Nino Villanueva,Tiago Fernandes,Solange Nunes,José A. Font,Antonio Onofre,Alejandro Torres-Forné,José D. Martin-Guerrero", "background": "引力波近似模型对于引力波天文学至关重要，它们允许无须昂贵的数值相对论模拟就能覆盖双黑洞参数空间，实现测量或匹配滤波，但通常减少了一些精确定价计算效率的提升。为了减少这种权衡，可以使用数值相对论波形空间内的插值构建数值相对论替代模型。本文采用一种两阶段训练方法训练神经网络替代模型。", "innovation": "提出了一种双阶段人工神经替代模型（DANSur），首先基于近似模型生成的波形训练，然后通过数值相对论数据进行微调。这种模型能够提供快速且竞争对手的精度，可在几毫秒内生成数百万个波形，同时保持数值相对论的平均不匹配度约为10^-4。这种模型在bilby框架中实现，并展示可在参数估计任务中使用。", "conclusion": "通过这种方法，研究人员能够显著降低和数值相对论之间的精度损失，同时继续保持计算效率。在bilby框架中的实现证明了该模型在参数估计任务中的适用性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.19688", "html_url": "https://arxiv.org/abs/2411.19688", "title": "SURE-VQA: 系统理解医学视觉问答任务中鲁棒性评估", "title_en": "SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks", "authors": "Kim-Celine Kahl,Selen Erkan,Jeremias Traub,Carsten T. Lüth,Klaus Maier-Hein,Lena Maier-Hein,Paul F. Jaeger", "background": "视觉语言模型（VLMs）在医学任务中展现出巨大潜力，尤其是在视觉问答（VQA）上，能够作为患者和临床医生的交互式助手。然而，这些模型在未见数据上的鲁棒性依然值得关注，因为这对于安全部署至关重要。现有的评估鲁棒性的实验设置通常无法提供充分的评估，所以需要一个新的框架来系统地研究VLM的鲁棒性。", "innovation": "作者提出了一个新的框架——SURE-VQA，主要包括三个关键要求：1) 测量鲁棒性时应基于VQA数据本身的现实变化，而不是合成的变化；2) 使用大规模语言模型（LLMs）进行语义评估，以更准确地衡量语义变化；3) 报告有意义的基线，使多模态影响的评估更加明确。通过这种方法，系统地分析了各种Fine-Tuning（FT）方法在不同医学数据集及分布变化下的鲁棒性。", "conclusion": "在此框架下进行研究表明，1) 没有一种Fine-Tuning方法在所有情况下都表现出更好的鲁棒性，2) 不同Fine-Tuning方法之间的鲁棒性趋势比不同分布变化的鲁棒性趋势更稳定。此外，研究发现简单的不使用图像数据的基线可以表现得相当好，并确认LoRA方法在内分布数据上表现最佳。相关代码已提供。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.11554", "html_url": "https://arxiv.org/abs/2412.11554", "title": "在临床多组学研究中学习大规模部分相关网络的HP-ACCORD", "title_en": "Learning Massive-scale Partial Correlation Networks in Clinical Multi-omics Studies with HP-ACCORD", "authors": "Sungdong Lee,Joshua Bang,Youngrae Kim,Hyungwon Choi,Sang-Yun Oh,Joong-Ho Won", "background": "多组学数据的图形模型估计需要在统计估计性能和计算可扩展性之间保持平衡。目前存在的方法可能在这些方面存在局限性，导致在处理大规模数据时性能下降或计算复杂度增加。本文旨在提出一种新的方法来解决这一问题，通过引入一个基于伪似然的图形模型框架，该框架在保持稀疏模式的同时重新参数化目标精度矩阵，并通过基于新损失函数的最小化$\boldsymbol{\boldsymbol{\text{ℓ_1}}}$-罚有监督风险估计来实现。", "innovation": "提出了一种新的基于伪似然的图形模型框架，通过重参数化目标精度矩阵，同时保持稀疏模式，并通过最小化一种新的基于$\boldsymbol{\boldsymbol{\text{ℓ_1}}}$罚的、基于新损失函数的有监督风险来估计精度矩阵。该方法在高维假设下能够保持估计和选择一致性。此外，该方法的优化问题可以通过一个新型的分块分裂法和避免通信的分布式矩阵乘法来实现高效的计算。", "conclusion": "本文方法被应用于模拟数据中，能够处理多达一百万个变量，并能展示出类似于生物网络的复杂依赖结构。通过利用这种可扩展性，文中估计了一个肝癌数据集中的部分相关网络，超高的表达网络估计优先于关键转录因子和共激活因子，排除了表观遗传调控的影响，突显了在多组学数据分析中计算可扩展性的重要性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.11074", "html_url": "https://arxiv.org/abs/2412.11074", "title": "Adapter-Enhanced Semantic Prompting for Continual Learning", "title_en": "Adapter-Enhanced Semantic Prompting for Continual Learning", "authors": "Baocai Yin,Ji Zhao,Huajie Jiang,Ningning Hou,Yongli Hu,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi", "background": "连续学习（CL）使模型能够适应不断演化的数据流。传统的CL方法面临着灾难性遗忘的问题，新知识会覆盖之前学到的知识。传统的解决方法要么保留过去的大量数据用于重放，要么在模型中增加额外的分支以学习新知识，这需要大量内存。", "innovation": "本文提出了一种新的轻量级连续学习框架，即Adapter-Enhanced Semantic Prompting (AESP)，该框架结合了提示调整和适配器技术。通过设计语义引导的提示来增强视觉特征的泛化能力，并使用适配器高效地融合语义信息，旨在为连续学习任务学习更适应的特征。此外，为选择适合特征调整的任务提示，开发了一种新颖的匹配机制进行提示选择。", "conclusion": "广泛实验在三个连续学习数据集上证明了该方法在多个指标上取得了优异的表现，展示了其在促进连续学习方面的发展潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.08290", "html_url": "https://arxiv.org/abs/2409.08290", "title": "重新考量脉冲神经网络的能效", "title_en": "Reconsidering the energy efficiency of spiking neural networks", "authors": "Zhanglu Yan,Zhenyu Bai,Weng-Fai Wong", "background": "脉冲神经网络（SNNs）相较于量化人工神经网络（QNNs），因其事件驱动的、基于脉冲的计算方式，理论上具有更高的能源效率。然而，现有的能源评估通常过于简化，主要关注计算部分，而忽视了全面的数据搬运和内存访问等关键开销。这种简化可能导致对SNNs真实能源效率的误解。本文通过重新评估这一问题，提出了更公平的方法来比较SNNs与QNNs的能效。这种方法通过将具有T个时间步长的率编码SNNs映射到功能上等效的具有$\text{ceiling}(\text{log}_2(T+1))$位的QNNs，使得两种模型在表示能力和硬件要求上具有可比性，从而实现有意义的能效对比。该研究还详细分析了核心计算和数据移动（稀疏和密集激活、权重）等能效模型，探索一系列参数空间，包括网络本身的属性（时间步长T、脉冲率$s_r$、QNN稀疏度$\text{gamma}$、模型大小N、权重位数）以及硬件属性（内存系统和片上网络）。", "innovation": "研究通过重新构建一个公平的基线，即通过将率编码SNNs映射到具有相似表示能力和硬件需求的等效QNNs来实现。此外，引入了详尽的能效模型，用于包含核心计算和数据移动的核心组成部分（稀疏和密集激活、权重），并通过系统地探索广泛的参数空间，包括网络和硬件特性，准确识别出了SNNs真正提供更高能效的操作区间。例如，在典型的神经形态硬件条件下，具有中等时间窗口（T位于5到10之间）的SNNs只需要低于6.4%的平均脉冲率就能超过等效的QNNs。这些发现为设计实现真正节能的人工神经网络解决方案提供了指导。", "conclusion": "本文展示了脉冲神经网络在不同参数组合下的真实能效优势。在特定的操作区间下，脉冲神经网络能够提供比量化人工神经网络更高的能源效率。特别是在中等时间窗口和较低的脉冲率条件下，脉冲神经网络能够表现出色。这些研究结果将帮助设计出真正能源高效的神经网络解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.05007", "html_url": "https://arxiv.org/abs/2501.05007", "title": "量子增强的小样本量因果发现方法", "title_en": "Quantum-enhanced causal discovery for a small number of samples", "authors": "Yu Terada,Ken Arai,Yu Tanaka,Yota Maeda,Hiroshi Ueno,Hiroyuki Tezuka", "background": "从观察数据中发现因果关系引起了经济学、社会科学和生物学等多个领域的极大兴趣。在实际应用中，对底层系统的知识往往不足，现实数据通常与非线性的因果结构相关联，这使得使用大多数传统因果分析方法变得困难。因此，亟需新的方法来发现因果关系，尤其是适用于小样本量的情况。", "innovation": "本文提出了一个新的量子Peter-Clark (qPC)算法，该算法不需要对底层模型结构作出任何假设。通过在量子电路表征的再生核希尔伯特空间中进行条件独立性测试来探索数据中的因果关系，尤其是来自任意分布的数据。此外，提出了一种基于核目标对齐（KTA）的新优化方法，用于确定量子核的超参数，有效降低了因果发现中的假阳性风险，提高了推断的可靠性。这种方法不仅在基础因果结构图的实验中表现出更优性能，特别是在小样本量的情况下，而且在实际数据集如波士顿房价、心脏病和生物信号系统中也得到了验证。", "conclusion": "本文提出的量子算法能够增强经典算法进行准确因果发现的能力，特别是在小样本量的情境下，克服了传统方法的局限性。该研究展示了基于量子的因果发现方法在解决实际问题方面的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03262", "html_url": "https://arxiv.org/abs/2501.03262", "title": "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models", "title_en": "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models", "authors": "Jian Hu,Xibin Wu,Wei Shen,Jason Klein Liu,Zilin Zhu,Weixun Wang,Songlin Jiang,Haoran Wang,Hao Chen,Bin Chen,Weikai Fang,Xianyu,Yu Cao,Haotian Xu", "background": "现有的RLHF（强化学习从人类反馈）和RLVR（具有可验证奖励的强化学习）框架虽然能够显著提高人类与AI的价值对齐和提升AI的能力，特别是在逻辑推理和长上下文任务中，但这些框架普遍面临推理瓶颈和复杂性障碍，限制了新用户的可访问性。", "innovation": "本文介绍了OpenRLHF，这是一种基于Ray、vLLM、DeepSpeed和HuggingFace Transformers构建的用户友好、可扩展且易于学习的开源RLHF框架。OpenRLHF通过简化设计、清晰的代码结构和详尽的文档，降低了研究者和实践者进入的门槛。实验结果显示，与最先进的框架相比，OpenRLHF在不同模型规模下的训练效率提高了1.22倍到1.68倍，同时实现了更少的代码实现量。OpenRLHF已公开发布，并被领先机构用于加速RLHF研究和学习。", "conclusion": "OpenRLHF作为一个高效的开源RLHF框架，通过简化设计和优化实现，显著提升了不同规模模型的训练效率，降低了入门门槛，并已广泛应用于多个机构的RLHF研究中。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03821", "html_url": "https://arxiv.org/abs/2501.03821", "title": "正则化回归中的归一化选择影响收缩", "title_en": "The Choice of Normalization Influences Shrinkage in Regularized Regression", "authors": "Johan Larsson,Jonas Wallin", "background": "在应用正则化模型时，特征的尺度对模型敏感。因此，通常会将特征标准化（即中心化和缩放）后再进行建模。但不同的标准化方法可能导致显著不同的结果。尽管如此，缺乏关于这一点研究的知识缺口导致了本研究的重要性。本文着眼于在lasso、岭回归和弹性网回归等正则化回归方法中，归一化选择如何影响模型收缩的不同影响。", "innovation": "本文研究了在lasso、岭回归和弹性网回归等正则化回归方法中，归一化选择如何通过特征的类别平衡（ones的比例）直接影响回归系数。本文特别强调了归一化与正则化方法组合使用的相互作用效应，并提出了通过特征或惩罚权重缩放来平衡这一效应的具体方法。", "conclusion": "对于lasso和岭回归，通过特征的方差或标准差进行归一化能减轻类别平衡对回归系数的影响，但这会导致系数估计的方差增加。对于弹性网回归，通过调整惩罚权重的标准化能实现相同的效果。此外，本文还初步探讨了如何在包含二元和正常特征的混合情景下以及交互效应的情况下进行特征归一化的方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.08589", "html_url": "https://arxiv.org/abs/2412.08589", "title": "SPACE-SUIT：基于人工智能的色球特征提取和分类器", "title_en": "SPACE-SUIT: An Artificial Intelligence Based Chromospheric Feature Extractor and Classifier for SUIT", "authors": "Pranava Seth,Vishal Upendran,Megha Anand,Janmejoy Sarkar,Soumya Roy,Priyadarshan Chaki,Pratyay Chowdhury,Borishan Ghosh,Durgesh Tripathi", "background": "SUIT载荷坐落在Aditya-L1望远镜上，主要用于观测太阳光球和色球结构。为了深入理解色球和光球形态结构的等离子体和热动力学性质，需要进行大量样本的统计研究，因此开发自动化特征检测方法是必要的。为实现这一目标，研究人员开发了名为SPACE-SUIT的特征检测算法，该算法使用增强视觉技术来识别和分类从SUIT Mg II k滤镜观测到的太阳色球特征，如斑点区域、日珥和背日结构。SPACE采用YOLO神经网络模型识别感兴趣区域，并通过预测比对信标提供的模拟SUIT图像和实际SUIT数据集来训练和验证该算法。研究表明，该算法在验证集上的精度为0.788，召回率为0.863，平均精度为0.874。研究还进一步通过统计测量和Tamura特征来验证探测区域的有效性。", "innovation": "研究人员开发了一种名为SPACE-SUIT的算法，能够使用增强视觉技术来自动识别和分类从SUIT观察到的色球特征，包括斑点区域、日珥和背日结构。该算法采用了YOLO神经网络模型来识别感兴趣区域，并通过模拟SUIT图像和实际SUIT数据集来训练和验证。此外，研究还验证了统计指标和Tamura特征在区分色球特征方面的有效性，提供了独立验证未来检测方案的可能性。", "conclusion": "研究不仅开发了一个色球特征提取器，还展示了统计指标和Tamura特征的有效性，这些方法能独立验证未来的检测方案。在没有标注真实地面真是值的情况下，SPACE算法预测的检测区域能够准确地反映特征的差异，并与实际SUIT观测图像一致。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08496", "html_url": "https://arxiv.org/abs/2501.08496", "title": "量化下游模型性能中数据对齐的重要性", "title_en": "Quantifying the Importance of Data Alignment in Downstream Model Performance", "authors": "Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo", "background": "传统上，人们强调数据集的大小对于训练强大语言模型（LLMs）的重要性，而忽视了数据对齐——数据质量的一个未被足够重视的方面——的作用。本文通过使用基于Task2Vec的数据对齐系数来研究数据对齐如何影响下游性能，这是一种量化的数据集相似性衡量标准。作者通过控制实验，分别研究了预训练数据和评估数据之间的对齐系数、以及领域特定微调数据和评估数据间的对齐系数，以考察其对下游任务性能的影响。他们在特定任务，即Autoformalization（自然语言与代码之间的机器翻译，用于形式验证）中进行了研究。", "innovation": "本文的研究创新在于，作者提出了一种基于Task2Vec的定量方法来衡量数据对齐对下游性能的影响。通过实验发现，在不同的场景中，模型的训练数据和评估数据之间的对齐系数越高，模型在下游任务上的损失/困惑度表现越差。这表明数据对齐对于模型性能的重要性可能超过了数据量的大小，特别是在像自动形式化这样的专业化下游任务中。", "conclusion": "研究结果表明，对于语言模型的训练方法需要重新评估，数据对齐相比数据量，在特定的下游任务中显得更为关键。这对于后续的语言模型训练策略和优化具有重要意义，特别是在需要高度精确和专业化任务的情况下。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.04614", "html_url": "https://arxiv.org/abs/2501.04614", "title": "XGeM: 一种用于多模态医学数据生成的多提示基础模型", "title_en": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation", "authors": "Daniele Molino,Francesco Di Feola,Eliodoro Faiella,Deborah Fazzini,Domiziana Santucci,Linlin Shen,Valerio Guarrasi,Paolo Soda", "background": "人工智能够在医学影像中的应用前景广阔，但数据稀缺、隐私问题和多模态集成的需要仍然限制了其发展。虽然生成模型的进步使得高质量的合成数据生成成为可能，但现有方法通常局限于单一模态或单向合成，缺乏同时合成多个模态并保持临床一致性的能力。为解决这一挑战，本文提出了XGeM，这是一种具有6.77亿参数的多模态生成模型，能够灵活地在医疗数据模态之间进行任意到任意的合成。", "innovation": "XGeM模型通过对比学习构建了一个共享的潜在空间，并引入了一种新颖的多提示训练策略，能够对输入模态中的任意子集进行条件设置，确保生成内容在语义和结构上的一致性。这种方法使得模型能够适应异质的临床输入并生成多个输出。本文对XGeM进行了广泛的验证，包括与五个竞争对手在MIMIC-CXR数据集上的基准测试、专家放射科医生进行的视觉图灵测试，以及展示了其在匿名化、类别不平衡和数据稀缺等医学数据挑战中的应用。", "conclusion": "本文验证了XGeM在多模态医学数据生成方面的有效性，证明它可以作为医学数据合成的基础模型，支持包括匿名化、类别不平衡和数据稀缺等多种医学数据挑战。项目页面为：this https URL。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04174", "html_url": "https://arxiv.org/abs/2503.04174", "title": "UniNet：网络安全性中的统一多层次流量建模框架", "title_en": "UniNet: A Unified Multi-granular Traffic Modeling Framework for Network Security", "authors": "Binghui Wu,Dinil Mon Divakaran,Mohan Gurusamy", "background": "随着现代网络日益复杂，受到多种设备、加密协议和不断演变的安全威胁的影响，网络流量分析变得至关重要。现有的机器学习模型通常只依赖于数据包或流的单一表示形式，这限制了它们捕捉用于稳健分析所需上下文关系的能力。此外，针对监督学习、半监督学习和无监督学习的具体架构导致在适应不同数据格式和安全任务方面效率低下。", "innovation": "我们提出了一种统一体系结构UniNet，它引入了一种新颖的多层次流量表示（T-Matrix），它将会话、流和数据包级别的特征综合起来，以提供全面的上下文信息。结合T-Attent，一种轻量级的基于注意力的模型，UniNet能够高效地学习用于多种安全任务的潜在嵌入。通过广泛的评估发现，UniNet在四个关键的网络安全和隐私问题——异常检测、攻击分类、IoT设备识别和加密网站指纹识别——上显著优于现有的最先进技术，实现了更高的准确性、更低的误报率和更好的扩展性。", "conclusion": "通过解决单一层次模型的局限性和统一网络数据分析框架，UniNet为现代网络安全设立了新的基准。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07813", "html_url": "https://arxiv.org/abs/2503.07813", "title": "MaizeField3D：来自多样化群体的田间种植玉米的3D点云和程序模型数据集", "title_en": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel", "authors": "Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian", "background": "由于缺乏大规模和多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型工具的发展，特别是针对玉米，受到了限制。二维图像数据集无法捕捉到3D数据提供的关键结构细节，如叶片结构、植物体积和空间布局。现有的2D数据集限制了准确评估植物表型的能力，因此急需高质量的3D植物数据集来改善这一现状。", "innovation": "本文介绍了MaizeField3D，这是一个由多样遗传群体收集的田间种植的玉米3D点云数据集，旨在为农业研究做好AI准备。MaizeField3D包含了1045个高质量的田间种植玉米的3D点云，使用了地面激光扫描仪（TLS）进行收集。520个植物的点云进行了分割和标注，以分离单个叶片和茎部，并确保所有样本的一致性标注。数据集还包含描述植物形态和质量的元数据，以及不同分辨率的点云子数据集，可用于各种下游计算任务。", "conclusion": "MaizeField3D将作为全面的AI驱动表型、植物结构分析和农业研究中3D应用的基础数据集。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03383", "html_url": "https://arxiv.org/abs/2501.03383", "title": "人工科学家——流式 plasma 模拟中的机器学习", "title_en": "The Artificial Scientist -- in-transit Machine Learning of Plasma Simulations", "authors": "Jeffrey Kelling,Vicente Bolea,Michael Bussmann,Ankush Checkervarty,Alexander Debus,Jan Ebert,Greg Eisenhauer,Vineeth Gutta,Stefan Kesselheim,Scott Klasky,Vedhas Pandit,Richard Pausch,Norbert Podhorszki,Franz Poschel,David Rogers,Jeyhun Rustamov,Steve Schmerler,Ulrich Schramm,Klaus Steiniger,Rene Widera,Anna Willmann,Sunita Chandrasekaran", "background": "高性能计算（HPC）集群的规模增大以及大规模模拟产生的庞大数据量，引发了分析中的输入输出（IO）和存储挑战。特别是深度学习技术大量利用这类领域的数据来提取有助于科学理解的模式。现有的工作流程中，数据通常需要通过文件系统进行处理，这造成了瓶颈。为了克服这些挑战，作者提出了一种新的流式工作流程，数据在传输过程中直接被机器学习框架利用，从而绕过了文件系统的限制。这种方法旨在通过流式传输直接对模型进行训练，并在数据传输过程中对其进行转换，无需在数据准备和处理之间产生延迟。此外，这种方法可以使用常见的编程语言执行数据操作，使应用程序用户无需修改数据输出程序。该研究选择使用 GPU 加速的粒子在单元模型（PIConGPU）进行 Kelvin-Helmoltz 波动（KHI）的模拟，以演示该方法的应用。", "innovation": "该研究提出了一种新的流式工作流程，其中模拟数据在传输过程中直接被机器学习框架利用并进行转换。这种“人工科学家”的方法能够直接在数据传输过程中进行模型训练，无需经过文件系统的处理。该方法使用常见的编程语言执行数据操作，简化了应用用户的流程，并且能够通过经验重放方法避免学习过程中出现灾难性遗忘问题，实现模型在非稳态过程的连续学习。该方法已经在 Frontier 极限系统中进行了移植和扩展，以应对更大的数据量和更高的性能需求。", "conclusion": "该研究成功地展示了如何通过一个“人工科学家”的流式方法为非稳态湍流模拟数据流式机器学习。这种新方法解决了传统 HPC 模拟数据处理中存在的瓶颈，并且通过使用常见的编程语言简化了流程。该方法在 Frontier 极限系统中取得了成功，证明了其在更大规模实验中的潜力。未来的研究可以进一步优化这种方法，并探索它在其他科学领域的应用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.17772", "html_url": "https://arxiv.org/abs/2501.17772", "title": "通过自监督正样本采样的 speaker 验证自监督框架", "title_en": "Self-Supervised Frameworks for Speaker Verification via Bootstrapped Positive Sampling", "authors": "Theo Lepage,Reda Dehak", "background": "近期，自我监督学习（SSL）在 speaker 验证（SV）中的应用展示出显著的潜力，然而，要缩小其与监督系统在性能上的差距仍然具有挑战性。现有的 SSL 框架依赖于来自同一音频片段的锚正样本对，这导致了正样本的特征与锚样本高度相似，即使经过大量数据增强的方法，这一特征限制仍存在于所学的表示中。因此，传统的正样本选择策略被证明是具有局限性的，因为它在所学习的表示中包含了过量的关于录音源的信息。", "innovation": "本文提出了自我监督正样本采样（SSPS），一种用于自监督学习（SSL）框架中的 bootstrap 技术，以选择更适合且多样化的正样本。SSPS 假设在表示空间中接近锚样本的伪正样本属于同一讲话人身份，但对应不同的录音条件。将 SSPS 应用到主要的 SSL 框架时，包括 SimCLR、SwAV、VICReg 和 DINO，可一致提高 SV 的性能。使用 SSPS，SimCLR 和 DINO 在 VoxCeleb1-O 上分别达到了 2.57% 和 2.53% 的 EER，其中 SimCLR 较之前的 EER 值实现了 58% 的相对减少，展现出更为简化的训练方法即可获得接近 DINO 的性能。此外，SSPS 还降低了讲话者表示内的类内方差，减少了话者表示中的信道信息，在没有数据增强的情况下表现出更强的鲁棒性。", "conclusion": "SSPS 方法显著地改进了基于 SSL 的 SV 性能，特别是在所应用的几个主要 SSL 框架中，而且这种提升不仅体现在 EER 的数值上，还通过简化训练过程而表现出对多变条件的鲁棒性提升。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08061", "html_url": "https://arxiv.org/abs/2503.08061", "title": "ForceGrip: 无参考的课程学习方法在VR手部操作中的参考自由握力控制", "title_en": "ForceGrip: Reference-Free Curriculum Learning for Realistic Grip Force Control in VR Hand Manipulation", "authors": "DongHeun Han,Byungmin Kim,RoUn Lee,KyeongMin Kim,Hyoseok Hwang,HyeongYeop Kang", "background": "在沉浸式虚拟现实（VR）中，实际的手部操作是一个关键组件，但现有的方法往往依赖于基于运动捕捉的数据集，这些数据集忽略了如接触力和手指扭矩等关键物理属性。这导致现有方法更注重紧致的一刀切式抓握，而不是反映用户的力意图。本文提出了一个基于深度学习的ForceGrip代理，用于合成现实的手部操作动作，反映用户的抓握力意图。而不是模拟预定义的运动数据集，ForceGrip 通过随机化对象形状、手腕运动和触发输入流，挑战代理完成广泛的物理交互。", "innovation": "ForceGrip 使用了一个三阶段的课程学习框架，包括手指定位、意图适应和动态稳定化，使得代理能够逐步学习复杂的任务。此外，还使用了接近奖励函数来促进自然手指动作并加速训练收敛。实证评估显示，ForceGrip 在力控制和合理性方面优于现有的最先进的方法。", "conclusion": "定量和定性的评估表明，ForceGrip 在力控制和合理性方面均优于最先进的方法。演示视频作为补充材料提供，代码在此网址：this https URL."}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16095", "html_url": "https://arxiv.org/abs/2502.16095", "title": "在基于变换器的遥感图像说明中的良好表示，更好的解释：卷积神经网络的作用", "title_en": "Good Representation, Better Explanation: Role of Convolutional Neural Networks in Transformer-Based Remote Sensing Image Captioning", "authors": "Swadhin Das,Saarthak Gupta,Kamal Kumar,Raksha Sharma", "background": "遥感图像说明（RSIC）是指从遥感图像中生成有意义描述的过程。近年来，此类方法引起了广泛关注，编码器-解码器模型成为生成有意义描述的核心。编码器从输入图像中提取关键视觉特征，将其转换为紧凑表示。解码器利用此表示来生成连贯的文本描述。虽然基于变换器的模型由于其捕捉远程依赖和上下文信息的能力而日益受到关注，解码器已被广泛研究，而编码器的研究仍未充分展开。然而，优化编码器的关键性不容忽视，因为它直接影响特征的丰富度，这反过来又影响生成描述的质量。为了解决这个问题，本研究系统性地评估了十二种不同的卷积神经网络（CNN）架构在变换器体系结构下的效果，以评估这些架构在RSIC中的有效性。评估分为两个阶段：首先，根据性能对CNN进行数值分析，将其分为不同的类别；性能最好的CNN随后将从人类视角进行人工评估。此外，研究还分析了不同的搜索策略，即贪婪搜索和束搜索，以确保最佳的描述。结果显示，编码器的选择在提高说明性能方面具有关键作用，特定的CNN架构明显提高了生成的描述质量，特别是在遥感图像中的应用。通过对多种编码器的详细比较，本研究为基于变换器的图像说明模型的进步提供了宝贵的见解。", "innovation": "本研究首次系统地分析了十二种不同的卷积神经网络架构在基于变换器的遥感图像说明中的效果，强调了编码器选择的重要性，并展示了特定CNN架构如何显著提高生成的描述质量。本研究通过引入人类评估和不同搜索策略的分析，为优化基于变换器的图像说明模型提供了指导。", "conclusion": "编码器选择对于提高生成说明的质量至关重要。特定的CNN架构能够显著提高生成遥感图像描述的质量。本研究通过详细的比较和分析为基于变换器的图像说明模型的进步提供了重要的指导。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03299", "html_url": "https://arxiv.org/abs/2504.03299", "title": "基于位置-姿态对之间的全局不变量集合", "title_en": "Universal Collection of Euclidean Invariants between Pairs of Position-Orientations", "authors": "Gijs Bellaard,Bart M. N. Smets,Remco Duits", "background": "在基于位置-姿态空间M(3)上的欧几里得E(3)对称神经网络中，应用于分子动力学预测和属性计算等任务。执行类似卷积的操作需要在M(3) x M(3)上具有欧几里得不变性的核。通常，通过手动选择一集不变量并将其喂入多层感知器来参数化这些核。但选择的不变量集合往往缺乏有效性或适用性，并且在实际应用中局限性强。因此，亟需一种高度通用且独立的不变量集合，以提升网络性能.", "innovation": "本文严格描述了M(3) x M(3)上的最优、全局无关且普遍适用的4个平滑标量不变量集合。与传统方法不同，我们的方法提供了两个不变量集合，一个完全通用，另一个不完全通用，二者均在PONITA神经网络架构下进行了评估。实验结果表明，使用完全通用的不变量集合显著提升了PONITA的预测精度，这证明了我们方法的有效性.", "conclusion": "研究证明，在M(3) x M(3)空间上应用4个最优、全局无关且普遍适用的不变量集合可以显著提升基于位置-姿态的神经网络的性能。未来可以进一步扩展这种方法的应用范围，以解决更多领域中的复杂问题。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03309", "html_url": "https://arxiv.org/abs/2504.03309", "title": "位置-取向空间上的刚体变换不变度量", "title_en": "Roto-Translation Invariant Metrics on Position-Orientation Space", "authors": "Gijs Bellaard,Bart M. N. Smets", "background": "在图像分析任务中，位置-取向空间M(3)上的刚体变换群SE(3)不变的黎曼度量起着关键作用，这些度量使得刚体变换不变的算法得以实施，常用于增强、降噪和分割任务。然而，计算黎曼距离较为昂贵，不适合需要常重组计算的情况。现有的方法不提供有效的替代方案，因此需要一种更实用的方法来替代现有的黎曼距离计算方法，从而提高计算效率并满足实际应用的需求。文中主要探讨了位置-取向空间上的刚体变换不变度量的问题背景，并指出现有方法的局限性，提出了最小角速度（mav）距离作为一种实用的替代方案，能提供更高的计算效率，同时适用于深度学习框架中需要刚体不变性的神经网络结构，如PONITA模型。", "innovation": "本文的主要创新点在于提出了最小角速度（mav）距离，这是一种适用于位置-取向空间M(3)上的刚体变换群SE(3)不变的度量方法。最小角速度距离将黎曼长度与几何意义上有意义的曲线相结合，作为一种可训练的不变量指标，其参数可用于度量黎曼度量的计算且可以作为可学习的权重。尤其是最小角速度距离可以替换现有的黎曼距离方法，在位置-取向空间M(3)上的刚体变换不变度量分类和参数化，在这种度量的基础上提出了一种高效的计算方法，并且探索了将最小角速度距离纳入PONITA模型中以提高其预测分子属性准确性的问题和方案。", "conclusion": "通过分类和参数化位置-取向空间M(3)上的所有刚体变换群SE(3)不变的度量，以及提出了一种高效的最小角速度（mav）距离计算方法，本文证明了在刚体变换不变的任务中，最小角速度距离作为一种替代方案可以有效提高算法效率和预测准确性。通过实验证明，最小角速度距离可以在PONITA模型中应用以提高分子属性预测的精度。该研究为进一步优化和改进深度学习框架提供了新的思路和方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨语言旅行：多模态大语言模型跨语言一致性的基准测试", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "随着多模态大语言模型（MLLMs）的迅速发展，它们在实际应用中的表现显著提升。但是，跨语言保持一致性能，尤其是在整合文化知识时，仍然面临巨大挑战。为了更好地评估这一问题，我们提出了两个新的基准测试：KnowRecall和VisRecall，用于评估MLLMs的跨语言一致性。KnowRecall是一个视觉问答基准测试，旨在衡量15种语言中的事实知识一致性，重点考察关于全球著名地标的文化和历史问题。VisRecall则通过要求模型在不提供图片的情况下描述9种语言中的地标外观，来评估视觉记忆的一致性。实验结果显示，最先进的MLLMs，包括专有的模型，仍然难以实现跨语言一致性，这表明需要更加健壮的方法来生成真正的多语言和文化意识模型。", "innovation": "本文介绍了两个新的跨语言一致性基准测试：KnowRecall和VisRecall，分别用于评估视觉问答中的事实知识一致性和视觉记忆一致性。该研究强调了现有的顶级多模态大语言模型在跨语言一致性方面仍存在的差距，提出了未来工作需要更好地理解和模仿实际语言使用中的文化知识集成需求。", "conclusion": "现有的顶级多模态大语言模型在跨语言一致性方面仍有挑战，需要开发更加健壮的方法来确保多语言和文化意识模型。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17046", "html_url": "https://arxiv.org/abs/2503.17046", "title": "HAPI: 一种从人类偏好学习机器人面部表情的模型", "title_en": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences", "authors": "Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida", "background": "自动机器人面部表情生成对于人机交互至关重要，但基于固定关节配置的手工方法往往产生僵硬和不自然的行为。尽管最近的自动技术减少了手动调优的需求，但它们往往因未能充分弥合人类偏好和模型预测之间的差距而无法展现细致且真实的表情。这主要是因为有限的自由度和不足的感知整合。因此，本研究旨在通过利用人类反馈，提出一种新的学习排序框架，以增强机器人的表情表达能力。具体来说，我们进行了成对比较标注以收集人类偏好的数据，并开发了基于Siamese RankNet的人类情感成对印象（HAPI）模型，这是一种细化表情评估的方法。我们通过贝叶斯优化和在线表情调查，在35-DOF的类人平台上得到了有效的结果，证明了我们的方法能产生比基线和专家设计方法更为真实且社会共鸣的愤怒、快乐和惊奇等表情。这表明我们的框架有效地将人类偏好与模型预测之间的差距桥接起来，同时稳健地将机器人表情生成与人类情感反应对齐", "innovation": "提出了利用人类反馈的学习排序框架，通过Siamese RankNet开发了HAPI模型，该模型可以细化表情评估，从而增强机器人的表情表达能力。研究通过贝叶斯优化和在线表情调查在35自由度（DOF）的类人平台上展示了HAPI的优势，证明了该方法能产生更真实且社会共鸣的表情，有效弥合了人机交互中的差距", "conclusion": "本研究通过一个基于研究框架的HAPI模型成功增强了机器人面部表情的真实性和社会共鸣性，解决了传统方法中表达不足的问题，该模型能更有效地模拟人类情感反应，从而实现更真实的人机交互。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.00494", "html_url": "https://arxiv.org/abs/2504.00494", "title": "Lie群上的Flow Matching", "title_en": "Flow Matching on Lie Groups", "authors": "Finn M. Sherry,Bart M.N. Smets", "background": "Flow Matching (FM) 是一种最近的生成建模技术，其目标是从易于采样的分布 $\boldsymbol{\textbf{X}}_0$ 生成分布 $\boldsymbol{\textbf{X}}_1$ 的样本。传统方法利用条件可定义在欧几里得空间中的直线段，但这种方法仅适用于欧几里得空间。Chen 和 Lipman 提出了扩展该方法，使其可以在黎曼流形上进行，用测地线或其谱近似来替代直线段。本文提出了不同视角：通过用指数曲线取代直线段在黎曼流形上的应用，将该方法推广到黎群上的应用。这种方法可以简化和快速实现许多矩阵黎群上的流匹配，因为所需的黎群操作（乘积、逆、指数、对数）可以直接通过相应的矩阵操作来获得。该方法可以用于具有一组特征（在 $\boldsymbol{\textbf{R}}^n$ 中）和姿态（在某个黎群中）的数据生成建模，例如对称性神经场的潜在代码（Wessels et al. 2025）.", "innovation": "本文提供了一种不同于直线段的新视角，称为黎群上的Flow Matching，用指数曲线替代直线段，这种方法在多个矩阵黎群上实施起来更加简单和快速，适合具有特征和姿态的数据生成模型。通过这种方法可以对各种数据进行生成建模，比如具有特征和姿态的数据集，即Equivariant Neural Fields的潜在编码数据等。", "conclusion": "本文通过黎群的应用，提出了一个新的Flow Matching方法，该方法提供了对多种矩阵黎群上的简单且快速的实现。使用该方法可以更方便地对特征和姿态的数据集进行生成建模，尤其适合对称性神经场的潜在代码等数据的应用场景。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13112", "html_url": "https://arxiv.org/abs/2505.13112", "title": "基于注意力的聚类", "title_en": "Attention-based clustering", "authors": "Rodrigo Maulen-Soto(SU, LPSM (UMR\\_8001)),Claire Boyer(IUF),Pierre Marion(EPFL)", "background": "transformers作为一种强大的神经网络架构，能够应对广泛的学习任务。本文对该模型在无监督设置下自动从数据中提取结构的能力进行了理论分析，特别是在输入数据来自高斯混合模型时，探讨了其聚类适用性。", "innovation": "研究了一个简化的双头注意力层，并定义了一个基于非标记数据最小化的群体风险，这使得层参数与真实的混合中心对齐，展示了基于注意力的层捕获潜在分布结构的能力。此外，研究了一个固定键、查询和值矩阵为单位矩阵的注意力层，在没有可训练参数的情况下，它们也可以进行上下文量化，揭示了基于变压器的方法能动态适应输入特定分布的惊人能力。", "conclusion": "本文展示了基于注意力的模型在无监督聚类中的潜力，并探讨了它们通过固定矩阵来灵活适应特定输入分布的能力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.20808", "html_url": "https://arxiv.org/abs/2504.20808", "title": "SoccerDiffusion：从比赛录像中学习端到端类人机器人足球", "title_en": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings", "authors": "Florian Vahl,Jörn Griepenburg,Jan Gutsche,Jasper Güldenstein,Jianwei Zhang", "background": "本文介绍了SoccerDiffusion，一种基于变压器的扩散模型，旨在直接从真实世界的比赛录像中学习类人机器人足球的端到端控制策略。该模型使用来自RoboCup比赛的数据，从多模态传感器输入（包括视觉、本体感受和比赛状态）中预测关节命令轨迹。尽管高级战术行为仍有局限性，但本文为后续强化学习或偏好优化方法提供了坚实的基础。", "innovation": "1. 直接从真实世界比赛录像中学习控制策略，而不仅仅是从合成数据或预编程比赛环境中学习。\n2. 使用蒸馏技术，在嵌入式平台上实现实时推理，简化多步扩散过程为单一步骤。\n3. 成功复制复杂运动行为（如行走、踢球和跌倒恢复），并在模拟和物理机器人上进行了验证。", "conclusion": "本文的成果表明，SoccerDiffusion模型能够在模拟和实际机器人中再现复杂的运动行为，并为后续的强化学习或偏好优化方法奠定了基础。该研究提供了数据集、预训练模型和代码供其他研究人员使用。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12552", "html_url": "https://arxiv.org/abs/2504.12552", "title": "使用数字孪生进行隐私保护的手术室工作流程分析", "title_en": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins", "authors": "Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath", "background": "手术室（OR）是一个复杂的工作环境，优化工作流程对于减少成本和改善患者结果至关重要。自动识别围手术期事件的计算机视觉方法虽然可以识别出手术室优化的瓶颈，但由于隐私问题限制了使用手术室视频进行自动事件检测。本研究提出了一个两阶段的隐私保护手术室视频分析和事件检测管道，通过这种方法，可以实现隐私保护下的手术室工作流程分析，有利于机构间共享去标识化的数据，并可能通过降低特定领域外观差异来增强模型泛化能力。", "innovation": "本研究提出了一种两阶段的隐私保护手术室视频分析管道，包括利用计算机视觉基础模型进行深度估计和语义分割生成去标识化的数字孪生（DT）以及使用SafeOR模型进行手术室事件检测。这种方法在内部38次模拟手术试验的数据集上表现良好，精度与直接使用原始RGB视频的方法相当或更好，且通过生成数字孪生模型，实现了隐私保护下的手术室工作流程分析，促进了数据的机构间共享并增强了模型的泛化能力。", "conclusion": "数字孪生技术使得手术室工作流程分析能够在保持隐私的同时，实现去标识化数据的共享，并通过减少特定领域外观差异来提高模型泛化能力。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22502", "html_url": "https://arxiv.org/abs/2505.22502", "title": "评估高斯过程回归的量子优越性", "title_en": "Assessing Quantum Advantage for Gaussian Process Regression", "authors": "Dominic Lowe,M.S. Kim,Roberto Bondesan", "background": "高斯过程回归是一种广为人知的机器学习技术，已有多种量子算法被提出。作者展示了在宽泛的数据和核函数假设下，这些量子算法在许多场景中并不显示指数级的加速。这一结果通过证明核矩阵的条件数在矩阵尺寸增大时至少按线性比例增加来得到。此外，还证明该矩阵的稀疏性和Frobenius范数在类似假设下按线性比例变化。这些结论独立于经典数据加载到量子计算机的复杂性，并适用于去量子化的算法。", "innovation": "论文通过严格的数学证明展示了高斯过程回归中量子算法可能不会显示指数级加速的新见解，不仅验证了量子算法的理论局限性，同时也对数据加载和去量子化算法的应用进行了相关讨论，为其未来发展提供了指导", "conclusion": "该研究的结果表明，高斯过程回归中的量子算法不一定能带来指数级加速，这一结论适用于所有可能的场景，证明了量子算法的性能可能并不如预期，同时也为后续研究提供了理论依据，表明未来应寻找其他具有潜在量子优越性的机器学习任务。在数值验证中，针对流行核函数展示了忽略量子加速的可能性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02825", "html_url": "https://arxiv.org/abs/2506.02825", "title": "在无边关联情形下的渐进完美种子图匹配（及应用到推理）", "title_en": "Asymptotically perfect seeded graph matching without edge correlation (and applications to inference)", "authors": "Tong Qi,Vera Andersson,Peter Viechnicki,Vince Lyzinski", "background": "该研究针对$d$维随机点积图（RDPG）中多重图匹配的问题。现有方法通常需要在图之间存在边关联的前提下才具有良好的性能，但在实际应用中，这种边关联可能并不存在。作者在这种无边关联的条件下，探索如何高效地进行多重图匹配，并证明了所提出的算法在多种模拟和假设检验场景下的有效性。", "innovation": "该研究提出了OmniMatch算法，该算法能够在无边关联的条件下，使用少量种子节点（$s$个）近乎完美地匹配$O(s^{\beta})$个无种子节点，其中$\beta<2\bigwedge d/4$。这一方法不仅在理论上证明了在无边关联条件下进行图匹配的可能性，还展示了该算法在各种实验和假设检验中的应用能力，特别是在纠正顶点错位以恢复假设检验能力方面表现出色。", "conclusion": "研究证明OmniMatch算法在无边关联的多重网络中具有高效的图匹配能力，即使在网络之间存在结构错位的情况下，仍能最大程度地恢复假设检验的效能。该方法在神经影像学（连接组学）和机器翻译的数据实例中也表现出良好的应用前景。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03764", "html_url": "https://arxiv.org/abs/2506.03764", "title": "矩形实矩阵高阶奇异值导数", "title_en": "Higher-Order Singular-Value Derivatives of Rectangular Real Matrices", "authors": "Róisín Luo,James McDermott,Colm O'Riordan", "background": "高阶奇异值导数的闭形式表达是通过标准矩阵分析技术非常具有挑战性的，本文通过利用Kato的自伴算子解析扰动理论中的减少余反演算子，提出了一个理论框架，来推导实矩形矩阵中奇异值的一般第n阶弗雷歇导数。通过将矩形矩阵视为有限维希尔伯特空间上的紧算子，并嵌入为一个块自伴算子，以捕获非对称扰动，结合Kato的渐近特征值展开，获得了无穷小第n阶谱变化的一般闭形式表达式。", "innovation": "通过结合抽象算子理论扰动和矩阵，本文框架为在随机矩阵应用（例如深度学习中的对抗性扰动）中的高阶光谱灵敏度研究提供了实用工具。特别地，将方法专用于n=2并基于矩阵表示应用Kronecker积表示，得出以往未见的奇异值Hessian表达式。", "conclusion": "本文框架为高阶奇异值导数提供了一般、闭形式的表达式，并且对于矩阵分析中有实际应用的重要方向，例如随机矩阵应用中的高阶谱灵敏度研究，提供了新的工具。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22675", "html_url": "https://arxiv.org/abs/2506.22675", "title": "多环境数据的贝叶斯不变性建模", "title_en": "Bayesian Invariance Modeling of Multi-Environment Data", "authors": "Luhuan Wu,Mingzhang Yin,Yixin Wang,John P. Cunningham,David M. Blei", "background": "该文章探讨了利用来自多个环境的数据预测不变特征的问题。以前的方法主要通过假设测试或正则化优化来解决这个问题。作者旨在通过贝叶斯不变预测（BIP）模型提供一种概率建模方法，该模型能有效地识别具有稳定预测关系的不变特征，这些特征对于新环境的推广和因果机制的揭示至关重要。", "innovation": "文章提出了贝叶斯不变预测（BIP）这一新的概率模型，将不变特征的索引作为潜在变量并通过后验推断来恢复。文章通过证明BIP后验能够针对真正的不变特征以及更大的环境异质性会导致后验收缩加速来展示其有效性。为了处理多个特征，文章还设计了一种高效的变分近似（VI-BIP）。在模拟和实际数据中，BIP和VI-BIP的表现证明了它们比现有方法更具准确性和可扩展性", "conclusion": "研究证明了BIP和VI-BIP模型在不变特征预测上的优越性，并且能够有效地应用于多环境数据中，为识别并解释跨环境条件下的稳定因果机制提供了一种新的方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18959", "html_url": "https://arxiv.org/abs/2506.18959", "title": "从网页搜索到具备推理能力的深度研究：以推理代理激励搜索", "title_en": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "authors": "Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu", "background": "信息检索是现代知识获取的基础，每天处理来自不同领域的数十亿查询。然而，传统的基于关键词的搜索引擎越来越难以满足复杂的、多步骤的信息需求。现有搜索引擎主要依靠静态网页搜索技术，这些技术在处理复杂的查询需求时显得不足。", "innovation": "本文提出了一个名为‘具备推理能力的深度研究’的新范式，利用大型语言模型（LLMs）的推理和自主能力，实现自主推理、迭代检索和信息合成的一体化。文中还引入了测试时的可扩展性定律，以量化计算深度对推理和搜索的影响。并通过基准测试结果和开源实现，展示‘具备推理能力的深度研究’不仅在性能上显著优于现有方法，而且有望成为未来信息获取的主要范式。", "conclusion": "本文系统地介绍了从静态网页搜索到具备推理和自主能力的动态反馈循环系统的发展演变，提出了激励搜索的新方法，并通过一系列实验证明了其有效性。所有相关的资源，包括行业产品、研究论文、基准数据集和开源实现已全部公开。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09993", "html_url": "https://arxiv.org/abs/2506.09993", "title": "基于扩散模型的知文字信息图像修复", "title_en": "Text-Aware Image Restoration with Diffusion Models", "authors": "Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim", "background": "图像恢复的目标是恢复受损图像，尽管现有的基于扩散的方法在自然图像恢复方面取得了极大的成功，但在恢复受损图像中的文本区域时，这些方法常常难以忠实重建。它们常常生成合理但错误的文本样式的图案，我们将其称为文本图像错觉。因此需要一种新的图像恢复任务，能同时恢复视觉内容和文本保真度，并提出了一种大规模的基准数据集和一种结合内部分特征的多任务扩散框架，该框架能够将扩散模型的内部特征整合到文本检测模块中，实现两者的联合训练。", "innovation": "提出了一种新的图像恢复任务，名为‘知文字信息图像恢复’（TAIR），并设计了一个大规模的数据集SA-Text，包含10万个高质量场景图像和多样复杂的文本实例。此外，提出了一个结合内部特征的多任务扩散框架TeReDiff，该框架将扩散模型内部特征融合到文本检测模块中，通过联合训练实现特征与文本检测模块的相互促进，从而提取丰富的文本表示，作为去噪步骤中的提示。", "conclusion": "实验证明，该方法在文本识别准确性上显著优于现有最先进的图像恢复方法。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15854", "html_url": "https://arxiv.org/abs/2506.15854", "title": "通过视觉到文本转换保护Connected and Autonomous Vehicles中的隐私", "title_en": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation", "authors": "Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy", "background": "Connected and Autonomous Vehicles (CAVs) 使用的各种设备通常处理隐私敏感数据，其中，路边单元通过具备人工智能设备（AIE）的摄像头进行诸如违规检测等应用时发挥着关键作用。然而，捕捉到的图像数据带来的隐私风险依然存在，因为这些数据可能被滥用，用于身份盗窃、特征分析或未经授权的商业用途。传统的隐私保护方法，例如面部模糊化和遮盖，虽然能减轻部分隐私风险，但个人隐私仍然面临风险，因为个体仍然可以通过其他特征（如穿着）被跟踪。因此，为了更好地保护隐私，本文提出了一种新颖的基于反馈的强化学习和视觉语言模型的隐私保护框架，通过将图像转换为语义上等效的文本描述来实现视觉隐私保护，同时保留场景相关信息。", "innovation": "本文提出了一种基于反馈的强化学习（RL）和视觉语言模型（VLMs）的隐私保护框架，该框架能够将图像转换为语义上等效的文本描述，从而在保障视觉隐私的同时保留场景相关信息，实现敏感视觉信息的保护。该框架采用层次化策略迭代优化生成的文本，提高了语义准确性和隐私保护水平。评估结果表明，与现有方法相比，文本的独特词汇计数（Unique Word Count）提高了约77%，细节密度（Detail Density）提高了约50%。", "conclusion": "实验结果证明了该隐私保护框架在隐私保护和文本质量方面的显著改进，通过将视觉信息转换为文本描述，能够在保护隐私的同时保持信息的语义准确性。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23351", "html_url": "https://arxiv.org/abs/2506.23351", "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "title_en": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "authors": "Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yu Chen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu", "background": "机器人领域中的嵌入式人工智能（Embodied AI）是一个新兴的前沿领域，旨在开发能够感知、推理并在复杂物理环境中行动的自主系统。单臂系统在执行特定任务时表现优异，但双臂协作系统对于处理涉及刚性、变形和触觉敏感对象的复杂任务至关重要。因此，需要通过适当的比赛挑战来推动双臂协作能力的发展。在2025年CVPR的MEIS Workshop上，启动了RoboTwin双臂协作挑战赛，旨在促进双臂协作处理方法的发展。", "innovation": "该研究表明，通过RoboTwin仿真平台（1.0和2.0）和AgileX COBOT-Magic机器人平台，组织了包含三个阶段的挑战赛（仿真阶段1、仿真阶段2和最终的现实世界阶段），总共涉及17项双臂操作任务，涵盖刚性、变形和基于触觉的场景。此次挑战赛吸引了来自全球的64个团队和超过400名参与者，其中SEMT和AnchorDP3等团队表现优异，这些结果对于研究双臂操作策略提供了有价值的见解，特别是双臂操作策略的学习方法。比赛结果和方法的分享将为未来相关研究提供支持。", "conclusion": "本次报告总结了挑战赛的设置、任务设计、评估方法及关键发现，并对未来的研究方向提出了建议，旨在促进双臂操作策略的健全性和泛化能力的研究。报告结果旨在支持未来在双臂操作策略方面更具稳健性和泛化能力的研究。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02068", "html_url": "https://arxiv.org/abs/2507.02068", "title": "软件工程候选人如何准备技术面试？", "title_en": "How do Software Engineering Candidates Prepare for Technical Interviews?", "authors": "Brian Bell,Teresa Thomas,Sang Won Lee,Chris Brown", "background": "应聘软件工程师需要通过技术面试，这是一种涉及候选人一边编写代码一边与面试官沟通的招聘流程。然而，技术面试的复杂性难以准备，且很少在计算机课程中涉及。因此，作者旨在了解候选人如何为技术面试做准备，探讨准备方法的效果以及教育的作用。通过对131名活跃准备技术面试的候选人的调查，研究发现候选人很少在真实环境中训练，课程对准备工作的支持不足，导致压力和准备不足的问题。", "innovation": "该研究通过调查真实参与技术面试准备的候选人，揭示了目前准备方法和教育支持的不足之处，为提高技术面试准备提供了依据和建议。这填补了现有研究在理解候选人实际准备技术面试过程以及现存教育支持的不足方面的空白。", "conclusion": "研究结果表明，候选人很少在真实环境中进行准备，且课程未能有效支持他们的准备工作，导致了压力和准备不足的问题。基于这些发现，作者为利益相关者提供了增强技术面试准备的建议，旨在改善软件工程角色寻求者的技术面试准备情况。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02110", "html_url": "https://arxiv.org/abs/2507.02110", "title": "Can Internal Software Metrics Predict App Popularity at Launch? Yeas! and Nays! ", "title_en": "Can Internal Software Metrics Predict App Popularity at Launch? Yeas! and Nays!", "authors": "Md Nahidul Islam Opu,Fatima Islam Mouri,Rick Kazman,Yuanfang Cai,Shaiful Chowdhury", "background": "研究如何在移动应用发布前预测其受欢迎程度对于开发者来说具有战略优势，特别是在竞争激烈的市场中。然而，这一问题仍然是一个具有挑战性的问题。本研究探讨内部软件度量是否可以在部署前，即从源代码中测量的可预测性指标，对于一种应用的受欢迎程度（通过用户评分和年下载量定义）有预测能力。研究使用446个开放源代码的Android应用数据集，并分析了多种特征来评估回归和分类模型的表现。", "innovation": "研究使用了回归和分类模型来评估预测移动应用受欢迎程度的能力，并发现通过重新定义成二元分类问题，内部代码度量可以显著提高预测结果。其中，使用投票集的多层感知机模型在F1分数上取得了0.72的最佳结果，这挑战了之前的研究认为内部度量无法预测软件质量的观点。", "conclusion": "尽管内部代码度量在解释能力上有限，但是它们可以作为应用受欢迎程度的有用指标。这表明内部度量可以作为预测应用受欢迎程度的有效工具，尽管它们在应用场景上的解释力有限，但可以提供重要的参考信息。"}
{"llm_update_time": "20250707", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01352", "html_url": "https://arxiv.org/abs/2507.01352", "title": "Skywork-Reward-V2：通过人机协同扩展偏好数据治理", "title_en": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "authors": "Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou", "background": "尽管奖励模型（RMs）在强化学习从人类反馈（RLHF）中扮演着关键角色，当前最先进的公开RMs在大多数现有评估基准上表现不佳，未能捕捉到人类微妙和复杂的偏好范围。即使引入了高级训练技术，也没有取得显著的性能提升。我们假设这种脆弱性主要源自缺乏完美数据集中的限制，数据集往往范围狭窄、合成标签或缺乏严格的质量控制。为了应对这些挑战，我们提出了一种包含4000万个偏好对的大规模偏好数据集，命名为SynPref-40M，并设计了一个混合了人类和AI的双重管道来规模化的数据治理，以弥补人类标注质量和AI可扩展性的优势。通过对这一偏好混合数据的训练，我们引入了Skywork-Reward-V2，包括8个从0.6B到8B参数的奖励模型，训练数据来自精心挑选的2600万个偏好对的子集。我们实验证明Skywork-Reward-V2在广泛能力范围内表现优秀，包括与人类偏好一致、客观正确性、安全性、风格偏见抵抗性和最佳N扩展，取得了在七个主要奖励模型基准上的领先性能。去解析性的研究表明，我们方法的有效性不仅源自数据规模，还来自高质量的数据治理。Skywork-Reward-V2系列在开放奖励模型领域取得了实质性的进步，展示了现有偏好数据集的未开发潜力，并展示了人机协同治理如何提高数据质量的重大意义。", "innovation": "提出了一种包含4000万个偏好对的大规模偏好数据集，命名为SynPref-40M，并设计了一个混合了人类和AI的双重管道来规模化的数据治理。通过对这一偏好混合数据的训练，引入了Skywork-Reward-V2，包括8个从0.6B到8B参数的奖励模型，实现了多种优异性能，在七个主要奖励模型基准上取得了领先。此外，实验证明方法的有效性不仅源自数据规模，还来自高质量的数据治理。", "conclusion": "Skywork-Reward-V2系列在开放奖励模型领域取得了实质性的进步，展示了现有偏好数据集的未开发潜力，并展示了人机协同治理如何提高数据质量的重大意义。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02118", "html_url": "https://arxiv.org/abs/2507.02118", "title": "编程中结合生理指标和自我报告仪器的多模态方法用于监测压力：方法论启示", "title_en": "A Multimodal Approach Combining Biometrics and Self-Report Instruments for Monitoring Stress in Programming: Methodological Insights", "authors": "Cristina Martinez Montes,Daniela Grassi,Nicole Novielli,Birgit Penzenstadle", "background": "传统的幸福感、压力和其他人类因素的研究主要依赖自我报告量表来评估关键变量。尽管这些量表在充分验证和标准化后基本上是可靠的，但关于它们可能存在的偏见的担忧仍在增加，因此，研究人员开始寻找将这些量表与更多客观指标（例如生理指标）相结合的替代方案。本研究旨在比较心理测量的压力指标和生物指标，并在编程任务中识别与生物数据相关的压力特征变化。参与者在完成预调查问卷、佩戴生物传感器编程两个任务、完成简短的后调查问卷后进行了简短的退出面谈。结果表明，心理测量工具未发现压力，并且面谈参与者报告了既无压力也经历时间压力的混合感受，仅生物数据的皮质醇模式显示差异显著。研究指出，通过设置更严格的时限来施加压力的方法可能并不充分，为此类研究提供方法论建议。", "innovation": "该研究结合了生理指标（如皮质醇）和自我报告量表来监测编程中的压力水平，这是该研究的一个创新之处。尽管已有研究探究了压力测量工具的偏见，但本文试图通过结合生理数据和自我评估来提供更全面的压力评估方法，这有助于更准确地识别压力相关模式。", "conclusion": "该研究的结果表明，采取更严格的时限施加压力的方法可能不足以准确反映受试者的压力水平。生理数据如皮质醇的变化能够揭示一些心理测量无法观察到的压力模式。该研究为今后结合生物指标和心理测量进行压力研究提供了方法论上的启示。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02137", "html_url": "https://arxiv.org/abs/2507.02137", "title": "在软件工程中实现可信赖的情感分析：数据集特征和工具选择", "title_en": "Towards Trustworthy Sentiment Analysis in Software Engineering: Dataset Characteristics and Tool Selection", "authors": "Martin Obaidi,Marc Herrmann,Jil Klünder,Kurt Schneider", "background": "软件开发过程中大量依赖于文本形式的交流，情感分析作为理解团队动态的工具尤为重要，还能支持基于人工智能的可信分析。然而，现有的情感分析工具在不同平台的数据集上的表现不一，原因是沟通风格和内容的差异。本研究分析了来自五个平台的10个开发人员通信数据集的语言和统计特征，并评估了14个情感分析工具的性能。研究表明，数据集特征可以用来改善工具选择，因为不同平台在语言和统计属性上存在显著差异。虽然像SetFit和RoBERTa这样的基于变换器的模型在大多数情况下表现出色，但工具的有效性仍然取决于具体情境。", "innovation": "本研究提出了一个基于数据集特征的映射方法和问卷，推荐适合新数据集的合适情感分析工具。此外，研究强调环境的演变需要持续评估和改进情感分析工具的效果，这支持了研究人员和实践者选择可信的情感分析工具的方法，突显了持续评估的必要性。", "conclusion": "研究结果表明，数据集特征可以用来改善工具选择。基于变换器的模型如SetFit和RoBERTa取得了良好的表现，但工具的效果仍然依赖于具体的使用环境。研究支持软件工程领域内选择可信的情感分析工具，并强调了随着沟通环境的变化进行持续评估的必要性。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02318", "html_url": "https://arxiv.org/abs/2507.02318", "title": "基于LLM的单元测试生成精确检测Python类型错误", "title_en": "Precisely Detecting Python Type Errors via LLM-based Unit Test Generation", "authors": "Chen Yang,Ziqi Wang,Yanjie Jiang,Lin Yang,Yuteng Zheng,Jianyi Zhou,Junjie Chen", "background": "Python中的类型错误通常会导致运行时失败，这对软件可靠性和开发者的生产力构成了重大挑战。现有的静态分析工具试图在不运行代码的情况下检测这些错误，但频繁遭遇较高的误报率。最近的单元测试生成技术在实现高测试覆盖率方面颇具潜力，但它们往往在不带定制化指导的情况下难以生成揭示bug的测试用例。", "innovation": "RTED是一种新颖的类型感知单元测试生成技术，通过逐步类型约束分析与反射验证结合来指导测试生成过程，并有效抑制误报。相比四种最先进的技术，RTED在两个广泛使用的基准测试集（BugsInPy和TypeBugs）上检测到了22-29个更多的类型错误。RTED还具备产生较少误报的能力，精度提高了173.9%-245.9%。此外，RTED成功发现了六个开源Python项目中的12个之前未发现的类型错误。", "conclusion": "实验结果显示，RTED在检测Python类型错误方面表现出色，不仅能更精确地检测到更多的类型错误，还能大幅降低误报率，并在实际开源项目中揭示新的类型错误。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02182", "html_url": "https://arxiv.org/abs/2507.02182", "title": "增强COBOL代码解释：大规模语言模型中多智能体方法", "title_en": "Enhancing COBOL Code Explanations: A Multi-Agents Approach Using Large Language Models", "authors": "Fangjian Lei,Jiawen Liu,Shayan Noei,Ying Zou,Derek Truong,William Alexander", "background": "COBOL是一种广泛应用于金融机构、企业和政府机构的业务应用程序的编程语言，但由于其年龄、复杂性，以及COBOL开发人员逐渐减少的情况，维护COBOL代码库变得越来越具有挑战性。现有的研究利用大规模语言模型（LLM）来解释代码片段的功能，但COBOL由于其架构和语法上的独特性，常常超出LLM的令牌窗口大小，因此带来额外挑战。因此，缺乏代码文档使得新开发人员难以有效理解并维护COBOL系统。", "innovation": "本文提出了一种多智能体方法，利用两个基于LLM的代理协作生成对功能、文件和整个项目的解释。这些代理通过利用代码库的上下文信息提高代码解释提示，进而用在实际的开源COBOL项目中进行评估。实验结果表明，在函数代码解释方面，本文的方法在METEOR、chrF和SentenceBERT分数上分别优于基线方法12.67%、18.59%和0.62%；在文件解释方面，该方法不仅解释了大量短代码和超过LLM令牌窗口大小的长代码，还在目的、功能和解释清晰度方面优于基线方法4.21%、10.72%和14.68%；在项目层面，该方法成功地解释了82%选择项目的功能和目的。", "conclusion": "本文提出的方法在COBOL代码解释方面表现显著优于基线方法，特别是在函数、文件和项目水平上生成更加清晰和准确的解释。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02107", "html_url": "https://arxiv.org/abs/2507.02107", "title": "使用自然语言查询的结构化代码搜索", "title_en": "Structural Code Search using Natural Language Queries", "authors": "Ben Limpanukorn,Yanjun Wang,Zach Patterson,Pranav Garg,Murali Krishna Ramanathan,Xiaofei Ma,Anoop Deoras,Miryung Kim", "background": "代码搜索是开发者常见的任务，用于理解API、学习常见代码模式和导航代码。目前，开发者最常用的搜索方法是使用关键词和正则表达式，这两种方法易于使用且广泛可用。除了关键词和正则表达式，结构化代码搜索工具允许开发者根据代码的语法结构进行搜索。这种方法在从错误查找、系统优化重构等多个方面有广泛的应用。然而，这些结构化代码搜索工具使用的都是领域特定语言（DSL），这些语言的学习和书写对开发者来说具有一定的难度。本文提出了一种新的方法，允许开发者使用自然语言进行结构性代码搜索。用自然语言表达查询提供了一种直观的代码搜索方法，降低了入门门槛。在这项工作中，作者开发了一种结合大型语言模型（LLM）的推理能力和结构化搜索工具的力量的新颖且通用的方法，以高效且准确地检索相关代码。该方法分别针对Semgrep和GQL两个结构化代码搜索DSL进行了实现。为了评估该方法，作者构建了一个新的包含10个Java项目中400个查询的新基准集。研究结果表明，基于LLM将自然语言查询转换为DSL查询的方法在结构化代码搜索方面是有效且稳健的，其精确度和召回率范围在55%-70%之间。此外，该方法在F1分数上显著优于基于语义代码搜索和LLM检索的基线方法，最多提高了57%和14%。", "innovation": "本研究提出了一种结合大型语言模型（LLM）和结构化搜索工具的新颖方法，允许开发者使用自然语言进行结构性代码搜索。通过将自然语言查询转化为领域特定语言（DSL）查询来检索相关代码，这种方法降低了入门门槛并提高了代码搜索的精度和召回率。", "conclusion": "研究结果表明，基于大型语言模型（LLM）将自然语言查询转换为DSL查询的方法在结构化代码搜索方面是有效且稳健的，其精确度和召回率范围在55%-70%之间。该方法显著优于现有的基线方法，特别是在F1分数上提高了最多57%和14%。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02376", "html_url": "https://arxiv.org/abs/2507.02376", "title": "VeFIA：一种高效的垂直联邦协作软件推理审计框架", "title_en": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software", "authors": "Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang", "background": "垂直联邦学习（VFL）是一种无需访问参与者数据的分布式AI软件部署机制，用于跨孤岛协作。然而，现有的VFL工作缺乏一种机制来审计数据方推理软件执行的正确性。VeFIA框架解决了这一问题，确保在大规模推理过程中，任务方可以验证数据方计算结果的正确性，同时不披露数据方的数据隐私或引入额外的推理系统延迟。VeFIA的核心在于，任务方可以利用包含可信执行环境（TEE）的框架和协调器的推理结果，来验证数据方计算结果的正确性。该框架保证，在异常推理超过5.4%的情况下，任务方可以在99.99%的概率下检测出推理软件的执行异常，且不增加在线推理延迟。VeFIA的随机抽样验证实现了对异常推理的100%阳性预测值、阴性预测值和真正率的检测。", "innovation": "设计了一个垂直联邦推理审计（VeFIA）框架，旨在解决现有VFL缺乏审计数据方推理软件执行正确性的机制问题。VeFIA采用可信执行环境（TEE）和协调器，使任务方能够对推理软件的执行结果进行验证，确保在大规模推理过程中不泄露数据隐私，且无额外的推理延迟。", "conclusion": "VeFIA确保了当异常推理超过5.4%时，任务方能以99.99%的概率检测出推理软件的执行异常，无需额外增加在线推理延迟。该框架通过随机抽样验证实现了对异常推理的100%检测准确率。据我们所知，这是第一篇讨论垂直联邦学习中推理软件执行正确性的论文。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02665", "html_url": "https://arxiv.org/abs/2507.02665", "title": "研究软件工程师和软件工程研究人员是否使用相同的语言？", "title_en": "Do Research Software Engineers and Software Engineering Researchers Speak the Same Language?", "authors": "Timo Kehrer,Robert Haines,Guido Juckeland,Shurui Zhou,David E. Bernholdt", "background": "研究软件工程师（RSEs）和软件工程研究人员（SERs）在相似概念上使用不同的术语，这造成了沟通障碍。因此，研究者已经开始探讨SER社区中的软件工程基本概念在RSE社区中的解释，发现了某些概念的对齐、知识缺口以及可能的学习和合作区域。", "innovation": "开发了一种系统的方法进行术语映射，这为未来众包扩展和验证奠定了基础。初步发现揭示了双向学习和协作的机会。", "conclusion": "初步研究结果表明，通过术语映射和系统方法可以帮助解决沟通难题，并为未来的研究和实践提供了指导。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02533", "html_url": "https://arxiv.org/abs/2507.02533", "title": "Meta-Fair: 通过AI辅助的大语言模型公平性测试", "title_en": "Meta-Fair: AI-Assisted Fairness Testing of Large Language Models", "authors": "Miguel Romero-Arjona,José A. Parejo,Juan C. Alonso,Ana B. Sánchez,Aitor Arrieta,Sergio Segura", "background": "公平性是AI系统开发中的核心原则，但评估和实施公平性仍存在困难。当前在大语言模型（LLMs）中实施公平性测试的方法往往依赖于手动评估、固定模板、确定性启发式方法和人工收集的数据集，这使得这种方法既耗时又难以扩展。因此，需要开发一种新的自动化方法来测试LLMs的公平性，减少对特定领域资源的依赖，扩大现有方法的应用范围。Meta-Fair基于两种主要想法：首先，利用元测试来通过研究输入提示在按元关系（MRs）控制修改后的变化来发现偏差；其次，利用LLMs的能力生成测试案例和评估输出结果。", "innovation": "Meta-Fair提出了一个新的自动化方法来测试LLMs的公平性，该方法使用元测试来发现偏差，并利用LLMs的生成和分类能力来生成测试案例。此外，Meta-Fair还提供了三个开源工具，支持基于LLMs的测试案例生成、执行和评估。实验结果表明，Meta-Fair在测试LLMs时是有效的，能够识别出29%的执行过程中的偏差行为，并且最好模型可以达到0.79的F1分数。同时，LLMs作为评估工具表现出可靠性，但需要通过精心设计元关系来解决非确定性带来的不一致性问题。", "conclusion": "虽然Meta-Fair的方法仍面临进一步扩展的挑战，但实验结果表明，这一方法能够实现前所未有的自动化程度，为LLMs的公平性测试带来了希望。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02695", "html_url": "https://arxiv.org/abs/2507.02695", "title": "云问答平台上识别可持续性帖子的可持续性标志", "title_en": "Sustainability Flags for the Identification of Sustainability Posts in Q&A Platforms", "authors": "Sahar Ahmadisakha,Lech Bialek,Mohamed Soliman,Vasilios Andrikopoulos", "background": "近年来，随着云计算的兴起和向云基架构的转变，软件系统的可持续性受到了越来越多的关注。这种转变加强了在架构讨论中识别可持续性的需求，以便做出有信息量的决策。然而，由于缺乏清晰和明确的指南，识别软件从业者讨论中的可持续性概念仍然具有挑战性。", "innovation": "提出了一种可持续性标志的概念，该概念通过主题分析多种云供应商的最佳实践开发，用于标识云架构帖子中的可持续性。此研究表明，使用可持续性标志可以减少将帖子分类为与可持续性相关的内容，同时具有较高的确定性和显著的性能提升。此外，与仅依赖定义相比，可持续性标志被认为是更实用和易于理解的方式来识别可持续性。", "conclusion": "初步结果表明，使用可持续性标志可以更有效地识别云架构帖子中的可持续性，并且可持续性标志的使用相较于定义法具有更高的性能和实用性。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02578", "html_url": "https://arxiv.org/abs/2507.02578", "title": "适应性网络物理系统中的人机协作与伦理考量", "title_en": "Human-Machine Collaboration and Ethical Considerations in Adaptive Cyber-Physical Systems", "authors": "Zoe Pfister", "background": "适应性网络物理系统（CPS）集成了物理和计算能力，能够根据环境变化进行调整，并越来越多地采用人机协作，以利用人类和机器各自的长处。人机团队协作（HMT）是最先进的协作模式之一，设想人与机器之间无缝合作。然而，要在适应性CPS中实现高效且无缝的HMT仍然具有挑战性。尽管适应性CPS已经能够利用如MAPE-K等反馈机制，但仍存在将人纳入其中的障碍，原因之一是人类和机器的操作节奏不同。此外，HMT要求持续监控操作人员，收集他们行为和行动的可能敏感信息，因此尊重CPS中参与者的隐私和人类价值观对于人机团队的成功至关重要。", "innovation": "该研究通过开发新型方法和流程，将HMT整合到适应性CPS中，重点在于人类与机器的互动原则及其在CPS反馈回路中的应用。另外，还创建了在整个系统生命周期中整合、验证和评估伦理与人类价值观的框架，从需求工程开始。", "conclusion": "该研究为在适应性CPS中实现高效且无缝的人机团队协作提供了新的方法和框架，着重解决了操作节奏差异和隐私保护等问题，确保人机协作的成功。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02564", "html_url": "https://arxiv.org/abs/2507.02564", "title": "LLMREI：使用大语言模型自动化需求获取访谈", "title_en": "LLMREI: Automating Requirements Elicitation Interviews with LLMs", "authors": "Alexander Korn,Samuel Gorsch,Andreas Vogelsang", "background": "需求获取访谈是收集系统需求的关键步骤，但高度依赖于技能成熟的分析师，这使得这一过程耗费大量资源，容易受到人为偏见的影响，并且可能导致沟通误解。近期，大语言模型（Large Language Models, LLMs）的进步为自动化需求获取面试的一部分流程提供了新的机会。本研究介绍了一款名为LLMREI的聊天机器人，旨在在最小化人类干预的情况下进行需求获取访谈，从而减少常见的访谈者错误并提高需求获取的规模性。我们探索了零样本提示和从易到难提示两种主要方法来优化LLMREI的需求获取表现，并在33次模拟的访谈中对其进行了评估。本研究评估聊天机器人的有效性在于三个方面：减少常见访谈错误、提取相关需求以及根据访谈语境和用户响应生成高度依赖上下文的问题。研究结果表明，LLMREI在错误数量、提取需求能力和生成高度上下文相关问题方面与人类访谈者表现相当", "innovation": "本研究提出了LLMREI，这是一种旨在通过最小化人际干预来进行需求获取访谈的聊天机器人。研究探索了零样本提示和从易到难提示两种方法优化聊天机器人的表现，并评估了其在模拟需求获取访谈中的效果。此外，研究还表明，虽然LLMREI在一些方面表现不错，如提取大量需求并生成上下文相关的问题，但在其他方面的性能仍有待提高，且由于初步试验证明适配性较差，因此未采用微调的方法", "conclusion": "LLMREI能够在一定程度上自动化需求获取访谈，并在某些方面表现出与人类访谈者相当的效果，尤其是在减少常见错误、提取需求和生成上下文相关问题方面。研究建议在实际应用中持续改进并充分利用大语言模型的潜力，特别是在访谈规模较大的情况下，LLMREI可能会带来显著的好处"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02858", "html_url": "https://arxiv.org/abs/2507.02858", "title": "要求获取后续问题生成", "title_en": "Requirements Elicitation Follow-Up Question Generation", "authors": "Yuchen Shen,Anmol Singhal,Travis Breaux", "background": "访谈是广泛用于获取软件系统需求的技术，用于收集相关方的需求、偏好和期望。有效的访谈需要熟练的访谈者能够实时提出恰当的问题，但这也面临多个挑战，包括对领域不熟悉、认知负荷过重以及信息过载影响人类处理访谈对象的言语信息。近年来，大型语言模型（LLMs）在多个自然语言处理任务上表现出最先进的性能，如文本摘要和蕴含。为支持访谈者，研究调查了GPT-4o在需求获取过程中的应用，用于生成后续访谈问题。同时，也描述了基于访谈对象言语生成问题的方法。通过受控实验评估了由LLM生成和人类撰写的问题的质量，并且通过指导问题生成来进一步评估LLM生成的问题。实验结果表明，无论是哪个实验，LLM生成的问题在清晰度、相关性、信息量方面都不逊于由人类撰写的问题，在指导生成后的情景下，LLM生成的问题甚至优于由人类撰写的问题。这突显了使用大型语言模型帮助访谈者在实时的情况下提高需求获取访谈质量的潜力。", "innovation": "本研究创新之处在于将大型语言模型（LLMs）应用于需求获取过程中生成后续问题，基于一个框架设计处理访谈者错误类型。这有助于提高访谈的质量和简便性，特别是在实时情景下。研究表明，在实验条件下，由LLM生成的问题在质量上不亚于人类撰写的问题，而且在利用常见错误类型指导生成时表现出更好的效果。这为进一步研究和实际应用提供了新的方向和可能性。", "conclusion": "本研究表明，大型语言模型（LLMs）能够在要求获取过程中有效地生成后续问题，这些问题在清晰度、相关性和信息量方面与人类撰写的相当；特别是在利用常见错误类型进行指导生成的情况下，LLM生成的问题甚至优于人类撰写的问题。这凸显了使用LLMs实时辅助访谈者提高需求获取质量的潜力。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02846", "html_url": "https://arxiv.org/abs/2507.02846", "title": "法律要求从法律翻译", "title_en": "Legal Requirements Translation from Law", "authors": "Anmol Singhal,Travis Breaux", "background": "软件系统必须遵守法律法规，这对资源有限的小型组织和初创企业来说是一个耗时的任务。从法规中提取有关软件的元数据以确保合规性是一个关键步骤，但由于法规文本的长度和复杂性，这一过程变得繁琐。尽管已有研究致力于自动化提取法律文本中的结构化和语义元数据，但它们未能考虑这些元数据类型之间及其属性间的相互作用，且依赖于手动标注或基于规则的机器学习方法，这些方法在新文档上的泛化效果不佳。因此，本研究针对这一问题，提出了一种基于文本蕴含和上下文学习的方法，自动生成法规文本的标准表示形式，该表示形式可以被编码和执行为Python代码。", "innovation": "本研究的创新之处在于提出了基于文本蕴含和上下文学习的新方法，该方法能够自动生成法规文本的标准Python代码表示形式，这种方法不仅克服了先前方法中未能考虑元数据类型之间及其属性相互作用的问题，还减少了对大量手动标注数据集的依赖，使得该方法能够在未见过的立法上广泛适用。", "conclusion": "本研究在对13个美国州的数据泄露通知法进行评估后发现，生成的标准表示形式通过了大约89.4%的测试案例，精度和召回率分别达到82.2和88.7。这表明该方法在法律文本处理中有较好的适用性和准确性。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.06416", "html_url": "https://arxiv.org/abs/2409.06416", "title": "探索大型语言模型在工业测试维护过程中的集成", "title_en": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes", "authors": "Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg", "background": "在软件测试过程中，大量的成本和努力都投入到测试维护中，即添加、删除或修改测试案例以使测试套件与被测系统保持同步或提高测试质量。现有的工具支持可以通过自动化测试维护过程中的某些方面或提供开发者的指导和支持，从而降低测试维护的成本并提升其质量。本文探讨大型语言模型（LLMs）在支持测试维护中的能力和应用。我们通过一家大型企业的案例研究，探索了触发测试维护需求的指标、LLMs可以采取的行动以及部署LLMs在工业环境中时需要考虑的因素。我们还提出了一个预测代码更改后哪些测试需要维护的多代理架构。", "innovation": "该研究引入了将大型语言模型应用于工业测试维护过程中的新方法，具体包括提出预测代码更改后哪些测试需要维护的多代理架构，从而自动化测试维护过程中的某些方面并提供相应的指导和支持，以降低测试维护的成本并提升其质量。这种方法提升了对如何利用大型语言模型优化工业测试维护流程的理解和实际操作水平。", "conclusion": "通过多角度的研究方法，本文在理论和实践层面上推进了关于如何利用大型语言模型改进工业测试维护流程的理解，为未来开发更高效的测试维护工具奠定了基础。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.15621", "html_url": "https://arxiv.org/abs/2505.15621", "title": "DSCodeBench: 一个现实的数据科学代码生成基准", "title_en": "DSCodeBench: A Realistic Benchmark for Data Science Code Generation", "authors": "Shuyin Ouyang,Dong Huang,Jingwen Guo,Zeyu Sun,Qihao Zhu,Jie M. Zhang", "background": "当前的基准测试，如DS-1000，在评估大型语言模型（LLMs）在复杂现实数据科学代码生成任务的能力方面可能存在不足。这些基准可能缺乏多样性和挑战性，不能全面评估模型的功能和能力。因此，需要一个新的基准测试来填补这一空白，确保能够评估模型在实际数据科学代码生成任务中的表现和限制。", "innovation": "DSCodeBench是一个新的基准，旨在通过1,000个精心构建的问题来评估LLMs在复杂和现实的数据科学代码生成任务中的性能。这些问题来自GitHub上广泛使用的Python数据科学库的真实问题。与现有的DS-1000基准相比，DSCodeBench提供了更具挑战性和代表性的测试环境，更长的代码解决方案，更全面的数据科学库，更清晰和更结构化的问题描述，以及更强的测试套件。DSCodeBench通过开发一个稳健的管道来进行任务范围选择、代码构建、测试案例生成和问题描述合成来构建，这个过程配以严格的手动编辑来确保一致性并增强评价可靠性。实验结果表明，DSCodeBench具有稳健的扩展行为，更大的模型系统地优于较小的模型，验证了其能够区分模型能力的能力。最好的测试模型，GPT-4o，其pass@1得分为0.202，表明LLMs在现实数据科学代码生成任务中仍然有很大的改进空间。", "conclusion": "DSCodeBench将成为LLM基础数据科学编程的一个严格且可信的基础，推动LLM在数据科学编程中的应用和发展。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.07967", "html_url": "https://arxiv.org/abs/2503.07967", "title": "代码数字孪生：赋予大型语言模型复杂软件维护的隐含知识", "title_en": "Code Digital Twin: Empowering LLMs with Tacit Knowledge for Complex Software Maintenance", "authors": "Xin Peng,Chong Wang,Mingwei Liu,Yiling Lou,Yijian Wu", "background": "大型语言模型（LLMs）在软件工程任务中展现出了代码完成和生成方面的潜力，但在复杂软件系统的维护方面支持程度有限。这些模型往往难以理解嵌入系统中的隐含知识，例如责任分配和不同模块之间的协作。为了弥合这一差距，论文提出了代码数字孪生的概念和框架，这是一种概念性表示，能够捕捉代码元素背后的概念、功能和设计依据，并与软件共同进化。代码数字孪生通过结合从结构化和非结构化来源（如源代码、文档和变更历史）提取的知识，利用LLMs、静态分析工具和人类专业知识构建而成。这一框架能够通过提供隐含知识作为上下文来增强LLMs在软件维护任务中的能力，例如问题定位和仓库级代码生成。", "innovation": "提出了一种称为‘代码数字孪生’的概念和框架，旨在解决大型语言模型在复杂软件系统维护中的不足。该框架通过结合从多种来源中的知识提取，利用LLMs、静态分析工具和人类专业知识，提供代码元素背后的概念、功能和设计依据，从而支持大型语言模型在软件维护中的应用，如问题定位和仓库级代码生成。", "conclusion": "基于所提出的方法，本文探讨了代码数字孪生的持续构建和完善的挑战与机遇。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02690", "html_url": "https://arxiv.org/abs/2507.02690", "title": "RLHGNN：基于强化学习的异构图神经网络在业务流程中的下一个活动预测", "title_en": "RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes", "authors": "Jiaxing Wang,Yifeng Yu,Jiahan Song,Bin Cao,Jing Fan,Ji Zhang", "background": "在服务导向架构中的微服务环境、分布式企业系统和云原生平台中，通过预测下一个活动来优化业务流程代表了一个基本挑战。这能使资源分配更为前瞻性，并实现动态服务组合。尽管顺序方法很普遍，但它们不能捕捉到并行执行和条件依赖产生的非顺序关系。即便使用图基方法，也采用了均质表示和静态结构，这些结构在所有过程复杂性特征上下统一进行建模，缺乏灵活性。为了改进这一点，本文提出了一种通过将事件日志转化为基于现有过程挖掘理论的特定边类型的异构过程图的新方法——RLHGNN。该方法通过可选结合这三种边类型来创建四个灵活的图结构，以适应不同的过程复杂性，并利用强化学习制定马尔科夫决策过程来进行自动图结构选择。此方法采用关系特定聚合策略的异构图卷积来实现对下一个动作的有效预测。这样的适应性方法允许精确建模服务交互中的序列和非序列关系。在六个实际数据集上的全面评估表明，该方法持续优于最先进的方法，并且具备近1毫秒的预测推断延迟，是一个可在实时业务流程监控中应用的实用解决方案。", "innovation": "本文提出了RLHGNN框架。该框架将事件日志转换为基于现有过程挖掘理论的异构过程图，并利用基于强化学习的图卷积预测下一个活动。该方法通过自动确定特定过程实例的最佳图结构，并采用关系特定聚合策略，能够灵活处理不同过程复杂度下的序列和非序列关系。其中，过程图中的三种不同类型边，能够帮助捕捉更多的动态和非顺序关系，使模型更适应复杂业务场景。此外，该方法还保持了较高的推理速度，在实际业务应用场景中具有较高的实用价值。", "conclusion": "实验证明，提出的RLHGNN方法在六个实际数据集上持续优于当前最先进的方法，且推理延迟低，为实时业务流程监控提供了有效解决方案。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02607", "html_url": "https://arxiv.org/abs/2507.02607", "title": "缓解攻击数据稀缺性：斯堪尼亚公司增强车内网络安全措施的经验", "title_en": "Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures", "authors": "Frida Sundfeldt,Bianca Widstam,Mahshid Helali Moghadam,Kuo-Yun Liang,Anders Vesterberg", "background": "联网车辆的数字化演进带来了新的安全风险，这凸显了实施车辆内网络安全措施（如入侵检测和响应系统）的迫切需求。随着攻击场景的不断升级，需要更适应变化、能够检测未知和复杂威胁的检测机制。机器学习（ML）驱动的技术能够应对这一挑战，但实施多样化的攻击场景存在安全、成本和伦理方面的限制，导致缺乏代表攻击场景的有效数据。因此，需要高效和有效的方法生成高质量的攻击场景数据，以缓解数据稀缺问题。", "innovation": "该论文提出了一种基于上下文的攻击数据生成器，能够生成代表多种攻击类型的输入和相应的车内网络日志（如控制器局域网CAN日志），包括拒绝服务（DoS）、模糊攻击、欺骗、悬挂攻击和回放攻击。该生成器利用参数化的攻击模型，并通过CAN消息解码和攻击强度调整来配置攻击场景，使其与真实世界情况高度相似，并促进多变性。通过入侵检测系统（IDS）案例研究评估生成数据在实际中的适用性，展示了所提出方法的效率和可扩展性，以及IDS模型的性能结果验证了生成数据的一致性和有效性。此外，还详细探讨了影响数据真实性的因素，并提供了其应用方面的见解。", "conclusion": "本文提出的方法能够有效应对车内网络安全中因攻击数据稀缺而导致的问题。通过深度神经网络IDS模型的实验评估，验证了生成数据的有效性和一致性，并展示了其在提升入侵检测能力方面的实际应用价值。同时，该研究为生成高质量攻击数据提供了新的思路，并对于提升车辆网络安全具有重要意义。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.03693", "html_url": "https://arxiv.org/abs/2504.03693", "title": "智能业务流程管理：业务流程中代理治理的从业者视角", "title_en": "Agentic Business Process Management: Practitioner Perspectives on Agent Governance in Business Processes", "authors": "Hoang Vu,Nataliia Klievtsova,Henrik Leopold,Stefanie Rinderle-Ma,Timotheus Kampik", "background": "随着生成型AI的兴起，软件代理在行业中的兴趣日益增加。鉴于基于生成型AI的代理具有随机性，它们在组织中的有效和安全部署需要坚实的治理机制，这可以通过代理业务流程管理得以实现。然而，鉴于这一新型代理概念的最初性，目前尚不清楚业务流程管理从业者认为代理是什么，以及它们在代理部署中与之关联的益处、风险和治理挑战是什么。为了研究组织如何有效地治理AI代理，我们对来自不同行业的22名业务流程管理者进行了半结构化的访谈。他们预见代理将提高效率、提高数据质量、确保更好的合规性，并通过自动化增强可扩展性，同时也警告可能存在偏见、过度依赖、网络安全威胁、就业替代和决策模糊性的风险。", "innovation": "研究通过半结构化访谈了解了业务流程管理从业者对代理的看法及其部署中的利益、风险和治理挑战，提出了六个关键建议来应对这些挑战，包括明确业务目标、设置法律和伦理边界、建立人类与代理的合作、自定义代理行为、管理风险，并确保与备用方案的安全集成。此外，该论文还概述了传统业务流程管理与代理型AI对齐的行动，包括平衡人类和代理的角色、重新定义人类参与、调整流程结构，并引入绩效指标。", "conclusion": "这些见解为将AI代理集成到业务流程中提供了一个实用的基础，同时保持监督、灵活性和信任。该研究提出了负责任地采用AI代理的指导原则，包括明确业务目标、设置法律和伦理约束、建立人类与代理的合作、自定义代理行为、管理风险，并确保与备用选项的安全集成。这些策略有助于协调传统业务流程管理和代理型AI的关系。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.08713", "html_url": "https://arxiv.org/abs/2506.08713", "title": "基于多跳自然语言推理的可解释性合规检测", "title_en": "Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure", "authors": "Fariz Ikhwantri,Dusica Marijan", "background": "确保复杂系统符合规定通常需要通过主张-论据-证据的框架检查保证案例的有效性。这一过程中存在一些挑战，包括法律和技术文本的复杂性，对模型解释的需求以及保证案例数据的受限访问。针对这些挑战，研究开发了一种基于自然语言推理（NLI）的合规检测方法——EXCLAIM（基于多跳推理的可解释性合规检测）方法，通过将保证案例的主张-论据-证据结构视为多跳推理，以实现可解释性和可追溯性的合规检测。", "innovation": "提出了一种基于大型语言模型（LLMs）生成保证案例的方法，并引入了衡量覆盖率和结构一致性的新指标。该方法的有效性通过从GDPR要求生成的保证案例在多跳推理任务中的案例研究得到了验证，强调了基于NLI的方法在自动化合规过程中的潜力。", "conclusion": "研究表明，EXCLAIM方法能够有效地实现解释性和可追溯的合规检测，为复杂系统合规性的自动化过程提供了一种新的技术手段，具有重要的理论和应用价值。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.01631", "html_url": "https://arxiv.org/abs/2506.01631", "title": "基于梯度的LLM相似度检测和家族分类模型指纹技术", "title_en": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification", "authors": "Zehao Wu,Yanjie Zhao,Haoyu Wang", "background": "大型语言模型（LLMs）在现代应用中已成为关键软件组件。通过微调、合并和重分发等方式进行的未经授权的模型衍生已成为重要的软件工程挑战。与传统的软件相比，LLM生态系统缺乏有效的机制来检测模型血缘和强制执行许可协议。开源模型创建者，例如Meta的LLaMA，要求衍生作品遵守命名约定以进行归属，但却没有技术手段来验证合规性。", "innovation": "我们提出的TensorGuard是一种基于梯度的指纹框架，用于LLM相似度检测和家族分类。该框架通过分析张量层随机输入扰动的梯度响应来提取模型固有行为特征，无需依赖于训练数据、水印或特定模型格式。TensorGuard支持广泛采用的safetensors格式，并通过统计分析梯度特征构建高维指纹。这些指纹能够提供直接的任意模型对之间的相似性评估以及未知模型的系统家族分类。实验评估涉及58个模型（包括8个基模型和50个衍生模型）的五个模型家族（Llama、Qwen、Gemma、Phi、Mistral），展示了在我们的聚类初始化下的94%分类准确性。", "conclusion": "实验结果表明，基于梯度的指纹技术在LLM相似度检测和家族分类方面表现出色，尤其是在使用有领域知识初始化的k-Means聚类算法时。"}
{"llm_update_time": "20250707", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.24100", "html_url": "https://arxiv.org/abs/2503.24100", "title": "基于模糊测试的C/C++软件在 cyber-物理系统中的变异测试", "title_en": "Fuzzing-based Mutation Testing of C/C++ Software in Cyber-Physical Systems", "authors": "Jaekwon Lee,Fabrizio Pastore,Lionel Briand", "background": "变异测试可以减少交付故障软件的可能性，因此在安全关键的 cyber-物理系统 (CPS) 中用于开发嵌入式软件是一个推荐的做法。然而，当今最先进的用于C和C++软件的变异测试技术依赖于符号执行，而符号执行的局限性限制了其应用，例如，黑盒组件的系统。为了克服这一问题，本文提出使用模糊测试，它已经被证明对C和C++软件非常有效。模糊测试工具会自动生成测试输入，这些输入能够以多种方式探索程序分支，操作不同程序状态下的陈述，从而检测出变异程序，这是本文的目标。", "innovation": "本文提出了基于模糊测试的变异测试方法，该方法利用模糊测试工具可自动生成多样化的测试输入，以发现变异程序，进而在清洁和工业化操作卫星系统的软件组件上进行评估。研究结果表明，该方法能够检测到40%到90%未被开发者测试集发现的变异程序。此外，结合使用Clang编译器、内存地址检查器和laf-intel仪器以收集覆盖率并指导模糊测试，可以更有效地发现活性变异程序。与符号执行相比，该方法发现更多的活性变异程序，检测率提高了50个百分点；尽管模糊测试结合符号执行可以发现更多被杀死的变异程序，其实际收益微乎其微（不到一个百分点的提升）。", "conclusion": "基于模糊测试的变异测试方法在C和C++软件的变异测试中表现出了优越性，相较于符号执行方法，它能更有效地提高变异程序的检测率，尽管两者的结合可能会发现少量额外的变异程序，但这种组合带来的收益却非常有限。因此，采用这种方法是能在安全关键的cyber-物理系统中高效地发现变异程序的一种可行策略。"}
