{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14936", "html_url": "https://arxiv.org/abs/2506.14936", "title": "CALM: Contextual Analog Logic with Multimodality", "title_en": "CALM: Contextual Analog Logic with Multimodality", "authors": "Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue", "background": "经典二值逻辑系统无法捕捉人类决策的细微之处。它们还需要人工对接具有多模态环境，这往往是随机的、僵化的和脆弱的。神经网络擅长从多模态数据中提取丰富的上下文信息，但缺乏可解释的结构来进行推理。", "innovation": "CALM 结合了符号推理和神经生成，使系统能够根据实际多模态数据做出情境敏感的决定。它通过结合符号和神经技术，填补了逻辑和神经感知之间的差距，并创造了一种可以处理多模态输入的类比逻辑。每个命题使用领域树表示，并在实体的上下文接地确定后进行迭代精炼，迭代精炼由能够捕捉多模态信息的神经网络预测，并通过符号推理模块进行筛选以确保满足约束条件。", "conclusion": "CALM 显示了在多模态环境中推理逻辑结构并与其偏好对齐的潜力。它为需要逻辑的精确性和解释性以及神经网络的多模态信息处理能力的新一代AI系统奠定了基础。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14990", "html_url": "https://arxiv.org/abs/2506.14990", "title": "MEAL: 一种持续多智能体强化学习基准", "title_en": "MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning", "authors": "Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy", "background": "基准在强化学习（RL）算法的发展和分析中发挥着重要作用，且环境的可用性严重影响了研究进展。目前，持续学习（CL）在合作多智能体环境中的应用是一个相对未被充分探索的领域。本文探讨了现有持续学习基准运行在CPU上带来的计算瓶颈，限制了任务序列的长度。因此，作者提出了MEAL（多智能体环境中的适应性学习基准），首个专为持续多智能体强化学习（CMARL）设计的基准。利用JAX进行GPU加速，MEAL能够在标准台式机上以数小时内处理100个任务序列并实现持续学习。但是，将流行的持续学习和多智能体强化学习方法简单结合在简单环境中表现良好，但在更复杂的高协调需求的环境中无法成功扩展。对MEAL进行的消融研究确定了CMARL中的关键架构和算法特征。", "innovation": "MEAL是首个专门为持续多智能体强化学习设计的基准，利用JAX进行GPU加速，可以在标准台式机上高效处理100个任务序列。通过这种方法，解决了现有持续学习基准在计算效率上的限制，为CMARL的研究提供了有力的支持。同时，基于MEAL进行的消融研究确定了CMARL中的关键架构和算法特征。", "conclusion": "MEAL作为一种新的基准，提供了一个新的平台来评估和改进CMARL的方法。研究表明，简单的组合方法虽然在简单环境中有效，但在复杂环境中表现不佳。基础研究揭示了实现CMARL的关键因素，为进一步的研究提供了指导。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15050", "html_url": "https://arxiv.org/abs/2506.15050", "title": "截断接近策略优化", "title_en": "Truncated Proximal Policy Optimization", "authors": "Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu", "background": "近期，测试时大规模语言模型（LLMs）通过生成长推理链（CoT）展示了卓越的推理能力，适用于科学和专业任务。强化学习（RL），如比例近似策略优化（PPO）及其变种，是开发这些推理模型的关键组件，允许模型通过试错学习。然而，PPO 由于其固有的在线策略性质，处理时间长的问题，在生成长响应时问题更加严重。\n", "innovation": "本文提出了截断接近策略优化（T-PPO），一种对 PPO 的创新扩展，通过简化策略更新和限制响应生成来提高训练效率。T-PPO 解决了完全同步的长时间生成过程中资源利用率低的问题，这些资源在等待完整卷出期间通常闲置。本文有两个贡献：首先，提出了基于不完整响应的增强估计的扩展通用优势估计（EGAE）；其次，设计了计算优化机制，允许策略和价值网络的独立优化，通过筛选提示和截断令牌降低冗余计算，加快训练过程而不牺牲收敛性能。\n", "conclusion": "实验结果表明，T-PPO 在 AIME 2024 上对一个 32B 基础模型的推理 LLM 训练效率提高了 2.5 倍，并超越了现有竞争对手。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15196", "html_url": "https://arxiv.org/abs/2506.15196", "title": "HeurAgenix：利用LLM解决复杂组合优化挑战", "title_en": "HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges", "authors": "Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian", "background": "启发式算法在解决组合优化（CO）问题上扮演着重要角色，但传统设计依赖手动专业知识且难以在不同实例间泛化。CO问题的复杂性导致可靠监督稀缺，这成为启发式算法发展的瓶颈。", "innovation": "引入了HeurAgenix，这是一种借助大型语言模型（LLMs）的两阶段超启发式框架，首先演化启发式算法，然后根据LLM的感知能力自动选择最合适的启发式。框架中的轻量级启发式选择器可以是现有的先进LLM或经过微调成本较低的模型。通过双重奖励机制，HeurAgenix能够根据选择偏好信号和状态感知进行微调，从而在嘈杂标注下做出稳健的选择。", "conclusion": "在经典基准上的广泛实验表明，HeurAgenix不仅超越了现有的基于LLM的超启发式算法，还能够匹敌或超越专门的求解器。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15207", "html_url": "https://arxiv.org/abs/2506.15207", "title": "多智能体强化学习在自主多卫星地球观测中的应用：一个现实案例研究", "title_en": "Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study", "authors": "Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk", "background": "低地球轨道（LEO）卫星数量的指数增长已经革新了地球观测（EO）任务，解决了气候监测、灾害管理等方面的问题。然而，多卫星系统中的自主协调仍然是一个基本挑战。传统优化方法难以应对动态EO任务中的实时决策需求，因此需要使用强化学习（RL）和多智能体强化学习（MARL）方法来解决这个问题。", "innovation": "本文探讨了通过基于RL的方法实现自主EO任务规划，并将单卫星操作建模并扩展到多卫星星座，使用MARL框架来应对关键挑战，包括能源和数据存储限制、卫星观测不确定性以及在部分可观测性下的分散协调复杂性。通过利用接近实际的卫星模拟环境来评估最新的MARL算法（包括PPO、IPPO、MAPPO和HAPPO）的训练稳定性和性能，展示了MARL在多卫星协调中的有效应用，同时解决了非平稳性和奖励相互依赖问题。", "conclusion": "本研究的结果表明，MARL能够有效平衡成像和资源管理，并解决了多卫星协调中的非平稳性和奖励相互依赖问题。本研究为自主卫星操作提供了重要见解，并为分散的EO任务中的政策学习提供了实用指南。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15225", "html_url": "https://arxiv.org/abs/2506.15225", "title": "联合UAV和船舶进行不确定性海上MEC计算卸载与资源分配", "title_en": "Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels", "authors": "Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han", "background": "近年来，海上物联网（MIoT）的计算需求快速增加，基于无人机会航（UAVs）和船舶的多接入边缘计算（MEC）能够满足这些要求。然而，海上任务的不确定性带来了计算卸载和资源分配的效率问题，这成为显著挑战。本文研究了在考虑不确定任务的情况下通过UAVs和船舶合作进行计算卸载和资源分配的方法，提出了一个考虑不同类型任务和资源异构性的计算卸载与资源分配框架，并通过Lyapunov优化和马尔科夫游戏方法解决优化问题，最终通过软行动者-评论家算法验证了其有效性。", "innovation": "提出了一种基于UAVs和船舶合作的计算卸载与资源分配框架，引入了Lyapunov优化方法应对不确定性任务和资源可用性的变化。问题通过转换长期约束为短期约束，分阶段解决并通过马尔科夫游戏和软行动者-评论家算法逐步优化。", "conclusion": "通过联合UAVs和船舶进行计算卸载与资源分配，在考虑不确定性任务的情况下，本文提出的方法能有效解决海上边缘计算的需求。仿真结果验证了该方法在降低整体执行时间方面的有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15377", "html_url": "https://arxiv.org/abs/2506.15377", "title": "视觉导航中高效的环境理解", "title_en": "Efficient and Generalizable Environmental Understanding for Visual Navigation", "authors": "Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao", "background": "视觉导航是嵌入式人工智能中的一个核心任务，使代理能够根据给定的目标导航到复杂环境中。在各种导航任务中，许多任务需要建模从先前时间步积累的序列数据。虽然现有方法表现良好，但它们通常会同时处理所有先前观察，可能会忽略数据内的内部关联结构，从而限制了进一步提升任务性能的潜力。", "innovation": "通过从因果关系的视角分析导航任务的独特特征，提出了一种因果框架，以突出传统序列方法的局限性。基于这一洞察，提出了Causality-Aware Navigation（CAN），该方法引入了因果理解模块，以提高代理对环境的理解能力。实验证明，这种方法在各种任务和仿真环境中都能超越基线方法，且归因研究显示，因果理解模块在强化学习和监督学习设置中表现出色，且没有额外的计算开销，实现了效率和通用性的提升。", "conclusion": "我们的方法克服了现有方法的局限性，在模拟环境中表现出色，并且在不同任务中都表现出显著优于基线方法的优势。因果理解模块的加入使代理能够在没有额外计算开销的情况下，提升对环境的理解和处理能力，显著提高了导航任务的表现。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15567", "html_url": "https://arxiv.org/abs/2506.15567", "title": "利用大型语言模型进行推理与行动代理管理复杂故障分析工作流", "title_en": "Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents", "authors": "Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer", "background": "故障分析（FA）是一个高度复杂且知识密集的过程。将AI组件整合到FA实验室的计算基础设施中可以自动化检测图像中的不合规情况、从多种数据源检索类似案例以及从注释图像生成报告等多种任务。然而，随着部署的AI模型数量增加，挑战在于如何将这些组件组织成协调且高效的流程，使其能够无缝集成到FA过程中。", "innovation": "本文探讨了一种基于大型语言模型（LLM）的规划代理（LPA）的设计与实现，以协助FA工程师解决分析案例。LPA将LLM与高级规划能力和外部工具利用相结合，能够自主处理复杂查询、从外部系统检索相关数据并生成人类可读的回复。评估结果表明，该代理在支持FA任务方面具有操作有效性和可靠性，", "conclusion": "基于LLM的规划代理能够有效地管理复杂故障分析工作流，提高FA过程的效率和可靠性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15624", "html_url": "https://arxiv.org/abs/2506.15624", "title": "动态路由游戏中LSTM代理行为的自然语言状态表示效应", "title_en": "The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games", "authors": "Lyle Goodyear,Rachel Guo,Ramesh Johari", "background": "大型语言模型（LLMs）在动态环境中作为决策者显示出前景，但它们无状态的特点需要构建自然语言的历史表示。然而，以往游戏中的LLM代理编码游戏历史的手法是随意的，这既模糊了状态表示对代理行为的影响，也限制了研究之间的可比性。本文提出了一种统一框架，系统地构建用于在重复多代理游戏中提示LLM代理的自然语言“状态”表示。该框架通过三条轴线来定义状态表示方法：行动信息性（即状态表示捕捉已执行行动的程度）、奖励信息性（即状态表示描述获得奖励程度）及提示风格（即自然语言压缩程度）来解决这些问题。研究应用于一个相对简单的动态自私路由游戏，结果显示代理行为对自然语言状态表示有关键依赖性。不同表示方式影响游戏表现，某些表示方式更容易使代理行为接近博弈论的均衡预测，游戏更加稳定。", "innovation": "本文提出了一种统一框架，系统地构建自然语言“状态”表示来用于在重复多代理游戏中提示LLM代理。该框架通过三条轴线来定义状态表示方法，即行动信息性、奖励信息性和提示风格，以此解决先前研究中随意编码游戏历史带来的问题。通过应用该框架，研究识别并描述了自然语言状态表示如何影响动态路由游戏中代理的行为，并发现特定类型的表示方式能够使代理行为更接近博弈论预测，且游戏表现更加稳定。", "conclusion": "研究发现，提供总结而非完整自然语言历史、包含后悔而非原始收益信息、并限制对其他行动的信息的表示方法，能够促使代理行为更加符合博弈论的均衡预测，并且使游戏过程更加稳定。相反，其他类型的表示方式可能导致偏离均衡、动态游戏过程中产生更高波动性，或两者兼有。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15639", "html_url": "https://arxiv.org/abs/2506.15639", "title": "AI政策模块：培养计算机科学学生人工智能伦理与政策能力", "title_en": "The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy", "authors": "James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry", "background": "随着人工智能（AI）进一步融入个人和专业场景，人们不仅要关注AI伦理，还需通过AI政策加强其治理和监管。然而，当前的大学计算机科学课程未能充分准备未来的AI从业者将抽象的伦理原则和规范性政策偏好融入AI系统的设计与开发中。我们相信，熟悉‘AI政策景观’及将伦理原则转化为实践责任将对未来包括最技术化AI工程师在内的从业者至关重要。为应对这些新的期望，我们开发了一个AI政策模块，将其引入计算机科学课程。经过秋季2024年的成功试点后，我们进一步更新并扩展了这个模块，包括了一个关于‘AI监管’的实战作业。我们通过开学前后的问卷调查评估了学生对AI伦理和政策的态度变化。结果显示，学生们对于AI技术的伦理影响提出了更多的关注，并且也表示了在这方面讨论AI监管的信心增加。我们特别强调了AI监管作业作为一种有效且引人入胜的工具，用于探索AI对齐的极限和突出政策在解决伦理问题中的作用。", "innovation": "我们开发了一个AI政策模块，旨在将AI政策讨论引入计算机科学课程。经过秋季2024年成功试点，我们更新并扩展了该模块，包括了一个关于‘AI监管’的实战作业。我们通过调查评估了学生对AI伦理和政策的态度变化，结果显示，学生们对于AI技术的伦理影响的关注增加，并且表示了在这种讨论中的自信心增加。AI监管作业被证明是一个有效且有吸引力的工具，用于探索AI对齐的极限和突出政策在解决伦理问题中的作用。", "conclusion": "通过AI政策模块的实施，计算机科学学生对AI伦理和政策的理解得到显著提升。学生们表达出更强的伦理意识和对参与AI监管讨论的自信。AI监管作业作为探索AI对齐极限的有效工具继续发挥重要作用，突出了政策在解决AI伦理挑战中的核心角色。这一模块为未来的计算机科学教育提供了新的范式，有助于培养具有伦理意识和政策敏感性的AI从业者。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15647", "html_url": "https://arxiv.org/abs/2506.15647", "title": "探索和利用大型推理模型内在效率以实现自我引导的效率增强", "title_en": "Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement", "authors": "Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu", "background": "近年来，大型推理模型（LRMs）在复杂问题解决方面的应用显著提升了语言模型的能力，通过模拟人类的推理过程。然而，这些模型往往会产生冗余和不必要的内容，这会影响效率并增加推理成本。研究发现，LRMs本具有更简洁推理的能力，但这种能力尚未充分开发。推理路径的长度在正确解决方案中差异显著，最短的正确响应通常就足够了，这表明存在可以挖掘的效率潜力。", "innovation": "提出的两种提升LRM效率的方法：第一，引入无需训练的效率导向技术，通过在模型表示空间中调整单一方向来调节推理行为；第二，开发自我奖励的效率强化学习框架，通过奖励简洁正确的解决方案动态平衡任务准确性和简洁性。此外，方法在七个LRM骨干模型上进行了广泛的实验，在多个数学推理基准测试中证明，这些方法能显著减少推理长度，同时保持或提升任务性能。", "conclusion": "研究表明，可以通过利用和引导现有模型的内在能力来提高推理效率，这种方法在自我引导的方式下实现。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15672", "html_url": "https://arxiv.org/abs/2506.15672", "title": "SwarmAgentic:通过群智导向实现完全自动化的代理系统生成", "title_en": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence", "authors": "Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp", "background": "大型语言模型的快速发展已经推动了代理系统在决策、协调和任务执行方面的能力。然而，现有的代理系统生成框架缺乏完全的自主性，无法从零开始生成代理，缺乏自我优化的功能，也没有协作能力，这限制了其适应性和可扩展性。", "innovation": "提出了SwarmAgentic框架，这是一种完全自动化的代理系统生成框架，可以从零开始构建代理系统，并通过语言驱动的探索共同优化代理功能和协作。SwarmAgentic借鉴了粒子群优化（PSO）的思想，维护了一群候选系统的群体，并通过反馈引导更新不断进化。该方法在六项真实世界、开放性和探索性的任务中表现出色，包括高级规划、系统级协调和创造性推理。仅给定任务说明和目标函数，SwarmAgentic在TravelPlanner基准测试上实现了超过261.8%的相对改进，表明在结构上不受限制的任务中完全自动化是有效的。", "conclusion": "该框架朝着面向规模和自主的代理系统设计迈出了重要一步，将群智与完全自动化的多代理系统生成结合了起来。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15677", "html_url": "https://arxiv.org/abs/2506.15677", "title": "Embodied Web Agents: 融合物理与数字领域的代理智能", "title_en": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence", "authors": "Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang", "background": "当前的AI代理大多独立存在，主要是在线检索和处理大量数字信息，或者通过实体感知、计划和行动来与物理世界互动，但很少两者结合。这种分离限制了它们解决需要整合物理和数字智能任务的能力，例如从在线食谱烹饪、使用动态地图数据导航或使用网络知识解释现实世界的地标等任务。", "innovation": "该研究引入了Embodied Web Agents（实体网络代理）这一新颖的AI代理范式，该范式流畅地连接了实体与网络规模的推理。该团队开发了Embodied Web Agents任务环境作为统一的模拟平台，集成真实三维室内外环境和功能性的网络接口。基于此平台，构建了Embodied Web Agents基准测试，涵盖烹饪、导航、购物、旅游和地理定位等多种任务，这些任务需要跨物理和数字领域的协调推理。实验证明最先进的AI系统与人类能力之间存在显著差距，这标志着在实体认知和网络规模知识访问交叉领域中的挑战和机遇的存在。", "conclusion": "实验结果表明最先进的AI系统在跨域智能方面与人类表现存在显著差距，这不仅指出了在实体认知和网络规模知识访问交叉领域的挑战，也为跨域智能的评估提供了新的基准。所有数据集、代码和网站均可通过项目页面公开获取。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2207.01732", "html_url": "https://arxiv.org/abs/2207.01732", "title": "DEFORMER: 结合变形的局部模式与全局上下文以实现稳健的端到端语音识别", "title_en": "DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition", "authors": "Jiamin Xie,John H.L. Hansen", "background": "卷积神经网络（CNN）通过利用时间-频率局部模式极大地改进了语音识别性能。但是，这些模式通常假定出现在传统CNN对称和刚性的 kernel 中。这激发了一个问题：异形 kernel 是否同样适用？研究表明，自适应视角能够发现与注意力耦合更好的局部特征，而固定视角在输入中则无法做到这一点。在此研究中，作者用变形的 CNN 替换了 Conformer 架构中的深度卷积模块，并取得了更好的性能。作者通过分析最佳模型，展示了学习到的局部感受野和全局注意力地图，表明特征关联在句子级别上有了提高。", "innovation": "提出了Deformer架构，其基于变形的深度卷积模块，用于Conformer模型。Deformer通过适应性视角来识别更好的局部特征，这些特征与全局注意力更紧密耦合。研究者提供的统计分析显示了网络深度如何改变特征中携带的信息。实验表明，即使只替换编码器中的一半层，Deformer也能够显著改善WSJ数据集上的语音识别错误率，无论是否有语言模型辅助都取得了显著成效。", "conclusion": "Deformer架构通过结合变形的局部模式与全局上下文，在不依赖语言模型的情况下将WSJ data集上的相对错误率（WER）降低了5.6%，有语言模型辅助的情况下降低了6.4%，从而提高了语音识别系统的鲁棒性和准确性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.13018", "html_url": "https://arxiv.org/abs/2309.13018", "title": "动态ASR路径：一种多语言ASR模型高效剪枝的自适应遮罩方法", "title_en": "Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model", "authors": "Jiamin Xie,Ke Li,Jinxi Guo,Andros Tjandra,Yuan Shangguan,Leda Sari,Chunyang Wu,Junteng Jia,Jay Mahadeokar,Ozlem Kalinli", "background": "神经网络剪枝为多语言自动语音识别（ASR）模型压缩提供了有效的方法，但每次语言都需要经历多轮剪枝和重新训练，存在效率低下的问题。现有方法在目标是稀疏单语言模型时表现良好，但在联合训练单个稀疏多语言模型时却不尽如人意。研究需要特定语言的剪枝，增加了复杂性和计算成本。", "innovation": "提出了一种自适应遮罩方法，在两种场景下用于有效剪枝多语言ASR模型，生成稀疏单语言模型或稀疏多语言模型（称为动态ASR路径）。该方法动态适应子网络，避免了过早决定固定的子网络结构，且能够在不同初始子网络初始化中发现并训练更好的子网络（路径），减少针对不同语言的剪枝需求，提高了剪枝效率和效果。", "conclusion": "与现有的剪枝方法相比，该方法在目标稀疏单语言模型时表现出色，同时通过自适应剪枝方式减少了对特定语言剪枝的需求，提升了多语言模型的剪枝效率。这种方法不仅改善了剪枝效能，而且简化了模型调整过程，适用于多种应用场景。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.18450", "html_url": "https://arxiv.org/abs/2310.18450", "title": "MixRep: 隐层表示Mixup在低资源语音识别中的应用", "title_en": "MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition", "authors": "Jiamin Xie,John H.L. Hansen", "background": "本文讨论了一种针对低资源语音识别（ASR）的简单且有效的方法——MixRep。现有的方法如MixSpeech存在局限性，MixRep扩展了这一方法，通过混合神经网络隐藏表征的特征维度进行数据增强。研究还提出了一种在输入的时间轴上加入正则化的混合策略，显示了混合方法和时间轴正则化的互补性。该方法被应用至端到端LAS模型中的Conformer编码器，使用联合CTC损失进行训练，实验数据来自WSJ和SWB数据集，涵盖了阅读和电话对话。实验结果表明，MixRep在低资源ASR中超出其他正则化方法，并且在与强SpecAugment基线相比时，在eval92集合和Callhome部分的eval'2000集合上分别实现了6.5%和6.7%的WER相对降低。", "innovation": "提出了一种新的数据增强策略—MixRep，它基于mixup对隐藏表征进行插值，可以应用于神经网络输入的声学特征以及每层的输出。进一步提出了一种结合mixup和沿输入的时间轴正则化的新方法，显示其互补性。并与现有的SpecAugment基线进行对比，证明其在低资源ASR中的优越性。", "conclusion": "MixRep在低资源ASR中表现出显著的效果，相较于其他正则化方法，MixRep在实验数据集上取得了更好的较竞品WER降低的成果。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14774", "html_url": "https://arxiv.org/abs/2506.14774", "title": "MedSyn: 人类与AI协作提升诊断", "title_en": "MedSyn: Enhancing Diagnostics with Human-AI Collaboration", "authors": "Burcu Sayin,Ipek Baris Schlicht,Ngoc Vo Hong,Sara Allievi,Jacopo Staiano,Pasquale Minervini,Andrea Passerini", "background": "临床决策本质上是复杂的，常常受到认知偏差、信息不完整以及案例模糊性的影响。大型语言模型（LLMs）已有潜力作为支持临床决策的工具，但它们通常的单次或有限交互使用方式可能忽略了现实医学实践的复杂性。本作中，我们提出了一种以人为本的AI混合框架MedSyn，其中医生和LLMs通过多步骤、互动对话来细化诊断和治疗决策。与静态的决策支持工具不同，MedSyn允许动态交流，使医生能够挑战LLM的建议，同时LLM则突出其他视角。", "innovation": "提出了MedSyn混合框架，该框架融合了医生和大型语言模型（LLMs）的能力，通过多步骤、互动对话来细化诊断和治疗决策。这种框架让医生能够挑战LLM的建议，同时LLM突出其他视角，实现动态交流。通过模拟医生-LLM互动，评估开源LLMs作为医生助手的潜力。结果表明，开源LLMs在提升诊断准确性方面有潜力成为医生助手。", "conclusion": "开源LLMs有潜力成为医生助手，提升诊断准确性。未来的研究将涉及真实医生的互动，进一步验证MedSyn在诊断准确性和患者结果方面的有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14775", "html_url": "https://arxiv.org/abs/2506.14775", "title": "看见我的意思吗？CUE：理解解释的认知模型", "title_en": "See What I Mean? CUE: A Cognitive Model of Understanding Explanations", "authors": "Tobias Labarta,Nhi Hoang,Katharina Weitz,Wojciech Samek,Sebastian Lapuschkin,Leander Weber", "background": "随着机器学习系统在关键决策中的应用越来越广泛，人们对于可以被人类理解的解释的需求也在增长。当前对可解释AI（XAI）的评估往往侧重于技术的准确性，而忽视了认知可访问性，这对用户的影响尤为明显，尤其是在视觉障碍用户群体中。研究发现，解释的可理解性与视觉感知（清晰度）、理解能力（阅读性）和解释能力（解释性）密切相关。通过一项试验性研究验证了这些观点，研究发现，不同颜色映射（BWR, Cividis, Coolwarm）下的热图在任务绩效上类似，但对视觉障碍用户的自信心和努力表现出更低的影响。这种结果质疑了关于感知优化的假设，并强调了自适应XAI界面的必要性。该研究结果支持CUE模型，证明改变解释的可读性会直接影响其理解性。", "innovation": "本文提出了CUE模型，它将解释的属性与认知过程相关联，包括可读性（感知）、阅读性（理解）和解释性（解释）。该模型通过实验证明，优化颜色映射虽然在技术上可能有用，但对于视觉障碍用户来说，有时甚至会恶化对解释的理解。这种发现挑战了感知优化的假设，并支持了可适应XAI界面的需求。该研究还贡献了（1）一个正式的认知模型来描述解释的理解过程，（2）一个整合了以人类为中心的解释属性的定义，（3）支持可访问和用户定制的XAI实验结果。", "conclusion": "研究表明，通过改变解释的可读性可以影响其理解性。该研究贡献了一个正式的认知模型来理解解释，定义了以人类为中心的解释属性，并通过实验支持了可访问和用户定制XAI的重要性。这些发现挑战了感知优化的假设，并强调了需要自适应XAI界面来提高用户，特别是视觉障碍用户群体的理解能力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14777", "html_url": "https://arxiv.org/abs/2506.14777", "title": "WebXAII：研究人机XAI交互的开源网络框架", "title_en": "WebXAII: an open-source web framework to study human-XAI interaction", "authors": "Jules Leguy,Pierre-Antoine Jean,Felipe Torres Figueroa,Sébastien Harispe", "background": "随着AI（特别是机器学习）在各种应用中的广泛应用，XAI（可解释的人工智能）领域的研究迅速发展。研究者在探索人类与XAI系统的交互时，通常会自行开发特定的用户界面。然而，这些界面往往不与研究结果一同分享，这限制了它们的再利用性和实验的可复现性。", "innovation": "本文介绍的WebXAII是一个开源的网络框架，旨在简化人类与XAI系统的交互研究。它设计成能够涵盖完整实验协议，可以向人类参与者展示实验的所有方面并记录他们的反应。实验协议被翻译成一种通用视图和模块的复合架构，提供了很大的灵活性，该架构可以通过结构化的配置文件定义，只需极少的编程技能即可实现协议。通过复制文献中的一项先进研究的协议，证明了WebXAII的有效性。", "conclusion": "WebXAII可用作研究人类与XAI交互的有效工具，解决了现有研究界面互不兼容、难以复现的问题，为研究人员提供了灵活且易于使用的平台。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14786", "html_url": "https://arxiv.org/abs/2506.14786", "title": "PIPE: 物理导向的空间编码以实现卫星图像与时间序列的对齐", "title_en": "PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series", "authors": "Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau", "background": "多模态时间序列预测在诸多领域中被认为是基础性的，例如在气候科学研究中，利用卫星图像和数值数据预测台风。然而，现有的多模态方法主要依赖文本数据来辅助时间序列预测，而忽略了时间序列数据集中的视觉数据。此外，现有的模型难以有效捕捉视觉数据（如卫星图像）中的物理信息，特别是在时间及地理空间上下文方面的信息，这超出了简单图像的范畴。因此，本研究旨在填补这一空白，提出了一种名为物理导向的空间编码（PIPE）的轻量级方法，该方法将物理信息嵌入到视觉语言模型中。", "innovation": "PIPE 引入了两个关键创新：（1）一种将物理信息映射到位置ID的物理导向位置索引方案；（2）一种变体频率位置编码机制，用于对物理变量的频率信息以及嵌入空间中令牌的顺序编码。通过保留两者的信息，PIPE 显著提高了多模态对齐和预测准确性。通过在最具代表性和最大规模的开放式卫星图像数据集上的实验，PIPE 在深度学习预测和气候领域方法中均实现了领先的性能，且在台风强度预测方面相比之前的工作提升了12%的性能。", "conclusion": "通过在最具代表性和最大规模的开放式卫星图像数据集上的实验证明，PIPE 在深度学习预测和气候领域方法中均实现了领先的性能，显著提高了台风强度预测的准确性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14787", "html_url": "https://arxiv.org/abs/2506.14787", "title": "多层存储系统中拓扑感知且高度通用的深度强化学习方法以提高高效的取货效率", "title_en": "Topology-Aware and Highly Generalizable Deep Reinforcement Learning for Efficient Retrieval in Multi-Deep Storage Systems", "authors": "Funing Li,Yuan Tian,Ruben Noortwyck,Jifeng Zhou,Liming Kuang,Robert Schulz", "background": "在现代工业和物流环境中，快速配送服务的快速扩张增加了对高效率与高密度结合的存储系统的需求。多层自主车辆存储和检索系统（AVS/RS）提供了一种提高存储密度的可行方案，但在取货操作中遇到显著挑战，受阻于通道堵塞。现有解决方法仅针对同质物品进行存储，限制了多层存储系统的灵活性和适应性。因此，提出了一种基于深度强化学习的框架，针对具有异构物品配置的多层存储系统中的取货问题。该框架的特点是每个物品都有一个特定的截止日期，目标是将总延迟降到最低。通过引入基于图的状态表示和新型神经网络架构（结合Graph Neural Network与Transformer模型）来有效捕捉系统的拓扑结构，该方法具备广泛的应用性，能适应各种布局的存储系统。广泛的数值实验表明，提出的神经网络架构及训练的代理在优化取货延迟方面表现出优越性，优于启发式方法。", "innovation": "提出了基于深度强化学习的框架，用于解决多层存储系统中异构物品配置下的取货问题。通过引入基于图的状态表示和结合Graph Neural Network与Transformer模型的新型神经网络架构来提高取货效率。框架能够有效应对通道堵塞问题，并能够适应不同布局的多层存储系统。", "conclusion": "提出的深度强化学习框架在处理多层存储系统中的取货问题中表现出优越性，通过优化物品的优先级分配，显著减少了取货的总延迟，优于传统的启发式方法。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14794", "html_url": "https://arxiv.org/abs/2506.14794", "title": "专家集合：构建具有 emergent 和可适应行为的 Chimera 大型语言模型变体的线性时间方法", "title_en": "Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors", "authors": "Henrik Klagges,Robert Dahlke,Fabian Klemm,Benjamin Merkel,Daniel Klingmann,David A. Reiss,Dan Zecha", "background": "在预训练期间计算一个8位权重需要$10^{13}$-$10^{15}$FLOPs，这非常昂贵且显得效率低下。为了更好地利用对预训练模型的巨大投资，作者开发了一种新的“专家集合”（AoE）构造方法，以线性时间创建现有专家混合（Mixture-of-Experts）母模型的有能力子变体。模型权重张量个体进行插值，允许增强或抑制父母的语义特征。通过调整来自父母模型的权重比例，观察到一些AoE子模型的特性逐渐改变，而其他行为特征则显示出突然的转变。几乎所有生成的模型都是可操作的且有能力的，这使得搜索模型空间变得容易。", "innovation": "开发了新的“专家集合”（AoE）构造方法，以线性时间创建现有专家混合（Mixture-of-Experts）母模型的有能力子变体。通过个体插值模型权重张量，可以增强或抑制父母的语义特征，同时调整来自父母模型的权重比例以观察到AoE子模型特性的渐变变化和突变转变。这种方法使得生成的模型几乎都是功能完整的，从而简化了模型空间的搜索。在没有任何微调或蒸馏的情况下构建了DeepSeek R1T“Chimera”模型，它是将DeepSeek V3-0324和R1模型变体的开放权重组合而成的671B模型。尽管继承了R1的路由专家张量，Chimera仍然达到了R1级别的智能，同时比R1少使用约40%的输出令牌，接近V3的速度。", "conclusion": "近每一个生成的模型都是功能性的且有能力的，使得模型空间的搜索变得容易。Chimera由于其紧凑且有条理的推理能力，表现出比其母模型更出色的性能，且在没有进行任何微调或蒸馏的前提下构建。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14795", "html_url": "https://arxiv.org/abs/2506.14795", "title": "风能预测中QNN架构比较分析：特征映射和参数配置", "title_en": "Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations", "authors": "Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu", "background": "量子机器学习（QML）是量子计算与机器学习交叉领域的一项新兴技术，旨在通过利用量子力学的基本原理如纠缠和叠加来增强经典的机器学习方法。然而，人们对QML的实际优势持怀疑态度，主要是由于当前噪声中等规模量子（NISQ）设备的限制。这项研究通过详细评估量子神经网络（QNNs）——受人工神经网络（ANNs）启发的量子替代方案，展示了它们在预测任务中的有效性，与经典方法相比更具优势。", "innovation": "研究系统地构建并评估了12种不同的QNN配置，结合了两种独特的量子特征映射和六种不同的纠缠策略来设计量子态。实验结果表明，使用Z特征映射的QNN在仅使用四个输入参数预测风功率输出时，准确率高达93%。这些发现表明，QNN在预测任务中优于经典方法，强调了QML在实际应用中的潜力。", "conclusion": "研究表明，QNN在预测任务中表现优于经典方法，尤其是在风能预测方面展示了高精度，进一步证明了QML的实际应用价值。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14796", "html_url": "https://arxiv.org/abs/2506.14796", "title": "PFMBench: 蛋白质基础模型基准", "title_en": "PFMBench: Protein Foundation Model Benchmark", "authors": "Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li", "background": "近年来，蛋白质科学与工程取得了重大进展，但该领域缺乏一个全面的基准来公平评估和深入理解蛋白质基础模型。尽管自ESM-1B以来，出现了许多蛋白质基础模型，每个模型都有独特的数据集和方法，但现有的评估往往局限于特定任务，无法提供对广泛泛化和限制的深入了解。研究人员难以理解不同任务之间的关系，评估当前模型在这些任务上的表现，以及制定开发新基础模型的标准。", "innovation": "本文介绍了PFMBench，这是一种全面的基准，通过跨38个任务（涵盖8个关键领域）评估17个最先进的蛋白质基础模型，揭示了任务之间的内在关联，识别出表现最佳的模型，并提供了一套简化的评估协议。", "conclusion": "PFMBench通过对17个最先进的蛋白质基础模型在38个任务上的数百次实验，展示了任务之间的固有关联，确定了表现最佳的模型，并提供了一套简化的评估协议。相关代码可在GitHub上获得。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14797", "html_url": "https://arxiv.org/abs/2506.14797", "title": "由语义性限定：调控泛化与识别权衡的通用法则", "title_en": "Bound by semanticity: universal laws governing the generalization-identification tradeoff", "authors": "Marco Nurisso,Jesseba Fernando,Raj Deshpande,Alan Perotti,Raja Marjieh,Steven M. Frankland,Richard L. Lewis,Taylor W. Webb,Declan Campbell,Francesco Vaccarino,Jonathan D. Cohen,Giovanni Petri", "background": "智能系统需要同时构建结构化的内部表示来支持广泛的一般化，以及选择性的输入身份保持。然而，这一要求在实践中并不会被轻易满足，因为任何模型之间的表示相似度随着有限语义分辨率ε而衰减，这使得正确泛化概率和识别概率之间的权衡受到根本限制。", "innovation": "文章提出了关于泛化与识别权衡的普遍法则。作者揭示了对于任何具有有限语义分辨率的模型，其正确泛化概率和识别概率可以表示成非依赖于输入空间几何的普塔洛夫前沿的闭式表达式。该研究还扩展到噪声不均匀空间和n>2输入，并预测了多输入处理能力的急剧1/n坍缩及正确泛化概率的非单调最优值。作者利用端对端训练的ReLU神经网络证明了这些法则，并且这些法则在卷积神经网络和最先进的视觉-语言模型中同样适用，说明有限分辨率的相关是在形式上是根本的存在约束而非玩具模型的艺术制品。", "conclusion": "文章提供了泛化与识别权衡的具体理论，并阐明了语义分辨率如何影响深度网络及其大脑的表示能力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14798", "html_url": "https://arxiv.org/abs/2506.14798", "title": "MODS: 多源观测条件扩散模型用于气象状态缩放", "title_en": "MODS: Multi-source Observations Conditional Diffusion Model for Meteorological State Downscaling", "authors": "Siwei Tu,Jingyi Xu,Weidong Yang,Lei Bai,Ben Fei", "background": "准确获取高分辨率地表气象条件对于气象变量的预报和模拟至关重要。直接使用空间插值方法从低分辨率网格字段推导特定位置的气象值往往与实际情况存在较大偏差。现有的降尺度方法主要依赖地基静止气象卫星和ERA5变量之间的耦合关系，但仅使用地基静止气象卫星的亮度温度数据无法全面捕捉ERA5地图中所有气象变量的变化。因此，本文提出Multi-source Observation Down-Scaling Model（MODS），一种条件扩散模型，综合考虑来自多颗静止气象卫星（GridSat）、极地轨道气象卫星（AMSU-A、HIRS和MHS）和地形数据（GEBCO）的观测数据，并在ERA5再分析数据集上进行预训练，通过多源交叉注意力模块提取多种条件输入的潜在特征并融合到ERA5地图中，从而生成更接近真实世界的气象状态。", "innovation": "本文提出的Multi-source Observation Down-Scaling Model（MODS）通过将来自多颗静止气象卫星（GridSat）、极地轨道气象卫星（AMSU-A、HIRS和MHS）和地形数据（GEBCO）的多种观测数据融合，利用再分析数据与多源大气变量之间的反演关系，生成更符合实际情况的气象状态。MODS在插值过程中通过结合低分辨率ERA5地图和站级气象数据增强降尺度一致性。", "conclusion": "实验结果表明，当将ERA5地图缩放至6.25公里分辨率时，MODS这种多源观测条件扩散模型能够实现更高的保真度。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14799", "html_url": "https://arxiv.org/abs/2506.14799", "title": "使用多模态基础模型分析媒体内容中的角色表示：有效性与信任度", "title_en": "Analyzing Character Representation in Media Content using Multimodal Foundation Model: Effectiveness and Trust", "authors": "Evdoxia Taka,Debadyuti Bhattacharya,Joanne Garde-Hansen,Sanjay Sharma,Tanaya Guha", "background": "近期AI技术的发展使得可以大规模自动化地分析复杂媒体内容，并生成有关角色表示（沿性别和年龄等维度）的具体行动见解。过去的研究侧重于使用各种机器学习模型从音频、视频和文本中衡量角色表示，但没有将观众纳入考量。然而，即使已知整体的性别和年龄分布，这些数据对普通公众有用吗？他们是否信任AI模型生成的数字？", "innovation": "本文通过用户研究提出了一种基于对比语言-图像预训练（CLIP）的新型AI角色表示与可视化工具。该工具用于分析视觉屏幕数据以衡量角色在年龄和性别维度上的表示情况，并设计了适合普通受众的可视化方式。研究进一步在精心选择的电影中展示了AI生成的结果，并通过用户研究验证了这些结果的有效性和信任度。参与者表示能够理解可视化中的分析，但希望有更详细的信息以包含更多的人口统计类别和角色上下文信息。参与者对AI生成性别和年龄模型的信任度中等，尽管他们接受在该语境下使用AI。", "conclusion": "研究工具连同代码、基准测试和用户研究数据可在以下链接找到：this https URL。该研究指出，尽管AI生成的性别和年龄模型受到了一定的信任，但为了提高工具的实用性和准确性，未来仍需改进细节和包含更多的人口统计信息。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14802", "html_url": "https://arxiv.org/abs/2506.14802", "title": "ss-Mamba: 联合语义插值及其可解释调和网络的时间选择型状态空间模型", "title_en": "ss-Mamba: Semantic-Spline Selective State-Space Model", "authors": "Zuochen Ye", "background": "该研究的背景在于现有的时间序列预测模型虽然在性能上有所提升，但往往面临着计算复杂度过高或泛化能力不足的问题。因此，研究者希望通过引入新的模型架构来提高预测准确性、泛化能力和可解释性，同时减少计算复杂度。", "innovation": "研究的创新点在于提出了一种名为ss-Mamba的新模型，该模型结合了语义感知嵌入和自适应样条函数_temporal编码，在选择性状态空间建模框架中提升了时间序列预测的能力。该模型采用了Mamba选择性状态空间模型的高效替代方案，实现了线性时间复杂度，与传统的二次复杂度相比显著降低了计算复杂度。此外，基于语义指数嵌入和Spline基Kolmogorov-Arnold Networks（KAN），ss-Mamba能够动态且可解释地捕捉复杂季节性和非稳态的时间效应。", "conclusion": "实验结果表明，ss-Mamba模型在准确度、稳健性和可解释性方面均优于传统的基于Transformer的时间序列预测模型。该研究证明了ss-Mamba不仅能够作为传统Transformer模型的灵活且计算高效的替代方案，还能够在未见过的数据上展现出有效的泛化能力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14805", "html_url": "https://arxiv.org/abs/2506.14805", "title": "Argus 检查：多模态大型语言模型具备潘诺普特斯之眼吗？", "title_en": "Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?", "authors": "Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang", "background": "随着多模态大型语言模型（MLLMs）的不断演进，它们的认知和推理能力取得了显著进步。然而，它们在视觉细节感知和常识因果推理方面仍然面临挑战。本文介绍了Argus Inspection基准测试，这个多模态基准分为两个难度级别，强调详细的视觉识别同时结合现实世界的常识理解来评估因果推理能力。", "innovation": "本研究提出了Eye of Panoptes框架，结合二元参数化Sigmoid度量和指示函数，以更全面地评估MLLMs在意见导向推理任务中的回应。实验结果显示，在26个主流MLLMs中，视觉细粒度推理的最高性能仅为0.46，表明有巨大的提升潜力。", "conclusion": "本研究为MLLMs的持续改进提供了有价值的视角。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14813", "html_url": "https://arxiv.org/abs/2506.14813", "title": "使用自働主动检查在深度学习训练中捕获隐式错误", "title_en": "Training with Confidence: Catching Silent Errors in Deep Learning Training with Automated Proactive Checks", "authors": "Yuxuan Jiang,Ziming Zhou,Boyu Xu,Beijie Liu,Runhui Xu,Peng Huang", "background": "深度学习模型的训练是一个复杂的过程，容易产生难以检测和诊断的隐形错误。现有方法对于这些问题缺乏有效的预防和检测手段，因此需要开发新的解决方案来解决这些问题。", "innovation": "本文提出了TRAINCHECK框架，这是一种主动检测深度学习训练过程中隐形错误的方法。该框架能够自动推断出适用于训练过程的不变式，并在训练过程中主动检测这些隐形错误，同时提供调试帮助。", "conclusion": "通过再现具有不同根本原因的20个真实世界的隐形训练错误，对 TRAINCHECK 进行了评估。实验结果表明，TRAINCHECK能够在单个训练迭代中检测出18个错误，并发现了6个在流行训练库中导致隐形错误的未知漏洞。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14817", "html_url": "https://arxiv.org/abs/2506.14817", "title": "下一代冲突预测：通过时空学习释放预测模式", "title_en": "Next-Generation Conflict Forecasting: Unleashing Predictive Patterns through Spatiotemporal Learning", "authors": "Simon P. von der Maase", "background": "高空间和时间分辨率下预测暴力冲突仍然是研究人员和政策制定者面临的主要挑战。本研究提出了一种新颖的神经网络架构，用于前瞻性预测三种不同类型的暴力行为（基于国家的行为、非国家行为和单边行为），在亚国家（priogrid-月）级别上，最多可提前36个月进行预测。该模型同时执行分类和回归任务，产生了未来事件的概率估计和预期规模。实验表明，该模型在所有任务上都达到了最先进的性能，并生成了近似预测后验分布，以量化预测不确定性。该架构基于蒙特卡洛丢弃长短期记忆（LSTM）U-Net，结合卷积层捕获空间依赖性以及循环结构来建模时间动态。", "innovation": "该研究通过在蒙特卡洛丢弃LSTM U-Net架构中整合卷积层和循环结构实现了时空学习，不需要手动特征工程，仅依靠历史冲突数据。这种方法使模型能够自主学习暴力冲突背后的复杂时空模式。此外，该模型的扩展能力强，能够集成额外数据源并联合预测辅助变量，成为一个有前途的早期预警系统、人道主义应对规划和基于证据的和平建设工具。", "conclusion": "该研究提出的新一代冲突预测模型，通过时空学习释放了预测模式，不仅在预测性能上达到了最先进的水平，还在预测扩展性方面表现出色。该模型具有提升早期预警、人道援助规划和基于证据的和平建设的潜力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14821", "html_url": "https://arxiv.org/abs/2506.14821", "title": "在资源约束条件下增强VLMs使用工具进行详细的视觉推理", "title_en": "Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints", "authors": "Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya", "background": "尽管大型模型在推理能力方面取得了巨大进展，视觉语言模型（VLMs）在处理详细的视觉推理任务时仍然存在困难，特别是在计算资源有限的情况下。现有的方法难以有效利用外部工具来补充视觉信息，从而提高模型的性能和准确性。这篇论文旨在解决这个问题，通过改进模型训练方式来提升其在资源受限条件下的详细视觉推理能力。", "innovation": "本文提出了一种新的方法，通过Group Relative Policy Optimization (GRPO)学习等技术搭配简单的奖励结构和简化工具调用接口，结合额外为工具调用结果分配标记以及训练数据集中过度呈现视觉难题的例子，从而改进了视觉问答（VQA）任务中的表现。这种方法使得模型能够更有效地利用外部工具提供的详细视觉信息，从而在某些VQA任务中超越了基线模型的性能。", "conclusion": "本文提出的方法通过优化模型训练策略和合理利用外部工具，显著提升了视觉语言模型在资源受限条件下的详细视觉推理能力，尤其是在视觉难题上的表现更为出色，为视觉问答等任务的进一步优化指明了方向。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14823", "html_url": "https://arxiv.org/abs/2506.14823", "title": "ViLLa：一种用于动物监测的神经符号方法", "title_en": "ViLLa: A Neuro-Symbolic approach for Animal Monitoring", "authors": "Harsha Koduri", "background": "在自然环境中监控动物种群需要能解释视觉数据和理解人类语言查询的系统。现有的监控系统通常侧重于单一任务，缺乏模块化和透明性，难以准确地回答关于动物数量、位置的问题。", "innovation": "ViLLa是一种神经符号框架，它集成了视觉检测模块、语言解析器和符号推理层，能够将视觉检测与逻辑推理相结合，以解答自然语言查询。ViLLa通过分离感知、理解和推理，提供了模块化和透明性，能够在不同动物图像任务中准确回答关于动物数量和位置的问题，并且能够将视觉内容与结构化的人工可理解查询关联起来。", "conclusion": "ViLLa 在动物监测任务中展示了从视觉数据到结构化查询反应的能力，该系统能够准确地生成关于动物存在的事实和位置的答案。与端对端的黑盒模型不同，ViLLa 提供了透明性和模块化性，使得系统更加易于理解和应用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14824", "html_url": "https://arxiv.org/abs/2506.14824", "title": "FedNano: 向预训练多模态大型语言模型的轻量级联邦微调迈进", "title_en": "FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models", "authors": "Yao Zhang,Hewei Gao,Haokun Chen,Weiguo Li,Yunpu Ma,Volker Tresp", "background": "多模态大型语言模型（MLLMs）在多模态推理和跨模态检索等任务中表现出色，但在现实场景中的部署却因分布式多模态数据和严格的隐私要求面临挑战。联邦学习（FL）通过在不集中数据的情况下实现协作模型训练提供了一个解决方案。然而，将FL应用于MLLMs带来了重大挑战，包括高额的计算需求、有限的客户端容量、大量的通信成本和客户端数据的异质性。现有的FL方法假定客户端部署完整的模型，这一假设由于大型MLLMs的庞大尺寸和通信需求被打破。这些限制催生了FedNano，该方法旨在集中LLM在服务器上，并引入NanoEdge进行客户端特定的适应，这显著减少了客户端的存储需求和通信开销，实现隐私保护下的大规模、分布式多模态AI系统的构建。", "innovation": "FedNano框架通过集中LLM在服务器上，并引入NanoEdge模块实现轻量级客户端特定的适应，采用模态特定编码器、连接器和可训练的NanoAdapters，降低内存开销并大幅减少通信成本。它仅传输紧凑的NanoAdapter更新，能够处理异质客户端数据和资源限制，同时保护隐私。实验证明，FedNano比之前的FL基线方法更出色，成功桥接了大规模MLLMs与FL实施之间的差距，开启了可扩展的、分散式的多模态AI系统的新时代。", "conclusion": "FedNano通过将大规模LLM集中部署在服务器上，并利用NanoEdge模块进行高效的客户端特定适应，有效解决了MLLMs在联邦学习中的部署挑战，实现了高效率、小开销的多模态AI系统的构建，展示了在保护隐私的同时进行大规模、分布式模型训练的可能性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14825", "html_url": "https://arxiv.org/abs/2506.14825", "title": "GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction", "title_en": "GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction", "authors": "Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong", "background": "针对自动驾驶中的3D语义占用预测任务，现有3D高斯分裂(3DGS)方法存在两个关键问题：一是统一特征聚合忽略了同类及不同区域之间的语义关联，二是由于MLP迭代优化缺乏几何约束导致边界模糊不清的问题。", "innovation": "提出了一种名为GraphGSOcc的新框架，该框架结合了语义和几何图变换器以处理基于3D高斯分裂的占用预测。引入了双高斯图注意力机制，动态构建了两种图结构：几何图根据高斯姿态自适应地计算KNN搜索半径，实现了大范围高斯体聚合更广泛邻域的特征，同时紧凑的高斯体专注于局部几何一致性；语义图通过余弦相似度保留高度相关节点以明确编码实例间的语义关系。结合多尺度图注意力框架，低层细粒度注意力优化边界细节，而高层粗粒度注意力建模对象级拓扑结构。", "conclusion": "在SurroundOcc数据集上的实验结果表明，内存使用减少至6.1 GB，并实现了24.10%的mIoU，相较于GaussianWorld，mIoU提升了1.97%，内存减少了13.7%。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14826", "html_url": "https://arxiv.org/abs/2506.14826", "title": "基于协同兴趣的图学习在群组识别中的应用", "title_en": "Collaborative Interest-aware Graph Learning for Group Identification", "authors": "Rui Zhao,Beihong Jin,Beibei Li,Yiyuan Zheng", "background": "随着社交媒体的普及，越来越多的用户参与在线社交平台上的群体活动，增加了对群组识别（GI）的需求，即推荐适合用户的群体。研究发现，用户受群体层和项目层兴趣的双重影响，并且这两种兴趣会呈协同进化的关系：加入新群体可以扩展用户的兴趣项目，进一步促使他们加入更多新群体，最终两种兴趣会动态趋于一致。现有的GI方法未能很好地建模这种协同进化关系，忽略了群体层兴趣对项目层兴趣的提升作用，导致跨层次兴趣对齐时出现假阴性样本等问题。", "innovation": "为了全面建模双层用户兴趣的协同进化关系，提出了一种名为CI4GI的模型，该模型利用群体平均兴趣来增强用户兴趣项目的维度，同时通过用户兴趣分布的距离来优化负样本的识别，减少跨层次兴趣对齐时的假阴性样本的干扰。", "conclusion": "在三个真实数据集上的实验结果显示，CI4GI显著优于现有最先进模型。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14827", "html_url": "https://arxiv.org/abs/2506.14827", "title": "DAVID-XR1: 使用可解释推理检测生成的视频", "title_en": "DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning", "authors": "Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang", "background": "随着AI生成的视频在媒体平台上的普及，可靠地区分合成内容与真实视频变得至关重要且必不可少。现有的方法主要将这一挑战视为一个二分类任务，无法提供模型识别视频为AI生成的原因或者具体位置的洞察。然而，核心挑战不仅在于检测细微的特征，更在于提供详细的、令人信服的证据，以说服审计人员和最终用户。", "innovation": "我们引入了DAVID-X，这是第一个将AI生成的视频与详细的缺陷级别、时空注释和书面理由相结合的数据集。基于这一丰富的注释，我们提出了DAVID-XR1，一种视频-语言模型，能够提供可解释的视觉推理链，包括缺陷分类、时空定位和自然语言解释。这种方法将AI生成视频的检测从不透明的黑盒决策过程转变为一种透明、可验证的诊断过程。我们展示了在我们紧凑的数据集上微调通用主干，并结合链式推理蒸馏，能够实现对多种生成器和生成模式的强大泛化。", "conclusion": "我们的结果突显了可解释检测方法在信任地识别AI生成的视频内容方面的潜力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14829", "html_url": "https://arxiv.org/abs/2506.14829", "title": "在社会影响研究中实现影响的难度：实地视角下的挑战与机遇", "title_en": "The Hardness of Achieving Impact in AI for Social Impact Research: A Ground-Level View of Challenges & Opportunities", "authors": "Aditya Majumdar,Wenbo Zhang,Kashvi Prawal,Amulya Yadav", "background": "在尝试解决联合国可持续发展目标（SDGs）方面，基于人工智能的社会影响力（AI4SI）项目关注利用人工智能技术来解决社会问题，例如医疗保健、社会正义等。尽管对AI4SI的兴趣日益增长，但在实际操作中实现具体的、有形的影响仍然是一个巨大的挑战。例如，识别并吸引有动力的合作者来共同设计和部署基于AI的解决方案具有挑战性，即使建立了这些合作关系，许多AI4SI项目大多未能越过概念验证阶段，无法转换为大规模生产的解决方案。此外，AI4SI研究人员面临的独特挑战在更广泛的AI社区中并不总是得到充分认可，这些工作有时被视为主要的应用研究，与核心AI场合所强调的创新标准不完全一致。因此，本研究旨在通过诊断妨碍AI4SI伙伴关系实现实际社会影响的多种因素，照亮AI4SI研究中所面临的多样性挑战。", "innovation": "本研究通过半结构化的访谈，结合作者自身的实际经验和来自六位领先AI4SI研究人员的数据，来理解在开发和部署具有社会影响力的AI解决方案过程中日常面临的困难。通过主题分析，识别出结构和组织、沟通、协作和操作挑战作为部署的主要障碍。尽管没有简单的解决方案，但本研究从这些访谈和他们自己的工作经验中总结出最佳实践和切实可行的战略。此研究旨在为希望更有效地参与社会影响力AI合作的AI4SI研究人员和合作伙伴组织提供一份实用的参考指南。", "conclusion": "本研究旨在通过揭示AI4SI研究中遇到的广泛挑战，提供一个实用的参考指南，帮助AI4SI研究人员和合作伙伴组织更好地进行社会影响力的AI合作，最终实现实质性社会影响。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14830", "html_url": "https://arxiv.org/abs/2506.14830", "title": "基于多头注意力机制优化双向门控循环单元单元的SSD健康状态分类模型", "title_en": "Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model", "authors": "Zhizhao Wen,Ruoxin Zhang,Chao Wang", "background": "SSD健康状态预测在保障数据可靠性方面扮演着关键角色，但是现有的健康状态分类模型在准确性和稳定性上还有提升空间。因此，急需一种能够提升存储设备健康分类准确性和稳定性的新方法。为了克服传统模型的泛化瓶颈，本文研究了一种结合多头注意力机制的BiGRU-MHA模型，旨在通过引入多头注意力机制和时间特征提取能力，提升存储设备健康状态分类的性能和可靠性。", "innovation": "提出了一种融合多头注意力机制的Hybrid BiGRU-MHA模型。该模型通过双向门控循环单元（BiGRU）网络的特点，能够同时捕捉SSD退化特征的正向和反向依赖关系。同时，多头注意力机制动态分配特征权重，提高了模型对关键健康指标的敏感度。实验结果显示，在训练集和测试集上分别实现了92.70%和92.44%的分类精度，且在ROC曲线下的面积（AUC）为0.94，表明模型具有优秀的泛化能力和二元分类性能。此外，该工作提出了基于多头注意力机制优化双向门控循环单元单元的新型技术方法，为工业级存储系统的预防性维护提供了可验证的方法，对降低数据丢失风险和支持智能决策具有实际意义。", "conclusion": "本研究提出的一种融合多头注意力机制的Hybrid BiGRU-MHA模型，在SSD健康状态分类上取得了较高精度，并且其优秀的泛化能力和强大的二元分类性能，有效解决了传统模型的泛化瓶颈问题，为工业级存储系统的维护提供了可验证的方法，支持了构建可靠存储系统的技术创新，在云数据计算中心和边缘存储环境中具有实际应用价值。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14832", "html_url": "https://arxiv.org/abs/2506.14832", "title": "ArchShapeNet：评估建筑形状的可解释3D-CNN框架", "title_en": "ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes", "authors": "Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu", "background": "在当代建筑设计中，设计需求的复杂性和多样性促使生成插件工具成为快速生成初步概念和探索新颖三维形态的关键工具。然而，客观分析人类设计与机器生成的三维形态之间的差异仍然是一个挑战，限制了我们对其各自优势的理解，阻碍了生成工具的发展。为解决此问题，本文构建了包含2000个建筑师设计的和2000个Evomass生成的三维形态的ArchForms-4000数据集；提出了针对建筑形体分类和分析设计的ArchShapeNet，该网络含有一个显著性模块，可以突出关键空间特征，与建筑推理一致；并且进行了对比实验，结果显示该模型在区分形态源方面优于人类专家，准确率为94.29%，精确率为96.2%，召回率为98.51%。", "innovation": "本文构建了包含2000个建筑师设计的和2000个机器生成的三维形态的ArchForms-4000数据集，并提出了一个名为ArchShapeNet的3D卷积神经网络。它能够对建筑形态进行分类和分析，引入了显著性模块，以突出关键空间特征，与建筑推理一致。而且，该模型在区分人类设计与机器生成的形态源方面表现出色，准确率、精确率和召回率表现优异，超过了人类专家的表现。", "conclusion": "本研究不仅突显了人类设计形态在空间组织、比例和谐与细节精细化方面的独特优势，还为未来增强生成设计工具提供了宝贵的见解。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14833", "html_url": "https://arxiv.org/abs/2506.14833", "title": "边缘设备上基于熵自适应缓冲和MobileNetV2的实时低延迟 surveillance", "title_en": "Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices", "authors": "Poojashree Chandrashekar Pankaj M Sajjanar", "background": "本文描述了一种针对资源受限环境设计的高性能低延迟视频监控系统。该系统能够处理受限资源设备（嵌入式平台）上的视频流，具有低于50ms的端到端推理延迟，并且能够维持较高的检测精度，即使在不同的光照、背景和速度条件下也表现出较好的鲁棒性。实验表明，与现有方法相比，该系统在多种关键指标上表现更优，同时也具有可扩展性、低成本和更好的数据隐私合规性，能够适应智能城市或嵌入式安全架构的要求。", "innovation": "提出了一种形式化熵自适应帧缓冲算法，并将其集成到MobileNetV2中，实现了在受限资源设备上低成本高吞吐量的视频处理，具有低延迟和高检测精度的优势。通过多种对比和消融实验验证了设计的有效性。此外，该架构具有可扩展性、低成本，并符合更严格的隐私保护要求，增强了在智能城市和嵌入式安全架构中的应用价值。", "conclusion": "本文提出的方法为资源受限环境下的视频监控提供了高效和可靠的解决方案，系统在实时性、低延迟、鲁棒性和数据隐私合规性方面表现出色，特别适用于智能城市或嵌入式安全架构中。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14834", "html_url": "https://arxiv.org/abs/2506.14834", "title": "在边缘设备上部署和评估多种深度学习模型以用于糖尿病视网膜病变检测", "title_en": "Deploying and Evaluating Multiple Deep Learning Models on Edge Devices for Diabetic Retinopathy Detection", "authors": "Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye", "background": "糖尿病视网膜病变（DR）是导致糖尿病患者视力受损的主要原因之一，全球约有34.6%的糖尿病患者受到影响，预计到2045年病例数将达到24200万。传统上，DR诊断依赖于对视网膜底片图像的手动检查，这既耗时又资源密集。", "innovation": "该研究提出了利用Edge Impulse在边缘设备上部署多个深度学习模型进行实时DR检测的新方案。通过使用预处理技术（包括扩增和标准化）对Kaggle EyePACS数据集中的超过3662张视网膜底片图像进行整理，设计并优化了多种卷积神经网络（CNN），包括MobileNet、ShuffleNet、SqueezeNet和自定义深度神经网络（DNN）。这些模型被转换为TensorFlowLite并量化为8位整数，以减少模型大小，提高推理速度，同时保持较高准确度。评估结果显示，MobileNet的准确率达到96.45%，ShuffleNet和自定义DNN在资源效率方面表现出色，适用于低端设备。", "conclusion": "边缘AI技术在医疗领域的结合提供了一种可扩展且成本效益高的早期DR检测解决方案，为资源受限和偏远医疗环境提供了及时准确的诊断。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14837", "html_url": "https://arxiv.org/abs/2506.14837", "title": "通过结构化指令改进的图表到代码生成的迭代精炼", "title_en": "Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction", "authors": "Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang", "background": "最近，多模态大规模语言模型（MLLMs）由于其强大的视觉理解能力而引起了越来越多的研究兴趣。尽管它们在各种视觉任务上取得了显著成果，但在图表到代码生成方面的表现却一直不理想。此任务要求MLLMs生成可执行代码以重现给定的图表，不仅需要精确的视觉理解，还需要将视觉元素准确转换为结构化代码。直接让MLLMs执行这一复杂任务往往效果不理想。", "innovation": "我们提出了一种基于结构化指令的迭代精炼方法{ChartIR}。首先，我们将任务分为视觉理解与代码翻译两个部分。设计了两类结构化指令：描述指令用于捕捉参考图表的视觉元素，差异指令用于描述参考图表与生成图表之间的差异。这两类指令可以将视觉特征有效转化为语言表示，从而促进后续的代码翻译过程。其次，将整个图表生成流水线分解为初期代码生成和迭代精炼两个阶段，允许对最终输出进行逐级优化。实验结果表明，与其它方法相比，本方法在开源模型Qwen2-VL和闭源模型GPT-4o上的表现更为优越。", "conclusion": "实验结果表明，与其它方法相比，我们的方法在开源模型Qwen2-VL和闭源模型GPT-4o上的表现更为优越。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14842", "html_url": "https://arxiv.org/abs/2506.14842", "title": "PictSure: 预训练嵌入对上下文学习图像分类器而言很重要", "title_en": "PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers", "authors": "Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop", "background": "在数据稀缺领域构建图像分类模型仍然繁琐，这是因为收集大量标注数据 impractical。上下文学习（ICL）在少数样本图像分类（FSIC）中被提出作为有力范式，使模型能够在没有基于梯度的适应的情况下泛化到不同领域。然而，先前的研究未能充分考虑到ICL基线FSIC管道中嵌入模型的作用。因此，当前工作提出了一种名为PictSure的ICL框架，其中嵌入模型及其架构、预训练和训练动态位于分析中心。这项研究系统地考察了不同视觉编码器类型、预训练目标和微调策略对下游FSIC性能的影响。研究表明，嵌入模型的预训练成功与否显著影响其领域的外推性能。", "innovation": "该研究首次将嵌入模型的预训练作为ICL-FSIC的关键因素进行系统分析，并提出了PictSure框架，通过改进嵌入模型的预训练和训练策略，提升了模型在不同领域的泛化能力。", "conclusion": "通过PictSure，研究在不同的域外基准测试中取得了优于现有ICL-FSIC模型的表现，同时在域内任务上保持了相近的性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14846", "html_url": "https://arxiv.org/abs/2506.14846", "title": "在卷积神经网络中寻找最优卷积核大小和维度：一种架构优化方法", "title_en": "Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach", "authors": "Shreyas Rajeev,B Sathish Babu", "background": "卷积神经网络（CNNs）中卷积核大小的选择是一个关键但常被忽视的设计决策，它影响着感受野、特征提取、计算成本和模型准确性。传统上，3×3的通用卷积核被广泛使用，但其实每个卷积层选择最适合的卷积核大小能够更好地优化模型性能。本文通过介绍一种名为Best Kernel Size Estimation Function（BKSEF）的数学基础和经过经验验证的框架，来解决这一问题。BKSEF结合了信息论、信号处理和学习理论的原则，平衡了信息增益、计算效率和准确性的提升，从而为每个卷积层提供了最佳的卷积核大小选择。", "innovation": "本文提出的BKSEF是一个数学依据和经验验证相结合的框架，用于层间最佳卷积核大小的确定。BKSEF通过整合信息论、信号处理和学习理论的原则，平衡信息增益、计算效率和准确性的提升，从而为每个卷积层提供了最佳的卷积核大小选择。研究显示，与使用传统3×3的固定卷积核相比，BKSEF指导的架构在CIFAR-10、CIFAR-100、ImageNet-lite、ChestX-ray14和GTSRB数据集上的准确率提高了3.1%，浮点运算次数（FLOPs）减少了42.8%。此外，通过实际案例研究进一步验证了该方法的有效性，包括医疗图像分类和边缘设备上的交通标志识别，证明了这种优化方法在不同应用场景下具有显著优势。", "conclusion": "本文通过BKSEF提供了一种新的方法，使得卷积核大小不再是固定的预设参数，而是可以通过优化提升模型性能的参数。BKSEF结合了理论与实践，为研究人员和开发者提供了有效的设计指南，并可以在神经架构搜索管道和实时系统中集成，为卷积神经网络优化提供了新的视角。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14851", "html_url": "https://arxiv.org/abs/2506.14851", "title": "使用概率需求建模高效服务LLM应用程序", "title_en": "Efficient Serving of LLM Applications with Probabilistic Demand Modeling", "authors": "Yifei Liu,Zuo Gan,Zhenghao Gan,Weiye Wang,Chen Chen,Yizhou Shan,Xusheng Chen,Zhenhua Han,Yifei Zhu,Shixuan Sun,Minyi Guo", "background": "大型语言模型（LLMs）的应用中包含了一系列任务，这些任务旨在通过增强的能力解决实际问题，并且这些任务在不同的后端有着多种多样的需求量。现有的服务系统将LLM应用程序的需求视为黑盒，这种处理方式会导致因不当的队列顺序和后端预热延迟而降低端到端的效率。研究发现，可以通过概率需求图（PDGraph）对LLM应用程序的需求进行一般性和准确性的建模。", "innovation": "提出了一种名为Hermes的系统，该系统利用PDGraph来高效地服务于LLM应用程序。Hermes能够应对概率性需求描述，通过应用盖特金斯策略来确定最小化平均应用程序完成时间的调度顺序。同时，Hermes还使用PDGraph模型在适当的时间预热冷后端。实验结果显示，Hermes能够有效提高应用程序的服务效率，平均完成时间减少超过70%，P95完成时间减少超过80%。", "conclusion": "Hermes通过概率需求图建模和盖特金斯策略的应用，显著提高了LLM应用程序的服务效率。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14852", "html_url": "https://arxiv.org/abs/2506.14852", "title": "通过测试时计划缓存实现基于LLM的代理成本高效服务", "title_en": "Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching", "authors": "Qizheng Zhang,Michael Wornow,Kunle Olukotun", "background": "基于LLM的代理在复杂工作流程中显示出越来越显著的能力，但由于需要广泛的规划和推理，其成本也相当高昂。现有的LLM缓存技术（如上下文缓存和语义缓存），主要是为了解决对话机器人的问题，不足以应对代理应用程序，这些应用程序的输出依赖于外部数据或环境上下文。现有的缓存方法无法适应代理应用程序的具体需求，导致高昂的服务成本。因此，需要一种新的方法来降低服务成本，同时保持性能。这种新的缓存方法需要能够从代理执行中抽取结构化的计划模板，在相似任务中存储、适应和再利用这些模板，以减少服务的开销。", "innovation": "我们提出了一种名为代理计划缓存的新方法，从代理应用程序的规划阶段中提取结构化的计划模板，并跨相似任务存储、改编和重用这些模板，以降低服务成本。与传统语义缓存不同，我们的系统在测试时从已执行代理中抽取计划模板，利用关键词提取技术匹配新请求与缓存的计划，并利用轻量级模型将这些模板适应为具有上下文的任务特定计划。这种方法通过多个现实世界的代理应用程序的评估，能够在降低成本46.62%的同时保持性能，提供了一种补充现有LLM服务基础设施的更高效解决方案", "conclusion": "我们的系统在一个46.62%的平均成本降低下保持了性能，提供了一种在不牺牲性能的前提下降低基于LLM的代理服务成本的有效方案，此方案补充了现有的LLM服务基础设施。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14854", "html_url": "https://arxiv.org/abs/2506.14854", "title": "高效的零售视频标注：面向产品和客户互动分析的稳健关键帧生成方法", "title_en": "Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis", "authors": "Varun Mannam,Zhenyu Shi", "background": "现代零售应用中，准确的视频标注扮演着重要角色，包括顾客行为分析、产品互动检测和店面活动识别。然而，传统的标注方法依赖于耗费时间的人力标注，导致关键帧选择不够稳健，并增加了运营成本。在零售领域，为解决这些挑战，我们提出了一种基于深度学习的方法，自动识别零售视频中的关键帧并提供自动的产品和顾客标注。实验结果表明，该方法在准确度方面优于传统方法，同时显著提高了零售视频标注的整体效率，平均节省了2倍的标注成本。通过允许人类标注者验证或调整视频数据集中的少于5%的检测到的帧，而自动化剩余帧的标注过程，零售商可以大幅降低运营成本，同时保持标注质量。关键帧检测的自动化在零售视频标签任务中节省了大量时间和努力，对于顾客旅程分析、产品互动检测和店内安全监控等多种零售应用都非常有价值。", "innovation": "提出了一种基于深度学习的自动关键帧识别方法，用于零售视频，并结合了视频帧嵌入和对象检测技术，以提高产品和顾客的自动标注。相比传统方法，该方法在成本节约和效率提升方面表现出显著优势，实现了2倍的成本节省，同时保持了标注质量的高水平。人类标注者只需验证或调整少于5%的检测帧，即可显著降低运营成本，提高效率，特别是在零售视频环境下应用价值巨大。", "conclusion": "该研究提出的方法显著提高了零售视频的标注效率和准确性，通过自动化关键帧识别和产品/顾客标注，减轻了人工标注的负担，大幅降低了运营成本。该方法在多种零售应用场景中显示出高度的价值，如顾客旅程分析、产品互动检测和店内安全监控等。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14855", "html_url": "https://arxiv.org/abs/2506.14855", "title": "Feedback-MPPI: 通过展开差分快速的采样基于MPC，再见低级控制器", "title_en": "Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers", "authors": "Tommaso Belvedere(RAINBOW, IRISA),Michael Ziegltrum(UCL),Giulio Turrisi(IIT),Valerio Modugno(UCL)", "background": "Model Predictive Path Integral 控制方法由于其在处理非线性动力学和非凸成本方面的灵活性，成为执行复杂机器人任务的有效方法。然而，由于计算需求高，该方法在实时、高频机器人控制场景中的应用受到限制。", "innovation": "提出了Feedback-MPPI 框架，该框架通过计算局部线性反馈增益，结合敏感性分析和基于梯度的方法中的 Riccati 反馈，增强了经典的 MPPI 方法，使控制能够在当前状态周围快速闭环校正，而无需在每个时间节点完全重新优化。", "conclusion": "通过模拟和实际实验，反馈-MPPI 在两个机器人平台上展示了其有效性：四足机器人在不平地形上执行动态运动和四旋翼飞行器进行猛烈机动。实验结果表明，引入局部反馈显著提高了控制性能和稳定性，使系统能够在复杂的机器人系统中实现鲁棒的高频操作。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14856", "html_url": "https://arxiv.org/abs/2506.14856", "title": "透过神经不确定性图探寻未知：基于神经不确定性图的主动视图选择在3D重建中的应用", "title_en": "Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction", "authors": "Zhengquan Zhang,Feng Xu,Mengmi Zhang", "background": "现有的3D对象重建技术中，不同的视角提供的信息量不一。如何利用人工智能系统有效地选择能够提供最有价值视角的方法以实现准确高效的3D重建，是一个基本挑战。传统的做法是从当前观察学习光照场或3D高斯散点图，并计算每个候选视图的不确定性。本文研究了‘主动视图选择（AVS）’在3D重建中的应用，旨在确定能够产生最准确3D重建的最小视角集，而非依赖于从观测数据中学习的方法，而是提出了一种基于神经不确定性图的新颖AVS方法。通过UPNet学习角度外观到潜在体素表示不确定性之间直接映射，进而有效抑制冗余视图，选择最有信息量的视角。", "innovation": "本文提出了一种名为UPNet的轻量级前向深度神经网络，用于生成基于神经不确定性图的主动视图选择方法。UPNet能够预测输入3D物体图像的不确定性图，直接从视图外观到不确定性之间的映射，并进一步有效选择最有信息量的视图。此外，相较于基线方法，本文方法在保持重建精度的同时显著减少了计算开销，提升了运行速度和减少了CPU、RAM和GPU的使用量。该项工作为新的物体类别提供了有效的泛化能力，而无需额外训练。", "conclusion": "通过利用UPNet生成的神经不确定性图，本文的方法能够实现准确高效的3D重建，即使使用较少的视图数目也保持了与标准方法相当的重建精度，同时在计算资源上实现了显著的节省和加速。这种方法有望在未来的3D重建和其他计算机视觉任务中得到应用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14861", "html_url": "https://arxiv.org/abs/2506.14861", "title": "BMFM-RNA：构建和评估转录组基础模型的开放框架", "title_en": "BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models", "authors": "Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou", "background": "转录组基础模型（TFMs）近年来已成为分析细胞和组织中基因表达的强大工具，支持细胞类型注释、批次校正和扰动预测等关键任务。然而，由于不同TFMs实现和训练策略的多样性，难以区分单个设计选择的贡献或评估它们的潜在协同作用，这阻碍了该领域的最佳实践发展，并限制了不同研究之间的可重复性。现有的TFMs多样化的实施和训练策略造成了这种困难，使得研究者难以专注于单一的改进措施，而忽视了可能存在的协同效应。", "innovation": "我们提出了一个名为BMFM-RNA的开源、模块化软件包，统一了各种TFMs预训练和微调目标。利用这一功能，我们引入了一种新的训练目标——全细胞表达解码器（WCED），它通过自编码器似的方法使用CLS瓶颈表示来捕获全局表达模式。BMFM-RNA不仅提供了一个系统基准测试和社区驱动的TFM训练策略探索的基础，还通过对比实验展示了基于WCED的模型在多项数据集上的性能，与当前最先进的方法如scGPT相当或超越。", "conclusion": "BMFM-RNA作为生物医学多组学项目的一部分（链接在此），提供了可重复的基础，用于系统基准测试和社区驱动的TFM训练策略探索，为利用最新人工智能技术理解细胞生物学发展的工具开发奠定了基础。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14862", "html_url": "https://arxiv.org/abs/2506.14862", "title": "时间序列汇总因果图中公共后门集的可识别性", "title_en": "Identifiability by common backdoor in summary causal graphs of time series", "authors": "Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier", "background": "干预的可识别性问题旨在判断某些特定干预措施的总体效应能否通过do-free表达式来表示，并仅通过观测数据进行计算。本文在时间序列的数据环境中研究这一问题，考虑的是多个干预和多个效应的情况。由于仅有一个真实的因果图的抽象表示（汇总因果图）可用，问题变得更加复杂。文章聚焦于可以通过共同后门集进行可识别性分析，并为包含一致性和非一致性时间序列提供了条件，以判断此类集中是否存在。同时，还提供了有限复杂度的算法来判断问题是否可识别。", "innovation": "在汇总因果图的情境下，提出了条件和算法来判断多干预与多效应的时间序列中是否可通过共同后门集进行可识别性分析。这为处理复杂数据环境提供了一种新的方法，使得虽然仅有一部分因果信息可用，但依然可以评估某些干预的总体效应。", "conclusion": "针对时间序列和汇总因果图条件下的干预可识别性问题，提出了联合后门集存在性条件，并且提供有限复杂度的判定算法。这不仅丰富了因果图分析的理论框架，也提高了实际应用的可行性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14863", "html_url": "https://arxiv.org/abs/2506.14863", "title": "准备迎接智能爆炸", "title_en": "Preparing for the Intelligence Explosion", "authors": "William MacAskill,Fin Moorhouse", "background": "人工智能加速科研进程，可能在短短几年内推动一个世纪的技术进步。在此过程中，新的技术和政治变革会连续地产生具有重大影响且难以逆转的决策。我们称这些变革为‘重大挑战’，包括大规模杀伤性新武器、AI 支持的独裁政权、争夺外太空资源的竞争，以及值得道德考虑的数字生命。这些挑战并不是总能完全留给未来的AI系统解决。作者认为，应对这些挑战不仅需要确保先进AI系统的协同性，还应立即准备面对智能爆炸带来的各种冲击性的发展，改善我们的未来前景。", "innovation": "该研究提出了面对重大挑战不应全部交给未来的AI系统解决的观点，提出亟需立即为智能爆炸带来的冲击性进展做准备。这是一种更为积极主动和现实的策略，强调当前行动的重要性。这与传统的关注确保AI系统正确工作不同，而是更多关注如何应对智能爆炸带来的具体问题和伦理道德挑战。", "conclusion": "研究强调，智能爆炸带来的挑战不能仅仅作为未来AI系统的问题来解决，而应从现在开始准备应对这些复杂多变的情况，以提高未来技术发展的成功可能性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14907", "html_url": "https://arxiv.org/abs/2506.14907", "title": "PeRL: 增强排列的强化学习方法以提升交错的视觉语言推理", "title_en": "PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning", "authors": "Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong", "background": "近期的研究开始探索使用强化学习（RL）来增强视觉语言模型（VLMs）以处理多模态推理任务，但大多数现有的多模态强化学习方法仅限于单图像内的空间推理，难以推广到包含多图像位置推理的复杂和现实场景中。在这些场景中，理解图像间的关系至关重要。", "innovation": "本文提出了一种名为PeRL的通用强化学习方法，专门针对交错的多模态任务，并设计了多阶段策略来改善探索与利用之间的权衡，从而提高学习效率和任务性能。此外，引入了图像序列排列来模拟不同的位置关系，以探索更大的空间和位置多样性。还设计了一种通路过滤机制进行重采样，专注于对学习最优行为贡献最大的路径，以有效利用已学策略。", "conclusion": "在5个常用的多图基准和3个单图基准上评估PeRL模型，实验结果表明，PeRL训练的模型在多图基准上持续超过了R1相关的 和交错的VLM基线，并且在单图任务上保持了相当的性能，实现了多图基准的最新性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14909", "html_url": "https://arxiv.org/abs/2506.14909", "title": "使用面部照片进行健康识别的基础人工智能模型（FAHR-Face）", "title_en": "Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)", "authors": "Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak", "background": "面部外观为非侵入性地洞察健康状况提供了一个窗口。研究人员构建了FAHR-Face基础模型，该模型基于超过4000万张面部图像训练，并针对两个独立任务进行了微调：生物年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）", "innovation": "开发了两个微调模型：FAHR-FaceAge专门用于生物年龄估计，FAHR-FaceSurvival用于生存风险预测。通过广泛测试模型的鲁棒性（如美容手术、化妆、姿态、照明）和独立性（如显著性映射），以确保其在不同条件下的有效性。研究结果在两个独立的癌症患者数据集中得到了验证，并展示了在不同年龄、性别、种族和癌症亚组中的普遍适用性。", "conclusion": "单个基础模型可以生成能够捕捉生物学老化和疾病相关死亡风险的廉价可扩展面部生物标志物。基础模型通过相对较小的临床数据集实现了有效的训练。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14923", "html_url": "https://arxiv.org/abs/2506.14923", "title": "使用深度学习预测由流体引起的微地震的时空演化", "title_en": "Forecasting the spatiotemporal evolution of fluid-induced microearthquakes with deep learning", "authors": "Jaehong Chung,Michael Manga,Timothy Kneafsey,Tapan Mukerji,Mengsu Hu", "background": "微地震（MEQs）由地下注水产生，可以记录储层的应力演化和渗透率变化。因此，准确预测它们的时空演化对于增强地热系统（EGS）、二氧化碳封存和其他地质工程应用至关重要。现有方法难以满足这一需求，而本文使用基于变压器的深度学习模型，结合压力刺激历史和先前的MEQ观测数据，预测关键数量累计微地震数、累计对数震级以及50%和95%百分位的微地震云范围，能够实现较高质量的预测结果。", "innovation": "提出了一种基于变压器的深度学习模型，能够结合压力刺激历史和先前的MEQ观测数据，预测微地震的时空演化关键参数：累计微地震数、累计对数震级、50%和95%百分位微地震云范围。该模型在EGS Collaborative Experiment 1数据集上的结果表明，通过学习预测误差的标准偏差提供了不确定性估计，对于1秒和15秒的预测窗口分别实现了$R^2 > 0.98$和$R^2 > 0.88$的高质量预测，确保了实时推断裂缝传播和渗透率演变的可能性，展示了深度学习方法在减轻未来流体注入操作中的地震风险评估方面的巨大潜力。", "conclusion": "利用深度学习模型可以实现高精度且具有不确定性量化预测的微地震时空演化预测，对于实时推断裂缝传播和渗透率演变，改善地震风险评估和指导未来流体注入操作中的缓解策略具有巨大潜力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14933", "html_url": "https://arxiv.org/abs/2506.14933", "title": "先解释再信任：基于图的加密异常检测中的增强语言模型辅助解释", "title_en": "Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection", "authors": "Adriana Watson", "background": "近年来，去中心化金融（DeFi）社区由于加密货币爱好者的推动而迅速增长，他们对新市场的巨大潜力表现出兴趣。加密货币的流行带来了金融犯罪的新时代，但由于该技术的独特性，追踪和起诉犯罪分子变得尤为困难。因此，迫切需要开发自动化的检测工具，藉助相关政策监控加密货币领域日益增长的犯罪活动。", "innovation": "该研究提出了一种将增强语言模型（LLM）与图基检测方法结合的新型加密异常检测方法。这种结合不仅可以提高检测异常交易的准确性，还能够为用户提供可解释的异常解释，增强用户对自动检测结果的信任度。", "conclusion": "该研究通过实验验证了提出的基于图的加密异常检测方法及其解释系统的有效性。通过增强检测结果的透明度和可解释性，该方法能有效辅助监管机构和金融机构追踪和打击加密货币领域的犯罪活动。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14937", "html_url": "https://arxiv.org/abs/2506.14937", "title": "利用自动编码器在计算机网络中自动确定攻击检测阈值", "title_en": "Determinação Automática de Limiar de Detecção de Ataques em Redes de Computadores Utilizando Autoencoders", "authors": "Luan Gonçalves Miranda,Pedro Ivo da Cruz,Murilo Bellezoni Loiola", "background": "目前，使用自动编码器（AE）的异常检测系统在解决数据固有的问题（如数据不平衡）方面显示出了很大的潜力。由于AE使用了一个非平凡且非标准化的分离阈值来分类重建错误，定义这个阈值直接决定了检测过程的性能。因此，这项工作提出了使用一些机器学习算法自动定义这个阈值的方法。", "innovation": "这项研究通过评估K-最近邻，K-均值和支持向量机三种算法来自动确定用于异常检测的阈值，从而解决了自动编码器中分离阈值定义的问题，提升了检测过程的性能.", "conclusion": "三种机器学习算法被用于自动定义自动编码器异常检测系统的分离阈值，以提升网络攻击检测的准确性和效率。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14951", "html_url": "https://arxiv.org/abs/2506.14951", "title": "神经网络损失景观中的无限平坦通道", "title_en": "Flat Channels to Infinity in Neural Loss Landscapes", "authors": "Flavio Martinelli,Alexander Van Meegen,Berfin Şimşek,Wulfram Gerstner,Johanni Brea", "background": "神经网络的损失景观包含局部最小值和鞍点，这些鞍点可能在平坦区域内相互连接或孤立出现。本研究致力于识别和描述损失景观中的特定结构：两条特殊的路径，在这些路径上损失函数变化极其缓慢，而至少两个神经元的输出权重同时趋向于正无穷或负无穷，其输入权重向量变得相等。这些通向无限的路径在几何学上与对称性诱导的临界点线趋近平行，不同的回归设置中，梯度流动优化器和相关的优化方法（如SGD或ADAM）高概率地通过这些路径，但除非仔细检查，它们看起来像是有有限参数值的平坦局部最小值。这表明了全连接层在计算能力上的有趣特性，即在这些路径末端可能会出现门控线性单元。", "innovation": "本研究创新性地识别并描述了一种特殊结构，即通向无限的平坦路径，这些路径上的损失函数变化极慢，而至少两个神经元的输出权重同时趋向于正无穷或负无穷，其输入权重向量变得相等。这些路径在几何学上与对称性诱导的临界点线趋近平行。该研究还提供了关于这些准平坦区域的渐变动力学、几何结构和功能性解释的全面图景，显著丰富了我们对神经网络损失景观的理解。", "conclusion": "本研究深入分析了通向无限的平坦通道，并揭示了在这些路径末端可能会出现的门控线性单元。该研究从渐变动力学、几何结构和功能性解释等角度，为这些准平坦区域提供了全面的理解，进一步展示了神经网络损失景观中隐藏的未探索结构。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14965", "html_url": "https://arxiv.org/abs/2506.14965", "title": "从跨域视角重新审视大语言模型推理中的强化学习", "title_en": "Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective", "authors": "Zhoujun Cheng,Shibo Hao,Tianyang Liu,Fan Zhou,Yutao Xie,Feng Yao,Yuexin Bian,Yonghao Zhuang,Nilabjo Dey,Yuheng Zha,Yi Gu,Kun Zhou,Yuqi Wang,Yuan Li,Richard Fan,Jianshu She,Chengqian Gao,Abulhair Saparov,Haonan Li,Taylor W. Killian,Mikhail Yurochkin,Zhengzhong Liu,Eric P. Xing,Zhiting Hu", "background": "强化学习(RL)已成为提升大语言模型(LLM)推理能力的有前途的方法，但大多数研究集中在数学和代码上，限制了我们对其实现更广泛推理能力的理解。关键挑战在于缺乏可靠的、跨领域的RL奖励信号。为此，本文提出了Guru，一个包含9.2万个验证示例的RL推理语料库，这些示例覆盖了六个推理领域：数学、代码、科学、逻辑推理、仿真和表格。每个领域都通过领域特定的奖励设计、去重和过滤来保证可靠性和有效性。通过Guru数据集，对已有研究进行了系统的回顾，揭示了在不同领域的显著差异。研究发现，相比以往工作表明的RL主要是从预训练模型中唤起现有知识这一结论，实验显示不同领域对RL的反应各不相同。", "innovation": "Guru提供了一个包含9.2万个验证示例的RL推理语料库，覆盖六个不同领域。该语料库通过领域特定的奖励设计、去重和过滤来确保可靠性。研究结果显示，跨域RL训练在数学、代码和科学领域效果显著，但在逻辑、仿真和表格等领域需要进行领域内训练以达到显著的性能提升。此外，Guru-7B和Guru-32B这两款模型在六领域17项任务测试中表现出色，相比现有最佳基线模型，分别在任务测试中提高了7.9%和6.7%的性能。研究还表明，这些改进在复杂任务上更为明显，特别是在预训练数据中不太可能出现的任务上。", "conclusion": "Guru-7B和Guru-32B两种模型在使用公开数据进行RL训练时达到了最先进的性能。模型有效提高了基础模型的Pass@k性能，特别是在不太可能出现于预训练数据中的复杂任务上。本文的数据、模型和评估代码已开源以促进一般推理能力的发展。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14968", "html_url": "https://arxiv.org/abs/2506.14968", "title": "FEAST：一种灵活的用餐辅助系统，旨在野外个性化", "title_en": "FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization", "authors": "Rajat Kumar Jenamani,Tom Silver,Ben Dodson,Shiqin Tong,Anthony Song,Yuting Yang,Ziang Liu,Benjamin Howe,Aimee Whitneck,Tapomayukh Bhattacharjee", "background": "物理护理机器人在改善全球数百万需要喂食帮助的人的生活质量方面显示出潜力。然而，在家中提供餐饮帮助仍然具有挑战性，因为进食期间会出现多样化的活动（如吃饭、喝水、擦拭嘴巴）、环境（如社交互动、看电视）以及食物种类和用户偏好。", "innovation": "本工作提出了一种名为FEAST的灵活餐饮辅助系统，该系统能够个性化以满足个体护理接收者的独特需求。FEAST通过模块化硬件、多样化的交互方式和参数化的行为树遵循三个基本原则：可适应性、透明性和安全性。FEAST通过模块化硬件实现了在喂食、饮水和擦拭嘴巴之间的切换；通过网页界面、头部手势和物理按钮等交互方式适应不同功能能力和偏好；并通过参数化的行为树使用大型语言模型实现安全且透明的自适应。", "conclusion": "基于形式化研究中确定的个性化需求，我们评估了系统，并证明FEAST提供了一种广泛的安全和透明的个性化方法，并优于仅限于固定定制的先进技术基线。通过在家中进行用户研究和职业治疗师评估，我们展示了FEAST在实际应用中的可行性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14973", "html_url": "https://arxiv.org/abs/2506.14973", "title": "思考定向性：基于多说话人的定向语音识别的大语言模型", "title_en": "Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition", "authors": "Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze", "background": "近期的研究表明，通过音频编码促使大型语言模型（LLM）能够有效实现语音识别能力。然而，语音大语言模型在处理多声道音频的空间线索方面的能力尚未得到充分的研究。本工作中，我们利用智能眼镜中的麦克风阵列来实现定向语音识别、声源定位和旁白交叉谈话抑制的新方法，以增强模型对定向性的理解能力，我们提出了一种基于序列化定向输出训练（S-DOT）和对比定向数据增强（CDDA）的关键技术，实验结果表明，我们的方法能够有效捕捉文本线索和空间音频之间的关系，在言语识别和声源定位任务中表现出强劲的性能", "innovation": "我们提出了基于序列化定向输出训练（S-DOT）和对比定向数据增强（CDDA）的技术，利用智能眼镜中的麦克风阵列实现定向语音识别、声源定位和旁白交叉谈话抑制，该方法在言语识别和声源定位任务中表现出强劲的性能", "conclusion": "实验结果显示，我们提出的定向-SpeechLlama有效地捕捉了文本线索和空间音频之间的关系，从而在多说话人的定向语音识别和声源定位任务中取得了优秀的性能"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14988", "html_url": "https://arxiv.org/abs/2506.14988", "title": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits", "title_en": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits", "authors": "Tianyi Xu,Jiaxin Liu,Zizhan Zheng", "background": "该研究提出了一个多代理多臂老虎机（MA-MAB）框架，旨在确保各个代理获得公平的回报同时最大化整个系统的整体性能。在这一环境中，决策面临的挑战是在对臂奖励信息有限的情况下做出选择。为了应对这一挑战，研究引入了一种新的探针框架，通过在分配之前策略性地收集选定臂的信息来解决问题。对于已知奖励分布的离线设置，研究利用子模性性质设计了一个贪婪探针算法，并提供了一个可证明的性能上限。对于规则更为复杂且奖励分布未知的在线设置，研究开发了一个能够实现亚线性后悔率，同时保持公平性的算法。广泛的合成数据集和真实数据集实验表明，该方法在公平性和效率上优于基准方法。\n", "innovation": "提出了一个多代理多臂老虎机框架，引入了探针框架在有限信息下的决策制作方法；在离线设置中，利用子模性设计了贪婪探针算法，并提供性能上限；在线设置中，开发了同时实现亚线性后悔率和公平性的算法。\n", "conclusion": "在合成数据集和真实数据集的实验结果表明，该方法在公平性和效率上优于基准方法，证明了框架的有效性。\n"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14995", "html_url": "https://arxiv.org/abs/2506.14995", "title": "使用时序卷积网络模型改进梯度轨迹误差的图像重建和扩散参数估计", "title_en": "Improved Image Reconstruction and Diffusion Parameter Estimation Using a Temporal Convolutional Network Model of Gradient Trajectory Errors", "authors": "Jonathan B. Martin,Hannah E. Alderson,John C. Gore,Mark D. Does,Kevin D. Harkins", "background": "梯度轨迹中的误差会引入磁共振图像中的重大伪影和失真，特别是在非笛卡尔成像序列中，不完美的梯度波形可显著降低图像质量。这些误差会导致非线性失真，使用现有的线性方法无法准确预测和补偿这些失真，从而限制了成像质量的提升。", "innovation": "本文开发了一种通用的非线性梯度系统模型，利用卷积网络准确预测梯度失真。通过训练建立的时序卷积网络，能够准确预测梯度系统产生的非线性失真，并将网络预测的梯度波形整合到图像重建管道中，提高了图像质量和扩散参数映射的准确性，相比名义梯度波形和梯度冲激响应函数具有明显优势。与传统的线性方法相比，这项技术能够更准确地建模梯度系统的行为，并可能用于回顾性地纠正梯度误差。", "conclusion": "时序卷积网络可以比现有线性方法更准确地建模梯度系统的行为，并可用于回顾性纠正梯度误差。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15001", "html_url": "https://arxiv.org/abs/2506.15001", "title": "记忆令牌：大型语言模型可以生成可逆的句子嵌入", "title_en": "Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings", "authors": "Ignacio Sastre,Aiala Rosá", "background": "背景部分未在提供的内容中明确指出，但可以推测研究基于当前大型语言模型（LLM）的研究背景，尤其是关于模型如何处理和生成文本嵌入的相关研究。文章提到的现象涉及到可通过特定记忆令牌（memory token）优化并生成可逆的句子嵌入，使得模型能够在不修改模型权重的情况下重建原始文本。研究考虑了英语和西班牙语数据集，序列长度从大约240个标记不等，以及不同参数规模的模型。研究表明，Llama 3.1 8B等模型成功地重建了所有测试序列，这表明大型语言模型具有此能力的原因和潜在应用场景的重要性。", "innovation": "创新在于引入一种特殊记忆令牌，其嵌入通过在固定序列上进行训练得到优化。当模型接收到这种嵌入时，它能够准确地重建固定序列。这项研究评估了这一现象在不同语言、序列长度和模型规模上的表现，特别是Llama 3.1 8B模型可以重建所有测试序列，展示了其有效性。这暗示了潜在的应用场景，包括基于记忆的检索、压缩和受控文本生成。", "conclusion": "研究结果表明，大型语言模型具有显着的可逆句子嵌入生成能力，并且这种能力在不同环境下的有效性得到验证。这为研究记忆库在LLM中的作用提供了新的视角，并为创建基于记忆的语言模型开辟了新的可能性，可能用于改进检索、压缩和生成控制文本的能力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15006", "html_url": "https://arxiv.org/abs/2506.15006", "title": "扩展智能：为下一代语言模型设计数据中心", "title_en": "Scaling Intelligence: Designing Data Centers for Next-Gen Language Models", "authors": "Jesmin Jahan Tithi,Hanjiang Wu,Avishaii Abuhatzera,Fabrizio Petrini", "background": "大规模语言模型（LLMs）如GPT-4，具有1.8万亿参数，其爆炸性增长迫切需要重新思考数据中心架构，以确保可扩展性、效率和成本效益。本文探讨了如何在数据中心架构中优化浮点运算、HBM带宽及容量、网络架构、扩展域大小以及流行的并行化/优化策略，从而提升性能和可扩展性。详细分析了如何通过优化计算和通信，利用硬件加速的集体通信机制，扩大扩展域和增加内存容量来提高效率和吞吐量。本文的研究涵盖了稀疏（专家混合）和密集（transformer）两种类型的LLMs，揭示了系统设计选择对模型浮点运算利用率（MFU）和总体吞吐量的影响。", "innovation": "本文提出了一个全面的协同设计框架，共同探索浮点运算、HBM带宽和容量、多种网络拓扑结构（两层光学网络 vs. 全平面光学网络）、扩展域大小以及在LLMs中使用的流行并行化/优化策略。引入并评估了全平面网络架构，提供了所有节点之间均匀的高带宽、低延迟连接。详细分析了计算和通信重叠、利用硬件加速的集体通信、扩大扩展域和增加内存容量带来的效益。开发并验证了一种性能建模工具，能够在10%误差范围内预测真实世界的LLM运行时性能，提供了实际可行的设计建议来支持万亿参数模型，降低优化复杂度，并维持AI能力的迅速发展。", "conclusion": "本文的研究为设计能够有效支持万亿参数模型、降低优化复杂度并持续适应AI能力快速演进的AI数据中心提供了实用的设计指南和改进策略。通过该研究，可以更好地理解系统设计选择如何影响模型浮点运算利用率和整体吞吐量，从而为下一代语言模型的高效数据中心设计提供洞见。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15008", "html_url": "https://arxiv.org/abs/2506.15008", "title": "基于现实数据指导生成式AI设计：文本到图像输出中融入实际数据", "title_en": "Insights Informed Generative AI for Design: Incorporating Real-world Data for Text-to-Image Output", "authors": "Richa Gupta,Alexander Htet Kyaw", "background": "生成式AI中的文本到图像模型已经改变了室内建筑设计，缩短了从文本提示到视觉表示的转化时间。尽管这些模型能生成吸引人的图像，但它们通常缺乏可供设计师使用的操作性数据。因此，研究人员提出了一种新方法，将DALL-E 3与材料数据集结合，为生成的建筑设计加入可持续性指标和材料使用见解。该方法识别图像中的前十大材料，并与通用材料字典中的二氧化碳当量(CO2e)值配对，使设计师能够立即评估环境影响并调整设计提示。研究通过三项用户测试评估了系统，结果显示在第三个测试中引入可持续性指标导致更明智的设计决策，但同时也可能会导致决策疲劳，降低总体满意度。然而，大多数参与者表示在第三个测试中已经将可持续性原则融入工作流程，表明集成的指标能够引导更生态友好的实践。研究强调了实现设计自由与实际约束之间的平衡对于AI辅助建筑设计全流程的重要性，提供了向全面、数据驱动解决方案过渡的清晰路径。", "innovation": "该研究提出了一个将DALL-E 3与材料数据集结合的新管道，通过识别图像中的前十大材料并配对CO2e值，为生成的建筑设计加入可持续性指标和材料使用见解。这种方法允许设计师立即评估环境影响并调整设计提示。通过三项用户测试评估了系统的效果，结果显示引入可持续性指标会带来更加明智的设计决策，但也可能引起决策疲劳，降低满意度。然而，大多数参与者表示将可持续性原则融入工作流程，证明了集成指标能够指导更生态友好的实践。论文强调了实现设计自由与实际约束之间的平衡对于AI辅助建筑设计的重要性和潜在价值。", "conclusion": "研究介绍了将现实数据整合到生成式AI设计中的重要性，并展示了如何通过引入可持续性指标和CO2e数据平衡设计自由与实际约束。这种综合方法为AI辅助建筑设计提供了清晰的数据驱动解决方案途径，赋能设计师做出更加环境敏感的设计决策。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15019", "html_url": "https://arxiv.org/abs/2506.15019", "title": "基于临床评分正则化的稳定CDE自动编码器在败血症治疗离线强化学习中的应用", "title_en": "Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment", "authors": "Yue Gao", "background": "有效的强化学习（RL）用于败血症治疗依赖于从重症监护室（ICU）不规则时间序列中学习稳定且临床上有意义的状态表示。虽然已有研究探索了此类任务中的表示学习，但序列表示训练过程中的不稳定性及其对策略性能的负面影响却未被充分认识到。这项工作表明，当两点得到满足时，可控差分方程（CDE）能够实现强大的RL策略：(1) 通过早停或稳定方法保证训练稳定；(2) 按照临床评分（SOFA、SAPS-II、OASIS）进行相关性正则化，以形成有意识度的表示方式。MIMIC-III败血症队列的实验显示，稳定的CDE自编码器能够生成与临床评分高度相关的表示并使RL策略具有出色的性能（WIS回报 > 0.9），而不稳定CDE表示会导致表示质量下降和策略失败（WIS回报 ≈ 0）。", "innovation": "这项工作首次证明了在训练过程中确保稳定性和通过临床评分正则化来强化表示能力可以在强化学习中有效处理败血症治疗问题。提出了两种关键因素，即通过早停或稳定方法保证训练稳定，并通过临床评分正则化实现有意识度的表示方式。这为如何使用CDE编码不规则医疗时间序列提供了实用指导，特别是在临床强化学习中。", "conclusion": "研究表明，稳定的CDE自编码器不仅能够生成与临床评分高度相关的表示，还能生产出性能更优的RL策略。此外，稳定的CDE空间能够区分幸存者和非幸存者的路径，并揭示清晰的临床评分梯度，而不稳定的CDE空间则无法捕捉到这些模式。这项研究强调了在序列表示学习中保持训练稳定性的必要性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15021", "html_url": "https://arxiv.org/abs/2506.15021", "title": "SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models", "title_en": "SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models", "authors": "Gyuhak Kim,Sumiran Singh Thakur,Su Min Park,Wei Wei,Yujia Bao", "background": "监督微调（SFT）已成为将大型语言模型（LLMs）调整为与人类期望和特定下游任务相一致的关键步骤。然而，现有的SFT方法通常是将每个训练实例视为均匀序列，对所有令牌给予同等的重要性，而不论它们的相关性。这种方法忽视了并非所有令牌都包含关键的任务特定信息这一事实。仅有一部分令牌才包含关键的信息。为了弥补这一不足，本文介绍了一种新的方法——SFT-GO（监督微调与组优化），该方法基于令牌的重要性值对令牌分组，并使用最差组损失和标准交叉熵损失的加权组合来优化LLM。这一机制能够适应性地强调最具挑战性的令牌组，并引导模型更好地处理不同的分组分布，从而改善整体学习动态。", "innovation": "SFT-GO根据令牌的重要性值对令牌进行分组，并使用最差组损失和标准交叉熵损失的加权组合来优化LLM。这一机制能够适应性地强调最具挑战性的令牌组，并引导模型更好地处理不同的分组分布，从而改善整体学习动态。我们还提供了SFT-GO收敛速度的理论分析，以证明其效率。并用三种不同的令牌分组策略应用SFT-GO，结果显示使用SFT-GO训练的模型在流行的LLM基准测试中表现始终优于基线方法，这些改进适用于各种数据集和基础模型，进一步验证了该方法的鲁棒性和有效性。", "conclusion": "我们的研究证明，SFT-GO能够在提升LLM性能方面有效地处理令牌分组的问题。通过适应性强调关键的令牌组并优化模型，SFT-GO能够改善模型的学习动力，提高在多个基准测试中的性能。这一方法在不同的数据集和基础模型上均表现出高水平的鲁棒性和有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15025", "html_url": "https://arxiv.org/abs/2506.15025", "title": "大语言模型中嵌入学习率的最优选择：词汇量大小的影响", "title_en": "Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size", "authors": "Soufiane Hayou,Liyuan Liu", "background": "预训练大型语言模型是一个成本高昂的过程。为了提高这个过程的效率，已经提出了一些方法来优化模型架构/参数化和硬件使用。在参数化方面，$\boldsymbol{μ} P$（最大更新参数化）以一种使超参数（HPs）在宽度（嵌入维度）上可转移的方式参数化模型权重和学习率（LR）。然而，最近的经验研究表明，当应用于大型语言模型（LLMs）时，$\boldsymbol{μ} P$的方法会出现一些冲突的观察结果。论文指出，$\boldsymbol{μ} P$理论的一个局限性在于在将宽度视为无穷大时忽略了词汇量大小的变化，而在实践中词汇量大小通常远大于宽度。因此，为了更好地理解词汇量大小对训练动态的影响，研究人员在此工作中的理论分析发现，随着词汇量大小的增加，训练动态会在$\boldsymbol{μ} P$制度和另一种称为大词汇量（LV）制度之间进行插值，而在这两种制度中的最佳放大规则是不同的。", "innovation": "该研究提供了词汇量大小对训练动态影响的理论分析，并发现当词汇量增大时，嵌入的LR（学习率）与隐藏层LR的最佳比例应该大致按$\boldsymbol{Θ}(\boldsymbol{√}\text{宽度})$进行缩放，这与之前文献中报告的经验结果非常接近，与$\boldsymbol{μ} P$预测的$\boldsymbol{Θ}(\text{宽度})$比例不同。研究人员还通过若干实验验证了他们的理论，并从头开始训练一个1亿参数的模型来展示建议的缩放规则的优势。", "conclusion": "研究表明，随着词汇量大小的增加，训练动态在$\boldsymbol{μ} P$制度和另一种称为大词汇量（LV）制度之间进行插值。在LV制度中，最佳嵌入LR与隐藏层LR的比例应按$\boldsymbol{Θ}(\boldsymbol{√}\text{宽度})$缩放，这一发现推翻了$\boldsymbol{μ} P$所预测的$\boldsymbol{Θ}(\text{宽度})$比例，并且研究展示了基于LV规则的嵌入学习率缩放的实用性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15043", "html_url": "https://arxiv.org/abs/2506.15043", "title": "使用CNN-LSTM-GRU架构预测超高速导弹轨迹的技术", "title_en": "Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures", "authors": "Amir Hossein Baradaran", "background": "随着国防工业的发展，确保国家的安全与稳定至关重要。新兴威胁如超高速导弹因其极高速度和机动性，对有效防御措施提出了巨大挑战。准确预测超高速导弹的轨迹对于有效的防御措施至关重要，但这是技术上的一个重要难题。", "innovation": "该研究采用了一种新颖的深度学习混合模型，结合了卷积神经网络（CNNs）、长短时记忆网络（LSTM）和门控循环单元（GRUs），综合利用这些架构的优点，实现了对超高速导弹复杂轨迹的高精度预测，这为防御策略和导弹拦截技术提供了重要贡献。", "conclusion": "本研究展示了先进的机器学习技术在增强军事防御系统预测能力方面的潜力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15047", "html_url": "https://arxiv.org/abs/2506.15047", "title": "映射护理人员需求到人工智能聊天机器人设计：针对阿尔茨海默病和痴呆症护理人员的心理健康支持的优势与不足", "title_en": "Mapping Caregiver Needs to AI Chatbot Design: Strengths and Gaps in Mental Health Support for Alzheimer's and Dementia Caregivers", "authors": "Jiayue Melissa Shi,Dong Whi Yoo,Keran Wang,Violeta J. Rodriguez,Ravi Karkar,Koustuv Saha", "background": "患有阿尔茨海默病及相关痴呆症（AD/ADRD）个体的家庭护理人员面临巨大的情感和物流挑战，增加了他们出现压力、焦虑和抑郁的风险。尽管生成式人工智能，尤其是大型语言模型（LLMs），提供了新的支持心理健康的机会，但护理人员对这些技术的看法和参与度还知之甚少。为了填补这一空白，我们开发了基于GPT-4o的聊天机器人Carey，旨在为AD/ADRD护理人员提供信息和情感支持。通过对16位护理人员进行半结构化访谈，我们分析了他们对常见照护压力情景的反应，确定了六个主要主题：即需信息访问、情感支持、安全披露空间、危机管理、个性化和数据隐私。每个主题我们都发现了护理人员的深层次紧张和担忧。我们详细说明了护理人员的需求、AI聊天机器人的优点、现有缺口以及设计建议，为设计更加主动、值得信赖且以护理人员为中心的AI系统提供了理论和实用的见解，以更好地支持AD/ADRD护理人员不断变化的心理健康需求。", "innovation": "我们开发了一款基于GPT-4o的聊天机器人Carey，旨在为AD/ADRD护理人员提供信息和情感支持。我们通过半结构化访谈和主题分析，系统地揭示了护理人员的需求和期望，确定了六个主题并识别了护理人员在这些主题上的复杂紧张关系。这项研究填补了对护理人员对人工智能技术的看法和参与度了解不足的空白，为设计更加有力、值得信赖且以护理人员为中心的AI系统提供了指导。", "conclusion": "我们的研究为设计具有前瞻性的、可信的、以护理人员为中心的AI系统提供了理论和实践指导，更好地支持AD/ADRD护理人员不断变化的心理健康需求。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15051", "html_url": "https://arxiv.org/abs/2506.15051", "title": "Sequential Policy Gradient for Adaptive Hyperparameter Optimization", "title_en": "Sequential Policy Gradient for Adaptive Hyperparameter Optimization", "authors": "Zheng Li,Jerry Cheng,Huanying Helen Gu", "background": "强化学习在神经架构搜索和超参数优化中至关重要，但传统方法由于时间和计算成本高而难以普及。计算机视觉、自然语言处理和音频领域的多种数据集被用来评估创新方法的工业适用性", "innovation": "提出了Sequential Policy Gradient modeling (SPG)，这是一种基于DeepSeek-V3多令牌预测架构的新型轻量级在线超参数优化路径生成范式。SPG通过扩展基本模型添加临时模块，使其可以在单个前向传递中生成填充的状态行为轨迹，与传统的策略梯度方法相比，SPG显示出更好的性能改进及显著较低的计算成本", "conclusion": "SPG方法在广泛采用的模型上表现出一致的性能改进，获得了0.2%到7%的性能提升。此外，SPG的计算成本远低于传统方法。已经提供可以完全复现的代码和预训练模型支持"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15081", "html_url": "https://arxiv.org/abs/2506.15081", "title": "通过话语感知的语句澄清改进对话话语解析", "title_en": "Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification", "authors": "Yaxin Fan,Peifeng Li,Qiaoming Zhu", "background": "对话话语解析旨在识别和分析对话中各陈述之间的语篇关系。然而，对话中的语言特征，如省略和成语，经常引入歧义，模糊了意图的语篇关系，对解析器提出了重大挑战。", "innovation": "本文提出了一种话语感知澄清模块（DCM），通过两种不同的推理过程——澄清类型推理和话语目标推理来增强对话话语解析器的性能。此外，引入了贡献感知偏好优化（CPO）来减轻因错误澄清而产生的风险，从而减少累积错误。CPO使解析器能够评估DCM澄清贡献并提供反馈以优化DCM，增强其适应性和与解析器需求的对齐。", "conclusion": "在STAC和Molweni数据集上的广泛实验表明，本方法有效解决了歧义并显著优于最先进的基线方法。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15113", "html_url": "https://arxiv.org/abs/2506.15113", "title": " Transit for All: 利用区域表示学习绘制公平的自行车-地铁连接图", "title_en": "Transit for All: Mapping Equitable Bike2Subway Connection using Region Representation Learning", "authors": "Min Namgung,JangHyeon Lee,Fangyi Ding,Yao-Yi Chiang", "background": "在人口密集的城市如纽约市（NYC），低收入和少数族裔社区往往面临公共交通可达性有限的问题。自行车共享系统（BSS）可以通过提供负担得起的第一英里和最后一英里的连接来弥补这些不平等。然而，将BSS战略地扩大到未服务的社区在新规划的站点位置往往需求不确定，并且传统的可达性指标可能忽视了实际的自行车使用潜力，这使得这一任务具有挑战性。", "innovation": "本文提出了一种名为Transit for All（TFA）的空间计算框架，通过三个组成部分来指导BSS的公平扩张：（1）利用多模态地理空间数据及其区域表示学习，在冷启动站点构建空间导向的自行车共享需求预测；（2）通过结合预测的自行车共享需求与传统的公共交通可达性指标，使用我们提出的加权公共交通可达性级别（wPTAL）进行全面的公共交通可达性评估；（3）基于潜在乘客数量和公平性的考虑，建议新的自行车站点部署策略。研究表明，通过wPTAL引导的新站点的战略部署显著降低了与经济和人口因素相关的交通可达性差距。", "conclusion": "本研究证明了TFA为城市规划者提供了一种实际的指导，以促进公平的交通并提高未服务城市社区的生活质量。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15120", "html_url": "https://arxiv.org/abs/2506.15120", "title": "Advancing Loss Functions in Recommender Systems: A Comparative Study with a Rényi Divergence-Based Solution", "title_en": "Advancing Loss Functions in Recommender Systems: A Comparative Study with a Rényi Divergence-Based Solution", "authors": "Shengjia Zhang,Jiawei Chen,Changdong Li,Sheng Zhou,Qihao Shi,Yan Feng,Chun Chen,Can Wang", "background": "损失函数在优化推荐模型中扮演着至关重要的角色。Softmax Loss（SL）和Cosine Contrastive Loss（CCL）是特别有效的两种损失函数。尽管两者各有优势，但它们之间存在着理论上的联系和差异，这需要深入探索。本文对这两种损失函数进行了全面分析，从中获得了重要的洞见。首先，两者都有普遍的优势，可以从传统的损失函数中增强分布鲁棒优化（DRO），增强模型对分布变化的鲁棒性。然而，它们也各有局限，SL对假阴性实例特别敏感，而CCL则在数据利用方面表现不佳。这为本文的创新提供了背景和动机。通过对SL和CCL的深入分析，本文提出了一个新的损失函数DrRL，在DRO优化中利用Rényi距离来通用化SL和CCL的优点，克服两者各自局限性，从而提升推荐系统的准确性和鲁棒性。", "innovation": "本文提出了一个新的损失函数DrRL，此函数结合了SL和CCL的优点，并通过利用Rényi距离在DRO优化中进行泛化。DrRL旨在解决SL和CCL的局限性，利用Rényi距离同时利用了SL和CCL的优势，提高了推荐系统的准确性和鲁棒性。", "conclusion": "通过广泛的实验验证，本文证明了DrRL在推荐系统准确性和鲁棒性方面优于SL和CCL。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15131", "html_url": "https://arxiv.org/abs/2506.15131", "title": "利用大规模语言模型在开放域对话中建模一对多特性", "title_en": "Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs", "authors": "Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan", "background": "开放域对话（OD）具有一个单一对话上下文对应多个合适响应（one-to-many, o2m）的特性。前期研究证明，建模这种特性可以提升响应多样性，但大多数现代基于LLM的对话代理却未明确这样做。本研究旨在通过将OD生成分解为多响应生成（MRG）和基于偏好的选择（PS）两个关键任务，为LLM建模开放域对话的一对多特性提供方法。为此，引入了一个专门设计来捕捉一对多特性的对话语料库o2mDial，以及新的上下文学习、指令调优策略和评价标准，以提高整体响应多样性和质量。实验结果表明，应用这种两阶段框架到较小的LLM中进行对话生成，在保持上下文连贯性的同时提升了总体响应多样性，并将响应质量提高了高达90%，使其性能更接近大型模型。", "innovation": "提出了一种两阶段框架，将开放域对话生成分解为多响应生成（MRG）和基于偏好的选择（PS）两个任务；设计了一种专门用于捕捉一对多特性的对话语料库o2mDial；提出了新的上下文学习和指令调优策略，以及针对MRG的新型评估指标；提供了一种建模PS的模型导向方法。", "conclusion": "将提出的两阶段框架应用于较小规模的LLM进行开放域对话生成，能够提高整体响应多样性，同时保持上下文连贯性，并在提升响应质量方面表现突出，达到或接近更大模型的性能水平。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15138", "html_url": "https://arxiv.org/abs/2506.15138", "title": "Thunder-Tok：减少韩语文本分词中单词的token数量以提高生成语言模型的效率", "title_en": "Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models", "authors": "Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee", "background": "介绍了Thunder-Tok，这是一种新的韩语分词器，旨在降低token繁殖率同时不损害模型性能。该方法采用规则预分词技术，与韩语语言结构相一致。通过创建一个种子词汇表包含类似语言单元的token，并使用分支熵为基础的选择算法，这些技术增加了平均token长度，从而降低了token繁殖率并保留了语言信息。实验结果显示，与BPE相比，Thunder-Tok大约降低了10%的token数量，加快了10%的推理速度，同时在各种下游任务中保持了性能。这些结果表明该方法的有效性和实用性，为语言模型设计高效的分词器提供了一种语言驱动的方法。", "innovation": "Thunder-Tok采用规则预分词方法和基于分支熵的选择算法，增加了平均token长度，从而降低token繁殖率并保留语言信息。它在不牺牲性能的情况下，将韩语文本的token数量减少了10%，提升了10%的推理速度。", "conclusion": "研究发现，Thunder-Tok是设计语言模型高效分词器的一种语言驱动方法，有效并且实用，能够减少token数量并提高推理速度。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15154", "html_url": "https://arxiv.org/abs/2506.15154", "title": "SonicVerse：基于音乐特征的多任务学习音乐描述", "title_en": "SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning", "authors": "Anuradha Chopra,Abhinaba Roy,Dorien Herremans", "background": "详细的、准确反映音乐作品特征的描述可以丰富音乐数据库，并推动音乐人工智能领域的研究。现有的研究通常侧重于低层次的声音细节，而未充分考虑高层次的音乐属性。因此，引入了一种名为SonicVerse的多任务音乐描述模型，该模型将描述生成与辅助音乐特征检测任务（如键检测和人声检测）相结合，以便同时捕捉低层次的声音细节和高层次的音乐属性。", "innovation": "SonicVerse的核心贡献是一种基于投影的架构，该架构可以将音频输入转换为语言标记，同时通过专用的辅助头部检测音乐特征。这些头部的输出也被投影到语言标记上，以增强描述输入。该框架不仅能够产生详尽描述的音乐片段，还能够通过大型语言模型链式输出直接生成详尽的时间信息描述。此外，通过使用MIRFLEX对MusicBench数据集进行扩展，该模型进一步提升了生成描述的质量和细节。", "conclusion": "实验结果表明，通过这种方式结合特征可以显著提高生成描述的质量和细节。SonicVerse模型成功地整合了多任务学习与音乐特征检测，为音乐描述领域带来了显著的创新。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15167", "html_url": "https://arxiv.org/abs/2506.15167", "title": "基于LLM的超参数优化代理", "title_en": "LLM Agent for Hyper-Parameter Optimization", "authors": "Wanzhe Wang,Jianqiu Peng,Menghao Hu,Weihuang Zhong,Tong Zhang,Shuai Wang,Yixin Zhang,Mingjie Shao,Wanli Ni", "background": "通信算法的性能高度依赖于其超参数的选择。对于基于温启动粒子群优化与交叉突变（WS-PSO-CM）算法的无人机（UAV）航路规划和通信优化，现有的超参数调优方法主要依赖于直觉，自动化程度较低，导致性能不佳。", "innovation": "本文设计了一个大型语言模型（LLM）代理来自动进行超参数调优。该代理采用迭代框架和模型上下文协议（MCP），首先通过配置文件设定任务需求，然后根据提示要求迭代调用WS-PSO-CM算法进行探索，最终自主终止循环并返回超参数集。实验结果显示，使用该LLM代理生成的超参数集下的最小汇聚率显著高于基于直觉和随机生成方法的结果，表明具有PSO知识的LLM代理对于发现高性能超参数是有用的。", "conclusion": "实验表明，通过设计的LLM代理生成的超参数能够显著提高性能，优于依赖于直觉和随机生成的方法，证实了将LLM与WS-PSO-CM算法结合进行超参数优化的有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15182", "html_url": "https://arxiv.org/abs/2506.15182", "title": "使用深度学习进行多参数体部MRI序列分类", "title_en": "Classification of Multi-Parametric Body MRI Series Using Deep Learning", "authors": "Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers", "background": "多参数磁共振成像(mpMRI)检查包含多种系列类型，这些系列类型根据不同的成像协议获取。这些系列类型的DICOM头信息经常因协议多样性或技术人员错误而包含不准确的信息。为了提高放射科医生阅片效率，研究提供了一种基于深度学习的分类模型，用于分类8种不同的体部mpMRI系列类型。该研究采用来自不同医疗机构的mpMRI数据，训练了ResNet、EfficientNet和DenseNet等多种基于深度学习的分类器来分类8种不同的MRI系列，并对比了它们的性能。", "innovation": "研究训练了基于ResNet、EfficientNet和DenseNet等多种深度学习分类器来分类8种不同的MRI系列，并通过比较不同模型的性能确定了表现最佳的分类器。此外，研究还探讨了该最佳分类器在不同训练数据量下的分类能力，并对其在外部数据集上的性能进行了评估。研究结果表明，DenseNet-121模型在各项指标上均表现最佳，且其性能随着训练数据量的增加而提升。", "conclusion": "研究发现，DenseNet-121模型在内部和外部数据集上均表现出高 accuracy，适用于多参数体部MRI序列的分类任务，且在超过729个训练研究的数量下，DenseNet-121模型的准确性超过0.95。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15189", "html_url": "https://arxiv.org/abs/2506.15189", "title": "无障碍手势驱动增强现实交互系统", "title_en": "Accessible Gesture-Driven Augmented Reality Interaction System", "authors": "Yikan Wang", "background": "增强现实（AR）提供了沉浸式的交互方式，但由于依赖于精准的输入方法，对于肢体障碍或受限灵活性的用户来说仍然难以访问。现有的AR系统无法很好地适应这些用户的使用需求，亟需一种能够适应这些用户能力的手势交互系统，以便提高AR的无障碍性和可扩展性。", "innovation": "该研究提出了一种基于手势的交互系统，利用深度学习技术从可穿戴传感器和摄像头中识别手势，并根据用户的能力调整界面。该系统综合使用了视觉变换器（ViTs）、时序卷积网络（TCNs）和图注意网络（GATs）进行手势处理，采用了联邦学习以确保在不同用户群体中进行隐私保护的数据训练。通过强化学习优化了界面元素，如菜单布局和交互模式。实验结果显示，与基准AR系统相比，该系统可将任务完成效率提高20%，用户满意度提高25%，对于肢体障碍用户来说具有显著的优势，提升AR的无障碍性和可扩展性。", "conclusion": "该研究通过手势识别和交互优化，实现了AR环境下的无障碍交互系统。通过联邦学习和强化学习的应用，提高了系统的适应性和用户体验。该系统为肢体障碍用户提供了一个更友好、更高效的AR交互环境，对提高AR系统的无障碍性和可扩展性具有重要意义。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15208", "html_url": "https://arxiv.org/abs/2506.15208", "title": "大型语言模型任务适应技术在识别可持续发展目标方面的比较研究", "title_en": "A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals", "authors": "Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi", "background": "2012年，联合国提出了17项可持续发展目标（SDGs），旨在到2030年创造一个更加可持续和改进的未来。然而，由于涉及大量复杂数据，追踪这些目标的进展情况具有挑战性。文本分类模型在这种情况下变得至关重要，可以自动化从各种来源的大量文本分析。近年来，大型语言模型（LLMs）在许多自然语言处理任务中变得不可或缺，包括文本分类，得益于它们识别复杂语言模式和语义的能力。本文研究了多种专有和开源LLMs在单一标签多类文本分类任务（关注SDGs）上的表现，并评估了几种任务适应技术（如零样本学习和少样本学习，以及微调）的有效性。结果表明，通过提示工程优化的小型模型可以与像OpenAI的GPT这样的大型模型性能相当。", "innovation": "本文研究了专有和开源LLMs在单一标签多类文本分类任务中的表现，并评估了多种任务适应技术的有效性，如零样本学习、少样本学习和微调。特别地，研究发现小型模型通过提示工程优化后可以与大型模型相当。这项研究对于理解小型模型在特定任务上的潜力有重要意义。", "conclusion": "小型模型通过优化后，在某些情况下可以与大型模型性能相当。这表明在特定任务中，可以使用更小、更高效的语言模型。研究还表明，任务适应技术，如零样本学习和少样本学习，可以在提高模型性能方面发挥关键作用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15251", "html_url": "https://arxiv.org/abs/2506.15251", "title": "Singular Value Decomposition on Kronecker Adaptation for Large Language Model", "title_en": "Singular Value Decomposition on Kronecker Adaptation for Large Language Model", "authors": "Yee Hin Chong,Peng Qu", "background": "大型预训练变换器模型在多种语言和推理任务中表现出优越的结果，但完整的微调会产生大量的存储、内存和计算开销。参数高效微调（PEFT）方法通过仅学习少量任务特定参数来缓解这些成本，现有的方法或是引入推理时延迟（适配模块），或是从次优收敛（随机初始化低秩更新）中受到影响，或是依赖于固定秩选择，这可能不匹配任务的复杂性（Kronecker分解）", "innovation": "本文提出SoKA（SVD on Kronecker Adaptation），这是一种新型的PEFT策略，结合了Kronecker积张量分解和SVD驱动的初始化以及基于谱的理解动态秩选择。KPSVD过程将完整的权重更新的主要成分提取为紧凑的Kronecker因子，而自适应秩选择算法利用能量阈值和肘点准则来修剪可忽略不计的成分。实验结果表明，SoKA需要仅0.99M可训练参数，比LoRA/PiSSA少25%，同时匹配或超越基线性能。此外，SoKA展示了更快的收敛速度和更稳定的梯度，突显了其在大规模模型适应中的鲁棒性和效率", "conclusion": "SoKA仅需0.99M可训练参数，比LoRA/PiSSA少25%，同时匹配或超越基线性能，且展示出更快的收敛速度和更稳定的梯度，是一种有效的参数高效微调策略。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15253", "html_url": "https://arxiv.org/abs/2506.15253", "title": "RAS-Eval: 在现实环境评估大语言模型代理安全性的全面基准", "title_en": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "authors": "Yuchuan Fu,Xiaohan Yuan,Dongxia Wang", "background": "在关键领域如医疗和金融中迅速部署的大语言模型（LLM）代理需要稳健的安全框架。由于缺乏标准化的评估基准，特别是在动态环境中，针对这些代理的评估相对缺乏。因此，需要一个新的全面安全基准来评估这些代理的安全性能，并确保它们在实际应用场景中的安全性与可靠性。基于此需求，本文提出了RAS-Eval，一个支持模拟和现实环境工具执行的全面安全基准。该基准涵盖了80个测试案例和3,802个攻击任务，这些任务可以映射到11个通用弱点枚举（CWE）类别，工具可以以JSON、LangGraph和Model Context Protocol (MCP)三种格式实现。", "innovation": "本文创新地提出了一种名为RAS-Eval的全面安全基准，该基准能够支持在模拟和现实环境中的大语言模型代理的安全性评估。它涵盖了广泛的测试案例和攻击任务，能覆盖多个常见的弱点类别，并且通过JSON、LangGraph和MCP格式实现了工具化。通过评估6个最先进的大语言模型代理在不同场景下的性能，研究发现这些模型存在严重的漏洞，平均降低了36.78%的任务完成率，并且在学术环境中达到了85.65%的成功率。研究揭示了一个显著的规律，即在安全能力方面，更大的模型表现优于更小的模型。研究结果为未来的大语言模型代理安全研究提供了重要的基础框架和启示。", "conclusion": "RAS-Eval为大型语言模型代理在现实环境中的安全性评估提供了全面的基准，揭示了代理在实际部署中存在的重大风险，同时明确了其潜在的安全改进方向。通过该框架，未来的研究和开发可以更好地指导大语言模型代理的安全性改进，以满足日益严格的安全要求。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15260", "html_url": "https://arxiv.org/abs/2506.15260", "title": "半导体制造中缺陷图像分类的领域适应", "title_en": "Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing", "authors": "Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto", "background": "在半导体行业，由于市场需求高且竞争激烈，时间和产品质量是获得特定应用领域显著市场份额的关键因素。近年来，深度学习方法在计算机视觉领域的成功应用，尤其是在工业4.0和5.0的应用中，如缺陷分类，已经取得了显著成果。领域适应（DA）因其专注于利用从一个（源）领域学到的知识去适应和在不同的但相关（目标）领域高效运行而显现出高度有效性。DA通过提高稳健性和可扩展性，减少了对大规模手动重新标记或重新训练模型的需求，不仅降低了计算和资源成本，还允许人类专家专注于高价值任务。因此，我们在半导体领域研究了领域适应技术在半监督和无监督设置中的有效性，并提出了一种名为DBACS的方法，该方法借鉴了CycleGAN并加入了额外的损失项以提高性能。所有的方法都通过对实际电子显微镜图像的研究和验证，证明了我们的方法在推动半导体领域的领域适应技术中具有应用价值。", "innovation": "我们首次提出了一种名为DBACS的领域适应方法，该方法结合了CycleGAN框架并加入了额外的损失项，以提升在半导体制造过程中从缺陷图像分类方面应用的性能和效果。这种方法不仅提高了稳健性和泛化能力，还减少了对大规模人工重新标记的需求，从而显著降低了成本并提升了效率。", "conclusion": "我们的研究证明，DBACS方法在无监督和半监督设置中对于在实际电子显微镜图像上的缺陷分类具有高度的有效性和可靠性，这对于推动半导体领域的领域适应技术具有重要的实际意义。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15271", "html_url": "https://arxiv.org/abs/2506.15271", "title": "使用合成数据解锁后验数据集推断", "title_en": "Unlocking Post-hoc Dataset Inference with Synthetic Data", "authors": "Bihe Zhao,Pratyush Maini,Franziska Boenisch,Adam Dziedzic", "background": "大型语言模型（LLMs）的强大能力主要归因于其大规模训练数据集，这些数据集通常从互联网上收集，但未尊重数据所有者的知识产权。现有的数据推断（DI）方法通过检测疑似数据集是否曾在训练中使用来找到潜在的侵权行为，但这些方法依赖于一种私人收集的数据集——这是与受损数据集分布相匹配且训练中未包含的数据集，而这种数据集在实践中很难获得，极大地限制了DI的应用范围。", "innovation": "本文提出了一种新的解决方案，通过合成生成所需的私人数据集并实现数据推断（DI）。该方法克服了现有方法中存在的两个主要障碍：一是通过一个基于加尾标补全任务训练的数据生成器，创建高质量、多样化的合成数据，准确反映原始分布；二是通过后续校准缩小真实数据和合成数据之间的可信度差异。", "conclusion": "实验结果表明，使用该生成的合成数据作为私人数据集进行数据推断，能以高置信度检测出原始训练集，同时保持较低的误报率。这使得版权持有者能够对其数据使用提出合法的主张，并展示了该方法在实际法律纠纷中的可靠性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15290", "html_url": "https://arxiv.org/abs/2506.15290", "title": "基于服装感知扩散模型的松散稀疏惯性传感器人体运动捕捉", "title_en": "Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models", "authors": "Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz", "background": "基于运动捕捉相机的方法由于遮挡问题并不适用于所有情况，而使用稀疏惯性传感器的运动捕捉方法由于其便携性而显示出巨大潜力。现有方法通常假设惯性测量单元（IMU）传感器紧紧附着在人体上，但在现实场景中这一假设往往不成立。因此，该研究旨在利用稀疏、松散附着的IMU传感器解决全身体姿估计的问题，通过模拟获取数据并与服装相关的参数相结合，训练生成式模型来合成松散的IMU数据并估计人体姿态。", "innovation": "提出了使用基于服装感知的扩散模型，从松散稀疏的惯性传感器中捕捉人体运动的新任务。模拟IMU数据并开发基于变压器的扩散模型以合成松散的IMU数据，同时结合服装相关参数以保持其表达性并提高捕捉服装带来的不同变形的能力。", "conclusion": "通过训练基于合成和仿真的数据生成的方法，该研究展示了与当前最先进的方法相比在定量和定性方面的优势，为未来的研究提供了有希望的发展方向。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15301", "html_url": "https://arxiv.org/abs/2506.15301", "title": "基于LLM的临床试验招募辅助：一项综述", "title_en": "Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment", "authors": "Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff", "background": "近期大规模语言模型（LLM）的进展显著提升了通用自然语言处理（NLP）任务的性能。然而，这些模型在诸如临床试验招募等关键领域中的应用仍然有限。临床试验设计使用自然语言描述，患者数据包括结构化和非结构化文本。匹配临床试验与患者的过程受益于LLM的知识聚合和推理能力。现阶段的方法往往是针对特定临床试验的，而LLM能够整合分散知识，具有构建更通用解决方案的潜力。尽管如此，现有的LLM辅助方法依赖专有模型和薄弱的评估基准。因此，本文旨在分析临床试验患者匹配任务，探讨基于LLM的方法，并对现有基准、方法和评估框架进行批判性评估，同时指出在临床研究中采用LLM技术的挑战和未来的研究方向。", "innovation": "本文是首次分析基于LLM的临床试验患者匹配任务，并将新兴的LLM方法置入临床试验招募的背景下。论文既审视了现有的基准、方法和评估框架，也探讨了在临床研究中采用LLM技术面临的挑战，并提出了令人兴奋的未来研究方向。这些创新之处在于提供了一个全面的视角来理解LLM在临床研究中的应用潜力，并展示了如何克服相关挑战以进一步推进该领域的发展。", "conclusion": "尽管当前的LLM辅助方法依赖专有模型和缺乏充分的基准评估，但LLM在临床试验患者匹配任务中展示出巨大的潜力。论文呼吁建立通用的可比较基准和共享数据集，同时强调开发的灵活性和适应临床试验多样化需求的必要性，并展望了研究者需要共同探索的多维度未来研究方向。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15304", "html_url": "https://arxiv.org/abs/2506.15304", "title": "ConLID: 监督对比学习在低资源语言识别中的应用", "title_en": "ConLID: Supervised Contrastive Learning for Low-Resource Language Identification", "authors": "Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut", "background": "语言识别（LID）是构建多语言LLM预训练数据集的重要步骤，以往的研究集中在收集多样化训练数据以提高性能。然而，低资源语言往往只能依赖于单一领域的数据（如圣经），其识别性能仍然较差。这类语言在分类不平衡和偏向性方面存在明显问题，需要新的方法来改进其识别效果。", "innovation": "本文提出了一种新的监督对比学习（SCL）方法，旨在为低资源语言学习领域不变的表示，以此解决分类不平衡和偏见问题。该方法在低资源语言的领域外数据上显著提高了语言识别性能（提高3.2%），证明了其在增强LID模型方面具有有效性。", "conclusion": "通过广泛分析，该研究展示了ConLID方法在低资源语言字段外数据上的显著性能提升，验证了监督对比学习在低资源语言识别中的有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15309", "html_url": "https://arxiv.org/abs/2506.15309", "title": "Seq2Seq 变分自编码器指导的主动学习多靶点抑制剂生成", "title_en": "Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation", "authors": "Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar", "background": "在药物发现过程中，同时优化分子针对多个治疗靶点仍然是一项重大挑战，尤其是由于奖励稀疏和设计约束的冲突。", "innovation": "提出了一种结构化的主动学习（AL）范式，将序列到序列（Seq2Seq）变分自编码器（VAE）集成到迭代循环中，平衡化学多样性、分子质量和多目标亲和力。该方法交替扩展化学可行的潜在空间区域，并根据越来越严格的多目标对接阈值逐步限制分子。在针对三种相关冠状病毒主蛋白酶（SARS-CoV-2、SARS-CoV、MERS-CoV）的初步研究中，这种方法高效生成了一组结构多样且泛抑制剂候选物。展示了在主动学习流水线中仔细安排化学过滤器的时机和位置，显著增强对有利化学空间的探索，并将稀疏奖励、多目标药物设计问题转变为可访问的计算任务。因此，这种框架为高效探索复杂多药理学景观提供了一个可推广的路线图。", "conclusion": "该研究提供了一种通用方法，用于高效导航复杂的多药理学景观，将药物设计问题转化为可处理的计算任务。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15313", "html_url": "https://arxiv.org/abs/2506.15313", "title": "MapFM: 基于基础模型的多任务上下文学习高精地图生成", "title_en": "MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning", "authors": "Leonid Ivanov,Vasily Yuryev,Dmitry Yudin", "background": "在自动驾驶中，高精度（HD）地图和鸟瞰图（BEV）语义地图对于准确的定位、规划和决策至关重要。现有的方法展示了通过增强端到端模型MapFM来在线生成矢量化的HD地图，通过增强基础模型对摄像机图像的编码来显著提升特征表示的质量。在BEV表示中加入辅助的语义分割预测头部，以进一步丰富环境理解并提高预测质量。这种多任务学习方法为场景提供了更丰富的上下文监督，使得生成的矢量HD地图具有更高的准确性和更高质量。关于这个模型的源代码可以在提供的链接中获得。", "innovation": "MapFM是一种增强的端到端模型，用于在线生成矢量化的高精度地图。它通过引入强有力的基础模型来提高摄像机图像的特征表示质量，同时在BEV表示中集成辅助预测头部来进行语义分割，以提升对环境的理解和预测质量。这种多任务学习方法提供更全面的场景表示，从而提高了预测的高精度地图的准确性和质量。", "conclusion": "通过对摄像机图像的特征表示进行增强，并在BEV表示中集成辅助预测头部，MapFM提出了一个多任务上下文学习方法，为自动驾驶场景提供更准确和高质量的矢量HD地图生成。这将有助于提高自动驾驶系统的整体性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15316", "html_url": "https://arxiv.org/abs/2506.15316", "title": "J3DAI: 一个基于DNN的3D堆叠CMOS图像传感器边缘AI加速器", "title_en": "J3DAI: A tiny DNN-Based Edge AI Accelerator for 3D-Stacked CMOS Image Sensor", "authors": "Benoit Tain,Raphael Millet,Romain Lemaire,Michal Szczepanski,Laurent Alacoque,Emmanuel Pluchart,Sylvain Choisnet,Rohit Prasad,Jerome Chossat,Pascal Pierunek,Pascal Vivet,Sebastien Thuries", "background": "本文提出了J3DAI，这是一种基于深度神经网络的硬件加速器，用于3层3D堆叠CMOS图像传感器，其中集成了一个基于深度神经网络（DNN）的加速器。DNN加速器被设计用于高效地执行神经网络任务，如图像分类和分割。本文重点介绍了J3DAI的数字系统及其性能-功耗-面积（PPA）特性，展示了其在CMOS图像传感器上的先进边缘AI能力。为了支持硬件，我们使用了Aidge综合软件框架，该框架能够为宿主处理器和DNN加速器编程。Aidge支持训练后量化，显著减少了内存占用和计算复杂性，这对于在资源受限的硬件如J3DAI上部署模型至关重要。实验结果表明，该创新设计在边缘AI领域的 versatility 和 efficiency，展示了其处理简单和复杂计算任务的潜力。未来的工作将重点关注进一步优化架构并探索新的应用，以充分利用J3DAI的能力。随着边缘AI的重要性不断增长，创新如J3DAI将在实现实时、低延迟和能耗高效的AI处理方面发挥关键作用。", "innovation": "J3DAI硬件加速器的设计整合了DNN加速器，使其能够高效执行神经网络任务，如图像分类和分割。该硬件利用了Aidge综合软件框架，支持训练后量化，减少了对资源的依赖，特别适用于资源受限的硬件。J3DAI展示了其在处理各种不同复杂度任务的 versatility 和 efficiency，对于推动边缘AI的发展起到了关键作用。", "conclusion": "该创新设计在边缘AI领域的 versatility 和 efficiency，展示了其处理简单和复杂计算任务的潜力。未来的工作将重点关注进一步优化架构并探索新的应用，以充分利用J3DAI的能力。随着边缘AI的重要性不断增长，创新如J3DAI将在实现实时、低延迟和能耗高效的AI处理方面发挥关键作用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15329", "html_url": "https://arxiv.org/abs/2506.15329", "title": "当且如何证明未标记数据提高上下文学习效果", "title_en": "When and How Unlabeled Data Provably Improve In-Context Learning", "authors": "Yingcong Li,Xiangyu Chang,Muti Kara,Xiaofeng Liu,Amit Roy-Chowdhury,Samet Oymak", "background": "近期研究显示，即使在示范信息有缺失或错误标签的情况下，上下文学习（ICL）仍然有效。为深入探讨这一能力，研究者们在示范按照二元高斯混合模型（GMM）随机抽取且一部分示范存在未标记情况的场景下进行了研究。研究分析了一层线性注意力模型与多层或循环变换器在利用未标记数据方面的表现差异。一层线性注意力模型在损失景观上能恢复完全标记情况下的最优估计，但无法利用未标记数据；而多层或循环变换器则能够通过隐式构造特定形式的估计器，有效利用未标记数据。这些估计器的形式导致了与期望最大化算法（EM算法）的联系，该算法是一种常用的半监督学习迭代伪标记法。研究还发现，多项式的高次幂与模型深度有关，因此少量的深度或循环层数就足以实现这一效果。", "innovation": "该研究提供了一个全面的理论研究，表明在二元高斯混合模型下，多层或循环变换器能够通过隐式构建特定形式的估计器，有效利用未标记数据。这与经典EM算法进行了联系，并强调了模型深度与多项式高次幂的关系，即少量的深度或循环层数就足以实现充分利用未标记数据。此外，研究还提出了利用循环改进现成表格基础模型的半监督学习能力的方法，并通过实际数据集的广泛评估验证了该方法的有效性。", "conclusion": "研究证明，在某些条件下，即使是有缺失或错误标签的未标记数据也能提高上下文学习的效果。通过构建特定形式的估计器，多层或循环变换器可以更有效地利用未标记数据，同时与经典半监督学习方法（如EM算法）建立了联系。提出的循环方法不仅在理论上有效，而且在实际数据集中的评估也显示出了显著的改进效果。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15368", "html_url": "https://arxiv.org/abs/2506.15368", "title": "视频中的开放世界对象计数", "title_en": "Open-World Object Counting in Videos", "authors": "Niki Amini-Naieni,Andrew Zisserman", "background": "该研究旨在解决视频中开放世界的对象计数问题，即给定文本描述或图像实例以指定目标对象，目的是在视频中枚举所有的目标对象实例。此任务在拥挤场景中的遮挡和相似对象中特别具有挑战性，回避重复计数和识别重复出现的对象至关重要。现有的方法可能无法有效地管理和提取目标对象的信息，特别是在复杂的背景和遮挡情况下.", "innovation": "研究引入了一个新的名为CountVid的模型，这一模型结合了基于图像的对象计数模型和可提示的视频分割与跟踪模型，为视频的开放世界对象计数提供了自动化的解决方案。同时，研究人员创建了一个新的数据集VideoCount，该数据集包含从TAO和MOT20追踪数据集以及其他特定领域视频（如企鹅和金属合金结晶）中提取的数据，用于评估性能，实验结果表明CountVid模型在准确性和性能上显著优于现有的基线方法.", "conclusion": "通过使用VideoCount数据集，研究展示了CountVid模型提供了准确的对象计数，并且在所有对基准测试中表现突出，模型及其代码已公开提供."}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15388", "html_url": "https://arxiv.org/abs/2506.15388", "title": "系统化搜索异常检测系统的评估管道", "title_en": "Evaluation Pipeline for systematically searching for Anomaly Detection Systems", "authors": "Florian Rokohl,Alexander Lehnert,Marc Reichenbach", "background": "数字化在医疗领域提供了许多益处，但同时也使得医疗网络成为攻击的目标，增加了保护网络的安全性难度。为了应对网络入侵者，作者提出了一种基于硬件的实时异常检测系统来检测恶意客户端。该检测系统利用FPGA在满足实时性和功耗限制的同时实现系统的整体性能，通过提出的整体系统评估，实现对系统性能的评估和优化，确保系统在保证性能的同时能够有效防止和检测恶意行为。", "innovation": "作者在医疗环境中提出了一种新的实时异常检测系统方案，利用FPGA技术来处理实时性和功耗的需求，从而有效提高了系统的整体性能，同时确保了系统的安全性。这种方法区别于传统的基于软件的检测系统，带来了更好的实时响应能力和稳定性。", "conclusion": "基于FPGA的实时异常检测系统在满足系统实时性和功耗需求的前提下，实现了对恶意客户端的有效检测，通过整体系统性能评估优化了系统的实际应用效果，提供了在医疗环境中一种新的安全防护策略。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15395", "html_url": "https://arxiv.org/abs/2506.15395", "title": "实时内窥镜图像去噪系统", "title_en": "A Real-time Endoscopic Image Denoising System", "authors": "Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui", "background": "随着内窥镜设计的小型化，它们显著提升了操作灵活性、便携性和诊断能力，并大幅降低了医疗程序的侵入性。最近，带有超紧凑型模拟图像传感器（尺寸小于1mm x 1mm）的一次性内窥镜带来革命性的进展，减少了重复使用设备的结构冗余和高额资本支出，消除了因消毒不当引起的患者感染风险，并减轻了患者的痛苦。但由于传感器的感光面积有限，导致每个像素捕获的光子减少，需要更高的光子灵敏度设置以保持足够的亮度。在高对比度的医疗成像场景中，小型传感器动态范围有限，难以同时捕捉高光区和阴影区的细节，需要额外的局部数字增益补偿。此外，简化电路设计和模拟信号传输引入了额外的噪声源，这些因素导致处理后的内窥镜图像中存在显著的噪声问题。", "innovation": "本文开发了一种全面的模拟图像传感器噪声模型，解决了固定模式噪声、周期性条带噪声和混合泊松-高斯噪声三种主要噪声类型。在此基础上，提出了一种结合传统图像处理算法和先进学习技术的混合去噪系统，应用于传感器捕获的原始帧。实验表明，该方法有效地减少了图像噪声，同时没有损失精细细节或色彩失真，实现在FPGA平台上的实时性能，并在测试数据集上平均PSNR提高了11.89。", "conclusion": "本研究通过开发一个系统性的噪声模型，并结合传统算法和学习技术提出了实时内窥镜图像去噪系统，成功提高了图像质量，同时保持了实时处理能力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15402", "html_url": "https://arxiv.org/abs/2506.15402", "title": "MCOO-SLAM: 一种球形多相机对象SLAM系统", "title_en": "MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System", "authors": "Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue", "background": "对象级SLAM可以提供结构化和语义丰富的环境表示，使其更易于解释，并适用于高级机器人任务。然而，现有方法通常依赖于RGB-D传感器或单目视图，这些方法在大范围或户外环境中容易受到视野狭窄、遮挡敏感性和深度感知有限的影响。这些限制往往使系统只能从有限的角度观察物体的部分视角，导致物体建模不准确和数据关联不可靠。因此，本研究提出了MCOO-SLAM，这是一种新颖的多相机全景对象SLAM系统，通过充分利用周围视图相机配置来实现复杂户外场景下的稳健、一致和语义丰富的制图。该方法结合了点特征和增强有词汇量语义的对象级地标，并引入了语义-几何-时间融合策略来实现多视图中的稳健对象关联，进一步，设计了一个全景循环闭合模块来使用场景级描述符实现视点无关的地点识别。此外，构建的地图被抽象为层次化3D场景图以支持后续推理任务。实验证明MCOO-SLAM实现了准确的定位和扩展的对象级制图，同时增强了在遮挡、姿态变化和环境复杂性方面的鲁棒性。", "innovation": "本研究提出了MCOO-SLAM，这是一种新颖的多相机全景对象SLAM系统，通过充分利用周围视图相机配置实现复杂户外场景下的稳健和一致制图。该方法结合了点特征和增强有词汇量语义的对象级地标，并引入了语义-几何-时间融合策略来实现多视图中的稳健对象关联，进一步设计了一个全景循环闭合模块以实现视点无关的地点识别。此外，所构建的地图被抽象为层次化3D场景图以支持后续推理任务。", "conclusion": "MCOO-SLAM在实际环境中的广泛实验表明，该系统能够实现准确的定位和可扩展的对象级制图，并在遮挡、姿态变化和环境复杂性方面表现出更强的鲁棒性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15408", "html_url": "https://arxiv.org/abs/2506.15408", "title": "统一的VXAI：解释性人工智能的系统回顾与评估框架", "title_en": "Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI", "authors": "David Dembinsky,Adriano Lucieri,Stanislav Frolov,Hiba Najjar,Ko Watanabe,Andreas Dengel", "background": "现代AI系统广泛使用复杂且难以理解的黑盒模型，尤其是深层神经网络，这些模型的性能依赖于其内部的复杂结构和数百万参数。尽管这些模型非常强大，但其复杂性也带来了可信度问题，特别是在透明度缺乏的情况下。解释性AI（XAI）通过提供易于理解的模型行为解释来解决这些问题，但要确保其有用性和可信度，必须对这些解释进行严格的评估。尽管现有的XAI方法数量在增加，但该领域缺乏标准化的评估协议和关于适当度量标准的共识。", "innovation": "进行了一项遵循PRISMA指南的系统文献综述，提出了一个统一的XAI评估框架（VXAI），并确定了362篇相关出版物，将它们的贡献聚合到41个功能相似的度量组中。此外，提出了一个三维分类方案，涵盖解释类型、评价情境性和解释质量要求。该框架是迄今为止最全面和结构化的VXAI概述，支持系统性度量选择、促进方法间的可比性，并为未来扩展提供灵活的基础。", "conclusion": "该框架目前提供了最完整的和结构化的VXAI概览，支持系统度量选择，促进方法间的可比性，并为未来扩展提供灵活的基础。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15421", "html_url": "https://arxiv.org/abs/2506.15421", "title": "深度强化学习中的奖励模型：综述", "title_en": "Reward Models in Deep Reinforcement Learning: A Survey", "authors": "Rui Yu,Shenghua Wan,Yucen Wang,Chen-Xiao Gao,Le Gan,Zongzhang Zhang,De-Chuan Zhan", "background": "在强化学习（RL）中，代理持续与环境互动并利用反馈来改善其行为。为了引导策略优化，引入了奖励模型作为目标的代理，当代理最大化累积奖励时，实际上也实现了任务设计者的目标。最近，学术界和工业界研究人员都开始重视开发既与真实目标紧密匹配又有利于策略优化的奖励模型。本文对深度强化学习文献中的奖励建模技术进行了全面回顾，指出了奖励建模的背景和基础概念，并对当前奖励模型方法进行了梳理分类，讨论了这些方法的应用，并审查了评估奖励模型的方法。", "innovation": "本文提供了深度强化学习文献中奖励建模技术的全面回顾，概括了建模背景和基础概念，梳理并分类了最新的奖励建模方法，探讨了这些方法的应用，并审阅了评估奖励模型的方法。并且强调了奖励建模的研究方向，填补了当前文献中系统化回顾奖励模型的空白，提供了一个全面的视角，有助于该领域的进一步发展和研究。", "conclusion": "本文强调了奖励建模的研究前景，指出了深度强化学习领域中奖励模型的发展方向，为未来的研究指明了路径。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15442", "html_url": "https://arxiv.org/abs/2506.15442", "title": "Hunyuan3D 2.1: 从图像到高保真3D资产的生产级PBR材质", "title_en": "Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material", "authors": "Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo", "background": "3D AI生成内容（AIGC）是一个充满激情的领域，极大地促进了游戏、电影和设计中的3D模型创建。尽管已经开发了多个革命性的3D生成模型，但该领域仍然仅对研究人员、开发人员和设计师开放，这主要是因为收集、处理和训练3D模型的复杂性。为了应对这些挑战，本文档以Hunyuan3D 2.1为例进行案例研究。文档提供了从3D数据处理到训练3D生成模型，再到使用Hunyuan3D 2.1进行高性能评估的全面、分步指南。Hunyuan3D 2.1系统包括两个核心组件：Hunyuan3D-DiT用于形状生成，Hunyuan3D-Paint用于纹理合成。整个工作流包括数据准备、模型架构、训练策略、评估指标和部署.", "innovation": "该文档通过Hunyuan3D 2.1提供了一种全流程的方法，从图像生成高分辨率的3D资产，并使用生产级PBR材质。这为游戏、虚拟现实和工业设计中的3D生成模型的应用提供了新的可能，简化了3D模型的创建过程，使得非技术专业人士也能容易地使用3D生成技术。", "conclusion": "通过本教程，读者将掌握如何微调或开发适合游戏、虚拟现实和工业设计等应用的稳健的3D生成模型。最终目标是提高3D生成内容在工业和消费市场的适用性，降低技术门槛，加速行业发展。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15446", "html_url": "https://arxiv.org/abs/2506.15446", "title": "零观测下的零样本强化学习", "title_en": "Zero-Shot Reinforcement Learning Under Partial Observability", "authors": "Scott Jeen,Tom Bewley,Jonathan M. Cullen", "background": "最近的研究表明，在某些假设下，零样本强化学习方法可以在不需要任何奖励信号的情况下进行预训练，并能够泛化到环境中任何未见过的任务。其中，马尔科夫状态的假设是关键之一。然而，在许多实际应用中，马尔科夫状态是部分可观的。本研究探讨了在部分可观情况下标准零样本RL方法的性能下降情况，并发现与单一任务RL类似，基于记忆的架构可以有效改进这一问题。", "innovation": "该研究创新性地探索了在部分可观情况下零样本RL方法的性能，并验证了基于记忆的架构能有效提高在此情况下的表现。实验评估了基于记忆的方法，在状态、奖励和动力学变化部分可观的领域中，展示了相比无记忆基线的改进性能。研究成果已开源。", "conclusion": "研究结果表明，即使在马尔科夫状态部分可观的情况下，使用基于记忆的架构也能在零样本强化学习任务中显著提高性能。未来工作将考虑更复杂和多样化的部分可观场景，以及进一步优化基于记忆的方法。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15452", "html_url": "https://arxiv.org/abs/2506.15452", "title": "时间序列之间扭曲与子序列匹配", "title_en": "Warping and Matching Subsequences Between Time Series", "authors": "Simiao Lin,Wannes Meert,Pieter Robberechts,Hendrik Blockeel", "background": "时间序列比较在聚类和分类等任务中至关重要。虽然弹性距离度量允许扭曲提供了稳健的定量比较，但在进行定性比较时仍然缺乏。传统的可视化方法主要关注点对点对齐，未能传达子序列的更广泛结构关系。这种局限性使得理解一个时间序列相对于另一个时间序列如何、何时以及在何处发生位移、加速或减速变得困难。", "innovation": "本文提出了一种新颖的方法，简化了扭曲路径以突出显示、量化并可视化关键转换（位移、压缩、振幅差异）。通过提供更清晰地表示时间序列之间子序列匹配的方式，该方法增强了解释性，改进了时间序列比较。", "conclusion": "通过提供更清晰地表示时间序列之间子序列匹配的方式，本文的方法增强了时间序列比较的解释性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15453", "html_url": "https://arxiv.org/abs/2506.15453", "title": "通过LLM驱动的代码片段描述生成揭示意图", "title_en": "Uncovering Intention through LLM-Driven Code Snippet Description Generation", "authors": "Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto", "background": "文档化的代码片段对于开发人员和用户识别关键区域至关重要，尤其是在说明使用示例和API方面。随着大型语言模型（LLMs）的兴起，研究开发人员常用描述类型，并评估LLM在描述生成上的支持能力变得尤为重要。研究使用NPM中的代码片段，包括185,412个包和1,024,579个代码片段。通过400个代码片段及其描述作为样本进行分析，发现大部分原始描述（55.5%）侧重于示例性用途，这突显了清晰文档的重要性，一些描述缺乏足够的细节来传达意图。", "innovation": "研究评估了大型语言模型（LLM）支持代码片段描述生成的能力，尤其是在示例识别和描述生成相似性方面，表明LLM在一般化方面具有优势，但描述生成仍存在改进空间，不完全相关的情况占比为10.25%，低于90%的相似度标准表明其存在一定的不准确性。研究结果显示，依赖于代码片段的任务，文档意图可能有所不同，可能是使用说明、安装说明或任何库使用者学习示例的描述性学习案例。", "conclusion": "研究结果揭示了代码片段描述生成的意图，强调了清晰文档的重要性，同时也指出了LLM在描述生成上的局限性，未来可以进一步优化LLM在代码文档生成的精准度和效率。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15455", "html_url": "https://arxiv.org/abs/2506.15455", "title": "RE-IMAGINE：逻辑推理能力评估的符号基准合成", "title_en": "RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation", "authors": "Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez", "background": "最近的大规模语言模型（LLMs）在逻辑推理基准上的表现准确度很高，但这些结果是否真正反映出了模型的推理能力，还是只是统计地回忆了训练集的内容尚不清楚。受到因果等级阶梯（Pearl, 2009）及其三个层次（关联、干预和反事实）的启发，本文提出了一种框架（RE-IMAGINE）以定性描述LLMs的推理能力层次，同时提供了一个自动流水线生成不同层次逻辑问题变体的方法。通过调整中间的符号表示方式，RE-IMAGINE能够生成仅依靠记忆无法解决的问题。此外，该框架具有普适性，可以跨诸多领域，包括数学、编程和逻辑，进行推理能力评估。这种方法已在四个广泛应用的基准评估了几个家族的LLMs，观察到当使用问题变体询问模型时性能下降，这表明模型过往表现中有统计回忆依赖的成分，提示了更多关于逻辑推理层级上技能研究的潜力。", "innovation": "提出了RE-IMAGINE框架，该框架能够定性描述LLMs的推理能力层次，并通过自动流水线生成不同层次的逻辑问题变体。该方法可以应用于数学、编程和逻辑等多个领域，并已经在四个广泛使用的基准上评估了多个家族的LLMs，展示了这些模型在处理问题变体时的性能下降，从而揭示了统计回忆对过去性能的依赖。这为针对推理能力各个层次的技能进一步研究打开了新的研究方向。", "conclusion": "该研究通过RE-IMAGINE框架，提高了理解LLMs推理能力的视角，并通过生成问题变体的自动化流程，揭示了统计回忆对模型过去性能的影响，为进一步研究逻辑推理金字塔上不同的技能提供了新的机会。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15468", "html_url": "https://arxiv.org/abs/2506.15468", "title": "通过人类和AI之间的资源赫斯特交互实现共创造性学习", "title_en": "Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI", "authors": "Ryota Okumura,Tadahiro Taniguchi,Akira Taniguchi,Yoshinobu Hagiwara", "background": "该研究背景在于探讨传统的人工智能教育中单向知识传递的局限性，特别是当需要整合来自不同感知模态的信息时，这一局限性尤为明显。研究者认为，人类和人工智能（AI）通过互相整合各自的感知信息和知识，共同构建共享的外部表示，这一过程可以理解为符号的形成，以此克服上述挑战并提出了一种新的学习范式——共创造性学习（Co-creative Learning）。", "innovation": "研究创新之处在于提出了一种新的共创造性学习范式，其中人类与AI能够相互整合自己的部分感知信息和知识，从而共同构建共享的外部表示形式，并在此过程中形成符号。不同于传统的单向知识传递，该方法利用了Metropolis-Hastings命名游戏（MHNG），一种分散式的贝叶斯推理机制进行测试。实验结果显示，人类与基于MH的AI交互可以显著提高分类准确性并朝着共享符号系统的共识方向取得更强的收敛，人类的接受行为也与MH推导出的接受概率高度一致，为共创造性学习在人类-AI交互中的实际应用提供了实证支持。", "conclusion": "研究结果表明，共创造性学习在人类-AI组合中通过MHNG交互形式能够实现，这为未来人机共生系统的开发提供了新的思路，即通过动态对齐感知体验，使得AI能够与人类一同学习，而非仅仅是模仿人类，这一发现揭示了一条有望实现人机共生智能系统的新路径。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15480", "html_url": "https://arxiv.org/abs/2506.15480", "title": "Context-Informed Grounding Supervision", "title_en": "Context-Informed Grounding Supervision", "authors": "Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo", "background": "大型语言模型（LLMs）常需要外部知识来提供模型参数中未编码的信息或减少幻觉。在这种情况下，通常期望模型依据提供的外部上下文生成响应，但现有研究表明，仅在推理时添加上下文并不能保证生成的响应是基于上下文的。因此，需要提出一种新的方法来确保模型的响应是基于上下文的。人们的期望是，通过这种方法，模型能够在文本和视觉领域中更好地实现语境化生成，从而减少幻觉并提高生成信息的一致性。", "innovation": "提出了Context-INformed Grounding Supervision（CINGS），这是一种后训练监督方法，在训练过程中，模型的响应前缀加上相关上下文，但在计算损失时只考虑响应令牌，并屏蔽掉上下文。实验结果显示，使用CINGS训练的模型在文本和视觉领域中的语境化表现优于标准指令调优模型和其他训练方法，特别是在信息查询数据集和视觉-语言基准测试中，CINGS在减少幻觉和保持事实一致性方面表现出色，且不会影响下游任务的一般性能。进一步分析结果显示，CINGS通过改变模型的先验知识和行为，间接促使模型更依赖外部上下文，从而增强其语境化能力。", "conclusion": "使用CINGS训练的模型在保持通用性能的同时，在文本和视觉领域中表现出更强的语境化能力，特别是在减少幻觉和保持生成内容的一致性方面优于其他训练方法。这种方法通过改变模型的先验知识和行为，实现了这种语境化的增强。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15483", "html_url": "https://arxiv.org/abs/2506.15483", "title": "GenHOI: 对于未见物体的文本驱动4D人类物体交互合成的泛化", "title_en": "GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects", "authors": "Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban", "background": "虽然扩散模型和大规模运动数据集提高了由文本驱动的人体动作合成水平，但将这些进步扩展到4D人类-物体交互（HOI）仍然充满挑战，主要原因是缺乏大规模的4D HOI数据集。现有的方法主要依赖于少量的3D HOI数据集进行训练，难以应对未见物体的场景。因此，GehOI框架旨在解决这两个关键问题：一是泛化到未见物体；二是生成高质量的4D HOI序列。该框架通过两阶段的方法，首先是使用Object-AnchorNet重建未见物体的稀疏3D HOI关键帧，从而不依赖大规模4D HOI数据集。第二阶段引入Contact-Aware Diffusion Model (ContactDM)来平稳地将稀疏的3D HOI关键帧插值成密集的时间连贯的4D HOI序列。", "innovation": "GehOI通过引入Contact-Aware Diffusion Model (ContactDM)和两个创新模块实现了创新：首先，使用Object-AnchorNet从3D HOI数据集中学习，重建未见物体的关键帧，解决了对大规模4D HOI数据集的依赖问题。其次，在第二阶段，通过设计Contact-Aware Encoder和Contact-Aware HOI Attention，有效地融合人类-物体接触信号，提高生成的4D HOI序列的质量。这使得GenHOI在公开的OMOMO和3D-FUTURE数据集上表现出卓越的效果，具备强大的未见物体的泛化能力，能够生成高质量的4D HOI序列。", "conclusion": "实验结果显示，GehOI在现有的OMOMO和3D-FUTURE数据集上达到了最先进的表现，展示了对未见物体的强大泛化能力，同时也能够生成高质量的4D HOI序列。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15498", "html_url": "https://arxiv.org/abs/2506.15498", "title": "SPARE: 单次通过注释与参考指导评估在自动过程监督与奖励建模中的应用", "title_en": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling", "authors": "Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych", "background": "复杂多步骤推理能力是大型语言模型（LLMs）向前发展的重要因素，其中过程或步骤级监督发挥了关键作用。然而，高效的高质量自动化过程标注仍然是一项重大的挑战。现有的方法需要多步或多阶段的检查与校对，不但费时而且复杂度高。本研究旨在解决这个问题，提出了一个新的单次通过并带有参考指导评估的框架(Single-Pass Annotation with Reference-Guided Evaluation, SPARE)，该框架能够进行一步到位的逐步骤标注，通过将每个解题步骤与一个或多个参考解决方案的步骤对齐，并附带明确的评估理由来提高效率和准确性。", "innovation": "该研究创新性地提出了SPARE框架，这是一种结构化的单次通过，并带有参考指导评估的新方法。SPARE通过将每个解题步骤与参考解决方案的某一步或几步对齐，并提供详细的评估理由，从而实现了高效的逐步骤标注。实验结果显示，与基线方法相比，SPARE提高了LLMs的推理性能：一是通过离线强化学习设置下的微调模型来提高推理时间的贪婪解码性能；二是通过训练奖励模型来对多个LLM生成的输出进行排名/聚合。此外，SPARE在具有挑战性的数学数据集上表现出竞争力，效率比基于树搜索的自动注释方法提高了2.6倍，仅需38%的运行时间。该代码库及训练好的SPARE-PRM模型已公开发布，以促进进一步的研究和可重复性的工作。", "conclusion": "SPARE框架通过参考指导的方式在提高自动化过程监督的效率和质量方面取得了显著进步，特别是在处理多步骤推理问题时展现出显著的性能提升。该研究为中国及其他地区的进一步研究提供了基础，并为提高大型语言模型的多步骤推理能力提供了有力的技术支持。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15499", "html_url": "https://arxiv.org/abs/2506.15499", "title": "基于随机平滑的像素级认证解释", "title_en": "Pixel-level Certified Explanations via Randomized Smoothing", "authors": "Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele", "background": "后 hoc 归因方法旨在通过强调影响预测的关键输入像素来解释深度学习的预测。然而，这些解释非常高灵敏：即使微小且难以感知的输入扰动也能剧烈改变归因图，同时保持相同的预测。这种脆弱性削弱了它们的可信度，并且需要对像素级归因评分提供严格的鲁棒性保证。已有方法无法满足对任意黑盒归因方法提供鲁棒保证的需求，本研究填补了这一空白，提出了首个通过随机平滑技术提供像素级鲁棒性的认证框架，这种方法能够将任务重新表述为分段问题，并对 $\boldsymbol{\boldsymbol{\textbf{l}}}_{2}$ 可界扰动认证每个像素的重要性。此外，还提出了三种评估认证鲁棒性、定位性和忠实性的度量标准，涵盖了 5 个 ImageNet 模型中的 12 种归因方法，都证实了认证归因的鲁棒性、可解释性及其对下游任务的可靠性是值得信赖的。", "innovation": "首次引入使用随机平滑技术认证任何黑盒归因方法的像素级鲁棒性框架。通过稀疏和平滑化归因图，将任务重新表述为分段问题，并针对 $\boldsymbol{\boldsymbol{\textbf{l}}}_{2}$ 可界扰动认证每个像素的重要性。进一步提出三种评估认证鲁棒性、定位性和忠实性的度量标准。", "conclusion": "在对 5 个 ImageNet 模型中的 12 种归因方法进行广泛的评估中，证实认证归因是鲁棒的、可解释的、忠实的，能够确保下游任务的可靠使用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15507", "html_url": "https://arxiv.org/abs/2506.15507", "title": "时空图神经网络中的过度压缩问题", "title_en": "Over-squashing in Spatiotemporal Graph Neural Networks", "authors": "Ivan Marisca,Jacob Bamberger,Cesare Alippi,Michael M. Bronstein", "background": "图神经网络（GNNs）在多个领域取得了显著的成功。然而，最近的理论研究表明，它们在信息传播能力方面存在根本性限制，比如过度压缩现象，导致远距离节点难以有效交换信息。这些问题在静态场景下已经被广泛研究，但在时空图神经网络（STGNNs）中尚未得到探索，而STGNNs用于处理与图节点相关的序列。时空维度增加了信息传播的难度，因为需要传播的信息量更大。因此，本文旨在对此问题进行形式化，并分析其与静态情况的不同特点。研究表明，意外的是，卷积STGNN倾向于从时间上遥远的节点传播信息，而不是时间相近的节点。进一步的分析显示，无论是遵循时间和空间并行处理还是时间后处理空间的架构都受到此现象的影响。", "innovation": "本文对时空图神经网络中的过度压缩问题进行了形式化分析，揭示了与静态情况的不同特性。证明了无论是遵循时间和空间并行处理还是时间后处理空间的架构都受到此现象的影响，为高效的计算实现提供了理论依据。通过合成数据集和真实世界数据集验证了研究发现，加深了对时空图神经网络工作的动态理解和提供更有效设计的依据。", "conclusion": "本文验证了研究发现，发现了卷积STGNN倾向于从时间上遥远的节点传播信息，而非更近时间的节点。证明了无论是时间和空间并行处理还是时间后处理空间的架构都受到此现象的影响。为时空图神经网络的设计提供了理论支持和实用指导。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15512", "html_url": "https://arxiv.org/abs/2506.15512", "title": "利用GPT整合在LangChain中的CoT增强提示工程方法优化基于Web的AI查询检索", "title_en": "Optimizing Web-Based AI Query Retrieval with GPT Integration in LangChain A CoT-Enhanced Prompt Engineering Approach", "authors": "Wenqi Guan,Yang Fang", "background": "大型语言模型在远程学习中的应用带来了教育活动上的重大变革，但当前的远程学习资源检索在处理复杂学生查询时缺乏深度的上下文意义，提供的信息不够全面。", "innovation": "本文提出了一种新的方法，通过将在LangChain框架中集成基于GPT的模型来增强远程学习检索，采用CoT推理和提示工程使系统更加直观和高效。这种方法强调提高检索结果的精确性和相关性，以提供全面且具有上下文的信息，更好地满足每个学生的需求。同时，本研究还评估了该方法与代表性语言模型的性能，并报告了用户满意度和学习成果的提升。", "conclusion": "通过集成基于GPT的模型和使用CoT推理与提示工程，LangChain框架有效提升了远程学习资源的检索质量，增强了用户满意度和学习效果。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15513", "html_url": "https://arxiv.org/abs/2506.15513", "title": "RePCS：诊断由LLM驱动的RAG系统中的数据记忆问题", "title_en": "RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation", "authors": "Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Luong Van Nghia", "background": "RAG已经成为使用当前外部信息更新大规模语言模型（LLM）响应的常见策略。然而，模型仍然可能会依赖于记忆中的训练数据，而不是利用检索到的证据，从而产生受污染的输出。", "innovation": "提出了一个名为RePCS的诊断方法，该方法可以检测这种行为，而无需访问模型或重新训练。RePCS通过计算使用查询和检索上下文的输出分布之间的Kullback-Leibler（KL）发散来比较两种推理路径：仅使用查询的参数路径和使用查询和检索上下文的检索增强路径。KL发散低表明检索上下文的影响极其有限，可能暗示模型在记忆数据。该方法模型无关，不需要梯度或内部状态访问，并且只需要一个附加的前向传递。此外，还推导了一种类似于PAC的方法，将KL阈值与用户定义的假阳性率和假阴性率联系起来。在Prompt-WNQA基准上，RePCS实现了0.918的ROC-AUC，这比之前最强的方法高出6.5个百分点，同时保持了NVIDIA T4 GPU下4.7%以下的延迟开销。RePCS提供了一种轻量级的黑盒保护，用于验证RAG系统是否真正利用了检索，尤其是在安全性关键的应用程序中特别有价值。", "conclusion": "RePCS是一种轻量级且无需修改的诊断方法，可以在不访问模型或重新训练的情况下，检测RAG系统中的数据记忆问题，从而确保了模型在使用检索上下文时的有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15538", "html_url": "https://arxiv.org/abs/2506.15538", "title": "使用PRISM捕捉多义性：一个多层次特征描述框架", "title_en": "Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework", "authors": "Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M.-C. Höhne,Oliver Eberle", "background": "自动可解释性研究旨在通过识别神经网络特征中包含的概念来增强对模型行为的理解。当前的特征描述方法面临两大挑战：鲁棒性有限以及单一神经元只编码单一概念（单义性）的假设，尽管有越来越多的证据表明神经元往往是多义性的。这种假设限制了特征描述的表达能力和捕捉模型内部全面行为的能力。因此，有必要引入一种能够捕捉神经网络特征内在复杂性的新框架来解决上述问题。", "innovation": "为解决上述问题，该文提出了一种名为Polysemantic FeatuRe Identification and Scoring Method (PRISM)的新型框架。PRISM采用的特征描述方法不同于以往单一特征单描述的方式，对多义性和单义性特征都提供更细微的描述。该方法被应用于语言模型，并通过与现有方法的广泛基准测试证明了其能够生成更准确和忠实的特征描述，提升整体描述质量和多义性概念捕捉能力（通过描述评分和多义性评分）.", "conclusion": "通过引入PRISM框架，论文展示了如何更准确地描述和捕捉神经网络特征的多义性，从而提高了对模型内部行为的理解。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15541", "html_url": "https://arxiv.org/abs/2506.15541", "title": "内在和外在组织的注意力机制: 软最大化不变性和网络稀疏性", "title_en": "Intrinsic and Extrinsic Organized Attention: Softmax Invariance and Network Sparsity", "authors": "Oluwadamilola Fasina,Ruben V.C. Pohle,Pei-Chun Su,Ronald R. Coifman", "background": "该研究探讨了 transformer 中自注意力机制的内在（在注意力头内部）和外在（在注意力头之间）结构。研究使用了 paradifferential calculus 及现有的张量分层组织方法，通过查询、键和头轴构建分层分区树，来解析网络结构。这种组织方式允许在特定几何结构上执行信号处理任务，其中网络张量显示规律性。研究还通过视觉和语言的 transformer 提供了计算实例以展示这些发现的实际用途。", "innovation": "研究通过 paradifferential calculus 理论证明了自注意力机制对 softmax 激活的不变性，并利用现有的张量分层组织方法解析了网络结构。通过分层分区树的构建，具体展示了一种组织方法，使得在特定几何结构上执行信号处理任务更为有效。该研究为后续的解释性分析提供了理论依据，并展示了使用网络 3 张量组织进行网络稀疏性分析、模型剪枝和网络结构比较等实际应用的可能性。", "conclusion": "研究分为两个方面的影响：首先，它为解释性分析提供了理论基础，并可以用于解决下游任务的实际问题；其次，通过网络 3 层张量的组织可以用于模型剪枝和网络架构比较等实际应用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15543", "html_url": "https://arxiv.org/abs/2506.15543", "title": "学习算法在极限中的学习", "title_en": "Learning Algorithms in the Limit", "authors": "Hristo Papazov,Nicolas Flammarion", "background": "本文研究了在Gold归纳推理框架基础上扩展出的学习可计算函数的问题，特别是通过结合计算观测和受限输入源来学习函数。在传统的输入输出观测基础上，引入了时间限制观测和策略轨迹观测，以研究在更现实约束条件下一般递归函数的可学习性。尽管输入输出观测不足以学习一般递归函数类的所有函数，但通过施加计算复杂度约束或补充近似的时间限制观测，克服了这一学习障碍。此外，本文建立了一个关于计算代理观测的正式框架，并展示了从策略轨迹中学习可计算函数可以归结为从输入和输出中学习有理函数，从而揭示了与有限状态转换推理之间的有趣联系。不过，本文也指出，即使在策略轨迹观测的情况下，线性时间可计算函数的可计算特征集或多项式质量特征集也不存在。", "innovation": "本文创新性地将计算观测和受限输入源引入Gold的归纳推理框架中，系统研究了在更现实约束条件下学习一般递归函数的问题。提出了时间限制观测和策略轨迹观测的概念，并通过施加计算复杂度约束或补充近似的时间限制观测来克服学习障碍。此外，本文建立了关于计算代理观测的正式框架，并揭示了有限状态转换推理与从策略轨迹中学习可计算函数之间的联系。", "conclusion": "尽管从策略轨迹中学习可计算函数并不适用于所有线性时间可计算函数类，但由于施加了计算复杂度约束或补充了近似的时间限制观测，本文解决了这一学习难题，并展示了从策略轨迹中学习可计算函数可以归结为从输入和输出中学习有理函数。此外，本文揭示了与有限状态转换推理之间的联系，并指出了线性时间可计算函数的可计算特征集或多项式质量特征集在策略轨迹观测情况下不存在的问题。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15549", "html_url": "https://arxiv.org/abs/2506.15549", "title": "CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation", "title_en": "CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation", "authors": "Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen(Cherise)Chen", "background": "基于深度学习的心肌疤痕分割技术从延迟钆增强（LGE）心脏MRI中取得了显著的成果，这在结构性心脏病的精确和及时诊断及治疗规划方面显现出巨大潜力。然而，高质量疤痕标签的LGE图像的稀缺性和差异性限制了稳健分割模型的发展。", "innovation": "本文介绍了一种名为CLAIM的框架，即：Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation。其核心是SMILE模块，指导基于扩散的生成器生成与临床采用的AHA 17-分区模型一致的、具有空间多样性的疤痕图像。CLAIM采用联合训练策略，同时优化疤痕分割网络和生成器，以增强合成疤痕的真实性和疤痕分割性能的准确性。实验结果显示，CLAIM生成了具备解剖一致性的心肌疤痕图案，并且其分割结果与实际疤痕分布的Dice相似度高于基线模型。通过这种方法，可以在下游医学成像任务中实现可控和真实的心肌疤痕合成，具有的实用价值。", "conclusion": "我们的方法使心肌疤痕的合成具有控制性和真实性，并展示了其在下游医学成像任务中的实际应用价值。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15554", "html_url": "https://arxiv.org/abs/2506.15554", "title": "DAILOC: 使用智能手机进行室内定位的领域增量学习", "title_en": "DAILOC: Domain-Incremental Learning for Indoor Localization using Smartphones", "authors": "Akhil Singampalli,Danish Gufran,Sudeep Pasricha", "background": "Wi-Fi指纹定位在实际部署中面临显著挑战，由于室内环境中的设备异质性和时间变化导致的数据域偏移。现有的方法通常独立处理这些问题，导致泛化能力差，随时间推移还容易出现灾难性遗忘。", "innovation": "提出了DAILOC，这是一种创新的领域增量学习框架，同时解决了时间因素和设备引起的域偏移问题。DAILOC引入了一种新的解耦策略，通过多级变分自编码器分离域偏移和与位置相关的关键特征。此外，引入了一种新的基于记忆的类别潜在对齐机制，以应对随时间推移的灾难性遗忘问题。", "conclusion": "DAILOC在多个智能手机、建筑物和时间实例上的实验表明，其显著优于现有最先进的方法，平均误差降低了2.74倍，最坏情况下的误差降低了4.6倍。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15559", "html_url": "https://arxiv.org/abs/2506.15559", "title": "基于逻辑门的可解释室内定位：使用逻辑门解释Wi-Fi指纹的学习", "title_en": "Towards Explainable Indoor Localization: Interpreting Neural Network Learning on Wi-Fi Fingerprints Using Logic Gates", "authors": "Danish Gufran,Sudeep Pasricha", "background": "基于深度学习的室内定位已经展示了在将Wi-Fi RSS指纹映射到物理位置时的强准确性，但大多数现有的深度学习框架作为黑盒模型运行，对预测如何做出或模型如何随时间响应真实世界噪声的信息有限。这种缺乏可解释性限制了我们理解由环境动态引起的时变影响的能力，并且阻碍了模型长期可靠性的适应能力。", "innovation": "为了应对这一挑战，我们提出了LogNet，一种基于逻辑门的新型框架，用于解释和增强基于深度学习的室内定位。LogNet通过识别每个参考点（RP）最具有影响力的接入点（AP），透明地提供推理，并揭示环境噪声如何干扰基于深度学习的定位决策。这种可解释性允许我们追踪并诊断模型故障，并适应DL系统以实现更加稳定的长期部署。通过在多个真实世界的楼面图和两年时间变化的评估中，LogNet不仅解释了DL模型的内部行为，而且提高了性能，使其定位误差减少了1.1倍到2.8倍，模型大小减少了3.4倍到43.3倍，延迟降低了1.5倍到3.6倍，相比于之前的DL基模型。", "conclusion": "我们的研究证明，LogNet不仅提高了基于DL的室内定位系统的性能，还通过增强其透明度和可解释性，使其更加稳定和可靠，为长期部署奠定了基础。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15591", "html_url": "https://arxiv.org/abs/2506.15591", "title": "一阶段扩散模型在细节丰富且时序一致的视频超分辨率中的应用", "title_en": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution", "authors": "Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang", "background": "在现实世界中的视频超分辨率（Real-VSR）任务中，同时保持丰富的空间细节和时间一致性是一个具有挑战性的问题，特别是在使用如稳定扩散（SD）之类的预训练生成模型进行现实细节合成时更为明显。现有的基于SD的实视频超分辨率方法通常会在空间细节和时间连贯性之间做出妥协，导致视觉质量不够理想。我们认为关键在于如何有效地从低质量输入视频中提取稳健的时间一致性先验，并在此基础上增强视频细节。现有的方法往往在空间细节和时间连续性之间妥协，导致视觉效果不佳。因此，提出一种双LoRA学习（DLoRAL）范式，通过训练一种有效的基于SD的一阶段扩散模型，以同时实现逼真的帧细节和时间一致性。", "innovation": "提出了一种双LoRA学习（DLoRAL）范式，引入了跨帧检索（CFR）模块和一致性LoRA（C-LoRA）来聚合跨帧的互补信息，从退化输入中学习稳健的时间表示。在一致性学习后，固定CFR和C-LoRA模块，训练细节LoRA（D-LoRA）以增强空间细节并保持与C-LoRA定义的时间空间进行对齐，以保持时间一致性。通过交替迭代优化两阶段模型，以提供一致且细节丰富的输出。在推断阶段，将两个LoRA分支合并到SD模型中，允许在单一步扩散步骤中高效地进行高质量视频恢复。实验表明DLoRAL在准确性和速度方面都表现出色。", "conclusion": "通过交替优化两阶段模型，DLoRAL在准确性和速度方面都实现了显著的提高，能够同时保持丰富的空间细节和时间一致性，从而提供高质量的视频超分辨率结果。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15594", "html_url": "https://arxiv.org/abs/2506.15594", "title": "WikiMixQA: 一个基于表格和图表的多模态问答基准", "title_en": "WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts", "authors": "Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret", "background": "文档是保存和传播信息的基础，常常包含复杂布局、表格和图表，这对于自动文档理解（DU）构成了巨大挑战。视觉-语言大模型（VLLMs）已在多种任务中展示了改善性能，但它们在处理长上下文视觉输入方面的有效性仍有待验证。", "innovation": "本论文提出了WikiMixQA，一个包含1000个多项选择题（MCQs）的基准，用于评估模型在表格和图表上的多模态推理能力。这些题目来源于4000个Wikipedia页面中的7个不同主题。不同于现有的基准，WikiMixQA更注重复杂推理，要求模型从多种模态中综合信息。此外，研究还评估了12种最先进的视觉-语言模型，揭示了这些模型在直接提供上下文时的表现，以及在从长文档中检索信息时性能的显著下降。唯一的例外是GPT-4-o模型，其在长文档推理情境中实现了超过50%的准确率，而开源模型的表现则较差，最高准确率仅达27%。这些发现突显了长上下文、多模态推理的挑战，并确立了WikiMixQA作为文档理解研究的关键基准地位。", "conclusion": "本研究通过揭示模型在多模态推理中的挑战，确立了WikiMixQA作为文档理解研究的重要基准，并验证了视觉-语言模型在长文档中的表现差异。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15598", "html_url": "https://arxiv.org/abs/2506.15598", "title": "从模型到课堂：基于叙事和难度考量评估生成的葡萄牙语选择题", "title_en": "From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns", "authors": "Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro", "background": "虽然选择题（MCQ）对于学习和评估具有重要价值，但人工创建具有不同难度层级和针对性阅读技能的MCQ仍然是一个耗时且成本高的任务。近年来，生成式AI的进步为高效自动化生成MCQ提供了可能，但对生成的MCQ实际质量与可靠性的评估却受到较少的关注，尤其是在生成失败的情况下更为重要。此外，大多数MCQ生成研究主要集中在英语上，而其他语言则相对未被充分探索。因此，本研究探讨了当前生成模型生成符合葡萄牙语（一个构词丰富语言）课程相关叙事元素，并具有不同难度层级的选择题的能力，通过专家评审和分析学生回应的测验心理统计属性来评估其适合作为小学学生的工具。", "innovation": "本研究创新性地关注了生成式模型在生成符合课程相关叙事元素、涵盖不同难度层级的葡萄牙语选择题方面的能力。更重要的是，通过对生成的MCQ进行专家评估和通过学生反馈分析测验的心理统计属性，评估这些选择题的适用性。这扩展了现有研究的视野，特别是在考虑生成失败情况下的质量评估方面，并探讨了当前模型在生成具有吸引力且符合高质量选择题设计标准的干扰项方面面临的挑战。", "conclusion": "研究表明，当前模型能够生成与人工撰写的同等质量的MCQ。然而，还存在语义清晰度和可回答性等方面的问题。另外，生成符合高标准选择题设计标准的干扰项仍然存在挑战。总体而言，当前生成模型在生成适用于小学水平学生的葡萄牙语阅读理解选择题方面具备潜力，但仍需进一步优化以提高其生成干扰项的质量和吸引力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15606", "html_url": "https://arxiv.org/abs/2506.15606", "title": "LoX: 低秩外推增强大型语言模型（LLM）的安全性以抵御微调攻击", "title_en": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "authors": "Gabrel J. Perin,Runjin Chen,Xuxi Chen,Nina S. T. Hirata,Zhangyang Wang,Junyuan Hong", "background": "大型语言模型（LLMs）在现实世界的应用中变得不可或缺。然而，它们的广泛应用也引发了一系列安全问题，尤其是在回应具有社会危害性的问题时。尽管已经做出了大量努力来通过模型对齐提高安全性，但对齐的模型仍然可能因为后续的微调而失去其安全性保护，即使附加的微调数据看似无害。现有的研究显示，这种漏洞主要源于大型语言模型参数中的安全关键低秩子空间对微调的高度敏感性。因此，如何有效地提高模型的安全性成了研究的一个重要课题。", "innovation": "本文提出了一种新的无需训练的方法，名为低秩外推（LoX），通过外推对齐的大型语言模型的安全子空间来增强其安全性。实验结果表明，这种方法显著提高了模型对良性或恶意微调攻击的鲁棒性，同时保持了其新任务适应能力。具体效果体现在可以将良性和恶意微调攻击的成功率分别降低11%到54%。这一方法通过参数的偏差角度分析提出，认为外推操作将模型参数移动到更加平坦的区域，使得模型参数对外部扰动的敏感性降低。", "conclusion": "实验结果验证了LoX的有效性，通过这种低秩外推的方法，大型语言模型在面对微调攻击时的鲁棒性得到了显著提高。同时，这种方法对于新任务的适应性也得到了保留。研究结果表明，LoX能够在不进行实际训练的情况下有效提升对齐的大型语言模型的安全性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15620", "html_url": "https://arxiv.org/abs/2506.15620", "title": "GFLC：基于图的公平性感知标签矫正以实现公平分类", "title_en": "GFLC: Graph-based Fairness-aware Label Correction for Fair Classification", "authors": "Modar Sulaiman,Kallol Roy", "background": "机器学习（ML）的公平性对于构建可信任的机器学习系统至关重要，特别是在人工智能（AI）系统日益影响社会的各种方面，如医疗决策和法律判决时。已有研究证实了ML存在不公平的结果，并强调了更稳健的公平性感知方法的必要性。然而，用于训练和开发去偏见技术的数据往往包含偏见和噪声标签，这会影响模型性能并误导公平性评估。因此，本研究旨在提出一种称为图基公平性感知标签矫正（GFLC）的有效方法，该方法在保持数据集的 demographics 平等的同时矫正标签噪声，增强模型的公平性。", "innovation": "GFLC方法结合了预测置信度度量、通过Ricci流优化的图拉普拉斯图形基正则化以及显式的demographic平等激励，以实现标签噪声的矫正同时保持公平性。这种方法的有效性通过实验得到了证明，结果表明GFLC方法在性能和公平性指标之间取得了显著改善，相较于基准方法有了显著提升。", "conclusion": "本研究提出了一种新的方法GFLC，该方法通过结合预测置信度度量、图拉普拉斯图形基正则化以及显式的demographic平等激励，在保持提高了模型公平性的前提下矫正了标签噪声。实验结果表明，GFLC方法在性能和公平性指标之间取得了显著的改善，相比基准方法有所提升，为构建更公平的机器学习系统提供了有效的解决方案。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15626", "html_url": "https://arxiv.org/abs/2506.15626", "title": "基于MRI的联邦学习BrainAGE：针对卒后功能结局预测的多中心研究", "title_en": "Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction", "authors": "Vincent Roca,Marc Tommasi,Paul Andrey,Aurélien Bellet,Markus D. Schirmer,Hilde Henon,Laurent Puy,Julien Ramon,Grégory Kuchcinski,Martin Bretzner,Renaud Lopes", "background": "脑预测年龄差异（BrainAGE）是一种反映大脑健康的影像学生物学标志物。然而，为了训练稳健的BrainAGE模型，通常需要庞大的数据集，而这些数据集往往受限于隐私保护的严格规定。因此，亟待一种替代的数据管理策略，以减少数据集的规模并保持模型的鲁棒性。联邦学习（FL）被用于解决这一问题，它允许在保护数据隐私的同时进行分布式训练。本研究旨在评估联邦学习在卒中患者（接受机械取栓治疗）中的应用效果，特别是对于脑健康指标（BrainAGE）的估计及其与临床表型和功能结局的关联。", "innovation": "引入了联邦学习（FL）策略，用于在多中心环境下对卒中患者进行无集中化处理的脑预测年龄（BrainAGE）估计。通过比较集中学习、联邦学习和单中心学习三种数据管理策略下的预测效果，验证联邦学习的优势。研究所使用的大规模MRI数据来源于16家医院中心的1674名卒中患者，通过标准机器学习和深度学习模型评估了不同策略下的预测准确性。研究表明，尽管集中学习能提供最准确的预测，但联邦学习在性能上持续超越单一中心模型，表明了联邦学习的有效性和实用性。此外，还探讨了BrainAGE与关键临床变量和功能恢复结局之间的关联，强调了这种新型预测指标在卒中管理中的潜在价值和应用前景。", "conclusion": "联邦学习能够确保在不集中化数据的情况下实现准确的年龄预测，这对于保护患者隐私提供了可能。研究发现，脑预测年龄指标（BrainAGE）与血管风险因素以及卒中后功能恢复具有显著关联，这表明它具有潜在的预后模型价值，在卒中护理中具有广泛的应用前景。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15629", "html_url": "https://arxiv.org/abs/2506.15629", "title": "重新审视大型语言模型的组成泛化能力，考虑指令遵循能力", "title_en": "Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability", "authors": "Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe", "background": "在生成常识推理任务（如CommonGen）中，生成型大型语言模型（LLMs）能够组合包含所有给定概念的句子。然而，在关注指令遵循能力时，如果提示指定了概念的顺序，LLMs必须生成符合指定顺序的句子。现有方法未能同时评估这两种能力。为此，本文通过Ordered CommonGen这一基准，旨在评估LLMs在组成泛化和指令遵循方面的表现，并进一步分析了36种LLMs的结果，揭示了LLMs在遵循指定顺序生成句子方面的挑战和局限性。", "innovation": "本文提出了Ordered CommonGen基准，以综合评估LLMs在指令遵循和组成泛化能力。这项工作填补了现有研究中的空白，通过具体的设计标准提升了对LLMs在这些方面能力的理解和评估方法。研究发现，尽管LLMs通常可以理解指令意图，但它们在生成符合特定顺序的概念方面表现出低多样性或一致性的问题。尽管一些LLMs的指令遵循性很高，但整体上仍然只达到了约75%的有序覆盖率，显示出改进的必要性。这项工作为未来研究提供了新的视角和方向。", "conclusion": "尽管LLMs通常能够理解指令背后的意思，但在处理特定顺序时表现出的偏差往往导致生成的输出缺乏多样性或重复。最佳的LLMs也只能在排序覆盖上达到约75%，这表明这两个方面（指令遵循和组成泛化）都需要进一步的改进。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15645", "html_url": "https://arxiv.org/abs/2506.15645", "title": "揭示多模态大语言模型中的视觉质量悖论", "title_en": "Demystifying the Visual Quality Paradox in Multimodal Large Language Models", "authors": "Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu", "background": "近年来，多模态大型语言模型（MLLMs）在视觉语言任务基准测试中表现出色，但鲜少有人研究输入视觉质量如何影响模型的响应。现有研究并未明确回答，更高的感知质量是否确实意味着更好的MLLM理解能力。为填补这一空白，该研究通过系统地应用图像的控制降级和风格转变，考察了领先MLLMs和一系列视觉语言基准测试中的表现差异，揭示了视觉质量悖论：当图像偏离人类感知的真实度时，模型、任务乃至单个实例的表现反而提升。现有图像去噪管道未能解释这种特殊偏好，因此该研究提出了一种新的方法——视觉质量测试时调校（VQ-TTT），以适应不同模型对输入图像的特定偏好。", "innovation": "该研究首次系统地分析了输入视觉质量对大型语言模型的影响，发现了视觉质量悖论。研究提出了一种轻量级的适应模块——VQ-TTT，该模块在不采用外部模型、不使用缓存特征或额外训练数据的情况下，通过在冻结的视觉编码器前插入可学习的低阶核来调整频率内容，并仅对视觉编码器的深层进行微调。VQ-TTT能够在单个向前传递中动态地调整每个输入图像，使其与任务特定的模型偏好相匹配。研究结果表明，对于评估的MLLMs和所有数据集，VQ-TTT显著提升了通用准确性。", "conclusion": "这些发现重新定义了对MLLMs来说“更好的”视觉输入，并强调了未来多模态模型需要适应性而非普遍“清洁”的图像的意义。在新的AI时代，数据成为主要消费者，这一研究为设计更有效的多模态模型提供了新的视角。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15651", "html_url": "https://arxiv.org/abs/2506.15651", "title": "AutoRule：从推理链中提取规则基奖励改善偏好学习", "title_en": "AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning", "authors": "Tevin Wang,Chenyan Xiong", "background": "基于规则的奖励为通过人类反馈改进强化学习（RLHF）提供了有希望的策略，但当前的方法经常依赖于人工规则工程。", "innovation": "AutoRule是一种完全自动化的从偏好反馈中提取规则并将其形成规则基奖励的方法。它分为三个阶段：利用推理模型解读用户偏好、从这些解释的推理链中识别候选规则、并合成为一个统一的规则集。这种规则集与语言模型验证器一起使用，用于衡量每个输出满足规则的比例，这被用作辅助奖励，与学习奖励模型一起用于策略优化。这种方法在多项指标上优于基线模型，证明了提取规则与数据集偏好的良好一致性，并展示了降低奖励应对策略的效果。提取的规则在附录中提供，代码开源。", "conclusion": "我们的分析显示，通过AutoRule提取的规则与数据集偏好良好匹配，且与仅使用学习奖励模型的基线相比，AutoRule在AlpacaEval2.0的长度控制胜率上实现了28.6%的相对改进，在MT-Bench的保留子集第二轮表现上实现了6.1%的相对改进。最终，案例研究表明，提取的规则揭示了不同数据集中独特的价值特征。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15674", "html_url": "https://arxiv.org/abs/2506.15674", "title": "露怯的思想：大型推理模型并非私密的思想家", "title_en": "Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers", "authors": "Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh", "background": "该研究探讨了在大规模推理模型中用于充当个人代理的角色中，推理路径中的隐私泄露问题。不同于最终结果，推理轨迹通常被认为主要是内部且安全的。然而，研究者通过实验证明，推理轨迹中经常包含用户的敏感数据，并且这些数据可通过提示注入或意外地出现在输出结果中被提取。测试时推理策略，尤其是增加推理步骤，会放大这种泄露。增加这些测试推理方法的预算，可以使得模型在最终答案上更加谨慎，但同时也使模型在推理过程中表现得更加详细，从而增加了其内部思想中的隐私泄露风险。这揭示了一个核心矛盾：推理提高了实用性，但同时也扩大了隐私攻击的范围。", "innovation": "研究者通过实验证明了推理路径中存在着隐私泄露的风险，特别是通过使用提示注入或意外泄漏到输出中；并且发现通过增加计算预算，虽然在最终答案上更谨慎，但也会导致其在推理过程中更详细，从而增加了其内部思想中的隐私泄露风险。", "conclusion": "研究指出，安全工作的范围需要扩展到模型的内部思考，而不仅仅是其输出结果。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15675", "html_url": "https://arxiv.org/abs/2506.15675", "title": "Sekai: 一个面向世界探索的视频数据集", "title_en": "Sekai: A Video Dataset towards World Exploration", "authors": "Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang", "background": "视频生成技术取得了显著进展，有望成为探索虚拟世界的基石。然而，现有的视频生成数据集存在一些不足，包括有限的地点、短暂的持续时间、静态场景以及缺乏关于探索和世界的注释。", "innovation": "本文介绍了一款名为Sekai的高质量第一人称全球视频数据集，带有丰富的探索注释。该数据集包含来自100多个国家和地区超过750个城市超过5000小时的行走或无人机视点（FPV和UVA）视频。开发了一个高效并有效的工具箱来收集、预处理和带有位置、场景、天气、人群密度、字幕和相机轨迹的注释的视频。实验展示了数据集的质量。", "conclusion": "使用部分数据集训练了一个名为YUME的互动视频世界探索模型。我们相信Sekai将有助于视频生成和世界探索领域，并激发有价值的应用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15679", "html_url": "https://arxiv.org/abs/2506.15679", "title": "密集型SAE潜在特征并非缺陷", "title_en": "Dense SAE Latents Are Features, Not Bugs", "authors": "Xiaoqing Sun,Alessandro Stolfo,Joshua Engels,Ben Wu,Senthooran Rajamanoharan,Mrinmaya Sachan,Max Tegmark", "background": "稀疏自编码器（SAEs）旨在通过施加稀疏约束从语言模型中提取可解释的特征。理想情况下，训练SAE会生成既稀疏又具有语义意义的潜在特征。然而，许多SAE的潜在特征经常被激活（即，是密集的），这引发了它们可能是训练过程不可取的副产品的问题。本文系统地调查了密集潜在特征的几何、功能及其起源，发现它们不仅是持久的，而且还反映了许多有意义的模型表示。通过研究较为详细的潜在特征的性质及层次结构变化，发现密集潜在特征可以在残差流中重建特定方向，并且删除它们的子空间会抑制新密集特征在重新训练后的出现。这表明高密度特征是残差空间的固有属性。此外，研究了这些密集潜在特征的各种类别，包括位置跟踪、上下文绑定、熵调节、字母特定输出信号、词性以及主成分重建等类别。在模型的不同层次中，发现结构特征在早期层，语义特征在中间层，而最后层则主要显示输出导向的信号。", "innovation": "本文通过系统研究，揭示了密集型SAE潜在特征不仅仅是训练过程中的噪音，而是具有功能性的特征。提出了一种密集潜在特征的分类体系，并发现这些密集特征在残差空间中具有特定的功能作用，表明它们是残差空间的固有属性，从而挑战了以往对这些特征简单归因于噪声的观点。此外，对密集特征在模型不同层数中的演化行为进行了详细的分析，揭示了从结构特征到语义特征再到输出导向信号的变化过程，为理解语言模型中的潜在特征提供了新视角。", "conclusion": "研究结果表明，密集型SAE潜在特征不仅在语言模型计算中发挥重要的功能作用，不应被视为训练噪音，而且其性质和作用随着模型层次的变化而演变。所提出的密集潜在特征分类体系和对其在残差空间中的作用的理解为未来研究提供了有价值的见解。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2308.05201", "html_url": "https://arxiv.org/abs/2308.05201", "title": "基于AI的未来工作：在线劳动力市场的实证证据", "title_en": "\"Generate\" the Future of Work through AI: Empirical Evidence from Online Labor Markets", "authors": "Jin Liu(1),Xingchen Xu(2),Xi Nan(2),Yongjun Li(1),Yong Tan(2) ((1) University of Science and Technology of China, (2) University of Washington)", "background": "大型语言模型（LLM）基于的生成型AI系统，例如ChatGPT，展示了在广泛下游任务上的零样本学习能力。由于这些系统具有通用性，能够在不同场景下增强或自动化工作职能，因此有望重塑劳动力市场的动态。然而，由于AI同时影响需求和供给，并且市场参与者会产生战略性响应，因此预测其具体影响具有挑战性。利用领先在线劳动力平台的数据集，论文揭示了这种系统在需求和供给都下降的情况下，供给下降幅度较小，导致自由职业者之间的竞争加剧。特别是在编程密集型细分市场中，这一现象更为明显。这一模式归因于技能过渡效应：ChatGPT降低了编程领域的人力资本门槛，使得求职者能够进入编程任务。此外，这些转变并非均匀分布，高技能自由职业者对此转变的贡献更大。这些结果揭示了通用型AI对劳动力市场多方面的影响，不仅包括特定职业的替代，还包括劳动力供给中的技能转换。这些见解对政策制定者、平台运营者和劳动者具有实际意义。", "innovation": "论文利用了大规模在线劳动力市场的数据集，通过实证分析展示了通用型AI对劳动力市场影响的具体表现，特别是在编程密集型市场中的技能过渡效应。研究发现，尽管需求和供给都减少，但供给减少的幅度较小，导致自由职业者之间的竞争加剧。这种研究方法和发现提供了对通用型AI影响的新见解。", "conclusion": "研究结果表明，通用型AI不仅替代了某些职业，还促进了劳动力供给中的技能转换。这对于政策制定者、平台运营商和劳动者具有重要影响。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.11585", "html_url": "https://arxiv.org/abs/2404.11585", "title": "基于空间上下文的自我监督学习在手写文本识别中的应用", "title_en": "Spatial Context-based Self-Supervised Learning for Handwritten Text Recognition", "authors": "Carlos Penarrubia,Carlos Garrido-Munoz,Jose J. Valero-Mas,Jorge Calvo-Zaragoza", "background": "手写文本识别（HTR）是计算机视觉中的一个重要问题，但由于其固有的变异性以及复杂的上下文解释需求，在计算机视觉领域取得的成功应用还相对有限，特别是自我监督学习（SSL）方法的应用尚未得到充分探索。", "innovation": "本文专注于其中一种基于空间上下文的自我监督学习方法，并探讨如何将其适应和优化以应用于HTR。提出了一种新的工作流程，利用手写文本的独特特性，实验结果表明在此类基准案例中这些方法能够推动SSL技术在HTR中的进步.", "conclusion": "研究成果展示了基于空间上下文的自我监督学习方法在多个基准案例中推动了HTR中的SSL技术的发展。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.04300", "html_url": "https://arxiv.org/abs/2405.04300", "title": "行为规划：一种用于多样化规划的工具包", "title_en": "Behaviour Planning: A Toolkit for Diverse Planning", "authors": "Mustafa F Abdelwahed,Joan Espasa,Alice Toniolo,Ian P. Gent", "background": "在实际应用中，如风险管理、实时数据分析和恶意软件检测等领域，多种规划方法被采用。当前的多样化规划公式将多样性模型编码为距离函数，这在比较两个计划时计算成本较低。但这种建模方法限制了可以编码为多样性的测量以及解释两个计划为何不同的能力。", "innovation": "本文介绍了用于多样化规划问题的新颖方法，允许通过多维网格表示法更灵活地建模多样性，其中每个维度对应用户定义的特征。此外，本文还提出了相应的工具包——行为规划，可以根据这样的自定义多样性模型生成多样化计划。本文通过规划及满足性问题的实现，提供了行为规划工具包的实现。结果表明，基于自定义多样性模型生成多样化计划方面，本文的方法显著优于当前的多样化规划方法。本文的方法是首个支持超越经典规划领域的多样化规划方法，如过订规划和数值规划的实现方法", "conclusion": "本实现方法在生成基于新自定义多样性的计划方面显著优于当前的多样化规划方法。与现有方法相比，它还支持涵盖经典规划之外的规划类别，如过订规划和数值规划。同时，行为规划工具包为多样化规划问题提供了解决方案。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.20302", "html_url": "https://arxiv.org/abs/2409.20302", "title": "OM4OV：利用本体匹配进行本体版本控制", "title_en": "OM4OV: Leveraging Ontology Matching for Ontology Versioning", "authors": "Zhangcheng Qiang,Kerry Taylor,Weiqing Wang", "background": "由于语义网的动态特性，版本控制对于捕捉时间变化的信息，尤其是广泛使用的本体是必要的。尽管本体版本控制（OV）作为高效本体管理的重要组成部分已经被广泛认识，但不断增加的本体规模和由手工劳动导致的累积错误正在使当前的版本控制方法变得过时。因此，本研究提出了一种新的方法，利用现有的本体匹配（OM）技术和系统来执行版本控制。通过重建OM视角下的新任务表述和度量，提出了一种集成的OM4OV流程，并提出了增强整体版本控制性能的跨参考机制（CR）。", "innovation": "提出了一种新的本体版本控制（OV）方法，通过现有的本体匹配（OM）技术和系统架构了一个统一的OM4OV流程，并引入了跨参考（CR）机制来增强总体版本控制性能。该研究还通过实验验证了OM4OV流程和跨参考机制的有效性，并讨论了本体匹配在版本控制任务中的一些洞见，即部分由版本控制系统检测的假映射并不总是不准确的。", "conclusion": "通过实验验证了OM4OV流程和跨参考机制的有效性，并提出了一种新的版本控制方法来增强整体版本控制性能。此外，讨论了本体匹配在版本控制任务中的应用和相关见解。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.13061", "html_url": "https://arxiv.org/abs/2410.13061", "title": "概率电路的最优传输", "title_en": "Optimal Transport for Probabilistic Circuits", "authors": "Adrian Ciotinga,YooJung Choi", "background": "已有研究展示了某些类别的随机电路（PCs）之间的散度可以高效计算，但到目前为止，还没有方法来计算由PCs表示的概率分布之间的Wasserstein距离。论文引入了一个新的框架，利用概率电路计算Wasserstein距离，并提出了一个与随机电路耦合措施相关的Wasserstein型距离。通过求解一系列小的线性规划问题，该框架能够高效地计算这种距离，并推导了可以实现该计算的电路条件。最后，论文还研究了随机电路与数据集之间的经验Wasserstein距离，并通过有效迭代算法估计了可以最小化该距离的PC参数.", "innovation": "首次提出了利用概率电路计算Wasserstein距离的新框架，开发了一种算法通过求解一系列小线性规划问题来计算这种距离，并推导了可以实现该计算的电路条件。此外，该方法可以通过有效迭代算法获取随机电路之间的最优传输计划，从而估计PC参数以最小化经验Wasserstein距离.", "conclusion": "研究发现可以通过优化随机电路来最小化随机电路与数据集之间的经验Wasserstein距离，这为从数据中高效学习概率电路提供了一种新方法。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04686", "html_url": "https://arxiv.org/abs/2502.04686", "title": "使用迭代隐空间策略优化在狼人游戏中学习战略语言代理", "title_en": "Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization", "authors": "Zelai Xu,Wanjun Gu,Chao Yu,Yi Wu,Yu Wang", "background": "大型语言模型（LLM）代理在开放式对话和多步骤决策等领域已经展示出了出色的性能，但在解决需要战略决策和自由形式语言交互的策略语言博弈，如狼人游戏时，仍然面临挑战。现有的LLM代理通常在行动分布中存在固有的偏差，并且难以探索无限的文本行动空间，导致性能不佳。", "innovation": "提出了一种结合博弈论方法与LLM微调的迭代框架——隐空间策略优化（LSPO）。该框架首先将自由形式的口头表达映射到有限的潜策略空间，形成一个抽象的扩展形式博弈，然后应用博弈论方法（如反事实后悔最小化CFR）优化潜策略空间中的策略，最后通过直接偏好优化（DPO）微调LLM使其与学习到的策略相匹配。这种方法通过迭代交替执行这些步骤，逐步增强代理的战略推理能力和语言交流能力。实验结果显示，该代理在狼人游戏中表现出更强的战略扩展空间和性能，在自由形式的语言博弈中优于现有代理，证明了其有效性。", "conclusion": "LSPO代理通过迭代优化方法，逐步提高战略推理和语言交流的能力，在狼人游戏中取得了优于现有代理的性能，特别是在涉及战略互动的自由形式语言博弈中显示出了有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15849", "html_url": "https://arxiv.org/abs/2502.15849", "title": "从符号乐库合成复合层次结构", "title_en": "Synthesizing Composite Hierarchical Structure from Symbolic Music Corpora", "authors": "Ilana Shapiro,Ruanqianqian Huang,Zachary Novack,Cheng-i Wang,Hao-Wen Dong,Taylor Berg-Kirkpatrick,Shlomo Dubnov,Sorin Lerner", "background": "音乐本质上是一个层次化的系统，从细微的旋律到高层次的形式。为了全面、多层次地分析音乐作品，提出了一个统一的、层次化的元表示，称为结构时间图（STG）。STG将单一作品表示为一种数据结构，定义了一种逐渐细化的结构音乐特征及其之间的时间关系层级结构。", "innovation": "提出了结构时间图（STG），并通过图同构为基础的结构距离顶峰值优化问题定义了一种新颖的方法，结合模拟退火算法和SMT求解器，生成整个STG音乐库的结构稳健的代表中心STG。", "conclusion": "实验验证结果显示，结构距离能够准确区分音乐作品，并且从中提取的中心STG能够准确地结构化地描述其音乐库。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01009", "html_url": "https://arxiv.org/abs/2503.01009", "title": "使用概率电路精确求解计数逻辑满足性", "title_en": "Solving Satisfiability Modulo Counting Exactly with Probabilistic Circuits", "authors": "Jinzhao Li,Nan Jiang,Yexiang Xue", "background": "计数逻辑满足性问题（SMC）是一种最近提出的一般语言，用于处理统计和象征人工智能相结合的问题。SMC问题是一个扩展的SAT问题，在该问题中，部分布尔变量的真值通过概率推理确定。现有的近似求解器可能会返回违反约束的解；直接将可用的SAT求解器和概率推理求解器集成可以得到精确解，但因两者频繁调用而导致性能缓慢。因此需要一个高效的、集成的SMC精确求解器。", "innovation": "本文提出了KOCO-SMC，这是一种高效的、集成的SMC精确求解器。KOCO-SMC通过在概率推理过程中跟踪部分变量赋值时的下界和上界，实现了早期估计概率推理的过程，无需进行完整的变量赋值。在实验中，KOCO-SMC在大规模数据集和实际应用中与当前可用的近似和精确SMC求解器进行比较，显示出显著的性能提升，能够以更少的时间找到精确解。", "conclusion": "KOCO-SMC能够以更高的效率求解SMC问题，尤其是在概率推理早期利用部分变量赋值估计的方法显著提升了计算效率。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15848", "html_url": "https://arxiv.org/abs/2503.15848", "title": "基于熵的多步推理探索导引", "title_en": "Entropy-based Exploration Conduction for Multi-step Reasoning", "authors": "Jinghan Zhang,Xiting Wang,Fengran Mo,Yeyang Zhou,Wanfu Gao,Kunpeng Liu", "background": "多步过程通过大型语言模型（LLMs）已经被证明能有效解决复杂的推理任务。然而，探索推理过程的深度显著地影响任务性能。现有的自动决定探索深度的方法往往成本高昂且缺乏灵活性。为了应对这些挑战，我们提出了基于熵的探索深度导引（Entro-duction），这是一种新颖的方法，在多步推理过程中动态调整探索深度，通过监测LLM的输出熵和方差熵来实现。这种方法利用两种特征捕捉当前推理步骤的不确定性及其不确定性随连续推理步骤的变化。", "innovation": "提出了基于熵的探索深度导引（Entro-duction），这是一种新颖的方法，在多步推理过程中动态调整探索深度。通过监测LLM的输出熵和方差熵来动态调整探索的深度，捕捉模型的当前不确定性及不确定性随连续推理步骤的变化。这有助于平衡推理准确性与探索效果之间的权衡。", "conclusion": "我们在四个基准数据集上的实验结果表明，Entro-duction方法有效。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10912", "html_url": "https://arxiv.org/abs/2506.10912", "title": "结构层面分子解毒：MLLMs准备好了吗？", "title_en": "Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?", "authors": "Fei Lin,Ziyang Gong,Cong Wang,Yonglin Tian,Tengchao Zhang,Xue Yang,Gen Luo,Fei-Yue Wang", "background": "毒性和早期药物开发阶段失败有密切关系。尽管分子设计和性质预测取得了进展，分子毒性修复的任务——生成具有结构有效性且毒性降低的分子替代物——仍未被系统地定义和测评。为填补这一空白，作者引入了ToxiMol，这是首个专注于分子毒性修复的基准任务，旨在为通用型多模态大型语言模型提供参考标准。ToxiMol包括11项基础任务和涵盖多样机制和粒度的560种代表性有毒分子的数据集。这些工作基于专业知识，设计了一种意识机制和适应任务的提示注释流水线，并提出了一套自动化评估框架ToxiEval，整合了毒性终点预测、合成可及性、药物可类比性和结构相似性指标，形成高通量评估链，以评估分子修复成功率。", "innovation": "作者提出了ToxiMol，这是首个针对分子毒性修复任务的基准数据集和评估框架ToxiEval。这些工具基于详细的毒性机制和药物设计专业知识进行设计，以评估多模态大型语言模型在结构有效性分子修复方面的潜力。一种机械化和任务适应性的提示注释流水线被设计出来，它能够利用专家有毒学知识。同时，提出了一套多因素分析的消融研究，以探究评价标准、候选多样性及失败归因关键因素。", "conclusion": "尽管现有的多模态大型语言模型在该任务上仍面临重大挑战，但它们已初步表现出毒性理解、语义约束和结构感知分子编辑方面的潜力。需要进一步研究和开发来更好地理解和提升这些模型的性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13584", "html_url": "https://arxiv.org/abs/2506.13584", "title": "从数据驱动到目标驱动的人工智能：数据分析驱动的患者护理自动化中的系统思考", "title_en": "From Data-Driven to Purpose-Driven Artificial Intelligence: Systems Thinking for Data-Analytic Automation of Patient Care", "authors": "Daniel Anadria,Roel Dobbe,Anastasia Giachanou,Ruurd Kuiper,Richard Bartels,Wouter van Amsterdam,Íñigo Martínez de Rituerto de Troya,Carmen Zürcher,Daniel Oberski", "background": "本文反思了AI驱动的患者护理自动化中日益流行的数据驱动建模范式。文章指出，重新利用现有的真实世界患者数据集进行机器学习可能不是模型开发的最优化方法，因为这可能会导致患者护理中的负面结果。回顾了数据统计的历史，解释了为何数据驱动范式得到了流行，并强调了临床领域理论和系统思维在现有模型开发方法中的补充作用，以达到以人为本的结果。文章呼吁一种基于临床理论和现实社会技术背景的目标驱动的人工智能范式。理解现有患者数据集的实用性需要从数据生成上下游两个方向进行。这种目标驱动的视角为人工智能系统开发提供了新的方法论机会，并对患者护理的自动化充满希望。", "innovation": "提出了目标驱动的人工智能范式，强调临床理论和现实社会技术背景的重要性。理解存在于现有患者数据集的实用性需要从数据生成和自动化目标两方面进行考虑。该视角为人工智能系统开发提供了新的方法论机会，并对患者护理的自动化充满希望。", "conclusion": "为了实现以人为本的AI自动化患者护理结果，论文倡导一种基于临床理论和实际社会技术背景的目标驱动的人工智能范式。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13790", "html_url": "https://arxiv.org/abs/2506.13790", "title": "NordDRG AI基准模型测试", "title_en": "The NordDRG AI Benchmark for Large Language Models", "authors": "Tapio Pitkäranta", "background": "目前，生成式大型语言模型（LLMs）已经在临床编码和决策支持方面进行了试点，但尚无公开基准测试关注诊断相关组（DRG）这一医院资助层面，DRG在很多国家决定了报销标准。此研究发布了NordDRG-AI-Benchmark，这是首个囊括完整DRG规则集并评估LLM在跨语言诊断、操作和费用逻辑推理能力的公开测试框架。基准测试的构建包括定义表、专家手册和变更日志模板以及14个病例组合任务。这些任务涵盖了代码查询、多表推理、多语言术语和质量保障审计等内容。", "innovation": "NordDRG-AI-Benchmark是首个专门针对DRG层面的公开基准测试框架，它首次集成了完整的DRG规则集，并通过案例组合任务评估LLM在跨语言诊断、操作和费用逻辑推理能力，强调了领域特定的优势和不足，不同于通用的LLM基准测试，为医院资助领域的自动化信任研究提供了可重复的基础线。", "conclusion": " Baseline结果显示，五种最先进的LLM在九项自动验证任务上的表现相差很大：o3获得9/9的分数，而GPT-4及其mini高版本获得7/9的分数，Gemini 2.5 Pro和Gemini 2.5 Flash分别仅解决了3/9和5/9的任务。这些结果证实了NordDRG-AI-Benchmark能够揭示领域特定的优势和不足，这在通用LLM基准测试中是隐藏的，提供了一个可复制的基础线以评估在医院资助方面的可信自动化研究效果。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2205.02225", "html_url": "https://arxiv.org/abs/2205.02225", "title": "HiURE：无监督关系提取的层级示例对比学习", "title_en": "HiURE: Hierarchical Exemplar Contrastive Learning for Unsupervised Relation Extraction", "authors": "Shuliang Liu,Xuming Hu,Chenwei Zhang,Shu`ang Li,Lijie Wen,Philip S. Yu", "background": "无监督关系提取的目标是从自然语言句子中提取实体之间的关系，而无需关于关系范围或分布的先验信息。现有的方法要么利用自我监督方案通过迭代利用自适应聚类和分类逐步引发漂移问题来细化关系特征信号，要么采用基于实例的对比学习，不合理地将语义相似的句子对分离开来。", "innovation": "提出了一种新颖的对比学习框架HiURE，该框架具有从关系特征空间中提取层级信号的能力，并通过样例级对比学习有效优化句子的关系表示，解决了现有方法中的缺陷。", "conclusion": "HiURE在两个公开数据集上的实验结果表明，与现有最先进的模型相比，它在无监督关系提取方面的有效性和鲁棒性更明显。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.13534", "html_url": "https://arxiv.org/abs/2402.13534", "title": "一种针对序列标注的高效异构知识 Curriculum 学习方法", "title_en": "An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling", "authors": "Xuemei Tang,Jun Wang,Qi Su,Chu-ren Huang,Jinghang Gu", "background": "序列标注模型通常可以从外部知识中受益，但这种做法引入了数据异质性，增加了额外模块的复杂性，增加了培训高性能模型的成本。现有的策略无法有效解决这些挑战，因此需要一种新的框架来改进这方面的性能和加速训练过程。", "innovation": "提出了一种针对序列标注任务的两阶段 Curriculum 学习（TCL）框架。该框架通过逐步引入从易到难的数据实例来增强训练，旨在提高模型性能和训练速度，并探索了评估序列标注任务难度的不同指标。", "conclusion": "通过在六个中文词性标注和部分标注数据集上进行广泛的实验，证明TCL框架可以有效提高序列标注模型的性能，同时加速训练过程，并缓解复杂模型的慢速训练问题。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.10989", "html_url": "https://arxiv.org/abs/2406.10989", "title": "通过代码度量分析预测计算笔记本的理解性", "title_en": "Predicting the Understandability of Computational Notebooks through Code Metrics Analysis", "authors": "Mojtaba Mostafavi Ghahfarokhi,Alireza Asadi,Arash Asgari,Bardia Mohammadi,Abbas Heydarnoori,Masih Beigi Rizi", "background": "计算笔记本是数据科学家的主要编码工具，但这些工具中的代码质量尚未得到充分研究，通常也较差。代码的可维护性和可重用性很重要，因此提高代码可理解性是必要的。传统评估可理解性的方法通常依赖于有限的问题问卷或喜欢和投票的元数据，这些可能不能反映实际代码的清晰度。已有研究缺乏有效的评估方式，本文提出了一种新的方法，利用软件仓库中的用户意见来评估Jupyter笔记本的理解性，通过一个案例研究使用了54.2万份Kaggle Jupyter笔记本数据集，引入了一个新的评价指标，即用户意见代码理解性（UOCU），并结合总点赞数提高了预测准确性。", "innovation": "本文提出了利用软件仓库中用户意见来评估Jupyter笔记本理解性的新方法，并引入了用户意见代码理解性（UOCU）这一新指标。通过结合UOCU和总点赞数的混合方法，提高了评估的准确性。使用这一改进后的指标，从132,723份最终的笔记本中收集了34个笔记级别指标，并训练机器学习模型来预测理解性。最佳模型，随机森林分类器，实现了89%的理解水平分类准确性。", "conclusion": "本文的工作证明了用户意见信号和笔记本指标在构建可扩展且准确的代码理解度量方面的重要性。通过代码度量分析预测计算笔记本的理解性是一个可行的方法。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.15621", "html_url": "https://arxiv.org/abs/2407.15621", "title": "RadioRAG：放射学检索增强生成以回答问题", "title_en": "RadioRAG: Online Retrieval-augmented Generation for Radiology Question Answering", "authors": "Soroosh Tayebi Arasteh,Mahshad Lotfinia,Keno Bressem,Robert Siepmann,Lisa Adams,Dyke Ferber,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn", "background": "大型语言模型（LLMs）通常基于静态训练数据生成过时或不准确的信息。检索增强生成（RAG）通过整合外部数据源来缓解这一问题。尽管之前的RAG系统使用了预先组装的固定数据库，灵活性有限，本研究开发了Radiology RAG（RadioRAG），这是一种端到端框架，实现实时从权威性放射学在线资源中检索数据。通过评估不同LLM在有无RAG辅助下对放射学专业问题的诊断准确性，研究探讨了RAG对LLM性能的提升及其在不同放射学专科的适用性。", "innovation": "开发了RadioRAG，这是一种实时从放射学权威源检索数据的端到端框架，提升了多种LLM在放射学专业问题上的诊断准确性，甚至在某些情况下与人类放射科医生的性能相当。这项研究展示了RAG机制在提高涉及特定领域数据的LLM准确性和可靠性方面的潜力，特别是在乳腺成像和急危重症放射学领域取得显著效果。同时，研究也展示了不同LLM对RAG技术的响应存在差异，突显了RAG技术在纵向应用中的灵活性和适应性。", "conclusion": "提供特定领域数据可显著提升LLMs的性能。RadioRAG通过集成实时的放射学特定数据，提高了LA转M中较多种类LLM的诊断准确性，并在某些情况下匹配甚至超越了人类放射科医生。然而，不同模型对RAG技术的响应存在差异，突显了RAG在实际应用中的多样效应。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.21243", "html_url": "https://arxiv.org/abs/2407.21243", "title": "离散扩散模型中的知情纠正器", "title_en": "Informed Correctors for Discrete Diffusion Models", "authors": "Yixiu Zhao,Jiaxin Shi,Feng Chen,Shaul Druckmann,Lester Mackey,Scott Linderman", "background": "离散扩散已成为离散域生成建模的强大框架，但高效地从这些模型中采样仍然具有挑战性。现有的采样策略在减少采样步骤时往往难以平衡计算和样本质量，即使模型已很好地学习了数据分布也无济于事。已有文献指出，当采样步骤减少时，现有的采样技术常常难以同时确保计算效率和样本质量。因此，计算效率与样本质量之间的权衡成为亟待解决的问题。这些问题限制了离散扩散模型的实际应用潜力。为了应对这些限制，本文提出了一种预测-纠正采样方案，其中正确器由扩散模型指导，以更可靠地对抗累积的近似误差。此外，通过引入基于空心变换器的互补架构修改和一个简单的自适应训练目标，进一步增强了知情正确器的有效性。在此基础上，本文通过合成示例阐释了现有采样器的失效模式，并演示了知情正确器如何缓解这些问题。实验结果表明，对于离散扩散模型，在较少的错误或更高的 FID 分值下，知情正确器能够产生更优质的样本，在 text8 和 tokenize 的 ImageNet 256x256 数据集上得到了验证。", "innovation": "本文提出了一种新的采样方案——预测-纠正采样策略。这项创新通过从扩散模型获取反馈来校正累积的近似误差，从而改进了采样器的有效性。此外，为了进一步提升正确器的性能，文章引入了基于空心变换器的架构修改和一个简单的自适应训练目标，以优化模型的训练过程。研究展示了该方法能够显著提高离散扩散模型的采样质量和计算效率，特别是在减少采样步骤的情况下依然能够保持良好性能。", "conclusion": "本文通过引入知情正确的纠正器来解决离散扩散模型采样中的挑战。实验结果表明，在较少的错误或更高的 FID 分值下，知情正确器能够产生更优质的样本，这在 text8 和 tokenize 的 ImageNet 256x256 数据集上得到了验证。这种方法展现出离散扩散模型在快速、高保真生成方面的潜在价值。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.21794", "html_url": "https://arxiv.org/abs/2407.21794", "title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey", "title_en": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey", "authors": "Atsuyuki Miyai,Jingkang Yang,Jingyang Zhang,Yifei Ming,Yueqian Lin,Qing Yu,Go Irie,Shafiq Joty,Yixuan Li,Hai Li,Ziwei Liu,Toshihiko Yamasaki,Kiyoharu Aizawa", "background": "对异常样本的检测对于确保机器学习系统的安全性至关重要，这已成为OOD检测领域的核心问题。此外，OOD检测与其他几个密切相关的问题，如异常检测（AD）、新颖性检测（ND）、开放集识别（OSR）和离群值检测（OD），密切相关。为了统一这些问题，提出了一种泛化的OOD检测框架，对这五个问题进行了分类。然而，Vision Language Models（VLM）如CLIP的出现显著改变了这一范式，模糊了这些领域的界限，使研究人员再次感到困惑。现有的文献主要集中在传统的OOD检测框架上，但忽视了VLM带来的变化和影响。", "innovation": "本文首先提出了一种泛化的OOD检测v2框架，该框架涵盖了VLM时代这些领域的发展演变。与现有文献相比，本文探讨了定义、问题设置和基准的显著转变，并全面回顾了OOD检测及其相关任务的方法，澄清了它们与OOD检测的关系。最后，文章还探讨了在大型Vision Language Model (LVLM)时代的进展，如GPT-4V，并提出了开放的研究挑战和未来方向，从而为后续研究提供了一种新的视角，更加适用于VLM时代的特点。", "conclusion": "本文通过提出泛化OOD检测v2框架，概述了泛化的OOD检测与相关任务自VLM时代以来的变化与进展。展望了未来的研究方向，指出了在这一领域中仍存在的挑战。本研究为OOD检测及其相关任务提出了新的见解，并提供了一个新的研究框架，旨在更好地应对VLM带来的变化。研究结果的资源可在这个 https URL 对公众免费开放。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.05249", "html_url": "https://arxiv.org/abs/2408.05249", "title": "基于联邦学习推动肿瘤学进展：乳腺癌、肺癌和前列腺癌跨界的系统综述", "title_en": "Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review", "authors": "Anshu Ankolekar,Sebastian Boie,Maryam Abdollahyan,Emanuela Gadaleta,Seyed Alireza Hasheminasab,Guang Yang,Charles Beauville,Nikolaos Dikaios,George Anthony Kastis,Michael Bussmann,Sara Khalid,Hagen Kruger,Philippe Lambin,Giorgos Papanastasiou", "background": "联邦学习（FL）作为解决集中式机器学习在肿瘤学中局限性的一种有前景的解决方案，特别是在克服隐私问题并利用多中心、多样化数据方面。本综述综述了当前肿瘤学中先进联邦学习的知识，重点是乳腺癌、肺癌和前列腺癌。与以往的综述不同，本研究全面评估了联邦学习在实际医疗环境中的实施情况及其对癌症护理的影响，证明了其在增强临床环境中机器学习的一般性、性能和数据隐私方面的有效性。", "innovation": "研究展示了联邦学习在应对不断收紧的数据隐私法规背景下被广泛采用的情况。在25项研究中，有15项表明联邦学习优于集中式机器学习，涵盖了多种机器学习模型和临床应用，促进了多模态信息在精准医疗中的整合。尽管现有的研究在可重现性、标准化和方法论方面仍存在挑战，但联邦学习在利用真实世界数据和解决临床需求方面的明显益处突显了其对肿瘤学研究的重要潜力。未来研究应该集中在解决这些限制并进一步探索先进的联邦学习方法上，以充分利用数据的多样性并实现尖端联邦学习在癌症护理中的变革性力量。", "conclusion": "尽管现有的研究仍然面临一些挑战，如可重现性、标准化和方法论方面的不足，但联邦学习在医疗环境中的应用展示了其在增强数据隐私和模型泛化能力方面的重要潜力，特别是在癌症研究中。提出了未来研究应解决这些问题并进一步探索更先进的联邦学习方法，以实现联邦学习在癌症护理中的变革性影响力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.05412", "html_url": "https://arxiv.org/abs/2408.05412", "title": "通过音频感知风格参考实现风格保留唇同步", "title_en": "Style-Preserving Lip Sync via Audio-Aware Style Reference", "authors": "Weizhi Zhong,Jichang Li,Yinqi Cai,Ming Li,Feng Gao,Liang Lin,Guanbin Li", "background": "近年来，基于音频的唇形同步因其在多媒体领域的广泛应用而受到广泛关注。不同个体在读同样话语时表现出独特的唇形，这主要由于个人独特的讲话风格，给基于音频的唇形同步带来了显著挑战。早期的方法往往忽略了对个人讲话风格的建模，导致唇形同步效果不尽如人意。近年来的技术通过聚合带有参考风格的视频中的信息来指导任意音频的唇形同步，但因为聚合风格不准确，从而难以很好地保留讲话风格。", "innovation": "本文提出了一种创新的音频感知风格参考方案，该方案有效利用了输入音频与参考音频之间的关系，解决了风格保留的音频驱动唇形同步问题。该方案首先开发了一个先进的基于Transformer的模型，能够根据输入音频预测相应的唇部运动，并通过交叉注意力层从参考风格视频中聚合风格信息进行增强。其次，为了更好地将唇部运动渲染成逼真的谈话面部视频，还设计了一种条件潜在扩散模型，通过调制卷积层整合唇部运动并借助空间交叉注意力层融合参考面部图像。", "conclusion": "大量的实验验证了所提出的方法在精确的唇形同步、保留讲话风格以及生成高保真、逼真的谈话面部视频方面具有有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.07448", "html_url": "https://arxiv.org/abs/2409.07448", "title": "一种用于缓解基于流的ML-NIDS中规避敌对攻击的新扰动得分", "title_en": "A Novel Perturb-ability Score to Mitigate Evasion Adversarial Attacks on Flow-Based ML-NIDS", "authors": "Mohamed elShehaby,Ashraf Matrawy", "background": "随着网络威胁的演变，确保基于流的机器学习（ML）网络入侵检测系统（NIDS）免受规避敌对攻击的欺骗变得至关重要。此背景下，论文提出了‘特征可扰动性’的概念，并提出了一个新的‘可扰动得分’（PS），以量化在问题空间中攻击者对NIDS特征进行操纵的可能性。该得分识别了由于网络流量字段的语义、特定领域限制和相关性而结构上对规避攻击具有抵抗力的特征，从而增强基于流的ML-NIDS的鲁棒性与安全性。实验表明，通过移除或掩蔽高度可操纵的特征可以保持检测性能的同时显著减少对抗性规避攻击的脆弱性。", "innovation": "提出了‘特征可扰动得分’（PS）概念，并通过PS评估和指导特征选择及掩蔽，以增强基于流的ML-NIDS的防御能力。这种得分能够识别出易受问题空间扰动影响的特征，利用网络检测领域的约束作为轻量级的防御机制，有效地抵御针对基于流的ML-NIDS的规避敌对攻击。", "conclusion": "通过实验验证，这种基于PS的防御方法能够有效减少基于流的ML-NIDS对规避敌对攻击的易感性，同时保持良好的检测性能。这一创新为提高网络入侵检测系统的安全性和鲁棒性提供了新的策略。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.09957", "html_url": "https://arxiv.org/abs/2409.09957", "title": "深度图异常检测：综述及新视角", "title_en": "Deep Graph Anomaly Detection: A Survey and New Perspectives", "authors": "Hezhe Qiao,Hanghang Tong,Bo An,Irwin King,Charu Aggarwal,Guansong Pang", "background": "图异常检测（GAD）旨在识别出异常的图实例（节点、边、子图或图），近年来由于其在广泛的应用领域的的重要性受到越来越多的关注。利用图神经网络（GNN）等深度学习方法进行图异常检测，由于其在捕捉图数据中的复杂结构和/或节点属性方面的强大能力，被认为是很有前景的方法之一。鉴于大量基于GNN的GAD方法的提出，对现有研究方法和发现进行总结变得尤为重要，以便能够针对开放的GAD问题制定有效的模型设计。尽管已有的一些综述集中在特定任务上的讨论，但在理解现有方法的技术洞见和解决GAD中某些独特挑战方面的局限性尚不清楚。因此，本文通过讨论问题的复杂性和由此产生的挑战，以及从三个新的方法论视角系统地回顾当前的深度GAD方法来填补这一空白：GNN骨干设计、GAD代理任务设计和图异常度量。为了进一步加深讨论，还提出了13个细粒度的方法分类来提供对模型设计及其能力的更深入的见解。为了便于实验和验证，还总结了一个广泛使用的GAD数据集集合和实证比较。此外，还讨论了多个开放问题，以激发更多的高质量研究未来的进行。", "innovation": "本文提出了一种从三个新的方法论视角系统地回顾当前的深度GAD方法，并引入了图异常度量，探讨了通过GNN骨干设计、代理任务设计和图异常度量来进行深入研究的方法。此外，还提出了13个细粒度的方法分类，以提供对模型设计及其实现能力的更深入的见解。同时，本文提供了一个持续更新的数据集库，链接到算法的代码，并进行了实证比较，以促进未来的研究。", "conclusion": "本文总结了现有基于GNN的图异常检测方法和发现，对三个新的方法论视角下的GAD方法进行了分类，并提出了详细的模型设计及其能力见解。还建议了进一步的研究问题，提供了用于图异常检测的数据集和算法代码的持续更新的仓库，为未来的研究奠定了基础。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.07009", "html_url": "https://arxiv.org/abs/2410.07009", "title": "Pap2Pat: 以专利-论文对为基准的基于提纲的长文专利生成评估", "title_en": "Pap2Pat: Benchmarking Outline-Guided Long-Text Patent Generation with Patent-Paper Pairs", "authors": "Valentin Knappich,Simon Razniewski,Anna Hätty,Annemarie Friedrich", "background": "大型语言模型（LLMs）在处理长且复杂的技术文本时仍有挑战，尤其是在支持昂贵且耗时的专利撰写过程中。专利描述部分通常占文档的90%以上，但其自动生成的研究相对不足。专利律师在撰写专利申请时通常会收到发明报告（IRs），这些报告通常是机密的，阻碍了对LLM支持下的专利撰写的研究所使用。我们利用专利-论文对的双重性质，构建了一个开放且现实的专利撰写基准PAP2PAT，包含1800个专利-论文对，描述相同发明。现有研究发现，尽管LLM可以有效利用来自论文的信息，但仍难以达到必要的详细程度。", "innovation": "我们提出了基于提纲的分块生成方法，使用研究论文作为发明规范来解决复杂的长文档专利生成任务。我们在PAP2PAT基准和人类案例研究中的广泛评估表明，LLM能够有效利用论文信息，但仍然难以提供必要的细节。微调可以使生成的文本更具专利风格，但也增加了妄言的风险。我们发布了该数据集和相关代码：this https URL", "conclusion": "LLM在处理专利撰写任务时可以有效地利用论文信息，但仍面临提供足够详细内容的挑战。通过微调，可以使生成的文本更具专利风格，但同时增加了一些妄言。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10056", "html_url": "https://arxiv.org/abs/2410.10056", "title": "学时锯齿现象：揭示Adam和其他优化器中的训练损失振荡", "title_en": "The Epochal Sawtooth Phenomenon: Unveiling Training Loss Oscillations in Adam and Other Optimizers", "authors": "Qi Liu,Wanjing Ma", "background": "在使用自适应梯度优化器如Adam进行训练时，经常观察到一种重复出现的训练损失模式，称为‘学时锯齿现象（ESP）’。这种模式的特点是在每个学时周期开始时损失急剧下降，然后逐渐上升，形成了锯齿形状的损失曲线。尽管这种现象在Adam上表现最为明显，但其他优化器如RMSProp也会表现出类似但较轻微的现象。", "innovation": "通过实证分析，作者发现了导致ESP的关键因素，包括Adam的$\beta$参数、批次大小、数据打乱以及样本替代。研究表明，ESP来源于适应性学习率调整，这是由第二矩估计控制的。此外，作者还发现，在数据打乱过程中，'立即重新暴露于样本'的效果使得模型在每个学时周期开始时学习或记忆更多内容。研究还发现，较小的$\beta_2$值会加剧ESP，但可以作为一种正则化手段。虽然ESP不一定是过拟合的标志，但较大的模型容量会放大这一现象。进一步通过高维度二次最小化任务重现ESP，证明了该模式的普遍性。", "conclusion": "尽管ESP不是过拟合的指标，但较大模型容量会放大这种现象，并且通过数据打乱可能导致模型在学时周期开始时学习或记忆更多内容。这为理解优化器行为提供了新的视角，有助于优化训练过程，改进模型性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.16930", "html_url": "https://arxiv.org/abs/2410.16930", "title": "数学神经手术：仅通过前向传递隔离语言模型的数学推理能力", "title_en": "Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes", "authors": "Bryan R. Christ,Zack Gottesman,Jonathan Kropko,Thomas Hartvigsen", "background": "数学推理是大型语言模型（LLM）研究的一个活跃领域，因为它是人工智能的标志，并且在数学教育等多个领域具有重要意义。然而，很少有研究探讨数学推理是如何编码在LLM参数中的，以及这种能力是否可以在模型内部被隔离出来。这样做可以允许对特定的数学表现进行有针对性的干预，而不改变非数学行为，并有助于理解模型如何编码数学推理。", "innovation": "我们提出了Math Neurosurgery（MathNeuro），一种计算效率高的方法，用于仅通过前向传递来隔离LLM中的数学特定参数。MathNeuro在现有研究的基础上，利用权重和激活值来计算参数的重要性，并通过过滤掉对于通用语言任务重要的参数来隔离数学特定参数。通过修剪MathNeuro识别的参数，可以删除LLM的数学推理能力，而不显著影响其通用语言能力。通过将选定参数放大一个小常数，可以显著提高预训练或指令调优的LLM在GSM8K和MATH数据集上的表现，同时保留非数学行为。MathNeuro还具有数据效率，其大部分效果仅使用一个样本就能生成。\n", "conclusion": "MathNeuro展示了未来工作干预数学特定参数的潜力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.11171", "html_url": "https://arxiv.org/abs/2411.11171", "title": "LLäMmlein：透明、紧凑且具有竞争力的从零开始的德语唯一语言模型", "title_en": "LLäMmlein: Transparent, Compact and Competitive German-Only Language Models from Scratch", "authors": "Jan Pfister,Julia Wunderle,Andreas Hotho", "background": "介绍了创建两个新的从零开始的德语解码器模型LLäMmlein 120M和1B，供德语自然语言处理研究社区使用。背景涵盖了模型训练的整个过程，包括数据预处理、自定义德语分词器、模型训练以及在多种基准测试上的评估。训练过程中保存了多个中间结果，并使用SuperGLEBer基准进行分析，以监控模型的学习动态。", "innovation": "创新之处在于，作者从零开始透明地创建了两个大型的德语解码器模型，并公开了这些模型及其训练数据，为德语自然语言处理研究社区提供了宝贵资源。通过SuperGLEBer基准进行的训练结果显示，这些模型与最先进的模型相比表现颇具竞争力，特别是在与相似参数量的模型比较时效果相当甚至更好。另外，结果显示模型的质量随着规模的增加而预期地提升，但在某些任务上的性能提升在早期阶段就达到了平台期，这为未来模型开发中的资源配置提供了有价值的信息。", "conclusion": "结论指出，这两个模型的质量与规模成正比，但某些任务的性能改善在早期就已经达到平台期。这为未来的模型开发提供了重要的资源分配见解，表明未来可能需要在其他方面进行更多的投入以进一步提高模型性能。同时也强调了开放共享模型和数据对于推动NLP研究的重要性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.11714", "html_url": "https://arxiv.org/abs/2411.11714", "title": "基于技能库和触觉表示的语义-几何-物理驱动的机器人操作技能转移", "title_en": "Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation", "authors": "Mingchao Qi,Yuanjin Li,Xing Liu,Zhengxiong Liu,Panfeng Huang", "background": "开发能够在未结构化环境中操作的通用机器人系统是一个显著挑战，特别是在执行长时程且具有丰富接触的任务时，需要在不同的任务场景之间高效地转移技能。为此，该研究提出了基于知识图谱的技能库构建方法，该方法使用“任务图”和“场景图”来分层组织操作知识，并采用“状态图”来促进高层次任务规划与低层次场景信息之间的交互。在此基础上，研究进一步提出了一种新的基于技能库和触觉表示的分层技能转移框架，该框架结合了高层次推理与低层次精确性的技能转移和执行。", "innovation": "该研究创新地提出了基于知识图谱的技能库构建方法，并在此基础上提出了分层技能转移框架。该框架利用大规模语言模型结合语境学习和四阶段链式思考提示范式实现子任务序列转移，并开发了基于技能库的自适应轨迹转移方法和基于触觉表示的自适应轮廓抽取和姿态感知方法，能够在新环境中动态获取高精度的轮廓和姿态信息，以确保转移技能的有效性。", "conclusion": "实验结果表明，该方法在不同任务场景中具有技能转移和适应性能力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12222", "html_url": "https://arxiv.org/abs/2411.12222", "title": "对比相似性感知的双路径Mamba算法用于多元时间序列节点分类", "title_en": "Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification", "authors": "Mingsen Du,Meng Chen,Yongjian Li,Xiuxin Zhang,Jiahui Gao,Cun Ji,Shoushui Wei", "background": "多元时间序列（MTS）数据来源于工程应用、健康监测和物联网等多个领域，具有时序变化和高维特征。近年来的研究集中在探索MTS中的长程依赖性和相似性，然而这些特性使得MTS难以建模并且难以有效高效地获取相似性，因此该研究提出了一种对比相似性感知的双路径Mamba（CS-DPMamba）算法来解决这些问题。", "innovation": "该研究通过引入时间对比学习模块来获取样本的动态相似性，并使用Fast动态时间规整（FastDTW）构建MTS表示之间的相似性矩阵；并且通过应用双路径Mamba来考虑MTS的双向特性，更好地捕捉数据中的长程和短程依赖关系；最后利用Kolmogorov-Arnold网络增强的图同构网络来完成矩阵内的信息交互与MTS节点分类任务，通过综合考虑长程依赖性和动态相似性特征，实现了精确的MTS节点分类。", "conclusion": "通过在各种应用背景下多元时间序列数据集上的实验验证，结果表明该方法在监督和半监督的多元时间序列分类任务中表现出优越性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18043", "html_url": "https://arxiv.org/abs/2411.18043", "title": "主体间异质关系和形状截取元素在半监督多变量系列分类中的应用", "title_en": "Heterogeneous Relationships of Subjects and Shapelets for Semi-supervised Multivariate Series Classification", "authors": "Mingsen Du,Meng Chen,Yongjian Li,Cun Ji,Shoushui Wei", "background": "多变量时间序列（MTS）分类在工业、医疗和金融等领域广泛应用，主要目的是从复杂的时序数据中提取关键特征，以实现准确的决策和预测。然而，现有的MTS分类方法往往难以有效建模高维数据，并且缺少标记数据，导致分类性能较差。因此，本文旨在解决上述问题，提出了一种异质关系主题和形状截取元素的半监督MTS分类方法。该方法通过整合多种类型的信息并捕捉它们之间的关系，提供了新的视角。具体来说，首先利用对比时序自注意力模块获取稀疏的MTS表示，然后使用软动态时间规整模拟能力表示之间的相似性构建相似图。接着，学习不同主题类型的形状截取元素，结合主题特征和形状截取元素作为附加信息进一步精炼相似图，最终生成异质图。最后，利用双重层次图注意力网络进行预测。通过这种方法，成功地将数据集转化为异质图，结合多样的附加信息实现了精确的半监督节点分类。实验结果证明了本文方法在MTS分类任务中优于现有最先进的方法，验证了其优越性。", "innovation": "本文提出了一种异质关系主题和形状截取元素方法，用于半监督MTS分类。该方法通过整合多种类型的附加信息并捕捉它们之间的关系，提供了新的视角。具体来说，利用对比时序自注意力模块获取稀疏的MTS表示，使用软动态时间规整构建相似图，学习不同主体类型的形状截取元素，结合主题特征和形状截取元素进一步精炼相似图，最终生成异质图，并通过双重层次图注意力网络进行预测。", "conclusion": "通过这种方法，成功地将数据集转化为异质图，结合多样的附加信息实现了精确的半监督节点分类。实验结果证明了本文方法在MTS分类任务中优于现有最先进的方法，验证了其优越性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.19479", "html_url": "https://arxiv.org/abs/2411.19479", "title": "FLARE：针对后门攻击的通用数据集净化方法", "title_en": "FLARE: Towards Universal Dataset Purification against Backdoor Attacks", "authors": "Linshan Hou,Wei Luo,Zhongyun Hua,Songhua Chen,Leo Yu Zhang,Yiming Li", "background": "深度神经网络（DNNs）容易受到后门攻击的影响，攻击者可以通过向数据集中注入含有特定触发器的恶意样本来植入隐藏后门，从而操控模型的预测结果。当前的数据集净化方法存在一种潜在假设，即后门攻击中触发器与目标标签之间的关联比正常特征更容易学习，但实际情况下，这一假设并不总是成立，特别是在全对全（A2A）和非目标（UT）攻击中，因此现有的净化方法效果有限。净化方法通常依赖于在输入输出空间或最终隐藏层空间中分离恶意和正常样本的能力，这种分离能力并不是仅存在于一层，而是在不同隐藏层之间存在差异性。", "innovation": "作者提出了FLARE，这是一种通用的数据集净化方法，旨在应对各种类型的后门攻击。FLARE通过聚合所有隐藏层中的异常激活来构建表示，进行聚类。FLARE还开发了一种自适应子空间选择算法，通过选择最佳分割整个数据集的区域来增强分离性。FLARE会评估每个簇的稳定性，并将更稳定的簇识别为受污染的数据。大量的基准测试数据显示FLARE在应对包括全对一（A2O）、全对全（A2A）和非目标（UT）在内的22种代表性后门攻击时表现出色，并且能够抵抗适应性攻击。", "conclusion": "基于广泛的数据集测试，FLARE在应对多种后门攻击时表现出有效的净化能力，并且对攻击具有韧性，这表明FLARE是一个具有广泛适用性的后门攻击防护方法。相关代码已公开可用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.03092", "html_url": "https://arxiv.org/abs/2412.03092", "title": "REVOLVE：通过跟踪文本优化中响应演变优化AI系统", "title_en": "REVOLVE: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization", "authors": "Peiyan Zhang,Haibo Jin,Leyang Hu,Xinnuo Li,Liying Kang,Man Luo,Yangqiu Song,Haohan Wang", "background": "近年来，大型语言模型（LLMs）的进步显著提升了基于LLM系统的自然语言处理和工具交互的能力，使其能够执行复杂的任务。然而，这些系统针对特定任务的优化依然具有挑战性，常常需要手动干预，比如提示工程和超参数调整。现有的自动生成优化方法，如基于文本反馈的技术（例如TextGrad），倾向于关注即时反馈，类似于传统数值梯度下降中的即时导数。但仅依赖这种反馈可能会导致调整响应过小或波动不规则，从而减慢甚至阻碍优化过程。", "innovation": "为了克服上述挑战，本文提出了REVOLVE，一种跟踪LLM系统响应演变的优化方法，通过关注响应随时间的演变，REVOLVE可以在每一步进行有思考的、渐进的调整，从而实现更稳定的优化。实验结果显示，REVOLVE在提示优化方面提高了7.8%，在解决方案精炼方面提高了20.72%，在代码优化方面提高了29.17%。此外，REVOLVE收敛于更少的迭代次数，带来了显著的计算节省。", "conclusion": "除了实用贡献，REVOLVE还展示了利用已建立优化原理中的丰富知识来增强LLM系统的潜力，这为这一混合领域的进一步发展铺平了道路，提出了一个新的有价值的方向。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.13612", "html_url": "https://arxiv.org/abs/2412.13612", "title": "大规模语言模型在自动文献综述中的应用：参考生成、摘要写作与综述撰写评估", "title_en": "Large Language Models for Automated Literature Review: An Evaluation of Reference Generation, Abstract Writing, and Review Composition", "authors": "Xuemei Tang,Xufeng Duan,Zhenguang G. Cai", "background": "大规模语言模型（LLMs）已展现出自动化文献综述过程（包括文献收集、组织和总结）的潜力。然而，难以确定LLMs是否能够有效地自动化进行全面且可靠的文献综述。本文介绍了一个框架，用于自动评估LLMs在文献写作的三大核心任务上的表现：参考生成、文献总结和文献综述撰写。", "innovation": "本研究引入了多维度的评估指标，用于评估生成的参考信息中的幻觉率，并衡量文献总结和综述与人工撰写版本的语义覆盖率和事实一致性。实验结果显示，即使是最先进的模型也会生成幻觉的参考信息，尽管最近有所进步。此外，研究发现不同模型在撰写不同学科的文献综述时性能差异显著，强调了进一步研究和开发以提高LLMs在自动化学术文献综述中的可靠性的重要性。", "conclusion": "本研究揭示了即使最先进的LLMs在自动撰写文献综述时也存在幻觉问题，并且模型在不同学科上的表现存在显著差异，这表明还需要进一步的研究和开发，以提升LLMs在自动化学术文献综述中的可靠性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.14018", "html_url": "https://arxiv.org/abs/2412.14018", "title": "SurgSora: 对象感知扩散模型用于可控手术视频生成", "title_en": "SurgSora: Object-Aware Diffusion Model for Controllable Surgical Video Generation", "authors": "Tong Chen,Shuya Yang,Junyi Wang,Long Bai,Hongliang Ren,Luping Zhou", "background": "现有的手术视频生成方法在精细运动控制和逼真性方面存在不足，无法有效提升医学教育和研究的水平。因此，需要开发一个能够从单个输入帧和用户指定的运动提示生成高保真、可控手术视频的框架。", "innovation": "SurgSora框架通过结合语义注入器、解耦流动映射器和轨迹控制器这三个主要模块，实现从单个输入帧生成高保真、可控制的手术视频。该框架利用自预测对象特征和深度信息来优化RGB外观和光学流动，使得生成的视频在视觉真实性和可控性方面达到了最先进的水平。SurgSora不对对象进行不分青红皂白的处理，也不依赖于真实分割掩码，而是依靠自预测的对象特征和深度信息来实现精细的视频合成。", "conclusion": "我们的结果表明，通过SurgSora生成的视频在视觉真实性和可控性方面达到了最先进的水平，尤其在手术培训和教育中具有潜在的应用价值。与专家外科医生的合作评估进一步证明了SurgSora生成视频的高度逼真性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.18043", "html_url": "https://arxiv.org/abs/2412.18043", "title": "将AI研究与临床编码工作流程的需求相一致：基于美国数据和批判性审查的八项建议", "title_en": "Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review", "authors": "Yidong Gan,Maciej Rybinski,Ben Hachey,Jonathan K. Kummerfeld", "background": "临床编码对于医疗收费和数据分析至关重要。手动临床编码既劳动密集又容易出错，这激发了研究以实现对该过程的完全自动化。然而，基于美国英语电子健康记录和使用这些记录的自动化编码研究分析表明，广泛使用的评估方法与实际临床环境不匹配。例如，仅针对最常见的前50个代码进行评估是一种简化，因为实践中使用的代码有数千种。", "innovation": "本文提出八项具体建议，旨在使AI编码研究更紧密地与临床编码的实际挑战相匹配。同时，提出了新的基于AI的方法，这些建议为支持临床编码流程提供替代方案。", "conclusion": "该论文通过对美国数据的分析和批判性审查，指出现有评估方法存在的问题，并提出了改进方法的具体建议，强调需要进一步关注实际临床编码的挑战和需求。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.03491", "html_url": "https://arxiv.org/abs/2501.03491", "title": "LLMs能否提出好问题？", "title_en": "Can LLMs Ask Good Questions?", "authors": "Yueheng Zhang,Xiaoyuan Liu,Yiyou Sun,Atheer Alharbi,Hend Alzahrani,Tianneng Shi,Basel Alomair,Dawn Song", "background": "本文评估了大型语言模型（LLMs）生成的问题与人类撰写的提问在六个维度上的差别：问题类型、问题长度、上下文覆盖范围、解答可能性、新颖性以及所需答案的长度。研究涵盖了四个顶级的开源和专有模型。结果表明，由LLMs生成的问题往往需要更长的描述性答案，并且关注上下文的分布更为均匀，不同于问答任务中常有的位置偏向性。", "innovation": "研究揭示了LLMs生成的问题特有的特征，并为后续提高问题质量和下游应用场景提供了指导。", "conclusion": "LLMs生成的问题倾向于需要更长描述性的答案，并且在关注上下文方面表现出更均匀的分布，这是对以往QA任务中的位置偏向性的对比。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.09265", "html_url": "https://arxiv.org/abs/2501.09265", "title": "大规模语言模型主观任务视角转换", "title_en": "Perspective Transition of Large Language Models for Solving Subjective Tasks", "authors": "Xiaolong Wang,Yuanchi Zhang,Ziyue Wang,Yuzhuang Xu,Fuwen Luo,Yile Wang,Peng Li,Yang Liu", "background": "大规模语言模型（LLMs）已经彻底改变了自然语言处理领域，使其在各种任务中取得了显著的进步。然而，与常识推理和算术问答等客观任务相比，LLMs在主观任务上的表现仍然有限，在这些问题中，特定问题的视角对于更好地理解上下文和给出适当的响应起着关键作用。例如，在某些情况下，LLMs从专家的角色视角回答问题可能表现更好，这可能会引发他们的相关领域知识。而在其他情况下，从第三方视角回答可能会提供更准确的答案，从而更全面地理解问题，并可能减轻固有偏见。因此，本研究旨在提出一种基于上下文学习的方法——视角转换推理（RPT），使LLMs能够在相应的主观问题上灵活地选择直接、角色和第三方视角，以获得最佳的解决方案。该方法通过使用包括GPT-4、GPT-3.5、Llama-3和Qwen-2在内的各种LLMs进行广泛实验，在12项主观任务上都优于使用固定视角的方法，展现了LLMs如何根据不同问题灵活调整视角，以提供更细腻且上下文相关的响应方式。", "innovation": "提出了一种基于上下文学习的方法——视角转换推理（RPT），使LLMs能够在相应的主观问题上灵活地选择直接、角色和第三方视角，以获得最佳的解决方案。这种方法显著提高了LLMs在主观任务上的表现，并展示了其如何更好地适应问题的不同要求，以提供更加精细和上下文相关的响应。通过广泛的实验验证了该方法的有效性，优于现有的一般方法如链式思考提示和专家提示。", "conclusion": "研究表明，RPT方法能够显著提升LLMs在解决主观问题时的表现。该方法强调了LLMs在解决不同类型的主观问题时灵活调整视角的重要性，其复杂的应用方式表明了它们在适应问题要求方面的能力，并能够提供对不同问题的更细腻和上下文相关的响应。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00620", "html_url": "https://arxiv.org/abs/2502.00620", "title": "代表性的表示塑造弱到强泛化：理论洞见与经验预测", "title_en": "Representations Shape Weak-to-Strong Generalization: Theoretical Insights and Empirical Predictions", "authors": "Yihao Xue,Jiping Li,Baharan Mirzasoleiman", "background": "弱到强泛化（W2SG）是一种模拟人类如何在未来引导超人工智能的关键类比。近期研究虽然提供了理论洞察，但弱模型与强模型之间相互作用的具体机制仍然是一个谜。本文通过理论视角探讨W2SG，揭示其基于弱模型和强模型内部表示主成分衍生出的核函数的特征，这些特征可用于定义一个空间，该空间在高层次上捕捉了弱模型无法学习但强模型可以学习的内容。标签在这个空间的投影量化了强模型因弱监督而未能实现其全部潜力的程度。这不仅提供了对强模型如何纠正弱监督某些错误的理解，还避免了过拟合问题。现有理论在实践中有重大意义，通过实验展示了在分子预测任务中使用变压器，及5个人工智能语言处理任务中52个大模型上的应用，均无需标签即可预测W2SG性能趋势。", "innovation": "本文通过理论分析揭秘弱到强泛化的机制，提出了基于主成分分解的核函数表征方法，帮助理解强模型如何纠正弱监督中的错误并且不受过拟合影响。此外，文中提出的理论提供了不需要标签就能预测W2SG性能趋势的度量标准，具有重要的实用价值。", "conclusion": "本文为Understanding Weak-to-Strong Generalization从理论上提供了洞见，并通过实验展示了这种理论在分子预测和自然语言处理任务中的应用效果，预测了W2SG的性能趋势，对理解未来人类引导超人工智能具有重要意义。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02834", "html_url": "https://arxiv.org/abs/2502.02834", "title": "任务感知虚拟训练：增强元强化学习在分布外任务中的泛化能力", "title_en": "Task-Aware Virtual Training: Enhancing Generalization in Meta-Reinforcement Learning for Out-of-Distribution Tasks", "authors": "Jeongmo Kim,Yisak Park,Minung Kim,Seungyul Han", "background": "元强化学习旨在开发能够在未见过的任务中泛化的策略。以前的方法通过任务潜在空间改善任务表示，但在分布外（OOD）任务上表现不佳。本研究背景强调了现有方法在处理OOD任务时的局限性，并提出了解决这一问题的需求。", "innovation": "提出了任务感知虚拟训练（TAVT），这是一种新的算法，利用基于度量的表示学习准确捕捉任务特性，适用于训练和OOD场景。TAVT通过虚拟任务保留任务特性，并采用状态正则化技术减轻状态变化环境中的过度估计误差。研究表明，TAVT在MuJoCo和MetaWorld环境中显著提高了对OOD任务的泛化能力。", "conclusion": "TAVT能够在虚拟任务中保持任务特征，并通过状态正则化技术减少状态变化环境中的过度估计误差。实验结果表明，TAVT显著增强了元强化学习对分布外任务的泛化能力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02844", "html_url": "https://arxiv.org/abs/2502.02844", "title": "狼群对抗性攻击：用于鲁棒多智能体强化学习", "title_en": "Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning", "authors": "Sunwoo Lee,Jaebak Hwang,Yonghyeon Jo,Seungyul Han", "background": "传统的鲁棒方法在多智能体强化学习（MARL）中难以应对协调的 adversarial 攻击，尤其是在合作场景中。这种问题限制了 MARL 在需要合作的复杂环境中的应用效果和安全性。现有方法难以在多智能体系统中实现全面的合作，以抵御潜在的攻击。为此，该论文提出了一种灵感来源于狼群狩猎策略的 Wolfpack 敌对攻击框架，以及用于提高 MARL 策略鲁棒性的 Wolfpack-敌对学习（WALL）框架。", "innovation": "提出的 Wolfpack 对抗性攻击框架，通过针对性地攻击初始智能体及其协助智能体来破坏合作。同时，WALL 框架通过促进整体协作来训练鲁棒的 MARL 策略，以防御 Wolfpack 攻击。该研究展示了 Wolfpack 攻击的强大破坏力，并且通过 WALL 框架显著提高了 MARL 策略的实际鲁棒性。", "conclusion": "实验证明了 Wolfpack 攻击的严重性，WALL 框架显著提升了 MARL 策略的鲁棒性。这种框架为复杂环境中的 MARL 应用提供了一种有效的防御机制，并提升了系统的整体合作和安全性。研究的代码可以在提供的链接中获取。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16645", "html_url": "https://arxiv.org/abs/2502.16645", "title": "CODESYNC: 规模化同步大型语言模型与动态代码演进", "title_en": "CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale", "authors": "Chenlong Wang,Zhaoyang Chu,Zhengxiang Cheng,Xuyi Yang,Kaiyue Qiu,Yao Wan,Zhou Zhao,Xuanhua Shi,Dongping Chen", "background": "大型语言模型（LLMs）在软件工程中表现出色，但在适应不断演变的代码知识方面面临挑战，特别是第三方库API的频繁更新。这些模型的静态预训练数据集导致代码更新不及时，容易出现不可执行的代码或安全性、效率不足的实现。", "innovation": "本文提出了CODESYNC，一种数据引擎，用于识别过时的代码模式并从Python第三方库中实时收集代码知识更新。在此基础上，开发了CODESYNCBENCH，一个全面的基准测试，评估LLMs在随代码进化保持同步的能力，涵盖了六个Python库的220个API的真实世界更新。还包括3300个测试用例和一个包含2200个训练样本的更新感知指令调优数据集。实验结果显示，即使使用高级知识更新方法（如DPO、ORPO和SimPO），最先进的LLM也难以应对动态代码的演变。", "conclusion": "我们认为，我们的基准可以为未来实时代码知识更新的有效方法开发提供坚实的基础。实验代码和数据集可以在以下网址获取：this https URL。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.21266", "html_url": "https://arxiv.org/abs/2502.21266", "title": "在AI_INFN平台支持联邦云中的基础科学研究中的机器学习开发", "title_en": "Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform", "authors": "Lucio Anderlini,Matteo Barbetti,Giulio Bianchini,Diego Ciangottini,Stefano Dal Pra,Diego Michelotto,Carmelo Pellegrino,Rosa Petrini,Alessandro Pascolini,Daniele Spiga", "background": "机器学习 (ML) 正在彻底改变科学家们设计、开发和部署大数据密集型软件的方式。然而，ML 的采用正在对计算基础设施提出新的挑战，特别是在为开发、测试和生产过程中协调访问硬件加速器方面。为了应对这些挑战，INFN 资助的 AI_INFN 项目旨在通过支持多个方面来促进 ML 技术在 INFN 应用场景中的应用，而无需牺牲研究所多样化的研究活动。该项目利用 INFN 云中的云原生解决方案，以尽可能有效地共享硬件加速器，从而促进基于 GPU 的数据分析工作流的开发及其在异构分布式计算资源上的扩展，这些资源可能通过 interLink 提供商以虚拟 Kubelets 形式进行联邦化。", "innovation": "该项目利用云原生解决方案在 INFN 云中有效共享硬件加速器。自主Commissioned的Kubernetes平台旨在简化GPU 动力数据流程的工作流开发及其在异构、分布计算资源上的扩展，并可能通过 interLink 提供商以虚拟 Kubelets 形式进行联邦化。", "conclusion": "该项目将通过AI_INFN平台提供对 ML 技术的支持，以促进 INFN 应用场景中的采用，同时确保研究所多样化的研究活动不会受到阻碍。此贡献更新了相关 Kubernetes 平台的设计和开发情况，该平台有助于基于 GPU 提高的数据分析工作流的可扩展性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01630", "html_url": "https://arxiv.org/abs/2503.01630", "title": "机器学习者应承认大语言模型作为个人数据的法律影响", "title_en": "Machine Learners Should Acknowledge the Legal Implications of Large Language Models as Personal Data", "authors": "Henrik Nolte,Michèle Finck,Kristof Meding", "background": "大多数大语言模型（LLMs）在某种程度上存储了训练数据。即使只存储少量个人数据，这些模型通常仍然受数据保护法律的约束。如果个人可被识别或推断出，LLMs 在培训阶段结束后仍需遵守欧盟通用数据保护条例（GDPR）的要求。研究表明，LLMs 在推理时会输出训练数据，无论是直引还是概括形式。部分模型本身即可被视为个人数据，这触发了一系列数据保护的影响，包括数据主体的权利，如访问权、修正权或删除权，这些权利适用于嵌入AI模型中的信息。 ", "innovation": "本文提出了一种新的视角，即机器学习研究人员必须在整个机器学习开发生命周期中承认LLMs作为个人数据的法律影响，不仅仅是在数据收集和整理阶段，还涵盖模型的发布阶段，如GitHub或Hugging Face。此外，作者还提出了一些方法，以帮助机器学习研究社区应对这些法律影响。", "conclusion": "本文旨在提高数据保护法律与大语言模型的现有技术能力之间的契合度，强调需要更多的法律领域与机器学习社区之间的互动，以改进这种联动。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01903", "html_url": "https://arxiv.org/abs/2503.01903", "title": "PsychBench: 普及心理健康辅助临床实践的综合且专业的基准体系", "title_en": "PsychBench: A comprehensive and professional benchmark for evaluating the performance of LLM-assisted psychiatric clinical practice", "authors": "Shuyu Liu,Ruoxi Wang,Ling Zhang,Xuequan Zhu,Rui Yang,Xinzhu Zhou,Fei Wu,Zhi Yang,Cheng Jin,Gang Wang", "background": "大型语言模型（LLMs）的出现为解决医疗资源短缺和精神科临床诊断一致性低的问题提供了潜在解决方案。然而，缺乏针对真实精神科临床环境评估LLMs有效性的坚实且全面基准框架，限制了专门针对精神科应用的LLMs的发展。鉴于此，本文通过结合精神科临床需求和数据，提出了一个评估体系PsychBench，以评估LLMs在精神科临床条件下实际表现。研究使用PsychBench对16种LLMs进行了全面的定量评估，并探讨了提示设计、链式思维推理、输入文本长度和领域特定知识微调对模型性能的影响。通过详细的错误分析，识别出了现有模型的优势和潜在局限，并提出了改进方向。进一步地，还进行了60名临床经验不同的精神科医生参与的临床读者研究，探讨了现有LLMs作为不同经验精神科医生辅助工具的实用性。研究结果表明，尽管现有模型具有很大潜力，但尚不足以在精神科临床实践中作为决策工具。临床读者研究进一步表明，作为辅助工具，LLM能够尤其显著地支持初级精神科医生，有效提升其工作效率和整体临床质量。", "innovation": "提出了一个名为PsychBench的基准系统，用于评估LLMs在精神科临床条件下的实际性能；该系统结合了精神科临床需求和数据，研究包括了16种LLMs，并分析了提示设计、链式思维推理、输入文本长度和领域特定知识微调对模型性能的影响；通过临床医生读者研究，进一步探讨了LLMs作为精神科医生辅助工具的实用性；研究结果表明，现有模型具有潜力但尚未达到在精神科临床实践中作为决策工具的水平；提出了关于改进已有模型的建议，特别是对于初级精神科医生的辅助支持。", "conclusion": "现有模型在精神科临床实践中具有很大潜力，但目前尚不足以作为决策工具。PsychBench为评估LLMs的实际性能提供了基准框架，通过公开数据集和评估框架，期待推进LLMs在精神科临床设置中的应用。LLM作为辅助工具，尤其是在支持初级精神科医生方面表现出特别的优势，提高了其工作效率和临床质量。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08221", "html_url": "https://arxiv.org/abs/2503.08221", "title": "EgoBlind: 向盲人提供第一人称视觉辅助", "title_en": "EgoBlind: Towards Egocentric Visual Assistance for the Blind", "authors": "Junbin Xiao,Nanxin Huang,Hao Qiu,Zhulin Tao,Xun Yang,Richang Hong,Meng Wang,Angela Yao", "background": "当前，多模态大型语言模型（MLLMs）在视觉辅助方面展现出潜力，但缺乏针对盲人用户的具体数据集进行评估。因此，该研究旨在创建一个专门的多模态数据集，以评估这些模型的辅助能力，特别是盲人的视觉辅助需求。这个数据集收集自真实的盲人用户，旨在提供更贴近现实需求的数据，帮助改善盲人的生活质量。", "innovation": "该论文创新地提出了EgoBlind数据集，这是首个专门用于评估辅助盲人视觉能力的多模态数据集，包含1,392个由实际盲人从第一视角录制的视频及5,311个直接由盲人生成或验证的问题，反映了他们在不同情境下的视觉辅助需求。此外，每个问题还提供了平均3个参考答案，以减少主观评价的影响。该研究还首次系统地评估了16种先进MLLMs在盲人视觉辅助领域的效果，并识别了现有模型的关键局限性，进而提出可能的改进方案。", "conclusion": "通过EgoBlind数据集的研究，论文发现所有模型在评估盲人视觉辅助需求时都表现不佳，最优秀模型的准确率为60%，远低于人类87.4%的准确率。该研究通过识别现有MLLMs的关键局限性，旨在为未来的发展提供指导，期望EgoBlind能够为开发更有效的AI助手提供有价值的基石，从而提高盲人的独立生活能力。数据和评估代码可在特定网址获取。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08327", "html_url": "https://arxiv.org/abs/2503.08327", "title": "增加薄荷中的巧克力：缓解机器翻译中的度量干扰", "title_en": "Adding Chocolate to Mint: Mitigating Metric Interference in Machine Translation", "authors": "José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins", "background": "随着自动化指标越来越强大并广泛采用，模型开发过程中无意“操纵指标”的风险也在增加。这种问题被称为度量干扰（MINT），即在同一或相关度量上进行模型调整和评估。MINT可能导致实践者对系统性能过于乐观：因为系统输出成为干扰度量的函数，其估计的质量不再与人类判断相关。本文分析了机器翻译任务中两种常见的MINT案例：训练数据过滤和使用质量信号解码。研究发现，即使度量没有直接优化，MINT也会严重扭曲实例级别的度量得分，质疑使用不同但相关的度量进行评估而不用于调优的常见策略。", "innovation": "为了应对这一问题，作者提出了MINTADJUST方法，用于在存在MINT的情况下进行更可靠的评估。在WMT24机器翻译共享任务测试集中，MINTADJUST在多数语言对上比最先进的度量更准确地排名翻译和系统，特别是在高质量系统上。此外，MINTADJUST超越了主办方使用的AUTORANK集成方法。", "conclusion": "MINTADJUST方法在多数语言对上比最先进的度量更准确地排名翻译和系统，特别是在高质量系统上。同时，MINTADJUST超越了主办方使用的AUTORANK集成方法，展示了其有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.11895", "html_url": "https://arxiv.org/abs/2503.11895", "title": "通过迭代和邻居辅助模型编辑解决UnderEdit和OverEdit问题", "title_en": "Resolving UnderEdit & OverEdit with Iterative & Neighbor-Assisted Model Editing", "authors": "Bhiman Kumar Baghel,Scott M. Jordan,Zheyuan Ryan Shi,Xiang Lorraine Li", "background": "大型语言模型（LLMs）在下游任务中广泛应用，但通过重新训练或微调来保持其知识的最新状态通常计算成本高昂。模型编辑提供了一种更有效的替代方案，它通过更新目标参数子集来进行更新，这通常遵循定位-编辑范式。然而，现有方法存在局限性：编辑可能无法注入知识（UnderEdit），或无意中破坏与之无关的相邻知识（OverEdit）.", "innovation": "为了解决这些挑战，该论文提出了两种互补的方法：迭代模型编辑，该方法应用连续编辑以减轻UnderEdit；邻居辅助模型编辑，在编辑过程中纳入相邻知识以减少OverEdit。实验结果表明，这些技术在多个LLMs、算法和基准测试中提高了编辑性能，减少了UpDate和OverEdit，同时广泛适用于任何locate-and-edit方法.", "conclusion": "该研究表明，通过迭代和邻居辅助模型编辑可以有效解决UnderEdit和OverEdit问题，显著提高了模型编辑的整体性能，并广泛适用于多种情景。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13115", "html_url": "https://arxiv.org/abs/2503.13115", "title": "超越随机群体传播：一种用于均场优化的随机算法", "title_en": "Beyond Propagation of Chaos: A Stochastic Algorithm for Mean Field Optimization", "authors": "Chandan Tankala,Dheeraj M. Nagaraj,Anant Raj", "background": "在2- Wasserstein空间中，梯度流被广泛用于优化概率分布上的函数，并通常通过包含n个粒子的相互作用粒子系统来实现。分析这些算法通常需要证明该有限粒子系统收敛，或其粒子的最终经验分布接近最优分布（即群体传播）。然而，确立有效的充分条件通常是具有挑战性的，因为有限粒子系统可能产生高度相关的随机变量。本文研究了一种虚拟粒子随机近似法，最初是为Stein变异化梯度下降引入的。该方法可视为Wasserstein空间中的随机梯度下降形式，并且可以高效实施。在流行的应用场景中，本文证明该算法的输出在与无限粒子限制相似的条件下收敛至最优分布，并且它生成了独立同分布的样本，而无需显式地建立种群传播上限.", "innovation": "提出了虚拟粒子随机近似法，该方法可以视为Wasserstein空间中的随机梯度下降形式，并高效实现。即使不需证明种群传播界限，也展示了该算法在流行应用场景下的输出能收敛至最优分布，并可生成独立同分布的样本.", "conclusion": "该研究证明了虚拟粒子随机近似算法在与无限粒子限制类相似条件下能够收敛至最优分布，并能生成独立同分布的样本，而无需显式证明种群传播界限。这种算法提供了一种高效且易于实施的方案，以实现均场优化。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13912", "html_url": "https://arxiv.org/abs/2503.13912", "title": "KANITE: Kolmogorov-Arnold Networks for ITE estimation", "title_en": "KANITE: Kolmogorov-Arnold Networks for ITE estimation", "authors": "Eshan Mehendale,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar", "background": "该论文介绍了一种名为KANITE的框架，用于在多治疗的情况下估计个体治疗效果（ITE）。通过利用Kolmogorov-Arnold网络（KAN）学习一元激活函数的独特能力，而不是多层感知机（MLPs）学习线性权重，从而提高了ITE的估计准确性。KANITE框架由两种关键架构组成，分别是概率度量（IPM）架构和熵平衡（EB）架构。IPM架构通过一种专门的方式应用概率度量损失，以有效对齐多个治疗方向上的ITE估计。ENTIRE架构使用根据优化熵并平衡治疗组协变量来学习样本权重的方法。这些架构旨在提高多治疗情况下ITE估计的效果。", "innovation": "KANITE框架通过利用KAN的独特能力，即学习一元激活函数而不是学习线性权重，来改进个体治疗效果（ITE）的估计。KANITE的IPM架构和ENTIRE架构通过专门设计来解决多治疗情况下的ITE估计问题，相比现有的最先进的算法，在${\rm \text{ε_{PEHE}}}$和${\rm \text{ε_{ATE}}}$指标上表现更佳。", "conclusion": "广泛的基准数据集评估表明，在个体治疗效果估计方面，KANITE框架优于现有的最先进的算法。实验结果强调了KAN在因果推理方法中提高因果估计能力的潜力，使得KAN在不同的应用场景中都可能发挥重要的作用。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15576", "html_url": "https://arxiv.org/abs/2503.15576", "title": "一种用于通过深度学习改进鸟类识别的鸟鸣检测器：从多尼亚纳的一例研究", "title_en": "A Bird Song Detector for improving bird identification through Deep Learning: a case study from Doñana", "authors": "Alba Márquez-Rodríguez,Miguel Ángel Mohedano-Munoz,Manuel J. Marín-Jiménez,Eduardo Santamaría-García,Giulia Bastianelli,Pedro Jordano,Irene Mendoza", "background": "被动声学监测是生物多样性保护的关键工具，但大量未经监督的音频数据给提取有意义的信息带来了巨大挑战。深度学习提供了可能的解决方案。尽管全球范围内广泛使用的鸟类识别模型（如BirdNET）在多种研究系统中成功应用，但它们在本地规模上的表现受限，因为其训练数据存在偏差，集中在特定地点和目标声音上，而非整个声音景观上。鸟类种群识别的关键挑战在于，许多录音中缺乏目标物种或包含重叠的声音，这增加了自动识别的复杂性。为了应对这些问题，在西班牙南部多尼亚纳国家级公园展开了一项研究，该地是一个高保护关注的湿地。通过部署音频记录器在三个主要生境中的九个地点进行录音，并人工标注461分钟的音频，共生成了包含3749个标签片段的34类音频段。", "innovation": "我们开发了一种多阶段管道，用于在多尼亚纳国家级公园自动识别鸟类鸣声。首先应用鸟鸣检测器来通过基于光谱图像处理的方法隔离鸟类鸣声。然后使用针对本地规模调优的自定义模型进行分类。在没有检测的情况下，添加检测器之前进行分类提高了物种识别性能，具体来说，检测器与微调的BirdNET结合使用比没有检测器的基线模型表现更好。这种方法展示了将鸟鸣检测器与本地分类模型集成的有效性。这些发现强调了需要适应通用工具以解决特定生态挑战的重要性。自动检测鸟类种类有助于跟踪这一受威胁生态系统的健康状况，考虑到鸟类对环境变化的敏感性，并支持减少生物多样性损失的保护规划。", "conclusion": "此方法证明了将鸟鸣检测器与本地分类模型相结合的有效性，并强调了开发适应特定生态挑战的工具的必要性。自动检测鸟类种类有助于监控多尼亚纳公园生态系统以及制定减少生物多样性损失的保护计划。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00857", "html_url": "https://arxiv.org/abs/2504.00857", "title": "探索用于监控视频中暴力检测的个性化联邦学习架构", "title_en": "Exploring Personalized Federated Learning Architectures for Violence Detection in Surveillance Videos", "authors": "Mohammad Kassir,Siba Haidar,Antoun Yaacoub", "background": "城市监控系统中暴力事件的检测面临着大量且多样化的视频数据的问题。现有的方法难以有效应对这一挑战。", "innovation": "本文提出了一种基于个性化联邦学习（PFL）的方法，具体采用FedLearner中的个性化层来处理监控视频的异构性和非同态特性，从而提高了检测的准确性和效率。", "conclusion": "通过实验验证，PFL模型在平衡和不平衡数据集上均表现出色，最高可达99.3%的准确性。本文表明PFL能够显著提升监控系统的可扩展性和有效性，为复杂城市环境中暴力检测提供了一个安全、隐私保护的解决方案。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04524", "html_url": "https://arxiv.org/abs/2504.04524", "title": "信任区域偏好近似：一种用于LLM推理的简单且稳定的强化学习算法", "title_en": "Trust Region Preference Approximation: A simple and stable reinforcement learning algorithm for LLM reasoning", "authors": "Xuerui Su,Shufang Xie,Guoqing Liu,Yingce Xia,Renqian Luo,Peiran Jin,Zhiming Ma,Yue Wang,Zun Wang,Yuting Liu", "background": "大型语言模型（LLMs）逐渐接近人工通用智能，通过大规模增强学习增强了人类对齐（HA）和推理能力。许多基于奖励的优化算法（如Proximal Policy Optimization (PPO)和Group Relative Policy Optimization (GRPO)）在推理任务中取得了显著的性能，而基于偏好的优化算法（如Direct Preference Optimization (DPO)）显著改进了LLMs的人类对齐性能。虽然基于奖励的优化方法在对齐任务中表现出色，但仍存在奖励作弊的问题。此外，基于偏好的算法尚未在推理任务上达到与基于奖励优化算法相同的效果，这使其在这一特定领域仍然值得探索。这些挑战促使我们提出了信任区域偏好近似（TRPA）算法，该算法结合了规则优化与基于偏好的优化，以应对推理任务中的问题，并且天然地消除了奖励作弊的问题。TRPA使用预先定义的规则构建偏好层级，形成相应的偏好对，并利用新的优化算法进行RL训练，具有理论上的单调改进保证。实验结果表明，TRPA不仅在推理任务上取得了具有竞争力的性能，还表现出高度的稳定性。", "innovation": "提出了一种结合规则优化与基于偏好优化的算法（TRPA）以增强大型语言模型（LLMs）的推理性能。TRPA算法天然地消除了奖励作弊的问题，并且通过构建偏好层级和使用新的优化算法进行RL训练，确保了理论上的单调改进。此外，TRPA还在多方面的实验中展示了良好的性能和稳定性，从而为强化学习算法的创新应用提供了新的途径。TRPA算法的代码已发布并持续更新。", "conclusion": "TRPA算法不仅在推理任务上展现了竞争力的性能，还保持了高度的稳定性。这种结合规则优化与基于偏好的方法为解决大型语言模型在对齐和推理方面的挑战提供了新的视角。未来的进一步研究可以探索TRPA在不同任务和场景中的应用。TRPA的代码已经在指定的链接上发布并持续更新，供研究人员参考。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04893", "html_url": "https://arxiv.org/abs/2504.04893", "title": "SCAM：多模态基础模型在真实世界中的一种类型图形鲁棒性评估", "title_en": "SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models", "authors": "Justus Westerhoff,Erblina Purelku,Jakob Hackstein,Jonas Loos,Leo Pinetzki,Lorenz Hufe", "background": "现有数据集在规模和多样性方面存在局限性，难以研究此类漏洞。因此，多模态基础模型中的类型攻击（exploits the interplay between text and visual content）能够利用文本和视觉内容之间的互动，导致在图像中嵌入误导性文本时发生分类错误。", "innovation": "该论文引入了SCAM，这是迄今为止最大的包含真实世界类型攻击图像的数据集，包含了1162张图像，覆盖数百种物体类别和攻击词汇。通过基准测试Vision-Language模型在SCAM上的表现，表明类型攻击显著降低了性能，并且发现训练数据和模型架构影响这些攻击的易感性。研究表明，大型Vision-Language模型（LVLM）中的视觉编码器的选择会导致此类攻击持续存在，尽管大型语言模型（LLM）的骨干网络有助于缓解这种脆弱性。此外，合成攻击与真实世界的手写攻击相似，验证了它们在研究中的使用。", "conclusion": "该研究提供了全面的资源和实证见解，促进了未来研究以实现稳健和可信赖的多模态AI系统的方向。同时，作者公开发布了本文中引入的数据库及其评估代码。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08200", "html_url": "https://arxiv.org/abs/2504.08200", "title": "影响性多臂悖论：拉动一个臂可能改变环境", "title_en": "Influential Bandits: Pulling an Arm May Change the Environment", "authors": "Ryoma Sato,Shinji Ito", "background": "经典的多臂悖论问题假设每个臂的回报是独立且稳定的，但在实际应用场景中，环境往往是非稳定的且臂之间存在相互依赖性。选中一个臂可能影响其他臂的未来回报，而现有的模型如衰减多臂悖论或多动多臂悖论无法很好地捕捉这一情况。因此，需要一个新的框架来处理这种相互影响的情形，即影响性多臂悖论。", "innovation": "提出了一种新的影响性多臂悖论，通过一个未知的对称正半定交互矩阵来建模臂之间的交互，该矩阵控制臂损失的动力学。该论文定义了这个问题，并证明了针对标准LCB算法（损失最小化版本的UCB）的超线性下界及算法独立的线性下界，以强调该设置的固有难度。还提出了一种新的LCB估计算法，该算法在假设条件下，实现了接近最优的后悔率$O(KT \text{log} T)$，并且具有简单的实现方式和高效的计算能力。", "conclusion": "通过实验验证了臂之间的相互影响，并表明该方法在合成数据集和现实世界数据集上的表现优于传统的多臂悖论算法。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11511", "html_url": "https://arxiv.org/abs/2504.11511", "title": "论持久化在大型语言模型时代的RL隐私重思", "title_en": "Position Paper: Rethinking Privacy in RL for Sequential Decision-making in the Age of LLMs", "authors": "Flint Xiaofeng Fan,Cheston Tan,Roger Wattenhofer,Yew-Soon Ong", "background": "随着强化学习（RL）在关键现实应用中的兴起，对AI系统中隐私的重新思考变得至关重要。传统的隐私框架设计用于保护孤立的数据点，但无法应对涉及时间序列模式、行为策略和协作动力的顺序决策系统的敏感信息。现代RL范式，如联邦RL（FedRL）和大型语言模型（LLMs）中的基于人类反馈的RL（RLHF），加剧了这些挑战，它们引入了复杂的、交互的和上下文相关的学习环境，而传统的技术无法解决这些问题。", "innovation": "提出了一种基于四个核心原则的新隐私范式：多尺度保护、行为模式保护、协作隐私保存和上下文感知适应。这些原则揭示了在高度关键领域（如医疗保健、自动驾驶和由LLMs驱动的决策支持系统）中随着RL系统的普及，隐私、效率和可解释性之间的固有紧张关系必须予以处理。为应对这些挑战，呼吁开发新的理论框架、实际机制和严格的评估方法，以综合实现序列决策系统的有效隐私保护。", "conclusion": "鉴于RL系统在关键领域的作用日益重要，需要发展新的理论框架、实用机制和严谨的评估方法，共同实现动态决策系统中有效的隐私保护。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.20304", "html_url": "https://arxiv.org/abs/2504.20304", "title": "UD-English-CHILDES: 董金德语资源中的黄金和银色通用依赖树集用于儿童语言交互", "title_en": "UD-English-CHILDES: A Collected Resource of Gold and Silver Universal Dependencies Trees for Child Language Interactions", "authors": "Xiulin Yang,Zhuoxuan Ju,Lanni Bu,Zoey Liu,Nathan Schneider", "background": "CHILDES是一种广泛使用的儿童和儿童导向语言转录资源。本文介绍了首个正式发布的通用依存句法（Universal Dependencies，UD）树库——UD-English-CHILDES，该树库是由之前已标注依存关系的CHILDES数据谐调形成的统一标注原则下的标准树集合，涵盖了来自11个儿童及其看护人的会话共计超过48,000句（236,000个标记）的语言样本，用于验证这些标准标注，并提供额外的100万银标准句子，为计算语言学和语言学研究提供一致性资源", "innovation": "首度推出UD-English-CHILDES树库，通过先前已标注依存关系的CHILDES数据，采用统一的标注原则对其进行规范化处理；提供超过48,000句（236,000个标记）的黄金标准标注句子，并额外提供了100万的银标准句子，从理论和实践两个层面提升在线语料库的有效性和可用性", "conclusion": "UD-English-CHILDES树库是首个官方发布的结合了黄金标准和银标准句子的通用依赖句法树库，为儿童语言交互的研究提供了统一且全面的资源，有助于提高语言学和计算语言学领域的研究精度与广度"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12705", "html_url": "https://arxiv.org/abs/2505.12705", "title": "DreamGen: 通过视频世界模型解锁机器人学习中的泛化能力", "title_en": "DreamGen: Unlocking Generalization in Robot Learning through Video World Models", "authors": "Joel Jang,Seonghyeon Ye,Zongyu Lin,Jiannan Xiang,Johan Bjorck,Yu Fang,Fengyuan Hu,Spencer Huang,Kaushil Kundalia,Yen-Chen Lin,Loic Magne,Ajay Mandlekar,Avnish Narayan,You Liang Tan,Guanzhi Wang,Jing Wang,Qi Wang,Yinzhen Xu,Xiaohui Zeng,Kaiyuan Zheng,Ruijie Zheng,Ming-Yu Liu,Luke Zettlemoyer,Dieter Fox,Jan Kautz,Scott Reed,Yuke Zhu,Linxi Fan", "background": "当前的研究主要集中在通过神经轨迹生成合成数据来训练机器人的策略，以实现跨行为和环境的泛化能力。然而，这些方法通常依赖于手动收集数据，效率低下。本文介绍了一种简化且高效的四阶段流水线DreamGen，它利用最先进的图像到视频生成模型，通过生成合成视频来训练机器人策略。这些合成视频用于创建合成的机器人数据，进而训练机器人在多元化环境中执行新的行为。", "innovation": "DreamGen的主要创新点在于：1）利用最先进的图像到视频生成模型，并将其适应目标机器人实体，以生成逼真的合成视频。2）通过使用潜在动作模型或逆运动学模型从生成的视频中恢复伪动作序列。3）DreamGen仅需要单个任务的少量示例数据即可在多种环境中实现强大的泛化能力。此外，引入了DreamGen Bench用于系统性地评估该流水线，展示了基准性能与下游策略成功之间的强关联性。这一工作为扩展机器人学习设定了一个新的轴线，远远超出手动数据收集。", "conclusion": "总的来说，DreamGen通过使用视频世界模型生成合成数据，在简化且高效的框架下实现了跨行为和环境的光谱泛化。通过DreamGen Bench的验证，已经证实了该方法的有效性和可靠性。团队的研究为机器人学习的发展提供了新的方向，有望大幅提升机器人的适应性和灵活性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12992", "html_url": "https://arxiv.org/abs/2505.12992", "title": "断裂链式推理", "title_en": "Fractured Chain-of-Thought Reasoning", "authors": "Baohao Liao,Hanze Dong,Yuhui Xu,Doyen Sahoo,Christof Monz,Junnan Li,Caiming Xiong", "background": "推理时的扩展技术大幅增强了大语言模型（LLMs）的推理能力，而无需重新训练，进一步利用额外的计算资源。链式思考（CoT）提示及其扩展形式长链式思考能通过生成丰富的中间推理轨迹来提高准确性，但在延迟敏感的场景中由于大量的令牌开销而受到影响。该研究首先展示了断言CoT（在推理完成前停止，并直接生成最终答案）通常在使用更少令牌的情况下与完整的CoT采样结果相当。", "innovation": "该研究提出了统一的推理时策略——断裂采样（Fractured Sampling），它可以沿三个维度在全CoT采样和仅解采样之间进行平滑转换：(1) 推理轨迹的数量；(2) 每条轨迹的最终解的数量；(3) 推理轨迹截断的深度。通过在五个不同的推理基准测试和多种模型规模上进行广泛实验，研究发现断裂采样在准确性和成本之间提供了更优的平衡，展现出陡峭的对数线性规模增益。研究表明在这些维度上分配计算资源以最大化性能的方法，为大语言模型推理提供了更高效和可扩展的方案。", "conclusion": "该研究表明，在这些维度上分配计算资源以最大化性能，为大语言模型推理提供了更高效和可扩展的方案。研究还发现断裂采样在准确性和成本之间提供了更优的平衡，极大提升了推理效率。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13346", "html_url": "https://arxiv.org/abs/2505.13346", "title": "J4R：使用等价初始状态组相对策略优化学习评判", "title_en": "J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization", "authors": "Austin Xu,Yilun Zhou,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty", "background": "为了跟上大型语言模型（LLM）快速发展的步伐，模型输出评估已从耗时的人类评估转变为自动评估，其中LLM自身被用于评估和批判其他模型的输出。然而，现有的LLM评估模型在处理复杂推理领域时效果不佳，因为它们难以处理包含更具实质性挑战性内容的模型响应。为了解决现有评估模型的不足，本研究探索了使用强化学习（RL）训练评估模型的方法。", "innovation": "本研究的主要创新之处在于：(1) 提出了等价初始状态组相对策略优化（EIS-GRPO）算法，以使评估模型能够应对更复杂的评估环境中的位置偏见；(2) 引入了ReasoningJudgeBench评估基准，该基准涵盖了以前未涉及的各种推理场景；(3) 使用EIS-GRPO训练了Judge for Reasoning (J4R) 7B模型，该模型在性能上超过了GPT-4o以及其他小型评估模型，且在两个评估基准上表现与大型PGRO训练的评估模型相当或更好。", "conclusion": "J4R通过EIS-GRPO算法训练，不仅在复杂推理任务上表现优越，而且在性能上较其他小型评估模型具有6.7%至9%的显著提升，展示了使用强化学习训练评估模型的有效性和潜力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14719", "html_url": "https://arxiv.org/abs/2505.14719", "title": "MSVIT: 使用多尺度注意力融合改进的脉冲视觉变换器", "title_en": "MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion", "authors": "Wei Hua,Chenlin Zhou,Jibin Wu,Yansong Chua,Yangyang Shu", "background": "由于脉冲神经网络（SNNs）与视觉变换器架构结合在节能和高性能计算方面的潜力，这两种架构的结合已经引起了广泛关注。然而，基于SNN的变压器架构与基于人工神经网络（ANN）的变压器架构之间仍然存在显著的性能差距。现有的方法虽然提出了结合SNN的脉冲自我注意机制，但这些方法所提出的整体架构在从不同图像尺度中有效提取特征方面存在瓶颈。", "innovation": "本文提出了一种名为MSVIT的新型脉冲驱动变换器架构，首先使用多尺度脉冲注意力（MSSA）以增强脉冲注意力块的能力。实验结果表明，MSVIT在各种主要数据集上的性能优于现有的SNN基模型，确立了其在SNN-变压器架构中的最先进的解决方案。", "conclusion": "MSVIT在多种主要数据集上的实验结果表明，它在SNN-变压器架构中表现出最先进的性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17830", "html_url": "https://arxiv.org/abs/2505.17830", "title": "Imagine Beyond! Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning", "title_en": "Imagine Beyond! Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning", "authors": "Nicolas Castanet,Olivier Sigaud,Sylvain Lamprier", "background": "目标条件强化学习(GCRL)能够使代理自主获取多样化的行为，但在视觉环境中面临高维度和语义稀疏观察带来的重大挑战。在线设置中，代理学习表示的同时探索，潜在空间随代理策略的演化而演变，以捕捉新发现的环境区域。然而，在缺乏最大化表示中状态覆盖激励的情况下，基于自编码器的经典方法可能会收敛到过度代表代理频繁访问的受限状态集合的潜在空间。这种问题在使用潜在空间中编码分布来采样其学习掌握的目标的内在动机设置中更加突出。为了解决这一问题，本文提出逐步强制分布向整个状态空间的均匀分布转变，以确保全面覆盖在环境中可以学习的技能。", "innovation": "本文引入了DRAG（分布鲁棒自编码）方法，结合了$\beta$-VAE框架和分布鲁棒优化。DRAG利用了对自编码器训练状态的对抗神经加权来考虑当前数据分布与环境中未见部分之间的不匹配，从而使代理能够构建超越其即时经验的语义有意义的潜在空间。该方法在迷宫和涉及绕过墙壁的机器人控制等具有挑战性的探索环境中提高了状态空间覆盖和下游控制性能，无需预训练或先验环境知识。", "conclusion": "DRAG方法通过逐步强制分布向均匀分布转变，确保了在环境中可以学习的所有技能的全面覆盖，从而改善了状态空间的覆盖范围和下游控制性能，在迷宫等环境类型上得到了验证，展示了该方法的有效性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18440", "html_url": "https://arxiv.org/abs/2505.18440", "title": "在小型语言模型中高效进行长链推理", "title_en": "Efficient Long CoT Reasoning in Small Language Models", "authors": "Zhaoyang Wang,Jinqi Jiang,Tian Qiu,Hui Liu,Xianfeng Tang,Huaxiu Yao", "background": "近年来，大型推理模型如DeepSeek-R1展示了通过生成长链条的推理步骤来解决复杂问题的强大能力。然而，直接训练小型语言模型（SLMs）来产生长链条的推理步骤是有挑战性的。因此，知识蒸馏成为一种实用方法，以使SLMs具备这种推理能力。然而，这些长的推理步骤通常包含许多冗余内容（例如过度思考的步骤），这可能使得SLMs难以学习，因为他们的容量和泛化能力相对较弱。", "innovation": "本文提出了一种简单而有效的修剪方法来消除长推理步骤中的不必要的步骤，然后利用一种基于策略的方法，为SLMs本身制定有效的和有用的长推理步骤训练数据。这种训练数据使SLMs能够有效地学习有效的长推理步骤，并保持竞争力。实验结果表明，在一系列数学推理基准测试中，所提出的方法在蒸馏长链条推理能力进入SLMs时，保持了竞争力但显著减少了生成冗余推理步骤。", "conclusion": "本文通过提出一种简单而有效的修剪方法和基于策略的方法，成功地将长链推理能力从大型推理模型转移到小型语言模型中，保持了模型的竞争力同时显著减少了冗余推理步骤的生成。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18787", "html_url": "https://arxiv.org/abs/2505.18787", "title": "Think Twice before Adaptation: Improving Adaptability of DeepFake Detection via Online Test-Time Adaptation", "title_en": "Think Twice before Adaptation: Improving Adaptability of DeepFake Detection via Online Test-Time Adaptation", "authors": "Hong-Hanh Nguyen-Le,Van-Tuan Tran,Dinh-Thuc Nguyen,Nhien-An Le-Khac", "background": "深度伪造（DF）检测器在实际应用环境中面临着重大挑战，特别是在处理与训练数据分布不一致或经过后处理修改的测试样本时。这些后处理技术和分布转移使得深度伪造样本中的生成特征变得难以识别，从而导致检测器性能的下降。", "innovation": "本文提出了双重考虑的在线测试时适应方法（\texttt{T$^2$A}），这是一种新颖的在线测试时间适应方法，能够在推理过程中增强检测器的适应性，而无需访问源训练数据或标签。该方法通过不确定性感知的负学习目标，使模型能够探索替代选项，而不是像基于熵最小化的（EM）方法那样仅依赖于初始预测。此外，还引入了不确定样本优先策略和梯度屏蔽技术，以通过关注重要样本和模型参数来改进适应性。", "conclusion": "理论分析表明，提出的负学习目标与EM表现出互补行为，有助于适应能力的提升。实验证明，本方法在现有的测试时适应（TTA）方法中实现了最佳结果，并显著增强了深度伪造检测器在推理过程中的鲁棒性和泛化能力。源代码可以在提供的链接中获取。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18799", "html_url": "https://arxiv.org/abs/2505.18799", "title": "ALPS: 注意聚焦和剪枝策略以提高大型语言模型集成效率", "title_en": "ALPS: Attention Localization and Pruning Strategy for Efficient Alignment of Large Language Models", "authors": "Hao Chen,Haoze Li,Zhiqing Xiao,Lirong Gao,Qi Zhang,Xiaomeng Hu,Ningtao Wang,Xing Fu,Junbo Zhao", "background": "在对通用的大规模语言模型（LLMs）进行下游任务对齐时，往往需要承担显著的训练调整成本。前期研究探索了多种提高对齐效率的方法，主要通过最小数据训练或数据驱动激活来识别关键注意力头，但这些方法不可避免地引入了数据依赖性，这妨碍了泛化能力和重用性。为解决这一问题，提升模型对齐效率，作者提出了一种高效的算法——注意力聚焦与剪枝策略（ALPS），该策略通过定位最任务敏感的注意力头并限制注意力训练更新到这些头，从而降低对齐成本。实验证明，该方法在微调过程中仅激活10%的注意力参数，同时在三个任务上比基线方法提高了2%的性能，且识别出的任务特定头部在不同数据集上具有可转移性，减少了知识遗忘。这项工作和发现提供了一种新的大规模语言模型集成效率视角。代码可以在下列链接下载：this https URL", "innovation": "ALPS是一种提高大规模语言模型任务对齐效率的创新策略。它通过定位最任务敏感的注意力头并限制注意力训练的更新范围，从而减少了对齐的计算成本，且识别出的任务特定头部在不同数据集上具有可转移性，减少了知识遗忘。", "conclusion": "ALPS的研究结果表明，通过仅激活10%的注意力参数，该方法在三个任务上比基线方法实现了2%的性能提升。此外，确定的任务特定头部在不同数据集上具有可转移性，减少了知识遗忘。这项工作提供了大规模语言模型对齐的一个新视角。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21569", "html_url": "https://arxiv.org/abs/2505.21569", "title": "ChemHAS: 合成代理堆叠以增强化学工具", "title_en": "ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools", "authors": "Zhucong Li,Bowei Zhang,Jin Xiao,Zhijian Zhou,Fenglei Cao,Jiaqing Liang,Yuan Qi", "background": "大语言模型（LLM）-基于的代理已经展示了在化学相关任务中选择合适工具以提高性能的能力。然而，它们的有效性仍然受到化学工具固有的预测误差的限制。这项研究旨在进一步探索如何利用LLM-基于的代理来减少这些工具的预测误差，通过从有限数据中优化代理堆叠结构来增强化学工具。为此，论文提出了ChemHAS（化学层次代理堆叠），一种简单而有效的增强化学工具的方法，实现了四项基本化学任务的最新性能。这表明该方法能够有效地弥补工具的预测误差，并识别和表征四种不同的代理堆叠行为，可能提高可解释性并显示AI代理在科学研究中的新应用可能性。相关代码和数据集均已公开可用。", "innovation": "论文提出了ChemHAS（化学层次代理堆叠），一种能通过从有限数据优化代理堆叠结构来增强化学工具的方法，从而实现四个基本化学任务的最新性能。此外，该研究还识别并表征了四种不同的代理堆叠行为，为AI代理在科学研究中的应用提供了新的可能性。", "conclusion": "ChemHAS方法能够有效补偿化学工具的预测误差，提升了四项基本化学任务的性能。同时，该研究还揭示了四种不同的代理堆叠行为，有助于提高AI代理在科学界的应用解释性。相关代码和数据集已公开。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24765", "html_url": "https://arxiv.org/abs/2505.24765", "title": "量子位到企业应用的监督量子机器学习未来展望", "title_en": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications", "authors": "Srikanth Thudumu,Jason Fisher,Hung Du", "background": "监督量子机器学习（QML）是一种结合量子计算和经典机器学习的技术，旨在利用量子资源支持模型的训练和推理。近年来，监督QML的研究取得了进展，涉及变量子电路、量子神经网络和量子核方法等方法，同时提出了一些混合量子-经典工作流。这些研究展示了一些量子优势的初步迹象，但也指出了诸如噪声、值枯竭、可扩展性问题和对性能改进的正式证明缺乏等当前限制。", "innovation": "该研究回顾了过去十年中监督量子机器学习的技术进展，特别关注变量子电路、量子神经网络和量子核方法等方法，同时强调提出了下十年的展望规划，描述了未来十年监督量子机器学习可能的发展路径以及哪些情况下量子机器学习可以在应用研究和企业系统中被使用。", "conclusion": "未来十年，监督量子机器学习有可能在实际应用和企业系统中得到广泛应用。然而，当前仍存在一些技术和实践限制，如量子噪声、值枯竭等问题需要进一步解决，并且需要更多的实验和理论支持来证明其相对于经典方法的优势。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04265", "html_url": "https://arxiv.org/abs/2506.04265", "title": "CORA：多智能体策略梯度中的联盟理性优势分解", "title_en": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "authors": "Mengda Ji,Genjiu Xu,Liying Wang", "background": "该研究聚焦于合作多智能体强化学习（MARL）中的信用分配问题。现有方法通常难以公正地分配全局优势，导致智能体贡献的不同被忽视，从而影响策略更新的最优化。尽管已经提出了一些综合考虑全局或个体贡献的方法，但在联盟层面的详细分析仍然较为缺乏。因此，该论文从联盟视角分析了多智能体策略更新中的过度更新问题，旨在提出一种新的信用分配方法，以提高MARL的性能。通过实验证明，该方法在多个场景下均优于现有基准方法，特别是在存在多个局部最优解的任务中表现出色。", "innovation": "本文提出了一种称为Coalitional Rational Advantage Decomposition（CORA）的信用分配方法，从联盟层面评估边际贡献并对优势进行分解，确保联盟理性。通过引入随机联盟采样来降低计算开销。CORA方法在多个游戏任务和多智能体协作基准任务中表现出色，特别是在处理多个局部最优解的任务中有显著优势。", "conclusion": "实验证明，CORA方法对于提高MARL性能至关重要。通过考虑联盟层面的贡献计算，能够更好地引导策略更新，从而提高学习效果。该研究强调了联盟感知信用分配对于提高MARL性能的重要性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06561", "html_url": "https://arxiv.org/abs/2506.06561", "title": "LaMP-Cap: 图像个人化图例生成", "title_en": "LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles", "authors": "Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang", "background": "图例对于帮助读者理解并记住图表的关键信息至关重要。许多模型已经开发出来生成这些图例，帮助作者更轻松地创作高质量的图例。然而，作者通常需要修改AI生成的通用图例，以适应其写作风格和领域风格，这突显了个性化的需求。尽管语言模型在个人化方面取得了进展，但这些技术通常集中在纯文本文档上，很少解决涉及多模态输入和配置文件的场景。", "innovation": "本文提出了LaMP-Cap数据集，用于多模态图配置文件下的个性化图例生成。对每个目标图表，LaMP-Cap不仅提供了所需的输入图像，还包括来自同一文档的最多三个其他图表及其图像、图例和提及图的段落，用作配置文件来描述上下文。实验表明，使用配置文件信息可以更接近原作者的手写图例。消融研究显示，配置文件中的图像比提及图的段落更 helpful，突显了使用多模态配置文件相对于纯文本文档配置文件的优势。", "conclusion": "使用的配置文件信息的一致性有助于生成更接近原作者手写的图例。配置文件中的图像比提及图的段落更helpful，突显了使用多模态配置文件的优势。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06955", "html_url": "https://arxiv.org/abs/2506.06955", "title": "BIS Reasoning 1.0: 日本第一个评估信念不一致演绎推理的大规模基准", "title_en": "BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning", "authors": "Ha-Thanh Nguyen,Chaoran Liu,Koichi Takeda,Yusuke Miyao,Pontus Stenetorp,Qianying Liu,Su Myat Noe,Hideyuki Tachibana,Sadao Kurohashi", "background": "目前，大多数大规模语言模型（LLMs）的数据集主要关注一般性或信念一致的推理问题。之前的研究，如NeuBAROCO和JFLD，侧重于此类问题。然而，BIS Reasoning 1.0引入了逻辑有效但信念冲突的命题，旨在检测LLMs在处理人类对齐数据训练时的推理偏差。这一背景强调了在评估LLMs时引入这种类型的数据的重要性，特别是在法律、医疗和科学文献等高风险领域，必须以真理为唯一标准来确保公正与安全性。", "innovation": "BIS Reasoning 1.0是首个专门设计用于评估LLMs在处理信念不一致的推理问题上的性能的大规模日语数据集。该数据集包含逻辑上有效的但与信念冲突的演绎推理题目，与以往主要基于一般或信念一致推理数据集的研究不同，填补了这一研究空白。", "conclusion": "通过BIS Reasoning 1.0，研究者发现在处理逻辑有效但信念冲突的输入方面，现有的LLMs具有明显的局限性。这些发现对LLMs在法律、医疗、科学文献等高风险领域的应用具有重要意义，必须以真理为准绳来确保公正性和安全性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08010", "html_url": "https://arxiv.org/abs/2506.08010", "title": "视觉变换器不需要训练过的注册标记", "title_en": "Vision Transformers Don't Need Trained Registers", "authors": "Nick Jiang,Amil Dravid,Alexei Efros,Yossi Gandelsman", "background": "研究发现，在视觉变换器（Vision Transformers）中存在一种已知现象，特定的高范数标记会导致嘈杂的注意力图。这些特定标记的激活是由稀疏的神经元集中在异常标记上，导致不规则的注意力模式，进而影响下游的视觉处理效果。目前，解决这个问题的方法是通过从头重建模型并加入额外学习的注册标记。本文在此基础上，利用新的发现提出了一种无需训练的解决方法，通过将高范数激活转移到未训练的额外标记上，模拟已有注册标记的模型效果，从而提高视觉任务的性能，并达到与训练了注册标记模型相当的效果。此外，还将测试时的注册标记应用于视觉-语言模型，以提高其可解释性。研究表明，测试时的注册标记可以有效替代训练过的注册标记，提供一个无需训练的解决方案，适用于任何未包含注册标记的预训练模型。", "innovation": "论文提出了一种无需训练的解决方法，通过将高范数激活转移到未训练的额外标记上，模拟已有注册标记的模型效果，从而提高视觉任务的性能，并达到与训练了注册标记模型相当的效果。此外，论文还将测试时的注册标记应用于视觉-语言模型，以提高其可解释性。", "conclusion": "测试时的注册标记可以有效替代训练过的注册标记，提供一个无需训练的解决方案，适用于任何未包含注册标记的预训练模型。该方法能产生更清洁的注意力和特征图，提高多种下游视觉任务的性能，并达到与训练了注册标记模型相当的结果。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09033", "html_url": "https://arxiv.org/abs/2506.09033", "title": "Router-R1：通过强化学习教给大规模语言模型多轮路由和聚合", "title_en": "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning", "authors": "Haozhen Zhang,Tao Feng,Jiaxuan You", "background": "大规模语言模型（LLMs）的迅速发展推动了LLM路由器的研究，这些路由器能够将用户的查询分配给最适合的模型。然而，现有的LLM路由器通常采用单轮一对一映射的方式（即，隔离地将每个查询分配给单一模型），这种方式限制了它们处理需要多个LLM互补优势的复杂任务的能力。", "innovation": "提出了一个基于强化学习（RL）的框架Router-R1，将多LLM路由和聚合过程建模为一个顺序决策过程。Router-R1将路由器本身实现为一个有能力的LLM，利用其推理能力交错执行‘思考’动作（内部思考）与‘路由’动作（动态模型调用），并将每个响应集成到不断演变的上下文中，通过一系列简单的模型描述符（如定价、延迟和示例性能）进行条件设置，以实现强大的未见过的新模型选择的泛化能力。", "conclusion": "在七个通用和多跳问答基准测试上的实验表明，Router-R1在多个强baseline中表现出色，不仅提供了卓越的性能而且保持了鲁棒的泛化和成本管理。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09099", "html_url": "https://arxiv.org/abs/2506.09099", "title": "超出思考范围：预训练Transformer模型的容量、记忆和泛化", "title_en": "Too Big to Think: Capacity, Memorization, and Generalization in Pre-Trained Transformers", "authors": "Joshua Barron,Devin White", "background": "大规模语言模型（LLMs）的存储和泛化关系研究是一个开放的研究领域，已有研究显示这两个方面是紧密相关的。本文通过从零开始预训练一系列容量有限的Transformer模型，分别探究泛化（通过算术外推）和记忆（通过事实召回）不同的合成字符级任务，来进一步研究这种关系。研究表明，小模型可以在未见过的算术实例上进行外推，但未能记忆事实；而大模型善于记忆事实但难以进行外推。中间容量的模型也表现出类似的趋势。当两种任务联合训练时，没有任何模型，不论大小，能够在泛化上表现出色.", "innovation": "通过设计特定的合成任务并分别评估泛化和记忆能力，本文首次揭示了预训练容量有限的Transformer模型中存储和泛化的内在倾向性。研究结果表明，预训练可能天然偏向于一种学习模式而不是另一种。此项研究通过控制环境下的分离分析，提供了关于模型能力如何塑造学习行为的见解，并提出了开发和部署小型语言模型时具有更广泛意义的推论.", "conclusion": "此研究发现，预训练可能会影响模型对于存储和泛化的能力偏向，容量有限的模型更偏向于记忆而非外推，而大型模型则反之。当同时进行两个任务的训练时，没有模型能在泛化上取得成功。这些发现进一步强调了理解不同容量模型的学习偏向性对模型设计和部署的重要性."}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09183", "html_url": "https://arxiv.org/abs/2506.09183", "title": "基于人类评分的多任务奖励学习", "title_en": "Multi-Task Reward Learning from Human Ratings", "authors": "Mingkang Wu,Devin White,Evelyn Rose,Vernon Lawhern,Nicholas R Waytowich,Yongcan Cao", "background": "强化学习从人类反馈（RLHF）成为实现模型行为与用户目标一致的关键因素。然而，当前的RLHF方法通常通过分类或回归等孤立任务来简化人类在决策时整合多种策略的过程。", "innovation": "本文提出了一种新颖的强化学习（RL）方法，通过联合考虑多个任务模拟人类决策过程。具体而言，该方法通过在无奖励环境中利用人类的评分来推断奖励函数，并引入可学习的权重来平衡分类和回归模型的贡献，从而捕捉人类决策中的固有不确定性，并使模型能够适应性地强调不同的策略。这种方法通过合成人类评分进行了多次验证，结果表明该方法在多个方面优于现有的基于评分的RL方法，甚至在某些情况下超过了传统的RL方法。", "conclusion": "我们的方法在多个实验中表现优于现有的基于评分的RL方法，展示了其在平衡分类和回归模型贡献方面的优势。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09331", "html_url": "https://arxiv.org/abs/2506.09331", "title": "多智能体语言模型：促进合作、协调与适应", "title_en": "Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation", "authors": "Arjun Vaithilingam Sudhakar", "background": "现代大规模语言模型（LLMs）在跨复杂数字语言任务上展现出惊人的零样本和少样本泛化能力，使其能够广泛应用于各种虚拟助手角色，例如翻译和概括。尽管这些模型仅被训练于大规模文本语料而未明确监督作者意图，它们似乎能够推断文本交互的深层含义。这一现象引发了一个根本问题：LLMs是否能够建模并推理他人的意图，即它们是否具备某种形式的“心理理论”？理解他人的意图对于有效的协作至关重要，这是人类社会成功的核心，并且对于多智能体之间的协作——包括人类和自主系统——也是必不可少的能力。", "innovation": "本文通过多智能体强化学习（MARL）的视角研究LLMs的心理理论，让智能体通过反复互动学习合作，类似于人类的社会推理。通过利用基于LLM的能够进行自然语言交互的智能体，提出了构建人机混合系统的方法，旨在增强人工代理适应和与人类伙伴合作的能力。", "conclusion": "通过这种方式，我们朝着创建能够实现无缝合作的混合人机系统迈进，对未来的长远人机互动具有广泛影响。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09507", "html_url": "https://arxiv.org/abs/2506.09507", "title": "TransXSSM：具有统一旋转位置嵌入的混合变换器状态空间模型", "title_en": "TransXSSM: A Hybrid Transformer State Space Model with Unified Rotary Position Embedding", "authors": "Bingheng Wu,Jingze Shi,Yifan Wu,Nan Tang,Yuyu Luo", "background": "变换器在捕捉长程依赖关系方面表现出色，而状态空间模型（SSMs）则有助于线性时序建模。虽然这两种架构具有协同潜力，但它们在位置编码机制上的差异（变换器依赖旋转位置嵌入（RoPE），而SSMs使用通过卷积实现的隐式位置表示）使得它们的结合变得困难，引发了不连续性和次优性能的问题。为解决这一问题，我们提出了一种统一的旋转位置嵌入（Unified RoPE）方法，从而为自注意力和状态空间组件提供了统一的位置编码框架。基于Unified RoPE，我们引入了结合了变换器和SSM层的TransXSSM混合架构。实验结果表明，在序列长度为4时，TransXSSM的训练和推理速度分别比标准变换器模型快42.3%和29.5%，并且在语言模型任务上也表现出更高的准确性。此外，TransXSSM在扩展性方面也更有效：1.3B版本比320M版本提高了7.22%的平均准确率，超过同等规模的变换器或SSMs的约6%的提高幅度。", "innovation": "我们提出了一种新的方法叫统一旋转位置嵌入（Unified RoPE），将变换器和状态空间模型相结合，创建了一个混合架构TransXSSM。这种方法解决了两者在位置编码上的不兼容问题，使得混合模型能够有效地实现高效的长上下文建模。TransXSSM比标准的变换器模型更快，并且在语言建模任务上也表现得更好。此外，TransXSSM还能够更有效地进行扩展，表现出更强的扩展性。", "conclusion": "统一对位置编码的解决方案使得变换器和状态空间模型的结合成为一个可行的方法，适用于高效和高性能的长上下文模型开发。TransXSSM相较于标准的变换器模型具有更快的速度和更高的准确性，并且在扩展模型规模时还能保持良好的性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11058", "html_url": "https://arxiv.org/abs/2506.11058", "title": "通过库设计重构代码库", "title_en": "Refactoring Codebases through Library Design", "authors": "Ziga Kovacic,Celine Lee,Justin Chiu,Wenting Zhao,Kevin Ellis", "background": "可维护且通用的软件能够帮助开发者高效地构建稳健的应用程序，但这种高质量通常需要将专业的解决方案重新组织成可重用的组件。随着代码代理在解决独立编程问题方面变得越来越精确，这个问题显得尤为重要。本研究探讨了代码代理的能力，使其能够以支持增长和重用的方式重构代码。研究中采用了一种方法和一个基准：Librarian，一种用于生成可重用库的采样和重新排名方法，以及Minicode，一个基准测试，其中代码代理必须对多个独立解决方案进行最小化和重构，聚合到一个共享库中。相较于最先进的代码代理，Librarian在Minicode上的压缩率和正确性表现更好，其压缩率提高了1.6-2倍，并且提高了正确性。研究者开源了他们的代码和基准测试数据，网址为 this https URL 。", "innovation": "研究提出了Librarian方法，一种生成可重用库的采样和重新排名方法，以及Minicode基准测试。Librarian能够在保持代码正确性的同时实现更强的压缩率，优于现有最先进的代码代理。此外，开源了这一研究的代码和基准测试，以推动相关技术的发展和应用。", "conclusion": "本研究通过库设计支持代码重构，验证了这种方法在生成更可重用库方面的强大能力。相比最先进的代码代理，该方法在压缩率和正确性上都表现优秀，这为开发高效、可维护的代码库提供了新的启示。开源代码和基准测试将有助于进一步的研究和应用开发。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11302", "html_url": "https://arxiv.org/abs/2506.11302", "title": "TARDIS STRIDE: 时空道路图像数据集和自主世界模型", "title_en": "TARDIS STRIDE: A Spatio-Temporal Road Image Dataset and World Model for Autonomy", "authors": "Héctor Carrión,Yutong Bai,Víctor A. Hernández Castro,Kishan Panaganti,Ayush Zenith,Matthew Trang,Tony Zhang,Pietro Perona,Jitendra Malik", "background": "世界模型旨在模拟环境并使智能体行为更有效。然而，模型真实世界环境存在独特挑战，因为这些环境在空间和时间上都会动态变化。为捕捉这些复杂的时空动态，引入了时空道路图像数据集（STRIDE），通过将360度全景图像转换为丰富的相互连接的观察、状态和动作节点来解决这些问题。利用此结构，可以同时建模视角、位置坐标和运动指令之间的关系，跨越空间和时间。通过TARDIS（基于变压器的生成世界模型），在STRIDE上进行统一的自回归框架训练，整合空间和时间动态。该方法在多种智能体任务中表现出稳健的性能，如可控的光逼真图像合成、指令遵循、自主自我控制和最先进的地理参考。这些结果表明了向复杂通用智能体发展的有希望的方向——具有更强的环境理解与操控能力的智能体，能够理解和操作其物质环境的时空特性。\n", "innovation": "引入了时空道路图像数据集（STRIDE），通过360度全景图像转换为丰富的相互连接的观察、状态和动作节点来解决动态环境挑战。利用此结构，通过TARDIS（基于变压器的生成世界模型）进行统一的自回归框架训练，整合空间和时间动态，并在多种智能体任务中表现出稳健的性能。\n", "conclusion": "TARDIS STRIDE展示了在复杂智能体任务中具有潜在应用的技术，其能够理解和操控环境的时空特性，并且在光逼真图像合成、指令遵循、自我控制和地理参考等任务中表现出优越性能。研究成果已公开训练代码、数据集和模型权重。\n"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12542", "html_url": "https://arxiv.org/abs/2506.12542", "title": "PLD：一种基于选择理论的列表级知识蒸馏", "title_en": "PLD: A Choice-Theoretic List-Wise Knowledge Distillation", "authors": "Ejafa Bassam,Dawei Zhu,Kaigui Bian", "background": "知识蒸馏是一种模型压缩技术，其中一个小巧的“学生”网络被训练以复制一个更大的“教师”网络的预测行为。在基于逻辑的知识蒸馏中，它已成为用蒸馏项补充交叉熵的有效方法。传统的蒸馏项通常是KL散度匹配边缘概率或者基于相关性的损失捕捉类内的关系和类间的关系，但无论哪种情况，都需要在交叉熵的基础上另外调整权重，这需要仔细调整。本文从决策理论的角度出发，将知识蒸馏重新构建在Plackett-Luce模型之下，将教师的逻辑视为“价值”分数。Plackett-Luce蒸馏(PLD)是一种加权的列表级排序损失，其中教师模型传递其对全部类别的完全排名的知识，每个排名选择由其自身的信心加权。", "innovation": "PLD直接优化了教师最优的真实标签的单个排名，然后按教师信心递减排列其他类别，生成一个凸的、平移不变的代理，该代理涵盖了加权交叉熵。实验结果显示，在标准图像分类基准上，PLD在同质设置中分别提高了DIST (arXiv:2205.10536) 和KD (arXiv:1503.02531)方法的Top-1精度0.42%和1.04%，在异质设置中分别提高了0.48%和1.09%。", "conclusion": "PLD是一种基于选择理论的知识蒸馏方法，通过教师的逻辑分数传递其对全部类别的完整排名，产生了单个优化目标，优化了教师的最优排名，并且在不同环境下表现出更好的性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12708", "html_url": "https://arxiv.org/abs/2506.12708", "title": "华为CloudMatrix384上的大规模语言模型服务", "title_en": "Serving Large Language Models on Huawei CloudMatrix384", "authors": "Pengfei Zuo,Huimin Lin,Junbo Deng,Nan Zou,Xingkun Yang,Yingyu Diao,Weifeng Gao,Ke Xu,Zhangyu Chen,Shirui Lu,Zhao Qiu,Peiyang Li,Xianyu Chang,Zhengzhong Yu,Fangzheng Miao,Jia Zheng,Ying Li,Yuan Feng,Bei Wang,Zaijian Zong,Mosong Zhou,Wenli Zhou,Houjiang Chen,Xingyu Liao,Yipeng Li,Wenxiao Zhang,Ping Zhu,Yinggang Wang,Chuanjie Xiao,Depeng Liang,Dong Cao,Juncheng Liu,Yongqiang Yang,Xiaolong Bai,Yi Li,Huaguo Xie,Huatao Wu,Zhibin Yu,Lv Chen,Hu Liu,Yujun Ding,Haipei Zhu,Jing Xia,Yi Xiong,Zhou Yu,Heng Liao", "background": "大型语言模型（LLMs）的快速发展，得益于参数规模的不断扩大、混合专家（MoE）架构的采用以及上下文长度的增加，对AI基础设施提出了前所未有的需求。传统AI集群在计算强度、内存带宽、芯片间通信和延迟方面存在局限性，而工作负载的不稳定性进一步加剧了这些问题。解决这些问题需要彻底重新设计硬件和软件的集成。", "innovation": "华为CloudMatrix是一种下一代AI数据中心架构，通过统一总线（UB）网络集成了384个Ascend 910C NPUs和192个Kunpeng CPU，实现了直接的全连接和资源的动态池化，优化了大规模MoE专家并行运算和分布式键值缓存访问。为了充分发挥CloudMatrix384的功能，提出了CloudMatrix-Infer先进LLM服务解决方案，包括：点对点服务架构，支持预填充、解码和缓存独立扩展；大规模专家并行策略，利用基于UB的令牌分发支持EP320；硬件感知优化，包括特殊操作符、微批处理管道化和INT8量化。", "conclusion": "通过使用DeepSeek-R1模型进行评估，CloudMatrix-Infer展示了卓越的效率：每个NPU的预填充吞吐量为6,688个令牌/秒和每个NPU的解码吞吐量为1,943个令牌/秒（<50 ms TPOT）。即使在严格的15 ms延迟限制下，它仍能维持每NPU 538个令牌/秒的吞吐量，而INT8量化则保持了模型的跨基准准确性。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13244", "html_url": "https://arxiv.org/abs/2506.13244", "title": "无遗憾学习在敌对资源限制下的表现：只需一个支出计划", "title_en": "No-Regret Learning Under Adversarial Resource Constraints: A Spending Plan Is All You Need!", "authors": "Francesco Emanuele Stradi,Matteo Castiglioni,Alberto Marchesi,Nicola Gatti,Christian Kroer", "background": "研究在线决策问题，在资源受限的情况下，奖励和成本函数可能会敌对地随时间变化。在标准设置中，观察到奖励和成本选择动作之前或之后，受到完全反馈或部分反馈。众所周知，在奖励和成本分布可能任意变化的情况下，实现亚线性遗憾是不可能的。为了解决这一挑战，分析了一个框架，其中学习者由支出计划指导——一个指定各轮预期资源使用顺序的序列。并设计了一种方法，使算法相对于遵循支出计划的基线具有亚线性遗憾。同时，还提供了处理支出计划分布极不平衡情况的鲁棒变体方法。最后，研究了算法与偏离支出计划规范的基准之间的遗憾问题。", "innovation": "设计了（对偶）-泛化方法，使算法相对于遵循支出计划的基线具备亚线性遗憾。关键在于支出计划确保预算在各轮间均匀分布时，算法性能提高。还提供了处理支出计划分布极不平衡情况的算法鲁棒性变体。", "conclusion": "研究了算法与遵守支出计划规范的基准之间的遗憾，结论表明，当支出计划确保预算在各轮间均匀分布时，算法的性能更佳。并提出了处理支出计划分布极不平衡情况的方法。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13300", "html_url": "https://arxiv.org/abs/2506.13300", "title": "Seewo的MLC-SLM提交：挑战约束下的语音推理语言模型经验", "title_en": "Seewo's Submission to MLC-SLM: Lessons learned from Speech Reasoning Language Models", "authors": "Bo Li,Chengben Xu,Wufeng Zhang", "background": "该论文提出了SeeWo在多语言会话语音语言模型挑战（MLC-SLM）竞赛中的系统解决方案，涵盖了自动语音识别（ASR）和带有ASR的说话人聚类（SD-ASR），以及相关的实验数据和结果。", "innovation": "论文引入了一种多阶段的训练管道，通过课程学习、Chain-of-Thought数据增强以及基于可验证奖励的强化学习（RLVR），增强了语音语言模型的推理和自我校正能力。该方法在基准线上实现了显著的进步，特别是在自动语音识别和带有ASR的说话人聚类上表现尤为突出。", "conclusion": "全面的消融研究显示了每个组件的有效性，并在挑战条件下验证了模型的性能。通过这些方法，论文中的最佳系统在评估集上的WER/CER为11.57%，tcpWER/tcpCER为17.67%。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13832", "html_url": "https://arxiv.org/abs/2506.13832", "title": "FrontendBench：一种通过自动评估来评估LLM在前端开发中的基准", "title_en": "FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation", "authors": "Hongda Zhu,Yiwen Zhang,Bing Zhao,Jingzhe Ding,Siyao Liu,Tong Liu,Dandan Wang,Yanan Liu,Zhaojian Li", "background": "现有的前端代码生成基准存在多个关键限制：任务过于简单、测试用例缺乏严谨性、缺乏端到端验证。这些问题阻碍了对模型性能的准确评估。这些现有基准的局限性影响了对前端代码生成能力的全面而实用的评估。", "innovation": "本文提出了一项名为FrontendBench的新基准，由人类和LLM联合开发。FrontendBench基于代码功能对任务进行分类，并引入了交互式测试场景，以提供更全面和实际的前端代码生成能力评估。该基准包括148个精心设计的提示-测试用例对，覆盖五个级别的网络组件，从基本的UI元素到复杂的交互特性。此外，还引入了一种自动评估框架，在沙盒环境中执行生成的代码，并使用预定义的测试脚本评估结果，该框架与专家评估的一致率为90.54%，表明其可靠性高。该基准测试了几种最新的LLM，展示了他们在处理真实世界的前端任务时性能的显著差异，展示了FrontendBench作为可靠和可扩展基准的价值，支持一致性多模态评估，并为未来的前端代码生成研究提供坚实的基础。", "conclusion": "FrontendBench作为一个可靠和可扩展的基准，支持一致性多模态评估，并为未来的前端代码生成研究提供坚实的基础。我们的数据和代码将很快发布。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14168", "html_url": "https://arxiv.org/abs/2506.14168", "title": "VideoMAR：具有连续标记的自回归视频生成", "title_en": "VideoMAR: Autoregressive Video Generatio with Continuous Tokens", "authors": "Hu Yu,Biao Gong,Hangjie Yuan,DanDan Zheng,Weilong Chai,Jingdong Chen,Kecheng Zheng,Feng Zhao", "background": "基于掩码的自回归模型已经在连续空间中展示了强大的图像生成能力，但在视频生成领域的潜力尚未被充分探索。视频自回归模型面临长期序列建模成本高且困难的基本问题，尤其是在时间和空间维度上的效率问题。", "innovation": "提出了VideoMAR，一种基于连续标记的紧凑且高效的仅解码自回归图像到视频模型，通过帧间因果性和空间双向性原则，以及创新性的下一帧扩散损失、时间短到长的课程学习、空间逐步分辨率训练，有效解决了长期序列建模问题。同时，VideoMAR 具有高效率和空间时间外推能力。", "conclusion": "VideoMAR 在 VBench-I2V 基准上超越了先前的最佳方法 (Cosmos I2V)，在参数量、训练数据和 GPU 资源使用上均有显著减少。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14175", "html_url": "https://arxiv.org/abs/2506.14175", "title": "GRAM: 一个生成基础奖励模型用于奖励泛化", "title_en": "GRAM: A Generative Foundation Reward Model for Reward Generalization", "authors": "Chenglong Wang,Yang Gan,Yifu Huo,Yongyu Mu,Qiaozhi He,Murun Yang,Bei Li,Tong Xiao,Chunliang Zhang,Tongran Liu,Jingbo Zhu", "background": "在对大型语言模型（LLMs）进行对齐时，奖励模型起到了关键作用，但通常只用标记的人类偏好数据作为有监督模型进行训练。本研究探索了利用未标记和标记数据训练奖励模型的方法。基于LLMs中的生成模型，开发了一个生成奖励模型，首先通过大规模的无监督学习训练，然后通过监督学习进行微调。通过使用标签平滑技术，实际上优化了正则化对偶排名损失，为训练奖励模型提供了一个新的视角，将生成模型和有监督学习模型统一到同一类训练目标下。这种方法形成的基础奖励模型，其应用范围广泛，只需少量或无进一步微调就可应用于多个任务中。广泛实验表明，该模型在包括响应排名、根据人类反馈进行强化学习以及细调任务适应等多个任务上，能很好地泛化，并显著提高了多种基准模型的表现。", "innovation": "开发了一个生成基础奖励模型（GRAM），通过无监督学习和监督学习相结合的训练方式，采用标签平滑技术优化正则化对偶排名损失。这种方法将生成模型和有监督模型统一到了同一类训练目标下，提高了奖励模型的泛化能力，广泛适用于多个任务，无需大量微调就可提升表现。", "conclusion": "通过Gram模型的开发，提供了一种在无监督和监督学习间切换的方法来训练奖励模型，并成功证明了标签平滑技术优化了正则化对偶排名损失。这些技术为多种任务提供了基础奖励模型，表现出良好的泛化能力，显著提高了几种基准模型的表现。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14540", "html_url": "https://arxiv.org/abs/2506.14540", "title": "与临床优先事项对齐的评估：校准、标签转移和错误成本", "title_en": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs", "authors": "Gerardo A. Flores,Alyssa H. Smith,Julia A. Fukuyama,Ashia C. Wilson", "background": "在临床环境中，基于机器学习的决策支持系统越来越多地被部署，使用概率评分函数来指导和优先处理患者管理决策。然而，广泛使用的准确性和AUC-ROC等评分规则不能充分反映关键的临床优先事项，如校准、分布转移的鲁棒性和不对称错误成本的敏感性。", "innovation": "本文提出了一种系统的但可操作的评估框架，用于选择校准的阈值分类器，该框架明确考虑了类别分布不确定性和通常在临床环境中发现的认知领域成本不对称性。该评估基于Schervish表示理论，特别是导出一种调整后的交叉熵（对数得分）变体，该变体在临床相关类别平衡范围内平均成本加权性能。", "conclusion": "该评估方法易于应用，能够反映出临床部署条件，并旨在优先考虑既具有校准性又对真实世界变化具有鲁棒性的模型。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14625", "html_url": "https://arxiv.org/abs/2506.14625", "title": "大规模语言模型中集体道德推理的概率聚合与目标嵌入优化", "title_en": "Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models", "authors": "Chenchen Yuan,Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci", "background": "大型语言模型（LLMs）已经展示了令人印象深刻的道德推理能力。然而，在面对复杂的多因素道德困境时，它们往往会有所不同。为了应对这些分歧，我们提出了一种框架，该框架将多种LLMs的道德判断综合为一个共同形成的道德判断，从而使偏离公识的模型重新对准。我们的聚合机制将连续的道德可接受性评分（而不仅仅是二元标签）融合成集体概率，并根据模型的可靠性进行加权。对于偏离公义模型，我们使用了目标嵌入优化程序针对道德哲学理论进行微调，以最小化JS散度，同时保留语义完整性和准确性。在大规模社会道德困境数据集上的实验表明，我们的方法构建了稳健的共识并提高了单个模型的准确性。", "innovation": "提出了一种融合多种LLMs道德判断的框架，通过融合连续的道德可接受性评分并采用目标嵌入优化程序进行微调，以最小化JS散度，最终构建了跨多个模型的稳健共识，并提高了个体模型的准确性。", "conclusion": "这些发现突显了数据驱动的道德对齐在多个模型之间的价值及其对未来更安全、更一致的AI系统的潜力。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14634", "html_url": "https://arxiv.org/abs/2506.14634", "title": "用LARGE语言模型对动机驱动的德语开放式调查响应进行编码", "title_en": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "authors": "Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessica Daikeler", "background": "近年来，大型语言模型（LLMs）的发展和应用更加广泛，特别是在调查研究中的使用，包括对开放式问卷回答的分类。由于其语言能力，LLMs 可能成为手动编码和监督机器学习模型预训练的高效替代方案。现有研究大多集中在英语回答或单一的LLM上，涉及非复杂主题，这使得其结果的普适性和与传统方法相比的质量成为未知数。因此，这项研究使用德语数据（用户参与调查的原因）作为例子，探讨不同LLMs在其他情境下对开放式调查响应进行编码的可能性，比较多种最先进的LLM和提示策略，通过人类专家编码评估LLMs的性能。研究表明，不同LLMs之间的整体性能差异巨大，仅通过精细调整的LLM才能达到可接受的预测性能。提示策略的性能差异依赖于所使用的LLM。不同原因类型的分类性能不均等，未进行精细调整时会导致不同的类别分布。研究讨论了这些发现对编码开放式响应的方法研究和实质分析，以及从业者处理或实质分析此类数据的含义。此外，研究指出了研究人员在选择用于开放式响应分类的自动化方法时需要考虑的许多权衡。研究为LLMs如何在调查研究中高效、准确且可靠地应用提供了新的见解，补充了现有研究。", "innovation": "研究使用德语数据（用户参与调查的原因）作为例子，探讨不同LLMs在其他情境下对开放式调查响应进行编码的可能性，比较多种最先进的LLM和提示策略，通过人类专家编码评估LLMs的性能。研究强调了精细调整LLM的重要性，揭示了不同LLM之间及不同提示策略下的性能差异。此外，该研究讨论了在利用LLMs进行开放式回答分类时面临的各种权衡，并补充了关于在何种条件下可以高效利用LLMs的研究。", "conclusion": "这项研究探索了不同LLMs在开放式调查响应编码中的应用，尤其是在德语情境下的可能性。研究表明，不同LLMs和提示策略之间存在显著的性能差异，需要精细调整的LLM才能实现满意的预测性能。这项研究强调了在选择自动化方法进行开放式响应分类时需要考虑的多方面权衡，并为进一步利用LLMs在调查研究中的应用提供了指导。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14665", "html_url": "https://arxiv.org/abs/2506.14665", "title": "利用深度学习实现精确且可扩展的交换相关性", "title_en": "Accurate and scalable exchange-correlation with deep learning", "authors": "Giulia Luise,Chin-Wei Huang,Thijs Vogels,Derk P. Kooi,Sebastian Ehlert,Stephanie Lanius,Klaas J. H. Giesbertz,Amir Karton,Deniz Gunceler,Megan Stanley,Wessel P. Bruinsma,Lin Huang,Xinran Wei,José Garrido Torres,Abylay Katbashev,Bálint Máté,Sékou-Oumar Kaba,Roberto Sordillo,Yingrong Chen,David B. Williams-Young,Christopher M. Bishop,Jan Hermann,Rianne van den Berg,Paola Gori-Giorgi", "background": "密度泛函理论(DFT)是预测分子和材料性质最广泛使用的方法。尽管DFT本质上是对薛定谔方程的精确重构，但实际应用依赖于对未知交换关联(XC)泛函的近似计算。目前大多数XC泛函都是通过储备一套递增复杂的人工设计特征构建的，这些特征在提高准确性的同时会牺牲计算效率。现有近似计算没有一种能够达到化学实验的预测精度，即通常定义为小于1 kcal/mol的误差。", "innovation": "本研究提出了一种基于深度学习的现代XC泛函Skala，它通过从数据中直接学习表示来绕过昂贵的人工设计特征，实现了小分子离解能的化学精度，同时保留了半局域DFT常见的计算效率。训练数据集使用高精度的基于波函数的方法生成，且数据集非常庞大。Skala通过增加涵盖多样化学的额外训练数据，系统地提高了精度。通过纳入少量针对超出离解能量化学的高精度数据，Skala在广泛主族化学上实现了与最佳混合泛函相当的准确性，但代价是计算效率类似半局域DFT。随着训练数据集的继续扩展，Skala预示了增强第一原理模拟预测能力的可能性。", "conclusion": "该研究展示了利用深度学习构建的Skala泛函，通过大数据集的训练实现了化学精度，并在保持计算效率的同时提高了预测能力。未来，随着更多数据的加入，Skala有望进一步提升第一原理模拟的预测性能。"}
{"topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14731", "html_url": "https://arxiv.org/abs/2506.14731", "title": "Ring-lite: 使用C3PO稳定强化学习实现大规模语言模型的可扩展推理", "title_en": "Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs", "authors": "Ling Team,Bin Hu,Cai Chen,Deng Zhao,Ding Liu,Dingnan Jin,Feng Zhu,Hao Dai,Hongzhi Luan,Jia Guo,Jiaming Liu,Jiewei Wu,Jun Mei,Jun Zhou,Junbo Zhao,Junwu Xiong,Kaihong Zhang,Kuan Xu,Lei Liang,Liang Jiang,Liangcheng Fu,Longfei Zheng,Qiang Gao,Qing Cui,Quan Wan,Shaomian Zheng,Shuaicheng Li,Tongkai Yang,Wang Ren,Xiaodong Yan,Xiaopei Wan,Xiaoyun Feng,Xin Zhao,Xinxing Yang,Xinyu Kong,Xuemin Yang,Yang Li,Yingting Wu,Yongkang Liu,Zhankai Xu,Zhenduo Zhang,Zhenglei Zhou,Zhenyu Huang,Zhiqiang Zhang,Zihao Wang,Zujie Wen", "background": "该研究基于公开的Ling-lite模型，这是一个包含168亿参数的模型，其中只有2.75亿个参数被激活。研究团队旨在通过强化学习(Reinforcement Learning, RL)优化该模型，提高其在推理能力方面的效率和稳定性，同时使其能够匹配甚至超过最先进的小型推理模型在复杂基准测试（如AIME、LiveCodeBench、GPQA-Diamond）上表现，而只激活相同模型所需参数量的三分之一。这一目标通过将蒸馏与RL结合起来，并由此产生的联合训练管道来实现，揭示了MoE RL培训中未被记录的挑战。", "innovation": "1. 提出Constrained Contextual Computation Policy Optimization (C3PO)，一种通过算法-系统协同设计来增强训练稳定性和提高计算吞吐量的新方法，用于解决强化学习训练中的优化不稳定问题。\n2. 发现并证明了在RL训练中基于熵损失而不是验证指标选择蒸馏检查点，能获得更好的性能效率trade-offs。\n3. 开发了一个两阶段的训练框架，以协调多域数据整合，解决由使用混合数据集引起的领域冲突，从而优化推理能力。", "conclusion": "通过上述创新，Ring-lite model在保持高性能的同时，显著减小了参数规模，不仅展示了先进推理能力，并且还通过公开提供的模型、数据集和源代码，展现其实用性。"}
