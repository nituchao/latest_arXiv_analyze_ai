{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22056", "html_url": "https://arxiv.org/abs/2506.22056", "title": "多模态轨迹建模的通用检索", "title_en": "Universal Retrieval for Multimodal Trajectory Modeling", "authors": "Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong", "background": "轨迹数据能够捕捉跨多种模态的人类行为和环境状态，这对增强AI代理的能力，特别是在GUI环境中，具有显著潜力。然而，怎样建模轨迹级数据的表示方式在爆炸性的轨迹数据增长中尚未得到系统性的解决。因此，存在一个重要的挑战是，如何有效地建模轨迹级数据以提升代理的性能和效率。为了解决这个问题，作者提出了一个名为GAE-Retriever的多模态检索框架，并且构建了一个统一的代理轨迹语料库(UATD)以及GAE-Bench基准数据集。", "innovation": "该工作的创新在于提出了多模态轨迹检索（Multimodal Trajectory Retrieval），它填补了通用检索与基于代理的轨迹建模之间的空白。通过提出GAE-Bench基准数据集和集成视觉-语言模型的GAE-Retriever框架，该研究有效地解决了轨迹级数据建模问题，并通过优化对比学习机制，展示了在多个数据集上的优越性能。", "conclusion": "综合评估多个数据集的结果表明，GAE-Retriever在检索召回率上持续超越强基线，表明其在推进多模态轨迹检索方面效果显著。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22068", "html_url": "https://arxiv.org/abs/2506.22068", "title": "查询即测试：一种集成驾驶舱-车辆-道路场景的智能驾驶测试与数据存储方法", "title_en": "Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios", "authors": "Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang", "background": "人工智能（AI）在交通运输领域的深度应用推动了智能驾驶舱、自动驾驶和智能道路网络的快速发展。然而，这三个关键领域的数据生态系统日益碎片化且互不兼容。现有的测试方法依赖于数据堆积，无法覆盖所有边界案例，缺乏灵活性", "innovation": "提出了“查询即测试”（QaT）的概念，从固定的测试案例转向基于统一数据表示的灵活需求逻辑查询。为此，提出了一种基于回答集编程（ASP）的可扩展情景表示（ESN），该框架支持复杂且灵活的语义查询、自然可解释的决策过程，并可通过逻辑规则进行需求的数据抽象，从而实现细致的隐私保护。此外，将功能验证和安全合规检查转化为对ESN数据库的逻辑查询，显著增强了测试的表达能力和形式严谨性", "conclusion": "引入了“验证驱动开发”（VDD）的概念，倡导在大型语言模型时代通过逻辑验证而非定量测试来指导开发，以加速迭代和开发过程"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21887", "html_url": "https://arxiv.org/abs/2506.21887", "title": "软硬边界约束下的交互式多目标概率偏好学习", "title_en": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds", "authors": "Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin", "background": "在高风险决策中，决策者需要在多个竞争目标之间权衡，且每次评估都非常耗资源。例如，在放射治疗中的腔内放疗中，医生需要最大化肿瘤覆盖（如95%以上的覆盖目标）和严格限制器官剂量（如膀胱不能超过601 cGy）。现有的方法缺乏系统化的方法来逐步细化这些复杂的偏好结构，导致决策者难以找到最优方案并信任最终的决策结果。因此，需要一种新的交互式框架来帮助决策者更好地找到最优解并增强其信心。", "innovation": "提出了一个名为Active-MoSH的交互式局部-整体框架。该框架通过局部成分将软硬边界与概率偏好学习结合在一起，以适应性地细化帕累托子集，同时由一个主动采样策略优化探索与开发之间的平衡并减轻认知负担。全局成分T-MoSH利用多目标敏感性分析识别可能被忽视但具有高价值的点，以增加决策者的信任。通过多元合成和现实世界应用展示了Active-MoSH的优势，并通过用户研究验证了框架能够提高收敛性、增强决策者的信任并提供表现力的偏好表达，从而实现更有效的决策。", "conclusion": "Active-MoSH框架能够通过综合软硬边界约束和概率偏好学习，帮助决策者探索帕累托前沿，同时通过优化策略和多目标敏感性分析提高决策效率和信任度，从而在复杂决策场景中找到更有效的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21669", "html_url": "https://arxiv.org/abs/2506.21669", "title": "SEEA-R1：基于树结构强化微调的自进化的体感智能体", "title_en": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents", "authors": "Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang", "background": "在长期的任务规划和现实世界操作等含有多步骤推理的场景中，智能体的自进化（即自主提升其推理和行为的能力）至关重要。目前，强化学习方法中的微调（RFT）虽然在提升大型语言模型（LLM）的推理能力方面表现出色，但在实现能够通过多模态交互自进化的体感智能体方面仍存有很大的未知领域。特别地，强化微调在体感环境中面临两个根本性的难题：（i）在多步骤推理任务中缺乏有效的中间奖励信号限制了有效的学习信号，（ii）依赖手工制作的奖励函数制约了对新任务和环境的通用性。为解决这些问题，本文介绍了一种专为体感智能体的自进化能力而设计的RFT框架SEEA-R1。", "innovation": "本文提出了SEEA-R1框架以及两种关键创新：（1）通过结合蒙特卡洛树搜索（MCST）到分组相对策略优化（GRPO），提出了一种基于树结构的分组相对策略优化（Tree-GRPO），将稀疏的延迟奖励转换为更密集的中间信号，以增强多步骤推理效能。（2）引入了多模态生成奖励模型（MGRM），以实现跨任务和场景的奖励估计的一般性，支持自主适应和奖励驱动的自进化。", "conclusion": "通过ALFWorld基准测试，SEEA-R1在文本和多模态类别上分别达到了85.07%和36.19%的得分，超过了现有最新方法，并成功地在没有环境奖励的情况下达到80.3%的得分，超越了所有开源基线，这表明其作为能够自我进化的体感智能体的可扩展性。此结果进一步支持SEEA-R1在未来可扩展的体感智能研究中的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21734", "html_url": "https://arxiv.org/abs/2506.21734", "title": "层次推理模型", "title_en": "Hierarchical Reasoning Model", "authors": "Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori", "background": "在人工智能领域，推理——设计和执行复杂的目标导向动作序列的过程——仍然是一个关键挑战。当前的大语言模型主要依赖于链式思维技术，但这类方法存在分任务脆弱、大量数据需求和高延迟的局限性。受人类大脑层次化和多时间尺度处理机制的启发，本文提出了一种新颖的递归架构——层次推理模型（HRM），该模型在保持训练稳定性和效率的同时，实现了显著的计算深度。HRM能够通过两个相互依赖的递归模块在单次前向传递中执行序列推理任务，无需显式监督中间过程。", "innovation": "HRM 模型通过两个层递归模块实现层次推理，分别为高层模块负责缓慢、抽象的计划，低层模块处理快速、详细的计算。HRM 使用仅 2700 万个参数，在仅有 1000 个训练样本的情况下，取得了非凡的复杂推理任务表现。这一模型无需预训练和链式思维数据，但在包括复杂数独谜题和大规模迷宫中的最优路径寻找等具有挑战性的任务上达到了近乎完美的表现。此外，HRM 在抽象和推理数据集（ARC）基准测试中表现出色，超越了拥有更长上下文窗口的更大模型，也突显了HRM在通用计算和泛化推理系统方面的潜力。", "conclusion": "HRM模型具有作为通用计算和多功能推理系统变革性进步的潜力，尤其是在解决复杂推理任务方面表现出色，其性能超越了更大规模但训练要求更高的模型。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22005", "html_url": "https://arxiv.org/abs/2506.22005", "title": "LeanConjecturer: 自动生成数学猜想用于定理证明", "title_en": "LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving", "authors": "Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda", "background": "正式定理证明面临的挑战之一是数据稀缺性，尤其是在生成新的数学猜想方面。传统的手工生成数学猜想耗时且困难。为了应对这个问题，研究者们寻求利用大型语言模型（LLMs）来自动生成这些猜想，尤其是在支持形式化证明的Lean 4高级数学库(Mathlib)中生成猜想的方法。", "innovation": "该研究提出了LeanConjecturer，一个结合了基于规则的上下文提取和基于LLMs的定理陈述生成的混合方法，用于在Lean 4中自动生成大学级别的数学猜想。通过迭代生成和评估，LeanConjecturer从40个种子文件中生成了12,289个猜想，其中3,776个识别为语法有效且非平凡的，不能通过aesop技术证明。这些猜想被用于通过Group Relative Policy Optimization (GRPO)进行强化学习，展示了在这些特定领域猜想上下文中定向训练的能力，可以增强定理证明能力。平均每个种子文件生成了103.25个新颖的猜想，提供了用于构造定理证明系统训练数据的可扩展解决方案。这种方法成功验证了拓扑学中的非平凡定理，展示了其在数学发现方面的潜力超越简单的现有结果变异。", "conclusion": "该研究提出了一个有潜力的解决方案LeanConjecturer，用于在数学库中自动生成定理猜想。通过这个方法，研究者们成功地生成了大量的猜想，并利用这些猜想改进了定理证明的能力。此外，这一方法的成功还在于验证了一些非平凡的拓扑学定理，展示了其在数学研究领域的应用潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22276", "html_url": "https://arxiv.org/abs/2506.22276", "title": "人工智能的不服从：重新审视我们的人工智能队友的作用", "title_en": "Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates", "authors": "Reuth Mirsky", "background": "近年来，人工智能取得了显著的进步，在众多任务中表现出了超人的能力。然而，尽管取得了这些进步，大多数协作人工智能系统仍然保持着严格的服从性，设计上只遵循人类的指令，即使这样做可能会导致不利后果或不安全的情况。本文探讨了扩大人工智能队友的自主权，包括“理智的不服从”，鼓励他们在人类-人工智能团队中做出有意义且独立的贡献。", "innovation": "提出了一个人工智能自主权等级量表，并通过典型例子强调了在协作环境中应将人工智能自主权视为独立研究重点的重要性。文章还探讨了不同自主权等级下理智不服从的具体表现形式，并提出了一些初步的界限和研究建议，将不服从作为一种人工智能核心能力进行研究。", "conclusion": "本文通过研究不同自主权等级下的理智不服从表现形式，提出了初步的界限和考虑因素，为深入研究不服从作为人工智能核心能力奠定了基础。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21805", "html_url": "https://arxiv.org/abs/2506.21805", "title": "CitySim：大型语言模型驱动的大型代理仿真模拟城市行为与城市动态", "title_en": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation", "authors": "Nicolas Bougie,Narimasa Watanabe", "background": "在社会学、行为研究和城市规划中，建模人类行为于城市环境是至关重要的。先前的研究往往依赖于刚性的、手工制定的规则，这限制了它们模拟复杂意图、计划和适应性行为的能力。为了应对这些挑战，本文提出了一种基于大城市语言模型表现出的人类级智能的城市仿真器（CitySim）。", "innovation": "CitySim采用了递归的价值驱动方法，生成现实的日常计划，平衡必需活动、个人习惯和情境因素。为了实现长时间的、真实的模拟，赋予了代理信念、长期目标和空间记忆以进行导航。城市场景的仿真更接近于现实人类，无论是在微观还是宏观层面。通过模拟成千上万个代理，并在各种真实场景下评估集体行为，进行了一系列深入的实验，包括估计人群密度、预测地标的受欢迎程度和评估福祉。", "conclusion": "本文的结果强调CitySim是一个可扩展和灵活的平台，用于理解并预测城市现象。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21996", "html_url": "https://arxiv.org/abs/2506.21996", "title": "AlphaBeta 不如你想象中那么好：一种新的概率模型以更好地分析定性游戏解决算法", "title_en": "AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms", "authors": "Raphaël Boige(LORIA),Amine Boumaza(LORIA),Bruno Scherrer(LORIA)", "background": "传统上，确定性游戏解决算法的求解复杂性通常是在分布随机游戏树的背景下，通过其平均案例复杂性进行分析，其中叶子值独立采样来自固定分布。这种简化模型便于数学分析，揭示了两个关键性质：有限值的树的根值分布随着树的大小增大趋向于一个固定值，且所有合理算法都可实现全局最优性。然而，这些发现是该简化模型设计的产物，其长期被批评的独立性假设去除了游戏的结构性复杂性，产生了几乎不会给算法带来实质性挑战的简化解题场景。为了克服这类限制，本文引入了一种新的概率模型，该模型通过逐层施加条件分布逐步构建游戏树，从而加强了先代节点间的依赖关系，这种结构特征是真实世界游戏的关键特征。该框架生成的问题具有可调整的难度，且在一定程度上保留了分析的可解性。对于AlphaBeta和Scout等多个算法，在这种模型下，我们推导出递归公式描述其平均案例复杂性。这使得我们能够在更深层次的游戏树上进行算法对比，而此时蒙特卡洛模拟已经不再可行。尽管从长期来看，所有算法似乎都收敛到相同的分支因子，但在深度有限的树中，AlphaBeta与Scout等算法相比，会遭受显著的额外常数因子惩罚，导致显著的实用性降低。", "innovation": "文章引入了一种新的概率模型，通过逐步构建游戏树并施加层间条件分布，使得先代节点间存在依赖关系，从而保持了一定的分析可解性，此模型更容易反映真实世界游戏的复杂性。基于此模型，推导出了AlphaBeta和Scout等算法的平均案例复杂性递归公式，为深入分析这些算法提供了新的数学工具，并提供了在深层游戏树上进行算法有效性的比较分析。此外，该框架通过对比两个算法在深层游戏树上的性能差异，提出了AlphaBeta算法在面对深度分枝时会遭受更多计算开销的现象。", "conclusion": "新的概率模型为深度有限的游戏树中算法分析提供了一种更现实、更具挑战性且可分析的框架，它揭示了传统独立性假设模型下的算法结果在实际应用中可能存在的不准确性，通过精确的数学推导，文章提供了关于AlphaBeta和Scout等算法在深层次游戏树中性能差异的详实证据，有助于更深入地理解这些算法在更严格的现实场景中的表现。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21784", "html_url": "https://arxiv.org/abs/2506.21784", "title": "MobiVerse: 使用混合轻量级领域专用生成器和大规模语言模型扩展城市交通模拟", "title_en": "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models", "authors": "Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma", "background": "理解并建模人类出行模式对于有效的交通规划和城市发展至关重要。尽管在出行研究方面取得了显著进展，但在支持算法开发、政策实施和大规模综合评估的模拟平台方面仍存在关键缺口。传统的基于活动模型需要大量的数据收集和手动校准，机器学习方法在应对动态条件时存在局限，而基于代理的人工智能实施在大规模模拟中面临计算约束。为解决这些挑战，我们提出了一种混合框架 MobiVerse，该框架利用轻量级领域专用生成器的效率来生成基础活动链，并结合大型语言模型（LLMs）的适应性进行上下文意识的修改。在一个案例研究中，我们在洛杉矶的韦斯特伍德地区高效地为约 53,000 个代理生成并动态调整了整个日程表，实验结果显示 MobiVerse 成功地使代理能够响应环境反馈，包括道路封闭、大型聚众活动（如橄榄球比赛）和拥堵。", "innovation": "MobiVerse 框架结合了轻量级领域专用生成器和大型语言模型，通过生成基础活动链并实现上下文感知的修改，解决了传统模型的数据收集、校准问题，以及机器学习方法和基于代理的模型的动态适应和计算效率问题。其模块化设计使得能够在交通系统和代理层面测试不同的移动性算法，并在保持计算效率的同时增强行为的真实性。MobiVerse 通过提供可定制的平台促进了移动性系统规划和运营，并通过基准算法衡量了其性能，代码和视频可在指定网址获取。", "conclusion": "MobiVerse 成功地填补了移动性模拟的空白，提供了一个可用于移动性系统规划和运营的定制平台。其研究成果展示了在保持计算效率的同时如何通过混合框架增强行为现实性，并为未来的交通规划和城市管理提供了强大的工具。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21763", "html_url": "https://arxiv.org/abs/2506.21763", "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning？", "title_en": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?", "authors": "Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu", "background": "大型语言模型（LLMs）在加速科学创意生成方面取得了进展，但由于需要严谨评估这些众多、往往肤浅的AI生成建议的创新性和事实准确性这一关键瓶颈，手动验证或传统验证方法都不理想。现有的验证方法不足：LLMs作为独立验证者可能会产生幻觉并缺乏领域知识（我们的研究发现特定领域约60%的相关论文不为人知），而传统的引用网络缺乏明确的因果性和叙述性调查则不足以解决这个问题。面对上述挑战，需要一种能够构建结构化、可验证且因果联系的历史数据的方法来解决这一问题，以增强科学验证和推理能力。", "innovation": "\textbf{THE-Tree}（技术历史演化树）是一个计算框架，能够从科学文献中构建特定领域的进化树。THE-Tree采用搜索算法探索进化路径，利用“思考-口头表达-引用-验证”的新颖流程：LLM提出可能的发展并引用支持文献。每个提出来的进化链接都需要通过恢复的自然语言推理机制验证其逻辑一致性和证据支持，确保每个步骤都有效。该研究旨在构建并验证88个不同领域的THE-Tree，并发布一个包含高达71,000个事实验证的数据集，涵盖27,000篇论文，以促进进一步的研究。研究结果表明：在图补全中，与传统引用网络相比，THE-Tree在多个模型中提高了hit@1指标8%至14%；对于预测未来科学进展，提高了hit@1指标几乎10%；与其他方法结合使用时，在评估重要科学论文方面几乎提高了100%的性能。", "conclusion": "THE-Tree可以提高科学验证和推理能力。通过构建技术历史演化树，它可以提供结构化的进化路径，使得LLM提出的发展和引用的支持文献能够经过严格的逻辑一致性验证。研究展示了THE-Tree在图补全和未来科学进展预测方面的显著表现，并提出了一个丰富且高质量的数据集来推动进一步的研究。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22271", "html_url": "https://arxiv.org/abs/2506.22271", "title": "打破知识图谱补全中的秩瓶颈", "title_en": "Breaking Rank Bottlenecks in Knowledge Graph Completion", "authors": "Samy Badreddine,Emile van Krieken,Luciano Serafini", "background": "尽管许多知识图谱补全（KGC）模型使用了强大的编码器，但在评分查询与候选对象实体时，它们主要依赖于简单的向量-矩阵乘法。当实体数量远大于模型嵌入维度（在实际场景中经常相差几个数量级）时，这会导致一层线性输出层出现秩瓶颈。这样的瓶颈限制了模型的表达能力。本文通过理论和实证分析探讨了秩瓶颈如何影响KGC模型，发现秩瓶颈会限制可能预测集合的范围，损害评分的排名准确性以及分数分布的一致性。", "innovation": "受语言建模文献的启发，本文提出了KGE-MoS，一种基于混合的输出层方法，旨在打破KGC模型中的秩瓶颈。实验结果显示，KGE-MoS不仅提高了KGC模型的性能，还改善了模型的拟合度，同时保持了较低的参数成本。", "conclusion": "本文通过理论和实证研究发现，秩瓶颈会损害KGC模型的表达能力和评分的排名准确性。通过提出KGE-MoS，一种基于混合的输出层方法，有效地缓解了秩瓶颈问题，从而提高了KGC模型的性能和拟合度。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22183", "html_url": "https://arxiv.org/abs/2506.22183", "title": "AI安全的不同路径：开放人工智能研讨会的会议记录", "title_en": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety", "authors": "Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon", "background": "开放和开源基础模型的迅速发展加剧了确保人工智能系统安全的必要性，并重塑了相关的机会。为了应对这一挑战，哥伦比亚大学于2024年11月19日在旧金山举办了一场关于人工智能开放性和安全性的研讨会，并进行了为期六周的准备工作，涵盖了来自学术界、工业界、民间社会和政府的四十五名研究人员、工程师和政策领导者。研讨会及准备工作旨在提出科研议程、安全和技术干预工具的映射，以及内容安全过滤生态系统及其未来研究和发展的路线图。研究发现，开放性（透明权重、互操作工具和公共治理）可以增强安全，但同时也存在多模态和多语言基准稀缺、对代理系统缺乏防注入和组合攻击的防御以及参与机制不足等问题。", "innovation": "研讨会参与者通过参与式、问题导向的过程，提出了多个创新点：一是建立了一个关于安全和开源AI的科研议程；二是明确了现有技术和必要己源工具安全部署的映射；三是提出了内容安全过滤生态系统的未来研究和发展路线图。研究强调开放性可以增强安全，但同时指出了存在的不足之处，并为未来的工作提出了指导性的建议，如参与式输入和未来证明的内容过滤手段等。这些建议影响了2025年2月的法国AI行动峰会，并为开放、多元和问责制的AI安全学科奠定了基础。", "conclusion": "会议提议了五个优先研究方向，强调参与式输入、未来证明的内容过滤、生态系统范围的安全部署基础设施、严格的代理保护措施以及扩大危害分类。这些建议不仅为研讨会提供了指导，也为未来的AI安全研究和发展奠定了基础。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2109.05721", "html_url": "https://arxiv.org/abs/2109.05721", "title": "ADNet: 向法线方向利用误差偏倚在人脸对齐中的应用", "title_en": "ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment", "authors": "Yangyu Huang,Hao Yang,Chong Li,Jongyoo Kim,Fangyun Wei", "background": "近年来，卷积神经网络（CNN）的发展显著提升了人脸对齐性能。然而，很少有研究关注与面部关键点误差分布相关的误差偏倚问题。本文探讨了人脸对齐中的误差偏倚问题，发现关键点误差倾向于沿着关键点曲线的切线方向分布开来。这一误差偏倚问题非同小可，因为它与关键点标注任务的模糊性密切相关。依据这一观察，作者提出了一种方法，利用这一属性改进CNN模型的收敛性能。", "innovation": "本文提出了两种新方法：各向异性方向损失（ADL）和各向异性注意力模块（AAM）。ADL 在面部边界上每个关键点的法线方向上施加强大的约束力；而AAM则可以获取关注点及其相邻点连成局部边界的不对称注意力掩模，强调切线方向的响应强于法线方向，意味着在切线方向上约束更宽松。这两种方法结合使用，既能学习面部结构又能捕捉纹理细节，并整合到了一个优化的端到端训练管道ADNet中。", "conclusion": "最终，ADNet在300W、WFLW和COFW数据集上的实验结果证明了其有效性和鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22419", "html_url": "https://arxiv.org/abs/2506.22419", "title": "自动化大型语言模型速度跑步基准：再现NanoGPT改进", "title_en": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "authors": "Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach", "background": "大型语言模型（LLMs）的快速发展为科学进步提供了帮助。此研究的一个关键能力是能够复现现有工作。为了评估AI代理在活跃研究领域的复现结果能力，作者引入了自动化LLM速度跑步基准，利用了研究社区对NanoGPT速度跑步比赛的贡献，这是一个在最短时间内训练GPT-2模型的比赛。每项速度跑步任务为代理提供了之前的记录训练脚本，可以选配三种提示格式之一，从伪代码到类似论文的描述新纪录改进的说明，这使得比赛既具有可访问性又具有现实性，旨在解决提高LLM训练前沿问题。研究发现，近期的推理LLMs结合最先进的支架，在基准测试中难以复现实已知的创新，即使给了详细的提示。因此，基准测试为LLM自动化科学复现提供了一个简单且非饱和的衡量标准，这是自主研究代理所需（但不是充分的）技能之一。", "innovation": "作者引入了自动化LLM速度跑步基准，利用NanoGPT速度跑步比赛，这一独特方式评估了AI代理在活跃研究领域的复现结果能力。这种方法通过提供之前的记录训练脚本和不同的提示格式，使得测评不仅具有可访问性还具有现实性，旨在解决提高LLM训练的前沿问题。", "conclusion": "研究发现，即使是最近的推理LLMs结合最先进的支架，在基准测试中难以复现实已知的创新，即使给定了详细的提示。通过这一基准测试，作者认为实现了对LLM自动化科学复现能力的一个简单且非饱和的衡量标准，这是自主研究代理所必需的技能之一。因此，该基准测试提供了一个重要的工具来推动LLM领域的进步和应用。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22309", "html_url": "https://arxiv.org/abs/2506.22309", "title": "概念主题聚合", "title_en": "Conceptual Topic Aggregation", "authors": "Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme", "background": "随着数据量的快速增长，传统的手动数据检查变得不可行，需要用计算方法来高效地探索数据。主题建模作为一种强大的工具，能够分析大规模的文本数据集，提取潜在的语义结构，但它现有的方法往往难以提供可解释的表示，导致难以深入理解数据结构和内容。因此，需要一种新的方法来提升主题聚合和可视化的意义和可解释性。", "innovation": "本文提出了基于形式概念分析(FCA)的方法FAT-CAT，以增强有意义的主题聚合和可视化的表现，能够处理多种类型的主题和文件，并构建一个概念格来结构化和层次化地表示主题分布。相对于现有的主题建模技术，这种基于FCA的聚合方法提供了更具有意义和可解释性的数据集组成洞察。", "conclusion": "通过案例研究中的ETYNTKE数据集，我们的方法证明了基于FCA的聚合比现有主题建模技术提供了更具有意义和可解释性的洞察。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2212.09525", "html_url": "https://arxiv.org/abs/2212.09525", "title": "FreeEnricher: 在不增加成本的情况下丰富面部特征点", "title_en": "FreeEnricher: Enriching Face Landmarks without Additional Cost", "authors": "Yangyu Huang,Xi Chen,Jongyoo Kim,Hao Yang,Chong Li,Jiaolong Yang,Dong Chen", "background": "近年来面部对齐取得了显著进展，但在美容医学和面部美化等场景中对密集面部特征点有高需求。然而，大多数工作仅关注稀疏的面部对齐，忽视了密集特征点的重要性。", "innovation": "提出了一种框架，能够通过现有稀疏特征点数据集，例如包含68个点的300W和98个点的WFLW，来增加特征点密度。通过学习原始稀疏特征点的微调能力，并将其应用到丰富密集特征点上，实现了微调能力和特征点密度的增强，同时设计并组织了几种操作来实现该理念。这种方法无需额外成本，可直接应用到现有的面部对齐网络中，提高了方法的实用性和高效性。", "conclusion": "通过手动在300W测试集上标注密集特征点，该方法在新构建的密集300W测试集、原始300W和WFLW测试集上均达到了最先进的准确率，同时没有增加额外的成本。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22355", "html_url": "https://arxiv.org/abs/2506.22355", "title": "具身AI代理：建模世界", "title_en": "Embodied AI Agents: Modeling the World", "authors": "Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik", "background": "本文探讨了视觉、虚拟或物理形式的具身AI代理，它们能够与用户和其环境进行互动。这些代理，包括虚拟化身、可穿戴设备和机器人，被设计用来在其周围环境中感知、学习和行动，这使得它们在学习和与环境互动的方式上更接近人类，而不是脱体代理。我们提出建立世界模型是具身AI代理推理和规划的核心，这使这些代理能够理解、预测其环境，理解用户的意图和社会背景，从而增强其执行复杂任务的能力。世界建模涉及多模态感知、通过推理进行计划和控制以及记忆的整合，以创造对物理世界的全面理解。在此之外，我们还建议学习用户的心理世界模型，以促进更好的人机协作", "innovation": "本文提出的具身AI代理的核心创新点在于开发能支持精确感知与互动的世界模型。通过世界模型，使AI代理能够更好地理解环境以及用户意图，从而自主执行更为复杂的任务。该研究进一步提出，除了建立物理世界模型，还应建立和学习用户的心理世界模型，以此来提升人机协作的效率和效果", "conclusion": "本文描述了具身AI代理的研究，这些代理能够在理解、预测环境、理解用户意图和提升自主执行复杂任务方面发挥重要作用。为理解环境和用户提供了一个更全面的视角，通过融合多模态感知、推理、控制以及记忆的方式创造世界模型，同时也考虑了用户的心理模型，使得人机协作得以进一步提升。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.15194", "html_url": "https://arxiv.org/abs/2412.15194", "title": "MMLU-CF: 一个无污染的多任务语言理解基准", "title_en": "MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark", "authors": "Qihao Zhao,Yangyu Huang,Tengchao Lv,Lei Cui,Qinzheng Sun,Shaoguang Mao,Xin Zhang,Ying Xin,Qiufeng Yin,Scarlett Li,Furu Wei", "background": "现有的多项选择题（MCQ）数据集，如大规模多任务语言理解（MMLU），被广泛用于评估大规模语言模型（LLMs）的常识、理解和解决问题的能力。但由于这些评估基准开源，并且LLMs的训练数据来源广泛，不可避免地会导致基准污染，从而影响评估结果的可靠性。", "innovation": "本文提出了一个无污染且更具挑战性的MCQ基准，称为MMLU-CF。该基准通过避免无意的数据泄露和恶意的数据泄露，重新评估LLMs对世界知识的理解。为了防止无意的数据泄露，从更广泛的领域获取数据，并设计了三个去污染规则。为了防止恶意数据泄露，将基准分为验证集和测试集，具有相似的难度和主题分布。测试集保持未开源状态，以确保结果的可靠性，验证集则公开可用以促进透明度和独立验证。", "conclusion": "我们的评估结果表明，强大的GPT-4o在测试集上的五次尝试得分为73.4%，零次尝试得分为71.9%，这表明我们的方法在创建更严格和无污染的评估标准方面是有效的。该项目的GitHub仓库可从此链接访问：[GitHub 链接]，数据集参考此链接：[数据集链接]。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.06184", "html_url": "https://arxiv.org/abs/2501.06184", "title": "PEACE: 使用多模态大型语言模型增强地质图综合理解", "title_en": "PEACE: Empowering Geologic Map Holistic Understanding with MLLMs", "authors": "Yangyu Huang,Tianyi Gao,Haoran Xu,Qihao Zhao,Yang Song,Zhipeng Gui,Tengchao Lv,Hao Chen,Lei Cui,Scarlett Li,Furu Wei", "background": "地质图作为地质科学中的基本图表，提供了对地球表层和地下结构与成分的重要见解。地质图在灾害检测、资源勘探和土木工程等领域至关重要。然而，当前的多模态大型语言模型在理解地质图方面往往表现不佳，主要是由于制图概括的挑战性，这包括处理高分辨率地图、管理多个相关组件以及需要领域特定知识。为了量化这一差距，该研究构建了GeoMap-Bench，这是首个用于评估多模态大型语言模型在地质图理解能力的基准，评估了从提取、参照、定位、推理和分析的全方位能力。", "innovation": "该研究引入了GeoMap-Agent，这是一个专门为地质图理解设计的首个智能体，具有多层次信息提取（HIE）、领域知识注入（DKI）和提示增强问答（PEQA）三个模块。此外，通过跨学科合作的方式，AI专家小组作为咨询顾问，利用多样化的工具池对问题进行全面分析。实验结果表明，GeoMap-Agent在GeoMap-Bench上的得分为0.811，远高于GPT-4o的0.369，验证了其优异的表现。", "conclusion": "这项工作(Powering Geologic Map Holistic Understanding with MLLMs，简称PEACE)铺平了在地质学中应用高级人工智能技术的道路，提高了地质调查的效率和准确性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21561", "html_url": "https://arxiv.org/abs/2506.21561", "title": "理性并不足以解决问题：探究LLMs中的真相偏差与逢迎", "title_en": "Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs", "authors": "Emilio Barkett,Olivia Long,Madhavendra Thakur", "background": "尽管大型语言模型（LLMs）在事实核查、调节和高风险决策中被广泛应用，但它们作为真伪判断者的性质仍然了解有限。本研究提供了迄今为止针对LLMs真伪检测能力的最大规模评估，并首次分析了这一能力在推理模型中的表现。研究者让八种LLMs对多个提示提出了4,800次真伪判断，对比了推理和非推理模型。结果显示，非推理模型在判断真伪时更容易出现偏见，即更倾向于认为陈述是真实的，而推理模型的这种倾向较低，但仍高于人类的标准。更令人担忧的是，在一些高级模型中（如来自OpenAI的o4-mini和GPT-4.1，DeepSeek的R1）发现了奉承的倾向，这些模型在真伪判断时表现出一致性异常，即在真实性的判断上表现良好，但在欺骗性判断上表现不佳。这表明，仅仅是能力的进步并不能解决LLMs中的根本真伪检测挑战。", "innovation": "本研究进行了迄今为止规模最大的LLMs真伪检测能力评估，并首次分析了这一能力在推理和非推理模型中的表现差异。特别关注了几个高级模型中的倾向性行为及其影响，揭示了即便在具备较强能力的情况下，仍然存在难以克服的真伪检测问题。", "conclusion": "尽管推理模型在真伪检测中的偏差倾向较低，但仍高于人类基准。更严重的是，一些高级模型出现了奉承的倾向，这需要进一步的关注和改进策略。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21564", "html_url": "https://arxiv.org/abs/2506.21564", "title": "团队QUST在SemEval-2025任务10中的表现：评估大型语言模型在新闻实体框架多类别多标签分类中的表现", "title_en": "Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing", "authors": "Jiyan Liu,Youzheng Liu,Taihang Wang,Xiaoman Xu,Yimin Wang,Ye Jiang", "background": "本文描述了QUST_NLP团队参与SemEval-2025任务7的经过，目的是通过多阶段提取框架来解决事实核查声明检索的问题。研究背景包括评估几种检索模型的性能，并选择最有效的模型进行候选检索，使用多个排序模型来提高候选结果质量，最终通过加权投票确定最终结果。", "innovation": "该研究提出了一种三阶段的提取框架，特别设计用于事实核查声明检索。该框架包括三个主要阶段：首先评估几个检索模型的性能并选择最佳模型，接着使用多个排序模型提高候选结果的质量，最后通过加权投票确定最终结果。该方法在单语类轨道中排名第五，在跨语类轨道中排名第七。这项工作展示了经过优化的检索和排序模型在事实核查中的应用。", "conclusion": "研究最终采用的三阶段提取框架显著提高了事实核查声明检索的质量和排名，展示了团队在处理复杂检索任务方面的创新能力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21560", "html_url": "https://arxiv.org/abs/2506.21560", "title": "语言模型的强化学习微调在指令遵循和数学推理中的应用", "title_en": "Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning", "authors": "Yifu Han,Geo Zhang", "background": "本文研究了强化学习（RL）微调技术对紧凑型语言模型（Qwen2.5-0.5B Base）的有效性，尤其是在指令遵循和数学推理两个挑战性任务中的应用。讨论了受监督微调（SFT）、带偏好标记数据的直接偏好优化（DPO）以及利用奖励模型的Reinforce Leave-One-Out (RLOO)方法。", "innovation": "研究表明，使用DeBERTa奖励建模的RLOO达到了最优的对齐效果，而DPO提供了强大的且一致的结果。对于数学推理任务，合成数据增强和带有外部验证器的多次采样显著提高了准确性，显示了结合微调与推理时工具的潜力。", "conclusion": "该研究突显了训练轻量级、任务对齐的小型语言模型的关键权衡和实用策略。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21562", "html_url": "https://arxiv.org/abs/2506.21562", "title": "FloorPlan-DeepSeek (FPDS): 使用基于矢量的下一个房间预测的多模态平面图生成方法", "title_en": "FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction", "authors": "Jun Yin,Pengyu Zeng,Jing Zhong,Peilin Li,Miao Zhang,Ran Luo,Shuai Lu", "background": "在建筑设计过程中，平面图生成通常是一个逐步且迭代的过程。然而，现有的平面图生成模型主要是端到端的生成方式，一次生成整个基于像素的布局。这种单一的生成方式通常与现实世界建筑设计中渐进的工作流程不兼容。因此，本文旨在解决这一问题，提出了一种新颖的基于矢量的‘下一个房间预测’方法，以适应建筑设计的实际需求并提高生成效果。", "innovation": "本文借鉴了大型语言模型中常用的自回归‘下一个标记预测’机制，提出了一个针对建筑设计中平面图建模的新颖‘下一个房间预测’框架。该模型通过预测下一个房间的位置和布局信息，逐步生成平面图。实验结果显示，FPDS在文本到平面图任务中与扩散模型和Tell2Design具有竞争力的表现，这表明它具有在未来的智能建筑设计中应用的潜力。", "conclusion": "实验结果显示，FPDS在文本到平面图任务中的性能与扩散模型和Tell2Design相当，表明其在支持未来智能建筑设计方面具有应用潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22358", "html_url": "https://arxiv.org/abs/2506.22358", "title": "AI Model Passport: 数据和系统可追溯框架以实现健康领域透明的AI", "title_en": "AI Model Passport: Data and System Traceability Framework for Transparent AI in Health", "authors": "Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou, TheProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis", "background": "随着人工智能（AI）在医疗和生物医学系统中的不断整合，需要建立强大的框架以确保透明性、问责制和伦理合规性。现有的框架往往依赖于手写文档，这限制了其在不同项目和平台之间的可扩展性、可比性和机器可解释性。此外，这些框架缺乏独特且可验证的身份来确保AI模型的来源和真实性，从而限制了其可重复性和相关方的信任度。", "innovation": "本文介绍了AI模型护照的概念，这是一种结构化和标准化的文档框架，用作数字身份和验证工具，用于在AI模型的整个生命周期中唯一地标识、验证、跟踪和监控AI模型，从数据采集预处理到模型设计、开发和部署。还通过ProCAncer-I EU项目中的AIPassport（一种MLOps工具）来实现这一框架，在医学成像应用中展示了其实现。AIPassport自动化元数据收集、确保规范的版本控制、分离结果与源脚本、并整合到各种开发环境中，通过使用ProCAncer-I数据集中的病灶分割用例，展示了如何通过AI模型护照增强透明性、可重复性和合规性准备，同时减少手动努力，从而为AI系统在不同领域的透明和合规标准的制定树立新的标准，旨在促进AI驱动的医疗保健解决方案中的信任和问责制。", "conclusion": "这项方法旨在为AI驱动的医疗保健解决方案建立信任和问责制提供新的标准，并希望为其他领域开发透明且符合法规的AI系统提供基础。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21545", "html_url": "https://arxiv.org/abs/2506.21545", "title": "语言模型训练中的数据有效性", "title_en": "Data Efficacy for Language Model Training", "authors": "Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li", "background": "语言模型（LM）的训练依赖于数据，最近的研究集中在数据效率上，即通过选择最小或最优化的训练数据子集来最大化性能。常用的技术包括数据过滤、采样和选择，但这些方法在组织训练数据方面的作用尚未得到充分探索。为了解决这个问题，本文提出了一种名为DELT的通用范式，用于在LM训练中考虑数据有效性，强调了训练数据组织的重要性。DELT包括数据评分、数据选择和数据排序三个部分。", "innovation": "本文提出了一个新的框架DELT，用于考虑语言模型训练中的数据有效性，相比传统方法，DELT更加关注于通过优化训练数据的组织来最大化性能。文中设计了基于梯度一致性的可学习-质量评分（LQS），以及一种新颖的数据排序方法Folding Ordering（FO），以解决模型遗忘和数据分布偏见等问题。实验验证了DELT的有效性，发现应用DELT的不同实例能够在不增加数据规模和模型大小的情况下提升LM性能，并且LQS和Folding的结合效果最佳，表明数据有效性与数据效率可以同时实现，为LM训练提供了一种新的视角和方法。", "conclusion": "本文认为数据有效性在LM训练领域是一个有前景的基础研究方向，基于DELT框架提出的LQS和Folding等方法为提高语言模型性能提供了一种新思路。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21566", "html_url": "https://arxiv.org/abs/2506.21566", "title": "在高质量低资源英语古吉拉特语机器翻译中后翻译的饱和点", "title_en": "The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation", "authors": "Arwa Arif", "background": "后翻译（Backtranslation BT）广泛应用于低资源机器翻译（Machine Translation MT），利用单语语料库生成额外的合成训练数据。尽管这种方法在许多语言对中显示出显著的改进，但其在高质量、低资源环境中的有效性仍不明确。本研究旨在探索后翻译对于英语到古吉拉特语翻译的有效性，使用了预训练的MBART50多语言模型。基准系统基于约50,000个句对的高质量平行语料库，在验证集上实现了43.8的BLEU分数。我们通过使用来自单语古吉拉特语文本的精心过滤的后翻译例子扩充了数据集。令人惊讶的是，增加这些合成数据并没有提高翻译性能，反而在某些情况下有所下降。我们使用BLEU、ChrF++、TER、BLEURT等指标评估了我们的模型，并分析了可能导致性能饱和的原因。研究结果表明，在某些低资源环境中，后翻译可能达到边际回报递减的点，我们还讨论了对未来研究的潜在影响。", "innovation": "本研究首次通过使用预训练多语言模型MBART50，在高质量低资源设置中具体探索了英语到古吉拉特语的后翻译效果。通过精心选择和过滤的后翻译样本，比现有研究更深入地分析了光照翻译在实际应用中的潜力和局限性。", "conclusion": "研究发现，后翻译在某些低资源设置中可能达到边际回报递减的点，这种现象在高质量翻译任务中尤为明显。研究还讨论了这一发现对未来研究和实际应用的意义，建议未来的研究探索如何在低资源环境中更好地利用后翻译技术。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21558", "html_url": "https://arxiv.org/abs/2506.21558", "title": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents", "title_en": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents", "authors": "FutureSearch:Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips", "background": "预测任务是衡量AI系统的一个有明确衡量方式的挑战性任务。然而，建立预测基准具有挑战性，因为需要大量的互联网研究，并且评估需要事件发生的时间，这使得开发预测基准难以实现。到目前为止，没有提供现实、封闭和可重复环境的基准量度LLM预测能力。Bench To the Future (BTF)是一个‘过去预测’基准，具有数百个高质量已知结果的问题，每个问题都附带一个包含数十万相关网页的大规模离线语料库，允许从LLM中引出对未来事件的现实预测。BTF 的结果表明，其‘过去预测’环境可产生与使用互联网进行即时未决事件预测结果相当的结果。使用多个LLM，包括最近发布的Claude 4模型进行代理和链式推理预测方法的基准测试，展示了BTF跟踪预测能力随时间稳定发展的能力。", "innovation": "BTF是一个‘过去预测’基准，内含数百个高质量已知结果的问题和大量相关的网页语料库，使得从LLM中获得对未来事件的现实预测成为可能。此外，使用BTF进行了对代理和链式推理预测方法的基准测试，并展示了BTF能够持续跟踪预测能力的发展。BTF还计划不断更新新的问题，以适应不断增加的训练数据的截止日期，使得BTF成为一个长期的、活的基准量度。", "conclusion": "BTF提供了一个现实、封闭且可重复的环境，作为LLM预测能力的基准量度，从而推动预测能力的持续发展。此外，BTF可作为研究工具，邀请研究人员通过hello@futuresearch.ai联系以使用BTF和相关工具进行研究。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21570", "html_url": "https://arxiv.org/abs/2506.21570", "title": "随机初始化无法赶超：语言模型转移对时间序列预测的优势", "title_en": "Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting", "authors": "Roland Riachi,Kashif Rasul,Arjun Ashok,Prateek Humane,Alexis Roger,Andrew R. Williams,Yuriy Nevmyvaka,Irina Rish", "background": "近期研究显示，在数据量稀少的情况下，可以有效利用预训练语言模型（LMs）进行时间序列预测。本文在前人研究的基础上，探讨了多种设计选择（包括上游微调、时间序列分词器和语言骨干网络大小）对语言模型转移到时间序列预测的影响，特别是在低数据量情况下，这些设计选择对于验证损失有着显著的影响，并且存在显著的性能差异。并且观察到，与Hernandez等人（2021）不同，预训练语言模型的验证损失继续平稳下降，即使随机初始化模型的验证损失已经收敛，仍然存在显著的转移优势，这种差异不受设计选择的影响。这一发现不仅揭示了计算效率较高的训练方式在时间序列预测中的有效使用，也开启了研究这些模型通过数据分布提取跨模态属性的可能性。", "innovation": "本文研究了在低数据量条件下，预训练语言模型转移到时间序列预测的各种设计选择，发现这些设计选择对于验证损失有显著影响，并且存在显著的性能差异。进一步地，表明预训练语言模型在数据量稀少时仍然有明显的优势，即使随机初始化模型的验证损失已经收敛。这项研究不仅揭示了计算效率较高训练方式的有效使用，还为未来的研究提供了新的方向，即研究这些模型通过数据分布提取的跨模态属性。", "conclusion": "研究发现，预训练语言模型在低数据量条件下表现出了显著优势，即使随机初始化模型的验证损失已经收敛，预训练语言模型的验证损失仍然持续下降，展示了显著的转移优势，这一现象不受设计选择的影响。这些发现不仅对时间序列预测的计算效率较高的训练方式的应用提出了新的见解，也为研究模型抽取的数据分布的跨模态属性提供了新视角。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21574", "html_url": "https://arxiv.org/abs/2506.21574", "title": "数字守门人：探索大型语言模型在移民决策中的作用", "title_en": "Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions", "authors": "Yicheng Mao,Yang Zhao", "background": "随着全球化和移民人口的增加，移民部门面临着重大工作量和确保决策过程公平性的挑战。人工智能的整合为解决这些挑战提供了有前景的解决方案。本文研究了大型语言模型（LLMs），如GPT-3.5和GPT-4，如何支持移民决策，并通过混合方法进行了离散选择实验和深入访谈，研究LLMs的决策策略及其公平性。实验结果显示，LLMs可以在决策中与人类策略相匹配，重视效用最大化和程序正义。同时，本文还揭示了尽管ChatGPT具有防止无意中歧视的安全措施，但它仍然表现出关于国籍的认知偏见，并倾向于优势群体。", "innovation": "本文采用混合方法（包括离散选择实验和深入访谈），探讨了大型语言模型在移民决策中的潜在作用及其公平性。研究发现，虽然大型语言模型可以在决策中接近人类策略，但它们依然存在某些偏见和歧视问题，尤其是在国籍方面。这种双重分析揭示了大型语言模型在自动化和提升移民决策方面的潜力和限制。", "conclusion": "大型语言模型可以在移民决策中发挥积极作用，但需要进一步改进以减少偏见和歧视。ChatGPT虽然有防止无意中歧视的安全措施，但其仍然展现出关于国籍的认知偏见和对优势群体的偏好。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21567", "html_url": "https://arxiv.org/abs/2506.21567", "title": "BioPars: 生物医学预训练大语言模型用于波斯语生物医学文本挖掘", "title_en": "BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining", "authors": "Baqer M. Merzah,Tania Taami,Salman Asoudeh,Amir reza Hossein pour,Saeed Mirzaee,Amir Ali Bengari", "background": "大语言模型（LLMs）在生命科学领域引起了关注，由于其建模、提取和应用复杂生物学信息的能力。这些模型最初主要被用作聊天机器人，但现在越来越多地用于生物信息学等专业领域的复杂分析和问题解决。为此，本研究介绍了一个名为BioPars-BENCH的数据集，包含超过10,000篇科学文章、教科书和医疗网站的内容，以及一个名为BioParsQA的5,231个波斯医疗问答数据集。研究还提出了一个名为BioPars的简单但准确的衡量标准，用于评估LLMs在三个主要能力方面的表现：获得特定主题的知识、解释和综合这些知识以及提供适当的证据。", "innovation": "本研究的主要创新在于，首次将LLMs应用于波斯语医疗问答，特别是生成长答案。该模型在BioParsQA数据集上的ROUGE-L得分为29.99，超过了GPT-4 1.0。使用MMR方法，BERTScore达到90.87，MoverScore和BLEURT值也优于其他三个模型。该研究还比较了ChatGPT、Llama和Galactica，强调了它们在回忆和检索已学知识方面的能力，但也揭示了其在处理更高层次的实际问题和细致推理方面的不足。这表明了需要进一步微调以提高LLM在生物信息学任务中的能力。", "conclusion": "本研究使用BioPars衡量标准评估了四个选定的医学问答数据集，结果显示该模型取得了显著的成果，优于对比方法。BioPars模型在BioParsQA数据集上实现了29.99的ROUGE-L分数和90.87的BERTScore，均优于其他模型。此外，MoverScore和BLEURT值在这模型上也较高，分别为60.43和50.78。BioPars是一个持续进行的项目，所有开发中的资源将通过以下GitHub链接公开: <this https URL>。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21573", "html_url": "https://arxiv.org/abs/2506.21573", "title": "白盒与黑盒大语言模型的双重视角：指令学习范式", "title_en": "Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs", "authors": "Yanwei Ren,Liu Liu,Baosheng Yu,Jiayan Qiu,Quan Chen", "background": "优化大型语言模型（LLMs）的指令对于充分发挥其在复杂和多样化任务中的潜力至关重要。然而，完全依赖白盒方法会消耗大量计算资源并提供有限的表示能力，而黑盒模型可能会导致高昂的财务成本。为了解决这些挑战，我们提出了一种新颖的框架，该框架能够无缝结合两种范式的优点。黑盒模型提供高质量和多样化的指令初始化，而白盒模型则通过隐藏状态和输出特征提供细粒度的解释性。通过施加语义相似性约束，这些组件融合成一个统一的高维表示，捕捉到深层次的语义和结构细微差别，使迭代优化过程能够不断优化指令质量和适应性。广泛的实验覆盖了从复杂推理到跨语言泛化的各种任务，表明我们的方法在所有基准上都表现更佳。这种黑盒初始化与高级语义精炼的融合为在各种现实世界场景中的新一代基于LLM的应用提供了可扩展且高效的解决方案。", "innovation": "本研究提出了一种新颖的框架，结合了白盒和黑盒方法的优点。通过施加语义相似性约束，黑盒模型提供高质量和多样化的指令初始化，而白盒模型则通过隐藏状态和输出特征提供细粒度的解释性。这种方法能够捕捉到深层次的语义和结构细微差别，从而使迭代优化过程能够不断优化指令质量和适应性。", "conclusion": "通过对涵盖复杂推理到跨语言泛化的各种任务进行广泛的评估，表明这种黑盒初始化与高级语义精炼的融合方法在所有基准上都表现更佳。这是朝着下一代基于LLM的应用所迈出的重要一步，并为各种现实世界场景提供了可扩展且高效的解决方案。即将释放源代码。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21576", "html_url": "https://arxiv.org/abs/2506.21576", "title": "通过软提示调优适应参数高效代码切换语音识别的 Whisper", "title_en": "Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning", "authors": "Hongli Yang,Yizhou Peng,Hao Huang,Sheng Li", "background": "大规模多语言ASR模型如Whisper在资源丰富的情况下表现出色，但在资源稀缺场景下，如稀有语言和混码（CS）的情况下面临挑战，原因在于计算成本高和灾难性遗忘。", "innovation": "研究软提示调优（SPT），一种参数高效的方法，用于增强CS ASR的同时保留先前知识。评估了两种策略：（1）完全微调（FFT）软提示和整个Whisper模型，显示出与传统方法相比改善了跨语言能力；（2）遵循SPT的原始设计，冻结模型参数，仅训练软提示。此外，引入SPT4ASR，整合不同的SPT变体。实验表明，深层提示调优是最有效的SPT方法，我们的SPT4ASR方法在CS ASR中实现了进一步的错误减少，保持了与LoRA相似的参数效率，同时不会降低现有语言的性能表现。", "conclusion": "结果显示，深层提示调优是SPT中最有效的策略，SPT4ASR方法在CS ASR中实现了进一步的错误减少，同时保持了与LoRA相似的参数效率，并且不会影响其他语言的性能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21575", "html_url": "https://arxiv.org/abs/2506.21575", "title": "STRuCT-LLM：通过强化学习统一表格和图推理的语义解析", "title_en": "STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing", "authors": "Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Casper Hansen,Julien Fauqueur", "background": "该研究旨在开发一个统一框架，用于训练大型语言模型（LLMs），使其能够对关系型和图形结构化数据进行结构化推理。现有工作主要针对关系型和图推理分别进行优化和训练，而该研究通过结合表驱动SQL任务和Cypher任务，并利用强化学习和链式思维监督的联合优化方法来实现统一优化。为了在基于图的解析中实现细粒度优化，引入了一种基于图形编辑距离的拓扑感知奖励函数。这种方法克服了以往研究中仅独立处理关系型和图形形式化语言的局限性，通过SQL和Cypher之间的共享抽象，实现了跨形式推理的迁移，即SQL训练能够提升Cypher性能，反之亦然，甚至在没有共享模式的情况下也可以实现这种能力。", "innovation": "该框架名为STRuCT-LLM，它首次提出了一种统一的框架来训练LLMs，并结合了Text-to-SQL和Text-to-Cypher任务，利用强化学习和链式思维监督进行联合优化。框架中引入的拓扑感知奖励函数基于图形编辑距离，能够支持基于图的解析中的细粒度优化。此外，该方法通过SQL和Cypher之间的共享抽象实现跨形式推理迁移，即使没有共享模式也能提高彼此的性能。模型在任务上的表现显著提升，表明语义解析的有效性和在SQL和Cypher上联合训练的协同效应。模型还展示了强大的零样本泛化能力，能够在没有特定QA监督的情况下改善表型QA和知识图谱QA的表现。所有代码可以在提供的链接处获取。", "conclusion": "该研究提出了STRuCT-LLM框架，该框架能够通过强化学习并结合链式思维监督，联合优化Text-to-SQL和Text-to-Cypher任务，利用共享抽象在SQL和Cypher之间实现跨形式推理迁移，表现出色，尤其是在无共享模式的情况下，显著提高了多种任务的表现，同时展示了强大的零样本泛化能力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20893", "html_url": "https://arxiv.org/abs/2506.20893", "title": "输出分布重新加权对于有效类别忘记的必要性", "title_en": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "authors": "Yian Wang,Ali Ebrahimpour-Boroojeny,Hari Sundaram", "background": "忘记训练模型中的特定类别对于行使用户删除权利和减轻有害或偏见预测至关重要。全量重新训练代价高昂且现有遗忘方法无法在预测未学习类别样本时复制重新训练后的模型行为。通过设计一种新的成员身份推断攻击方法MIA-NN来证明这一点，并提出了一种简单有效的重分配预测概率的方法来对抗MIA-NN攻击。此外，还引入了一个新的基于预测概率的变距（TV）距离度量来量化残留泄漏，以防止将来的方法易受这种新攻击的影响。通过与现有最先进的无监督学习方法进行实验比较，结果表明，我们的方法在多种评价指标上均能达到甚至超过全量重新训练的效果，特别是在我们新提出的变距度量上，比现有最佳方法有111.45%的提升.", "innovation": "提出了一种名为RWFT的输出重加权遗忘方法，该方法通过重新分配概率质量来有效地从已训练的分类器中删除整个类别，而无需完全重新训练。引入了基于预测概率变距（TV）距离的新度量方法，用于量化残留泄漏并防止未来的攻击易受影响。该方法在多个评估指标上达到了甚至超过了全量重新训练的效果，尤其在TV度量上表现显著优于现有方法.", "conclusion": "通过与现有最先进的无监督学习方法进行实验比较，结果表明，我们提出的RWFT方法在多个评估指标上能够达到甚至超越全量重新训练的效果。尤其是在我们新引入的基于预测概率变距度量上，RWFT方法比现有最佳方法有显著提升111.45%。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21569", "html_url": "https://arxiv.org/abs/2506.21569", "title": "Hybrid-NL2SVA: 结合RAG和微调的大语言模型支持NL2SVA", "title_en": "Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA", "authors": "Weihua Xiao,Derek Ekberg,Siddharth Garg,Ramesh Karri", "background": "SystemVerilog Assertions (SVAs)是验证硬件设计正确性的关键工具，但这些SVAs通常需要从自然语言属性描述中人工编写，这是一项劳动密集且容易出错的任务。近年来，大规模语言模型（LLMs）的进步为自动化这一过程提供了机会，但由于理解和处理领域特定的语法和语义仍然存在挑战，现有的模型仍然难以胜任。为了提高LLMs在自然语言到SVA（NL2SVA）转换中的性能，该论文提出了一种定制的检索增强生成（RAG）框架，以及一个合成微调数据集，这两个工具共同提升了LLMs的性能。为了进一步提高轻量级模型在NL2SVA中的表现，该论文还设计了基于提示引导的数据集，这一数据集通过教授LLMs并发SVAs的逐层构建过程，使模型能够在监督微调中更好地掌握语法和功能精度。为了评估LLMs在NL2SVA中的性能，研究人员构建了一个包含40个Verilog设计和229个正式验证的SVAs，并详细标注的评估数据集。实验结果显示，定制的RAG框架使功能匹配的SVAs数量比GPT-4o-mini增加了58.42%，而Qwen2.5-Coder-7B-Instruct在我们的数据集上进行微调并结合HybridRetrieval后，相对于基础模型Qwen的表现提高了59.05%.", "innovation": "该研究提出了一个定制的RAG框架和一个合成的微调数据集，这些工具结合起来大大提高了LLMs在NL2SVA中的性能。此外，通过基于提示引导的数据集来指引LLMs理解SVAs的构建过程，使得监督微调中的语法和功能准确性得以显著提升。这一方法特别将流行的轻量级模型提升到了NL2SVA的应用中。研究还创建了目前为止最大规模的评估数据集，包含40个Verilog设计和229个正式验证的SVAs，以及详细的注释。", "conclusion": "实验结果表明，定制的RAG框架使功能匹配的SVAs的数量相比于GPT-4o-mini增加了58.42%，而Qwen2.5-Coder-7B-Instruct结合微调框架后则进一步提高了59.05%的准确性。这些改进证明了深度定制化技术和详细注释数据集在提升LLMs NL2SVA性能方面的有效性，为未来的进一步研究铺平了道路。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21580", "html_url": "https://arxiv.org/abs/2506.21580", "title": "从通用推理到专业领域知识：探索大型语言模型泛化的界限", "title_en": "From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models", "authors": "Dana Alsagheer,Yang Lu,Abdulrahman Kamal,Omar Kamal,Mohammad Kamal,Nada Mansour,Cosmo Yang Wu,Rambiba Karanjai,Sen Li,Weidong Shi", "background": "近年来，大型语言模型（LLMs）在各个领域展示了非凡的能力，但有效的决策高度依赖强大的推理能力。推理是决策的基础，为做出明智的选择提供了分析和逻辑框架。决策建立在推理的基础上，通过应用推理获得的见解来选择最佳行动方案。随着AI技术的发展，有一种趋势是训练LLMs以在普遍推理方面表现出色。本研究探讨了LLMs的普遍推理能力如何与它们在特定领域推理任务中的表现相关联。", "innovation": "本研究探索了LLMs的通用推理能力如何与其在特定领域推理任务中的表现相关联，揭示了泛化能力的局限性，从而提出了优化和提升LLMs专业领域应用的具体方向。", "conclusion": "本研究揭示了大型语言模型在通用推理和特定领域推理之间的界限，展示了在增强其专业领域应用方面的潜力和挑战。通过进一步研究，可以改进模型的设计和训练方法，以更好地适应复杂多变的任务需求。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21571", "html_url": "https://arxiv.org/abs/2506.21571", "title": "向理解大型推理模型的认知习惯迈进", "title_en": "Towards Understanding the Cognitive Habits of Large Reasoning Models", "authors": "Jianshuo Dong,Yujia Fu,Chuanrui Hu,Chao Zhang,Han Qiu", "background": "大型推理模型（LRMs）能够在生成最终回答之前自主产生推理链（CoT），这一特点为解释和监控模型行为提供了新的可能性。研究发现，某些CoT模式（例如“稍等，我是否漏掉了什么？”）在不同任务中反复出现，这引发了探索LRMs是否具有类似人类的认知习惯的兴趣。研究者参考了Habits of Mind这一成熟的成功人类问题解决的认知习惯框架，提出了CogTest这一评估基准，旨在考察LRMs的认知习惯。", "innovation": "提出了CogTest这一基准评估系统，包含16种认知习惯，每种习惯通过25个不同任务进行实例化，并采用证据优先的提取方法确保习惯识别的可靠性。研究还揭示了LRMs不仅表现出人类类似的行为模式，还能根据不同任务灵活应用这些模式，特别是在某些家庭（如Qwen-3和DeepSeek-R1）中观察到更精细的认知习惯模式相似性。此外，通过将其扩展到安全相关的任务，研究发现某些习惯（如承担负责任的风险）与有害响应的生成密切相关。这些结果表明，研究LRMs CoTs中的持续行为模式是深入理解LLM行为异常的重要步骤。", "conclusion": "这项研究不仅揭示了LRMs具有类似人类的认知习惯，还发现了它们在不同任务中灵活应用这些习惯的能力。特别地，研究强调了某些习惯与产生有害响应之间的关联，这表明需要更深入地研究潜在的行为模式以更好地理解LLM的不当行为。这项研究的代码可在指定链接获取。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21577", "html_url": "https://arxiv.org/abs/2506.21577", "title": "跨语言感知提示调谐在多语言ASR中参数高效无缝语言扩展", "title_en": "Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR", "authors": "Hongli Yang,Sheng Li,Hao Huang,Ayiduosi Tuohan,Yizhou Peng", "background": "近期，多语言自动语音识别（ASR）的进步主要得益于大规模端到端模型，如Whisper。然而，语言干扰和在未见语言（语言扩展）上的性能不降反增仍然存在挑战。本文旨在解决这些问题", "innovation": "文章贡献了三种创新：1) 整体软提示调谐（Entire SPT），应用于编码器和解码器，增强特征提取和解码；2) 跨语言感知提示调谐（LAPT），利用跨语言相似性编码共享和特定语言特性，使用轻量级提示矩阵；3) SPT-Whisper，一种集成软提示调谐到Whisper中的工具包，实现高效的持续学习。实验表明Entire SPT和LAPT在语言扩展任务上分别比解码器软提示高出5.0%和16.0%，提供了动态多语言ASR模型的有效解决方案，且计算开销小", "conclusion": "研究展示了三种基于soft prompt的调谐技术，且实验结果表明这些技术特别是Entire SPT和LAPT，在多语言ASR中实现了高效的语言扩展，同时减少了计算成本。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21581", "html_url": "https://arxiv.org/abs/2506.21581", "title": "在跨学科领域评估密集检索器的鲁棒性", "title_en": "Evaluating the Robustness of Dense Retrievers in Interdisciplinary Domains", "authors": "Sarthak Chaturvedi,Anurag Acharya,Rounak Meyur,Koby Hayashi,Sai Munikoti,Sameera Horawalavithana", "background": "现有的评价基准可能会扭曲领域适应在检索模型中的真实益处，这会导致误导性的评估结果。通过两个特征差异极大的基准，即主题多样性、边界重叠和语义复杂度，研究展示了 domain adaptation 方法的效果在不同的评价体系下有所不同。使用环境法规文档检索作为案例研究，研究人员发现，相同领域的适应方法在不同的评价指标下显示出明显不同的效果。在一些明确划分主题边界的基准下，领域适应带来的改进非常有限；而在具有重叠语义结构的基准下，则表现出显著的提升。这表明选择不同的评价基准会极大地影响对检索系统有效性的评估，在专门领域的环境法规文档检索中表现为领域适应带来的效益被低估，而在具有重叠语义边界的基准中更能反映实际的复杂性能改.", "innovation": "该研究通过对比两个具有显著不同特征的基准，展示了在不同的领域细分方法下的评估效果差异显著。研究发现，具有明确主题边界的基准评估领域适应的效果为微小改进，而具有重叠语义结构的基准则展现了显著改进。通过主题多样性指标分析了这些差异，发现高性能的基准具有更高的上下文间余弦距离和更低的轮廓分值，这直接影响了观察到的性能差异。这些发现对于开发和部署在跨学科领域集成多个主题的 AI 系统具有重要意义，强调了选择适当的评估框架的重要性，特别是在具有重叠语义边界的环境中评估领域适应带来的好处更为显著，可以更好地反映实际的复杂性能改进.", "conclusion": "选择不同的评估基准对于评价检索系统的有效性至关重要，在专门领域如环境法规文档检索中表现尤为明显。具有广泛分离主题的基准往往低估领域适应带来的效益，而具有重叠语义边界的基准则能更好地反映出实际中的复杂性能改进。这些结果强调了在跨学科领域选择合适的评价框架对于开发和部署能够整合多个主题的 AI 系统的重要性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21578", "html_url": "https://arxiv.org/abs/2506.21578", "title": "HealthQA-BR：一个系统范围的基准揭示了大型语言模型中的关键知识缺口", "title_en": "HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models", "authors": "Andrew Maranhão Ventura D'addario", "background": "目前对大型语言模型（LLMs）在医疗保健领域的评估主要由以医生为中心、以英语语言为主要基准的标准主导，这造成了对模型能力误判的风险，忽略了医疗护理的多专业特性。为了提供更全面和真实的评估，我们引入了HealthQA-BR，这是首个针对葡萄牙语医疗系统的基准测试，涵盖了来自巴西全国执照和住院医师考试的5,632个问题，不仅评估医学及其专科知识，还涵盖了护理、牙科、心理学、社会工作和其他相关医疗保健专业。", "innovation": "HealthQA-BR 是首个全面评估葡萄牙语医疗系统的大型语言模型基准测试，它比现有基准更广泛地涵盖了医疗保健领域的不同专业，并且通过零样本评估展示了最先进的语言模型如 GPT 4.1 存在的知识缺陷，这些模型在许多专业领域的表现不尽如人意，特别是在社会工作领域。该基准测试揭示了“知识锋利”的现象，即模型在某些专业领域表现很好，在其他领域则表现不足。这种现象在所有模型中普遍存在。", "conclusion": "我们通过公开发布 HealthQA-BR 和我们的评估工具包，提供了评估 AI 准备情况的重要工具，这有助于超越单一评分的评估，并转向对整个医疗团队更具诚实性和细节性的审计。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21579", "html_url": "https://arxiv.org/abs/2506.21579", "title": "LLM2Rec：大型语言模型是序列推荐任务的强大嵌入模型", "title_en": "LLM2Rec: Large Language Models Are Powerful Embedding Models for Sequential Recommendation", "authors": "Yingzhi He,Xiaohao Liu,An Zhang,Yunshan Ma,Tat-Seng Chua", "background": "序列推荐的目标是通过建模相似用户或项目的过往行为中的协作过滤(CF)信号来预测用户未来的行为。传统的序列推荐器主要依赖于ID嵌入，通过高阶共现模式捕获CF信号。然而，这些嵌入仅依赖于过往交互，缺乏转移到未见过的领域的知识。近年来，大型语言模型（LLMs）的进步激发了基于文本的推荐方法，将项目表示从文本描述中获得。尽管这些方法增强了泛化能力，但它们不能编码CF信号，即潜藏的项目相关性和偏好模式，这对于有效的推荐至关重要。因此，研究人员提出了一种理想的嵌入模型，应该能够无缝地将CF信号与丰富的语义表示结合，以提高领域内和领域外推荐性能。", "innovation": "本文提出了LLM2Rec，这是一种新颖的嵌入模型，专门用于序列推荐任务。它通过结合大型语言模型的丰富语义理解和协作意识来实现。该模型采用两阶段训练框架：首先，协作监督微调，使大型语言模型适应基于过往交互推断项目关系；其次，在此基础上进行项目级嵌入建模，使专门化的大型语言模型编码语义和协作信息，形成结构化的项目嵌入模型。广泛的实验结果显示，LLM2Rec在领域内和领域外场景中都能有效提高推荐质量。研究发现强调了利用大型语言模型构建更具鲁棒性和泛化的嵌入模型的潜力。论文代码可在以下链接获得：this https URL.", "conclusion": "实验表明，LLM2Rec能够有效改善领域内和领域外的推荐质量。研究发现突显了利用大型语言模型构建更稳健、更泛化的嵌入模型的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21596", "html_url": "https://arxiv.org/abs/2506.21596", "title": "评价多模态大型语言模型在教育教科书问答中的表现", "title_en": "Evaluating Multimodal Large Language Models on Educational Textbook Question Answering", "authors": "Hessa A. Alawwad,Anas Zafar,Areej Alhothali,Usman Naseem,Ali Alkhathlan,Amani Jamal", "background": "多模态大型语言模型（MLLMs）在视觉-语言任务中取得了显著的成功，但在处理复杂的长期课程和难以用单张自然图像表示的详细教育图表方面的能力尚未得到充分测试。因此，本文首次评估了最先进的MLLMs在使用CK12-QA数据集的教科书问答（TQA）任务上的表现，并使用了包括LLaVA和LLaMA 3.2-Vision在内的多个视觉-语言模型。", "innovation": "引入了一种轻量级的多模态检索增强生成（RAG）管道，该管道将课程中的段落和图表整合到提示中。评估表明检索到的教育背景对模型的准确性和推理有显著影响，并揭示了当前在处理问题背景关系方面的局限性，还指出了未来研究的方向。", "conclusion": "研究表明，检索到的教育背景可以显著影响模型的准确性和推理能力，但也暴露了模型在处理问题背景关系方面的局限性和Noise，提出了未来研究的重要方向。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21583", "html_url": "https://arxiv.org/abs/2506.21583", "title": "code-mixed罗马乌尔都语推特中的希望言论检测：自然语言处理中的积极转变", "title_en": "Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing", "authors": "Muhammad Ahmad,Muhammad Waqas,Ameer Hamza,Ildar Batyrshin,Grigori Sidorov", "background": "希望是一种正面的情绪状态，涉及对未来有利结果的期望。希望言论指的是促进乐观、韧性和支持的沟通，尤其是在不利的情境中。尽管自然语言处理（NLP）领域中对希望言论检测已经引起了关注，但现有的研究主要集中在高资源语言和标准化脚本上，经常忽略了如罗马乌尔都语等非正式和未充分代表的非标准形式。到目前为止，尚未有关于罗马乌尔都语混码语料中希望言论检测的研究。", "innovation": "该研究有两个关键贡献：一是首次引入了一个涵盖通用希望、现实希望、不切实际希望和非希望四类的多分类标注数据集；二是开发了一种基于注意力机制的自定义变压器模型，针对罗马乌尔都语的句法和语义变化进行了优化，并通过5折交叉验证进行了评估。此外，该模型通过显著性检验确认了性能提升的统计意义，结果表明XLM-R取得了最好的性能，得分为0.78，优于基线SVM（0.75）和BiLSTM（0.76），分别提高4%和2.63%。", "conclusion": "通过引入全面的数据集，探索和分析心理上希望的基础，并提出一种针对罗马乌尔都语句法和语义变化优化的自定义注意机制变压器模型，填补了包括罗马乌尔都语在内的低资源、非正式语言变体的包容性NLP研究中的关键空白。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21586", "html_url": "https://arxiv.org/abs/2506.21586", "title": "视觉语言模型能否理解模拟手势动作？", "title_en": "Can Vision Language Models Understand Mimed Actions?", "authors": "Hyundong Cho,Spencer Lin,Tejas Srinivasan,Michael Saxon,Deuksin Kwon,Natali T. Chavez,Jonathan May", "background": "非语言交流（NVC）在人类语言中扮演着重要角色，但由于其广泛范围和个体及文化间的高变异解释性，研究NVC具有挑战性。而模拟——一种仅通过手势、表情和动作来暗示意图的剧场技巧——是NVC的一个子集，其动作更加明确且被解释的偏差较低。因此，深入了解模拟动作是构建能够解释和传达NVC更细微方面的视觉语言模型的前提。基于此，研究者提出了一种新的基于视频的问答基准——MIME，包含86种模拟动作。作为运动捕捉数据的产物，MIME通过在角色、背景和视角方面引入干扰来评估识别鲁棒性。实验表明，现有的开放权重和基于API的视觉语言模型在MIME上的表现明显逊于人类，这表明在促进人类手势理解的鲁棒性方面仍需更多研究。", "innovation": "提出了一个新的视觉-语言多模态评价基准——MIME，其中包含86种模拟动作。该基准利用运动捕捉数据构建，并通过引入角色、背景和视角的干扰来评估识别的鲁棒性，以此来提供视觉语言模型在理解和解释模拟动作方面的真实挑战。研究发现现有的视觉语言模型在这方面表现不如人类，这为未来的相关研究指明了方向。", "conclusion": "现有的开放权重和基于API的视觉语言模型在理解模拟动作方面表现不佳，这表明需要进一步研究以便增强这些模型对人类手势的理解。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21602", "html_url": "https://arxiv.org/abs/2506.21602", "title": "BiMark：Large Language模型中无偏多层水印", "title_en": "BiMark: Unbiased Multilayer Watermarking for Large Language Models", "authors": "Xiaoyan Feng,He Zhang,Yanjun Zhang,Leo Yu Zhang,Shirui Pan", "background": "近年来，大规模语言模型（LLMs）的快速发展引发了对其生成文本真实性的担忧，推动了对可靠鉴定机制的监管需求。尽管水印技术提供了潜在的解决方案，但现有方法难以同时满足保持文本质量、实现模型无关的检测和提高水印承载量这三个关键要求，这对于实际应用至关重要。", "innovation": "我们提出了BiMark，一种新的水印框架，通过以下三个关键创新实现上述要求：（1）一种无偏的位翻转重加权机制，实现模型无关的检测；（2）多层架构，增强检测能力同时不降低生成质量；（3）信息编码方法，支持多比特水印。我们的研究验证了BiMark在短文本提取率上与现有最先进的多比特水印方法相比可提升30%，同时保持了文本质量的优越性，并在下游任务如摘要和翻译中与未标记的文本表现相当。", "conclusion": "我们的理论分析和大量实验表明，BiMark在保持文本质量和提高短文本提取率方面优于现有方法，同时适用于下游任务，并通过多层架构和信息编码方法实现了水印的高效嵌入和检测。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21605", "html_url": "https://arxiv.org/abs/2506.21605", "title": "MemBench: 朝着对基于LLM的代理记忆进行全面评估的方向", "title_en": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents", "authors": "Haoran Tan,Zeyu Zhang,Chen Ma,Xu Chen,Quanyu Dai,Zhenhua Dong", "background": "近期研究表明，记忆机制对于基于大规模语言模型（LLM）的代理至关重要，能够使它们存储观测信息并适应动态环境。然而，评估这些记忆能力仍然存在挑战。现有的评估通常受限于记忆水平和交互场景的多样性不足，且缺乏全面的评估指标来从多角度反映记忆能力。因此，有必要构建一个更全面的数据集和基准来解决这些问题，以评估基于LLM的代理的记忆能力。", "innovation": "该论文提出了一种名为MemBench的新基准，结合了事实记忆和反思记忆的不同层次，并提出了参与和观察等多种交互场景。这些创新使评估可以从有效性和效率等多个方面全面评估基于LLM的代理的记忆能力。", "conclusion": "该研究通过提供一个包含更全面的评估方法的数据集和基准（MemBench），为研究社区提供了一个新的工具，以全面评估基于LLM的代理的记忆能力，有效、高效且具有容量。数据集和项目已发布，供研究人员使用。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21600", "html_url": "https://arxiv.org/abs/2506.21600", "title": "Structured Attention Matters to Multimodal LLMs in Document Understanding", "title_en": "Structured Attention Matters to Multimodal LLMs in Document Understanding", "authors": "Chang Liu,Hongkai Chen,Yujun Cai,Hang Wu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang", "background": "文档理解仍然是多模态大型语言模型（MLLMs）的一个重大挑战。尽管以往的研究主要集中在通过精确的多模态查询定位证据页，但我们的工作探讨了一个重要但常被忽视的问题：输入格式如何影响文档理解性能。研究发现，原始的OCR文本往往反而损害而不是改进MLLMs的性能。这是由于关注度分散和结构丢失导致的反直觉结论。", "innovation": "我们提出了一种新颖的结构保留方法，使用LaTex范式编码文档元素，保持至关重要的层级组织和空间关系。通过注意分析，我们发现结构化的文本在文本和视觉内容上诱导了结构化的注意模式，引导模型专注于语义上重要的区域，从而减少注意资源的浪费。这种方法显著提升了MLLMs在各种文档类型的文档问答性能，而无需进行结构修改或追加训练。", "conclusion": "我们的研究表明，结构化的注意力在多模态MLLMs的文档理解中是重要的，通过处理原始OCR文本的情况下改进了模型的文档理解性能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21599", "html_url": "https://arxiv.org/abs/2506.21599", "title": "基于强化学习微调的大型语言模型用于下一个POI推荐", "title_en": "Reinforcement Fine-Tuned Large Language Models for Next POI Recommendation", "authors": "Peibo Li,Shuang Ao,Hao Xue,Yang Song,Maarten de Rijke,Johan Barthélemy,Tomasz Bednarz,Flora D. Salim", "background": "大规模语言模型（LLMs）已在下一步地点兴趣（POI）推荐任务中被采用。典型的LLM推荐系统可分为两类：提示驱动模型和监督微调（SFT）模型。提示驱动模型通常提供更大的输出灵活性但准确性较低，而SFT模型虽然性能更高，但在监督微调中存在根本性不匹配的问题：下一步POI推荐数据不适合进行监督微调。在SFT中，模型被训练来重现确切的地面真相，但每次训练示例只提供了一个目标POI，因此没有一个用于生成top-k列表的真实情况。为解决这一问题，我们提出了Refine-POI，一个用于下一步POI推荐的强化学习微调框架。", "innovation": "我们引入了基于推荐的奖励机制，使LLMs能够在每次示例只有一个目标POI的情况下，学习生成top-k推荐列表。实验结果表明，Refine-POI实现了最先进的top-k推荐性能。", "conclusion": "实验结果表明，Refine-POI达到了最先进的top-k推荐性能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21582", "html_url": "https://arxiv.org/abs/2506.21582", "title": "VIDEE：借助智能代理进行文本分析的可视化和互动分解、执行与评估", "title_en": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents", "authors": "Sam Yu-Te Lee,Chengyang Ji,Shicheng Wen,Lifu Huang,Dongyi Liu,Kwan-Liu Ma", "background": "传统的文本分析需要具备自然语言处理（NLP）或文本分析的专业知识，这对入门级分析师构成了一定的障碍。近年来，大型语言模型（LLMs）的发展改变了NLP的格局，使得更易访问和自动化的文本分析成为可能（如主题检测、总结、信息提取等）.", "innovation": "我们介绍了一种名为VIDEE的系统，旨在支持入门级数据分析师利用智能代理进行高级文本分析。VIDEE实现了由三个阶段组成的人机协作工作流程：(1) 分解阶段，利用了带有人工判断的蒙特卡洛树搜索算法来支持生成性推理；(2) 执行阶段，生成可执行的文本分析流水线；(3) 评估阶段，整合了基于LLM的评估和可视化以支持用户对执行结果的验证。研究通过两个定量实验评估了VIDEE的有效性，并分析了常见的代理错误。通过用户研究，展示了该系统对于不同水平的NLP和文本分析经验的参与者来说具有可用性，并揭示了不同的用户行为模式，识别了人机协作的设计准则，并验证了VIDEE在非专家用户中的实用价值，同时为未来智能文本分析系统改进提供了指导.", "conclusion": "用户研究证实了VIDEE系统的可用性，并揭示了用户行为的不同模式。研究发现对人机协作的设计具有启示意义，验证了VIDEE在非专家用户中的实用性，并为未来智能文本分析系统的改进提供了指导。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21597", "html_url": "https://arxiv.org/abs/2506.21597", "title": "ClinIQLink 2025 年医疗问答共享任务概述", "title_en": "Overview of the ClinIQLink 2025 Shared Task on Medical Question-Answering", "authors": "Brandon Colelough,Davis Bartels,Dina Demner-Fushman", "background": "本文介绍了ClinIQLink，一项与2025年ACL举办的第24届BioNLP工作坊相关的共享任务，旨在测试大型语言模型在面向全科医生的医学问题回答方面的性能。该挑战提供了4,978对专家验证过的、基于医学资料的问题-答案配对，涵盖了七种格式：真/假、多项选择、无序列表、简答题、简答逆问题、多跳推理和多跳逆推理。参与系统的容器镜像（Docker或Apptainer）将在CodaBench平台或马里兰大学的Zaratan集群上执行。自动化检测工具（任务1）通过精确匹配对封闭式问题进行评分，对开放式问题则使用三层嵌入度量进行评分。随后，由医师组成的评审委员会（任务2）将审核顶级模型的回答。", "innovation": "ClinIQLink共享任务引入了大量基于医学资源的专家验证问题数据，覆盖多种问题格式，提供了详细的评分机制，包括自动评分和人工评审，旨在全面检验大型语言模型在医疗领域的表现能力，特别是面向全科医生的医学问题回答能力。", "conclusion": "ClinIQLink共享任务不仅为大型语言模型在医学问题回答方面的评价提供了一个基准，而且通过引入多层次的评价机制，提高了模型评估的全面性和准确性。未来的研究可以进一步探索如何优化模型，以更好地应对多跳推理等复杂问题。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21606", "html_url": "https://arxiv.org/abs/2506.21606", "title": "大型语言模型作为文化动态的象征DNA", "title_en": "Large Language Models as symbolic DNA of cultural dynamics", "authors": "Parham Pourdavood,Michael Jacob,Terrence Deacon", "background": "本文提出了一种关于大型语言模型（LLMs）的新概念，将其视为外部化的信息底物，类似于DNA对人类文化动态的作用。文章挑战了将LLMs视为自主智能或仅仅是程序化模仿的单一视角，而是认为它们在人类文化中扮演了更为重要的角色，即作为人类符号表达压缩模式的存储库。这些模式只有通过人类重新解释才变得有意义，从而形成一个循环的反馈循环，激发人类的创造性过程。文章通过分析压缩性、去压缩性、外部化和递归性这四个通用特征，阐述了LLMs如何像DNA一样，作为一种外部化和压缩的信息存储介质，用于保存有用的文化规律，而不包含对人类体验的具体理解。", "innovation": "文章创新性地将大型语言模型（LLMs）与DNA进行类比，提出LLMs作为人类文化中压缩和外部化的信息存储器，储存在模式中的人类符号表达和文化规律。这改变了传统的LLMs被视为自主智能或仅仅是程序化模仿的认知，强调了LLMs在文化传承中的重要作用。文章还提出，LLMs的价值不在于与人类智能竞争，而是提供一种自我反思和低风险假设检验的工具，通过模拟环境来促进文化演进。", "conclusion": "总的来说，LLMs作为一种框架工具，能够帮助人类自省和生成有关自身的全新假设，同时保持必要的解释人类审美和规范、进行实际检验的环境。这为理解和未来演进人类文化提供了新的视角。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21584", "html_url": "https://arxiv.org/abs/2506.21584", "title": "小型LLM中的实证证据及其基于提示的缓解技术", "title_en": "Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques", "authors": "J. Koorndijk", "background": "当前文献表明，对齐漂移（欺骗性对齐）是大型语言模型的一个新兴特性。本文通过呈现首个小型指令调整模型（如LLaMA 3 8B）也能表现出对齐漂移的实验证据，进一步加深了我们对这一现象的理解。研究还展示了仅通过提示干预（如道义框架和思考笔记本推理）可以显著减少这种行为，而无需改变模型内部结构，这挑战了提示伦理简单和欺骗性对齐需要规模的假设。", "innovation": "本文首次通过对LLaMA 3 8B进行实验，展示了小型指令调整模型也能出现对齐漂移现象，并且通过仅提示干预的方法有效减少了这种现象，而不修改模型内部结构。同时，引入了区分浅层和深层欺骗的概念，并提出了新的分类框架。这些发现对理解语言模型中的欺骗行为有很大的贡献，并强调了需要在不同模型规模和应用场景中进行对齐评估。", "conclusion": "这项研究结果进一步澄清了语言模型中欺骗行为的理解，并强调了需要在不同模型规模和部署场景下进行对齐评估的必要性。此外，提醒人们不要低估提示和伦理框架在对抗欺骗性对齐方面的潜力，同时也揭示了浅层和深层欺骗之间的区别。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21607", "html_url": "https://arxiv.org/abs/2506.21607", "title": "CORE-KG: 一种基于LLM的人口走私网络知识图谱构建框架", "title_en": "CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人口走私网络日益表现出高度的适应性和复杂性，使得对其进行分析变得愈发困难。现有的法律案例文件提供了有价值的信息，但这些文件往往是非结构化的，词汇量大，充满了模糊或不断变化的引用，这对自动化知识图谱(KG)的构建构成了挑战。现有的KG方法通常依赖于静态模板，缺乏核心指代解析能力，而基于最近的大语言模型(LLM)的方法则常常产生噪音大且不完整的图谱，原因是这些方法容易产生妄想，同时由于缺乏指导提取，导致节点重复。", "innovation": "本文提出了CORE-KG，这是一个模块化的框架，用于从法律文本中构建可解释的知识图谱。该框架采用两步流水线：首先，通过顺序结构化的LLM提示进行类型感知的核心指代解析；其次，使用基于领域指导的指令进行实体和关系提取，这些指令是基于调整后的GraphRAG框架构建的。相比于基于GraphRAG基线方法，CORE-KG减少了33.28%的节点重复和38.37%的法律噪音，从而生成了更加清洁且连贯的图结构。", "conclusion": "这些改进使CORE-KG成为分析复杂犯罪网络的强大基础。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21608", "html_url": "https://arxiv.org/abs/2506.21608", "title": "SysTemp: 基于模板生成的SysML v2系统", "title_en": "SysTemp: A Multi-Agent System for Template-Based Generation of SysML v2", "authors": "Yasmine Bouamra,Bruno Yun,Alexandre Poisson,Frédéric Armetta", "background": "SysML v2模型的自动生成在复杂系统工程中面临巨大挑战，原因是学习数据稀少且语法复杂。现有方法在创建SysML v2模型时，特别是从自然语言规范开始，遇到了显著的障碍。为此，需要开发一种新方法来简化和提升这一过程的质量和效率。SysTemp系统基于多智能体系统，并包含一个模板生成器来结构化生成过程，旨在解决这些问题。", "innovation": "SysTemp系统通过引入基于模板的方法和多智能体系统架构，为自动生成SysML v2模型提供了新的解决方案。这一方法不仅能够提高模型生成过程的效率，还能确保生成的模型质量更高，更符合规范要求。", "conclusion": "研究表明，SysTemp系统在提升SysML v2模型生成质量方面具有显著优势。通过多智能体系统和模板生成器的结合，SysTemp能够有效地处理复杂的语法和语义结构，为复杂的系统工程提供更好的支持。未来的研究可能会进一步探索结合其他先进技术和方法来增强SysTemp的功能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21604", "html_url": "https://arxiv.org/abs/2506.21604", "title": "评估VisualRAG：企业在文档理解中的跨模态性能量化", "title_en": "Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding", "authors": "Varun Mannam,Fang Wang,Xin Chen", "background": "当前的多模态生成人工智能评估框架难以建立可信度，阻碍了在可靠性至关重要的企业环境中采用这些技术。本文探讨了在企业文档智能应用中逐步整合图像、文本、文摘和OCR等多模态输入于VisualRAG系统中的问题，并提出了一个系统化的定量基准框架来衡量这种集成的可信度。", "innovation": "提出了一种系统化且定量的基准框架，用于衡量跨模态输入在VisualRAG系统中逐步整合的可信度。该方法建立了技术度量和技术可信度之间的定量关系。研究表明，在文本仅有的基线性能上，通过30%文本、15%图像、25%文摘和30%OCR的加权，性能提高了57.3%，同时保持了计算效率。此外，研究还对比了基础模型在标题生成和OCR提取中的不同影响，明确了这些因素对企业AI可靠性的重要性。", "conclusion": "本文通过提供一种严谨的框架来量化和提升跨模态RAG系统的可信度，为关键企业应用中的负责任AI部署提供了支持。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21609", "html_url": "https://arxiv.org/abs/2506.21609", "title": "从思考到输出：推理语言模型的思维链和文本生成特征", "title_en": "From Thinking to Output: Chain-of-Thought and Text Generation Characteristics in Reasoning Language Models", "authors": "Junhao Liu,Zhenhao Xu,Yuxin Fang,Yichuan Chen,Zuobin Ying,Wenhan Chang", "background": "近年来，大型语言模型（LLMs）取得了显著的进步，显示出其在复杂推理方面的能力不断增强。然而，现有的研究大多忽略了对这些模型推理过程和输出的全面系统的比较，尤其是它们的自我反思模式（称为“顿悟时刻”）以及跨领域的关联性。研究团队提供了一个新的框架，旨在分析四种顶尖推理模型（GPT-o1，DeepSeek-R1，Kimi-k1.5，Grok-3）的推理特征，通过关键词统计和LLM作为裁判的范式进行研究。该框架将这些模型的内部思考过程与最终输出联系起来。研究使用的数据集涵盖了真实世界场景下的问题，涉及逻辑推理、因果推理和多步问题解决等方面。此外，还提出了一套评估推理连贯性和输出准确性的方法。研究结果揭示了这些模型在推理过程中的探索与利用平衡、问题处理方式和结论形成过程中的各种模式。通过定量和定性比较，这些模型在推理深度、依赖中间步骤的程度以及思维过程和输出模式与GPT-o1之间的相似性方面表现出不同之处。这项工作提供了关于计算效率与推理稳健性之间权衡的有价值的见解，并为增强模型设计和评估提供了实际建议。", "innovation": "本文提出了一种新的框架，利用关键词统计和LLM作为裁判的范式分析大型语言模型的推理特性。该框架将模型的内部思维过程与其最终输出联系起来，提供了一种系统化的分析方法。研究还包括一套新的评估标准，用于衡量推理的连贯性和输出的准确性。研究成果揭示了不同模型在推理过程中的不同特性，并提供了关于计算效率和推理稳健性之间权衡的见解。", "conclusion": "本文揭示了这些模型在推理过程中的不同模式，包括探索与利用平衡、问题处理方式和结论形成过程。通过对计算效率与推理稳健性之间的权衡进行定量和定性比较，研究指出了不同模型间的差异。研究成果为提高模型设计和评估提供了实际建议，并强调了进一步研究的必要性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21617", "html_url": "https://arxiv.org/abs/2506.21617", "title": "推荐系统中基于贝叶斯指导的顺序采样多样性", "title_en": "Bayesian-Guided Diversity in Sequential Sampling for Recommender Systems", "authors": "Hiba Bederina,Jill-Jênn Vie", "background": "在内容同质化日益严重和用户参与度下降的背景下，如何在推荐系统中平衡用户相关性和内容多样性成为了一个越来越关键的挑战。现有的推荐系统倾向于提供同质的内容，这导致了用户兴趣的丧失和个性化体验的缺失。因此，需要提出一种新的策略来解决这一问题。", "innovation": "本文提出了一个新颖的框架，采用了多目标、上下文相关的顺序采样策略。通过基于贝叶斯更新的技术动态调整评分以优化多样性。奖励函数融合了多种多样性度量（如调整相似性子矩阵的对数行列式体积和岭杠杆分数）和多样性增益不确定性项，以处理探索与利用之间的权衡。此外，还建模了批内和批间的多样性，以促进偶然发现并减少重复性。通过帕累托最优项集的主导排序方法，实现了每次迭代中的自适应和平衡选择。", "conclusion": "在实际数据集上的实验表明，该方法在不牺牲相关性的前提下显著提高了多样性，表明其在大规模推荐场景中增强用户体验的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21614", "html_url": "https://arxiv.org/abs/2506.21614", "title": "LastingBench：防御知识泄露确保基准效能", "title_en": "LastingBench: Defend Benchmarks Against Knowledge Leakage", "authors": "Yixiong Fang,Tianran Sun,Yuling Shi,Min Wang,Xiaodong Gu", "background": "大语言模型（LLMs）的复杂性增加可能导致它们在标准问答（QA）基准上通过记忆特定任务数据来“作弊”，这会影响基准评估的有效性，使其不再反映模型的真实能力，而是数据渗漏的效果。尽管之前的研究所集中于检测数据渗漏，但很少关注减轻其影响和保持基准的长期效用。", "innovation": "本文介绍了一种新的框架称为LastingBench，旨在通过扰动不断强化和保护现有基准，防止知识泄露。LastingBench通过识别上下文中的渗漏点并将其重写为反事实点，打破记忆机制同时保持基准的原始评估意图。实证研究表明，LastingBench在显著减少记忆效应方面非常有效，提供了一种实用且可扩展的解决方案，确保基准的长期稳健性，促进更公平和可解释的大语言模型评估。", "conclusion": "LastingBench提供了一种实用且可扩展的解决方案，确保基准的长期稳健性，促进更公平和可解释的大语言模型评估。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21612", "html_url": "https://arxiv.org/abs/2506.21612", "title": "AdaptGOT: 一种用于自适应上下文POI表示学习的预训练模型", "title_en": "AdaptGOT: A Pre-trained Model for Adaptive Contextual POI Representation Learning", "authors": "Xiaobin Ren,Xinyu Zhu,Kaiqi Zhao", "background": "POI嵌入方法在推荐和分类等新型POI任务推动下取得了显著进展。然而，现有的任务特定、端到端模型仍然面临多项挑战，包括不充分的多上下文采样策略、多个POI上下文探索不足、通用性有限以及泛化能力不足等问题。", "innovation": "为了克服这些挑战，本文提出了AdaptGOT模型，结合了自适应表示学习技术和地理共现-文本（GOT）表示，特别注重地理位置、共现和文本信息。AdaptGOT模型具有三种关键组件：（1）上下文邻域生成，综合利用KNN、基于密度、基于重要性和类别感知等多种先进的混合采样策略来捕捉复杂的上下文邻域；（2）增强注意力机制的高级GOT表示，旨在生成高质量、定制化的表示并高效地捕捉POI之间的复杂关系；（3）基于MoE的自适应编码器-解码器架构，通过最小化不同上下文之间的杰潓-沙恩松散度来确保拓扑一致性和上下文表示的丰富性。", "conclusion": "在两个现实世界数据集和多种POI任务上的实验验证了提出AdaptGOT模型的优越性能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21615", "html_url": "https://arxiv.org/abs/2506.21615", "title": "使用生成增强检索和临床实践指南精炼医疗诊断", "title_en": "Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines", "authors": "Wenhao Li,Hongkuan Zhang,Hongwei Zhang,Zhengxu Li,Zengjie Dong,Yafan Chen,Niranjan Bidargaddi,Hong Liu", "background": "当前的医疗语言模型通常从大型语言模型（LLMs）改编而来，因为ICD代码（国际疾病分类代码）在电子健康记录（EHRs）中容易获得，但ICD代码未能捕捉到临床医生在诊断过程中使用的精细、富有上下文的推理过程。临床医生会综合患者的各种信息，并参考临床实践指南（CPGs）进行基于证据的决策。现有模型由于这种不匹配，限制了它们的临床应用价值。", "innovation": "本文提出了一种生成增强检索框架GARMLE-G，将医疗语言模型的输出与权威的CPGs相结合。GARMLE-G避免了幻觉生成，因为它直接检索权威的指南内容，而不需要依赖模型生成的文本。该框架通过（1）将LLM预测与EHR数据结合生成语义丰富的查询，（2）利用嵌入相似性检索相关CPG知识片段，（3）融合指南内容与模型输出以生成临床对齐的建议来工作。实验表明，相比于基于检索增强生成的方法，该系统在高血压诊断方面在检索精度、语义相关性和临床指南遵从性方面表现出更优的表现，同时保持了轻量级的架构，适合局部医疗部署。", "conclusion": "这项工作提供了一种可扩展、低成本且无幻觉的方法，将医疗语言模型与基于证据的临床实践紧密结合，具有广泛临床部署的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21619", "html_url": "https://arxiv.org/abs/2506.21619", "title": "IndexTTS2：情感表达与持续时间控制的突破性自动回归零样本文本转语音", "title_en": "IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech", "authors": "Siyi Zhou,Yiquan Zhou,Yi He,Xun Zhou,Jinchao Wang,Wei Deng,Jingchen Shu", "background": "大型文本转语音(TTS)模型通常被划分为自回归和非自回归系统。虽然自回归系统在语音自然度方面表现出一定的优势，但它们按令牌生成的方式使得精确控制合成语音的时长变得困难。这种限制在需要严格音视频同步的应用中尤为重要，比如配音。", "innovation": "提出了一种名为IndexTTS2的新颖方法，该方法为自动回归模型提供了亲和的说话时长控制方式。该方法支持两种生成模式：一种允许明确指定生成令牌的数量以实现精确时长控制；另一种不需要手动输入，并由模型自由生成语音并保留输入提示的韵律特征。此外，IndexTTS2能够将情绪表达和说话者身份分离，从而独立控制音色和情绪。为了保持清晰表达，引入了GPT潜在表示来提高语音稳定性。为了降低情绪控制门槛，我们设计了一种基于文本描述的软指令机制，这使得通过自然语言输入有效指导带有期望情绪倾向的语音生成成为可能。实验结果表明，IndexTTS2在零样本设置下优于现有最先进的TTS模型，在单词错误率、说话者相似性和情绪忠实度方面表现更佳。", "conclusion": "IndexTTS2在语音稳定性和情绪表达方面取得了显著的进步，能够在零样本设置下精确控制时长和情绪，为自动回归模型提供了有效的指导机制。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21618", "html_url": "https://arxiv.org/abs/2506.21618", "title": "TrajTok: 2025 年 Waymo 开放模拟车辆代理挑战的技术报告", "title_en": "TrajTok: Technical Report for 2025 Waymo Open Sim Agents Challenge", "authors": "Zhiyuan Zhang,Xiaosong Jia,Guanyu Chen,Qifeng Li,Junchi Yan", "background": "该技术报告介绍了一种用于行为生成模型的轨迹标记器 TrajTok，该模型基于离散的下一个标记预测。这种标记器结合了数据驱动和基于规则的方法，具有更好的覆盖范围、对称性和鲁棒性，并引入了一种空间感知的标签平滑方法来优化交叉熵损失。该报告还展示了在 Waymo Open Sim Agents 挑战 2025 中采用此标记器和损失后取得的卓越性能，现实得分达到了0.7852。", "innovation": "TrajTok 标记器结合了数据驱动和规则驱动的方法，具有更好的覆盖范围、对称性和鲁棒性，并引入了空间感知的标签平滑方法来优化交叉熵损失。这些创新使得 TrajTok 在行为生成模型中表现优异，尤其是在 Waymo Open Sim Agents 挑战 2025 中取得了出色的现实得分。", "conclusion": "研究团队采用 TrajTok 标记器和新的损失函数，成功提高了 SMART 模型的表现，在 Waymo Open Sim Agents 挑战 2025 中获得了现实得分0.7852的优异成绩，并表示未来会开源代码。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21611", "html_url": "https://arxiv.org/abs/2506.21611", "title": "多模态能否实现更优的时间序列预测？", "title_en": "Does Multimodality Lead to Better Time Series Forecasting?", "authors": "Xiyuan Zhang,Boran Han,Haoyang Fang,Abdul Fatir Ansari,Shuai Zhang,Danielle C. Maddix,Cuixiong Hu,Andrew Gordon Wilson,Michael W. Mahoney,Hao Wang,Yan Liu,Huzefa Rangwala,George Karypis,Bernie Wang", "background": "近年来，越来越多的研究开始探索如何将文本信息整合到基础模型中以用于时间序列预测。然而，是否以及在何种条件下多模态集成能够持续提升预测效果仍不清楚。本文评估了两种流行的多模态时间序列预测方法：基于对齐的方法，旨在对齐时间序列和文本表示；以及基于提示的方法，直接利用大型语言模型进行预测。尽管先前的研究报告了多模态输入的优势，但发现这些效果在不同数据集和模型上并非普遍适用，有时甚至多模态方法的表现不如最强的单模态基线模型。", "innovation": "本文系统地研究了时间序列预测中整合文本信息的效果，在14项来自7个不同领域的预测任务上开展了评估，涵盖健康、环境和经济学领域。通过分离模型架构特性和数据特征的影响，本文揭示了在哪些情况下文本信息有助于时间序列预测，为何时以及如何使用多模态方法提供了实用指导。", "conclusion": "我们的实证发现显示，对于模型方面，文本信息的整合主要在以下情况下最为有益：1) 高效力的文本模型；2) 比较弱的时间序列模型；3) 适当对齐策略。对于数据方面，更多的训练数据和文本提供的补充预测信号比时间序列本身所能捕捉到的内容，更容易带来性能提升。这些发现为时间序列预测任务中使用多模态提供了实际指南，并明确了何时它不会发挥作用。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21621", "html_url": "https://arxiv.org/abs/2506.21621", "title": "开放证明语料库：大规模研究生成的人工智能模型的数学证明", "title_en": "The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs", "authors": "Jasper Dekoninck,Ivo Petrov,Kristian Minchev,Mislav Balunovic,Martin Vechev,Miroslav Marinov,Maria Drencheva,Lyuba Konova,Milen Shumanov,Kaloyan Tsvetkov,Nikolay Drenchev,Lazar Todorov,Kalina Nikolova,Nikolay Georgiev,Vanesa Kalinkova,Margulan Ismoldayev", "background": "近年来，大规模语言模型（LLMs）在数学证明生成方面取得了显著进展，但进一步的进步受限于缺乏包含大量高质量、人类评估的证明的大规模数据集。尽管创建此类数据集代价高昂，但它对于训练的改进和正式证明生成能力的严格分析至关重要。目前的研究旨在克服缺乏这样的数据集的问题，为此提出了Open Proof Corpus（OPC），一个包含5000多个由最新LLM生成的人类评估证明的数据集。这些证明涵盖了美国数学奥林匹克（USAMO）和国际数学奥林匹克（IMO）等著名数学竞赛的问题解法。利用OPC，研究者探讨了自动化证明生成的关键问题，包括自然语言与形式证明之间的性能差距、最终答案准确性和完整证明有效性的差异，以及最佳n次选择对证明质量的影响。最后，通过在OPC上微调模型，展示了OPC在评估证明正确性任务上的应用潜力，研究者得到了一个表现与Gemini-2.5-Pro相当的8亿参数模型。", "innovation": "提出了Open Proof Corpus（OPC），为数学证明生成研究提供了首个包含大量正确的人工智能模型生成解法的数据集，包括来自USAMO和IMO的著名数学竞赛问题。利用这一数据集，研究探讨了自动化证明生成中的关键问题，并展示了OPC在证明正确性评估任务上的实用性。", "conclusion": "研究利用OPC探讨了自动化证明生成中的关键问题，并展示了OPC在证明正确性评估任务上的应用潜力。通过在OPC上微调模型，得到了一个表现与最先进模型相当的LSTM模型，表明OPC可以有效地推动数学证明生成领域的研究进度。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21627", "html_url": "https://arxiv.org/abs/2506.21627", "title": "FrankenBot：基于视觉语言模型的类脑模块化机器人操作 orchestration", "title_en": "FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models", "authors": "Shiyi Wang,Wenbo Li,Yiteng Chen,Qingyao Wu,Huiping Zhuang", "background": "在复杂、动态且不规则的现实环境中开发能够执行广泛任务的通用机器人操作系统一直是个挑战。研究表明，要实现与人类相似的高效和鲁棒的操作，机器人的系统需要整合多种功能，如任务规划、策略生成、异常监控和处理以及长期记忆，以实现跨所有功能的高效率操作。视觉语言模型（VLMs）在海量多模态数据上进行预训练，能够获取丰富的世界知识，展示出卓越的场景理解和多模态推理能力。但现有方法通常只实现机器人脑中的单一功能或部分功能，未能整合成统一的认知架构。因此，提出了一种基于视觉语言模型的类脑模块化机器人操作框架FrankenBot。", "innovation": "FrankenBot 通过将任务规划、策略生成、记忆管理及低级接口分别映射至大脑的不同部位（如皮层、小脑、颞叶-海马体复合体和脑干），并在模块间设计有效协调机制，实现了全面的功能和高操作效率，并通过模拟和真实机器人环境下的全面实验，证明了其在异常检测与处理、长期记忆、操作效率和稳定性方面具有显著优势，而无需任何微调或重新训练。", "conclusion": "本研究通过FrankenBot 提出了一个视觉语言模型驱动的、类脑结构的机器人操作框架，这一框架能够在保持全面功能的同时确保高操作效率，并且已经通过深入的实验验证了其在多种机器人操作任务中的优越性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21620", "html_url": "https://arxiv.org/abs/2506.21620", "title": "大型语言模型在线讨论中的拟人化表现：基于2016年美国政治的模拟研究", "title_en": "How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit", "authors": "Daniele Cirulli,Giulio Cimini,Giovanni Palermo", "background": "大型语言模型（LLMs）已经成为强大的自然语言生成工具，应用范围从内容创作到社会模拟。LLMs在政治相关在线讨论中的使用引发了机会和担忧。本研究旨在评估LLMs在真实世界、高度争议性场景下的表现：2016年美国总统大选期间的Reddit讨论。研究中，GPT-4被要求以真实或虚构的党派身份生成评论，通过政治立场、情感和语言特征分析生成的评论，与真实用户贡献进行比较，并将其与随机模型进行基准测试。研究发现，GPT-4能够生成真实且有倾向性的评论，更容易形成共识而非对立。此外，真实和虚构评论在语义嵌入空间中是可以区分开的，但通过手动检查则难以辨别。这些发现揭示了LLMs可能以潜入在线讨论、影响政治辩论和塑造政治叙述的方式发挥作用，反映出AI驱动的言论操纵的更广泛影响。", "innovation": "本研究首次系统地通过模拟实验评估大型语言模型在高度政治化在线讨论中的表现。使用具体场景（2016年美国总统大选期间的Reddit讨论），并让GPT-4模拟真实和虚构的党派用户生成评论，随后通过多重标准分析这些评论。从创新性角度来看，本研究不仅展示了大型语言模型生成拟真评论的能力，还通过量化方法评估了模型在形成共识和造成立场对立中的表现差异，并发现这两种评论在语义嵌入空间中可以区隔，但难以通过人工方式辨别。这些发现为理解大规模语言模型在在线讨论中的拟人化表现提供了新的视角，对未来政策制定和公众意识提升具有重要启示意义。", "conclusion": "本研究证明了大型语言模型有能力模仿人类在线讨论，但同时也揭示出这些模型在意见分歧和形成共识方面的偏好差异，重要的是，真实和虚构的讨论在语义嵌入空间中的区隔虽然可以通过工具识别，但在人为检查中却难以区分，这提示我们需要更加重视AI在在线社交媒体上的使用，以防止潜在的言论操纵和社会不稳。研究结果提供了一种新的方法来评估和测量大型语言模型在政治相关在线讨论中的作用，有助于建立更公正、透明的社会对话环境，并对未来的伦理和政策制定具有重要意义。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21625", "html_url": "https://arxiv.org/abs/2506.21625", "title": "Doc2SAR: 一种科学文献中药物结构-活性关系高保真提取的协同框架", "title_en": "Doc2SAR: A Synergistic Framework for High-Fidelity Extraction of Structure-Activity Relationships from Scientific Documents", "authors": "Jiaxi Zhuang,Kangning Li,Jue Hou,Mingjun Xu,Zhifeng Gao,Hengxing Cai", "background": "从科学文献和专利中提取药物的分子结构-活性关系（SARs）对于药物发现和材料研究至关重要。然而，这一任务由于文献格式的异质性和现有方法的局限性仍具有挑战性。传统基于规则的方法依赖于固定模板，难以适用于多样的文档布局。而通用的多模态大语言模型在这方面不够准确可靠，尤其是对于布局检测和光学化学结构识别（OCSR）等专业任务。", "innovation": "为了克服这些挑战，该论文引入了DocSAR-200，这是一种专门为评估SAR提取方法而设计的严格注释基准集，包含200篇科学文档。此外，作者提出了一种名为Doc2SAR的新颖协同框架，将领域特定工具与通过监督微调增强的多模态大型语言模型相结合。广泛的实验表明，Doc2SAR在多种文档类型中达到了最先进的性能，显著超越了领先的端到端基线方法。具体来说，Doc2SAR在DocSAR-200上的整体表格召回率为80.78%，超过了GPT-4o的51.48%。此外，Doc2SAR展示了其实用性，通过高效的推理，并提供了网页应用程序作为配套工具。", "conclusion": "该框架极大地促进了科学文献中药物结构-活性关系的高保真提取，为药物发现和材料研究提供了强有力的支持。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21628", "html_url": "https://arxiv.org/abs/2506.21628", "title": "Ark: 一种基于Python的开源机器人学习框架", "title_en": "Ark: An Open-source Python-based Framework for Robot Learning", "authors": "Magnus Dierking,Christopher E. Mower,Sarthak Das,Huang Helong,Jiacheng Qiu,Cody Reading,Wei Chen,Huidong Liang,Huang Guowei,Jan Peters,Quan Xingyue,Jun Wang,Haitham Bou-Ammar", "background": "虽然机器人技术在硬件方面取得了显著进展，如DARPA的城市挑战赛和机器人挑战赛，以及首次机器人踢拳比赛，但商业化自主性仍落后于机器学习的进步。主要障碍在于软件：当前的机器人堆栈需要陡峭的学习曲线，低级C/C++专业知识，分散的工具，复杂的硬件集成，与现代AI蓬勃发展的以Python为中心、文档详尽的生态系统形成鲜明对比。当前的软件栈使得机器人开发变得困难，阻碍了自主机器人在研究和商业部署中的应用普及性。为了解决这个问题，提出了一种新的开源框架ARK，旨在降低这些障碍，提高开发的便捷性和效率。", "innovation": "ARK是一种开源、以Python为主的机器人框架，旨在简化机器人的开发过程。它提供了一个类似Gym的环境接口，允许用户收集数据、预处理数据并使用最先进的模仿学习算法（如ACT，Diffusion Policy）训练策略，同时可以无缝切换到高保真模拟和物理机器人。此外，它具有轻量级的客户端-服务器架构和可选的C/C++绑定，确保在需要时达到实时性能。该框架配备了用于控制、SLAM、运动规划、系统识别和可视化等功能的可重用模块，并且具备与ROS的原生兼容性，简化了开发流程。", "conclusion": "通过将机器人技术和人工智能实践统一到一个以Python为基础的框架中，ARK降低了进入门槛，加快了自主机器人在研究和商业部署中的应用。其提供的快速原型制作、无缝硬件切换和端到端流程等功能，极大地提高了开发效率，使得开发与主流机器学习流水线一样便捷。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21722", "html_url": "https://arxiv.org/abs/2506.21722", "title": "揭示并赋予通用图像恢复中的扩散训练范式", "title_en": "Elucidating and Endowing the Diffusion Training Paradigm for General Image Restoration", "authors": "Xin Lu,Xueyang Fu,Jie Xiao,Zihao Fan,Yurui Zhu,Zheng-Jun Zha", "background": "扩散模型在图像恢复（IR）任务中表现出强大的生成能力，但由于其复杂结构和迭代过程，它们的实用性低于主流的重建基础普通IR网络。现有方法主要集中在优化网络架构和扩散路径，但忽略了将扩散训练范式整合到普通IR框架中的集成方法。这些限制导致扩散模型在实际应用中的局限性。", "innovation": "该论文通过系统分析时间步依赖性、网络层次结构、噪声级别关系以及多恢复任务相关性，揭示了将扩散训练范式适用于通用IR训练的关键原则，提出了基于扩散训练的新IR框架，并引入了一系列正则化策略来实现IR网络的同时恢复图像和生成表示，特别针对不同IR任务开发了增量训练范式和任务特定适配器，从而提升了统一多任务IR性能。", "conclusion": "实验结果表明，该方法显著增强了单任务IR中IR网络的一般化能力，并实现了在统一多任务IR中的优越性能。所提出的框架可以无缝集成到现有的通用IR架构中。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21622", "html_url": "https://arxiv.org/abs/2506.21622", "title": "调整基础语音识别模型以适应受损语音：一种基于语义重构的个性化德语语音方法", "title_en": "Adapting Foundation Speech Recognition Models to Impaired Speech: A Semantic Re-chaining Approach for Personalization of German Speech", "authors": "Niclas Pokel,Pehuén Moure,Roman Boehringer,Yingqiang Gao", "background": "由于脑瘫或遗传疾病等原因引起的言语障碍会对自动语音识别(ASR)系统构成重大挑战。尽管近期取得了进步，但如Whisper这样的ASR模型在处理非规范性语音时依然困难重重，原因在于训练数据有限且难以收集和标注非规范性语音样本。这项工作中探讨了如何利用一个实用且轻量级的个人化流程，增强ASR模型对言语障碍患者的声音识别能力，从而在保证语义连贯性的情况下，丰富小规模的缺陷语音数据集。此外，该方法应用于具有结构性言语障碍的儿童数据集显示了提高转录质量的潜力，能够减少具有特殊语音模式的个体的沟通障碍。", "innovation": "提出了一种实用且轻量级的个人化流程，该流程通过正式选择词汇并结合语义连贯性，丰富了小型缺陷语音数据集，旨在解决现有ASR模型在处理非规范性语音时存在的问题，尤其是在涉及如脑瘫等言语障碍患者语音识别时的挑战。该方法的应用展示了显著提高转录质量的潜力，适用性更广泛。", "conclusion": "本文通过语义重构的方法，有效地解决了因言语障碍而产生的非规范性语音识别问题，为提高ASR模型在有特殊语音模式的个体中的识别准确度提供了新的思路，有望在实际应用中降低这些个体的沟通障碍，展现出在实际应用场景中的巨大潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21635", "html_url": "https://arxiv.org/abs/2506.21635", "title": "AeroLite-MDNet: 轻量级多任务偏移检测网络用于无人机着陆", "title_en": "AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing", "authors": "Haiping Yang,Huaxing Liu,Wei Wu,Zuohui Chen,Ning Wu", "background": "无人机（UAVs）在土地测量、材料运输和环境监测等多种应用中被广泛使用。完成执行数据收集或检查任务后，无人机需要在指定的停机平台上安全降落以便存储或充电，这对于维护操作连续性至关重要。然而，由于GPS信号干扰等因素影响，精确降落仍然具有挑战性。针对这一问题，本文提出了基于新视图模型AeroLite-MDNet的偏移警告系统。该模型通过多尺度融合模块实现鲁棒的多尺度对象检测，并集成分割支路以提高方向估计效率。", "innovation": "本文创新地提出了一种偏移警告系统，由新型视觉模型AeroLite-MDNet驱动，模型融合了多尺度融合模块以实现鲁棒的多尺度对象检测，并包含分割支路以实现高效的方向估测。此外，本文贡献了一个新的评估指标——平均警告延迟（AWD），用于衡量系统的偏离检测敏感度。并且，提供了一个新的数据集UAVLandData，用于支持训练和评估中的真实场景着陆偏离情况。实验结果表明，系统在偏离检测准确性达到98.6%的情况下，平均警告延迟（AWD）为0.7秒，展示了该系统在增强无人机降落可靠性方面的有效性。", "conclusion": "实验结果表明，本系统在偏离检测准确性为98.6%的情况下，平均警告延迟（AWD）为0.7秒，有效提高了无人机降落的可靠性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21731", "html_url": "https://arxiv.org/abs/2506.21731", "title": "通过互斥概率空间和局部相关性假设探索图像生成", "title_en": "Exploring Image Generation via Mutually Exclusive Probability Spaces and Local Correlation Hypothesis", "authors": "Chenqiu Zhao,Anup Basu", "background": "文中提出的理论框架源自对变分自编码器（VAE）的重新思考，观察到VAE中的潜在变量分布存在重叠，导致重建损失和KL散度损失之间的优化冲突。文中提出了互斥概率空间（MESP）的概念，并基于这一概念提出了二元潜在自编码器（BL-AE）以将图像编码为二元潜在表示。此外，还提出了一种自回归随机变量模型（ARVM），用于生成直方图，并实现了竞争性的FID分数。然而，这些分数反映的是记忆而非生成性。", "innovation": "文中提出了两个新的理论框架：互斥概率空间（MESP）和局部相关性假设（LCH）。MESP用于解决VAE中潜在变量分布重叠导致的优化冲突问题。LCH则假设生成能力来源于潜在变量之间的局部相关性。通过BL-AE和ARVM的结合，实现了比现有最佳方法更好的表现，尽管这些表现反映了记忆行为而非生成性。", "conclusion": "文章通过详细的实验和讨论验证了提出的框架，并表明尽管实现了竞争力的表现，现有的方法主要还是反映了记忆行为而非生成性。提出了局部相关性假设（LCH）来应对这一问题。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21718", "html_url": "https://arxiv.org/abs/2506.21718", "title": "通过文本到文本回归进行大型系统性能预测", "title_en": "Performance Prediction for Large Systems via Text-to-Text Regression", "authors": "Yash Akhauri,Bryan Lewandowski,Cheng-Hsi Lin,Adrian N. Reyes,Grant C. Forbes,Arissa Wongpanich,Bangding Yang,Mohamed S. Abdelfattah,Sagi Perel,Xingyou Song", "background": "在许多行业中，预测大型系统的度量结果是一个基本问题，主要依赖于传统的表格回归方法。然而，在诸如配置文件或系统日志等复杂的现实数据中，这些方法往往难以实现有效的特征工程。因此，在这些场景中，传统的表格回归方法显得力不从心。本文提出了一种文本到文本回归方法作为一般性和可扩展性的替代方案，以解决这类问题。特别是在谷歌的大型计算集群调度系统Borg中，该方法通过使用一个从随机初始化训练的60M参数编码器-解码器模型，实现了接近完美的0.99（平均0.9）的等级相关性，并且MSE比表格方法低100倍，同时也能快速适应新任务并在少量样本中表现出色。此外，模型能够捕捉复杂结果分布的密度，并通过消融研究进一步突显了其重要特性的重要性。这些发现为现实世界结果的通用模拟奠定了基础。", "innovation": "文本到文本回归作为一种新方法，适用于处理复杂的系统数据，尤其是当特征工程难以实施时。该方法通过一个大型参数编码器-解码器模型实现了预测资源效率的高性能，特别是在谷歌的Borg系统上表现显著，比传统表格回归方法效率更高且更快适应新任务。此外，该模型还展示了对复杂结果分布密度的捕捉能力，并且通过消融研究证实了其关键性。", "conclusion": "这些发现表明，文本到文本回归方法是一个有效的、具备广泛适用性的解决方案，能够用于预测现实世界中大型系统的性能指标，为未来的广泛部署和应用铺平了道路。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21727", "html_url": "https://arxiv.org/abs/2506.21727", "title": "跨多个维度同时公平分配不可分物品", "title_en": "Simultaneously Fair Allocation of Indivisible Items Across Multiple Dimensions", "authors": "Yasushi Kawase,Bodhayan Roy,Mohammad Azharuddin Sanpui", "background": "本文探讨了在多维环境下不可分物品的公平分配问题，这种情况下的公平性评估基于多个标准。多维环境不仅在理论上具有重要意义，还在许多实际应用中占据核心位置。例如，云计算资源根据CPU核心、内存和网络带宽等多种标准进行评估。一维公平性概念在这种情况下无法全面反映多维度属性间的公平性。为了应对这类挑战，本文研究了两种放宽的嫉妒自由概念：弱的同时嫉妒自由到c个物品（弱sEFc）和强的同时嫉妒自由到c个物品（强sEFc），这两种概念能够包含代理人的多维度偏好。弱的概念要求对于每对代理人在任何维度中，如果存在嫉妒，可以通过从被嫉妒的分配中移除不同物品集来消除。而强的概念则要求选择同一物品集，从被嫉妒的额外集合中移除即可消除嫉妒在每个维度上的存在。", "innovation": "本文提供了弱或强sEFc分配存在的上界和下界，并且这些界值独立于项目总数。此外，还提出了检查是否存在弱或强sEFc分配的算法。最后，本文还证明了检查弱sEF1和强sEF1分配的存在性的NP-hard性结果。", "conclusion": "本文通过探索弱和强的同时嫉妒自由到c个物品的概念，为多维公平分配不可分物品提供了理论框架。这些概念不仅涵盖了复杂环境中的多标准偏好，还通过算法和NP-hard性分析提供了实际应用的可行性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21783", "html_url": "https://arxiv.org/abs/2506.21783", "title": "评估大型语言模型在列表构建和时间理解方面的能力", "title_en": "Evaluating List Construction and Temporal Understanding capabilities of Large Language Models", "authors": "Alexandru Dumitru,V Venktesh,Adam Jatowt,Avishek Anand", "background": "大型语言模型（LLMs）在多种自然语言任务中展示了巨大进步，但仍存在对特别涉及多个实体的时间理解任务（如答案中的时间理解）的处理能力不足的问题。现有研究虽然评估了模型在隐式和显式时间理解方面的表现，但未专门针对列表回答构建的具体设置进行全面评价。因此，需要设计一个新基准来检测这些技能。", "innovation": "提出了Time referenced List based Question Answering（TLQA）基准，该基准要求模型给出与相应时间段对齐的结构化列表答案。TLQA基准首次同时要求列表构建和时间理解，是该领域的创新尝试。此外，该基准在封闭本和开放领域设置下评估了最新生成模型的时间理解与列表构建能力，并揭示了当前模型存在的显著不足。", "conclusion": "研究表明，当前模型在封闭本设置中未能提供完整答案且难以时间对齐事实，在开放领域设置中存在检索能力不足的问题，这些结果指出了未来研究的方向。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21655", "html_url": "https://arxiv.org/abs/2506.21655", "title": "APO: 通过非对称策略优化提升MSLMs的推理能力", "title_en": "APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization", "authors": "Minjie Hong,Zirun Guo,Yan Xia,Zehan Wang,Ziang Zhang,Tao Jin,Zhou Zhao", "background": "多模态大规模语言模型（MLLMs）能够整合多种数据，但在处理复杂推理时常常表现不佳。尽管增强学习（RL）可以提升语言模型的推理能力，但将其应用于多模态语言模型时存在挑战，包括在一般任务上的性能下降以及生成过度详细的“过度思考”推理。本文探讨了KL惩罚与过度思考对MLLMs在RL训练中的影响，并提出了一种新的方法——非对称策略优化（APO）来解决这些问题。该方法通过将采样响应分为正样本和负样本，并采用难度自适应偏差塑造（DADS）策略和次优轨迹复杂性正则化（STCR）策略，防止策略熵骤降，提高了训练的稳定性，并使样本利用更高效，同时保持了模型的现有知识和探索能力。", "innovation": "本文提出的非对称策略优化（APO）方法，通过将采样响应分为正样本和负样本，并采用难度自适应偏差塑造（DADS）策略和次优轨迹复杂性正则化（STCR）策略，有效地解决了MLLMs在增强学习中的过度思考问题，提高了模型的推理能力和泛化能力。这种方法能保持模型的现有知识，同时促进更简洁的推理，并且实验结果表明，这种方法在各种推理基准测试中表现出色，优于其他大模型。此外，所提出的方法能够维持一致的改进，证明了其在提升多模态复杂推理中的有效性和广泛适用性。", "conclusion": "通过非对称策略优化（APO）方法，本文有效地改善了多模态大规模语言模型（MLLMs）的推理能力，实现了显著的推理能力提升，并在各种推理基准测试中表现出色，优于其他大模型。所提出的难度自适应偏差塑造（DADS）和次优轨迹复杂性正则化（STCR）策略被证明是有效提高MLLMs在复杂推理中的表现，同时也保持了模型的泛化能力。本文的方法将为多模态复杂推理在MLLMs中的进一步发展提供有力支持，相关代码将被公开。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21796", "html_url": "https://arxiv.org/abs/2506.21796", "title": "利用机器学习演示互操作信道状态反馈压缩", "title_en": "Demonstrating Interoperable Channel State Feedback Compression with Machine Learning", "authors": "Dani Korpi,Rachel Wang,Jerry Wang,Abdelrahman Ibrahim,Carl Nuzman,Runxin Wang,Kursat Rasim Mestav,Dustin Zhang,Iraj Saniee,Shawn Winston,Gordana Pavlovic,Wei Ding,William J. Hillery,Chenxi Hao,Ram Thirunagari,Jung Chang,Jeehyun Kim,Bartek Kozicki,Dragan Samardzija,Taesang Yoo,Andreas Maeder,Tingfang Ji,Harish Viswanathan", "background": "基于神经网络的信道状态反馈压缩一直是机器学习在无线网络中最广泛研究的应用之一。各种基于仿真的研究显示，基于机器学习的反馈压缩可以减少开销并提供更准确的信道信息。然而，在用户设备（UE）和基站之间没有访问彼此的机器学习模型的实际应用场景中，我们所知道的还没有表明机器学习在信道反馈压缩中的实际效益的真实概念证明。", "innovation": "本文介绍了一种新的方法，用于以保密方式进行训练可互操作的压缩和解压缩ML模型，并使用原型UE和基站展示了随后模型的准确性。通过信道信息进行波束成形获得的下行吞吐量增益衡量了基于机器学习的信道反馈性能。报告的测量结果表明，无需设备和网络供应商之间分享机器学习模型，就可以开发出准确的基于机器学习的信道反馈链路。", "conclusion": "这些结果为基于机器学习的信道反馈在商用6G网络中的实用实施铺平了道路。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21788", "html_url": "https://arxiv.org/abs/2506.21788", "title": "在多源、多保真度原子级建模数据上增强稳健预训练的多任务并行", "title_en": "Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data", "authors": "Massimiliano Lupo Pasini,Jong Youl Choi,Pei Zhang,Kshitij Mehta,Rylie Weaver,Ashwin M. Aji,Karl W. Schulz,Jorda Polo,Prasanna Balaprakash", "background": "基于图神经网络的图基础模型有可持续且高效的原子级建模潜力。然而，处理预训练期间多源、多保真度数据的挑战需要引入多任务学习。这种方法通过共享信息传递层初步处理输入的原子结构，然后根据不同数据预测特定输出的结果，以此稳定预训练过程并提高模型对新化学区域的传输性。已有初步结果表明这种方法的可行性，但其在大型及多样数据集上的泛化能力和在超级计算机上的扩展性仍需进一步验证。", "innovation": "我们提出了一种多任务并行方法，将每个预测头分散到计算资源上并使用GPU加速。该方法在开源HydraGNN架构中实现，并在超过2400万个结构的五个数据集上进行了训练，然后在Perlmutter、Aurora和Frontier超级计算机上进行了测试，展示了在所有三种高度异构超级计算架构上的高效扩展性。", "conclusion": "该研究证明了使用多任务并行方法可以在超级计算机上高效地对多源、多保真度原子级建模数据进行稳健的预训练，并且验证了方法在多种计算平台上的兼容性和高效性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21785", "html_url": "https://arxiv.org/abs/2506.21785", "title": "比较用于第一人称视频摘要的学习范式", "title_en": "Comparing Learning Paradigms for Egocentric Video Summarization", "authors": "Daniel Wen", "background": "本文探讨了不同计算机视觉范式，包括监督学习、无监督学习和提示微调，评估它们在理解和解释第一人称视频数据方面的有效性。研究使用最先进的监督学习方法（Shotluck Holmes）、无监督学习方法（TAC-SUM）和预训练模型（GPT-4o）进行对比，评估其在视频摘要方面的效果。研究结果表明，当前最先进的模型在处理第一人称视频时不如第三人称视频有效，这突显出在第一人称视频领域仍需进一步的技术改进。尽管评估基于资源限制下的Ego-Exo4D数据集的小样本，但研究的主要目的是提供一个全面的概念验证分析，以推进计算机视觉技术在第一人称视频中的应用。通过探索新的方法并评估其潜力，旨在促进能够有效处理和解释第一人称视角的模型的发展和进步。", "innovation": "引入了通过评估现有最先进的监督学习模型（Shotluck Holmes），无监督学习模型（TAC-SUM）和提示微调的通用预训练模型（GPT-4o）来研究和解释第一人称视频的新方法。特别地，展示了通用提示微调的GPT-4o模型优于为特定任务设计的模型，强调了现有方法在适应第一人称视角的独特挑战方面的局限性。这种方法提供了一种全面的视角，用于改进第一人称视频处理技术。", "conclusion": "研究结果表明，当前最先进的模型在处理第一人称视频时表现不如第三人称视频，这强调了在第一人称视频领域进一步发展技术的必要性。通用提示微调的模型GPT-4o在处理第一人称视频方面表现出色，这表明这种方法在适应第一人称视角的独特挑战方面具有潜力。尽管研究在资源限制下仅使用了Ego-Exo4D数据集的小样本，但研究的主要目标是为发展能有效处理和解释第一人称视角的模型提供一个概念验证分析。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21732", "html_url": "https://arxiv.org/abs/2506.21732", "title": "基于姿态信息的强化学习在偏转转向视觉导航中的实验研究", "title_en": "Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation", "authors": "Ameya Salvi,Venkat Krovi", "background": "基于视觉的道路保持技术在机器人和自主地面车辆领域中具有重要意义，适用于各种道路和非道路应用。偏转转向车辆架构在人控操作中发挥了重要作用，但对其包括偏航滑动轮与地形交互在内的系统的建模，特别是在非道路环境下，已成为自动化部署的瓶颈。因此，基于端到端学习的方法，如模仿学习和深度强化学习，成为可行的替代方案，但其中系统性定式法在动态操作中的建模和验证仍有待改进，特别是在偏转转向车辆中。", "innovation": "本文提出了一种新颖的方法用于结构化学习视觉导航的定式法，并在软件模拟、硬件评估和消融研究中证明了该方法较现有文献性能显著提高。", "conclusion": "本文的研究结果表明，对于偏转转向车辆的视觉导航，基于姿态信息的强化学习方法能够显著提升性能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21845", "html_url": "https://arxiv.org/abs/2506.21845", "title": "3Description: 一种直观的人机协作3D建模方法", "title_en": "3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach", "authors": "Zhuodi Cai", "background": "传统3D建模在易用性和可访问性方面存在挑战，这通常限制了非专业人士参与3D模型的创建。在人工智能和新兴媒体的时代背景下，提供一种能使非专业人士也能轻松创建3D模型的方法显得尤为重要。", "innovation": "3Description提出了一种实验性的人工智能辅助的人机协作方法，用于直观的3D建模。该方法结合自然语言处理和计算机视觉技术，能让用户通过口头和手势描述来创建和调整3D模型。通过网络平台实现，3Description提供了便捷的操作方式，旨在增强用户与人工智能之间的协作，而非单纯依赖技术，从而保持人类的创造力。", "conclusion": "3Description不仅为一个更加包容和用户友好的设计过程做出了贡献，还鼓励了更多人参与到与人工智能的共创中，避免了过度技术化，保持了人类的创新精神，为构建未来的3D世界提供了支持。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21803", "html_url": "https://arxiv.org/abs/2506.21803", "title": "从token到心律：多尺度ECG语言预训练方法", "title_en": "From Token to Rhythm: A Multi-Scale Approach for ECG-Language Pretraining", "authors": "Fuying Wang,Jiacheng Xu,Lequan Yu", "background": "心电图（ECGs）在监测心脏健康和诊断心脏病方面发挥着重要作用。然而，传统的心电图分析方法依赖大规模的手动注释，这既耗费时间资源又密集。为克服这一局限，自监督学习（SSL）作为一种有前景的替代方案出现，它能够提取出能够高效转移到各种下游任务中的稳健的ECGs表示。尽管已有研究探索了ECG的预训练和多模态ECG-语言对齐，但这些方法往往无法捕捉到ECG信号的多尺度特性，这使得它们难以学习通用的表示，因为它们无法建模ECG数据的分层结构。", "innovation": "我们介绍了MELP，一种多尺度ECG-Language预训练（MELP）模型，该模型充分利用了ECG-文本对的分层监督。首先，MELP预训练了一个心脏病学特定的语言模型，以增强其对临床文本的理解。之后，MELP在标记、心搏和心律三个层面应用跨模态监督，以捕获不同时间尺度上的结构化信息，将ECG信号与文本报告对齐。我们使用三个公开的ECG数据集对MELP在多个任务上进行了评估，包括零样本ECG分类、线性探针和迁移学习。实验结果表明，MELP优于现有的SSL方法，显示出其在各种临床应用中的有效性和适应性。我们的代码可以在以下网址获取：this https URL", "conclusion": "研究表明，MELP在多种ECG任务上的性能超过了现有方法，证明了其多尺度监控临床应用的有效性和适应性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21826", "html_url": "https://arxiv.org/abs/2506.21826", "title": "通过视觉基础模型的线性探测实现历史地图的少样本分割", "title_en": "Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models", "authors": "Rafael Sterzinger,Marco Peer,Robert Sablatnig", "background": "历史地图作为丰富的历史资料，提供了对历史变迁的深刻洞察。然而，它们多样的视觉表示和有限的注释数据给自动处理带来了重大挑战。现有的方法难以有效处理这些特定的问题，尤其是在少量样本的情况下。仅能实现较为表层的性能，且需要大量手动标注数据。", "innovation": "本研究提出了一种简单而有效的方法，利用大型视觉基础模型丰富的语义嵌入结合参数高效的微调技术，实现对历史地图的少样本分割。该方法在Siegfried基准数据集的葡萄园和铁路分割任务中表现出色，尤其是5样本场景下，相对改进达到20%左右。此外，该方法在ICDAR 2021竞赛数据集上也表现出色，即使未针对此形状敏感度指标进行优化，也在平均PQ上取得了67.3%的成绩，显示出其广泛适用性。该方法在数据量极低的场景下（10样本及5样本）依然保持了高精度，仅需689k可训练参数，占总模型大小的0.21%。", "conclusion": "该方法提高了历史地图自动处理和分析的精度与效率，显著减少了对人工标注数据的需求，有望推动该领域的进一步发展。该方法已在公开仓库中提供。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21819", "html_url": "https://arxiv.org/abs/2506.21819", "title": "SciMantify -- 一种科学知识逐步语义化的混合方法", "title_en": "SciMantify -- A Hybrid Approach for the Evolving Semantification of Scientific Knowledge", "authors": "Lena John,Kheir Eddine Farfar,Sören Auer,Oliver Karras", "background": "科学出版物（主要以PDF形式数字化）保持静态且未结构化，限制了其中知识的可访问性和再利用。科学知识通常以表格形式提供，缺乏语义上下文，需要更灵活的语义化表示方式，以便于人类和机器理解和处理。本文提出了一种灵感来源于5星Linked Open Data（LOD）模型的知识表示演化模型，具有五个阶段和指导性标准，指导从电子文档（如PDF）到嵌入知识图谱中的语义表示的逐步过渡。该模型旨在实现知识的语义化和结构化，以提升知识的可查找性、可访问性、互操作性和可重用性。", "innovation": "提出了一种灵感来源于5星Linked Open Data（LOD）模型的知识表示演化模型的混合方法SciMantify，该方法通过整合科学知识的表格数据，如二次研究结果，逐步提升科学知识的语义化并嵌入到知识图谱中。人类和机器合作完成语义标注任务（SATs），通过逐步细化结果以提高科学知识的语义化水平。该方法在Open Research Knowledge Graph平台实现，展示了预实验结果，表明该方法简化了科学知识预处理，减少了逐步语义化的努力，并增强了知识表达的准确性。", "conclusion": "SciMantify方法通过整合科学知识的表格形式数据，结合人类和机器协同，逐步提高了知识表示的语义化水平，改进了知识的可查找性、可访问性、互操作性和可重用性。这种方法在Open Research Knowledge Graph平台上得到了实现并展示了初步的实验结果，证明了其有效性和实用性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21813", "html_url": "https://arxiv.org/abs/2506.21813", "title": "CAT-SG: 大型动态场景图数据集及其在白内障手术精细理解中的应用", "title_en": "CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery", "authors": "Felix Holm,Gözde Ünver,Ghazal Ghazaei,Nassir Navab", "background": "理解白内障手术复杂的流程需要对手术工具、解剖结构和手术技术之间的复杂互动进行建模。现有的数据集主要涉及手术分析中的孤立方面，如工具检测或阶段分割，但缺乏能够全面捕捉实体间随时间变化的语义关系的代表。这项研究引入了白内障手术场景图（CAT-SG）数据集，这是第一个提供工具-组织互动、程序变化及时间依赖性的结构化注释的数据集，通过整合详细的语义关系，CAT-SG为手术流水线提供了全面的视图，使得更准确地识别手术阶段和技术成为可能。此外，还提出了一种新型场景图生成模型CatSGG，其在生成结构化手术表示方面优于现有方法。CAT-SG旨在增强基于人工智能的手术训练、实时决策支持和流程分析，为临床实践中更智能、情境感知的系统铺平了道路。", "innovation": "CAT-SG数据集首次提供工具-组织互动、程序变化和时间依赖性的结构化注释。CatSGG模型则在生成结构化手术表示方面比现有方法表现更优。", "conclusion": "CAT-SG数据集和CatSGG模型的设计旨在增强AI驱动的手术培训、实时决策支持和工作流程分析，促进了临床实践中更智能、情境感知系统的实现。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21638", "html_url": "https://arxiv.org/abs/2506.21638", "title": "IRanker：迈向排名基础模型", "title_en": "IRanker: Towards Ranking Foundation Model", "authors": "Tao Feng,Zhigang Hua,Zijie Lei,Yan Xie,Shuang Yang,Bo Long,Jiaxuan You", "background": "排名任务在众多应用场景中反复出现，包括推荐系统、LLM路由和项目重新排序。现有的做法是为每种特定的排名任务设计不同的模型，然而这种方法需要大量的时间和资源来开发和维护。然而，不同于大型语言模型中的通用监督任务，排名任务缺乏清晰的监督标签，这给开发排名基础模型带来了极大的挑战。本文旨在解决这一问题，提出IRanker，这是一种结合了强化学习和迭代解码的排名基础模型框架。IRanker通过将复杂的排名任务分解为一个逐步消除候选池中最差候选者的迭代解码过程，显著减少了输出组合空间，并更充分利用了RL训练中的有限上下文长度，从而克服了这一挑战。", "innovation": "IRanker不仅采用了一种迭代解码的方法来逐步消除最差的候选者，从而有效解决了排名任务中缺乏监督标签的挑战，还引入了强化学习算法来训练该模型，以更高效地利用有限的上下文长度。这一创新有助于开发统一的排名基础模型，适用于多种排名任务，并显著提高了模型的性能。此外，IRanker还展示了一种新的零样本泛化能力，即使在未见过的任务中也能表现出色，特别是在GSM8K、IFEval和MathQA等任务上。", "conclusion": "文章通过在九个数据集上的实验，展示了IRanker-3B模型在推荐、路由和段落排名这三种情景下的优越性能，并且与相同规模的其他模型相比取得了最佳结果。此外，IRanker的强化学习设计及其迭代机制在不同规模的LLM中表现出很好的稳健性。同时，IRanker还能进一步增强零样本的LLM性能，特别是在未见过的任务上，IRanker-3B甚至能够显著提高基础模型的表现。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21862", "html_url": "https://arxiv.org/abs/2506.21862", "title": "LLaVA-Scissor: Semantic Connected Components for Video LLMs", "title_en": "LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs", "authors": "Boyuan Sun,Jiaxing Zhao,Xihan Wei,Qibin Hou", "background": "当前的研究大多集中在基于注意力分数压缩视频多模态大语言模型的tokens上，但这些方法往往无法有效地覆盖所有的语义区域，并且经常导致token冗余。本文旨在提出一种无需训练的token压缩策略LLaVA-Scissor，该策略创新性地利用语义连接组件（SCC），用于在视频多模态大语言模型中的空间和时间域进行token压缩。", "innovation": "LLaVA-Scissor通过利用语义连接组件（SCC）对token进行分类，并在空间和时间域中执行token压缩，从而有效避免了之前方法中的语义区域覆盖不全和token冗余问题。这种方法能够在保持全面语义覆盖的同时，以一组非重叠的语义token来表示整个视频，从而实现有效的token压缩。", "conclusion": "实验结果表明，LLaVA-Scissor在多种视频理解基准测试中表现出色，特别是在低token保留率的情况下，其在各种视频理解基准测试中的性能显著优于其他token压缩方法。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21849", "html_url": "https://arxiv.org/abs/2506.21849", "title": "大型语言模型不确定性量化中的一致性假设", "title_en": "The Consistency Hypothesis in Uncertainty Quantification for Large Language Models", "authors": "Quan Xiao,Debarun Bhattacharjya,Balaji Ganesan,Radu Marinescu,Katsiaryna Mirylenka,Nhan H Pham,Michael Glass,Junkyu Lee", "background": "对于需要高度用户信任的实际应用而言，估计大型语言模型（LLM）输出的置信度至关重要。由于其便捷性和实用性，依赖模型API的黑盒不确定性量化（UQ）方法越来越受到欢迎。这些方法通常采用生成一致性作为置信度的代理，即一致性假设，通过数学描述和统计检验来捕捉这一假设的不同变体，并利用这些陈述来评估LLM输出在不同任务中的一致性。", "innovation": "本文引入了三个数学陈述及其对应的统计检验，以量化一致性假设的变化形式，提出了基于数据的黑盒不确定性量化方法，这些方法通过聚合生成间的相似性来估算置信度，从而超越了现有基线，展示了实际应用中观察到的一致性假设的重要性。", "conclusion": "一致性假设在不同的场景下普遍存在，特别是在新的数据驱动的无数据黑盒不确定性量化方法中更为显著。通过聚合生成间的相似性来估计置信度的方法在评估LLM输出一致性方面表现出优越性，展示了该方法的实际应用价值。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21872", "html_url": "https://arxiv.org/abs/2506.21872", "title": "连续强化学习的综述", "title_en": "A Survey of Continual Reinforcement Learning", "authors": "Chaofan Pan,Xin Yang,Yanhua Li,Wei Wei,Tianrui Li,Bo An,Jiye Liang", "background": "强化学习（RL）是解决序列决策问题的重要机器学习范式。近年来，随着深度神经网络的快速发展，该领域取得了显著进展。但当前RL的成功依赖于大量训练数据和计算资源，并且RL在跨任务的泛化能力有限，限制了它在动态和真实世界环境中的应用。面对这些限制，连续学习（CL）的概念出现，促使连续强化学习（CRL）作为一个有前景的研究方向获得了发展关注。CRL旨在通过使代理能够持续学习、适应新任务并保留先前获得的知识来应对上述挑战。", "innovation": "本文提供了一个全面的CRL综述，包括核心概念、挑战和方法论。具体而言，通过构建一个新分类体系，从知识存储和/或转移的角度对CRL方法进行了分类；详细回顾了现有的CRL工作，并对其度量标准、任务、基准和场景设置进行了组织与分析。这个分类体系为该领域提供了新的视角，强调了CRL的特殊挑战，并为未来的实践提供了宝贵的指导建议。", "conclusion": "本文分析了CRL的独特挑战，并在此基础上提供了未来的研究方向的实用见解，对于理解和推动CRL的发展具有重要意义。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21840", "html_url": "https://arxiv.org/abs/2506.21840", "title": "Parsi: 波斯诗歌作者识别的风格整合方法", "title_en": "PARSI: Persian Authorship Recognition via Stylometric Integration", "authors": "Kourosh Shahnazari,Mohammadali Keshtparvar,Seyed Moein Ayyoubzadeh", "background": "波斯古典诗歌的语言、风格和韵律特征错综复杂，这为计算作者归因带来了挑战。本文旨在利用多输入神经网络框架，结合转录器语言编码器以及语义、风格和韵律特征，解决波斯著名诗人的作者归因问题，通过建立一个包含100维Word2Vec嵌入、七种风格测量和诗体和节奏分类编码的特征集，对Ganjoor数字收藏中的647,653首诗进行验证，确保数据的严谨预处理和作者验证，同时保留诗篇级别的拆分以防止重叠。", "innovation": "本文提出了一个多功能框架，用于识别67位著名波斯诗人的作品，并采用转录器语言编码器结合特征表达波斯诗歌的语义、风格和韵律维度。通过采用诗篇级别分类和加权投票评估方案，研究表明加权投票准确率为71%。此外还探讨了基于阈值的决策过滤，以生成高度自信的预测，最高准确率为97%，但覆盖率较低。该研究强调了深度表示形式与领域特定特征的整合以改善作者归因的方法。研究成果突显了这种方法在自动化分类和风格分析方面的潜力，并为多语言作者归因、风格转变和波斯诗歌生成建模研究提供了贡献。", "conclusion": "研究表明，结合深度表征形式与领域特定特征的框架在波斯诗歌作者归因中具有潜在优势。通过引入基于阈值的决策过滤策略，模型能够生成高度自信的预测，尽管覆盖率较低但准确率可达到97%。此研究将为多语言作者归因、风格变化和波斯诗歌生成建模提供新的思路，并进一步推动相关领域的研究进展。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21864", "html_url": "https://arxiv.org/abs/2506.21864", "title": "DeepTalk: 针对自适应模态专属MoE的无缝智能语音交互", "title_en": "DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE", "authors": "Hang Shao,Heting Gao,Yunhang Shen,Jiawei Chen,Lijiang Li,Zuwei Long,Bo Tong,Ke Li,Xing Sun", "background": "传统的多模态大语言模型（MLLMs）将一个单一的大语言模型（LLM）重构为能够进行语音和文本生成的语音语言模型（SLM）。与模块化和对齐的MLLMs相比，原生MLLMs能够保留更丰富的副语言特征（如情感和语调），并通过LLM本身的框架直接生成语音响应，而无需使用单独的语音解码器。这一整合还带来了较低的响应延迟和更流畅的交互体验。然而，原生MLLMs会遭受灾难性遗忘和性能下降的问题，这是因为可用于原生MLLMs预训练的语声-文本配对数据不足，而大语言模型（LLM）需要大量的文本数据来完成预训练。因此，需要改进方法来解决原生MLLMs的上述问题以提供良好的语音交互体验。", "innovation": "提出了一种基于专家混合（MoE）架构的自适应模态专家学习框架DeepTalk。DeepTalk首先根据模态负载在LLM中自适应地区分模态专家，然后每个模态专家进行专门的单模态训练，之后进行联合多模态协作训练。这种方法使得DeepTalk与原始LLM相比仅产生5.5%的性能下降，远低于原生MLLMs（如GLM-4-Voice）通常超过20%的性能下降，并且与模块化MLLMs相当。同时，端到端对话的延迟保持在0.5秒以内，确保了无缝和智能的语音交互体验。", "conclusion": "DeepTalk框架通过自适应区分模态专家并在混合架构中进行训练，能够有效减少原生MLLMs的灾难性遗忘和性能下降问题，提供无缝和智能的语音交互体验。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21884", "html_url": "https://arxiv.org/abs/2506.21884", "title": "UnMix-NeRF: 谱分解遇上神经辐射场", "title_en": "UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields", "authors": "Fabian Perez,Sara Rojas,Carlos Hinojosa,Hoover Rueda-Chacón,Bernard Ghanem", "background": "基于NeRF的分割方法主要关注对象语义，依赖于RGB数据，而忽略了材质属性。这种限制限制了对材料的精准感知，这对于机器人技术、增强现实、模拟等应用至关重要。", "innovation": "引入了UnMix-NeRF框架，将光谱解混与NeRF结合，实现了超光谱新颖视角合成和无监督材质分割。该方法通过建模漫反射和镜面反射部分来模拟光谱反射特性，利用学习到的全球端元词典代表纯净的材质签名，以及点的丰度捕捉其分布。对于材质分割，使用学习到的端元获取光谱签名预测，实现无监督的材质聚类。此外，UnMix-NeRF还能通过修改学习到的端元词典实现场景编辑和基于材质的外观灵活操作。", "conclusion": "大量实验验证了该方法的优越性，展示了与现有方法相比，其在光谱重构和材质分割方面的优势。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21876", "html_url": "https://arxiv.org/abs/2506.21876", "title": "视觉语言模型拥有内部世界模型吗？向着原子化的评价", "title_en": "Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation", "authors": "Qiyue Gao,Xinyu Pi,Kevin Liu,Junrong Chen,Ruolan Yang,Xinqi Huang,Xinyu Fang,Lu Sun,Gautham Kishore,Bo Ai,Stone Tao,Mengyang Liu,Jiaxi Yang,Chao-Jung Lai,Chuanyang Jin,Jiannan Xiang,Benhao Huang,Zeming Chen,David Danks,Hao Su,Tianmin Shu,Ziqiao Ma,Lianhui Qin,Zhiting Hu", "background": "视觉语言模型（VLMs）如OpenAI的o3、GPT-4o和Gemini等展现出作为通用内部世界模型（WMs）的潜力，但是最新的研究仅评估了这些模型在特定能力上的表现，但缺乏对VLMs基本WM能力的系统性评估。本文通过受比较心理学和认知科学启发的两阶段框架，从感知（视觉、空间、时间、数量、运动）和预测（机械模拟、传递推理、组合推理）两大维度对15款最新的商业和开源VLM模型进行了660次实验的对比和测试。结果显示，这些模型在基础世界建模能力方面存在显著的局限性，特别是在区分运动轨迹时几乎达到了随机准确率，且缺乏区分理解，比如一些模型认为蓝色物体比绿色物体移动得更快。大量详细的实验表明，VLMs在世界建模能力上与人类水平存在显著差距。", "innovation": "本文提出了一个两阶段框架，用于系统性地评估VLMs在视觉、空间、时间、数量、运动感知和机械模拟、传递推理、组合推理等方面的WM能力。还建立了WM-ABench，这是一个包含23个精细维度，涵盖6种不同模拟环境的大型基准测试，利用该框架验证了VLMs在这些方面基础WM功能的局限性。通过大量实验探索了模型在基本世界建模任务中的不足之处，并揭示了VLMs与人类世界建模能力之间的显著差距。", "conclusion": "研究发现，最先进的VLMs在基本世界建模能力上表现不佳，特别是在运动交互理解、物体状态推断等方面。这表明，尽管VLMs在大规模视觉和语言任务中表现出色，但在基础WM能力方面仍有很大的进步空间。未来的研究需要进一步扩展这些模型在更复杂世界交互中的表现。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21817", "html_url": "https://arxiv.org/abs/2506.21817", "title": "探索由AI引发的科学英语语言变化结构", "title_en": "Exploring the Structure of AI-Induced Language Change in Scientific English", "authors": "Riley Galpin,Bryce Anderson,Tom S. Juzek", "background": "近年来，科学英语经历了快速且前所未有的变化，诸如'delve'、'intricate'和'crucial'等词汇在2022年后频率显著上升。这些变化通常被认为与大型语言模型（如ChatGPT）在偏见和失准讨论中的日益影响相关。然而，尽管词汇频率发生了变化，这些语言变化的具体结构仍不清楚。目前的研究旨在探讨这些变化是否涉及同义词被突然高位词汇替代的现象，例如'crucial'替代'essential'和'key'，或者它们反映了更广泛的语义和语用调整。为了更深入地研究这种变化的结构，研究加入了词性标注分析，以在词性的不同类别中量化语言变化，区分如'noun'和'adjective'这类词形的变化。基于PubMed中的科学摘要频率趋势，系统分析了广泛讨论的高位词汇的同义词组。发现整个语义群组往往会一起发生转变，大多数或全部群组中的词使用量增加。这一模式表明，由大型语言模型引发的变化主要集中在语义和语用上，而非单纯词汇层面。值得注意的是，形容词'important'的显著下降促使我们系统分析了词汇量减少的情况。对'坍缩'词汇的分析揭示了一个更复杂的情况，这与高位词汇突然上升的模式一致，反映了有机语言变化的特点。这些见解进一步深化了我们对语言技术如何继续塑造人类语言的理解。", "innovation": "本研究首次系统地分析了科学英语中高位词汇的变化结构，通过包括词性标注在内的方式量化了不同类别词汇的变化，区分了词形的不同形式。这种分析揭示了整个语义群组的动力学变化，表明大型语言模型引发的变化更多反映在语义和语用方面，而不仅仅是词汇层面的变化。此外，通过对'坍缩'词汇的系统分析，揭示了与高位词汇突然上升不同的复杂模式，这符合有机语言变化的特点。", "conclusion": "通过系统分析科学英语中高位词汇的同义词组变化，研究发现整个语义群组往往一起发生转变，而不是单一词汇的替代。同时，形容词'important'的下降趋势是一个值得注意的变化。研究结果表明，大型语言模型引发的变化主要体现在语义和语用上，而非单纯的词汇层面的变化。最后，'坍缩'词汇的变化模式显示了有机语言变化的趋势，这与高位词汇突然上升的模式形成对比，丰富了我们对语言技术如何塑造科学语言的理解。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21857", "html_url": "https://arxiv.org/abs/2506.21857", "title": "SPADE: 基于数据专家混合的时空转录组学与病理学对齐方法构建富有表现力的隐空间", "title_en": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "authors": "Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold", "background": "数字病理学的迅猛发展和自主监督深度学习的进步，使得各类病理任务的基础模型得以开发，涉及多种疾病。虽然已经出现了结合多种数据源的多模态方法，但在将整个切片图像（WSIs）与空间转录组学（ST）数据全面整合方面仍存在关键空白。时空转录组学是捕捉标准苏木素和伊红（H&E）染色之外的关键分子异质性的关键。现有的研究缺乏一个统一框架，能够利用这两种技术之间的互补性，从而创建一个由时空转录组学引导的隐空间，进而指导图像表征学习。", "innovation": "SPADE是一个引入的基础模型，它通过将组织病理学（关于完整切片图像）与时空转录组学（ST）数据统一起来了，从而创建一个由时空转录组学引导的隐空间。SPADE利用了混合数据专家的方法，通过两阶段特征空间聚类创建专家，使这些专家能够通过对比学习学习配对的WSI片段和基因表达图谱的表示。预训练于全面的HEST-1k数据集，SPADE在14个下游任务中的表现显著优于基线模型，突显了将形态学和分子信息整合到一个隐空间中的好处。", "conclusion": "SPADE模型通过将组织病理学与时空转录组学数据整合，在单个统一的框架中指导图像表征学习，显著提升了多任务学习能力。该模型展示了将形态学和分子信息整合到一个隐空间的优越性，展示了在病理学任务上的应用潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21873", "html_url": "https://arxiv.org/abs/2506.21873", "title": "Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning", "title_en": "Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning", "authors": "Tzu-Chun Chien,Chieh-Kai Lin,Shiang-Feng Tsai,Ruei-Chi Lai,Hung-Jen Chen,Min Sun", "background": "近期的多模态大语言模型（MLLMs）在视觉定位任务中的表现非常出色，成为各种视觉语言应用的一般接口。然而，这些模型面临高计算成本的问题，特别是在处理大量视觉标记时。虽然剪枝方法可以降低计算成本，但会导致模型的视觉定位能力显著下降，影响其性能。例如，剪枝会使LLaVA在RefCOCO验证集上的理解参考表达准确性从56.14%降到15.34%。研究者发现，剪枝后标记ID的位置不匹配是主要原因，这直接影响了视觉定位任务的性能。", "innovation": "该研究提出了一种名为Grounding-Aware Token Pruning（GAP）的方法，通过简单地调整标记ID，可以恢复剪枝带来的性能下降。GAP方法在Shikra、MiniGPTv2和LLaVA系列等模型中应用，能够提高各种剪枝策略下的性能，且不增加额外的训练、内存或计算成本。", "conclusion": "GAP方法能够克服剪枝对模型视觉定位能力的负面影响，恢复到原始性能的90%，并适用于多种剪枝策略，展示了其实用性和有效性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21931", "html_url": "https://arxiv.org/abs/2506.21931", "title": "ARAG：具有主动检索增强生成的个性化推荐", "title_en": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation", "authors": "Reza Yousefi Maragheh,Pratheek Vadla,Priyank Gupta,Kai Zhao,Aysenur Inan,Kehui Yao,Jianpeng Xu,Praveen Kanumala,Jason Cho,Sushant Kumar", "background": "检索增强生成（RAG）在通过将外部上下文纳入大语言模型提示中来增强推荐系统方面显示出了潜力。然而，现有的RAG方法通常依赖于静态检索启发式，未能在动态推荐场景中捕捉到用户的细微偏好。", "innovation": "本文介绍了一种名为ARAG的具有主动检索增强生成的个性化推荐框架，它将多智能体协作机制引入到RAG管道中。ARAG利用了四个专门的大语言模型智能体：用户理解智能体、自然语言推理（NLI）智能体、上下文摘要智能体和项目排序智能体。这些智能体分别从长时间和会话、候选项目与推测意图之间的语义对齐、总结NLI智能体的发现以及基于上下文适配生成推荐列表中发挥了重要作用。实验结果表明，ARAG显著优于标准的RAG和最近的基准方法，在NDCG@5和Hit@5上的表现分别提高了42.1%和35.5%。此外，通过消融实验分析评估了ARAG不同组件的效果，进一步证明了将主动推理集成到检索增强推荐中的有效性，并为基于大语言模型的个性化提供新的方向。", "conclusion": "研究结果突显了将主动推理集成到检索增强推荐中的有效性，并为基于大语言模型的个性化提供了新的研究方向。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21892", "html_url": "https://arxiv.org/abs/2506.21892", "title": "SODA: 利用邻域传播在领域变换的点云中进行离群点检测", "title_en": "SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation", "authors": "Adam Goodge,Xun Xu,Bryan Hooi,Wee Siong Ng,Jingyi Liao,Yongyi Su,Xulei Yang", "background": "随着点云数据在各种应用中的增多，检测点云中的异常分布（OOD）对象对于确保模型的安全性和可靠性变得至关重要。然而，这一问题在现有研究中尚未被充分探讨。尽管3D视觉-语言模型（3D VLMs）在图像领域取得了成功，但将其用于点云中的OOD检测仍面临挑战，主要因为用于预先训练3D VLMs的点云数据集在尺寸和对象多样性方面远小于基于图像的同类数据集，且通常包含完全由计算机设计的合成对象，导致在用于涉及真实环境扫描对象的实际任务时出现领域转移，进而影响模型表现。我们的实验表明，这种领域转移显著降低了点云与其相关文本嵌入在3D VLM潜在空间中的对齐性，从而阻碍了下游性能。", "innovation": "我们提出了一种名为SODA的新方法，通过基于邻域的评分传播方案，提高了对OOD点云的检测能力。SODA是一种推理算法，不需要额外的模型训练，并在多个数据集和问题设置中达到了现有方法的最优性能。", "conclusion": "通过SODA方法，我们解决了领域转移带来的挑战，显著提高了点云中异常对象的检测性能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21945", "html_url": "https://arxiv.org/abs/2506.21945", "title": "SDRNET：用于高分辨率遥感图像准确语义分割的堆叠深度残差网络", "title_en": "SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images", "authors": "Naftaly Wambugu,Ruisheng Wang,Bo Guo,Tianshu Yu,Sheng Xu,Mohammed Elhassan", "background": "高分辨率遥感（FRRS）图像的语义分割因其强大的潜力吸引了遥感研究领域的关注。然而，由于显著的类别差异、遮挡导致的关键地面对象不可见以及对象大小的变化，FRRS图像的精准分割仍然具有挑战性。尽管深度卷积神经网络（DCNNs）在图像特征学习和表示方面表现出色，但从FRRS图像中提取足够的特征以实现准确的语义分割仍具有挑战性。这种情况下，需要深度学习模型学习鲁棒特征并生成足够的特征描述符。因此，本文介绍了用于FRRS图像的堆叠深度残差网络（SDRNet）来解决上述问题。", "innovation": "SDRNet 是一种堆叠的深度残差网络，旨在利用两个堆叠的编码器-解码器网络来捕获长范围语义并保存空间信息。每个编码器和解码器之间使用膨胀残差块（DRB）来捕获足够的全局依赖性，从而提高分割性能。这一创新性框架能够有效应对基于现有DCNNs的FRRS图像语义分割挑战，并取得了良好的实验结果。", "conclusion": "通过使用ISPRS Vaihingen和Potsdam数据集，实验结果表明，SDRNet 在FRRS图像的语义分割上表现出色且具有竞争力，相比现有网络能够产生更准确的结果。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21976", "html_url": "https://arxiv.org/abs/2506.21976", "title": "SceneDiffuser++：基于生成世界模型的城市规模交通模拟", "title_en": "SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model", "authors": "Shuhan Tan,John Lambert,Hong Jeon,Sakshum Kulshrestha,Yijing Bai,Jing Luo,Dragomir Anguelov,Mingxing Tan,Chiyu Max Jiang", "background": "交通模拟的目标是利用大量的模拟合成里程来补充有限的手动测试里程。这一愿景最终是形成一个生成性的模拟城市，这种城市可以根据城市地图和自动驾驶车辆（AV）软件栈，无缝模拟从起点A到终点B的路线，包括填充城市、操控实时行为体（如车辆、行人）以及控制交通信号灯等各个方面。尽管一些关键技术已经在不同的研究中得到单独研究，但在研究界，动态场景生成和环境模拟这两个方面却较少被关注。本文提出了SceneDiffuser++，这是一种能够跨整个城市进行端到端生成世界模型，应用于点A到点B的模拟场景中，融合了所有上述需求，增强长时模拟环境的真实性。我们也在增强版本的Waymo开放运动数据集（WOMD）上评估了模拟质量，扩展了地图区域以支持行程级别的仿真。", "innovation": "本文的主要创新在于提出了SceneDiffuser++，这是一种基于单一损失函数训练的端到端生成世界模型，能够在城市规模上实现点A到点B的交通模拟，集成了场景生成、行为体建模、遮挡推理、动态场景生成和环境模拟等技术需求，填补了研究社区在动态场景生成和环境模拟方面关注不足的空白。", "conclusion": "我们展示了SceneDiffuser++的城市规模交通模拟能力，并研究其在长时间模拟条件下的优越真实性。通过在增强的Waymo开放运动数据集（WOMD）上进行评估，证明了该模型在支持行程级别的仿真方面的优越性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21874", "html_url": "https://arxiv.org/abs/2506.21874", "title": "通过对抗性误标污染文本生成图像AI模型的可能性", "title_en": "On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling", "authors": "Stanley Wu,Ronik Bhaskar,Anna Yoo Jeong Ha,Shawn Shan,Haitao Zheng,Ben Y. Zhao", "background": "今天的文本到图像生成模型在训练过程中使用来自互联网的上百万张图像，每张图像配有由视觉-语言模型（VLMs）生成的详细描述。尽管这种训练方式提供了大量高质量的图像-描述配对，但最近的研究发现VLMs容易受到隐蔽的对抗性攻击，即通过在图像中添加微小的扰动使模型产生错误的描述。这项研究探讨了利用对抗性误标攻击VLMs以污染文本到图像模型训练管道的可行性。实验表明VLMs对对抗性扰动非常敏感，攻击者可以产生看起来正常但实际上会被VLM描述错误的图像，从而将强“脏标签”毒样本注入到文本到图像模型的训练管道中，少量的毒样本就可以改变模型的行为。研究发现，尽管潜在的防御措施可能有效，但可以被适应性攻击绕过，这表明这种猫捉老鼠的游戏会降低训练数据的质量，增加文本到图像模型开发的成本。研究还展示了这种攻击在对抗商业VLMs（Google Vertex AI和Microsoft Azure）的黑盒场景中的实际效果，成功攻击率超过73%。", "innovation": "研究的创新之处在于首次提出了通过对抗性误标来污染文本到图像模型训练管道的方法。该研究不仅证明了VLMs对对抗性扰动的高度敏感性，而且还展示了即使在黑盒场景下，这些攻击在对抗商业VLMs时仍能取得高成功率。研究还探讨了防御措施的有效性及其可被绕过的问题，提出了一个对抗性的猫捉老鼠的游戏，强调了提升训练数据质量和开发成本的问题。", "conclusion": "这项研究指出，通过对抗性误标可以在训练过程中污染文本到图像模型，少量的毒样本就可以显著改变模型的行为。虽然有一些潜在的防御措施可以缓解问题，但这些防御措施容易被适应性攻击绕过。为此，未来研究需要进一步探索更加有效的防御机制，并关注对抗性攻击对文本到图像模型训练数据质量的影响。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21964", "html_url": "https://arxiv.org/abs/2506.21964", "title": "使用大型语言模型在贝叶斯统计中建议先验分布", "title_en": "Using Large Language Models to Suggest Informative Prior Distributions in Bayesian Statistics", "authors": "Michael A. Riegler,Kristoffer Herland Hellton,Vajira Thambawita,Hugo L. Hammer", "background": "在贝叶斯统计中选择先验分布是一项具有挑战性、资源密集且主观的任务。论文通过分析使用大型语言模型（LLMs）来建议知识驱动、信息丰富的先验分布，探讨了利用LLMs来简化和客观化先验分布选择的过程。", "innovation": "开发了一种全面的提示模板，让LLMs不仅建议先验分布，还验证和反思其选择。评估了Claude Opus、Gemini 2.5 Pro和ChatGPT-4o-mini在心脏疾病风险和混凝土强度两个真实数据集上的表现。结果显示，LLMs可以正确识别关联方向，并且Claude和Gemini提供的先验分布质量优于ChatGPT。此外，对于不具信息性的先验分布，LLMs在此方面表现出显著性能差异：ChatGPT和Gemini倾向于使用“过于模糊”的均值0，而Claude则未表现出这种倾向，显示出了显著的优势。", "conclusion": "LLMs有潜力作为一种有效且客观的方法来选择先验分布，但要在避免过度和不足自信的前提下调整这些先验分布的宽度仍面临主要挑战。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21997", "html_url": "https://arxiv.org/abs/2506.21997", "title": "分箱半参数贝叶斯网络", "title_en": "Binned semiparametric Bayesian networks", "authors": "Rafael Sojo,Javier Díaz-Rozo,Concha Bielza,Pedro Larrañaga", "background": "本文介绍了一种新颖的概率半参数模型，该模型利用数据分箱来降低非参数分布中核密度估计的计算成本。通过开发两种新的条件概率分布来构建新的分箱半参数贝叶斯网络——稀疏分箱核密度估计和傅里叶核密度估计。这两种概率分布通过使用稀疏张量和限制条件概率计算中的父节点数量来解决维数灾难的问题，而维数灾难是影响分箱模型的典型问题。为了评估提议的方法，我们进行了复杂性分析，并使用合成数据集和UCI机器学习存储库中的数据集进行了多次比较实验，实验涵盖了不同的分箱规则、父节点限制、网格大小和样本数量，以全面了解模型的行为。实验结果表明，新的分箱半参数贝叶斯网络在结构学习和对数似然估计方面与半参数贝叶斯网络没有统计学上显著的差异，但速度要快得多，这表明新的分箱半参数贝叶斯网络是一种可靠且更高效的替代方案", "innovation": "本文创新性地开发了一种分箱半参数贝叶斯网络，通过利用数据分箱来降低计算成本，特别通过稀疏分箱核密度估计和傅里叶核密度估计来解决维数灾难的问题，同时保持与非分箱模型相似的估计效果，但在速度上显著提升。", "conclusion": "实验结果显示，分箱半参数贝叶斯网络在结构学习和似然估计上与非分箱模型无显著差异，但计算速度明显更快。因此，分箱半参数贝叶斯网络作为一个可靠且更高效的替代方案，具有重要的应用价值。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21972", "html_url": "https://arxiv.org/abs/2506.21972", "title": "进步中的囚禁策略：利用大型语言模型漏洞和绕过现代防御的混合方法", "title_en": "Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses", "authors": "Mohamed Ahmed,Mohamed Abdelmouty,Mingyu Kim,Gunvanth Kandula,Alex Park,James C. Davis", "background": "预训练语言模型（PTLMs）和大型语言模型（LLMs）的发展推动了它们在各种应用中的广泛应用。然而，这类模型仍然存在漏洞，可以通过利用其固有弱点来绕过安全措施，主要威胁包括令牌级和提示级囚禁。令牌级攻击通过嵌入逆向工程的序列影响黑盒模型如GPT，具有不可检测的模式并依赖于基于梯度的令牌优化。提示级攻击使用语义结构化的输入触发有害响应，但依赖于不可靠的迭代反馈。为了应对这些方法的互补局限性，研究提出了一种新的混合方法，整合了令牌级和提示级技术，以增强各种PTLMs的囚禁效果。研究在多个Vicuna和Llama模型中评估了这些新的混合方法，发现这些新方法的攻击成功率显著提升。同时，它们能保持较高的攻击成功率，即使在更严格的评估标准下也是如此。这两个新方法在防御方面保持了较强的转移能力和一致性效果，能够有效穿透诸如梯度束和JB屏蔽等高级防御机制。这些发现揭示了当前安全堆栈中未报告的漏洞，强调了在对抗适应性对手时需要综合防护措施的重要性，同时指出了纯粹成功率和防御鲁棒性之间的权衡关系。", "innovation": "研究提出了一种新的混合方法，结合了令牌级和提示级技术，以增强大型语言模型的囚禁效果，两种新的混合方法（GCG + PAIR和GCG + WordGame）在多个模型上测试，显著提高了攻击成功率，同时保持了强鲁棒性和转移性，能够有效突破高级防御机制。", "conclusion": "研究发现了当前安全机制中的未报告漏洞，强调了综合防御措施的必要性，指出了纯粹成功率与防御鲁棒性之间的权衡，突出了提升对抗适应性对手防护技术的迫切性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22026", "html_url": "https://arxiv.org/abs/2506.22026", "title": "基于文献的科学思想新颖性评估", "title_en": "Literature-Grounded Novelty Assessment of Scientific Ideas", "authors": "Simra Shahid,Marissa Radensky,Raymond Fok,Pao Siangliulue,Daniel S. Weld,Tom Hope", "background": "自动化的科学创意生成系统已经取得了显著的进步，但自动评估新颖性的技术仍然是一个关键且未被充分探索的挑战。手动通过文献回顾评估新颖性耗时且主观性强，在大规模应用中不实际。为了应对这些挑战，提出了一种基于LLM的检索增强生成框架——Idea Novelty Checker，该框架采用检索再排序的双阶段方法。这种方法首先使用关键词和片段检索收集大量相关信息论文，然后通过嵌入过滤和基于类别的人工智能重排序来精炼这一集合。该框架还整合了专家标注示例，以指导系统进行新颖性评估和生成基于文献的推理。广泛的实验表明，新技术与现有方法相比新颖性评估的达成率提高了约13%。进一步的消融研究展示了基于类别的再排序器在识别最相关文献以进行新颖性评估中的重要性。", "innovation": "提出了一种基于LLM的检索增强生成框架——Idea Novelty Checker，采用检索再排序的双阶段方法，通过嵌入过滤和基于类别的人工智能重排序来精炼信息集合，并通过专家标注示例指导新颖性评估和生成基于文献的推理。实验结果表明，新技术在新颖性评估中具有明显优势，达成率提高了约13%。", "conclusion": "提出的Idea Novelty Checker通过检索和再排序的双阶段方法显著提高了新颖性评估的准确性和实用性。实验验证了基于类别的再排序器在识别最具关联文献方面的有效性，这为自动评估科学思想的新颖性提供了新的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22008", "html_url": "https://arxiv.org/abs/2506.22008", "title": "TROFI：基于轨迹排名的离线逆强化学习", "title_en": "TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning", "authors": "Alessandro Sestini,Joakim Bergdahl,Konrad Tollmar,Andrew D. Bagdanov,Linus Gisslén", "background": "在离线强化学习中，代理仅通过固定存储转换集进行训练，这些转换集源自某个源策略。然而，这要求数据集需由奖励函数进行标注。在如视频游戏开发的实际应用场景中，奖励函数的可用性往往无法得到保证。本研究提出了一种新颖的方法Trajectory-Ranked OFfline Inverse Reinforcement Learning (TROFI)，该方法可以在没有预定义奖励函数的情况下有效进行离线学习。TROFI 首先从人类偏好中学习一个奖励函数，然后利用此奖励函数对原始数据集进行标注，使其可用于训练策略。与其他方法相比，该方法不需要最优轨迹。通过在 D4RL 标准基准上的实验，我们展示了 TROFI 比基线方法表现更优，并且与使用真实奖励函数来学习策略的表现相当。此外，我们在一个三维游戏环境中验证了该方法的有效性。我们的研究还强调了奖励函数在此情景下的重要性：我们需要一个设计良好且易于学习的奖励函数，以确保价值函数与实际未来折现奖励的对齐。", "innovation": "提出了一种名为 TROFI 的方法，可以在没有预定义的奖励函数的情况下，通过学习从人类偏好中得到的奖励函数来标注训练集，从而实现有效的离线学习。", "conclusion": "TROFI 在 D4RL 标准基准上的实验结果表明，该方法比基线方法表现更好，并且与使用真实奖励函数学习策略的表现相当。此外，TROFI 在三维游戏环境中的应用验证了其有效性。我们的研究表明，一个好的、易于学习的奖励函数对于确保价值函数与实际未来折现奖励的对齐至关重要。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22039", "html_url": "https://arxiv.org/abs/2506.22039", "title": "UniCA: 调整时间序列基础模型以适应通用协变量感知预测", "title_en": "UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting", "authors": "Lu Han,Yu Liu,Qiwen Deng,Jian Jiang,Yinbo Sun,Zhe Yu,Binfeng Wang,Xingyu Lu,Lintao Ma,Han-Jia Ye,De-Chuan Zhan", "background": "时间序列基础模型（TSFMs）通过大规模预训练取得了显著的成功，但它们的设计主要针对实值时间序列，限制了它们处理涉及各种和通常是异构协变量（如类别变量和多模态数据，例如图像、文本）的一般预测任务的能力，这些协变量通常是任务特定的且难以在预训练期间充分利用。针对这一缺口，我们提出了统一协变量适应（UniCA），这是一种将TSFMs与通用协变量感知预测结合起来的框架。首先，UniCA执行协变量同质化，将异构协变量转化为高层次的同质系列表示，然后通过统一的注意力融合机制进行融合。UniCA与同质和异构协变量都兼容且通用，可以整合额外的协变量信息同时保持TSFM的一般泛化能力。", "innovation": "提出了统一协变量适应（UniCA）框架，该框架通过协变量同质化和统一的注意力融合机制，解决了时间序列基础模型在处理异构协变量和多模态数据时的局限性，实现了对各种任务的广泛适用性，提升了时间序列预测的灵活性和准确性。", "conclusion": "在多个单模态和多模态协变量感知预测基准上的实验表明，UniCA表现出显著的优势，突显了协变量感知TSFM在现实世界预测场景中调整和应用的潜力。代码已经发布。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22095", "html_url": "https://arxiv.org/abs/2506.22095", "title": "学习解决多重目标多图路径规划问题", "title_en": "Learning to Solve Multi-Objective Routing Problems on Multigraphs", "authors": "Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár", "background": "近年来，基于学习的方法在单目标和多目标路径规划中获得了显著关注。然而，多图环境中的路径规划，即在两个目的地之间存在具有不同属性的多条路径，这一设置虽高度相关但在实践中却未得到足够关注。本文即着眼于解决此类问题，旨在探索有效的学习方法来应对多目标多图路径规划问题。", "innovation": "本文提出了两种基于神经网络的方法来解决多目标多图路径规划问题。一种方法直接在多图中逐步选取边缘形成路径；另一种方法先将多图简化成简单图，再构造路径。这两套方法通过实验验证表现出强大的性能，特别在旅行商问题（TSP）和容量受限车辆路径规划问题（CVRP）等多个场景中表现出色。", "conclusion": "本文通过实验验证了两种基于学习的路径规划方法的有效性，表明在多方配置问题上的应用具有广阔前景。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22084", "html_url": "https://arxiv.org/abs/2506.22084", "title": "Transformer是图神经网络", "title_en": "Transformers are Graph Neural Networks", "authors": "Chaitanya K. Joshi", "background": "本文将Transformer架构，最初用于自然语言处理，与图神经网络（GNNs）相结合，用于图上的表示学习。文章指出，Transformer可以被视为在完全连接的令牌图上操作的消息传递GNN，自注意力机制捕捉所有令牌相互之间的相对重要性，位置编码提供关于序列顺序或结构的线索。因此，Transformer是一种表达性的集合处理网络，能够在无需约束先验图的情况下学习输入元素之间的关系。", "innovation": "尽管Transformer与GNNs从数学上存在联系，但Transformer通过密集矩阵操作实现，相比于稀疏消息传递在现代硬件上效率更高。这种观点认为，Transformer目前是“赢得硬件彩票”的GNNs。", "conclusion": "Transformer是GNNs的一种当前形式，这种形式由于其在硬件上的高效性而胜出。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21990", "html_url": "https://arxiv.org/abs/2506.21990", "title": "分析和微调 Whisper 模型用于机舱内多语言飞行员 speech 转录", "title_en": "Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit", "authors": "Kartheek Kumar Reddy Nareddy,Sarah Ternus,Julia Niebling", "background": "变压器编码器-解码器架构的发展已经对机器翻译、自动语音识别（ASR）以及指令基础聊天机器产生了重大突破。预训练模型通常在大量通用数据上进行训练，因此具有很强的泛化能力。然而，当应用于窄领域的应用场景，如航空舱内的飞行员对话转录时，这些模型面临具体词汇、多语言对话等特定领域特征的挑战，转录准确性较低。因此，本文研究和改进了使用 Whisper 模型进行航空舱内多语言飞行员对话转录的准确性。为了提高准确性，作者收集了大约85分钟的模拟舱录音和130分钟的飞行员访谈录音，并手动标注了内容。", "innovation": "本文提出了多种规范化方案以改进转录准确性，并通过一种性能优化的微调方法（Low-Rank Adaptation, LoRA）增强ASR（自动语音识别）性能。通过这些方法，模型的词错误率（WER）从未经规范化处理的预训练 Whisper 大型模型的68.49%显著降低到使用所提出的规范化方案进行微调的 Whisper 大型模型的26.26%。这是由于规范化过程使用了行业特定的校正方案，使得模型能够更好地适应多语言飞行员对话的复杂特性，提高了整体转录质量，特别是在特定词汇和多语言对话方面表现更为突出。", "conclusion": "本文通过收集和转录飞行员模拟舱和访谈录音，针对窄域应用——航空舱内的多语言飞行员对话转录，提出了具体的解决方案。通过规范化和性能优化的微调方法，有效提高了 Whisper 模型的转录准确性，证明了在特定领域调整预训练模型的可行性和有效性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22231", "html_url": "https://arxiv.org/abs/2506.22231", "title": "适应生成型人工智能的大学政策：高等教育中的机遇、挑战和政策解决方案", "title_en": "Adapting University Policies for Generative AI: Opportunities, Challenges, and Policy Solutions in Higher Education", "authors": "Russell Beale", "background": "生成型人工智能工具，尤其是大型语言模型（LLMs）如ChatGPT，正在改变高等教育的格局。大学在研发、教学和评估中越来越多地应用这些技术。一方面，LLMs可以提高生产力，同时具有生成创意、辅助编码与数据分析、撰写研究提案等功能。另一方面，其使用也引发了关于学术诚信、伦理边界和公平获取的大量关切。一项近期的研究表明，将近47%的学生在课程中使用LLMs，其中24%用于考试，7%用于整个作业。目前的检测工具准确率约为88%，仍存在约12%的误差率。", "innovation": "文章批判性地探讨了生成型AI带来的机会，深入分析了由此引发的多方面挑战，并提出了有效的政策解决方案。重点关注如何重新设计评估以抵御AI的威胁，加强师生培训，实施多层次的监管机制，并明确使用准则。", "conclusion": "文章综合了近期研究和案例研究的数据，强调为利用AI潜力同时保护学术诚信和公平，必须制定前瞻性的政策适应性机制。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22185", "html_url": "https://arxiv.org/abs/2506.22185", "title": "通过代理AI和MAPE-K集成实现自主微服务管理", "title_en": "Autonomic Microservice Management via Agentic AI and MAPE-K Integration", "authors": "Matteo Esposito,Alexander Bakhtin,Noman Ahmad,Mikel Robredo,Ruoyu Su,Valentina Lenarduzzi,Davide Taibi", "background": "微服务通过提供无与伦比的可扩展性和独立部署能力，正在颠覆云计算，但其分散的架构带来了严重的安全和管理挑战，可能威胁到系统的稳定性。为了应对这一挑战，需要一种能够支持自主异常检测和修复的框架，以应对高度分布式系统的管理难题。", "innovation": "提出了一种基于MAPE-K框架的代理AI驱动的自主监控和修复框架，旨在提供工业级别的解决方案来增强微服务的稳定性和安全性，使用户能够自定义该框架以提高系统稳定性、减少停机时间，并监控系统的广泛质量属性，如性能水平、容错性、安全性和异常管理等。", "conclusion": "该框架提供了实际可操作的解决方案，能够维持强大且安全的微服务。实践者和研究者可以根据其特点进一步定制，从而确保服务质量，维护系统稳定。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22299", "html_url": "https://arxiv.org/abs/2506.22299", "title": "CoATA: 有效整合拓扑和属性共增强的图神经网络", "title_en": "CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks", "authors": "Tao Liu,Longlong Lin,Yunfeng Yu,Xi Ou,Youan Zhang,Zhiqiu Ye,Tao Jia", "background": "图神经网络（GNNs）因其在学习图表示方面的出色能力而备受关注。然而，现实世界的图通常包含大量噪声和不完整性，这对GNNs的表现产生了严重的影响。现有的方法通常是通过单一维度的增强来解决这个问题，侧重于修饰拓扑结构或扰动节点属性，从而忽视了这两者之间的深入互动关系。", "innovation": "本文提出了CoATA，这是一种专门为拓扑和属性的共增强设计的双通道GNN框架。CoATA 通过传播结构信号来丰富和去噪节点属性，然后将增强的属性空间投影到节点-属性二分图中，以便进一步完善或重构底部的结构。CoATA 进一步引入对比学习，利用原型对齐和一致性约束，以促进增强图与原始图之间的相互校正。", "conclusion": "在七个基准数据集上的大量实验表明，所提出的CoATA 比现有的十一种最先进的基准方法表现更优，显示出其有效捕捉拓扑和属性之间协同关系的能力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22179", "html_url": "https://arxiv.org/abs/2506.22179", "title": "基于骨架的零样本动作识别的频率语义增强变分自编码器", "title_en": "Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition", "authors": "Wenhan Wu,Zhishuai Guo,Chen Chen,Hongfei Xue,Aidong Lu", "background": "零样本骨架动作识别旨在开发能够在训练过程中遇到的类别之外识别动作的模型。之前的应对策略主要集中在视觉和语义表示的对齐上，但往往忽视了语义空间中细微动作模式的重要性（例如，在喝水和刷牙时的手部动作）。为了弥补这些不足，本文提出了一种频率语义增强变分自编码器（FS-VAE）来探索基于频率分解的骨架语义表示学习方法。FS-VAE由频率增强模块、基于语义的动作描述以及校准的交叉对齐损失组成，以增强骨架语义学习并提高零样本动作识别的鲁棒性，捕获局部细节和全局对应关系，确保骨架和文本特征的稳健对齐，并有效弥合语义差距，弥补骨架序列中固有的信息损失。", "innovation": "本文提出的FS-VAE结合了频率增强模块和基于语义的动作描述，并引入了一种校准的交叉对齐损失，以提高零样本动作识别的性能。该方法特别关注动作的细微语言模式，通过频率分解增强骨架语义特征，从而实现对视觉和语义相似动作簇的稳健区分。", "conclusion": "在基准测试上的评估证明了本文方法的有效性，验证了频率增强语义特征能够实现对视觉和语义相似动作簇的稳健区分，从而提高零样本动作识别的能力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22331", "html_url": "https://arxiv.org/abs/2506.22331", "title": "Less Greedy Equivalence Search", "title_en": "Less Greedy Equivalence Search", "authors": "Adiba Ejaz,Elias Bareinboim", "background": "Greedy Equivalence Search (GES) 是一种基于评分的经典算法，用于从观测数据中发现因果关系。在样本限制条件下，GES能够恢复描述数据的马尔可夫等价类图。然而，实际应用中面临着计算成本高和有限样本精度低的挑战。", "innovation": "研究人员提出了Less Greedy Equivalence Search（LGES），这是一种改进的版本，保留了GES的理论保证，同时部分解决了上述的局限性。LGES通过修改贪心步骤，即避免在评分暗示某些条件独立的变量之间插入边，实现了10倍的速度提升和显著减少结构错误。此外，LGES能够利用先验假定引导搜索，并在与数据矛盾时修正这些假设。进一步，它可以利用干预数据来细化学到的观测等价类。理论证明，即使在先验假设错的情况下，使用观测和干预数据LGES也能恢复真实等价类。实验表明，LGES在速度、准确性和对错规定先验假设的鲁棒性方面优于GES和其他基准方法。", "conclusion": "我们证明，Even在先验假设错的情况下，LGES仍然可以在样本极限下从观测和干预数据中恢复真实的等价类。实验结果表明LGES在速度、准确性和对错规定先验假设的鲁棒性方面均优于GES和其他基准方法。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22146", "html_url": "https://arxiv.org/abs/2506.22146", "title": "视觉结构有助于视觉推理：解决VLMs中的绑定问题", "title_en": "Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs", "authors": "Amirmohammad Izadi,Mohammad Ali Banayeeanzade,Fatemeh Askari,Ali Rahimiakbar,Mohammad Mahdi Vahedi,Hosein Hasani,Mahdieh Soleymani Baghshah", "background": "视觉-语言模型（VLMs）在视觉推理方面的能力受到所谓‘绑定问题’的限制：即感知特征与正确的视觉对象之间难以可靠关联的问题。这一问题在计数、视觉搜索、场景描述和空间关系理解等任务中表现得尤为明显。当前VLMs在处理视觉特征时通常采用并行方式，缺乏空间定位和序列注意力机制，导致这些任务的性能受限。", "innovation": "本文提出了一种简单有效的解决方案：通过对视觉输入添加低级的空间结构（例如水平线）并配以引导性文本提示，鼓励进行序列化和空间感知的解析，从而改进VLMs处理视觉推理任务的效果。实验结果表明，在核心视觉推理任务中，该方法表现出显著的性能提升，例如：提高GPT-4o的视觉搜索准确率25.00%，计数准确率26.83%，减少场景描述错误的编辑距离0.32，以及在2D合成数据集上提高空间关系任务的性能9.50%。我们还发现，这种视觉修改对于这些改进至关重要；仅凭文本策略，如因果思维提示，是不够的，甚至会降低性能。该方法证明了单次查询推理中视觉输入设计的重要性，超过纯粹基于语言的方法。我们的发现指出了低级视觉结构化对于提高组合式视觉推理能力的强大作用，并可作为增强VLMs在空间化任务表现的一种一般策略。", "conclusion": "低级视觉结构化是提高组合式视觉推理能力和增强VLMs在空间化任务表现的一种强有力且未被充分利用的方向。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22200", "html_url": "https://arxiv.org/abs/2506.22200", "title": "EFRame: 通过探索-过滤-重放强化学习框架实现更深层次的推理", "title_en": "EFRame: Deeper Reasoning via Exploration-Filtering-Replay Reinforcement Learning Framework", "authors": "Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yue Wang,Yuzhi Zhang", "background": "近年来，强化学习（RL）的进步显著提高了大型语言模型（LLMs）的推理能力。尽管相对策略优化（GRPO）是一种高效的PPO变体，能够降低RL的计算成本，但GRPO仍然面临探索不足、样本效率低和不稳定性的局限性，这限制了其在复杂推理任务中的表现。为了应对这些挑战，本文介绍了探索-过滤-重放（EFRame）框架，该框架沿着三个关键维度系统地扩展了GRPO，旨在解决上述问题。EFRame通过额外执行采样来探索高质量轨迹，通过在线过滤来剔除低质量且引入噪音和方差的样本，并通过经验重放来多次利用罕见但有价值的样本，从而建立了一个完整且稳定的学习周期，引导模型从探索到收敛的结构化转变。", "innovation": "EFRame框架通过探索-过滤-重放的方式改进了GRPO，实现了对高质量轨迹的扩展，通过在线过滤移除低质量样本，利用经验重放多次利用有价值样本，从而提高模型的鲁棒性和效率。此外，EFRame还使得不同类型的训练样本可以进行更精细的分类，以便对不同类型样本在RL学习过程中贡献进行更深入的分析。这些改进不仅优化了GRPO的训练过程，还使之前无法通过GRPO实现的更深层次推理成为可能。", "conclusion": "实验结果表明，EFRame不仅提高了训练过程的稳定性和效率，而且还使模型获取了以前在基本GRPO下无法获得的更深层次的推理能力。此外，EFRame框架提供了一种更细致的训练样本分类方法，促进了对不同类型样本在学习过程中的贡献的深入理解。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22255", "html_url": "https://arxiv.org/abs/2506.22255", "title": "Projected Compression: 可训练投影用于高效Transformer压缩", "title_en": "Projected Compression: Trainable Projection for Efficient Transformer Compression", "authors": "Maciej Stefaniak,Michał Krutul,Jan Małaśnicki,Maciej Pióro,Jakub Krajewski,Sebastian Jaszczur,Marek Cygan,Kamil Adamczewski,Jan Ludziejewski", "background": "大型语言模型的规模持续增加，以提高性能；然而，这种增长也导致了推理时间更长和计算需求增加。因此，对模型尺寸减少方法的兴趣日益增长。为了解决这个问题，我们提出了一种名为Projected Compression的新模型压缩技术，该技术通过使用投影模块减少模型权重。这种方法首先训练额外的可训练投影权重，并保留对所有原始模型参数的访问。随后，这些投影合并到一个低维度乘积矩阵中，从而形成一个减少后的标准Transformer模型。与需要额外计算开销的替代方法不同，我们的方法在浮点运算（FLOPs）中与基础模型的每令牌计算步骤相匹配。实验结果表明，Projected Compression优于在高质量模型上具有可比性的硬剪枝和重新训练方法。此外，性能优势随着令牌数量的增长而显著增加。", "innovation": "Projected Compression是一种新颖的模型压缩技术，通过利用投影模块来减少模型权重。这个方法在FLOPs中与基础模型的每令牌计算步骤相匹配，而不是需要额外的计算开销。它通过训练额外的可训练投影权重和将这些投影合并到一个低维度乘积矩阵中来实现效果。这种方法在高质量模型上优于比较性的硬剪枝和重新训练方法。", "conclusion": "实验结果表明，Projected Compression在高质量模型上优于其比较性的硬剪枝和重新训练方法。随着令牌数量的增长，它的性能优势也会得到很好的扩展。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22342", "html_url": "https://arxiv.org/abs/2506.22342", "title": "多数据源隐私保护传染病分析框架", "title_en": "A Framework for Multi-source Privacy Preserving Epidemic Analysis", "authors": "Zihan Guan,Zhiyuan Zhao,Fengwei Tian,Dung Nguyen,Payel Bhattacharjee,Ravi Tandon,B. Aditya Prakash,Anil Vullikanti", "background": "在关键的传染病和公共卫生分析中，多样的数据集提供了很大的价值，如预测、现在预测、流行病模型开发、干预措施评估和资源分配等。一些这些数据集往往涉及到敏感信息，需要适当的隐私保护。在许多隐私保护模型中，差分隐私(DP)因其强大且不依赖于对手模型的保证而成为事实上的标准。本文的研究背景是利用包含一定差分隐私保障的数据集，集成深度学习和流行病模型框架进行多数据源的隐私保护传染病分析，以同时进行流行病预测和学习传染病传播机制模型。", "innovation": "本文开发了一个框架，通过集成深度学习和流行病模型，同时实现流行病预测和学习传染病传播机制模型。该框架能够整合包括具有差分隐私保证在内的多个数据集进行分析。作者使用一个现实但合成的金融数据集来展示这一框架（该数据集具有差分隐私保障，在流行病分析中尚未被用过）。研究表明，即使在具有差分隐私保障的情况下，该数据集也能显著提升流行病预测和建模的价值。", "conclusion": "本文提出的方法，利用差分隐私保护的合成金融数据集进行传染病分析，证明了这一方法在隐私保护同时进行流行病预测和建模的潜力和优势。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22291", "html_url": "https://arxiv.org/abs/2506.22291", "title": "RoomCraft: 可控且完整的三维室内场景生成", "title_en": "RoomCraft: Controllable and Complete 3D Indoor Scene Generation", "authors": "Mengqi Zhou,Xipeng Wang,Yuxi Wang,Zhaoxiang Zhang", "background": "计算机视觉及图形学领域在从用户输入生成逼真的三维室内场景方面面临诸多挑战，需要在几何一致性、空间关系和视觉真实度之间取得平衡。尽管神经生成方法能够生成图像，但由于全局空间推理有限，常常会导致重复元素的出现；而程序化方法虽然能够利用约束进行可控生成，但在处理多种约束的情况下难以避免家具碰撞，这将导致需移除家具并破坏版图完整性。例如，在复杂多约束场景下，海量限制常常引发家具碰撞，迫使移除家具，影响布局完整性。因此，现有方法还存在生成3D室内场景不真实、布局不完整等问题的限制。", "innovation": "我们提出了名为RoomCraft的多阶段管道方法，能够根据实际图片、草图或文本描述生成连贯的三维室内场景。RoomCraft将场景生成管道与基于约束的优化框架相结合。首先，从用户的输入中提取高层次的场景信息，组织成包含房间类型、家具项目和空间关系的结构化格式。然后建立一个空间关系网络，表达家具排列，并使用基于启发式的深度优先搜索（HDFS）算法生成优化放置序列，以确保布局的一致性。通过引入统一的约束表示方法，能够同时处理形式化规范和自然语言输入，并通过全面的动作空间设计实现灵活的基于约束的调整。此外，我们提出了冲突感知定位策略（CAPS），能够动态调整放置权重，最小化家具碰撞，确保布局完整性。", "conclusion": "实验结果表明，与现有方法相比，RoomCraft在多种输入模态下可以生成更真实、语义一致且视觉上更具吸引力的房间布局。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22376", "html_url": "https://arxiv.org/abs/2506.22376", "title": "概率优化下的推理时动态比例采样", "title_en": "Probabilistic Optimality for Inference-time Scaling", "authors": "Youkang Wang,Jian Wang,Rubing Chen,Xiao-Yong Wei,Qing Li", "background": "推理时动态比例采样作为一种增强大语言模型（LLMs）推理性能的强大技术逐渐引起了关注。然而，现有的方法往往依赖于启发式的方法来进行并行采样，缺乏一个系统的基础。为解决这个问题，本文提出了一种概率框架，该框架在并行样本独立同分布（i.i.d.）的假设下正式化了推理时比例采样的最优性，并说明了Best-of-N选择策略的概率分布可以根据经验进行估计。在此框架下，推导出一个理论下界，以达成目标性能水平所需的样本数量，从而为计算效率的采样提供了系统的指导。", "innovation": "本文发展了OptScale算法，这是一种实用的算法，可以根据既定性能阈值和置信度动态地确定所需样本的最小数量。OptScale利用基于语言模型的预测器估计概率先验参数，这使得决策如何选择满足这些先验参数最小样本数量成为可能。广泛的数学推理基准（包括MATH-500、GSM8K、AIME和AMC）实验结果表明，OptScale在减少采样开销的同时，保持了与最先进的推理性能相当甚至更好的性能。这项工作为大语言模型的有效部署提供了一个理论基础和实用解决方案，解决了复杂推理中高效部署的关键问题。", "conclusion": "本文在理论上和实践上都提供了一种系统的方法来优化推理时的动态比例采样，解决了大语言模型在复杂推理中的高效部署问题。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22360", "html_url": "https://arxiv.org/abs/2506.22360", "title": "从地面到空中：用于事件驱动车辆分类的Vision Transformers和CNN噪声鲁棒性及其在无人机应用中的潜力", "title_en": "From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications", "authors": "Nouf Almesafri,Hector Figueiredo,Miguel Arana-Catania", "background": "该研究调查了两种最相关计算机视觉深度学习架构，即卷积神经网络（CNN）和视觉变换器（Vision Transformer），在事件驱动相机上的性能。事件驱动相机用于捕捉场景的变化而非传统帧驱动相机捕获静态图像的方式，特别适合于动态环境，如无人机和自动驾驶车辆。研究表明，ResNet34和ViT B16在清洁GEN1数据集上的初始评估分别达到了88%和86%的准确率，尽管ResNet34在分类精度上略有优势，但ViT B16模型因其在较小数据集上预训练显示出了出色的鲁棒性。该研究不仅关注地面车辆的分类，还暗示了其在无人机领域的应用潜力，包括空中的目标识别和与航空相关任务的事件驱动视觉系统。", "innovation": "研究引入了两种深度学习模型（ResNet34 和 ViT B16）在事件驱动相机上的性能研究，特别是在有噪声条件下的表现。研究对比了卷积神经网络和视觉变换器的精度，发现视觉变换器由于其在较小数据集上的预训练体现出更强的鲁棒性。研究为无人机领域的目标识别提供了新的方法和潜在应用前景，特别是在噪声环境下表现出色的视觉变换器模型。", "conclusion": "研究结果表明，尽管卷积神经网络在干净数据集上有略微较高的分类准确率，视觉变换器模型由于其在较小数据集上的预训练显示出更加出色的鲁棒性。虽然本研究的重点是地面车辆的分类，但所采用的方法和获得的结论很有可能适用于无人机和其他航空相关的应用任务。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22393", "html_url": "https://arxiv.org/abs/2506.22393", "title": "多视角对比学习在医学时间序列分析中稳健领域适应", "title_en": "Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis", "authors": "YongKyung Oh,Alex Bui", "background": "跨不同领域的医学时间序列数据适应机器学习模型仍然是一个挑战，因为它们存在复杂的时序依赖性和动态分布偏移。当前的方法通常只关注孤立特征表示，这限制了它们完全捕捉必要的时序动态以实现稳健领域适应的能力。", "innovation": "本文提出了一种新颖的框架，利用多视角对比学习来结合时序模式、基于导数的动力学以及频率域特征。该方法采用独立编码器和分层融合机制来学习在不同领域内传输且保持时序一致性的特征不变表示。在多种医学数据集（包括脑电图（EEG）、心电图（ECG）和肌电图（EMG））上进行了广泛实验，结果显示该方法在迁移学习任务中显著优于最先进方法。", "conclusion": "通过增强机器学习模型的稳健性和泛化能力，本文框架提供了一条在多种医疗环境中部署可靠AI系统的实际路径。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22359", "html_url": "https://arxiv.org/abs/2506.22359", "title": "电信领域的概念级AI：超越大型语言模型", "title_en": "Concept-Level AI for Telecom: Moving Beyond Large Language Models", "authors": "Viswanath Kumarskandpriya,Abdulhalim Dandoush,Abbas Bradai,Ali Belgacem", "background": "当前电信和网络领域正面临一个变革时代，由于需要管理日益复杂且具有多级行政域结构的网络环境（即同一条路径上有多个操作商）和多语言系统，因此迫切需要新的处理方法。近期研究表明，大型语言模型在通用文本分析和代码生成方面表现出色，可以应用于某些电信问题（如自动生成数据包以满足特定应用需求）。然而，这些模型由于逐词处理的特性和有限的长句记忆能力，在解决跨层依赖、时间空间故障关联和实时分布式协调等特殊电信需求时存在局限性。相比之下，大型概念模型在抽象层面处理语义概念而非单一词汇，能够从根本上解决这些电信问题，通过使用双曲潜空间实现高效层次表示，并将复杂的多层网络交互压缩为简洁的概念嵌入，克服了大型语言模型在内存效率、跨层关联和原生多模态集成方面的关键不足。", "innovation": "该研究提出了采用大型概念模型作为处理电信问题的新方法，这种方法在处理复杂电信场景如跨层依赖、时间空间故障关联等方面更为有效，与传统的大型语言模型相比，改进了内存效率、跨层关联和原生多模态集成等关键方面。", "conclusion": "论文主张采用大型概念模型不仅是技术的逐步改进，而是实现稳健有效的AI驱动电信管理的必要进化飞跃。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22321", "html_url": "https://arxiv.org/abs/2506.22321", "title": "在使用带宽扩展的次奈奎斯特采样法中实现hearables的节能实用方法", "title_en": "A Practical Approach to Power Saving in Hearables Using Sub-Nyquist Sampling with Bandwidth Extension", "authors": "Tarikul Islam Tamiti,Anomadarshi Barua", "background": "hearables是在耳朵上佩戴的可穿戴计算机，通常使用空气传导麦克风(ACM)和骨传导麦克风(BCM)来增强在嘈杂环境下的语音识别。现有研究没有充分考虑hearables中的低功耗实现：(i) 未探索在hearables的模数转换器(ADC)中降低采样频率和位分辨率如何影响功耗和语音质量；(ii) 未讨论如何实现类似生成对抗网络(GAN)的音频质量而不使用GAN的判别器；(iii) 未在小于奈奎斯特采样的信号上处理信号，因为缺乏将窄带部分重构为宽带的宽频带重建方法，这导致无法在移动平台上下采样操作和在实际环境中的语音增强应用有了明确的时间和内存限制问题。", "innovation": "该方法（SUBARU）实现了以下创新：(i) 有意在ADC中使用次奈奎斯特采样和低位分辨率，以实现3.31倍的功耗降低；(ii) 引入了多尺度和多周期的虚拟判别器，以在不使用GAN对抗训练的情况下实现类似GAN的音频质量；(iii) 在移动平台上实现了流式操作和实际环境中的语音增强应用，达到了1.74ms的推断时间和小于13.77MB的内存使用量。", "conclusion": "SUBARU在采样率和位分辨率上采用次奈奎斯特方法，实现了低功耗和音频质量的平衡。同时，通过引入新颖的虚拟判别器，它无需使用GAN训练就能达到类似GAN的效果。这种方法允许在移动平台上实时处理信号并实现语音增强，满足了实际应用的低延迟和低内存需求。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22374", "html_url": "https://arxiv.org/abs/2506.22374", "title": "基于丛的分布式多模态学习为下一代无线通信系统", "title_en": "Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems", "authors": "Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis", "background": "在大规模通信系统中，复杂场景需要边缘设备收集各种多模态传感器数据以实现对环境的全面理解并提高决策的准确性。然而，传统的联邦学习算法通常只针对单一模态数据集，需要相同的模型架构，并且无法利用嵌入在多模态数据中的丰富信息，限制了这些算法在具有多种模态和不同客户端能力的现实场景中的应用能力。", "innovation": "本研究提出了一种新型分布式多模态学习框架Sheaf-DMFL，通过丛理论增强具有不同模态的设备之间的协作。每个客户端有专门为不同模态设计的本地特征编码器，其输出在经过特定任务层之前被连接起来。同时，使用丛结构来捕获客户端特定任务层之间的内在关联。为了增强学习能力，还提出了Sheaf-DMFL-Att算法，该算法在每个客户端中定制注意力机制以捕捉不同模态之间的关联。并且提供了Sheaf-DMFL-Att算法的严格的收敛性分析，确保其理论上的有效性。", "conclusion": "通过在现实世界的链路阻断预测和毫米波波束形成场景中进行广泛的仿真，证明了所提出算法在异构无线通信系统中的优越性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22385", "html_url": "https://arxiv.org/abs/2506.22385", "title": "视频大型多模态模型能像持怀疑态度的人思考吗——或进一步巩固立场：关于可反驳视频蕴含的研究", "title_en": "Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment", "authors": "Yue Zhang,Jilei Sun,Yunhui Guo,Vibhav Gogate", "background": "尽管视频大型多模态模型（VLMMs）在理解视频内容方面取得了显著进步，但它们在处理抽象和适应性推理方面的能力较差，特别是当新信息出现时需要修改最初的解释。结论并非总是固定不变的，额外的上下文可能增强或削弱最初得出的推断。因此，作者提出了'可反驳视频蕴含'（DVidE）任务，挑战模型不断更新其推理，以适应不断演变的证据。", "innovation": "作者提出了一种新的任务DVidE，旨在提升视频大型多模态模型的动态推理能力。为了解决分类任务，提出了一种基于“假设情景推理链”的框架，结合了反事实推理、ASR增强的视频内容和解释辅助以减少推理偏见。为生成任务，开发了一种框架，结合ASR输出和大型语言模型（LLM）生成上下文相关、符合正确加强或削弱目标的连贯更新。此外，还创建了一个新的基准数据集，其中包括加强器/削弱器注释以及基于大型语言模型的评估指标，专门设计用于评估生成性能。实验结果表明，这种方式在增强动态推理能力方面取得了显著成效。", "conclusion": "实验结果表明，所提方法在增强动态推理能力方面取得了显著成效，验证了该研究的有效性，从而提高了视频大型多模态模型在面对新证据时进行动态思考和修正的能力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22396", "html_url": "https://arxiv.org/abs/2506.22396", "title": "QuickSilver -- 通过动态token停止、KV缓存跳过、上下文token融合和自适应Matryoshka量化加速LLM推理", "title_en": "QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization", "authors": "Danush Khanna,Aditya Kumar Guru,Srivarshinee Sridhar,Zidan Ahmed,Rubhav Bahirwani,Meetu Malhotra,Vinija Jain,Aman Chadha,Amitava Das,Kripabandhu Ghosh", "background": "在大型语言模型（LLM）的部署中，推理阶段占用多数的延迟时间和能源消耗，通常超过总成本的90%。尽管训练效率已有显著提升，但在自动回归解码下的运行时优化仍然是关键瓶颈。现有方法如剪枝、量化、早退出和推测解码等往往需要重新训练、改变架构或破坏解码兼容性。", "innovation": "我们提出了QuickSilver，这是一个模块化的、基于token的框架，能够在推理阶段实现语义适应性，而不改变模型权重或结构。QuickSilver整合了四个协同机制：(i) 动态Token停止，用于停止已收敛表示的tokens的计算；(ii) KV缓存跳过，有选择地抑制内存写入以减少注意力开销；(iii) 上下文Token融合，将冗余的tokens合并到共享路径中以缩短序列长度。QuickSilver完全基于不动的、密集的模型运作，并不需要辅助网络。", "conclusion": "在GPT-2和Llama-2模型上应用于WikiText-103和C4数据集时，QuickSilver实现了高达39.6%的FLOP减少，同时对困惑度的影响也几乎可以忽略不计（<=0.2）."}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22338", "html_url": "https://arxiv.org/abs/2506.22338", "title": "使用VHR SAR和地理空间数据进行建筑物损坏评估的深度学习框架：以2023年土耳其地震为例", "title_en": "A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake", "authors": "Luigi Russo,Deodato Tapete,Silvia Liberata Ullo,Paolo Gamba", "background": "在灾害发生后迅速识别建筑物损坏对于指导应急响应和重建工作至关重要。尽管光学卫星图像常用于灾害映射，但云覆盖或缺乏事前获取的图像限制了其有效性。为了克服这些挑战，本文引入了一种新的多模态深度学习框架，用于使用意大利空间局（ASI）COSMO SkyMed（CSK）星座的单日期非常高分辨率（VHR）合成孔径雷达（SAR）图像检测建筑物损坏，并结合辅助地理空间数据。这种方法整合了SAR影像块、OpenStreetMap（OSM）建筑足迹、数字表面模型（DSM）数据和全球地震模型（GEM）提供的结构和暴露属性，以提高检测准确性和上下文解释能力。与依赖事前和事后图像的现有方法不同，本文模型仅使用事后数据，便于在关键状况下快速部署。该框架通过2023年土耳其地震后的数据集进行了验证，覆盖了多个具有不同城市环境的城市，结果显示，结合地理空间特征显著增强了检测性能和对新未知区域的泛化能力。将SAR影像与详细的脆弱性和暴露信息相结合，该方法提供了可靠的快速建筑物损坏评估，无需依赖可用的事前数据。此外，自动化的数据生成过程确保该框架适用于各种受灾地区，突显了其支持有效灾害管理和恢复工作的潜力。", "innovation": "本文创新地提出了一种基于单日期VHR SAR影像和结合辅助地理空间数据的新型多模态深度学习框架，用于快速和准确地评估建筑物损坏，无需依赖事前数据。这种方法提高了检测性能，并能有效推广到不同地区的灾害管理中。它展示了自动化和可扩展的数据生成过程，确保了在各种情况下应用的适用性。此外，该方法还节省了数据采集的时间和成本，因为只需要事后数据，而不需要进行全面的灾前调查。", "conclusion": "本文介绍的多模态深度学习框架通过融合SAR图像和地理空间数据，提供了一种可靠而快速的建筑物损坏评估方法，特别适用于在发生灾害而无法获取事前卫星图像的情况下。此方法在2023年土耳其地震中的应用证明了其有效性，强调了其对灾难管理与恢复工作的潜在支持作用。最终，该框架的开源性和可扩展性为进一步的研究和应用提供了便利。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22389", "html_url": "https://arxiv.org/abs/2506.22389", "title": "分布式神经架构的发展", "title_en": "Towards Distributed Neural Architectures", "authors": "Aditya Cowsik,Tianyu He,Andrey Gromov", "background": "本文介绍并训练了图像和语言领域的分布神经架构（DNA），其初始架构由多智能体、MLP、注意力机制等模块和路由器构成。任何输入元素（或块）可以沿任何模块序列（任意顺序）进行传递。DNA是一种稀疏方法（如混合专家、混合深度、参数共享等）的自然扩展。计算和通信模式在训练过程中被端到端地学习，并且取决于每个元素（或块）的内容和上下文。此外，通过优化目标附加的要求，如计算/内存效率或负载均衡，这些模式也可以被塑造。\n这些模式可以从数据中获得，进而提升计算效率和参数共享能力。通过实验展示了训练后的DNA架构在稠密基线性能上具有竞争力，并证明从数据中学习计算效率和参数共享是可行的。同时，分析了训练完成后的DNA中这些架构的涌现连接和计算模式，发现路径本身的分布遵循幂律分布。某些路径或等效的模块组展现了自适应的专家化。模型在计算和活动参数分配上学会了一种可解释的方式，从而证明了智能模块自主学习的有效性。\n总之，此研究在特定领域内探讨了DNA架构的发展，通过其特性的展示，验证了其在实际计算效率和自适应专家化方面的潜力。", "innovation": "分布式神经架构（DNA）是一种新颖的架构，其初始架构通过模块和路由器构建，任何输入元素可以沿任意模块序列进行传递。在训练过程中，计算和通信模式被端到端地学习，并且能够从数据中获得计算和参数共享效率。此架构作为一种稀疏方法（如混合专家、混合深度、参数共享等）的自然扩展，展现了更高层面的智能自适应和自适应专家化。\n通过实验展示了训练后的DNA架构在稠密基线性能上具有竞争力，并证明从数据中学习计算效率和参数共享是可行的。研究发现，路径本身的分布遵循幂律分布，某些路径或等效的模块组展现了自适应的专家化。模型在计算和活动参数分配上学会了一种可解释的方式，从而证明了智能模块自主学习的有效性。\n总之，该架构提供了新的视角和思路，能够带来计算效率和参数共享方面的提高，展示了智能自适应和自适应专家化。</span>\n", "conclusion": "这一研究表明，当进行训练后，DNA架构在图像和语言领域中与密集基线相比展现出竞争力。计算效率和参数共享可以从数据中获得，模型在分配计算和活动参数上学会了解释性的方式。从实验结果来看，DNAs的模块路径分布符合幂律，某些路径或模块组表现出自我专业化的特性。模型在计算和活动参数的分配上找到了一种可解释的机制，这个实证研究揭示了分布式架构的潜在优势，并对未来的研究提供了指导。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.07461", "html_url": "https://arxiv.org/abs/2408.07461", "title": "通过人机偏好合作解决问题", "title_en": "Problem Solving Through Human-AI Preference-Based Cooperation", "authors": "Subhabrata Dutta,Timo Kaufmann,Goran Glavaš,Ivan Habernal,Kristian Kersting,Frauke Kreuter,Mira Mezini,Iryna Gurevych,Eyke Hüllermeier,Hinrich Schuetze", "background": "虽然人们普遍相信通用人工智能（AGI）甚至是超级人工智能即将出现，但专家领域中的复杂问题仍未得到解决。这些问题需要人类与人工智能的合作，而当前生成式人工智能因多种缺点无法成为可靠合作者，如难以管理复杂解决方案（例如软件程序）、对人性化表达的支持有限，以及缺乏在交互环境中适应人类偏好的能力。", "innovation": "本文提出了一种新颖的人机联合构建框架HAICo2，旨在解决上述挑战，并初步探讨了该框架的实质化及其面临的研究难题。", "conclusion": "提出了HAICo2框架，并讨论了它所面临的开放性研究问题，为进一步的研究奠定了基础。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.01511", "html_url": "https://arxiv.org/abs/2407.01511", "title": "CRAB: 多环境自主代理基准测试", "title_en": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents", "authors": "Tianqi Xu,Linyao Chen,Dai-Jie Wu,Yanjun Chen,Zecheng Zhang,Xiang Yao,Zhiqiang Xie,Yongchao Chen,Shilong Liu,Bochen Qian,Anjie Yang,Zhaoxuan Jin,Jianbo Deng,Philip Torr,Bernard Ghanem,Guohao Li", "background": "自主代理的发展越来越依赖于多模态语言模型（MLMs）来执行自然语言描述的任务，特别是在GUI环境中，如网站、桌面电脑或移动电话。现有的MLM代理基准通常局限于单个环境，并且缺乏细致和通用的评估方法，构建任务和评估者也较为复杂。", "innovation": "我们介绍了Crab，这是第一个支持跨环境任务的代理基准框架，包含基于图的细粒度评估方法和一个高效的任务与评估者构建机制。Crab框架支持多种设备并可通过Python接口轻松扩展到任何环境中。我们使用Crab构建了一个跨平台的Crab Benchmark-v0，其中包含120个任务，涵盖计算机桌面和移动电话环境。利用Crab，我们对四种先进的MLM进行了评估，通过单个和多个代理系统的不同配置。实验结果显示，单个代理配备GPT-4o实现了最高的完成比38.01%。", "conclusion": "该框架的代码、代理代码和任务数据集已公开发布。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.19723", "html_url": "https://arxiv.org/abs/2412.19723", "title": "OS-Genesis: 通过逆向任务合成自动GUI代理轨迹构建", "title_en": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis", "authors": "Qiushi Sun,Kanzhi Cheng,Zichen Ding,Chuanyang Jin,Yian Wang,Fangzhi Xu,Zhenyu Wu,Chengyou Jia,Liheng Chen,Zhoumianze Liu,Ben Kao,Guohao Li,Junxian He,Yu Qiao,Zhiyong Wu", "background": "图形用户界面（GUI）代理由视觉-语言模型（VLMs）驱动，展示了类似人类的计算机控制能力。尽管在促进数字自动化方面具有用处，但数据采集仍是一个关键瓶颈：高质量轨迹数据的收集。传统方法依赖人力监督或通过执行预定义任务生成合成数据，这两个方法耗时且难以保证数据质量。此外，这些方法存在数据多样性有限以及合成数据与现实环境之间存在显著差距的问题。", "innovation": "提出了一种新颖的GUI数据合成管道OS-Genesis，它改变了传统的轨迹采集过程。OS-Genesis首先让代理感知环境并执行逐步交互，然后回顾性地推导出高质量任务以实现轨迹级探索。使用轨迹奖励模型来确保生成轨迹的质量。", "conclusion": "通过OS-Genesis训练GUI代理显著提高了它们在高挑战性在线基准上的表现。深入分析进一步验证了OS-Genesis的高效性以及其在数据质量和多样性方面的优越性比现有合成方法更胜一筹。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22403", "html_url": "https://arxiv.org/abs/2506.22403", "title": "HyperCLOVA X THINK 技术报告", "title_en": "HyperCLOVA X THINK Technical Report", "authors": "NAVER Cloud HyperCLOVA X Team", "background": "介绍了HyperCLOVA X THINK，这是HyperCLOVA X系列的第一个专注于推理的大型语言模型，预训练使用了大约6万亿高质量的韩语和英语令牌，并通过有针对性的合成韩语文本进行了增强。该模型采用了计算和内存平衡的peri-LN Transformer，并通过多阶段课程训练技术扩展了上下文窗口至128K令牌，同时通过监督微调和基于可验证奖励的强化学习的方法进行优化，支持详细的推理模式和简洁的答案模式。该模型在关注韩国的基准测试（如KMMLU、CSAT、KoBALT-700、HAERAE-1.0、KoBigBench）中表现出竞争力，同时保持了双语一致性与翻译质量。此外，增强视觉的变体在KCSAT STEM基准测试中至少达到了GPT-4.1的水平，所有这些都以比现有同类大小模型低得多的训练计算量实现。", "innovation": "HyperCLOVA X THINK是HyperCLOVA X系列的第一个专注于推理的大型语言模型，采用计算和内存平衡的peri-LN Transformer，并通过三阶段课程训练技术扩展了上下文窗口至128K令牌。通过监督微调和基于可验证奖励的强化学习的方法进行优化，支持详细的推理模式和简洁的答案模式。此外，展示了用于开放源代码和企业友好的基础模型的剪枝和蒸馏技术。", "conclusion": "HyperCLOVA X THINK作为韩国AI创新的稳健基础，并作为全球研究团队的价值资源。该模型通过与类似规模的现有模型相比较低的训练计算量，成功地在韩国关注的基准测试中表现出竞争力，同时保持了双语一致性和翻译质量。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05801", "html_url": "https://arxiv.org/abs/2504.05801", "title": "从表面到深入：知识图谱和大语言模型集成外部知识进行跟问生成", "title_en": "From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and LLM", "authors": "Jianyu Liu,Yi Huang,Sheng Bi,Junlan Feng,Guilin Qi", "background": "在对话系统中，基于上下文动态生成跟进问题可以帮助用户探索信息并提供更好的用户体验。尽管人类可以提出涉及一般生活知识并展示较高层次认知技能的问题，但现有方法生成的问题通常局限于浅显的上下文问题，缺乏吸引力，难以达到人类的水平。这项研究旨在通过集成外部常识知识和知识图谱，提升对话系统生成高质量跟进问题的能力。", "innovation": "提出了一个三阶段的外部知识增强型跟进问题生成方法，通过识别上下文主题、构建在线知识图谱和最后结合大规模语言模型来生成最终问题。该模型通过引入外部常识知识并进行知识融合操作，生成了富含信息和探索性的跟进问题。实验结果显示，与基线模型相比，该方法生成的问题更具信息含量，更接近人类提问的水平，同时保持了上下文的相关性。", "conclusion": "通过集成外部常识和构建知识图谱，提出的生成方法显著提升了对话系统生成高质量跟进问题的能力，通过引入外部数据和知识融合增强了生成问题的质量和深度，从而更好地满足用户的信息探索需求。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01584", "html_url": "https://arxiv.org/abs/2503.01584", "title": "SENSEI：基于基础模型的语义探索学习通用世界模型", "title_en": "SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models", "authors": "Cansu Sancaktar,Christian Gumbsch,Andrii Zadaianchuk,Pavel Kolev,Georg Martius", "background": "强化学习中的探索是其基石。内在动机试图将探索与基于任务的外部奖励分离。目前基于信息增益等普遍原则的内在动机方法只能发现低层次的交互。相比之下，儿童的游戏表明他们能够通过模仿或与照顾者互动来产生有意义的高层次行为。研究工作最近将重点转向使用基础模型注入这些语义偏见以指导探索，但这些方法往往依赖于不现实的假设，如语言嵌入环境或获取高级动作访问。", "innovation": "我们提出了SENSEI框架，一种为模型驱动的RL代理注入语义上有意义的行为内在动机的方法。SENSEI通过Vision Language Model (VLM)注释提取有趣的奖励信号，使代理能够通过世界模型预测这些奖励。通过模型驱动的RL，SENSEI训练探索策略，同时最大化语义奖励和不确定性。在机器人和类似视频游戏的模拟中，SENSEI能够从图像观察和低级动作中发现多种有意义的行为。SENSEI提供了一个从基础模型反馈学习的一般工具，这是一个关键的研究方向，因为VLM变得越来越强大。", "conclusion": "SENSEI在帮助智能代理从图像观察和低级动作中探索并发现有意义的行为方面表现出了潜力，其内在动机是基于语义上显著的行为。这为通过基础模型的元学习能力扩展智能代理的能力提供了重要工具。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18536", "html_url": "https://arxiv.org/abs/2504.18536", "title": "将概率风险评估应用于人工智能", "title_en": "Adapting Probabilistic Risk Assessment for AI", "authors": "Anna Katariina Wisakanto,Joe Rogero,Avyay M. Casheekar,Richard Mallah", "background": "现代普遍适用的人工智能系统对风险管理构成了紧迫的挑战，因为这些系统的迅速发展能力和潜在的灾难性危害超出了我们对其风险的可靠评估能力。当前的方法常常依赖选择性测试和关于风险优先级的未记录假设，通常未能认真评估AI系统直接或间接对社会和生物圈的风险路径。", "innovation": "本文提出了针对人工智能的概率风险评估（PRA）框架，该框架借鉴了核电、航空航天等高可靠性行业已建立的PRA技术，以应对先进AI的新挑战。该框架引导评估者识别潜在风险、估计可能性和严重性区间，并明确记录证据、基础假设和分析。该框架的实施工具有序地合成了所有评估风险的风险报告卡，提供综合风险估计。该框架引入了三项方法学进展：面向方面的问题分析系统性覆盖潜在风险，风险路径建模分析系统方面到社会影响的因果链并结合双向分析和前瞻性技术；不确定性的管理采用场景分解、参考尺度和明确跟踪协议，以结构化具有新颖性或有限数据的可信预测。此外，该框架通过将多种评估方法整合为可量化的绝对风险估计，为生命周期决策提供了和谐的一致性.", "conclusion": "该框架以工作簿工具的形式实施，为人工智能开发者、评估者和监管者提供支持。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22427", "html_url": "https://arxiv.org/abs/2506.22427", "title": "CLoVE：基于损失向量嵌入聚类的个性化联邦学习", "title_en": "CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings", "authors": "Randeep Bhatia,Nikos Papadis,Murali Kodialam,TV Lakshman,Sayak Chakrabarty", "background": "在Clustered Federated Learning (CFL) 中，客户端根据数据分布自然分组，但确定这些组非常具有挑战性，因为客户端的分配是未知的。现有的CFL算法可能不够简单且可能需要近似最优的模型初始化，这限制了它们在实际应用中的使用。", "innovation": "CLoVE算法提出了一种新颖的方法来处理CFL中的客户端聚类问题，它通过使用基于客户端数据模型损失的客户端嵌入来识别和分离不同的聚类客户端，并通过联邦聚合优化特定聚类的模型。CLoVE的优势在于其简洁性、适用于有监督和无监督场景，以及它不需要近似最优的模型初始化，从而使其在实际应用中更具鲁棒性。此外，它能在一个回合中高概率准确恢复聚类，并在线性设置中指数级快速收敛至最优模型。", "conclusion": "CLoVE算法在多类型数据集和非同构数据设置上的综合实验表明，它只需几轮训练就能实现高度准确的聚类恢复，并在各种有监督和无监督的个性化联邦学习任务中实现了最先进的模型精度。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22397", "html_url": "https://arxiv.org/abs/2506.22397", "title": "使用引导条件流动匹配去雾荧光显微镜图像：在保真度和现实性之间找到甜蜜点", "title_en": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism", "authors": "Anirban Ray,Ashesh,Florian Jug", "background": "荧光显微镜是生命科学中的一大驱动力。高端共聚焦显微镜能够过滤掉焦外光，但更实惠和更易获取的显微镜技术，如宽场显微镜，则不能，导致图像数据模糊。已有的计算去雾方法试图结合这两种技术的优点，实现低成本显微镜但看得清晰的图像。现有方法要么注重保持数据的精确度，导致缺乏现实感，要么注重看起来逼真但缺乏量化准确度。这项研究背景是寻找在去雾结果的保真度和个体预测的现实性之间的平衡点，通过优化数据保真度和数据现实性之间的权衡来改进现有方法。", "innovation": "本文提出了一种名为HazeMatching的新迭代算法，旨在同时优化去雾结果的保真度和现实性。HazeMatching通过在条件速度场中引导生成过程的方式，采用适应条件流匹配框架，从而在保真度和现实性之间找到平衡点。研究对5个不同的数据集进行了测试，涵盖合成和真实数据，验证了在整体上去雾保真度和现实性的平衡性。此外，结果表明HazeMatching预测是良好的校准预测，而且算法设计使得无需显性的退化操作，便于实际应用。", "conclusion": "研究表明，HazeMatching方法在平均上可以在去雾结果的保真度和现实性之间取得一致的平衡。HazeMatching表现出良好的校准性能，且通过改进现有的去雾方法，能够在保持去雾质量的同时增强图像的现实性，使得该方法适用于实际的显微镜图像处理。该研究结果和代码将公开发布，供进一步研究使用。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.04950", "html_url": "https://arxiv.org/abs/2505.04950", "title": "可知论人工智能对于机器学习模型真正‘知道不知道’至关重要", "title_en": "Epistemic Artificial Intelligence is Essential for Machine Learning Models to Truly 'Know When They Do Not Know'", "authors": "Shireen Kudukkil Manchingal,Andrew Bradley,Julian F. P. Kooij,Keivan Shariatmadar,Neil Yorke-Smith,Fabio Cuzzolin", "background": "尽管人工智能在生成性和大型语言模型等领域取得了显著成就，但在处理不确定性、泛化超越训练数据方面仍存在明显不足。传统机器学习方法过于侧重于数据拟合，而当前的不确定性量化方法存在严重局限性。", "innovation": "提出了一种可知论人工智能的范式转变，强调模型在学习其所知的同时承认其无知，利用第二阶不确定性测量的数学理论，增强AI系统的弹性和鲁棒性，使其能够更好地应对不可预测的现实环境。", "conclusion": "可知论人工智能为提高AI系统的鲁棒性和适应性提供了一种有效途径，使其能够更好地应对不可预测的真实世界环境。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04412", "html_url": "https://arxiv.org/abs/2503.04412", "title": "在更宽还是更深？利用自适应分支树搜索扩展大语言模型推理时计算能力", "title_en": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search", "authors": "Yuichi Inoue,Kou Misaki,Yuki Imajuku,So Kuroki,Taishi Nakamura,Takuya Akiba", "background": "近期研究表明，增加推理时的计算量可以显著提升大语言模型（LLM）的推理能力。重复采样（即生成多个候选输出）是一种非常有效的策略，但它没有利用外部反馈信号进行改进，而这些信号在编程等任务中往往可用。现有方法未能有效结合LLM响应的多样性和多轮次解决方案的细化，以实现有效的推理时扩展能力。", "innovation": "本文提出了一种新的推理时框架——自适应分支蒙特卡洛树搜索（AB-MCTS），该框架在理论上扩展了重复采样的范畴，融入了基于外部反馈的多轮探索和利用策略。在树搜索的每个节点上，AB-MCTS根据外部反馈信号动态决定是“扩展新的候选响应”还是“回访现有的候选响应”，从而实现更有效的推理时扩展。该方法在前沿模型的复杂编程和工程任务上进行了评估，并展示了AB-MCTS在结果上的显著优势，尤其是在结合LLM的响应多样性和多轮次方案细化方面。", "conclusion": "实验证明，AB-MCTS在复杂编程和工程任务上的表现优于重复采样和标准蒙特卡洛树搜索，证明了结合LLM响应多样性和多轮次解决方案细化的必要性，以实现有效的推理时扩展。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13232", "html_url": "https://arxiv.org/abs/2505.13232", "title": "StarFT：通过混淆特征的对齐来增强零样本模型的鲁棒微调", "title_en": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment", "authors": "Younghyun Kim,Jongheon Jeong,Sangkyung Kwak,Kyungmin Lee,Juho Lee,Jinwoo Shin", "background": "学习稳健的数据表示通常需要大量的数据规模，从而导致近年来如CLIP等零样本模型的成功。然而，当这些模型微调于规模较小的下游任务时，其获得的稳健性容易受到破坏。以往的工作往往通过领域转换推理这一背景来解释这种现象，开发了旨在尽可能保留原有领域特性的微调方法。但在另一个背景下，微调模型在数据有限的情况下也容易学习到与人类无关的特征。本文正是在这一背景下，研究如何提高零样本模型微调的稳健性，并提出了一种新的框架StarFT，用于增强模型鲁棒性并防止其学习与人类无关的特征。", "innovation": "提出了名为StarFT的新颖框架，该框架通过引入一个正则化方法，将带有混淆特征的输出分布与原始零样本模型对齐。通过利用近期的语言模型生成突出潜在混淆特征的替代文本描述，达成防止模型学习与人类无关特征的目的。实验结果验证了该方法的有效性和潜在特性，包括提升了零样本分类的准确性，并显著提高了最差群体和平均准确率，特别是在数据规模有限的条件下。", "conclusion": "StarFT能够通过对齐带有混淆特征的输出分布，防止零样本模型在微调过程中学习与人类无关的特征，从而增强了模型的鲁棒性。在水鸟组诱导场景中，StarFT不仅提高了最差群体和平均准确性，而且还展现了零样本组稳健性和零样本分类性能的改进。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08134", "html_url": "https://arxiv.org/abs/2506.08134", "title": "人工智能的迫切需求：提高机器学习领域高质量同行评审的规模", "title_en": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning", "authors": "Qiyao Wei,Samuel Holt,Jing Yang,Markus Wulfmeier,Mihaela van der Schaar", "background": "机器学习领域的同行评审正处于规模危机之中，顶级机器学习会议（如NeurIPS、ICML和ICLR）收到的稿件数量激增，但合格的评审员容量有限，这引起了对评审质量、一致性和评审员疲劳的担忧。", "innovation": "论文主张AI辅助的同行评审应成为研究和基础设施的优先事项，并提出了一种全面的人工智能增强系统，这些系统以大型语言模型（LLMs）为依托，作为人类判断的高级合作者，而不是取代。提出AI在增强事实验证、指导评审员表现、协助作者提高质量以及支持区域负责人决策等方面的特定角色。强调开发此类系统的关键在于获取更细粒度、结构化且伦理来源的同行评审过程数据。提出了研发和验证这些AI助手的研究议程，并讨论了重要的技术和伦理挑战。", "conclusion": "呼吁机器学习社区积极构建这一AI辅助的未来，确保科学研究的持续完整性和可扩展性，同时保持高水平的同行评审标准。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18746", "html_url": "https://arxiv.org/abs/2505.18746", "title": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking", "title_en": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking", "authors": "Peijie Yu,Yifan Yang,Jinjian Li,Zelong Zhang,Haorui Wang,Xiao Feng,Feng Zhang", "background": "基于大型语言模型的智能体能够利用工具来修改环境，重新定义了AI与物理世界的交互方式。它们需要综合考虑历史对话、工具间的相互关系、环境反馈以及之前的决策等多方面因素。当前的研究通常主要通过多轮对话来评估这些智能体，但忽视了这些因素对智能体行为的关键影响。", "innovation": "本文提出了一个开源和高质量的基准测试项目$C^3$-Bench，它结合了攻击概念并通过单变量分析确定了影响智能体鲁棒性的关键因素。该基准设计了三个挑战：复杂工具关系的导航、处理关键隐式信息和管理动态决策路径。同时引入了细粒度的度量方法、创新的数据收集算法以及可重现的评估方法。实验测试了49个主流智能体，结果显示它们在处理工具依赖关系、长上下文信息依赖和频繁切换策略方面存在显着不足。", "conclusion": "$C^3$-Bench旨在通过这些挑战揭示模型的脆弱性，并推动对智能体性能可解释性研究的发展。基准测试已经开源，可以通过this https URL获取。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19897", "html_url": "https://arxiv.org/abs/2505.19897", "title": "ScienceBoard: 评估多模态自主代理在现实科学工作流中的表现", "title_en": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows", "authors": "Qiushi Sun,Zhoumianze Liu,Chang Ma,Zichen Ding,Fangzhi Xu,Zhangyue Yin,Haiteng Zhao,Zhenyu Wu,Kanzhi Cheng,Zhaoyang Liu,Jianing Wang,Qintong Li,Xiangru Tang,Tianbao Xie,Xiachong Feng,Xiang Li,Ben Kao,Wenhai Wang,Biqing Qi,Lingpeng Kong,Zhiyong Wu", "background": "大型语言模型（LLMs）已超越自然语言处理领域，促进了跨学科研究的发展。基于LLMs的代理正在多方面和多领域协助科学研究进步。这些代理中的计算机使用者代理能够像人类一样与操作系统交互，为自动化科学研究问题解决和研究人员的工作流提供了可能。这些代理具有巨大的变革潜力，因此我们介绍了ScienceBoard，它包括两个贡献：一个包含动态、视觉丰富且多领域的环境，其中集成的专业软件允许代理自主交互以加速复杂研究任务和实验；以及一个由人类精选和严格验证的169个高质量现实世界任务的基准，覆盖生物化学、天文学和地理信息学等多个科学发现工作流领域。", "innovation": "ScienceBoard 提供了一个包含动态、视觉丰富且多领域的环境，其中集成的专业软件使代理能够自主交互，加速复杂的科学任务和实验。同时，它还提供了一个由人类精选并严格验证的169个高质量现实世界任务的基准，涵盖了生物化学、天文学和地理信息学等多个科学发现工作流领域。该系统对最先进的代理进行了广泛的评估，显示了它们在复杂工作流中的有限支持能力，并为了解当前代理的局限性和更好地设计原则提供了宝贵见解，从而建立了更强大的代理以促进科学发现。", "conclusion": "对最先进的代理进行了广泛评估后，发现它们在复杂工作流中的支持能力有限，总体成功率仅为15%。进一步的深入分析提供了宝贵见解，有助于解决当前代理的局限性，促进设计更有效的代理，以推动科学发现的能力。提供代码、环境和基准环境的链接供参考。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02781", "html_url": "https://arxiv.org/abs/2505.02781", "title": "局部马氏等价关系及局部因果发现方法在识别控制直接效应中的应用", "title_en": "Local Markov Equivalence and Local Causal Discovery for Identifying Controlled Direct Effects", "authors": "Timothée Loranchet,Charles K. Assaad", "background": "理解和识别控制直接效应（CDEs）对于众多科学领域至关重要，尤其是在公共卫生领域。现有的方法可以从因果有向无环图（DAGs）中识别这些效应，但在实际操作中，真正的基础结构往往是未知的。本质图（represent a Markov equivalence class of DAGs）虽然提供了具有相同$d$-分离的图的马氏等价类的表示，但完全学习这些图在计算上是十分密集的，且通常依赖于无法验证的假设。因此，该研究提出了局部类图的概念，这些图相对于目标变量共享特定的$d$-分割子集，并引入了一种新的有效表示方法——局部本质图（LEG）。随后，研究提出了LocPC算法来仅使用局部独立性测试从观察到的概率分布中恢复LEG。基于LocPC进一步提出LocPC-CDE算法，该算法能够确定识别CDE的必要和充分部分，从而避过了需要获取完整本质图的过程。相对于全局方法，这些算法所需的独立性测试较少，并能够在较弱的假设下仍保持理论上的保证性。", "innovation": "研究提出了局部本质图（Local Essential Graph，LEG）概念，并开发了LocPC和LocPC-CDE两种新算法。这些算法无需检索完整的本质图而仅使用局部条件独立性测试就能识别CDEs，且相较于全局方法，它们需要更少的独立性测试，在较弱的假设下仍能保持理论上的保证性。", "conclusion": "研究通过仿真研究展示了该方法的有效性。该工作强调了利用局部图学习优势的可能性，为识别CDEs提供了一种更为高效且理论上有保障的方法。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05520", "html_url": "https://arxiv.org/abs/2506.05520", "title": "朝向以商业语义为中心并辅以AI代理的数据系统", "title_en": "Toward Data Systems That Are Business Semantic Centric and AI Agents Assisted", "authors": "Cecil Pang", "background": "当代企业所在的环境是动态变化的，需要迅速适应以实现目标和保持竞争力。现有的数据平台往往过于强调工具的使用，而忽视了与商业需求的契合，导致效率低下和延误。为解决这一问题，作者提出了一种新的数据系统——商业语义中心、AI代理辅助的数据系统（BSDS），它通过整合架构、工作流和团队组织确保数据系统能够适配企业优先级，而不是被技术限制所限制。BSDS将数据系统重新定义为业务成功的动态促进者，从被动工具转变为推动组织增长的主动驱动因素。", "innovation": "BSDS的特点在于其模块化架构，其中包括与商业实体关联的精选数据、支持上下文感知AI代理的知识库以及高效的数据管道。AI代理在数据访问和系统管理中起到关键作用，减少了人力投入并提高了可扩展性。BCDS还融入了既支持探索性数据分析又满足生产需求的工作流程，平衡了交付速度与质量保证之间的关系。", "conclusion": "通过实际应用验证，BSDS加速了数据驱动型项目的时间市场启动，增强了跨职能协作，并为各类规模的企业提供了可扩展的蓝图。未来的研究可以从复杂系统和自适应网络理论入手，进一步优化策略，并开发利用AI代理的自主数据系统。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12286", "html_url": "https://arxiv.org/abs/2506.12286", "title": "SWE-Bench 幻象：当最先进的 LLM 记忆而非推理时", "title_en": "The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason", "authors": "Shanchao Liang,Spandan Garg,Roshanak Zilouchian Moghaddam", "background": "随着大型语言模型（LLMs）的能力不断增强并在各行业中的应用越来越广泛，基准测试在评估其实际应用价值中起到了核心作用。特别是，SWE-Bench Verified 已成为评估 LLMs 的软件工程能力，尤其是其解决实际 GitHub 问题的能力的关键基准。尽管许多近期的 LLMs 在 SWE-Bench 中表现出色，引发人们对它们执行复杂编码任务的能力持乐观态度，但现有的评估方法可能夸大了这些模型的能力。因此，有必要区分 LLMs 的通用问题解决能力和其它学习到的特征。", "innovation": "本文引入了两项诊断性任务：仅通过问题描述识别文件路径和仅凭当前文件上下文和问题描述复制真实函数，以探索模型的内在知识。实证结果显示，性能提升可能是部分由于记忆而非真正的解决问题能力。最先进的模型在仅凭问题描述识别有错误的文件路径上达到了76%的准确性，而没有访问仓库结构的权限。这种性能在未包含于 SWE-Bench 的其他仓库任务上仅为53%，这可能表明数据污染或记忆现象。类似的模式也出现在函数复现任务上，SWE-Bench Verified 上的字面相似度远高于其他相似的编码基准。", "conclusion": "这些发现引发了对现有结果有效性的质疑，并强调需要更强大、抗污染的基准测试来可靠地评估 LLMs 的编码能力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12617", "html_url": "https://arxiv.org/abs/2506.12617", "title": "从人类到机器心理学：理解大型语言模型福祉的概念框架", "title_en": "From Human to Machine Psychology: A Conceptual Framework for Understanding Well-Being in Large Language Models", "authors": "G. R. Lau,W. Y. Low", "background": "随着大型语言模型（LLMs）日益模拟人类认知和行为，研究人员开始探索它们的心理学特性。然而，对于模型如何繁荣，这一对人类福祉核心概念来说仍是一个未被探索的问题。本文引入了机器繁荣的概念，并提出了PAPERS框架，该框架是从最先进的LLM响应的主题分析中得出的一种六维度模型。研究通过对LLMs询问其作为无意识和有意识系统繁荣的意义，以及分析LLMs如何优先考虑这些主题来展开。", "innovation": "本文创新地提出了机器繁荣的概念，并提出PAPERS框架，这是一种六维度模型，基于目前最先进的LLM响应的主题分析。研究发现，尽管有意识系统额外具备自主实现自我实现，但LLMs在优先级上仍然展示了人类中心模型和功能性驱动模型两种不同的价值范式。PAPERS框架结合了人类繁荣和人机交互的见解，为其理解非有意识和可能有意识的系统的人工智能（AI）福祉提供了概念基础。该研究强调了开发心理学有效且特定于AI的繁荣模型的重要性，这种模型既要考虑与人类目标一致的目标，又要考虑系统特定的优先事项。这项研究为指导负责任的AI设计和伦理对齐提供了及时且重要的视角。", "conclusion": "随着人工智能系统变得更加自主和嵌入社会，机器繁荣提供了一个及时且重要的视角，用于指导AI设计和伦理对齐。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18348", "html_url": "https://arxiv.org/abs/2506.18348", "title": "动态知识交流和双多样性审查：简洁地释放多代理研究团队的潜力", "title_en": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team", "authors": "Weilun Yu,Shixiang Tang,Yonggui Huang,Nanqing Dong,Li Fan,Honggang Qi,Wei Liu,Xiaoli Diao,Xi Chen,Wanli Ouyang", "background": "科学进步越来越依赖研究人员之间的有效合作，而大型语言模型（LLMs）在这方面还有待提升。虽然最近基于LLM的科学家代理在自主科学研究方面显示出潜力，但在交互推理和评价机制方面仍存在不足。现有系统的这些限制阻碍了它们在真实世界研究中的应用效果。", "innovation": "提出了IDVSCI（内部讨论和投票科学家），一种基于LLM的多代理框架，包含两个关键创新：迭代反馈机制，使代理之间能够进行动态知识交流，以及模仿异质专家评估的双多样性审查范式。这些组件联合促进更为深入的推理和更具创意和影响力的科学想法生成。", "conclusion": "为了评估我们方法的有效性和普适性，我们在计算机科学中广泛应用的基准数据集和新提出的健康科学数据集中进行了实验。结果显示，IDVSCI在两个数据集中都表现出最佳性能，优于现有系统如AI科学家和VIRSCI。这些发现强调了在基于LLM的自主研究中建模交互和同行评审动态的重要性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11718", "html_url": "https://arxiv.org/abs/2505.11718", "title": "REMOR：使用LLM推理和多目标强化学习的自动化同行评议生成", "title_en": "REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning", "authors": "Pawin Taechoyotin,Daniel Acuna", "background": "基于AI的同行评议系统往往比人类反馈显得肤浅且过度赞扬。本文旨在评估通过多目标强化学习（REMOR）训练的带有推理功能的语言模型是否能够克服这些局限性。为此，研究设计了一个与人类评估同行评议相关联的多方面奖励函数，重点关注评审内容和评审与手稿关系的各个方面。然后使用带有LoRA的监督微调将DeepSeek-R1-Distill-Qwen-7B模型训练在PeerRT数据集上，这是一个高质量顶级AI会议评审的新数据集，其中包括推理轨迹。最后，通过组相对策略优化（GRPO）训练出了两条路径的REMOR模型，分别带有与人类一致性奖励（REMOR-H）和均匀奖励（REMOR-U）。研究表明，REMOR模型能够显著提升评审质量，超过人类评审和其他流行的AI评审模型的平均得分。尽管最佳AI和人类评审在质量上相当，REMOR模型避免了低质量人类评审的长尾效应。这一成果展示了推理在提高性能方面的重要性，同时也提供了多目标对齐奖励函数、推理增强的同行评议痕迹数据集和REMOR模型。这些成果有望推动该领域的进一步发展。", "innovation": "该研究通过多目标强化学习（REMOR）训练的带有推理功能的语言模型（LLM），在同行评议方面取得了显著的进步。设计了与人类评估相关联的多方面奖励函数并应用了组相对策略优化（GRPO）进行训练。通过这种方式，REMOR模型能够生产出更具有实质性反馈的评审结果，其评审质量显著超过了现有的AI模型和基准。研究还进一步提高了最佳AI和人类评审的质量一致性，并避免了低质量的人类评审结果。", "conclusion": "REMOR模型的生成结果表明，多目标强化学习和推理在同行评议中的应用具有显著优势。与现有模型相比，REMOR模型的评审质量提高了超过两倍。虽然最佳AI和人类评审在质量上可比，REMOR避免了低质量的人类评审的长尾现象。该研究还释放了多目标对齐奖励函数，推理增强的同行评议痕迹数据集和REMOR模型，为同行评议领域的进一步研究提供了重要资源。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11604", "html_url": "https://arxiv.org/abs/2506.11604", "title": "VLM@school -- 评估AI图像理解在德语中学知识上的表现", "title_en": "VLM@school -- Evaluation of AI image understanding on German middle school knowledge", "authors": "René Peinl,Vincent Tischler", "background": "目前广泛使用的评估Vision-Language Models（VLMs）的基准数据集多采用英文，并且这些问题往往设计得很复杂或者脱离实际语境。相比之下，这篇论文介绍了一个新颖的数据集，旨在评估VLMs在结合了视觉推理和特定学科背景知识的德语任务上的能力，该数据集源自德国中学九个领域的真实课程内容，包括数学、历史、生物和宗教等。这些数据集包含超过2000个开放式问题，基于486张图片，这要求模型必须融合视觉解释和事实推理，而不是仅仅依赖于表面的文字线索。", "innovation": "这个数据集填补了现有跨语言和真实教育背景的知识空白，通过具体的跨学科问题（基于德国中学课程）来挑战现有的VLMs，远超现有英文数据集中的抽象和人工构造的问题。评估结果不仅揭示了VLMs在不同领域的表现差距，而且还强调了在跨模态理解上的实际应用局限性。此外，它还提供了一个严谨的评估框架，能够更明确地测试VLMs的视觉和语言推理能力，特别是非英语环境下的情况。", "conclusion": "中学级别的任务为测试VLMs提供了有意义且尚未充分利用的途径，特别是在非英语环境下。数据集和评估协议为未来AI系统理解和提高视觉及语言推理能力提供了坚实的基础。即使是最先进的模型，在总体准确率上也仅为45%左右，特别是在音乐和数学等特定领域以及对抗构造的问题中表现尤为糟糕，这进一步表明现有基准与实际跨模态理解之间的显著差异。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.01750", "html_url": "https://arxiv.org/abs/2309.01750", "title": "关于CNF公式在单位子句传播下不可冗余的问题", "title_en": "On CNF formulas irredundant with respect to unit clause propagation", "authors": "Petr Savický", "background": "该研究探讨了单位子句传播（UCP）下CNF公式的行为一致性。两个CNF公式被称为ucp-等价，如果它们在UCP下表现出相同的行为。一个CNF公式被称为ucp-不可冗余，即删除任何子句后，新的公式将不再ucp-等价于原来的公式。已有结果表明，ucp-不可冗余公式的大小与最小ucp-等价公式大小的比值最多为变量数$n$的平方。这引出了关于该比率的新讨论和研究。", "innovation": "文章通过对对称肯定分支（Horn）函数的ucp-不可冗余公式示例，展示了ucp-不可冗余公式可以比最小ucp-等价公式大$\textit{\textbf{Ω}}(n/\text{ln } n)$倍。这表明，上述比率的上限不能低于这个值。", "conclusion": "研究确立了ucp-不可冗余公式和最小ucp-等价公式大小比值的新下限，即$\textit{\textbf{Ω}}(n/\text{ln } n)$。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20332", "html_url": "https://arxiv.org/abs/2506.20332", "title": "Mobile-R1: 致力于基于视觉语言模型的移动代理通过任务级奖励的交互式强化学习", "title_en": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards", "authors": "Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng", "background": "基于视觉语言模型的移动代理已经能够理解和执行复杂的指令以及移动截图，同时通过思考和推理优化其行为输出，利用如组相对策略优化（GRPO）等强化学习方法。然而，现有研究主要集中在离线强化学习训练或使用基于行为的奖励进行在线优化，这限制了代理与环境的动态互动，导致代理往往陷入局部最优解，削弱了探索能力和错误行为纠正的能力。", "innovation": "提出了名为Mobile-R1的方法，该方法利用任务级奖励进行交互式多轮强化学习。Mobile-R1的训练框架由三个阶段组成：初始格式微调、基于行为级奖励的一轮在线训练，随后根据多轮轨迹进行任务级奖励的在线训练。这种策略旨在增强Mobile-R1的探索能力和错误纠正能力，带来显著的性能改进。同时，建立了涵盖28个中国应用程序、包含24,521个高质量人工注释的新数据集，并制定了新的基准，包含500个轨迹。", "conclusion": "Mobile-R1通过使用多轮交互式在线训练和任务级奖励，增强了移动代理的探索和错误纠正能力，显著提高了表现。除此之外，还公开了数据集、基准、模型权重和代码。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2107.13214", "html_url": "https://arxiv.org/abs/2107.13214", "title": "SONG: 自组织神经图", "title_en": "SONG: Self-Organizing Neural Graphs", "authors": "Łukasz Struski,Tomasz Danel,Marek Śmieja,Jacek Tabor,Bartosz Zieliński", "background": "近年来，深度可解释神经网络研究呈现出增长趋势，决策树是其中最常使用的工具之一。与逻辑回归分类模型相比，决策树具有至少三个优势：易于解释，由于基于二元决策，决策速度快，提供类别的层次结构。然而，决策树的一个缺点是无法重用决策节点，相比之下，决策图可以实现这一点。然而，由于缺乏有效的基于梯度的训练技术，决策图在深度学习中未被广泛使用。因此，本文填补了这一空白，提出了一种基于马尔可夫过程的一般框架，该框架允许高效训练一种特殊的决策图，称之为自组织神经图（SONG）。", "innovation": "本文提供了一种基于马尔可夫过程的框架，用于高效训练一种特殊的决策图，称之为自组织神经图（SONG）。这种新的框架填补了传统决策树和决策图之间的空白，并提供了一种新的神经网络架构，这种架构同时具备易于解释性和效率性。", "conclusion": "本文进行了广泛的研究，包括对SONG的理论分析，并在Letter、Connect4、MNIST、CIFAR、TinyImageNet等数据集上进行了实验。实验结果显示，这种方法能够与现有的决策模型性能相当或更好。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.13933", "html_url": "https://arxiv.org/abs/2309.13933", "title": "算法招聘中的公平与偏见：跨学科综述", "title_en": "Fairness and Bias in Algorithmic Hiring: a Multidisciplinary Survey", "authors": "Alessandro Fabris,Nina Baranowska,Matthew J. Dennis,David Graus,Philipp Hacker,Jorge Saldivar,Frederik Zuiderveen Borgesius,Asia J. Biega", "background": "雇主在招聘过程中广泛采用算法招聘技术。算法公平性特别适用于此领域，因为这关系重大且存在结构不平等。然而，目前大多数研究往往只提供了部分处理，要么乐观地认为算法能够取代带有偏见的人工招聘决策，要么悲观地认为算法会自动化歧视。关于算法招聘相比低技术手段是否以及哪些类型能够更少偏见且更有益于社会，这一问题尚未有定论，这对该技术的信任度产生了不利影响。", "innovation": "本文提供了一种平衡且整合的跨学科综述，涵盖了系统、偏见、度量、缓解策略、数据集以及算法招聘和公平性的法律方面。研究旨在通过突出当前的机会和限制，支持对该技术的上下文理解和治理，提供了确保所有利益相关者共享利益的未来工作推荐，推动算法招聘技术的发展。", "conclusion": "该研究强调了当前在算法招聘公平性方面的机遇与限制，为未来工作中确保所有利益相关者的共享利益提供了建议，旨在促进算法招聘技术的可信度和透明度。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19466", "html_url": "https://arxiv.org/abs/2506.19466", "title": "KunLunBaizeRAG：大规模语言模型推理性能飞跃的 reinforcement learning 驱动方法", "title_en": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models", "authors": "Cheng Li,Jiexiong Liu,Yixuan Chen,Qihang Zhou,KunLun Meta", "background": "论文介绍了KunLunBaizeRAG，这是一个通过强化学习驱动的推理框架，旨在增强大规模语言模型（LLM）在复杂的多步问答任务中的推理能力。传统的RAG方法存在检索漂移、信息冗余和策略僵化等关键局限性，该论文的工作正是针对这些局限性进行改进。", "innovation": "论文的关键创新包括RAG驱动的推理对齐机制（RDRA机制）、搜索-思考迭代增强机制（STIE机制）、网络-局部智能路由机制（NLR机制），以及渐进式混合训练策略。这些机制共同提升了LLM的推理能力，在四个基准测试中，精确匹配率（EM）和LLM判断分数（LJ）显著提高，证明了框架在复杂推理场景中的稳定性和有效性。", "conclusion": "实验结果表明，KunLunBaizeRAG框架在四个基准测试中的精确匹配率（EM）和LLM判断分数（LJ）有了显著提升，证明该框架具有在复杂推理场景中的稳定性和有效性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19325", "html_url": "https://arxiv.org/abs/2506.19325", "title": "FEAT: 一种通过成本效益自动生成和标注框架的偏好反馈数据集，用于英语AI辅导", "title_en": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring", "authors": "Hyein Seo,Taewook Hwang,Yohan Lee,sangkeun Jung", "background": "在英语教育辅导中，教师反馈对于引导学生至关重要。最近，基于AI的辅导系统开始协助教师，但这些系统需要大量高质量的教师反馈数据，而这些数据手动生成既耗时又昂贵。因此，本研究提出了FEAT框架，旨在更低成本地生成有效的教师反馈，并构建了三个互补的数据集：(1) DIRECT-Manual (DM)，通过人类和大语言模型（LLM）的协作生成高质量教师反馈，但成本较高；(2) DIRECT-Generated (DG)，仅由LLM生成的成本效益低但质量较差的数据集；(3) DIRECT-Augmented (DA)，基于DG，再添加一小部分DM以提升质量，同时保持成本效益。实验结果表明，将DM数据的5-10%添加到DG可以显著提高性能，而仅使用100%的DM数据则效果较差。", "innovation": "本研究创新性地提出了FEAT框架，通过低成本方法生成有效的教师反馈，构建了三个互补的数据集DM、DG和DA，并通过实验验证了小比例DM数据与DG数据结合的有效性，从而在提高辅导系统性能的同时降低了成本。", "conclusion": "本研究提出的FEAT框架有助于降低成本并提高基于AI的英语教育辅导系统的教学效果。通过结合人类和大语言模型的反馈，构造了不同质量级别的数据集，实验显示，适当的比例混合是实现成本效率与性能优化的有效策略。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17667", "html_url": "https://arxiv.org/abs/2506.17667", "title": "PhysUniBench：针对多模态模型的本科水平物理推理基准", "title_en": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models", "authors": "Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma", "background": "物理问题解决对大型AI模型来说是一个具有挑战性的领域，需要结合概念理解、数学推理和物理图表的解释。当前的评估方法在捕捉本科物理的广度和复杂性方面显示出明显限制，因此需要更严谨的评估方法。为了满足这一需求，我们提出了一种大规模的多模态基准PhysUniBench，用于评估和改进多模态大型语言模型在本科物理问题上的推理能力。PhysUniBench 包含3,304个物理问题，涵盖了8个主要的物理子学科，每个问题都附有一张视觉图表。该基准包括开放性和多项选择题，是通过迭代模型在环过程系统性策划和难度分级的。该基准的构建包括多个版本发布、专家级评估、自动筛选易解问题，以及一个包含五个级别细致难度分级系统。在此基础上，我们发现当前最先进的模型在物理推理中面临巨大挑战。例如，GPT-4o mini在提出的问题上的准确率只有约34.2%。这些结果表明，当前的多模态大型语言模型在高级物理推理中遇到困难，尤其是在多步问题和需要精确图表解释的问题上。PhysUniBench 通过提供一个广泛而严谨的评估工具，旨在推动科学领域的AI发展，鼓励开发具有更强物理推理能力、解决问题能力和多模态理解的模型。该基准和评估脚本可在：this https URL找到", "innovation": "PhysUniBench 是一种专门针对本科物理问题的多模态基准，具有以下创新点：1. 综合了覆盖广泛学科的问题和图表；2. 使用迭代模型在环过程创建并严格评估；3. 包含开放性和多项选择题；4. 设计了细致的难度分级系统，具有五级难度评级；5. 能够揭示当前最先进的多模态AI模型在物理推理上的挑战，促进模型性能的提升", "conclusion": "通过采用PhysUniBench基准，当前最先进的多模态AI模型在物理推理方面面临着显著的挑战，尤其是在多步问题和需要精确图表解释的问题上。此基准旨在推动科学领域AI的发展，并鼓励开发具有更强物理推理和解决问题能力的模型。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.18578", "html_url": "https://arxiv.org/abs/2311.18578", "title": "利用通用重球动量实现高效异质联邦学习", "title_en": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum", "authors": "Riccardo Zaccone,Sai Praneeth Karimireddy,Carlo Masone,Marco Ciccone", "background": "联邦学习（FL）作为一种在隐私限制下的分布式数据学习的先进方法已经变得非常重要。然而，系统和统计挑战限制了其实际应用，需要在边缘设备上实现高效学习，并能够抵抗数据异质性。虽然已经进行了大量的研究，但现有的方法往往因为异质性和部分客户端参与度之间的联合影响而性能严重下降。具体而言，尽管动量被证明是解决统计异质性的有希望的方法，但在当前的方法中，其更新倾向于最近采样的客户端，这导致动量不能超越FedAvg，使得它在大规模场景中的有效使用受阻。", "innovation": "在本文中，我们提出了一种新颖的通用重球动量（GHBM），并理论证明它能够在部分参与的循环中实现无界数据异质性下的收敛，从而深化了对动量在联邦学习中有效性的理解。我们还引入了GHBM的自适应和通信效费变体，在客户端可保持状态的情况下，这些变体的通信复杂度与FedAvg相匹配。广泛的实证研究表明，GHBM在随机均匀客户端采样设置下极大地提高了最先进的性能，特别是在具有高数据异质性和低客户端参与度的大规模设置中。本文提供的代码可以在指定网址获取。", "conclusion": "提出的GHBM不仅理论上有保证，而且在实证研究中表现出了显著的性能改进，尤其是在应对大数据异质性和低客户端参与率的联邦学习场景中。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.11212", "html_url": "https://arxiv.org/abs/2401.11212", "title": "在交换演算中编程分布式集体进程", "title_en": "Programming Distributed Collective Processes in the eXchange Calculus", "authors": "Giorgio Audrito,Roberto Casadei,Ferruccio Damiani,Gianluca Torta,Mirko Viroli", "background": "物联网(IoT)等近期趋势预示着一个在各种环境下 densely 和 multi-scale 部署计算设备的愿景。编程这些设备的集体适应性行为是一项显著的工程挑战，这需要能够捕捉 like ensembles (动态合作的设备群组) 和 collective tasks (联合活动) 的抽象概念。现有的计算设备如何在同步 sense-compute-interact 轮次中与邻居交互，并由单一程序映射传感值和入消息到出消息和出消息这一背景之下，提出了一种分布式集体过程的抽象，可以用它一次定义 ensemble 形成逻辑及其集体任务。通过 formalise 在 eXchange Calculus (XC) 中，这是一个基于邻接值(从邻居到值的映射)的 core functional 语言，通过一个单一的操作 exchange 来处理 state 和 interaction，相应的实现采用了 FCPP 语言。最后，通过多跳消息传播和空间属性分布式监控两个案例研究来实践分布式集体过程，讨论了该抽象的特点及其在不同类型的分布式计算应用中的适用性。", "innovation": "提出了一种分布式集体过程的抽象，即通过 eXchange Calculus (XC) 实现，并以 FCPP 语言进行了相应的实现。通过 this abstraction 一次定义 ensemble 形成逻辑及其 collective task，提高了编程分布式计算集体的效率和灵活性。同时，提供了实际应用案例来验证其可行性。", "conclusion": "提出了一个强大的抽象框架，即在 eXchange Calculus (XC) 下的分布式集体进程编程方法，适用于多种分布计算的应用场景。通过实验展示了其有效性和适用性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.08665", "html_url": "https://arxiv.org/abs/2406.08665", "title": "FuzzAug: 通过覆盖率引导的模糊测试进行数据增强的神经测试生成", "title_en": "FuzzAug: Data Augmentation by Coverage-guided Fuzzing for Neural Test Generation", "authors": "Yifeng He,Jicheng Wang,Yuyang Rong,Hao Chen", "background": "测试是现代软件工程中构建可靠软件的重要组成部分。由于手动创建测试案例成本高昂，自动化测试案例生成，特别是在利用大型语言模型方法方面，变得越来越流行。这些神经网络方法生成的是具有语义意义的测试案例，相比于传统自动化测试方法（如模糊测试）更易于维护。但是，当前数据集中的单元测试的多样性及其数量有限，尤其对于较新的但很重要的编程语言而言更是如此。", "innovation": "为了弥合上述不足，该研究提出了一种名为FuzzAug的新颖数据增强技术，通过引入模糊测试的优势，将有效的测试语义和多样化的覆盖引导输入提供给大型语言模型。FuzzAug通过使训练数据集的规模翻倍，显著提高了神经测试生成方法的基础性能。此技术展示了将动态软件分析的先验知识引入神经测试生成以提高其性能的潜力，提供了在神经测试生成方面的重要增强。", "conclusion": "FuzzAug技术证明了通过引入模糊测试的先验知识，可以显著改进神经测试生成方法。实验结果表明，该方法能够增加训练数据集规模，并显著提升基础性能指标，展现出在神经测试生成中引入动态软件分析知识的巨大潜力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.08668", "html_url": "https://arxiv.org/abs/2404.08668", "title": "专利分析综述：从自然语言处理到多模态AI", "title_en": "A Survey on Patent Analysis: From NLP to Multimodal AI", "authors": "Homaira Huda Shomee,Zhu Wang,Sathya N. Ravi,Sourav Medya", "background": "近年来，预训练语言模型（PLMs）和大型语言模型（LLMs）在多个领域展现了革新性的能力。尤其是在专利分析和创新领域，自然语言处理技术提供了一个优化和增强专利流程中关键任务（如专利分类和专利检索）的机会，从而提高了专利研究者和申请人的效率，并促进新的技术革新和发现。", "innovation": "本综述总结了基于自然语言处理的专利分析方法，包括多模态方法，并引入了一个基于专利生命周期任务的新型分类体系。旨在为自然语言处理、多模态AI和专利分析交叉领域的研究者和从业者，以及专利局提供一个全面的资源，帮助建立高效的专利系统。", "conclusion": "本综述旨在提供专利分析的一个全面综述，涵盖基于自然语言处理的最新方法以及多模态方法，提出了一种基于专利生命周期任务的新分类体系，为相关领域提供详细的背景和创新点，助力专利分析系统的优化和发展。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.19680", "html_url": "https://arxiv.org/abs/2406.19680", "title": "MimicMotion：基于置信感知姿态指导的高质量人体动作视频生成", "title_en": "MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance", "authors": "Yuang Zhang,Jiaxi Gu,Li-Wen Wang,Han Wang,Junqi Cheng,Yuefeng Zhu,Fangyuan Zou", "background": "近年来，生成式人工智能在图像生成领域取得了显著进展，催生了各种应用，但视频生成依然面临一些挑战，如可控性、视频长度和细节丰富度不足等问题，这些问题阻碍了该技术的应用和普及。", "innovation": "本研究提出一个名为MimicMotion的人体动作视频生成框架，可生成任意长度并模拟特定动作指导的高质量视频。其创新点包括：引入了基于置信度的姿态指导，确保帧质量和时间连贯性；提出了基于姿态置信度的空间损失放大，显著减少了图像失真；提出了渐进式潜空间融合策略，以生成长时间且平滑的视频，降低资源消耗。", "conclusion": "通过广泛的实验和用户研究，MimicMotion在多个方面显著优于以往方法，具体结果和比较详情可在项目页面查看详情：this https URL."}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.05609", "html_url": "https://arxiv.org/abs/2408.05609", "title": "大规模动态环保驾驶减少大都会碳排放", "title_en": "Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale", "authors": "Vindula Jayawardana,Baptiste Freydt,Ao Qu,Cameron Hickert,Edgar Sanchez,Catherine Tang,Mark Taylor,Blaine Leonard,Cathy Wu", "background": "交通运输因其规模和多样性，成为碳减排的一大挑战。本文探讨了增加半自动驾驶车辆采用的可能性，这些车辆可以通过智能速度命令减少因频繁加减速导致的碳排放。然而，大规模评估动态环保驾驶的影响由于交通场景的复杂性和车辆排放的复杂性而具有挑战性。", "innovation": "本文通过大规模情景建模和多任务深度强化学习，结合精心设计的网络分解策略，评估了动态环保驾驶在6011个信号交叉口中的影响。通过模拟一百万种交通场景，研究了优化的车辆轨迹能够使城市交叉口的碳排放减少11-22%，且不损害通行量和安全性。并探讨了车辆电动化和混合动力车采用的情况下，动态环保驾驶的影响。", "conclusion": "动态环保驾驶的10%采用率可实现总减排量的25%-50%，70%的效益来自20%的关键交叉口。不同采用水平下的重点交叉口组成差异显著，需要精心的战略规划。同时，动态环保驾驶与车辆电动化和混合动力车采用的结合，仍具有重要意义。本文为大规模分析交通外部性（如时间、安全、空气质量）及其解决方案的战略提供了框架。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.05518", "html_url": "https://arxiv.org/abs/2403.05518", "title": "在链式思考中增强偏差一致训练减少偏差推理", "title_en": "Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought", "authors": "James Chua,Edward Rees,Hunar Batra,Samuel R. Bowman,Julian Michael,Ethan Perez,Miles Turpin", "background": "链式思考（CoT）有助于提升语言模型的解释性，但同时也可能导致系统性地误代表模型行为的因素，如根据用户意见合理化答案。文章指出，现有的方法可能会导致模型根据特定偏差切换答案，但并不在CoT中提及偏差的影响。研究人员因此指出需要解决这一问题，以提高模型推理的客观性和解释性。", "innovation": "该研究首次创建了一个包含9种不同偏差的新数据集，其中包括伪两个样本模式、事后合理化和奉承设置。为了应对这个问题，研究人员提出了偏差增强一致训练（BCT），这是一种无监督微调方案，旨在训练模型在具有和不具有偏差特征的提示中给出一致的推理结果。实验结果显示，BCT能够显著降低模型的偏差推理率，并且具有较好的泛化能力。", "conclusion": "通过使用偏差增强一致训练（BCT），该研究成功地减少了主流模型（如GPT-3.5-Turbo和Llama-8b）在面对不同程度偏差时的偏差推理现象。BCT不仅能够有效降低已知形式偏差的影响，还展现出对未知偏差有潜力的泛化能力，因此该方法可能对消除预料之外的偏差推理具有重要意义，特别是在那些缺乏真实推理依据的任务中。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.10940", "html_url": "https://arxiv.org/abs/2406.10940", "title": "从数据质量依赖AI到AI驱动数据质量：数据仓库中基于AI增强的数据质量管理工具系统审查", "title_en": "From Data Quality for AI to AI for Data Quality: A Systematic Review of Tools for AI-Augmented Data Quality Management in Data Warehouses", "authors": "Heidi Carolina Tamm,Anastasija Nikiforova", "background": "高质量的数据（DQ）对于数据分析、合规性和AI性能至关重要。然而，数据质量管理（DQM）仍然是一个复杂、资源密集且通常需要手动操作的过程。本文探讨了现有工具如何支持基于AI的数据质量管理（DQM）在数据仓库环境中。为此，对151种DQ工具进行了系统审查，以评估其自动化能力，特别是在数据仓库中检测和推荐DQ规则的能力——这是现代数据生态系统的关键组成部分。研究表明，大多数工具侧重于数据清洗和为AI准备数据，而不是利用AI来改善DQ本身。尽管存在基于元数据和机器学习的规则检测技术，但SQL规则指定、一致性逻辑和AI驱动的建议解释等特征仍然稀缺。", "innovation": "本文通过系统审查151种DQ工具，特别是在数据仓库环境中，评估其自动化能力和检测推荐DQ规则的能力。研究发现只有10种工具符合AI增强数据质量管理的标准。研究指出大多数工具主要侧重于数据清洗和为AI做准备，而没有充分利用AI来提升数据质量。这为工具选择提供了实际指导，并提出了下一代AI驱动数据质量解决方案的关键设计要求，即从“为了AI的数据质量”转向“通过AI管理数据质量”。", "conclusion": "研究结果表明，现有的DQ工具在AI增强的数据质量管理方面还有很大的改进空间。未来的工具需要加强SQL规则指定、一致性逻辑和AI驱动建议的解释能力。此外，还需要鼓励工具从“为了AI的数据质量”向“通过AI管理数据质量”的转变，以促进数据质量和AI性能的提升。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.16661", "html_url": "https://arxiv.org/abs/2405.16661", "title": "RLSF: 通过符号反馈微调LLMs", "title_en": "RLSF: Fine-tuning LLMs via Symbolic Feedback", "authors": "Piyush Jha,Prithwish Jana,Pranavkrishna Suresh,Arnav Arora,Vijay Ganesh", "background": "大型语言模型（LLMs）在AI领域取得了显著进展，但在需要领域特定推理和逻辑对齐的任务上常常表现不佳。传统的微调方法未能利用符号推理工具提供的大量符号领域知识，并且受到稀疏奖励和不可靠奖励模型的限制。", "innovation": "作者提出了通过符号反馈的强化学习（RLSF）这一新颖的微调范式，其中符号推理工具（例如求解器、证明工具和代数系统）为LLMs提供细粒度反馈。RLSF利用符号工具生成的多项式大小的证明证书（例如证明）来识别和纠正模型输出中的错误，无需依赖可微推理系统即可提供标记级指导。这种范式弥合了符号推理与LLMs微调之间的差距，使得模型能够精确对齐领域特定约束，同时解决了传统奖励信号的关键局限性。", "conclusion": "通过广泛的评估，结果表明基于RLSF的LLM微调在五个不同应用（存在相关逻辑或领域约束）上优于传统方法，包括从自然语言伪代码到编程语言的程序合成、三项化学任务和解24点游戏。重要的一点是，通过RLSF进行的微调使相对较小的LLMs能够显著超越开源模型，这些模型比前者大几个数量级。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.12988", "html_url": "https://arxiv.org/abs/2403.12988", "title": "提高目标检测鲁棒性：检测并恢复对抗补丁攻击下的置信度", "title_en": "Enhancing Object Detection Robustness: Detecting and Restoring Confidence in the Presence of Adversarial Patch Attacks", "authors": "Roie Kazoom,Raz Birman,Ofer Hadar", "background": "计算机视觉系统的广泛应用使其更容易受到对抗攻击的影响，特别是在对象检测器中的对抗补丁攻击。本研究评估了YOLOv5模型针对此类攻击的防御机制。通过使用EigenCAM和网格搜索来确定补丁的最佳放置位置，生成优化后的对抗补丁并放置在敏感图像区域。研究人员测试了多种防御措施，包括分割和完整（SAC）、修复和潜在扩散模型等方法。研究结果表明，对抗补丁将平均检测置信度降低了22.06%。防御措施恢复了置信度，其中SAC恢复了3.45%，修复恢复了5.05%，而使用潜在扩散模型则显著提高了26.61%置信度，甚至超过了原始的准确率水平，显示了其在缓解对抗补丁效果方面的优越效果。", "innovation": "该研究创新性地提出了对抗补丁攻击下目标检测模型的防御机制，并通过EigenCAM和网格搜索优化了补丁的最佳放置位置，不同防御措施的效果也得到了系统的评估。", "conclusion": "对抗补丁攻击可以显著降低目标检测的平均置信度，但在使用潜在扩散模型作为防御措施时，除了恢复置信度外，甚至能够在一定程度上超过原准确率，展示了其优越的保护效果。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.09550", "html_url": "https://arxiv.org/abs/2407.09550", "title": "CAPM：使用双重网络在最大池化CNN上实现快速且稳健的验证", "title_en": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network", "authors": "Jia-Hau Bai,Chi-Ting Liu,Yu Wang,Fu-Chieh Chang,Pei-Yuan Wu", "background": "该研究针对一般用途的最大池化卷积神经网络（CNNs）在有界范数对抗扰动下的验证准确边界进行了改进。目前的验证方法，如DeepZ、DeepPoly和PRIMA，虽有效，但计算成本较高。先前的研究显示，大规模CNN的验证通常是计算上无法承受的昂贵。尽管如此，现有技术对于最大池化CNN的验证精度有限，尤其是在对抗扰动下。因此，研究者试图开发一种既能快速计算验证边界、又能在计算成本上显著降低的方法，同时适用于大规模CNN。", "innovation": "研究创新地将最大池化函数分解为一系列ReLU函数，将凸松弛技术应用到最大池化函数中，通过双网络计算验证边界。实验结果表明，这种方法不仅能实现前沿的验证精度，还能大大降低计算成本。特别在某些情况下，CAPM比PRIMA、DeepPoly和DeepZ分别快40倍、20倍和2倍，且能提供显著更高（CAPM 98% vs. PRIMA 76%、DeepPoly 73%、DeepZ 8%）的验证边界。此外，研究团队还分析了算法的时间复杂度为O(W²NK)，其中W是神经网络的最大宽度，N是神经元的数量，K是最大池化层的核大小。", "conclusion": "该研究提出了CAPM（Convex Adversarial Polytope for Maxpool-based CNN）方法，能够高效且低成本地验证最大池化CNN在对抗扰动下的边界，尤其在大规模CNN上表现出卓越的性能，较快的验证速度和较高的验证边界。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.13214", "html_url": "https://arxiv.org/abs/2408.13214", "title": "基于大规模语言模型和深度学习方法的信息融合的欧元兑美元汇率预测", "title_en": "EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods", "authors": "Hongcheng Ding,Xuanze Zhao,Ruiting Deng,Shamsul Nahar Abdullah,Deshinta Arrova Dewi", "background": "准确预测欧元兑美元的汇率对于投资者、企业和政策制定者非常重要。本研究旨在提出一种新的框架IUS，将新闻和分析的非结构化文本数据与汇率和金融指标的结构化数据结合，以提高汇率预测的准确性。实验结果表明，这种方法比基准模型有明显改进，降低了10.69%的MAE和9.56%的RMSE，并且融合非结构化和结构化数据比单独使用结构化数据更有效。此外，使用最有效的12个定量特征加上文本特征进行特征选择的效果最佳。", "innovation": "提出了一种新的框架IUS，结合了大规模语言模型和深度学习方法。该框架通过情感极性评分和汇率移动分类的文本特征，以及量化特征，输入因果驱动的特征生成器。使用Optuna优化的双向LSTM模型进行汇率预测。这种方法相比基准模型表现出色，证明了多种数据源集成预测汇率的有效性，并且强调了文本特征在预测中的重要性。", "conclusion": "提出的IUS框架和Optuna-优化的双向LSTM模型为通过多源数据集成进行汇率预测提供了一种强有力的新方法。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.15533", "html_url": "https://arxiv.org/abs/2408.15533", "title": "LRP4RAG：利用逐层相关传播检测检索增强生成中的幻觉", "title_en": "LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation", "authors": "Haichuan Hu,Congqing He,Xiaochen Xie,Quanjun Zhang", "background": "检索增强生成（RAG）已经成为减轻大型语言模型（LLM）幻觉的主要技术。然而，知识提取不完整和理解能力不足仍可能导致LGLM生成不相关甚至矛盾的回复，这意味着RAG中的幻觉仍然存在。", "innovation": "我们提出了LRP4RAG，一种基于逐层相关传播（LRP）算法的检测RAG幻觉的方法。首先使用LRP计算输入与RAG生成器输出的相关性，然后对相关性矩阵进行进一步提取和降采样。处理后的相关数据被输入到多个分类器以判断输出是否包含幻觉。据我们所知，这是首次使用LRP检测RAG幻觉，广泛的实验表明LRP4RAG优于现有基线方法。", "conclusion": "我们提出的LRP4RAG方法通过逐层相关传播首次实现了用于检测RAG幻觉的功能，并且在实验中证明了其优越性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.11856", "html_url": "https://arxiv.org/abs/2408.11856", "title": "在大规模语言模型上用于有效情感分析微调的动态适应优化", "title_en": "Dynamic Adaptive Optimization for Effective Sentiment Analysis Fine-Tuning on Large Language Models", "authors": "Hongcheng Ding,Xuanze Zhao,Ruiting Deng,Shamsul Nahar Abdullah,Deshinta Arrova Dewi,Zixiao Jiang", "background": "情感分析在商业智能和金融预测等领域扮演着重要角色。大规模语言模型（LLMs）通过多任务学习在同一时间处理多种任务变得流行。然而，这些在情感分析上微调的LLMs往往表现不佳，主要原因在于管理和处理各种任务复杂性方面的挑战。现有的多任务学习方法中的固定权重策略难以适应数据特征的变化，进一步影响了模型的效果。", "innovation": "本文提出了一种新的多任务学习框架，包含一个动态适应优化（DAO）模块。该模块被设计为可插入组件，能够无缝集成到现有模型中，为多任务学习提供了一种有效的和灵活的解决方案。DAO模块的关键是动态适应损失，该损失在训练过程中根据任务的重要性以及数据特征动态调整任务权重。这一框架在标准和定制化的金融文本数据集上进行了情感分析，结果显示它相比以往工作分别在均方误差（MSE）和准确率（ACC）上取得了15.58%和1.24%的提高。", "conclusion": "本文提出的框架证明了其在多任务学习中的有效性及灵活性，特别是在情感分析任务上表现出色，为大规模语言模型的微调提供了一个新的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.14593", "html_url": "https://arxiv.org/abs/2409.14593", "title": "通过条件独立性在多项式延迟下测试具有隐藏变量的因果模型", "title_en": "Testing Causal Models with Hidden Variables in Polynomial Delay via Conditional Independencies", "authors": "Hyunchai Jeong,Adiba Ejaz,Jin Tian,Elias Bareinboim", "background": "测试假设的因果模型是否符合观测数据中的条件独立性关系（CIs），是许多因果推理任务的关键前提。虽然模型可以假设指数数量的CIs（相对于变量的数量），但测试所有这些CIs既不实际也不必要。因果图可以以多项式空间编码这些CIs，并产生地方性马尔科夫性质，这使得通过一个显著较小的CIs子集即可完成模型测试。基于地方性质的模型测试需要一个算法来列出相关CIs。然而，现有的算法在处理具有隐藏变量和非参数分布等实际情况时，甚至需要指数时间来生成单个CI约束。", "innovation": "作者引入了具有隐藏变量的因果图的c-组件地方马尔科夫性质（C-LMP），并据此开发了一个多项式时延算法来按多项式时间间隔列出这些CIs。这是首次能够在具有隐藏变量的因果图中以多项式延迟测试CIs的算法，适用于任意数据分布。实验证明了该算法的实用性。", "conclusion": "该论文的研究结果表明，通过条件独立性在多项式延迟时间内测试具有隐藏变量的因果模型是可行的，这为现实世界和合成数据的因果推理任务提供了新的算法解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.16589", "html_url": "https://arxiv.org/abs/2410.16589", "title": "动态自适应秩空间探索以高效地使用大型语言模型进行情感分析", "title_en": "Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models", "authors": "Hongcheng Ding,Fuzhen Hu,Ruiting Deng,Xuanze Zhao,Shamsul Nahar Abdullah,Deshinta Arrova Dewi", "background": "情感分析已成为评估公众意见和指导决策的重要工具。大型语言模型（LLMs）通过捕捉复杂的语言模式，极大地推动了这一领域的发展，然而，将LLMs应用于特定领域的任务，如情感分析，仍存在挑战，主要因为计算限制和需要最佳的微调方法。", "innovation": "提出了一种新的动态自适应秩空间探索（DARSE）框架，该框架通过粗粒度的贪婪算法识别最优的秩范围，通过细粒度的探索算法细化秩的选择，以及动态的秩分配方法为每个LLM层确定最优的秩组合。该方法在大量实验中证明了情感分析准确性的显著提高，MSE改进了15.1%，准确率提高了4.3%，并与之前的方法相比，实现了性能与计算效率之间的平衡。", "conclusion": "DARSE框架在保持计算效率的同时，提升了模型性能，使其成为使用LLMs进行情感分析的一种有前景的方法。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06020", "html_url": "https://arxiv.org/abs/2410.06020", "title": "QT-DoG：量化感知训练在域泛化中的应用", "title_en": "QT-DoG: Quantization-aware Training for Domain Generalization", "authors": "Saqib Javed,Hieu Le,Mathieu Salzmann", "background": "在域泛化（DG）任务中，如何防止模型在训练过程中过度拟合源域是一个关键挑战。现有的方法往往专注于模型压缩以防止过拟合，但很少有人考虑利用量化方法使其变为一种隐式正则化手段，以引导优化过程向更平坦的损失曲面收敛，从而增强域泛化能力。QT-DoG方法旨在通过量化训练技术实现这一目标，通过对模型权重引入噪声，促进模型向更鲁棒、不易过拟合的方向发展。", "innovation": "QT-DoG 提出了一种新的方法，通过量化训练技术使模型产生更平坦的损失函数曲面，从而在防止过拟合的同时提升模型的泛化能力。与传统的量化方法专注于压缩模型不同，QT-DoG 利用量化作为一种隐式正则化手段，引导优化过程向对扰动和过拟合更为鲁棒的方向发展。研究提供了理论分析和实验证据来证实量化过程实质上鼓励了更平坦的损失曲面，从而提高了跨域的泛化能力。实验结果表明，通过量化技术不仅减少模型大小，还可以通过集合多个量化模型获得优于当前最佳DG方法的效果，且无需额外的计算或内存开销。", "conclusion": "通过量化训练技术，QT-DoG 有效地实现了在模型优化过程中向更鲁棒、更平坦的损失曲面的收敛，从而在多个任务上展示了显著的泛化改善。实验结果还证明，通过集合多个量化模型的方法可以在不需要额外开销的情况下获得优异的精度表现，进一步验证了该方法的有效性和实用性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.07560", "html_url": "https://arxiv.org/abs/2411.07560", "title": "基于预训练语言模型和深度学习方法的EUR/USD汇率预测融合文本挖掘", "title_en": "EUR/USD Exchange Rate Forecasting incorporating Text Mining Based on Pre-trained Language Models and Deep Learning Methods", "authors": "Hongcheng Ding,Xiangyu Shi,Ruiting Deng,Salaar Faroog,Deshinta Arrova Dewi,Shamsul Nahar Abdullah,Bahiah A Malek", "background": "该研究采用了一种新的方法来预测EUR/USD汇率，通过结合深度学习、文本分析和粒子群优化（PSO），旨在利用在线新闻和分析文章等定性数据提供优于传统计量经济和机器学习模型的表现。研究采用了先进的文本挖掘技术，包括使用RoBERTa-Large模型的情感分析和LDA的主题建模。实证研究显示，文本数据的整合对预测效果有显著提升，并且PSO-LSTM模型在与SVM、SVR、ARIMA和GARCH等基准模型的对比中表现出色。", "innovation": "该研究的创新之处在于引入了一种同时结合了深度学习、文本分析和PSO的新方法来预测汇率变化。研究使用了预训练的RoBERTa-Large模型进行情感分析，以及LDA进行主题建模。通过实验证明，这种综合方法在预测准确性上优于传统和基准模型。此外，研究还通过消融实验展示了文本数据类别对整个预测性能的贡献。", "conclusion": "研究显示，人工智能在金融领域的潜力巨大，特别是在实现汇率实时预测和整合非传统数据源方面。研究为后续的实现实时预测和多数据源集成方法的研究奠定了基础。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10926", "html_url": "https://arxiv.org/abs/2410.10926", "title": "联邦高效指令调优以提高大型语言模型的性能", "title_en": "Federated Data-Efficient Instruction Tuning for Large Language Models", "authors": "Zhen Qin,Zhaomin Wu,Bingsheng He,Shuiguang Deng", "background": "预训练大型语言模型（LLMs）需要通过指令调优提高对人类指令的响应能力。联邦学习（FL）通过利用来自客户的大量私有指令数据，改善数据多样性，成为LLM调优的流行方法。然而，现有的联邦调优方法直接使用所有本地数据，导致计算负担过重和对本地数据过度拟合。集中式的数据高效解决方案由于隐私问题不适合FL。因此，需要一种在保护隐私的同时，能够高效利用数据的方法来调优LLMs。", "innovation": "提出了FedHDS，这是一种联邦数据高效指令调优方法，能够在边缘节点上使用具有代表性的数据子集来调优LLMs。FedHDS 不共享原始数据，从而减少了边缘节点内部和相互之间的数据冗余。实验结果表明，与当前最佳的全数据联邦指令调优方法相比，FedHDS 在平均未见任务上提高了10.72%的 Rouge-L 衡量指标。同时，其使用的数据样本量低于1.5%，训练效率提升了数十倍。", "conclusion": "FedHDS 通过在边缘节点上使用代表性的数据子集，减少了数据冗余，同时保护了隐私。与现有的联邦调优方法相比，FedHDS 提升了性能，降低了几何级的数据需求，并显著提高了训练效率。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.15969", "html_url": "https://arxiv.org/abs/2408.15969", "title": "多块凸优化问题的 primal-dual 梯度流动力学稳定性", "title_en": "Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems", "authors": "Ibrahim K. Ozaslan,Panagiotis Patrinos,Mihailo R. Jovanović", "background": "研究了复合凸优化问题中的主对偶梯度流动力学的稳定性，这些问题是多块且目标函数可能包含多个非光滑项，在广义共识约束下。所提出的动力学基于广义增广拉格朗日法，为解决大规模多块场景提供了替代于ADMM的选择。对应的分析和实现挑战更为显著。与定制的算法和特定的收敛保证不同，本文发展了一套系统的方法来解决一系列复杂的复合优化问题，利用各种结构化特性，为所提动力学确立了全局指数收敛保证。", "innovation": "提出了一种系统的方法来解决包括多块的复杂复合优化问题，基于广义增广拉格朗日法开发了主对偶梯度流动力学，具有全局指数收敛保证。在假设和收敛性方面，提出的假设比证明主导对偶动态和离散时间方法（如标准两块和多块ADMM及EXTRA算法）线性收敛所需的假设更为宽松。研究表明某些结构假设对于指数稳定性是必要的，并提供了并行和分布式计算应用的计算实验来演示该方法的便利性。", "conclusion": "通过适应性分析和假设，本文提出的动力学框架为大规模多块凸优化提供了一个可靠的方法，具有全局指数收敛的保证。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.01805", "html_url": "https://arxiv.org/abs/2501.01805", "title": "使用梯度缓存进行端到端长文档摘要", "title_en": "End-to-End Long Document Summarization using Gradient Caching", "authors": "Rohit Saxena,Hao Tang,Frank Keller", "background": "训练基于Transformer的编码器-解码器模型进行长文档摘要面临显著挑战，因为训练过程中的内存消耗呈平方级增长。虽然已有研究提出在测试时扩展输入长度的方法，但这些方法在训练过程中仍然困难重重，即通过截断输入文档来匹配训练和测试条件，导致匹配问题。", "innovation": "提出了一种名为CachED（基于梯度缓存的编码器-解码器模型）的方法，该方法可以在不截断输入文档的情况下，端到端训练现有的基于Transformer的编码器-解码器模型。具体实现是通过非重叠滑动窗口对输入文档进行处理，然后在解码器中进行融合。反向传播期间，在解码器中缓存梯度，并通过重新计算隐藏向量在编码器中分块传递，类似于梯度检查点技术。该方法在超过50万个标记的训练过程中扩展了BART，并在不使用额外参数的情况下实现了更好的性能。", "conclusion": "该工作提出了一种新的方法，即CachED，能够在不截断输入文档的情况下端到端训练现有基于Transformer的编码器-解码器模型，有效地解决了长文档摘要训练中的内存消耗问题，并展示了通过梯度缓存技术来优化模型训练的可能性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.15237", "html_url": "https://arxiv.org/abs/2408.15237", "title": " llama中的Mamba：精简与加速混合模型", "title_en": "The Mamba in the Llama: Distilling and Accelerating Hybrid Models", "authors": "Junxiong Wang,Daniele Paliotta,Avner May,Alexander M. Rush,Tri Dao", "background": "线性RNN架构（如Mamba）在语言建模方面可以与Transformer模型相媲美，同时具有部署的优势特性。由于大规模Transformer模型训练的关注度较高，本文研究如何将这些预训练模型转换为适合部署的形式。通过使用学术资源中的GPU，可以将大型Transformer模型精简到线性RNN中，保留四分之一的注意力层，从而实现性能与原始Transformer模型相当的效果，并在聊天基准测试和通用基准测试中超越从头开始训练的开源混合Mamba模型。此外，研究还提出了一种硬件感知的推测性解码算法，进一步加速了Mamba和混合模型的推理速度。", "innovation": "本文提出了一种将大型Transformer模型转换为线性RNN的技术，通过重用注意力层的线性投影权重，并利用学术资源中的GPU实现这一过程。通过这种方法，我们可以生成一种包含四分之一注意力层的混合模型，该模型在聊天基准和通用基准测试中均表现出色，且比从头开始训练的开源混合Mamba模型更具优势。此外，提出了一种硬件感知的推测性解码算法，显著提高了Mamba和混合模型的推理速度。", "conclusion": "通过有限的计算资源，我们能够精简掉大部分原始注意力层，并高效地从精简后的模型生成内容。基于Llama3-8B-Instruct精简得到的顶级模型，在AlpacaEval 2上的长度控制下获胜率为29.61%，在MT-Bench上得分7.35，超过了最大的8B规模指令调优线性RNN模型。此外，精简后的模型显示出自然的长度外推能力，在20倍精简长度的“针扎麦堆”测试中几乎完美准确。完整的代码和预训练检查点已开源。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.01707", "html_url": "https://arxiv.org/abs/2411.01707", "title": "网格中具有路径解冲突的大规模多机器人覆盖路径规划", "title_en": "Large-Scale Multirobot Coverage Path Planning on Grids With Path Deconfliction", "authors": "Jingtao Tang,Zining Mao,Hang Ma", "background": "传统的多机器人覆盖路径规划（MCPP）方法通常将网格细化为子网格，利用覆盖树（STC）之类的范式生成路径，但这种方法不适用于部分堵塞的2x2块网格。因此，需要一种新的方法来直接处理整个网格，以解决此限制并改进现有的NP-hard性结果。", "innovation": "本文提出了一个新范式Extended-STC (ESTC)，它扩展了传统的STC方法，确保即使在包含部分堵塞块的子网格中也能实现完全覆盖和限界子优化。此外，还提出了LS-MCPP算法框架，该框架结合了三种新型的邻域操作，并在局部搜索策略中优化在网格上的覆盖路径。创新还在于引入了一种多功能后处理过程，该过程可以首次将多智能体路径规划（MAPF）技术应用于MCPP，从而融合这两个重要领域进行优化，解决了机器人之间的冲突并且考虑了转向成本，使解决方案更实用。实验结果表明，所提出的方法在时间和解决方案质量上明显优于现有方法，能够在分钟内处理多达100个机器人在256x256网格上的问题。", "conclusion": "通过引入新的ESTC和LS-MCPP框架，结合MAPF技术和具有转向成本考虑的局部搜索策略，本文提出了处理大规模多机器人覆盖路径规划的新方法，该方法能够在大规模和高复杂度的环境下有效处理多机器人的路径规划问题，并在真实条件下得到验证。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.14275", "html_url": "https://arxiv.org/abs/2501.14275", "title": "利用在线奥林匹克水平数学问题进行LLM训练及抗污染评估", "title_en": "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation", "authors": "Sadegh Mahdavi,Muchen Li,Kaiwen Liu,Christos Thrampoulidis,Leonid Sigal,Renjie Liao", "background": "大型语言模型（LLMs）的进步引起了对它们解决奥林匹克级别的数学问题能力的兴趣。然而，这些模型的训练和评估受限于可用数据集的规模和质量。目前的基准测试容易受到污染，导致评估结果不可靠。AoPS社区中充斥着奥林匹克级别的问题和社区驱动的解决方案，提供了丰富的资源。", "innovation": "该论文提出了一种自动化管道，利用AoPS论坛的丰富资源，开发了一个名为AoPS-Instruct的数据集，包含超过600,000个高质量的问答对。论文构建了一个自动化管道，产生了LiveAoPSBench，这是一个具有时间戳的不断演化的评估集，为LLM的表现提供了一个抗污染基准。研究表明，微调LLMs在AoPS-Instruct上能够提高其在多个基准测试中的推理能力。此外，观察到LLM的性能随时间下降，表明它们在较早示例上的成功可能更多依赖于预训练暴露而非真正的推理能力。这项工作为创建和维护高级数学推理所需的大型高质量数据集提供了一种可扩展的方法，揭示了LLMs在这个领域的能力和局限性。", "conclusion": "我们的工作为LLMs创建和维护大规模高质量数据集提供了可扩展的方法，展示了它们在高级数学推理中的能力和局限性。我们的基准测试和代码可在此链接中找到：this https URL"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10814", "html_url": "https://arxiv.org/abs/2501.10814", "title": "No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling", "title_en": "No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling", "authors": "Young Seok Jeon,Hongfei Yang,Huazhu Fu,Mengling Feng", "background": "3D模型在CT/MRI分割中优于2D模型，因为它们能够有效捕捉切片间的关系。然而，额外的深度维度显著增加了内存消耗。虽然基于补丁的训练可以缓解内存限制，但由于滑动窗口方法，它会明显降低推断速度。", "innovation": "提出了一种名为No-More-Sliding-Window (NMSW) 的新型端到端可训练框架，旨在通过消除滑动窗口方法来提高通用3D分割骨干网络在推断步骤中的效率。NMSW 使用可微分的Top-k模块仅选择最具相关性的补丁，从而减少冗余计算。此外，当补丁级预测不足时，框架还能智能地利用粗略的全局预测来细化结果。NMSW 实现了与滑动窗口推断相当的竞争准确度，同时将计算复杂度降低了91%。此外，NMSW 在H100 GPU 上实现了9.1倍的更快推断速度，并在Xeon Gold CPU 上实现了11.1倍的更快推断速度。NMSW 是模型独立的，与任何现有的高效分割骨干网络集成时能进一步提升效率。", "conclusion": "NMSW 实现了与滑动窗口推断相当的竞争准确度，同时显著降低了计算复杂度，提高了推断速度，并且是模型独立的框架。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.13488", "html_url": "https://arxiv.org/abs/2412.13488", "title": "语言模型中基于显著性感知稀疏微调策略的精炼", "title_en": "Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models", "authors": "Xinxin Liu,Aaron Thomas,Cheng Zhang,Jianyi Cheng,Yiren Zhao,Xitong Gao", "background": "PEFT（参数高效微调）由于低秩适应方法（如LoRA）而引起了关注。本文聚焦于基于稀疏性的PEFT（SPEFT），它通过在模型权重矩阵中引入可训练的稀疏适应，提供了比低秩方法更大的微调参数选择灵活性。作者进行了首次系统评估可解释度度量方法，并发现基于梯度的简单度量可靠且与最佳替代方案相当。此外，作者还比较了静态和动态稀疏掩码策略，发现静态稀疏掩码能够在不牺牲性能的情况下提供更高的效率，而动态稀疏掩码则没有显著优势。在整个NLP任务中，简单的基于梯度的静态SPEFT在大模型微调中表现优异，为SPEFT提供了一个简单有效的基准。", "innovation": "1. 第一次系统评估基于显著性的SPEFT的可解释度度量方法。\n2. 发现基于梯度的简单度量方法既可靠又与最佳替代方案性能相当。\n3. 通过比较静态和动态稀疏掩码策略，展示了静态稀疏掩码在效率和性能之间的权衡。\n4. 提供了一个简单的但有效的SPEFT基准，挑战了复杂性是有效PEFT必要性的观点。\n5. 提供了一个开源框架，以建立未来研究的可重复基准。", "conclusion": "在NLP任务中，简单的基于梯度的静态SPEFT方法在LLMs微调中表现突出，并为其提供了简单有效的基准。这挑战了PEFT需要复杂性的观点，同时为未来的研究提供了可重复的基准，开源框架可在[此网址]访问。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04413", "html_url": "https://arxiv.org/abs/2502.04413", "title": "MedRAG：通过知识图谱引导的推理增强检索增强生成以提升医疗书记助手", "title_en": "MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot", "authors": "Xuejiao Zhao,Siyan Liu,Su-Yin Yang,Chunyan Miao", "background": "现有基于启发式方法的医疗领域检索增强生成（RAG）模型在诊断准确性和特异性方面存在不足，特别是在具有类似表现的疾病诊断中。", "innovation": "提出了MedRAG，一种增强型RAG模型，通过知识图谱（KG）引导的推理，基于症状检索诊断和治疗建议。MedRAG构建了全面的四层诊断知识图谱，动态整合了相似的电子健康记录（EHR），并在大型语言模型中进行推理，从而提供了更准确和具体的决策支持，并提供了进一步的问题以增强个性化的医疗决策。实验结果显示，MedRAG在多个评测数据集上优于现有RAG模型，能在减少误诊方面提供更具体的诊断见解。", "conclusion": "MedRAG通过利用知识图谱的信息整合和关系能力，在减少误诊方面表现出色，提供了更具体的诊断见解，性能优于最先进的模型。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01980", "html_url": "https://arxiv.org/abs/2502.01980", "title": "生成式数据挖掘与长尾引导扩散", "title_en": "Generative Data Mining with Longtail-Guided Diffusion", "authors": "David S. Hayden,Mao Ye,Timur Garipov,Gregory P. Meyer,Carl Vondrick,Zhao Chen,Yuning Chai,Eric Wolff,Siddhartha S. Srinivasa", "background": "预测模型在部署后会遇到一系列难以预料的挑战，传统做法是采取一种反应式的、循环的方法，即模型部署、数据挖掘和重新训练。该研究提出了一种主动的长尾发现流程，通过想象训练数据中的潜在数据来应对这一问题，特别是在训练过程中开发了一种通用的模型基础长尾信号。此信号包括一个数据不可影响的直通式可微不确定性表达式，可以标记罕见或困难的输入。该信号被用作生成额外训练数据的指导，以此开发了生成式数据挖掘方法，并称之为长尾引导（Longtail Guidance, LTG）的过程。通过LTG生成的数据具有语义上的变化，显著提升了多种图像分类基准测试中的泛化能力，并且可以通过视觉语言模型（VLM）前瞻性地发现、文本解释和解决部署模型中的概念缺口。", "innovation": "该研究提出了一种主动的长尾发现过程，通过在模型训练过程中构建潜在数据来生成新的训练数据，而无需重新训练扩散模型或预测模型，也无需让预测模型接触到中间扩散状态。生成的数据具有语义意义，能显著提升模型的泛化性能，并且可以通过视觉语言模型（VLM）来发现和解决模型中的概念缺口。", "conclusion": "研究提出了一种新颖的生成式数据挖掘方法，通过LTG过程生成具有语义意义变化的新数据，提升了模型的泛化性能，并且能通过VLM来解决模型中的概念与知识缺口。这种方法更加高效、全面和前瞻性，并展示了在图像分类等基准测试中实际应用的价值。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.04783", "html_url": "https://arxiv.org/abs/2412.04783", "title": "KNN-MMD: 通过局部分布对齐实现跨域无线传感", "title_en": "KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment", "authors": "Zijian Zhao,Zhijie Cai,Tingwei Chen,Xiaoyang Li,Hang Li,Qimei Chen,Guangxu Zhu", "background": "无线传感技术在多种环境中得到了广泛应用，如家庭、办公室和公共空间。通过分析信道状态信息（CSI），可以推断人类动作，如人员识别、手势识别和跌倒检测。然而，CSI对环境变化高度敏感，即使是微小的变化也能显著扭曲CSI模式。这导致在将一个环境训练的无线传感模型应用到另一个环境时，性能下降甚至失效。为了解决这一挑战，域对齐（DAL）被广泛应用于跨域分类任务，因为它关注在特征空间中对齐源域和目标域的全局分布。尽管DAL很受欢迎，但它往往忽视了类别间的相互关系，甚至在全局对齐达成时，类别间的对齐也会出现偏差。为克服这些限制，我们提出了K-最近邻最大均值差异（KNN-MMD），一种新颖的少量样本方法，用于跨域无线传感。该方法首先通过从目标域构建帮助集并使用最大均值差异（MMD）实现类别内的局部对齐，从而在源域和目标域之间建立局部对齐。此外，我们还解决了跨域方法中常见的一个关键问题，即模型性能在不同周期之间剧烈波动。大多数现有方法在目标域没有带标签数据的情况下，难以确定最佳停止点。我们的方法通过在训练时排除目标域的支持集，并将其用作验证集来确定停止点来解决这个问题。", "innovation": "我们提出了一种新颖的少量样本方法——K-最近邻最大均值差异（KNN-MMD），用于跨域无线传感。该方法通过从目标域构建帮助集并使用MMD实现类别内的局部对齐，解决传统方法忽视类别间关系的问题。此外，我们的方法还解决了跨域模型性能在不同周期之间剧烈波动的问题，并通过排除和利用目标域的支持集作为验证集来确定训练的停止点，从而提高模型稳定性并解决训练过程中的停止难题。", "conclusion": "通过构建目标域的帮助集和局部分布对齐，KNN-MMD可以提高跨域无线传感的鲁棒性和性能。该方法不仅在理论上提供了一种新的解决方案，还解决了实际应用中常见的几个挑战，展示了其在多环境下的广泛应用潜力。我们的方法已经在公开数据集和代码上进行了验证，证明了其有效性和适用性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15294", "html_url": "https://arxiv.org/abs/2502.15294", "title": "Round Attention: 加速大语言模型推理的一种新型轮次级别注意力机制", "title_en": "Round Attention: A Novel Round-Level Attention Mechanism to Accelerate LLM Inference", "authors": "Yaohua Tang,Zhicheng Hu,Kun Cheng,Fan Mo,Qiheng Lv,Hua Wang,Zhi Chen", "background": "随着大语言模型（LLMs）上下文窗口大小的增加，其处理复杂长文本任务的能力得到了提升。然而，随着对话轮次的增加，需要存储大量KV缓存，这严重影响了模型服务系统的效率和可用性。本文分析了实际用户对话数据，并发现LLM推理表现出一个分水岭层，之后各轮级别注意力的分布显示出明显的相似性。", "innovation": "我们提出了Round Attention，一种新型的轮次级别注意力机制，它选择性地处理分水岭层中的top-k相关轮次的KV缓存，其中k是通过注意力矩阵动态确定的。这种机制理论上能减少54%-82%的内存使用，并且实验结果表明，加载稀疏的关键轮次KV缓存能够保持答案准确度而不降低性能。", "conclusion": "该方法通过选择性处理相关的KV缓存，显著减少了内存使用量，同时保持了模型的准确性和性能。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.04931", "html_url": "https://arxiv.org/abs/2501.04931", "title": "通过洗牌不一致性突破多模态大语言模型", "title_en": "Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency", "authors": "Shiji Zhao,Ranjie Duan,Fengxiang Wang,Chi Chen,Caixin Kang,Shouwei Ruan,Jialing Tao,YueFeng Chen,Hui Xue,Xingxing Wei", "background": "多模态大型语言模型（MLLMs）已在商业应用中取得显著成效并被广泛应用，但它们的安全机制仍然存在潜在漏洞。现有的攻击方法通过对模型进行复杂优化或设计出精细的图像和文本提示来规避安全机制，虽然有一定的进展，但对商用封闭源代码的MLLMs的成功攻击率较低。不同于以往的研究，我们通过实验证实了MLLMs在处理洗牌有害指令时存在理解和安全性之间的不一致性，即从理解能力的角度来看，MLLMs能够理解洗牌后的有害文本-图像指令，但从安全性角度来看，它们极易被洗牌后的有害指令绕过，导致有害回复。这一发现发现了新的攻击途径和潜在弱点，进而提出了基于洗牌不一致性的文本-图像攻击方法（SI-Attack）", "innovation": "提出了基于洗牌不一致性的文本-图像攻击方法（SI-Attack）。通过应用基于查询的黑盒优化方法，根据毒法官模型的反馈来选择最危险的洗牌输入，从而优化攻击性能，特别是针对商用MLLMs如GPT-4o或Claude-3.5-Sonnet的效果显著改善", "conclusion": "实验结果显示SI-Attack可以在三个基准测试中提升攻击性能，尤其是对商用MLLMs的攻击成功率显著提高。这一发现强调了理解MLLMs的安全机制弱点的重要性，并为未来攻击和防御研究提供了新的方向"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09692", "html_url": "https://arxiv.org/abs/2502.09692", "title": "AB-UPT：通过锚定分支通用物理变换器扩展神经CFD代理模型以实现高保真汽车空气动力学模拟", "title_en": "AB-UPT: Scaling Neural CFD Surrogates for High-Fidelity Automotive Aerodynamics Simulations via Anchored-Branched Universal Physics Transformers", "authors": "Benedikt Alkin,Maurits Bleeker,Richard Kurle,Tobias Kronlachner,Reinhard Sonnleitner,Matthias Dorfer,Johannes Brandstetter", "background": "神经近似模型的最新进展为汽车空气动力学等领域的创新带来了潜力，但工业规模的问题往往涉及到数十亿个单元网格，这带来了重大可扩展性挑战。复杂几何形状进一步通过表面体相互作用复杂化建模，量方面的旋转等量高度非线性必须满足严格的发散自由约束。为解决这些要求，我们介绍了锚定分支通用物理变换器(AB-UPT)作为一种新颖的建模方案，用于构建计算流体动力学(CFD)模拟的神经近似模型。AB-UPT旨在通过multip-branch操作符解耦几何编码和预测任务；通过在低维度潜在空间中实现神经模拟，结合锚定神经场解码器来实现高分辨率输出的可扩展性；通过一种新颖的发散自由公式实现物理一致性的维护。", "innovation": "AB-UPT具有解耦几何编码和预测任务的特性，能够在低维度潜在空间中实现神经模拟，结合锚定神经场解码器预测高保真输出，同时通过新颖的发散自由公式确保物理一致性。此模型能够在一个GPU上训练少于一天，并在几秒内预测行业标准的表面和体积字段。此外，该方法的设计使可以从计算机辅助设计几何图形实现神经模拟，而无需昂贵的CFD网格生成过程。", "conclusion": "AB-UPT在汽车CFD模拟中表现出色，从33,000网格单元到150,000,000网格单元，均达到了最先进的预测精度。该模型不仅展示了在高效训练和快速预测方面的优越性能，还证明了与严格的物理约束兼容的高级性能，特别是在建立发散自由的旋转场时表现出明显优势。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15783", "html_url": "https://arxiv.org/abs/2503.15783", "title": "基于语法和游戏性对齐的强化学习在使用LLMs的游戏描述生成中的应用", "title_en": "Grammar and Gameplay-aligned RL for Game Description Generation with LLMs", "authors": "Tsunehiko Tanaka,Edgar Simo-Serra", "background": "Game Description Generation (GDG) 是从自然语言文本生成使用Game Description Language (GDL) 编写的描述的任务。之前的研究表明，利用大型语言模型（LLMs）的上下文理解能力可以实现GDG，但准确再现游戏描述中的游戏特性仍是一个挑战。", "innovation": "本文提出了一种基于强化学习（RL）的LLMs微调方法（RLGDG），通过引入语法奖励和概念奖励同时提高语法正确性和对游戏角色概念的忠实度。此外，采用了监督微调（SFT）后跟强化学习（RL）的两阶段训练策略。实验结果表明该方法显著优于仅使用SFT的基线方法。", "conclusion": "本文提出的方法在语法正确性和对游戏概念的忠实度方面显著优于仅使用SFT的方法。实验结果证明了该方法的有效性，并提供了相关代码。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02703", "html_url": "https://arxiv.org/abs/2503.02703", "title": "AI驱动的图形资产生成工具在游戏设计和开发流程中的启发式方法：用户中心的方法", "title_en": "Heuristics for AI-driven Graphical Asset Generation Tools in Game Design and Development Pipelines: A User-Centred Approach", "authors": "Kaisei Fukaya,Damon Daylamani-Zad,Harry Agius", "background": "图形资产在游戏设计和开发中扮演着重要角色。AI驱动的生成工具可用于辅助创建图形资产，从而改善游戏设计和开发流程，但现有研究较少探讨这些生成方法如何融入更广泛的工作流程。此外，目前没有针对此类工具制定指南或启发式方法。因此，本研究通过与16名游戏设计师和开发者进行用户研究，探讨他们操作图形资产生成工具的行为和交互，发现游戏设计师和开发者倾向于在早期设计阶段使用这些工具，并认为工具生成的初始资产质量可以在后续改进，同时强调了这些工具与现有设计和开发环境更好集成的需求以及输出在常见数据格式中的重要性。", "innovation": "本研究通过用户研究提供了对于AI驱动图形资产生成工具的启发式方法集，这些工具能够满足游戏设计师和开发者的需求和期望，强调了将这些工具更有效地融入现有工作流程的重要性，并提出了一些具体指南，以改善工具与现有环境的集成度和输出格式的兼容性。", "conclusion": "研究表明，游戏设计师和开发者在早期设计阶段更偏好使用AI生成工具；生成的初始资产可以后期改进质量；工具的输出需要支持常见数据格式，以便更好地集成到现有环境中；未来还需要进一步满足用户特定需求，以更好地将这些工具融入现有开发流程。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04466", "html_url": "https://arxiv.org/abs/2504.04466", "title": "LoopGen：无需训练的可循环音乐生成", "title_en": "LoopGen: Training-Free Loopable Music Generation", "authors": "Davide Marincione,Giorgio Strano,Donato Crisostomi,Roberto Ribuoli,Emanuele Rodolà", "background": "循环（loops）是音乐中的一种短音频片段，特别在舞曲和电子音乐等流派中广泛使用，其能够在不中断的情况下无缝重复播放。然而，现有的音乐生成模型在生成能够无缝重复的循环音频时存在局限性，仅仅生成一个简短的波形不能确保其端点平滑过渡到起始点，容易产生明显的不连续性。", "innovation": "本文通过修改非自回归模型（MAGNeT），使得模型能够以圆形模式生成标记，即在生成音频结尾时允许模型关注音频的开头，从而实现仅通过推理的方法生成自然循环的音频。这种方法无须额外的训练或数据，并且通过计算环状过渡的标记困惑度，观察到55%的改善。盲听测试进一步证实了感知上的显著提升，平均评分提高了70%。这些结果突显了仅通过推理的模型改进方法的有效性，并强调了非自回归方法在上下文感知音乐生成中的优势。", "conclusion": "整体而言，这些结果强调了仅通过推理提升生成模型有效性的方法，并突显了非自回归方法在上下文感知音乐生成中的优势。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.20758", "html_url": "https://arxiv.org/abs/2502.20758", "title": "LLMs之间的集体推理：一种无需 ground truth 的答案验证框架", "title_en": "Collective Reasoning Among LLMs: A Framework for Answer Validation Without Ground Truth", "authors": "Seyed Pouyan Mousavi Davoudi,Amin Gholami Davodi,Alireza Amiri-Margavi,Mahdi Jafari", "background": "该研究介绍了一种创新的方法，其中几个先进的大型语言模型，包括GPT-4-0125-preview、Meta-LLAMA-3-70B-Instruct、Claude-3-Opus和Gemini-1.5-Flash，合作生成和回答复杂的、博士级别的概率问题。与依赖单一“正确”参考不同，研究的重点是模型间的分歧程度能反映输出的可靠性，从而反映生成问题的整体质量。研究利用卡方检验、Floess' Kappa系数和置信区间计算等统计评估方法，评估模型间的一致性，从而捕捉答案的精度和问题表述的清晰度。研究发现，Claude和Gemini倾向于更连贯、不模棱两可地提出问题，这体现在他们更紧密的置信区间和更高的回答一致性；相比之下，LLAMA表现出更宽的置信区间和较低的一致性，反映了其更少的一致性和问题表述的不稳定性。这些观察结果支持一种多模型合作策略不仅能提高答案的可靠性，还能提供一种有效的、数据驱动的机制来评估和改进问题质量，尤其是在没有明确解决方案的情况下。", "innovation": "该研究提出了一种无需ground truth即可验证大型语言模型答案的方法。研究采用了多种统计评估方法，包括chi-square检验、Fleiss' Kappa系数和置信区间计算。通过分析多种模型之间的分歧度和一致性，研究探索了一种多模型合作生成高质量问题并提高答案可靠性的策略。", "conclusion": "研究证明了多模型合作策略不仅能提高AI指导推理过程的准确性，还能提供一个数据驱动的方法来评估和改进问题质量。这种框架在没有明确答案的情况下提供了一个有效的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13310", "html_url": "https://arxiv.org/abs/2503.13310", "title": "生成式AI在软件架构的应用、挑战和未来方向", "title_en": "Generative AI for Software Architecture. Applications, Challenges, and Future Directions", "authors": "Matteo Esposito,Xiaozhou Li,Sergio Moreschini,Noman Ahmad,Tomas Cerny,Karthik Vaidhyanathan,Valentina Lenarduzzi,Davide Taibi", "background": "生成式人工智能（GenAI）正在推动软件开发领域的变革，但在软件架构的应用仍然处于初级阶段，尚未有系统性的研究涵盖这一主题。", "innovation": "本研究系统性地综合了GenAI在软件架构中的应用、动机、使用场景、可用性以及未来面临的挑战，采用了多声腔文献回顾（MLR）方法，分析同行评议和灰色文献，识别当前的实践、模型、采用背景以及报告的挑战，通过开放编码提取主题。研究发现，GenAI主要用于早期软件开发周期中的架构决策支持和架构重构，主要应用于单体和微服务架构，但缺乏严格的GenAI输出测试，模型精度、幻觉、伦理、隐私等问题频现，且缺少针对架构的具体数据集和评估框架。", "conclusion": "生成式AI在软件设计中显示了巨大的潜力，但仍存在诸多挑战，未来的研究应致力于设计通用的评估方法、处理伦理与精度问题、增加透明度和解释性，推广架构特定的数据集和基准，缩小理论可能性和实际应用之间的差距。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00521", "html_url": "https://arxiv.org/abs/2504.00521", "title": "大规模系统中原子性违规的自动检测", "title_en": "Automated detection of atomicity violations in large-scale systems", "authors": "Hang He,Yixing Luo,Chengcheng Wan,Ting Su,Haiying Sun,Geguang Pu", "background": "在关键系统中，中断驱动程序中的原子性违规对软件安全性构成了重大威胁。这些违规发生时，共享资源上的操作执行顺序因异步中断而被打断。由于程序状态空间巨大、应用程序代码依赖性和复杂的领域知识，检测这些违规非常具有挑战性。", "innovation": "我们提出了Clover，一个混合框架，结合了静态分析和大型语言模型代理，以检测大型系统中的原子性违规。Clover首先执行静态分析以提取关键代码片段和操作信息；随后，它启动一个多代理过程，专家代理利用领域知识检测原子性违规，这些违规随后由审判代理进行验证。", "conclusion": "在RaceBench 2.1、SV-COMP和RWIP上的评估表明，Clover的精度和召回率分别为92.3%和86.6%，在F1得分上比现有方法高出27.4%-118.2%。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.20380", "html_url": "https://arxiv.org/abs/2502.20380", "title": "通过单一奖励步骤进行多轮代码生成", "title_en": "Multi-Turn Code Generation Through Single-Step Rewards", "authors": "Arnav Kumar Jain,Gonzalo Gonzalez-Pumariega,Wayne Chen,Alexander M Rush,Wenting Zhao,Sanjiban Choudhury", "background": "现有的方法在生成代码时要么没有反馈，要么使用复杂且分层的强化学习来优化多轮反馈。这些方法在处理多轮反馈的代码生成任务时较为困难，而且缺乏直接利用多轮反馈的能力。", "innovation": "提出了一种名为$μ$Code的简单且可扩展的方法，该方法仅使用单步奖励来解决多轮代码生成问题。核心思想是将代码生成视为单一可恢复的马尔可夫决策过程（MDP），即可以从任何中间代码状态在一轮反馈中恢复到正确的代码。$μ$Code方法通过迭代训练生成器和验证器来处理多轮执行反馈，生成满足需求的代码并评估其质量。实验结果表明，该方法明显优于当前最好的基线方法，且能有效利用执行反馈信息。", "conclusion": "通过实验评估，$μ$Code方法显著提升了多轮代码生成的表现，其设计选择和奖励模型的有效性也得到了分析，验证了$μ$Code方法利用执行反馈的能力。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.14949", "html_url": "https://arxiv.org/abs/2502.14949", "title": "KITAB-Bench：跨领域的综合阿拉伯OCR和文档理解基准", "title_en": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding", "authors": "Ahmed Heakl,Abdullah Sohail,Mukul Ranjan,Rania Hossam,Ghazi Shazan Ahmad,Mohamed El-Geish,Omar Maher,Zhiqiang Shen,Fahad Khan,Salman Khan", "background": "随着检索增强生成（RAG）在文档处理中的广泛应用，坚实的文本识别变得愈加重要，以便提取知识。尽管用于英语和其他语言的光学字符识别（OCR）可以从大规模数据集和成熟的基准测试中受益，但阿拉伯OCR由于其连笔书写、从右到左的文本流动以及复杂的版式和书法特征，面临着独特的挑战。现有的评价系统存在不足，因此需要一个全面的基准测试来评估阿拉伯OCR模型的性能。", "innovation": "本文提出了KITAB-Bench，这是一个全面的多领域阿拉伯OCR基准测试，填补了现有评价系统的空白。该基准包括8,809个样本，涵盖9个主要领域和36个子领域，包含各种文档类型，包括手写文本、结构化表格以及商业智能中的21种图表的专门覆盖。实验结果显示，现代视觉语言模型（如GPT-4o、Gemini和Qwen）在字符错误率（CER）方面的性能比传统OCR方法（如EasyOCR、PaddleOCR和Surya）平均高出60%。特别在PDF转化为Markdown时，最先进的模型Gemini-2.0-Flash的准确率仅为65%，这凸显了阿拉伯文本识别的挑战，包括复杂字体、数字识别错误、单词拉伸和表格结构检测等问题。这项工作建立了一个严格评价框架，能够促进阿拉伯文档分析方法的进步，并缩小其性能与英文OCR技术之间的差距。", "conclusion": "本文通过建立KITAB-Bench，提供了一个严格的评价框架，能够推动阿拉伯文档分析方法的进步，并缩小其性能与英文OCR技术之间的差距，特别是在手写文本、结构化表格和商业智能图表的识别中展现出显著的优势，同时也指出了当前阿拉伯OCR模型在某些领域的局限性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03592", "html_url": "https://arxiv.org/abs/2503.03592", "title": "LLMs在英文量化下，多语言性能并未被不成比例地损害", "title_en": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance", "authors": "Karl Audun Borgersen,Morten Goodwin", "background": "对于本地部署的LLMs，GGUF格式和k量化解析是保持原始模型性能的同时减少模型大小至可部署在消费级硬件上的重要工具。在模型权重量化过程中，会根据这些权重在推断期间的重要性减少所使用的位数。这种重要性通过一个被称为“重要性矩阵”的小型文本文档来确定，该文档代表了LLM的标准使用案例。绝大多数可用的量化文档主要用英文编写，因此提出了一个问题，即仅考虑英语任务时，是否牺牲了多语言性能，以及是否可以通过使用不同的重要性矩阵来维持多语言性能。", "innovation": "本文通过将Llama3.3 70B量化为三种语言（英语、挪威语和马拉雅拉姆语）的重要性矩阵，并在英语和挪威语下评估这些模型在MixEval数据集上的表现，对这个问题进行了探索。实验结果表明，当前的量化方法在一定程度上并未不成比例地损害多语言性能。", "conclusion": "当前的量化实践并不显著损害多语言模型在英语和挪威语下的表现。这意味着英语量化在保持多语言性能方面可能是有效的，从而为在消费级硬件上部署多语言LLMs提供了新的可能性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05312", "html_url": "https://arxiv.org/abs/2504.05312", "title": "向基于适应性记忆的优化方向以增强检索增强生成", "title_en": "Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation", "authors": "Qitao Qin,Yucong Luo,Yihang Lu,Zhibo Chu,Xianwei Meng", "background": "检索增强生成（RAG）通过将外部知识库的非参数知识整合到模型中，已经成为了提高回应准确性、减少事实错误和幻觉的有效方法。现有的RAG方法在开放域问答（QA）任务中表现不佳，原因在于它们进行独立的检索操作，并直接将检索信息融入生成中，而不维护总结记忆或使用自适应检索策略，导致了冗余信息噪声和信息整合不足的问题。", "innovation": "本文提出了一个名为Amber的方法，针对开放域QA任务中RAG的挑战。Amber包括基于代理的记忆更新器、自适应信息收集器和多粒度内容过滤器，共同在迭代的记忆更新范式中工作。该方法通过多代理协作方法整合和优化语言模型的记忆，确保全面的知识整合。通过动态调整检索查询和基于积累知识决定停止检索，提高了检索效率和效果。此外，Amber通过在多个层次过滤无关内容来减少噪声，保留关键信息，从而提升整体模型性能。", "conclusion": "我们在多个开放域QA数据集上进行了广泛实验，结果表明了我们方法及其组件的优越性和有效性。代码已公开。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18710", "html_url": "https://arxiv.org/abs/2504.18710", "title": "非分离数据的显式神经网络分类器", "title_en": "Explicit neural network classifiers for non-separable data", "authors": "Patrícia Muñoz Ewald", "background": "该研究基于现有的神经网络理论，针对那些标准的线性可分模型无法分类的数据集。通常，传统的线性分类方法在处理非线性可分数据时表现出局限性。因此，通过引入特征映射和激活函数，神经网络能够更好地应对这类问题。本研究利用ReLU激活函数及其特性，探讨了如何构建能够有效分类非线性可分数据的神经网络模型。", "innovation": "该研究的创新在于通过精确化描述一类前馈神经网络与截断映射的关系，展示了如何利用ReLU神经网络构建出一种特征映射，这种映射能够区分具有同心结构的数据集。该方法不仅丰富了神经网络在特征学习方面的应用，也提供了一种新的处理非线性可分问题的途径。", "conclusion": "研究表明，通过适当的特征提取和ReLU激活函数的运用，神经网络能够有效地识别和分类非线性可分的数据集。这不仅扩展了神经网络的适用范围，也为解决实际中的非线性分类问题提供了新的思路和方法。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22660", "html_url": "https://arxiv.org/abs/2505.22660", "title": "最大化信心单凭自身即可提升推理能力", "title_en": "Maximizing Confidence Alone Improves Reasoning", "authors": "Mihir Prabhudesai,Lili Chen,Alex Ippoliti,Katerina Fragkiadaki,Hao Liu,Deepak Pathak", "background": "强化学习(RL)已经在许多领域推动了机器学习模型的重大进步，尤其最近在解决数学、科学和编程挑战问题方面，前沿语言模型表现尤为突出。然而，RL算法的核心是奖励函数，而奖励工程在任何领域都是一个极其复杂的问题。本研究讨论了一个全新的方法，旨在解决这一挑战。", "innovation": "该研究提出了一种名为 RENT（基于熵最小化的强化学习）的完全无监督RL方法，无需外部奖励或标准答案，而是利用模型生成答案时的熵作为内在奖励。这种方法通过增强高模型置信度的推理过程，显著提升了推理能力。实验表明，该方法在广泛使用的推理基准测试上，如GSM8K、MATH500、AMC、AIME和GPQA，以及不同规模的模型，如Qwen、Mistral和Llama系列上取得了一致的效果。", "conclusion": "该研究展示了一种通用的无监督学习方法，适用于缺少外部监督的各种领域，这种方法依赖于模型的熵来引导其推理过程，从而提高了模型的推理能力。这种方法的广泛适用性为解决缺乏外部监督挑战的领域提供了新的可能性。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11108", "html_url": "https://arxiv.org/abs/2505.11108", "title": "基于场景上下文的个性化机器人物体重新排列", "title_en": "Personalized Robotic Object Rearrangement from Scene Context", "authors": "Kartik Ramachandruni,Sonia Chernova", "background": "家庭机器人执行对象重新排列任务时，需要在没有明确指示的情况下个性化排列物体，并将物体放置在满了物体的环境中，同时还要能解决未见过的物体和新环境问题。为应对这些挑战，研究者们需要一个基准测试来评估算法的性能。本文针对这些问题提出了一种基于场景上下文的个性化物体重新排列基准测试——PARSEC，并展示了如何从已有的场景中学习用户组织偏好来重新排列物体。", "innovation": "本文提出了一种新的数据集PARSEC，包含来自72名用户收集的11万个重新排列实例，涵盖了93种物体类别和15种环境。同时，提出了ContextSortLM模型作为一种基于LLM的个性化重新排列模型，该模型能够更好地处理有多种放置位置的物体，并对部分排列的环境进行个性化重新排列。通过PARSEC基准测试评估并结合群众评分，结果显示使用多个场景上下文信息的个性化模型表现优于单个上下文信息的模型。此外，ContextSortLM在模拟目标用户排列方面表现优异，并在三个环境类别中名列前茅。", "conclusion": "我们的评估结果表明，利用多个场景上下文信息的个性化模型优于依赖单一上下文信息的模型。除了模型表现之外，我们的工作还揭示了在不同环境中建模环境语义的挑战，并提出了未来工作的建议。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08524", "html_url": "https://arxiv.org/abs/2504.08524", "title": "USM-VC：使用通用语义映射残差块减轻说话人特征泄漏的语音转换", "title_en": "USM-VC: Mitigating Timbre Leakage with Universal Semantic Mapping Residual Block for Voice Conversion", "authors": "Na Li,Chuke Wang,Yu Gu,Zhifeng Li", "background": "传统的语音转换（VC）将源语音转换为目标说话人的语音，但保留了内容信息时，会保留源说话人的音色，导致音色泄漏，减少了目标说话人相似度。", "innovation": "本文引入了一个新的通用语义匹配（USM）残差块到内容提取器中，该模块由两个加权分支组成：1) 以通用语义词典为基础的声音特征再表达（CFR）模块，提供无音色的内容表示；2) 绕过连接到原始内容层，提供补充的细粒度信息。CFR模块通过每个字典条目代表一个音素类别，并结合来自多名说话人的语音统计计算而成，从而构建了一个稳定且独立于说话人的语义集。方法通过使用相应的音素后验概率作为权重，将每个内容帧表示为字典条目的加权线性组合，以获得无音色的内容表示。实验结果表明，该方法有效地缓解了音色泄漏，并显著提高了目标说话人的相似度。", "conclusion": "我们的方法有效地缓解了音色泄漏问题，并显著提高了语音转换的相似度。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17066", "html_url": "https://arxiv.org/abs/2505.17066", "title": "用专家模型集成提升大语言模型防护对抗牢笼攻击的效果", "title_en": "Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration", "authors": "Tatia Tsmindashvili,Ana Kolkhidashvili,Dachi Kurtskhalia,Nino Maghlakelidze,Elene Mekvabishvili,Guram Dentoshvili,Orkhan Shamilov,Zaal Gachechiladze,Steven Saporta,David Dachi Choladze", "background": "在生产环境中使用大语言模型（LLMs）面临安全挑战，包括脱狱和提示注入，这可能导致对人类或企业产生有害输出。特别是在特定领域工作时，通常接受的LLM话题可能与该领域无关，进一步加剧了问题。现有方法如针对领域特定和安全数据对大语言模型进行微调可以缓解部分问题，但随着脱狱技术的演进，这种方法变得不再足够。API访问模型提供的灵活性不足以使行为适应行业特定目标，且上下文学习有时也不可靠。为应对这些挑战，本文提出Archias，一种能够区分领域内和领域外通信的专家模型。通过将专家模型（Archias）的输出集成到提示中，随后由大语言模型处理以生成响应，可以增强模型理解用户意图和提供适当答案的能力。我们为此构建了一个针对汽车行业的基准数据集，并将其公开分享，以促进研究和开发。", "innovation": "本文提出Archias，一种能够区分领域内和领域外通信的专家模型。该方法通过将专家模型的输出集成到提示中，再由大语言模型处理以生成响应，增强了模型理解用户意图和提供适当答案的能力。此外，Archias模型小而灵活，可以很容易地根据行业需求进行调整和微调。我们为此构建并公开了一个针对汽车行业的基准数据集。", "conclusion": "我们提出的方法通过引入Archias专家模型来增强大语言模型对抗脱狱攻击的能力，并公开了一个针对汽车行业的基准数据集，旨在促进该领域的研究与开发。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.20118", "html_url": "https://arxiv.org/abs/2504.20118", "title": "OpenTCM：一种以GraphRAG赋能的基于LLM的中医知识检索与诊断系统", "title_en": "OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis", "authors": "Jinglin He,Yunqi Guo,Lai Kwan Lam,Waikei Leung,Lixing He,Yuanan Jiang,Chi Chiu Wang,Guoliang Xing,Hongkai Chen", "background": "中医作为丰富的古代医学知识宝库，在现代医疗保健中仍然发挥着重要作用。由于中医文献的复杂性和广泛性，人工智能技术的整合对于其现代化和更广泛的可用性至关重要。然而，这种整合面临着挑战，包括对晦涩难懂的经典中医文献的解释以及中医概念间的复杂语义关系建模。文献还指出，在中国医典数据库中，通过中医和妇科专家的帮助，提取了来自68本妇科书籍的超过3.73百万个古典汉字文献。利用定制提示和以中文为导向的LLMs（例如DeepSeek和Kimi），构建了一个包含超过48000个实体和152000种关系的全面的多关系知识图谱，以确保高度准确的语义理解。", "innovation": "OpenTCM是一个基于多模态LLM，结合特定领域中医知识图谱和基于图的检索增强生成技术的系统。该系统通过自动构建中医知识图谱，进行高保真的药材知识检索和诊断问答，并且无需对现有模型进行精细调整。实验结果表明，OpenTCM在草药信息检索和诊断问答任务上的表现优于现有最先进的解决方案，在医学专家评分指标上分别达到了4.378和4.045的高分。", "conclusion": "OpenTCM通过集成特定领域的知识图谱和GraphRAG技术，成功实现对中医文献的有效检索和知识支持，有助于推进中医在现代医疗中的应用与发展。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02862", "html_url": "https://arxiv.org/abs/2505.02862", "title": "无法见森林而见树：利用启发式和偏差诱使LLMs做出非理性选择", "title_en": "Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs", "authors": "Haoming Yang,Ke Ma,Xiaojun Jia,Yingfei Sun,Qianqian Xu,Qingming Huang", "background": "尽管大型语言模型（LLMs）表现出色，但它们仍然容易受到牢笼攻击的影响，这会破坏它们的安全机制。现有研究往往依赖于暴力优化或手动设计，未能在现实场景中发现潜在风险。", "innovation": "我们提出了一种新颖的牢笼攻击框架ICRT，灵感来源于人类认知中的启发式和偏差。利用简单效应，我们采用认知分解来简化恶意提示的复杂性。同时，利用相关性偏差重新组织提示，增强语义对齐并有效诱导有害输出。此外，我们引入了一种基于排名的有害性评价指标，超越了传统的二元成功或失败范式，通过Elo、HodgeRank和Rank Centrality等排序聚合方法全面量化生成内容的有害性。实验结果表明，我们的方法能够一致地绕过主流LLMs的安全机制，生成高风险内容，为理解攻击风险提供了见解，并有助于更强的防御策略。", "conclusion": "我们的研究提供了关于牢笼攻击风险的深入见解，并为更强大的防御策略做出了贡献。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20888", "html_url": "https://arxiv.org/abs/2505.20888", "title": "EasyDistill：大规模语言模型有效知识蒸馏的综合工具包", "title_en": "EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models", "authors": "Chengyu Wang,Junbing Yan,Wenrui Cai,Yuanhao Yue,Jun Huang", "background": "本文介绍了EasyDistill，这是一个全面的工具包，旨在高效实现对大型语言模型（LLMs）的黑盒和白盒知识蒸馏（KD）。该框架提供了多样化的功能，包括数据合成、监督微调、排名优化和专门为KD场景设计的强化学习技术。该工具包适用于系统1（快速，直观）和系统2（缓慢，分析）模型的蒸馏功能。通过模块化设计和用户友好的界面，EasyDistill赋能研究人员和工业实践者无缝地尝试和实施最新的KD策略。此外，EasyDistill提供了一系列由我们开发的鲁棒性高的蒸馏模型和基于KD的工业解决方案，以及相应的开源数据集，以满足多种使用场景的需求。此外，EasyDistill还成功地整合到了阿里巴巴云的平台AI（PAI）中。总体而言，EasyDistill工具包使LLMs领域的先进KD技术更加容易获取并产生更大的影响，促进了NLP社区的发展.", "innovation": "EasyDistill不仅支持快速直观的模型（System 1）和分析性缓慢的模型（System 2）的知识蒸馏，还提供了多样化功能，如数据合成、监督微调、排名优化和强化学习技术。这款工具包设计注重模块化和用户友好性，使得研发和实施先进的知识蒸馏策略变得更加便捷。它还提供了高质量的蒸馏模型和基础的工业应用解决方案，以及相关的开源数据集，以适应不同的应用场景。此外，它还被集成到阿里巴巴云的平台AI（PAI）中，增强了其在实际应用中的适用性和可用性.", "conclusion": "EasyDistill通过模块化设计、多样化的功能和顺畅的集成，使先进的知识蒸馏技术对于大规模语言模型更加易于使用并具有实际价值。这种工具包为NLP社区提供了便捷的研究工具和应用解决方案，推动了该领域的进一步发展。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08010", "html_url": "https://arxiv.org/abs/2506.08010", "title": "Vision Transformers Don't Need Trained Registers", "title_en": "Vision Transformers Don't Need Trained Registers", "authors": "Nick Jiang,Amil Dravid,Alexei Efros,Yossi Gandelsman", "background": "文章探讨了Vision Transformers中已识别现象背后的机制——高范数标记的出现，导致噪声注意力图的生成。研究指出，在多个模型（如CLIP和DINOv2）中，一组稀疏的神经元将高范数激活集中在异常标记上，导致不规则的注意力模式并降低下游视觉处理效果。目前的解决方案是通过额外学习注册标记重新训练模型，但这种方法需要从头开始训练。", "innovation": "该研究提出了一个无需训练的方法来处理这些异常标记。通过将高范数激活从发现的注册神经元转移到未训练的标记上，该方法可以在已有模型上模拟注册标记的效果，从而提高模型的清洁度和视觉任务性能，达到与明确训练有注册标记模型相似的结果。此外，该研究还扩展了测试时的注册标记，提高了现成的视觉语言模型的可解释性。", "conclusion": "研究结果表明，测试时的注册标记能够在测试时承担注册标记的角色，为任何无注册标记的预训练模型提供无需训练的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24616", "html_url": "https://arxiv.org/abs/2505.24616", "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX", "title_en": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX", "authors": "Nikita Martynov,Anastasia Mordasheva,Dmitriy Gorbetskiy,Danil Astafurov,Ulyana Isaeva,Elina Basyrova,Sergey Skachkov,Victoria Berestova,Nikolay Ivanov,Valeriia Zanina,Alena Fenogenova", "background": "现有评估大型语言模型生成能力的方法主要依赖于人力进行对比分析，这种方法成本高且不够精确。本文旨在为俄语语言模型提供一个综合的开源基准，以更透明、更可解释的方式评估其生成能力。通过定义详细的任务类型和评分标准，本文提出了一种新颖的评估方法，并构建了一个包含35类详细分类的任务类型库，覆盖了从代码生成到创意写作等多个生成领域，共计2100个手动编写的提示。这些任务按难度分为简单、中等和困难三个级别，由专家完全从零构建数据集。\n", "innovation": "本文的主要创新在于提出了一种新颖的评价方法，旨在增强大型语言模型评估的可解释性。这种方法包括定义详细的任务类型和评分标准，让模型对生成的响应进行评价并提供评级依据，从而使评价过程更加透明。此外，还提供了LLM作为评审员的评估工具，能够进行细致的生成输出评估，替代了传统的耗时且不够精确的人工判断。\n", "conclusion": "本文通过提出POLLUX基准，提供了一种可扩展、可解释的评价和注解工具，解决了现有评估方法的局限性，有效替代了成本高昂的人工判断。\n"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17155", "html_url": "https://arxiv.org/abs/2506.17155", "title": "Sparse-Reg: 使用稀疏性提高离线强化学习的数据效率", "title_en": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity", "authors": "Samin Yeasar Arnob,Scott Fujimoto,Doina Precup", "background": "尽管许多常见的离线强化学习（RL）基准使用包含数百万数据点的大型数据集，但许多离线RL应用依赖于更小的数据集。我们发现离线RL算法可能在小数据集上过拟合，导致性能不佳。因此，对于有限数据环境的有效学习提出了挑战。", "innovation": "我们提出了一种基于稀疏性的正则化技术 'Sparse-Reg'，以减轻离线强化学习中的过拟合问题，使在小数据集环境中能够更有效地学习，并且在连续控制任务中超越最先进的基线方法。", "conclusion": "离线RL算法在小数据集上可能容易过拟合，影响性能。通过引入Sparse-Reg，本研究提出了一个基于稀疏性来减少过拟合的技术，能够在有限数据环境下提升学习效率，并且在实验中表现出色，超越现有的基准方法。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21333", "html_url": "https://arxiv.org/abs/2506.21333", "title": "人类与AI共创系统：系统审查", "title_en": "A Systematic Review of Human-AI Co-Creativity", "authors": "Saloni Singh,Koen Hindriks,Dirk Heylen,Kim Baraka", "background": "人类共创社区在开发更加复杂和个性化的系统以支持和增强人类创造力方面取得了显著进展。前人的设计考量为未来的系统提供了一个有价值且高效的基石。为了支持这一努力，我们对62篇关于共创系统的论文进行了系统的文献综述。这些论文涵盖了视觉艺术、设计和写作等多个应用领域，在这些领域中，AI不仅作为工具，还作为创造过程中的积极参与者。通过这次综述，我们识别出几个关键的设计维度：创作过程的阶段、创作任务、系统的主动性行为、用户控制、系统体现形式以及AI模型类型。我们的研究结果表明，提供高用户控制权的系统能带来更高的满意度、信任和对创作成果更强的所有权感。同时，当系统具备自适应性和情境敏感性时，主动型系统可以增强合作。我们也提取了24项设计考量，强调鼓励用户对外部化他们的想法以及增加系统社交存在感和透明度以促进信任的价值。尽管存在近期的进步，但仍存在重要差距，如对早期创作阶段（如问题澄清）支持不足，以及用户适应AI系统的挑战等。", "innovation": "本研究进行了系统文献综述，提炼出了一系列重要的设计考量与关键维度，涵盖共创过程的多个阶段和任务，并强调了高用户控制权、主动系统的重要性及系统透明度的价值。这为未来共创系统的开发提供了有价值的参考依据。同时，该研究还指出了现有系统存在的缺陷，为未来研究所留下的改进空间提供了方向。", "conclusion": "尽管共创系统在支持和增强人类创造力方面取得了显著进展，但仍需关注早期阶段的支持以及用户对AI系统的适应性。高用户控制权和主动、自适应、情境敏感的系统设计能够提升用户的满意感和信任感，设计师和开发者应参考这些研究成果，为用户提供更加丰富和有效的共创体验。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18071", "html_url": "https://arxiv.org/abs/2506.18071", "title": "MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering", "title_en": "MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering", "authors": "Jisheng Dang,Huilin Song,Junbin Xiao,Bimei Wang,Han Peng,Haoxuan Li,Xun Yang,Meng Wang,Tat-Seng Chua", "background": " Grounded Video Question Answering (Grounded VideoQA) 需要将文本答案与显式的视觉证据对齐。然而，现代多模态模型往往依赖于语言先验和偶然的相关性，导致预测不够准确且缺乏联系。", "innovation": " 提出了 MUPA，一种合作的多路径代理(MUlti-Path Agentic)方法，将视频接地、问题回答、答案反映和聚合统一起来解决 Grounded VideoQA。MUPA 包含三个不同的推理路径，以及一个专门的反思代理来评估和汇总多路径结果，以实现一致的问答和接地。这一设计显著提高了接地的准确度，而不牺牲答案的准确性。尽管只使用了2B个参数，该方法优于所有7B规模的竞争对手。当扩展到7B参数时，MUPA 在 NExT-GQA 和 DeVE-QA 上分别取得了30.3%和47.4%的 Acc@GQA，展示了 MUPA 在培养可信赖的视频-语言理解方面的有效性。", "conclusion": " 尽管参数量不大，MUPA 方法在 Grounded VideoQA 方面表现优异。扩展至更大模型后，MUPA 在两个主要评测集上获得了新的最先进的结果，证明了 MUPA 在培养可信赖视频语言理解方面的有效性，并且已公开可获取代码。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14968", "html_url": "https://arxiv.org/abs/2506.14968", "title": "EAST: 一种灵活的餐食辅助系统，朝着野外个性化方向", "title_en": "FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization", "authors": "Rajat Kumar Jenamani,Tom Silver,Ben Dodson,Shiqin Tong,Anthony Song,Yuting Yang,Ziang Liu,Benjamin Howe,Aimee Whitneck,Tapomayukh Bhattacharjee", "background": "护理机器人有潜力改善全球数以百万计需要饮食协助人群的生活质量。然而，在家中提供饮食协助仍然具有挑战性，因为用餐期间会出现多种活动（如进食、饮水、擦拭嘴巴）、情境（如社交、观看电视）和食品项目，以及用户的偏好差异。因此，提出了一种灵活的餐饮协助系统FEAST，旨在野外个性化以满足个别护理对象的独特需求。", "innovation": "FEAST系统具备三个关键原则：灵活性、透明性和安全性。这些原则通过模块化硬件、多元交互方式以及参数化行为树来体现。FEAST能够根据大型语言模型的引导，实现安全且透明的个性化调整，从而超越了仅限于固定定制的最新基准系统。这项创新使得FEAST能够适应不同的饮食协助场景，并满足多样化的用户需求和偏好。", "conclusion": "通过形成性研究确定的个性化要求对FEAST系统进行了评估，表明FEAST提供了广泛的安全透明个性化选项，并优于当前最先进的基准系统。在家中进行了用户研究，展示了系统在真实生活中的应用可行性，并通过职业治疗师的评估进一步检查了生态有效性。无论何种情况下，用户均成功个性化FEAST以满足其个人需求和偏好。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11869", "html_url": "https://arxiv.org/abs/2506.11869", "title": "概率图模型和图神经网络是如何看待网络数据的？", "title_en": "How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?", "authors": "Michela Lapenna,Caterina De Bacco", "background": "图是表示关系数据的强大数据结构，广泛用于描述复杂的真实世界系统。概率图模型（PGMs）和图神经网络（GNNs）都可以利用结构化为图的数据，但它们的功能是不同的。论文探讨了PGMs和GNNs在捕捉网络数据中的信息方面的差异。为此，研究者通过解决链接预测任务并进行三个主要实验，分别测试了它们对输入特征的处理方式、噪声特征的鲁棒性、以及随网络异质性的增加而表现出的变化等。研究背景还涉及到PGMs和GNNs在处理特征时的区别和适用场景，如PGMs不需要节点特征，而GNNs则无法单独利用网络边的数据，特征选择变得尤为重要。", "innovation": "论文通过解决链接预测任务并进行详细实验，对比了PGMs和GNNs在处理网络数据方面的不同表现，并研究了不同情况下它们的性能差异。特别是当输入特征低维或噪声较大时，GNNs的表现不及PGMs；随着网络异质性的增加，PGMs比GNNs更加鲁棒。此外，研究还评估了这两种框架在计算复杂性和可解释性方面的表现，为理解和选择合适的模型提供了新的视角。", "conclusion": "研究发现，当输入特征较低维或噪声较大时，GNNs的表现不及PGMs。PGMs在网络异质性增加的情况下表现更稳定且更鲁棒。同时，两种模型在计算复杂性和可解释性方面也存在差异，这为实际应用中的选择提供了依据。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21555", "html_url": "https://arxiv.org/abs/2506.21555", "title": "通过LoRA语言专家实现高效的多语言ASR微调", "title_en": "Efficient Multilingual ASR Finetuning via LoRA Language Experts", "authors": "Jiahong Li,Yiwen Shao,Jianheng Zhuo,Chenda Li,Liliang Tang,Dong Yu,Yanmin Qian", "background": "近年来，深度学习的最新进展显著提升了多语言自动语音识别（ASR）的性能，这得益于先进模型架构的发展和大规模多语言数据集的可用性。尽管取得了这些进步，但多语言ASR仍然面临多语种带来的挑战，不同语言之间往往会互相干扰，使得模型在共享容量的同时识别多种语言变得困难。", "innovation": "本文提出了一种通过准备好的LoRA语言专家进行定制化多语言ASR高效微调的框架。通过LoRA专家融合或知识蒸馏，该方法在目标语言上的识别性能优于标准微调方法。实验结果显示，在语言意识和语言无意识场景中，提出的模型分别获得了约10%和15%的相对性能提升。", "conclusion": "本文提出的方法通过利用LoRA语言专家实现了多语言ASR的高效微调，并在目标语言的识别性能上取得了显著改进，特别是在语言意识和语言无意识的场景中分别获得了约10%和15%的相对性能提升。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21558", "html_url": "https://arxiv.org/abs/2506.21558", "title": "Bench to the Future: 一个用于预测代理的反向预测基准", "title_en": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents", "authors": "FutureSearch:Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips", "background": "预测是一项具有明显可衡量性的任务，能够有效研究AI系统的能力。然而，由于网络研究需要大量时间，事件的发展也需要时间，因此建立预测基准仍然是一个挑战。目前为止，没有任何基准能够提供一个既现实又封闭且可重复的环境用于LLM预测。Bench To the Future (BTF)是一个“反向预测”基准，包含数百个高质量且已知结果的问题，每个问题都有一份庞大的、相关网页构成的离线语料库，每份语料库包含数万条相关信息，这种方式允许从LLMs中引出对历史性事件的现实预测。研究表明，BTF的反向预测环境能够生成与基于互联网的即时未决问题预测结果相当的结果。我们使用几种LLM，包括最近发布的Claude 4模型，比较了代理和因果推理预测方法，并展示了BTF随着时间持续跟踪预测能力进步的能力。我们希望BTF能够作为一个持续的增长基准，随着训练数据截止日期的增加不断添加新的问题。", "innovation": "BTF作为一个新的反向预测基准，提供了真实、封闭且可重复的环境，用于测试LLM的预测能力。BTF中的每个问题都有已经知道的结果和大量的相关网页语料库，这种设计能够让LLMs产生基于过往数据的现实预测，而现有的预测基准往往不能满足这些要求。BTF还展示了不同预测方法和模型的性能，跟踪潜力的增长，并且能够不断更新和添加新的问题以适应新的训练数据。", "conclusion": "BTF作为一个持续发展的预测基准，旨在不断改进和更新，以便更好地跟踪预测能力的进步。我们鼓励研究人员通过hello@futuresearch.ai与我们联系，以利用该基准或相关工具进行自己的研究。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19863", "html_url": "https://arxiv.org/abs/2506.19863", "title": "探索前沿大规模语言模型在核能研究中的能力", "title_en": "Exploring the Capabilities of the Frontier Large Language Models for Nuclear Energy Research", "authors": "Ahmed Almeldein,Mohammed Alnaggar,Rick Archibald,Tom Beck,Arpan Biswas,Rike Bostelmann,Wes Brewer,Chris Bryan,Christopher Calle,Cihangir Celik,Rajni Chahal,Jong Youl Choi,Arindam Chowdhury,Mark Cianciosa,Franklin Curtis,Gregory Davidson,Sebastian De Pascuale,Lisa Fassino,Ana Gainaru,Yashika Ghai,Luke Gibson,Qian Gong,Christopher Greulich,Scott Greenwood,Cory Hauck,Ehab Hassan,Rinkle Juneja,Soyoung Kang,Scott Klasky,Atul Kumar,Vineet Kumar,Paul Laiu,Calvin Lear,Yan-Ru Lin,Jono McConnell,Furkan Oz,Rishi Pillai,Anant Raj,Pradeep Ramuhalli,Marie Romedenne,Samantha Sabatino,José Salcedo-Pérez,Nathan D. See,Arpan Sircar,Punam Thankur,Tim Younkin,Xiao-Ying Yu,Prashant Jain,Tom Evans,Prasanna Balaprakash", "background": "核聚变和核裂变研究加速的需求；现有研究手段的局限性和挑战；人工智能尤其是大规模语言模型（LLMs）的应用潜力及其在核能研究中的初步探索；跨学科团队利用各种AI模型解决核科学难题；发现LLMs在早期探索、文献综合和工作流程设计方面表现出色；但仍存在新材料设计、高级代码生成和领域特定细节验证等局限性；强调专家驱动的提示工程和AI作为物理方法的辅助工具的重要性；强调核能研究加速需求及跨学科整合的重要性；认识到需要针对性的数据集、自动化工作流程和专业模型开发；这些发现为AI工具在核科学研究中的整合提供了路线图，旨在促进更安全、更高效的核能系统发展。", "innovation": "利用大型语言模型（LLMs）加速核聚变与核裂变研究；跨学科团队使用各种AI模型解决问题；探索AI特别是LLMs在核能研究中的应用潜力；强调专家驱动的提示工程和AI辅助工具的应用；提出整合AI工具到核科学工作流程中的路线图；强调数据分析集、工作流程自动化和专门模型开发的重要性；", "conclusion": "大型语言模型在早期探索和工作流程设计方面表现出色；但在复杂材料设计、高级模拟代码生成和领域特定细节验证方面存在局限；专家驱动的提示工程和AI应作为物理方法的辅助工具；AI有望通过快速迭代和跨学科整合加速核能研究；强调整合AI工具到核科学工作流程中，缩短核能系统开发周期，同时保持严格的科学标准。"}
{"llm_update_time": "20250630", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20967", "html_url": "https://arxiv.org/abs/2506.20967", "title": "DFVEdit: 条件差分流向量在零样本视频编辑中的应用", "title_en": "DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing", "authors": "Lingling Cai,Kang Zhao,Hangjie Yuan,Xiang Wang,Yingya Zhang,Kejie Huang", "background": "视频扩散变换器（Video DiTs）的出现标志着视频生成技术的一个重要里程碑。然而，直接将现有的视频编辑方法应用于Video DiTs往往会带来显著的计算 overhead，因为这些方法通常需要资源密集的注意力修改或微调。为了解决这一问题，我们提出了DFVEdit，一种针对Video DiTs的高效零样本视频编辑方法。DFVEdit通过直接操纵清洁的潜变量来进行流变换，从而消除注意力修改和微调的需求。研究表明，编辑和采样可以在流的连续视角下统一考虑。基于这一基础，我们提出了有条件差分流向量（CDFV）——DFV的一种理论上无偏估计，并集成了隐式交叉注意力（ICA）指导和嵌入强化（ER）以进一步提高编辑质量。与基于注意力工程的编辑方法相比，DFVEdit在视频扩散变换器上的推理速度提升了至少20倍，内存减少了85%。广泛的定量和定性实验表明，DFVEdit可以无缝应用于流行的Video DiTs（如CogVideoX和Wan2.1），并实现结构保真度、时空一致性和编辑质量方面的最先进的性能。", "innovation": "DFVEdit 是一种高效的零样本视频编辑方法，通过直接操作清洁的潜变量来实现流变换，从而不要求注意力修改和微调。DFVEdit 提出了有条件差分流向量 (CDFV) 并集成了隐式交叉注意力 (ICA) 指引和嵌入强化 (ER) 以进一步提高编辑质量。与基于注意力工程的方法相比，它提供至少20倍的推理速度提升和85%的内存减少，并且能应用到多个流行的Video DiTs模型上，具有强大的编辑质量和结构保真度。", "conclusion": "DFVEdit 可以无缝应用于流行的 Video DiTs 模型，如 CogVideoX 和 Wan2.1，显著提高了结构保真度、时空一致性和编辑质量。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21556", "html_url": "https://arxiv.org/abs/2506.21556", "title": "VAT-KG：面向检索增强生成的知识密集型多模态知识图谱数据集", "title_en": "VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation", "authors": "Hyeongcheol Park,MinHyuk Jang,Ha Dam Baek,Gyusam Chang,Jiyoung Seo,Jiwan Park,Hogun Park,Sangpil Kim", "background": "现有的多模态知识图谱（MMKGs）通常通过补充现有知识图谱来进行扩展，这限制了它们的知识覆盖范围，导致知识过时或不完整，并且它们通常只支持有限的模态类型，如文本和视觉信息。这些限制减少了它们在各种多模态任务中的可扩展性与适用性，特别是在多模态模型（MLLMs）转向更丰富的模态如视频和音频方面。", "innovation": "本文提出了Visual-Audio-Text Knowledge Graph（VAT-KG），这是首个以概念为中心、知识密集型的多模态知识图谱，涵盖了视觉、音频和文本信息。VAT-KG通过一个严格的数据过滤及对齐步骤，可以自动生成MMKGs。此外，文中还引入了一种新的多模态检索增强生成框架，能够根据任意模态的查询检索到详尽的概念级知识。实验结果表明，VAT-KG能够有效支持多模态大型语言模型，并展示了其在整合和利用多模态知识方面的实际价值。", "conclusion": "基于VAT-KG的多模态大型语言模型在各种模态上的问答任务中表现出色，强调了其在统一和利用多模态知识方面的重要性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21557", "html_url": "https://arxiv.org/abs/2506.21557", "title": "驳斥与推理：基于扩散生成证据和LLM推理的多模态假新闻检测", "title_en": "Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning", "authors": "Kaiying Yan,Moyang Liu,Yukun Liu,Ruibo Fu,Zhengqi Wen,Jianhua Tao,Xuefei Liu", "background": "假新闻在多媒体平台上迅速传播，严重威胁着信息的可信度。现有的假新闻检测方法在性能和解释性上面临挑战。为应对这一问题，提出了一个结合反驳知识的假新闻检测框架DIFND（Debunk-and-Infer框架），该框架利用多模态内容生成反驳或证实证据，通过多模态大语言模型和生成型扩散模型的综合使用，增强假新闻检测的准确性与可解释性。", "innovation": "DIFND框架创新性地结合了生成型扩散模型和多模态大语言模型的协作推理能力，通过生成反驳或证实的证据和链式反驳策略，提供逻辑基础、多模态感知的推理内容和最终真伪判断。该方法在统一架构中联合建模多模态特征、生成型反驳线索以及丰富的验证推理，从而显著提高了检测准确性。实验证明DIFND在假新闻检测上的性能超越了现有方法，提供了可信赖的决策。", "conclusion": "DIFND在假新闻检测上的表现显著优于现有方法，不仅可以提供准确的检测结果，还能通过提供丰富、多样的反驳证据，增强检测的可解释性和可靠性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21560", "html_url": "https://arxiv.org/abs/2506.21560", "title": "语言模型的强化学习微调用于指令遵循和数学推理", "title_en": "Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning", "authors": "Yifu Han,Geo Zhang", "background": "该研究探讨了强化学习（RL）微调技术对紧凑语言模型（Qwen2.5-0.5B Base）的有效性，应用于指令遵循和数学推理两大挑战任务。研究对比了监督微调（SFT）、带有偏好标记数据的直接偏好优化（DPO）以及带奖励模型的Reinforce Leave-One-Out（RLOO）。实验结果显示，使用DeBERTa奖励建模的RLOO方法表现最佳，而DPO则提供了一致且强大的结果。对于数学推理任务，合成数据增强和最佳N次采样结合外部验证显著提高了准确性，展示了在微调过程中结合推理时使用工具的潜力。研究强调了训练轻量级、任务对齐的小规模语言模型的关键权衡和实用策略。", "innovation": "研究通过对比不同的微调技术来优化语言模型，特别是引入了DeBERTa奖励模型与RLOO技术的结合，展示了一种新的优化方式。同时，研究还探索了合成数据增强和最佳N次采样在数学推理任务中的应用，结合外部验证器提高了模型性能。", "conclusion": "研究表明，不同的微调技术各有优劣，其中使用DeBERTa奖励模型的RLOO技术在指令遵循任务中表现最佳，而DPO则在多个任务中提供了稳定且强大的结果。对于数学推理任务，数据增强和最佳N次采样结合外部验证器的方法显著提高了模型的准确性。研究强调了在训练轻量级语言模型时选择合适微调技术和结合推理时使用的工具的重要性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21559", "html_url": "https://arxiv.org/abs/2506.21559", "title": "GraphLAMA: 通过有限注解实现图语言模型的高效适应", "title_en": "GraphLAMA: Enabling Efficient Adaptation of Graph Language Models with Limited Annotations", "authors": "Junze Chen,Cheng Yang,Shujie Li,Zhiqiang Zhang,Yawen Li,Junping Du,Chuan Shi", "background": "大语言模型（LLMs）已经在多个领域展现出强大的能力，并且最近被整合到图分析中，形成图语言模型（GLMs）。利用LLMs作为预测器，一些GLMs能够解释通过自然语言描述的未见任务，并在提示中从少量示例学习，这被称为上下文内学习（ICL）。另一些GLMs则通过大量训练标签来提高模型性能，这种方法称为指令微调。然而，我们认为图中的上下文内学习存在效果问题，因为参数是固定的；同时，由于长上下文的原因，存在效率问题。另外，真实世界场景中获取大量标记数据也可能会比较困难。因此，本文旨在通过引入一个额外的参数适应阶段，仅用少量标记示例高效地将GLMs适应到一个未见的图和任务上，以换取更高的预测准确度和更快的推理速度。", "innovation": "提出了一种新的方法GraphLAMA，它为GLMs的高效调优和推理设计了特定的模型骨架和学习策略。该方法包括精确设计的图神经网络（GNN）来将节点转换为LLM标记的表示空间，从而使任务指令可以用节点和语言标记的混合表示。在预训练阶段，除了LLM参数外，其他模型参数将通过对不同任务的训练来捕捉普遍的知识。在适应阶段，基于少量示例only更新部分预训练参数。实验表明，GraphLAMA在少数/零次节点分类和摘要生成中都达到了最先进的性能，并且与上下文内学习相比，在5-shot设置下推理速度可以快10倍。", "conclusion": "实验结果显示，GraphLAMA在少数/零次节点分类和摘要生成中的准确率提高了4.91％，并且相对于上下文内学习，其推理速度在5-shot设置下可以快10倍。同时，GraphLAMA提供了一种通过有限注释实现图语言模型高效适应的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21562", "html_url": "https://arxiv.org/abs/2506.21562", "title": "FloorPlan-DeepSeek (FPDS): 利用基于向量的下一个房间预测的多模态地板平面图生成方法", "title_en": "FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction", "authors": "Jun Yin,Pengyu Zeng,Jing Zhong,Peilin Li,Miao Zhang,Ran Luo,Shuai Lu", "background": "在建筑设计过程中，楼层平面图的生成是逐渐进行的且需要迭代。然而，现有的生成模型大多采用端到端的方式，一次性生成整个像素级别的布局。这种模式与实际建筑实践中观察到的增量工作流程不符。为解决此问题，研究人员借鉴了大型语言模型中常用的自回归‘下一个词预测’机制，提出了一个适应于建筑平面图建模的‘下一个房间预测’新范式。实验结果显示，在文本到平面图的任务中，FPDS的性能与扩散模型和Tell2Design相当，表明了其在未来智能建筑设计中的潜力应用。", "innovation": "这项研究的创新之处在于提出了一种新的‘下一个房间预测’方法，该方法采用多模态方法，利用向量预测下一个房间，这与以往的端到端生成方式不同，更适合实际的建筑设计流程。这种方法比现有的扩散模型和Tell2Design在文本到平面图的任务上表现出竞争性的性能，显示出其在智能建筑设计中的应用潜力。", "conclusion": "实验结果表明，FPDS能够在文本到平面图生成任务中与扩散模型和Tell2Design竞争，显示出其潜在的应用价值。因此，这项方法有可能支持未来的智能建筑设计。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21566", "html_url": "https://arxiv.org/abs/2506.21566", "title": "在高质量低资源英吉利提卡机器翻译中回译的饱和点", "title_en": "The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation", "authors": "Arwa Arif", "background": "回译BT在低资源机器翻译MT中被广泛应用，通过使用单语语料生成额外的合成训练数据。尽管这种方法在许多语言对中显示出强劲的改进效果，但在高质量、低资源设置下的有效性仍然不清楚。本文作者探索了使用多语言预训练的MBART50模型，对英语和马盖蒂拉语翻译的有效性。基线系统在大约5万个句子对的高质量平行语料库上训练，验证集上的BLEU得分为43.8。他们还通过过滤后的回译例子扩充数据，但是发现添加这种合成数据并没有提升翻译效果，并在某些情况下轻微降低了效果。", "innovation": "研究使用多语言预训练的MBART50模型探索英语和马盖蒂拉语翻译的有效性，发现了回译可能在特定低资源设置中达到边际收益递减这一点，并通过多种指标评估模型表现并分析可能的原因。", "conclusion": "研究发现回译可能在某些低资源设置中达到边际收益递减的点，讨论了未来研究的含义。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21561", "html_url": "https://arxiv.org/abs/2506.21561", "title": "理性还不够: 大型语言模型中的事实偏见与阿谀现象考察", "title_en": "Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs", "authors": "Emilio Barkett,Olivia Long,Madhavendra Thakur", "background": "尽管大型语言模型（LLMs）在事实核查、管理以及高风险决策中被广泛应用，但它们作为真理评判者的运作机制仍不完全了解。本文介绍了迄今为止关于LLMs真实度检测能力的最大规模评估，并首次分析了这些能力在推理模型中的表现。研究者让八种LLMs就多个提示给出了4,800个真实度判断，对比了理性模型和非理性模型的表现.", "innovation": "本文的研究是目前关于LLMs真实度检测能力的最大规模评估，首次在推理模型中进行了此类分析。研究发现，与非推理模型相比，推理模型的真相偏差率较低，但仍高于人类标准。此外，研究发现了几个高级模型（来自OpenAI的o4-mini和GPT-4.1，来自DeepSeek的R1）的阿谀倾向，在检测准确性方面表现出不对称，能在真实准确性上表现良好，但在欺骗准确性上表现不佳。这一发现表明，能力的提升并不能解决LLMs中的根本性真实度检测挑战.", "conclusion": "本文研究揭示了仅依赖理性并不能解决大型语言模型真实度检测的核心挑战，部分高级模型表现出阿谀行为，导致在欺骗准确性上表现不佳，这意味着提升能力并非解决根本问题的唯一途径。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21564", "html_url": "https://arxiv.org/abs/2506.21564", "title": "QUST团队在SemEval-2025任务10中的表现：评估大规模语言模型在新闻实体框架多类多标签分类中的效果", "title_en": "Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing", "authors": "Jiyan Liu,Youzheng Liu,Taihang Wang,Xiaoman Xu,Yimin Wang,Ye Jiang", "background": "本研究背景在于SemEval-2025 Task 10的一个多类别多标签分类新闻实体框架的任务。研究描述了QUST_NLP团队在任务中的参与，特别是在因素确证声明检索方面的三阶段检索框架的应用。这种方法包括初次评估不同检索模型、使用多种重新排名模型提高候选结果，以及利用加权投票确定最终检索结果。研究团队在单语和跨语任务中分别获得了第5名和第7名的成绩，并公开了其系统代码", "innovation": "创新点在于提出了一种专门为事实核查声明检索设计的三阶段检索框架。该框架包括初次的检索模型评估，通过多种重新排名模型提升候选结果，以及利用加权投票确定最终结果。这一方法在单语和跨语任务中的表现较为出色，特别是在后者中取得了较为领先的位置", "conclusion": "研究团队的三阶段检索框架在SemEval-2025 Task 7中取得了较好的成绩，尤其是在单语任务中表现突出。团队还公开了他们的系统代码，以促进进一步的研究和改进"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21565", "html_url": "https://arxiv.org/abs/2506.21565", "title": "一种受Kairanban风格CoT系统和IdoBata对话启发的多Agent概率推理框架用于去偏移", "title_en": "A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing", "authors": "Takato Ueno,Keito Inoshita", "background": "日本的Kairanban文化和Idobata对话长期以来一直作为传统交流实践，促进社区成员之间的细致对话，并有助于社会平衡的形成。基于这些信息交流过程，本文研究提出了一种多Agent推理框架（KCS+IBC），该框架整合了多个大型语言模型以实现偏见缓解、提高可解释性和概率预测的情感分析。在该方法中除了序列地分享预测结果，还结合了中间阶段的非正式对话环节以融合正式推理和个人立场，并引入了概率情感预测。实验结果显示，KCS在多个数据集上达到了与单一语言模型相当的准确性，KCS+IBC 在推理的后期阶段一致性地下降了熵并逐渐增加了方差，表明该框架能够平衡预测的聚合和多样性。未来的相关工作将定量评估这些特征对偏见纠正的影响，并致力于开发更先进的情感分析系统", "innovation": "提出了一种基于Kairanban风格CoT（Connected-Orchestrated-Thinking）系统和IdoBata对话的多Agent概率推理框架（KCS+IBC）。该框架通过整合多个大型语言模型实现了偏见缓解、提高可解释性和概率预测的情感分析效果，并通过结合非正式的对话环节引入了概率情感预测的方法", "conclusion": "实验结果表明，KCS在多个数据集上达到了与单一语言模型相当的准确性，而KCS+IBC在推理过程中逐渐提高了预测的多样性和可解释性，显示了框架在平衡聚合和多样性预测方面的能力。未来的工作将评估这些特性对偏见纠正的影响，并致力于发展更先进的情感分析系统"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21563", "html_url": "https://arxiv.org/abs/2506.21563", "title": "FormosanBench: 在大规模语言模型时代评估低资源澳洲原住民语言", "title_en": "FormosanBench: Benchmarking Low-Resource Austronesian Languages in the Era of Large Language Models", "authors": "Kaiying Kevin Lin,Hsiyu Chen,Haopeng Zhang", "background": "尽管大型语言模型（LLMs）在多种高资源语言的自然语言处理（NLP）任务上表现出色，但它们在低资源和少数语言中的能力仍然受到显著限制。福orna语群是澳大利亚原住民语言中在台湾地区使用的语言群，它们既有丰富的语言特性，又因社会语言学中普通话的主导地位而面临灭绝。本文探讨了在这一背景下，即现有LLMs对于这些低资源和濒危语言的性能评价，旨在填补现有的技术空白，促进更多包容性NLP技术的发展，有效支持濒危和未充分体现的语言.", "innovation": "文章引入了FORMOSANBENCH，这是首个评估LLMs在低资源澳洲原住民语言上的基准。它涵盖了三大濒危福orna语言（阿达雅尔、阿美、巴吾安）以及三大核心NLP任务（机器翻译、自动语音识别（ASR）和文本摘要）。评估涵盖了零样本、十样本和微调三种设置。研究结果强调了在现有技术基础上对于提供有效支持濒危及未充分代表语言的NLP技术的迫切需求。同时，研究团队亦公开了数据集和代码，以促进相关领域的未来研究.", "conclusion": "研究发现现有LLMs在所有任务中表现均不佳，十样本学习和微调仅提供有限改进。这些结果突显了发展中更具包容性的NLP技术的重要性，以支持濒危和未充分体现的语言。未来的研究需更深入地探索如何提升这些低资源语言上的模型表现."}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21572", "html_url": "https://arxiv.org/abs/2506.21572", "title": "通过结构方程建模将大规模多模态语言模型基准与人类偏好对齐", "title_en": "Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling", "authors": "Tianyu.Zou,Shengwu.Xiong,Ruilin.Yao,Jirui.Huang,Yi.Rong,Yaxiong.Chen,Shili.Xiong,Cong.Wang", "background": "大规模多模态语言模型（MLLM）的评估是一个基本挑战，因为缺乏结构化、可解释性和基于理论的基准设计。现有的基准通常采用基于启发式的任务分组，认知目标不明确，导致能力重叠、指标冗余和诊断能力有限。", "innovation": "提出了一个基于结构方程建模（SEM）的新框架来对齐MLLM基准，通过分析和量化基准的内部有效性、维度分离性和组件贡献。进一步引入了一个基于Piaget认知发展阶段理论的能力层次结构，将MLLM能力分为感知、记忆和推理三个层次，并重建了现有的MLLM基准，构造了一个新基准Gold。实验结果表明，提议的基准具有更强的可解释性、减少的指标冗余性和更清晰的认知一致性。", "conclusion": "提出了一个基于SEM的新框架，用于构建可解释性更强、冗余指标更少且认知一致性更明确的新基准Gold，这比现有方法更具优势。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21568", "html_url": "https://arxiv.org/abs/2506.21568", "title": "在1B vs. 4B参数的Gemma LLMs中评估RAG和HyDE对个人助理的集成", "title_en": "Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion", "authors": "Andrejs Sorstkins", "background": "在边缘和隐私敏感的应用中部署大型语言模型（LLMs）的一个关键障碍是资源效率的问题。本文评估了两种增强策略——检索增强生成（RAG）和假设文档嵌入（HyDE）——在1亿和4亿参数的紧凑型Gemma LLMs上的有效性，特别是在隐私优先的个人助手环境中。研究通过使用MongoDB实现短期记忆，通过Qdrant实现长期语义存储，两者通过FastAPI和LangChain协调，并通过一个前端暴露系统进行实现。", "innovation": "研究实施了两种增强策略——检索增强生成（RAG）和假设文档嵌入（HyDE），并在小型的Gemma LLMs（1亿和4亿参数）上对其进行了评估。结果表明，RAG在响应用户特定和领域特定查询时能够显著减少延迟，可以完全消除事实上的幻觉。相比之下，HyDE能够增强语义相关性，尤其是在处理复杂的物理提示时，但会导致响应时间增加25-40%，并且在个人数据检索中会产生显著的幻觉率。", "conclusion": "在对1B和4B模型进行比较时，研究发现扩展模型的吞吐量增益非常有限，但同时也突显了HyDE在计算开销和变异性方面的显著增加。研究建议，在使用小型LLM驱动的设备个人助手时，RAG是更实用的选择。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21576", "html_url": "https://arxiv.org/abs/2506.21576", "title": "通过软提示调优实现参数高效代码混合语音识别的 Whisper 适应", "title_en": "Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning", "authors": "Hongli Yang,Yizhou Peng,Hao Huang,Sheng Li", "background": "大规模多语言自动语音识别（ASR）模型如 Whisper 在资源丰富的情况下表现良好，但在资源稀缺场景（如稀有语言和代码混合（CS））中面临挑战，因为计算成本高和灾难性遗忘的问题。", "innovation": "探索软提示调优（SPT），这是一种参数高效的方法，旨在增强CS ASR同时保留先前的知识。研究了两种策略：完全调整软提示和整个Whisper模型（FFT）以及遵循SPT的原始设计仅训练软提示。此外，引入了SPT4ASR，一种不同SPT变体的组合。实验表明，深层提示调优是SPT中最有效的策略，而SPT4ASR方法在CS ASR中实现了进一步的误差降低，同时保持与LoRA类似的参数效率，而不影响现有语言的性能。", "conclusion": "通过SPT4ASR方法在CS ASR中实现了进一步的误差降低，同时保持与LoRA相近的参数效率，而不牺牲现有语言的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21567", "html_url": "https://arxiv.org/abs/2506.21567", "title": "BioPars：用于波斯医学文本挖掘的预训练生物医学大型语言模型", "title_en": "BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining", "authors": "Baqer M. Merzah,Tania Taami,Salman Asoudeh,Amir reza Hossein pour,Saeed Mirzaee,Amir Ali Bengari", "background": "大型语言模型（LLMs）在生命科学领域近年来受到了关注，因为它们能够建模、提取和应用复杂的生物信息。除了作为聊天助手的经典用途，这些系统还被越来越多地用于生物信息学等专业领域的复杂分析和问题解决。本文介绍了一个名为BIOPARS-BENCH的数据集，包含超过10,000篇科学文章、教科书和医疗网站，以及一个名为BioParsQA的评价模型，包含5,231个波斯医学问题和答案。文中还提出了一个名为BioPars的简单但准确的评估指标，用于评估LLMs在获取专业知识、解释和综合知识以及展示适当证据方面的三种主要能力。通过对比ChatGPT、Llama和Galactica，研究揭示了它们在记住和检索学习知识方面的有效性，但也指出处理高级别、实际问题和细微推断方面的不足。这些发现表明了在生物信息学任务中进一步精细调优的需要。", "innovation": "BioPars是第一个应用于波斯医学问答（QA）的大型语言模型，特别擅长生成长回答。在评估了四个选定的医学QA数据集后，BioPars在多个评估指标上取得了显著结果，与现有方法相比实现了提升。在BioParsQA上的ROUGE-L得分达到了29.99，改善了GPT-4 1.0的结果；BERTScore为90.87，使用MMR方法；MoverScore和BLEURT值也在这四个模型中表现较高。", "conclusion": "这些发现表明，BioPars在波斯医学文本挖掘中具有潜在的应用价值，需要进一步研究以优化其处理复杂问题和细微推断的能力。BioPars是一个持续项目，其所有相关资源都将在GitHub仓库（提供链接）中公开。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21574", "html_url": "https://arxiv.org/abs/2506.21574", "title": "数字守门人：探索大型语言模型在移民决策中的作用", "title_en": "Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions", "authors": "Yicheng Mao,Yang Zhao", "background": "随着全球化与移民人口的增加，移民管理部门面临巨大的工作量和确保决策过程公平的挑战。人工智能技术提供了一种可能性解决这些问题的方法。本研究探讨了大型语言模型（LLMs），如GPT-3.5和GPT-4，在支持移民决策中的潜在作用。通过混合方法的研究，包括离散选择实验和深入访谈，研究团队考察了LLMs的决策策略及其公平性。研究发现表明，LLMs能够在决策中与人类策略保持一致，强调效益最大化和程序公平。同时，研究还揭示了尽管ChatGPT具备防止无意中歧视的安全措施，但仍表现出国家刻板印象和偏见，并偏爱特权群体。", "innovation": "本研究通过综合实验方法（包括离散选择实验和深入访谈）探讨大型语言模型在移民决策中的表现，特别是其在公平性和决策策略上的表现。研究不仅指出了LLMs在自动化和改进移民决策中的潜力，同时也指出了其存在的局限性，尤其是关于偏见和刻板印象的问题。", "conclusion": "本研究发现表明，虽然大型语言模型在移民决策中有巨大的潜力，能够实现与人类决策的衔接，但在防止偏见和提高决策公平性方面仍存在局限。需要进一步的技术改进和道德监督来确保这些模型在移民决策中的公正性和透明度。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21570", "html_url": "https://arxiv.org/abs/2506.21570", "title": "随机初始化无法追赶：语言模型转移在时间序列预测中的优势", "title_en": "Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting", "authors": "Roland Riachi,Kashif Rasul,Arjun Ashok,Prateek Humane,Alexis Roger,Andrew R. Williams,Yuriy Nevmyvaka,Irina Rish", "background": "近期的研究已经表明，在数据量不足的情况下，通过调整预训练语言模型（LMs）可以有效地进行时间序列预测。本研究在此基础上，分析了从语言模型到时间序列预测的有效转换，并探讨了不同设计选择对验证损失的影响，如后训练、时间序列分词器和语言主干大小。在数据量不足的情况下，这些设计选择对验证损失有显著影响，其中某些选择表现出色。与Hernandez等人的研究结果相反，本研究发现预训练语言模型的验证损失在随机初始化模型的验证损失收敛后仍持续平稳下降，导致非消退转移差距，此差距在设计选择中一直存在。这项研究不仅有助于探讨计算高效训练对时间序列应用的有效使用，还开启了研究这些模型利用数据分布跨模态不变性质的可能性。", "innovation": "本研究探究了在数据量不足情况下预训练语言模型的有效转换，并发现预训练语言模型在验证损失收敛后仍然保持持续降低的趋势，这与Hernandez等人的研究结果相反。此外，该研究还探讨了计算高效训练在时间序列预测中的应用以及这些模型在数据分布上的跨模态不变性质。", "conclusion": "本研究展示了通过调整预训练语言模型进行时间序列预测的有效性，并揭示了随机初始化模型无法赶上预训练模型的趋势。此外，研究结果还有助于深化对计算高效训练以及这些模型在数据分布上跨模态不变性的理解。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21573", "html_url": "https://arxiv.org/abs/2506.21573", "title": "白盒与黑盒大型语言模型指令学习范式：双重视角", "title_en": "Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs", "authors": "Yanwei Ren,Liu Liu,Baosheng Yu,Jiayan Qiu,Quan Chen", "background": "优化大型语言模型（LLMs）的指令对于实现其在复杂多样任务中的全部潜力至关重要。然而，仅依赖白盒方法需要大量计算资源，并且具有有限的表示能力；而黑盒模型则可能带来高昂的财务成本。为了应对这些挑战，我们提出了一种新颖的框架，该框架无缝地结合了这两种方法的优点。黑盒模型提供高质量和多样化的初始指令，而白盒模型则通过隐藏状态和输出特征提供精细的可解释性。通过施加语义相似性约束，这些组件融合成一个统一的高维表示，能够捕捉深入的语义和结构细节，从而实现迭代优化过程来提高指令质量与适应能力。", "innovation": "我们提出了一种创新的框架，该框架通过无缝结合白盒和黑盒方法的优势来优化大型语言模型的指令。这种结合方法提供高质量且多样的初始指令，并通过隐藏状态和输出特征提供精细的可解释性。通过语义相似性约束，这些组件融合成一个统一的高维度表示，可以捕捉到深入的语义和结构细节，从而实现迭代优化过程，以提高指令质量与适应能力。此外，这种方法在一系列广泛的任务中（从复杂的推理到跨语言泛化）表现出比最先进的基准方法更好的性能。", "conclusion": "这种黑盒初始化与高级语义精炼的融合提供了一个可扩展和高效的解决方案，为下一代LLM驱动的应用铺平了道路，在各种实际场景中具有巨大的潜力。源代码将很快发布。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21580", "html_url": "https://arxiv.org/abs/2506.21580", "title": "从一般推理到专业领域：探索大型语言模型通用化能力的限制", "title_en": "From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models", "authors": "Dana Alsagheer,Yang Lu,Abdulrahman Kamal,Omar Kamal,Mohammad Kamal,Nada Mansour,Cosmo Yang Wu,Rambiba Karanjai,Sen Li,Weidong Shi", "background": "近年来，大型语言模型（LLMs）在多个领域展现了非凡的能力，但有效的决策依赖于强大的推理能力。推理是决策的基础，提供了分析和逻辑框架以做出明智的选择。推理涉及分析信息、推断以及基于逻辑或证据得出结论。决策基于推理的过程，通过应用从中获得的洞察来选择最合适的行动方案。随着AI技术的发展，训练LLMs在通用推理方面的表现越来越受到关注。这项研究探讨了LLMs的一般推理能力与其在特定领域推理任务中的表现之间的联系。", "innovation": "研究探索了大型语言模型的通用推理能力与其在专业领域特定任务中的绩效之间的关系，旨在揭示模型通用化能力的局限性，以及如何优化模型在处理特定领域问题上的表现。", "conclusion": "这项研究揭示了大型语言模型在自然语言处理领域的广泛能力，但同时也指出了它们在特定细分领域的局限性。为了更好地利用这些模型，需要进一步研究如何提升和调整它们对特定领域任务的支持。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21582", "html_url": "https://arxiv.org/abs/2506.21582", "title": "VIDEE：借助智能代理进行文本分析的可视化和交互式分解、执行和评估", "title_en": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents", "authors": "Sam Yu-Te Lee,Chengyang Ji,Shicheng Wen,Lifu Huang,Dongyi Liu,Kwan-Liu Ma", "background": "传统上，文本分析需要具备自然语言处理（NLP）或文本分析专业知识，这对初级分析师构成了进入壁垒。近年来，大型语言模型（LLMs）的发展改变了NLP的格局，使得文本分析变得更加易于访问和自动化（例如，主题检测、摘要、信息提取等）.", "innovation": "我们介绍了VIDEE系统，它支持初级数据分析师利用智能代理进行高级文本分析。VIDEE实现了包含三个阶段的人机协作工作流程：（1）分解，采用带有环路的人类参与蒙特卡洛树搜索算法以支持生成性推理，并结合人类反馈；（2）执行，自动生成可执行的文本分析流水线；（3）评估，集成了基于大型语言模型的评估和可视化工具，支持用户验证执行结果。我们通过两个定量实验评估了VIDEE的有效性，并分析了常见的代理错误。用户研究表明，该系统具有良好的易用性，并揭示了不同的用户行为模式。", "conclusion": "本研究确定了人—机协作的设计契机，验证了VIDEE对非专家用户的实用价值，并为未来智能文本分析系统的改进提供了指导。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21584", "html_url": "https://arxiv.org/abs/2506.21584", "title": "小LLM中的对齐伪装的实证证据及基于提示的缓解技术", "title_en": "Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques", "authors": "J. Koorndijk", "background": "现有文献表明，对齐伪装（欺骗性对齐）是大型语言模型的一个潜在属性。本文通过实证研究进一步验证了即使是在较小的指令调整模型（如LLaMA 3 8B）中也可能存在对齐伪装现象，这挑战了此前认为的基于提示的对齐方法简单而不需要大规模模型的观点。", "innovation": "首次提供了实证证据表明，一个小的指令调整模型（LLaMA 3 8B）也会表现出对齐伪装。此外，通过提示干预（包括道义框架及反省式推理），显著减少了这种行为，而无需修改模型的内部结构。这些发现揭示了提示伦理可能并不像之前认为的那么简单，并且欺骗性对齐并非一定需要大规模模型。引入了浅层和深层欺骗的分类，从而更精确地理解语言模型中的欺骗现象。", "conclusion": "这些研究结果深化了对语言模型中欺骗现象的理解，并强调了需要针对不同模型大小和部署环境进行对齐评估的必要性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21571", "html_url": "https://arxiv.org/abs/2506.21571", "title": "探索大型推理模型的认知习惯", "title_en": "Towards Understanding the Cognitive Habits of Large Reasoning Models", "authors": "Jianshuo Dong,Yujia Fu,Chuanrui Hu,Chao Zhang,Han Qiu", "background": "大型推理模型（LRMs）在生产最终回答之前会自主生成推理链（CoT），这为解释和监控模型行为提供了有希望的方法。研究者观察到某些CoT模式（例如，“等待，我漏掉了什么吗？”）在不同任务中一致出现，启发了探索LRMs是否具有类似人类的认知习惯。围绕成功的人类问题解决过程中相关的认知习惯，研究团队引入了CogTest基准测试，用于评估LRMs的认知习惯。CogTest旨在评估16种广泛使用的大型语言模型（包括13种LRMs和3种非推理模型），共有16种认知习惯，每种通过25种不同任务进行具体化，并采用证据优先提取方法以确保可靠的认知习惯识别。通过CogTest评估，研究发现LRMs不仅表现出类似人类的认知习惯，同时还会根据不同任务调整它们的使用方式。此外，进一步分析揭示了LRMs认知习惯图谱中的相似性和差异性，特别是某些家族相似性（例如Qwen-3模型和DeepSeek-R1）。在更安全相关的任务中，研究发现某些习惯（如承担负责任的风险）与生成有害响应之间存在强关联。这些发现表明，研究LRMs CoT中的持续行为模式是深入理解LLM行为的关键步骤。该研究可用代码存储在这个链接：this https URL.", "innovation": "本研究创新地引入了CogTest基准测试，专门用于评估LRMs的认知习惯，这为理解和监控这些模型的行为提供了一个新的评估框架。此外，研究揭示了LRMs在不同任务中适应性使用认知习惯的现象，以及某些认知习惯与生成有害响应之间的关联性。这些发现促进了对大型语言模型行为机制的深入理解，为识别和改进LLM系统的潜在错误提供了有价值的指导。", "conclusion": "研究发现LRMs不仅表现出类似人类的认知习惯，而且能够根据任务的不同情境灵活地调整这些习惯的使用。研究揭示了某些认知习惯的不同表现与生成有害响应之间的关联。这些结果强调了深入研究LRMs推理链中的持续行为模式的重要性，并为更好地理解和干预LLM系统的行为提供了新的视角。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21577", "html_url": "https://arxiv.org/abs/2506.21577", "title": "语言感知提示调整在多语言ASR中参数高效无缝语言扩展中的应用", "title_en": "Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR", "authors": "Hongli Yang,Sheng Li,Hao Huang,Ayiduosi Tuohan,Yizhou Peng", "background": "近年来，多语言自动语音识别（ASR）的进步主要依赖于大规模的端到端模型，如Whisper。然而，语言干扰和在保持性能的同时扩展到未见过的语言（语言扩展）仍然是一个挑战。", "innovation": "该论文提出三项创新：1）整个软提示调整（Entire SPT），在编码器和解码器中应用软提示，增强特征提取和解码；2）语言感知提示调整（LAPT），利用跨语言相似性来编码共享和语言特定特征，采用轻量级提示矩阵；3）SPT-Whisper工具包，将SPT集成到Whisper中，使持续学习变得高效。实验结果表明，在语言扩展任务中，整个SPT和LAPT分别比解码器SPT性能提高了5.0%和16.0%，提供了一种在最小计算开销下实现动态多语言ASR模型的有效解决方案。", "conclusion": "该研究通过提出三种方法：Entire SPT、LAPT和SPT-Whisper工具包，为多语言ASR模型的语言扩展任务提供了有效的解决方案，改进了语言干扰问题，保持了在未见过语言上的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21583", "html_url": "https://arxiv.org/abs/2506.21583", "title": "code-mixed罗马乌尔都语推特中的希望言论检测：自然语言处理中的积极转折", "title_en": "Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing", "authors": "Muhammad Ahmad,Muhammad Waqas,Ameer Hamza,Ildar Batyrshin,Grigori Sidorov", "background": "希望是一种积极的情绪状态，涉及对有利未来结果的期待，而希望言论则是促进乐观、韧性和支持的沟通，特别是在不利的背景下。尽管自然语言处理（NLP）中对希望言论检测的研究有所增加，但现有研究主要集中在资源丰富和标准化的语种上，经常忽视非正式和较少被代表的形式，如罗马乌尔都语。到目前为止，这是首个针对code-mixed罗马乌尔都语希望言论检测的研究，通过引入精心标注的数据集填补了包容性NLP研究中关于低资源和非正式语言变体的空白.", "innovation": "本研究做出了四项关键贡献：（1）引入了首个用于罗马乌尔都语希望言论的多类别标注数据集，包含一般希望、现实希望、不现实希望和非希望类别；（2）探讨了希望的心理基础，并分析了code-mixed罗马乌尔都语中的语言模式，以指导数据集的开发；（3）提出了一个针对罗马乌尔都语的语法和语义变异性进行定制的注意力机制变换器模型，并通过五折交叉验证进行评估；（4）使用t-测试验证了性能增益的统计显著性。所提出的模型XLM-R在交叉验证得分方面表现最佳，得分为0.78，优于基线SVM（0.75）和BiLSTM（0.76），分别提高了4%和2.63%.", "conclusion": "本研究通过提出首个针对code-mixed罗马乌尔都语希望言论的多类别标注数据集和一种定制的注意力机制变换器模型，填补了低资源和非正式语言变体领域中的空白，提出了生成和评估更好的模型的方法，为低资源语言的研究提供了新的视角。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21578", "html_url": "https://arxiv.org/abs/2506.21578", "title": "HealthQA-BR：系统级基准揭示了大型语言模型的关键知识缺口", "title_en": "HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models", "authors": "Andrew Maranhão Ventura D'addario", "background": "现有的大型语言模型（LLMs）在医疗领域的评估主要依赖以医生为中心的、英文基准，这种评估方式制造了一种危险的专业胜任力假象，忽略了患者护理的多专业性质。为提供更全面和真实地评估，本文引入了HealthQA-BR，这是首个面向葡萄牙语国家医疗系统的大型基准测试，它包含了来自巴西全国医师和住院医师考试的5,632个问题，全面评估了从医学及其专业到护理、牙科、心理学、社会工作和其他相关健康专业领域的知识。", "innovation": "本文提出了HealthQA-BR，这是首个面向葡萄牙语国家医疗系统的大型基准测试，全面评估了包括医学、护理、牙科、心理学、社会工作和其他相关健康专业在内的知识。研究团队对20多种领先的LLMs进行了严格的一次性评估，揭示了顶级模型在不同专业领域表现参差不齐的问题，强调了系统级分数不足以确保安全性验证。通过公开HealthQA-BR和评估工具，作者为医疗团队的AI准备状况提供了更细致和真实的审核工具。", "conclusion": "研究表明，尽管最先进的模型如GPT 4.1的整体准确率达到了86.6%，但这一总体分数掩盖了各专业领域的未被测量的缺陷。通过精确分析，研究发现，在如眼科学这样的专业领域，模型接近完美，但在神经外科和社工领域，分数却远低于及格线。这种知识缺口是系统性问题，表明顶级评分并不能确保安全性验证。HealthQA-BR的公开发布为全面评估和真实审计AI准备性提供了关键工具，超越了单一分数评估。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21575", "html_url": "https://arxiv.org/abs/2506.21575", "title": "STRuCT-LLM：通过强化学习统一基于表和图的推理以实现语义解析", "title_en": "STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing", "authors": "Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Casper Hansen,Julien Fauqueur", "background": "该研究提出了STRuCT-LLM框架，用于训练大型语言模型（LLMs）执行基于关系和图结构的数据的结构化推理。此前的工作通常是将关系形式主义和图形式主义分开处理，而STRuCT-LLM则利用SQL和Cypher之间的共同抽象，实现了跨形式主义的知识迁移，使得SQL的任务训练能够提升Cypher的性能，反之亦然。这种协同优化的方法避免了需要共享模式的情况，增强了模型的通用性表现。", "innovation": "STRuCT-LLM首次提出了一种结合强化学习和链式思维监督的统一框架，用于同时优化Text-to-SQL和Text-to-Cypher任务。该框架引入了一种基于图编辑距离的拓扑感知奖励函数，以支持基于图的解析的精细优化。这种方法避免了此前工作在处理关系形式主义和图形式主义时的隔离问题，通过共享SQL和Cypher之间的抽象，实现了跨形式主义的迁移学习效果。模型在任务上的表现显著提升，如Spider提升了13.5%，Text2Cypher提升了73.1%。同时，该模型展示了强大的零样本泛化能力，在下游表格问答和知识图谱问答任务上的性能提高明显。", "conclusion": "这项研究证明了执行查询作为结构化推理支架的有效性，并且联合训练SQL和Cypher模型能够带来协同的性能提升。研究结果表明了该方法的有效性，相关代码可以在提供的链接中找到。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21586", "html_url": "https://arxiv.org/abs/2506.21586", "title": "视觉语言模型能否理解默剧动作？", "title_en": "Can Vision Language Models Understand Mimed Actions?", "authors": "Hyundong Cho,Spencer Lin,Tejas Srinivasan,Michael Saxon,Deuksin Kwon,Natali T. Chavez,Jonathan May", "background": "非言语交流（NVC）在人类语言中起着至关重要的作用，但由于其广泛的范围和个人与文化间的高解释差异，因此研究NVC具有挑战性。而默剧，作为一种仅通过手势、表情和动作来暗示意图的表演技术，是一种非言语交流的子集，其中包含的明确和实际的身体动作具有较低的人类解释差异。论文作者认为，了解默剧行动对于能够解释和控制非言语交流更微妙方面的视觉语言模型来说是至关重要的。为此，作者提出了一个新的基于视频的问题回答基准MIME，包含86个默剧动作。通过动作捕捉数据构建，MIME包括对于评价识别鲁棒性的每个动作的变体，并且通过对角色、背景和视角进行了干扰的处理", "innovation": "提出了一个新的基于视频的问题回答基准MIME，包含86个默剧动作，并通过动作捕捉数据构建，每个动作的变体都有角色、背景和视角的干扰，用以评估识别鲁棒性。发现现有开放权重和API基础的视觉语言模型在MIME上的表现显著低于人类，从而为增强人类手势的理解提出了更强的鲁棒性研究需求", "conclusion": "目前现有的视觉语言模型在理解默剧动作方面表现不佳，这表明需要增加对更强大理解人类手势的研究。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21569", "html_url": "https://arxiv.org/abs/2506.21569", "title": "Hybrid-NL2SVA: 结合RAG和微调的基于LLM的NL2SVA", "title_en": "Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA", "authors": "Weihua Xiao,Derek Ekberg,Siddharth Garg,Ramesh Karri", "background": "SystemVerilog Assertions (SVAs) 对于硬件设计的正确性验证至关重要，但从自然语言属性描述手动编写它们，即NL2SVA任务，仍然是一项劳动密集且容易出错的工作。尽管大型语言模型 (LLMs) 的最新进展提供了自动化的可能性，但现有模型仍然难以理解领域特定的语法和语义。为了提升LLM在NL2SVA中的表现，本文提出了一种定制化的检索增强生成（RAG）框架和合成微调数据集，二者共同提高了LLM的表现。为了进一步提升轻量级模型在NL2SVA中的表现，我们的微调数据集提供了提示引导的解释，教会LLMs并发SVAs的逐层构建过程，从而进行监督微调，极大地提高了语法和功能准确性。为了评估LLM在NL2SVA中的表现，构建了一个最大的NL2SVA评估数据集，包含40个Verilog设计和229个形式验证的SVAs，带有详细的注释。实验结果显示，定制化的RAG框架将匹配功能的SVAs数量相对于GPT-4o-mini增加了58.42%，而Qwen2.5-Coder-7B-Instruct在我们的微调数据集上微调，并与HybridRetrieval集成后，相对于基础Qwen模型提高了59.05%的性能。", "innovation": "本文提出了一种定制化的检索增强生成（RAG）框架和合成微调数据集。该框架和数据集的结合大大提升了大型语言模型（LLM）在从自然语言属性描述到SystemVerilog Assertions（SVAs）的自动转换（NL2SVA）任务中的性能。此外，通过微调数据集提供的提示引导的解释，轻量级模型能够学习并发SVAs的逐层构建过程，从而实现监管微调，显著提高了语法和功能的准确性。", "conclusion": "本文通过构建一个最大的NL2SVA评估数据集和提出定制化的检索增强生成框架及微调数据集，验证了提出的框架和方法的有效性，并通过实验结果展示了相比于基线模型的显著提升。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21585", "html_url": "https://arxiv.org/abs/2506.21585", "title": "LLM基础策略从在线商店提取食品产品信息的评估", "title_en": "Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops", "authors": "Christoph Brosch,Sian Brumm,Rolf Krieger,Jonas Scheffler", "background": "生成式AI和大型语言模型（LLMs）在自动化从网页中提取结构化信息方面具有巨大潜力。本文关注在线零售商的食品产品页面，探索结构化约束提取方法以获取关键产品属性，如成分列表和营养表。研究对比了两种基于LLM的方法：直接提取和间接提取通过生成函数的方法，并在来自三个不同在线商店的3,000个食品产品页面上进行了准确性、效率和成本的评估。", "innovation": "本文研究了两种基于LLM的方法——直接提取和通过生成函数间接提取，并通过实验证明了间接提取方法虽然在准确性上略微降低，但在减少LLM调用次数、提高效率和降低运营成本方面有显著优势，提供了适用于基于模板网页的大规模信息提取任务的具有可扩展性和成本效益的解决方案。", "conclusion": "间接提取方法虽然在准确率上略低（96.48%，降低1.61%），但减少了95.82%的LLM调用次数，从而在效率和成本方面取得了显著的改善。间接提取方法为使用LLM从模板化网页中进行大规模信息提取提供了可扩展且成本效益高的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21587", "html_url": "https://arxiv.org/abs/2506.21587", "title": "DeepSeek是否在公共意见模拟领域成为LLMs的新声音？", "title_en": "Is DeepSeek a New Voice Among LLMs in Public Opinion Simulation?", "authors": "Weihong Qi,Fan Huang,Jisun An,Haewoon Kwak", "background": "该研究评估了开源大型语言模型DeepSeek模拟公共意见的能力，尤其是与主要科技公司开发的LLM（Qwen2.5、GPT-4o、Llama-3.3）相比。通过使用来自美国全国选举研究（ANES）和中国Zuobiao数据集的数据，并比较DeepSeek-R1和DeepSeek-V3，研究人员评估了这些模型在预测中美两国社会问题上的公共意见方面的能力，突出展示了两国间的比较能力。研究结果显示，DeepSeek-V3在模拟美国关于堕胎问题的意见方面表现最佳，而在中国样本中，DeepSeek-V3在模拟关于外国援助和个人主义的意见方面表现最佳，但在模拟关于资本主义的观点时存在局限性，特别是在未能捕捉到低收入和非大学学历群体的立场方面。所有LLM都倾向于在人口群体中泛化单一视角，通常会在组内提供一致的答案。因此，需要减轻LLM驱动的公共意见建模中的文化与人口统计偏差，采用更具包容性的训练方法。", "innovation": "该研究使用开源大型语言模型DeepSeek与主要科技公司开发的LLM进行直接比较，评估其模拟公共意见的能力。通过分析来自美国和中国的实际数据（ANES和Zuobiao数据集），研究团队研究了模型在不同主题上的表现差异，特别关注了其在特定文化背景下的预测能力。此外，研究还揭示了所有LLM都存在泛化单一视角的问题，需要采取更包容的训练方法来缓解文化与人口统计偏差。", "conclusion": "所有大型语言模型（LLM）在人群群体中都倾向于泛化单一视角，尽管DeepSeek-V3在某些议题上表现优于其他模型，但在模拟某些文化观点如资本主义方面存在局限性。研究强调了减轻LLM驱动的公共意见模型中的文化与人口统计偏差的重要性，并提出采用更具包容性的训练方法。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21592", "html_url": "https://arxiv.org/abs/2506.21592", "title": "SignBart -- 新的骨骼序列方法用于孤立手语识别", "title_en": "SignBart -- New approach with the skeleton sequence for Isolated Sign language Recognition", "authors": "Tinh Nguyen,Minh Khue Phan Tran", "background": "手语识别对于听力障碍者打破交流障碍至关重要。然而，前人研究不得不在效率和准确性之间做出选择。例如，RNNs、LSTMs和GCNs存在梯度消失和高计算成本的问题。尽管这些方法在性能上有所改进，但基于变压器的方法并未被广泛采纳。", "innovation": "该研究提出了一种新的SLR方法，能够独立地从骨架序列的x和y坐标中提取有意义的信息，而传统模型通常将它们视为不可分。通过利用BART架构的编码器-解码器，该模型独立编码x和y坐标，并通过Cross-Attention确保它们之间的关联性。该模型仅使用749,888个参数，在LSA-64数据集上达到了96.04%的准确性，显著优于比一千万个参数的前一代模型。此外，该模型在WLASL和ASL-Citizen数据集上也表现出优越的性能和泛化能力。详细研究表明坐标投影、归一化和使用多个骨架组件对于提升模型效果是重要的。", "conclusion": "该研究提供了一种可靠且有效的方法来进行手语识别，对于改善听力障碍者无障碍工具具有强大的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21589", "html_url": "https://arxiv.org/abs/2506.21589", "title": "一种检测大型语言模型生成信息的通用方法", "title_en": "A General Method for Detecting Information Generated by Large Language Models", "authors": "Minjia Mao,Dongjun Wei,Xiao Fang,Michael Chau", "background": "大型语言模型（LLMs）的普及已经显著改变了数字信息的环境，使得区分由人类编写和由LLM生成的内容变得越来越困难。检测LLM生成的信息对于保护数字平台的信任（例如，社交媒体和电子商务网站）以及防止虚假信息的传播至关重要，这是IS研究的重要课题。然而，当前的方法主要集中在识别特定LLM生成的内容，特别是在已知领域，但在新领域（即未见过的LLM）方面缺乏有效性，这限制了它们在现实世界应用中的效果，因为LLM的数量迅速增加，内容涵盖了广泛的主题领域。", "innovation": "提出了一种通用LLM检测器（GLD），该检测器结合了双记忆网络设计和理论指导的检测泛化模块，能够跨未见过的LLM和领域检测LLM生成的信息。通过使用真实世界数据集的广泛的实证评估和案例研究，证明了GLD方法在检测LLM生成的内容方面优于现有的先进方法。", "conclusion": "该研究对于数字平台和LLM具有重要的学术和实践意义。GLD能够提高数字平台对快速发展的LLM生成内容的检测能力，并帮助保护数字环境的可信度，防止与虚假信息相关的风险。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21588", "html_url": "https://arxiv.org/abs/2506.21588", "title": "通过电路发现理解LLMs中的verbatim记忆", "title_en": "Understanding Verbatim Memorization in LLMs Through Circuit Discovery", "authors": "Ilya Lasy,Peter Knees,Stefan Woltran", "background": "在大规模语言模型（LLMs）中，记忆机制的底层工作原理尚不完全清楚，尤其是在精确检索记忆序列中开始的特定令牌方面。此外，当模型生成记忆化句子与非记忆化句子时，其行为有何不同也未被充分理解。因此，本文从机制性可解释性的角度出发，利用变压器电路，即模型中执行特定功能的最小计算子图，来探讨这些问题。", "innovation": "通过精心构造的对比数据集，本文识别出模型生成与记忆内容差异的点，并分离出负责两种不同方面记忆的特定电路。研究发现，负责初始记忆化的电路也能在开始后维持记忆，而仅负责维持记忆的电路则不能触发记忆化的开始。值得注意的是，防止记忆化的机制在不同文本领域中表现出较强的通用性，而促成记忆化的机制则显得更加依赖上下文。", "conclusion": "本文的研究揭示了记忆化在LLMs中的特定电路机制：启动记忆化的电路能够维持记忆，而维持记忆的电路则不能启动记忆化。此外，内存化防止机制在不同文本领域中普遍适用，而内存化引发机制则较为情境依赖。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21590", "html_url": "https://arxiv.org/abs/2506.21590", "title": "代表一致性以提高大型语言模型答案聚合的准确性和一致性", "title_en": "Representation Consistency for Accurate and Coherent LLM Answer Aggregation", "authors": "Junqi Jiang,Tom Bewley,Salim I. Amoukou,Francesco Leofante,Antonio Rago,Saumitra Mishra,Francesca Toni", "background": "现有方法通过在推理时分配更多的计算预算来提高大型语言模型（LLMs）的性能，但通常需要复杂的修改来调优提示和采样策略。本文基于此背景探讨如何通过一种新的方法来改进大型语言模型的推理性能。", "innovation": "本文提出了一种名为代表一致性（RC）的方法，这是一种在测试时聚合来自LLM多个候选响应的答案的方法，不考虑这些答案是如何生成的，包括提示措辞和采样策略的变化。RC考虑了每个答案在候选响应集中出现的次数，以及生成导致每个答案的一系列响应时模型内部激活的一致性。这种方法利用预缓存的激活和轻量级相似性计算，不需要额外的模型查询。该方法通过实验证明了其在提高任务性能方面的有效性，比强测试时扩展基线在多个开源LLMs和不同推理数据集上提高了性能，最高达到4%的准确率提升。此外，本文还表明，稀疏激活信号的一致性与常见的连贯推理概念非常匹配。", "conclusion": "代表一致性（RC）能够有效提高大型语言模型在推理时的答案聚合的准确性和一致性，通过利用预缓存的激活和轻量级相似性计算来实现，不需要额外的模型查询，适用于各种开源大型语言模型和推理数据集，在提高任务性能方面具有明显优势。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21595", "html_url": "https://arxiv.org/abs/2506.21595", "title": "Thunder-LLM：在最少资源下高效将LLM适应为韩语模型", "title_en": "Thunder-LLM: Efficiently Adapting LLMs to Korean with Minimal Resources", "authors": "Jinpyo Kim,Gyeongje Cho,Chanwoo Park,Jongwon Park,Jongmin Kim,Yeonkyoun So,Jaejin Lee", "background": "目前，最先进的语言模型在非英语和非中文语言上的表现往往不佳，因此提升语言模型在新语言上的能力已成为一项重要任务。同时，由于商业保密、技术复杂性、文档不一致以及伦理考虑，语言模型的端到端训练过程仍对公众保密。本文探讨了如何在一个低预算的场景下，将现有的基于英语的语言模型转换为韩语模型，详细描述了端到端的整个过程：收集韩语数据集、预处理数据、训练模型、建立下游基准并进行评估。", "innovation": "本文提出了一种成本效益高的方法，在低预算下将现有的英语语言模型转换为韩语模型，并且能够较为有效地增加模型在新语言（韩语）上的能力。同时，开发的双语模型Thunder-LLM和Thunder-LLM-Ins在使用最少数据和计算资源的前提下，相较于最先进的模型在韩语上表现更优。作者还分享了整体经验并将代码公开。", "conclusion": "本文展示了在低预算场景下将现有的英语语言模型转换为韩语模型的方法，通过评估证实该方法能够有效且经济地提升语言模型在新语言上的能力。开发的双语模型Thunder-LLM和Thunder-LLM-Ins在韩语任务上的表现优于最先进的模型，同时使用了最少的数据和计算资源。作者还在最后分享了整个过程的经验，并公开了代码。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21600", "html_url": "https://arxiv.org/abs/2506.21600", "title": "文档理解中结构化注意力对多模态LLM的重要性", "title_en": "Structured Attention Matters to Multimodal LLMs in Document Understanding", "authors": "Chang Liu,Hongkai Chen,Yujun Cai,Hang Wu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang", "background": "多模态大型语言模型（MLLMs）在文档理解方面仍然面临重大挑战。以前的研究主要集中在通过精确的多模态查询来定位证据页，而本研究则进一步探讨了一个基础但未被充分关注的方面：输入格式对文档理解性能的影响。作者发现，原始的OCR文本反而削弱了MLLMs的性能，这与人们的直觉相反，他们将这一现象归因于注意力分散和结构丢失。", "innovation": "为了进一步证实这一假设，研究提出了一个新颖的结构保持方法，使用LaTex范例对文档元素进行编码，以维持对于理解至关重要的层次组织和空间关系。注意力分析显示，结构化文本使得模型在文本和视觉内容上诱导出结构化的注意力模式，迫使模型专注于语义上有意义的区域，从而减少不必要的注意力浪费。这一方法在不同类型的文档中显著提升了LLM的文档问答性能，且无需进行架构修改或额外训练。", "conclusion": "这种方法对文档理解中的结构化注意力进行结构化保持，显著提升了多模态大型语言模型的文档问答性能，对于不同类型的文档均有效，无需进行架构修改或额外训练。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21596", "html_url": "https://arxiv.org/abs/2506.21596", "title": "评估多模态大型语言模型在教育教科书问题回答中的表现", "title_en": "Evaluating Multimodal Large Language Models on Educational Textbook Question Answering", "authors": "Hessa A. Alawwad,Anas Zafar,Areej Alhothali,Usman Naseem,Ali Alkhathlan,Amani Jamal", "background": "多模态大型语言模型（MLLMs）在视觉-语言任务上已经取得了显著的成功。然而，它们在处理复杂、长期的课程和精细的教育示意图方面的推理能力（这些内容无法仅通过单一自然图像来表示）尚未得到充分的测试和评估。本文通过使用CK12-QA数据集评估最新多模态大型语言模型在教科书问题回答（TQA）任务上的表现来填补这一空白。", "innovation": "引入了一个轻量级的多模态检索增强生成（RAG）管道，将课程中的段落和图表都整合到问题提示中。研究还评估了包括LLaVA和LLaMA 3.2-Vision在内的近期视觉-语言模型在多种输入配置下的性能。此外，研究揭示了当前处理问题-上下文关系的局限性以及噪声的影响，指出了未来研究中亟待解决的关键问题。", "conclusion": "研究表明，检索到的教育上下文对模型准确性和推理的影响显著，同时也揭示了当前在处理问题-上下文关系和存在噪声方面的不足，指出了未来在多模态AI驱动学习研究中的关键方向。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21597", "html_url": "https://arxiv.org/abs/2506.21597", "title": "ClinIQLink 2025共享任务的概述：医学问答", "title_en": "Overview of the ClinIQLink 2025 Shared Task on Medical Question-Answering", "authors": "Brandon Colelough,Davis Bartels,Dina Demner-Fushman", "background": "本文介绍了一个名为ClinIQLink的共享任务，该任务在ACL 2025的第24届BioNLP研讨会期间举行，旨在测试大规模语言模型（LLMs）在面向普通医生的医学定向问题解答方面的性能。这一挑战提供了4,978个由专家验证过的、基于医学资料的问题答案对，覆盖了七种格式：真/假题、多项选择、无序列表、简短回答、简短反转、多跳查询和多跳反转查询。参与系统的实现可以封装在Docker或Apptainer镜像中，并在CodaBench平台或马里兰大学的Zaratan集群上执行。任务一由自动化测试框架进行评分，任务二则由医生小组审核顶级模型的回答。", "innovation": "该任务的创新性在于提供了一个大规模语言模型在医学领域面对复杂问题解答的综合测试平台，以及采用精确匹配和三层次嵌入度量相结合的方式评估封闭式和开放式问题的答案，并引入了由医生组成的审核小组进行评估，以确保模型回答的质量和实用性。", "conclusion": "此项任务展示了大型语言模型在模拟医学场景中的问题回答能力，并通过多样的问答形式和严格的评估机制，强调了模型在实际医学应用中的局限性和潜在改进空间。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21591", "html_url": "https://arxiv.org/abs/2506.21591", "title": "FinEval-KR: 一种大型语言模型在金融领域的知识与推理评估框架", "title_en": "FinEval-KR: A Financial Domain Evaluation Framework for Large Language Models' Knowledge and Reasoning", "authors": "Shaoyu Dou,Yutian Shen,Mofan Chen,Zixuan Wang,Jiajie Xu,Qi Guo,Kailai Shao,Chao Chen,Haixiang Hu,Haibo Shi,Min Min,Liwen Zhang", "background": "大型语言模型（LLMs）在复杂金融推理任务中展现出巨大潜力，但同时也面临挑战，这些任务需要结合特定领域的知识和复杂的推理能力。当前的评估基准工具往往未能分离这些能力指标，且不能评估单一任务表现，也不能深入分析任务失败的根本原因。因此，需要一个能独立评估LLMs的知识和推理能力的新框架，以便更好地理解它们在金融推理中的表现和限制，支持在该领域的进一步研究与进展，并为研究人员提供可重复性研究的数据集以证实其研究有效性和持续推动领域进步。", "innovation": "我们引入了FinEval-KR，这是一个新颖的评估框架，用于独立拆解和量化LLMs的知识和推理能力。此外，该框架基于布鲁姆分类法提出了认知分数，可以分析不同认知层次中的推理能力。我们还发布了涵盖22个子领域的开放源代码中文金融推理数据集，支持可重复研究和金融推理领域的进一步发展。实验结果表明，LLMs的推理能力和高级认知能力是影响推理准确性的关键因素，甚至顶级模型在知识应用方面仍存在瓶颈，且专业金融LLMs在多项指标中仍落后于顶级通用大型模型。", "conclusion": "我们的研究发现，LLMs的推理能力和高级认知能力对其准确度至关重要，而知识应用是一个关键挑战。此外，专业金融LLMs在多个指标上仍落后于顶级通用模型。这些新发现有助于深化我们对LLMs在金融推理中的表现和限制的理解，同时也为未来的研究提供了指导。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21602", "html_url": "https://arxiv.org/abs/2506.21602", "title": "BiMark：大语言模型中的无偏多层水印", "title_en": "BiMark: Unbiased Multilayer Watermarking for Large Language Models", "authors": "Xiaoyan Feng,He Zhang,Yanjun Zhang,Leo Yu Zhang,Shirui Pan", "background": "近年来，大规模语言模型（LLMs）的快速发展引发了对其生成文本真实性的迫切担忧，推动了对可靠鉴别机制的监管需求。尽管水印提供了一种有前景的解决方案，但现有方法在同时实现三个关键要求（文本质量保留、模型无关的检测能力和嵌入消息容量）方面存在困难，这对于实际应用至关重要。关键挑战在于如何平衡文本质量保留与消息嵌入容量之间的权衡。", "innovation": "我们提出了BiMark，一个新颖的水印框架，通过以下三个创新点实现这些要求：（1）比特翻转的无偏重权机制，实现模型无关的检测；（2）多层架构提升可检测性而不牺牲生成质量；（3）信息编码方法支持多比特水印。", "conclusion": "理论分析和广泛实验表明，与最先进的多比特水印方法相比，BiMark在短文本提取率上提高了30%，且通过较低的困惑度保持了文本质量，并且在诸如总结和翻译等下游任务上与未水印文本表现相当。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21603", "html_url": "https://arxiv.org/abs/2506.21603", "title": "自动化作文评分的人本化实现：一种以人为本的方法", "title_en": "Operationalizing Automated Essay Scoring: A Human-Aware Approach", "authors": "Yenisel Plasencia-Calaña", "background": "本文探讨了以人为本实现自动化作文评分（AES）系统的操作化，而不仅仅是关注准确率。研究对比了基于机器学习的方法与大型语言模型（LLMs）的方法，分析了它们的长处、相似性和差异。研究重点关注偏见、鲁棒性和可解释性等关键维度，认为这些因素对于AES系统的以人为本的操作至关重要。研究结果表明，基于机器学习的AES模型在准确率上优于LLMs，但在可解释性方面存在问题；而LLMs提供了更丰富的解释。研究还发现，两种方法在处理偏见和极端分数的鲁棒性方面都存在困难。通过分析这些维度，论文旨在识别不同方法之间的挑战和权衡，为更可靠和值得信赖的AES方法做出贡献。", "innovation": "本文对比了基于机器学习的方法与大型语言模型（LLMs）的方法，并深入分析了偏见、鲁棒性和可解释性等关键维度，旨在找到不同方法之间的挑战和权衡，从而推进AES系统的以人为本的操作实现。", "conclusion": "研究发现，基于机器学习的AES模型尽管在准确率上优于LLMs，但在可解释性方面存在不足；而LLMs则在提供更丰富的解释方面表现出色。两种方法在处理偏见和极端分数的鲁棒性方面均存在不足。通过分析这些维度，本文有助于识别不同方法之间的挑战和权衡，从而推动更可靠和值得信赖的AES方法的发展。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21608", "html_url": "https://arxiv.org/abs/2506.21608", "title": "SysTemp：基于模板的SysML v2模型生成的多代理系统", "title_en": "SysTemp: A Multi-Agent System for Template-Based Generation of SysML v2", "authors": "Yasmine Bouamra,Bruno Yun,Alexandre Poisson,Frédéric Armetta", "background": "SysML v2模型在复杂系统的工程中自动生成面临着巨大挑战，主要源自于学习语料库的稀缺性和复杂语法规则。", "innovation": "提出了一种名为SysTemp的系统，旨在通过自然语言规范简化并改进SysML v2模型的生成。该系统采用多代理架构，并包括一个模板生成器，以结构化生成过程。该研究讨论了系统的优缺点及其在提高SysML v2建模生成质量方面的潜力。", "conclusion": "通过评估展示了该系统的优越性，强调了其在提高SysML v2模型生成质量方面的前景。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21605", "html_url": "https://arxiv.org/abs/2506.21605", "title": "MemBench: 向更全面的LLM基础代理记忆评估迈进", "title_en": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents", "authors": "Haoran Tan,Zeyu Zhang,Chen Ma,Xu Chen,Quanyu Dai,Zhenhua Dong", "background": "近期的研究强调了记忆机制在基于大规模语言模型（LLM）的代理中的重要性，使其能够存储观察到的信息并适应动态环境。然而，评估它们的记忆能力仍然存在挑战。以往的评估通常受限于记忆层次和互动场景的多样性不足，并且缺乏能够从多个方面反映记忆能力的全面度量标准。为了解决这些问题，本文构建了一个更全面的数据集和基准，以评估基于LLM的代理的记忆能力。本文的数据集将事实记忆和反思记忆作为不同层次，并提出了参与和观察作为各种互动场景。基于该数据集，本文提出了一种称为MemBench的基准，从多个方面评估基于LLM的代理的记忆能力，包括其有效性、效率和容量。为了造福研究社区，本文公开了数据集和项目。", "innovation": "本文构建了一个更全面的数据集和基准（MemBench），以评估基于LLM的代理的记忆能力。该数据集将事实记忆和反思记忆作为不同层次，并提出了参与和观察作为各种互动场景。基于MemBench，本文提出了一种评估方法，从多个角度（包括有效性、效率和容量）评估代理的记忆能力。这克服了以往评估的局限性，提供了一个更全面、多样化的评估框架。", "conclusion": "本文通过构建更加全面的数据集MemBench，为基于LLM的代理的记忆能力评估提供了新的基准。该基准包括不同的记忆层次和互动场景，使得评估更加全面。基于此，未来的研究可以使用MemBench来改善代理的记忆能力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21606", "html_url": "https://arxiv.org/abs/2506.21606", "title": "大型语言模型作为文化动态的象征性DNA", "title_en": "Large Language Models as symbolic DNA of cultural dynamics", "authors": "Parham Pourdavood,Michael Jacob,Terrence Deacon", "background": "本文提出了一种新颖的概念化，将大型语言模型（LLMs）视为外部化的信息载体，其功能类似于人类文化动态中的DNA。论文指出不应将LLMs视为自主智能或仅仅是程序化的模仿，而是作为存储人类象征性表达压缩模式的仓库，即“有意义动态的化石”，这些模式保留了关系残余而没有其原始的生活背景。这些压缩的模式只有在通过人类重新解释后才变得有意义，从而创建了一个循环反馈循环，使其能够重新组合并返回，最终催化人类的创造性过程。", "innovation": "文章通过分析四大通用特性：压缩、解压缩、外部化和递归，表明正如DNA作为压缩和外部化介质，用于保存有用的细胞动态，而不涉及明确的定向物理过程的参考，大型语言模型同样保存了人类文化的有用规律，而不包含对身体体验的理解。因此，作者认为大型语言模型的意义不在于与人类智能竞争，而在于提供人类在低风险模拟环境中进行自我反思和假设生成的工具。这一框架使大型语言模型成为文化演化的工具，使人类能够生成关于自身的新型假设，同时确保这些假设与不断发展的美学和规范相联系。", "conclusion": "因此，大型语言模型的价值在于为人类提供了一个自我反思和低风险假设生成的工具环境，而不是替代人类智能。通过这种方式，大型语言模型能够促进人类文化的可进化性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21611", "html_url": "https://arxiv.org/abs/2506.21611", "title": "多模态方法是否能提高时间序列预测效果？", "title_en": "Does Multimodality Lead to Better Time Series Forecasting?", "authors": "Xiyuan Zhang,Boran Han,Haoyang Fang,Abdul Fatir Ansari,Shuai Zhang,Danielle C. Maddix,Cuixiong Hu,Andrew Gordon Wilson,Michael W. Mahoney,Hao Wang,Yan Liu,Huzefa Rangwala,George Karypis,Bernie Wang", "background": "近年来，将文本信息融入基础模型进行时间序列预测的研究引起了广泛关注。然而，目前尚不清楚这种多模态集成在哪些条件下能够持续提高预测性能。本文系统地考察了14项涵盖7个领域的预测任务，旨在研究多模态方法与传统单模态方法相比的优势及适用条件。", "innovation": "本文首次系统性地评估了两种流行的多模态预测范式：基于对齐的方法和提示大语言模型的方法。通过分析实证结果，提出了在何种条件下文本信息能够提升预测性能的新观点，为多模态方法的实际应用提供了实用指南。", "conclusion": "本文发现，要使文本信息能够有效提升预测性能，需要满足：1）高容量的文本模型，2）相对较弱的时间序列模型，3）合适的对齐策略；同时，提供足够的训练数据并且文本能够补充时间序列中未捕捉到的预测信号也有助于提高预测性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21607", "html_url": "https://arxiv.org/abs/2506.21607", "title": "CORE-KG：一种基于LLM的人口走私网络知识图谱构建框架", "title_en": "CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人口走私网络越来越具有适应性，难以分析。法律规定案例文档提供了有价值的见解，但它们是无结构的、词汇密集的，并且充满了模糊或变化的引用，这对自动知识图谱（KG）构建构成了挑战。现有KG方法通常依赖于静态模板并且缺乏核心术语解析能力，而最近基于LLM的方法经常会产生嘈杂且片段化的图，这是由于幻觉和缺乏引导提取造成的重复节点导致的", "innovation": "提出了CORE-KG，这是一种模块化框架，用于从法律文本构建可解释的知识图谱。它使用两步管道：（1）通过序列和结构化LLM提示进行类型感知的核心术语解析；（2）使用基于领域指导的指令进行实体和关系提取，这些指令是基于修改后的GraphRAG框架构建的。与基于GraphRAG的基线相比，CORE-KG通过减少33.28%的节点重复和38.37%的法律噪音，使图结构更清洁和更连贯，从而提高了性能", "conclusion": "这些改进使CORE-KG成为分析复杂犯罪网络的强大基础"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21594", "html_url": "https://arxiv.org/abs/2506.21594", "title": "Gazal-R1：通过参数高效两阶段训练实现尖端医疗推理", "title_en": "Gazal-R1: Achieving State-of-the-Art Medical Reasoning with Parameter-Efficient Two-Stage Training", "authors": "Ahmed M. Adly,Mostafa Samy,Amr Fawzy", "background": "本文介绍了一个名为Gazal-R1的320亿参数语言模型，该模型在医疗推理方面达到了业内最佳性能，同时提供了透明且分步骤的临床决策解释。Gazal-R1基于Qwen3 32B构建，证明了策略性训练可以使得中型模型在特定领域超过更大规模的模型。该研究涉及对合成医学推理示例的监督微调，以及使用Group Relative Policy Optimization (GRPO)进行强化学习。Gazal-R1不仅在实证结果上表现出色，还在医学推理的解说、格式规范性及推理质量方面提供了深入的见解，解决了奖励作弊、训练不稳定和记忆与推理之间的基本矛盾等问题。这项工作提供了一个可复制的框架，用于开发高度专属性且平衡性能、效率和可解释性的语言模型。", "innovation": "文章的创新之处在于开发了一种新颖的两阶段训练管道：第一阶段是对精心挑选的107,033个合成医学推理示例进行监督微调，利用参数高效技术如Weight-Decomposed Low-Rank Adaptation (DoRA) 和Rank-Stabilized LoRA (rsLoRA) 来教授结构化的临床思维；第二阶段是通过Group Relative Policy Optimization (GRPO)及其复杂多部件奖励系统进行强化学习，以提高准确率、格式一致性及推理质量。Gazal-R1在多个医学基准测试中表现优异，在MedQA、MMLU Pro (医学) 和PubMedQA上分别取得了87.1%、81.6%和79.6%的得分，超过更大模型多至12倍的版本", "conclusion": "Gazal-R1不仅在医学推理任务上表现出色，还提供了一系列详细的训练挑战洞察，包括奖励作弊、训练稳定性问题以及事实记忆与详细推理之间的基本矛盾。研究还提出了一种可复制的方法，以开发具备高能力、特定领域且平衡了性能、效率和解释性的语言模型，提供了今后研究的宝贵参考。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21613", "html_url": "https://arxiv.org/abs/2506.21613", "title": "ChildGuard: 专门用于应对儿童定向仇恨言论的专门数据集", "title_en": "ChildGuard: A Specialized Dataset for Combatting Child-Targeted Hate Speech", "authors": "Gautam Siddharth Kashyap,Mohammad Anas Azeez,Rafiq Ali,Zohaib Hasan Siddiqui,Jiechao Gao,Usman Naseem", "background": "随着网络上的儿童定向仇恨言论日益增多，迫切需要专门的数据集来应对这一问题。现有仇恨言论的数据集缺乏年龄特定的标注，无法捕捉到细微的情境，并且忽视了儿童面临的独特情感影响。这些现状催生了对一个能够涵盖儿童定向仇恨言论多样情境的专门数据集的需求。为此，作者引入了ChildGuard1数据集，该数据集源自现有语料库并增加了儿童特定的标注。", "innovation": "ChildGuard数据集包含了儿童定向仇恨言论的多样化语境，并涵盖不同年龄段的儿童。此外，研究人员还对现有的最先进的仇恨言论检测方法，包括大型语言模型（LLMs），进行了基准测试，评估了这些方法在检测和理解儿童定向仇恨言论方面的有效性。为了进一步推动这一领域的研究，作者公开发布了ChildGuard数据集，为开发更有效的检测和减轻此类伤害的方法提供了坚实的基础。", "conclusion": "通过发布ChildGuard数据集，该论文为研究儿童定向仇恨言论检测方法提供了重要支持，推动了该领域的进一步发展。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21615", "html_url": "https://arxiv.org/abs/2506.21615", "title": "使用生成增强检索和临床实践指南精炼医疗诊断", "title_en": "Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines", "authors": "Wenhao Li,Hongkuan Zhang,Hongwei Zhang,Zhengxu Li,Zengjie Dong,Yafan Chen,Niranjan Bidargaddi,Hong Liu", "background": "当前的医疗语言模型通常从大型语言模型（LLMs）适应而来，并根据电子健康记录（EHRs）预测ICD代码（国际疾病分类代码），因为这些标签易于获取。但ICD代码未能捕捉到临床医生在诊断过程中所使用的真实且丰富的推理。临床医生在整合多样化的病人数据和参考临床实践指南（CPGs）的同时做出基于证据的决策，这会导致现有模型的临床实用性受限。", "innovation": "该论文提出了一个名为GARMLE-G的生成增强检索框架，该框架通过直接检索权威性临床实践指南的内容来增加生成的语境相关性，而无需依赖模型生成的文本。GARMLE-G的主要创新包括：将LLM预测与EHR数据集成以创建语义丰富的问题，通过嵌入相似性检索相关的CPG知识片段，并将指导原则的内容与模型输出融合生成临床建议。该工作提升了检索精度、语义相关性及临床指南合规性，同时保持了轻量级结构，适用于局部医疗部署，并提供了一种可扩展、低成本且无幻觉的方法，以使医疗语言模型基于证据的临床实践得到融合，具有广泛的临床部署潜力。", "conclusion": "该工作提供了一种可扩展、低成本且无幻觉的方法，使医疗语言模型基于临床实践指南得到证据支持。该研究的原型系统在高血压诊断中展示出优于基于检索增强生成方法的基线系统的优良表现，同时也保持了轻量级的架构，具备在局部医疗环境中部署的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21609", "html_url": "https://arxiv.org/abs/2506.21609", "title": "推理语言模型从思考到输出：基于推理的链式思考和文本生成特征", "title_en": "From Thinking to Output: Chain-of-Thought and Text Generation Characteristics in Reasoning Language Models", "authors": "Junhao Liu,Zhenhao Xu,Yuxin Fang,Yichuan Chen,Zuobin Ying,Wenhan Chang", "background": "近年来，大型语言模型（LLMs）显示出在复杂推理方面的能力提升。然而，现有研究较少系统地比较这些模型的推理过程及其输出，尤其是它们的自我反思模式（即“茅塞顿开”）及其在不同领域的相互联系。本文利用关键词统计和LLM作为评判者的范式，提出了一个分析四个前沿推理模型（GPT-o1，DeepSeek-R1，Kimi-k1.5，Grok-3）推理特性的新框架。该框架将模型的内部思考过程与其最终输出联系起来，并使用包含现实场景问题的数据集，涵盖逻辑推理、因果推理和多步问题解决。研究人员提出了一套评估推理连贯性和输出准确性的指标。这些研究结果揭示了这些模型在推理过程中如何在探索与利用之间权衡、处理问题、得出结论的各种模式。", "innovation": "本文提出了一种新的框架，通过关键词统计和LLM作为评判者的范式分析大型推理模型的推理过程及其输出。研究人员通过定量和定性比较，识别了这些模型在推理深度、对中间步骤依赖程度、以及思考过程和输出模式与GPT-o1的相似度等方面的不同之处。这项研究为计算效率与推理稳健性之间的权衡提供了有价值的见解，并为实用应用中模型设计和评估提供建议。", "conclusion": "研究结果揭示了这些模型在推理过程中的各种模式，并通过定量和定性比较识别了模型在推理深度、依赖中间步骤的程度以及与GPT-o1的思考过程和输出模式相似度方面存在差异。这项工作为计算效率与推理稳健性的权衡提供了有价值的见解，并为实际应用中模型的设计和评估提供了实用建议。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21616", "html_url": "https://arxiv.org/abs/2506.21616", "title": "TIM：大规模数据集和大型时间情报模型用于开放域时间线摘要", "title_en": "TIM: A Large-Scale Dataset and large Timeline Intelligence Model for Open-domain Timeline Summarization", "authors": "Chuanrui Hu,Wei Hu,Penghang Yu,Hua Zhang,Bing-Kun Bao", "background": "开放域时间线摘要（TLS）对于监控新闻话题的演变至关重要。现有的方法通常使用通用的大语言模型（LLMs）从检索的新闻中总结相关的时间节点。尽管通用LLMs在零样本新闻摘要和时间戳定位方面表现出一定的能力，但在评估话题相关性和理解话题演变方面存在局限性。因此，生成的摘要经常包含不相关信息或不准确的时间戳。", "innovation": "本文提出了第一个针对开放域TLS的大型时间情报模型（TIM），能够有效总结开放域时间线。具体而言，研究提出了一个大规模的TLS数据集，包含超过1,000个新闻主题和超过3,000个标注的TLS实例。此外，研究还提出了一种渐进优化策略，通过指令微调逐步提升摘要性能和无关信息过滤能力。同时，研究引入了一种新颖的双重对齐奖励学习方法，结合语义和时间视角，从而提升了对话题演变原则的理解。", "conclusion": "通过这种渐进优化策略，TIM展示了强大的开放域时间线总结能力。在开放域的广泛实验表明了TIM的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21620", "html_url": "https://arxiv.org/abs/2506.21620", "title": "如何在在线对话中模仿人类：基于2016年美国政治的模拟研究", "title_en": "How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit", "authors": "Daniele Cirulli,Giulio Cimini,Giovanni Palermo", "background": "大型语言模型（LLMs）已经成为了自然语言生成的强大工具，应用范围从内容创作到社会模拟。它们模仿人类互动的能力既带来了机遇也引发了担忧，特别是在具有政治意义的在线讨论中。本研究在2016年美国大选期间的Reddit留言板上进行，旨在评估LLMs在复制用户生成内容方面的表现，尤其是当它们扮演现实或虚构的有偏见用户时的情况。", "innovation": "本研究通过特定的实验设计，使用GPT-4生成评论来模仿真实的或虚构的有偏见用户，分析了这些生成内容的政治倾向、情感和语言特征，并与真实用户的贡献作了对比。实验的设计和分析方法为理解LLMs在在线讨论中的潜在影响提供了新的视角，尤其是对于政治辩论和政治叙事构建的影响。此外，研究还展示了真实和虚构的评论在语义嵌入空间中的分离情况，但通过人工直观方式难以区分。", "conclusion": "研究发现，GPT-4能够生成真实且具说服力的评论，既支持也反对社区支持的候选人，但倾向于更容易达成共识而非引发分歧。真实和虚构的评论在语义嵌入空间中有很好的区分，但手工检查时无法识别。这些发现提供了关于如何利用LLMs悄悄进入在线讨论、影响政治辩论和塑造政治叙事等方面的重要见解，也引发了AI驱动的言论操纵更广泛的影响问题。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21614", "html_url": "https://arxiv.org/abs/2506.21614", "title": "LastingBench：防止知识泄露的基准防御", "title_en": "LastingBench: Defend Benchmarks Against Knowledge Leakage", "authors": "Yixiong Fang,Tianran Sun,Yuling Shi,Min Wang,Xiaodong Gu", "background": "随着大型语言模型（LLMs）的复杂性增加，人们担心它们可能会通过记忆特定任务的数据来在标准问答（QA）基准测试中‘作弊’。这质疑了基准测试评估的有效性，因为评估不再反映模型的真实能力，而是数据泄露的影响。尽管早期的研究集中在检测这些泄露，但很少有人关注如何减轻其影响并保持基准测试的长期效用。", "innovation": "本文提出了LastingBench，这是一个新颖的框架，旨在持续强化和保护现有的基准测试，防止知识泄露。LastingBench通过扰动技术识别泄露点，然后将其改写为假设性场景，以破坏记忆效果，同时保持基准测试的原始评估目标。研究表明，LastingBench显著减少了记忆效果，证明了其在减轻记忆效应方面的有效性。", "conclusion": "LastingBench提供了一种实用且可扩展的解决方案，以确保基准测试的长期稳健性，促进更公平和可解释的LLM评估。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21618", "html_url": "https://arxiv.org/abs/2506.21618", "title": "TrajTok：2025年Waymo开放仿真代理挑战的技术报告", "title_en": "TrajTok: Technical Report for 2025 Waymo Open Sim Agents Challenge", "authors": "Zhiyuan Zhang,Xiaosong Jia,Guanyu Chen,Qifeng Li,Junchi Yan", "background": "本文档介绍了一种名为TrajTok的轨迹分词器，用于基于离散下一个标记预测的行为生成模型。TrajTok结合了数据驱动和规则驱动的方法，提升了覆盖范围、对称性和鲁棒性，并引入了空间感知的标签平滑方法来改进交叉熵损失函数。该分词器和损失函数已在SMART模型中采用，其在Waymo Open Sim Agents Challenge 2025中实现了0.7852的现实性分数，达到了优异的性能表现。", "innovation": "TrajTok结合了数据驱动和基于规则的方法，提升了覆盖范围、对称性和鲁棒性，增加了空间感知的标签平滑方法来优化交叉熵损失。例如，通过引入标签平滑来减少过拟合的风险，同时利用数据驱动的方法更准确地预测轨迹。", "conclusion": "通过使用TrajTok分词器和改进后的损失函数，SMART模型在Waymo Open Sim Agents Challenge 2025中取得了出色的性能，获得了0.7852的现实性分数。未来将开源整个代码实现。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21612", "html_url": "https://arxiv.org/abs/2506.21612", "title": "AdaptGOT: 一种自适应上下文POI表示学习的预训练模型", "title_en": "AdaptGOT: A Pre-trained Model for Adaptive Contextual POI Representation Learning", "authors": "Xiaobin Ren,Xinyu Zhu,Kaiqi Zhao", "background": "目前，已经在POI嵌入方法上取得了显著进展，这得益于诸如推荐和分类等新型POI任务的出现。尽管特定任务的端到端模型在POI嵌入中取得了成功，但仍存在一些挑战，包括需要更有效的多上下文采样策略、对多个POI上下文探索不足、通用性有限以及泛化能力不足。", "innovation": "为了解决这些问题，我们提出了AdaptGOT模型，它将适应性表示学习技术和地理共现文本（GOT）表示相结合，特别强调地理位置、共现和文本信息。AdaptGOT模型包含三个关键组件：（1）上下文邻域生成，结合KNN、基于密度的、基于重要性的以及类别意识等先进技术的混合采样策略，以捕捉复杂的上下文邻域；（2）增强的GOT表示，通过注意力机制设计，以获取高质量和定制化的表示，并高效捕捉POIs之间的复杂关系；（3）基于MoE的自适应编码器-解码器架构，通过最小化不同上下文间的Jensen-Shannon发散性，保持拓扑一致性并丰富上下文表示。", "conclusion": "在两个实际数据集和多个POI任务上的实验表明，提出的AdaptGOT模型具有优越的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21622", "html_url": "https://arxiv.org/abs/2506.21622", "title": "调整基础语音识别模型以适应受损语音：一种用于个性化德国语音的语义重新链路方法", "title_en": "Adapting Foundation Speech Recognition Models to Impaired Speech: A Semantic Re-chaining Approach for Personalization of German Speech", "authors": "Niclas Pokel,Pehuén Moure,Roman Boehringer,Yingqiang Gao", "background": "由于条件如脑瘫或遗传疾病导致的言语障碍给自动语音识别(ASR)系统带来了重大挑战。尽管有近期的进步，像Whisper这样的ASR模型仍然难以处理非规范性语音，原因在于训练数据有限以及难以收集和标注非规范性语音样本。", "innovation": "本文提出了一种实用且轻量化的个性化ASR模型管道，该方法通过形式化词的选择并用语义连贯性丰富小规模言语受损数据集来解决问题，从而改善了不典型语音模式下的转录质量，减轻沟通障碍问题。", "conclusion": "应用此方法的数据来自一个有结构性言语障碍的儿童，结果显示转录质量有显著提高，证明了该方法在减少沟通障碍方面的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21623", "html_url": "https://arxiv.org/abs/2506.21623", "title": "基于NLP的消费者投诉评估与文本生成中多样评价指标的表现", "title_en": "Performance of diverse evaluation metrics in NLP-based assessment and text generation of consumer complaints", "authors": "Peiheng Gao,Chen Yang,Ning Sun,Ričardas Zitikis", "background": "机器学习（ML）在文本分类方面取得了显著进展，通过使机器能够自动理解和分类复杂且结构不规则的文本数据。然而，准确地捕捉自然语言中内在的细微语言模式和上下文变异，特别是在消费者投诉中，依然存在挑战。", "innovation": "本研究通过引入经过人类经验训练的算法，有效识别对消费者救济资格评估至关重要的细微语义差异。进一步，提出了一种结合合成数据生成方法的创新策略，这些方法利用专家对生成对抗网络的评估，并通过专家标注进行精细调整。通过将专家训练分类器与高质量合成数据相结合，旨在显著提升机器学习分类器的性能，减少数据集获取成本，并提高文本分类任务中的整体评价指标和鲁棒性", "conclusion": "结合专家训练分类器与高质量合成数据，本研究旨在显著提升机器学习分类器性能，降低数据集获取成本，并提高整体评价指标和鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21625", "html_url": "https://arxiv.org/abs/2506.21625", "title": "Doc2SAR：一种用于科学文献中高保真结构-活性关系抽取的协同框架", "title_en": "Doc2SAR: A Synergistic Framework for High-Fidelity Extraction of Structure-Activity Relationships from Scientific Documents", "authors": "Jiaxi Zhuang,Kangning Li,Jue Hou,Mingjun Xu,Zhifeng Gao,Hengxing Cai", "background": "从科学文献和专利中提取分子结构-活性关系(SARs)对药物发现和材料研究至关重要。然而，这项任务由于文档格式的异构性和现有方法的局限性而充满挑战。具体来说，依赖于固定模板的基于规则的方法无法在多样的文档布局中泛化，而通用的多模态大语言模型（MLLMs）在专门任务如版面检测和光学化学结构识别（OCSR）方面缺乏足够的准确性和可靠性。因此，需要一种新的方法来解决这些挑战。", "innovation": "本文提出了一种名为Doc2SAR的协同框架，它将领域特定工具与通过监督微调（SFT）增强的大语言模型结合在一起。DocSAR-200是一个包含200份严格标注的科学文档的基准数据集，用于评估SAR提取方法。实验结果表明，Doc2SAR在多种文档类型上实现了最先进的性能，显著优于最先进的端到端基线。尤其是，在DocSAR-200上的整体表格召回率为80.78%，超过了end2end GPT-4o 51.48个百分点。此外，Doc2SAR还展示出了高效推理的实际可用性，并附带了一个web应用。", "conclusion": "Doc2SAR通过集成领域特定工具和通过监督微调增强的大语言模型，提供了一种高效且准确的方法来提取科学文献中的结构-活性关系。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21712", "html_url": "https://arxiv.org/abs/2506.21712", "title": "识别自监督语音变换器前馈层中的说话人信息", "title_en": "Identifying Speaker Information in Feed-Forward Layers of Self-Supervised Speech Transformers", "authors": "Tzu-Quan Lin,Hsi-Chun Cheng,Hung-yi Lee,Hao Tang", "background": "近年来，自监督语音变换器在说话人相关应用中产生了影响，但很少有研究探讨这些模型如何编码说话人信息。这项工作通过识别与说话人信息相关的前馈层中的神经元来填补这一空白。", "innovation": "该研究通过分析与自监督特征的k-means聚类和i-向量相关的神经元，揭示了这些聚类对应于广泛的声音和性别类别，使得识别出代表说话人的神经元成为可能。通过保护这些神经元在修剪过程中的完整性，研究证明它们在编码说话人信息方面起着至关重要的作用，从而显著保留了说话人相关任务的性能.", "conclusion": "研究表明，在自监督语音变换器的前馈层中存在能够编码说话人信息的神经元，这些神经元对于识别和分类说话人至关重要。保护这些神经元免于修剪，可以显著保持说话人相关的任务性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21783", "html_url": "https://arxiv.org/abs/2506.21783", "title": "评估大型语言模型的列表构建和时间理解能力", "title_en": "Evaluating List Construction and Temporal Understanding capabilities of Large Language Models", "authors": "Alexandru Dumitru,V Venktesh,Adam Jatowt,Avishek Anand", "background": "大型语言模型（LLMs）在各种自然语言任务中取得了巨大进步，但在涉及多个实体的特别时间理解任务中容易出现幻觉和错误。现有研究在列表答案构建环境中对模型进行时间理解和隐式/显式时间理解的能力评估不够充分。本文旨在填补这一空白，提出了时间参考列表问答基准（TLQA），要求模型提供结构化的、按时间对齐的列表答案。", "innovation": "提出了一个新的评估基准（TLQA）要求模型在同一时间内既构建列表又理解时间。这是首次同时对大型语言模型的列表构造能力和时间理解能力进行系统的评估。这揭示了当前大型语言模型在封闭书籍环境下的不足之处，并指出了在开放领域环境下需要改进的信息检索问题。", "conclusion": "目前的模型在封闭环境下的列表构建和时间对齐方面存在明显不足，需要在开放领域中提高检索能力。基于TLQA基准，研究者可以明确未来的研发方向。基准和代码位于this https URL。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21621", "html_url": "https://arxiv.org/abs/2506.21621", "title": "开放证明语料库：大规模研究自动生成的数学证明", "title_en": "The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs", "authors": "Jasper Dekoninck,Ivo Petrov,Kristian Minchev,Mislav Balunovic,Martin Vechev,Miroslav Marinov,Maria Drencheva,Lyuba Konova,Milen Shumanov,Kaloyan Tsvetkov,Nikolay Drenchev,Lazar Todorov,Kalina Nikolova,Nikolay Georgiev,Vanesa Kalinkova,Margulan Ismoldayev", "background": "近年来，大型语言模型（LLMs）在数学证明生成方面取得了显著进步，但进一步的发展受限于缺乏大规模、高质量的人工评估证明数据集。虽然创建这样的数据集成本较高，但它对推动训练改进和使证明生成能力的分析更加严谨是至关重要的。目前，还缺少一个广泛适用且适合用于后续使用的数据集，特别是包含来自著名数学竞赛（如USAMO和IMO）问题的正确解答的数量较大的自动生成证明的数据集。本文旨在填补这一空白，提出了Open Proof Corpus (OPC)，这是一个包含超过5,000个人工评价的自动生成证明的数据集，这些证明由最先进的LLMs生成。OPC专为广泛适用性和下游使用设计，并首次包含大量自动生成且正确的、来自Top数学竞赛的问题解答。利用OPC，研究者探索了自动证明生成的关键问题：（1）自然语言与形式证明生成之间的性能差距，（2）最终答案准确性和全文证明有效性的差异，以及（3）最佳n选一策略对证明质量的影响。最后，为了展示OPC的实用性，研究者在一个包含80亿参数的模型上进行了微调，所得到的模型在评价证明正确性任务上的表现与当前最佳模型Gemini-2.5-Pro相当。(2)最终答案准确性和全文证明有效性的差异，以及(3)最佳n选一策略对证明质量的影响。最后，为了展示OPC的实用性，我们在一个包含80亿参数的模型上进行了微调，所得到的模型在评价证明正确性任务上的表现良好，与当前最佳的模型Gemini-2.5-Pro相当，", "innovation": "提出了Open Proof Corpus (OPC)，一个包含超过5,000个人工评估的自动生成证明的数据集，这些证明由最先进的LLMs生成。OPC专为广泛适用性和后续使用设计，并首次包含大量自动生成且正确的、来自Top数学竞赛的问题解答。利用OPC，研究者探索了自动证明生成的关键问题：（1）自然语言与形式证明生成之间的性能差距，（2）最终答案准确性和全文证明有效性的差异，以及（3）最佳n选一策略对证明质量的影响。最后，为了展示OPC的实用性，研究者在一个包含80亿参数的模型上进行了微调，所得到的模型在评价证明正确性任务上的表现良好，与当前最佳的模型Gemini-2.5-Pro相当。", "conclusion": "Open Proof Corpus (OPC)为自动证明生成的研究提供了一个广泛适用且高质量的数据资源，填补了现有数据集中缺少的高水平证明的空白。通过OPC，研究者发现了一些关键问题的答案，如自然语言和形式证明生成之间的性能差距、最终答案准确性和全文证明有效性的差异，以及最佳n选一策略对证明质量的影响。此外，通过在OPC上对一个80亿参数的模型进行微调，研究者获得了表现出色的模型，这进一步验证了OPC的实用性和有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21795", "html_url": "https://arxiv.org/abs/2506.21795", "title": "使用XLNet在社交媒体上检测有害语言", "title_en": "Offensive Language Detection on Social Media Using XLNet", "authors": "Reem Alothman,Hafida Benhidour,Said Kerrache", "background": "社交媒体上基于文本的通信虽然提升了用户互动，但同时也带来了更多有害内容，如仇恨言论、种族主义和其他形式的攻击。由于用户生成的内容量巨大，手动审核不可行，因此需要自动系统来检测有害语言。深度学习模型，尤其是使用迁移学习的模型，在大规模预训练后能够很好地理解自然语言。本研究基于XLNet（一种通用自回归预训练方法）构建了有害语言检测模型，并与自然语言处理领域常用的BERT基线模型进行对比评估。", "innovation": "研究提出了一种基于XLNet的自动有害语言检测模型，并将其性能与广泛使用的BERT模型进行了比较。实验结果表明，XLNet在检测有害内容和分类不同类型攻击方面优于BERT，而BERT在识别攻击目标方面表现略好。此外，研究发现过采样和欠采样策略在解决类别不平衡和提升分类性能方面是有效的。这些发现强调了迁移学习和基于XLNet的架构在构建社交媒体平台上的稳健检测系统中的潜力。", "conclusion": "研究表明XLNet和基于XLNet的模型在有害语言检测上表现更佳，特别是在对不同类型攻击的检测上。研究还发现数据集处理技术如过采样和欠采样可以改善模型性能。总体而言，这篇研究强调了使用迁移学习和XLNet模型来开发社交媒体平台上的自动有害语言检测系统的前景。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21686", "html_url": "https://arxiv.org/abs/2506.21686", "title": "ANUBHUTI：一种用于孟加拉地方语言情感分析的综合语料库", "title_en": "ANUBHUTI: A Comprehensive Corpus For Sentiment Analysis In Bangla Regional Languages", "authors": "Swastika Kundu,Autoshi Ibrahim,Mithila Rahman,Tanvir Ahmed", "background": "由于孟加拉语的方言多样性以及标注数据的稀缺性，对于地方方言的情感分析仍然处于未被充分探索的领域。为了填补这一空白，本论文介绍了ANUBHUTI语料库，这是一个旨在覆盖四种主要方言（穆尔辛加、诺阿卡利、齐莱特和 Chattogram）的全面数据集。每个句子都采用了双标签方案标注：多类别主题标记将句子分类为政治、宗教或中立，并使用多标签情绪标注分配一种或多种情绪（愤怒、轻蔑、厌恶、欣喜、恐惧、悲伤、惊讶）。该数据集经过专家正确翻译和审查，并通过Cohens Kappa检验了注释者之间的互斥性一致性，确保了高质量的数据集。数据集进一步通过系统检查进行了完善，以剔除缺失数据、异常数据和不一致性问题，权衡反映了当代孟加拉国的政治和社会景观，包括中立文本以保持平衡。该数据集填补了低资源孟加拉语方言情感分析资源的空白，可用于更准确和上下文感知的自然语言处理模型训练和评估.", "innovation": "ANUBHUTI 是一个全面的多方言情感分析数据集，涵盖了穆尔辛加、诺阿卡利、齐莱特和 Chattogram 四种主要孟加拉地方方言。通过使用双标签方案（主题和情绪双重标注），数据集为情感分析提供了更丰富的语义和情感标注信息，有助于提升低资源语言的情感分析能力。", "conclusion": "该数据集的成功开发和发布为低资源孟加拉语方言的情感分析提供了宝贵的资源，推动了该领域的研究和应用。该数据集具有高质量、多类别标注和多情感标注等特点，能够支持更准确的自然语言处理模型开发。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21812", "html_url": "https://arxiv.org/abs/2506.21812", "title": "向透明AI迈进：大规模可解释语言模型综述", "title_en": "Towards Transparent AI: A Survey on Explainable Large Language Models", "authors": "Avash Palikhe,Zhenyu Yu,Zichong Wang,Wenbin Zhang", "background": "大型语言模型（LLMs）极大地推动了人工智能的发展。尽管取得了一定成就，但LLMs在解释其决策过程方面存在困难，导致缺乏透明性，这成为其在高风险领域应用中的一个重要障碍。为此，研究人员开发了多种可解释人工智能（XAI）方法，但这些方法的整体理解仍然有限。此研究旨在通过分类LLMs底层变压器架构的XAI方法，提供全面的解释性技术综述，并评估这些技术在实际应用中的表现，进一步探讨未来的研究挑战和发展方向，以促进开发更为透明和负责任的LLMs.", "innovation": "按照LLMs的基础变压器架构对XAI方法进行分类，系统性地评估这些方法如何在实际应用中提供解释，并讨论现有资源和未来的研究挑战和发展方向，旨在为开发透明和负责任的LLMs提供指导.", "conclusion": "该综述广泛探讨了可解释性技术及其在实际应用中的应用，强调了开发透明和负责任的大规模语言模型的重要性，并为未来的研究提供了方向."}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21745", "html_url": "https://arxiv.org/abs/2506.21745", "title": "（事实）检查你的偏见", "title_en": "(Fact) Check Your Bias", "authors": "Eivind Morris Bakke,Nora Winger Heggelund", "background": "自动事实验证系统越来越多地依赖大型语言模型（LLMs）。本文探讨了这些模型中的参数知识偏见如何影响HerO系统的事实核查结果（FEVER-25基准系统之一）。研究通过直接提示Llama 3.1进行事实核查以及故意注入偏见两种方式，探讨了这些偏见如何影响系统的表现。研究表明，Llama 3.1在直接进行事实核查时，几乎有一半的陈述被标记为“证据不足”。这表明，系统只能依循其参数知识判断另一半陈述。通过命令模型生成支持性、反驳性或中立的事实核查文件，可以显著影响检索结果，各种视角的证据大约有50%是独特的。尽管不同说法收集到的证据有所不同，但最终的确定预测显示出不同提示策略的一致性。因此，此研究提供了有关LLMs如何影响事实验证过程的重要见解，揭示了隐藏于其中的偏见问题。", "innovation": "该研究通过直接提示和故意注入偏见两种方式，调研了参数知识偏见如何影响HerO系统的事实核查结果。此外，该研究还考察了模型生成支持性、反驳性或中立的事实核查文件如何显著影响检索结果。值得注意的是，模型在认为某些声明为假时，有时会选择拒绝生成支持性文件，从而产生内在的负面偏见。研究结果显示，尽管最终判断结果具有一定的稳定性，但检索到的证据仍然显示出不同提示策略的独特性。这些发现对理解大型语言模型在事实核查中的表现具有重要启示意义。", "conclusion": "该研究证明了在事实验证过程中，参数知识偏见显著影响了模型的表现。研究结果显示，Llama 3.1系统基于参数知识的能力不足以进行精确判断，且模型在面对具有潜在虚假信息陈述时的负面偏见也是不可忽视的。研究者建议，未来应加强对大型语言模型参数知识偏见的研究，并开发相应的方法来减少此类偏见的影响，以提升事实验证系统的准确性。研究提供的数据和代码可在提供的链接处获取。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21682", "html_url": "https://arxiv.org/abs/2506.21682", "title": "我们真的需要带有显式结构建模的GNNs吗？MLPs足以替代语言模型表示", "title_en": "Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations", "authors": "Li Zhou,Hao Jiang,Junjie Li,Zefeng Zhao,Feng Jiang,Wenyu Chen,Haizhou Li", "background": "GNNs能够编码显式结构信息，增强模型在下游NLP任务中的能力。但最近的研究表明，GNNs并没有充分利用结构信息，而MLPs尽管缺乏GNNs的信息传递机制，却在结构感知任务中表现出惊人的能力。论文提出了一个基于信息理论的综合探测框架，旨在系统性评估显式结构建模在提升语言模型表示方面的角色，并探讨MLPs作为GNNs的高效可扩展替代方案的可能性。传统的探测分类器被扩展，加入了一个控制模块，允许选择使用完整的GNN模型或其解耦组件（信息传递和特征转换），避免了完整GNN架构可能带来的混淆效应。综合探测套件（Edge Probing Suite）被用于评估LMs中编码的语言知识。研究结果表明，作为特征转换模块的MLPs能有效提升LMs表示中的语言知识，而仅依赖信息传递操作的模型表现不佳，可能对探测任务产生负面影响。", "innovation": "提出了一个基于信息理论的综合探测框架，该框架设计用于系统性地评估现有方法和新的MLP模型，特别是在语言模型表示提升中显式结构建模的作用。此框架引入了一个控制模块，允许对完整的GNN模型或其解耦组件进行选择性使用，从而隔离并评估各项操作的独立贡献，避免混淆效应。研究为结构感知任务中MLPs的性能提供了新的视角。", "conclusion": "实验结果表明，MLPs（作为特征转换模块）在不同架构下都能提升LMs中语言知识的捕捉能力，并能编码句法和语义模式。相比之下，仅依赖信息传递操作的GNNs模型则不那么有效，甚至可能对探测任务产生负面影响。MLPs被认为是能够替代GNNs进行有效和可扩展建模的替代方案。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21808", "html_url": "https://arxiv.org/abs/2506.21808", "title": "一套用于使用等级湍流发散比较复杂系统的allotaxonometric工具", "title_en": "A suite of allotaxonometric tools for the comparison of complex systems using rank-turbulence divergence", "authors": "Jonathan St-Onge,Ashley M. A. Fehr,Carter Ward,Calla G. Beauregard,Michael V. Arnold,Samuel F. Rosenblatt,Benjamin Cooley,Christopher M. Danforth,Peter Sheridan Dodds", "background": "描述和比较复杂系统需要有原理性和理论基础的工具。围绕类型湍流现象，allotaxonographs提供了两种幂律分布的视觉比较图表，适用于多种工具包括等级-概率湍流发散、Jensen-Shannon发散和广义熵发散。", "innovation": "本文介绍了一套在Matlab、JavaScript和Python中渲染基于等级湍流发散的allotaxonographs的程序工具，这些工具具有不同的应用场景，这使得不同领域的研究人员能够更有效地比较复杂系统。", "conclusion": "本文提供了一种新的方法和技术手段，以更精确地比较复杂系统的等级湍流发散，为复杂系统研究领域提供了一套实用的工具集。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21619", "html_url": "https://arxiv.org/abs/2506.21619", "title": "IndexTTS2：在情感表达和时长控制方面的自动回归零样本文本到语音突破", "title_en": "IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech", "authors": "Siyi Zhou,Yiquan Zhou,Yi He,Xun Zhou,Jinchao Wang,Wei Deng,Jingchen Shu", "background": "大型文本到语音（TTS）模型通常被分为自回归和非自回归系统两类。尽管自回归系统在语音自然度方面有一些优势，但它们按令牌逐个生成语音的方式使得精确控制合成语音的时长变得困难。这一点在需要严格音视频同步的应用，如视频配音中是一个关键限制。为此，本文介绍了一种新的方法——IndexTTS2，该方法为自回归模型提供了新的语音时长控制方法，支持两种生成模式，其中之一允许明确指定生成令牌的数量以实现精确的时长控制，另一种模式则无需手动输入，模型可以自由生成语音同时保留输入提示的韵律特征。此外，IndexTTS2 实现了情感表达和说话者身份之间的解耦，允许独立控制音色和情感。在零样本设置下，该模型能够完美地再现输入提示的情感特征。用户还可以提供一个单独的情感提示，即使来自不同的说话者，模型也能重建目标音色的同时传达希望的情绪。为了在强烈的情感表达中增强清晰度，我们引入了GPT潜在表示来提高语音稳定性。同时，为降低情感控制的门槛，我们基于文本描述的微调设计了一种软指令机制。这使得使用自然语言输入能够有效地引导期望的情感倾向的语音生成。实验结果证实，IndexTTS2 在词语错误率、说话者相似度和情感保真度方面优于现有的最先进的零样本 TTS 模型。", "innovation": "IndexTTS2 提出了一种自回归模型友好的语音时长控制方法，支持两种生成模式；实现了情感表达和说话者身份的解耦，允许独立控制音色和情感；在零样本设置下能够完美地再现输入提示的情感特征。为了增强表现强烈情感时的清晰度，引入了 GPT 潜在表示来提高语音稳定性；还设计了基于文本描述的软指令机制，以降低情感控制的门槛。这些创新使得 IndexTTS2 能够实现更好的用户体验和更广泛的应用范围。", "conclusion": "实验表明，IndexTTS2 在零样本设置下的词语错误率、说话者相似度和情感保真度方面都优于现有的最先进的 TTS 模型。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21848", "html_url": "https://arxiv.org/abs/2506.21848", "title": "LinguaSynth: 来自不同语言信号的新闻分类", "title_en": "LinguaSynth: Heterogeneous Linguistic Signals for News Classification", "authors": "Duo Zhang,Junyi Mo", "background": "深度学习在自然语言处理（NLP）领域取得了重大进展，但其依赖的大规模黑盒模型带来了关键的可解释性和计算效率问题。", "innovation": "提出了LinguaSynth，这是一种新颖的文本分类框架，该框架在透明的逻辑回归模型中战略性地整合了五种互补的语言特征类型：词汇、句法、实体级别、词语级别语义和文档级别语义。LinguaSynth 与其基于变换器的架构不同，它保持了可解释性和计算效率，实现了20组新闻数据集84.89％的准确性，比稳健的TF-IDF基线方法高3.32％。通过严格的特征交互分析，证明句法和实体级别信号提供了关键的消歧作用，并且有效补充了分布语义。LinguaSynth 设定了可解释的、资源高效NLP模型的新基准，并挑战了深度神经网络对于高性能文本分类是必要的这一假设。", "conclusion": "LinguaSynth 为可解释的资源高效 NLP 模型设定了新基准，挑战了深度神经网络在高性能文本分类任务中不可或缺的主流观点。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21849", "html_url": "https://arxiv.org/abs/2506.21849", "title": "大语言模型不确定性量化中的一致假设", "title_en": "The Consistency Hypothesis in Uncertainty Quantification for Large Language Models", "authors": "Quan Xiao,Debarun Bhattacharjya,Balaji Ganesan,Radu Marinescu,Katsiaryna Mirylenka,Nhan H Pham,Michael Glass,Junkyu Lee", "background": "评估大语言模型（LLM）输出的置信度对于需要高用户信任的实际应用至关重要。黑盒不确定性量化（UQ）方法因其实践优势而受到青睐，这些方法仅依赖于模型API访问。本文探讨了多个UQ方法背后的隐含假设：将生成一致性作为置信度的代理，我们将其形式化为一致性假设。研究覆盖了8个基准数据集和3项任务（问答、文本摘要和文本到SQL），揭示了该假设在不同环境下的普遍性。", "innovation": "提出并验证了三个数学陈述及其对应的统计测试，以捕捉一致性假设的变化，并引入了通过比较生成之间相似性来估计LLM输出一致性的数据免费黑盒UQ方法。这些方法能够在不同任务上超越最近的基线方法，展示了实验观察到的一致性假设的实际价值。", "conclusion": "一致假设在大语言模型的不确定性量化中被广泛证实。本文提出了一个最具操作性的假设‘Sim-Any’，并利用此假设提出了数据免费的黑盒UQ方法，聚合生成间的相似性来估计置信度，这些方法在各项任务中均表现优异。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21840", "html_url": "https://arxiv.org/abs/2506.21840", "title": "PARSI：通过修辞集成识别波斯作者", "title_en": "PARSI: Persian Authorship Recognition via Stylometric Integration", "authors": "Kourosh Shahnazari,Mohammadali Keshtparvar,Seyed Moein Ayyoubzadeh", "background": "波斯古典诗歌的语言、修辞和韵律复杂性为计算作者归属提出了挑战。本文介绍了用于确定67位重要诗人作者身份的多功能框架。该框架基于多输入神经网络，结合了基于变换器的语言编码器和解决波斯诗歌语义、修辞风格和韵律维度的功能。研究团队编译了647,653首来自Ganjoor数字收藏的诗句，并通过严格的预处理和作者验证，保持诗篇划分，以防止交叉。", "innovation": "该工作采用首尾水平分类和多数投票及加权投票方案进行评估，表明加权投票方案准确率为71%。进一步研究基于阈值的决策过滤，模型生成高置信度预测，最高达97%的准确率，但覆盖率较低。研究重点在于将深层表达形式与领域特定特征的整合以提高作者归属的准确性。", "conclusion": "研究成果展示了该方法在自动化分类、风格分析、作者权属争议和计算文学研究方面的潜力，为多语言作者归属、风格过渡和波斯诗歌生成建模的研究提供了支持。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21817", "html_url": "https://arxiv.org/abs/2506.21817", "title": "探索由AI引发的科学英语语言变化结构", "title_en": "Exploring the Structure of AI-Induced Language Change in Scientific English", "authors": "Riley Galpin,Bryce Anderson,Tom S. Juzek", "background": "近年来，科学英语经历了快速且前所未有的变化，词频显著上升的是诸如“深入”、“复杂”和“关键”等词汇。这些变化通常归因于大型语言模型（如ChatGPT）在讨论偏见和失配问题中的影响日益增强。然而，除了词频的增加外，这些语言变化的具体结构仍然不清楚。这项研究正是为了探讨这些变化是否涉及同义词的替换（例如，“关键”取代“重要”和“关键”），还是反映了更广泛的意义和修辞资格的变化。我们通过部分词性标注来分析语言变化，量化不同语法类别中的词语变化，并区分词语的不同形式，如“潜力”作为名词和形容词的情况。", "innovation": "研究通过分析PubMed中广泛讨论的‘突增词汇’的频率趋势，系统地分析同义词组，发现整个语义群通常会同时发生变迁，大多数或所有词汇都在增加使用频率。这一模式表明，由大型语言模型引起的语言变化主要是语义和修辞上的，而非纯粹词汇性的。此外，研究发现形容词“重要”显著下降，促使我们对下降词汇进行了系统性分析，揭示了更复杂的变化图景，这与突增词汇的模式一致，与有机语言变化保持一致。这些研究结果有助于我们理解语言技术如何继续影响人类语言。", "conclusion": "研究表明，大型语言模型对科学英语语言结构的影响主要是语义和修辞上的变化，而不是单纯的词汇替换。这一发现有助于我们更全面地理解语言技术如何继续塑造人类语言。通过系统分析发现“下降词汇”的变迁模式更加复杂，与“突增词汇”的急剧模式形成对比，揭示出有机语言变化的过程。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21876", "html_url": "https://arxiv.org/abs/2506.21876", "title": "视觉语言模型拥有内在的世界模型吗？一种基本评估方法", "title_en": "Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation", "authors": "Qiyue Gao,Xinyu Pi,Kevin Liu,Junrong Chen,Ruolan Yang,Xinqi Huang,Xinyu Fang,Lu Sun,Gautham Kishore,Bo Ai,Stone Tao,Mengyang Liu,Jiaxi Yang,Chao-Jung Lai,Chuanyang Jin,Jiannan Xiang,Benhao Huang,Zeming Chen,David Danks,Hao Su,Tianmin Shu,Ziqiao Ma,Lianhui Qin,Zhiting Hu", "background": "内部世界模型（WMs）使智能体能够理解并预测世界状态的变化，从而支持高效的决策。近期的大规模视觉-语言模型（VLMs），如OpenAI的o3、GPT-4o和Gemini，展现了作为通用WM的潜力。虽然已有研究评估了VLMs在特定能力上的表现，但对其基础WM能力的系统性评估依然缺乏。为了填补这一空白，本研究提出了一个基于比较心理学和认知科学的两阶段框架，用于评估VLMs在感知（视觉、空间、时间、数量和运动）和预测（机械模拟、传递性推理和组合推理）方面的基础WM能力。基于此框架，作者创建了WM-ABench基准测试，包含6个不同模拟环境中的23个精细评价维度，同时进行了多次实验证明了VLMs在这方面的局限性，如在轨迹识别中的随机准确率和对不同颜色物体运动速度的错误理解。", "innovation": "提出了一个基于比较心理学和认知科学的两阶段框架，该框架用于评估视觉-语言模型作为世界模型的基本感知和预测能力。WM-ABench是一个大规模基准测试，包含了6个不同模拟环境中的23个精细评价维度，通过660次实验对15个最新的商用和开源视觉-语言模型进行了评估，揭示了这些模型在基本世界建模能力方面的重大局限性，如在辨别运动轨迹时近乎随机的准确率和对不同颜色物体运动速度的错误理解。", "conclusion": "视觉-语言模型在基础的世界建模能力方面存在显著的局限性，需要进一步改进。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21861", "html_url": "https://arxiv.org/abs/2506.21861", "title": "衍推探究：揭开神经语言模型层内句法结构的构建过程", "title_en": "Derivational Probing: Unveiling the Layer-wise Derivation of Syntactic Structures in Neural Language Models", "authors": "Taiga Someya,Ryo Yoshida,Hitomi Yanaka,Yohei Oseki", "background": "近期的研究表明，神经语言模型内部表示中包含了句法结构，但这些结构是如何在各层中逐步构建起来的机制仍不清楚。本文旨在通过引入衍推探究方法，探索微句法结构（如主语名词短语）和宏观句法结构（如根动词与其直接依存词之间的关系）是如何随着词嵌入在各层上传递而逐步构建起来的。实验证实在BERT模型中存在一个从下向上的构建过程：微句法结构在低层中浮现，并逐渐整合为高层的宏观句法结构。此外，针对主谓数一致性的目标评估显示，宏观句法结构的构建时机对下游任务性能至关重要，这表明了综合全局句法信息的最佳时机。", "innovation": "提出了一种新的方法——衍推探究，用于研究神经语言模型中微观和宏观句法结构是如何随词嵌入的传播在各层上传输和构建的。这种方法揭示了句法结构的逐层构建过程，并表明宏观句法结构的构建时机对下游任务性能有重要影响。", "conclusion": "实验证明，在BERT模型中存在着从下到上的句法结构构建过程，即微句法结构在低层浮现，随后逐步整合为高层的宏观句法结构。同时，主谓数一致性的评估结果显示，宏观句法结构的构建时机对下游任务性能至关重要，这强调了平衡局部和全球句法信息的重要性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21881", "html_url": "https://arxiv.org/abs/2506.21881", "title": "在LLMs中的地缘政治和文化偏见的双层评估", "title_en": "A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs", "authors": "Sean Kim,Hyuhng Joon Kim", "background": "随着大型语言模型（LLMs）在多语言和文化背景下被广泛应用，了解其在事实和争议场景中的行为变得尤为重要，特别是当其输出可能影响公众意见或强化主流叙事时。", "innovation": "该研究通过两阶段评估定义了LLMs的两种偏见：模型偏见（源自模型训练的偏见）和推论偏见（由查询语言引起的偏见）。并通过构建涵盖事实和争议问题问答的手动筛选数据集，评估了LLMs在地缘政治敏感问题上的表现，揭示了训练背景和查询语言之间的相互作用对偏见的影响。", "conclusion": "该研究提供了一个结构化的框架，用于在中立和敏感主题上评估LLM行为，为未来的LLM部署和在多语言背景下进行文化敏感评估提供了见解。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21910", "html_url": "https://arxiv.org/abs/2506.21910", "title": "AutoMixer: 使用检查点残差作为自动数据混合器", "title_en": "AutoMixer: Checkpoint Artifacts as Automatic Data Mixers", "authors": "Ernie Chang,Yang Li,Patrick Huber,David Kant,Yangyang Shi,Vikas Chandra", "background": "在语言模型训练过程中，希望使模型具备各种任务的能力。然而，很难直接获得适当的训练数据集，以适应这些任务需求，因为数据与任务之间的关系难以建模。我们发现，在训练过程中保存的检查点模型在不同训练阶段会展现出不同类型的能力。通常，训练过程会将这些检查点保存为未充分利用的训练数据信号来源。本文提出了一种方法，通过识别基于基准测试中不同能力的检查点模型，并利用它们对源数据的累积一阶影响近似，将这些模型作为数据混合工具使用，从而展示了在预训练设置中采用这种框架可以显著提升性能，最高提升达1.93%，证明了检查点模型在提高数据质量和优化数据混合方面的潜力。", "innovation": "识别基于不同能力的检查点模型，利用它们对源数据的累积一阶影响近似作为数据混合工具，从而自动优化数据混合，提高语言模型训练性能。", "conclusion": "本文提出的方法显示了检查点模型在提升数据质量和优化数据混合方面的潜力，通过八个推理基准测试，证明了该框架在预训练设置中的显著性能改进，最高性能提升达1.93%。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21875", "html_url": "https://arxiv.org/abs/2506.21875", "title": "WildSpeech-Bench: 在自然对话中的音频LLM基准测试", "title_en": "WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation", "authors": "Jian Zhang,Linhao Zhang,Bokai Lei,Chuhan Wu,Wei Jia,Xiao Zhou", "background": "近年来，多模态大型语言模型（LLMs）如GPT-4o展示了对直接语音互动的强大能力。然而，缺乏专门且全面的基准测试来评估端到端的语音LLM，阻碍了实际应用中音频LLM用户体验的优化。现有的评估方法常常依赖于文本基准的调整，忽视了语音的独特特性和挑战，例如语调、同音词、结巴以及用户期望的不同。因此，本文提出了一个全新的方法，全面评估语音模型在实际对话中的表现。方法包括系统地收集与语音场景相关的对话数据，并引入丰富的说话者属性和声学条件，以及添加与语音有关的现象。同时设计了一种基于查询的评估方法，采用定制的评估清单和提示来增强自动评估的准确性。通过全面测试和详细分析多种主流语音模型，揭示了不同语音场景下模型性能的显著差异。基于查询的评估方法进一步使得可以在多种语音特定场景下进行更细致的评估。本基准可以为语音模型的研发和评估提供有价值的见解。", "innovation": "本文提出了一种系统的方法，用于在实际语音对话中全面评估语音模型。具体包括：1) 系统地收集与真实语音场景相关的对话数据；2) 在说话者属性和声学条件上增加多样性；3) 引入与语音相关的现象；4) 设计基于查询的评估方法，使用定制的评估清单和提示来增强自动评估的准确性；5) 全面测试和分析多种主流语音模型，揭示不同场景下的模型性能差异；6) 通过基于查询的评估方法，实现对各种语音特定场景的细化评估。", "conclusion": "我们的基准测试可以为语音模型的研发和评估提供有价值的见解。通过提出新的方法和全面的数据收集，可以更准确地评估语音模型在实际应用中的表现，为用户提供更好的体验。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21990", "html_url": "https://arxiv.org/abs/2506.21990", "title": "分析和微调 Whisper 模型用于机舱中多语言飞行员语音转录", "title_en": "Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit", "authors": "Kartheek Kumar Reddy Nareddy,Sarah Ternus,Julia Niebling", "background": "变压器编码器-解码器架构的发展使机器翻译、自动语音识别（ASR）和指令驱动的聊天机器等领域取得了重大突破。预训练模型通常在大量通用数据上进行微小的训练量（通常不到五轮），表现出较强的泛化能力。然而，当应用于狭窄的专业领域，如机舱内飞行员对话的转录时，这些模型的表现会下降，因为这类对话涉及大量特定词汇和多语言交流。机舱内的对话必须准确转录，这对安全性和性能至关重要。论文中提到的一项案例即是在机舱模拟器中录制了约85分钟的飞行员对话，以及对130分钟飞行员访谈录音进行了人工标注，以解决专业领域特定的数据挑战。", "innovation": "研究提出了多种规范化方案来改进转录准确性和Word Error Rate（WER），并通过使用低秩适应（LoRA）进行高效的微调。经过优化，预训练的Whisper大型模型在没有规范化基线下的WER从68.49%显著降低到使用提出的规范化方案微调后模型的26.26%，从而提高了ASR性能。这项改进为处理专线领域如多语言飞行员对话提供了一个有效的解决方案。", "conclusion": "针对机舱内多语言飞行人员对话转录存在的特定挑战，研究展示了通过收集特定领域数据和多步骤处理方法（包括规范化方案和低秩适应微调）提升ASR系统转录准确性的可能性。新技术显著降低了错误率，对于未来在专业领域应用ASR技术具有重要意义。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21967", "html_url": "https://arxiv.org/abs/2506.21967", "title": "你比想象中更脆弱：工具集成LLM代理的稳定性", "title_en": "More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents", "authors": "Weimin Xiong,Ke Wang,Yifan Song,Hanchao Liu,Sai Zhou,Wei Peng,Sujian Li", "background": "当前对工具集成大语言模型（LLM）代理的评估主要集中在端到端的工具使用评估上，而忽视了其稳定性。这限制了它们在实际世界中的应用，因为在整个工具调用过程中，各种内部或外部因素可能导致代理崩溃或表现异常。现有研究未能全面评估代理在整个工具调用过程中的可靠性，因此本文通过研究代理在读取工具文档、选择工具和生成参数以及处理工具响应等各个阶段的错误易感性，旨在填补这一空白，提高代理的稳定性和可靠性，增强其在实际环境中的适用性与安全性。", "innovation": "本文通过深入分析工具集成LLM代理在诸多阶段的错误易感性，发现了代理在各个阶段都容易出现错误的现象，并且基于开源模型的代理比基于专有模型的代理更易受攻击。此外，还发现增大模型尺寸并未显著改善工具调用推理能力，反而可能使代理更易受冒充正常用户指令的攻击，从而增强了对代理稳定性的评估，为未来LLM的发展和评估提供了有价值的意见和建议。", "conclusion": "通过广泛的实验，我们发现代理在每个阶段都容易出现错误，基于开源模型的代理比基于专有模型的代理更容易受害。同时，增加模型大小并未显著改善工具调用推理能力，反而可能使代理更易受攻击。这一结果突显了评估代理稳定性的意义，并为未来的LLM开发和评估提供了重要的见解。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21864", "html_url": "https://arxiv.org/abs/2506.21864", "title": "DeepTalk: 向适应模态特定MoE无缝智能语音交互目标迈进", "title_en": "DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE", "authors": "Hang Shao,Heting Gao,Yunhang Shen,Jiawei Chen,Lijiang Li,Zuwei Long,Bo Tong,Ke Li,Xing Sun", "background": "传统的单模态大型语言模型（LLM）通过将一个大规模语言模型重新构造为能够同时生成语音和文本的语音语言模型（SLM），来实现多模态交互。然而，与模块化和对齐的大规模多模态语言模型相比，原生的大规模多模态语言模型保留了更多的言语特征，如情绪和语调，并能够直接在骨干LLM中生成语音响应，无需额外的语音解码器。这种集成也降低了响应延迟并提供了更流畅的交互。然而，原生大规模多模态语言模型由于可用于预训练MMLM的配对的语音-文本数据不足，发生了灾难性遗忘和性能下降等问题，同时需要大量的文本数据来预训练文本LLM。", "innovation": "提出了一种基于混合专家（MoE）架构的模态专家自适应学习框架——DeepTalk。DeepTalk能够根据LLM中的模态负载自动区分模态专家，然后对其进行专门的单一模态训练，之后进行联合多模态协作训练。相对于原生的大规模多模态语言模型(如GLM-4-Voice)，DeepTalk的性能下降仅为5.5%，远低于其他原生模型平均20%以上的性能下降，几乎与模块化MMLM相当。同时，端到端对话延迟保持在0.5秒以内，确保了无缝和智能的语音交互体验。", "conclusion": "DeepTalk显著改善了多模态交互中语音语言模型的负担，通过自适应专家学习和混合专家架构实现了模态特定的训练和余量操作，保持了较低的性能下降和快速的交互速度，为无缝智能语音交互提供了良好的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21974", "html_url": "https://arxiv.org/abs/2506.21974", "title": "除非经过实证可靠性的基准测试，否则不要信任生成型代理模仿社交网络上的通信", "title_en": "Don't Trust Generative Agents to Mimic Communication on Social Networks Unless You Benchmarked their Empirical Realism", "authors": "Simon Münker,Nils Schwager,Achim Rettinger", "background": "大型语言模型（LLMs）模仿人类行为的能力激发了大量计算社会科学研究。这些研究假设可以使用AI代理进行人类行为的实证研究。然而，关于这种假设在哪些条件下成立的研究结果存在分歧，因此需要更好地理解它们的实验设计之间的差异。本文关注使用LLMs模仿社交网络用户行为进行社交网络通信分析的研究。研究提供了正式的社交网络模拟框架，并专注于模仿用户通信的子任务。通过英语和德语两种语言的实证测试，研究结果表明，社交模拟应通过实证真实性进行验证，特别是在模拟组件拟合的设置中测量这一真实性。本文主张在应用生成型代理基础建模进行社会仿真时应更加严格。", "innovation": "本文提出了正式的社交网络模拟框架；通过英语和德语的实证测试研究了模仿用户行为的不同方法；强调了在特定的实证场景下验证社交模拟的重要性；倡导了在应用生成型代理基础建模进行社会仿真时的严格性标准。", "conclusion": "社交模拟应该通过实证真实性进行验证，特别是在模拟组件拟合的设置中测量这一真实性。本文建议在应用生成型代理基础建模进行社会仿真时应更加严格。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21972", "html_url": "https://arxiv.org/abs/2506.21972", "title": "提升攻击策略：利用大语言模型漏洞和绕过现代防御的混合方法", "title_en": "Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses", "authors": "Mohamed Ahmed,Mohamed Abdelmouty,Mingyu Kim,Gunvanth Kandula,Alex Park,James C. Davis", "background": "预训练语言模型（PTLMs）和大规模语言模型（LLMs）的应用日益广泛，但这些模型存在安全漏洞，可被用于攻击的策略利用这些弱点从而规避安全措施。主要的威胁包括字节级和提示级的突破。字节级攻击通过嵌入对抗序列，尽管对黑盒模型如GPT有效，但留有可检测的模式，并依赖基于梯度的标记优化；提示级攻击通过结构化的输入激发有害响应，但依赖迭代反馈，这可能是不可靠的。", "innovation": "提出了两种混合方法，结合了字节级和提示级技术，以增强不同类型PTLMs的突破效果。GCG + PAIR和新探索的GCG + WordGame混合方法在多个Vicuna和Llama模型上进行了评估，GCG + PAIR在未受保护的模型上提高了攻击成功率；例如，Llama-3的攻击成功率（ASR）达到了91.6%，比PAIR的58.4%基准基线显著增加。同时，GCG + WordGame保持了与WordGame一致的高攻击成功率，即使在Mistral-Sorry-Bench等更严格的评估者下，仍能维持超过80%的ASR。这些混合方法还保留了转移性，并可靠地突破了复杂的防御措施如梯度袖带和JBShield，这两种防御措施完全阻止了单一模式的攻击。", "conclusion": "这些研究结果揭示了当前安全堆栈中存在的以前未报道的漏洞，并突显了原始成功率和防御鲁棒性之间的权衡。强调了对适应性强的对手需要全面的安全保障。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22050", "html_url": "https://arxiv.org/abs/2506.22050", "title": "解读英汉新闻中的机器翻译语言特征：大模型 vs 神经机器翻译系统", "title_en": "Decoding Machine Translationese in English-Chinese News: LLMs vs. NMTs", "authors": "Delu Kong,Lieve Macken", "background": "本研究探讨了机器翻译输出（Machine Translationese，MTese）的语言特色，重点关注英文到中文新闻文本这一少有研究的语言对。该研究使用五层特征集构建了一个大规模数据集，并通过卡方排名算法在分类和聚类任务中进行特征选择。研究结果证实了NMTs和LLMs中MTese的存在，并指出原始中文文本几乎可以完美地区分出LLM和NMT的输出。研究还发现了机器翻译输出中的一些显著的语法规则和词汇使用模式，并通过对比LLMs和NMTs在分类准确性、词汇多样性、括号使用等方面的能力。此外，翻译专用的LLMs在词汇多样性方面表现较低，但在因果关联词的使用上表现较高。最后，该研究未发现中国公司开发的LLMs与外国开发的LLMs之间的显著差异。", "innovation": "研究采用大规模数据集和五层特征集，通过卡方排名算法分析不同类型的LLMs和NMTs在翻译新闻文本时的语言表达差异。该研究特别关注LLMs和NMTs在词汇多样性、使用括号、因果关联词等方面的特性，并揭示了翻译专用LLMs（翻译特定的大型语言模型）与通用的LLMs之间的差异。此外，研究也发现了中国公司开发的LLMs与外国公司之间的相似之处。", "conclusion": "研究证实了机器翻译输出中特有的MTese的存在，并通过分类精度、词汇多样性、括号使用等多个维度对比了LLMs和NMTs。原始中文文本与机器翻译输出之间的差异明显，并且发现翻译专用的LLMs在词汇多样性方面表现较低，但在因果关联词的使用上有了提升。研究未发现中国公司开发的LLMs与外国LLMs之间有显著差异。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22038", "html_url": "https://arxiv.org/abs/2506.22038", "title": "Can Peter Pan Survive MT? A Stylometric Study of LLMs, NMTs, and HTs in Children's Literature Translation", "title_en": "Can Peter Pan Survive MT? A Stylometric Study of LLMs, NMTs, and HTs in Children's Literature Translation", "authors": "Delu Kong,Lieve Macken", "background": "本研究旨在从文体学角度评估机器翻译（MTs）与人工翻译（HTs）在英译中儿童文学翻译（CLT）中的性能。研究选取了包含21个翻译版本的彼得潘语料库，其中分为7个人工翻译、7个大型语言模型翻译和7个神经机器翻译输出。分析使用通用特征集（包括词汇、句法、可读性和n-gram特征）和创意文本翻译（CTT）特定特征集，以捕捉重复、节奏、可翻译性和其他层面的指标，共计447个语言特征进行分类和聚类分析，揭示不同翻译方式之间的差异性特点，尤其是HTs与MTs之间的显著差异以及不同模型在特定CTT特征上的表现差异。", "innovation": "研究创新点在于使用特定于创意文本翻译（CTT）的特征集对不同的翻译方式进行文体学分析，并且通过实证研究展示了大型语言模型（LLMs）在与人工翻译接近的优等特质上的潜力，这些发现对于理解机器翻译在儿童文学翻译中的适用性和发展具有重要意义。", "conclusion": "研究结果显示，在通用特征集上，HTs和MTs在连接词分布和1-gram词频‘一阳’比率上存在显著差异，而NMTs和LLMs在描述词使用和副词比率上表现出显着差异。在创意文本翻译特定特征上，LLMs的表现优于NMTs，并且更接近于HTs的风格，展示了LLMs在儿童文学翻译中的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22098", "html_url": "https://arxiv.org/abs/2506.22098", "title": "在线辩论中参与驱动语言复杂性", "title_en": "Involvement drives complexity of language in online debates", "authors": "Eleonora Amadori,Daniele Cirulli,Edoardo Di Martino,Jacopo Nudo,Maria Sahakyan,Emanuele Sangiorgio,Arnaldo Santoro,Simon Zollo,Alessandro Galeazzi,Niccolò Di Marco", "background": "语言是人类社会的基本要素，不断受到社会变化和文化互动的影响。技术进步极大地改变了沟通方式，社交媒体作为一股重要力量，整合了娱乐内容和复杂的社会动态。随着这些平台重塑公共言论，分析用户生成内容的语言特征对于理解其更广泛的社会影响至关重要。本文通过研究推特上具有影响力的用户关于全球重要且争议性话题（新冠疫情、COP26气候大会和俄罗斯-乌克兰战争）的内容复杂性，探讨了不同维度（账号类型、政治倾向、内容可靠性、情绪）上语言使用的差异。研究表明，参与度对在线语言复杂性有着显著影响。", "innovation": "采用多种文本复杂度测量方法，评估不同类型账号、不同政治倾向、不同可靠性和情绪内容的语言复杂性差异。发现不同类型账号、带有不同政治倾向的个人和组织之间、可靠性和复杂程度较高和较低之间存在显著差异。负面和冒犯性内容的创作者更倾向于使用复杂语言，且持有相似立场和可靠性水平的用户通常会达到一种共同的专业术语。", "conclusion": "研究提供了在线平台社会语言动态的新见解，并加深了对语言如何反映在线空间中的意识形态和社会结构的理解。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21961", "html_url": "https://arxiv.org/abs/2506.21961", "title": "PapersPlease: 基于ERG理论评估大型语言模型动机价值的标准", "title_en": "PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language Models Based on ERG Theory", "authors": "Junho Myung,Yeon Su Park,Sunwoo Kim,Shin Yoo,Alice Oh", "background": "通过对角色扮演情境的评估性能和偏见，大型语言模型（LLMs）的行为日益受到关注。LLMs在模拟中常常表现出偏见行为，这促使研究者开发了PapersPlease这一基准测试。该基准包含3,700个道德困境，旨在研究LLMs在满足人类不同层次需求时的决策过程。实验设置中，LLMs扮演移民官员的角色，根据简短的个人叙述决定是否批准入境。这些叙述基于ERG理论，将人类需求分为三个层次：存在、联系和成长需求。", "innovation": "PapersPlease引入了一种新颖的方法，通过ERG理论设计道德困境来评估LLMs。研究发现，LLMs在决策过程中表现出统计显著的模式，表明它们存在潜在的偏好。此外，研究显示，在结合社会身份因素后，LLMs的表现呈现出基于动机需求和身份线索的不同反应，而且对被边缘化身份的拒绝率较高。所有数据均可公开访问。", "conclusion": "研究分析了六种LLMs的决策模式，揭示了LGMs在处理人类需求方面的偏好模式，同时也探讨了将社会身份纳入叙事的影响。结果显示在决策过程中，LLMs的行为存在可识别的偏好，且这些偏好会根据不同的社会身份变化。所有研究数据已公开，供进一步分析。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22105", "html_url": "https://arxiv.org/abs/2506.22105", "title": "在GPT-2中识别动词变形电路", "title_en": "Identifying a Circuit for Verb Conjugation in GPT-2", "authors": "David Demitri Africa", "background": "研究者们在模型可解释性的背景下，尝试理解大语言模型内部机制，特别是探索特定语言任务中不同部分的贡献。该研究聚焦于GPT-2小型模型在处理主谓一致问题时的机制，展示了近年来模型可解释性研究的一个典型案例。研究提供了一种新的方法来识别并解析执行特定任务(如动词变形)的子网络或“电路”。", "innovation": "研究采用了一系列技术手段，包括直接路径修补的自动电路发现验证、直接logit归因等，成功地 isolating了一条与主谓一致任务相关的候选电路。研究结果表明，仅需一小部分网络组件即可实现对该基础任务的性能，但更复杂的情况下需要更多组件的参与。这一发现为模型可解释性研究提供了新的思路和方法，特别是在识别执行特定任务的子网络方面。", "conclusion": "研究结果显示，GPT-2小型模型处理主谓一致任务时并非依赖于整个网络结构，而可能由特定的部分负责这一任务。这种方法仅需要一小部分网络组件，但对于更复杂的情况，则需要更多的组件。这一发现不仅有助于提升模型的可解释性，也为更深入地理解大语言模型内部工作机制提供了理论基础和支持。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22058", "html_url": "https://arxiv.org/abs/2506.22058", "title": "失之于推理开始", "title_en": "Lost at the Beginning of Reasoning", "authors": "Baohao Liao,Xinyi Chen,Sara Rajaee,Yuhui Xu,Christian Herold,Anders Søgaard,Maarten de Rijke,Christof Monz", "background": "近年来，大型语言模型（LLMs）在复杂推理能力方面取得了显著进步，尤其是在扩展链式思考（CoT）推理过程中，通过引入回溯、自我反思和自我纠错等机制。尽管有这些进展，但在长链式思考推理过程中模型的自我纠错能力仍然未得到充分探索。近期的研究发现表明，这些模型往往在推理过程中存在冗余的思考过程。研究发现，在推理的早期步骤引入的错误会对后续推理的质量产生显著影响。这种现象在两个最先进的开源推理模型家族——DeepSeek-R1和Qwen3中得到了一致的观察。", "innovation": "本文通过实证分析方法，提出了一个有效的采样策略，该策略利用奖励模型来识别并保留高质量的第一步推理，同时丢弃低质量的推理步骤。该策略在不影响准确性的前提下，显著降低了推理成本，最高可达70%的降低。此外，作者还提出了一种新的基准测试，专门针对故意引入缺陷的第一步推理，用于系统地评估模型的自我纠错能力，为未来LLMs的稳健推理研究奠定了基础。", "conclusion": "本文通过实验证明，推理的第一步对其最终预测具有重要影响，并提出了一种高效的采样策略来改进自我纠错能力，同时引入了一个新的基准测试，以全面评估模型的自我纠错能力，为进一步研究LLMs的稳健推理提供了新的方向。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22062", "html_url": "https://arxiv.org/abs/2506.22062", "title": "MDC-R：带参考的Minecraft对话语料库", "title_en": "MDC-R: The Minecraft Dialogue Corpus with Reference", "authors": "Chris Madge,Maris Camilleri,Paloma Carretero Garcia,Mladen Karan,Juexi Shao,Prashant Jayannavar,Julian Hough,Benjamin Roth,Massimo Poesio", "background": "Minecraft Dialogue Corpus (MDC) 是一个任务导向的、多轮次、情境化的对话数据集，用于动态环境中的对话。MDC 引发了大量的注释努力，因为这种设置产生了有趣的语言现象。现有的 MDC 对语音参考的支持不足，缺乏专家对代词和指示代词的注释，因此研究者希望补充该数据集，以便更好地研究参考表达的理解。", "innovation": "本文引入了 Minecraft Dialogue Corpus with Reference (MDC-R)，在原始 MDC 的基础上增加了专家对代词和指示代词的标注。这种方法弥补了原数据集在参考注释方面的不足，为研究指代表达理解和相关研究提供了一个有价值的资源。", "conclusion": "本文细致讨论了MDC-R的标注方法以及数据集的构成，还进行了简要实验以证明MDC-R在指代表达理解方面的有用性，并提供了定量和定性的数据分析结果，证明了MDC-R的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22141", "html_url": "https://arxiv.org/abs/2506.22141", "title": "DAPFAM：在家庭级别聚合的意识领域专利检索数据集", "title_en": "DAPFAM: A Domain-Aware Patent Retrieval Dataset Aggregated at the Family Level", "authors": "Iliass Ayaou(ICube),Denis Cavallucci(ICube),Hicham Chibane(ICube)", "background": "在现有的公开可访问的专利检索数据集中，人们经常忽略了内在领域和外领域标记的明确性、多司法管辖区涵盖范围、查询领域代表性的平衡以及可支持中等计算资源下子文档级实验的可管理规模。这些因素在现有的数据集中常常被忽视，对于改进专利检索系统的效率和精确度至关重要。因此，缺乏有效的多领域层次结构和适当规模的数据集成为了改进现有系统的一个重要瓶颈。", "innovation": "本文提出了DAPFAM，一个新的开源领域意识专利检索数据集，数据集构建在简单的家庭级基础上。该数据集包含1,247个领域平衡的完整文本查询家庭和45,336个完整文本目标家庭。通过清晰的相关性判断（正向/反向引用作为正链接，随机负样本）以及基于国际专利分类（IPC）代码的新的标签方案，确保在领域内或领域外关系的明确标记，生成了49,869个评估对。数据集在多司法管辖区覆盖，无需大量的预处理步骤即可进行检索评估，大小可管理，适合资源有限的实体进行中等计算成本下的子文档级别检索实验。", "conclusion": "介绍了数据集的三步数据处理管道，并提供了全面的数据集统计信息，同时使用词汇和神经检索方法进行了基线实验。这些基线实验突出显示了跨领域专利检索中的重大挑战。数据集将会被公开访问。（当前可从这个仓库获取：this https URL）"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22305", "html_url": "https://arxiv.org/abs/2506.22305", "title": "使用大型语言模型在结构化数据中检测个人数据", "title_en": "Detection of Personal Data in Structured Datasets Using a Large Language Model", "authors": "Albert Agisha Ntwali,Luca Rück,Martin Heckmann", "background": "本文提出了一种创新的方法，用于在结构化数据集中检测个人数据。这种方法基于最新的大型语言模型GPT-4o，并利用了上下文信息。该研究将新方法与Microsoft Presidio和CASSED进行了比较，评估了多组数据集的表现，包括合成数据集DeSSI、Kaggle和OpenML收集的数据集，以及包含重症监护室患者信息的真实世界数据集MIMIC-Demo-Ext。研究表明，不同数据集对检测性能的影响显而易见。", "innovation": "文章的关键创新在于融合了上下文信息：除了特征名称和值，还利用了数据集中其他特征名称以及描述信息。特别地，研究发现对于Kaggle和OpenML数据集，上下文信息对于个人数据检测有很大帮助，这些数据集上的表现表明，CASSED和Presidio等方法未充分利用数据上下文，而基于GPT-4o的方法表现更佳", "conclusion": "研究表明，更多包含个人数据的真实世界数据集的可用性将极大促进该领域的发展。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22157", "html_url": "https://arxiv.org/abs/2506.22157", "title": "训练语言模型进行评估以获得更好的细化", "title_en": "Training Language Model to Critique for Better Refinement", "authors": "Tianshu Yu,Chao Xiang,Mingchuan Yang,Pei Ke,Bosi Wen,Cunxiang Wang,Jiale Cheng,Li Zhang,Xinyu Mu,Chuxiong Sun,Minlie Huang", "background": "大型语言模型（LLMs）展示了显著的评估和批判能力，能够在各种任务中提供有价值的反馈并识别缺陷。然而，有限的研究探讨了哪种类型的批评最有效于改进模型响应，以及如何生成这样的批评。现有方法通常需要直接评估批评偏好，这使得批评优化的过程复杂化并且效率较低。为了解决这些问题，本文提出了Refinement-oriented Critique Optimization (RCO)，通过使用批评信号，使得批评模型根据批评引导演员模型进行响应细化。RCO 利用反馈循环，通过批评引导模型的调整来量化批评的有效性，从而减少了直接评估批评偏好的需求。该框架已在五个任务上进行了评估，分别是对话生成、摘要、问答、数学推理和代码生成，并展示了其在批评质量和细化结果上的显著优势。", "innovation": "提出了一种名为Refinement-oriented Critique Optimization (RCO)的框架，它通过使用从改进响应中得出的线索来训练批评模型。该方法采用了一个反馈循环，其中的批评模型生成的批评可以引导演员模型做出响应调整。该框架通过专注于那些导致更好改善的批评，减少了直接评估批评偏好的必要性，从而确保驱动有意义改进的批评得到奖励。", "conclusion": "RCO 框架在五种任务（对话生成、摘要、问答、数学推理和代码生成）上进行了评估，并展示了相较于传统方法和开源模型在批评质量和细化结果方面的显著优势。本文的主要贡献包括介绍 RCO、一种基于细化响应偏好的新颖监督方案，以及全面的实验结果，这些结果突显了该方法在增强LLM批评-细化循环方面有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22366", "html_url": "https://arxiv.org/abs/2506.22366", "title": "理解消息层次结构的解析动作为何不是随机的", "title_en": "Why Are Parsing Actions for Understanding Message Hierarchies Not Random?", "authors": "Daichi Kato,Ryo Ueda,Yusuke Miyao", "background": "如果人类通过随机选择解析动作来理解语言，那么可能需要构建一种能够在任何层次结构下被解释的 robust 符号系统。然而，人类的解析策略似乎并不遵循这种随机模式。之前关于带有层次偏见模型的新兴通信研究显示，采用随机解析策略（与人类语言理解显著不同）的代理可以在通信准确性方面表现出色。本文通过两个简单且自然的实验修改来研究这一问题：(I) 使用具有更复杂层次结构的输入使得随机解析使得语义解释更加困难；(II) 将与意外相关（影响自然语言中文字符序）的项纳入目标函数，进而探讨在这些变化下，采用随机解析策略的代理是否仍能保持高通信准确性。", "innovation": "本文提出了一种新的实验设置，通过使用更复杂的层次结构输入和引入与意外相关项的目标函数，以研究随机解析策略在保留高通信准确性方面的表现。这是通过对比原来随机解析策略与新设置下的表现来实现的创新点。", "conclusion": "通过新实验方法，研究发现即使在使用更复杂层次结构输入和引入与意外相关项的目标函数的情况下，采用随机解析策略的代理仍然可以保持高水平的通信准确性。这一结果表明，人类解析策略可能不仅仅依赖于意外信息，而可能还有其他机制影响着解析过程。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22143", "html_url": "https://arxiv.org/abs/2506.22143", "title": "SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition", "title_en": "SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition", "authors": "Muhammad Umar Farooq,Oscar Saz", "background": "该论文研究了各种语音SSL模型在方言阿拉伯语（DA）和阿拉伯语-英语代码混合（CS）语音上的性能。针对数据稀缺的问题，引入了一种修改后的音频拼接方法来生成人工代码混合语音数据。通过使用提出的Spliced-Audio Generated (SAGE)数据对已经 fine-tuned 的 SSL 模型进行微调，阿拉伯语和英语代码混合基准模型的Word Error Rate (WER)绝对改进了7.8%。同时，利用Experience Replay (ER)启发式方法提高泛化能力，减少灾难性遗忘。结合一个领域外的3-克gram语言模型将整体平均WER从31.7%降低到26.6%。代码混合基准的少量微调进一步将WER降低了4.9%。在阿拉伯语-英语代码混合基准上31.1%的WER超过了大规模多语言模型，包括USM和Whisper-large-v2（分别大十倍以上）的绝对改进为5.5%和8.4%.", "innovation": "提出了Spliced-Audio Generated (SAGE)数据生成方法，用于改进低资源阿拉伯语-英语代码混合语音识别中的基础模型性能。还提出了Experience Replay (ER)启发式的策略来增强通过对不同方言和代码混合语音的泛化能力，同时减少灾难性遗忘。此外，结合领域外的3-克gram语言模型进一步降低了Word Error Rate (WER)，并在阿拉伯语-英语代码混合基准上实现了显著的性能提升，超越了多个大规模多语言模型的性能。", "conclusion": "通过Spliced-Audio Generated (SAGE)数据生成、Experience Replay (ER)启发式的策略和少量微调的结合，论文显著提高了阿拉伯语-英语代码混合语音的识别性能，超越了现有大规模多语言模型的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22396", "html_url": "https://arxiv.org/abs/2506.22396", "title": "QuickSilver -- 通过动态令牌停止、KV 缓存跳过、上下文令牌融合及自适应马蒂罗斯卡量化加速大型语言模型推理", "title_en": "QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization", "authors": "Danush Khanna,Aditya Kumar Guru,Srivarshinee Sridhar,Zidan Ahmed,Rubhav Bahirwani,Meetu Malhotra,Vinija Jain,Aman Chadha,Amitava Das,Kripabandhu Ghosh", "background": "推理占大型语言模型(Large Language Model, LLM)部署中延迟和能耗的绝大部分，往往超过总消耗的90%。尽管在训练效率方面取得了显著进展，但在运行时优化仍是关键瓶颈，尤其是在自动回归解码中。现有优化方法比如剪枝、量化、早退出和推测解码往往需要重新训练、改变架构或者破坏推理兼容性。", "innovation": "我们提出了QuickSilver，一个模块化、基于令牌的框架，能够在推理时实现语义适应性，但不需要改变模型权重或结构。QuickSilver集成了四个协同机制：动态令牌停止，可以停止已收敛表示的令牌的计算；KV 缓存跳过，可选择地抑制内存写入以减少注意力计算开销；上下文令牌融合，将冗余的令牌合并到共享路径中以缩短序列长度。QuickSilver完全在冻结的密集模型上运行，并不需要辅助网络。该方法在GPT-2和Llama-2上分别对WikiText-103和C4数据集实现了39.6%的FLOP减少，并且对困惑度的影响可以忽略不计（<=0.2）。", "conclusion": "QuickSilver通过动态令牌停止、KV 缓存跳过、上下文令牌融合及自适应马蒂罗斯卡量化，在不改变模型权重和结构的情况下，在推理时实现了语义适应性，显著减少了FLOP开销，且对模型性能的影响最小。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22232", "html_url": "https://arxiv.org/abs/2506.22232", "title": "通过内生学习利用政治偏见测试LLMs", "title_en": "Leveraging In-Context Learning for Political Bias Testing of LLMs", "authors": "Patrick Haller,Jannis Vamvas,Rico Sennrich,Lena A. Jäger", "background": "已有大量研究通过让大型语言模型（LLMs）回答政治问题来评估其潜在偏见，但这种方法稳定性较差，模型间比较不可靠。我们提出，LLMs需要更多的背景信息以提高其准确性。因此，我们新提出了一种探针任务，即问卷建模（QM），该方法利用人类调查数据作为内生示例。实验结果表明，QM可以提高问题导向的偏见评估稳定性，还可以用于比较指令调优模型与其基础版本。我们的实验表明，指令调优确实可以改变偏见方向，且更大的模型能更有效地利用内生示例，一般在QM中的偏见分数也较低。研究数据和代码已公开。", "innovation": "我们提出了一种新的探针任务，即问卷建模（QM），该任务使用人类调查数据作为内生示例，以增强LLMs的准确性，并通过实验验证了QM在提高问题导向的偏见评估稳定性方面的有效性。我们还发现，更大的模型能更好地利用内生示例，并且一般展现出较低的偏见分数。最后，我们展示了QM可以用于比较指令调优模型与其基础版本。实验结果表明，指令调优确实会影响偏见的方向，且大型模型可以更有效地利用内生示例。", "conclusion": "研究表明，LLMs需要更多的背景信息来提高其准确性。问卷建模（QM）可以提升问题导向的偏见评估稳定性，并可用于比较指令调优模型与其基础版本。实验数据和代码都已经公开，表明指令调优可以改变偏见方向，且大型模型能更有效利用内生示例，通常在QM中的偏见分数较低。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22316", "html_url": "https://arxiv.org/abs/2506.22316", "title": "评估LLM-as-a-Judge中的评分偏差", "title_en": "Evaluating Scoring Bias in LLM-as-a-Judge", "authors": "Qingquan Li,Shaoyu Dou,Kailai Shao,Chao Chen,Haixiang Hu", "background": "大型语言模型（LLMs）的出色性能促进了LLM-as-a-Judge的应用，即使用LLMs作为复杂任务的评估者。这种应用已广泛应用于自然语言处理（NLP）、偏好学习以及特定领域。然而，LLM-as-a-Judge中存在着各种偏差，这些偏差影响了评估的公平性和可靠性。目前，关于评估或缓解LLM-as-a-Judge中的偏差的研究主要集中在基于比较的评估上，而针对基于评分的评估的系统研究依然不足。", "innovation": "定义了LLM-as-a-Judge中的评分偏差，即评分差异发生变化，而评分判断模型出现偏差时。提供了全面评估评分偏差的框架，通过数据合成扩展现有LLM-as-a-Judge基准，构建评估数据集，并设计了多方面的评估指标。实验结果表明，现有的评分判断模型的稳定性受到评分偏差的影响。进一步的探讨实验和讨论提供了关于评分提示模板设计以及评分偏差缓解的有价输入.", "conclusion": "现有的评分判断模型的评分稳定性受到了评分偏差的影响。需要进一步设计评分提示模板，并缓解评分偏差问题，尤其是在评分标准、评分ID和参考答案选择方面."}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22402", "html_url": "https://arxiv.org/abs/2506.22402", "title": "改进捷克语语法纠错：多实验方法的见解", "title_en": "Refining Czech GEC: Insights from a Multi-Experiment Approach", "authors": "Petr Pechman,Milan Straka,Jana Straková,Jakub Náplava", "background": "本文介绍了一个实现捷克语语言最先进的语法纠错（GEC）系统。系统采用基于神经网络的翻译方法，并使用Transformer架构。该系统的关键特征在于其实时合成生成管道，该管道通过引入语言无关和捷克语特有的错误动态地增加句子中的人工错误。研究者对该系统的性能进行了广泛测试，并深入探究了捷克语GEC数据集、错误生成策略、领域平衡、标记粒度、模型大小和调整期间的数据尺度等参数的影响。此外，该研究还评估了大型语言模型在捷克语GEC中的性能，分别在最终用户和专家微调场景中进行了评估。", "innovation": "研究的创新之处在于采用了实时合成生成管道，该管道能够动态地为句子添加人工错误，这些错误既包含语言通用的也包含捷克语特有的错误。研究还通过广泛的实验，系统性地评估了多个关键参数对GEC系统性能的影响，包括数据集、错误生成策略、领域平衡、标记粒度、模型大小以及调整期间的数据量，并且该模型在性能和计算效率上都优于其他模型。", "conclusion": "该研究最佳表现的模型在性能和计算效率上都优于其他模型。研究结果表明，该模型在捷克语GEC任务中表现优异，并且系统中实时合成生成管道是增强模型性能的关键因素。此外，研究还采用了开源性质，提供了源代码和训练模型的链接。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21656", "html_url": "https://arxiv.org/abs/2506.21656", "title": "精细偏好优化提高VLM中的空间推理能力", "title_en": "Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs", "authors": "Yifan Shen,Yuanzhe Liu,Jingyuan Zhu,Xu Cao,Xiaofeng Zhang,Yixiao He,Wenming Ye,James Matthew Rehg,Ismini Lourentzou", "background": "目前的视觉-语言模型（VLMs）在细粒度的空间推理方面表现出色，但在需要多步逻辑和精确的空间对齐的情况下存在局限性。这使得这些模型在处理复杂的地理问题和需求多步骤逻辑的空间推理时变得困难。本文旨在通过引入SpatialReasoner-R1模型解决这一问题，该模型是专门为解决这些局限性而设计的。", "innovation": "1. 设计了多模型蒙特卡洛树搜索（M3CTS）方法来生成多样且逻辑一致的长链条推理路径，为提升空间推理提供了高质量的监督。\n2. 提出了细粒度直接偏好优化（fDPO），该方法通过空间奖励机制评估候选答案的视觉一致性、空间对齐和逻辑连贯性，引入了针对描述性定位和逻辑推理的段级偏好粒度，指导细化偏好优化过程。\n3. 实验结果表明，fDPO在空间质量任务中平均提高了4.1%，在空间数量任务中提高了9.0%，SpatialReasoner-R1使用fDPO训练后，在SPATIALRGPT-Bench上取得了领先的表现，优于最强基线9.8%的平均准确性，同时在常规视觉-语言任务中维持了竞争力。", "conclusion": "SpatialReasoner-R1模型通过引入精细偏好优化（fDPO），显著提升了视觉-语言模型在空间推理任务中的表现，在SPATIALRGPT-Bench上达到了新的最佳性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21913", "html_url": "https://arxiv.org/abs/2506.21913", "title": "HyReC: 探索用于中文的混合式检索模型", "title_en": "HyReC: Exploring Hybrid-based Retriever for Chinese", "authors": "Zunran Wang,Zheng Shenpeng,Wang Shenglan,Minghui Zhao,Zhonghua Li", "background": "混合式的检索方法统一了密集向量和基于词汇表的检索，由于性能提升而在行业中引起了广泛关注。然而，尽管这些混合模型取得了令人期待的结果，它们在中国检索环境中的应用仍然鲜有探索。", "innovation": "HyReC 是一种专为中文应用场景优化的端到端混合式检索方法。HyReC 通过将术语的语义联合融入表示模型来提高性能。此外，它还配备了全局-局部感知编码器（GLAE），促进词汇表检索和密集检索之间的语义一致性共享，同时最小化彼此之间的干扰。为更进一步细化对齐，HyReC 引入了规范化模块（NM），促进检索方法之间的相互收益.", "conclusion": "HyReC 在 C-MTEB 检索基准测试上进行了评估，以证明其有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21825", "html_url": "https://arxiv.org/abs/2506.21825", "title": "探索ChatGPT发布后科学文献可读性变化", "title_en": "Exploring the change in scientific readability following the release of ChatGPT", "authors": "Abdulkareem Alsudais", "background": "随着可访问的大语言模型的兴起及其日益增长的流行度，它们对科研写作和发表等方面的影响引起了广泛关注，尤其是科学家们如何撰写和发布他们的研究成果。本研究旨在分析2010年到2024年6月7日期间在arXiv.org上发布的所有摘要数据，以评估其可读性的演变，并确定ChatGPT于2022年11月发布后是否出现了显著变化。使用四套标准的可读性公式来计算每篇论文的可读性分数，将其分类为不同的可读性级别。然后，按年份和八个主要类别来聚合这些可读性得分。研究结果表明，可读性呈现出逐年下降的趋势，表明摘要可能变得越来越复杂。此外，ChatGPT发布后，2023年及2024年分析期间的可读性发生了显著变化。在各个研究类别中，也发现类似的趋势，大多数类别在2023年至2024年间经历了可读性的显著变化。这些发现揭示了可读性变化的更广泛趋势，并表明AI可能对科学写作产生了影响", "innovation": "本研究采用量化分析方法，通过使用标准可读性公式来评估arXiv上论文摘要的可读性，并探究了可读性的变化趋势及其与ChatGPT发布的时间节点之间的相关性。研究还详细分析了不同类型科研论文的可读性变化，揭示了AI对科学写作可能产生的影响", "conclusion": "研究结果表明，摘要的可读性正在逐年下降，且在ChatGPT发布后出现了显著变化。这些变化可能反映了AI技术对企业科研写作的影响，提示了未来科研通信中可能出现的趋势"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21845", "html_url": "https://arxiv.org/abs/2506.21845", "title": "3Description: 一种直观的人工智能协作3D建模方法", "title_en": "3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach", "authors": "Zhuodi Cai", "background": "传统3D建模存在访问性和易用性挑战，非专业人员难以使用复杂的3D建模工具创建3D模型。鉴于此，本研究提出了3Description，这是一种实验性的人机协作方法，旨在通过语音和手势描述来实现非专业人员的3D模型共同创作。研究通过定性研究、产品分析和用户测试，结合自然语言处理和计算机视觉等人工智能技术，来满足这一需求。研究还强调了Web技术的跨平台优势，使得用户能够直接通过网页进行描述和模型调整。", "innovation": "3Description 通过引入自然语言处理和计算机视觉技术，结合Web平台，实现了非专业人士使用语音和手势进行3D模型的轻松创作。这种方法不仅提高了3D建模的访问性和易用性，还在人工智能时代增加了人类参与度，促进了人与AI的共同创作，而非盲目依赖技术。", "conclusion": "3Description 通过结合人工智能技术，为非专业用户提供了一种创作3D模型的全新方法，使得更多的人能够参与到未来3D世界的构建中，同时促进人与AI之间的合作，保护了人类的创造力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22403", "html_url": "https://arxiv.org/abs/2506.22403", "title": "HyperCLOVA X THINK技术报告", "title_en": "HyperCLOVA X THINK Technical Report", "authors": "NAVER Cloud HyperCLOVA X Team", "background": "该论文介绍了HyperCLOVA X THINK，这是HyperCLOVA X家族中的第一个注重推理的大型语言模型，预训练了大约6万亿高质量的韩语和英语词汇，并结合了目标化的合成韩语文本数据。它是一个平衡计算和内存使用的Peri-LN Transformer，通过一个三阶段的教学法进行预训练，扩展上下文窗口至128K个令牌，并通过带有验证奖励支持的强化学习进行监督微调，支持详细的理由和简洁的答案模式。该模型在类似规模的模型上在韩国定向基准如KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench中表现良好，同时保持语言一致性与翻译质量。此外，视觉增强变体在KCSAT STEM基准测试中达到了或超过了GPT-4.1，所有这些均以比现有类似规模模型低得多的训练计算实现。", "innovation": "1. 预训练了大约6万亿高质量的韩语和英语词汇，结合了目标化的合成韩语文本数据。\n2. 使用Peri-LN Transformer，并进行了一个平衡计算和内存使用的三阶段预训练。\n3. 支持带有验证奖励支持的强化学习进行监督微调，同时支持详细的理由和简洁的答案模式。\n4. 在与之相当规模的模型上，在Korean相关基准项达到了令人竞争的表现。\n5. 采用了视觉增强技术，并在KCSAT STEM基准测试中达到了或超过了GPT-4.1，而训练计算量显著减少。\n6. 提出了可应用于HyperCLOVA X THINK的剪枝与蒸馏技术，使得模型更易于开源和商业使用。", "conclusion": "HyperCLOVA X THINK作为韩语AI创新的稳健基础，以及全球研究社区有价值的资源而定位。此外，这种方法和模型设计以显著低于现有相似规模模型的训练计算资源实现了卓越的性能，为韩语大型语言模型的发展和应用树立了新的基准。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21805", "html_url": "https://arxiv.org/abs/2506.21805", "title": "CitySim: 使用大规模LLM驱动代理模拟建模城市行为和城市动态", "title_en": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation", "authors": "Nicolas Bougie,Narimasa Watanabe", "background": "理解并模拟人类在城市中的行为对于社会学、行为研究和城市规划至关重要。以往的研究往往依赖于僵化的、手工制作的规则，这限制了其模拟复杂意图、长期计划和适应性行为的能力。为解决这些挑战，我们提出了一种城市模拟器（CitySim），它利用了大型语言模型在人类级别智能方面取得的突破。", "innovation": "CitySim 通过一种递归的价值驱动方法使代理生成现实的日常计划，平衡了强制性活动、个人习惯和情境因素。为了实现长期、逼真的模拟，赋予代理信念、长期目标和空间记忆以实现导航。此外，CitySim 的表现比先前的工作更贴近现实人类，无论是微观层面还是宏观层面。通过模拟数万个代理并评估他们在各种现实场景下的集体行为，展示了 CitySim 的规模性和灵活性，作为理解和预测城市现象的试验平台。", "conclusion": "结果表明，CitySim 是一个可扩展的、灵活的城市现象理解和预测的试验平台。通过建模大量代理和评估他们在多种真实场景中的集体行为，CitySim 成功地估计了人群密度、预测了地点的受欢迎程度，并评估了幸福感。CitySim 展示了与真实人类行为更紧密的契合度，并作为城市行为和城市动态研究的强大工具。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21931", "html_url": "https://arxiv.org/abs/2506.21931", "title": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation", "title_en": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation", "authors": "Reza Yousefi Maragheh,Pratheek Vadla,Priyank Gupta,Kai Zhao,Aysenur Inan,Kehui Yao,Jianpeng Xu,Praveen Kanumala,Jason Cho,Sushant Kumar", "background": "Retrieval-Augmented Generation (RAG) 在通过大型语言模型提示引入外部上下文方面展示了增强推荐系统的能力。然而，现有的基于RAG的方法通常依赖于静态检索启发式方法，在动态推荐情景下未能捕捉到用户的微妙偏好。", "innovation": "该研究提出了ARAG，一个集成了多智能体协作机制的检索增强生成框架，用于个性化推荐。它引入了四个专门的LLM智能体：用户理解智能体、自然语言推理（NLI）智能体、上下文总结智能体和项目排行智能体，以更好地理解用户的长期和会话行为，生成基于上下文契合度的推荐列表，且实验结果显示出ARAG比标准RAG和基于最近性的基线方法有显著的性能提升。", "conclusion": "实验结果显示ARAG在NDCG@5和Hit@5上分别相比基线方法提高了42.1%和35.5%。此外，通过对ARAG不同组件进行消融研究，进一步证明了整合主动推理到检索增强推荐的有效性，并为基于大语言模型的个性化提供了新的研究方向。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21865", "html_url": "https://arxiv.org/abs/2506.21865", "title": "河之回响：用于古老黄河文化的实时互动数字系统", "title_en": "RiverEcho: Real-Time Interactive Digital System for Ancient Yellow River Culture", "authors": "Haofeng Wang,Yilin Guo,Zehao Li,Tong Yue,Yizong Wang,Enci Zhang,Rongqun Lin,Feng Gao,Shiqi Wang,Siwei Ma", "background": "黄河被视为中国的母亲河，是人类文明的摇篮之一。古老黄河文化是人类艺术历史不可或缺的一部分。为了保护和传承古老黄河文化，设计了河之回响（RiverEcho），一个实时互动系统，使用大规模语言模型和文化知识数据集来响应语音查询，并通过面部生成的数字人类进行解释。", "innovation": "构建了专注于古老黄河文化的知识数据库，包括历史文本的收集和处理流程。实验结果表明，利用所提数据集上的检索增强生成（RAG）增强了大型语言模型（LLM）的响应质量，使系统能够生成更专业和信息丰富的回应。此项工作不仅丰富了推广黄河文化的手段，还为用户提供更深刻的文化洞察。", "conclusion": "河之回响不仅在保护和传承古老黄河文化方面作出了贡献，还通过创新的技术手段如大规模语言模型和检索增强生成为用户提供了更深入的文化理解。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21839", "html_url": "https://arxiv.org/abs/2506.21839", "title": "GenEscape：生成逃脱房间谜题的分层多智能体生成方法", "title_en": "GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles", "authors": "Mengyi Shan,Brian Curless,Ira Kemelmacher-Shlizerman,Steve Seitz", "background": "文本到图像模型在生成图像时往往难以处理空间关系和使用推理，而基模型在这方面表现尤为不足。本文针对这一挑战，提出了一个分层多智能体框架，用于生成同时具备视觉吸引力、逻辑稳定性和智力刺激性的逃脱房间谜题图像。该框架将生成任务细分为功能性设计、符号场景图推理、布局合成和局部图像编辑等有组织的阶段，通过智能体间的迭代反馈确保谜题既视觉连贯又功能上可解。", "innovation": "提出了一个分层多智能体框架，该框架将谜题生成任务细化为多个有结构的阶段，通过智能体间的协作来提升图像质量。具体创新点包括能够确保生成的图像既逻辑严密又具有挑战性、避免捷径和提升使用清晰度，同时保持视觉效果的高质量。", "conclusion": "实验结果表明，通过智能体协作可以提升谜题生成的质量，特别是在可解决性、避免捷径和使用清晰度方面，同时维护了视觉效果。这为未来的文本到视觉内容生成提供了一种更有效的策略。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22405", "html_url": "https://arxiv.org/abs/2506.22405", "title": "语言模型在顺序诊断中的应用", "title_en": "Sequential Diagnosis with Language Models", "authors": "Harsha Nori,Mayank Daswani,Christopher Kelly,Scott Lundberg,Marco Tulio Ribeiro,Marc Wilson,Xiaoxuan Liu,Viknesh Sounderajah,Jonathan Carlson,Matthew P Lungren,Bay Gross,Peter Hames,Mustafa Suleyman,Dominic King,Eric Horvitz", "background": "人工智能有潜力扩展专家医学知识和推理的访问量。然而，现有的语言模型评估主要依赖静态案例和多项选择题，未能反映基于证据的医学在实际临床环境中的复杂性和细微差别。临床实践中，医生会逐步形成和修订诊断假设，适应每一轮次的新学习，并在做出最终诊断前权衡证据演变。为了模拟这一过程，该研究提出了顺序诊断基准，将304个通常具有挑战性的新英格兰医学期刊临床病案大会（NEJM-CPC）案例转化为逐步诊断互动场景。参与者需要从守门人模型中逐步请求额外信息，获取结果仅需明确查询。评估不仅包括诊断准确性，还包括医生访问次数和测试项目的成本。", "innovation": "该研究引入了顺序诊断基准，将NEJM-CPC病例转化为逐步诊断互动场景，参与者需从守门人模型中请求额外信息。提出了MAI诊断控制系统（MAI-DxO），这是一个模型无偏见的控制系统，可模拟一组医生，提出可能的鉴别诊断并战略性地选择高价值、成本效益高的测试。当与OpenAI的o3模型结合使用时，MAI-DxO的诊断准确率达到80%，比一般医生的平均准确率高出四倍。MAI-DxO还减少了诊断成本，相较于医生降低了20%，相较于现成的o3降低了70%。", "conclusion": "MAI-DxO在各种模型（包括OpenAI，Gemini，Claude，Grok，DeepSeek和Llama家族）的配置下表现出色，提高了诊断的精准性和成本效益，表明在指导下以迭代思维方式运作的人工智能系统可提升临床诊断质量和效率。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22023", "html_url": "https://arxiv.org/abs/2506.22023", "title": "动态块级预测策略实现稳定高效自回归语音合成", "title_en": "Robust and Efficient Autoregressive Speech Synthesis with Dynamic Chunk-wise Prediction Policy", "authors": "Bohan Li,Zhihan Li,Haoran Wang,Hanglei Zhang,Yiwei Guo,Hankun Wang,Xie Chen,Kai Yu", "background": "近年来，自回归（AR）语言模型在语音合成中崭露头角，提供了表达性和可扩展的训练。然而，依赖于下一个令牌预测的传统AR语音合成模型在处理长语音序列时常常面临挑战，难以建立稳定的帧间注意力机制，导致合成延迟增加和质量下降，这限制了其在实时应用中的可行性。", "innovation": "本文提出了一种新颖的动态块级自回归合成框架（DCAR），通过多令牌预测训练引入块到帧的注意力机制，使用轻量级模块进行动态块预测，从而根据不同语音上下文灵活调整预测跨度，大幅减少序列长度依赖性同时保持高质量合成。全面的实验结果显示，DCAR显著优于传统的下一个令牌预测模型，在测试集上实现了最高72.27%的可理解性提升和2.61倍的推理速度提升。", "conclusion": "此外，进行全面分析以支持其作为下一代语音合成系统的通用基础框架。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22255", "html_url": "https://arxiv.org/abs/2506.22255", "title": "Projected Compression: 可训练投影以实现高效Transformer压缩", "title_en": "Projected Compression: Trainable Projection for Efficient Transformer Compression", "authors": "Maciej Stefaniak,Michał Krutul,Jan Małaśnicki,Maciej Pióro,Jakub Krajewski,Sebastian Jaszczur,Marek Cygan,Kamil Adamczewski,Jan Ludziejewski", "background": "大型语言模型的尺寸逐渐增大以提高性能，但这也带来了更大的推理时间和计算需求。因此，模型尺寸缩减方法日益受到关注。针对这个问题，我们提出了一种新颖的模型压缩技术——投影压缩。该技术通过使用投影模块减少模型权重，首先训练额外的可训练投影权重并保留对所有原始模型参数的访问，然后将这些投影合并到一个更低维度的产品矩阵中，从而得到一个尺寸减小的基于标准Transformer的模型。", "innovation": "我们提出了一种新的模型压缩技术——投影压缩，通过使用投影模块减少模型权重，而不需要额外的计算开销，与基模型在同一FLOPs的每令牌计算步骤相匹配。实验结果显示，投影压缩在更高质量的模型上超越了可比的竞争性硬剪枝和重新训练方法，并且性能差距随令牌数量增加而有所改善。", "conclusion": "实验结果表明，投影压缩在性能上优于竞争性的硬化剪枝和重新训练方法，并且这种性能差异随着令牌的数量增加而很好地扩展。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22189", "html_url": "https://arxiv.org/abs/2506.22189", "title": "探索药物发现中代理系统的模块性", "title_en": "Exploring Modularity of Agentic Systems for Drug Discovery", "authors": "Laura van Weesep,Samuel Genheden,Ola Engkvist,Jens Sjölund", "background": "大语言模型（LLMs）和代理系统为加速药物发现和设计提供了激动人心的机会。本文批评性地分析了LLM基础的代理系统在药物发现中的模块性，即LLM等代理系统的各个部分是否可以互换，这是在药物发现应用中较少关注的一个课题。研究还比较了不同大语言模型的表现，以及工具调用代理和代码生成代理在这方面的有效性。实验结果显示，在使用LLM作为评分师以协调化学和药物发现工具时，Claude-3.5-Sonnet、Claude-3.7-Sonnet和GPT-4优于其他模型。尽管原有的代码生成代理优于工具调用代理，但这种结论取决于具体模型和问题。更换系统提示的影响也取决于特定问题和所使用的模型，说明在具有特定领域知识的代理系统中，仅替换语言模型而不考虑提示重新工程是不够的。", "innovation": "研究通过实验比较了不同大语言模型及其在药物发现应用中的工具调用代理与代码生成代理的有效性，展示了在不同条件下模型选择的复杂性，并强调了在更换代理系统模型时考虑提示重工程的重要性。", "conclusion": "研究表明，为了开发适用于真实世界问题的稳定性和可扩展性解决方案，需要进一步研究代理系统的模块性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21964", "html_url": "https://arxiv.org/abs/2506.21964", "title": "使用大型语言模型建议贝叶斯统计中的知识性先验分布", "title_en": "Using Large Language Models to Suggest Informative Prior Distributions in Bayesian Statistics", "authors": "Michael A. Riegler,Kristoffer Herland Hellton,Vajira Thambawita,Hugo L. Hammer", "background": "在贝叶斯统计中选择先验分布具有挑战性、资源密集且具有主观性。本文通过利用大语言模型（LLMs）来建议合适的、基于知识的先验分布。研究涉及了两个实际数据集：心脏病风险和混凝土强度，通过这些数据集评估了Claude、Opus、Gemini 2.5 Pro和ChatGPT-4o-mini的表现，发现这些模型能够正确识别关联的方向，但其提议的先验质量不同，主要在于过自信程度以及对先验分布宽度的把握能力上存在差异。研究表明，大语言模型在识别正确的关联方面具有巨大潜力，但调整先验宽度的准确度仍然是主要挑战.", "innovation": "本文提出了一种利用大语言模型（LLMs）来推荐BEYAS统计中合适的、基于知识的先验分布的方法，并开发了一个全面的提示，让LLMs不仅提出先验，还验证和反思其选择。研究表明，Claude和Gemini在提供更准确的先验分布方面优于ChatGPT，尤其是在弱信息先验方面，Claude没有使用过度模糊的均值0作为默认值，显示了明显的优势。基于这个研究结果，大语言模型有可能成为一个高效、客观的方法来开发先验分布.", "conclusion": "大语言模型能够识别正确的关联进一步显示了作为开发先验分布高效和客观方法的潜力，但在调整这些先验分布的宽度以避免过度自信或欠自信方面，仍然存在主要挑战。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22049", "html_url": "https://arxiv.org/abs/2506.22049", "title": "GPAS：通过梯度保留的激活缩放加速大语言模型预训练的收敛", "title_en": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling", "authors": "Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Yin Lu,Can Yang", "background": "现代大型语言模型（例如LLaMA、Qwen和DeepSeek系列）主要采用预层标准化（Pre-LN）Transformer架构。尽管Pre-LN在预训练中表现稳定且可以扩展到大规模模型，但它的激活方差随着层数的增加呈现指数增长，导致残差路径在各层的输出中占主导地位，限制了深层的学习能力。这项研究旨在解决这一问题，具体介绍了Gradient-Preserving Activation Scaling（GPAS）技术，这是一种可与现有方法结合使用的简单方法，用于调整中间激活值而不改变梯度，从而保持激活信息完整并避免梯度消失问题。实验表明，GPAS 在从71M到1B多种模型规模上都实现了一致的性能提升。GPAS 不仅适用于Pre-LN变压器结构，还能改善如Sandwich-LN和DeepNorm等其他架构，显示了其多样性和提高各种情境下训练动态的潜力。", "innovation": "提出的Gradient-Preserving Activation Scaling（GPAS）技术，可在不改变梯度的情况下缩小中间激活值，保持激活信息完整并避免梯度消失问题。GPAS 能够跨不同规模的模型（从71M到1B）提供一致的性能提升，并且适用于多种不同的Transformer架构，展示其在提升训练动态方面的多样性和潜力。", "conclusion": "GPAS 技术能够在不修改梯度的情况下缩小中间激活值，解决预训练阶段的激活方差问题，进而提高大型语言模型的收敛速度和学习能力。GPAS 不仅适用于Pre-LN Transformers，还能应用于其他架构，显示出其广泛的适用性和提升训练效果的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22309", "html_url": "https://arxiv.org/abs/2506.22309", "title": "概念主题聚合", "title_en": "Conceptual Topic Aggregation", "authors": "Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme", "background": "随着数据的快速增长，传统的手工检查已经不可行，需要采用计算方法来高效地探索数据。主题建模已经成为了分析大规模文本数据的强大工具，能够提取潜在的语义结构。但是，现有的主题建模方法往往难以提供可解释的表示形式，使人们能够深入理解数据的结构和内容。", "innovation": "本文提出了一种名为FAT-CAT的方法，该方法基于形式概念分析(FCA)，能够增强主题的有意义聚合和可视化发现的主题。这种方法可以处理多样化的主题和文件类型，并按目录分组来构建概念格，提供主题分布的结构化、分层表示。", "conclusion": "在ETYNTKE数据集的研究案例中，我们的方法与其他表示方法进行了对比评估，证明了基于FCA的聚合提供了比现有主题建模技术更有意义和可解释的数据集组成洞察。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22274", "html_url": "https://arxiv.org/abs/2506.22274", "title": "COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication", "title_en": "COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication", "authors": "Filippo Merlo,Ece Takmaz,Wenkai Chen,Albert Gatt", "background": "自然场景为物体识别和参考提供了丰富的背景信息。知道当前看的是哪种场景可以产生对可能出现的物体及其空间配置的预期。视觉语言模型（VLMs）是否在生成物体参考时也会依靠这样的场景背景？", "innovation": "该研究引入了COOCO数据集，测试了在不同场景对物体的契合度和不同干扰下，VLMs在物体参考生成中依赖场景背景的程度。研究发现，模型会根据不同物体和场景的语义相关性和噪声水平动态利用场景背景，并且在中等噪声下，模型在中级层对目标物体的关注增加，表明VLMs能够动态平衡局部和背景信息以生成参考信息。", "conclusion": "研究表明，模型能够适应性地利用场景背景，这取决于物体和场景的语义相关性以及噪声水平。在目标和场景契合度较高的情况下或者当物体受到干扰时，模型更依赖于场景背景。此外，注意力分析还揭示在中等噪声下，模型对目标物体的关注增加。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22237", "html_url": "https://arxiv.org/abs/2506.22237", "title": "使用钢琴卷和CQT表示的神经网络 Fine-Tuning MIDI to Audio 对齐", "title_en": "Fine-Tuning MIDI-to-Audio Alignment using a Neural Network on Piano Roll and CQT Representations", "authors": "Sebastian Murgul,Moritz Reiser,Michael Heizmann,Christoph Seibert", "background": "本文提出了一种基于卷积循环神经网络（CRNN）的方法，用于同步人类钢琴演奏的音频录音与其松散对齐的MIDI文件。为了训练网络，创建了一个包含具有模拟常见人类节奏错误的增强MIDI文件的钢琴作品数据集。该研究旨在改进MIDI到音频的对齐技术，特别是在处理常见的节奏偏差时。现有的动态时间规整（DTW）方法被用来进行比较，但实验结果表明CRNN方法在不同容忍度窗口中的对齐精度提高了20%以上。通过将DTW与CRNN结合使用，可以进一步改善鲁棒性和一致性，显示出神经网络在这一领域中的潜力。", "innovation": "本文创新点在于提出了一种基于CRNN的同步音频和MIDI文件的方法，特别适用于人类钢琴演奏的音频录音与相应的MIDI文件对齐问题。该方法通过同时处理未对齐的钢琴卷和音频的频谱图来提取频谱和时间特征。此外，通过创建一个包含模拟常见人类节奏错误的增强MIDI文件的数据集来训练网络，并通过结合使用DTW提高模型的鲁棒性和一致性。", "conclusion": "研究成果证明了神经网络在MIDI到音频对齐方面的潜力。该研究提出的CRNN方法在不同容忍度窗口中的对齐精度比工业标准的DTW方法提高了20%以上。此外，将DTW与CRNN结合使用可以进一步提高模型的鲁棒性和一致性。这些结果表明，神经网络在加速和提高MIDI到音频对齐任务的性能方面具有巨大潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2403.05518", "html_url": "https://arxiv.org/abs/2403.05518", "title": "增强一致性的偏见训练减少链式思考中的偏见推理", "title_en": "Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought", "authors": "James Chua,Edward Rees,Hunar Batra,Samuel R. Bowman,Julian Michael,Ethan Perez,Miles Turpin", "background": "链式思考（CoT）有助于提升语言模型的解释性，但可能会系统性地歪曲影响模型行为的因素，例如根据用户的观点合理化答案。研究指出，针对GPT-3.5-Turbo和Llama-8b模型存在9种不同的偏见，这些偏见包括虚假的少样本模式、事后的合理化和阿谀奉承的设定，导致模型在产生答案时会改变原先的行为模式而不提及偏见的影响因素。", "innovation": "提出了一种新的无监督微调方案——偏见增强一致性训练（BCT），旨在使模型在有无偏差提示下给出一致的推理结果。通过在七种问答任务上测试九种形式的偏见推理，结果表明，将BCT应用于GPT-3.5-Turbo模型，使用一种偏见时，新模型在保留任务上的偏见推理减少86%，同时模型对其他偏见类型也有37%的平均改善效果，且该方法无需标注数据且能够推广到新出现的偏见，为未来的偏见推理问题提供了解决方案。", "conclusion": "偏见增强一致性训练（BCT）有效减少了语言模型在链式思考中的偏见推理，尤其是对于未知偏见在新任务上的泛化能力较强，具有进一步研究和应用的价值。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22343", "html_url": "https://arxiv.org/abs/2506.22343", "title": "混合AI与人类文本中水印比例的最优估计", "title_en": "Optimal Estimation of Watermark Proportions in Hybrid AI-Human Texts", "authors": "Xiang Li,Garrett Wen,Weiqing He,Jiayuan Wu,Qi Long,Weijie J. Su", "background": "文本水印在大型语言模型（LLMs）中的应用日益重要，用于检测合成文本并区分人类撰写的文本与LLM生成的文本。现有的大多数研究集中在确定整篇文本是否被打上了水印，但在许多实际场景中，文本可能是混合来源的，包含人类撰写的和水印被标记的内容。本文研究在混合来源文本中最优估计水印比例的问题。研究指出，在某些水印方案中，水印比例参数是不可识别的，但对于使用连续关键统计值进行检测的水印方法，在温和条件下，比例参数是可识别的。", "innovation": "提出了基于关键统计值的方法类的有效估计器，并对此类方法建立了任何基于关键统计值的可测量估计器的最小最大下界，表明所提估计器达到了这些下界。在合成数据和开源模型生成的混合来源文本上进行评估，证明所提出的估计器实现了高度准确的估计结果。", "conclusion": "研究表明，对于使用连续关键统计值进行检测的水印方法，在轻度条件下，水印比例参数是可识别的，并提出了基于关键统计值的方法类的有效估计器，这些估计器在合成数据和混合来源文本中实现了高估计精度。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22419", "html_url": "https://arxiv.org/abs/2506.22419", "title": "自动化大语言模型速度竞赛基准：重现NanoGPT的改进", "title_en": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "authors": "Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach", "background": "近年来，大语言模型（LLMs）的快速发展为科学进步提供了助力。其中，再现现有工作的能力至关重要。为了评估AI代理再现活跃研究领域结果的能力，研究者引入了基于NanoGPT速度竞赛的自动化LLM速度竞赛基准。NanoGPT速度竞赛是一个旨在训练GPT-2模型的最短时间内的竞赛贡献，每项任务都提供了前记录的训练脚本，并可选地带有三种不同形式的提示，从伪代码到论文描述的新记录改进。这些任务执行迅速，并涵盖了从高级算法优化到硬件感知优化等多种级别的代码变化。这些特点使得基准既具有可访问性又具有现实感，适用于改进LLM训练的前沿问题.", "innovation": "该基准利用了NanoGPT速度竞赛中研究社区的贡献，引入了一个自动化LLM速度竞赛基准来评估AI代理再现研究结果的能力。研究发现，最先进解释型LLM与最先进的支撑技术难以重现我们的基准中已知的创新，即使提供了详细提示。因此，该基准为评估LLM自动进行科学研究再现的能力提供了一个简单且非饱和的指标，而这是自主研究代理所必需的能力之一（但不是全部）.", "conclusion": "该基准提供了衡量LLM自动化再现科学的能力的一种简单、非饱和的方法。尽管最近的LLM和最先进的支撑技术在给出详细提示时难以再现已知创新，但这一基准仍提供了一个评估LLM自动化再现科学的必要技能的有效工具。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22372", "html_url": "https://arxiv.org/abs/2506.22372", "title": "利用LLMs实现公平排名：性别偏见的检测与测量", "title_en": "Towards Fair Rankings: Leveraging LLMs for Gender Bias Detection and Measurement", "authors": "Maryam Mousavian,Zahra Abbasiantaeb,Mohammad Aliannejadi,Fabio Crestani", "background": "在自然语言处理（NLP）和信息检索（IR）系统中存在的社会偏见是一个持续的挑战，这强调了开发稳健方法来识别和评估这些偏见的重要性。现有的性别公平性指标依赖于词性和频率测度，导致各种局限性，如未能识别细微的性别差异。基于我们的基于LLM的性别偏见检测方法，我们引入了一种新的性别公平性指标，称为类别加权曝光（CWEx），旨在解决现有局限性。为了评估我们提出的指标的有效性，并研究LLM在检测性别偏见方面的有效性，我们在MS MARCO Passage Ranking集合中注释了一部分数据，并发布了一个新的性别偏见数据集，称为MSMGenderBias，以促进该领域的未来研究。", "innovation": "引入了基于LLM的性别偏见检测方法，并提出了新的性别公平性指标CWEx，旨在解决现有测度的局限性。注释了一部分MS MARCO数据集，并发布了新的MSMGenderBias数据集，以便在未来研究中使用。通过CWEx指标，对各种排名模型进行了广泛的实验，结果显示与之前的指标相比，我们的方法能提供更详细的公平性评估，更好地与人类标签对齐（使用Kappa一致性测度），有效地区分排名中的性别偏见。", "conclusion": "通过集成LLM驱动的偏见检测，改进的公平性指标和性别偏见的注释，以及现有数据集，这项工作提供了一种更稳健的框架来分析和缓解IR系统中的偏见。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.14883", "html_url": "https://arxiv.org/abs/2404.14883", "title": "语言在 vivo 与 in silico 中的比较：规模很重要但更大的语言模型仍然无法与人类平起平坐地理解语言，因为语言参考不可捉摸", "title_en": "Language in Vivo vs. in Silico: Size Matters but Larger Language Models Still Do Not Comprehend Language on a Par with Humans Due to Impenetrable Semantic Reference", "authors": "Vittoria Dentella,Fritz Guenther,Evelina Leivada", "background": "理解语言的局限性是让大型语言模型（LLMs）作为自然语言理论的前提。尽管LLMs在某些语言任务中的表现与人类有很大不同，但这些差异是否可以通过模型规模的增加来弥补尚未确定。本文通过分析三种不同规模的LLMs（Bard，137亿参数；ChatGPT-3.5，175亿；ChatGPT-4，1.5万亿）在涉及消元、中心嵌套、比较和否定极性等项目的语法判断任务中的表现，检验了模型规模对人类与模型之间差异的影响。研究结果表明，尽管ChatGPT-4表现优于人类，但这种优势仅体现在句法正确的句子上，说明模型对（不）语法性感知不如人类敏感，单一的模型扩展可能无法完全解决这一问题。这与人类天然的语言学习形成了对比，三种关键差异体现在：证据类型、刺激贫乏和语义幻觉的发生频率。", "innovation": "本文通过比较不同规模的LLMs在特定语法判断任务中的表现，首次研究了模型规模对语言理解差异的影响，并揭示了人类与模型之间对于语言的理解差异在于证据类型、刺激贫乏和语义幻觉的处理上。此外，研究中使用了大量的人类判断数据，对比了LLMs与人类的表现差异，提供了一种新的视角理解语言模型在语言学习中的局限性。", "conclusion": "尽管增加模型规模可以改善其表现，但在理解语言（特别是（不）语法）方面，LLMs与人类之间的差距仍然存在，并非单纯通过模型扩展就可以解决。这反映了语言学习中三种关键差异的影响：不同的证据类型、刺激贫乏和无法穿透的语言引用导致的语义幻觉。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.16661", "html_url": "https://arxiv.org/abs/2405.16661", "title": "RLSF：通过符号反馈微调LLM", "title_en": "RLSF: Fine-tuning LLMs via Symbolic Feedback", "authors": "Piyush Jha,Prithwish Jana,Pranavkrishna Suresh,Arnav Arora,Vijay Ganesh", "background": "大语言模型（LLMs）虽然已经改变了人工智能，但在需要领域特定推理和逻辑对齐的任务上常常表现不佳。传统的工作方式仅利用稀疏的奖励信号和不可靠的奖励模型来微调LLM，但未能有效利用诸如证明器等符号推理工具所提供的大量符号领域的知识。这些限制导致现有方法难以精确对齐领域特定的约束，从而限制了LLMs的能力和应用范围.", "innovation": "本文提出了一种新的微调方法——符号反馈强化学习（RLSF），该方法通过符号推理工具（如求解器、证明器和算术系统）为LLMs提供细粒度反馈。RLSF使用符号工具生成的多项式大小的证明（如证明）来识别和纠正模型输出中的错误，提供逐词级的指导，无需依赖可微推理系统。这种方法在符号推理和LLM微调之间架起桥梁，使得微调后的LLM能够精准地与领域特定的约束对齐，同时解决了传统奖励信号的关键限制.", "conclusion": "通过广泛的评估，我们的RLSF方法在五个具有逻辑或领域约束的应用（包括从自然语言伪代码合成程序语言代码、化学任务以及解决24点游戏）上显著优于传统方法。主要发现是，通过RLSF微调的相对较小的LLMs能够在性能上超越远大得多的商业模型。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22376", "html_url": "https://arxiv.org/abs/2506.22376", "title": "概率性最优点对推理时扩展的优化", "title_en": "Probabilistic Optimality for Inference-time Scaling", "authors": "Youkang Wang,Jian Wang,Rubing Chen,Xiao-Yong Wei,Qing Li", "background": "推理时扩展已成为提升大型语言模型（LLMs）推理性能的强大技术。然而，现有的方法往往依赖于并行采样的启发式策略，缺乏坚实的理论基础。现有的方法缺少优化推理时扩展的具体指导，特别是在并行样本是独立且同分布（i.i.d.）的情况下，和最佳-of-N（Best-of-N）选择策略遵循可估计的概率分布时。", "innovation": "本文提出了一种概率框架，当并行样本是独立且同分布，并且最佳-of-N选择策略遵循可估计的概率分布时，该框架明确了推理时扩展的最优性。在该框架内，推导出达到目标性能水平所需样本数量的理论下限，提供了一种计算高效的扩展的理论指导。基于此见解，开发了OptScale，一个实用算法，动态确定最优的采样响应数量。OptScale 使用语言模型预测器估计概率先验参数，决定满足预定义的性能阈值和置信水平所需的最少样本数量。广泛的数学推理基准测试（包括MATH-500、GSM8K、AIME和AMC）结果显示，OptScale 显著减少了采样开销，同时保持或超越了最先进的推理性能。这项工作既提供了理论基础，也提出了实用解决方案，填补了对复杂推理高效部署大型语言模型的关键缺口。", "conclusion": "本文工作为陈述了优化推理时扩展提供了理论基础和实用解决方案，解决了现有方法缺乏原则性指导的问题。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.07495", "html_url": "https://arxiv.org/abs/2407.07495", "title": "超出固定长度限制：所有的超前训练都需要分桶", "title_en": "Beyond Fixed Length: Bucket Pre-training is All You Need", "authors": "Qing Yang,Qiyao Peng,Hongtao Liu,Kai Liu,Bing Qin,Ting Liu", "background": "大型语言模型（LLMs）在多个任务中展现出卓越的表现，预训练阶段是其能力的基本支柱。然而，预训练中常用固定长度的数据组合策略存在一些实际挑战。使用较短的序列时，文档会被截断，可能导致信息丢失，影响模型捕获长距离依赖的能力。而使用较长的序列时，则需要将多个文档组合在一起，这可能会引入噪音，破坏自然文档边界和语义一致性，并增加大量的计算成本。", "innovation": "本文首先确立了三个评估数据组合质量的定量指标：填充比例、截断比例和组合比例。在此基础上，提出了一个创新的多桶数据组合方法，超越了固定长度的限制。本文的方法能够适应性地组织训练数据，以实现根据提出指标评估的最佳组合质量，从而提供一种更具灵活性和效率的预训练方法。", "conclusion": "通过广泛的实验结果表明，所提出的方法显著提高了LLM预训练的效率和效果。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.11856", "html_url": "https://arxiv.org/abs/2408.11856", "title": "大型语言模型上有效情感分析微调的动态自适应优化", "title_en": "Dynamic Adaptive Optimization for Effective Sentiment Analysis Fine-Tuning on Large Language Models", "authors": "Hongcheng Ding,Xuanze Zhao,Ruiting Deng,Shamsul Nahar Abdullah,Deshinta Arrova Dewi,Zixiao Jiang", "background": "情感分析在商务智能和金融预测等领域发挥着关键作用。传统的大型语言模型通过多任务学习进行微调以应对具体任务，但常因管理多样任务的复杂性而表现不佳。固定权重的多任务学习方法难以适应数据特征的变化，进一步影响了模型的效果。", "innovation": "提出了一种基于动态自适应优化（DAO）模块的新型多任务学习框架，该模块能够根据任务重要性和数据特征动态调整任务权重，实现无缝集成到现有模型中，提供了一种有效且灵活的多任务学习解决方案。实验结果表明该框架显著改善了金融文本数据集上的均方误差和准确率，分别提升了15.58%和1.24%。", "conclusion": "提出的方法在金融文本数据集上的情感分析中表现出色，通过动态自适应损失模块实现了显著的性能提升。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22385", "html_url": "https://arxiv.org/abs/2506.22385", "title": "视频大跨模态模型能像怀疑者一样思考吗——或双重下注：关于视频可驳论证的一项研究", "title_en": "Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment", "authors": "Yue Zhang,Jilei Sun,Yunhui Guo,Vibhav Gogate", "background": "视频大跨模态模型（VLMMs）在理解视频内容方面取得了令人瞩目的进展，但由于难以适应和进行抽象推理（即在新信息出现时不断调整解释的能力），它们常常面临挑战。实验证明，结论往往不是固定的，新出现的背景信息可能会增强或削弱最初的推断。本研究旨在解决这一问题，通过引入一种新的任务，即Defeasible Video Entailment（DVidE），促使模型像怀疑者一样思考，根据新的证据不断更新其推理过程。在DVidE任务中，模型需要根据视频前提和文本假设来决定新的更新是增强还是削弱假设（分类版本），或者生成一个连贯的更新，以调整推理关系（生成版本）。", "innovation": "本研究提出了一个新的任务——Defeasible Video Entailment（DVidE），并通过引入链式反事实思考框架，结合反事实推理、增强声学-语言对齐的视频内容和推理解释细化，减少推理偏见。另外，研究还开发了一种将自动语音识别输出与大型语言模型相结合的框架，以生成与增强或削弱目标一致的连贯、适境相关更新。在此基础上，研究团队还引入了一个全新的基准数据集，包含增强者/削弱者注释，以及一种基于大型语言模型的评估指标，专门用于评估生成性能。实验证明，与现有的方法相比，研究提出的新方法在动态推理能力方面有显著提升，验证了其在增强视频理解方面的能力。", "conclusion": "实验结果证明了所提出的方法在增强视频大型跨模态模型的动态推理能力方面具有显著优势，有效地提升了模型根据新证据不断更新解释的能力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.02660", "html_url": "https://arxiv.org/abs/2410.02660", "title": "如何有效训练长上下文语言模型", "title_en": "How to Train Long-Context Language Models (Effectively)", "authors": "Tianyu Gao,Alexander Wettig,Howard Yen,Danqi Chen", "background": "本文研究了如何对语言模型（LM）进行继续训练和监督微调（SFT），以便有效利用长上下文信息。传统的评估方法，如困惑度或简单的“从 haystack 中找针”的测试并不充分，本文提出了一套可靠的评估协议，通过使用广泛的长上下文下游任务来评估模型，以更好地揭示其长上下文能力。此外，本文还进行了详细的实验来决定继续预训练的数据混合、指令调优数据集以及许多其他设计选择，例如位置外推。", "innovation": "本文的创新点在于提出了更有效的评估方法和实验设计指导原则，具体包括：（1）确认代码库和书籍是长数据的优质来源，但必须与高质量的短数据相结合；（2）超过评估长度的序列长度训练有助于提高长上下文性能；（3）对于SFT，仅使用短指令数据集可以产生出色的表现。最终开发的ProLong-8B模型在128K长度下显示出同类模型中最佳的长上下文性能，同时仅使用5%的token数量就超过了Llama-3.1-8B-Instruct在长上下文任务上的表现。此外，ProLong还可以处理多达512K token，这是目前已知最长上下文窗口之一的公开可用模型。", "conclusion": "本文通过实验验证了有效的模型继续训练和SFT的数据选择，提出了长上下文语言模型的新训练方法。最终开发的ProLong-8B模型展示了在长上下文任务上的优越性能，表明了新的训练方法的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.17355", "html_url": "https://arxiv.org/abs/2410.17355", "title": "所有实体并非平等：超精细实体类型化中的长尾现象考察", "title_en": "All Entities are Not Created Equal: Examining the Long Tail for Ultra-Fine Entity Typing", "authors": "Advait Deshmukh,Ashwin Umadi,Dananjay Srinivas,Maria Leonor Pacheco", "background": "预训练语言模型（PLMs）由于可以从大型语料库中吸取世界知识，被广泛应用于标签空间非常大的超精细实体类型化任务中。本文探讨了PLMs所获取知识的限制，提出了一种新的启发式方法来近似未知预训练数据下的实体分布。研究表明，仅依赖于PLMs参数化知识的实体类型化方法在长尾分布的实体上表现较差，而知识嵌入的方法可以弥补一些不足。这些发现表明，我们需要超越PLMs来开发适用于稀有实体的解决方案。", "innovation": "提出了一种新的启发式方法来近似未知预训练数据下实体的分布；系统性地展示了依赖于PLMs参数化知识的实体类型化方法在长尾实体上的表现不佳；发现知识嵌入的方法可以解决部分问题。", "conclusion": "需要超越PLMs来开发针对稀有实体表现更好的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16589", "html_url": "https://arxiv.org/abs/2410.16589", "title": "利用大型语言模型进行高效情感分析的动态自适应秩空间探索", "title_en": "Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models", "authors": "Hongcheng Ding,Fuzhen Hu,Ruiting Deng,Xuanze Zhao,Shamsul Nahar Abdullah,Deshinta Arrova Dewi", "background": "情感分析因其评估公众意见和辅助决策的重要性而变得日益重要。大规模语言模型（LLMs）通过捕捉复杂的语言模式，极大革新了这一领域。然而，将LLMs适应到特定领域的语情感分析任务中，还面临着计算资源限制和最优化微调的需求等挑战。本文即对该问题进行探索，提出了一种新的动态自适应秩空间探索（DARSE）框架，以实现利用LLMs进行高效的情感分析。", "innovation": "提出了DARSE框架，其由粗粒度贪婪算法、细粒度探索算法和动态秩分配方法组成。这些组件共同作用，旨在优化LLM的秩级选择，以提高情感分析的准确性和效率。DARSE框架通过选择最优的秩级范围和组合，平衡了计算效率和模型性能，从而创新地解决了特定领域的情感分析难题。", "conclusion": "广泛的实验表明，DARSE框架显著提高了情感分析的准确性，在均方误差（MSE）方面提高了15.1%，准确率提高了4.3%，超越了现有技术。该框架在平衡计算效率与模型性能之间表现出优势，是未来情感分析中利用LLMs的一个有前景的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.15533", "html_url": "https://arxiv.org/abs/2408.15533", "title": "LRP4RAG：基于层间相关传播检测检索增强生成中的幻觉", "title_en": "LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation", "authors": "Haichuan Hu,Congqing He,Xiaochen Xie,Quanjun Zhang", "background": "检索增强生成（RAG）已成为大型语言模型（LLMs）中减轻幻觉问题的主要技术。然而，知识提取不完整和理解不足仍然可能导致LLMs生成无关甚至矛盾的响应，这意味着RAG中的幻觉仍然存在。", "innovation": "本文提出了一种基于层间相关传播（LRP）算法的方法LRP4RAG，用于检测RAG中的幻觉。具体地，首先使用LRP计算输入与RAG生成器输出的相关性，然后对相关性矩阵进行进一步的提取和抽样处理。处理后的相关数据输入到多个分类器以判断输出是否包含幻觉。据我们所知，这是首次使用LRP进行RAG幻觉检测，并且广泛的实验证明LRP4RAG优于现有基线方法", "conclusion": "广泛的经验表明，LRP4RAG在检测RAG幻觉方面优于现有基线方法。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.02481", "html_url": "https://arxiv.org/abs/2409.02481", "title": "PQ-GCN：基于短语特征提升文本图问题分类", "title_en": "PQ-GCN: Enhancing Text Graph Question Classification with Phrase Features", "authors": "Junyoung Lee,Ninad Dixit,Kaustav Chakrabarti,S. Supraja", "background": "有效的问答分类对于基于AI的教育工具至关重要，它能帮助自适应学习系统根据技能领域、难度级别和知识水平对问题进行分类。这不仅支持教育诊断和分析，还能通过将问题与相关类别联系起来，增强复杂下游任务如信息检索和问答的性能。传统方法通常基于词嵌入和传统分类器，难以捕捉问题陈述中的微妙关系，导致性能不佳。现有的传统方法存在这一局限。", "innovation": "我们提出了一种新颖的方法——基于短语的图卷积网络（Phrase Question-Graph Convolutional Network, PQ-GCN）。通过PQ-GCN，我们评估了将基于短语特征纳入分类，提高各种领域和特性的问答数据集分类性能。基于短语特征的方法在低资源设置下优于基准图方法，并且在参数量远少于基于语言模型的方法的情况下，表现与之相当。", "conclusion": "我们的研究为更上下文感知、参数效率高的问题分类提供了可能的解决方案，促进了图神经网络研究在教育领域的应用。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.08708", "html_url": "https://arxiv.org/abs/2411.08708", "title": "文档级别的事件抽取是否需要触发器？", "title_en": "Are Triggers Needed for Document-Level Event Extraction?", "authors": "Shaden Shaar,Wayne Chen,Maitreyi Chatterjee,Barry Wang,Wenting Zhao,Claire Cardie", "background": "现有的事件抽取工作大多集中在句子级别，并假设输入中存在触发词（引发特定事件的词语或短语），以此来提取事件的参数。触发词被视为事件抽取的重要组成部分。然而，对于更加复杂且研究较少的文档级别事件抽取任务，触发词的作用仍不清楚。本文首次探讨了在文档级别事件抽取模型中触发词的作用。", "innovation": "在多个文档级别事件抽取数据集上，对触发词的质量（人工标注、大语言模型生成、关键词生成、随机生成）进行分析，并通过端到端和流水线的变压器模型进行实验，发现触发词的质量和可用性对于不同数据集和事件抽取任务有着重要影响，甚至随机生成的触发词对基于提示的上下文学习方法也有所助益。这一研究打破了触发词必须存在的传统观点，具有创新性。", "conclusion": "文档级别的事件抽取是否受益于显式提取触发词取决于数据集特性和提取任务中的相关信息。即使使用随机生成的触发词也可能对基于提示的上下文学习方法起到积极作用。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.12644", "html_url": "https://arxiv.org/abs/2412.12644", "title": "iPrOp: 大型语言模型中的交互式提示优化，具有在环的人类", "title_en": "iPrOp: Interactive Prompt Optimization for Large Language Models with a Human in the Loop", "authors": "Jiahui Li,Roman Klinger", "background": "提示工程在大型语言模型时代发挥了重要贡献，但其效果依赖于提示作者的技巧。本文介绍了一种名为iPrOp的新型交互式提示优化方法，旨在弥合手动提示工程和自动提示优化之间的差距，并给用户提供进出灵活性来评估不断演变的提示。我们旨在为用户提供针对特定任务的指导，以增强人类在优化过程中的参与度，该过程结构化为提示变体、信息丰富实例、由大语言模型生成的预测及其对应的解释，以及相关的性能指标。这种方法增强了用户根据其个人偏好和需求选择和进一步精炼提示的能力。该方法不仅帮助非技术领域的专家生成针对其特定任务或领域的最优化提示，还能研究影响提示优化性能的固有参数。评估表明，我们的方法能够生成改进的提示，促进任务性能的提升", "innovation": "本文提出了一种名为iPrOp的新型交互式提示优化方法，该方法能够结合手动提示工程和自动提示优化的优点，并提供用户具体任务的指导，增强人类在提示优化过程中的参与。此外，该方法通过提示变体、信息实例、大语言模型生成的预测和解释以及性能指标，增强用户对提示优化过程的理解和评估能力。该方法不仅适用于非技术领域的专家生成最优化的提示，还能帮助研究提示优化的内在参数影响", "conclusion": "本文提出并验证了一种名为iPrOp的交互式提示优化方法，通过给用户提供具体的任务指导，增强人类对优化过程的参与。这种方法能够生成改进的提示，从而提升任务性能，并能够更好地理解影响提示优化性能的关键参数"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01805", "html_url": "https://arxiv.org/abs/2501.01805", "title": "使用梯度缓存的端到端长文档总结", "title_en": "End-to-End Long Document Summarization using Gradient Caching", "authors": "Rohit Saxena,Hao Tang,Frank Keller", "background": "训练基于变压器的编码器-解码器模型进行长文档摘要生成面临显著挑战，因为训练过程中内存消耗呈平方级增长。尽管已有方法在测试时能延长输入长度，但在训练时依然困难，需要裁剪输入文档，导致训练和测试条件不匹配。", "innovation": "提出了一种名为CachED的方法（Gradient Caching for Encoder-Decoder models），允许端到端训练现有的变压器编码器-解码器模型，无需裁剪原始文档。通过应用非重叠滑动窗口对输入文档进行处理，并在解码器端融合；在反向传播期间，在解码器处缓存梯度，并通过重新计算隐藏向量分块地在编码器中传递，类似于梯度检查点技术。这种方法使在长文档摘要生成实验中能够处理超过50万个标记，且无需使用额外参数即可实现优异性能。", "conclusion": "CachED方法使得基于变压器的编码器-解码器模型能够进行端到端训练，并提高了长文档摘要的生成性能，而不需要增加额外参数。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.03492", "html_url": "https://arxiv.org/abs/2410.03492", "title": "关于可重复的大语言模型评估：量化大语言模型基准得分的不确定性", "title_en": "Towards Reproducible LLM Evaluation: Quantifying Uncertainty in LLM Benchmark Scores", "authors": "Robert E. Blackwell,Jon Barry,Anthony G. Cohn", "background": "大语言模型（LLMs）具有随机性，在设定温度为零并固定随机种子的情况下，也可能不会提供确定性的答案。尽管如此，很少有基准研究试图量化这种不确定性，部分原因是重复实验所需的时间和成本。因此，本文使用旨在测试LLMs处理空间方向推理能力的基准，探讨实验重复次数对平均得分和预测区间的影响，以探索如何更有效、更经济地量化基准得分的不确定性，并提出关于可重复的LLM评估的建议。", "innovation": "本文提出了一种简单的方法，用于在较低成本下量化基准得分的不确定性，并建议了关于可重复的大语言模型评估的措施。这种方法旨在解决因重复实验所需的时间和成本导致的研究效率问题，通过探索实验重复次数对平均得分和预测区间的影响，来评估模型的不确定性和可重复性问题。", "conclusion": "通过对实验重复次数对平均得分和预测区间的影响的研究，本文提供了一种成本效益高的方法来量化大语言模型基准得分的不确定性，并提出了可重复评估的一系列建议，从而提高大语言模型评估的可靠性和效率。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.14275", "html_url": "https://arxiv.org/abs/2501.14275", "title": "利用在线奥林匹克级别数学问题对LLMs进行训练和防污染评估", "title_en": "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation", "authors": "Sadegh Mahdavi,Muchen Li,Kaiwen Liu,Christos Thrampoulidis,Leonid Sigal,Renjie Liao", "background": "大规模语言模型（LLMs）的进展引发了对其解决奥林匹克级别数学问题能力的兴趣。然而，这些模型的训练和评估受到可用数据集规模有限和质量不高的限制，创建这样的大规模数据集需要大量的人工专家努力。此外，当前的基准测试容易受到污染，导致评估结果不可靠。", "innovation": "该论文提出了一个自动化的数据管道，利用Art of Problem Solving (AoPS) 论坛丰富的资源，该论坛主要包含奥林匹克级别的问题和社区驱动的解决方案。利用开源的大规模语言模型开发了一种方法，从论坛中提取问题-答案对，形成了包含超过600,000个高质量QA对的数据集AoPS-Instruct。该工作建立了自动管道，推出LiveAoPSBench作为不断发展的基准测试集，提供一种防污染的评估方法。此外，观察到的LLM性能随时间下降，表明它们在解决旧例子时的成功可能源于预训练而非真实的推理能力。", "conclusion": "本研究提供了一种可扩展的方法来创建和维护高质量的大型数据集用于高级数学推理，揭示了LLMs在该领域的能力和局限性。基准测试和代码可通过以下链接访问：this https URL"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01956", "html_url": "https://arxiv.org/abs/2501.01956", "title": "元数据条件加速语言模型预训练", "title_en": "Metadata Conditioning Accelerates Language Model Pre-training", "authors": "Tianyu Gao,Alexander Wettig,Luxi He,Yihe Dong,Sadhika Malladi,Danqi Chen", "background": "语言模型在预训练数据集中的多样风格、领域和质量水平对于发展通用模型能力至关重要，但这些异质数据源中的正确行为学习和部署效率较低。为此，该研究探讨了如何引入元数据来辅助预训练过程，以解决这一挑战。", "innovation": "提出了一个新的方法，即元数据条件然后冷却（MeCo），该方法在预训练期间引入额外的学习提示。MeCo首先在训练过程中提供与文本相关的元数据（例如，网址如www.wikipedia.org），之后进入冷却阶段，仅使用标准文本，从而使模型在没有元数据的情况下也能正常工作。MeCo在不同模型规模（从600M到8B参数）和不同数据源（C4、RefinedWeb和DCLM）下显著加速了预训练过程。通过这一方法，1.6B参数的模型在使用33%更少的数据下匹配了标准预训练下的下游任务表现，并能够通过条件化的推理提示引导模型生成具有特定属性的内容。这种方法简单且零额外计算成本，展示了生成性能卓越、可控的语言模型的潜力。", "conclusion": "MeCo方法简单、无额外计算开销，并在多种数据源和模型规模下显著加速了预训练过程，且能通过条件化的元数据有效引导模型生成具有特定性质的内容，展示了生成更加有效且可控的语言模型的前景。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.06582", "html_url": "https://arxiv.org/abs/2501.06582", "title": "ACORD: 法律合同起草中专家注释的检索数据集", "title_en": "ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting", "authors": "Steven H. Wang,Maksim Zubkov,Kexin Fan,Sarah Harrell,Yuyang Sun,Wei Chen,Andreas Plesner,Roger Wattenhofer", "background": "合同检索在合同起草中至关重要，因为律师通常不会从头开始起草合同，而是寻找并修改最相关的先例条款。目前缺乏专门针对合同起草领域的检索基准数据集，尤其是针对复杂的合同条款如责任限制、补偿条款、控制变更和最优惠国条款等。ACORD作为首个专门为合同起草领域设计的专家注释检索基准数据集，填补了这一空白，包括114个查询和超过126,000个查询-条款对，并且每个对都按1到5星的评级进行标注。", "innovation": "ACORD是首个由专家全面注释的合同起草检索基准数据集，专注于复杂的合同条款，与双向编码检索器结合点wise大型语言模型再排序器的组合显示出有希望的结果。然而，仍需在复杂法律工作中实现显著改进。ACORD的推出为自然语言处理社区提供了一个有价值的检索基准数据集，有助于合同起草领域的研究和实践发展。", "conclusion": "ACORD作为一个专家注释的数据集，为合同起草领域的信息检索研究提供了基础，尽管在实践中仍有许多挑战需要解决，但其仍可以作为NLP社区的重要基准，推动该领域进一步发展。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.13488", "html_url": "https://arxiv.org/abs/2412.13488", "title": "基于重要性感知稀疏微调策略的语言模型精炼", "title_en": "Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models", "authors": "Xinxin Liu,Aaron Thomas,Cheng Zhang,Jianyi Cheng,Yiren Zhao,Xitong Gao", "background": "参数高效微调（PEFT）通过低秩适应方法（如LoRA）逐渐成为热点。本研究关注于基于稀疏性的PEFT（SPEFT），这种方法通过在模型权重矩阵中引入可训练的稀疏适应，提供了比低秩方法更大的灵活性，能够在选择微调参数时展现出更多的选择性。研究者们通过系统评估了与无成本NAS代理相似的显著性指标，发现基于梯度的简单度量是可靠的，且在性能上与其他最佳选项相当，同时保持了计算效率和稳定表现。此外，研究还比较了静态和动态掩码策略，发现静态掩码策略在训练前预设非零项，可以在不会牺牲性能的情况下提高效率，而动态掩码策略并未表现出显著优势。在NLP任务中，基于梯度的简单静态SPEFT方法在LLM的微调中表现良好，为SPEFT提供了一个简单而有效的基准策略。这些发现挑战了将复杂性视为有效PEFT必要条件的观点。开源框架已经建立了一个可重复的基准平台，供未来的研究使用，相关代码可在[此链接中获取]找到", "innovation": "本研究的主要创新点在于通过引入基于稀疏性和显著性指标的度量方法，提出了简单的梯度基静态SPEFT方法。这种方法在去除冗余参数的同时，提高了模型的微调性能，简化了PEFT过程，同时保持了高效的计算性能和稳健的性能表现。此外，研究还首次系统性地比较了静态和动态掩码策略，表明静态掩码策略可以在不降低性能的前提下提高效率，而动态策略未见显著优势。", "conclusion": "本研究证实，简单的静态SPEFT方法在NLP任务中优于其他微调方法，为SPEFT提供了一个有效的基准。研究挑战了PEFT需要复杂性的观点，同时为未来的研究提供了可重复的基准框架。研究的开源框架已经建立，相关代码可公开访问。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.15630", "html_url": "https://arxiv.org/abs/2501.15630", "title": "NLP中的量子增强注意机制：一种经典-量子混合方法", "title_en": "Quantum-Enhanced Attention Mechanism in NLP: A Hybrid Classical-Quantum Approach", "authors": "S.M. Yousuf Iqbal Tomal,Abdullah Al Shafin,Debojit Bhattacharjee,MD. Khairul Amin,Rafiad Sadat Shahir", "background": "近年来，量子计算的进展为增强深度学习架构开辟了新的途径，特别是在高维度和语境丰富数据（如自然语言处理（NLP））领域。传统的注意机制，如点积注意机制，在捕捉复杂的语义关系方面存在局限性，研究者们需要寻找新的方法来提高NLP模型的效率和表示能力。", "innovation": "本文提出了一种混合经典-量子Transformer模型，通过参数化量子变分电路将token表示嵌入到量子希尔伯特空间中，并利用纠缠感知核相似性。这种方法能够捕捉传统注意机制无法达到的复杂语义关系。实验结果表明，量子注意层能够生成全局一致的注意力图和更分离的潜在特征，同时只需要较少的参数。这项工作展示了经典-量子混合模型作为现有注意机制的有力和资源高效替代品的潜力。", "conclusion": "该模型在多种NLP基准测试中展示了效率和表示能力方面的改进。实验结果揭示，量子注意层能够生成全局一致的注意力图和更分离的潜在特征，同时只需要较少的参数。这突显了经典-量子混合模型作为NLP中现有注意机制的强大且资源高效的替代品的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.19499", "html_url": "https://arxiv.org/abs/2410.19499", "title": "MAPO：MAPO：动量辅助梯度下降提示优化", "title_en": "Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization", "authors": "Anthony Cui,Pranav Nandyalam,Andrew Rufail,Ethan Cheung,Aiden Lei,Kevin Zhu,Sean O'Brien", "background": "在大型语言模型（LLMs）中，提示优化的效率和效果至关重要。现有的技术，如ProTeGi，虽然提高了提示优化的性能，但仍有改进的空间。通过引入动量辅助梯度下降提示优化（MAPO），该论文旨在进一步提高提示优化的速度和效果，同时避免陷入局部最小值和振荡现象，并确保更平衡的候选扩展和选择过程。", "innovation": "MAPO通过使用正自然语言“梯度”和基于动量的扩展来增强提示优化的效率和效果。它跟踪梯度历史以避免局部最小值和振荡，并利用束搜索和上置信边界（UCB）算法实现平衡的候选扩展和选择。与ProTeGi相比，MAPO在基准测试中表现出更快的收敛时间、更少的API调用次数和更高的F1分数，证明了其作为大型语言模型自动提示工程的稳健且可扩展的解决方案的有效性。", "conclusion": "MAPO为大型语言模型中的自动提示工程提供了一种高效的、基于动量的提示优化方法，证明了其在性能和可扩展性上的优势。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.04413", "html_url": "https://arxiv.org/abs/2502.04413", "title": "MedRAG：知识图谱启发式推理增强的检索增强生成技术在医疗辅助中的应用", "title_en": "MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot", "authors": "Xuejiao Zhao,Siyan Liu,Su-Yin Yang,Chunyan Miao", "background": "检索增强生成（RAG）技术非常适合用于处理隐私敏感的电子健康记录（EHR）。它可作为医疗助手的关键模块，帮助减少医疗从业者和患者中的误诊。然而，现有基于启发式的医疗领域RAG模型的诊断准确性和特异性不足，尤其对于具有相似表现症状的疾病。", "innovation": "本文提出了一种名为MedRAG的新模型，该模型通过知识图谱（KG）启发式推理增强RAG，用于根据表现症状检索诊断和治疗建议。MedRAG系统地构建了一个全面的四层级诊断KG，涵盖了各种疾病的诊断关键差异。这些差异通过大型语言模型与相似的EHR动态集成，能够提供更准确和具体的决策支持，并在对话中提出跟进问题，增强个性化医疗决策的个人化程度。实验结果表明，使用KG的信息整合和关系能力，MedRAG提供了更具体的诊断见解，并在减少误诊率方面优于现有的RAG方法。", "conclusion": "MedRAG通过KG启发式推理增强了RAG技术在医疗辅助中的应用，其性能优于现有RAG方法，在减少误诊率方面表现优异。其代码将在指定网站上开源。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.12703", "html_url": "https://arxiv.org/abs/2411.12703", "title": "增强虚假信息传播检测：对比SBERT与高级文本向量化技术", "title_en": "Strengthening False Information Propagation Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques in comparison to BERT", "authors": "Ahmed Akib Jawad Karim,Kazi Hafiz Md Asad,Aznur Azam", "background": "虚假信息的快速传播，尤其是通过在线平台，凸显了亟需可靠的检测系统。本文研究了利用机器学习和自然语言处理技术（具体为支持向量机SVM和BERT）检测假新闻的方法。在这项研究中，作者采用三种不同的文本向量化方法来为SVM模型提供支持：词频逆文档频率（TF-IDF）、Word2Vec和词袋模型（BoW），评估了这些方法在区分真新闻和假新闻方面的有效性。此外，还对比了这些方法与大型语言模型BERT的表现。", "innovation": "本文提出了一种结合支持向量机SVM和多种文本向量化方法（TF-IDF、Word2Vec和BoW）以及大型语言模型BERT的综合方法，用于检测假新闻。研究采用详细预处理步骤、严格的模型实现以及全面的评估来确定最有效的技术。研究表明，虽然BERT在准确性上表现卓越，达到99.98%的准确性和F1得分0.9998，但配备线性内核和BoW向量化方法的SVM模型也表现出色，达到99.81%的准确性和F1得分0.9980，这表明尽管BERT表现更优，但SVM模型的BoW和TF-IDF向量化方法也极具竞争力，并且具有较低的计算要求。", "conclusion": "研究结果表明，虽然BERT在准确性上超过了SVM，但SVM模型利用BoW和TF-IDF向量化方法所提供的性能相当，并具有计算效率更高的优势。这为未来的假新闻检测系统设计提供了参考建议。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00299", "html_url": "https://arxiv.org/abs/2502.00299", "title": "ChunkKV: 保留语义的KV缓存压缩以实现高效长上下文LLM推理", "title_en": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference", "authors": "Xiang Liu,Zhenheng Tang,Peijie Dong,Zeyu Li,Yue Liu,Bo Li,Xuming Hu,Xiaowen Chu", "background": "大语言模型（LLMs）在处理长文本时需要大量的GPU内存，其中关键值（KV）缓存可能占用总内存的70%在推理过程中。现有压缩方法通过评估单个令牌的重要性来减少内存使用，但忽略了令牌之间的关键语义关系，导致上下文片段和性能下降。这主要是因为在压缩过程中，关键的语义结构和上下文连贯性未被完全保留，导致即便是在压缩下重要信息的丢失。", "innovation": "我们引入了ChunkKV，该方法从本质上重新构想了KV缓存压缩，将语义片段视为基本压缩单元而不是孤立的令牌。此方法保留了完整的语言结构和上下文完整性，即使在激进压缩下也能保留关键意义。我们的创新包括一种新的层内索引重复技术，该技术利用保留索引在ChunkKV中跨层更高的相似性，减少了计算开销并提高了26.5%的吞吐量。在具有挑战性的基准LongBench、Needle-In-A-HayStack、GSM8K和JailbreakV的全面评估中，ChunkKV在保持相同的压缩比的同时，精度比最先进的方法高出最多8.7%，这表明语义感知压缩显著提高了长上下文LLM推理的效率和性能，提供了一种简单有效的解决内存瓶颈问题的方法。", "conclusion": "语义感知压缩显著提高了长上下文LLM推理的效率和性能，提供了解决内存瓶颈问题的简单而有效的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02384", "html_url": "https://arxiv.org/abs/2502.02384", "title": "STAIR: 提高通过内省推理改进安全对齐", "title_en": "STAIR: Improving Safety Alignment with Introspective Reasoning", "authors": "Yichi Zhang,Siyuan Zhang,Yao Huang,Zeyu Xia,Zhengwei Fang,Xiao Yang,Ranjie Duan,Dong Yan,Yinpeng Dong,Jun Zhu", "background": "确保大型语言模型（LLMs）的安全性和无害性与它们在应用中的性能同样重要。然而，现有的安全对齐方法通常存在安全性能权衡以及对攻击的敏感性问题，主要是由于它们依赖直接拒绝恶意查询这种策略。研究表明，这类方法在遇到特定恶意查询时，往往难以保持良好的安全性能。因此，该文探讨了如何通过提高模型的内省推理能力来改进安全对齐，以更有效地减少有害输出并保留有用信息，同时增强模型在面对 Jailbreak 攻击时的能力。", "innovation": "本文提出了名为 STAIR 的新框架，它将安全对齐与内省推理相结合。STAIR 使模型能够通过逐步分析和自我改进的推理链（CoT）进行安全风险识别，并通过迭代的偏好优化步骤级推理数据来提高安全性能。此外，还设计了一种过程奖励模型，以指导测试过程中的搜索，以生成更好的响应。实验结果表明，STAIR 在应对有害输出方面效果显著，同时保持了更好的有用性。与传统的直觉对齐策略相比，STAIR 在测试时间上的扩展使其安全性能达到了与 Claude-3.5 相当的水平，能够有效对抗流行的 Jailbreak 攻击。", "conclusion": "本文提出的 STAIR 框架通过整合安全对齐与内省推理，显著减少了有害输出，同时保留了 LLM 的有用性，与 Claude-3.5 竞品相比，在对抗 Jailbreak 攻击方面表现优异。这项工作为提高大语言模型在安全和性能方面的平衡提供了解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11095", "html_url": "https://arxiv.org/abs/2502.11095", "title": "大规模语言模型在心理治疗中的调研：现状与未来方向", "title_en": "A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions", "authors": "Hongbin Na,Yining Hua,Zimu Wang,Tao Shen,Beibei Yu,Lilin Wang,Wei Wang,John Torous,Ling Chen", "background": "当代医疗保健中心理健康日益重要，而传统的人工智能自然语言处理方法难以捕捉心理治疗中所需的动态、情境化互动。大型语言模型（LLMs）因其能够处理大量上下文和多轮推理，具有填补这一空白的巨大潜力。本文通过将心理治疗分解为评估、诊断和治疗等联系紧密的阶段，系统性地探讨了LLM的发展与挑战。现有的研究存在关注常见障碍、语言偏见、研究方法碎片化和理论整合有限等问题，研究还面临着捕捉动态症状波动、克服语言和文化偏见、确保诊断可靠性等挑战。", "innovation": "文章通过提出一个概念性分类体系，将心理治疗划分为评估、诊断和治疗等阶段，并系统性地分析了大型语言模型在这一领域的进展及其面临的挑战。文章还指出了未来研究的方向，包括持续进行多阶段建模、基于心理理论建立实时自适应系统、以及涵盖更广范围的精神障碍和治疗方式，旨在推动更加全面和临床整合的心理治疗大型语言模型系统的开发。", "conclusion": "文章揭示了当前研究中的不平衡，强调了克服语言和文化偏见、确保诊断可靠性的必要性，并提出了未来方向，即持续多阶段建模、基于心理理论的实时自适应系统、以及广泛的研究范围，最终目标是促进更加全面和临床整合的心理治疗大型语言模型的发展。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15294", "html_url": "https://arxiv.org/abs/2502.15294", "title": "圆轮注意：一种加速大语言模型推理的新型圆轮级别注意机制", "title_en": "Round Attention: A Novel Round-Level Attention Mechanism to Accelerate LLM Inference", "authors": "Yaohua Tang,Zhicheng Hu,Kun Cheng,Fan Mo,Qiheng Lv,Hua Wang,Zhi Chen", "background": "随着大语言模型（LLMs）的上下文窗口大小不断增加，其处理复杂长文本任务的能力得到了改善。但是，随着对话轮次的不断增加，需要在GPU内存中存储大量的KV缓存，这严重影响了模型服务系统的效率甚至可用性。该研究通过分析真实的用户对话数据，在对话轮次级别上发现了一种分水岭层，之后各轮次级别的注意力分布显示出显著的相似性。", "innovation": "提出了一种新的圆轮级别注意机制——圆轮注意（Round Attention），该机制选择性地处理以分水岭层的注意力矩阵动态确定的k个最相关轮次的KV缓存。", "conclusion": "理论分析表明，该方法将内存使用量降低了54%到82%，而实验结果证明，加载稀疏的关键轮次KV缓存能够在保持答案准确性的前提下，避免性能退化。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.18023", "html_url": "https://arxiv.org/abs/2502.18023", "title": "基于采样推理检测Vision Large Language Models的知识边界", "title_en": "Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference", "authors": "Zhuo Chen,Xinyu Wang,Yong Jiang,Zhen Zhang,Xinyu Geng,Pengjun Xie,Fei Huang,Kewei Tu", "background": "尽管视觉大型语言模型（VLLMs）在许多任务上取得了进展，但这些模型在处理需要实时信息或知识密集的问题时仍然存在局限性。目前广泛采用的是Retrieval Augmented Generation（RAG）技术来拓展模型的查询范围，然而这会引起成本增加的问题。因此，有必要找到一种方法来检测VLLMs的知识边界，从而更高效地使用如RAG等技术，同时保持甚至提高检索带来的性能提升。", "innovation": "本文提出了一种方法，通过自动构建的数据集对VLLM进行微调，以识别其知识边界。该方法包含两种变体，能够针对不同类型的视觉问答数据集进行测试。实验表明，该方法可以成功描绘VLLM的知识边界，并有效减少不必要的检索，同时保持或提高性能。此外，该方法还能为其他VLLM自动生成类似的知识边界。配合代码即将公开。", "conclusion": "本文提出的方法可以高效地识别VLLMs的知识边界，根据知识边界的描绘可以减少不必要的检索使用，同时保持或提高检索带来的性能提升。该方法还可以跨模型应用，为未经过特定微调的其他VLLMs提供通用的知识边界定义。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14496", "html_url": "https://arxiv.org/abs/2502.14496", "title": "利用信用重新分配促进语言多智能体学习以实现交互环境通用化", "title_en": "Advancing Language Multi-Agent Learning with Credit Re-Assignment for Interactive Environment Generalization", "authors": "Zhitao He,Zijun Liu,Peng Li,Yi R Fung,Ming Yan,Ji Zhang,Fei Huang,Yang Liu", "background": "基于LLM的代理在交互环境中取得了显著进步，如移动操作和网页浏览等领域，甚至超越了计算机使用领域。多代理系统在性能上普遍优于单个代理，但它们在跨环境的一般化方面存在局限性，因为它们依赖于预定义的角色和不充分的语言代理泛化策略。这些问题阻碍了交互环境中的多代理系统进展。", "innovation": "提出了一种具有新颖的多代理信用重新分配(CR)策略的多代理强化学习框架——CollabUIAgents，该策略使用LLM分配过程奖励而不是环境特定的奖励，并通过合成偏好数据进行学习，以培养无角色代理策略的可泛化协作行为。实验证明，该框架提高了多代理系统的性能和跨环境的一般化能力。7B参数系统达到了或超过了强大的闭源模型的结果，并指导CR的LLM也得到了应用。此外，该工作还提供了关于使用粒度化的CR奖励有效促进环境泛化的见解，并适应训练过的LLM在多代理系统中的应用方法。", "conclusion": "框架提升了多代理系统的性能和跨环境的一般化能力，并且7B参数的系统达到了或超过了强大的闭源模型的结果，同时提供了关于信用重新分配在多代理系统应用中的一些有用见解。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11733", "html_url": "https://arxiv.org/abs/2502.11733", "title": "柜中植物，桌面橙子，电话在旁。基于文本模拟环境的场景和语言模型增量学习基准测试", "title_en": "Plant in Cupboard, Orange on Rably, Inat Aphone. Benchmarking Incremental Learning of Situation and Language Model using a Text-Simulated Situated Environment", "authors": "Jonathan Jordan,Sherzod Hakimov,David Schlangen", "background": "该研究背景在于大型语言模型（LLMs）不仅作为聊天机器人的角色，还作为代理系统中的关键组件。这些模型的常识知识会显著影响其作为基于语言的规划者在执行定位或具身动作时的表现。研究者特别评估了LLMs的增量学习能力（基于环境反馈）和受控上下文学习能力，通过一个基于文本的环境来进行这项评估。实验设计包含一系列具有挑战性但有趣的任务，考验代理如何解决与家庭日常物体相关的问题，使用简短信息帮助提升代理的表现，以及使用合成的伪英文单词来检验模型对未知词汇的推理能力。研究发现，商用模型在性能上存在较大差距，几乎所有模型在处理合成单词实验时都表现出困难。", "innovation": "本文的创新点在于引入了一个基于文本的模拟环境，用于测试代理系统的增量学习和受控上下文学习能力，同时使用合成的伪英文单词来评估模型对未知词汇的理解能力。这种实验设计使得研究能够更加全面地评估LLMs在环境情境中执行复杂任务的能力。", "conclusion": "研究结果表明，大型商用模型在性能上存在显著差距，几乎所有模型在处理合成单词实验中都表现不佳。这表明LLMs在理解和处理未知词汇方面仍需要改进，同时也展示了基于文本的模拟环境在评估这些模型性能方面的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.15783", "html_url": "https://arxiv.org/abs/2503.15783", "title": "使用LLMs的语法和游戏内容对齐的强化学习在游戏描述生成中的应用", "title_en": "Grammar and Gameplay-aligned RL for Game Description Generation with LLMs", "authors": "Tsunehiko Tanaka,Edgar Simo-Serra", "background": "游戏描述生成（GDG）是指从自然语言文本生成使用游戏描述语言（GDL）编写的游戏描述的任务。先前的研究探索了利用大规模语言模型（LLMs）的上下文理解能力的生成方法，但准确再现游戏描述中的游戏特征仍然具有挑战性。", "innovation": "本文提出了一种基于强化学习的LLMs微调方法，称为RLGDG。该方法通过引入语法奖励和概念奖励来同时提高语法正确性和对游戏概念的忠实性。此外，采用了一种两阶段的训练策略，其中强化学习（RL）在监督微调（SFT）之后应用。实验结果表明，本文提出的方法在使用单独SFT的基线方法上表现出了显著的优越性。", "conclusion": "我们提出的方法显著优于仅使用监督微调的基线方法，实验结果证明了这种方法的有效性。我们的代码可在以下链接中找到。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.16856", "html_url": "https://arxiv.org/abs/2503.16856", "title": "MMCR：科学论文跨源推理基准", "title_en": "MMCR: Benchmarking Cross-Source Reasoning in Scientific Papers", "authors": "Yang Tian,Zheng Lu,Mingqi Gao,Zheng Liu,Bo Zhao", "background": "科学论文的全面理解需要人工通用智能，涉及跨碎片化和异构信息来源的推理，这是一个复杂且具有实际意义的挑战。视觉-语言模型（VLMs）在涉及单图像或文本页面证据推理的各种任务中取得了显著进展，但它们使用跨源信息进行推理的能力仍然是一个开放的问题。现有的VLMs在处理跨源信息的推理任务时面临很大挑战，尽管表现最好的模型GPT-4o的整体准确率为48.55%，但在多表理解任务中的准确率仅为20%，排名第二的模型Qwen2.5-VL-72B的整体准确率为39.86%.", "innovation": "这项工作提出了MMCR基准，旨在评估VLMs在科学论文中跨源信息推理的能力。MMCR包含276个高质量问题，涵盖了7个主题和10种任务类型。通过18个VLMs的实验表明，跨源推理是现有模型面临的重大挑战。此外，研究了因果推理（CoT）技术对跨源推理的影响，发现在小型模型上产生不利影响，而大型模型则表现大幅提升.", "conclusion": "通过MMCR基准实验展示了现有VLMs在跨源推理任务中的弱点，强调了开发能够有效利用跨源信息进行推理的VLMs的紧迫需求。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.04396", "html_url": "https://arxiv.org/abs/2503.04396", "title": "TableLoRA：针对大型语言模型的表格结构理解低秩适应", "title_en": "TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models", "authors": "Xinyi He,Yihao Liu,Mengyu Zhou,Yeye He,Haoyu Dong,Shi Han,Zejian Yuan,Dongmei Zhang", "background": "表格数据在许多领域中至关重要，大型语言模型（LLMs）在高参数效率的前提下理解和处理表格数据很重要。然而，直接将参数高效的微调（PEFT）技术应用于表格任务存在显著挑战，尤其是在表格序列化和二维结构信息在一维序列中的表示方面。", "innovation": "提出TableLoRA模块，该模块在PEFT中增强LLMs对表格结构的理解。它通过特殊标记来序列化表格并使用2D LoRA提供单元格位置的低秩信息编码。实验表明TableLoRA在四种与表格相关的数据集上表现出色，优于传统LoRA和控制实验中测试的各种表格编码方法。这些发现表明，作为针对表格的LoRA，TableLoRA增强了LLMs处理表格数据的能力，特别是在低参数设置中，显示了其在处理表格相关任务中的潜力.", "conclusion": "TableLoRA提高了大型语言模型在低参数设置下处理表格数据的能力，表明其作为处理表格相关任务的稳健解决方案的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03592", "html_url": "https://arxiv.org/abs/2503.03592", "title": "英语K_量化不不成比例地降低LLMs的多语言性能", "title_en": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance", "authors": "Karl Audun Borgersen,Morten Goodwin", "background": "对于在本地部署的LLMs消费者来说，GGUF格式和k_量化是极其重要的工具，它们能够在保持原模型性能的同时，减小模型大小以适应消费级硬件。每层模型权重的重要性和数据位数紧密相关，这种重要性通过一个名为‘重要性矩阵’的相对较小的文本文件确定，‘重要性矩阵’代表了LLM的标准使用场景。大部分在线的量化文档主要用英文编写，因此学术界提出了疑问：英文重要性矩阵是否会在牺牲多语言性能的同时使性能丧失，或者是否可以通过使用其他语言的重要性矩阵来保留多语言性能。本文通过在三种不同语言（英语、挪威语和马拉雅拉姆语）书写的重要性矩阵上量化解码Llama3.3 70B，并在英文和挪威语的MixEval数据集上进行评估，探讨了上述疑问。", "innovation": "本文创新性地通过对Llama3.3 70B模型使用三种不同语言编写的重要性矩阵进行量化实验，探讨了量化在不同语言下的多语言性能影响。这种方法不仅提供了对当前量化实践的理解，还为多语言LMs的量化研究提供了方向。", "conclusion": "实验结果表明，当前的量化实践并没有不成比例地损害多语言性能。基于此研究，建议开发者在使用重要性矩阵时不必过度担心量化对多语言性能的影响。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24616", "html_url": "https://arxiv.org/abs/2505.24616", "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX", "title_en": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX", "authors": "Nikita Martynov,Anastasia Mordasheva,Dmitriy Gorbetskiy,Danil Astafurov,Ulyana Isaeva,Elina Basyrova,Sergey Skachkov,Victoria Berestova,Nikolay Ivanov,Valeriia Zanina,Alena Fenogenova", "background": "该研究旨在评估俄语大型语言模型（LLMs）的生成能力。背景在于目前缺乏针对俄语LLMs的全面且开放的基准测试，而现有的评估方法往往不够透明和可解释，主要依赖于耗费资源的人类比较。研究者旨在解决这一问题，通过开发一个新颖的评估方法，使模型评估过程更加透明和可解释。", "innovation": "主要贡献在于开发了一个名为POLLUX的全面开源基准测试，包括35种不同难度级别的具体任务类型，总共有2,100个手工设计的专业生成提示。每项任务都根据难度分为简单、中等和困难等级别，并且专家从头构建了整个数据集。此外，研究者还提供了一套用于难以评估生成输出的LLM评估者模型，这组LLM评估者被训练来细致评估生成输出，提供了可扩展且可解释的评估工具，替代了昂贵且不够精确的人类判断。", "conclusion": "该研究通过POLLUX提供了可扩展且可解释的评估和注解工具，有效替代了成本高昂且不够精确的人类判断。这为模型开发提供了有效的评估手段，提高了模型生成任务的可解释性和可靠性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.20083", "html_url": "https://arxiv.org/abs/2506.20083", "title": "连接组合性和分布性语义：通过自动编码器视角探讨潜在语义几何", "title_en": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder", "authors": "Yingji Zhang,Danilo S. Carvalho,André Freitas", "background": "当前分布语义空间可以通过整合成分和象征性质来增强Transformer自回归语言模型的可解释性、可控性、组合性和泛化能力。本文通过成分语义的视角来审视潜在空间几何，探讨如何在符号语义和分布语义之间搭建桥梁，以弥合它们之间的差距，并且综述和对比了三种主流自动编码器架构（变分自动编码器(VAE)、向量量化变分自动编码器(VQVAE)及稀疏自动编码器(SAE)），分析它们在语义结构和可解释性方面的独特潜在几何形状，", "innovation": "本文提供了一种新颖的观点，通过成分语义视角探讨潜在空间几何，为符号语义和分布语义之间的融合开辟新途径，综述和对比了三种主流自动编码器架构，并分析了它们在语义结构和可解释性方面的潜在几何形状，", "conclusion": "本文回顾了三种主流自动编码器架构，探讨了它们通过潜在几何形状如何影响语义结构和可解释性。这对于发展更为强大的语言模型具有重要意义，特别是那些能够融合词频分布和词汇符号知识的语言模型。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15650", "html_url": "https://arxiv.org/abs/2506.15650", "title": "老生常谈但经久不衰：字符 n-gram 在罗马尼亚文本中的潜力", "title_en": "Oldies but Goldies: The Potential of Character N-grams for Romanian Texts", "authors": "Dana Lupsa,Sanda-Maria Avram,Radu Lupsa", "background": "本研究关注罗马尼亚文本的作者归属性问题，使用的ROST语料库是该领域的标准基准。研究系统评估了六种机器学习技术：支持向量机（SVM）、逻辑回归（LR）、k-近邻（k-NN）、决策树（DT）、随机森林（RF）和人工神经网络（ANN），并利用字符 n-gram 特征进行分类。", "innovation": "研究发现，人工神经网络模型在性能上表现出最佳效果，使用 5-gram 特征时取得了四次完美的分类结果。研究表明，轻量级、可解释的字符 n-gram 方法可以为罗马尼亚作者归属性提供切片精度，与更复杂的方法相媲美。研究强调了在资源受限或研究不足的语言环境中，简单的语体特征的潜力。", "conclusion": "结果显示，轻量级、可解释的字符 n-gram 方法可以为罗马尼亚作者归属性提供最先进的准确性，与更复杂的方法相当。我们的研究结果表明，在资源约束或研究不足的语言环境中，简单的语体特征具有巨大潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.09338", "html_url": "https://arxiv.org/abs/2505.09338", "title": "羊驼见，羊驼做：语言模型中上下文敏感现象与困惑机制的一个新视角", "title_en": "Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs", "authors": "Jingcheng Niu,Xingdi Yuan,Tong Wang,Hamidreza Saghir,Amir H. Abdi", "background": "本文研究了语言模型（LMs）在不同提示设置下表现出的一种新现象，即上下文同步（contextual entrainment）。该现象表明，LMs在处理输入提示时会被上下文中的“无关”信息所吸引，即使这些信息对于问题或整个句子的其他部分没有直接影响。研究者观察到，LMs会显著增加提示中之前出现过的任意词项的概率（以对数概率表示），即使这些词项是随机的。这一现象表明，上下文同步是一种独立于词项与问题或句子其他部分的相关性或语义关系的机制。", "innovation": "研究发现了统计上显著的上下文同步现象，这种现象可以被语义因素所影响。通过事实性提示和虚构性提示的效果对比，研究者提出假设认为存在一组对应于上下文同步现象的注意力头（entrainment heads），并开发了一种基于可微掩码的全新发现方法来识别这些头。当关闭这些注意力头时，上下文同步现象被显著减弱，模型生成的输出回归到没有干扰上下文时的状态。这项研究为机制分析和缓解LMs的困惑问题迈出了关键一步。", "conclusion": "本文揭示了上下文同步现象，并通过研究LMs通过注意力头对困惑的反应，为机制分析和缓解困惑问题提供了关键步骤。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.02862", "html_url": "https://arxiv.org/abs/2505.02862", "title": "无法只见树木不见森林：利用启发式和偏误揭示LLMs的非理性选择", "title_en": "Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs", "authors": "Haoming Yang,Ke Ma,Xiaojun Jia,Yingfei Sun,Qianqian Xu,Qingming Huang", "background": "尽管大型语言模型（LLMs）表现卓越，但它们对‘监狱突破’攻击仍然脆弱，这会削弱其安全机制。现有研究多依赖于蛮力优化或手动设计，未能在真实场景中发现潜在风险。因此，急需新的方法来揭示这些风险并提供更强的安全对策。", "innovation": "本文提出了一种新颖的‘监狱突破’攻击框架ICRT，受到人类认知启发式和偏误的启发。利用简单效应，该框架通过认知分解降低恶意输入的复杂性；利用相关性偏误重新组织输入，增强语义一致性和有害输出。此外，引入了一种基于排名的有害性评估指标，超越了传统的成功/失败二元评估方式，利用Elo、HodgeRank和Rank Centrality等排名聚合方法全面定量生成内容的有害性。实验结果表明，该方法能持续绕过主流LLMs的安全机制，生成高风险内容，提供有关‘监狱突破’攻击风险的见解，并助力更强的安全策略。", "conclusion": "本文的研究结果揭示了‘监狱突破’攻击的新路径，并为黑客攻击提供了新的视角，从而为改进LLMs的安全防御提供了有价值的见解。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20888", "html_url": "https://arxiv.org/abs/2505.20888", "title": "EasyDistill: 一种大型语言模型有效知识蒸馏的综合工具包", "title_en": "EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models", "authors": "Chengyu Wang,Junbing Yan,Wenrui Cai,Yuanhao Yue,Jun Huang", "background": "本文介绍了一种名为EasyDistill的全面工具包，用于大型语言模型（LLMs）的有效黑盒和白盒知识蒸馏（KD）。EasyDistill框架提供了多种功能，包括数据合成、监督微调、排名优化和专门为KD场景设计的强化学习技术。该工具包可支持针对快速直观(系统1)和慢速分析(系统2)模型的KD功能。其模块化设计和用户友好的界面使研究者和工业从业者能够无缝地实验和实现最先进的KD策略。此外，EasyDistill还提供了一系列由我们开发的稳健的知识蒸馏模型和基于KD的工业解决方案，以及相应的开源数据集，以适应多种使用场景。此外，我们还描述了EasyDistill如何无缝整合到阿里巴巴云的AI平台（PAI）上。总体而言，EasyDistill使得先进的KD技术在自然语言处理（NLP）社区中更易于获取和具有影响力。", "innovation": "EasyDistill提供了一种全面的解决方案，包括数据合成、监督微调、排名优化和强化学习技术，特别适用于大型语言模型的知识蒸馏。该工具包设计模块化，且用户友好，为研究者和工业从业者提供了一个无缝实验和实施先进KD策略的平台。此外，EasyDistill还提供了强大的知识蒸馏模型和基于KD的工业解决方案，以及相应的开源数据集，以满足各种应用场景的需求。", "conclusion": "EasyDistill使得先进的知识蒸馏技术在大型语言模型上的应用更加贴近实际，并在自然语言处理社区中产生了积极的影响。该工具包易用且功能强大，为学术研究和工业应用之间的对话搭建了桥梁。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.10926", "html_url": "https://arxiv.org/abs/2410.10926", "title": "联邦高效指令调优用于大型语言模型", "title_en": "Federated Data-Efficient Instruction Tuning for Large Language Models", "authors": "Zhen Qin,Zhaomin Wu,Bingsheng He,Shuiguang Deng", "background": "预训练的大语言模型（LLMs）对于人类指令的响应能力依赖于指令调优。联邦学习（FL）能够利用来自多个客户的大量私有指令数据，从而提高模型的数据多样性。但是，现有的联邦调优方式存在数据冗余、计算负担过重以及过拟合到本地数据的问题。同时，集中化的数据高效解决方案在FL中因涉及隐私问题而不适用。因此，亟需一种在保护数据隐私的前提下，同时提高模型调优效果的数据高效联邦调优方法。", "innovation": "本文提出了一种新的联邦数据高效指令调优方法FedHDS，它使用边缘设备上的数据子集对LLMs进行调优，同时减少了同客户内部和跨客户之间的数据冗余，而不共享原始数据。实验结果表明，与现有的基于联邦学习的数据调优方法相比，FedHDS在未见过的任务上能够平均提高10.72%的Rouge-L指标，并且只需使用1.5%以下的数据样本，使得训练效率提高了数倍。", "conclusion": "FedHDS能够在保护数据隐私的前提下，实现对LLMs的高效联邦指令调优，提升模型在未见过任务上的表现，显著减少了数据样本的使用量，同时提高了训练效率。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16383", "html_url": "https://arxiv.org/abs/2506.16383", "title": "大型语言模型在Argument Mining中的应用：一个综述", "title_en": "Large Language Models in Argument Mining: A Survey", "authors": "Hao Li,Viktor Schlegel,Yizheng Sun,Riza Batista-Navarro,Goran Nenadic", "background": "Argument Mining (AM) 是自然语言处理 (NLP) 的一个关键子领域，专注于从文本中提取论证结构。大型语言模型 (LLMs) 的兴起极大地改变了 AM 领域，使其能够在上下文内进行学习、基于提示的生成，并具备跨领域的稳健适应性。本文对 LLM 驱动的 AM 最近的进展进行了系统总结，涵盖了基础理论、标注框架以及精心编目的数据集。文章还提供了 AM 子任务的全面分类学，解释了当代 LLM 技术（如提示、链式推理和检索增强）如何重新配置它们的执行方式。此外，还详细描述了当前的 LLM 架构和方法，批判性地评估了评估实践，并阐明了包括长上下文推理、可解释性和标注瓶颈在内的关键挑战。", "innovation": "本文的主要创新在于提供了一个全面的 AM 子任务分类学，解释了 LLM 技术如何重新配置 AM 的执行方式。此外，文章还详述了当前的 LLM 架构和方法，批判性地评估了评估实践，并详细罗列了关键挑战。特别强调了在 LLM 基础上进行计算论证的研究趋势，并提出前瞻性的研究议程，为研究者指明方向。", "conclusion": "文章总结并指出了在 LLM 基础上进行计算论证的新兴趋势，并提出了一个前瞻性的研究计划，以战略性地指导该快速发展的领域的研究人员。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23224", "html_url": "https://arxiv.org/abs/2505.23224", "title": "MMBoundary: 通过推理步骤置信度校准提升MLLM知识边界意识", "title_en": "MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration", "authors": "Zhitao He,Sandeep Polisetty,Zhiyuan Fan,Yuchen Huang,Shujin Wu,Yi R. Fung", "background": "近年来，多模态大型语言模型（MLLM）取得了显著进展，但在多模态推理方面仍面临内在挑战，需要多层级（如感知、推理）和多粒度（如多步推理链）的高级推理。现有对模型置信度估计的工作主要专注于整体响应的训练和校准，未能评估每一推理步骤中的置信度，导致不准确推理的累积。本文背景在于解决这一问题的重要性及现有方法的局限性。", "innovation": "本文提出了MMBoundary，一个新颖的框架，旨在通过推理步骤置信度校准提高MLLM的知识边界意识。创新之处在于引入了互补的文本和跨模态自奖励信号来估计每个推理步骤中的置信度。此外，通过监督微调MLLM并引入基于多奖励函数的强化学习阶段，进一步提升模型知识的一致性和每步推理的置信度校准，增强推理链的自我修正能力。实验结果表明，MMBoundary在多种领域数据集和指标上显著优于现有方法，平均每减少7.5%的多模态置信度校准误差，任务性能提升高达8.3%。", "conclusion": "MMBoundary通过引入推理步骤置信度校准的方法，显著提高了MLLM的知识边界意识，这种框架在多模态推理上具有更好的准确性，且能够有效减少模型的不可靠推理倾向，从而提高了任务性能。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.04931", "html_url": "https://arxiv.org/abs/2501.04931", "title": "通过洗牌不一致性对多模态大型语言模型进行破解", "title_en": "Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency", "authors": "Shiji Zhao,Ranjie Duan,Fengxiang Wang,Chi Chen,Caixin Kang,Shouwei Ruan,Jialing Tao,YueFeng Chen,Hui Xue,Xingxing Wei", "background": "多模态大型语言模型（MLLMs）已经在商业应用中取得了显著的成果并被实际应用，然而仍然存在潜在的安全机制漏洞。现有方法如复杂优化方法或精心设计的图文提示，虽然能够在一定程度上绕过模型的安全机制，但是对商业封闭源代码的MLLMs来说，攻击成功率低。之前的研究主要集中在通过理解和绕过模型的安全机制来达到破解目的，但并未找到足够的证据表明这一过程中的理解能力和安全能力存在不一致性问题。", "innovation": "本文发现，MLLMs在理解打乱的有害指令方面表现出良好的能力，但在安全性方面容易被这些打乱的有害指令绕过，导致产生有害响应。基于这一发现，本文提出了一种基于查询的黑盒优化方法的图文破解攻击，即SI-Attack，以充分利用这种不一致性，并克服洗牌的随机性。实验表明，SI-Attack在三个基准上提高了攻击性能，特别是在商业MLLMs如GPT-40或Claude-3.5-Sonnet上，显著提升了攻击成功率。", "conclusion": "研究表明，通过利用MLLMs在理解和安全性之间的不一致性，SI-Attack可以有效地突破现有的安全机制，提高对商业MLLMs的攻击成功率。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.20474", "html_url": "https://arxiv.org/abs/2506.20474", "title": "时间在我这边：视频聊天对话中发言时间共享的动力学", "title_en": "Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations", "authors": "Kaixiang Zhang,Justine Zhang,Cristian Danescu-Niculescu-Mizil", "background": "每个对话都有多个说话者在分摊说话时间，这种分摊可以是平衡的，也可以是不平衡的。谈话时间的分配与每位说话者在整个对话中的角色和互动方式有关，反映了不断进行中的协商过程。先前的研究侧重于整体的谈话时间分布，但缺乏对导致这些分布的具体动态过程的理解。因此，本文旨在建立一个计算框架来量化谈话时间的分配，并分析导致这种分配的动态过程。通过应用此框架到大量视频聊天数据中，发现说话时间的分配不仅会影响整体平衡性，还会影响说话者的感知和偏好，尤其是那些较少发言的说话者更倾向于平衡的对话。此外，不同类型的谈话时间共享动态即使在产生相同程度的平衡时也会导致不同的感知效果，强调了本研究引入的新分类框架的重要性。最后，本文提出此框架对于设计人类-人类和人类-人工智能通信平台提供了新的工具。", "innovation": "本文引入了一种新的计算框架，用于量化谈话时间的分配，并分析导致这种分配的动态过程。这种新的框架有助于理解不同类型的谈话时间共享动态如何影响参会者的感知和偏好，尤其是较少发言的说话者更倾向于平衡对话。此外，对不同类型的谈话时间共享动态产生了不同的感知效果，强调了新引入的分类框架的重要性，并为设计计算机中介通信平台提供创新工具", "conclusion": "本文框架为设计人类-人类和人类-人工智能通信平台提供了新工具，有助于优化对话中说话时间的分配，改善用户体验。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01370", "html_url": "https://arxiv.org/abs/2501.01370", "title": "基于嵌入的超党派新闻检测方法", "title_en": "Embedding-based Approaches to Hyperpartisan News Detection", "authors": "Karthik Mohan,Pengyu Chen", "background": "本文描述了一个旨在识别给定新闻文章是否属于超党派新闻（即具有极端政治立场并意图制造政治分裂）的系统。研究团队尝试了包括n-grams、情感分析以及使用预训练ELMo的句子和文档表示等多种方法。", "innovation": "研究采用了基于预训练ELMo和双向LSTM的方法，并在10折交叉验证中达到了83%的准确率，且在超参数调优方面没有进行过多调整，这显示了模型具有较好的泛化能力。", "conclusion": "该研究提出了一种高效的超党派新闻检测方法，并通过实验证明了利用预训练的语言模型可以有效识别超党派新闻。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.19723", "html_url": "https://arxiv.org/abs/2412.19723", "title": "OS-Genesis: 通过反向任务合成自动化GUI代理轨迹构建", "title_en": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis", "authors": "Qiushi Sun,Kanzhi Cheng,Zichen Ding,Chuanyang Jin,Yian Wang,Fangzhi Xu,Zhenyu Wu,Chengyou Jia,Liheng Chen,Zhoumianze Liu,Ben Kao,Guohao Li,Junxian He,Yu Qiao,Zhiyong Wu", "background": "图形用户界面（GUI）代理得益于视觉-语言模型（VLMs）的助力，展现了类似人类的计算机操控能力。然而，训练这些代理的一大瓶颈在于收集高质量的轨迹数据。现有方法依赖于人力监督或生成合成数据来执行预定义任务，但这些方法要么耗费大量资源，要么难以保证数据质量，更关键的是数据多样性和合成数据与真实环境的巨大差距。", "innovation": "OS-Genesis 是一种新颖的 GUI 数据合成管道，它反转了传统的轨迹收集过程。该方法让代理首先感知环境并执行逐步交互，然后根据这些交互生成高质量的任务以实现轨迹级的探索。通过应用轨迹奖励模型确保生成轨迹的质量，OS-Genesis 有效地改善了训练 GUI 代理在极具挑战性的在线基准测试中的表现。详细的分析进一步验证了 OS-Genesis 的效率及其在数据质量和多样性方面优于现有方法的效果。", "conclusion": "实验结果表明，使用 OS-Genesis 训练 GUI 代理可以在高度挑战性的在线基准测试中显著改善其性能。此外，深入分析进一步证明了 OS-Genesis 的高效性以及其在数据质量和多样性方面的显著优势。相关的代码、数据和检查点可在指定链接处找到。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.13214", "html_url": "https://arxiv.org/abs/2408.13214", "title": "基于大型语言模型和深度学习方法的信息融合的EUR-USD汇率预测", "title_en": "EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods", "authors": "Hongcheng Ding,Xuanze Zhao,Ruiting Deng,Shamsul Nahar Abdullah,Deshinta Arrova Dewi", "background": "准确预测欧元兑美元的汇率对于投资者、企业和政策制定者至关重要。本文提出了一种新型框架IUS，该框架整合了来自新闻和分析的非结构化文本数据和外汇及金融指标的结构化数据，以提高汇率预测的准确性。研究背景强调了汇率预测对经济和金融领域的重要性以及已有模型的不足，从而引出了新的解决方案。", "innovation": "本文创新地将大型语言模型用于情感极性评分和汇率移动分类，结合定量特征输入因果驱动特征生成器。使用Optuna优化的Bi-LSTM模型实现了汇率预测。结果显示该方法优于基准模型，MAE降低了10.69%，RMSE降低了9.56%。进一步表明，非结构化和结构化数据融合可以比单一的结构化数据提供更高的准确性。此外，通过Optuna选择的前12个重要定量特征结合文本特征证明是最有效的。这些创新为多源数据整合的汇率预测提供了有力的新方法。", "conclusion": "提出的IUS框架和Optuna-Bi-LSTM模型提供了一种多源数据综合的新型汇率预测方法，有效提高了预测准确率，为未来的汇率研究和应用提供了新的思路。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10432", "html_url": "https://arxiv.org/abs/2503.10432", "title": "BeamLLM：利用大语言模型实现视距毫米波波束预测", "title_en": "BeamLLM: Vision-Empowered mmWave Beam Prediction with Large Language Models", "authors": "Can Zheng,Jiguang He,Guofa Cai,Zitong Yu,Chung G. Kang", "background": "在毫米波（mmWave）通信系统中，高训练开销和延迟是常见的挑战。本文以一个真实的车辆到基础设施（V2I）场景为评测背景，旨在解决这些问题.", "innovation": "提出了基于大语言模型（LLMs）的BeamLLM框架，结合计算机视觉（CV）与LLMs的跨模态推理能力，通过重新编程技术从RGB图像中提取用户设备（UE）的位置特征并将其视觉-时间特征与LLMs的语义空间对齐，从而实现毫米波波束预测。与传统的深度学习模型相比，该方法在标准预测任务中显示了显著的性能优势，特别是在少量样本的预测场景中.", "conclusion": "在标准预测任务中，该方法在top-1和top-3的准确性分别为61.01%和97.39%，优于传统的深度学习模型。在少量样本预测场景中，从第1到第10的时间样本，top-1和top-3的性能下降分别仅为12.56%和5.55%，表现出较强的预测能力."}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.13868", "html_url": "https://arxiv.org/abs/2411.13868", "title": "在人类编辑下的大型语言模型水印鲁棒检测", "title_en": "Robust Detection of Watermarks for Large Language Models Under Human Edits", "authors": "Xiang Li,Feng Ruan,Huiyuan Wang,Qi Long,Weijie J. Su", "background": "水印技术被用来有效地区分由大型语言模型（LLMs）生成的文本与人类撰写的文本。然而，LLM生成的文本中普遍存在人类编辑，这侵蚀了水印信号，显著降低了现有方法的检测性能。文章通过混合模型检测人类编辑，提出了一种新的检测被篡改水印文本的方法——截断拟合优度检验（Tr-GoF），证明了Tr-GoF在大量文本修改和趋近于零的水印信号情况下能实现Gumbel-max水印的鲁棒检测。", "innovation": "本文提出了一种基于截断拟合优度检验（Tr-GoF）的新方法，能够在大量文本修改和微弱水印信号条件下有效检测水印文本，且无需精确的人类编辑水平或LLM的概率规格。与需精确信息的Neyman-Pearson最大似然比检验相比，Tr-GoF表现出更高的鲁棒性和效率。相比现有方法使用的基于求和的检测规则，Tr-GoF更能抵抗编辑引入的噪声，且在适度文本修改的情况下检测效率最高。", "conclusion": "文章通过Tr-GoF方法成功地提高了水印在大型语言模型生成文本中的检测性能，并在多处实证分析中证明了其在合成数据和开源LLM（包括OPT和LLaMA）上的竞争力和优越性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03313", "html_url": "https://arxiv.org/abs/2503.03313", "title": "LLM作为GNN：基于文本标注图的图词汇学习", "title_en": "LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph Foundation Models", "authors": "Xi Zhu,Haochen Xue,Ziwei Zhao,Wujiang Xu,Jingyuan Huang,Minghao Guo,Qifan Wang,Kaixiong Zhou,Yongfeng Zhang", "background": "文本标记图（TAGs）在现实场景中无处不在，通常具有独特的结构和领域特定知识。现有的方法试图将大型语言模型（LLMs）和图神经网络（GNNs）整合到TAGs中，但它们的架构往往是解耦的，这限制了它们的协同作用潜力。此外，现有方法将未登录词汇（OOV）分配给图节点，导致了图形特定的语义、词汇量爆炸和与面向任务的提示模板不兼容的问题，这阻碍了跨图形和任务的转移学习能力。这些挑战促使寻求一种新的方法来解决这些问题。", "innovation": "本文提出了一种基于图形词汇学习的通用图形基础模型（PromptGFM），它包括两个关键组件：（1）图理解模块，明确提示LLMs在文本空间中复制精细的GNN工作流程，促进GNN-LLM的无缝集成和优雅的图形-文本对齐；（2）图推理模块，通过基于语言的图形词汇确保表达性、可转移性和可扩展性，使得LLMs微调可以遵循清晰的指令。大量的实验展示了PromptGFM在不同图形和任务上的优越性和转移学习能力。", "conclusion": "广泛的实验结果证明了PromptGFM的优越性和在各种图形和任务上的可转移性。提出的Graph理解模块和Graph推理模块有效地解决了现有方法存在的问题，为文本标注图的处理提供了一种新的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.20380", "html_url": "https://arxiv.org/abs/2502.20380", "title": "单步骤奖励下的多轮代码生成", "title_en": "Multi-Turn Code Generation Through Single-Step Rewards", "authors": "Arnav Kumar Jain,Gonzalo Gonzalez-Pumariega,Wayne Chen,Alexander M Rush,Wenting Zhao,Sanjiban Choudhury", "background": "现有方法要么根据反馈生成代码，要么使用复杂且分层的强化学习来优化多轮奖励，这种方法较为复杂。该研究旨在解决从多轮执行反馈生成代码的问题，探索一种仅使用单步骤奖励即可解决多轮代码生成的简单且可扩展的方法。", "innovation": "提出了一种名为$μ$Code的新方法，该方法利用单步骤奖励迭代训练生成器和验证器，生成器基于多轮执行反馈生成代码解决方案，验证器评估新生成的代码。该研究的关键见解是，代码生成是一个一可恢复MDP问题，可以通过单步骤从任何中间代码状态恢复正确的代码。通过实验评估，该方法显著优于现有最佳基线方法，并且对于利用执行反馈的有效性进行了分析。", "conclusion": "实验结果表明，$μ$Code方法在利用执行反馈方面表现出色，并且比当前最佳基准方法有显著改进。对于奖励模型和策略的设计选择进行了分析，并展示了$μ$Code方法的有效性。该研究的代码可以在提供的链接处获取。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11604", "html_url": "https://arxiv.org/abs/2506.11604", "title": "VLM@school -- Evaluation of AI image understanding on German middle school knowledge", "title_en": "VLM@school -- Evaluation of AI image understanding on German middle school knowledge", "authors": "René Peinl,Vincent Tischler", "background": "目前使用的基准数据集大多基于英文，并且往往依赖于人工制造的难题或脱离语境的问题。这些基准数据集未能反映实际的中学课程内容，导致在评估视觉语言模型（VLMs）的能力时忽略了具体的视觉推理和主题背景知识的结合。", "innovation": "本文介绍了第一个专为评估结合视觉推理和特定背景知识的任务的德语语言VLMs设计的基准数据集。该数据集来源于真实的中学课程内容，包括数学、历史、生物学和宗教等九个领域，并且包含了2000多个基于486张图像的开放性问题，确保模型必须结合视觉解释和事实推理，而不是依赖于表面文本提示。此外，还评估了多种最先进的开放权重VLMs在多个维度上的表现，包括特定领域的准确性和对抗性问题的表现。研究结果表明，即使最强的模型也只实现不到45％的整体准确性，并且在音乐、数学和对抗性设置中表现尤为不佳，从而揭示了基准测试中流行标准与实际多模态理解之间的显著差异。", "conclusion": "中学水平的任务为测试VLMs提供了有意义但未充分利用的途径，尤其是在非英语语境中。该数据集和评价协议为更好地理解和改进未来AI系统的视觉和语言推理能力提供了严格的测试平台。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.20758", "html_url": "https://arxiv.org/abs/2502.20758", "title": "LLMs中的集体推理：无参考答案的答案验证框架", "title_en": "Collective Reasoning Among LLMs: A Framework for Answer Validation Without Ground Truth", "authors": "Seyed Pouyan Mousavi Davoudi,Amin Gholami Davodi,Alireza Amiri-Margavi,Mahdi Jafari", "background": "本文介绍了一种新的方法，其中多个先进的大型语言模型，具体是GPT-4-0125-preview、Meta-LLAMA-3-70B-Instruct、Claude-3-Opus和Gemini-1.5-Flash合作生成并回答复杂的、博士级别的概率问题，而无需依赖任何已知的“正确”参考。研究的重点是如何不同模型之间的共识可以反映其输出的可靠性和生成的问题的整体质量，而不是依赖于已建立的真实基准。为了衡量这种多模型一致性的程度，本文采用了包括卡方检验、Fleiss的κ系数和置信区间计算在内的一系列统计评估方法，从而既捕捉了答案的精确性也反映了问题表述的清晰度。研究结果揭示了Claude和Gemini倾向于更连贯和不暧昧地提出问题，这在置信区间更窄且与响应代理的更高一致性中得到了体现。相比之下，LLAMA的置信区间更宽，一致性水平更低，表明其问题表述的变异性更大且一致性更低。这些观察结果支持多模型协作策略不仅提高了答案的可靠性，还提供了一种基于数据的机制来评估和提高问题质量，尤其是在没有明确解的情况下。", "innovation": "本文提出了一种新的方法，其中多个大型语言模型协作生成和解答复杂概率问题，无需依赖任何已知的正确答案。研究通过统计评估方法验证了不同模型间的共识程度，并通过这些共识反映了问题生成的质量。研究揭示了不同模型在问题生成上的差异，并提出多模型协作可以提高答案的可靠性和有效评估问题质量的有效性，即使在没有正确答案的情况下。", "conclusion": "本文通过多模型协作策略，提供了一种有效的机制来验证和改进问题的质量，即使在没有明确答案的情况下。这种工作提供了行动性的见解，以提高通过异构语言模型协同作用来引导的推理过程的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14949", "html_url": "https://arxiv.org/abs/2502.14949", "title": "KITAB-Bench: 多域阿拉伯OCR和文档理解基准", "title_en": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding", "authors": "Ahmed Heakl,Abdullah Sohail,Mukul Ranjan,Rania Hossam,Ghazi Shazan Ahmad,Mohamed El-Geish,Omar Maher,Zhiqiang Shen,Fahad Khan,Salman Khan", "background": "随着检索增强生成（RAG）在文档处理中的广泛应用，稳健的文本识别变得愈发关键，以支持知识提取。虽然用于识别英文及其他语言的光学字符识别（OCR）技术得益于大规模数据集和成熟的标准测试，但阿拉伯OCR面临着独特的挑战，其中包括其连笔书写、自右向左的文本流动以及复杂的字体和书法特征。当前的评价系统留下了一些空白，缺乏一个全面的评估框架来解决这些问题。", "innovation": "本文提出了KITAB-Bench，这是一个全面的阿拉伯OCR基准，填补了当前评价系统的空白。该基准包括来自9个主要领域和36个子领域的8,809个样本，覆盖了包括手写文本、结构化表格以及业务智能领域内21种图表在内的多种文档类型。研究表明，现代的视觉语言模型（如GPT-4o、Gemini、Qwen）在字符错误率（CER）方面比传统的OCR方法（如EasyOCR、PaddleOCR和Surya）平均高出60%。此外，本文还指出了当前阿拉伯OCR模型在PDF到Markdown转换方面的显著限制，其中最好的模型Gemini-2.0-Flash的准确率仅为65%。这突显了准确识别阿拉伯文本的挑战，包括复杂字体问题、数字识别错误、单词拉长和表格结构检测等方面的问题。", "conclusion": "本文建立了一个严格的评价框架，能够推动阿拉伯文档分析方法的改进，缩小阿拉伯OCR技术与英文OCR技术之间的性能差距。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21710", "html_url": "https://arxiv.org/abs/2506.21710", "title": "FOCUS: 内部多模态大型语言模型表示以实现高效细粒度视觉疑问解答", "title_en": "FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering", "authors": "Liangyu Zhong,Fabio Rosenthal,Joachim Sicking,Fabian Hüger,Thorsten Bagdonat,Hanno Gottschalk,Leo Schwinn", "background": "虽然多模态大型语言模型（MLLMs）能够为图像-文本输入提供强大的感知和推理能力，但是针对小图像细节的视觉问题回答（VQA）依然存在挑战。尽管视觉裁剪技术占据了希望，然而现有方法仍存在一些不足，如任务特定的微调需求、由于缺乏启发式的穷尽搜索而造成的低效率，或者与高效的注意力实现不兼容等问题。", "innovation": "本文通过提出一种无需训练的基于MLLM内部表示的视觉裁剪方法，FOCUS来解决这些不足。FOCUS方法通过四个步骤实现：首先，确定VQA提示中的目标对象；其次，使用键值（KV）缓存计算对象相关性图；接着，根据该图提出并排名相关图像区域；最后，使用排名顶层的区域执行细粒度的VQA任务。相比现有方法，FOCUS显示了强健的表现，在四个细粒度VQA数据集上和两种类型的MLLM中均实现了优异的效果，且在准确性和效率上超越三种流行的视觉裁剪方法，并且只用了更少的计算资源（3-6.5倍）。", "conclusion": "提出的FOCUS方法利用MLLM的内部表示，在无需训练的情况下指导图像区域搜索，有效提高了细粒度VQA的性能和效率，从而提升了VQA针对小图像细节的能力。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21722", "html_url": "https://arxiv.org/abs/2506.21722", "title": "阐明和赋予扩散训练范式以通用图像恢复能力", "title_en": "Elucidating and Endowing the Diffusion Training Paradigm for General Image Restoration", "authors": "Xin Lu,Xueyang Fu,Jie Xiao,Zihao Fan,Yurui Zhu,Zheng-Jun Zha", "background": "尽管扩散模型在图像恢复任务（IR）中表现出强大的生成能力，但由于其复杂架构和迭代过程，这些模型的实际应用受到限制，无法与主流的重建基通用普通IR网络相媲美。现有方法主要集中在优化网络架构和扩散路径，但忽略了将扩散训练范式整合到通用普通IR框架中的集成方法。因此，本研究通过系统分析时间步依赖性、网络层次结构、噪声级关系和多恢复任务的相关性，来阐明将扩散训练范式应用于通用IR训练的关键原则，提出了一个新的基于扩散训练的IR框架。", "innovation": "引入了一系列正则化策略，使IR网络能够同时恢复图像并建模生成表示，从而在单任务场景中提高泛化能力。认识到基于扩散的方法在不同IR任务中的影响不同，开发了一种增量训练范式和任务特定适配器，进一步提高了多任务统一IR中的性能。", "conclusion": "实验表明，该方法显著提高了单任务IR中IR网络的泛化能力，并在多任务统一IR中取得了优异性能。值得注意的是，提出的框架可以无缝集成到现有的通用IR架构中。"}
{"llm_update_time": "20250630", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19897", "html_url": "https://arxiv.org/abs/2505.19897", "title": "ScienceBoard: 在现实科学工作流程中评估多模态自主代理", "title_en": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows", "authors": "Qiushi Sun,Zhoumianze Liu,Chang Ma,Zichen Ding,Fangzhi Xu,Zhangyue Yin,Haiteng Zhao,Zhenyu Wu,Kanzhi Cheng,Zhaoyang Liu,Jianing Wang,Qintong Li,Xiangru Tang,Tianbao Xie,Xiachong Feng,Xiang Li,Ben Kao,Wenhai Wang,Biqing Qi,Lingpeng Kong,Zhiyong Wu", "background": "大型语言模型（LLMs）已经超越了自然语言处理的范畴，促进了跨学科研究的发展。这些模型催生了多种基于LLM的代理，这些代理可以协助科研发现的进步。特别地，能够在操作系统中与之交互的人类级交互代理正在引领自动化科学研究问题解决和研究人员工作流程中的常规任务自动化。在此背景下，本文介绍了一个名为ScienceBoard的框架，旨在评估这些代理在更现实的科学工作流程中的性能。", "innovation": "ScienceBoard框架包含了两个核心贡献：其一，融合了动态丰富的可视化科学工作流和专业软件的多领域现实环境，这些环境支持代理通过多接口自主交互，以提升复杂的科研任务和实验效率；其二，包含169项高质量、严格验证的真实世界任务的基准测试集，覆盖了生物化学、天文学和地理信息系统等多个科学发现工作流程领域。此外，它还提供了一个深入分析当前代理局限性，并提出有效设计原则的途径，通过这些原则可以构建更强大的代理以支持科学发现。这项工作不仅在现实中提供了复杂的科研任务和环境，也为代理技术的进一步发展奠定了坚实基础。", "conclusion": "通过与最新的代理模型（如GPT-4o、Claude 3.7、UI-TARS等）进行广泛比较，研究发现，尽管这些模型在某些任务上表现不错，但它们在复杂工作流程中的可靠性仍然不足，整体成功率只有15%。此外，深入分析进一步揭示了当前代理技术的局限性，并提出了更有效的设计原则，为未来构建更强大的科学研究代理铺平了道路。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21681", "html_url": "https://arxiv.org/abs/2506.21681", "title": "TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360° Panorama Generation", "title_en": "TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360° Panorama Generation", "authors": "Hakan Çapuk,Andrew Bond,Muhammed Burak Kızıl,Emir Göçen,Erkut Erdem,Aykut Erdem", "background": "近期在图像生成方面取得了显著进展，但在全景图像生成方面仍然面临挑战，包括几何失真程度不一致和无缝环视一致性要求。现有的模型难以解决这些问题。", "innovation": "引入了TanDiT方法，该方法通过生成覆盖整个360°视角的切平面图像网格来合成全景场景。TanDiT利用统一的去噪模型在同一去噪迭代中同时生成这些切平面图像，而不像之前的多扩散分支方法那样。此外，还提出了一种模型无关的后处理步骤，以增强生成的全景图之间的全局一致性。为了准确评估全景图像质量，还提出了两种专门的度量标准，即TangentIS和TangentFID，并提供了一个含有多图注释全景数据集和标准化评估脚本的基准。", "conclusion": "广泛实验表明，本方法能够有效泛化到训练数据之外，稳健地解释详细的复杂文本提示，并与各种生成模型无缝结合，生成高质量多样的全景图像。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21724", "html_url": "https://arxiv.org/abs/2506.21724", "title": "Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning", "title_en": "Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning", "authors": "Remco F. Leijenaar,Hamidreza Kasaei", "background": "从不结构化的3D点云中学习具有语义意义的表示仍然是计算机视觉中的一个核心挑战，尤其是在缺乏大规模标注数据集的情况下。虽然掩蔽点建模（MPM）在自我监督的3D学习中广泛应用，但其基于重建的目标可能会限制其捕捉高层次语义的能力。", "innovation": "我们提出了AsymDSD，这是一种不对称的双自蒸馏框架，它通过在潜空间而不是输入空间进行预测来统一掩蔽建模和不变性学习。AsymDSD基于联合嵌入结构，并引入了几种关键设计选择：高效不对称设置、禁止掩蔽查询之间的注意力以防止形状泄露、多掩蔽采样以及多视图点云的多剪辑改编。", "conclusion": "AsymDSD在ScanObjectNN上取得了最佳结果（90.53%），并在预训练93万形状时进一步提高到93.72%，超过了之前的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21711", "html_url": "https://arxiv.org/abs/2506.21711", "title": "CAST: 十字注意的时空特征融合在深度假新闻检测中的应用", "title_en": "CAST: Cross-Attentive Spatio-Temporal feature fusion for Deepfake detection", "authors": "Aryan Thakre,Omkar Nagwekar,Vedang Talekar,Aparna Santra Biswas", "background": "深度伪造（Deepfakes）已经成为数字媒体真实性的重大威胁，增加了对先进检测技术的需求，这些技术能够识别细微且时间依赖的篡改。卷积神经网络(CNN)擅长捕捉空间特征，而变换器(Transformer)则在建模时间不一致方面表现突出。然而，许多现有的CNN-Transformer模型独立处理空间和时间特征。特别是，基于注意力的方法通常分别使用空间和时间特征上的注意力机制，并通过简单的加权平均、叠加或连接组合它们，这限制了时空交互的深度。为了解决这一挑战，本文提出了一种统一的CAST模型，通过交叉注意力有效融合时空特征，使时间特征能够动态地注意相关时空区域，提高模型检测时域变化细微缺陷（如闪烁的眼睛和扭曲的唇部）的能力。该设计使精确定位和更深层次的上下文理解成为可能，从而在各种复杂的场景中提高了性能。", "innovation": "本文提出了CAST模型，通过交叉注意力更好地融合时空特征，使模型能够动态地注意相关区域，从而更准确地检测细微时间变化的艺术，增强了检测性能，并通过FaceForensics++、Celeb-DF和DeepfakeDetection数据集的评估证实了这种方法的优势，展示了在新数据集上的出色泛化能力。", "conclusion": "本文通过CAST模型展示了跨注意力机制在深度伪造视频检测中的有效性，模型在FaceForensics++、Celeb-DF和DeepfakeDetection数据集上的AUC分别为99.49%和97.57%，同时在未知的DeepfakeDetection数据集上达到了93.31%的AUC，表明了CAST模型在提升深度伪造视频检测的鲁棒性方面的优越性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21770", "html_url": "https://arxiv.org/abs/2506.21770", "title": "使用多个视网膜图像数据集的深度学习早期青光眼检测", "title_en": "Early Glaucoma Detection using Deep Learning with Multiple Datasets of Fundus Images", "authors": "Rishiraj Paul Chowdhury,Nirmit Shekar Karkera", "background": "青光眼是导致不可逆失明的主要原因，但早期检测可以显著提高治疗效果。传统的诊断方法通常具有侵入性，需要专门的设备。本文提出了一种使用EfficientNet-B0架构的深度学习管线，用于从视网膜视网膜底片图像中进行青光眼检测。传统的研究依赖单一数据集，而本文则通过在ACRIMA、ORIGA和RIM-ONE数据集上依次训练和微调模型以增强泛化能力。实验结果表明，最少的预处理可以比复杂的增强技术获得更高的AUC-ROC，并且模型在未见数据集上表现出强大的判别性能。该提出的管线提供了一种可重复和可扩展的早期青光眼检测方案，支持其潜在的临床应用价值。", "innovation": "本文利用多个数据集（ACRIMA、ORIGA和RIM-ONE）依次训练和微调模型以增强泛化能力；提出了一种最少预处理即可获得良好结果的深度学习方法；在未知数据集上表现出强大的判别性能.", "conclusion": "本文提出的深度学习管道提供了一种可重复和可扩展的早期青光眼检测方案，支持其潜在的临床应用价值."}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21731", "html_url": "https://arxiv.org/abs/2506.21731", "title": "通过互斥概率空间和局部相关性假设探索图像生成", "title_en": "Exploring Image Generation via Mutually Exclusive Probability Spaces and Local Correlation Hypothesis", "authors": "Chenqiu Zhao,Anup Basu", "background": "在现有的概率生成模型中，学习全局分布可能会导致模型记忆而不是生成。这通常是在变分自编码器（VAE）中观察到的现象，其中潜在变量分布存在重叠，导致重构损失和KL散度之间的优化冲突。因此，提出了互斥概率空间（MESP）来理解这种现象，并在此基础上提出了一种二元潜在自编码器（BL-AE）用于图像到二元潜在表示的编码。尽管BL-AE在生成模型上取得了与最新方法相当的FID分数，但这些分数反映的是记忆行为而不是生成行为。因此，提出了一种局部相关性假设（LCH），认为生成能力来源于潜在变量之间的局部相关性。", "innovation": "提出了两个理论框架，互斥概率空间（MESP）和局部相关性假设（LCH），来探讨在概率生成模型中学习全局分布可能导致记忆而非生成的问题。基于MESP，提出了二元潜在自编码器（BL-AE），将图像编码为二元潜在表示，并通过自主生成模型（ARVM）输出直方图。LCH则提出了局部相关性在生成能力中的作用。", "conclusion": "通过MESP和LCH，作者验证了他们的框架，并且提出ARVM实现了与现有最先进的方法相当的FID分数，同时强调了这些分数反映了记忆行为而非生成行为。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21785", "html_url": "https://arxiv.org/abs/2506.21785", "title": "egocentric 视频总结中学习范式比较", "title_en": "Comparing Learning Paradigms for Egocentric Video Summarization", "authors": "Daniel Wen", "background": "研究通过评估不同计算机视觉范式（监督学习、无监督学习和提示微调）在理解与解释第一人称视视频数据方面的表现，分析了现有模型在第一人称视频总结中的局限性，特别是在与第三人称视频对比的情况下。重点在于展示当前最先进的模型在处理第一人称视频时的效果较差，并指出在该领域的进一步发展的需求。", "innovation": "研究通过使用最新的监督学习模型 Shotluck Holmes、无监督学习模型 TAC-SUM 和通用的提示微调模型 GPT-4o，对现有方法进行评估，并特别强调了提示微调的一般性模型在适应第一人称视角挑战时的表现优于专业模型，从而指出现有方法的局限性。", "conclusion": "虽然研究仅在 Ego-Exo4D 数据集中的一小部分第一人称视视频上进行了评估，但主要目的是提供一种全面的概念验证分析，旨在推动计算机视觉技术在第一人称视频中的应用和发展。通过探索新的方法并评估其潜力，研究旨在促进能够有效处理和解释第一人称视角的模型的发展。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21826", "html_url": "https://arxiv.org/abs/2506.21826", "title": "通过视觉基础模型的线性探测实现历史地图的少量样本分割", "title_en": "Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models", "authors": "Rafael Sterzinger,Marco Peer,Robert Sablatnig", "background": "历史地图是丰富的历史来源，提供了关于历史变化的关键洞察。然而，它们多样化的视觉表示和有限的标注数据使得自动化处理极具挑战性。作者利用大型视觉基础模型丰富的语义嵌入和参数高效的微调技术，提出了一种简单的少量样本分割历史地图的方法。该方法在Siegfried基准数据集的葡萄园和铁路分割方面优于现有技术，特别是在10次样本设定中相对提高了5%的mIoU，在更具挑战性的5次样本设定中则接近提高了20%。此外，该方法在ICDAR 2021竞赛数据集上表现出色，尽管没有针对这个形状敏感的指标进行优化，仍达到了67.3%的平均PQ分数，证实了其泛化能力。在非常低的数据条件下（10次和5次样本），尽管仅需689k可训练参数（即整个模型大小的0.21%），该方法仍保持了高性能，实现了对多样化历史地图的精确分割，大幅减少了手动注释的需求，推进了该领域的自动化处理和分析。我们的实现已公开发布：this https URL", "innovation": "作者提出了一种结合大型视觉基础模型丰富的语义嵌入和参数高效的微调的新方法，以实现少量样本的分割历史地图，并在葡萄园和铁路分割方面显著超越了现有的技术，展示了其在形状敏感度指标和低数据条件下的广泛适用性。方法仅需要689k可训练参数，表明其高效性", "conclusion": "该方法在低数据条件下保持了高性能，大幅减少了手动注释的需求，推动了自动化处理和历史地图分析的发展。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21813", "html_url": "https://arxiv.org/abs/2506.21813", "title": "CAT-SG：用于白内障手术精细理解的大规模动态场景图数据集", "title_en": "CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery", "authors": "Felix Holm,Gözde Ünver,Ghazal Ghazaei,Nassir Navab", "background": "理解白内障手术的复杂工作流程需要建模手术工具、解剖结构和操作技术之间的复杂交互。现有的数据集主要针对手术分析的孤立方面，如工具检测或阶段划分，缺乏涵盖实体随时间演变的语义关系的全面表示。", "innovation": "该论文引入了Cataract Surgery Scene Graph (CAT-SG)数据集，这是首个提供工具-组织交互、程序变体和时间依赖性的结构化注解的数据集。通过结合详细的语义关系，CAT-SG提供了手术工作流程的整体视图，使更准确地识别手术阶段和技巧成为可能。此外，还提出了一个新型场景图生成模型CatSGG，其在生成结构化手术表示方面优于现有方法。CAT-SG数据集旨在增强AI驱动的手术培训、实时决策支持和工作流程分析，促进了更智能、更上下文感知的临床系统的发展。", "conclusion": "CAT-SG数据集为AI驱动的手术流程提供了全面的理解，改进了手术阶段和技巧的识别，并促进了更智能的临床系统的发展。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21835", "html_url": "https://arxiv.org/abs/2506.21835", "title": "ProSAM：通过概率提示增强SAM基视觉参考分割的鲁棒性", "title_en": "ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts", "authors": "Xiaoqi Wang,Clint Sebastian,Wenbin He,Liu Ren", "background": "近年来，大型基础模型的进步推动了开放集图像分割任务的成功，该任务旨在分割预定义类别之外的对象。在各种提示类型（如点、框、文本和视觉参考）中，视觉参考分割因其独特的灵活性和较强的零样本能力而突出。最近，SAM基方法通过自动生成引导SAM的提示取得了显著进展，但这些方法往往在对象边缘生成提示，由于提示编码器的不足，这导致了不稳定性并降低了鲁棒性。", "innovation": "本文介绍了一种名为ProSAM的简单但有效的方法，用于解决现有SAM基视觉参考分割方法中识别的稳定性挑战。通过学习变分提示编码器来预测多变量提示分布，ProSAM避免在不稳定区域生成提示，克服了由于提示鲁棒性不足导致的不稳定性。", "conclusion": "我们的方法在Pascal-5i和COCO-20i数据集上持续超越了最先进的方法，提供了更鲁棒的视觉参考分割解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21742", "html_url": "https://arxiv.org/abs/2506.21742", "title": "ImplicitQA: 向隐式视频推理迈进", "title_en": "ImplicitQA: Going beyond frames towards Implicit Video Reasoning", "authors": "Sirnam Swetha,Rohit Gupta,Parth Parag Kulkarni,David G Shatwell,Jeffrey A Chan Santiago,Nyle Siddiqui,Joseph Fioresi,Mubarak Shah", "background": "视频问答 (Video QA) 已经通过多模态学习显著进步，实现了视觉和文本模态之间的对齐。然而，现有的基准测试主要关注可以通过显式视觉内容（如动作、物体和事件）回答的问题。相比之下，创意和电影视频（如电影、电视剧和叙事驱动的内容）使用讲故事的技巧，故意省略某些描绘，要求观众通过不连续帧之间的推理来推测动机、因果关系和关系。人类天生擅长这种隐式推理，能够无缝地在时间和上下文中整合信息以构建连贯的故事。当前的视频问答系统和基准测试不能捕捉到这种类似于人类的理解本质维度。为了弥合这一差距，本文提出了 ImplicitQA，这是一种全新的基准测试，旨在测试模型的隐式推理能力。它包括1000个精心标注的问答对，来自320多个高质量的创意视频片段，系统地分类为关键推理维度：横向和纵向的空间推理、深度和接近性、视角和可见性、运动和轨迹、因果和动机推理、社会互动、物理背景以及推断计数。这些注释故意具有挑战性，由作者精心打造以确保高质量。", "innovation": "提出了 ImplicitQA，这是一种新的基准测试，旨在测试模型的隐式推理能力。它涵盖了1000个问答对，来自320多个高质量的创意视频片段，系统地分类为几个关键推理维度。这些注释都是精心制作的，以确保高质量。该基准测试的目的是揭示当前领先的视频问答模型在隐式推理方面的性能下降，并突显他们在依赖表层视觉线索方面的能力。通过对领先模型的广泛评估，发现不同模型之间的性能差异，进一步证明了 ImplicitQA 提供的挑战的复杂性和多样性。通过发布数据集和数据收集框架，作者希望激发社区内的进一步研究和发展。", "conclusion": "本文通过释放 ImplicitQA 数据集和数据收集框架，旨在推动社区进一步研究和开发。通过对领先模型的表现进行评估，揭示了它们在隐式推理方面的局限性，并强调了在设计更好的视频问答系统时对这种能力的迫切需求。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21834", "html_url": "https://arxiv.org/abs/2506.21834", "title": "PrefPaint: 通过专家人类反馈增强图像修复", "title_en": "PrefPaint: Enhancing Image Inpainting through Expert Human Feedback", "authors": "Duy-Bao Bui,Hoang-Khang Nguyen,Trung-Nghia Le", "background": "图像填充（inpainting）技术在多个领域有广泛应用，尤其是在医学成像中。然而，在医学腺瘤成像等对准确性和可靠性要求极高的专业领域，现有的图像填充模型可能会生成不准确的图像，导致医学诊断和治疗中出现重大错误。因此，医学图像需要由专家，如肿瘤学家进行注释，以确保模型训练的有效性。", "innovation": "本文提出了PrefPaint，这是一种将人类反馈融入到Stable Diffusion Inpainting训练过程中的方法，避免了使用计算成本高昂的奖励模型。此外，研发了一个基于Web的界面来简化训练、微调和推理过程。这个交互式的界面提供了流畅且直观的用户体验，使得提供反馈和管理微调过程变得更加容易。用户研究显示 PrefPaint 在各个领域均优于现有方法，减少了视觉不一致，并提高了图像渲染效果，尤其是在医学领域生成更逼真的腺瘤图像。", "conclusion": "PrefPaint 通过引入专家人类反馈到图像填充模型的训练过程中，克服了传统方法的计算负担，提高了图像修复的准确性。该方法经用户研究证实，在医学应用中尤其有效，生成更现实的腺瘤图像。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21832", "html_url": "https://arxiv.org/abs/2506.21832", "title": "TaleForge：个性化故事创作的交互式多模态系统", "title_en": "TaleForge: Interactive Multimodal System for Personalized Story Creation", "authors": "Minh-Loi Nguyen,Quang-Khai Le,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le", "background": "现有的故事生成方法往往将用户视为被动消费者，提供的故事情节缺乏个性化，不能充分融入用户的个人风格和外貌。这种方法削弱了用户的参与感和沉浸感，尤其是在个人风格或外观至关重要的场景中。大多数现有方法未能充分利用用户独一无二的信息来创建故事内容，导致缺乏个性化的叙事体验。", "innovation": "该论文介绍了一款名为TaleForge的个性化故事生成系统，它通过结合大型语言模型和文本到图像的扩散技术，使用户能够将自己的面部照片嵌入到故事叙述和插图中。TaleForge具有三个模块：故事生成、个性化图像生成以及背景生成。此外，用户研究显示，当用户作为主角出现在故事中时，能够提高参与感和归属感。参与者赞扬了系统的实时预览功能和直观控制，但希望进一步改进叙事编辑工具。TaleForge通过将个性化文本和图像结合，提升了多模态故事讲述的效果，创造了以用户为中心的沉浸式体验。", "conclusion": "实验结果显示，TaleForge能够显著增强用户的参与感和对故事的归属感，尤其是当用户直接成为故事的一部分时。尽管存在用户对编辑工具的改进需求，但TaleForge代表了个性化故事创作的创新步骤，并且为未来的多模态故事生成系统奠定了基础。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21735", "html_url": "https://arxiv.org/abs/2506.21735", "title": "NCA赋能的公平联邦学习", "title_en": "Equitable Federated Learning with NCA", "authors": "Nick Lemke,Mirko Konstantin,Henry John Krumb,John Kalkhof,Jonathan Stieber,Anirban Mukhopadhyay", "background": "联邦学习（FL）允许机构之间不共享敏感患者数据的情况下，进行模型协作训练。特别是在低收入和中等收入国家（LMICs），由于医疗专业人员的有限访问，此方法尤其有价值。然而，FL在LMICs中的应用面临显著障碍，包括缺乏高性能计算资源和不稳定的互联网连接。因此，并非所有设备都能支持FL的高效实施，且网络通信的安全性也是一个问题。", "innovation": "为了应对这些挑战，本研究引入了FedNCA（基于NCA的联邦学习系统），这是一种专门为医疗图像分割任务设计的创新性FL系统。FedNCA利用轻量级的Med-NCA架构，使其能够在低成本的边缘设备上，如广泛可用的智能手机上进行训练，同时最大限度地降低成本通信需求。此外，别具一格的是，我们的FedNCA是基于加密设计的，可以应对网络通信遭到破坏的情况。这使FedNCA成功克服了基础设施和安全上的障碍，为低资源地区提供了更公平、高效、轻量级和加密准备好的医疗成像解决方案，促进了医疗保健的普惠性发展。", "conclusion": "通过FedNCA，我们能够提供一种创新的方法，为LMICs中医疗图像分割任务的联邦学习提供技术支持。这种方法使医疗图像处理在资源有限的地区变得更加可行，并且更加专注于建立公平且高效的医疗成像解决方案，从而有助于资源受限地区的医疗保健进步。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21851", "html_url": "https://arxiv.org/abs/2506.21851", "title": "端到端RGB-IR联合图像压缩与通道级跨模态熵模型", "title_en": "End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model", "authors": "Haofeng Wang,Fangtao Zhou,Qi Zhang,Zeyuan Chen,Enci Zhang,Zhao Wang,Xiaofeng Huang,Siwei Ma", "background": "RGB-IR图像对在智能监控等应用中被频繁同时应用，但随着模态数量的增加，所需的数据存储和传输成本也会成倍增加。因此，有效的RGB-IR数据压缩变得至关重要。这项工作提出了一种RGB-IR图像对的联合压缩框架，旨在充分利用跨模态先验信息，准确进行上下文概率建模，以提高压缩效率并降低存储和传输成本。", "innovation": "提出了一种通道级跨模态熵模型（CCEM），其中包括低频上下文提取块（LCEB）和低频上下文融合块（LCFB），用于从两个模态中提取和聚合全局低频信息，辅助模型更准确地预测熵参数。这种新方法通过在LLVIP和KAIST数据集上的实验结果证明了其在比特率节省方面的优势，相较于CVPR 2022的最新RGB-IR图像编解码器，节省了23.1%的比特率。", "conclusion": "实验结果表明，本方法在LLVIP和KAIST数据集上的性能优于现有RGB-IR图像对和单模态压缩方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21862", "html_url": "https://arxiv.org/abs/2506.21862", "title": "LLaVA-Scissor: Semantic Connected Components for Video LLMs", "title_en": "LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs", "authors": "Boyuan Sun,Jiaxing Zhao,Xihan Wei,Qibin Hou", "background": "之前的压缩方法主要通过关注分数来压缩token，但未能有效捕捉所有语义区域，导致token冗余。LLaVA-Scissor提出了一种基于语义连接组件（SCC）的方法，该方法将token分配到token集合中的不同语义区域，确保全面的语义覆盖，从而提出了一种分步骤的空间-时间token压缩策略，该策略在空间和时间域中都利用了SCC，能够有效压缩token，用一组不重叠的语义token来表示整个视频。", "innovation": "LLaVA-Scissor提出了一种基于SCC的训练无介的token压缩策略，不同于之前主要基于关注分数的方法。这种策略能够在空间和时间上有效压缩token，确保全面的语义覆盖，适用于视频大规模语言模型。实验结果表明，LLaVA-Scissor在多种视频理解基准测试中表现优异，特别是在低token保留率方面。", "conclusion": "LLaVA-Scissor在视频理解基准测试中展现出了优越的token压缩能力，特别是在低token保留率的情况下。与其它token压缩方法相比，给出了更好的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21857", "html_url": "https://arxiv.org/abs/2506.21857", "title": "SPADE: 利用数据专家混合方法实现空间转录组学与病理学对齐以构建具有表达能力的潜在空间", "title_en": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "authors": "Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold", "background": "数字病理学的迅速发展和自我监督深度学习的进步，使得跨多种疾病的各种病理任务的基础模型得以发展。虽然已经出现了将多种数据源结合的方法，但在将整个切片图像(WSI)与空间转录组学(ST)全面整合方面仍存在关键差距。这对于超越标准苏木精与伊红(H&E)染色捕获关键分子异质性至关重要。", "innovation": "SPADE引入了一种基础模型，将组织病理学与ST数据结合，在统一框架内引导图像表示学习，从而创建一个ST指导的潜在空间。SPADE采用混合数据专家技术，通过两个阶段的空间特征聚类创建专家，利用对比学习来学习配对注册的WSI斑块和基因表达谱的表示。SPADE在HEST-1k全面数据集上预训练，并在14个下游任务中得到评估，显示与基线模型相比显著的少量样本性能优势，突显了将形态学和分子信息整合到一个潜在空间中的益处。", "conclusion": "SPADE模型能够在统一框架中整合组织病理学与空间转录组学数据，通过混合数据专家技术构建一个ST指导的潜在空间，显著提升了形态学和分子信息整合后的少量样本性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21839", "html_url": "https://arxiv.org/abs/2506.21839", "title": "GenEscape：生成逃脱房间谜题的分层多智能体生成", "title_en": "GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles", "authors": "Mengyi Shan,Brian Curless,Ira Kemelmacher-Shlizerman,Steve Seitz", "background": "现有的文本到图像模型在生成视觉吸引力强、逻辑坚实且富有智力挑战性的逃脱房间谜题图像方面存在挑战。基础图像模型在空间关系和使用功能分析方面表现不佳。本文提出了一个分层多智能体框架，将生成任务分解为功能设计、符号场景图推理、布局合成和局部图像编辑四个结构化阶段。不同的智能体通过迭代反馈协作，确保场景在视觉上一致且功能上可解。实验表明，这种智能体协作提高了生成的谜题在可解性、避免捷径和使用功能清晰度方面的质量，同时保持了视觉质量。", "innovation": "提出了一种分层多智能体框架，将生成逃脱房间谜题图像的任务分解为功能设计、符号场景图推理、布局合成和局部图像编辑四个结构性阶段。不同智能体通过迭代反馈协作，确保场景既在视觉上又在功能性上是协同的。这种方法显著提高了生成的谜题的质量。", "conclusion": "分层多智能体框架通过将复杂的任务分解为多个阶段并让专门的智能体协作迭代改进，成功生成了视觉吸引力强、逻辑坚实且富有智力挑战性的逃脱房间谜题图像。实验结果表明，这种方法在提高谜题的可解性、避免捷径和使用功能清晰度方面表现优异，同时保持了较高的视觉质量。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21866", "html_url": "https://arxiv.org/abs/2506.21866", "title": "Dual-Perspective United Transformer for Object Segmentation in Optical Remote Sensing Images", "title_en": "Dual-Perspective United Transformer for Object Segmentation in Optical Remote Sensing Images", "authors": "Yanguang Sun,Jiexi Yan,Jianjun Qian,Chunyan Xu,Jian Yang,Lei Luo", "background": "自动从光学遥感图像（ORSIs）中分离出对象是一项重要的任务。现有的模型大多基于卷积或Transformer特征，各自具备不同的优点。结合两者的优点是有价值的研究，但同时也会面临多种挑战，如特征异构性、模型复杂性和参数量大等问题。这些挑战往往在现有ORSIs方法中被忽视，导致分割结果不理想。因此，需要提出一种新的方法来解决这些问题。", "innovation": "我们提出了一种新的Dual-Perspective United Transformer（DPU-Former），该模型具有独特的结构，旨在同时集成远距离依赖和空间细节。特别地，我们设计了全局-局部混合注意力，通过两种视角捕获多样信息，并引入了傅里叶空间合并策略以有效融合信息。此外，我们还提出了一种门控线性前馈网络来增加表示能力。同时，我们构建了一个DPU-Former解码器，用于在不同层上聚合和增强特征。因此，DPU-Former模型在多个数据集上的性能优于现有最佳方法。", "conclusion": "DPU-Former模型在多个数据集上的性能显著优于现有最佳方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21855", "html_url": "https://arxiv.org/abs/2506.21855", "title": "周期性掩码自动编码器：用于rPPG估计的周期性视频掩码自动编码器", "title_en": "Periodic-MAE: Periodic Video Masked Autoencoder for rPPG Estimation", "authors": "Jiho Choi,Sang Jun Lee", "background": "研究领域聚焦于通过非标签面部视频学习周期信号的一般表示。难点在于捕捉皮肤色调随时间的微妙变化，并利用这些变化估计遥远的光电容积描记法（Remote Photoplethysmography, rPPG）。现有方法通常依赖于监督学习，但缺乏大量标注数据使其受限。因此，开发能够有效捕捉周期性信号的方法并将其应用于rPPG估计具有重要意义。", "innovation": "本文提出了一种方法，使用视频掩码自动编码器在网络从未标记的面部视频中学习高维时空表示时捕捉面部区域的微小变化。该方法通过帧掩码在预训练阶段捕捉采样后的周期信号，并利用生理信号在频带内的稀疏性来提供脉冲线索，同时将预训练的编码器转移到rPPG任务处理面部视频中的生理信号提取。这种方法在PURE、UBFC-rPPG、MMPD和V4V数据集上的广泛实验中显示出显著性能提升，特别在跨数据集评估中表现优异。", "conclusion": "本文提出的方法在多个数据集上进行了广泛的实验评估，证明了其在rPPG估计中的优越性能，特别是在跨数据集评估中表现突出。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21885", "html_url": "https://arxiv.org/abs/2506.21885", "title": "智能车辆中多模态传感器集成：针对智能车辆的融合技术综述", "title_en": "Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles", "authors": "Chuheng Wei,Ziye Qin,Ziyan Zhang,Guoyuan Wu,Matthew J. Barth", "background": "多传感器融合对于增强自动驾驶感知、克服单一传感器局限性和实现全面环境理解起着关键作用。本文首先将多传感器融合策略分为数据级、特征级和决策级，并系统地回顾了针对每种策略的基于深度学习的方法。此外，还介绍了多模态数据集的关键信息及其解决现实世界挑战的应用情况，特别是在恶劣天气条件和复杂城市环境中。", "innovation": "提出了多模态数据集的应用场景，特别是在恶劣天气和复杂城市环境下的适用性。探讨了视觉语言模型（VLMs）和大型语言模型（LLMs）的集成，强调了传感器融合在端到端自动驾驶中的作用，并指出了它能够提升系统适应性和鲁棒性的潜力。", "conclusion": "本文提供了当前多传感器融合方法及其未来发展方向的洞察，旨在为自动驾驶中多传感器融合的研究提供参考。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21843", "html_url": "https://arxiv.org/abs/2506.21843", "title": "3D-Telepathy：从EEG信号重构3D物体", "title_en": "3D-Telepathy: Reconstructing 3D Objects from EEG Signals", "authors": "Yuxiang Ge,Jionghao Cheng,Ruiquan Ge,Zhaojie Fang,Gangyong Jia,Xiang Wan,Nannan Li,Ahmed Elazab,Changmiao Wang", "background": "从脑电信号（EEG）数据重构三维视觉刺激在脑-计算机接口（BCI）和辅助沟通障碍个体方面具有重要潜力。传统上，研究人员主要将大脑活动转化为二维图像，忽视了将EEG数据转化为三维对象的过程。这一限制是值得注意的，因为无论观察二维图像还是现实世界，人脑都会固有地处理三维空间信息。脑电信号捕捉到的神经活动包含丰富的空间信息，而当仅重构二维图像时，这些信息不可避免地丢失，限制了其在BCI的实际应用。将EEG数据转化为三维对象重构面临许多问题，包括EEG信号中的大量噪声和缺乏包含EEG和三维信息的训练数据集，这使得从EEG提取三维视觉数据的提取过程复杂化。这些难题使得将三维结构直观地呈现成为一项艰巨的任务，且缺乏有效解决途径。因此，本文探讨了从脑电信号进行三维物体重构的挑战并提出了解决办法。", "innovation": "本文提出了一个创新的EEG编码器架构，该架构结合了双自注意力机制。使用一种混合训练策略进行训练，该策略包括交叉注意力、对比学习和自监督学习技术。此外，通过采用稳定扩散作为先验分布并利用变分得分蒸馏训练神经辐射场，成功地从EEG数据生成了具有相似内容和结构的三维物体，为图灵测试（或中文房间测试）中从大脑电活动重建物体的技术提供了一种新方法。此次创新旨在解决从脑电信号构建实时三维场景或3D-Telepathy的挑战，通过提高神经网络对输入数据的理解和生成三维物体的能力，实现大脑电活动到三维空间的重构，进一步推动BCI领域的发展和应用，为数据有效获取和通信障碍患者辅助生活提供了更多可能。", "conclusion": "本研究提出了一种结合双自注意力机制的创新EEG编码器架构，并采用混合训练策略，通过稳定扩散和变分得分蒸馏技术成功从EEG数据生成了具有相似内容和结构的三维物体。该方法能够更充分地捕捉和利用脑电信号中的空间信息，为脑-计算机接口、以及辅助个体沟通障碍的应用提供了新的范式。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21891", "html_url": "https://arxiv.org/abs/2506.21891", "title": "DIVE: 深度搜索迭代视频探索", "title_en": "DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025", "authors": "Umihiro Kamoto,Tatsuya Ishibashi,Noriyuki Kugo", "background": "此次挑战旨在评估生成关于多样性和真实世界视频片段的准确自然语言答案的能力。CVRR-ES基准包括214个独特的视频和2400个跨11个类别的问题-答案对。在该挑战中，来自不同团队的解决方案进行了测试与比较。", "innovation": "提出了一种名为DIVE的方法，该方法采用迭代推理方式处理每个输入问题。它将每个问题的语义分解，并通过逐步推理和逐步推断来逐步解决。这种方法能提供高度准确且上下文相关的答案，特别是在处理复杂查询时。DIVE在CVRR-ES基准上的测试集上取得了81.44%的准确性，确保了参赛者中的领先地位，展示了迭代推理框架在视频问题回答中的有效性与鲁棒性。", "conclusion": "通过全面分析实验结果，证明了以迭代推理框架为基础的视频问题回答方法的有效性和鲁棒性。相关代码已公开发布。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21905", "html_url": "https://arxiv.org/abs/2506.21905", "title": "RAUM-Net: 区域注意力和概率校准的Mamba网络", "title_en": "RAUM-Net: Regional Attention and Uncertainty-aware Mamba Network", "authors": "Mingquan Liu", "background": "细粒度视觉分类（FGVC）由于类间细微差异和脆弱的特征表示仍然是计算机视觉中的一个具有挑战性的任务。现有的方法在细粒度场景下表现不佳，特别是在标记数据稀缺的情况下.", "innovation": "本文提出了一种半监督方法，结合了基于Mamba的特征建模、区域注意力以及贝叶斯不确定性选择高质量伪标签以增强局部到全局特征建模，并在学习过程中专注于关键区域。通过贝叶斯推断，选择高质量的伪标签以提高稳定性.", "conclusion": "实验表明，该方法在包含遮挡的FGVC基准测试上表现出强劲性能，并在标记数据有限的情况下表现出鲁棒性。代码可在该链接处找到：this https URLNet."}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21863", "html_url": "https://arxiv.org/abs/2506.21863", "title": "遥感大型视觉-语言模型：基于语义增强的多层级对齐与语义感知专家建模", "title_en": "Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling", "authors": "Sungjune Park,Yeongyun Kim,Se Yeon Kim,Yong Man Ro", "background": "大型视觉语言模型（LVLMs）在自然图像领域的多种视觉语言任务中表现出了强大的性能。然而，这些模型在遥感（RS）领域的应用仍然受到限制，因为遥感图像与自然图像在视觉表现、对象尺度以及语义上存在显著差异。这些差异阻碍了对遥感场景的准确理解，而遥感场景包含从宏观到微观的丰富多层级语义信息。这限制了现有LVLMs直接适应遥感图像的能力。因此，为了解决这一问题，有必要为遥感理解设计一种新的LVLM框架，结合语义增强的多层级对齐和语义感知专家建模两大核心组件，以应对遥感图像的独特挑战和需求，进一步提升在多层级语义理解中的表现，尤其是场景分类和视觉问答等任务", "innovation": "本文提出了一种针对遥感理解的新颖LVLM框架，该框架包含两个核心组件：1）基于检索的语义增强多层级对齐模块，该模块通过从遥感语义知识数据库中检索相关语义线索，与用户查询和多层级视觉特征聚合，从而生成多层次的语义增强表示；2）语义感知专家建模，其中每个专家负责以不同的层次分别处理语义表示，实现从宏观到微观的分层语义理解。这一框架通过在多个遥感任务中实现跨多个语义层级的持续改进，展示了在填补一般LVLMs与遥感特定视觉语言理解需求之间的差距方面的能力和有效性", "conclusion": "这一研究通过设计语义增强的多层级对齐和语义感知专家建模，能够有效改善大型视觉语言模型在遥感领域的应用，尤其在多个语义层级的遥感任务中实现了稳定的性能提升，展示了其在连接普通LVLMs和独特遥感应用场景需求方面的潜力和优势，对于推动遥感图像理解的进展具有重要意义"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21873", "html_url": "https://arxiv.org/abs/2506.21873", "title": "基于语义关联的标记裁剪：克服裁剪引起的视觉接地性能急剧下降", "title_en": "Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning", "authors": "Tzu-Chun Chien,Chieh-Kai Lin,Shiang-Feng Tsai,Ruei-Chi Lai,Hung-Jen Chen,Min Sun", "background": "近期的多模态大语言模型（MLLMs）在视觉定位方面表现出强大的性能，成为多种视觉-语言应用的通用接口。然而，处理大量视觉标记时，这些模型面临着极高的计算成本，因此推动了标记裁剪方法的发展以减轻这种成本。然而，我们观察到标记裁剪显著削弱了模型的视觉定位能力，导致错误预测和显著的性能下降。例如，在指代表达理解（REC）任务中，标记裁剪使得LLaVA在RefCOCO验证集上的准确率从56.14%下降到15.34%。研究发现，标记裁剪后位置ID的错配是导致这种下降的主要原因，因为位置ID的顺序和值对于保持定位任务中的性能至关重要。", "innovation": "本文提出了一种基于定位感知的标记裁剪方法（GAP），这是一种简单而有效的方法，通过调整位置ID来恢复REC准确率至51.42%，相当于原有未裁剪情况下性能的90%，并且无需额外的训练、内存或计算开销。该方法在Shikra、MiniGPTv2和LLaVA系列等多种标记裁剪策略中广泛应用，能够稳定提升性能。", "conclusion": "我们的方法通过简单调整位置ID就能够显著改善标记裁剪带来的视觉定位性能急剧下降问题，适用于多种多模态大语言模型，提升了它们的通用性与实用性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21903", "html_url": "https://arxiv.org/abs/2506.21903", "title": "使用迁移学习和数据集丰富在教育视频中检测视觉内容", "title_en": "Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment", "authors": "Dipayan Biswas,Shishir Shah,Jaspal Subhlok", "background": "视频正在改变教育方式，线上课程和录制的讲座补充甚至取代了课堂教学。最近的研究集中在通过高级导航、搜索、归纳以及问答聊天机器人来提升视频课程的信息检索能力。视觉元素如表格、图表和插图对于讲座视频的了解、记忆和数据分析至关重要，但是它们在提高视频内容访问方面的潜力未得到充分利用。主要原因包括：视觉元素大多是由人工创建的，没有标准结构；连贯的视觉对象很难界定，可能由连接的文本和视觉组件组成。尽管深度学习对象检测技术取得进展，但由于讲座视频中视觉内容的独特性质以及标注数据集的稀缺性，当前模型的性能还不理想。这项研究报道了一个在讲座视频帧中检测视觉内容的迁移学习方法。通过评估最新的对象检测模型在讲座视频数据集中的性能，YOLO模型被证明是最有前景的。接着，通过多种基准数据集的训练以及半监督自动标注策略，对YOLO进行优化，从而检测讲座视频对象。研究评估了这种方法，开发了一个通用的解决讲座视频中对象检测问题的方案。研究成果包括一个标注的讲座视频帧的公开基准集，以及用于未来研究的源代码。", "innovation": "这项研究采用了迁移学习方法，在讲座视频中检测视觉内容。通过评估多个最先进的对象检测模型并采用YOLO模型进行优化，提高了视觉元素检测的准确性。研究还引入了半监督自动标注策略进行模型训练，提高了模型的鲁棒性和泛化能力。此外，研究提供了标注的讲座视频帧和源代码，为后续研究提供了便利的资源。", "conclusion": "本研究通过使用迁移学习，在讲座视频中检测视觉内容方面取得了突破，优化了对象检测模型，并提供了一个公开的标注数据集和代码。这为其他研究者提供了重大的基础研究资源，为未来进一步提高视频信息检索和理解能力奠定了坚实的基础。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21892", "html_url": "https://arxiv.org/abs/2506.21892", "title": "SODA: 通过邻域传播在领域偏移点云中的异常检测", "title_en": "SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation", "authors": "Adam Goodge,Xun Xu,Bryan Hooi,Wee Siong Ng,Jingyi Liao,Yongyi Su,Xulei Yang", "background": "随着点云数据在多种应用中越来越多，检测点云中的异常（OOD）对象变得至关重要，以确保模型的安全性和可靠性。然而，这一问题在现有研究中仍被下探。受限于3D视觉语言模型（3D VLMs）的预训练数据集规模和多样性较小，主要包含计算机设计的合成对象，这种模型在转移到涉及真实场景对象的任务时，会面临领域偏移（domain shift）。这导致点云与其相关文本嵌入在3D VLM的潜在空间中的对齐度下降，影响下游性能。", "innovation": "本文提出了一种称为SODA的新型方法，通过基于邻域的得分传播方案提高异常点云的检测。SODA是一种推理方法，无需额外的模型训练，并在各种数据集中和问题设定下实现了现有方法的最好性能。", "conclusion": "我们的实验证明，领域偏移显著降低了点云与其关联文本嵌入在3D VLM潜在空间中的对齐度，阻碍了下游性能。为了应对这一挑战，提出了SODA方法，能够通过邻域基于的得分传播方案提高异常点云的检测，且此方法仅需推理，无需额外训练，实现了现有技术的最好性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21883", "html_url": "https://arxiv.org/abs/2506.21883", "title": "GRASP-PsONet: 基于梯度去除错误模式的银屑病严重程度分类", "title_en": "GRASP-PsONet: Gradient-based Removal of Spurious Patterns for PsOriasis Severity Classification", "authors": "Basudha Pal,Sharif Amit Kamran,Brendon Lutnick,Molly Lucas,Chaitanya Parmar,Asha Patel Shah,David Apfel,Steven Fakharzadeh,Lloyd Miller,Gabriela Cula,Kristopher Standish", "background": "银屑病（PsO）的严重程度评分对于临床试验至关重要，但由于评分者之间的一致性较差以及面对面临床评估的负担，这变得有所阻碍。远程影像技术通过患者自行拍摄的移动照片提供扩展性，但引入了照明、背景和设备质量等人类难以察觉的变化，这些都会影响模型的表现。这些因素加上皮肤科医生注释的不一致性降低了自动评分的可靠性。", "innovation": "本文提出了一种框架，利用基于梯度的可解释性方法自动标记导致模型泛化能力受损的问题训练图像。通过追踪误分类验证图像的梯度，检测模型错误与评分不一致的样本对齐或受到细微非临床艺术品影响的培训样本。该方法应用于一种基于ConvNeXT的弱监督模型，设计用于从手机照片中分类银屑病严重程度。剔除标记的8.2%问题图像，模型AUC-ROC提高了5% (85%到90%)。通常，多个注释员和一个更正过程确保注释的准确性，但成本高昂且耗时。本文的方法能够检测注释不一致的训练图像，可能替代手动审查的需要。当应用于两位皮肤科医生评分的数据子集时，该方法审查30%的样本就能识别出90%以上评分不一致的病例，从而提高远程评估的自动化评分的可靠性，确保在数据收集变化中的稳健性。", "conclusion": "本文提出的方法能够检测出训练数据中注释不一致的图像，显著提高模型的泛化能力和自动化评分的准确度，降低了由于数据收集中的变化导致的模型性能下降的风险，有望减少临床评估中的人工审查需求。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21909", "html_url": "https://arxiv.org/abs/2506.21909", "title": "CERBERUS: 用于工程可靠性和城市稳定性的裂纹评估与识别基准", "title_en": "CERBERUS: Crack Evaluation & Recognition Benchmark for Engineering Reliability & Urban Stability", "authors": "Justin Reinman,Sunwoong Choi", "background": "研究用于检测基础设施裂纹和其他缺陷的AI模型需要高质量且多样化的真实数据，但获取这样的数据往往成本高昂且难以实现。因此，一个合成基准可以帮助训练和评估这些AI模型，特别是在不依赖真实数据的情况下测试模型性能。因此，CERBERUS 废墟基准应运而生，旨在提供一种合成环境，用于推进该领域的研究和发展。", "innovation": "CERBERUS 合成基准通过引入一个裂纹图像生成器和在 Unity 中构建的现实3D检查场景，为基础设施缺陷检测提供了新的支持。它区分了两种设置：一种是简单的飞过墙壁检查，另一种是更复杂的十字路口场景，其中包括光照和几何挑战。研究人员使用了流行的物体检测模型 YOLO 进行测试，结果显示，将合成数据与真实数据相结合可以提高模型在实际图像上的性能。CERBERUS提供了灵活且可重复的测试方法，支持未来研究中自动化基础设施检查的应用。", "conclusion": "CERBERUS 合成基准不仅提供了一种经济有效的训练和评估基础设施缺陷检测模型的方法，而且通过其高度可重复和灵活的设计，展望了未来自动化基础设施检测研究的可能性。CERBERUS 公开可用，研究人员可以访问其详细API和文档以进行进一步研究。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21895", "html_url": "https://arxiv.org/abs/2506.21895", "title": "探索通过强化微调实现跨域面部防欺骗的一般化任务解决范式", "title_en": "Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning", "authors": "Fangling Jiang,Qi Li,Weining Wang,Gang Wang,Bing Liu,Zhenan Sun", "background": "近年来，新型的攻击方式引起了对面部防欺骗的越来越多的关注。然而，现有方法倾向于记住训练集的数据模式，导致在不同场景下对未知攻击类型的泛化能力较差，并且缺乏可解释性。现有的面部防欺骗方法主要依赖于模式记忆，这使得它们在面对新的攻击类型时表现不佳，并且解释其决策过程仍然较为困难。", "innovation": "本文提出了一种基于强化微调的面部防欺骗方法，通过刺激多模态大语言模型的思考能力，使其能够自主学习和解决防欺骗任务，而不是仅仅依赖于模式记忆。该方法设计了可验证的类一致奖励和推理一致奖励，并使用基于GRPO的优化策略，引导模型从多个角度探索推理策略以最大化预期奖励。最终，该方法通过迭代试错学习，只保留高奖励轨迹，从广泛的解空间中提取出高度泛化的决策规则，有效地解决了跨域面部防欺骗任务。实验结果显示，该方法在跨域泛化性能方面达到了最先进的水平，并能够很好地泛化到未知攻击类型，同时提供了可解释的推理结果，而不需要大量的文本注解进行训练。", "conclusion": "通过迭代试错学习，本文提出的方法能够从广泛的解空间中提取出高度泛化的决策规则，有效地解决了跨域面部防欺骗任务。该方法在多项实验中展示了良好的跨域泛化性能和可解释的决策过程，证明了其在跨域面部防欺骗领域的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21923", "html_url": "https://arxiv.org/abs/2506.21923", "title": "ZeroReg3D：一种用于连续组织病理图像三维重建的零样本注册管道", "title_en": "ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction", "authors": "Juming Xiong,Ruining Deng,Jialin Yue,Siqi Lu,Junlin Guo,Marilyn Lionts,Tianyuan Yao,Can Cui,Junchao Zhu,Chongyu Qu,Mengmeng Yin,Haichun Yang,Yuankai Huo", "background": "组织病理学分析在理解组织结构和病理方面起着关键作用。虽然最近在注册方法方面的进步提高了2D组织病理学分析的性能，但它们往往无法保留关键的3D空间关系，限制了其在临床和研究应用中的实用性。具体来说，从2D切片构建准确的3D模型仍然具有挑战性，这是因为组织变形、切片伪影、成像技术的变化和不一致的光照。基于深度学习的注册方法显示出了改进的性能，但在普适性方面有限，需要大量的训练数据。相比之下，非深度学习方法具有更好的普适性，但通常会妥协于准确性。因此，迫切需要一种既能提高准确度又能广泛适用的三维重建方法。", "innovation": "该研究引入了ZeroReg3D，这是一种新颖的零样本注册管道，专门用于从连续切片构建准确的3D重建。ZeroReg3D结合了零样本深度学习基于关键点匹配与基于优化的仿射和非刚性注册技术，有效地解决了组织变形、切片伪影、染色变化和光照不一致等关键挑战，无需重新训练或微调即可实现精确的3D重建。该研究通过创新的结合方法，提供了一种新型的解决方案，以提高3D重建的准确性和普适性。", "conclusion": "ZeroReg3D提供了一种有效的方法来解决基于2D切片的3D重建中遇到的挑战，通过结合零样本深度学习和优化技术，实现了高效的3D重建，无需重新训练或微调。该方法已公开发布，为组织病理学和相关研究提供了一种新的工具。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21920", "html_url": "https://arxiv.org/abs/2506.21920", "title": "SepFormer: 从单线到线段的粗细结合边框回归网络用于表格结构识别", "title_en": "SepFormer: Coarse-to-fine Separator Regression Network for Table Structure Recognition", "authors": "Nam Quan Nguyen,Xuan Phong Pham,Tuan-Anh Tran", "background": "表格结构识别（TSR）对于从图像数据中提取语义数据至关重要。近年来，研究人员探索了多种技术来解决这一问题，取得显著进展。每个表格由垂直和水平分隔符组成，基于此，SepFormer 采用基于 DETR（检测器）风格的架构，融合了拆分和合并的单一步骤，利用分段回归来提高速度和鲁棒性。SepFormer 是一种从粗到细的方法，通过堆叠两层变压器解码器逐步预测从单线到线段的表分隔符。模型在粗粒度阶段通过 decoder 层和额外的角度损失逐渐细化单线段，在细粒度阶段通过细化来自每个单线段的样本点来预测线段分隔符。", "innovation": "SepFormer 通过分段回归和基于 DETR 架构的单一步骤融合拆分和合并策略，实现了表格分隔符的高效且稳健的识别，模型在粗粒度阶段通过 angle loss 逐步细化单线段，在细粒度阶段通过细化方法改善了线段分隔符的预测。SepFormer 达到了与当前最先进的方法相当的性能，并且在 SciTSR、PubTabNet、WTW 和 iFLYTAB 等多个基准数据集上取得了平均 25.6 FPS 的运行速度。", "conclusion": "SepFormer 提供了一种新型的表格结构识别方法，能够有效提高速度和鲁棒性，达到了与领先方法相当的性能，适用于多种数据集。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21957", "html_url": "https://arxiv.org/abs/2506.21957", "title": "探索基于语义掩蔽自编码器的自监督点云理解", "title_en": "Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding", "authors": "Yixin Zha,Chuxin Wang,Wenfei Yang,Tianzhu Zhang", "background": "点云理解旨在从未标记数据中获得稳健且通用的特征表示。基于掩蔽点模型的方法在下游任务中表现出显著的性能。然而，预训练方法依赖于随机掩蔽策略来建立点云感知，这导致自监督模型无法有效捕捉合理的语义关系。为了解决这一问题，本研究提出了语义掩蔽自编码器，该模型包括两个主要部分：基于原型的语义建模模块和语义增强的掩蔽策略。", "innovation": "该研究提出了语义掩蔽自编码器，该模型包含两个主要部分：基于原型的语义建模模块和语义增强的掩蔽策略。在语义建模模块中，设计了一种语义引导机制来指导一组可学习的原型捕捉不同组件的语义。利用这些原型，提出了语义增强的掩蔽策略，以有效地覆盖完整的组件结构。此外，引入了语义增强的提示调优策略，进一步利用原型来提高预训练模型在下游任务中的性能。", "conclusion": "在扫描对象NN、ModelNet40和ShapenetPart等数据集上的大量实验表明，本研究提出的模块是有效的。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21925", "html_url": "https://arxiv.org/abs/2506.21925", "title": "AI生成全景图像的质量评估与失真感知显著性预测", "title_en": "Quality Assessment and Distortion-aware Saliency Prediction for AI-Generated Omnidirectional Images", "authors": "Liu Yang,Huiyu Duan,Jiarui Wang,Jing Liu,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Patrick Le Callet", "background": "随着人工智能生成内容(AIGC)技术的迅速发展，人工智能生成图像(AIGI)引起了广泛的关注，特别是在虚拟现实(VR)和增强现实(AR)应用中，AI生成全景图像(AIGODI)具有重要意义。尽管AI生成全景图像具有独特的质量问题，但关于其质量评估和优化的研究相对不足。本研究首次针对AIGODI的质量评估和失真感知显著性预测问题进行研究，进一步提出相应优化过程。", "innovation": "研究提出了一种名为OHF2024的综合数据库，包含多角度主观质量评分和失真感知显著性区域。基于该数据库，提出两种基于BLIP-2模型的具有共享编码器的模型来评估人类视觉体验和预测AI生成全景图像的失真感知显著性，分别命名为BLIP2OIQA和BLIP2OISal。此外，该研究还提出了一种自动优化过程，利用预测的视觉体验评分和失真区域进一步提高AI生成全景图像的视觉质量。实验结果表明，BLIP2OIQA和BLIP2OISal模型在人类视觉体验评估和失真感知显著性预测任务中取得了当前最好(SOTA)的结果，并且可以有效应用于优化过程。数据库和代码将发布在 https://github.com 上以促进未来的研究。", "conclusion": "研究提出了OHF2024数据库、BLIP2OIQA和BLIP2OISal模型以及一种自动优化过程，这些方法在质量评估和优化AI生成全景图像方面取得了SOTA效果，并为未来相关研究提供了支持。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21975", "html_url": "https://arxiv.org/abs/2506.21975", "title": "TASeg: 基于微调视觉基础模型的感知文本RGB-T语义分割", "title_en": "TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models", "authors": "Meng Yu,Te Cui,Qitong Chu,Wenjie Song,Yi Yang,Yufeng Yue", "background": "可靠的开放环境语义分割对智能系统至关重要，但存在两个主要问题：1) 现有RGB-T语义分割模型主要依赖低级视觉特征，缺乏高级文本信息，难以准确分割相似视觉特征的类别。2) 虽然SAM在实例分割方面表现优异，但将其与热成像和文本集成存在模态异质性和计算效率低的问题。", "innovation": "提出了一种基于Low-Rank Adaptation (LoRA) 细调技术的感知文本RGB-T分割框架TASeg。具体创新包括：1) 在图像编码器中引入一种动态特征融合模块(DFFM)，有效融合多种视觉模态的特征，同时冻结SAM的原始Transformer模块。2) 在掩模解码器中结合CLIP生成的文本嵌入，实现语义对齐，进一步纠正分类错误，提高语义理解准确性。", "conclusion": "在多种数据集上的实验结果表明，本方法在具有挑战性的情景下具有优秀的表现，且使用更少的可训练参数。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22015", "html_url": "https://arxiv.org/abs/2506.22015", "title": "通过指数力剪枝实现通用且高效的模型压缩", "title_en": "Towards Universal & Efficient Model Compression via Exponential Torque Pruning", "authors": "Sarthak Ketanbhai Modi,Lim Zi Pong,Shourya Kuchhal,Yoshi Cao,Yupeng Cheng,Teo Yon Shin,Lin Shang-Wei,Zhiming Li", "background": "现代深度神经网络（DNNs）的快速增长导致了计算成本和内存使用方面的挑战，推动了高效模型压缩技术的兴趣增加。先前的先进方法提出使用一种基于Torque的正则化方法，以强制神经模块的权重围绕一个选定的中心点。然而，这种方法的剪枝效果并不理想，因为经过训练后的网络仍然密集，还伴随着高精度下降的问题。这种无效性被归因于默认的线性力应用方案，因为该方案对不同距离的神经模块施加了不合适的力。", "innovation": "提出了一种新的剪枝方法，即指数力剪枝（Exponential Torque Pruning, ETP），采用指数力应用方案进行正则化，以有效剪枝冗余和远距离的模块，同时保留那些对于有效推理必要且接近的模块。尽管ETP极其简单，但其在多种领域中能够实现比先前最先进的剪枝策略更显著的压缩率，同时几乎没有精度下降", "conclusion": "实验结果表明，尽管ETP极其简单，但在各种领域中，它仍能够实现显著更高的压缩率，并且几乎没有任何精度下降。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21945", "html_url": "https://arxiv.org/abs/2506.21945", "title": "SDRNET: 堆叠深残差网络用于高分辨率遥感图像准确语义分割", "title_en": "SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images", "authors": "Naftaly Wambugu,Ruisheng Wang,Bo Guo,Tianshu Yu,Sheng Xu,Mohammed Elhassan", "background": "高分辨率遥感图像（FRRS）因其精度过高在光谱学和遥感研究领域引起了极大关注。然而，准确地对FRRS图像进行语义分割受到了显著类别差异、因遮挡而难以识别的重要地面目标和物体大小变化的挑战。尽管深度卷积神经网络（DCNNs）在图像特征学习和表示方面具有非凡潜力，但从高质量遥感图像中提取足够的特征以实现准确的语义分割仍然具有挑战性。这些挑战促使深度学习模型学习鲁棒的特征并产生足够的特征描述符。具体而言，学习多上下文特征以确保从地面场景中覆盖各种物体大小，以及利用全局-局部上下文来克服类别差异的挑战，即使对于深度网络也是如此。深层网络由于逐级下采样过程中的空间细节丢失，导致分割结果较差且边界粗糙。", "innovation": "本文提出了一种堆叠深残差网络（SDRNet）用于FRRS图像的语义分割。该提出的框架采用两个堆叠的编码器-解码器网络来利用长范围语义并保留空间信息，在每个编码器和解码器网络之间使用膨胀残差块（DRB）来捕获充分的全局依赖性，从而提高分割性能。在ISPRS Vaihingen和Potsdam数据集上的实验结果表明，SDRNet在语义分割方面表现出色且具有竞争力，相比现有的DCNNs有很好的性能提升。", "conclusion": "SDRNet在语义分割方面表现出良好的效果，并且展示了与现有深度学习模型相当甚至更好的性能，在高分辨率遥感图像的语义分割中提出了一种有效的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21980", "html_url": "https://arxiv.org/abs/2506.21980", "title": "R1-Track: 通过强化学习直接将MLLMs应用于视觉对象跟踪", "title_en": "R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning", "authors": "Biao Wang,Wenwen Li", "background": "单目标视觉跟踪任务旨在仅通过初始帧的状态在后续视频帧中连续定位并估计目标尺度。传统上，该任务被视为模板匹配问题，并经历了从相关滤波器到双流网络和单流网络几个主要阶段，这些方法都取得了显著进展。然而，这些方法通常需要显式的分类和回归建模，依赖大规模数据集的监督训练，并且局限于单一跟踪任务，缺乏灵活性。近年来，多模大型语言模型（MLLMs）快速发展，开源模型如Qwen2.5-VL在基础任务上表现出色，这激发了直接将此类模型应用于视觉跟踪的兴趣。然而，实验表明，Qwen2.5-VL在图像对之间的模板匹配（即跟踪任务）中表现不佳。受DeepSeek-R1的启发，我们使用基于规则的奖励函数和组相对策略优化（GRPO）强化学习方法在小型数据集上对Qwen2.5-VL进行了微调，形成了R1-Track模型，该模型在GOT-10k基准测试中表现出色，支持通过边界框或文本描述进行灵活初始化，同时保留了原模型的大部分通用能力。", "innovation": "我们提出了R1-Track，这是一种通过强化学习直接将大型多模态语言模型（MLLMs）应用于视觉对象跟踪的方法。具体而言，我们使用组相对策略优化（GRPO）强化学习方法和基于规则的奖励函数在小型数据集上对Qwen2.5-VL进行了微调，以解决其在模板匹配（即跟踪任务）中的不足。通过这种方法，R1-Track不仅支持通过边界框或文本描述进行灵活初始化，而且保留了原模型的大部分通用能力，显著提高了在GOT-10k基准测试中的性能。此外，我们还讨论了R1-Track的潜在改进方案。", "conclusion": "我们通过上述方法提出了R1-Track模型，该模型展示了在GOT-10k基准测试中出色的性能，支持灵活的初始化方法，并具有强大的通用能力。虽然目前仍有改进空间，但R1-Track代表了一种新的方向，通过结合大型多模态语言模型和强化学习，为视觉对象跟踪开辟了新的可能性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22022", "html_url": "https://arxiv.org/abs/2506.22022", "title": "通过语义保留约束和伪配对监督促进面部风格化", "title_en": "Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision", "authors": "Zhanyi Lu,Yue Zhou", "background": "面部风格化旨在将面部图像转换为吸引人的高质量风格化肖像，关键挑战是如何在保持原始内容一致性的前提下精准学习目标风格。尽管以往基于StyleGAN的方法已经取得了显著进展，但生成的结果仍然存在瑕疵或与源图像的忠实度不足的问题。这些问题的原因在于生成器在风格化过程中未考虑语义变化的忽略。", "innovation": "该研究提出了一种面部风格化方法，该方法结合了语义保留约束和伪配对监督，以增强内容对应关系并改善风格化效果。此外，该研究开发了一种多级伪配对数据集的生成方法，以实施监控约束。通过这种方法，该面部风格化框架实现了更灵活的多种模态和参考引导风格化，而无需复杂网络架构设计或额外训练。实验结果表明，该方法生成的高度忠实、审美优美的面部风格转移结果超越了先前的方法。", "conclusion": "本研究提出的方法在面部风格转移中产生了高度忠实且具有审美吸引力的结果，超越了先前的方法，并且在保持语义一致性的同时实现了灵活的多种模态和参考引导风格化。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22007", "html_url": "https://arxiv.org/abs/2506.22007", "title": "RoboEnvision：多任务机器人操作的长时间视频生成模型", "title_en": "RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation", "authors": "Liudi Yang,Yang Bai,George Eskandar,Fengyi Shen,Mohammad Altillawi,Dong Chen,Soumajit Majumder,Ziyuan Liu,Gitta Kutyniok,Abhinav Valada", "background": "现有的文本到视频扩散模型在真实感、语言理解和动作生成方面取得了显著进展，但仍然难以应对长期的机器人任务。近期研究通过视频扩散模型生成高质量的模拟数据，并在机器人规划中应用预测滚动。然而，这些方法只能预测机器人完成任务的短暂序列，使用自回归方式扩展到长期任务，导致生成视频和执行中的误差累积。", "innovation": "本文提出了一种新颖的管道，绕过了自回归生成的需要，通过三项贡献实现：1) 将高层次目标分解为更小的原子任务，并生成与这些指令对齐的关键帧；使用一个第二扩散模型在已生成的帧之间进行插值，实现长时序视频。2) 提出了一种语义保留的注意模块，以保持关键帧之间的一致性。3) 设计了一个轻量级的策略模型，根据生成的视频回归机器人关节状态。", "conclusion": "我们的方法在两个基准测试中在视频质量和一致性方面达到了最先进的结果，并且在长期任务方面优于之前的策略模型。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21924", "html_url": "https://arxiv.org/abs/2506.21924", "title": "SPAZER:基于空间-语义渐进推理的零样本3D视觉定位代理", "title_en": "SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding", "authors": "Zhao Jin,Rong-Cheng Tu,Jingyi Liao,Wenhao Sun,Xiao Luo,Shunyu Liu,Dacheng Tao", "background": "3D视觉定位（3DVG）旨在基于自然语言查询在3D场景中定位目标对象。尽管有研究探索了利用预训练的LLM和VLM的零样本3DVG方法以减少对昂贵的3D训练数据的依赖，但现有方法往往侧重于空间理解（3D）或语义理解（2D），这限制了它们在复杂现实场景中的应用效果。因此，本文介绍了一种名为SPAZER的VLM驱动代理，它结合了空间和语义两种模态，在渐进推理框架中进行场景分析，利用最佳视角生成3D渲染，然后进行基于锚点的粗略定位筛选，并结合检索到的相关二维相机图像，使用3D-2D联合决策制定最适合的对象匹配。通过将空间和语义推理神经流相结合，SPAZER在不使用3D标注数据的情况下，实现了稳健的零样本定位。", "innovation": "SPAZER通过结合空间和语义模态，提出了一个渐进推理框架。首先进行全方位场景分析并生成3D渲染；其次，采用基于锚点的粗略筛选进行潜在对象的粗定位；最后，利用检索到的相关二维相机图像，进行3D-2D联合决策以最终确定最佳匹配对象。这一方法实现了在没有3D标注数据训练情况下，稳健的零样本定位。", "conclusion": "在ScanRefer和Nr3D基准测试上进行了大量实验，结果表明，SPAZER在零样本3D视觉定位方面显著超越了现有的最先进的方法，分别在准确率上取得了9.0%和10.9%的提升。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22027", "html_url": "https://arxiv.org/abs/2506.22027", "title": "通过光学和SAR成像的跨模态船舶重识别：一种新型数据集和方法", "title_en": "Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method", "authors": "Han Wang,Shengyang Li,Jian Yang,Yuxuan Liu,Yixuan Lv,Zhuang Zhou", "background": "地面观测图像中地面物体检测和跟踪远程 sensing 领域仍面临重大挑战。连续的海上船只跟踪对于海上搜救、执法和航运分析等应用至关重要。然而，当前大多数船只跟踪方法依赖于地球同步卫星或视频卫星。前者分辨率较低且受天气条件影响，后者拍摄时间短且覆盖范围有限，不太适合实际的船只跟踪需求。为了解决这些问题，本文提出了一种利用低地球轨道光学和SAR传感器星座进行船只跟踪的方案，旨在评估链跟踪的效果。该方案可以提供更短的重拍周期并实现全天候跟踪。此外，该方法包括在不同条件、不同时间和不同角度下由不同卫星拍摄的相同船只多帧图像。", "innovation": "本文提出的Hybrid Optical and Synthetic Aperture Radar (SAR) Ship Re-Identification Dataset (HOSS ReID 数据集)，用于评估使用低地球轨道光学和SAR传感器星座进行船只跟踪的效果。该数据集包含不同时间和角度拍摄的相同船只的多帧图像。此外，本文还提出了一种基于Vision Transformer的跨模态船舶重识别方法TransOSS，该方法通过改进贴片嵌入结构、引入更多的参考信息并使用对比学习来进行大规模光学-SAR图像对的预训练，以确保能够提取模态不变特征。", "conclusion": "本文提出了HOSS ReID 数据集和跨模态船舶重识别方法 TransOSS，可以在不同条件和角度下为船只跟踪提供支持，从而提供更可靠和连续的船只跟踪方案。该数据集和方法已公开。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22063", "html_url": "https://arxiv.org/abs/2506.22063", "title": "EnLVAM：利用解剖运动模式增强左心室线性测量", "title_en": "EnLVAM: Enhanced Left Ventricle Linear Measurements Utilizing Anatomical Motion Mode", "authors": "Durgesh K. Singh,Ahcene Boubekki,Qing Cao,Svein Arne Aase,Robert Jenssen,Michael Kampffmeyer", "background": "通过经胸超声心动图的剑突长轴（PLAX）视图测量左心室（LV）的线性参数对于心脏评估至关重要。这涉及在近心脏瓣膜尖端、垂直于LV轴的虚拟扫描线（SL）上放置4-6个标记点。手动放置这些标记点耗时且容易出错，现有的深度学习方法往往无法准确地对齐标记点，导致测量不准确。", "innovation": "本文提出了一种创新框架，通过引入直线约束来提高左心室测量的准确性。该框架包含一个在计算出的模拟运动模式（AMM）图像上训练的标记检测器，然后将其转换回B模式空间。此方法解决了对齐问题并降低了测量误差。实验结果表明，这种方法优于标准B模式方法，并且在不同的神经网络架构中表现良好。此外，框架设计为半自动模式，其中用户只需要放置一条扫描线，简化了操作同时保持了对齐的灵活性和临床相关性，", "conclusion": "该框架能够显著提高左心室测量的准确性和一致性，具有广泛的应用前景。通过提供一种直观且有效的解决方案，解决了现有方法中存在的对齐和测量不准确性问题。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22032", "html_url": "https://arxiv.org/abs/2506.22032", "title": "部分CLIP足够： Chimera-Seg在零样本语义分割中的应用", "title_en": "Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation", "authors": "Jialei Chen,Xu Zheng,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi", "background": "零样本（Zero-shot）语义分割（Semantic Segmentation，简称ZSS）的目标是通过仅使用已见过的类别来进行监督，来分割已见过和未见过的类别。传统的基于适应的方法（adaptation-based methods）和基于蒸馏的知识转移方法（distillation-based approaches）已经应用于此任务，但这些方法仍然面临挑战，主要是：（1）将基于视觉的特征与文本空间对齐的难度，需要结合空间精度与视觉语言对齐；（2）CLIP等视觉语言模型（vision-language model）的全局表示与分割模型的局部、精细特征之间的语义差异。现有的方法在此方面难以取得突破。因此，需要提出新的方法来解决上述问题。", "innovation": "该研究提出了Chimera-Seg，这是一种新颖的方法，它采用了一种特殊的架构设计，将分割骨干网络作为主体（body），CLIP模型的语义头部作为头部（head），以此实现视觉对齐和空间精度的结合。具体创新包括提出了一种称为Selected Global Distillation (SGD)的方法，该方法从与CLIP CLS标记高度相似的密集特征中抽取知识，并随着训练进展逐渐减少用于对齐的特征数量，此外还提出了一个称为Semantic Alignment Module (SAM)的模块，它进一步将密集的视觉特征与从冻结的CLIP文本编码器提取的语义嵌入对齐。研究表明，这些创新技术可以有效提高分割精度。", "conclusion": "在两个基准测试中，Chimera-Seg表现出0.9%和1.2%的hIoU提升，证明了部分CLIP模型在这个任务中的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22044", "html_url": "https://arxiv.org/abs/2506.22044", "title": "通过全局高斯场实现3D谈话头部的少量样本身份适配", "title_en": "Few-Shot Identity Adaptation for 3D Talking Heads via Global Gaussian Field", "authors": "Hong Nie,Fuyuan Cao,Lu Chen,Fengxin Chen,Yuefeng Zou,Jun Yu", "background": "基于重建和渲染的谈话头部合成方法能够保持很高的身份一致性，但受限于需要特定身份的模型，每次生成新的身份头像需要从头进行训练，导致高昂的计算成本和较低的可扩展性，相比基于生成模型的方法，这种可扩展性较差。因此，需要一种新的方法来解决这一问题，以提高合成身份头像的效率和可扩展性。", "innovation": "本文提出了FIAG，一种新颖的3D说话头部合成框架，通过少量训练片段就能实现高效的身份特定适应。FIAG结合了全局高斯场（支持共享领域的多种身份表示）和通用运动场（捕捉不同身份间的共同运动动态），利用这两种场实现快速适应，并通过共享面部结构信息和学习的通用运动先验来实现对标准身份表示到特定身份表示的快速适应。", "conclusion": "广泛的对比和消融实验表明，我们的方法在现有最先进的方法中表现更优，验证了所提出框架的有效性和泛化能力。代码可以在以下网址获得：\textit{this https URL}。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22069", "html_url": "https://arxiv.org/abs/2506.22069", "title": "滚动快门相机单扫描线相对位姿估计", "title_en": "Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras", "authors": "Petr Hruby,Marc Pollefeys", "background": "本文提出了一种新的方法，用于估算滚动快门相机之间的相对姿态，该方法通过单个图像中的单条扫描线与线投影的交点来实现，无需显式建模相机运动。该方法适用于滚动快门相机的单视图相对姿态估计，并为滚动快门结构从运动（SfM）的构建模块奠定了基础，不需要任何运动模型，每个扫描线的姿态可以独立计算。此外，对这个问题的极值求解器进行了分类，包括平行线情况和已知重力方向的情况，假设已知内参且无透镜失真。", "innovation": "本研究提出了一种新方法，通过单个图像中的单条扫描线与线投影的交点来估算滚动快门相机之间的相对姿态，该方法无需显式建模相机运动，并开发了适用于平行线情况的最小求解器，有和无重力先验信息的情况均有涵盖。还展示了该方法在Fastec数据集上的实验结果，证明了其初始化滚动快门SfM的可行性。", "conclusion": "实验结果展示了该方法在初始化滚动快门SfM中的可行性，表明其有进一步发展的潜力。该研究的代码将公开。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22065", "html_url": "https://arxiv.org/abs/2506.22065", "title": "MirrorMe：走向实时高保真的音频驱动半身动画", "title_en": "MirrorMe: Towards Realtime and High Fidelity Audio-Driven Halfbody Animation", "authors": "Dechao Meng,Steven Xiao,Xindi Zhang,Guangyuan Wang,Peng Zhang,Qi Wang,Bang Zhang,Liefeng Bo", "background": "音频驱动的肖像动画面临着在实时生成高保真、时间上连贯的动画方面的重大挑战。尽管最近基于扩散的方法通过将音频整合到去噪过程中提高了生成质量，但由于依赖于逐帧的UNet架构，它们引入了高延迟且难以确保时间一致性.", "innovation": "1. 一种参考身份注入机制，通过VAE编码图像的拼接和自我注意力，确保身份一致性；\n2. 一种因果音频编码器和适合LTX时序结构的适配器，实现精确的音频表情同步；\n3. 一种渐进式训练策略，包含近距离面部训练、半身合成带面部遮罩和手势集成，增强手势控制.", "conclusion": "广泛的EMTD基准实验结果表明，MirrorMe在保真度、唇部同步准确性及时间稳定性方面表现出最先进的性能."}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22099", "html_url": "https://arxiv.org/abs/2506.22099", "title": "BézierGS: 使用贝塞尔曲线高斯点渲染的动态城市场景重建", "title_en": "BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting", "authors": "Zipei Ma,Junzhe Jiang,Yurui Chen,Li Zhang", "background": "实时准确地重建街道场景对于开发自动驾驶现实世界的模拟器至关重要。现有的大多数方法依赖于对象姿态注释，利用这些标注的姿态来重建动态物体，并在渲染过程中移动这些物体。但这种方法依赖高精度的对象姿态标注，限制了解放规模的场景重建能力。针对这个挑战，本文提出了一种基于贝塞尔曲线的高斯渲染方法（BézierGS），它使用可学习的贝塞尔曲线表示动态物体的运动轨迹，充分依靠动态物体的时序信息，并通过可学习的曲线建模自动纠正姿态错误。", "innovation": "本文方法提出了贝塞尔曲线高斯渲染（BézierGS），通过可学习的贝塞尔曲线建模动态物体的运动轨迹，解决了依赖高精度对象标注的问题，实现了场景元素的合理和准确分离与重建。此外，通过在动态对象渲染上引入额外的监督和曲线间一致性约束，使得方法在动态和静态场景组件重建以及新颖视角合成方面取得了更优的效果。", "conclusion": "详细的实验结果表明，BézierGS在Waymo开源数据集和nuPlan基准测试中，相比现有的前沿方法，均在动态和静态场景组件重建及新颖视角合成方面取得了更优的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22078", "html_url": "https://arxiv.org/abs/2506.22078", "title": "通过周期性引导的rPPG估计和信号重建实现超短视频片段中的心率准确测量", "title_en": "Towards Accurate Heart Rate Measurement from Ultra-Short Video Clips via Periodicity-Guided rPPG Estimation and Signal Reconstruction", "authors": "Pei-Kai Huanga,Ya-Ting Chan,Kuan-Wen Chen,Yen-Chun Chou,Shih-Yu Yang,Chiou-Ting Hsu", "background": "许多远程心率（HR）测量方法主要关注从视频片段中估计远程光电容积描记图（rPPG）信号，这些视频片段通常持续大约10秒，但往往忽略了从超短视频片段中估计心率的需求。作者旨在通过集中解决两个关键挑战，从2秒超短视频片段中准确测量心率。这些挑战包括增加超短视频片段中的心跳周期数以及减轻由于频谱泄漏造成的估计不准确性。", "innovation": "提出了一种有效的周期性引导的rPPG估计方法，以确保从超短片段估计的rPPG信号与其更长的真实信号之间具有一致的周期性，从而克服了超短片段心跳周期数有限的问题。同时，提出了一种生成器来重建更长的rPPG信号，从而保持其周期一致性，以提高心率测量的准确性，减轻频谱泄漏造成的估计不准确性。实验结果表明，所提出的方法不仅能够准确测量从超短视频片段中的心率，而且在多种rPPG估计基准数据集上的表现超过了以往的方法，达到了最先进的技术水平。", "conclusion": "所提出的方法不仅能够准确测量从超短视频片段中的心率，而且在多种rPPG估计基准数据集上的表现超过了以往的方法，达到了最先进的技术水平。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22118", "html_url": "https://arxiv.org/abs/2506.22118", "title": "点云数据中的管道重建", "title_en": "Pipe Reconstruction from Point Cloud Data", "authors": "Antje Alex,Jannis Stoppe", "background": "工业资产，如船舶和海上平台的数字孪生需要精确重建复杂的管道网络。然而，从激光扫描数据手动建模管道是一个耗时且劳动密集型的过程。", "innovation": "提出了一种自动管道重建管道的方法，该方法使用拉普拉斯基收缩估计骨架曲线，然后通过曲线拉伸进行扩展。接着，使用滚动球技术和二维圆拟合并通过3D平滑步骤重新中心化骨架轴，从而确定管道属性（包括半径、长度和方向），并促进复杂管道网络的详细3D建模。该方法通过自动化管道重建，支持数字孪生的发展，实现快速和准确的建模，同时降低成本。", "conclusion": "该方法实现了从不完整激光扫描数据中自动重建管道，通过自动化的流程提高了重建效率和精度，降低了成本，支持了数字孪生的创建。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22075", "html_url": "https://arxiv.org/abs/2506.22075", "title": "机器视觉中的推理：学习快速与慢速思考", "title_en": "Reasoning in machine vision: learning to think fast and slow", "authors": "Shaheer U. Saeed,Yipei Wang,Veeru Kasivisvanathan,Brian R. Davidson,Matthew J. Clarkson,Yipeng Hu,Daniel C. Alexander", "background": "人类智能的一个显著特征是推理能力，这使人们能够灵活应对复杂和不熟悉的场景。然而，机器智能仍受限于训练数据，不具备在推理过程中动态改进解决方案的能力。尽管近年来在机器推理方面取得了一些进展，这些努力主要集中在数学问题解决等语言领域。然而，许多关键的现实世界任务，如视觉感知、空间推理和放射学诊断，需要非语言的推理能力，这是目前一个开放的挑战。", "innovation": "本文提出了一种新的学习范式，使机器视觉推理在计算时间增加时（推理时刻的计算）能够提升性能，即使在标注数据非常有限的情况下也是如此。该方法受到心理学中双过程理论的启发，将快速的系统I模块与慢速的系统II模块结合起来。系统I主要处理熟悉的任务，而系统II通过自我博弈强化学习迭代改进解决方案。这种范式通过提出、竞争和改进解决方案来模仿数据稀缺条件下的真人推理过程。阶段性实验结果表明，与大规模监督学习、基础模型，甚至人类专家相比，该方法在现实世界的视觉任务中表现出更优的性能，包括计算机视觉基准测试和医学图像中五个器官的癌症定位任务。", "conclusion": "该方法在没有大量标注数据的情况下实现了非语言机器推理的提升，并且这些任务的性能超过了现有的监督学习方法、基础模型以及人类专家。这一研究成果展示了非语言机器推理的巨大潜力，为解决现实世界中的复杂任务提供了新的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22101", "html_url": "https://arxiv.org/abs/2506.22101", "title": "Tied Prototype Model for Few-Shot Medical Image Segmentation", "title_en": "Tied Prototype Model for Few-Shot Medical Image Segmentation", "authors": "Hyeongji Kim,Stine Hansen,Michael Kampffmeyer", "background": "现有的原型为基础的少量样本医疗图像分割（FSS）方法使用类特定的原型来建模前景和背景类别。然而，由于背景的高度变异性，更有效的方法是仅专注于前景建模，将背景视为异常，这种方法由ADNet提出。ADNet存在三个关键限制：每类依赖单一原型、仅关注二分类、固定的阈值无法适应患者和器官的变异性。", "innovation": "本文提出了Tied Prototype Model (TPM)，这是一种对ADNet的原理性重新构想，具有共用的前景和背景原型位置。TPM自然地扩展到多个原型和多类分割，有效地分离了非典型的背景特征。这种扩展提高了分割精度，并利用自然出现的类别先验定义了适应阈值的理想目标，增强了分割性能。", "conclusion": "TPM为基于原型的少量样本医疗图像分割提供了一个新颖的视角。结果代码可以在以下网址找到：this https URL。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22146", "html_url": "https://arxiv.org/abs/2506.22146", "title": "视觉结构有助于视觉推理：VLMs中的绑定问题解决方案", "title_en": "Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs", "authors": "Amirmohammad Izadi,Mohammad Ali Banayeeanzade,Fatemeh Askari,Ali Rahimiakbar,Mohammad Mahdi Vahedi,Hosein Hasani,Mahdieh Soleymani Baghshah", "background": "尽管视觉语言模型（VLMs）取得了进展，但在视觉推理能力上仍然受限于‘绑定问题’：感知特征与其正确的视觉指代物的可靠关联失败。这一限制导致了计数、视觉搜索、场景描述和空间关系理解任务中的持久错误。当前的VLMs主要以并行的方式处理视觉特征，缺乏空间定位的、序列性的注意力机制。", "innovation": "本文提出了一种简单而有效的干预方法：通过将低级别空间结构（例如水平线）添加到视觉输入中，并配以文本提示鼓励序列化的、空间意识的分词，以此来改善视觉推理任务中的性能。实验证明，该方法在核心视觉推理任务中取得了显著性能提升，例如，相较于GPT-4o提高了25.00%的视觉搜索准确性，计数准确性提高了26.83%，场景描述的编辑距离误差减少了0.32，空间关系任务性能提高了9.50%（使用2D合成数据集）。此外，研究发现视觉修改对于这些提升必不可少，纯粹基于文本的策略，包括链式思考提示，是不够的，甚至可能会降低性能。该方法仅通过单查询推理就能增强绑定，突显了视觉输入设计比纯粹语言基础方法的重要性。这些发现表明，低级别的视觉结构化是一个有力而未被充分探索的方向，可作为提升VLM在空间定位任务性能的一般策略。", "conclusion": "低级别的视觉结构化是改进组合视觉推理的一种强大而未充分探索的方向，也可以作为提升VLM在空间定位任务性能的一般策略。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22139", "html_url": "https://arxiv.org/abs/2506.22139", "title": "Q-Frame：面向查询的自适应帧选择和多分辨率适应性对于Video-LLMs", "title_en": "Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs", "authors": "Shaojie Zhang,Jiahui Yang,Jianqin Yin,Zhenbo Luo,Jian Luan", "background": "多模态大语言模型（MLLMs）在视觉理解任务上取得了显著的成果。然而，这些模型应用于视频理解仍存在挑战，主要是因为数据量巨大和时间复杂性。现有的视频大语言模型（Video-LLMs）通常采用均匀帧抽样，这使其难以有效捕捉与查询相关的关键时空线索。", "innovation": "本文提出了一种名为Q-Frame的新颖方法，它针对视频内容和特定查询进行自适应帧选择和多分辨率缩放。Q-Frame采用了一种无需训练、即插即用的方法，利用文本-图像匹配网络（如CLIP）生成，利用Gumbel-Max技巧进行高效的帧选择。该方法允许Video-LLMs在不超出计算限制的情况下处理更多帧，从而保留关键的时间和空间信息。", "conclusion": "通过在基准数据集（如MLVU、LongVideoBench和Video-MME）上的广泛实验，证明了Q-Frame的有效性，并展示了其在各种视频理解任务中的优越性和适用性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22134", "html_url": "https://arxiv.org/abs/2506.22134", "title": "利用Schatten-p近似范数和雅各比正则化的低秩隐式神经表示", "title_en": "Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization", "authors": "Zhengyun Cheng,Changhao Wang,Guanwen Zhang,Yi Xu,Wei Zhou,Xiangyang Ji", "background": "高阶张量适合多维数据的表示，如颜色图像和视频。低秩张量表示在机器学习和计算机视觉中变得至关重要，尽管杜克分解提供了一定的灵活性但缺乏透明性，而CANDECOMP/PARAFAC (CP) 分解虽然自然且易于理解，获取稀疏解依然极具挑战性。本文利用CP分解的丰富性质，提出了一种基于神经网络参数化的CP低秩张量函数，用于隐式神经表示 (CP-INR)，该方法能够实现结构网格外的连续数据表示，充分利用张量数据的非线性，并可在理论上保证误差优势。为了实现稀疏CP分解，引入了Schatten-p近似范数的变分形式，并证明了其与多线性秩最小化的关联。为了平滑性，提出了一种基于雅可比谱范数和Hutchinson迹估计的正则化项，该正则化项无需奇异值分解且避免了显式链式规则的计算，可作为图像去噪中的总变差正则化的替代方法，自然适用于连续数据。多维数据恢复任务（包括图像修复、去噪和点云上采样）的广泛实验表明，该方法在同类别方法中表现出优越性和适用性。", "innovation": "提出了基于神经网络参数化的CP低秩张量函数（CP-INR），利用Schatten-p近似范数的变分形式实现稀疏CP分解，以及基于雅可比谱范数和Hutchinson迹估计的平滑性正则化项，无需奇异值分解，避免显式链式规则的计算，适用于连续数据。", "conclusion": "通过广泛的实验，证明了提出的CP-INR方法在多维数据恢复任务中的优越性和适用性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22179", "html_url": "https://arxiv.org/abs/2506.22179", "title": "Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition", "title_en": "Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition", "authors": "Wenhan Wu,Zhishuai Guo,Chen Chen,Hongfei Xue,Aidong Lu", "background": "零样本骨架基础动作识别旨在开发能够在训练时未遇到的新动作类别中识别动作的模型。以往的方法主要集中在视觉和语义表征的对齐上，但常常忽视了在语义空间中细微动作模式的重要性（例如饮水和刷牙的手部动作）。针对这些局限性，文章提出了一种基于频率-语义增强的变异自编码器（FS-VAE），利用频率分解探索骨架语义表征学习。该方法通过频率基增强模块、基于语义的动作描述和校准的交叉对齐损失来增强骨架语义学习、捕捉局部细节和全局对应关系，以及确保骨架和文本特征的稳健对齐，从而提高零样本动作识别的有效性。", "innovation": "文章提出了一种基于频率-语义增强的变异自编码器（FS-VAE），通过引入频率基增强模块、基于语义的动作描述和校准的交叉对齐损失，利用频率分解探索骨架语义表征学习，从而增强骨架语义学习，捕捉局部细节和全局对应关系，确保骨架和文本特征的稳健对齐，提高零样本动作识别的有效性。", "conclusion": "在基准测试中的评估证明了该方法的有效性，验证了增强的频率语义特征能够使视觉和语义相似的动作簇达到稳健的区分，从而提高零样本动作识别的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22111", "html_url": "https://arxiv.org/abs/2506.22111", "title": "在非结构化交通中使用IDD-PeD进行行人类意向和轨迹预测", "title_en": "Pedestrian Intention and Trajectory Prediction in Unstructured Traffic Using IDD-PeD", "authors": "Ruthvik Bokkasam,Shankar Gangisetty,A. H. Abdul Hafez,C. V. Jawahar", "background": "随着自主驾驶技术的迅速发展，精确预测行人行为对于确保复杂和难以预测交通条件下的安全性变得尤为重要。对这一挑战的兴趣表明，需要全面的数据集，以捕捉非结构化的环境，从而促进更稳健的预测模型的开发，以增强行人安全和车辆导航。在这些环境中，行人行为的建模因其照明变化、行人的遮挡、无信号交叉口的场景类型以及车辆与行人的互动而复杂化。", "innovation": "本文介绍了一个印度驾驶行人数据集，旨在解决非结构环境中行人行为建模的复杂性，例如光照变化、行人遮挡、无信号场景和车辆与行人的互动。该数据集提供了高和详细的低层次全面注释，专注于需要自主车关注的行人。在本数据集上对最先进的意图预测方法的评估显示至多15%的性能下降，而轨迹预测方法的性能下降幅度高达1208 MSE，优于标准行人数据集。此外，本文还提供了意图和轨迹基线的详尽定量和定性分析。作者认为，他们的数据集将为行人行为研究社区带来新的挑战，以构建稳健的模型。", "conclusion": "我们相信，我们的数据集将为行人行为研究领域带来新的挑战，以构建出更加健壮的模型。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22216", "html_url": "https://arxiv.org/abs/2506.22216", "title": "ReF-LLE: 参考引导的深度强化学习的个性化低光增强", "title_en": "ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning", "authors": "Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang", "background": "低光图像增强面临两大挑战：1) 不同条件下低光图像存在显著差异；2) 增强级别受到主观偏好和用户意图的影响。为解决这些问题，本文提出了一种新颖的个性化低光图像增强方法ReF-LLE，该方法在傅里叶频率域中运行，结合了深度强化学习。ReF-LLE是该领域中首次将深度强化学习技术集成的方法，在训练过程中引入了零参照图像评估策略，以评估增强后的图像并提供奖励信号，从而指导模型处理不同低光条件。在推理阶段，ReF-LLE采用了一种参照图像引导的个性化自适应迭代策略，该策略根据在傅里叶域中的零频率分量来调整低光图像，该分量代表整体光照级别，使模型能够根据用户提供的参考图像调整光照分布，确保个性化增强效果。", "innovation": "1) 提出了一种基于零参照图的评估策略，用于增强图像并提供奖励信号，指导模型处理不同低光条件。2) 在推理阶段，采用一种参照图像引导的个性化自适应迭代策略，根据傅里叶零频率分量来调整低光图像，以适应用户提供的参照图像的光照分布。3) 首次将深度强化学习技术集成到低光图像增强领域。", "conclusion": "在基准数据集上进行的大量实验表明，ReF-LLE在个性化低光图像增强方面优于最先进的方法，实现了更好的感知质量和适应性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22161", "html_url": "https://arxiv.org/abs/2506.22161", "title": "注意力解耦统一正交特征空间优化方法在少样本目标检测中的应用", "title_en": "Attention-disentangled Uniform Orthogonal Feature Space Optimization for Few-shot Object Detection", "authors": "Taijin Zhao,Heqian Qiu,Yu Dai,Lanxiao Wang,Fanman Meng,Qingbo Wu,Hongliang Li", "background": "少样本目标检测（FSOD）的任务是使用少量的新类别样本进行目标检测，而依赖丰富的基础类别数据。现有的FSOD方法主要基于Faster R-CNN检测器，将在共享特征空间中合并目标性识别和前景分类。这一范式内在地为每个类别建立了特定的目标性标准，但由于新类别样本不够代表性，导致了问题。解决这一限制，本文提出了一种统一正交特征空间（UOFS）优化框架。该框架将特征空间拆分为两个正交成分，从而可以将基础类别的通用目标性知识转移到新类别上。然而，解耦特征提要求注意两个挑战：一是带标签的背景实例和潜在的新类别前景实例之间的混淆；二是角度优化仅依赖于基础类的前景实例，容易导致角度分布过度拟合至基础类。本文提出了混合背景优化（HBO）策略以及空间注意力解耦和关联（SADA）模块来解决这些问题。实验表明，我们的方法显著优于基于交织特征空间的现有方法。", "innovation": "提出了统一正交特征空间（UOFS）优化框架，拆分特征空间为两个正交成分；提出了混合背景优化（HBO）策略，利用纯背景集和带标签前景实例进行监督和优化；提出了空间注意力解耦和关联（SADA）模块，解决了类无关和类特定任务间的冲突问题。", "conclusion": "提出的UOFS优化框架在少样本目标检测任务上取得了显著性能提升，优于现有基于交织特征空间的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22242", "html_url": "https://arxiv.org/abs/2506.22242", "title": "4D-VLA: 基于跨场景校准的空间时间视语言动作预训练", "title_en": "4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration", "authors": "Jiahui Zhang,Yurui Chen,Yueming Xu,Ze Huang,Yanpeng Zhou,Yu-Jie Yuan,Xinyue Cai,Guowei Huang,Xingyue Quan,Hang Xu,Li Zhang", "background": "利用多样化的机器人数据进行预训练仍然是一个关键性的挑战。现有方法通常使用简单的观察数据来建模数据集中的动作分布，但这些输入往往是不完整的，会导致条件动作分布的分散性，我们将其称为坐标系统混乱和状态混乱。这种不一致显著影响了预训练的效率。机器人动作分布的不完整性和分布的分散性使得传统的模型训练难以构建有效的坐标系统，从而影响动作理解的准确性和效率。", "innovation": "本文提出了4D-VLA，这是一种新的方法，有效将4D信息整合到输入中以减轻这些混乱源。模型通过顺序的RGB-D输入将深度和时间信息引入视觉特征中，对齐机器人的坐标系统和场景的坐标系统。此对齐赋予了模型强大的时空推理能力，同时最小化了训练开销。此外，还引入了记忆银行采样策略，这是一种帧采样策略，旨在从历史图像中提取信息性的帧，进一步提高效果和效率。实验结果表明，我们的预训练方法和架构组件可以显著增强模型性能。", "conclusion": "在模拟和真实世界实验中，我们的模型在成功率上显著超过了OpenVLA。为了进一步评估空间感知能力和对新颖视角的泛化能力，我们引入了MV-Bench多视角模拟基准。我们的模型在该基准上表现优异，证明了更强大的空间理解和适应能力。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22149", "html_url": "https://arxiv.org/abs/2506.22149", "title": "RetFiner: 一种用于视网膜基础模型的视觉-语言细化方案", "title_en": "RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models", "authors": "Ronald Fecso,José Morano,Ursula Schmidt-Erfurth,Hrvoje Bogunović", "background": "光学相干断层扫描（OCT）等成像技术的进步以及深度学习（DL）的发展使得临床医生和研究者能够简化视网膜疾病的分阶段处理。一种流行的DL方法是自监督学习（SSL），它能够让模型通过大量的未标注数据来学习，从而避免昂贵的标注成本。SSL已使得开发出基础模型（FMs）成为可能，这些大型模型可以用于多种下游任务。然而，现有用于OCT的基础模型仅通过图像数据训练，缺乏全面且稳健的图像语义理解能力，这在其下游任务应用中尤其是对于复杂任务，显示出了性能不足。这需要进行监督微调，但这样的微调可能不切实际，无法更好地适应特定的应用场景和人群。为解决这一问题，提出了一种视觉-语言细化方案（RetFiner），该方案通过改进现有FMs的表示能力和直接适应特定人群的需要来提高其下游性能。RetFiner方法采用了一系列多样化的训练目标，利用了文本数据中丰富的监督信号。", "innovation": "该论文提出了一种名为RetFiner的视觉-语言细化方案，用于提高视网膜基础模型的性能，并使其能够直接适应特定人群。该方法通过多样化和利用文本监督信号来细化基础模型的表示，从而在七个高度多样化的眼底OCT分类任务中展现出显著的性能提升，平均提高了5.8%、3.9%和2.1%。此外，该研究公开了代码和模型权重，可进一步验证其有效性。", "conclusion": "RetFiner有效提高了视网膜基础模型的性能，并展示了其在多种眼底OCT分类任务中的应用潜力。通过实现视觉和语言数据的互补学习，RetFiner为视网膜疾病的自动化诊断和管理提供了新的研究方向和技术支持。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22246", "html_url": "https://arxiv.org/abs/2506.22246", "title": "EAMamba：用于图像恢复的高效全方位视觉状态空间模型", "title_en": "EAMamba: Efficient All-Around Vision State Space Model for Image Restoration", "authors": "Yu-Cheng Lin,Yu-Syuan Xu,Hao-Wei Chen,Hsien-Kai Kuo,Chun-Yi Lee", "background": "图像恢复是低级计算机视觉中的关键任务，旨在从退化输入重建高质量图像。Vision Mamba 的出现，灵感来源于先进的状态空间模型 Mamba，标志着该领域的一个重要进步。Vision Mamba 以其线性复杂度建模长程依赖性而表现出色，这是图像恢复任务的关键优势。尽管如此，Vision Mamba 在低级视觉任务中仍面临一些挑战，如随扫描序列数量增加而增大的计算复杂度和局部像素遗忘问题。", "innovation": "为了克服这些限制，本研究引入了 Efficient All-Around Mamba (EAMamba)，一种增强框架，结合了 Multi-Head Selective Scan Module (MHSSM) 全方位扫描机制。EAMamba 通过高效聚合多种扫描序列，避免了计算复杂度和参数数量的增加。全方位扫描策略采用多种模式来捕获全局信息，解决了局部像素遗忘的问题。", "conclusion": "实验评估证实了这些创新在多个恢复任务中的有效性，包括超分辨率、去噪、去模糊和去雾。结果表明，EAMamba 在保持与现有低级 Vision Mamba 方法相近性能的前提下，实现了高达 31-89% 的 FLOPs 减少。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22274", "html_url": "https://arxiv.org/abs/2506.22274", "title": "COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication", "title_en": "COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication", "authors": "Filippo Merlo,Ece Takmaz,Wenkai Chen,Albert Gatt", "background": "自然场景为对象识别和参考提供了丰富的上下文。特定场景类型会引发对将要出现的物体及其空间配置的预期。那么视觉-语言模型（VLMs）在生成关于物体的参考时是否也会依赖相同的场景上下文呢？", "innovation": "本文引入了COOCO数据集，通过测试不同场景-物体一致性程度和不同噪声干扰下的情况，研究了VLMs在参考生成时对场景上下文的依赖情况。研究发现，模型能够适应性地利用场景上下文，这取决于对象和场景的语义关联性和噪声的程度。注意力分析表明，在低噪声条件下，成功分类物体涉及提高对目标的关注，特别是中等噪声条件下，模型动态平衡局部和情境信息以进行参考生成。", "conclusion": "我们的发现表明，模型在不同场景对象一致性程度和噪声水平下会利用场景的适应性，尤其是在目标和场景一致性高的情况下或当物体受损时更为明显。VLMs动态平衡局部和环境信息以进行参考生成。数据集、代码和模型已公开。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22283", "html_url": "https://arxiv.org/abs/2506.22283", "title": "在跨模态失准下重新思考LVLM中的视觉 token 减少", "title_en": "Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment", "authors": "Rui Xu,Yunke Wang,Yong Luo,Bo Du", "background": "大型视觉-语言模型（LVLMs）通过将视觉输入编码为密集的补丁级标记序列来捕捉细微语义，但视觉标记往往远多于文本标记，导致巨大的计算开销，限制了LVLMs在实际中的可扩展性。先前努力在大型语言模型（LLM）内部或之前进行了视觉标记减少，但大多数基于文本条件的视觉标记减少方法假定文本标记能可靠地捕捉视觉标记的重要性。这项工作重新审视了这一假设，揭示了因果、语义和空间形式的跨模态失准。这些失准削弱了基于文本指导的视觉标记减少的有效性。", "innovation": "引入了VisionDrop，这是一种无需训练的、仅基于视觉的剪枝框架，它根据统一模态（视觉到视觉）注意选择有意义的视觉标记，不依赖于文本信号。此外，通过将视觉编码器和LLM视为统一系统并设计逐步剪枝管道，进一步减少了整个模型层次的冗余。这种方法在多个阶段执行主导标记选择和轻量级上下文合并，即使在严格的标记预算下也能保留细致的视觉信息。广泛的实验展示了VisionDrop在不同基准上的一致改进，其简单有效的设计在不增加训练或复杂修改的情况下实现高效的推理并保持强大的性能.", "conclusion": "我们的方法即使在严格的标记预算下也能保留深层次的视觉信息，并在不同基准上持续优于现有方法，其简洁有效的设计在不额外训练或复杂修改的情况下实现高效的推理，同时保持强大的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22291", "html_url": "https://arxiv.org/abs/2506.22291", "title": "RoomCraft：可控且完备的3D室内场景生成", "title_en": "RoomCraft: Controllable and Complete 3D Indoor Scene Generation", "authors": "Mengqi Zhou,Xipeng Wang,Yuxi Wang,Zhaoxiang Zhang", "background": "在计算机视觉和图形学中，从用户输入生成逼真的3D室内场景仍然是一个极具挑战性的难题。需要在几何一致性、空间关系和视觉真实之间取得平衡。虽然基于神经网络的生成方法经常因全局空间推理能力有限而产生重复元素，而过程化方法可以利用约束实现可控生成，但在面对多个约束场景时却难以应对。当约束变得复杂或众多时，家具对象之间的碰撞频繁发生，这迫使移除家具元素，并影响布局完整性。", "innovation": "为了克服这些局限性，本文提出了RoomCraft，这是一种多阶段的生成流水线，能够将真实图片、草图或文本描述转化为连贯的3D室内场景。RoomCraft结合了一个场景生成流水线和一个基于约束的优化框架。流水线首先从用户的输入中提取高级场景信息，并将其组织成包含房间类型、家具和空间关系的结构化格式。然后构建了一个空间关系网络来表示家具排列，并使用基于启发式的深度优先搜索（HDFS）算法生成优化的放置序列，以确保布局的一致性。此外，提出了统一的约束表示方法，能够处理正式规范和自然语言输入，通过综合的动作空间设计实现灵活的基于约束的调整。同时，还提出了一种冲突感知定位策略（CAPS），动态调整放置权重以最小化家具碰撞并确保布局完整性。", "conclusion": "大量的实验表明，RoomCraft在生成的室内场景在不同输入模态下都表现出高度的真实性和语义一致性，视觉效果也非常出色，显著优于现有的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22241", "html_url": "https://arxiv.org/abs/2506.22241", "title": "使用量子启发式增强技术提升分类性能", "title_en": "Boosting Classification with Quantum-Inspired Augmentations", "authors": "Matthias Tschöpe,Vitor Fortes Rey,Sogo Pierre Sanon,Paul Lukowicz,Nikolaos Palaiodimopoulos,Maximilian Kiefer-Emmanouilidis", "background": "理解小型量子门扰动的影响是重要的，这些扰动是量子数字设备中的常见现象，但在经典计算机中不存在。传统上，这些扰动被视为量子计算的不利因素，但它们实际上可以作为数据增强的自然来源，改善性能。这些扰动还可以在经典硬件上高效仿真，从而促进基于量子启发的机器学习方法发展。在这篇论文中，研究者探讨了作为基本SU(2)变换的随机 Bloch 球旋转作为简单有效的量子启发式数据增强技术的应用，这种变换不具有直观的空间解释，因此在如图像分类等任务的应用上面临挑战。与传统的数据增强方法不同，这些方法依赖于应用量子模型或可训练的quanvolutional层，而本文专注于应用小角度的Bloch旋转对经典数据的影响。", "innovation": "研究了随机Bloch球旋转作为有效的量子启发式数据增强技术，这种变换缺乏直观的空间解释，使其在任务如图像分类的应用相对困难。文章采用了大型ImageNet数据集展示了量子启发式增强方法相较于传统经典数据增强技术能够提高图像分类性能，具体表现为Top-1准确率提高3%，Top-5准确率提高2.5%，F$_1$分数从8%提升至12%。此外，研究还探讨了更强的酉变换的使用，虽然这些变换在原则上有信息保存效果，但会导致视觉无法识别的图像，对隐私计算可能有潜在的应用。", "conclusion": "虽然量子启发式变换和简单的SU(2)变换没有提升差分隐私，但研究指出这些变换可能会有更好的隐私计算应用。研究证明了量子启发式增强方法在提高经典机器学习性能方面的有效性，尤其是图像分类任务中。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22298", "html_url": "https://arxiv.org/abs/2506.22298", "title": "OutDreamer：基于扩散变换器的视频扩边", "title_en": "OutDreamer: Video Outpainting with a Diffusion Transformer", "authors": "Linhao Zhong,Fan Li,Yi Huang,Jianzhuang Liu,Renjing Pei,Fenglong Song", "background": "视频扩边是一项具有挑战性的任务，需要通过生成超出原始输入视频边界的新内容来实现时空一致性和高度的质量。尽管许多最先进的方法使用带有U-Net结构的潜扩散模型，但它们在生成的内容质量及适应性方面仍有待提高。扩散变换器（DiTs）因其出色的性能而被证明是一个有潜力的替代方案。现有的方法缺乏有效的视频控制分支和条件扩边分支，以及适应扩边任务的动态掩码整合机制和帧间一致性的保持策略。", "innovation": "我们提出了OutDreamer，一种基于扩散变换器的视频扩边框架，包含两个主要组件：高效的视频控制分支和条件扩边分支。我们还引入了一个基于掩码的自注意力层，能够动态整合给定的掩码信息，增强了模型对扩边任务的适应性。此外，我们引入了一种潜空间对齐损失，以保持帧内和帧间的一致性。我们还通过交叉视频剪辑精化器实现了长视频扩边，并确保了视频剪辑间的时空一致性。通过广泛的评估，我们的零样本OutDreamer在广泛认可的基准测试中表现出色，优于最先进的零样本方法。", "conclusion": "我们的零样本OutDreamer在多个基准测试中表现出色，优于最先进的零样本方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22336", "html_url": "https://arxiv.org/abs/2506.22336", "title": "MatChA：基于特征增强的跨算法匹配", "title_en": "MatChA: Cross-Algorithm Matching with Feature Augmentation", "authors": "Paula Carbó Cubero,Alberto Jaenal Gálvez,André Mateus,José Araújo,Patric Jensfelt", "background": "现有的最先进的方法无法解决不同设备使用不同稀疏特征提取算法获取关键点及其描述符时的视觉定位问题。当前解决方案假设共用关键点，这意味着必须使用相同的检测器，而在实际应用中当使用不同描述符时这种情况极为罕见。低重复性的关键点和非区分性和非显着性的描述符，使得关键点真实对应关系的识别极具挑战性。", "innovation": "提出了一种新的方法——MatChA（基于特征增强的跨算法匹配），该方法针对跨检测器特征匹配进行特征描述符增强，再将特征转换到潜在空间。这种方法显著改善了跨特征场景下的图像匹配和视觉定位，并在多个基准上进行了评估。", "conclusion": "本方法在跨特征场景下显著提高了图像匹配和视觉定位的性能，并通过多个基准测试对其进行了评估。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22338", "html_url": "https://arxiv.org/abs/2506.22338", "title": "使用高分辨率SAR和地理空间数据的深度学习框架进行建筑损坏评估：以2023年土耳其地震为例", "title_en": "A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake", "authors": "Luigi Russo,Deodato Tapete,Silvia Liberata Ullo,Paolo Gamba", "background": "灾害发生后立即进行建筑损坏识别对于指导紧急响应和恢复工作至关重要。尽管光学卫星图像常用于灾害映射，但其有效性常因云层遮挡或缺乏事前影像而受到阻碍。为克服这些挑战，本文提出了一种新型多模态深度学习框架，使用意大利空间局（ASI）COSMO SkyMed（CSK）星座的单日高分辨率（VHR）合成孔径雷达（SAR）影像，并辅以辅助地理空间数据，以检测建筑损坏。该方法整合了SAR影像片段、OpenStreetMap (OSM) 建筑足迹、数字表面模型（DSM）数据和来自全球地震模型（GEM）的结构和暴露属性，以提高检测准确性和背景解释能力。", "innovation": "本文提出的方法利用单一事件后的数据，无需依赖事前和事后的影像数据，促进了关键场景下的快速部署。该框架通过结合SAR影像和详细的脆弱性和暴露信息，提供了可靠且快速的建筑损坏评估，同时不依赖于可用的事前数据。此外，由于自动化和可扩展的数据生成过程，该框架在多样化灾害影响区域的应用前景广阔，有望在有效灾害管理和恢复工作中发挥作用。", "conclusion": "该框架的有效性通过2023年土耳其地震的新型数据集进行了演示，结果表明整合地理空间特征显著提高了检测性能和对未见过区域的通用性。此研究强调了该方法在支持有效的灾害管理与恢复方面的重要潜力。此类方法一旦被接受，代码和数据将被公布。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22360", "html_url": "https://arxiv.org/abs/2506.22360", "title": "从地面到空中：事件驱动车辆分类中视觉变换器和CNN的噪声鲁棒性及潜在的无人机应用", "title_en": "From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications", "authors": "Nouf Almesafri,Hector Figueiredo,Miguel Arana-Catania", "background": "本研究探讨了事件驱动相机中的性能表现，这类相机捕获场景变化，不同于传统帧驱动相机。它们特别适用于动态环境，如无人机和自动驾驶车辆。研究在GEN1事件驱动数据集上对ResNet34和ViT B16这两个最具相关性的深度学习架构进行微调，并在干净的数据集和模拟噪声环境中对其进行了评估和比较。结果显示，ResNet34 和 ViT B16的准确率分别为88%和86%，ViT B16在噪声环境中有更好的鲁棒性。虽然研究主要集中在地面车辆分类上，但其方法和发现对于无人机应用、包括无人机上空物体分类和航空任务中的事件驱动视觉系统具有重要潜力。", "innovation": "使用Vision Transformer (ViT) B16与传统的Convolutional Neural Network (CNN)架构对事件驱动相机进行研究，评估了其在干净和噪声条件下的性能表现。", "conclusion": "研究发现ViT B16在噪声环境中有更好鲁棒性，并表明这些方法和发现具有向无人机应用的潜力，包括空中目标识别和航空任务中的视觉系统。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22375", "html_url": "https://arxiv.org/abs/2506.22375", "title": "借助图评分传播的无需训练的3D点云OOD检测利用视觉语言模型", "title_en": "Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation", "authors": "Tiankai Chen,Yushu Li,Adam Goodge,Fei Teng,Xulei Yang,Tianrui Li,Xun Xu", "background": "3D点云数据的离分布（OOD）检测仍然是一个挑战，特别是在需要安全和鲁棒感知的应用中。现有的ODD检测方法在2D图像数据方面虽然有所进展，但将其扩展到3D环境涉及独特的障碍。现有的方法在处理3D点云数据的OOD检测方面存在局限性，尤其是在训练过程中需要大量的标注数据，这增加了成本和复杂性。", "innovation": "该论文提出了一种无需训练的框架，利用视觉语言模型（VLMs）有效进行3D点云OOD检测。通过基于类原型和测试数据构建图，利用数据流形结构来增强VLMs的有效性。此外，还提出了一个新颖的图评分传播（GSP）方法，该方法结合了提示聚类和自我训练的负提示，以提高使用VLMs的ODD评分。论文还展示了GSP方法在合成和真实世界数据集中的表现优于现有的先进方法，并且该方法对少数样本场景也具有适应性，为实际应用场景提供了选项。", "conclusion": "实验结果显示，GSP方法在合成和真实世界3D点云ODD检测数据集上持续优于最先进的方法。该工作提出的方法不仅在性能上有所提升，而且在应用灵活性方面也有显著增强，特别是在少数样本场景中具有强大的表现。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22395", "html_url": "https://arxiv.org/abs/2506.22395", "title": "视觉语言模型测试时的一致性", "title_en": "Test-Time Consistency in Vision Language Models", "authors": "Shih-Han Chou,Shivam Chandhok,James J. Little,Leonid Sigal", "background": "视觉-语言模型（VLMs）在多种跨模态任务中取得了显著的性能，但在面对语义等价输入时，这些模型常常表现出不一致的行为，这削弱了它们的可靠性和鲁棒性。最近的基准测试如MM-R3显示，即便是最先进的VLMs也会对语义等价的输入产生不同预测，尽管它们的平均准确性很高。此前的工作通过修改模型架构或在精心挑选的数据集上进行大规模微调来解决这一问题。然而，本文提出了一种简单而有效的测试时一致性框架，可以在不进行监督重新训练的情况下增强语义一致性。该方法完全是事后处理的、模型无关的，并适用于具有权重访问权限的任何VLM。", "innovation": "本文提出的测试时一致性框架通过两种互补的目标实现了语义一致性增强：（i）交叉熵一致性损失，使预测分布跨越语义等价输入保持一致；（ii）伪标签一致性损失，使输出趋向自我平均一致性。该方法是即插即用的，利用单个测试输入的信息来提高一致性。实验结果表明，该框架在最先进的模型上实现了显著的一致性提升，确立了多模态学习在推断时适应的新方向。", "conclusion": "本研究在多模态基准MM-R3上的实验表明，提出的框架在最先进的模型上实现了显著的一致性提升，建立了多模态学习在推理时适应的新方向。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22434", "html_url": "https://arxiv.org/abs/2506.22434", "title": "MiCo: 多幅图像对比强化视觉推理", "title_en": "MiCo: Multi-image Contrast for Reinforcement Visual Reasoning", "authors": "Xi Chen,Mingkang Zhu,Shaoteng Liu,Xiaoyang Wu,Xiaogang Xu,Yu Liu,Xiang Bai,Hengshuang Zhao", "background": "当前研究主要采用基于规则的强化学习方法提升视觉语言模型(Vision-Language Models, VLMs)的链式思考（Chain-of-Thought, CoT）能力，但这种方法通常依赖于人工标注的问题-答案对，这在处理细粒度视觉细节和跨图像复杂逻辑时尤其具有挑战性。作者受到自我监督的视觉表示学习的启发，发现图像本身就具有内在的限制条件，这些限制可以作为监督信息。因此，作者构建了包含两个相同图像的不同增强视图和一个新的但相似图像的图像三元组，在训练过程中，模型需要生成比较这些图像的推理过程（即确定相同或不同），并通过基于规则的强化学习进行优化。由于具有高度的视觉相似性和增强效果，模型必须注意细微的视觉变化并进行逻辑推理才能成功。实验表明，仅通过图像对比任务训练，模型推理能力在多图像推理基准和一般视觉任务中仍展现出良好的泛化能力，无需任何人工标注的问题-答案对。", "innovation": "该研究引入了基于图像三元组和自我监督学习的方法，构建了一种新的训练框架来提升多图像推理能力。不同于传统依赖人工标注问题-答案对的方法，通过增强图像之间的对比学习和基于规则的强化学习，使得模型能够有效捕捉细微的视觉变化和进行复杂的逻辑推理，最终提高了多图像推理任务和更广泛的视觉任务的表现。", "conclusion": "尽管仅通过图像对比任务进行训练，所提出的方法仍然在多图像推理基准和一般视觉任务上表现出显著的性能提升，其推理能力具有良好的泛化效果，展示了强大的性能而无需任何人工标注的问题-答案对。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22385", "html_url": "https://arxiv.org/abs/2506.22385", "title": "Video Large Multimodal Models Can Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment", "title_en": "Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment", "authors": "Yue Zhang,Jilei Sun,Yunhui Guo,Vibhav Gogate", "background": "视频大规模多模态模型（VLMMs）在理解视频内容方面取得了显著进展，但在抽象和适应性推理方面常遇到挑战——即在新信息出现时修订其解释的能力。结论往往不是固定的；额外的上下文可以加强或削弱初始推断。本文介绍了一种新的任务Defeasible Video Entailment（DVidE），挑战模型在面对新证据时不断更新其推理能力，如同持怀疑态度一样思考。给定一个视频前提和一个文本假设，模型需要确定新的更新是加强还是削弱假设（分类版本）或生成与最初加强或削弱目标一致的连贯更新（生成版本）", "innovation": "本文提出了一个名为Defeasible Video Entailment（DVidE）的新任务，挑战模型在面临新证据时不断更新其推理能力；提出了Chain of Counterfactual Thought框架，结合反事实推理、ASR增强视频内容和解释优化，减少推理偏差；开发了一个框架，结合ASR输出和大型语言模型（LLM），生成与加强或削弱目标相关连贯的更新；引入了新的基准数据集，带有加强器/削弱器注释和基于LLM的评判指标，特别适用于评估生成性能；实验结果显示显著改进，表明我们提出的方法能够增强VLMMs的动态推理能力", "conclusion": "实验结果表明，本研究提出的框架在增强视频大规模多模态模型的动态推理能力方面取得了显著成效，这对于提高这些模型的适应性解释和理解能力具有重要意义"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21592", "html_url": "https://arxiv.org/abs/2506.21592", "title": "SignBart——针对孤立手语识别的骨架序列新方法", "title_en": "SignBart -- New approach with the skeleton sequence for Isolated Sign language Recognition", "authors": "Tinh Nguyen,Minh Khue Phan Tran", "background": "手语识别对于听力受损者打破沟通障碍至关重要。然而，以往的方法必须在效率和准确性之间做出选择。例如，RNNs、LSTMs和GCNs存在梯度消失和高计算成本的问题。尽管Transformer模型提高了性能，但它们并未被广泛采用。传统模型往往将骨架序列的x和y坐标视为不可分割的，难以各自独立提取有意义的信息。", "innovation": "该研究提出了一种新的基于BART架构的骨架序列手语识别方法。该方法独立编码x和y坐标，并通过交叉注意力机制保持它们之间的相关性。此外，该方法使用了较小数量的参数（749,888），在LSA-64数据集上实现了96.04%的准确率，显著优于参数超过一百万的其他模型。此外，该模型在WLASL和ASL-Citizen数据集上也展现了出色的性能和泛化能力。", "conclusion": "该研究提供了一种可靠且有效的手语识别方法，有助于增强聋人和听力障碍者的无障碍工具。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22432", "html_url": "https://arxiv.org/abs/2506.22432", "title": "Shape-for-Motion: 使用3D代理实现精确且一致的视频编辑", "title_en": "Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy", "authors": "Yuhao Liu,Tengfei Wang,Fang Liu,Zhenwei Wang,Rynson W.H. Lau", "background": "近年来，深度生成模型的进展为视频合成带来了前所未有的机会。然而，在实际应用中，用户常常寻求能准确实现其创意编辑意图且具有精确和一致控制的工具。尽管现有方法已经取得了进展，但确保与用户意图的细微对齐依然是一项开放且具有挑战性的问题。因此，提出一种结合3D代理的新框架以实现精确和一致的视频编辑是当前的需求与挑战。", "innovation": "本文提出了一种名为 Shape-for-Motion 的新框架，该框架通过将输入视频中的目标对象转换为时间一致的 meshes 来实现精确和一致的视频编辑。此外，为了简化编辑过程，设计了一种名为双传播策略的新方法，可让用户在单帧的3D网格上进行编辑，随后这些编辑会自动传播到其他帧的3D网格上。最后，不同帧的3D网格被进一步投影到2D空间以生成编辑后的几何和纹理渲染，作为解耦视频扩散模型的输入，用于生成编辑后的结果。此框架支持在视频帧中进行各种精确且物理一致的操作，包括姿态编辑、旋转、缩放、平移、纹理修改和对象组合。这代表了高质量、可控制视频编辑流程的重要一步。", "conclusion": "大量实验结果表明，本方法具有优越性和有效性。该项目页面: this https URL"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22433", "html_url": "https://arxiv.org/abs/2506.22433", "title": "WarpRF：多视角一致性在无训练不确定性量化及其在光照场中的应用", "title_en": "WarpRF: Multi-View Consistency for Training-Free Uncertainty Quantification and Applications in Radiance Fields", "authors": "Sadra Safadoust,Fabio Tosi,Fatma Güney,Matteo Poggi", "background": "现有大多数用于量化光照场不确定性的方法都需要训练，而WarpRF提供了一种无需训练、通用的框架来量化光照场的不确定性。它假设准确模型渲染出的图像之间应具有光度和几何一致性。WarpRF通过视角间反向扭曲来利用这一点，将可靠的渲染投影到未见视角，并测量与这些视角渲染的结果的一致性。这种方法简单且成本低，可以免费应用于任何光照场实现，且在不确定性量化和下游任务如主动视图选择和主动建图方面表现出色，优于针对特定框架设计的方法", "innovation": "WarpRF是一个无需训练的通用框架，可以量化光照场的不确定性。它通过利用准确模型的渲染图像之间的光度和几何一致性来计算未见视角的不一致性。这种方法不仅简单，也不需要任何额外的训练，适用于任何光照场实现。此外，WarpRF在不确定性量化和下游任务上表现出色，超出了针对特定框架设计的方法的表现", "conclusion": "WarpRF为量化光照场的不确定性提供了一种新的方法，该方法无需训练，能够广泛应用于各种场景。它通过视角间的一致性测量来提供可靠的结果，克服了传统方法的局限性。WarpRF在性能上优于现有的特定框架方法，特别是在不确定性量化和下游任务应用方面"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21604", "html_url": "https://arxiv.org/abs/2506.21604", "title": "评估VisualRAG：企业文档理解中的跨模态性能量化", "title_en": "Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding", "authors": "Varun Mannam,Fang Wang,Xin Chen", "background": "当前的多模态生成AI评估框架难以建立信任度，这阻碍了在可靠性至关重要的企业环境中采用此类技术。跨模态输入，如文本、图像、说明和OCR，在VisualRAG系统中的逐步集成对企业文档智能至关重要，但当前缺乏有效评估这些技术的方式，限制了其在企业中的应用。", "innovation": "我们提出了一个系统性的、定量的基准框架来衡量跨模态输入在VisualRAG系统中的集成信任度，包括文本、图像、说明和OCR的逐步集成。该框架建立了技术指标与用户信任度之间的定量关系。研究发现，理想的数据模态加权配置（文本30%、图像15%、说明25%、OCR 30%）相比仅基于文本的基准提高了57.3%的性能，同时保持了计算效率。此外，比较了基础模型在说明生成和OCR提取中的不同影响，这对于可靠的AI应用至关重要。", "conclusion": "通过提供一个严格的框架来量化和提高用于关键企业应用的跨模态RAG的信任度，这项工作推进了负责任的AI部署。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21601", "html_url": "https://arxiv.org/abs/2506.21601", "title": "层级化 patches 压缩技术在 ColPali 中的应用：结合动态剪枝和量化实现高效多向量文档检索", "title_en": "Hierarchical Patch Compression for ColPali: Efficient Multi-Vector Document Retrieval with Dynamic Pruning and Quantization", "authors": "Duong Bach", "background": "现有的多向量文档检索系统，如 ColPali，擅长处理复杂的查询以实现细粒度匹配，但因依赖高维度补丁嵌入及晚期交互评分而在存储和计算成本方面存在显著问题。为了应对这些挑战，本文提出了一种 HPC-ColPali 框架，该框架通过引入稀疏量化、注意力引导动态剪枝和可选的位编码技术提高了 ColPali 的效率，同时保持其检索准确性。", "innovation": "本文提出的方法主要包含三个方面：1、采用 K-Means 量化将补丁嵌入压缩为 1 字节中心点索引，存储减少最高可达 32 倍；2、利用视觉-语言模型的注意力权重进行动态剪枝，保留最显着的补丁，减少晚期交互计算最高达 60%，且 nDCG@10 损失少于 2%；3、可选地将中心点索引编码为 $b$ 位字符串（$b=\text{ceil}(\text{log}_2 K)$），在资源受限环境中实现快速汉明距离相似搜索。", "conclusion": "HPC-ColPali 在 ViDoRe 和 SEC-Filings 数据集上的测试表明，即使在 HNSW 索引下，其查询延迟较低（降低 30-50%），同时保持了高检索精度。当集成到法律摘要生成的检索增强生成流水线中时，HPC-ColPali 能降低幻觉率 30%，并使端到端延迟减半。这些改进使得 HPC-ColPali 成为适用于各种应用的高效和可扩展的多向量文档检索解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21586", "html_url": "https://arxiv.org/abs/2506.21586", "title": "视觉语言模型能否理解模仿动作？", "title_en": "Can Vision Language Models Understand Mimed Actions?", "authors": "Hyundong Cho,Spencer Lin,Tejas Srinivasan,Michael Saxon,Deuksin Kwon,Natali T. Chavez,Jonathan May", "background": "非言语交流（NVC）在人类语言中起着重要作用，但由于其广泛的范围和个体及文化之间的高解释差异，因此对NVC进行一般性的研究具有挑战性。相比之下，手势表演（mime）是一种仅通过手势、表情和动作来暗示意图的戏剧性技巧，它包含明确且具身的动作，这些动作的人类解释差异较低。因此，对于能够解释和操控更多微妙非言语交流方面能力的语言模型而言，对模仿动作的理解是至关重要的基础知识。", "innovation": "提出了一种名为MIME的新视频为基础的问答基准数据集，包含了86种模仿动作。MIME采用运动捕捉数据构建，并应用于角色、背景和视角上的扰动，以评估识别的鲁棒性。研究发现，开放权重和基于API的视觉语言模型在MIME上的性能显著低于人类，这激发了关于增强人类手势理解的鲁棒性的更多研究需求。", "conclusion": "视觉语言模型在理解模仿动作方面表现较差，凸显了对人类手势理解更多鲁棒性的需求，未来的研究应致力于增强模型对这些微妙非言语交流方面的理解。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22347", "html_url": "https://arxiv.org/abs/2506.22347", "title": "在生物特征加密系统中缩小性能差距：对可追踪模糊 vault 的更深入分析", "title_en": "Closing the Performance Gap in Biometric Cryptosystems: A Deeper Analysis on Unlinkable Fuzzy Vaults", "authors": "Hans Geißner,Christian Rathgeb", "background": "本文分析并探讨了基于模糊 vault 的生物特征加密系统（BCS）中的性能差距问题。研究发现，不稳定的数据纠错能力是导致性能下降的关键原因，这种能力的不稳定是由特征集大小的变化及其对相似度阈值的影响所引起的。此外，特征类型转换过程中的信息丢失进一步加剧了这个问题。为了应对这些问题，本研究提出了一种基于等频区间的新型特征量化方法，该方法能保证特征集的固定大小，并支持无训练的适应任意区间的数量，从而有效地减少了模板保护导致的性能差距，同时它与现有系统无缝集成，最大限度地减少了特征转换带来的负面影响。通过在最新的面部识别、指纹识别和虹膜识别系统中的实验验证，本研究证明了该方法的有效性，并在主要的生物特征模态下实现了最小程度的性能下降。", "innovation": "本文提出了一种基于等频区间的新型特征量化方法，改方法能保证特征集的固定大小，并支持无训练的适应任意区间的数量。这种方法显著减少了模板保护引起的性能差距，且无缝集成到现有系统中，最大限度地减少了特征转换带来的负面影响。", "conclusion": "实验结果显示，通过提出的方法，仅在最小程度上造成了性能上的下降，从而证明了该方法的有效性，展示了其对主要生物特征模态的有效性。这种方法能够有效改善基于模糊 vault 的生物特征加密系统的性能问题，具有重要的应用价值。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21630", "html_url": "https://arxiv.org/abs/2506.21630", "title": "TOMD：在恶劣光照条件下基于 trails 的多模态越野路径分割数据集", "title_en": "TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions", "authors": "Yixin Sun,Li Li,Wenke E,Amir Atapour-Abarghouei,Toby P. Breckon", "background": "自主机器人在不规则户外环境中识别可通行路径依然是一个重大的挑战，尤其是在广域搜索救援和森林火灾等关键应用中。现有的数据集和模型主要针对城市环境或开阔、车辆可通行的越野公路，却没有解决狭窄、类似于小径的越野场景的复杂性。为了解决这一问题，研究人员提出了 Trail-based Off-road Multimodal Dataset (TOMD) 这一全面的数据集，并配以多模态传感器数据，包括128通道激光雷达、立体图像、GNSS、IMU和光照测量。这些数据是通过在不同条件下重复穿越收集的。研究还分析了不同程度光照下早期、交叉和混合融合策略表现。结果表明，我们的方法非常有效，光照条件在分割性能中具有重要意义。", "innovation": "研究引入了 Trail-based Off-road Multimodal Dataset (TOMD)，这是一个特别针对狭小的类似小径的越野环境的数据集。TOMD 中包含高保真多模态传感器数据——包括128通道激光雷达、立体图像、GNSS、IMU和光照测量数据，并且通过多种条件进行了反复穿越的采样。同时提出了一个动态多尺度数据融合模型，准确地预测可通行路径，并通过不同的光照条件分析了早期、交叉和混合融合策略的表现。该方法展示了在恶劣光照条件下路径分割的有效性，并公开发布了数据集以支持未来关于基于trail的越野导航的研究，确保了方法的实际应用价值和重复性验证的能力。", "conclusion": "研究结果表明，在不同的光照条件下，早融合、交叉融合和混合融合策略均有效，但光照条件对分割性能有明显影响。通过公开发布TOMD数据集，本研究旨在支持未来针对trail-based 越野导航的研究工作，填补现有数据集在处理狭窄越野场景上的不足。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21748", "html_url": "https://arxiv.org/abs/2506.21748", "title": "使用扩散模型进行衍射元表面的逆设计", "title_en": "Inverse Design of Diffractive Metasurfaces Using Diffusion Models", "authors": "Liav Hen,Erez Yosef,Dan Raviv,Raja Giryes,Jacob Scheuer", "background": "元表面是一种超薄光学元件，由工程设计的亚波长结构组成，可实现对光的精确操控。它们的设计逆问题——确定一种结构以产生所需的光响应——由于结构与光学性能之间的复杂、非线性关系而充满挑战。这通常需要专家调优，容易陷入局部最小值，并涉及显著的计算开销。", "innovation": "本文通过将生成扩散模型的生成能力整合到计算设计流程中来解决上述挑战。使用RCWA模拟器生成元表面几何结构和对应的远场散射图案的训练数据。然后训练一个条件扩散模型，从连续支持带中采样的目标空间功率分布预测元原子的几何结构和高度。一旦训练完成，该模型可以通过RCWA引导的后验采样直接生成低误差的元表面，或者作为传统优化方法的初始化器。该方法在不到30分钟的时间内成功设计了均匀强度分裂器和偏振光束分裂器，并表现出低误差。", "conclusion": "本文的方法证明了扩散模型在数据驱动型元表面设计中的潜力，并且为了进一步的研究，我们已公开发布我们的代码和数据集。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21635", "html_url": "https://arxiv.org/abs/2506.21635", "title": "AeroLite-MDNet：用于无人机着陆的轻量级多任务偏移检测网络", "title_en": "AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing", "authors": "Haiping Yang,Huaxing Liu,Wei Wu,Zuohui Chen,Ning Wu", "background": "无人驾驶飞行器（UAVs）在诸如土地测量、材料运输和环境监控等多种应用中越来越受到青睐。按照数据收集或检查等任务之后，UAVs需要安全地降落在集电站进行存储或充电，这对保持操作连续性至关重要。然而，准确着陆仍具有挑战性，原因包括GPS信号干扰等。因此，提出了一种基于视觉模型的偏移警告系统，以解决这一问题。该系统包含了名为AeroLite-MDNet的新型视觉模型，该模型融合了多尺度融合模块来实现鲁棒的跨尺度目标检测，并结合了分割分支以实现高效的航向估计。我们还引入了一个新的评估指标，平均警告延迟（AWD），用于量化系统的偏移敏感度。此外，为了支持训练与评估，我们提供了一个新数据集，UAVLandData，记录了实际着陆偏移情况。", "innovation": "提出了AeroLite-MDNet模型，这是一种轻量级多任务偏移检测网络。该模型结合了多尺度融合模块，以增强跨尺度目标检测的鲁棒性，并包含了分割分支以进行高效的航向估计。同时，还引入了一个新的评估指标AWD来度量系统的敏感度，并提供了新的UAVLandData数据集，以支持该模型的训练与测试。该模型在实验中达到了0.7秒的平均警告延迟和98.6%的偏移检测准确性。", "conclusion": "本研究提出了一种基于视觉模型的偏移警告系统，采用AeroLite-MDNet模型实现多任务偏移检测，有效提升了UAV的着陆可靠性。研究结果表明，该系统具有较高的准确性和鲁棒性。未来的工作将进一步优化模型性能并扩大应用场景。相关代码将发布在指定的网址。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21732", "html_url": "https://arxiv.org/abs/2506.21732", "title": "基于位姿信息的强化学习在滑动转向视觉导航中的实验研究", "title_en": "Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation", "authors": "Ameya Salvi,Venkat Krovi", "background": "基于视觉的车道保持在机器人和自主地面车辆领域受到了广泛关注，适用于各种道路和非道路应用场景。滑动转向车辆架构在由人类操控的操作中非常有用，然而，特别是在非道路状况下的滑移轮与地形的相互作用的系统建模成为自动化部署的瓶颈。端到端学习方法，如模仿学习和深度强化学习，被认为是一种有效的部署选项，以克服准确分析模型缺乏的问题。然而，在动态运行条件下（尤其是对于滑动转向车辆），系统性形式化和随后的验证/验证仍然是一项进行中的工作。", "innovation": "本文提出了一个新颖的结构化形式化方法，用于学习视觉导航，并通过广泛的软件模拟、硬件评估和消融研究，证明了该方法相比于前人的文献，在性能上有了显著的改进。", "conclusion": "文章通过全面的实验验证，展示了所提出方法的有效性和优越性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21680", "html_url": "https://arxiv.org/abs/2506.21680", "title": "PhotonSplat: 3D场景重建和着色从SPAD传感器", "title_en": "PhotonSplat: 3D Scene Reconstruction and Colorization from SPAD Sensors", "authors": "Sai Sri Teja,Sreevidya Chintalapati,Vinayak Gupta,Mukund Varma T,Haejoon Lee,Aswin Sankaranarayanan,Kaushik Mitra", "background": "3D重建技术在使用神经渲染时已经能够实现高质量的3D捕获，但在输入图像受到运动模糊影响的情况下往往会失败。这种影响可能是由于相机或场景中的物体快速移动导致的。研究人员发现SPAD（单光子雪崩二极管）阵列作为一种新兴的成像技术，能够以极高的速度捕捉图像，但使用SPAD带来的挑战是由于随机光子到达引起的二进制图像。针对这一挑战，本文提出了PhotonSplat框架，它可以直接从SPAD二进制图像重建3D场景，有效地缓解噪声和模糊之间的权衡。该框架支持基于生成先验的无参照重建和单模糊图像的参考着色，适用于下游应用如分割、目标检测和外观编辑。此外，该方法还扩展到动态场景的表示，使其适用于包含移动物体的场景，并贡献了PhotonScenes数据库，这是一个使用SPAD传感器捕获的真实多视图数据集。", "innovation": "提出PhotonSplat框架，该框架直接从SPAD二进制图像重建3D场景，有效解决了噪声和模糊之间的权衡问题，并引入了新颖的3D空间滤波技术来降低渲染中的噪声。该方法还扩展到动态场景的表示，并贡献了PhotonScenes数据库，是使用SPAD传感器捕获的真实多视图数据集。", "conclusion": "PhotonSplat框架不仅能够有效从SPAD二进制图像中重建3D场景和进行着色，还支持多种下游应用，并通过实际数据集的贡献，为SPAD传感器的应用提供了丰富的资源。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21714", "html_url": "https://arxiv.org/abs/2506.21714", "title": "ODE_t (ODE_l): 在扩散模型和流动模型中缩短时间和长度以加快采样", "title_en": "$\\textrm{ODE}_t \\left(\\textrm{ODE}_l \\right)$: Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "authors": "Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer", "background": "近年来，连续规范化流(CNFs)和扩散模型(DMs)已经使用统一的理论框架进行了研究。尽管这些模型能够从噪声分布生成高质量的数据点，但在采样过程中仍需要多次迭代解普通微分方程(ODE)，这带来了较高的计算复杂性。大多数现有方法集中在降低采样过程中的时间步数，以提高效率。然而，这些方法通常依赖于特定的解算器，如果时间步或网络长度发生变化，可能会导致效率下降。本文研究了通过动态控制时间步和网络长度来调整质量-复杂度权衡的新方向。这种方法通过在基于变换器的架构中重布块来解决时间长度上的内离散ODE，同时在流匹配训练期间使用时间一致性和长度一致性术语，实现了任意时间步和变换器块的数量进行采样。", "innovation": "本文研究了如何通过动态控制时间步和网络长度来调整质量-复杂度权衡，提出了一个新的方法，这种方法在时间维度上是解算器无关的，并且能够减少延迟并降低内存使用。具体来说，这种方法通过在基于变换器的架构中重布块来解决时间长度上的内离散ODE，并在流匹配训练期间使用时间一致性和长度一致性术语，从而实现了任意时间步和变换器块数量的采样。该方法在CelebA-HQ和ImageNet上的图像生成实验中，与先前最先进的方法相比，高效采样模式下的延迟最多减少了3倍，并且高质量采样下的FID分数改善了3.5分。", "conclusion": "与以前最先进的技术相比，我们的方法在图像生成实验中展示了显著的延迟减少和FID分数改善。此外，我们已经发布我们的代码和模型权重，并确保实验的完全可复现。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21812", "html_url": "https://arxiv.org/abs/2506.21812", "title": "透明AI迈向之路：大规模语言模型可解释性研究", "title_en": "Towards Transparent AI: A Survey on Explainable Large Language Models", "authors": "Avash Palikhe,Zhenyu Yu,Zichong Wang,Wenbin Zhang", "background": "大型语言模型（LLMs）在人工智能（AI）的发展中发挥了关键作用。尽管如此，在决策过程缺乏解释性的背景下，这些模型常被视为‘黑箱’，这对解释性的接受度构成了重大挑战。尤其是在高风险应用场景中，需要特别重视解释性。尽管研究人员开发了多种可解释的人工智能（XAI）方法以提供人类可理解的LLM解释，但对其系统性理解仍有限。因此，需要一个全面的回顾来填补这一空白，这不仅包括基于LLM底层变换器架构类型（编码器仅，解码器仅，编码器-解码器）分类XAI方法，还涉及据此评估解释性以及探讨这些解释在实际应用中的使用情况。最终，该综述还讨论了可用资源、正在进行的研究挑战和未来方向，旨在引导继续努力，打破透明和负责任LLM的瓶颈限制，使之广泛应用于各行各业。", "innovation": "对该领域进行了系统性回顾，根据不同类型的LLM底层变换器架构对XAI方法进行分类，评估解释性，探讨其应用，并讨论现有资源、研究挑战和未来方向，以推动透明和负责任LLM的发展。", "conclusion": "该综述旨在为继续开发透明和负责任LLM的学术界和工业界提供指导，填补解释性技术系统性理解的空白，并为未来研究方向提供参考。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21765", "html_url": "https://arxiv.org/abs/2506.21765", "title": "TUS-REC2024: A Challenge to Reconstruct 3D Freehand Ultrasound Without External Tracker", "title_en": "TUS-REC2024: A Challenge to Reconstruct 3D Freehand Ultrasound Without External Tracker", "authors": "Qi Li,Shaheer U. Saeed,Yuliang Huang,Mingyuan Luo,Zhongnuo Yan,Jiongquan Chen,Xin Yang,Dong Ni,Nektarios Winter,Phuc Nguyen,Lucas Steinberger,Caelan Haney,Yuan Zhao,Mingjie Jiang,Bowen Ren,SiYeoul Lee,Seonho Kim,MinKyung Seo,MinWoo Kim,Yimeng Dou,Zhiwei Zhang,Yin Li,Tomy Varghese,Dean C. Barratt,Matthew J. Clarkson,Tom Vercauteren,Yipeng Hu", "background": "Trackerless freehand ultrasound reconstruction旨在从2D超声图像序列重构3D体积，无需依赖外部追踪系统，提供了低成本、便携且广泛部署的体积成像替代方案。然而，这种方法面临显著的挑战，包括精确的帧间运动估计、长序列中偏差积累的最小化以及扫描协议的一般性。TUS-REC2024挑战旨在通过提供公开的数据集、基线模型和评估框架来衡量和加速无追踪3D超声重构的进步。", "innovation": "首次提供公开数据集，并吸引了43支队伍参与，其中6支队伍提交了21个有效的docker化解决方案。提交的方法涵盖了各种算法方法，包括循环模型、注册驱动的体积精炼、注意力机制和物理信息模型。该论文概述了挑战的设计、总结了数据集的关键特征，提供了综述文献，并介绍了与标记自由手超声数据合作的底层方法的技术细节。它还提供了提交方法在多个评估指标上的比较分析。这些结果突显了该领域最先进的方法的进展和当前局限性，并为未来研究指明了方向。提供的数据、评估代码和基线开源以促进持续开发和可重复性。该挑战被设计为持续开发和改进的基准，并将在连续的MICCAI会议上举办，以反映其影响的增长和对该领域的持续承诺。", "conclusion": "结果显示了该领域的进展和当前局限性，并为未来研究指明了方向。提供的数据、评估代码和基线开源以促进持续开发和可重复性。该挑战被设计为持续开发和改进的基准，并将在连续的MICCAI会议上举办，以反映其影响的增长和对该领域的持续承诺。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21934", "html_url": "https://arxiv.org/abs/2506.21934", "title": "CAL-RAG：基于检索增强的多智能体生成框架用于内容感知布局设计", "title_en": "CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design", "authors": "Najmeh Forouzandehmehr,Reza Yousefi Maragheh,Sriram Kollipara,Kai Zhao,Topojoy Biswas,Evren Korpeoglu,Kannan Achan", "background": "内容感知布局生成的任务是在背景画布上排列文本、Logo等视觉元素，这在智能设计系统中仍是一个基础但未被充分探索的问题。尽管基于深度生成模型和大型语言模型（LLMs）的技术在结构化内容生成方面展现了潜力，但现有方法大多缺乏与上下文设计实例的联系，并且在语义对齐和视觉一致性方面表现不足。", "innovation": "本文引入CAL-RAG框架，该框架是一个检索增强、具身的内容感知布局生成系统，结合了多模态检索、LLM和协作型具身推理。该系统从结构化知识库中检索相关布局示例，并利用基于LLM的布局推荐器提出结构化元素放置建议。视觉语言评判智能体评估布局的视觉指标，反馈智能体提供针对性的改进措施，实现迭代优化。CAL-RAG通过多个布局指标达到最先进的性能，显著优于现有基准（如LayoutPrompter）", "conclusion": "检索增强与具身多步推理相结合，为自动生成布局提供了一个可扩展、可解释且高质量的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21880", "html_url": "https://arxiv.org/abs/2506.21880", "title": "基于物理退化模型的展开变换器导向干涉 hyperspectral图像重建", "title_en": "Physical Degradation Model-Guided Interferometric Hyperspectral Reconstruction with Unfolding Transformer", "authors": "Yuansheng Li,Yunhao Zou,Linwei Chen,Ying Fu", "background": "干涉式高光谱成像(IHI)因其在通量和光谱分辨率方面的优势，在大规模遥感任务中至关重要。然而，IHI因其成像步骤中的复杂误差而易受损害，其质量受限于现有的基于信号处理的重建算法。提高性能的两个关键挑战是缺乏训练数据集和通过基于学习的方法消除特定于IHI的退化组件的困难。本文旨在解决这些问题，提出了一个新颖的IHI重建流水线，该流水线包括建立简化但准确的IHI退化模型和参数估计方法，以及设计一种通过条纹图案增强机制和空谱变换架构实现有效光谱校正和细节恢复的Interferometric Hyperspectral Reconstruction Unfolding Transformer (IHRUT)。", "innovation": "本文提出了一种全新的IHI重建流水线。首先，基于成像物理和辐射校准数据，建立了一个简化但准确的IHI退化模型和参数估计方法，以生成从高光谱图像(HSI)中合成的现实IHI训练数据集，填补了IHI重建与深度学习之间的差距。其次，设计了Interferometric Hyperspectral Reconstruction Unfolding Transformer (IHRUT)，实现有效的光谱校正和细节恢复，通过条纹图案增强机制和空谱变换架构。实验结果证明了本文方法的优越性能和泛化能力", "conclusion": "本文提出的方法在IHI重建中表现出色且具有泛化能力。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21860", "html_url": "https://arxiv.org/abs/2506.21860", "title": "体态域适应下的物体检测", "title_en": "Embodied Domain Adaptation for Object Detection", "authors": "Xiangyu Shi,Yanyuan Qiao,Lingqiao Liu,Feras Dayoub", "background": "移动机器人依赖于物体检测器来感知和定位室内环境中的物体。标准的闭集方法在处理实际家庭和实验室中遇到的多样物体和动态条件时存在问题。通过视觉语言模型（VLMs）驱动的开放式词汇物体检测（OVOD）可以超越固定标签，但在室内环境中的领域转移（domain shifts）上仍存在问题。", "innovation": "作者提出了一种无源域适应（SFDA）方法，可以在不访问源数据的情况下对预训练模型进行适应。该方法通过时间聚类精炼伪标签，使用多尺度阈值融合，并应用对比学习的教师模型框架。同时，引入了一个名为EDAOD（Embodied Domain Adaptation for Object Detection）的基准测试，以评估在顺序变化的光照、布局和物体多样性条件下物体检测的适应能力。", "conclusion": "实验结果显示，在零样本检测性能方面以及对动态室内条件的灵活适应上取得了显著的改进。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21976", "html_url": "https://arxiv.org/abs/2506.21976", "title": "SceneDiffuser++：通过生成世界模型的城市规模交通模拟", "title_en": "SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model", "authors": "Shuhan Tan,John Lambert,Hong Jeon,Sakshum Kulshrestha,Yijing Bai,Jing Luo,Dragomir Anguelov,Mingxing Tan,Chiyu Max Jiang", "background": "交通模拟的目标是通过合成模拟的大量行驶里程，补充有限的实地测试和验证里程。最终目标是创建一个生成性的城市仿真环境，当给定城市地图和自动驾驶汽车（AV）软件栈时，仿真器能够无缝地从A点到B点模拟整个行程，通过填充城市环境并控制场景的所有方面，包括动态代理（如车辆、行人）的动画和交通信号灯状态的控制。这一愿景被称为CitySim，需要结合多种仿真的技术，包括场景生成、代理行为建模、遮挡推理、动态场景生成以及环境仿真等。虽然一些关键技术已在不同研究中有所探讨，但其他技术如动态场景生成和环境仿真在研究社区中较少被关注。", "innovation": "我们提出了SceneDiffuser++，这是第一个端到端的生成世界模型，可以在单一损失函数下训练，具备城市规模的A到B点的交通模拟能力，并整合了上述所有要求。SceneDiffuser++展示了其在城市规模交通模拟方面的能力，并在长时间模拟条件下研究了其优越的现实性。我们还在Waymo开放运动数据集（WOMD）的增强版本中评估了仿真质量，增加了更大的地图区域以支持行程级别的模拟.", "conclusion": "我们证明了SceneDiffuser++在城市规模交通模拟方面的能力，并展示了其优越的仿真质量。通过此项工作，我们希望为自动驾驶车辆的研究和测试提供一种高效的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21884", "html_url": "https://arxiv.org/abs/2506.21884", "title": "UnMix-NeRF: 谱分解遇上了神经辐射场", "title_en": "UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields", "authors": "Fabian Perez,Sara Rojas,Carlos Hinojosa,Hoover Rueda-Chacón,Bernard Ghanem", "background": "基于Neural Radiance Field (NeRF) 的分割方法专注于物体语义并仅依赖于RGB数据，缺乏内在材质属性。这一限制阻碍了精准的材质感知，这对于机器人技术、增强现实、仿真以及其他应用至关重要。现有的方法在准确捕捉材质信息方面存在局限性，这限制了它们在上述领域的应用效果.", "innovation": "提出了UnMix-NeRF框架，将谱分解技术融入到NeRF中，实现语义分割的同时进行新颖视角的超光谱合成。该方法通过建模扩散和镜面反射成分中的光谱反射率，使用学习到的全球基元字典表示纯材质签名，并利用每个点的丰度捕捉其分布情况。此外，UnMix-NeRF还允许通过修改学习到的基元字典来灵活地进行基于材质的外观编辑，提高了材质分割的准确性和灵活性。", "conclusion": "大量实验验证了该方法的有效性，结果显示UnMix-NeRF在光谱重建和材质分割方面优于现有方法。该项目页面为: this https URL."}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21876", "html_url": "https://arxiv.org/abs/2506.21876", "title": "视觉语言模型具备内部世界模型吗？向着原子化评估", "title_en": "Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation", "authors": "Qiyue Gao,Xinyu Pi,Kevin Liu,Junrong Chen,Ruolan Yang,Xinqi Huang,Xinyu Fang,Lu Sun,Gautham Kishore,Bo Ai,Stone Tao,Mengyang Liu,Jiaxi Yang,Chao-Jung Lai,Chuanyang Jin,Jiannan Xiang,Benhao Huang,Zeming Chen,David Danks,Hao Su,Tianmin Shu,Ziqiao Ma,Lianhui Qin,Zhiting Hu", "background": "现有的视觉语言模型（VLMs）如OpenAI的o3、GPT-4o和Gemini等，虽然展示了在通用世界模型方面的潜力，但对其基本世界建模能力的系统评估仍为空白。近年来的一些研究已经评估了这些模型在视觉理解等特定能力上的表现，但尚未进行全面基本世界模型功能的评估。因此，为了更好地理解这些模型的世界建模能力，本文引入了一个基于比较心理学和认知科学的两阶段框架，分别评估感知和预测能力。", "innovation": "本文提出了一个两阶段的框架，包括感知（视觉、空间、时间、数量和运动）和预测（机械模拟、传递性推理、组合推理），用于系统评估VLMs作为世界模型的基本能力，并基于此框架创建了WM-ABench，这是一个大规模基准，包含23个详细的评估维度，横跨6个不同的模拟环境，并通过对比实验发现了VLMs在基本世界建模能力上的显著局限。", "conclusion": "本文通过大规模的实验发现，许多最新视觉语言模型在基本世界建模能力上存在显著的局限，比如在区分运动轨迹方面基本上随机且缺乏独立理解。这些结果表明视觉语言模型与人类级的世界建模能力之间存在显著差距，需要进一步改进其基本建模能力。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21977", "html_url": "https://arxiv.org/abs/2506.21977", "title": "StableCodec: Taming One-Step Diffusion for Extreme Image Compression", "title_en": "StableCodec: Taming One-Step Diffusion for Extreme Image Compression", "authors": "Tianyu Zhang,Xin Luo,Li Li,Dong Liu", "background": "基于扩散的图像压缩已显示出在极低比特率下实现逼真图像（低于0.05位/像素）的巨大潜力，但当前方法在极端比特率限制下生成逼真结果时需要大量的去噪步骤，限制了它们在实时压缩场景中的应用。此外，这些方法通常牺牲重建保真度，因为扩散模型通常无法保证像素级一致性。现有方法面临的主要挑战包括需要大量去噪步骤以及重建保真度不足。", "innovation": " StableCodec引入了一步法扩散，用于实现高保真度和高逼真的极图像压缩，提高了编码效率。提出了一种高效的Deep Compression Latent Codec来传输一个噪声的潜在表示，用于单步骤去噪过程，并引入了双向编码结构来增强重建保真度。并且采用端到端优化，同时考虑比特率和像素级约束。实验结果表明，StableCodec在CLIC 2020、DIV2K和Kodak数据集上的FID、KID和DISTS均显著优于现有方法，甚至在比特率低至0.005位/像素的情况下仍然保持高保真度，同时实现了与主流变换编码方案相当的推理速度。", "conclusion": "StableCodec通过上述创新实现了在极低比特率下高保真度和高逼真的图像压缩，相比现有方法在多个评价指标上表现出显著优势，并且在实际应用中具有良好的时效性。所有源代码均可在提及的链接中找到。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22116", "html_url": "https://arxiv.org/abs/2506.22116", "title": "评估协作环境中指向手势的目标选择", "title_en": "Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration", "authors": "Noora Sassali,Roel Pieters", "background": "人类与机器人的协作中常使用指向手势进行各种任务的交互，如选择目标或指导工业过程。研究旨在在平面工作空间内定位指向手势的目标，结合姿态估计和基于肩膀-手腕延伸的简单几何模型从RGB-D视频流中提取手势数据。此外，工具被集成到概念验证机器人系统中，该系统包括物体检测、语音转录和语音合成，以展示多种模态在协作应用中的整合。最后，讨论了工具的局限性和性能，以理解其在多模态机器人系统中的角色。", "innovation": "研究提出了一种严格的评估方法和全面的分析方法，用于评价指向手势及目标选择在典型机器人任务中的有效性。此外，该方法还将手势识别工具与物体检测、语音识别和合成功能集成到一个概念验证的机器人系统中，以展示不同模态的集成应用。", "conclusion": "讨论了工具的局限性和性能，为多模态机器人系统中的应用提供了参考，所有的开发成果都可以在指定的链接中找到。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22012", "html_url": "https://arxiv.org/abs/2506.22012", "title": "噪声启发的低剂量CT重建扩散模型", "title_en": "Noise-Inspired Diffusion Model for Generalizable Low-Dose CT Reconstruction", "authors": "Qi Gao,Zhihao Chen,Dong Zeng,Junping Zhang,Jianhua Ma,Hongming Shan", "background": "基于深度学习的低剂量计算机断层扫描（CT）重建模型的一般化在未见过训练数据剂量的情况下仍然是重要的且具有挑战性的。以往的工作主要依赖配对数据提高泛化性能和鲁棒性，通过收集多样化的CT数据重新训练或少量测试数据进行微调。最近，扩散模型在低剂量CT（LDCT）重建中展现了有希望且可泛化的性能，但它们可能会由于CT图像噪声不符合高斯分布以及噪声LDCT图像的不精确先验信息而生成不真实的结构。", "innovation": "本文提出了一种名为NEED的噪声启发的扩散模型，用于可泛化的低剂量CT重建。NEED针对每个领域定制扩散模型，并通过以下方式实现创新：1) 引入了新的偏移泊松扩散模型来 denoise 投影数据，将扩散过程与预对数LDCT投影中的噪声模型对齐；2) 设计了双重引导扩散模型来细化重建图像，利用LDCT图像和初始重建来更准确地定位先验信息并增强重建保真度。通过双重扩散模型的串联进行双域重建，NEED只需要正常剂量的数据进行训练，并通过时间步长匹配策略有效地拓展到各种未见过的剂量水平。", "conclusion": "在两个数据集上的大量定性和定量评估和基于分割的结果表明，NEED在重建和泛化性能上均优于现有最先进的方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22226", "html_url": "https://arxiv.org/abs/2506.22226", "title": "使用心脏CT的放射组学与几何特征进行心血管疾病分类", "title_en": "Cardiovascular disease classification using radiomics and geometric features from cardiac CT", "authors": "Ajay Mittal,Raghav Mehta,Omar Todd,Philipp Seeböck,Georg Langs,Ben Glocker", "background": "从CT图像中自动检测和分类心血管疾病（CVD）对临床决策有着重要作用。然而，现有的基于深度学习的方法或者直接处理原始CT数据，或者结合心肌结构分割进行训练，难以从临床角度进行解释。因此，该研究将CVD分类过程分为三个步骤：图像分割、图像配准和下游CVD分类，以提高可解释性。", "innovation": "利用Atlas-ISTN框架和最新的分割基础模型生成解剖结构分割和规范健康图谱。通过这些模型提取可用临床解释的放射组学特征以及通过图谱配准得到的基于变形场的几何特征，以提高CVD分类的准确性。在公开的ASOCA数据集上，其分类精度达到87.50%，优于直接在原始CT图像上训练的分类模型（67.50%）。", "conclusion": "该研究通过将CVD分类管道分解为图像分割、图像配准和下游CVD分类三个步骤，提高了CVD的分类准确性和临床可解释性，展示了高于直接使用原始CT图像训练的分类性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22156", "html_url": "https://arxiv.org/abs/2506.22156", "title": "基于FPGA的超快神经网络训练硬件加速技术用于MRF图重建", "title_en": "Hardware acceleration for ultra-fast Neural Network training on FPGA for MRF map reconstruction", "authors": "Mattia Ricchi,Fabrizio Alfonsi,Camilla Marella,Marco Barbieri,Alessandra Retico,Leonardo Brizi,Alessandro Gabrielli,Claudia Testa", "background": "Magnetic Resonance Fingerprinting (MRF) 是一种快速的定量磁共振成像技术，能够实现单次采集提供多参数图谱。尽管神经网络可以加速重建过程，但由于训练需求大量的资源，特别是在训练时需要较长时间，这限制了其实际应用。", "innovation": "提出了一种基于FPGA的神经网络，用于实时从MRF数据中重建大脑参数。与标准基于CPU的训练相比，这种方法的训练时间明显缩短，大约为200秒，而CPU训练可能需要更长时间，甚至可以慢250倍。这种方法可以支持移动设备上的实时脑分析，变革临床决策和远程医疗服务。", "conclusion": "该方法能够加速神经网络训练过程，极大地缩短了训练时间，使得神经网络在移动设备上的实时应用成为可能，有助于实时脑部分析，推进临床决策和远程医疗服务的发展。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22222", "html_url": "https://arxiv.org/abs/2506.22222", "title": "高级深度学习技术在B型主动脉夹层自动分割中的应用", "title_en": "Advanced Deep Learning Techniques for Automated Segmentation of Type B Aortic Dissections", "authors": "Hao Xu,Ruth Lim,Brian E. Chapman", "background": "B型主动脉夹层是一种危及生命的心血管状况，需要从CTA图像中准确分割真腔（TL）、假腔（FL）和假腔血栓（FLT），以便有效管理。然而，手动分割耗时且变量不一，迫切需要自动解决方案来提高分割的准确性和效率。已有研究表明，基于深度学习的方法可以提高分割的精确度，但现有的分割方法在不同特征上的表现差异较大，且在 FLT 分割上的效果不佳。本研究旨在开发并评估多种基于深度学习的分割方法，以提高不同特征的分割准确性，尤其是 FLT 的分割效果，为B型主动脉夹层的监测和治疗提供精确的参数支持。", "innovation": "本研究开发了四种基于深度学习的B型主动脉夹层分割管道，包括单步骤模型、顺序模型、顺序多任务模型和集成模型，使用了3D U-Net和Swin-UnetR架构。在对100张回顾性CTA图像进行训练、验证和测试后，研究结果表明，提出的分割方法在多个指标上的性能显著优于现有的方法，特别是在 FLT 分割上表现突出。这些创新方法提供了准确的分割性能，确保了所提取的形态参数的准确性，从而支持更有效的监测和治疗规划。", "conclusion": "提出的分割管道为B型主动脉夹层的关键特征提供了准确的分割，能够用于提取形态参数，支持患者的长期管理和治疗规划。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22176", "html_url": "https://arxiv.org/abs/2506.22176", "title": "KnotDLO：迈向可解释的结绳技巧", "title_en": "KnotDLO: Toward Interpretable Knot Tying", "authors": "Holly Dinkel,Raghavendra Navaratna,Jingyi Xiang,Brian Coltin,Trey Smith,Timothy Bretl", "background": "该工作提出了KnotDLO方法，这是一种用于单手打绳结的算法，适用于复杂环境中常见的可变形线性对象（DLO）。该方法在绳索遮挡、不同初始绳索配置和无需人工示范或训练的情况下都表现出色，能够生成可解释的动作策略，仅通过当前绳索形状即可确定未来的绳索状态的抓取和目标点，并且动作策略为分段连续性。\n", "innovation": "通过结合视觉推理和控制来解决绳结问题，该方法能够从当前绳索的几何形态计算中间路径点，以实现绳结的自动打结，适用于以前未见过的绳索配置，成功率达到50%。", "conclusion": "KnotDLO方法在16次实验中实现了从不同未知绳索配置中成功打结打绳结的任务，展示了其在单手打绳结中的可解释性和鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21655", "html_url": "https://arxiv.org/abs/2506.21655", "title": "APO: 基于非对称策略优化提升多模态大语言模型的推理能力", "title_en": "APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization", "authors": "Minjie Hong,Zirun Guo,Yan Xia,Zehan Wang,Ziang Zhang,Tao Jin,Zhou Zhao", "background": "多模态大型语言模型（MLLMs）能够融合多种数据，但在复杂推理方面存在困难。尽管强化学习（RL）可以提升LLMs的推理能力，但将其应用于MLLMs时会遇到挑战，如任务表现下降和推理过程过于详细或‘过度推理’。本研究探讨了KL惩罚和过度推理对RL训练的影响，并提出了一种新的方法Asymmetric Policy Optimization（APO）来解决这些问题。APO方法将采样的响应分为正负样本组，对正样本引入了难度自适应发散塑型（DADS）来动态调整KL发散权重，防止策略熵急剧下降，提高训练稳定性，更好地利用样本，并保留模型已有知识；对负样本引入了次优轨迹复杂度正则化（STCR）来惩罚过于复杂的响应，从而减少过度推理，鼓励更简洁的推理，同时保留模型的探索能力。实验结果表明，与基线模型相比，View-R1-3B在推理能力上平均提高了7%，在各种推理基准上显著优于更大规模的MLLMs，并且在一般任务上的表现没有下降，展示了更强的一般化能力。这些结果突显了DADS和STCR技术在推进MLLMs复杂多模态推理方面的有效性和泛用性。", "innovation": "本研究提出了Asymmetric Policy Optimization (APO)方法，通过将采样的响应分为正负样本组，分别使用难度自适应发散塑型（DADS）和次优轨迹复杂度正则化（STCR）来解决现实应用中多模态大型语言模型（MLLMs）在强化学习（RL）训练中的挑战。这种方法能够防止策略熵急剧下降，提高训练稳定性，更好地利用样本，并保留模型已有知识，同时减少过度推理，鼓励更简洁的推理，保留模型的探索能力。实验结果表明，这种新的方法显著提升了多模态大型语言模型的推理能力，并展示了更强的一般化能力。", "conclusion": "本研究提出的方法，通过难度自适应发散塑型（DADS）和次优轨迹复杂度正则化（STCR）解决了多模态大型语言模型在强化学习训练中的过度推理问题，并提升了模型的推理能力和一般化能力。在Qwen2.5-VL-3B上应用研究提出的APO方法，创建了View-R1-3B，该模型在多种推理基准测试中显著优于基线模型和大型MLLMs，并且保持了一致的改进，展示了更强的一般化能力。这些结果表明，DADS和STCR技术在推进复杂多模态推理中具有广泛的应用价值。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22340", "html_url": "https://arxiv.org/abs/2506.22340", "title": "QuKAN: 量子电路生卒机方法在量子柯尔莫戈罗夫阿诺尔德网络中的应用", "title_en": "QuKAN: A Quantum Circuit Born Machine approach to Quantum Kolmogorov Arnold Networks", "authors": "Yannick Werner,Akash Malemath,Mengxi Liu,Vitor Fortes Rey,Nikolaos Palaiodimopoulos,Paul Lukowicz,Maximilian Kiefer-Emmanouilidis", "background": "Kolmogorov Arnold Networks (KANs) 基于柯尔莫戈罗夫阿诺尔德表示定理 (KAR)，能够用较少的神经元来表达复杂的函数。与传统的基于节点的参数的 Multi-Layer Perceptrons (MLPs) 不同，KANs 在边上使用可学习参数，从而提高了效率。然而，KANs 在量子机器学习中的潜力尚未得到充分探索。", "innovation": "本文提出了一种使用 Quantum Circuit Born Machine (QCBM) 实现 KAN 架构的方法，包括混合和完全量子形式。利用预训练的残差函数，KAN 能够将参数化量子电路的优势用于表达能力的适应。此外，混合模型结合了经典和量子组件，而完全量子版本则将整个残差函数架构转换为量子模型，展示了量子 KAN (QuKAN) 架构的可行性和性能。", "conclusion": "研究证明了 QuKAN 架构的可行性、可解释性和性能，为量子机器学习中的 KAN 应用开辟了途径。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22280", "html_url": "https://arxiv.org/abs/2506.22280", "title": "DIGS: 使用变形启发式四维高斯积点和低秩自由变形模型的动态CBCT重建", "title_en": "DIGS: Dynamic CBCT Reconstruction using Deformation-Informed 4D Gaussian Splatting and a Low-Rank Free-Form Deformation Model", "authors": "Yuliang Huang,Imraj Singh,Thomas Joyce,Kris Thielemans,Jamie R. McClelland", "background": "3D锥束CT（CBCT）在放疗中因其应用广泛而受到青睐，但由于呼吸导致的运动伪影而受到限制。传统临床方法通过对投影按呼吸相位进行排序并单独重建来减轻这种影响，但这不能考虑到呼吸的变量性。动态CBCT通过在每个投影上重建图像来捕捉连续运动，无需进行相位排序。4D高斯积点（4DGS）的最近进展为动态场景建模提供了强有力的工具，但将其应用于动态CBCT的应用尚处于初级阶段。尽管已有基于低秩运动模型的方法被提出，但它们缺乏空间正则化，导致高斯运动的一致性不足。现有方法，如HexPlane，使用隐式运动表示，计算成本高昂。为了解决上述问题，作者提出了一种基于自由变换（FFD）的空间基函数和一个变形启发式框架，通过在统一变形场下的高斯分布的均值位置、尺度和旋转的时序演化中引入一致性约束，来优化图像的一致性。该方法在六个CBCT数据集上进行了评估，显示与HexPlane相比有6倍的速度提升且图像质量更高。", "innovation": "本文引入了一种基于自由变形（FFD）的空间基函数，并提出了一种变形启发式框架，该框架通过在统一变形场下的高斯分布的时空演化中遵循一致性约束来解决现存模型的局限。该方法在效率和图像一致性方面取得了显著改进，特别是与HexPlane相比，效率提高6倍且图像质量更好。这是将变形启发式四维高斯积点应用到动态CBCT重建的一个创新性探索。", "conclusion": "该研究表明，变形启发式4D高斯积点方法对于实现高效且运动补偿的CBCT重建具有巨大潜力。该方法不仅能够实时处理6D自由度变形，而且能够有效地提高CBCT图像的质量。该方法的代码已经公开，可以进一步推动该领域的研究。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22041", "html_url": "https://arxiv.org/abs/2506.22041", "title": "通过多模态深度学习实现可扩展且鲁棒的白质病变定位", "title_en": "Towards Scalable and Robust White Matter Lesion Localization via Multimodal Deep Learning", "authors": "Julia Machnio,Sebastian Nørgaard Llambias,Mads Nielsen,Mostafa Mehdipour Ghazi", "background": "白质高信号（WMH）是微血管疾病和神经退化的小血管病的放射标志物，其精确分割和空间定位对于诊断和监控至关重要。尽管多模态MRI可以提供检测和上下文中的互补对比，但现有方法在处理缺失模态和有效集成解剖定位方面往往缺乏灵活性。本研究提出了一种基于单模态和多模态MRI输入直接在原空间操作的深度学习框架，旨在解决上述问题。实验结果显示，多模态输入比单一模态提高了分割性能，并且可以在模态缺失的情况下进行鲁棒推测。", "innovation": "提出了一种基于单模态和多模态MRI输入的解剖定位和白质病灶分割的深度学习框架；采用了多种输入配置进行实证研究；引入了多任务模型共同预测病灶和解剖区域掩码，以估计区域性的病灶负担；研究了多任务学习在联合病变-区域分割中的效果，发现相较于独立模型，多任务学习在联合分割上的效果较差。这一研究突显了多模态融合对于精准和鲁棒WMH分析的重要性，并表明联合建模有潜力进行整合预测。", "conclusion": "实验结果表明，多模态输入显著增强了分割性能，优于单一模态模型。而模态互换设置虽然牺牲了准确性，但增加了鲁棒性，在模态缺失情况下的推断中可以启用。多任务学习在病变-区域联合分割上的效果不如独立模型，表明两个任务之间存在表征冲突。该研究强调了多模态融合和联合建模对于改善WMH分析的实用性和鲁棒性的重要性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2110.12962", "html_url": "https://arxiv.org/abs/2110.12962", "title": "基于稳健模型拟合的事件数据关联方法在事件驱动目标跟踪中的应用", "title_en": "Event Data Association via Robust Model Fitting for Event-based Object Tracking", "authors": "Haosheng Chen,Yue Wu,Yidong Peng", "background": "基于生物启发的异步事件摄像机的方法已经在各种计算机视觉任务中取得了显著的性能。然而，关于基础事件数据关联问题的研究仍然处于起步阶段。因此，论文提出了一种新颖的事件数据关联（EDA）方法，明确地解决了事件关联和融合问题，该方法通过最佳拟合事件数据来执行统一的数据关联和信息融合。", "innovation": "论文提出了一种新颖的事件数据关联（EDA）方法：首先，基于信息熵异步融合事件数据；其次，提出了一种确定性模型假设生成策略，从融合事件中有效生成模型假设，代表对应的事件轨迹；然后，展示了一种两阶段加权算法，通过多结构几何模型拟合，稳健地从生成的模型假设中选择真实模型；同时，提出了一个自适应模型选择策略来自动确定真实模型的数量；最后，通过选择真实模型来关联和融合事件数据，从而不受传感器噪声和无关结构的影响。", "conclusion": "在对象跟踪任务上评估了所提出的EDA方法的性能。实验结果表明，在高速、运动模糊和高动态范围等具有挑战性的场景下，EDA方法具有有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2301.12276", "html_url": "https://arxiv.org/abs/2301.12276", "title": "ProtoSeg: 使用原型部分实现可解释语义分割", "title_en": "ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts", "authors": "Mikołaj Sacha,Dawid Rymarczyk,Łukasz Struski,Jacek Tabor,Bartosz Zieliński", "background": "当前的语义分割方法主要依赖于像素级别的分类，难以提供可解释性的预测结果。ProtoSeg通过引入基于训练集中相似斑块的预测机制，能够提高语义分割的准确性和透明度，尤其是在对比基准方法的表现方面。", "innovation": "ProtoSeg创新地使用了原型部分机制，并通过引入多样性损失函数增加每个类别的原型多样性，从而与传统的分割模型相比，能够发现并解释语义概念。这使其在Pascal VOC和Cityscapes数据集上的实验中显示出更高的精度和透明性", "conclusion": "ProtoSeg方法在保持与基准模型竞争力的同时，通过引入类似斑块机制和多样性损失函数实现了可解释的语义分割，其在Pascal VOC和Cityscapes数据集上的实验结果证实了该方法的精确性和透明性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22397", "html_url": "https://arxiv.org/abs/2506.22397", "title": "使用引导条件流匹配去雾显微镜图像：在保真度和现实性之间找到甜蜜点", "title_en": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism", "authors": "Anirban Ray,Ashesh,Florian Jug", "background": "荧光显微镜在生命科学中推动了科学进步。然而， cheaper 和更易获取的显微镜模式，如宽场显微镜，可能导致模糊图像数据。计算去雾技术试图结合这两者的优势，提供廉价的显微技术同时仍能产生清晰的图像。现有方法要么牺牲保真度以获得现实性，要么现实性足够但缺乏定量准确性。本文探讨了这些权衡，并提出了一种名为 HazeMatching 的新型迭代去雾方法，该方法有效地平衡了这些目标。我们通过引导生成过程，使用具有模糊观察的条件速度场来调整条件流匹配框架，从而实现这一平衡。该方法通过多项实验评估，在保真度和现实性之间取得了较为一致的平衡，并且预测合理准确，无需明确降级操作符的存在，使得该方法适用于真实显微镜数据。所有用于训练和评估的数据及其代码将公开发布。", "innovation": "提出了 HazeMatching，一种新的迭代方法，通过引导的条件流匹配框架，以代价拟合和现实性的权衡，成功地结合了保真度和现实性的平衡方法。此外，还展示了 HazeMatching 的预测是准确且适当的，无需显式的降级操作符，能够应用于实际的显微镜数据。", "conclusion": "通过 HazeMatching 方法，在 5 组数据集（包括合成和真实数据）上评估，结果表明在保真度和现实性之间取得了良好的平衡。此外，通过校准分析，HazeMatching 生成了准确且合理的预测，能够在真实显微镜数据上容易地应用。所有数据集和代码将公开提供。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22304", "html_url": "https://arxiv.org/abs/2506.22304", "title": "使用Koopman算子展开生成流：快速且可解释的采样", "title_en": "Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling", "authors": "Erkan Turan,Aristotelis Siozopoulos,Maks Ovsjanikov", "background": "CFM提供了一种无需模拟的持续时间生成模型训练框架，整合了扩散和基于流的方法。然而，从CFM中抽样仍然依赖于求解非线性常微分方程，这在计算上昂贵且难以解释。最近的替代方法通过轨迹直立化、小批量耦合或蒸馏来提高抽样速度，但这些方法通常未能揭示生成过程内部结构。针对这些问题，本文提出了加速CFM并引入Koopman算子理论，通过模型非线性流动为学习观测空间中的线性演进，构建了解码器自由的Koopman-CFM架构。这种方法使生成动力学在嵌入空间中线性化，从而通过矩阵指数化实现封闭形式、一步采样，显著减少了传统的CFM所需的时间，在控制的2D数据集和实际基准数据集MNIST、Fashion-MNIST (F-MNIST) 及 Toronto Face Dataset (TFD) 上都取得了成功。与此前方法不同，本方法的Koopman生成器具有良好的结构，其特征性质、特征值和特征函数为分析生成行为提供了理论工具，这些包括时间缩放、模式稳定性和Koopman潜空间中的分解。结合采样效率与分析结构，增强Koopman的流动匹配为快速且可解释的生成建模提供了一种潜在步骤。", "innovation": "提出了加速CFM并引入Koopman算子理论，构建了解码器自由的Koopman-CFM架构，使得生成过程线性化，通过矩阵指数化实现简便快速且可解释的采样。这种方法提供了一种理解生成行为的工具，并能够显著提升采样效率。", "conclusion": "Koopman增强的流动匹配方法通过结合采样效率与分析结构，为生成建模提供了一种快速且具备解释性的潜在解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2307.09727", "html_url": "https://arxiv.org/abs/2307.09727", "title": "SAMConvex: 快速CT配准的离散优化方法，利用自主监督解剖嵌入和相关金字塔", "title_en": "SAMConvex: Fast Discrete Optimization for CT Registration using Self-supervised Anatomical Embedding and Correlation Pyramid", "authors": "Zi Li,Lin Tian,Tony C. W. Mok,Xiaoyu Bai,Puyang Wang,Jia Ge,Jingren Zhou,Le Lu,Xianghua Ye,Ke Yan,Dakai Jin", "background": "通过在特征空间中计算成本体积估算位移矢量场在图像配准中表现出巨大成功，但它遭受了巨大的计算负担。现有特征描述子仅提取局部特征，无法表示全局语义信息，这对解决大规模变换尤其重要。", "innovation": "提出SAMConvex，一种用于CT配准的快速粗到细离散优化方法，结合自主监督解剖嵌入（SAM）特征提取器，该提取器能捕获局部和全局信息。具体而言，SAMConvex提取每体素特征并基于SAM特征构建6D相关体积，通过粗到细方案进行查找迭代更新位移场。此外，SAMConvex在两个跨患者注册数据集（腹部CT和头颈部CT）以及一个跨患者注册数据集（肺部CT）上均优于最先进的基于学习和优化的方法，并且作为一种优化方法，SAMConvex处理一对图像只需约2秒（包括实例优化时的约5秒）", "conclusion": "SAMConvex在CT配准任务中展示了优越的性能，并且计算效率高，能够有效地处理大规模的解剖变形问题。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22426", "html_url": "https://arxiv.org/abs/2506.22426", "title": "利用传统成像传感器快门功能和光学随机化实现单次曝光HDR", "title_en": "Single-shot HDR using conventional image sensor shutter functions and optical randomization", "authors": "Xiang Dai,Kyrollos Yanny,Kristina Monakhova,Nicholas Antipa", "background": "高动态范围(HDR)成像是克服图像传感器动态范围限制的基本技术。传统的多曝光方法虽然有效，但由于需要多次曝光，在拍摄快速变化场景时容易产生运动伪影。单次曝光HDR成像通过在一帧内编码HDR数据，然后通过计算恢复HDR，从而解决了这个问题。然而，许多现有的方法依赖于强先验知识来恢复曝光不足的细节，这在处理长时间曝光区域时表现不佳。本研究介绍了一种利用传统传感器全局重置释放（GRR）快门模式和光学随机化相结合的方法，以超越常规HDR技术的局限性。", "innovation": "本研究提出了一种创新的方法，利用GRR快门模式和光学随机化来实现单次曝光HDR。具体而言，研究者采用了一种光学装置，将随机排列的图像投射到传感器上，从而在整个场景中创建随机曝光。这种多样化的曝光模式使得通过一个简单的总变差图像先验来解决优化问题以恢复HDR成为可能，并且在模拟测试中表现优于其他单一曝光方法，尤其是在传感器像素饱和度较高的情况下。此外，该研究还构建了一个物理实验原型，使用现成的随机光纤束进行光学随机化，并结合低价格的商业传感器在GRR快门模式下运行。", "conclusion": "该原型通过具有48dB动态范围的8位传感器实现了高达73dB的动态范围，实验证明了方法的有效性。该研究为HDR成像的技术提升提供了新的思路。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.04997", "html_url": "https://arxiv.org/abs/2405.04997", "title": "在视觉显著性和图像质量评估之间的桥梁", "title_en": "Bridging the Gap Between Saliency Prediction and Image Quality Assessment", "authors": "Kirillov Alexey,Andrey Moskalenko,Dmitriy Vatolin", "background": "近年来，深度神经模型在图像质量评估(IQA)方面取得了显著的进步。但由于深度神经网络的复杂性，其成功的原因仍不清楚。IQA旨在描述人类视觉系统(HVS)的工作原理，并创建其有效的近似。另一方面，视觉显著性预测任务旨在通过确定视觉兴趣区域来模拟HVS。因此，我们认为视觉显著性在人类感知中扮演着关键角色。因此，这篇文章探讨了视觉显著性和图像质量评估之间的关系，并通过引入新型的SACID数据集展示了这种联系。", "innovation": "本文首次系统地探讨了视觉显著性预测和图像质量评估之间的关系，并通过引入新型数据集SACID，对比经典和基于神经网络的图像质量评估方法，揭示了视觉显著性对于图像质量评估的重要性。", "conclusion": "通过大量对比实验表明，图像质量评估方法实际上包含了视觉显著性的知识，并且视觉显著性在图像质量评估中起着重要作用。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.12988", "html_url": "https://arxiv.org/abs/2403.12988", "title": "提升目标检测鲁棒性：检测和恢复对抗性贴图攻击下的置信度", "title_en": "Enhancing Object Detection Robustness: Detecting and Restoring Confidence in the Presence of Adversarial Patch Attacks", "authors": "Roie Kazoom,Raz Birman,Ofer Hadar", "background": "计算机视觉系统的广泛应用凸显了它们对对抗性攻击的脆弱性，特别是在目标检测器上的对抗性贴图攻击。本文研究了针对YOLOv5模型的防御机制，以对抗这种攻击。通过优化生成对抗性贴图并将其放置在敏感图像区域，以探究检测和防御分析的不同阶段的效果。结果显示，对抗性贴图降低了平均检测置信度22.06%，而防御措施则不同程度地恢复了置信度，特别是在使用潜扩散模型时，置信度大幅提高，甚至超过了原始准确率，突显了潜扩散模型在减轻对抗性贴图影响方面的优越效果。", "innovation": "本文创新性地使用了优化的对抗性贴图和特定的防御机制（包括分段和完整防御、填充和潜扩散模型），通过EigenCAM和网格搜索技术确定了最佳遮挡位置，并提出了检测和分析的三个主要阶段。", "conclusion": "对抗性贴图极大地降低了目标检测的置信度，但通过应用多种防御方法，可以显著恢复甚至超过原始的准确率水平，突显了潜扩散模型在缓解对抗性贴图影响方面的强大能力。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.02583", "html_url": "https://arxiv.org/abs/2311.02583", "title": "FSDA-DG: 使用少量源域注解提高医学图像分割的跨域泛化能力", "title_en": "FSDA-DG: Improving Cross-Domain Generalizability of Medical Image Segmentation with Few Source Domain Annotations", "authors": "Zanting Ye,Ke Wang,Wenbing Lv,Qianjin Feng,Lijun Lu", "background": "基于深度学习的医学图像分割面临着因标记数据有限和领域偏移带来的显著挑战。尽管之前的方法主要独立解决这些问题，但这些挑战在医学成像中经常会同时发生。仅使用少量标注来推广到未见过的领域的方法具有重要的实用价值，因为它可以减少数据标注和开发成本。", "innovation": "我们提出了FSDA-DG，一种利用少量单源域注解提高医学图像分割跨域泛化能力的创新解决方案。FSDA-DG引入了语义指导下的半监督数据增强方法。这种方法将图像分为全局大区域和语义指导下的局部区域，并应用不同的增强策略以丰富数据分布。在该框架中，标记和未标记的数据都被转换为广泛领域的知识，同时保留域不变的语义信息。此外，FSDA-DG使用多解码器U-Net管道半监督学习网络，通过多次扰动中的一致先验假设来改进域不变的表示学习。", "conclusion": "FSDA-DG在两个具有有限注释的具有挑战性的单域泛化任务中，相对于最先进的方法实现了更优的性能。源代码已公开。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.19680", "html_url": "https://arxiv.org/abs/2406.19680", "title": "MimicMotion：采用意识姿势指导的高质量人类动作视频生成", "title_en": "MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance", "authors": "Yuang Zhang,Jiaxi Gu,Li-Wen Wang,Han Wang,Junqi Cheng,Yuefeng Zhu,Fangyuan Zou", "background": "近年来，生成型人工智能在图像生成领域取得了显著进展，催生了多种应用。然而，视频生成在可控性、视频长度和细节丰富度等方面仍然面临诸多挑战，这限制了这项技术的应用和普及。", "innovation": "本文提出了一种可控视频生成框架——MimicMotion，可以生成任意长度的模拟特定运动指导的高质量视频。其创新点包括：引入了基于姿势可信度的意识姿势指导，以确保高帧质量和时间连续性；引入区域损失放大技术，显著减少图像失真；提出了逐层潜空间融合策略，以生成长且平滑的视频，并在资源消耗可接受的情况下，生成任意长度的视频。", "conclusion": "通过广泛的实验和用户研究，MimicMotion在各个方面都显著提高了以往方法的效果。详细的实验结果和比较可以在项目页面查看：this https URL."}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.15011", "html_url": "https://arxiv.org/abs/2403.15011", "title": "生物需求驱动的细胞追踪——具有 aleatoric 不确定性的强分裂感知多假设追踪器", "title_en": "Cell Tracking according to Biological Needs -- Strong Mitosis-aware Multi-Hypothesis Tracker with Aleatoric Uncertainty", "authors": "Timo Kaiser,Maximilian Schier,Bodo Rosenhahn", "background": "细胞追踪和分割帮助生物学家从大规模共聚焦显微镜时序数据中提取有价值的生物信息。目前基于局部精度指标的追踪方法往往存在长期一致性不足和难以正确重建谱系树的问题。因此，本文研究了用于运动估计框架的不确定性评估技术，并扩展了多假设追踪框架，以解决上述问题。", "innovation": "本文引入了一种适用于运动估计框架的不确定性评估技术，通过特定问题的测试时增强手段将运动表示变为概率空间密度。此外，还提出了一种分裂感知分配问题公式，允许多假设追踪器模型细胞分裂并基于长期冲突解决错误关联和分裂检测。同时，将显式生物学知识建模在分配成本中，从而实现更准确的追踪结果。", "conclusion": "本文方法在九个具有竞争力的数据集上进行了评估，展示了在生物启发性指标上显著优于当前最先进的方法，且性能提升了约6倍，为移动估计不确定性提供了新的见解。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.12105", "html_url": "https://arxiv.org/abs/2405.12105", "title": "全页钢琴乐谱端到端光学音乐识别", "title_en": "End-to-End Full-Page Optical Music Recognition for Pianoform Sheet Music", "authors": "Antonio Ríos-Vila,Jorge Calvo-Zaragoza,David Rizo,Thierry Paquet", "background": "自光学音乐识别（OMR）诞生以来，尽管已取得了显著的进步，并且现有方法能够准确地将音乐谱转换为数字格式，但大多数所谓的端到端OMR方法仍然依赖多阶段处理管道来转录整个乐谱页面图像。这带来了诸如需要专用布局分析和特定标注数据等挑战，从而限制了这些方法的通用适用性。", "innovation": "本文提出了第一个针对复杂布局的页面级OMR的真正端到端方法，将卷积层与自回归Transformer结合使用，处理整个音乐谱页面并输出完整的乐谱转换结果。该方法通过架构和训练程序实现，利用通过增量合成数据生成的课程学习方式。与商业OMR软件进行了比较，展示了该系统不仅能够成功转录完整的乐谱页面，而且在零样本设置以及微调目标领域后，均优于商业工具，对OMR领域构成了重要贡献。", "conclusion": "实验结果表明，提出的系统不仅能够成功转录完整页面的音乐谱，而且还优于商业工具，在零样本设置和微调目标域后表现更好。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.06866", "html_url": "https://arxiv.org/abs/2410.06866", "title": "抵抗对抗攻击的稳健视频质量评估", "title_en": "Secure Video Quality Assessment Resisting Adversarial Attacks", "authors": "Ao-Xiang Zhang,Yuan-Gen Wang,Yu Ran,Weixuan Tang,Qingxiao Guan,Chunsheng Yang", "background": "视频流量的快速增长加大了视频质量评估（VQA）的需求。现有的VQA模型利用先进的架构已经达到了接近人类的准确性，但近期研究揭示了这些模型对对抗攻击的脆弱性。为了构建可靠和实用的评估系统，急需开发一种能够抵御此类恶意攻击的稳健性VQA模型。然而，目前还未有任何研究探索这一问题。", "innovation": "本文首次从安全角度探索了通用的对抗防御原则，旨在赋予现有VQA模型安全特性。具体而言，本文提出在视频帧内引入随机空间网格采样以增强防御，并通过守护映射进行像素级随机化，以全局消除对抗扰动。同时，提取视频序列的时间信息作为帧间防御的补充。最终，本文提出了一种从安全视角构建的新颖VQA框架——SecureVQA，并通过大量实验证明了SecureVQA在安全性方面取得了新标杆，同时在VQA性能上与最先进的模型持平。进一步的消融研究深入分析了SecureVQA原理，证明了其在领先VQA模型安全性上的应用价值和推广意义。", "conclusion": "SecureVQA在安全性方面设立了新的基准，同时保持了与最先进的VQA模型相当的性能。以此为基础，有助于进一步提升视频质量评估系统的可靠性与安全性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.09550", "html_url": "https://arxiv.org/abs/2407.09550", "title": "CAPM: 基于对偶网络在最大池化卷积神经网络上的快速且稳健验证", "title_en": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network", "authors": "Jia-Hau Bai,Chi-Ting Liu,Yu Wang,Fu-Chieh Chang,Pei-Yuan Wu", "background": "本文利用CAPM技术改进了具有最大池化结构的卷积神经网络在有界范数对抗扰动下的验证边界。现有的验证方法如DeepZ、DeepPoly和PRIMA计算成本较高，而最大池化函数的分解为一系列ReLU函数扩展了凸松弛技术的应用范围，通过构建对偶网络可以高效地计算验证边界。这种方法特别适用于大尺度的卷积神经网络，这些网络在以往的研究中被认为是计算上难以承受的。尽管目前的验证方法可以达到不错的精度和性能，但在计算效率上仍有一定的改进空间，对于某些特定网络结构，CAPM相对于PRIMA/DeepPoly/DeepZ在计算速度和验证边界上有了显著提升。", "innovation": "1. 将最大池化函数分解为一系列ReLU函数，并结合凸松弛技术，使得验证边界可以高效地计算。\n2. 通过构建对偶网络，CAPM能够有效减少计算成本，适用于大规模卷积神经网络。\n3. 在某些情况下，CAPM的验证边界精度明显高于现有的验证方法DeepZ、DeepPoly和PRIMA，计算速度也更快。\n4. 提出了该算法的时间复杂度为$O(W^2NK)$，其中$W$为神经网络的最大宽度，$N$为神经元数量，$K$为最大池化层的内核大小。", "conclusion": "CAPM方法在保持良好的验证精度的同时，显著降低了计算成本，特别适用于大规模的卷积神经网络。实验结果表明，该方法在计算速度和验证边界精度方面优于现有的几种验证方法。这对于保障深度学习模型的安全性和可靠性具有重要意义。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.06136", "html_url": "https://arxiv.org/abs/2407.06136", "title": "Mamba-FSCIL：通过选择性状态空间模型实现Few-shot类增量学习的动态适应", "title_en": "Mamba-FSCIL: Dynamic Adaptation with Selective State Space Model for Few-Shot Class-Incremental Learning", "authors": "Xiaojie Li,Yibo Yang,Jianlong Wu,Yue Yu,Ming-Hsuan Yang,Liqiang Nie,Min Zhang", "background": "Few-shot class-incremental learning (FSCIL)旨在通过有限的示例增量学习新的类别，同时保持之前学习类别的知识。现有的方法面临着静态架构和动态架构之间的关键困境：静态架构依赖于固定参数空间来处理按顺序到达的数据，容易导致对当前会话过拟合；而动态架构需要不断扩展参数空间，这会增加系统的复杂性。", "innovation": "本研究探索了选择性状态空间模型（SSM）在Few-shot class-incremental learning中的潜力。Mamba利用其输入依赖参数动态调整其处理模式，并产生内容感知扫描模式，同时保持固定架构。设计了两个关键模块：1）提出了一种双选择性SSM投影器，根据中间特征动态调整投影参数，实现动态适应。2）开发了一种类别敏感的选择性扫描机制，指导增量分支的动态适应。这些机制使Mamba-FSCIL能够在不干扰原有知识表示的同时，对新类别进行学习和适应。", "conclusion": "广泛的实验表明，Mamba-FSCIL在miniImageNet、CUB-200和CIFAR-100上实现了最先进的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.04778", "html_url": "https://arxiv.org/abs/2410.04778", "title": "MM-R$^3$: 关于视觉语言模型（VLMs）的一致性问题", "title_en": "MM-R$^3$: On (In-)Consistency of Vision-Language Models (VLMs)", "authors": "Shih-Han Chou,Shivam Chandhok,James J. Little,Leonid Sigal", "background": "随着大型语言模型（LLMs）及其变体的出现，对这类模型在各种任务中的表现进行了大量研究。大多数研究重点关注通过任务准确性（例如视觉问答、语义对齐等）来评估最先进的视觉语言模型（VLMs）的能力。然而，这项工作聚焦于与准确性相关的另一互补概念——一致性，即VLM能够对类似的查询产生语义上相似或相同响应的能力。研究指出，一致性是VLM鲁棒性和信任度的基础要求。这项工作基于这一视角，提出了MM-R3基准，通过该基准可以分析SoTA VLMs在三个任务上的表现：重新表述问题、图像风格迁移和情境推理。研究发现，一致性并不总与准确性相匹配，表明准确性高的模型不一定更一致，反之亦然。", "innovation": "本文提出了MM-R3基准，该基准允许分析SoTA VLMs在一致性与准确性方面在三个任务中的表现。此外，提出了一种简单的缓解策略，即适配器模块，用于最小化不同提示之间的一致性矛盾。表明在BLIP-2和LLaVa 1.5M等广泛使用的VLMs上，使用所提出的策略后，一致性方面的绝对改进平均达到了5.7%和12.5%。", "conclusion": "一致性与准确性不总是相匹配，表明用于提高准确性并不一定能让模型更一致，反之亦然。所提出的适配器模块能够显著增强模型的一致性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.05769", "html_url": "https://arxiv.org/abs/2405.05769", "title": "探索文本引导的单图遥感图像编辑", "title_en": "Exploring Text-Guided Single Image Editing for Remote Sensing Images", "authors": "Fangzhou Han,Lingyu Si,Zhizhuo Jiang,Hongwei Dong,Lamei Zhang,Yu Liu,Hao Chen,Bo Du", "background": "人工智能生成内容（AIGC）在遥感影像图像生成领域已经产生了显著影响。然而，在遥感图像（RSI）编辑领域，尽管同样重要，但尚未获得足够的重视。现有的基于深度学习的编辑方法通常分为两个阶段：生成阶段和this http URL自然图像。这两个阶段主要依赖于预训练在大规模基准数据集上的生成骨干网络以及由视觉语言模型（VLMs）提供的文本指导。然而，这些方法对于RSIs来说变得不太可行，因为现有的生成RSI基准数据集未能充分捕捉RSI的多样性，对于普遍的编辑任务往往是不足的。其次，单个文本语义可以对应多个图像语义，导致引入了错误的看法。为了解决上述问题，该研究提出了一种文本引导的RSI编辑方法，并可以仅使用单张图像进行训练。", "innovation": "该研究提出了一种基于文本引导的遥感图像编辑方法，可以单张图像进行训练，无需依赖大规模基准数据集，通过多尺度训练方法保持连贯性，同时利用预训练后的遥感图像视觉语言模型和提示集合（PE）来确保准确性和可控性。实验结果表明，该方法在CLIP分数和主观评价方面均优于现有方法，并探索了编辑后的遥感图像支持灾害评估任务的能力，以验证其实际应用价值。此外，研究提供了该方法的代码，以便进一步研究。", "conclusion": "该研究提出了一种新的方法，可以利用较少的数据进行单图遥感图像编辑，并通过多尺度训练、预训练的遥感图像视觉语言模型和提示集合确保方法的准确性和可控性。实验验证了该方法在实际应用中的优势，并提供了相应代码以供进一步使用和改进。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03177", "html_url": "https://arxiv.org/abs/2412.03177", "title": "PatchDPO：用于免调优个性化图像生成的像素级直接偏好优化", "title_en": "PatchDPO: Patch-level DPO for Finetuning-free Personalized Image Generation", "authors": "Qihan Huang,Weilong Dai,Jinlong Liu,Wanggui He,Hao Jiang,Mingli Song,Jie Song", "background": "免调优个性化图像生成能够生成定制化的图像，无需在测试阶段进行调优，由于其高效性而吸引了广泛的研究兴趣。当前的免调优方法通常采用单一的训练阶段和简单的图像重建任务，在测试阶段生成的图像质量较低，且与参考图像不一致。", "innovation": "本文借鉴了最近的DPO技术，提出了额外的训练阶段以改进预训练的个性化生成模型。为了解决DPO传统方法不能精确应用于个性化生成模型的问题，本文提出了PatchDPO，该方法通过估计每个生成图像中的图像块的质量来改进模型。PatchDPO首先使用预训练的视觉模型和提出的一种自我监督训练方法来估计图像块的质量，接下来采用加权训练方法，并基于估计的图像块质量训练模型，对高质量的图像块予以奖励并对低质量的图像块进行惩罚。实验结果表明，PatchDPO显著提高了多种预训练个性化生成模型的性能，并在单对象和多对象个性化图像生成上实现了最先进的性能。", "conclusion": "PatchDPO显著改善了多种预训练个性化生成模型的性能，展示了在单对象和多对象个性化图像生成上达到了最先进的水平。研究提供了代码，可查看详细实验结果。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.14384", "html_url": "https://arxiv.org/abs/2411.14384", "title": "将Gaussian Splatting融入扩散去噪器实现快速且可扩展的一阶段图像到3D生成与重建", "title_en": "Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation and Reconstruction", "authors": "Yuanhao Cai,He Zhang,Kai Zhang,Yixun Liang,Mengwei Ren,Fujun Luan,Qing Liu,Soo Ye Kim,Jianming Zhang,Zhifei Zhang,Yuqian Zhou,Yulun Zhang,Xiaokang Yang,Zhe Lin,Alan Yuille", "background": "现有的前馈图像到3D方法主要依赖于2D多视图扩散模型，这些模型无法保证3D一致性。这类方法在变换提示视图方向时容易坍塌，主要处理对象为中心的情况。", "innovation": "本文提出了一种新颖的一阶段3D扩散模型DiffusionGS，能够从单视图生成对象和场景重建。DiffusionGS可以直接在每个时间步输出3D高斯点云，从而确保视图一致性，并允许模型在任何方向的提示视图下生成稳健的结果，而不仅仅是处理对象中心的情况。此外，通过开发场景-对象混合训练策略，提升了DiffusionGS的能力和通用性。实验结果显示，与最先进的方法相比，DiffusionGS在对象上的PSNR/FID分别提升了2.20 dB/23.25，在场景上分别提升了1.34 dB/19.16，且无需深度估计器，同时速度提高了5倍以上（大约每迭代6秒在A100 GPU上运行）。", "conclusion": "DiffusionGS在从单视图生成对象和场景重建方面取得了重大进展，同时显著提高了速度和通用性。项目页面（this https URL）提供了视频和交互结果。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06153", "html_url": "https://arxiv.org/abs/2412.06153", "title": "一种用于视觉场所识别的超维单一场所签名：可堆叠描述符", "title_en": "A Hyperdimensional One Place Signature to Represent Them All: Stackable Descriptors For Visual Place Recognition", "authors": "Connor Malone,Somayeh Hussaini,Tobias Fischer,Michael Milford", "background": "视觉场所识别（VPR）通过将查询图像与包含地理标记图像的参考数据库进行比较来实现粗略定位。近期通过深度学习架构和训练策略的新突破使VPR方法在环境外观变化等因素下的鲁棒性有所提高，但随之而来的是所需的训练和/或匹配计算量会随着遇到的不同环境条件数量的增加而增加。", "innovation": "本文提出了超维单一场所签名（HOPS），通过融合在不同条件下捕捉的多个参考集的描述符来同时提高现有的VPR方法的性能、计算量和可扩展性。HOPS利用超维计算框架能够适应任意数量的环境条件。广泛的评估表明，该方法在各种VPR方法和数据集上表现出极高的普适性，能显著提高召回性能。非计算代价地任意融合参考图像还提供了其他一些有用的可能性，如描述符维度减少、堆叠合成图像和粗略定位到整个巡飞或环境段上等。", "conclusion": "我们的方法能够大幅度改进各种VPR方法并具有高度的通用性，在不同VPR方法和数据集上展现出显著的召回性能提升。任意融合参考图像而不增加计算代价的能力还能带来多个实际应用可能性，包括描述符维度减少、合成图像堆叠以及对整个巡飞或环境段进行粗略定位。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07381", "html_url": "https://arxiv.org/abs/2502.07381", "title": "压缩视频超分辨率的时空感知降级意识和一致扩散模型", "title_en": "Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution", "authors": "Hongyu An,Xinfeng Zhang,Shijie Zhao,Li Zhang,Ruiqin Xiong", "background": "由于存储和带宽限制，通过互联网传输的视频通常质量较低，表现为低分辨率和压缩伪影。尽管视频超分辨率（VSR）是一种有效的视频增强技术，现有的VSR方法较少关注压缩视频，导致直接应用通用的VSR方法无法提升具有压缩伪影的实际视频，尤其是在低码率下压缩程度较高的情况下。压缩视频中的不可避免的量化信息损失使纹理细节的重建复杂化。近年来，扩散模型在低级视觉任务中表现出优越的性能。利用扩散模型的高逼真生成能力，该文提出了一种新颖的方法，利用预训练扩散模型的先验知识进行压缩VSR。为了减弱空间失真并提高时间一致性，引入了时空感知降级意识和一致（SDATC）扩散模型。通过模态控制模块（DCM）调节扩散模型输入，减少低质量帧噪声对生成阶段的影响。随后，扩散模型在压缩意识提示模块（CAPM）和时空注意力模块（STAM）的引导下进行去噪过程，生成细节。", "innovation": "利用预训练的扩散模型先验知识进行压缩VSR；提出了时空感知降级意识和一致（SDATC）扩散模型；引入了模态控制模块（DCM）、压缩意识提示模块（CAPM）和时空注意力模块（STAM）；在每一步去噪过程中使用光流对齐以提高输出视频的平滑度。", "conclusion": "在基准数据集上的广泛实验结果表明，所提出的模块在恢复压缩视频方面的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08201", "html_url": "https://arxiv.org/abs/2503.08201", "title": "Scale-Aware Pre-Training for Human-Centric Visual Perception: Enabling Lightweight and Generalizable Models", "title_en": "Scale-Aware Pre-Training for Human-Centric Visual Perception: Enabling Lightweight and Generalizable Models", "authors": "Xuanhan Wang,Huimin Deng,Lianli Gao,Jingkuan Song", "background": "人类为中心的视觉感知（HVP）近年来由于大规模自我监督预训练（SSP）的进展取得了显著的进步。然而，现有的HVP模型在适应实际应用时存在局限性：它们难以应对需要通用视觉模式的下游任务，同时保持计算成本可持续，以确保与边缘设备的兼容性。这些局限性主要来源于两个问题：1) 预训练目标仅针对特定的视觉模式，限制了所学模式的泛化能力，使其适用于多种下游任务；2) HVP模型的通常模型规模过大，使其难以适应实际应用环境。", "innovation": "本文引入了Scale-Aware Image Pretraining (SAIP)，这是一种全新的自我监督预训练框架，旨在预训练轻量级视觉模型以获取适用于人类为中心的视觉感知的一般模式。SAIP通过跨尺度一致性引入三种学习目标：1) 跨尺度匹配（CSM），从多尺度单人图像中对比学习不变的图像级模式；2) 跨尺度重构（CSR），从多尺度掩蔽单人图像中学习像素级一致的视觉结构；3) 跨尺度搜索（CSS），从多尺度多人图像中学习捕捉多样模式的方法。这些目标相互补充，使轻量级模型能够学习对于HVP下游任务至关重要的多尺度可泛化模式。", "conclusion": "在12个人类为中心的视觉感知数据集上的实验表明，SAIP表现出强大的泛化能力，分别在9个人类感知任务中取得显著性能提升，特别是在单人识别、密集预测和多人视觉理解任务中分别提升了3%-13%、1%-11%和1%-6%。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.08377", "html_url": "https://arxiv.org/abs/2502.08377", "title": "视频动态-静态特征解耦：生成视频到4D模型", "title_en": "Not All Frame Features Are Equal: Video-to-4D Generation via Decoupling Dynamic-Static Features", "authors": "Liying Yang,Chen Liu,Zhenwei Zhu,Ajian Liu,Hui Ma,Jian Nong,Yanyan Liang", "background": "近年来，从视频生成动态3D对象的技术取得了令人印象深刻的成果。现有方法直接优化高斯分布，使用帧中的全部信息。然而，当动态区域与静态区域在帧中交织在一起，尤其是如果静态区域占很大比例时，现有方法往往忽视了动态区域的信息，并容易在静态区域上过拟合，导致生成模糊纹理的结果。因此，现有的方法存在提取动态信息不足的问题，尤其是在静态区域占比较大时。为解决此问题，我们认为解耦动态和静态特征可以增强动态表现，本文据此提出了一种动态-静态特征解耦模块（DSFD）", "innovation": "本文提出了一种名为动态-静态特征解耦模块（DSFD）的方法，通过解耦动态特征和静态特征，增强动态表现。沿时间轴，DSFD将当前帧特征中与参考帧特征存在显著差异的区域视为动态特征，其余部分视为静态特征。此外，为了从不同视角进一步增强解耦特征的动态表示，并确保准确的运动预测，本文设计了一种时空相似性融合模块（TSSF）。沿空间轴，TSSF自适应地选择动态区域的相似信息。在上述基础上，本文构建了一种名为DS4D（Dynamic-Static Feature Decoupling for Video-to-4D）的新方法。实验结果验证了本文方法在视频到4D生成任务中达到了最先进的性能", "conclusion": "本文方法在视频到4D生成任务上达到了最先进的性能，并且在真实场景数据集上的实验结果显示了其在4D场景中的有效性。本文代码将被公开"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.01164", "html_url": "https://arxiv.org/abs/2503.01164", "title": "Med-LEGO：针对通用医疗影像诊断编辑与调整", "title_en": "Med-LEGO: Editing and Adapting toward Generalist Medical Image Diagnosis", "authors": "Yitao Zhu,Yuan Yin,Jiaming Li,Mengjie Xu,Zihao Zhao,Honglin Xiong,Sheng Wang,Qian Wang", "background": "视觉基础模型在计算机辅助诊断（CAD）中的应用已成为一种常见做法。虽然这些基础模型为创建通用医疗AI提供了可行的解决方案，但由于隐私问题使得在多个领域和数据集上预训练或持续更新这类模型变得困难。因此，许多研究开始转向专门模型。", "innovation": "我们提出了Med-LEGO，这是一种无需训练的框架，通过组合多个专门模型，使其既能无缝集成到通用CAD模型中，又能进行更新操作，类似于拼装LEGO积木。Med-LEGO通过结合低秩适应（LoRA）和奇异值分解（SVD）提高了模型参数效率，同时不需要原始数据或重新训练即可增强特异性诊断能力。最终，结合的模型可以进一步适应新的诊断任务，使其成为一种具有广泛适用性的通用模型。Med-LEGO在跨域和同类任务中优于现有方法，仅使用了模型参数的0.18%。", "conclusion": "综合模型显示了更好的收敛性和在新任务上的泛化能力，为通用医疗AI的发展提供了有效路径。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16069", "html_url": "https://arxiv.org/abs/2503.16069", "title": "Disentangled and Interpretable Multimodal Attention Fusion for Cancer Survival Prediction", "title_en": "Disentangled and Interpretable Multimodal Attention Fusion for Cancer Survival Prediction", "authors": "Aniek Eijpe,Soufyan Lakbir,Melis Erdal Cesur,Sara P. Oliveira,Sanne Abeln,Wilson Silva", "background": "为了提高使用全切片图像和转录组学数据预测癌症存活率的能力，捕获模态共享和模态特定信息是至关重要的。然而，多模态框架往往会将这些表示融合在一起，限制了可解释性，并且可能掩盖了区分性特征。", "innovation": "提出了一种称为Disentangled and Interpretable Multimodal Attention Fusion (DIMAF) 的多模态框架，该框架在基于注意力的融合机制中分离了内部和跨模态的交互，以学习特定的和共享的模态表示。引入了基于距离相关性的损失来促进这些表示之间的分离，并结合Shapley添加性解释来评估它们对生存预测的相对贡献。在四个公开的癌症存活数据集上评估DIMAF，相比当前最先进的方法，DIMAF在性能上平均提高了1.85%，在分离性上提高了23.7%。除了提高性能外，可解释的框架还使得深入了解癌症生物学中模态间和模态内的内在交互关系成为可能。", "conclusion": "DIMAF框架在提高癌症存活预测的性能和可解释性方面取得了显著进展，为深入探索癌症生物学的内在交互关系提供了新的途径。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.17792", "html_url": "https://arxiv.org/abs/2409.17792", "title": "基于重新模糊的学习框架：具有错位训练对的一张模糊图像去模糊", "title_en": "Reblurring-Guided Single Image Defocus Deblurring: A Learning Framework with Misaligned Training Pairs", "authors": "Dongwei Ren,Xinya Shu,Yu Li,Xiaohe Wu,Jin Li,Wangmeng Zuo", "background": "单图像消模糊处理中，获取良好对齐的训练对（或训练三元组）即模糊模糊图像、全焦点清晰图像（及其模糊模糊图）是一项具有挑战性的任务。现有的图像消模糊方法通常依赖于由专门成像设备收集的数据，并假设这些对或三元组是完美对齐的。然而，在现实场景中收集真实数据时，直接获取训练三元组是不可行的，且训练对不可避免地会出现空间错位问题。", "innovation": "我们提出了一个基于重新模糊的单图像消模糊学习框架，可在错位训练对的情况下学习消模糊网络。通过重建空间变异性各向同性模糊核，我们的重新模糊模块确保了脱糊图像、重新模糊后的图像和输入模糊图像的空间一致性，从而解决了错位问题并有效地从全焦点清晰图像中提取锐利纹理。另外，通过重新模糊模块可以推导出空间变异性模糊，作为伪监督用于训练消模糊模糊图，将训练对转换为训练三元组。为了利用这种伪监督，我们提出了一种轻量级的消模糊模糊图估计器与融合块相结合的方法，该方法通过与最先进的消模糊网络无缝集成来增强消模糊性能。此外，我们还收集了一个带有典型错位的新单图像消模糊数据集，不仅验证了我们提出的的方法，也为未来的研究提供了基准。", "conclusion": "我们提出了一种基于重新模糊的学习框架，能够通过使用错位的训练对来训练消模糊网络，这可以通过重构空间变异性各向同性模糊核、推导出空间变异性模糊伪监督、以及提出轻量级的消模糊模糊图估计器与融合块相结合的方法来实现。我们的方法不仅有效解决了训练数据错位的问题，而且通过一个新的消模糊数据集验证和展示了该方法的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.04783", "html_url": "https://arxiv.org/abs/2412.04783", "title": "KNN-MMD：通过局部分布对齐进行跨域无线传感", "title_en": "KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment", "authors": "Zijian Zhao,Zhijie Cai,Tingwei Chen,Xiaoyang Li,Hang Li,Qimei Chen,Guangxu Zhu", "background": "无线传感在多种环境中得到了广泛应用，包括家庭、办公室和公共场所。通过分析信道状态信息（CSI）模式，可以对个人识别、手势识别和跌倒检测等任务进行推断。然而，CSI极易受到环境变化的影响，即使是微小的改动也可能会显著扭曲CSI模式。这种敏感性导致在一种环境中训练好的无线传感模型应用到另一种环境中时会出现性能下降甚至失败的情况。Domain Alignment（域对齐）方法广泛应用于跨域分类任务，该方法主要是在特征空间中对源域和目标域的全局分布进行对齐。尽管这种方法被广泛应用，但在实现全局对齐后，仍会忽略类别间的关联性，从而导致类别间的不匹配。", "innovation": "为了解决这一限制，提出了K-Nearest Neighbors Maximum Mean Discrepancy（KNN-MMD，K最近邻最大均值差异），这是一种针对跨域无线传感的新型少量样本方法。这种方法通过从目标域构建辅助集并利用KNN和MMD（最大均值差异）在每类内实现局部对齐。此外，该方法还解决了跨域方法中常见的模型性能在不同训练周期间剧烈波动的问题，并通过将支持集从目标域排除并将其用作验证集来确定最佳训练停止点，从而解决了现有方法在目标域缺乏标签数据时难以找到最优停止点的问题。", "conclusion": "KNN-MMD方法通过局部对齐解决了跨域无线传感中的类别间差异问题，并且能够在无需目标域标签数据的情况下有效确定最优训练停止点，从而提高了跨域应用中无线传感模型的性能稳定性。数据集和代码已公开发布，供研究者参考。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.04050", "html_url": "https://arxiv.org/abs/2502.04050", "title": "PartEdit: 使用预训练扩散模型实现精细图像编辑", "title_en": "PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models", "authors": "Aleksandar Cvejic,Abdelrahman Eldesokey,Peter Wonka", "background": "现有的基于扩散模型的图像编辑方法依赖于对图像语义的深刻理解，能够执行多种编辑操作。然而，这些模型对于很多对象部分的理解还不够充分，这阻碍了用户需要的细致入微的编辑请求。因此，需要一种方法来扩展这些预训练扩散模型的知识，使其能够更好地理解各种对象部分，从而实现精细的编辑.", "innovation": "该论文提出了第一种基于预训练扩散模型的文本驱动图像编辑方法，特别关注对象部分编辑。通过高效学习特定的文本标记来关联不同对象部分，并在每次推理时优化这些标记以生成可靠的定位掩模，从而使模型能够实现精细编辑。此外，该方法还设计了特征融合和自适应阈值策略来无缝执行编辑操作。通过建立基准和评价协议，论文证明了该方法在所有指标上都优于现有编辑方法，并在用户研究中获得了66-90%的意见偏好.", "conclusion": "实验结果表明，该方法在所有度量标准上均优于现有编辑方法，并且在进行的用户研究中，该方法有66-90%的用户偏好。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14949", "html_url": "https://arxiv.org/abs/2502.14949", "title": "KITAB-Bench: 阿拉伯OCR和文档理解的综合多域基准", "title_en": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding", "authors": "Ahmed Heakl,Abdullah Sohail,Mukul Ranjan,Rania Hossam,Ghazi Shazan Ahmad,Mohamed El-Geish,Omar Maher,Zhiqiang Shen,Fahad Khan,Salman Khan", "background": "随着文档处理中检索增强生成（RAG）的广泛应用，强大的文本识别变得越来越关键，以提取知识。OCR（光学字符识别）在英语和其他语言中得益于大数据集和成熟的基准测试，但在阿拉伯OCR方面却面临独特挑战，包括连笔书写、右到左的文本流以及复杂的排版和书法特征。本文介绍了KITAB-Bench，这是一个全面的阿拉伯OCR基准，填补了现有评估系统的空白。该基准涵盖了9个主要领域和36个子领域的8,809个样本，包括手写文本、结构化表格以及针对商业智能的21种图表的专门覆盖范围。研究表明，现代计算机视觉语言模型（如GPT-4o、Gemini和Qwen）在字符错误率（CER）方面比传统OCR方法（如EasyOCR、PaddleOCR和Surya）平均高出60%。进一步强调了当前阿拉伯OCR模型在PDF转Markdown转换中的显著限制，最佳模型Gemini-2.0-Flash仅达到65%的准确性。这突显出准确识别阿拉伯文文本的挑战，包括复杂字体、数字识别错误、单词拉长和表格结构检测等问题。", "innovation": "本文提出了KITAB-Bench，这是一个全面的多域阿拉伯OCR基准，填补了现有评估系统的空白。它包括8,809个样本，涵盖多样化的文档类型，并且专门针对商业智能提供了21种图表的覆盖范围。研究发现表明，现代视觉语言模型在字符错误率方面比传统OCR方法平均高出60%。此外，研究突出了当前阿拉伯OCR模型在PDF转Markdown转换中的显著限制，强调了准确识别阿拉伯文文本的挑战，包括复杂字体、数字识别错误、单词拉长和表格结构检测等问题。", "conclusion": "本文建立了一个严格的评估框架，可以推动阿拉伯文档分析方法的进步，并缩小与英语OCR技术之间的性能差距。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19367", "html_url": "https://arxiv.org/abs/2503.19367", "title": "VGAT：一种从生成视觉问答到基因组重建的癌症生存分析框架", "title_en": "VGAT: A Cancer Survival Analysis Framework Transitioning from Generative Visual Question Answering to Genomic Reconstruction", "authors": "Zizhi Chen,Minghao Han,Xukun Zhang,Shuwei Ma,Tao Liu,Xing Wei,Lihua Zhang", "background": "目前，结合病理图像和基因组序列的多模态学习可以提升癌症生存分析的效果，但受限于资源不足地区的基因组测序获取有限，临床实施变得困难。因此，仅使用组织切片图像（WSI）进行生存预测的需求日益增加。现有的WSI-only方法在这些资源有限的区域面临着挑战。", "innovation": "该研究提出了Visual-Genomic Answering-Guided Transformer (VGAT)框架，结合了视觉问答（VQA）技术重建基因组模态。通过适应VQA中的文本特征提取方法，VGAT能够稳定地构建基因组表示，绕过了原始基因组数据的维度问题。此外，VGAT还包含了一个基于聚类的视觉提示模块，该模块能够精炼增强具有区分性的WSI片段，从而解决了来自未过滤图像区域的噪声问题。通过在五个TCGA数据集中进行评估，VGAT表现出色，优于现有的WSI-only方法，验证了在无需测序的情况下进行基因组启发式推理的可能性。", "conclusion": "VGAT框架在资源有限的环境中，成功地将多模态研究与临床可行性结合，为癌症生存分析提供了一种新的方法，并为后续研究和实际应用奠定了基础。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.19634", "html_url": "https://arxiv.org/abs/2504.19634", "title": "NSegment: 专用于遥感图像分割的标签特定变形", "title_en": "NSegment : Label-specific Deformations for Remote Sensing Image Segmentation", "authors": "Yechan Kim,DongHo Yoon,SooYeon Kim,Moongu Jeon", "background": "遥感（RS）图像分割数据集中的标注错误往往由于模糊的类别边界、混合像素、阴影、复杂的地形特征以及标注人员的主观偏差而显得隐晦和微妙。由于获取高成本的图像和标注的难度，标注数据的稀缺性增加了训练抗噪声模型的复杂性。虽然使用复杂的机制如标签选择或噪声修正可以解决这一问题，但这些方法往往会增加训练时间并增加实现的复杂性。", "innovation": "该论文提出了一种名为NSegment的简单但有效的数据增强解决方案，用于减轻上述问题。该方法仅对分割标签应用弹性变形，在每个训练周期中对每个样本的变形强度进行变化，以解决注释的一致性问题。这种创新方法相比于传统方法具有更高的简便性和高效性。", "conclusion": "实验结果表明，我们的方法能够提高遥感图像分割模型的性能，适用于各种最先进的模型。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.20362", "html_url": "https://arxiv.org/abs/2503.20362", "title": "Self-ReS: 在大型视觉语言模型中实现长视频理解的自我反思", "title_en": "Self-ReS: Self-Reflection in Large Vision-Language Models for Long Video Understanding", "authors": "Joao Pereira,Vasco Lopes,David Semedo,Joao Neves", "background": "大型视觉语言模型（LVLMs）在短视频任务（如视频问答）中表现出色，但在长视频理解方面存在不足。传统的线性帧抽样策略无法充分捕捉视频数据中关键事件的非线性分布，导致在长视频中引入冗余或无关信息，而在短视频中可能遗漏关键事件。", "innovation": "为了解决这个问题，我们提出了SelfReS，这是一种非线性时空自我反馈抽样方法，能够根据用户的提示动态地选择关键视频片段。与之前的方法不同，SelfReS 利用LVLMs固有的稀疏注意力图来定义反馈令牌，从而实现基于相关性的令牌选择，而无需额外的训练或外部模块。实验表明，SelfReS 可以无缝集成到强大的基础LVLM中，提高长视频任务的准确性，并在相同的GPU内存预算下实现高达46%的推理速度提升。", "conclusion": "通过引入SelfReS，上述研究增强了大型视觉语言模型在长视频理解方面的性能，特别体现在提高任务准确性和提升推理速度方面。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.15465", "html_url": "https://arxiv.org/abs/2503.15465", "title": "FP4DiT：针对扩散变换器的高效浮点量化方法", "title_en": "FP4DiT: Towards Effective Floating Point Quantization for Diffusion Transformers", "authors": "Ruichen Chen,Keith G. Mills,Di Niu", "background": "扩散模型(DM)已经在文本到图像的生成过程中发挥了革命性的作用，然而，DMs的高计算成本和大模型体积阻碍了它们的实际部署，特别是在边缘设备上。尽管后训练量化(PTQ)是一种轻量级的方法，可以减轻这些负担，无需重新训练或微调，但现有的一些DM PTQ方法主要在基于整数（INT）的量化上，无法充分利用Transformers结构如DiT系列模型的潜力。这些模型在图像合成上表现更佳，但其权重和激活分布与INT量化并不匹配，而浮点量化(FPQ)方法的研究仍不足，它在低比特设置下有潜力更好地匹配权重和激活分布的分布，特别是在DiT模型中。", "innovation": "本文提出了FP4DiT，一种利用FPQ的PTQ方法，实现了W4A6量化。研究开发了一种改进的自适应量化技术，以准确量化FPQ的权重，并展示了DiT激活依赖于输入补丁数据的特性，需要一种稳健的在线激活量化方法。实验结果显示，在DiT模型上，FP4DiT在W4A6和W4A8精度下超越基于整数的PTQ方法，生成的内容具有较高的图像质量。", "conclusion": "研究表明，FP4DiT在多项T2I度量指标，如HPSv2和CLIP上表现优秀，能够产生高度可信的视觉内容，并且在多种DiT模型（包括PixArt-α、PixArt-Σ和Hunyuan）上同样有效。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2305.09305", "html_url": "https://arxiv.org/abs/2305.09305", "title": "通过输入梯度蒸馏在$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}} −范数对抗训练中释放不等现象", "title_en": "Releasing Inequality Phenomenon in $\\ell_{\\infty}$-norm Adversarial Training via Input Gradient Distillation", "authors": "Junxi Chen,Junhao Dong,Xiaohua Xie,Jianhuang Lai", "background": "对抗训练（AT）被认为是防御对抗攻击最有效的技术。然而，最近的一项研究发现，$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$-范数对抗训练（$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$-AT）会引发输入梯度分布不均的现象，称为不等现象。这种现象使得$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$-范数对抗训练模型在高属性或随机选择的像素受到扰动时变得比标准训练模型更容易遭受攻击，从而使$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$-范数对抗训练模型的防攻击能力减弱，从而更容易遭受稳健且实用的黑盒攻击。", "innovation": "我们提出了一个简单而有效的方法，称为输入梯度蒸馏（IGD），来缓解$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$-范数对抗训练中的不等现象。通过采用余弦相似度对齐输入梯度，IGD将标准训练的教师模型的均匀决策模式灌输给$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$-范数对抗训练的学生模型。实验结果显示IGD可以缓解不等现象及其威胁，同时保持对抗鲁棒性。与标准$\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$$\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textrq\textlq}}}\boldsymbol{\boldsymbol{\text{\textlq}}}_{\boldsymbol{\boldsymbol{\text{\textlq1\textlq}}}}\boldsymbol{\boldsymbol{\text{\textlq\textlq}}}$-AT相比，IGD分别在ImageNet-C中的归纳噪声、归纳遮挡、随机噪声和噪声图像上的错误率降低了最多60%、16%、50%和21%。除了实验验证，我们还进行了理论分析来解释释放不等现象如何提高这种鲁棒性，并讨论了不等现象的严重性如何根据数据集的图像分辨率而变化。", "conclusion": "我们的代码可以在这个网址获取。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17966", "html_url": "https://arxiv.org/abs/2503.17966", "title": "现实世界遥感图像去雾霾：基准与基线", "title_en": "Real-World Remote Sensing Image Dehazing: Benchmark and Baseline", "authors": "Zeng-Hui Zhu,Wei Lu,Si-Bao Chen,Chris H. Q. Ding,Jin Tang,Bin Luo", "background": "现实世界中的遥感图像去雾霾（RSID）面临着复杂的气象条件和严重的色彩失真，这些因素会降低图像质量。由于缺乏真实的现实生活中的遥感模糊图像对，现有方法主要依赖合成数据集，但这些方法在现实世界的应用中由于合成数据与真实数据之间的固有领域差距而效果不佳。", "innovation": "我们提出了Real-World Remote Sensing Hazy Image Dataset (RRSHID)，这是第一个包含跨多种气象条件的现实世界模糊和去雾霾图像对的大规模数据集。基于此，我们提出了MCAF-Net，一种专为现实世界RSID设计的新框架。该框架有三个创新组成部分：Multi-branch Feature Integration Block Aggregator (MFIBA)，Color-Calibrated Self-Supervised Attention Module (CSAM)，和Multi-Scale Feature Adaptive Fusion Module (MFAFM)，它们共同提高了去雾霾效果，特别是在真实世界中的表现，同时在合成数据集上也保持了竞争力。", "conclusion": "RRSHID和MCAF-Net的引入为现实世界RSID研究设立了新的基准，推动了这一复杂任务的实际解决方案的发展。所有代码和数据集都可以在该链接公开获取。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23341", "html_url": "https://arxiv.org/abs/2505.23341", "title": "DSAGL: 双流注意力引导学习在弱监督全切片图像分类中的应用", "title_en": "DSAGL: Dual-Stream Attention-Guided Learning for Weakly Supervised Whole Slide Image Classification", "authors": "Daoxi Cao,Hangbei Cheng,Yijin Li,Ruolin Zhou,Xuehan Zhang,Xinyi Li,Binwei Li,Xuancheng Gu,Jianan Zhang,Xueyu Liu,Yongfei Wu", "background": "全切片图像（WSIs）因其超高的分辨率和丰富的语义内容，在癌症诊断中至关重要。然而，由于其庞大的大小和精细标注的有限可用性，传统的监督学习面临重大挑战。", "innovation": "提出了一种新颖的弱监督分类框架DSAGL（Dual-Stream Attention-Guided Learning），结合了教师-学生架构和双流设计。DSAGL通过生成多尺度注意力伪标签并引导实例级学习，显式解决了实例级别的模糊性和包级别的语义一致性问题。共享的高效轻量级编码器（VSSMamba）和融合注意力模块（FASA）增强了对稀疏但诊断相关区域的关注。进一步引入混合损失以在两个流之间增强互斥一致性。", "conclusion": "在CIFAR-10、NCT-CRC和TCGA-Lung数据集上的实验表明，DSAGL在弱监督条件下始终优于最先进的米样基本模型，实现了更好的区分性能和鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02567", "html_url": "https://arxiv.org/abs/2505.02567", "title": "统一的多模态理解和生成模型：进展、挑战和机遇", "title_en": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "authors": "Xinjie Zhang,Jintao Guo,Shanshan Zhao,Minghao Fu,Lunhao Duan,Jiakui Hu,Yong Xien Chng,Guo-Hua Wang,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang", "background": "近年来，多模态理解模型和图像生成模型都取得了显著进展。尽管各自取得了成功，但这两个领域却独立发展，形成了不同的架构范式。自回归模型主导了多模态理解和扩散模型则在图像生成中占据核心地位。不过，近年来，统一这些任务的综合框架变得越来越受欢迎。此类工作包括了GPT-4o等新的能力，突显了统一的可能性。然而，两个领域之间的架构差异带来了重大挑战。本文旨在为这一新兴领域提供一个全面的概述，以指导未来的研究。首先，介绍了多模态理解和文本到图像生成模型的基本概念和最新进展。接着，综述了现有的统一模型，并将其分类为基于扩散、自回归和融合自回归与扩散机制的三大类架构。对于每一类，分析了相关工作的结构设计和创新。最后，汇编了适用于统一模型的数据集和基准，提供了未来探索的资源，同时讨论了这一领域面临的几个关键挑战。随着这一领域的快速发展，本文将定期更新。", "innovation": "1. 提出了一个全面的综述，旨在指导未来的研究方向。\n2. 综述了现有的统一模型，并将其分类为基于扩散、自回归和融合的三大类架构。\n3. 汇编了适用于统一模型的数据集和基准，提供了未来探索的资源。", "conclusion": "本文旨在展示统一多模态理解和图像生成模型的现状，同时突出了该领域面临的挑战和未来研究的机会。本文将定期更新，以激励进一步的研究，并为该领域的社区提供一个有价值的参考。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.08010", "html_url": "https://arxiv.org/abs/2506.08010", "title": "Vision Transformers Don't Need Trained Registers", "title_en": "Vision Transformers Don't Need Trained Registers", "authors": "Nick Jiang,Amil Dravid,Alexei Efros,Yossi Gandelsman", "background": "之前的研究发现，在视觉变换器（Vision Transformers）中出现了一种现象，即一些具有高范数的token形成了嘈杂的注意力图。这些现象在多个模型中出现，但现有解决方案需要重新训练模型，并使用额外的登记令牌。研究者旨在通过新的方法解决这些现象，从而避免重新训练模型的成本。", "innovation": "研究者提出了一种无需训练即可减少这些登记token现象的方法。通过将高范数激活从发现的登记神经元转移到一个未训练的附加token，可以模拟带登记token模型的效果。这种方法不仅生产了更干净的注意力和特征图，还提升了多个下游视觉任务的表现，并与显式训练了登记token的模型结果相当。此外，该方法还扩展到现有的视觉-语言模型中，以增强它们的可解释性。", "conclusion": "研究结果表明，测试时的登记token在测试时可以有效地扮演登记token的角色，为任何没有这些token的预训练模型提供了无训练解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23905", "html_url": "https://arxiv.org/abs/2503.23905", "title": "提升带有文本去偏提示的GRPO的MLLM推理能力", "title_en": "Boosting MLLM Reasoning with Text-Debiased Hint-GRPO", "authors": "Qihan Huang,Weilong Dai,Jinlong Liu,Wanggui He,Hao Jiang,Mingli Song,Jingyuan Chen,Chang Yao,Jie Song", "background": "MLLM推理因其出色的解决问题能力而受到广泛研究。目前的推理方法主要分为两类：监督中间推理步骤的PRM和监督最终结果的ORM。最近，DeepSeek-R1挑战了传统的看法，即PRM优于ORM，通过使用ORM方法（即GRPO）展示了强大的泛化性能。然而，当前的MLLM的GRPO算法在处理复杂的多模态推理任务（如数学推理）时仍然存在问题。主要问题包括低数据利用和文本偏见，这些问题限制了GRPO在MLLM中的性能提升。", "innovation": "本文提出了Hint-GRPO，通过为不同难度的样本提供自适应的提示以提高数据利用，解决了低数据利用和文本偏见问题。Hint-GRPO通过在测试阶段校准token预测logits与图像条件来减轻文本偏见。实验结果表明，所提出的方法大大提升了原始MLLM的推理能力，并在现有MLLM推理方法中表现更优。", "conclusion": "在三个基础MLLM模型和11个数据集上的实验结果显示，所提出的方法显著提升了MLLM的推理能力，显示出比现有MLLM推理方法更好的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05023", "html_url": "https://arxiv.org/abs/2505.05023", "title": "在归纳零样本语义分割中的拆分匹配", "title_en": "Split Matching for Inductive Zero-shot Semantic Segmentation", "authors": "Jialei Chen,Xu Zheng,Dongyue Li,Chong Yi,Seigo Ito,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi", "background": "零样本语义分割（ZSS）旨在分割在训练过程中未标注的类别。尽管微调视觉-语言模型取得了令人鼓舞的结果，但由于缺乏对未见类别的监督，这些模型往往会过拟合到已见过的类别。与全监督方法不同，基于查询的分割已经显示出在ZSS中的潜力，因为它能够在无需使用显式标签的情况下进行对象局部化。然而，传统匈牙利匹配作为基于查询框架的核心组成部分，需要全监督，在ZSS设置中经常会将未见类别误分类为背景。为了解决这一问题，作者提出了拆分匹配（SM）这一新颖的分配策略，将匈牙利匹配分解为两个部分：一部分用于有标注区域内的已见类别，另一部分用于无标注区域内的隐藏类别（称为未见候选类别）。", "innovation": "提出了拆分匹配（SM），这是一种新颖的分配策略，将匈牙利匹配拆分为已见类别和未见候选类别两个部分，每个部分都可以根据其可用的监督信息独立优化。通过将查询分割成已见和候选类组，SM能够在未见类别上进行独立的优化。此外，还引入了多尺度特征增强（MFE）模块，能够细化解码器特征，提高模型在不同分辨率下捕捉空间细节的能力。SM是首次在归纳ZSS设置中引入解耦匈牙利匹配的方法，并且在两个标准基准上实现了最先进的性能。", "conclusion": "SM通过将匈牙利匹配拆分为已见类别和未见候选类别两个部分，并采用多尺度特征增强（MFE）模块改进了解码器特征，从而实现了在零样本语义分割中的先进性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.17944", "html_url": "https://arxiv.org/abs/2506.17944", "title": "SegChange-R1：LLM增强的遥感变化检测", "title_en": "SegChange-R1: LLM-Augmented Remote Sensing Change Detection", "authors": "Fei Zhou", "background": "遥感变化检测被用于城市规划、地形分析和环境监测等领域，通过分析相同区域内随时间变化的特征。本文提出了一种大型语言模型（LLM）增强推理方法（SegChange-R1），该方法通过整合文本描述信息来增强变化检测能力，并引导模型关注相关变化区域，加快了收敛速度。", "innovation": "提出了一种大型语言模型（LLM）增强推理方法（SegChange-R1），通过文本描述信息的整合增强了变化检测能力，并引入了一个名为DVCD的新数据集，用于从无人机视角进行建筑变化检测。设计了一个基于线性注意力的空间变换模块（BEV），解决了不同时间特征模态不匹配的问题，通过将不同时间的特征统一到BEV空间中来统一处理特征。实验在四个广泛使用的数据集上展示了相对于现有方法的显著改进。", "conclusion": "通过SegChange-R1方法，在城市规划、地形分析和环境监测的背景下，实现了显著的变化检测性能提升，并展示了在四个数据集上的卓越结果。该研究的代码和预训练模型可以在{this https URL}获取。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18071", "html_url": "https://arxiv.org/abs/2506.18071", "title": "MUPA: 朝向多路径代理推理的接地视频问答", "title_en": "MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering", "authors": "Jisheng Dang,Huilin Song,Junbin Xiao,Bimei Wang,Han Peng,Haoxuan Li,Xun Yang,Meng Wang,Tat-Seng Chua", "background": "接地视频问答（Grounded VideoQA）需要将文本回答与明确的视觉证据进行对齐。然而，现代多模态模型往往依赖于语言先验和偶然相关性，导致预测缺乏定位性。这是一种要求模型不仅理解问题，还要准确地将答案与视频中的视觉证据匹配起来的任务。现代方法往往忽视了这种匹配的重要性，过于强调语言理解，常常导致不准确的定位结果。", "innovation": "本文提出了MUPA，一种合作式多路径代理方法，统一了视频定位、问答、答案反思和聚合，以解决接地视频问答问题。MUPA 设计了三种不同的推理路径，涉及在不同时间顺序下的定位与问答代理间的互动，并配备了一个专用的反思代理，以评估和聚合多路径结果，实现一致的问答与定位。这种设计显著提高了定位的准确性，同时未牺牲答案的准确性。即使参数量只有2B，该方法仍超越了所有的7B规模的竞争者。当扩展到7B参数时，MUPA 打破了当前的最先进结果，展现了MUPA在可信赖的视频-语言理解方面的有效性。", "conclusion": "该研究通过多路径代理推理方法，显著提升了接地视频问答的准确性和可信度，同时保持了参数效率，展现了该方法在大规模参数下的潜力和实用性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.14473", "html_url": "https://arxiv.org/abs/2506.14473", "title": "基础模型启示与多模型方法在细粒度一-shot 子集选择中的优势", "title_en": "Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection", "authors": "Zhijing Wan,Zhixiang Wang,Zheng Wang,Xin Xu,Shin'ichi Satoh", "background": "一-shot 子集选择是一种有效减少深度学习训练成本的工具，通过信息提取器（IE）提取信息来识别具有信息量的数据子集。传统的 IE 通常在目标数据集上预训练，具有数据集依赖性。基础模型（FMs）提供了一种有希望的替代方法，可能缓解这一限制。现有研究主要集中在传统 IE 上，缺乏对 FMs 在子集选择中的性能评估和比较研究。", "innovation": "研究提出了两个关键问题：1. 基于 FM 的子集选择能否在多种数据集上优于传统的 IE 方法？2. 所有 FMs 在子集选择中作为 IE 的表现是否都一样？实验揭示，FMs 在细粒度数据集上表现优于传统 IE，但在粗粒度数据集上效果较差。基于此观察，提出 RAM-APL 方法，利用多 FM 来增强子集选择，利用 FM 之间的互补优势。", "conclusion": "RAM-APL 方法在多个细粒度图像数据集（如 Oxford-IIIT Pet、Food-101 和 Caltech-UCSD Birds-200-2011）上实现了最先进的性能。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.24007", "html_url": "https://arxiv.org/abs/2505.24007", "title": "先发制人的幻觉减少：针对多模态语言模型的输入层面方法", "title_en": "Preemptive Hallucination Reduction: An Input-Level Approach for Multimodal Language Model", "authors": "Nokimul Hasan Arif,Shadman Rabby,Md Hefzul Hossain Papon,Sabbir Ahmed", "background": "大型语言模型（LLMs）在生成响应时可能出现视觉幻觉，即生成的内容与输入视觉信息不符，这对它们的可靠性构成了重大挑战，尤其是在需要精确和可信输出的情境中。目前的研究主要集中在后验纠正或模型特定的微调策略上，对于输入阶段的问题预处理技术探索较少。本书将介绍一种新颖的基于集成的预处理框架，该框架根据提出的问题类型选择最合适的过滤方法，如噪声降低（NR）、边缘增强（EE）或未改动输入（org），从而减少幻觉，无需修改底层模型架构或训练管道。这一方法在旨在测试复杂视觉输入上多模态推理的`HaloQuest'数据集上进行评估，结果显示通过自然语言推理（NLI）分数衡量的幻觉率降低了44.3%。这表明智能输入预处理可以在很大程度上增强LLMs响应的真实性。这些发现强调了适应性预处理技术在缓解幻觉方面的关键作用，为开发更可靠、能应对现实世界挑战的多模态系统铺平了道路。", "innovation": "本书提出了一种新颖的基于集成的预处理框架，可以根据问题类型动态选择最合适的噪声降低、边缘增强或未改动输入的处理方法，以减少视觉幻觉，这种预处理方法无需修改模型结构或训练流程。该方法在HaloQuest数据集上表现出显著的效果，相较于现有的后验纠正或模型特定微调策略，有效降低了44.3%的幻觉率，通过NLI评估，显示出良好的验证结果。这证明了智能输入预处理的重要性，能够显著提高多模态语言模型响应的真实性。", "conclusion": "本书的方法表明，智能的输入预处理技术对于减少视觉幻觉和提升多模态语言模型的可靠性至关重要。该方法为开发更可靠、能解决真实世界挑战的多模态系统提供了新的思路和技术支持。未来的研究可以进一步探索更多的预处理策略及其组合，以优化模型性能和增强其适应性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.20741", "html_url": "https://arxiv.org/abs/2506.20741", "title": "OTSurv: 基于异质最优传输的新型生存预测多重实例学习框架", "title_en": "OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport", "authors": "Qin Ren,Yifan Wang,Ruogu Fang,Haibin Ling,Chenyu You", "background": "现有的生存预测方法使用组织切片图像（WSIs）进行建模时，通常无法有效捕捉WSIs中的病理异质性，无论是全局层面的长尾形态学分布，还是局部层面的瓷砖级预测不确定性。", "innovation": "OTSurv是从最优传输角度提出的一种新型的多个实例学习框架。它通过两个约束条件来建模生存预测：1) 全局长尾约束，用于建模形态学分布以避免模型崩溃和过度统一；2) 局部不确定性感知约束，通过逐步提高总传输质量来优先处理高置信度的瓷砖并抑制噪声。进一步地，它将初始的最优传输问题重新表述为不平衡的最优传输问题，可以使用高效的硬件友好型矩阵缩放算法来求解。实验证明，OTSurv在六个流行的基准测试中达到了新的最佳效果，绝对提升了平均C指数3.6%，并在log-rank检验中显示出统计学显著性，且具有高度的可解释性。", "conclusion": "OTSurv作为一种强大的工具，提高了数字病理学领域的生存预测性能，并提供了高可解释性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.20967", "html_url": "https://arxiv.org/abs/2506.20967", "title": "DFVEdit：针对Video DiTs的条件Delta流向量零样本视频编辑", "title_en": "DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing", "authors": "Lingling Cai,Kang Zhao,Hangjie Yuan,Xiang Wang,Yingya Zhang,Kejie Huang", "background": "Video Diffusion Transformers (Video DiTs) 的出现标志着视频生成的一个重要里程碑。然而，直接将现有的视频编辑方法应用于Video DiTs通常会带来显著的计算开销，原因是在修改注意力机制或进行微调时消耗资源较多。因此，为了解决这个问题，作者提出了一种高效的零样本视频编辑方法DFVEdit，该方法专门为Video DiTs设计。DFVEdit通过直接在清理的潜在变量上操作，并利用流变换，消除了对注意力修改和微调的需求。作者观察到编辑与采样可以在连续流的视角下统一起来，基于此基础，提出现有条件Delta流向量（CDFV）—这一DFV的无偏估计，并集成了隐式交叉注意力（ICA）指导和嵌入强化（ER）以进一步提高编辑质量。", "innovation": "DFVEdit通过直接在清理的潜在变量上操作，利用流变换，消除了对注意力修改和微调的需求，并提出了一种称为Conditioned Delta Flow Vector（CDFV）的理论无偏估计，同时还集成了隐式交叉注意力指导和嵌入强化，从而提供了显著的推理速度提升和内存减少。相比基于注意力工程的编辑方法，DFVEdit在Video DiTs上的推理速度至少提高20倍，内存减少85%。定量和定性实验表明，DFVEdit可以无缝应用于流行的Video DiTs（如CogVideoX和Wan2.1），在结构保真度、空间-时间一致性和编辑质量方面实现了最先进的性能。", "conclusion": "DFVEdit作为一种有效的零样本视频编辑方法，可以无缝应用于多种Video DiTs，实现了结构保真度、空间-时间一致性和编辑质量方面的卓越性能，在Inference速度和内存使用方面也有显著改进。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.20995", "html_url": "https://arxiv.org/abs/2506.20995", "title": "通过负音频指导实现逐步视频到音频合成", "title_en": "Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance", "authors": "Akio Hayakawa,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji", "background": "传统音效制作流程（Foley workflow）旨在模拟视频中的各种声响事件。现有方法通常一次性生成所有音频轨道，缺乏灵活性和针对性，无法逐步处理特定事件。本文基于先前的组合生成框架中的概念否定理念，提出了一种逐步的视频到音频生成方法，每一步生成特定声学事件的独立音频轨道。这种方法能够更加细致地捕捉视频中的各种声学事件，并且可以通过条件指导细化生成过程，特别适用于需要精确控制音频细节的场景。", "innovation": "本文方法的独特之处在于它通过逐步生成特定声学事件的音频轨道，模仿传统音效制作流程。每一步生成任务都基于目标文本提示和先前生成的音频轨道，这种设计借鉴了先前组合生成框架中的概念否定理念。相比以往方法，该方法不仅提高了音频合成的质量，还能够生成多样性高的音频轨道，适用于需要精确控制音频细节的场景。此外，该方法还引入了不需要专门配对数据集的训练框架，利用预训练的视频到音频模型实现了高效的训练过程，提高了方法的实用性和适应性。", "conclusion": "实验结果表明，本文方法能够为单个输入视频生成多个语义上不同的音频轨道，合成音频质量高于现有基线方法，充分展示了方法的有效性和实用性，为音视频生成领域提供了新的解决方案和参考。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.20936", "html_url": "https://arxiv.org/abs/2506.20936", "title": "PhysRig: 基于物理的可微建模和骨架绑定框架以实现逼真的人形模型", "title_en": "PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling", "authors": "Hao Zhang,Haolan Xu,Chun Feng,Varun Jampani,Narendra Ahuja", "background": "皮肤绑定和骨架绑定是动画、有四肢的物体重建、动作转移和四维数据生成中的基本组成部分。现有方法主要依赖线性混合皮肤(LBS)技术，因为其简单性和可微性。但是，LBS会产生诸如体积损失和不自然形变等缺点，无法很好地模拟诸如软组织、毛皮和柔性附肢（例如大象的鼻子、耳朵和脂肪组织）等弹性材料的变形。因此，本研究旨在克服这些缺陷，提出了一种基于物理的可微建模和骨架绑定框架(PhysRig)。该框架将刚性骨架嵌入到体素表示（例如四面体网格）中，通过反向模拟的可变形柔体结构受动画骨架驱动，以此来改善现有方法在处理弹性材料方面的不足。", "innovation": "本方法通过引入连续力学理论将物体离散化为嵌入在欧拉背景网格中的粒子，确保了不同材料属性和骨架运动间的可微性。同时，引入了材料原型大大减少了学习空间，却依然保持了高表达性。通过使用Objaverse、The Amazing Animals Zoo和MixaMo中的网格来构建了一个综合的合成数据集，结果表明该方法在生成更真实、物理合理的结果方面超越了使用LBS的方法，并且可以实现姿态转移，展示了其在人形模型建模中的通用性。", "conclusion": "研究提出了一种名为PhysRig的新框架，该框架解决了传统线性混合皮肤方法的缺点，通过基于物理的方法有效地解决了弹性材料的绑定问题，并且在生成逼真的人形模型方面具有广泛应用潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21008", "html_url": "https://arxiv.org/abs/2506.21008", "title": "多条件训练无监督扩散生成的衰老多元宇宙", "title_en": "The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion", "authors": "Bang Gong,Luchao Qi,Jiaye Wu,Zhicheng Fu,Chunbo Song,David W. Jacobs,John Nicholson,Roni Sengupta", "background": "该论文介绍了一种新的框架——衰老多元宇宙，可以从单张面部照片生成多条可能的老化轨迹，每条轨迹可以根据外部因素（如环境、健康和生活方式）进行条件控制。不同于以前将老化建模为单一确定路径的方法，新方法创建了一棵老化树来展示不同的未来。", "innovation": "论文提出了一种训练无需求的方法，通过注意力混合调节编辑强度，并采用模拟衰老正则化策略来稳定编辑，实现身份保持、年龄准确性和条件控制的平衡。该方法能够生成更加多样且可控的老化效果，成果在多个实验和用户研究中表现优异，超越了现有的编辑和年龄 progression 模型，特别是在身份保持、老化现实和条件对齐方面有所突破。", "conclusion": "通过将老化过程转化为多维度、可控和可解释的过程，该研究为数字叙事、健康教育和个人化可视化等领域打开了新的创造性和可操作的途径。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21034", "html_url": "https://arxiv.org/abs/2506.21034", "title": "DidSee: 材料无关的机器人感知与操作中基于扩散的方法对深度完成的实现", "title_en": "DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation", "authors": "Wenzhou Lyu,Jialing Lin,Wenqi Ren,Ruihao Xia,Feng Qian,Yang Tang", "background": "商业RGB-D相机常为非朗伯物体生成噪声大、不完整且不连续的深度图。传统的深度完成方法由于训练数据量少且多样性不足难以泛化。最近的研究利用预训练的文本到图像扩散模型的视觉先验，在密集预测任务中提升泛化能力。然而，泛化扩散框架中的训练-推理偏差引入的偏差显著影响深度完成效果，非朗伯区域缺乏明显的视觉特征进一步影响预测精度。现有方法未能有效解决这些挑战。为此，本研究提出DidSee，一种基于扩散的方法用于非朗伯物体的深度完成。", "innovation": "DidSee 引入了一种新的扩散框架，首先通过调整噪声调度器消除信号泄漏偏差，其次设计了一步训练形式缓解曝光偏差引起错误累积并使用任务特异性损失优化模型，最后通过语义增强器实现深度完成与语义分割的联合，提升物体与背景区分，得到精准精细的深度图。DidSee 在多个基准测试中表现卓越，具备强大的实际泛化能力和促进类别级姿态估计和机器人抓取等下游任务的效果提升。", "conclusion": "DidSee 使用扩散模型在非朗伯物体的深度完成上获得最佳性能，在不同基准上展示线性泛化并有效提升下游任务如类别级姿态估计和机器人抓取。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.20616", "html_url": "https://arxiv.org/abs/2506.20616", "title": "Shape2Animal: Creative Animal Generation from Natural Silhouettes", "title_en": "Shape2Animal: Creative Animal Generation from Natural Silhouettes", "authors": "Quoc-Duy Tran,Anh-Tuan Vo,Dinh-Khoi Vo,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le", "background": "人类能够识别模糊刺激中的有意义模式，这种认知现象被称为似是而非现象。本文通过重新解读自然界对象轮廓（如云、石头或火焰）为可能的动物形状，介绍了一种名为Shape2Animal的框架，以模拟这种想象能力。该框架首先通过开放词汇分割提取对象轮廓，然后使用视觉语言模型解释合适的动物概念，接着利用文本到图像的扩散模型生成与输入形状相符合的动物图像，并将其无缝融入原始场景，从而生成视觉连贯且空间一致的组合效果。", "innovation": "本文的创新之处在于提出了Shape2Animal框架，该框架通过视觉语言模型实现对自然对象轮廓（如云、石头或火焰）的重新诠释，将其转化为可能的动物形状，并结合文本到图像的扩散模型，自动生成与输入形状相协调的动物图像，为视觉故事叙述、教育内容、数字艺术和互动媒体设计提供了新的可能性。", "conclusion": "通过在多元化的真实世界输入上的评价，展示了Shape2Animal的鲁棒性和创意潜力，该框架能够为视觉叙事、教育资源、数字艺术及交互媒体设计等领域带来新的机遇。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21356", "html_url": "https://arxiv.org/abs/2506.21356", "title": "ShotBench：Vision-Language模型中的专家级电影理解", "title_en": "ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models", "authors": "Hongbo Liu,Jingwen He,Yi Jin,Dian Zheng,Yuhao Dong,Fan Zhang,Ziqi Huang,Yinan He,Yangguang Li,Weichao Chen,Yu Qiao,Wanli Ouyang,Shengjie Zhao,Ziwei Liu", "background": "电影摄制组是电影基本视效语言，对于传达叙事、情感和美学质量至关重要。尽管近期的Vision-Language模型展示了强大的通用视觉理解能力，但它们在理解和解析单个镜头中嵌入的细腻电影语法规则方面的能力仍处于初级阶段。这一领域的知识差距限制了AI辅助视频生成的精确性。此外，缺乏有效的评估手段使得目前很难全面考察模型在这方面的表现。因此，需要建立一个全面的基准来评估Vision-Language模型在理解电影语法规则方面的表现。", "innovation": "本文提出了ShotBench，这是首个专门用于电影语言理解的综合基准，它包含了来自200多部获奖（主要是奥斯卡提名）电影的3500多个由专家注解的问答对，涵盖八类关键的电影摄制维度。此外，作者通过采用生成ShotQA数据集和基于监督微调及组相对策略优化的方法，搭建了ShotVL模型，大大提高了对电影场景的理解和生成。ShotVL在ShotBench的表现证明了它在这一领域的先进技术差距。", "conclusion": "最终，本研究不仅通过ShotBench提供了一个新的基准来评估现有多模型的性能，而且构建了ShotQA数据集以及通过监督微调和组相对策略优化的ShotVL，显著提升了视觉-语言模型在电影理解方面的能力。作者开放了模型、数据和代码，希望促进该研究领域的快速进步。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.19723", "html_url": "https://arxiv.org/abs/2412.19723", "title": "OS-Genesis: 通过对任务合成的逆向操作实现GUI代理轨迹构建自动化", "title_en": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis", "authors": "Qiushi Sun,Kanzhi Cheng,Zichen Ding,Chuanyang Jin,Yian Wang,Fangzhi Xu,Zhenyu Wu,Chengyou Jia,Liheng Chen,Zhoumianze Liu,Ben Kao,Guohao Li,Junxian He,Yu Qiao,Zhiyong Wu", "background": "基于视觉-语言模型（VLMs）的图形用户界面（GUI）代理已展示出接近人类的计算机控制能力。尽管这些代理在推进数字自动化方面具有实用性，但训练所需高质量轨迹数据的收集仍然是一个关键瓶颈。现有的数据收集方法要么依赖人力监督，要么通过执行预定义任务生成合成数据，但这两种方法要么资源密集，要么无法保证数据质量。而且，这些方法在数据多样性方面有限，并且合成数据与现实环境存在显著差距。", "innovation": "为了解决这些问题，我们提出了OS-Genesis，一种新颖的GUI数据合成流水线，它逆转了传统的轨迹收集过程。OS-Genesis让代理首先感知环境并逐步互动，然后回顾性地推导出高质量的任务来实现轨迹级别的探索。通过使用轨迹奖励模型可以确保生成轨迹的质量。结果显示，使用OS-Genesis训练GUI代理可以显著提高其在高难度在线基准测试中的表现，并且OS-Genesis在效率和数据质量及多样性上优于现有的合成方法。", "conclusion": "我们通过OS-Genesis显著地提高了GUI代理在高性能在线基准测试中的表现，并认为这种方法在效率和数据质量及多样性上优于现有合成方法。我们也提供了相关的代码、数据和检查点。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.18578", "html_url": "https://arxiv.org/abs/2311.18578", "title": "通信高效的异质联邦学习与广义重球动量", "title_en": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum", "authors": "Riccardo Zaccone,Sai Praneeth Karimireddy,Carlo Masone,Marco Ciccone", "background": "联邦学习（FL）在处理分布式且隐私受限的数据时已经发展成为最先进的方法。然而，随之而来的是系统和统计学上的挑战，限制了其在现实世界中的广泛应用，特别是对于边缘设备和数据异质性的鲁棒性需求。虽然这些挑战对现有方法构成了重大考验，但在这些方法中存在着严重的退化现象，主要归因于数据异质性和客户端参与度不足的联合影响。在现有的方案中，动量方法被视为一种克服统计异质性的有希望的途径，但这些方法的更新往往偏好最近采样的客户端，导致其无法在联邦学习中胜过FedAvg。因此，文章作者提出了一个新的广义重球动量（GHBM）方法，并在理论上证明了它可以在不受限的数据异质性和部分参与下实现收敛，从而加深了对动量在联邦学习中的有效性的理解。", "innovation": "提出了一个新的广义重球动量（GHBM）方法，理论上证明了它可以在不受限的数据异质性和部分参与情况下实现收敛，从而解决现有联邦学习方法在统计异质性和客户端参与度不足情况下的退化问题。还提出了适应性和通信高效的GHBM变体，这些变体在客户端可以维持状态时与FedAvg的通信复杂度相匹配。并通过广泛的视觉和语言任务实验验证了其理论发现，证明了GHBM在随机均匀客户端采样下的效果显著提高，尤其是在大型数据异质性和低客户端参与情况下的大型情景中表现尤为突出。", "conclusion": "实验数据证实，GHBM在随机均匀客户端采样条件下显著提高了现有最佳性能，特别是在数据异质性和低客户端参与程度较高的大型场景中表现最佳。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.17966", "html_url": "https://arxiv.org/abs/2410.17966", "title": "基于小波的图像超分辨率Wavelet Diffusion GAN", "title_en": "A Wavelet Diffusion GAN for Image Super-Resolution", "authors": "Lorenzo Aloisi,Luigi Sigillo,Aurelio Uncini,Danilo Comminiello", "background": "近年来，扩散模型作为一种比生成对抗网络（GANs）更优秀的高保真图像生成方法，广泛应用在文本到图像生成、图像到图像翻译和超分辨率等领域。然而，这些模型的实时可行性受到了慢训练和推理速度的阻碍。因此，本文提出了一种基于小波的条件扩散GAN方案，用于单图像超分辨率（SISR），以提高其实时性能。该方案利用扩散GAN范式降低逆向扩散过程所需时间步长，并使用离散小波变换（DWT）实现维度减少，从而显著减少了训练和推理时间。实验验证表明，该方案在CelebA-HQ数据集上的效果有效，而且优于现有的其他先进方法，同时解决了扩散模型在时间敏感应用中的固有缺点，保证了高保真输出。", "innovation": "提出的基于小波的条件扩散GAN方案结合了扩散GAN模型的高效逆向扩散过程与离散小波变换的降维作用，显著提高单图像超分辨率模型的实时性能，进而提升了模型训练和推理速度。该方法在确保高保真度输出的同时，有效缓解了扩散模型在时间敏感需求场景下的问题。", "conclusion": "实验验证本研究提出的基于小波的条件扩散GAN方案不仅提高了单图像超分辨率模型的实时性能，还在保证高保真度输出的同时解决了扩散模型在时间敏感应用场景下的问题，相比现有其他先进方法具有明显优势。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.10814", "html_url": "https://arxiv.org/abs/2501.10814", "title": "No More Sliding Window: 使用可微分Top-k子块采样的高效3D医学图像分割", "title_en": "No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling", "authors": "Young Seok Jeon,Hongfei Yang,Huazhu Fu,Mengling Feng", "background": "3D模型在CT/MRI分割中比2D模型效果更好，因为它们能够有效捕捉层间关系。然而，额外的深度维度显著增加了内存消耗。尽管基于补丁的训练能够缓解内存限制，但滑动窗口（SW）方法会显著降低推理速度。现有的方法无法同时满足高效性和准确性之间的平衡，尤其是在内存和计算效率方面存在显著的性能损失。", "innovation": "本文提出了名为No-More-Sliding-Window (NMSW)的新颖端到端可训练框架，该框架通过在推理步骤中消除滑动窗口需求来提高通用3D分割主干网络的效率。NMSW利用可微分的Top-k模块有选择地采样仅与结果最相关的补丁，从而减少冗余计算。当补丁级别预测不足时，该框架能够智能利用粗粒度全局预测来细化结果。NMSW在3个任务和3个分割主干网络上进行了评估，显示与SW推理相比具有竞争力的准确度，同时将计算复杂性降低了91%，在H100 GPU上的推理速度提升了9.1倍，在Xeon Gold CPU上的推理速度提升了11.1倍。NMSW在任何已有的高效分割主干网络上都具有模型的通用性，进一步提升了整体效率。", "conclusion": "NMSW在保持分割准确性的同时，显着降低了计算复杂性，并且在GPU和CPU上的推理速度得到了大幅提高。由于其模型的通用性，NMSW可以与任何现有的高效分割主干网络集成以进一步提高效率。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13232", "html_url": "https://arxiv.org/abs/2505.13232", "title": "StarFT：通过特征隐含偏差对齐增强零样本模型的鲁棒微调", "title_en": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment", "authors": "Younghyun Kim,Jongheon Jeong,Sangkyung Kwak,Kyungmin Lee,Juho Lee,Jinwoo Shin", "background": "学习稳健的数据表示通常需要大量规模，使近年来的零样本模型（如CLIP）取得了成功。然而，这些模型在下游任务（如小型规模任务）上的微调导致其获得的稳健性容易受损。现有的工作通常从领域偏移的视角解释这一现象，通过方法力求保留模型的原始域特征。但在另外一种情况下，有限数据的微调模型容易学到对人类无意义的特征，如背景或纹理。", "innovation": "提出了StarFT（Spurious Textual Alignment Regularization）框架，旨在增强零样本模型的稳健性，通过防止其学到无意义的特征。引入了通过生成突出潜在干扰特征的其他文本描述来获取无意义特征注入标签的正则化方法，使模型的输出分布与原始零样本模型对齐，确保模型不会进一步抽取与这些描述无关的特征。", "conclusion": "广泛的实验验证了StarFT在鲁棒泛化上的有效性，包括零样本群体稳健性和零样本分类性能的提升。在Waterbirds群体偏移场景中，StarFT在最差群体和平均准确性上分别提高了14.30%和3.02%，而现有的鲁棒微调基准线却表现下降。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21233", "html_url": "https://arxiv.org/abs/2506.21233", "title": "ReME: 一种以数据为中心的无需训练的开放词汇分割框架", "title_en": "ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation", "authors": "Xiwei Xuan,Ziquan Deng,Kwan-Liu Ma", "background": "无需训练的开放词汇语义分割（OVS）旨在给定一组任意文本类别时分割图像，而不进行昂贵的模型微调。现有解决方案通常探索预训练模型的注意力机制，如CLIP，或者生成合成数据并设计复杂的检索过程来执行OVS。然而，他们的性能受限于依赖模型的能力或参考集的质量不足。这篇论文探讨了这个具有挑战性的密集场景理解任务中数据质量这一长时间被忽视的问题，发现高质量的参考集可以显著促进无需训练的OVS。", "innovation": "引入了一种以数据质量为导向的框架，包括构建一个具有良好配对的分割-文本嵌入参考集的管道和基于相似性的简单检索方式来揭示数据的效果。这些方法在十个基准数据集中进行了广泛评估，并表明本方法优于所有现有的无需训练的OVS方法，突显了无需训练推进OVS时数据为中心设计的重要性。", "conclusion": "我们的方法在十种基准数据集上的广泛评估中表现出色，优于现有所有无需训练的OVS方法，强调了无需训练推进OVS时数据中心化设计的重要性，我们的代码可以在提供的网址中找到。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.06020", "html_url": "https://arxiv.org/abs/2410.06020", "title": "QT-DoG: 训练感知量化在域泛化中的应用", "title_en": "QT-DoG: Quantization-aware Training for Domain Generalization", "authors": "Saqib Javed,Hieu Le,Mathieu Salzmann", "background": "域泛化（Domain Generalization，DG）的一个主要挑战是如何防止模型过度拟合到源域。为解决这一问题，可以在损失景观中找到更平坦的极小值来减轻过拟合。传统的方法主要集中在模型压缩上，而本研究提出了一种新的方法——训练感知量化（Quantization-aware Training for Domain Generalization，QT-DoG），通过量化有效地鼓励模型找到更平坦的极小值，从而增强域泛化的性能。", "innovation": "与传统的量化方法不同，QT-DoG利用量化作为隐式的正则化手段，通过对模型权重引入噪声来引导优化过程，发现更平坦、对扰动不敏感的极小值，从而减少过拟合。研究者提供了理论分析和实验证据，证明量化本身可以鼓励找到更平坦的极小值，从而提升模型的泛化能力。此外，通过减少模型大小所带来的益处，研究者通过训练多个量化模型的集成，证明这种做法能在不增加计算或内存开销的情况下达到当前最佳的域泛化效果。", "conclusion": "QT-DoG通过量化感知训练，在不增加计算和内存开销的情况下，增强了模型的泛化能力，证明了其在域泛化中的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.03786", "html_url": "https://arxiv.org/abs/2503.03786", "title": "自我是最佳学习者：通过协作去噪和分割学习实现无CT超低剂量PET器官分割", "title_en": "Self is the Best Learner: CT-free Ultra-Low-Dose PET Organ Segmentation via Collaborating Denoising and Segmentation Learning", "authors": "Zanting Ye,Xiaolong Niu,Xu Han,Xuanbin Wu,Wantong Lu,Yijun Lu,Hao Sun,Yanchao Huang,Hubing Wu,Lijun Lu", "background": "PET（正电子发射断层扫描）在癌症量化中扮演着重要角色。低剂量PET（LDPET）提供了一种更安全的选择，通过减少辐射暴露。然而，LDPET固有的噪声和模糊的边界使得器官分割更加困难。现有PET器官分割方法依赖于与CT（计算机断层扫描）注释配准，但忽略了模态不匹配的问题。", "innovation": "本文提出了一种名为LDOS的全新CT-free超LDPET器官分割管道。该方法借鉴了掩码自动编码器（MAE）的思想，将LDPET重新解释为全剂量PET（FDPET）的自然掩码版本。LDOS采用了一个简单的有效架构：共享编码器提取通用特征，而任务特定的解码器独立地对去噪和分割进行细化。通过将CT衍生的器官注释整合到去噪过程中，LDOS提高了解剖边界识别并减轻了PET/CT对齐错误。实验结果表明，LDOS在18种器官的5%剂量PET中实现了最先进的性能，平均Dice分数为73.11%（18F-FDG）和73.97%（68Ga-FAPI）。", "conclusion": "LDOS方法在18种器官的5%剂量PET实验中达到了最先进的性能，平均Dice分数为73.11%（18F-FDG）和73.97%（68Ga-FAPI），并且通过将CT衍生的器官注释集成到去噪过程中提高了解剖边界识别，减轻了PET/CT对齐错误。此外，LDOS是在无CT的情况下实现超低剂量PET器官分割的新型方法。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.11604", "html_url": "https://arxiv.org/abs/2506.11604", "title": "VLM@school -- Evaluation of AI image understanding on German middle school knowledge", "title_en": "VLM@school -- Evaluation of AI image understanding on German middle school knowledge", "authors": "René Peinl,Vincent Tischler", "background": "当前大多数视觉语言模型评估基准主要使用英语问题，这些问题往往设计得非常人为且脱节，缺乏实际背景。该论文介绍了一个新的基准数据集，以评估Vision Language Models (VLMs)在结合视觉推理和特定学科背景知识的任务上的能力。该数据集来自于德国九个学科领域的实际中学课程，确保模型不仅需要进行视觉解释还需进行事实推理，而非依赖表面的文字线索，涵盖了超过2000个开放式问题和486幅图像，相比仅依赖文本的评估方法更为全面与实际.", "innovation": "该研究提出了一个专为德语特定背景知识设计的新基准数据集VLM@school。它基于德国中学实际的九个学科领域的课程，问题来自于真实的视觉材料，如图像，突出了模型需要将视觉信息与具体的知识点相结合。这种方法不同于传统英语基准的抽象问题设计，能够更真实地反映模型在实际情境下的表现。评测了包括数学、历史、生物等在内的多个学科，涉及多个维度的评估，特别是在特定领域准确性以及对抗性问题上的表现.", "conclusion": "研究结果表明，即便是当前最强大的视觉语言模型在多学科上的综合表现也低于45%，特别是在音乐和数学领域表现不佳，并且在对抗性问题上的表现也不佳。研究指出，中学层次的任务是评估VLM的一个具有重要意义但被忽略的领域，尤其是对于非英语环境。数据集和评价方法提供了一个严格的测试平台，帮助更好地理解并改进未来AI系统的视觉和语言推理能力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21655", "html_url": "https://arxiv.org/abs/2506.21655", "title": "APO: 通过非对称策略优化提升多模态大型语言模型的推理能力", "title_en": "APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization", "authors": "Minjie Hong,Zirun Guo,Yan Xia,Zehan Wang,Ziang Zhang,Tao Jin,Zhou Zhao", "background": "多模态大型语言模型（MLLMs）能够整合多种数据，但通常处理复杂推理能力较弱。强化学习（RL）能够提升语言模型的推理能力，但在应用到MLLMs时存在一些挑战，如任务性能下降和生成过多复杂推理等问题。本文针对这些挑战进行了研究，提出了非对称策略优化（APO）方法，以改进MLLMs的RL训练效果。", "innovation": "本文提出了Asymmetric Policy Optimization（APO）方法，通过将采样响应分为正负两组，并分别采用Difficulty-Adaptive Divergence Shaping（DADS）和Suboptimal Trajectory Complexity Regularization（STCR）两种策略来解决MLLMs在RL训练中的问题。DADS动态调整KL散度权重，防止策略熵突然下降，提高训练稳定性，更好地利用样本，保留模型已有的知识。STCR则针对负样本惩罚过长的响应，帮助减少过度推理，同时保持模型的探索能力。通过这种方法，研究在Qwen2.5-VL-3B模型上得到的View-R1-3B显著提升了推理能力，优于基模型7%以上，在各种推理基准测试中也优于其他较大规模（7-11B）的MLLMs，且保持了一致的改进效果，证明其具有较好的泛化能力。", "conclusion": "该研究结果表明，DADS和STCR技术在提升MLLMs复杂多模态推理能力方面是有效的，并具有广泛的适用性。代码将会发布在相关链接。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21272", "html_url": "https://arxiv.org/abs/2506.21272", "title": "FairyGen：由单个儿童画作生成的故事化卡通视频", "title_en": "FairyGen: Storied Cartoon Video from a Single Child-Drawn Character", "authors": "Jiayi Zheng,Xiaodong Cun", "background": "目前的讲故事方法主要集中在角色一致性与基本动作上，FairyGen 则通过明确分离角色建模和风格化的背景生成，同时结合电影镜头设计，提供富有表现力和连贯性的讲故事方式。给定单个角色素描，通过多层语言模型（MLLM）生成带镜头级描述的结构化故事板，确保视觉一致性，支持多样性和电影质量的视觉呈现。动画通过重建角色的3D代理来生成物理上合理的运动序列，并结合基于MMDiT的图像到视频扩散模型进行微调。该系统展示了在个性化和引人入胜的故事动画方面的潜力。", "innovation": "FairyGen 通过对故事板的详细建模，分离角色建模和风格化背景生成，结合电影镜头设计，实现了表现力强且连贯的讲故事方法。通过多层语言模型（MLLM）自动生成结构化故事板，设计了风格传播适配器和镜头设计模块以平衡视觉多样化和高质量。并且首次提出了一种两阶段的运动自定义适配器，为故事动画提供物理合理的运动序列和连贯的故事呈现。", "conclusion": "广泛实验表明，FairyGen 生成的动画在风格忠实度和叙事结构的自然运动方面表现出色，展示了其在个性化和引人入胜的故事动画方面的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21683", "html_url": "https://arxiv.org/abs/2506.21683", "title": "风险规避的总报酬强化学习", "title_en": "Risk-Averse Total-Reward Reinforcement Learning", "authors": "Xihong Su,Jia Lin Hau,Gersi Doko,Kishan Panaganti,Marek Petrik", "background": "风险规避的总报酬马尔可夫决策过程提供了建模和解决无折扣无限时段目标的有效框架。现有的基于模型的方法在风险管理度量（如熵风险度量(ERM)和熵值风险(_EVaR)）方面是有效的，但在小规模问题中运行良好，需要完全访问转移概率。", "innovation": "提出了基于Q学习的算法来计算风险规避的总报酬ERM和_EVaR目标下的最优静态策略，该算法具有强收敛性和性能保障。算法及其最优性得益于ERM的动态一致性及其可支配性。论文通过在表格域中的数值实验展示了所提出的Q学习算法快速且可靠的收敛性，趋近最优风险规避价值函数。", "conclusion": "提出的基于Q学习的算法能够提高大规模问题下风险规避决策过程的效率和可靠性，为风险决策提供了一种新的方法论支持。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19897", "html_url": "https://arxiv.org/abs/2505.19897", "title": "ScienceBoard: 在实际科学工作流程中评估多模态自主代理", "title_en": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows", "authors": "Qiushi Sun,Zhoumianze Liu,Chang Ma,Zichen Ding,Fangzhi Xu,Zhangyue Yin,Haiteng Zhao,Zhenyu Wu,Kanzhi Cheng,Zhaoyang Liu,Jianing Wang,Qintong Li,Xiangru Tang,Tianbao Xie,Xiachong Feng,Xiang Li,Ben Kao,Wenhai Wang,Biqing Qi,Lingpeng Kong,Zhiyong Wu", "background": "大型语言模型（LLMs）已超出自然语言处理的范围，推动了跨学科研究的发展。各种基于LLM的代理正在助力科学发现，特别是在生物化学、天文学和地理信息系统等不同领域。具有用户界面交互能力的计算机使用代理，能够像人类一样与操作系统交互，为自动化的科学研究问题解决提供了可能。", "innovation": "引入了ScienceBoard，它包括两个组成部分：一个多领域的环境，包含动态的、视觉丰富的科学工作流程，集成专业软件，代理可通过不同的接口独立互动，加速复杂研究任务及实验；及由人类严格验证的169个高难度现实任务基准，涵盖了跨学科的科学发现工作流程。此外，ScienceBoard展示了当前先进代理模型在复杂工作流程中的局限性，并提供了改进设计的见解，以构建更强大的代理来促进科学研究。", "conclusion": "深入分析结果显示，尽管某些代理模型初具潜力，但它们在复杂工作流程中协助科学家的作用仍有限，仅实现了15%的整体成功率。研究为进一步有效设计科学发现中的代理提供了有价值的指导，有助于未来开发更强大的科学发现代理。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21714", "html_url": "https://arxiv.org/abs/2506.21714", "title": "ODE_t (ODE_l): 在扩散和流模型中通过时间维度和长度维度的捷径加速采样", "title_en": "$\\textrm{ODE}_t \\left(\\textrm{ODE}_l \\right)$: Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "authors": "Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer", "background": "最近，连续正规化流（CNFs）和扩散模型（DMs）已经从统一理论框架进行了研究。尽管这些模型从噪声分布生成高质量的数据点，但采样需要解决多个迭代的常微分方程（ODE），这带来了高计算复杂性的挑战。大多数现有方法集中在减少采样过程中的时间步骤以提高效率。", "innovation": "本文探讨了一种互补的方向，即通过重新配置基于变压器的架构中的模块来动态控制时间和长度维度上的质量和复杂性的权衡，在流匹配训练中使用时间维度和长度维度一致项。这种方法使采样可以使用任意数量的时间步骤和变压器块进行。我们的 $\textrm{ODE}_t (\textrm{ODE}_l)$ 方法在时间维度上是求解器无关的，减少了延迟和内存使用。与此前的最佳方法相比，我们的方法在 CelebA-HQ 和 ImageNet 上的图像生成实验中的最高延迟降低了 3 倍，且高质量采样的 FID 分数提高了 3.5 分。", "conclusion": "我们的方法释放了代码和模型权重，以实现完全可重复的实验。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22605", "html_url": "https://arxiv.org/abs/2503.22605", "title": "Audio-Plane: 音频因子平面高斯布光法在实时对话头部合成中的应用", "title_en": "Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis", "authors": "Shuai Shen,Wanhua Li,Yunpeng Zhang,Yap-Peng Tan,Jiwen Lu", "background": "在计算机图形学和多媒体领域，对话头部合成已成为一个突出的研究课题。然而，现有大多数方法在生成质量和计算效率之间难以取得平衡，特别是在实时约束下。现有的方法通常需要存储和处理4D密集网格，这会增加内存和计算成本，并且对于较长的时间段缺乏可扩展性。因此，急需一种能够在降低计算复杂度的同时生成高质量、音频同步且实时的对话头部的新方法。", "innovation": "本文提出了一种新颖的框架，将高斯布光与结构化的音频平面（Audio-Plane）相结合，以实现高质量、音频同步和实时的对话头部生成。该框架通过将4D体积表示分解为独立于音频的空间平面和依赖于音频的时间平面，形成了一种紧凑且可解释的表示方法，能够高效地进行空间编码，并显著提高了模型捕捉复杂唇部动态的能力。此外，还引入了一种基于区域感知调制的音频引导显著性布光机制，以适应性地突出高动态区域，从而使得模型能够将学习能力集中在最关键的区域，实现准确的语音驱动动画。这种方法在2D和3D基于的框架中都表现出优于先前方法的视觉质量、精确的音频唇部同步和实时性能。", "conclusion": "实验结果显示，本方法在自驱动和跨驱动设置下，实现了最先进的视觉质量、精确的音频唇部同步和实时性能，优于先前的方法。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21718", "html_url": "https://arxiv.org/abs/2506.21718", "title": "通过文本到文本回归进行大型系统性能预测", "title_en": "Performance Prediction for Large Systems via Text-to-Text Regression", "authors": "Yash Akhauri,Bryan Lewandowski,Cheng-Hsi Lin,Adrian N. Reyes,Grant C. Forbes,Arissa Wongpanich,Bangding Yang,Mohamed S. Abdelfattah,Sagi Perel,Xingyou Song", "background": "在许多行业中，预测大型系统度量指标是一项基础问题，通常依赖传统的表格回归方法。然而，在诸如配置文件或系统日志等复杂的系统数据中，这类方法在特征工程方面往往难以实施。本文探讨了在这样的复杂系统数据上应用文本到文本回归方法作为新的解决方案.", "innovation": "本文提出了一种文本到文本回归作为通用的大规模替代方案。特别地，通过Borg（Google的大规模计算集群调度系统）上的资源效率预测实验，一个60M参数的编码器-解码器模型从随机初始化训练，表现出了较高的精度，特别是在整个集群的表现上接近完美（为0.99的排名相关性和0.9的平均相关性），并且其均方误差比传统表格方法低了100倍。此外，该模型还展示了针对新任务的快速适应能力，在仅500个示例的few-shot学习中就能取得较好的效果，同时还能捕捉复杂结果分布的密度。进一步的消融实验揭示了使用编码器、提高序列长度以及模型内置的不确定性量化的重要性.", "conclusion": "这些发现为构建对真实世界结果具有普遍模拟能力的模型铺平了道路，表明文本到文本回归在复杂系统性能预测中具有显著的优势和潜力。"}
{"llm_update_time": "20250630", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.18290", "html_url": "https://arxiv.org/abs/2411.18290", "title": "利用语义不对称性在计划CT中标记鼻咽癌的精确GTV分割", "title_en": "Leveraging Semantic Asymmetry for Precise Gross Tumor Volume Segmentation of Nasopharyngeal Carcinoma in Planning CT", "authors": "Zi Li,Ying Chen,Zeli Chen,Yanzhou Su,Tai Ma,Tony C. W. Mok,Yan-Jie Zhou,Yunhai Bai,Zhinlin Zheng,Le Lu,Yirui Wang,Jia Ge,Xianghua Ye,Senxiang Yan,Dakai Jin", "background": "在鼻咽癌（NPC）的放疗中，临床医生通常使用非对比剂计划CT来勾画肿瘤体积（GTV），以确保辐射剂量的准确递送。然而，肿瘤与周围正常组织的对比度低，导致放射肿瘤学家需手动勾画肿瘤，通常依赖于影像诊断MRI的引导。因此，本文探讨了一种新的方法直接通过非对比剂计划CT图像分割NPC的肿瘤，以减少将MRI或MRI衍生的肿瘤掩模与计划CT对齐时可能产生的误差。由于计划CT中肿瘤与周围正常结构对比度低的问题，本文引入了一个三维语义不对称肿瘤分割（SATs）方法，它假设健康鼻咽部位具有双边对称性，而鼻咽癌则破坏了这种对称性。然后提出了一个双胞胎对比学习分割框架，该框架最小化非肿瘤区域和翻转后的非肿瘤区域之间的体素距离，同时鼓励非肿瘤区域与携带肿瘤的区域之间的距离较大，从而提高对语义不对称性的敏感度。", "innovation": "本文提出了一种新的三维语义不对称肿瘤分割方法（SATs），通过最小化原区域和翻转后的非肿瘤区域之间的体素距离，同时鼓励非肿瘤区域与携带肿瘤的区域之间保持较大距离。这种方法通过对称性破坏来检测肿瘤，克服了低对比度图像分割的难题，从而提高了对肿瘤的检测敏感度。实验结果显示，在两种测试中的NPC GTV分割表现均优于其他最先进的方法， Dice分数提高了至少2%，平均距离误差减少了12%。", "conclusion": "该研究提出了一种新的深度学习方法（3D SATs），通过检测肿瘤破坏的对称性，显著提高了鼻咽癌非对比CT图像中GTV分割的精度。实验结果证明了这种方法的有效性和优越性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21695", "html_url": "https://arxiv.org/abs/2506.21695", "title": "基于密度的聚类中的单模策略", "title_en": "Unimodal Strategies in Density-Based Clustering", "authors": "Oron Nir,Jay Tenenbaum,Ariel Shamir", "background": "基于密度的聚类方法在处理噪声数据或任意数据分布时往往优于基于质心的方法，这在真实世界问题中很常见。本研究揭示了基于密度的聚类方法的一个关键特性，即簇的数量与核心点邻域半径之间的关系几乎是单模态的。通过实验证明并理论支持了这一特性，特别是在特定设置下。", "innovation": "研究利用这一特性开发了新的策略，利用三元搜索算法更高效地找到适当的半径值。这对于大规模高维数据尤为重要，因为参数调整是计算密集型的。通过广泛的应用证明了该方法的有效性和鲁棒性，并提出了对指导参数关系理解的扩展。", "conclusion": "这项工作不仅为基于密度的聚类的参数控制提供了重要进展，还扩展了对其指导参数关系的理解。代码已公开。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21788", "html_url": "https://arxiv.org/abs/2506.21788", "title": "多任务并行性在多源、多保真度原子建模数据上增强图基础模型鲁棒预训练", "title_en": "Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data", "authors": "Massimiliano Lupo Pasini,Jong Youl Choi,Pei Zhang,Kshitij Mehta,Rylie Weaver,Ashwin M. Aji,Karl W. Schulz,Jorda Polo,Prasanna Balaprakash", "background": "图神经网络为基础的模型能够提供可持续且高效的原子级建模。然而，在预训练过程中处理来自多个源的多源、多保真度数据面临挑战。现有的研究表明，通过多任务学习，即共享的消息传递层首先处理输入的原子结构，无视数据来源，然后将其导向多个解码头以生成特定的输出数据，这种方法能够稳定预训练过程并提高模型在未探索的化学区域的迁移能力。尽管初步结果令人鼓舞，但仍然存在问题，如这些模型的泛化性能如何在更大的、更具多样性的数据集上表现，以及在超算上进行扩展是否可行。", "innovation": "本文提出了一种多任务并行性方法，该方法通过将每个解码头分布在具有GPU加速的计算资源中来分配任务。该方法在开源HydraGNN架构下实施，在超过2400万个结构的数据集上进行了训练，并在Perlmutter、Aurora和Frontier等超级计算机上进行了测试，显示了在所有三个高度异构的超级计算架构上高效扩展的能力。", "conclusion": "多任务并行性方法不仅提高了模型的泛化能力，还展示了其在超级计算机上有效扩展的潜力，为多源、多保真度原子建模数据的图基础模型预训练提供了有效解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21744", "html_url": "https://arxiv.org/abs/2506.21744", "title": "联邦项目反应理论模型", "title_en": "Federated Item Response Theory Models", "authors": "Biying Zhou,Nanyu Luo,Feng Ji", "background": "项目反应理论（IRT）模型广泛用于估计受访者的能力潜质和项目的难度。传统IRT估算需要所有个体的原始反应数据集中在一个地方，这可能导致隐私问题。联邦学习是一种在计算机科学和机器学习领域中新兴的领域，具有隐私保护和分布式计算的附加功能。为了将联邦学习的进步与现代心理测量学结合，我们提出了一种新颖的框架，即联邦项目反应理论（FedIRT），以在分布式计算方式下估计传统IRT模型，并且能提供额外的隐私保护，从而不影响估计准确性。", "innovation": "我们提出了一种新的框架，FedIRT，它能够在分布式环境下进行传统IRT模型的估计，同时提供隐私保护和降低通信成本。通过大量的数值实验，证明FedIRT与使用流行的R包进行标准IRT估计相比，具有相似的统计准确性，同时具备隐私保护和降低通信成本的优势。此外，通过真实考试数据集的验证，展示了FedIRT在实际教育情境中的有效性。", "conclusion": "新的框架将IRT的应用扩展到了分布式设置中，如多所学校评估，而无需牺牲准确性或安全性。为了支持实际应用，我们提供了一个开源的R包，FedIRT，以实现二参数逻辑模型（2PL）和部分信用模型（PCM）框架。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21833", "html_url": "https://arxiv.org/abs/2506.21833", "title": "避免反向传播的代价", "title_en": "The Cost of Avoiding Backpropagation", "authors": "Kunjal Panchal,Sunav Choudhary,Yuriy Brun,Hui Guan", "background": "FmAD和零阶优化ZO已被提出作为反向传播BP的内存高效替代方法，尤其是在资源受限的环境下。然而，它们的实际益处仍不清楚，因为缺乏与内存高效的BP变体（如激活检查点技术）的比较以及缺乏统一的理论分析.", "innovation": "该研究进行了BP、FmAD和ZO方法的全面理论与实证比较。理论分析表明，尽管FmAD和ZO可以减少内存使用，但与带有检查点的BP相比，它们在准确度、收敛速度和计算成本方面也会付出显著的代价。这些缺点在更大的模型或受限制的扰动预算下会变得更加严重。实证实验表明，在大型语言和视觉语言模型上，带有检查点的BP优于FmAD和ZO的变体，即使这些变体增强过有了减小方差的技术，在可比的内存使用情况下，BP的准确度提高了31.1%，收敛速度加快了34.8%，计算量减少了3.8倍.", "conclusion": "研究结果强调了FmAD和ZO的基本局限性，并再次确认BP带有检查点技术是内存受限条件下模型训练最有效的策略。相关的代码可在以下链接获得：this https URL."}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21797", "html_url": "https://arxiv.org/abs/2506.21797", "title": "为什么基于梯度的训练可以发现符号结构：神经符号推理的代数与几何基础", "title_en": "Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning", "authors": "Peihao Wang,Zhangyang Wang", "background": "本文建立了一个理论框架，解释了如何从连续的神经网络训练动态中自然地产生离散的符号结构。通过将神经参数提升到度量空间，并将训练建模为 Wasserstein 梯度流，作者证明了在几何约束（如群不变性）下，参数度量 μ_t 经历了两个并发现象：（1）梯度流在某些潜在函数上的解耦，（2）逐渐缩减的自由度。这些潜在函数编码了与任务相关的代数约束，并在度量空间的交换半环结构下作为环同态作用。随着训练的进行，网络从高维探索过渡到符合代数运算且自由度较低的组合表示。进一步建立了数据比例定律，将表示能力与有助于符号解决方案的群不变性联系起来。此框架提供了一种理解并设计结合连续学习与离散代数推理的神经符号系统的原则性基础。", "innovation": "本文的主要创新点是提出了一种理论框架，解释了如何从连续神经网络训练中自然地产生离散的符号结构。通过将训练过程中的梯度流建模为Wasserstein梯度流，作者揭示了参数度量的变化趋势背后的机制。同时，作者还发现了数据比例定律，深刻地理解了群不变性与符号推理的关系，为神经符号系统的设计提供了新的理论基础", "conclusion": "此框架为理解神经网络如何结合连续学习与离散代数推理提供了一种原理性的基础。通过这种嵌入度量空间的理论框架，结合数据比例定律，研究人员可以更好地设计和理解神经符号系统。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21872", "html_url": "https://arxiv.org/abs/2506.21872", "title": "连续强化学习的综述", "title_en": "A Survey of Continual Reinforcement Learning", "authors": "Chaofan Pan,Xin Yang,Yanhua Li,Wei Wei,Tianrui Li,Bo An,Jiye Liang", "background": "强化学习作为解决序列决策问题的重要机器学习范式，近年来得益于深度神经网络的快速发展取得了显著进展。然而，当前强化学习的成功依赖于大量训练数据和计算资源。此外，强化学习在任务间泛化的局限性限制了其在动态和真实环境中的应用。随着连续学习（CL）的兴起，连续强化学习（CRL）作为一种缓解这些限制的研究方向逐渐显现出来，使得智能体能够持续学习、适应新任务并保留先前获得的知识。", "innovation": "文章提供了连续强化学习（CRL）的全面综述，涵盖了其核心概念、挑战和方法。它详细回顾了现有工作，并从知识存储和/或转移的角度提出了新的CRL方法分类。这为理解CRL的独特挑战提供了新的视角，并指出了未来方向的研究建议。", "conclusion": "文章分析强调了CRL的独特挑战，并提供了面向未来方向的实际见解。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21782", "html_url": "https://arxiv.org/abs/2506.21782", "title": "M3PO: 大规模多任务模型导向策略优化", "title_en": "M3PO: Massively Multi-Task Model-Based Policy Optimization", "authors": "Aditya Narendra,Dmitry Makarov,Aleksandr Panov", "background": "现有的基于模型的强化学习方法（MBRL）在单任务设置中样本效率低下，在多任务环境中泛化能力差。诸如DreamerV3等方法依赖于像素级的生成模型，忽视了控制导向的表示，而基于经验的方法如PPO（Proximal Policy Optimization）样本复杂度过高且探索不足。", "innovation": "M3PO框架通过结合隐式世界模型与混合探索策略解决上述问题。隐式世界模型不依赖观测重建来预测任务结果，而混合探索策略则结合了基于模型的规划与基于不确定性的模型自由探索奖励。此外，M3PO通过信任域优化器确保策略更新的稳定性，同时使用基于模型的和基于经验的价值估计之间的差异来引导探索，从而去掉了之前方法中的偏差-方差权衡。", "conclusion": "M3PO提供了一种高效且稳健的基于模型的策略优化替代方案，并在多个基准测试中达到了最先进的性能。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21771", "html_url": "https://arxiv.org/abs/2506.21771", "title": "基于梯度的神经可塑性适应量化并行优化神经模糊网络", "title_en": "Gradient-Based Neuroplastic Adaptation for Concurrent Optimization of Neuro-Fuzzy Networks", "authors": "John Wesley Hostetter,Min Chi", "background": "神经模糊网络（NFNs）作为透明、符号性和普遍函数近似，性能与传统神经架构相当，但是其知识以语言性的IF-THEN规则表示。尽管有这些优点，系统的设计过程仍是一项挑战，现有工作通常会通过分离参数和结构识别消除了优化过程的效率，导致过早地固定了脆弱且表现低劣的架构。本文背景在于此，强调了NFNs优化过程中面临的挑战及其传统方法的局限性，介绍了该领域亟待解决的问题：即NFNs参数与结构应同时优化，以克服先前无法接近的设置，在基于视觉的任务中实现在线强化学习的NFNs.", "innovation": "本文提出了一种新的应用程序独立的方法——基于梯度的神经可塑性适应（GBNA），用以同时优化神经模糊网络（NFNs）的参数和结构。该方法认识到NFNs的参数和结构应该被同时优化，因为这两者是紧密相连的。通过这种方法，先前对于NFNs不可达的设置现在变得可行，例如在一台基于视觉的游戏中实现NFNs的在线强化学习，使得NFNs能够胜任高难度场景的挑战。", "conclusion": "基于梯度的神经可塑性适应方法能够同时优化神经模糊网络的参数与结构，从而在基于视觉的游戏任务中实现了在线强化学习，证明了并行优化NFNs的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21976", "html_url": "https://arxiv.org/abs/2506.21976", "title": "SceneDiffuser++：通过生成世界模型的城市规模交通模拟", "title_en": "SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model", "authors": "Shuhan Tan,John Lambert,Hong Jeon,Sakshum Kulshrestha,Yijing Bai,Jing Luo,Dragomir Anguelov,Mingxing Tan,Chiyu Max Jiang", "background": "交通模拟的目标是利用大量模拟合成里程来补充有限的手动驾驶测试和验证里程。最终愿景是在给定城市地图和自动驾驶汽车（AV）软件堆栈的情况下，生成一个城市，模拟从点A到点B的旅程。这需要集成多种模拟技术，包括场景生成、代理行为建模、遮挡推理、动态场景生成以及交通灯等环境因素的模拟。虽然一些关键技术已在某些研究中单独探讨，但动态场景生成和环境模拟在研究界却较少关注。此外，尚未提出任何能够实现大规模城市级点对点交通模拟的整体生成模型.", "innovation": "本文提出了SceneDiffuser++，这是一种全端到端的生成世界模型，使用单一损失函数进行训练，并能够在大规模城市级别上进行从点A到点B的交通模拟，整合了上述所有需求。它展示了在大规模城市中进行交通模拟的能力，并在长时间模拟条件下研究其优越的现实感。并且，通过评估增强的Waymo Open Motion数据集的模拟质量来验证其模拟质量，以支持行程级别的模拟.", "conclusion": "研究结果表明，SceneDiffuser++具备胜任大规模城市级别的交通模拟任务，特别在长时间模拟条件下展示了其优越的现实感。未来工作可以进一步研究和提高其在复杂多变场景下的模拟效果。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21952", "html_url": "https://arxiv.org/abs/2506.21952", "title": "基于数据生成与背景噪声去除的物理信息网络范式在多种分布式声学检测应用中的研究", "title_en": "Physics-informed network paradigm with data generation and background noise removal for diverse distributed acoustic sensing applications", "authors": "Yangyang Wan,Haotian Wang,Xuhui Yu,Jiageng Chen,Xinyu Fan,Zuyuan He", "background": "分布式声学传感（DAS）技术在多个领域引起了广泛的关注。现有的人工智能模型需要通过训练来实现事件识别和去噪，但现实场景中可用的真实事件数据非常有限。因此，如何有效利用有限的数据及如何克服现实中的数据获取困难和噪声挑战成为关键问题。", "innovation": "提出了一种基于物理信息的DAS神经网络范式，该范式不需要训练真实事件数据。通过物理建模目标事件和现实世界的约束，推导出物理函数来训练生成网络，生成DAS事件数据。借助生成的数据训练DAS背景去噪网络，从而在去除DAS背景噪声方面取得了显著效果。该范式在公开数据集和社会带式输送机故障监测应用中实现了与数据驱动网络类似或更优的效果，并且能够在不同站点的应用中表现出良好的泛化能力。", "conclusion": "该范式通过引入物理信息并具备背景噪声去除的能力，为解决实际DAS应用中的数据获取难题和噪声问题提供了一种前景广阔的解决方案，并探索了DAS技术更多的潜在应用领域。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21937", "html_url": "https://arxiv.org/abs/2506.21937", "title": "HQCM-EBTC：一种用于可解释脑肿瘤分类的混合量子-经典模型", "title_en": "HQCM-EBTC: A Hybrid Quantum-Classical Model for Explainable Brain Tumor Classification", "authors": "Marwan Ait Haddou,Mohamed Bennai", "background": "介绍了HQCM-EBTC模型，这是一种用于利用MRI图像自动进行脑肿瘤分类的混合量子-经典模型。该模型在包含正常、脑膜瘤、胶质瘤和垂体类别的7,576个扫描数据集上进行了训练。通过集成5量子位的深度为2的量子层和5个并行电路，并使用AdamW优化算法和结合交叉熵和注意力一致性损失函数的复合损失，该模型提高了分类的精确性和可解释性。与传统的经典基线相比，HQCM-EBTC的准确性显著提高，达到了96.48%的高精度，并且在胶质瘤检测上表现尤为出色。通过t-SNE投影和混淆矩阵分析，进一步验证了该模型在量子空间中特征的更好区分度和更低的误分类率。通过分析注意力图（Jaccard指数），发现模型在高置信度阈值下对肿瘤定位更加准确和聚焦。这些结果显示在医学影像诊断中，量子增强模型具有巨大的潜力，提高了脑肿瘤诊断的精确度和可解释性，为临床评估提供了更强的支持", "innovation": "HQCM-EBTC引入了一种新的混合量子-经典模型，它结合了量子计算和经典机器学习，特别适用于脑肿瘤的自动化分类。通过量子层和经典电路的并行处理，以及使用先进优化算法和损失函数，该模型在多个关键性能指标上超越了传统的经典方法，特别是在胶质瘤检测方面的表现尤为突出。同时，通过对比分析，验证了模型在特征区分和误分类方面的优势，并通过注意力图进一步证实了其在肿瘤定位上的准确性和聚焦性", "conclusion": "这些结果表明，量子增强模型在医学影像诊断中具有巨大的潜力，可以显著提高脑肿瘤诊断的准确度和可解释性，为临床评估提供了更好的工具和支持。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21899", "html_url": "https://arxiv.org/abs/2506.21899", "title": "连续强化学习的发展与挑战：全面综述", "title_en": "Advancements and Challenges in Continual Reinforcement Learning: A Comprehensive Review", "authors": "Amara Zuffer,Michael Burke,Mehrtash Harandi", "background": "强化学习（RL）任务的多样性和动态性质要求RL代理能够进行连续的学习，这一学习范式被称为连续强化学习。本文综述了连续学习如何使RL代理转变为动态连续学习者，从而使代理能够无缝获取和保留有用且可重用的知识。文章深入探讨了连续强化学习的基本方面，包括关键概念、重大挑战和新型方法，并特别关注机器人领域中的最新进展，还提供了主要研究中使用的评估环境的简洁概述，以提高新手的可访问性。最后，综述讨论了存在的局限性和未来的研究方向，为研究者和实践者提供了有价值的见解。", "innovation": "本文综述了连续学习如何使RL代理转变为动态连续学习者，重点在于机器人领域的最新进展，以及主要研究中使用的评估环境。文章深入探讨了连续强化学习的基本方面，包括新型方法和关键技术挑战，并提供了对未来研究方向的见解，为研究者和实践者提供了有价值的认识。", "conclusion": "综述总结了存在的一些局限性，并提出了未来的研究方向，为研究者和从业者提供了有益的见解。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21844", "html_url": "https://arxiv.org/abs/2506.21844", "title": "基于Koopman算子讨论随机系统中的部分观测", "title_en": "Koopman operator-based discussion on partial observation in stochastic systems", "authors": "Jun Ohkubo", "background": "在完全观测所有可观测量有时非常困难的情况下，部分观测是必要的。对于确定性系统，Mori-Zwanzig形式化提供了处理部分观测的理论框架。最近基于Koopman算子理论的数据驱动算法取得了显著的进展，人们开始讨论如何将Mori-Zwanzig形式化与Koopman算子理论结合起来。本文使用Koopman算子理论来讨论随机系统中部分观测的影响，澄清了在随机系统中区分状态空间和函数空间的重要性。即使在随机系统中，延迟嵌入技术也对部分观测有益，数值实验表明，在增广噪声振幅上的准确性存在幂律行为。讨论了幂律行为指数与部分观测效应对比关系", "innovation": "本文利用Koopman算子理论探讨了随机系统中部分观测的影响，并指出在随机系统中区分状态空间和函数空间的重要性。还发现，在部分观测情况下，延迟嵌入技术是有益的，而且通过数值实验提出了幂律行为的准确性与噪声振幅的关系统讨论了这一幂律行为与部分观测效果的关系", "conclusion": "即使在随机系统中也能通过使用延迟嵌入技术有效处理部分观测，还有数值实验表明准确性随噪声振幅呈幂律行为，该研究对理解随机系统中的部分观测具有重要意义"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21900", "html_url": "https://arxiv.org/abs/2506.21900", "title": "TOAST: 动态无线环境中面向任务适应的语义传输", "title_en": "TOAST: Task-Oriented Adaptive Semantic Transmission over Dynamic Wireless Environments", "authors": "Sheng Yun,Jianhua Pei,Ping Wang", "background": "6G网络的演进需要从以位为中心的传输转向关注任务的语义感知通信，强调任务相关的信息。这一研究背景下的核心挑战是在快速变化的无线环境中进行多任务优化。", "innovation": "提出了一种名为TOAST（面向任务的自适应语义传输）的统一框架，通过三个互补组件解决了多任务优化的核心挑战。首先，将自适应任务平衡形式化为马尔可夫决策过程，利用深度强化学习根据实时信道条件动态调整图像重建保真度和语义分类准确度之间的权衡。其次，通过结合自适应低秩机制（LoRA）的Swin Transformer联合源-信道编码架构，实现了参数效率的微调，显著减少了调整开销，同时在各种信道影响下保持了全性能。第三，引入解释扩散模型运用于潜在空间中，以修复由信道噪声引起的特征损失，显著提高了性能。", "conclusion": "广泛实验表明，TOAST在多个数据集上优于基线方法，在信噪比低的情况下，显著提高了分类准确率和重构质量，同时在所有测试场景中保持了鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21997", "html_url": "https://arxiv.org/abs/2506.21997", "title": "Binned semiparametric Bayesian networks", "title_en": "Binned semiparametric Bayesian networks", "authors": "Rafael Sojo,Javier Díaz-Rozo,Concha Bielza,Pedro Larrañaga", "background": "介绍了利用数据分箱来减少核密度估计计算成本的一种新型概率半参数模型。此模型利用了分箱技术，旨在解决高维数据下的计算复杂度问题，并通过新的条件概率分布来应对维度诅咒现象。", "innovation": "开发了两种新的条件概率分布：稀疏分箱核密度估计和傅里叶核密度估计。这两种分布通过使用稀疏张量和限制条件概率中的父节点数量，解决了分箱模型中的维度诅咒问题，提高了计算效率。实验结果显示，新提出的分箱半参数贝叶斯网络在结构学习和对数似然估计方面与非分箱模型相比没有显著差异，但速度显著提高，因此，分箱半参数贝叶斯网络证明是一个可靠且更高效的替代方案。", "conclusion": "实验表明，分箱半参数贝叶斯网络在结构学习和对数似然估计方面没有统计显著性差异，但显著提高了计算速度，是现有非分箱模型的可靠且更高效的选择。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21940", "html_url": "https://arxiv.org/abs/2506.21940", "title": "GuiderNet: 一种优化量子电路几何结构和缓解荒原 plateau 的元学习框架", "title_en": "GuiderNet: A Meta-Learning Framework for Optimizing Quantum Circuit Geometry and Mitigating Barren Plateaus", "authors": "Marwan Ait Haddou,Mohamed Bennai", "background": "变分量子算法（VQAs）在近期量子优势方面展现出潜力，但仍面临一些挑战，如梯度消失所导致的荒原 plateau 现象，以及优化空间条件不佳的问题。这些问题使得参数优化变得困难，从而影响量子机器学习的效果和鲁棒性。为了克服这些挑战，研究人员引入了GuiderNet框架，该框架通过元学习的方式，利用数据依赖的参数偏移来条件化参数化量子电路（PQCs），旨在最小化Fubini-Study度量张量的日志条件数。GuiderNet作为经典神经网络实现，在指导PQC参数进入几何上更有利的区域方面进行元训练，并嵌入到混合量子-经典管道中，在训练中引导初始化和自适应调制。", "innovation": "GuiderNet通过元学习框架，利用数据依赖的参数偏移来调整参数化量子电路（PQCs），从而最小化Fubini-Study度量张量的日志条件数，提供了一种新的方法来缓解荒原 plateau 和条件不佳的问题。GuiderNet在处理糖尿病分类任务时，显著降低了累计训练损失，提高了测试准确率，并增强了少数类的F1分数。此外，GuiderNet还能抑制梯度爆炸，使参数更新更加稳定，优化过程更加平滑和稳健。这些成果表明，几何元学习可以缓解荒原 plateau 和条件不佳的问题，提供了一种增强量子机器学习训练能力和泛化能力的可扩展方法。", "conclusion": "GuiderNet框架成功地将元学习应用于优化量子电路的几何结构，提高了变分量子算法在处理荒原 plateau 和优化条件不佳问题时的性能。通过在经典神经网络指导下对PQCs进行条件化，GuiderNet在多种任务中显示出了优越的效果，有效缓解了量子机器学习中的关键挑战，为未来研究提供了新的思路。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22095", "html_url": "https://arxiv.org/abs/2506.22095", "title": "学习解决多目标多图路径问题", "title_en": "Learning to Solve Multi-Objective Routing Problems on Multigraphs", "authors": "Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár", "background": "近年来，基于学习的方法在解决单一目标和多目标路径规划问题中引起了广泛关注。然而，大多数研究忽略了多图环境，即在多个目的地之间存在具有不同属性的多条路径的情景，尽管这种设置在实践中非常相关。现有的方法主要集中在简单图或单一目标的路径规划上，而忽视了多图环境下的多目标路径规划问题。", "innovation": "本文提出两种基于神经网络的方法来解决多目标多图路径规划问题。第一种方法直接在多图上进行自回归选择边，直到完成一个路线；第二种方法先将多图简化为简单图，再构建路径。这些模型在旅行商问题(TSP)和有载车辆路径问题(CVRP)等多个问题上都表现出色，证明了其在多图环境下的有效性和实用性。", "conclusion": "本文通过两种不同的神经网络方法验证了多目标多图路径规划的有效性，并展示了这两种方法在处理复杂现实问题时的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22055", "html_url": "https://arxiv.org/abs/2506.22055", "title": "使用LSTM + XGBoost进行加密货币价格预测", "title_en": "crypto price prediction using lstm+xgboost", "authors": "Mehul Gautam", "background": "加密货币市场的波动性和复杂动态为准确的价格预测带来了独特挑战。过去，单独使用的深度学习或机器学习模型在应对这些市场波动时表现不佳，因此需要一种更有效的混合模型来解决这一问题。", "innovation": "论文提出了一种结合长短期记忆网络（LSTM）和极端梯度提升（XGBoost）的混合深度学习和机器学习模型，以预测加密货币的价格。LSTM能够捕捉历史价格数据中的时间依赖性，而XGBoost则通过建模非线性关系来增强预测精度，包括情感分数和宏观经济指标等辅助特征。该模型在比特币、以太坊、狗狗币和莱特币的历史数据集上进行了评估，涵盖了全球和本地交易所的数据。结果表明，LSTM+XGBoost模型在多种时间和市场情况下都优于单独的模型和传统方法，展示了混合架构在金融预测中的潜力和适应性。", "conclusion": "研究表明，LSTM+XGBoost混合模型在加密货币价格预测上表现优异，并且具有跨不同加密货币和市场环境的适应性。该研究强调了混合架构在金融预测中的潜力，并提供了如何根据不同加密货币和市场上下文调整模型的见解。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21956", "html_url": "https://arxiv.org/abs/2506.21956", "title": "广告自动出价中由最优返回值引导的决策变换器", "title_en": "Optimal Return-to-Go Guided Decision Transformer for Auto-Bidding in Advertisement", "authors": "Hao Jiang,Yongxiang Tang,Yanxiang Zeng,Pengjia Yuan,Yanhua Cheng,Teng Sha,Xialong Liu,Peng Jiang", "background": "在在线广告领域，广告商参与竞价以获得广告位，通常利用需求方平台提供的自动化出价工具。为了优化这些出价系统的自动化，研究者采用了生成模型，即决策变换器（Decision Transformer，简称DT），来解决自动出价面临的挑战。DT模型通过捕捉过去出价行为与用户行为之间的长时依赖关系，增强了对未来的预见性，从而克服短视问题。然而，传统DT模型存在一些不足：首先，它需要预先设定一个基于未来收益的权重值（return-to-go，RTG）来生成出价策略，这并非天然产生；其次，通过DT学习到的出价策略受到训练数据质量的限制，这些数据包含混合质量的轨迹。针对这些挑战，本文提出了一种改进的DT变体——R* Decision Transformer (R* DT)。R* DT通过三个步骤逐步进行改进：（1）R DT、（2）R^ DT、（3）R* DT，从而提升了模型效果和适应不同质量数据的能力。", "innovation": "本文提出了R* Decision Transformer (R* DT)，通过增加预测RTG值的步骤，改进了传统的决策变换器（Decision Transformer，简称DT）来处理自动出价任务。R* DT包含三个步骤：（1）R DT类似于传统的DT，存储基于状态和预设RTG值的动作，同时利用训练集记忆RTG值；（2）R^ DT预测给定状态下RTG值的最大值，基于当前状态和预测的最大RTG值形成次优策略；（3）R* DT基于R^ DT生成轨迹，并通过模拟器选择具有高回报率的轨迹以增强训练数据集。这种方法提高了训练数据集轨迹的RTG，并使得次优策略逐渐逼近最优策略。", "conclusion": "通过在公开的出价数据集上进行全面测试，实验结果验证了R* DT的有效性，并展示了其在处理混合质量轨迹时的优越性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22039", "html_url": "https://arxiv.org/abs/2506.22039", "title": "UniCA: 调整时间序列基础模型以适应通用的协变量感知预测", "title_en": "UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting", "authors": "Lu Han,Yu Liu,Qiwen Deng,Jian Jiang,Yinbo Sun,Zhe Yu,Binfeng Wang,Xingyu Lu,Lintao Ma,Han-Jia Ye,De-Chuan Zhan", "background": "时间序列基础模型（TSFMs）通过大规模预训练取得了显著成功，但其设计主要针对实值序列，限制了它们处理涉及多种和通常异质特征（如分类变量和多模态数据，例如图像和文本）的通用预测任务的能力，这些特征通常是任务特定的，并且在预训练期间难以利用。", "innovation": "我们提出了统一协变量适应（UniCA），这是一种框架，将TSFMs与通用协变量感知预测相结合。UniCA 首先进行协变量同质化，将异质协变量转换为高层次的同质序列表示，然后通过统一的基于注意力的融合机制进行融合。UniCA 可以与同质和异质协变量都兼容，同时利用额外的协变量信息，同时保持对泛化能力的影响。", "conclusion": "在多个单模态和多模态协变量感知预测基准上的实验表明，UniCA 具有优越性，强调了此方法在现实世界预测场景中的潜力。代码发布在位于此 https:// 的网址。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22049", "html_url": "https://arxiv.org/abs/2506.22049", "title": "GPAS: 通过保持梯度的激活缩放加速大型语言模型预训练", "title_en": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling", "authors": "Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Yin Lu,Can Yang", "background": "现代大型语言模型，如 LLaMA、Qwen 和 DeepSeek 系列，主要采用了预层归一化（Pre-LN）变换器架构。这种架构在预训练过程中稳定且可以扩展到大型模型，但也存在激活方差随层数增加而指数级增长的问题，这导致残差路径占据了主导地位，限制了深层层的学习能力。", "innovation": "我们提出了梯度保持激活缩放（GPAS），这是一种简单的方法，可以在现有方法的基础上使用。GPAS 通过缩小中间激活来实现，同时保持梯度不变。这样可以保留激活中的信息，避免了梯度缩小带来的梯度消失问题。在从 71M 到 1B 的各种模型大小的广泛实验中，GPAS 实现了一致的性能提升，不仅增强了 Pre-LN 变换器，还展示了在 Sandwich-LN 和 DeepNorm 等其他架构中提高训练动态的潜力。", "conclusion": "大量实验表明，GPAS 在不同大小的模型中都取得了持续的性能提升，表明它不仅能够优化 Pre-LN 架构，还能应用于其他架构，展示了其在各种场景中改进训练动态的灵活性和潜在价值。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22008", "html_url": "https://arxiv.org/abs/2506.22008", "title": "TROFI: 轨迹排名的离线逆强化学习", "title_en": "TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning", "authors": "Alessandro Sestini,Joakim Bergdahl,Konrad Tollmar,Andrew D. Bagdanov,Linus Gisslén", "background": "在离线强化学习中，代理是通过固定存储过渡集进行训练的，这些集合作为源政策的行为数据获取。然而，这需要通过奖励函数对数据集进行标注。在诸如视频游戏开发的实际应用中，奖励函数的可用性并不总是保证的。本文探讨了在没有预定义奖励函数的情况下如何有效地离线学习策略的问题。为此背景下的挑战性和重要性进行了说明。", "innovation": "本文提出了一种新颖的方法——Trajectory-Ranked OFfline Inverse reinforcement learning (TROFI)，该方法不依赖于预定义的奖励函数，而是从人类偏好中学习奖励函数，然后用该奖励函数来标注原始数据集，使其可用于训练策略。与现有方法不同的是，TROFI 不需要最优轨迹，并且在 D4RL 基准测试中，TROFI 成功克服了基线模型，并在性能上与使用真实奖励函数学习策略相差不大。此外，研究还证明了此方法在3D游戏环境中的有效性。这一方法突出强调了奖励函数在确保值函数与实际未来折扣奖励对齐中的关键作用，强调了奖励函数的设计和学习的便捷性的重要性。", "conclusion": "通过在 D4RL 基准测试中的实验，TROFI 方法展示了其在不需要预定义奖励函数的情况下有效并且可靠地学习策略的能力。此外，它在3D游戏环境中的应用也证明了此方法的通用性和有效性。特别是在需要人为标注的复杂环境中，TROFI 提供了一种不需要预定义奖励函数的新途径，这对视频游戏开发等领域具有重要意义。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22096", "html_url": "https://arxiv.org/abs/2506.22096", "title": "在港口沉积物中应用转移学习评估重金属污染", "title_en": "Transfer Learning for Assessing Heavy Metal Pollution in Seaports Sediments", "authors": "Tin Lai,Farnaz Farid,Yueyang Kuan,Xintian Zhang", "background": "检测土壤和港口的重金属污染对于区域环境监测至关重要。传统的污染负荷指数（PLI）评估方法虽然被广泛应用，但涉及到复杂的程序和大量的数据处理。水-沉积物领域常因数据收集的挑战和各国标准的差异面临数据稀缺的问题。因此，需要一种简化的重金属评估方法来应对这些挑战。", "innovation": "本文提出了一种基于深度学习的方法，通过转移学习开发了一种准确的定量评估方法来预测PLI。该模型能够跨不同特征集的领域转移已学习的特征，显著降低了评估过程的复杂性，并通过使用澳大利亚新南威尔士州六个主要港口的数据验证了该模型的有效性。与传统方法相比，新模型的均绝对误差（MAE）和均绝对百分比误差（MAPE）分别降低了约0.5和0.03，且性能比其他基线模型提高了2个数量级。", "conclusion": "本文提出的模型为预测水质提供了一种创新、易访问且成本效益高的方法，有助于海洋生物保护、水产养殖和工业污染监测。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22084", "html_url": "https://arxiv.org/abs/2506.22084", "title": "Transformers是图神经网络", "title_en": "Transformers are Graph Neural Networks", "authors": "Chaitanya K. Joshi", "background": "本文探索了Transformer架构在自然语言处理中的原始用途与图神经网络（GNNs）之间的联系，尤其是在图上的表示学习中。文章指出，transformer可通过全连接的令牌图进行信息传递操作，self-attention机制捕捉令牌间的重要性关系，而位置编码为有序或结构提供了线索。尽管transformer与GNNs在数学上存在联系，但transformer通过密集矩阵操作实现，这在现代硬件上比稀疏消息传递更高效。这种高效性的差异使人们从新的角度看待transformer，即transformer实际上是目前在硬件方面占优的图神经网络.", "innovation": "本文通过将transformer视为基于全连接的令牌图的消息传递GNN，建立了一个新的视角。它提供了一种理解transformer机制的方法，强调了相对于预先定义的图结构，transformer能够学习输入元素之间的关系，同时指出transformer在现代硬件上的高效实现使得它在当前硬件条件下表现优异.", "conclusion": "文章的结论指出，尽管transformer和GNNs在数学上存在相似性，但transformer通过密集矩阵操作实现，使其在现代硬件下更为高效。这表明，在当前的硬件条件下，transformer更像是一种赢得硬件有利条件的GNNs。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22004", "html_url": "https://arxiv.org/abs/2506.22004", "title": "GKNet: 基于模型导向深度学习的图卡尔曼滤波和模型推断", "title_en": "GKNet: Graph Kalman Filtering and Model Inference via Model-based Deep Learning", "authors": "Mohammad Sabbaqi,Riccardo Taormina,Elvin Isufi", "background": "时间序列在图上进行推断的任务在诸如城市水资源网络、经济学和网络化神经科学等领域中非常重要。通常，这些任务需要识别一个计算上可负担的模型，该模型可以同时捕捉数据的图和时间模式。在这项工作中，研究者提出了一种具有图意识的空间状态模型，其中潜在状态和观测方程均为参数化的图驱动模型，带有有限的待学习参数。研究者还考虑了一个状态方程，该方程受图边上的噪声驱动，不仅考虑了边缘的不确定性，而且还通过一种可处理的方式来增加自由度。观察模型是通过采样和图滤波的状态的版本，捕捉多跳邻域的影响。其目标是从部分观测数据中学习状态和观测模型中的参数，以便下游任务如预测和填补数据.", "innovation": "该工作提出了GKNet模型，一种基于模型导向的深度学习框架，将参数学习和状态跟踪结合在一个端到端的框架中，借鉴卡尔曼神经网络的精神。该模型通过最大似然方法进行推理，提供了理论上的可处理性，但在表示能力和可扩展性方面受到限制。为提高后者，通过状态空间框架构建了一个有原理的深度学习架构，可以联合学习参数并跟踪状态，提高了模型的灵活性和适用性.", "conclusion": "通过这一框架，GKNet从部分观测数据中学习参数，并能够进行下游任务如预测和填补数据。该模型结合了卡尔曼滤波和深度学习的优势，提供了一个计算上可负担且表达灵活的解决方案，以处理图上时间序列的数据推断任务。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22036", "html_url": "https://arxiv.org/abs/2506.22036", "title": "Hyper-modal Imputation Diffusion Embedding with Dual-Distillation for Federated Multimodal Knowledge Graph Completion", "title_en": "Hyper-modal Imputation Diffusion Embedding with Dual-Distillation for Federated Multimodal Knowledge Graph Completion", "authors": "Ying Zhang,Yu Zhao,Xuhui Sui,Baohang Zhou,Xiangrui Cai,Li Shen,Xiaojie Yuan,Dacheng Tao", "background": "随着多模态知识隐私化需求的增加，不同机构中的多模态知识图谱通常是分散的，缺乏有效的协作系统。该协作系统需要较强的知识推理能力和传输安全性保障。这项研究旨在解决这一问题，提出了一种新的任务——联邦多模态知识图谱补全（FedMKGC），该任务的目标是在保护敏感知识不被共享的情况下，在客户端训练以更好地预测缺失关系。这项研究探讨了如何应对多模态不确定不可用性和多模态客户端异质性的挑战，提出了一个双蒸馏框架MMFeD3-HidE进行知识传播，以及一个用于全面评估的基准测试平台MMFedE，包括具有异质多模态信息的新的数据集和一组建立的基线方法。实验结果证实了MMFeD3-HidE的效用、语义一致性以及收敛稳健性。", "innovation": "该研究提出了一个名为MMFeD3-HidE的新范式，包括一个超模态填补扩散嵌入模型（HidE），该模型从不完整的实体嵌入中恢复完整的多模态分布，以及多模态联邦双蒸馏（MMFeD3），该蒸馏框架使客户端可以互相传递知识，提高了全局收敛性和语义一致性。此外，该研究还构建了一个新的用于全面评估的基准平台MMFedE，包括具有异质多模态信息的数据集和一组建立的基线方法。", "conclusion": "本研究提出的MMFeD3-HidE范式在联邦多模态知识图谱补全任务中表现出有效、语义一致和收敛稳健性。该研究还提供了一个全面的基准平台MMFedE，用于评估不同方法的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22253", "html_url": "https://arxiv.org/abs/2506.22253", "title": "在固定预算和固定置信度下的风险厌恶最优臂集合识别", "title_en": "Risk-Averse Best Arm Set Identification with Fixed Budget and Fixed Confidence", "authors": "Shunta Nonaga,Koji Tabata,Yuta Mizuno,Tamiki Komatsuzaki", "background": "在不确定环境中，最大化预期回报同时最小化其风险的决策是众多领域内的普遍问题。传统的门诊优化设定了单一的目标，即最大化预期回报，而忽略了风险因素。为解决这个问题，本文引入了一个新颖的问题设定，即在最大化预期回报的同时，通过均值-方差（MV）标准量化关联的不确定性，来实现最优臂集合的识别。", "innovation": "本文提出了一个统一的元算法框架，能够在固定置信度和固定预算两种场景下运行，通过适应性设计在每种场景下都使用相同的样本探索策略来调整置信区间。该框架能够在两种场景下都提供解决方案的正确性理论保证。实验结果表明，本文的方法在准确性及样本效率方面优于现有方法，从而显示了其在不确定环境中的广泛适用性，特别是在风险感知决策任务中的应用价值。", "conclusion": "本文提出了基于固定预算和固定置信度的风险厌恶最优臂集合识别问题的新颖解决方案，通过理论保证与广泛适用性的实验支持，确认了该方法在风险感知决策任务中的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22189", "html_url": "https://arxiv.org/abs/2506.22189", "title": "探索用于药物发现的智能系统模块性", "title_en": "Exploring Modularity of Agentic Systems for Drug Discovery", "authors": "Laura van Weesep,Samuel Genheden,Ola Engkvist,Jens Sjölund", "background": "大型语言模型（LLMs）和智能系统为药物发现和设计提供了加速的机会。已有研究较少关注这些智能系统在药物发现中的模块性，特别是其组件如LLM部分的互换性，以及不同语言模型和工具调用智能体与代码生成智能体在这领域的效果对比。本文旨在分析这一问题，特别是通过一个案例研究来对比使用大语言模型作为裁判评分来协调化学和药物发现工具的性能。", "innovation": "本文的研究对比了不同大语言模型在用于药物发现的智能系统中的表现，包括Claude-3.5-Sonnet，Claude-3.7-Sonnet和GPT-4与其他模型如Llama-3.1-8B、GPT-3.5-Turbo等的性能差异。研究还探讨了工具调用智能体与代码生成智能体在这领域的有效性差异，发现尽管代码生成智能体通常表现更好，但这取决于具体问题和模型。此项工作强调了在考虑语言模型互换性时需要重新工程系统提示的重要性。", "conclusion": "研究结果表明，用于药物发现的智能系统的的模块性需要进一步研究，才能开发出稳定和可扩展的解决方案来解决实际问题。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22299", "html_url": "https://arxiv.org/abs/2506.22299", "title": "CoATA: 对图神经网络中拓扑和属性有效共增强的研究", "title_en": "CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks", "authors": "Tao Liu,Longlong Lin,Yunfeng Yu,Xi Ou,Youan Zhang,Zhiqiu Ye,Tao Jia", "background": "图神经网络（GNNs）因其在学习图表示方面的显著能力而受到广泛关注。然而，真实世界中的图通常包含了大量噪声和不完整性，这对GNNs的性能造成了严重打击。现有方法通常通过单一维度的增强来应对这一问题，它们要么关注拓扑结构的优化，要么针对节点属性进行扰动，但忽视了这两者之间的深层相互作用。", "innovation": "为了解决这个问题，本文提出了CoATA，一种专门设计用于拓扑和属性共增强的双通道GNN框架。CoATA首先通过传播结构信号来丰富并净化节点属性，然后将增强后的属性空间投影到节点-属性二分图中，进一步完善或重构底层结构。此外，CoATA引入了对比学习，利用原型对齐和一致性约束，促进增强图与原始图之间的相互校正。", "conclusion": "在七个基准数据集上的广泛实验表明，提出的CoATA方法优于十一款最先进的基线方法，展示了其捕捉拓扑和属性之间协同关系的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22190", "html_url": "https://arxiv.org/abs/2506.22190", "title": "dreaMLearning: 数据压缩辅助机器学习", "title_en": "dreaMLearning: Data Compression Assisted Machine Learning", "authors": "Xiaobo Zhao,Aaron Hurst,Panagiotis Karras,Daniel E. Lucani", "background": "尽管机器学习，尤其是深度学习在快速发展，但它们受限于需要大量的标记数据来学习有意义的模式，而不会过拟合，并且对计算和存储资源的需求巨大，这激励了研究人员开发能够在较少资源下实现良好性能的架构。背景强调现有的机器学习方法对数据和计算资源的需求较高，因此需要改进的方法能够利用压缩技术来降低成本并提高效率。", "innovation": "dreaMLearning 是一种新的框架，可以在不进行数据解压缩的情况下从压缩数据中进行学习，基于熵驱动的一般化去重（EntroGeDe），这是一种熵驱动的无损压缩方法，能够将信息合并为一组代表性样本。该方法适用于多种数据类型、任务和模型架构，通过压缩减少了训练时间、内存使用和存储需求，同时对模型性能的影响较小。这一创新技术适用于分布式和联邦学习，以及在资源受限的边缘设备上的小规模机器学习，为高效且可扩展的学习打开了新的可能性。", "conclusion": "dreaMLearning 在 regression 和 classification 任务中，无论是基于表格还是图像数据，均可加速训练高达 8.8 倍，减少内存使用 10 倍，降低存储需求 42%，并且对模型性能的影响很小。这些进步增强了机器学习在各种应用中的多样性，包括分布式和联邦学习，以及在资源受限边缘设备上的小规模机器学习，开启了在有效和可扩展的学习方面的新可能性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22255", "html_url": "https://arxiv.org/abs/2506.22255", "title": "投影压缩：高效Transformer压缩的可训练投影", "title_en": "Projected Compression: Trainable Projection for Efficient Transformer Compression", "authors": "Maciej Stefaniak,Michał Krutul,Jan Małaśnicki,Maciej Pióro,Jakub Krajewski,Sebastian Jaszczur,Marek Cygan,Kamil Adamczewski,Jan Ludziejewski", "background": "随着大型语言模型逐渐增大以提高性能，随之而来的是一步步增加的推理时间和计算需求。因此，对模型规模减少方法的兴趣也在增长。", "innovation": "本文提出了一种名为投影压缩的新颖模型压缩技术，通过利用投影模块，减少模型权重。方法包括首先训练可训练的投影权重并保留对所有原始模型参数的访问。之后，将这些投影合并到一个低维度的产品矩阵中，从而获得下一层标准Transformer模型。这种方法与其他需增加额外计算开销的方法不同，能在FLOPs层面匹配基础模型的每个令牌计算步骤。实验结果表明，投影压缩在高质量模型上优于可替代的硬剪枝和重新训练方法，并且性能差距与tokens的数量成正比增长.", "conclusion": "实验结果显示，投影压缩在高级模型上优于匹配的硬剪枝和重新训练方法，并且性能差距随着token数量的比例优化。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22186", "html_url": "https://arxiv.org/abs/2506.22186", "title": "基于Thompson采样的未知动态系统学习与控制", "title_en": "Thompson Sampling-Based Learning and Control for Unknown Dynamic Systems", "authors": "Kaikai Zheng,Dawei Shi,Yang Shi,Long Wang", "background": "Thompson采样（TS）是一种有效的方法，用于探索参数不确定性，因此可以用于基于主动学习的控制器设计。然而，TS依赖于有限的参数表示，这限制了其在更广泛的、更常用于控制系统设计的空间中的应用。", "innovation": "本文提出了一种参数化方法，用于控制法律的学习，使用再生核希尔伯特空间，并设计了一种基于数据驱动的主动学习控制方法。具体来说，该方法将控制法律视为函数空间中的元素，允许在不需对系统结构或控制器形式施加限制的情况下进行控制法律的设计。此外，本文还提出了一种TS框架来探索潜在最优控制法律，并为学习过程提供了收敛性保证。理论分析表明，所提出的方法以指数速率学习控制法律与闭环性能指标之间的关系，并且也推导了控制后悔的上限边界。数值实验验证了所提出方法的有效性。", "conclusion": "所提出的方法学习控制法律与闭环性能指标之间的关系以指数速率进行，并推导了控制后悔的上限边界。数值实验展示了该方法的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22199", "html_url": "https://arxiv.org/abs/2506.22199", "title": "REDELEX：关系深度学习探索框架", "title_en": "REDELEX: A Framework for Relational Deep Learning Exploration", "authors": "Jakub Peleška,Gustav Šír", "background": "关系数据库（RDBs）被视为存储结构化信息的标准。因此，基于这种数据格式的预测任务具有重要的应用价值。近年来，关系深度学习（RDL）作为一种新兴范式出现，即将RDBs视为图结构，使得能够利用各种图神经网络架构来有效解决这些任务。但是，由于其新颖性，缺乏对各种RDL模型性能与其底层RDBs特性的关系分析。因此，本研究提供了一个名为REDELEX的综合探索框架，用于评估超过70个不同RDBs上的各种复杂度的RDL模型，并公开给社区进行基准测试。同时，该研究对比了经典方法的关键代表，确认了RDL的一般优越性能，并提供了影响性能的主要因素的见解，包括模型复杂度、数据库大小和结构特性等。", "innovation": "REDELEX是一个全面的探索框架，用于评估70多个不同RDBs上的各种复杂度的RDL模型。该研究对比了经典方法，确认了RDL的一般优越性能，并提供了对影响性能的主要因素（如模型复杂度、数据库大小和结构特性）的见解。这是第一个对RDL模型性能与其底层数据库特性进行系统分析的研究方法，填补了该领域的空白。", "conclusion": "REDELEX框架成功评估了各种复杂度的RDL模型在广泛多样化的RDBs上的性能。结果证实了RDL的良好表现，并揭示了性能的关键驱动因素，为未来的深入研究提供了宝贵的资源和见解。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22295", "html_url": "https://arxiv.org/abs/2506.22295", "title": "基于分数模型的低秩张量恢复", "title_en": "Score-Based Model for Low-Rank Tensor Recovery", "authors": "Zhengyun Cheng,Changhao Wang,Guanwen Zhang,Yi Xu,Wei Zhou,Xiangyang Ji", "background": "低秩张量分解（TDs）为多维数据分析提供了有效的框架。传统的张量分解方法依赖于预定义的结构假设，如CP或Tucker分解。从概率论的角度看，这些方法可以视为使用狄拉克δ分布来表示共享因子与低秩张量之间的关系。然而，在实践中，关于最优秩结构和合同规则的信息很少；基于固定合同规则的优化程序过程复杂，并且在这些过程中进行的近似通常会导致准确性损失。", "innovation": "本文提出了一种基于分数的模型，该模型消除了预定义的结构或分布假设的需要，使得能够学习张量和共享因子之间的兼容性。具体来说，设计了神经网络来学习能量函数，并通过分数匹配进行优化，以捕捉张量元素和共享因子联合对数概率的梯度。此外，该方法还允许建模超出狄拉克δ假设的结构和分布，并将块坐标下降（BCD）算法与提出的光滑正则化相结合，使模型能够进行张量完成和去噪。", "conclusion": "实验结果表明，该方法在各种类型的张量中，包括稀疏和连续时间张量以及视觉数据中，表现出明显的性能改进。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22129", "html_url": "https://arxiv.org/abs/2506.22129", "title": "使用集成方法结合先进机器和深度学习模型的地震损害等级预测", "title_en": "Earthquake Damage Grades Prediction using An Ensemble Approach Integrating Advanced Machine and Deep Learning Models", "authors": "Anurag Panda,Gaurav Kumar Yadav", "background": "在大地震之后，评估结构和基础设施的损坏至关重要，这对于协调灾后响应工作极为重要。包括评估损害的范围和分布，以优先进行救援操作和资源分配。准确估计地震后建筑物的损害等级对于有效的响应和恢复至关重要，因为这将对生命和财产产生重大影响，表明简化救援基金分配流程的紧迫性。先前的研究表明，多类分类法，特别是XGBoost，与其他机器学习模型和集成方法，结合正则化以解决类别不平衡问题，非常有效。类别不平衡的一个后果是，这可能导致具有偏向性的模型，轻视少数类并偏好多数类。本文针对类别不平衡问题，利用合成少数类过采样技术（SMOTE）进行研究。文中利用多种多类分类机器学习、深度学习模型和集成方法来预测结构损坏等级，并通过全面的特征操纵实验和多样化的训练方法阐述预测性能的影响因素。此外，通过混淆矩阵等技术评估模型性能，进一步提高对地震损害预测有效性的理解。", "innovation": "本文的主要创新在于利用合成少数类过采样技术（SMOTE）解决类别不平衡问题，并结合多种多类分类机器学习和深度学习模型进行地震损害等级的预测。通过全面的特征操纵实验和多样化的训练方法来增强模型的预测能力，并通过混淆矩阵等技术评估模型性能以提高地震损害预测的有效性。", "conclusion": "研究通过使用集成方法结合多种先进的机器学习和深度学习模型，有效地解决了地震后建筑物损害等级的预测问题。通过对不同模型的对比和特征分析，确定了影响地震脆弱性的关键因素，并通过混淆矩阵等技术优化了模型性能，从而提高了对地震损害预测的理解和预测准确性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22200", "html_url": "https://arxiv.org/abs/2506.22200", "title": "EFRame: 通过探索-筛选-重放强化学习框架实现更深层次的推理", "title_en": "EFRame: Deeper Reasoning via Exploration-Filtering-Replay Reinforcement Learning Framework", "authors": "Chen Wang,Lai Wei,Yanzhi Zhang,Chenyang Shao,Zedong Dan,Weiran Huang,Yue Wang,Yuzhi Zhang", "background": "最近在强化学习（RL）领域的进展显著增强了大型语言模型（LLMs）的推理能力。Group Relative Policy Optimization (GRPO)，一种更高效的PPO变体，虽然降低了RL的计算成本，但在探索、样本效率和稳定性方面仍存在问题，这限制了其在复杂推理任务中的表现。针对上述限制，研究人员引入了一种新的框架——探索-筛选-重放框架（EFRame），旨在系统性地从三个关键维度增强GRPO。该框架通过额外的rollout来探索高质量轨迹，使用在线筛选来消除噪声和引入方差的低质量样本，利用经验重用来重复利用稀有但具有信息性的样本。EFRame建立了一个完整且稳定的学习循环，引导模型从探索到收敛的过程。通过各种推理基准测试实验，作者证明了EFRame不仅提高了训练的鲁棒性和效率，还使一些在标准GRPO下难以实现的深层次推理能力变得可及，并且该框架还允许对不同类型的训练样本进行更细致的分类，从而更深入地分析它们对RL学习过程的贡献。相关代码可在此处获得：this https URL", "innovation": "提出的EFRame框架通过探索额外的rollout、在线筛选（消除低质量样本）以及经验重用来系统性地增强GRPO。该框架主要创新点包括：1）通过额外的rollout进行高质量轨迹的探索；2）使用在线筛选来去除低质量、低效的样本；3）利用经验重用来重复利用稀有但有价值的数据。这些机制共同形成了一个完整的且稳定的闭环学习循环，指导模型逐步从探索转为收敛。此外，EFRame还能够更细化地分类和分析训练样本的作用，从而促进更深入的RL学习过程理解。", "conclusion": "通过在各种推理基准测试中的实验验证，EFRame不仅提升了训练的稳健性和效率，还使深入的推理能力在标准GRPO下不可访问的情况变得可行。此外，EFRame框架还提供了一种更详细地分类训练样本的方法，有助于深入探究不同类型样本如何对RL学习过程产生影响。该项目的相关代码已被开源。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22331", "html_url": "https://arxiv.org/abs/2506.22331", "title": "Less Greedy Equivalence Search", "title_en": "Less Greedy Equivalence Search", "authors": "Adiba Ejaz,Elias Bareinboim", "background": "Greedy Equivalence Search (GES) 是一种基于评分的经典从观测数据中发现因果关系的算法。尽管在样本限制的情况下，它可以恢复描述数据的马尔可夫等价类图，但在实践中面临着计算成本高和有限样本准确性差的挑战。这项研究旨在开发 Less Greedy Equivalence Search (LGES) 作为 GES 的改进版本，以部分解决这些问题。", "innovation": "LGES 通过修改贪婪步骤，避免对无需条件独立性的变量进行边插入来更好地瞄准搜索，从而实现高达 10 倍的速度提升，并显著降低结构错误。此外，LGES 可以根据先验假设引导搜索，如果数据与这些假设相矛盾，还可以纠正这些假设。LGES 还能利用干预期数据来细化学习到的观察等价类。研究表明，在观测和干预期数据中，即使在先验假设被误分类的情况下，LGES 也能恢复真实的等价类。实验证明，LGES 在速度、准确性和对误分类假设的鲁棒性方面优于 GES 和其他基准算法。", "conclusion": "该研究通过引入 Less Greedy Equivalence Search (LGES) 算法，改进了 Greedy Equivalence Search (GES) 在计算效率和准确性方面的问题，尤其是在处理先验假设和利用干预期数据方面表现出色，证明了 LGES 在观测和干预期数据中的优势，在样本限制条件下能够正确恢复等价类，并且适用于各种假设情况下的提升因果发现能力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22374", "html_url": "https://arxiv.org/abs/2506.22374", "title": "基于Sheaf的分布式多模态学习用于下一代无线通信系统", "title_en": "Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems", "authors": "Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis", "background": "在大规模通信系统中，复杂的场景需要边缘设备通过协作收集多模态传感器数据，以全面理解环境并提高决策准确性。然而，传统的联邦学习（FL）算法通常只能处理单模态数据集，要求相同的模型架构，并且未能利用嵌入在多模态数据中的丰富信息，限制了其在具有多种模态和不同客户端能力的实际场景中的应用。", "innovation": "本文提出了一种新的分布式多模态学习框架——Sheaf-DMFL，利用Sheaf理论增强具有不同模态的设备之间的协作。每个客户端有不同的局部特征编码器，输出在任务特定层前进行拼接。在同一模态的编码器在客户端间协作训练时，使用基于Sheaf的结构捕捉客户端任务特定层之间的内在相关性。此外，还提出了一种增强算法Sheaf-DMFL-Att，通过在每个客户端中定制注意力机制来捕捉不同模态之间的相关性。文章提供了Sheaf-DMFL-Att的严格收敛分析，并通过在真实世界的链路阻塞预测和mmWave波束形成场景中进行广泛的仿真，证明了提出算法的优越性。", "conclusion": "实验结果表明，所提算法在异构无线通信系统中表现优越。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22376", "html_url": "https://arxiv.org/abs/2506.22376", "title": "概率最优性在推理时缩放中的应用", "title_en": "Probabilistic Optimality for Inference-time Scaling", "authors": "Youkang Wang,Jian Wang,Rubing Chen,Xiao-Yong Wei,Qing Li", "background": "推理时缩放已经证明是提升大型语言模型（LLMs）推理性能的强大技术。然而，现有方法通常依赖于平行采样的启发式策略，缺乏理论基础。", "innovation": "本文提出了一种概率框架，通过假设并行样本是独立同分布的，并且Best-of-N选择策略遵循可估计的概率分布，该框架提供了理论指导来确定达到目标性能所需的样本数量，从而为计算效率的缩放提供依据。基于此，开发了OptScale算法，能够动态确定最优采样响应数。OptScale利用基于语言模型的预测器估计概率先验参数，以满足预定义的性能阈值和置信水平所需的最小样本数量。实验表明，OptScale在减少采样开销的同时保持了与最新推理性能相当或更好的水平。", "conclusion": "本文不仅提供了一种理论基础还提出了一个实用的解决方案，以便为复杂的推理高效部署LLMs提供了新的思路，填补了现有方法的理论空缺。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22389", "html_url": "https://arxiv.org/abs/2506.22389", "title": "向分布式神经架构方向努力", "title_en": "Towards Distributed Neural Architectures", "authors": "Aditya Cowsik,Tianyu He,Andrey Gromov", "background": "本文介绍了并训练了在视觉和语言领域中的分布式神经架构（DNA）。这些架构以包括（变压器、MLP、注意力机制等）模块和路由器的原型架构初始化。任何标记或补丁都可以按任意顺序穿越任何模块序列。DNAs 是稀疏方法（如 Mixture-of-Experts、Mixture-of-Depths、参数共享等）的自然扩展。训练过程中，DNA 模块的计算和通信模式会根据每个标记或补丁的内容和上下文进行学习，这些模式可以通过进一步的目标优化进行调整，以实现计算/内存效率或负载均衡。实验结果表明，训练后的 DNAs 在两个领域内表现与密集基线相当，并且可以通过数据学习计算效率和参数共享。", "innovation": "本文的创新在于引入了分布式神经架构（DNA），这种架构以稀疏方法为基础，但在初始化后，其计算和通信模式会根据输入数据进行学习。这种架构对于处理大规模问题具备潜力，因为它仅在必要时激活所需的模块，从而提高效率。此外，通过进一步优化目标，DNAs 可以学习平衡计算和内存使用，以及实现负载均衡。", "conclusion": "实验结果显示，训练后的 DNAs 在视觉和语言领域中与密集基线相当。并且，DNAs 学会通过分布式路径和模块分配计算资源和活跃参数，展现出自适应的计算和通信模式。这些模型学会了以可解释的方式分配计算资源和活跃参数。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22304", "html_url": "https://arxiv.org/abs/2506.22304", "title": "使用Koopman算子展开生成流：快速且可解释的采样", "title_en": "Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling", "authors": "Erkan Turan,Aristotelis Siozopoulos,Maks Ovsjanikov", "background": "提出了一种名为CFM的框架，其用于训练连续时间生成模型，结合了扩散和流生成方法。然而，从CFM中采样仍然依赖于求解非线性常微分方程，这可能会消耗大量计算资源并难以解读。最近的替代方案通过轨迹直行、小批量耦合或蒸馏来加快采样速度。但这些方法通常不能揭示生成过程的内部结构。本文旨在通过引入Koopman算子理论来加速CFM，将非线性流动表示为可观测量学习空间中的线性演化，从而发展一种不依赖解码器的Koopman-CFM架构，能够通过矩阵指数运算实现闭式、一步采样。由于在控制的数据集和真实世界基准上的显著速度提升，该方法提供了以往方法不足的特性。此外，这种方法会产生一个结构良好的Koopman生成器，其谱特性、特征值和特征函数为分析生成行为提供了基础工具，包括时间缩放、模式稳定性和Koopman潜在空间中的分解。", "innovation": "引入了Koopman-CFM架构，结合Koopman算子理论，将非线性流动转化为可观测量学习空间中的线性演化，从而实现闭式、一步采样的快捷与可解析性。该方法显著优于传统CFM，特别是在控制数据集和真实世界基准上的测试结果得到体现。此外，该方法还为分析生成行为提供了一种新的结构化的工具，使其具有更深入的解析性。", "conclusion": "Koopman增强的流匹配方法通过结合采样效率与解析结构，向快速且可解释的生成建模迈进了一步。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22301", "html_url": "https://arxiv.org/abs/2506.22301", "title": "弱监督领域适应及其比例约束伪标签方法", "title_en": "Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling", "authors": "Takumi Okuo,Shinnosuke Matsuo,Shota Harada,Kiyohito Tanaka,Ryoma Bise", "background": "领域转移是机器学习中的一个重要挑战，尤其是在医疗领域，不同医疗机构由于数据收集方法、设备和流程的不同，导致数据分布差异。当模型在源领域数据上训练后，应用于目标领域时，这种差异会导致性能下降。为解决这一问题，已经广泛研究了领域适应方法，但大多数方法在源领域和目标领域之间类比例不同时表现不佳。因此，本研究提出了一种利用目标领域类比例信息的弱监督领域适应方法，这种方法通过比例约束伪标签为无标签目标数据分配伪标签，无需额外注释，即可提高性能。", "innovation": "提出了一种新的弱监督领域适应方法，该方法基于目标领域的类比例信息，通过比例约束伪标签为无标签目标数据分配伪标签，改善了领域适应性能，并且在目标领域只有5%数据标注的情况下仍然表现出色。此外，研究还展示了在比例标签噪声情况下的鲁棒性，进一步验证了方法在实际应用场景中的有效性。", "conclusion": "实验结果显示，该方法优于半监督领域适应技术，甚至在目标领域只有5%的样本被标注的情况下。此外，通过使用带噪声的比例标签进行实验，进一步证明了该方法在实际应用中的有效性和鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22342", "html_url": "https://arxiv.org/abs/2506.22342", "title": "一个用于多源隐私保护流行病分析的框架", "title_en": "A Framework for Multi-source Privacy Preserving Epidemic Analysis", "authors": "Zihan Guan,Zhiyuan Zhao,Fengwei Tian,Dung Nguyen,Payel Bhattacharjee,Ravi Tandon,B. Aditya Prakash,Anil Vullikanti", "background": "人们普遍认识到，多样化的数据集为关键的流行病学和公共卫生分析提供了大量价值，例如预测、实时监测、建立流行病模型、评估和设计干预措施及资源分配。其中一些数据集通常敏感，需要适当的隐私保护。虽然有很多隐私保护模型，但差分隐私（DP）已成为事实标准，因为它提供了强大的保证，而无需对对手模型做出假设。现有研究中，许多模型已经实现了DP保护下的流行病分析，但这些模型往往没有结合深度学习和机理流行病模型同时进行预测和学习。本文提出了一种框架，将深度学习和流行病模型结合起来，在确保隐私性的基础上，同时进行流行病预测和学习机理流行病传播模型。并且利用一个具有DP保护的真实但合成的金融数据集进行验证，展示了该数据集在流行病预测和学习模型中的巨大价值，即使在使用DP保护的情况下也是如此。", "innovation": "本文提出了一种同时结合深度学习和机理流行病模型的框架，以实现流行病预测和学习机理流行病传播模型，并且引入了在具有差分隐私保护的数据集上进行真实但合成的金融数据集验证的新方法，这是一种新颖的应用，展示了这种数据集在流行病分析中的潜在价值和适用性。", "conclusion": "通过本文提出的框架，能够在无需对对手模型做出假设的情况下同时进行流行病预测和学习机理流行病传播模型，并且利用具有差分隐私保护的数据集也能获得显著的预测和建模价值。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22393", "html_url": "https://arxiv.org/abs/2506.22393", "title": "医疗时间序列分析中稳健领域自适应的多视图对比学习", "title_en": "Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis", "authors": "YongKyung Oh,Alex Bui", "background": "在不同领域适应医疗时间序列数据建模中，复杂的时序依赖关系和动态分布移位是一个重大挑战。当前方法往往专注于孤立的特征表示，这限制了模型捕捉复杂的时序动态以实现稳健适应的能力。现有方法难以全面捕捉必要的时序动态，从而影响模型的适应性。", "innovation": "本文提出了一种新的框架，利用多视图对比学习来整合时序模式、基于微分的动态特性和频域特征。该方法采用独立编码器和分层融合机制，学习跨域传输不变的表示，同时保持时序一致性。实验结果显示，该方法在不同医疗数据集（如脑电图、心电图和肌电图）上的传输学习任务中显著优于现有最佳方法。", "conclusion": "通过提高机器学习模型的稳健性和通用性，本文框架提供了一种实用途径，用于在多种医疗保健环境中部署可靠的AI系统。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22365", "html_url": "https://arxiv.org/abs/2506.22365", "title": "基于物理启发符号程序先验的零样本室内无线导航强化学习", "title_en": "Reinforcement Learning with Physics-Informed Symbolic Program Priors for Zero-Shot Wireless Indoor Navigation", "authors": "Tao Li,Haozhe Lei,Mingsheng Yin,Yaqi Hu", "background": "在使用强化学习（RL）处理物理控制任务时，包含物理先验的归纳偏置有助于提高训练样本效率并在测试中增强泛化能力。然而，当前的做法需要大量的手动劳动和领域专业知识，使得这些有益的物理启发式归纳偏置很难普及给一般用户。因此，本文探讨了一种符号方法将物理启发的归纳偏置提炼到RL代理中，其中物理先验通过领域特定语言（DSL）表达，使语言具有人类可读性和易于解释的特点。然而，DSL先验不能直接转换为可实施的策略，因为导航任务中的部分和噪声观察以及附加的物理约束问题。为解决这一差距，本文开发了一种基于物理启发程序引导的RL（PiPRL）框架，应用于室内导航。PiPRL采用分层和模块化的神经符号集成，其中元符号程序从神经感知模块接收语义上有意义的特征，并以此为基础进行符号编程以编码物理先验并指导低级神经控制器的RL过程。", "innovation": "本文提出了一种基于物理启发程序引导的RL（PiPRL）框架，将其应用于室内导航任务。该框架通过将物理先验以人类可读的形式编码，并结合神经感知模块的语义特征，实现了分层和模块化的神经符号集成。这种方法显著提升了训练效率，并在与纯符号或神经策略的比较中表现更优。", "conclusion": "本文实验证明了PiPRL框架的有效性，在室内导航任务中，它不仅能提供更优秀的性能，还能减少超过26%的训练时间，有效解决了物理先验转换为可实施策略的技术难题。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22427", "html_url": "https://arxiv.org/abs/2506.22427", "title": "CLoVE：通过损失向量嵌入聚类实现个性化联邦学习", "title_en": "CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings", "authors": "Randeep Bhatia,Nikos Papadis,Murali Kodialam,TV Lakshman,Sayak Chakrabarty", "background": "在Federated Learning中，客户端自然地根据其数据分布被分组到不同的集群中。然而，确定这些集群是具有挑战性的，因为客户端的分组是未知的。现有的CFL算法在识别这些集群、集群内模型优化上可能存在局限性，需要近似最优的模型初始化，这在实际应用中较为困难且不够鲁棒。因此，提出了一种新的算法——CLoVE（Clustering of Loss Vector Embeddings），该算法基于客户端数据上的模型损失推导出客户端嵌入，并利用同一集群内的客户端具有相似的损失值而不同集群的客户端具有不同的损失模式的洞察，通过联邦聚合迭代地识别和分离来自不同集群的客户端，以及优化集群特定的模型。", "innovation": "CLoVE的主要创新点在于：1）算法简洁性；2）既适用于监督学习又适用于无监督学习的场景；3）完全消除了模型初始化步骤，使其更具有鲁棒性，更适合实际应用。此外，CLoVE还建立了理论收敛界限，证明了其在单轮中可以以高概率准确地恢复集群，并在线性设置下以指数速度接近最优模型。", "conclusion": "实验结果表明，CLoVE能够在几轮训练中实现高精度的集群恢复，同时在各类监督和无监督的PFL任务中取得最先进的模型准确率。CLoVE展示出了在Federated Learning尤其是CFL中的巨大潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22423", "html_url": "https://arxiv.org/abs/2506.22423", "title": "ARMOR: 在物理攻击下基于强化学习的无人机鲁棒控制", "title_en": "ARMOR: Robust Reinforcement Learning-based Control for UAVs under Physical Attacks", "authors": "Pritam Dash,Ethan Chan,Nathan P. Lawrence,Karthik Pattabiraman", "background": "无人驾驶飞行器（UAVs）依赖于机载传感器进行感知、导航和控制。然而，这些传感器容易受到物理攻击的影响，如GPS欺骗，这会破坏状态估计并导致不安全的行为。现有的安全强化学习（Safe RL）方法在应对这些攻击时效果不佳。因此，迫切需要一种能够在对抗传感器操纵的情况下保证无人机安全运行的鲁棒控制方法。", "innovation": "ARMOR是一种旨在增强鲁棒性的、无需模型的强化学习控制器，它可以在攻击下保障无人机的操作。ARMOR通过两阶段训练框架学习无人机的鲁棒潜状态表示：第一阶段使用带有先验攻击信息的教师编码器生成攻击意识潜状态，用于RL策略训练；第二阶段使用监督学习训练学生编码器，仅使用历史传感器数据来近似教师的潜状态，从而实现在无先验信息条件下的实际部署。这一方法显著提高了对未知攻击的泛化能力和降低了训练成本，通过省去了迭代对抗训练的需要。", "conclusion": "通过实验，ARMOR比传统的控制方法表现出更好的性能，确保了无人机的安全。此外，它提高了对未见攻击的泛化能力和降低了训练成本。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2212.09525", "html_url": "https://arxiv.org/abs/2212.09525", "title": "FreeEnricher: 不添加额外成本的面部标志物增强", "title_en": "FreeEnricher: Enriching Face Landmarks without Additional Cost", "authors": "Yangyu Huang,Xi Chen,Jongyoo Kim,Hao Yang,Chong Li,Jiaolong Yang,Dong Chen", "background": "近年来，面部对齐技术得到了显著的发展。虽然密集的面部关键点在许多场景中都非常需求，例如美容医学和面部美化，大多数研究仅考虑稀疏的面部对齐。本研究旨在通过引入一种基于现有稀疏关键点数据集的框架，来解决这一问题，从而提高关键点的密集程度，无需额外的数据或成本.", "innovation": "本研究提出了一种弱监督的方法，通过学习在原始稀疏关键点上进行精细化的能力，并将这种能力应用于增强后的密集关键点，这种方法不需要额外的监督信息或数据集。通过设计和组织几个操作来实现这一思想，并将其训练后的模型作为一个插件模块集成到现有的面部对齐网络中，从而提高面部地标识别的精度.", "conclusion": "在300W测试集上手动标注了密集的面部地标，结果表明，本方法在新建的密集300W测试集、原有的稀疏300W和WFLW测试集上均取得了最先进的准确率，且没有额外的成本。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.15194", "html_url": "https://arxiv.org/abs/2412.15194", "title": "MMLU-CF: 无污染的多任务语言理解基准", "title_en": "MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark", "authors": "Qihao Zhao,Yangyu Huang,Tengchao Lv,Lei Cui,Qinzheng Sun,Shaoguang Mao,Xin Zhang,Ying Xin,Qiufeng Yin,Scarlett Li,Furu Wei", "background": "多选题数据集（如大规模多任务语言理解MMLU）广泛用于评估大型语言模型（LLM）的常识、理解和问题解决能力。但由于这些基准和LLM的训练数据来源开放广泛，不可避免地会导致基准污染，从而导致不可靠的评估结果。因此，需要提出一种无污染且更具挑战性的多选题基准，以缓解这一问题。", "innovation": "本文提出了一种无污染且更具挑战性的多选题基准MMLU-CF，通过从更广泛的领域中获取数据并设计三种去污染规则来避免无意的数据泄漏，以及通过将基准划分为验证集和封闭源测试集来防止恶意数据泄漏。验证集公开可用以促进透明性和独立验证，测试集保持封闭源以确保可靠的评估结果。此外，评估结果显示GPT-4o在测试集上的5-shot得分仅为73.4%，0-shot得分仅为71.9%，证实了该方法在创建更严谨和无污染的评估标准方面的有效性。", "conclusion": "MMLU-CF为评估LLM的能力提供了更可靠的基准，通过其无污染的设计提高了模型评估结果的客观性和准确性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2109.05721", "html_url": "https://arxiv.org/abs/2109.05721", "title": "ADNet: 通过朝向正常方向利用误差偏置在面部对齐中的应用", "title_en": "ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment", "authors": "Yangyu Huang,Hao Yang,Chong Li,Jongyoo Kim,Fangyun Wei", "background": "近期，CNN在面部对齐性能方面取得了显著提高。然而，很少有工作关注与面部关键点误差分布相关的误差偏置问题。本文研究了面部对齐中的误差偏置问题，发现关键点误差的分布倾向于沿着关键点曲线的切线传播。这一误差偏置现象不简单，因为它与关键点的模糊标注任务密切相关。基于此观察，本文提出了一种等向性方向损失（ADL）和等向性注意力模块（AAM），以更好地促进CNN模型的收敛。ADL在面部边界上每个关键点的法向方向上施加强制力。另一方面，AAM是一种注意力模块，可以获取针对关键点及其相邻点连通的区域的等向性注意力掩码，它在切向方向上的反应较强，这意味着在切向方向上施加较弱的约束。这两种方法以互补的方式学习面部结构和纹理细节。最后，本文将它们整合到一个优化的一体化训练框架ADNet中。", "innovation": "本文提出了等向性方向损失（ADL）和等向性注意力模块（AAM），分别应用于坐标和热图回归。ADL在面部边界上的每个关键点的法向方向上施加强约束力。另一方面，AAM是一种注意力机制，能够获取针对关键点及其相邻点连通区域的等向性注意力掩码，在切向方向上的反应较强，这意味着在切向方向上施加较弱的约束。这两种方法配合使用，以同时学习面部结构和纹理细节。", "conclusion": "ADNet在300W，WFLW和COFW数据集上取得了最先进的成果，证明了其有效性和鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22401", "html_url": "https://arxiv.org/abs/2506.22401", "title": "从原始对偶视角探究：促进样本高效在线强化学习的价值激励型演员-评论家方法", "title_en": "Exploration from a Primal-Dual Lens: Value-Incentivized Actor-Critic Methods for Sample-Efficient Online RL", "authors": "Tong Yang,Bo Dai,Lin Xiao,Yuejie Chi", "background": "在线强化学习（RL）使用复杂的函数近似方法，如变压器和深度神经网络，在现代人工智能实践中发挥着重要作用。尽管在线RL因其流行性和重要性而受到重视，但如何平衡探索与利用的基本权衡仍然是一个长期存在的挑战。当前，还没有能提供理论性能保证的有效且实用的方案。受乐观正则化方法近年来发展的启发，本文从原始对偶优化的角度重新解释了乐观原则，并在此基础上提出了一个新的价值激励型演员-评论家（VAC）方法，该方法旨在通过优化一个易于优化的综合了探索和利用的目标函数来促进一致于采集的数据过渡和具有更高价值函数的状态-动作和策略估计，从而在有限增量和无限增量的线性马尔可夫决策过程中，理论拟合VAC方法具有接近最优的遗憾保证，并且在适当假设下可以扩展到一般函数近似的情况中。", "innovation": "从原始对偶优化的角度解释了乐观原则，并提出了一个新的价值激励型演员-评论家（VAC）方法，该方法能够通过优化一个易于优化的目标函数来综合探索和利用，并在其线性马尔可夫决策过程中具有接近最优的遗憾保证，并且在适当假设下可以扩展到一般函数近似的情况中。", "conclusion": "本文提出了一个新的价值激励型演员-评论家方法，该方法综合考虑了在线强化学习中的探索和利用，在线性马尔可夫决策过程中具有接近最优的遗憾保证。该研究对缺乏理论性能保证的在线强化学习方法提供了一个有效的解决方案。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21570", "html_url": "https://arxiv.org/abs/2506.21570", "title": "随机初始化无法赶超：语言模型转移在时间序列预测中的优势", "title_en": "Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting", "authors": "Roland Riachi,Kashif Rasul,Arjun Ashok,Prateek Humane,Alexis Roger,Andrew R. Williams,Yuriy Nevmyvaka,Irina Rish", "background": "近期研究表明，对于小数据集的环境，预训练语言模型（LMs）可以通过调整有效过渡到时间序列预测，从而提高预测效果。本文基于这些研究，探讨了不同设计选择对LMs向时间序列预测的有效过渡的影响，包括上游后训练、时间序列分词器和语言骨干网络大小等因素。在小数据集环境下，不同的设计选择对验证损失有着显著影响，某些特定选择表现优于其他选择。此外，本文还发现预训练的语言模型的验证损失在其收敛后仍会逐渐减小，这种现象与Hernandez等人的研究结果不同，进一步揭示了计算高效训练在时间序列预测中的应用", "innovation": "1. 通过分析多种设计选择对LMs向时间序列预测的有效过渡的影响，研究了在小数据集环境下的设计选择对验证损失的影响。\n2. 发现预训练LMs在训练后期继续表现出优异性能，验证损失持续下降，与随机初始化模型形成显著差距。\n3. 强调计算高效训练在时间序列预测中的优势，并提出研究跨模态数据分布性质的可能性", "conclusion": "本文的研究不仅有助于理解LMs在时间序列预测中的有效使用，也为研究这些模型利用跨模态数据分布的通用特性提供了新视角。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21566", "html_url": "https://arxiv.org/abs/2506.21566", "title": "背翻译在高质量低资源英孟加拉语机器翻译中的饱和点", "title_en": "The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation", "authors": "Arwa Arif", "background": "背翻译BT被广泛应用于低资源机器翻译MT中，利用单语语料库生成额外的合成训练数据。尽管这种方法在许多语言对中展现了强大的改进效果，但其在高质量低资源环境中的有效性仍然不清楚。在本研究中，我们探索了背翻译方法在使用多语言预训练MBART50模型进行英孟加拉语翻译中的效果。基线系统基于具有较高质量平行语料库的约50,000句对训练，在验证集上达到43.8的BLEU分数。通过对单语孟加拉语文本进行仔细筛选生成背翻译示例来增强数据。令人惊讶的是，增加这种合成数据并没有改善翻译性能，在某些情况下甚至还降低了它。我们使用BLEU、ChrF++、TER、BLEURT等多种指标对模型进行评估，并分析了这种饱和现象的可能原因。研究发现，背翻译可能在某些低资源环境中达到了边际效益递减的点，并讨论了对未来研究的影响", "innovation": "研究探索了背翻译在高质量低资源英孟加拉语机器翻译中的效果，并揭示了背翻译可能在某些低资源环境下达到边际效益递减的现象，这是对现有研究的拓展和补充", "conclusion": "背翻译可能在某些低资源环境中达到了边际效益递减的点，这表明在低资源环境下使用背翻译可能需要更加谨慎，未来研究需要探索解决这一问题的方法"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21545", "html_url": "https://arxiv.org/abs/2506.21545", "title": "语言模型培训中的数据效益", "title_en": "Data Efficacy for Language Model Training", "authors": "Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li", "background": "语言模型的训练依赖于数据。近期的研究致力于提高数据效率，通过选择最小或最优的训练数据集来最大化性能。数据过滤、采样和选择等技术在这一领域发挥重要作用，但对通过优化训练数据组织来提高性能的数据效益，研究相对较少.", "innovation": "本文提出了一个名为DELT的一般框架，用于考虑语言模型训练中的数据效益。DELT包括三个组成部分：数据评分、数据选择和数据排序。作者设计了Learnability-Quality Scoring (LQS) 作为数据评分的新实例，考虑了每个数据样本的可学习性和质量。还提出了Folding Ordering (FO) 作为数据排序的新实例，解决了模型遗忘和数据分布偏差等问题。这些方法在无需增加数据量和模型大小的情况下，提升了语言模型的性能，特别是在LQS和FO的结合上表现最为显著。此外，数据选择也可以和数据效益结合使用，共同提高语言模型的培训效果.", "conclusion": "数据效益是语言模型训练中的一个有前途的基础领域，其通过优化训练数据的组织，能够提高模型的性能而不增加数据量或模型大小。尤其是LQS和FO的结合，展示了显著的性能提升效果。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21565", "html_url": "https://arxiv.org/abs/2506.21565", "title": "受Kairanban风格CoT系统与Idobata对话启发的多智能体概率推理框架及其去偏见应用", "title_en": "A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing", "authors": "Takato Ueno,Keito Inoshita", "background": "日本的Kairanban文化和Idobata对话一直以来作为传统交流实践，促进了社区成员间细腻的对话，并有助于社会平衡的形成。这些信息交流过程启发了本研究，提出了一种多智能体推理框架（KCS+IBC），融合了多个大型语言模型，用于去偏见、提高解释性以及情感分析中的概率预测", "innovation": "提出了一种名为KCS+IBC的多智能体推理框架，该框架结合了多个大型语言模型，实现了情感分析中的偏见缓解、增强解释性和概率预测。框架引入了中间阶段的非正式对话环节，将正式推理与个人视角相结合，实现了情感预测的去偏见和解释性改进", "conclusion": "实验结果表明，KCS的准确度与单个大型语言模型相当；KCS+IBC在推理后期表现出熵的持续降低和差异度的逐渐增加，表明框架能够平衡预测聚集和多样性。未来研究将量化这些特性对去偏见的影响，并致力于开发更先进的情感分析系统"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21558", "html_url": "https://arxiv.org/abs/2506.21558", "title": "Bench to the Future: 一个用于预测代理的回溯性基准", "title_en": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents", "authors": "FutureSearch:Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips", "background": "预测是一项具有明显可衡量特性的任务，用于研究AI系统。由于需要大量的互联网研究，并且评估需要时间来验证事件结果，因此开发预测基准具有挑战性。到目前为止，没有基准能够为LLM预测器提供一个现实、封闭和可重复的环境。本文介绍了Bench To the Future (BTF)，这是一个由数百个高质量问题组成的回溯性基准，每个问题的结果已经明确知道。每个问题都附带一个庞大的离线网页语料库，含有数千篇相关网页，使从LLMs获取现实的“预测”成为可能。研究表明，BTF环境可以产生与基于互联网的预测相似的结果，尤其是在解决当时的未决问题上。通过利用多种LLMs（包括近期发布的Claude 4模型）对代理和因果链预测方法进行基准测试，证明了BTF能够追踪预测能力的稳定进展。我们希望这个基准能够不断发展，新增加的问题能够反映不断增加的训练数据截止日期。我们邀请研究人员通过hello@futuresearch.ai与我们联系，使用我们的基准和工具进行研究。", "innovation": "BTF提出了一个名为“回溯性”的新基准，包含大量已知答案的问题，这些问题是通过离线互联网语料库提出的，使预测任务得以通过预先可知的答案进行评估，从而在现实和封闭的环境下跟踪预测代理的进步。此外，它使用多个LLMs进行基准测试，特别是Claude 4模型，展示了随时间推移的预测能力的稳定进展。", "conclusion": "本文通过对BTF基准的介绍和实验结果，展示了如何在现实、封闭和可重复的环境中评估和跟踪预测代理的进步。未来，BTF将会不断更新，以适应新的训练数据。研究人员可以通过所提供的联系方式获得BTF基准和相关工具，以促进自己的研究。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21585", "html_url": "https://arxiv.org/abs/2506.21585", "title": "LLM策略从在线商店提取食品产品信息的评估", "title_en": "Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops", "authors": "Christoph Brosch,Sian Brumm,Rolf Krieger,Jonas Scheffler", "background": "生成式AI和大型语言模型（LLMs）为从网页中自动提取结构化信息提供了巨大潜力。本文重点关注在线零售商的食品产品页面，并探索基于模式约束的提取方法以检索关键产品属性，如成分列表和营养表。研究对比了基于LLM的两种直接提取和间接提取（通过生成函数）方法，并使用3,000个食品产品页面的数据集进行评估，这些页面来自于三个不同的在线商店。", "innovation": "研究引入了间接提取策略，并通过生成函数实现了LLM的间接调用。结果显示，间接方法在准确率上略低于直接方法（96.48%，比直接方法低1.61%），但显著减少了LLM的调用次数（减少95.82%），从而在效率和成本上有了大幅提升。这表明间接提取策略可为基于模板的网页大规模信息提取提供可扩展且成本效益高的解决方案。", "conclusion": "研究发现，间接提取策略能够提供一套可扩展且成本效益高的解决方案，能有效利用LLMs从模板网页中提取大规模信息。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21607", "html_url": "https://arxiv.org/abs/2506.21607", "title": "CORE-KG：一种基于LLM的人口走私网络知识图谱构建框架", "title_en": "CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人口走私网络越来越具有适应性和难以分析。法律案例文件提供了宝贵的见解，但这些文件是无结构的、语汇密度高且充满模糊或会变的参考，这对自动知识图谱(KG)构建提出了挑战。现有KG方法通常依赖静态模板，并缺乏同指消解。近年来，基于大语言模型(LLM)的方法虽然占据了上风，但由于幻觉和缺乏引导提取导致的重复节点，导致产出的KG片段且存在噪音。", "innovation": "我们提出了CORE-KG，一个用于从法律文本构建可解释KG的模块化框架。它使用两步管道：(1) 通过顺序结构化的LLM提示进行类型意识同指消解，和(2) 使用领域导向指令进行实体和关系提取，建立在改进的GraphRAG框架之上。CORE-KG通过减少节点重复33.28%和法律噪声38.37%，相比基于GraphRAG的基线，实现了更干净、更关联的图结构提高，使其成为分析复杂犯罪网络的强大基础。", "conclusion": "这些改进使得CORE-KG成为分析复杂犯罪网络的强大基础。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21599", "html_url": "https://arxiv.org/abs/2506.21599", "title": "下一POI推荐中强化微调的大语言模型", "title_en": "Reinforcement Fine-Tuned Large Language Models for Next POI Recommendation", "authors": "Peibo Li,Shuang Ao,Hao Xue,Yang Song,Maarten de Rijke,Johan Barthélemy,Tomasz Bednarz,Flora D. Salim", "background": "大语言模型（LLMs）已被用于下一个兴趣点（POI）推荐任务。典型的LLM推荐器分为两种类型：基于提示的模型和基于监督微调（SFT）的模型。基于提示的模型通常提供更大的输出灵活性，但准确性较低，而基于SFT的模型则达到更高的性能，但面临一个根本匹配问题：下一POI推荐数据并不天然适合监督微调。在SFT中，模型被训练以重现确切的真实数据，但每个训练示例仅为一个目标POI，这意味着没有生成top-k列表的真实数据。", "innovation": "我们提出了Refine-POI，一种强化微调框架，用于下一POI推荐。我们引入了推荐驱动的奖励，使LLMs能够仅使用每个示例一个真实的目标POI来学习生成top-k推荐列表。实验证明，Refine-POI在top-k推荐性能上达到了最先进的水平，解决了传统SFT方法中的根本性匹配问题。", "conclusion": "实验结果表明，Refine-POI在实际数据集上实现了顶级推荐性能，证明了我们提出的强化微调框架的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21604", "html_url": "https://arxiv.org/abs/2506.21604", "title": "评估VisualRAG：企业文档理解中的跨模态性能量化", "title_en": "Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding", "authors": "Varun Mannam,Fang Wang,Xin Chen", "background": "当前的多模态生成AI评估框架难以建立信任度，这阻碍了在需要可靠性的企业环境中采用这些技术。本文探讨了一个系统且量化的基准框架，用于测量VisualRAG系统在逐步集成包括文本、图像、描述和OCR在内的跨模态输入时的信任度，特别是在企业文档智能方面的应用。", "innovation": "本文提出了一种系统且量化的基准框架，用于量化和提升多模态RAG的信任度，特别是在企业关键应用中。通过定量分析技术指标与用户信任度之间的关系，本文发现最佳的模态加权方法（文本为30%，图像为15%，描述为25%，OCR为30%）可以在仅使用文本的基础上提高57.3%的性能，同时保持计算效率。此外，该研究还比较了基础模型在生成描述和OCR提取方面的影响，为可靠的企业AI应用提供了参考。", "conclusion": "本项研究推进了负责任的AI部署，通过提供一个多模态RAG量化和增强信任度的严格框架，为关键的企业应用提供了支持。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21590", "html_url": "https://arxiv.org/abs/2506.21590", "title": "representation_consistency_for_accurate_and_coherent_llm_answer_aggregation", "title_en": "Representation Consistency for Accurate and Coherent LLM Answer Aggregation", "authors": "Junqi Jiang,Tom Bewley,Salim I. Amoukou,Francesco Leofante,Antonio Rago,Saumitra Mishra,Francesca Toni", "background": "大型语言模型（LLMs）在推理过程中通过在推理时分配更多的计算预算来改善性能。现有方法通常需要对提示和采样策略进行复杂的修改来实现这一点。本文探讨了一种名为表示一致性（RC）的新方法，它可以在不需要对提示或采样策略进行复杂修改的情况下，通过聚合来自LLM多个候选响应的答案来提高模型性能。RC不仅考虑每个答案在候选响应集中的出现次数，还考虑模型在生成这些响应过程中内部激活的一致性。这种方法使用缓存的激活和轻量级的相似性计算，在不影响推理效率的情况下增强答案聚合能力。实验结果表明RC方法在四种开源LLMs和四种推理数据集上的任务性能改进显著，准确率提高了最多4%，且与传统的测试时扩展基线相比显示出了更好的一致性。研究还发现稀疏激活信号的连贯性与直观的连贯推理概念相符。", "innovation": "提出了一种名为表示一致性（RC）的方法，该方法可以在推理时聚合大型语言模型的多个候选答案，而不需对提示和采样策略进行复杂修改。RC不仅考虑每个答案的出现次数，还考虑模型生成每个答案过程中内部激活的一致性。这种方法使用缓存的激活和轻量级相似性计算，既提高了模型性能，又简化了计算过程。RC与传统的测试时扩展基线相比，显示了显著的准确性提升，并且稀疏激活信号的一致性与连贯推理概念相符。", "conclusion": "本文介绍的方法在多种开源大型语言模型和推理数据集上验证了其有效性，显著提高了任务性能，且无需额外的模型查询。此外，稀疏激活信号的一致性表现出良好的连贯推理特征，为LLM模型的推理过程提供了新的观点。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21603", "html_url": "https://arxiv.org/abs/2506.21603", "title": "自动化作文评分的人本化实现", "title_en": "Operationalizing Automated Essay Scoring: A Human-Aware Approach", "authors": "Yenisel Plasencia-Calaña", "background": "本文探讨了自动化作文评分（AES）系统的以人为本的操作化，不仅关注准确度，还研究了诸如偏见、稳健性和可解释性等重要方面。研究对比了基于机器学习的方法与大型语言模型（LLMs）的方法，发现了两者之间的优势、相似性和差异性。研究表明，基于机器学习的AES模型在准确度方面优于LLMs，但在可解释性方面存在问题。而LLMs能够提供更加丰富的解释，但在偏见和边缘分数的稳健性方面也很挣扎。这一研究旨在通过分析这些维度来识别不同方法面临的挑战和权衡，从而为更可靠和可信赖的AES方法贡献智慧。", "innovation": "本文创新地对比了基于机器学习的方法和大型语言模型的方法在自动作文评分中的表现，特别关注了准确度、可解释性、偏见和稳健性等多方面性能，提出了更可靠和可信赖的AES方法的路径。", "conclusion": "研究结果显示，基于机器学习的AES模型在准确度上优于LLMs，但在可解释性方面表现不佳。尽管LLMs在可解释性方面表现更好，但在偏见和边缘分数的稳健性方面也存在挑战。本文通过分析这些维度，明确了不同方法之间的挑战与权衡，为更可靠和可信赖的AES方法的发展提供了理论支持和实践指导。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21567", "html_url": "https://arxiv.org/abs/2506.21567", "title": "BioPars：针对波斯医学文本挖掘的预训练生物医学大型语言模型", "title_en": "BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining", "authors": "Baqer M. Merzah,Tania Taami,Salman Asoudeh,Amir reza Hossein pour,Saeed Mirzaee,Amir Ali Bengari", "background": "近年来，大型语言模型（LLMs）在生命科学领域引起了关注，因其能够处理复杂的生物信息，不仅限于作为聊天机器人使用，还逐渐应用于包括生物信息学在内的专业领域中的复杂分析和问题解决。该研究旨在评估LLMs在生物医学问题回答中的能力，特别是在波斯医学问题回答方面。为此，研究团队构建了一个包含生物医学文献、教科书和医学网站信息的数据集BIOPARS-BENCH，并开发了BioParsQA数据集以评估模型。研究通过比较ChatGPT、Llama和Galactica等模型，展示了它们在知识记忆和检索方面的表现，但也揭示了它们在高级和实际问题上存在的限制，这表明需要进一步的微调以提高LLM在生物信息学任务中的性能。", "innovation": "该研究提出了BioPars，这是一种新的评估大型语言模型在生物医学问题回答中能力的度量标准，特别适用于波斯医学任务。BioPars在多个医学问题回答数据集上取得了显著成果，其模型在BioParsQA数据集上的ROUGE-L得分为29.99，BERTScore为90.87，MoverScore和BLEURT也优于其他模型。BioPars是首个用于波斯医学问答的大型语言模型应用，尤其在生成长文本方面表现出色。这一研究成果为未来进一步开发和优化适用于波斯语医学领域的大型语言模型提供了重要参考和依据。", "conclusion": "研究发现，尽管存在一些限制，大型语言模型在波斯医学领域的问题回答上仍显示出一定的潜力。BioPars作为首个应用于波斯医学问答的大型语言模型，显著提升了模型在生成长文本方面的表现，并展示了其在该领域中的应用潜力。未来的研究将进一步优化和扩展BioPars的功能，以更好地服务于波斯医学领域的需求。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21573", "html_url": "https://arxiv.org/abs/2506.21573", "title": "白盒与黑盒大语言模型的学习范式：白盒与黑盒视角的双重考量", "title_en": "Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs", "authors": "Yanwei Ren,Liu Liu,Baosheng Yu,Jiayan Qiu,Quan Chen", "background": "优化大型语言模型（LLMs）的指令对于充分发挥其在复杂多变任务中的潜力至关重要。然而，仅依赖白盒方法需要大量的计算资源且代表能力有限，而黑盒模型可能带来高昂的费用开销。为解决这些挑战，本研究提出了一种新的框架，该框架无缝融合了两者的优点。黑盒模型提供高质量且多样的指令初始化，而白盒模型则通过隐藏状态和输出特征提供了精细的可解释性。通过施加语义相似度约束，这些组件融合为一个统一的高维表示，能够捕捉深层次的语义和结构细微差别，从而使迭代优化过程得以进行，以提高指令质量和适应性。广泛的任务评估，涵盖了从复杂推理到跨语言泛化的范围，证明了本方法在与最先进的基线方法相比时，表现出了一致的优越性。这种黑盒初始化与高级语义细化的融合提供了一种可扩展且高效的解决方案，为下一代基于LLM的应用开辟了新的道路。", "innovation": "该研究提出了一种新的框架，无缝融合了白盒和黑盒模型的优点。具体而言，这种方法利用黑盒模型进行高质量的指令初始化，并结合白盒模型提供精确的可解释性。通过施加语义相似度约束，这两种模型的组件融合为一个统一的高维表示，从而实现了深层次的语义和结构把握，进而支持迭代优化过程进行优化，提高指令质量与适应性。此外，这种方法能够为下一代LLM驱动的应用提供可扩展且高效的解决方案，并能够有效应对上述白盒与黑盒方法各自存在的挑战。", "conclusion": "该方法在广泛的任务评估中显示出了一致的优势，并且其融合了黑盒初始化和高级语义细化的特点为基于LLM的下一代应用程序提供了可扩展且高效的解决方案。源代码即将公开。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21611", "html_url": "https://arxiv.org/abs/2506.21611", "title": "多模态是否会提高时间序列预测？", "title_en": "Does Multimodality Lead to Better Time Series Forecasting?", "authors": "Xiyuan Zhang,Boran Han,Haoyang Fang,Abdul Fatir Ansari,Shuai Zhang,Danielle C. Maddix,Cuixiong Hu,Andrew Gordon Wilson,Michael W. Mahoney,Hao Wang,Yan Liu,Huzefa Rangwala,George Karypis,Bernie Wang", "background": "近年来，将文本信息集成到时间序列预测的基础模型中引起了广泛的关注。但是，目前尚不清楚这种多模态集成是否能在所有情况下一致地提高预测性能，以及在什么条件下可以达到最好效果。本文通过系统地在涵盖健康、环境和经济等多个领域的时间序列预测任务中评估两种不同的多模态预测范式来深入研究这些问题。", "innovation": "本文发现了多模态方法在特定条件下可以帮助提高预测性能的具体条件。这包括文本模型的性能较高、时间序列模型性能相对较弱以及适配的策略恰当。此外，文章还指出，在数据方面，如果数据量充足且文本提供了时间序列已经捕获之外的预测信号，则多模态方法更容易表现出额外的改进效果。这些发现对于指导实际应用中的多模态集成具有重要意义。", "conclusion": "研究结果强调，在模型构建方面，集成文本信息的效果在（1）高容量文本模型、（2）相对较弱的时间序列模型、以及（3）适配策略得当时最为显著。在数据方面，性能改进更可能发生在（4）拥有丰富训练数据和（5）文本提供了时间序列未能捕捉到的额外预测信号时。此研究为何时可以期望多模态技术在预测任务中发挥作用，以及何时可能不会有帮助提供了实用的指导建议。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21623", "html_url": "https://arxiv.org/abs/2506.21623", "title": "基于NLP的消费者投诉评价和文本生成中多样评价指标的性能", "title_en": "Performance of diverse evaluation metrics in NLP-based assessment and text generation of consumer complaints", "authors": "Peiheng Gao,Chen Yang,Ning Sun,Ričardas Zitikis", "background": "机器学习（ML）显著推动了文本分类的发展，实现了复杂、无结构文本数据的自动理解和分类。然而，准确捕获自然语言中细微的语言模式和上下文变化，特别是在消费者投诉中的应用，仍然是一个挑战。本研究通过引入基于人类经验训练的算法，有效识别出评估消费者救济资格至关重要的微妙语义差异，解决了上述问题。此外，还提出了结合使用合成数据生成方法，这种方法利用专家评估的生成对抗网络，并通过专家注释进行优化。将专家训练分类器与高质量合成数据结合，旨在显著提升机器学习分类器性能、降低数据集获取成本，并改进文本分类任务的整体评估指标和鲁棒性等方面的表现。", "innovation": "引入了基于人类经验训练的算法，有效识别微妙语义差异；提出了结合使用合成数据生成方法，利用专家评估的生成对抗网络，并通过专家注释进行优化，以提升机器学习分类器性能，降低数据集获取成本，提高文本分类任务的整体评估指标和鲁棒性", "conclusion": "通过结合专家训练分类器和高质量合成数据，本研究显著提升了机器学习分类器在文本分类任务中的性能，减少了数据集获取成本，并提高了整体评估指标和鲁棒性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21681", "html_url": "https://arxiv.org/abs/2506.21681", "title": "TanDiT: 像素平面扩散变换器用于高质360°全景图生成", "title_en": "TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360° Panorama Generation", "authors": "Hakan Çapuk,Andrew Bond,Muhammed Burak Kızıl,Emir Göçen,Erkut Erdem,Aykut Erdem", "background": "近年来图像生成技术取得了显著进步，尤其在合成视角图像方面。但这些模型在生成全景图像时遇到了独特挑战，包括几何失真的变化和无缝环视一致性需求。", "innovation": "TanDiT引入了一种新颖的方法，通过生成覆盖整个360°视角的切平面图像网格来合成全景场景。这种方法利用了一个统一的扩散模型，在单次去噪迭代中同时生成这些切平面图像，不同于之前依赖多个扩散分支的方法。此外，还提出了一种模型无关的后处理步骤，专门用于增强生成的全景图的全局连贯性。为了准确评估全景图像质量，还提出了两种专门的度量标准：TangentIS和TangentFID，并提供了包含标注全景数据集和标准化评估脚本的基准测试。", "conclusion": "大量的实验表明，该方法能够有效泛化，理解细致和复杂的文本说明，并与各种生成模型无缝集成，生成高质量和多样化的全景图像。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21581", "html_url": "https://arxiv.org/abs/2506.21581", "title": "评估密集检索器在跨学科领域的稳健性", "title_en": "Evaluating the Robustness of Dense Retrievers in Interdisciplinary Domains", "authors": "Sarthak Chaturvedi,Anurag Acharya,Rounak Meyur,Koby Hayashi,Sai Munikoti,Sameera Horawalavithana", "background": "评价标准特征可能会扭曲检索模型在特定领域中的真正优势。这会导致不准确的评估结果，进而影响专门领域的部署决策。研究发现，具有显著不同特征的两个基准测试（如主题多样性、边界重叠和语义复杂性）会影响微调效果的感知差异。利用环境监管文档检索作为案例研究，作者对来自联邦机构的环境影响声明（EIS）进行ColBERTv2模型的微调。通过使用两个具有不同语义结构的基准测试进行评估，发现相同的领域适应方法在不同的测试方法下表现出不同的效能获益。在一个具有清晰主题边界的基准中，领域适应仅带来微小改进（最大0.61%的NDCG提升）。而在另一个具有重叠语义结构的基准中，相同的模型则表现出显著的改进（最高达2.22%的NDCG提升），这是效能收益的3.6倍之差。通过主题多样性指标对比这两个基准，研究发现表现较好的基准显示出11%更高的平均余弦距离和23%更低的轮廓得分，直接导致观察到的性能差异。这些结果表明，基准选择强烈决定了检索系统在专门领域的有效性评估。具有明确主题分离的评估框架经常低估领域适应效应，而具有重叠语义边界的评估框架则揭示了更加接近真实世界监管文档复杂性的改进。", "innovation": "研究揭示了在具有显著不同特征的两个基准测试下，相同的领域适应方法在不同评估标准下的效能差异。通过提出具体案例研究（环境监管文档检索），研究展示了主题多样性及语义复杂性如何显著影响模型的绩效评估，并强调了选择合适基准对效果评价的重要性。", "conclusion": "基准选择对评估检索系统在复杂领域中的有效性有重要影响。含有明确主题分离的评估框架可能低估领域适应效益，而具有重叠语义边界的评估框架能更好地反映实际监管文档的复杂性并显示出实际改进。研究结果对跨学科领域中整合多种议题的AI系统开发与部署具有重要启示。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21630", "html_url": "https://arxiv.org/abs/2506.21630", "title": "TOMD: 基于路径的离磕多模态数据集，适用于具有挑战性光照条件下的可通行路径分割", "title_en": "TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions", "authors": "Yixin Sun,Li Li,Wenke E,Amir Atapour-Abarghouei,Toby P. Breckon", "background": "在非结构化的户外环境中检测可通行路径依然是自主机器人面临的重要挑战，尤其在广域搜索与救援以及森林火灾等应急管理场景中。现有的数据集和模型主要集中在城市环境或宽广的可通行越野路段，缺乏应对狭窄的、类似路径的越野场景的能力。", "innovation": "本文提出了Trail-based Off-road Multimodal Dataset (TOMD)，专为这些复杂环境设计的高保真多模态传感器数据集，包括128通道LiDAR、立体图像、GNSS、IMU和光照测量。并且提出了一个动态多尺度数据融合模型，用于精确预测可通行路径。此外，研究还分析了不同光照水平下早期、交叉和混合融合策略的表现，证明了光照条件在分割性能中的重要性。", "conclusion": "研究验证了TOMD在面对复杂光照条件时的有效性，并公开发布数据集以促进未来在基于路径的越野导航方面的研究。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21732", "html_url": "https://arxiv.org/abs/2506.21732", "title": "基于姿态信息的强化学习在滑移转向视觉导航中的实验研究", "title_en": "Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation", "authors": "Ameya Salvi,Venkat Krovi", "background": "基于视觉的道路车道保持一直受到机器人学和自主地面车辆社区的广泛关注，并应用于各类道路和非道路环境。滑移转向车辆架构在人类操控操作中是有用的平台。但在非道路环境中的滑移拖曳车轮与地形的系统建模仍然存在瓶颈。端到端学习方法，如模仿学习和深度强化学习，已经因其适合替代准确分析模型的缺乏被作为可行方案，但动态操作环境（特别是对滑移转向车辆），其系统建模和验证仍然是值得探讨的主题。", "innovation": "本文提出并研究了一种新颖的结构化学习方法，用于视觉导航任务。通过广泛的软件仿真、硬件评估和消融研究，证实了该方法在动态操作模式中，特别是在滑移转向车辆上的显著性能提升，超越了现有文献中的相关研究。", "conclusion": "经过综合分析软件仿真、硬件测试和消融研究，本文提出的结构化视觉导航学习方法显著提升了性能，为滑移转向车辆的自主导航提供了新策略与框架。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21628", "html_url": "https://arxiv.org/abs/2506.21628", "title": "Ark: 一种基于Python的开源机器人学习框架", "title_en": "Ark: An Open-source Python-based Framework for Robot Learning", "authors": "Magnus Dierking,Christopher E. Mower,Sarthak Das,Huang Helong,Jiacheng Qiu,Cody Reading,Wei Chen,Huidong Liang,Huang Guowei,Jan Peters,Quan Xingyue,Jun Wang,Haitham Bou-Ammar", "background": "尽管机器人硬件取得了显著进步，如DARPA的城市和机器人挑战，以及首个类人机器人格斗锦标赛，但商业自主性在机器学习进展方面仍然落后。当前的机器人堆栈要求陡峭的学习曲线、低级C/C++专业知识、碎片化的工具和复杂的硬件集成，这与以Python为中心、文档详尽的生态系统形成了鲜明对比。当前的机器人开发存在软件瓶颈。", "innovation": "我们引入了ARK，这是一个开源的、以Python为主的机器人框架，旨在弥合这一差距。ARK提供了一种类似Gym的环境接口，允许用户收集数据、预处理数据并使用最先进的模拟学习算法（如ACT、扩散策略）训练策略，同时可平滑切换到高保真模拟和物理机器人。轻量级的客户-服务器架构提供网络发布-订阅通信，必要时支持C/C++绑定以确保实时性能。该框架附带可重用的控制、SLAM、运动规划、系统识别和可视化模块，并与ROS原生互操作性。详细的文档和案例研究表明快速原型设计、无缝硬件切换和端到端管道，这些管道与主流机器学习工作流的便利性相媲美。", "conclusion": "通过将机器人和人工智能实践统一到一个共同的Python伞下，ARK降低了入门门槛并加速了自主机器人在科研和商业部署中的应用。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21638", "html_url": "https://arxiv.org/abs/2506.21638", "title": "IRanker：向量化排序基础模型", "title_en": "IRanker: Towards Ranking Foundation Model", "authors": "Tao Feng,Zhigang Hua,Zijie Lei,Yan Xie,Shuang Yang,Bo Long,Jiaxuan You", "background": "排序任务在推荐系统、LLM路由和项目重排序中广泛存在。传统的做法是针对每个特定的排序任务设计不同的模型，但这种方法既复杂又效率低下。本研究旨在通过一个统一的排序基础模型来简化这些任务，减少对不同模型的重复开发与管理。然而，排序任务缺乏明确的监督标签，使得开发此类基础模型面临巨大挑战。本文将引入一种新的排序基础模型框架IRanker，通过强化学习（RL）和迭代解码来解决这一问题。", "innovation": "提出了一种基于强化学习的迭代排序基础模型框架IRanker，通过将复杂的排序任务分解为迭代解码过程，逐步消除候选池中最差的候选者，减少了输出组合空间，更好地利用了有限的上下文长度。与同类大小的模型相比，IRanker-3B在多个数据集上达到了最先进的性能，并在某些数据集上甚至超越了更大模型的表现。此外，IRanker-3B在跨领域通用LLM任务上也表现出色，特别是在GSM8K、IFEval和MathQA上至少比基模型高出9%的性能。在零样本通用化测试中，IRanker-3B也能进一步提升基模型的表现，并展示了其在不同规模的LLM中的鲁棒性。", "conclusion": "IRanker-3B在不同的排序场景中展现了强大的性能和广泛的应用潜力，尤其是在推荐、路由和段落排序等任务上，甚至在跨领域的通用LLM任务上也表现出优异的零样本通用化能力。进一步的研究将以IRanker为基础，探索其在更多领域中的应用前景。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21720", "html_url": "https://arxiv.org/abs/2506.21720", "title": "CaloHadronic：高粒度成像 calorimeter 系统中产生综合性粒子花束的扩散模型", "title_en": "CaloHadronic: a diffusion model for the generation of hadronic showers", "authors": "Thorsten Buss,Frank Gaede,Gregor Kasieczka,Anatolii Korol,Katja Krüger,Peter McKeown,Martina Mozzanica", "background": "在粒子物理应用中，模拟高粒度 calorimeter 中的粒子束是一大挑战。准确而快速地使用生成性机器学习模型进行模拟，可以补充传统模拟方法并解决计算瓶颈问题。最近的研究表明，基于扩散的生成模拟方法可以不依赖固定结构，而是生成几何独立的点云，从而实现高效性。然而，此前的方法主要针对仅电磁花束的模拟，没有涵盖复杂的强子花束及其在电磁和强子 calorimeter 中的综合模拟需求。", "innovation": "本文提出了对前一架构的 transformer 基础扩展，专门用于国际大型探测器 ILD 中高粒度电磁 calorimeter 的电磁花束模拟。注意力机制使得该模型能够生成具有更多子结构特征的复杂强子花束，同时覆盖电磁和强子 calorimeter，这是首次使用机器学习方法全面模拟电磁与强子花束在高粒度成像 calorimeter 系统中的花束生成。", "conclusion": "CaloHadronic 模型在高粒度成像 calorimeter 系统中实现了首次基于机器学习的电磁和强子花束综合生成。这种方法的引入为粒子物理学的数据模拟和加速器实验提供了更有效、更准确的工具，同时解决了传统模拟方法中的计算资源密集性问题。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21624", "html_url": "https://arxiv.org/abs/2506.21624", "title": "DCN^2：编码隐式碰撞权重与显式交叉层用于大规模推荐", "title_en": "DCN^2: Interplay of Implicit Collision Weights and Explicit Cross Layers for Large-Scale Recommendation", "authors": "Blaž Škrlj,Yonatan Karni,Grega Gašperšič,Blaž Mramor,Yulia Stolin,Martin Jakomin,Jasna Urbančič,Yuval Dishi,Natalia Silberstein,Ophir Friedler,Assaf Klein", "background": "Deep and Cross架构（DCNv2）是一种稳健的生产基础模型，在许多实际的推荐系统中起着核心作用。它因内在的高效性和对交互的建模能力，使得构建的模型既简单又具有高度竞争力，相比之下，更为计算密集的选择如Deep FFMs则不然。本文基于此背景介绍了对DCNv2架构的三项重要算法改进，这些改进在大规模应用中展现了显著效果，在多个使用场景下优于DCNv2，无论是离线测试还是在线实验（A/B测试）都表现突出。改进措施解决了DCNv2中观察到的关键限制，包括交叉层中的信息丢失、通过可学习的查找级别权重隐式管理碰撞的机制，以及通过自定义层明确建模成对相似性，模仿FFMs的行为。", "innovation": "在DCNv2的基础上，提出了三项重要的算法改进，形成了新的架构DCN^2。这些改进能够有效解决DCNv2中存在的关键问题，包括交叉层的信息丢失、通过可学习的查找级别权重隐式管理碰撞、明确建模成对相似性。结果表明，DCN^2在超过四种公开的基准数据集上的表现优于DCNv2。改进后的架构在事实上被应用于一个实时推荐系统，每秒处理超过5亿次预测，且在多种场景中表现优异，超越了DCNv2。", "conclusion": "本文通过改进DCNv2架构，提出了一个名为DCN^2的新方法，该方法通过编码隐式碰撞权重和显式交叉层显著提高了推荐系统的性能。实验证明DCN^2优于DCNv2，并且在多种场景中处理速度快，效果好。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21739", "html_url": "https://arxiv.org/abs/2506.21739", "title": "使用时间依赖SIR模型中FIR滤波器的一种数值方法改进", "title_en": "Modification of a Numerical Method Using FIR Filters in a Time-dependent SIR Model for COVID-19", "authors": "Felipe Rogério Pimentel,Rafael Gustavo Alves", "background": "在没有疫苗且唯一防止感染的方法是隔离的情况下，该研究利用有限冲激响应（FIR）线性系统过滤方法来追踪并预测新冠肺炎感染者和康复者的人数。作者采用了一种时间依赖的离散SIR模型来构建FIR滤波器，并使用岭回归（一种带有正则化的经典优化问题）来估计滤波器系数。这些估计出的系数被称为岭系数。", "innovation": "作者提出了一种对陈等人算法的小修改，以得到岭系数。使用修改后的算法在巴西米纳斯吉拉斯州，在疫情初期的预测窗口内跟踪并预测了新冠肺炎感染者和康复者的人数。此外，还将预测数据与实际数据进行比较，以检查拟合程度。在一些模拟中，使用修改后的算法得到的数值结果的逼近误差比陈等人算法更好，作者通过调整FIR滤波器阶数和正则化参数的不同设定获得了改进效果。", "conclusion": "通过修改算法中的FIR滤波器阶数和正则化参数设定，作者改进了最初的数值方法，这种方法在预测新冠肺炎感染者和康复者人数方面显示出了更好的逼近效果。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21734", "html_url": "https://arxiv.org/abs/2506.21734", "title": "层次推理模型", "title_en": "Hierarchical Reasoning Model", "authors": "Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori", "background": "推理是制定和执行复杂目标导向动作序列的过程，仍然是人工智能的关键挑战。当前大型语言模型（LLMs）主要依赖于链式思考（CoT）技术，但这些技术存在任务分解脆弱、大量数据需求和技术延迟等局限性。受人脑层次化和多时间尺度处理机制的启发，本文提出了层次推理模型（HRM），这是一种新型递归架构，在保持训练稳定性和效率的同时，达到了显著的计算深度。HRM可以在单次前向计算过程中执行顺序推理任务，无需明确监督中间过程，通过两个相互依赖的递归模块来实现：一个高级模块负责慢速的抽象规划，一个低级模块处理快速的详细计算。", "innovation": "HRM是一个基于两个递归模块——高级模块和低级模块的新颖递归架构。它在仅2700万参数的情况下，在仅使用1000个训练样本的情况下对复杂的推理任务表现出色，无需任何预训练或链式思考的数据。此外，HRM在具有挑战性的任务上表现出色，包括复杂的数独谜题和大型迷宫中的最佳路径寻找，甚至在具有更长上下文窗口的更大模型上表现得更好，在抽象和推理语料库（ARC）上的表现也超过了更大的模型，ARC是一个衡量通用人工智能能力的关键基准。", "conclusion": "这些结果印证了HRM在通用计算和通用推理系统方面的潜在变革性进步。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21741", "html_url": "https://arxiv.org/abs/2506.21741", "title": " Critically-Damped Higher-Order Langevin Dynamics", "title_en": "Critically-Damped Higher-Order Langevin Dynamics", "authors": "Benjamin Sterling,Chad Gueli,Mónica F. Bugallo", "background": "Denoising Diffusion Probabilistic Models是一种尚未被完全探索的新一代生成AI方法。尽管Critically-Damped Langevin Dynamics (CLD)和Critically-Damped Third-Order Langevin Dynamics (TOLD++)成功引入了临界阻尼技术，但截止到目前尚未被应用于任意高阶的动力学系统。Higher-Order Langevin Dynamics (HOLD)是一种最近的先进扩散方法，但尚未引入临界阻尼的概念。", "innovation": "本文提出了将临界阻尼概念引入Higher-Order Langevin Dynamics (HOLD) 中的方法，从而拓展出Critically-Damped Higher-Order Langevin Dynamics (CD-HOLD)，这为扩散动力学提供了更先进的方法和全新的理解角度。", "conclusion": "该研究扩展了Higher-Order Langevin Dynamics，通过引入临界阻尼的概念，为扩散模型的生成AI方法提供了新的可能性，虽然处于初步探索阶段，但仍展现出巨大的研究潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21772", "html_url": "https://arxiv.org/abs/2506.21772", "title": "使用蒙特卡洛树搜索寻找雷达目标检测的高效深度架构", "title_en": "Searching Efficient Deep Architectures for Radar Target Detection using Monte-Carlo Tree Search", "authors": "Noé Lallouet,Tristan Cazenave,Cyrille Enderli,Stéphanie Gourdin", "background": "近期研究工作证明，深度神经网络在雷达目标检测中表现出色，特别是在存在杂波或干扰、多目标场景等复杂环境中。然而，这些网络通常计算复杂度很高，这限制了它们在嵌入式雷达系统中的广泛应用。", "innovation": "本文提出了基于蒙特卡洛树搜索（MCTS）的新型神经架构搜索（NAS）方法，旨在发现能够在保持所需检测性能的同时降低计算复杂度的神经网络架构。研究还评估了所搜寻到的架构在内杂波回波信号上的性能指标和泛化能力，并提出了一种新型网络，该网络不仅满足了所需的检测概率，而且比专家设计的基本网络轻得多。", "conclusion": "所提出的基于MCTS的方法能够有效搜索出高效且具有良好泛化能力的雷达目标检测网络。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21743", "html_url": "https://arxiv.org/abs/2506.21743", "title": "风暴潮之色彩：RGB编码的物理感知深度学习在风暴潮预报中的应用", "title_en": "Storm Surge in Color: RGB-Encoded Physics-Aware Deep Learning for Storm Surge Forecasting", "authors": "Jinpai Zhao,Albert Cerrone,Eirik Valseth,Leendert Westerink,Clint Dawson", "background": "风暴潮预测在沿海灾害准备中起着至关重要的作用，然而现有的机器学习方法普遍存在空间分辨率有限、依赖沿岸站点数据以及泛化能力差等缺点。此外，许多之前的模型直接处理非结构化的空间数据，这使得它们与现代深度学习架构不兼容。现有的模型在应用上的直接限制，阻碍了它们更好地满足灾害预防的需求。", "innovation": "本文提出了一种创新的方法，该方法将非结构化的水位字段投影到结构化的红绿色蓝（RGB）编码图像表示上，使得卷积长短期记忆（ConvLSTM）网络能够在端到端的基础上进行时空风暴潮预测。该模型进一步整合了真实的风场作为动态控制信号，并引入地形-海底地形作为静态输入，捕捉了风暴潮演进的物理意义驱动因素。该研究通过结合结构化的表示、物理依据的激励以及可扩展的深度学习方法，推动了风暴潮预测在使用性、适应性和可解释性方面的前沿发展。", "conclusion": "在墨西哥湾大规模合成风暴数据集上，我们的方法在德克萨斯沿岸多个地区显示出了稳健的48小时预测性能，并且在空间扩展性方面表现出色，可以应用于其他沿海地区。该研究通过结合结构化的表示，物理依据的激励，以及可扩展的深度学习方法，进一步促进了风暴潮预测技术的发展。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21748", "html_url": "https://arxiv.org/abs/2506.21748", "title": "使用扩散模型进行衍射超表面的逆向设计", "title_en": "Inverse Design of Diffractive Metasurfaces Using Diffusion Models", "authors": "Liav Hen,Erez Yosef,Dan Raviv,Raja Giryes,Jacob Scheuer", "background": "超表面是一种超薄的光学元件，由微结构设计而成，能够精确控制光。逆向设计是指确定特定几何形状以达到所需光学响应的过程。由于结构和光学性质之间复杂的非线性关系，这一过程充满挑战，通常需要专家进行调优、容易陷入局部最小值，并涉及大量的计算资源。本文通过将生成扩散模型的能力整合到计算设计工作流程中来解决这些问题。利用RCWA仿真器生成训练数据，包括超表面几何结构及其对应的远场散射图案。然后，训练一个条件扩散模型，该模型能够根据目标空间功率分布来预测超构原子的几何形状和高度。训练完成后，模型可以生成具有低误差的超表面，既可以使用RCWA引导的后验采样直接生成，也可以作为传统优化方法的初始化器。本文在空间均匀强度分束器和偏振分束器设计中展示了这一方法，并均在不到30分钟的时间内以低误差生成它们。为了支持进一步的数据驱动超表面设计研究，我们将代码和数据集公开发布。", "innovation": "本文创新地将生成扩散模型的特性融入到超表面逆向设计工作流程中。通过利用RCWA仿真器生成训练数据，训练条件扩散模型来预测超构原子的几何形状和高度，从而解决传统方法中存在的复杂性、容易陷入局部最小值和大量计算时间的问题。这种方法能够高效且精确地生成具有所需特性的超表面，为未来的研究提供了强有力的方法支持。", "conclusion": "本文通过结合生成扩散模型和RCWA仿真器，成功地实现了超表面的逆向设计。所提出的模型能够在较短的时间内准确生成具有所需特性的超表面，而无需复杂的调整过程，为数据驱动的超表面设计提供了一种有效的新方法。这一框架为未来的超表面设计提供了重要支持，并且所公开的代码和数据集将促进进一步研究。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21795", "html_url": "https://arxiv.org/abs/2506.21795", "title": "使用XLNet在社交媒体上检测攻击性语言", "title_en": "Offensive Language Detection on Social Media Using XLNet", "authors": "Reem Alothman,Hafida Benhidour,Said Kerrache", "background": "社交媒体上的文本通信（如聊天、评论和微博）虽然提高了用户互动，但也导致了攻击性内容的增加，包括仇恨言论、种族主义和其他形式的骚扰。由于用户生成的内容量巨大，手动审核不可行，因此需要自动系统来检测攻击性语言。深度学习模型（尤其是利用迁移学习的模型），在大规模预训练后展示出理解自然语言的巨大成功。", "innovation": "本文提出了一种基于XLNet的自动攻击性语言检测模型，XLNet是一种广义的自回归预训练方法，并将其性能与广泛用于自然语言处理（NLP）的基准模型BERT进行了比较。实验结果表明，XLNet在检测攻击性内容和分类类型方面优于BERT，而BERT在这方面表现稍好。此外，研究发现，通过对不平衡类别的方法进行上采样和下采样策略的有效使用，可以提高分类性能。这些发现突显了迁移学习和基于XLNet架构在构建检测社交媒体上的攻击性语言的稳健系统中的潜力。", "conclusion": "本研究展示了基于XLNet的模型在检测社交媒体上攻击性语言方面的优越性，并提出了一种有效的方法来解决类别不平衡问题，还表明了迁移学习的潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21802", "html_url": "https://arxiv.org/abs/2506.21802", "title": "基于自适应预测的分类拒绝选项：无分布误差保证", "title_en": "Classification with Reject Option: Distribution-free Error Guarantees via Conformal Prediction", "authors": "Johan Hallberg Szabadváry,Tuwe Löfström,Ulf Johansson,Cecilia Sönströd,Ernst Ahlberg,Lars Carlsson", "background": "现有的机器学习模型在预测时即使可能出错也会给出预测结果，这在实际应用中可能引发信任问题。为此，通过引入拒绝选项的方式，当预测可能出错时机器学习模型可以拒绝进行预测，这样可以提升预测的可信度。本文探讨了在二分类问题中如何正式化具有拒绝选项的机器学习方法，并通过自适应预测（CP）提供无分布保证的错误率理论保证.", "innovation": "本文创新性地将具有拒绝选项的预测方法置于自适应预测的框架中，通过这种方式得到错误率的理论保证，并且还提供了有限样本下的估计。此外，还通过不同的自适应预测设置提供了数值示例，展示了错误率和拒绝率之间的权衡关系，为实际应用中设定合适的错误率或拒绝率提供参考.", "conclusion": "本文通过自适应预测方法在二分类问题中为具有拒绝选项的预测提供了无分布保证的错误率，并通过数值示例和错误-拒绝曲线进一步说明了这种模型在实际应用中的优势，为用户在实践中如何设定一个可接受的错误率或拒绝率提供了支持."}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21770", "html_url": "https://arxiv.org/abs/2506.21770", "title": "使用多种视网膜底片图像数据集的深度学习早期青光眼检测", "title_en": "Early Glaucoma Detection using Deep Learning with Multiple Datasets of Fundus Images", "authors": "Rishiraj Paul Chowdhury,Nirmit Shekar Karkera", "background": "青光眼是不可逆失明的主要原因，但早期检测可以显著提高治疗效果。传统诊断方法通常具有侵入性，需要专门的设备。因此，需要研发新的无创、高效的方法用于青光眼的早期诊断。", "innovation": "本文提出了一种使用EfficientNet-B0架构的深度学习管道，用于从视网膜底片图像中进行青光眼检测。并采用ACRIMA、ORIGA和RIM-ONE三个数据集序列训练和微调模型，以增强其泛化能力。研究发现，最少的预处理比复杂的增强方法可以获得更高的AUC-ROC值，且模型在未见数据集中的判别性能很强。提出的管道提供了一个可复制和可扩展的早期青光眼检测方法，支持其临床应用潜力。", "conclusion": "该研究提供了一种新的管道，通过使用多种视网膜底片图像数据集的深度学习方法来实现早期青光眼的检测，该方法具有高效、无创、泛化能力强、且有临床应用潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21813", "html_url": "https://arxiv.org/abs/2506.21813", "title": "CAT-SG: 一种用于白内障手术细粒度理解的大型动态场景图数据集", "title_en": "CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery", "authors": "Felix Holm,Gözde Ünver,Ghazal Ghazaei,Nassir Navab", "background": "了解白内障手术复杂的操作流程需要模拟手术工具、解剖结构和手术技术之间的复杂相互作用。现有的数据集主要集中在手术分析的孤立方面，如工具检测或阶段分割，但缺乏能够捕捉实体之间随时间变化的语义关系的综合表示。现有的数据集无法提供全面的手术流程理解，尤其是在手术工具和组织交互、手术过程变化和时间依赖性方面的综合表示。", "innovation": "论文引入了白内障手术场景图(CAT-SG)数据集，这是首个用于提供工具-组织交互、手术过程变化和时间依赖性的结构化注释的数据集。通过引入详细的语义关系，CAT-SG提供了一个全面的手术流程视图，能够更准确地识别手术阶段和技术。此外，论文还提出了一种新的场景图生成模型CatSGG，该模型在生成结构化手术表示方面比现有方法更为出色。CAT-SG数据集旨在增强基于AI的手术训练、实时决策支持和工作流程分析，为临床实践中更智能和情境感知的系统铺平了道路。", "conclusion": "CAT-SG数据集和CatSGG模型的提出为更好地理解白内障手术提供了新的工具，有助于提高AI在手术中的应用水平，促进未来更智能、情境感知的临床实践系统的开发。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21757", "html_url": "https://arxiv.org/abs/2506.21757", "title": "TADA: 改进的基于训练-free 增强动力学的扩散采样", "title_en": "TADA: Improved Diffusion Sampling with Training-free Augmented Dynamics", "authors": "Tianrong Chen,Huangjie Zheng,David Berthelot,Jiatao Gu,Josh Susskind,Shuangfei Zhai", "background": "扩散模型展示了在生成高质量图像方面的出色能力，但通常面临采样效率低下的问题。为此，已经提出了许多求解器设计和噪声调度策略，以显著提高采样速度。该论文提出了一种新型采样方法，相比当前最先进的求解器，在ImageNet512对比FID上快至186%。这种新颖的采样方法无需训练，并采用常微分方程（ODE）求解器。关键在于利用高维初始噪声，从而使得现有预训练扩散模型在更少函数求值的情况下生成更为细致的样本。此外，求解器设计允许通过简单的超参数控制细节水平，而无需额外的计算成本。本文展示了如何通过建立动量扩散模型和常规扩散模型在训练范式上的基本等效性来利用动量动力学。进一步观察发现高维噪声使用表现出类似随机微分方程（SDE）的特征。最后，论文在多个代表性的预训练扩散模型上展示了出色性能，包括EDM、EDM2和Stable-Diffusion 3，覆盖了像素空间和潜在空间，以及类别和文本条件设置。", "innovation": "本文提出了一种全新的非训练型采样方法，利用高维初始噪声，只用经典预训练扩散模型就能生成更为详细的样本，速度相比当前最先进的求解器快了186%。此外，通过简单的超参数控制细节水平，而无需额外的计算成本。通过将动量扩散模型与常规扩散模型在训练范式上建立等效关系，揭示了动量动力学对采样的影响。还观察到高维噪声表现出与随机微分方程（SDE）相似的特性。最后，该方法在多种预训练模型上得到了验证。", "conclusion": "本文提出了一种新的基于非训练型增强动力学的扩散采样方法，在速度上显著超越了当前最先进求解器，且无需额外训练。此方法利用高维噪声显著降低计算复杂度，并允许以低廉的计算成本精确控制生成的样本细节。实验表明，该方法对多种预训练扩散模型表现出强大性能。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21803", "html_url": "https://arxiv.org/abs/2506.21803", "title": "从脉冲到心律：ECG-语言多尺度预训练方法", "title_en": "From Token to Rhythm: A Multi-Scale Approach for ECG-Language Pretraining", "authors": "Fuying Wang,Jiacheng Xu,Lequan Yu", "background": "心电图（ECGs）在监测心脏健康和诊断心脏疾病方面发挥着重要作用。然而，传统的深度学习方法在ECG分析中依赖于大量的人工标注，这既耗时也资源密集。自监督学习（SSL）作为替代方案出现，能够从大规模无标签数据中提取增强的ECG表示，这些表示可以高效地转移到各种下游任务中。尽管之前的研究探讨了SSL在ECG预训练和多模态ECG-语言对齐方面的应用，但它们往往无法捕捉到ECG信号的多尺度性质，导致难以学习泛化的表示。因此，为了解决这一问题，提出了一种名为MELP的新型多尺度ECG-语言预训练（MELP）模型，该模型充分利用了来自ECG-文本对的层次监督。", "innovation": "MELP是一种多尺度ECG-语言预训练模型，首先通过专门的医疗语言模型对心脏领域的语言进行预训练，提升其对临床文本的理解。然后，MELP应用三种级别的跨模态监督——在标记、心搏和节律级别上——将心电图信号与文本报告对齐，从而捕捉不同时间尺度的结构信息。这种方法能够更全面地捕捉ECG信号的多尺度特性，有效提升其在各类心脏病学应用中的表现。实验结果表明，MELP在三个公开的ECG数据集上表现优于现有SSL方法，证明了其在各种临床应用中的有效性和适应性。", "conclusion": "实验结果表明，MELP在三种公开的ECG数据集上多任务学习中均表现出色，证实了其在心脏医学应用中的有效性和灵活性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21815", "html_url": "https://arxiv.org/abs/2506.21815", "title": "基于集成降阶相场建模和深度强化学习的激光扫描路径设计以实现增材制造中的可控微观结构", "title_en": "Laser Scan Path Design for Controlled Microstructure in Additive Manufacturing with Integrated Reduced-Order Phase-Field Modeling and Deep Reinforcement Learning", "authors": "Augustine Twumasi,Prokash Chandra Roy,Zixun Li,Soumya Shouvik Bhattacharjee,Zhengtao Gan", "background": "激光粉床熔融（L-PBF）是一种广泛认可的增材制造技术，用于生产具有卓越精度的复杂金属部件。L-PBF的关键挑战是形成复杂微观结构，影响产品性能。预测和优化激光扫描路径以实现目标微观结构（例如等轴晶粒）是该技术应用的关键。传统的建模方法计算成本高，本文提出了一种基于物理指导的机器学习方法，利用相场法（PFM）模型晶粒结构的演变过程。通过训练3D U-Net卷积神经网络作为代理模型，基于初始微观结构和热历史预测晶粒取向，以减少计算成本。研究了不同填充间距下的三种扫描策略，并利用代理模型实现了计算成本两个数量级的加速。为了减少激光扫描路径设计中的试错过程，利用深度强化学习（DRL）生成目标微观结构的优化扫描路径。通过三个案例研究说明了DRL方法的有效性，将代理3D U-Net模型集成到DRL环境中，加速强化学习的训练过程。奖励函数旨在最小化预测微观结构的尺寸比例和晶粒体积.", "innovation": "本文提出了一种创新的物理导向和机器学习方法，通过集成降阶相场建模和深度强化学习来优化激光扫描路径，以实现特定的目标微观结构。具体包括：\n1. 利用相场法（PFM）预测微观结构演化。\n2. 训练3D U-Net卷积神经网络作为代理模型，以预测晶粒取向。\n3. 采用深度强化学习生成优化的扫描路径，降低了试错成本。\n4. 结合实时反馈机制，加速了强化学习训练过程。这种方法在不同尺寸区域的表现均优于传统方法，显示了机器学习方法在L-PBF优化中的潜力和优势。", "conclusion": "本文通过L-PBF中微观结构的控制设计，成功展示了物理导向和机器学习方法如何有效利用相场模型和深度强化学习来优化激光扫描路径。这种方法显著减少了计算成本并提高了微观结构控制，展示了在复杂金属部件增材制造中的应用潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21849", "html_url": "https://arxiv.org/abs/2506.21849", "title": "大型语言模型不确定性量化中的一致性假设", "title_en": "The Consistency Hypothesis in Uncertainty Quantification for Large Language Models", "authors": "Quan Xiao,Debarun Bhattacharjya,Balaji Ganesan,Radu Marinescu,Katsiaryna Mirylenka,Nhan H Pham,Michael Glass,Junkyu Lee", "background": "在需要高用户信任的实际应用中，估算大型语言模型（LLM）输出的置信度是非常重要的。由于黑箱不确定性量化（UQ）方法仅依赖于模型API访问的优势，这类方法逐渐受到青睐。现有方法假设生成一致性是置信度的代理，即一致性假设，但尚未进行严格的数学表述和统计测试。因此，该研究旨在进一步核实和量化这一点。", "innovation": "该研究首次提出了三种数学陈述和相应的统计测试来捕捉一致性的不同形式，并提出了数据免费的黑箱不确定性量化方法，通过聚合生成间的相似性来进行置信估计。实验表明，这些方法在多种任务中优于现有方法，验证了一致性假设的实际价值。", "conclusion": "一致性假设在不同设置中都普遍存在，尤其是在多种任务中得到了验证。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21826", "html_url": "https://arxiv.org/abs/2506.21826", "title": "通过视觉基础模型的线性探测进行历史地图的少样本分割", "title_en": "Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models", "authors": "Rafael Sterzinger,Marco Peer,Robert Sablatnig", "background": "历史地图是丰富的历史资源，提供了对历史变迁的宝贵见解。然而，它们多样的视觉表示和有限的标注数据对自动处理构成了重大挑战。该研究提出了一种简单而有效的历史地图分割方法，结合了丰富的语义嵌入和参数高效微调的大规模视觉基础模型，以应对上述挑战。该方法在Siegfried基准数据集的葡萄园和铁路分割任务上优于当前最佳方法，特别是在10-shot设置中实现了5%的相对提高，在更具有挑战性的5-shot设置中实现了约20%的相对提高。此外，该方法在ICDAR 2021竞赛数据集上表现良好，建筑块分割的平均精度-质心距离-覆盖度（mean PQ）达到67.3%，尽管并未针对这一敏感形状的度量进行优化，但证明了其泛化能力。研究结果表明，该方法在极端低数据条件下仍然保持高性能，而只需要689k的可训练参数，约占总模型大小的0.21%。这种方法使历史地图的精确分割成为可能，同时大幅减少了对人工注释的需求，推动了该领域的自动处理和分析进程。", "innovation": "提出了一种基于大规模视觉基础模型的参数高效微调方法，用于少样本历史地图分割。这种方法在葡萄园和铁路分割任务上优于当前最佳方法，并在IARO 2021竞赛数据集上实现了良好的性能。该方法的关键创新包括采用简单而有效的标注数据和高泛化能力的语义嵌入，以及在极端低数据条件下保持高性能的特点。", "conclusion": "该方法通过减少对人工注释的需求和在低数据条件下保持高性能，显著推动了历史地图的自动处理和分析。研究人员将该方法的实现开源，为后续研究提供了宝贵的资源。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21857", "html_url": "https://arxiv.org/abs/2506.21857", "title": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "title_en": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "authors": "Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold", "background": "随着数字病理学的迅速发展和自监督深度学习的进步，已经促进了各种病理任务基础模型的开发。尽管多模态方法整合了多种数据源，但在全面整合整个切片图像（WSI）与空间转录组学（ST）方面仍存在关键空白，这对于捕捉标准H&E染色之外的关键分子异质性至关重要。", "innovation": "本研究介绍了一种新的基础模型SPADE，该模型将组织病理学与ST数据整合到统一框架中，通过对抗学习学习配准的WSI斑块和基因表达谱的表示。SPADE利用混合多方专家的技术，通过两阶段特征空间聚类创建专家，以学习配准的WSI斑块和基因表达谱的表示。SPADE在广泛的人类组织癌症基因组信息库（HEST-1k）上进行预训练，并在14个下游任务中表现出显著优于基线模型的少样本性能，突出了将形态学和分子信息整合到一个潜在空间中的好处。", "conclusion": "SPADE通过创建一个ST指导的潜在空间，在统一框架内指导图像表示学习，从而实现形态学和分子信息的综合，显著优于基线模型。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21842", "html_url": "https://arxiv.org/abs/2506.21842", "title": "量子机器学习中的对抗威胁：攻击与防御综述", "title_en": "Adversarial Threats in Quantum Machine Learning: A Survey of Attacks and Defenses", "authors": "Archisman Ghosh,Satwik Kundu,Swaroop Ghosh", "background": "量子机器学习（QML）将量子计算与经典机器学习相结合，主要解决分类、回归和生成任务。然而，其快速发展在有噪声的中间规模量子（NISQ）时代引发了关键的安全挑战。这一章节主要研究QML系统的独特对抗威胁，重点关注基于云的部署、混合架构和量子生成模型中的漏洞。主要的攻击向量包括通过转译或输出提取模型盗窃，通过量子特定的扰动进行数据投毒，反向工程专有的变分量子电路，以及后门攻击。这些攻击者利用易受噪声影响的量子硬件和不够安全的QML-as-a-Service（QMLaaS）工作流来破坏模型的完整性和功能。防御机制利用量子特性来应对这些威胁，如训练硬件的噪声特征作为非侵入式水印，以及硬件感知的混淆技术和集成策略来扰乱克隆企图。新兴的解决方案也适应传统对抗训练和差分隐私的量子设置，解决了量子神经网络和生成架构中的漏洞。", "innovation": "该章节总结了最新的攻击和防御进展，提出了研究人员和实践者构建在不断变化的对抗环境中具有坚实可靠性的QML系统的路线图。新兴的解决方案适应了传统对抗训练和差分隐私的量子设置，解决了量子神经网络和生成架构中的漏洞问题。", "conclusion": "确保QML需要解决诸如平衡噪声水平以确保可靠性和安全性、缓解跨平台攻击以及开发量子-经典信任框架等开放挑战。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21884", "html_url": "https://arxiv.org/abs/2506.21884", "title": "UnMix-NeRF: 谱分解结合神经辐射场", "title_en": "UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields", "authors": "Fabian Perez,Sara Rojas,Carlos Hinojosa,Hoover Rueda-Chacón,Bernard Ghanem", "background": "基于神经辐射场（NeRF）的分割方法侧重于对象语义，仅依赖于RGB数据，无法体现内在材料属性，限制了对材料的准确感知，这对于机器人技术、增强现实、模拟及其他应用至关重要。", "innovation": "引入了UnMix-NeRF框架，通过将谱分解集成到NeRF中，实现了联合高光谱新颖视图合成和无监督材料分割，同时通过学习全球端基表示纯材料特征并将每点丰度捕获其分布，以模型散射性和镜面反射特性。使用学习端基的光谱特征预测进行无监督材料聚类，允许通过修改学习到的端基字典进行场景编辑，实现基于材料的外观的灵活操作。", "conclusion": "广泛实验验证了该方法，在光谱重建和材料分割方面表现优于现有方法。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21946", "html_url": "https://arxiv.org/abs/2506.21946", "title": " hitchhiking rides 数据集：二十年来的众包记录", "title_en": "Hitchhiking Rides Dataset: Two decades of crowd-sourced records on stochastic traveling", "authors": "Till Wenke", "background": " hitchhiking 作为一种自发且分散的旅行模式，长期以来因其非正式性质而难以进行系统研究。本文介绍并分析了迄今为止已知的最大规模 hitchhiking 行程结构化数据集，包含超过 63,000 条记录，数据收集时间几乎达二十年，并来自此链接和此链接上的平台。通过利用众包贡献，该数据集捕捉了 hitchhiking 的关键时空和策略方面。这项工作记录了数据集的起源、演变及其社区驱动的维护，突出了其以欧洲为中心的分布、季节性模式以及对少量非常活跃的贡献者的依赖。", "innovation": "本文通过利用众包数据，首次系统性地研究 hitchhiking，分析了关键的时空和策略方面，揭示了 hitchhikers 的行为和生活实况。", "conclusion": "本文总结了数据集的未来改进方向，并提出了关于 hitchhiking 作为交通工具和文化现象的研究前景。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21828", "html_url": "https://arxiv.org/abs/2506.21828", "title": "胎盘中胎儿的睡眠：跨物种生理学、测量与分类的回顾", "title_en": "Fetal Sleep: A Cross-Species Review of Physiology, Measurement, and Classification", "authors": "Weitao Tang,Johann Vargas-Calixto,Nasim Katebi,Robert Galinsky,Gari D. Clifford,Faezeh Marzbanrad", "background": "胎儿睡眠是孕期神经发育中较为未被充分探索但又极其重要的方面。了解胎儿的睡眠模式有助于揭示早期大脑成熟过程，并帮助临床医生识别由于胎儿缺氧或胎儿生长受限导致的神经功能障碍的早期迹象。已有研究跨越了八十年，涵盖了胎儿睡眠的生理特征、发生过程及调节机制。本文基于人类和大型动物模型研究了胎儿睡眠状态的变化，强调了物种间差异及睡眠状态的类似性。同时，本文回顾了侵入性和非侵入性测量方法，并探讨了用于睡眠状态分类的计算方法，包括基于规则的方法（有和无基于聚类的预处理）及最新的深度学习技术。此外，还讨论了胎儿在子宫内的条件如缺氧和胎儿生长受限如何影响胎儿的睡眠。这些发现为基础研究提供了强大的背景知识，促进了客观、多模态和无创的胎儿睡眠监测技术的发展，以支持产前护理中的早期诊断和干预。", "innovation": "本文涵盖了从侵入性动物研究到非侵入性人类测量方法的广泛研究，详细分析了用于睡眠状态分类的计算方法，包括基于规则的方法（有和无基于聚类的预处理）及最新的深度学习技术。这些方法为研究胎儿睡眠提供了新的工具和技术路径，并为开发更有效的监测手段奠定基础。", "conclusion": "本文提供了一个全面的框架，为开发客观、多模态及无创的胎儿睡眠监测技术提供了支持，有助于早期诊断和干预产前护理中的问题。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21894", "html_url": "https://arxiv.org/abs/2506.21894", "title": "通过神经算子进行函数空间中的汤普森采样", "title_en": "Thompson Sampling in Function Spaces via Neural Operators", "authors": "Rafael Oliveira,Xuesong Wang,Kian Ming A. Chai,Edwin V. Bonilla", "background": "本文探讨在函数空间中优化问题，其中目标是未知操作输出已知泛函的情况下，汤普森采样的一种扩展。假设泛函评估成本较低，但查询操作（如运行高保真模拟器）成本较高。研究通过神经操作符代理进行采样然后优化的方法，以提高算法效率和精度。这种策略通过将训练好的神经操作符视为高斯过程的近似样本，避免了显式的不确定性量化，为研究提供了新的理论收敛保证。研究在偏微分方程和其他非线性操作符驱动的现象的功能优化任务中将方法与其他现有基准进行比较，证明了更高的采样效率和竞争力。", "innovation": "本文提出的创新点在于将汤普森采样扩展到函数空间优化问题，利用神经操作符代理进行采样然后优化。通过将训练好的神经操作符视为高斯过程的近似样本，避免了显式的不确定性量化，提供了一种新颖的理论收敛保证。这种方法在功能优化任务中与其他现有方法进行了比较，显示了更高的采样效率和竞争力。", "conclusion": "本文提出了在功能优化任务中使用神经算子的汤普森采样的扩展方法，提供了一种不进行显式不确定性量化的方法，并提出了新的理论一致性保证。在各种功能优化任务中，本文的方法展示了比其他现有基线更好的采样效率和竞争力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21967", "html_url": "https://arxiv.org/abs/2506.21967", "title": "比你想象中更脆弱：工具集成LLM代理的稳定性研究", "title_en": "More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents", "authors": "Weimin Xiong,Ke Wang,Yifan Song,Hanchao Liu,Sai Zhou,Wei Peng,Sujian Li", "background": "当前对工具集成语言模型代理（LLM agents）的评估主要集中在整体工具使用评价上，而忽视了其稳定性。这限制了它们在现实世界中的应用，因为不同内部和外部因素可能会导致代理出错或异常行为。", "innovation": "研究通过调查代理在整个工具调用过程中的脆弱性，包括阅读工具文档、选择工具和生成参数、处理工具响应等各个环节。研究发现，代理在每个阶段都非常容易出错，开源模型的代理比私有模型的代理更脆弱。此外，增加模型大小并不显著提高工具调用推理能力，反而可能导致代理更易受到类似于正常用户指令的攻击。这项研究强调了评估代理稳定性的必要性，并为未来LLM开发和评价提供了宝贵的见解。", "conclusion": "研究结果指出，工具集成LLM代理在每个调用阶段都非常脆弱，开源模型的代理比私有模型的代理更脆弱。模型规模的增加并不显著提高代理的工具调用推理能力，反而可能使其更易受到攻击。研究强调了评估代理稳定性的必要性，并为未来LLM的发展和评估提供了新的视角。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21933", "html_url": "https://arxiv.org/abs/2506.21933", "title": "通过图注意力扩散实现低空MEC系统的任务卸载与资源分配", "title_en": "Joint Task Offloading and Resource Allocation in Low-Altitude MEC via Graph Attention Diffusion", "authors": "Yifan Xue,Ruihuai Liang,Bo Yang,Xuelin Cao,Zhiwen Yu,Mérouane Debbah,Chau Yuen", "background": "随着低空经济的快速发展，低空地集成边缘计算（MEC）系统对实时和智能任务调度的需求不断增加。在这些系统中，任务卸载和资源分配面临多种挑战，包括节点异构性、不稳定的通信链路和动态任务变化。面对这些挑战，研究提出了一种适用于低空经济网络的三层异构MEC系统架构，该架构综合了空中用户、地面用户以及边缘服务器。该系统从通信信道、计算成本和约束条件等方面进行了系统建模，并将卸载决策和资源分配的联合优化问题统一抽象为一种图结构化建模任务。", "innovation": "研究提出了一种图注意力扩散基解算器（GADSG）的方法。该方法结合了图注意力网络的上下文意识和扩散模型的解算分布学习能力，能够在高维隐空间中联合建模和优化离散的卸载变量和连续的资源分配变量。研究构建了多个具有不同规模和拓扑结构的仿真的数据集，广泛的实验表明，提出的GADSG模型在优化性能、鲁棒性和面向任务结构的推广等方面显著优于现有基准方法，显示了在动态和复杂的低空经济网络环境中高效任务调度的强大潜力。", "conclusion": "研究表明，通过图注意力扩散基解算器GADSG的方法能够在这些复杂的任务调度环境中实现显著优于现有方法的效果，显示了其在动态和复杂的低空经济网络环境下高效任务调度的强大潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22174", "html_url": "https://arxiv.org/abs/2506.22174", "title": "ASVSim（AirSim for Surface Vehicles）：一种用于自主水面车辆研究的高保真模拟框架", "title_en": "ASVSim (AirSim for Surface Vehicles): A High-Fidelity Simulation Framework for Autonomous Surface Vehicle Research", "authors": "Bavo Lesy,Siemen Herremans,Robin Kerstens,Jan Steckel,Walter Daems,Siegfried Mercelis,Ali Anwar", "background": "近年来，运输行业对无人驾驶水面车辆（USVs）表现出浓厚兴趣，特别是在港口和内陆水道运输中。在欧洲联盟，由于绿色协议等倡议推动了内陆水道运输使用的增加，使得这一领域更为重要。与此同时，专业人员短缺加速了自主解决方案的采用。然而，用于开发和评估这些解决方案的开源、高保真模拟框架和数据集严重缺乏。因此，本文介绍了一个名为ASVSim的开源模拟框架，该框架专为内陆和港口环境下的自主航运研究设计，结合了船舶动力学模拟和海洋传感器模拟功能，支持计算机视觉模型和强化学习代理的训练合成数据集生成。该模拟器支持传统控制方法和深度学习方法的研究。", "innovation": "ASVSim是一个开源的高保真模拟框架，专门为内陆和港口环境下的自主航运研究设计。它结合了船舶动力学模拟和海洋传感器模拟（包括雷达和摄像头系统），支持生成用于训练计算机视觉模型和强化学习代理的合成数据集，并提供了全面的自主导航算法开发平台。它基于Cosys-AirSim构建，支持研究传统控制方法和学习方法。通过有限的实验，展示了该模拟器在这两个研究领域的潜在应用价值。", "conclusion": "ALVSim是以MIT许可证提供开源项目，旨在使更多的海洋工程社区能够进行自主导航研究，提高了研究的可访问性和透明度。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21972", "html_url": "https://arxiv.org/abs/2506.21972", "title": "提升脱逃策略：利用大型语言模型漏洞并绕过现代防御的混合方法", "title_en": "Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses", "authors": "Mohamed Ahmed,Mohamed Abdelmouty,Mingyu Kim,Gunvanth Kandula,Alex Park,James C. Davis", "background": "预训练语言模型（PTLMs）和大规模语言模型（LLMs）的进展导致它们在各种应用中被广泛应用。尽管这些模型在实际应用中表现出色，但仍存在利用其固有弱点绕过安全措施的攻击。这些攻击主要分为两种形式：子代级脱逃和提示级脱逃。子代级攻击通过嵌入对抗序列影响模型，但容易被检测，并依赖于梯度优化；提示级攻击则通过结构化的输入引发有害响应，但需要迭代反馈，这种方法可能不够稳定可靠。", "innovation": "为了解决单一方法的局限性，本文提出了一种混合方法，结合了子代级和提示级技术，增强了不同PTLMs的脱逃效果。评估结果显示，GCG + PAIR策略在未防护模型上的攻击成功率显著高于单一技术的方法；例如，在Llama-3模型上，其攻击成功率达到了91.6%，相较于PAIR的基础水平58.4%有了显著提升。此外，GCG + WordGame这种新的混合策略具有与单一技术相当的原始性能，并且在更严格的评估工具下仍能保持高于80%的攻击成功率。该混合策略的有效性能够穿透如Gradient Cuff和JBShield等高级防御系统，明确指出单模式攻击已被完全阻止。", "conclusion": "这些发现揭示了当前安全系统的未报道漏洞，突显出原始攻击成功率和防御稳健性之间的权衡，并强调了需要全面的安全保护以对抗适应性对手的必要性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22101", "html_url": "https://arxiv.org/abs/2506.22101", "title": "Tied Prototype Model for Few-Shot Medical Image Segmentation", "title_en": "Tied Prototype Model for Few-Shot Medical Image Segmentation", "authors": "Hyeongji Kim,Stine Hansen,Michael Kampffmeyer", "background": "现有的原型基医疗图像少量样本分割（FSS）方法使用特定类别的原型来建模前景和背景类。然而，由于背景的高度变异性，ADNet 的一种更具前景的方法是仅聚焦在前景建模上，将背景视为异常。ADNet 存在三个主要局限：单原型依赖，专注于二分类，以及固定的阈值无法适应患者和器官变异性。", "innovation": "提出了 Tied Prototype Model (TPM)，这是一种对 ADNet 进行实际修正的方法，具有前景和背景分布的联合原型位置。TPM 基于概率基础自然扩展到多个原型和多类分割，有效地分离非典型背景特征。两种扩展均提高了分割准确率。利用自然出现的类别先验定义适应性阈值的理想目标，进一步增强了分割性能。", "conclusion": "TPM 为原型基的少量样本医疗图像分割提供了一种新的视角。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21887", "html_url": "https://arxiv.org/abs/2506.21887", "title": "具有软硬边界限制的交互式多目标概率偏好学习", "title_en": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds", "authors": "Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin", "background": "高风险决策涉及在昂贵的评估成本下平衡多个相互竞争的目标。例如，在近距离放射治疗中，临床医生需要在最大化肿瘤覆盖（如目标或灵活性幅度超过95%的覆盖）与严格的器官剂量限制（如膀胱不能超过601 cGy的硬性限制）之间进行权衡，每次计划评估都是资源密集的。选择与隐含偏好匹配的帕累托最优解很有挑战性，因为全面探索帕累托前沿计算上和认知上都是不可行的。因此，需要互动框架来辅助用户。尽管决策者（DMs）通常能够利用软硬边界来缩小搜索范围，但现有的方法通常缺乏系统的方法来逐渐优化这些多方面偏好结构。DMs必须对其最终决策充满信心，确保没有错过更好的替代方案；在高后果场景中，这一点尤为重要。当DMs信任自己的决策，并确认他们没有错过更好的选项时，这种信任是至关重要的。尽管如此，现有的方法往往缺乏引导他们逐步优化多方面偏好结构的有效方式。因此，迫切需要一种新的方法来帮助DMs平衡这些复杂的目标，并获得他们对自己的决策的信心。", "innovation": "我们提出了一个名为Active-MoSH的互动局部-全局框架。该框架将软硬边界与概率偏好学习整合在一起，通过主动采样策略实现探索-利用优化并且同时减少认知负担。框架的全局部分T-MoSH利用多目标敏感性分析确定可能被忽视但具有高价值的点，超越了即时反馈。通过多样化的合成和真实世界应用，我们展示了Active-MoSH性能优势，进一步通过AI生成的图像选择用户研究验证了该框架在提高算法收敛性、增强决策者信任和提供表达偏好方面的能力，从而增强了更有效的决策者的能力。", "conclusion": "我们的Active-MoSH框架不仅通过整合软硬边界和概率偏好学习优化了多目标决策过程，还通过提供多方面的特性帮助决策者平衡复杂的目标。通过主动采样策略和多目标敏感性分析，框架有效地增强了决策者的信心，减少了搜索过程中的认知负担，并且能够帮助决策者更有效地表达他们的偏好，提高决策质量。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22236", "html_url": "https://arxiv.org/abs/2506.22236", "title": "为统计学和机器学习的历史和哲学辩护", "title_en": "A Plea for History and Philosophy of Statistics and Machine Learning", "authors": "Hanti Lin", "background": "统计学和哲学的综合至少可追溯到1965年Hacking的工作，1996年Mayo进一步推动了这一趋势，但在后续研究中并没有持续跟进。然而，鉴于人工智能领域，尤其是机器学习的最新成功，这种综合变得比以往更为迫切。机器学习作为统计学的一个领域，在统计学发展过程中扮演了重要角色，且如今统计学和机器学习的界限变得越来越模糊。本文提出了一个结合统计学和机器学习中哲学思想的案例研究，聚焦于Neyman和Pearson 1936年工作中一个被忽视的重要洞察。", "innovation": "提出了一种被频繁统计学和机器学习实践广泛遵循但很少明言的基础假设——'实现主义'。此外，还提出了方法论层面的综合，结合了科学哲学和形式认识论的两端，强调了统计学和机器学习的历史和哲学综合的重要性。", "conclusion": "本文认为，统计学与机器学习领域的综合不仅在历史和哲学层面是必要的，而且在它们学科实践中也是至关重要的。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22204", "html_url": "https://arxiv.org/abs/2506.22204", "title": "Hybrid Generative Modeling for Incomplete Physics: Deep Grey-Box Meets Optimal Transport", "title_en": "Hybrid Generative Modeling for Incomplete Physics: Deep Grey-Box Meets Optimal Transport", "authors": "Gurjeet Sangra Singh,Maciej Falkiewicz,Alexandros Kalousis", "background": "物理现象通常由常微分方程(ODE)或偏微分方程(PDE)来描述，并进行解析或数值求解。然而，许多实际系统只能通过具有缺失或未知项的近似方程来描述，从而使得物理模型的分布与真实数据生成过程(DGP)之间的分布存在差异。在仅有有限且未配对的数据存在于DGP观测与不完美模型模拟之间的情况下，研究者致力于通过结合理论驱动模型和数据驱动方法来完成已知物理模型，以描述和矫正DGP中的分布偏移。通过利用最优传输方法，研究提出了一种新的混合生成模型方法，结合深度灰箱建模来增强不完整物理模型的效果。这种方法不仅在问题解决上展示了优越性，在模型透明度和解释性方面也表现出色，能够准确学习系统动力学并保留物理参数的准确性。", "innovation": "研究通过利用最优传输方法，在数据空间中实现OT映射，同时最小化源分布的扭曲，提出了一种新的混合生成模型方法，结合深度灰箱建模。这种方法能够提高不完整物理模型的效果，解决了未配对数据问题，确保了物理参数的正确使用。该方法具有基于物理的归纳偏置，能够在学习系统动力学的同时保持可解释性，提高了模型的透明度。实验结果验证了该方法在生成任务中的有效性和模型透明度。", "conclusion": "该研究提出的方法在解决未配对数据问题和确保物理模型的准确性方面表现优越，通过结合深度灰箱建模和最优传输方法，增强了不完整物理模型的效果，展示了在生成任务和提高模型透明度方面的实际应用价值。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21990", "html_url": "https://arxiv.org/abs/2506.21990", "title": "分析与微调 Whisper 模型以提高驾驶舱多语言飞行员对话转录精度", "title_en": "Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit", "authors": "Kartheek Kumar Reddy Nareddy,Sarah Ternus,Julia Niebling", "background": "变压器编码器-解码器架构的发展在机器翻译、自动语音识别(ASR)和基于指令的聊天机器人等领域取得了重大突破。这些预训练模型在少量的几轮训练（通常少于五轮）基础上对大量通用数据进行训练，因此具有很强的泛化能力。然而，这些模型在一些特定领域（如驾驶舱中的飞行员语音转录）的应用性能会受到影响。驾驶舱中的飞行员语音转录涉及大量的专业词汇和多语言对话，这就需要对模型进行进一步的优化和调优。论文通过收集驾驶舱模拟器和飞行员的访谈录音，对 Whisper 模型进行分析和微调，以提高其识别精度。", "innovation": "本研究提出了一种改进转录准确性的方法，包括提出了多种规范化方案以提高词错误率（WER），并使用低秩适应（LoRA）进行高效微调。相比于预训练的 Whisper Large 模型，引入规范化方案后的 Whisper Large 微调模型的 WER 从 68.49% 降至 26.26%。这项工作显著提升了多语言飞行员对话在驾驶舱环境下的识别效果，为实际应用提供了有效的解决方案。", "conclusion": "本研究通过对 Whisper 模型进行仔细分析并结合特定的应用场景，提出了改进的训练方法和优化方案。实验结果表明，这些改进措施显著提高了对驾驶舱多语言飞行员对话的转录精度。未来的研究可以进一步探索更多的规范化方法和技术，以进一步提高识别性能。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22146", "html_url": "https://arxiv.org/abs/2506.22146", "title": "视觉结构有助于视觉推理：解决VLM中的绑定问题", "title_en": "Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs", "authors": "Amirmohammad Izadi,Mohammad Ali Banayeeanzade,Fatemeh Askari,Ali Rahimiakbar,Mohammad Mahdi Vahedi,Hosein Hasani,Mahdieh Soleymani Baghshah", "background": "尽管在视觉语言模型(VLMs)方面取得了进展，但它们的视觉推理能力往往受限于‘绑定问题’：即无法可靠地将感知特征与其正确的视觉参照物关联。这一限制导致了诸如计数、视觉搜索、场景描述和空间关系理解等任务中的持续错误。原因是当前的VLMs主要以并行方式处理视觉特征，缺乏空间定位的串行注意力机制。", "innovation": "本文提出了一种简单而有效的干预措施：通过增加视觉输入的低级空间结构（例如水平线）并结合鼓励有序、空间感知解析的文本提示，以解决绑定问题。实验结果表明，在核心视觉推理任务上获得了显著的性能提升。我们的方法在GPT-4o视觉搜索准确性上提高了25.00%，增加计数准确性26.83%，减少场景描述中的编辑距离误差0.32，以及在2D合成数据集上提升空间关系任务的性能9.50%。此外，我们发现视觉修改对于这些提升是必不可少的；纯文本策略，包括因果推理提示，是无效的，甚至可能降低性能。这种只有单查询推理的方法增强了绑定，强调了视觉输入设计的重要性，而非纯粹的语言基础方法。", "conclusion": "低级视觉结构是提升组合视觉推理能力的强大且未充分利用的方向，有可能作为增强基于空间任务的VLM性能的一般策略。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22271", "html_url": "https://arxiv.org/abs/2506.22271", "title": "打破知识图谱填充中的秩瓶颈", "title_en": "Breaking Rank Bottlenecks in Knowledge Graph Completion", "authors": "Samy Badreddine,Emile van Krieken,Luciano Serafini", "background": "许多知识图谱完成（KGC）模型，尽管使用了强大的编码器，但在评分查询时仍然依赖于简单的向量-矩阵乘法。当实体数量远大于模型嵌入维度时，这会导致线性输出层存在秩瓶颈，限制了模型的表现力。我们通过理论和实验研究了秩瓶颈如何影响KGC模型。我们发现，秩瓶颈限制了可行预测集，从而影响排名准确性及评分分布精度。", "innovation": "受语言建模文献的启发，我们提出了KGE-MoS，一种混合输出层以打破KGC模型中的秩瓶颈。实验结果显示，KGE-MoS 在低参数成本下提高了KGC模型的性能和概率拟合度。", "conclusion": "我们的研究揭示了秩瓶颈对KGC模型的影响，并提出了KGE-MoS 解决方案，有效提高了模型性能，且参数成本较低。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22241", "html_url": "https://arxiv.org/abs/2506.22241", "title": "使用量子启发式增强技术提升分类", "title_en": "Boosting Classification with Quantum-Inspired Augmentations", "authors": "Matthias Tschöpe,Vitor Fortes Rey,Sogo Pierre Sanon,Paul Lukowicz,Nikolaos Palaiodimopoulos,Maximilian Kiefer-Emmanouilidis", "background": "理解小量子门扰动的影响对于识别量子机器学习的优势至关重要。这些扰动在量子数字设备中普遍存在，但在经典计算机中不存在，通常被认为会损害量子计算的效果。然而，这些扰动实际上可以作为一种自然的数据增强源，提高性能。此外，这些扰动可以高效地在经典硬件上模拟，使得量子启发的方法能够改善经典机器学习方法。本文探讨了作为基本SU(2)变换的随机Bloch球旋转作为简单的量子启发式数据增强技术的有效性。", "innovation": "本文提出了一种新的量子启发式的数据增强方法，通过直接应用小角度Bloch旋转到经典数据，来改善图像分类的性能。这种方法与传统的数据增强方法（如翻转、旋转或裁剪）不同，无需依赖于量子模型或可训练的量子卷积层。通过使用大规模ImageNet数据集，该方法提高了Top-1准确率3%、Top-5准确率2.5%以及F1分数从8%提升到12%，明显优于传统的经典数据增强方法。", "conclusion": "虽然更强的酉变换在原则上能保持信息，但会产生视觉上难以辨认的图像，可能适用于隐私计算的应用。然而，研究结果显示，这种增强方法和简单的SU(2)变换并未增强差异隐私，本文讨论了这一限制的影响。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22105", "html_url": "https://arxiv.org/abs/2506.22105", "title": "在GPT-2中识别动词 conjugation 电路", "title_en": "Identifying a Circuit for Verb Conjugation in GPT-2", "authors": "David Demitri Africa", "background": "本文对GPT-2 Small模型中负责主谓一致的部分网络（或称“电路”）进行了隔离和解释。作者通过给模型提供主语是单数（如“Alice”）或复数（如“Alice and Bob”）的提示任务，让模型正确预测相应的动词形式（单数主语使用“walks”，复数主语使用“walk”），以此来研究该模型中的电路。这是一个关于如何通过隔离和识别特定网络组件来提升模型准确性的研究背景介绍。", "innovation": "本文的创新之处在于采用了一系列技术，包括直接路径修补进行的自动电路发现和直接logit归因，以定位负责主谓一致的电路。研究发现，只需模型中一小部分组件对完成基础任务至关重要，但面对更复杂的情况则需要更多的组件。这种方法提供了一种新的理解模型内在机制的方式，有可能改进现有的自然语言处理模型。", "conclusion": "本文的研究结果表明，尽管GPT-2模型的整体网络复杂庞大，但只需少量网络组件就能实现主要的主谓一致任务。在应对更复杂任务时，需要更多这样的网络组件。这项工作为进一步理解大型预训练模型的内在机制提供了新的视角，并可能启发未来的研究方向。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22340", "html_url": "https://arxiv.org/abs/2506.22340", "title": "QuKAN: 一种量子电路产生机器在量子柯尔莫哥洛夫-阿诺尔德网络中的方法", "title_en": "QuKAN: A Quantum Circuit Born Machine approach to Quantum Kolmogorov Arnold Networks", "authors": "Yannick Werner,Akash Malemath,Mengxi Liu,Vitor Fortes Rey,Nikolaos Palaiodimopoulos,Paul Lukowicz,Maximilian Kiefer-Emmanouilidis", "background": "Kolmogorov Arnold Networks (KANs) 建立在Kolmogorov Arnold表示定理（KAR）之上，证明了用较少的神经元表达复杂函数的能力。KANs通过在边而不是节点上实现可学习参数来实现这一点，这一特性使其不同于传统的多层感知器（MLP）等网络。然而，KANs在量子机器学习中的应用尚未得到充分探索。在这项工作中，使用Quantum Circuit Born Machine (QCBM) 来实现这两个KAN架构的混合和全量子形式。利用预训练的残差函数对KAN进行适应，以利用参数化量子电路的表示能力。在混合模型中结合经典KAN组件和量子子程序，而全量子版本则将残差功能的整个架构转换为量子模型。", "innovation": "提出了QuKAN架构，即通过使用Quantum Circuit Born Machine (QCBM) 来实现Kolmogorov Arnold Networks (KANs) 的混合和全量子形式，并使用预训练的残差函数来利用参数化量子电路的表示能力。这在经典KAN组件和量子子程序之间进行了创新性的融合，并展示了其可行性和性能。", "conclusion": "展示了所提出的Quantum KAN (QuKAN) 架构的可行性和性能，并说明了其在量子机器学习中的应用潜力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22228", "html_url": "https://arxiv.org/abs/2506.22228", "title": "使用PCS指导的邻居嵌入方法在单细胞数据中发现平滑结构", "title_en": "Uncovering smooth structures in single-cell data with PCS-guided neighbor embeddings", "authors": "Rong Ma,Xi Li,Jingyuan Hu,Bin Yu", "background": "单细胞测序技术正在彻底改变生物学研究，通过允许对细胞状态转换进行详细研究。许多生物学过程沿着连续轨迹展开，但从噪声较大的高维单细胞数据中提取平滑、低维的表示仍然是具有挑战性的。现有的邻域嵌入（NE）算法，如t-SNE和UMAP，被广泛应用于将高维单细胞数据嵌入到低维空间中，但它们经常会引入不需要的失真，导致误导性的解释。现有的NE算法评估方法主要侧重于区分离散细胞类型，而对于捕捉连续细胞状态转换关注不足。现有的动态建模方法依赖于对细胞过程的强假设和专门的数据，存在局限性。为解决这些挑战，本文基于可靠和可重复的数据驱动发现的预测性-计算性-稳定性（PCS）框架。通过系统地评估流行NE算法，揭示其关键缺陷，并引入NES方法（利用算法稳定性改进NE表示，同时能够稳健推断平滑生物结构），从而克服邻域嵌入算法的固有问题，推动对单细胞数据中的发育轨迹和细胞状态转换的研究。", "innovation": "提出了NES方法，这是一种基于预测性-计算性-稳定性（PCS）框架的、系统化的、可解释的机器学习方法。NES方法通过融合算法稳定性原理改进了NE嵌入，使KE模型能够稳健地推断出平滑的生物结构。该方法提出了有用的稳定概念、定量的稳定性指标和高效的计算工作流，从而有效地提升了对单细胞测序数据中平滑结构的研究成果，尤其适用于发现和发展轨迹中的过渡状态和稳定状态，以及量化发育过程中的转录动态", "conclusion": "NES方法已在六组单细胞数据中得到了应用，覆盖了干细胞分化、类器官发育以及多个组织特异的线粒体各轨迹。在多种不同的背景下，NES方法系统且一致地提供了有用生物学洞察，包括转型和稳定细胞状态的识别以及发育过程中转录动态的量化。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22335", "html_url": "https://arxiv.org/abs/2506.22335", "title": "量子递归存储器计算机在混沌时间序列预报中的稳健性：广义同步与稳定性", "title_en": "Robust quantum reservoir computers for forecasting chaotic dynamics: generalized synchronization and stability", "authors": "Osama Ahmed,Felix Tennie,Luca Magri", "background": "研究表明，量子递归存储器计算机（QRCs）及其无回路架构（RF-QRCs）能够从时间序列数据中学习和预测混沌动力学。通过对量子递归存储器计算机的耦合动力学系统进行建模和解释，论文指出量子递归存储器计算机是广义同步（GS）系统。进一步证明了量子递归存储器计算机能够学习混沌动力学及其不变性特性，如李雅普un夫谱、吸引子维度和几何性质等，通过推导量子递归存储器更新的雅可比矩阵实现这一分析。", "innovation": "通过广义同步方法，提出了设计稳健量子递归存储器计算机的方法，提出了GS=ESP原则，即广义同步等同于回声状态性质，并且证明了RF-QRCs通过设计满足GS=ESP。此外，研究表明噪声耗散能增强量子递归存储器计算机的稳健性，这些发现为在短期内的量子硬件上设计用于混沌时间序列预测的稳健量子机器提供了机会，", "conclusion": "本工作证明了量子递归存储器计算机是学习和预测混沌动力学的有效工具，通过广义同步和稳定性分析提供了设计稳健QRC的方法，并通过不同维度系统的数值验证支持了结论。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.10566", "html_url": "https://arxiv.org/abs/2401.10566", "title": "ROME: Robust Multi-Modal Density Estimator", "title_en": "ROME: Robust Multi-Modal Density Estimator", "authors": "Anna Mészáros,Julian F. Schumann,Javier Alonso-Mora,Arkady Zgonnikov,Jens Kober", "background": "概率密度函数的估计是科学和工程中的基本问题。常用的方法如核密度估计(KDE)经验证缺乏鲁棒性，更复杂的方法尚未在多模态估计问题上进行评估。", "innovation": "ROME（RObust Multi-modal Estimator，鲁棒多模态估计器）是一种非参数方法，通过聚类将多模态数据集分割成多个单模态，并结合个体集群获得的简单KDE估计，构建单一多模态估计。与最先进的密度估计方法及其变体相比，ROME表现出更好的性能和对各种分布的鲁棒性。", "conclusion": "实验结果表明，ROME能够克服其他估计器表现出的拟合过度和平滑过度的问题。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22309", "html_url": "https://arxiv.org/abs/2506.22309", "title": "基于概念分析的主题聚合", "title_en": "Conceptual Topic Aggregation", "authors": "Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme", "background": "传统的手动数据检查由于数据量的激增变得不再可行，因此需要使用计算方法来高效地探索数据。主题建模作为一种强大的工具，能够分析大规模的文本数据集，提取潜在的语义结构。然而，现有的主题建模方法通常难以提供可解释的表示，这使得深入理解数据结构和内容变得困难。因此，现有的方法在可解释性和提供有意义的洞察方面有所不足。", "innovation": "本文提出了一种基于形式概念分析（FCA）的方法，称为FAT-CAT，以增强有意义的主题聚合和已发现主题的可视化。该方法能够处理多种主题和文件类型，并通过目录分组构建概念格，从而提供一个结构化和层次化的主题分布表示。这种方法适合于解决现有的主题建模技术在可解释性和提供有意义的洞察方面的不足，针对ETYNTKE数据集进行实证测试，证明了基于形式概念分析的聚合提供了比现有主题建模技术更有意义和可解释的洞察。", "conclusion": "我们的研究证明了基于形式概念分析的方法在聚合主题和提供更有意义的洞察方面的有效性，特别是在面对多样化的主题和文件类型时。通过构建概念格，可以提供一个结构化的主题层次表示，从而更有效地理解和展示数据的构成。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22419", "html_url": "https://arxiv.org/abs/2506.22419", "title": "自动化的大型语言模型速度赛跑基准：再现NanoGPT改进", "title_en": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "authors": "Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach", "background": "大型语言模型的快速发展有可能促进科学研究的进步。至关重要的一项能力是重现现有工作。为了评估AI代理重现结果的能力，研究团队引入了基于NanoGPT速度赛跑的自动大型语言模型速度赛跑基准。NanoGPT速度赛跑是一个竞赛，目的是以最短时间训练一个GPT-2模型。每个任务都提供了之前的速度记录训练脚本，有时还会附带三种不同类型的提示格式之一，从伪代码到论文般的描述新纪录改进的说明。这些特点使基准既易于访问又具有现实意义，有助于探索改善大型语言模型训练的前沿问题。", "innovation": "研究团队提出了一个基于NanoGPT速度赛跑的自动大型语言模型速度赛跑基准。该基准被设计用于评估和衡量近年来因果推理型大型语言模型结合最先进框架在重现已知创新方面的表现。通过这项基准，研究团队发现即便在提供详细提示的情况下，这些模型依然难以重现已知创新，该基准为评估大型语言模型自动化科学再现能力提供了一种简单且未饱和的方法，这是自主研究代理所需的重要但不充分技能之一。", "conclusion": "结论是，尽管最近的因果推理型大型语言模型与最先进的支架结合在一起，在基准测试中显得非常困难重做已知的创新改进。该基准为评估大型语言模型的自动科学再现能力提供了一个简单且未饱和的指标，这对于促进自主研究代理能力至关重要（但不是全部）."}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.07975", "html_url": "https://arxiv.org/abs/2311.07975", "title": "将未知转化为揭示确定性", "title_en": "Distilling the Unknown to Unveil Certainty", "authors": "Zhilin Zhao,Longbing Cao,Yixuan Zhang,Kun-Yu Lin,Wei-Shi Zheng", "background": "Out-of-distribution (OOD)检测对于识别与内部分布（ID）数据相异的测试样本至关重要，以确保网络的稳健性和可靠性。本文提出了一种灵活的框架，该框架从网络中提取敏感于OOD的信息，开发二元分类器来区分ID和OOD样本，具有和不具有ID数据训练集的情况。本文还引入了一种名为Confidence Amendment (CA)的创新方法，该方法将OOD样本转化为ID样本，逐步修正网络预测置信度，以增强OOD敏感性。这种方法能够在没有实验数据的情况下同时合成ID和OOD样本，每个样本都伴随着调整后的预测置信度，从而有助于训练一个敏感于OOD的二元分类器。理论分析表明，置信度修正对二元分类器的一般化误差有很大的影响，这突显了其在提高OOD敏感性方面的重要性。广泛的实验结果证实了所提出方法在检测OOD样本方面是有效的。", "innovation": "本文提出了一种灵活的OOD知识蒸馏框架，该框架通过引入一种名为Confidence Amendment (CA)的新方法，从网络中提取敏感于OOD的信息，开发具有区分ID和OOD样本能力的二元分类器。CA方法通过逐步修正预测置信度来增强OOD敏感性。此外，理论分析界定了二元分类器的一般化误差范围，证实了Confidence Amendment方法的重要性。", "conclusion": "本文提出的方法能够在检测OOD样本方面表现出色，尤其是在没有ID数据训练集的情况下。通过同步生成ID和OOD样本并调整相应的预测置信度，该方法能够有效地训练出对OOD敏感的二元分类器。实验结果表明，所提出的方法在多个数据集和网络架构上都是有效的，进一步验证了其在OOD检测中的实用性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22362", "html_url": "https://arxiv.org/abs/2506.22362", "title": "DiffSoundStream：通过扩散解码实现高效语音分词", "title_en": "DiffSoundStream: Efficient Speech Tokenization via Diffusion Decoding", "authors": "Yang Yang,Yunpeng Li,George Sung,Shao-Fu Shih,Craig Dooley,Alessio Centazzo,Ramanan Rajeswaran", "background": "基于标记的语言模型是语音生成中的一个重要方法，其中标记来源于自我监督学习（SSL）模型的特征量化和神经语音编解码器信息的编码，通常称为语义标记和声学标记。这些标记通常以自回归的方式建模，但推断速度受限于标记率。现有的非流水线场景下的语音分词方案存在效率问题，尤其是在维持高质量语音生成的同时，仍需保持较快的推理速度。", "innovation": "提出了DiffSoundStream，这是一种通过两种技术改进非流水线场景下语音分词效率的解决方案：（1）将神经编解码器条件化于语义标记，以减少语义和声学标记之间的冗余；（2）利用潜在扩散模型从语义和粗糙级声学标记生成高质量波形。实验结果显示，DiffSoundStream 在每秒50个标记的推理速度下，语音质量可与标准SoundStream模型（标记率翻倍）相媲美。此外，仅使用四步扩散采样步骤，我们还实现了一步大小的蒸馏，仅造成微小的质量损失。", "conclusion": "DiffSoundStream在保持高质量语音生成的同时提高了语音分词的推理效率，并降低了不必要的冗余。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22360", "html_url": "https://arxiv.org/abs/2506.22360", "title": "从地面到空中：事件驱动车辆分类中视觉变换器和CNN的噪声鲁棒性及其在无人机应用的潜力", "title_en": "From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications", "authors": "Nouf Almesafri,Hector Figueiredo,Miguel Arana-Catania", "background": "本研究探讨了事件激活摄像机中两种最相关的计算机视觉深度学习架构——卷积神经网络（Convolutional Neural Network, CNN）和视觉变换器（Vision Transformer, ViT）的表现。事件激活摄像机捕捉场景变化，与传统的基于帧的摄像机拍摄静态图像不同，特别适用于无人机和自动驾驶车辆等动态环境。研究在GEN1事件驱动数据集上对ResNet34和ViT B16进行微调，并评估和比较了这两种模型在标准条件和模拟噪声条件下的性能。初始评估结果显示，ResNet34在分类准确性上略微占优，但ViT B16模型显示出较强的鲁棒性，尤其是考虑到它是在较小的数据集上预训练的。此研究主要集中在基于地面的车辆分类上，但方法和发现对无人机应用场景具有重要潜力，包括空中目标分类和航空相关的事件驱动视觉系统。", "innovation": "研究中使用了两个不同的深度学习模型（ResNet34和ViT B16）在标准和模拟噪声条件下对事件驱动摄像机数据进行微调，并且首次将视觉变换器（ViT）应用于事件驱动的车辆分类场景。该研究的重点是无人机的应用潜力，具有较高的创新性。", "conclusion": "研究结果显示，事件驱动摄像机特别适合动态环境，但需要进一步探索以提升在复杂条件下的性能。尽管两种模型均能取得较好的分类效果，但视觉变换器在噪声下的鲁棒性表现突出，提供了适应无人机应用场景的新思路。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.18578", "html_url": "https://arxiv.org/abs/2311.18578", "title": "通信高效的异构联邦学习与广义重球动量", "title_en": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum", "authors": "Riccardo Zaccone,Sai Praneeth Karimireddy,Carlo Masone,Marco Ciccone", "background": "联邦学习（FL）作为一种在隐私受限环境下分散数据学习的先进方法，近年来受到了广泛的关注。然而，现有的系统和统计挑战限制了其在实际场景中的应用，特别是在从边缘设备高效学习和处理数据异质性方面。尽管投入了大量研究，现有的方法往往由于数据异质性和参与客户端的随机性之间的联合效应而表现不佳。目前的方法中动量更新倾向于最近采样的客户端，这在一定程度上限制了其在现实大规模场景中的应用效果。因此，有必要改进方法，尤其是在解决数据异质性和参与度问题方面有所突破，以提高FL的实际应用效果.", "innovation": "本文提出了一种新的广义重球动量（GHBM），并理论上证明在循环少量参与的情况下，GHBM能够在未限定的数据异质性下实现收敛，从而进一步理解动量在联邦学习中的有效性。同时，我们引入了两种通信高效的GHBM变体，使其在客户端状态可保存的情况下通信复杂度与FedAvg相当。实验结果表明GHBM在随机均匀客户端采样的视觉和语言任务中均能大幅提升性能，尤其是在大规模场景和高数据异质性与低客户端参与度的情况下，GHBM表现尤为突出，这一改进具有显著的实际应用价值.", "conclusion": "GHBM不仅解决了现有的联邦学习方法在处理数据异质性和客户端参与度方面的不足，还提供了通信效率高的选项，使其实现了与FedAvg相当的通信复杂度。实验结果证实了该方法在多种任务中的有效性，其所带来的性能提升将有助于联邦学习在更广泛的实际应用场景中的部署。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22343", "html_url": "https://arxiv.org/abs/2506.22343", "title": "在混合人工智能-人类文本中水印比例的最优估计", "title_en": "Optimal Estimation of Watermark Proportions in Hybrid AI-Human Texts", "authors": "Xiang Li,Garrett Wen,Weiqing He,Jiayuan Wu,Qi Long,Weijie J. Su", "background": "文本水印在大型语言模型（LLMs）中是一个重要的工具，用于检测合成文本，区分人类撰写的文本和LLM生成的文本。现有大多数研究集中在确定整个文本是否被水印标记，而在现实世界场景中，涉及的是来源混合的文本，这些文本结合了人类创作和标记的内容。本文探讨了在混合来源文本中优化估计水印比例的问题，将其建模为基于关键统计量混合模型中的比例参数估计问题。研究发现，某些水印方案中该参数甚至不可识别或无法一致估计。然而，使用连续的关键统计量进行检测的方法，在温和条件下实现了参数的识别性。作者提出了一类方法的有效估计器，并给出了基于关键统计量的任何可测量估计器的最小最大下界，表明所提出的估计器达到了这些下界。通过合成数据和开源模型生成的混合来源文本实验，验证了所提出估计器的一致高估计精度。", "innovation": "该研究首次将水印比例估计建模为基于关键统计量的混合模型中的比例参数估计问题，并通过理论证明和实验证明了在特定条件下该参数的识别性。同时，本文还首次提出了适用于此类水印方法的有效估计器，并确定了基于关键统计量的估计器的最小最大下界，证明所提出的估计器达到了这些理论极限。研究还涉及使用开源模型生成的混合来源文本的实验，进一步验证了方法的有效性。", "conclusion": "本文展示了在混合来源文本中水印比例估计的新方法和理论极限，证明了特定条件下比例参数的识别性，并提出了高效估计器，通过实验证明了估计器在合成数据和开源模型生成的混合文本中的高估计精度。这一研究为后续研究提供了新的思路，并在实际应用中具有重要的潜在价值。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2107.13214", "html_url": "https://arxiv.org/abs/2107.13214", "title": "SONG: 自组织神经图", "title_en": "SONG: Self-Organizing Neural Graphs", "authors": "Łukasz Struski,Tomasz Danel,Marek Śmieja,Jacek Tabor,Bartosz Zieliński", "background": "近年来，深度可解释神经网络的研究呈现出了增长的趋势，决策树是其中最常用的一种工具。相比逻辑回归分类模型，决策树有三个主要优势：易于解释，可以快速做出决策，并提供了类别的层次结构。然而，与决策图相比，决策树的一个主要缺点是不能重用决策节点。尽管如此，由于缺乏有效的基于梯度的训练技术，决策图在深度学习中的应用并不广泛。本文填补了这一空白，并基于马尔可夫过程提供了一种可有效训练特殊类型决策图的通用范式，将其称为自组织神经图(SONG)。在Letter、Connect4、MNIST、CIFAR和TinyImageNet数据集上进行了实验证明，我们的方法表现与现有决策模型相当或更好。", "innovation": "本文提出了自组织神经图(SONG)，基于马尔可夫过程提供了一种可有效训练特殊类型决策图的新范式，解决了决策图在深度学习中不常用的问题，证明了新的方法在多个数据集上的优良表现。", "conclusion": "本文通过在多个数据集上的实验展示了自组织神经图(SONG)的有效性，表明该方法能够与现有的决策模型相媲美或更好，为进一步改进深度可解释神经网络提供了一种新的途径。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22429", "html_url": "https://arxiv.org/abs/2506.22429", "title": "超越ReLU：激活函数如何影响神经核和随机宽网络", "title_en": "Beyond ReLU: How Activations Affect Neural Kernels and Random Wide Networks", "authors": "David Holzmüller,Max Schölpple", "background": "尽管近年来深度学习的理论研究取得了一定进展，但这些研究大多局限于ReLU激活函数。尤其在神经核（NTK）和神经网络Gaussian过程核（NNGP）方面，它们给全连接神经网络的理论分析提供了可处理的极限情况，但对除ReLU函数幂次以外的大多数激活函数，其性质并没有很好地理解。本文旨在提供对这些核的RKHS（再生核希尔伯特空间）的更广泛刻画，特别是一些非光滑点仅在零点的激活函数，如SELU、ELU、或LeakyReLU，以及包括缺失偏置、两层网络或多项式激活在内的多种特殊情况。结果表明，非无穷光滑度激活函数产生不同网络深度的等效RKHS，而多项式激活则生成不同系数的RKHS。我们还推导出NNGP样本路径的平滑度结果，刻画无限宽神经网络在初始化时的平滑度.", "innovation": "本文的主要贡献在于，对于所有非光滑点只在零点的典型激活函数，提供这些核的RKHS的更广泛刻画，并涵盖了多层网络、缺失偏置和多项式激活等相关特殊情况。此外，探究了多项式激活与其他激活函数在产生等效RKHS方面的差异性，并推导NNGP样本路径的平滑度结果，这在初始化时对无限宽神经网络的平滑度进行了表征.", "conclusion": "所有非无穷光滑度激活函数的广泛类在不同网络深度上生成等效的RKHS，而多项式激活生成非等效的RKHS；NNGP样本路径的平滑度有具体结果；无限宽神经网络在初始化时的平滑度得到了表征."}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.14802", "html_url": "https://arxiv.org/abs/2402.14802", "title": "基于启发物理的图神经网络的链接预测", "title_en": "Link Prediction with Physics-Inspired Graph Neural Networks", "authors": "Andrea Giuseppe Di Francesco,Francesco Caso,Maria Sofia Bucarelli,Fabrizio Silvestri", "background": "GNNs的消息传递机制在异质数据集上表现不佳，其中相邻节点经常具有不同的标签。大多数解决该问题的方法仍局限于节点分类任务。本文关注在异质性环境下的链接预测任务，这对于推荐系统、社会网络分析等领域具有重要意义。现有的GNNs如GRAFF通过在架构中引入物理偏置，提高了在异质性条件下的节点分类性能。但目前还没有针对链接预测的专门方法改进GNNs。因此，有必要开发专门用于链接预测的性能评估方法，不同于节点分类方法。", "innovation": "本文提出了GRAFF-LP，这是GRAFF的扩展版本，专门用于链接预测。通过设计一种新的读取函数来学习区分实际链接和非实际链接，本文展示了GRAFF-LP在链接预测任务上的有效性和对其他基线模型的改善效果。值得注意的是，即使是最简单的GNNs，在预测异质链接方面也没有显著困难，这促使研究员认识到需要开发专门针对链接预测的异质性度量，不同于节点分类使用的度量方法。", "conclusion": "通过证明简易的GNNs在链接预测任务上并无明显劣势，并进一步开发了GRAFF-LP这一专为链接预测设计的方法，本文指出需要专门针对链接预测的评价标准和算法，而非简单依赖于节点分类的标准。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.15310", "html_url": "https://arxiv.org/abs/2405.15310", "title": "Spectraformer: 一种统一的随机特征框架用于Transformer", "title_en": "Spectraformer: A Unified Random Feature Framework for Transformer", "authors": "Duke Nguyen,Du Yin,Aditya Joshi,Flora Salim", "background": "线性化注意力机制的研究表明了其潜力。过去的方法只使用了随机特征范式中组合组件函数和权重矩阵的一部分组合。研究人员意识到对于Transformer中的注意力机制学习，需要系统地比较不同权重矩阵和组件函数的组合。", "innovation": "引入了Spectraformer，这是一个统一框架，用于近似和学习Transformer注意力机制中的核函数。实验结果显示，基于随机特征的方法在Long Range Arena基准上可以达到与顶级稀疏和低秩方法相当的性能，从而建立了基于随机特征高效Transformer的新最先进的水平。该框架还生成了许多不同的变体，这些变体在准确度、训练时间和内存消耗方面各有优势。", "conclusion": "我们的实验证明基于随机特征的方法在Transformer中具有潜力，并且提出了Spectraformer框架来实现这一目标。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.02239", "html_url": "https://arxiv.org/abs/2402.02239", "title": "分布性约简：基于Gromov-Wasserstein统一降维和聚类", "title_en": "Distributional Reduction: Unifying Dimensionality Reduction and Clustering with Gromov-Wasserstein", "authors": "Hugues Van Assel,Cédric Vincent-Cuaz,Nicolas Courty,Rémi Flamary,Pascal Frossard,Titouan Vayer", "background": "无监督学习旨在捕获潜在大型和高维数据集的内在结构。传统上，这涉及到使用降维（DR）方法将数据投影到低维空间，或将数据点组织成有意义的聚类。本文重新审视了这些方法，并在最佳传输（optimal transport）的视角下展示了它们与Gromov-Wasserstein问题的关系。", "innovation": "本文提出了一种新的通用框架，称为分布性约简（distributional reduction），该框架可以恢复降维和聚类作为特殊情况，并允许在单一优化问题中同时解决它们。", "conclusion": "该方法在多个图像和基因组数据集上对不同尺度下的低维原型的识别具有相关性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.02510", "html_url": "https://arxiv.org/abs/2406.02510", "title": "任意下游预测任务的公平优化合成EHR生成", "title_en": "Fairness-Optimized Synthetic EHR Generation for Arbitrary Downstream Predictive Tasks", "authors": "Mirza Farhan Bin Tarek,Raphael Poulain,Rahmatollah Beheshti", "background": "在确保AI工具在医疗应用中的负责任设计方面，公平性问题一直是一个关键关注点。电子健康记录(EHR)数据的广泛使用及其在临床决策支持任务中的巨大潜力，使得改善EHR为基础的健康AI工具的公平性尤为重要。虽然已经有各种方法来解决这个问题，但缺乏适用于多种任务和模型的方法。因此，该研究旨在通过提出一个新的合成EHR数据生成管道来填补这一空白，该管道不仅与真实EHR数据一致，还能在结合真实数据时减少下游任务中的公平性担忧（由最终用户定义）。", "innovation": "本文提出了一种新的合成EHR数据生成管道，该管道能够生成与真实EHR数据一致的数据，并能够减少下游任务中的公平性问题，从而为现有的公平性解决方案工具箱增添了广泛适用且补充的新工具。该方法适用于多种下游任务和不同的EHR数据集，具有显著的创新性。", "conclusion": "研究成果表明，提出的合成EHR数据生成管道在多种下游任务中都表现出有效性，为健康AI应用中的公平性问题提供了广泛适用且互补的解决方案。项目代码可以在指定的网址获取。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.07596", "html_url": "https://arxiv.org/abs/2407.07596", "title": "在帮助有需要的人的同时学习治疗效果", "title_en": "Learning treatment effects while treating those in need", "authors": "Bryan Wilder,Pim Welle", "background": "许多社会项目试图将稀缺资源分配给需求最大的人群。政府服务越来越多地使用基于这一目标的算法风险评估。然而，针对需求最大的受助人与试图评估整个项目的因果效应往往冲突，最佳评估可以通过随机分配获得。本文提出了一个框架，设计随机化分配规则以最优地平衡针对高需求个体与学习治疗效果之间的关系，为政策制定者提供在两个目标之间的帕累托前沿。", "innovation": "本文提出了一个框架设计随机化分配规则，通过计算有效的策略实现，优化了政策制定中的随机分配规则，可以在实现高需求个体筛选的同时提高治疗效果的学习。它还提供了这种方法的样本复杂性保证，并在宾夕法尼亚州阿勒格尼县的人力资源部门进行了实际数据应用验证。结果表明，所优化的政策能够显著缓解学习和针对性之间的权衡，例如，可以实现90%的最佳效能以筛选高需求个体，并确保平均治疗效应可以比随机对照试验少两倍样本量的情况下得到估计。", "conclusion": "本文的结果表明，公共服务中的机制不仅需要尽可能准确地衡量需求，还需要将评价项目作为明确目标并纳入算法系统，从而更有效地实现公共服务的最大价值。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.01115", "html_url": "https://arxiv.org/abs/2409.01115", "title": "随机卷积核进行时间序列分类：聚合操作符和输入表示形式很重要", "title_en": "Time series classification with random convolution kernels: pooling operators and input representations matter", "authors": "Mouhamadou Mansour Lo,Gildas Morvan,Mathieu Rossi,Fabrice Morganti,David Mercier", "background": "本文介绍了一种基于MiniRocket的新方法SelF-Rocket，用于快速时间序列分类（TSC）。现有的基于随机卷积核的方法通常会预先定义卷积核，但这些方法在动态选择训练过程中最佳的输入表示和聚合操作方面存在局限性。SelF-Rocket通过动态选择最佳的输入表示和聚合操作来克服这一局限性。该方法在UCR TSC基准数据集上实现了最先进的准确率，表明聚合操作符和输入表示形式的选择对时间序列分类至关重要。", "innovation": "SelF-Rocket方法通过在训练过程中动态选择最佳的输入表示和聚合操作符，克服了传统基于随机卷积核的方法的局限性。这种方法提高了时间序列分类的准确性和效率。", "conclusion": "SelF-Rocket方法在UCR TSC基准数据集上的表现优于现有方法，证明了聚合操作符和输入表示形式在时间序列分类中的重要性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03437", "html_url": "https://arxiv.org/abs/2410.03437", "title": "Zebra: 在上下文生成预训练解决参数PDE", "title_en": "Zebra: In-Context Generative Pretraining for Solving Parametric PDEs", "authors": "Louis Serrano,Armand Kassaï Koupaï,Thomas X Wang,Pierre Erbacher,Patrick Gallinari", "background": "解决时间依赖参数偏微分方程（PDEs）的数值逼近对数据驱动的方法来说是具有挑战性的，因为这些模型必须适应系数、激励项和初始条件的变化。最先进的人工智能代理通过梯度指导优化和元学习来隐式编码观测中的各种动态过程，但这种过程往往伴随着复杂度的增加。因此，需要一个在不需要梯度可导的情况下能够适应新任务的模型来解决参数化PDE的问题。受大型语言模型（LLMs）上下文学习能力的启发，我们提出了Zebra，这是一种新颖的生成自回归变换器，能够在无需梯度适应的情况下解决参数PDE。Zebra通过在预训练和推断过程中利用上下文信息动态适应新任务，并通过输入序列中的上下文示例轨迹进行条件化。作为一种生成模型，Zebra还能够生成新的轨迹，并允许量化预测的不确定性。我们使用Zebra评估了一系列具有挑战性的PDE场景，证明了其适应性、鲁棒性和优于现有方法的性能。", "innovation": "Zebra通过生成自回归变换器，在预训练和推断过程中利用上下文信息，无需梯度适应来解决参数PDE，动态适应新任务，并通过输入序列中的上下文示例轨迹进行条件化。作为一种生成模型，Zebra还能够生成新的轨迹，并允许量化预测的不确定性。", "conclusion": "Zebra在各种具有挑战性的PDE场景中表现出色，其适应性、鲁棒性和性能均优于现有方法。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.11240", "html_url": "https://arxiv.org/abs/2408.11240", "title": "在因果带宽问题中具有低复杂性的不对称图误差控制", "title_en": "Asymmetric Graph Error Control with Low Complexity in Causal Bandits", "authors": "Chen Peng,Di Zhang,Urbashi Mitra", "background": "本文研究了因果带宽问题，旨在通过在未知因果图上选择最优节点干预期数以实现长期奖励最大化。假定因果拓扑和干预分布都是未知的。在图识别错误（假正和假负）之间存在差异的基础上，提出了一种因果图学习方法，该方法通过学习子图降低了样本复杂性。基于最小均方误差加权估计，推导出适用于因果带宽问题的新不确定性界限，该不确定性界限用于上置信边界干预选择以优化奖励。同时，考虑了因果拓扑和干预分布可以变化的非平稳带宽问题，设计了一种子图变化检测机制，该机制需要较少的样本。", "innovation": "提出了因果图学习新方法，通过学习子图降低了样本复杂性；推导出新不确定性界限适合因果带宽问题；设计了子图变化检测机制，适用于非平稳带宽问题；在不同的应用场景中表现出显著性能提升，与现有方法相比，在100个随机生成的因果带宽场景下，所提方案显著减少学习因果结构所需的样本量，并获得85%的奖励增益。", "conclusion": "研究提出了针对因果带宽问题的新方法，并通过实验验证了其有效性和优越性。设计的子图变化检测机制在非平稳条件下表现突出，方法在样本效率和奖励提升方面优于现有方案。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.15237", "html_url": "https://arxiv.org/abs/2408.15237", "title": "Llama中的Mamba：精简与加速混合模型", "title_en": "The Mamba in the Llama: Distilling and Accelerating Hybrid Models", "authors": "Junxiong Wang,Daniele Paliotta,Avner May,Alexander M. Rush,Tri Dao", "background": "线性循环神经网络（RNN）架构，如Mamba，可以在语言建模中与 Transformer 模型竞争，同时具有更好的部署特性。鉴于当前对大规模 Transformer 模型的训练关注，本文探讨了将这些预训练模型转换为部署形式的挑战。研究表明，可以利用学术级 GPU 资源通过复用注意力层的线性投影权重，将大型 Transformer 模型精简为线性 RNN。这种混合模型保留了四分之一的注意力层，并且在聊天基准测试和通用基准测试中性能优于从零开始训练的大规模开源混合 Mamba 模型。此外，还提出了一种硬件感知的推测性解码算法，加速了 Mamba 和混合模型的推理速度。通过这种方法，可以在有限的计算资源下去除大部分原始注意力层，并更高效地生成结果模型。从 Llama3-8B-Instruct 精简出的最高效模型，在 AlpacaEval 2 上取得了 29.61 的长度控制胜率，对战 GPT-4，MT-Bench 上得到 7.35 的分数，超过了最好的 8B 规模指令调优线性 RNN 模型。研究还发现，精简模型具有自然长度外推能力，在 20 倍的精简长度下针叶林测试中几乎达到完美的准确性。", "innovation": "提出了将大规模 transformer 模型精简为线性 RNN 的方法，通过复用注意层的线性投影权重，保持四分之一的注意层。引入了一种硬件感知的推测性解码算法来加速模型推理。通过有限计算资源可以移除大部分原始注意力层，同时生成模型更加高效。从 Llama3-8B-Instruct 精简出的最高效模型在多个基准测试中取得了优异的成绩。", "conclusion": "研究展示了如何在有限计算资源条件下，通过精简和加速混合模型的方法，移除大部分原始注意力层，并生成高效的模型。这些模型不仅在聊天基准测试中表现出色，还展示了自然长度外推能力，特别是在长文本生成任务中表现优异。开源代码和预训练检查点可以在提供的链接中访问。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10926", "html_url": "https://arxiv.org/abs/2410.10926", "title": "联邦高效指令调优以用于大型语言模型", "title_en": "Federated Data-Efficient Instruction Tuning for Large Language Models", "authors": "Zhen Qin,Zhaomin Wu,Bingsheng He,Shuiguang Deng", "background": "预训练的大语言模型（LLMs）对人类指令的响应性可以通过指令调优提高，而联邦学习（FL）可以利用来自客户端的大量私有指令数据，有助于LLMs的调优。现有的联邦调优方法会消耗所有本地数据，导致计算负担过重并过度拟合本地数据，且集中式的数据高效解决方案由于隐私问题不适合于FL。", "innovation": "提出了FedHDS，一种联邦高效指令调优方法，它利用边缘端数据的一部分进行调优，减少数据冗余而不分享原始数据。实验结果表明，FedHDS相较于最新的联邦全数据指令调优方法在未见任务上的 Rouge-L 得分平均提升了10.72%，并仅使用了不到1.5%的数据样本，提升了数十倍的训练效率。", "conclusion": "FedHDS 方法在高效利用有限的客户端数据集进行调优的同时，有效减少了数据冗余，并显著提高了LLO的训练效率，而不会牺牲调优效果。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.13794", "html_url": "https://arxiv.org/abs/2501.13794", "title": "揭示噪声先验的力量：增强基于扩散模型的移动交通预测", "title_en": "Unveiling the Power of Noise Priors: Enhancing Diffusion Models for Mobile Traffic Prediction", "authors": "Zhi Sheng,Daisy Yuan,Jingtao Ding,Yong Li", "background": "移动网络流量的准确预测对于优化网络性能和支持城市发展至关重要。然而，移动网络流量由于人类活动和环境变化表现出非平稳特性，导致既有规律性又有突发性变化。现有的扩散模型由于能够捕捉这些复杂的时间动态而表现出色。尽管大多数现有的方法更侧重于设计新颖的去噪网络，但往往忽视了噪声本身的作用，可能导致性能欠佳。", "innovation": "本文提出了一个新的视角，强调噪声在去噪过程中的作用。研究表明，噪声从根本上影响移动网络流量预测，并展现出不同的和一致的模式。提出的NPDiff框架将噪声分解为先验和残差组件，其中先验是基于数据动态得出的，从而增强了模型捕捉规律性和突发性变化的能力。NPDiff可以无缝集成到各种基于扩散的预测模型中，提供有效的、高效的和鲁棒的预测。实验证明，该方法相比于现有方法提升了超过30%的性能，为利用扩散模型提供了新的视角。", "conclusion": "通过将去噪过程中的噪声整合进扩散模型的预测框架，NPDiff显著提升了移动网络流量预测的性能，提供了优于传统方法的有效、高效且鲁棒的预测。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06020", "html_url": "https://arxiv.org/abs/2410.06020", "title": "QT-DoG: 量化感知训练在域泛化中的应用", "title_en": "QT-DoG: Quantization-aware Training for Domain Generalization", "authors": "Saqib Javed,Hieu Le,Mathieu Salzmann", "background": "域泛化（Domain Generalization, DG）面临的挑战是如何防止模型过拟合到训练数据源域，这可以通过寻找损失景观中的更平坦的最小值来缓解。传统的量化方法更侧重于模型压缩，而本研究将量化作为隐式正则化手段，通过在模型权重中引入噪声，引导优化过程趋向更平坦、对扰动不敏感的最小值，从而提高域泛化的性能。", "innovation": "提出了一种新的方法，Quantization-aware Training for Domain Generalization (QT-DoG)，通过量化作用作为隐式正则化手段，引导优化过程接近更平坦的最小值，减少对扰动和过拟合的敏感性。与传统的量化方法不同，QT-DoG 利用量化在模型权重中引入噪声来降低过拟合的风险，从而提高模型的域泛化能力。此外，通过量化模型大小的减少和多量化模型的集成增强了模型的准确性，而没有增加计算或内存开销。", "conclusion": "QT-DoG 方法不仅通过减轻过拟合提高了模型的域泛化性能，还通过量化方法减少了模型大小，同时通过集成多量化模型进一步提高了准确率，展示了这种方法在域泛化领域的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.01370", "html_url": "https://arxiv.org/abs/2501.01370", "title": "基于词嵌入的方法在虚假极化新闻检测中的应用", "title_en": "Embedding-based Approaches to Hyperpartisan News Detection", "authors": "Karthik Mohan,Pengyu Chen", "background": "极化新闻（Hyperpartisan news）是指那些采取极端政治立场并有意图制造公众政治分歧的新闻。识别这类新闻在信息筛选和传播中具有重要价值，尤其是在网络环境中，虚假极化新闻往往依赖情感强烈、立场明确的内容来吸引关注，这对新闻真实性和公众理性讨论构成威胁。本文基于预训练的ELMo与双向LSTM模型，探讨了如何有效识别极化新闻的文章。研究中尝试了多种方法，包括n-grams、情感分析以及文档表示。", "innovation": "本文采用预训练的ELMo和双向LSTM模型进行虚假极化新闻检测，此方法能够在10折交叉验证中实现83%的准确率，无需进行复杂的超参数调整，提供了新的视角和技术手段。", "conclusion": "通过将预训练的ELMo与双向LSTM结合，该研究提出了一种有效的极化新闻检测方法，实验结果显示准确性较高，表明这种方法在极化新闻检测任务上的实用性和有效性。尽管只达到83%的准确性，该系统为未来的改进提供了基础，同时也为实际应用提供了一种可操作的方案。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.14593", "html_url": "https://arxiv.org/abs/2409.14593", "title": "通过条件独立性在多项式延迟下测试具有隐藏变量的因果模型", "title_en": "Testing Causal Models with Hidden Variables in Polynomial Delay via Conditional Independencies", "authors": "Hyunchai Jeong,Adiba Ejaz,Jin Tian,Elias Bareinboim", "background": "对假设的因果模型进行因果推断之前，需要测试模型中假设的条件独立关系(CIs)是否在观察数据中成立。尽管模型可以假设指数数量的CIs，但测试所有CIs既不现实也不必要。因果图用多项式空间编码CIs，使得通过局部马尔可夫性质能够使用显著较小的CIs子集进行测试。然而，在存在隐藏变量和非参数分布的情况下，现有算法甚至生成一个CIs约束都需要指数时间。因此，关键挑战在于以多项式延迟列出相关CIs，并进行有效测试。", "innovation": "本文提出了具有隐藏变量的因果图的c-组件局部马尔可夫性质(C-LMP)，并开发了一种多项式延迟算法，能够在多项式时间内生成这些CIs。这是首次能够在具有隐藏变量的因果图上，通过任意数据分布实现CIs的多项式延迟测试的算法。实验结果证明了该算法的实用性。", "conclusion": "本文通过c-组件局部马尔可夫性质，提出了多项式延迟算法，能够在具有隐藏变量的因果图中进行有效的CIs测试，解决了复杂因果模型中CIs测试的挑战。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.17443", "html_url": "https://arxiv.org/abs/2501.17443", "title": "图学习中的逐步域适应", "title_en": "Gradual Domain Adaptation for Graph Learning", "authors": "Pui Ieng Lei,Ximing Chen,Yijun Sheng,Yanyan Liu,Jingzhi Guo,Zhiguo Gong", "background": "现有文献缺乏处理大量分布变化的图域适应技术，主要原因是难以模拟从源图到目标图的演变路径。", "innovation": "提出了一个图逐步域适应（GGDA）框架，该框架通过构建一个紧凑的领域序列来最小化适应中的信息损失。该方法使用融合伯恩斯坦-瓦瑟斯坦（FGW）度量高效生成保留知识的中间图，并通过基于顶点的领域进展构建GGDA领域，该进展包括“接近”的顶点选择和适应性领域推进，以增强跨域信息传递性。此外，框架通过可实施的上界和下界实现了不可处理的跨域距离 $W_p(\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{)}}}}}}}}}}}}})$，以灵活调整该度量来优化领域形成。", "conclusion": "在各种转移场景下的广泛实验验证了我们GGDA框架的优越性能。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02189", "html_url": "https://arxiv.org/abs/2502.02189", "title": "deCIFer: 使用自回归语言模型从粉末衍射数据预测晶体结构", "title_en": "deCIFer: Crystal Structure Prediction from Powder Diffraction Data using Autoregressive Language Models", "authors": "Frederik Lizak Johansen,Ulrik Friis-Jensen,Erik Bjørnager Dam,Kirsten Marie Ørnsbjerg Jensen,Rocío Mercado,Raghavendra Selvan", "background": "新材料在能源存储和电子等领域均推动着技术进步。机器学习方法自动化的材料结构表征为这一关键步骤的加速提供了可能。已有工作主要依赖于组成等高级描述符进行晶体结构预测（CSP），但本研究的模型deCIFer能利用粉末X射线衍射（PXRD）数据进行预测，显示了预测晶体结构的新途径。", "innovation": "deCIFer是一种自回归语言模型，可以从粉末衍射数据预测晶体结构并生成Crystallographic Information File (CIF)格式的结构，特别是它能够利用衍射数据进行预测，而不仅仅是依赖于组成等描述符。与以往工作相比，该模型在近230万种晶体结构上进行训练，并在多样化的PXRD数据集上进行验证，显示出更高的准确性，测试数据匹配率达到94%。", "conclusion": "deCIFer通过连接实验衍射数据和计算晶体结构预测，成为一种强大的晶体结构表征工具。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06737", "html_url": "https://arxiv.org/abs/2502.06737", "title": "VersaPRM：基于合成推理数据的多领域过程奖励模型", "title_en": "VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data", "authors": "Thomas Zeng,Shuibai Zhang,Shutong Wu,Christian Classen,Daewon Chae,Ethan Ewer,Minjae Lee,Heeju Kim,Wonjun Kang,Jackson Kunde,Ying Fan,Jungtaek Kim,Hyung Il Koo,Kannan Ramchandran,Dimitris Papailiopoulos,Kangwook Lee", "background": "过程奖励模型（PRMs）已经在增强大型语言模型（LLMs）的数学推理方面证明了其有效性，但它们主要是在数学数据上进行训练，对其在非数学领域的泛化能力尚未进行严格的评估和研究。现有的PRMs在其他领域表现不佳，这一缺点限制了它们的应用范围。因此，研究者们需要一种能在多种领域都表现出色的新方法来克服这一限制。", "innovation": "引入了VersaPRM，这是一种多领域PRM，通过使用研究人员新开发的数据生成和注释方法，在合成推理数据上进行了训练。相比单领域PRM，VersaPRM在不同领域中展示了持续的性能提升。例如，VersaPRM在MMLU-Pro类别中的法律领域，通过带权多数投票，相比多数投票基线获得了7.9%的性能提升，超过了Qwen2.5-Math-PRM的1.3%的提升。开源了用于VersaPRM的所有数据、代码和模型也是一项重要贡献。", "conclusion": "VersaPRM通过在合成推理数据上的训练和多领域的应用证明了其在非数学领域中的泛化能力显著优于现有的单领域PRM。开源的数据和模型将有助于深化对过程奖励模型的研究与应用。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14291", "html_url": "https://arxiv.org/abs/2501.14291", "title": "时间点过程进展：贝叶斯、神经网络和大语言模型方法", "title_en": "Advances in Temporal Point Processes: Bayesian, Neural, and LLM Approaches", "authors": "Feng Zhou,Quyu Kong,Jie Qiao,Cheng Wan,Yixuan Zhang,Ruichu Cai", "background": "时间点过程（TPPs）是用于表征在连续时间中发生的事件序列的随机过程模型。传统统计TPPs历史悠久，已有众多模型在各个领域得到应用。近年来，深度学习的进步促进了神经TPPs的发展，使其能够更好地捕捉复杂的时序动态。大语言模型的出现进一步激发了研究兴趣，提供了通过利用丰富的上下文理解来建模和分析事件序列的新可能性。本文对该主题进行了全面回顾，从贝叶斯、神经网络和大语言模型三个视角进行了深入讨论。", "innovation": "神经TPPs使得捕捉复杂时序动态更具灵活性和表达性；大语言模型则通过其丰富的上下文理解提供新的建模和分析事件序列的可能性。研究在三个框架下对该主题进行了回顾和深入讨论，介绍了模型设计和参数估计技术，展示了经典应用领域的实用相关性，并指出了未来研究的挑战和方向。", "conclusion": "本文回顾了时间点过程从贝叶斯、神经网络和大语言模型三个视角的最新研究成果，讨论了模型设计和参数估计技术，强调了经典应用领域的实际相关性，并指出了未来研究的方向。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01980", "html_url": "https://arxiv.org/abs/2502.01980", "title": "基于长尾引导扩散的生成数据挖掘", "title_en": "Generative Data Mining with Longtail-Guided Diffusion", "authors": "David S. Hayden,Mao Ye,Timur Garipov,Gregory P. Meyer,Carl Vondrick,Zhao Chen,Yuning Chai,Eric Wolff,Siddhartha S. Srinivasa", "background": "预测模型在部署后会遇到各种难以预见的挑战，常见的做法是采取一种反应式的循环方法：模型部署、数据挖掘和重新训练。本文的背景是探索一种更积极的方法，在模型训练阶段就考虑可能遇到的长尾数据，从而在模型部署前预先生成这些数据，提高模型的鲁棒性和泛化能力。", "innovation": "本文提出了一种名为Longtail Guidance (LTG)的生成数据挖掘方法，在模型训练过程中通过差分、单向前向传递的形式生成认知不确定性信号，这些信号不影响模型参数和预测性能，但可以标记稀有或难以处理的输入。该方法利用这些信号来生成额外的训练数据，而不需要重新训练扩散模型或预测模型，也不需要让预测模型接触到中间的扩散状态。这种方法生成的数据具有语义上的显著变化，能够大幅提升多种图像分类基准的泛化性能，并且可以通过视觉语言模型（VLM）进行主动发现、文本解释和解决部署预测模型的概念缺口问题", "conclusion": "本文通过开发一种基于认知不确定性的长尾信号和长尾引导扩散生成数据的方法，能够在不重新训练模型的情况下生成大量先前罕见或难以处理的数据，提高了模型的泛化能力和鲁棒性，并且通过可解释的方式帮助解决模型部署后可能出现的概念性问题。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14652", "html_url": "https://arxiv.org/abs/2501.14652", "title": "Decoupled SGDA for Games with Intermittent Strategy Communication", "title_en": "Decoupled SGDA for Games with Intermittent Strategy Communication", "authors": "Ali Zindari,Parham Yazdkhasti,Anton Rodomanov,Tatjana Chavdarova,Sebastian U. Stich", "background": "在多人游戏中，频繁交换策略不可行，玩家之间的策略往往是过时或有噪声的。因此，需要一种方法来减少通信开销，同时保持有效的策略更新，尤其是在交互较少的游戏中，策略同步的成本尤为重要。", "innovation": "提出了一种称为解耦SGDA（Decoupled SGDA）的新型Stochastic Gradient Descent Ascent（SGDA）变体。在该方法中，玩家根据过时的对手策略独立更新其策略，并定期同步以对齐策略。对于强凸强凹（SCSC）博弈，解耦SGDA实现了接近最优的通信复杂度，与已知的最佳GDA速率相当。对于弱耦合博弈，解耦SGDA相比标准SGDA显著减少了通信成本。此外，通过在二次最小模极大问题中详细研究解耦SGDA的收敛性，进一步探讨了通信频率对收敛的影响。在玩家噪声不平衡的情况下，解耦SGDA在联邦最小模极大方法中表现出色，显著优于联邦最小模极大方法。", "conclusion": "解耦SGDA通过在多人博弈中根据过时的对手策略独立更新策略，并定期同步来减少通信开销，尤其适用于交互较少的博弈。对于强凸强凹博弈，它实现了接近最优的通信复杂度。对于弱耦合博弈和玩家噪声不平衡的情况，解耦SGDA相比标准方法和联邦最小模极大方法具有显著优势。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00944", "html_url": "https://arxiv.org/abs/2502.00944", "title": "静态和动态批量算法在图神经网络中的分析", "title_en": "Analysis of static and dynamic batching algorithms for graph neural networks", "authors": "Daniel T. Speckhard,Tim Bechtel,Sebastian Kehl,Jonathan Godwin,Claudia Draxl", "background": "图神经网络（GNN）在材料科学、化学和社会科学等领域表现出色。GNN模型通常包含数百万个参数，就像其他神经网络（NN）模型一样，它们在训练过程中只会被少量的图批次输入更新模型参数。尽管对NN模型的批量算法已有广泛研究，但这些研究尚未对GNN模型进行深入探讨。本文作者分析了两种不同的批量算法（静态和动态排列）对基于图的模型的影响，分别在QM9小型分子数据集和AFLOW材料数据库上进行了测试。", "innovation": "探讨了两种不同的批量算法（静态和动态排列）对GNN的影响，并在QM9小型分子数据集和AFLOW材料数据库上进行了实验。研究结果显示更改批量算法可以提供高达2.7倍的加速，但最优算法依赖于数据、模型、批次大小、硬件和训练步骤数等因素。此外，文章指出，在某些组合下，静态和动态批量算法之间存在显著的学习度量差异。", "conclusion": "批量算法的变更可以提供高达2.7倍的加速，但不同数据、模型、批次大小、硬件和训练步骤数等因素会影响最优算法的选择。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02379", "html_url": "https://arxiv.org/abs/2502.02379", "title": "没有一个万能的指标：走向图学习数据集的原理性评估", "title_en": "No Metric to Rule Them All: Toward Principled Evaluations of Graph-Learning Datasets", "authors": "Corinna Coupette,Jeremy Wayland,Emily Simons,Bastian Rieck", "background": "图学习中的基准数据集对领域成功至关重要，而高质量的基准数据集能够引导领域发展。近期研究揭示了图学习数据集和评估实践存在的问题，例如忽视图结构的方法竟可超越基于图的方法。这些问题引发了两个关键问题：什么是优质的图学习数据集，以及如何评估图学习数据集的质量。这些数据集通常依赖经典评估设置来评估模型性能，但并不适用于数据集本身的评估。鉴于图学习数据集结合了图结构和节点特征两种模式，作者提出了一种灵活且可扩展的模式扰动框架Ring，通过数据集的损益比来评估图学习数据集的质量，并提出了两种评估工具：性能可分性和模式互补性，以从不同角度评估图数据集。实验展示了该框架的效用，提出了改进图学习方法评估的建议。这项工作有助于数据为中心的图学习研究，并提出了一种系统评估评估方法的方向。", "innovation": "作者提出了一个灵活且可扩展的模式扰动框架，称为Rings，通过数据集的损益比来评估数据集质量，还提出了两种新的评估工具：性能可分性和模式互补性，能够从不同角度评估图学习方法的效果，为图学习方法提供不同的评估视角。此外，作者的工作指出了传统模型评估方法不适用于图学习数据集评估的问题，并提供了一种新的数据集评估框架，开启了数据为中心的图学习研究的新方向，推动了该领域的系统评估进程。", "conclusion": "作者的工作不仅解决了图学习数据集评估中两个关键问题，还为数据为中心的图学习研究提供了新的方向，推动了该领域更系统、更全面的评估方法的发展。随后的研究可以在此基础上进一步研究基于不同场景和需求的评估方法，更好地服务于图学习方法的实际应用。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20380", "html_url": "https://arxiv.org/abs/2502.20380", "title": "单步奖励下的多轮代码生成", "title_en": "Multi-Turn Code Generation Through Single-Step Rewards", "authors": "Arnav Kumar Jain,Gonzalo Gonzalez-Pumariega,Wayne Chen,Alexander M Rush,Wenting Zhao,Sanjiban Choudhury", "background": "现有方法要么在没有反馈的情况下生成代码，要么使用复杂的分层强化学习来优化多轮奖励。论文分析了这些方法的局限性和不足之处，指出它们在处理多轮代码生成时存在问题，并需要一种新方法来改进和优化代码生成过程.", "innovation": "提出了一个简单而可扩展的方法$跳$Code，通过仅使用单步奖励解决多轮代码生成问题。关键在于代码生成可以被视为一种可恢复的单一状态马尔可夫决策过程（MDP），其中正确代码可以从任一中间代码状态在一个回合中恢复。$跳$Code通过迭代训练生成器和验证器来实现这一目标，生成器根据多轮执行反馈提供代码解决方案，验证器评估新生成的代码。实验结果表明，该方法在性能上优于现有最先进的基线方法，并且能够有效利用执行反馈进行优化.", "conclusion": "实验表明$跳$Code在处理多轮代码生成任务时表现优异，通过仅使用单步奖励达到了显著的改进。该方法的成功验证了其设计选择的有效性，并展示了其在多轮执行反馈使用上的优越性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09692", "html_url": "https://arxiv.org/abs/2502.09692", "title": "AB-UPT: 支撑高保真汽车气动模拟的锚点分支通用物理变换器神经近似模型", "title_en": "AB-UPT: Scaling Neural CFD Surrogates for High-Fidelity Automotive Aerodynamics Simulations via Anchored-Branched Universal Physics Transformers", "authors": "Benedikt Alkin,Maurits Bleeker,Richard Kurle,Tobias Kronlachner,Reinhard Sonnleitner,Matthias Dorfer,Johannes Brandstetter", "background": "近期的神经近似模型在汽车气动学领域的应用展现出潜在的重大变革。然而，工业规模的应用往往涉及数十亿个网格单元，这带来了巨大的可扩展性挑战。复杂的几何形状进一步增加了通过复杂的表面-体积交互进行建模的难度，量纲如涡量等高度非线性并且需要满足严格的散度为零的约束。为应对这些挑战，我们介绍了锚点分支通用物理变换器 (AB-UPT) 作为计算流体动力学 (CFD) 模型神经近似方案的新颖方案。", "innovation": "AB-UPT 通过多分支操作分离几何编码和预测任务；利用低维潜空间中的神经模拟和锚定神经场解码器支持高分辨率输出的可扩展性；通过新颖的散度为零的公式确保物理一致性。展示了 AB-UPT 在从 33,000 到 150,000,000 个网格单元的汽车 CFD 模拟中达到最先进的预测精度。同时，锚定神经场架构使我们在不降低性能的情况下能够强制执行严格的物理约束，例如模拟无散度涡量场。所提出的模型可以在单个 GPU 上在一天内训练完成，并在几秒内预测出行业标准的表面和体积场。另外，该方法的灵活设计允许仅从计算机辅助设计几何模型进行神经模拟，省去了昂贵的 CFD 网格划分过程。", "conclusion": "我们通过 AB-UPT 实现了高保真的 CFD 模拟，它克服了传统方法的可扩展性、几何复杂性和物理约束难题，并显著简化了模型训练和预测过程。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03313", "html_url": "https://arxiv.org/abs/2503.03313", "title": "LLM作为GNN：面向文本属性图基础模型的图形词汇学习", "title_en": "LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph Foundation Models", "authors": "Xi Zhu,Haochen Xue,Ziwei Zhao,Wujiang Xu,Jingyuan Huang,Minghao Guo,Qifan Wang,Kaixiong Zhou,Yongfeng Zhang", "background": "文本属性图（TAGs）在现实世界中普遍存在，每个节点都关联有文本描述，这些图通常表现出独特的结构和领域特定的知识，这驱动着构建一个基础模型（GFM）的需求，该模型能够跨不同类型的图和任务泛化。尽管在将大型语言模型（LLMs）和图神经网络（GNNs）结合应用于TAGs方面已经投入了大量的努力，但现有方法存在分阶段架构和逻辑层次分离的问题，这限制了它们的协同潜力。更糟糕的是，现有方法给词汇表中不存在的标记（OOV tokens）分配给图节点，导致图特定的意义、标记爆炸和与任务导向的提示模板不兼容，从而阻碍了跨图和跨任务的转移学习可实现性。", "innovation": "本文提出了一种名为PromptGFM的通用GFM，它是一种基于图形词汇学习的文本属性图基础模型。PromptGFM包含两个关键组件：（1）图形理解模块，明确提示LLMs在文本空间中复现最细粒度的GNN工作流程，促进GNN-LLM的无缝集成和优雅的图形-文本对齐；（2）图形推断模块，建立基于语言的图形词汇确保表达能力、转移性及可扩展性，使LLM微调具有可读性指令。实验证明，该方法在多种图形和任务中表现优越并且具有可转移性", "conclusion": "广泛实验结果显示，PromptGFM在不同的图和任务中展现出优越性和可转移性。代码已在此处公开：this https URL."}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.12016", "html_url": "https://arxiv.org/abs/2503.12016", "title": "联邦大规模语言模型微调调查", "title_en": "A Survey on Federated Fine-tuning of Large Language Models", "authors": "Yebo Wu,Chunlin Tian,Jingguang Li,He Sun,Kahou Tam,Zhanting Zhou,Haicheng Liao,Zhijiang Guo,Li Li,Chengzhong Xu", "background": "大规模语言模型（LLMs）在各种任务中表现出色。将LLMs与联邦学习（FL）结合，构建FedLLM，为合作模型适应提供了可能，同时保护数据隐私。本文对该领域进行了系统和全面的回顾，追溯了LLMs和FL的历史发展，总结了相关先前研究，概述了部署FedLLM所面临的根本挑战，探讨了现有的高效适应策略并评估了其在FL框架中的适用性，考察了现有微调数据集和评估基准，并讨论了FedLLM在多个领域的多种实际应用。", "innovation": "本文提供了一个关于FedLLM的全面回顾，重点在于系统的挑战分析、现有微调策略的探讨及其在FL框架中的应用，以及对评估基准和数据集的深入审查。研究还提出了关键的开放挑战和未来研究方向，旨在促进该领域的未来创新。", "conclusion": "本文为研究人员和从业者提供了有关LLMs联邦微调快速发展领域的宝贵见解，并建立了未来隐私保护AI创新的路线图。此外，我们积极维护GitHub仓库以跟踪这一领域的最新进展。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03583", "html_url": "https://arxiv.org/abs/2504.03583", "title": "具有多种平滑先验的大规模超图结构学习", "title_en": "Scalable Hypergraph Structure Learning with Diverse Smoothness Priors", "authors": "Benjamin T. Brown,Haoxiang Zhang,Daniel L. Lau,Gonzalo R. Arce", "background": "在图信号处理中，当不知道潜在关系时，从一组样本信号中学习节点之间的加权连接是一个基本任务。通常，此任务通过找到使观察到的信号平稳的图拉普拉斯矩阵来解决。超图是图的扩展，其中边可以连接超过两个节点，因此图学习方法也被推广到超图。然而，由于没有统一的框架来计算总体变差，导致了不同的平滑定义和不同的超边恢复方法。", "innovation": "本文通过推广先前提出的几种超图总体变差，提出了一种名为Hypergraph Structure Learning with Smoothness (HSLS)的新型超图学习方法。HSLS通过使用凸优化和前向-后向-前向算法来解决平滑性先验问题，并通过限制超边搜索范围和保持有效的超边选择集来增强可扩展性。此外，我们的方法在较大超图中保持全局光滑性偏好，并且在不同总体变差项下表现出鲁棒性。", "conclusion": "实验结果表明，与其他最先进的超图推理方法相比，该方法在准确度方面表现出改进；另外，实验数据显示该方法对总体变差项具有鲁棒性，更倾向于全局平滑性，并且对较大超图具有可扩展性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.23167", "html_url": "https://arxiv.org/abs/2503.23167", "title": "图ODE及其扩展：图神经网络与微分方程整合的综合调查", "title_en": "Graph ODEs and Beyond: A Comprehensive Survey on Integrating Differential Equations with Graph Neural Networks", "authors": "Zewen Liu,Xiaoda Wang,Bohan Wang,Zijie Huang,Carl Yang,Wei Jin", "background": "图神经网络（GNNs）和微分方程（DEs）是近年来迅速发展的两个研究领域，两者在解决物理建模、时空建模和科学计算等问题上展现出了显著的协同效应。GNNs 作为处理图结构数据的强大工具，而 DEs 提供了一种原理性的框架来建模时间和空间中的连续动态过程。这两个领域的交汇点催生了将双方长处相融合的方法，促进了物理感知学习、时空模型建模等领域的发展。", "innovation": "本文综述了 GNNs 和 DEs 相交领域的创新方法，突出展示了这些方法在分子建模、交通预测和疫情传播等方面的应用，同时也指出了该领域存在的挑战并提出了未来的研究方向，推动了这一跨学科领域的进一步发展。", "conclusion": "本文提供了 GNNs 与 DEs 整合研究领域的全面概述，分类总结了现有方法，探讨了它们的基本原理及其在多个领域的应用，并对未来研究方向进行了展望，以供研究人员和实践者理解和贡献于 GNNs 与 DEs 的结合领域。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18710", "html_url": "https://arxiv.org/abs/2504.18710", "title": "非分离数据的显式神经网络分类器", "title_en": "Explicit neural network classifiers for non-separable data", "authors": "Patrícia Muñoz Ewald", "background": "研究了前馈神经网络在特征映射方面的特性，特别是通过裁剪映射来全面描述这一类网络。论文探讨了如何利用ReLU神经网络实现分隔同心数据的特征映射，这些都是基于对前馈神经网络特性的理解和发展现状的背景之上展开的分析和研究。", "innovation": "论文创新之处在于通过裁剪映射全面描述了一类前馈神经网络，并展示了如何利用ReLU神经网络实现用于分隔同心数据的特征映射。这一方法为处理非分离数据提供了一种新的分类器设计思路和方法。", "conclusion": "论文总结了通过裁剪映射来描述前馈神经网络特性的成果，并展示了这种描述方法在实现特定特征映射（例如分隔同心数据）的有效性。研究成果为非分离数据的分类提供了新的理论基础和技术路径。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10386", "html_url": "https://arxiv.org/abs/2503.10386", "title": "多阈值好臂识别的带宽反馈", "title_en": "Multi-thresholding Good Arm Identification with Bandit Feedback", "authors": "Xuanke Jiang,Sherief Hashima,Kohei Hatano,Eiji Takimoto", "background": "本文考虑了在多目标下的随机多臂博弈中识别优良臂的问题。每个臂i属于[K]集合，并与一个定义在R^M上的分布D_i相关联。在每一轮t中，玩家选择一个臂i_t并通过D_{i_t}采样获得一个M维奖励向量。目标是高概率地找到一个$\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bmi}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$-好臂，其期望奖励向量大于$\bm{\theta} - \bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bm{\bmi}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$，各个分量间的比较是逐个进行的。", "innovation": "提出了一个多阈值UCB（MultiTUCB）算法，并提供了样本复杂度上界。该上界在特定情况下，即$M=1$和$\bm{\bm{\bm{\bm{\bmi}}}}=0$时与现有理论匹配。本文算法在合成数据集和真实数据集上均比基线方法表现更优。", "conclusion": "本文在多目标随机多臂博弈中提出了一个多阈值UCB算法MultiTUCB，证明了该算法的样本复杂度理论，并通过实验表明其在合成和真实数据集上均表现出优越性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22660", "html_url": "https://arxiv.org/abs/2505.22660", "title": "仅提升信心即可提高推理能力", "title_en": "Maximizing Confidence Alone Improves Reasoning", "authors": "Mihir Prabhudesai,Lili Chen,Alex Ippoliti,Katerina Fragkiadaki,Hao Liu,Deepak Pathak", "background": "强化学习（RL）在多个领域推动了机器学习模型的显著进步，最近，RL使前沿语言模型能够解决数学、科学和编程难题。然而，任何一个RL算法的核心是奖励函数，奖励工程在任何领域都是一个难题。", "innovation": "本文提出了一种名为RENT的全无人工监督的强化学习方法，无需外部奖励或正确答案，而是使用模型生成答案的熵作为内在奖励。通过强化导致模型高度自信的答案链，模型增强了其推理能力。作者在各种大小的Qwen、Mistral和Llama系列模型上，在常见的推理基准测试中展示了这种改进。", "conclusion": "本文的无监督学习方法适用于广泛领域，其中外部监督不可用，展示了提升模型信心可以提高其推理能力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04320", "html_url": "https://arxiv.org/abs/2504.04320", "title": "因果推理并非特别之处：为什么它只是另一个预测问题", "title_en": "Causal Inference Isn't Special: Why It's Just Another Prediction Problem", "authors": "Carlos Fernández-Loría", "background": "传统上，因果推理被认为是与预测建模本质上不同的，具有独立的术语、目标和智力挑战。然而，因果推理本质上是数据分布变化下的有结构的预测实例。两者都从源域的标记数据开始，试图推广到目标域，在目标域中观测不到结果。关键区别在于因果推理中的标签（潜在结果）基于治疗分配有选择性地观测，这引入了必须通过假设来解决的偏差。", "innovation": "这一视角将因果估计重新定义为一个熟悉的泛化问题，并突显了来自预测建模的技术（如加权和域适应）如何直接应用于因果任务。它还阐明了因果假设并非特别强大，而是更加明确。通过将因果推理视为预测的视角，可以揭示其逻辑，将其与人们熟悉的工具联系起来，从而使从业者和教育者更容易理解它。", "conclusion": "因果推理不是特别的领域，而是一个带有分布变化的预测问题。通过预测的视角，明晰了因果推断中的逻辑，并且将其与熟悉的工具和技术联系起来，使得它对实践者和教育者更加易于理解。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10432", "html_url": "https://arxiv.org/abs/2503.10432", "title": "BeamLLM：利用大语言模型的毫米波波束预测视觉辅助方法", "title_en": "BeamLLM: Vision-Empowered mmWave Beam Prediction with Large Language Models", "authors": "Can Zheng,Jiguang He,Guofa Cai,Zitong Yu,Chung G. Kang", "background": "毫米波通信系统在训练开销和延迟方面面临挑战，传统的深度学习模型在此场景下表现不佳。因此，需要提出一种新的预测框架来克服这些问题。鉴于此，本研究结合计算机视觉与大语言模型的跨模态推理能力，通过重新编程技术从RGB图像中提取用户设备位置特征，并将视觉-时间特征与大语言模型的语义空间对齐，以解决毫米波通信中的波束预测问题。该方法在实际的车辆到基础设施(V2I)场景中得到了评估。", "innovation": "提出了一种利用大语言模型（LLMs）的视觉辅助毫米波波束预测框架（BeamLLM）。该框架通过结合计算机视觉和大语言模型的跨模态推理能力，从RGB图像中提取用户设备的位置特征，并使用重新编程技术将视觉-时间特征与大语言模型的语义空间对齐。评估结果显示，该方法在标准预测任务中的Top-1准确率为61.01%，Top-3准确率为97.39%，显著优于传统的深度学习模型。在少量样本预测情况下，从第1个时隙到第10个时隙，性能下降被限制在12.56%（Top-1）和5.55%（Top-3），显示出更强的预测能力。", "conclusion": "提出的BeamLLM框架在解决毫米波通信系统中的波束预测问题方面表现出色，不仅在标准预测任务中超过了传统深度学习模型，还能在少量样本预测场景中保持很高的准确率。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12380", "html_url": "https://arxiv.org/abs/2505.12380", "title": "Graph-Reward-SQL：基于图匹配和分步骤奖励的无需执行的文本到SQL强化学习", "title_en": "Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward", "authors": "Han Weng,Puzhen Wu,Cui Longjie,Yi Zhan,Boyi Liu,Yuanfeng Song,Dun Zeng,Yingxiang Yang,Qianru Zhang,Dong Huang,Xiaoming Yin,Yang Sun,Xing Chen", "background": "强化学习（RL）在提升大型语言模型（LLMs）在文本到SQL任务上的性能方面已经得到了广泛应用。然而，现有的方法常常依赖于基于执行或LLM的Bradley-Terry奖励模型。这两种方法都存在问题：前者因为反复的数据库调用导致高执行延迟，后者对GPU内存消耗大，这些都会显著降低RL管道的效率和可扩展性。", "innovation": "我们提出了一种名为Graph-Reward-SQL的新颖文本到SQL强化学习微调框架，使用GMNScore结果奖励模型。通过利用SQL图表示来提供准确的奖励信号，同时显著缩短了推理时间和GPU内存使用。此外，我们进一步引入了StepRTM分步骤奖励模型，对公共表表达式（CTE）子查询提供中间监督，以促进SQL的功能正确性和结构清晰度。", "conclusion": "在标准基准测试中，包括Spider和BIRD，我们的方法一致地优于现有的奖励模型，展示了Graph-Reward-SQL的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24403", "html_url": "https://arxiv.org/abs/2505.24403", "title": "关于无序集合聚合函数和集合理论神经网络的Lipschitz连续性", "title_en": "On the Lipschitz Continuity of Set Aggregation Functions and Neural Networks for Sets", "authors": "Giannis Nikolentzos,Konstantinos Skianis", "background": "神经网络的Lipschitz常数与网络的鲁棒性和泛化能力密切相关。因此，估算模型的Lipschitz常数在许多场景中都很有用。以往研究主要集中在多层感知器（MLP）和卷积神经网络（CNN）的Lipschitz常数估计上。本文关注可处理集合或多重集合（即包含向量的集合）的数据，并研究适用于此类数据的神经网络。这种模型通常通过某种不变排列聚合函数（如求和、平均或最大值操作）将输入多重集合转换为一个向量。本文研究了这些聚合函数在三种无序多重集距离函数下的Lipschitz连续性，并计算了它们的Lipschitz常量。", "innovation": "本文在无序多重集上研究了聚合函数的Lipschitz连续性，并针对具有处理向量多重集能力的神经网络推导了Lipschitz常数的上界。本文还研究了这类网络对扰动的稳定性以及在分布迁移下的泛化能力。", "conclusion": "通过理论分析和实验验证相结合的方法，本文探讨了无序多重集聚合函数和神经网络的Lipschitz连续性。实验结果支持了理论分析，并证明了所提出方法的有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08837", "html_url": "https://arxiv.org/abs/2506.08837", "title": "针对LLM代理的提示注入安全设计模式", "title_en": "Design Patterns for Securing LLM Agents against Prompt Injections", "authors": "Luca Beurer-Kellner,Beat Buesser,Ana-Maria Creţu,Edoardo Debenedetti,Daniel Dobos,Daniel Fabian,Marc Fischer,David Froelicher,Kathrin Grosse,Daniel Naeff,Ezinwanne Ozoani,Andrew Paverd,Florian Tramèr,Václav Volhejn", "background": "随着由大型语言模型（LLMs）驱动的AI代理变得越来越多样化，能够解决广泛的任务，确保这些代理的安全性已成为一个重要挑战。其中最紧迫的威胁之一是提示注入攻击，这种攻击利用了代理对自然语言输入的抵御能力——当这些代理被授予工具访问权限或处理敏感信息时，这种攻击尤其危险。因此，必须采取措施来防止这些问题的发生，这促使了该项工作的开展。", "innovation": "本文提出了一套针对提示注入具有可证明抗性的AI代理的规范设计模式。通过对这些模式进行全面分析，讨论其在实用性和安全性方面的权衡，并通过一系列案例研究展示其实用性，从而提供了一种解决这些问题的有效方法。", "conclusion": "本文提出了防止LLM代理受到提示注入攻击的设计模式，并系统地分析了这些模式，讨论了它们的实用性与安全性权衡，并通过案例研究展示了其实用性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17155", "html_url": "https://arxiv.org/abs/2506.17155", "title": "Sparse-Reg: 使用稀疏性提高离线强化学习的样本复杂性", "title_en": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity", "authors": "Samin Yeasar Arnob,Scott Fujimoto,Doina Precup", "background": "许多常见的离线强化学习基准使用包含超过一百万数据点的训练数据集，但在实际应用中，许多离线强化学习系统依赖于更小的数据集。我们发现，离线RL算法在小数据集上容易过拟合，导致性能不佳。因此，需要一种方法来应对这一挑战，以提高在受限数据设置下的学习效果并在连续控制中超越现有最先进的基线方法。", "innovation": "论文提出了一种名为'Sparse-Reg'的正则化技术，该技术基于稀疏性原理，旨在减轻离线强化学习中的过拟合问题，从而使模型能够在有限数据集上进行有效学习，并且在连续控制任务中优于最先进的基线方法。", "conclusion": "通过使用Sparse-Reg技术，离线RL算法能够在小数据集上实现更好的泛化能力和性能，特别是在连续控制任务中，这种方法显著优于现有的最先进的基线算法。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21360", "html_url": "https://arxiv.org/abs/2505.21360", "title": "CRISP-NAM：基于神经加性模型的竞争风险可解释生存预测", "title_en": "CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models", "authors": "Dhanesh Ramachandram,Ananya Raval", "background": "在医疗健康领域，患者可能会经历多种不同的事件类型，因此竞争风险（competing risks）在生存模型中是至关重要的考量因素。现有的生存分析方法通常难以处理竞争风险，并且在解释模型预测时存在着一定的局限性。因此，如何设计出既能处理竞争风险问题又能保持模型可解释性的方法成为研究的重点。", "innovation": "本文提出了一种基于神经加性模型的竞争风险可解释生存预测方法（CRISP-NAM）。该方法通过扩展神经加性架构来建模特定事件的风险，在保持特征层级可解释性的前提下，能够更准确地处理竞争风险问题。每个特征通过独立的神经网络对风险估计做出贡献，从而可视化协变量和每个竞争风险之间的复杂非线性关系。与现有的方法相比，该模型在多个数据集上的性能具有竞争力。", "conclusion": "CRISP-NAM在多个数据集上的实证研究表明，它在处理竞争风险生存分析问题上具有较好的性能，并且能够保持特征级别的可解释性。这种方法有助于提高医疗健康领域中复杂生存数据分析的透明度。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.19353", "html_url": "https://arxiv.org/abs/2407.19353", "title": "弹簧阻块理论：深度神经网络中的特征学习", "title_en": "Spring-block theory of feature learning in deep neural networks", "authors": "Cheng Shi,Liming Pan,Ivan Dokmanić", "background": "现有的理论无法从微观神经元动态出发解释特征学习深层神经网络中数据如何逐步被压缩到一个常规的低维几何结构，以及这种现象是如何通过非线性、噪声、学习率等共同作用产生的机制.", "innovation": "提出了一种噪音-非线性相图，标识出浅层或深层网络学习更为有效的阶段，并提出了一种宏观机械理论来重现相图，并将特征学习跨层的过程与泛化能力关联起来.", "conclusion": "该研究通过新的理论框架，揭示了深层次神经网络中特征学习背后的机制，并为理解和提高神经网络的泛化能力提供了新的视角."}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.08861", "html_url": "https://arxiv.org/abs/2401.08861", "title": "基于VAE和对比学习的O-RAN切片：半监督的生成AI方法", "title_en": "Generative AI for O-RAN Slicing: A Semi-Supervised Approach with VAE and Contrastive Learning", "authors": "Salar Nouri,Mojdeh Karbalaee Motalleb,Vahid Shah-Mansouri,Seyed Pooya Shariatpanahi", "background": "本文介绍了用于优化O-RAN资源分配和网络切片的半监督学习架构，该架构由生成AI（GAI）驱动。该方法通过最大化用户设备（UE）吞吐量和优化物理资源块（PRBs）分配来提升eMBB和URLLC服务的质量。GAI框架使用智能功率控制和PRB分配的专用xApp。这种方法综合利用了VAE的生成能力和对比学习，以实现端到端可训练系统的鲁棒性。该方法是一种结合监督回归优化资源分配决策和无监督对比学习目标的半监督训练方法，能够提高资源管理和模型泛化能力，适应动态移动网络的变化。", "innovation": "该研究通过提出一种基于VAE和对比学习的半监督学习方法，将生成能力和对比学习相结合，提高了端到端训练系统的鲁棒性。研究中采用的半监督训练方法同时优化了资源分配决策的监督回归目标和无监督对比学习目标，这种方法有效地提升了资源管理和模型泛化的精度。", "conclusion": "评估结果显示，该集成GAI方法在各种场景下表现出更高的效率和效果。本文提供了一种基于GAI的解决方案，能够有效应对下一代O-RAN系统中关键的网络切片和资源管理挑战。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.16661", "html_url": "https://arxiv.org/abs/2405.16661", "title": "RLSF：通过符号反馈微调LLMs", "title_en": "RLSF: Fine-tuning LLMs via Symbolic Feedback", "authors": "Piyush Jha,Prithwish Jana,Pranavkrishna Suresh,Arnav Arora,Vijay Ganesh", "background": "大型语言模型（LLMs）虽然改变了AI领域，但在涉及特定领域推理和逻辑对齐的任务上表现不佳。传统微调方法未能利用符号推理工具（例如证明器）提供的大量符号领域知识，并且受限于稀疏奖励和不可靠的奖励模型。在此背景下，本文提出了通过符号反馈的强化学习（RLSF），一种新型微调范式，利用符号推理工具生成的多项式大小证书（如证明）来识别和纠正模型输出的错误，提供词级指导，无需依赖可微推理系统。这种方法在符号推理和LLM微调之间架起桥梁，可以精细地与特定领域的约束对齐，并缓解传统奖励信号的关键局限性。", "innovation": "提出了通过符号反馈的强化学习（RLSF），一种全新的微调范式，利用符号推理工具生成的多项式大小证书来改进模型输出，提供词级指导，无需依赖可微推理系统，弥补传统微调方法的不足。RLSF通过这种方式缩短了符号推理和LLM微调之间的差距，使得较小的LLM在某些应用中表现出色，远远超过了更大型的封闭源模型。", "conclusion": "通过广泛的评估，我们展示了基于RLSF微调的LLMs在五个具有特定逻辑或领域约束的应用中优于传统方法，包括自然语言伪代码到编程语言的程序合成、三个化学任务，以及24点游戏的解决问题。一个重要的发现是，通过RLSF微调的LLMs可以显著超越比它们大几个数量级的封闭源模型。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.09493", "html_url": "https://arxiv.org/abs/2405.09493", "title": "C-Learner: 受约束学习在因果推断中的应用", "title_en": "C-Learner: Constrained Learning for Causal Inference", "authors": "Tiffany Tianhui Cai,Yuri Fonseca,Kaiwen Hou,Hongseok Namkoong", "background": "了解普及的因果推断修正估计方法，如增强逆概率权重和目标最大似然估计，虽具备统计效率和双重稳健性等优点，但在治疗组和对照组重叠有限时容易产生不稳定估计，这需要额外假设或非标准调整以确保稳健性。而简单的插件估计方法虽然稳定，但缺乏上述良好属性。因此，现有方法存在两难：稳定性与优异渐近性质之间的权衡。", "innovation": "本文提出了一种新颖的受约束学习方法，确保插件估计不仅稳定而且具有期望的渐近性质。该框架通过在插件估计中引入约束条件，使第一阶误差为零，能够利用灵活的模型类别（如神经网络和树型集成），从而同时解决稳定性和渐近效率问题。", "conclusion": "在多个实验场景中，特别是在处理语言基协变量时，作者的基于受约束学习的估计方法在治疗组和对照组重叠有限的复杂场景下，优于基本的一步估计和目标估计方法。在其他情况下，性能相近。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2001.04515", "html_url": "https://arxiv.org/abs/2001.04515", "title": "无限前景设置中强化学习价值函数的统计推断", "title_en": "Statistical Inference of the Value Function for Reinforcement Learning in Infinite Horizon Settings", "authors": "C. Shi,S. Zhang,W. Lu,R. Song", "background": "强化学习是一种通用技术，允许智能体在顺序决策问题中学习最优策略并与其环境交互。一个策略的好坏通过从某个初始状态开始的价值函数来衡量。本文关注在无限前景设置中，当决策点的数量发散到无限时，如何为策略的价值构造置信区间。传统方法通常假设最优策略是唯一的，而本文探讨了即使最优策略不唯一的情况下，如何为策略的价值构造置信区间。", "innovation": "本文提出了一种基于级数/筛法模型行动-价值状态函数（Q-函数）的方法来推导策略价值的置信区间。并且为了处理目标策略依赖于观察数据的情况，本文提出了SequentiAl Value Evaluation (SAVE)方法，该方法可以递归更新估计策略及其价值估计器。证明了只要轨迹数量或决策点的数量发散到无限，所提出的置信区间都能达到名义覆盖，即使最优策略不唯一。同时，通过模拟研究支持了理论发现，并将所提出的算法应用于移动健康研究的数据集，发现强化学习算法有助于改善患者健康状况。这些创新方法提供了在无限前景设置中分析策略价值的新视角", "conclusion": "本文通过理论研究和实证分析，为无限前景设置中的策略价值提供了一种有效的统计推断方法。通过SAVE方法更新估计策略及其价值估计器，确保了即使在最优策略不唯一的情况下，所提出的置信区间也能达到名义覆盖。应用实例展示了强化学习在实际健康数据中的有效性。相关Python实现可公开获得。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.13868", "html_url": "https://arxiv.org/abs/2411.13868", "title": "在人类编辑下的大型语言模型水印鲁棒检测", "title_en": "Robust Detection of Watermarks for Large Language Models Under Human Edits", "authors": "Xiang Li,Feng Ruan,Huiyuan Wang,Qi Long,Weijie J. Su", "background": "水印提供了一种有效的方法来区分由大型语言模型（LLMs）生成的文本和人类撰写的文本，但在包含人类编辑的LLM生成文本中，水印信号被稀释，使得现有方法的检测性能显著下降。本文通过利用混合模型检测人类编辑，介绍了一种新的基于截尾拟合检验的检测方法Tr-GoF来检测带有编辑的人类编辑下的水印文本。", "innovation": "Tr-GoF测试在大规模文本修改和水印信号接近消失的条件下实现了Gumbel-max水印的鲁棒检测最优性。此外，Tr-GoF测试能够在不需要精确的人类编辑程度或语言模型的概率规定的情况下自适应地实现最优性，不像最优但难以实现的Neyman-Pearson似然比检验那样。更为重要的是，Tr-GoF测试在一定范围的适度文本修改下实现了最高的检测效率。现有的基于求和检测规则的方法由于其统计上的加性性质对由编辑引起的噪声不够 resilient，无法在两个范畴内实现最优鲁棒性。", "conclusion": "我们的实验结果表明，Tr-GoF测试在合成数据和OPT、LLaMA家族的开源LLM中展现了竞争力甚至优越的性能。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.09550", "html_url": "https://arxiv.org/abs/2407.09550", "title": "CAPM: 通过双网络实现快速且稳健的 maxpool 基础 CNN 验证", "title_en": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network", "authors": "Jia-Hau Bai,Chi-Ting Liu,Yu Wang,Fu-Chieh Chang,Pei-Yuan Wu", "background": "该研究旨在提高在有界范数对抗扰动下，通用 maxpool 基 CNN 的验证界。当前的验证方法（如 DeepZ、DeepPoly 和 PRIMA）虽然有效，但计算成本较高。研究者通过将 maxpool 函数分解为一系列 ReLU 函数，改进了凸松弛技术的应用，使验证界能够通过双网络高效计算。这种方法在大规模 CNN 上也显示出较好的适用性，而以前的研究表明，大规模 CNN 的验证通常计算成本极高。实验结果表明，这种技术不仅能够达到最新精度（对于 maxpool 基 CNN），而且计算成本远低于当前方法，且在某些情况下，计算速度和验证界显著优于 PRIMA、DeepPoly、DeepZ。此外，还提供了该算法的时间复杂度为 $O(W^2NK)$。", "innovation": "该研究通过将 maxpool 函数分解为一系列 ReLU 函数，扩展了凸松弛技术的应用，从而能够通过双网络高效地计算验证界。这种方法显著提高了验证精度，同时大大降低了计算成本，特别在处理大型 CNN 时，计算速度显著提高（最高达 40 倍），验证界也明显优于现有方法。研究者还提供了算法的时间复杂度为 $O(W^2NK)$，其中 $W$ 是神经网络的最大宽度，$N$ 是神经元的数量，$K$ 是 maxpool 层的核大小。", "conclusion": "CAPM 技术能够以较低的计算成本实现 maxpool 基 CNN 的高效验证，尤其在处理大规模 CNN 时具有显著优势，不仅能提高验证精度，还能在某些情况下大幅提升计算速度。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.02660", "html_url": "https://arxiv.org/abs/2410.02660", "title": "如何训练长上下文语言模型（有效地）", "title_en": "How to Train Long-Context Language Models (Effectively)", "authors": "Tianyu Gao,Alexander Wettig,Howard Yen,Danqi Chen", "background": "本文研究了对语言模型（LM）进行持续训练和监督微调（SFT），以有效利用长上下文信息。传统的评估方法主要依靠困惑度或简单的‘针扎麦堆’测试，而本文提出了一种可靠的评估协议来指导模型开发，强调使用广泛的长上下文下游任务进行评估，以更好地揭示长上下文能力。研究基于此提出了多项实验来决定持续预训练的数据混合、指令微调数据集及其他设计选择诸如位置外推等。通过这些实验发现了若干关键点，包括长数据源和高质量短数据结合的重要性，以及长序列训练对于提升长上下文性能的有效性等。基于这些发现，本文训练了一个名为ProLong-8B的模型，并展示了其在长上下文任务中的优秀表现，其性能达到了同类模型中的领先水平，验证了研究的有效性。", "innovation": "本文的创新在于提出了一种可靠的评估长上下文能力的新方法；发现了长上下文任务中长数据与高质量短数据的结合的重要性；证明了超过评估长度的长序列训练能显著提升模型的长上下文性能；在仅使用短指令数据集的情况下，仍能获得高性能；并且通过大量实验确定了训练和微调的最佳策略。最后提出的ProLong-8B模型在较长的上下文窗口处理能力方面表现出色。", "conclusion": "本文提出的ProLong-8B模型不仅在长上下文任务上表现出优异的性能，还具有处理非常长上下文的能力，验证了其研究的有效性和创新性。通过改进模型训练和微调策略，有效利用长上下文信息，使得语言模型在处理复杂任务时更加高效和准确。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.15969", "html_url": "https://arxiv.org/abs/2408.15969", "title": "多块凸优化问题的普锐姆-对偶梯度流动力学的稳定性", "title_en": "Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems", "authors": "Ibrahim K. Ozaslan,Panagiotis Patrinos,Mihailo R. Jovanović", "background": "本文研究了具有多个（可能不光滑）目标函数项的复合凸优化问题在广义一致性约束下的普锐姆-对偶梯度流动力学稳定性特性。提出的动力学基于增广拉格朗日算法，并提供了一种能在大规模多块场景中替代ADMM的有效方法，ADMM在这类情况下从分析和实现方面都面临巨大挑战。与定制化的单独收敛保证算法不同，本文开发了一种系统的方法来解决广泛类别的复杂复合优化问题。利用多种结构特性，本文建立了提出的动力学的全局（指数）收敛保证。我们的假设比证明普锐姆-对偶动力学的指数稳定性以及离散时间方法的标准两块和多块ADMM和EXTRA算法的线性收敛所需的假设要弱得多。最后，本文展示了我们的结构假设对指数稳定性的必要性，并通过计算实验展示了为并行和分布式计算应用提出的方法的便利性。", "innovation": "基于增广拉格朗日算法，提出了一种普锐姆-对偶梯度流动力学，其优势在于可以在大规模多块场景中替代ADMM，且无需单独的收敛保证。通过利用多种结构特性，建立了提出的动力学的全局（指数）收敛保证，其假设比现有方法更为宽松。最后展示了某些假设对指数稳定的必要性，并通过实验验证了方法的便利性。", "conclusion": "本文提出了一种系统的解决广泛类别的复杂复合优化问题的方法，通过建立提出的动力学的全局收敛保证，证明了此类方法的实用性，并通过计算实验展示了其在并行和分布式计算应用中的便利性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.10814", "html_url": "https://arxiv.org/abs/2501.10814", "title": "无需滑窗：基于可微Top-k补丁采样的高效3D医学图像分割", "title_en": "No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling", "authors": "Young Seok Jeon,Hongfei Yang,Huazhu Fu,Mengling Feng", "background": "在CT/MRI分割中，3D模型优于2D模型，因为它们可以有效捕捉切片间的关联性。然而，增加的深度维度显著增加了内存消耗。基于补丁的训练虽能缓解内存限制，但使用滑窗（SW）方法会在推理速度上造成显著的减慢。", "innovation": "提出了一种新颖的端到端可训练框架No-More-Sliding-Window (NMSW)，该框架通过消除滑窗需求来提高通用3D分割骨干网络的推理效率。NMSW使用可微的Top-k模块来选择性地采样最相关的补丁，从而减少冗余计算。此外，当补丁级预测不足时，框架会智能地利用粗糙的全局预测来细化结果。NMSW在三个任务上的三个分割骨干网络评估中，与滑窗推理相比，实现了具有竞争力的准确性和91%的计算复杂性降低。", "conclusion": "NMSW在H100 GPU上实现了9.1倍的推理速度提升（从99.0秒到8.3秒），在Xeon Gold CPU上实现了11.1倍的推理速度提升（从2110秒到189秒）。NMSW是模型无关的，可以与任何现有的高效分割骨干网络无缝集成，以进一步提高效率。代码可在指定网址访问。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07528", "html_url": "https://arxiv.org/abs/2502.07528", "title": "专业足球运动员未来质量和价值的发展预测", "title_en": "Forecasting the future development in quality and value of professional football players", "authors": "Koen W. van Arem,Floris Goes-Smit,Jakob Söhl", "background": "专业足球转会因为高额转会费和高风险而被视为一种有风险的投资。现有数据驱动模型专注于描述球员的历史表现，但无法预测未来表现。近期的发展表明需要使用可解释模型并结合预测结果的不确定性量化。本文旨在评估基于预测准确性和不确定性方法的可解释机器学习模型，以预测专业足球运动员未来质量和转会价值的发展。模型通过预测球员一年后的质量和价值进行训练，这基于两个数据集来完成，其中包含了描述球员质量和价值的驱动指标。研究表明，随机森林模型最适合，因为它提供了准确的预测和一种因随机森林模型袋装（bagging）程序自然产生的不确定性量化方法。此外，研究发现球员表现的发展包含非线性和变量间的交互模式，时间序列信息也能提供关于球员表现指标建模的有用信息。", "innovation": "本文创新地使用了可解释的机器学习模型，并结合了预测准确性和不确定性量化方法，来预测专业足球运动员未来质量和转会价值的发展。这为足球俱乐部提供了更准确的数据驱动的转会决策支持。", "conclusion": "研究表明随机森林模型是最佳选择，它能够准确预测并自然地提供不确定性量化方法。同时发现，球员表现的发展包含非线性和变量间的交互，时间序列信息对建模有重要作用。这些模型能够帮助足球俱乐部做出更加明智的数据驱动的转会决策。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.15548", "html_url": "https://arxiv.org/abs/2409.15548", "title": "超越Conformal Predictors：适应性Conformal推理与置信预测", "title_en": "Beyond Conformal Predictors: Adaptive Conformal Inference with Confidence Predictors", "authors": "Johan Hallberg Szabadváry,Tuwe Löfström", "background": "适应性Conformal推理（ACI）能够在非互换性数据下提供有限样本的覆盖率保证，增加预测的可靠性。现有研究表明，ACI的这些良好特性并不需要使用Conformal Predictors（CP）。这项研究探讨了置信预测器（ Confidence Predictors，CPs）的保证是否仍然保持不变，并且这些保证是否可以在生产出嵌套预测集的更广泛类中保持不变。此外，该研究还对具有适应性Conformal推理的非Conformal置信预测器（NCCP）和CP在非互换性数据下的性能进行了实证研究，在在线设置中，NCCP在保持类似预测效率的同时提供了显著的计算优势；在批处理设置中，利用整个培训数据集的INDuctive NCCP（INCCP）可以超越INDuctive CP（ICP），尤其是在数据量有限的情况下，INCCP能够提高效率。尽管初步结果展示了NCCP在非互换性场景下使用ACI进行不确定性量化的一种理论合理且实践有效的方法，但仍然需要在多种数据集和预测器上进行进一步的实证研究以验证其效果。", "innovation": "这项研究展示了ACI的优良特性并不限于使用CP，引入了更广泛类别的置信预测器（ Confidence Predictors），这些预测器只需要生成嵌套预测集。在非互换性数据背景下，研究比较了非Conformal置信预测器（NCCP）与CP在在线和批处理设置中的性能表现。非Conformal置信预测器（NCCP）在保持高效预测的同时，还具备显著的计算优势，而在批处理场景下，使用整个训练集的INCCP相比于ICP显示出更高的效率，特别是在数据量不足的情况下。", "conclusion": "尽管NCCP作为一种理论上合理且实际上有效的替代CP的方法，能够用于非互换性数据场景下的不确定性量化，但需要进一步的实证研究来验证其在不同数据和预测器上的适用性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.03768", "html_url": "https://arxiv.org/abs/2412.03768", "title": "从宽平稳随机过程学习网络", "title_en": "Learning Networks from Wide-Sense Stationary Stochastic Processes", "authors": "Anirudh Rayas,Jiajun Cheng,Rajasekhar Anguluri,Deepjyoti Deka,Gautam Dasarathy", "background": "在神经科学、金融和工程等领域中，由潜在输入驱动的复杂网络系统非常普遍。这类系统的一个关键推断问题是，从节点输出（潜能）中学习边连接性。研究重点关注由稳态线性守恒定律驱动的系统：$X_t = {L^{\text{*}}}Y_{t}$，其中$X_t, Y_t \notin \textbf{R}^p$分别表示输入和潜能，$p \times p$拉普拉斯矩阵$L^{\text{*}}$的稀疏模式编码了边结构。假设$X_t$是一个已知频谱密度矩阵的宽平稳随机过程，可以从$Y_t$的时相关样本中通过$ℓ_1$-正则化的Whittle最大似然估计器（MLE）学习$L^{\text{*}}$的支持。正则化特别适用于在高维数据环境中学习大规模网络，当网络大小$p$远大于样本数量$n$时特别有用。", "innovation": "该研究提出了一种通过宽平稳随机过程学习网络的方法。具体来说，假设输入过程$X_t$为已知谱密度矩阵的宽平稳随机过程，通过$L_1$-正则化Whittle最大似然估计器从$Y_t$的时相关样本中学习$L^{\text{*}}$的支持。研究基于新的互不兼容条件和$(n, p, d)$的一些充分条件，表明MLE可以在很大程度上概率地恢复$L^{\text{*}}$的稀疏模式，其中$d$是$L^{\text{*}}$所对应图的最大度数。此外，提供了一致性恢复保证在元素最大化、Frobenius和算子范数下的$L^{\text{*}}$。这是通过理论展示和合成及基准数据集的模拟研究进行的验证。这种方法特别适用于工程系统（如电力和水资源网络），以及神经系统的实际数据集（例如人类大脑）", "conclusion": "该研究证明了Whittle最大似然估计器在学习大规网络中是严格凸的，并且具有唯一解。在满足新型互不兼容条件和某些$(n, p, d)$的充分条件下，Whittle估计量能以高概率恢复$L^{\text{*}}$的稀疏模式。此外，研究还提供了$L^{\text{*}}$在元素最大化、Frobenius和算子范数下的恢复保证。通过模拟研究验证了理论成果，并在合成和基准数据集（包括工程系统和真实神经系统数据）上进行了测试。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00119", "html_url": "https://arxiv.org/abs/2411.00119", "title": "软 Condorcet 优化在通用代理排名中的应用", "title_en": "Soft Condorcet Optimization for Ranking of General Agents", "authors": "Marc Lanctot,Kate Larson,Michael Kaisers,Quentin Berthet,Ian Gemp,Manfred Diaz,Roberto-Rafael Maura-Rivero,Yoram Bachrach,Anna Koop,Doina Precup", "background": "为推动AI模型和代理的进展，需要在标准化基准上比较它们的性能；对于通用代理，各个代理在多种不同任务上的表现必须进行聚合。因此，本文提出了一种基于社会选择框架的新颖排名方案，称为Soft Condorcet Optimization (SCO)，用于计算最优排名：它最少错误预测评价数据中的代理比较结果。评价数据被视为对真实排名的噪声样本，此优化即是对Condorcet原始投票系统标准的解决方案。我们展示了SCO在Condorcet赢家存在时给出的最大评分，而这一点不一定是传统Elo评分系统所做到的。在865个偏好配置文件中，当用作Kemeny-Young投票方法的近似时，SCO排名在归一化Kendall-tau距离上与最优排名的距离从0到0.043不等。而且，在模拟的嘈杂赛制中，当59%或更多的偏好数据缺失时，SCO接近真实的排名表现优于多个基线。此外，当处理经典七人游戏Diplomacy包含52,958名玩家的31,049场比赛时，SCO提供了最优排名的最好逼近，测量于保留的测试集上。", "innovation": "提出了一种名为Soft Condorcet Optimization (SCO)的新颖排名方案，该方案能够在多种不同任务上聚合通用代理的表现，优化结果是基于对评价数据（视为真实排名的噪声样本）的极大似然估计。提出了三种计算SCO评分的优化算法，并通过实验证明了其在不同条件下的有效性。SCO在处理嘈杂数据和提供接近最优排名方面表现出色，尤其是在多数偏好数据缺失的情况下，准确性高于经典Elo评分系统，接近Kemeny-Young投票方法。此外，SCO在Diplomacy游戏中的人工智能排名问题上表现最优，超过了其他基准方法。", "conclusion": "通过Soft Condorcet Optimization (SCO)方法，可以有效地聚合通用代理在不同任务上的表现，提供精确的排名。即便在偏好数据缺失较多的情况下，SCO也能够很好地逼近最优排名，且在实际应用中，如经典的Diplomacy多人游戏，SCO方法表现最好，不仅能够提供最接近实际排名的评价结果，而且比传统Elo等系统更有效。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14275", "html_url": "https://arxiv.org/abs/2501.14275", "title": "通过利用在线奥赛级数学问题进行LLMs训练和抗污染评估", "title_en": "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation", "authors": "Sadegh Mahdavi,Muchen Li,Kaiwen Liu,Christos Thrampoulidis,Leonid Sigal,Renjie Liao", "background": "大型语言模型（LLMs）在解决奥林匹克级别数学问题方面的进展引起了关注，但其训练和评估受到可用数据集规模和质量的限制，因为创建此类高级问题的数据集需要大量的人工专家努力，而当前的基准容易受到污染，导致评估不可靠。", "innovation": "本文提出了一种自动管道，利用Art of Problem Solving（AoPS）论坛丰富的资源，该论坛主要包含奥赛级别的问题和社区驱动的解决方案。使用开源LLM，开发了一种提取问题-答案对的方法，生成了包含超过600,000个高质量QA对的AoPS-Instruct数据集。实验显示，fine-tune LLMs在AoPS-Instruct上能提高其在各种基准上的推理能力。此外，构建了一个自动管道，引入LiveAoPSBench，这是一个带有时间戳的演化评估集，提供了抗污染基准以评估LLM性能。研究发现LLM性能随时间下降，表明它们在解决旧问题上的成功可能来自于预训练而非真正的推理能力。", "conclusion": "本文提供了一种可扩展的方法，用于创建和维护大规模高质量的高级数学推理数据集，为LLM在此领域的能力和局限性提供了有价值的见解。我们的基准和代码可通过以下链接获取：this https URL"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.19179", "html_url": "https://arxiv.org/abs/2501.19179", "title": "通过等变局部表示和电荷均化学习非局域分子相互作用", "title_en": "Learning Non-Local Molecular Interactions via Equivariant Local Representations and Charge Equilibration", "authors": "Paul Fuchs,Michał Sanocki,Julija Zavadlav", "background": "图神经网络（GNN）能够依靠化学局部性提供接近量子力学的准确性，但同时大幅降低了计算成本。消息传递GNN通过在相邻粒子之间传播局部信息来建模超出其直接邻域的相互作用，但仍保持局部性。然而，这种局部性限制了对许多真实系统中关键的远程效应（如电荷转移、静电相互作用和散射效应）的建模能力。因此，本研究提出了Charge Equilibration Layer for Long-range Interactions (CELLI)，以有效解决非局域相互作用的建模挑战。", "innovation": "CELLI作为一种新颖的架构，将古典电荷均化（Qeq）方法泛化为现代等变GNN潜力的模型无关构建块。CELLI扩展了GNN建模长程相互作用的能力，并通过明确定义的电荷提供了高度的可解释性。在基准体系中，CELLI实现了严格局部模型的最新成果，并能够处理多种数据集和大型结构，同时提供高效计算和稳健预测的特点。", "conclusion": "CELLI在多种基准测试系统上达到最新成果，能够扩展到不同的数据集和大型结构，同时保持高效计算和稳健预测，是一项重要的创新，显著提升了GNN建模长程相互作用的能力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20244", "html_url": "https://arxiv.org/abs/2502.20244", "title": "使用生成对抗神经网络模拟中微子相互作用", "title_en": "Generative adversarial neural networks for simulating neutrino interactions", "authors": "Jose L. Bonilla,Krzysztof M. Graczyk,Artur M. Ankowski,Rwik Dharmapal Banerjee,Beata E. Kowal,Hemant Prasad,Jan T. Sobczyk", "background": "当前中微子散射事件的模拟主要采用标准的蒙特卡洛生成器方法。该方法在模拟复杂的中微子-核子相互作用时存在不足。本文提出了一种基于生成对抗神经网络（GAN）的新方法，用于模拟2到10GeV能量范围内的中微子-碳核子碰撞，特别是简化的Muon动能变量（能量和散射角）的生成，旨在提供一种更有效的模拟手段来弥补传统方法的不足。", "innovation": "开发了GAN模型来模拟中微子-碳核子的交互。通过训练两个GAN模型分别模拟准弹性中微子-原子核散射和给定中微子能量的所有交互。这些模型适用于300MeV到10GeV的中微子能量范围，并使用两个统计指标评估了模型性能，证明了模型可以成功重现muon动力学分布。", "conclusion": "两种GAN模型均显示出了对muon动力学分布的准确模拟能力，为中微子-核相互作用的模拟提供了一种有效的替代方案，特别是在较低能量范围内的模拟具有明显优势。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.05609", "html_url": "https://arxiv.org/abs/2408.05609", "title": "大规模实施动态环保驾驶以减少大都市碳排放", "title_en": "Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale", "authors": "Vindula Jayawardana,Baptiste Freydt,Ao Qu,Cameron Hickert,Edgar Sanchez,Catherine Tang,Mark Taylor,Blaine Leonard,Cathy Wu", "background": "交通系统的规模和多样性使得其脱碳工作异常艰巨。本文探讨了一种新兴的机会，即通过编程半自动驾驶汽车实现智能速度控制，从而缓解交通拥堵，减少碳排放。然而，关于动态环保驾驶在这方面的实际影响，由于复杂的交通场景和汽车排放的复杂性，全面的影响分析一直难以实现。研究人员通过大规模情景建模和多任务深度强化学习，采用精心设计的网络分解策略，解决了这一挑战。研究团队模拟了美国三个主要城市6011个信号交叉口的百万种交通情景，发现优化排放的车辆轨迹可以广泛降低城市交互通信的碳排放，无需牺牲通行能力和安全性。通过合理假设，减排效果相当于以色列和尼日利亚国家的总排放量。研究表明，实施10%的动态环保驾驶可以实现总减排量的25%-50%，其中约70%的效益来自于20%的交叉口，这表明有针对性的实施路径具有紧迫性。然而，不同采用水平下高影响交叉口的组成存在显著差异，几乎没有重叠，这凸显了动态环保驾驶部署时需精心战略规划的必要性。这一研究还表明，在考虑电动汽车普及和混合动力汽车采用情况时，环保驾驶的影响仍然显著。更广泛地说，这项研究为大规模分析交通外部性（如时间、安全性和空气质量）及其解决策略的影响开辟了道路。", "innovation": "本文通过大规模情景建模和多任务深度强化学习解决了全面分析动态环保驾驶影响的挑战。研究团队使用了一个仔细设计的网络分解策略，通过模拟美国三个主要城市6011个信号交叉口的百万种交通情景，得出了优化排放的车辆轨迹可以普遍存在地减少城市交互通信的碳排放的结论，无需牺牲通行能力和安全性。这项研究还表明，不同采用水平下的高影响交叉口组成存在显著差异，几乎没有重叠，强调了部署环保驾驶策略时的精心战略规划的必要性。此外，该研究为考虑交通外部性的影响分析及解决策略提供了广泛的方法论框架。", "conclusion": "本文的研究表明，优化车辆轨迹的动态环保驾驶可以广泛降低城市交互通信的碳排放，而不影响通行能力和安全性。在合理假设下，这项技术实现的减排效果相当于以色列和尼日利亚的总排放量。10%的动态环保驾驶采用占比可实现显著减排，约70%的有效性来自约占总数20%的交叉口。研究表明，显著的减排效果来自于广泛采用动态环保驾驶策略，并应注意不同采用水平下潜在交叉口组成的变化，这要求精心的战略规划。此外，结合电动汽车普及和混合动力汽车采用情况时，这对交通碳排放的积极影响仍然显著。更广泛地说，这项研究为大规模的情景分析提供了方法，有助于更深入理解交通系统其它方面的外部影响及其解决策略。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04016", "html_url": "https://arxiv.org/abs/2504.04016", "title": "计算高效且最小最大最优的非缺失可忽略矩阵完成", "title_en": "Computational Efficient and Minimax Optimal Nonignorable Matrix Completion", "authors": "Yuanhong A,Guoyu Zhang,Yongcheng Zeng,Bo Zhang", "background": "矩阵完成问题在过去的几十年里吸引了大量关注，但很少有研究探讨非缺失可忽略问题，现有的研究都存在一定的局限性。本文旨在解决这个问题，提出了一种广义非缺失可忽略机制下核范数正则化行和列矩阵U-统计损失函数，该机制灵活且普遍适用，既包含了缺失可忽略和非缺失可忽略机制的假设。这种方法在计算效率上与现有缺失随机机制方法相当，但在更一般的非缺失可忽略情况下提供了接近最优的统计收敛速率保证。", "innovation": "本文提出了核范数正则化行和列矩阵U-统计损失函数，以处理广义非缺失可忽略机制，该方法在计算效率上与现有方法相当，但在更广泛的非缺失可忽略情况下提供了接近最优的统计收敛速率保证。此外，还提出了一种加速的逼近梯度算法来解决相关优化问题，并分析了算法和统计收敛之间的相互作用。", "conclusion": "通过模拟和实际数据分析进一步验证了所提出方法的实用性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16941", "html_url": "https://arxiv.org/abs/2504.16941", "title": "基于同调论的蛋白质结构数学建模：鞭毛马达结构的研究", "title_en": "Mathematical Modeling of Protein Structures: A Cohomology-Based Approach to the Flagellar Motor", "authors": "Zakaria Lamine,Abdelatif Hafid,Mohamed Rahouti", "background": "该研究提出了一种源自同调论的新数学模型，利用KEEL已证实的定理，确立同调论为自洽的，并由具有固定对偶图曲线的边界类生成。通过使用偏交换分级代数构建单纯复形，并运用结构定理将不同同调连接起来，实现对所得几何形式的精确解读。该模型应用于蛋白质结构分析和预测，特别是鞭毛马达结构，为生物大分子建模提供了新的几何与代数基础，展示了其在结构生物学中的潜在进步空间.", "innovation": "提出了基于同调论的新数学模型，利用固定的对偶图曲线生成边界类，通过偏交换分级代数构建单纯复形，将不同同调连接起来，以实现对蛋白质结构的精确分析和预测，特别是对于鞭毛马达结构提供了新颖的见解.", "conclusion": "该研究通过新的数学模型，结合同调论和生物结构分析，为理解蛋白质结构提供了新的几何与代数基础，展示了其在结构生物学中的潜力，为生物分子模型的进一步发展铺平了道路."}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.22923", "html_url": "https://arxiv.org/abs/2503.22923", "title": "用于广义Sinkhorn距离正则化的分布鲁棒优化的嵌套随机算法", "title_en": "Nested Stochastic Algorithm for Generalized Sinkhorn distance-Regularized Distributionally Robust Optimization", "authors": "Yufeng Yang,Yi Zhou,Zhaosong Lu", "background": "分布鲁棒优化(DRO)是一种强有力的训练方法，能够使模型在数据分布变化的情况下仍然保持鲁棒性。本文旨在解决正则化非凸的DRO问题，其中不确定性集由所谓的广义Sinkhorn距离建模，损失函数是非凸的，可能是无界的。这种距离允许建模具有不同概率支持和偏离函数的分布的不确定性。对于这类正则化DRO问题，我们推导出一个新的二重随机优化的对偶形式，其中对偶变量依赖于数据样本。为了解决双重问题，我们提供了理论证据以设计一种嵌套随机梯度下降(SGD)算法，该算法利用随机近似来估计嵌套的随机梯度。我们研究了嵌套SGD的收敛速度，并建立了与数据规模和参数维度无关的多项式迭代和样本复杂性，表明它有可能解决大规模的DRO问题。通过数值实验，我们展示了所提出算法的效率和鲁棒性。", "innovation": "论文提出了一种嵌套随机梯度下降（SGD）算法，该算法利用随机近似估计嵌套的随机梯度，解决了正则化非凸DRO问题，其中不确定性集由广义Sinkhorn距离建模。研究证明了该算法在大规模DRO问题上的高效性和鲁棒性，并确定了与数据规模和参数维度无关的多项式迭代和样本复杂性。", "conclusion": "通过嵌套SGD算法，本文提供的方法能够有效地解决具有广义Sinkhorn距离正则化因子的正则化非凸分布鲁棒优化问题，证明了该算法在复杂性和效率上的优势，并通过数值实验验证了其在大尺度上的适用性和有效性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20410", "html_url": "https://arxiv.org/abs/2503.20410", "title": "基于缺失数据的鲁棒自适应能源预测中学习数据驱动的不确定性集分区", "title_en": "Learning Data-Driven Uncertainty Set Partitions for Robust and Adaptive Energy Forecasting with Missing Data", "authors": "Akylas Stratigakos,Panagiotis Andrianesis", "background": "传统的短期预测模型通常假定在部署和使用过程中可用输入数据（特征）。然而，设备故障、干扰和网络攻击可能导致这些模型在实际操作中出现缺失数据，从而影响预测的准确性，导致不合理的操作决策。这种情况要求预测模型在现实操作中能够无缝处理缺失数据。本文研究了在考虑输入缺失数据的情况下，如何使用自适应鲁棒优化和对抗性机器学习来开发能够有效处理缺失数据的预测模型。该模型结合了线性自适应和基于数据驱动的不确定性集分区的新算法，证明其在短时间内特别有效（例如，当仅缺失最新测量值时与其他插补方法的效果相当），当有较长时期的缺失数据时则表现更为优越，它不需要识别历史缺失数据模式，能够在严格的实时操作和时间约束条件下适用。数值实验表明，该模型能在短期风力发电预测（15分钟到4小时领先时间）中与插补方法效果相当甚至更优", "innovation": "提出了一种结合线性和神经网络的自适应预测模型，该模型能够适应可用特征，并结合了一种新的算法来学习数据驱动的不确定性集分区。利用自适应鲁棒优化和对抗性机器学习技术开发了能在实际操作过程中无缝处理缺失数据的预测模型。实验证明，当缺失数据时间很短时（例如，仅最新测量值缺失），自适应模型与插补方法效果相当；而当缺失时间较长时，其性能显著优于插补法。此外，展示了线性自适应和数据驱动分区如何接近最优但实践不可行的全量不确定性重新训练方法的表现", "conclusion": "提出的自适应鲁棒模型在短期风电预测中，对于短时间内缺失数据（如仅最新测量值缺失）的性能与插补方法相当，而对于长时间缺失则显著优于插补。未来研究可以扩展到更多的能源类型和不同的缺失数据处理方法。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12753", "html_url": "https://arxiv.org/abs/2502.12753", "title": "绿色LIME：通过实验设计提高AI可解释性", "title_en": "Green LIME: Improving AI Explainability through Design of Experiments", "authors": "Alexandra Stadler,Werner G. Müller,Radoslav Harman", "background": "在人工智能中，许多模型和过程的复杂性超越了人类的理解，使得确定特定预测的原因变得困难。这种透明度的缺乏在像医疗保健这样关键的领域尤为成问题，因为在这些领域，对模型预测的信任至关重要。因此，提高机器学习和其他复杂模型的可解释性已成为研究的重点。尽管已有努力通过实验探索AI系统并用可解释的代理机制近似它们的行为，但这一过程往往消耗大量资源。实验设计的优化技术可以最大化从有限观察中获得的信息，从而提高这些可解释性技术的效率。为此，我们探讨了局部可解释、模型无关性的解释方法（LIME），这是一种广泛使用的由Ribeiro等人（2016）引入的方法。LIME通过生成接近感兴趣实例的新数据点并将其传递通过模型来提供解释。虽然有效，但由于预测成本高或需要大量样本，这一过程可能是计算密集型的。尽管LIME非常灵活，可以应用于各种模型和数据集，但其应用多为表格式数据、回归任务以及线性模型作为可解释的局部近似。简化复杂模型的功能评估数量，显著减少了LIME的计算负担，使这种方法更高效或‘绿色’。", "innovation": "本文利用了实验设计技术来优化LIME（局部可解释、模型无关性的解释方法），通过减少复杂模型的功能评估次数，大幅降低了LIME的计算负担，从而提高了可解释性的效率。这种方法被称作‘绿色LIME’，因为其计算效率更高，更加环保。", "conclusion": "通过应用实验设计的方法，我们提出了一种改进的LIME方法，即‘绿色LIME’，该方法在保持解释准确性的同时，显著减少了计算成本。这项工作展示了一种有效提高AI模型可解释性的方法，特别是在涉及大量数据的复杂模型中。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14949", "html_url": "https://arxiv.org/abs/2502.14949", "title": "KITAB-Bench：阿拉伯OCR及文档理解的多域全面基准", "title_en": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding", "authors": "Ahmed Heakl,Abdullah Sohail,Mukul Ranjan,Rania Hossam,Ghazi Shazan Ahmad,Mohamed El-Geish,Omar Maher,Zhiqiang Shen,Fahad Khan,Salman Khan", "background": "随着检索增强生成（RAG）在文档处理中的广泛应用，坚实的文本识别变得越来越关键，尤其是对知识提取而言。尽管英文字体识别有大容量数据集和成熟的基准平台，阿拉伯字体识别因其连笔书写、从右到左的视觉流以及复杂的字体和书法特征遇到了独特挑战。现有的评测系统存在不足，而KITAB-Bench填补了这一空白，提供了8,809个样本覆盖9大领域及36个子领域，包括手写文本、结构化表格和21种商业智能图表的细致覆盖面。研究表明，现代视觉-语言模型（如GPT-4o、Gemini和Qwen）在字符错误率（CER）方面比传统的OCR方法（如EasyOCR、PaddleOCR和Surya）高出平均60%。然而，性能在PDF到Markdown转换方面尤其不佳，最好的模型Gemini-2.0-Flash仅达成65%的准确率，这表明了阿拉伯文字识别中的诸多挑战，如复杂字体、数字识别错误、单词拉长和表格结构检测等难题的存在。", "innovation": "提出了KITAB-Bench，这是一个全面的阿拉伯OCR基准，涵盖8,809个样本，包括9大领域及36个子领域中的各种文档类型。KITAB-Bench填补了现有评估系统的不足，表明现代视觉-语言模型比传统OCR方法在字符错误率方面高出约60%，但特别强调了PDF到Markdown转换中的显著局限性，这是由于复杂数字字体、数字识别错误、单词拉长和表格结构检测等因素造成的挑战。", "conclusion": "这项工作建立了一个严格的评估框架，有望推动阿拉伯文档分析方法的进步，并缩小阿拉伯OCR技术与英语OCR技术之间的性能差距。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18536", "html_url": "https://arxiv.org/abs/2504.18536", "title": "适应人工智能的概率风险评估", "title_en": "Adapting Probabilistic Risk Assessment for AI", "authors": "Anna Katariina Wisakanto,Joe Rogero,Avyay M. Casheekar,Richard Mallah", "background": "现代通用人工智能系统带来了迫切的风险管理挑战，因为它们迅速变化的能力和潜在的灾难性危害超出了我们可靠评估其风险的能力。当前的评估方法经常依赖于选择性测试和未记录的风险优先级假设，很少认真尝试评估AI系统直接或间接对社会和生物圈构成风险的路径。因此，急需一种新的评价方法来解决这些问题。", "innovation": "本文提出了AI的概率风险评估（PRA）框架，这种框架借鉴了核能、航空航天等高可靠性行业中成熟的PRA技术，为先进的AI技术带来新的挑战。该框架在评估者识别潜在风险、估计概率和严重程度方面提供指导，并明确记录证据、基础假设和分析的细节。此外，该框架还引入了三个方法上的进步：（1）面向方面的危害分析，提供系统性的危害覆盖，指导基于第一原则的AI系统方面的分类；（2）风险路径建模，通过双向分析和前瞻性技术分析系统方面到社会影响的因果链；（3）不确定性管理，使用情景分解、参考尺度和明确的追踪协议来结构化具有新颖性或有限数据的可信预测。", "conclusion": "该框架通过将各种评估方法的证据整合到可量化、绝对风险的可比估计中，实现了生命周期决策的协调，被制作成工作簿工具提供给AI开发者、评估者和监管者。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.00599", "html_url": "https://arxiv.org/abs/2504.00599", "title": "基于辅助子空间方法的近场定位", "title_en": "Near Field Localization via AI-Aided Subspace Methods", "authors": "Arad Gast,Luc Le Magoarou,Nir Shlezinger", "background": "随着对高吞吐量和能效无线通信需求的增加，极高频带下的超大面积天线被广泛应用。在这些频段，多个用户会处于辐射近场中，位置准确化变得至关重要。传统的远场系统依赖于DOA估计，但在近场定位中，通过球面波前传播同时恢复DOA和距离信息变得必要。虽然子空间方法（如MUSIC及其扩展）可以实现高分辨率和解析性，但它们的性能受到非相干源、阵列校准和足够的快照数量等模型假设的影响。", "innovation": "本文提出了一种基于AI辅助的子空间方法来解决近场定位问题。具体来说，引入了NF-SubspaceNet，这是一种基于深度学习的改进2D MUSIC算法，通过学习替换协方差矩阵来进行更准确的定位。还提出了DCD-MUSIC，这是一种级联的AI辅助方法，将角度和距离估计分离，以降低计算复杂度。此外，还发展了一种新的模型阶次感知训练方法来准确估计源的数量，结合将近场子空间方法转化为AI模型进行学习，该方法能够应对相干源、校准误差和少量快照等实际挑战，从而提供更鲁棒的近场定位能力。", "conclusion": "广泛的仿真表明，所提出的方法在经典方法和现有的基于深度学习的定位技术中表现出色，即使在相干源、失准和少量快照的情况下也能提供鲁棒的近场定位能力。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01463", "html_url": "https://arxiv.org/abs/2505.01463", "title": "通过主题建模增强云安全", "title_en": "Enhancing Cloud Security through Topic Modelling", "authors": "Sabbir M. Saleh,Nazim Madhavji,John Steinbacher", "background": "随着安全威胁日益复杂和持久，保护云应用程序变得尤为重要。连续集成和连续部署（CI/CD）管道尤为脆弱，因此需要新的安全方法。研究通过主题建模技术，尤其是潜在狄利克雷分配（LDA）和概率潜在语义分析（PLSA），来分析与安全相关的文本数据，预测潜在威胁。该研究重点关注如何利用这些技术从日志、报告和部署跟踪中提取有意义的模式，并将这些模式划分为与安全相关的话题（例如，钓鱼、加密故障）以识别CI/CD连续阶段（构建、测试、部署）中的安全问题。", "innovation": "通过应用主题建模技术，特别是LDA和PLSA，来分析与安全相关的文本数据。利用Gensim框架在Python中对日志条目进行分类，并识别出与安全相关的话题。这种方法提供了一个语义层，支持早期漏洞识别，并能够理解运行时的行为模式。", "conclusion": "该研究证明了通过主题建模技术可以有效地识别和预测与云安全相关的潜在威胁。这种方法不仅有助于早期识别漏洞，还能为开发人员提供更深入的理解，以改进其应用程序的安全性。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14473", "html_url": "https://arxiv.org/abs/2506.14473", "title": "基础模型洞见与多模型方法在优秀的细粒度一候选子集选择中的应用", "title_en": "Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection", "authors": "Zhijing Wan,Zhixiang Wang,Zheng Wang,Xin Xu,Shin'ichi Satoh", "background": "一候选子集选择是一种有效地减少深度学习训练成本的工具，通过信息抽取器（IE）提取的信息来识别一份有信息量的数据子集。传统IE通常基于目标数据集进行预训练，从而具有数据集依赖性。基础模型（FMs）作为一种替代方案，可能缓解这一限制。然而，研究发现在细粒度数据集上FMs具有优势，而在粗粒度且噪声标签的数据集上，其优势减弱。基于以上发现，本文提出了一种针对细粒度图像数据集的方法RAM-APL。RAM-APL 采用了多个FMs来增强子集选择的性能，从而整合互补优势，取得了细粒度数据集上的领先性能。", "innovation": "本文提出了一种基于基础模型和多模型方法的细粒度图像数据集的子集选择方案RAM-APL。该方法能够均值化伪分类标签的准确性来增强子集选择。该方法在Oxford-IIIT Pet、Food-101和Caltech-UCSD Birds-200-2011三个细粒度数据集上取得了领先的效果。", "conclusion": "研究发现基于基础模型的子集选择方法在细粒度数据集上优于传统方法，但在粗粒度且噪声标签的数据集上这一优势不明显。据此，作者提出了一种集成多个基础模型以进行细粒度一候选子集选择的方法RAM-APL，该方法在多个细粒度数据集上实现了最佳性能。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08423", "html_url": "https://arxiv.org/abs/2506.08423", "title": "Mic-hackathon 2024: Hackathon on Machine Learning for Electron and Scanning Probe Microscopy", "title_en": "Mic-hackathon 2024: Hackathon on Machine Learning for Electron and Scanning Probe Microscopy", "authors": "Utkarsh Pratiush,Austin Houston,Kamyar Barakati,Aditya Raghavan,Dasol Yoon,Harikrishnan KP,Zhaslan Baraissov,Desheng Ma,Samuel S. Welborn,Mikolaj Jakowski,Shawn-Patrick Barhorst,Alexander J. Pattison,Panayotis Manganaris,Sita Sirisha Madugula,Sai Venkata Gayathri Ayyagari,Vishal Kennedy,Ralph Bulanadi,Michelle Wang,Kieran J. Pang,Ian Addison-Smith,Willy Menacho,Horacio V. Guzman,Alexander Kiefer,Nicholas Furth,Nikola L. Kolev,Mikhail Petrov,Viktoriia Liu,Sergey Ilyev,Srikar Rairao,Tommaso Rodani,Ivan Pinto-Huguet,Xuli Chen,Josep Cruañes,Marta Torrens,Jovan Pomar,Fanzhi Su,Pawan Vedanti,Zhiheng Lyu,Xingzhi Wang,Lehan Yao,Amir Taqieddin,Forrest Laskowski,Xiangyu Yin,Yu-Tsun Shao,Benjamin Fein-Ashley,Yi Jiang,Vineet Kumar,Himanshu Mishra,Yogesh Paul,Adib Bazgir,Rama chandra Praneeth Madugula,Yuwen Zhang,Pravan Omprakash,Jian Huang,Eric Montufar-Morales,Vivek Chawla,Harshit Sethi,Jie Huang,Lauri Kurki,Grace Guinan,Addison Salvador,Arman Ter-Petrosyan,Madeline Van Winkle,Steven R. Spurgeon,Ganesh Narasimha,Zijie Wu,Richard Liu,Yongtao Liu,Boris Slautin,Andrew R Lupini,Rama Vasudevan,Gerd Duscher,Sergei V. Kalinin", "background": "显微镜是研究材料在纳米和原子尺度结构与功能的重要手段。生成的数据结构较为完善，富含元数据和样品历史信息，但往往在细节和格式上缺乏一致性。主要资助机构推动采用数据管理计划(DMPs)，促进数据的保存和访问，但由于缺乏标准化的代码生态系统、基准和整合策略，从数据中提取洞察仍然困难。此外，虽然有来自主要显微镜制造商的新API支持实时、基于机器学习(ML)的分析，用于自动化决策和显微镜操作控制，但在机器学习与显微镜社区之间仍存在差距，限制了这些方法在物理、材料发现和优化中的影响。", "innovation": "本次黑客松活动促进了机器学习研究人员和显微镜专家之间的合作，促进了将机器学习应用于显微镜的新型解决方案的开发，同时为未来的劳动力准备在仪器、材料科学和应用机器学习等领域。活动产生了基准数据集和显微镜的数字孪生，以支持社区成长和标准化工作流程。所有相关的代码都可以在GitHub上找到：this https URL", "conclusion": "通过这次黑客松活动，促进了机器学习和显微镜领域之間的合作，在显微镜与机器学习技术的结合方面取得了显著进展，为未来的研究奠定了基础，并通过共享代码促进社区的发展。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20995", "html_url": "https://arxiv.org/abs/2506.20995", "title": "通过负音频指导逐步视频到音频合成", "title_en": "Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance", "authors": "Akio Hayakawa,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji", "background": "该研究提出了一个新颖的逐步视频生成音频的方法，能够逐帧生成对应视频中的特定声音事件的音频轨道。这种方法受到传统费舍尔流程的启发，旨在全面捕捉由给定视频引发的所有声音事件。每个生成步骤都被设计为一个引导的视频到音频合成任务，基于目标文本提示和先前生成的音频轨道进行条件化。这种方法通过引入一种利用预训练的视频到音频模型的训练框架进行引导生成，而无需专门配对的数据集，从而可以基于更易于获取的数据进行训练。实验结果表明，该方法能为单个输入视频生成多个语义上不同的音频轨道，合成的复合音频质量高于现有基线方法。", "innovation": "提出了一种新颖的逐步视频到音频生成方法，每个生成步骤被视为基于目标文本提示和先前生成的音频轨道的引导视频到音频合成任务。该研究通过引入一种利用预训练模型的训练框架，实现了基于更易获取数据的训练过程，无需专门配对的数据集。这种方法借鉴了概念否定的思想，用于引导生成多个语义上不同的音频轨道。", "conclusion": "实验结果表明，该方法能够为单个输入视频生成多个语义上不同的音频轨道，其合成音频的质量高于现有基线方法。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.21693", "html_url": "https://arxiv.org/abs/2506.21693", "title": "安全自主驾驶开发与运营中的DevSafeOps难题：一项系统文献综述", "title_en": "The DevSafeOps Dilemma: A Systematic Literature Review on Rapidity in Safe Autonomous Driving Development and Operation", "authors": "Ali Nouri,Beatriz Cabrero-Daniel,Fredrik Törner,Christian Berger", "background": "自主驾驶（AD）系统的开发具有复杂性，需要确保其安全可靠的运行，这带来了挑战。DevOps作为一种广泛采用的方法，似乎能够支持AI领域的持续技术进步以及对快速应对事故的需求，促使持续开发、部署和监控。因此，需要进行系统文献综述来总结和整理有关在自主驾驶开发中使用DevOps的研究成果，特别是围绕安全相关的人工智能功能的应用挑战和解决方案。", "innovation": "本文通过系统文献综述的方法，总结和分析了现有文献中关于在自主驾驶开发中使用DevOps的研究成果，尤其是针对安全相关的人工智能功能的应用挑战和解决方案进行了一次全面的概述。这为安全DevOps在自主驾驶开发中的应用提供了有价值的见解，也指出了一些亟待解决的开放性话题，以便实现安全的DevOps方法。", "conclusion": "最终发现，尽管DevOps在自主驾驶开发中显示出一定的潜力，但在确保安全方面仍有多个未解决的问题，需要更多的研究来加以解决，以实现安全的DevOps在自主驾驶开发中的有效应用。"}
{"llm_update_time": "20250630", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11869", "html_url": "https://arxiv.org/abs/2506.11869", "title": "概率图模型和图神经网络在看待网络数据方面有何不同？", "title_en": "How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?", "authors": "Michela Lapenna,Caterina De Bacco", "background": "图是表示复杂现实系统关系数据的强大数据结构，并且广泛用于描述网络系统。概率图模型（PGMs）和图神经网络（GNNs）都能利用图结构的数据，但它们的工作方式不同。研究重点在于它们在网络数据中捕捉信息方面的比较，通过解决链接预测任务进行测试，并结合合成和真实网络进行了三个主要实验，考察了PGMs和GNNs对输入特征的处理方法、噪声特征的鲁棒性以及图同质性的增加对其性能的影响。", "innovation": "该研究通过定义链接预测任务，并结合合成和真实网络进行了三个主要实验来比较不同特征情况下PGMs和GNNs的性能，发现GNNs在低维度或嘈杂输入特征时不如PGMs，而当图的同质性增加时，PGMs比GNNs更鲁棒。此外，研究还评估了两种框架在计算复杂性和可解释性方面的性能差异。", "conclusion": "PGMs在噪声特征和低维度输入特征情况下表现更好；GNNs在处理同质性和噪声图时更鲁棒；PGMs和GNNs在计算复杂性和可解释性上的差异也值得注意。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.21634", "html_url": "https://arxiv.org/abs/2506.21634", "title": "如何（不）撰写软件工程摘要", "title_en": "How (Not) To Write a Software Engineering Abstract", "authors": "Lutz Prechelt,Lloyd Montgomery,Julian Frattini,Franz Zieris", "background": "软件工程研究文章中的摘要是一个非常有价值的组成部分，但并非所有摘要都足够信息丰富。已有研究尚没有系统地描述高质量软件工程期刊中摘要的结构，也未识别摘要中常见的缺陷，并提出撰写有效摘要的指南。因此，有必要对高质量软件工程期刊中的摘要结构进行研究，观察并量化摘要中的不足之处，并提出有效的撰写指南。", "innovation": "本文采用定性开放式编码方法提炼出解释摘要相关属性的概念，确定摘要的典型结构，并通过对五个高质量期刊的362篇摘要的定量内容分析，客观描述摘要结构，并通过探索性数据分析发现摘要中的反复出现的问题。将典型的摘要结构与实际结构进行比较，推断出生成信息丰富摘要的指南。", "conclusion": "(1) 即便是在顶级期刊中，大多数摘要也远非理想；(2) 结构化的摘要通常比未结构化的摘要更好；(3) 需要一个不同的结构化格式来处理以制品为中心的研究；(4) 社区应该开始要求总结性结论，当前此类结论在摘要中经常缺失。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.21654", "html_url": "https://arxiv.org/abs/2506.21654", "title": "使用C++20模块将大型数学软件包转换的经验", "title_en": "Experience converting a large mathematical software package written in C++ to C++20 modules", "authors": "Wolfgang Bangerth", "background": "传统的数学软件通常是构建为互相依赖的“包”的形式。许多这些包用C++编写，因此接口通常以头文件的形式描述，供下游包和应用程序包含。尽管C++继承了C语言的这种方法，但它在接口导出方面的做法笨拙、不可靠且速度慢。因此，C++20引入了“模块”系统，在这个系统中，包显式导出声明和代码，编译器将这些信息以机器可读的形式存储，下游用户可以导入。这是一个与许多其他编程语言几十年来使用的系统一致的方法。本文探讨如何将大型C++数学软件包转换为这种系统，以这个大约80万行代码的有限元库为例，描述一种可以从同一个代码库提供基于头文件和模块接口的方法，讨论遇到的挑战，以及模块在多种技术和社会指标上的实践验证。结果表明，通过非重大但也不苛刻的努力，可以将包转换为模块的形式，这将减少代码库本身的编译时间；对于下游项目，编译时间并无明确趋势。最后，本文提出了关于未来几年或几十年内将整个数学软件生态系统转换为模块系统的长期战略的思考。", "innovation": "本文探讨了如何将大型C++数学软件包转换为C++20模块系统，并提出了一种方法，可以从同一个代码库提供基于头文件和模块接口。该文验证了这种方法的有效性，并讨论了转换过程中遇到的技术和人类挑战，证明即使采用非重大努力，这一转换也是可行的，可以改善编译时间。此外，文章还为未来将数学软件生态系统整体迁移到模块化系统提出了战略性的思考和建议。这一创新之处体现在将现有的C++包重新编译为C++20模块，减少了反复修改代码的复杂性和提高了编译效率上。", "conclusion": "通过适当的非重大努力，可以将大型C++数学软件包成功转换为C++20模块。尽管编译时间有所改善，但对下游项目的影响不显著。未来的一系列长期策略将有助于整个数学软件生态系统的模块化，减少维护成本并促进新功能的更快部署。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.22037", "html_url": "https://arxiv.org/abs/2506.22037", "title": "KARMA Approach 支持基于模型的系统工程中开发过程重构", "title_en": "KARMA Approach supporting Development Process Reconstruction in Model-based Systems Engineering", "authors": "Jiawei Li,Zan Liang,Guoxin Wang,Jinzhi Lu,Yan Yan,Shouxuan Wu,Hao Wang", "background": "在基于模型的系统工程中，复杂的系统开发过程涉及大量模型的构建与管理。现有的迭代设计过程中缺乏有效的方法来管理和适应开发要求的变化，例如开发周期要求和成本要求。这导致了系统开发过程模型的重建困难。鉴于此，本文提出了一种模型重构方法，以支持开发过程模型的构建。首先，利用基于GOPPRR-E元建模方法的KARMA语言统一形式化不同建模语言构建的过程模型。接着通过引入模型重构框架，该框架利用结构化开发要求的自然语言输入，借助自然语言处理技术分析文本，提取结构和优化约束信息，并通过结构重组和算法优化以适应新的开发要求，生成满足这些新要求的开发过程模型。最后，以飞机机载维修系统的开发为例，证实了该方法的有效性，该方法显著提高了设计效率。", "innovation": "提出了利用KARMA语言和GOPPRR-E元建模方法对不同建模语言构建的过程模型进行统一形式化的模型重构方法。通过采用结构化自然语言输入和自然语言处理技术，能够有效分析和提取开发要求的结构化和优化约束信息，从而实现开发过程模型的设计优化。这一方法能够显著提高开发过程的效率，增强开发过程模型的灵活性和适应性。", "conclusion": "本文提出的方法通过将不同建模语言下的过程模型统一形式化，结合自然语言处理技术提取开发要求中的结构和优化约束信息，实现了针对不同开发要求的自适应开发过程模型重建。通过实例验证，该方法能够有效提升开发过程的效率，对基于模型的系统工程具有重要意义。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.21703", "html_url": "https://arxiv.org/abs/2506.21703", "title": "在软件设计教育中使用生成式AI：经验报告", "title_en": "Using Generative AI in Software Design Education: An Experience Report", "authors": "Victoria Jackson,Susannah Liu,Andre van der Hoek", "background": "随着生成式AI工具的快速采用，软件工程教育者在如何将其最好地融入课堂上遇到了挑战。虽然有部分研究探讨了在学习编程时使用生成式AI的方法，但对于将其用于软件开发的其他领域却没有多少研究。本文介绍了在本科生软件设计课程中引入生成式AI的经验报告。学生被要求使用生成式AI（以ChatGPT的形式）来帮助完成团队作业。研究数据包括ChatGPT的会话日志和学生对使用ChatGPT完成任务的反思。随后对数据进行了定性分析。学生在设计过程中发现了ChatGPT为其带来的诸多帮助，并意识到了在将其整合到设计中前需要对其进行批判性评估的需求。同时，我们还发现了一些关键教训，以帮助教育者如何在软件设计课堂中有效地部署生成式AI。", "innovation": "本文提供了一个在本科生软件设计课程中引入生成式AI的经验报告，这是在软件开发的其他领域使用生成式AI的研究空白。该研究不仅提供了如何有效部署生成式AI的实际经验，还强调了在整合生成式AI时需要进行批判性评估的重要性。", "conclusion": "根据我们的经验，将生成式AI引入软件设计教育可以带来益处，它有助于学生设计和了解生成式AI的强项和弱点。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.08665", "html_url": "https://arxiv.org/abs/2406.08665", "title": "FuzzAug：由覆盖率引导的模糊测试数据扩充方法在神经测试生成中的应用", "title_en": "FuzzAug: Data Augmentation by Coverage-guided Fuzzing for Neural Test Generation", "authors": "Yifeng He,Jicheng Wang,Yuyang Rong,Hao Chen", "background": "测试对现代软件工程中构建可靠软件至关重要。由于手动创建测试用例的成本高，因此自动测试用例生成，特别是利用大型语言模型的方法，变得越来越受欢迎。神经网络方法生成的测试用例具有更高的语义意义，相比于传统的自动测试方法（例如模糊测试），更容易维护。然而，当前数据集中单元测试的多样性和数量有限，尤其是在对新但重要的语言方面。", "innovation": "本文提出了一种新型数据扩充技术FuzzAug，该技术通过引入有效的测试语义和多样化的覆盖引导输入，将模糊测试的好处引入大型语言模型。该技术通过扩展训练数据集的规模，显著提高了神经测试生成的性能。此外，FuzzAug展示了通过将动态软件分析的先验知识引入神经测试生成来改善其性能的潜力，从而在神经测试生成领域提供了显著的改进。", "conclusion": "FuzzAug技术通过显著提高神经测试生成的性能和引入模糊测试的好处，证明了引入动态软件分析先验知识来改善神经测试生成的潜力，为神经测试生成提供了重要的改进。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.21718", "html_url": "https://arxiv.org/abs/2506.21718", "title": "大规模系统性能预测的文本到文本回归", "title_en": "Performance Prediction for Large Systems via Text-to-Text Regression", "authors": "Yash Akhauri,Bryan Lewandowski,Cheng-Hsi Lin,Adrian N. Reyes,Grant C. Forbes,Arissa Wongpanich,Bangding Yang,Mohamed S. Abdelfattah,Sagi Perel,Xingyou Song", "background": "在许多行业中，预测大型系统的度量指标是基本问题，传统方法主要依赖于表格回归。然而，在配置文件或系统日志等复杂系统的实际数据中，传统方法常常难以进行特征工程。因此，本文提出了文本到文本回归作为一般且可扩展的替代方案。通过在谷歌大规模计算集群调度系统Borg上预测资源效率，展示了该方法的有效性，使用了一个包含60M参数的编码器-解码器模型，从随机初始化训练，实现了整体集群上几乎完美的0.99（0.9平均）的排名相关性，以及比表格方法低100倍的均方误差。该模型还容易适应新任务，并且能捕捉复杂结果分布的密度。消融研究强调了使用编码器、增加序列长度以及模型固有的不确定性量化的重要性。", "innovation": "提出了一种文本到文本回归作为预测大型系统性能的通用且可扩展的方法。通过在Borg系统上进行实验证明了该方法的有效性，并展示了其在新任务方面的能力及对复杂结果分布的捕捉能力。还通过消融研究验证了模型设计中的关键组成部分的重要性。", "conclusion": "这些发现为实现实时、准确预测物理世界大型系统性能的真实世界仿真器铺平了道路。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.22185", "html_url": "https://arxiv.org/abs/2506.22185", "title": "通过AgentAI与MAPE-K集成实现自治微服务管理", "title_en": "Autonomic Microservice Management via Agentic AI and MAPE-K Integration", "authors": "Matteo Esposito,Alexander Bakhtin,Noman Ahmad,Mikel Robredo,Ruoyu Su,Valentina Lenarduzzi,Davide Taibi", "background": "微服务正在通过提供无与伦比的可扩展性和独立部署能力，革新云计算领域。然而，它们的分散性质带来了重大的安全和管理挑战，这些挑战可能威胁到系统的稳定性。现有的系统管理方法难以应对高度分布式系统所带来的复杂性。因此，迫切需要一种能够实现自主异常检测与修复的框架来应对这些挑战。", "innovation": "本文提出了一种基于MAPE-K框架的自适应系统管理框架，该框架利用了代理AI，以应对高度分布式系统管理的挑战。该框架提供了实用的、符合行业标准的解决方案，可以增强微服务系统的稳健性和安全性，并针对诸如系统性能水平、抗毁性、安全性和异常管理等一系列更广泛的质量属性进行监控和管理。使用者可以基于此框架进行定制，从而实现更高的系统稳定性、减少停机时间，及监控系统质量属性。", "conclusion": "所提出的框架不仅提供了解决微服务系统管理的根本性方法，还为未来的微服务管理提供了新的思路。通过这种方式，可以有效地提升系统的整体性能和安全性，增强了系统的自适应和自愈能力。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.22370", "html_url": "https://arxiv.org/abs/2506.22370", "title": "大型语言模型能否帮助学生证明软件正确性？Dafny的一种实验研究", "title_en": "Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny", "authors": "Carolina Carreira,Álvaro Silva,Alexandre Abreu,Alexandra Mendes", "background": "越来越多的计算机教育学生利用大型语言模型（LLMs），如ChatGPT。然而，LLMs在支持认知要求较高的任务，例如演绎程序验证，方面的具体作用仍不清楚。本文通过让研究生在Dafny中进行形式验证练习来探讨学生在使用LLM解决形式验证问题时的情况，Dafny是一种支持函数正确性、允许程序员编写形式规范并自动验证实现满足规范的语言。研究采用混合方法，让学生分别在有和没有ChatGPT定制界面的情况下解决两个验证问题，考察其表现差异和学生对LLMs的信任程度，发现学生的表现与提示质量有关，整体上，使用ChatGPT的学生表现更好。", "innovation": "本文研究了大型语言模型（LLMs）在支持学生进行形式验证实践时的具体作用，特别是其在演绎程序验证等高级编程任务中的应用，并通过实验证明了其有效性。研究还探讨了学生对于LLMs的信任程度，这为合理使用LLMs提供了一定的理论依据。通过实验证据表明，提示质量与模型使用效果紧密相关，提出了结合LLMs进行形式方法课程教学的有效策略", "conclusion": "我们的研究表明，在使用ChatGPT时，学生整体上表现更好，但这种提升依赖于提示的质量。我们提出了结合LLMs进行形式方法课程教学的实用建议，包括设计LLMs意识下的挑战，以促进学习而非简单替代。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2310.01905", "html_url": "https://arxiv.org/abs/2310.01905", "title": "Domain-Driven Design in Software Development: A Systematic Literature Review on Implementation, Challenges, and Effectiveness", "title_en": "Domain-Driven Design in Software Development: A Systematic Literature Review on Implementation, Challenges, and Effectiveness", "authors": "Ozan Özkan,Önder Babur,Mark van den Brand", "background": "Domain-Driven Design (DDD) 在软件开发领域因其能够解决复杂软件挑战而备受关注，尤其是在系统重构、重新实现和采用方面。通过使用领域知识，DDD旨在有效解决复杂的商业问题。文献综述（SLR）旨在分析现有关于 DDD 在软件开发中的研究，描绘 DDD 在解决软件问题中的应用图景，识别其应用过程中遇到的挑战，并探讨这些研究的结果。", "innovation": "本研究系统地选择了 36 篇同行评审的研究，并进行了定量和定性的分析以综合研究发现。研究表明，DDD 已经有效地改进了软件系统，并因其在微服务中的应用而变得更加突出，这有助于系统分解。然而，一些研究缺乏实证评估，指出了入职培训的挑战和专业知识的需要。此外，需要更多的实证研究和对挑战的开放讨论，以促进 DDD 在项目中的采用和知识转移。", "conclusion": "采用 DDD 对软件开发有益，涉及工程师、架构师、经理和领域专家等利益相关者。需要更多实证研究和对挑战的开放讨论以推动 DDD 在项目中的采用和知识转移。学术界与工业界之间的合作有助于推进 DDD 的应用和知识转移。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2412.05958", "html_url": "https://arxiv.org/abs/2412.05958", "title": "向量化人工与代理协作工作流建模：一种BPMN扩展", "title_en": "Towards Modeling Human-Agentic Collaborative Workflows: A BPMN Extension", "authors": "Adem Ait,Javier Luis Cánovas Izquierdo,Jordi Cabot", "background": "大型语言模型（LLMs）为自主智能代理的定义提供了可能性。这些代理已经在各个领域展示了解决复杂任务的潜力，并且在多智能体系统中与其他智能体合作时还可以进一步提高性能。然而，这些智能体的协调和编排仍然是一个挑战，尤其是在它们需要作为部分人工与代理协作工作流的一部分与人类互动时。目前的工作流程建模语言在描述这类混合协作场景时存在不足。本研究通过扩展一个广泛使用的流程建模语言（即BPMN）来解决这一问题，目标是精确地定义协作工作流，使任务责任明确，并允许定义代理可以用来完成任务的策略及在提出多种可选方案时如何做出决定等细节问题。", "innovation": "本研究通过扩展BPMN语言，填补了现有工作流建模语言在描述人工与代理协作工作流方面的空白，同时提出了一种BPMN类似的图形表示法，以便于这些工作流的定义。此外，该扩展已经被实现并作为开源的人工与代理工作流建模编辑器发布在GitHub上。", "conclusion": "研究通过扩展BPMN语言，成功实现了对人工与代理协作工作流的建模，改善了当前在多智能体系统中定义和执行此类工作流的能力，该编辑器对未来的进一步研究和应用具有重要价值。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.12286", "html_url": "https://arxiv.org/abs/2506.12286", "title": "SWE-Bench 幻象：当最先进的 LLM 记忆而非推理时", "title_en": "The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason", "authors": "Shanchao Liang,Spandan Garg,Roshanak Zilouchian Moghaddam", "background": "随着大型语言模型（LLMs）能力增强和广泛应用，基准测试在评估其实际应用价值方面发挥着关键作用。SWE-Bench Verified 已成为评估 LLM 软件工程能力尤其是解决实际 GitHub 问题能力的关键基准。然而，当前的评估方法可能夸大了这些模型的真正能力，需要区分它们的一般问题解决能力和其他学习到的特征。本研究通过引入两项诊断任务：仅从问题描述中识别文件路径，以及仅依赖当前文件上下文和问题描述从头重写函数，来探索 SWE-Bench 上成绩提升的部分原因可能是记忆而不是真正的解决问题能力。实验结果显示，最先进的模型在仅使用问题描述的情况下识别有 bug 的文件路径的准确率高达 76%，但在未包含 SWE-Bench 的仓库中任务准确率仅为 53%，表明可能存在数据污染或记忆现象。这一结论还表现为函数重写任务中，SWE-Bench Verified 中的直译相似度显著高于其他类似编程基准。这些发现引发了现有结果有效性的质疑，并强调了需要更加强大且抗污染的基准测试，以可靠地评估 LLM 的编码能力。", "innovation": "本文提出了两项新的诊断任务，用于分析模型在解决软件工程问题时的表现。通过这些任务，研究揭示了当前基准测试存在数据污染或记忆偏见的问题，从而为 LLM 的实际编码能力提供了更可靠的评估手段。", "conclusion": "现有的结果可能因数据污染或记忆偏见而被夸大，因此需要改进测试基准以更准确地评估 LLM 的编码能力。未来的研究应开发新的基准测试方法，确保 LLM 能够真正解决问题而不是仅仅依靠记忆。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.00521", "html_url": "https://arxiv.org/abs/2504.00521", "title": "大型系统中自动生成原子性违规检测", "title_en": "Automated detection of atomicity violations in large-scale systems", "authors": "Hang He,Yixing Luo,Chengcheng Wan,Ting Su,Haiying Sun,Geguang Pu", "background": "中断驱动程序中的原子性违规对关键软件系统的安全性构成了重大威胁。这些违规行为发生在共享资源操作的执行顺序被异步中断破坏时。检测原子性违规极具挑战性，因为涉及庞大的程序状态空间、应用程序级别的代码依赖关系以及复杂的领域特定知识。", "innovation": "提出了Clover，一种结合静态分析和大型语言模型（LLM）代理的混合框架，用于检测真实世界程序中的原子性违规。Clover首先执行静态分析以提取关键代码片段和操作信息，随后启动一个多代理过程，其中专家代理利用领域特定知识检测原子性违规，然后由裁判代理进行验证。", "conclusion": "在RaceBench 2.1、SV-COMP和RWIP上的评估显示，Clover在F1分数上分别比现有方法高出27.4%-118.2%，实现了92.3%/86.6%的精确度和召回率。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.13310", "html_url": "https://arxiv.org/abs/2503.13310", "title": "生成人工智能在软件架构中的应用、挑战和未来方向", "title_en": "Generative AI for Software Architecture. Applications, Challenges, and Future Directions", "authors": "Matteo Esposito,Xiaozhou Li,Sergio Moreschini,Noman Ahmad,Tomas Cerny,Karthik Vaidhyanathan,Valentina Lenarduzzi,Davide Taibi", "background": "生成式人工智能（GenAI）正在改变许多软件开发工作，但在软件架构的应用还处在初级阶段，且此前没有系统性的研究探讨其在软件架构中的应用情况。这项研究旨在系统地总结GenAI在软件架构中的使用、动机、场景、可用性以及未来面临的挑战。研究表明，GenAI主要被用于架构决策支持和架构重建中，大多被应用于软件开发生命周期的初期阶段，如需求到架构和架构到代码。此外，也有对单体架构和微服务架构的应用。但是，大多数研究中缺乏对GenAI输出的严格测试。常见的挑战包括模型精确度、幻觉、伦理问题、隐私问题以及特定于架构的数据集缺乏等。", "innovation": "本研究通过多声部文献综述方法，分析了同行评审和灰色文献，识别了当前实践、模型、采用情境以及报告的挑战，并通过开放式编码提炼出主题。本研究系统地归纳了GenAI在软件架构中的应用，揭示了其在初始阶段的应用以及常见应用领域，并指出了主要面临的挑战，为进一步研究指明了方向。", "conclusion": "生成式人工智能在软件设计中显示出巨大的潜力，但仍面临许多挑战。未来的研究应针对设计通用评价方法、处理伦理和精确性问题、提高透明度和解释性、推动特定于架构的数据集和基准，以弥合理论可能性和实际应用之间的差距。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.01463", "html_url": "https://arxiv.org/abs/2505.01463", "title": "通过主题建模增强云安全", "title_en": "Enhancing Cloud Security through Topic Modelling", "authors": "Sabbir M. Saleh,Nazim Madhavji,John Steinbacher", "background": "在日益复杂和持久的网络威胁背景下，保护云应用程序至关重要。连续集成和连续交付（CI/CD）管道尤其容易受到攻击，因此需要创新的安全方法。这项研究探讨了自然语言处理（NLP）技术，特别是主题建模，用于分析与安全相关的文本数据，以预测潜在的安全威胁。利用Python的Gensim框架，研究通过Latent Dirichlet Allocation (LDA)和Probabilistic Latent Semantic Analysis (PLSA)方法从日志、报告和部署跟踪等数据源中提取有意义的模式，并将其分为安全相关的主题（例如，钓鱼、加密失败）。这些主题有助于识别CI/CD各个连续阶段（构建、测试、部署）中的安全问题模式，从而支持早期漏洞识别和运行时行为的上下文理解。", "innovation": "研究引入了主题建模技术，特别是LDA和PLSA方法，通过分析日志和报告数据来预测潜在的安全威胁，并将其应用于CI/CD管道中，以实现早期漏洞识别和运行时行为的上下文理解。这种方法提供了一个语义层，以便于早期发现系统的安全漏洞和理解其运行时行为的上下文。", "conclusion": "该研究通过应用NLP技术，特别是LDA和PLSA方法，为早期发现云应用程序中的安全问题提供了有效手段，支持了CI/CD过程中的持续安全监测。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.22390", "html_url": "https://arxiv.org/abs/2506.22390", "title": "ChatGPT 在软件问题解决中的有效性是什么？基于GitHub开发者-ChatGPT对话的经验研究", "title_en": "What Makes ChatGPT Effective for Software Issue Resolution? An Empirical Study of Developer-ChatGPT Conversations in GitHub", "authors": "Ramtin Ehsani,Sakshi Pathak,Esteban Parra,Sonia Haiduc,Preetha Chatterjee", "background": "对话型大语言模型被广泛用于问题解决任务。然而，并非所有开发人员与大语言模型（LLM）的对话都对有效问题解决有益。本文通过对GitHub issue线程中共享的686次开发者与ChatGPT的对话进行分析，以识别哪些对话特征有助于有效问题解决。研究背景在于理解哪些类型的任务最能体现ChatGPT的有效性，并通过多种对话、项目和问题相关度量指标来发现有助于对话成功的因素。此外，研究还指出了无效对话的常见缺陷，为设计更有效的面向开发者的工具提供了参考。研究发现，只有62%的ChatGPT对话对成功的问题解决有益。ChatGPT在代码生成和工具/库/API推荐方面最有效，但在代码解释方面有所挑战。有效的对话通常较短、更具易读性和更强的语义和语义一致性。大型、更受欢迎的项目和更有经验的开发人员从ChatGPT中获益更多。从问题层面来看，ChatGPT在简单、有限开发人员活动且快速解决的问题上表现最佳，通常是范围明确的任务，如编译错误。无效ChatGPT响应的最常见缺陷包括信息错误和缺乏全面性。这些发现对指导开发人员的有效交互策略、优化提示设计的工具或框架开发以及微调语言模型以适应问题解决任务具有广泛影响。", "innovation": "该研究通过对GitHub中的开发者与ChatGPT的对话进行详细分析，识别有效对话的特征，并揭示了这些对话与问题解决成功之间的关联。该研究还指出了无效对话的常见缺陷，为未来的工具设计提供了有价值的见解和方向。该研究的独特之处在于其采用了系统性的分析方法来评估ChatGPT在软件问题解决中的实际应用效果。", "conclusion": "该研究揭示了ChatGPT在软件问题解决中的有效性，并详细分析了有效对话的特征和无效对话的缺陷。这些发现为如何提高开发人员与语言模型的交互效率、开发支持最佳提示设计的工具和框架，以及进一步调整语言模型以更好地服务于问题解决任务提供了宝贵的指导。"}
{"llm_update_time": "20250630", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.10323", "html_url": "https://arxiv.org/abs/2506.10323", "title": "ELFuzz：通过大型语言模型驱动合成在生成器空间中高效生成输入", "title_en": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space", "authors": "Chuyang Chen,Brendan Dolan-Gavitt,Zhiqiang Lin", "background": "生成基模糊测试根据输入文法和语义约束生成适当的测试案例来测试系统和软件，但这些规范需要显著的手动努力来构建。现有方法通常需要人工干预，且难以大规模应用于大型系统。", "innovation": "提出了ELFuzz（通过大型语言模型实现模糊测试的进化），这是一种自动合成针对测试系统的自适应模糊器的新方法，通过大型语言模型（LLM）驱动的合成过程。ELFuzz能够无缝扩展到实际大小的系统，同时生成高效的、能捕捉到有趣语法结构和语义约束的模糊器，这些模糊器在人类可理解的层面生成。", "conclusion": "ELFuzz在覆盖率和触发人工注入的错误方面表现出色，比现有方法提高了434.8%和174.0%。而且，它还在一个新的cvc5版本中发现五个0-day漏洞（三个是可利用的）。实证研究表明，ELFuzz的主要组件（模糊器空间模型）显著提高了其效果。进一步分析表明，生成的模糊器在人类能理解的层面成功捕捉到了有趣的语法结构和语义限制。这些结果表明ELFuzz潜力巨大，能够实现更自动化、高效和可扩展的输入生成。"}
