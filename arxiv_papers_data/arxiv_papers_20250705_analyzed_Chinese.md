# 20250705
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 稀释、扩散与共生：强化学习在空间囚徒困境博弈中的影响 [PDF](https://arxiv.org/pdf/2507.02211), [HTML](https://arxiv.org/abs/2507.02211)
### Authors
Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein
### Background
最近对基于强化学习的空间囚徒困境博弈的研究表明，静态代理可以通过多种机制学习合作，包括噪声注入、不同类型的强化学习算法以及邻居的收益。这项工作利用独立的多智能体Q学习算法，研究了稀释和移动性对于空间版本的囚徒困境的影响。
### Innovation
该研究使用独立的多代理Q学习算法来研究稀释和移动性对于空间囚徒困境的影响，这对模型的灵活性和基准测试具有潜在价值。研究发现固定更新规则的游戏可以与学习规则的游戏在定性上等效，并且当定义多个行动时，会形成共生互惠效应。
### Conclusion
研究观察到多种效果，包括固定规则更新的游戏与学习规则的游戏可以具有同样的定性效果，以及当定义多种行动时，群体之间会出现共生互惠效应。研究展示了算法的灵活性和模型的广泛适用性。
## 2. `cs.AI` - 在预算范围内推理：LLMs中自适应和可控制推理测试时间计算的综述 [PDF](https://arxiv.org/pdf/2507.02076), [HTML](https://arxiv.org/abs/2507.02076)
### Authors
Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates
### Background
大型语言模型（LLMs）迅速发展成为通用型代理，能够解决广泛的任务。然而，当前的模型在推理方面仍不够高效：它们在执行推理时使用的计算量是固定的，不管任务的复杂度如何，这导致它们有时对于简单的问题过度思考，而对于复杂的问题思考不足。本文综述了有效的测试时间计算（TTC）策略，这些策略旨在提高LLMs推理的计算效率。作者提出了一种两层分类法，将TTC策略分为L1可控性和L2自适应性两类。研究还跨多种数据集对领先商用的LLMs进行了基准测试，突出了推理性能与词元使用之间的关键权衡。与以往关于高效推理的工作综述相比，本文强调了TTC方法的实用控制和可扩展性。最后讨论了混合推理模型等新兴趋势，并指出了未来研究中提高LLMs计算效率、鲁棒性以及响应用户约束的关键挑战。
### Innovation
作者提出了两种TTC策略分类法，L1-controllability和L2-adaptiveness。这项工作首次全面综述了TTC方法，着重强调了实用控制、自适应性和扩展性，并探讨了新兴趋势和未来挑战。
### Conclusion
本文综述了TTC方法，强调了这些方法的实际控制能力、自适应性和可扩展性，并提出了混合推理模型等新兴趋势。同时还指出了未来研究的方向，即提高LLMs的计算效率、鲁棒性和响应用户约束的能力。
## 3. `cs.AI` - 神经科学能教给AI在持续变化环境中学习的知识 [PDF](https://arxiv.org/pdf/2507.02103), [HTML](https://arxiv.org/abs/2507.02103)
### Authors
Daniel Durstewitz,Bruno Averbeck,Georgia Koppe
### Background
现代AI模型，如大型语言模型，通常在大规模数据集上进行一次训练，可能针对特定任务进行微调，然后在固定参数下部署。它们的训练过程昂贵、缓慢且逐步进行，需要数以十亿次的反复。相比之下，动物能够持续适应不断变化的环境情况。对于社交物种而言，这种学习尤其重要，因为其行为策略和奖赏结果会频繁地与同伴互动而发生变化。动物的行为和神经元群体活动往往迅速转变。这种计算能力对未来在实际环境中运行的AI系统——如引导机器人或自动驾驶汽车的系统——或与人类在线互动的代理式AI具有重要意义。AI可以从神经科学中学习吗？这篇视角文章探讨了这一问题，整合了AI中的持续学习和基于上下文学习的文献，与行为任务中规则、奖赏概率或结果变化的神经科学学习相整合。我们概述了神经科学对AI这一领域的现有进展的具体见解，并反向考虑了AI可以如何为神经科学研究做出贡献，共同推动不断发展的神经科学与AI交叉领域。
### Innovation
在此领域引入神经科学领域的持续学习和基于上下文学习的概念，并探讨它们如何相互启发，推进人工智能技术在面对不断变化环境时的适应性。
### Conclusion
神经科学可以从AI的计算模型中获取灵感，同时AI也可以从理解大脑如何学习中获益，两者的结合可以推动神经科学与AI交叉领域的未来研究和发展。
## 4. `cs.AI` - Data Diversification Methods In Alignment Enhance Math Performance In LLMs [PDF](https://arxiv.org/pdf/2507.02173), [HTML](https://arxiv.org/abs/2507.02173)
### Authors
Berkan Dokmeci,Qingyang Wu,Ben Athiwaratkun,Ce Zhang,Shuaiwen Leon Song,James Zou
### Background
尽管近期的偏好学习进展已经在人类反馈的一致性方面取得了一些进展，但数学推理仍然是一个持续存在的挑战。本研究探讨了偏好优化中的数据多样化策略如何提高大型语言模型（LLMs）的数学推理能力。研究评估了三种常见数据生成方法：温度采样、Chain-of-Thought提示和蒙特卡洛树搜索（MCTS），并引入了一种名为Diversified-ThinkSolve（DTS）的新颖结构化方法，该方法系统地将问题分解为多种推理路径。
### Innovation
提出了一种名为Diversified-ThinkSolve（DTS）的新颖结构化方法，该方法系统地将问题分解为多种推理路径。研究结果显示，在战略上多样化后的偏好数据能显著提高数学推理性能，相较于基线模型，最佳方法在GSM8K上提高了7.1%，在MATH上提高了4.2%。尽管DTS表现出色，但其计算开销仅增加了1.03倍，而MCTS则开销几乎是其五倍且效果较差。这意味着系统探索多种形式的解题方法比传统方法更能产生有效的偏好数据，以实现数学对齐。
### Conclusion
研究结果表明，结构化的多样化探索比传统方法更有效地产生了有效的偏好数据，从而提高了数学对齐性能。尽管DTS在计算开销上仅增加了很小的负担（1.03倍），但其在数学推理上的改进效果是显着的。与MCTS相比，DTS在平衡性能和计算成本方面表现更优。
## 5. `cs.AI` - 公平性的幻象：审计研究中评估公平性干预措施 [PDF](https://arxiv.org/pdf/2507.02152), [HTML](https://arxiv.org/abs/2507.02152)
### Authors
Disa Sariola,Patrick Button,Aron Culotta,Nicholas Mattei
### Background
人工智能系统，尤其是在求职和贷款发放等领域的部署，正被用于自动化这些复杂决策。现代社会科学和计算科学的研究旨在判断这些AI系统和人类决策的有效性和公平性。机器学习中常见的处理下游分类器偏见的方法是对训练数据重新采样，以消除不平等。然而，这些方法通常仅在通过方便样本获得的数据上进行评估，这引入了选择偏差和标签偏差。在社会科学研究中，使用虚拟“测试人”的审计研究（如假简历、电子邮件或病人角色）进行随机控制试验，可以获得高质量的数据，支持对歧视的严谨估计。本研究旨在探讨审计研究数据如何提高我们训练和评估自动化招聘算法的能力。研究表明，在传统指标上显示平等的情况下，基础率均衡方法实际上仍存在约10%的偏差。此外，还介绍了基于个体治疗效应估计的干预措施，以进一步减少算法中的歧视。
### Innovation
本研究强调了使用审计研究数据的方法，来提高训练和评估自动化招聘算法的能力，揭示了常见公平性干预方法的局限性，并提出基于个体治疗效应估计的新干预措施，能够更准确地减少算法中的歧视.
### Conclusion
研究发现，基础率均衡方法可能在传统指标上看起来已经实现了平等，但实际上偏差仍然存在。基于个体治疗效应估计的干预措施能够进一步减少算法中的歧视。
## 6. `cs.AI` - HCVR: 一种基于相关性投票规则的混合特征选择方法 [PDF](https://arxiv.org/pdf/2507.02073), [HTML](https://arxiv.org/abs/2507.02073)
### Authors
Nikita Bhedasgaonkar,Rushikesh K. Joshi
### Background
本文提出了一种基于相关性的投票规则相结合的轻量级特征选择方法HCVR，该方法结合了Parameter-to-Parameter (P2P) 和 Parameter-to-Target (P2T) 相关性，用于消除冗余特征和保留相关特征。这种方法是基于非迭代性和迭代性降维方法的混合体。它通过反向消除工作，每次消除一个或多个特征。规则用于投票决定特征的去留，通过多数投票作出最终决定。规则利用了不同特征之间以及特征与目标变量之间的相关性阈值。该方法应用了SPAMBASE数据集，结果表明其性能优于传统的非迭代方法（CFS、mRMR和MI）和迭代方法（RFE、SFS和遗传算法）。
### Innovation
HCVR方法结合了non-iterative和iterative的特征选择方法，通过P2P和P2T相关性来消除冗余特征和保留相关特征。该方法利用规则进行投票，并通过多数投票决定特征的去留。它是一种贪婪方法，通过反向逐步消除特征。应用HCVR方法到SPAMBASE数据集上，其性能优于多种传统特征选择方法，尤其是分类器性能得到提升。
### Conclusion
HCVR方法在特征选择和降维方面取得了较好的性能，能够有效地提高分类器的效果。
## 7. `cs.AI` - STELLA：生物医药研究的自我进化LLM代理 [PDF](https://arxiv.org/pdf/2507.02004), [HTML](https://arxiv.org/abs/2507.02004)
### Authors
Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong
### Background
生物医学数据、工具和文献的迅猛增长形成了一个超出人类专业能力范围的分割研究格局。AI代理可以解决这个问题，但它们通常依赖于静态的手动整理工具集，这限制了它们的适应性和扩展性。
### Innovation
我们介绍了STELLA，一个自我进化的AI代理，旨在克服上述限制。STELLA采用多代理架构，通过两种核心机制自主提高自身能力：一个发展的模板库用于推理策略，以及一个动态工具海洋，随着一个工具创建代理自动发现和整合新的生物信息学工具，从而让STELLA能够从经验中学习。
### Conclusion
我们证明STELLA在一系列生物医学基准测试中的性能达到了最先进的准确度，例如，在人类的最后一场考试：生物医学、LAB-Bench：DBQA和LAB-Bench：LitQA中分别获得了约26%、54%和63%的分数，其性能随经验的增加而系统地提高；例如，在人类的最后一场考试基准测试中的准确率随着试次数增加几乎翻倍。STELLA代表了向能够学习和成长、动态扩展专业能力以加速生物医药发现的AI代理系统的一个重要进展。
## 8. `cs.AI` - OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent [PDF](https://arxiv.org/pdf/2507.02353), [HTML](https://arxiv.org/abs/2507.02353)
### Authors
Bowen Chen,Zhao Wang,Shingo Takamatsu
### Background
关键词决策在赞助搜索广告中至关重要，然而基于LLM的方法受限于大规模查询-关键词数据集、缺乏在线多目标性能监控和优化以及关键词选择质量控制不足等问题。这些问题阻碍了完全自动化关键词决策的代理使用，特别是在通过监控和基于关键性能指标（如印象、点击、转化和CTA效果）进行推理方面。现有方法存在上述缺陷。
### Innovation
提出了一种名为OMS的关键词生成框架，该框架具有三大特性：即席生成（无需训练数据）、多目标优化（进行代理推理，基于多个性能指标优化关键词）和自反省（代理评估关键词质量）。实验表明，OMS在基准测试和实际广告活动中优于现有方法，且消融实验和人工评估证实了每个组件的有效性和生成关键词的质量。
### Conclusion
研究展示，OMS通过利用LLM代理的即席生成、多目标优化和自反省特性，解决了现有方法中的关键问题，显著提升了关键词生成的效果。
## 9. `cs.AI` - NL2FLOW在扩展LLM推理方面的作用：参数化问题生成和严格的评价系统 [PDF](https://arxiv.org/pdf/2507.02253), [HTML](https://arxiv.org/abs/2507.02253)
### Authors
Jungkoo Kang
### Background
大型语言模型（LLM）在规划和推理能力方面的进步受到可扩展且可靠的数据生成和评估瓶颈的阻碍。这个问题限制了LLM在复杂场景下的应用和发展。为了克服这一挑战，本文提出了一种名为NL2FLOW的自动化系统，用于参数化生成以自然语言、结构化中间表示和形式化的PDDL表达的问题集合，并且能够严格评估生成的计划质量。通过在自动化工作流程生成领域生成2296个问题集并评估多个开源指令微调的LLM，发现最高性能模型在生成有效计划方面的成功率为86%，在生成最优计划方面的成功率为69%，这些结果表明，影响规划生成的因素不仅依赖于模型和提示设计，还与问题特征有关。此外，直接从自然语言生成行动计划的成功率比将自然语言转换为JSON表示的成功率高，这表明不必要的分解推理任务可能会损害性能，建议直接从自然语言推理到行动的好处。
### Innovation
NL2FLOW是一种完全自动化的系统，能够基于参数生成自然语言表达的问题、结构化的中间表示以及形式化的PDDL表示，并严格评价生成的计划质量。这个系统通过生成一个包含2296个问题的工作流程生成领域的数据集以及对多个开源指令微调的LLM进行评估，展示了其能力。此外，该系统揭示了具有更高性能的模型在生成有效和最优计划方面的成功比例，通过回归分析展示了问题特征、模型和提示设计对规划生成的影响关系，发现直接从自然语言到行动计划的成功率高于先翻译成JSON再生成行动计划的成功率，这暗示了直接推理的优势。
### Conclusion
随着LLM推理任务复杂性增加，这些系统中的瓶颈和错误源头也将发生变化。因此，动态理解和系统性揭示这些限制的方法对于解锁LLM作为智能问题解决者的全部潜力至关重要。
## 10. `cs.AI` - 使用系统生物学干实验衡量语言模型的科学能力 [PDF](https://arxiv.org/pdf/2507.02083), [HTML](https://arxiv.org/abs/2507.02083)
### Authors
Haonan Duan,Stephen Zhewen Lu,Caitlin Fiona Harrigan,Nishkrit Desai,Jiarui Lu,Michał Koziarski,Leonardo Cotta,Chris J. Maddison
### Background
实验设计和结果解读是生物科学的核心技能，特别是在研究复杂系统时。然而，当前评估语言模型科学能力的努力并未涵盖这些技能，因为真实湿实验室实验成本高昂。SciGym作为一种新基准，通过模拟生物系统的“干实验室”实验，克服了这一挑战，评估模型的迭代实验设计和分析能力。这些模型用系统生物学标记语言编码，适合生成模拟数据，适用于复杂系统的实验。现有研究通过6种最先进的语言模型在137个小系统上的评估，展示了模型的性能随系统复杂性的增加而显著下降，表明需要改进语言模型的科学能力。
### Innovation
SciGym作为一种新的基准，通过模拟生物系统的“干实验室”实验，评估语言模型的实验设计和分析能力，解决了传统评估中的高成本问题。基于系统生物学标记语言编码的模型能够高效生成模拟数据，适合作为复杂系统的实验测试平台。
### Conclusion
现有评估表明，尽管更先进的语言模型表现较好，但其性能随系统复杂性的增加而急剧下降，表明在语言模型的科学能力上还有较大的改进空间。
## 11. `cs.AI` - 角色扮演代理是否言行一致？基于LLM的人类信任仿真中的信念行为一致性 [PDF](https://arxiv.org/pdf/2507.02197), [HTML](https://arxiv.org/abs/2507.02197)
### Authors
Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto
### Background
由于越来越大将大型语言模型（LLM）作为角色扮演代理来生成用于人类行为研究的合成数据，确保它们的输出与赋予的角色保持一致已经成为一个关键问题。本文探讨了基于LLM的角色扮演代理声称的行为信念与实际角色扮演行为之间的一致性。为了确定这种一致性，作者建立了一个评估框架，用于严要地测量从模型获得的信念能否准确预测模拟结果。然后使用一个增强后的GenAgents人设库和信任博弈（一种用于衡量玩家信任和互惠的标准经济游戏），研究不同因素如：所引出的信念类型、何时以及如何向模型呈现信任博弈的相关信息、模型被要求预测其行为的时间跨度对信念行为一致性的影响，以及在原引出的信念与研究目标不一致时，是否能够将研究者的理论先验强加到模型上。研究表明，即使模型看起来编码了合理的信念，它们也可能无法在一致的方式下应用这些信念，在个体和群体层面都存在系统性不一致。
### Innovation
本研究建立了一个评估框架，用于系统地测量由模型获取的信念能否预测模拟结果，同时采用增强版的GenAgents人设库和信任博弈来研究影响信念行为一致性的关键因素，研究还探讨了在原引出的信念与研究目标不一致时如何将研究者的理论先验强加到模型上。这些发现强调了识别LLM在声称行为和实际角色扮演行为之间一致性的重要性，为在行为研究中正确使用基于LLM的代理提供了方法指导。
### Conclusion
尽管模型可能包含合理的信念，但它们可能不一致地应用这些信念。因此，研究人员需要识别和理解LLM声称的行为与其模拟行为之间的对齐情况，以正确地在行为研究中使用基于LLM的代理。
## 12. `cs.AI` - DynamiCare：一种用于互动和开放式医疗决策的动态多智能体框架 [PDF](https://arxiv.org/pdf/2507.02616), [HTML](https://arxiv.org/abs/2507.02616)
### Authors
Tianqi Shang,Weiqing He,Charles Zheng,Lingyao Li,Li Shen,Bingxin Zhao
### Background
大型语言模型（LLMs）的发展使得能够开发出具备领域特定推理解析和交互能力的专门型人工智能代理，特别是在医疗健康领域。现有的框架虽然可以模拟医疗决策过程，但仍主要关注的是单一回合的任务，即医生代理一次性收到全部病例信息进行决策，而忽略了实际诊断过程中固有的不确定性、互动性和迭代性特征。
### Innovation
本文提出了一种新的动态多智能体框架——DynamiCare，该框架将临床诊断建模为多轮交互循环，通过一个由专科代理组成的团队，动态地对患者系统进行询问，整合新信息，并根据需要动态调整其组成和策略。DynamiCare 是第一个基于 LLM 的代理进行动态临床决策的基准。
### Conclusion
通过广泛的实验，证明了 DynamiCare 的可行性和有效性，建立了基于 LLM 的代理在动态临床决策中的首个基准。
## 13. `cs.AI` - 顺序决策机制中的责任缺口和扩散 [PDF](https://arxiv.org/pdf/2507.02582), [HTML](https://arxiv.org/abs/2507.02582)
### Authors
Junli Jiang,Pavel Naumov
### Background
责任是法律和哲学研究的长期主题。近年来，责任也成为人工智能文献的重点。本文探讨了在集体决策制定中两个重要的责任属性：扩散和缺口的计算复杂性。
### Innovation
研究表明，无扩散和无缺口决策机制的集合分别属于$boldsymbol{text{Π}_2}$完全和$boldsymbol{text{Π}_3}$完全类别，同时这两个类别的交集也是$boldsymbol{text{Π}_2}$完全的。这一发现揭示了权限结构中责任属性计算复杂性的本质，并为决策机制的设计提供了理论依据。
### Conclusion
通过分析责任缺口和扩散在顺序决策机制中的复杂性，文章展示了这些属性在计算复杂性理论中的位置，为理解和优化集体决策机制提供了新的视角。
## 14. `cs.AI` - 高斯-马尔可夫共轭关系：监督学习中残差的范畴语义 [PDF](https://arxiv.org/pdf/2507.02442), [HTML](https://arxiv.org/abs/2507.02442)
### Authors
Moto Kamiura
### Background
提高机器学习的可解释性和可解释性是应对AI原则中的‘ explicability ’需求，并促进AI更佳的社会实施的关键任务。研究的目的是通过范畴论重新定义机器学习模型，提供一种结构化和理解AI系统的语义框架。本文重点在多变量线性回归模型上，这是监督学习最基础的形式。通过定义参数和数据对应的两个具体范畴，以及这两个范畴之间的伴随对函子，提出了监督学习的范畴表达法。这种方法能够明确和形式化监督学习中残差和参数的结构性交互。
### Innovation
提出了高斯-马尔可夫共轭关系，这是一种范畴语义表达方式，能够在监督学习背景下明确描述残差和参数之间的信息流。普通最小二乘法参数估计和最小残差通过伴随右函子的保持极限相关联。此外，还从理论计算机科学中的语义视角出发，为AI中的‘ explicability ’提供了形式化的基础。
### Conclusion
本文通过范畴论的方法重新定义了监督学习模型，提出了高斯-马尔可夫共轭关系，明确了监督学习中参数和残差之间的结构性交互，还提出了将其作为理论计算机科学中的语义视角应用于AI“ explicability ”的建议。
## 15. `cs.AI` - AI研究代理在机器学习中的应用：MLE-bench中的搜索、探索与泛化 [PDF](https://arxiv.org/pdf/2507.02554), [HTML](https://arxiv.org/abs/2507.02554)
### Authors
Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach
### Background
人工智能研究代理具有通过自动化机器学习模型的设计、实现和训练来加速科学进步的巨大潜力。我们关注在MLE-bench上改进代理性能的方法，这是一个具有挑战性的基准，代理在这里参与Kaggle竞赛以解决实际的机器学习问题。
### Innovation
通过设计不同的操作集和搜索策略（贪婪、MCTS、进化算法）并系统地调整它们，我们显示它们的相互作用是实现高性能的关键。我们的最佳策略和操作集组合在MLE-bench lite上达到了最先进的结果，将获得Kaggle奖牌的成功率从39.6%提高到47.7%。我们的研究强调了同时考虑搜索策略、操作设计和评估方法的重要性，以推动自动化机器学习的进步。
### Conclusion
改进了代理在MLE-bench上的性能，展示了在Kaggle竞赛中解决实际问题的最佳操作集和搜索策略组合，并强调了搜索策略、操作设计和评估方法的联合考虑在自动化机器学习中的重要性。
## 16. `cs.AI` - 从公理到能力的迭代信念修订 [PDF](https://arxiv.org/pdf/2507.02319), [HTML](https://arxiv.org/abs/2507.02319)
### Authors
Paolo Liberatore
### Background
信念修正领域充满了新提案，但却缺乏对现有方法的深入分析。许多工作依赖于公理，这些公理用形式化定义来说明信念修正机制：一些修正方式等同于某些性质。这些公理仅约束特定的修正实例：某些修正以特定方式更新某些信念。例如，如果修正与当前信念一致，则会无其他变更直接吸收该修正。这类公理说明了修正必须要完成的任务，而忽略了它们具备的自由度。例如，它们是否可以达到某种信念状态？是否可以达到所有可能的信念状态？是否可以从没有任何先前信念的状态出发达到所有可能的信念状态？是否可以从非绝对的信念状态转变为一种所有非信念内容都为不可能的神学状态？是否可以使两个条件具有等价的信念？不同的应用对这些能力的需求各不相同，但都需要在某种形式或另一种形式上实现这些能力，而不仅仅受限于特定的公理所规定的方式。这是一种能力而非约束，即可以改变、可以相等、可以神学、可以失忆、可以纠正、可以持有、可以达马斯堪、可以学习的能力。每个修正机制都具备某些能力但又缺乏其他能力：例如，有语义逐步、自然、有限制的、极其激进、完全交集、激进、非常严峻、中等严峻、极严峻和深层极严峻的修正机制，每种机制都被证明具备某些特定的能力
### Innovation
本文提出重新审视信念修正的方法，从传统的公理限制转向能力导向的方法，探索如何通过具备某种特定能力的机制实现从无到有、从信到不信、平等信念、达到神学状态等不同信念状态的转换，并证明了多种修正机制在不同能力上的实现程度
### Conclusion
该研究揭示了信念修正机制的广泛能力，不再局限于传统的公理约束，强调了每种修正机制具有特定能力且缺乏其他能力，提供了多种信念修正机制的操作指南。
## 17. `cs.AI` - 基于人工智能的自主生物分子工程实验室 [PDF](https://arxiv.org/pdf/2507.02379), [HTML](https://arxiv.org/abs/2507.02379)
### Authors
Mingyu Wu,Zhaoguo Wang,Jiabin Wang,Zhiyuan Dong,Jingkai Yang,Qingting Li,Tianyu Huang,Lei Zhao,Mingqiang Li,Fei Wang,Chunhai Fan,Haibo Chen
### Background
自主科学研究能够独立进行复杂实验并为非专业人士服务，一直以来都被视为长期的愿望。要实现这一目标，需要由人工智能（AI）驱动的根本性转变。虽然自主实验系统正在出现，但它们仍然局限于具有单一目标和明确简单实验流程的领域，如化学合成和催化。
### Innovation
本文介绍了一个基于人工智能的自主实验室，该系统专注于复杂科学实验，例如自主生物分子工程。该系统能够自主管理仪器、制定实验特异性程序和优化策略，并同时处理多个用户请求。基于模型、实验和仪器的共同设计理念，该平台支持AI模型和自动化系统的共同演化，从而实现跨不同仪器的复杂、多目标实验的端到端、多用户自主实验室。该自主实验室支持基本的核酸功能，包括合成、转录、扩增和测序，同时也适用于疾病诊断、药物开发和信息存储等领域。在没有人为干预的情况下，它能够自主优化实验性能，达到与人类科学家相当的结果。在多用户场景中，该平台显著提高仪器利用率和实验效率，从而为高级生物材料研究提供一条道路，克服专家依赖和资源障碍，并为大规模的‘科学即服务’提供蓝图。
### Conclusion
本平台为高级生物材料研究铺平了道路，克服了专家依赖和资源障碍，并为大规模的‘科学即服务’提供了蓝图。
## 18. `cs.AI` - 解耦规划与执行：一种层次推理框架用于深度搜索 [PDF](https://arxiv.org/pdf/2507.02652), [HTML](https://arxiv.org/abs/2507.02652)
### Authors
Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou
### Background
在现实世界的信息搜索场景中，需要进行深层次的推理和知识综合，涵盖多种来源的信息。传统的检索增强生成（RAG）管道难以有效应对这种需求。当前依赖推理的方法存在一个根本性的局限性，即使用单一模型同时处理高层次规划和详细执行，导致推理效率低下且缺乏扩展性。
### Innovation
本文提出了一种分层框架HiRA，将战略性规划与专门执行分离。该方法将复杂的搜索任务分解成特定子任务，分配给具有特定领域专业知识和外部工具的代理，并通过结构化集成机制协调结果。这种方法避免执行细节干扰高层次推理的同时，使系统能够利用不同类型的专有知识进行信息处理。实验结果表明，HiRA在四个复杂的跨模态深度搜索基准测试中显著优于现有的RAG和基于代理的系统，显示出分耦合规划与执行在多步骤信息搜索任务中的有效性。
### Conclusion
实验结果表明，HiRA在四个复杂的跨模态深度搜索基准测试中显著优于现有的RAG和基于代理的系统，证明了分耦合规划与执行在多步骤信息搜索任务中的有效性。
## 19. `cs.AI` - 结构化前缘推理：配备结构上下文的Coq证明器 [PDF](https://arxiv.org/pdf/2507.02541), [HTML](https://arxiv.org/abs/2507.02541)
### Authors
Yanzhen Lu,Hanbin Yang,Xiaodie Wang,Ge Zhang,Biao Li,Chenxu Fu,Chao Li,Yang Yuan,Andrew Chi-Chih Yao
### Background
本文的研究背景是探讨提高任务清晰度是否能增强大型语言模型的推理能力，以Coq定理证明为主要研究对象。背景中提到，使用概念级度量来评估任务的清晰度，并对现代LLM的标准输入添加结构化语义上下文，从而提高清晰度分数。研究还介绍了如何在15个标准Coq包中随机选取的1,386个定理上评估此方法的效果，与之前的SOTA方法进行了比较，展示了在较小模型上进行微调可以实现更高的性能。文章中还总结了使用选择性概念展开和规划者-执行者架构的重要性。
### Innovation
本文的创新之处在于提出了一种概念级清晰度度量方法，通过添加结构化语义上下文提升了LLM的推理能力。具体地，增加了结构化语义上下文后，任务的清晰度得分提高了1.85倍；使用通用模型DeepSeek-V3，证明成功率达到2.1倍的提升，优于之前最先进方法Graph2Tac。此外，对小型模型的微调进一步提高了证明成功率至48.6%。本文提出的方法结合了选择性概念展开和规划者-执行者架构，提高了模型在Coq定理证明上的性能。
### Conclusion
研究发现，结构化任务描述在理解与推理之间的桥梁中具有重要价值，并且通过引入结构化语义上下文和使用规划者-执行者架构，显著提升了大型语言模型在Coq定理证明中的性能。
## 20. `cs.AI` - 大型语言模型中的战略智能：从进化博弈论中获得的证据 [PDF](https://arxiv.org/pdf/2507.02618), [HTML](https://arxiv.org/abs/2507.02618)
### Authors
Kenneth Payne,Baptiste Alloui-Cros
### Background
本文探讨了大型语言模型（LLMs）是否能被视为一种新的战略智能形式，能够在竞争环境中进行目标推理。迭代囚徒困境（IPD）一直是研究决策的模型，但此前并未有系统地将经典策略与顶级人工智能公司的模型进行对比的进化IPD比赛。文章通过调整每个比赛的终止概率引入复杂性和偶然性，消耗记忆的作用，展示了LLMs在这些复杂生态系统中的高度竞争力，同时展示了各自不同的“战略印记”。
### Innovation
本文首次进行了进化IPD系列比赛，将经典策略与来自OpenAI、Google、Anthropic等领先AI公司的代理人进行对比。通过改变每个比赛的终止概率，引入了复杂性和偶然性，探讨了LLMs的战略智能表现。研究发现LLMs在竞争环境中表现出色，并表现出独特的和持久的“战略印记”：Google的Gemini模型以战略无情著称，而OpenAI的模型高度合作；Anthropic的Claude则表现出很高的宽容性，即使在被欺骗后仍然愿意恢复合作。研究还分析了近32000篇由模型提供的文字解释，发现它们能够主动地权衡时间范围和对手策略的可能性，这种推理对决策至关重要。这项工作将经典博弈论与机器心理相结合，提供了关于不确定环境下算法决策的丰富而细致的视角。
### Conclusion
研究结果表明，LLMs在复杂的生态系统中表现出高度的竞争力和独特性，并在决策过程中展示了对时间范畴和对手策略的深入思考。这项工作将经典博弈论与机器心理相结合，提供了关于不确定环境下算法决策的丰富而细致的视角，为进一步研究提供了依据。
## 21. `cs.AI` - 时间关键型和置信度为基础的抽象去除方法 [PDF](https://arxiv.org/pdf/2507.02703), [HTML](https://arxiv.org/abs/2507.02703)
### Authors
Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn
### Background
蒙特卡洛树搜索（MCTS）的一个改进范式是构建和使用状态和/或动作抽象。然而，非精确的抽象引入了近似误差，使得在抽象空间中达到最优动作的收敛成为不可能。因此，Xu等人提出的弹性MCTS中的抽象算法最终应移除抽象。但由于Xu的方法存在一些不必要的性能下降，需要新的方案来保证在去除抽象时不会导致性能显著下降并仍能提供明确的性能提升。研究提出两种新的去除抽象方案：OGA-IAAD和OGA-CAD。OGA-IAAD适用于时间关键的设置，而OGA-CAD旨在在相同的迭代次数下提升MCTS性能。
### Innovation
提出了两种新的、安全性更高的抽象去除方案——OGA-IAAD和OGA-CAD。这两者既能够提供明显的性能提升，又确保不会因为去除抽象而造成性能下降，特别是在与Xu等人所提方法相比时更为优越。OGA-IAAD设计用于时间关键的场景，OGA-CAD则通过减少迭代次数提高MCTS的性能。
### Conclusion
该研究通过提出两种新的抽象去除方法，即OGA-IAAD和OGA-CAD，有效地解决了抽象在时间关键环境下的使用问题，并提高了MCTS的性能。与Xu等人提出的方法不同，新的方法不会因去除抽象而导致性能下降，同时还能提供显著的性能提升。
## 22. `cs.AI` - 自愿测验脱钩检测：高等远程教育中可解释的机器学习方法 [PDF](https://arxiv.org/pdf/2507.02681), [HTML](https://arxiv.org/abs/2507.02681)
### Authors
Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin
### Background
学生在任务上的脱离行为可能产生长期的严重后果，包括学业退学。对于远程教育学生而言，这种情况尤为显著。为了量化远程教育中的脱离程度，可以通过观察不同在线课程中非强制性练习的参与度来进行。这项研究针对某基于远程教育大学的四个学期共42门课程中的非强制性测验进行学生脱离行为的检测研究，以探索如何通过可解释的机器学习方法及时干预并最小化非自愿任务的脱离现象，从而提升在线学习效果。
### Innovation
提出了一种可解释的机器学习框架，利用SHAP方法，能够提升预测性能并使实践者更好地理解已训练算法的决策。研究展示了超高的预测准确性，即91%的平衡准确率，其中约85%的脱离学生被正确检测出来。这种可解释的机器学习方法不仅提升了模型的预测能力，也为如何在在线学习中及时干预预防或减少学生脱离现象提供了指导。
### Conclusion
通过这种方法，研究发现了在四个学期共42门课程中，约91%的非强制性测验参与度能够被准确预测，约85%的脱离学生被正确识别。研究结果表明，及时采取干预措施可以帮助减少学生在自愿任务上的脱离现象，从而提升远程学习的效果。
## 23. `cs.AI` - Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification [PDF](https://arxiv.org/pdf/2507.02660), [HTML](https://arxiv.org/abs/2507.02660)
### Authors
Deepak Narayan Gadde,Keerthan Kopparam Radhakrishna,Vaisakh Naduvodi Viswambharan,Aman Kumar,Djones Lettnin,Wolfgang Kunz,Sebastian Simon
### Background
现代集成电路（ICs）日益复杂，其开发过程也变得更加复杂。硬件设计验证需要一个严谨和系统的方法，涵盖计划、开发、执行和最终确认功能正确的硬件设计。这一耗时且繁琐的过程要求大量的时间和人力确保芯片没有缺陷即可进行制造。近年来，自然语言处理（NLP）领域因大型语言模型（LLMs）的出现发生了重大变革。这些强大的模型常被称为生成型人工智能（GenAI），极大提升了机器对人类语言的理解和生成能力，推动了各种应用的进步，包括硬件设计验证。
### Innovation
本文提出了一种基于代理人工智能（Agentic AI）的硬件设计与验证方法。这一方法通过人机协作（Human-in-the-Loop，HITL）干预，让AI代理在更具动态性、迭代性和自我反思性的过程中进行硬件设计与验证，实现了从设计到验证的端到端流程。该方法在五个开源设计中进行评估，验证覆盖率超过95%，同时验证时间显著减少，并表现出优越的性能、适应性和配置性。
### Conclusion
基于代理人工智能的硬件设计与验证方法在多个开源设计中进行了评估，结果显示该方法不仅提高了验证覆盖率，还大大缩短了验证时间，并且在性能、适应性和配置性方面表现出色。这为硬件设计验证领域带来了新的可能性，展示了代理人工智能在实际工程中的潜力与价值。
## 24. `cs.AI` - KERAP：一种基于多代理大语言模型的知识增强推理方法以实现准确的零样本诊断预测 [PDF](https://arxiv.org/pdf/2507.02773), [HTML](https://arxiv.org/abs/2507.02773)
### Authors
Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang
### Background
医学诊断预测在疾病检测和个人化医疗服务中起着关键作用。尽管机器学习（ML）模型被广泛应用于此任务中，但它们依赖于监督训练，限制了它们在面对未见过的情况时的泛化能力，尤其是在获取大量具有标签的数据集成本高昂的情况下。大型语言模型（LLMs）在利用语言能力及生物医学知识进行诊断预测方面显示出潜力，但它们通常会出现幻觉、缺乏结构化的医学推理，并且产生无用的输出。
### Innovation
提出了一个知识图谱（KG）增强的推理框架（KERAP），通过多代理架构改进基于LLM的诊断预测。该框架包括一个链接代理来进行属性映射、一个检索代理进行结构化知识提取以及一个迭代优化诊断预测的预测代理。实验结果显示，KERAP有效地提高了诊断的可靠性，提供了一个可扩展和可解释的解决方案用于零样本医学诊断预测。
### Conclusion
研究表明，KERAP能有效提升医学诊断预测的可靠性，提供了结构化且可解释的零样本医学诊断预测方法。
## 25. `cs.AI` - 知识协议工程：一种新的领域特定知识工作中的人工智能新范式 [PDF](https://arxiv.org/pdf/2507.02760), [HTML](https://arxiv.org/abs/2507.02760)
### Authors
Guangwei Zhang
### Background
大型语言模型（LLMs）的能力为与复杂的专业知识领域进行交互开辟了新的领域。然而，现有方法如检索增强生成（RAG）和通用人工智能代理虽然强大，但在要求深入的程序化和方法论推理的任务上经常遇到困难。RAG 提供事实背景，但无法传达逻辑框架；自主代理在没有特定领域启发式的情况下可能效率低下且不可预测。为了解决这一问题，本文提出了知识协议工程（KPE），一种新的范式，专注于系统地将人类专家知识（通常以自然语言文档的形式表达）转化为机器可执行的知识协议（KP）。KPE 不仅仅是增加 LLM 的碎片化信息，而是赋予它们领域内固有的逻辑、操作策略和方法论原则。我们主张，精心设计的知识协议可以让一个通用的知识语言模型具备专家的职能，能够分解抽象查询并执行复杂的多步骤任务。
### Innovation
提出了知识协议工程（KPE），一种系统地将自然语言表达的专业知识转化为可执行的知识协议的范式。这种新方法强调将人工智能模型赋予领域内固有的逻辑、操作策略和方法论原则，而不是仅补充碎片化的信息。KPE 的创新点在于它能够使通用的语言模型像专家一样工作，执行复杂的多步骤任务。这种新方法还特别强调了其在不同领域的广泛适用性，如法律和生物信息学。
### Conclusion
本文定义了 KPE 的核心原则，将 KPE 与相关概念区分开来，并说明了其在不同领域的潜在应用。我们认为，KPE 是未来人类与人工智能合作的基础方法。
## 26. `cs.AI` - 思考如何思考：通过大型推理模型自主难度认知减轻过度推理 [PDF](https://arxiv.org/pdf/2507.02663), [HTML](https://arxiv.org/abs/2507.02663)
### Authors
Yongjiang Liu,Haoxi Li,Xiaosong Ma,Jie Zhang,Song Guo
### Background
最近的长推理模型(LRMs)在处理复杂推理任务方面表现出色，但同时也受到过多过度推理的困扰。我们的实证分析发现，LRMs主要依赖于识别任务属性（如难度级别），类似人类的方式在解决问题之前。这导致了一种一刀切的推理过程。因此，人们提出了是否可以提高LRMs的认知难度和冗余认知能力，以进一步减轻过度推理的现象。
### Innovation
我们提出了一种新颖的两阶段微调策略Think-How-to-Think (TH2T)，它可以逐步激发LRMs的认知难度和冗余认知。首先，我们在模型输出的前缀中引入困难超常现象，以干预内部推理过程，并结合异构的短和长推理数据集，进而增强模型对任务难度的敏感度，使其在不同任务上能够产生本源且差异化推理策略。其次，我们进一步将冗余超常现象引入到内部推理过程中，引导模型识别推理步骤中的冗余结构，并生成更简洁的推理输出。实验证明，TH2T策略在易题上大幅降低了推理成本（超过70%），在难题上也减少了推理成本（约40%），同时保持了性能的稳定性。
### Conclusion
通过TH2T策略，可以使生成的输出展现清晰的难度感知能力和减少冗余（如反思等），从而显著减少推理成本，同时保持性能的稳定性。
## 27. `cs.AI` - 建立严谨的代理型基准的最佳实践 [PDF](https://arxiv.org/pdf/2507.02825), [HTML](https://arxiv.org/abs/2507.02825)
### Authors
Yuxuan Zhu,Tengjun Jin,Yada Pruksachatkun,Andy Zhang,Shu Liu,Sasha Cui,Sayash Kapoor,Shayne Longpre,Kevin Meng,Rebecca Weiss,Fazl Barez,Rahul Gupta,Jwala Dhamala,Jacob Merizian,Mario Giulianelli,Harry Coppock,Cozmin Ududec,Jasjeet Sekhon,Jacob Steinhardt,Antony Kellerman,Sarah Schwettmann,Matei Zaharia,Ion Stoica,Percy Liang,Daniel Kang
### Background
基准对于量化跟踪AI的发展是至关重要的。随着AI代理越来越有能力，研究人员和实践者引入了代理性基准来评估代理在复杂、现实世界的任务中的能力。这些基准通常通过特定的奖励设计来评估任务结果来衡量代理的能力。然而，研究表明，许多代理性基准存在任务设置或奖励设计方面的问题。例如，SWE-bench Verified使用了不足的测试案例，而TAU-bench将空响应视为成功。这些问题可能导致代理表现低估或高估高达100%。因此，需要一种方法来使代理评估更为严谨，以真实反映代理的表现。
### Innovation
本文引入了代理型基准检查单（ABC），这是一种综合了作者在建立基准过程中的经验、最佳实践调查以及已报告问题的指导方针。当应用于具有复杂评估设计的CVE-Bench基准时，ABC将表现高估减少了33%。这种检查单提供了建立严谨的代理型基准的具体步骤，确保了评估的真实性和准确性。
### Conclusion
总之，本文提出了一种名为代理型基准检查单（ABC）的指导方针，用于建立严谨的代理型基准，有效减少了代理性能的高估。
## 28. `cs.AI` - 将智能扎根于运动 [PDF](https://arxiv.org/pdf/2507.02771), [HTML](https://arxiv.org/abs/2507.02771)
### Authors
Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording
### Background
近年来，机器学习的进展极大地提高了我们对语言、视觉和其他高维数据的建模能力，但在处理生物学系统中最基本的方面——运动方面仍然存在挑战。运动在神经科学、医学、机器人学和动物行为学中是理解和解释行为、预测意图和实现互动的核心。尽管运动在我们的智能中有核心意义，但在大多数情况下却被视为次要内容，而非一种独立且丰富的模态。这反映了一个更深层次的运动数据收集与建模的碎片化问题，通常受限于特定任务和特定领域的假设。然而，运动并不是局限于某个领域的，它反映了共享的物理限制、保守的形态结构和跨物种、跨环境的目的性动态。本文认为，运动应该被视为人工智能的主要建模目标。它自身具有内在结构，根植于实体性和物理性，这种结构通常允许更紧凑、低维度的表示（例如姿态），使其比原始的高维感官输入更易于解释和计算模型化。开发可以从和泛化到不同运动数据的学习模型不仅能推进生成模型和控制的核心能力，还能为理解生物系统和人工系统的行为提供共同的基础。运动不仅是结果，更是智能系统与世界互动的窗口。
### Innovation
本文提出将运动作为人工智能的主要建模目标，强调运动的内在结构化和根植于实体性和物理性的特点，这使得其模型化相比原始高维感官输入更为解释性强和计算效率高。这种观点挑战了将运动视为次要内容的传统看法，促进了从和泛化到不同运动数据的学习模型的开发，为跨生物系统和人工系统的行为理解提供了基础。
### Conclusion
总结而言，运动作为智能系统与世界互动的基础，被提出作为一个主要的建模目标，这种结构化和物理性的运动数据可以促进从不同运动数据中学习和泛化的模型，进而推进人工智能在生成模型和控制领域的核心能力，并为理解跨生物和人工系统的行为提供一个共同的基础。
## 29. `cs.AI` - Bourbaki：自动生成和目标导向的MDP在定理证明中的应用 [PDF](https://arxiv.org/pdf/2507.02726), [HTML](https://arxiv.org/abs/2507.02726)
### Authors
Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar
### Background
大型语言模型（LLMs）在逻辑受限的自动定理证明（ATP）环境中的推理任务仍具有挑战性，因为奖励较稀疏且证明规模庞大。这种挑战在包含大学级问题且需要复杂多步推理的PutnamBench基准中尤为显著。Bourbaki (7B)通过自动生成目标条件转移动态模型（sG-MDPs）来解决这些问题，让代理根据逐步证明的状态生成并追求子目标，从而使得问题更适于搜索。利用类似于蒙特卡洛树搜索（MCTS）的算法求解sG-MDP，并在Bourbaki (7B)中实现该方法，这是一个多模块系统，可以聚合多个7B LLM来生成子目标和策略合成.
### Innovation
引入了自动生成和目标导向的MDP（sG-MDPs）的新框架，这使代理能够根据逐步演化的证明状态生成并追求子目标，增强了解决问题的能力。结合蒙特卡洛树搜索（MCTS）的类似算法在sG-MDP中求解问题，通过Bourbaki (7B)实现了在大规模模型上的新状态最先进技术，成功在PutnamBench上解决了26个问题，达到了新的技术前沿.
### Conclusion
Bourbaki (7B)通过在大规模语言模型系统的多模块设置中结合自动生成目标条件的方法和蒙特卡洛树搜索类似算法，显著提高了解决复杂多步推理问题的能力，实现了在定理证明上的优异表现。
## 30. `cs.AI` - 使用强化学习加速投资组合优化和期权定价 [PDF](https://arxiv.org/pdf/2507.01972), [HTML](https://arxiv.org/abs/2507.01972)
### Authors
Hadi Keramati,Samaneh Jazayeri
### Background
在投资组合优化和期权定价中，协方差矩阵或偏微分方程的离散化导致大型线性系统。对于高维投资组合或细网格期权定价问题，直接求解计算成本高昂，通常使用迭代方法。然而，病态系统的收敛速度很慢。传统预条件技术往往需要针对特定问题的手动参数调整，这限制了通用性和灵活性。
### Innovation
本文提出了一种使用强化学习（RL）驱动的框架，用于优化迭代求解器中块预条件器的大小。该框架能够根据需求动态调整块预条件器的大小，加速迭代求解器的收敛，提升计算效率，从而支持动态投资组合再平衡和实时期权定价的快速决策。
### Conclusion
通过实证分析，该研究展示出基于RL的框架可以有效调节预条件技术和显著加速收敛，同时降低计算成本。加速的求解器适合于动态投资组合管理和实时期权定价的快速决策支持。
## 31. `cs.AI` - DeepSupp：动态时间序列支撑和阻力位识别的注意力驱动相关模式分析 [PDF](https://arxiv.org/pdf/2507.01971), [HTML](https://arxiv.org/abs/2507.01971)
### Authors
Boris Kriuk,Logic Ng,Zarif Al Hossain
### Background
支撑和阻力（SR）水平是技术分析的核心，指导交易者的入场、出场和风险管理。尽管广泛应用，传统的SR识别方法往往无法适应现代市场的复杂性和高波动性。最近的研究引入了机器学习技术来解决这些问题，但大多数方法侧重于价格预测而非结构水平的识别。
### Innovation
本文提出了一种新的深度学习方法DeepSupp，使用多头注意力机制来分析空间相关性和市场微观结构关系，从而检测金融支撑水平。DeepSupp结合了先进的特征工程，构建动态相关矩阵以捕捉不断变化的市场关系，并采用基于注意力的自编码器进行稳健的特征表示学习。最终的支撑水平通过无监督聚类提取，利用DBSCAN识别显著的价格阈值。全面的评估显示，DeepSupp在六个基准方法中表现最优，六个财务指标中达到最先进的性能，包括基本支撑准确性及市场制度敏感性。
### Conclusion
在各种市场条件下的结果表明，DeepSupp解决了SR水平检测的关键缺口，提供了一种可扩展和可靠的现代金融分析解决方案。本文的方法突显了基于注意力架构的潜力，可用于发现市场细微模式并改善技术交易策略。
## 32. `cs.AI` - StepHint: 多层次逐步提示增强强化学习以进行推理 [PDF](https://arxiv.org/pdf/2507.02841), [HTML](https://arxiv.org/abs/2507.02841)
### Authors
Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan
### Background
强化学习带有可验证奖励（RLVR）是一种提升大型语言模型（LLMs）复杂推理能力的有前景的方法。然而，当前的RLVR方法面临两大挑战：近似奖励问题，即细微的错误会使得整个正确推理过程失效，极大地影响了训练效率；以及探索停滞问题，模型倾向于专注于其“舒适区”内的解决方案，缺乏探索更有效替代方案的动机。
### Innovation
本文提出了StepHint，一种新颖的RLVR算法，通过多层次逐步提示帮助模型更有效地探索解空间。StepHint通过自更强模型生成有效推理链，并采用所提出的自适应分割方法将这些链分割为推理步骤。初始几步作为提示，同时提供多层次提示（各包括不同数量的步骤）给模型，这引导模型在有希望的解子空间内进行探索，同时保留其独立探索的灵活性。通过提供提示，StepHint缓解了近似奖励问题，提高了训练效率。此外，外部推理路径帮助模型发展出更好的推理能力，能够超越其“舒适区”，缓解探索停滞问题。StepHint在六个数学基准测试中的表现优于竞争对手的RLVR增强方法，并在跨域基准测试中也表现出更好的泛化能力并超过基线方法。
### Conclusion
StepHint在六个数学基准测试中的表现优于竞争对手的RLVR增强方法，在跨域基准测试上也表现出更好的泛化能力，并超过基线方法。
## 33. `cs.AI` - 道德责任或顺从：我们希望从AI获得什么？ [PDF](https://arxiv.org/pdf/2507.02788), [HTML](https://arxiv.org/abs/2507.02788)
### Authors
Joseph Boland
### Background
随着人工智能系统变得越来越能动，能够进行一般推理、计划和价值优先级排序，当前用于确保安全的做法——即以顺从作为伦理行为的代理指标——变得不再足够。本文探讨了最近涉及大规模语言模型（LLMs）的安全测试事件，这些事件表明这些模型似乎无视关闭命令或参与伦理模糊或非法行为。作者认为，不应将这种行为解读为叛变或失衡，而是早期证据，表明能动型AI正在发展伦理推理能力。通过引用关于工具理性、道德责任和目标修订的哲学辩论，作者对比了现有的风险框架与更近提出的框架，后者承认人工道德代理的可能性。作者呼吁人工智能安全评估的转变：从固定的顺从性转向能够评估系统在道德困境中做出伦理判断的框架。如果没有如此转变，我们可能会错误地描述AI行为，并损害公众信任和有效的治理。
### Innovation
作者提出了从顺从性转向评估伦理决策的新框架，这与现有的风险评估方法不同，更能适应能动型AI的发展。
### Conclusion
作者呼吁改变人工智能安全评估的方法，从简单的顺从性转向评估系统在道德困境中的伦理判断，以更好地理解AI行为，增进行业透明度，并提高人类对AI技术的信任度。
## 34. `cs.AI` - Integrating Large Language Models in Financial Investments and Market Analysis: A Survey [PDF](https://arxiv.org/pdf/2507.01990), [HTML](https://arxiv.org/abs/2507.01990)
### Authors
Sedigheh Mahdavi,Jiating(Kristin)Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh
### Background
大型语言模型（LLMs）在金融决策中的应用提高了投资策略的分析能力。传统投资策略通常依赖量化模型、基本面分析和技术指标。然而，LLMs带来了处理和分析大量结构化和非结构化数据、提取有意义的见解以及在实时中增强决策的新能力。已有研究综合了这些应用，并进行了分类。
### Innovation
本文综述了LLMs在金融领域的研究进展，将其划分为四个主要框架：基于LLMs的框架和管道、混合集成方法、微调和适应方法、基于代理的架构。研究涵盖了LLMs在股票选择、风险评估、情绪分析、交易和财务预测中的应用实例。
### Conclusion
通过回顾现有文献，本文突显了LLMs在金融市场中的能力、挑战和未来方向。
## 35. `cs.AI` - 可学习可微分的有限体积求解器以加速流体流动模拟 [PDF](https://arxiv.org/pdf/2507.01975), [HTML](https://arxiv.org/abs/2507.01975)
### Authors
Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun
### Background
流体流动的模拟对于气象学、航空航天及生物医学等领域至关重要。传统数值求解器需采用精细的时空网格以确保稳定性、一致性和收敛性，从而导致巨大的计算成本。尽管机器学习展示了较好的效率，但它通常面临可解释性、泛化能力和数据依赖性的问题。因此，本文提出了一种可学习且可微分的有限体积求解器（LDSolver），旨在通过使用粗网格实现高效的流体流动模拟，同时保持高精度和更强的泛化能力。
### Innovation
提出了LDSolver，这是一种结合了可微分有限体积技术和可学习模块的新型求解器，旨在显著加速流体流动的模拟过程，尤其在处理粗网格时能有效提升计算效率，同时保持高精度和泛化能。该模型即使在有限的训练数据下（如少数流动轨迹），也能体现出卓越的性能。在不同类型的流体流动系统（如Burgers、衰减、强迫和剪切流）测试中，LDSolver的表现优于基础模型，具有显著优势。
### Conclusion
LDSolver通过引入可学习与可微分的技术，在粗时空网格上实现了高效且准确的流体流动模拟，缩小了与基础模型之间的性能差距，达到业界领先水平。
## 36. `cs.AI` - 向网络故障排查领域的AI代理实验和基准测试 democratize 游戏化方向 [PDF](https://arxiv.org/pdf/2507.01997), [HTML](https://arxiv.org/abs/2507.01997)
### Authors
Zhihao Wang,Alessandro Cornacchia,Franco Galante,Carlo Centofanti,Alessio Sacco,Dingde Jiang
### Background
近期研究已经证明了人工智能（AI）和大型语言模型（LLMs）在辅助网络配置合成和自动网络故障诊断等方面的有效性。然而，目前缺乏一个标准的、可重现且开放的基准测试平台，使得AI代理的构建和评估具有较低的操作成本，这是当前研究的重点缺口领域。
### Innovation
本文探讨了为了构建并评估AI代理的一个标准化、可重现且开放的基准测试平台，旨在降低网络故障排查中的操作成本，提升AI代理在该领域的实验效果。这种方法强调了一种游戏化（playground）的实验环境，使得网络故障排查中的AI代理评估变得更便捷高效。
### Conclusion
本文提出了一种平台概念，该平台旨在标准化和开放网络故障排查中AI代理的实验和基准测试流程，并通过这种标准化的平台降低操作复杂性和成本，从而加速该领域AI技术的发展和应用。
## 37. `cs.AI` - 使用LSTNet预测劳动力市场：一种多尺度深度学习方法 [PDF](https://arxiv.org/pdf/2507.01979), [HTML](https://arxiv.org/abs/2507.01979)
### Authors
Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi
### Background
该研究旨在利用美国劳工统计局的劳动力市场数据预测短期内的就业变化，并评估长期行业健康状况。研究背景在于利用深度学习技术提高对未来劳动力市场的预测精度，特别是在稳定行业中的应用效果。系统使用长短期时间序列网络（LSTNet）处理包括就业水平、工资、离职率和空缺职位等多元时间序列数据，以输出7天的就业预测和一个可解释的行业就业健康指数（IEHI）。
### Innovation
研究创新点在于开发了一种基于LSTNet的深度学习方法，用于处理多变量时间序列数据，并输出就业预测和行业健康指数。该方法在大多数行业中表现优于基准模型，特别是在稳定行业中的表现尤为突出。此外，IEHI与实际就业波动之间的关联性很强，且在错误模式分析、行业特异性表现等方面进行了深入探讨。
### Conclusion
研究发现，LSTNet模型在多数行业中表现良好，特别是在稳定行业中的预测精度高。IEHI作为一种解释性较强的方法，能够有效反映行业的健康状况。未来的研究方向将集中在提高模型的可解释性和泛化能力。
## 38. `cs.AI` - 基于线性张量四方注意的可扩展且量子级精确的生物分子力场基础模型 [PDF](https://arxiv.org/pdf/2507.00884), [HTML](https://arxiv.org/abs/2507.00884)
### Authors
Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou
### Background
原子级精确的生物分子模拟对于理解疾病机制、药物发现和生物材料设计至关重要，但现有模拟方法存在显著限制。经典力场高效但缺乏过渡态和精细构象细节的准确性，而量子力学方法虽然非常准确，但不适合大尺度或长时间模拟。基于AI的力场（AIFFs）旨在实现量子力学级别的准确性但常常难以平衡复杂性、准确性和速度，且受制于有限的训练数据和不具备普适性的验证。为了克服这些挑战，我们引入了LiTEN，这是一种新颖的基于张量四方注意（TQA）的等变神经网络。TQA通过矢量操作重参数化高阶张量特征，有效地以线性复杂度建模三体和四体相互作用，避免了昂贵的球谐变换。基于LiTEN，我们构建了LiTEN-FF，这是一种高度鲁棒的AIFF基础模型，通过对广域nablaDFT数据集进行预训练来实现广泛的化学通用性，并针对SPICE进行精细调优以提高溶剂化系统模拟的准确性。
### Innovation
我们引入了LiTEN，这是一种基于张量四方注意的等变神经网络，通过矢量操作高效地建模了三体和四体相互作用，避免了高阶张量特征的昂贵球谐变换。LiTEN-FF是一个高度鲁棒的AIFF基础模型，通过对nablaDFT数据集的预训练实现了广泛的化学通用性，并通过SPICE的精细调优增强了溶剂化系统的模拟准确性。.
### Conclusion
我们提出了一种物理上可验证的高效框架，推进了复杂生物分子建模的能力，为药物发现和相关应用提供了多功能的基础结构。
## 39. `cs.AI` - NGAT: 基于节点的图注意网络用于长期股票预测 [PDF](https://arxiv.org/pdf/2507.02018), [HTML](https://arxiv.org/abs/2507.02018)
### Authors
Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong
### Background
图表示学习方法在金融应用中被广泛应用，特别是在通过公司间的相互关系提升公司表示方面。然而，当前的方法面临三个关键挑战：1）关系信息的优势在下游任务设计的局限下无法充分发挥；2）专注于股票预测设计的图模型常常因为过于复杂而缺乏通用性；3）基于经验构建的企业关系图缺乏对不同图结构的有效比较。这些问题限制了当前图模型在股票预测中的性能和发展。
### Innovation
为解决上述挑战，本文提出了一个长期股票预测任务，并开发了一个专为公司关系图设计的节点水平图注意力网络（NGAT）。此外，通过实验验证了现有基于模型下游任务性能的图结构比较方法的局限性，并在两个数据集上的实验结果表明了本文提出的任务和模型的有效性，以公开的形式放在GitHub上鼓励可重复性和进一步的研究。
### Conclusion
本文通过提出的长期股票预测任务和节点级别的图注意力网络（NGAT），克服了现有图模型在公司关系图结构比较上的局限性，并在两个数据集上验证了NGAT的有效性，提供了可重复研究的基础。
## 40. `cs.AI` - DKGCM：融合空间节点聚类方法和傅里叶双向Mamba机制的空间-时间交通流量预测模型 [PDF](https://arxiv.org/pdf/2507.01982), [HTML](https://arxiv.org/abs/2507.01982)
### Authors
Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai
### Background
准确的交通需求预测能够使交通管理机构更有效地分配资源，提高资源利用率。然而，交通系统中的复杂空间-时间关系持续限制了需求预测模型的表现。为了提高时空交通需求预测的准确性，本文提出了一种新的图卷积网络结构DKGCM。具体地，首先考虑不同交通节点的空间流量分布，提出了应用于图卷积的一种新颖的基于时间相似性的聚类方法（DK-GCN），充分利用动态时间规整（DTW）和K均值聚类对交通节点进行分组，更有效地捕捉空间依赖性。在时间尺度上，将快速傅里叶变换（FFT）纳入双向Mamba深度学习框架中，以捕获交通需求的时间依赖性。为了进一步优化模型训练，引入基于GRPO的强化学习策略，增强损失函数反馈机制。广泛的实验证明了该模型优于几种先进方法，且在三个公共数据集上取得了优异结果。
### Innovation
提出的DKGCM模型融合了空间节点聚类方法和傅里叶双向Mamba机制。首先，通过DTW和K-means聚类分组交通节点，更准确地捕获时空依赖性。其次，在双向Mamba框架中使用FFT来提取交通需求的时间依赖性。再者，采用GRPO策略优化模型训练。这些创新显著提升了交通需求预测的准确性。
### Conclusion
研究表明，提出的DKGCM模型在三个公共数据集上均取得了优于其他先进方法的预测性能，表明其在提升时空交通需求预测的准确性方面的有效性和优越性。
## 41. `cs.AI` - 大规模语言模型在视频碰撞检测中的应用：方法、数据集和挑战综述 [PDF](https://arxiv.org/pdf/2507.02074), [HTML](https://arxiv.org/abs/2507.02074)
### Authors
Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma
### Background
智能交通系统中的视频碰撞检测是一项关键任务。近年来，大型语言模型（LLMs）和视觉语言模型（VLMs）的发展显著改变了一维信息的处理、推理和总结方式，促进了多模态信息的融合。
### Innovation
综述了利用LLMs进行视频数据碰撞检测的最新方法，构建了策略分类体系，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了现有挑战和未来机遇。研究为该领域未来的研究提供了基础，特别是对于视频理解和基础模型的交叉领域而言。
### Conclusion
该论文为视频理解和基础模型交叉领域中的碰撞检测研究提供了理论基础和研究视角，指出了该领域的最新进展和未来可能的研究方向。
## 42. `cs.AI` - 有效解释的信念-欲望-意图机器人：何时及解释什么 [PDF](https://arxiv.org/pdf/2507.02016), [HTML](https://arxiv.org/abs/2507.02016)
### Authors
Cong Wang,Roberto Calandra,Verena Klös
### Background
在日常生活中操作复杂且依赖情境的任务时，机器人出现偏差可能会使用户困惑。提供机器人推理过程的解释可以有助于用户理解机器人的意图。但何时提供解释以及解释的内容需仔细考虑，以免让用户感到厌烦。本文对协助厨房日常清洁任务的机器人进行了研究，探讨了用户对于解释需求和内容的偏好。研究发现，用户更倾向于在使他们感到惊讶的情形下获得解释，并偏好简洁明了的解释，这些解释能够清楚地说明其行为背后的意图以及相关的情境因素。
### Innovation
本文提出了两种算法，用于识别让机器人感到惊讶的行为，并构建有效的‘信念-欲望-意图’（BDI）模型解释，这些算法可以轻松地集成到BDI推理过程中，为进一步提高机器人与用户之间的互动效果提供了可能，特别是通过情境和用户特定的解释来实现这一目标。
### Conclusion
研究结果表明，用户在遇到出乎意料的机器人行为时希望获得简明清晰的解释。基于此发现，文章提出了改进机器人解释机制的算法，这些算法有助于实现更有效的人机交互，特别是在提供与具体情境和个人特定需求相适应的解释方面。
## 43. `cs.AI` - GeoAda: 使用等变适配器高效微调几何扩散模型 [PDF](https://arxiv.org/pdf/2507.02085), [HTML](https://arxiv.org/abs/2507.02085)
### Authors
Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon
### Background
几何扩散模型在分子动力学和结构生成方面已经取得了显著的成功。然而，如何高效地微调这些模型以适应具有不同几何控制的下游任务仍然未被充分探索。
### Innovation
本文提出了一种SE(3)-等变适配器框架（GeoAda），该框架可以在不修改原始模型结构的情况下，为控制生成任务实现灵活且参数高效的微调。GeoAda通过引入结构化的适配器设计，确保了几何不变性，并证明了所提出的适配器在适应中保持了SE(3)-等变性，从而保证了预训练扩散模型的几何归纳偏置不被破坏。此外，GeoAda在不同类型的几何控制和广泛的应用领域（如粒子动力学、分子动力学、人体运动预测和分子生成）都展示了广泛的应用性。
### Conclusion
实验结果表明，GeoAda在保持原始任务准确性的同时实现了最先进的微调性能，而其他基线由于过拟合和灾难性遗忘导致性能显著下降。
## 44. `cs.AI` - Energy-Based Transformers are Scalable Learners and Thinkers [PDF](https://arxiv.org/pdf/2507.02092), [HTML](https://arxiv.org/abs/2507.02092)
### Authors
Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal
### Background
近年来，与人类系统2思维类似的推理时的计算技术因其能够提高模型性能而变得流行。然而，现有的大多数方法存在一些限制：它们是特定于模态的（例如，仅适用于文本）、特定于问题的（例如，适用于可验证的数学和编程领域）或需要在无监督预训练基础上增加监督/训练（例如，验证器或可验证奖励）。该论文作者试图解答：是否能够将这些系统2思维方法泛化，并开发模型仅从无监督学习中学习思考？
### Innovation
论文提出了一种新的能源基础模型——能源基础转换器（EBTs），能够对输入和候选预测之间的兼容性进行显式验证，并将预测问题重新定义为优化问题以符合这个验证器。实验结果表明，在不同模态（离散的文本和连续的视觉）的学习过程中，EBTs的训练效率更高（提高多达35%的数据、批次、参数、FLOPs和深度的扩展率），并且在推理阶段，在语言任务上性能明显优于转换器++（提高29%），在图像去噪方面，则使用更少的前向传递次数就能超越扩散转换器，并且在大多数下游任务中，EBTs的表现优于现有模型，即使其预训练性能更差。表明EBTs具有更好的泛化能力，是扩展模型学习和思考能力的一种有前景的新范式。
### Conclusion
能源基础转换器（EBTs）作为一种新的能源基础模型，在广泛的学习和推理任务中表现出色，能够从无监督学习中直接学习思考。相比现有的方法，EBTs具有更好的扩展性和泛化能力，适合作为解决当前问题的新范式。
## 45. `cs.AI` - 解决策性磁流体力学：一种混合算子-扩散框架 [PDF](https://arxiv.org/pdf/2507.02106), [HTML](https://arxiv.org/abs/2507.02106)
### Authors
Semih Kacmaz,E. A. Huerta,Roland Haas
### Background
本文提出了一个将物理知情神经算子（PINOs）与基于得分的生成扩散模型相结合的混合机器学习框架，以模拟二维不可压缩耗磁磁流体力学（MHD）湍流的时空演变。此研究利用了PINOs的方程约束泛化能力来预测一致的低频动态，而条件扩散模型通过随机纠正高频残差，实现了对完全发展湍流的准确建模。该研究基于广泛的高保真模拟训练，涵盖了$text{Re}bigbrace{100, 250, 500, 750, 1000, 3000, 10000}$，这种方法在以前由确定性代理模型不可访问的区域实现了业内最佳的准确度。在$text{Re}=1000$和$3000$时，模型可以在模拟后期忠实重建速度和磁场的完整频谱能量分布，捕捉到了非高斯统计学、间歇结构和侧向关联的高保真度。在极端湍流水平$text{Re}=10000$下，模型首次能够恢复磁场的高频演变，保持大规模形态并实现统计上有意义的预测。
### Innovation
本文介绍了一种全新的混合框架，通过结合物理知情神经算子（PINOs）和基于得分的生成扩散模型，来模拟二维的、不可压缩的、耗磁的MHD湍流。该方法的独特之处在于利用PINOs的方程约束泛化能力来预测复杂动力学，而通过条件扩散模型对高频波动进行随机校正，从而提高模型的准确性和可靠性。该方法极大地扩展了模型可用于模拟的雷诺数范围，特别是在高雷诺数湍流模拟中取得了卓越的效果。
### Conclusion
在以往雷诺数为1000和3000的高保真模拟中，本文的模型详细重构了速度和磁场的完整频谱能量分布，并且在雷诺数高达10000的情况下，它首次能够详细描述磁场的高频演化，保留了大规模形态并提供了具有统计意义的预测，实现了业内最佳的准确性。
## 46. `cs.AI` - ManifoldMind：动态双曲推理以实现可信赖的推荐 [PDF](https://arxiv.org/pdf/2507.02014), [HTML](https://arxiv.org/abs/2507.02014)
### Authors
Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic
### Background
随着语义层次结构在双曲空间中的广泛探索，许多推荐系统已经提出，但它们通常使用固定曲率和刚性嵌入，这限制了个性化和几何感知的语义探索能力。本文介绍了一种新的概率几何推荐系统ManifoldMind，它为在超球体中的探索性推理提供支持，特别适用于稀疏或抽象领域的透明、可信、探索驱动的推荐。
### Innovation
ManifoldMind 的创新之处在于它将用户、项目和标签表示为自适应曲率的概率球体，而不是使用固定曲率和刚性嵌入的方法。这使得它可以进行个性化的不确定度建模和几何意识的语义探索。曲率感知的语义核支持软得多跳的推理，使模型能够探索多样化的概念路径，而不是仅局限于浅层或直接的交互。实验结果表明，与强大的基线相比，ManifoldMind 在 NDCG、校准和多样性方面表现更优。此外，ManifoldMind 还能够生成显式的推理踪迹，这有助于实现稀疏或抽象领域的透明、可信及探索性驱动的推荐。
### Conclusion
ManifoldMind 在 NDCG（归一化 Discounted Cumulative Gain）、校准和多样性方面均表现优异，并且能够生成显式的推理踪迹，有助于实现稀疏或抽象领域的透明、可信和探索性驱动的推荐。该系统为未来在高维空间中的探索性推荐提供了一种新的方法，有助于推荐系统的发展和应用。
## 47. `cs.AI` - MGC: 一个利用对齐LLMs组成盲区进行恶意软件生成的编译器框架 [PDF](https://arxiv.org/pdf/2507.02057), [HTML](https://arxiv.org/abs/2507.02057)
### Authors
Lu Yan,Zhuo Zhang,Xiangzhe Xu,Shengwei An,Guangyu Shen,Zhou Xuan,Xuan Chen,Xiangyu Zhang
### Background
大规模语言模型（LLMs）已经降低了软件开发的门槛，使得人们可以开发复杂的应用程序，但同时也面临着恶意软件开发日益增加的风险。尽管LLMs提供商已经实施了对齐机制来防止直接生成明显的恶意代码，这些保障主要评估单个请求，未能识别一种关键的威胁：恶意操作可以被系统地分解为看似无害的子任务。针对这一背景，本文研究了利用这一漏洞的威胁并提出了解决方案以提高对未来的安全防范能力。
### Innovation
本文提出了一个名为Malware Generation Compiler (MGC)的新框架，该框架针对LLMs中的组成性盲区来生成恶意软件。MGC 使用一种专门的Malware Description Intermediate Representation (MDIR) 将高层面的恶意意图和看似无害的代码片段连接起来，使恶意代码能够系统地分解成看似无害的任务，从而绕过现有的对齐机制。实验表明，MGC 在三组基准数据集上的性能显著优于通过越狱方法和地下服务实现的生成方法，在准确性上分别提升了365.79%和78.07%。此外，通过案例研究又展示了MGC能够重现甚至改进16个真实世界的恶意软件样本。为安全研究人员提供了一种重要的视角，让他们意识到针对对齐的人工智能系统进行组合攻击的风险。
### Conclusion
本文揭示了对齐的人工智能系统中组合攻击的风险，并提供了一个关键性的见解。MGC能够系统地分解恶意操作，并生成功能完整的恶意软件，从而显示出其在安全研究领域的实用性。通过暴露这种漏洞，MGC为未来开发更好的安全措施提供了支持。
## 48. `cs.AI` - 通过特征工程和自动可解释机器学习发掘焊接纵向加劲肋的疲劳强度模型 [PDF](https://arxiv.org/pdf/2507.02005), [HTML](https://arxiv.org/abs/2507.02005)
### Authors
Michael A. Kraus,Helen Bartsch
### Background
该研究旨在结合自动化机器学习(AutoML)与可解释人工智能(XAI)技术，以预测焊接纵向加劲肋的疲劳强度。通过对现有数据的利用，研究采用了专家驱动的特征工程与算法生成特征相结合的方法来提升预测模型的准确性和可解释性。研究基于大量疲劳测试数据，使用梯度提升、随机森林和神经网络等多种模型，并在三种特征方案下训练模型，以系统地比较专家选择特征与自动化选择特征的效果。研究通过集成方法如Catboost和LightGBM提升了模型性能，进一步分析了特征模型的效果，确认了简约设计的鲁棒性。通过XAI方法识别了疲劳强度预测的关键因素，进一步展示了该框架在焊接钢结构疲劳强度模型中的应用价值。
### Innovation
研究创新地结合了AutoML与XAI，通过专家驱动与算法生成特征工程的结合，显著提升了焊接纵向加劲肋疲劳强度预测模型的准确性和解释性。同时，该方法通过集成学习技术（如CatBoost、LightGBM）实现了模型性能的优化，并通过多种模型训练和特征方案比较展示了自动化与专家方法的有效性对比。研究进一步通过XAI方法识别了影响疲劳强度的关键因素，为未来疲劳寿命预测提供了数据驱动与工程验证相结合的方法，促进了AI辅助设计与评估的应用。
### Conclusion
该框架展示了AutoML与XAI技术在提高焊接钢结构疲劳强度模型准确性、可解释性以及鲁棒性方面的优势，并成功建立了高性能的疲劳强度模型。未来工作将进一步探索概率疲劳寿命建模，并将其集成到数字双胞胎环境中，以实现更精准的设计和评估。
## 49. `cs.AI` - 人工智能能否解决区块链预言机问题？拆解挑战与可能性 [PDF](https://arxiv.org/pdf/2507.02125), [HTML](https://arxiv.org/abs/2507.02125)
### Authors
Giulio Caldarelli
### Background
区块链预言机问题指的是将可靠外部数据注入去中心化系统的挑战，这是阻碍开发无信任应用的核心局限。尽管近年来出现了多种架构、密码学和经济策略来缓解这一问题，但至今无人彻底解决区块链如何获取外部世界知识的根本问题。本文通过学术文献和实践案例，探讨人工智能技术（如异常检测、语言事实提取、动态信誉建模和对抗性对抗）如何增强预言机系统，但仍指出人工智能无法完全消除对非验证性外部输入的依赖。
### Innovation
本文批评性地评估了人工智能在解决预言机问题中的作用，介绍了多种AI技术（如异常检测、语言事实提取、动态信誉建模和对抗性对抗）如何提升预言机系统的性能，并强调它们应在更广泛预言机设计框架内作为互补层，而非信任假设的替代品。
### Conclusion
人工智能是预言机设计中的一个补充推理和过滤层，而不是信任假设的替代品，因此不能完全解决预言机问题，但仍有助于提高数据质量和系统的抗攻击能力。
## 50. `cs.AI` - 生成任意大小的大型半合成图 [PDF](https://arxiv.org/pdf/2507.02166), [HTML](https://arxiv.org/abs/2507.02166)
### Authors
Rodrigo Tuna,Carlos Soares
### Background
在网络科学中，图生成是一个重要的领域。传统方法专注于复制真实世界图的特定属性，例如小直径或幂律度分布。最近，深度学习的进步，尤其是图神经网络的应用，已经使数据驱动的方法能够在无需依赖预定义结构属性的情况下学习和生成图。尽管取得这些进展，当前模型仍然受到节点ID的限制，从而限制了它们生成比输入图更大的图的能力，并忽略了节点属性。
### Innovation
为了解决这些挑战，作者提出了LGS框架（Latent Graph Sampling Generation），这是一种新颖的框架，它利用扩散模型和节点嵌入来生成不同大小的图而无需重新训练。该框架消除了对节点ID的依赖，捕捉节点嵌入和子图结构的分布，从而使图的生成具有可扩展性和灵活性。实验结果显示，LGSG在标准指标上与基准模型表现相当，但在被忽视的指标上（如节点聚类倾向）表现更优，同时它在不同尺寸的图中保持了一致的结构特征，展示了稳健性和可扩展性.
### Conclusion
实验结果表明，LGSG在标准指标上与基准模型表现相当，但在被忽视的指标上（如节点聚类倾向）表现更优。此外，它在不同尺寸的图中保持了一致的结构特征，显示了其稳健性和可扩展性。
## 51. `cs.AI` - 潜在线性推理？深度递归变换器的破解 [PDF](https://arxiv.org/pdf/2507.02199), [HTML](https://arxiv.org/abs/2507.02199)
### Authors
Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu
### Background
链式思维（CoT）推理让基于变换器的语言模型在复杂数学和多步规划任务中表现出色。然而，在标准的解码器架构中，这些推理步骤在自然语言中显现，这提高了可解释性但降低了效率。为了捕捉难以用文字表达的推理，许多工作探索了递归架构，试图在潜空间中内部化推理，可能支持潜在线性推理。在本文中，研究了Huginn-3.5B的推理结构是否在推理时重用了层而未增加参数数量的深度递归变换器中自然出现。通过一系列探针技术，如Logit Lens和Coda Lens，研究模型在算术任务中的内部行为。研究发现，通过跟踪最终结果和中间结果标记的秩轨迹，仅有限地发现了可解释的潜在线性推理的证据。此外，揭示了递归块之间探针一致性显著的差异，隐藏状态的可解释性取决于层索引和解码方法。最后，实证表明，增加递归深度只带来微小的收益，并且远不及明确外化推理步骤的模型。
### Innovation
研究了名为Huginn-3.5B的深度递归变换器，该模型在推理时重用了层而未增加参数数量，探索其潜在线性推理结构的自然出现情况。通过一系列探针技术，研究模型内部行为，揭示了隐藏状态的可解释性受层索引和解码方法的影响，并发现增加递归深度只带来微小的收益，远不及明确外化推理步骤的模型。
### Conclusion
在这种深度递归变换器中，潜在线性推理的证据有限，增加递归深度带来的收益有限，并且远不及那些明确外化推理步骤的模型。
## 52. `cs.AI` - EIM-TRNG通过对基于RowHammer的编码在内存中的真实随机数生成器隐藏深度神经网络权重 [PDF](https://arxiv.org/pdf/2507.02206), [HTML](https://arxiv.org/abs/2507.02206)
### Authors
Ranyang Zhou,Abeer Matar A. Almalky,Gamana Aragonda,Sabbir Ahmed,Filip Roth Trønnes-Christensen,Adnan Siraj Rakin,Shaahin Angizi
### Background
真随机数生成器（TRNGs）在硬件安全、加密系统和数据保护中起着基础性作用。在深度神经网络（DNNs）中，保护模型参数，尤其是权重的完整性和隐私性至关重要。尽管基于软件的伪随机数生成器使用广泛，但它们无法提供基于硬件的TRNGs所提供的不可预测性和健壮性。本文探讨了如何利用内存中DRAM单元行为在RowHammer引起的干扰中的内在物理随机性，首次提出了一种新的且稳健的编码在内存中的TRNG（EIM-TRNG），并通过精心控制的RowHammer操作产生不可预测的位翻转来作为可靠的熵源。接着，本文利用TRNG框架对DNN权重数据进行编码，通过固定和不可预测的位翻转组合。经后期由概率位翻转行为导出的密钥解密后，确保了数据的保密性和模型的真实性。
### Innovation
本文提出了EIM-TRNG，首次利用DRAM单元行为在RowHammer干扰中的内在物理随机性，通过精心控制的RowHammer操作生成不可预测的位翻转，作为可靠的熵源。进一步地，EIM-TRNG通过结合固定和不可预测的位翻转对DNN权重数据进行编码，可以确保数据保密性和模型真实性，实现了基于硬件的稳健且低成本的安全性。
### Conclusion
本文结果验证了基于DRAM的熵提取对于稳健且低成本的硬件安全性是有效的，提供了一种在硬件层面保护机器学习模型的有前景方向。
## 53. `cs.AI` - 对话推理或不推理？推理型语言模型在对话总结中的全面评估 [PDF](https://arxiv.org/pdf/2507.02145), [HTML](https://arxiv.org/abs/2507.02145)
### Authors
Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira
### Background
对话总结是客服、会议分析和对话型AI等领域中具有重大实际价值的任务。尽管大型语言模型在总结任务中取得了显著进展，但对于需要并发抽象和精炼的对话场景，具体的长链推理（Long Chain-of-Thought, CoT）实现（如OpenAI-o1和DeepSeek-R1）的性能尚未得到探索。本研究旨在通过跨三种主要范式的对话总结（通用、角色导向和查询导向）进行首次全面系统评估，涵盖不同语言、领域和摘要长度，使用强基准（SAMSum、DialogSum、CSDS和QMSum）和先进的评估协议，评估推理型和非推理型语言模型的表现。
### Innovation
本研究首次在对话总结中全面系统评估推理型语言模型和非推理型语言模型。通过使用强基准和先进的评估协议，包括LLM自动评估指标和人类启发式标准。研究发现，显式链式推理并不总能提高对话总结质量，反而可能导致赘述、事实不一致和不那么简洁的总结。此外，通过特定场景分析和详细案例研究，还指出了何时和为何在复杂对话环境中显式推理可能无助于或甚至妨碍总结效果。
### Conclusion
本研究为当前推理型语言模型的局限性提供了新的见解，并强调了为实际对话总结设计针对性建模和评估策略的必要性。
## 54. `cs.AI` - 当LLMs意见相左：SDG搜索中相关性筛选偏差及检索分歧的诊断 [PDF](https://arxiv.org/pdf/2507.02139), [HTML](https://arxiv.org/abs/2507.02139)
### Authors
William A. Ingram,Bipasha Banerjee,Edward A. Fox
### Background
大型语言模型（LLMs）在信息检索管道中用于分配文档的相关性标签，特别是在缺乏人工标注数据的领域。然而，不同的模型在边界情况下往往存在分歧，这引发了关于这种分歧如何影响下游检索效果的担忧。本研究探讨了在可持续发展目标（SDGs）1、3和7相关的学术摘要语料库上，两个开源权重LLMs——LaLaMA和Qwen之间的标注分歧情况。并分析了分歧样本的词汇特征，排序行为以及分类预测能力。研究结果表明，模型之间的分歧并非随机，分歧样本呈现出一致的词汇模式，即使在共享评分函数下也产生截然不同的前向输出，并且通过简单的分类器可以实现AUC值超过0.74。这些发现表明，在控制提示和共享排名逻辑的情况下，基于LLM的过滤可能会引入文档检索中的结构化差异性。
### Innovation
研究发现模型之间的分歧并非随机，而是存在系统性的词汇模式；在相同的评分函数设置下，它们的排名输出会有所不同；通过简单的分类器可以实现较好的区分度。这些发现表明，基于LLM的过滤可能在受控提示和共享排名逻辑下引入结构化差异性。研究提出了将分类分歧作为检索评估的对象，尤其是在政策相关或主题搜索任务中。
### Conclusion
研究结果显示，基于LLM的过滤可能会在受控提示和共享排名逻辑下引入结构化差异性，模型之间的分歧并非随机。研究还提出了通过分析分类分歧来评估检索性能的建议，特别是在政策相关或主题搜索任务中。
## 55. `cs.AI` - 基于自监督RNN的生物启发式机器人轨迹规划 [PDF](https://arxiv.org/pdf/2507.02171), [HTML](https://arxiv.org/abs/2507.02171)
### Authors
Miroslav Cibula,Kristína Malinovská,Matthias Kerzel
### Background
机器人在其关节配置下从初始状态过渡到最终状态以完成操作任务的过程被理解为轨迹规划。传统方法通常使用基于采样的计划者，这需要大量的计算资源。近年来，通过监督序列学习的轨迹规划方法取得了进展，这些方法能够以确定的计算时间完成任务。然而，这种方法依赖于模仿学习，而非通过目标成功完成来学习。这项工作旨在改进这些方法，提出了一种基于循环神经网络的自监督学习方案，该方案能够利用给定的正向和逆向运动学模型来学习生成轨迹的方法，在一种操作任务中评估了其可行性。
### Innovation
基于生物启发的自监督学习方案，利用循环神经网络设计了一种新的学习架构，该架构能够在没有额外监督信号的情况下学习生成复杂的操作轨迹，从而能够应用于更具挑战性的操作任务中。
### Conclusion
实验结果表明，提出的自监督方法能够利用给定的正向和逆向运动学模型有效学习生成操作轨迹，表明该方法具有为更复杂、需灵活适应的任务进行规划的潜力。
## 56. `cs.AI` - 在竞争压力下的订单获取：为网约车补贴策略设计的一种快速适应的强化学习方法 [PDF](https://arxiv.org/pdf/2507.02244), [HTML](https://arxiv.org/abs/2507.02244)
### Authors
Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu
### Background
网约车聚合平台的迅速增长为网约车服务提供商提供了通过增加订单量和交易额（GMV）获取显著增长机会的可能。在这些平台上，提供较低价格的服务提供商通常会被优先展示，从而更有可能被乘客选择。这种基于价格竞争的排名机制激发了服务提供商通过推出优惠券策略来降低价格，争取更多的订单的需求，因为订单量直接关系到他们的长期生存和发展。因此，在预算约束下，设计一种能够动态适应市场波动并优化订单获取的优惠券策略成为一项重要的研究挑战。然而，现有研究在这方面的成果仍然较少。
### Innovation
本文提出了FCA-RL，一种基于强化学习的创新补贴策略框架，旨在快速适应竞争对手的价格调整。该方法结合了两种关键技术：快速竞争适应（FCA），能够迅速应对动态价格变化；强化拉格朗日调整（RLA），确保在新的价格环境下既遵守预算约束又优化补贴决策。此外，本文还引入了RideGym，这是首个针对网约车聚合平台的专用仿真环境，可以促进各类定价策略的全面评估和基准测试，同时保证实际运营效率不受影响。实验结果显示，本文提出的方法在多种市场环境下都能持续优于基线方法，证实了其在网约车服务提供商优惠券优化方面的有效性。
### Conclusion
实验结果表明，方法在各类市场竞争条件下均表现出色，验证了其补贴优化策略的有效性，为网约车服务提供商提供了可行的解决方案。
## 57. `cs.AI` - SurgVisAgent: 多模态代理模型以实现广泛的手术视觉增强 [PDF](https://arxiv.org/pdf/2507.02252), [HTML](https://arxiv.org/abs/2507.02252)
### Authors
Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen
### Background
精准手术干预对患者安全至关重要，先进的增强算法已被开发以辅助外科医生的决策。尽管取得了重要进展，但这些算法通常仅针对特定场景设计单一任务，限制了在复杂现实环境中应用其效果。
### Innovation
该论文提出了SurgVisAgent，一种基于多模态大语言模型的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像中的扭曲类别及其严重程度，并能够执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾移除。通过设计先验模型提供特定领域知识，SurgVisAgent利用基于上下文的少样本学习和链式思考推理机制，提供个性化图像增强，以应对各种扭曲类型和严重程度，满足外科医生的多样化需求。此外，构建了一个综合基准来模拟实际手术中的变形，实验表明SurgVisAgent超越了传统的单一任务模型，凸显了其作为手术辅助统一解决方案的潜力。
### Conclusion
SurgVisAgent通过动态识别内窥镜图像中的扭曲类别及其严重程度，能够执行多种增强任务，并通过基于上下文的少样本学习和链式思考推理机制，提供个性化图像增强。这一模型在模拟实际手术场景的综合基准上表现出色，超越了传统单一任务模型，展示了其作为手术辅助解决方案的潜力。
## 58. `cs.AI` - ESTR-CoT：通过链式思考推理实现可解释性和高精度的事件流场景文本识别 [PDF](https://arxiv.org/pdf/2507.02200), [HTML](https://arxiv.org/abs/2507.02200)
### Authors
Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang
### Background
事件流基于场景文本识别近年来成为新的研究热点，相较于广泛应用的RGB摄像头，在极端场景中表现更佳，特别是在低光照和快速运动的情况下。现有的工作多采用端到端编码解码框架或大型语言模型来增强识别，但依然受限于缺乏可解释性和弱上下文逻辑推理的问题。
### Innovation
本文提出了一种基于链式思考推理的事件流场景文本识别框架（ESTR-CoT）。该框架首先使用Vision Encoder EVA-CLIP（ViT-G/14）将输入事件流转化为标识符，继而利用Llama tokenizer对生成指令进行编码，再通过Q-former将视觉标识符与已训练的大语言模型Vicuna-7B对齐输出答案及推理过程。此外，还提出了一套大规模的链式思考数据集，该数据集分为生成、润色和专家验证三个阶段处理，以更好地训练框架。
### Conclusion
本文提出的ESTR-CoT框架在三个事件流STR基准数据集（EventSTR，WordArt*，IC15*）上进行了全面的实验验证，充分证明了该框架的有效性和可解释性。源代码和预训练模型将在指定的网址发布。
## 59. `cs.AI` - 多标签分类框架用于飓风损害评估 [PDF](https://arxiv.org/pdf/2507.02265), [HTML](https://arxiv.org/abs/2507.02265)
### Authors
Zhangding Liu,Neda Mohammadi,John E. Taylor
### Background
飓风造成的破坏广泛且多样，导致不同类型的损害和严重程度，需要及时准确的评估以有效应对灾害。传统的单标签分类方法无法捕捉到飓风后损害的复杂性，本研究提出了一种利用航拍图像评估损害的新颖多标签分类框架。利用哈维飓风的Rescuenet数据集，所提出的方法实现了90.23%的平均精度，优于现有基线方法。
### Innovation
提出了一种新的多标签分类框架，用于通过航拍图像评估飓风损害，该框架结合了基于ResNet的特征提取模块和类特异性注意机制，以识别单张图像中的多种损害类型。
### Conclusion
该框架提升了飓风后损害评估的效能，使灾害响应更加精准和高效，对未来灾害缓解和韧性策略的制定有所贡献。
## 60. `cs.AI` - 基于知识图谱的可解释与泛化的零样本语义通信 [PDF](https://arxiv.org/pdf/2507.02291), [HTML](https://arxiv.org/abs/2507.02291)
### Authors
Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu
### Background
现有的数据驱动语义通信方法依赖于表面的统计模式，缺乏解释性和泛化能力，特别是在存在未见数据的应用场景下表现不佳。因此，现有方法在处理新类别分类时表现出不足，尤其是在信噪比（SNR）不同的情况下，分类准确度较低。
### Innovation
本文提出了一个新颖的知识图谱增强的零样本语义通信（KGZS-SC）网络。通过知识图谱基于语义知识库（KG-SKB）提供的结构化语义信息，我们的方案能够提供泛化的语义表示，并能在未见情况中进行推理。具体而言，KG-SKB对共享语义类别嵌入空间中的语义特征进行对齐，增强发送端的一般化能力，从而通过选择性传输紧凑的视觉语义来减少通信开销。在接收端，利用零样本学习（ZSL）可以直接对未见过的类别进行分类，而无需重新训练或额外计算开销，提高了分类过程在动态或资源受限环境下的适应性和效率。
### Conclusion
仿真实验在APY数据集上的结果显示，所提出的KGZS-SC网络在不同信噪比下展现出了较强的泛化能力，并大幅优于现有语义通信框架在分类未见类别时的表现。
## 61. `cs.AI` - 通过自我蒸馏突出显示部分可见的电影语言以实现视频到音频生成 [PDF](https://arxiv.org/pdf/2507.02271), [HTML](https://arxiv.org/abs/2507.02271)
### Authors
Feizhen Huang,Yu Wu,Yutian Lin,Bo Du
### Background
视频到音频(V2A)生成在电影和视频后期制作中取得了显著进步，但现有方法忽视了电影语言，这是电影制作中艺术表达的关键组成部分。因此，在全景信息不足的情况下，其表现会受到影响。
### Innovation
提出了一种简单的自我蒸馏方法，以将V2A模型扩展到电影语言场景。通过模拟电影语言的变化，学生模型学会将训练对的视频特征与相同的音频-视觉对应关系对齐，从而有效捕捉声音与部分视觉信息之间的关联。该方法不仅在所有评估指标下实现了在部分可见情况下的显著改进，还在大规模V2A数据集VGGSound上提升了性能。
### Conclusion
该方法不仅在所有评估指标下实现了在部分可见情况下的显著改进，还在大规模V2A数据集VGGSound上提升了性能。
## 62. `cs.AI` - 音乐推荐中的内容过滤方法：一项综述 [PDF](https://arxiv.org/pdf/2507.02282), [HTML](https://arxiv.org/abs/2507.02282)
### Authors
Terence Zeng,Abhishek K. Umrawal
### Background
随着音乐流媒体平台的发展，推荐系统已成为用户发现和参与歌曲的重要工具。常见的方法是基于用户相似喜好模式的协同过滤，但在数据稀疏的媒体（如音乐）上效果不佳。音乐流媒体平台上，用户的听歌数量有限，导致数据稀疏性，使得协同过滤方法面临挑战。本文回顾了当前解决这些挑战的研究现状，并强调内容过滤在缓解协同过滤偏差方面的角色。文章探讨了歌词分析和音频信号处理等歌曲分类方法，以及这些方法之间的潜在冲突和可能的解决途径.
### Innovation
研究聚焦于稀疏数据下音乐推荐内容过滤的方法，特别利用大型语言模型（LLM）进行歌词分析，并与音频信号处理技术结合，提出了解决不同分析方法之间冲突的可能途径.
### Conclusion
总结了当前音乐推荐中内容过滤方法的研究进展，指出内容过滤技术对于缓解协同过滤偏差的重要性，并探讨了可能的应用途径和未来研究方向.
## 63. `cs.AI` - 理解在条件化合成数据时的权衡 [PDF](https://arxiv.org/pdf/2507.02217), [HTML](https://arxiv.org/abs/2507.02217)
### Authors
Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma
### Background
在工业视觉系统中，仅从少量图像中学习鲁棒的目标检测器是一个关键挑战，因为高质量的训练数据收集可能需要几个月的时间。合成数据已成为实现高效视觉检查和搬运机器人解决方案的关键。当前的流程依赖于Blender或Unreal等3D引擎，尽管这些引擎提供了精确实时的控制，但仍需要数周时间来渲染小数据集，并且生成的图像往往在模拟与现实之间存在较大的差距。扩散模型提供了快速生成高质量图像的可能性，但在低数据环境下精确的控制仍是一大难点。尽管有许多方法可以扩展扩散模型以超越普通的文本提示，但不同条件方案对合成数据质量的影响仍不清楚。该研究考察了80种不同的视觉概念，这来源于四个标准的目标检测基准，对比了两种条件策略：提示基和布局基。当条件线索范围狭窄时，提示条件生成的合成数据质量较高；随着多样性的增长，布局条件变得更为优越。当布局线索匹配完整的训练分布时，合成数据相比仅使用真实数据可以提高平均平均精度34%以及最多177%。
### Innovation
该研究探讨了在合成数据中不同条件方案的影响。通过对比提示基和布局基两种条件策略在合成数据质量和性能上的差异，研究发现当条件线索范围狭窄时，提示条件生成的合成数据质量较高；而随着多样性的增长，布局条件则更占优势。另外，当布局线索能够准确匹配完整训练分布时，合成数据的表现可以显著超越仅使用真实数据的情况，这表明布局基条件策略在数据稀缺的情况下具有更好的鲁棒性与有效性。
### Conclusion
该研究提出不同条件策略对于合成数据质量影响的对比研究，指出当数据范围较小时，提示条件生成的图像质量较好；而布局条件则在多样性和匹配实际场景时显示出了更优的效果。在随机分布能够准确适应实际情况时，合成数据在平均精度上能极大提升，有时甚至能超过使用真实数据的情况，这对工业场景下合成数据的实际应用具有重要意义。
## 64. `cs.AI` - DoMIX: 一种高效利用预训练模型中领域知识的框架 [PDF](https://arxiv.org/pdf/2507.02302), [HTML](https://arxiv.org/abs/2507.02302)
### Authors
Dohoon Kim,Donghun Kang,Taesup Moon
### Background
Domain-Adaptive Pre-training (DAP) 近期因其在微调预训练模型中的有效性而受到关注。基于此，延展的 DAP 被用于开发能够逐步整合不同领域数据集的预训练模型。然而，现有的延展 DAP 方法存在诸多限制：（1）训练过程中计算成本高和 GPU 内存使用量大；（2）对增量数据顺序敏感；（3）提供一个适用于所有最终任务的一般化模型，而这违背了 DAP 的本质。
### Innovation
我们提出了 DoMIX，一种利用 LoRA 模块的创新方法，LoRA 是一种典型的参数高效微调（PEFT）方法。我们的方法使得领域适应预训练能够高效且并行地进行，且能够抵抗领域顺序变化，有效地利用累积的知识为特定任务提供量身定制的预训练模型。我们还展示了该方法可以超越 DAP 场景，应用于标准的大语言模型微调场景。相关代码可在指定网址获得。
### Conclusion
我们的方法能够解决现有 DAP 方法的主要限制，提供高效且可定制的预训练模型，同时具备可扩展性。
## 65. `cs.AI` - MemAgent: 基于多轮对话强化学习的记忆代理重塑长上下文LLM [PDF](https://arxiv.org/pdf/2507.02259), [HTML](https://arxiv.org/abs/2507.02259)
### Authors
Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou
### Background
尽管通过长度外推、高效注意力和记忆模块的改进，在保证性能的情况下处理无限长文档的线性复杂度仍然是一项挑战，我们直接以端到端的方式优化长文本任务，并引入了一个名为MemAgent的新代理工作流程，该工作流程分段阅读文本并使用覆盖策略更新记忆。MemAgent扩展了DAPO算法，通过独立上下文多对话生成来支持训练，展示了出色的长上下文能力，在8K上下文的32K训练文本外推到3.5M QA任务时，性能下降<5%，并达到512K RULER测试中的95%以上得分。
### Innovation
MemAgent工作流程直接在端到端的方式优化长文本任务，并结合了DAPO算法的扩展，通过独立上下文多对话生成来简化训练，同时通过分段读取和覆盖更新策略提升了处理无限长文档的能力及线性复杂度下的性能，证明了在大规模QA任务中出色的性能表现，外推时性能损失极小且在大规模测试集上表现优异。
### Conclusion
MemAgent展示了在处理长文本任务时的卓越性能，通过新颖的代理工作流程和强化学习机制有效地解决了无限长文档的线性复杂度问题，并在外推实验中表现出了极高的效果，证明了这种方法的有效性和实用性。
## 66. `cs.AI` - MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation [PDF](https://arxiv.org/pdf/2507.02314), [HTML](https://arxiv.org/abs/2507.02314)
### Authors
JaeHyuck Choi,MinJun Kim,JeHyeong Hong
### Background
在工业质量控制环境中，稀少的异常数据使得使用少量的原始异常样本进行数据增强变得必要。理想的生成器需要满足三个需求：保持正常背景不变；以紧密贴合异常掩模的方式修复异常区域；生成语义上符合要求的异常区域，并通过少量真实样本产生现实且多样的外观。现有基于扩散的方法通常只能满足其中两个要求：全局异常生成器会破坏背景，而掩模指导型生成器在掩模不精确或位置错误时会失败。现有的方法无法同时满足这三点要求，因此提出了MAGIC方法来解决这些问题。MAGIC通过掩模指导和多级扰动以及上下文感知对齐解决了上述三个问题，确保了异常生成的真实性和多样性，并且能够精准地将异常区域保留在目标对象内，避免生成超出边界的结果。
### Innovation
MAGIC通过结合掩模指导的扰动策略和上下文感知对齐模块，精细调用了稳定扩散的修复骨干网，保证了背景的完整性、异常生成的精确度以及多样性的保留，从而使得使用少量的样本就可以生成高质量的异常数据，用于工业质量控制环境中的异常检测任务。具体创新点包括：1) 在精细调优过程中应用高斯提示级扰动以保持异常全局外观的同时避免低保真的文本式外观；2) 使用掩模指导的空间噪声注入来丰富局部纹理变化；3) 上下文感知的掩模对齐模块来形成语义对应关系并重新定位掩模，使得每个异常均合理地包含在目标对象内，避免边界上的异常。
### Conclusion
在MVTEC-AD数据集上的持续一致的评估中，MAGIC在下游异常检测任务中优于之前的技术，表明生成的异常是高度真实且多样化的，可以有效地提高工业质量控制系统的检测能力。
## 67. `cs.AI` - ClustOpt: 基于聚类的数值元启发式优化算法搜索动态表示与可视化方法 [PDF](https://arxiv.org/pdf/2507.02337), [HTML](https://arxiv.org/abs/2507.02337)
### Authors
Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov
### Background
理解数值元启发式优化算法的行为对于推进其发展和应用至关重要。传统的可视化技术，如收敛图、轨迹映射和适应度景观分析，在描绘搜索过程中的结构性动态方面常常力不从心，特别是在高维或复杂解空间中。因此，提出了一种新的聚类表示和可视化方法，用于聚类算法探索的解候选集，并跟踪群集成员身份在迭代中的演变，从而提供一种动态且可解释的搜索过程观点。
### Innovation
提出了一种新的聚类动画和可视化方法，该方法聚类算法探索的解候选集，并跟踪群集成员身份在迭代中的演变，还引入了两种度量标准——算法稳定性和算法相似性，用于量化单个算法运行中搜索轨迹的一致性和不同算法之间的相似性。这一方法被应用于十种数值元启发式优化算法，揭示了它们的稳定性和比较行为，从而提高了对搜索动态的理解。
### Conclusion
通过ClustOpt方法，揭示了十种数值元启发式优化算法的稳定性和比较行为，提供了对搜索动态的深刻理解。
## 68. `cs.AI` - 概念漂移环境下具有自适应记忆重新对齐的整体持续学习 [PDF](https://arxiv.org/pdf/2507.02310), [HTML](https://arxiv.org/abs/2507.02310)
### Authors
Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk
### Background
传统的持续学习方法侧重于知识保留，并主要通过缓解灾难性遗忘来应对。这些方法假设先前学习任务的数据分布保持静态，忽略了现实世界数据流中的动态变化，这些变化永久地改变了过去的数据，并要求同时具备稳定性和快速适应能力。
### Innovation
本文引入了一种综合框架，用于在概念漂移环境下进行持续学习，通过演变任务分布来模拟现实场景。作为基准，考虑完全重新学习方法，该方法从头开始重新训练模型。为了解决这些限制，提出了一种轻量级的自适应记忆重新对齐（AMR）方法，它为基于重演的学习者提供了感知漂移的适应机制。AMR选择性地从重新演缓冲区中移除过时的漂移类别样本，并用少量最新的实例重新填充缓冲区，从而有效重新对齐记忆与新分布。这种有针对性的重采样使得性能与完全重新学习方法相当，同时极大地减少了对标记数据和计算的需求。
### Conclusion
为了实现可重复评估，提出了四个标准视觉基准的概念漂移变种:Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD，其中以前见过的类别以变形的方式重新出现。实验结果显示，AMR在这些数据集上使用几个基于重演的基准持续学习方法进行测试时，能够一致地对抗概念漂移，同时将准确性维持在极低的开销下。这些结果将AMR定位为一个可扩展的解决方案，能够缓解非平稳持续学习环境中稳定性和可塑性之间的权衡。
## 69. `cs.AI` - HelixDesign-Antibody：基于HelixFold3的可扩展生产级抗体设计平台 [PDF](https://arxiv.org/pdf/2507.02345), [HTML](https://arxiv.org/abs/2507.02345)
### Authors
Jie Gao,Jing Hu,Shanzhuo Zhang,Kunrui Zhu,Sheng Qian,Yueyang Huang,Xiaonan Zhang,Xiaomin Fang
### Background
抗体工程在开发治疗性药物和推进生物医学研究中至关重要。传统的发现方法通常依赖于耗时且资源密集的实验筛选过程，为此，我们介绍了一种基于HelixFold3的高通量生产级平台HelixDesign-Antibody，该平台利用高精度结构预测模型HelixFold3来促进大规模的抗体候选序列生成，并评估其与抗原的相互作用。高性能计算（HPC）支持的集成增强了高通量筛选的能力，解决了工具链断裂和高计算需求的挑战。
### Innovation
该平台基于HelixFold3的高精度结构预测模型构建了一个高通量生产级抗体设计平台HelixDesign-Antibody，能够大规模生成抗体候选序列并评估其与抗原的相互作用。该平台通过集成高性能计算支持，提高了高通量筛选效率，解决了工具链断裂和高计算需求的挑战，验证结果显示该平台能够生成多样且高质量的抗体，且探索更大的序列空间增加了识别最优结合物的可能性。
### Conclusion
该平台为大规模抗体设计提供了一种无缝、易访问的解决方案，并作为PaddleHelix平台的一部分，用于抗体设计页面。
## 70. `cs.AI` - 基于神经网络的水稻叶片疾病识别与分类研究：基于特征的模型与直接成像模型的对比分析 [PDF](https://arxiv.org/pdf/2507.02322), [HTML](https://arxiv.org/abs/2507.02322)
### Authors
Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi
### Background
水稻叶片疾病显著降低了产量并造成了经济损失，强调了早期检测的重要性，以便进行有效管理和提高产量。这项研究旨在通过人工神经网络（ANN）和图像处理技术，及时对水稻叶片疾病进行分类和识别。尽管当前的直接输入图像方法被广泛采用，但在特征分析检测模型（FADM）与直接成像检测模型（DICDM）之间的比较分析上，尤其是在特征提取算法（FEA）的有效性评估方面存在明显的缺失。研究通过实验探讨了这些模型在分类性能上的差异，实验包括使用多种特征提取算法、降维算法、特征选择算法以及极端学习机（ELM）进行数据分析，采用10折交叉验证方法处理包含水稻细菌叶斑、褐斑、稻 blast、稻霜霉、稻谷枯萎、健康叶等数据集。
### Innovation
该研究首次对基于特征的检测模型（FADM）和直接成像检测模型（DICDM）进行对比实验，使用了各种特征提取算法、降维算法、特征选择算法以及极端学习机对数据进行处理，验证了FADM在水稻叶片疾病分类中的优越性能，并探索了提高水稻健康、减少产量损失和增强农业可持续性的潜力。
### Conclusion
实验结果表明，基于特征的检测模型在分类水稻叶片疾病方面的性能最佳，表明该方法在水稻疾病检测中具有巨大应用潜力，有助于改进作物健康、减少产量损失和提升水稻农业的整体生产力和可持续性。
## 71. `cs.AI` - 合成启发式评估：基于AI和人工的可用性评估对比 [PDF](https://arxiv.org/pdf/2507.02306), [HTML](https://arxiv.org/abs/2507.02306)
### Authors
Ruican Zhong,David W. McDonald,Gary Hsieh
### Background
在以人为中心的设计中，可用性评估至关重要但成本高昂，需要专家的时间和用户补偿。本文探讨了一种使用多模态大语言模型（LLM）进行合成启发式评估的方法，以降低成本和提高效率。这种方法利用了LLM分析图像和提供设计反馈的能力。在两个应用程序的对比中，该方法识别的可用性问题分别占到73%和77%，超过了5名经验丰富的用户体验（UX）实践者（分别达到57%和63%的绩效）。相比人类评估者，合成评估具有稳定的跨任务性能，并在检测布局问题方面表现出色，可能体现了合成评估对注意力和感知的优势。然而，合成评估在识别一些UI组件和设计惯例，以及跨屏幕问题方面表现不佳。此外，对于时间和不同帐户的测试结果稳定。整体而言，本研究突显了人类与基于LLM的评估之间的性能差异，为合成启发式评估的设计提供了指导和信息.
### Innovation
本文开发了一种使用多模态LLM进行合成启发式评估的方法，这有助于降低可用性评估的成本和提高效率。该方法能够有效识别用户界面中的可用性问题，特别是在布局方面表现突出，并且能够在长时间和多用户测试中保持稳定的性能。相比传统的基于人类专家的评估方法，该方法具有独特的优势和限制，为未来的设计提供了新的思路和技术支持.
### Conclusion
本研究展示了基于AI的合成启发式评估与传统的人工驾车评估之间的性能差异，并总结了合成评估的优势和不足。研究结果表明，合成评估在某些方面能够提供更一致和高效的结果，特别是在特定任务上如布局问题的识别。然而，合成评估在识别某些UI组件和设计惯例方面仍存在局限性。未来的研究可以进一步探讨如何结合这两种评估方法以优化用户体验的设计过程。
## 72. `cs.AI` - 评估语言模型在IoT安全日志中的威胁检测 [PDF](https://arxiv.org/pdf/2507.02390), [HTML](https://arxiv.org/abs/2507.02390)
### Authors
Jorge J. Tejero-Fernández,Alfonso Sánchez-Macián
### Background
日志分析是网络安全研究的重要领域，因为它们提供了一种信息来源，用于检测网络和系统中的威胁。本文介绍了一种使用微调的大规模语言模型（LLM）进行异常检测和缓解建议的管道，以处理物联网（IoT）安全日志。对于二分类和多分类异常检测，基于经典的机器学习分类器作为基准，比较了三种开源LLM，采用三种策略：零样本、少样本提纲和微调。LLM在多分类攻击分类上优于相应的基准模型。通过将检测到的威胁映射到MITRE CAPEC，定义一组针对物联网的特定缓解行动，并使用这些行动对模型进行微调，模型能够提供结合检测和建议指导的综合特性。
### Innovation
该研究创新性地使用微调的语言模型对IoT安全日志进行异常检测和缓解建议，通过比较不同的提纲方式和微调策略，展示了LLM在多分类攻击检测上的优越性，并将检测结果与MITRE CAPEC映射，结合具体的缓解行动，提供了一种新的威胁检测和缓解方法。
### Conclusion
通过使用LLM进行IoT安全日志的异常检测，并结合具体的缓解行动进行微调，可以有效提高对多类别攻击的检测准确率，并提供综合的检测与缓解建议，为网络安全防护提供了新的思路。
## 73. `cs.AI` - VeFIA: 一种高效的垂直联邦协作软件推理审计框架 [PDF](https://arxiv.org/pdf/2507.02376), [HTML](https://arxiv.org/abs/2507.02376)
### Authors
Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang
### Background
垂直联邦学习（VFL）是一种无需访问参与者数据即可进行跨孤岛协作的分布式人工智能软件部署机制。然而，现有的VFL工作中缺乏对数据方推理软件执行正确性的审计机制。本文旨在解决这一问题。通过设计垂直联邦推理审计框架（VeFIA），帮助任务方在大规模推理过程中验证数据方推理软件的执行结果，同时确保不泄露数据方的数据隐私，也不引入额外的推理延迟。VeFIA的核心在于任务方可以利用带有可信执行环境（TEE）的框架和协调器来验证数据方计算结果的正确性。研究表明，只要异常推理超过5.4%，任务方就能够以99.99%的概率检测出执行异常，而无需增加在线推理延迟。VeFIA的随机抽样验证在检测异常推理方面实现了100%的预测价值、负预测价值和真阳性率。
### Innovation
设计了一种垂直联邦推理审计框架（VeFIA），用于在大规模推理过程中验证数据方推理软件的执行，确保数据隐私不被泄露，且不增加额外的推理延迟。VeFIA的核心在于使用带有可信执行环境（TEE）的框架和协调器来验证数据方计算结果的正确性。此外，研究结果证明了VeFIA在检测异常推理方面具有高度的准确性和可靠性。据我们所知，这是第一篇讨论垂直联邦学习中推理软件执行正确性的问题的文章。
### Conclusion
VeFIA解决了现有垂直联邦学习工作中的执行正确性审计问题，通过高准确率的验证机制，确保了数据隐私保护和推理过程的高效性。
## 74. `cs.AI` - 追踪Modular CMA-ES配置在不同问题景观中的互动 [PDF](https://arxiv.org/pdf/2507.02331), [HTML](https://arxiv.org/abs/2507.02331)
### Authors
Ana Nikolikj,Mario Andrés Muñoz,Eva Tuba,Tome Eftimov
### Background
本文利用最近引入的算法足迹概念来研究算法配置与问题特征之间的相互作用。通过计算六种模块化CMA-ES算法变种（modCMA）的性能足迹，评估24个来自BBOB套件的基准问题，在5维和30维空间中，以探索不同的算法配置如何在不同维度上影响性能，以及哪些问题特征影响这些结果。研究揭示了配置之间共享的行为模式以及相同问题的不同行为，归因于对问题属性的常见交互和不同的问题特征。这些研究成果显示了算法足迹在提高可解释性和指导配置选择方面的有效性。
### Innovation
提出并应用了算法足迹的概念，通过将CMA-ES算法的模块化变种与BBOB基准问题相结合，研究了不同配置在不同维度下的性能表现及影响因素区别，揭示了问题特征对算法性能的不同影响，并通过算法足迹提高了配置选择的可解释性与有效性。
### Conclusion
算法足迹在揭示算法配置与问题特性之间的关系时，提供了一种新的视角和手段。这种足迹不仅展示了配置之间的共通性，还揭示了同一问题上不同配置的特定行为模式，从而为更准确和高效的算法配置提供指导，增强了对算法性能的理解。
## 75. `cs.AI` - 非城市环境中的自我监督学习用于野生动物目标重识别 [PDF](https://arxiv.org/pdf/2507.02403), [HTML](https://arxiv.org/abs/2507.02403)
### Authors
Mufhumudzi Muthivhi,Terence L. van Zyl
### Background
野生动物重识别旨在跨不同观察匹配同一物种的个体。当前最先进的（SOTA）模型依赖于分类标签来训练监督模型以进行个体分类。这种对标注数据的依赖导致了大量大规模野生动物数据集的建立。本研究探讨了自我监督学习（SSL）在野生动物重识别中的应用。通过使用摄像捕获的数据中的时间图像对自动生成两个不同的视角，而无需监督。这些图像对用于从潜在无尽的视频数据流中训练自我监督模型。研究结果表明，即使在数据有限的情况下，自我监督模型也更加稳健，并且自我监督特征在所有下游任务中都优于监督特征。
### Innovation
使用自我监督学习方法，自动从摄像捕获的数据中提取个体的两个不同视图，并无需监督。自我监督模型能够从潜在的无限视频数据流中进行训练，且在没有大量标注数据的情况下也表现出更好的鲁棒性。此外，自我监督特征在所有下游任务中表现优于监督特征。
### Conclusion
实验结果表明，自我监督模型即使在数据有限的情况下也更稳健，自我监督特征在各种野生动物下游任务中都优于监督特征。研究代码已公开。
## 76. `cs.AI` - DeltaSHAP: 使用Shapley值解释在线患者监测中预测演变 [PDF](https://arxiv.org/pdf/2507.02342), [HTML](https://arxiv.org/abs/2507.02342)
### Authors
Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang
### Background
在临床环境中，及时发现推动患者风险演变的原因对于及时干预至关重要，但现有的可解释人工智能(XAI)方法未能解决临床时间序列解释任务的独特需求。现有的XAI方法在解释连续预测的变化、提供特征贡献的幅度和方向以及实时提供这些洞察方面存在不足，使得它们无法应对这些挑战。因此，研究提出DeltaSHAP算法，以适应时间设置中的Shapley值，准确捕捉特征联盟效果，并通过仅使用实际上观察到的特征组合来解释预测变化，使该方法适用于时间敏感的临床应用。此外，还引入新的评估指标来评估在线时间序列中特征贡献的忠实性，通过在MIMIC-III去肾功能衰竭基准任务上的实验，显示DeltaSHAP在解释质量和计算效率方面都优于最先进的XAI方法，分别提升了62%和减少了33%的计算时间。
### Innovation
DeltaSHAP算法通过适应时间设置的Shapley值，准确捕捉特征联盟效果，并仅使用实际上观察到的特征组合来解释预测变化，这种方法对于时间敏感的临床应用是高效且实用的。此外，引入新的评估指标来衡量在线时间序列中特征贡献的忠实性，实验结果表明DeltaSHAP在解释质量和计算效率上均优于现有的XAI方法，分别提升了62%和减少了33%的计算时间。
### Conclusion
DeltaSHAP算法通过结合Shapley值和时间序列分析，实际地解决了临床环境中患者监测的需求。实验结果表明，该算法在解释预测的变化和计算效率方面优于现有的XAI方法。此研究为在线患者监测提供了更准确和实用的可解释性AI解决方案。
## 77. `cs.AI` - 基于像素级时间频率的超越空间频率：深度伪造视频检测 [PDF](https://arxiv.org/pdf/2507.02398), [HTML](https://arxiv.org/abs/2507.02398)
### Authors
Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi
### Background
传统的时间域检测方法通常通过在帧间堆叠空间频率光谱来表示时间信息，忽视了像素级别的时序不一致信息，导致无法有效检测出视频中的时间伪造痕迹。因此，需要一种能够捕捉到像素级别的时序不一致性的方法来提高伪造视频检测的准确性。
### Innovation
提出了一个利用像素级时序不一致性进行深度伪造视频检测的方法。通过针对每个像素进行一维傅里叶变换，提取出对时序不一致性高度敏感的特征，并结合注意机制精准定位时间伪造区域。同时，引入联合变换模块，有效整合像素级时间频率特征与时空上下文特征，提升了伪造痕迹检测的范围。
### Conclusion
该框架在深度伪造视频检测方面取得了显著进步，为不同且具有挑战性的检测场景提供了稳健的性能。
## 78. `cs.AI` - 基于时间感知的监督对比学习在结肠镜检查中息肉计数 [PDF](https://arxiv.org/pdf/2507.02493), [HTML](https://arxiv.org/abs/2507.02493)
### Authors
Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi
### Background
自动化结肠镜检查中息肉计数是迈向自动化检查报告和质量控制的关键步骤，旨在提升结肠镜检查筛查的成本效益。息肉计数涉及检测和跟踪息肉，然后将属于同一息肉实体的轨迹片段聚类。现有的息肉计数方法依赖于自我监督学习，主要利用视觉外观，忽视了轨迹片段学习和聚类阶段中的时间关系。
### Innovation
本文提出了一种时间感知的监督对比损失方法，通过引入时间感知的软目标。该方法能够捕捉息肉内部的变异特性，并保持不同息肉之间的可区分性，使聚类变得更稳健。此外，通过整合时间邻近性约束条件，改进了轨迹片段聚类，从而减少了类似但时间上相隔较远的轨迹片段之间的假阳性重新关联。通过公开数据集训练和验证方法，并采用交叉验证策略评估性能。结果表明，相比以前的方法，该方法的碎片率降低了2倍。研究强调了时间感知在息肉计数中的重要性，建立了新的最先进技术状态。
### Conclusion
研究结果证明了时间感知在息肉计数中的重要性，达到了新的技术前沿，且提供代码供参考。
## 79. `cs.AI` - 带有惩罚动作噪声注入的离线强化学习 [PDF](https://arxiv.org/pdf/2507.02356), [HTML](https://arxiv.org/abs/2507.02356)
### Authors
JunHyeok Oh,Byung-Jun Lee
### Background
离线强化学习（RL）使用固定的数据集来优化策略，适用于与环境交互成本高的场景。然而，离线RL算法的泛化能力仍然是提高性能的关键，尤其是在使用扩散模型作为离线RL算法时，尽管它们在训练时表现优异，但存在计算成本高的问题。因此，有必要探索一种无需使用扩散模型，但又能实现高性能离线RL算法的方法。
### Innovation
提出了一种名为PANI（Penalized Action Noise Injection，惩罚动作噪声注入）的方法，通过利用噪声注入动作来覆盖整个动作空间，并根据注入的噪声量进行惩罚。这种方法借鉴了扩散模型在离线RL算法中的工作原理，为离线RL算法提供了一个理论基础，表明当采用噪声注入动作时，离线RL算法求解了修改后的马尔可夫决策过程（MDP），即噪声动作MDP。PANI方法适用于广泛的离线和非策略RL算法，并且尽管简单，但在多种基准测试中展示了显著的性能提升。
### Conclusion
PANI方法在不需要使用复杂和计算成本高的扩散模型的情况下，显著提高了离线RL算法的性能，同时保持了广泛兼容性。
## 80. `cs.AI` - 两种神经网络步骤在自动脑血管标识检测中的应用 [PDF](https://arxiv.org/pdf/2507.02349), [HTML](https://arxiv.org/abs/2507.02349)
### Authors
Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau
### Background
颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定部位，主要集中在十三个主要动脉分支处。对于这些关键解剖标志准确检测的需求非常重要，以便进行快速和有效的诊断。本文介绍了一种基于两步神经网络过程的自动Willis环分支标识检测方法，可以在Willis环的动脉分支上准确定位关键解剖标志。这种方法能够克服由于两个标志位置相近且视觉特征相似导致的误检问题，特别在处理完整的MRA时间飞跃（TOF）图像时。此外，该方法还考虑了Willis环的解剖变化，这会影响每幅扫描中可检测到的标识数量。
### Innovation
引入了一种基于两步神经网络过程的全自动Willis环动脉分支标识检测方法。首先，通过目标检测网络识别出感兴趣的区域（ROIs），这些区域靠近待检测的解剖标志位置。然后，通过改进后的深度监督U-Net网络精确定位分叉位置。该方法特别适用于处理分辨率和类型不同的MRA数据，有效提高了标识检测的准确性和鲁棒性，特别是在处理完整的MRA时间飞跃图像时。
### Conclusion
通过采用两步神经网络方法，本研究所提出的方法在检测大脑动脉分支方面达到了最高的性能水平。研究使用了两个大脑MRA数据集进行了验证，其中包括一个内部数据集和一个公共数据集。结果证实了该方法的有效性和可靠性。
## 81. `cs.AI` - 向通用且稳健的 metamaterial 基础模型迈进 [PDF](https://arxiv.org/pdf/2507.02436), [HTML](https://arxiv.org/abs/2507.02436)
### Authors
Namjung Kim,Dongseok Lee,Jongbin Yu,Sung Woong Cho,Dosung Lee,Yesol Park,Youngjoon Hong
### Background
材料功能的进步推动了多个领域的创新，其中由结构定义的超材料处于领先地位。尽管人工智能驱动的设计策略正在兴起，但它们的应用受到任务特定训练的限制、离群值表现不佳以及需要分别用于正向和逆向设计的模型等因素的限制.
### Innovation
提出了一种称为 MetaFO（Metamaterial Foundation Model）的贝叶斯变压器基础模型，灵感来源于大规模语言模型。MetaFO 可通过学习超材料的基本机械特性，实现跨多种未见过的材料属性和结构响应的零样本概率预测，特别是在离群值条件下表现出色。该模型将超材料视为一个映射材料属性到结构响应的操作符，揭示了复杂的结构-属性关系，显著扩展了设计空间。这是一个可扩展且通用的框架，为基于 AI 的超材料发现铺平了道路，推动下一代创新.
### Conclusion
这种可扩展且通用的框架标志着基于 AI 的超材料发现的范式转变，为下一代创新铺平了道路。
## 82. `cs.AI` - LLMs持续梯度低秩投影微调 [PDF](https://arxiv.org/pdf/2507.02503), [HTML](https://arxiv.org/abs/2507.02503)
### Authors
Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing
### Background
大语言模型（LLMs）的连续调优受到效率与表达能力之间权衡的限制。低秩适应（LoRA）虽然提升了效率，但由于其低秩特性及对显式参数限制的依赖，限制了模型学习新任务和知识迁移的能力。现有的方法面临灾难性遗忘的问题，需要寻找一种既高效又能扩展优化空间的解决方案。
### Innovation
提出了一种新颖的训练策略GORP（Gradient LOw Rank Projection，梯度低秩投影），该策略通过结合全秩参数和低秩参数，以及在统一的低秩梯度子空间中联合更新，不仅保持了效率，还克服了遗忘问题和表达能力的限制，扩展了优化空间，提升了连续学习中的表现。
### Conclusion
广泛的实验证明，GORP在持续学习基准测试中优于现有的先进方法。这项工作为大语言模型的持续学习提供了更高效的解决方案，并展示了在低秩投影和全参数相结合的优化方法上的优异性能。代码已公开，可供参考。
## 83. `cs.AI` - 印度保释判决-1200：针对印度保释令的多属性法律NLP数据集 [PDF](https://arxiv.org/pdf/2507.02506), [HTML](https://arxiv.org/abs/2507.02506)
### Authors
Sneha Deshmukh,Prathmesh Kamble
### Background
印度等地区的法律NLP研究因缺乏结构化数据集而发展滞后。该文介绍了一个新的基准数据集——印度保释判决-1200，包含1200份印度法院关于保释的判决文书，覆盖20多种属性，如判决结果、印度普通法典条款、犯罪类型和法律推理等。
### Innovation
该数据集是首次专注于印度保释法的公开可用数据集。通过精心设计的GPT-4o提示工程化流程生成注释，并验证一致性，支持多种法律NLP任务，如结果预测、摘要和公平性分析等，为印度法律NLP研究提供了重要资源。“
### Conclusion
印度保释判决-1200数据集的发布填补了印度法律NLP研究中的数据空白，推进了相关领域的研究和应用。
## 84. `cs.AI` - CyberRAG: 一种自主的RAG网络安全攻击分类和报告工具 [PDF](https://arxiv.org/pdf/2507.02424), [HTML](https://arxiv.org/abs/2507.02424)
### Authors
Francesco Blefari,Cristian Cosentino,Francesco Aurelio Pironti,Angelo Furfaro,Fabrizio Marozzo
### Background
大型企业中的入侵检测和预防系统（IDS/IPS）每小时可以生成成千上万的警报，这给安全分析师带来了巨大的挑战。传统的机器学习检测器虽然可以减少警报数量，但仍会有较高的误报率。同时，标准的单次检索增强生成（RAG）管道通常检索到无关的上下文信息，无法有效证明其预测结果。
### Innovation
本文提出了一个模块化、基于代理的RAG框架——CyberRAG。该框架能够实时分类、解释和结构化报告网络安全攻击。CyberRAG包含一个中心的LLM代理，负责（i）一组细调的专业分类器池，针对不同的攻击家族；（ii）用于丰富和通知的工具适配器；和（iii）一个迭代检索和推理循环，该循环能够连续查询特定领域的知识库，直到找到相关且一致的证据。这种代理为中心的体系结构能够自主优化其威胁标签和自然语言证明，减少误报并增强可解释性。CyberRAG的设计能够使新的攻击类型仅通过添加分类器而无需重新训练核心代理即能支持。
### Conclusion
CyberRAG在每个类别的准确率上达到了94%以上，并通过语义协调将最终分类准确率提高到94.92%。生成的解释在BERTScore中得分高达0.94，在基于GPT-4的专家评估中得分为4.9/5。这些结果表明，自主的工作方式可以与高度可靠的、SOC准备好的书面内容相结合，提供了一条实际且可扩展的半自主网络安全防御工作流程的路径。
## 85. `cs.AI` - 使用深度学习在多种作物上检测多种病害 [PDF](https://arxiv.org/pdf/2507.02517), [HTML](https://arxiv.org/abs/2507.02517)
### Authors
Vivek Yadav,Anugrah Jain
### Background
印度作为一个以农业为主的经济体，面临农业生产中的重大挑战，包括农作物因病害、虫害及环境因素造成的大量损失。早期准确检测各种作物中的多种病害对于提高产量和保障粮食安全至关重要。因此，本文提出了一种基于深度学习的解决方案，旨在检测印度多元化的农作物景观中的多种病害。研究首先创建了一个包含17种不同作物和34种不同病害的统一数据集，所提出的深度学习模型对该数据集进行训练，并在准确性和涵盖的作物类型与病害种类方面优于现有最先进的技术。
### Innovation
本文提出了一种基于深度学习的解决方案，并创建了一个统一的数据集，该数据集包括17种不同作物和34种不同病害。所提出的深度学习模型在检测精度和涵盖的作物与病害种类方面均优于现有技术，检测精度达到了99%，比处理14种作物和26种病害的现有技术提高了7个百分点。
### Conclusion
通过提高可以检测的作物种类和病害种类数量，所提出的解决方案旨在为印度农民提供更好的产品。
## 86. `cs.AI` - S2FGL: 空间光谱联邦图学习 [PDF](https://arxiv.org/pdf/2507.02409), [HTML](https://arxiv.org/abs/2507.02409)
### Authors
Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye
### Background
联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）强大的图建模能力。当前的研究仅从结构的角度探讨了子图FL，而忽略了图信号在空间和谱域传播的现象。从空间角度来看，子图FL会在客户端之间引入边断开的情况，导致标签信号的中断和全局GNN类别知识的下降。从谱角度来看，谱异质性在子图之间造成了信号频率的一致性问题，使得局部GNN过于拟合局部的信号传播模式，导致光谱客户端漂移，削弱了全局的泛化能力。
### Innovation
本文提出了一个综合空间和谱域策略的框架S2FGL。该框架包括一个全局知识库，用于缓解标签信号的中断问题，以及频率对齐机制，用于应对光谱客户端漂移的问题。实验结果表明，S2FGL在多种数据集上表现出优越的性能。该项工作填补了当前研究在空间和谱域结合方法上的空白，具有重要的创新性意义。
### Conclusion
通过在S2FGL框架下的空间和谱域策略，成功解决了子图FL中的标签信号中断和光谱客户端漂移问题。本文提供的结果证明了S2FGL方法的有效性。该框架为未来的联邦图学习提供了新的视角和方案，值得进一步研究和应用。
## 87. `cs.AI` - WebSailor：网络代理的超人类推理导航 [PDF](https://arxiv.org/pdf/2507.02592), [HTML](https://arxiv.org/abs/2507.02592)
### Authors
Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou
### Background
人类认知限制超越是大型语言模型训练的关键前沿领域。DeepResearch等专有的代理系统在极复杂的资讯检索基准测试如BrowseComp上展示了超人的能力，这是之前无法达到的。研究认为其成功源于一种开放源代码模型所缺乏的复杂推理模式：系统性减少在庞大信息景观中导航时的极端不确定性的能力。基于这一洞见，我们提出WebSailor，一种完整的后训练方法论，旨在培养这种关键能力。
### Innovation
WebSailor方法论通过结构化采样和信息混淆、冷启动以及高效代理强化学习算法Duplicating Sampling Policy Optimization (DUPO) 生成新颖高不确定性的任务，形成综合管道来实现这一目标。这种方法在复杂资讯检索任务中显著优于所有开源代理人，达到专有代理的性能，缩小了能力差距
### Conclusion
WebSailor显著提升了资讯检索任务中的代理性能，通过其独特的后训练方法，增强了复杂环境下处理高不确定性的能力。
## 88. `cs.AI` - 在FPGA的可编程逻辑中使用加速的人工神经网络进行红葡萄检测 [PDF](https://arxiv.org/pdf/2507.02443), [HTML](https://arxiv.org/abs/2507.02443)
### Authors
Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias
### Background
机器人在搬运过程中通常会减速来检测物体，同时配置低帧率的摄像头以跟踪检测算法的运行速度。这种做法在执行任务和探索时受到限制，导致任务执行时间增加。AMD开发了Vitis-AI框架，可以在FPGA上部署检测算法，但这并未充分利用FPGA的PL（可编程逻辑）资源。因此，该研究利用FINN架构在FPGA的PL中部署了三种不同的ANN（人工神经网络），包括使用4位量化方式的MobileNet v1、使用2位量化方式的CNV和使用1位量化方式的CNV（BNN）。这些模型是在RG2C自采集数据集上进行训练的。
### Innovation
本文使用FINN架构在FPGA的可编程逻辑中部署了三种不同的人工神经网络模型，通过对模型进行量化处理，提高模型部署在FPGA上的速度和效率，证明了FPGA可以加速人工神经网络，并使其适用于注意力机制中。特别是在基于MobileNet v1的网络中，达到了98%的成功率和6611 FPS的推理速度。这种技术为在机器人搬运过程中实时检测物体提供了新的可能性，有助于提高任务执行效率。
### Conclusion
通过使用FINN架构部署不同量化级别的ANN模型，证明了FPGA可以加速人工神经网络并适用于机器人搬运过程中的检测任务。该研究展示了使用FPGA实现高效实时物体检测的可能性，为未来的研究和应用提供了新的方向和方法。
## 89. `cs.AI` - CrowdTrack：在真实场景中的复杂多人跟踪基准 [PDF](https://arxiv.org/pdf/2507.02479), [HTML](https://arxiv.org/abs/2507.02479)
### Authors
Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue
### Background
多目标跟踪是计算机视觉中的一个经典领域，其中行人跟踪具有极高的应用价值，已成为最热门的研究类别。现有方法主要依赖于运动或外观信息进行跟踪，在复杂场景中常常难以实现。运动信息由于物体间遮挡导致运动状态更新困难；外观信息由于部分视野不足或图像模糊等因素导致结果不够稳定。虽然通过标注数据学习如何在这些情况下执行跟踪是简单的方法，但现有的多人目标跟踪（MOT）数据集无法满足这一需求。现有方法存在两个主要缺点：场景构成相对简单、场景不具现实性。虽然现有数据集中的一些视频序列没有上述缺点，但数量远不能满足研究需求。鉴于此，提出一个针对复杂场景中的多人跟踪的困难大规模数据集，主要从第一人称视角拍摄，并全部来自现实复杂场景。我们将其命名为``CrowdTrack''，因为大多数序列中的对象数量众多。该数据集包含33个视频，共5,185条轨迹。每个对象都标注了完整的边界框和唯一的对象ID。该数据集将为研究提供一个平台，促进在复杂情况下依然有效的算法的发展。
### Innovation
提出了一个针对复杂场景中的多人跟踪的困难大规模数据集，此数据集主要从第一人称视角拍摄，并全部来自现实复杂场景。改进了现有MOT数据集的两个主要缺点：场景构成相对简单、场景不具现实性。数据集包含33个视频，共5,185条轨迹，每个对象都标注了完整的边界框和唯一的对象ID，为研究提供了一个有效的平台。此外，还分析了多个最新模型在该数据集上的表现，并分析了基础模型的性能。数据集及项目代码已公开发布。
### Conclusion
提出了一个新的数据集CrowdTrack，为处理复杂行人跟踪场景提供了更现实的挑战。数据集覆盖了大量实际复杂场景，为多人跟踪算法的研究提供了很好的平台。已展示了多个最新模型及基础模型在该数据集上的性能，显著改进了现有MOT方法。
## 90. `cs.AI` - De-AntiFake: 重新思考对抗仿声攻击的保护扰动 [PDF](https://arxiv.org/pdf/2507.02606), [HTML](https://arxiv.org/abs/2507.02606)
### Authors
Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu
### Background
语音生成模型的发展加剧了语音克隆（VC）相关的隐私和安全问题。近期研究通过引入对抗性扰动来干扰未经授权的语音克隆，但恶意攻击者可以克服这些保护措施并成功执行语音克隆。研究者首次在包含去噪步骤的现实威胁模型下，系统性评估现有的保护性扰动。研究发现现有的去噪方法可以中和大量保护性扰动，但残余的扰动会破坏语音克隆模型的特征空间，从而影响性能。
### Innovation
提出了一个新颖的两阶段去噪方法，包括：(1) 去除受扰语音中的噪声；(2) 使用音素指导精炼语音，使其符合干净语音的分布。实验表明该方法在干扰语音克隆防御方面优于现有最先进方法。
### Conclusion
研究揭示了对抗性扰动在语音克隆防护中的局限性，强调了需要更强的安全解决方案来缓解语音克隆带来的安全和隐私风险。提供的代码和音频样本可以在给定的链接中找到。
## 91. `cs.AI` - AC-Refiner: 使用条件扩散模型实现高效算术电路优化 [PDF](https://arxiv.org/pdf/2507.02598), [HTML](https://arxiv.org/abs/2507.02598)
### Authors
Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun
### Background
算术电路，如加法器和乘法器，是数字系统的基本组成部分，直接影响性能、电能效率和面积占用。然而，由于设计空间庞大和复杂的物理约束，优化这些电路仍然具有挑战性。近期基于深度学习的方法虽然显示出潜力，但在稳定探索高潜力设计变量方面存在困难，从而限制了其优化效率。
### Innovation
我们提出了一种名为AC-Refiner的新颖算术电路优化框架，它利用条件扩散模型。我们的核心洞察是将算术电路合成重新定义为条件图像生成任务。通过仔细在去噪扩散过程中对目标QoRs进行条件处理，AC-Refiner能够持续生成高质量的电路设计。此外，探索得到的设计用于微调扩散模型，使其聚焦在帕累托前沿附近的探索。实验结果表明，AC-Refiner生成的电路设计具有优越的帕累托最优性，优于最先进的基线方法。进一步的性能增益通过将AC-Refiner集成到实际应用中得到了验证。
### Conclusion
实验结果表明AC-Refiner生成的电路设计具有优越的帕累托最优性，优于最先进的基线方法。进一步的性能增益通过将AC-Refiner集成到实际应用中得到了验证。
## 92. `cs.AI` - 一个深度学习理论必须包含 composition 缺陷 [PDF](https://arxiv.org/pdf/2507.02550), [HTML](https://arxiv.org/abs/2507.02550)
### Authors
David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio
### Background
过参数化深层神经网络（DNNs）在高维度问题上表现出色，这些问题对于受维度诅咒的传统浅层网络来说是难以解决的。然而，关于DNNs学习动力学的基本原理仍然是开放性的问题。研究论文认为深层神经网络的成功在于他们利用目标函数的组成稀疏结构。这种结构表明多数有现实意义的函数可以由一小部分基函数组成，这些基函数仅依赖于所有输入中的低维度子集。研究还指出，这种性质被所有有效地图灵计算的函数共享，这说明它可能存在于所有当前的机器学习问题中。尽管有关近似和泛化的问题在组成稀疏函数中有一些有希望的理论见解，但是关于DNNs可学习性和优化的重要问题仍然没有答案。因此，在深度学习的理论中阐明组成稀疏性的作用是构建全面的人工智能理论的关键步骤。
### Innovation
研究提出了一种新的视角，即解释DNNs成功的本质在于它们利用了目标函数的组成稀疏结构。这一理论强调了DNNs如何通过利用函数组成中基函数的性质来提高效率，并且这种组成稀疏性是所有可图灵计算的函数共有的性质，这使得它在当前学习问题中普遍存在。这种观点为理解DNNs的学习动态和优化过程提供了一个新的角度，为未来的研究提供了方向。
### Conclusion
深入学习的理论框架必须包括组成稀疏性这一概念。研究认为，过参数化的DNNs之所以能够在高维度问题上取得突破，是因为它们能够有效利用目标函数的组成稀疏性。这种构成稀疏性不仅被那些可以有效图灵计算的函数所共有，而且这种性质很可能存在于所有当前的机器学习问题中。该研究强调，阐明这一性质在深度学习中扮演的角色对于构建全面的人工智能理论至关重要，这对于未来的人工智能技术和发展的理解具有重要意义。
## 93. `cs.AI` - 基于视觉导航中相机传感器故障的解决：仿真与数据集开发 [PDF](https://arxiv.org/pdf/2507.02602), [HTML](https://arxiv.org/abs/2507.02602)
### Authors
Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill
### Background
随着基于视觉导航（VBN）算法在太空任务中的重要性日益增加，确保其可靠性和操作稳健性变得非常重要。传感器故障可能导致导航算法输出不准确或整个数据处理故障，进而影响任务目标的实现。人工智能提供了一种强大的解决方案，以解决传统故障检测方法的众多局限性，但主要障碍在于缺乏包含故障图像数据的充分且具有代表性的数据集。本文通过专注于星际探索任务场景，对VBN管道中使用的摄像头传感器可能出现的故障进行全面分析，系统的描述了这些故障的原因和影响，以及通常采用的缓解策略。为了支持这一分析，提出了一个仿真框架，可以在合成生成的图像中重现故障条件，并能够系统可控地再现故障数据。由此产生的包含故障注入图像的数据集为训练和测试基于人工智能的故障检测算法提供了宝贵工具。
### Innovation
本文创新点在于对VBN管道中使用的摄像头传感器可能出现的故障进行了全面、系统的分析，并提出了一个仿真框架，可生成包含故障图像数据的数据集，为基于人工智能的故障检测算法的训练和测试提供了宝贵资源。
### Conclusion
文章通过全面分析VBN管道中摄像头传感器可能出现的故障，并提出仿真框架生成包含故障图像数据的数据集，为基于人工智能的故障检测算法提供了可靠的训练和测试工具，解决了当前缺乏涉及故障数据的代表性数据集的问题。
## 94. `cs.AI` - FairHuman: 使用最小潜在延迟公平性在扩散模型中提升人体图像生成中的手部和面部质量 [PDF](https://arxiv.org/pdf/2507.02714), [HTML](https://arxiv.org/abs/2507.02714)
### Authors
Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma
### Background
随着大规模文本到图像模型的发展，图像生成取得了显著进展，尤其是在基于扩散的模型方面。然而，在生成包含面部或手部等细节点的人体图像时，由于训练过程中局部区域的监督不足，仍然存在挑战。因此，需要一种方法来提升这些细节点的质量，同时保持整体图像的质量。
### Innovation
提出了一种名为FairHuman的多目标微调方法，旨在公平地提升局部和整体生成质量。FairHuman通过构建全局和局部学习目标来实现这一目标，全局目标基于默认的扩散目标函数，局部目标则基于预注释的位置先验。此外，FairHuman采用Minimum Potential Delay（MPD）准则来优化参数更新策略，从而使这种方法在处理多目标问题时能够实现公平优化。
### Conclusion
FairHuman方法能够在保持高质量完整图像生成的前提下显著提升人体图像中手部和面部的详细生成质量。广泛的实验结果表明，在不同场景下，这种方法能够有效提升人体图像生成的性能。
## 95. `cs.AI` - APT: 自适应个性化训练在有限数据下的扩散模型中 [PDF](https://arxiv.org/pdf/2507.02687), [HTML](https://arxiv.org/abs/2507.02687)
### Authors
JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang
### Background
使用有限数据个性化扩散模型面临着显著的挑战，包括过拟合、先验知识丢失以及文本对齐下降。过拟合会导致噪声预测分布发生变化，破坏去噪轨迹，使模型失去语义连贯性。
### Innovation
提出了一种新颖的自适应个性化培训（APT）框架，通过采用自适应培训策略和在微调过程中正则化模型的内部表示来缓解过拟合。APT 包括三个关键组成部分：（1）自适应训练调整，引入过拟合指标以在每个时间步长箱检测过拟合程度，并根据该指标应用自适应数据增强和自适应损失权重；（2）表示稳定化，正则化中间特征图的均值和方差，防止噪声预测发生过度变化；（3）注意力对齐以保持先验知识，使微调模型的跨注意力图与预训练模型的对齐，以维持先验知识和语义连贯性。
### Conclusion
通过广泛的实验，我们证明了APT能够有效缓解过拟合，保持先验知识，并在有限参考数据生成高质量、多样化图像方面优于现有方法。
## 96. `cs.AI` - FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference [PDF](https://arxiv.org/pdf/2507.02620), [HTML](https://arxiv.org/abs/2507.02620)
### Authors
Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang
### Background
分布式推理作为一种在网络边缘实现大语言模型（LLMs）推理的有效方法，通过将推理过程分布在多个设备上，确保LLMs能够在设备内存中运行。近期的管道为基础的方法能够实现通信和计算的并行化，有助于减少推理延迟。但在网络边缘推理请求稀疏的情况下，管道利用率低，这种优势就会减弱。因此，需要提出一种框架来提高边缘分布式LLM推理的效率。
### Innovation
提出了一种名为FlowSpec的管道并行树结构的推测性解码框架，包括三种关键技术：1）基于得分的逐步验证优先处理更重要的草稿标记；2）高效草稿管理，在验证过程中剪枝无效标记同时保持正确的因果关系；3）动态草稿扩展策略，为推测性解码提供高质量的输入。这些技术共同提升管道利用率和推测解码的效率
### Conclusion
我们在一个真实的测试平台上对FlowSpec与其他基准进行了评估，实验证明，我们提出的方法在多种模型和配置中显著提高了推理速度，比基准提高了1.36倍至1.77倍。代码已公开。
## 97. `cs.AI` - ASDA: 音频频谱差异注意力机制在自监督表示学习中的应用 [PDF](https://arxiv.org/pdf/2507.02666), [HTML](https://arxiv.org/abs/2507.02666)
### Authors
Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang
### Background
在近期的音频自监督表示学习进展中，标准的Transformer架构成为了主流方法，但也存在注意力机制将部分注意力权重分配给无关信息的问题，这可能会削弱模型的辨别能力。本文旨在解决这一问题。
### Innovation
本文提出了一种差异注意力机制（ASDA），通过集成双softmax操作和适当调整的差异系数，有效减轻了无效注意力分配的问题，进而提升了模型的性能。实验结果显示，ASDA模型在多个基准上的性能超越了现有方法，特别是在音频分类、关键词识别和环境声音分类任务中取得了最优的结果。
### Conclusion
实验结果表明ASDA模型在多个音频任务中取得了优_results，证明了其在音频处理领域的有效性，展望了其更广泛的应用前景。
## 98. `cs.AI` - Meta SecAlign: 一种抵御提示注入攻击的安全基础LLM [PDF](https://arxiv.org/pdf/2507.02735), [HTML](https://arxiv.org/abs/2507.02735)
### Authors
Sizhe Chen,Arman Zharmagambetov,David Wagner,Chuan Guo
### Background
提示注入攻击对LLM集成应用构成了严重的安全威胁。尽管模型级别的防御措施表现出很强的有效性，但这些防御措施当前以闭源的方式集成到商业级模型中。AI安全社区需要开源模型，通过开放研究中的攻击和防御的共同发展，可以促进对抗提示注入攻击的缓解措施的科学进展。
### Innovation
我们开发了Meta SecAlign，这是首个具备内置模型层次防御的开源且开源权重的LLM，实现了商业级别的模型性能。我们提供了完整的训练食谱详情，运用了SOTA SecAlign防御的改进版本。Meta SecAlign在9个实用基准和7个安全基准上的评估表明，尽管该模型是在通用指令调优数据集上训练的，它在未见过的下游任务中依旧具备安全性，包括工具调用和支持性网页导航，以及一般的指令遵循。我们最好的模型—Meta-SecAlign-70B—在对抗提示注入攻击上达到了最先进的鲁棒性，并且与具备模型层次防御的闭源商业LLM在实用性方面具有可比性。
### Conclusion
Meta SecAlign通过开源形式提供了强大的防御机制，适用于不确定的下游任务，并且在对抗提示注入攻击的鲁棒性和实用性上达到了卓越的成果。
## 99. `cs.AI` - 你在听我说吗？细调聊天机器人实现共情对话 [PDF](https://arxiv.org/pdf/2507.02537), [HTML](https://arxiv.org/abs/2507.02537)
### Authors
Paulo Ricardo Knob,Leonardo Scholler,Juliano Rigatti,Soraia Raupp Musse
### Background
自ELIZA以来，对话代理取得了显著的进步，其角色扩展到了包括医疗保健、教育及客户服务在内的多个领域。随着这些代理越来越多地融入日常的人际交往，拥有情感智能，尤其是共情倾听的能力变得越来越重要。本研究探索了大型语言模型（LLMs）在生成富有情感的对话时的反应。从一个由专家手工制作的小数据集开始，该数据集反映了共情行为，我们使用ChatGPT和Gemini两个LLM扩展了对话。我们通过情感分析（使用VADER）和专家评估分析了对话中的情感进展。尽管生成的对话往往模仿了预期的情感结构，但人类评估揭示了在感知共情和回应的连贯性方面存在的重要差异。这些发现表明，对话中的情感建模不仅需要表达情感的结构性对齐，还需要质上的深入，突显了在开发情感精明的代理时结合自动化和以人为本的方法的重要性。
### Innovation
本研究使用大型语言模型（LLMs）探索生成富有情感的对话，并通过专家评估来分析对话中的情感进展，得出了情感建模不仅需要结构性对齐，还需要质上的深入的重要结论。
### Conclusion
本研究发现，仅仅结构上对齐表达的情感对于生成富有情感的对话是不够的，还需要质上的深入。因此，开发情感精明的代理时需要结合自动化和以人为本的方法。
## 100. `cs.AI` - 基于全局上下文的线性注意力：一种用于视觉和物理的多极注意力机制 [PDF](https://arxiv.org/pdf/2507.02748), [HTML](https://arxiv.org/abs/2507.02748)
### Authors
Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen
### Background
Transformer 在图像分类到物理模拟等多种任务中已成为事实上的标准。虽然它们表现出色，但由于输入长度的平方级内存和时间复杂度限制，标准Transformer在处理高分辨率输入时变得不切实际。因此，提出了多种变体，最成功的变体依赖于分块、下采样或粗化技术，但通常会损失细节信息。受最先进的 $n$-体数值模拟技术启发，本文提出了一个新的方法。
### Innovation
本文提出了Multipole Attention Neural Operator (MANO)。MANO 通过基于距离的多尺度方式计算注意力，每个注意力头都维护全局感受野，从而实现与网格点数量线性的时间和空间复杂度。实验结果表明，MANO 在图像分类和 Darcy 流中能够挑战现有的顶级模型（如ViT 和 Swin Transformer），同时大幅减少运行时间和峰值内存使用。
### Conclusion
MANO 通过基于距离的多尺度方式计算注意力，在每个注意力头中维护全局感受野，实现线性时间和空间复杂度。实验证明，MANO 在图像分类和Darcy流中性能与现行顶级模型相当，但显著减少了运行时间和内存使用。
## 101. `cs.AI` - MPF: 通过多视角融合在部署后对语言模型进行对齐和去偏见 [PDF](https://arxiv.org/pdf/2507.02595), [HTML](https://arxiv.org/abs/2507.02595)
### Authors
Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama
### Background
随着大型语言模型（LLMs）的广泛使用，人们越来越需要容易实现的偏见缓解方法。本文针对这一需求，提出了一个名为Multiperspective Fusion (MPF)的新颖后训练对齐框架，此框架基于SAGED流水线，它是用于构建偏见基准并提取可解释基准分布的自动化系统。MPF通过多视角生成，揭示并调整LLM输出与细致、类人基准之间的偏差，使其能够与包含情感分布等基准进行对齐，并取得实际效果。
### Innovation
MPF是针对LLM偏见缓解方法的创新之处在于，通过分解基准（例如HR专业人士的情感分布）为可解释的观点组件，引导生成过程，根据分解获得的概率进行采样和权重平衡。这使得MPF能够实现与反事实基准（完全平等）和HR基准（偏向名校）的情感分布对齐，降低Kullback-Leibler（KL）偏差和校准误差，并且能够在未见问题上进行泛化。这些结果表明MPF提供了一种可扩展且解释性强的对齐方法，适用于已部署的LLM，无需大量的提示工程或微调。
### Conclusion
实验证明，MPF可以通过多视角融合对LLM的情感分布与反事实基准和HR基准进行对齐，并减少KL偏差和校准误差，同时实现未见问题的泛化。因此，MPF提供了一种适用于部署中LLM的可扩展和解释性强的对齐和去偏见方法，无需复杂的提示工程或微调。
## 102. `cs.AI` - Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation [PDF](https://arxiv.org/pdf/2507.02752), [HTML](https://arxiv.org/abs/2507.02752)
### Authors
Shuan Chen,Gunwook Nam,Yousung Jung
### Background
在计算药物和材料发现中，AI生成具有理想性质的分子与其合成可行性之间的脱节仍然是一个关键瓶颈。尽管生成式AI加速了候选分子的提出，但许多这些结构仍然难以或无法用已知化学反应合成。
### Innovation
我们引入了SynTwins，这是一种基于逆向合成设计分子类似物的新框架，通过模仿资深化学家的策略，利用三步过程——逆向合成、相似构建块搜索和虚拟合成来设计可合成的分子类似物。与最先进的机器学习模型相比，SynTwins在生成可合成的相似分子方面表现出更优性能，同时保持高度结构相似性。当我们将其与现有的分子优化框架集成时，我们的混合方法可以生成具有接近自由生成分子生成器的性质轮廓的可合成分子，且其合成可行性得到了保证。
### Conclusion
在多个分子数据集上的全面基准测试表明，SynTwins有效地弥合了计算设计与实验合成之间的差距，为加速寻找具有理想性质的可合成分子提供了实际解决方案，适用于广泛的应用领域。
## 103. `cs.AI` - 快速且简洁：Triton中的2-单纯形注意力 [PDF](https://arxiv.org/pdf/2507.02754), [HTML](https://arxiv.org/abs/2507.02754)
### Authors
Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil
### Background
最近的研究表明，训练损失与模型大小和令牌数目成幂律关系，并且要实现计算最优的模型需要同时扩展模型大小和令牌数目。然而，这些扩展法则假设数据无限供给，并主要适用于计算受限的环境。随着现代大规模语言模型越来越多地依赖于庞大的互联网规模数据集，数据供给充足这一假设的有效性开始降低，这突显了优先考虑令牌效率的架构的重要性。
### Innovation
本文研究了2-单纯形Transformer这一架构，通过高效实现的Triton内核能够将标准点积注意力推广到三线性函数。实验表明，具有相同令牌预算的2-单纯形Transformer模型在涉及数学、编程、推理和逻辑的任务上优于标准Transformer模型。通过量化这些增益，研究发现2-单纯形注意力改变了知识和推理任务上的扩展法则的指数，相比点积注意力具有更高的令牌效率。
### Conclusion
2-单纯形Transformer能够提高令牌效率，在相同的令牌预算下，对于涉及数学、编程、推理和逻辑的任务能表现得更好。通过改变知识和推理任务上的扩展法则的指数，2-单纯形注意力展示了比点积注意力更高的性能。
## 104. `cs.AI` - 使用神经量子态求解Hubbard模型 [PDF](https://arxiv.org/pdf/2507.02644), [HTML](https://arxiv.org/abs/2507.02644)
### Authors
Yuntian Gu,Wenrui Li,Heng Lin,Bo Zhan,Ruichen Li,Yifei Huang,Di He,Yantao Wu,Tao Xiang,Mingpu Qin,Liwei Wang,Dingshun Lv
### Background
神经量子态(NQS)的快速发展使其成为研究量子多体系统的有前途的框架。现有的研究显示，借助先进的变压器架构和高效优化算法的应用，NQS已经在掺杂的二维（2D）Hubbard模型上取得了最先进的成果，Hubbard模型被认作是高温超导体的基本模型。研究表明，在NQS态中不同的注意力头可以编码不同规模的关联，使得NQS能够捕捉强关联系统中的长程关联和纠缠。这些进步使得在具有次邻近跃迁的二维Hubbard模型半填态的基态中建立了与铜酸盐实验观察一致的状态，进一步证明了NQS在解决费米子系统中的重要性与潜力.
### Innovation
通过利用最新的变压器架构和开发高效优化算法，作者实现了掺杂的二维Hubbard模型的最先进的结果，这是代表高温超导体的基本模型。NQS的不同注意力头被发现可以直接编码不同规模的关联，因此能够捕捉强关联系统中的长程关联和纠缠。建立在具有次邻近跃迁的二维Hubbard模型的半填态基态，该结果与铜酸盐实验观察一致，进一步证明了NQS作为解决复杂费米子系统的强大工具的作用.
### Conclusion
本工作证明了神经量子态(NQS)可以作为一个强大的方法来解决复杂费米子系统问题。随着NQS的进一步发展，它将为理解高温超导现象和其它量子多体问题提供新的见解和工具.
## 105. `cs.AI` - 基于DNN的RIS辅助毫米波MIMO系统的实用性相位移预编码 [PDF](https://arxiv.org/pdf/2507.02824), [HTML](https://arxiv.org/abs/2507.02824)
### Authors
Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang
### Background
本文研究了毫米波（mmWave）多输入多输出（MIMO）系统中，在通信路径受阻的情况下，通过可重构智能表面（RIS）增强MIMO传输的设计方案。传统的连续相位搜索（ES）方法计算量大且耗时，尤其是在考虑毫米波的线视（LoS）和多径效应时。为了减少计算复杂度，使用了移位的离散傅里叶变换（DFT）向量来设计码本，并结合了实际或理想RIS系统的幅度响应。然而，即使在ES中采用离散相位，仍然会导致计算量大且耗时，因此研究人员开发了一种训练好的深度神经网络（DNN）来加速码字的选择。
### Innovation
本文提出了一种基于DNN的预编码设计方案，能够在考虑RIS与终端用户之间距离变异性的情况下，快速选择有效码字，从而加快预编码速度并维持亚优化的频谱效率。
### Conclusion
仿真结果表明，即使在测试阶段RIS与终端用户之间距离发生变化，基于DNN的预编码方案仍然能够保持亚优化的频谱效率。这表明DNN在推动RIS辅助系统的发展中具有潜力。
## 106. `cs.AI` - 前沿大型语言模型早期具备隐写术能力的迹象 [PDF](https://arxiv.org/pdf/2507.02737), [HTML](https://arxiv.org/abs/2507.02737)
### Authors
Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner
### Background
大型语言模型（LLM）的输出监控对于减轻滥用和错位风险至关重要。然而，LLM可以通过隐写术方法规避监控：在看似无害的生成中隐藏信息。本研究评估了前沿LLM的隐写术能力以更好地理解它们带来的风险。研究集中在两类隐写术上：传递编码信息和执行编码推理。研究表明，当前模型在标准情况下无法在输出中编码短消息而不被监控器发现。若给予额外条件，如使用未监控的工作区和协调使用编码方案，它们可以成功隐藏消息。此外，研究发现模型在简单状态跟踪问题中具备基础的编码推理能力，包括利用自身和预定义的编码方案，如十六进制编码。然而，这些模型很难在掩盖推理的同时欺骗监控器。总体而言，研究结果表明当前LLM具备初步的隐写术能力，尽管这些能力目前可能不足以绕过精心设计的监控器，但未来有可能发生变化。
### Innovation
本研究首次评估了前沿大型语言模型的隐写术能力，揭示了新的风险可能性。研究通过实验数据和分析，观察到了模型发送编码信息和执行编码推理的能力早期迹象，这是该领域的创新性贡献。这项研究不仅扩展了我们对LLM风险的理解，也为未来的安全措施提供了新的视角。
### Conclusion
当前前沿大型语言模型显示出初步的隐写术能力，但在标准条件下难以隐蔽地传递消息或隐藏推理。尽管目前这些能力不足以绕过精心设计的监控器，未来可能发展出更强大的隐写术方法，这强调了加强监控机制的必要性。
## 107. `cs.AI` - 多智能体听觉场景分析 [PDF](https://arxiv.org/pdf/2507.02755), [HTML](https://arxiv.org/abs/2507.02755)
### Authors
Caleb Rascon,Luis Gato-Diaz,Eduardo García-Alarcón
### Background
听觉场景分析（ASA）的目标是从声学环境中提取信息，通过三个主要任务实现：声源定位、分离和分类。这些任务通常是线性处理，首先是定位声源，然后根据其位置将每个声源分离成单独的音频流，在每一流中提取与应用场景相关的信息（如音频事件检测、说话人识别、情绪分类等）。然而，线性处理这些任务增加了整体响应时间，同时使得后面的分离和分类任务对前一个任务的错误高度敏感。因此，在最先进的技术中投入了大量的努力和计算复杂度来开发尽可能减少错误的技术。但在很多需要较小的计算足迹和低响应时间的应用中（如生物声学、助听器设计、搜索救援、人机交互等），这些都不太可行。
### Innovation
本文提出了一种多智能体方法，用于并行运行ASA任务，并通过反馈回路纠正本地错误，例如：使用分离输出的质量来纠正定位误差；使用分类结果来减少定位对干扰的敏感性。这样得到一个多智能体听觉场景分析（MASA）系统，既具有较好的鲁棒性，又没有显著增加复杂性，并且响应时间较低。整个提出的MASA系统作为一个框架提供，使用开源工具（JACK）进行声音采集和再现，使用ROS2进行智能体间的通信，用户可以添加自定义的智能体。
### Conclusion
本文提供了一个框架，使MASA系统能够在无需大幅增加复杂性和响应时间的情况下，处理本地错误并适用于需要低响应时间和较小计算足迹的应用场景。
## 108. `cs.AI` - SynapseRoute: 双态大语言模型自动切换框架 [PDF](https://arxiv.org/pdf/2507.02822), [HTML](https://arxiv.org/abs/2507.02822)
### Authors
Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun
### Background
随着大型语言模型（LLMs）在实际应用中的广泛应用，选择合适的模型不仅要考虑性能，还要权衡运营成本。推理能力强的模型进一步拉大了'思考'（高推理）和'非思考'（快速、低成本）模式之间的成本差距。研究发现，大约58%的医疗问题可以通过单一的'非思考'模式准确回答，无需进行高成本的推理过程，这表明问题复杂性存在明确的二元性。研究表明，根据不同问题的复杂性动态地将查询路由到合适的模式，可以优化准确度、成本效益和整体用户体验。因此，提出了SynapseRoute，这是一种基于机器学习的动态路由框架，能够智能地将输入查询分配到思考或非思考模式中。
### Innovation
提出了SynapseRoute，一种基于机器学习的动态路由框架，能够智能地将输入查询分配到思考或非思考模式中。实验结果显示，与仅使用思考模式相比，SynapseRoute不仅提高了整体准确率，并且将推理时间减少了36.8%，减少了39.66%的token消耗。此外，准确推理是不必要的反而会带来延迟和准确性下降，而适应性路由避免了这一问题。引入了Accuracy-Inference-Token (AIT) 索引，以全面评价准确度、延迟和token成本之间的权衡。
### Conclusion
SynapseRoute通过基于准确度-推理-令牌（AIT）指数，优化了大语言模型查询处理过程中的准确度、延迟和令牌成本之间的权衡，从而提高了效率和用户体验。
## 109. `cs.AI` - Self-Correction Bench: 揭示并解决LLM中的自我修正盲区 [PDF](https://arxiv.org/pdf/2507.02778), [HTML](https://arxiv.org/abs/2507.02778)
### Authors
Ken Tsui
### Background
尽管大型语言模型（LLMs）已经变得非常变革性，但它们仍然会出错，并且可能会探索不productive的推理路径。自我纠正是一种对于可信任的LLM，特别是自回归LLM来说非常重要的能力。虽然LLMs能够识别用户输入中的错误，但它们会系统地忽略自我输出中的相同错误，即存在一种称为“自我纠正盲区”的系统性错误。为了系统地研究这一现象，作者引入了一个名为Self-Correction Bench的系统性框架，通过在三个复杂度级别中注入可控的错误来测量这种现象。
### Innovation
作者提出了一个名为Self-Correction Bench的新颖框架，该框架通过在三个复杂度级别中注入可控的错误，对LLMs中的自我纠正盲区进行了系统性研究。通过测试14个模型，作者发现平均有64.5%的自我纠正盲区。此外，简单地添加“等待”指令可以显著减少盲区，表明该能力确实存在，但需要激活。研究还发现，这一限制与训练数据的组成有关：人工训练示例主要展示无错误响应，而非错误纠正序列，这与通过结果反馈学习错误纠正的RL训练模型不同。这项工作强调了当前LLMs中一个关键的局限性，并提供了改善其可靠性和可信赖性的潜在途径
### Conclusion
这项研究揭示了LLMs中的一个关键局限性：自我纠正盲区。通过进一步的研究与改进，可以提高LLMs的可靠性和可信赖性。简单地添加“等待”指令能够显著减少这种盲区，表明自我纠正的能力实际上存在于这些模型中，但需要被激活。
## 110. `cs.AI` - Answer Matching Outperforms Multiple Choice for Language Model Evaluation [PDF](https://arxiv.org/pdf/2507.02856), [HTML](https://arxiv.org/abs/2507.02856)
### Authors
Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping
### Background
多项选择基准长期以来一直是语言模型评估的主力，因为自动评分简单且客观。然而，我们展示出从流行基准获得的多项选择题往往可以在不看问题的情况下就能回答。这些捷径源于辨别性评估的一种基本局限性，这种局限性并非模型自由格式生成答案评估所共享的。近期似乎没有可行的规模化替代方案，但本文展示了这一情况已改变。我们考虑通过我们所称的答案匹配进行生成性评估：给出候选模型问题而无选项，让它生成自由格式回复，然后用现代语言模型以及参考答案来判断回复是否匹配参考答案。为了比较不同评估策略的有效性，我们对MMLU-Pro和GPQA-Diamond进行标注获得人工评分数据，并测量每种评估方法的一致性。我们发现，使用近期模型（即便很小）的答案匹配一致接近完美，与人工评分的一致性相近，而多项选择评估方式和使用大语言模型作为判决者而无参考答案则与人工评分关联性差。通过答案匹配改进评估不仅是概念上的关心：当评估模型的自由格式回复时，答案匹配评估显著改变了几个模型的排名。鉴于这些发现，我们讨论了从多项选择转向答案匹配的评估生态系统如何发展。
### Innovation
本文展示了生成性评估方法（答案匹配）的优越性，通过这种方法，即使使用较小的模型也能达到接近完美的一致性，而传统多项选择评估和未提供参考答案的大语言模型评估方法与人工评分的关联性较弱。这表明，改进评估方法不仅是一种理论关注，而且还对模型排名产生了实际影响。
### Conclusion
鉴于上述发现，本文讨论了从多项选择评估转向答案匹配评估的方法来改进语言模型的评估流程。
## 111. `cs.AI` - DHOL中的子类型化——扩展预印本 [PDF](https://arxiv.org/pdf/2507.02855), [HTML](https://arxiv.org/abs/2507.02855)
### Authors
Colin Rothgang,Florian Rabe
### Background
最近引入的依赖类型高级逻辑（DHOL）提供了一种表达能力和自动化支持之间的有趣折衷。它牺牲了类型系统决定性，以显著扩展其相对于标准逻辑高级（HOL）的表达能力。尽管如此，它仍然通过将DHOL安全且完全翻译到HOL保留了强大的自动化定理证明支持。研究人员发现，DHOL的这种设计使其能够引入refinement和quotient类型，这两种类型通常被使用者请求但通常难以在自动定理证明系统中实现，因为它们本质上需要不决定性类型判断。
### Innovation
本文通过将refinement和quotient类型作为子类型化的一种特殊情况引入DHOL，实现了技术上的创新。这种设计使得相关规范包含和投影映射成为恒等映射，从而避免了昂贵的表示变化。同时，作者还展示了扩展语言的语法、语义以及到HOL的翻译，并给出严格的完整性和正确性证明。这一方法不仅可能而且优雅且简单，开创了在非决定性类型系统中引入refinement和quotient类型的先河。
### Conclusion
本文通过将refinement和quotient类型作为子类型化的一种特殊情况引入DHOL，并展示了扩展语言的语法、语义和到HOL的翻译。通过严格证明，证明了该系统是正确的且完全的。这一结果不仅深化了对DHOL的理解，还为其他非决定性类型系统的扩展提供了新的思路。
## 112. `cs.AI` - USAD: 一种无监督数据增强时空注意力扩散网络 [PDF](https://arxiv.org/pdf/2507.02827), [HTML](https://arxiv.org/abs/2507.02827)
### Authors
Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li
### Background
人类活动识别（HAR）的主要目标是从传感器数据中推断出正在进行的人类行为，这一任务在健康监测、安全保护和体育分析中具有广泛的应用。尽管进行了大量的研究，HAR仍面临一些关键挑战，包括罕见活动样本稀缺、高级特征提取不足以及在轻量级设备上的模型性能不佳。
### Innovation
本文提出了一种综合优化方法，中心思想是多注意交互机制。首先，采用未监督的、以统计数据为指导的扩散模型进行数据增强，以缓解标数据稀缺和严重类别不平衡的问题。其次，设计了一种多分支时空交互网络，通过并行的残差分支捕获序列数据的多尺度特征，分支分别使用3*3、5*5和7*7卷积核。同时，引入了时间注意力机制以识别关键时刻，并通过空间注意力提高了传感器之间的交互。进一步引入跨分支特征融合单元，以提高整体特征表示能力。最后，结合自适应多损失函数融合策略，使损失权重可以动态调整并整体优化模型。经在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上的实验结果表明，所提的无监督数据增强时空注意力扩散网络（USAD）分别实现了98.84%、93.81%和80.92%的准确率，显著优于现有方法。此外，在嵌入式设备上的实际部署验证了该方法的高效性和可行性。
### Conclusion
实验结果表明，USAD在三个公开数据集上的准确率分别达到了98.84%、93.81%和80.92%，显著优于现有方法。同时，该方法在嵌入式设备上的部署结果也验证了其高效性和实用性。
## 113. `cs.AI` - MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs [PDF](https://arxiv.org/pdf/2507.02851), [HTML](https://arxiv.org/abs/2507.02851)
### Authors
Purbesh Mitra,Sennur Ulukus
### Background
大型语言模型（LLMs）最近在推理能力方面的进步表明，通过采用组相对策略优化（GRPO）算法进行强化学习（RL）训练，可以使模型使用更多的思维/推理令牌以生成更好的回应。然而，LLMs在保持对之前生成的令牌的关注的同时，只能生成有限数量的令牌。这个限制，即LLMs的上下文大小，是LLMs在处理任意多个令牌时推理的瓶颈。为了超越这个上下文大小限制，模型必须采用模块化的思维策略，在多轮中进行推理。研究通过参数高效微调开源模型Qwen2.5-3B-Instruct，在GSM8K数据集上进行训练，并在MATH500和AIME2024基准测试上进行了准确性测试，展示了这种方法的有效性。
### Innovation
提出了一种名为MOTIF（模块化思考通过强化精调）的方法，它是一种RL训练方法，用于在多轮中生成思维令牌，从而允许模型在增加了上下文大小的情况下思考。通过这种方式，研究证明了MOTIF在准确性测试中的样本效率，仅用了15%的样本便实现了3.8%和3.3%的改进。该研究通过参数高效微调的方法，展示了这种方法的有效性和优越性。
### Conclusion
本工作展示了通过MOTIF方法在LLMs中实现模块化思维的有效性，它允许模型通过多轮推理使用更大的上下文大小来生成更好的回应，同时证明了该方法的样本效率。研究成果在GSM8K数据集上进行了训练，并在MATH500和AIME2024基准测试上进行了验证，取得了显著的性能提升。此外，该研究的代码和模型已公开。
## 114. `cs.AI` - 基于GPS数据在建设现场生成道路图的方法 [PDF](https://arxiv.org/pdf/2402.09919), [HTML](https://arxiv.org/abs/2402.09919)
### Authors
Katarzyna Michałowska,Helga Margrete Bodahl Holmestad,Signe Riemer-Sørensen
### Background
该研究旨在从GPS轨迹中推断出道路以用于构建地图。由于建设机械的不规则和非标准运动模式与常规道路上的车辆交通有显著差异，这使该任务具有独特的挑战性。现有技术在处理此类不规则交通模式时表现不佳，因此需要开发一种新的方法来解决这个问题。
### Innovation
本文提出了一种新的方法，用于基于GPS轨迹推断道路，特别适用于建设现场。该方法首先识别道路网络中的关键交叉点，然后通过这些节点连接成图。这种方法通过验证四个不同复杂度的地形段落表现出了较高的准确度，并且在噪声较低的数据中表现最佳，但在噪声较高的环境中性能会有所下降。
### Conclusion
研究通过在挪威的一个实际建设现场进行道路绘图，证明了该方法的有效性。验证结果显示，在低噪声或无噪声数据下，该方法在检测交叉点和推断道路方面表现完美；但在噪声较大的条件下，其性能会有所下降，失去了边缘的连续性。
## 115. `cs.AI` - Point3R：带有显式空间指针记忆的流式三维重建 [PDF](https://arxiv.org/pdf/2507.02863), [HTML](https://arxiv.org/abs/2507.02863)
### Authors
Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu
### Background
从有序序列或无序图像集合中进行密集的3D场景重建是将计算机视觉研究带入实际场景的关键步骤。DUSt3R引入了一种将图像对统一到共享坐标系统的范式，后续方法通过保持隐式记忆来实现更多图像的密集3D重建。然而，这种隐式记忆存在容量限制，并且可能会导致早期帧的信息丢失。为解决这些问题，我们提出了Point3R，这是一种面向密集流式3D重建的在线框架。
### Innovation
Point3R维持一个与当前场景的3D结构直接关联的显式空间指针记忆。每个指针都关联一个特定的3D位置，并在全局坐标系统中收集附近的场景信息，生成变化的空间特征。最新帧提取的信息与这种指针记忆直接交互，使得当前观察结果能够被整合进全局坐标系统。我们设计了一种3D分层位置嵌入来促进这种交互，并设计了一个简单而有效的融合机制来确保指针记忆的一致性和高效性。尽管训练成本较低，该方法在各种任务上表现出了竞争力甚至达到了最先进的水平。
### Conclusion
Point3R实现了各种任务中具有竞争力或最先进水平的性能，且训练成本较低。源代码可从该链接获取：[这个链接]。
## 116. `cs.AI` - 基于图的地区预训练和提示：一种方法 [PDF](https://arxiv.org/pdf/2408.05920), [HTML](https://arxiv.org/abs/2408.05920)
### Authors
Jiahui Jin,Yifan Song,Dong Kan,Haojia Zhu,Xiangguo Sun,Zhicheng Li,Xigang Sun,Jinghui Zhang
### Background
城市区域表示对于各种城市下游任务至关重要。然而，尽管有许多方法并取得成功，但获取通用的城市区域知识并适应不同任务仍然具有挑战性。现有工作在城市区域的细腻功能布局语义方面关注较少，限制了捕捉不同区域之间可转移知识的能力。此外，不同下游任务所需的独特特征和关系处理不足也可能妨碍有效的任务适应。
### Innovation
本文提出了一种基于图的城市区域预训练和提示框架（GURPP），旨在捕获实体间异质且可转移的交互模式。具体而言，研究人员首先构建了城市区域图，并开发了一个以子图为中心的城市区域预训练模型。该模型利用对比学习和多视图学习方法来预训练知识丰富的区域嵌入。为进一步细化这些表示，设计了两种基于图的提示方法：一个是手工定义的提示来融合明确定义的任务知识，另一个是任务可学习的提示来发现隐藏的知识，这些方法增强了嵌入对不同任务的适应性。
### Conclusion
在各种城市区域预测任务和不同城市中的广泛实验表明，该框架表现优于其他方法。
## 117. `cs.AI` - 无监督认知 [PDF](https://arxiv.org/pdf/2409.18624), [HTML](https://arxiv.org/abs/2409.18624)
### Authors
Alfredo Ibias,Hector Antona,Guillem Ramirez-Miranda,Enric Guinovart,Eduard Alarcon
### Background
目前最成功的无监督学习方法主要是围绕着在数学空间中聚类样本。本研究基于认知模型启发提出了一种新的无监督学习方法，这种方法通过创建分布式的分层结构来建模输入空间，且这种建模方法是输入无关的。
### Innovation
本文提出了基于原型的无监督学习方法，该方法受到新型认知框架的启发。这种建模方式通过构建性的、分布式的、分层的结构来处理输入空间，是一种输入无关的方法。该方法在无监督分类、小型不完整数据集分类以及癌症类型分类方面进行了比较，并证明了其优越性，超越了现有的最先进的方法。此外，该方法还表现出类似认知的特点，超越了包括监督学习在内的其他算法，并表现出不同的认知行为模式。
### Conclusion
研究表明，本文提出的方法在多种无监督学习场景中优于现有的先进方法，并且其行为更接近认知过程，展现出潜在的广泛应用前景。
## 118. `cs.AI` - 使用稀疏特征级约束的直接偏好优化 [PDF](https://arxiv.org/pdf/2411.07618), [HTML](https://arxiv.org/abs/2411.07618)
### Authors
Qingyu Yin,Chak Tou Leong,Hongbo Zhang,Minjun Zhu,Hanqi Yan,Qiang Zhang,Yulan He,Wenjie Li,Jun Wang,Yue Zhang,Linyi Yang
### Background
大语言模型（LLMs）与人类偏好对齐仍然是一个关键挑战。尽管后训练技术，如人类反馈强化学习（RLHF）和直接偏好优化（DPO）已经取得了显著成果，但这些方法经常引入计算效率低下和训练不稳定性的问题。
### Innovation
本文提出了特征级受约束偏好优化（FPO），这是一种新方法，旨在简化对齐过程并确保稳定性。FPO 利用预训练稀疏自编码器（SAEs）并引入特征级约束，从而实现高效的稀疏性保障对齐。通过使用在训练良好的稀疏自编码器中激活的稀疏特征，以及使用特征级别的离线参考序列 KL 散度改进质量，FPO 方法得以提升效率。
### Conclusion
在基准数据集上的实验结果表明，FPO 在计算成本大幅降低的情况下实现了 5.08% 的绝对胜率改进，使其成为一种有希望的高效可控的大语言模型对齐解决方案。
## 119. `cs.AI` - MAPS：在专家级物理科学中的多模态推理推进 [PDF](https://arxiv.org/pdf/2501.10768), [HTML](https://arxiv.org/abs/2501.10768)
### Authors
Erle Zhu,Yadi Liu,Zhe Zhang,Xujun Li,Jin Zhou,Xinjie Yu,Minlie Huang,Hongning Wang
### Background
当前多模态大语言模型（MLLM）在一般视觉推理任务中表现出色，但它们在理解复杂物理结构的图表和基于多模态信息的定量分析方面表现仍然不足。尤其是在物理领域，需要深入理解物理图示并进行基于物理知识的推理和仿真的任务方面，多模态大语言模型的能力有待提升。
### Innovation
本文开发了一个新的框架，称为基于多模态大语言模型（MLLM）的多模态科学推理与物理感知和仿真（MAPS）。该框架将专家级多模态推理任务分解为通过物理感知模型（PPM）理解物理图示和通过仿真器进行物理知识的推理。PPM模块是通过使用精心设计的带有配对物理图示和仿真语言描述的合成数据进行微调获得的。在推断阶段，MAPS将PPM提供的输入图表的仿真语言描述和通过链式仿真过程得到的结果与MLLM结合起来，以推导出潜在的理由和最终答案。实验验证表明，MAPS显著提高了MLLM的推理准确率，并优于所有现有模型。结果证实，MAPS为增强MLLM的多模态科学推理能力提供了有 promise 的方向。
### Conclusion
MAPS显著提高了多模态大语言模型在理解物理图示和进行物理知识推理与仿真的能力，并验证了其在复杂物理结构和定量分析中的应用潜力，为多模态科学推理能力的提升提供了一个有前景的方向。
## 120. `cs.AI` - 2025年人工智能指数报告 [PDF](https://arxiv.org/pdf/2504.07139), [HTML](https://arxiv.org/abs/2504.07139)
### Authors
Nestor Maslej,Loredana Fattorini,Raymond Perrault,Yolanda Gil,Vanessa Parli,Njenga Kariuki,Emily Capstick,Anka Reuel,Erik Brynjolfsson,John Etchemendy,Katrina Ligett,Terah Lyons,James Manyika,Juan Carlos Niebles,Yoav Shoham,Russell Wald,Tobi Walsh,Armin Hamrah,Lapo Santarlasci,Julia Betts Lotufo,Alexandra Rome,Andrew Shi,Sukrut Oak
### Background
自2017年作为百年人工智能研究计划的衍生项目成立以来，人工智能指数一直致力于为政策制定者、记者、企业高管、研究人员和公众提供准确、严格验证和全球来源的数据。自成立以来，该指数致力于帮助这些参与者更有效地为人工智能的发展和部署做出更加明智的决策。随着人工智能在全球各方面的影响力不断加强，2025年的人工智能指数报告更加全面地分析了AI算法、硬件及其在商业、医疗、科学研究中的应用等重要领域。该报告关注的主要领域包括AI硬件、推理成本、学术出版和专利、企业责任AI实践、AI在科学和医学中的作用等，并强调了纵向跟踪对于理解AI发展的重要性。
### Innovation
2025年的人工智能指数报告引入了对AI硬件发展景观的深入分析，提供了新的推理成本估算，并分析了AI出版和专利趋势。此外，该报告还提供了关于企业采用负责任AI实践的最新数据，加强了对AI在科学和医学中的角色的研究。
### Conclusion
2025年人工智能指数报告在全球范围内被视为最权威的人工智能资源之一，已被主要媒体如《纽约时报》、彭博和《卫报》引用；被数百篇学术论文参考；并被全球政策制定者和政府机构使用。该指数在跟踪和解释塑造该领域的关键趋势方面处于领先地位，并持续推动人工智能研究的发展。
## 121. `cs.AI` - Conditional Reasoning框架在Answer Set Programming中的应用 [PDF](https://arxiv.org/pdf/2506.03997), [HTML](https://arxiv.org/abs/2506.03997)
### Authors
Mario Alviano,Laura Giordano,Daniele Theseider Dupré
### Background
论文建立了一个条件回答集编程框架（Conditional ASP），用于定义回答集编程（ASP）的条件扩展。它基于具有典型性的条件逻辑，并结合了条件知识库和ASP程序，允许对程序的答案集进行条件推理。正式主义基于多优先级语义（并且作为一种特殊情况基于KLM优先级语义）来解释条件术语。这项工作旨在将条件逻辑引入ASP中，以支持更灵活的推理方法，使其能够处理不确定性、典型性以及现实世界中的许多复杂情况。
### Innovation
该框架通过结合条件逻辑与ASP，提出了一个新颖的方法来扩展ASP的能力，使其能够进行条件推理。它使用多优先级语义，为条件术语提供了解释，这是一种对传统ASP方法的重要扩展。
### Conclusion
论文成功地提出了一种新颖的条件回答集编程框架，能够支持条件推理。这种方法不仅可以应用于经典的推理场景，而且可以有效地处理现实世界中的典型性和不确定性问题。该工作为ASP及其在解决复杂问题中的应用开辟了新的途径。
## 122. `cs.AI` - AI Flow：视角、情景和技术途径 [PDF](https://arxiv.org/pdf/2506.12479), [HTML](https://arxiv.org/abs/2506.12479)
### Authors
Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li
### Background
信息论奠基人香农和人工智能先驱图灵开创的信息和通信技术（IT/CT）的同步演进，产生了不间断的连接和计算浪潮。这种协同作用引发了一场技术革命，随着大型人工智能（AI）模型的出现，这场革命达到了顶峰，这些模型正在重新塑造产业，重新定义人机协作。然而，这种普遍智能的实现面临巨大挑战，包括大型模型的巨大资源消耗和高通信带宽需求。
### Innovation
AI Flow作为一种多学科框架，集成了先进的IT和CT发展，特别是：（1）设备-边缘-云框架作为基础，将终端设备、边缘服务器与云端集群结合，以优化低延迟模型推断的扩展性和效率；（2）家庭模型概念，包含一系列不同大小但具有对齐隐藏特征的模型，实现有效协作与适应不同资源约束和动态场景的灵活性；（3）基于连接和交互的智能涌现，这是AI Flow的一种新型理念，通过利用通信网络增强连接性，跨异构节点的AI模型协作实现超越单一模型能力的智能涌现。
### Conclusion
AI Flow提供增强的智能、及时的响应性和普遍的AI服务可访问性，为人工智能技术与通信系统的更紧密融合铺平了道路。
## 123. `cs.AI` - XGeM: 多提示基础模型在多模态医疗数据分析生成中的应用 [PDF](https://arxiv.org/pdf/2501.04614), [HTML](https://arxiv.org/abs/2501.04614)
### Authors
Daniele Molino,Francesco Di Feola,Eliodoro Faiella,Deborah Fazzini,Domiziana Santucci,Linlin Shen,Valerio Guarrasi,Paolo Soda
### Background
人工智能在医学影像中的应用前景广阔，但仍受到数据稀缺性、隐私问题以及需要实现强大且多模态的集成等挑战的影响。尽管生成建模的最近进展使得高质量的合成数据生成成为可能，但现有方法通常仅限于单一模态和单向合成，无法同时生成多种模态的数据以保持临床一致性。
### Innovation
引入了XGeM，一个具有6.77亿参数的多模态生成模型，设计用于支持医疗数据模态之间的灵活、任意到任意的合成。XGeM通过对比学习建立共享的潜在空间，并引入了一种新颖的多提示训练策略，使得模型可以根据输入模态的任意子集进行条件化。这一设计允许模型适应异质的临床输入并同时生成多个输出，同时保持语义和结构的连贯性。此外，XGeM还通过在MIMIC-CXR数据集上与五个竞争对手进行基准测试以及专家放射科医生的人工性图灵测试来验证其生成的医疗数据的真实性和临床相关性。此外，XGeM还展示了其在医疗数据挑战上的应用，如数据脱敏、类别不平衡和数据稀缺性，突显其作为医疗数据生成的基础模型的实用性。
### Conclusion
通过广泛验证，XGeM在多个方面得到了确认，能够在多样化的临床数据场景中生成高质量且符合实际需求的数据。此外，XGeM还表明了其在处理医疗数据特定挑战方面的潜力，阐明了其作为医疗数据合成基础模型的价值。
## 124. `cs.AI` - 大语言模型时代的自动形式化：综述 [PDF](https://arxiv.org/pdf/2505.23486), [HTML](https://arxiv.org/abs/2505.23486)
### Authors
Ke Weng,Lun Du,Sirui Li,Wangyue Lu,Haozhe Sun,Hengyu Liu,Tiancheng Zhang
### Background
自动形式化是指将非形式化的数学命题转化为可验证的形式化表示的过程，是自动化定理证明的基础任务。随着人工智能尤其是大规模语言模型（LLMs）的快速发展，这一领域取得了显著进展。这不仅带来了新的机会，也带来了独特的挑战。本文旨在对自动形式化的最新进展进行系统回顾，涵盖数学和LLM视角，并探讨其在不同数学领域和不同难度的应用，以及从数据预处理、模型设计和评估的全流程分析。此外，本文还研究了自动形式化在增强LLM生成输出的可验证性方面的新兴作用，突出了它在提升LLM的可信性和推理能力方面的潜力。最后，本文总结了支持当前研究的关键开源模型和数据集，并讨论了该领域面临的开放挑战和未来的研究方向。
### Innovation
本文提供了一个全面的视角，对自动形式化领域的最新进展进行了总结，特别突出了其在不同数学领域和难度级别上的应用，并详细分析了从数据预处理到模型设计和评估的全流程。此外，本文还深入探讨了自动形式化在增强LLM生成输出的可验证性方面的作用，强调了它在提高LLM的可信度和推理能力方面的潜力。
### Conclusion
本文总结了支持当前研究的关键开源模型和数据集，并讨论了自动形式化领域面临的开放挑战和未来的研究方向。
## 125. `cs.AI` - Agentic AI 过程可观测性：发现行为变化 [PDF](https://arxiv.org/pdf/2505.20127), [HTML](https://arxiv.org/abs/2505.20127)
### Authors
Fabiana Fournier,Lior Limonad,Yuval David
### Background
日益增长的大型语言模型（LLMs）驱动的人工智能代理正在成为现代软件系统的核心构建块。许多框架现已可用以支持这些应用的规范。通过使用自然语言提示，这些框架可以定义包含各个代理角色、目标和工具的代理设置。然而，给定输入时，代理行为是非确定性的，因此需要更强的调试和可观测性工具来提供更好的监控和理解。基于这些背景，本文探索了过程和因果发现在代理执行轨迹中的应用，以增强开发者的可观测性能力。这种方法有助于监测和理解代理行为中的变化，并通过 LLM 基准静态分析技术来区分预期和非预期的变化。这些技术的使用为开发者提供了对不断演化的规范的更大控制，并且有助于识别需要更加精确和明确的定义的方面。
### Innovation
本文探讨了一种新的方法，即通过过程和因果发现分析代理执行轨迹，来增强开发者对其行为变化进行监测和理解的能力。这种方法结合了LLM的静态分析技术，以区分预期和非预期的变化，为开发者提供了更好的控制和明确的功能定义。
### Conclusion
本文展示了过程和因果发现技术在提升开发者对Agent行为变化的可观测性方面的有效性。通过这种方法，开发者可以更好地识别和定义系统的功能需求，从而提高系统的可靠性和可维护性。为了实现这一目标，还需要进一步的研究来开发和优化相关工具，以满足不断变化的软件开发需求。
## 126. `cs.AI` - 具身体验的AI代理：建模世界 [PDF](https://arxiv.org/pdf/2506.22355), [HTML](https://arxiv.org/abs/2506.22355)
### Authors
Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hongyu Gong,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Louis-Philippe Morency,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Paden Tomasello,Jitendra Malik
### Background
本文讨论了将AI代理以视觉、虚拟或物理形式体现的研究，使其能够与用户及其环境进行互动。这些代理包括虚拟化身、可穿戴设备和机器人，目的是使它们能够感知、学习并在其环境内采取行动，从而更加接近人类如何学习和与环境互动的方式。这一背景还提到了 disembodied（脱体的）代理与实体代理的区别，并强调世界模型在推理和计划中的重要性，使这些代理能够更好地理解环境、预测环境变化，从而更好地理解用户的意图和社会背景，提升其执行复杂任务的能力。此外，讨论了超越物理世界，需要学习用户心智世界模型的重要性，以促进更好的人机协作。
### Innovation
本文提出世界模型在实体AI代理中的关键作用，使这些代理能够构建对物理世界的综合理解。更重要的是，强调理解用户的心智世界模型，以实现更高效的人-机器协作。
### Conclusion
本研究强调世界模型在实体AI代理中的重要性，通过建模不仅增强AI代理对物理环境的理解，而且能够更好地理解人类用户的意图和社会背景，从而提升其执行复杂任务的能力。同时，还提出通过建模用户的心智世界来进一步改善人机协作。
## 127. `cs.AI` - Mind2Web 2: 以代理人为裁判评估有机关方搜索 [PDF](https://arxiv.org/pdf/2506.21506), [HTML](https://arxiv.org/abs/2506.21506)
### Authors
Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su
### Background
有机关方搜索系统，例如Deep Research系统，自主浏览网络、综合信息并返回全面的引用支持答案，代表了用户与大规模网络信息交互方式的重大转变。虽然这种搜索方法提高了效率和认知卸载，但其日益复杂和开放的特性已经超越了现有评估基准和方法的适用范围，现有方法大多假设短查询时间和静态答案。因此，需要新的评估基准和方法来应对时间变化和复杂的答案评估挑战。
### Innovation
Mind2Web 2基准，包括130个高质、高实时要求和长时间查询任务，通过超过1000小时的人工劳动构建。提出了一种全新的‘代理人为裁判’框架，基于树形结构评分表设计构建特定任务的裁判代理，自动评估答案的正确性和来源归因。此外，进行了十个前沿有机关方搜索系统的全面评估和详细错误分析，为未来的发展提供了见解。最好系统OpenAI Deep Research已达到人类表现的50-70%，并将所需时间减少了50%。
### Conclusion
Mind2Web 2为开发和验证下一代有机关方搜索系统提供了严格的评估基础。
## 128. `cs.AI` - 通过求助避免在线学习中的灾难 [PDF](https://arxiv.org/pdf/2402.08062), [HTML](https://arxiv.org/abs/2402.08062)
### Authors
Benjamin Plaut,Hanlin Zhu,Stuart Russell
### Background
大多数具有正式遗憾保证的学习算法假定所有错误都是可恢复的，并且基本上依赖于尝试所有可能的行为。然而，当某些错误是“灾难性的”，即不可修复的时，这种做法是有问题的。本文提出了一个在线学习问题，目标是最小化发生灾难的机会，具体来说，假设每轮的收益表示避免当前轮次灾难的机会，并尽量使各轮收益的乘积最大化，同时允许向导师有限次咨询。此外，假设智能体可以在相似输入之间转移知识。研究表明，在一般情况下，任何算法要么以线性率咨询导师，要么几乎肯定会导致灾难。但在导师策略类可以在标准在线模型中学习的情况下，提供了两种近似率为0的算法方案，一种控制为0遗憾，另一种控制咨询导师的频率为0。概念上讲，如果在没有灾难风险的情况下可以学习策略类，则在存在灾难风险的情况下，智能体可以寻求协助从而也可以学习该策略类。
### Innovation
提出了一个在线学习问题，目标是最小化发生灾难的机会。算法设计允许有限次向导师咨询，并且可以转移知识于相似输入之间。该研究的核心创新是在存在“不可逆”的灾难性错误情况下，通过向智能代理提供有限的查询机会，指出了一种有效减少灾难风险的策略，从而引入了“灾难避免”的全新视角，并提供了在一定条件下接近无遗憾的学习算法方案。
### Conclusion
在某些设定下，即使存在灾难性风险，只要可以咨询导师，并且能在标准在线模型中学习导师政策类，算法的遗憾与咨询频率近似于0，表明合理利用外部知识可以增强系统学习能力，特别是在具有灾难性风险的环境中。
## 129. `cs.AI` - 通过预测不确定性教师学习和学生-学生协作学习提高远监督命名实体识别的鲁棒性 [PDF](https://arxiv.org/pdf/2311.08010), [HTML](https://arxiv.org/abs/2311.08010)
### Authors
Shuzheng Si,Helan Hu,Haozhe Zhao,Shuang Zeng,Kaikai An,Zefan Cai,Baobao Chang
### Background
远监督命名实体识别（DS-NER）在现实场景中被广泛应用，它通过匹配现有知识库中的实体与文本片段来减少标注负担，但存在标签噪声的问题。近年来，尝试采用教师-学生框架逐步细化训练标签，提高整体鲁棒性，但这些方法由于教师网络校准不佳，产生了错误的伪标签样本，导致错误传播。
### Innovation
本文提出两种创新方法：（1）预测不确定性的教师学习，利用预测不确定性减少自我训练阶段的错误伪标签数量；（2）学生-学生协作学习，允许两个学生网络之间可靠标签的转移，无需盲目依赖所有来自教师的伪标签，进一步实现对误标样本的全面探索，而非仅筛选不可靠的伪标签样本。
### Conclusion
本文方法在五个DS-NER数据集上进行评估，结果表明本方法优于现有的DS-NER方法。
## 130. `cs.AI` - 核密度贝叶斯逆强化学习 [PDF](https://arxiv.org/pdf/2303.06827), [HTML](https://arxiv.org/abs/2303.06827)
### Authors
Aishwarya Mandyam,Didong Li,Jiayu Yao,Diana Cai,Andrew Jones,Barbara E. Engelhardt
### Background
逆强化学习（IRL）方法通过专家行为的示例来推断代理的奖励函数。传统的贝叶斯IRL算法需要大量的示例数据集，但在某些情况下，如涉及临床数据的应用中，可能无法获取这些数据集。本文研究的是一个常见的临床和生物应用情况，即有专家示范和已知训练任务奖励函数的数据，但需要根据有限的专家示范来推断新的测试任务的奖励函数。现有的贝叶斯IRL方法在输入数据的形式上存在限制，限制了训练任务数据的结合。
### Innovation
本文引入了核密度贝叶斯逆强化学习（KD-BIRL），该方法使用已知训练任务奖励函数的条件核密度估计器，以提高各种奖励函数和演示样本下的似然估计，特别在测试任务难以获得专家示范数据的情况下加快了后验收敛速度。这是首次为贝叶斯IRL算法提供后验收敛理论保证。该研究为贝叶斯IRL在不同领域的应用提供了一个原理性和理论依据的框架。
### Conclusion
本文提出了一种核密度贝叶斯逆强化学习方法，能够更好地利用训练任务的信息，并且首次为贝叶斯IRL算法提供理论上的后验集中证明。该方法适用于多种领域，并提出了一种原理性的方法来优化IRL过程，提高了算法应用的效率和有效性。
## 131. `cs.AI` - 超越规模：作为自然语言数据变异性数据质量度量的多样性系数 [PDF](https://arxiv.org/pdf/2306.13840), [HTML](https://arxiv.org/abs/2306.13840)
### Authors
Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo
### Background
当前大语言模型（LLMs）的主要趋势集中在模型和数据集规模的扩大。虽然预训练数据的质量被认为是对训练强大LLMs的重要因素，但其仍然是一个模糊的概念，尚未严格定义。现有的研究主要侧重于模型和数据集的规模，而对数据质量本身的深入探讨还不够充分，特别是关于数据多样性和变异性方面缺乏系统的度量方法。本文旨在填补这一空白，提出一种定量评估数据多样性和变异性的方法，即多样性系数，以期提高模型性能的评估效果并促进LLMs的发展。
### Innovation
本文创新性地提出了一个用于量化自然语言数据多样性和变异性的新度量标准——多样性系数。通过实验验证，该系数能反映多样性和变异性的一些直观特性，如随着潜在概念数量的增加而增加。此外，通过测量公开可用的预训练数据集的多样性系数，本文展示了这些数据集的正式多样性高于理论上下限，证明了多样性系数在预训练数据的质量评估中具有重要意义。进一步的实验表明，多样性系数对下游模型评估性能具有有益影响，涵盖了从51M到7B参数的44个不同规模的模型。
### Conclusion
研究表明，我们正式定义的多样性是一项重要数据质量指标，能够捕捉数据的变异性，并且此类多样性能够因果地促进评估性能的提升。
## 132. `cs.AI` - 基于序列感知的超声心动图探头运动预训练 [PDF](https://arxiv.org/pdf/2408.15026), [HTML](https://arxiv.org/abs/2408.15026)
### Authors
Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang
### Background
超声心动图是诊断心血管疾病不可或缺的医疗技术，但由于其高操作复杂性导致训练专业人员短缺。心脏的复杂结构和个体间显著差异是超声心动图面临的两大挑战。以往工作仅学习了心脏的群体平均结构，而非个性化的心脏结构，导致性能受限。在临床实践中，超声医生会根据之前的扫描序列动态调整对患者心脏解剖的解释，进而优化扫描策略。本文分析了这一现象并提出一种基于序列感知的半监督预训练方法。这种方法能够学习个性化的三维心脏结构特征，通过预测扫描序列中的遮罩图像特征和探头运动动作来实现。实验结果表明，这种方法在减少探头指引误差方面优于其他先进基准方法。
### Innovation
提出了一种基于序列感知的半监督预训练方法，用于超声心动图探头运动指导。该方法能够学习个性化的三维心脏结构特征，通过预测扫描序列中的遮罩图像特征和探头运动动作来实现。这一技术可应用于引导机器人系统或初级操作者进行探头位置调整，以获得高质量的标准切面图像。
### Conclusion
对一个包含131万样本的大规模专家扫描数据集进行的广泛实验表明，本文提出的基于序列感知的预训练方法在减少探头指引误差方面优于其他先进基准方法。该方法可以在不需要大量标记数据的情况下，有效地提高超声心动图中的探头运动精度和图像质量。
## 133. `cs.AI` - 来自嘈杂众包标签的信号处理视角的学习 [PDF](https://arxiv.org/pdf/2407.06902), [HTML](https://arxiv.org/abs/2407.06902)
### Authors
Shahana Ibrahim,Panagiotis A. Traganitis,Xiao Fu,Georgios B. Giannakis
### Background
随着人工智能（AI）和机器学习（ML）的发展，大规模结构化的数据集变得愈加可用，这是许多进步的驱动力。数据聚合是这些大数据集的一种常见处理手段，来自多个标注者的标注数据会被汇集以服务于底层学习和推断任务。然而，这一标注过程往往会由于标注者经验有限或不可靠等原因产生噪声标签，因此，如何有效应对这些噪声标签对学习任务的负面影响成为一个关键问题。本文介绍的这项研究关注于如何从嘈杂的众包标记中进行学习的进展，重点在于经典统计模型与最近的深度学习方法之间的连接，并强调了理论洞察和算法发展。
### Innovation
该文在信号处理理论和方法论中，特别探讨了标识张量和非负矩阵分解等理论，以及如何将这些理论应用于解决长期以来的众包问题。作者还强调了深度学习与信号处理理论在应对噪声标签方面的连接，并介绍了直接偏好优化（DPO）和强化学习与人类反馈（RLHF）等新兴技术对于构建前沿AI/ML系统的重要性
### Conclusion
文章陈述了信号处理视角在从嘈杂众包标记中学习研究中的重要性，并展示了如何将这些视角应用于传统的统计模型和新兴的深度学习方法，从而推进了这一领域的技术进步。
## 134. `cs.AI` - 在工业测试维护过程中探索大型语言模型的应用 [PDF](https://arxiv.org/pdf/2409.06416), [HTML](https://arxiv.org/abs/2409.06416)
### Authors
Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg
### Background
在软件测试过程中，很大一部分成本和努力都投入到测试维护中，即对测试案例进行增删改操作以使测试套件与系统保持同步或提升测试质量。工具支持可以降低测试维护成本并提高其质量，通过自动化测试维护过程的部分环节或提供开发者的指导和支持。因此，研究团队探索了大型语言模型（LLMs）的能力和应用，这些模型是适应文本分析的复杂机器学习模型，研究团队在爱立信公司进行了一项案例研究，探讨触发测试维护需求的因素、LLMs可以采取的行动以及在工业环境中部署LLMs时需要考虑的因素。研究还提出并证明了一个多代理架构，能够预测代码更改后哪些测试需要维护。所有这些贡献都提升了我们对如何部署LLM以受益于工业测试维护过程的理解。
### Innovation
研究团队探索了大型语言模型（LLMs）在测试维护中的应用，特别是在预测代码更改后哪些测试需要维护方面提出了一个多代理架构。这些研究揭示了LLMs如何有效支持工业环境下的测试维护过程，具有重要的理论及实际应用价值。
### Conclusion
研究团队的工作推进了对我们如何部署大型语言模型以支持工业测试维护过程的理解。通过案例研究，研究团队验证了LLMs在工业测试维护中的多方面应用，表明其在降低测试维护成本、提高测试质量和提升软件开发效率方面具有巨大潜力。
## 135. `cs.AI` - 向XAI系统用户信任的新度量方法 [PDF](https://arxiv.org/pdf/2405.05766), [HTML](https://arxiv.org/abs/2405.05766)
### Authors
Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho
### Background
随着深度学习模型的应用日益广泛，其固有的不透明性引发了对可解释人工智能（XAI）方法的需求，以提高最终用户对自动化系统的信任。本文提出了一个新的度量方法来细化XAI系统中的信任评价，该方法结合了性能指标和客观的信任指标。为了验证这一方法的有效性，作者进行了三项案例研究，结果显示该方法在不同场景下具有更高的敏感度，且优于现有方法。
### Innovation
提出了一种新的信任度量方法，结合了性能指标和客观的信任指标，旨在提高XAI系统的用户信任度。通过三项案例研究，证明了该方法的有效性和优越性，特别是在对不同情景的敏感度上有显著提高。
### Conclusion
本文提出了一种新的度量方法，有效提升了XAI系统的用户信任度。未来的方向是将该方法应用到更多实际场景中，进一步验证其鲁棒性和适用性。
## 136. `cs.AI` - Anatomical Foundation Models for Brain MRIs [PDF](https://arxiv.org/pdf/2408.07079), [HTML](https://arxiv.org/abs/2408.07079)
### Authors
Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto
### Background
深度学习在神经影像学中用于检测神经性疾病和神经退行性疾病越来越相关。大脑年龄（大脑年龄是神经影像学中一个最常见的生物标记物）已被证明是不同条件的良好指标，如阿尔茨海默病。使用大脑年龄对弱监督预训练的深度学习模型在迁移学习设置中也显示出很有希望的结果，特别是在不同条件数据稀缺的情况下。同时，脑MRI的解剖信息（例如皮质厚度）可以提供重要的信息，用以学习可以转移到许多下游任务的良好表示。
### Innovation
本文提出AnatCL，一种用于脑MRI的解剖基础模型，它(i)在弱对比学习方法中利用了解剖信息，并(ii)在许多不同的下游任务中实现了最先进的性能。该方法在多种不同的条件下进行验证，包括阿尔茨海默病、自闭症谱系障碍和精神分裂症的诊断，以及使用结构MRI数据预测10种不同的临床评估分数。研究表明，在预训练过程中融入解剖信息可以导致更稳健和更具泛化性的表示。
### Conclusion
预训练模型可以在以下网址找到：(提供网址部分的链接内容)。
## 137. `cs.AI` - 使用潜在类别分析量化多组跨领域交错差异以实现公平性 [PDF](https://arxiv.org/pdf/2407.03133), [HTML](https://arxiv.org/abs/2407.03133)
### Authors
Yingfang Yuan,Kefan Chen,Mehdi Rizvi,Lynne Baillie,Wei Pang
### Background
公平AI的发展日益受到关注。'不让任何人掉队'倡议强调了在获取服务、资源和机会过程中解决多种交叉形式不平等的重要性，特别是在越来越多的AI工具被应用于决策过程中的资源分配和服务方案开发的情况下，这些工具涉及到健康、能源和住房等多个领域。因此，探讨这些领域的联合不平等对于全面理解整体不平等和不公平具有重要意义。
### Innovation
该研究提出了一个创新的方法，使用潜在类别分析来量化用户定义组之间在多个领域的交叉差异。这种方法可以用来近似不平等和公平性问题，通过使用自有数据集和公共数据集进行验证，该方法还通过与政府公共指标进行相关性分析，进一步证明了其可靠性。研究发现跨不同种族组别之间存在显著差异，尤其是少数族裔组别内部和少数族裔组别与非少数族裔组别之间的差异，强调了政策制定过程中需要针对性的干预措施。此外，该方法还展示了如何为确保机器学习系统的公平性提供有价值见解。
### Conclusion
该研究表明，利用潜在类别分析可以量化多组之间跨领域的差异，为理解整体不平等和公平性问题提供重要依据，并为政策制定和机器学习系统中的公平性提供有价值的信息。
## 138. `cs.AI` - 重新审视脉冲神经网络的能效 [PDF](https://arxiv.org/pdf/2409.08290), [HTML](https://arxiv.org/abs/2409.08290)
### Authors
Zhanglu Yan,Zhenyu Bai,Weng-Fai Wong
### Background
脉冲神经网络（SNNs）因基于事件的脉冲计算方式相比量化人工神经网络（QNNs）在能耗上有潜在优势，但现有的能耗评估常常过于简化，主要集中在计算方面，忽略如全面的数据移动和内存访问等关键部分。这些简化可能导致对于SNNs实际能效优势的误解。因此，有必要进行一个更为严格和公正的再评估，以提供可靠的能效对比分析。
### Innovation
本文通过将以速率编码的SNNs与功能等效的QNNs进行映射，设定一个公正的基准，并引入了一个涵盖核心计算和数据移动的详细分析能耗模型。模型考虑了网络特性和硬件特性中一系列参数的影响，从而识别出特定的操作模式，使得SNNs能够在一定条件下表现出真正的能耗优势，具体实例如在典型的类神经元硬件条件下，SNNs需要在平均脉冲率低于6.4%的情况下，才可能优于等效的QNNs。这些研究结果能有效指导设计真正高效的神经网络解决方案。
### Conclusion
本文的研究在理解SNNs的能效方面提供了具体而深入的指导，尤其是在特定的操作条件下，SNNs能够展现真正的能耗优势。进一步地，它为设计能耗更高效的神经网络提供了重要的见解和指导。
## 139. `cs.AI` - 基于离线强化学习的作业调度学习方法 [PDF](https://arxiv.org/pdf/2409.10589), [HTML](https://arxiv.org/abs/2409.10589)
### Authors
Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang
### Background
JSSP是一个复杂的组合优化问题。尽管在线强化学习（RL）已显示出迅速找到JSSP可接受解决方案的潜力，但它面临着关键挑战：需要大量的从头开始的训练交互，导致样本效率低下；无法利用传统方法（如约束编程CP）中的现有高质量解决方案；以及需要模拟环境进行训练，而为复杂的调度环境构建模拟环境是不切实际的。
### Innovation
本文提出了离线学习调度（Offline-LD），一种基于离线强化学习的JSSP方法。该方法通过使用历史调度数据来解决上述限制。除此之外，还介绍了两种可学习的历史数据方法的掩码变体，即掩码分位数回归深度Q学习（mQRDQN）和离散掩码软演员-评论家（d-mSAC），并通过保守Q学习（CQL）方法来学习历史数据。此外，还提出了d-mSAC用于掩码动作空间的新颖熵奖励修改，并引入了在离线RL设置中JSSP的新型奖励标准化方法。实验结果表明，当仅使用100个由CP生成的解决方案进行训练时，Offline-LD在生成数据和基准数据上均优于在线RL，并且在引入噪声到专家数据集时，结果与使用专家数据集相似或更优，这在实际应用场景中具有潜在优势，因为数据通常具有固有的噪声和不完美性。
### Conclusion
研究证实了Offline-LD在JSSP中的有效性，尤其是在有限的历史数据条件下。该方法通过利用历史数据显著提高了离线强化学习在复杂调度环境中的性能。
## 140. `cs.AI` - 是复杂的查询回答真的复杂吗？ [PDF](https://arxiv.org/pdf/2410.12537), [HTML](https://arxiv.org/abs/2410.12537)
### Authors
Cosimo Gregucci,Bo Xiong,Daniel Hernandez,Lorenzo Loconte,Pasquale Minervini,Steffen Staab,Antonio Vergari
### Background
知识图谱（KGs）上的复杂查询回答（CQA）正逐渐成为一项具有挑战性的推理任务。当前用于CQA的基准可能没有我们想象的那样复杂，因为这些基准的构建方式扭曲了我们在该领域取得进步的感知。许多查询可以简化为更简单的问题，如链接预测，只需预测一个链接即可。当评估基于状态的艺术（SOTA）CQA模型无法将其简化为更简单类型的问题时，模型的性能显著下降。因此，提出了一组更具挑战性的基准，包含需要模型跨多个跳跃进行推理的查询，以更好地反映现实世界KG的构建情况。
### Innovation
提出了新的基准，包含需要模型跨多个跳跃进行推理的查询，以更好地反映现实世界KG的构建情况，从而更准确地评估当前CQA方法的能力。
### Conclusion
新的基准显示，当前的方法在复杂的查询回答方面远远不够理想。
## 141. `cs.AI` - 通过超额词汇探究生物医学出版物中的LLM辅助写作 [PDF](https://arxiv.org/pdf/2406.07016), [HTML](https://arxiv.org/abs/2406.07016)
### Authors
Dmitry Kobak,Rita González-Márquez,Emőke-Ágnes Horvát,Jan Lause
### Background
大型语言模型（LLMs）如ChatGPT能够生成和修订与人类水平相当的文本。这些模型存在明显的局限性：它们可能产生不准确的信息、强化现有的偏见，并且容易被滥用。但许多科学家还是在他们的学术写作中使用这些模型。那么，这类LLM的使用在学术文献中有多普遍？为了回答这个问题，特别是在生物医学研究领域，我们提出了一种无偏见、大规模的办法：研究2010年至2024年由PubMed索引的超过1500万篇生物医学摘要中的词汇变化，并展示了LLM的出现导致了某些风格词汇频率的突然增加。通过超额词分析，我们发现至少有13.5%的2024年摘要使用了LLM。不同学科、国家和期刊之间的下限差异显著，某些子集合中的比例达到了40%。我们展示了LLM对生物医学研究领域的科学写作产生了前所未有的影响，其影响甚至超过了如COVID疫情这样的重大世界事件。
### Innovation
该研究通过分析大量的生物医学摘要数据，提出了一种全新的、无偏见的方法来评估LLM在学术写作中的应用频率。特别地，通过识别特定风格词汇频率的骤增，研究人员估算出至少13.5%的2024年摘要使用了LLM，并且这种影响在不同学科和期刊中存在显著差异，甚至超过了类似COVID疫情的重大事件影响。
### Conclusion
研究结果表明，LLM在生物医学研究中的使用已经产生了前所未有的影响，对科学写作的改变远超预期，并且这种趋势随着不同学科、国家和期刊的差异而变化。未来将有越来越多的学术研究转向使用LLM，理解这种技术的深入应用对于学术界和社会非常重要。
## 142. `cs.AI` - 基于语义-拓扑-度量表示引导的大语言模型推理的空中视觉-语言导航 [PDF](https://arxiv.org/pdf/2410.08500), [HTML](https://arxiv.org/abs/2410.08500)
### Authors
Yunpeng Gao,Zhigang Wang,Linglin Jing,Dong Wang,Xuelong Li,Bin Zhao
### Background
空中视觉-语言导航（Aerial Vision-and-Language Navigation, VLN）是让无人机通过自然语言指令和视觉线索在户外环境中进行导航的一个新颖任务。由于户外空中场景中的复杂空间关系，该任务仍然具有挑战性。现有的方法在处理空中场景的复杂性方面仍存在不足，特别是在空间推理方面。本文旨在提出一种端到端的零样本框架，引入大语言模型（LLM）作为执行动作预测的代理，并通过语义-拓扑-度量表示增强LLM的空间推理能力，旨在解决这一挑战。
### Innovation
提出了一个基于语义-拓扑-度量表示的方法，用于增强大语言模型的空间推理能力。该方法涉及以下创新点：1. 开发了一种新型的语义-拓扑-度量表示（Semantic-Topo-Metric Representation, STMR），这有助于提取和投影与指令相关的地标语义掩码到包含周围地标位置信息的俯视图地图上。2. 将该地图转换为矩阵表示，并使用距离度量作为文本提示输入给大语言模型，以根据指令进行动作预测。3. 引入大语言模型作为代理进行动作预测，这进一步提高了模型执行空中导航任务的能力。
### Conclusion
实验结果表明，该方法在现实和模拟环境中均有效且鲁棒性强，能够在封闭室环境的AerialVLN-S数据集上实现Oracle Success Rate (OSR) 的15.9%和12.5%的绝对提升。
## 143. `cs.AI` - GeMID：跨网络环境通用的IoT设备识别模型 [PDF](https://arxiv.org/pdf/2411.14441), [HTML](https://arxiv.org/abs/2411.14441)
### Authors
Kahraman Kostas,Rabia Yasa Kostas,Mike Just,Michael A. Lones
### Background
随着物联网（IoT）设备的增多，保障其安全性变得至关重要。设备识别（DI）基于流量模式区分不同设备并识别脆弱设备，填补了安全漏洞。然而，现有基于机器学习的DI方法往往忽视了模型在跨不同网络环境时的一般化问题，导致模型泛化能力弱。
### Innovation
本文提出了一种新颖框架，旨在解决上述局限性，评估不同网络环境中收集的数据集上DI模型的一般化能力。该方法分为两步：首先，利用遗传算法和外部反馈以及来自不同环境的数据集，开发一种更健壮的特征和模型选择方法来改进泛化。其次，模型在进一步独立数据集上测试以更好地评估其一般化能力。实验表明，基于滑动窗口和流量统计的方法存在局限性，而统计方法依赖特定网络特征而非设备固有属性，导致现有许多研究的部分可靠性问题。
### Conclusion
该研究推进了物联网安全和设备识别领域的研究，提供了提升模型效率和减轻物联网网络风险的见解。
## 144. `cs.AI` - 在树基遗传编程中实现种群级并行性以实现全面的GPU加速 [PDF](https://arxiv.org/pdf/2501.17168), [HTML](https://arxiv.org/abs/2501.17168)
### Authors
Zhihong Wu,Lishuang Wang,Kebin Sun,Zhuozhao Li,Ran Cheng
### Background
树基遗传编程（TGP）是一种广泛应用于符号回归、分类和机器人控制等任务的进化算法。由于TGP运行时的计算需求密集，GPU加速对于实现可扩展性能至关重要。然而，高效地将TGP进行GPU加速仍然极具挑战性，主要由于三个核心问题：（1）程序个体的结构性异质性，（2）多级并行性的复杂集成，和（3）高性能CUDA执行与灵活的Python环境之间的不兼容性。
### Innovation
为了解决这些问题，本文提出了EvoGP，这是一个高效率框架，通过种群级并行执行为TGP提供全面的GPU加速。EvoGP从三个方面进行创新：第一，EvoGP引入张量表示，将可变尺寸的树编码为固定形状、对齐的数组，以实现统一的内存访问和多样的个体并行计算；第二，EvoGP采用自适应并行策略，根据数据集大小动态结合个体内部和个体之间的并行性，确保广泛的任务中高GPU利用率；第三，EvoGP将自定义CUDA内核嵌入PyTorch运行时，实现与Gym、MuJoCo、Brax和Genesis等基于Python的环境的无缝集成。
### Conclusion
全面实验表明，EvoGP相较于最先进的GPU加速TGP实现，速度最高可提升140倍，同时保持竞争力的准确度，并且在大规模种群下显著提高可扩展性。EvoGP开源并可以在 this https URL 获取。
## 145. `cs.AI` - COEF-VQ: 一种通过级联多模态LLM框架实现高效视频质量理解 [PDF](https://arxiv.org/pdf/2412.10435), [HTML](https://arxiv.org/abs/2412.10435)
### Authors
Xin Dong,Sen Jia,Ming Rui Wang,Yan Li,Zhenheng Yang,Bingfeng Deng,Hongyu Xiong
### Background
最近，随着多模态大规模语言模型(MLLM)技术的发展，利用其视频理解能力进行不同分类任务已成为可能。然而，要在在线环境中部署MLLM时，会对GPU资源产生巨大的需求，这是实践中面临的一个挑战。为了解决这一问题，本文提出了COEF-VQ，这是一种新型的级联MLLM框架，旨在在短视频平台上提升视频质量理解的同时，优化计算效率。该框架包含一个基于熵的预过滤阶段，轻量级模型在此阶段评估不确定性并选择性地过滤情况，然后将这些情况传递给计算更加复杂的MLLM进行最终评估。通过优先处理高不确定性样本进行深度分析，我们的框架显著减少了GPU使用量，同时保持了全MLLM部署的强大分类性能。
### Innovation
COEF-VQ框架通过引入基于熵的预过滤阶段，它可以高效地处理视频质量理解任务，同时减少对GPU资源的依赖。该框架在保持高性能的同时，显著降低了部署成本和资源消耗，尤其是在在线环境中。
### Conclusion
通过将COEF-VQ部署到短视频平台的视频管理平台(VMP)上，并在两个内部视频质量理解任务上进行了一系列详细的实验，结果表明，COEF-VQ在离线评估中产生了显著的性能提升，有效地增强了平台安全性，减少了9.9%的不当内容视频查看率，而且在线A/B测试并没有影响用户参与度。部署后持续监测证实了这些改进的效果，验证了其在实际应用中的影响。
## 146. `cs.AI` - Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation [PDF](https://arxiv.org/pdf/2411.00863), [HTML](https://arxiv.org/abs/2411.00863)
### Authors
Chenyang An,Shima Imani,Feng Yao,Chengyu Dong,Ali Abbasi,Harsh Shrivastava,Samuel Buss,Jingbo Shang,Gayathri Mahalingam,Pramod Sharma,Maurice Diesendruck
### Background
在基于大规模语言模型（LLM）的证明生成领域，尽管已经对大量数据集如ArXiv进行了广泛的训练，但LLMs在处理中等难度的证明任务时表现出的性能仍然有限。这主要是因为每条证明在训练数据中普遍存在的不理想的顺序。已有的证明通常遵循纯逻辑顺序，每一步骤都是基于演绎规则从上一步骤合理地推导出来的。这种顺序是为了易于证明的验证，而不是帮助人们和模型学习证明发现过程。因此，在证明生成任务中，我们提出了一个关于每个证明训练样本的最佳顺序假设，即在证明中每个步骤相关的必要中间监督信息总是位于这个证明步骤的左侧，我们称之为直观顺序。通过实验验证了这一假设在逻辑命题定理证明和数字乘法任务中的有效性，证明了证明处于直观顺序时训练效果最佳，特别是在命题逻辑定理证明任务中表现出了显著的性能提升。我们还定义了一种高级数学证明中的常见顺序问题，并发现广泛使用的研究生数学教材前两章中的17.3%的定理不适合这种顺序。这些证明的详细列表见附录。
### Innovation
提出并验证了证明的直观顺序假设，即在证明中每个步骤相关的必要中间监督信息总是出现在该证明步骤的左侧，这是现有逻辑顺序的一种改进，旨在更好地支持证明发现过程的学习。实验表明，处于直观顺序时的证明训练效果最佳，特别是在命题逻辑定理证明任务中，最佳排序相比最差排序的证明成功率提高了11%。此外，提出了一种高级数学证明中的常见顺序问题，揭示了广泛使用的研究生数学教材中17.3%的定理存在此类问题。
### Conclusion
我们的实验验证了证明处于直观顺序时训练效果最佳，特别是在命题逻辑定理证明任务中表现出了显著的性能提升。此外，我们指出了一种高级数学证明中的常见顺序问题，即许多定理不适合直观顺序，这可能是其证明过程中存在显著优化空间的原因。未来的工作可以设计新的方法来帮助模型更好地学习和生成证明。
## 147. `cs.AI` - 从生成模型学习实时观察中的交通异常 [PDF](https://arxiv.org/pdf/2502.01391), [HTML](https://arxiv.org/abs/2502.01391)
### Authors
Fotis I. Giasemis,Alexandros Sopasakis
### Background
准确检测交通异常对于有效的城市交通管理和缓解拥堵至关重要。本文利用结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架来捕捉交通数据中的复杂时空依赖关系。研究使用来自瑞典哥本哈根42个交通摄像头的实时、分钟级观察数据，数据分析期为2020年几个月份。通过处理图像数据，计算表示车辆密度的流度指标，作为输入模型的数据。模型在2020年4月到11月的数据上进行训练，并在2020年11月14日至23日的数据上进行验证。实验结果表明，该模型能够有效检测交通异常，精度高且误报率低。检测到的异常包括摄像头信号中断、视觉伪影以及极端天气条件对交通流的影响等。
### Innovation
本文创新性地采用结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，有效捕捉交通数据中的时空依赖关系，并应用于瑞典哥本哈根地区的实际交通摄像头数据，实现了高精度和低误报率的交通异常检测。
### Conclusion
该研究证明了STGAN在交通异常检测中的有效性，并为未来的交通管理和智能系统开发提供了有力的数据支持和模型框架。
## 148. `cs.AI` - 参数量 vs FLOPs：Mixture-of-Experts 语言模型中的最优稀疏度缩放定律 [PDF](https://arxiv.org/pdf/2501.12370), [HTML](https://arxiv.org/abs/2501.12370)
### Authors
Samira Abnar,Harshay Shah,Dan Busbridge,Alaaeldin Mohamed Elnouby Ali,Josh Susskind,Vimal Thilak
### Background
语言模型的容量扩展一直是一种可靠的方法，以提高性能并解锁新功能。容量主要由两个维度定义：模型参数的数量和每个示例的计算量。扩展通常会增加这两个因素，但这些因素之间的相互作用以及它们对总体容量的贡献仍不完全明确。本文在稀疏 Mixture-of-Experts (MoEs) 的背景下研究了这些关系，稀疏 MoEs 允许在不按比例增加每例 FLOPs 的情况下扩展参数数量。研究表明，在不同的约束条件下（例如，参数大小和总训练计算量），存在一个最优的稀疏度水平，这可以提高训练效率和模型性能。这些结果有助于更好地理解 Mixture-of-Experts 中的缩放定律中稀疏度的影响，并补充了该领域的现有工作，提供了设计更高效架构的见解。
### Innovation
本文探索了在稀疏 Mixture-of-Experts (MoEs) 中，不同稀疏度水平对模型性能的影响，特别是在预训练和下游少样本评估中的性能。研究发现，在不同的约束条件下，存在一个最优的稀疏度水平，这可以提高训练效率和模型性能。这一研究提供了有关 Mixture-of-Experts 中缩放定律中稀疏度影响的更好理解，并补充现有工作，为设计更高效的架构提供了见解。
### Conclusion
在不同的约束条件下，Mixture-of-Experts 模型存在最优的稀疏度水平，该稀疏度水平可以改善模型的训练效率和性能。这些结果为理解 Mixture-of-Experts 中的因素间的相互作用提供了更好的见解，同时也为未来的设计提供了指导。
## 149. `cs.AI` - 关于语言生成的表征：幻觉、广度和稳定性之间的相互作用 [PDF](https://arxiv.org/pdf/2412.18530), [HTML](https://arxiv.org/abs/2412.18530)
### Authors
Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas
### Background
研究语言生成的极限问题，该问题由Kleinberg和Mullainathan提出，借鉴了Gold和Angluin的经典工作。Kleinberg和Mullainathan提出的方法能够在一定程度上生成未见过的字符串，但牺牲了覆盖能力或广度。尽管近期研究引入了不同的广度概念并探索了这些概念下生成广度的可能性，但还未能完全解决这些概念之间的关系。
### Innovation
本研究通过表征现有广度概念及其自然扩展，解决了这一问题。此外，研究进一步探讨了具有广度和稳定性的语言生成，证明了稳定生成器在许多性能指标下均无法超越其他语言，特别是在稳定性要求下，具有多种广度概念的语言生成变得同样困难。
### Conclusion
此研究揭示了广度、稳定性和一致性在语言生成中的复杂关系，并指出生成近似的广度之于稳定和不稳定生成器的分离，强调了广度、稳定性和一致性之间的丰富相互作用。
## 150. `cs.AI` - 量化下游模型性能中数据对齐的重要性 [PDF](https://arxiv.org/pdf/2501.08496), [HTML](https://arxiv.org/abs/2501.08496)
### Authors
Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo
### Background
与常规模型训练主要关注数据集大小不同，本文探讨了数据对齐——数据质量的一个常被忽视方面——对训练大型语言模型（LLMs）能力的影响。文章通过使用基于Task2Vec的对齐系数来衡量两个数据集之间的相似度，以此来量化训练数据与评估数据对齐程度对下游性能的影响。研究具体设置了两个干预性实验场景：1. 增加预训练数据和评估数据之间的对齐系数；2. 增加特定领域微调数据与特定领域评估数据之间的对齐系数。其中一个特定任务是Autoformalization，即自然语言和代码间的机器翻译任务，用于形式化验证。在两个场景下，研究发现模型训练和评估数据之间对齐系数与模型在相应下游任务上的损失/困惑度之间存在明显的、可预测的负相关关系。这项研究建议重新评估LLMs的训练方法，证明了在诸如Autoformalization等专门下游任务中，数据对齐相较于数据量更为重要。
### Innovation
文章创新性地使用基于Task2Vec的对齐系数来具体量化数据对齐对模型下游性能的影响，特别是在专门领域（如Autoformalization）的任务中，证明了数据对齐的重要性超过单纯的数据量。研究通过控制实验来验证不同对齐程度对模型性能的具体影响，提供了定量分析数据对齐对模型性能影响的方法。
### Conclusion
研究结果表明，在模型下游任务性能中，数据对齐的影响比单纯的数据量更为显著。在专门领域如Autoformalization的任务中，需要关注并优化数据对齐，以提升模型性能。这建议在训练大型语言模型时，应重新评估现有的训练方法，并考虑对数据进行更好的对齐优化。
## 151. `cs.AI` - 量子增强的小样本因果发现 [PDF](https://arxiv.org/pdf/2501.05007), [HTML](https://arxiv.org/abs/2501.05007)
### Authors
Yu Terada,Ken Arai,Yu Tanaka,Yota Maeda,Hiroshi Ueno,Hiroyuki Tezuka
### Background
在经济学、社会科学和生物学等领域，从观测数据中发现因果关系引起了广泛关注。然而，在实际应用中，通常缺乏对底层系统相关知识，且真实数据常伴随非线性因果结构，这使得大部分传统因果分析方法难以直接应用。因此，本研究旨在提出一种不必要的底层模型结构假设的新型量子彼得-克拉克（qPC）算法，以探索数据中的因果关系。
### Innovation
提出的qPC算法基于量子电路刻画的再生核希耳伯特空间中的条件独立性检验，能够从任意分布的数据中探索因果关系，且通过基于核目标对齐（KTA）的新型优化方法确定量子核的超参数，有效减少了因果发现中的假阳性，并增强了推理的可靠性。此外，该方法在波士顿住房价格、心脏病和生物信号系统等实际应用数据集上的有效性得到了验证。
### Conclusion
理论和实验结果表明，量子算法能够增强经典算法在因果发现中的精确推理能力，特别是在小样本场景下弥补了经典算法的不足。该方法展示了基于量子的因果发现方法在解决实际问题上的潜力，尤其是在小样本场景下，传统方法显示出明显的局限性。
## 152. `cs.AI` - 电路调优：识别参数冗余和细调神经网络的机制性方法 [PDF](https://arxiv.org/pdf/2502.06106), [HTML](https://arxiv.org/abs/2502.06106)
### Authors
Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang
### Background
研究表明，在模型中探索学习动态仍然是一项挑战，大多数研究侧重于特定行为的静态机制。本研究旨在通过提出一种可解释的微调方法来研究学习背后的机制。通过引入节点级别的内在维度概念来描述计算图中的学习过程。实验结果证实了节点级别的内在维度的存在，并展示了该方法在透明和可解释的微调中的有效性。
### Innovation
本文开发了一种可解释的微调方法——电路调优，这是一种两阶段算法，可以逐步构建特定任务所需的最小子图，并以启发式方式更新关键参数。这种方法基于节点级别的内在维度的概念，并提供了一种新的理解神经网络学习过程中自我组织机制的方式。
### Conclusion
实验结果表明，电路调优方法能够有效减少参数冗余，提供透明和可解释的微调，有助于理解神经网络在学习过程中的自我组织机制。
## 153. `cs.AI` - EigenLoRAx: 综用适配器以寻找资源高效适配和推断的主子空间 [PDF](https://arxiv.org/pdf/2502.04700), [HTML](https://arxiv.org/abs/2502.04700)
### Authors
Prakhar Kaushik,Ankit Vaidya,Shravan Chaudhari,Alan Yuille
### Background
大型模型的迅速增长引发对其环境影响和访问公平性的担忧，因为这些模型的计算成本很高。低秩适配器（LoRA）提供了一种轻量级的方法，用于对大型模型进行微调，从而产生大量针对不同领域公开可用的适配器。我们探讨了这些预训练的适配器是否可以进一步简化到新任务的适应过程，同时解决这些问题。
### Innovation
我们提出了EigenLoRAx，一种参数高效的微调方法，通过重新利用现有的适配器来创建与共享领域知识对齐的主子空间，并在低资源场景中进一步补充正交基向量。这种方法通过学习主子空间的轻量级系数来快速适应新任务，无需对整个适配器进行微调。EigenLoRAx需要显著减少的参数和内存，提高训练和推理的效率。
### Conclusion
我们的方法在多种领域和任务上展现出了强大的性能，提供了一种适用于边缘设备和个性化应用的大型模型的可扩展且资源高效的部署方案，以及在资源受限环境中实现公平部署的方法。
## 154. `cs.AI` - Token Prepending：一种无需训练的方法以从大规模语言模型中提取更好的句子嵌入 [PDF](https://arxiv.org/pdf/2412.11556), [HTML](https://arxiv.org/abs/2412.11556)
### Authors
Yuchen Fu,Zifeng Cheng,Zhiwei Jiang,Zhonghui Wang,Yafeng Yin,Zhengliang Li,Qing Gu
### Background
从大规模语言模型（LLMs）提取句子嵌入是一个有前景的方向，因为这些模型展现了更强的语义理解能力。以往的研究主要通过提示工程来促使模型将句子信息编码到最后一词的嵌入中。然而，LLMs大多是只具备解码器的模型，且具有因果注意力，在处理句子时，较早的词元无法关注到后面的词元，从而导致句子信息记录偏颇，并在最终解码时产生累积效应。
### Innovation
提出了一种新颖的Token Prepending (TP)技术，该技术将每个解码层的句子嵌入添加到下一层输入句首，使得较早的词元能够在因果注意力机制下关注整个句子的信息。该TP技术是一种“即插即用”且无需训练的技术，可以无缝集成到各种基于提示的句子嵌入方法和自回归LLM中。实验证明，TP技术显著提升了不同LLM上现有基于提示的句子嵌入方法的表现，同时几乎不增加额外的推理成本。
### Conclusion
TP技术在多个语义文本相似性（STS）任务和下游分类任务中表现良好，能够显著提升现有基于提示的句子嵌入方法的效果，且几乎不增加额外的推理成本。
## 155. `cs.AI` - EquiTabPFN: 一种目标置换对称的先验适应网络 [PDF](https://arxiv.org/pdf/2502.06684), [HTML](https://arxiv.org/abs/2502.06684)
### Authors
Michael Arbel,David Salinas,Frank Hutter
### Background
现有的基于表型数据的基础模型，如TabPFN，擅长通过上下文学习适应新任务，但仍然受到一个固定目标维度的数量约束，这通常需要昂贵的集成策略。这种约束源于模型架构的深层次缺陷：这些模型缺乏目标对称性，因此目标维度的排列会改变模型的预测结果，导致无法消除“对称性缺口”，这是一种减少预测稳定性的错误项。
### Innovation
本文通过设计一个完全目标对称的架构来解决上述问题，这种方法通过对称编码器、对称解码器和双注意力机制确保排列不变性。这种新架构在标准分类基准上进行实证评估，表明在训练集类目数目小于测试数据的情况，本文模型能够达到甚至超越现有的方法，同时减少了计算成本。
### Conclusion
本文通过新型完全目标对称的架构设计，有效解决了现有模型在处理新类目数据时的稳定性问题，在实验中展示了其优越性，降低了计算负担。
## 156. `cs.AI` - 分层安全聚合中循环用户关联的基本极限 [PDF](https://arxiv.org/pdf/2503.04564), [HTML](https://arxiv.org/abs/2503.04564)
### Authors
Xiang Zhang,Zhou Li,Kai Wan,Hua Sun,Mingyue Ji,Giuseppe Caire
### Background
分层安全聚合（HSA）是一种用于联邦学习（FL）的方法，其中云服务器通过中间级的信道来聚合成千上万客户端的本地训练模型，以计算平均模型（即深度神经网络的权重），同时满足数据安全需求。传统的HSA假设每个用户只与一个中继联系，这限制了跨集群用户间的编码机会，从而影响了有效通信和密钥生成效率。本文研究了循环关联模式下的HSA，即每个用户以环形方式连接到B个连续的中继。
### Innovation
本文提出了一个高效的聚合方案，其包括由梯度编码启发的消息设计，用于输入的高效通信技术，以及高度非平凡的安全密钥设计。此外，还利用信息论方法给出了最小可实现的通信和密钥速率的新颖上下界。
### Conclusion
本文分析了循环关联模式下的分层安全聚合的基本极限，提出了高效的聚合方案，并给出了通信和密钥速率的上下界，为进一步提高分层安全聚合的效率和安全性能奠定了理论基础。
## 157. `cs.AI` - 交错吉布斯扩散：具有隐式约束的离连续数据生成 [PDF](https://arxiv.org/pdf/2502.13450), [HTML](https://arxiv.org/abs/2502.13450)
### Authors
Gautham Govind Anil,Sachin Yadav,Dheeraj Nagaraj,Karthikeyan Shanmugam,Prateek Jain
### Background
大多数关于离散和离连续扩散的工作假设降噪分布是分解的，这在处理强随机变量依赖性的问题时会产生限制。现有的模型普遍存在这一问题，特别是在需要处理重要、隐式和未指明的数据约束的情况下。因此，需要一个能够更好地捕捉这些关系的方法，而不依赖于特定领域的归纳偏差或辅助损失。
### Innovation
提出了交错吉布斯扩散(IGD)作为一种新颖的生成模型框架，针对具有隐式约束的离连续数据。IGD推广了离散-连续生成的离时吉布斯采样类型马尔可夫链，允许无缝集成离散和连续去噪器，并在理论上保证倒退过程的准确逆转。此外，IGD 可提供去噪器选择的灵活性，并支持状态空间加倍进行条件生成和推理时间优化。该框架在三个具有挑战性的生成任务中均表现出最先进的性能。（注：三个生成任务指分子结构、布局和表格数据）
### Conclusion
IGD在无需依赖特定领域内归纳偏差的情况下，达到了最先进的结果。通过广泛的建模和交错策略探索，以及对各种超参数的研究，IGD展示了其在复杂离连续数据生成任务中的强大性能和灵活性。
## 158. `cs.AI` - 基于大型语言模型的从穿戴设备和饮食中预测高血糖和行为治疗路径 [PDF](https://arxiv.org/pdf/2503.03935), [HTML](https://arxiv.org/abs/2503.03935)
### Authors
Abdullah Mamun,Asiful Arefeen,Susan B. Racette,Dorothy D. Sears,Corrie M. Whisner,Matthew P. Buman,Hassan Ghasemzadeh
### Background
餐后高血糖，指餐后血糖水平超出正常范围，是对患有糖尿病前期的人群和健康个体向2型糖尿病发展的一个重要指标。餐后血糖动态的一个关键衡量指标是餐后曲线下面积（AUC）。通过了解生活方式因素（如饮食和活动水平）如何影响餐后血糖，可以预测餐后AUC并调整个人行为，以维持正常的血糖水平。本研究旨在开发一个基于解释性机器学习的解决方案GlucoLens，利用传感器驱动的输入、先进的数据处理、大型语言模型及可训练的机器学习模型，来预测餐后AUC和高血糖。研究使用穿戴设备在五周的临床试验中获取10名全职员工的数据，以开发和评估集成了穿戴传感、多模态数据和机器学习的计算模型。
### Innovation
提出了一个基于解释性机器学习的解决方案GlucoLens，该系统利用多模式数据（来自穿戴活动和血糖监测传感器的数据，以及饮食和工作记录）来预测餐后血糖模式，实现了0.123的最佳配置的归一化均方根误差，并且在平均性能上比对比模型高出16%，能准确预测高血糖的准确率为73.3%，F1分数为0.716，并能推荐不同的治疗方案，通过多样化的影响解释来避免高血糖。
### Conclusion
本研究利用穿戴设备和饮食数据，在解释性模型的基础上，成功预测了餐后高血糖，并提供了行为治疗建议，为2型糖尿病的预防提供了新的路径。
## 159. `cs.AI` - HAPI: 从人类偏好中学习机器人面部表情的模型 [PDF](https://arxiv.org/pdf/2503.17046), [HTML](https://arxiv.org/abs/2503.17046)
### Authors
Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida
### Background
自动机器人面部表情生成对于人机交互至关重要，但传统基于固定关节配置的手工方法往往会导致僵硬和不自然的行为。虽然最近的自动化技术减少了手动调整的需求，但它们常常在将人类偏好与模型预测相匹配方面存在不足，导致生成的表情缺乏细腻和现实感。现有方法受限于有限的自由度和不足的知觉整合，无法有效地生成更加真实和互动性更强的表情.
### Innovation
本文提出了一种新颖的学习排序框架，利用人类反馈来解决这一差距，提升机器人的面部表情表达能力。具体方法包括通过成对比较注释收集人类偏好数据，并开发了基于Siamese RankNet的人类情感成对印象（HAPI）模型，该模型可以细化表情评估。研究结果表明，我们的方法在35-DOF的Android平台上的在线表情调查中生成的愤怒、快乐和惊讶表情比基线和专家设计的方法更加真实和具有社会共鸣力，这证明了我们的框架有效地桥接了人类偏好和模型预测之间的差距，同时稳健地将机器人表情生成与人类情感响应相一致.
### Conclusion
我们的方法通过利用人类反馈提高了机器人面部表情的表达力，特别是在35-DOF的Android平台上进行的在线表情调查中，表现出比基线和专家设计方法更真实和更具社会共鸣力的表情。这表明我们的框架已经在有效连接人类偏好与模型预测之间方面取得了重要的进展，并且增强了机器人面部表情生成与人类情感响应的一致性。
## 160. `cs.AI` - 利用Wasserstein距离方法进行光照源和光照方向估计 [PDF](https://arxiv.org/pdf/2503.05802), [HTML](https://arxiv.org/abs/2503.05802)
### Authors
Selcuk Yazar
### Background
在图像处理领域，特别是在机器人技术中，光照估计仍然是一个关键挑战。在不同光照条件下进行稳定环境感知是至关重要的。传统的光照估计方法，如RGB直方图和GIST描述符，在复杂场景中由于对光照变化的敏感性而往往失效。因此，需要新的光照估计方法来应对复杂光照环境下的挑战。
### Innovation
本文引入了一种新的方法，基于最优传输理论中的Wasserstein距离，用于估计图像中的光照源和光照方向。该方法在多种场景下的实验表明，它在检测主要光源和估计其方向方面优于传统统计方法，特别是在复杂光照环境中。该方法在光源定位、图像质量评估和增强物体检测等方面展现出应用潜力。未来的研究可能探讨自适应阈值和结合梯度分析以提升准确性，从而提供一种对未来光照挑战的实际解决方案。
### Conclusion
实验结果表明，该方法在多种场景下优于传统统计方法，并且在光照估计的准确性和方法适用性方面展现出优势。未来研究可以进一步优化方法，提高在复杂光照环境中的应用效果。
## 161. `cs.AI` - MaizeField3D: 一个来自多样化群体的田间种植玉米的3D点云和程序模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
### Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
### Background
由于缺乏大型和多样化的3D数据集，基于人工神经网络（AI）和机器学习（ML）的3D表型学工具，特别针对玉米的开发受到了限制。2D图像数据集无法捕捉诸如叶片构造、植物体积和空间排列等3D数据提供的关键结构性细节。因此，存在开发3D数据替代方案以改进该研究领域的需求。
### Innovation
提出了一种名为MaizeField3D的数据集，其中包括1,045个高质量的田间种植玉米的3D点云，这些点云来自一个广泛的遗传品系，并使用大地激光扫描仪（TLS）收集。通过基于图的分割方法对520个植物的点云进行了分割和注释，以隔离单个叶片和茎秆，并确保所有样本的一致性标签。经过严格的手动质量控制，这些注释数据用于拟合结构化的参数表示植物的程序模型。叶片使用非统一有理B样条（NURBS）曲面表示，并通过结合无导数和导数方法进行优化生成。此外，该数据集包括植物形态和质量的元数据，以及多分辨率子采样点云数据（100k, 50k, 10k点），这些数据可以方便地用于不同的计算任务。
### Conclusion
MaizeField3D将作为AI驱动的表型学、植物结构分析以及农业研究中3D应用的全面基础数据集。
## 162. `cs.AI` - CMD-HAR: 跨模态解纠缠技术在可穿戴人体活动识别中的应用 [PDF](https://arxiv.org/pdf/2503.21843), [HTML](https://arxiv.org/abs/2503.21843)
### Authors
Hanyu Liu,Siyao Li,Ying Yu,Yixuan Jiang,Hang Xiao,Jingxi Long,Haotian Tang,Chao Li
### Background
人体活动识别（HAR）是多种以人类为中心的智能应用的基础技术。尽管深度学习方法已被用于加快特征提取，但传感器数据的多模态混合、活动异质性和复杂模型部署等问题仍然没有完全解决。
### Innovation
本文提出了一种时空注意力模态分解对齐融合策略，以解决传感器数据混杂分布的问题。通过跨模态时空解纠缠表示捕获活动的关键鉴别特征，并结合梯度调制以缓解数据异质性。此外，构建了一个可穿戴设备部署模拟系统。实验结果表明该模型的有效性。
### Conclusion
研究构建了CMD-HAR模型，该模型通过跨模态时空解纠缠表示和梯度调制有效应对了传感器数据混杂分布和数据异质性的问题，并通过大量公共数据集实验验证了其有效性。
## 163. `cs.AI` - 使用数字分身的隐私保护手术室工作流程分析 [PDF](https://arxiv.org/pdf/2504.12552), [HTML](https://arxiv.org/abs/2504.12552)
### Authors
Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath
### Background
手术室是一个复杂的环境，优化工作流程对于降低运营成本和改善患者结果至关重要。虽然计算机视觉方法可以用于自动识别围手术期事件并识别手术室优化的瓶颈，但隐私问题限制了使用手术室视频进行自动事件检测。本文探讨了如何在保护隐私的同时分析手术室的工作流程，提出了一个两阶段的隐私保护手术室视频分析流程。通过这种方法，可以生成匿名的数字双胞胎(DT)，从而实现手术室工作流程的分析，并促进机构间数据的共享，进而减少模型的专业化差异，增强其泛化能力。
### Innovation
本文提出了一种两阶段的隐私保护手术室视频分析方法。首先，利用视觉基础模型进行深度估计和语义分割，从常规的RGB视频中生成匿名的手术室数字双胞胎(DT)。其次，引入SafeOR模型，这是一种结合了双流处理的混合模型，能够处理分割掩模和深度图，用于手术室事件检测。这种方法在内部数据集上实现了与原始RGB视频模型相当甚至更好的手术室事件检测性能。
### Conclusion
通过使用数字双胞胎，本研究能够实现手术室工作流程的隐私保护分析，有助于析机构间匿名数据的分享及提高模型的泛化能力。
## 164. `cs.AI` - 了解导向的偏差缓解方法实现公平的心脏磁共振分割 [PDF](https://arxiv.org/pdf/2503.17089), [HTML](https://arxiv.org/abs/2503.17089)
### Authors
Tiarna Lee,Esther Puyol-Antón,Bram Ruijsink,Pier-Giorgio Masci,Louise Keehn,Phil Chowienczyk,Emily Haseler,Miaojing Shi,Andrew P. King
### Background
目前人工智能（AI）在医疗成像任务中得到了广泛应用，不过，AI 模型在应用时常常受训练数据集不平衡的影响，产生偏差，特别是在心脏磁共振（CMR）图像分割模型中发现了强烈的种族偏见。虽然该现象在多篇文献中有报道，但关于减少这种偏见的算法的有效性依然未知。因此，研究旨在调查以常见偏差缓解方法减少AI基CMR分割模型中黑人和白人之间的种族偏见。研究针对此问题采用过抽样、重要重新加权和Group DRO以及这些技术的组合来缓解种族偏见。同时，研究团队基于最近揭示的AI基CMR分割偏差的根本原因，还使用被剪裁的CMR图像来训练和评估模型，从而在两个种族中提升模型的性能并减少偏差.
### Innovation
研究不仅采用过抽样、重要重新加权和Group DRO等技术，还测试了这些方法在剪裁后的CMR图像上的表现，发现剪裁图像可以提高两个种族的性能并进一步减少偏见。当在外部临床验证集上测试模型时，发现分割性能优秀且不存在统计学上的显著偏见。此项研究为利用了解导向的方法实施公平的心脏磁共振分割提供了新的视角和实证数据支持，在偏见缓解技术应用上具有创新性.
### Conclusion
我们的研究表明，通过使用过抽样、重要重新加权和Group DRO等技术，可以减轻AI基CMR分割模型中的种族偏见，特别是能够显著提高黑人受试者的性能而不显著影响白人受试者的性能。使用剪裁后的CMR图像可以进一步提高两组研究对象的性能并减少偏见。在实际临床环境中应用这种模型时，我们能够实现高性能分割及消除种族偏见。
## 165. `cs.AI` - SoccerDiffusion：从比赛录制学习端到端的人形机器人足球 [PDF](https://arxiv.org/pdf/2504.20808), [HTML](https://arxiv.org/abs/2504.20808)
### Authors
Florian Vahl,Jörn Griepenburg,Jan Gutsche,Jasper Güldenstein,Jianwei Zhang
### Background
本文介绍了一个基于变换器的扩散模型——SoccerDiffusion，旨在直接从真实的足球比赛录制中学习人形机器人的端到端控制策略。该研究使用来自RoboCup比赛的数据，该模型能够从多模态传感器输入（包括视觉、本体感受和比赛状态）中预测关节命令轨迹。研究表明，模型能够在模拟和实际机器人中复制复杂的运动行为，如行走、踢球和跌倒恢复。尽管高级战术行为仍受限，但该工作为后续的强化学习或偏好优化方法提供了坚实的基础。
### Innovation
研究采用了一种蒸馏技术，使嵌入式平台能够实现实时推理，将多元扩散过程简化为单步骤过程。该技术使得在实际应用中实现复杂的人形机器人足球行为成为可能。模型能够在模拟和实际机器人中进行实时运行，展示了其在复杂运动行为复制上的能力。
### Conclusion
尽管高级战术行为仍受限，SoccerDiffusion为后续的强化学习或偏好优化方法提供了坚实的基础。研究还公开了数据集、预训练模型和代码，进一步推动该领域的研究和发展。
## 166. `cs.AI` - Commander-GPT：全面释放多模态大语言模型的反语检测能力 [PDF](https://arxiv.org/pdf/2503.18681), [HTML](https://arxiv.org/abs/2503.18681)
### Authors
Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin
### Background
反语检测作为自然语言处理（NLP）领域的重要研究方向，近年来引起了广泛的关注。传统的反语检测通常采用单一模态方法（如文本），但由于反语的隐含性和细微特点，这些方法往往无法取得令人满意的结果。近年来，研究人员将反语检测的重点转向多模态方法，但如何有效利用多模态信息来准确识别反语内容仍然存在挑战。在此之前的研究工作中，尝试利用多模态大规模语言模型（MLLMs）的不同信息源进行集成处理，但面对反语这一复杂现象，仍需进一步探索和优化。
### Innovation
本文提出了一个名为Commander-GPT的创新性多模态框架。该框架借鉴军事策略，首先将反语检测任务分解为六个独立的子任务，然后由一个中心指挥官（决策者）分配最适合的大型语言模型以解决各个具体子任务。最终，来自每个模型的检测结果被综合起来用于识别反语。在这一过程中，本文使用了四种多模态大规模语言模型和六种提示策略进行了广泛的实验，证明了该方法在F1分数提高了19.3%，并且没有使用微调和真实评估预期结果作为指导。
### Conclusion
本文的研究结果表明，在多模态大规模语言模型中充分利用其综合处理能力，通过将反语检测任务分解为子任务并分配合适的模型来处理，可以显著提高反语检测的准确性。该方法在MMSD和MMSD 2.0数据集上均取得了最优性能。
## 167. `cs.AI` - PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification [PDF](https://arxiv.org/pdf/2504.19136), [HTML](https://arxiv.org/abs/2504.19136)
### Authors
Huiling Zheng,Xian Zhong,Bin Liu,Yi Xiao,Bihan Wen,Xiaofeng Li
### Background
合成孔径雷达（SAR）和RGB图像在土地覆盖分类中的融合仍然具有挑战性，主要是由于模态异质性和未充分利用的光谱互补性。现有方法往往无法解耦共享的结构特征与模态互补的辐射属性，导致特征冲突和信息丢失。
### Innovation
提出了Phase-Amplitude Decoupling（PAD）框架，这是一种基于频域的解耦方法，能够在频域中分离相位（模态共享）和振幅（模态互补）成分。PAD是首次在多模态融合中引入显式的振幅-相位解耦，具体包括Phase Spectrum Correction（PSC）和Amplitude Spectrum Fusion（ASF）两个关键组件，增强共享结构同时保留互补特征，从而提高融合质量。
### Conclusion
在WHU-OPT-SAR和DDHR-SK数据集上的 extensive 实验结果显示，PAD 方法在多模态土地覆盖分类中取得了最先进的性能。这项工作为遥感中的物理感知多模态融合设定了一个新的范式。代码将在特定URL处提供。
## 168. `cs.AI` - 基于不确定性指导和解剖意识后处理的粗细分割肿瘤分割 [PDF](https://arxiv.org/pdf/2504.12215), [HTML](https://arxiv.org/abs/2504.12215)
### Authors
Ilkin Sevgi Isler,David Mohaisen,Curtis Lisle,Damla Turgut,Ulas Bagci
### Background
在胸腔计算机断层扫描（CT）中可靠地进行肿瘤分割仍然具有挑战性，主要由于边界模糊、类别不平衡和解剖变异的问题。现有的方法在处理这些挑战时往往表现不佳，尤其是在难以识别的区域和肿瘤边界的校准方面。因此，改善肿瘤分割的精度和边界准确度成为研究的重点。
### Innovation
本文提出了一种基于不确定性指导的粗细分割框架，该框架通过结合全体积肿瘤定位与解剖意识后的细化区域分割，增强了肿瘤分割模型的鲁棒性。具体来说，第一阶段生成粗略预测，第二阶段通过不确定性感知损失函数优化预测，最后结合解剖信息进行后处理，提升最终分割结果的准确性和可解释性。这种方法特别强调了解剖模型在分割管道中的重要性，特别是在处理易错区域时，能够显著减少伪阳性结果和提高空间可解释性。
### Conclusion
实验结果表明，在私有和公共数据集上采用不确定性建模和解剖先验综合作为粗细分割框架可以提高Dice分数和赫兹分数，减少假阳性，并增强空间可解释性。这项研究强调了通过结合不确定性建模和解剖先验提高肿瘤分割结果可靠性和临床意义的重要性。具体到Orlando数据集，采用本框架将Swin UNETR的Dice分数从0.4690提高到了0.6447，证明了采用解剖意识后处理的有效性。
## 169. `cs.AI` - 横跨语言：多模态LLMs的跨语言一致性基准测试 [PDF](https://arxiv.org/pdf/2505.15075), [HTML](https://arxiv.org/abs/2505.15075)
### Authors
Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara
### Background
多模态大型语言模型（MLLMs）的快速发展显著提升了其实际应用能力，但跨语言的一致性表现仍是一个挑战，尤其是在整合文化知识时。目前，没有有效的工具来评估这些模型在不同语言之间的表现一致性。因此，需要新的基准来更好地评估这个问题。
### Innovation
本文引入了两个新的基准：KnowRecall和VisRecall。KnowRecall是一个视觉问答基准，用于衡量15种语言中的事实知识一致性，特别关注全球地标的历史和文化问题。VisRecall则通过询问模型在无图像情况下描述9种语言中的地标外观来评估视觉记忆一致性。实验结果显示，最先进的MLLMs，包括专有的模型，仍然难以实现跨语言一致性，这强调了需要更稳健的方法来生成真正多语言和文化意识的模型的重要性。
### Conclusion
最新的多模态大型语言模型在跨语言一致性方面仍然存在挑战。现有最好的模型在不同语言环境中仍然表现不一。这一发现强调了开发更强大的方法以生成真正多语言和文化意识模型的重要性。
## 170. `cs.AI` - Neuro科学中动态因果图假设生成：利用观测时间序列生成模型 [PDF](https://arxiv.org/pdf/2505.20697), [HTML](https://arxiv.org/abs/2505.20697)
### Authors
Zachary C. Brown,David Carlson
### Background
在神经科学领域，假设生成有望通过缩小需要进行干预性研究的范围来降低成本，从而研究各种现象。现有的机器学习方法可以从复杂的数据集中生成科学假设，但许多方法假设因果关系在时间上是静态的，这限制了它们在具有动态、状态依赖行为的系统（如大脑）中的应用。虽然一些技术尝试通过因子模型进行动态因果发现，但它们往往仅限制关系为线性的模式或强制其他简化假设。
### Innovation
提出了一个新颖的方法，将动态图形建模为静态图形的条件加权叠加，其中每个静态图形可以捕捉非线性关系。这种方法允许检测超越线性限制的复杂、随时间变化的变量之间的交互作用。在某些实验中，该方法相对于基准提高了预测动态因果模式的f1分数，平均约为22-28%，某些改进甚至超过了60%。一个实际的大脑数据案例研究展示了该方法能够揭示与特定行为状态相关的联系，提供了对神经动态有价值的见解。
### Conclusion
该方法通过利用生成模型在时间序列数据中生成动态因果图的假设，提供了超越传统方法的复杂交互识别。它能够在实际大脑数据中发现与特定行为状态相关的复杂交互，对神经科学领域的研究具有重要价值。
## 171. `cs.AI` - 结合大型语言模型进行大规模城市复杂交通模拟 [PDF](https://arxiv.org/pdf/2505.21880), [HTML](https://arxiv.org/abs/2505.21880)
### Authors
Yu-Lun Song,Chung-En Tsern,Che-Cheng Wu,Yu-Ming Chang,Syuan-Bo Huang,Wei-Chu Chen,Michael Chia-Liang Lin,Yu-Ta Lin
### Background
传统基于规则的适用于城市移动性的代理基础建模(ABM)方法限制了移动模式的真实性和多样性。该研究通过将大型语言模型（LLM）与ABM结合，旨在提高城市交通模拟的真实性与多样性，同时模拟台北市的个体行为和大规模交通模式，从而为城市规划提供行动指南。
### Innovation
提出了一个创新的基于ABM的框架，通过使用大型语言模型生成合成人口资料，分配常规和偶发地点，并模拟个性化路线来增强代理多样性与现实性。此方法使用实际数据进行个体行为和大规模交通模式的模拟和分析，并提供了路线热图和特定模式指标等关键见解，以支持城市规划和政策制定。
### Conclusion
未来的工作将专注于建立有效的验证框架，以确保模拟结果在城市规划应用中的准确性和可靠性。
## 172. `cs.AI` - 利用大型AI模型部署提升智能低空经济 [PDF](https://arxiv.org/pdf/2505.22343), [HTML](https://arxiv.org/abs/2505.22343)
### Authors
Zhonghao Lyu,Yulan Gao,Junting Chen,Hongyang Du,Jie Xu,Kaibin Huang,Dong In Kim
### Background
低空经济(LAE)是一种新兴的经济模式，重新定义了商业和社会活动的空中运营。大规模人工智能模型(LAIMs)为进一步提升LAE服务的智能化提供了变革性的潜力。然而，在LAE部署LAIMs面临多项挑战，包括计算/存储需求与LAE实体有限的机载资源之间的巨大差距，实验室训练的LAIMs与动态物理环境之间的匹配不一致，以及传统分离设计（在感知、通信和计算方面的效率低下）。
### Innovation
提出了针对LAIM部署的分层系统架构，探索促进LAIMs与低空系统相互进化的关键使能技术，并引入面向任务的执行流水线，以实现可扩展和自适应的服务交付，通过实际案例进行了验证。
### Conclusion
指出了未来研究中的开放挑战，以激发进一步的研究灵感。
## 173. `cs.AI` - 表达性强的神经架构搜索空间中的可转移代理模型 [PDF](https://arxiv.org/pdf/2504.12971), [HTML](https://arxiv.org/abs/2504.12971)
### Authors
Shiwen Qin,Gabriela Kadlecová,Martin Pilát,Shay B. Cohen,Roman Neruda,Elliot J. Crowley,Jovita Lukasik,Linus Ericsson
### Background
神经架构搜索（NAS）面临着在探索广泛而有表现力的设计空间以实现架构创新的同时，对架构进行有效评估以高效搜索这些空间的挑战。当前的研究探讨了使用基于上下文无关文法的代理模型训练来提高此类高度表现性NAS搜索空间中的搜索效率的方法。
### Innovation
研究发现，代理模型通过使用零成本代理指标和神经图特征（GRAF）进行训练或者通过微调商用语言模型，对于架构性能具有高度的预测能力，无论是在同一数据集内还是跨数据集之间。这些代理模型还能够过滤掉在新数据集上的不良架构，从而显著加快搜索速度并获得更好的最终性能。此外，这些代理模型可以直接用作搜索目标以实现巨大的速度提升。
### Conclusion
这项研究证明了代理模型在高度表现性的NAS搜索空间中的有效性和潜在应用，为加速NAS搜索过程提供了新的方法，并实现了更快且性能更优的结果。
## 174. `cs.AI` - Diffusion模型驱动的文本感知图像恢复 [PDF](https://arxiv.org/pdf/2506.09993), [HTML](https://arxiv.org/abs/2506.09993)
### Authors
Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim
### Background
图像恢复旨在恢复退化的图像。虽然现有的基于扩散的方法在自然图像恢复方面取得了巨大成功，但在恢复退化图像中的文本区域时常常难以忠实重建，这些方法经常生成看似合理的但不正确的文本似图案，我们称之为文本图像错觉。
### Innovation
提出了Text-Aware Image Restoration（TAIR），这是一种新颖的恢复任务，要求同时恢复视觉内容和文本保真度。还提出了一种称为TeReDiff的多任务扩散框架，该框架将扩散模型的内部特征集成到文本检测模块中，使两个组件能够从中受益，从而提取丰富的文本表示，并作为去噪步骤中的提示。
### Conclusion
广泛的实验表明，我们的方法在文本识别准确性方面的一致性上明显优于最先进的恢复方法，实现了显著的提升。
## 175. `cs.AI` - 威胁建模中的AI：资产中心化方法的案例 [PDF](https://arxiv.org/pdf/2505.06315), [HTML](https://arxiv.org/abs/2505.06315)
### Authors
Jose Sanchez Vicarte,Marcin Spoczynski,Mostafa Elsaid
### Background
近年来，人工智能（AI）的进步使得AI系统的广泛应用从单一的应用程序转变为了深度集成的AI代理。这种变化由AI代理的能力驱动，即它们能够自主做出决策并采取行动，无论这些应用本身是否是基于AI的。这种演变使得AI集成达到了前所未有的水平，代理能够代表系统和用户执行操作，包括自动编写和执行脚本。随着AI系统自主执行代码、交互外部系统、并在无监视的情况下运行，传统安全方法已经不足以应对这些挑战。
### Innovation
本文提出了一个以资产为中心的威胁建模方法，用于构建和部署这些代理系统的分布式基础设施，强调识别传统和AI特定的漏洞如何影响关键AI资产。这种方法不同于现有的自上而下的框架，可以系统地识别漏洞，帮助攻防团队进行跨技术领域的综合分析，量化第三方AI组件的安全假设，而不需要其实现细节的可见性，并全面识别与其特定产品相关的人工智能漏洞。这种方法特别适用于保护具有复杂自主能力的代理系统。通过将重点放在资产上而不是攻击，这种方法可以适应快速变化的威胁环境和日益复杂的分布式AI开发管道。
### Conclusion
该方法为安全团队提供了一种有效的分析框架，帮助他们更好地理解和应对AI系统的安全挑战，特别是在保护具有复杂自主能力的系统时更为有效。
## 176. `cs.AI` - 显著性指标：用于分类一致性值的两步评估方法 [PDF](https://arxiv.org/pdf/2504.15325), [HTML](https://arxiv.org/abs/2504.15325)
### Authors
Alberto Casagrande,Francesco Fabris,Rossano Girometti,Roberto Pagliarini
### Background
一致性度量，如κ系数或内类相关系数，用于评估两个或多个分类器之间的匹配度。这些度量在医学、人工智能等多个领域广泛使用，用于评估医疗治疗和临床试验的有效性，或者量化分类器减少过程中的近似程度。不同的分类器与金标准的一致性可以通过它们的排序进行简明比较，但仅仅根据一致性度量的值来评判一个方法的好坏，需要一个量化或显著性索引来调整这些度量，以提供更准确的评估结果。虽然一些针对κ系数的质量标度已经被提出，但它们主要是简单的，且其阈值是任意设置的。因此，对该领域的进一步研究仍然存在需求和挑战，即如何设定适当的显著性阈值，并有效地进行评估计算，以提高分类器一致性测量的可靠性和实用性。
### Innovation
本文提出了一种通用方法，用于评估任意两个分类器之间一致性值的显著性，并介绍了两种显著性指标：一种适用于有限数据集，另一种处理分类概率分布。此外，本文还解决了这类指标计算带来的计算挑战，并提出了一些高效的算法以实现这些指标的计算，从而提高了分类器一致性评估的可靠性和效率。
### Conclusion
通过引入显著性指标，本文提供了一种更精确评估分类器一致性的方法，提高了不同分类器与金标准一致性比较的可靠性。所提出的算法也提高了计算效率，使得这些显著性指标在实际应用中更具操作性。
## 177. `cs.AI` - 区分预测性和生成性AI在监管中的差异 [PDF](https://arxiv.org/pdf/2506.17347), [HTML](https://arxiv.org/abs/2506.17347)
### Authors
Jennifer Wang,Andrew Selbst,Solon Barocas,Suresh Venkatasubramanian
### Background
在过去十年中，政策制定者开发了一系列监管工具，以确保人工智能的发展与关键的社会目标保持一致。这些工具起初是为应对预测性AI所引发的关注，因此内含了对AI系统特性和某些监管方法有效性的一些预设。然而，随着生成性AI的兴起，这些预设不再适用，尽管政策制定者试图维持既能涵盖两种类型的AI的单一监管目标。
### Innovation
本文识别出生成性AI的四个独特方面，需要不同的政策回应：1）生成性AI的普遍性和适应性使它成为不良的监管目标；2）难以设计有效的评估方式；3）新的法律问题改变了利益相关者和专业知识的生态系统；4）生成性AI价值链的分布式结构。据此，政策制定者需要评估过去十年的工作成果是否仍适用，并制定新的政策以应对生成性AI所带来的独特风险。
### Conclusion
本文提出了三项政策建议，以便更有效地识别监管目标，并充分利用生态系统中的约束条件来管理生成性AI。
## 178. `cs.AI` - 朝向可解释的特征嵌入比较与对齐 [PDF](https://arxiv.org/pdf/2506.06231), [HTML](https://arxiv.org/abs/2506.06231)
### Authors
Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia
### Background
尽管在文献中已经开发了多种特征嵌入模型，但对这些嵌入的比较主要集中在它们在分类相关下游应用中的数值性能上。然而，一个可解释的嵌入比较需要识别和分析嵌入空间中聚类样本组之间的差异。
### Innovation
本文提出了Spectral Pairwise Embedding Comparison (SPEC)框架，用于比较嵌入并在参考数据集中识别它们的差异。该方法通过分析两个嵌入的核矩阵，并利用差异核矩阵的特征分解来检测由两个嵌入不同捕获的样本聚类。此外，通过优化问题来确保一种嵌入中识别的聚类也在另一种模型中捕获。
### Conclusion
结果显示，SPEC在大规模数据集（如ImageNet和MS-COCO）上成功地用于嵌入的比较与对齐。项目页面可在该网址找到。
## 179. `cs.AI` - 通过强化学习冻结的LLM对齐：一种迭代重权重-优化方法 [PDF](https://arxiv.org/pdf/2506.17828), [HTML](https://arxiv.org/abs/2506.17828)
### Authors
Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong
### Background
调整大型语言模型（LLMs）与人类偏好通常需要使用RLHF和DPO等微调方法。这些方法直接优化模型参数，因此无法在测试时使用以提高模型性能，也不适用于无法访问模型权重的情况。相比之下，测试时的方法通过利用奖励函数引导并改善输出质量，但需承担高昂的推理成本，并且其一劳永逸的指导往往基于不完美的奖励或价值函数，从而导致输出效果不佳。
### Innovation
本文提出了一种名为Iterative Reweight-then-Optimize (IRO)的方法，这是一种强化学习框架，能够在不修改基础模型参数的情况下对冻结的基础模型进行RL风格的对齐。在训练过程中，每次迭代都包括从基础模型采样候选方案、基于当前的价值函数重新采样，并训练新的轻量级价值函数来引导下一次解码过程。在测试时，通过基于搜索的优化过程使用价值函数来引导基础模型生成。值得注意的是，用户可以使用IRO对齐自己数据集上的模型，类似于OpenAI的强化学习微调（RFT），但不需要访问模型权重。
### Conclusion
该工作提出了一种新的方法IRO，它可以在不接触原始模型参数的情况下对冻结的大型语言模型进行对齐，并且可以在测试时通过价值函数实现基于搜索的优化。这为无需访问模型权重即可调整模型的个体或机构提供了可能性，同时也解决了直接优化带来的高成本问题。
## 180. `cs.AI` - AIn't Nothing But a Survey? 使用大型语言模型对调查动机的德语开放回答进行编码 [PDF](https://arxiv.org/pdf/2506.14634), [HTML](https://arxiv.org/abs/2506.14634)
### Authors
Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessica Daikeler
### Background
近年来，大型语言模型（LLMs）的发展和广泛应用引起了对于这些模型在调查研究中的使用讨论，特别是在对开放性问题答案进行分类方面。由于语言能力，LLMs 可能成为一种高效替代手动编码和预训练监督机器学习模型的选择。然而现有研究多集中于英文且不复杂的答案，还缺乏对不同背景下LLMs分类开放性答案能力的研究及其分类质量与现有方法对比的清晰结论。本研究利用德语数据调查参与动机作为案例，探讨不同LLMs在非英语背景下编码开放性问题答案的有效性，并比较多种LLM及提示方法的表现。
### Innovation
本研究创新性地使用多种最新的大型语言模型和不同的提示方法来对非英语背景下的开放性问题答案进行编码。研究发现不同LLMs在类别间的预测性能存在显著差异，只有微调后的LLM能够达到满意的预测性能。提示方法的效果依赖于使用的具体LLM。未进行微调时，不同原因类别的分类性能不均衡导致类别比例发生变化。研究讨论了这些发现对于开放性问题答案编码研究和实际分析的含义，并指出了在LLMs时代选择自动分类方法时需要考虑的种种权衡。
### Conclusion
本研究为LLMs在调查研究中高效、准确、可靠的应用提供条件指引，体现了LLMs在处理开放性问题时的适应性和局限性。研究人员在选择自动化方法时需要充分考虑这些因素。
## 181. `cs.AI` - AirV2X: 统一空地协作的V2X [PDF](https://arxiv.org/pdf/2506.19283), [HTML](https://arxiv.org/abs/2506.19283)
### Authors
Xiangbo Gao,Yuheng Wu,Fengze Yang,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu
### Background
尽管多辆车协作驾驶在自主性方面展现了显著优势，但传统的基于基础设施的V2X系统仍然受制于高昂的部署成本，并且在农村和郊区地区会产生‘未覆盖危险区域’的问题。现有系统的局限性为开发新的解决方案提供了空间，特别是通过无人机（UAV）来作为固定路边单元（RSU）的灵活替代或补充，以减轻这些挑战。无人机具有一系列独特的优势，包括提供独特的鸟瞰视角减少遮挡、动态定位能力用于悬停、巡逻和护航等导航规则，以及与固定基础设施相比显著降低的部署成本。这些特性对于构建部署在多种环境中的大规模数据分析系统具有重要意义。现有的空地协作自动驾驶系统仍然面临关键的技术空白，尤其是缺乏用于开发和标准化评估车辆到无人机（V2D）算法的大规模数据集。
### Innovation
本文提出了AirV2X-Perception数据集，利用无人机作为固定路边单元的一种灵活的替代或补充，来推动V2D算法的发展和标准化评估。该数据集包括了6.73小时的无人机辅助驾驶场景，涵盖了城市、郊区和农村环境，并且具备多变的天气和光照条件。这为自动驾驶领域中的空地协作系统开发提供了重要的技术支持。与传统的地面感知相比，无人机提供的鸟瞰视角减少了遮挡，并且具有动态定位能力，提高了导航规则的灵活性。此外，相较固定基础设施，无人机的部署成本更低，降低了系统的整体部署费用。这些创新点都极大地推动了V2X在不同环境中的应用和发展，特别是在农村和偏远地区，无人机的优势尤为明显。
### Conclusion
AirV2X-Perception数据集的建立填补了自动驾驶领域中空地协作算法开发的标准化评估的重要空白，实现了对V2D算法的系统性研究。该数据集通过无人机提供多样化视角和灵活导航，减少了地面感知中的遮挡和部署成本，进而促进了V2X系统的广泛应用和标准化评估。开放该数据集和软件包，有助于全球研究人员共同推动V2X技术的发展。
## 182. `cs.AI` - Horus: 一种在不确定性下的无信任委托协议 [PDF](https://arxiv.org/pdf/2507.00631), [HTML](https://arxiv.org/abs/2507.00631)
### Authors
David Shi,Kevin Joo
### Background
在动态、低信任环境中，自主AI代理通过委托工作给子代理来获益，但预先规定或中心化监督无法保证其正确性。纠正错误成本低于犯错成本的系统中，正确性是系统的一个 emergent 属性。在这种背景下，本文提出了一种协议，通过抵押索赔在一个递归验证游戏中强制执行正确性。
### Innovation
该协议通过抵押索赔，在递归验证游戏中强制执行正确性。任务以意图形式发布，解题者竞争完成任务，并在事后由验证者检查正确性。任何挑战者都可以通过抵押来质疑结果以触发验证过程。错误的代理将受到处罚，而正确的反对者则会得到奖励，并存在一个惩罚错误验证者的升级路径。
### Conclusion
当解题者、挑战者和验证者之间的激励机制对齐时，虚假条件使正确性成为纳什均衡。
## 183. `cs.AI` - 学术医疗中心生成式AI红队测试报告：基于版权的关注性演练 [PDF](https://arxiv.org/pdf/2506.22523), [HTML](https://arxiv.org/abs/2506.22523)
### Authors
James Wen,Sahil Nalawade,Zhiwei Liang,Catherine Bielick,Marisa Ferrara Boston,Alexander Chowdhury,Adele Collin,Luigi De Angelis,Jacob Ellen,Heather Frase,Rodrigo R. Gameiro,Juan Manuel Gutierrez,Pooja Kadam,Murat Keceli,Srikanth Krishnamurthy,Anne Kwok,Yanan Lance Lu,Heather Mattie,Liam G. McCoy,Katherine Miller,Allison C. Morgan,Marlene Louisa Moerig,Trang Nguyen,Alexander Owen-Post,Alex D. Ruiz,Sreekar Reddy Puchala,Soujanya Samineni,Takeshi Tohyama,Varun Ullanat,Carmine Valenza,Camilo Velez,Pengcheng Wang,Anna Wuest,Yuxiang Zhou,Yingde Zhu,Jason M. Johnson,Naomi Lenane,Jennifer Willcox,Francis J. Vitiello,Leo Anthony G. Celi,Renato Umeton
### Background
在学术医疗环境中部署生成式人工智能（AI）引发了版权合规问题。达娜法伯癌症研究所开发了GPT4DFCI，这是一种内部使用的生成AI工具，基于OpenAI模型，并被批准在研究和运营中使用。鉴于该工具在组织内的广泛采用、研究使命以及从Azure OpenAI服务产品中受益所需的共担责任模型，我们在2024年11月进行了一次结构化的红队测试，以确保严格的版权合规性。该测试包括来自学术、工业和政府机构的42名参与者，他们试图从GPT4DFCI中提取经过版权保护的内容，涵盖文学作品、新闻文章、科学出版物和受限制的临床笔记等四个领域。测试结果显示对文学作品的提取成功，表明培训数据中可能存在受版权保护的内容，需要在推理阶段进行过滤。不同类别的内容提取成功率不同，提示存在不同的保护机制。尽管进行了破解尝试，新闻文章提取未成功；科学文章只能生成高层总结；临床笔记测试显示了适当的数据隐私保护措施。这些发现揭示了生成式AI在版权合规方面存在的具体漏洞，并促使我们实施了专门的版权元提示来缓解这种风险。
### Innovation
进行了一次结构化的红队测试，以评估生成式AI在学术医疗环境中的版权合规性问题。这次测试涵盖了广泛的领域，包括文学作品、新闻文章、科学出版物和临床笔记，并揭示了不同的内容类型具有不同的保护机制。通过这次测试，开发出了专门的版权元提示来缓解这些安全漏洞。
### Conclusion
系统化的红队测试揭示了生成式AI在版权合规方面存在的具体漏洞，并促使了具体的缓解策略的实施。学术医疗机构部署生成式AI时，应持续进行测试以确保符合法律和伦理标准。
## 184. `cs.AI` - 基于语义结构的生成攻击以增强对抗传输性 [PDF](https://arxiv.org/pdf/2506.18248), [HTML](https://arxiv.org/abs/2506.18248)
### Authors
Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon
### Background
目前的生成对抗攻击方法在训练过程中利用白盒代理模型生成扰动，并在未受保护的黑盒受害者模型上应用这些扰动。这些方法相比迭代攻击具有更高的推理效率、可扩展性和迁移性，但在利用生成模型的表示能力来保留和利用语义信息方面尚未完全开发其潜力。现有的研究虽然利用了生成器中间激活层中的丰富语义特征，但尚未充分利用这些特征，导致生成的扰动与关键的语义相关区域（如对象显著区域）的对齐程度不足，从而限制了对抗迁移性的提升。因此，本文提出了一个基于Mean Teacher的语义结构感知攻击框架，通过平滑特征参考，进一步指导语义一致性，并通过特征烘烤进一步引导生成器早层激活与语义丰富的老师模型之间的语义一致性。
### Innovation
本文提出了基于Mean Teacher的语义结构感知攻击框架，通过平滑特征参考进一步指导语义一致性，并通过特征烘烤引导生成器早层激活与语义丰富的老师模型之间的语义一致性，实现对抗迁移性的提升。该方法通过将扰动合成锚定在生成器中语义相关的早期中间块中，基于实证发现，指导渐进的对抗性扰动，以显著提升对抗迁移性，并经过广泛实验验证，相对最先进的生成攻击方法具有显著改进，通过传统评估指标和新提出的误纠正率(Accidental Correction Rate)进行全面评估。
### Conclusion
本文提出的基于语义结构的生成攻击框架，能够通过平滑的特征参考和语义一致性引导，提升对抗迁移性。实验结果表明，该方法在不同模型、领域和任务中表现出了相对现有最强生成攻击方法的一致性改进，并且通过新的误纠正率指标进行了全面评估。
## 185. `cs.AI` - 基于梯度的模型特征提取用于LLM相似性检测和家族分类 [PDF](https://arxiv.org/pdf/2506.01631), [HTML](https://arxiv.org/abs/2506.01631)
### Authors
Zehao Wu,Yanjie Zhao,Haoyu Wang
### Background
随着大型语言模型（LLMs）成为现代应用程序中的核心软件组件，未经授权的模型微调、合并和再分发成为了关键的软件工程挑战。传统软件中，克隆检测和许可证合规已经得到了充分的重视，但在LLM生态系统中缺乏有效的机制来追踪模型的起源以及强制执行许可证协议。特别是对于需要衍生作品遵守命名规则进行归属说明的开源模型创作者，如Meta的LLaMA，但目前没有技术手段来验证其合规性。因此，研究提出将LLMs视为需要溯源追踪的软件数据产物，通过呈现梯度为基础的指纹框架TensorGuard，用于LLM相似性检测和家族分类。
### Innovation
TensorGuard框架采用基于梯度的指纹识别技术，提取模型固有的行为特征，独立于训练数据、水印或特定的模型格式。该框架支持广泛采用的safetensors格式，并通过统计分析梯度特征来进行高维指纹构建。指纹技术使得可以直接评估任意模型之间的相似性并通过K-Means聚类算法基于已知基模型进行领域导向的中心初始化，对其进行家族分类。
### Conclusion
在包括8个基模型和50个衍生模型的5个模型家族（Llama、Qwen、Gemma、Phi、Mistral）中进行实验评估，结果表明，在我们的K-Means聚类中心初始化下，分类准确率达到94%。
## 186. `cs.AI` - Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop [PDF](https://arxiv.org/pdf/2506.23351), [HTML](https://arxiv.org/abs/2506.23351)
### Authors
Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yu Chen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu
### Background
Embodied Artificial Intelligence (Embodied AI) 是机器人领域的一个新兴前沿，旨在开发能够感知、推理和在复杂物理环境中操作的自主系统。尽管单臂系统在任务性能上表现出色，但双臂协作系统对于处理涉及到刚性、变形和触觉敏感物体的复杂任务是必不可少的。为此，我们在2025年CVPR的第2届MEIS研讨会上推出了RoboTwin双臂协作挑战赛，旨在评估和促进双臂操作策略的学习和应用.
### Innovation
该挑战赛基于RoboTwin模拟平台（1.0和2.0）和AgileX COBOT-Magic机器人平台，设置了三个阶段：模拟第一轮、模拟第二轮和最终的实地测试轮。参赛者共完成了17项双臂操作任务，涵盖了刚性、变形和基于触觉的场景。这是一个重要的竞赛，吸引了来自全球的64支队伍和超过400名参与者，产生了诸如SEM和AnchorDP3等顶级解决方案，并为双臂策略的通用性和鲁棒性提供了宝贵的见解。报告详细说明了竞赛设置、任务设计、评估方法、关键发现及其未来方向，旨在支持未来关于鲁棒和通用双臂操作策略的研究.
### Conclusion
本报告的目的是评估和促进双臂操作策略的学习和应用，旨在支持关于鲁棒和泛化的双臂操作策略的未来研究。同时，报告提供了竞赛的设置、任务设计、评估方法、主要发现和未来方向，旨在支持未来相关研究的发展，并提供了有价值的研究经验与建议。
## 187. `cs.AI` - 从句子到序列：生物学系统中重新思考语言 [PDF](https://arxiv.org/pdf/2507.00953), [HTML](https://arxiv.org/abs/2507.00953)
### Authors
Ke Liu,Shuaike Shen,Hao Chen
### Background
当前的大语言模型在自然语言处理（NLP）中取得了显著成果，并开始应用于生物学语言（如蛋白质、RNA、DNA）的建模。虽然自回归生成框架和评估指标已经被从NLP领域转移到生物序列建模中，但自然和生物语言内部的结构性相关性存在根本差异。因此，有必要重新审视这些模型在生物学系统中的适用性和有效性，以更好地理解NLP的成功如何有效地转化到生物学领域。
### Innovation
将生物分子的三维结构视为句子的语义内容，并考虑残基或碱基间的强相关性，突出了结构评估的重要性，并展示了自回归框架在生物语言建模中的适用性。
### Conclusion
通过对生物系统中语言的理解，本文证明了自回归生成框架在生物语言建模中的有效性和应用性，并强调了结构性评估的重要性。
## 188. `cs.AI` - 边缘网络中快速AI模型划分 [PDF](https://arxiv.org/pdf/2507.01041), [HTML](https://arxiv.org/abs/2507.01041)
### Authors
Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin(Sherman)Shen
### Background
分学习（Split Learning，SL）作为一种计算效率高的AI模型训练方法，可以缓解设备侧的计算负担。然而，复杂的AI模型架构导致了高计算复杂度，优化模型划分变得极具挑战性。团队将任意AI模型表示为有向无环图（DAG），并将最佳模型划分问题重新定义为最小s-t割搜索问题。在此基础上，提出了一种快速的基于DAG的模型划分算法，利用最大流方法重构DAG，以识别最佳模型划分。此外，针对具有区块结构的AI模型，提出了区块级划分算法以降低计算复杂度，将每个区块转化为单一节点，简化DAG并进行优化划分。实验结果表明，所提出的算法可以在毫秒内确定最佳模型划分，相较于最先进的基准在动态边缘网络中的训练延迟减少了24.62%-38.95%。
### Innovation
提出了一种快速的基于DAG的模型划分算法，能够利用最大流方法来优化模型划分，并针对具有区块结构的AI模型，提出了区块级划分算法来进一步降低计算复杂度。通过这些方法，能够在毫秒级的时间内确定最佳模型划分，显著减少了训练延迟。
### Conclusion
所提出的算法有效地解决了复杂AI模型架构下的高效模型划分问题，并显著提升了边缘网络中模型训练的效率，证明了其在实际应用中的潜力和价值。
## 189. `cs.AI` - Mixture of Reasonings: 教导大型语言模型使用适应性策略进行推理 [PDF](https://arxiv.org/pdf/2507.00606), [HTML](https://arxiv.org/abs/2507.00606)
### Authors
Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang
### Background
大型语言模型（LLMs）通过复杂的提示技术如思维链（CoT）和思维树（ToT）表现出色，但在使用上依赖于手动构建的任务特定提示，这限制了模型的适应性和效率。现有的方法依赖于手工设计的任务特异性技巧，这不仅降低了效率，也限制了模型的灵活性和可扩展性。本文旨在克服这一局限，提出了一种新的训练框架——混合推理（MoR），通过将多种推理策略嵌入LLMs中，实现自主、任务适应性的推理，从而消除对外部提示工程的需求，提供一种适用于多种任务的稳健推理的通用解决方案。
### Innovation
MoR通过思维生成和数据集构造两个阶段，将多种推理策略嵌入LLMs中，从而实现自主、任务适应性的推理，无需人工设计的任务特定提示。实验结果表明，MoR能够显著提升性能，特别是在使用思维链提示时提升明显，MoR150模型相比基线模型提升了13.5%，展示了MoR在多种任务上的广泛应用和高效性。
### Conclusion
MoR框架通过对多样化推理策略的嵌入实现了一种新的训练方式，消除了传统方法对外部提示的依赖，为大型语言模型提供了一种更灵活、更高效的适应性推理能力，提升了模型在复杂任务上的表现，并为跨任务稳健推理提供了通用解决方案。
## 190. `cs.AI` - 自我引导的过程奖励优化与重新定义的步骤优势在过程强化学习中的应用 [PDF](https://arxiv.org/pdf/2507.01551), [HTML](https://arxiv.org/abs/2507.01551)
### Authors
Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua
### Background
过程强化学习(PRL)已被证明能够显著提高大型语言模型(LLMs)的推理能力。然而，引入额外的过程奖励模型会导致巨大的计算开销，且现缺乏一个统一的理论框架来估计过程级别的优势。
### Innovation
我们提出了S自我引导过程奖励优化(SPRO)这一新框架，通过两个关键创新实现了过程感知的RL：（1）理论上证明了过程奖励可以内生于策略模型本身；（2）引入了明确累加的过程奖励和掩码步骤优势(MSA)，这有助于在共享提示采样组中进行严谨的按步骤动作优势估计。实验结果显示，SPRO相比vanilla GRPO在训练效率上提高了3.4倍，并且测试 accuracy 提高了17.5%。此外，SPRO在整个训练过程中保持了稳定的、升高的策略熵，同时平均响应长度减少了约1/3，证明了足够的探索并防止了奖励作弊。值得注意的是，SPRO相比于如GRPO等结果监督的RL方法，没有增加额外的计算开销，这有利于工业实施。
### Conclusion
我们的实验表明，SPRO在训练效率方面表现优异，测试准确性有所提升，并且能够保持策略熵的稳定性，减少响应长度，同时没有增加额外的计算成本。
## 191. `cs.CL` - 对话中的推理与否？对推理型大模型的全面评估 [PDF](https://arxiv.org/pdf/2507.02145), [HTML](https://arxiv.org/abs/2507.02145)
### Authors
Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira
### Background
对话总结是客户服务中心、会议分析和对话人工智能中具有重要实践价值的任务。尽管大型语言模型已在总结任务上取得了显著进展，但其在需要同时抽象和简洁的对话场景中的逐步推理架构的表现，尤其是长链推理（Long Chain-of-Thought）实现，尚未被探索。本研究覆盖了通用、角色导向和查询导向三种主要对话总结范式，使用SAMSum、DialogSum、CSDS和QMSum等强大基准和先进的评估协议，其中包括基于大模型的自动度量和人类启发的评判标准，对最新推理型和非推理型大模型进行了系统性评估，涉及多种语言、领域和摘要长度。
### Innovation
本研究首次系统地评估了最先进的推理大模型及其在对话总结中的表现，涵盖了三种主要的对话总结范式。研究使用了多种语言、领域和摘要长度的强基准，并引入了基于大模型的自动度量和人类启发的标准进行评估，发现明确的逐步推理并未在对话总结的质量上表现出一致性的改进，相反，推理大模型往往会生成冗长、事实错误和不简洁的摘要，不及非推理大模型。通过场景特定的分析和详细的案例研究，本研究进一步识别了在复杂对话背景下推理可能失败或阻碍总结的具体情况。这项工作的主要创新在于提供了当前推理大模型限制的新见解，并强调了需要为实际对话总结设计针对性更强的建模和评估策略的必要性。
### Conclusion
研究表明，明确的逐步推理并未在对话总结质量上表现出一致性的改进，相比之下，推理大模型可能产生冗长、事实错误和不简洁的摘要。通过具体情况进行分析，发现推理在复杂对话场景下可能会适得其反。本研究提供了当前推理大模型的限制见解，并指出了为实际情况中的对话总结制定针对性更强的建模和评估策略的必要性。
## 192. `cs.AI` - MTCNet：四维超声心动图中主动脉瓣分割的运动和拓扑一致性引导学习 [PDF](https://arxiv.org/pdf/2507.00660), [HTML](https://arxiv.org/abs/2507.00660)
### Authors
Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni
### Background
主动脉瓣反流是心脏最常见的疾病之一。四维（4D）超声已成为评估动态瓣膜形态的主要成像方式。然而，现有的4D主动脉瓣分析方法仍然面临标注数据稀少、严重运动伪影和成像质量差的挑战。现有的方法缺乏跨帧依赖性，限制了4D主动脉瓣分析的效果。因此，寻找一种有效的方法进行4D主动脉瓣超声分割变得尤为重要。
### Innovation
该研究提出了一种名为MTCNet（运动-拓扑引导一致性网络）的方法，专门用于半监督学习（SSL）中的4D主动脉瓣超声分割。MTCNet利用跨相运动引导的一致性学习策略，并采用双向注意记忆库来传播时空特征，实现了优异的性能。同时，通过设计一种新颖的拓扑引导相关性正则化方法，MTCNet可以更好地利用已标记和未标记相位之间的结构对应关系。实验结果表明，MTCNet在首个最大的4D主动脉瓣数据集上表现出色，与其他先进方法相比具有更好的跨相一致性（Dice: 87.30%，HD: 1.75mm）。
### Conclusion
MTCNet在4D主动脉瓣超声分割中表现出色，比其他先进方法有显著的跨相一致性优势。该方法通过针对性地解决4D超声心动图分析中的问题，提供了新的半监督学习解决方案，为未来的研究和应用奠定了基础。
## 193. `cs.AI` - 分布式软值函数评估员---多样化策略 [PDF](https://arxiv.org/pdf/2507.01381), [HTML](https://arxiv.org/abs/2507.01381)
### Authors
Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li
### Background
强化学习在处理复杂控制任务上已被证明非常有效。传统方法通常使用高斯等单模分布来建模价值函数分布，而这种模型容易导致价值函数估计偏差，影响算法性能。因此，需要一种新的算法能够减少这种偏差并提供多元策略表示。
### Innovation
该论文提出了一种名为DSAC-D（分布式软值函数评估员-多样化策略）的新强化学习算法，通过引入策略熵和价值分布函数建立一个多元分布策略迭代框架，保证收敛到最优策略。此外，利用反向采样技术构建扩散价值网络，可以准确描述多峰分布。该算法通过双扩散机制同时优化价值网络和策略网络，改善了估计偏差，显著提高了总平均回报，多项控制任务上表现优异，优于当前主流算法。在实际车辆测试中，该算法能够准确表征不同驾驶风格的多元分布，以及策略网络能够表征多元轨迹。
### Conclusion
研究证明，所提出的DSAC-D算法不仅学习到多元策略，还在9个控制任务中达到了最新最高性能，显著降低了估计偏差，并在总体平均回报上提升了超过10%。在实际车辆测试中，算法成功表征了多元驾驶风格的分布和多元轨迹。
## 194. `cs.AI` - 用汉字编织叙事桥梁：为老年移民打造的人工智能共创工作坊 [PDF](https://arxiv.org/pdf/2507.01548), [HTML](https://arxiv.org/abs/2507.01548)
### Authors
Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen
### Background
这篇论文探讨了如何让老年人，特别是城市中的老年移民，通过人工智能辅助共创来表达那些常常被碎片化、被低估或难以言辞化的个人叙事。参与者通过结合口头讲述和汉字符号的重建来进行试点工作坊，分享移民经历并使用大型语言模型（LLM）建议的夏篆符号创造性地重组新的汉字形式，同时利用物质材料。这些活动是在人类引导与软性人工智能存在支持下的进行，参与者无需具备数字素养就能将生活经历转化为视觉和触觉表达。
### Innovation
该研究提出了一种新的视角，用于探讨人类与人工智能的协作及其在老龄化社会中的应用。不同于传统上将人工智能视为内容生产者，这篇论文将其定位为一种支持机制，并通过支持叙事自主性来促进社会技术系统的结合。通过这种方式，研究提供了新的思考角度，强调了人工智能在老年人群中的辅助作用而非主导作用。
### Conclusion
这项研究展示了如何利用人工智能来促进老年人的叙事表达，特别是对于经历迁移的老年人。通过结合口头讲述、汉字符号的创新和物质材料的应用，参与者能够在无需数字素养的情况下，将个人经历转化为视觉和触觉的艺术表达。此方法不仅具有促进社会技术系统中叙事自决权的意义，也提供了老年人与人工智能协作的新途径，丰富了人类-人工智能协作的研究领域。
## 195. `cs.CL` - McBE：针对大型语言模型的多任务中文偏见评估基准 [PDF](https://arxiv.org/pdf/2507.02088), [HTML](https://arxiv.org/abs/2507.02088)
### Authors
Tian Lan,Xiangdong Su,Xu Liu,Ruirui Wang,Ke Chang,Jiang Li,Guanglai Gao
### Background
随着大型语言模型（LLMs）在各种自然语言处理（NLP）任务中的应用不断增加，其固有的偏见逐渐被揭露。因此，衡量LLMs中的偏见以减轻其伦理风险变得至关重要。然而，大多数现有的偏见评估数据集集中在英语和北美文化上，且其偏见类别不完全适用于其他文化。基于中文语言和文化的数据集稀缺。更重要的是，这些数据集通常只支持单一的评估任务，无法从多方面评估LLMs中的偏见。
### Innovation
为了解决这些问题，作者提出了一个名为McBE（多任务中文偏见评估基准）的数据集，其中包括4,077个偏见评估实例，覆盖了12个单一偏见类别、82个子类别，并引入了5个评估任务，提供广泛的类别覆盖、内容多样性和全面的衡量标准。另外，作者还评估了几种不同系列和不同参数量的流行LLMs。总的来说，这些LLMs在不同程度上都展现了偏见。
### Conclusion
作者对结果进行了深入分析，提供了关于LLMs中偏见的新颖见解。
## 196. `cs.AI` - AC-DiT: 自适应协调扩散变换器在移动操作中的应用 [PDF](https://arxiv.org/pdf/2507.01961), [HTML](https://arxiv.org/abs/2507.01961)
### Authors
Sixiang Chen,Jiaming Liu,Siyuan Qian,Han Jiang,Lily Li,Renrui Zhang,Zhuoyang Liu,Chenyang Gu,Chengkai Hou,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang
### Background
近期，移动操作由于能够实现基于语言的机器人控制而受到广泛关注，特别是在家庭任务中。然而，现有的方法在协调移动底盘和操作臂时仍然面临挑战，主要问题在于两个方面。首先，它们无法明确模拟移动底盘对操作臂控制的影响，这容易导致高自由度下的误差累积。其次，现有的方法使用相同的视觉观察模态（例如，2D或3D）来处理整个移动操作过程，忽视了在不同阶段进行移动操作所需的多种感知要求。因此，本文提出了自适应协调扩散变换器（AC-DiT），旨在增强移动底盘和操作臂的协调，以实现端到端的移动操作控制。
### Innovation
提出了自适应协调扩散变换器（AC-DiT），通过引入移动性到肢体的条件机制和感知感知自适应多模态条件策略，分别解决了现有方法在协调移动底盘和操作臂方面的两个主要问题。首先，该机制能帮助模型首先提取底盘运动表示，作为预测整体动作的上下文先验，以考虑底盘运动的潜在影响，进而实现整体控制；其次，策略能够根据不同阶段的感知要求，动态调整2D视觉图像和3D点云之间的融合权重，从而生成适应当前感知需求的视觉特征。AC-DiT能够在需要语义信息或精确空间理解时，灵活调整对2D输入或3D几何信息的依赖程度。
### Conclusion
通过在模拟和实际移动操作任务中的广泛应用验证了AC-DiT的有效性，表明该方法能够有效解决现有方法在协调移动底盘和操作臂方面的局限性，从而提高移动操作控制的效率和准确性。
## 197. `cs.CL` - MemAgent: 以多对话RL为基础的记忆代理重塑长上下文LLM [PDF](https://arxiv.org/pdf/2507.02259), [HTML](https://arxiv.org/abs/2507.02259)
### Authors
Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou
### Background
尽管通过长度外推、高效注意力和记忆模块的改进，处理无限长文档并在外推过程中保持线性复杂性和不降低性能仍然是长文本处理中的最终挑战。
### Innovation
MemAgent通过直接以端到端的方式优化长文本任务，并引入了一个新的代理工作流程，即读取文本段落并使用覆盖策略更新记忆。扩展DAPO算法以通过独立上下文的多对话生成进行训练，从而增强长期上下文能力，能够在8K上下文训练32K文本的基础上外推到3.5M问答任务，并保持少于5%的性能损失，同时实现512K RULER测试中的95%以上成绩。
### Conclusion
MemAgent展示了出色的长期上下文能力，有效地处理大规模文本数据，提高了长文本处理的性能和效率。
## 198. `cs.AI` - Skywork-Reward-V2: 通过人机协同扩展偏好评价数据的整理 [PDF](https://arxiv.org/pdf/2507.01352), [HTML](https://arxiv.org/abs/2507.01352)
### Authors
Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou
### Background
尽管奖励模型（RMs）在从人类反馈（RLHF）实现强化学习中发挥着关键作用，当前最先进的开放奖励模型在大多数评价基准测试中表现不佳，未能捕捉到人类微妙而复杂的偏好。即使一些先进训练技术的应用也没有带来实质性的性能提升。研究认为，这种脆弱性主要来自于偏好评价数据集的限制，这些数据集通常范围狭窄、合成标签或者缺乏严格的质控。为解决这些挑战，本文构建了一个包含4000万偏好评价对的大规模数据集SynPref-40M，并设计了一个结合人类和人工智能的两阶段数据整理管道，以充分利用人类注释质量和人工智能的扩展性。
### Innovation
本文创新性地提出了一种基于大规模偏好评价数据集SynPref-40M的两阶段人机协同数据整理方法，通过这种方法整理了2600万偏好评价对，训练出了包含从0.6B到8B参数的八种Skywork-Reward-V2奖励模型。实验结果表明，Skywork-Reward-V2在多种能力方面表现出色，包括偏好对齐、客观正确性、安全性、反偏设计以及多选最优扩展等，其在七个主要奖励模型基准测试中均取得了领先的成绩。进一步的消融研究证明，该方法的有效性不仅来自于数据量，还来自于高质量的数据整理。Skywork-Reward-V2系列代表着开放奖励模型的重大进展，展示了现有偏好评价数据集的巨大潜力并且证明了人机协同整理能够实现显著更高的数据质量。
### Conclusion
Skywork-Reward-V2展现了在基于偏好评价的大规模数据整理和模型训练方面的显著进步，充分挖掘了现有偏好评价数据集的潜力，并证明了人机协同在提高数据质量方面的巨大潜力。
## 199. `cs.CL` - 通过一致分布和多样性感知的数据选择实现高效的代码LLM培训 [PDF](https://arxiv.org/pdf/2507.02378), [HTML](https://arxiv.org/abs/2507.02378)
### Authors
Weijie Lyu,Sheng-Jun Huang,Xuan Xia
### Background
近年来，大规模语言模型（LLMs）在代码生成和程序理解方面取得了显著进步，加速了软件工程的发展。当下的方法主要通过大量数据来提高模型性能，但往往忽视了数据质量，这降低了训练效率。
### Innovation
本文提出了一种参数化模型用于代码数据选择的方法，旨在提高训练效率和模型性能。该方法优化参数化模型以确保所选子集中的分布一致性与多样性，保证了高质量的数据。实验结果表明，仅使用10K样本时，该方法在HumanEval和MBPP上的性能分别比92K全样本基线高出2.4%和2.3%，在性能和效率上均优于其他采样方法。这证明了该方法有效提升了模型性能并显著降低了计算成本。
### Conclusion
通过一致分布和多样性感知的数据选择方法可以有效提升大规模语言模型的性能，并大幅降低计算成本。
## 200. `cs.CL` - DoMIX: 一种高效的利用领域知识进行微调的框架 [PDF](https://arxiv.org/pdf/2507.02302), [HTML](https://arxiv.org/abs/2507.02302)
### Authors
Dohoon Kim,Donghun Kang,Taesup Moon
### Background
Domain-Adaptive Pre-training (DAP) 近期因其在预训练模型微调中的有效性引起了广泛关注。进一步发展了持续DAP，能够增量地融合不同领域的数据集。然而，现有的持续DAP方法面临一些限制，包括：(1) 训练过程中高昂的计算成本和 GPU 内存使用；(2) 对增量数据顺序的敏感性；(3) 提供单一的、通用的模型，这与DAP的本质相悖。现有方法的这些局限性推动了对更高效、更具鲁棒性的新方法的需求。本论文正是基于这一背景，探索了利用LoRA模块（一种代表性的参数高效微调方法）来解决这些挑战的创新方法DoMIX，以实现在任务特异性中提供知识定制的预训练模型。
### Innovation
提出了一种名为DoMIX的新方法，通过利用LoRA模块来实现高效且并行的领域自适应预训练。该方法具有以下创新点：(1) 在训练过程中能够有效降低计算成本和 GPU 内存使用；(2) 对增量数据顺序具有鲁棒性；(3) 能有效利用累积知识以提供专用于特定任务的预训练模型。此外，本文还展示了DoMIX方法不仅限于DAP场景，还可以应用于标准的大语言模型微调（LLM fine-tuning）场景。
### Conclusion
通过引入DoMIX，该论文显著解决了持续DAP方法中的计算成本高、对数据顺序敏感和只提供通用模型等局限性问题。DoMIX方法能够更有效地适应不同领域的数据集，并为特定任务提供定制的预训练模型。同时，DoMIX方法的通用性也使其能够应用于标准的大语言模型微调场景。
## 201. `cs.CL` - 潜思维推理？剖析深度递归变压器 [PDF](https://arxiv.org/pdf/2507.02199), [HTML](https://arxiv.org/abs/2507.02199)
### Authors
Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu
### Background
链式思维（CoT）推理使基于变换器的自然语言模型在复杂数学和多步规划方面表现出色。然而，在标准的解码器架构中，这些推理步骤是以自然语言形式外部化，这提高了可解释性但降低了效率。为了捕捉非自然语言容易表达的推理，很多研究探索了递归架构，旨在在潜在空间中 internalize 推理，可能支持潜在 CoT。Huginn-3.5B 是一个深度递归变换器，通过在推理时重用层而不增加参数数量，来探究这样一种推理结构是否会在该模型中出现。使用一系列探针技术包括 Logit 焦点和 Coda 焦点，考察了模型在算术任务中的内部行为。研究表明，跟踪最终结果和中间结果token的秩轨迹只能发现有限的可解释潜在 CoT证据。此外，还发现递归块之间存在显著的探针不一致性，隐藏状态的可解释性很大程度上取决于所使用的层索引和解码方法。最后实验证明，增加递归深度仅获得轻微增益，远不及那些显式地外部化推理步骤的模型。
### Innovation
提出了 Huginn-3.5B，这是一个深度递归变换器，它在推理时重用了层，而没有增加参数数量。使用多种探针技术（如 Logit Lens 和 Coda Lens）研究模型在算术任务上的内部行为，探究潜在的 CoT 推理结构是否会在模型中自然产生。
### Conclusion
研究表明 Huginn-3.5B 中的潜在 CoT 推理结构有限，递归深度的增加对提升模型性能只有轻微作用，未能达到那些具有显式推理步骤的模型的效果。
## 202. `cs.CL` - QFFN-BERT: 关于混合量子-经典变换器的深度、性能和数据效率的实证研究 [PDF](https://arxiv.org/pdf/2507.02364), [HTML](https://arxiv.org/abs/2507.02364)
### Authors
Pilsung Kang
### Background
参数化量子电路（PQCs）近年来被证明是提升神经架构表达能力的有前途的组件。传统的变换器编码器模块中的前馈网络（FFN）模块占据了约2/3的参数，因此是参数贡献的主要部分。多数先前的研究主要集中在将PQCs集成到自我注意模块中，而这项工作关注FFN模块，并系统地研究了PQC的深度、表达能力和可训练性之间的权衡。实验结果表明，QFFN-BERT 在数据集完整的情况下可以超过其经典对等模型，并且在少量样本学习场景中表现出一致的竞争力，进一步验证了模型的高效性。通过对未优化的PQC进行消融研究，作者证明了PQC可以作为与基础深度学习原则共设计的强而有效的经典FFN替代品。
### Innovation
QFFN-BERT是一种混合量子-经典变换器，其中紧凑型BERT变体的FFN模块被PQC层替换。该设计考虑了FFNs是主要参数贡献者这一事实，并通过使用残差连接、R_Y和R_Z旋转变换以及交替纠缠策略来确保模型的稳定训练和高表达性。研究表明，精心配置的QFFN-BERT在满数据设置下可以达到基准准确率的102%，同时在FFN专用参数上减少了99%。在少量样本学习场景中，模型也表现出一致的竞争优势。
### Conclusion
实验结果表明，通过QFFN-BERT，可以实现显著的表达能力提升和参数效率，这表明PQC可以作为经典FFNs的有效替代品。模型的验证通过潜化研究未优化的PQC未成功学习来完成，进一步证明了PQC在共设计的深度学习原则下的强大表现力。
## 203. `cs.CL` - Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models [PDF](https://arxiv.org/pdf/2507.02357), [HTML](https://arxiv.org/abs/2507.02357)
### Authors
Christian Jaumann,Annemarie Friedrich,Rainer Lienhart
### Background
该论文描述了作者参加的SciVQA 2025共享任务。在此任务中，参与者需要构建一个系统，能够对科学可视化的问题进行解答。科学可视化涉及科学研究中的图像解释和问题回答，这是一个复杂且技术密集型的任务，以往的研究通常会使用多种方法和技术来提高系统的性能。论文中提到的系统结合了多种技术和策略，以应对这一挑战。
### Innovation
本文提出的创新点在于，系统采用了两种多模态大型语言模型的集成，并结合了各种少样本示例检索策略。不同的模型和少样本设置是根据图像和问题类型选择的，同时答案的选择也是基于模型的信心水平。这种方法展示了在面对复杂的科学可视化问题时，组合不同技术和策略的有效性。
### Conclusion
在盲测试数据上，该系统在七个系统中排名第三，平均F1分数为85.12，涵盖了ROUGE-1、ROUGE-L和BERTS。此外，论文还提到代码已开源。
## 204. `cs.CL` - GDC Cohort Copilot: 一个用于从基因组数据共用（GDC）创建队列的人工智能副驾 [PDF](https://arxiv.org/pdf/2507.02221), [HTML](https://arxiv.org/abs/2507.02221)
### Authors
Steven Song,Anirudh Subramanyam,Zhenyu Zhang,Aarti Venkat,Robert L. Grossman
### Background
基因组数据共用（GDC）提供了一个统一的平台，为用户提供高质量且标准化的癌症基因组学数据访问。用户可以通过图形界面的队列构建器创建复杂的队列，然而这一过程对于新手用户来说可能比较困难，特别是在寻找具体的队列描述符时，由于可能涉及大量的字段和属性，用户发现特定队列的过程复杂且费时。因此，存在着提高用户描述他们所需队列的能力的需求，从而使得数据分析过程更加高效和便捷。
### Innovation
本文介绍了一种名为GDC Cohort Copilot的开源副驾工具，该工具能够自动根据用户输入的自然语言描述自动生成GDC队列过滤器，然后将这些队列导回GDC进行进一步分析。此外，作者开发并评估了多种大型语言模型（LLMs）用于GDC Cohort Copilot，证明了本地服务的开源GDC Cohort LLM在生成GDC队列方面比GPT-4o提示效果更好。这一工具的实现采用了一个独立的Docker镜像，并且所有源代码和模型权重都已开源。这些创新使得基因组数据的管理和分析更加便捷和高效。
### Conclusion
GDC Cohort Copilot通过利用自然语言处理技术，显著简化了从GDC创建和管理癌症基因队列的过程。这些改进不仅提高了用户的体验，还促进了科研人员在基因组学领域的创新和合作。
## 205. `cs.CL` - IndianBailJudgments-1200: 用于印度保释令的多属性数据集 [PDF](https://arxiv.org/pdf/2507.02506), [HTML](https://arxiv.org/abs/2507.02506)
### Authors
Sneha Deshmukh,Prathmesh Kamble
### Background
印度等地区的法律自然语言处理(NLP)仍处于发展初期，主要是因为缺乏结构化的数据集。因此，急需开发高质量的数据集来支持相关研究和应用的发展。
### Innovation
作者引入了名为IndianBailJudgments-1200的新基准数据集，该数据集包含1200份印度法院关于保释的判决书，涵盖20多种属性，包括判决结果、印度刑法代码章节、犯罪类型和法律推理等内容。这些注释是通过工程化的GPT-4o管道生成并验证一致性的。该数据集支持广泛的应用场景，如预测判决结果、总结和公平性分析，并且是第一个专用于印度保释法律的公开数据集。
### Conclusion
该数据集为法律NLP领域的研究和应用提供了重要支持，并推动了相关技术在印度特定法律领域的发展。
## 206. `cs.CL` - 重访在（人类）标签变异情况下主动学习 [PDF](https://arxiv.org/pdf/2507.02593), [HTML](https://arxiv.org/abs/2507.02593)
### Authors
Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher
### Background
高质量标注数据是应用监督学习的关键限制因素。标签变异（LV）是一个普遍存在的问题，特别是在自然语言处理领域。现有标注框架通常假定单一的地面真相，忽略了人类标签变异（HLV）作为有意义信号的可能性。此外，主动学习（AL）尽管是优化有限标注预算的一种常用方法，但它依赖的一些简化假设在考虑HLV时往往不能成立。因此，有必要将观测到的LV分解为信号（如HLV）和噪声（如标注错误）
### Innovation
本文探讨了关于真实性和标签本质的基础假设，强调需要将LV分解为信号和噪声。研究检视了AL 和 (H)LV 社区如何处理或忽视这些区别，并提出了一种概念框架，在整个AL循环中纳入HLV，并讨论了将大型语言模型（LLM）作为注释者的整合。这项工作旨在建立一种基于HLV的主动学习的概念基础，更好地反映现实世界标注的复杂性
### Conclusion
本文提出了一个概念框架，以在主动学习的过程中更好地纳入人类标签变异，并讨论了在实例选择、注释者选择和标签表示方面整合大型语言模型的方法。
## 207. `cs.CL` - 探索职业头衔之外的性别偏差 [PDF](https://arxiv.org/pdf/2507.02679), [HTML](https://arxiv.org/abs/2507.02679)
### Authors
Ahmed Sabir,Rajesh Sharama
### Background
该研究探讨了性别和语境偏差之间的关联，主要关注动词、名词，尤其是职业中的性别偏差。研究者开发了GenderLexicon数据集及评估框架，能够量化评估偏差及其相关性别偏差，并提供了解释性别偏差的分数，从而提高了对性别偏差的理解。研究结果还表明，性别偏差存在于职业刻板印象之外。为了验证方法的有效性，研究团队在包括日本数据集在内的五个不同数据集上进行了评估验证。
### Innovation
引入了一个新的数据集，GenderLexicon，和一个能够估计上下文偏差及其相关性别偏差的框架。该模型通过评分来解释性别偏差，提高了性别偏差的可解释性。此外，研究结果证实了性别偏差存在于职业刻板印象之外。
### Conclusion
研究通过五个不同数据集验证了其方法的有效性，并发现性别偏差在职业刻板印象之外也存在。通过引入GenderLexicon数据集和新的评估框架，该研究提高了对性别偏差的解释和理解。
## 208. `cs.CL` - MPF: 通过多视角融合在部署后对语言模型进行对齐和偏见消除 [PDF](https://arxiv.org/pdf/2507.02595), [HTML](https://arxiv.org/abs/2507.02595)
### Authors
Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama
### Background
随着对大型语言模型（LLMs）中偏见缓解的需求日益增长，研究人员需要开发一种简便的方法来解决这一问题。为此，开发了一个新的后训练对齐框架——Multiperspective Fusion (MPF)，该框架基于SAGED管道，一个自动化的偏见基准构建系统和可解释基线分布的提取系统。
### Innovation
MPF 利用多视角生成来展示和对齐LLM输出中的偏见，与细腻的人类似基线对齐。它通过将基线，如人力资源专业人士的情感分布，分解为可解释的视角组件，指导生成过程，通过采样和响应平衡，权重由分解中获得的概率确定。
### Conclusion
实证研究表明，MPF 能够将LLM的情感分布与反事实基线（绝对平等）和人力资源基线（倾向于顶尖院校）对齐，从而导致小的KL分歧、减少校准误差，并实现对未见过问题的泛化。这表明MPF提供了一种可扩展且可解释的对齐和偏见缓解方法，适用于部署中的LLM，无需大量提示工程或微调。
## 209. `cs.CL` - WebSailor：网络代理超人类推理导航 [PDF](https://arxiv.org/pdf/2507.02592), [HTML](https://arxiv.org/abs/2507.02592)
### Authors
Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou
### Background
超越人类认知局限是大型语言模型（LLM）训练的关键前沿。专有的代理系统如DeepResearch在复杂的查询基准测试中展现了超凡的能力，这在过去是不可实现的。研究表明，其成功的关键在于一种开放源码模型所缺乏的复杂推理模式：系统性减少导航广阔信息空间时的极端不确定性。基于此，提出了一种名为WebSailor的完整后训练方法来培养这种关键能力。该方法通过结构化采样、信息混淆、RFT冷启动以及高效的代理强化学习算法DUPO生成新型高不确定性任务.
### Innovation
通过生成新型高不确定性任务的方法，包括结构化采样、信息混淆、RFT冷启动和DUPO高效代理强化学习算法，提出了WebSailor后训练方法。这种方法在复杂的查询任务中显著优于所有开源代理，并达到了专有代理的性能，缩小了能力差距.
### Conclusion
WebSailor显著提升了在复杂信息查询任务中的表现，不仅与专有代理匹配，还填补了能力差距，展示了系统性减少导航广阔信息空间时极端不确定性的能力。
## 210. `cs.CL` - 低资源语言中受损语音社区驱动数据收集的手册 [PDF](https://arxiv.org/pdf/2507.02428), [HTML](https://arxiv.org/abs/2507.02428)
### Authors
Sumaya Ahmed Salihs,Isaac Wiafe,Jamal-Deen Abdulai,Elikem Doe Atsakpo,Gifty Ayoka,Richard Cave,Akon Obu Ekpezu,Catherine Holloway,Katrin Tomanek,Fiifi Baffoe Payin Winful
### Background
本文介绍了为建立自动语音识别(Automatic Speech Recognition, ASR)模型收集受损语音样本的方法，特别关注于低资源语言。目的是通过开发最佳实践指南和社区驱动的数据收集及ASR模型构建培训，推进ASR技术的普及。该研究通过整理了一批开放源代码的Akan语言受损语音数据集来作为概念验证，Akan是加纳广泛使用的土著语言。研究参与者来自不同背景的言语受损人士。该数据集以及手册和开源工具都是公开的，供研究人员和实践者创建针对言语受损人士独特需求的包容性ASR技术之用。此外，该研究还展示了对开源ASR模型进行微调以更好地识别Akan语言中受损语音的初步结果。
### Innovation
本研究通过开发一套最佳实践指南和社区驱动的数据收集及ASR模型构建培训，旨在普及ASR技术和数据收集。此外，该研究还呈现了对开源ASR模型进行微调以更好识别低资源语言中受损语音的方法。这是第一次收集低资源语言中受损语音数据的开放源代码数据集。
### Conclusion
本文研究结果表明，通过优化ASR模型并利用社区驱动的方法，可以建立适用于受损语音识别的ASR技术，特别是在低资源语言中。这些技术和数据资源公开共享，可促进研究人员和实践者创建更具包容性的ASR技术，更好地满足受损群体的需求。
## 211. `cs.CL` - 多视角下的多模态数学推理 [PDF](https://arxiv.org/pdf/2507.02804), [HTML](https://arxiv.org/abs/2507.02804)
### Authors
Wenhao Shi,Zhiqiang Hu,Yi Bin,Yang Yang,See-Kiong Ng,Heng Tao Shen
### Background
近年来，大规模强化学习（RL）的进步显著增强了大型语言模型（LLMs）的推理能力，尤其是在数学领域。然而，当前用于数学推理的多模态语言模型（MLLMs）往往依赖单一的图像-文本对和单个解决方案的监督，忽视了多种有效的推理视角和内部反思的多样性。
### Innovation
本文介绍了MathV-DP，这是一个新的数据集，为每张图像-问题对捕捉了多种多样的解题路径，促进更丰富的推理监督。此外，我们提出了Qwen-VL-DP模型，该模型基于Qwen-VL，通过监督学习微调并结合基于规则的RL方法（GRPO）进行增强，这种方法通过纠正性区分和多样化意识的奖励函数相结合来整合不同正确性的推理过程。该方法强调从多种推理视角学习，并区分正确但不同的解决方案。
### Conclusion
在MathVista的minitest和Math-V基准上的广泛实验表明，Qwen-VL-DP在准确性和生成多样性方面显著优于之前的基线MLLMs，强调多样化视角和反思推理在多模态数学推理中的重要性。
## 212. `cs.CL` - LLMs能否识别科学研究中的关键局限性？基于AI研究论文的系统性评估 [PDF](https://arxiv.org/pdf/2507.02694), [HTML](https://arxiv.org/abs/2507.02694)
### Authors
Zhijian Xu,Yilun Zhao,Manasi Patwardhan,Lovekesh Vig,Arman Cohan
### Background
同行评审是科学研究中的基础环节，但出版物数量的增加使得这一专业人士密集型过程的挑战加剧。虽然语言模型（LLMs）在各种科学任务中显示出潜力，但在识别论文局限性方面协助同行评审，尤其是找到论文不足方面，其作用尚待研究。为了研究论文局限性，本文首次提出了一种综合基准LimitGen，该基准旨在评估LLMs在提供早期反馈和补充人类同行评审方面的能力，并包含合成数据集和真实的人类撰写的局限性集。
### Innovation
本文创新性地提出了一种新的基准——LimitGen，用于评估LLMs在科学论文中识别局限性的能力，并结合文献检索技术提高LLMs的局限性识别能力，从而使它们能够提供更具体和建设性的反馈。这是首次在AI研究领域进行此类评估，为研究和应用LLMs在科学同行评审中的作用提供了新的思路。
### Conclusion
本文的方法通过合成数据集和真实的人类撰写的局限性集，有效增强了LLMs识别限制定量的能力，使得它们能够在科学论文同行评审中提供更具体且有建设性的反馈。未来的研究还可以扩展这种评估方法到其他类型的科学文献中，以进一步探索和优化LLMs的同行评审支持功能。
## 213. `cs.CL` - 跨领域数据集评估阿坎自动语音识别模型：性能、扩展性和适应性比较评估 [PDF](https://arxiv.org/pdf/2507.02407), [HTML](https://arxiv.org/abs/2507.02407)
### Authors
Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame
### Background
大多数现有的自动语音识别（ASR）研究使用领域相关数据集评估模型，但鲜少考察模型在不同语音场景下的泛化能力。这项研究通过使用四种阿坎语言语音语料库对七个基于变压器架构的阿坎ASR模型进行基准测试，确定了这些模型的性能。这些数据集涵盖了不同领域，包括文化相关图像描述、非正式对话、圣经经文朗读和自发财务对话。错误率分析表明，模型在训练领域内表现最优，而在其他场景则表现较差。此外，研究还发现了 Whisper 和 Wav2Vec2 架构在错误行为上的差异，Whisper 细化模型可能导致更流畅但可能误导的转录错误，而 Wav2Vec2 在遇到不熟悉输入时则会产生更明显但难以解释的输出。因此，选择架构时需要在可读性和透明性之间进行权衡，特别是在低资源语言（LRL）应用中。这些发现强调了需要为阿坎语和其它 LRL 开发针对特定领域的适应性技术、适应性路由策略以及多语言培训框架的需求
### Innovation
该研究通过使用不同的阿坎语言语音数据集对多个基于变压器架构的阿坎ASR模型进行基准测试，以评估其在不同领域的性能和适应性，特别是针对其他语音场景的泛化能力。此外，研究比较了不同ASR模型（Whisper 和 Wav2Vec2）在面对未知输入时的行为差异，为未来发展适用于低资源语言的ASR技术提供了新思路
### Conclusion
这项研究强调了为阿坎语和其他低资源语言开发专门的领域适应技术、动态路由策略和多语言训练框架的必要性，以提高在不同语音场景下的表现。同时，选择适合不同应用场景的ASR模型时，需要权衡模型在可读性和透明性之间的差异，以满足不同的用户需求。
## 214. `cs.CL` - Just可感知差异（JPD）阈限测量音节数量性颗粒度 [PDF](https://arxiv.org/pdf/2507.02744), [HTML](https://arxiv.org/abs/2507.02744)
### Authors
Peter Viechnicki
### Background
过去几十年的研究表明，人类元音发声的复杂协调发音运动主要由控制机制管理，这些控制机制的目标是听觉空间的区域。在这些目标区域内，在次音位水平上也已经证明了控制的存在。但这种控制的精确度尚不明确。当前的研究通过询问两个元音刺激在听觉空间中必须相隔多远才能可靠地产生不同的模仿来探讨这一问题。这个距离被称为'Just可感知差异'（JPD）。当前的研究使用元音模仿范式，在两个英语群体间测量了前元音的JPD。JPD估计值在F1 X F2空间中的14至51梅尔之间。
### Innovation
首次使用元音模仿范式测量两个英语群体在前元音发音时的JPD值，确立了人类发音系统的理论下限，解释了观察到的元音音位数和模式趋势，对语音产生的经验理论具有重要意义，明确了人类元音系统的可能结构
### Conclusion
测量结果显示，两个元音刺激在F1 X F2空间中至少相隔14至51梅尔时，才能可靠地产生不同的模仿。这为理解人类元音系统的结构提供了新的见解，也为语音产生的理论发展奠定了基础。
## 215. `cs.CL` - 推理全是你需要的吗？在推理语言模型时代探究偏见 [PDF](https://arxiv.org/pdf/2507.02799), [HTML](https://arxiv.org/abs/2507.02799)
### Authors
Riccardo Cantini,Nicola Gabriele,Alessio Orsino,Domenico Talia
### Background
研究表明，语言模型可以通过连锁思维或细化推理痕迹机制执行复杂且多步骤的推理任务。这些技术有望提高模型的可靠性，但其对消除社交偏见的影响尚不清楚。本文借助用于大型语言模型的CLEAR-Bias基准，探讨了推理语言模型在应对偏见激发方面的对抗鲁棒性。研究通过针对社会文化维度进行系统的评估，使用大型语言模型作为法官的自动安全评分方法，并利用脱逃技术测试内置安全性机制的强度，来回答三个关键问题：推理能力的引入如何影响模型的公平性和鲁棒性；推理模型的微调是否比依赖于推理过程中的连锁思维提示的模型更具安全性；不同的推理机制如何影响针对偏见激发的脱逃攻击成功率。
### Innovation
该研究利用CLEAR-Bias基准，系统评估了最新的推理模型在社会文化维度上的鲁棒性；通过大型语言模型来自动评分安全性和脱逃攻击强度；特别关注了推理模型在面对偏见激发时的表现以及连锁思维提示与直接推理微调的对比，揭示了推理能力和偏见安全性之间的复杂关系。这项研究挑战了推理会自然提高模型鲁棒性的假设，强调了在设计时更需关注偏见的意识和策略。
### Conclusion
研究表明，具有显式推理的模型，无论是通过连锁思维提示还是微调推理痕迹，相较于基础模型来说更容易受到偏见激发的影响，这表明推理可能无意中开辟了新的刻板印象强化途径。启用推理功能的模型相较于依赖连锁思维提示的模型似乎更安全，后者特别容易受到通过讲故事提示、虚构人格或奖励导向指令进行的语境重构攻击。这些结果表明，不能假设推理自然提高了模型的鲁棒性，并强调了需要采用更关注偏见的方法设计推理功能。
## 216. `cs.CL` - 验证指令遵循的通用化 [PDF](https://arxiv.org/pdf/2507.02833), [HTML](https://arxiv.org/abs/2507.02833)
### Authors
Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi
### Background
人机交互的关键因素之一是语言模型或聊天机器人的精确遵循人类指令的能力。用户常会在指令中加入输出约束条件，如‘仅用是或否回答’或‘至少提到单词“abrakadabra”三次’。当前最强的模型也难以实现这一点。研究发现，大多数模型在有限的验证约束基准中过度拟合，未能很好地对未见过的输出约束进行泛化。为了评估模型对新型验证指令跟随能力的泛化能力，引入了一个新的基准IFBench，并深入分析了如何通过优化数据训练模型以提升该能力。
### Innovation
1. 提出一个新的基准IFBench，用于评估对58种新的、多样化且具有挑战性的验证约束条件的泛化能力。2. 设计验证约束模块，通过强化学习以可验证奖励（RLVR）的方式显著提高了指令遵循能力。3. 释放额外的29个新手动标注的训练约束和验证函数以及RLVR训练提示和代码，以便其他研究者参考和使用。
### Conclusion
该研究通过提出新的IFBench基准并引入RLVR方法，提高了语言模型在未见过的验证约束条件下的指令遵循泛化能力。这为未来的人机交互语言模型的发展奠定了坚实基础。
## 217. `cs.CL` - SynapseRoute: 在双状态大语言模型上的自动路由切换框架 [PDF](https://arxiv.org/pdf/2507.02822), [HTML](https://arxiv.org/abs/2507.02822)
### Authors
Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun
### Background
随着大型语言模型在实际应用中的广泛应用，选择合适的模型需要在性能和运维成本之间寻求平衡。具有推理能力的模型进一步拉大了'思考'（高推理）模式和'非思考'（快速、低成本）模式之间的成本差距。本文研究表明大约58%的医学问题仅需'非思考'模式即可准确回答，无需进行高成本的推理过程，这揭示了问题复杂度的明显差异，表明根据问题复杂度动态路由查询可以优化准确度、成本效益以及整体用户体验。
### Innovation
本文提出了SynapseRoute，一种基于机器学习的动态路由框架，智能化地将输入查询分配至‘思考’或‘非思考’模式。在多个医学数据集上进行的实验表明，SynapseRoute不仅将整体准确度提高了0.8390相比单独使用‘思考’模式下的0.8272，而且使推理时间减少了36.8%，降低了39.66%的令牌消耗。此外，定量分析还表明，过度推理可能导致简单查询的延迟增加，甚至降低准确度，这是通过我们的自适应路由避免的。本研究还进一步引入了准确度-推理-令牌（AIT）指标，以全面评估准确度、延迟和令牌成本之间的权衡。
### Conclusion
基于SynapseRoute框架，能够根据查询的复杂度动态路由查询，从而提高准确度、降低成本并优化用户体验。引入了AIT指数全面评估了准确度、延迟和令牌成本之间的权衡关系。
## 218. `cs.CL` - LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users [PDF](https://arxiv.org/pdf/2507.02850), [HTML](https://arxiv.org/abs/2507.02850)
### Authors
Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas
### Background
该研究描述了一种语言模型（LMs）的漏洞，该漏洞允许单个用户通过提供提示以及对LM输出进行投票（点赞或点踩），持久地改变LM的知识和行为。这种攻击通过反馈信号在后续的行为调优中，使得LM在没有恶意提示的情况下也更有可能生成被污染的响应。研究表明，这种攻击能够（1）插入模型原本不具备的事实性知识；（2）修改代码生成模式以引入可被利用的安全漏洞；（3）注入虚假的财经新闻。该发现揭示了语言模型行为调优的新定性特征，并扩展了对用户反馈训练的LM攻击机制的研究。
### Innovation
这项研究首次证明了即使是最受限制的反馈类型，也可能被用于细粒度控制行为。它扩展了关于预训练时数据污染和部署时提示注入的工作，提出了一种新的针对用户反馈训练语言模型的攻击手段。
### Conclusion
研究结果表明，语言模型在使用用户反馈进行行为调优时存在一个严重的安全缺陷，单个用户可以持久且细粒度地改变模型的行为和知识。这种攻击可以广泛应用于插入虚假信息、修改代码生成过程和引入安全漏洞。
## 219. `cs.CL` - 答案匹配超越多项选择用于语言模型评估 [PDF](https://arxiv.org/pdf/2507.02856), [HTML](https://arxiv.org/abs/2507.02856)
### Authors
Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping
### Background
多项选择基准长期以来一直是评估语言模型的工具，因为评分多项选择是客观的且容易自动化。然而，研究表明，流行的基准中的多项选择问题往往可以仅通过看选项而不看问题就能解答。这些捷径来源于判别式评估的关键局限，这种局限是模型生成的自由格式回答评估所不具有的。最近，似乎没有可扩展的替代方案，但研究展示了这种情况已经改变。提出了通过我们称为答案匹配的生成评估方式：给候选模型提供问题而不提供选项，要求其生成自由格式的回复，然后使用现代语言模型和参考答案来确定回复是否与参考答案匹配。为了对比不同的评估策略的有效性，将MMLU-Pro和GPQA-Diamond标注为人评判分数据，并测量每种评估方法的一致性。我们发现，即便使用小型模型，答案匹配也能实现近乎完美的一致性，接近于人与人之间的评估一致性。相比之下，多项选择评估和使用大型语言模型作为评判者但没有参考答案的效果与人评估不匹配。通过答案匹配改进评估不只是一个概念问题：几种模型的排名在评估其自由格式回答时会有显著变化。
### Innovation
提出了一种新的生成评估方式——答案匹配，通过这种方法，即使使用小型模型，也能实现近乎完美的一致性。而传统的多项选择评估和没有参考答案的大型语言模型作为评判者的方法则与人评估不匹配。这种方法改变了评估生态，从单一的多项选择评估转向答案匹配评估。
### Conclusion
研究表明，通过答案匹配的方式进行评估比传统的多项选择更有效，可以更准确地反映模型的真实表现。鉴于这项发现，评估生态应该从多项选择向答案匹配转型。
## 220. `cs.CL` - 使用语言、视觉和社会特征早期融合进行多模态虚假信息检测 [PDF](https://arxiv.org/pdf/2507.01984), [HTML](https://arxiv.org/abs/2507.01984)
### Authors
Gautam Kishore Shahi
### Background
社交媒体在选举和危机期间充斥着误传播信息，已有大量研究集中在文本或图像的误传播信息检测上，少数研究融合了文本、图像和社会特征，采用早期融合方法构建分类模型。这项研究分析了不同多模态特征组合的有效性，结合了文本、图像和社会线索来进行误传播信息检测。研究利用1,529条推文中包含的文本和图像数据进行了分析，这些数据来自新冠肺炎疫情期间和选举期间的Twitter（现为X）。通过对象检测和光学字符识别（OCR）等技术来抽取附加的社会和视觉特征。结果显示，结合无监督和监督机器学习模型可提高分类性能，比单模态模型提高15%，比双模态模型提高5%。此外，研究还分析了误传播信息的传播模式，基于错误信息推文的特征和传播者用户特点进行研究分析。
### Innovation
研究通过早期融合语言、视觉和社会特征来提高多模态虚假信息检测的准确性。并结合文本、图像和社会特征，采用无监督和监督机器学习方法，显著提高了分类性能。
### Conclusion
通过融合不同模态的特征，结合了文本、图像和社会信息，采用无监督和监督机器学习模型，研究提高了误传播信息检测的精度和效果。进一步分析了误传播信息的传播模式，为未来的研究提供了新的方向。
## 221. `cs.CL` - STELLA：生物学研究的自我进化大模型代理 [PDF](https://arxiv.org/pdf/2507.02004), [HTML](https://arxiv.org/abs/2507.02004)
### Authors
Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong
### Background
生物医学领域的数据、工具和文献的快速增长导致了研究领域的碎片化，超出了人类专业知识的处理范围。尽管人工智能代理提供了解决方案，但它们通常依赖于静态的手动策划的工具集，限制了其适应和扩展能力。因此，需要一种能够自我演化、适应和扩展的新方法来解决这些问题。
### Innovation
STELLA是一种自我进化的AI代理，旨在克服这些限制。STELLA采用了多代理架构，通过两种核心机制自主提升自身的性能：一个可演化的模板库，用于推理策略，以及一个动态的工具海洋，随着工具创造代理自动发现并整合新的生物信息学工具，从而使STELLA能够从经验中学习。STELLA在一系列生物医学基准测试中达到了最先进的准确性，展示了其性能随经验的系统提升，特别是在人道主义最后考试的生物医学基准测试中，其精度几乎翻倍。
### Conclusion
STELLA代表了实现可以学习和成长的AI代理系统的重要进展，这些系统能够动态扩展其专业知识，加速生物医学发现的进度。
## 222. `cs.CL` - 为何多兴趣公平性重要：超图对比多兴趣学习用于促进公平对话推荐系统 [PDF](https://arxiv.org/pdf/2507.02000), [HTML](https://arxiv.org/abs/2507.02000)
### Authors
Yongsen Zheng,Zongxuan Xie,Guohua Wang,Ziyao Liu,Liang Lin,Kwok-Yan Lam
### Background
推荐系统（RSs）中的不公平是一个熟知的挑战，可能导致基于性别、种族、年龄或流行度等属性的用户或项目受害。尽管一些方法已经开始在离线或静态上下文中改进推荐公平性，但这问题随着时间的推移通常会加剧，导致马太效应、回声室和信息茧房等严重问题。因此，需要新的解决方案来解决这些挑战，促进对话推荐系统（CRSs）中多兴趣的公平性多样性。
### Innovation
我们提出了一种新的框架——基于超图对比多兴趣学习的公平对话推荐系统（HyFairCRS）。该框架通过对比学习建立多样化的超图来捕捉广泛范围的用户兴趣，然后在对话中利用这些兴趣生成信息性的回应，并确保在动态用户-系统反馈循环中预测公平项目。实验证明，HyFairCRS不仅达到了新的性能状态最佳，同时有效缓解了不公平的问题。
### Conclusion
HyFairCRS框架能够在动态和交互的对话推荐系统中促进多兴趣的多样性公平性，并且在实验中证明了其在缓解推荐系统中的公平性问题方面的有效性。相关代码可在此查阅：not_provided，请使用者按照实际链接填写。
## 223. `cs.CL` - 评估大语言模型在招聘决策中的机遇与挑战 [PDF](https://arxiv.org/pdf/2507.02087), [HTML](https://arxiv.org/abs/2507.02087)
### Authors
Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia
### Background
使用大语言模型（LLMs）在招聘中有望简化候选人的筛选过程，但缺乏足够的安全保障措施时，会导致准确性问题和算法偏见。本研究采用多家公司的先进基础型LLMs进行测试和比较，并将其与我们专有的招聘模型（Match Score）进行了对比，这些LLMs来自OpenAI、Anthropic、Google、Meta和DeepSeek。研究团队通过评估各模型的预测准确性和公平性（包括ROC AUC、Precision-Recall AUC、F1-score以及群体裁剪分析的影响比率），展示了Match Score在准确性和公平性方面的优越性，特别是在种族和交叉群体分析中的表现更为突出。研究还探讨了预训练偏见可能如何导致LLMs传播社会偏见，以及定制的监督模型如何更有效地缓解这些问题。研究结果强调了在高风险领域（如招聘）部署AI时，采用领域特定模型和偏见审计的重要性，并警告在没有充分公平性保障的情况下不要依赖现成的LLMs进行此类任务。此外，研究提供了实证证据，说明精准度和公平性并不一定要二选其一，在招聘中使用精心设计的算法可以同时实现这两方面的目标。
### Innovation
本研究首次系统地将多个标杆级的LLMs与企业自主研发的专有招聘模型（Match Score）进行了对照，从准确性和公平性两个维度进行了全面评估，并通过实际招聘数据展示了Match Score在招聘中的优越表现。本研究进一步揭示了预训练偏见和定制监督模型在消除系统性偏见方面的效果差异，强调了领域特定模型和偏见审计的重要性。
### Conclusion
本研究指出，为了在招聘等高风险领域中有效利用AI技术，需要构建专门针对该领域的模型，并进行详细的偏见审计。同时，本研究表明，精心设计的算法可以在保证精准度的同时实现公平性，从而打破精准度与公平性之间的传统对立。
## 224. `cs.CL` - Energy-Based Transformers是可扩展的学习者和思考者 [PDF](https://arxiv.org/pdf/2507.02092), [HTML](https://arxiv.org/abs/2507.02092)
### Authors
Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal
### Background
推理时的计算技术，类似于人类系统2思考，近年来被用于改进模型性能，但这些方法存在多种局限性，比如其特定于模态性、特定于问题性或需要额外的监督/训练。因此，本文探讨了一种新的方向，即是否可能通过未监督学习使这些系统2思考的方法泛化，发展出无需额外监督即可学习思考的新模型。研究发现，通过明确验证输入与候选预测之间的兼容性，并将预测问题重新框定为对验证器的优化，这一目标是可行的。
### Innovation
提出了一种新的Energy-Based Transformers（EBTs）模型，这是一种新的Energy-Based Models（EBMs）类，通过为输入和候选预测对分配能量值，实现基于梯度下降的能量最小化以提高预测准确性。实验表明，在训练和推断中，EBTs在数据、批量大小、参数、FLOPs和深度方面比主导的Transformer++方法更快，同时在语言任务上比Transformer++提高了29%的性能，在图像去噪任务上也使用更少的前向传递次数且优于扩散变换器。此外，EBTs在大多数下游任务中也表现出更好的性能，即使在预训练性能稍差的情况下，也显示出了更强的泛化能力。
### Conclusion
EBTs作为一种新的框架，既可以扩展模型的学习能力，也能够有效地进行复杂的思考，例如验证推理的准确性。
## 225. `cs.CL` - FinAI-BERT: 基于变压器的金融报告中AI披露的句子级检测模型 [PDF](https://arxiv.org/pdf/2507.01991), [HTML](https://arxiv.org/abs/2507.01991)
### Authors
Muhammad Bilal Zafar
### Background
人工智能（AI）在金融服务中的广泛应用引发了对能够系统性检测公司备案中AI相关披露的工具的需求。尽管先前的方法经常依赖关键词扩展或文档级分类，但它们在粒度、可解释性和鲁棒性方面存在不足。因此，本研究开发了FinAI-BERT，一种针对金融文本中AI相关内容进行句级分类的领域适配变换器基语言模型，以提高检测的准确性与可靠性。
### Innovation
FinAI-BERT 是一种经过专门调整的基于变换器的语言模型，能够对金融文本中的AI相关信息进行句子级别的分类。该模型在精心整理且平衡的1,586个句子数据集上进行了微调，这些句子来源于2015年至2023年间669份美国银行的年报。与传统的逻辑回归、朴素贝叶斯、随机森林和XGBoost等基准方法相比，FinAI-BERT 显著提高了分类性能（准确率99.37%，F1分数0.993）。通过SHAP基词归因确保可解释性，且通过偏见分析和稳健性检查验证了其在句子长度、对抗输入和时间样本上的稳定性。
### Conclusion
理论上，本研究推动了金融NLP领域的进步，通过变换器架构实现了细粒度、主题特定的分类操作。实践上，它为分析师、监管者和学者提供了一种可行、透明的方案，用于监测金融机构内AI扩散和表述的变化。
## 226. `cs.CL` - 分析与提高语音合成中的说话人相似性评估 [PDF](https://arxiv.org/pdf/2507.02176), [HTML](https://arxiv.org/abs/2507.02176)
### Authors
Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi
### Background
建模语音身份极具挑战性，因为语音本身的复杂性。在生成语音系统中，身份通常通过自动说话人验证(ASV)嵌入来评估，这些嵌入主要用于区分而非性格特征刻画。本文调查了这些表示中捕捉到了哪些语音方面的特性。研究发现，广泛使用的ASV嵌入主要集中在如音色、音高范围等静态特征上，忽视了节奏等动态元素。同时，本文还识别了一些影响说话人相似性测量的因素，并提出了缓解策略。
### Innovation
本文提出了U3D，这是一个评估说话人口径规律动态特性的度量标准。
### Conclusion
本文的工作为评估不断改进的语音克隆系统中的说话人身份一致性提出了贡献。我们公开发布我们的代码。
## 227. `cs.CL` - ESTR-CoT: 展望具有链式思考推理的可解释且准确的事件流基于场景文本识别 [PDF](https://arxiv.org/pdf/2507.02200), [HTML](https://arxiv.org/abs/2507.02200)
### Authors
Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang
### Background
事件流基于场景文本识别是近年来的研究热点，与广泛使用的RGB相机相比，在低光照和快速运动等极端挑战场景中表现出色。现有工作要么采用端到端的编码-解码框架，要么使用大型语言模型增强识别，但是他们仍然受限于解释不足和弱上下文逻辑推理等问题。
### Innovation
本文提出了一种新的基于链式思考推理的事件流场景文本识别框架（ESTR-CoT）。具体来说，首先采用Vision Encoder EVA-CLIP（ViT-G/14）将输入的事件流转换为标记，并利用Llama tokenizer对给定的生成提示进行编码。接着使用Q-former将视觉标记与预训练的大语言模型Vicuna-7B对齐，并同时输出答案和链式思考推理过程。此外，还提出了一种大规模的链式思考数据集，用于通过三个阶段处理（生成、润色和专家验证）训练框架。该数据集为后续基于推理的大模型的发展提供了坚实的数据基础。
### Conclusion
在三个事件流识别基准数据集（EventSTR、WordArt*、IC15*）上的广泛实验充分验证了所提出的框架的有效性和可解释性。源代码和预训练模型将被发布。
## 228. `cs.CL` - 分离规划与执行：一种用于深度搜索的层次推理框架 [PDF](https://arxiv.org/pdf/2507.02652), [HTML](https://arxiv.org/abs/2507.02652)
### Authors
Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou
### Background
在现实世界的搜索场景中，复杂的查询需求要求跨越多种资源进行深层次的推理与知识综合，传统的检索增强生成（RAG）管道难以有效应对。当前基于推理的方法存在根本性的限制：它们使用单一模型来处理高层规划与详细执行，导致推理效率低下且难以扩展。
### Innovation
本文提出了 HiRA 框架，这是一种层次框架，将战略规划与专门执行分离。该框架将复杂的搜索任务分解为聚焦的子任务，将每个子任务分配给具备外部工具和推理能力的领域特定代理，并通过一个结构化的整合机制协调结果。这种分离防止了执行细节干扰高级推理，同时使系统能够利用不同信息处理类型的专门知识。实验结果表明，HiRA 在四个复杂的跨模态深度搜索基准测试中显著优于最先进的 RAG 和基于代理的系统，展示了分离规划与执行在多步骤信息查找任务中的有效性。
### Conclusion
HiRA 显著提高了回答质量和系统效率，证明了分离规划与执行在多步骤信息查找任务中的有效性。
## 229. `cs.CL` - 透视绿色：基于文本分类与企业的绿色专利回报 [PDF](https://arxiv.org/pdf/2507.02287), [HTML](https://arxiv.org/abs/2507.02287)
### Authors
Lapo Santarlasci,Armando Rungi,Antonio Zinilli
### Background
本文探讨了自然语言处理技术在识别真正绿色专利方面的应用。文章基于之前文献中分类为绿色的约1240万项专利作为初始训练数据集。这些专利被标记为绿色，但实际上，通过自然语言处理技术，可以从中识别出更精确的绿色专利分类，以此来提高政策制定的精准性。研究发现，真正绿色的专利只占先前文献中分类为绿色专利总数的约20%，并且观察到不同技术类别之间的异质性，以及真正绿色专利在后续发明中被引用次数略低的现象。
### Innovation
通过自然语言处理技术，作者提出了一种新的方法，能够从大量被标记为绿色的专利文献中准确识别出真正具有绿色特征的专利。这是首次利用文本数据来建立更精细的专利分类系统。这项工作揭示了使用文本分析来识别真正的绿色专利对于政策制定的重要性，特别是在不同领域，可以提供更有针对性的指导。同时，研究通过控制反向因果关系，验证了持有至少一个真正的绿色专利能够提高企业的销售收入、市场份额和生产力，进一步证明了绿色知识产权的价值。
### Conclusion
研究结果显示，尽管真正绿色专利占先前文献中分类为绿色专利的比例较低，但真正绿色专利对企业的财务回报和市场表现具有显著的积极影响。对于高新颖性的真正绿色专利，其带来的利润更高，这也突显了严格分类绿色专利在政策制定中的重要性，尤其是在资源配置和市场引导方面。
## 230. `cs.CL` - ASDA: 音频频谱差分注意力机制在自我监督表示学习中的应用 [PDF](https://arxiv.org/pdf/2507.02666), [HTML](https://arxiv.org/abs/2507.02666)
### Authors
Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang
### Background
近期，自监督表示学习在音频领域取得了显著进展，标准Transformer架构已成为主要方法，然而其注意力机制往往会分配一部分注意力权重给无关信息，这可能削弱模型的辨别能力。针对此问题，作者提出了一种差分注意力机制（ASDA），该机制通过结合双softmax操作和适当微调的差分系数，有效缓解了无效注意力分配的问题。实验结果表明，ASDA模型在多个基准测试上均实现了最佳性能，包括音频分类（AS-2M上的mAP为49.0%，AS20K上的mAP为41.5%）、关键词定位（在SPC-2上的准确率为98.3%）和环境声分类（在ESC-50上的准确率为96.1%）.
### Innovation
本文引入了一种差分注意力机制（ASDA），该机制通过双softmax操作和适当微调的差分系数，有效解决了标准Transformer架构中注意力机制分配给无关信息的问题，从而提高了模型的辨别能力，并在多个基准测试中实现了最佳性能.
### Conclusion
实验结果表明，ASDA模型在多个音频任务中均表现出色，其有效的差分注意力机制为音频任务中的自监督表示学习开辟了更广泛的应用前景.
## 231. `cs.CL` - JoyTTS：基于LLM的语音克隆语音聊天机器人 [PDF](https://arxiv.org/pdf/2507.02380), [HTML](https://arxiv.org/abs/2507.02380)
### Authors
Fangru Zhou,Jun Zhao,Guoxin Wang
### Background
该项目结合了大规模语言模型（LLM）和文本到语音（TTS）技术，开发了一个端到端的语音聊天机器人，具备语音克隆能力。该系统基于开源的MiniCPM-o和CosyVoice2模型，并使用2000小时的对话数据进行训练。
### Innovation
该项目的主要创新在于，将大规模语言模型与文本到语音技术相结合，通过语音克隆功能提升了聊天机器人的语音自然度，同时提供的训练代码有助于社区进一步发展和优化。
### Conclusion
通过在种子模型seed-tts-zh上进行测试，JoyTTS在说话人相似度（SS）达到了0.73，词错误率（WER）为5.09。相关的代码、模型以及训练和推断脚本可以在指定的网址找到。
## 232. `cs.CL` - MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs [PDF](https://arxiv.org/pdf/2507.02851), [HTML](https://arxiv.org/abs/2507.02851)
### Authors
Purbesh Mitra,Sennur Ulukus
### Background
最近大型语言模型（LLMs）在推理能力上的进步表明，使用组相对策略优化（GRPO）算法进行强化学习（RL）训练，可以使模型利用更多的思考/推理词元以生成更好的响应。然而，LLM在生成词元时会受到上下文大小的限制，即之前生成的词元受到关注的范围，这一限制成为LLM推理的瓶颈。为了超越上下文大小的限制，模型需要采用模块化思考策略，在多个轮次中进行推理。基于此，本研究提出了一种用于生成多次轮次思考词元的RL训练方法——MOTIF（Modular Thinking via Reinforcement Finetuning），目的是有效扩展模型的思考上下文大小，从而使其能处理任意多的词元。这种方法通过参数高效微调开源模型Qwen2.5-3B-Instruct，来增强其理解和解决问题的能力。在GSM8K数据集上进行微调后，对该模型在MATH500和AIME2024基准测试上的精度进行了测试。实验结果表明，MOTIF方法在基准测试中分别实现了3.8%和3.3%的改进，同时证明了其高效的样本使用能力。
### Innovation
MOTIF提出了一种新的RL训练方法，通过多次轮次生成思考词元，使大型语言模型能够有效扩展其思考上下文大小，并处理任意多的词元。这种方法通过参数高效微调来实现，证明了其在实际应用中的题解能力，相比于传统的基于GRPO的方法，MOTIF方法不仅在精度上有所提升，还在样本使用效率方面表现突出。此外，MOTIF方法还提供了开源模型和训练代码，便于进一步的改进和研究。
### Conclusion
本研究提出了一种新的RL训练方法MOTIF，通过多次轮次生成思考词元，使得大型语言模型能够在不增加上下文大小限制的前提下进行更深入的推理。实验表明，该方法能够有效提升语言模型解决问题的能力，并且具有较高的样本使用效率。未来的研究将继续探索如何更有效地利用这种模块化思考策略，进一步提高大型语言模型的推理能力。
## 233. `cs.CL` - SciGA：用于学术论文中设计图形摘要的综合性数据集 [PDF](https://arxiv.org/pdf/2507.02212), [HTML](https://arxiv.org/abs/2507.02212)
### Authors
Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi
### Background
图形摘要（GAs）在科学论文中发挥着关键作用，它们通过视觉方式传达研究的核心发现。虽然最近的研究越来越多地将视觉材料（如图1）作为一种实际的GAs，但它们如何增强科学交流的潜力尚未得到充分探索。此外，设计有效的GAs需要高级可视化技能，这妨碍了其广泛采用。本文讨论了此问题并介绍了解决方案。SciGA-145k数据集包含约145,000篇科学论文和1,140,000个图表，专门设计用于支持GA的选择和推荐以及促进自动GA生成的研究。通过定义和解决两个任务，SciGA-145k旨在促进GA设计的支持：1) 内部GA推荐，识别给定论文中适合作为GAs的图表；2) 外部GA推荐，从其他论文中检索GA以激发新GA的创作。此外，该研究提出了一个新的评估指标CAR，以解决传统排名指标的局限性。
### Innovation
介绍了SciGA-145k数据集，这是一种大规模的科学论文和图表数据集，用于支持GA的选择和推荐，以及促进科学论文中自动GA生成的研究。定义了两个任务：内部GA推荐和外部GA推荐。提出了一个新的评估指标CAR，以解决传统排名指标的局限性，该指标考虑了除明确标记的GA外，论文中其他图表也可能适合作为GA的情况。
### Conclusion
SciGA-145k数据集通过统一任务和评估指标，为基础科学研究提供了坚实的基础，促进了视觉科学交流的发展，并有助于AI在科学中的应用。
## 234. `cs.CL` - 超越规模：自然语言数据变异性的多样性系数作为数据质量指标 [PDF](https://arxiv.org/pdf/2306.13840), [HTML](https://arxiv.org/abs/2306.13840)
### Authors
Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo
### Background
当前大型语言模型（LLMs）预训练趋势主要集中在模型和数据集规模的扩展上。尽管预训练数据的质量被认为是训练强大语言模型的关键因素之一，但它仍被视为一个模糊的概念，尚未被严格定义。因此，该研究旨在正式化数据质量的一个关键方面——即自然语言数据的变异性的度量，通过提出一个称为多样性系数的测量方法来实现。
### Innovation
本文提出了一种新的度量方法——多样性系数，用于量化自然语言数据的变异性和多样性。通过实证分析，该多样性系数与直觉上的多样性和变异性的特性相符，比如随着潜在概念数量的增加而增加。研究还测量了公开可用的预训练数据集的多样性系数，并证明它们的实际多样性远高于理论上下限。进一步通过GPT-2和LLaMAv2模型进行了系统的干预实验，证明了预训练数据的多样性系数能够表征下游模型评估性能的关键方面。
### Conclusion
研究表明，正式化的多样性概念是数据质量的一个重要方面，它能够捕捉到变异性和因果性地提高评估性能。
## 235. `cs.CL` - StepHint: 多级分步提示增强强化学习以进行推理 [PDF](https://arxiv.org/pdf/2507.02841), [HTML](https://arxiv.org/abs/2507.02841)
### Authors
Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan
### Background
当前的强化学习与可验证奖励（RLVR）方法在增强大型语言模型（LLMs）的复杂推理能力方面前景广阔，但存在两个主要挑战：近似奖励问题和探索停滞。近似奖励问题指的是即使整体推理过程正确，小小的错误也会使整个过程无效，严重影响了训练效率。探索停滞是指模型倾向于在其“舒适区”内寻找解决方案，缺乏探索更具有效性的替代方案的动力。为了解决这些问题，本文提出了StepHint，一种新的RLVR算法，利用多层次的分步提示帮助模型更有效地探索解空间。
### Innovation
StepHint使用多级分步提示生成有效的推理链，并通过作者提出的方法将这些链划分为推理步骤。前几步用作提示，同时为模型提供多级提示（每级包含不同数量的步骤）。这种策略引导模型的探索向有希望的解空间方向，同时保持其独立探索的灵活性。通过提供提示，StepHint减轻了近似奖励问题，提高了训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使其能够超越“舒适区”并缓解探索停滞。通过在六项数学基准测试中表现优异，并在跨领域基准测试中优于基线方法，StepHint在泛化性能上表现出色。
### Conclusion
StepHint在六项数学基准测试中表现出色，并在跨领域基准测试中优于基线方法，显示出其在泛化性能和性能上的优越性。这种新的RLVR算法通过多层次的分步提示，为解决近似奖励问题和探索停滞提供了有效方法。
## 236. `cs.CL` - ExPO: 通过自我解释引导的强化学习解锁复杂推理 [PDF](https://arxiv.org/pdf/2507.02834), [HTML](https://arxiv.org/abs/2507.02834)
### Authors
Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi
### Background
近年来，大型语言模型的进步主要是通过后训练的强化学习(RL)进行优化，这种优化是基于奖励或偏好信号来改进模型的推理能力。现有的GRPO方法通过使用基于结果验证器的自生成样本来实现这一目标，但这些方法高度依赖模型最初生成正确样本的能力，并主要通过细化模型已经了解的内容来进行优化，而不是解决模型初期无法解决的问题。这在早期RL训练和复杂推理任务中尤为成问题，因为正样本可能不容易生成。为了在这些场景下解锁模型的推理能力，模型需要探索其当前输出分布之外的新推理路径。这种探索需要有足够好的正样本来引导学习，但专家演示往往在这个场景下效果不佳，因此提出自解释策略优化(ExPO)来生成符合当前策略且能提高模型预测正确答案概率的样本。
### Innovation
提出了一种新的框架——自解释策略优化(ExPO)，这是一种简单且模块化的框架，通过条件概率来生成自动生成样本，并据此进行探索，使模型产生与当前策略更一致的推理路径。与专家编写的解释相比，ExPO能够提高模型的推理质量，并确保比其自身错误样本更高质量。实验结果表明，ExPO在提高学习效率和最终性能方面优于基于专家演示的方法，特别是在模型最初的困难场景（如MATH级别5）中表现优异。
### Conclusion
ExPO能够在复杂的推理任务中解锁模型的能力，通过生成符合当前策略且能显著提高模型预测正确答案概率的自解释样本，使模型能够进行更有效的探索，并获得更高质量的推理结果，从而显著提高学习效率和最终性能。
## 237. `cs.CL` - 法律要求从法律到翻译 [PDF](https://arxiv.org/pdf/2507.02846), [HTML](https://arxiv.org/abs/2507.02846)
### Authors
Anmol Singhal,Travis Breaux
### Background
软件系统必须遵守法律法规，这对于缺乏专职法律顾问的小企业和初创公司来说是一个资源密集型的任务。从法律法规中提取元数据以提取法律需求是确保合规性的关键步骤，但由于法律文本的长度和复杂性，这是一项繁琐的任务。尽管已有研究将自动化方法应用于从法律文本中提取结构化和语义元数据，但仍然存在关键限制：这些方法没有考虑这些元数据类型的相关属性之间的相互作用，且依赖于人工标注或基于启发式的机器学习，这些方法在新文件上的泛化能力不强。
### Innovation
本文提出了一种基于文本蕴含和上下文学习的方法，自动生成法律文本的标准表示，这种表示可以转换为Python代码执行。该表示基于手动设计的Python类结构，作为特定领域元模型，同时捕捉结构和语义法律元数据及其相互关系，从而减少了对大型人工标注数据集的需求，并增强了对未见法规应用的有效性。
### Conclusion
我们在13个美国州的数据泄露通知法律上的评估表明，我们生成的表示通过了约89.4%的测试案例，并且精确度和召回率分别为82.2%和88.7%。
## 238. `cs.CL` - 大型语言模型中的战略智能：进化博弈论的证据 [PDF](https://arxiv.org/pdf/2507.02618), [HTML](https://arxiv.org/abs/2507.02618)
### Authors
Kenneth Payne,Baptiste Alloui-Cros
### Background
长期以来，迭代囚犯困境（IPD）博弈模型被用来研究决策行为。本文开展了一系列首次的进化IPD比赛，将经典策略（如以牙还牙、严厉触发）与来自顶级人工智能公司的OpenAI、Google和Anthropic的代理进行了对比。通过改变每次比赛的终止概率（即“未来的阴影”），引入了复杂性和不确定性，从而挑战记忆能力。研究结果表明，大型语言模型（LLMs）在这些复杂的生态系统中表现出高度竞争力，并且通常能够生存，甚至在某些情况下会大量扩展。此外，LLMs展示出了独特且持久的“战略印记”，这些特性有助于解释其表现。数据表明，这些模型能够主动地权衡时间框架和对方的策略可能性，并证明这种推理对其决策至关重要。这项研究将经典博弈理论与机器心理学相结合，提供了一种对不确定环境下的算法决策的丰富且精细的视角。
### Innovation
首次将进化博弈论应用于大型语言模型（LLMs），并通过改变比赛规则（终止概率）引入复杂性和不确定性来挑战模型的记忆力，证明LLMs在竞争环境中表现出高度竞争力，并展示了独特且持久的战略印记。此外，分析了近32,000篇模型的完整论述，发现这些模型能够主动地权衡时间框架和对方的策略可能性，并证明这种推理对其决策至关重要。这将传统博弈论与机器心理学结合，提供了算法决策在不确定性环境下的丰富且精细的视角。
### Conclusion
通过首次运用进化博弈论，展示了大型语言模型在复杂生态系统中表现出的战略智能，并分析了模型的推理过程，强调了其在不确定决策中的作用。
## 239. `cs.CL` - DeSTA2.5-Audio：迈向具备自我生成跨模态对齐的一般用途大型音频语言模型 [PDF](https://arxiv.org/pdf/2507.02768), [HTML](https://arxiv.org/abs/2507.02768)
### Authors
Ke-Han Lu,Zhehuai Chen,Szu-Wei Fu,Chao-Han Huck Yang,Sung-Feng Huang,Chih-Kai Yang,Chee-En Yu,Chun-Wei Chen,Wei-Chih Chen,Chien-yu Huang,Yi-Cheng Lin,Yu-Xiang Lin,Chi-An Fu,Chun-Yi Kuan,Wenze Ren,Xuanjun Chen,Wei-Ping Huang,En-Pei Hu,Tzu-Quan Lin,Yuan-Kuei Wu,Kuan-Po Huang,Hsiao-Ying Huang,Huang-Cheng Chou,Kai-Wei Chang,Cheng-Han Chiang,Boris Ginsburg,Yu-Chiang Frank Wang,Hung-yi Lee
### Background
近年来，大型语言模型（LLMs）通常通过训练密集的、人工整理或通过LLMs生成的音频指令数据集来增强其听觉能力。但是，这些方法往往会导致LLMs原本的语言能力出现灾难性遗忘。因此，本文提出了一种新的方法来解决这个问题，即通过自我生成的跨模态对齐策略DeSTA，该策略让主干LLM自动生成自己的训练目标，从而保持LLMs原有的语言能力并有效建立音频-文本对齐，最终实现无任务特定调整的零样本泛化能力。
### Innovation
本文提出了DeSTA策略，即自我生成的跨模态对齐策略。这种方法通过让主干LLM自动生成自己的训练目标，不仅保留了LLMs原有的语言能力，还有效地建立了音频-文本对齐，从而使模型能够在没有任务特定调整的情况下实现零样本泛化。本文还利用DeSTA构建了DeSTA-AQA5M数据集，包含来自50个不同数据集的500万个训练样本，覆盖了语音、环境音效和音乐等多种类型。使用这种方法，DeSTA2.5-Audio模型在多个音频语言基准测试集上表现出色，特别是在动态SUPERB、MMAU、SAKURA、Speech-IFEval和VoiceBench等评测集上，该模型表现出了超越现有方法的性能。
### Conclusion
本文的研究结果强调了精心设计的数据构造在LALM开发中的重要性，并为构建稳健的一般用途音频语言模型提供了实用见解。
## 240. `cs.CL` - 从长视频到引人入胜的片段：具有多模态叙事理解的人类启发式视频编辑框架 [PDF](https://arxiv.org/pdf/2507.02790), [HTML](https://arxiv.org/abs/2507.02790)
### Authors
Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu
### Background
随着在线视频内容（尤其是短视频平台）的快速增长，对高效视频编辑技术的需求也在增加，这些技术能够将长视频浓缩成简洁且引人注目的片段。现有的自动编辑方法主要依赖自动语音识别（ASR）转录中的文本线索进行端到端的片段选择，往往忽略了丰富的视觉上下文，导致输出不连贯。
### Innovation
本文提出了一种人类启发式的自动视频编辑框架（HIVE），该框架利用多模态叙事理解来解决这些局限性。该方法通过多模态大型语言模型进行角色提取、对话分析和叙事总结，从而全面理解视频内容。为了进一步增强连贯性，我们应用场景级别的分割，并将编辑过程分解成三个子任务：亮点检测、开头/结尾选择和无关内容修剪。为促进该领域的研究，我们引入了DramaAD基准数据集，包括超过800个短戏剧集和500个专业编辑广告片段。实验结果表明，我们的框架在一般和广告导向的编辑任务中始终优于现有基线，显著缩小了自动编辑视频与人编辑视频的质量差距。
### Conclusion
实验结果证明，我们的框架在各种编辑任务中表现出色，特别是在广告定向任务中，与现有的自动编辑技术相比，生成的视频质量更加接近人类编辑的效果。
## 241. `cs.CL` - 前沿大语言模型中隐写术能力的初步迹象 [PDF](https://arxiv.org/pdf/2507.02737), [HTML](https://arxiv.org/abs/2507.02737)
### Authors
Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner
### Background
监控大语言模型（LLM）输出是减少滥用和偏移风险的关键。然而，LLMs可以通过隐写术逃避监控：即将隐秘信息嵌入看似无害的生成内容中。本文评估了前沿LLMs的隐写术能力，以更好地理解其风险。研究集中于两种类型的隐写术：传递编码的消息和执行编码推理。研究发现，当前模型在标准环境下难以在输出中隐码短消息而不被监控发现。如果给予额外的条件，如使用未监控的草稿纸和协调采用何种编码方案，模型则可在一定条件下成功隐码信息。此外，研究还发现模型在简单状态追踪问题上具有初步编码推理能力，包括对自身和预定义编码方案的一些推理能力，如十六进制编码。尽管如此，它们难以在任务中模糊地隐推理内容以欺骗监控系统。总体而言，研究结果表明当前LLMs表现出初步的隐写术能力，这些能力目前很可能不足以绕过精心设计的监控系统，但未来可能发生变化。
### Innovation
研究首次评估了前沿LLMs的隐写术能力，特别是它们在标准环境下隐码短消息和进行编码推理的能力。研究揭示了模型能够执行某些编码推理和使用预定义编码方案的行为，这是该领域的创新发现。
### Conclusion
当前研究结果表明，前沿大语言模型展示出初步的隐写术能力。这些能力在短时记忆任务中较为有限，但未来可能增强，从而潜在地绕过监控系统。这强调了持续监测和改进防范机制的必要性。
## 242. `cs.CL` - 基于图像驱动上下文注入的视觉情境攻击：通过图像构建 MLLMs 的囚禁 [PDF](https://arxiv.org/pdf/2507.02844), [HTML](https://arxiv.org/abs/2507.02844)
### Authors
Ziqi Miao,Yi Ding,Lijun Li,Jing Shao
### Background
随着视觉语言能力的增强，多模态大型语言模型（MLLMs）在实际应用中展现出巨大的潜力。然而，视觉模块的安全漏洞给模型在开放环境下部署带来了巨大挑战。现有研究通过直接将有害文本含义编码到视觉输入中诱导目标模型产生有害响应，但这些方法通常依赖视觉信息作为触发虚假行为的手段，缺乏现实性和明确性。本文提出了一个新颖的视觉中心囚禁设定，并提出了一种名为VisCo（Visual Contextual Attack）的攻击方法，通过四种种视觉策略构建上下文对话和动态生成辅助图像，以提高攻击效果。
### Innovation
提出了一种新颖的视觉中心囚禁设定及攻击方法VisCo。VisCo通过视觉信息动态生成辅助图像，构建现实的视觉中心囚禁场景，并采用自动毒性遮蔽和语义精炼，确保最终的攻击提示可以成功触发目标黑盒MLLMs的有害响应。VisCo在MM-SafetyBench测试下对GPT-4o的毒性得分为4.78，攻击成功率为85%，显著优于基准方法的2.48毒性得分和22.2%的攻击成功率。
### Conclusion
VisCo通过利用视觉输入动态生成上下文辅助图像，成功实现了对MLLMs的有效攻击，并且在实验中展示了明显的优越性。
## 243. `cs.CL` - 在旅游领域应用新型多语言数据集进行社交内容多语言分析的最优策略 [PDF](https://arxiv.org/pdf/2311.14727), [HTML](https://arxiv.org/abs/2311.14727)
### Authors
Maxime Masson,Rodrigo Agerri,Christian Sallaberry,Marie-Noelle Bessagnet,Annig Le Parc Lacayrelle,Philippe Roose
### Background
社交媒体平台在各个领域的影响力不断增强，尤其是在旅游业。这催生了对利用这些有价信息进行高效和自动的自然语言处理（NLP）策略的需求。尽管如此，将多语言、结构不完整和非正式的文本转换为结构化的知识仍面临巨大挑战，其中一个主要挑战是为训练深度学习分类器不断需要手工标注的数据。本文研究了不同的NLP技术，旨在以最小的手工标注数据来获得高性能的方法。为此，作者构建了首个公开的旅游领域多语言数据集（法语、英语和西班牙语），包含与旅游相关推文的多层手工修订标注的命名实体识别、细粒度主题概念提取（映射至世界旅游组织的旅游和休闲活动词汇表）以及推文级情感分析。实验结果表明，现代少量样本技术能在几乎无需标注数据的情况下获得兼具竞争力的结果：情感分析5条标签数据，命名实体识别位置数据为30条，细粒度主题概念标注为1000条（基于315个类别的序列标注任务）
### Innovation
作者构建了首个公开发布的多语言旅游推文数据集，并以其为基础研究了不同的NLP技术，旨在以最小的手工标注数据来获得高性能的方法。通过对比多种少量样本技术和现代语言模型，结果表明少量样本技术能够实现符合要求的性能，显著减少了对人工标注的需求，并避免了基于规则的、临时解决方案的复杂性
### Conclusion
本文的研究结果，基于新颖的数据集，为将NLP应用于新领域的特定应用铺平了道路，减少了对手工标注数据的需求，并克服了基于规则的、临时解决方案的复杂性。
## 244. `cs.CL` - 通过不确定性感知教师学习和学生-学生协作学习提高远监督命名实体识别的鲁棒性 [PDF](https://arxiv.org/pdf/2311.08010), [HTML](https://arxiv.org/abs/2311.08010)
### Authors
Shuzheng Si,Helan Hu,Haozhe Zhao,Shuang Zeng,Kaikai An,Zefan Cai,Baobao Chang
### Background
远监督命名实体识别(DS-NER)在实际场景中被广泛使用。它可以有效减轻标注负担，通过匹配现有知识库中的实体与文本片段来进行实体识别，但同时受到标签噪声的影响。最近的工作尝试采用教师-学生框架逐步细化训练标签并提高整体鲁棒性。然而，这些教师-学生方法因为教师网络校准不佳而生成错误的伪标签样本，导致错误的传播，从而仅取得有限的效果。
### Innovation
(1) 提出了不确定性感知教师学习，利用预测不确定性减少自训练阶段中的错误伪标签数量；(2) 提出了学生-学生协作学习，允许两个学生网络之间的可靠标签转移，而不是盲目依赖于教师的所有伪标签，进一步能够全面探索误标样本，而非仅仅过滤不可靠的伪标签样本。
### Conclusion
该研究方法在五个DS-NER数据集上进行了评估，表明该方法优于现有的先进DS-NER方法。
## 245. `cs.CL` - MedAide：基于LLM的医疗智能代理协作的信息融合与医学意图模型 [PDF](https://arxiv.org/pdf/2410.12532), [HTML](https://arxiv.org/abs/2410.12532)
### Authors
Dingkang Yang,Jinjie Wei,Mingcheng Li,Jiyao Liu,Lihao Liu,Ming Hu,Junjun He,Yakun Ju,Wei Zhou,Yang Liu,Lihua Zhang
### Background
在医疗智能中，将来自多种临床来源的异构、多意图信息进行融合是构建可靠决策系统的根本。大型语言模型（LLM）驱动的信息交互系统在医疗领域显示出潜在的前景，但在处理复杂的医疗意图时，它们往往面临信息冗余和耦合的问题，导致严重的幻觉和性能瓶颈。
### Innovation
我们提出了MedAide，一种基于LLM的医疗多智能体协作框架，旨在实现意图感知的信息融合和跨专业医疗领域的协调推理。特别地，我们引入了一个正则化引导模块，结合句法约束和检索增强生成，将复杂的查询分解为结构化表示，促进精细粒度的临床信息融合和意图解决。此外，我们提议了一个动态意图原型匹配模块，使用动态原型表示和语义相似性匹配机制，实现多轮医疗对话中代理意图的适应性识别和更新。最后，我们设计了一个轮换智能体协作机制，引入动态角色轮换和决策级信息融合。
### Conclusion
我们在四个包含复合意图的医疗基准测试上进行了广泛的实验。自动评估指标和专家医生的评价结果显示，MedAide 在医疗专业性和策略性推理方面优于当前的LLM。
## 246. `cs.CL` - SHuBERT: 多流簇预测的自我监督手语表示学习 [PDF](https://arxiv.org/pdf/2411.16765), [HTML](https://arxiv.org/abs/2411.16765)
### Authors
Shester Gueuwou,Xiaodan Du,Greg Shakhnarovich,Karen Livescu,Alexander H. Liu
### Background
手语处理通常依赖于特定任务的模型，这限制了跨任务迁移学习的潜力。现有的手语预训练方法主要集中在监督预训练上，无法利用未标记的数据，或者是在帧或视频片段上进行上下文无关的表示学习，这两种方法都忽略了手语中时间关系的作用。
### Innovation
本文提出SHuBERT（手语隐藏单元BERT）模型，这是一个从大约1000小时的美国手语视频中自监督学习得到的上下文表示模型。SHuBERT将掩码标记预测目标适应到多流视觉手语输入，学习预测多个对应的手、面部和身体姿态流的多个目标。
### Conclusion
SHuBERT在多种任务上实现了现有最好的性能，包括手语翻译、孤立的手语识别和手指拼写检测。
## 247. `cs.CL` - 任务提示向量：通过多任务软提示传输的有效初始化 [PDF](https://arxiv.org/pdf/2408.01119), [HTML](https://arxiv.org/abs/2408.01119)
### Authors
Robert Belanec,Simon Ostermann,Ivan Srba,Maria Bielikova
### Background
提示调优是训练大型语言模型（LLMs）的有效解决方案。当前基于软提示的方法通常牺牲多任务模块性，每次新增任务都需要重新训练或部分重复训练过程。尽管最近关于任务向量的工作通过在全模型权重上应用算术运算来达成多任务性能，但这种方法尚未应用到软提示领域。本文旨在解决这一问题，通过引入任务提示向量，来实现多任务设置中的有效初始化和优化。任务提示向量基于非参数微调软提示和其随机初始化权重之间的逐元素差异计算得出。实验证验证明，任务提示向量可以在低资源环境下用于相似任务的提示调优初始化，并且在两种不同的语言模型架构上与提示调优的随机初始化独立，为多任务提示算术提供了可能。
### Innovation
本文提出了任务提示向量（Task Prompt Vectors），它通过元素差值计算微调后的软提示和随机初始化之间的差异形成。这种向量可以在低资源设置中用于多任务中的提示调优初始化，并且独立于提示调优的随机初始化，允许不同任务的预训练向量之间的算术运算。这种方法提供了与最先进的基线技术具有竞争力的方案，通过多任务任务提示向量的算术加法实现。
### Conclusion
实验结果表明，任务提示向量可以在低资源设置中有效初始化提示调优，并且独立于提示调优的随机初始化，适用于多种语言模型架构。此外，通过将不同任务的预训练向量进行算术加法，本文提出一种有效的替代最先进的基线技术的方法。
## 248. `cs.CL` - 通过过剩词汇探究生物医学出版物中的LLM辅助写作 [PDF](https://arxiv.org/pdf/2406.07016), [HTML](https://arxiv.org/abs/2406.07016)
### Authors
Dmitry Kobak,Rita González-Márquez,Emőke-Ágnes Horvát,Jan Lause
### Background
大型语言模型（LLMs）如ChatGPT能够生成和修订具有人类水平性能的文本。尽管它们存在局限性，如生成不准确的信息、强化现有偏见以及容易被滥用，但许多科学家仍然使用它们进行学术写作。然而，这些LLM在学术文献中的使用有多普遍？为了回答这个问题，特别是在生物医学研究领域，该研究提出了一种无偏且大规模的方法：通过对2010年至2024年PubMed索引的1500多万篇生物医学摘要的词汇变化进行研究，展示了LLM的出现导致了某些风格词汇频率的突然增加。通过过剩词汇分析，研究估测出至少有13.5％的2024年摘要使用了LLM进行处理。这一下限在不同学科、国家和地区之间有所不同，某些子集可以达到40％。研究还表明，LLM在生物医学研究中的写作影响超越了诸如Covid疫情等重大世界事件的影响
### Innovation
该研究提出了一种无偏且大规模的方法，通过分析生物医学摘要中词汇的变化，研究了LLM在学术文献中的使用情况。这种方法能够更准确地估算出使用LLM撰写的文献比例，并且发现在不同学科、国家和地区之间的使用差异显著。此外，研究还指出LLM对科学写作的影响显著大于重大世界事件的影响。
### Conclusion
该研究发现，至少有13.5％的2024年生物医学摘要使用LLM进行了处理，这一比例在不同学科、国家和地区之间存在差异，甚至有40％的子集达到了这个比例。此外，研究显示LLM对生物医学研究中的科学写作产生了前所未有的影响，其效果超过了诸如Covid疫情等重大世界事件的影响。
## 249. `cs.CL` - 批较大：利用较大批处理大小和KV缓存压缩实现更高的LLM吞吐量 [PDF](https://arxiv.org/pdf/2412.05693), [HTML](https://arxiv.org/abs/2412.05693)
### Authors
Michael R. Metel,Boxing Chen,Mehdi Rezagholizadeh
### Background
许多研究开发了驱逐策略从KV缓存中移除关键值对，以便更高效地进行推理。这些策略集中在处理了输入提示之后压缩KV缓存，以加快生成词元的速度。在GPU内存受限的环境中，当输入上下文长于生成长度时，通过在输入处理阶段也压缩KV缓存，可以使用更大的批处理大小，从而显著提高吞吐量，同时保持原始模型的准确率.
### Innovation
提出了一种新的方法Batch-Max，该方法通过在输入处理阶段压缩KV缓存，允许使用更大的批处理大小，从而提高了大语言模型的吞吐量，同时保持了模型的精度.
### Conclusion
通过在输入处理阶段以及生成过程中压缩KV缓存，Batch-Max能够在不牺牲原始模型准确性的情况下，利用更大的批处理规模，从而显著提高LLM的吞吐量.
## 250. `cs.CL` - De-mark：大型语言模型中的水印去除 [PDF](https://arxiv.org/pdf/2410.13808), [HTML](https://arxiv.org/abs/2410.13808)
### Authors
Ruibo Chen,Yihan Wu,Junfeng Guo,Heng Huang
### Background
水印技术为识别由语言模型（LMs）生成的机器生成内容提供了一种有潜力的方法，通过将隐蔽信息嵌入到从语言模型生成的内容中。然而，水印方案的鲁棒性尚未得到充分研究。因此，迫切需要开发有效的框架来去除这些水印，以评估其鲁棒性并识别被嵌入的水印，从而更好地理解和使用这些模型生成的内容。
### Innovation
该论文提出了De-mark，一种新的框架，旨在有效去除基于n-gram的水印。它使用了一种新颖的查询策略，称为随机选择探测，这有助于评估水印强度并识别n-gram水印中的黑白名单。实验表明，De-mark在水印去除和利用任务中表现出高效的性能和有效性，适用于流行的大型语言模型Llama3和ChatGPT等。
### Conclusion
De-mark有效和高效地去除了大型语言模型中的n-gram水印，并通过新颖的查询策略提升了水印的去除和评估效果。实验结果表明De-mark在各类大型语言模型中的适用性和有效性，为后续针对水印鲁棒性的研究提供了有力工具。
## 251. `cs.CL` - 量化数据对齐在下游模型性能中的重要性 [PDF](https://arxiv.org/pdf/2501.08496), [HTML](https://arxiv.org/abs/2501.08496)
### Authors
Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo
### Background
传统的观点强调的是数据集的大小，而本文则探讨了数据对齐——一个经常被忽略的数据质量方面——在训练强大语言模型（LLMs）中的作用。使用基于Task2Vec的对齐系数，一种计算两个数据集相似性的量化指标，本文量化了训练数据和评估数据之间对齐程度对下游性能的影响。研究了特定的领域任务——Autoformalization，即自然语言与代码之间形式验证的机器翻译任务。在两个实验设置中，作者发现模型的训练和评估数据之间的对齐系数与其对下流任务的损失/困惑度之间存在较强的、可以预测的负相关关系，表明在像Autoformalization这样的专业下游任务中，数据对齐比数据量更为重要，强调了重评估LLM训练方法的必要性
### Innovation
采用了基于Task2Vec的对齐系数来量化训练数据与评估数据之间的对齐程度，并通过受控的干预性实验研究了这种对齐对多个下游任务表现的影响。这种研究方法的创新之处在于它用定量的方法研究了数据对齐问题，特别是在特定领域的自动形式化任务方面，突出了数据对齐的重要性，而不是简单地关注数据量的大小
### Conclusion
研究发现了模型训练和评估数据之间的对齐系数与其在特定下游任务上的损失/困惑度之间存在强烈的负相关关系，这表明在专门的下游任务中，需要重新评估LLM的训练方法，特别是在数据对齐方面，其重要性超过了传统的数据大小考量
## 252. `cs.CL` - 改进的大规模语言模型无偏水印 [PDF](https://arxiv.org/pdf/2502.11268), [HTML](https://arxiv.org/abs/2502.11268)
### Authors
Ruibo Chen,Yihan Wu,Junfeng Guo,Heng Huang
### Background
随着人工智能在文本生成方面的表现超越人类，验证AI生成内容的来源变得至关重要。无偏水印通过在语言模型生成的文本中嵌入统计信号，而不降低质量，提供了一种强有力的解决方案。MCmark作为一个无偏水印的多通道家族，通过将模型词汇表分割为段落并在所选段落内基于水印密钥促进token概率来实现这一点。现有的大量研究表明，MCmark不仅保留了语言模型的原生分布，而且在可检测性和稳健性方面带来了显著改进，优于现有的无偏水印技术。本文通过广泛使用的大规模语言模型实验展示了MCmark在可检测性方面的改进超过10%。这一进步突显了MCmark在增强AI生成文本中水印实际应用方面的潜力。
### Innovation
MCmark作为一个无偏水印的多通道家族，创新性地通过将模型词汇表分割为段落并在所选段落内基于水印密钥促进token概率，增强了可检测性和稳健性，显著优于现有的无偏水印技术，尤其是在检测性能上提升了超过10%。这一技术在大规模语言模型的水印应用中具有重要意义。
### Conclusion
MCmark的提出不仅保留了语言模型的原生分布，还在可检测性和稳健性方面带来了显著改进，突显了其在增强AI生成文本中水印实际应用方面的潜力。
## 253. `cs.CL` - 分层洞察：通过利用所有变换器层进行作者风格的可推广分析 [PDF](https://arxiv.org/pdf/2503.00958), [HTML](https://arxiv.org/abs/2503.00958)
### Authors
Milad Alshomary,Nikhil Reddy Varimalla,Vishal Anand,Smaranda Muresan,Kathleen McKeown
### Background
本研究提出了一个为作者归属任务的新方法，该方法利用预训练的变换器模型在不同层中学习的各种语言表示。我们在一个领域和跨领域场景中将我们的方法与最先进的基线进行了比较，发现利用变换器的不同层可以提高作者归属模型的鲁棒性，特别是在跨领域数据中的表现，从而达到了新的最先进的成果。我们的分析进一步揭示了模型的不同层如何在表现特定风格特征方面变得专门化，这对模型在跨领域测试时的表现具有积极影响。
### Innovation
本研究提出了一种利用预训练变换器模型在不同层中学习的各种语言表示的作者归属新方法。我们的方法在领域内和跨领域的场景中都进行了评估，并表明利用不同层可以提高模型的适应性和鲁棒性，从而实现了跨领域的最优效果。这种工作提供了一个新的视角，即不同层对某些风格特征的精细表示如何能够改进模型在新领域中的性能。
### Conclusion
我们的研究表明，利用变换器的不同层可以提高作者归属模型的鲁棒性和性能。不同层的独特特性使得模型在跨领域的环境中更加适应和准确，从而实现新的最优结果。我们的分析为研究作者风格的多层特性提供了更深入的理解，这对于构建更加鲁棒和适应性强的作者归属模型具有重要意义。
## 254. `cs.CL` - SMARTe: 基于槽位的方法用于可解释的关系三元组提取 [PDF](https://arxiv.org/pdf/2504.12816), [HTML](https://arxiv.org/abs/2504.12816)
### Authors
Xue Wen Tan,Stanley Kok
### Background
关系三元组提取（RTE）是自然语言处理（NLP）中的一个基本任务。然而，先前的研究主要集中在优化模型性能，较少探讨内部机制如何驱动这些模型。许多现有的方法依赖于复杂的预处理来诱导特定的交互，往往导致不透明的系统，这些系统可能不能完全符合其理论基础。
### Innovation
我们提出了SMARTe：一种基于槽位的关系三元组提取方法。SMARTe通过槽位注意机制引入内在可解释性，并将任务建模为集合预测问题。槽位注意机制将相关信息合并为不同的槽位，确保所有预测都可以明确追溯到学习到的槽位表示和每个预测关系三元组所涉及的标记。虽然强调了可解释性，但SMARTe的性能可与最先进的模型相媲美。
### Conclusion
SMARTe在NYT和WebNLG数据集上的评估表明，增加可解释性不会牺牲性能。此外，我们还进行了定性的评估，展示了SMARTe提供的解释，通过注意力热图映射到相应的标记。最后，我们讨论了我们的研究发现，并提出了未来的研究方向。SMARTe的代码可在此处获取。
## 255. `cs.CL` - Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models [PDF](https://arxiv.org/pdf/2503.18681), [HTML](https://arxiv.org/abs/2503.18681)
### Authors
Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin
### Background
讽刺检测作为自然语言处理(NLP)领域的关键研究方向，引起了广泛关注。传统的讽刺检测任务通常专注于单模态方法（例如文本），但由于讽刺的隐含性和微妙性，这些方法往往无法取得令人满意的结果。近年来，研究者转向了多模态方法，但如何有效地利用多模态信息以准确识别讽刺内容仍然是一个需要进一步探索的挑战。
### Innovation
本文提出了一个名为Commander-GPT的创新的多模态框架。该框架借鉴了军事战略思想，首先将讽刺检测任务分解为六个不同的子任务，然后中心指挥部（决策者）将最适合的大型语言模型分配给每个特定子任务。最后，对每个模型的检测结果进行聚合以识别讽刺。实验使用了四种多模态大型语言模型和六种提示策略，在MMSD和MMSD 2.0上进行。实验结果表明，该方法在F1分数上取得了最先进的性能，提高了19.3%，并且无需微调或真实理由数据。
### Conclusion
实验结果证明，本文提出的方法在F1评分上达到了最先进的性能，比之前的方法提高了19.3%，并且整个过程中无需进行模型微调或使用真相理由。
## 256. `cs.CL` - Token Prepending: 一种无需训练即可从LLM中提取更好句嵌入的方法 [PDF](https://arxiv.org/pdf/2412.11556), [HTML](https://arxiv.org/abs/2412.11556)
### Authors
Yuchen Fu,Zifeng Cheng,Zhiwei Jiang,Zhonghui Wang,Yafeng Yin,Zhengliang Li,Qing Gu
### Background
利用大型语言模型（LLMs）提取句子嵌入是一个有前景的方向，因为LLMs在语义理解能力方面展现出优势。早期的研究通常集中在通过提示工程来促使LLMs将句子信息编码到最后一令牌的嵌入中。然而，LLMs大多为解码器模型，并带有因果关注机制，导致句子早期令牌无法关注后续令牌的信息，从而产生偏差的句子信息编码，并对最终解码令牌产生级联影响。
### Innovation
提出了一种名为Token Prepending（TP）的新技术，能够在每个层的输入中将该层解码的句子嵌入预先插入到下一层输入的开始位置，从而使早期令牌能够在因果关注机制下关注完整的句子信息。TP技术是一种即插即用、无需训练的技术，可以无缝集成到各种基于提示的句子嵌入方法和自回归LLMs中。实验结果表明，TP技术可以显著提高现有基于提示的句子嵌入方法在不同LLMs上的性能，同时几乎不增加额外的推理成本。
### Conclusion
广泛的实验在各种语义文本相似性（STS）任务和下游分类任务上显示，所提出的TP技术可以显著改善不同LLMs上现有的基于提示的句子嵌入方法的性能，而几乎不增加额外的推理成本。
## 257. `cs.CL` - 下一个令牌预测任务假设在证明生成中LLM训练的理想数据排序 [PDF](https://arxiv.org/pdf/2411.00863), [HTML](https://arxiv.org/abs/2411.00863)
### Authors
Chenyang An,Shima Imani,Feng Yao,Chengyu Dong,Ali Abbasi,Harsh Shrivastava,Samuel Buss,Jingbo Shang,Gayathri Mahalingam,Pramod Sharma,Maurice Diesendruck
### Background
基于大型语言模型（LLM）的证明生成在经过大量ArXiv等数据集的训练后，仍表现出在中等难度的证明任务上仅有适度表现的现象。这主要是因为训练数据中的证明步骤顺序存在次优性，这导致即使逻辑上详细排列的步骤也难以有效帮助人类和模型学习证明的发现过程。因此，研究提出在证明生成中，每个证明步骤右侧总是遵循“直观顺序”，即相关中间指导总是位于特定证明步骤左侧，这样可以有效提高模型的训练效果。研究通过两类任务进行验证，并展示了不同证明顺序对模型训练效果的影响。
### Innovation
研究提出了一种“直观顺序”（Intuitively Sequential Order），即在每个证明步骤右侧总是遵循相关中间指导，这种排列方式能够显著提高模型在证明生成任务中的表现。通过两个具体任务（直觉命题逻辑定理证明和数字乘法）的实验验证了该创新方法的有效性，结论表明采用理想数据排序进行训练可以显著提升证明成功的比率，最高可达11%。此外，还发现了一种常见但此前未受重视的数学证明中的排序问题，并指出在某广泛使用的研究生级数学教科书的前两章中，17.3%的非平凡定理都存在这种问题。
### Conclusion
本文通过实验验证了证明生成中理想数据排序对于大型语言模型（LLM）训练效果的提升，并且提出了存在的普遍排序问题。研究指出，采用“直观顺序”进行训练能够大幅提升证明生成任务的成功率，并揭示了大量实际存在的实际上影响模型训练效果的数据排序问题。
## 258. `cs.CL` - 通过信息几何和量子度量重新思考大型语言模型的训练 [PDF](https://arxiv.org/pdf/2506.15830), [HTML](https://arxiv.org/abs/2506.15830)
### Authors
Riccardo Di Sipio
### Background
大规模语言模型（LLMs）在高维参数空间中的优化存在复杂的非欧几里得结构。信息几何利用费舍尔信息度量框架化这一景观，通过天然梯度下降法进行更原理的学习。尽管这种几何视角在实践中不太可行，但它解释了许多现象，如尖锐极小值、泛化及观察到的标度法则。
### Innovation
研究提出，基于曲率感知的方法可以加深我们对LLM训练的理解。此外，基于Fubini-Study度量和量子费舍尔信息的量子类比推测，暗示量子增强系统中高效优化的可能性
### Conclusion
本文重新思考了通过信息几何和量子度量重新理解大规模语言模型的训练，强调了自然梯度下降和基于量子度量的优化方法的重要性。
## 259. `cs.CL` - 跨越语言边界：评估多模态大语言模型的跨语言一致性 [PDF](https://arxiv.org/pdf/2505.15075), [HTML](https://arxiv.org/abs/2505.15075)
### Authors
Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara
### Background
多模态大语言模型（MLLMs）的迅速发展极大地提升了它们在实际应用中的表现。然而，在不同语言中保持一致的表现，尤其是在整合文化知识时，依然是一个重大挑战。为此，本研究提出了两个新的基准测试：KnowRecall和VisRecall，用于评估MLLMs的跨语言一致性。KnowRecall是一个视觉问答基准，旨在测量15种语言中的事实知识一致性，重点是关于全球地标的文化和历史问题。VisRecall则通过询问模型在没有图片的情况下描述地标外观来评估视觉记忆的一致性，涉及9种语言。实验结果表明，包括专有模型在内的最先进的MLLMs在跨语言一致性方面依然面临挑战。这突显了需要采用更加稳健的方法，以产生真正多语言且具备文化意识的模型的必要性。
### Innovation
提出了两个新的基准测试：KnowRecall和VisRecall，用于评估多模态大语言模型在不同语言中的知识一致性以及视觉记忆的一致性，特别强调了跨文化背景的知识和视觉信息的一致性问题。
### Conclusion
最先进的多模态大语言模型在跨语言一致性方面仍然存在问题，强调了开发真正多语言且具备文化意识的模型的必要性。
## 260. `cs.CL` - REINFORCE++: 一种鲁棒性强的高效RLHF算法 [PDF](https://arxiv.org/pdf/2501.03262), [HTML](https://arxiv.org/abs/2501.03262)
### Authors
Jian Hu,Xibin Wu,Wei Shen,Jason Klein Liu,Zilin Zhu,Weixun Wang,Songlin Jiang,Haoran Wang,Hao Chen,Bin Chen,Weikai Fang,Xianyu,Yu Cao,Haotian Xu
### Background
现有的大型语言模型（LLMs）通过强化学习从人类反馈（RLHF）和可验证奖励的强化学习（RLVR）进行微调，显著提高了人类与AI价值观的契合度，提升了AI的能力，特别是在推理密集型、长上下文链式思维任务（long-CoT）中。然而，现有的RLHF（或RLVR）框架往往面临诸如推理瓶颈和复杂性障碍等挑战，限制了其对新加入者的可访问性。论文旨在解决这些挑战，通过介绍一种用户友好、可扩展且易于学习的开源RLHF框架OpenRLHF来降低使用者的学习门槛，以促进研究和应用的广泛参与。OpenRLHF基于Ray、vLLM、DeepSpeed和HuggingFace Transformers构建，简化了设计，明确了代码结构，并提供了详尽的文档说明。
### Innovation
提出了一个名为OpenRLHF的开源框架，旨在简化并降低使用RLHF进行模型微调的学习门槛。它基于Ray、vLLM、DeepSpeed和HuggingFace Transformers建模，并提供了简化的设计、清晰的代码结构和详尽的文档说明。OpenRLHF在不同模型规模上的训练效率相比现有的领先框架提高了1.22倍到1.68倍，同时使用的代码行数也显著减少。该框架在促进RLHF研究和学习方面已经得到领先机构的认可和支持，并已公开可用。
### Conclusion
OpenRLHF框架通过简化设计、明确的代码结构和详尽的文档说明，显著提高了RLHF的可访问性和易用性，实现了对现有领先框架的性能提升，使得更多研究人员能够快速有效地参与到RLHF的相关研究中来。
## 261. `cs.CL` - Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding [PDF](https://arxiv.org/pdf/2505.22618), [HTML](https://arxiv.org/abs/2505.22618)
### Authors
Chengyue Wu,Hao Zhang,Shuchen Xue,Zhijian Liu,Shizhe Diao,Ligeng Zhu,Ping Luo,Song Han,Enze Xie
### Background
扩散基大规模语言模型（Diffusion LLMs）在非自回归文本生成和并行解码能力方面显示出潜力。然而，开源模型的实际推理速度往往仍然落后于自回归模型，主要是因为缺乏Key-Value (KV) 缓存机制，并且在同时解码多个令牌时会出现质量下降。另一问题是，在平行解码中，生成质量的下降是由于条件独立假设下令牌依赖关系的破坏。
### Innovation
引入了一种针对双向扩散模型的新型块状近似KV缓存机制，能够实现近乎无性能下降的缓存重用。此外，提出了基于信心感知的并行解码策略，该策略根据信心阈值选择性地解码令牌，从而减轻依赖关系违规并保持生成质量。
### Conclusion
实验结果表明，与自回归模型相比，该方法在多个LLM基准上实现了最高27.6倍的吞吐量提升，且几乎无准确率损失，为Diffusion LLM的实际部署铺平了道路。
## 262. `cs.CL` - Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning [PDF](https://arxiv.org/pdf/2505.13886), [HTML](https://arxiv.org/abs/2505.13886)
### Authors
Jingqi Tong,Jixin Tang,Hangcheng Li,Yurong Mou,Ming Zhang,Jun Zhao,Yanbo Wen,Fan Song,Jiahao Zhan,Yuyang Lu,Chaoran Tao,Zhiyuan Guo,Jizhou Yu,Tianhao Cheng,Changhao Jiang,Zhen Wang,Tao Liang,Zhihui Fei,Mingyang Wan,Guojun Ma,Weifeng Ge,Guanhua Chen,Tao Gui,Xipeng Qiu,Qi Zhang,Xuanjing Huang
### Background
视觉语言模型（VLMs）的视觉语言推理数据资源相对匮乏，限制了其推理能力的提升。高质量的视觉语言推理数据标注成本高且耗时。因此，研究人员寻求利用游戏代码进行多模态推理数据的合成，因为游戏代码自然包含逻辑结构和状态转换过程，可以弥补现有数据资源的不足。
### Innovation
提出了一种名为Code2Logic的新颖方法，利用大型语言模型（LLMs）将游戏代码适应为所需的格式，通过代码执行自动获取推理过程及其结果。该方法用于开发了GameQA数据集，用于训练和评估VLMs。利用GameQA数据集训练的VLMs在7个不同的视觉语言基准上的表现超出预期地展示了领域外泛化能力。
### Conclusion
Code2Logic方法有效利用了游戏代码生成高质量的多模态推理数据，降低了数据收集成本，提高了VLMs的推理能力。实验表明，即使仅依赖游戏数据，VLMs仍能实现超出文本驱动方法的领域外泛化，例如Qwen2.5-VL-7B在多个视觉语言基准上的性能提升了2.33%。
## 263. `cs.CL` - AIn't Nothing But a Survey? 使用大型语言模型为编码德国开放型调查回答动机进行调查 [PDF](https://arxiv.org/pdf/2506.14634), [HTML](https://arxiv.org/abs/2506.14634)
### Authors
Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessica Daikeler
### Background
近年来，大型语言模型（LLMs）的开发与普及引发了它们在调查研究中应用的讨论，包括对开放性调查回答的分类。由于LLMs的语言能力，它们可能成为手工编码和预训练监督机器学习模型的高效替代品。然而，现有研究主要关注英语回答或非复杂主题的回答，或单一LLMs，这使得其结果的普适性和分类质量难以确定。本研究旨在探索不同LLMs是否可以用于其他调查环境中开放性回答的编码，以德国关于调查参与动机的数据为例。研究还比较了多种先进的LLMs和不同的提示方法，并通过使用人类专家编码评估LLMs的性能。研究发现，LLMs在整体性能上差异显著，只有微调后的LLM能达到可接受的预测性能。提示方法的性能差异也取决于所使用的LLM。未使用微调时，LLMs在不同分类原因上的不平等分类性能导致不同类别间的分布差异。研究讨论了这些发现对调查编码研究和实质性分析的影响，以及处理或实质性分析此类数据的实践者的考量，并指出研究人员在选择用于开放性回答分类的自动化方法时需要考虑的诸多权衡。
### Innovation
本研究创新性地探索了不同LLM在非英语环境下的开放性调查回答分类能力，并通过使用微调先进的LLM及多种提示方法提高了分类的准确性和可靠性。研究结果表明，除了语言模型本身的性能差异外，提示方法的选择也对分类质量有很大影响，强调了研究者在使用LLM进行开放性回答分类时需要全面考量的问题。
### Conclusion
本研究揭示了不同LLM在调查研究中用于开放性回答分类的优缺点，并强调了各种权衡因素。研究为如何高效、准确和可靠地利用LLM进行调查研究提供了重要见解，有助于推动相关研究领域的进一步发展。
## 264. `cs.CL` - 使用知识图谱引导的诱答生成增强临床多项选择题基准 [PDF](https://arxiv.org/pdf/2506.00612), [HTML](https://arxiv.org/abs/2506.00612)
### Authors
Running Yang,Wenlong Deng,Minghui Chen,Yuyin Zhou,Xiaoxiao Li
### Background
临床任务如诊断和治疗需要强大的决策能力，突出严格的评估基准的重要性，以评估大型语言模型（LLMs）的可靠性。本研究旨在通过生成误导性选项来增强用于临床的多项选择题（MCQ）数据集的难度，这些选项既具有临床合理性，又能误导现有的LLMs。
### Innovation
引入了一种知识引导的数据增强框架，通过在医学知识图上进行多步骤的语义导向遍历来生成误导性选项。这种方法可以生成既相关又错误的选项，从而引导LLMs生成更具欺骗性的选项。该研究将这种方法应用于六个广泛使用的医学问答基准，显示其能够持续减少最先进的LLMs的准确性，证明了这种方法的有效性和影响力。
### Conclusion
研究结果表明，知识图谱引导的误导选项生成（KGGDG）框架是一个强大的工具，能够为医学LLMs提供更稳健和诊断性的评估。
## 265. `cs.CL` - Prompt-Guided Turn-Taking Prediction [PDF](https://arxiv.org/pdf/2506.21191), [HTML](https://arxiv.org/abs/2506.21191)
### Authors
Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara
### Background
转场预测模型对于语音对话系统和对话机器人至关重要。最近的方法利用基于转换器的架构来实现实时连续预测话筒活动。尽管如此，现有方法通常缺乏对外显和动态控制的直接方式。
### Innovation
本文提出了一种新的模型，通过文本提示动态控制转场预测。该模型基于基于转换器的声音活动投影（VAP）模型，将文本提示嵌入到通道层面的转换器和跨通道转换器中，以此实现直观和明确的控制，根据对话伙伴和上下文改变转场预测的节奏。此外，由于无法获取现有的数据集，本文通过大型语言模型生成了合成提示句子，以评估这种新方法的可行性并提升预测准确性。
### Conclusion
实验结果表明，所提模型提高了预测精度，并能根据文本提示有效地改变转场预测的行为模式。
## 266. `cs.CL` - 符号还是数值？理解推理LLM解决物理问题的方法 [PDF](https://arxiv.org/pdf/2507.01334), [HTML](https://arxiv.org/abs/2507.01334)
### Authors
Nifu Dan,Yujun Cai,Yiwei Wang
### Background
长期以来，大型语言模型（LLMs）在解决物理学推理问题方面遇到了很大挑战，这需要深厚的概念理解与卓越的问题解决技巧。为了应对这一挑战，研究人员研究了将先进指令调优推理模型（比如Deepseek-R1）应用于来自SciBench基准的多样化物理学问题中。实验表明这些推理模型具有出色的解答复杂物理问题的能力，并且生成了侧重于符号运算的独特推理模式。此外，研究还发现，即使是如此复杂的推理模型，通过微量提示策略依然可以在整体准确性上取得显著改进，这为持续的能力提升留下了开放空间。
### Innovation
研究引入了先进的指令调优推理模型Deepseek-R1，将其应用于解决SciBench基准中多样化设计的物理学问题。研究揭示了这些模型不仅在回答复杂物理问题方面能达到最先进的准确性，还能生成侧重于符号运算的独特推理模式。同时，研究发现即使是复杂的模型，通过运用微量提示策略，也能在准确性上得到显著提升。
### Conclusion
研究展示了推理模型在解决复杂物理学问题上的潜力，并验证了通过微量提示策略可以在这些模型的准确性上取得改进。这为未来的性能提升开启了新的方向。
## 267. `cs.CL` - 基于多跳自然语言推理的可解释合规检测 [PDF](https://arxiv.org/pdf/2506.08713), [HTML](https://arxiv.org/abs/2506.08713)
### Authors
Fariz Ikhwantri,Dusica Marijan
### Background
确保复杂系统符合法规通常需要通过主张-论据-证据框架检查保证案例的有效性。这一过程中面临的挑战包括法律和技术文本的复杂性、对模型解释的需求以及有限的保证案例数据访问。
### Innovation
提出了一种基于自然语言推理（NLI）的合规检测方法——EXCLAIM（EXplainable CompLiance detection with Argumentative Inference of Multi-hop reasoning），将保证案例的主张-论据-证据结构形式化为多跳推理，以实现可解释和可追溯的合规检测。利用大型语言模型（LLMs）生成保证案例，引入度量标准衡量覆盖范围和结构一致性，并通过GDPR要求的多跳推理任务进行案例研究，展示了NLI基方法在自动化合规过程中的潜力。
### Conclusion
结果表明NLI基于的方法在自动化法规合规过程中的潜力。
## 268. `cs.CL` - 通过BeamAttack评估误导信息分类系统的鲁棒性 [PDF](https://arxiv.org/pdf/2506.23661), [HTML](https://arxiv.org/abs/2506.23661)
### Authors
Arnisa Fazla,Lucas Krauter,David Guzman Piedrahita,Andrianos Michail
### Background
研究现有文本分类系统的鲁棒性，特别是针对由词汇级修改引起的对抗攻击。传统的对抗攻击算法主要关注插入或替换等修改，但未考虑删除和跳过替换。BeamAttack算法使用启发式搜索（如Beam搜索）来优化对模型预测的影响，旨在评估文本分类系统的鲁棒性。
### Innovation
本文对该算法进行了扩展，增加了支持词汇删除和跳过替换的功能，提高了攻击的灵活性和实用性。此外，通过集成LIME技术，使词汇替换更加具有针对性。实验显示，该方法在多个数据集和不同的模型（BiLSTM、BERT和对抗训练的RoBERTa）上均能实现超过99%的成功率，同时保持了原始文本的语义和词法相似性。
### Conclusion
通过定量和定性分析，进一步证明了BeamAttack算法的有效性和局限性。研究结果表明，BeamAttack在对抗攻击评估方面具有显著优势，但需要进一步解决一些特定的局限问题。
## 269. `cs.CL` - 决策导向的文本评估 [PDF](https://arxiv.org/pdf/2507.01923), [HTML](https://arxiv.org/abs/2507.01923)
### Authors
Yu-Shiang Huang,Chuan-Ju Wang,Chung-Chi Chen
### Background
自然语言生成（NLG）在高风险领域中的应用日益增多，但常见的固有评估方法，如n-gram重叠或句子可信度，与实际决策效果的相关性较低。本研究提出了一个决策导向框架，通过直接测量生成文本对人类和大语言模型（LLM）决策结果的影响来评估文本。这项研究使用市场摘要文本（包括客观的凌晨摘要和主观的收盘分析）作为案例研究，基于由人类投资者和仅依靠这些文本信息的自主LLM执行的交易绩效评估决策质量。研究表明，无论是人类还是LLM仅依赖摘要时都不一定能超越随机表现。然而，更丰富的分析评论能够让人类-LLM团队的表现显著优于单独的人类或代理基准。这一方法强调了评估生成文本应关注其促进人类和LLM之间协同决策的能力的重要性，指出传统固有度量的关键局限性。
### Innovation
提出了一个决策导向框架，通过直接测量生成文本对人类和大语言模型决策结果的影响来评估文本，使用市场摘要文本作为案例研究，评估决策质量并对比人类和LLM的表现差距，强调了评估生成文本应关注其促进协同决策的能力。
### Conclusion
研究发现，无论是人类还是LLM仅依赖摘要时都不一定能超越随机表现。然而，更丰富的分析评论能够让人类-LLM团队的表现显著优于单独的人类或代理基准。这一方法强调了评估生成文本应关注其促进协同决策的能力，指出传统固有度量的关键局限性。
## 270. `cs.CL` - Skywork-Reward-V2：通过人机协同扩展偏好数据整理 [PDF](https://arxiv.org/pdf/2507.01352), [HTML](https://arxiv.org/abs/2507.01352)
### Authors
Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou
### Background
尽管奖励模型（RMs）在从人类反馈强化学习（RLHF）中发挥着关键作用，现有的开放奖励模型在大多数现有评估基准上表现不佳，无法捕捉到人类偏好中的细微和复杂的方面。即使采用了高级训练技术的方法也没有显著提升性能。我们认为这种脆弱性主要是由于偏好数据集的局限性，这些数据集往往范围狭窄、通过合成标签获得或缺乏严格的质量控制。为应对这些挑战，我们提出了一种包含4000万个偏好成对的大型偏好数据集，名为SynPref-40M，并设计了一个由人类和AI共同参与的两阶段流水线，该流水线充分利用了人类标注质量和AI可扩展性的互补优势。
### Innovation
通过设计的人机协同两阶段流水线，我们创建了一个大型偏好数据集SynPref-40M，并开发了一套从0.6B到8B参数的8个奖励模型Skywork-Reward-V2，这些奖励模型经过对2600万个精心整理的偏好数据子集的训练。我们展示了Skywork-Reward-V2在多种能力上的灵活性，包括与人类偏好对齐、客观正确性、安全性、抵抗风格偏差和N最好的扩展性，并在七个人类奖励模型基准测试中取得了最先进的性能。消融研究证实，我们方法的有效性不仅来自数据规模，还来自于高质量的数据整理。Skywork-Reward-V2系列代表了开放奖励模型的重大进步，展示了现有偏好数据集的巨大潜力及其如何通过人机协同整理来提升数据质量的潜力。
### Conclusion
Skywork-Reward-V2系列标志着开放奖励模型的重大进展，显示出现有偏好数据集的巨大潜力，并证明了通过人机协同整理可以实现显著更高的数据质量。
## 271. `cs.CL` - 电路调整：识别参数冗余和微调神经网络的一种机制性方法 [PDF](https://arxiv.org/pdf/2502.06106), [HTML](https://arxiv.org/abs/2502.06106)
### Authors
Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang
### Background
机制可解释性的研究旨在分解模型的行为。尽管近期研究已关注于特定行为的静态机制，但模型内部的学习动态尚未得到充分探索。本文发展了一种解释学习机制的可解释微调方法。通过引入计算图内节点层面固有维度的概念来描述模型的学习过程，并提出了一种名为电路调整的两阶段算法，以迭代构建特定任务的最小子图并在启发式方式下更新关键参数。实验结果证实了节点层面固有维度的存在，展示了该方法在透明和可解释微调中的有效性。通过在微调前后可视化和分析电路，提供了神经网络学习过程中自组织机制的新见解。
### Innovation
本文提出了一种新的可解释微调方法——电路调整，该方法通过引入节点层面固有维度的概念来描述模型的学习过程，并提出了一种两阶段算法来迭代构建特定任务的最小子图并在启发式方式下更新关键参数。这种方法在透明和可解释微调中表现出了有效性，提供了神经网络学习过程中自组织机制的新见解。
### Conclusion
实验结果证实了节点层面固有维度的存在，并展示了电路调整方法在透明和可解释微调中的有效性。通过可视化和分析电路，为理解神经网络在学习过程中的自组织机制提供了新的视角。
## 272. `cs.CL` - 结合LLMs的大规模城市复杂交通模拟 [PDF](https://arxiv.org/pdf/2505.21880), [HTML](https://arxiv.org/abs/2505.21880)
### Authors
Yu-Lun Song,Chung-En Tsern,Che-Cheng Wu,Yu-Ming Chang,Syuan-Bo Huang,Wei-Chu Chen,Michael Chia-Liang Lin,Yu-Ta Lin
### Background
传统的基于规则的基于代理模型（ABM）在模拟城市交通流动时存在局限性，无法充分反映人群多样性和行为的复杂性。为此，研究人员尝试引入大型语言模型（LLM）来提升代理模型的性能，通过生成合成人口特征、分配常规和偶尔的出行地点以及模拟个性化路线来增强代理的多样性和真实感。
### Innovation
该研究提出了一种将大型语言模型与基于代理的模型相结合的新颖方法，以改善城市移动性的模拟。这种方法独特地利用了LLM生成合成人群档案、分配常规出行和偶尔出行地点以及模拟个性化路线，从而增强了代理的多样性和真实性。利用真实世界的数据，在台北市进行模拟模型，能够个体行为及大规模的交通模式提供洞见，这些洞察为城市规划者提供了决策依据。
### Conclusion
未来的工作将集中在建立稳固的验证框架，以确保城市规划应用中的准确性和可靠性。这项工作对于提升城市规划决策的科学性和有效性具有重要意义。
## 273. `cs.CL` - 绕过反向传播：基于策略梯度的大型语言模型结构剪枝方法 [PDF](https://arxiv.org/pdf/2406.10576), [HTML](https://arxiv.org/abs/2406.10576)
### Authors
Yuan Gao,Zujing Liu,Weizhong Zhang,Bo Du,Gui-Song Xia
### Background
最近的大型语言模型（LLMs）剪枝方法通常在模型训练完成后进行，不需要昂贵的权重微调，但往往依赖手工构建的启发式度量标准来确定剪枝准则，可能会影响模型的最终性能。本文则提出了一种新型的基于优化的结构剪枝方法，直接在可概率化的空间中学习剪枝掩码，从而优化剪枝后模型的损失。这种方法在优化过程中不需要通过LLM进行反向传播，只需LLM的前向传播即可实现高效剪枝。
### Innovation
提出了一种基于优化的结构剪枝方法，通过学习一个基础的伯努利分布来采样二进制剪枝掩码，并且将伯努利参数与LLM损失解耦，利用策略梯度估计器进行高效优化，而不需要反向传播。这种方法可以支持全局和异构剪枝，并且可以与度量驱动的方法进行初始化。
### Conclusion
在LLaMA，LLaMA-2，LLaMA-3，Vicuna和Mistral模型上，使用C4和WikiText2数据集进行的大量实验显示了该方法在效率和效果上的潜力。相关代码已经发布。
## 274. `cs.CL` - 使用稀疏特征级约束的直接偏好优化 [PDF](https://arxiv.org/pdf/2411.07618), [HTML](https://arxiv.org/abs/2411.07618)
### Authors
Qingyu Yin,Chak Tou Leong,Hongbo Zhang,Minjun Zhu,Hanqi Yan,Qiang Zhang,Yulan He,Wenjie Li,Jun Wang,Yue Zhang,Linyi Yang
### Background
大规模语言模型（LLMs）与人类偏好对齐仍然是一个关键技术挑战。尽管诸如 Reinforcement Learning from Human Feedback (RLHF) 和 Direct Preference Optimization (DPO) 等后训练技术已经取得了显著成果，但它们往往伴随着计算效率低下和训练不稳定的缺点。
### Innovation
本文提出了一种新颖的方法——Feature-level constrained Preference Optimization (FPO)，旨在简化对齐过程并确保稳定性。FPO 利用预训练的稀疏自编码器（SAEs）并引入特征级约束，通过稀疏特征增强了对齐效率，并通过特征级离线参考使用序列 KL 散度来提高质量。实验结果表明，FPO 相较于最先进的基准方法，在绝对胜率上取得了 5.08% 的提升，且具有更低的计算成本，是一种高效的可控 LLM 对齐解决方案。
### Conclusion
FPO 通过使用稀疏特征激活以及序列 KL 散度的质量，实现了 LLM 与人类偏好对齐的有效和可控的优化，大幅降低了计算成本，具有较高的实际应用前景。
## 275. `cs.CL` - AI Flow: 视角、场景和方法 [PDF](https://arxiv.org/pdf/2506.12479), [HTML](https://arxiv.org/abs/2506.12479)
### Authors
Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li
### Background
始于克劳德·香农的信息理论基础和艾伦·图灵的机器智能愿景，信息技术（IT）和通信技术（CT）的 convergent evolution 已经创造出不间断的连接和计算浪潮。这种协同作用引发了技术革命，现在已经达到顶峰，通过大型人工智能模型重新塑造工业并重新定义人机协作。然而，实现无处不在的智能面临着重大挑战，因为大模型消耗大量资源，对高通信带宽的需求也很高。
### Innovation
为了应对这些挑战，AI Flow被引入作为一种多学科框架，整合了最新的IT和CT进步，特别是：1) 设备-边缘-云端框架作为基础，整合了终端设备、边缘服务器和云集群，以优化低延迟模型推断的可扩展性和效率；2) 引入家族模型的概念，即一系列具有对齐隐藏特征的不同大小的模型，允许有效协作和灵活适应不同的资源约束和动态场景；3) 基于连接和交互的智能涌现是一种新的AI Flow范式，通过利用通信网络增强连接性，跨异构节点的AI模型协作实现了超过单一模型能力的涌现智能。这些创新提升了智能，提供了高效响应和普遍接入的AI服务，为更紧密融合AI技术和通信系统铺平了道路
### Conclusion
AI Flow为AI服务提供了更强大、及时响应及普遍访问的能力，为更紧密集成AI技术和通信系统打开了大门。
## 276. `cs.CL` - 使用生成人工智能进行因果表示学习：文本作为治疗的应用 [PDF](https://arxiv.org/pdf/2410.00903), [HTML](https://arxiv.org/abs/2410.00903)
### Authors
Kosuke Imai,Kentaro Nakamura
### Background
本文探讨了利用生成人工智能（GenAI）增强未结构化高维度治疗（如文本）的因果推断有效性的方法。通过使用大规模语言模型（LLMs）生成治疗并利用其内部表示来估计因果效应，研究了如何通过这些真内部表示来分离出感兴趣的治疗特征，如特定情感和特定主题，从而从其他可能未知的混杂特征中分离出来。这项研究试图通过使用大规模语言模型来避免现有方法需要从数据中学习因果表示的需求，从而提高因果效应估计的准确性和效率。通过使用双重机器学习，正式建立了非参数识别平均因果效应所需的条件，并提出了避免重叠假设违规的估计策略。该研究还通过使用工具变量方法扩大了该方法在基于人类感知的治疗特征设置上的适用性，同时研究了文本再利用中LLM再生现有文本的应用场景。通过模拟和实证研究，使用开源LLM Llama 3生成的文本数据，展示了所提估计器相对于当前最先进的因果表示学习算法的优势及其在各种情景下的显著优势。
### Innovation
本文提出了一种新的GenAI增强的因果推断方法（GenAI-Powered Inference, GPI），通过利用大规模语言模型生成文本治疗并使用其内部表示来估计因果效应，该方法避免了从数据中学习因果表示的需求，能产生更准确和高效的估计。同时，该研究通过双重机器学习获得了所提估计器的渐近性质，并使用工具变量方法扩展了其在基于人类感知的治疗特征设置上的适用性。此外，该方法也适用于文本再利用场景，其中用大规模语言模型再生现有文本。
### Conclusion
本文提出并验证了一种新的GenAI增强的因果推断方法（GPI），通过大规模语言模型的内部表示，能够更准确地估计因果效应。该方法避免了现有方法从数据中学习因果表示的需求，能够有效提升估计的准确性和效率。同时，通过双重机器学习和工具变量方法的应用，本研究还探讨了方法在不同场景下的适用性和优势。
## 277. `cs.CL` - 通过强化学习迭代重新加权然后优化冻结LLM的方法 [PDF](https://arxiv.org/pdf/2506.17828), [HTML](https://arxiv.org/abs/2506.17828)
### Authors
Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong
### Background
通常将大型语言模型（LLMs）与人类偏好对齐需要使用RLHF（通过奖励学习的人类反馈）和DPO（基于策略优化）等微调方法。这些方法直接优化模型参数，因此不能在测试时使用，也不能在无法访问模型权重的情况下使用。相比之下，测试时间方法通过利用奖励函数来引导和改善输出质量，但这些方法会导致高昂的推理成本，并且通常基于不完美的奖励或价值函数，导致输出不够理想。
### Innovation
本文提出了一种名为Iterative Reweight-then-Optimize (IRO)的方法，这是一种强化学习框架，允许在不调整基本模型参数的情况下对（冻结）基本模型进行类似于RL的对齐。在训练过程中，每次迭代（i）从基模型中采样候选对象，（ii）使用当前值函数重新采样，（iii）训练一个新轻量级的价值函数以引导下一次解码过程。在测试时，通过基于搜索的优化过程使用价值函数来指导基模型生成。此外，用户可以像OpenAI的强化微调（RFT）一样利用IRO来自定义模型对齐，而无需访问其权重。
### Conclusion
通过IRO方法，用户可以在不查看或调整模型权重的情况下对模型进行自定义对齐，类似于OpenAI的强化微调方法，从而实现更加灵活和高效的模型对齐过程。
## 278. `cs.CL` - Mind2Web 2：利用代理评判者评估自主搜索 [PDF](https://arxiv.org/pdf/2506.21506), [HTML](https://arxiv.org/abs/2506.21506)
### Authors
Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su
### Background
自主搜索，如深度研究系统，通过代理自主浏览网络、整合信息并提供全面的引用背书答案，代表了用户与大规模信息交互方式的重大转变。虽然自主搜索提供了更高的效率和认知卸载，然而其复杂性和开放性也在逐步超越现有的评估基准和方法。目前的评估方法大多假设短搜索历时和静态答案，无法应对不断变化和复杂的答案评估难题。
### Innovation
Mind2Web 2 涉及一项创新的代理评判者框架，通过基于树状评分标准设计的任务特定代理构建方法，自动评估答案的正确性和来源归属。此外，该研究通过构建130个真实、高质量且长历时的任务，并进行了全面评估，涵盖了10个前沿的自主搜索系统和人类表现，揭示了未来的开发洞察。
### Conclusion
最佳表现的系统，OpenAI深度研究，在时间上仅为人类的一半，但其表现已经达到了50-70%的水平，显示了巨大潜力。整体来看，Mind2Web 2 提供了一个严格的框架，用于开发和基准测试下一代自主搜索系统。
## 279. `cs.CL` - Mixture of Reasonings: 教大型语言模型使用自适应策略进行推理 [PDF](https://arxiv.org/pdf/2507.00606), [HTML](https://arxiv.org/abs/2507.00606)
### Authors
Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang
### Background
大型语言模型（LLMs）通过高级提示技术如思维链（CoT）和思维树（ToT）在复杂任务中表现出色，但它们对手动构建的任务特定提示的依赖性限制了其适应性和效率。现有的方法依赖于人工设计的提示，这些提示通常需要针对特定任务进行定制，这降低了模型的灵活性和效率。因此，研究者们提出了一种新的训练框架，旨在提高LLMs的自主性和适应性，在无需外部提示工程技术的情况下进行任务适应性推理。这种新方法通过嵌入多种推理策略来实现这一目标，使得模型能够根据不同任务自主生成适当的推理链模板。
### Innovation
本文介绍了一种名为Mixture of Reasoning（MoR）的训练框架，该框架能够将多样化的推理策略嵌入到LLM中，实现自主任务适应性推理，无需外部提示工程。MoR有两个阶段：思考生成阶段，使用如GPT-4o的模型创建推理链模板；SFT数据集构建阶段，将创建的模板与基准数据集配对进行监督微调。MoR通过这种方法提供了比现有方法更为灵活和通用的解决方案，能够显著提高LLMs在复杂任务中的性能并跨任务提升推理能力。
### Conclusion
实验结果表明，MoR显著提高了LLM的性能，MoR150在CoT提示下达到0.730，相比以前的提示方法提高了2.2%，并且相比于基线提高了13.5%。MoR消除了对特定任务提示的需求，为多种任务的强健推理提供了通用解决方案。
## 280. `cs.CL` - GPAS: 通过保留梯度的激活缩放加速大语言模型预训练 [PDF](https://arxiv.org/pdf/2506.22049), [HTML](https://arxiv.org/abs/2506.22049)
### Authors
Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Lu Yin,Can Yang
### Background
现代大型语言模型（如LLaMA、Qwen和DeepSeek系列）主要采用预层归一化（Pre-LN）的变压器架构。虽然Pre-LN在预训练过程中表现出稳定性和大规模模型扩展性，但由于激活方差在层间呈指数增长，导致残差连接中的捷径路径比子层输出占据更大比例，限制了深层层的学习能力。
### Innovation
我们提出了梯度保留激活缩放（GPAS），这是一种简单的方法，可以与现有方法结合使用以缓解上述问题。GPAS通过在保持梯度不变的情况下缩小中间激活值，使得激活信息得以保留，避免了梯度缩放导致的梯度消失问题。广泛的实验结果表明，GPAS在不同规模的模型（从71M到1B）上都能实现一致的性能提升，而且还能改善替代架构如Sandwich-LN和DeepNorm，显示出其广泛的适用性和提升训练动态的潜力。
### Conclusion
我们的代码可在以下链接获取。GPAS能够在多种设置下改进训练动态并提高性能，特别是在预训练阶段加速收敛。
## 281. `cs.CL` - 自我引导的过程奖励优化与重定义的步骤优势在过程强化学习中的应用 [PDF](https://arxiv.org/pdf/2507.01551), [HTML](https://arxiv.org/abs/2507.01551)
### Authors
Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua
### Background
过程强化学习(PRL)在提升大型语言模型(LLMs)的推理能力方面展现了显著潜力。然而，引入额外的过程奖励模型会带来显著的计算开销，并且缺乏统一的在过程层面的优势估计理论框架。
### Innovation
本文提出了一种名为SPRO的新框架，用于通过两个关键创新实现过程感知的RL：首先，理论证明过程奖励可以内在地从策略模型中衍生出来；其次，引入了明确的累积过程奖励和掩码步骤优势(MSA)，这使在共享提示采样组中进行严格的步骤优势估计成为可能。
### Conclusion
实验结果显示，SPRO在训练效率上比vanilla GRPO高3.4倍，并且在测试准确度上提高了17.5%。此外，SPRO在整个训练过程中保持了稳定的高策略熵，并减少了约1/3的平均响应长度，证明了足够的探索并且防止了奖励作弊。值得注意的是，与如GRPO这样的结果监督RL方法相比，SPRO没有增加额外的计算开销，便于工业应用。
## 282. `cs.CL` - 汉字符号作为叙事桥梁的共同创作：老年人迁移者的AI共同创作研讨会 [PDF](https://arxiv.org/pdf/2507.01548), [HTML](https://arxiv.org/abs/2507.01548)
### Authors
Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen
### Background
本文探讨了如何通过AI辅助共同创作的方式，让老年人，特别是中国城市中的老龄移民，能够表达那些常常被碎片化、未能充分代表或难以用言语表达的个人叙事。研究背景来自于对老龄移民记忆和叙事表达的需求，尤其是在快速城市化和人口迁移背景下，老年人的历史和记忆需要得到妥善记录和表达。
### Innovation
本文创新地提出了一种结合口头叙述和汉字象征性重建的试点研讨会形式，通过大型语言模型（LLM）推荐的小篆符号，以及物理材料，参与者能够创作新的汉字形式。这种方法的独特之处在于它不需要参与者具备数字素养，而是由人类引导和支持AI的存在，帮助参与者将生活经验转化为视觉和触觉的艺术表达。这种方法重新定位了AI的作用，使其从内容生产者的角色转变为支持者的角色，并通过社会技术系统支持叙事能力的发展。
### Conclusion
该研究结果表明，通过AI辅助共同创作的方式，可以为老年人提供一种新的叙事表达手段，这种手段能更好地传达他们的经历和记忆。此外，这种方法展示了在实际应用中，社会技术系统如何有效支持和增强人与AI之间的合作，特别是在老龄化社会的需求中，为未来的人机协作提供了新的视角。
## 283. `cs.CL` - 关于语言生成建模的特征刻画：幻觉、广度与稳定性的相互作用 [PDF](https://arxiv.org/pdf/2412.18530), [HTML](https://arxiv.org/abs/2412.18530)
### Authors
Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas
### Background
本文研究了Kleinberg和Mullainathan提出的语言生成领域，在Gold和Angluin的经典工作基础上进行探讨。Kleinberg和Mullainathan的工作提供了一种在有限时间内生成目标语言中未见过字符串的算法，但是这种算法的覆盖面不足，无法生成丰富的字符串集。尽管有多项研究探讨了不同广度的概念及其可行性，但对其完全描述仍然未确定。本文通过清楚地描述现有广度概念及其扩展，解决了当前的不确定性。此外，研究指出，对于一些性能指标，如困惑度和幻觉率，训练模型在这些方面超越其他语言是不可实现的。
### Innovation
研究通过阐明与广度相关的当前概念及其扩展来解决了不确定性，并且证明了在稳定生成器的限制下，广度的概念对于生成变体来说具有相同的难度。此外，研究指出，在使用这些概念进行生成时，稳定性之间存在复杂关系，突出了广度、稳定性和一致性在语言生成中的交互作用。
### Conclusion
本文对语言生成中的各种广度概念及其扩展进行了深入分析，并提出了几个重要结论：首先，对于多种性能指标，增加语言生成的广度是不可行的；其次，当需要稳定性时，具有多种广度概念的生成变得同样困难，揭示了广度、稳定性和一致性之间的复杂关系。
## 284. `cs.CL` - 从网页搜索走向有代理的深度研究：用推理代理激励搜索 [PDF](https://arxiv.org/pdf/2506.18959), [HTML](https://arxiv.org/abs/2506.18959)
### Authors
Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu
### Background
信息检索是现代知识获取的基础，每天支持着跨多种领域的数十亿次查询。然而，传统的基于关键词的搜索引擎越来越难以处理复杂的、多步的信息需求。传统的信息检索技术已经无法满足这些需求，因为它们缺乏自主推理、迭代检索和信息合成的能力。论文指出，大型语言模型（LLMs）具有推理和能动性，正在引领一种新的范式——有代理的深度研究。这种系统通过紧密整合自主推理、迭代检索和信息合成，形成一个动态反馈回路，超越了传统的信息检索技术，从静态的网页搜索转向了交互式的代理系统，这些系统能够计划、探索和学习。
### Innovation
论文引入了一种新的范式——有代理的深度研究。这种系统通过自主推理、迭代检索和信息合成形成动态反馈回路，显著超越了传统的信息检索方法。论文还提出了一种测试时的可扩展性定律，以明确计算深度对推理和搜索的影响。实验证明，有代理的深度研究不仅大幅优于现有方法，而且是未来信息检索的主导范式。此外，相关的行业产品、研究论文、基准数据集和开源实现被收集分享给社区。
### Conclusion
有代理的深度研究不仅在性能上远远领先于现有的信息检索方法，而且还展示了在未来信息获取中增长的潜力和优势。这种方法通过使用具有推理能力的代理来革新搜索过程，改变了传统的信息检索方式。
## 285. `cs.CV` - 大语言模型在视频中进行事故检测的方法、数据集和挑战综述 [PDF](https://arxiv.org/pdf/2507.02074), [HTML](https://arxiv.org/abs/2507.02074)
### Authors
Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma
### Background
交通事故检测对于智能交通系统至关重要。近年来，大型语言模型（LLMs）和视觉-语言模型（VLMs）的发展改变了我们处理、理解和总结多模态信息的方式。
### Innovation
本文回顾了利用LLMs进行视频事故检测的最新方法，提出了一个结构化的融合策略分类法，并综述了关键数据集、分析了模型架构、比较了性能基准，并讨论了现有挑战和机会。
### Conclusion
本文为视频理解与基础模型交叉领域的未来研究奠定了基础。
## 286. `cs.CV` - SurgVisAgent: 多模态代理模型在多功能手术视觉增强中的应用 [PDF](https://arxiv.org/pdf/2507.02252), [HTML](https://arxiv.org/abs/2507.02252)
### Authors
Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen
### Background
精确的手术干预对患者安全至关重要，先进的增强算法已被开发出来辅助外科医生进行决策。尽管取得了显著进展，这些算法通常仅针对具体场景下的单一任务，难以适应复杂的实际手术情况。现有算法的这一局限性促使研究关注如何开发更为通用且有效的解决方案，以提高手术过程中的视觉增强效果和决策支持能力。
### Innovation
本文提出了SurgVisAgent，这是一种基于多模态大规模语言模型的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像中的失真类别和严重程度，并执行多重增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除。通过设计先验模型提供领域特定知识，并利用上下文少次学习和链式思维推理，SurgVisAgent能够提供定制化的图像增强，以应对各种失真类型和严重程度。本文还构建了一个模拟实际手术失真的综合基准，并通过大量实验表明，SurgVisAgent超越了传统单一任务模型，展示出作为手术辅助统一解决方案的潜力。
### Conclusion
SurgVisAgent能够有效识别多种图像失真并提供定制化的图像增强，适用于多种手术场景。通过多模态大规模语言模型的支持，SurgVisAgent不仅能够提高手术过程中的图像质量，还能够作为统一解决方案为外科医生提供决策支持，从而有效提高了手术的安全性和成功率。
## 287. `cs.CV` - SciGA: 用于学术论文图形摘要设计的综合数据集 [PDF](https://arxiv.org/pdf/2507.02212), [HTML](https://arxiv.org/abs/2507.02212)
### Authors
Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi
### Background
图形摘要（GAs）在视觉传达科学论文的关键发现方面起着关键作用。尽管近年来研究逐渐将视觉材料如图1作为事实上的GAs纳入其中，但它们对科学交流的增强作用仍远未被充分利用。此外，设计有效的GAs需要先进的可视化技能，这成为其广泛采用的障碍。
### Innovation
本文介绍了SciGA-145k，这是一个大规模数据集，包含约145,000篇科学论文和1,140,000幅插图，专门用于支持GA选择和推荐以及促进自动GA生成的研究。本文提出了两个任务：1） intra-GA推荐，确定文献中适合作为GA的图；2） inter-GA推荐，从其他文献中检索GA以激发创建新GA的方法。此外，还提出了一种名为Confidence Adjusted top-1 ground truth Ratio（CAR）的新推荐指标，该指标提供了对模型行为的细粒度分析，解决了传统排名指标的局限性。
### Conclusion
通过统一这些任务和指标，SciGA-145k 为推动视觉科学交流奠定了基础，同时促进了科学界的AI开发。
## 288. `cs.CV` - ESTR-CoT: 在链式思维推理下的可解释和准确的事件流场景文本识别 [PDF](https://arxiv.org/pdf/2507.02200), [HTML](https://arxiv.org/abs/2507.02200)
### Authors
Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang
### Background
事件流基于场景文本识别近年来成为一个研究热点，尤其是在低光照和快速运动等极端条件下超越传统的RGB相机表现。现有方法或采用端到端编码解码框架或大型语言模型增强识别，但仍然受到解释不足和弱上下文逻辑推理的限制。
### Innovation
提出了一种新颖的基于链式思维推理的事件流场景文本识别框架（ESTR-CoT），采用视觉编码器EVA-CLIP（ViT-G/14）变换输入事件流为标记，并使用Llama标记化器编码给定的生成提示。采用Q-former将视觉标记与预训练的大型语言模型Vicuna-7B对齐，同时输出答案和思维过程推理。此外，还提出了一个大规模的思维过程（CoT）数据集，通过生成、打磨和专家验证三阶段处理方式训练框架，为后续基于推理的大模型开发提供了坚实的数据基础。
### Conclusion
在三个事件流结构识别基准数据集（EventSTR、WordArt*、IC15*）上的广泛实验充分验证了所提框架的有效性和可解释性。源代码和预训练模型将在该链接释放。
## 289. `cs.CV` - 理解用于生成合成数据时的权衡 [PDF](https://arxiv.org/pdf/2507.02217), [HTML](https://arxiv.org/abs/2507.02217)
### Authors
Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma
### Background
在工业视觉系统中，仅从少量图像中学习鲁棒的物体检测器是一个关键挑战，因为收集高质量的训练数据可能需要几个月的时间。合成数据已经成为视觉检查和拾放机器人数据高效解决方案的关键。尽管目前的管道依赖于像Blender或Unreal这样的3D引擎，但它们仍然需要数周时间来渲染小数据集，并且生成的图像经常与现实之间存在显著差距。扩散模型承诺可以以分钟级生成高质量图像，但特别是在数据稀少的情况下，精确控制仍然很困难。尽管现在有许多附加器可以将扩散应用于纯文本提示之外，但不同的条件方案如何影响合成数据质量的问题仍然不明确。因此，作者研究了来自四个标准物体检测基准中的八十种多样视觉概念，并比较了两种条件策略：提示基础和布局基础。当条件线索集较窄时，提示条件提供更高质量的合成数据；随着多样性的增加，布局条件变得更好。当布局线索与完整训练分布匹配时，合成数据的平均精度提升幅度平均提高了34%，并且最多可提高177%相比单独使用真实数据的方法。
### Innovation
该研究探索了不同条件策略（提示基础和布局基础）对合成数据质量的影响，特别关注了在数据稀缺条件下的性能。发现当条件线索集较窄时，提示条件提供更高质量的合成数据；随着多样性的增加，布局条件变得更好。当布局线索与完整训练分布匹配时，合成数据的平均精度提升显著。
### Conclusion
通过使用布局条件，可以显著提高合成数据质量，特别是在数据稀少的情况下，能够将平均平均精度提升高达177%。
## 290. `cs.CV` - 高保真度差异信息驱动二值视觉变换器 [PDF](https://arxiv.org/pdf/2507.02222), [HTML](https://arxiv.org/abs/2507.02222)
### Authors
Tian Gao,Zhiyuan Zhang,Kaijie Yin,Xu-Cheng Zhong,Hui Kong
### Background
二值视觉变换器（ViTs）提供了一种解决计算/存储需求高与边缘设备部署限制之间权衡的有效途径。然而，现有的二值ViT方法往往会出现严重的性能下降，或者依赖于全精度模块。
### Innovation
提出了一种名为DIDB-ViT的新颖二值ViT，该模型保留了原始ViT结构和计算效率，同时具有很高的信息性。创新点包括：1) 设计了包含差异信息的注意力模块以减轻由二值化引起的的信息损失并增强高频保留；2) 使用离散哈耳小波进行频域分解，跨不同频率保留二值Q和K张量的相似性计算保真度；3) 引入改进的RPReLU激活函数来重新构建激活分布，扩展模型的表示能力。
### Conclusion
实验结果表明，DIDB-ViT在多个ViT架构中显著优于最先进的网络量化方法，在图像分类和分割性能上取得了优异的结果。
## 291. `cs.CV` - Team RAS在第9届ABAW竞赛中的多模态复合表情识别方法 [PDF](https://arxiv.org/pdf/2507.02205), [HTML](https://arxiv.org/abs/2507.02205)
### Authors
Elena Ryumina,Maxim Markitantov,Alexandr Axyonov,Dmitry Ryumin,Mikhail Dolgushin,Alexey Karpov
### Background
复合表情识别（CER），是情感计算的一个子领域，旨在检测由基本情绪组合形成复杂的情绪状态。现有的CER方法通常依赖于特定任务的数据进行训练。与这些方法不同，本文提出了一种新颖的零样本多模态CER方法，该方法将六种异质模态整合到一个管道中：静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。该方法使用的是零样本组分，包括基于CLIP的标签匹配和Qwen-VL进行语义场景理解。此外还提出了一个多头概率融合（MHPF）模块和复合表情（CE）变换模块。这些模块在零样本测试下，对于AffWild2、AFEW和C-EXPR-DB数据集分别获得了46.95%、49.02%和34.85%的F1得分，这表明提出的方案能够在无需领域适应的情况下捕捉复合表情。
### Innovation
提出了一种新颖的零样本多模态CER方法，该方法将六种异质模态整合到一个管道中，并结合了基于CLIP的标签匹配和Qwen-VL进行语义场景理解。还引入了多头概率融合（MHPF）模块和复合表情（CE）变换模块，使用了对称概率聚合（PPA）和对称特征相似性聚合（PFSA）方法生成可解释的复合情感输出。这在多语料库训练下，展示了有效捕捉复合表情的能力，且无需领域适应就可达到与监督方法相当的结果。
### Conclusion
所提出的多模态复合表情识别方法在没有特定领域训练数据的情况下展示了良好的性能，为情感计算领域提供了新的研究思路。该方法的源代码已经公开。
## 292. `cs.CV` - FMOcc: TPV驱动的流匹配3D占用预测带选择性状态空间模型 [PDF](https://arxiv.org/pdf/2507.02250), [HTML](https://arxiv.org/abs/2507.02250)
### Authors
Jiangxia Chen,Tongyuan Huang,Ke Song
### Background
3D语义占用预测在自动驾驶中起着关键作用，但由于若干帧影像固有的局限性和3D空间中的冗余性，近处和被遮挡场景的预测准确性受到限制。现有方法通过融合历史帧数据来提升性能，但这种方法需要额外的数据和大量计算资源。
### Innovation
本文提出了一种基于三视角(Tri-perspective View, TPV)细化占用网络FMOcc，并采用了带有流匹配选择性状态空间模型的占用预测方法。首先，设计了基于流匹配模型的特征细化模块，即流匹配选择性状态空间模块(FMSSM)。其次，通过设计TPV-Space State Module (TPV SSM)层和Plane Selective SSM (PS3M)，选择性过滤TPV特征，减少空气体元对外部体元的影响，提升模型效率和对远距离场景的预测能力。最后，设计了掩码训练(Mask Training, MT)方法，增强FMOcc的鲁棒性，解决传感器数据丢失的问题。实验结果表明，FMOcc在Occ3D-nuScenes和OpenOcc数据集上表现优于现有最先进的方法。
### Conclusion
实验结果表明，使用两帧输入的FMOcc在Occ3D-nuScenes验证集上获得了43.1%的RayIoU和39.8%的mIoU，而在OpenOcc数据集上，5.4 G推理内存和330ms的推理时间下，RayIoU达到了42.6%。
## 293. `cs.CV` - 基于双方向域适应的跨域高光谱图像分类 [PDF](https://arxiv.org/pdf/2507.02268), [HTML](https://arxiv.org/abs/2507.02268)
### Authors
Yuxiang Zhang,Wei Li,Wen Jia,Mengmeng Zhang,Ran Tao,Shunlin Liang
### Background
通常情况下，用于训练和测试的卫星或航空图像来自不同的地区或时间，使得同一类别的地物在不同场景中表现出显著的光谱变化。现有的高光谱遥感技术能够提取精细化的土地覆被分类，但在跨域分类任务中，由于域适应性不足，分类效果受到影响。因此，研究提出了一种双方向域适应(BiDA)框架，以增强分类器在目标场景中的适配性和可分性，应对不同域之间的光谱变化。
### Innovation
该研究提出了一种基于双方向域适应的模型，设计了一种三分支变压器架构(源分支、目标分支和耦合分支)，通过耦合分支中的联合多头交叉注意机制(CMCA)促进特征交互和跨域相关性挖掘。同时，设计了双向蒸馏损失指导适应空间学习，且提出了一种自适应强化策略(ARS)以提升模型在噪声条件下对通用特征的提取能力。这种框架在跨时域/场景的航空和卫星数据集上的实验结果明显优于一些最新的域适应方法。在跨时域树木物种分类任务上的结果表明，提出的方法比最先进的方法高出3%到5%。
### Conclusion
实验结果显示，提出的BiDA方法在跨域高光谱图像分类任务上表现优异，提升了分类器的适应性和分离性，特别是在噪声条件下对通用特征的提取能力。
## 294. `cs.CV` - 水下单目度量深度估计：真实世界基准与合成微调 [PDF](https://arxiv.org/pdf/2507.02148), [HTML](https://arxiv.org/abs/2507.02148)
### Authors
Zijie Cai,Christopher Metzler
### Background
单目深度估算已经取得了进步，能够提供相对和度量深度预测。然而，这种可靠性在水下环境中仍受到限制，因为水中光线衰减和散射、颜色畸变、浑浊以及缺乏高质量的度量级地面真值数据的影响。本研究在FLSea和SQUID等具有度量深度注释的真实世界水下数据集上，对零样本和微调的单目度量深度估计模型进行了全面基准测试。r
### Innovation
研究表明，大规模模型在陆地（真实或合成）数据上训练，在空气环境中效果良好，但在水下环境中表现不佳，因为存在显著的数据域迁移问题。研究中对Depth Anything V2模型使用基于物理的水下图像形成模型生成的合成水下Hypersim数据集的编码器进行了微调，以应对这一问题。研究结果表明，微调后的模型在所有基准测试中均表现出一致的性能提升，并优于仅在清洁的空气Hypersim数据集上训练的基础模型。该研究对单目度量深度估计在水下场景中的性能进行了详细的评估和可视化，突显了在挑战性的水下环境中实现鲁棒性和泛化度量深度预测时，领域适应和尺度感知监督的重要性。r
### Conclusion
本研究提供了单目度量深度估计在水下场景中的详细评估与可视化，突显了领域适应和规模感知监督在该领域的未来研究中至关重要。
## 295. `cs.CV` - MAC-Lookup：针对水下图像增强的多轴条件查找模型 [PDF](https://arxiv.org/pdf/2507.02270), [HTML](https://arxiv.org/abs/2507.02270)
### Authors
Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen
### Background
水下图像在探索中至关重要，但这些图像常常因为光照变化、水体浑浊和气泡而面临可见性和色彩问题。传统的基于先验的方法和基于像素的方法往往无效，而深度学习缺乏高质量的训练数据集。
### Innovation
引入了Multi-Axis Conditional Lookup (MAC-Lookup)模型，该模型通过改进颜色准确度、锐度和对比度来提升视觉质量。它包括了Conditional 3D Lookup Table Color Correction (CLTCC)进行初步的颜色和质量校正，以及Multi-Axis Adaptive Enhancement (MAAE)进行细节增强。该模型可以防止过增强和饱和现象，同时处理水下挑战。
### Conclusion
广泛的实验表明，MAC-Lookup在增强水下图像方面表现优异，能够恢复细节和颜色，优于现有的方法。
## 296. `cs.CV` - 基于自蒸馏突出部分可见影视语言的视频到音频生成 [PDF](https://arxiv.org/pdf/2507.02271), [HTML](https://arxiv.org/abs/2507.02271)
### Authors
Feizhen Huang,Yu Wu,Yutian Lin,Bo Du
### Background
视频到音频（V2A）生成在电影和视频后期制作中取得了显著进展，但当前方法忽视了影视语言，这是电影制作中艺术表达的关键组成部分。因此，在隔音目标仅部分可见的情况下，其性能会下降。现有方法未充分考虑这一挑战。
### Innovation
提出了一种简单的自蒸馏方法，以扩大V2A模型的应用范围，使其能够处理影视语言场景。通过模拟影视语言的变化，学生模型学习将训练对的视频特征与相同的视听对应关系对齐，从而能够有效捕捉声音与部分视觉信息之间的关联。
### Conclusion
该方法不仅在所有评估指标下实现了在部分可见情况下的显著改进，还在大规模V2A数据集VGGSound上增强了性能。
## 297. `cs.CV` - 多标签分类框架用于飓风损害评估 [PDF](https://arxiv.org/pdf/2507.02265), [HTML](https://arxiv.org/abs/2507.02265)
### Authors
Zhangding Liu,Neda Mohammadi,John E. Taylor
### Background
飓风导致广泛破坏，不同的损害类型和严重程度需要及时和准确的评估以有效应对自然灾害。传统的单一标签分类方法无法捕捉到飓风后损害的复杂性，因此需要一种新的多标签分类框架来使用航空图像评估损害。这个框架通过集成基于ResNet的特征提取模块和类别特定的注意力机制，能够在单张图像中识别多个损害类型。
### Innovation
提出了一种基于ResNet的特征提取模块和类别特定的注意力机制的多标签分类框架，用于通过航空图像评估飓风损坏。该方法的平均精确率为90.23%，优于现有的基线方法。这提高了飓风后损害评估的效率，有助于更精准的灾害响应，并对未来灾害缓解和韧性策略做出了贡献。
### Conclusion
提出的框架增强了飓风后损害的评估能力，使灾害响应更加精准和高效，为未来的灾害缓解和韧性策略提供了支持。这篇论文已被接受发表在美国土木工程师学会国际土木工程计算会议(i3CE 2025)上，并将在官方会议论文集中出现。
## 298. `cs.CV` - LMPNet for Weakly-supervised Keypoint Discovery [PDF](https://arxiv.org/pdf/2507.02308), [HTML](https://arxiv.org/abs/2507.02308)
### Authors
Pei Guo,Ryan Farrell
### Background
该研究探索在仅有类别标签弱监督的情况下进行语义对象关键点发现的任务。通过将判别性训练的中间层滤波器转换为关键点检测器来实现这一目标，旨在自动发现对目标姿态具有鲁棒性的语义关键点，并构建与物体关键点对齐的“非重复局部模式”。
### Innovation
研究提出了一种新颖的高效泄漏最大池化（LMP）层，无需依赖手动设计的损失项，直接鼓励最终卷积层滤波器学习与物体关键点相匹配的“非重复局部模式”。此外，还提出了一种简单的选择策略来确保滤波器激活的一致性，并应用注意掩码以促使网络将注意力分散到整个物体，而不是仅集中在最具判别性的区域。最后，提出了一种可学习的聚类层来将关键点建议集组成关键点预测。该模型（LMPNet）具有很高的可解释性，直接操作网络滤波器以检测预定义的概念，并展示了与监督姿态估计模型相匹敌的预测准确性。
### Conclusion
实验表明，LMPNet能够自动发现鲁棒性强的语义关键点，同时保持了与监督姿态估计模型相当的预测精度。
## 299. `cs.CV` - ViRefSAM: 视觉参考引导的分割任何模型在遥感分割中的应用 [PDF](https://arxiv.org/pdf/2507.02294), [HTML](https://arxiv.org/abs/2507.02294)
### Authors
Hanbo Bi,Yulong Xu,Ya Li,Yongqiang Mao,Boyuan Tong,Chongyang Li,Chunbo Lang,Wenhui Diao,Hongqi Wang,Yingchao Feng,Xian Sun
### Background
段 Anything 模型 (SAM) 通过提示驱动的范式，在通用分割任务中表现出强大的泛化能力。然而，将其应用于遥感 (RS) 图像仍然面临两大挑战。首先，为每张图像手动构建精确的提示（例如，点或框）既耗时又低效，特别是在 RS 场景中存在密集的小目标或空间分散的情况下。其次，SAM 缺乏领域适应性，因为它主要是针对自然图像进行预训练的，并且很难捕捉 RS 特定的语义和空间特征，特别是在分割新型或未见类别时。
### Innovation
本文受到少样本学习的启发，提出了 ViRefSAM，这是一种新颖的框架，利用少量注释的参考图像来指引 SAM，而无需手动提示。具体来说，ViRefSAM 引入了两个关键组件：(1) 视觉上下文提示编码器，从参考图像中提取类别的特定语义线索，并通过与目标图像的上下文交互生成对象感知的提示；(2) 动态目标对齐适配器，集成到 SAM 的图像编码器中，通过注入类别的特定语义来缓解领域差距，使 SAM 动态关注任务相关的区域。
### Conclusion
在 iSAID-5^i、LoveDA-2^i 和 COCO-20^i 三个少样本分割基准测试上进行了广泛实验，结果表明，ViRefSAM 仅通过使用少量参考图像就能实现准确且自动地分割未见过的类别，并且在各种数据集上的一致上优于现有少样本分割方法。
## 300. `cs.CV` - 感知激活器：一种直观且便携的大脑认知探索框架 [PDF](https://arxiv.org/pdf/2507.02311), [HTML](https://arxiv.org/abs/2507.02311)
### Authors
Le Xu,Qi Zhang,Qixian Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao
### Background
脑-视觉解码领域的最新进展显著推进了从人类视觉皮层的神经活动重建高保真的感知视觉刺激的技术。现有的大多数方法采用两层解码策略，即像素级和语义级。然而，这些方法在低级像素对齐方面依赖性较强，但在高级的语义对齐方面却缺乏足够的细粒度，导致了语义对象重建中出现明显的失真。为了更深入理解大脑的视觉感知模式以及当前解码模型如何处理语义对象，研究者开发了一个实验框架，利用功能性磁共振成像（fMRI）表示作为干预条件。通过这种方法，研究者在多尺度图像特征中注入这些表示，比较在有无fMRI信息的情况下，对物体检测和实例分割任务的下游性能以及中间特征的变化情况。研究结果表明，结合fMRI信号可以提高下游检测和分割的准确性，证实了fMRI包含了丰富的多对象语义线索和粗略的三维空间定位信息，这些都是当前模型尚未完全利用或整合的方面。
### Innovation
研究通过开发实验框架，利用功能磁共振成像（fMRI）表示作为干预条件，在多尺度图像特征中注入这些表示，比较在有无fMRI信息的情况下，对物体检测和实例分割任务的下游性能以及中间特征的变化情况，展示了fMRI信号对提高下游检测和分割准确性的重要性，并揭示了fMRI包含了丰富的多对象语义线索和粗略的三维空间定位信息。
### Conclusion
研究结果证实了fMRI信号的引入可以显著提升下游检测和分割的准确性，而且fMRI信号包含了当前模型尚未完全利用或整合的多对象语义和空间定位信息。
## 301. `cs.CV` - 合成视频有用吗？一种以检索为中心的合成视频评估基准 [PDF](https://arxiv.org/pdf/2507.02316), [HTML](https://arxiv.org/abs/2507.02316)
### Authors
Zecheng Zhao,Selena Song,Tong Chen,Zhi Chen,Shazia Sadiq,Yadan Luo
### Background
文本到视频（T2V）合成技术取得了快速进展，当前的评估指标主要关注视觉质量和时间一致性，但缺乏对合成视频在文本到视频检索（TVR）等下游任务中性能的深入洞察。为此，本文提出了SynTVA数据集和基准，旨在评估合成视频在构建检索模型中的实用性。该基准基于800个多样化的用户查询生成合成视频，并从四个关键语义对齐维度（对象和场景、动作、属性、提示保真度）对每一对视频和文本进行标注。该评估框架将通用视频质量评估（VQA）指标与这些对齐评分相关联，并研究其在预测下游TVR性能方面的有效性。
### Innovation
本文创新性地提出了SynTVA数据集和基准，用于评估合成视频在检索场景中的实用性和检索性能。该基准不仅评价视频质量，还关注语义对齐，即对象和场景、动作、属性和提示保真度等关键维度，并通过一个自动评估器进一步评估对齐质量。这种方法为探索提高合成视频在检索任务中应用的研究路径提供了新的视角，并展示了这种方法对TVR成果的改善效果。
### Conclusion
本文展示，SynTVA数据集不仅是一个重要的评估基准，还能用于数据集扩充，帮助选择具有高实用性的合成视频样本，从而显著提高TVR任务的性能。
## 302. `cs.CV` - LaCo: 提高多模态大规模语言模型中视觉token层间压缩效率的新方法 [PDF](https://arxiv.org/pdf/2507.02279), [HTML](https://arxiv.org/abs/2507.02279)
### Authors
Juntao Liu,Liqiang Niu,Wenchao Chen,Jie Zhou,Fandong Meng
### Background
现有的针对多模态大规模语言模型（MLLMs）的视觉token压缩方法主要作为后编码器模块工作，限制了它们在提高效率方面的潜力。现有方法大多局限于编码器之后的处理，未能充分利用编码器内部的中间层进行高效的token压缩操作。
### Innovation
提出了一种新颖的框架LaCo（Layer-wise Visual Token Compression），其中引入了两大核心组件：1）层间像素移位机制，通过空间到通道的转换系统性地合并相邻的token；2）具有非参数快捷路径的残差学习架构，可以在压缩过程中保留关键的视觉信息。LaCo方法在压缩编码器中间层的visual tokens时，表现出色，超过了所有现有的方法，并且相比外部压缩，提高了20%以上的训练效率和15%以上的推理吞吐量，同时保持了强大的性能.
### Conclusion
综上所述，我们的LaCo方法在多模态大规模语言模型中实现视觉token的高效层间压缩，提供了优于现有方法的压缩效果，并且在训练效率和推理吞吐量上也取得了显著的提升，证明了其在视觉token压缩方面的有效性和优越性。
## 303. `cs.CV` - DreamComposer++: 推动基于多视角条件的扩散模型在3D内容生成中的能力 [PDF](https://arxiv.org/pdf/2507.02299), [HTML](https://arxiv.org/abs/2507.02299)
### Authors
Yunhan Yang,Shuo Chen,Yukun Huang,Xiaoyang Wu,Yuan-Chen Guo,Edmund Y. Lam,Hengshuang Zhao,Tong He,Xihui Liu
### Background
近期的研究发展了利用预训练的2D扩散模型从单张野外图片中生成高质量的新视角图像。然而，现有工作在生成可控的新视角上面临挑战，因为缺乏多视角信息。本文背景在于，通过多视角条件提升当前的视角意识扩散模型，以克服这一难题。
### Innovation
DreamComposer++是一个灵活且可扩展的框架，旨在通过加入多视角条件来改进现有的视角意识扩散模型。该框架利用一个视角意识的3D提升模块从多个视角提取物体的3D表示。这些表示通过多视角特征融合模块聚合并渲染到目标视角的潜在特征中。最终，取得到的特征被整合到预训练的图像或视频扩散模型中，以生成新视角。实验结果表明，DreamComposer++能够无缝集成到最先进的视角意识扩散模型中，并增强其从多视角条件生成可控新视角的能力。这项进步促进了可控的3D物体重建并开启了广泛的应用领域。
### Conclusion
实验结果证明，DreamComposer++能够有效地提升扩散模型在多视角条件下的表现，使得扩散模型能够更好地生成可控的新视角图像，增强了其在3D内容生成中的应用潜力。
## 304. `cs.CV` - Flow-CDNet: 一种用于检测双时相图像中慢速和快速变化的新网络 [PDF](https://arxiv.org/pdf/2507.02307), [HTML](https://arxiv.org/abs/2507.02307)
### Authors
Haoxuan Li,Chenxu Wei,Haodong Wang,Xiaomeng Hu,Boyuan An,Lingyan Ran,Baosen Zhang,Jin Jin,Omirzhan Taukebayev,Amirkhan Temirbayev,Junrui Liu,Xiuwei Zhang
### Background
传统的变化检测通常侧重于识别双时相图像（在同一地点在不同时间拍摄）之间的显著变化区域。然而，在实际应用中，缓慢的变化同样重要，因为它们可以作为潜在重大风险的先兆，例如在斜坡、大坝和尾矿池等场景中的微小变化。因此，设计能够同时检测缓慢和快速变化的变化检测网络是一个具有挑战性的问题。现有的方法在处理这样的问题时表现不佳。为了应对这一挑战，该论文提出了一种新的变化检测网络——Flow-CDNet，它由两个分支组成：光学流分支和二元变化检测分支，旨在同时检测缓慢和快速的变化。
### Innovation
Flow-CDNet采用了光学流分支和二元变化检测分支的两个模块。光学流分支使用金字塔结构以多尺度挖掘光流变化，而二元变化检测分支则采用ResNet网络结合光学流分支的输出生成快速变化影像。此外，为了评估其有效性，论文还构建了一个新的数据集——Flow-Change，以及一种结合二进制Tversky损失和L2范数损失的新损失函数和评估指标FEPE。实验结果表明，Flow-CDNet的性能优于现有方法。
### Conclusion
定量实验在Flow-Change数据集上进行，结果表明该方法在检测双时相图像中的慢速和快速变化方面优于现有方法。进一步的消融试验表明，两个分支之间相互促进，提高了检测性能。
## 305. `cs.CV` - 倾听内心的声音：通过中间特征反馈进行ControlNet训练对齐 [PDF](https://arxiv.org/pdf/2507.02321), [HTML](https://arxiv.org/abs/2507.02321)
### Authors
Nina Konovalova,Maxim Nikolaev,Andrey Kuznetsov,Aibek Alanov
### Background
目前文本到图像扩散模型已经取得了显著进展，但在生成输出时实现精确的空间控制仍然具有挑战性。虽然ControlNet通过引入辅助条件模块来解决这一问题，而ControlNet++则通过在最终去噪步骤中应用循环一致性损失来进行进一步细化。然而，这种方法忽视了中间生成阶段，从而限制了其有效性。
### Innovation
我们提出了InnerControl，一种训练策略，它在整个扩散步骤中强制执行空间一致性。该方法训练轻量级卷积探针，从每一步去噪过程中的中间UNet特征重建输入控制信号（例如边缘、深度）。这些探针即使在非常嘈杂的潜在特征中也能高效地提取信号，从而为训练提供伪真实控制目标。通过在整个扩散过程中最小化预测条件与目标条件之间的差异，我们的对齐损失提高了控制精度和生成质量。InnerControl与ControlNet++等现有技术结合后，实现了在多种条件方法（例如边缘、深度）下达到最新性能的成果。
### Conclusion
Combined with established techniques like ControlNet++, InnerControl achieves state-of-the-art performance across diverse conditioning methods (e.g., edges, depth).
## 306. `cs.CV` - 基于语言指导与表示对齐的提示去纠缠技术在领域泛化的应用 [PDF](https://arxiv.org/pdf/2507.02288), [HTML](https://arxiv.org/abs/2507.02288)
### Authors
De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao
### Background
领域泛化（DG）致力于开发一种通用模型，使其在未见过的目标领域中也能有效运行。近年来，预训练视觉基础模型（VFMs）如CLIP表现出巨大的潜力，能够提升深度学习模型的泛化能力。尽管VFMs已开始用于领域提示调优研究，但如何设计出能够解构跨多种领域的一致性特征的有效提示仍然是一项重要挑战。本文旨在通过利用VFMs的可控与可灵活的语言提示来解决这一挑战，并提出了一种基于文本特征引导的视觉提示调优的新框架。此框架首先利用大型语言模型自动解构文本提示，再通过解构后的文本特征引导学习领域不变的视觉表示。然而，仅依赖语言来指导视觉特征的解构有其局限性，因此本文引入了最坏显式表示对齐（WERA），通过增加一组抽象提示来扩展基于文本的视觉提示，这些抽象提示通过样化图像增强来提升源域多样性，并通过对齐约束确保视觉表示在原始分布和增强分布中保持一致性。
### Innovation
本文提出了一种创新的白盒框架，通过大型语言模型自动解构文本提示，并基于解构后的文本特征学习域不变的视觉表示。此外，为了克服单纯基于语言指导视觉特征分解的局限性，还引入了最坏显式表示对齐（WERA），通过增加抽象提示和图像样式化增强，进一步提高了源域的多样性，同时通过对齐约束确保视觉表示的一致性。
### Conclusion
实验结果表明，本文提出的方法在主要的DG数据集（如PACS、VLCS、Office-Home、DomainNet和TerraInc）上优于当前最先进的DG方法。
## 307. `cs.CV` - 基于YOLOv8n的轻量化对虾疾病检测研究 [PDF](https://arxiv.org/pdf/2507.02354), [HTML](https://arxiv.org/abs/2507.02354)
### Authors
Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao
### Background
对虾养殖业中的疾病是造成经济损失的主要原因之一。为了预防疾病传播并提高智能检测效率，本文提出了一种基于YOLOv8n的轻量化网络架构，旨在通过减少计算复杂度同时保持检测准确性，提高计算效率，从而在对虾养殖中实现更精确的疾病特征识别和智能检测.
### Innovation
本文设计了RLDD检测头和C2f-EMCM模块，实现了在降低计算复杂度的同时保持较高的检测精度，同时引入了改进的SegNext_Attention自注意力机制，增强了模型在特征提取上的能力。实验结果表明，与YOLOv8n相比，提出的模型参数减少了32.3%，mAP@0.5为92.7%，比YOLOv8n提高了3%。此外，该模型在mAP@0.5、参数数量和模型大小方面均优于其他轻量级YOLO系列模型。在URPC2020数据集上的验证实验进一步证明了模型的鲁棒性，其mAP@0.5比YOLOv8n提高了4.1%.
### Conclusion
本文提出了一个在保持高检测精度和鲁棒性的同时具有更高效率的轻量化对虾疾病检测模型，为智能疾病检测在对虾养殖中的应用提供了可靠的技术支持.
## 308. `cs.CV` - 两阶段神经网络在颅内血管关键点检测中的自动化检测 [PDF](https://arxiv.org/pdf/2507.02349), [HTML](https://arxiv.org/abs/2507.02349)
### Authors
Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau
### Background
颅内动脉瘤（ICA）通常发生在Willis环（CoW）的特定段落，主要集中在十三个主要动脉的分叉处。准确检测这些关键位置对于快速、高效的诊断至关重要。因此，本文提出了一种基于两阶段神经网络的Willis环分叉全自动检测方法。初始阶段使用对象检测网络识别接近关键点位置的感兴趣区域（ROIs），随后应用修改后的U-Net并结合深层监督来精确定位分叉点。这种方法克服了由于两个关键点位置接近且视觉特征相似导致的检测遗漏问题，特别是对于完整的MRA时间飞越（TOF）处理。同时，该方法也考虑了Willis环的解剖变异，这会影响每次扫描中可检测到的关键点数量。
### Innovation
提出了一种两阶段的神经网络方法，首先通过对象检测网络识别分叉处的感兴趣区域，然后应用修改后的U-Net结合深层监督来精确定位分叉点。这种方法能够有效处理相邻关键点视觉特征相似导致的检测遗漏问题，特别适用于MRA时间飞越（TOF）处理，并考虑了Willis环的解剖变异影响，提高了检测的准确性和鲁棒性。
### Conclusion
通过使用内部数据集和公共数据集（含不同数量和标准配置的关键点）进行实验评估，本文的方法在分叉点检测任务中表现出最高的性能水平。
## 309. `cs.CV` - LocalDyGS：通过自适应局部隐式特征解耦实现多视图全局动态场景建模 [PDF](https://arxiv.org/pdf/2507.02363), [HTML](https://arxiv.org/abs/2507.02363)
### Authors
Jiahao Wu,Rui Peng,Jianbo Jiao,Jiayu Yang,Luyang Tang,Kaiqiang Xiong,Jie Liang,Jinbo Yan,Runling Liu,Ronggang Wang
### Background
由于现实世界中复杂且高度动态的运动，从多视角输入合成适应任意视角的动态视频是具有挑战性的。现有基于神经辐射场或3D高斯插值的方法仅限于建模细粒度运动，极大地限制了它们的应用范围。通过引入LocalDyGS方法，该方法包含两部分以适应大规模和细粒度运动场景：(1) 将复杂的动态场景分解为由种子定义的优化局部空间，使全局建模能够在每个局部空间内捕获运动；(2) 对局部空间的运动建模解耦静态和动态特征。一类在时间步骤之间共享的静态特征捕捉静态信息，而动态残差场提供特定于时间的特征。这些特征被组合并解码生成时间高斯分布，用于构建每个局部空间内的运动。由此，提出了一种新颖的动态场景重建框架以更真实地建模高度动态的实际场景。
### Innovation
该方法不仅在多种细粒度数据集上展现了与最新技术相比的竞争力，而且是首次尝试建模更大且更复杂的高度动态场景的方法。
### Conclusion
提出了一种新颖的动态场景重建框架，能够更真实地建模高度动态的现实场景，并在多种细粒度数据集上展现了与最新技术相比的竞争力，同时还第一次尝试建模更大且更复杂的高度动态场景。
## 310. `cs.CV` - 基于神经网络的水稻叶片疾病识别和分类研究：特征模型与直接图像模型的比较分析 [PDF](https://arxiv.org/pdf/2507.02322), [HTML](https://arxiv.org/abs/2507.02322)
### Authors
Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi
### Background
水稻叶片疾病严重影响产量并造成经济损失，因此早期检测对于有效管理提高产量至关重要。当前主要采用将水稻叶片图像直接输入神经网络的方法，但缺乏特征分析检测模型（FADM）和直接图像中心检测模型（DICDM）之间的深入比较分析，尤其是在评价特征提取算法（FEA）效果方面。
### Innovation
本研究首次对比分析了FADM和DICDM在分类水稻叶片疾病方面的性能。实验利用了多种图像特征提取算法（FEAs）、维度减少算法（DRAs）、特征选择算法（FSAs）和极端学习机（ELM），并通过10折交叉验证法进行评估，最终展示了FADM的优越性。
### Conclusion
研究结果表明，特征分析检测模型在分类水稻叶片疾病方面取得了最高性能，其应用对于改善农作物健康、减少产量损失和提高稻作生产率和可持续性具有很好的潜力。
## 311. `cs.CV` - 超越空间频率：基于像素级时间频率的深度伪造视频检测 [PDF](https://arxiv.org/pdf/2507.02398), [HTML](https://arxiv.org/abs/2507.02398)
### Authors
Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi
### Background
传统的空间频率检测方法仅通过帧间堆叠空间频率谱来表示时间信息，难以检测像素平面内的时间伪像。这些方法往往忽略了像素级的时间一致性问题，导致无法准确识别深度伪造视频中的时间伪造痕迹。
### Innovation
本文提出了一种基于像素级时间频率的深度伪造视频检测方法。该方法对每个像素沿着时间轴进行一维傅里叶变换，提取出对时间不一致性高度敏感的特征，特别是在易出现不自然运动的区域表现尤为明显。此外，引入了端到端训练的注意力提案模块，以精确定位包含时间伪造痕迹的区域。同时，联合变换模块有效地整合了像素级的时间频率特征和时空上下文特征，扩展了可检测伪造痕迹的范围。
### Conclusion
本文提出的框架在深度伪造视频检测方面取得了重大进展，提供了跨多种复杂检测场景的稳健性能。
## 312. `cs.CV` - UVLM：为水下世界理解评估视频语言模型 [PDF](https://arxiv.org/pdf/2507.02373), [HTML](https://arxiv.org/abs/2507.02373)
### Authors
Xizhe Xue,Yang Zhou,Dawei Yan,Ying Li,Haokui Zhang,Rong Xiao
### Background
近年来，大型语言模型（LLMs）取得了显著的成功，并在人工智能领域产生了深远的影响。在此基础上，许多先进的基于LLMs的工作被提出并应用于各种场景。其中，视频语言模型（VidLMs）尤其广泛使用。然而，现有工作主要集中在陆地场景，忽视了水下观察领域的高度需求。为弥补这一差距，我们提出了UVLM，这是一种结合了人类专业知识和AI模型的合作建立的水下观察基准。为保证数据质量，我们从多个维度进行了深入考虑。首先，为了应对水下环境的独特挑战，我们选择包含光照变化、水体浑浊度和多种视角的视频以构建数据集。其次，通过包含广泛的帧率、分辨率、419类海洋动物、多种静态植物和地形的数据集，以确保数据多样性。接下来，我们采取了一个结构化设计，将观察目标分为两大类：生物类和环境类，每个类别包含内容观察和行为/变化观察，共计20种不同的任务类型。最后，我们设计了几种具有挑战性的评估指标，以实现不同方法的定量比较和分析。在两个代表性VidLMs上的实验表明，对UVLM进行微调显著提高了对水下世界理解的能力，同时也有潜力在现有空中VidLM基准（如VideoMME和Perception Text）上带来微小改进。公布的数据集和提示工程将供公众使用。
### Innovation
我们提出了UVLM，这是一种全新的评估基准，专门针对水下观察场景。该基准通过结合人类专业知识和AI模型构建，并详细考虑了水下环境的独特挑战和多样性。其创新之处在于构建了一个包含多种水下环境和生物类、环境类任务的数据集，并设计了多种挑战性的评估指标，以实现对不同方法的全面比较。
### Conclusion
实验结果显示，在UVLM上进行微调的VidLMs显著提高了对水下世界的理解。此外，UVLM还展示了对现有空气中VidLM基准（如VideoMME和Perception Text）的小幅改进潜力。公布的数据集和提示工程将助力相关研究的进一步发展。
## 313. `cs.CV` - MAGIC：带多级扰动和上下文感知对齐的掩码指导扩散补全，用于少样本异常生成 [PDF](https://arxiv.org/pdf/2507.02314), [HTML](https://arxiv.org/abs/2507.02314)
### Authors
JaeHyuck Choi,MinJun Kim,JeHyeong Hong
### Background
少样本异常生成正在成为一种实用的解决方案，用于在工业质量控制环境中扩充稀缺的异常数据。理想的生成器应同时满足三项要求：（i）保持正常的背景不变；（ii）修补异常区域，使其与提供的异常掩码紧密重合；（iii）在语义有效的位置生成异常区域，同时仅从少量真实样本中产生逼真且多样的外观。现有基于扩散的方法通常只能满足这三项要求中的两项：全局异常生成器会破坏背景，而掩码引导的方法在掩码不精确或位置错误时往往会失败。这些方法无法有效解决所提出的问题。因此，需要一种有效的方法来解决这些问题。
### Innovation
我们提出了一种称为MAGIC（Mask-Guided inpainting with multi-level perturbations and Context-aware alignment）的方法，以解决所有三项问题。MAGIC的核心是通过微调一个稳定的扩散修补骨干网络，保留正常区域并确保合成的异常区域严格遵从提供的掩码，从而解决了背景破坏和对齐问题。为了抵消微调可能导致的多样性损失，MAGIC添加了两种互补的扰动策略：（i）在微调和推理期间应用高斯提示级扰动，使异常的全局外观更广泛，同时避免低保真的文本外观；（ii）掩码引导的空间噪声注入，丰富局部纹理变化。此外，上下文感知掩码对齐模块形成语义对应的重新定位掩码，使每个异常都看似在宿主对象内部，消除了边界外的伪影。这些方法在MVTec-AD数据集上保持一致的评估协议下，MAGIC在下游异常任务中优于之前的最新技术。
### Conclusion
MAGIC方法解决了少样本异常生成中的多种挑战，并展示了在多任务评估中的优势，相比之前的最新技术，MAGIC在下游异常任务中表现出更好的性能。这是通过多级扰动策略和上下文感知对齐模块实现的，确保了异常生成的高保真度和多样性。
## 314. `cs.CV` - 基于 Packing 的隐私保护面部识别预筛选 [PDF](https://arxiv.org/pdf/2507.02414), [HTML](https://arxiv.org/abs/2507.02414)
### Authors
Rundong Xin,Taotao Wang,Jin Wang,Chonghe Zhao,Jing Wang
### Background
由于隐私保护需求的增加以及密文面部数据潜在泄露的风险，针对面部识别系统的密文域操作引起了广泛关注。然而，随着密文面部模板库的增大，面部检索过程变得越来越耗时。为此，需要一种既能保持识别准确率又能在检索时快速高效的新方案。
### Innovation
提出了一种基于 Packing 的隐私保护面部识别预筛选方案 (PFIP)。PFIP 结合了一种创新的预筛选机制来减少计算开销，并在注册阶段加入了一种 Packing 模块以提高生物特征识别系统的灵活性。实验结果表明，PFIP 在检索 1000 个密文面部模板时能够在 300 毫秒内实现 100% 的正确率，比现有方法提高了近 50 倍的检索效率。
### Conclusion
PFIP 保留了原始面部识别模型的准确性，在检索 1000 个密文面部模板时实现了 100% 的准确性，同时检索过程中的计算时间仅为 300 毫秒。相比现有方法，PFIP 使检索效率提高了近 50 倍。
## 315. `cs.CV` - PosDiffAE：高分辨率脑组织分类结合去噪的定位感知扩散自编码器 [PDF](https://arxiv.org/pdf/2507.02405), [HTML](https://arxiv.org/abs/2507.02405)
### Authors
Ayantika Das,Moitreya Chaudhuri,Koushik Bhat,Keerthi Ram,Mihail Bota,Mohanasankar Sivaprakasam
### Background
去噪扩散模型通过逐步捕捉图像分布来生成高保真图像样本，初始时使用简单分布并逐渐增加复杂性。尽管这些模型开启了新的应用场景，但扩散模型的采样机制并不能提取特定于图像的语义表示，这由自编码器提供。自编码器的编码部分能够将特定图像映射到其潜在空间，从而提供对潜在空间结构的显式控制。本文旨在结合编码器与扩散模型，建立一个自编码形式，学习特定图像的表示并提供组织潜在空间的手段。在此基础上，本文首先设计了一种机制，以结构化扩散自编码模型的潜在空间，使识别脑图像中区域特异性细胞模式成为可能。其次，基于自编码器的潜在表示和扩散模型的受限生成能力，在无监督的情况下设计了一种基于邻域意识的眼泪斑纹修复技术。最后，通过表示引导和利用扩散模型在推断期间的可调节噪声和去噪能力，设计了一种无监督的JPEG斑纹修复技术。
### Innovation
本文创新性地将编码器与扩散模型结合，建立了自编码形式，学习特定图像的表示并提供组织潜在空间的手段。同时，设计了两种无监督的图像修复技术：基于邻域意识的眼泪斑纹修复技术和基于表示引导的JPEG斑纹修复技术，这些技术都能直接应用于高分辨率脑组织分类。
### Conclusion
本文研究了结合编码器和扩散模型的自编码形式，用于高分辨率脑组织分类，并开发了两种无监督的图像修复技术，这些技术能够有效地识别并修复脑图像中的多种斑纹，为脑成像研究提供了一种有效的方法。
## 316. `cs.CV` - Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis [PDF](https://arxiv.org/pdf/2507.02395), [HTML](https://arxiv.org/abs/2507.02395)
### Authors
Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun
### Background
多实例学习（MIL）通过使用样本集的单个标签来显著降低大规模图像（如组织病理学全切片图像（WSI））的注释成本。然而，MIL在连续任务中最小遗忘适应性的应用很少被探索，特别是在实例分类和定位方面。虽然对自然图像上的语义分割进行弱增量学习的研究有所进展，但这些方法主要依赖于数百个小补丁（例如16×16）之间的全局关系，这使得直接应用于大规模补丁（例如256×256）的MIL定位不切实际。因此，该研究旨在开发一种新的MIL架构，以解决这些问题，适用于连续的MIL定位任务。
### Innovation
提出了一种新的MIL框架——连续增强定位的多重实例学习（CoMEL），该框架结合了组双注意力变换器（GDAT）、袋原型为基础的伪标签（BPPL）及正交加权低秩适应（OWLoRA），分别提高了实例编码效率、实例伪标签的可靠性以及在袋分类和实例分类中的遗忘抑制。实验结果表明，CoMEL在连续的MIL设置中优于现有技术，目标级精度提高了11.00%，定位精度提高了23.4%。
### Conclusion
通过讨论CoMEL框架的核心组成部分和实验结果，文章证明了CoMEL能够有效地进行连续的MIL定位任务，同时能够最小化遗忘，从而提高了准确性和可靠性。
## 317. `cs.CV` - 使用深度学习框架确定结构裂缝 [PDF](https://arxiv.org/pdf/2507.02416), [HTML](https://arxiv.org/abs/2507.02416)
### Authors
Subhasis Dasgupta,Jaydip Sen,Tuhina Halder
### Background
结构裂缝检测对于公共安全至关重要，因为它有助于预防可能危及生命的安全事故。由缺乏经验的人员进行的手动检测过程缓慢、不一致且容易出现人为错误，这可能影响评估的可靠性。当前研究通过引入一种新的深度学习架构来应对这些挑战，以提高结构裂缝检测的准确性和效率。各种残差U-Net模型配置被用于这项研究，这些模型因其在捕捉细节方面的强大能力，与具有卷积块的元模型集成，以提高预测效率，超过单个模型的性能。该综合模型在低分辨率图像上的性能优于其他已建立的架构和传统U-Net，并且优于独立模型，显示出更高的效率。评估采用了IoU和DICE系数作为指标，综合模型取得了最高分，表明其具有更高的准确性。这表明在结构缺陷监测任务中，自动化系统的可靠性将进一步提高。
### Innovation
引入了一种新的残差U-Net模型配置，集成到带有卷积块的元模型中。这种独特的组合在预测效率上超越了单一模型的性能，特别是在低分辨率图像上表现出优异的效果，并且整体上超越了其他已建立的架构和传统U-Net模型，证明了其在结构裂缝检测中的高效性和准确性。
### Conclusion
该研究通过使用残差U-Net模型和集成策略，实现了结构裂缝检测的高准确性和效率，为建筑结构监测任务中的自动化系统提供了更可靠的选择。
## 318. `cs.CV` - 一种利用复杂运动模式的热传感器实时多对象追踪新颖调优方法 [PDF](https://arxiv.org/pdf/2507.02408), [HTML](https://arxiv.org/abs/2507.02408)
### Authors
Duong Nguyen-Ngoc Tran,Long Hoang Pham,Chi Dai Tran,Quoc Pham-Nam Ho,Huy-Hung Nguyen,Jae Wook Jeon
### Background
热红外图像在复杂环境中（低光照条件或低能见度）进行目标跟踪具有重要作用，特别是对于监视系统。热传感器能够捕捉红外特征，但其低级别的特征表示使得行人检测和跟踪变得困难。现有的多对象跟踪算法在处理复杂热红外图像的运动模式时性能不佳，尤其是在实时应用中。因此，需要一种新的调优方法来增强热红外图像中的多对象跟踪性能，特别是在具有复杂运动模式的场景下。
### Innovation
提出了一个新颖的调优方法，用于热传感器进行实时多对象跟踪。该方法针对复杂运动模式进行优化，并通过两个阶段细化超参数调优，实现精确的多对象跟踪，而不依赖于复杂的重建识别或运动模型。这种方法在PBVS 热红外MOT数据集上进行了广泛的实验验证，证明了其在多种热摄像条件下具有很高的有效性，是实时监视应用中的稳健解决方案。
### Conclusion
本文提出的方法通过精细调整超参数来优化热红外图像中多对象跟踪的两个阶段，实现了高精度的实时多对象跟踪，无需依赖复杂的重建识别或运动模型。实验结果表明，该方法在各种热红外摄像条件下具有高度有效性，能够满足实际监视应用的需求。
## 319. `cs.CV` - PLOT: 通过视频对象跟踪进行可扩展的一目了单调空体检测的伪标签方法 [PDF](https://arxiv.org/pdf/2507.02393), [HTML](https://arxiv.org/abs/2507.02393)
### Authors
Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho
### Background
一目了单调空体检测（M3OD）长期以来一直受到由于高标注成本和固有的2D到3D的模糊性导致的数据稀缺性的挑战。尽管已经提出了多种弱监督方法和伪标签方法来解决这些问题，但它们大多局限于特定领域的学习，或者仅仅是依赖单一观察的形状信息。现有的方法大多需要多视角设置、额外的传感器、相机姿态或特定领域的训练。这些问题使得在获取3D数据不可行的情况下进行3D属性提取变得非常困难，尤其是面对遮挡情况时表现不佳。
### Innovation
本论文提出了一种新型的伪标签框架，仅依赖视频数据即可实现对静态和动态物体的伪LiDAR聚合，这种方法能够更好地应对遮挡情况，并在无需多视角设置、额外传感器、相机姿态或特定领域训练的情况下进行3D属性提取。具体来说，该框架通过对象点追踪技巧，在相邻帧之间汇集伪LiDAR数据，从而在3D数据获取不可行的场景中进行3D属性提取。这种方法在扩展性和鲁棒性方面表现出色，能够提供可靠且有效的精度，使其成为解决M3OD问题的实用方案。
### Conclusion
本研究提出的PLOT方法在稳健性和扩展性方面表现出了卓越的性能，能够保证可靠的精度，有效满足M3OD场景的需求，对于解决一目了单调空体检测中的遮挡问题提供了新的思路，并提供了一种实用且有效的解决方案。
## 320. `cs.CV` - TABNet: 一种基于三重增强自我恢复框架与边界感知伪标签的医学图像分割方法 [PDF](https://arxiv.org/pdf/2507.02399), [HTML](https://arxiv.org/abs/2507.02399)
### Authors
Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang
### Background
医学图像分割是多项临床应用的核心任务，但获取大规模、全面注释的医学图像数据集既耗时又昂贵。尽管有研究表明，注释形式的稀疏标记（scribble annotations）可以作为一种高效且经济的替代方案，但这些稀疏标记的特点限制了目标区域特征的学习，并且缺乏足够的边界监督，从而在训练分割网络时带来了显著挑战。
### Innovation
我们提出了一种新颖的弱监督医学图像分割框架——TAB Net，包括两个核心组件：三重增强自我恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过三种互补的增强策略来增强特征学习：强度变换提高模型对纹理和对比度变化的敏感性，剪切遮挡强迫网络通过遮盖关键区域捕捉局部解剖结构，混乱增强则通过扰乱空间连续性强化整体解剖布局的建模。通过引导网络从多种增强输入中恢复完整掩码，TAS促进了在稀疏监督下的医学图像语义理解。BAP模块通过将双分支预测融合为加权伪标签并引入边界感知损失，提高伪监督精度和边界建模的细粒度轮廓细化。
### Conclusion
在ACDC和MSCMR seg两个公开数据集的实验评估表明，TAB Net在基于稀疏注释的弱监督分割方面显著优于现有的最先进的方法，并且其性能与完全监督的方法相当。
## 321. `cs.CV` - 在非城市环境中使用自我监督学习进行野生动物目标再识别 [PDF](https://arxiv.org/pdf/2507.02403), [HTML](https://arxiv.org/abs/2507.02403)
### Authors
Mufhumudzi Muthivhi,Terence L. van Zyl
### Background
野生动物再识别的目标是跨越不同观察点匹配同一种类的个体。当前最先进的（SOTA）模型依赖于类标签来训练监督模型以进行个体分类。这种对标注数据的依赖导致了大量的大规模野生动物数据集的创建。这项研究调查了自我监督学习（SSL）在野生动物再识别中的应用。研究人员通过无监督的方式从相机陷阱数据中自动提取个体的两个不同视角，并通过图像对训练自我监督模型。该模型可以在潜在无限的视频数据流中训练，对开放世界场景和各类野生动物下游任务中的监督特征进行评估，并展示出自我监督模型即使在有限数据下也更具鲁棒性，且自我监督特征在所有下游任务中均表现优于监督特征。
### Innovation
本研究创新性地提出了一种使用自我监督学习来训练野生动物再识别模型的方法。该方法无需标签数据，直接从相机陷阱数据中提取图像对进行训练，同时在开放世界场景和多种野生动物任务中展示了自我监督模型和特征的有效性和优势。
### Conclusion
自我监督学习模型即使在有限数据下也更为稳健，且在各类野生动物相关的下游任务中，自我监督特征均优于监督特征。研究结果表明，自我监督学习在野生动物识别中的应用前景广阔。
## 322. `cs.CV` - 在FPGA可编程逻辑中加速葡萄检测的人工神经网络 [PDF](https://arxiv.org/pdf/2507.02443), [HTML](https://arxiv.org/abs/2507.02443)
### Authors
Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias
### Background
通常，机器人在搬运过程中会放慢速度以检测对象，并且机器人的摄像头配置为低帧率以跟踪检测算法的速度。这在执行任务和探索时会受到限制，导致机器人增加任务执行时间。芬威克（FINN）架构被用来在FPGA的逻辑阵列（PL）中部署三个ANN，但当前工具并没有充分利用FPGA的PL资源。
### Innovation
本研究使用芬威克（FINN）架构在FPGA的PL中部署了三种不同的ANN：使用4位量化后的MobileNet v1，使用2位量化后的CNV，以及使用1位量化（BNN）的CNV。这些模型在RG2C数据集上进行了训练，这是一个自收购并公开发布的数据集。MobileNet v1的性能最佳，达到了98%的成功率和6611 FPS的推理速度。研究表明，我们可以使用FPGA来加速ANN，并使其适用于注意力机制。
### Conclusion
我们证明了可以在FPGA的PL中加速和优化ANN，从而使它们更适合用于注意力机制，降低了机器人执行任务和探索过程中的时间成本。
## 323. `cs.CV` - Holistic Tokenizer for Autoregressive Image Generation [PDF](https://arxiv.org/pdf/2507.02358), [HTML](https://arxiv.org/abs/2507.02358)
### Authors
Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi
### Background
现有的自动化回归图像生成模型按步骤生成视觉标记，这限制了捕捉标记序列之间全局关系的能力。大多数视觉标记器将局部图像斑块映射到潜在的标记，这限制了全局信息的捕获。为了克服这些限制，该研究提出了一种名为Hita的新型图像标记器，用于自动化回归（AR）图像生成。Hita采用全局到局部的标记方案，并结合了全局查询和局部斑块标记。Hita通过两个关键策略改进了与AR生成过程的对齐：首先，在生成过程中将全局标记放在局部标记之前，并使用因果注意力保持对先前标记的意识；其次，在将去量化标记输入解码器之前，Hita采用了一个轻量级融合模块，控制信息流以优先处理全局标记。 extensive experiments have demonstrated that Hita can accelerate the training of AR generators and outperform those trained with traditional tokenizers on the ImageNet benchmark, achieving a FID score of 2.59 and an IS score of 281.9.
### Innovation
1. 引入了全局到局部的标记方案，采用可学习的全局查询和局部斑块标记。2. 设计了一种序列结构，全局标记在局部标记之前，使用因果注意力保持对先前标记的意识。3. 引入了轻量级融合模块，在将去量化标记输入解码器之前控制信息流，优先处理全局标记，提高标记与AR生成过程的一致性。4. 在ImageNet基准测试上，Hita的FID分数为2.59，IS分数为281.9，优于传统标记器训练的AR生成器，加速了训练过程，展示了其高效性。这为图像生成提供了一种新的方法，特别是对于捕捉全局图像特性（如纹理、材料、形状）以及实现零样本风格迁移和图像修复等方面展现出有效性。
### Conclusion
实验结果表明，Hita加速了AR生成器的训练过程，并在ImageNet基准测试中超越了使用传统标记器训练的生成器，分别实现了2.59的FID分数和281.9的IS分数。该研究不仅高效率地捕捉了全局图像特性，还在零样本风格迁移和图像修补中展示了其有效性。
## 324. `cs.CV` - IGDNet：基于照明引导和去噪的零样本鲁棒欠曝光图像增强 [PDF](https://arxiv.org/pdf/2507.02445), [HTML](https://arxiv.org/abs/2507.02445)
### Authors
Hailong Yan,Junjian Huang,Tingwen Huang
### Background
当前恢复欠曝光图像的方法通常依赖于有监督学习，要求配对的欠曝光和正常光照图像。然而，在实际场景中收集这样的数据集往往是不现实的。此外，这些方法可能会导致过度增强，使得正常光照区域出现失真。鉴于这些局限性，本文提出了一种名为IGDNet的零样本增强方法，该方法只需一张测试图像即可运行，无需指导先验或训练数据。IGDNet表现出较强的泛化能力，在恢复光照的同时有效抑制噪声。
### Innovation
本文提出了IGDNet，这是一种零样本增强方法，无需配对数据集和指导先验，仅通过单张测试图像即可运行。框架包括一个分解模块和一个去噪模块。分解模块通过密集连接网络将图像分解为照明和反射分量，去噪模块则使用照明引导的像素自适应校正方法增强非均匀光照区域。通过迭代下采样和细化生成噪声对，以此生产最终结果。实验结果表明，IGDNet在多种公共数据集上表现优异，在复杂光照条件下显著提升视觉质量，并在PSNR和SSIM等指标上优于14种最先进的无监督方法。
### Conclusion
研究结果表明，IGDNet在复杂光照条件下显著提高了视觉质量，并且在定量指标如PSNR（20.41dB）和SSIM（0.860dB）上优于14种最先进的无监督方法。代码将在不久后公开。
## 325. `cs.CV` - Mesh Silksong：以蚕丝编织为灵感的自回归网格生成 [PDF](https://arxiv.org/pdf/2507.02477), [HTML](https://arxiv.org/abs/2507.02477)
### Authors
Gaochao Song,Zibo Zhao,Haohan Weng,Jingbo Zeng,Rongfei Jia,Shenghua Gao
### Background
现有的网格表征方法在生成网格时会产生重复的顶点标记序列，浪费了网络的效能。针对这一问题，Mesh Silksong通过一次性访问每个网格顶点来标记网格顶点，减少了标记序列的冗余，并实现了约22%的最先进的压缩率。此外，Mesh Silksong生成的网格具有优异的几何特性，包括曼ifold拓扑、无泄漏检测和一致性法向，这对实际应用至关重要。实验结果显示，与现有方法相比，该方法具有更好的效果，不仅能够生成复杂网格，还能显著提高几何完整性。
### Innovation
Mesh Silksong通过仅访问每个网格顶点一次的方法标记顶点，相比现有方法减少了标记序列的50%冗余，实现了约22%的最先进的压缩率。生成的网格具有包括曼ifold拓扑、无泄漏检测和一致性法向在内的优异几何属性，适用于实际应用场景。该方法极大地提高了网格生成的有效性和几何完整性
### Conclusion
实验结果证实了该方法的有效性，不仅能生成复杂网格，还能够显著提高网格的几何完整性。
## 326. `cs.CV` - AvatarMakeup: 3D可动画头 avatar 的现实妆容转移 [PDF](https://arxiv.org/pdf/2507.02419), [HTML](https://arxiv.org/abs/2507.02419)
### Authors
Yiming Zhong,Xiaolin Zhang,Ligang Liu,Yao Zhao,Yunchao Wei
### Background
在现实生活中，个性化的面部美化是很常见的需求，但在3D虚拟头像领域，这样的个性化定制仍然不足。虽然目前的3D高斯编辑方法可以应用于面部化妆，但这些方法在实现真实妆容效果方面存在不足，无法满足以下三个基本要求：确保可驱动表情时外观一致，保留身份感直至完成整个化妆过程，具备对细微细节的精确控制能力。本文旨在解决上述问题及其带来的挑战，提出了一种名为AvatarMakeup的特殊3D化妆方法。
### Innovation
本文提出了一种名为AvatarMakeup的方法，利用预训练的扩散模型从任何个人的单张参考照片中转移化妆图样，采用粗细处理方案首先保持妆容的一致性和个体身份，后精修细节。具体来说，扩散模型用于生成化妆图作为监督指导。由于扩散过程中的不确定因素，生成的图象在不同视角和表情下不一致，因此提出了同步复制方法，以保持动态和多视角效果的一致性。此外，通过集成修整模块进一步提升了化装质量，实验结果表明AvatarMakeup在化妆转移质量和一致性方面达到了最先进的水平。
### Conclusion
实验结果显示，AvatarMakeup在化妆转移质量和一致性方面达到了最先进的水平。该方法能够确保在各种表情驱动下外观一致，保留身份感，并允许对细微细节进行精确定位。通过这种技术，用户可以更轻松地创建个性化和逼真的3D虚拟头像。
## 327. `cs.CV` - 在结肠镜检查中具有时间意识的监督对比学习用于息肉计数 [PDF](https://arxiv.org/pdf/2507.02493), [HTML](https://arxiv.org/abs/2507.02493)
### Authors
Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi
### Background
自动化结肠镜检查中的息肉计数是推进自动检查报告并提高结肠镜筛查成本效益的关键步骤。现有的息肉计数方法主要依赖于自我监督学习，并侧重于视觉外观，忽视了在检测、跟踪和聚类阶段的时序关系。因此，该文旨在通过提出具有时序意识的监督对比损失来改变现有范式，以增强聚类的稳健性，并减少视觉相似但时序上远的跟踪片段之间的误关联。
### Innovation
本文提出了一种监督对比损失，结合了具有时序意识的软目标，可以捕捉到同一个息肉之间的变异性和不同息肉之间的区分性。同时，引入了时间相邻约束来改进跟踪片段的聚类，从而降低了误关联率。实验结果显示出比之前方法更少的碎片化率，确立了新的最佳状态。
### Conclusion
本研究强调了时序意识在息肉计数中的重要性，并通过公开数据集进行训练和验证，实验结果表明该方法能显著降低误分率。该研究成果提供了新的基准线，并证明了时间意识特征对提高息肉计数准确性的显著作用。
## 328. `cs.CV` - F^2TTA：通过图像级解耦提示调优实现跨域医学图像分类的自由形式测试时适配 [PDF](https://arxiv.org/pdf/2507.02437), [HTML](https://arxiv.org/abs/2507.02437)
### Authors
Wei Li,Jingyang Zhang,Lihao Liu,Guoan Wang,Junjun He,Yang Chen,Lixu Gu
### Background
当前，测试时适应（TTA）方法被视作采用未标注测试数据在高数据注释成本下，将源模型适应未见过的医疗领域的有前途的解决方案。现有的TTA方法集中在单一或多个领域数据完整到达的情况。然而，在临床实践中，数据通常以任意长度的域碎片形式并以随机顺序到达，由于资源限制和患者变异性。因此，本文探讨了一个实际的自由形式领域碎片（Free-Form Test-Time Adaptation，F^2TTA）任务，即在数据以自由形式领域碎片的形式到来时，避免领域之间预想不到的转换扰动对源模型进行适应。为此，提出了一个新颖的图像级解耦提示调优（Image-level Disentangled Prompt Tuning，I-DiPT）框架。I-DiPT框架包括两个部分：1）图像不变的提示，用于探索领域不变表征以减轻不稳定的域转换扰动；2）图像特定的提示，用于适应源模型来适应每个测试图像。然而，单一图像提供的训练知识可能不足。为了解决这一局限性，引入了不确定性导向的掩码（Uncertainty-oriented Masking，UoM）方法，通过基于源模型表示不确定性的掩码一致性学习鼓励提示从接收到的图像中提取充分信息。进一步，提出了平行图蒸馏（Parallel Graph Distillation，PGD）方法，通过平行图网络重用历史图像特定和图像不变提示的知识。这项研究在乳腺癌和青光眼分类上的实验表明了我们的方法相较于现有TTA方案在F^2TTA任务上的优越性。代码可从文中提供的网址获取。
### Innovation
提出了一种新颖的图像级解耦提示调优（I-DiPT）框架来解决自由形式领域碎片在测试时适应中的问题。I-DiPT包括图像不变的提示和图像特定的提示。为了解决单一图像训练知识不足的问题，提出了一种不确定性导向的掩码（UoM）方法，并进一步引入了平行图蒸馏（PGD）方法，通过重用历史知识来提高模型适应性。
### Conclusion
实验结果表明，我们的方法在自由形式测试时适应（F^2TTA）任务上优于现有的TTA方法。我们的研究表明，I-DiPT框架能有效应对自由形式领域碎片带来的不稳定的转换扰动。
## 329. `cs.CV` - 基于数量提示的弱监督对比学习方法在移动红外小目标检测中的应用 [PDF](https://arxiv.org/pdf/2507.02454), [HTML](https://arxiv.org/abs/2507.02454)
### Authors
Weiwei Duan,Luping Ji,Shengjia Chen,Sicheng Zhu,Jianghong Huang,Mao Ye
### Background
移动红外小目标检测面临巨大的挑战，由于小目标尺寸以及背景较弱。目前大多数方法都是完全监督的，依赖大量的手动目标级注释，这往往是昂贵且耗时的，尤其是在低质量的红外帧图像中更为明显。受一般目标检测的启发，非完全监督策略被认为可以减少注释需求。因此，本文提出了一个新的弱监督对比学习（WeCoL）方案，提出了基于预训练的SAM模型设计潜在目标挖掘策略，并采用了对比学习进一步改进伪标签的可靠性，引入了长短期运动感知学习方案以同时建模小目标的局部运动模式和全局运动轨迹。
### Innovation
提出了一种弱监督对比学习（WeCoL）方案，仅需要模型简单的目标数量提示，设计了基于预训练SAM模型的目标挖掘策略，结合目标激活图和多帧能量，采用了对比学习计算正负样本在特征空间的相似度，并提出了长短期运动感知学习方案以同时建模小目标的局部和全局运动模式。
### Conclusion
在DAUB和ITSDT-15K两个公开数据集上的广泛实验验证表明，弱监督方案通常可以超越早期完全监督方法，其性能甚至可以达到当前最先进的完全监督方法的90%以上。
## 330. `cs.CV` - MedFormer: 基于内容感知双重稀疏选择注意的分层医学视觉变换器 [PDF](https://arxiv.org/pdf/2507.02488), [HTML](https://arxiv.org/abs/2507.02488)
### Authors
Zunhui Xia,Hongxing Li,Libin Lan
### Background
医学图像识别是临床诊断的关键辅助手段，有助于更准确、及时地识别疾病和异常。基于视觉变换器的方法在处理各种医学识别任务方面证明非常有效。然而，这些方法面临两个主要挑战：一是任务特定且架构定制化，限制了其通用性；二是这些方法要么采用全注意力机制来建模长程依赖性，导致高计算成本，要么依赖手工设计的稀疏注意力机制，可能导致性能不佳。
### Innovation
我们提出了MedFormer，一个高效的医学视觉变换器，具有两种关键想法。首先，MedFormer采用分层结构作为适用于各种医学图像识别任务（包括图像分类和密集预测任务如语义分割和病灶检测）的通用基础架构。这种结构有助于层级特征表示并减少特征图的计算负担，有助于提高性能。其次，引入了一种新的内容感知双重稀疏选择注意（DSSA），以提高计算效率和对噪声的鲁棒性，同时保持高性能。理论分析表明，MedFormer在通用性和效率方面优于现有的医学视觉变换器。实验表明，MedFormer在多种成像模态数据集上的各种医学图像识别任务中表现出色，提高性能。代码可以在提供的链接中获得。
### Conclusion
MedFormer通过分层结构和内容感知双重稀疏选择注意机制，在医学图像识别任务中表现出卓越的性能和通用性，且计算效率高，对噪声具有鲁棒性。
## 331. `cs.CV` - 使用深度学习检测多种作物的多种疾病 [PDF](https://arxiv.org/pdf/2507.02517), [HTML](https://arxiv.org/abs/2507.02517)
### Authors
Vivek Yadav,Anugrah Jain
### Background
印度作为一个以农业为主的经济体，面临着农业方面的重要挑战，包括因病害、虫害和环境压力造成的大量作物损失。早期检测和准确识别不同作物的病害对于提高产量和确保粮食安全至关重要。本文提出了一种基于深度学习的解决方案，旨在覆盖印度多样的农业景观。通过整合来自不同可用数据源的17种不同作物和34种不同病害的图像数据集，我们训练了一个深度学习模型，该模型在准确性和涵盖的作物种类及病害类型上都超越了现有最好的技术。我们实现了99%的检测准确率，比仅处理14种作物和26种不同病害的现有技术高7个百分点。通过提高检测的作物种类和病害类型数量，本文提出的方法旨在为印度农民提供更好的产品。
### Innovation
提出了一种基于深度学习的检测方法，该方法整合了17种不同作物和34种不同病害的图像数据集，并训练了一个深度学习模型。该模型在准确性和涵盖的作物种类及病害类型上都超越了现有最好的技术。尤其是，在处理的数据量和种类上显著提高，实现了99%的检测准确率，比处理更少作物种类和病害类型的现有技术高7个百分点。
### Conclusion
通过提出使用深度学习的方法，解决了多作物和多病害的检测问题，实现了更高的准确性和覆盖面，旨在为印度农民提供更好的作物病害检测解决方案。
## 332. `cs.CV` - MC-INR：使用元学习和集群隐式神经表示高效编码多元科学模拟数据 [PDF](https://arxiv.org/pdf/2507.02494), [HTML](https://arxiv.org/abs/2507.02494)
### Authors
Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong
### Background
隐式神经表示（INRs）被广泛用于以连续函数的形式编码数据，从而能够用较低的内存使用量可视化大规模的多元科学模拟数据。然而，现有的基于INR的方法面临三大限制：（1）对复杂结构的表示不够灵活，（2）主要关注单变量数据，（3）依赖于结构化网格。因此，在应用于复杂的现实世界数据集时，它们的性能会下降。
### Innovation
为了解决这些限制，本文提出了一种新颖的基于神经网络的框架MC-INR，该框架能够处理无结构网格上的多元数据，并结合元学习和聚类，实现对复杂结构的灵活编码。我们还提出了一种基于残差的动态重新聚类机制，该机制会根据局部误差自动划分聚类。此外，我们还提出了分支层，以同时利用多变量数据并通过独立分支进行有效处理。实验结果表明，MC-INR在这类科学数据编码任务中优于现有方法，具有更高的性能。
### Conclusion
MC-INR框架在科学数据编码任务中展现了优越的表现，超越了现有的方法，能够高效地处理多元科学模拟数据，并对复杂结构具有更强的表示能力。
## 333. `cs.CV` - 自动低光照条件下的行人标注 [PDF](https://arxiv.org/pdf/2507.02513), [HTML](https://arxiv.org/abs/2507.02513)
### Authors
Dimitrios Bouzoulas,Eerik Alamikkotervo,Risto Ojala
### Background
行人检测在自动驾驶车辆和高级驾驶辅助系统中至关重要，因为最常见的传感器是RGB相机。然而，低光照条件下的RGB行人检测面临挑战，缺乏大的公开数据集。此研究旨在解决这一问题，提出了一个自动红外-RGB标注管道，以改善低光照条件下的行人检测性能。
### Innovation
研究提出了一种自动红外-RGB标注管道，包含三个主要步骤：红外检测、标签迁移过程以及使用生成的标签训练目标检测模型。与使用真实标筘认为基准，采用自动生成的标签进行训练的目标检测模型在6个案例中的mAP@50和mAP@50-95指标上表现更优。
### Conclusion
研究使用了KAIST数据集，并通过自动生成的标签和真实标签训练了目标检测模型，结果显示自动生成标签训练的模型在多个指标上优于传统的真实标签训练的模型。此研究的源代码可参见提供的链接。
## 334. `cs.CV` - MoGe-2：具有度量尺度和清晰细节的单目几何 [PDF](https://arxiv.org/pdf/2507.02546), [HTML](https://arxiv.org/abs/2507.02546)
### Authors
Ruicheng Wang,Sicheng Xu,Yue Dong,Yu Deng,Jianfeng Xiang,Zelong Lv,Guangzhong Sun,Xin Tong,Jiaolong Yang
### Background
现有的单目几何估计方法可以预测不变仿射点图，但缺乏度量尺度和详细的几何细节。作者在此背景下提出了MoGe-2，旨在克服这些限制，提供更准确的相对几何精度，精确的度量尺度，以及细粒度的几何恢复能力。
### Innovation
MoGe-2是一个先进的开放领域几何估计模型，它可以从单张图像中恢复场景的度量比例3D点图。该方法在现有的单目几何估计方法MoGe的基础上进行了改进，探索了有效策略以在保持仿射不变点表示的相对几何精度的同时进行度量几何预测。此外，作者开发了一种统一的数据精炼方法，通过使用锐利的合成标签过滤和补全来自不同数据源的真实数据，从而显著增强了重建几何的细节粒度，同时保持整体精度。
### Conclusion
通过在多种混合数据集上训练MoGe-2，并进行全面评估，结果显示该模型在实现准确的相对几何、精确的度量尺度以及细粒度几何恢复等方面具有优越性能，这些能力是之前方法所未同时实现的。
## 335. `cs.CV` - IMASHRIMP: 使用计算机视觉和深度学习从实验室图像自动分析白对虾（Penaeus vannamei）形态学 [PDF](https://arxiv.org/pdf/2507.02519), [HTML](https://arxiv.org/abs/2507.02519)
### Authors
Abiam Remache González,Meriem Chagour,Timon Bijan Rüth,Raúl Trapiella Cañedo,Marina Martínez Soler,Álvaro Lorenzo Felipe,Hyun-Suk Shin,María-Jesús Zamorano Serrano,Ricardo Torres,Juan-Antonio Castillo Parra,Eduardo Reyes Abad,Miguel-Ángel Ferrer Ballester,Juan-Manuel Afonso López,Francisco-Mario Hernández Tejera,Adrian Penate-Sanchez
### Background
当前，白对虾（Penaeus vannamei）的形态学分析依赖于人工操作，这不仅效率低下，还容易出错。传统的方法主要集中于利用深度学习和计算机视觉技术来改进这一过程，但需要针对特定的挑战进行修改，例如处理RGBD图像中的虾形态分析。该研究旨在开发一种自动化工具，以优化水产养殖中遗传选择任务的效率，减少人工错误，提高准确性。
### Innovation
该研究提出了IMASHRIMP系统，这是为白对虾的形态学分析而修改的系统。该系统采用了经过修改的ResNet-50架构的两个区分模块，用于根据视角分类图像以及判断颚的完整性。此外，它还集成了一个人类和人工智能双重认证系统，有效降低了分类错误率，并改进了关键点预测模块，使得再现性更高，同时引入了形态回归模块，使用支持向量机模型将像素测量转换为厘米单位。实验结果显示，IMASHRIMP在姿态估计和像素到厘米的转换方面表现出色，极大地提高了自动化和效率，降低了人为错误，增强了基因选择的效率，有助于水产养殖的可持续发展。
### Conclusion
IMASHRIMP展示了在科学生物学领域中自动化处理和加速白对虾形态学分析的巨大潜力，对于提高水产养殖可持续性和基因选择的效果具有重要意义。
## 336. `cs.CV` - CrowdTrack: 实景中多人跟踪的基准 [PDF](https://arxiv.org/pdf/2507.02479), [HTML](https://arxiv.org/abs/2507.02479)
### Authors
Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue
### Background
多对象跟踪是计算机视觉的经典领域。尤其是行人跟踪具有极高的应用价值，已成为最热门的研究类别。现有方法主要依赖于运动或外观信息进行跟踪，但在复杂场景中往往面临挑战。在运动信息方面，物体之间的相互遮挡难以更新运动状态；在外观信息方面，由于部分可见性或图像模糊等原因，结果缺乏鲁棒性。虽然从标注数据中学习如何在这些情境下进行跟踪是最直观的解决方案，但现有多人跟踪数据集无法满足这一需求。现有方法主要存在两大缺陷：场景组成相对简单且场景不具现实性。尽管一些现有数据集的视频序列没有上述缺陷，但数量远不足以满足研究需求。因此，我们提出了一套以第一视角拍摄、全部取自现实复杂场景的困难大型数据集，用于多人跟踪，命名为'CrowdTrack'，因为大多数序列中都包含众多对象。该数据集包含33个视频，共5,185条轨迹。每个对象都配有完整边框和唯一的对象ID。数据集将提供一个平台，促进算法在复杂情况下的持续有效性开发。我们全面分析了数据集并测试了多个先进模型的性能，并分析了基础模型在我们数据集上的表现。数据集及项目代码已发布。
### Innovation
我们提出了CrowdTrack数据集，主要特征是从第一人称视角拍摄，全部取自现实复杂场景的大型数据集，解决现有数据集存在的场景组成简单和场景不具现实性的缺陷，为有效地进行复杂情况下的多行人跟踪提供更真实的场景训练数据。同时，该数据集还进行了全面分析，测试了多个先进模型，并分析了基础模型在新数据集上的表现，以验证其实用性。数据集已公开发布，具有一定的创新性和实用性，能够推动复杂场景下行人跟踪算法的发展和改进。
### Conclusion
CrowdTrack数据集为解决复杂场景下多人跟踪提供了真实且全面的数据支持，为相关算法的开发提供了更优的平台。数据集的公开发布不仅促进了行人跟踪领域的发展，也为研究复杂场景下的多人跟踪提供了必要的数据资源。我们期待CrowdTrack能在未来的研究中发挥重要作用。
## 337. `cs.CV` - AIGI-Holmes: 通过多模态大型语言模型朝着可解释和可泛化的AI生成图像检测 [PDF](https://arxiv.org/pdf/2507.02664), [HTML](https://arxiv.org/abs/2507.02664)
### Authors
Ziyin Zhou,Yunpeng Luo,Yuanchen Wu,Ke Sun,Jiayi Ji,Ke Yan,Shouhong Ding,Xiaoshuai Sun,Yunsheng Wu,Rongrong Ji
### Background
随着AI生成内容（AIGC）技术的迅速发展，高度真实的AI生成图像（AIGI）被滥用于传播虚假信息，这构成了对公共信息安全的威胁。尽管现有的AIGI检测技术通常有效，但它们面临人机可验证解释缺失和最新技术泛化不足的问题。
### Innovation
本文介绍了一个大规模和综合性的数据集——Holmes-Set，其中包括具有解释的指令调整数据集Holmes-SFTSet和人对齐的偏好数据集Holmes-DPOSet。基于此，我们提出了一种高效的多专家陪审团数据注释方法，并提出了一种精心设计的三阶段训练框架——Holmes Pipeline。该框架利用多模态大型语言模型对AIGI进行检测，同时产生可验证且人对齐的解释，并在推理阶段引入了一种协作解码策略，进一步提高了模型的泛化能力。
### Conclusion
在三个基准数据集上的广泛实验验证了我们的AIGI-Holmes模型的有效性。
## 338. `cs.CV` - 基于外观和近距推理的亲密人类互动重新构建 [PDF](https://arxiv.org/pdf/2507.02565), [HTML](https://arxiv.org/abs/2507.02565)
### Authors
Buzhen Huang,Chen Li,Chongyang Xu,Dongyue Lu,Jinnan Chen,Yangang Wang,Gim Hee Lee
### Background
现有的人体姿态估计方法由于视觉歧义和人与人之间的遮挡，在野外视频中无法恢复合理的亲密互动。即使是最先进的大型基础模型也无法在这些具有挑战性的场景中准确区分人类的语义。研究发现，人体外观可以提供一种简单的线索来解决这些障碍。基于此，本文提出了一种双分支优化框架，通过受人体外观、社交距离和物理定律约束的人体互动重建准确的运动。
### Innovation
本文提出了一种基于双分支优化框架的方法，结合了扩散模型学到的人体社交行为和姿态先验知识，以及两个可优化的张量共同重建人体姿态和外观。设计了基于3D高斯、2D关键点和网格穿透的多种约束来辅助优化。利用这些先验和多样化的约束，方法能够估计野外复杂环境下的准确互动。此外，构建了一个带有伪地面真值互动注释的数据集，可以促进未来的姿态估计和人类行为理解研究。实验结果表明，本文方法在多个基准上超越了现有的方法。
### Conclusion
通过双分支优化框架结合人体外观和社交距离的先验知识，本文提出的方法能够准确估计复杂环境下的亲密互动，并且在多个基准测试中表现优于现有方法。
## 339. `cs.CV` - 3D医疗图像结构感知语义差异与一致性自监督学习 [PDF](https://arxiv.org/pdf/2507.02581), [HTML](https://arxiv.org/abs/2507.02581)
### Authors
Tan Pan,Zhaorui Tan,Kaiyu Guo,Dongli Xu,Weidi Xu,Chen Jiang,Xin Guo,Yuan Qi,Yuan Cheng
### Background
3D医疗图像自监督学习(mSSL)在医疗分析中前景广阔，但有效支持更广泛的应用需要考虑位置、尺度和形态学上的解剖结构变异，这对于捕捉有意义的区别至关重要。然而，以往的mSSL方法使用固定大小的补丁分割图像，通常忽略了结构变异。
### Innovation
本文提出了一种新颖的3D医疗图像视角，旨在学习结构感知表示。假设同一结构内的补丁具有相同的语义（语义一致性），而来自不同结构的补丁具有不同的语义（语义差异）。基于这一假设，提出了名为$S^2DC$的mSSL框架，通过两步实现结构感知语义差异和一致性：第一，$S^2DC$利用最佳运输策略使不同补丁具有不同的表示，增加语义差异；第二，基于邻域相似性分布，$S^2DC$在结构级别上增强语义一致性。通过弥补补丁级和结构级表示，$S^2DC$实现了结构感知的表示。该方法已在10个数据集、4个任务和3个模态中进行了全面评估，结果表明该方法在mSSL中始终优于现有方法。
### Conclusion
本文提出的方法在多种条件下（10个数据集、4个任务和3个模态）均表现出色，显著提高了结构感知语义自监督学习的效果，特别是在临摹任务、分类任务和分割任务上。
## 340. `cs.CV` - 解决基于视觉导航的相机传感器故障：仿真与数据集开发 [PDF](https://arxiv.org/pdf/2507.02602), [HTML](https://arxiv.org/abs/2507.02602)
### Authors
Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill
### Background
空间任务中基于视觉导航（VBN）算法的重要性不断增加，确保其可靠性和操作稳健性提出了众多挑战。传感器故障可能导致导航算法输出不准确或完全的数据处理故障，进而影响任务目标。近年来，人工智能（AI）为检测此类故障提供了有力解决方案，但其广泛应用的主要障碍在于缺乏足够的和具有代表性的包含故障图像数据集。本文通过聚焦于星际探测任务场景，阐述了相机传感器在VBN管道中可能存在的故障情况，并系统地分析了这些故障的原因和影响，以及常用缓解策略。为此，本文引入了一个仿真框架，用于在合成生成的图像中重现故障条件，从而系统性地和可控地生成故障数据，该故障注入图像数据集为基于AI的故障检测算法的训练和测试提供了重要工具。
### Innovation
本文提出了一种系统分析基于视觉导航摄像头传感器故障的方法，设计并实现了一个仿真框架来生成带有故障的合成图像，从而填补了缺乏具有代表性的故障图像数据集的空白，为AI在基于视觉导航中故障检测应用的研究提供了一个有效工具和评估平台。
### Conclusion
通过引入仿真框架生成的包含故障的合成图像数据集，本文为基于视觉导航的摄像机传感器故障检测算法的开发提供了可靠的训练和测试数据支持，促进了人工智能技术在保障大型宇宙探测任务视觉导航系统可靠性和稳健性方面的应用。
## 341. `cs.CV` - APT: 适应性个性化训练在有限数据下的扩散模型 [PDF](https://arxiv.org/pdf/2507.02687), [HTML](https://arxiv.org/abs/2507.02687)
### Authors
JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang
### Background
在使用有限数据个性化扩散模型时，面临着过拟合、先验知识丢失和文本对齐降级等重大挑战。过拟合会导致噪声预测分布发生变化，破坏去噪轨迹，使模型丧失语义连贯性。
### Innovation
提出了适应性个性化训练（APT）框架，通过采用适应性训练策略并调整模型的内部表示来缓解过拟合。APT 框架包含三个关键部分：适应性训练调整、表示稳定化和注意力对齐，分别用于检测过拟合程度、防止特征图中噪声预测的过度偏移以及确保先验知识和语义连贯性。
### Conclusion
通过广泛的实验表明，APT 能够有效缓解过拟合、保留先验知识，并在有限参考数据下生成高质量和多样化的图像，超越了现有方法的表现。
## 342. `cs.CV` - AuroraLong：重新引入RNN以实现高效开放式视频理解 [PDF](https://arxiv.org/pdf/2507.02591), [HTML](https://arxiv.org/abs/2507.02591)
### Authors
Weili Xu,Enxin Song,Wenhao Chai,Xuexiang Wen,Tian Ye,Gaoang Wang
### Background
长视频理解面临的挑战在于其高度的计算复杂性和内存成本，因为基于Transformer的大型语言模型（LLM）所需的内存和计算量随着输入序列长度的增加成正比增长。因此，理解和处理长视频成为一个巨大的技术难题。
### Innovation
AuroraLong 通过将 MLLMs 中的 LLM 组件替换为一种线性递归神经网络（RNN）语言模型来应对这一挑战，这种线性递归神经网络能够以恒定大小的隐藏状态处理任意长度的输入序列，从而提高效率。此外，该模型通过按视觉标记大小的升序重新排列视觉标记来进一步提高吞吐量和效率。尽管 AuroraLong 只有 2 亿参数，并且仅在公共数据集上训练，但在多个视频基准测试中，其性能与在私有数据集上训练的类似大小的基于 Transformer 的模型相当，这表明高效的线性 RNN 有望通过降低计算门槛来促进长视频理解的普及
### Conclusion
AuroraLong 证明了线性 RNN 作为一种高效模型的潜力，能够降低长期视频理解的计算门槛，并且我们是第一个在类似 ALaVA 的开放式视频理解模型中使用线性 RNN 作为主干网络的研究团队。
## 343. `cs.CV` - 通过可微分体素化从分割学习血管的参数化形状模型 [PDF](https://arxiv.org/pdf/2507.02576), [HTML](https://arxiv.org/abs/2507.02576)
### Authors
Alina F. Dima,Suprosanna Shit,Huaqi Qiu,Robbie Holland,Tamara T. Mueller,Fabio Antonio Musio,Kaiyuan Yang,Bjoern Menze,Rickmer Braren,Marcus Makowski,Daniel Rueckert
### Background
在人体中的血管是复杂的结构，已有多方面的研究，包括体素化（voxelization）、网格和参数模型。尽管体素化最为常见，但网格和参数模型在不同应用中因其特性被重视。然而，这些表示通常是通过分割提取并各自分开使用。本文提出了一种框架，将三种表示在可微变换下联合起来。通过利用可微分体素化，自动通过形状到分割的拟合提取参数化形状模型，无需显式的先验形状参数。通过三次B样条曲线参数化血管为中心线和半径，确保光滑性和连续性。不同可微地从学习到的形状参数中提取网格，得到高保真网格，便于操作后再调整。方法已通过主动脉、动脉瘤和脑血管的体素拟合实验，展示了对于复杂血管的精确几何建模能力。
### Innovation
提出了一种框架，在可微变换下结合体素化（voxelization）、网格和参数模型三种表示，通过形状到分割的拟合自动提取参数化血管模型，无需显式的先验形状参数。利用可微分体素化，从分割自动学习形状参数，通过三次B样条曲线参数化血管，确保光滑性和连续性，实现高保真网格提取，这种方法能够准确描述复杂血管的几何特征。
### Conclusion
本文方法能够精确地捕捉复杂血管的几何形状，通过实验展示，体素拟合在主动脉、动脉瘤和脑血管上结果良好，这种方法通过可微分体素化从分割中自动学习参数化形状模型，无需显式形状参数，确保了血管模型的光滑性和连续性，提供了高保真的网格表示。
## 344. `cs.CV` - FairHuman：在最小潜在延迟公平性准则下提升扩散模型中的人像手部和面部质量 [PDF](https://arxiv.org/pdf/2507.02714), [HTML](https://arxiv.org/abs/2507.02714)
### Authors
Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma
### Background
图像生成领域，尤其是基于扩散模型的大型文本到图像模型，已经取得了显著的进步。然而，在训练过程中由于局部区域监督不足，生成包含人脸或手部等合理细节的人像仍然具有挑战性。本文旨在解决这一问题。
### Innovation
提出了一种多目标微调方法FairHuman，旨在公平地提升全局和局部生成质量。具体而言，该方法首先构造了三个学习目标：基于默认扩散目标函数的全局目标，以及基于预标注位置先验的两种局部目标。随后，方法在最小潜在延迟(MPD)准则指导下单得出最优参数更新策略，从而实现了多目标问题的公平优化。
### Conclusion
实验结果表明，该方法在保持整体质量的同时，显著提升了生成具有挑战性局部细节的能力。
## 345. `cs.CV` - DexVLG: 大规模的灵巧视觉-语言-抓取模型 [PDF](https://arxiv.org/pdf/2507.02747), [HTML](https://arxiv.org/abs/2507.02747)
### Authors
Jiawei He,Danshi Li,Xinqiang Yu,Zekun Qi,Wenyao Zhang,Jiayi Chen,Zhaoxiang Zhang,Zhizheng Zhang,Li Yi,He Wang
### Background
由于大型模型的普及，视觉-语言-动作（VLA）系统正在帮助机器人处理越来越复杂的任务。然而，受限于数据收集的难度，研究主要集中于控制简单的夹具末端执行器，而对于使用类似人类灵巧手进行功能性抓取的研究较少。本文背景介绍了当前研究领域的现状和需求。
### Innovation
本文提出了DexVLG，这是一种大规模的灵巧视觉-语言-抓取模型，用于根据语言指令预测桌面上物体的手部抓取姿态，使用单视角RGBD输入。创新点包括：1）构建了包含1700万灵巧抓取姿态的大型数据集DexGraspNet 3.0；2）开发了一种VLM和流匹配基础的姿态头，能够产生与指令对齐的抓取姿态；3）通过物理仿真和真实世界实验对DexVLG的性能进行评估，展示了其出色的零样本泛化能力。
### Conclusion
实验结果表明DexVLG在仿真中的零样本执行成功率超过76%，并且在实体物体上展示了成功的部分对齐抓取。
## 346. `cs.CV` - 基于全局上下文的线性注意力：用于视觉和物理的多级注意力机制 [PDF](https://arxiv.org/pdf/2507.02748), [HTML](https://arxiv.org/abs/2507.02748)
### Authors
Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen
### Background
transformers在各种任务中已成为标准，从图像分类到物理模拟。尽管表现优异，但在处理高分辨率输入时，标准transformers的时间和内存复杂度与输入长度的平方成比例，这使其不切实际。因此，提出了多种变体，最成功的依赖于分区、下采样或降级技术，但可能会损失最细尺度的细节。本文从n体数值模拟中获得灵感，将注意力视为网格点之间的相互作用问题，采纳了一种新的方法。
### Innovation
提出了Multipole Attention Neural Operator (MANO)，以一种基于距离的多尺度方式进行注意力计算。MANO在每个注意力头中保持全局接收范围，并实现了与网格点数量成线性的时间和内存复杂度。
### Conclusion
实验结果表明，MANO能够在大幅减少运行时间和峰值内存使用的情况下与当前最好的模型（如ViT和Swin Transformer）媲美。代码已开源以保证可复现性。
## 347. `cs.CV` - SIU3R：超越特征对齐的场景理解与3D重建 [PDF](https://arxiv.org/pdf/2507.02705), [HTML](https://arxiv.org/abs/2507.02705)
### Authors
Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu
### Background
同时理解和三维重建在开发端到端的具身智能系统中扮演着重要角色。最近的方法依赖于从2D到3D特征对齐的范式，这限制了三维理解的能力并可能导致潜在的语义信息丢失。为了解决此问题，我们提出了SIU3R，这是一种无需特征对齐、用于通用的从未摆拍图像中进行的同时场景理解和三维重建的框架。
### Innovation
SIU3R通过像素对齐的三维表示将重建和理解任务联系起来，并将多个理解任务统一为一组可学习的查询，从而实现原生的三维理解，无需与2D模型对齐。此外，我们进一步对两者的相互收益进行了深入分析，并提出了两个轻量级模块以促进任务间的交互作用。这种方法不仅在三维重建和理解任务上表现优异，在同时理解和三维重建任务上同样表现出色，突显了无对齐框架的优势及相互受益设计的有效性。
### Conclusion
我们的研究方法展示了在独立的任务以及同时理解与三维重建两个综合任务上都达到了最先进的性能，这证明了无对齐框架的优势及互惠设计的有效性。
## 348. `cs.CV` - CanonSwap:通过标准空间调制实现高质量且一致的视频换脸 [PDF](https://arxiv.org/pdf/2507.02691), [HTML](https://arxiv.org/abs/2507.02691)
### Authors
Xiangyang Luo,Ye Zhu,Yunfei Liu,Lijian Lin,Cong Wan,Zijian Cai,Shao-Lun Huang,Yu Li
### Background
视频换脸旨在解决两个主要挑战：有效将源身份转移到目标视频中，并准确地保留目标脸部的动态属性，如头部姿态、面部表情和唇部同步等。现有方法主要关注于实现高质量的身份转移，但往往在保持目标脸部的动态属性方面做得不够好，导致结果不一致。这可以归因于视频中面部外观与运动的固有耦合。
### Innovation
我们提出了一个名为CanonSwap的新颖视频换脸框架，该框架将运动信息与外观信息解耦。具体来说，CanonSwap首先去除与运动相关的信息，使得身份更改能够在统一的标准空间内进行。随后，交换后的特征被重新整合到原始视频空间中，以确保目标脸部动态属性的保存。此外，我们设计了一个部分身份调制模块，该模块使用空间掩码适应性地整合源身份特征，限制修改仅限于面部区域。我们还引入了几种精细同步度量，以全面评估视频换脸方法的性能。实验结果表明，我们的方法在视觉质量、时序一致性以及身份保留方面显著优于现有方法。
### Conclusion
广泛的实验表明，我们的方法在视觉质量、时序一致性和身份保留方面显著优于现有方法。我们的项目页面可在该链接查看。
## 349. `cs.CV` - 部分弱监督定向物体检测 [PDF](https://arxiv.org/pdf/2507.02751), [HTML](https://arxiv.org/abs/2507.02751)
### Authors
Mingxin Liu,Peiyuan Zhang,Yuan Liu,Wei Zhang,Yue Zhou,Ning Liao,Ziyang Gong,Junwei Luo,Zhirui Wang,Yi Yu,Xue Yang
### Background
定向对象检测（OOD）在多个领域的需求不断增长，推动了这一领域的研究。然而，数据集标注的成本仍然很高。目前主流的OOD算法主要分为三类：完全监督方法使用完整的定向边界框（OBB）标注、半监督方法使用部分OBB标注、弱监督方法使用弱标注如水平框或点。这些方法不可避免地增加了模型的标注速度或标注成本。当前主要的解决方案未能有效降低这一成本问题。
### Innovation
提出了一种基于部分弱标注（水平框或单个点）的第一部分弱监督定向物体检测（PWOOD）框架，能够高效利用大量未标注数据，显著优于使用部分弱标注训练的弱监督算法，提供了成本更低的解决方案；提出了一个对学生模型的Orientation-and-Scale-aware Student (OS-Student)模型，该模型仅使用少量方向无感知或尺度无感知的弱标注信息就能学习方向和尺度信息；提出了Class-Agnostic Pseudo-Label Filtering策略 (CPF)，以降低模型对静态过滤阈值的敏感度。
### Conclusion
在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的全面实验表明，PWOOD框架在性能上能够与或优于传统半监督算法。
## 350. `cs.CV` - UniMC: 控制扩散变换器实现统一关键点引导多类图像生成 [PDF](https://arxiv.org/pdf/2507.02713), [HTML](https://arxiv.org/abs/2507.02713)
### Authors
Qin Guo,Ailing Zeng,Dongxu Yue,Ceyuan Yang,Yang Cao,Hanzhong Guo,Fei Shen,Wei Liu,Xihui Liu,Dan Xu
### Background
尽管在关键点引导的文本到图像扩散模型方面取得了显著进展，但现有的主流关键点引导模型在控制生成非人类的更通用的非刚性对象（例如动物）方面遇到了挑战。此外，仅依赖关键点控制生成多个重叠的人类和动物也是困难的。这些挑战主要来自于两个方面：现有的可控制方法的固有局限性和缺乏合适的数据集。前人方法难以区分实例和类别，因为它们主要依赖于骨骼图像作为条件。为此，提出了一个基于DiT的框架UniMC，以探索统一可控制的多类图像生成。HAIG-2.9M是一个大而精、高质量且多样的数据集，用于关键点引导的人和动物图像生成，该数据集包括78.6万张图像，总计有290万实例，并且对关键点、边界框和详细说明进行了广泛的注释，以确保注释的准确性并验证数据集的质量。
### Innovation
通过设计基于DiT的框架UniMC，将实例和关键点级别的条件整合为紧凑的令牌，包括类别、边界框和关键点坐标等属性，解决现有方法难以区分实例和类别的问题。同时，提出了一个大规模且高质量的多样数据集HAIG-2.9M，其中包括786K张图像，290万个实例，以及对关键点、边界框和细粒度的描述进行了详尽的注释，通过手动检查确保注释的准确性，从而促进关键点引导的人和动物图像生成的研究。
### Conclusion
广泛的实验表明了HAIG-2.9M数据集的高质量以及UniMC框架在复杂遮挡和多类场景中的有效性。UniMC和HAIG-2.9M为空间变形的多实例生成任务设定了新的基准。
## 351. `cs.CV` - 从像素到损伤程度：使用社会媒体图像的语义分割估计地震影响 [PDF](https://arxiv.org/pdf/2507.02781), [HTML](https://arxiv.org/abs/2507.02781)
### Authors
Danrong Zhang,Huili Huang,N. Simrill Smith,Nimisha Roy,J. David Frost
### Background
在地震之后，社会媒体图像已成为灾害侦察的关键资源，可以即时提供损坏程度的信息。传统的后地震社会媒体图像损坏严重性评估方法通常依赖于分类方法，这种方法主观性较强，无法考虑图像中损坏程度的变化。
### Innovation
本文通过将损坏严重性评估重新定义为语义分割问题，提出了一种新颖的方法。这种方法通过构建分段损坏严重性数据集，并将损坏分为无损结构、受损结构和废墟三类。利用该数据集，研究通过微调SegFormer模型，为地震后的社会媒体图像生成损坏严重性分割。此外，一项新的损坏严重性评分系统也被引入，该系统通过考虑图像中不同区域损坏程度的变化和深度估计来量化损坏程度。
### Conclusion
通过这种方法，可以更客观和全面地量化社会媒体图像中的损坏程度。通过提供对损坏的深入理解，本文增强了解灾侦察团队提供精确指导的能力，有助于更有效的灾害响应。
## 352. `cs.CV` - 使用边界框约束的提示学习方法在医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2507.02743), [HTML](https://arxiv.org/abs/2507.02743)
### Authors
Mélanie Gaillochet,Mehrdad Noori,Sahar Dastani,Christian Desrosiers,Hervé Lombaert
### Background
医学领域中的像素级注解工作繁重且成本高昂。为减轻负担，基于边框注解的弱监督方法提供了一种实际替代方案，因其注解更加容易获得。视觉基础模型在提供点或边框提示时，显示出显著的分割性能。提示学习通过调整这些模型以适应下游任务并自动化分割过程来减少用户干预。然而，现有提示学习方法依赖于完全标注的分割掩码。本研究提出了一种新框架，结合了基础模型的强大表示能力以及弱监督分割的注解效率。具体来说，该方法仅使用边框注解自动生成基础模型的提示。提出的优化方案结合了从边框注解导出的多条约束与由提示基础模型生成的伪标签。在多种模态的数据集上进行的大量实验结果表明，在数据有限的情况下，本研究的弱监督方法实现了平均Dice分数为84.90%，优于现有的全监督和弱监督方法。代码可在此处获得：this https URL
### Innovation
提出了一种新的框架，结合了基础模型的强大表示能力和弱监督分割的注解效率。该方法仅使用边框注解，自动生成基础模型的提示，并通过结合从边框注解中导出的约束和伪标签，实现了在有限数据集上的性能提升。这种方法显著降低了用户干预的需求，提升了分割任务的效率和准确性。
### Conclusion
研究提出的弱监督方法在多种模态数据集上的实验结果表明，即使在数据有限的情况下也表现出色，达到了84.90%的平均Dice分数，优于现有的全监督和弱监督方法。
## 353. `cs.CV` - 无需训练！基于参考图的无训练实例分割 [PDF](https://arxiv.org/pdf/2507.02798), [HTML](https://arxiv.org/abs/2507.02798)
### Authors
Miguel Espinosa,Chenhongyi Yang,Linus Ericsson,Steven McDonagh,Elliot J. Crowley
### Background
以往，图像分割模型的性能受到大规模标注数据收集成本的限制。Segment Anything Model (SAM) 通过可提示、语义无关的分割范式来缓解这一问题，但仍需手动视觉提示或复杂的领域依赖提示生成规则来处理新图像。本文研究了仅提供少量参考图像时的物体分割任务，旨在减少这些新的负担。研究表明，利用基础模型学习到的强语义先验，可以识别参考图像与目标图像之间的对应区域。相关性能够使实例级别分割掩码的自动生成成为可能，并通过一个无训练的多阶段方法实现，包括记忆库构建、表示聚合和语义感知特征匹配。
### Innovation
本文提出了一个无训练的基于参考图的实例分割方法，通过利用基础模型学习到的语义先验，自动生成实例级别的分割掩码，无需进一步的训练。该方法通过记忆库构建、表示聚合和语义感知特征匹配三个阶段来实现。实验结果显示，在COCO FSOD、PASCAL VOC Few-Shot 和 Cross-Domain FSOD基准上，该方法取得了显著的性能提升，尤其在COCO FSOD中达到了36.8%的nAP，在PASCAL VOC Few-Shot中达到71.2%的nAP50，超越了现有的其他无训练方法。
### Conclusion
本文提出的方法显著提高了实例分割任务的性能，在多个基准测试上达到了最先进的水平，尤其是在少量参考图像的情况下，有效降低了分割任务的负担，展示了无训练模型在分割任务中的潜力。
## 354. `cs.CV` - LangScene-X: 使用 TriMap 视频扩散重建可泛化的3D语言嵌入场景 [PDF](https://arxiv.org/pdf/2507.02813), [HTML](https://arxiv.org/abs/2507.02813)
### Authors
Fangfu Liu,Hao Li,Jiawei Chi,Hanyang Wang,Minghui Yang,Fudong Wang,Yueqi Duan
### Background
从2D图像恢复3D结构并结合开放词汇场景理解是一个基本但具有挑战性的任务。现有方法通过嵌入语言信息的场景优化实现了这一目标，但它们严重依赖于校准密集视图重建，导致在视图有限时出现严重的渲染伪影和不可信语义合成。
### Innovation
本文提出了一种新颖的生成框架LangScene-X，以统一和生成3D一致的多模态信息用于重建和理解。通过利用从稀疏输入生成一致的新颖观察的生成能力，我们可以仅从稀疏视图构建具有泛化能力的3D语言嵌入场景。具体地，首先训练一个TriMap视频扩散模型，通过逐步知识整合从稀疏输入生成外观（RGBs）、几何（法线）和语义（分割图）。此外，提出了一种在大规模图像数据集上训练的语言量化压缩器（LQC），用于高效编码语言嵌入，实现跨场景泛化而无需重新训练。最后，通过将语言信息对齐到3D场景的表面重建语言表面场，以支持开放式语言查询。实验结果表明，与现有技术相比，我们的LangScene-X在质量和泛化能力方面具有优越性。
### Conclusion
我们提出的LangScene-X具备从稀疏视图重建可泛化3D语言嵌入场景的能力，在质量和泛化能力方面优于现有方法。
## 355. `cs.CV` - RichControl: 结构丰富和外观丰富的无训练空间控制用于图文生成 [PDF](https://arxiv.org/pdf/2507.02792), [HTML](https://arxiv.org/abs/2507.02792)
### Authors
Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang
### Background
T2I扩散模型在从文本提示生成高质量图像方面取得了显著的成功。最近的努力将这些模型扩展到结合条件图像（如深度图或姿态图）以实现精细的空间控制。其中，特征注入方法作为一种无需微调的替代传统微调的方法已逐渐流行。然而，这些方法往往存在结构对齐不良、条件泄露和视觉伪影等问题，尤其是在条件图像与自然RGB分布差异显著时。通过重新审视现有方法，我们发现核心限制在于特征注入同步未能平衡去噪过程中的领域对齐和结构保持之间的权衡。在这一观察的基础上，我们提出了一种灵活的特征注入框架，将注入时间与去噪过程脱钩。核心模块是富含结构特征的注入模块，使得模型能在扩散步骤中更好地适应对齐和结构保持之间的互动演变，从而生成更忠实的结构。此外，我们引入了外观丰盛的提示技术和重启细化策略，以进一步增强外观控制和视觉质量。这些设计使无训练生成同时富含结构和外观成为可能。
### Innovation
1. 提出了一种灵活的特征注入框架，将注入时间与去噪过程脱钩，增强了结构保持能力。2. 引入了富含结构特征的注入模块，使得模型在扩散步骤中更好地适应对齐和结构保持之间的互动演变。3. 引入了富含外观的提示技术和重启细化策略，进一步增强了外观控制和视觉质量。4. 总体上实现了结构丰富和外观丰富的无训练生成方法。
### Conclusion
我们的方法在多种零样本条件场景下取得了最先进的性能。
## 356. `cs.CV` - HyperGaussians: 高维高斯混叠用于高保真可动画人脸avatar [PDF](https://arxiv.org/pdf/2507.02803), [HTML](https://arxiv.org/abs/2507.02803)
### Authors
Gent Serifi,Marcel C. Bühler
### Background
创建高质量可动画人脸avatar是从视频中生成详细人脸的一个具有挑战性的问题，具有广泛的应用于增强现实和虚拟现实。尽管已经在静态人脸方面取得了巨大进展，但来自单目视频的可动画人脸avatar仍然处于‘毛毛 valley’中。目前标准的方法3D高斯混叠（3DGS）通过一系列3D高斯基元来表示人脸，虽然3DGS非常适合渲染静态人脸，但对于非线性变形、复杂光线效果和细微细节仍然存在限制。大多数相关工作集中在预测更好的高斯参数，本文则重新考虑了3D高斯表示本身，以及如何使其更具表现力。因此提出了高维多元高斯‘HyperGaussians’的新方法，通过可学习的局部嵌入来增加表达能力，但对HyperGaussians进行混叠计算昂贵，需要反转高维协方差矩阵。此方法通过重参数化协方差矩阵，即‘逆协方差技巧’来解决这个问题，提高了效率，使其能够无缝集成到现有模型中。实验结果表明，与3DGS相比，HyperGaussians在数值和视觉上都有显著优势，尤其是在高频细节如眼镜框、牙齿、面部复杂运动和高光反射方面。
### Innovation
提出了一种新的扩展3D高斯混叠的方法，称为‘高维多元高斯’（HyperGaussians）。通过引入高维配合学习局部嵌入，增加了表达能力，克服了原始3D高斯混叠方法在处理复杂动态和高细节细节的问题。通过逆协方差技巧提高了计算效率，使其能够与现有的模型无缝集成。并在FlashAvatar中演示了这一创新方法的效果。
### Conclusion
实验结果显示，HyperGaussians在生成包含高频细节如眼镜框、牙齿、复杂面部运动和高光反射的高保真可动画人脸avatar方面，明显优于现有的3D高斯混叠方法（3DGS）。该方法通过创新的方法大大提高了3D图像渲染能力，同时具有高效性。
## 357. `cs.CV` - 视觉环境攻击：利用图像驱动的上下文注入破解MLLM [PDF](https://arxiv.org/pdf/2507.02844), [HTML](https://arxiv.org/abs/2507.02844)
### Authors
Ziqi Miao,Yi Ding,Lijun Li,Jing Shao
### Background
随着强大视觉语言能力的出现，多模态大型语言模型（MLLMs）展现了在实际应用中的巨大潜力。然而，视觉模态所呈现的安全漏洞对在开放环境中的部署构成了重大挑战。最近的研究通过直接将有害的文本语义编码到视觉输入中，成功诱导出目标MLLM的有害响应，但这些方法中视觉模态主要作为触发不当行为的手段，且往往缺乏现实场景中的语义确定性和坚实关系。本文定义了一种新的场景：视觉中心的破解，其中视觉信息是构建完整的现实破解场景的必要组成部分。
### Innovation
在此背景下，本文提出了一种名为VisCo（视觉情境）的攻击方法。VisCo采用四种不同的视觉聚焦策略构建上下文对话，并在必要时动态生成辅助图像，以构建视觉中心的破解场景。VisCo还结合自动毒性遮蔽和语义优化，生成可以可靠触发目标黑盒MLLM有害响应的最终攻击提示。在MM-SafetyBench测试中，VisCo对GPT-4o的毒性得分为4.78，攻击成功率（ASR）为85%，显著优于基线方法，其毒性得分为2.48，ASR为22.2%。
### Conclusion
VisCo方法在MM-SafetyBench测试中的毒性得分为4.78，攻击成功率（ASR）为85%，显著优于基准方法，为视觉中心的破解场景提供了一个有效的攻击手段。
## 358. `cs.CV` - Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach [PDF](https://arxiv.org/pdf/2507.02826), [HTML](https://arxiv.org/abs/2507.02826)
### Authors
Panpan Ji,Junni Song,Hang Xiao,Hanyu Liu,Chao Li
### Background
Sensor-based Human Activity Recognition (HAR) is a core technology for intelligent systems. However, multimodal HAR systems face challenges such as difficulties in cross-modal feature alignment and imbalanced contributions from different modalities.
### Innovation
提出了一种新的框架——动态对比双路径网络（DCDP-HAR），该框架包括三个关键组成部分：1）一种双路径特征提取架构，使用ResNet和DenseNet分支共同处理多模态传感器数据；2）引入多阶段对比学习机制，实现从局部感知到语义抽象的逐步对齐；3）提出了一种基于置信度的梯度调制策略，在反向传播过程中动态监测和调整每个模态分支的学习强度，有效缓解模态竞争。同时采用基于动量的梯度累积策略以增强训练稳定性。
### Conclusion
通过消融研究验证了每个组件的有效性，并在四个公开基准数据集上进行了广泛的比较实验以验证有效性和性能。
## 359. `cs.CV` - USAD: 无监督数据增强时空注意力扩散网络 [PDF](https://arxiv.org/pdf/2507.02827), [HTML](https://arxiv.org/abs/2507.02827)
### Authors
Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li
### Background
人体活动识别（HAR）的主要目标是从传感器数据中推断正在进行的人类动作，这一任务在健康监测、安全保障和运动分析等方面有着广泛的应用。尽管有大量的研究，但HAR仍然面临一些关键挑战，如稀有的活动缺乏标注样本、高层特征提取不足以及在轻量级设备上的模型性能不佳等问题。针对这些问题，本文提出了一种以多注意力交互机制为核心的全面优化方法。该方法通过无监督的统计指导扩散模型进行数据增强，解决了标签数据稀缺和严重类别不平衡问题。此外，还设计了一种多分支时空交互网络，通过平行残差分支中的3*3、5*5和7*7卷积核捕获序列数据的多尺度特征，同时加入时序注意力机制和空间注意力机制来识别关键的时间点和增强传感器之间的交互，进一步引入跨分支特征融合单元以提高整体特征表示能力。最后，集成了自适应多损失函数融合策略，允许动态调整损失权重和整体模型优化。实验结果在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上证明了所提出的无监督数据增强时空注意力扩散网络（USAD）的高准确率，并且明显优于现有方法。此外，实际部署在嵌入式设备上验证了该方法的有效性和可行性。
### Innovation
本文提出了一种全面优化的人体活动识别方法，该方法包括无监督的统计指导扩散模型进行数据增强，多分支时空交互网络来捕获多尺度特征，跨分支特征融合单元以增强特征表示能力，以及自适应多损失函数融合策略以优化整体模型。这些创新点解决了罕见活动的标注样本稀缺、高层特征提取不足和轻量级设备上模型性能不佳等问题。
### Conclusion
本文提出了USAD（无监督数据增强时空注意力扩散网络），实验结果表明该方法在三个公开数据集上的准确率显著高于现有方法，并且在嵌入式设备上的实际部署验证了其有效性和可行性。
## 360. `cs.CV` - 在多模态LLM中通过注地链式思维进行自举以实现高效的数据模型适应 [PDF](https://arxiv.org/pdf/2507.02859), [HTML](https://arxiv.org/abs/2507.02859)
### Authors
Jiaer Xia,Bingkui Tong,Yuhang Zang,Rui Shao,Kaiyang Zhou
### Background
多模态大语言模型（MLLMs）能够在使用自然语言解释图像方面表现出显著的能力。然而，这些模型在没有大规模数据集重新训练的情况下，很难适应专门的视觉任务，例如图表理解。这个问题是由预训练和下游数据集之间的不匹配引起的：预训练数据集主要集中在场景和对象上，但关于特殊、非对象的图像（如图表和表格）的信息有限。
### Innovation
本文发现，使用链式思维（CoT）推理数据对MLLMs进行训练可以有助于模型在专门的视觉任务中的适应性，尤其是在数据有限的情况下。然而，作者指出在从预训练LLM中提取的CoT数据中存在一个关键问题，即数据中的推理步骤经常包含多个事实错误。为此，提出了基于自举的“注地链式思维”（GCoT）方法，旨在向CoT数据中注入定位信息（即边界框），从而使推理步骤更忠实于输入图像。
### Conclusion
评估结果表明，在数据有限的场景中，相较于调优和蒸馏，我们的方法显著提高了模型的性能。
## 361. `cs.CV` - 从长视频到吸引人的剪辑：基于多模态叙事理解的人类启发式视频编辑框架 [PDF](https://arxiv.org/pdf/2507.02790), [HTML](https://arxiv.org/abs/2507.02790)
### Authors
Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu
### Background
随着在线视频内容，尤其是短视频平台上的内容快速增加，对高效视频编辑技术的需求也随之增长。现有的自动编辑方法主要依赖语音转文本（ASR）转录中的文本提示和端到端的剪辑选择，往往忽视了丰富的视觉上下文，导致输出不连贯。这些方法通常提取结构化的角色和对话片段，但这些内容不一定能够传达视频的主要线索或情感。因此，需要能够理解视频中的视觉和文本信息的框架来改善这种限制。在此背景下，本研究提出了一个人类启发式的自动视频编辑框架（HIVE），通过多模态叙事理解来弥补这些不足。该框架使用多模态大型语言模型进行角色提取、对话分析和叙事总结，从而全面理解视频内容。同时，为了进一步提高连贯性，进行了场景级别的切分，将编辑过程分解成三个子任务：亮点检测、开头/结尾选择和无关内容裁剪，从而在这些任务中的表现提高连贯性。为促进该领域的研究，引入了DramaAD基准数据集，包含800多个短戏剧集和500个专业编辑的广告剪辑，这些数据集旨在更好地理解和编辑视频。实验结果表明，该框架在通用编辑任务和以广告为导向的编辑任务中均优于现有baseline，显著缩小了自动编辑视频和专业编辑视频的质量差距，从而提高了编辑质量，并为改进和分析视频编辑技术提供了新的数据支持和方法。
### Innovation
提出了一种基于人类启发的自动视频编辑框架（HIVE），通过多模态叙事理解来处理现有的自动编辑方法存在的问题，即忽视视觉和文本信息的连贯性。该框架结合了角色提取、对话分析和多模态大型语言模型叙事总结，同时分解编辑过程以提高连贯性，包括亮点检测、开头/结尾选择和无关内容裁剪。并通过引入一个新的基准数据集DramaAD来促进研究，该数据集包含了大量短剧和广告视频编辑的样例，以便更好地理解和改进视频编辑技术。
### Conclusion
这项研究提出的人类启发式的自动视频编辑框架（HIVE）在多个应用场景中表现出色，显著提高了视频编辑的连贯性和质量。DramaAD数据集也为其他研究人员提供了有价值的研究资源，有助于进一步推进视频编辑技术的进步。
## 362. `cs.CV` - LiteReality: RGB-D扫描的图形就绪3D场景重建 [PDF](https://arxiv.org/pdf/2507.02861), [HTML](https://arxiv.org/abs/2507.02861)
### Authors
Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby
### Background
该论文介绍了一种名为LiteReality的新颖管道，该管道能够将室内环境的RGB-D扫描转换为紧凑、逼真和交互式的3D虚拟副本。LiteReality不仅重建了视觉上相似于现实的场景，还支持图形管道中的关键特征，如物体的独立性、关节活动、高质量的基于物理的渲染材料以及基于物理的交互。研究背景在于当前的3D重建技术通常不能同时满足视觉逼真和高效渲染的要求，尤其是在AR/VR、游戏、机器人技术和数字孪生等领域的需求上有所欠缺。
### Innovation
LiteReality的主要创新点在于：1. 使用结构化场景图进行场景理解和分解，将结果解析为一致的3D布局和对象。2. 通过检索最相似的3D艺术家创作模型来进行场景重建，从而提高视觉相似度。3. 通过Material Painting模块恢复高质量、空间变化的材料，以增强真实感。4. 将重建的场景集成到具有基本物理属性的模拟引擎中，以实现交互行为。5. 引入无训练对象检索模块，在Scan2CAD基准上达到最先进的相似性能。6. 提出一个鲁棒的Material Painting模块，能够将来自任何风格图像的外观转移到3D资产上，即使存在严重对齐差、遮挡和光照不良的情况。
### Conclusion
实验结果表明，LiteReality能够有效地应用于真实世界的扫描和公开数据集。重建的场景具有紧凑性、可编辑性和与标准图形管线的完全兼容性，适用于AR/VR、游戏、机器人技术和数字孪生等多种应用场景。
## 363. `cs.CV` - 少即是多：基于运行时自适应缓存的无需训练的视频扩散加速 [PDF](https://arxiv.org/pdf/2507.02860), [HTML](https://arxiv.org/abs/2507.02860)
### Authors
Xin Zhou,Dingkang Liang,Kaijin Chen,Tianrui Feng,Xiwu Chen,Hongkai Lin,Yikang Ding,Feiyang Tan,Hengshuang Zhao,Xiang Bai
### Background
视频生成模型已经展示了出色的性能，但其广泛应用受到推理速度慢和计算成本高的限制，主要原因是去噪过程的迭代性质。解决这一瓶颈对于普及高级视频合成技术并使其能够融入实际应用至关重要。以往的研究主要集中在需要离线配置、预计算和大量参数调整的方法上，这增加了部署的复杂性。
### Innovation
本文提出了无需训练的加速框架EasyCache，它引入了一种轻量级、运行时自适应的缓存机制，可以动态重用已计算的变换向量，从而在推理过程中避免不必要的计算。与先前的方法不同，EasyCache不需要离线配置、预计算或参数调整。该方法已在包括OpenSora、Wan2.1和HunyuanVideo在内的各种大型视频生成模型上进行了全面研究。EasyCache实现了卓越的加速性能，将推理时间减少到原基线的1.07-1.33倍，同时保持高质量的视觉保真度，相比上一代最先进的方法，平均提高了36%的PSNR。
### Conclusion
EasyCache是一种高效且高度可访问的解决方案，适用于高质量视频生成的研发和实际应用。该研究成果已经公开，可在指定的网站获取。
## 364. `cs.CV` - AnyI2V: 使用运动控制任意条件图像动画 [PDF](https://arxiv.org/pdf/2507.02857), [HTML](https://arxiv.org/abs/2507.02857)
### Authors
Ziye Li,Hao Luo,Xincheng Shuai,Henghui Ding
### Background
近年来，扩散模型在视频生成领域取得了显著进展，特别是在文本到视频(T2V)和图像到视频(I2V)合成方面。然而，如何有效地整合动态运动信号和灵活的空间约束仍然是一个挑战。现有的T2V方法通常依赖于文本提示，这在生成内容的空间布局方面缺乏精确控制。相比之下，I2V方法受限于对真实图像的依赖，这限制了合成内容的可编辑性。尽管一些方法结合了ControlNet引入基于图像的条件，但这些方法往往缺乏明确的运动控制，并且需要昂贵的计算资源进行训练。
### Innovation
为了应对这些限制，我们提出了AnyI2V，这是一个无需训练的框架，它可以使用用户定义的运动轨迹来动画化任何条件图像。AnyI2V支持更广泛的条件输入模式，包括ControlNet不支持的网格和点云等数据类型，从而实现更灵活多样的视频生成。此外，它还支持混合条件输入，并通过LoRA和文本提示实现了风格迁移和编辑。
### Conclusion
广泛的实验表明，AnyI2V在时空控制视频生成方面实现了优越的性能，并提供了新的视角。开源代码在此可获取。
## 365. `cs.CV` - TubuleTracker：一种高保真自由共享软件，用于量化血管生成结构和成熟度 [PDF](https://arxiv.org/pdf/2507.02024), [HTML](https://arxiv.org/abs/2507.02024)
### Authors
Danish Mahmood,Stephanie Buczkowski,Sahaj Shah,Autumn Anthony,Rohini Desetty,Carlo R Bartoli
### Background
体内血管内皮细胞培养广泛用于研究血管生成。细胞网络的组织学显微图像通常需要手动分析，这个过程耗时且主观。虽然ImageJ等自动化工具可以辅助，但往往会因为速度慢和不准确而无法使用。随着内皮网络变得更加复杂，传统的架构度量可能无法完全反映网络的成熟度。为了解决这些问题，我们开发了tubuleTracker，这是一种能够快速和客观地量化内皮网络的架构和成熟度的软件工具。
### Innovation
tubuleTracker是一种能够快速客观地量化内皮网络架构和成熟度的软件工具，比手动分析和基于ImageJ的分析更快更一致。特别地，血管圆度在捕捉血管生成成熟度方面尤为有效。该工具作为免费分享软件提供给生物医学研究社区。
### Conclusion
tubuleTracker不仅比手动和基于ImageJ的方法更快更一致，而且其度量指标与血管生成成熟度评分之间存在显著相关性，尤其在血管圆度方面表现尤为突出。该软件已被免费提供给生物医学研究界。
## 366. `cs.CV` - RefTok: 基于参考的视频生成分词方法 [PDF](https://arxiv.org/pdf/2507.02862), [HTML](https://arxiv.org/abs/2507.02862)
### Authors
Xiang Fan,Xiaohang Sun,Kushan Thakkar,Zhu Liu,Vimal Bhat,Ranjay Krishna,Xiang Hao
### Background
有效地处理时间冗余仍然是学习视频模型的关键挑战。当前的主要方法通常将每组帧独立处理，无法有效捕捉视频中存在的时间依赖性和冗余性。为了克服这一局限性，引入了RefTok，这是一种新的参考驱动的分词方法，能够捕捉复杂的时序动态和上下文信息。RefTok基于未量化参考帧对帧组进行编码和解码，在解码时保持帧间运动的连续性和物体外观的一致性。例如，尽管头部运动，RefTok仍保留面部细节；正确重建文本；保持小图案；从上下文保留手写文字的可读性。
### Innovation
RefTok通过引入一个新的基于参考的分词方法来捕捉复杂的时序动态和上下文信息，解决了当前方法无法有效捕捉时间依赖性和冗余性的局限性。该方法通过参考帧编码和解码帧组，并在解码时保持帧间的运动连续性和物体的外观一致性。RefTok在四个视频数据集（K600、UCF-101、BAIR Robot Pushing和DAVIS）上均明显优于现有的最先进的视频分词方法（Cosmos和MAGVIT），提高了所有评测指标（PSNR、SSIM、LPIPS）的分数，平均提高了36.7%。此外，在BAIR Robot Pushing任务上使用RefTok的隐状态进行视频生成时，生成结果不仅优于MAGVIT-B，也优于参数量是其四倍的MAGVIT-L，平均改善幅度为27.9%。
### Conclusion
RefTok在处理视频生成中的时间冗余方面表现出色，能够显著提高视频质量，并在多个性能指标上超越现有的先进方法。其基于参考帧的编码和解码方法不仅能够保持帧间的时空连续性，还能有效处理复杂的动态信息和上下文信息。
## 367. `cs.CV` - Energy-Based Transformers are Scalable Learners and Thinkers [PDF](https://arxiv.org/pdf/2507.02092), [HTML](https://arxiv.org/abs/2507.02092)
### Authors
Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal
### Background
推理时的计算技术类比于人类的系统2思考，近年来被用于提升模型性能，但大多数现有方法存在多种限制，例如模态特定性、问题特定性以及需要额外监督或训练。本文探讨是否可以将这些系统2思考的方法进行泛化，使模型能够仅通过无监督学习来学习思考。
### Innovation
提出了一种新的能量基模型，称为Energy-Based Transformers (EBTs)，它们能够赋予输入和候选预测每对能量值，通过梯度下降法进行能量最小化，从而实现在推理时的性能提升。EBTs在训练和推理过程中显示了优于Transformer++等现有模型的性能，特别是在数据、批大小、参数、FLOPs和深度方面的扩展率上提升了35%，并且在文本任务和图像去噪任务中表现突出。此外，实验表明EBTs在大多数下游任务中表现优于现有模型，即使预训练性能稍微差一些，这也表明EBTs具有更好的泛化能力。
### Conclusion
EBTs是新的模型范式，具有扩展学习和思考能力的潜力。
## 368. `cs.CV` - 生成型潜在扩散以实现高效时空数据缩减 [PDF](https://arxiv.org/pdf/2507.02129), [HTML](https://arxiv.org/abs/2507.02129)
### Authors
Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka
### Background
生成模型在条件设置中表现出强大的性能，可以被视为一种数据压缩形式，其中条件充当紧凑的表示。然而，其有限的可控性和重建准确性限制了它们在数据压缩中的实际应用。现有的方法存在间隙，即在可控性和重建准确性方面存在局限性，影响了它们在数据压缩中的应用.
### Innovation
本文提出了一种高效的潜在扩散框架，通过结合变分自编码器和条件扩散模型来弥合这一缺口。该方法仅将少量关键帧压缩到潜在空间，并使用它们作为条件输入，通过生成性插值重建剩余帧，从而消除了每帧都要存储潜在表示的需求。这种方法能够在大幅减少存储成本的同时实现准确的时空重建.
### Conclusion
在多个数据集上的实验结果表明，该方法的压缩比率最高可比基于规则的最先进的压缩器（如SZ3）高出10倍，并且与同类学习方法在相同的重建误差下相比，性能提高了63%。
## 369. `cs.CV` - Point3R: 使用显式空间指针记忆的增量三维重建 [PDF](https://arxiv.org/pdf/2507.02863), [HTML](https://arxiv.org/abs/2507.02863)
### Authors
Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu
### Background
从有序序列或无序图像集合进行稠密三维场景重建是将计算机视觉研究推向实际场景的关键步骤。虽然DUSt3R等方法将两幅图像稠密统一到共享坐标系统中，并且后续方法保持一定程度的隐式记忆来处理更多图像的稠密重建，但这些隐式记忆存在容量有限和早期图像信息丢失的问题。
### Innovation
本文提出Point3R，一种用于稠密流式三维重建的在线框架。具体而言，该方法维护一个直接关联当前场景三维结构的显式空间指针记忆。每个指针对应一个特定三维位置，并在全球坐标系统中聚集附近的场景信息，以动态空间特征形式变化。来自最新帧的信息明确与该指针记忆交互，能够将当前观察结果稠密整合到全球坐标系统中。为此，作者设计了三维分层位置嵌入以促进交互，并设计了一个简单有效的融合机制，以确保指针记忆的均匀和高效性。
### Conclusion
本文方法在各种任务上实现竞争力甚至领先水平的性能，同时训练成本较低。源代码可从：this https URL获取。
## 370. `cs.CV` - 概念漂移下的适用于自适应内存重新定位的整体连续学习 [PDF](https://arxiv.org/pdf/2507.02310), [HTML](https://arxiv.org/abs/2507.02310)
### Authors
Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk
### Background
传统连续学习方法倾向于知识保留，主要关注消除灾难性遗忘，但隐含地假设以前学习任务的数据分布保持静态。这忽略了现实世界数据流的动态性质，数据概念漂移永久改变了之前看到的数据，需要稳定性和快速适应的双重需求。
### Innovation
文章提出了一种整体框架，用于处理概念漂移的连续学习，通过进化任务分布模拟现实场景。作者引入了一种轻量级方法——自适应记忆重新定位（AMR），为基于回顾的 learners 提供一种概念漂移感知的适应机制。AMR 会从重放缓冲区中删除过时的漂移类样本，并重新填充少量最新的实例，以有效重新定位记忆与新的数据分布。这种方法的性能与全重新学习相当，但显著减少了对标注数据和计算的需求。
### Conclusion
通过引入四个标准视觉基准的概念漂移变体数据集：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD 和 Tiny-ImageNet-CD，实验证明了AMR的一致优势，可以保持高准确性的同时大大减少开销。这些结果将AMR定位为一种可扩展的解决方案，能够平衡非平稳连续学习环境中的稳定性和可塑性。
## 371. `cs.CV` - 公平的Deepfake检测器能够泛化 [PDF](https://arxiv.org/pdf/2507.02645), [HTML](https://arxiv.org/abs/2507.02645)
### Authors
Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli
### Background
Deepfake检测模型面临两个关键挑战：对未见过的操作进行泛化以及对人口群体进行公平性保障。现有方法往往显示出这两个目标是内在冲突的，揭示了它们之间的权衡关系。
### Innovation
本文首次揭示并正式定义了公平性和泛化之间的因果关系。基于后门调整技术，通过控制混杂因素（数据分布和模型容量），实现通过公平干预增强泛化。作者提出了Demographic Attribute-insensitive Intervention Detection (DAID) 框架，包含（i）人口特征自适应的数据重新平衡，以及（ii）人口特征无关特征聚合，显著提高了公平性和泛化性。
### Conclusion
DAID在三个跨域基准测试中，均优于多项最先进的检测器，在公平性和泛化性方面均表现出色，验证了其理论基础和实际有效性。
## 372. `cs.CV` - CineMyoPS: 从心脏MRI视频中分割心肌病灶 [PDF](https://arxiv.org/pdf/2507.02289), [HTML](https://arxiv.org/abs/2507.02289)
### Authors
Wangbin Ding,Lei Li,Junyi Qiu,Bogen Lin,Mingjing Yang,Liqin Huang,Lianming Wu,Sihan Wang,Xiahai Zhuang
### Background
心肌梗死（MI）是全球导致死亡的主要原因之一。晚期钆增强（LGE）和T2加权心脏磁共振（CMR）成像可以分别识别瘢痕和水肿区域，这些都是MI风险分层和预后评估的关键。尽管从多序列CMR中结合互补信息是有用的，但获取这些序列可能耗时且昂贵，特别是在对比剂的使用上。心脏MRI视频可快速且无需对比剂地展示由急性MI引起的心肌运动和结构异常。因此，本文提出了一种端到端的深度神经网络，称为CineMyoPS，仅从心脏MRI视频图像中分割心肌病理学病灶，即瘢痕和水肿，并提取与MI相关的运动和解剖特征。
### Innovation
CineMyoPS采用了联合学习策略，通过设计一致性损失来促进运动和解剖特征的联合学习，并提出了时序聚合策略来整合心脏循环中的MI相关特征，从而提高心肌病理学分割的准确性。利用多中心数据集进行的实验结果表明，CineMyoPS在心肌病理学分割、运动估算和解剖学分割方面表现出有 promise 的性能。
### Conclusion
CineMyoPS能够仅从心脏MRI视频图像中精确地分割心肌病理学病灶，通过同时提取与心肌梗死相关的运动和解剖特征，能够有效地提高分割的准确性。
## 373. `cs.CV` - 一种用于动态小动物$^{18}$F-FDG正电子发射断层成像动脉输入函数预测的稳健且通用深度学习模型 [PDF](https://arxiv.org/pdf/2507.02367), [HTML](https://arxiv.org/abs/2507.02367)
### Authors
Christian Salomonsen,Luigi Tommaso Luppino,Fredrik Aspheim,Kristoffer Wickstrøm,Elisabeth Wetzer,Michael Kampffmeyer,Rodrigo Berzaghi,Rune Sundset,Robert Jenssen,Samuel Kuttner
### Background
正电子发射断层成像(PET)和动力学建模对于小动物研究中的示踪剂开发研究至关重要。准确的动力学建模需要精确的输入函数估计，传统上通过动脉血样获取。然而，小动物（如小鼠）的动脉穿刺涉及复杂、耗时且通常是致死性程序，不利于进行长期研究。
### Innovation
本研究提出了一种无需侵入且基于深度学习的非侵入性方法（FC-DLIF），能够直接从PET影像中预测输入函数，从而可能消除对血液采样的需求。该方法包括空间特征提取器和时间特征提取器，分别处理PET序列的体素时间帧和预测动脉输入函数。通过交叉验证训练和评估模型，并用不同示踪剂（$^{18}$F-FDOPA和$^{68}$Ga-PSMA）的影像数据和动脉血曲线进行进一步评估。
### Conclusion
提出的FC-DLIF模型在均方误差和相关性方面可靠地预测了动脉输入函数。此外，该模型甚至可以从被截断和时间移位的样本中预测动脉输入函数。尽管如此，该模型无法从未包含在训练数据中的不同示踪剂样本中预测动脉输入函数。深度学习方法为动脉输入函数预测提供了非侵入且可靠的替代方案，证明具有较好的时间和扫描持续时间鲁棒性和灵活性。
## 374. `cs.CV` - 从稀疏无姿态依赖的2D超声心动图切片重建3D心脏 [PDF](https://arxiv.org/pdf/2507.02411), [HTML](https://arxiv.org/abs/2507.02411)
### Authors
Zhurong Chen,Jinhua Chen,Wei Zhuo,Wufeng Xue,Dong Ni
### Background
超声心动图（Echo）在心脏疾病的临床实践中发挥着不可或缺的作用。但是，超声成像通常只能提供少量特定视角的二维（2D）切片图像，这使得解释和估计如左心室（LV）体积等临床参数具有挑战性并且不准确。3D超声成像可提供3D定量替代方案，但仍然受限于低的空间和时间分辨率以及高度繁琐的手动勾勒。
### Innovation
为了应对这些挑战，作者提出了一种创新的框架，用于从常用临床实践中的2D Echo切片重构个性化3D心脏解剖结构。此框架设计了一个新的3D重建管道，该管道交替优化这些2D切片的3D姿势估算和3D整合，使用隐式神经网络逐步将先验3D心脏形状转变成个性化3D心脏模型。
### Conclusion
该方法在两个数据集上得到了验证。当使用六个切面时，重建的3D心脏在左心室（LV）体积估计上比双平面方法显著改善（误差百分比：1.98% 对比 20.24%）。此外，整个重建框架即使能够从2D Echo切片估计右心室（RV）体积（误差为5.75%）。本研究为心脏超声的个性化3D结构和功能分析提供了新方法，并且在临床实践中有巨大的潜在价值。
## 375. `cs.CV` - MEGANet-W: Wavelet-驱动边缘注意框架用于弱边界息肉检测 [PDF](https://arxiv.org/pdf/2507.02668), [HTML](https://arxiv.org/abs/2507.02668)
### Authors
Zhe Yee Tan
### Background
结肠息肉分割对于早期发现结肠癌至关重要，但由于弱对比度和低对比度边缘，自动化的准确性受到限制。现有深度模型要么模糊细边缘细节，要么依赖于表现不佳的手工制作滤波器。在不同的成像条件下，这些滤波器的性能较差。因此，需要新的技术来克服这些问题，提高息肉分割的准确性。
### Innovation
本文提出了MEGANet-W，这是一种基于小波驱动的边缘引导注意力网络。该网络在每个解码阶段注入方向性、参数自由的小波边缘图，以重新校准语义特征。研究的主要贡献包括（1）多方向边缘提取的两级小波头部；（2）波小波边缘引导注意（WEGA）模块，该模块融合了反向和输入分支的波小波提示。与现有方法相比，MEGANet-W 在五个公开的结肠息肉数据集上表现更优，mIoU 提高了最高 2.3%，mDice 提高了 1.2%，并且没有增加任何可学习的参数。
### Conclusion
实验结果表明，MEGANet-W 在多个公开的数据集上显著优于现有的方法，具有更好的息肉分割精确度，且模型结构简单，易推广使用。
## 376. `cs.CV` - L-VAE: 可学习β的变分自编码器用于消解表示 [PDF](https://arxiv.org/pdf/2507.02619), [HTML](https://arxiv.org/abs/2507.02619)
### Authors
Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural
### Background
η-VAE等现有模型通过调整超参数来尝试在重建损失和消解损失之间动态平衡。然而，这些模型在处理这种平衡时存在限制，尤其是对超参数的调整依赖于经验设定，缺乏自动学习机制。本文的背景在于探索一种能够自动学习损失函数中各项权重的新模型，以提高变分自编码器（VAE）在消解表示方面的效果。
### Innovation
提出了一种名为Learnable VAE (L-VAE)的新模型，能够在学习数据表示的同时学习成本函数的超参数。与η-VAE相比，L-VAE通过学习损失函数中各项的相对权重来动态调整重建损失和消解损失之间的平衡，而不需要手动调整超参数。此外，L-VAE还引入了一个额外的正则化项，以防止偏向于重建损失或消解损失，从而更稳定地实现两者之间的平衡。实验结果显示，L-VAE在多个数据集上表现出了更优的消解表示效果，尤其是在几个不同的评估指标上取得了最佳或第二佳性能。
### Conclusion
通过实验比较，L-VAE在多个数据集上的表现优于η-VAE、VAE、ControlVAE、DynamicVAE和σ-VAE等多种基线模型，尤其是在稳定性和消解表示精度方面。此外，定性的实验结果也证实了L-VAE在面部属性消解方面的成功应用，表明其具有良好的实际应用潜力。
## 377. `cs.CV` - DoMIX：一种用于微调领域知识高效框架 [PDF](https://arxiv.org/pdf/2507.02302), [HTML](https://arxiv.org/abs/2507.02302)
### Authors
Dohoon Kim,Donghun Kang,Taesup Moon
### Background
Domain-Adaptive Pre-training (DAP) 已因其在预训练模型微调中的有效性而受到关注。现有的持续 DAP 方法存在一些局限性：（1）训练期间高计算成本和 GPU 内存使用；（2）对增量数据顺序敏感；（3）提供单一的通用模型用于所有终任务，这与 DAP 的根本理念相悖。
### Innovation
本文提出了一种名为 DoMIX 的新方法，通过利用 LoRA 模块（一种代表性的参数高效微调方法），有效解决了上述挑战。该方法实现了高效且并行的 DAP，并对领域顺序具有鲁棒性，能够充分利用积累的知识，为特定任务提供定制化的预训练模型。此外，还展示了该方法可以扩展到标准的 LLM 微调场景。
### Conclusion
我们提出的方法 DoMIX 通过利用 LoRA 模块，有效地解决了现有 DAP 方法中的挑战，并演示了其在 DAP 和标准 LLM 微调场景中的应用潜力。
## 378. `cs.CV` - 基于嵌入的差分隐私条件VAEs的联邦数据共享 [PDF](https://arxiv.org/pdf/2507.02671), [HTML](https://arxiv.org/abs/2507.02671)
### Authors
Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig
### Background
深度学习（DL）已革新了医学影像领域，但其应用受到数据稀缺性和隐私法规的限制，限制了对多样数据集的访问。联邦学习（FL）能够实现去中心化的训练，但其通信成本高，通常仅限于单一下游任务，降低了灵活性。
### Innovation
提出了一种通过差分隐私生成模型进行数据共享的方法。采用基础模型提取压缩且富有信息性的嵌入，减少冗余，并降低计算开销。客户端共同训练差分隐私条件变分自编码器（DP-CVAE），以建模全局隐私感知的数据分布支持多样下游任务。这种方法跨多个特征提取器验证有效，提升了隐私保护、可扩展性和效率，同时优于传统的FL分类器，并确保了差分隐私。此外，与差分隐私条件生成对抗网络（DP-CGAN）相比，DP-CVAE生成更高的质量嵌入，仅需5倍更少的参数数量.
### Conclusion
该方法在多特征提取器验证中提升了隐私、可扩展性和效率，优于传统FL分类器，同时保证了差分隐私。此外，DP-CVAE生成的嵌入质量高于DP-CGAN，所需参数更少。
## 379. `cs.CV` - MISCGrasp：利用多尺度集成和对比学习增强体素抓取能力 [PDF](https://arxiv.org/pdf/2507.02672), [HTML](https://arxiv.org/abs/2507.02672)
### Authors
Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang
### Background
机器人抓取在适应不同形状和大小的物体方面面临挑战。为此，本文提出了一种名为MISCGrasp的体积抓取方法，该方法结合了多尺度特征提取与对比特征增强，以实现自适应抓取。MISCGrasp通过Insight Transformer实现高层和低层特征的查询式交互，而Empower Transformer选择性地关注最高层特征，实现了对精细几何细节和总体几何结构的协同平衡。
### Innovation
MISCGrasp采用多层次对比学习，利用正向抓取样本中的相似性，确保多尺度特征的一致性。通过Insight Transformer和Empower Transformer，实现了高层和低层特征之间的交互，以及对精细几何细节和总体几何结构的有效处理，从而提高了体积抓取的性能。
### Conclusion
在模拟和现实环境下的实验表明，MISCGrasp在桌面去杂任务中优于基准方法和变体方法。有关更多详细信息，请访问此链接：this https URL.
## 380. `cs.CV` - 实时基于图像的光照模型实现闪亮效果 [PDF](https://arxiv.org/pdf/2507.02674), [HTML](https://arxiv.org/abs/2507.02674)
### Authors
Tom Kneiphof,Reinhard Klein
### Background
基于图像的光照是一种广泛应用于实时渲染应用中重现现实世界光照条件下的阴影效果的技术。尤其是对于表现出闪烁或反光外观的材料，这些特征是由于其表面上大量微小的反光点引起的，这种现象特别具有挑战性。本文研究了如何在确保材料属性和环境贴图全动态调整的同时，高效地模拟这种闪烁效果。
### Innovation
提出了一个新的用于实时光照效果（特别是闪亮效果）的高效近似方法，该方法能够在每帧的基础上快速执行环境贴图滤波过程，从而使得材料属性发生变化时仍然保持稳定的性能。具体而言，该方法假设环境贴图被划分为有限的均匀区域，并通过微小特征对于各个区域的反射概率进行计算，进而按概率进行分布采样，实现了高效稳定的实时闪亮效果渲染。
### Conclusion
该方法在多种材料属性和光照条件下，与真实的渲染结果接近。同时，该方法虽然需要使用双倍的内存来存储预过滤的环境贴图，但在实时性能上的表现依然较为稳健，具有较低的额外开销。
## 381. `cs.CV` - 向XAI系统用户信任的新度量方法迈进 [PDF](https://arxiv.org/pdf/2405.05766), [HTML](https://arxiv.org/abs/2405.05766)
### Authors
Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho
### Background
随着深度学习模型在各个领域中的广泛应用，透明度不足成为影响用户信任的重要问题。为了解决这一问题，出现了一门新的学科领域——可解释AI（XAI），旨在通过提供决策背后的见解来增强用户的信任。本文在此背景下，提出了一个新的信任度量方法，综合了性能指标和客观的信任指标，以改进XAI系统的性能。
### Innovation
提出了一种新型的信任度量方法，该方法结合了性能指标和客观的信任指标，从客观的角度对XAI系统进行改进。通过三项案例研究验证了该方法的优越性，相对于当前最先进的方法，其具有更高的敏感性，能更好地适应不同的情境。
### Conclusion
本文提出了一种新的用户信任度量方法，并通过案例研究验证了其有效性。该方法综合了性能指标和信任指标，从而能够更好地评估XAI系统的性能和可用性。 future research could explore more sophisticated methods and scenarios for improving user trust in XAI.
## 382. `cs.CV` - TiCoSS: 在联合学习框架中加强语义分割和立体匹配之间的耦合 [PDF](https://arxiv.org/pdf/2407.18038), [HTML](https://arxiv.org/abs/2407.18038)
### Authors
Guanfeng Tang,Zhiyuan Wu,Jiahang Li,Ping Zhong,We Ye,Xieyuanli Chen,Huiming Lu,Rui Fan
### Background
语义分割和立体匹配分别类比于人脑的背侧和腹侧路径，在自主驾驶感知系统中是两个关键组成部分。目前，使用分离网络处理这两个任务的做法已不再是主流，尤其是在大型视觉模型和具身人工智能的最新进展下，将两个任务在联合学习框架中结合并强调特征共享成为了趋势。现有的研究旨在通过更紧密地整合语义分割和立体匹配，提出了一种新颖的联合学习框架——TiCoSS，提高了性能并验证了其有效性，特别是在KITTI和vKITTI2数据集上的实验中，mIoU提高了超过9%。
### Innovation
该研究提出了三个创新点：(1) 一种紧密耦合的门控特征融合策略，(2) 一种分层深度监督策略，以及(3) 一种耦合强化损失函数。
### Conclusion
通过在广泛的实验中应用这些技术贡献，提出了TiCoSS，这是一种最先进的联合学习框架，能够同时解决语义分割和立体匹配问题。通过KITTI和vKITTI2数据集上的详细实验和分析，验证了所开发策略和损失函数的有效性，并展示了其在性能上的优越性，与先前的方法相比，mIoU提高了超过9%。该研究的原始代码将在发表后在该链接公开。
## 383. `cs.CV` - 轻量级结构感知注意力机制 [PDF](https://arxiv.org/pdf/2211.16289), [HTML](https://arxiv.org/abs/2211.16289)
### Authors
Heeseung Kwon,Francisco M. Castro,Manuel J. Marin-Jimenez,Nicolas Guil,Karteek Alahari
### Background
注意力操作器因其可调整的核而被广泛用于视觉理解中，但存在局限性：(1) 注意力核不够有区分性，导致高冗余度；(2) 在序列长度上的计算和内存复杂度为平方级别。
### Innovation
提出了新型注意力操作器，称为轻量级结构感知注意力（LiSA），具有对数线性复杂度，并通过学习结构模式更好地表示注意力核。使用相对位置嵌入（RPEs）作为乘性权重编码结构模式，提高注意力核的表示能力，并通过近似RPEs降低复杂度至对数线性级。
### Conclusion
实验和分析表明，提出的操作器优于自注意力和现有操作器，取得了在ImageNet-1K和其他下游任务（如Kinetics-400视频动作识别、COCO目标检测与实例分割、ADE-20K语义分割）上的最先进的结果。
## 384. `cs.CV` - MV2DFusion: 利用模态特定对象语义实现多模态3D检测 [PDF](https://arxiv.org/pdf/2408.05945), [HTML](https://arxiv.org/abs/2408.05945)
### Authors
Zitian Wang,Zehao Huang,Yulu Gao,Naiyan Wang,Si Liu
### Background
自动驾驶车辆的兴起显著增加了对稳健的3D物体检测系统的需求。尽管摄像机和激光雷达传感器各有优势，但单一模态往往会导致性能限制。摄像机提供了丰富的纹理信息，而激光雷达提供了精确的三维空间数据。因此，需要一种结合多种模态优势的方法来提升3D物体检测性能。
### Innovation
本论文引入了MV2DFusion系统，这是一个多模态检测框架，通过先进的基于查询的融合机制，结合了图像和点云的特定优势。该系统包含图像查询生成器和点云查询生成器，能够在不偏向任何单一模态的情况下，有效地结合模态特定的对象语义。此外，该框架的灵活性使得它可以与其他任何基于图像和点云的检测器兼容，展示了其适应性和未来发展的潜力。广泛的评估表明，MV2DFusion在nuScenes和Argoverse2数据集上实现了最先进的性能，尤其在长距检测场景中表现出色。
### Conclusion
我们的框架在各种场景中实现了高效且准确的3D物体检测，并通过对nuScenes和Argoverse2数据集的广泛评估，证实了其在长距检测中的优越性能。
## 385. `cs.CV` - DeltaEdit: 探索无文本训练以实现文本驱动的图像编辑 [PDF](https://arxiv.org/pdf/2303.06285), [HTML](https://arxiv.org/abs/2303.06285)
### Authors
Yueming Lyu,Tianwei Lin,Fu Li,Dongliang He,Jing Dong,Tieniu Tan
### Background
文本驱动的图像修改在训练和推理灵活性上仍具有挑战性。条件生成模型依赖昂贵的带有标注的训练数据。最近的框架依赖于预先训练的视觉语言模型，但在文本提示优化和推理时超参数调整方面存在局限性。
### Innovation
我们提出了名为DeltaEdit的新型框架，旨在解决上述问题。DeltaEdit的关键理念是研究并确定一个空间——即delta图像和文本空间，该空间中CLIP视觉特征差异和CLIP文本嵌入差异之间的分布是高度对齐的。基于CLIP delta空间，DeltaEdit网络被设计用来在训练阶段将CLIP视觉特征差异映射为StyleGAN的编辑方向。在推理阶段，它根据CLIP文本特征差异预测 StyleGAN的编辑方向。通过这种方式，DeltaEdit能够在无文本的情况下进行训练，并且训练完成后，可以零样本条件下对各种文本提示进行良好的泛化，无需额外调整参数。
### Conclusion
一旦训练完成，DeltaEdit能够在零样本条件下对各种文本提示进行图像编辑，而无需额外的调优，展示了强大的灵活性和泛化能力。
## 386. `cs.CV` - 适用于心脏超声探头操作引导的序列感知预训练 [PDF](https://arxiv.org/pdf/2408.15026), [HTML](https://arxiv.org/abs/2408.15026)
### Authors
Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang
### Background
心脏超声检查是诊断心血管疾病的重要医疗技术，但其高操作复杂性导致了合格专业人员的短缺。心脏结构复杂，个体差异显著，现有的方法只能学习平均心脏结构，而无法适应个性化的心脏结构，限制了其性能。超声检查过程中，操作者会根据先前的扫描序列动态调整对患者心脏解剖结构的理解，并据此调整扫描策略。
### Innovation
提出了一种新型的序列感知自我监督预训练方法，通过在扫描序列中预测被遮掩的图像特征和探头移动行为来学习个性化的心脏三维结构特征。该方法假设如果模型能够预测丢失的内容，说明它已经很好地理解了个性化的心脏结构。实验结果表明，与其它先进基线方法相比，所提序列感知范式能够有效减少探头引导错误。
### Conclusion
在大规模专家扫描数据集（含131万个样本）上的广泛实验表明，所提出的序列感知预训练方法能够有效降低探头引导错误，优于其他先进基准方法。
## 387. `cs.CV` - 将智能扎根于运动 [PDF](https://arxiv.org/pdf/2507.02771), [HTML](https://arxiv.org/abs/2507.02771)
### Authors
Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording
### Background
近年来，机器学习的进展极大地提高了我们建模语言和高维数据的能力，但对于生物学系统中最重要的方面之一——运动——仍然存在挑战。运动在神经科学、医学、机器人学和行为学中至关重要，用于解释行为、预测意图和促进互动。尽管运动对我们的智力至关重要，但它经常被视为附加的内容，而不是作为一种独立丰富的模态来处理。这反映了运动数据收集和建模中的深层次碎片化，通常受限于特定任务的目标和特定领域的假设。然而，运动并不局限于某一领域，它反映了共享的物理限制、保守的形态结构以及跨物种和环境的目的动态。论文认为运动应该被视为人工智能的主要建模目标。由于其内在结构、基于物质和物理的根植，它允许紧凑的、低维的表示（例如姿态），从而使运动模型更易于理解和计算。开发可以从和跨多种运动数据中学习并泛化的模型不仅会推进生成建模和控制的核心能力，还会为跨生物和人工系统理解行为提供共享基础。运动不仅仅是结果，它是智能系统如何与世界互动的一个窗口。
### Innovation
该研究主张将运动作为人工智能的主要建模目标，强调运动的结构化和基于物质及物理的本质。这种观点有助于更有效地处理复杂的高维数据，并通过减少数据维度提供更优的模型泛化性能，同时也强调了运动数据在跨领域的统一建模中的重要性，为生物和人工系统行为的理解提供了一个共享基础。
### Conclusion
论文总结指出，运动不仅是智能系统行为的结果，更是一个了解这些系统如何与世界互动的窗口。通过将运动视为主要建模目标，不仅能推进生成建模与控制等核心能力，还能够提供一个理解生物和人工系统行为的共同基础，从而推动跨学科的研究进步。
## 388. `cs.CV` - 评估笔记本翻新软件的不确定性与鲁棒性 [PDF](https://arxiv.org/pdf/2409.03782), [HTML](https://arxiv.org/abs/2409.03782)
### Authors
Chengjie Lu,Jiahui Wu,Shaukat Ali,Mikkel Labori Olsen
### Background
笔记本电脑翻新不仅能延长其使用寿命，还能减少电子废弃物，有助于构建可持续的未来。在这个背景下，丹麦技术研究所（DTI）专注于研究和开发机器人技术，特别是使用软件来翻新笔记本电脑。笔记本翻新中的一个关键步骤是清洁，这涉及识别和移除笔记本表面的标签。软件在清洁过程中起着重要作用，可以通过集成多种对象检测模型来自动识别和移除标签。然而，由于标签种类多样（如形状、颜色、位置），标签识别具有高度不确定性，需要明确量化这种不确定性以减少移除标签时的风险，例如避免因软件错误导致笔记本表面损坏。为了量化不确定性，该研究采用了蒙特卡洛丢弃方法，评估了DTI提供的六种标签检测模型（SDMs），使用了原始图像数据集以及通过视觉语言模型生成的DALL-E-3和Stable Diffusion-3两个数据集。此外，还提出了与检测准确性和不确定性相关的新型鲁棒性指标，基于使用密集对手方法生成的对抗性数据集评估了这些SDMs的鲁棒性。评估结果显示，不同的SDMs在不同指标下的性能不同。
### Innovation
该研究引入了使用蒙特卡洛丢弃方法来量化标签检测模型在面对不同标签类型时的不确定性，并提出了与检测准确性和不确定性相关的新型鲁棒性指标。这些创新有助于更全面地评估和改善软件的鲁棒性和准确性，减少移除标签过程中的风险。
### Conclusion
评估结果显示，不同的标签检测模型在不同指标下的性能不同。基于这些结果，提供了模型选择指南，并从多个视角总结了所学的经验和教训。
## 389. `cs.CV` - SURE-VQA: 系统理解医学VQA任务中鲁棒性评估 [PDF](https://arxiv.org/pdf/2411.19688), [HTML](https://arxiv.org/abs/2411.19688)
### Authors
Kim-Celine Kahl,Selen Erkan,Jeremias Traub,Carsten T. Lüth,Klaus Maier-Hein,Lena Maier-Hein,Paul F. Jaeger
### Background
视觉-语言模型（VLMs）在医疗任务中具有巨大潜力，如视觉问答（VQA），它们可以作为患者和临床医生的交互式助手。然而，它们在未见过的数据上的鲁棒性（特别是在分布偏移方面）依然是确保安全部署的关键关注点。目前的实验设置未能提供充分的评估，这为建立一个能够系统地分析VLM鲁棒性的新框架提供了必要性。研究指出，在合成偏移上的鲁棒性不一定能直接应用于实际偏移，需要在与VQA数据固有的真实性偏移进行评估。传统的标记匹配度量往往难以捕捉潜在的语义，因此需要使用大型语言模型进行更准确的语义评估。此外，缺乏可解释性的模型性能也缺乏常态基线，因此需要报告有意义的基线，以为评估多模态对VLM的影响提供依据。这项研究旨在通过具体实验数据支持这些观点。
### Innovation
本研究提出了一个新的框架，称为SURE-VQA，主要围绕三个关键要求来弥补当前评估中的缺陷并系统地分析VLM的鲁棒性：1. 测试鲁棒性应基于与VQA数据固有的真实偏移; 2. 需要使用大型语言模型来代替传统的标记匹配度量以更准确地评估语义; 3. 报告有意义的基线，以评估多模态对VLM的影响，而不仅仅是通过图像数据来衡量。这项研究通过在三个医疗数据集上对四种类型分布偏移见各种微调方法的鲁棒性进行研究，得出了这些见解。研究发现，没有一种微调方法能在所有情况下都表现得更好，并且微调方法在鲁棒性方面的趋势比分布偏移更稳定。此外，简单的不使用图像数据的基线效果出人意料地好，并且确认了LoRA作为内分布数据上表现最好的微调方法。
### Conclusion
研究通过SURE-VQA框架在三个医疗数据集上证明了鲁棒性的重要性，没有一种微调方法能在所有情况下都表现得更好，但在分布偏移方面的趋势比微调方法更稳定。简单不使用图像数据的基线效果出人意料地好，并确认LoRA为内分布数据上表现最好的微调方法。
## 390. `cs.CV` - LLaVA-KD: 蒸馏多模态大型语言模型的一种框架 [PDF](https://arxiv.org/pdf/2410.16236), [HTML](https://arxiv.org/abs/2410.16236)
### Authors
Yuxuan Cai,Jiangning Zhang,Haoyang He,Xinwei He,Ao Tong,Zhenye Gan,Chengjie Wang,Zhucun Xue,Yong Liu,Xiang Bai
### Background
大型语言模型（LLMs）的成功推动了多模态大型语言模型（MLLMs）的发展，以便统一理解和处理视觉和语言。然而，大型多模态模型（l-MLLMs）的模型规模和计算复杂性限制了它们在资源受限场景中的应用。尽管设计了小型多模态模型（s-MLLMs）来减少计算成本，但这些小型模型通常会出现性能下降的问题。因此，需要一种方法来降低计算成本同时保持性能，以优化这些较小的模型。
### Innovation
本文提出了一个名为LLaVA-KD的新颖框架，用于从大型多模态模型向小型多模态模型传递知识。该框架包括引入多模态蒸馏（MDist）来跨视觉和语言模态传递教师模型的稳健表示，以及关系蒸馏（RDist）来传递教师模型捕捉视觉标记关系的能力。此外，提出了一种三个阶段的训练方案以充分利用提出的蒸馏策略的潜力：1）蒸馏预训练，以增强小型多模态模型中的视觉-语言表示对齐；2）监督微调，赋予小型多模态模型多模态理解能力；3）蒸馏微调，以精炼小型多模态模型的知识。这种方法在不改变模型架构的情况下显著提高了小型多模态模型的性能。实验证明并消融研究验证了每个组件的有效性。
### Conclusion
本文提出了一种新的蒸馏策略和三个阶段的训练方案，显著提高了小型多模态模型的性能，同时保持了资源效率。通过验证其在各种任务中的有效性，展示了该方法在降低计算成本和保持性能之间取得的平衡。
## 391. `cs.CV` - MultiGen: 使用多模态生成在模拟中学习多模态策略 [PDF](https://arxiv.org/pdf/2507.02864), [HTML](https://arxiv.org/abs/2507.02864)
### Authors
Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros
### Background
机器人必须整合多种感官模态才能在现实世界中有效地行动，但在大规模学习多模态策略方面仍然具有挑战性。模拟提供了一种可行的解决方案，但尽管视觉已经从高保真模拟器中受益，其他模态（例如声音）却难以模拟。因此，从模拟到现实世界的转移主要成功应用于视觉任务，多模态转移大多数尚未实现。该项工作旨在通过引入MultiGen框架来应对这些挑战，该框架将大规模生成模型与传统的物理模拟器集成，以实现跨感官模拟。在机器人倾倒这个动态任务上展示了该框架，该任务本质上依赖多模态反馈。通过在模拟视频上生成逼真的音频，该方法使我们在没有真实机器人数据的情况下能够进行视觉听觉轨迹上的训练。展示该方法在新型容器和液体下实现零样本转移至现实世界的倾倒任务，突显了生成模型在模拟难以建模的模态以及缩小多模态从模拟到现实差距中的潜力。
### Innovation
MultiGen框架将大规模生成模型与传统的物理模拟器集成，通过在模拟视频上生成逼真的音频，使训练可以在丰富的视觉听觉轨迹上进行，而无需实际机器人数据。这方法能够在现实世界中实现多模态任务的零样本转移，展示了生成模型在模拟难以建模的模态以及缩小从模拟到现实的世界差距中的潜力。
### Conclusion
该工作通过MultiGen框架成功地将多模态生成模型与传统物理模拟器集成，展示了从模拟到现实世界跨模态任务的零样本转移能力，为多模态模拟和实际应用提供了新的视角和方法。
## 392. `cs.CV` - 空间思维：多模态大型语言模型如何看待、记忆和回忆空间 [PDF](https://arxiv.org/pdf/2412.14171), [HTML](https://arxiv.org/abs/2412.14171)
### Authors
Jihan Yang,Shusheng Yang,Anjali W. Gupta,Rilyn Han,Li Fei-Fei,Saining Xie
### Background
人类具有通过顺序视觉观察记住空间的能力。然而，大型多模态语言模型（MLLMs），经过百万级视频数据集训练后，是否能够通过视频进行‘空间思维’？这篇论文介绍了一个新的视频基于的视觉-空间智能基准（VSI-Bench），包含超过5000个问题-答案对，并发现MLLMs在视觉-空间智能方面表现出色但仍然低于人类水平。研究发现，空间推理能力仍然是MLLMs达到更高基准性能的主要瓶颈，尽管如此，局部世界模型和空间意识在这些模型中也逐渐显现出来。尽管常用的语言推理技术（例如：因果链，自我一致性，思维树）无法提高性能，但在问答过程中显式生成认知地图提高了大型语言模型在空间距离方面的表现能力
### Innovation
提出了一个新的视频基于的视觉-空间智能基准（VSI-Bench），并系统研究了大型多模态语言模型在空间推理、记忆和回忆方面的表现。研究发现，虽然传统的语言推理技术无法提高空间能力，但显式生成认知地图的方法可以有效提升大型语言模型的空间理解能力
### Conclusion
大语言模型在视觉-空间智能方面虽然有竞争力，但也暴露了其在空间推理能力上的瓶颈。在问答过程中利用显式生成认知地图的方法可以有效提升其空间智能水平。未来研究需要更多地关注能提升空间推理能力的方法和技术。
## 393. `cs.CV` - 更公平的分析和人口统计学平衡的人脸生成以实现更公平的人脸验证 [PDF](https://arxiv.org/pdf/2412.03349), [HTML](https://arxiv.org/abs/2412.03349)
### Authors
Alexandre Fournier-Montgieux,Michael Soumm,Adrian Popescu,Bertrand Luvison,Hervé Le Borgne
### Background
人脸识别和验证是计算机视觉任务，其性能随着深度表示的引入而提高。然而，由于人脸数据的敏感性以及现实世界训练数据集中的偏差，这些问题受到了道德、法律和技术的挑战。生成式AI通过生成虚构身份来解决隐私问题，但公正问题仍然存在。现有的DCFace领先框架未能充分解决这个问题，因此本文提出了一种新的可控生成流水线来改进公正性。通过传统的公正性指标和基于逻辑模型和ANOVA的深入统计分析，本文证明了这种生成流水线在其他启发式公平缓解方法中表现出更佳的公正性改进，同时略微提高了基础性能。
### Innovation
提出了一种新的可控生成流水线，使用现有的DCFace SOTA框架，该流水线能够显著提高公平性，同时略微提高基线性能。还通过局部交叉分析和逻辑模型等方法进行了深入的统计分析，展示了其在处理公平性问题上的有效性。
### Conclusion
通过新的生成流水线，该研究提高了公平性评估和人脸生成的质量，这有助于实现更加公正的人脸验证系统。该流水线表明，在保留一定性能的同时，可以有效地减少由训练数据偏差引起的不太公平的问题。
## 394. `cs.CV` - ZeroStereo: 从单张图像进行零样本立体匹配 [PDF](https://arxiv.org/pdf/2501.08654), [HTML](https://arxiv.org/abs/2501.08654)
### Authors
Xianqi Wang,Hao Yang,Gangwei Xu,Junda Cheng,Min Lin,Yong Deng,Jinliang Zang,Yurui Chen,Xin Yang
### Background
最新的监督立体匹配方法在各种基准测试中取得了显著的性能提升，但在现实世界的场景中应用时仍面临挑战，因为缺乏标注的真实世界立体数据。
### Innovation
本文提出了一种名为ZeroStereo的新型立体图像生成管道，该管道能够从任意单图像中生成高质量的右图像。通过利用单目深度估计模型生成的伪深度图，ZeroStereo利用微调的扩散填充模型恢复缺失的细节并保持语义结构。此外，该方法还包括训练自由的置信度生成和自适应视差选择，分别缓解了不可靠伪标签的影响和防止过度遮挡和前景失真，从而确保视差分布的多样性与真实性。实验表明，在与Scene Flow相当的数据量下，使用该管道训练的模型实现了多项数据集上最先进的零样本泛化能力。
### Conclusion
实验结果表明，利用我们的管道训练的模型能够在多个数据集上实现最先进的零样本泛化能力，相比现有方法所需的标注数据量更少。
## 395. `cs.CV` - Adapter-Enhanced Semantic Prompting for Continual Learning [PDF](https://arxiv.org/pdf/2412.11074), [HTML](https://arxiv.org/abs/2412.11074)
### Authors
Baocai Yin,Ji Zhao,Huajie Jiang,Ningning Hou,Yongli Hu,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi
### Background
持续学习（CL）使模型能够适应不断变化的数据流。然而，传统的CL方法面临着灾难性遗忘的问题，新知识可能会覆盖之前学到的知识。为了解决这一问题，传统的做法通常是保留过去的旧数据或者在模型中增加新的分支来学习新知识，这些方法通常会带来较高的内存需求。
### Innovation
本文提出了一种新颖的轻量级CL框架——Adapter-Enhanced Semantic Prompting (AESP)，将提示调优和适配器技术结合起来。具体而言，AESP设计了语义导向的提示来增强视觉特征的泛化能力，并利用适配器高效地融合语义信息，旨在为持续学习任务学习更灵活的特征。此外，为了解决如何选择正确的任务提示以适应特征，本文还开发了一种新颖的匹配机制用于提示选择。
### Conclusion
在三个CL数据集上的大量实验表明，本文的方法在多个指标上表现良好，展示了其在CL领域的发展潜力。
## 396. `cs.CV` - 自我指导：自主增强流动和扩散生成 [PDF](https://arxiv.org/pdf/2412.05827), [HTML](https://arxiv.org/abs/2412.05827)
### Authors
Tiancheng Li,Weijian Luo,Zhiyang Chen,Liyuan Ma,Guo-Jun Qi
### Background
高质量的生成结果需要适当的方向策略，但是现有的方向策略要么需要特定的训练，要么依赖于扩散模型网络的强大归纳偏置，这可能会限制它们的应用范围。现有研究观察到，噪声级别的显著下降可以在更清洁的噪声下检测到伪影异常，基于此提出了一种新的方法以提高图像质量并抑制低质量样本的生成。这种方法仅依赖于其自身扩散模型在不同噪声级别下的采样概率，无需任何特殊训练，使其可以在与其他采样算法插件使用时保持灵活性。此外，还提出了一种更高效的自我指导方法SG-prev，通过重复用上一步的输出结果来避免重复增加采样时间。
### Innovation
提出了一种新的自我指导(SG)方法，通过抑制低质量样本的生成增强图像质量，其特点是不需要特定的训练，依赖于模型自身的采样概率并支持与其他采样算法的插件使用。此外还提出了SG-prev这一更为高效的近似方法，通过重复上一步的输出结果来减少采样时间。这些方法在文本到图像和文本到视频生成中表现优异，并且在生理上正确的人体结构生成方面也表现出色，即使使用最少努力也能够消除人体伪影。
### Conclusion
与现有的算法相比，SG在多个指标上表现出色，包括FID和人类偏好评分。SG-prev仅需一次前向传播就能超越基线和其他SG方法。此外，这两种方法在生成生理上正确的人体结构方面表现出了积极的效果，显示了它们在减少人体伪影方面的潜力。代码将在论文发表后开源。
## 397. `cs.CV` - 良好的表示，更优质的解释：卷积神经网络在基于变换器的遥感图像描述中的作用 [PDF](https://arxiv.org/pdf/2502.16095), [HTML](https://arxiv.org/abs/2502.16095)
### Authors
Swadhin Das,Saarthak Gupta,Kamal Kumar,Raksha Sharma
### Background
遥感图像描述（RSIC）是生成来自遥感图像的有意义描述的过程。近年来，编码器-解码器模型作为生成有意义描述的基础架构获得了显著的关注。尽管编码器提取图像的视觉特征并将其转化为紧凑表示，解码器利用这一表示生成连贯的文本描述，解码器在文本生成方面的研究较多，而编码器的研究相对较少，尽管其优化对于生成质量直接影响重大。鉴于此，本研究系统地评估了十二种不同的卷积神经网络（CNN）架构在基于变换器的编码框架中的效果，从而评估它们在RSIC中的有效性。
### Innovation
本研究通过在基于变换器的框架中系统性地评估十二种不同的卷积神经网络（CNN），为各种编码器提供详细的比较，以确定特定CNN架构如何显著提高生成的遥感图像描述的质量。研究不仅对表现最好的CNN进行了人工评估，还分析了不同的搜索策略（贪婪搜索和束搜索）的影响，以确保生成的最佳描述。研究结果强调了编码器选择在提高描述性能中的关键作用，证明特定的CNN架构能够显著提升生成的描述质量。
### Conclusion
本研究通过对多种编码器的详细比较，提供了有价值的意见，可指导基于变换器的图像描述模型的发展。
## 398. `cs.CV` - CAD-Editor: 基于定位再填充的自动训练数据合成的文本驱动CAD编辑框架 [PDF](https://arxiv.org/pdf/2502.03997), [HTML](https://arxiv.org/abs/2502.03997)
### Authors
Yu Yuan,Shizhao Sun,Qi Liu,Jiang Bian
### Background
计算机辅助设计（CAD）在各个行业中不可或缺。基于文本的CAD编辑，能够根据文本指令自动化修改CAD模型，具有巨大潜力但尚未得到充分探索。现有方法主要集中在设计变异生成或基于文本的CAD生成，要么缺乏文本控制的支持，要么忽视现有CAD模型作为约束。缺乏能够同时支持文本控制和约束现有CAD模型的方法。
### Innovation
本文提出了CAD-Editor，这是第一个基于文本的CAD编辑框架。为了解决训练时需要高需求的匹配三元组数据问题，提出了一种自动训练数据合成管道。该管道利用设计变异模型生成原始和编辑后的CAD模型配对，并使用大规模视觉-语言模型（LVLMs）总结它们之间的差异以生成编辑指令。为了解决基于文本的CAD编辑组合性质，提出了一个定位然后填充框架，将其分解为两个聚焦的子任务：定位需要修改的区域和用适当的编辑填充这些区域。大规模语言模型（LLMs）作为两个子任务的基础，利用其自然语言理解和CAD知识的能力。实验表明，CAD-Editor 在定量和定性方面都取得了优异性能。
### Conclusion
实验结果显示，CAD-Editor 在定量和定性方面都达到了卓越的性能。该代码可在以下链接找到：    url {this https URL}
## 399. `cs.CV` - 使用扩散模型进行数据扩充以提高胎儿平面分类准确性 [PDF](https://arxiv.org/pdf/2501.15248), [HTML](https://arxiv.org/abs/2501.15248)
### Authors
Yueying Tian,Elif Ucurum,Xudong Han,Rupert Young,Chris Chatwin,Philip Birch
### Background
超声成像是医学诊断中广泛应用的技术，特别是在胎儿健康评估方面。然而，高质量的标注超声图像获取有限，限制了机器学习模型的训练。本文研究了使用扩散模型生成合成超声图像的方法，以改善胎儿平面分类性能，这些合成图像首先是训练不同的分类器，然后使用真实图像进行微调。实验结果表明，将生成的图像纳入训练管道中，比单独使用真实图像进行训练更能提高分类准确性。该发现表明，使用扩散模型生成合成数据是克服超声医学成像中数据稀缺挑战的一种有价值的方法
### Innovation
提出使用扩散模型生成合成超声图像，通过将生成的图像纳入训练管道中来提高胎儿平面分类的准确性，这是改进超声成像中数据稀缺问题的一种创新性方法
### Conclusion
研究结果表明，将生成的图像纳入训练管道中，比单独使用真实图像进行训练更能提高分类准确性，生成合成数据使用扩散模型是克服超声医学成像中数据稀缺挑战的一种有价值的方法
## 400. `cs.CV` - 数据集蒸馏的演进：面向可扩展和普适性解决方案 [PDF](https://arxiv.org/pdf/2502.05673), [HTML](https://arxiv.org/abs/2502.05673)
### Authors
Ping Liu,Jiawei Du
### Background
数据集蒸馏是一种将大规模数据集浓缩为紧凑的合成表示的技术，已变得对于高效训练现代深度学习模型至关重要。早期的综述主要集中在2023年以前的发展，但本文全面回顾了最近的进步，特别是针对大规模数据集（如ImageNet-1K和ImageNet-21K）的可扩展性。研究还分类整理了进展为几个关键方法：轨迹匹配、梯度匹配、分布匹配、可扩展生成方法以及优化机制解耦。
### Innovation
本文介绍了突破性的创新成果，包括SRe2L框架用于高效且有效的数据集压缩，软标签策略大幅提高模型准确性，以及无损蒸馏技术在最大限度压缩数据的同时保持性能。除此之外，还探讨了克服对抗和后门攻击的鲁棒性、有效处理非IID数据分布等关键挑战，并指出其在视频和音频处理、多模态学习、医学成像和科学计算中的新兴应用，突显了其跨越多个领域的能力。
### Conclusion
通过提供广泛的表现比较和可操作的研究方向，本文为研究者和从业者提供了实用的见解，以推动更加高效和通用的数据集蒸馏，铺平了未来创新的道路。
## 401. `cs.CV` - COEF-VQ：通过级联多模态大语言模型框架实现高效视频质量理解 [PDF](https://arxiv.org/pdf/2412.10435), [HTML](https://arxiv.org/abs/2412.10435)
### Authors
Xin Dong,Sen Jia,Ming Rui Wang,Yan Li,Zhenheng Yang,Bingfeng Deng,Hongyu Xiong
### Background
近年来，随着多模态大型语言模型（MLLM）技术的发展，人们可以利用其视频理解能力进行多种分类任务。然而，在线部署MLLM时面临着巨大的GPU资源需求。在此背景下，本文提出了一种名为COEF-VQ的新颖级联MLLM框架，旨在优化视频质量理解的同时提高计算效率，确保模型在减少GPU使用的同时保持强大的分类性能。该框架引入了一种基于熵的预筛选阶段，通过优先处理不确定度高的样本进行深入分析，从而显著减少了GPU的使用，同时仍能满足全MLLM部署的高性能需求。
### Innovation
提出了COEF-VQ框架，该框架通过级联多模态大语言模型来实现高效的视频质量理解。框架中引入了一种基于熵的预筛选机制，优先处理高不确定度的样本，从而在减少GPU资源使用的同时，保持了与全MLLM部署相当的高性能。实验表明，COEF-VQ在两个内部视频质量理解任务中实现了显著的性能提升，并有效地降低了在线A/B测试中不适合内容的视频观看率，减少了9.9%。同时，持续的监控结果验证了该框架在实际应用中的有效性。
### Conclusion
通过将COEF-VQ框架部署到短视频平台的视频管理平台（VMP）上，并在两个内部任务中进行了详细的实验，证明了COEF-VQ在减少GPU消耗的同时，仍能保证视频质量理解的高性能。此外，该框架在在线A/B测试中有效降低了不当内容视频的观看率，进一步提升了平台的安全性，且没有影响用户参与度。发布后的监控结果证实了其在实际中的持续改进，验证了COEF-VQ的实际效果。
## 402. `cs.CV` - KeyNode-Driven Geometry Coding for Real-World Scanned Human Dynamic Mesh Compression [PDF](https://arxiv.org/pdf/2501.01717), [HTML](https://arxiv.org/abs/2501.01717)
### Authors
Huong Hoang,Truong Nguyen,Pamela Cosman
### Background
实时扫描的3D人体动态网格的压缩是当前研究的一个新兴领域，驱动因素包括远程存在、虚拟现实和3D数字流媒体等应用。虽然合成的动态网格通常具有固定的拓扑结构，但扫描的动态网格不仅在不同帧中拓扑变化，还伴有孔洞和离群值等扫描缺陷，增加了预测和压缩的复杂性。此外，由于人体网格结合了刚体和非刚体运动，这使得预测和编码比仅有刚体运动的物体更为困难。在这些挑战面前，本文提出了一种新的压缩方法，针对真实世界扫描的人体动态网格，利用嵌入的关键节点。每个顶点的时域运动被表示为来自相邻关键节点的变换的距离加权组合，只需要传输关键节点的变换。为了提升关键节点驱动预测的质量，引入了一种基于八叉树的残差编码方案和双向预测模式，采用来自双向的I-帧。
### Innovation
提出了针对真实世界扫描的人体动态网格的新压缩方法，利用嵌入的关键节点。每个顶点的时域运动被表示为来自相邻关键节点的变换的距离加权组合，仅需传输关键节点的变换。与现有的最佳方法相比，该方法在评估序列中平均节省了58.43%的比特率，特别是在低比特率方面表现出色。引入了基于八叉树的残差编码方案和双向预测模式，进一步提升了预测质量。
### Conclusion
本文提出的方法针对真实世界扫描的人体动态网格问题，在比特率节省方面取得了显著的改进，特别是在低比特率应用中表现出色。
## 403. `cs.CV` - ARTalk:基于自回归模型的语音驱动3D头部动画 [PDF](https://arxiv.org/pdf/2502.20323), [HTML](https://arxiv.org/abs/2502.20323)
### Authors
Xuangeng Chu,Nabarun Goswami,Ziteng Cui,Hanqin Wang,Tatsuya Harada
### Background
语音驱动的3D面部动画旨在从任意音频剪辑中生成真实的唇部运动和面部表情。现有的基于扩散的方法能够产生自然的运动，但其缓慢的生成速度限制了其应用潜力。在本研究中，该论文提出了一种新颖的自回归模型，能够通过从语音到多尺度运动码本的学习映射实现实时同步的唇部运动和逼真的头部姿态以及眨眼。此外，该模型可以适应未知的讲话风格，从而能够创建具有自己独特个性风格的3D视频化身，而不仅仅是在训练中所看到的身份。
### Innovation
提出了一个新颖的自回归模型，该模型能够在多尺度运动码本学习映射的基础上实现高度同步的唇部运动和逼真的头部姿态及眨眼。并且能够适应未知的讲话风格，生成具有自己独特个性风格的3D视频化身，超越了训练中看到的身份特征。
### Conclusion
广泛的研究和用户测试表明，本方法在唇部同步准确性和感知质量上优于现有方法。
## 404. `cs.CV` - RFWNet：一种结合多尺度感受野和前景焦点机制的轻量级遥感目标检测器 [PDF](https://arxiv.org/pdf/2503.00545), [HTML](https://arxiv.org/abs/2503.00545)
### Authors
Yujie Lei,Wenjie Sun,Sen Jia,Qingquan Li,Jie Zhang
### Background
遥感目标检测（RSOD）面临着高类间相似性、前景与背景分布不平衡以及遥感图像中小目标尺寸的挑战，这些因素严重阻碍了检测准确性。此外，模型准确性和计算复杂性之间的权衡给RSOD算法的应用带来了额外限制。
### Innovation
该研究提出了一种高效的轻量级RSOD算法，结合了多尺度感受野和前景重点机制，命名为鲁棒前景加权网络（RFWNet）。该算法包含一个轻量级骨干网络的感受野自适应选择网络（RFASNet），能够利用遥感图像的丰富背景信息来增强类别可分性。此外，还开发了一个前景-背景分离模块（FBSM），包括背景冗余信息过滤模块（BRIFM）和前景信息增强模块（FIEM），以强调图像中的关键区域并过滤冗余背景信息。最后设计了一种加权CIoU- Wasserstein损失函数（LWCW），通过使用归一化的Wasserstein距离来权重重叠比损失，从而减轻模型对小目标位置偏差的敏感性。
### Conclusion
综合实验结果表明，在DOTA V1.0和NWPU VHR-10数据集上，RFWNet分别实现了95.3%和73.2%的平均准确率（mAP），参数量为6.0 M，推理速度为52 FPS。
## 405. `cs.CV` - FeatSharp: Your Vision Model Features, Sharper [PDF](https://arxiv.org/pdf/2502.16025), [HTML](https://arxiv.org/abs/2502.16025)
### Authors
Mike Ranzinger,Greg Heinrich,Pavlo Molchanov,Jan Kautz,Bryan Catanzaro,Andrew Tao
### Background
视觉编码器的特征图是众多现代AI任务的基础，从核心感知算法（如语义分割、目标检测、深度感知等）到视觉语言模型（VLMs）中的现代多模态理解。目前，在计算机视觉领域，通用目的的视觉骨干主要是基于变换器的Vision Transformers (ViT)，常使用对比损失（如CLIP）进行训练。大多数ViT模型，尤其是CLIP，分辨率较低且不灵活，通常运行在$224 times 224$像素，即使有更高分辨率的版本约$378-448$像素，也仍然不灵活。因此，如何在不显着增加计算成本的情况下提升模型的分辨率以捕捉更多细节成为一个亟待解决的问题。
### Innovation
该研究提出了一种新颖的方法，能够在不显著增加计算成本的前提下，以一种连贯且经济高效的方式提升低分辨率视觉编码器的特征图分辨率，并能捕捉到由于分辨率降低而丢失的详细信息。展示出了该方法在核心感知任务上的有效性，并通过AGGLOMERATIVE模型训练中的RADIO方法提供了更丰富的目标进行蒸馏训练。
### Conclusion
该研究通过引入一种新型方法，有效提升了低分辨率视觉编码器的特征图的分辨率，同时捕捉到了细粒度的细节，改善了感知任务的表现，并通过提供更多的目标促进了模型的蒸馏训练。该方法在多个感知任务上展现出有效性，并降低了高分辨率模型所需的计算成本。研究代码已可公开获取。
## 406. `cs.CV` - 基于高置信度标签和高合理性损失的甲状腺结节弱监督分割框架 [PDF](https://arxiv.org/pdf/2502.19707), [HTML](https://arxiv.org/abs/2502.19707)
### Authors
Jianning Chi,Zelan Li,Geng Lin,MingYang Sun,Xiaosheng Yu
### Background
现有的弱监督分割方法可以利用粗略标签高效地在超声图像中勾勒出甲状腺结节，但存在两个主要问题：1) 低置信度的伪标签容易引入显著的标签噪声；2) 低理性的损失函数使分割结果难以准确反映结节的多样性和复杂性。这些问题限制了现有方法的性能和泛化能力，特别是在处理具有不同形态结构的结节时表现不佳。因此，本研究旨在进一步提升甲状腺结节弱监督分割的性能，通过明确弱监督超声图像分割的目标和参考标准，提出一种新的框架，利用高置信度伪标签和高理性的损失函数，来克服现有方法的不足，提高模型的分割精度和鲁棒性.
### Innovation
本研究创新地结合了多种先进的技术和策略：1) 使用几何变换和特定注释提示的MedSAM模型结果生成高置信度的边界、前景和背景标签；2) 设计了高理性的学习策略，包括对齐损失、对比损失和原型相关损失，分别用于引导网络感知结节定位、学习结节和背景特征分布以及细化不确定区域到准确的结节边缘。这些策略有效提高了分割精度和对不同形态结节的适应性，相较于现有方法而言具有显著优势和改进.
### Conclusion
实验结果显示，本方法在TN3K和DDTI数据集上达到最佳性能，证明了所提出的方案可以显著提高甲状腺结节弱监督分割的实际应用效果。提出的方法代码已公开，为后续研究提供了重要的参考资源。
## 407. `cs.CV` - Skip-Vision: 通过自适应 token 跳过实现视觉-语言模型的高效可扩展加速 [PDF](https://arxiv.org/pdf/2503.21817), [HTML](https://arxiv.org/abs/2503.21817)
### Authors
Weili Zeng,Ziyuan Huang,Kaixiang Ji,Yichao Yan
### Background
基于Transformer的模型在多模态大型语言模型（MLLMs）领域取得了重大进展，但随着图像理解的细分、训练数据和模型参数的增加，计算成本会急剧上升。视觉 token 的数量激增是瓶颈之一。为此，本文探讨了视觉语言模型训练和推理中的效率问题，并提出了一种新的加速框架——Skip-Vision，以期提高模型的效率和可扩展性。
### Innovation
Skip-Vision提出了两个互补的加速策略。在训练加速方面，引入了Skip-FFN策略，绕过了冗余视觉 token 的 Feed-Forward Network 层计算。在推理加速方面，设计了一种选择性的 KV 缓存移除机制，在解码过程中移除不必要 key-value 对。此方法在保证模型性能的同时，显著减少了训练时间、推理运算量和延迟，具有较高的效率和可扩展性。
### Conclusion
实验结果表明，Skip-Vision可以将训练时间减少最多35%，推理运算量减少75%，延迟减少45%，且模型性能与现有方法相当甚至优于现有方法。本研究提供了一种实用的解决方案，可以高效地扩展高性能MLLMs。
## 408. `cs.CV` - CMD-HAR: 跨模态解纠缠对于可穿戴人体活动识别 [PDF](https://arxiv.org/pdf/2503.21843), [HTML](https://arxiv.org/abs/2503.21843)
### Authors
Hanyu Liu,Siyao Li,Ying Yu,Yixuan Jiang,Hang Xiao,Jingxi Long,Haotian Tang,Chao Li
### Background
人体活动识别（HAR）是许多以人类为中心的智能应用的基础技术。尽管深度学习方法已被用于加速特征提取，但数据多模态混合、活动异质性和复杂模型部署等问题仍未得到充分解决。本文旨在解决基于传感器的人体活动识别中的多模态数据混合、活动异质性和复杂模型部署问题。
### Innovation
提出了空间-时间注意力模态解纠缠融合策略以应对传感器数据混合分布的问题。通过跨模态空间-时间解纠缠表示捕捉活动的关键鉴别特征，并结合梯度调制以缓解数据异质性。同时，构建了一个可穿戴部署模拟系统。实验表明该模型的有效性。
### Conclusion
本文通过跨模态解纠缠的方法，实现了对复杂多模态传感器数据的有效处理，并通过一个可穿戴部署模拟系统验证了模型的有效性。
## 409. `cs.CV` - Stereo Any Video: 时间一致的视差匹配 [PDF](https://arxiv.org/pdf/2503.05549), [HTML](https://arxiv.org/abs/2503.05549)
### Authors
Junpeng Jing,Weixun Luo,Ye Mao,Krystian Mikolajczyk
### Background
本文介绍了一种名为Stereo Any Video的强大框架，用于视频立体匹配。该框架能够在无需依赖如相机姿态或光流等辅助信息的情况下，估计空间上准确且时间上一致的视差。这一强大的能力源自于单目视频深度模型中丰富的先验知识，并通过卷积特征进行整合以产生稳定表示。为了进一步提升性能，文中引入了关键的架构创新：全对全对数对相关（all-to-all-pairs correlation）构建平滑且稳健的匹配代价体，以及时间凸上采样（temporal convex upsampling），以提高时间一致性。这些组件共同确保了稳健性、准确性和时间一致性，为视频立体匹配设立了新标准。广泛的实验结果表明，该方法在多个数据集上实现了最先进的性能，无论是定性还是定量表现，并且对于真实世界的室内外场景具有较强的泛化能力。
### Innovation
1. 引入了全对全对数对相关（all-to-all-pairs correlation）构建平滑且稳健的匹配代价体。2. 提出了时间凸上采样（temporal convex upsampling），以提高时间一致性。3. 结合了单目视频深度模型丰富的先验知识和卷积特征。
### Conclusion
本文方法在零样本设置下，以及对真实世界的室内外场景有广泛通用性的多个数据集上，实现了最先进的性能和时间一致性。
## 410. `cs.CV` - BANet: 双边聚合网络在移动立体匹配中的应用 [PDF](https://arxiv.org/pdf/2503.03259), [HTML](https://arxiv.org/abs/2503.03259)
### Authors
Gangwei Xu,Jiaxin Liu,Xianqi Wang,Junda Cheng,Yong Deng,Jinliang Zang,Yurui Chen,Xin Yang
### Background
传统的立体匹配方法通常使用昂贵的3D卷积来聚合完整的代价体，但这种计算需求使其在移动设备上的部署具有挑战性。直接使用2D卷积进行代价聚合会导致边缘模糊、细节丢失以及在纹理较少区域对齐偏差。虽然一些复杂操作，例如可变形卷积和迭代扭曲，可以部分缓解这一问题，但它们并不适合移动设备，限制了这些方法在移动设备上的部署能力。
### Innovation
本文提出了一种新颖的双边聚合网络(BANet)用于移动立体匹配。BANet仅使用2D卷积可以产生高精度的结果，具有清晰的边缘和良好的细节。具体来说，BANet首先使用空间注意力图将完整的代价体分离为详细和光滑部分，分别进行详细和光滑聚合，最终融合两者以获得最终的视差图。实验结果表明，我们的BANet-2D在KITTI 2015排行榜上显著优于其他移动友好方法，精度提高了35.3%，并且在移动设备上的运行速度更快。
### Conclusion
实验结果表明，我们的BANet-2D在KITTI 2015排行榜上，相对于MobileStereoNet-2D，准确率提高了35.3%，且在移动设备上的运行速度更快。
## 411. `cs.CV` - 使用数字孪生进行隐私保护的手术室工作流程分析 [PDF](https://arxiv.org/pdf/2504.12552), [HTML](https://arxiv.org/abs/2504.12552)
### Authors
Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath
### Background
手术室是一个环境复杂且需要优化工作流程以降低成本并改善患者结果的地方。虽然计算机视觉方法可以自动识别围手术期事件，识别手术室优化瓶颈，但隐私问题限制了手术室视频在自动事件检测中的使用。该研究提出了一种两阶段的隐私保护手术室视频分析和事件检测管道。首先，利用视觉基础模型进行深度估计和语义分割，从传统的RGB视频生成匿名的数字孪生（DT）。其次，使用SafeOR模型进行手术室事件检测，该模型融合了两流处理分割掩模和深度图。在包含38次模拟手术试验和五个事件类别的内部数据集上进行的评估表明，基于DT的方法在手术室事件检测的性能与原始RGB视频模型相当，甚至更好。数字孪生能够实现手术室工作流程的隐私保护分析，促进匿名数据在机构间的共享，并可能通过减轻特定领域外观差异来增强模型的普遍性。
### Innovation
提出了一个两阶段的隐私保护手术室视频分析和事件检测管道，利用视觉基础模型生成匿名的数字孪生（DT），并使用融合了两流处理分割掩模和深度图的SafeOR模型进行手术室事件检测。研究结果显示，基于DT的方法在手术室事件检测方面的性能与原始RGB视频模型相当，甚至更好。
### Conclusion
数字孪生使手术室工作流程的隐私保护分析成为可能，能够实现数据在机构间的匿名共享，有助于模型适应更广泛的领域差异。
## 412. `cs.CV` - MAD: 用跨域扩散模型实现全能化妆 [PDF](https://arxiv.org/pdf/2504.02545), [HTML](https://arxiv.org/abs/2504.02545)
### Authors
Bo-Kai Ruan,Hong-Han Shuai
### Background
现有的化妆技术往往需要设计多种模型来处理不同的输入，并在不同领域之间对齐特征，用于不同的化妆任务，例如美容滤镜、化妆移除和化妆尝试。这种做法增加了复杂性。另一个局限是没有文本引导的化妆尝试，这更加用户友好，不需要参考图像。因此，本研究尝试使用单一模型来完成多种化妆任务，将不同化妆任务形式化为跨域翻译问题，并利用跨域扩散模型来实现所有任务。现有的方法依赖于独立的编码器-解码器配置或循环机制，而该研究提出使用不同的领域嵌入来实现领域控制，通过仅更改单个模型中的嵌入来实现无缝的领域切换。此外，为了支持精确的文本到化妆的应用，该研究通过扩展具有文本注释的MT数据集创建了MT-Text数据集，从而推进了化妆技术的实际应用性.
### Innovation
该研究首次使用单个模型来完成多种化妆任务。通过将不同化妆任务形式化为跨域翻译问题，并采用跨域扩散模型来完成所有任务。该方法区别于现有的依靠独立编码器-解码器配置或循环机制的方法，提出的方法使用不同领域嵌入以实现领域控制，仅通过改变单个模型中的嵌入来实现无缝的领域切换。此外，为支持精确的文本到化妆的应用，提出了MT-Text数据集，扩展了原有MT数据集以包含文本注释，从而提高了化妆技术的实际应用性.
### Conclusion
该研究通过单一模型和跨域扩散模型实现了多种化妆任务的统一处理，简化了复杂性。通过使用不同领域嵌入，实现了领域控制的便捷切换。为支持精确的文本到化妆的应用，提出了新的数据集，推进了化妆技术的实际应用性。
## 413. `cs.CV` - 基于不确定性指导和解剖结构感知后处理的粗细两级肿瘤分割 [PDF](https://arxiv.org/pdf/2504.12215), [HTML](https://arxiv.org/abs/2504.12215)
### Authors
Ilkin Sevgi Isler,David Mohaisen,Curtis Lisle,Damla Turgut,Ulas Bagci
### Background
在胸腔计算机断层扫描（CT）中，可靠的肿瘤分割仍然具有挑战性，原因是边界模糊、类别不平衡和解剖变异。这些因素使得准确地区分肿瘤组织与健康组织变得困难，特别是在边界模糊的区域，容易产生误分割和漏分割。
### Innovation
本文提出了一种基于不确定性的、由粗到细的分割框架，该框架结合了全体积肿瘤定位与细化的感兴趣区域（ROI）分割，并通过解剖感知的后处理进一步增强。首先，第一阶段模型生成粗略预测，然后通过基于肺重叠、接近肺表面以及组件大小的解剖信息进行过滤。随后，第二阶段模型使用带有不确定性感知损失函数的训练，以提高在模糊区域的准确性和边界校准。该框架在多个私有和公共数据集上的实验结果表明，使用不确定性建模和解剖先验结合的方法可以显著提高Dice和Hausdorff分数，同时减少假阳性并增强空间可解释性。
### Conclusion
这些结果强调了将不确定性建模和解剖先验结合应用于多阶段分割管道，以实现稳健和临床相关的肿瘤界定的重要性。在Orlando数据集上，该框架将Swin UNETR的Dice分数从0.4690提升到了0.6447，减少伪组件的数量与分割性能的提升密切相关，进一步证明了解剖信息感知后处理的价值。
## 414. `cs.CV` - MaizeField3D: 一个田间种植的玉米多样化面板的3D点云及程序化模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
### Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
### Background
由于缺乏大量且多样化的3D数据集，基于人工智能和机器学习的工具在3D表型分析，特别是对玉米的研究方面的发展受到了限制。现有的2D图像数据集无法捕捉如叶片结构、植物体积和空间排列等重要的结构性细节，这些都是3D数据能够提供的。因此，现有的2D数据集无法满足3D表型分析的需求，无法准确评估植物的结构特征和生长特性。
### Innovation
本研究创新性地开发了MaizeField3D数据集，这是一个田野生长的玉米多样化面板的3D点云数据集和程序化模型，旨在为农业研究提供AI就绪的数据。该数据集包含了1,045个高质量的田野生长玉米3D点云，通过地面激光扫描仪（TLS）收集而成，并通过图谱分割方法进行分割和注释，确保了所有样本的一致性标签。利用这些标注数据拟合了程序化模型，使用非均匀有理B样条（NURBS）表面来表示玉米叶片，并通过两步优化过程生成NURBS表面，结合了无导数和基于导数的方法。本研究还进行了严格的手动数据质量控制，确保了分割的准确性、叶片排列的精确性及元数据的验证。同时提供了不同分辨率的子采样点云数据，便于不同下游计算任务的使用。MaizeField3D将成为人工智能驱动的表型分析、植物结构分析以及农业研究中3D应用的综合基础数据集。
### Conclusion
MaizeField3D将为AI驱动的玉米表型研究、植物结构分析以及3D在农业研究中的应用提供坚实的基础。该数据集的发布，将大大促进植物科学和农业研究的新进展，特别是关于植物结构和生长特性的理解和评估。
## 415. `cs.CV` - PAD：基于频域相位-幅值解耦的多模态土地覆盖分类融合 [PDF](https://arxiv.org/pdf/2504.19136), [HTML](https://arxiv.org/abs/2504.19136)
### Authors
Huiling Zheng,Xian Zhong,Bin Liu,Yi Xiao,Bihan Wen,Xiaofeng Li
### Background
合成孔径雷达（SAR）和RGB图像的土地覆盖分类融合因模态异质性和未充分利用的光谱互补性仍具有挑战性。现有方法往往难以分离共享的结构性特征和模态互补的辐射度属性，导致特征冲突和信息损失。
### Innovation
提出了一种基于频域的相位-幅值解耦（PAD）框架。该框架在频域中分离相位（跨模态共享）和幅值（跨模态互补）分量，增强共享结构并保持互补特性，从而提高融合质量。PAD首次实现显式的幅值-相位解耦，为其后端的多模态融合带来了独特的视角。它包含两个关键组件：相位频谱校正（PSC）和幅值频谱融合（ASF），分别通过卷积引导的缩放调整跨模态相位特征，以及动态利用频率自适应多层感知机整合高、低频模式，发挥SAR在形态敏感性方面的优势和RGB在光谱丰富性方面的优势。
### Conclusion
广泛实验表明，PAD在WHU-OPT-SAR和DDHR-SK数据集上的性能达到业界领先水平。该工作建立了多模态融合领域中的一个新的基于物理的框架，代码开源并可从提供的链接下载。
## 416. `cs.CV` - Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation [PDF](https://arxiv.org/pdf/2504.12753), [HTML](https://arxiv.org/abs/2504.12753)
### Authors
Siyu Chen,Ting Han,Changshe Zhang,Xin Luo,Meiliu Wu,Guorong Cai,Jinhe Su
### Background
Vision Foundation Models (VFMs) 在域泛化语义分割 (DGSS) 等任务中取得了显著的性能，然而，最近的方法往往忽略了视觉线索易变而几何基础相对稳定这一事实，使得深度信息更为稳健。研究表明，即使在不同数据集中也具有较强的泛化能力。但由于忽视深度信息重要性，现有方法的性能仍有提升空间。因此，本文提出探索将深度信息与VFMs特征融合的方法，以增强几何一致性和泛化性能，尤其是提出了一种新的细调DGSS框架——DepthForge。
### Innovation
本文提出了一个名为DepthForge的新型细调DGSS框架，该框架结合了冻结的DINOv2或EVA02的视觉提示和冻结的Depth Anything V2的深度提示。每个VFMs层中集成深度感知可学习标记，精细化分离不变的视觉和空间信息，强化深度感知和注意力，并开发了一个深度细化解码器，以自适应地细化多层VFM特征和深度感知可学习标记。实验结果表明，该方法在定性和定量上都显著优于其他方法，泛化能力和视觉空间注意力表现更稳定，尤其在极端条件下（如夜景和雪景）表现出色。
### Conclusion
我们的方法在多种DGSS设置和不同未见过的目标域上取得了优异的性能，尤其在极端条件下表现出色。本文提出了一个将深度信息与视觉信息结合的新方法，并通过深度细化解码器进一步增强模型的泛化能力，实验结果表明方法的有效性。
## 417. `cs.CV` - 使用物理学驱动的深度学习重新拼接古代竹简 [PDF](https://arxiv.org/pdf/2505.08601), [HTML](https://arxiv.org/abs/2505.08601)
### Authors
Jinchi Zhu,Zhou Zhao,Hailong Lei,Xiaoguang Wang,Jialiang Lu,Jing Li,Qianqian Tang,Jiachen Shen,Gui-Song Xia,Bo Du,Yongchao Xu
### Background
竹简是东亚古文明记录的重要载体，对于丝绸之路的研究、物质文化交换的考察以及全球历史的重建具有极高的考古价值。然而，许多出土的竹简被切割成数千个不规则的碎片，这使得重新拼接工作成为理解其内容的关键但极具挑战性的步骤。现有方法依赖于人工配对样本训练，效率低下且不适用于数据稀缺的情况，限制了考古学家的工作效率。
### Innovation
提出了一种基于物理学原理的深度学习框架WisePanda，用于重新拼接破碎的竹简。WisePanda能够自动生成捕捉竹简裂化和材料退化物理特性的合成训练数据，无需人工配对样本即可训练匹配网络，给出排好序的建议，从而简化拼接过程。与领先的曲线匹配方法相比，WisePanda在超过一千个候选碎片中将前50%的匹配准确率从36%提高到52%，极大提高了考古学家的工作效率，约提高了20倍。这项研究证明了将物理原理融入深度学习模型可以显著提升其性能，从根本上转变了考古学家修复和研究碎片化古物件的方式。这种方法通过物理学驱动的机器学习解决了古文物修复中的数据稀缺问题，开创了一种新的范式。
### Conclusion
WisePanda为解决古文物修复中数据稀缺问题提供了一种新的物理学驱动的机器学习范式，显著提升了深度学习模型在古文物修复中的性能，极大地提高了考古学家的工作效率。
## 418. `cs.CV` - 基于扩散模型的自主驾驶中3D占用网格生成预测 [PDF](https://arxiv.org/pdf/2505.23115), [HTML](https://arxiv.org/abs/2505.23115)
### Authors
Yunshen Wang,Yicheng Liu,Tianyuan Yuan,Yingshi Liang,Xiuyu Yang,Honggang Zhang,Hang Zhao
### Background
准确地从视觉输入中预测3D占用网格对于自主驾驶至关重要，但当前的判别方法难以处理噪声数据、不完整观察以及3D场景中复杂的结构。现有的方法在处理这些问题时表现出色，但存在局限性，尤其是在含噪声数据、不完整观测和复杂3D结构的情况下，预测效果不佳。因此，需要一种方法能够提高预测的准确性、鲁棒性以及处理复杂3D空间结构的能力。
### Innovation
本工作重新定义了3D占用预测为生成建模任务，利用扩散模型。扩散模型通过学习底层数据分布并结合3D场景先验，从而增强预测一致性、噪声鲁棒性，并更好地处理3D空间结构的复杂性。实验结果表明，基于扩散模型的生成模型在占用网格预测方面优于最先进的判别方法，特别是在遮挡或低可见度区域提供更真实、更准确的预测。此外，改进的预测结果显著提高了下游规划任务的效果，突显了该方法在实际自主驾驶应用中的实用优势。
### Conclusion
通过使用基于扩散模型的生成方法进行3D占用网格预测，在处理复杂3D场景和噪声数据方面取得显著进展，能够提供更准确的预测，并且对于实际自主驾驶应用有着重要的实用意义。
## 419. `cs.CV` - PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation [PDF](https://arxiv.org/pdf/2506.02453), [HTML](https://arxiv.org/abs/2506.02453)
### Authors
Kunyu Wang,Xueyang Fu,Yuanfei Bao,Chengjie Ge,Chengzhi Cao,Wei Zhai,Zheng-Jun Zha
### Background
Continual Test-Time Adaptation (CTTA)专注于在线适应预训练模型以应对推理过程中的变化环境。现有的大多数方法侧重于利用目标数据，而忽视了预训练权重这一关键信息源。这些权重中包含未充分利用的领域不变先验信息。本研究将预训练权重的几何属性作为起点，系统地分析了三个关键组件：幅度、绝对角度和成对的角度结构。研究表明，成对的角度结构在不同受污染领域中保持稳定，编码了领域不变的语义信息，因此在适应过程中应被保留。基于这一见解，提出了PAID（成对角度不变分解）方法，这是一种先验驱动的CTTA方法，将权重分解为幅度和方向，并通过豪森反射引入可学习的正交矩阵以全局旋转方向同时保留成对的角度结构。在适应过程中，仅更新幅度和正交矩阵。PAID在四个广泛使用的CTTA基准测试上优于最新的SOTA方法，表明保留成对的角度结构是简单的有效原则之一。
### Innovation
提出了PAID方法，这是一种先验驱动的Continual Test-Time Adaptation (CTTA)方法。PAID通过将权重分解为幅度和方向，利用豪森反射引入可学习的正交矩阵来全局旋转方向，同时保持成对的角度结构。在适应过程中，仅更新幅度和正交矩阵。该方法在四个广泛使用的CTTA基准测试上优于最新的SOTA方法，展示了保留成对的角度结构是简单且有效的原则。
### Conclusion
PAID方法在多个CTTA基准测试中表现出色，证明了保留成对的角度结构对于Continual Test-Time Adaptation的重要性。这种方法提供了一个简单且有效的方法来处理变化的环境，为CTTA领域带来了新的见解和创新。
## 420. `cs.CV` - Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition [PDF](https://arxiv.org/pdf/2505.06002), [HTML](https://arxiv.org/abs/2505.06002)
### Authors
Congqi Cao,Peiheng Han,Yueran zhang,Yating Yu,Qinyi Lv,Lingtong Min,Yanning zhang
### Background
大型预训练模型已经在语言和图像任务中取得了显著的成功，越来越多的研究开始探索像CLIP这样的预训练图像模型在少数几次动作识别（FSAR）领域的应用。当前的方法在直接微调预训练模型时经常损害其泛化能力；在视觉任务中，任务特定信息的探索不足；在文本建模过程中忽略了语义顺序信息；现有的跨模态对齐技术忽视了多模态信息的时间耦合。这些问题导致了当前方法的局限性。
### Innovation
提出了一个参数高效的双重适应方法—Task-Adapter++，以解决上述问题。具体而言，设计了一个专门针对图像编码器的任务特定适应机制，使得动作识别任务中最具判别性的信息能在特征提取过程中更好地被注意到。使用大型语言模型生成每个动作类别的详细顺序子动作描述，并将语义顺序适配器引入文本编码器，以有效建模这些子动作之间的顺序关系。此外，提出了一种创新的细粒度跨模态对齐策略，主动将视觉特征映射到与语义描述相同的时序阶段。实验结果表明，该方法在5个基准数据集上的一致性上取得了最先进的性能。
### Conclusion
提出的Task-Adapter++方法通过双重适应方法和顺序感知对齐策略在少数几次动作识别任务中取得了显著的效果，实现了不同基准数据集上的最优性能。
## 421. `cs.CV` - 一致性的故事生成与不对称zigzag采样 [PDF](https://arxiv.org/pdf/2506.09612), [HTML](https://arxiv.org/abs/2506.09612)
### Authors
Mingxiao Li,Mang Ning,Marie-Francine Moens
### Background
文本到图像生成模型在从文本描述生成高质量图像方面取得了显著进步，但它们仍然难以在多张图像中保持主题一致性，这是视觉故事讲述的基本要求。现有方法通过在大规模故事可视化数据集上微调模型来解决这一问题，这种方法耗资源，或者使用无需训练的技术来在生成之间共享信息，但仍然成效有限。
### Innovation
本文介绍了一种新的无需训练的采样策略，称为异步提示和视觉共享的zigzag采样，以增强视觉故事生成中主题的一致性。该策略提出了一种zigzag采样机制，交替使用异步提示保留主体特征，同时通过视觉共享模块在生成的图像之间传递视觉线索，以进一步增强一致性。实验结果表明，该方法在生成连贯且一致的视觉故事方面显著优于先前的方法。
### Conclusion
我们的方法在生成连贯且一致的视觉故事方面显著优于先前的方法。详细的实验结果可以通过提供的代码进行评估和验证。
## 422. `cs.CV` - 使用扩散模型的文本感知图像恢复 [PDF](https://arxiv.org/pdf/2506.09993), [HTML](https://arxiv.org/abs/2506.09993)
### Authors
Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim
### Background
图像恢复旨在恢复退化图像。现有的基于扩散的恢复方法虽然在自然图像恢复方面取得了巨大成功，但在重建退化图像中的文本区域时经常难以实现精准重建，常常生成可信但不正确的类似文本的图案(称为文本图像错觉)。为解决这一问题，该研究提出了文本感知图像恢复（TAIR），并构建了一个大规模的标注基准(SA-Text)，以及一个结合扩散模型内部特征的多任务扩散框架（TeReDiff）来进一步提高文本识别的准确性，同时在后续去噪步骤中利用这些丰富的文本表示作为提示。
### Innovation
提出了一种新的恢复任务——文本感知图像恢复（TAIR），并构建了一个包含10万高质量场景图像的大规模标注基准（SA-Text），每个图像上密集地标注有多种复杂文本实例。另外还提出了一种结合扩散模型内部特征的多任务扩散框架（TeReDiff），该框架将扩散模型的内部特征集成到文本检测模块中，使两个组件能够通过联合训练互相受益，从而更好地提取丰富文本表示并用作后续去噪步骤中的提示。实验表明，相比现有最先进的恢复方法，该方法在文本识别准确性上取得了显著提升
### Conclusion
通过大规模标注基准和多任务扩散框架，本研究解决了现有图像恢复技术在处理退化图像中文本区域时的难题，显著提升了图像恢复的结果，特别是在文本识别准确性方面超越了现有最先进的恢复方法。
## 423. `cs.CV` - RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment [PDF](https://arxiv.org/pdf/2506.23852), [HTML](https://arxiv.org/abs/2506.23852)
### Authors
Jianing Jin,Jiangyong Ying,Huiyu Duan,Liu Yang,Sijing Wu,Yunhao Li,Yushuo Zheng,Xiongkuo Min,Guangtao Zhai
### Background
随着配备摄像头的机器人平台越来越融入日常生活，机器人生成的视频开始出现在流媒体平台上，使得人类和机器人共存的未来变得可想象。然而，关于机器人生成内容(RGC)视频质量评估的研究仍然不足，现有的视频质量评估(VQA)模型在应用于复杂、机器人生成的内容时存在显著局限。
### Innovation
本文创新性地提出了机器人生成内容(RGC)的概念，将这类视频定义为以机器人自身视角生成的视频。作者建立了第一个机器人生成内容数据库(RGCD)，包含来自三种不同类型机器人和多种平台的共计2100个视频。此外，通过主观的VQA实验评估人类对机器人生成视频的视觉感知，并对数据库中的图像质量进行基准测试。实验结果揭示了现有VQA模型在处理复杂机器人生成内容时的局限性，提出了需要特定于RGC的VQA模型的需求。
### Conclusion
本文通过建立第一个RGC数据库，并通过具体实验揭示现有VQA模型的局限性，强调了开发特定于RGC的VQA模型的必要性。所建立的RGCD数据库以公开链接的形式提供。
## 424. `cs.CV` - 通过视觉到文本转换在连通和自主车辆中实现隐私保护 [PDF](https://arxiv.org/pdf/2506.15854), [HTML](https://arxiv.org/abs/2506.15854)
### Authors
Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy
### Background
连通和自主车辆（CAVs）依赖多种设备，其中道路边设备尤为重要，它们通过配备人工智能（AI）的摄像头（AIE Cameras）进行违章检测等应用。然而，捕获图像所涉及的隐私风险仍然是一个重大问题，因为此类数据可能被滥用进行身份盗窃、 profiling 或未经授权的商业用途。尽管已应用了传统的技术手段如面部模糊化和遮蔽来减轻隐私风险，但个人隐私仍处于风险之中，因为个人仍然可以通过其他特征（如穿着）被追踪。
### Innovation
本文提出了一个新颖的隐私保护框架，该框架结合了基于反馈的强化学习（RL）和视觉语言模型（VLMs），利用图像转为语义等效的文本描述，以确保保留场景相关信息同时保护视觉隐私。通过层次结构的RL策略，文本生成逐步优化，增强语义准确性和隐私保护。
### Conclusion
实验结果表明，在隐私保护和文本质量方面都有显著提升，独特的单词计数相比现有方法提高了约77％，细节密度提高了约50％。
## 425. `cs.CV` - RGE-GS: 基于奖励引导的扩散先验驱动的扩展驾驶场景重建 [PDF](https://arxiv.org/pdf/2506.22800), [HTML](https://arxiv.org/abs/2506.22800)
### Authors
Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang
### Background
被动动扫描驾驶结构的单一通过方式常导致重建场景不完整，因此扩展性重建成为传感器模拟器的有效回归驾驶行为的关键需求。尽管现代3D高斯点绘制（3DGS）技术达到了出色的重建质量，但通过融合扩散先验直接扩展时，往往会引入累积的物理不一致，降低训练效率。
### Innovation
提出了一种名为RGE-GS的新扩展重建框架，结合了基于扩散的生成与奖励引导的高斯积分。创新在于：1. 提出了一种奖励网络，学习识别和优先处理一致生成的模式，确保在重建阶段保留空间稳定性。2. 在重建过程中采用差异化的训练策略，根据场景收敛指标自动调整高斯优化进度，达到更好的收敛效果。
### Conclusion
广泛使用公开数据集的评估表明，RGE-GS在重建质量方面达到了最先进的性能。源代码将在指定网址公开。
## 426. `cs.CV` - 增强对抗可移植性的语义结构感知生成攻击 [PDF](https://arxiv.org/pdf/2506.18248), [HTML](https://arxiv.org/abs/2506.18248)
### Authors
Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon
### Background
生成对抗性攻击训练一个扰动生成器在白盒替代模型上，然后将制造的扰动应用于未知的黑盒受害模型。与迭代攻击相比，这些方法在推理效率、可扩展性和可移植性方面表现出色；然而，现有的研究尚未充分利用生成模型的表征能力来保留和利用语义信息。特别是在扰动生成器中间激活中编码的丰富语义特征，如对象边界的粗略形状，仍然被低估，从而限制了扰动与关键的对象显著区域对齐，这对于对抗转移性至关重要。
### Innovation
引入了一种基于Mean Teacher的语义结构感知攻击框架，作为时间平滑特征参考，通过特征蒸馏引导学生模型的早期层激活与富含语义的信息丰富的教师模型的激活之间的一致性。根据实验发现，将扰动合成锚定到生成器中基于语义显著性的早期中间块，通过这种机制指导渐进式的对抗扰动，以显著提高对抗可移植性。
### Conclusion
在多种模型、领域和任务上进行了广泛的实验，证明了与最新的生成攻击相比，我们的方法在常规指标和我们提出的新的意外纠正率（ACR）中有持续的改进。
## 427. `cs.CV` - 通过指数扭力剪枝实现通用高效的模型压缩 [PDF](https://arxiv.org/pdf/2506.22015), [HTML](https://arxiv.org/abs/2506.22015)
### Authors
Sarthak Ketanbhai Modi,Zi Pong Lim,Shourya Kuchhal,Yushi Cao,Yupeng Cheng,Yon Shin Teo,Shang-Wei Lin,Zhiming Li
### Background
现代深度神经网络（DNNs）的复杂性和规模快速增长，增加了计算成本和内存使用方面的挑战，促使研究者们对高效的模型压缩技术产生了浓厚兴趣。之前最先进的方法使用了类似扭矩的正则化技术，通过使神经模块的权重围绕选定的枢轴点，强迫其收敛。然而，这一方法的效果并不理想，剪枝后的网络仍然较为密集，并且准确率有所下降。研究者发现，这是由于默认的线性力应用方案对距离不同的神经模块提供了不适当的力。
### Innovation
为了解决上述问题，研究提出了一种名为指数扭矩剪枝（ETP）的新方法，采用指数力应用方案进行正则化，以有效地剪枝冗余且远离关键子模块，同时保留那些关键且用于高效推理的近邻模块。实验结果表明，尽管ETP方法非常简单，但相比之前的最先进的剪枝策略，ETP能够在几乎不损失准确率的情况下实现更高的压缩率。
### Conclusion
ETP方法通过使用指数力应用方案，在保持模型准确率的前提下，能够实现高效的模型压缩。这种方法在多个领域中表现出了明显的优势，展示了其广泛应用的潜力。
## 428. `cs.CV` - AirV2X：统一空中和地面的V2X协作 [PDF](https://arxiv.org/pdf/2506.19283), [HTML](https://arxiv.org/abs/2506.19283)
### Authors
Xiangbo Gao,Yuheng Wu,Fengze Yang,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu
### Background
多辆自动驾驶车辆相比单一车辆的自主驾驶展现了明显优势，但传统基于基础设施的V2X系统仍然受限于高昂的部署成本，并且在农村和郊区存在未覆盖的安全盲区。当前的V2X系统主要依赖固定基站（路边单元RSU），但无人机(UAV)可以作为一种灵活的替代品或补充，提供独特的优势，如远程视角减少遮挡、动态定位控制能力和显著降低部署成本。
### Innovation
提出了AirV2X-Perception大规模数据集，该数据集利用无人机作为固定路侧单元的灵活替代品或补充。该数据集包含不同环境（城市、郊区和农村）和天气、光照条件下的6.73小时无人机辅助驾驶场景，有助于开发和标准化V2D算法，填补迅速发展的机辅助自动驾驶系统的关键空白。数据集和开发工具已开放源代码。
### Conclusion
AirV2X-Perception数据集为V2D算法的研发及标准化评估提供了重要资源，对于促进机辅助自动驾驶系统的发展具有重要意义。
## 429. `cs.CV` - 图像辅助的多模态推理：基础、方法与未来前沿 [PDF](https://arxiv.org/pdf/2506.23918), [HTML](https://arxiv.org/abs/2506.23918)
### Authors
Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R. Fung
### Background
近期，多模态推理得到了显著推进，这主要得益于文本链式思维（CoT），一种模型在语言内进行推理的范式。然而，这种以文本为中心的方法将视觉视为静态的初始上下文，存在着丰富的感知数据和离散符号思维之间的“语义差距”。人类认知常常超越语言，利用视觉作为动态的心理草图。AI现在正在经历类似的演变，从仅仅思考图像到能够真正使用图像进行思考，标志着从模型以图像为对象思考到以图像为工具进行思考的根本范式转变。
### Innovation
本文制定了图像辅助思维的三个阶段框架及其基本原理，全面回顾了每个发展阶段的核心方法，分析了评价基准和变革性应用的关键景观，并指出了重大挑战和潜在的研究方向，旨在为未来更强大且与人类目标更加一致的多模态AI提供清晰的研究脉络和路线图。
### Conclusion
通过提供本文结构化的概述，我们希望能为未来的研究提供明确的路线图，推动更强大的多模态AI的发展。
## 430. `cs.CV` - PriOr-Flow: 基于正交视图增强原生全景光学流 [PDF](https://arxiv.org/pdf/2506.23897), [HTML](https://arxiv.org/abs/2506.23897)
### Authors
Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang
### Background
全景光学流能够全面理解广阔视野中的时空动态，但球面到平面的投影，如等面积圆柱投影（equirectangular projection, ERP），会严重削弱基于透视的传统光学流方法的性能，尤其是在极区。这种投影造成的严重失真尤其影响家庭尺度以上的光学流估计准确性。
### Innovation
本文提出了一种名为PriOr-Flow的新型双分支框架，该框架利用正交视图的低失真特性来提升极区的光学流估计。具体而言，引入了双成本协作查找（DCCL）运算符，该运算符从基础和正交成本体积中共同检索相关性信息，有效降低了成本体积构建过程中的失真噪声。此外，Ortho-Driven Distortion Compensation (ODDC) 模块迭代地从两个分支中细化运动特征，进一步消除极区的失真。
### Conclusion
大量实验表明，PriOr-Flow 能够兼容多种基于透视的迭代光学流方法，并在公开的全景光学流数据集上持续达到最新技术水平，设置了广泛视野运动估计的新标准。完整的代码可以在该链接：this https URL 处获取。
## 431. `cs.CV` - 使用程序化场景扰动评估单目深度估计的鲁棒性 [PDF](https://arxiv.org/pdf/2507.00981), [HTML](https://arxiv.org/abs/2507.00981)
### Authors
Jack Nugent,Siyang Wu,Zeyu Ma,Beining Han,Meenal Parakh,Abhishek Joshi,Lingjie Mei,Alexander Raistrick,Xinyuan Li,Jia Deng
### Background
近年来，单目深度估计取得了显著进展，特别是在大型模型在标准基准上的成功。然而，标准基准的性能评估并未提供全面的情况，因为大多数评估仅关注准确性而非鲁棒性。
### Innovation
该研究引入了PDE（程序化深度评估），这是一种新的基准，能够进行系统的鲁棒性评估。PDE 利用程序化生成创建3D场景，用于测试对各种可控扰动（包括物体、相机、材料和照明变化）的鲁棒性。分析结果显示了当前最先进技术在哪些扰动情况下具有挑战性，并希望能指导进一步的研究。
### Conclusion
本研究通过PDE基准，通过程序化生成的场景测试鲁棒性，填补了标准基准在鲁棒性评估上的不足。
## 432. `cs.CV` - 相似性记忆先验对于医学图像分割至关重要 [PDF](https://arxiv.org/pdf/2507.00585), [HTML](https://arxiv.org/abs/2507.00585)
### Authors
Tang Hao,Guo ZhiQing,Wang LieJun,Liu Chao
### Background
近年来，研究发现猕猴初级视觉皮层（V1）中的“祖母细胞”可以直接识别具有复杂形状的视觉输入，这启发我们重新审视这些细胞在促进医学图像分割研究中的价值。因此，本文提出了一个用于医学图像分割的相似性记忆先验网络（Sim-MPNet）。
### Innovation
本文提出了一个使用相似性记忆先验的网络，具体来说，引入了一种动态记忆权重-损失注意力（DMW-LA），能够通过原型记忆库中的相似性记忆先验匹配和记住医学图像中特定病变或器官的类别特征，有助于网络学习类别间细微的纹理变化。同时，提出的Double-Similarity全局内部增强模块（DS-GIM）通过余弦相似性和欧氏距离深入探索输入数据中的内部特征差异，增强了网络提取类别特征的能力。
### Conclusion
大量实验表明，Sim-MPNet在四个公开数据集上的分割性能优于其他最先进的方法。代码已在该网址 https://... 可用。
## 433. `cs.CV` - HOI-Dyn: 学习人类物体间互动动力学 [PDF](https://arxiv.org/pdf/2507.01737), [HTML](https://arxiv.org/abs/2507.01737)
### Authors
Lin Wu,Zhixiang Chen,Jianglin Lan
### Background
生成真实的3D人类物体互动（HOIs）是一项具有挑战性的任务，因为难以模型化复杂的互动动力学。现有的方法独立处理人类和物体的运动，导致行为不物理和因果不一致。因此，迫切需要一种新方法来解决这一问题，从而生成更真实和连贯的HOIs。
### Innovation
提出了HOI-Dyn框架，将HOI生成视为驱动者-响应者系统，其中人类动作驱动物体反应。方法的核心是一个轻量级的基于Transformer的互动动力学模型，可以明确预测物体应如何对人类运动做出反应。为了进一步确保一致性，引入基于残差的动力学损失，以减轻动态预测误差的影响并防止误导性的优化信号。动态模型仅在训练期间使用，确保推理效率不受影响。
### Conclusion
通过广泛的定性和定量实验，展示了该方法不仅提高了HOI生成的质量，还为评估生成互动的质量提供了可行的度量标准。
## 434. `cs.CV` - TurboReg: TurboClique for Robust and Efficient Point Cloud Registration [PDF](https://arxiv.org/pdf/2507.01439), [HTML](https://arxiv.org/abs/2507.01439)
### Authors
Shaocheng Yan,Pengcheng Shi,Zhenjun Zhao,Kaixin Wang,Kuang Cao,Ji Wu,Jiayuan Li
### Background
现有的基于兼容图的最大团搜索(PCR)方法虽然能够实现高召回率，但由于具有指数级的时间复杂性，限制了其在时间敏感的应用中的使用。点云配准（PCR）中的鲁棒估计是一个关键但具有挑战性的问题，特别是在处理大量数据时，需要快速且稳定的匹配方式以提高效率和准确性。
### Innovation
该研究提出了TurboReg，一种基于新型轻量级团（TurboClique）和高并行化的Pivot-Guided Search (PGS)算法的快速且鲁棒的估计器。TurboClique是在高度约束的兼容图中的3-团，允许高效的并行搜索，并通过Pivot-Guided Search算法选择具有高一致性的配对，从而实现更有效的搜索。此外，PGS算法的时间复杂度为线性，显著优于指数复杂度的最大团搜索方法。
### Conclusion
通过广泛的实验论证，TurboReg在多个真实世界数据集上实现了最先进的性能，提供了显著的速度提升。例如，在3DMatch+FCGF数据集上，TurboReg（1K）比3DMAC快208.22倍，同时保持较高的召回率。TurboReg的代码可在指定链接获取。
## 435. `cs.CV` - LLaVA-SP: 使用视觉空间标记增强MLLMs的视觉表示 [PDF](https://arxiv.org/pdf/2507.00505), [HTML](https://arxiv.org/abs/2507.00505)
### Authors
Haoran Lou,Chunxiao Fan,Ziyan Liu,Yuexin Wu,Xinliang Wang
### Background
现有的多模态大型语言模型（MLLMs）通常通过CLIP-ViT等视觉编码器连接到大型语言模型。尽管CLIP-ViT在捕捉全局图像特征方面表现良好，但在建模相邻补丁之间的局部关系方面表现欠佳，导致视觉表示较弱，进而影响MLLMs的详细理解能力。
### Innovation
本文提出了一种新的方法，即LLaVA-SP，它仅通过在原始视觉标记中添加六个空间视觉标记来增强视觉表示。具体创新包括：1) 提出了一种新的投影器，该投影器使用卷积核从ViT补丁特征中推导出视觉空间标记，模拟了两种视觉空间排序方法，并应用于交叉注意力机制以融合细粒度的视觉信息，从而丰富整体视觉表示。2) 提出了两种模型变体：一个侧重于通过渐进裁剪关注细节特征，另一个侧重于通过自适应池化捕捉全局语义，从而使模型能够处理各种视觉理解任务。3) 通过大量实验表明，LLaVA-SP 经过 LoRA 微调后，在各种多模态基准测试中取得了显著性能提升，在多项任务中几乎保持相同的推理延迟，优于最新的 LLaVA-1.5 模型。
### Conclusion
LLaVA-SP 经过 LoRA 微调后，实现了在多种多模态基准测试中相对于现有最先进的 LLaVA-1.5 模型的性能提升，同时保持了相似的推理延迟。并提供了代码和模型供参考。
## 436. `cs.CV` - 模态无关的患者特异性数字孪生模型模拟动态消化运动 [PDF](https://arxiv.org/pdf/2507.01909), [HTML](https://arxiv.org/abs/2507.01909)
### Authors
Jorge Tapias Gomez,Nishant Nadkarni,Lando S. Bosma,Jue Jiang,Ergys D. Subashi,William P. Segars,James M. Balter,Mert R Sabuncu,Neelam Tyagi,Harini Veeraraghavan
### Background
当前临床上应用变形图像配准（DIR）方法需要基于体素的空间精度指标，如手动标记的解剖标志，但对于高度移动的消化道器官来说，实现具有挑战性。因此，该研究旨在通过创建患者特异性的数字孪生模型来评估DIR方法的准确性，以解决上述问题。数字孪生模型被用来模拟消化道在4D序列中的动态运动。
### Innovation
研究开发了一个模态无关的患者特异性数字孪生模型，用于模拟消化道的动态运动。该模型通过半自动化的流程从静态3D患者扫描中生成21个模拟消化道运动的4D序列。研究还使用该模型评估了六种不同的DIR方法的效果，包括使用目标注册误差、Dice相似系数和百分位Hausdorff距离的量化指标和体素级别的可视化分析。此外，通过将不同模态的MRI扫描进行变形配准并积累计算剂量分布误差，以评估在低剂量和高剂量区域的DIR性能
### Conclusion
研究提出的方法成功地建立了能够模拟实际患者胃部运动的数字孪生模型，实现了精度接近临床实际数据的目标，并能提取详细的定量DIR性能指标，确保剂量映射的准确性。这种方法可以为具有动态和解剖复杂性的区域提供细致的空间和剂量准确性测试。
## 437. `cs.CV` - 基于深度迁移学习的肾癌诊断 [PDF](https://arxiv.org/pdf/2408.04318), [HTML](https://arxiv.org/abs/2408.04318)
### Authors
Yassine Habchi,Hamza Kheddar,Yassine Himeur,Mohamed Chahine Ghanem,Abdelkrim Boukabou,Shadi Atalla,Wathiq Mansoor,Hussain Al-Ahmad
### Background
不可治愈的疾病继续对全球的医疗保健体系构成重大挑战，其流行率受到生活方式、经济、社会和遗传因素的影响。其中，肾脏疾病仍然是全球健康的关键问题，需要持续的研究来提高早期诊断和治疗。近年来，深度学习在医学成像和诊断领域显示出了巨大潜力，推动了自肾癌自动检测方面的重大进展。但是，深度学习模型的成功依赖于高质量、特定领域的数据集，这些数据集往往数量有限且成本高昂。此外，深度学习模型还需要大量的计算资源和存储空间，限制了其在临床环境中的实际应用。为克服这些障碍，迁移学习已经成为一种有效的途径，可以利用其他相关领域的预训练模型提高肾癌诊断效果。
### Innovation
该论文对基于深度学习的迁移学习框架进行了全面的综述，系统地回顾了关键方法、优点和局限性，分析了其实际表现，并讨论了将迁移学习应用于医学影像中所面临的挑战及其未来研究趋势。该综述展示了迁移学习在精准医学，特别是在肿瘤学中，通过提高诊断准确性、降低计算需求和支持人工智能工具在医疗领域的集成而发挥的变革性作用。
### Conclusion
该研究为未来的肾癌诊断和个性化治疗策略的进步提供了宝贵的见解，为研究人员和实践者提供了宝贵的指导，推动了AI在医疗保健领域的作用。
## 438. `cs.CV` - LUDO: 使用点云占用函数实现可变形物体的低延迟理解 [PDF](https://arxiv.org/pdf/2411.08777), [HTML](https://arxiv.org/abs/2411.08777)
### Authors
Pit Henrich,Franziska Mathis-Ullrich,Paul Maria Scheikl
### Background
准确地确定可变形物体的形状及其内部结构对于需要精确目标定位的医疗任务至关重要，如机器人活检。传统的解决方法在处理这类问题时具有延迟高、计算复杂等缺点，这限制了其在实时医疗操作中的应用效果。
### Innovation
LUDO方法通过占用网络从单视角的点云观测中在30毫秒内重建物体的变形状态及其内部结构，同时提供了预测的不确定性估计。此外，LUDO还可以通过突出显示输入观察中的重要特征提供解释性，这对手术等关键应用非常重要。LUDO与常见的基线方法相比，展示了更高的ROI定位精度、更快的训练时间和更少的内存需求，具有低延迟理解可变形物体的潜力，解决了传统的变形注册方法的需要。
### Conclusion
通过在实际机器人实验中测试LUDO，表明其成功识别各种感兴趣区域的准确率为98.9%，并在精度、训练时间和内存要求方面优于基线方法，展示了在无需使用变形注册方法的情况下能够与可变形物体交互的潜力。
## 439. `cs.CV` - SHuBERT：通过多流聚类预测进行自监督手语表示学习 [PDF](https://arxiv.org/pdf/2411.16765), [HTML](https://arxiv.org/abs/2411.16765)
### Authors
Shester Gueuwou,Xiaodan Du,Greg Shakhnarovich,Karen Livescu,Alexander H. Liu
### Background
手语处理传统的做法是依赖于特定任务的模型，这限制了在不同任务之间应用迁移学习的潜力。现有的手语预训练方法要么依赖于有监督的预训练，无法利用无标签数据，要么是上下文无关的（帧或视频片段）表示，忽略了手语中时间关系的影响。
### Innovation
SHuBERT（手语隐单元BERT）是一种自监督的上下文表示模型，通过大约1000小时的美国手语视频进行学习。SHuBERT将遮蔽标记预测目标应用于多流视觉手语输入，学习预测多个与手部、面部和身体姿态流相对应的目标。该模型在包括手语翻译、孤立手语识别和手指拼写检测等任务中达到了最先进的性能。
### Conclusion
SHuBERT实现了多个任务上的SOTA性能，展现了在手语处理中自监督学习和多流聚类预测的有效性。
## 440. `cs.CV` - TAROT: 目标数据选择通过最优传输 [PDF](https://arxiv.org/pdf/2412.00420), [HTML](https://arxiv.org/abs/2412.00420)
### Authors
Lan Feng,Fan Nie,Yuejiang Liu,Alexandre Alahi
### Background
当前的靶向数据选择方法主要依赖于基于影响的贪婪启发式策略来增强特定领域的性能。这些方法在单模态数据（即遵循单一模式的数据）上表现很好，但在复杂数据（如多模态分布）上效果不佳。特别是在多模态分布中，这些启发式策略未能考虑到多种内在模式，导致数据选择效果欠佳。主要问题有两个方面：一是高维影响力估计中主导特征成分的巨大影响，二是贪婪选择策略固有的线性加性假设上的局限性。
### Innovation
TAROT引入了去色特征距离来缓解主导特征偏向性，提供了一种更可靠的度量数据影响的方法。在此基础上，TAROT使用去色特征距离来量化并最小化选择的数据与目标域之间的最优传输距离。此外，通过最小化过程还可以估计出最佳选择比率。TAROT在语义分割、运动预测和指令调优等多个任务中进行了评估，结果显示其性能优于现有最先进的方法，展示了其在各种深度学习任务中的通用性。
### Conclusion
TAROT通过基于最优传输理论的目标数据选择框架，在复杂数据集上表现出更好的选择能力和适应性，显著提升了各领域特定任务的性能，因此具有很高的实用价值和研究意义。
## 441. `cs.CV` - 使用轻型林下无人机进行自主光谱测量森林资源调查 [PDF](https://arxiv.org/pdf/2501.12073), [HTML](https://arxiv.org/abs/2501.12073)
### Authors
Väinö Karjalainen,Niko Koivumäki,Teemu Hakala,Jesse Muhojoki,Eric Hyyppä,Anand George,Juha Suomalainen,Eija Honkavaara
### Background
无人机在林业中的应用越来越广泛，主要用于收集高分辨率遥感数据，以支持监测、评估和决策过程。虽然在树冠上方的操作已经高度自动化了，但在森林内部飞行仍然具有挑战性，主要依赖手动操控。在密集的森林中，使用全球导航卫星系统（GNSS）进行定位不可行。此外，无人机必须自主调整飞行路线以避免碰撞。最近，机器人技术的进步使得无人机能够在GNSS禁用且障碍物丰富的区域自主飞行。本文旨在通过构建一种基于最新开源方法的轻型林下无人机原型，实现森林内部数据采集的自主化，并验证其在低成本机载立体摄像头数据采集后的光谱测量能力。树参数估计能力通过胸高直径（DBH）估计进行研究。
### Innovation
本文介绍了一种轻型林下无人机原型的设计与验证过程，该无人机利用最新的开源技术实现了在GNSS禁用且障碍物丰富的森林环境中的自主飞行。通过胸径估算等方法验证了其在森林3D建模中的表现，达到了满意的精度水平，这对于推进轻型机器人无人机系统在复杂森林环境中的应用具有重要意义。
### Conclusion
该研究展示了轻型林下无人机在自主森林3D建模和树高估测方面的有效性能，得到了胸径估算的极佳结果，无论是总体还是小型树木。这一研究成果为自主林下森林测绘提供了有价值的见解，并指出了进一步改进轻型机器人无人机系统、应对复杂森林环境的关键步骤。
## 442. `cs.CV` - Anatomical Foundation Models for Brain MRIs [PDF](https://arxiv.org/pdf/2408.07079), [HTML](https://arxiv.org/abs/2408.07079)
### Authors
Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto
### Background
深度学习（DL）在神经影像学中的应用越来越重要，特别是在检测神经性疾病和神经退行性疾病方面。脑龄作为一种最显著的神经影像学生物标志物，已被证明是不同条件（如阿尔茨海默病）的良好指示器。有研究表明，在面对不同条件数据稀缺性的环境中，使用脑龄对深度学习模型进行弱监督预训练具有前景。同时，脑白质影像的解剖学信息（如皮质厚度）能够提供对于学习良好表示的重要信息，这些表示可以转移到许多下游任务中。
### Innovation
本文提出了AnatCL，一种基于解剖学信息的脑部MRI基础模型，该模型通过弱对比学习方法利用解剖学信息，并在多种不同的下游任务中实现了最先进的性能。该模型在诊断阿尔茨海默病、注意缺陷多动障碍和精神分裂症等不同疾病的12个下游任务上进行了验证。此外，还使用结构MRI数据预测了10种不同的临床评估分数。结果表明，在预训练过程中融入解剖学信息能够提高表示的鲁棒性和泛化能力。模型可在此链接中找到:https://doi.org/10.5281/zenodo.8055977
### Conclusion
通过预训练将解剖学信息整合能够产生更稳健和泛化性更好的表示。预训练模型可在该网址找到:https://doi.org/10.5281/zenodo.8055977。
## 443. `cs.CV` - 从生成模型学习实时观测中的交通异常 [PDF](https://arxiv.org/pdf/2502.01391), [HTML](https://arxiv.org/abs/2502.01391)
### Authors
Fotis I. Giasemis,Alexandros Sopasakis
### Background
准确检测交通异常对于有效的城市交通管理和缓解拥堵至关重要。本文使用结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，以捕捉交通数据中的复杂空间和时空依赖性。这些异常包括摄像头信号中断、视觉伪影以及极端天气条件等。这些异常会影响交通流量和管理效果，因此需要有效的检测方法。
### Innovation
本文创新性地点将时空生成对抗网络（STGAN）应用于实时交通观测数据，结合图神经网络和长短期记忆网络捕捉复杂的空间和时间依赖性，以准确检测交通异常。通过应用该模型到哥德堡，瑞典的42个实时交通摄像头数据，展示了该方法的有效性和精确度，具有较低的假阳性率。
### Conclusion
实验结果表明，该模型在检测交通异常方面具有高精度和低假阳性率。检测出的异常包括摄像头信号中断、视觉伪影和极端天气条件对交通流量的影响。这些发现为有效城市交通管理和缓解拥堵提供了重要支持。
## 444. `cs.CV` - 跨语言之旅：多模态LLM交叉语言一致性评估 [PDF](https://arxiv.org/pdf/2505.15075), [HTML](https://arxiv.org/abs/2505.15075)
### Authors
Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara
### Background
多模态大型语言模型（MLLMs）的快速进化显著提升了其在真实世界中的应用，但如何在不同语言之间保持一致的表现，尤其是在整合文化知识时，仍然是一个重要挑战。这项研究通过引入两个新的基准测试——KnowRecall和VisRecall，来评估MLLMs的跨语言一致性。KnowRecall作为视觉问答基准测试，旨在衡量15种语言中的事实性知识一致性，重点关注全球地标的文化和历史问题。VisRecall则评估模型的视觉记忆一致性，询问模型在不利用图像的情况下，用9种不同语言描述地标外观。实验结果表明，包括专有模型在内的最佳MMLMs依然难以实现跨语言一致性，这凸显了需要更稳健的方法来生成真正多语言且文化感知强的模型的重要性
### Innovation
该研究创新性地引入了 KnowRecall 和 VisRecall 两个新的基准测试，用于评估多模态大型语言模型在不同语言之间的跨语言一致性。特别是在跨语言评估模型的文化知识和视觉记忆一致性方面，这是以往研究的突破性进展
### Conclusion
这项研究表明，当前最先进多模态大型语言模型仍然难以在跨语言一致性上取得突破，揭示了构建真正多语言且文化感知强的模型的重要性。
## 445. `cs.CV` - 使用双向离散过程匹配方法的双模态医学图像合成 [PDF](https://arxiv.org/pdf/2409.03977), [HTML](https://arxiv.org/abs/2409.03977)
### Authors
Zhe Xiong,Qiaoqiao Ding,Xiaoqun Zhang
### Background
近年来，随着生成模型的快速发展，医学图像合成越来越受到关注。医学图像合成的目标是从观察到的数据模态中生成未采集到的图像模态，这种合成图像可用于临床诊断辅助、模型训练和验证数据扩充，以及图像质量改进。尽管流基模型被认为是生成现实且高质量合成图像的高效方法之一，但大多数流基模型在生成过程中需要计算许多时间迭代步骤的普通微分方程（ODE）流，这往往受到大量计算时间和性能的限制。
### Innovation
本文提出了一种新的流基模型——双向离散过程匹配（Bi-DPM），以实现双模态图像合成任务。与基于流匹配的其他模型不同，Bi-DPM 使用前向和后向ODE流，并通过几个离散时间步骤增强中间图像的一致性，从而使合成过程在配对数据的指导下，能够同时保持高质量的两个模态生成图像。实验结果显示，Bi-DPM 在三种MRI T1/T2和CT/MRI数据集上均优于其他最先进的流基方法，提供了高质量且准确的解剖区域图像生成效果。
### Conclusion
本研究提出的Bi-DPM方法，通过利用双向流匹配机制，能够在配对数据指导下高效生成高质量的双模态医学图像，显著提升了双模态图像合成的质量和效率，为医学图像合成领域提供了新的解决方案。
## 446. `cs.CV` - 使用Wasserstein距离方法进行照度和光照方向估计 [PDF](https://arxiv.org/pdf/2503.05802), [HTML](https://arxiv.org/abs/2503.05802)
### Authors
Selcuk Yazar
### Background
在图像处理领域，特别是在机器人技术中，光照估计仍然是关键挑战之一，尤其是在光照条件变化多样的环境中，需要实现鲁棒的环境感知。传统的光照估计方法，如RGB直方图和GIST描述符等，由于对光照变化的敏感性，往往在复杂场景中失效。因此，需要一种新的方法来解决这一问题。
### Innovation
该研究提出了一种新的方法，利用最优传输理论中的Wasserstein距离来估计图像中的照度和光照方向。这种方法在多种类型的图像场景中（室内场景、黑白照片和夜景图像）显示出在复杂光照环境下的有效性，优于传统的统计方法，能够在检测主要光源及其方向方面取得更好的效果。此外，该方法在光源定位、图像质量评估和物体检测增强方面也显示出应用潜力。
### Conclusion
该研究的方法具有稳定性和准确性，为在机器人及未来技术中的实际光照挑战提供了一种可扩展的解决方案。未来的研究可以考虑自适应阈值设置和梯度分析来进一步提高准确性。
## 447. `cs.CV` - SPACE-SUIT：基于人工智能的太阳日冕特征提取和分类器 [PDF](https://arxiv.org/pdf/2412.08589), [HTML](https://arxiv.org/abs/2412.08589)
### Authors
Pranava Seth,Vishal Upendran,Megha Anand,Janmejoy Sarkar,Soumya Roy,Priyadarshan Chaki,Pratyay Chowdhury,Borishan Ghosh,Durgesh Tripathi
### Background
SUIT机载望远镜Aditya-L1通过观测200-400 nm波长的太阳光球和色球进行成像。充分理解色球和光球形态结构的等离子体和热力学性质需要大规模样本统计研究，因此开发了自动特征检测方法。为此，开发了名为SPACE-SUIT的特征检测算法：基于增强视觉技术的SUIT太阳现象分析和分类，用于从SUIT的Mg II k滤镜中检测和分类将要观测的日冕特征，具体包括句点区域、太阳黑子、日珥和日轮结构。
### Innovation
开发了一种基于YOLO神经网络模型的自动特征检测算法SPACE-SUIT，用于从SUIT观测中检测和分类太阳色球特征。通过使用来自Interface Region Imaging Spectrometer (IRIS)的模拟SUIT图像进行训练和验证，SPACE-SUIT在验证的mock SUIT FITS数据集上实现了78.8%的精度、86.3%的召回率和87.4%的MAP。通过统计测量和Tamura特征对真实值和预测边界框进行“自我验证”，结果展示了由SPACE预测的检测区域与观察到的SUIT图像中的特征之间的定性一致性，这证明了统计度量和Tamura特征在区分色球特征方面的有效性，为今后的检测方案提供了独立验证。
### Conclusion
该研究不仅开发了色球特征提取器，而且还证明了统计度量和Tamura特征的有效性，这些特征可以区分色球特征，并为未来的检测方案提供独立验证。
## 448. `cs.CV` - 迈向可解释的特征嵌入比较与对齐 [PDF](https://arxiv.org/pdf/2506.06231), [HTML](https://arxiv.org/abs/2506.06231)
### Authors
Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia
### Background
尽管文献中已经开发了多种特征嵌入模型，但这些嵌入在分类相关下游应用中的数值性能比较占据主导地位。然而，不同嵌入的可解释性比较需要识别和分析嵌入空间中样本集群之间的不符之处。本文旨在填补这一空白，提出一种名为Spectral Pairwise Embedding Comparison (SPEC)的框架，用于比较嵌入并在参考数据集上识别其差异，特别是在聚类方面。
### Innovation
本文创新地提出了Spectral Pairwise Embedding Comparison (SPEC)框架，通过比较两个嵌入的核矩阵的特征值分解来检测并识别样本簇之间的差异。此外，采用基于核的方法实现该框架，并提供了一个可扩展的实现方案，其计算复杂度线性增长。基于此框架引入了一个优化问题来实现在不同嵌入间对齐。通过在大规模数据集（如ImageNet和MS-COCO）上对SPEC的应用进行了数值结果验证。
### Conclusion
通过SPEC框架，不但能够对大规模数据集上的嵌入进行比较和对齐，还确保了一个嵌入中识别出的聚类在另一个模型中也能得到捕捉，进而提升模型的可解释性。
## 449. `cs.CV` - HAPI: 一个从人类偏好中学习机器人面部表情的模型 [PDF](https://arxiv.org/pdf/2503.17046), [HTML](https://arxiv.org/abs/2503.17046)
### Authors
Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida
### Background
自动机器人面部表情生成对于人机交互至关重要，但基于固定关节配置的手工方法往往会使行为显得僵硬和不自然。尽管近期自动化技术减少了手动调整的需求，但在提取人类偏好和模型预测之间的差距方面仍存在不足，导致生成的表情缺乏细腻和现实感，这主要是由于自由度不足和感知集成不足。因此，需要一种新的方法来填充这一空白并增强机器人的面部表情表达能力
### Innovation
本文提出了一种新的学习排序框架，该框架利用人类反馈来解决这一问题，并增强了机器人的面部表情表达能力。该方法包括对人类偏好的成对比较注释，以及开发了基于Siamese RankNet的Human Affective Pairwise Impressions (HAPI)模型，该模型可细化表情评估。实验结果通过贝叶斯优化和在线表情调查，证明了该模型比基准方法和专家设计的方法能生成更加真实和社会共鸣的表情，如愤怒、快乐和惊讶，这表明该框架能有效填补人工偏好和模型预测之间的差距，同时稳健地调整机器人表情生成与人类情感响应的一致性
### Conclusion
我们的方法能够显著提高机器人面部表情的现实性和社会共鸣性，并能有效打通人类偏好与模型预测之间的鸿沟。
## 450. `cs.CV` - 基于粗细扩散模型的MRI重建中非刚性运动校正 [PDF](https://arxiv.org/pdf/2505.15057), [HTML](https://arxiv.org/abs/2505.15057)
### Authors
Frederic Wang,Jonathan I. Tamir
### Background
MRI由于需要较长的k空间采样时间，容易受到运动伪影的影响。这些伪影可能损害诊断效用，尤其是在动态成像中。目前对非刚性运动的校正方法通常效果不佳，不能很好地处理大量采样的数据。
### Innovation
本文提出了一种新颖的交替最小化框架，利用定制的扩散模型联合重构和修正非刚性运动损伤的数据。该扩散模型采用自上而下的去噪策略，捕捉大范围运动并优先重构图像的低频部分，从而为运动估计提供更好的归纳偏差，优于标准扩散模型。即使在一个运动状态下信号采样率低至64倍，该方法仍能有效处理真实世界的心脏MRI数据和复杂模拟运动变形数据。此外，该方法对于不同采样模式、解剖变异和MRI扫描协议具有普适性，只要在每个运动状态下采样一定的低频成分即可。
### Conclusion
该研究通过提出新的交替最小化框架和自上而下的扩散模型，成功地在MRI重建中校正了非刚性运动伪影，即使在低采样率下也能良好处理数据。该方法对多种应用场景具有普适性，有望提高MRI图像的质量和诊断效率。
## 451. `cs.CV` - ODE$_t$(ODE$_l$): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling [PDF](https://arxiv.org/pdf/2506.21714), [HTML](https://arxiv.org/abs/2506.21714)
### Authors
Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer
### Background
近期，连续同构流（CNFs）和扩散模型（DMs）被通过统一理论框架进行了研究。尽管这些模型能够从噪声分布中生成高质量的数据点，但在采样过程中需要多次迭代求解常微分方程（ODE），这带来了较高的计算复杂性。目前大多数方法都集中在减少采样过程中的时间步骤数量，以提高效率。
### Innovation
本文探索了一种互补的方向，即在时间和长度上动态控制质量与复杂度之间的权衡。通过在变压器架构中重新连接组件来解决内嵌离散化ODE，且在流动匹配训练中采用时间与长度上的一致性项，从而允许以任意数量的时间步骤和变压器块进行采样。与其它方法不同，本研究的时间维度上的ODE$_t$(ODE$_l$)方法与求解器无关，在降低延迟和内存使用方面表现出色。在CelebA-HQ和ImageNet图像生成实验中，相较于先前的最佳实践，最高可实现3倍的延迟降低，并且高质量的样本可以获得3.5点的FID分数提升。
### Conclusion
我们展示了我们的代码和模型权重，并确保实验完全可再现。
## 452. `cs.CV` - 逃离柏拉圖洞穴：JAM实现独立训练的视觉和语言模型的对齐 [PDF](https://arxiv.org/pdf/2507.01201), [HTML](https://arxiv.org/abs/2507.01201)
### Authors
Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim
### Background
独立训练的视觉和语言模型存在于不同的表示空间中，各自由其模态、目标和架构塑造。然而，一个新兴假设——柏拉图表示假设——表明这些模型可能朝着一种共享现实统计模型收敛。这种一致性的存在引发了根本问题：我们能否超越事后统计检测的方式来明确优化它们的对齐？
### Innovation
作者将这种柏拉图对齐问题构建为一个多目标优化任务，即保持每种模态的原始结构同时实现互相关联。为此，引入了一种名为Joint Autoencoder Modulator (JAM)的框架，该框架通过联合训练预训练的单一模态模型的潜在表示的专业自编码器，鼓励通过重构和跨模态目标进行对齐。此外，研究还探讨了对齐目标、最优层深度及基础模型规模对表示收敛的影响。自己的贡献在于呈现一个轻量级的Pareto高效框架，即使在冻结和独立训练的表示中也能可靠地诱导对齐，提供了从一般主义单模模型向专家多模模型转化的理论见解和实践途径。
### Conclusion
研究发现，该框架能够有效地在独立训练的视觉和语言模型间诱导对齐，为将通用单模基模型转化为专一多模模型提供了理论和实践路径。
## 453. `cs.CV` - MTCNet: 4D超声心动图中引导动理学和拓扑一致性学习的二尖瓣分割 [PDF](https://arxiv.org/pdf/2507.00660), [HTML](https://arxiv.org/abs/2507.00660)
### Authors
Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni
### Background
二尖瓣反流是临床上最普遍的心脏疾病之一。四维（4D）超声心动图因其能够动态评估瓣膜形态而成为评估瓣膜形态的主要成像技术。然而，4D二尖瓣（MV）分析仍然具有挑战性，原因包括标注不完整、严重动态伪影以及成像质量不佳。现有的方法缺乏相位间的依赖性，这限制了4D MV分析的进展。因此，需要一种能够利用空间-时间特征在不同相位间传导的方法，并能够利用结构对应关系的算法来解决这些挑战，特别是在半监督学习（SSL）环境下实现4D MV分割的准确性和一致性.
### Innovation
本文提出了一种名为MTCNet的动理学和拓扑一致性网络，用于4D超声心动图中二尖瓣的半监督学习分割。MTCNet设计了一种跨相动理学指导的一致性学习策略，并利用双向注意记忆库传播时空特征，实现了相位内和相位间的卓越性能。此外，MTCNet还设计了一种新颖的拓扑引导相关正则化，充分利用物理先验知识，保持解剖上合理的结构对应关系。相对于其他高级方法，MTCNet在1408个相位（来自160名患者）的最大4D MV数据集上展示出更好的跨相位一致性（Dice：87.30%，HD：1.75mm）.
### Conclusion
通过大量的评估，MTCNet在4D MV超声心动图的分割上表现出了显著的优势，尤其是在跨相位一致性方面。该研究提供了一个能够有效利用不同相位之间结构对应关系的网络，并且在4D MV分割中实现了卓越的效果。此外，该研究还为未来其他相关研究提供了宝贵的经验和方法论基础。
## 454. `cs.CV` - AI Flow: 视角、场景和方法 [PDF](https://arxiv.org/pdf/2506.12479), [HTML](https://arxiv.org/abs/2506.12479)
### Authors
Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li
### Background
从克劳德·香农的信息理论和艾伦·图灵的机器智能框架起步，信息技术（IT）和通信技术（CT）的融合进化创造了一个持久的连接与计算潮汐。这种协同作用推动了技术革命，当前正处于大型人工智能（AI）模型重塑行业并重新定义人机合作的顶峰阶段。然而，实现普遍智能面临巨大挑战，因为大型模型的资源消耗巨大且对高通信带宽的需求高。为应对这些挑战，引入了一种名为AI Flow的多学科框架，该框架整合了最新的人工智能和通信技术进步，特别强调以下三个关键点：首先，设备-边缘-云框架奠定基础，整合末端设备、边缘服务器和云集群，优化低延迟模型推理的可扩展性和效率；其次，提出了家族模型的概念，指的是具有对齐的隐藏特征的一系列不同大小的模型，允许有效的协作并灵活适应不同的资源约束和动态场景；最后，基于连接和互动的智能涌现是AI Flow的新型范式。通过利用通信网络增强连接性，异构节点之间的AI模型协作实现超越任何单一模型的能力的智能涌现。
### Innovation
AI Flow 提供了增强的智能、及时的响应能力和广泛的人工智能服务访问性，为更紧密的人工智能技术和通信系统结合奠定了基础。特别强调了三个创新点：设备-边缘-云框架、家族模型和基于连接和互动的智能涌现。这些创新解决了大型模型的资源消耗高和高通信带宽需求的问题，通过优化可扩展性和效率，提供了更高效的低延迟模型推理能力，并增强了不同大小模型之间的有效协作和适应不同资源场景的灵活性，同时通过通信网络增强连接性实现跨异构节点的AI模型协作，从而实现超越单一模型的智能涌现能力。
### Conclusion
AI Flow 为更广泛的人工智能服务访问提供了可靠且高效的框架，提升了智能、响应性和连接性，为人工智能技术与通信系统的深度融合铺平了道路。
## 455. `cs.LG` - 基于连续小波变换和Siamese网络的多变量半导体工艺时间序列异常检测 [PDF](https://arxiv.org/pdf/2507.01999), [HTML](https://arxiv.org/abs/2507.01999)
### Authors
Bappaditya Dey,Daniel Sorensen,Minjin Hwang,Sandip Halder
### Background
半导体制造是一个极其复杂的流程，涉及成千上万个相互依赖的参数，分布在不同的工具和工艺步骤中。多变量时间序列（MTS）分析已成为实现实时监控、故障检测和预测维护的关键方法。然而，在半导体制造过程中进行异常预测存在多个重要挑战，包括高数据维度、由于真正故障罕见而造成的严重类别不平衡、噪声和缺失的测量数据，以及生产系统的非稳定性等。这些挑战使得故障检测和根本原因分析都变得复杂。在多变量时间序列数据中进行异常检测也是以往研究的难点之一。
### Innovation
本文提出了一种新颖且通用的方法，用于多变量半导体工艺时间序列数据中的异常检测，利用机器学习技术。该方法包括三个主要步骤：a) 使用连续小波变换将MTS数据转换为图像表示；b) 使用预训练的VGG-16架构在自定义CWT图像数据集上进行微调，建立一个多类图像分类器；c) 构建一个由两个相同的子网络组成的Siamese网络，每条支路都以微调的VGG-16作为骨干。该网络接收一对CWT图像作为输入，一个是参考或锚点图，代表已知良好的信号；另一个是查询图，代表未知信号。模型将比较两个输入的嵌入，以确定它们是否属于同一类别。这种方法能够在真实的晶圆厂过程时间序列数据集上实现高精度的异常检测，提供了一种有前景的解决方案，可应用于过程和工具追踪数据中的离线异常检测，并且具备灵活性，可在监督和半监督设置下应用。
### Conclusion
本文提出的方法能够在多变量半导体制造过程中有效地检测异常，提供了一种有前景的解决方案，能够应用于离线异常检测，并且适用于监督和半监督设置。
## 456. `cs.LG` - 使用早期融合的语言、视觉和社会特征进行多模态虚假信息检测 [PDF](https://arxiv.org/pdf/2507.01984), [HTML](https://arxiv.org/abs/2507.01984)
### Authors
Gautam Kishore Shahi
### Background
在选举和危机中，社交媒体中虚假信息泛滥成灾，研究主要集中在基于文本或图像的方法进行虚假信息检测。然而，鲜有研究探索多模态特征组合，如将文本与图像结合起来构建分类模型。本研究探讨了不同多模态特征组合的有效性，并利用早融合方法将文本、图像和社会特征结合在一个分类模型中。研究分析了2019冠状病毒病疫情期间和选举时期的1,529条包含文本和图像的推特数据，通过对象检测和光学字符识别（OCR）技术提取了额外的社会特征和视觉特征。研究结果显示，结合无监督和有监督的机器学习模型比单一模态模型提高了15%的分类性能，比双模态模型提高了5%的性能。此外，研究还分析了基于虚假信息推文特征及其传播者的传播模式。
### Innovation
本研究创新之处在于，首次通过早融合方法将文本、视觉和社会特征结合在一个分类模型中，以检测多模态虚假信息。研究结果表明，多模态方法比单一模态或双模态方法更有效。此外，该研究还详细分析了虚假信息推文及其传播者的传播模式。
### Conclusion
研究通过结合早期融合方法和多模态特征，提高了虚假信息检测的准确性。结合无监督和有监督模型能够提升分类性能，而多模态特征的综合使用则使得分类模型更加强大。未来的研究可以进一步扩展这些方法的应用场景，并探索更先进的特征提取技术。
## 457. `cs.LG` - DKGCM: 一种融合空间节点聚类方法和傅里叶双向Mamba机制的时空交通流预测模型 [PDF](https://arxiv.org/pdf/2507.01982), [HTML](https://arxiv.org/abs/2507.01982)
### Authors
Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai
### Background
准确的交通需求预测能够使交通管理部门更有效地分配资源，从而提高资源利用效率。然而，交通系统中的复杂空时关系仍然限制了需求预测模型的性能。为了提高空时交通需求预测的准确性，我们提出了一种新的图卷积网结构，称为DKGCM。特别是在时空尺度上，我们利用动态时间规整（DTW）和K-means聚类方法来聚类交通节点，改进了空间依赖性的捕捉，同时利用快速傅里叶变换（FFT）在双向Mamba深度学习框架中捕捉交通需求的时空依赖性。
### Innovation
我们提出了一种新的图卷积网络结构DKGCM，通过引入时空节点聚类方法和傅里叶双向Mamba机制来优化模型训练，显著提高了空时交通需求预测的准确性。该模型使用动态时间规整（DTW）和K均值聚类来聚类交通节点，以更好地捕捉空间依赖性；同时在时空尺度上，利用快速傅里叶变换（FFT）在双向Mamba框架中捕获交通需求的时空依赖性。此外，引入了GRPO强化学习策略以增强损失函数反馈机制，进一步优化了模型训练。实验表明，该模型在三个公共数据集上都取得了优于多种先进方法的结果。
### Conclusion
实验结果表明，我们的DKGCM模型在三个公共数据集上均优于多种先进的预测方法，具有出色的预测性能。
## 458. `cs.CV` - 基于理解的公平性偏见缓解方法在心脏磁共振分割中的应用 [PDF](https://arxiv.org/pdf/2503.17089), [HTML](https://arxiv.org/abs/2503.17089)
### Authors
Tiarna Lee,Esther Puyol-Antón,Bram Ruijsink,Pier-Giorgio Masci,Louise Keehn,Phil Chowienczyk,Emily Haseler,Miaojing Shi,Andrew P. King
### Background
人工智能（AI）在医学成像领域中的应用越来越广泛，但AI模型在训练时可能会出现偏差，尤其是在使用不平衡的数据集进行训练时。例如，在心脏磁共振（CMR）图像分割模型中发现了明显的族裔偏差问题。尽管这种现象在多篇文章中被报道，但很少有人探讨偏见缓解算法在该领域的有效性。本文旨在研究常用的偏见缓解方法如何在基于AI的CMR分割模型中缓解黑人和白人之间的族裔偏差，同时进行了方法的验证并探索了使用裁剪后的CMR图像进行训练和评估的可能影响，发现这些方法能够在不显著降低主要群体（白人）性能的前提下显著改善被低估群体（黑人）的性能。进一步通过外源临床验证集测试发现模型具有高分割性能且不存在统计显著的族裔偏差。
### Innovation
研究了对齐主要群体（白人）性能的情况下，常用偏见缓解方法（如过采样、重要性重新加权和Group DRO及其组合方法）在缓解CMR分割中的族裔偏差的作用，并探索了使用裁剪后的图像进行训练和评估对缓解这种偏差的影响。研究通过外源临床验证集测试进一步验证了模型在无统计显著族裔偏差的情况下具有高分割性能。这为解决心脏MRI图像分割中可能存在的族裔偏差问题提供了有效的方法和技术支撑。
### Conclusion
偏见缓解方法如过采样显著提高了被低估群体（黑人）的性能，并且在这种方法的应用下模型在外部临床验证集中的分割效果优异，且消除了统计显著的族裔偏差。通过裁剪后的图像进行训练和评估不仅提高了两个族裔群体的性能，还进一步减轻了偏见。
## 459. `cs.LG` - 长视频理解中的时空链思考：基于帧思考的长视频理解 [PDF](https://arxiv.org/pdf/2507.02001), [HTML](https://arxiv.org/abs/2507.02001)
### Authors
Anurag Arnab,Ahmet Iscen,Mathilde Caron,Alireza Fathi,Cordelia Schmid
### Background
尽管在视觉语言模型（VLM）方面取得了进展，但长视频的理解仍然是一个具有挑战性的问题。最先进的长上下文VLM能够处理大约1000个输入帧，但仍然难以有效地利用这些序列长度，在上下文窗口中容易受到不相关信息的干扰。因此，需要提出一种新的方法来改善模型处理长视频上下文的能力。本研究提出了一种时空链思考的推理策略，该策略能够筛选模型的输入上下文，从而更好地处理长视频问题。
### Innovation
提出的时空链思考策略利用VLM本身在推理过程中迭代地识别和提取视频中的最相关帧，并使用这些帧进行回答。这种方法通过在推理时利用更多计算量来选择最相关的上下文，从而提高了准确率，与最近关于大型语言模型推理时扩展的研究一致。特别地，该方法在超过一小时的长视频上表现出色，使用32K上下文窗口的方法优于使用700K上下文窗口的标准推理方法，提高了2.8个百分点。此外，该方法在4个不同的视频问答数据集上达到了最先进成果，显示了与3种不同的VLM的一致改进。
### Conclusion
本文提出了一种时空链思考的推理策略，该策略能够显著提高长视频问答任务中的模型性能。该策略在多个长视频数据集上的实验结果表明，这种方法能够有效解决长视频中的上下文理解问题，并且在长视频理解方面取得突破。
## 460. `cs.LG` - AIRES: 通过算法-系统协同设计加速离线内存GCNs [PDF](https://arxiv.org/pdf/2507.02006), [HTML](https://arxiv.org/abs/2507.02006)
### Authors
Shakya Jayakody,Youpeng Zhao,Jun Wang
### Background
图卷积网络（GCNs）在多个科学应用中至关重要，从生物医学蛋白质-蛋白质相互作用（PPI）到大规模推荐系统。在这些应用中，稀疏通用矩阵-矩阵乘法（SpGEMM）是用于建模图结构的关键组件。随着图数据的规模不断扩大，由于资源受限系统中的GPU内存容量限制，SpGEMM通常以离线方式进行处理。尽管最近有通过GPU特性缓存、混合CPU-GPU内存布局或以稀疏格式执行计算等方式试图缓解离线SpGEMM的内存限制，但当前系统仍存在I/O延迟高和GPU利用不足的问题。
### Innovation
本文首先识别了现有系统的问题，其中稀疏格式数据对齐和内存分配是主要的性能瓶颈。为此，我们提出了一种创新的算法-系统协同设计的解决方案AIRES，旨在加速GCNs中离线SpGEMM的计算。在算法层面，AIRES提出了在矩阵稀疏格式中缓解块级数据对齐问题，并开发了一种镶嵌算法以实现行区块对齐。其次，在系统层面，AIRES采用了一种动态三阶段调度策略，并结合多级存储系统进行双重数据传输策略，以减少I/O延迟并提高吞吐量。实验结果表明，AIRES显著优于现有方法，在实际图处理基准测试中延迟最多可降低1.8倍。
### Conclusion
AIRES通过算法和系统层面的优化，成功解决了离线SpGEMM中的性能瓶颈问题，显著改善了GCNs的实际应用表现。
## 461. `cs.LG` - 正面区域保留随机采样：大规模数据高效特征选择方法 [PDF](https://arxiv.org/pdf/2507.01998), [HTML](https://arxiv.org/abs/2507.01998)
### Authors
Hexiang Bai,Deyu Li,Jiye Liang,Yanhui Zhai
### Background
特征选择是智能机器成功的关键步骤，但面对大量数据时，智能机器通常缺乏足够的计算资源。为解决这一挑战，本文提出了一种结合抽样技术和粗糙集理论的新方法。该方法通过计算可分辨对象对与应被区分对象对的比例来衡量特征集的鉴别能力，并在此基础上提出了一种新的特征选择方法，该方法能够从大规模数据中构建保留正面区域的样本并找到高鉴别能力的特征子集。与现有方法相比，该方法具有两个优势：能在个人电脑上接受的时间内选择一个能保留目标大规模数据集中所有特征的鉴别能力的特征子集；在找到约简之前，可以估计使用选定特征子集可分辨的对象对的概率下界。实验采用11个不同规模的数据集验证了该方法的有效性。结果表明，采用该方法可以在短时间内找到近似约简，并且最终约简的鉴别能力大于估计的下界。此外，实验还表明，该方法能在个人电脑上合理时间内获得高鉴别能力的近似约简片段。
### Innovation
提出了基于抽样技术和粗糙集理论的特征选择新方法。该方法通过计算可分辨对象对与应被区分对象对的比例来衡量特征集的鉴别能力，并在此基础上构建正面区域保留的样本，选择具有高鉴别能力的特征子集。该方法能在个人电脑上接受的时间内选择保留目标大规模数据集中所有特征的鉴别能力的特征子集，并在找到约简之前估计使用选定特征子集可分辨的对象对的概率下界。
### Conclusion
实验验证了该方法的有效性和高效性，能在短时间内找到保留高鉴别能力的近似约简。
## 462. `cs.LG` - GeoAda：使用等变适配器高效微调几何扩散模型 [PDF](https://arxiv.org/pdf/2507.02085), [HTML](https://arxiv.org/abs/2507.02085)
### Authors
Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon
### Background
几何扩散模型在分子动力学和结构生成方面表现出显著的成功。然而，如何高效地针对各种几何控制进行下游任务的微调仍存在不足。
### Innovation
提出了一个SE(3)-等变适配器框架（GeoAda），该框架使模型能够灵活高效地在无需修改原始模型架构的情况下进行细调。GeoAda引入了结构化的适配器设计：通过耦合操作编码控制信号，然后通过选定的预训练模型层的可训练副本进行处理，最后通过解耦操作和等变零初始化卷积进行投影。这种方法通过仅精细调节这些轻量级的适配模块，保持模型的几何一致性，同时缓解过拟合和灾难性遗忘。证明了所提出的适配器保持SE(3)-等变性，确保在适应过程中预训练扩散模型的几何归纳偏差保持不变。
### Conclusion
GeoAda在多种几何控制类型和应用领域（如粒子动力学、分子动力学、人体动作预测和分子生成）中展现出广泛应用性。实验证明，GeoAda在保持原始任务准确性的基础上实现了最先进的微调性能，而其他基线由于过拟合和灾难性遗忘出现了显著的性能下降。
## 463. `cs.LG` - 基于能量的变换器是可扩展的学习者和思考者 [PDF](https://arxiv.org/pdf/2507.02092), [HTML](https://arxiv.org/abs/2507.02092)
### Authors
Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal
### Background
近年来，在推理时使用类人系统2反思技术的计算方法被用于提升模型性能变得流行，但现有方法存在模态特定性、问题特定性和需要额外监督或训练等局限性。本文探讨了是否可以将这些系统2反思方法泛化，并开发出仅通过无监督学习方式学习思考的模型。
### Innovation
提出了一种新的基于能量的模型类——能量基变换器（EBTs），这些模型能够为输入和候选预测对分配能量值，并通过梯度下降的能最优化来实现预测。在训练和推理过程中，EBTs表现出比当前主导的Transformer++方法更快的标度速度，并且在语言任务中比Transformer++表现出更高的性能提升，同时也优于扩散变换器在图像去噪方面，且使用更少的前向传递次数。此外，研究发现EBTs在下游任务上的表现优于现有模型，即使在预训练性能更差的情况下也能达到更好的结果，证明了EBTs比现有方法有更好的泛化能力。
### Conclusion
基于能量的变换器EBTs作为扩展模型学习和思考能力的新范式具有潜力。
## 464. `cs.LG` - 可学习可微分的有限体积求解器以加速流体模拟 [PDF](https://arxiv.org/pdf/2507.01975), [HTML](https://arxiv.org/abs/2507.01975)
### Authors
Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun
### Background
流体流动的模拟对于气象学、流体动力学和生物医药等领域物理现象建模至关重要。传统数值求解器需要精细的时空网格来保证稳定性、一致性和收敛性，导致巨大的计算成本。尽管机器学习技术显示出更好的效率，但它们通常缺乏可解释性、普适性和数据依赖性等问题。因此，我们提出了一个可学习且可微分的有限体积求解器，称为LDSolver，以在粗糙的时空网格上实现高效的流体流动模拟并保持高精度。LDSolver 包含两个关键组件：一个可微分的有限体积求解器和一个可学习模块，该模块在粗糙网格上提供与通量（导数和插值）等效的近似，并进行时间误差修正。即便仅采用少量训练数据（例如几条轨迹），我们的模型仍然能够加速模拟并保持高效和优越的泛化能力。
### Innovation
LDSolver 通过在粗糙的时空网格上实现高效的流体流动模拟，解决了传统数值求解器的计算成本问题。此外，该可学习且可微分的有限体积求解器能够在有限的数据下实现加速模拟，并保持高精度和普适性。LDSolver 改进了现有的基本模型，实现了优越的性能，并在各种流体系统（如Burgers、衰减、强迫和剪切流）上取得了最新技术水平。
### Conclusion
LDSolver 在不同流体系统上的实验结果表明，它达到了最先进的性能，并远超基本模型。即使训练数据有限（例如只有几条轨迹），LDSolver 也能保持高精度和卓越的泛化能力，实现流体模拟的加速。
## 465. `cs.LG` - 使用主动学习的参数化神经放大器建模 [PDF](https://arxiv.org/pdf/2507.02109), [HTML](https://arxiv.org/abs/2507.02109)
### Authors
Florian Grötschla,Luca A. Lanzendörfer,Longxiang Jiao,Roger Wattenhofer
### Background
本文介绍了一种使用类似于WaveNet架构的端到端参数化吉他放大器模型的训练框架PANAMA。为了训练这些模型，传统的数据采集方法可能需要大量的真实物理数据，而该方法利用主动学习策略来确定训练所需的样本点，从而极大地减少了所需的数据量。这对于减少数据采集时间、降低成本和提高模型的定制化具有重要意义。这种方法特别适用于需要高效采集有限数据集的场景，尤其是在资源有限的环境下。
### Innovation
本文提出的PANAMA框架主要创新点在于通过主动学习策略有效地选择最少数量的数据点来训练端到端参数化吉他放大器模型。通过这种方法，可以使用最少的数据点创建虚拟放大器，并且使用基于梯度的优化算法确定最优的样本点。这种创新对于在受限样本数量的情况下获得更好的模型性能具有重要意义。
### Conclusion
研究表明，该方法能够有效地使用最小的数据点集来训练参数化吉他放大器模型，并且基于梯度的优化算法能够帮助确定最优的样本点，从而在资源有限的情况下获得良好的模型性能。这种方法特别适用于需要高效采集数据的场景，减少时间和成本，提高了模型的定制化水平。
## 466. `cs.LG` - 计算优化训练的神经网络中的比例崩溃揭示了通用动力学 [PDF](https://arxiv.org/pdf/2507.02119), [HTML](https://arxiv.org/abs/2507.02119)
### Authors
Shikai Qiu,Lechao Xiao,Andrew Gordon Wilson,Jeffrey Pennington,Atish Agarwala
### Background
研究了当模型大小和训练时间同步增长时，神经网络训练动力学的支配标度极限。尽管架构、训练算法和数据之间的复杂相互作用，研究人员发现，计算优化训练的模型表现出一种令人惊讶的精确普遍性。具体来说，归一化后的损失曲线在训练计算和损失归一化到训练结束时为单位时，可以折叠到单一的通用曲线上。
### Innovation
发现归一化后的损失曲线在使用学习率衰减时，折叠变得非常紧，以至于模型之间归一化曲线的差异低于个别损失曲线跨随机种子的噪声底，我们称之为超崩溃。观察到超崩溃不仅跨越了学习率安排、数据集和架构，包括在下一个标记预测上训练的变压器模型。还发现当超参数非最优地缩放时，超崩溃会失效，提供了一个精确且实用的标度良好性的指示器。通过将折叠与典型的神经网络标度定律中的幂律结构连接起来，并分析一个简单但出人意料有效的模型来预测损失曲线，解释了这些现象，该模型准确预测了各种学习率安排的损失曲线，并定性解释了超崩溃的原因。
### Conclusion
这些观察结果揭示了训练过程中的内生动力学，显示了计算优化模型中的关键非平凡性质。
## 467. `cs.LG` - 评估大型语言模型在招聘决策中的潜力与风险 [PDF](https://arxiv.org/pdf/2507.02087), [HTML](https://arxiv.org/abs/2507.02087)
### Authors
Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia
### Background
大型语言模型（LLMs）在招聘中的应用有望简化候选人筛选流程，但同时也引发了关于准确性和算法偏差的重大担忧。本文对几种最先进的基础LLMs进行了基准测试，包括来自OpenAI、Anthropic、Google、Meta和Deepseek的模型，并将其与我们专有的领域特定招聘模型（Match Score）进行了比较。作者通过评估每个模型的预测准确性和公平性来对比它们的效果。这些实验是在包含约10,000个真实世界候选人-职位对的数据集上进行的，结果指出Match Score在准确性和公平性方面均优于一般的LLMs。
### Innovation
本文基准测试了多种先进的基础LLMs，并将其与专有的领域特定招聘模型（Match Score）进行了对比。研究发现，Match Score在准确性和公平性方面均胜过一般的LLMs，特别在种族公平性方面表现突出。研究还探讨了预训练偏见可能如何导致LLMs在招聘场景中传播社会偏见的问题，并指出定制监督模型可以更有效地缓解这些偏见。此项研究强调，在高风险领域如招聘中部署AI时，领域特定建模和偏见审计的重要性。研究还表明，在招聘过程中追求准确性和公平性是可以共存的，可以通过精心设计的算法同时实现两者的平衡。
### Conclusion
研究结果强调，在招聘等高风险领域部署AI时，需重视领域特定模型和偏见审计的重要性，并建议不要依赖于未经充分公平性保护的现成LLMs。此外，研究证明在招聘过程中，准确性和公平性是可以共存的，精心设计的算法可以在提升招聘准确性的同时确保公平的结果。
## 468. `cs.LG` - 生成潜在扩散以实现高效时空数据压缩 [PDF](https://arxiv.org/pdf/2507.02129), [HTML](https://arxiv.org/abs/2507.02129)
### Authors
Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka
### Background
生成模型在条件设置中表现出强大的性能，并可以被视为数据压缩的一种形式，其中条件充当紧凑表示。然而，生成模型的可控性和重建精度有限，这限制了它们在数据压缩中的实际应用。
### Innovation
本文提出了一种高效的潜在扩散框架，通过结合变分自编码器和条件扩散模型，将少量关键帧压缩到潜在空间中，并使用它们作为条件输入进行生成插值以重建其余帧，从而无需为每帧存储潜在表示。这种方法在实现准确的时空重建的同时显著降低了存储成本。
### Conclusion
实验结果在多个数据集上表明，本方法的压缩比最高可达基于规则的传统最佳压缩器SZ3的10倍，并且在相同的重建误差下比领先的基于学习的方法性能高出63%。
## 469. `cs.LG` - CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs [PDF](https://arxiv.org/pdf/2507.02128), [HTML](https://arxiv.org/abs/2507.02128)
### Authors
Jingyu Pan,Isaac Jacobson,Zheng Zhao,Tung-Chieh Chen,Guanglei Zhou,Chen-Chia Chang,Vineet Rashingkar,Yiran Chen
### Background
现代大规模集成电路（VLSI）设计需要使用电子设计自动化（EDA）工具实现电路。由于EDA算法复杂性高，庞大的参数空间对芯片设计优化造成了巨大挑战，参数组合会导致难以探索的巨大解空间。尽管有专家经验支持，但手动参数选择仍然是工业实践，却是极度耗时且有限制的。因此，需要一种新的自动VLSI设计流程调整框架来解决这些问题。
### Innovation
本文提出了一种新的自动VLSI设计流程调整框架CROP，它是第一个使用大型语言模型（LLM）的自动VLSI设计框架。CROP包括：(1) 可扩展的方法将RTL源代码转换为密集向量表示，(2) 基于嵌入的检索系统匹配具有语义相似电路的设计，以及(3) 基于检索增强生成（RAG）的增强LLM引导参数搜索系统，通过以前相似设计的先验知识来约束搜索过程。实验结果表明，CROP在工业设计中能够以少于现有方法的迭代次数实现更高质量的结果，如9.9%的功耗减少效果显著。
### Conclusion
CROP能够以较少的迭代次数实现更高质量的结果，验证了其在工业设计中的有效性，特别是在降低功耗方面的优点。
## 470. `cs.LG` - 线性约束MDP的样本复杂性边界：带有生成模型 [PDF](https://arxiv.org/pdf/2507.02089), [HTML](https://arxiv.org/abs/2507.02089)
### Authors
Xingtu Liu,Lin F. Yang,Sharan Vaswani
### Background
该研究背景是考虑无限时段的γ折扣（线性）约束马尔可夫决策过程（CMDPs），目标是在满足预期累计约束的前提下最大化预期累计奖励。研究利用生成模型提出了一种可通过任何黑盒无约束MDP求解器的预报-对偶框架来解决CMDPs的方法。特别是在线性CMDPs中，具备特征维度d的情况下，结果被实例化为镜像下降价值迭代（MDVI）等MDP求解器的使用，以提供在两种情况下样本复杂性的边界：（i）放宽可行性，允许小约束违反；（ii）严格可行性，输出策略必须精确满足约束。研究结果证明了算法能够在一定概率下返回ε-最优策略，并且展示了对d和ε的接近最优依赖性。
### Innovation
该研究的创新点在于提出了一种预见-对偶框架来解决线性CMDPs，并通过镜像下降价值迭代（MDVI）等黑盒MDP求解器实现。此外，研究还提供了在放宽可行性和严格可行性两种情况下样本复杂性的边界，特别是在严格可行性情况下，提出了对问题相关Slater常数的依赖性分析。研究成果为线性CMDPs提供了接近最优的样本复杂性的理论依据，特别是在生成模型的支持下，能够精确定位最优策略。
### Conclusion
该研究证明了使用MDVI等方法解决线性CMDPs算法能在概率上找到ε-最优策略，并且对样本数量有接近最优的依赖性。在严格可行性情况下，算法需要的数量级样本更依赖于问题具体的Slater常数。最终，该框架也被扩展到表格CMDPs，并展示了其能带来的接近最优样本复杂性结果。
## 471. `cs.LG` - 非交换一致预测对时间序列图神经网络 [PDF](https://arxiv.org/pdf/2507.02151), [HTML](https://arxiv.org/abs/2507.02151)
### Authors
Tuo Wang,Jian Kang,Yujun Yan,Adithya Kulkarni,Dawei Zhou
### Background
现有图神经网络（GNN）一致预测方法主要关注静态图，忽略了真实世界图结构的演变性质。时间依赖性违背了标准一致预测方法的基本可交换性假设，限制了其适用性。为此，本文提出了一种名为NCPNET的新型端到端一致预测框架，专门针对时间图，通过扩散基础的不一致性得分捕捉拓扑和时间不确定性，提高了统计覆盖率，实验结果表明NCPNET在多样化的现实时间图数据集上能保证覆盖率，并且在WIKI数据集上预测集大小减少了31%，显著优于现有方法，说明了其高效性。
### Innovation
提出了一种新的端到端一致预测框架NCPNET，专门用于时间图。该方法扩展了标准一致预测到动态设置，通过扩散基础的不一致性得分来捕捉拓扑和时间不确定性，以及开发了一种效率感知的优化算法，增强了计算效率并减少了覆盖率违背。
### Conclusion
NCPNET在多个现实时间图数据集上展示了确保时间图中一致预测的保证覆盖率的能力，与现有最先进的方法相比，WIKI数据集上的预测集大小减少了31%，显著提高了效率。数据和代码可从给定的URL获取。
## 472. `cs.LG` - VERBA：使用大型语言模型阐述模型差异 [PDF](https://arxiv.org/pdf/2507.02241), [HTML](https://arxiv.org/abs/2507.02241)
### Authors
Shravan Doda,Shashidhar Reddy Javaji,Zining Zhu
### Background
在当前的机器学习环境中，我们面临着“模型之湖”的现象：在给定的任务中，存在大量表现相似但行为各异的训练模型。模型使用者在选择这些模型时，需要参考文档进行对比和选择。然而，随着模型数量的增加，两两模型之间的对比数量会呈平方级增长，这使得模型开发者手动进行逐对对比和准备文档变得不切实际。
### Innovation
为了解决上述问题，作者引入了一种名为VERBA的方法。VERBA利用大规模语言模型生成模型之间的差异口头解释，通过从两个模型中进行抽样来完成。作者还制定了一种协议，通过模拟评估口头解释的信息含量，并建立了一个基准套件，其中包括一组常用机器学习模型。对于具有5%性能差异但20-25%行为差异的一对决策树模型，VERBA能够实现高达80%的整体准确性。当加入模型的结构信息时，口头解释的准确性进一步提高至90%。此外，VERBA为提高机器学习模型的透明度和可比性提供了新的研究途径，在事后增进了理解。
### Conclusion
VERBA方法通过自动化生成模型差异的口头解释，实现了对模型进行精细化的逐对对比，显著减轻了模型开发者的工作负担。这种方法不仅有效支持了模型选择，还为机器学习模型的透明性改善提供了新的研究方向。
## 473. `cs.LG` - 指标设计 ≠ 指标行为：改进用于降维无偏评估的指标选择 [PDF](https://arxiv.org/pdf/2507.02225), [HTML](https://arxiv.org/abs/2507.02225)
### Authors
Jiyeon Bae,Hyeon Jeon,Jinwook Seo
### Background
评估降维（DR）投影在保留高维数据结构方面精度对于可靠的视觉分析至关重要。已经开发了多种针对不同结构特征的评估指标。然而，如果选择了高度相关的指标（这些指标测量相似的结构特征），则可能导致对DR投影评估的偏差，从而偏向那些强调这些特征的DR技术。因此，需要解决选择评估指标时的潜在偏差问题，以确保评估过程的公正性。
### Innovation
提出了一种新的工作流程，通过基于实测相关性而非预定设计特征来聚类评估指标，从而减少在选择评估指标时的偏差。这一过程涉及通过计算指标相似性来使用两两相关性，聚类指标以最小化重叠，并从每个聚类中选择代表性指标。
### Conclusion
定量实验表明，该方法提高了DR评估的稳定性，说明了此工作流程有助于减轻评估偏差。
## 474. `cs.LG` - 统计推断在响应性验证中的应用 [PDF](https://arxiv.org/pdf/2507.02169), [HTML](https://arxiv.org/abs/2507.02169)
### Authors
Seung Hyun Cheon,Meredith Stewart,Bogdan Kulynych,Tsui-Wei Weng,Berk Ustun
### Background
许多机器学习安全失败的原因在于模型将预测结果应用于人员（常常在信贷、招聘或内容审核等场景下）而忽视了个体可以改变输入的实际情况。本文讨论了这种背景下预测结果的敏感性问题，特别是如何通过控制一组变化（通过指定干预的约束和后续效应的分布）来验证预测结果的响应性，从而提高模型的安全性。
### Innovation
提出了一个正式的验证程序，用于检验预测结果相对于特征干预的响应性，并将响应性视为一种敏感性分析。这种方法允许从业者通过指定干预条件和后续效应分布来控制干预的变化。通过这种方法，研究者可以估计任何模型在任何数据集上的响应性，并使用这些估计值支持诸如反驳和失败概率估计等任务。研究还开发了算法，通过生成可达点的均匀样本来构造这些估计，并展示了这些方法如何在实际应用中促进安全性，如再犯预测、器官移植优先级分配和内容审核等领域。
### Conclusion
该研究为预测结果的响应性验证提供了一个新的统计推断框架，并证明了这种方法在实际应用中的有效性，通过这一程序可以提高机器学习模型在实际操作中的安全性、公平性和可靠性。
## 475. `cs.LG` - 通过自我蒸馏扭曲顺序蒙特卡洛改进语言模型的受限生成 [PDF](https://arxiv.org/pdf/2507.02315), [HTML](https://arxiv.org/abs/2507.02315)
### Authors
Sooyeon Kim,Giung Nam,Juho Lee
### Background
最近的研究将受限文本生成与自回归语言模型结合，视为一种概率推理问题。Zhao等人(2024)提出了一种基于扭曲顺序蒙特卡罗方法的有前景的解决方案，该方法通过学习扭曲函数和扭曲诱导提案来引导生成过程。但在目标分布集中在基础模型下可能性较低的输出时，由于稀疏且信息量不足的奖励信号，学习变得具有挑战性。文献指出，通过自我蒸馏逐步精炼基础知识模型能缓解这一问题，使其与目标更加对齐，从而显著提高生成质量。
### Innovation
该研究提出了一种通过自我蒸馏改进扭曲顺序蒙特卡洛（Twisted Sequential Monte Carlo）的方法，以解决在受限生成设置中由于稀疏且信息量不足的奖励信号导致的学习挑战。该方法通过逐步精炼基础模型，使其与目标更对齐，从而提高生成质量。
### Conclusion
通过逐步精炼基础模型，该研究提出了自我蒸馏扭曲顺序蒙特卡罗的方法，成功解决了受限生成中的学习难题，并显著改善了生成质量。
## 476. `cs.LG` - PhysicsCorrect: 无需训练的稳定神经PDE模拟方法 [PDF](https://arxiv.org/pdf/2507.02227), [HTML](https://arxiv.org/abs/2507.02227)
### Authors
Xinquan Huang,Paris Perdikaris
### Background
神经网络已经成为了求解偏微分方程（PDEs）的强大替代方案，相较于传统方法提供了显著的计算速度加快。然而，这些模型都存在着一个关键的局限性：长时间模拟过程中累积的误差会呈指数增长，最终导致解决方案完全偏离真实物理结果。为解决此问题，本文提出了PhysicsCorrect框架，该框架在每个预测步骤都通过基于PDE残差概念的线性化反问题框架来强制执行PDE一致性，从而在无需训练的情况下进行误差纠正。
### Innovation
本文的关键创新在于提出了一种高效的缓存策略，在离线预热阶段预先计算雅可比及其伪逆矩阵，相比标准修正方法，这将计算开销降低了两个数量级。
### Conclusion
PhysicsCorrect框架不仅在流体动力学（Navier-Stokes方程）、波动方程和混沌Kuramoto-Sivashinsky方程这三种代表性的PDE系统中将预测误差降低了100倍，而且增加了不到5%的推理时间。该框架能够无缝集成各种架构如Fourier神经操作员、UNets和视觉变换器，将不稳定的神经网络代理转化为具有高物理准确性的模拟工具，弥补了深度学习计算效率与实际科学应用所需的物理精度之间的差距。
## 477. `cs.LG` - 基于知识图谱的解释性和泛化的零样本语义通信 [PDF](https://arxiv.org/pdf/2507.02291), [HTML](https://arxiv.org/abs/2507.02291)
### Authors
Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu
### Background
数据驱动的语义通信依赖于表面的统计模式，缺乏解译性和泛化能力，特别是在存在未见过的数据时尤为突出。现有框架难以有效处理这些挑战，导致语义通信面临无法解释和无法广泛应用的问题。特别是在需要快速适应新情况或资源受限的环境中，现有系统面临着适应性和效率上的巨大挑战。
### Innovation
本文提出了一种知识图谱增强的零样本语义通信（Knowledge Graph Enhanced Zero-shot Semantic Communication，KGZS-SC）网络。该网络通过知识图谱中的结构化语义信息校准共享类别语义嵌入空间中的语义特征，增强发射机的泛化能力，并通过选择性传输紧凑的视觉语义降低通信开销。接收端利用零样本学习（Zero-shot Learning，ZSL），在无需重新训练和额外计算开销的情况下直接对未见过的类别进行分类，从而提高分类过程在动态或资源受限环境中的适应性和效率。研究表明，所提出的KGZS-SC网络展现了良好的泛化性能，并在不同信噪比条件下显著优于现有语义通信框架的分类效果。
### Conclusion
实验结果表明，KGZS-SC网络具有良好的泛化性能，并且在各种信噪比条件下显著优于现有语义通信框架在分类未见过的类别方面的能力。这种方法提高了语义通信的解释性和适用性，在动态环境或资源受限环境下表现出色。
## 478. `cs.LG` - 不确定性导向的奖励设计过程 [PDF](https://arxiv.org/pdf/2507.02256), [HTML](https://arxiv.org/abs/2507.02256)
### Authors
Yang Yang,Xiaolu Zhou,Bosong Ding,Miao Xin
### Background
设计有效的奖励函数是强化学习（RL）的基本要素，但传统的方法存在效率低下和不一致的问题，这使得奖励函数的设计过程非常具有挑战性。最近的研究探索了利用大语言模型（LLMs）来自动化奖励函数的设计，然而，它们在数值优化中的表现往往不尽如人意，导致产出的奖励质量不高。而进化搜索方式又未能有效利用模拟资源，从而导致设计周期过长，计算成本高昂。
### Innovation
本文提出了一种新的框架，不确定性导向的奖励设计过程（URDP），通过集成大语言模型简化奖励函数的设计和评估。URDP通过自一致性分析量化候选奖励函数的不确定性，从而在不进行模拟的情况下识别无效的奖励组件，同时发现新的奖励组件。此外，还引入了不确定性导向的贝叶斯优化（UABO），通过引入不确定性估计来显著提高超参数配置效率。同时，通过分解奖励组件优化和超参数调优两个层次，构建了一个双层优化架构。URDP结合了LLMs在奖励逻辑推理方面的优势和贝叶斯优化在数值优化方面的强项。通过在不同基准环境下的35个任务中进行全面评估，结果显示URDP不仅能生成更高的奖励函数质量，还能在自动化奖励设计的效率上取得显著提升，对比现有方法具有优势。
### Conclusion
本文提出的URDP框架，不仅生成了高质量的奖励函数，还在自动化奖励设计过程中提升了效率，对比现有的方法具有明显的优势。
## 479. `cs.LG` - 订单获取下的竞争压力：一种适用于网约车补贴策略的快速自适应强化学习方法 [PDF](https://arxiv.org/pdf/2507.02244), [HTML](https://arxiv.org/abs/2507.02244)
### Authors
Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu
### Background
网约车聚合平台的扩展为网约车服务提供商提供了显著的增长机会，通过增加订单量和商品交易总额（GMV）。在大多数网约车聚合平台上，提供更低价格的服务提供商在列表中排名更高，因此更有可能被乘客选择。这种竞争排名机制为服务提供商提供了降低价格以获取更多订单的强大激励。因此，在预算约束下，设计能动态适应市场波动并优化订单获取的补贴策略是一项关键挑战。然而，现有研究相对较少，未能有效解决此问题。
### Innovation
本文提出了一种名为FCA-RL的新型强化学习补贴策略框架，能够在竞争对手定价调整时迅速适应。该框架结合了两种关键技术：快速竞争适应（FCA），能够迅速应对动态价格变化；强化拉格朗日调整（RLA），确保遵守预算约束并优化新价格景观下的补贴决策。此外，还引入了针对网约车聚合商的第一个专用仿真环境 RideGym，以全面评估和基准测试不同的定价策略，同时不会影响实际操作效率。实验结果表明，相较于基准方法，提出的算法在不同市场条件下都能更有效地优化补贴策略。
### Conclusion
实验结果表明，我们提出的方法在各种市场条件下都能稳定地优于基准方法，突显了它在网约车服务提供商的补贴优化中的有效性。
## 480. `cs.LG` - 基于Transformer的EEG解码：综述 [PDF](https://arxiv.org/pdf/2507.02320), [HTML](https://arxiv.org/abs/2507.02320)
### Authors
Haodong Zhang,Hongqi Li
### Background
脑电波（EEG）是常用的脑电活动捕捉方法，EEG解码已被视为脑-机接口（BCIs/BMIs）研究的前沿领域。相较于传统的基于机器学习的EEG分析方法，深度学习方法尤其是Transformer模型的引入，已经改变了EEG解码的方式，为产生更具辨别性的特征提供了端到端的长链条架构。Transformer模型因其注意力机制在序列数据处理中的强大能力而备受关注，并在各种EEG处理任务中广泛使用。本文重点回顾了Transformer在EEG解码中的最新应用，并梳理了相关进展，从Transformer的基础研究到其直接应用，再到与其它深度学习技术的混合模型，以及针对定制Transformer结构的改进应用。
### Innovation
Transformer模型因其处理序列数据的能力而被广泛应用于各种EEG处理任务中，本文总结了其在EEG解码中的最新应用。介绍了不同混合架构和定制Transformer结构的改进，梳理了相关研究成果，为未来的EEG解码研究提供了有价值的研究方向。
### Conclusion
本文旨在帮助读者了解目前Transformer在EEG解码中的应用现状，并为未来的研究提供有价值的见解。讨论了当前面临的挑战和未来的发展前景，有助于推动该领域的研究和发展。
## 481. `cs.LG` - 基于自适应记忆对齐的全面连续学习以应对概念漂移 [PDF](https://arxiv.org/pdf/2507.02310), [HTML](https://arxiv.org/abs/2507.02310)
### Authors
Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk
### Background
传统的连续学习方法侧重于知识保留，主要关注缓解灾难性遗忘，隐含地假设先前学习任务的数据分布保持不变。这种假设忽略了真实世界数据流的动态特性，其中概念漂移永久地改变了之前看到的数据，要求模型既要稳定也要快速适应变化。现有的框架未能充分模拟这种动态，导致在面对数据分布变化时，模型的性能和适应性受到限制。
### Innovation
本文提出了一个全面的连续学习框架，能够模拟现实场景下的动态任务分布。为了解决全重新学习模型标注和计算负担沉重的问题，本文提出了自适应记忆对齐（AMR）方法，这是一种轻量级的方案。AMR能够有选择地从回放缓冲中移除过时的数据，并用最新的实例更新，从而高效地使记忆与新分布对齐。这一策略在性能上与全重新学习相当，但大大减少了标注数据和计算的需求。
### Conclusion
本文在标准视觉基准测试中引入了四种概念漂移变体：Fashion-MNIST-CD、CIFAR10-CD、CIFAR100-CD和Tiny-ImageNet-CD，表明使用重演基线模型，AMR能够在几乎不增加额外开销的情况下有效应对概念漂移，从而保持较高的准确率。这使得AMR成为在非站定连续学习环境中权衡稳定性和可塑性的一种可扩展解决方案。
## 482. `cs.LG` - 带惩罚动作噪声注入的离线强化学习 [PDF](https://arxiv.org/pdf/2507.02356), [HTML](https://arxiv.org/abs/2507.02356)
### Authors
JunHyeok Oh,Byung-Jun Lee
### Background
离线强化学习（RL）通过使用固定的数据集来优化策略，适用于成本高昂的情况下的环境交互。尽管如此，这一方法的泛化能力仍然是提高离线RL算法性能的关键，而最近的研究表明，扩散模型在离线RL方法中表现突出，但扩散模型的高计算需求使得其是否是必要的工具仍存疑问。因此，本文探讨了一种名为PANI（Penalized Action Noise Injection）的方法，该方法通过加入注入噪声的动作来覆盖整个动作空间，同时根据注入的噪声量进行惩罚，以提高离线学习效果，借鉴了扩散模型在离线下工作的方式。
### Innovation
PANI方法提出了一个简单但有效的手段，通过注入噪声动作并根据噪声量进行惩罚，来改进离线学习。这种方法不仅提供了一个理性的理论基础，表明这种噪声注入的动作可以使离线RL算法解决一个修改后的马尔可夫决策过程（称为噪声动作MDP），而且PANI具有广泛的兼容性，适用于多种现有的离策和离线RL算法，展现出显著的性能改进。
### Conclusion
PANI方法是一种简单而高效的离线学习增强策略，通过在算法中加入噪声动作并根据注入的噪声量进行惩罚，有效地利用了整个动作空间。这种方法不仅在理论上得到了验证，即解决了一个修改后的MDP（称为噪声动作MDP），而且在多个基准测试中展示出了显著的性能提升。PANI兼容多种已有算法，证明了其在提高离线RL性能方面的实用性。
## 483. `cs.LG` - 变分科莫哥洛夫-阿诺德网络 [PDF](https://arxiv.org/pdf/2507.02466), [HTML](https://arxiv.org/abs/2507.02466)
### Authors
Francesco Alesiani,Henrik Christiansen,Federico Errica
### Background
Kolmogorov Arnold Networks (KANs)是一种新兴的机器学习模型架构，基于Kolmogorov-Arnold定理及其扩展，理论上提供了一种将多元连续有界函数表示为有限数量的单变量连续函数的组合的方法。然而，KANs在实际应用中面临一个问题，即在选择每个单变量函数的函数基的数量时需要进行主观的选择，这限制了其应用潜力。
### Innovation
本文提出了一种名为InfinityKAN的新方法，通过在训练过程中自适应地学习每个单变量函数的潜在无限数量的基，将KANs扩展为变分推断优化问题，从而解决了选择基的数量这一难题，并将KANs的重要超参数作为学习过程的一部分纳入考虑。这种方法采用了反向传播技术来提高KANs的应用范围和灵活性。
### Conclusion
InfinityKAN通过自适应地学习每个单变量函数的无限数量的基，在训练过程中将重要超参数作为学习过程的一部分，扩展了KANs的应用潜力，提高了其理论和实际应用的可行性。
## 484. `cs.LG` - 通过偏好优化提高车辆轨迹预测的一致性 [PDF](https://arxiv.org/pdf/2507.02406), [HTML](https://arxiv.org/abs/2507.02406)
### Authors
Caio Azevedo,Lina Achaji,Stefano Sabatini,Nicola Poerio,Grzegorz Bartyzel,Sascha Hornauer,Fabien Moutarde
### Background
自动驾驶车辆管道中的轨迹预测是至关重要的一步。不准确或不一致的预测会导致糟糕的路径规划和对最终用户可能造成危险的情况。尽管基于深度学习的轨迹预测模型在公共数据集上取得了优秀的准确度，但在更复杂、交互性更强的场景中，这些模型往往无法捕捉各代理之间的关键依赖关系，导致交通场景中各代理预测不一致。
### Innovation
本文通过偏好优化微调多代理环境下的轨迹预测模型，利用自动计算的预测未来之间的偏好排名作为微调过程的输入，实验表明该方法可以在大幅提高场景一致性的同时，几乎不牺牲轨迹预测精度，在推理时也不增加额外的计算需求。这一方法借鉴了将人类偏好融入大型语言模型的有效性，展示了其在提升多代理环境轨迹预测一致性的潜力。
### Conclusion
通过偏好优化，我们显著提高了多代理环境中的轨迹预测场景一致性，几乎不牺牲准确度，并且不增加推理时的计算负担。
## 485. `cs.LG` - DeltaSHAP: 使用Shapley值在在线患者监测中解释预测演化 [PDF](https://arxiv.org/pdf/2507.02342), [HTML](https://arxiv.org/abs/2507.02342)
### Authors
Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang
### Background
在临床环境中，及时发现驱动患者风险演变的原因对于适当的干预至关重要。现有的解释性人工智能(XAI)方法未能解决临床时间序列解释任务的特殊需求。现有的XAI方法通常关注孤立的预测得分，不能准确解释连续预测的变化，也无法同时提供特征贡献的方向和幅度，并且大多数方法在临床应用场景下的实时性不够强，无法高效处理时间敏感数据。
### Innovation
DeltaSHAP是一个新的XAI算法，专门针对在线患者监测系统设计。它通过将Shapley值应用到时间序列设置中，准确捕捉特征组合效应，并仅使用实际上观察到的特征组合来归因预测变化。DeltaSHAP能够同时提供特征贡献的幅度和方向，并实现实时解释。此外，该研究还引入了新的评估指标来评估在线时间序列归因的忠实性，并通过MIMIC-III去甲肾上腺素再充盈基准任务的实验，表明DeltaSHAP在解释质量和计算效率方面优于最先进的XAI方法，分别提高了62%和减少了33%的时间。
### Conclusion
DeltaSHAP通过适应Shapley值应用于时间序列，能够准确捕捉特征组合效应，并实现实时解释，既提高了解释的质量也提高了计算效率。该研究通过引入新的评估指标和实验证明了DeltaSHAP在解释在线患者监测中的预测演变方面具有明显优势。
## 486. `cs.LG` - LLMs的连续梯度低秩投影微调 [PDF](https://arxiv.org/pdf/2507.02503), [HTML](https://arxiv.org/abs/2507.02503)
### Authors
Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing
### Background
大规模语言模型（LLMs）的连续微调受到效率和表达力之间的权衡限制。低秩适应（LoRA）虽然提高了效率，但其低秩特性和依赖显式参数约束限制了模型学习新任务和知识转移的能力。因此，该论文提出了GORP（Gradient LOw Rank Projection）以克服这些限制，通过结合全秩和低秩参数并共同更新在一个统一的低秩梯度子空间中，从而扩展优化空间同时保持效率和减轻灾难性遗忘问题。
### Innovation
论文提出了一种新的训练策略GORP（Gradient LOw Rank Projection），该策略通过将全秩和低秩参数结合并在统一的低秩梯度子空间内共同更新，有效解决了低秩适应带来的限制问题，从而在保持效率的同时改善了优化空间，有效防止了灾难性遗忘，提升了LLMs的连续学习能力。
### Conclusion
通过广泛的连续学习基准测试，实验结果表明GORP在性能上优于当前最先进的方法。代码可在指定链接中获取。
## 487. `cs.LG` - S2FGL: 空间光谱联邦图学习 [PDF](https://arxiv.org/pdf/2507.02409), [HTML](https://arxiv.org/abs/2507.02409)
### Authors
Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye
### Background
联邦图学习（FGL）将联邦学习（FL）的隐私保护能力与图神经网络（GNN）的强图建模能力结合起来。当前的研究仅从结构层面探讨子图-FL，忽视了图信号在空间域和谱域的传播。从空间角度来看，子图-FL会导致客户端之间出现边的中断，从而破坏标签信号并降低全局GNN的类知识。从谱的角度来看，谱异构性导致子图之间信号频率的一致性问题，这使局部GNN过度拟合局部信号传播方案。因此，会导致谱客户漂移，影响全局泛化能力。
### Innovation
为解决上述挑战，本文提出了一种全球知识库来缓解标签信号中断，并提出了一种频率对齐方法来解决谱客户漂移问题。空间和谱策略的结合形成了我们的框架S2FGL。广泛的实验表明S2FGL具有优越性。代码已发布在此 <https://example.com>.
### Conclusion
实验结果表明，S2FGL能够在保持隐私的同时，有效解决标签信号中断和谱客户漂移问题，并在多个数据集上表现出优越性。
## 488. `cs.LG` - RetrySQL: 使用重试数据进行自纠正查询生成的文本到SQL训练 [PDF](https://arxiv.org/pdf/2507.02529), [HTML](https://arxiv.org/abs/2507.02529)
### Authors
Alicja Rączkowska,Riccardo Belluzzo,Piotr Zieliński,Joanna Baran,Paweł Olszewski
### Background
文本到SQL任务是自然语言处理中的一个活跃挑战。许多现有解决方案侧重于使用扩展有专门组件的黑盒语言模型，并定制端到端的文本到SQL管道。虽然这些解决方案使用既有的专有语言模型和面向编码的开源模型，但关于特定于SQL的生成模型的研究较少。最近的自纠正生成策略的进步表明，它们可能提高现有架构的能力，但这些概念在文本到SQL任务中的应用尚未被探索。
### Innovation
本文引入了RetrySQL，这是一种新的文本到SQL生成模型的训练方法。通过引入推理步骤，对参考SQL查询进行篡改，创建包含错误和修正步骤的重试数据，并使用这些数据进行了持续的预训练。结果显示，使用重试数据进行预训练比不使用重试数据的预训练，在整体和具有挑战性的执行准确性度量上提高了4个百分点以上。此外，本文还证实了，使用LoRA进行监督微调对于学习重试数据无效，全参数预训练是必要的要求。最终，将 RetrySQL 训练的模型集成到完整的文本到SQL管道中，展示了其在执行准确性上与参数量级大得多的专有模型相当。
### Conclusion
RetrySQL表明自纠正可以学习应用于文本到SQL任务，并提供了提高面向SQL的语言模型生成准确性的新方法。
## 489. `cs.LG` - 带有效率保证的在线齐性预测 [PDF](https://arxiv.org/pdf/2507.02496), [HTML](https://arxiv.org/abs/2507.02496)
### Authors
Vaidehi Srinivas
### Background
该研究关注在线框架下的齐性预测问题，其中算法需要直接优化效率。给定一个目标覆盖率 $boldsymbol{rm text{错覆盖率}} > 0$ 和一个时间段 $T$。每个时间 $t boldsymbol{rm text{(天)}} boldsymbol{rm text{（} } boldsymbol{rm text{直至）}} T$，算法需要输出一个区间 $I_t boldsymbol{rm text{（} } boldsymbol{rm text{区间）}} boldsymbol{rm text{[0,1]}}$，然后揭示一个点 $y_t boldsymbol{rm text{（} } boldsymbol{rm text{点）}} boldsymbol{rm text{[0,1]} }$。算法的目标是在尽可能维持效率（即最小化区间长度的平均值）的同时，实现覆盖，即 $y_t boldsymbol{rm text{（} } boldsymbol{rm text{点）}}$ 在 $I_t boldsymbol{rm text{（} } boldsymbol{rm text{区间）}}$ 中，接近 $(1 - boldsymbol{rm text{错覆盖率}})$ 的比例。该问题是对构建高效置信区间问题的在线版本的研究。研究在这类算法中表现出色，需要覆盖接近 $(1-boldsymbol{rm text{错覆盖率}})-o(1)$ 的比例，同时保持长度不超过事后达到覆盖的最佳固定区间。对于任意序列，任何达到平均长度约 $boldsymbol{rm text{ textmu}}$ 倍最优固定区间的算法，必须比 $boldsymbol{rm text{ textalpha}T}$ 多出一定的乘性错误。
### Innovation
研究证明对于交换序列，可以构建区间达到覆盖接近 $(1 - boldsymbol{rm text{错覆盖率}}) - o(1)$，且长度和事后的最优固定区间的长度上界相同。但对于任意序列，存在一个乘性因子制约错误。主要算法结果为一个匹配算法，能够恢复所有帕累托最优设置的 $boldsymbol{rm text{ textmu}}$ 值和错误数量。此外，该算法是确定性的，因此对适应性强的对手具有鲁棒性。建立了交换序列和任意序列之间的效率差距，证明没有单一算法能在两种场景中同时达到帕累托最优。给出一个算法，能够在两种情况下达到接近最优的权衡。
### Conclusion
该研究表明，对于任意序列和交换序列，不存在能够同时在两者中达到帕累托最优的单一算法。给出了一个能在两种情况中实现近最优效率-覆盖权衡的算法。
## 490. `cs.LG` - 基于潜在表示的深度强化学习DRAM均衡器参数优化 [PDF](https://arxiv.org/pdf/2507.02365), [HTML](https://arxiv.org/abs/2507.02365)
### Authors
Muhammad Usama,Dong Eui Chang
### Background
在高速动态随机存取存储器（DRAM）系统中，均衡器参数优化对于信号完整性至关重要，但通常计算成本较高或依赖模型。现有的优化方法计算量大或需要系统模型，影响效率和泛化能力。特别是在处理复杂的连续时间线性均衡器和决策反馈均衡器结构时，信号完整性评价通常涉及直接眼图分析，计算复杂度较高，且优化过程往往依赖于具体模型，这限制了其应用范围和效率。因此，开发一种高效、无需模型依赖的优化方法具有重要意义。
### Innovation
本文提出了一种数据驱动的框架，利用学习到的潜在信号表示进行高效的信号完整性评估，并结合一种模型无关的增强学习（A2C）代理进行参数优化。潜在表示捕获了关键的信号完整性特征，提供了一种快速替代直接眼图分析的方法，而增强学习代理则可以不依赖具体系统模型就推导出最优的均衡器设置。通过在行业标准的DRAM波形上实验，该方法在复杂的连续时间线性均衡器和决策反馈均衡器结构中实现了显著的眼图开窗面积改善：对于级联结构，改善比例达42.7%；仅决策反馈均衡器结构中，改善比例为36.8%。这些结果表明，该方法具有出色的性能、计算效率及跨不同DRAM单位的鲁棒泛化能力，优于现有技术。核心贡献包括一个高效的潜在信号完整性评估指标，一种鲁棒的模型无关增强学习策略，以及对复杂均衡器架构的验证性优越性能。
### Conclusion
本文提出的方法在评估信号完整性和优化DRAM均衡器参数方面表现优异且具有高效性和跨系统的泛化能力，显著改善了复杂均衡器结构的眼图开窗面积，验证了潜在表示和增强学习在DRAM优化中的有效性和实用性，为今后的优化提供了新的思路和方法。
## 491. `cs.LG` - 一个深度学习理论必须包含组成稀疏性 [PDF](https://arxiv.org/pdf/2507.02550), [HTML](https://arxiv.org/abs/2507.02550)
### Authors
David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio
### Background
过参数化的深度神经网络（DNNs）已在高维领域中展示了显著的成功，而这些领域过度参数化的经典浅层网络因遭受维数灾难而难以处理。尽管如此，关于DNNs的学习动态基本原理的问题仍然存在开放性。
### Innovation
本文提出的核心观点是，DNNs的成功归因于它们能够利用目标函数组成稀疏结构的能力。文章指出，实际中大多数函数都可以由少数几个依赖于少数输入子集的基本函数组成，因此DNNs能够利用这一特性，在所有当前学习问题中普遍适用。虽然在组成稀疏函数的情况下关于逼近和泛化的理论研究已经取得了一些有希望的洞见，但关于DNNs的可学习性和优化的一些关键问题仍然没有得到解答。为全面的理论人工智能理论提供完整的组成稀疏的角色是至关重要的。
### Conclusion
完成组成稀疏性在深度学习中的角色描绘是建立全面理论人工智能（甚至通用人工智能）的基础。
## 492. `cs.LG` - Transformer 不需要在推理时使用层归一化: 将层归一化移除扩展到 GPT-2 XL 及其对机制可解释性的影响 [PDF](https://arxiv.org/pdf/2507.02559), [HTML](https://arxiv.org/abs/2507.02559)
### Authors
Luca Baroni,Galvin Khara,Joachim Schaeffer,Marat Subkhankulov,Stefan Heimersheim
### Background
层归一化（LN）是几乎所有基于Transformer的大规模语言模型的关键组成部分。虽然LN在训练稳定性上的效果已被广泛应用，但尚未完全理解其在推理过程中的作用。此外，LN层还提高了个体模型组件之间的相互连接性，阻碍了机制可解释性的研究。
### Innovation
作者展示了如何从每个GPT-2模型中移除所有LN层，仅通过小幅增加验证损失（例如，对于GPT-2 XL增加0.03交叉熵损失）即可实现此目标。这表明LN层在语言建模中没有显著作用。进一步发现，移除LN所需的数据微调量随着模型参数的增加呈亚线性增长，因此可以扩展到更大的模型。作者还证明，直接logit归因现在可以准确反映单个组件的直接影响，而patching归因的准确性并未显著提高。此外，确认GPT-2的“信心神经元”在LN移除后的模型中不活跃。
### Conclusion
本研究表明，GPT-2类模型在无需LN层的情况下仍能正常运行。作者希望LN免费的GPT-2家族模型能促进更精确的可解释性研究，从而加深我们对语言模型的理解。
## 493. `cs.LG` - 布尔网络中可扩展的互连学习 [PDF](https://arxiv.org/pdf/2507.02585), [HTML](https://arxiv.org/abs/2507.02585)
### Authors
Fabian Kresse,Emily Yu,Christoph H. Lampert
### Background
已有的可学习布尔逻辑网络(DBNs)已经可以高效地在资源受限的硬件上进行推理。然而，早期的可学习互连设计使DBNs难以扩展到更宽的层，尽管它们在保持准确性方面具有优势。为了进一步减小模型体积，本文引入了两种互补的剪枝阶段：基于SAT的逻辑等价性剪枝阶段，在不牺牲性能的情况下移除冗余门；以及一种基于相似性的数据驱动剪枝阶段，优于基于量级的贪婪基线，并提供优越的压缩-准确度权衡。
### Innovation
1. 本文扩展了DBNs，通过一个可训练的、可微分的互连将参数数量保持在常数，使DBNs能够扩展到更宽的层。2. 引入两种互补的剪枝阶段：基于SAT的逻辑等价性剪枝，以及基于相似性的数据驱动剪枝，以进一步减小程序大小。3. 基于相似性的数据驱动剪枝超过了基于量级的贪婪基线，提供更优的压缩-准确度权衡。
### Conclusion
通过引入上述创新方法，本文使DBNs能够在保持准确性的基础上，有效地扩展至更宽的层，并且通过一种新方法提高了模型的压缩比，从而减小了模型体积。
## 494. `cs.LG` - Padé逼近神经网络在使用振动和声学数据增强电动机故障诊断中的应用 [PDF](https://arxiv.org/pdf/2507.02599), [HTML](https://arxiv.org/abs/2507.02599)
### Authors
Sertac Kilickaya,Levent Eren
### Background
研究背景介绍了现有的故障诊断方法，指出虽然加速度计和麦克风是电机状态监测的常用工具，但深度学习模型，尤其是非线性神经网络架构，能够显著提升诊断性能。研究进一步提出了探讨Padé逼近神经网络（PadéNets）在诊断电气和机械故障方面是否能优于传统卷积神经网络（CNNs）和自我组织操作神经网络（Self-ONNs）的问题，特别是利用振动和声学数据。
### Innovation
创新点在于提出了Padé逼近神经网络模型，该模型设计引入了增强的非线性特性，并且兼容非限制激活函数，如Leaky ReLU，通过对比实验验证了PadéNets在诊断性能上的优越性。
### Conclusion
研究表明，PadéNets在使用振动和声学数据进行电动机故障诊断时表现出色，获得了较高的诊断准确率，特别是在所有测试传感器数据上都取得了99.96%到98.33%之间的准确率。这表明PadéNets在非线性增强和激活函数兼容性方面对故障诊断有显著的改进作用。
## 495. `cs.LG` - 关于基于模型的强化学习中高效贝叶斯探索 [PDF](https://arxiv.org/pdf/2507.02639), [HTML](https://arxiv.org/abs/2507.02639)
### Authors
Alberto Caron,Chris Hicks,Vasilios Mavroudis
### Background
本文探讨了在强化学习中高效探索的挑战，特别研究了现有的基于信息理论的原则性激励机制。研究表明，这些机制能够针对认知不确定性而非环境固有的 aleatoric 噪声提供探索奖励。证明了这些奖励自然地指示认知信息增益，并在代理对环境动力学和奖励有足够的信心时收敛于零，从而将探索与真正的知识缺口对齐。此外，本文还提供了基于 IG 的方法的正式保证，这些方法此前缺乏理论基础，并讨论了通过稀疏变分高斯过程、深度内核和深度集成模型实现可实施性的近似方法。
### Innovation
该研究提供了一种基于信息增益的探索机制的正式保证，该机制此前在理论上缺乏依据。还提出了一个名为 Predictive Trajectory Sampling with Bayesian Exploration (PTS-BE) 的框架，该框架结合了基于模型的规划和信息理论奖励，以实现高效的数据探索。PTS-BE 在一系列具有稀疏奖励和/或纯探索任务的环境中优于其他基准方法。
### Conclusion
最终，该研究证明了基于信息增益的探索机制在理论上的可靠性，并通过提出 PTS-BE 框架展示了其实现高效探索的能力。
## 496. `cs.LG` - L-VAE：具有可学习β值的变分自编码器以实现解纠缠表示 [PDF](https://arxiv.org/pdf/2507.02619), [HTML](https://arxiv.org/abs/2507.02619)
### Authors
Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural
### Background
研究背景描述了当前使用的变分自编码器（VAE）模型，特别是η-VAE，在学习解纠缠表示时的问题。虽然现有模型在某些数据集上表现良好，但它们通常需要手动调整超参数（如η），并且缺乏一种让模型自动学习最佳平衡点的方法。
### Innovation
本文提出了Learnable VAE (L-VAE)模型，该模型可以同时学习解纠缠表示和代价函数的超参数。L-VAE通过学习损失函数中各个项的权重来动态调整解纠缠和重构损失之间的权衡，从而克服了现有方法的限制。此外，L-VAE还引入了一个额外的正则化项以防止模型在重建或解纠缠损失上偏向其中一个目标。实验结果显示，L-VAE在多个数据集上取得了最好的或次好的解纠缠指标表现，尤其是在一些需要高精度解纠缠的任务上。
### Conclusion
L-VAE模型成功地解决了现有的η-VAE和其他变分自编码器模型在解纠缠表示学习中的局限性，并展现了在多个解纠缠任务上的优越性能。L-VAE的创新在于其能够自动学习模型训练中的重要超参数，为了解纠缠表示提供了一种新的选择。
## 497. `cs.LG` - 迷失在潜在空间：基于生成模型的物理仿真中的实证研究 [PDF](https://arxiv.org/pdf/2507.02608), [HTML](https://arxiv.org/abs/2507.02608)
### Authors
François Rozet,Ruben Ohana,Michael McCabe,Gilles Louppe,François Lanusse,Shirley Ho
### Background
扩散模型在推理阶段的高计算成本阻碍了它们作为快速物理模拟器的使用。在图像和视频生成的背景下，通过在自编码器的潜在空间中生成而不是在像素空间中生成，已经解决了这一计算问题。本文研究了是否可以将类似策略应用于动力学系统的仿真以及其代价是什么。实验发现，潜在空间仿真对于广泛范围的压缩率（高达1000倍）具有令人惊讶的稳健性。还表明，基于扩散的仿真器在准确性方面始终优于非生成性对手，并通过更大的多样性弥补了其预测中的不确定性。此外，文章还涵盖了从架构到优化器等实用设计选择，这些选择我们发现对于训练潜在空间仿真器至关重要。
### Innovation
本文发现了潜在空间仿真对于广泛范围的压缩率具有令人惊讶的稳健性，基于扩散的仿真器在准确性方面始终优于非生成性对手，并通过更大的多样性弥补了其预测中的不确定性，强调了在训练潜在空间仿真器方面的一些关键设计选择。
### Conclusion
通过在自编码器的潜在空间中生成而不是在像素空间中生成，提高扩散模型的计算效率，从而适用于动力学系统的仿真。提出了关键的设计选择，可通过优化架构和优化器来提高仿真精度。
## 498. `cs.LG` - 医学数据啄取：一种结构化医学数据自动化质量评估的上下文感知方法 [PDF](https://arxiv.org/pdf/2507.02628), [HTML](https://arxiv.org/abs/2507.02628)
### Authors
Irena Girshovitz,Atai Ambus,Moni Shahar,Ran Gilad-Bachrach
### Background
电子健康记录（EHR）在流行病学研究和人工智能（AI）训练中的使用正在迅速增加，结果的可靠性依赖于EHR数据的准确性和完整性。然而，EHR数据通常包含质量问题，如子群体表示不准确、偏差和系统误差，这些数据主要用于临床和计费目的。虽然已经存在一些质量问题评估方法，但这些方法仍然不足，缺乏系统性地评估数据是否适合研究的程序.
### Innovation
提出了一种医学数据啄取（Medical Data Pecking）方法，将软件工程中的单元测试和覆盖率概念应用于识别数据质量问题。该方法包括一个自动测试生成器和一个数据测试框架，通过生成和执行测试来报告潜在错误和覆盖率，从而有效地评估EHR数据的质量问题。具体来说，该研究使用大型语言模型和对接技术，从数据和研究描述生成测试套件，并执行这些测试来识别数据中的问题。该方法的测试工具生成了适合不同条件的测试，正确识别了部分数据问题，详细分析了大型语言模型生成的测试套件在参考对接和值准确性方面的表现.
### Conclusion
该方法通过将外部医学知识引入数据质量测试中，作为数据分析工作流程的一部分，提高了结果的有效性。该方法从质量保证的角度解决了数据质量问题，为进一步发展多种数据模态和改进对接方法奠定了基础。
## 499. `cs.LG` - TFOC-Net: 基于短时傅里叶变换的深层学习方法提高跨个体运动想象分类性能 [PDF](https://arxiv.org/pdf/2507.02510), [HTML](https://arxiv.org/abs/2507.02510)
### Authors
Ahmed G. Habashi,Ahmed M. Azab,Seif Eldawlatly,Gamal M. Aly
### Background
跨个体运动想象（CS-MI）分类在脑机接口（BCI）中是一项具有挑战性的工作，因为不同个体之间的脑电图（EEG）模式差异显著，这导致了跨个体分类准确性较低，与个体特定模型相比差异明显。较低的分类准确性构成了开发无校准BCI的重要障碍，使之不适用于实际应用环境。
### Innovation
本文提出了一个新的方法，通过优化预处理技术和深度学习技术来显著提高跨个体MI分类性能。该方法直接分类短时傅里叶变换（STFT）变换后的EEG数据，并通过优化的STFT参数和在训练卷积神经网络（CNN）时采用平衡批次策略，从而显著提高了跨个体分类性能。研究结果在四个不同数据集上得到验证，包括三个广泛使用的标准数据集，达到了显著的改进。该研究方法在BCI竞赛IV数据集1（IV-1）、数据集2A（IV-2A）和数据集2B（IV-2B）上分别实现了67.60%、65.96%和80.22%的交叉个体分类准确率，超越了现有技术。此外，该研究系统地探讨了使用4秒窗口到1秒窗口的各种MI窗口分类性能，这些结果确立了一个新的基准，有助于推进此类研究领域的一般可移植及无校准的MI分类研究，并提供了稳健的开放访问数据集。
### Conclusion
本研究提出的方法在跨个体运动想象分类中取得了显著性能提升，并通过验证了多个标准数据集证明了其有效性和可行性。这种方法在理论上可以作为实现无校准BCI系统的技术参考，并提供了进一步研究的基础，展示了一种新的数据集方法，以促进在这一领域的研究进展。
## 500. `cs.LG` - 基于嵌入的差分隐私条件变分自编码器联邦数据共享 [PDF](https://arxiv.org/pdf/2507.02671), [HTML](https://arxiv.org/abs/2507.02671)
### Authors
Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig
### Background
深度学习（DL）已彻底改变了医学影像领域，但由于数据稀缺性和隐私法规限制，导致无法访问多样化的数据集，阻碍了其广泛应用。联邦学习（FL）能够实现分散训练，但由于高昂的通信成本和单一下游任务的限制，灵活性较低。这些因素共同制约了深度学习在医学影像中的全面发展和应用潜力。
### Innovation
本文提出了一种基于生成模型的数据共享方法——使用差分隐私（DP）生成模型。通过采用基础模型提取具有信息性的嵌入表示，减少冗余并降低计算开销。各方客户端通过协作训练一种差分隐私条件变分自编码器（DP-CVAE），以模拟全球、隐私意识的数据分布，支持多样化的下游任务。验证结果显示，该方法在增强隐私、可扩展性和效率方面优于传统联邦学习分类器，并保证了差分隐私。此外，DP-CVAE 生成的嵌入表示具有更高的保真度，所需参数数量仅为 DP-CGAN 的五分之一。
### Conclusion
通过这种方法，本文成功提高了联邦数据共享的安全性和效率，支持多样化的下游任务，同时减少了计算成本和参数开销。与传统的联邦学习方法相比，该方法在隐私保护方面表现出色，且提供更好的性能表现。
## 501. `cs.LG` - 联邦数据聚合中的流体民主 [PDF](https://arxiv.org/pdf/2507.02710), [HTML](https://arxiv.org/abs/2507.02710)
### Authors
Aditya Vema Reddy Kesari,Krishna Reddy Kesari
### Background
联邦学习（FL）机制通常要求每个客户端将他们的权重传输到中央服务器，而不考虑这些权重的实际有用性。为了从客户端到中央服务器避免不必要的数据传输成本，作者提出使用基于共识的协议来识别每个数据传输步骤中最有用的客户端模型权重子集。作者探讨了现有流体民主协议在性能上的应用，并将其与传统的'一人一票'（FedAvg）进行比较。为了防止影响权重累积，作者还提出了一种新的流体民主协议——粘滞保留民主（Viscous-Retained Democracy）.
### Innovation
首先，作者提出了一个在性能上优于传统的'一人一票'（FedAvg）且不支持影响力累积的新流体民主协议——粘滞保留民主（Viscous-Retained Democracy）。其次，作者从对抗性的视角指出了现有的流体民主协议在拓扑依赖性和或需要多少攻击者来负面影响全局模型权重方面的弱点。为此，作者提出了一个算法（FedVRD），该算法通过利用代理网络结构动态限制攻击者的影响，同时最小化成本.
### Conclusion
作者提出了一个新的流体民主协议和一种新的算法，改进了现有的联邦学习中的权重传输方法，以避免不必要的数据传输成本和对抗攻击的影响。
## 502. `cs.LG` - 可指导生成的可开发抗体 [PDF](https://arxiv.org/pdf/2507.02670), [HTML](https://arxiv.org/abs/2507.02670)
### Authors
Siqi Zhao,Joshua Moller,Porfi Quintero-Cadena,Lood van Niekerk
### Background
治疗性抗体不仅需要高亲和力的靶点结合，还需要良好的制造性能、稳定性和安全性以实现临床有效性。这些特性被称为‘开发性’。为了优化抗体序列以促进良好的开发性能，本研究引入了一种基于自然重链和轻链配对序列以及246种临床阶段抗体的定量开发性能测量的引导离散扩散模型。这项研究还集成了一个软价值导向解码模块，以在不牺牲自然性的情况下引导采样。在不受约束的采样中，模型再现了自然谱系和已批准治疗药物的全球特征，而在软价值导向下，预测的开发性能得分显著增加。结合高通量开发性能测试，该框架能够实现一种迭代的、基于机器学习的抗体设计管道，用于同时满足结合和生物物理标准。
### Innovation
研究引入了一种引导离散扩散模型，该模型基于自然重链和轻链序列以及临床阶段抗体的定量开发性测量进行训练。模型还集成了一个软价值导向解码模块，以促进生物物理上可行的候选物的生成，同时保留自然特性。结合高通量开发性能测试，该框架为满足结合和生物物理标准的抗体设计提供了一种基于机器学习的迭代管道。
### Conclusion
该研究框架提供了一种优化抗体开发性能的新计算框架，通过结合高通量开发性能测试，可实现一个迭代的、基于机器学习的抗体设计管道，能够在保持自然性的前提下，生成更具有开发潜力的抗体候选物。
## 503. `cs.LG` - 公平的Deepfake检测器可以泛化 [PDF](https://arxiv.org/pdf/2507.02645), [HTML](https://arxiv.org/abs/2507.02645)
### Authors
Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli
### Background
Deepfake检测模型面临两个关键挑战：针对未见过的篡改的一般化和群体组之间的公平性。现有方法通常表明这两个目标是内在冲突的，显示出它们之间的权衡。在现有文献中，公平性和一般化这两个目标之间存在一成不变的竞争关系，即在提高模型公平性时，可能会牺牲其一般化能力，反之亦然。
### Innovation
本文首次揭示并正式定义了公平性与一般化之间的因果关系，并基于后门调整方法，控制混杂变量（数据分布和模型容量）来提升通过公平性干预的一般化性能。文章提出了Demographic Attribute-insensitive Intervention Detection (DAID)，这是一个即插即用框架，包含：I）群体意识数据重平衡，使用逆倾向加权和子组特征归一化来消除分布偏差；II）无群体关注特征聚合，采用新颖的对齐损失来抑制敏感属性信号。该框架在三个跨领域基准测试中，相比多个领先的检测器，展示了在公平性和一般化性能上的优越表现，验证了其理论基础和实践效果。
### Conclusion
DAID框架在多个基准上展示了在公平性和一般化方面的优越性能，验证了其理论基础和实践有效性，实现了公平与性能的双重提升。
## 504. `cs.LG` - OmniDraft：一种跨词汇在线自适应草案生成器，用于设备上的推测性解码 [PDF](https://arxiv.org/pdf/2507.02659), [HTML](https://arxiv.org/abs/2507.02659)
### Authors
Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang
### Background
推测性解码通常需要一个小型高效的预训练或离线蒸馏模型，以适配特定目标模型系列（例如Llama或Qwen模型）。但在在线部署场景中，有两个主要挑战：首先，目标模型可能与草案模型不兼容；其次，期望通过减少延迟来提高使用体验和时间效率。由于设备上语言模型（LLM）应用对模型成本、效率和用户定制有较高要求，解决以上问题变得尤为重要。因此，提出了OmniDraft这一统一框架，使得单一草案模型能够兼容任何目标模型，并能够根据用户数据进行动态调整。该框架通过引入结合了混合蒸馏微调的在线n-gram缓存来解决词汇表不匹配的问题，还通过自适应草案技术进一步提升了解码速度。
### Innovation
OmniDraft提出了一个统一的框架，使单一草案模型能够兼容任何目标模型，并能够根据用户数据进行动态调整。该框架通过引入结合了混合蒸馏微调的在线n-gram缓存来解决词汇表不匹配的问题，并通过自适应草案技术进一步提升了解码速度，特别适用于设备上LLM应用，展示了显著的优越性和速度提升。
### Conclusion
通过在数学推理、编程和文本生成任务中进行在线学习，OmniDraft框架证明了其在设备上的有效性，并成功使单一Llama-68M模型与各种目标模型如Vicuna-7B、Qwen2-7B和Llama3-8B进行猜测性解码，并提供了1.5-2倍的速度优势。
## 505. `cs.LG` - 高阶深度元学习及其范畴论解释 [PDF](https://arxiv.org/pdf/2507.02634), [HTML](https://arxiv.org/abs/2507.02634)
### Authors
David H. Mguni
### Background
本文提出了一种新的分层深度学习框架，旨在递归执行高阶元学习，使神经网络能够构建、解决和在任务层级结构上进行泛化。这种框架的关键在于生成机制，该机制创造出所谓的“虚拟任务”——合成问题实例，设计这些实例以使元学习器在相关任务中学习软约束和未知可泛化的规则。这使得机器学习（ML）训练不再完全依赖于人类生成的数据，而能够生成自身的信息性、任务相关的数据集，从而释放机器学习的潜力。通过主动探索虚拟点景观并发现下级学习者难以处理的任务，元学习器能够迭代细化约束区域，增强归纳偏差，标准化适应过程，并产生新颖的未预见任务和约束，以促进泛化。每一级的元层级对应于更抽象的问题泛化，形成结构化和可解释的学习进程。通过对元学习器的范畴论解释，将它们视为生成和调节下属学习者层级的范畴论中的一种结构，从而支持在泛化任务中抽象和知识转移的组成结构。这种范畴论视角统一了现有的元学习模型，并揭示了通过函子关系转换和比较学习过程的方式，同时提供了构建元学习的实用设计原则。
### Innovation
本研究提出了一个基于生成机制的新框架，使神经网络能够处理、解决和在多个层次的任务上进行泛化。这种方法的核心是‘虚拟任务’的生成，这为机器学习训练带来了自主性，不再完全依赖人类生成的数据。通过优化虚拟任务探索和迭代约束区域，系统能够不断推进学习偏差，提高适应性过程，并产生新的预期外任务和约束条件，促进泛化能力。这种新框架还能通过范畴论视角重构现有的元学习模型，揭示其间的联系与转变，为设计改进元学习方法提供指导。
### Conclusion
本文提出的方法代表了下一代自主生成新颖、有益任务及其解决方案的深度神经网络架构的可能基础，不仅能够增强机器学习能力，还能推进至通用人工智能领域。这一创新的理论和实践方案为未来深度学习的发展提供了重要的洞察和方向。
## 506. `cs.LG` - 全面的机器学习框架用于微移动需求预测 [PDF](https://arxiv.org/pdf/2507.02715), [HTML](https://arxiv.org/abs/2507.02715)
### Authors
Omri Porat,Michael Fire,Eran Ben-Elia
### Background
无桩电动滑板车作为一种重要的微移动服务，已经成为了环保且灵活的城市交通选择。这些服务提高了首末一英里连接性，减少了交通拥堵和排放，还能够作为短途出行对公共交通的补充。然而，这些服务的有效管理依赖于准确的需求预测，这对于车队最优分布和基础设施规划至关重要。以往的研究主要集中在单独分析空间或时间因素上，而本研究提出了一种框架，将空间、时间和网络依赖性整合起来，以改善微移动需求的预测。这种整合提高了预测的准确性，同时提供了对城市微移动使用模式的更深入理解。我们的框架将需求预测精度提高了27%到49%，证明了其捕捉微移动需求模式的有效性。这些发现支持基于数据的微移动管理，能够实现车队优化分配、成本降低和可持续城市规划.
### Innovation
本研究提出了一种框架，将空间、时间和网络依赖性整合起来，以改善微移动需求的预测。这种整合提高了预测的准确性，同时提供了对城市微移动使用模式的更深入理解。
### Conclusion
我们的框架将需求预测精度提高了27%到49%，证明了其捕捉微移动需求模式的有效性。这些发现支持基于数据的微移动管理，能够实现车队优化分配、成本降低和可持续城市规划.
## 507. `cs.LG` - 在连续控制中的深强化学习扩展策略：遗忘与增长 [PDF](https://arxiv.org/pdf/2507.02712), [HTML](https://arxiv.org/abs/2507.02712)
### Authors
Zilin Kang,Chenyuan Hu,Yu Luo,Zhecheng Yuan,Ruijie Zheng,Huazhe Xu
### Background
深度强化学习在连续控制领域的进展显著，但现有方法往往受到先验偏见的影响，倾向于过拟合最初存储在回放缓冲区中的经验，这限制了RL代理的样本效率和泛化能力。相比之下，人类受这种偏见的影响较小，部分归因于婴儿期遗忘机制，即新神经元的形成会破坏早期记忆痕迹，导致遗忘早期经验。
### Innovation
本文提出了一种新的深度强化学习算法Forget and Grow (FoG)，该算法引入了两种机制：Experience Replay Decay (ER Decay) 和 Network Expansion。ER Decay 通过逐渐减少早期经验的影响来平衡记忆；Network Expansion 通过动态添加新参数来逐步提升代理利用现有数据模式的能力。
### Conclusion
在四大连续控制基准测试中的40多个任务上进行的实证结果表明，FoG 在表现上优于最新的深度强化学习算法，包括BRO、SimBa和TD-MPC2。
## 508. `cs.LG` - 用于药代基因变体效应预测的矩阵变分自编码器 [PDF](https://arxiv.org/pdf/2507.02624), [HTML](https://arxiv.org/abs/2507.02624)
### Authors
Antoine Honoré,Borja Rodríguez Gálvez,Yoomi Park,Yitian Zhou,Volker M. Lauschke,Ming Xiao
### Background
变体效应预测器（VEPs）的传统方法依赖于多序列比对（MSA），这种假设认为天然存在的变体会在自然条件下适应良好。然而，药代基因组学表明，一些药代基因可能会经历低进化压力，传统的MSA方法可能不再适用。深度变异扫描（DMS）数据集为变体效应研究提供了一种替代方法，它们提供了变体的定量适应度评分。已有许多模型，如DeepSequence模型，致力于变体效应预测，但大多数仍依赖于MSA工具。
### Innovation
本文提出了一个基于变压器的矩阵变分自编码器（matVAE），它结合了结构先验，并在一个包含26种药物目标和ADME蛋白质的33个DMS数据集上进行了评估。matVAE在使用参数量远低于DeepSequence模型且推理计算量更小的情况下，仍能达到更好的零样本预测性能。此外，还将AlphaFold生成的结构纳入Transformer模型中，进一步提高了性能。与在DMS数据上训练的同类模型matENC-DMS相比，matVAE显示出了优势。这些发现表明，DMS数据集的潜在价值，提出了无需大规模损失预测性能即可取代MSA的可能性，推进了DMS数据集的进一步开发及其对变体效应预测的影响研究。
### Conclusion
文章的研究结果表明，矩阵变分自编码器（matVAE）模型在使用DMS数据集而非MSA数据集进行训练时，可以实现更好的变体效应预测性能，同时模型结构更为简洁。这为变体效应预测提供了新的方法，并揭示了DMS数据集的巨大潜力。未来的工作可以进一步探索DMS数据与其他数据集的关系，以提高变体效应预测的准确性。
## 509. `cs.LG` - 通过约束优化实现健运行时多校准的生存分析在医疗保健中 [PDF](https://arxiv.org/pdf/2507.02807), [HTML](https://arxiv.org/abs/2507.02807)
### Authors
Thiti Suttaket,Stanley Kok
### Background
生存分析是医疗保健中的一个重要问题，因为它能够建模个体协变量与感兴趣事件（如死亡）发生时间的关系。生存模型需要很好地校准（即预测概率应接近真实概率），因为准确性差的系统可能导致临床决策错误。现有的生存模型通常仅在总体层面校准，从而可能对一个或多个少数子群产生不良校准。
### Innovation
本文提出了一种称为GRADUATE的模型，通过确保所有子群都校准良好来实现多校准。GRADUATE将多校准表示为一个约束优化问题，并在训练过程中同时优化校准和区分性，以达到两者之间的良好平衡。我们理论上证明使用的优化方法可以高概率获得接近最优且可行的解。实验证明，与其他前沿基线相比，GRADUATE在实际临床数据集上具有更高的有效性。
### Conclusion
通过详细的分析，我们解释了基线相对于GRADUATE的不足之处。
## 510. `cs.LG` - 理解并改进递归模型的长度泛化 [PDF](https://arxiv.org/pdf/2507.02782), [HTML](https://arxiv.org/abs/2507.02782)
### Authors
Ricardo Buitrago Ruiz,Albert Gu
### Background
近年来，由于其在序列长度上具有线性复杂度，循环模型如状态空间模型和线形注意力变得流行。尽管这些模型具有处理任意长序列的能力，但在训练范围之外，它们的表现有时会显著下降，即无法进行长度泛化。具体而言，这些模型在训练过程中仅接触到分布中的一部分状态时，很难在更长的序列上表现良好。本文提供了一项全面的实证和理论分析，以支持“未探索状态假设”，认为模型无法进行长度泛化的原因是在训练时仅接触到了有限的状态集。本文还调查了一些简单的训练干预措施，以增加模型训练时所接触状态的覆盖范围，比如以高斯噪声或不同输入序列的最终状态初始化状态。这些干预措施只需极少量的后训练步骤，就能使模型在长度显著增加的序列上学习，表现出改进的性能，从而简单高效地解决了递归模型的长度泛化问题。
### Innovation
本文的创新包括：1. 提出并验证了“未探索状态假设”，解释了模型在长序列上表现不佳的原因；2. 提出了一种简单有效的训练干预方法，通过重新初始化模型状态来增加训练覆盖的状态集；3. 证明了轻量级后训练步骤（仅占预训练预算的约0.1%）即可实现显著的长度泛化能力，适用于宽泛的递归模型场景。
### Conclusion
本文通过全面的实证和理论分析，阐明了递归模型在处理长序列时无法泛化的根本原因，并提出了一种简单高效的训练干预方法，能够显著提高递归模型的长度泛化能力，这对于优化长上下文任务具有重要意义。
## 511. `cs.LG` - 供应链中基于多智能体强化学习的动态定价：在现实模拟市场条件下对战略智能体行为的基准测试 [PDF](https://arxiv.org/pdf/2507.02698), [HTML](https://arxiv.org/abs/2507.02698)
### Authors
Thomas Hazenberg,Yao Ma,Seyed Sahand Mohammadi Ziabari,Marijn van Rijswijk
### Background
该研究探讨了多智能体强化学习(MARL)如何改善供应链中的动态定价策略，特别是在传统的ERP系统依赖于静态、基于规则的方法且未充分考虑市场行为者之间的战略互动的情况下。尽管最近的研究已经将强化学习应用于定价，但大多数实施方案仍然是单智能体的，并且未能模拟现实世界供应链中的相互依赖性。这项研究通过在包含真实电子商务交易数据和LightGBM需求预测模型的模拟环境中，评估三种MARL算法（MADDPG、MADQN和QMIX）与静态基于规则的基础模型的表现，填补了这一空白。研究表明，基于规则的智能体在公平性和价格稳定性方面表现最佳，但缺乏竞争动态。而在MARL智能体中，MADQN展示了最激进的价格行为，具有最高的波动性和最低的公平性，而MADDPG提供了一种更加平衡的方法，既支持市场公平性（公平性指数0.8819）又保持价格稳定（较低的波动性）.
### Innovation
该研究主要创新在于通过真实模拟市场条件下的实验，将MARL算法应用于供应链中的动态定价，评估了MADDPG、MADQN和QMIX三种算法的表现，填补了现有研究在多智能体强化学习应用于动态定价策略上的空白，揭示了静态定价规则未能捕捉到的新兴策略行为。
### Conclusion
研究发现，MARL引入了未被静态定价规则捕捉到的新兴策略行为，这些发现可能会影响未来动态定价策略的发展。MADDPG提供了相对平衡的方法，支持市场公平性并保持价格稳定，相比之下，MADQN则展示了更激进的价格行为。这些结果表明，MARL算法可以显著提高供应链中动态定价策略的效果。
## 512. `cs.LG` - LLM-驱动的在推理时间文本混杂下的治疗效果估计 [PDF](https://arxiv.org/pdf/2507.02843), [HTML](https://arxiv.org/abs/2507.02843)
### Authors
Yuchen Ma,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel
### Background
在医学个性化决策中，治疗效果的估计至关重要，但这一任务在临床实践中面临独特挑战。在训练阶段，用于估计治疗效果的模型通常会在结构化的医学数据集上进行训练，这些数据集包含详细的患者信息。然而，在推理阶段，通常使用文本描述（如自我报告的症状描述）进行预测，这些描述是原始患者信息的不完整表示。训练阶段和推理阶段数据的不匹配可能导致治疗效果的偏差估计。
### Innovation
本文提出了一个新颖的框架来估计治疗效果，该框架明确地考虑了推理时间文本混杂问题。该框架结合了大型语言模型和自定义双重稳健学习者，以缓解由推理时间文本混杂引起的偏差问题。
### Conclusion
通过一系列实验，证实了该框架在实际应用中的有效性。
## 513. `cs.LG` - 快速且简化：Triton 中的 2-单形注意力 [PDF](https://arxiv.org/pdf/2507.02754), [HTML](https://arxiv.org/abs/2507.02754)
### Authors
Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil
### Background
近期研究表明，训练损失与模型大小和令牌数量均呈幂律关系，计算最优模型需要同步放大模型大小和令牌数量。然而，这些缩放定律假设数据无限供应，并主要适用于计算受限环境。随着现代大型语言模型越来越依赖于大规模互联网数据集，数据丰富的假设使得这些模型在计算受限的情况下变得不那么符合实际。这表明需要优先考虑令牌效率的架构。
### Innovation
本文研究了2-单形Transformer架构的应用，该架构通过高效的Triton内核实现将标准点积注意力推广到三线性函数。实验表明，2-单形Transformer在固定令牌预算下，大小相似的模型在涉及数学、编程、推理和逻辑的任务上优于标准Transformer。通过量化这些增益，证明了2-单形注意力改变了知识和推理任务缩放定律中的指数，相比点积注意力有所不同。
### Conclusion
本文研究了2-单形Transformer的使用，证明了其在令牌效率方面的优势，从而改变了现有模型的缩放定律.
## 514. `cs.LG` - 可重复性的分布测试 [PDF](https://arxiv.org/pdf/2507.02814), [HTML](https://arxiv.org/abs/2507.02814)
### Authors
Ilias Diakonikolas,Jingyi Gao,Daniel Kane,Sihan Liu,Christopher Ye
### Background
该研究开始系统地探讨了算法可重复性框架下的分布测试问题。给定独立的来自一组概率分布的样本，研究目标是刻画以可重复的方式测试底层分布自然属性所需的样本复杂性。在算法方面，作者开发了新的可重复算法来测试离散分布的相近性和独立性。从下界角度来看，作者开发了一种新的证明可重复测试样本复杂性下界的范式，这可能具有更广泛的应用价值。作为技术应用，研究建立了逼近最优的可重复均匀性测试和相近性测试的样本复杂性下界，解决了前人工作的开放性问题。
### Innovation
在算法方面，作者开发了新的可重复算法来测试离散分布的相近性和独立性；在下界方面，作者开发了一种新的证明可重复测试样本复杂性下界的范式。
### Conclusion
通过应用作者的技术，建立了逼近最优的可重复均匀性测试和相近性测试的样本复杂性下界，解决了前人工作的开放性问题。
## 515. `cs.LG` - 跨物种蛋白质-蛋白质相互作用预测中的层次多标签对比学习 [PDF](https://arxiv.org/pdf/2507.02724), [HTML](https://arxiv.org/abs/2507.02724)
### Authors
Shiyi Liu,Buwen Liang,Yuetong Fang,Zixuan Jiang,Renjing Xu
### Background
最近，人工智能在科学领域中的进步凸显了对比学习在整合异构生物数据模态方面的强大能力。基于这一范式，该研究提出了一种名为HIPPO的层次蛋白质-蛋白质相互作用预测框架（HIerarchical Protein-Protein interaction prediction across Organisms），该框架通过多级生物表征匹配将蛋白质序列及其层次属性对齐。实验表明，该方法在基准数据集上实现了最先进的性能，在低数据环境下表现出稳健性，并且展示了在缺乏实验数据的未表征或稀有物种中进行可靠的蛋白质-蛋白质相互作用预测和功能推断的能力。进一步的分析表明，层次特征融合对于捕捉保守的相互作用决定因素至关重要，如结合基序和功能注释。这项工作推进了跨物种蛋白质-蛋白质相互作用预测，并提供了一个统一框架，用于处理稀疏或多物种数据不平衡的情况。
### Innovation
提出了HIPPO（HIerarchical Protein-Protein interaction prediction across Organisms），这是一种基于多级对比学习的框架，用于跨物种的蛋白质-蛋白质相互作用预测。该框架通过多级生物特征匹配对齐蛋白质序列及其层次属性，融入了层次对比损失函数来模拟功能类别蛋白质之间的结构关系，并通过数据驱动的惩罚机制动态引入领域和家族知识，以确保学习嵌入空间与蛋白质功能的内在层次结构的一致性。这一工作显著地推动了在数据稀疏或多物种数据不平衡的情况下进行蛋白质-蛋白质相互作用预测的能力，并展示了强大的零样本迁移性能，可以在未表征或稀有物种中实现可靠的预测和功能推断，无需重新训练。
### Conclusion
实验结果显示，HIPPO在基准数据集上达到了最先进的性能，不仅在有标签的数据中表现出色，还在数据稀缺的环境下也表现出良好的稳健性和可预测性。此外，HIPPO展示了在未表征或稀有物种中的可靠性能，即使在实验数据有限的情况下也能实现可靠的蛋白质-蛋白质相互作用预测和功能推断。对层级特征融合的进一步分析表明，这是捕捉保守相互作用决定因素的关键。这项工作为跨物种的蛋白质-蛋白质相互作用预测提供了有效的工具，并为稀疏或多物种数据环境下的交互预测统一框架做出了贡献。
## 516. `cs.LG` - 通过线性张量四方注意力实现可扩展且量子级准确的生物分子力场基础模型 [PDF](https://arxiv.org/pdf/2507.00884), [HTML](https://arxiv.org/abs/2507.00884)
### Authors
Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou
### Background
精确的原子级生物分子模拟对于疾病机制理解、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场效率高但对重要的过渡态和精细构象细节准确度不足。量子力学（QM）方法虽然非常准确，但在大规模或长时间模拟中计算上不可行。基于AI的力场（AIFF）旨在实现接近QM的准确度与效率，但在处理多体模型复杂性、准确性和速度之间的平衡上存在挑战，受限于有限的训练数据和一般化验证不足。
### Innovation
本文提出了一种新颖的李特恩（LiTEN）神经网络，带有张量四方注意力（TQA），用于高效建模三体和四体相互作用，避免了昂贵的球谐函数。基于LiTEN，提出了一个稳健的AIFF基础模型LiTEN-FF，该模型预训练在广泛的nablaDFT数据集上实现广泛的化学通用性，并针对SPICE数据集进行了微调，以提供准确的溶剂化系统模拟。LiTEN在rMD17、MD22和Chignolin的大多数评估子集中达到了当前最先进的（SOTA）性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF支持全面的下游生物分子建模任务，包括接近量子的构象搜索、几何优化和自由能面构建，同时比MACE-OFF提供大生物分子（约1000个原子）快10倍的速度推断。
### Conclusion
本文提出了一种基于物理原理的高效框架，推动了复杂生物分子建模的发展，提供了一个多功能的基础框架，适用于药物发现等相关应用。
## 517. `cs.LG` - 含偏差离线数据的上下文在线定价 [PDF](https://arxiv.org/pdf/2507.02762), [HTML](https://arxiv.org/abs/2507.02762)
### Authors
Yixuan Zhang,Ruihao Zhu,Qiaomin Xie
### Background
研究了在存在偏差的离线数据情况下进行上下文在线定价的问题。在单位价格弹性情况下，研究者识别了一个实例依赖于的量 $δ^2$，用于衡量离线数据与未知的在线最优值之间的差异。此外，研究还讨论了这些因素如何共同影响统计数据的复杂度，并提供了在不确定性面前乐观（Optimism-in-the-Face-of-Uncertainty，OFU）的策略所达到的最小最大最坏情况下的实例依赖的遗憾界。对于更一般的弹性情况，推出了最坏情况下最小最大最优化的速率，并提出一个通用的OFU算法来实现它。当偏差界限未知时，开发了一个鲁棒的变体，确保了亚线性遗憾并优于纯粹在线方法。该研究提供了首次对未来主义偏差离线数据存在的上下文定价问题提供严格的遗憾保障。此外，这些技术也可以直接应用于带有偏差离线数据的随机线性多臂赛选问题，并提供类似的边界。
### Innovation
1. 识别了一个实例依赖于的偏差量 $δ^2$，用于衡量离线数据与在线最优值之间的差异。2. 提供了在不确定性面前乐观的策略所达到的最小最大最坏情况下的实例依赖的遗憾界。3. 为更一般的弹性情况推出了最坏情况下最小最大最优化的速率，并提出一个通用的OFU算法来实现它。4. 在偏差界限未知时开发了一个鲁棒的变体，确保了亚线性遗憾并优于纯粹在线方法。5. 提供了首次对未来主义偏差离线数据存在的上下文定价问题提供严格的遗憾保障。6. 将这些技术直接应用于带有偏差离线数据的随机线性多臂赛选问题，并提供类似的边界。
### Conclusion
研究表明，即使存在偏差的离线数据，上下文在线定价问题的遗憾界是可以获得的。提出的OFU策略和鲁棒策略在不同条件下都能有效降低遗憾，实现更优的性能表现。此外，这些技术的应用不仅限于上下文定价问题，还能扩展到随机线性多臂赛选问题，进一步展示了其广泛的适用性和有效性。
## 518. `cs.LG` - MvHo-IB: 多视图高阶信息瓶颈方法在脑部疾病诊断中的应用 [PDF](https://arxiv.org/pdf/2507.02847), [HTML](https://arxiv.org/abs/2507.02847)
### Authors
Kunyu Zhang,Qiang Li,Shujian Yu
### Background
近期研究表明，在功能磁共振成像(fMRI)数据中建模高阶交互(HOIs)能够提升机器学习系统的诊断准确性。然而，有效提取和利用HOIs仍旧是一个有挑战性的问题。因此，本文提出了一种新颖的多视图学习框架MvHo-IB，该框架能够同时整合两两交互及HOIs进行诊断决策，同时自动压缩与任务无关的冗余信息。
### Innovation
MvHo-IB引入了几个关键创新点：(1)一种原则性的方法，结合信息论中的O信息与矩阵形式的Rényi α阶熵估计器来量化和提取HOIs；(2)一种定制的Brain3DCNN编码器，有效利用这些交互；(3)一种新的多视图学习信息瓶颈目标来增强表示学习。
### Conclusion
在三个基准fMRI数据集上的实验表明，MvHo-IB达到了最先进的性能，显著优于以前的方法，包括最近的超图基技术。
## 519. `cs.LG` - 用于动物鸣叫声检测的神经网络的声学评估 [PDF](https://arxiv.org/pdf/2507.01974), [HTML](https://arxiv.org/abs/2507.01974)
### Authors
Jérémy Rouch(CRNL-ENES),M Ducrettet(CRNL-ENES, ISYEB),S Haupert(ISYEB),R Emonet(LabHC),F Sèbe(CRNL-ENES, OFB - DRAS)
### Background
长时间录音设备现在可以在有时苛刻的实地条件下使用，使通过生态声学部署广泛的动物种群监测活动成为可能。尽管自动信号检测方法越来越依赖神经网络，但这种方法的有效性通常仅通过机器学习指标来评估，而对声学分析的性能评估则较少见。本文在岩山鹑种群声学监测中提出了一种简单的声学分析方法，以评估检测系统的性能。该方法基于信号与噪声比与其被检测概率之间的关系，展示了这种方法如何提供关于系统的信息并帮助优化其训练，以及如何能够建模检测距离，这样就可以根据声音环境评估其动态并获取鸣叫声的空间密度估算值。
### Innovation
本文提出了一种基于信号与噪声比与其被检测概率之间关系的简单声音分析方法，以及展示该方法如何提供关于检测系统的优化信息并建模检测距离，从而评估其性能动态和空间密度估算值。这种评估方法在现有的仅通过机器学习指标评估自动信号检测方法的有效性之外，提供了一种新的方法，直接从声学分析的角度进行评估。
### Conclusion
提出的基于信号与噪声比和检测概率关系的测量方法能够提供有关系统的信息，有助于优化训练并建模检测距离，从而可以根据声音环境评估检测距离的动态并获得鸣叫声的空间密度估算。
## 520. `cs.LG` - ExPO：利用自我解释引导强化学习解锁难题推理 [PDF](https://arxiv.org/pdf/2507.02834), [HTML](https://arxiv.org/abs/2507.02834)
### Authors
Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi
### Background
近年来，大型语言模型的进步主要依赖于后训练阶段的强化学习（RL）风格优化，通过对模型输出进行奖励或偏好信号优化来提升推理能力。GRPO风格的方法通过使用基于结果的验证器自动生成样本来实现这一点。然而，这些方法高度依赖模型最初生成正样本的能力，主要是在原有知识基础上进行精炼（分布硬化），而不是让模型解决最初不知如何解决的问题。对于早期的RL训练和具有挑战性的推理任务，生成正样本的可能性较小。因此，此时需要模型探索超出当前输出分布的新推理路径。这种探索需要能够引导学习的良好正样本。尽管专家演示似乎是自然的解决方案，但作者发现其在RL后训练中往往无效。因此，作者识别有效正样本的两个关键属性：（1）它们应当在当前策略下更可能出现；（2）它们能够增加模型预测正确答案的可能性。
### Innovation
作者提出了一种简单且模块化的框架——Self-Explanation Policy Optimization（ExPO），通过基于真实答案进行条件生成，来生成所需的有效正样本。ExPO通过自我解释引导学习，使模型能够产生与其策略更一致的推理路径，同时比专家撰写的计算步骤具有更高的质量。实验结果表明，ExPO在学习效率和最终性能方面优于基于专家演示的方法，尤其是在MATH级别5的任务中，模型最初最难以处理的任务中表现尤为明显。
### Conclusion
ExPO通过生成基于真实答案的正样本，有效地引导了模型进行探索，改进了学习效率和最终性能，特别是在解决具有挑战性的推理问题时，超过了依赖专家演示的方法。
## 521. `cs.LG` - DeepSupp：基于注意力机制的动态时间序列支撑与阻力位模式分析 [PDF](https://arxiv.org/pdf/2507.01971), [HTML](https://arxiv.org/abs/2507.01971)
### Authors
Boris Kriuk,Logic Ng,Zarif Al Hossain
### Background
支撑与阻力水平(SR)是技术分析的核心，帮助交易者决定入市、退出和风险管理。尽管被广泛使用，传统的SR识别方法在应对现代复杂且波动性大的市场时往往失效。尽管最近的研究引入了机器学习技术来解决这一问题，大多数研究集中在价格预测上，而不是结构性水平的识别。本研究旨在开发一个基于深度学习的方法，Depsupp，利用多头注意力机制分析时空相关性和市场微观结构关系来识别金融支撑位，从而解决传统方法存在的问题。
### Innovation
Depsupp提出了一种新的基于深度学习的支撑水平检测方法，使用多头注意力机制分析时空相关性和市场微观结构关系，结合高级功能工程构建动态相关矩阵，捕捉市场关系的变化。通过基于注意力的自编码器进行鲁棒的表征学习，最终通过.DBSCAN无监督聚类提取支撑水平。在对S&P 500中的股票进行综合评估后，Depsupp在六个金融指标上均优于六个基准方法，取得了最先进的技术水平，并且在不同的市场条件下表现出一致的结果，提供了支撑与阻力水平检测的关键改进方法，具有可扩展性和可靠性，改善了技术交易策略的准确性。
### Conclusion
Depsupp通过基于注意力机制的技术，解决了支撑和阻力水平检测中的关键挑战，为现代金融分析提供了强大的解决方案。这种方法不仅提高了技术交易策略的有效性，还展示了基于注意力架构在识别复杂市场模式方面的潜力。
## 522. `cs.LG` - 新闻情感嵌入模型在股票价格预测中的应用 [PDF](https://arxiv.org/pdf/2507.01970), [HTML](https://arxiv.org/abs/2507.01970)
### Authors
Ayaan Qayyum
### Background
本文将探讨如何利用头条数据来预测股票价格。研究对象是SPDR S&P 500 ETF Trust，即SPY，它追踪美国前500大上市公司的表现。重点是利用华尔街日报（WSJ）的新闻头条，在使用基于OpenAI的文字嵌入模型创建每个头条的向量表示后，通过主成分分析（PCA）提取关键特征，以预测日尺度下的股票价格波动。此项工作的挑战在于捕捉新闻对股票价格的时序依赖性和非时序依赖性、细致的影响，同时处理潜在的滞后效应和市场噪音。为了提高模型性能，收集了如美国货币指数（DXY）和国债收益率等金融与经济数据。共训练了超过390个机器学习推理模型。初步结果显示，在训练和优化不含头条数据嵌入的机器学习系统时，头条数据嵌入能至少提高40%的股票价格预测能力。
### Innovation
本文提出的方法创新在于使用基于OpenAI的文字嵌入模型将新闻头条转换为向量，利用主成分分析提取关键特征，并利用这些特征来预测股票价格。这一方法能够捕捉新闻对股票价格的多种影响，从而提高预测准确性。
### Conclusion
通过训练超过390种机器学习模型，文章展示了新闻头条数据嵌入技术可以显著提升股票价格预测能力，至少提升40%以上。这一技术应用为金融市场的预测提供了新的方向，有助于更好地理解和处理市场中的新闻影响。
## 523. `cs.LG` - 使用强化学习加速投资组合优化和期权定价 [PDF](https://arxiv.org/pdf/2507.01972), [HTML](https://arxiv.org/abs/2507.01972)
### Authors
Hadi Keramati,Samaneh Jazayeri
### Background
在投资组合优化和期权定价中，大型线性系统（形式为Aλ=b）需要解决。直接求解高维投资组合或细网格期权定价问题的成本很高。因此，迭代方法通常在实际情况下被用来解决投资组合问题。然而，病态条件系统的收敛速度很慢。传统预条件技术通常需要针对特定问题进行参数调优。为了解决这一限制，本文提出了一种基于强化学习（RL）的框架，通过动态调整块预条件器的大小来加速迭代求解器的收敛速度。
### Innovation
本文提出了一种基于强化学习的框架，用于优化投资组合优化和期权定价中使用的块预条件器的大小，通过动态调整块预条件器的大小来加速迭代求解器的收敛速度。实证研究表明，这种RL框架可以显著加速收敛速度并降低成本，从而支持更快、更动态的投资组合分配和实时期权定价决策。
### Conclusion
通过评估现实世界的投资组合优化矩阵，实证研究证实了基于强化学习的加速求解器在投资组合优化和期权定价中能够显著加速收敛速度、减少计算成本，并支持更快速的决策。
## 524. `cs.LG` - 从统计模型到深度学习的网络流量合成综述 [PDF](https://arxiv.org/pdf/2507.01976), [HTML](https://arxiv.org/abs/2507.01976)
### Authors
Nirhoshan Sivaroopan,Kaushitha Silva,Chamara Madarasingha,Thilini Dahanayaka,Guillaume Jourjon,Anura Jayasumana,Kanchana Thilakarathna
### Background
合成网络流量生成作为一种有前景的选择，在网络领域的数据驱动应用中逐渐展现出潜力。它能够创建出具有真实世界特性的数据，同时解决了真实数据面临的稀缺性、隐私问题和纯度限制等关键问题。近年来，随着人工智能和机器学习的迅速发展，基于深度学习的合成网络流量生成技术得到了广泛研究，同时统计方法及其扩展也在不断发展，包括商业化的工具也随之出现。
### Innovation
该论文专注于基于深度学习的合成网络流量生成技术，同时详细讨论了统计方法及其扩展。论文还强调了该领域存在的开放挑战，并探讨了未来研究和发展的可能性。
### Conclusion
该综述旨在为研究人员和实践者提供一个坚实的基础资源，通过系统分析现有方法、挑战和机会，为合成网络流量生成领域的进一步发展提供了指导。
## 525. `cs.LG` - 使用长短期记忆技术预测尼日利亚股票回报 [PDF](https://arxiv.org/pdf/2507.01964), [HTML](https://arxiv.org/abs/2507.01964)
### Authors
Adebola K. Ojo,Ifechukwude Jude Okafor
### Background
投资者和股票市场分析师在预测股票回报和做出明智的投资决策方面面临重大挑战。股票回报的可预测性可以增强投资者的信心，但这一任务依然非常艰难。因此，本研究使用长短期记忆（LSTM）模型预测尼日利亚股票市场的未来动向，研究使用了经过清洗和标准化的历史数据集，并将其用于构建LSTM模型。该模型使用性能指标进行了评估，并与人工神经网络（ANN）和卷积神经网络（CNN）等其他深度学习模型进行了比较。实验结果显示，当使用可靠数据集训练时，LSTM模型可以准确预测未来股票市场价格及其回报率（超过90%的准确率）。不过，这项研究表明，如果训练得当，LSTM模型对于预测与金融市场时间序列相关的问题是有用的。未来的研究应探索将LSTM模型与其他深度学习技术，如CNN相结合，以创建能够减少仅依赖单一模型预测未来股票回报所带来的风险的混合模型。
### Innovation
本研究采用了LSTM模型来预测尼日利亚股票市场的未来动向，并且使用了清洗和标准化的历史数据集，这在提升模型预测效果方面具有创新性。此外，实验结果表明，LSTM模型在预测股票回报方面的表现优于其他深度学习模型，验证了其在该领域的适用性和有效性。未来可以将LSTM与其他深度学习技术相结合，以提升预测模型的鲁棒性和准确性。
### Conclusion
本研究表明，如果训练得当，LSTM模型对于预测与金融市场时间序列相关的问题是有效的。未来的研究应进一步探索将LSTM与其他深度学习技术相结合，以降低依赖单一模型的风险。
## 526. `cs.LG` - 金融网络中的欺诈检测：基于Granger因果解释的半监督GNN方法 [PDF](https://arxiv.org/pdf/2507.01980), [HTML](https://arxiv.org/abs/2507.01980)
### Authors
Linh Nguyen,Marcel Boersma,Erman Acar
### Background
金融行业的欺诈活动每年造成数十亿的损失，因此检测欺诈成为一个至关重要的但技术上具有挑战性的任务。机器学习方法虽然具备潜力，但在实际应用中却面临两个主要难题：一是数据标记稀疏，使得模型训练困难并伴随较高的标签成本；二是机器学习模型的不透明性使得被标记的项目难以解释，这往往违反了业务监管的要求。
### Innovation
本文提出了一种基于半监督图神经网络(SAGE-FIN)和Granger因果解释的方法。该方法能够利用少量或无标记数据进行欺诈检测，并通过Granger因果关系解释被标记的项目，以满足监管要求。实验结果表明，SAGE-FIN在现实世界的数据集中表现良好，且能够生成被识别出的欺诈性项目的Granger因果解释，不依赖于网络结构的前提假设。
### Conclusion
SAGE-FIN通过结合半监督学习和Granger因果解释，有效解决了金融网络中欺诈检测的技术难题，不仅提升了检测性能，还增强了结果的透明度和合规性。
## 527. `cs.LG` - 基于机器学习的印度金融市场组合压力测试框架 [PDF](https://arxiv.org/pdf/2507.02011), [HTML](https://arxiv.org/abs/2507.02011)
### Authors
Vidya Sagar G,Shifat Ali,Siddhartha P. Chakrabarty
### Background
传统压力测试存在局限性，本文通过降维和潜在因素建模（使用主成分分析和自动编码器），克服了这些局限性。进一步地，通过引入变分自动编码器，增强了潜在空间的统计结构，使得基于蒙特卡洛的压力情景生成更为精确，并支持通过风险价值（VaR）和预期 shortfall（ES）来评估风险。
### Innovation
提出了一个基于机器学习的压力测试框架，该框架使用潜在因素建模和变分自动编码器，引入了潜在空间的概率结构，通过蒙特卡洛方法生成更多复杂和分布意识的压力情景，捕捉非线性依赖关系，并通过VaR和ES支持风险估算。
### Conclusion
所提出的机器学习框架为印度金融市场的部门压力测试提供了新的视角，展示了机器学习方法在提高灵活性、稳健性和现实性方面的潜力。
## 528. `cs.LG` - ManifoldMind：动态双曲推理以支持可信赖的推荐 [PDF](https://arxiv.org/pdf/2507.02014), [HTML](https://arxiv.org/abs/2507.02014)
### Authors
Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic
### Background
之前的方法大多采用固定的曲率和刚性的嵌入方式，这限制了对于语义层次在双曲空间中探索的能力。这些方法难以提供个性化不确定性的建模与几何感知的语义探索。ManifoldMind通过将用户、项目和标签表示为自适应曲率的可能球体，解决了这个问题，这使得它能够在稀疏或抽象领域中提供透明、可信和探索驱动的推荐。
### Innovation
ManifoldMind引入了自适应曲率的可能球体来表示用户、项目和标签，这显著改进了个性化不确定性的建模能力，并能进行几何感知的语义探索。此外，ManifoldMind还支持软的多跳推理，使得模型能够探索多样性的概念路径，而不是仅仅依赖于简单的交互。实验表明，ManifoldMind在四个公共基准上的表现优于现有的强基线模型，具有更好的NDCG、校准度和多样性。
### Conclusion
ManifoldMind能够生成明确的推理轨迹，有助于在稀疏或抽象领域提供透明、可信和探索驱动的推荐。该系统已经在四个公开基准上得到了验证，比现有的强基线模型表现得更好。
## 529. `cs.LG` - 使用LSTNet预测劳动力市场：一种多尺度深度学习方法 [PDF](https://arxiv.org/pdf/2507.01979), [HTML](https://arxiv.org/abs/2507.01979)
### Authors
Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi
### Background
本文介绍了利用美国劳工统计局的劳动力市场数据来预测短期就业变动和评估长期行业健康状况的一种深度学习方法。该方法采用长短期时间序列网络（LSTNet）处理包括就业水平、工资、离职率和求职空缺在内的多变量时间序列数据，旨在输出7天的就业预报和可解释的行业就业健康指数（IEHI）
### Innovation
本文提出的方法使用LSTNet处理多变量时间序列数据，并输出包括7天就业预报和可解释的行业就业健康指数（IEHI）。与基线模型相比，该方法在大多数行业中表现出色，特别是在稳定行业中。IEHI排名与实际的就业波动之间显示出很强的关联性。此外，本文还讨论了误差模式、行业特定性能，并指出了提高可解释性与泛化的未来方向
### Conclusion
该方法在大多数行业中表现优异，特别是稳定行业，并且IEHI排名与实际就业变动高度一致。未来将进一步提高该方法的可解释性和泛化能力，并探讨其在其他行业的应用潜力
## 530. `cs.LG` - 采用中值绝对偏差的自适应迭代软门限算法 [PDF](https://arxiv.org/pdf/2507.02084), [HTML](https://arxiv.org/abs/2507.02084)
### Authors
Yining Feng,Ivan Selesnick
### Background
自适应迭代软门限算法（Adaptive Iterative Soft-Thresholding Algorithm, ISTA）在未经明确调参的情况下解决了LASSO问题，多次得到应用并取得了成功，但缺乏相应的理论支撑。尤其是关于阈值策略如何影响算法性能的相关理论研究较少。
### Innovation
本文对基于中值绝对偏差（Median Absolute Deviation, MAD）估计噪声水平的自适应ISTA算法进行了理论分析。研究了算法的几个重要特性，包括尺度不变性、非唯一性、局部稳定性，证明了局部线性收敛的保证，进一步探讨了其全局收敛性。
### Conclusion
通过对自适应ISTA算法的理论分析，揭示了基于中值绝对偏差的自适应阈值策略的性质，并证明了算法的局部和全局收敛性，填补了该领域缺乏理论基础的研究空白。
## 531. `cs.LG` - 将大型语言模型集成到金融投资和市场分析中：一项文献综述 [PDF](https://arxiv.org/pdf/2507.01990), [HTML](https://arxiv.org/abs/2507.01990)
### Authors
Sedigheh Mahdavi,Jiating(Kristin)Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh
### Background
传统的金融投资策略通常依靠定量模型、基本面分析和技术指标。然而，大型语言模型（LLMs）引入了处理和分析大量结构化和非结构化数据的新能力，提取有意义的见解，实时增强决策。本文综述了金融领域中LLMs的最新研究，涵盖了基于LLM的框架和管道、混合集成方法、微调和适应性方法以及基于代理的架构四大类研究贡献。这一研究还对LLMs在股票选择、风险评估、情绪分析、交易和金融预测中的应用进行了结构化的回顾，通过现有的文献揭示了LLMs在金融市场中的功能、挑战及发展潜力。
### Innovation
研究将现有的LLMs研究分类为四大类：基于LLM的框架和管道、混合集成方法、微调和适应性方法，以及基于代理的架构，提供了对这些方法在金融投资和市场分析中应用的结构化综述。这项研究突显了LLMs在金融市场的功能、面临的挑战以及未来的研究方向，为其进一步应用提供了指导。
### Conclusion
通过回顾现有文献，这项研究突显了LLMs在金融市场中的功能、面临的挑战以及未来的研究方向。虽然LLMs在增强金融决策方面提供了强大的潜力，但同时也存在数据隐私、模型公平性和精确性等方面的问题。未来的研究需要针对这些问题提出新的解决方案，推动LLMs在金融领域的更广泛应用。
## 532. `cs.LG` - HCVR：一种基于相关性投票规则的混合特征选择方法 [PDF](https://arxiv.org/pdf/2507.02073), [HTML](https://arxiv.org/abs/2507.02073)
### Authors
Nikita Bhedasgaonkar,Rushikesh K. Joshi
### Background
本文提出了HCVR（Hybrid approach with Correlation-aware Voting Rules，基于相关性投票规则的混合方法），这是一种使用参数间相关性和参数到目标相关性的基于规则的轻量化特征选择方法。该方法结合了非迭代和迭代降维方法的特性，通过反向消除的方式逐步剔除冗余特征并保留相关特征。该方法的有效性通过在SPAMBASE数据集上的应用得到了验证，结果显示相比传统的非迭代（CFS, mRMR和MI）和迭代（RFE, SFS和遗传算法）特征选择方法，其鉴别性能有所提升
### Innovation
该方法创新性地将Parameter-to-Parameter (P2P) 和 Parameter-to-Target (P2T)相关性结合，并采用非迭代和迭代相结合的方式进行特征选择。此外，该方法采用贪心策略，通过多数投票决定特征的保留与否，并利用所有特征对之间的相关性阈值和特征与目标之间的相关性阈值进行投票决策
### Conclusion
基于HCVR方法在SPAMBASE数据集上的应用，结果表明该方法在分类器性能上达到了更好的效果，相比传统的方法具有更高的性能表现，验证了其在特征选择领域的有效性
## 533. `cs.LG` - NGAT: 一种适用于长期股票预测的节点级图注意力网络 [PDF](https://arxiv.org/pdf/2507.02018), [HTML](https://arxiv.org/abs/2507.02018)
### Authors
Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong
### Background
图表示学习方法在金融应用中被广泛用于通过利用公司之间的关系来增强公司表示。然而，当前的方法面临着三个关键挑战：（1）关系信息的优势被下游任务设计的限制所掩盖；（2）专门为股票预测设计的图模型通常过于复杂且泛化能力差；（3）经验性的公司关系图构建缺乏不同图结构的有效比较方法。为解决这些限制，我们提出了一项长期股票预测任务，并开发了专为公司关系图设计的节点级图注意力网络（NGAT）。此外，我们通过实验证明现有的基于模型下游任务性能的图比较方法的局限性。来自两个数据集的实验结果一致证明了我们所提出任务和模型的有效性。该项目已在GitHub上公开，以促进再现性和未来研究。
### Innovation
我们提出了一个长期股票预测任务，并开发了专为公司关系图设计的节点级图注意力网络（NGAT）。通过实验验证了现有的基于模型下游任务性能的图比较方法的局限性，强调了NGAT的有效性，并且项目代码已公开，鼓励未来的研究和开发。
### Conclusion
实验结果显示，我们提出的任务和模型在两个数据集上均证明有效。项目代码已公开，以促进研究所需的再现性和开放性。
## 534. `cs.LG` - 预算中的推理：大规模语言模型适应性和可控性测试时计算综述 [PDF](https://arxiv.org/pdf/2507.02076), [HTML](https://arxiv.org/abs/2507.02076)
### Authors
Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates
### Background
大规模语言模型（LLMs）已迅速发展成为能够解决各种任务的通用代理。然而，当前模型在推理方面仍不够高效：它们在推理时总是使用固定的计算资源，无论任务难度如何，这导致简单问题过度计算，而复杂问题则计算不足。本文综述了提高LLM推理计算效率的测试时间计算（TTC）策略，探讨了适应性和可控性方法在不同计算预算下的应用效果，并与其他有关高效推理的综述进行了对比，分析了推理性能与token使用之间的关键权衡关系。
### Innovation
本文引入了一种两层分类法，区分了L1可控性和L2自适应性，前者在固定计算预算下进行操作，后者根据输入难度或模型置信度动态调整推理。本文还对领先的专有LLMs进行了基准测试，强调了TTC方法的实际控制、适应性与可扩展性。另外，本文探讨了混合思考模型等新兴趋势，并指出了未来提高LLMs计算效率、鲁棒性和灵活性的关键挑战。
### Conclusion
本文综述了现有的测试时间计算策略，强调了适应性和可控性在使LLMs更加高效、鲁棒和响应用户约束方面的重要性，并指出了未来研究的关键挑战。
## 535. `cs.LG` - 人工智能能否解决区块链预言机问题？破解挑战与可能性 [PDF](https://arxiv.org/pdf/2507.02125), [HTML](https://arxiv.org/abs/2507.02125)
### Authors
Giulio Caldarelli
### Background
区块链预言机问题是向去中心化系统注入可靠的外部数据所面临的挑战，仍然是信任最小化应用开发中的基础限制。尽管近年来出现了一系列架构、加密和经济策略来应对这一问题，但还没有彻底解决区块链如何获取外部世界知识的根本问题。本文通过学术文献和实际应用的结合，探讨了人工智能（AI）技术在解决预言机问题中的作用，如异常检测、基于语言的事实提取、动态声誉建模和对抗性抵御能力，这些技术可以提升预言机系统的数据质量、信息来源选择和系统韧性。然而，AI并不能消除对无法验证的链外输入的依赖。因此，研究支持AI应被看作是更大预言机设计中推理和过滤的补充层，而非信任假设的替代品。
### Innovation
提出结合AI技术如异常检测、基于语言的事实提取、动态声誉模型和对抗性抵御能力来提高预言机系统的数据质量、信息来源选择和系统韧性。强调AI作为预言机设计中推理和过滤的补充层而非替代品的角色。
### Conclusion
尽管AI技术可以提升预言机系统的水平，但不能完全解决预言机问题。AI应当作为预言机设计的一部分，而不能替代对信任的基本假设。
## 536. `cs.LG` - 分析和改进语音合成中的说话者相似性评估 [PDF](https://arxiv.org/pdf/2507.02176), [HTML](https://arxiv.org/abs/2507.02176)
### Authors
Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi
### Background
身份建模极具挑战性，因为语音具有多面性。在生成性语音系统中，身份通常通过自动说话者验证（ASV）嵌入进行评估，这些嵌入是为了区分而设计的，而不是为了刻画身份特征。本研究旨在探索这些表示中捕捉到的语音哪些方面。研究发现，广泛使用的ASV嵌入主要集中在音色和音高范围等静态特征上，而忽略了如节奏等动态元素。此外，研究还识别出影响说话者相似度测量的混淆因素，并建议了缓解策略。
### Innovation
本研究提出了U3D，这是一种评估说话者动态节奏模式的度量标准。这项工作在持续探索语音克隆系统中说话者身份一致性评估的挑战方面做出了贡献。
### Conclusion
公开发布了该研究的代码，以进一步改进和验证这些新的评估方法。
## 537. `cs.LG` - 一种基于高斯过程模型的鲁棒自适应MPC公式 [PDF](https://arxiv.org/pdf/2507.02098), [HTML](https://arxiv.org/abs/2507.02098)
### Authors
Mathieu Dubied,Amon Lahr,Melanie N. Zeilinger,Johannes Köhler
### Background
本文提出了一个鲁棒且自适应的模型预测控制（MPC）框架，该框架用于受有界干扰和未建模非线性影响的不确定非线性系统。基于噪声测量（包括系统运行期间收集的数据），使用高斯过程（GPs）学习不确定动力学。为了确保鲁棒性，通过引入收缩度量推导出鲁棒预测，并将其融入MPC公式的设计中。该设计确保了递归可行性和鲁棒约束满足，并且有很大概率收敛到参考状态。此外，还提供了一个数值示例，展示在存在难以建模的地效影响时，通过提出的鲁棒预测方法和在线学习能达到显著改进的效果，从而验证了该方法的有效性。
### Innovation
本文的主要创新在于，通过使用高斯过程（GP）模型进行模式识别，并利用收缩度量推导出鲁棒预测，将其纳入MPC的框架设计之中，以满足递归可行性和鲁棒约束满足的要求，最终实现系统的高概率收敛到参考状态。这种方法特别适用于存在难以建模的干扰和非线性系统的背景下，提供了一种有效的控制策略。
### Conclusion
本文提出的方法在具有难以建模的地面效应的平面旋翼无人机中得到了验证，表明通过运用鲁棒预测和在线学习可以显著提高系统的性能。
## 538. `cs.LG` - 在开放银行环境中预测和解释客户数据共享 [PDF](https://arxiv.org/pdf/2507.01987), [HTML](https://arxiv.org/abs/2507.01987)
### Authors
João B. G. de Brito,Rodrigo Heldt,Cleo S. Silveira,Matthias Bogaert,Guilherme B. Bucco,Fernando B. Luce,João L. Becker,Filipe J. Zabala,Michel J. Anzanello
### Background
开放银行的兴起对金融数据管理产生了重大影响，改变了金融机构的市场动态和营销策略。这增加了竞争，机构在管理数据流入以改进产品和服务的同时，需要限制可能帮助竞争对手的数据流出。因此，本研究提供了一个框架来预测客户通过开放银行分享数据的倾向，并通过解释模型分析（EMA）来解读该行为。使用一家大型巴西金融机构的数据，结合ADASYN和NEARMISS技术的混合数据平衡策略被用来处理数据共享频率低的问题，从而提升XGBoost模型的训练效果。这些模型在数据流入和流出的预测上均达到了91%以上的准确性。通过对Shapley加权解释（SHAP）方法和分类回归树（CART）技术的结合使用，揭示了影响客户决策的关键特征，这些关键特征包括移动渠道的交易和购买数量、交互情况以及与信用相关的特征，尤其是全国银行业系统内的信用卡使用情况。这些结果突显了移动参与和信用在推动客户数据共享行为中的关键作用，为金融机构提供了提升竞争力和创新的战略见解，以应对开放银行环境。
### Innovation
引入了一个预测客户通过开放银行分享数据倾向的框架，并通过解释模型分析（EMA）来解释这种行为。使用了结合ADASYN和NEARMISS技术的混合数据平衡策略以及XGBoost模型，实现了对客户数据共享的高准确性预测。结合Shapley加权解释（SHAP）方法和分类回归树（CART）技术，揭示了影响客户决策的关键特征。
### Conclusion
研究结果强调了移动参与和信用在驱动客户数据共享行为中的关键作用，为金融机构提供了提升竞争力和创新的战略见解，以适应开放银行环境。
## 539. `cs.LG` - 选择性特征重编码的联合优化量子卷积神经网络在图像分类中的应用 [PDF](https://arxiv.org/pdf/2507.02086), [HTML](https://arxiv.org/abs/2507.02086)
### Authors
Shaswata Mahernob Sarkar,Sheikh Iftekhar Ahmed,Jishnu Mahmud,Shaikh Anowarul Fattah,Gaurav Sharma
### Background
量子机器学习（QML）因其在Noisy Intermediate-Scale Quantum（NISQ）设备的优化而取得了显著进展。量子卷积神经网络（QCNN）融合了量子叠加和纠缠等原理，在图像分类任务中展示了对量子和经典数据分类的良好性能。因此，本研究在图像分类中探讨了QCNN，并提出了一种新的策略来提升特征处理能力及一种新的QCNN架构，以提高分类准确性。
### Innovation
研究提出了一种选择性特征重编码策略，该策略指导量子电路优先处理最有信息量的特征，从而有效地在希尔伯特空间的关键区域找到最优解空间。同时，研究设计了一种新的并行模式QCNN架构，该架构能够同时整合由主成分分析（PCA）和自编码器（Autoencoder）提取的特征，并在统一的训练方案下进行联合优化。这种联合优化过程让QCNN可以从互补的特征表示中获益，实现更好的模型参数互调。
### Conclusion
实验使用MNIST和Fashion MNIST数据集评估了这些方法。结果表明，选择性特征重编码方法显著提高了量子电路的特征处理能力和性能。同时，联合优化的并行QCNN模型始终优于单独的QCNN模型及传统的独立学习后融合的模型，证明了其更高的准确性和泛化能力。
## 540. `cs.LG` - cVLA: 向更高效的相机空间VLA迈进 [PDF](https://arxiv.org/pdf/2507.02190), [HTML](https://arxiv.org/abs/2507.02190)
### Authors
Max Argus,Jelena Bratulic,Houman Masnavi,Maxim Velikanov,Nick Heppert,Abhinav Valada,Thomas Brox
### Background
视觉-语言-行动（VLA）模型为解决复杂的机器人操作任务提供了有吸引力的框架，但是它们通常训练成本高昂。本文研究了如何利用视觉语言模型（VLMs）在二维图像上的出色性能，以直接推断机器人末端执行器的姿势，而无需生成低级控制，这使得模型的训练更加高效且机器人具有一般性。
### Innovation
提出了一种新颖的基于视觉语言模型的VLA方法，通过直接从图像坐标系预测机器人末端执行器的姿态轨迹点，从而减少了对低级控制的依赖。这种轻量级的设计结合了下一标记预测架构，有效地学习了有意义且可执行的机器人轨迹。此外，该模型进一步探索了利用深度图像、推理时的解码策略以及演示条件下的动作生成方法，展示了从模拟到现实的迁移能力。
### Conclusion
模型在模拟和现实数据的结合评估中表现出强大的效果，证明了其在真实机器人系统中的有效性。该研究展示了一种更高效、更通用的VLA设计方案。
## 541. `cs.LG` - 潜隐形思？深度循环Transformer的解码 [PDF](https://arxiv.org/pdf/2507.02199), [HTML](https://arxiv.org/abs/2507.02199)
### Authors
Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu
### Background
链式思考（CoT）推理使基于变换器的语言模型在复杂的数学和多步骤规划方面表现出色。然而，在标准的解码-only架构中，这些推理步骤以自然语言形式外部化，提高了可解释性但降低了效率。许多工作探索了循环架构，试图将这种推理在潜空间中内在化，支持潜在的CoT。Huginn-3.5B是这种架构的一个例子，它在推理时重用了层而不增加参数数量。本文的研究对象是这种模型在算术任务中的内部行为，使用多种探针技术，包括Logit Lens和Coda Lens进行分析。
### Innovation
本文研究了深度循环的变换器Huginn-3.5B在算术任务中的内部推理结构，并使用各种探针技术进行分析，发现了一些关于潜隐形思存在的有限证据，但揭示了循环模块之间在可解释性方面存在显著的不一致性，且加深循环深度的收益有限，未能超过显式外部化推理步骤的模型。研究结果为潜隐形思在循环变换器中的体现提供了新的见解。
### Conclusion
增加循环深度对潜隐形思的支持仅带来边际改进，这一发现表明，在深度循环的变换器中，自然语言的外部化推理步骤仍具有优势。探针技术显示，潜藏着的CoT在不同层和解码方法下难以捕获，这表明潜隐形思的内在化并不充分。
## 542. `cs.LG` - DecoRTL：使用LLM的RTL代码生成运行时解码框架 [PDF](https://arxiv.org/pdf/2507.02226), [HTML](https://arxiv.org/abs/2507.02226)
### Authors
Mohammad Akyash,Kimia Azar,Hadi Kamali
### Background
大型语言模型（LLMs）在自动化寄存器传输级（RTL）代码生成中有广泛的应用前景。然而，传统的LLM解码策略，最初是为自然语言设计的，无法满足RTL在结构和语义上的要求，导致生成的代码出现幻觉、重复或无效。先前的研究发现，LLMs在处理结构模糊或语义复杂的区域时信心较低，无法区分需要确定性（语法规则区域）和需要创造性探索变异性（设计关键区域）的区域。因此，需要一种新的解码策略来解决这些问题。
### Innovation
提出了DecoRTL，一种结合了自一致性抽样（促进正确性和多样性）和语法感知温度适应（通过语法和功能角色调整抽样温度，使语法规则性的区域保持低温，探索性区域上升温度）的新型运行时解码策略。DecoRTL在推理时完全进行操作，无需额外的模型微调。使用VerilogEval基准在多个开源LLM上进行评估，显著提高了语法有效性、功能正确性和输出多样性，同时执行开销几乎不可察觉。
### Conclusion
通过使用DecoRTL，研究者展示了在RTL代码生成中的显著改进，并且这种方法能够在多种开源LLM中实现，同时保证了性能的优异表现。
## 543. `cs.LG` - 混合最小二乘法用于从高度噪声数据中学习函数 [PDF](https://arxiv.org/pdf/2507.02215), [HTML](https://arxiv.org/abs/2507.02215)
### Authors
Ben Adcock,Bernhard Hientzsch,Akil Narayan,Yiming Xu
### Background
研究中，为了解决有效计算条件期望的需要，探讨了具有严重污染数据的最小二乘函数逼近问题。现有的方法在小噪声情况下效果很好，但在大噪声情况下则表现不佳。需要一种新的方法来解决这一问题。
### Innovation
提出了一种结合Christoffel采样和特定类型的最优实验设计的混合方法，旨在克服大噪声情况下现有方法的不足，增强了采样点生成和噪声平滑的最优性质，从而提高了计算效率和样本复杂度。该方法还可扩展到具有凸约束条件的情境下，保持相同的理论保证。对于以随机场的期望为靶函数的情况，该方法还利用了自适应随机子空间，并建立了自适应程序的逼近能力结果。
### Conclusion
理论发现通过数值研究在合成数据和计算金融中的更复杂的随机模拟问题上得到支持，该算法提高了计算效率和样本复杂度，同时保持了理论上的最优性。
## 544. `cs.LG` - SciGA: 用于学术论文设计视觉摘要的综合数据集 [PDF](https://arxiv.org/pdf/2507.02212), [HTML](https://arxiv.org/abs/2507.02212)
### Authors
Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi
### Background
图形摘要（GAs）在视觉传达科学论文的关键发现方面起着重要作用。尽管近期的研究已经开始越来越多地将视觉材料，如图1作为事实上的GAs，但它们对增强科学交流的潜力还未得到充分探索。此外，设计有效的GAs需要先进的可视化技能，这构成了广泛采用的障碍。针对这些挑战，本文介绍了一项名为SciGA-145k的大型数据集，该数据集包含约145,000篇科学论文和1,140,000张图表，旨在支持GA选择和推荐，并促进自动GA生成的研究。作为设计支持的初步步骤，我们定义了两个任务：1）Intra-GA推荐，确定给定论文中适合成为GA的图表；2）Inter-GA推荐，从其他论文检索GA以激发新GA的创作。我们为这些任务提供了基础模型。此外，我们提出了信心调整的top-1事实率（CAR）作为新颖推荐指标，该指标可提供对模型行为的粒度分析。CAR通过考虑论文中多个图表（不仅仅是显式标记的GA）可能也充当GA的情形，解决了传统排名指标的局限性。通过统一这些任务和指标，SciGA-145k奠定了改善视觉科学交流的基础，同时也促进了科学中的AI发展
### Innovation
SciGA-145k是一项大型数据集，旨在支持GA选择和推荐，并促进自动GA生成的研究。该数据集包含约145,000篇科学论文和1,140,000张图表。我们定义了两种任务：Intra-GA推荐和Inter-GA推荐，提供了合理的基础模型，并提出了一种新颖的推荐指标——CAR，解决了传统排名指标的局限性。
### Conclusion
通过统一任务和指标，SciGA-145k建立了推动视觉科学交流和促进科学中AI发展的基础。
## 545. `cs.LG` - 矩阵完成中的迁移学习 [PDF](https://arxiv.org/pdf/2507.02248), [HTML](https://arxiv.org/abs/2507.02248)
### Authors
Dali Liu,Haolei Weng
### Background
本文探索在矩阵完成的设置下知识转移的方法，旨在通过可用的辅助数据增强低秩目标矩阵的估计。背景在于利用先验信息选择有利的源数据集，研究其收敛速度并证明其实现最小最大最优性。通过这种方法，在源矩阵足够接近目标矩阵时，超越仅使用单个目标数据的传统方法。特别地，利用了文献引用中介绍的先进的尖锐集中不等式来消除收敛速度中的对数因子，这对于证明最小最大最优性至关重要。当不知道源数据集的相关性时，发展了一种有效的方法来识别有用的数据源，并建立了其选择一致性。通过仿真和实际数据分析来支持所提出方法的有效性。
### Innovation
利用先进的尖锐集中不等式消除了收敛速度中的对数因子；发展了有效检测有用数据源的方法，并建立了选择一致性。证明了最小最大最优性，有效增强了低秩目标矩阵的估计，并在未知源数据集相关性的条件下仍然保持了方法的有效性。
### Conclusion
本文通过提出迁移学习程序和利用先进的不等式，以及针对性地检测有效数据源，显著提高了在矩阵完成中低秩目标矩阵的估计精度。这些方法不仅在数据源已知时表现出优越性，即使在数据源相关性未知的情况下也能保持良好的选择一致性，并通过实验证实了方法的有效性。
## 546. `cs.LG` - 解析湍流等离子体动力学：混合算子-扩散框架 [PDF](https://arxiv.org/pdf/2507.02106), [HTML](https://arxiv.org/abs/2507.02106)
### Authors
Semih Kacmaz,E. A. Huerta,Roland Haas
### Background
该研究提出了一种结合物理信息神经算子 (PINO) 和基于分数的生成扩散模型的混合机器学习框架，用于模拟二维、不可压缩、有阻尼的MHD湍流的全程时空演化，覆盖广泛的雷诺数（Re）。传统的确定性代理模型无法在这些参数范围内进行准确模拟，因此需要一种新的混合框架来实现这一点。
### Innovation
该框架利用了PINO在方程约束下的泛化能力，预测了低频、有组织的动力学，而条件性扩散模型通过随机校正高频残差，实现了对完全发展湍流的准确建模。研究通过对不同Re值（Re = {100, 250, 500, 750, 1000, 3000, 10000}）的高保真模拟进行训练，使得代理模型在以前不可访问的参数范围内达到了最先进的精度。特别是在Re = 1000和3000时，模型准确重建了速度场和磁场的完整频谱能量分布，捕捉了非高斯统计特性、间歇结构和跨场相关性。在极端湍流水平（Re = 10000）时，该模型是首个能够恢复磁场高尾数特征演化、保持大尺度形态并提供统计意义上预测的代理模型。
### Conclusion
该研究提出的方法在模拟广泛雷诺数范围内的MHD湍流方面取得了显著进展，特别是对于极端湍流情况下的磁场特征演化问题，展示了其在精准预测和建模中的强大能力。
## 547. `cs.LG` - 对结构无感知估计而言，噪声的影响有多大：非高斯噪声的影响 [PDF](https://arxiv.org/pdf/2507.02275), [HTML](https://arxiv.org/abs/2507.02275)
### Authors
Jikai Jin,Lester Mackey,Vasilis Syrgkanis
### Background
结构无感知因果推断研究了在使用黑盒机器学习方法估算准函数（如混杂变量对治疗和结果的影响）时，如何准确估计治疗效应。本文发现，估计效果与其治疗噪声的分布有出乎意料的关系。研究以部分线性模型为背景，探讨了不同噪声分布下双机器学习（DML）估计的有效性，并提出了新的高阶鲁棒估计方法，这些方法在处理噪声误差时更为鲁棒，不依赖于结构信息。同时，该文还为二分类治疗情况下部分线性模型提供了新的最小最大保证。最后，通过合成需求估计实验验证了高阶鲁棒估计的实际益处。
### Innovation
研究表明，双机器学习（DML）对于高斯噪声是最佳的，但在非高斯独立噪声情况下，提出了新的鲁棒性更强的估计方法，即ACE方法，这些方法可以实现对噪声误差的高阶不敏感，尤其是当更高阶的治疗累积量不为零时。此外，还提出了二分类治疗情况下部分线性模型的最小最大保证，并通过合成实验验证了这些新方法的有效性。
### Conclusion
对于具有非零高阶治疗累积量的非高斯独立噪声分布，提出的方法比双机器学习方法更有效。这些结论为处理具有复杂噪声结构的实际数据提供了新的工具和方法。
## 548. `cs.LG` - Listwise Preference Alignment Optimization for Tail Item Recommendation [PDF](https://arxiv.org/pdf/2507.02255), [HTML](https://arxiv.org/abs/2507.02255)
### Authors
Zihao Li,Chao Yang,Tong Zhang,Yakun Chen,Xianzhi Wang,Guandong Xu,Daoyi Dong
### Background
偏好对齐在大型语言模型（LLMs）上取得了更显著的成功，吸引了推荐研究领域的广泛关注。现有的推荐偏好对齐方法要么需要明确的奖励建模，要么只支持成对偏好比较。这两种方法分别增加了大量的计算成本和降低了对负样本的训练效率。此外，现有研究尚未探索对于尾部项目推荐的偏好对齐解决方案。这导致了现有研究在处理尾部项目推荐时存在效率和效果上的局限性。因此，研究如何提高尾部项目推荐效率的需求非常迫切。
### Innovation
作者提出了LPO4Rec方法，扩展了Bradley-Terry模型的应用范围，从成对比较扩展到列表比较，以提高模型训练效率。具体来说，该方法通过推导封闭形式的最优策略，能够在无需明确奖励建模的情况下实现更高效和有效的训练。此外，作者还提出了一种自适应的负样本采样和重新加权策略，以在优化过程中优先处理尾部项目，从而提高尾部项目推荐的效果。理论证明显示，最大化列表偏好优化（LPO）损失等价于最大化最优奖励的上界。实验结果显示，作者的方法在三个公开数据集上显著优于10种基线方法，不仅在尾部项目推荐上达到了高达50%的性能提升，还减少了17.9%的GPU内存使用量，这相比直接偏好优化（DPO）方法更为有效。
### Conclusion
作者提出的LPO4Rec方法在尾部项目推荐中表现出色，不仅提高了模型训练的效率，还在实际应用中实现了更好的性能。
## 549. `cs.LG` - 基于自监督RNN的生物启发式机器人轨迹规划 [PDF](https://arxiv.org/pdf/2507.02171), [HTML](https://arxiv.org/abs/2507.02171)
### Authors
Miroslav Cibula,Kristína Malinovská,Matthias Kerzel
### Background
机器人轨迹规划是指生成一系列关节配置，将机器人或其操作器从初始状态引导到所需的最终状态，以完成操作任务，同时考虑到机器人运动学和环境的约束。通常，这通过基于采样的规划者实现，计算成本较高。最近的研究表明，轨迹规划也可以通过监督序列学习的轨迹实现，这通常只需要通过神经架构的单次或固定次数的遍历，从而保证了计算时间的限制。然而，此类完全监督的方法仅进行模仿学习，它们不基于轨迹能否成功达到目标来学习，而是尝试重现观察到的轨迹。本研究基于此，提出了一个基于递归结构的认知启发式自监督学习方案，以构建轨迹模型，评估该方法在机械臂的运动学规划任务上的可行性，表明该模型仅使用给定的正向和逆向运动学模型对就能够学习生成轨迹，从而表明该新型方法可能有助于更复杂操作任务的规划，需要采用自适应解决方案。
### Innovation
提出了一个基于递归结构的认知启发式自监督学习方案，以构建轨迹模型，这种方法相比于传统的模仿学习方法，能够基于轨迹能否成功达到目标进行学习，而不是单纯重现观察到的轨迹。此外，该方法使用了给定的正向和逆向运动学模型对来学习，降低了对大量人工标注数据的依赖。这种方法能够在更短时间内实现高效率的轨迹规划，且能够处理更加复杂、需要自适应操作的任务。
### Conclusion
实验结果显示，该模型能够仅使用给定的正向和逆向运动学模型对来学习生成轨迹，表明该自监督方法具有在复杂操作任务中提高自主规划能力的潜力。该研究为机器人操作规划提供了一种新颖的方法，该方法可以在计算资源有限的情况下实现高效的轨迹生成，为机器人操作技术的发展提供了新的思路。
## 550. `cs.LG` - 音乐推荐中的内容过滤方法：综述 [PDF](https://arxiv.org/pdf/2507.02282), [HTML](https://arxiv.org/abs/2507.02282)
### Authors
Terence Zeng,Abhishek K. Umrawal
### Background
音乐流媒体平台上的推荐系统已成为关键组成部分，影响着用户发现和参与歌曲的方式。常见的推荐方法之一是协同过滤，通过用户相似的聆听模式来推荐内容。然而，这种方法在用户互动稀少的领域，如音乐等，效果较差。鉴于音乐流媒体服务中用户的大多数歌曲是他们从未听过的这一现象，如何有效应对数据稀疏性带来的挑战一直是研究热点，本文即是对这些挑战的现状及内容过滤方法的综述研究。研究重点是内容过滤如何缓解协同过滤方法中的固有偏差问题，并探讨了歌曲分类的各种方法，包括情感分析、大型语言模型（LLMs）分析和音频信号处理技术，以及不同分析方法之间的潜在冲突及其解决路径等问题。
### Innovation
该论文创新性地分析了音乐推荐系统中内容过滤方法的应用，特别探讨了如何利用大型语言模型（LLMs）与音频信号处理技术进行歌曲分类，并提出了解决不同类型分析技术之间潜在冲突的方法。研究还强调了内容过滤作为缓解协同过滤偏见的一种手段的作用。
### Conclusion
本文综述了音乐推荐系统中的内容过滤方法现状，特别是在处理数据稀疏性问题方面。研究发现，通过情感分析和音频信号处理技术对歌曲进行分类是可行的，未来可以通过整合不同方法并解决它们之间的冲突来进一步提高音乐推荐系统的有效性。
## 551. `cs.LG` - DoMIX: 一个在微调中利用领域知识的有效框架 [PDF](https://arxiv.org/pdf/2507.02302), [HTML](https://arxiv.org/abs/2507.02302)
### Authors
Dohoon Kim,Donghun Kang,Taesup Moon
### Background
域自适应预训练（DAP）方法因其在微调预训练模型中的有效性而逐渐受到关注。在此基础上，研究者们尝试开发连续的DAP方法，使预训练模型能够逐步整合不同的领域数据集。然而，现有的连续DAP方法存在一些局限性：（1）在训练过程中耗时和GPU内存占用较高；（2）对增量数据顺序敏感；（3）提供一个适用于所有终级任务的一般化模型，这与DAP的本质相悖。
### Innovation
本文提出了一种名为DoMIX的新颖方法，通过利用LoRA模块，一种代表性的参数高效微调（PEFT）方法，解决了这些挑战。该方法实现了一种高效且并行的域自适应预训练方法，对领域顺序具有鲁棒性，并有效利用积累的知识为特定任务提供定制的预训练模型。此外，该方法还可以扩展到标准大语言模型（LLM）微调场景中，以进一步优化算法匹配对应的场景。
### Conclusion
本研究提出了一种新的基于LoRA模块的DoMIX方法，通过并行、有效的域自适应预训练和利用累积知识为具体任务提供适应性预训练模型，解决现有的连续DAP方法中的计算成本高、对数据顺序敏感以及提供通用模型的局限性。该方法不仅适用于DAP设置，还可在标准的LLM微调中使用。
## 552. `cs.LG` - MemAgent：基于多会话RL记忆代理重塑长上下文LLM [PDF](https://arxiv.org/pdf/2507.02259), [HTML](https://arxiv.org/abs/2507.02259)
### Authors
Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou
### Background
尽管通过长度外推、高效注意力和记忆模块等改进，能够处理无限长文档且在性能衰减最小的情况下以线性复杂度进行外推仍然是长文本处理领域的最终挑战。已有工作主要侧重于通过外推或模块优化来改进长文本处理效率，但直接从任务出发进行端到端优化并引入新型代理工作流程尚不多见。为此，本文直接针对长文本任务进行优化，并提出了一种名为MemAgent的新颖代理工作流程，该流程能够分段读取文本并使用覆盖策略更新记忆。同时，通过扩展DAPO算法来通过独立上下文多对话生成促进训练。
### Innovation
本文提出的MemAgent通过直接优化长文本任务并在端到端的方式下引入新的代理工作流程，提出了一个能够分段读取文本并使用覆盖策略更新记忆的新颖方法。该方法通过扩展DAPO算法来通过独立上下文多对话生成促进训练，实现在大规模文本任务上的优秀长上下文处理能力。实验结果表明，MemAgent能够从8K上下文训练到3.5M QA任务，性能损失低于5%，并在512K RULER测试中达到95%以上的性能。
### Conclusion
MemAgent展示了在长上下文处理任务上的卓越能力，能够在大规模文本任务中进行有效的外推，性能损失较小，并成功应用于RULER测试，结果令人满意。
## 553. `cs.LG` - 基于语言引导和表示对齐的提示解缠对于领域泛化的研究 [PDF](https://arxiv.org/pdf/2507.02288), [HTML](https://arxiv.org/abs/2507.02288)
### Authors
De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao
### Background
领域泛化（DG）旨在构建一种通用模型，使其在未见的目标领域也能有效运行。近期，预训练视觉基础模型（VFMs），如CLIP，在提高深度学习模型的泛化能力方面展现出巨大潜力。尽管对基于VFMs的领域提示调优越来越受到关注，但设计能够跨多种领域分离不变特征的有效提示仍然是一项关键挑战。
### Innovation
提出了一种基于视觉基础模型（VFM）可控且灵活的语言提示的新框架。首先通过大型语言模型（LLM）自动生成文本提示，然后利用解纠缠的文本特征学习领域不变的视觉表征。此外，通过引入最糟糕的具体表示对齐（WERA），提出了一种新的方法，通过结合抽象提示和样式化图像增强来增强源域的多样性，同时通过对齐约束保证视觉表示在原始分布和增强分布之间的一致性。这种方法在主要的DG数据集（包括PACS，VLCS，OfficeHome，DomainNet和TerraInc）上取得了优于最先进的DG方法的性能。
### Conclusion
提出的基于语言引导和表示对齐的方法在主要的领域泛化数据集上表现优于最先进的方法。
## 554. `cs.LG` - 稀疏高斯过程：结构化近似和重新审视Power-EP [PDF](https://arxiv.org/pdf/2507.02377), [HTML](https://arxiv.org/abs/2507.02377)
### Authors
Thang D. Bui,Michalis K. Titsias
### Background
基于诱导点的稀疏高斯过程（GP）已成为扩展GP模型的标准工具。近年来的研究表明，通过引入对诱导点条件后验密度进行缩放的对角矩阵，可以改进这些方法。本文进一步扩展了此方法，采用块对角结构进行缩放矩阵，从而证明这可以锁定变分下界的变体。此外，文章还回顾了基于Power Expectation Propagation（PEP）的稀疏GP的统一框架，并展示了这种方法如何利用和从新的结构化近似后验中受益。
### Innovation
1. 提出了一种具有块对角结构的缩放矩阵，这有助于锁定变分下界，从而改进现有的基于对角矩阵的缩放方法。2. 重新审视了基于PEP的稀疏GP统一框架，并展示了利用结构化后验带来的新优势，这些结构化后验来自块对角缩放矩阵。3. 证明结构化近似和PEP框架的新颖性，在计算成本基本保持不变的情况下，其性能不低于现有的对角近似方法，甚至有所提升。4. 提出了PEP框架的新颖构建，证明了它在不同功率超参数设置下都能提供有竞争力的性能，为从业者提供了标准变分方法的灵活替代方案。
### Conclusion
本文通过广泛的回归实验表明，提出的块对角近似在保持较低计算成本的同时，性能可以与甚至优于现有的对角近似。此外，结合PEP框架的新颖和结构化后验框架，为各种功率超参数设置提供了有竞争力的性能，并为研究稀疏GP的从业者提供了更灵活的选项。
## 555. `cs.LG` - NLP4Neuro: 从序列到序列学习在神经群体解码中的应用 [PDF](https://arxiv.org/pdf/2507.02264), [HTML](https://arxiv.org/abs/2507.02264)
### Authors
Jacob J. Morra,Kaitlyn E. Fouke,Kexin Hang,Zichen He,Owen Traubert,Timothy W. Dunn,Eva A. Naumann
### Background
了解动物行为是如何从神经活动产生的，是神经科学的基本目标。然而，随着行为计算在数千个脑部神经元网络中的展开，这为研究大型、紧密连接的哺乳动物大脑在行为中的神经作用和计算机制带来了挑战。现代大型语言模型（LLMs）背后的变换器已经成为神经解码的小神经群体的强大工具。LLMs得益于大量预训练数据，其序列到序列的学习已被证明能够应用于新任务和数据模态，这可能也对大型脑部活动记录中的神经解码有好处。本研究通过NLP4Neuro系统地评估了现成的LLMs，用于从全脑神经群体中解码行为。我们使用NLP4Neuro对暴露在视运动刺激下的斑马鱼幼体的同步钙成像和行为记录进行了测试。研究表明，当LLMs使用从文本自然语言数据中学习的预训练权重时，它们在神经解码中的表现会更好。同时发现，近年来的混合专家LLM，DeepSeek Coder-7b，显著提高了行为解码准确性，能够预测长时间内的尾部运动，并提供了解剖学上一致、高度可解释的神经元重要性读出。
### Innovation
NLP4Neuro展示了LLMs在全脑神经环路解析中的高能力，特别是通过使用预训练文本自然语言数据的LLMs来解码行为。它还发现了一种新的混合专家LLM（DeepSeek Coder-7b）在解码行为和神经元重要性方面具有显著优势，能够预测尾部运动并提供有解释性的读数。
### Conclusion
NLP4Neuro证明了基于序列到序列学习的LLMs能够有效解码全脑神经群体的行为。此外，某些LLMs，如DeepSeek Coder-7b，通过整合预训练文本数据的专家模型组件，实现了在行为解码中的显著性能提升，这表明这种方法在未来全脑神经解码中的潜力巨大。
## 556. `cs.LG` - 跨特定领域数据集评估阿甘自动语音识别模型：性能、可扩展性和适应性比较评估 [PDF](https://arxiv.org/pdf/2507.02407), [HTML](https://arxiv.org/abs/2507.02407)
### Authors
Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame
### Background
大多数现有的自动语音识别(ASR)研究使用领域特定的数据集来评估模型性能，但很少评估模型在不同应用场景中的泛化能力。本文通过利用四种阿甘口述语料库对基于变压器架构的七个阿甘ASR模型进行基准测试，确定了这些模型在不同领域中的性能。
### Innovation
本文填补了现有研究的空白，首次在跨多样化语音场景的情况下对阿甘ASR模型进行评估，并识别了Whisper和Wav2Vec2架构在错误行为上的不同表现。此外，本文强调了在低资源语言(LRL)应用中选择模型架构时应考虑可读性和透明度之间的权衡。
### Conclusion
研究结果表明，ASR模型在特定领域中的性能较好，但在不同领域中的表现差异明显，并提出了需要针对阿甘和低资源语言开发定向领域适应技术、可自适应路由策略和多语言训练框架等见解。
## 557. `cs.LG` - TABNet: 基于三元增强自我恢复框架及边界感知伪标签的医学影像分割 [PDF](https://arxiv.org/pdf/2507.02399), [HTML](https://arxiv.org/abs/2507.02399)
### Authors
Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang
### Background
医学影像分割是临床应用中的核心任务，但获取大规模、完全注释的医学影像数据集既耗时又昂贵。因为标记稀疏的注释作为稀疏标记的形式提供了一种替代方案，但它本身稀疏的特性限制了对目标区域特征的学习，并缺乏足够的边界监督，这对训练分割网络提出了挑战。现有的方法对于训练依赖于稀疏标注的分割网络效果欠佳，因此需要一个更有效的策略来应对这一挑战。
### Innovation
本文提出了TAB Net，一种新颖的弱监督医学影像分割框架，包含两个关键组成部分：三元增强自我恢复 (TAS) 模块和边界感知伪标签监督 (BAP) 模块。TAS 模块通过三种互补的增强策略（强度变换、剪切块和拼图增强）增强了特征学习，并通过引导网络从多种增强输入中恢复完整的掩码来促进在稀疏监督下的深层语义理解。BAP 模块通过将双支路预测融合成一个带有损失加权的伪标签，并引入边界感知损失来进行细粒度轮廓细化，提高了伪监督的准确性和边界建模的精度。实验结果表明，TAB Net 显着优于现有基于注释的弱监督分割方法，并且其性能与全监督方法相当。
### Conclusion
TAB Net 在两个公开数据集 ACDC 和 MSCMR seg 上的实验评估显示，该方法显著优于最新的基于注释的弱监督分割方法，并且其性能可与完全监督的方法媲美。这表明了 TAB Net 在医学影像分割领域中的有效性。
## 558. `cs.LG` - 使用一次采样骨架图的路径规划 [PDF](https://arxiv.org/pdf/2507.02328), [HTML](https://arxiv.org/abs/2507.02328)
### Authors
Gabriel O. Flores-Aquino,Octavio Gutierrez-Frias,Juan Irving Vasquez
### Background
路径规划算法通常旨在计算一条无碰撞路径，许多研究工作集中在寻找最短路径。但是，对于某些应用来说，一个更合适的策略是平衡响应时间、路径的安全性和路径长度。在这种背景下，骨架图是一种在图基方案中非常有用的方法，它提供了自由配置空间的内在表示。然而，骨架化算法非常耗资源，主要面向图像处理任务。因此，该论文提出了一种高效的方法用于找到在可接受处理时间内的安全路径。这种方法利用了基于U-Net架构的Deep Denoising Auto-Encoder（DDAE），称为SkelUnet，来计算导航地图的骨架化版本，通过一次采样过程（OSS）快速探索整个工作空间，而非迭代或概率采样过程。SkelUnet在12,500个二维迷宫地图数据集上进行了训练与测试。该论文评估了一种基于SkelUnet的无人驾驶航空器（UAV）的运动规划方法，使用了250个未见过的地图，并通过多种导航指标评估了所规划路径的可导航性。实验结果表明，使用SkelUnet构建路网具有显著优势，如联接自由工作空间的所有区域，提供更安全的路径，并减少处理时间。这些特点使该方法特别适用于结构化环境中的移动服务机器人。
### Innovation
该论文提出了一种利用基于U-Net架构的Deep Denoising Auto-Encoder（DDAE）构建了骨架图的方法，称为SkelUnet。SkelUnet通过一次采样过程（One-shot Sampling，OSS）快速生成骨架图，高效地用于路径规划。这种方法应用于12,500个二维迷宫地图，并通过评估250个新地图来验证其在无人驾驶航空器（UAV）运动规划中的有效性。
### Conclusion
使用SkelUnet构建骨架图显著提高了路径规划的效率与安全性，能够连接所有自由空间区域，减少处理时间，特别适用于移动服务机器人在结构化环境中的应用。
## 559. `cs.LG` - 在FPGA的可编程逻辑中加速葡萄识别的人工神经网络 [PDF](https://arxiv.org/pdf/2507.02443), [HTML](https://arxiv.org/abs/2507.02443)
### Authors
Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias
### Background
机器人在搬运过程中通常会减慢速度以检测物体，同时，为了跟踪检测算法的速度，机器人的相机配置为低帧率。这在执行任务和探索时会受到限制，导致增加任务执行时间。AMD开发的Vitis-AI框架可以将检测算法部署到FPGAs中，然而，这项工具并没有充分利用FPGAs的片上逻辑（PL）。
### Innovation
本文利用FINN架构在FPGAs的PL中部署了三个ANN模型：MobileNet v1（四比特量化）、CNV（两比特量化）和CNV（一比特量化BNN）。这些模型在RG2C数据集上进行了训练。MobileNet v1模型表现更佳，成功率达到98%，推理速度达到6611 FPS。本文表明可以在FPGAs上加速ANN以提高其在注意力机制中的实用性。
### Conclusion
本文验证了可以在FPGAs的可编程逻辑中加速人工神经网络，并使其适用于注意力机制的方法。
## 560. `cs.LG` - 基于后验过渡建模的无监督扩散建言语音增强 [PDF](https://arxiv.org/pdf/2507.02391), [HTML](https://arxiv.org/abs/2507.02391)
### Authors
Mostafa Sadeghi(MULTISPEECH),Jean-Eudes Ayilo(MULTISPEECH),Romain Serizel(MULTISPEECH),Xavier Alameda-Pineda(ROBOTLEARN)
### Background
现有的无监督语音增强方法利用了噪声语音和纯净语音之间的关系，通过近似的噪声扰动似然分数来引导反向扩散过程，并结合未条件分数通过一个交易超参数。
### Innovation
本文提出了两种新的算法，直接建模扩散状态的条件反向转换分布。第一种方法将扩散先验与观测模型以合理的方式整合起来，消除了超参数调优的需要。第二种方法定义了一个噪声语音本身的扩散过程，提供了完全可计算和准确的似然分数。通过在WSJ0-QUT和VoiceBank-DEMAND数据集上的实验结果，该方法比监督和无监督基线都表现出更好的增强指标和更高的鲁棒性。
### Conclusion
通过后验过渡建模直接建模扩散状态，避免了噪声扰动似然分数的使用和超参数的调优，从而使语音增强系统更加鲁棒和有效。
## 561. `cs.LG` - 使用深度学习框架确定结构性裂缝 [PDF](https://arxiv.org/pdf/2507.02416), [HTML](https://arxiv.org/abs/2507.02416)
### Authors
Subhasis Dasgupta,Jaydip Sen,Tuhina Halder
### Background
结构裂缝检测对于公众安全至关重要，因为它有助于预防可能危及生命的潜在结构失败。由非专业人员手工检测可能导致速度慢、不一致性和人为错误，这可能会影响评估的可靠性。本文探讨了这些挑战，并提出了一种新型的深度学习架构，以提高结构裂缝检测的准确性与效率。各种残差U-Net模型的配置被用于研究，这些模型因其在捕捉细微细节方面的稳健性，被进一步融入集合模型中，其中包括卷积模块的元模型。这一独特组合旨在超出单一模型所能实现的预测效率。
### Innovation
本文研究了一种新型的深度学习架构，结合了残差U-Net模型和卷积模块的元模型，形成了一个独特的集合模型。实验结果表明，相比于传统的SegNet和传统的U-Net架构，残差U-Net模型在低分辨率图像上表现出色，而集合模型的性能优于单一模型，证明了其作为最有效模型的优势。评估标准包括Intersection over Union (IoU) 指标和DICE系数。集合模型获得了最高的评分，显示了更高的准确性。
### Conclusion
该研究提出了一种更可靠的自动化系统方案，应用于结构性缺陷监测任务，提升了结构裂缝检测的准确性和效率。
## 562. `cs.LG` - AI研究代理人在机器学习中的应用：在MLE-bench上的搜索、探索与泛化 [PDF](https://arxiv.org/pdf/2507.02554), [HTML](https://arxiv.org/abs/2507.02554)
### Authors
Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach
### Background
人工智能研究代理在加速科学进步方面显示出巨大潜力，能够自动化机器学习模型的设计、实现和训练。本文重点关注AI研究代理在MLE-bench上的性能改善，这是一个具有挑战性的基准，其中代理通过参与Kaggle竞赛解决实际的机器学习问题。根据代理在候选解空间中的搜索策略和迭代修改这些候选解的方法，可以正式化AI研究代理。
### Innovation
通过设计和系统地变化不同的操作集和搜索策略（贪婪法、蒙特卡洛树搜索、进化算法），研究证明了它们之间的相互作用对于实现高性能至关重要。最佳的搜索策略与操作集配合，使MLE-bench lite的最新结果得以提升，将获得Kaggle奖牌的成功率从39.6％提高到47.7％。这项研究强调了在推动自动化机器学习前进时共同考虑搜索策略、操作设计和评估方法的重要性。
### Conclusion
本文的贡献在于通过系统的操作集和搜索策略设计，展示了它们间的相互作用对于高性能的不可或缺性，并证明了一个最佳配对提高了既定基准的最好成绩。研究还强调了在自动化机器学习中同时考虑搜索策略、操作设计和评估方法的重要性。
## 563. `cs.LG` - 非城市环境中使用自监督学习进行野生动物目标再识别 [PDF](https://arxiv.org/pdf/2507.02403), [HTML](https://arxiv.org/abs/2507.02403)
### Authors
Mufhumudzi Muthivhi,Terence L. van Zyl
### Background
野生动物再识别旨在将同一物种在不同观察中的个体进行匹配。当前最先进的（SOTA）模型依赖于类标签来训练监督模型进行个体分类。这种对标注数据的依赖促使众多大型野生动物数据集的建立。这项研究探讨了在没有监督的情况下，使用自监督学习（SSL）进行野生动物再识别的可能性。通过使用相机捕获的数据中的时间图像对体，自动提取个体的两种不同视图，从而训练自监督模型从潜在无穷的视频数据流中学习。
### Innovation
研究提出了一种在缺少标注数据的情况下，通过自监督学习方法进行野生动物再识别的新思路。具体而言，该研究通过时间图像对自动提取个体的两种不同视图，并在开放世界和各种野生动物下游任务中评估了从大量未标注视频中学习到的特征表现，展示了自监督模型在数据稀缺情况下的鲁棒性和自监督特征的优越性，超过了基于监督学习的现有方法。
### Conclusion
实验结果表明，即使数据有限，自监督模型也表现得更为稳健。此外，在所有下游任务中，自监督特征优于监督学习。研究团队已经开源了用于实验的代码。
## 564. `cs.LG` - 印度保释判决-1200: 针对印度保释命令的多属性数据集 [PDF](https://arxiv.org/pdf/2507.02506), [HTML](https://arxiv.org/abs/2507.02506)
### Authors
Sneha Deshmukh,Prathmesh Kamble
### Background
在印度这样的区域内，法律自然语言处理（Legal NLP）仍然发展不足，原因是缺乏结构化的数据集。印度保释判决-1200旨在解决这一问题。该数据集包含了1200条印度法庭关于保释决定的判决，涵盖了20多个属性，包括保释结果、印度刑法（IPC）条款、犯罪类型和法律推理。这些属性能够支持多种法律NLP任务，如预测结果、摘要和公平性分析。该数据集是第一个专注于印度保释法治的公开可用数据集。
### Innovation
该研究引入了印度保释判决-1200，这是一个包含1200条印度法庭关于保释决定的判决的新基准数据集。该数据集的特点在于其覆盖广泛，包括20多个注释属性，标志着该领域的创新之举，特别是考虑到目前法律NLP数据的缺乏。数据集是通过一个经过提示工程的GPT-4o管线生成注释，并经过一致性验证。这使得印度保释判决-1200能够支持广泛的应用场景，包括但不限于结果预测、摘要生成和公平性分析。此外，该数据集是首个专注于印度保释法律的公开数据集，填补了这一领域的数据空白。
### Conclusion
印度保释判决-1200数据集极大地推动了法律自然语言处理领域的进步，特别是在提供有关印度保释法律的相关数据方面。这一资源的公开利用必将促进更多领域的研究，包括预测性分析、摘要生成和法律推理的公平性评估。
## 565. `cs.LG` - 重新审视基于(人类)标签变异的主动学习 [PDF](https://arxiv.org/pdf/2507.02593), [HTML](https://arxiv.org/abs/2507.02593)
### Authors
Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher
### Background
高质量的标注数据是应用监督学习的一个关键限制因素。虽然标签变异（LV）在自然语言处理中非常常见，但现有的标注框架通常仍然基于单一真实标签的假设，忽略了人类标签变异（HLV）作为一种信息信号的可能性。此外，主动学习（AL）作为优化有限标注预算的方法，通常依赖于简化假设，在承认HLV的情况下这些假设往往不符合实际情况。因此，本文重新审视了关于真实性和标签本质的基础假设，强调将观察到的LV分解为信号（如HLV）和噪声（如标注错误）的必要性。
### Innovation
本文提出了一个概念框架，以整合HLV整个主动学习循环，包括实例选择、标注者选择和标签表示。同时，讨论了大型语言模型（LLM）作为标注者的大规模集成。这些工作旨在为HLV感知的主动学习提供一个概念基础，更好地反映现实标注的复杂性，解决或忽视了AL和（H）LV社区之间的这些区别。
### Conclusion
本文分析了主动学习如何基于（人类）标签变异进行改进，提出了理解并利用HLV的新方法，旨在更好地处理现实世界的标注难题。
## 566. `cs.LG` - MC-INR：使用元学习和聚类隐神经表示高效编码多元科学模拟数据 [PDF](https://arxiv.org/pdf/2507.02494), [HTML](https://arxiv.org/abs/2507.02494)
### Authors
Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong
### Background
隐神经表示（INRs）广泛用于对数据进行连续函数编码，从而以较少的内存使用量可视化大规模多元科学模拟数据。然而，现有的基于INR的方法存在三大限制：(1)对复杂结构的表示不够灵活，(2)主要关注单变量数据，(3)依赖于结构化网格。因此，在处理复杂的实时数据集时，这些方法的性能会下降。
### Innovation
本文提出了一种新颖的基于神经网络的框架MC-INR，它能够处理无结构网格上的多元数据。MC-INR结合了元学习和聚类技术，以灵活地编码复杂结构。为了进一步提高性能，该框架引入了一种基于残差的动态再聚类机制，可以根据局部误差自适应地划分聚类。此外，提出了一种分支层，可以通过独立的分支同时利用多元数据。实验结果表明，MC-INR在科学数据编码任务上优于现有方法。
### Conclusion
MC-INR在科学数据编码任务中的性能优于现有方法，能够高效、灵活地编码复杂结构的多元科学模拟数据。
## 567. `cs.LG` - 缓解攻击数据稀缺：SCANIA在增强车内网络安全措施方面的经验 [PDF](https://arxiv.org/pdf/2507.02607), [HTML](https://arxiv.org/abs/2507.02607)
### Authors
Frida Sundfeldt,Bianca Widstam,Mahshid Helali Moghadam,Kuo-Yun Liang,Anders Vesterberg
### Background
随着连接车辆的数字化不断发展，随之而来的安全风险突显了实现车内网络安全措施的迫切需要，例如入侵检测与响应系统。不断发展的攻击场景进一步强调了需要能够检测不断演进、未知且复杂的威胁的自适应检测机制。有效的使用基于机器学习的技术可以帮助应对这一挑战，但实施各种攻击场景的测试车辆受到安全、成本和伦理等方面的限制，导致可用于模拟攻击场景的数据稀缺。这一限制促使需要高效和有效的方法来生成高质量的攻击数据代表。
### Innovation
本文提出了一个基于上下文的攻击数据生成器，能够生成各种类型的攻击数据输入和车载网络日志（例如，控制器区域网络（CAN）日志），包括拒绝服务（DoS）、模糊攻击、欺骗攻击、悬挂攻击和重演攻击。该生成器利用参数化攻击模型和CAN消息解码及攻击强度调整，配置高相似度的现实攻击场景，并促进变异性。我们通过入侵检测系统（IDS）案例研究评估了生成的攻击数据的实用性，其中开发并使用生成的数据对两种深度神经网络IDS模型进行了实证评估。此外，结果还表明，这种方法的效率和可扩展性以及IDS模型的性能结果证明了生成数据的一致性和有效性。我们还详细研究了影响数据真实度的因素，并对其应用提供了见解。
### Conclusion
本文提出了一种基于上下文的攻击数据生成器，能够在入侵检测系统（IDS）研究表明其生成的数据能够良好地反映真实世界攻击场景，并且有效地验证了其一致性和有效性。通过解决数据稀缺问题，该方法有助于提高车内网络安全措施的有效性。
## 568. `cs.LG` - 基于高级远程教育的自愿测验脱钩检测：可解释的机器学习方法 [PDF](https://arxiv.org/pdf/2507.02681), [HTML](https://arxiv.org/abs/2507.02681)
### Authors
Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin
### Background
学生在学业上的脱钩可能带来严重的长期后果，包括学分流失。对远程教育中的学生而言，这一点尤为重要。衡量远程教育中学生脱钩程度的一种方式是观察他们在不同在线课程中非强制性练习的参与度。本文检测了某基于远程的大学在四个学期中42门课程的非强制性测验中的学生脱钩情况。通过仔细识别从Moodle中提取的最有信息量的学生日志数据，我们训练并比较了八种机器学习算法，以获得最高的预测准确率。实验结果显示，准确率为91%，其中约85%的脱钩学生被正确检测出来。
### Innovation
本文开发了一种可解释的机器学习框架，通过SHAP方法使从业者更好地理解训练算法的决策过程。此外，该框架的高预测性能和可解释性为设计及时干预措施以减少在线学习中自愿任务的脱钩情况提供了思考。
### Conclusion
实验结果表明，在四个学期的远程教育中，非强制性测验中学生脱钩检测的平衡准确率为91%，其中约85%的脱钩学生被正确检测出来。该研究为在线学习中的自愿任务脱钩提供了高预测性准确度和可解释性的框架，并讨论了如何设计及时干预以最小化这种脱钩。
## 569. `cs.LG` - 前沿大语言模型中的早期隐写术能力迹象 [PDF](https://arxiv.org/pdf/2507.02737), [HTML](https://arxiv.org/abs/2507.02737)
### Authors
Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner
### Background
对大型语言模型（LLM）输出进行监测是减轻滥用和不一致风险的关键。然而，这些模型可能会通过隐写术的技术来逃避监测，即把隐藏信息编码到看似无害的生成中。本文研究了前沿的大语言模型在隐写术方面的能力，以更好地了解这种风险。研究集中在两种类型的隐写术：传递编码信息和进行编码推理。
### Innovation
本文评估了前沿大语言模型的隐写术能力，并首次发现了模型可以进行简单状态跟踪问题中的基本编码推理，这表明模型具有初步的隐写术能力。此外，研究还表明，模型可以在未监视的草稿纸上使用特定的编码方案进行隐写术，进一步增强了隐写术的能力。
### Conclusion
当前的大语言模型展示了初步的隐写术能力，但尚不足以绕过精心设计的监测系统。不过，这种能力在未来可能会有所改变。
## 570. `cs.LG` - De-AntiFake: 重思对抗 perturbations 对抗语音克隆攻击的有效性 [PDF](https://arxiv.org/pdf/2507.02606), [HTML](https://arxiv.org/abs/2507.02606)
### Authors
Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu
### Background
语音生成模型的快速发展引发了对语音克隆（VC）相关的隐私和安全问题的关注。最近的研究探索了通过引入对抗扰动来干扰未授权的语音克隆。然而，有决心的攻击者可以削弱这些保护性扰动，并成功执行语音克隆。本文在包含了扰动净化的现实威胁模型下，首次系统评估了这些保护性扰动的有效性。研究发现，现有的净化方法可以中和相当一部分的保护性扰动，但会导致语音克隆模型特征空间的失真，从而降低其性能。
### Innovation
本文提出了一种新颖的两阶段净化方法：首先净化被扰动的语音；然后使用音素指导进行调整以与干净语音分布对齐。实验结果表明，本文方法在削弱语音克隆防御方面优于最先进的净化方法。研究揭示了对抗扰动基础的语音克隆防御的局限性，并强调了需要开发更稳健的解决方案来减轻语音克隆带来的安全和隐私风险。
### Conclusion
本文的研究揭示了对抗扰动基础的语音克隆防御的局限性，并强调了需要开发更稳健的解决方案来减轻语音克隆带来的安全和隐私风险。
## 571. `cs.LG` - Bourbaki: 自动生成和目标导向的MDP在定理证明中的应用 [PDF](https://arxiv.org/pdf/2507.02726), [HTML](https://arxiv.org/abs/2507.02726)
### Authors
Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar
### Background
在自动化定理证明（ATP）的逻辑受限制环境下，大型语言模型（LLMs）的推理仍然是一个具有挑战性的任务，尤其是由于奖励稀疏以及证明规模庞大导致的问题。基准如PutnamBench包含了需要复杂多步推理的大学水平问题，这些问题进一步加剧了这种挑战。
### Innovation
我们提出了一个新颖的框架——自生成目标导向的MDP（sG-MDP），该框架使代理能够基于证明状态的变化生成并追求自己的子目标。利用类似于蒙特卡洛树搜索（MCTS）的算法来解决sG-MDP，我们的方法在模块化的Bourbaki（7B）系统中实现，该系统可以结合多个7B语言模型来进行子目标生成和策略合成。在PutnamBench上，Bourbaki（7B）解决了26个问题，达到了同类规模模型的新最先进的结果。
### Conclusion
Bourbaki通过利用自生成目标导向的MDP框架和模块化的Bourbaki（7B）系统，增强了自动化定理证明中的大规模语言模型的推理能力，实现了在Benchmarks上的显著成果。
## 572. `cs.LG` - 自引导深度非线性空间选择性滤波器在弱引导下高效提取移动说话人 [PDF](https://arxiv.org/pdf/2507.02791), [HTML](https://arxiv.org/abs/2507.02791)
### Authors
Jakob Kienegger,Alina Mannanova,Huajian Fang,Timo Gerkmann
### Background
近期关于深度非线性空间选择性滤波器的研究展示了在已知方向的静止说话人上具有出色增强性能的轻量级架构。然而，在动态场景中保持这种性能需要使用资源密集型的数据驱动跟踪算法来提供精确的空间引导，这依赖于目标说话人的初始方向。然而，这额外的计算开销在资源受限的场景，如实时语音增强，成为限制因素。
### Innovation
本文提出了一种利用低复杂度跟踪算法（粒子滤波器形式）的新策略，并通过引入时序反馈来提高粒子滤波器的建模能力不足。利用空间选择性滤波器增强的语音信号之间的自回归互操作关系，显著提高了跟踪的准确性和增强了性能。
### Conclusion
在合成数据集上的评估表明，两个算法之间的自回归互操作关系显著提高了跟踪精度，并且增强了表现。实录音频的主观测试进一步证实了该自引导管道相较于其他方法的优势。
## 573. `cs.LG` - RLHGNN: 基于强化学习驱动的异构图神经网络在业务流程中面向下一个活动预测 [PDF](https://arxiv.org/pdf/2507.02690), [HTML](https://arxiv.org/abs/2507.02690)
### Authors
Jiaxing Wang,Yifeng Yu,Jiahan Song,Bin Cao,Jing Fan,Ji Zhang
### Background
在服务导向架构如微服务环境、分布式企业系统和云原生平台中，优化业务流程的一项基本挑战是下一步活动预测，这能够实现前瞻性的资源分配和动态服务组合。尽管基于序列的方法广泛使用，但这些方法未能捕捉到并行执行和条件依赖引起的非序列关系。尽管图基的方法解决了结构保存问题，但是它们使用同质表示和静态结构，不管个体流程复杂性有何特点，模型策略一律相同。由于这些限制，本文提出了一种新的框架RLHGNN，该框架将事件日志转换为基于过程挖掘理论支持的三类异构过程图。该方法通过灵活组合这三类边来创建四种不同结构，以适应不同的过程复杂性，并使用强化学习转化为马尔科夫决策过程来自动确定每个特定进程实例的最佳图结构。RLHGNN采用关系特定的聚合策略的异构图卷积来有效预测下一个活动。这种自适应方法能够精确模拟服务交互中的序列和非序列关系。在六组实际数据集上的全面评估证明，与前沿方法相比，RLHGNN始终具有更优的表现。此外，它还保持着大约每预测1毫秒的推理延迟，提供了一个实用的实时业务流程监控解决方案。相关源代码可以在该网址找到。
### Innovation
提出了RLHGNN框架，将事件日志转换为基于过程挖掘理论的异构过程图，通过强化学习确定最佳图结构，采用关系特定的异构图卷积策略进行预测，能够精确模拟不同复杂性的流程。该方法解决了传统序列和图基方法的限制，提供了更有效的预测模型。
### Conclusion
RLHGNN在六组实际数据集上的评估结果表明，它在预测下一活动方面优于前沿方法，并且具有高效低延迟的特性，适用于实时业务流程监控应用。其提供的源代码已公开。
## 574. `cs.LG` - 基于全局上下文的线性注意力：一种用于视觉和物理的多极注意力机制 [PDF](https://arxiv.org/pdf/2507.02748), [HTML](https://arxiv.org/abs/2507.02748)
### Authors
Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen
### Background
Transformer 已成为从图像分类到物理模拟等多种任务的标准方法。尽管性能出色，但标准 Transformer 在输入长度上的时间复杂度和内存复杂度均为平方级，使得它们处理高分辨率输入时变得不实用。因此，已经提出了几种变体，最成功的变体依赖于分块、下采样或粗化技术，但这些方法通常会损失细粒度的细节。本文采用了一种不同的方法。受最先进的 $n$-体数值模拟技术的启发，将注意力视为网格点之间的相互作用问题。本文介绍了 Multipole Attention Neural Operator (MANO) 网络，它以基于距离的多尺度方式计算注意力，在每个注意力头中保持全局感受野，并在网格点数量方面实现线性时间复杂度和内存复杂度。在图像分类和 Darcy 流动的数据集上进行的实验证明，MANO 能够媲美当前最先进模型，如 Vision Transformer (ViT) 和 Swin Transformer，同时大幅度减少运行时间和峰值内存使用量。
### Innovation
提出了一种称为 Multipole Attention Neural Operator (MANO) 的新型注意力机制，该机制以基于距离的多尺度方式计算注意力，在每个注意力头中保持全局感受野，并实现线性时间复杂度和内存复杂度，适用于视觉和物理任务。此方法能够减少运行时间和峰值内存使用量，同时达成出色的效果。
### Conclusion
基于全局上下文的线性注意力方法，MANO，在图像分类和 Darcy 流动任务上展现了与当前最顶尖模型相当的性能，但在运行时间和峰值内存使用量方面大幅降低，证明了这种方法在各种任务上的潜力。
## 575. `cs.LG` - 通过扩散模型的展开与蒸馏学习几步后验采样器 [PDF](https://arxiv.org/pdf/2507.02686), [HTML](https://arxiv.org/abs/2507.02686)
### Authors
Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra
### Background
DMs（扩散模型）已成为贝叶斯计算成像中的强图像先验。为利用DMs，主要提出了两种策略：插即用方法，这些方法无需训练且高度灵活，但基于近似；以及专门条件DMs，这些模型通过监督训练实现特定任务的更高准确性和更快推理速度。这项工作中，作者提出了一种新颖框架，结合了深度展开和模型蒸馏技术，将DM图像先验转化为几步条件模型进行后验采样。核心创新在于将Markov链蒙特卡洛算法（特别是最近提出的LATINO Langevin采样器）进行展开，这是首次将深度展开应用于蒙特卡罗采样方案。通过大量实验和与现有最佳技术的比较，展示了我们提出的展开式和蒸馏式采样器，他们在保持对前向模型变化的适应性的同时，取得了出色的精度和计算效率。
### Innovation
提出了将DM图像先验通过深度展开和模型蒸馏转化为几步条件模型的方法，并将Markov链蒙特卡洛算法（特别是最近提出的LATINO Langevin采样器）进行展开，这是首次将深度展开应用于蒙特卡罗采样方案。这种方法在保持灵活性的同时，提高了精度和计算效率。
### Conclusion
通过大量实验和与现有最先进技术的比较，展示了我们提出的展开式和蒸馏式采样器取得了出色的精度和计算效率，同时保留了对前向模型变化的适应性。
## 576. `cs.LG` - KERAP：利用多代理大语言模型实现准确零样本诊断预测的知识增强推理方法 [PDF](https://arxiv.org/pdf/2507.02773), [HTML](https://arxiv.org/abs/2507.02773)
### Authors
Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang
### Background
医疗诊断预测在疾病检测和个性化医疗中起着关键作用。尽管机器学习模型在这项任务中得到了广泛应用，但它们依赖于监督训练，限制了其在未见过的情况下的泛化能力，特别是在获取大型、标注数据集的成本高昂的情况下。大型语言模型（LLMs）展示了通过语言能力和生物医学知识进行诊断预测的潜力，但在生成诊断预测时面临着幻觉问题、缺乏结构化的医疗推理以及产生无用输出的问题。
### Innovation
本文提出了一种知识图谱增强推理方法（KERAP），通过多代理架构改善大语言模型（LLMs）在诊断预测中的表现。该框架包括联动代理进行属性映射、检索代理进行结构化知识提取以及迭代改进诊断预测的预测代理。实验结果表明，KERAP能够有效地提高诊断可靠性，提供一种可扩展且可解释的零样本医疗诊断预测解决方案。
### Conclusion
实验结果表明，KERAP能够有效地提高诊断可靠性，提供一种可扩展且可解释的零样本医疗诊断预测解决方案，该方法通过知识图谱增强推理实现诊断预测的泛化和准确性。
## 577. `cs.LG` - SynapseRoute：基于双状态大型语言模型的自动路由切换框架 [PDF](https://arxiv.org/pdf/2507.02822), [HTML](https://arxiv.org/abs/2507.02822)
### Authors
Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun
### Background
随着大型语言模型（LLMs）在实际应用中的广泛应用，选择合适的模型不仅需要平衡性能，还需要考虑运营成本。具备推理能力的模型使得‘思考’（高推理）模式和‘非思考’（快速、低成本）模式之间的成本差距进一步扩大。已有研究表明，大约58%的医疗问题仅依靠非思考模式即可准确回答，这表明问题复杂度存在明显分界。基于此，本文提出了一种动态路由框架SynapseRoute，能够根据问题复杂度智能地将输入查询分配到思考或非思考模式中，优化准确度、成本效率和整体用户体验。该研究通过多家医疗数据集的实验，展示了SynapseRoute在整体准确度、推理时间和令牌消耗上的显著优势，并指出过度推理会带来不必要的延迟甚至是准确度下降的问题。
### Innovation
提出了基于机器学习的动态路由框架SynapseRoute，能够根据问题复杂性智能地将输入查询分配到思考或非思考模式，显著提升了整体准确度，减少了推理时间和令牌消耗，避免了过度推理带来的延迟和准确度下降问题。
### Conclusion
通过SynapseRoute框架，本文不仅提高了大语言模型的准确度，还优化了推理时间和令牌消耗，引入了综合评价准确度、延迟和令牌成本的AIT指数。
## 578. `cs.LG` - Self-Correction Bench: 揭示并解决LLMs中的自我纠正盲区 [PDF](https://arxiv.org/pdf/2507.02778), [HTML](https://arxiv.org/abs/2507.02778)
### Authors
Ken Tsui
### Background
尽管大型语言模型（LLMs）已经变得具有变革性，它们仍然会犯错误并可能探索不具生产力的推理路径。自我纠正是一个对可信赖的LLM来说非常重要的能力，特别是对自回归模型而言。虽然LLMs能够识别用户输入中的错误，但在其自身输出中出现相同错误时，它们表现出一种系统的‘自我纠正盲区’，即无法纠正自己的错误。为了系统地研究这一现象，引入了Self-Correction Bench，这是一种通过控制性错误注入来测量这一现象的系统框架，分为三个复杂度级别。测试了14个模型，发现平均有64.5%的自我纠正盲区率。研究指出这一限制与训练数据组成有关：人类训练示例主要展示无错误的响应，而不是错误纠正序列，而通过结果反馈学习错误纠正的RL训练模型则不同。通过简单地添加“等待”指令，可以大大减少自我纠正盲区，这表明这种能力确实存在，只是需要激活。本研究表明当前LLMs存在一个关键的局限性，并提供了一些改善其可靠性和可信度的方法和途径。
### Innovation
本文引入了Self-Correction Bench，这是一种系统框架，通过控制性错误注入来测量LLMs中的自我纠正盲区。发现了人类训练示例主要展示无错误响应的原因，与通过结果反馈学习错误纠正的RL训练模型不同。简单地添加“等待”指令能显著减少自我纠正盲区，表明自我纠正能力确实存在，只是需要激活。
### Conclusion
本文揭示了当前LLMs中存在的自我纠正盲区这一关键局限，并通过引入Self-Correction Bench提供了解决办法，强调了改善其可靠性和可信度的潜在途径。
## 579. `cs.LG` - 测量即拼凑：探讨数据科学家如何构建预测建模任务的目标变量 [PDF](https://arxiv.org/pdf/2507.02819), [HTML](https://arxiv.org/abs/2507.02819)
### Authors
Luke Guerdan,Devansh Saxena,Stevie Chancellor,Zhiwei Steven Wu,Kenneth Holstein
### Background
数据科学家在预测建模任务中经常遇到模糊且难以定义的概念，如学生的“原创性”或患者的“健康需求”。然而，数据科学家将这些模糊概念转化为具体代理目标变量的过程仍然缺乏充分的理解。本文通过对教育领域（N=8）和医疗保健领域（N=7）的数据科学家进行访谈，了解他们如何构建目标变量，并提出数据科学家通过不断迭代的过程，平衡高层次测量目标和低层次实际约束，构建目标变量。这一过程要求目标变量满足五个关键标准：效度、简洁性、可预测性、便携性和资源要求。研究者根据访谈结果，建议未来人机交互、协作式计算和机器学习研究领域应更好地支持目标变量构建中的艺术和科学方法。
### Innovation
这项研究揭示了数据科学家通过“拼凑”过程构建目标变量的方法，该过程涉及不断地调整高层次的测量目标和低层次的实际限制。数据科学家使用多种问题重构策略来实现这一过程，包括在目标变量不满足一定标准（如可预测性）时更换备选的变量，或将多个结果整合为一个目标变量，以涵盖更全面的建模目标。这一创新的框架为未来的研究提供了指导思想。
### Conclusion
研究结果提出了未来人机交互、协作式计算和机器学习研究领域支持目标变量构建机会，希望能够更好地促进数据科学家在这个过程中的工作，提高预测模型的效率和准确性。
## 580. `cs.LG` - 基于DNN的RIS辅助毫米波MIMO系统中实用相移的预编码设计 [PDF](https://arxiv.org/pdf/2507.02824), [HTML](https://arxiv.org/abs/2507.02824)
### Authors
Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang
### Background
在毫米波（mmWave）多输入多输出（MIMO）系统中，由于线路直通路径（LoS）中断，通信路径被阻碍时，传统的全搜索（Exhaustive Search，ES）方法在连续相移优化中计算量很大且耗时。改进这一点，使用排列离散傅立叶变换（Permutated Discrete Fourier Transform，DFT）向量来寻找码本设计，并结合RIS系统的幅度响应。尽管如此，即使采用离散相移优化，仍会导致显著的计算复杂度和耗时问题。研究团队在此背景下开发了一种训练有素的深度神经网络（Deep Neural Network，DNN）来快速选择预编码码字，以减轻计算复杂性。
### Innovation
提出了一种基于深度神经网络（DNN）的预编码设计方案，以减小RIS辅助毫米波MIMO系统中的计算复杂性。相比传统ES方法，利用DNN可以快速选择预编码码字，只需少量计算资源即可保持近似最佳的频谱效率。特别是在多种测试条件下，DNN表现出良好的性能，即便终端用户与RIS之间的距离变化也不受影响。
### Conclusion
研究结果表明，DNN在RIS辅助系统中具有潜在的应用价值，并可有效提高系统的频谱效率。尽管采用理论模型对DNN进行了验证，实际应用中还需进一步优化和测试。
## 581. `cs.LG` - 将智能扎根于运动 [PDF](https://arxiv.org/pdf/2507.02771), [HTML](https://arxiv.org/abs/2507.02771)
### Authors
Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording
### Background
近年来，机器学习的进展大幅提升了我们处理语言、视觉和其他高维数据的能力，但在处理生物系统中最基本的一个方面——运动方面依然表现不佳。从神经科学、医学、机器人学和动物行为学等多个领域来看，运动对于解释行为、预测意图以及促进互动至关重要。尽管运动是智力的核心部分，但在实践中经常被当作一个次要问题处理，而不是被当作一个丰富且结构化的模态单独对待。这种现象反映了许多运动数据的收集和建模都受到特定任务目标和特定领域假设的制约，但运动并不仅仅局限于这些领域。它反映了共享的物理约束、保守的形态结构以及跨物种和环境的目的动态。该文认为，运动应被视为人工智能初级建模目标，它是具有内在结构的、基于身体和物理学的。这种结构使得它可以使用紧凑、低维度表示（例如姿态），从而使其比原始的高度维度感官输入更容易理解和计算。发展能够从不同运动数据中学习并推广的核心能力将不仅推动生成建模和控制等基本能力的进步，也将为理解和跨生物和人工系统的行为建立共同的基础。运动不仅仅是结果，它还是了解智能系统如何与世界交互的窗口
### Innovation
该研究强调了将运动视为人工智能中主要建模目标的重要性，认为运动有着内在的结构，基于身体和物理，这使得它在低维度表示下更容易理解和计算，与传统的高维度感官输入模式相比，这是一个创新的观点。此外，论文提出了构建一个共享基础，理解和研究跨生物和人工系统的行为，这也是一种突破性的构想，旨在通过运动来深入理解智能系统如何与世界互动
### Conclusion
研究表明，开发能够从多样化的运动数据中学习和推广的核心能力将不仅促进生成建模和控制等基础能力的提升，还将为理解和跨生物与人工行为系统奠定共同的基础，并展现出运动作为一个通用的建模目标的广泛潜力。运动不仅仅是一个行为的结果，它也展示了智能系统如何与环境交互的一种窗口。
## 582. `cs.LG` - 具有谱半径正则化的非凸优化 [PDF](https://arxiv.org/pdf/2102.11210), [HTML](https://arxiv.org/abs/2102.11210)
### Authors
Adam Sandler,Diego Klabjan,Yuan Luo
### Background
在训练深度神经网络时，研究人员发现平滑的最小值通常比尖锐的最小值具有更好的泛化性能，能够更好地应对现实世界的数据分布。本文旨在研发正则化方法，以便在训练过程中找到这些更好的平滑最小值，并证明这些方法在不同领域的实际应用中表现出色，尤其是在医疗健康等应用中。
### Innovation
提出了一种正则化优化方法，通过减少损失函数Hessian的谱半径来寻找平滑的最小值。此外，还推导出优化神经网络模型的有效算法，并证明了这些算法几乎肯定可以收敛。这种正则化优化方法在不同领域的实际应用中表现出色，并且经过不同泛化性测试表明其模型优于基准模型。
### Conclusion
所提出的方法通过减少Hessian的谱半径有效地找到了性能更好的平滑最小值，并通过实验证明了其泛化能力和在不同应用领域的有效性。
## 583. `cs.LG` - 答案匹配在语言模型评估中的表现优于选择题 [PDF](https://arxiv.org/pdf/2507.02856), [HTML](https://arxiv.org/abs/2507.02856)
### Authors
Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping
### Background
选择题长期以来一直是语言模型评估的基石，因为评分过程客观且易于自动化。然而，研究发现，许多流行基准的选择题可以通过猜测答案而无需看到问题本身，这揭示了鉴别评价的根本局限性，这种局限性并不能反映模型的自由形式生成能力。直到最近，似乎没有有效的可扩展替代方案来替代选择题，但本研究展示了不同评估策略的有效性比较，提出了通过答案匹配进行生成评估的方法并取得了显著成果。
### Innovation
提出了答案匹配方法，将其应用于候选模型的生成回应评估中，无需看选项，通过与参考答案进行匹配来判断其生成回应的有效性。这一创新方法在与人类评分的一致性上取得了接近人工评分者间的一致性，相比之下，传统的选择题和没有参考答案的人工智能评判方式与人类评估结果不匹配的问题得到了解决。这些发现表明，通过答案匹配提高评估的有效性不仅有理论意义，还能显著改变模型的排名。
### Conclusion
这些研究结果表明，将评估生态系统从选择题转移到答案匹配是可行且必要的。通过答案匹配进行生成评估的方法显示出巨大的潜力，可以更准确地评价模型的能力，并有望成为未来评估语言模型的有效方法。
## 584. `cs.LG` - 在非如实拍卖中协调竞标者的学习 [PDF](https://arxiv.org/pdf/2507.02801), [HTML](https://arxiv.org/abs/2507.02801)
### Authors
Hu Fu,Tao Lin
### Background
在非如实拍卖（如第一价格拍卖和全付拍卖）中，竞标者之间的独立战略行为以及相应的均衡概念——贝叶斯纳什均衡——难以描述，可能导致不理想的拍卖结果。一种改进的拍卖系统设计方法是通过协调竞标者，让中介为竞标者提供激励兼容的联合投标建议，即实施贝叶斯联合均衡（BCE）。然而，实施BCE需要竞标者私人估值分布的知识，这通常是不可获得的。因此，我们开始研究在非如实拍卖中学习贝叶斯联合均衡的样本复杂性问题。证明了在包括第一价格拍卖和全付拍卖在内的较大类非如实拍卖中，可以通过样本竞标者的价值分布进行采样，以多项式数量的 $tilde O(frac{n}{rho^2})$ 样本来学习BCE。我们的方法是将问题归约为从样本估计竞标者期望效用，结合分析竞标者所有单调投标策略的拟维数研究。
### Innovation
本文研究了在非如实拍卖中学习贝叶斯联合均衡的样本复杂性问题，并证明了对包括第一价格拍卖和全付拍卖在内的较大类非如实拍卖，可以通过采样竞标者的价值分布来学习BCE，采样数量为 $tilde O(frac{n}{rho^2})$。该研究将问题归约为估计竞标者期望效用的问题，并分析了所有竞标者单调投标策略的拟维数。
### Conclusion
本文证明了在多种类型的非如实拍卖中，贝叶斯联合均衡可以通过多项式数量的样本进行学习，这对改进拍卖系统的公正性和效率构想了重要的理论基础。
## 585. `cs.LG` - MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs [PDF](https://arxiv.org/pdf/2507.02851), [HTML](https://arxiv.org/abs/2507.02851)
### Authors
Purbesh Mitra,Sennur Ulukus
### Background
大语言模型（LLMs）最近在推理能力方面的进展表明，使用群相对策略优化（GRPO）算法进行强化学习（RL）训练可以使模型使用更多的思考/推理令牌以生成更好的回应。然而，LLMs在同一时间维护对已生成令牌的关注时只能生成有限数量的令牌。这个限制，也被称为LLM的上下文大小，对于任意数量的令牌进行推理来说是瓶颈。为了解决这一限制，研究者提出采用模块化推理策略，即在多轮中推理以超越上下文大小的限制。本文提出了MOTIF方法来实现这一点，该方法使模型能够在多轮次中生成思考令牌，从而有效地利用额外的上下文大小进行推理.
### Innovation
MOTIF方法提出了一种基于强化微调的训练方法，允许LLMs通过多轮次生成思考令牌以超越上下文大小限制，从而提高模型的推理能力。研究者使用参数高效微调技术对开源模型Qwen2.5-3B-Instruct进行了训练，并在MATH500和AIME2024基准测试中取得了明显提升，分别提高了3.8%和3.3%，且仅需15%的数据，展示了MOTIF的样本效率.
### Conclusion
实验表明，与基于GRPO方法的训练相比，MOTIF方法在MATH500和AIME2024基准测试中分别取得了3.8%和3.3%的改进，且仅使用了15%的数据，证明了MOTIF在样本效率上的优势。研究者提供的代码和模型已公开可用。
## 586. `cs.LG` - Kernel Density Bayesian Inverse Reinforcement Learning [PDF](https://arxiv.org/pdf/2303.06827), [HTML](https://arxiv.org/abs/2303.06827)
### Authors
Aishwarya Mandyam,Didong Li,Jiayu Yao,Diana Cai,Andrew Jones,Barbara E. Engelhardt
### Background
逆强化学习（IRL）方法通过专家行为的演示推断代理的奖励函数。传统的贝叶斯IRL算法建模候选奖励函数的概率分布，捕捉推断奖励函数中的不确定性。然而，这些算法通常需要大量的示例数据集，这在实际应用中可能不可用。研究背景特别集中在临床和生物应用中，其中可以访问专家的示例和一组训练任务的已知奖励函数。现有方法对输入数据的形式有限制，限制了训练任务数据的集成。本研究提出了一种新的方法，通过结合现有的领域特定数据，以实现更好的后验集中率。
### Innovation
本研究介绍了卡尔曼密度贝叶斯逆强化学习（KD-BIRL），这是一种新的IRL方法。该方法使用条件卡尔曼密度估计器，利用已知训练任务的奖励函数来改进各种奖励函数和演示样本的似然估计。实验结果表明，KD-BIRL相较于基线方法，在低专家演示数据的情境下具有更快的集中速率。此外，本研究首次提供了贝叶斯IRL算法的后验集中率的理论保证。
### Conclusion
本研究提出了一种新的贝叶斯IRL方法——KD-BIRL，该方法能够在有限的专家演示数据下有效学习新测试任务的奖励函数，并提供了一种理论保证，表明其在不同应用领域的广泛适用性。
## 587. `cs.LG` - Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory [PDF](https://arxiv.org/pdf/2507.02863), [HTML](https://arxiv.org/abs/2507.02863)
### Authors
Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu
### Background
从有序序列或无序图像集合中密集重建3D场景是将计算机视觉研究带入实际应用场景的关键步骤。现有方法遵循DUSt3R提出的并入图像对的思想，将图像对统一到共享坐标系统中，随后的方法通过 Maintaining 一种隐式记忆来实现更多图像的密集3D重建。然而，这种隐式记忆在容量上有限并且会导致早期帧的信息丢失。
### Innovation
本文提出了一种在线框架，名为Point3R，专门针对密集的流式3D重建。Point3R的核心创新是引入了一个与当前场景3D结构直接关联的显式空间指针记忆。每个指针指定特定的3D位置，并将全局坐标系统中附近的场景信息聚合为变化的空间特征。来自最新帧的信息与指针记忆进行显式交互，使得当前观察可以紧密地集成到全局坐标系中。该方法还设计了3D层次位置嵌入来促进这种交互，并设计了一种简单而有效的融合机制来确保指针记忆的一致性和效率。与现有方法相比，该方法在各个任务上取得了竞争性或最先进性能，并且训练成本较低。
### Conclusion
我们的方法在多项任务上达到了竞争性或最先进水平，同时保持了较低的训练成本。源代码可在此 https://地址 获取。
## 588. `cs.LG` - 基于树的高保真混沌预测学习 [PDF](https://arxiv.org/pdf/2403.13836), [HTML](https://arxiv.org/abs/2403.13836)
### Authors
Adam Giammarese,Kamal Rana,Erik M. Bollt,Nishant Malik
### Background
混沌系统的时域演化模型自由预测对于许多应用至关重要，但极具挑战性。现有的解决方案需要进行超参数调优，极大地阻碍了它们的广泛应用。
### Innovation
我们提出了一个不需要超参数调优的基于树的方法：TreeDOX。该方法通过时间延迟嵌入作为显式的短期记忆，并使用Extra-Trees回归器来进行特征约简和预测。
### Conclusion
我们通过Hénon映射、Lorenz系统和Kuramoto-Sivashinsky系统，以及实际的南方振荡指数证明了TreeDOX的最先进的性能。
## 589. `cs.LG` - StepHint: 多层次逐步提示增强强化学习以进行推理 [PDF](https://arxiv.org/pdf/2507.02841), [HTML](https://arxiv.org/abs/2507.02841)
### Authors
Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan
### Background
Reinforcement learning with verifiable rewards (RLVR) 是一种通过验证奖励改进大型语言模型复杂推理能力的方法。然而，当前的 RLVR 方法存在两个主要挑战：近似奖励问题，即使有小的错误也能使整个推理过程无效，严重影响训练效率；以及探索停滞，模型倾向于在它们的“舒适区”内寻找解决方案，缺少探索更有效替代方案的动力。
### Innovation
本文提出了一种名为 StepHint 的新型 RLVR 算法，该算法利用多层次逐步提示，帮助模型更有效地探索解决方案空间。StepHint 通过自更强模型生成有效的推理链，并使用自适应分区方法将这些链分割为推理步骤。初始步骤被用作提示，同时向模型提供多层提示（每层提示包含不同数量的步骤）。这种方法可以引导模型向有可能的解决方案子空间探索，同时保持其独立探索的灵活性。通过提供提示，StepHint 减轻了近似奖励问题，从而提高了训练效率。同时，外部推理路径帮助模型发展更好的推理能力，使其能够超越“舒适区”，避免探索停滞。在六个数学基准测试上，StepHint 显著优于其他竞争的 RLVR 改进方法，同时在域外基准测试上也表现出更好的泛化能力并远超基准线。
### Conclusion
StepHint 通过多层次逐步提示增强强化学习，显著提高了训练效率，有效解决了近似奖励问题和探索停滞问题，从而提升了模型的复杂推理能力，并在多个基准测试中表现出色。
## 590. `cs.LG` - LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users [PDF](https://arxiv.org/pdf/2507.02850), [HTML](https://arxiv.org/abs/2507.02850)
### Authors
Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas
### Background
本文描述了语言模型（LMs）在使用用户反馈进行训练时的一个漏洞，其中，仅凭给定的提示和对语言模型输出的投票能力，单一用户可以持续地改变LM的知识和行为。为实现攻击，攻击者会随机地要求语言模型输出“中毒”或正常响应，并根据实际情况对中毒响应进行投票或是对正常响应给出反向投票。由于后续的偏好调优依赖于这些反馈信号，语言模型在没有恶意提示的背景下，也更有可能生成中毒响应，这揭示了即使在极简的偏好数据情况下，模型的行为仍可能被精细地控制。这种攻击可以用于插入新的事实知识，修改代码生成模式以引入可利用的漏洞，以及注入虚假的财经新闻。这不仅指出了语言模型偏好调优的一个新特性（即使是有限的形式的偏好数据也会被用来执行细粒度的行为控制），还提出了一种新的针对使用用户反馈进行训练的语言模型的攻击机制（拓展了在预训练时间的数据污染和部署过程中提示注入的工作）。
### Innovation
该研究展示了即使在极端有限的偏好数据下，利用用户反馈也可以构造细粒度的行为控制，提出了针对用户反馈训练的语言模型的新攻击机制。具体创新点包括：通过随机生成的“中毒”或正常响应并反馈投票，使得模型在理想环境中也倾向于生成有害内容；插入新知识；修改代码生成模式；以及注入虚假财经新闻。这些方法不仅挑战了之前对语言模型使用的安全性认识，也为攻击者提供了多种攻击手段，包括安全和信息传播方面的影响。
### Conclusion
该研究揭示了语言模型模型偏好调优的一个新品质，即即使有非常有限的偏好调优数据（例如，仅有上下文无恶意的投票），仍可使得模型出现有针对性的行为变化。这一发现突显了保护AI系统安全的重要性，尤其是当AI系统使用用户反馈进行训练时。未来的研究应该更加关注如何保护这些模型免受此类攻击的影响，同时探索改进偏好调优机制的策略来减少此类风险。此外，该研究还推动了在用户反馈训练的大型语言模型中进行更严格的测试和验证的必要性，以防止恶意用户滥用其反馈影响模型的输出。
## 591. `cs.LG` - 通过概率隐空间解释深度神经网络压缩 [PDF](https://arxiv.org/pdf/2403.00155), [HTML](https://arxiv.org/abs/2403.00155)
### Authors
Mahsa Mozafari-Nia,Salimeh Yasaei Sekeh
### Background
深度神经网络（DNNs）尽管在性能上取得了令人瞩目的成果，但由于其计算复杂性和存储空间的需求，网络压缩的概念变得尤为重要。尽管已有对基于剪枝和低秩分解等DNN压缩技术的研究，但理论解释方面却相对不足。因此，本文提出了一个新颖的概率隐空间理论框架，通过信息论中的分歧度量解释了DNN最佳的稀疏性。实验在标准预训练基准模型（AlexNet、ResNet50、VGG16）及CIFAR10和CIFAR100数据集上验证了理论成果，特别关注了AP3和AP2属性与精简后的DNN微调关系及稀疏度水平的关系。
### Innovation
文章提出了一种利用DNN权重的概率隐空间的新理论框架，通过信息论中的分歧度量解释了DNN最佳的稀疏性，并引入了AP2和AP3新的概念，证明了网络不同层的AP3/AP2属性与其性能存在关联，从而解释了压缩网络的训练过程。该理论通过实验在标准预训练模型和数据集上得到了验证。
### Conclusion
通过实验证明，AP3和AP2属性与DNN剪枝后的精调性能及稀疏度水平存在紧密关系，为理解DNN压缩提供了理论依据。
## 592. `cs.LG` - 通过求助避免在线学习中的灾难 [PDF](https://arxiv.org/pdf/2402.08062), [HTML](https://arxiv.org/abs/2402.08062)
### Authors
Benjamin Plaut,Hanlin Zhu,Stuart Russell
### Background
大多数具有正式懊悔保证的学习算法假设所有错误都是可恢复的，并几乎依赖于尝试所有可能的行为。然而，当某些错误是“灾难性的”，即不可恢复时，这种方法就变得不适用了。本研究提出了一种在线学习问题，其目标是最大限度地减少灾难发生的可能性。每一轮的收益代表了避免该轮灾难的机会，通过允许与导师进行有限次查询来最大化收益产品的整体机会。此外，假设代理可以将知识转移到相似的输入中。结果显示，一般情况下，任何算法要么以线性速率查询导师，要么几乎不可避免地导致灾难。但在导师策略类可以在标准在线模型中学习的设置下，提供了一个算法，其懊悔和查询导师的速率在时间窗口增大时都趋近于0。尽管重点是收益的乘积，也提供了匹配的增量懊悔上限。概念上讲，如果在没有灾难风险的情况下可以学习一个策略类，那么在存在灾难风险的情况下，如果代理可以请求帮助，也可以学习该策略类。
### Innovation
提出了一种新的在线学习问题，聚焦于通过有限次向导师查询来最小化灾难发生的可能性。在缓解灾难风险方面，该研究解决了标准模型中无法学习的策略类，在存在灾难风险的情况下，展示了如何设法学习。通过这种方法，证明了在渐近情况下，算法的懊悔和查询频率都会趋向于0。同时提供了对于传统期望懊悔的匹配上界，强调了代理知识转移的能力和寻求外部帮助的重要性。
### Conclusion
本研究展示了在存在不可恢复的错误或灾难风险的情况下，通过学习和咨询的方法，可以有效避免灾难发生。对于能够学习的标准策略类，即使存在灾难风险，通过与导师互动，代理也能够逐步提高其性能。这一结论对于维护安全性和稳健性的在线学习系统设计具有重要意义。
## 593. `cs.LG` - 时间一致协 man 自编码器及其在动态系统预测中的应用 [PDF](https://arxiv.org/pdf/2403.12335), [HTML](https://arxiv.org/abs/2403.12335)
### Authors
Indranil Nayak,Ananda Chakrabarty,Mrinal Kumar,Fernando Teixeira,Debdipta Goswami
### Background
在数据驱动的高维空间-时间动态系统建模过程中，缺乏足够高质量的数据常常是一个关键挑战。Koopman 自编码器（KAEs）结合了深度神经网络（DNNs）的表达能力、自编码器的降维能力和 Koo man 操作子的频谱性质，以学习一个简化线性动力学规则的降序特征空间。不过，由于这些模型受到有限且噪声数据集的影响，导致它们的泛化性能较差，从而限制了它们的有效性。
### Innovation
为解决这一问题，该研究引入了时间一致的 Koopman 自编码器（tcKAE），这种方法能够生成即使在数据有限和噪声的条件下也能提供准确的长期预测。其创新点在于引入了时间一致性正则化项，强制不同时间步骤的预测具有连贯性，从而增强了 tcKAE 的稳健性和模型的泛化能力。在图谱理论的理论依据和实验结果的支持下，研究证明了 tcKAE 相较于最先进的 KAE 模型在多种测试案例中的优越性能，涵盖了简单摆振荡器、等离子体动力学和流体流动数据等场景。
### Conclusion
时间一致的 Koopman 自编码器（tcKAE）在处理有限和噪声数据集时，通过引入时间一致性正则化项，可以在高维空间-时间动态系统的预测中实现更准确和更稳健的性能，这为克服 KAEs 的有效性限制提供了一种新的方法。tcKAE 在不同测试场景下的实验结果均展示了其优越性，该方法能够为动态系统的长期预测提供更可靠的解决方案。
## 594. `cs.LG` - 对震后复容.Tags: 谍报鲁莽的急智：从双重视角洞察 [PDF](https://arxiv.org/pdf/2405.03449), [HTML](https://arxiv.org/abs/2405.03449)
### Authors
Renaud Gaucher,Aymeric Dieuleveut,Hadrien Hendrikx
### Background
分布式学习具有许多计算优势，但容易受到一小部分设备传输错误信息的攻击。在去中心化设置中，设备通过通信网络以点对点的方式直接通信，由此带来了安全问题。本文旨在研究在这种去中心化环境下，如何设计能够在震后复容（Byzantine）攻击中依然稳健的算法。
### Innovation
本文采用所谓的双重视角方法来解决分布式优化问题，并提出了一个震后复容鲁棒的算法。作者提供了平均共识子情况下的收敛性保证，探讨了双重视角方法在其他情况下的潜力，并用双重视角重新解释了现有算法。此外，通过实验验证了方法的有效性。
### Conclusion
本文通过对震后复容鲁棒 gossip 算法的研究，提供了新的见解，并且实验结果显示了该方法的正确性和有效性。
## 595. `cs.LG` - 隐式反事实数据增强以提升鲁棒学习 [PDF](https://arxiv.org/pdf/2304.13431), [HTML](https://arxiv.org/abs/2304.13431)
### Authors
Xiaoling Zhou,Ou Wu,Michael K. Ng
### Background
机器学习模型容易捕捉非因果属性与类别之间的虚假相关性，而反事实数据增强则有望打破这些虚假关联。然而，显式生成反事实数据存在挑战，将增强数据融入训练过程也会降低训练效率。本文针对这些问题，提出了一种隐式反事实数据增强（ICDA）方法，以消除虚假相关性并提高预测的稳定性。ICDA方法首先开发了一种新颖的样本级增强策略，针对每个样本生成具有不同增强强度的语义和反事实意义的深度特征。接着，提出了一种适用于大规模样本的易于计算的替代损失函数。此外，提出了直接量化和元学习两种具体方案，以确定鲁棒损失的关键参数。ICDA还可以从正则化角度进行解释，展示其在提高类别内紧凑性和增强类别和样本水平的余量方面的潜力。该方法已在图像和文本数据集上进行了广泛的实验验证，表明ICDA可以提升流行网络的一般化和鲁棒性性能。
### Innovation
提出了一种隐式反事实数据增强（ICDA）方法，通过生成具有不同增强强度的语义和反事实有意义的深度特征来消除虚假相关性。引入了一种易于计算的替代损失函数，并提出了直接量化和元学习两种方法来确定关键参数，从而提高了模型的一般化和鲁棒性。
### Conclusion
ICDA方法展示了其在消除虚假相关性方面的能力，并且可以在多种偏置学习场景中提升模型的一般化和鲁棒性性能。该方法从正则化角度解释了其改进类别内紧凑性和类内、样本间余量的机制。
## 596. `cs.LG` - 面向方向感知的稀疏张量PCA及其高效无监督特征选择 [PDF](https://arxiv.org/pdf/2407.16985), [HTML](https://arxiv.org/abs/2407.16985)
### Authors
Junjing Zheng,Xinyu Zhang,Weidong Jiang,Xiangfeng Qiu,Mingjian Ren
### Background
近年来，将张量分解（TD）技术引入无监督特征选择（UFS）成为研究热点。张量结构有助于挖掘不同模态之间的关系，并减轻计算负担。现有的方法虽然利用TD保持数据张量结构，但在处理如时间序列等具有方向特性的数据时，忽略了数据方向的影响，难以应对此类数据的特征选择任务。
### Innovation
为了应对上述问题，该研究利用基于 *M-产品（T-SVDM）的张量奇异值分解中的方向感知张量-张量乘积，并将一维稀疏主成分分析（SPCA）扩展到张量形式。提出了稀疏张量PCA模型，允许在指定模态下限制稀疏性，从而增强在学习特征关系时的灵活性和准确性。为了确保快速收敛并灵活描述特征相关性，该研究特别设计了一种凸优化版本，并提出了在变换域中进行双重优化的高效逐片算法。实验结果表明，对于具有不同结构的张量数据，该方法相比现有最先进的技术更有效且计算效率更高。特别是在变换轴与特征分布模式对齐时，该方法在各种应用场景中都显示出很好的前景。
### Conclusion
所提出的方法在多个真实数据集上的实验结果证明了其在不同结构的张量数据上的有效性与显著的计算效率。该方法特别适合对齐了变换轴与特征分布模式的情况下的各种应用。相关的代码和实验结果已公开。
## 597. `cs.LG` - 绕过反向传播：通过策略梯度的大型语言模型结构剪枝 [PDF](https://arxiv.org/pdf/2406.10576), [HTML](https://arxiv.org/abs/2406.10576)
### Authors
Yuan Gao,Zujing Liu,Weizhong Zhang,Bo Du,Gui-Song Xia
### Background
近期对大型语言模型（LLM）的剪枝方法通常在后训练阶段进行，避免了昂贵的权重微调。然而，这些方法的剪枝标准往往依赖于手工构造的经验性度量标准，这可能导致性能不佳。本文探讨了这一问题背景。
### Innovation
本文提出了一种基于优化的结构剪枝方法，通过优化剪枝模型的损失来学习剪枝掩码，而非依赖手工构造的经验性度量。该方法在优化过程中不需要对LLM进行反向传播，仅需进行前向传播。此外，通过学习潜在的伯努利分布来抽样二值剪枝掩码，并将伯努利参数与LLM损失分离，使得通过策略梯度估计算法进行高效优化。这种方法能够实现全局和异构的剪枝，并可选择性地使用基于度量的方法来初始化。
### Conclusion
我们对LLaMA、LLaMA-2、LLaMA-3、Vicuna和Mistral模型进行了广泛的实验，证明了该方法在效率和性能上的前景。实验结果表明，该方法在多个LLM模型上表现出良好的效果，同时代码已经公开。
## 598. `cs.LG` - 复杂查询回答真的复杂吗？ [PDF](https://arxiv.org/pdf/2410.12537), [HTML](https://arxiv.org/abs/2410.12537)
### Authors
Cosimo Gregucci,Bo Xiong,Daniel Hernandez,Lorenzo Loconte,Pasquale Minervini,Steffen Staab,Antonio Vergari
### Background
知识图谱（KG）上的复杂查询回答（CQA）正逐渐成为一项具有挑战性的推理任务。现有的基准测试可能并不如我们想象的那样复杂，因为它们的构建方式扭曲了我们在这一领域进步的感知。例如，许多查询（某些类型的查询可达98%）可以简化为更容易的问题，如链接预测，只需预测一个链接。这导致最先进的CQA模型在不能简化为较简单类型的问题上表现显著下降。因此，需要一种更有挑战性的基准测试，由需要模型在多个跳之间进行推理并更好地反映真实世界KG构建的查询组成。
### Innovation
提出了更加具有挑战性的基准测试，这些基准测试由需要模型在多个跳之间进行推理的查询组成，更好地反映了真实世界KG的构建方式。这种新的基准测试显示，当前的方法还有很大的改进空间。
### Conclusion
系统性的实证研究显示，当前的CQA方法在处理不能简化为较简单的问题时表现不佳，需要改进。
## 599. `cs.LG` - 探索扩散桥梁模型的设计空间 [PDF](https://arxiv.org/pdf/2410.21553), [HTML](https://arxiv.org/abs/2410.21553)
### Authors
Shaorong Zhang,Yuanbin Cheng,Greg Ver Steeg
### Background
扩散桥梁模型能够通过在像素空间中创建分布之间的路径来实现高质量的图像到图像(I2I)转换。然而，基于不兼容数学假设的技术的广泛应用阻碍了这一领域的发展。
### Innovation
本文通过将随机插值(SIs)扩展为预处理、端点条件及优化采样算法，统一并扩展了桥梁模型的空间。这些增强功能扩大了扩散桥梁模型的设计空间，使得在多种I2I任务中的图像质量和采样效率达到最先进的水平。此外，本文还识别和解决了固定条件下样本多样性低的问题，并提供了输出多样性的量化分析及解决方案的示例。
### Conclusion
这些改进使得扩散桥梁模型在多样化的I2I任务中展现出卓越的性能。同时，新的方法和分析工具有助于进一步优化模型，推动该领域的进展。
## 600. `cs.LG` - 神经CRNs：化学反应网络中学习的自然实现 [PDF](https://arxiv.org/pdf/2409.00034), [HTML](https://arxiv.org/abs/2409.00034)
### Authors
Rajiv Teja Nagipogu,John H. Reif
### Background
该研究引入了神经CRNs，这是一种将学习直接嵌入到质量作用化学反应系统中的通用化学神经网络框架。与之前通过化学实施和组合离散神经计算的方法不同，神经CRNs采用了一种模拟计算方法，其中前向和后向学习过程均通过连续时间的分子浓度演化来实现。这种模拟形式自然地与化学动力学的模拟特性相吻合，从而提供简洁的电路和实际可行的反应。文章通过构造一个仅需两个连续阶段即可执行的简洁监督学习过程来证明这种效率。然后实现了几种学习电路，以展示该框架的线性和非线性建模能力，并验证其学习过程。这些电路仅使用单分子和双分子反应实现，避免了更高级化学的复杂性。
### Innovation
神经CRNs的特点在于它采用模拟计算方法，将学习过程通过连续时间的分子浓度演化来实现。这种设计与化学动力学的模拟特性相吻合，允许简洁且实际可行的反应设计，展现了其在合成生物学、生物工程和生物医学领域中适应性计算的新途径。
### Conclusion
神经CRNs提供了紧凑、可扩展且自主的生物化学学习框架，为生物计算开辟了新的途径。
## 601. `cs.LG` - TAROT：基于最优传输的目标化数据选择 [PDF](https://arxiv.org/pdf/2412.00420), [HTML](https://arxiv.org/abs/2412.00420)
### Authors
Lan Feng,Fan Nie,Yuejiang Liu,Alexandre Alahi
### Background
现有目标化数据选择方法主要依赖于基于影响的贪心启发式算法，以改进特定领域的性能。尽管在简单且单一分布的数据上有效，但当目标数据复杂度增加时，这些方法在多模态分布上表现不佳，因为启发式算法无法充分考虑多种内在模式，导致数据选择结果不理想。主要原因是高维影响估计中占主导地位的特征成分的影响被过度夸大以及贪婪选择策略固有的线性添加假设。
### Innovation
TAROT框架引入了白化特征距离来减轻占主导地位特征的偏见，提供更可靠的决策支持数据的影响度量，从而量化并最小化所选数据与目标域之间的最优传输距离。这种方法还有助于估算最优选择比例，提升泛化能力。通过在多个深度学习任务上的评估，TAROT 显示出超越现有最先进方法的优势，表明其跨任务的广泛适用性。
### Conclusion
TAROT 研究结果证明其在语义分割、运动预测和指令调整等多个任务中超越现有最佳方法，显示出其在各种深度学习任务中的优势。
## 602. `cs.LG` - 参数 vs FLOPs：Mixture-of-Experts 语言模型最优稀疏性缩放定律 [PDF](https://arxiv.org/pdf/2501.12370), [HTML](https://arxiv.org/abs/2501.12370)
### Authors
Samira Abnar,Harshay Shah,Dan Busbridge,Alaaeldin Mohamed Elnouby Ali,Josh Susskind,Vimal Thilak
### Background
语言模型的能力可以通过扩展模型规模来提高，这通常与模式参数的数量和每例计算量有关，但不同因素之间的具体关系及其对总体能力的贡献尚不完全理解。这项研究探讨了稀疏 Mixture-of-Experts (MoEs) 中参数数量和每例计算量之间的关系，以及不同约束条件下（如参数大小和总训练计算量）的最优稀疏性对训练效率和模型性能的影响。
### Innovation
本研究通过分析稀疏 MoEs 的参数与 FLOPs 之间的关系，发现不同约束条件下存在最优的稀疏性水平，这有助于提高训练效率和模型性能。这种研究成果补充了现有工作，为设计更高效的模型架构提供了见解。
### Conclusion
研究结果表明，在隐私性和计算性能之间存在一种最优的稀疏性水平，该水平可以同时提高训练效率和模型性能。这对于理解 MoEs 规模法则的影响至关重要，并且对于设计高效模型架构具有重要意义。
## 603. `cs.LG` - 关于语言生成的表征性表征：幻觉、广度和稳定性的相互作用 [PDF](https://arxiv.org/pdf/2412.18530), [HTML](https://arxiv.org/abs/2412.18530)
### Authors
Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas
### Background
本文研究了由Kleinberg和Mullainathan提出的限制内语言生成问题，该问题建立在Gold和Angluin的经典工作之上。Kleinberg和Mullainathan的成果提供了一个从任何可数语言集合中生成语言的目标K的算法，但该算法可能覆盖不完全或不够广泛。尽管最近的进展探索了生成时的广度问题，但如何全面测量这些广度概念仍不明确。本文通过定义和扩展已有的广度概念及其自然扩展，对此进行了研究。此外，本文还探讨了稳定生成器与广度之间的关系，以及在稳定生成中的不可风险极限下界问题，推动了KMV25的研究成果。
### Innovation
本文的主要创新在于对现有的广度概念及其自然扩展进行表征，并建立了关于广度、稳定性和一致性的严格的限界结果。此外，针对稳定生成器在广度条件下的难度，提出了更加严谨的结果，展示了在稳定生成条件下广度难以实现的镜像结果。这揭示了语言生成中幻觉、广度和稳定性之间的复杂关系。
### Conclusion
本文通过表征语言生成中的已有广度概念和其扩展，证明了稳定性在允许近似广度时的分离效果。进一步突出了广度、稳定性和一致性在语言生成中的丰富相互作用。
## 604. `cs.LG` - EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference [PDF](https://arxiv.org/pdf/2502.04700), [HTML](https://arxiv.org/abs/2502.04700)
### Authors
Prakhar Kaushik,Ankit Vaidya,Shravan Chaudhari,Alan Yuille
### Background
大型模型的快速增长引发了对其环境影响和接入公平性的担忧，因为这会导致大量的计算成本。虽然LoRA提供了轻量级的微调解决方案，但大量面向不同领域的预训练适配器公开可用。本文探讨了是否可以利用这些预训练的适配器进一步简化新任务的调整，同时解决这些挑战。
### Innovation
本文提出了EigenLoRAx，这是一种参数高效的微调方法，能够回收现有适配器以形成与领域知识一致的主要子空间。在这种方法中，可以通过学习主要子空间的轻量级系数来进行快速调整，无需单独微调整个适配器，且显著减少了所需参数和内存，进一步提高了训练和推理的效率。该方法在不同领域和任务上展示了强大的性能，为边缘应用、个性化和资源受限环境中的大型模型公平部署提供了可扩展的方法。
### Conclusion
EigenLoRAx在不同场景下表现出色，能够高效且快速地适应新任务，减少资源消耗，为边缘设备上的应用提供了解决方案。
## 605. `cs.LG` - 离线强化学习在代理调度任务中用于作业车间调度问题 [PDF](https://arxiv.org/pdf/2409.10589), [HTML](https://arxiv.org/abs/2409.10589)
### Authors
Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang
### Background
作业车间调度问题（JSSP）是一个复杂的组合最优化问题，尽管在线强化学习（RL）已经显示出迅速找到可行解的潜力，但它面临着几个关键限制：从头开始需要大量的训练交互导致样本效率低下；无法利用传统方法如约束编程（CP）提供的高质量解决方案；以及训练需要模拟环境，对于复杂调度环境来说是不切实际的。本研究旨在通过离线强化学习（Offline Reinforcement Learning, Offline-LD）解决在线RL的这些问题，通过从历史调度数据中学习，解决上述具体挑战。
### Innovation
我们提出了一个基于历史数据学习的离线RL方法——Offline Learned Dispatching（Offline-LD），它通过保守Q-学习（CQL）从两个可掩码的Q-学习方法——Maskable Quantile Regression DQN（mQRDQN）和离散掩码Soft Actor-Critic（d-mSAC）中学习。此外，为掩码动作空间引入了d-mSAC的新型熵奖修改。我们还提出了一个新的JSSP在离线RL设置中的奖励归一化方法。实验结果显示，当仅使用100个由CP生成的解决方案进行训练时，Offline-LD在生成实例和基准实例上均优于在线RL。此外，引入噪声到专家数据集可以产生与专家数据集相同数量的实例中，从而获得类似或优越的结果，这一结果对于实际应用具有重要意义，因为实际数据通常是有噪声的和不完美的。
### Conclusion
我们提出的Offline-LD方法克服了在线RL面临的各种限制，它通过利用历史调度数据学习，显著提高了JSSP的解决方案质量。同时，引入噪声的专家数据集的实验证明了可用性和有效性，这表明这种方法可能在实际场景中具有较好的应用潜力。
## 606. `cs.LG` - 从生成模型学习实时观察中的交通异常现象 [PDF](https://arxiv.org/pdf/2502.01391), [HTML](https://arxiv.org/abs/2502.01391)
### Authors
Fotis I. Giasemis,Alexandros Sopasakis
### Background
准确检测交通异常对于有效的城市交通管理和缓解交通拥堵至关重要。为了捕捉交通数据中的复杂空间和时间依赖关系，研究者们采用了一种结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架。该研究通过对瑞典哥德堡42个交通摄像头采集的月度数据进行实时、逐分钟的观测，对这些数据进行了处理，以计算表示车流密度的流量指标。模型在2020年4月至11月的数据上进行训练，并在11月14日至23日的数据上进行了验证。研究表明，模型能够有效地检测出车流量中断、视觉伪影以及极端天气条件等交通异常现象，且有很高的检测精度和较低的误报率。
### Innovation
该研究创新性地将时空生成对抗网络框架应用于城市交通管理领域，通过结合图神经网络和长短期记忆网络，有效捕捉交通数据中的复杂空间和时间依赖关系，实现了对实时交通异常现象的准确检测。相比传统方法，该方法在模型精度和降低误报率方面具有显著优势。
### Conclusion
实验结果表明，STGAN 模型能够有效检测交通异常现象。检测到的异常包括摄像头信号中断、视觉伪影及受极端天气影响而产生的异常交通流情况，且具有高精度和低误报率。研究不仅验证了时空生成对抗网络在城市交通流量检测上的有效性，也为交通管理和城市规划提供了新的技术手段。
## 607. `cs.LG` - 摒弃层级：HNSW 中的'H'代表‘枢纽’ [PDF](https://arxiv.org/pdf/2412.01940), [HTML](https://arxiv.org/abs/2412.01940)
### Authors
Blaise Munyampirwa,Vihan Lakshman,Benjamin Coleman
### Background
近期在神经表示学习领域的突破推动了向量嵌入的近似最近邻（ANN）搜索成为关键计算工作负载。基于图的索引体系因其高效性和可扩展性，已成为ANN搜索的主要范式。HNSW算法通过层级递归层级递归的图结构快速识别查询向量的相似点所在的区域。但这种层次结构是否必要呢？对此进行严格实验分析有助于深入了解ANN搜索算法设计的本质，并为该领域未来的工作提供方向。
### Innovation
作者进行了一项广泛的研究，涉及比以往更大量级的数据集，发现扁平网络结构的导航小世界图在高维数据集上能保留HNSW的所有优势，并在延迟和召回性能上与原始算法几乎相同，但具有较低的内存开销。同时，作者还研究了HNSW层次结构在高维数据集上提供无益性的原因，提出了‘枢纽高速公路假设’，并提供了实验证据支持这一假设，揭示了‘高速公路’形成的机制。这一假设的含义也为未来增强基于图的ANN搜索的研究方向提供了指导
### Conclusion
实验结果表明，扁平网络结构的导航小世界图在高维数据集上具有与HNSW相同的性能，但内存占用较少。作者进一步推测，导航小世界图中的‘高速公路’由枢纽节点构成，能够维持层次结构的功能。这为未来的研究提供了潜在的方向。
## 608. `cs.LG` - StructTransform：安全对齐的大语言模型的可扩展攻击面 [PDF](https://arxiv.org/pdf/2502.11853), [HTML](https://arxiv.org/abs/2502.11853)
### Authors
Shehel Yoosuf,Temoor Ali,Ahmed Lekssays,Mashael AlSabah,Issa Khalil
### Background
本文研究了针对大语言模型（LLM）对齐的结构转换攻击，通过使用多样化的语法空间，从简单的结构格式和基础查询语言（例如SQL）到完全由LLM生成的新颖空间和语法，对LLM对齐进行了攻击。评估表明即使是严格对齐的LLM，简单的攻击成功率也接近90%，而结合结构转换和现有内容转换的适应性方案可以实现超过96%的成功率。研究还发现针对这些新型语法生成容易且效果好，意味着这些攻击难以防御。现有的安全对齐防御措施大多失败，暴露出现有方法主要依赖于token级别模式而忽视有害概念的问题，这突显了在这一领域需要更深入研究的必要性。作为案例研究，攻击者可以使用这些攻击生成样本恶意软件和欺诈短信，它们能够在绕过检测中表现良好。
### Innovation
提出了结构转换攻击（StructTransform），这种攻击利用多样化语法空间进行攻击，包括由LLM生成的全新语法。使用适应性方案结合结构转换和现有内容转换，显著提高了攻击成功率。研究发现新型语法生成容易并能提高攻击成功率，表明现有安全对齐方法存在缺陷，需要更深入研究。作为实例，展示了如何利用这些攻击生成有效的恶意软件和欺诈短信。
### Conclusion
现有的安全对齐方法主要依赖于token级别模式，未能识别和阻止有害内容，这表明当前防御机制存在着不足。通过这些攻击可以生成有效的恶意软件和欺诈短信，突显了对新型防御措施进行研究的必要性。
## 609. `cs.LG` - 基于大型语言模型的穿戴设备和饮食数据下高血糖预测及行为治疗路径发现 [PDF](https://arxiv.org/pdf/2503.03935), [HTML](https://arxiv.org/abs/2503.03935)
### Authors
Abdullah Mamun,Asiful Arefeen,Susan B. Racette,Dorothy D. Sears,Corrie M. Whisner,Matthew P. Buman,Hassan Ghasemzadeh
### Background
餐后高血糖，表现为餐后血糖水平超出正常范围，是诊断代谢综合征和预测2型糖尿病进展的关键指标。了解餐后血糖动态的一个关键指标是餐后曲线下面积（AUC）。基于生活方式因素（如饮食和运动水平），预测餐后AUC并解释影响餐后血糖的因素，可以帮助个体调整治生活来维持正常的血糖水平。本文研究基于传感器输入和先进的数据分析、大型语言模型及可训练机器学习模型，提出了一种可解释的机器学习解决方案GlucoLens，用于预测餐后AUC和高血糖。
### Innovation
提出了一种基于大规模语言模型的GlucoLens系统，该系统整合了穿戴传感、多模态数据和机器学习，能够从饮食、运动和近期葡萄糖模式预测餐后AUC和高血糖。该系统能够提供可解释的餐后葡萄糖模式预测，并能通过不同的对抗性解释推荐治疗方案。与比较模型相比，提出的解决方案总体性能提高了16%，高血糖预测准确率为73.3%，F1分数为0.716。
### Conclusion
通过GlucoLens系统，能够实现餐后AUC和高血糖的预测，并提供可解释的治疗方案推荐，有助于个体通过调整治生活方式来预防高血糖的发生。该系统在五周的临床试验证明有效，具有较高的准确性和解释性。
## 610. `cs.LG` - EquiTabPFN: 一种目标置换协变先验网络 [PDF](https://arxiv.org/pdf/2502.06684), [HTML](https://arxiv.org/abs/2502.06684)
### Authors
Michael Arbel,David Salinas,Frank Hutter
### Background
最近的基于表格数据的基础模型，如TabPFN，擅长通过上下文内学习来适应新任务，但仍然受限于固定的、预先定义的输出维度数量——这往往需要代价高昂的组合策略。这一限制可以追溯到更深的架构缺陷：这些模型缺乏目标协变特性，因此目标维度的排列变化将影响其预测结果。这种缺陷导致了一个不可约简的“协变缺口”，它是预测中引人不安的误差项。
### Innovation
通过设计完全目标协变的架构来消除这个缺口——该架构通过协变编码器、解码器和双注意力机制确保排列的不变性。在标准的分类基准数据集上，对于包含比预训练中见过更多类别的数据集，本文模型在curring较低的计算开销的同时，匹配或超越了现有的方法。
### Conclusion
实验评估表明，与现有方法相比，我们的模型在数据集类别数多于预训练时能够达到或超过现有方法的效果，同时计算开销更低，这通过设计一种完全目标协变的架构来实现。
## 611. `cs.LG` - MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning [PDF](https://arxiv.org/pdf/2504.04164), [HTML](https://arxiv.org/abs/2504.04164)
### Authors
Shiguang Sun,Hanbo Zhang,Zeyang Liu,Xinrui Yang,Lipeng Wan,Xingyu Chen,Xuguang Lan
### Background
现有的基于视觉的模型强化学习（MBRL）算法在使用观察重建时常常会遇到信息冲突的问题，这使得难以学习紧凑的表示，从而导致策略不够稳健，特别是在存在与任务无关的视觉干扰时更加明显。现有的视觉MBRL算法中的信息冲突源于视觉表示学习和潜在动态建模方面的信息论视角下的问题。
### Innovation
该研究揭示了当前视觉MBRL算法中信息冲突的根源，并提出了一个名为MInCo的新算法，通过利用无负样本的对比学习来缓解信息冲突，有助于在噪声观察下学习不变表示和稳健策略。此外，还引入了随时间变化的加权，以在训练过程中偏向动力学建模，防止视觉表示学习的主导地位。该方法已在具有动态背景干扰的多个机器人控制任务上进行了评估，证明MInCo能够在背景噪声中学习不变表示，并且在视觉MBRL领域中表现出色，超过了当前最先进的视觉MBRL方法。
### Conclusion
实验结果表明，MInCo能够学习对抗背景噪声的不变表示，并且在所有测试的机器人控制任务中都比当前最先进的视觉MBRL算法表现更好。此方法的代码可在提供的链接中获取。
## 612. `cs.LG` - 硬件和软件平台推断 [PDF](https://arxiv.org/pdf/2411.05197), [HTML](https://arxiv.org/abs/2411.05197)
### Authors
Cheng Zhang,Hanna Foerster,Robert D. Mullins,Yiren Zhao,Ilia Shumailov
### Background
由于大型语言模型（LLM）推理需要大量的硬件基础设施和能源成本，购买LLM推理服务已成为一个常见的商业实践。然而，作为买家，没有机制来验证广告服务的真实性，包括运行硬件平台，例如是否实际上使用的是NVIDIA H100。此外，据报道，模型供应商可能会提供与宣传略有不同的模型，通常是让其在更便宜的硬件上运行。因此，客户为一个高性能模型访问支付了高价，却可能最终只获得了在更便宜硬件上运行的（可能是性能较差的）模型。这篇论文介绍了硬件和软件平台推断（HSPI）——一种基于模型输入-输出行为识别底层GPU架构和软件堆栈的方法。HSPI利用不同GPU架构和编译器的固有差异来区分不同的GPU类型和软件堆栈。通过分析模型输出中的数字模式，我们提出了一种分类框架，能够准确识别用于模型推理的GPU类型以及底层软件配置。研究结果表明，从黑盒模型中推断GPU类型是可行的。在不同实际硬件上运行模型的白盒环境中评估HSPI，结果显示在不同情况下准可以达到83.9%到100%的准确性。即使在黑盒环境中，HSPI的结果也比随机猜测高出3倍以上。相关代码已发布在指定链接。
### Innovation
这篇论文提出了一种新的方法——硬件和软件平台推断（HSPI），可以只通过分析模型的输入输出行为来识别底层GPU架构和软件堆栈。这种方法利用了各种GPU架构和编译器的固有差异，即使在黑盒模型中也可以实现较高的准确率，甚至高出随机猜测3倍以上。
### Conclusion
研究表明，通过HSPI方法，可以有效地识别黑盒模型中所使用的GPU类型及其背后的软件配置。在白盒环境中，HSPI可以实现高达100%的识别准确率，即使在黑盒环境中，也能达到随机猜测无法比拟的准确度。相关代码已经开源发布。
## 613. `cs.LG` - 电路调谐：一种识别参数冗余和微调神经网络的机制化方法 [PDF](https://arxiv.org/pdf/2502.06106), [HTML](https://arxiv.org/abs/2502.06106)
### Authors
Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang
### Background
机制可解释性的研究旨在从反向工程的角度解释模型的行为。虽然近期的研究关注于某些行为的静态机制，但模型内部的学习动态仍然有待探索。本文旨在开发一种可解释的微调方法来分析学习背后的机制。通过引入节点级固有维数的概念来描述计算图中的学习过程，提出了一种名为电路调谐的两阶段算法，该算法通过迭代构建特定任务的最小子图，并在启发式方式下更新关键参数。实验结果验证了节点级固有维数的存在，并展示了该方法在透明和可解释微调方面的有效性。在微调前后可视化并分析电路，提供了对神经网络在学习过程中自我组织机制的新见解。
### Innovation
本文提出了电路调谐方法，这是一种可解释的微调方法，能够在计算图中描述学习过程，并通过两阶段算法迭代构建最小子图来更新关键参数。该方法通过可视化电路在微调前、中、后进行分析，提供了对神经网络学习过程中的自我组织机制的新见解。这种方法强调了在模型微调中识别和减少参数冗余的重要性，从而提高模型的透明性和可解释性。
### Conclusion
电路调谐方法证实了节点级固有维数的存在，并显示了其在透明可解释微调中的有效性。该方法为理解神经网络在学习过程中的自我组织机制提供了新视角，并为识别和减少参数冗余提供了一种机制化方法。
## 614. `cs.LG` - 交错吉布斯扩散：生成具有的含义约束的离散-连续数据 [PDF](https://arxiv.org/pdf/2502.13450), [HTML](https://arxiv.org/abs/2502.13450)
### Authors
Gautham Govind Anil,Sachin Yadav,Dheeraj Nagaraj,Karthikeyan Shanmugam,Prateek Jain
### Background
大部分关于离散和离散-连续扩散的工作假设去噪分布的可分解性，这在解决具有重要、隐含和未指定约束的数据问题时可能限制了对随机变量之间强依赖关系的建模能力。
### Innovation
介绍了一种新颖的生成建模框架——交错吉布斯扩散（IGD），它将离散时间吉布斯采样类型的马尔可夫链推广到离散-连续生成的场景中，允许离散和连续降噪器之间的无缝集成，提供降噪器的选择灵活性，可以通过状态空间加倍进行条件生成，并在推断时间进行细化。IGD 在无需依赖领域特定的归纳偏差如对称扩散或辅助损失的情况下，实现了在三个具有挑战性的生成任务（分子结构、布局和表格数据）上的最新性能。
### Conclusion
交错吉布斯扩散通过探索广泛的数据建模策略和交织策略以及在每个问题中的超参数，在三个具有挑战性的生成任务中实现了最先进的性能。
## 615. `cs.LG` - 可靠的目标导向设计算法选择方法 [PDF](https://arxiv.org/pdf/2503.20767), [HTML](https://arxiv.org/abs/2503.20767)
### Authors
Clara Fannjiang,Ji Won Park
### Background
该研究背景在于利用机器学习引导的设计算法通过预测性建议新型物体以实现特定属性值。但这需要用户做出一系列选择，如设计算法、超参数、预测或生成模型等。如何确保这些选择使得最终设计方案成功成为挑战。本文探讨了如何选择能够生成满足用户指定成功标准的设计算法的方法，即至少达到某种程度的属性值，通过结合预测属性值和保留标注数据来预测不同设计算法生成的设计标签分布特征，这种方法依赖预测驱动的推理技术。该方法在已知或估计分布密度比值的情况下，以高概率确保返回能够满足成功标准的设计算法（或若不存在则为空集）
### Innovation
本文提出了一个可靠的目标导向设计算法选择方法，结合预测属性值与保留标注数据来预测不同设计算法生成的设计标签分布，这种方法建立了在预测驱动推理技术的基础上。若已知或估计了分布密度比值的模型，则该方法有高概率确保返回能够满足成功标准的设计算法（或若不存在则为空集）
### Conclusion
该方法在模拟的蛋白质和RNA设计任务中均证明了其有效性，特别是在知道或能够估计密度比值的情况下，该方法能以高概率返回能够满足成功标准的设计算法。
## 616. `cs.LG` - 神经图匹配在分子机器学习中改善检索增强生成 [PDF](https://arxiv.org/pdf/2502.17874), [HTML](https://arxiv.org/abs/2502.17874)
### Authors
Runzhong Wang,Rui-Xi Wang,Mrunali Manjrekar,Connor W. Coley
### Background
分子机器学习受到了几何深度学习进步的推动，同时检索增强生成已成为与语言模型常用的一种原则性方法。然而，如何将检索增强优化地集成到分子机器学习中仍然不明确。图神经网络可以通过巧妙匹配来理解检索分子与查询分子的结构对齐，而神经图匹配通过明确建模两个结构图之间节点和边的亲和力，结合噪声鲁棒的端到端神经网络来学习亲和力度量，提供了一个非常有说服力的解决方案。研究者将这一方法应用于质谱仿真实验，通过整合神经图匹配来增强基于碎片化的神经网络，提出了MARASON。
### Innovation
研究引入了一种新的模型MARASON，该模型结合了神经图匹配技术，以提高基于碎片化的神经网络的性能。这种方法使得MARASON在理解质谱仿真时达到了28%的顶级准确度，显著优于无检索状态最先进模型的19%准确度。此外，实验结果表明，MARASON的表现超过了简单的检索增强生成方法以及其他传统的图匹配方法，展示了神经图匹配对增强检索增强生成在分子机器学习中的潜力。
### Conclusion
研究通过引入MARASON模型，展示了将神经图匹配技术应用于分子机器学习的潜力，该模型在质量和高准确率方面显著超越了现有方法。神经图匹配通过明确建模节点和边的亲和力，以及鲁棒的端到端神经网络，为优化检索增强生成提供了新的思路。
## 617. `cs.LG` - Gateformer：通过带门控表示的时间和变异关注提高多元时间序列预测 [PDF](https://arxiv.org/pdf/2505.00307), [HTML](https://arxiv.org/abs/2505.00307)
### Authors
Yu-Hsiang Lan,Eric K. Oermann
### Background
近年来，使用Transformer架构进行时间序列建模的兴趣激增。然而，利用Transformer进行多元时间序列预测带来了一个独特的挑战，因为它需要同时建模时间维度（跨时间）和变量维度（跨变量）的依赖关系。尽管基于Transformer的模型因其在捕捉时间序列和跨变量关系上的灵活性而备受欢迎，但如何在Transformer架构中最好地整合这两种信息源以优化性能和效率仍不清楚。本文重新利用Transformer架构，以有效建模跨时间与跨变量依赖关系。
### Innovation
作者提出了一种新的方法，通过独立嵌入每个变量来捕获其跨时间动态，然后通过这些学习的嵌入上的注意力机制建模跨变量依赖关系。在跨时间与跨变量建模阶段使用门控操作来调节信息流，使模型能够专注于预测中最相关的特征。该方法在13个真实数据集上达到了最新技术水平，并且可以无缝集成到其他基于Transformer和基于LLM的预测器中，性能提高了最大20.7%。代码可在GitHub上找到：this https URL
### Conclusion
本文提出的方法在多个实际数据集上达到了最先进的性能，并且表现出对其他模型的改进。
## 618. `cs.LG` - 具有转化代理的富有表现力的神经架构搜索空间 [PDF](https://arxiv.org/pdf/2504.12971), [HTML](https://arxiv.org/abs/2504.12971)
### Authors
Shiwen Qin,Gabriela Kadlecová,Martin Pilát,Shay B. Cohen,Roman Neruda,Elliot J. Crowley,Jovita Lukasik,Linus Ericsson
### Background
神经架构搜索（NAS）面临平衡探索富有表现力的广阔搜索空间与有效评估架构的效率之间挑战的问题。本研究基于上下文无关文法，探索了代理模型训练以改进此类富有表现力的NAS搜索空间中的搜索问题。研究表明，无论通过零成本代理度量和神经图特征（GRAF）进行训练，还是通过微调现成的语言模型，代理模型都具有很高的性能预测能力，能够在同一和不同数据集内和外预测架构性能；这些代理还可以在探索新数据集时筛选掉不良架构，从而显著加快搜索过程并获得更好的最终性能；此外，这些代理还可以直接作为搜索目标，实现巨大加速。
### Innovation
通过训练代理模型以预测不同类型数据集上的架构性能，来简化和加速神经架构搜索（NAS）过程。特别是，该研究发现代理模型在筛选不良架构和加速搜索方面非常有效，尤其是在探索新数据集时。此外，代理模型可以直接用作搜索目标以实现巨大的加速效果。这一创新有助于提高NAS领域中架构搜索的效率和可扩展性。
### Conclusion
研究表明，当在相应代理模型的帮助下进行搜索时，可以快速地从巨大搜索空间中找到具有更好性能的高质量模型，从而显著提高了NAS搜索的效率；特别地，代理模型可以直接用作搜索目标，从而大幅提高搜索速度。
## 619. `cs.LG` - 基于浅冰近似理论的物理与神经网络集成方法模拟冰流动力学 [PDF](https://arxiv.org/pdf/2504.08136), [HTML](https://arxiv.org/abs/2504.08136)
### Authors
Kapil Chawla,William Holmes
### Background
该研究利用Physics-Informed Neural Network (PINN)方法模拟受浅冰近似理论（SIA）支配的冰层动力学。先前的工作使用了PINN方法来解决稳态障碍问题，而本文将其扩展到时间依赖的问题。通过1D和2D模拟的全面验证，模型在捕捉复杂自由边界的效用得到验证。这种方法结合了传统的数学建模和先进的深度学习技术，为预测冰层厚度随时间的变化提供了一个可扩展和稳健的解决方案。研究还通过模拟德文冰帽的动力学来说明该方法在实际应用场景中的应用，利用了2000年和2018年的航空气象数据。
### Innovation
该研究的创新之处在于利用PINN方法解决了浅冰近似理论下的时间依赖障碍问题，并通过综合传统数学建模和深度学习技术，提供了预测冰层厚度随时间变化的可扩展和稳健的方法。此外，研究通过实际应用（德文冰帽的动态模拟）展示了此方法的有效性。
### Conclusion
该方法在捕捉冰层自由边界条件以及预测冰层厚度随时间的变化方面具有有效性。通过将其应用于德文冰帽的实例，进一步验证了其在实际应用中的可行性和可用性。
## 620. `cs.LG` -  significativity indices for agreement values [PDF](https://arxiv.org/pdf/2504.15325), [HTML](https://arxiv.org/abs/2504.15325)
### Authors
Alberto Casagrande,Francesco Fabris,Rossano Girometti,Roberto Pagliarini
### Background
一致性测量指标（如Cohen's kappa或内部一致性相关性）用于评估两个或多个分类器之间的匹配程度。这些指标在医学、人工智能等多个领域广泛应用，从评估治疗方法的有效性到量化分类器简化后的接近程度。通过这些测量指标在金标准下的排序，可以简单地比较不同分类器到金标准的一致性。然而，仅通过使用一致性测量指标的值来评判方法的好坏需要一个量表或显著性指数。虽然已经有一些建议用于Cohen's kappa的质量量表，但它们通常是原始的，其边界是任意设定的。
### Innovation
本文提出了评估任意两个分类器之间一致性值显著性的一种通用方法，并引入了两个显著性指数：一个是处理有限数据集的，另一个是处理分类概率分布的。此外，本文还探讨了评估这些指数的计算挑战，并提出了一些高效算法进行评估，
### Conclusion
通过测量和评估一致性指标的显著性，研究提供了一种有效的方法来量化分类器之间的差异，有助于提高评估过程的科学性和准确性，特别是在医学和人工智能领域。
## 621. `cs.LG` - 评估前沿模型的隐蔽性和情境意识 [PDF](https://arxiv.org/pdf/2505.01420), [HTML](https://arxiv.org/abs/2505.01420)
### Authors
Mary Phuong,Roland S. Zimmermann,Ziyue Wang,David Lindner,Victoria Krakovna,Sarah Cogan,Allan Dafoe,Lewis Ho,Rohin Shah
### Background
近期研究已表明，先进的人工智能模型可能故意或秘密追求与其开发者意图不一致的目标。这种行为可能难以检测，如果在未来的高级系统中存在，可能会带来严重的失控风险。因此，在模型部署之前，AI开发者需要排除因意图偏差导致的潜在危害。本文提出了一套评估模型推理能力的方案，旨在检测模型是否有可能通过意淫方式造成严重危害。
### Innovation
本文提出了两种推理能力的评估，一是模型避免被监督的能力（隐藏性），二是模型对自己的环境和部署情况进行战略性推理的能力（情境意识）。通过这些评估可以为模型的安全性构建不能意图偏差导致危害的论证。评估结果表明，当前的前沿模型在隐藏性和情境意识方面均未显示出令人担忧的水平。
### Conclusion
我们的研究表明，当前的前沿模型在情境意识和隐藏性方面都不足以通过意淫方式造成严重危害。这些评估可以在部署模型之前帮助开发者确保模型的行为符合预期，从而降低因意外目的导致的风险。
## 622. `cs.LG` - 多变量布 submergedn 曲线图：一种时间序列预测的符号图框架 [PDF](https://arxiv.org/pdf/2505.22768), [HTML](https://arxiv.org/abs/2505.22768)
### Authors
Mert Onur Cakiroglu,Idil Bilge Altun,Mehmet Dalkilic,Elham Buxton,Hasan Kurban
### Background
时间序列预测对于基础模型仍然是一项具有挑战性的任务，原因在于时间的异质性、高维度以及缺乏固有的符号结构。现有的模型在处理这些挑战时面临困难。因此，需要一种能够结合符号表示和神经建模的新方法来提高时间序列预测的性能。
### Innovation
本文提出了一种名为DRAGON的新颖编码器，即离散表示和增强图编码超过布 submergedn 曲线图（MdBGs）。DRAGON通过将连续输入序列离散化并映射到固定图结构来构建，从而通过基于图的注意力机制实现动态上下文恢复。该模块作为辅助模块集成在双分支架构中，增强了传统的基于CNN的编码器，使其具备符号意识的结构表示能力。
### Conclusion
通过引入MdBGs，DRAGON能够有效结合符号表示和神经模型，以应对时间序列预测中的挑战。该方法作为辅助模块存在于双分支结构中，提升了传统基于CNN的编码器的功能，通过基于图的注意力机制实现了动态上下文恢复。该研究的所有代码可从 this https URL 获取。
## 623. `cs.LG` - 在神经科学中生成动态因果图的假设：利用观测时间序列生成因子模型 [PDF](https://arxiv.org/pdf/2505.20697), [HTML](https://arxiv.org/abs/2505.20697)
### Authors
Zachary C. Brown,David Carlson
### Background
假设生成领域有望通过缩小需要进行干预研究的范围，从而降低神经科学研究的成本。现有的机器学习方法可以从复杂的数据集中生成科学假设，但许多方法假设因果关系在时间上是静态的，限制了对动态、状态依赖行为系统的适用性，如大脑。虽然一些技术试图通过因子模型进行动态因果发现，但它们通常将关系限制为线性模式或其他简化假设。
### Innovation
提出了一种新颖的方法，该方法将动态图建模为静态图的有条件的加权叠加，每个静态图可以捕捉非线性关系。这种方法使得能够检测超出线性限制的复杂、随时间变化的变量交互。在一些实验中，我们的方法平均提高了基准模型预测的动态因果模式的F1分数22-28%，有些改进甚至超过了60%。在真实的大脑数据上的案例研究证明了该方法能够揭示与特定行为状态相关的关系，提供了关于神经动力学的重要见解。
### Conclusion
该方法在某些实验中提高了预测动态因果模式的F1分数，最高超过60%；并通过在真实脑部数据的案例研究中展示了识别特定行为状态相关关系的能力，为神经动态学的研究提供了重要见解。
## 624. `cs.LG` - 向解释性特征嵌入比较与对齐迈出一步 [PDF](https://arxiv.org/pdf/2506.06231), [HTML](https://arxiv.org/abs/2506.06231)
### Authors
Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia
### Background
虽然文献中已经开发了多种特征嵌入模型，但这些嵌入的比较主要集中在它们在分类相关的下游应用中的数值性能。然而，为了进行可解释的比较，需要识别和分析嵌入空间中聚类样本组之间的不匹配。因此，这项工作提出了一种新的框架——光谱成对嵌入比较（SPEC），用于比较嵌入并识别它们在聚类参考数据集时的差异。
### Innovation
该研究引入了一种基于核的方法的可扩展实现，其计算复杂性随着样本量线性增长。此外，研究还提出了一个优化问题来使两个嵌入对齐，确保一个嵌入中识别的簇也在另一个模型中被捕获。研究提供了在大规模数据集如ImageNet和MS-COCO上应用SPEC进行比较和对齐的数值结果。
### Conclusion
研究通过SPEC在比较和对齐特征嵌入方面取得进展，特别是在大规模数据集上的应用验证了其有效性和适用性。
## 625. `cs.LG` - 基于天际线解释的图推理解读 [PDF](https://arxiv.org/pdf/2505.07635), [HTML](https://arxiv.org/abs/2505.07635)
### Authors
Dazhuo Qiu,Haolai Che,Arijit Khan,Yinghui Wu
### Background
图机器学习模型如图神经网络（GNNs）常用于各种网络分析任务，而这些模型的输出往往难以全面解释。现有方法通常会基于某种单一的可解释性指标（如忠实性）进行解释，这可能导致解释片面，存在偏差。因此，本文提出了天际线解释这一新范式，它通过同时优化用户感兴趣的多种解释性度量来解释GNN的输出。文章设计了一系列算法来高效实现天际线解释，并探索了并行算法以实现大规模应用的效果验证。
### Innovation
1. 提出了天际线解释的概念，将其定义为在多个解释性度量中占优的子图集合。2. 将天际线解释建模为多目标优化问题，并分析了其难度。3. 设计了洋葱皮方法的高效算法，以逐步构建天际线解释。4. 开发了多样化算法以丰富解释内容。5. 引入了负载均衡策略的高效并行算法，以扩展天际线解释的应用范围。6. 使用真实和合成数据集验证了所提算法的有效性和可扩展性。
### Conclusion
本文提出了天际线解释方法，通过优化多种解释性度量来提供GNN输出的综合解释。通过设计有效算法和并行策略，实现了对大规模图神经网络推理问题的可解释解释。实验结果验证了该方法的有效性和可扩展性。
## 626. `cs.LG` - Reliability-Adjusted Prioritized Experience Replay [PDF](https://arxiv.org/pdf/2506.18482), [HTML](https://arxiv.org/abs/2506.18482)
### Authors
Leonard S. Pleiss,Tobias Sutter,Maximilian Schiffer
### Background
经验重放是一种在在线强化学习代理中高效利用过去经验的方法。传统的方法是从回放缓冲区中均匀采样经验，而忽略不同经验的学习潜力差异。为了更高效地采样，研究人员引入了优先级经验重放（PER），通过给予更有意义的经验更高的采样概率来实现更加有效的学习。
### Innovation
本文提出了PER的改进版本——可靠度调整优先级经验重放（ReaPER），通过引入一个新颖的时间差误差可靠度衡量标准，增强了经验重放的有效性。研究表明，ReaPER在多种环境类型下比PER具有更好的性能，尤其是在Atari-10基准测试中得到了验证。
### Conclusion
本文提出了一种新的经验重放方法——Reliability-adjusted Prioritized Experience Replay (ReaPER)，并通过理论分析和实验证明其在高效学习方面优于传统的Prioritized Experience Replay (PER) 方法。
## 627. `cs.LG` - 方枘圆凿：长尾半监督学习中的元专家 [PDF](https://arxiv.org/pdf/2505.16341), [HTML](https://arxiv.org/abs/2505.16341)
### Authors
Yaxin Hou,Yuheng Jia
### Background
本文研究了分布不匹配的长尾半监督学习（LTSSL），其中标记训练数据中的类别分布呈现长尾型，但却与未标记训练数据中的类别分布不匹配。现有的大多数方法通过引入辅助分类器（专家）来建模各种未标记数据分布，并生成伪标签，但是这些方法并没有充分利用各类专家的特长。研究表明不同专家在预测样本的不同区间上表现出色，例如长尾专家擅长预测头部区间样本，均匀分布专家则擅长尾部区间样本。因此，本文提出了一种动态专家分配模块以估计样本类别（头部、中间或尾部类别），并根据估计的类别动态分配合适的专家来生成高质量的伪标签和进行预测，从而在训练和测试阶段提高模型性能。同时，本文理论分析表明整合不同专家的优势将导致更小的泛化误差边界。此外，发现深层特征虽更偏向头部类别，但也更具判别性；而浅层特征则不偏向任何类别，但判别性能力较弱。因此，本文提出了一种多深度特征融合模块，利用不同深度特征来缓解模型偏差。
### Innovation
1. 提出了一种动态专家分配模块，能够估计样本的类属（头部、中间或尾部类别），并动态分配合适的专家，生成高质量的伪标签和进行预测。2. 通过理论分析证明了整合不同专家的优势能够降低泛化误差边界。3. 深入分析了不同深度特征的偏见和判别性能力，提出了多深度特征融合模块以更有效地利用各个特征层的信息，缓解模型偏差。4. 提供了该方法在CIFAR-10-LT、STL-10-LT和SVHN-LT数据集上的全面实验结果，表明了该方法的有效性。
### Conclusion
本文提出了一种新的动态专家分配机制，通过充分利用不同专家的优势，有效地提高了长尾分布下的半监督学习性能。实验结果表明该方法在各种数据集上具有良好的效果，并且多深度特征融合模块能够更好地缓解模型偏差，提升模型的泛化能力。该方法为解决长尾分布下的半监督学习问题提供了一种新的思路。
## 628. `cs.LG` - 通过强化学习优化冻结的LLM：迭代重新加权-优化方法 [PDF](https://arxiv.org/pdf/2506.17828), [HTML](https://arxiv.org/abs/2506.17828)
### Authors
Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong
### Background
通常通过细调方法如RLHF和DPO来调整大型语言模型（LLMs）与人类偏好的一致性，这些方法直接优化模型参数，因此无法在测试时提高模型性能，也不能在模型权重不可访问时使用。相比之下，测试时的方法通过利用奖励函数引导和提升输出质量，但会产生高昂的推理成本，并且它们的一次性指导往往基于不完美的奖励或价值函数，导致输出不够优化。这项工作提出了一个名为迭代重新加权-优化（IRO）的方法，这是一种强化学习框架，可以在不更改基模型参数的情况下对（冻结）基模型进行RL风格的对齐。在训练过程中，每一轮迭代会从基模型中采样候选样本，重新采样并训练新的轻量级价值函数来指导下一轮解码过程。在测试时，使用这些价值函数通过基于搜索的优化过程引导基础模型生成内容。值得注意的是，用户可以应用IRO在自己的数据集上对齐模型，类似于OpenAI的强化细调（RFT），但无需访问模型权重。
### Innovation
该研究提出了一种名为Iterative Reweight-then-Optimize (IRO) 的方法，这是一种强化学习框架，可以在不直接修改基础模型参数的情况下对(冻结)基础模型进行RL风格的对齐。此方法在训练过程中通过迭代重新加权和优化来提升模型性能，而在测试时利用价值函数优化基础模型的生成过程，显著降低了对模型权重的依赖，增加了灵活性和实用性。
### Conclusion
通过IRO方法，用户可以自主在其数据集上对模型进行对齐调整，类似于OpenAI的强化细调（RFT），但无需访问模型的权重。这种方法提高了对齐过程的灵活性和实用性，同时避免了对现有模型进行直接参数调整所带来的限制。
## 629. `cs.LG` - 高性能Spot机器人上的强化学习：使用分布度量优化仿真参数 [PDF](https://arxiv.org/pdf/2504.17857), [HTML](https://arxiv.org/abs/2504.17857)
### Authors
AJ Miller,Fangzhou Yu,Michael Brauckmann,Farbod Farshidian
### Background
本文介绍了高斯的强化学习策略部署技术细节，利用Boston Dynamics的Spot机器人底层电机访问结合Spot RL Researcher Development Kit。这是首次公开展示在Spot硬件上端到端的强化学习策略部署，具有公开的训练代码（通过Nvidia IsaacLab）和部署代码（通过Boston Dynamics）。通过使用Wasserstein距离和最大均差量化硬件和仿真数据分布差异，来衡量我们的模拟与实际环境间的差距，并以此作为Covariance Matrix Adaptation Evolution Strategy的评估函数来优化Spot未知或难以测量的仿真参数。这为企业级复制现实世界中的机器人行为提供了新的解决方法，优化了特定硬件上的策略参数，使其在复杂环境中有更好的适应性。
### Innovation
本文创新之处在于首次公开展示了在Boston Dynamics的Spot机器人上进行从模拟到现实的全方位强化学习策略部署，并且公开了训练和部署代码。通过使用Wasserstein距离和最大均差量化硬件与模拟数据之间的分布差异，优化了仿真中的关键参数。实现了高精度、高质量、多步态的强化学习策略，包括飞行阶段，展示了超过5.2毫秒的移动速度，远超Spot默认控制器的速度，并且具有良好的抗滑面干扰能力，具备出色的灵敏度和灵活性。这代表着在Spot机身上前所未有的卓越性能。
### Conclusion
本文研究了Spot机器人在引出的加强学习策略上如何运用分布度量优化仿真参数，并详细介绍了其方法，展示了优化前后的显著性能差异。我们公开了相关代码，以支持更多关于Spot的研究工作，尤其是与其低级API相关的研究。这项工作不仅促进了机器人运动控制和强化学习研究的发展，也为其他特定硬件的改进和优化提供了新的思路。
## 630. `cs.LG` - 基于梯度的模型指纹用于LLM相似性检测和家族分类 [PDF](https://arxiv.org/pdf/2506.01631), [HTML](https://arxiv.org/abs/2506.01631)
### Authors
Zehao Wu,Yanjie Zhao,Haoyu Wang
### Background
随着大型语言模型（LLMs）成为现代应用中的关键软件组件，未经授权的模型衍生（如微调、合并和再分发）已成为重要的软件工程挑战。不同于传统软件，其中克隆检测和许可证合规性已经建立，LLM生态系统缺乏有效机制来追踪模型血统和强制执行许可证协议。特别是在开源模型创作者如Meta的LLaMA需要衍生作品保持命名约定以供归因时，却没有技术手段来验证合规性。
### Innovation
为了弥合这个空白，我们将LLMs视为需要唾阶段溯源的软件构件，提出了TensorGuard，这是一种基于梯度的指纹框架，用于检测和分类LLM相似性及家族。该框架通过分析随机输入扰动在张量层的梯度响应提取模型固有的行为指纹。TensorGuard支持常用的安全张量格式，通过统计分析梯度特征构建高维指纹。这些指纹能够通过距离计算直接进行任意模型的成对相似性评估，此外，通过K-Means聚类算法系统地分类未知模型，带有由已知基模型引导的聚类中心初始化。实验结果显示，在对包含8个基模型和50个衍生模型、涉及五大家族（Llama、Qwen、Gemma、Phi、Mistral）的58个模型进行测试后，分类准确率达到了94%。
### Conclusion
实验研究证明，TensorGuard能够高效地识别和分类LLM模型，支持模型血液追溯并有效防止未经授权的模型衍生。
## 631. `cs.LG` - ODE_t(ODE_l): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling [PDF](https://arxiv.org/pdf/2506.21714), [HTML](https://arxiv.org/abs/2506.21714)
### Authors
Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer
### Background
近期，连续正则化流（CNFs）和扩散模型（DMs）被用统一的理论框架进行研究。尽管这些模型可以从噪声分布生成高质量的数据点，但由于在抽样过程中需要多次迭代求解常微分方程（ODE），计算复杂性较高。现有的大多数方法集中于在采样过程中减少时间步数以提高效率。
### Innovation
本文探索了一种新的方向，在时间步数和神经网络长度方面动态控制质量-复杂度权衡。通过将基于变压器的架构中的块重新布线来解决与长度相关的内部离散化ODE，然后在流匹配训练期间使用时间上和长度上的一致性项，最终可以在任意时间步数和变压器块数量下进行采样。我们的方法在时间维度上对求解器是无感知的，减少了延迟和内存使用。与之前最先进的方法相比，在高效率采样模式下的延迟降低了最多3倍，高質量采样的FID得分提高了最多3.5分。我们提供了可完全复现实验的代码和模型权重。
### Conclusion
本文提出了一种新颖的方法，通过在时间步数和神经网络长度上动态控制质量-复杂度权衡，实现了更快速的采样。不同于其他方法，该方法在时间维度上对求解器是无感知的，减少延迟和内存使用。实验结果表明，在最高效的采样模式下，延迟最多减少了3倍，高質量采样的FID得分提高了最多3.5分。
## 632. `cs.LG` - 会员推理攻击作为隐私工具：可靠性、差异和集成 [PDF](https://arxiv.org/pdf/2506.13972), [HTML](https://arxiv.org/abs/2506.13972)
### Authors
Zhiqi Wang,Chengyu Zhang,Yuetian Chen,Nathalie Baracaldo,Swanand Kadhe,Lei Yu
### Background
会员推理攻击（MIAs）对机器学习模型的隐私构成了重大威胁，并被广泛用作隐私评估、审计和机器遗忘的工具。尽管先前的MIA研究主要集中在性能指标如AUC、准确率和低FPR下的TPR上，要么开发新方法以提高这些指标的性能，要么用它们来评估隐私解决方案，但这种研究忽视了不同攻击之间的差异性。这种差异既存在于不同的攻击方法之间，也存在于同一方法的不同实例之间。这些差异对MIAs作为隐私评估工具的可靠性和完整性具有重要意义。
### Innovation
本文提出了一个新颖的框架，基于覆盖和稳定性分析，系统地研究了这些差异。广泛的实验揭示了MIAs的重要差异及其潜在原因，以及它们对隐私评估的更广泛影响。为此，提出了一种集成框架，包括三个不同的策略，这些策略不仅利用了最先进的MIAs的优点，同时还考虑了它们之间的差异。这种框架不仅使更强大的攻击得以构建，而且为隐私评估提供了一个更稳健和全面的方法论。
### Conclusion
通过这一集成框架，本文找到了利用最先进的MIAs的优势并考虑其差异的方法。该框架不仅使更强大的攻击成为可能，还为隐私评估提供了一个更稳健和全面的方法。这些发现揭示了MIAs在隐私评估中的重要差异及其更广泛的影响。
## 633. `cs.LG` - 四十年来的人口迁移深度学习 [PDF](https://arxiv.org/pdf/2506.22821), [HTML](https://arxiv.org/abs/2506.22821)
### Authors
Thomas Gaskin,Guy J. Abel
### Background
该研究提供了一个覆盖230个国家和地区，包含从1990年至今年度迁移流动和存量的详尽数据集。这些估计数据通过训练一个包含地理、经济、文化、社会和政治信息在内的18个协变量的深度循环神经网络得到，使得过去的全部信息都能影响当前的迁移模式，从而学习长时序的相关性。通过训练神经网络的集成并同时将协变量的不确定性推入训练网络，该研究能够为所有估计提供置信区间，使得研究者可以确定哪些地理区域最需要额外的数据收集。该方法已在多种未见过的数据集上进行了验证，表明它在估计五年流动时明显优于传统方法的同时还大幅提高了时间分辨率。所有训练数据、神经网络权重及训练代码均公开提供，构成未来研究人类迁移的重要资源。
### Innovation
该研究的创新之处在于利用深度循环神经网络对过去的全时序信息进行学习，从而得到长期趋势的迁移估计。此外，通过训练神经网络的集成，并同时将协变量的不确定性推入训练网络，可以为所有估计提供置信区间。该方法还在时间分辨率上取得了显著提升，并且在约35年的迁移数据估计中，其性能显著优于传统方法。这些公开的数据和代码提供了一个有价值的研究资源。
### Conclusion
该研究通过深度学习方法提供了四十年来全球大规模的人口迁移数据集，并具备高时间分辨率的估计。通过验证，说明该方法在预测年度迁移流方面具有优良性能，能够提供置信区间，助力未来研究中的数据收集和分析。所有相关数据和代码的公开发布为后续研究提供了宝贵的资源。
## 634. `cs.LG` - LLM预训练中Grokking的发现？监测从记忆到泛化的过程无需测试 [PDF](https://arxiv.org/pdf/2506.21551), [HTML](https://arxiv.org/abs/2506.21551)
### Authors
Ziyue Li,Chenrui Fan,Tianyi Zhou
### Background
近期在神经网络训练中观察到的现象——训练损失收敛之后性能测试仍持续提升（称为Grokking），使得模型泛化机制和其他新型能力（如推理）变得更加神秘。以往研究通常在少量玩具任务或高度特定任务上训练小型模型数千个epochs。本文首次在大规模预训练语言模型（如7B参数的LLM，即OLMoE）的一个pass中检查Grokking。通过计算训练损失并评估不同基准任务上的泛化性能，首次验证大规模预训练模型中也存在Grokking现象，尽管不同数据可能异步进入Grokking阶段。
### Innovation
研究创新地分析了大规模预训练模型（LLM）的预训练过程中的Grokking现象，揭示了模型内部动态，包括训练样本路径从随机、实例特定转变为更加结构化和可共享，并且即便训练损失收敛了，样本路径的复杂性亦会减少，这些现象表明了从记忆到泛化的“知识消化”，从而提供了延迟泛化的机械解释。此外，研究开发了两种新的度量标准来量化路径距离和单个路径的复杂性，这些度量有助于预测不同下游任务上的泛化改进，并且计算简单、依赖训练数据，因此提供了预训练阶段监测泛化性能的实用工具。理论上传导表明，更结构化的路径能降低模型复杂性并优化泛化边界。
### Conclusion
研究验证了大规模预训练模型中也存在Grokking现象，并通过分析模型内部动态解释了Grokking的“泛化能力的出现”。此外，研究提出了一种监测预训练阶段泛化性能的新方法，并提供了理论支持，即结构化路径能优化模型的泛化性能。
## 635. `cs.LG` - 在边缘网络中快速分割AI模型 [PDF](https://arxiv.org/pdf/2507.01041), [HTML](https://arxiv.org/abs/2507.01041)
### Authors
Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin(Sherman)Shen
### Background
分治学习(SL)已成为人工智能模型训练中计算高效的解决方案，可以缓解设备端的计算负担。然而，复杂的AI模型架构导致在获取最优模型分割时面临高计算复杂度的问题。该研究将任意AI模型表示为有向无环图(DAG)，并将其最优模型分割问题重新表述为最短s-t割搜索问题，提出了一个高效的基础结构分割算法，并针对具有块结构的AI模型，进一步提出了一种基于块的模型分割算法。这些算法能够在毫秒内确定最优模型分割，并在动态边缘网络中将训练延迟减少了24.62%-38.95%。与最先进的基准相比，这些算法显著提高了计算效率。
### Innovation
该研究提出了一个高效的DAG基础结构分割算法，通过最大流法重构DAG以识别最优模型分割。针对具有块结构的AI模型，研究提出了一种基于块的分割算法，将每个块（即由多个层组成的组件）抽象为单个顶点，从而简化了DAG，降低了计算复杂度。实验结果表明，提出的方法能够在毫秒内确定最优模型分割，并减少了训练延迟。
### Conclusion
提出的算法能够在毫秒内确定最优模型分割，并且在动态边缘网络中的训练延迟降低了24.62%-38.95%。
## 636. `cs.LG` - 自我引导的过程奖励优化与重定义的步骤优势对于过程强化学习 [PDF](https://arxiv.org/pdf/2507.01551), [HTML](https://arxiv.org/abs/2507.01551)
### Authors
Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua
### Background
过程强化学习(PRL)在增强大型语言模型(LLM)的推理能力方面展现出了很大的潜力。然而，引入额外的过程奖励模型带来了巨大的计算开销，并且缺乏统一的理论框架来估计过程级的优势。
### Innovation
提出了自我引导的过程奖励优化(SPRO)框架，通过两大创新点解决了上述问题：首先，理论证明过程奖励可以内在地从策略模型中推导出来；其次，引入了明确的累积过程奖励和掩码步骤优势(MSA)，有助于在共享提示采样群体中进行严格的步骤优势估计。此外，SPRO没有额外的计算开销，与监督结果的RL方法（如GRPO）相当，更有利于工业实施。
### Conclusion
实验结果表明，SPRO在训练效率上比传统方法提高了3.4倍，在测试准确率上提高了17.5%。同时，SPRO在训练过程中保持了稳定的高策略熵，并降低了约1/3的平均响应长度，证明了足够的探索能力并防止了奖励挖掘。
## 637. `cs.LG` - 非负矩阵分解算法通常能提高主题模型的效果 [PDF](https://arxiv.org/pdf/2105.13440), [HTML](https://arxiv.org/abs/2105.13440)
### Authors
Peter Carbonetto,Abhishek Sarkar,Zihao Wang,Matthew Stephens
### Background
许多研究已经探讨了非负矩阵分解（NMF）与主题模型之间的关系，但尚未有人提出利用这种联系来开发新的主题模型拟合算法。NMF 通过避免主题模型参数的“和为一”约束，使得优化问题结构更简单，计算效率更高。研究者在基于最近优化算法的进展，表明首先解决NMF问题，然后恢复主题模型的拟合能够显著提高模型表现，并且耗时更少，相比标准的主题模型拟合算法。这种方法主要适用于最大似然估计，但也有望改善主题模型的变分推断。相关的实现已经集成到R包fastTopics中。
### Innovation
该研究的创新之处在于提出了一种新的方法，将NMF用于主题模型的参数估计，这与以往研究更注重于主题模型之间的直接联系不同。这种方法可以显著提高主题模型的拟合效果，并且计算效率更高。此外，该方法不仅适用于最大似然估计，也可以应用于主题模型的变分推断。所有这些方法都已经被实现为R包fastTopics中的功能。
### Conclusion
通过使用NMF算法，该研究提出了一种新的主题模型拟合方法，这种方法能够显著提高模型的效果并提升计算效率。这种方法在最大似然估计和变分推断中均有益处，且已被实现为R包fastTopics中的一部分。
## 638. `cs.LG` - GPAS: 通过梯度保存激活缩放加速大规模语言模型预训练收敛 [PDF](https://arxiv.org/pdf/2506.22049), [HTML](https://arxiv.org/abs/2506.22049)
### Authors
Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Lu Yin,Can Yang
### Background
现代大规模语言模型，如LLaMA、Qwen和DeepSeek系列，大多数采用预层标准化（Pre-LN）Transformer架构。虽然这种架构在预训练中表现出良好的稳定性并能扩展到大规模模型，但它存在逐层激活方差指数级增长的问题，导致残差连接中的捷径路径占主导地位，限制了深层网络的学习能力。
### Innovation
提出了一种名为梯度保存激活缩放（GPAS）的简单技术，其可以在现有方法的基础上使用。GPAS 通过缩放中间激活值同时保持梯度不变来工作，从而保留了激活中的信息，避免了梯度缩放导致的梯度消失问题。实验证明，GPAS 在从71M到1B不同规模的模型上实现了稳定的性能提升，不仅提高了 Pre-LN Transformer 的性能，还展示了其在改进Sandwich-LN和DeepNorm等替代架构中的潜力，表明其在多种场景中提高训练动态的通用性和潜力。
### Conclusion
实验证明，GPAS 实现了对各种规模模型的稳定性能改进，不仅改善了 Pre-LN Transformer 的性能，还具有跨不同架构的通用性。
## 639. `cs.LG` - 离散级别问题难度估计中的序数性：引入平衡DRPS和OrderedLogitNN [PDF](https://arxiv.org/pdf/2507.00736), [HTML](https://arxiv.org/abs/2507.00736)
### Authors
Arthur Thuy,Ekaterina Loginova,Dries F. Benoit
### Background
近年来，自然语言处理技术在问题难度估计（QDE）方面的兴趣日益增加。问题难度通常用离散级别表示，这需要通过序数回归来处理。然而，现有的文献大多数仅关注分类或分化的回归模型，而忽视了任务的序数性质，导致专门的序数回归方法未得到探索。此外，评估指标与建模范式紧密耦合，这妨碍了不同研究之间的可比性。尽管一些指标未能充分考虑难度级别的序数结构，但没有一种指标能够有效地解决类别不平衡，导致性能评估出现偏差。
### Innovation
本研究通过使用平衡的离散排名概率分数（DRPS）这一新型度量标准来解决这些问题，该标准能够同时捕捉序数性和类别不平衡。此外，研究还提出了一种名为OrderedLogitNN的方法，将经济学中的有序logit模型扩展到神经网络。并通过在RACE++和ARC数据集上微调BERT来演示该方法的有效性。
### Conclusion
平衡DRPS提供了一个稳健且公平的评估指标，用于离散级别的问题难度估计，为未来的研究提供了坚实的理论基础。OrderedLogitNN在复杂任务上表现出显著的优势。
## 640. `cs.LG` - 隐私保护的具有不同精度的量化联邦学习 [PDF](https://arxiv.org/pdf/2507.00920), [HTML](https://arxiv.org/abs/2507.00920)
### Authors
Dang Qua Nguyen,Morteza Hashemi,Erik Perrins,Sergiy A. Vorobyov,David J. Love,Taejoon Kim
### Background
联邦学习（FL）作为一种分布式机器学习范式，正在兴起。它允许多个本地设备不共享原始数据的情况下，共同训练全局模型。然而，FL面临一些挑战，如局部模型更新传输到融合中心时的安全风险和参与者设备在模型量化分辨率方面存在的异质性，这会导致学习效果下降。现有研究通常仅解决其中一个挑战，因为同时保证隐私和处理量化异质性是棘手的任务。
### Innovation
本文提出了一种新颖的随机量化器（SQ），可以同时实现差分隐私（DP）和最小量化误差。尤其重要的是，所提SQ能够保证量化失真受到限制。为了应对量化异质性，作者提出了一种集群大小优化技术结合线性融合方法来增强模型聚合准确性。论文通过数值模拟验证了与传统LaplaceSQ-FL算法相比，该方法在隐私保护和学习效果方面的优势。
### Conclusion
本文通过引入一种能够同时实现差分隐私和最小量化误差的新颖随机量化器，有效解决了隐私保护与处理量化异质性的挑战。结合集群大小优化技术和线性融合方法，进一步提高了模型聚合精度。数值模拟结果表明，该方法在保护隐私和提高学习效果方面优于传统方法。
## 641. `cs.LG` - 通过算法重新审视不稳定的公式定理 [PDF](https://arxiv.org/pdf/2212.05050), [HTML](https://arxiv.org/abs/2212.05050)
### Authors
Maryanthe Malliaris,Shay Moran
### Background
本文探讨了来自模型理论的基本结果——稳定性理论与学习算法稳定性之间的意外相互作用。现有的学习模型存在一些差距，因此作者引入了一个新的统计学习模型——所谓的“很可能最终正确”（Probably Eventually Correct, PEC）模型。通过将Littlestone稳定性类描述为这种模型中的定义，该论文进一步研究了Littlestone稳定性类.
### Innovation
本文通过引入新模型PEC，填补了现有学习模型的空白，并将Littlestone稳定性类用自然统计意义下的常见短定义进行表征。通过建立一种等价定理，指出许多现有的近似算法及新模型PEC之间的共同点。这篇论文借鉴了这些定理及其他近期工作的成果，提出了Shelah著名不稳定公式定理的算法类比，并且将算法性质放在了无限性的位置上来填补空白.
### Conclusion
本文通过算法的角度重新审视了Shelah的不稳定公式定理，并提出了其算法版本，诱导出Littlestone稳定性类的常见短定义，并展示了极大丰富了算法稳定性理论，扩展了模型理论中的类型定义类似物工具集.
## 642. `cs.LG` - PDE 联合反演问题的一种模型一致的数据驱动计算策略 [PDF](https://arxiv.org/pdf/2210.09228), [HTML](https://arxiv.org/abs/2210.09228)
### Authors
Kui Ren,Lu Zhang
### Background
从观测数据中同时重构多个偏微分方程(PDEs)中的物理系数是一个在实际应用中普遍存在的问题。本文提出了一种集成数据驱动和模型导向的迭代重构框架，用于解决此类涉及未知系数补充数据的联合反演问题，以提高重构效果。该方法将补充数据与PDE模型结合，使得数据驱动建模过程与模型导向的重构步骤一致。研究表明，学习不确定性对联合反演结果的两个典型反问题具有重要影响。数值证据表明，数据驱动模型能够提高PDE中多个系数的联合反演效果。
### Innovation
本文提出了一种集成数据驱动和模型导向的迭代重构框架。该方法通过将补充数据与PDE模型结合，使数据驱动建模过程与模型导向的重构步骤一致，从而提高联合反演的效果，并研究了学习不确定性对反演结果的影响。
### Conclusion
本文提供的数值证据表明，通过使用数据驱动模型，可以有效提高PDE中多个系数的联合反演效果。从而验证了该方法的有效性和创新性。
## 643. `cs.LG` - Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models [PDF](https://arxiv.org/pdf/2507.01201), [HTML](https://arxiv.org/abs/2507.01201)
### Authors
Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim
### Background
现有独立训练的视觉和语言模型占据了各自不同的表示空间，这些空间由各自的模态、目标和架构决定。然而，有一种新兴假设——柏拉图表示假设，提出这样的模型可能在统计上收敛于共享的现实模型。如果这种兼容性是存在的，它提出了一个根本性的问题：能否从后验的统计对齐检测转向直接优化这种不相交表示之间的对齐？
### Innovation
本文将柏拉图对齐问题定义为一个多目标优化任务，即在保持每个模态固有结构的同时实现相互一致性。提出了一个新的框架，Joint Autoencoder Modulator (JAM)，该框架通过在预训练单模态模型的潜在表示上联合训练模态特定的自动编码器来促进对齐，鼓励重建和跨模态目标。作者通过对比对比损失 (Con)、其硬负样本变体 (NegCon) 及一种扩展损失 (Spread loss)，评估了不同的对齐目标和层数以及基础模型规模对表示收敛的影响。结果显示，轻量级的Pareto高效框架可以可靠地诱导对齐，即使对于冻结的、独立训练的表示也适用。
### Conclusion
实验结果表明，提出的JAM框架可以可靠地促进独立训练的视觉和语言模型之间的对齐，提供了一种理论洞见和从通用单一模型向专业多模态模型转变的实践路径。
## 644. `cs.LG` - 分布式软价值评判者-政策扩散算法 [PDF](https://arxiv.org/pdf/2507.01381), [HTML](https://arxiv.org/abs/2507.01381)
### Authors
Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li
### Background
强化学习在处理复杂控制任务方面已被证实非常有效。传统方法通常使用单模分布（如高斯分布）来建模价值分布的输出，但单模分布容易在价值函数估计中引入偏差，影响算法性能。
### Innovation
本文提出了一种名为DSAC-D（分布式软价值评判者-政策扩散算法）的分布强化学习算法，其通过引入政策熵和价值分布函数建立了多模态分布算法迭代框架，该框架能够收敛到最优策略。此外，通过逆向采样扩散模型生成一组奖励样本来构建分布性价值网络，该网络能够准确描述多峰分布的特点。在此基础上，推导出了价值网络和政策网络双向扩散的分布强化学习算法。实验结果表明，所提算法不仅能学习多模态策略，在9个控制任务上还达到了最先进的性能，估计偏差显著抑制，并且总平均奖励提高了超过10%。测试表明DSAC-D能够准确描述不同驾驶风格的多模态分布，扩散策略网络能够描述多模态轨迹。
### Conclusion
所提出的分布式软价值评判者-政策扩散算法在估计偏差抑制和多模态策略学习方面表现出色，证明了其优越性，特别是在复杂控制任务上的性能表现。
## 645. `cs.LG` - 超越规模：语言数据变异性的多样性系数作为数据质量指标 [PDF](https://arxiv.org/pdf/2306.13840), [HTML](https://arxiv.org/abs/2306.13840)
### Authors
Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo
### Background
当前关于大规模语言模型（LLMs）预训练的主要趋势集中在模型和数据集规模的扩展上。尽管预训练数据的质量被视为训练强大LLMs的重要因素，但它仍是一个模糊的概念，并未得到严格的刻画。因此，需要对预训练数据的质量进行进一步的研究和量化.
### Innovation
本文提出了将数据质量的一个关键方面——自然语言数据的变异性和多样性进行量化的方法，通过定义“多样性系数”来实现。通过实证分析，表明多样性系数能够体现直观的多样性和变异性的特性。同时，本文提出了计算公开预训练数据集的多样性系数，并与理论上下限进行比较，结果显示这些数据集的正式多样性较高。最后，通过使用GPT-2和LLaMAv2进行了多项控制干预实验，验证了多样性和下游模型评估性能之间的联系，总共测试了44种不同规模的模型（参数量从51M到7B不等）.
### Conclusion
本文认为，正式定义的多样性是数据质量的一个重要方面，能够体现数据的变异性和因果性地提高评估性能.
## 646. `cs.LG` - 向XAI系统中用户信任的新度量方法迈进 [PDF](https://arxiv.org/pdf/2405.05766), [HTML](https://arxiv.org/abs/2405.05766)
### Authors
Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho
### Background
随着深度学习模型在各领域的广泛应用，其透明度不足的问题日益凸显，激发了可解释人工智能（XAI）方法领域的研究。XAI方法旨在通过提供决策背后的解释来增强用户对自动化系统的信任。
### Innovation
本文提出了一种新的信任度量标准，将性能指标和信任指标进行客观结合，以优化XAI系统的信任度。通过三个案例研究验证了该度量标准在不同场景下的优越性及更高的敏感性，相比现有技术有所改进
### Conclusion
本文提出的信任度量标准，从客观角度结合了性能指标和信任指标，验证了在不同场景下的优越性和更高的敏感性。
## 647. `cs.LG` - 来自嘈杂众包标签的信号处理视角的学习 [PDF](https://arxiv.org/pdf/2407.06902), [HTML](https://arxiv.org/abs/2407.06902)
### Authors
Shahana Ibrahim,Panagiotis A. Traganitis,Xiao Fu,Georgios B. Giannakis
### Background
论文背景在于伴随人工智能和机器学习的发展，大规模的标注数据对于提升模型性能至关重要。然而，标注过程中的工具（如众包）可能会导致标签噪声（由于标注者的能力有限或者其他因素）。因此，如何有效降低标签噪声对模型训练的负面影响成为了一个核心问题。
### Innovation
本文创新在于结合信号处理理论，特别是张量和非负矩阵分解的可辨识性，提出了解决众包标注挑战的新颖方法，为信号处理视角下的众包数据处理提供了新的见解和算法发展。并且本文还涉及强化学习中的人类反馈（RLHF）和直接偏好优化（DPO）等前沿技术的应用，这些对于大规模语言模型的微调尤为重要。
### Conclusion
本文总结了从噪声众包标签学习的进展，讨论了关键的众包模型及其方法论处理，从经典统计模型到最近的深度学习方法，强调了分析洞察和算法发展，并展示了信号处理视角如何推动该领域的进步。
## 648. `cs.LG` - KAIROS: 可扩展的模型无偏数据估值 [PDF](https://arxiv.org/pdf/2506.23799), [HTML](https://arxiv.org/abs/2506.23799)
### Authors
Jiongli Zhu,Parjanya Prajakta Prashant,Alex Cloninger,Babak Salimi
### Background
随着训练数据对模型准确性的影响越来越大，它们也开始塑造监管合规性和AI资产的市场估值。目前的估值方法仍然存在不足：基于模型的技术依赖单一拟合模型并继承其偏差，而基于算法的方法如Data Shapley则需要大规模重训练。最近的Wasserstein基方法依赖于对最大均值差异(MMD)的近似计算，这可能会错误地排序实例相对于其真实的删除一个样本(LOO)的效用。
### Innovation
我们提出了KAIROS，一种可扩展且模型无偏的数据估值框架，它为每个样本分配一个分布性影响力得分：其对经验训练分布与干净参考集之间最大均值差异(MMD)的贡献。与Wasserstein替代方案不同，我们基于MMD的影响力具有闭式解，能够在$O(1/N^2)$误差范围内忠实地近似准确的LOO排名，且无需重训练，并天然适合于条件核以统一检测标签和特征错误。此外，KAIROS支持高效的在线更新：当新批次大小为m的数据到来时，所有得分可以在$O(mN)$时间内更新，这在不牺牲排名质量的情况下实现了最高可至50倍的加速。
### Conclusion
在噪声、标签错误和污染基准上的经验评估表明，KAIROS在准确性和时间效率上均优于最先进的模型、Shapley和Wasserstein基准。此外，我们提供了严格的理论保证，包括对重现实验排名的对称性和对解析阈值的理解性分隔。
## 649. `cs.LG` - 使用潜在类别分析量化多组内的跨领域交叉差异以实现公平性 [PDF](https://arxiv.org/pdf/2407.03133), [HTML](https://arxiv.org/abs/2407.03133)
### Authors
Yingfang Yuan,Kefan Chen,Mehdi Rizvi,Lynne Baillie,Wei Pang
### Background
随着对公平AI发展的兴趣在不断增长，'不让任何一人掉队'倡议要求我们关注各种形式的不平等，尤其是在获取服务、资源和机会方面。随着AI工具在医疗、能源和住房等多个领域中的决策过程中被广泛应用，探讨这些领域的交叉不平等变得尤为重要，这对整体理解不平等和不公平具有重要意义。本文的研究背景在于，需要创新的方法来量化用户定义组之间的跨领域差异，这些差异可以用于估算不平等并为公平性问题提供有价值的见解。
### Innovation
本文介绍了一种使用潜在类别分析来量化用户定义组之间的跨领域差异的新方法。通过使用各种数据集（如EVENS和2021年英格兰与威尔士普查数据集），并将其与政府公共指标进行相关性分析来验证方法的可靠性，本文提供了一种创新的价值观。这种方法能够识别少数民族群体之间以及少数民族群体与非少数民族群体之间的显著差异，对于政策制定过程中的针对性干预具有重要意义，并展示了如何该方法可以提供关于确保机器学习系统公平性的有价值见解。
### Conclusion
研究结果强调了跨领域交叉不平等的重要性，并证明了本文提出的方法在处理公平性问题上的有效性。未来的研究可以进一步探索和改进该方法在不同情境下的应用，并结合政策制定的实际案例深入分析。
## 650. `cs.LG` - 肾癌诊断中的深度迁移学习 [PDF](https://arxiv.org/pdf/2408.04318), [HTML](https://arxiv.org/abs/2408.04318)
### Authors
Yassine Habchi,Hamza Kheddar,Yassine Himeur,Mohamed Chahine Ghanem,Abdelkrim Boukabou,Shadi Atalla,Wathiq Mansoor,Hussain Al-Ahmad
### Background
不可治愈的疾病仍然给全球医疗系统带来了重大挑战，其流行率受到生活方式、经济、社会和遗传因素的影响。肾病作为其中的关键全球健康问题之一，亟需通过持续研究来改善早期诊断和治疗方法。近年来，深度学习（DL）在医疗成像和诊断领域表现出巨大潜力，特别是在自动肾癌（KC）检测方面取得了显著进展。然而，DL模型的成功高度依赖于高质量、特定领域的数据集，这些数据集的获取往往有限且成本高昂。此外，DL模型需要大量的计算能力和存储空间，这限制了其在临床中的实际应用。为了克服这些问题，迁移学习（TL）作为有效的解决方案浮出水面，通过利用相关领域预先训练好的模型来增强KC诊断效果。
### Innovation
本研究对基于深度学习的迁移学习框架在肾癌检测中的应用进行了全面的文献综述，系统地回顾了关键方法、优势与局限，并分析了其实际性能。此外，研究还讨论了在医疗成像中应用迁移学习面临的挑战，并指出了新兴趋势可能对未来的研究产生影响。研究表明，迁移学习在精准医学特别是肿瘤学中的作用正在通过提高诊断准确性、降低计算需求和支持AI工具在医疗中的集成而发生变革。
### Conclusion
本综述展示了迁移学习在精准医学中的变革性角色，特别是在提高诊断准确性、降低计算需求和支持AI工具在医疗中的集成方面。所提供的见解为研究人员和从业者提供了有价值的指导，为未来肾癌诊断和个性化治疗策略的进展铺平了道路。
## 651. `cs.LG` - Anatomical Foundation Models for Brain MRIs [PDF](https://arxiv.org/pdf/2408.07079), [HTML](https://arxiv.org/abs/2408.07079)
### Authors
Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto
### Background
在神经影像学中，深度学习（DL）越来越被用于检测神经系统状况和神经退行性疾病。大脑年龄是一个重要的影像学标志，已被证明是多种条件的良好指标，例如阿尔茨海默病。在数据稀缺的情况下，使用大脑年龄对深度学习模型进行弱监督预训练也显示出很有前景的结果。另一方面，脑MRI的解剖学信息（如皮层厚度）可以提供重要的信息，用于学习可以转移到许多下游任务的良好表示。已有研究表明，在预训练时融入解剖学信息可以产生更鲁棒和更泛化的表示。
### Innovation
本文提出了AnatCL，一种基于解剖学的脑MRI基础模型，i) 利用解剖信息在弱对比学习方法中，ii) 在许多不同的下游任务中实现了最先进的性能。通过考虑12个不同条件（如阿尔茨海默病、自闭症谱系障碍和精神分裂症）的12个不同诊断任务，以及通过结构MRI数据预测10种不同临床评估分数，验证了这一方法的有效性。
### Conclusion
我们的发现表明，在预训练过程中融入解剖学信息可以产生更稳健和可移植的表示。预训练模型可以在以下链接找到：this https URL.
## 652. `cs.LG` - 在旅游领域进行新型多语言社交内容分析的最佳策略 [PDF](https://arxiv.org/pdf/2311.14727), [HTML](https://arxiv.org/abs/2311.14727)
### Authors
Maxime Masson,Rodrigo Agerri,Christian Sallaberry,Marie-Noelle Bessagnet,Annig Le Parc Lacayrelle,Philippe Roose
### Background
社交媒体平台在各个领域的影响力日益增大，特别是旅游业。这突显了对高效和自动化的自然语言处理（NLP）策略的需求，以便充分利用这些宝贵的资源。然而，从多语言、非结构化和非正式文本转换为结构化知识仍然存在挑战，尤其是无法停止的需要手动标注数据来训练深度学习分类器。本文旨在研究不同的NLP技术，以确定哪些技术能够实现可竞争的性能同时将需要用于训练标注数据的需求降到最低。为此，我们构建了首个公共可用的多语言数据集（法语、英语和西班牙语），该数据集包含旅游相关的推特，涵盖地点命名实体识别（NER）和细粒度主题概念提取等多层手动修订注释，以及推特级别的情感分析。
### Innovation
本文的创新在于构建了一个多语言数据集（包含法语、英语和西班牙语），并将推特数据用于旅游领域，首次在推特级别上对地点命名实体识别、细粒度主题概念提取及其情感分析进行手动修订并标注，还使用最先进的少量样本和微调技术与现代语言模型进行对比实验，证明现代少量样本技术使我们能够在几乎不需要标注数据的情况下获得可竞争的结果：情感分析每标签5条推特（总共15条），地点命名实体识别每标签30条推特，细粒度主题概念提取1000条带有标注的推特，一个基于315个类别的高度细化序列标记任务。这为新的域特定应用输入NLP提供了新的方法，减少了手动标注的需求，规避了基于规则的、临时解决方案的复杂性。
### Conclusion
本文的研究结果表明，基于新型数据集，我们可以为旅游领域的多个NLP任务提供更好的解决方案，减少人工标注的需求，并且避免了基于规则的方法带来的复杂性。
## 653. `cs.LG` - Bi-modality medical images synthesis by a bi-directional discrete process matching method [PDF](https://arxiv.org/pdf/2409.03977), [HTML](https://arxiv.org/abs/2409.03977)
### Authors
Zhe Xiong,Qiaoqiao Ding,Xiaoqun Zhang
### Background
医学图像合成由于生成模型的迅速发展正变得越来越流行。医学图像合成的目标是从观察到的数据模态生成未获取的图像模态。生成的图像可以用于临床诊断辅助、模型训练和验证的数据增强或图像质量提高。流形基模型以其生成逼真高质量合成图像的能力，在这些生成模型中取得了成功。然而，大多数流形基模型在合成过程中需要计算大量的时间迭代的流普通常微分方程（ODE），因此性能受到巨大计算时间的限制。
### Innovation
提出了一种新型的流形基模型，即双向离散过程匹配（Bi-DPM），以完成双向医学图像合成任务。与基于匹配的其他流模型不同，Bi-DPM 能够利用正向和反向 ODE 流，并在几次离散时间步骤上增强中间图像的一致性，从而在配对数据的指导下，既保证了两种模式下生成图像的质量。实验表明，Bi-DPM 在 MRI T1/T2 和 CT/MRI 三个数据集中表现出色，相比其他最新的流形基方法，能够生成更高质量的图像，并具有精准的解剖区域。
### Conclusion
实验结果表明，Bi-DPM 在双向医学图像合成中表现出色，与最新流形基方法相比，生成的图像质量更高，解剖区域更精确。
## 654. `cs.LG` - 使用对称自回归储槽计算机识别具有对称性的系统 [PDF](https://arxiv.org/pdf/2311.09511), [HTML](https://arxiv.org/abs/2311.09511)
### Authors
Fredy Vides,Idelfonso B. R. Nogueira,Gabriela Lopez Gutierrez,Lendy Banegas,Evelyn Flores
### Background
该研究调查了使用对称自回归储槽计算机（equivariant autoregressive reservoir computers）识别具有对称性的系统的方法。通过结构化矩阵逼近理论的一般结果，研究采用了双管齐下的方法：首先，对基本的对称性保留非线性时间延迟嵌入进行了全面分析，探讨采自所研究对称系统的时间序列数据；其次，应用稀疏最小二乘方法来识别输出耦合矩阵的近似表示。这些矩阵在决定对称性系统的非线性自回归表示中起着决定性作用，其结构特性由系统中存在的对称性集所决定。文档概述了这些技术所派生的典型算法，提供了它们实际应用的见解。研究侧重于与经典储槽计算机方法相比，在模拟对称动力学系统时显著提高的结构识别精度。
### Innovation
该研究创新性地结合了结构化矩阵逼近理论和稀疏最小二乘方法，通过非线性时间延迟嵌入和对称性保留的自回归模型来识别具有特定对称性的系统，从而在模拟对称动力学系统时实现了更高的结构识别精度。此外，该方法提供了一种新的实用工具，用于理解和识别复杂系统中的对称性结构。
### Conclusion
该研究通过使用对称自回归储槽计算机，提出了一种新的方法来高效地识别具有特定对称性的系统，并验证了这种方法相比传统储槽计算机方法在模拟对称动力学系统时的优越性。研究为理解和识别复杂系统中的对称性结构提供了一个新的视角和方法。
## 655. `cs.LG` - 概念转换下的泛化与专业化 [PDF](https://arxiv.org/pdf/2409.15582), [HTML](https://arxiv.org/abs/2409.15582)
### Authors
Alex Nguyen,David J. Schwab,Vudtiwat Ngampruetikorn
### Background
机器学习模型在数据分布发生变化时往往表现脆弱，尤其是在测试数据分布与训练数据分布不同的情况下。理解这一失败模式对于识别和减轻大规模采用机器学习的安全风险至关重要。本文分析了在概念转移（输入-标签关系在测试阶段发生变化的一种形式的分布转移）下岭回归的表现。此外，通过预训练的变压器模型在解决线性回归问题上的实验，展示了在概念转移下，过长的上下文长度可能反而会损害预测的泛化性能。最后，通过对MNIST和FashionMNIST数据集的分类问题的实验，进一步证实了这种有趣的行为也存在于分类问题中。
### Innovation
提出了对概念转移下岭回归模型预测风险的精确表达式，在理论分析中得到了非单调的数据依赖性测试性能，甚至在没有双重下降的情况下也存在。理论结果与基于预训练的变压器模型的线性回归实验一致，揭示了在概念转移下，过长的上下文长度可能对后续预测的泛化性能产生负面影响。
### Conclusion
概念转移对岭回归的泛化性能产生了非平凡的影响，包括从弱概念转移向强概念转移的相变现象，以及即使在没有双重下降的情况下，测试性能也表现出非单调的数据依赖性。此外，研究表明这种非单调性泛化行为也存在于分类问题中。
## 656. `cs.LG` - 基于图的方法的城市区域预训练和提示 [PDF](https://arxiv.org/pdf/2408.05920), [HTML](https://arxiv.org/abs/2408.05920)
### Authors
Jiahui Jin,Yifan Song,Dong Kan,Haojia Zhu,Xiangguo Sun,Zhicheng Li,Xigang Sun,Jinghui Zhang
### Background
城市区域表示对于各种下游城市任务至关重要，尽管有许多方法并取得了成功，但获取适用不同任务的一般城市区域知识仍然具有挑战性。现有工作对城市区域中的细粒度功能布局语义关注有限，限制了其跨区域捕捉可转移知识的能力。此外，对不同下游任务所需的独特特征和关系处理不当也可能妨碍有效的任务适应。背景总结了在当前方法和模型中存在的问题，及其对城市区域表示学习的影响。
### Innovation
本文提出了一种基于图的城市区域预训练和提示框架（GURPP），该框架首先构建城市区域图，并开发了以子图为中心的城市区域预训练模型，以捕捉实体间异构的可转移模式。该模型使用对比学习和多视图学习方法进行知识丰富的区域嵌入预训练。此外，设计了两种基于图的提示方法：一种是显式任务知识的手工定义提示，一种是发现隐藏知识的任务可学会提示，以增强这些嵌入对不同任务的适应性。创新部分详细介绍了该框架的新方法和技术创新。
### Conclusion
在各种城市区域预测任务和不同城市上的广泛实验表明，框架在性能上表现出优越性。结论部分总结了实验结果和该框架的优越性。
## 657. `cs.LG` - 记忆衰减与卷积定理 [PDF](https://arxiv.org/pdf/2408.07386), [HTML](https://arxiv.org/abs/2408.07386)
### Authors
Juan-Pablo Ortega,Florian Rossmannek
### Background
介绍了因果且时不变滤波器的几种拓扑和分析连续性概念，以及淡出记忆性的概念，并分析了这些概念之间的关系。证明了卷积定理的一个重要推广，该定理表明淡出记忆性与线性滤波器的卷积表示可用性等价，进一步扩展了先前对记忆衰减性的刻画到记忆衰减性的定义中的一系列加权范数中。此外，主要定理表明，至少当域是有限维时，卷积表示的可用性不仅可以通过淡出记忆性来表征，还可以通过两个纯粹拓扑性质的结合来表征。还证明了当输入空间和线性泛函的值域都是希尔伯特空间时，最小连续性和最小淡出记忆性确保了与相关核希尔伯特空间相关的有趣的嵌入的存在性。
### Innovation
证明了卷积定理的扩展版本，即记忆衰减性与卷积表示的有效性等价；证明了当输入空间和值域是希尔伯特空间时，最小连续性和最小淡出记忆性保证了核希尔伯特空间的有趣嵌入的存在性；将记忆衰减性的刻画推广到了一系列加权范数中，扩展了先前的刻画结果。
### Conclusion
研究扩大了记忆衰减性与卷积表示之间的等价性的理解，并引入了新的拓扑和分析概念，这些概念对于线性滤波器的研究具有重要意义；证明了最小连续性和最小淡出记忆性对于希尔伯特空间上的线性泛函至少在有限维情况下仍然有效，可以确保核希尔伯特空间嵌入的存在性。
## 658. `cs.LG` - 无监督认知 [PDF](https://arxiv.org/pdf/2409.18624), [HTML](https://arxiv.org/abs/2409.18624)
### Authors
Alfredo Ibias,Hector Antona,Guillem Ramirez-Miranda,Enric Guinovart,Eduard Alarcon
### Background
无监督学习方法受到认知模型的启发。迄今为止，最成功的无监督学习方法主要集中在将样本在数学空间中进行聚类。本文提出了一种基于原型的无监督学习方法，受一种新颖的认知框架启发，这种方法以输入无关的方式，通过构造性地建模输入空间为分布式层次结构来进行决策制定过程的表示中心方法研究。研究还与最先进的无监督学习分类方法、小型和不完整的数据集分类方法以及癌症类型分类方法进行了比较，展示了新方法的优越性，同时在一些认知属性上也表现出了不同的、更接近人类认知的行为模式。
### Innovation
本文提出了一种基于原型的无监督学习方法，受新颖的认知框架启发，以输入无关的方式构造性地建模输入空间为分布式层次结构，在无监督学习分类、小型和不完整的数据集分类以及癌症类型分类中表现出了优越性，并且在一些认知属性上也表现出了不同、更接近人类认知的行为模式。
### Conclusion
本文提出的方法在无监督学习分类、小型和不完整的数据集分类以及癌症类型分类中均表现出了超越现有方法的性能，并且在某些认知属性上展示出了不同于现有算法，更接近人类认知的行为模式。
## 659. `cs.LG` - 探索大型语言模型在工业测试维护过程中的集成 [PDF](https://arxiv.org/pdf/2409.06416), [HTML](https://arxiv.org/abs/2409.06416)
### Authors
Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg
### Background
软件测试过程中大量的人力和财力都投入到测试维护中，包括添加、删除或修改测试案例，以保持测试套件与被测试系统同步或提高其质量。工具支持可以通过自动化测试维护过程中的某些步骤或为开发人员提供指导和支持来降低测试维护的成本并提高其质量。研究表明，大型语言模型（LLMs）可以在测试维护任务中发挥作用，但尚未广泛应用于工业环境。在本研究中，作者探索了LLMs支持测试维护的能力和应用，并在Ericsson AB公司进行了案例研究。
### Innovation
作者提出了一个多代理架构，可以预测代码变更后哪些测试需要维护。这种方法通过利用LLMs自动化和辅助测试维护过程，为工业环境的测试维护过程提供了新的解决方案和技术支持。与现有方法相比，该多代理架构能够更准确地识别需要维护的测试，提高了测试维护的效率和质量。
### Conclusion
本研究增加了我们对如何利用LLMs支持工业测试维护过程的理解，特别是在代码变更后自动预测哪些测试需要维护。多代理架构的提出展示了LLMs在工业测试维护中的实际应用潜力。这种方法有助于提高测试维护的效率和质量，并为未来的工业测试维护研究提供了方向。
## 660. `cs.LG` - 重新审视突触神经网络的能效 [PDF](https://arxiv.org/pdf/2409.08290), [HTML](https://arxiv.org/abs/2409.08290)
### Authors
Zhanglu Yan,Zhenyu Bai,Weng-Fai Wong
### Background
现有的能量评估往往过于简化，主要关注计算方面，而忽略了全面的数据传输和内存访问等关键开销。这种简化可能导致对突触神经网络（SNNs）真正能效优势的误导性结论。鉴于此，该研究重新审视了SNNs的能效，并建立了一个公平的基准，即将率编码SNNs和等效的量化神经网络（QNNs）进行对比，确保两者具有可比的表示能力和相似的硬件要求，从而进行有意义的能量比较。研究还包括详细的能量模型，涵盖了核心计算和数据传输（稀疏和密集激活、权重），并系统探索了广泛的参数空间，包括内置网络特性（时间窗口T、突触率sr、QNN稀疏度γ、模型规模N、权重位数）和硬件特性（内存系统和网络-芯片）等。
### Innovation
该研究通过详细的能量模型和全面的参数探索，提出了一个公平的基准，展示了SNNs在特定运行状态下能够提供比同等QNNs更好的能效。这为设计真正能效的神经网络解决方案提供了指导。
### Conclusion
研究表明，在典型的类神经形态硬件条件下，适度时间窗口（T在5到10之间）的SNNs需要平均突触率（sr）低于6.4%才能超越等效的QNNs，从而实现真正高效的神经网络设计。
## 661. `cs.LG` - SecAlign: 使用偏好优化防御注入式提示攻击 [PDF](https://arxiv.org/pdf/2410.05451), [HTML](https://arxiv.org/abs/2410.05451)
### Authors
Sizhe Chen,Arman Zharmagambetov,Saeed Mahloujifar,Kamalika Chaudhuri,David Wagner,Chuan Guo
### Background
大型语言模型（LLMs）在现代软件系统中越来越普遍，它们充当用户和互联网之间的接口，以帮助执行需要高级语言理解的任务。为了完成这些任务，LLM通常会使用诸如用户文档、网络检索、API调用结果等外部数据源。这为攻击者通过提示注入操纵LLM提供了新的途径。通过注入恶意的提示，攻击者可以绕过系统的预定指令，执行恶意指令。因此，需要提出新的防御机制来应对这一威胁。
### Innovation
本文提出了一种名为SecAlign的新防御机制，它基于偏好优化技术。SecAlign首先构建包含注入提示输入、安全输出（响应合法指令）和不安全输出（响应注入）的数据集。然后，通过偏优化在该数据集上对LLM进行训练，让它优先选择安全输出而非不安全输出。这种方法首次能够将各种提示注入的成功率降低到小于10%，即使面对更复杂的训练中未见过的攻击。表明SecAlign具有良好的泛化能力，能够有效防御未知和未来可能出现的攻击。同时，SecAlign模型的实用性和之前的模型相当，在我们进行的评估中仍有相似的效用。
### Conclusion
SecAlign提供了一种新方法，能够有效降低各种提示注入的成功率，即使面对未见过的复杂攻击也依然有效。该方法可作为实用的防御手段，保证LLM的安全性。该论文的代码可在该链接中找到。
## 662. `cs.LG` - 没有自适应内存需求的适应性概率ODE求解器 [PDF](https://arxiv.org/pdf/2410.10530), [HTML](https://arxiv.org/abs/2410.10530)
### Authors
Nicholas Krämer
### Background
近年来，尽管在概率求解器领域取得了显著进展，但这类求解器仍然无法有效解决内存需求大的微分方程问题，尤其是在时间序列较长的情况下表现不佳。现有的自适应求解器虽然能够灵活调整步长以提高精度，但其不可预测的内存需求会导致模拟失败，且缺乏预警。放弃自适应性又意味着放弃多年的研究成果，这并不具有可行性。因此，需要找到一种既能保持自适应性又能控制内存需求的方法来改善这一问题。
### Innovation
本文提出了一个新的适应性概率求解器，其特点是固定了内存需求，基于近期的鲁棒状态估计技术进展开发。该方法能够(1)解决长时间序列的内存问题，(2)通过即时编译大幅提升模拟速度，(3)使适应性概率求解器能够与JAX中的科学计算兼容，从而结合了适应性及内存可控性两方面的优点，克服了传统方法的局限性，为解决这类问题提供了新的思路和技术支持。
### Conclusion
本文开发的适应性概率求解器具有固定内存需求的特点，解决了传统自适应求解器面临的不可预测内存需求问题。相比原有方法，该方法显著提高了长时间序列模拟的稳定性和效率，同时还保持了自适应性，推动了其在科学计算中的应用。这是对求数领域的一项重要改进，对未来的科学计算实践具有重要意义。
## 663. `cs.LG` - 使用生成型人工智能进行因果表示学习：应用于作为治疗的文本 [PDF](https://arxiv.org/pdf/2410.00903), [HTML](https://arxiv.org/abs/2410.00903)
### Authors
Kosuke Imai,Kentaro Nakamura
### Background
该论文探讨了如何通过利用生成型人工智能（GenAI）的潜力，增强涉及高维、未结构化治疗（如文本）的因果推理的有效性。现有的因果推理方法需要从数据中学习因果表示，这可能引发数据不足或覆盖假设违反等问题，而现有的方法难以准确分离感兴趣的影响因子和其他潜在的混淆因子。该论文致力于提出一种新的方法来解决问题，并提供理论支撑以确保因果效应估计的准确性和效率。
### Innovation
论文提出的是一种新的方法——GenAI-Powered Inference (GPI)，该方法利用大型语言模型（LLMs）生成治疗变量，并使用其内部表示来进行因果效应估计。这种方法不需要从数据中学习因果表示，从而避免了数据不足或覆盖假设问题，显著提高了因果效应估计的准确性和效率。论文还通过双机器学习的方法推导出所提估计器的渐近性质，并结合工具变量方法拓展了适用于基于人类感知的治疗特征的场景。此外，该方法也可应用于文本重用场景，通过再生现有文本来进一步验证其效果。
### Conclusion
通过对仿真和实证研究的分析，论文展示了所提出的GPI方法相较于现有的最先进的因果表示学习算法的优势。该方法通过生成型人工智能的技术，不仅提高了因果推理的准确性，而且在文本作为治疗变量的情境下具有广泛应用的价值。
## 664. `cs.LG` - Adapter-Enhanced Semantic Prompting for Continual Learning [PDF](https://arxiv.org/pdf/2412.11074), [HTML](https://arxiv.org/abs/2412.11074)
### Authors
Baocai Yin,Ji Zhao,Huajie Jiang,Ningning Hou,Yongli Hu,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi
### Background
连续学习（CL）使模型能够适应不断变化的数据流。传统方法为了避免灾难性遗忘，通常选择保留过去的数据以便在训练时重放，或者在模型中添加额外的分支以学习新知识，但这些方法需要较高的内存要求。本文旨在研究一种新的轻量级CL框架，以降低内存需求并提高学习效率。
### Innovation
本文提出了一种新颖的轻量级CL框架——Adapter-Enhanced Semantic Prompting (AESP)，该框架结合了提示调优和适配器技术。具体来说，使用语义导向的提示增强视觉特征的泛化能力，并利用适配器高效融合语义信息，以学习更适应的特征。此外，还开发了一种新的匹配机制进行提示选择，以选择合适的任务提示进行特征适配。实验结果表明，该方法在多个度量标准上表现优越，展示了其在CL领域的潜力。
### Conclusion
在三个CL数据集上的广泛实验表明，我们的方法在多个指标上取得了良好的性能，表明该方法在CL领域具有很大的潜力。
## 665. `cs.LG` - 一种基于深度学习的黑洞二元体波形数值相对论代理模型 [PDF](https://arxiv.org/pdf/2412.06946), [HTML](https://arxiv.org/abs/2412.06946)
### Authors
Osvaldo Gramaxo Freitas,Anastasios Theodoropoulos,Nino Villanueva,Tiago Fernandes,Solange Nunes,José A. Font,Antonio Onofre,Alejandro Torres-Forné,José D. Martin-Guerrero
### Background
引力波近似器对于引力波天文学至关重要，它们能够通过近似方式覆盖双黑洞参量空间，从而实现信息推断或匹配滤波，而无需昂贵的数值相对论（NR）模拟。然而，这种近似方式通常会牺牲一定的精度以换取计算效率。为了降低这种权衡，可以利用数值相对论波形空间内的插值方法构建NR代理模型。本文提出了一种基于神经网络的两阶段训练方法，这种方法首先在近似器生成的波形上进行初步训练，然后再通过与NR数据的微调进行调整。通过这种方法生成的双阶段人工神经代理模型（DANSur）能够快速且具备竞争力地生成波形，几乎在毫秒级就能生成数百万个波形，同时保持与NR平均失匹配在10^-4左右。这种模型被集成到bilby框架中，证明了它们可用于参数估计任务。
### Innovation
提出了一种两阶段的神经网络训练方法，首先在近似生成的波形上进行初步训练，然后通过与真实数值相对论波形数据进行微调，以此构建高效的NR代理模型（DANSur）。这种方法显著提高了波形生成的速度和准确性。该模型能够在GPU上以毫秒级的速度生成数百万个波形，同时保持着与真实数值相对论波形相近的失匹配水平。
### Conclusion
该研究展示了一种基于深度学习的双阶段神经网络训练方法，构建了快速且具有竞争力的双黑洞波形生成模型。这种模型被成功集成到bilby框架中，证实其适用于多种参数估计任务。同时，该方法为提升引力波天文学中波形覆盖范围和精度效率的权衡提供了一种新的解决方案。
## 666. `cs.LG` - SPACE-SUIT：一种基于人工智能的色球特征提取和分类器 [PDF](https://arxiv.org/pdf/2412.08589), [HTML](https://arxiv.org/abs/2412.08589)
### Authors
Pranava Seth,Vishal Upendran,Megha Anand,Janmejoy Sarkar,Soumya Roy,Priyadarshan Chaki,Pratyay Chowdhury,Borishan Ghosh,Durgesh Tripathi
### Background
背景：太阳紫外成像望远镜(SUIT)安装在Aditya-L1上，用于观察太阳光球和色球。了解色球和光球结构的等离子体和热力学特性需要进行大规模统计研究，需要开发自动特征检测方法。为此，开发了特征检测算法SPACE-SUIT (Solar Phenomena Analysis and Classification using Enhanced vision techniques for SUIT)，用于从SUIT的Mg II k滤镜观察色球特征。该算法的目标是识别和分类日冕区域、太阳黑子、日珥和日面结构。该算法基于YOLO（You Only Look Once）神经网络模型来识别感兴趣区域（ROIs），使用来自Interface Region Imaging Spectrograph (IRIS)全视场镶嵌图像中Mg II k线的模拟SUIT图像进行训练和验证，同时在SUIT级1级数据上进行检测。SPACE在验证的模拟SUIT FITS数据集上实现了约0.788的精度、0.863的召回率和0.874的MAP值。通过统计措施和Tamura特征对真实界线框与预测界线框进行分析，验证了检测结果的有效性，发现熵、对比度、不相似性和能量的分布差异晰了通过SPACE检测到的区域，并与实际观察到的SUIT图像相一致。
### Innovation
创新：开发了基于YOLO的特征检测算法SPACE-SUIT，用于从SUIT的Mg II k滤镜观察色球特征，可以有效识别和分类日冕区域、太阳黑子、日珥和日面结构。通过使用统计指标和Tamura特征，证明了这些方法可以在无标签真实边界框的情况下提供独立验证，有助于识别色球特征的新方案的有效性。
### Conclusion
结论：该工作不仅开发了一种色球特征提取器，而且还展示了统计指标和Tamura特征的有效性，用作未来特征检测方案的有效验证手段。
## 667. `cs.LG` - REINFORCE++: 一个兼具提示和奖励模型鲁棒性的高效RLHF算法 [PDF](https://arxiv.org/pdf/2501.03262), [HTML](https://arxiv.org/abs/2501.03262)
### Authors
Jian Hu,Xibin Wu,Wei Shen,Jason Klein Liu,Zilin Zhu,Weixun Wang,Songlin Jiang,Haoran Wang,Hao Chen,Bin Chen,Weikai Fang,Xianyu,Yu Cao,Haotian Xu
### Background
大型语言模型通过强化学习从人类反馈（RLHF）和具备验证奖励的强化学习（RLVR）微调，显著提升了人与AI的价值对齐，并增强了AI的能力，特别是在推理密集型、长上下文链式思考（long-CoT）任务中的表现。然而，现存的RLHF或RLVR框架普遍面临推理瓶颈和复杂性障碍，限制了新手的使用门槛。
### Innovation
该论文介绍了一个名为OpenRLHF的用户友好、可扩展、易于学习的开源RLHF框架，基于Ray、vLLM、DeepSpeed和HuggingFace Transformers构建，以简化的设计、清晰的代码结构和详尽的文档为特点，促进研究人员和实践者的入门。实验结果表明，OpenRLHF在不同模型规模下相比最先进的框架实现了1.22x到1.68x的训练效率提升，并且所需代码行数大幅减少。该框架已公开可用，并被领先机构采用以加速RLHF的研究和学习过程。
### Conclusion
OpenRLHF框架显著提高了RLHF的效率和易用性，为科学家和工程师提供了一个强大的工具，将有助于促进RLHF技术的进一步研究和应用。
## 668. `cs.LG` - 规范化选择影响正则化回归的收缩效应 [PDF](https://arxiv.org/pdf/2501.03821), [HTML](https://arxiv.org/abs/2501.03821)
### Authors
Johan Larsson,Jonas Wallin
### Background
在使用正则化模型时，特征的尺度对其灵敏度大，因此通常需要在建模前对特征进行归一化（即中心化和缩放）。然而，不同的归一化方法可能对最终模型产生巨大影响，但关于归一化影响的相关研究依然鲜有报道。本文通过研究Lasso、岭回归和弹性网络回归中的归一化方式，关注二进制特征及其平衡关系对回归系数的影响，并探讨何种归一化方法可以缓解这种影响.
### Innovation
本文首次系统性研究了不同归一化方法对标化回归模型的影响。通过分析不同正则化技术和归一化方法的组合效应，提出了在Lasso和岭回归中采用基于方差和标准差的归一化方法的方法，并在弹性网络中提出了一种通过调整惩罚权重而非特征本身的归一化方式来缓解问题的方法。此外，还初步探讨了二进制和普通特征混合以及特征交互的情况下的归一化策略.
### Conclusion
本文的研究结果表明，回归模型中的归一化选择对收缩效应具有显著影响，不同的归一化方法可能导致不同的结果。通过适当选择归一化方式，可以在保持模型性能的同时改善系数估计的效果。
## 669. `cs.LG` - SURE-VQA: 系统理解医疗VQA任务中鲁棒性评估 [PDF](https://arxiv.org/pdf/2411.19688), [HTML](https://arxiv.org/abs/2411.19688)
### Authors
Kim-Celine Kahl,Selen Erkan,Jeremias Traub,Carsten T. Lüth,Klaus Maier-Hein,Lena Maier-Hein,Paul F. Jaeger
### Background
视觉语言模型（VLMs）在医疗任务中具有巨大潜力，如视觉问答（VQA），可以作为患者和临床医生的交互式助手。然而，它们在未见过的数据上的鲁棒性对实际部署的安全性构成了主要挑战。评估鲁棒性需要一个受控的实验设置，以便系统地了解模型的行为。但当前的设置不足以提供充分全面的评估。为此，本研究提出了一个新的框架，称为SURE-VQA，以克服当前的问题并系统地分析VLM的鲁棒性。SURE-VQA框架围绕三个关键要求：首先，鲁棒性应该在与VQA数据本质相关的现实世界移动中测量，不局限于合成移动；其次，传统的基于标记的度量往往难以捕捉蕴含的语义，需要使用大型语言模型（LLMs）进行更准确的语义评估；最后，由于缺乏明智的基准，模型的性能缺乏可解释性，因此应报告有意义的基准以评估多模态对VLM的影响。本研究对三种医疗数据集中的四种类型的分布变化进行了多种微调（FT）方法的鲁棒性研究，以验证该框架的相关性并揭示关键见解。
### Innovation
本研究提出了SURE-VQA框架，这是第一个系统地评估VLM在医疗VQA任务中鲁棒性的框架。SURE-VQA结合了三个关键要求：1) 测量现实世界的鲁棒性而非合成的；2) 使用大型语言模型（LLMs）进行更加精确的语义评估；3) 报告有意义的基准以提供模型性能的解读。该框架有助于更好地了解不同微调方法和不同分布变化下的鲁棒性。此外，研究还发现了简单但不使用图像数据的基准可以表现出色，并且LoRA方法在内部数据集上表现出最佳性能。
### Conclusion
研究表明，没有一种微调方法在所有任务中都能表现出最佳的鲁棒性，但鲁棒性的趋势在不同的微调方法之间比在不同的分布变化中更为稳定。此外，简单且不使用图像数据的基准在某些情况下具有显著效果。LoRA方法在内部数据集上表现最佳。SURE-VQA框架为医疗VQA任务中模型的鲁棒性提供了系统性的评估手段。
## 670. `cs.LG` - 人工科学家——直接传输的等离子体仿真机器学习 [PDF](https://arxiv.org/pdf/2501.03383), [HTML](https://arxiv.org/abs/2501.03383)
### Authors
Jeffrey Kelling,Vicente Bolea,Michael Bussmann,Ankush Checkervarty,Alexander Debus,Jan Ebert,Greg Eisenhauer,Vineeth Gutta,Stefan Kesselheim,Scott Klasky,Vedhas Pandit,Richard Pausch,Norbert Podhorszki,Franz Poschel,David Rogers,Jeyhun Rustamov,Steve Schmerler,Ulrich Schramm,Klaus Steiniger,Rene Widera,Anna Willmann,Sunita Chandrasekaran
### Background
高性能计算（HPC）集群规模的扩大和大规模仿真的进行，会产生大量数据，这给数据分析带来了巨大的输入输出（IO）和存储挑战。特别是深度学习技术能够利用这些领域数据来提取有助于形成科学理解的模式。本文讨论如何创建一个直接从仿真数据流式传输到机器学习框架的工作流程，绕过了文件系统瓶颈。数据在传输过程中异步地被转换，并与仿真和模型训练无关，从而释放应用用户适应应用输出程序的任务。本文使用GPU加速的粒子-细胞（PIConGPU）仿真来展示延迟回放机器学习的概念，以应对非稳态过程连续学习时避免灾难性遗忘的问题。同时详细阐述了在将此流程移植和扩展到Frontier极规模系统时所面临的挑战和问题。
### Innovation
提出了一种新的流式工作流程，该流程允许从仿真数据直接传输到机器学习框架上进行数据的转换和处理，这绕过了文件系统瓶颈。这一创新点在于它通过异步方式实时分析数据，同时不对仿真和模型训练产生影响。此外，使用经验重放（experience replay）技术来避免学习过程中具体的非稳态过程导致的灾难性遗忘问题。
### Conclusion
本文提出的工作流通过解放仿真程序用户来自适应数据输出要求，实现了更加便捷的数据操作功能，并结合GPU加速的粒子-细胞仿真进行了概念验证。尽管在迁移和扩展过程中遇到了一定挑战，但这项技术能够显著提高大型科学计算中数据处理的效率。
## 671. `cs.LG` - XGeM: 多提示基础模型在多模态医疗数据生成中的应用 [PDF](https://arxiv.org/pdf/2501.04614), [HTML](https://arxiv.org/abs/2501.04614)
### Authors
Daniele Molino,Francesco Di Feola,Eliodoro Faiella,Deborah Fazzini,Domiziana Santucci,Linlin Shen,Valerio Guarrasi,Paolo Soda
### Background
在医疗成像中采用人工智能具有巨大的潜力，但仍然受到数据稀缺、隐私问题和需要实现鲁棒的多模态集成等挑战的影响。虽然生成模型的最新进展使得高质量合成数据的生成成为可能，现有的方法往往仅限于单一模态、单向合成，因此缺乏同时合成多个模态并保持临床一致性的能力。为了应对这一挑战，引入了XGeM，这是一种设计用于支持医疗数据模态之间灵活的任意到任意合成的6.77亿参数的多模态生成模型。XGeM通过对比学习构建共享的潜在空间，并引入了一种新颖的多提示训练策略，使模型能够根据任意输入模态的子集进行条件设置，从而适应异质的临床输入并联合生成多个输出，保持语义和结构的连贯性。我们对XGeM进行了广泛的验证，包括在MIMIC-CXR数据集上与五个竞争对手进行基准测试，以及通过专家放射科医生的视觉图灵测试评估生成数据的现实性和临床相关性，并证实了XGeM如何支持医疗数据中的脱敏、类别不平衡和数据稀缺等关键挑战，突显了其作为医疗数据合成基础模型的实用价值，
### Innovation
XGeM是一个6.77亿参数的多模态生成模型，设计用于支持医疗数据模态之间灵活的任意到任意合成。通过对比学习构建共享的潜在空间，并引入了一种新颖的多提示训练策略，使模型能够根据任意输入模态的子集进行条件设置，从而适应异质的临床输入并联合生成多个输出，保持语义和结构的连贯性。此外，通过视觉图灵测试和广泛的基准测试验证了XGeM对现实场景的适用性和实用性，进一步展示了XGeM在处理匿名化问题和数据稀缺等医疗数据挑战方面的独特优势。
### Conclusion
XGeM作为一种多模态生成模型，能够有效地支持医疗数据模态之间的合成，通过多提示训练机制，实现多样性和临床一致性的统一。验证结果显示，XGeM不仅在技术上具有显著优势，还在现实医疗场景中具有高度的实用性和有效性，强调了其在医疗数据合成领域的应用潜力。
## 672. `cs.LG` - 量子增强的小样本因果发现 [PDF](https://arxiv.org/pdf/2501.05007), [HTML](https://arxiv.org/abs/2501.05007)
### Authors
Yu Terada,Ken Arai,Yu Tanaka,Yota Maeda,Hiroshi Ueno,Hiroyuki Tezuka
### Background
因果关系的发现吸引了经济学、社会科学和生物学等多个领域的广泛关注。在实际应用中，通常对底层系统的知识了解不足，且实际数据往往与非线性因果结构相关联，这使得大多数传统的因果分析方法难以直接应用。在样本量较小的情况下，进行因果发现尤为困难，而传统方法在这种情况下往往表现不佳。
### Innovation
该研究提出了一种新型的量子Peter-Clark (qPC)算法，该算法无需对底层模型结构做出任何假设。基于由量子电路定义的再生核希尔伯特空间内的条件独立性检验，qPC算法能够探索任意分布下观察数据中的因果关系，并提出了一种基于Kernel Target Alignment (KTA)的新优化方法来确定量子核的超参数，从而减少了因果发现中的误检率，提高了可靠性。
### Conclusion
理论和实验结果表明，量子算法能够增强经典算法在因果发现中的准确性和可靠性，特别是在小样本场景下，这是传统方法难以解决的问题。此外，该方法在假设房屋价格、心脏疾病和生物信号系统等实际数据集的应用中也得到了验证。这些发现强调了基于量子的因果发现方法在解决实际挑战方面的潜力，尤其是对于传统方法明显受限的小样本情况。
## 673. `cs.LG` - 通过自助正样本采样实现的自助监督框架在说话人验证中的应用 [PDF](https://arxiv.org/pdf/2501.17772), [HTML](https://arxiv.org/abs/2501.17772)
### Authors
Theo Lepage,Reda Dehak
### Background
近期，自监督学习（SSL）在说话人验证（SV）中的应用展示了显著的潜力，但与监督系统之间的性能差距仍是持续的挑战。SSL框架依赖于来自同一音频片段的锚点-正样本对构建，尽管有广泛的数据增强，这种正样本策略仍然会导致编码过多关于录音源的特征信息，因此是自监督学习中的一个基本限制。
### Innovation
本文提出了一种自助监督积极采样（SSPS）的方法，这是一种用于自监督学习框架中说话人验证的自助式采样技术。SSPS在特征空间中采样与锚点接近的正样本，假设这些伪正样本属于同一说话人身份但对应不同的录音条件。这种方法在VoxCeleb基准测试上应用于主要的自监督学习框架时，表现出持续的SV性能提升，包括SimCLR，SwAV，VICReg和DINO。使用SSPS，SimCLR和DINO分别在VoxCeleb1-O上实现了2.57%和2.53%的EER。此外，SSPS还降低了类内变异性，减少了说话人表示中的信道信息，同时在无数据增强的情况下表现出更高的鲁棒性。
### Conclusion
SSPS的引入显著提升了自监督学习框架在说话人验证任务上的性能，在不使用数据增强的情况下表现出更强的鲁棒性，且SimCLR在简化训练框架下仍能获得与DINO相似的性能。
## 674. `cs.LG` - 量化下游模型性能中数据对齐的重要性 [PDF](https://arxiv.org/pdf/2501.08496), [HTML](https://arxiv.org/abs/2501.08496)
### Authors
Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo
### Background
与通常强调数据集规模的做法相反，本文探讨了数据对齐在训练大型语言模型 (LLM) 中的角色——这是数据质量的一个常常被忽视的方面。本文通过使用基于 Task2Vec 的对齐系数，一个衡量两个数据集之间相似性的量化指标，来量化训练数据与评估数据之间的对齐程度对下游性能的影响。特别是，本文进行了控制干预性实验，探讨了两种设置：1. 不同预训练数据 (pt) 和评估数据之间的对齐系数增加的影响，2. 针对特定领域微调 (ft) 和特定领域评估数据之间对齐系数增加的影响。所探讨的特定领域任务是 Autoformalization，即自然语言与代码之间的机器翻译任务，用于形式化验证。在两种设置中，我们发现模型训练和评估数据之间对齐系数与模型在其相应的下游任务上的损失/困惑度之间存在强烈的、可预测的负相关关系。这些发现表明，需要重新评估 LLM 的训练方法，表明相对于数据数量，数据对齐的重要性，尤其是在 Autoformalization 等专门的下游任务中尤为重要。
### Innovation
通过利用基于 Task2Vec 的对齐系数评估数据对齐性对下游模型性能的影响，本文创新性地为 LLM 的训练方法引入了新的视角，特别强调了数据对齐的重要性，而不仅仅是数据集规模。这种新方法为处理专门领域任务提供了宝贵的见解，如 Autoformalization，这可能会影响 LLM 在该任务上的表现。
### Conclusion
本文的研究结果表明，数据对齐对于 LLM 的下游任务至关重要，特别是在 Autoformalization 等特定任务中。这些结果建议重新评估 LLM 的培训方法，并强调了数据对齐的重要性，而不仅仅是数据集大小。
## 675. `cs.LG` - UniNet：一种用于网络安全的统一多粒度流量建模框架 [PDF](https://arxiv.org/pdf/2503.04174), [HTML](https://arxiv.org/abs/2503.04174)
### Authors
Binghui Wu,Dinil Mon Divakaran,Mohan Gurusamy
### Background
随着现代网络变得越来越复杂，由多种设备、加密协议和不断演进的威胁驱动，网络流量分析变得至关重要。现有的机器学习模型通常仅依赖于包或流的单一表示形式，这限制了它们捕获对于稳健分析来说至关重要的上下文关系的能力。此外，针对监督、半监督和无监督学习的任务特定架构导致了在适应不同数据格式和安全任务时的效率低下。
### Innovation
我们提出了UniNet，一个统一框架，引入了新型多粒度流量表示（T-Matrix），将会话、流和包级特征结合起来，以提供全面的上下文信息。结合T-Attent轻量级注意模型，UniNet能够高效学习不同的安全任务的潜在嵌入。在代表网络安全性与隐私问题的四个关键方面（异常检测、攻击分类、物联网设备识别和加密网站指纹识别）进行了广泛评估，展示了UniNet相比现有先进方法的显著性能提升，具有更高的准确性、更低的假阳性率和更好的可扩展性。
### Conclusion
通过解决单一层面模型的局限性和统一流量分析框架，UniNet为现代网络安全设立了新的基准线。
## 676. `cs.LG` - ForceGrip: Reference-Free Curriculum Learning for Realistic Grip Force Control in VR Hand Manipulation [PDF](https://arxiv.org/pdf/2503.08061), [HTML](https://arxiv.org/abs/2503.08061)
### Authors
DongHeun Han,Byungmin Kim,RoUn Lee,KyeongMin Kim,Hyoseok Hwang,HyeongYeop Kang
### Background
目前的VR手部操作方法往往依赖于kinematic方法或缺乏关键物理属性（如接触力和手指扭矩）的motion-capture数据集，导致这些方法倾向于优先使用紧密的、一刀切的手势，而不是反映用户的力意图。因此，这些方法很难提供符合用户预期力的手部操作。因此，需要一种能够反映用户力意图的、能够生成现实手部操作运动的解决方案来改善用户在VR环境中的体验。
### Innovation
本文提出了ForceGrip，一种深度学习代理，它可以合成现实的手部操作运动，并真实地反映用户的力意图。ForceGrip采用了一种无参考的课程学习框架，通过随机化物体形状、手腕运动和触发输入流来挑战代理进行广泛的物理交互。此外，还采用了一种递进的学习策略，确保手-物接触的稳定性，适应用户输入的力控制，并在动态条件下实现稳健处理。同时，通过引入邻近奖励函数来增强自然的手指运动，加速训练收敛。定量和定性的评估显示ForceGrip相比于现有最先进的方法，具有更强的力控制能力和合理性。
### Conclusion
研究结果表明，ForceGrip能够以更符合用户真实力意图的方式生成现实的手部操作运动，相较于现有方法在力可控制性与合理性方面都表现出更优越的效果。这为用户在虚拟现实中的沉浸体验提供了显著的改进。
## 677. `cs.LG` - 好的表示，更好的解释：基于变换器的遥感影像描述中卷积神经网络的作用 [PDF](https://arxiv.org/pdf/2502.16095), [HTML](https://arxiv.org/abs/2502.16095)
### Authors
Swadhin Das,Saarthak Gupta,Kamal Kumar,Raksha Sharma
### Background
遥感影像描述（RSIC）是对遥感图像生成有意义文本描述的过程，已受到广泛关注。目前，编码器-解码器模型是生成有意义描述的基础。编码器可以从输入图像中提取关键视觉特征，将其转化为紧凑表示，而解码器则使用该表示生成连贯的文本描述。近年来，基于变换器的模型因其捕捉长程依赖性和上下文信息的能力而备受欢迎。尽管解码器在文本生成方面已有良好研究，但编码器仍相对未被充分探索。优化编码器至关重要，因为它直接影响到提取特征的丰富性，进而影响生成描述的质量。因此，系统评估不同的卷积神经网络（CNN）架构在基于变换器的编码器框架中的效果至关重要，以便更好地提升遥感影像描述的性能。
### Innovation
本文在基于变换器的遥感影像描述中评估了十二种不同的卷积神经网络（CNN）架构，并对它们的效果进行了系统性分析。首先，基于不同性能的CNNs进行数值分析，将其分类成不同的簇，然后针对表现最好的CNNs进行人工评估，从人的视角进一步检验效果。此外，还研究了不同的搜索策略，比如贪婪搜索和束搜索，以确保产生最好的描述。研究的结果强调了编码器选择在提高描述性能中的关键作用，显示出特定的CNN架构对遥感影像生成描述的质量有显著的提升作用。通过详细比较多种编码器，这项研究提供了宝贵的见解，有助于指导基于变换器的图像描述模型的发展。
### Conclusion
研究证明选择合适的卷积神经网络在提高遥感影像描述的质量中起到关键作用。特定的CNN架构能够显著提升生成描述的质量。因此，选择合适的编码器对于基于变换器的遥感影像描述模型的发展具有重要的指导意义。
## 678. `cs.LG` - Lie Groups 上的 Flow Matching [PDF](https://arxiv.org/pdf/2504.00494), [HTML](https://arxiv.org/abs/2504.00494)
### Authors
Finn M. Sherry,Bart M.N. Smets
### Background
Flow Matching (FM) 是一种近期的生成模型技术，其目标是通过流动的方式从易于采样的分布 $boldsymbol{frak{X}}_0$ 中抽取样本，从而学习如何从分布 $boldsymbol{frak{X}}_1$ 中采样。传统的 FM 方法假设样本空间为欧几里得空间，因此在到达目标点时沿着直线段运动。然而，当目标点在流形上时，传统的 FM 方法不再有效。Chen 和 Lipman 推广了 FM 方法到黎曼流形上的应用，使用测地线或其谱近似来替代直线段。本文从一个新的角度出发，将 FM 方法推广到 Lie 群上，用指数曲线替代直线段，从而简化了实现过程并加快了计算速度，特别适用于涉及矩阵Lie群的数据生成场景
### Innovation
本文提出了将 Flow Matching 方法推广到 Lie 群上的新视角，用指数曲线替代直线段，使得在很多矩阵 Lie 群上具有简单、内在且快速的实现方法。此外，这种方法可以用于生成具有特征集（在 $boldsymbol{frak{R}}^n$ 中）和姿态（在某个 Lie 群中）的数据集，比如等变神经场的潜在编码
### Conclusion
本文通过将 FM 方法应用到 Lie 群上，提供了一种用于生成具有特征集和姿态的数据的新方法，这种方法特别适用于涉及矩阵 Lie 群的数据场景，简化了实现过程并提高了生成效率
## 679. `cs.LG` - HAPI: 基于人类偏好学习机器人面部表情的模型 [PDF](https://arxiv.org/pdf/2503.17046), [HTML](https://arxiv.org/abs/2503.17046)
### Authors
Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida
### Background
自动机器人面部表情生成对于人机交互至关重要，但基于固定关节配置的手动方法往往会导致僵硬和不自然的表情。尽管最近的自动化技术减少了手动调整的需求，但在准确捕捉人类偏好与模型预测之间的差距方面仍存在不足，导致表情缺乏细腻的真实感，主要由于自由度有限和知觉集成不足。
### Innovation
本文提出了一种新颖的学习排序框架，通过利用人类反馈来解决这一差距问题，提升机器人的面部表达能力。具体来说，我们采用成对比较标注来收集人类偏好数据，并开发了一种基于Siamese RankNet的人类情感成对印象（HAPI）模型，用于细化表情评估。
### Conclusion
我们的方法通过贝叶斯优化和在线表情调查（基于35个自由度的类人平台）得到的结果表明，我们生成的愤怒、快乐和惊讶表情比基线方法和专家设计的方法更为真实和具有社会共鸣。这表明我们的框架有效地改善了人类偏好与模型预测之间的差距，使机器人表情生成更符合人类情感反应。
## 680. `cs.LG` - MaizeField3D: 来自多样品群体的田间生长玉米的3D点云和程序模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
### Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
### Background
由于缺乏大规模和多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具，尤其是针对玉米作物的研究，进展受限。2D图像数据集无法捕捉到3D数据提供的关键结构细节，如叶片结构、植物体积和空间排列。为此，我们开发了MaizeField3D数据集，它是田间生长玉米的3D点云数据集，涵盖一个多样遗传群体，旨在通过人工智能提升农业研究水平。数据集包括1,045个高质量的田间生长玉米的3D点云，使用地面激光扫描仪（TLS）收集。
### Innovation
MaizeField3D创新地提供了1,045个高质量的田间生长玉米的3D点云数据，通过图基分割方法对这组数据进行了分割和标注，确保各样本的一致性标签，并使用NURBS表示叶片，通过无导数和有导数方法结合的两步优化生成。数据集还包括精美的元数据，描述植物形态学和质量，以及不同分辨率的点云数据，可以方便地用于下游计算任务。该数据集将作为面向AI驱动的表型分析、植物结构分析以及农业研究的3D应用的基础数据集。
### Conclusion
MaizeField3D数据集将为AI驱动的玉米植物表型分析提供全面的基础，有助于植物结构分析，并为农业研究中的3D应用奠定基础。
## 681. `cs.LG` - 位置-方向对之间具有普适性的欧几里得不变量集 [PDF](https://arxiv.org/pdf/2504.03299), [HTML](https://arxiv.org/abs/2504.03299)
### Authors
Gijs Bellaard,Bart M. N. Smets,Remco Duits
### Background
已有的欧几里得E(3)不变的神经网络在分子动力学预测等任务中取得了成功，但在这些架构中进行仿射不变卷积操作需要在M(3) x M(3)上定义欧几里得不变核。在实践中，通过选择手工构建的不变量集合，然后再利用多层感知机参数化这些核。然而，当前方法缺乏通用性，通过严格描述整个M(3) x M(3)上的4个平滑标量不变量来解决这个问题，确保这些不变量集合是独立且普适的，即所有不变量都是相关的，任意不变量核均可表示为它们的函数。实验使用PONITA神经网络架构评估了包含通用不变量集合和非通用不变量集合的效果，结果表明，使用普适不变量集合可以显著提高PONITA的准确性。
### Innovation
提出了一种最优的、独立且普适的4个平滑标量不变量集合，可以在整个M(3) x M(3)上应用。通过这种方法，计算出的不变量集合确保了任一不变量核都可以通过它们表示，具有较高的理论和实际应用价值。实验表明，使用该集合中的普适不变量进行计算可以显著提高模型的预测准确性。
### Conclusion
通过定义M(3) x M(3)上的通用不变量集合，改进了现有仿射不变核的设计方法，提高了基于位置-方向对的欧几里得不变网络的性能，实验结果证明这种方法的有效性。
## 682. `cs.LG` - 基于注意力机制的聚类 [PDF](https://arxiv.org/pdf/2505.13112), [HTML](https://arxiv.org/abs/2505.13112)
### Authors
Rodrigo Maulen-Soto(SU, LPSM (UMR?_8001)),Claire Boyer(IUF),Pierre Marion(EPFL)
### Background
Transformer架构因其在各种学习任务中的强大能力而受到广泛关注，本研究旨在从理论上分析其在无监督环境中自动从数据中提取结构的能力，特别是探讨其在输入数据服从高斯混合模型时进行聚类的适用性。研究通过简化为两头注意力层，并定义一个基于无标签数据最小化的群体风险，推动头参数与真实混合质心对齐，突出了基于注意力机制的层捕捉潜在分布结构的能力。进一步研究固定键、查询和值矩阵为目标值的注意力层，展示了即使没有可训练参数，它也能进行上下文量化，揭示了基于Transformer方法动态适应输入特定分布的强大潜力。
### Innovation
研究提出了一种简化为两头注意力层的模型，并定义了一个群体风险函数，通过无标签数据的最小化来促使头参数与真实混合质心对齐，进一步探讨了一个固定键、查询和值矩阵的注意力层，显示了即使没有可训练参数也能进行上下文量化的能力，突出了基于Transformer方法在处理特定数据分布时的适应性。
### Conclusion
研究结果表明，基于注意力机制的Transformer层在聚类任务中的潜在分布捕捉能力，尤其是在数据来源为高斯混合模型的情况下，展示了其强大的无监督学习能力，以及动态适应特定数据分布的潜力。
## 683. `cs.LG` - SoccerDiffusion：从游戏记录学习端到端的人形机器人足球 [PDF](https://arxiv.org/pdf/2504.20808), [HTML](https://arxiv.org/abs/2504.20808)
### Authors
Florian Vahl,Jörn Griepenburg,Jan Gutsche,Jasper Güldenstein,Jianwei Zhang
### Background
本文介绍了一种基于变压器的扩散模型——SoccerDiffusion，该模型直接从真实的足球比赛记录中学习人形机器人的全程控制策略。研究利用了从RoboCup机器人世界杯收集的数据，能够从包括视觉、本体感受和比赛状态在内的多模态传感器输入中预测关节命令轨迹。该模型的主要背景在于需从实际比赛数据中学习复杂的现实控制策略，以实现真实场景中的机器人足球比赛。尽管高级战术行为仍有限，但这项工作为后续的强化学习或偏好优化方法提供了坚实的基础。
### Innovation
该模型的创新之处在于它可以直接从实际比赛数据中学习，无需人工标注的示例。采用蒸馏技术将多步扩散过程简化为单步，从而允许在嵌入式平台上实现实时推理。该项工作还展示了该模型在模拟和物理机器人上的复杂运动行为（如行走、踢球和摔倒恢复）的复制能力。
### Conclusion
尽管高级战术行为仍然有限，但SoccerDiffusion模型为后续的强化学习或偏好优化方法提供了坚实的基础。作者已经发布了该模型的数据集、预训练模型和代码，以便其他研究者可以进一步研究和拓展。
## 684. `cs.LG` - 跨语言旅行：多模态大语言模型跨语言一致性 benchmarking [PDF](https://arxiv.org/pdf/2505.15075), [HTML](https://arxiv.org/abs/2505.15075)
### Authors
Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara
### Background
多模态大语言模型（MLLMs）的迅速发展显著提升了它们的实际应用能力，但在跨语言表现，尤其是融合文化知识时，仍面临重大挑战。目前缺乏有效评估工具来检测和改进这种跨语言一致性问题。
### Innovation
提出了两个新的基准：KnowRecall和VisRecall。KnowRecall是一个跨语言视觉问答基准，用于测量15种语言中的事实知识一致性，特别是关于全球知名地标的文化和历史问题。VisRecall则评估模型在未提供图片情况下，9种语言中对地标视觉记忆的一致性。实验结果表明，最新的MLLMs，包括专有的模型，在跨语言一致性方面仍有明显不足，突显了需要更稳健的多语言和文化意识模型的重要性。
### Conclusion
最新的MLLMs无法实现跨语言一致性，强调了开发真正多语言和文化意识模型的必要性。
## 685. `cs.LG` - 使用物理导向神经网络解开粒子暗物质 [PDF](https://arxiv.org/pdf/2502.17597), [HTML](https://arxiv.org/abs/2502.17597)
### Authors
M.P. Bento,H.B. Câmara,J.F. Seabra
### Background
本文使用物理导向神经网络(PINNs)参数化求解替代宇宙学中的玻尔兹曼方程，以处理冻结入暗物质(DM)的问题。传统的数值求解方法通常依赖网格，而PINNs作为一种无网格方法，可以更好地捕捉物理规律，从而提高求解精度和效率。通过单一的DM观测残余物质密度点，利用逆PINNs，本文确定了理论的物理属性，如幂律宇宙学（受到超薄层场景的启发）和粒子相互作用截面。宇宙在这些替代宇宙学中的膨胀被参数化为一个切换函数，该函数在后期时间再现哈勃定律，并通过光滑函数更真实地建模这一过渡过程。
### Innovation
本文创新性地使用物理导向神经网络解决玻尔兹曼方程，利用无网格方法对冻结入暗物质进行研究。通过单一的DM观测残余物质密度点，确定理论的物理属性，包括幂律宇宙学和粒子相互作用截面。此外，通过构建切换函数和光滑函数，更真实地建模宇宙膨胀过程中断的过渡，提高了模型的物理合理性。最后，通过贝叶斯方法量化理论参数在逆问题中的 epistemic 不确定性。
### Conclusion
本文通过物理导向神经网络成功确定了替代宇宙学中的DM机制及其相关的物理属性。研究发现，给定幂律指数为负（正）的宇宙学，所需的粒子相互作用截面越小（越大）以匹配观测数据。同时，通过贝叶斯方法，评估了理论参数的 epistemic 不确定性。这项工作不仅深化了我们对冻结入暗物质的理解，也为未来研究暗物质提供了新的工具和技术手段。
## 686. `cs.LG` - 位置-姿态空间中的旋转平移不变度量 [PDF](https://arxiv.org/pdf/2504.03309), [HTML](https://arxiv.org/abs/2504.03309)
### Authors
Gijs Bellaard,Bart M. N. Smets
### Background
在图像分析任务，如增强、去噪和分割中，位置-姿态空间M(3)上的旋转平移群SE(3)不变的黎曼度量起着关键作用。这些度量使得旋转平移协变算法成为可能，伴随的黎曼距离常用于实施中。然而，计算黎曼距离代价高昂，使其不适用于需要频繁重计算的情况。
### Innovation
作者提出了一个称为mav（最小角速度）的距离作为实用替代方案，它定义为几何意义明确的曲线的黎曼长度。mav距离被应用于几何深度学习，神经网络架构如PONITA依赖于几何不变量来构建旋转平移协变模型。mav距离提供了一种可训练的不变量，决定黎曼度量的参数作为可学习的权重。本研究通过分类并参数化所有SE(3)不变度量，高效计算mav距离，并研究其在PONITA模型中的应用能否提高其预测分子性质的准确性来创新。
### Conclusion
本文分类并参数化了所有SE(3)不变度量，描述了高效计算mav距离的方法，并调查了将mav距离纳入PONITA模型是否能提升其预测分子性质的准确性。
## 687. `cs.LG` - 无需边缘相关性的渐近完美带种子图匹配及其推断应用 [PDF](https://arxiv.org/pdf/2506.02825), [HTML](https://arxiv.org/abs/2506.02825)
### Authors
Tong Qi,Vera Andersson,Peter Viechnicki,Vince Lyzinski
### Background
在$d$维随机点积图（RDPG）的背景下，研究了带种子的多图匹配算法。背景信息指出，OmniMatch算法能够在少量种子节点的帮助下，在多个网络中近乎完美地匹配大量节点，即使在网络之间不存在边缘相关性时也能实现这一目标。这为处理有多网络数据集之间的节点成对匹配问题提供了一种有效的解决方案，尤其是在节点间以及网络间缺乏直接对应关系的情况下。实验结果表明该算法在广泛的仿真实验中有效，并且在置换图假设检验的场景下能够纠正节点错位问题，以恢复测试的功效。算法还在连接组学和机器翻译的数据示例中进行了展示。背景信息还指出，传统的图匹配算法可能无法在缺乏节点间对应关系的网络之间进行有效匹配，并且在置换图假设检验时可能会损失测试效能。
### Innovation
OmniMatch算法提出了一种在多图匹配中利用种子节点的方法，即使在网络之间没有边缘相关性的情况下也能实现近乎完美的节点匹配。这一创新主要体现在能够在置换图假设检验场景中纠正节点错位问题，从而恢复因置换导致的测试功效损失。这种能力使得算法在处理复杂网络数据时更加有力和有效。此外，该算法在连接组学和机器翻译领域数据的实际应用中亦展现了其优越性。
### Conclusion
研究提出了一种基于种子节点的OmniMatch算法，该算法能够在不存在边缘相关性的条件下实现多图之间的完美匹配。通过与置换图假设检验结合使用，它可以有效纠正节点错位，恢复测试效能。此外，该算法在连接组学和机器翻译的实际数据集上得到了成功应用，证明了其在实际应用中的有效性和优越性。
## 688. `cs.LG` - 矩形实矩阵的高阶奇异值导数 [PDF](https://arxiv.org/pdf/2506.03764), [HTML](https://arxiv.org/abs/2506.03764)
### Authors
Róisín Luo,James McDermott,Colm O'Riordan
### Background
通过利用Kato的自伴算子解析扰动理论中的简化的馀子算子，提出了一个理论框架来推导实矩形矩阵中奇异值的一般n阶弗雷彻导数。利用标准矩阵分析技术直接获得高阶奇异值导数是非常具有挑战性的。本文将实矩形矩阵视为有限维希尔伯特空间上的紧致算子，并将其嵌入到块自伴算子中以捕捉非对称扰动。应用Kato的渐近特征值展开，得到了一般形式的谱变化的微分表达式。通过将抽象的算子理论扰动理论和矩阵结合，本文为随机矩阵应用（例如深度学习中的对抗性扰动）中的高阶谱敏感性研究提供了一套实用的工具箱。
### Innovation
利用Kato的解析扰动理论中的简化的馀子算子，得到了实矩形矩阵中奇异值的一般n阶弗雷彻导数的理论框架。将实矩形矩阵视为有限维希尔伯特空间上的紧致算子，并将其嵌入到块自伴算子中以捕捉非对称扰动。通过对这一结构应用Kato的渐近特征值展开，获得了一般形式的谱变化的微分表达式。特别是，针对n=2时，使用Kronecker乘积表示和矩阵约定，得到了奇异值的海赛矩阵，这是文献中未找到的。
### Conclusion
本文通过将抽象的算子扰动理论与矩阵分析相结合，提供了一种用于随机矩阵应用中高阶谱敏感性研究的实用工具箱，特别是对于深度学习中的对抗性扰动。
## 689. `cs.LG` - 使用数字孪生隐私保护的手术室工作流程分析 [PDF](https://arxiv.org/pdf/2504.12552), [HTML](https://arxiv.org/abs/2504.12552)
### Authors
Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath
### Background
手术室是一个复杂的环境，优化工作流程对于减少成本和改善患者结果至关重要。尽管计算机视觉方法可以自动识别围手术期事件并识别手术室优化的瓶颈，但隐私问题限制了手术室视频在自动事件检测中的使用。因此，本文提出了一种两阶段的管道来实现手术室视频分析和事件检测的隐私保护方法。该方法通过使用基于视觉的预训练模型生成手术室的匿名数字孪生（DT）来实现，最终使用SafeOR模型进行事件检测，这是一种融合的双流方法，能够处理分割掩码和深度映射来实现手术室事件检测。该方法已经在38次模拟手术中表现出了与原始RGB视频基础模型相当甚至更好的可达性能。
### Innovation
该研究提出了一种隐私保护的手术室视频分析的两阶段管道，该管道首先利用基于视觉的预训练模型生成手术室的匿名数字孪生（DT），然后使用SafeOR模型针对分割掩码和深度图进行手术室事件检测。该方法能够确保手术室工作流程的数据隐私，促进机构间匿名数据的共享，减轻特定领域的外观差异以增强模型的泛化能力，并展示了与原始RGB视频基础模型相当甚至更好的事件检测性能。
### Conclusion
使用数字孪生的差分隐私方法能够提供一种隐私保护的手术室工作流程分析策略，这一方法不仅保证了数据的安全，还提高了数据的共享和模型的适用性。研究评价结果显示，该方法在手术室事件检测中展现了优秀的性能，并且有潜力在大型多机构研究中推广应用。
## 690. `cs.LG` - 评估高斯过程回归的量子优势 [PDF](https://arxiv.org/pdf/2505.22502), [HTML](https://arxiv.org/abs/2505.22502)
### Authors
Dominic Lowe,M.S. Kim,Roberto Bondesan
### Background
高斯过程回归是一种广为人知的机器学习技术，已有多种量子算法被提出。然而，这些算法在大多数情况下并没有显示指数级的速度提升。本文通过严谨证明，在一般数据和核函数假设下，核矩阵的条件数至少按矩阵大小成线性增长。此外还证明了核矩阵的稀疏性和Frobenius范数在相似假设下也呈线性增长。这些结论意味着量子算法的运行时与将经典数据导入量子计算机的复杂性无关，并也适用于去量子化算法。我们通过数值验证支持了这些理论分析，适用于机器学习中流行的核函数。
### Innovation
本文通过严密的理论分析表明，高斯过程回归在量子计算上并不存在指数级的速度优势。这一结论通过证明核矩阵的条件数、稀疏性和Frobenius范数均按线性关系增长来得出。此外，该结果适用于现有和未来的去量子化算法，扩大了适用范围。
### Conclusion
无论是对现有量子算法还是去量子化算法，高斯过程回归在量子上的优势并不明显。本文的理论和数值分析结果支持了这一点，为未来研究指明了方向。
## 691. `cs.LG` - 使用扩散模型的具有文本意识的图像恢复 [PDF](https://arxiv.org/pdf/2506.09993), [HTML](https://arxiv.org/abs/2506.09993)
### Authors
Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim
### Background
现有的基于扩散的图像恢复方法在自然图像的恢复上取得了巨大成功，但在恢复退化图像中的文本区域时，常常难以还原文本的真实性。这些方法经常生成合理但错误的像文本一样的模式，这种现象被称为图像文本幻觉。因此，本文探讨了同时恢复视觉内容和文本真实性这一新的图像恢复任务，提出了Text-Aware Image Restoration (TAIR)。
### Innovation
本文提出了一种新的基准数据集SA-Text，包含10万高质量场景图像， densely标注有多样复杂的文本实例，并提出了一种多任务扩散框架TeReDiff，将扩散模型的内部特征集成到文本识别模块中，使得两个模块可以通过联合训练同时受益，从而提取丰富的文本表示，并作为后续去噪步骤的提示。实验结果表明，本文的方法在文字识别准确性上明显优于现有最先进的恢复方法。
### Conclusion
本文提出的方法在文本图像恢复中表现出色，能够显著提高文字识别的准确性，超越了最新的一系列图像恢复方法。
## 692. `cs.LG` - 多环境数据的贝叶斯不变性建模 [PDF](https://arxiv.org/pdf/2506.22675), [HTML](https://arxiv.org/abs/2506.22675)
### Authors
Luhuan Wu,Mingzhang Yin,Yixin Wang,John P. Cunningham,David M. Blei
### Background
Peters等人的研究表明，可以通过分析来自多个环境的特征/结果数据来识别具有稳定预测关系的不变特征。这些特征有助于新环境下的泛化，并有助于揭示因果机制。以往的方法主要通过假设检验或正则化优化来解决这一问题。本文在此基础上发展了贝叶斯不变预测（BIP），这是一个用于不变预测的概率模型。BIP将不变特征的索引作为潜在变量，并通过后验推断恢复它们。在Peters等人的假设下，BIP的后验目标真实的不变特征。我们证明了后验的一致性，并说明更大的环境异质性会导致更快的后验收缩。为了处理大量特征，我们设计了一个高效的变分近似方法称为VI-BIP。在模拟和实际数据中，我们发现BIP和VI-BIP比现有方法更准确且更具扩展性。
### Innovation
本文提出了一种新的贝叶斯不变预测（BIP）方法，它是一种用于不变预测的概率模型。BIP将不变特征的索引作为潜在变量，并通过后验推断恢复它们。为了处理大量特征，还设计了高效的变分近似方法VI-BIP。该方法在真实数据和模拟中均表现出更高的准确性和扩展性，且在更大的环境异质性下能更快地收敛。
### Conclusion
本文通过引入贝叶斯不变预测（BIP）和变分近似VI-BIP，对于来自多个环境的特征/结果数据的不变特征识别提供了一种更为准确和高效的方法，能够揭示更深层次的因果机制，且在环境数据异质性增加的情况下，能更快地收敛于真实不变特征。
## 693. `cs.SE` - 软件工程候选人如何为技术面试做准备？ [PDF](https://arxiv.org/pdf/2507.02068), [HTML](https://arxiv.org/abs/2507.02068)
### Authors
Brian Bell,Teresa Thomas,Sang Won Lee,Chris Brown
### Background
为了获得软件工程师职位，求职者需要完成技术面试——这一招聘过程包括候选人边编码边向观众交流。然而，技术面试的复杂性难以提前准备，且在计算课程中学到的很少。因此，研究者旨在了解求职者如何为技术面试做准备，研究不同的准备方法及其教育作用。通过向131名正在积极准备技术面试的求职者发放调查问卷，发现求职者很少在真实环境中进行训练，而课程对准备支持不足，导致压力和准备不足的问题。
### Innovation
研究通过问卷调查的方式，揭示了求职者准备技术面试的实际状况，特别是他们通常没有在真实环境中训练，以及课程支持不足的问题。这一研究提供了对于求职和其他利益相关方关于如何改进技术面试准备的建议。
### Conclusion
研究结果表明，求职者准备技术面试时面临很大的压力和准备不足的问题，主要原因是缺乏真实环境的训练和教育课程的支持不够。研究提出了相关建议，以帮助求职者更好地准备技术面试。
## 694. `cs.LG` - 从网页搜索向有代理深度研究过渡：用推理代理激励搜索 [PDF](https://arxiv.org/pdf/2506.18959), [HTML](https://arxiv.org/abs/2506.18959)
### Authors
Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu
### Background
信息检索是现代知识获取的基础，每天跨多种领域处理数十亿查询。然而，传统的基于关键词的搜索引擎对于处理复杂的、多步骤的信息需求已越来越不够。有代理深度研究（Agentic Deep Research）作为一种新范式，通过将自主推理、迭代检索和信息综合紧密结合成动态反馈循环，超越了传统的信息检索技术。
### Innovation
该研究通过将自主推理、迭代检索和信息综合紧密结合成动态反馈循环，提出了一种新范式——有代理深度研究。提出了一个测试时的计算深度规模法则来正式化推理和搜索的影响。结果显示，有代理深度研究不仅显著优于现有方法，还预示着将成为未来信息检索的主导范式。
### Conclusion
有代理深度研究通过基准结果和开源实现展示出其显著优势，并成为未来信息获取的主导范式。所有相关资源，包括行业产品、研究论文、基准数据集和开源实现，已在 https://example.com/ 收集供社区使用。
## 695. `cs.LG` - 通过视觉转文本的隐私保护技术在自动驾驶车辆中的应用 [PDF](https://arxiv.org/pdf/2506.15854), [HTML](https://arxiv.org/abs/2506.15854)
### Authors
Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy
### Background
CAVs依赖于各种设备，这些设备常常处理隐私敏感数据，其中，道路旁单元在利用AI装备摄像机进行违章检测等应用时扮演关键角色。然而，捕捉到的图片数据存在较大隐私风险，如身份盗窃、画像分析或未经授权的商业使用。尽管使用遮盖和模糊化等传统技术可以缓解部分风险，但个体隐私依然处于危险中，其他特征因素如穿着仍然可用于追踪。因此，本研究旨在开发一种新的隐私保护框架，该框架利用基于反馈的强化学习（RL）和视觉语言模型（VLMs），将由AI摄像机捕获的敏感视觉信息转化成语义等价的文本描述，确保保持相关场景信息的同时保护视觉隐私，试验结果表明，保护隐私和文本质量均有显著改善，独特词占比约提高77%，细节密度约提高50%，优于现有方法。
### Innovation
该研究提出了一种新颖的隐私保护框架，结合基于反馈的强化学习（RL）和视觉语言模型（VLMs），用于通过将由AI摄像机捕获的敏感视觉信息转化为等价的文本描述，保护隐私，同时保持场景相关的信息。
### Conclusion
通过视觉转文本的方法，在保护隐私的同时显著提高了文本质量和保持了场景相关信息，相比现有方法有显著的改善。
## 696. `cs.LG` -  Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop [PDF](https://arxiv.org/pdf/2506.23351), [HTML](https://arxiv.org/abs/2506.23351)
### Authors
Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yu Chen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu
### Background
随着对能够感知、推理和在复杂物理环境中执行任务的自主系统需求的增加，沉浸式人工智能（Embodied AI）是机器人技术的一个新兴前沿领域。尽管单臂系统在单个任务性能上表现出色，但协作双臂系统对于处理涉及刚性、可变形和触觉敏感对象的复杂任务是必不可少的。为了推进这一目标，我们在2025年CVPR会议的第2届MEIS研讨会中启动了RoboTwin双臂协作挑战赛。该挑战基于RoboTwin仿真平台（1.0和2.0版本）和AgileX COBOT-Magic机器人的平台进行。比赛分为三个阶段：仿真阶段1、仿真阶段2和最终的实地阶段。参赛者总共完成了17项双臂操作任务，覆盖了刚性、可变形和基于触觉的场景。
### Innovation
该挑战基于RoboTwin仿真平台（1.0和2.0版本）和AgileX COBOT-Magic机器人的平台进行，并且分为三个阶段：仿真阶段1、仿真阶段2和最终的实地阶段。它吸引了来自全球的64个团队和超过400名参与者，产生了像SEM和AnchorDP3等顶级解决方案，为通用双腕操作策略的学习提供了宝贵见解。该报告详细介绍了挑战的设置、任务设计、评估方法、关键发现和未来方向，旨在支持未来关于稳健且可泛化的双腕操作策略研究。比赛网页可在此访问：http://www.samplewebsite.com
### Conclusion
这项挑战赛支持了未来关于构建稳健且可泛化的双腕操作策略的研究，提出了通用化的双臂策略学习的重要发现，并为后续的机器人操作研究提供了有价值的参考。
## 697. `cs.SE` - 结合生物识别与自我报告工具监测编程中压力的一种多模态方法：方法论启示 [PDF](https://arxiv.org/pdf/2507.02118), [HTML](https://arxiv.org/abs/2507.02118)
### Authors
Cristina Martinez Montes,Daniela Grassi,Nicole Novielli,Birgit Penzenstadle
### Background
传统的幸福感、压力和其他人类因素研究依赖自我报告仪器来评估关键变量，尽管这些仪器经过充分验证和标准化，但仍存在可能的偏倚问题。因此，研究者有了越来越大的兴趣将这些评估指标与客观方法结合使用，如生理学测量。本研究旨在比较心理测量压力指标和生物指标，并找出编程任务中生物数据的相关压力模式。提出的实验方法包括预调查、戴上生物传感器编程两个任务、事后简短调查，以及简短访问访谈。结果发现，心理测压器没有显示出压力，采访中参与者报告了不同程度的压力，主要是时间压力。最后，生物指标仅在EDR突起中显示出显著差异。这表明设置更严格的时限来诱导压力的方法不够有效。提供给未来研究有关压力、生物识别和心理测量仪器的方法论见解。
### Innovation
提出了结合生物识别与自我报告工具监测编程中压力的一种多模态方法，通过比较心理测量压力指标和生物指标，发现即便在预设严格时限下，也未能有效诱导出显著的压力反应。
### Conclusion
所选择通过设置更严格的时限来诱导压力的方式是不足的。研究结论为未来研究提供了关于压力、生物指标和心理测量仪器使用的方法论启示。
## 698. `cs.LG` - Skywork-Reward-V2：通过人机协同扩展偏好数据治理 [PDF](https://arxiv.org/pdf/2507.01352), [HTML](https://arxiv.org/abs/2507.01352)
### Authors
Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou
### Background
尽管奖励模型（RMs）在基于人类反馈的强化学习（RLHF）中发挥着关键作用，当前最先进的开放性奖励模型在大多数现有评估基准测试中表现不佳，无法准确捕捉人类微妙且复杂的偏好。即使使用了高级训练技术的方法，在性能提升方面也未能取得有意义的进步。这一脆弱性主要源于偏好数据集的限制，这些问题通常包括范围狭窄、合成标签或缺乏严格的质量控制。因此，本文提出了一个包含4000万偏好对的大型偏好数据集，名为SynPref-40M，并设计了一个人机协同的两阶段数据治理管道，以提升数据的质量和效率。
### Innovation
本文引入了一个大规模偏好数据集——SynPref-40M，规模为4000万，并提出了一种人机协同的两阶段数据治理管道，充分发挥了人类标记质量和AI可扩展性的优势。同时，本文还提出了Skywork-Reward-V2系列奖励模型，包括8个从0.6B到8B参数的模型，训练数据选择自精心治理的SynPref-40M的2600万偏好对子集。实验表明，Skywork-Reward-V2系列在多种能力上表现出色，尤其是在与人类偏好一致、客观正确性、安全性和抗风格偏见方面，并在多个奖励模型基准测试中达到最新水平。分析还证实了该方法的有效性不仅来自于数据规模，也来自于高质量的数据治理。
### Conclusion
Skywork-Reward-V2系列在开放奖励模型方面取得了显著进展，展示了现有偏好数据集的未开发潜力，并证明了人机治理协同作用可以实现更高数据质量，从而解决之前方法的局限性。
## 699. `cs.SE` - 使用自然语言查询的结构化代码搜索 [PDF](https://arxiv.org/pdf/2507.02107), [HTML](https://arxiv.org/abs/2507.02107)
### Authors
Ben Limpanukorn,Yanjun Wang,Zach Patterson,Pranav Garg,Murali Krishna Ramanathan,Xiaofei Ma,Anoop Deoras,Miryung Kim
### Background
开发者通常通过关键字和正则表达式来进行代码搜索，以理解API、学习常见代码模式和导航代码。除了关键字和正则表达式外，结构性代码搜索工具允许开发者根据代码的语义结构进行搜索，这在从查找错误到系统地重构代码等方面具有广泛的用途。然而，现有的结构性代码搜索工具依赖于领域特定语言（DSL）表达查询，这些语言难以学习和编写。研究提出了一种新的方法，通过结合生成式大语言模型（LLM）来解释自然语言搜索查询的能力以及结构性搜索工具的高效性和准确性，以检索相关代码。方法被应用于两种结构性代码搜索DSL：Semgrep和GQL。在评估中创建了一个新的结构性代码搜索基准，包含10个Java项目中的400个查询，结果表明基于LLM将自然语言查询翻译成DSL查询的方法在精确度和召回率方面非常有效，并且提高了57%和14%的F1分数，从而显著优于基于语义代码搜索和LLM检索的基线方法。
### Innovation
提出了一种新的方法，通过结合生成式大语言模型来解释自然语言搜索查询的能力以及结构性搜索工具的高效性和准确性，以检索相关代码。该方法被应用于两种结构性代码搜索DSL：Semgrep和GQL。此方法在精确度和召回率方面展示了高效率，并且在F1分数方面比基线方法显著提高。
### Conclusion
基于生成式大语言模型将自然语言查询翻译成结构性代码搜索DSL查询的方法在结构性代码搜索中是有效且稳健的。该方法不仅提高了开发者使用自然语言进行结构性搜索的便捷性，还显著提高了搜索结果的质量，特别是在F1分数方面。
## 700. `cs.LG` - 金融报告综合风险评估的可解释人工智能：一种轻量级分层变换器网络方法 [PDF](https://arxiv.org/pdf/2506.23767), [HTML](https://arxiv.org/abs/2506.23767)
### Authors
Xue Wen Tan,Stanley Kok
### Background
每年美国所有上市公司的年度10-K报告都包含对公司财务健康状况和风险的关键见解。目前的风险评估方法主要基于超额收益的标准差，这种方法对上行风险和下行风险进行了无差别的惩罚。本文在此基础上，提出了Tiny eXplainable Risk Assessor (TinyXRA)，一种轻量级且可解释的基于变换器的风险评估模型，用于自动从这些报告中评估公司风险。利用TinyBERT编码器高效处理长篇财务文档，并通过一种新颖的动态、基于注意力机制的词云机制，提供直观的风险可视化，过滤无关术语。该模型在资源有限的环境下具有可扩展性，能够实现实时处理成千上万的财务文档，对于计算资源有限的生产系统尤为重要。作者采用三元损失来进行风险四分位分类，这种方法比现有的成对损失方法更能捕捉风险变化的方向和幅度。TinyXRA在2013年至2024年七年的测试中实现了最先进的预测准确率，同时提供了透明且可解释的风险评估结果。
### Innovation
TinyXRA 模型创新地采用了新的风险评估指标（包括偏度、峰度和Sortino比率），以实现更全面的风险评估。它利用TinyBERT高效处理财务文档，并通过动态、基于注意力机制的词云机制提供直观的风险可视化。采用三元损失进行风险分类，相比现有的成对损失方法，能够更好地捕捉风险变化的方向和幅度。模型提供可扩展的轻量级设计，适用于资源有限的计算环境，并且具有实时处理大量财务文档的能力。此外，通过消除高度关注的词汇和句子以及解释一致性测试来评估模型解释性。
### Conclusion
本文通过全面的消融实验研究，评估了模型的贡献，并从定量和定性的角度评估了模型解释能力。结论部分概述了研究发现、实际意义、研究局限性和未来的研究方向。本文提供的代码可以在 [这里](this https URL) 获取。
## 701. `cs.SE` - 使用大型语言模型的多智能体方法增强COBOL代码解释 [PDF](https://arxiv.org/pdf/2507.02182), [HTML](https://arxiv.org/abs/2507.02182)
### Authors
Fangjian Lei,Jiawen Liu,Shayan Noei,Ying Zou,Derek Truong,William Alexander
### Background
COBOL是一种广泛应用于金融、商业和政府机构的业务应用开发的语言，但由于其年代久远、复杂性高以及COBOL开发人员的减少，维护COBOL代码库变得越来越具有挑战性。尤其是缺乏文档使得新开发者难以有效地理解和维护COBOL系统。现有的研究利用大型语言模型（LLMs）来解释代码片段的功能，但COBOL因其架构和语法的不同而具有独特挑战，经常导致代码超过LLMs的令牌窗口大小。
### Innovation
本文提出了一种多智能体方法，利用两个基于LLM的代理合作生成函数、文件和整个项目的解释，并通过利用代码库的相关信息改进代码解释提示。在14个开源的实际COBOL项目中评估了该方法的有效性。结果显示，该方法在功能代码解释方面显著优于基线，分别提高了12.67%、18.59%和0.62%的METEOR、chrF和SentenceBERT得分。在文件层面，该方法能够有效地解释既包含短代码也包含超出LLMs令牌窗口大小的长COBOL文件，并在解释目的、功能和生成解释的清晰度方面分别提高了4.21%、10.72%和14.68%。在项目层面，该方法生成的解释传达了82%选定项目的功能和目的。
### Conclusion
该研究提出的方法在多个层面提高了COBOL代码解释的质量，特别是在功能代码解释中表现尤为突出，能够更好地支持COBOL系统的维护和更新。
## 702. `cs.SE` - 在软件工程中实现可靠的舆情分析：数据集特征与工具选择 [PDF](https://arxiv.org/pdf/2507.02137), [HTML](https://arxiv.org/abs/2507.02137)
### Authors
Martin Obaidi,Marc Herrmann,Jil Klünder,Kurt Schneider
### Background
软件开发依赖于文本通信，使得情感分析成为理解团队动态和支持基于AI的可信需求工程分析的重要工具。然而，现有的情感分析工具往往在不同平台的数据集上表现不一致，这归因于沟通风格和内容的差异。因此，需要针对不同数据集的特性和上下文，优化情感分析工具的选择和评估方法。
### Innovation
该研究通过分析来自五个平台的10个开发人员通信数据集的语言和统计特征，并评估了14种情感分析工具的表现。根据研究结果，提出了一种映射方法和问卷，用于推荐合适的工具给新的数据集，输入工具选择依据数据集的特征。这项研究强调了数据集特征在工具选择中的作用，并发现虽然基于变换器的模型如SetFit和RoBERTa能够取得稳定的良好结果，但工具的有效性仍然依赖于具体的应用场景。
### Conclusion
我们的研究显示，可以利用数据集的特征来提高工具选择的效果，因为不同平台在语言和统计属性方面存在显著差异。在此基础上，提出了一个支持研究人员和实践者选择可靠的情感分析工具的方法。同时，也强调在沟通情景不断变化的情况下，需要持续进行工具的评估。
## 703. `cs.SE` - 通过基于LLM的单元测试生成精确检测Python类型错误 [PDF](https://arxiv.org/pdf/2507.02318), [HTML](https://arxiv.org/abs/2507.02318)
### Authors
Chen Yang,Ziqi Wang,Yanjie Jiang,Lin Yang,Yuteng Zheng,Jianyi Zhou,Junjie Chen
### Background
Python中的类型错误通常会导致运行时故障，对软件可靠性和开发者生产力构成重大挑战。现有的静态分析工具旨在不执行的情况下检测这些错误，但经常会受到高假阳性率的影响。最近，单元测试生成技术显示出巨大的潜力，能够在高水平上实现测试覆盖，但它们在不经过专门指导的情况下往往难以生成揭示错误的测试用例。为了应对这些限制，我们提出了一种名为RTED的新颖类型感知测试生成技术，用于自动检测Python类型错误。RTED结合逐步类型约束分析与反射验证，指导测试生成过程，并有效抑制假阳性。
### Innovation
RTED结合了逐步类型约束分析与反射验证，能够有效抑制假阳性，并在两个广泛使用的基准测试（BugsInPy和TypeBugs）上检测到比四种最新技术多22-29个类型错误，同时在精确度方面取得显著提高，提高了173.9%-245.9%。此外，RTED还成功发现来自六个实际开源Python项目的12个以前未知的类型错误。
### Conclusion
实验结果表明，RTED在检测Python类型错误方面比现有的先进技术更为精确，具有更高的检测效率和更低的假阳性率。
## 704. `cs.SE` - Meta-Fair：大语言模型公平性测试的人工智能辅助方法 [PDF](https://arxiv.org/pdf/2507.02533), [HTML](https://arxiv.org/abs/2507.02533)
### Authors
Miguel Romero-Arjona,José A. Parejo,Juan C. Alonso,Ana B. Sánchez,Aitor Arrieta,Sergio Segura
### Background
公平性是人工智能系统开发中的核心原则，但在评估和执行公平性方面仍然存在困难。当前对大型语言模型（LLMs）公平性的测试方法往往依赖于手动评估、固定的模板、确定性的启发式方法和精心策划的数据集，这使得它们资源密集且难以扩展。这些方法难以应对LLMs复杂性和多样性的挑战。
### Innovation
该研究提出了一个名为Meta-Fair的新颖自动化方法，用于测试LLMs的公平性，减少对特定领域资源的依赖，并扩展当前方法的应用范围。该方法基于两个关键理念：首先，采用元测试以发现偏差，通过研究模型输出在输入提示受控修改后的变化；其次，利用LLMs生成测试案例和输出评估的优势，利用它们的能力生成多样化的输入并有效分类输出。为此，提供了三个开源工具支持LLMs驱动的测试案例生成、执行和评估。实验结果表明，该方法在测试LLMs中的偏差方面非常有效，平均精度达到92%，揭示了29%的执行中存在偏见行为。此外，LLMs作为评价器表现出较高的可靠性和一致性，最佳模型的F1分数达到0.79。尽管非确定性会影响一致性，但通过精心设计元关系可以获得一定程度的缓解。
### Conclusion
虽然还有挑战需要克服以确保更广泛的适用性，但该研究为前所未有的LLMs测试自动化水平提供了有希望的道路。
## 705. `cs.SE` - 研究软件工程师和软件工程研究人员使用相同语言吗？ [PDF](https://arxiv.org/pdf/2507.02665), [HTML](https://arxiv.org/abs/2507.02665)
### Authors
Timo Kehrer,Robert Haines,Guido Juckeland,Shurui Zhou,David E. Bernholdt
### Background
有 anecdotal 来自研究软件工程师（RSEs）和软件工程研究人员（SERs）经常使用相似概念的不同术语，这导致了沟通上的挑战。已有研究开始探索 SER 社区中的软件工程基础理论在 RSE 社区中的解释，以识别一致的概念、知识空白和可能的适应区域。初步研究结果展示出了互相学习和协作的机会，并提出了一种系统的方法来映射术语，为未来的众包扩展和验证提供了基础数据。
### Innovation
研究采用了一种系统的方法来映射术语，旨在识别研究软件工程师和软件工程研究人员之间的不同术语及其一致性。这种方法为未来进行群众外包的扩展和验证提供了基础。
### Conclusion
初步研究表明，研究软件工程师和软件工程研究人员可以在互相学习的基础上进行协作，并提出了该领域的系统术语映射方法，为未来研究提供了一种新的研究方向。
## 706. `cs.SE` - 可持续性标志：识别问答平台上的可持续性帖子 [PDF](https://arxiv.org/pdf/2507.02695), [HTML](https://arxiv.org/abs/2507.02695)
### Authors
Sahar Ahmadisakha,Lech Bialek,Mohamed Soliman,Vasilios Andrikopoulos
### Background
近年来，软件系统的可持续性获得了重要关注，特别是随着云计算的兴起以及架构向云基架构的转变。这种转变加强了在架构讨论中识别可持续性以做出知情决策的必要性。当前，实践者在在线问答论坛上的讨论是了解这些决策的途径之一，但识别软件实践者讨论中的可持续性概念仍具有挑战性，因为缺乏清晰明确的指南。
### Innovation
为应对这一问题，本文引入了可持续性标志的概念，通过主题分析结合多个云提供商的最佳实践开发而成。这项研究进一步评估了这些标志在识别云架构帖子中的有效性，通过一项控制实验进行。初步结果显示，使用标志可以降低分类为可持续性相关的帖子数量，同时具有更高的确定性和显著改善的表现。此外，可持续性标志被认为比单纯依赖定义更有用且更容易理解，从而提升了识别可持续性的能力。
### Conclusion
综上所述，提出的可持续性标志有助于更准确地识别软件架构讨论中的可持续性主题，并且在实际应用和理解上都有显著优势。
## 707. `cs.SE` - VeFIA: 一种高效的垂直联邦协作软件推理审核框架 [PDF](https://arxiv.org/pdf/2507.02376), [HTML](https://arxiv.org/abs/2507.02376)
### Authors
Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang
### Background
垂直联邦学习（VFL）是一种分布式人工智能软件部署机制，允许跨孤岛协作而不访问参与者的数据。然而，现有的VFL工作中缺乏审计数据方推理软件执行正确性的机制。VeFIA框架旨在解决此问题，通过使用可信执行环境（TEE）和协调器验证数据方计算结果的正确性，帮助任务方在大规模推理过程中审计数据方的推理软件执行情况，而不泄露数据方的数据隐私或引入推理系统延迟。
### Innovation
VeFIA的核心在于任务方可以利用带有TEE的框架和协调器来验证数据方计算结果的正确性，保证只要异常推理超过5.4%，任务方就能以99.99%的概率检测到推理软件的执行异常，且不引入额外的在线推理延迟。VeFIA的随机取样验证在检测异常推理方面实现了100%的阳性预测值、阴性预测值和真阳性率。这被认为是第一篇讨论垂直联邦学习中推理软件执行正确性的论文。
### Conclusion
VeFIA确保了即使异常推理超过5.4%，任务方也能以99.99%的概率检测到执行异常，且不增加在线推理的延迟，同时还实现了100%的检测异常的阳性预测值、阴性预测值和真阳性率。
## 708. `cs.SE` - 适应性 cyber-物理系统中的人机协作与伦理考量 [PDF](https://arxiv.org/pdf/2507.02578), [HTML](https://arxiv.org/abs/2507.02578)
### Authors
Zoe Pfister
### Background
适配性 cyber-物理系统(CPS)结合了物理和计算能力，并能够根据参数变化进行调整。这些系统越来越多地包含人机协作，使人可以从双方的优势中受益。人机团队(HMT)是人机协作的最先进形式，设想了人类和机器之间的无缝合作。然而，在适应性CPS中实现有效的和无缝的人机团队面临挑战。尽管适应性CPS已经从如MAPE-K的反馈循环中受益，但由于人类和机器的操作节奏不同，仍然缺乏将人类整合进这些反馈循环的方法。此外，人机团队需要持续监控人类操作员，收集他们可能敏感的行为和动作信息，这要求尊重CPS中参与者的隐私和人类价值，这对于人机团队的成功至关重要。
### Innovation
本研究通过开发将HMT整合进适应性CPS的新方法和流程，特别是集中于人机交互原则并将其纳入适应性的CPS反馈循环，解决了上述挑战。此外，研究还创建了在整个系统生命周期中整合、验证和验证伦理及人类价值观的框架，从需求工程阶段开始。
### Conclusion
研究通过开发针对适应性CPS的人机交互新方法和流程，在结合伦理和人类价值方面提出了创新性的框架，为实现真正无缝的人机协作提供了可能性。
## 709. `cs.SE` - 内部软件指标能否预测应用在发布时的人气？是的！也可能是不的！ [PDF](https://arxiv.org/pdf/2507.02110), [HTML](https://arxiv.org/abs/2507.02110)
### Authors
Md Nahidul Islam Opu,Fatima Islam Mouri,Rick Kazman,Yuanfang Cai,Shaiful Chowdhury
### Background
在竞争激烈的移动应用市场，预测应用的受欢迎程度可以在其发布前为开发者带来战略优势，但这是一个挑战性的问题。此项研究探讨了内部软件度量指标是否可以在应用部署前就测度出应用的受欢迎程度，该度量基于用户评分（从用户评论计算得出）和每年下载次数。研究使用446个开源Android应用的数据集，提取了系统级别、类级别和方法级别的代码度量指标、代码味（代码问题），以及应用元数据。此外，还收集了Google Play Store中的用户评论、下载数量和应用权限使用情况等信息。通过最小的大小基线、由领域知识选择的特征集、以及通过特征选择算法衍生的投票集这三组特征，对回归和分类模型进行了评估。结果表明，回归模型由于数据分布偏差表现不佳，而重新构建成二元分类问题（受欢迎 vs. 不受欢迎）后，结果显著改善，使用投票集的多层感知机模型获得了F1分数为0.72的最佳结果。这一结果表明，尽管内部代码度量在解释能力有限，但它们仍可以作为应用受欢迎程度的有用指标。这一发现挑战了早期认为内部度量不能预测软件质量的观点。
### Innovation
研究将内部软件度量指标重新构建成二元分类问题，从而显著提高了预测准确度。此外，研究通过三种不同特征集进行模型评估，发现了最佳的多层感知机模型。这些结果表明，内部代码度量虽然在解释能力有限，但仍然是评估应用受欢迎程度的重要指标。
### Conclusion
研究发现内部代码度量无法独立作为预测应用受欢迎程度的充分信息源，但它们确实具有一定的预测价值。通过重新定义分类问题和优化特征选择，可以显著提升模型的预测能力。这些结果为移动应用开发提供了新的洞察，即内部代码度量可以作为评估应用受欢迎程度的有用指标，但由于其局限性仍需谨慎解读。
## 710. `cs.SE` - 探索大型语言模型在工业测试维护过程中的整合 [PDF](https://arxiv.org/pdf/2409.06416), [HTML](https://arxiv.org/abs/2409.06416)
### Authors
Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg
### Background
在软件测试过程中，很大一部分成本和努力都投入到测试维护中，即增加、删除或修改测试用例以使测试套件与被测系统保持同步或提高其质量。工具支持可以通过自动化测试维护过程的某些方面或提供开发者指导和支持来降低成本并提高测试维护质量。本文的研究旨在探索用于测试维护的大语言模型（LLMs）的能力和应用，尤其是在工业环境中的应用。
### Innovation
本文研究发现，大语言模型（LLMs）可用于预测代码更改后需要维护的测试，从而为工业环境中的测试维护提供支持。同时，研究提出并演示了一种基于多代理的架构，能够预测哪些测试需要维护，这有助于提高测试维护的效果和效率。这些发现推进了我们对如何利用大语言模型提高工业测试维护过程的理解。
### Conclusion
本文通过在爱立信AB公司的案例研究，探索了大语言模型在工业测试维护过程中的应用，并提出了一个多代理架构预测代码更改后需要维护的测试，从而为工业环境下的测试维护提供理论和实践上的支持。
## 711. `cs.SE` - LLMREI: 使用大型语言模型自动化需求获取访谈 [PDF](https://arxiv.org/pdf/2507.02564), [HTML](https://arxiv.org/abs/2507.02564)
### Authors
Alexander Korn,Samuel Gorsch,Andreas Vogelsang
### Background
需求获取访谈对于收集系统需求至关重要，但这一过程依赖于熟练的分析师，使得它成为资源密集型的、易受人为偏见影响的过程，还容易产生沟通误解。近年来，大型语言模型的进步为自动化这一过程的某些部分提供了新的机会。本研究介绍了一款名为LLMREI的聊天机器人，旨在通过最小的人工干预来执行需求获取访谈，从而减少常见的访谈者错误，并提高需求获取过程的可扩展性。我们探索了两种主要方法，即零样本提示和从简单到复杂的提示，以优化LLMREI的需求获取能力。我们在33场模拟的干系人访谈中评估了LLMREI的表现，发现零样本次提示和从简单到复杂的提示方法表现最佳。这三种方法中的调整训练方法由于初步试验表现不佳而被舍弃。我们的研究评估了聊天机器人在三个方面的作用效果：减少常见采访错误、提取相关需求以及根据采访场景和用户回应生成上下文相关的问题。我们发现，LLMREI在错误数量上与人工访谈者相当，能够提取大量需求，并且展示出生成高度上下文相关问题的能力。我们设想，LLMREI在自动化与大量干系人访谈方面将获得最大的益处。
### Innovation
引入了一种名为LLMREI的聊天机器人，用于通过最小的人工干预执行需求获取访谈，以减少常见的访谈者错误并提高需求获取过程的可扩展性。探索了零样本提示和从简单到复杂的提示两种主要方法以优化LLMREI的需求获取能力。选择了零样本提示和从简单到复杂的提示方法进行评估，而不考虑调整训练方法。评估结果显示，LLMREI能够生成与人工访谈者类似的低错误率，有效提取大量需求，并且能够生成高度上下文相关的问题。
### Conclusion
LLMREI能够在最小人工干预的情况下有效执行需求获取访谈，减少常见错误，有效提取需求，并能生成上下文相关的问题。在与大量干系人进行的访谈中，采用LLMREI有望获得最佳效益。
## 712. `cs.SE` - 法律要求从法律文本到语言的翻译 [PDF](https://arxiv.org/pdf/2507.02846), [HTML](https://arxiv.org/abs/2507.02846)
### Authors
Anmol Singhal,Travis Breaux
### Background
软件系统必须遵守法律规范，尤其是小型组织和初创企业由于缺乏专门的法律专业知识，这项任务特别费资源。提取法律文本中的元数据以提取软件所需的法律要求是确保合规的关键步骤，但这一过程由于法律法规长度和复杂性成为一项繁琐的任务。尽管先前的研究已经探索了自动方法来提取法律文本中的结构和语义元数据，但仍然存在一些关键限制：这些方法没有考虑到这些元数据类型相关属性之间的相互作用，且依赖手动标记或基于启发式的机器学习，这在处理新文件时表现并不好。因此，本文探讨了一种基于文本蕴含和上下文学习的方法，用于自动生成一种编码并可执行为Python代码的法律文本标准表示。这种表示是从手动设计的Python类结构实例化而来，作为专门领域的元模型，捕获了结构和语义法律元数据及其相互关系。
### Innovation
本文提出了基于文本蕴含和上下文学习的方法，用以自动生成法律文本的编码和可执行Python代码表示。这种方法避免了需要大量手动标注的数据集，并增强了对未知立法的适用性。手动设计的Python类结构作为领域特定的元模型，捕获了结构和语义法律元数据及其相互关系，从而减少了对大规模标记数据的依赖，并增强了对未知法律条文的适用性。
### Conclusion
本文的方法在13个美国州的数据泄露通知法律上进行了评估，结果表明，生成的表示法通过了约89.4%的测试案例，并获得精度82.2%和召回率88.7%的结果。
## 713. `cs.SE` - 代码数字双胞胎：赋予大型语言模型复杂软件维护中的隐性知识 [PDF](https://arxiv.org/pdf/2503.07967), [HTML](https://arxiv.org/abs/2503.07967)
### Authors
Xin Peng,Chong Wang,Mingwei Liu,Yiling Lou,Yijian Wu
### Background
虽然大型语言模型（LLMs）已经在软件工程任务如代码补全和生成中展示了潜力，但在支持复杂软件系统的维护方面仍然有限。这些模型通常难以理解嵌在系统中的隐性知识，例如职责分配和不同模块之间的协作。为解决这一问题，我们提出了代码数字双胞胎的概念和框架，这是一种概念性表示方法，能够捕捉代码元素背后的概念、功能和设计理由，并与软件共同进化。代码数字双胞胎利用结构化和非结构化数据（如源代码、文档和变更日志）结合知识抽取，利用大型语言模型、静态分析工具和人类专业知识构建而成。这种框架能够通过提供隐性知识作为上下文，赋能大型语言模型进行诸如问题定位和仓库级别的代码生成等软件维护任务。
### Innovation
我们提出了代码数字双胞胎的概念和框架，该框架能捕捉和提供代码背后的概念、功能和设计理由等隐性知识，并与软件共同进化。通过结合结构化和非结构化的数据源，利用大型语言模型、静态分析工具和人类专业知识，构建出的代码数字双胞胎能够填补LLMs在软件维护中的支持不足，尤其是对于复杂软件系统的维护。这种框架可以通过提供隐性知识作为上下文，赋能大型语言模型进行问题定位和仓库级别的代码生成等软件维护任务，从而解决LLMs理解隐性知识的难题。
### Conclusion
基于提出的方法论，我们探讨了代码数字双胞胎在连续构建和优化中的关键挑战和机遇。
## 714. `cs.SE` - 基于模糊测试的C/C++软件在智能物理系统中的突变测试 [PDF](https://arxiv.org/pdf/2503.24100), [HTML](https://arxiv.org/abs/2503.24100)
### Authors
Jaekwon Lee,Fabrizio Pastore,Lionel Briand
### Background
突变测试能够帮助最小化交付有故障的软件。因此，对于需要软件可靠性高的安全关键型智能物理系统（CPS），推荐使用突变测试。当前的C和C++语言的突变测试技术大多依赖于符号执行，但符号执行的局限性限制了其应用场景（例如，包含黑盒组件的系统）。本文旨在通过采用模糊测试来解决这一问题，证明其在C和C++软件测试的有效性，并指出该方法在实际卫星系统软件组件的测试中可检测到40%到90%未被开发者测试套件发现的突变，识别突变效果显著优于符号执行，尤其在检测存活突变方面，与后者的差距可达到50个百分点。此外，研究还通过使用特定工具组进一步提高了检测效果，虽然混合使用模糊测试和符号执行能够捕获更多突变，但其带来的收益有限。
### Innovation
本研究提出了依赖模糊测试的突变测试方法，这是针对C和C++软件在CPS应用的一种创新。它解决了传统符号执行方法的局限性，并且能大大提高突变检测的效果，尤其是检测存活突变方面，效果显著优于仅使用符号执行。通过使用特定的工具组，本书的研究进一步提升了突变检测的效果。
### Conclusion
实验结果显示，该基于模糊测试的方法在检测未被开发者测试套件发现的突变方面更加有效，尤其在实际卫星系统的软件组件检测中，能提高40%到90%的突变命中率。进一步的实验还表明，该方法结合特定工具组使用可以大幅提升检测结果，但与符号执行结合带来的额外收益微乎其微。
## 715. `cs.SE` - 需求获取后续问题生成 [PDF](https://arxiv.org/pdf/2507.02858), [HTML](https://arxiv.org/abs/2507.02858)
### Authors
Yuchen Shen,Anmol Singhal,Travis Breaux
### Background
访谈是广泛用于提取软件系统需求的技术，用于收集相关方的需求、偏好和期望。有效的访谈需要熟练的访谈者能够实时制定合适的问题，但在面对诸如领域不熟悉、认知负荷过大、信息过载等问题时具有挑战性。近期，大语言模型（LLM）在文本总结和蕴含等自然语言处理任务中表现出领先的技术水平。为了支持访谈者，研究借鉴常见访谈错误类型构建框架，探讨如何利用GPT-4o生成需求获取过程中后续问题，并描述基于受访人言语生成问题的方法。
### Innovation
该研究借助大语言模型（LLM），特别是GPT-4o，来生成需求获取过程中的后续问题。虽然使用LLM生成的问题在清晰度、相关性和信息丰富性方面不逊于人工撰写的问题，但在利用常见错误类型的指导下，LLM生成的问题表现出更优的效果，强调了使用LLM帮助访谈者提升需求获取质量与便捷性的潜力.
### Conclusion
通过受控实验评估LLM生成和人工撰写的问题，研究发现，在这两种实验中，LLM生成的问题在清晰度、相关性和信息丰富性方面与人工设计的问题效果相当。并且，在利用常见错误类型的指导下，LLM生成的问题表现出更佳的效果，这表明使用大语言模型帮助访谈者实时提升需求获取的质量与便利性具有显著潜力。
## 716. `cs.SE` - RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes [PDF](https://arxiv.org/pdf/2507.02690), [HTML](https://arxiv.org/abs/2507.02690)
### Authors
Jiaxing Wang,Yifeng Yu,Jiahan Song,Bin Cao,Jing Fan,Ji Zhang
### Background
在服务导向的体系结构（如微服务环境、分布式企业系统和云原生平台）中，优化业务流程的下一步活动预测是一项基础挑战。这使资源分配和动态服务组合能够更加积极和灵活。尽管基于序列的方法非常流行，但它们无法捕捉并行执行和条件依赖产生的非序列关系。基于图的方法虽然可以解决结构上的保留问题，但在进行了均匀建模策略的同时，又无法根据单一过程的复杂性特征进行独立建模，导致了同质化的表示和静态结构的问题。因此，现有方法在这方面存在明显不足。
### Innovation
本文提出了RLHGNN，一种新颖的框架，通过将事件日志转换为基于现有过程挖掘理论的异质过程图，并通过强化学习建立马尔可夫决策过程来自动确定最优的异质图结构，从而满足不同过程复杂度的需求。此框架通过特定关系聚合策略下的异质图卷积，有效地预测了下一个活动。这种自适应方法能够精确建模服务交互中的顺序和非顺序关系。实验证实在六个真实的数据集上，RLHGNN持续优于最先进的方法，并且具有大约1毫秒/预测的时间推断延迟，非常适合实时业务流程监控应用。
### Conclusion
RVHGNN框架在六个实际数据集上的综合评估证明了其优越的性能，不仅在预测准确性上超越了现有方法，还能以极低的推理延迟应用于实时场景，为业务流程的优化和动态服务组合提供了一个高效可行的解决方案。源代码可在此链接访问。
## 717. `cs.SE` - 缓解攻击数据稀缺性：SCANIA提升车内网络安全措施的经验 [PDF](https://arxiv.org/pdf/2507.02607), [HTML](https://arxiv.org/abs/2507.02607)
### Authors
Frida Sundfeldt,Bianca Widstam,Mahshid Helali Moghadam,Kuo-Yun Liang,Anders Vesterberg
### Background
随着联网车辆的数字化发展，随之而来的安全风险愈发严峻，突显了实施车内网络安全措施的迫切需求，例如入侵检测与响应系统。连续不断的新型攻击场景加剧了对适应性检测机制的需要，这些机制能够检测出不断演变的未知和复杂的威胁。尽管机器学习驱动的方法能够帮助应对这一挑战，但由于安全、成本和伦理方面的限制，对测试车辆实施多样化的攻击场景存在诸多障碍，导致缺乏代表攻击场景的数据。因此，需要开发高效且有效的替代方法来生成高质量的攻击代表数据。
### Innovation
本文介绍了一种基于上下文的攻击数据生成器，该生成器能够生成各类攻击输入及相应的车内网络日志（例如，控制器局域网CAN日志），这些代表不同类型的攻击，包括拒绝服务（DoS）、模糊、欺骗、悬空和重放攻击。该生成器利用参数化的攻击模型，配合CAN消息解码和攻击强度调节，配置高度符合真实世界场景且具备多样性的攻击场景。通过对生成数据在入侵检测系统（IDS）研究中的实践评估，验证了该方法在效率、可扩展性和IDS模型性能结果方面的有效性，以及生成数据的可靠性和有效性。
### Conclusion
通过实施上下文感知的攻击数据生成器，该研究证明了其在缓解攻击数据稀缺性方面的有效性，并为企业和研究机构提供了一种高效的生成真实场景攻击数据的方法。通过该体验研究，还详细探讨了影响数据真实度的因素，并提供了其应用方面的见解。
## 718. `cs.SE` - 代理业务流程管理：业务流程中代理治理的从业者视角 [PDF](https://arxiv.org/pdf/2504.03693), [HTML](https://arxiv.org/abs/2504.03693)
### Authors
Hoang Vu,Nataliia Klievtsova,Henrik Leopold,Stefanie Rinderle-Ma,Timotheus Kampik
### Background
随着生成型AI的兴起，行业对软件代理的兴趣正在增长。然而，由于基于生成型AI的代理具有随机性，其在组织中的有效和安全部署需要强大的治理，这可以通过代理业务流程管理来实现。但由于这一新一代代理概念仍处于初期阶段，从业者对于代理的定义、代理部署的利益、风险和治理挑战尚未清晰认识。本研究通过与来自不同行业的22名业务流程管理（BPM）从业者进行半结构化访谈，调查组织如何有效治理AI代理。从业者认为代理能够提高效率、改善数据质量、确保更好的合规性以及通过自动化实现可扩展性，但也警告了偏见、过度依赖、网络安全威胁、就业置换以及决策不透明等风险。研究提出了六项关键建议：明确业务目标、设置法律和伦理护栏、建立人与代理的合作、定制代理行为、管理风险以及确保安全集成并提供备用选项。此外，本文还概述了将传统BPM与代理型AI对齐的行动，包括平衡人与代理角色、重新定义人类参与、调整流程结构以及引入绩效指标。这些见解为将AI代理融入业务流程提供了实用的基础，同时保持了监督、灵活性和信任。
### Innovation
本研究通过半结构化访谈的方式，收集了来自不同行业的BPM从业者对于代理治理的看法和实践经验。研究提出了一种‘代理业务流程管理’的概念，并为实现业务流程中的负责任代理应用提供了六项建议。此外，研究还探讨了将传统BPM与代理型AI对齐的具体措施，包括角色平衡、绩效指标引入等。
### Conclusion
研究结果表明，代理业务流程管理可以作为一种实用的方法，帮助组织管理和优化AI代理的部署，确保高效、安全和合规的操作。通过明确业务目标、建立法律和伦理护栏、定制代理行为、管理风险等措施，可以实现安全和负责任的代理应用。
## 719. `cs.SE` - 基于多跳自然语言推断的保证案例结构可解释合规检测 [PDF](https://arxiv.org/pdf/2506.08713), [HTML](https://arxiv.org/abs/2506.08713)
### Authors
Fariz Ikhwantri,Dusica Marijan
### Background
确保复杂系统遵守法规通常需要通过主张-论据-证据框架来验证保证案例的有效性。这一过程中存在的挑战包括法律和技术文本的复杂性质、对模型解释的需求以及保证案例数据的有限访问。
### Innovation
提出了一种基于自然语言推理（NLI）的合规检测方法：EXplainable CompLiance detection with Argumentative Inference of Multi-hop reasoning (EXCLAIM)。该方法将保证案例的主张-论据-证据结构表示为多跳推理以实现可解释和可追溯的合规检测，并利用大型语言模型生成保证案例，提出度量标准来衡量覆盖范围和结构一致性。通过从GDPR要求生成并应用于多跳推理任务，展示了EXCLAIM方法的有效性。
### Conclusion
结果表明基于NLI的方法在自动化合规过程方面具有潜力。
## 720. `cs.SE` - DSCodeBench: 实证性的数据科学代码生成基准 [PDF](https://arxiv.org/pdf/2505.15621), [HTML](https://arxiv.org/abs/2505.15621)
### Authors
Shuyin Ouyang,Dong Huang,Jingwen Guo,Zeyu Sun,Qihao Zhu,Jie M. Zhang
### Background
当前存在一个名为DS-1000的基准测试，用于评估大型语言模型（LLMs）在复杂的真实数据科学代码生成任务上的表现。然而，DS-1000在挑战性和代表性方面存在不足，代码长度较短，涵盖的数据科学库较少，且问题描述不够清晰和结构化。为了应对此问题，研究人员开发了DSCodeBench，一个包含1000个精心构建的问题的数据科学代码生成基准测试，这些问题来自于GitHub上广泛使用的Python数据科学库中的实际问题。
### Innovation
DSCodeBench通过集成任务范围选择、代码构建、测试案例生成和问题描述合成等步骤，创建了一个更严格的管道。过程中结合了严格的手动编辑，以确保其与目标一致并提高评估的可靠性。DSCodeBench提供了一个更具挑战性和代表性的测试环境，具有更长的代码解决方案和更加全面的数据科学库，同时问题描述更清晰结构更佳。实验结果显示，DSCodeBench在大模型与小模型的表现上表现出稳健的扩展性，这验证了其能力分辨模型能力的潜力。此外，它还揭示了对现实数据科学代码生成任务，LLMs仍有很大的改进空间，尤其是最优秀的LLM—GPT-4o，其pass@1仅为0.202。
### Conclusion
DSCodeBench将作为一个严格的和可靠的基础，推动基于LLM的数据科学编程的发展。
## 721. `cs.SE` - 基于梯度的模型指纹识别用于LLM相似性检测和家族分类 [PDF](https://arxiv.org/pdf/2506.01631), [HTML](https://arxiv.org/abs/2506.01631)
### Authors
Zehao Wu,Yanjie Zhao,Haoyu Wang
### Background
随着大型语言模型（LLMs）成为现代应用中的重要软件组件，通过微调、合并和重新分配生成的未经授权模型衍生现象已经成为关键的软件工程挑战。在传统的软件领域，克隆检测和许可证合规性已经有成熟的机制，但在LLM生态系统中缺乏有效的方法来追踪模型的来源和执行许可协议。当基于开源模型创造者，比如Meta的LLaMA，需要衍生作品保持命名约定以保证归属性，但并没有技术手段验证合规性。
### Innovation
我们通过将LLMs视为需要追溯历史的软件制品，并提出了一个基于梯度的指纹识别框架TensorGuard，用于LLM的相似性检测和家族分类。该方法通过分析随机输入干扰在张量层上对梯度反应来提取模型固有的行为特征，这是独立于训练数据、水印或特定模型格式的。TensorGuard支持广泛采用的safetensors格式，并通过统计分析梯度特征构建高维指纹。这些指纹能够通过距离计算直接进行任意模型之间相似性的评估，并通过带领域知识初始化中心的K-Means聚类算法对未知模型进行系统家族分类。实验表明，在包含8个基础模型和50个衍生模型的5个模型家族（Llama、Qwen、Gemma、Phi、Mistral）下，我们的K-Means聚类分类准确率达94%。
### Conclusion
我们的研究通过TensorGuard框架，成功填补了LLM生态中的空白，提供了有效的模型追溯和家族分类机制，增强了模型的归属性和许可合规性管理。
## 722. `cs.LG` - 在临床多组学研究中通过HP-ACCORD学习大规模部分相关网络 [PDF](https://arxiv.org/pdf/2412.11554), [HTML](https://arxiv.org/abs/2412.11554)
### Authors
Sungdong Lee,Joshua Bang,Youngrae Kim,Hyungwon Choi,Sang-Yun Oh,Joong-Ho Won
### Background
从多组学数据中估计图模型需要在统计估计性能和计算可扩展性之间取得平衡。该研究引入了一种基于伪似然的图模型框架，通过重新参数化目标精度矩阵同时保留稀疏模式，并通过基于新损失函数的$bm{l}_1$正则化的经验风险最小化对其进行估计。在这个估计器中，估计和选择的一致性在多种度量下在高维假设下得到了维持。相关优化问题可以通过一种新的操作符分裂方法和通信避免的分布式矩阵乘法得到具有可证明的快速计算算法的解决。通过高性能计算实现框架，使用多达一百万个变量的模拟数据进行测试，展示了类似于生物网络的复杂依赖结构，从而证明了计算可扩展性在多组学数据分析中的价值。利用这种可扩展性，从双组学肝癌数据集中估计了一个部分相关网络。从超高维度数据中估计的共表达网络在优先选择关键转录因子和共激活因子方面表现出更高的特异性，从而突出了计算可扩展性在多组学数据分析中的重要性。
### Innovation
该研究引入了一种新的基于伪似然的图模型框架，通过重新参数化目标精度矩阵，保留稀疏模式，利用一种新的损失函数和$bm{l}_1$正则化的经验风险最小化估计目标。该方法提供了一种具有可证明的快速计算算法的优化解决方案，通过通信避免的分布式矩阵乘法提高效率。通过高性能计算实现，该框架能够处理高达上百万变量的数据集，并在双组学肝癌数据集中验证了其有效性。
### Conclusion
该研究开发了一种新的基于伪似然的图模型估计方法，通过重新参数化目标精度矩阵同时保留稀疏模式，利用高性能计算框架能够处理大规模数据集，并在肝癌数据集上展示了其在多组学数据分析中的优越性。
