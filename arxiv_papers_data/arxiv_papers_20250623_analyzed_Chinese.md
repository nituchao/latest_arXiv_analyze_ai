# 1. `cs.AI` - CALM: Contextual Analog Logic with Multimodality [PDF](https://arxiv.org/pdf/2506.14936), [HTML](https://arxiv.org/abs/2506.14936)
## Authors
Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue
## Background
经典二值逻辑系统无法捕捉人类决策的细微差异。同时，这些系统需要人工在多模态环境中进行接地，这往往是临时的、僵化的和脆弱的。神经网络擅长从多模态数据中提取丰富的上下文信息，但缺乏用于推理的可解释结构。因此，传统的AI系统要么脆弱，要么结构不明确，难以在实际任务中泛化。CALM旨在弥合逻辑和神经感知之间的差距，创建一种模拟逻辑，用于处理多模态输入。
## Innovation
引入了Contextual Analog Logic with Multimodality (CALM)，通过结合符号推理和神经生成，让系统能够基于真实世界的多模态数据做出上下文相关的决策。每个谓词用领域树表示，并根据实体的上下文关系迭代调整其模拟真值。这些迭代调整由能够捕捉多模态信息的神经网络预测，并通过符号推理模块进行筛选，以确保约束满足。CALM在填补空白的物体定位任务中表现优异，准确率达到92.2%，超过了经典逻辑（86.3%）和大语言模型（59.4%）的基线。同时，它生成的空间热图与逻辑约束和微妙的人类偏好一致，如人类研究所示。
## Conclusion
CALM展示了在多模态环境中进行逻辑推理并符合偏好的潜力，为下一代需要逻辑精确性和解释性的AI系统奠定了基础，同时结合了神经网络对多模态信息处理的能力。
# 2. `cs.AI` - MEAL: 基于连续多agent强化学习的基准 [PDF](https://arxiv.org/pdf/2506.14990), [HTML](https://arxiv.org/abs/2506.14990)
## Authors
Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy
## Background
强化学习（RL）算法的研发需要基准，并且环境的提供对研究影响很大。目前，较少探索多agent连续学习（CL）这一领域，特别是合作多agent环境下的连续学习。现有的CL基准大多运行在CPU上，导致计算瓶颈，限制了任务序列的长度。而在标准台式PC上使用GPU加速运行100个任务序列需要时间较长，难以满足连续多agent强化学习（CMARL）的研究需求。
## Innovation
MEAL是首个为CMARL设计的基准，采用了JAX进行GPU加速，允许在几个小时内完成100个任务序列的学习。通过将流行的CL和MARL方法简单结合，显示出在简单环境中取得了良好的性能，但在面对更加复杂需要长期协调和适应的任务时表现不佳。通过消融研究发现，特定的体系结构和算法特征是CMARL在MEAL上的关键因素。
## Conclusion
MEAL作为首个CMARL基准，为多agent环境下的连续学习提供了更为高效的计算平台与研究框架。通过CNN对比，表明简单方法在简单环境中有效但在复杂任务中不适用，进一步定向研究可以重点关注适当选择结构和算法的因素。
# 3. `cs.AI` - 剪裁的近似策略优化 [PDF](https://arxiv.org/pdf/2506.15050), [HTML](https://arxiv.org/abs/2506.15050)
## Authors
Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu
## Background
近期，通过生成长推理链（CoT）来展示出色科学和专业任务推理能力的测试时缩放大型语言模型（LLMs）引起了广泛关注。这促进了这些推理模型的开发。然而，强化学习（RL）中的传统方法，如渐进策略优化（PPO）及其变体，由于其固有的序列依赖性以及响应长度增加导致的试错过程变长，变得耗时。因此，设备利用率低下是一个由此引发的重要问题。
## Innovation
本文提出了一种名为剪裁的近似策略优化（T-PPO）的新方法。T-PPO在保留策略学习完整性的同时，通过简化策略更新和长度限制的响应生成来提高训练效率。具体创新点包括：1) 引入了来自不完整响应的优势估计（EGAE），以改进优势估计；2) 设计了一种计算优化机制，允许策略和价值模型独立优化，通过选择性地过滤提示和裁剪标记来减少冗余计算。这些手段共同提升了训练效率。
## Conclusion
T-PPO在AIME 2024上使用32B基模型的实验结果表明，其能够将推理LLMs的训练效率提高2.5倍，并且在性能上优于现有竞争对手。
# 4. `cs.AI` - HeurAgenix：利用大型语言模型解决复杂组合优化挑战 [PDF](https://arxiv.org/pdf/2506.15196), [HTML](https://arxiv.org/abs/2506.15196)
## Authors
Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian
## Background
启发式算法在解决组合优化（CO）问题中起着至关重要的作用，但传统设计高度依赖手动专业知识，并且难以在不同实例中进行泛化。针对这一挑战，该研究提出了一种名为HeurAgenix的两级超启发式框架，该框架利用大语言模型（LLMs）不仅进化启发式算法，还在问题解决阶段自动选择最合适的启发式算法。该框架在启发式进化阶段利用LLM来比较种子启发式解决方案，并提炼出可重用的进化策略；在问题求解阶段，通过LLM的感知能力动态地选择最有可能解决问题状态的启发式算法。此外，该帧构还通过双奖励机制对轻量级启发式选择器进行微调，以克服组合优化问题复杂性带来的可靠监督稀缺问题，从而在嘈杂的注解下实现稳健的选择。
## Innovation
该论文提出的HeurAgenix框架利用大语言模型（LLMs）实现启发式算法的进化和自动选择，不仅提高了组合优化问题的求解能力，还增强了框架的灵活性和适应性。通过双奖励机制对轻量级启发式选择器进行微调，以克服组合优化问题复杂性带来的可靠监督稀缺问题，从而实现稳健的选择。实验结果表明，HeurAgenix在多种经典基准测试中不仅优于现有的基于语言模型的超启发式算法，还能够匹敌或超越专门的求解器。
## Conclusion
该研究通过引入HeurAgenix框架，显著提高了组合优化问题的求解质量和灵活性。实验结果表明，该框架在多个经典问题上表现出色，不仅优于现有的基于语言模型的启发式算法，而且还能够与专门的求解器相媲美。未来的研究可以通过进一步优化和扩展HeurAgenix的应用范围，以提高其在更多复杂问题上的性能。
# 5. `cs.AI` - 多智能体强化学习在自主多卫星地球观测中的应用：一个现实案例研究 [PDF](https://arxiv.org/pdf/2506.15207), [HTML](https://arxiv.org/abs/2506.15207)
## Authors
Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk
## Background
低地球轨道（LEO）卫星数量的指数级增长已经革新了地球观测（EO）任务，在气候变化监测、灾害管理等方面带来了新机遇，但多卫星系统中的自主协调依然是一个基础性挑战。传统的优化方法难以应对动态EO任务的实时决策需求，因此需要采用强化学习（RL）和多智能体强化学习（MARL）方法。本文通过模拟单卫星运行，扩展到多卫星星座，并利用MARL框架研究了基于RL的多卫星自主EO任务规划。研究重点关注能量和数据存储限制、卫星观测不确定性以及在部分可观测条件下的去中心化协调复杂性等关键问题。
## Innovation
通过模拟环境评估最先进的MARL算法（包括PPO、IPPO、MAPPO、HAPPO），研究展示了MARL在多卫星协调中的应用潜力，可有效平衡成像和资源管理，并解决非平稳性和奖励相互依赖性问题。这项研究为自主卫星操作提供了宝贵的见解，为分散式EO任务中提高策略学习提供了具体指导。
## Conclusion
研究的结果表明，MARL能有效解决多卫星协调中的成像和资源管理问题，适应非平稳性和奖励相互依赖性，并提供了一套用于增强政策学习的基础框架，推动了自主卫星操作的发展。
# 6. `cs.AI` - 海洋无人飞行器和船舶协作下具有不确定性的边缘计算联合计算卸载与资源分配 [PDF](https://arxiv.org/pdf/2506.15225), [HTML](https://arxiv.org/abs/2506.15225)
## Authors
Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han
## Background
近年来，海洋物联网（MIoT）的计算需求快速增加，无人飞行器（UAV）和船舶基于多接入边缘计算（MEC）可以满足这些MIoT需求。然而，不确定性的海洋任务带来计算卸载和资源分配效率低下等挑战。
## Innovation
提出了一种海洋协作边缘计算框架，结合MIoT设备、UAV和船舶进行计算卸载和资源分配。利用系数优化处理不可预测的任务到达和计算资源变化。通过将长期约束转换为短期约束，获得一系列小规模优化问题。针对UAV和船舶资源的异构性，将小规模优化问题重新表述为马尔可夫博弈（MG），并提出了异构代理软演员-评论家来解决MG问题。
## Conclusion
通过仿真实验验证了提出的框架在处理计算卸载和资源分配方面的有效性。
# 7. `cs.AI` - 视觉导航中的高效且普适的环境理解 [PDF](https://arxiv.org/pdf/2506.15377), [HTML](https://arxiv.org/abs/2506.15377)
## Authors
Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao
## Background
视觉导航是嵌入式人工智能中的核心任务，使代理能够在复杂的环境中导航至指定目标。在导航任务中，许多场景需要对先前时间步骤累积的数据进行序列建模。尽管现有方法表现良好，但它们通常会一次性处理所有历史观测数据，忽视了数据内部关联结构，这可能限制了任务性能的进一步提升。现有方法的这种处理方式未能充分利用数据中的因果关系，因此存在改进的空间。
## Innovation
通过从因果关系的角度审视导航任务的特殊性，引入因果框架以揭示传统序列方法的局限性。在此基础上，提出了因果感知导航(CAN)方法，该方法引进因果理解模块以增强代理在环境中的理解能力。实证研究表明，该方法在各种任务和模拟环境中均优于基准方法。进一步的消融实验表明，因果理解模块在强化学习和监督学习设置中都表现出有效的泛化能力，且无额外的计算开销。
## Conclusion
我们的研究结果表明，通过因果视角的方法能在视觉导航任务中提高代理的环境理解能力和任务性能，且该方法适用于广泛的导航场景，显示了对该领域的实质性贡献。
# 8. `cs.AI` - 利用基于大规模语言模型的推理和行动代理管理复杂故障分析工作流 [PDF](https://arxiv.org/pdf/2506.15567), [HTML](https://arxiv.org/abs/2506.15567)
## Authors
Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer
## Background
故障分析（FA）是一个高度复杂且知识密集型的过程。将AI组件集成到FA实验室的计算基础设施中，可以自动执行多种任务，如图像中非合规性的检测、从各种数据源检索类似案例以及从注释图像生成报告。然而，随着部署的AI模型数量的增加，挑战在于将这些组件组织成协同且高效的流程，无缝地与FA过程集成。因此，如何有效管理和优化复杂的故障分析工作流成为亟待解决的问题。
## Innovation
本文研究了一种基于大规模语言模型（LLM）的规划代理（LPA）的设计与实现，以协助FA工程师解决分析案例。LPA结合了LLM和高级规划能力以及外部工具利用，能够自主处理复杂查询、从外部系统检索相关数据并生成易于阅读的响应。通过评估结果表明，该代理在支持故障分析任务方面具有良好的运作效果和可靠性。
## Conclusion
基于大规模语言模型的规划代理（LPA）能够有效地辅助故障分析工程师解决复杂分析案例，并通过集成LARGE语言模型、高级规划能力和外部工具利用技术，实现了复杂故障分析工作流中的高效和无缝操作。
# 9. `cs.AI` - 动态路由博弈中自然语言状态表示对LLM代理行为的影响 [PDF](https://arxiv.org/pdf/2506.15624), [HTML](https://arxiv.org/abs/2506.15624)
## Authors
Lyle Goodyear,Rachel Guo,Ramesh Johari
## Background
大语言模型（LLMs）在动态环境中的决策能力显示出潜力，但它们的状态无依赖性要求创建自然语言的历史表示。然而，以往在使用LLMs的博弈中，编码游戏历史采用非系统且随意的方法，这不仅模糊了状态表示对代理行为的影响，也限制了不同研究间的可比性。本文提出了一种框架，以系统地构建动态多代理博弈中LLM代理的自然语言状态表示。该框架通过行为信息、奖励信息和提示风格三个角度定义了状态表示的方法，从而解决上述问题。研究选择了动态自私路由博弈作为模型，因为它在理论与人类实验中都具有简单的基本准均衡，尽管相对简单，但仍发现自然语言状态表示对LLM行为有关键依赖性，具体表现为摘要而非完整历史、关于后悔而非原始收益的信息以及有限的他方行动信息促使行为更符合博弈论预测，并且游戏稳定性更强。
## Innovation
本文提出了一个统一框架，系统地构建动态多代理博弈中LLM代理的自然语言状态表示。该框架通过三个维度定义了各种状态表示方法，解决了以往工作的非系统性和不可比性问题，为理解状态表示对博弈中代理行为的具体影响提供了工具。特别地，研究揭示了不同状态表示形式对博弈结果的不同影响，如摘要历史、后悔信息和有限他方信息的作用，这些方法能促使代理行为更接近博弈论上的准均衡，并提高博弈的稳定性。
## Conclusion
研究发现，在动态自私路由博弈中，自然语言状态表示对LLM代理的行为有显著影响。特定的状态表示形式（如提供摘要而非完整的历史、关于后悔而非原始收益的信息以及有限的他方行动信息）可以使得代理的行为更符合博弈论的预测，并且游戏的稳定性更好。相比之下，其他表示方式可能导致代理行为严重偏离均衡，或游戏动态性变化更大。
# 10. `cs.AI` - AI政策模块：培养计算机科学学生在AI伦理与政策方面的竞争力 [PDF](https://arxiv.org/pdf/2506.15639), [HTML](https://arxiv.org/abs/2506.15639)
## Authors
James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry
## Background
随着人工智能（AI）越来越多地嵌入个人和专业环境中的各种场景，人们必须关注AI伦理、以及通过AI政策对AI技术进行治理和规范的需求。目前的大学计算机课程未能为未来的AI从业者提供足够的准备，使他们能够将抽象的伦理原则和规范性政策偏好融入AI系统的设计与开发中。我们相信，即使是技术侧重的AI工程师，也需要对‘AI政策景观’有所了解，并能够将伦理原则转化为实践。为此，我们开发了一个AI政策模块，旨在将AI政策讨论引入计算机科学课程。基于2024年秋季试点成功，我们在这篇创新实践的完整论文中呈现了更新和扩展后的模块，包括‘AI规范’的技术作业。我们通过事前和事后的模块调查评估了学生对AI伦理和政策的态度。结果发现，学生对AI技术的道德影响更加关注，同时对自己的参与AI规范讨论的能力更有信心。最后，我们强调AI规范作业是探索AI对齐极限的有效工具，突出政策在解决道德挑战中的作用。
## Innovation
我们开发了一个AI政策模块，将AI政策讨论引入计算机科学课程。该模块在2024年秋季试点成功，并在此篇论文中呈现了更新和扩展后的版本，包括一个“AI规范”的技术作业，旨在帮助学生更好地理解和应用AI伦理原则，并促进他们参与AI政策讨论的能力。
## Conclusion
通过AI政策模块的学习，学生对AI技术的伦理影响更加关注，同时对自己的参与AI规范讨论的能力更有信心。AI规范作业被证明是探索AI对齐极限的有效工具，并强调了政策在解决道德挑战中的作用。
# 11. `cs.AI` - 探索和利用大型推理模型中的固有效率以实现自我引导的效率增强 [PDF](https://arxiv.org/pdf/2506.15647), [HTML](https://arxiv.org/abs/2506.15647)
## Authors
Weixiang Zhao,Jiahe Guo,Yang Deng,Xingyu Sui,Yulin Hu,Yanyan Zhao,Wanxiang Che,Bing Qin,Tat-Seng Chua,Ting Liu
## Background
最近，大型推理模型（LRMs）的进步显著增强了语言模型在复杂问题解决中的能力，通过模拟类似人类的推理方式。然而，这些模型通常会表现出过度推理（即生成不必要的冗长和重复的内容），这阻碍了效率，并增加了推理成本。
## Innovation
作者探索了效率低下的表征和行为根源，揭示了LRMs具有更简洁推理的能力。通过实证分析，发现正确的推理路径在长度上差异很大，最短的正确响应常常足够，这表明存在未开发的效率潜力。为此，作者提出了两种轻量级方法来提高LRM的效率。首先，引入了无需训练的激活引导技术，称为效率引导，通过模型表示空间中的单一方向来调节推理行为。其次，开发了一种自我奖励的强化学习框架，称为自我奖励效率强化学习，该框架通过奖励简洁的正确解决方案来动态平衡任务准确性与简洁性。这些方法在七个LRM架构上多个数学推理基准测试中的实验结果表明，显著减少了推理长度，同时保持或提高了任务表现。
## Conclusion
研究结果强调，可以通过利用和引导现有模型的内在能力来提高推理效率，从而实现自我引导的效率增强。
# 12. `cs.AI` - SwarmAgentic: 通过群体智能实现全面自动的代理系统生成 [PDF](https://arxiv.org/pdf/2506.15672), [HTML](https://arxiv.org/abs/2506.15672)
## Authors
Yao Zhang,Chenyang Lin,Shijie Tang,Haokun Chen,Shijie Zhou,Yunpu Ma,Volker Tresp
## Background
大型语言模型的快速发展促进了代理系统的决策、协调和任务执行能力。然而，现有的代理系统生成框架缺乏完全的自主性，无法从零开始生成代理，缺乏自我优化的代理功能以及协作能力，这限制了其适应性和扩展性。
## Innovation
提出了SwarmAgentic框架，这是一个实现全面自动代理系统生成的方法，能够从零开始构建代理系统，并通过语言驱动的探索来共同优化代理功能和协作。为了实现高效的系统级结构搜索，SwarmAgentic维护了一群候选系统，并通过反馈引导的更新进行进化，借鉴了粒子群优化（PSO）的理念。这一方法在六个实际任务中表现突出，包括高层次的计划、系统级的协调和创造性推理。仅凭任务描述和目标函数，SwarmAgentic就超越了所有基线，特别是在TravelPlanner基准测试中，相对于ADAS实现了261.8%的相对改进，证明了在结构约束不足的任务中全自动化技术的有效性。
## Conclusion
SwarmAgentic框架标志着朝着大规模和自主的代理系统设计迈出的重要一步，连接了群体智能和完全自动化的多代理系统生成。该代码已公开发布。
# 13. `cs.AI` - Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence [PDF](https://arxiv.org/pdf/2506.15677), [HTML](https://arxiv.org/abs/2506.15677)
## Authors
Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang
## Background
现有的AI代理大多是独立工作的——它们要么获取并推理大量的在线数字信息和知识；要么通过身体感知、计划和行动与物理世界互动，但很少两者兼而有之。这种分离限制了它们解决需要综合物理和数字智能的任务的能力，如根据在线食谱烹饪、使用动态地图数据导航，或者利用网络知识解释现实世界的地标。本文背景下，AI代理在物理和数字领域的综合表现仍然较为有限，缺乏将这两个领域的知识和能力有机结合的能力。因此，构建一个能够综合物理和数字领域的AI代理具有重要研究意义和应用价值。
## Innovation
本文介绍了一种新的范式——实体化网络代理（Embodied Web Agents），它能够流畅地连接身体化和大规模网络推理。该研究通过构建一个统一的模拟平台Embodied Web Agents task environments，将现实3D室内外环境与功能性的网络界面紧密结合，为AI代理跨领域的智能提供了评估基准。这套基准涵盖了烹饪、导航、购物、旅游和地理定位等一系列需要在物理和数字领域进行协调推理的任务，以系统评估跨域智能。研究表明，最先进的AI系统在某些任务上与人类能力之间存在显著差距，揭示了在实体认知和大规模网络知识获取交汇点存在的挑战与机遇。
## Conclusion
实验结果表明，最先进的AI系统与人类的能力之间存在显著差距，这为跨域智能评估建立了新的标准，并确立了实体认知与大规模网络知识访问交汇点的挑战与机遇。所有数据集、代码和网站均可在项目页面上公开访问。
# 14. `cs.AI` - DEFORMER: 结合变形局部分布与全局上下文以实现鲁棒的端到端语音识别 [PDF](https://arxiv.org/pdf/2207.01732), [HTML](https://arxiv.org/abs/2207.01732)
## Authors
Jiamin Xie,John H.L. Hansen
## Background
卷积神经网络（CNN）通过利用时间-频率的局部模式极大地提升了语音识别性能。但常规CNN操作假设这些模式出现在对称且刚性的小窗口中。因此，作者提出这个问题：不对称的小窗口会怎样呢？研究中表明，自适应视角可以发现与注意力耦合较好的局部特征，而不是固定视角输入的固定视角。通过使用变形的深度CNN替代移位的同伴在Conformer架构中，开发出“Deformer”。
## Innovation
作者提出了“Deformer”，这是一种可以使用变形局部图与全局上下文进行语音识别的新型结构。通过替换Conformer架构中的一半编码器层，性能提高了+5.6%相对误差率（无语言模型）和+6.4%（有语言模型）。分析结果表明，Deformer能够在多个语音单元级别发现增强的特征关联，并通过统计分析深度增加对特征所含信息变化的观察。
## Conclusion
Deformer能够在保留模型性能的同时，通过结合变形局部模式和全局上下文来增强语音识别的鲁棒性。其最佳性能模型在WSJ eval92集上的相对错误率改善了+5.6%（无语言模型）和+6.4%（有语言模型）。
# 15. `cs.AI` - 动态ASR路径：一种面向多语言ASR模型高效剪枝的自适应掩码方法 [PDF](https://arxiv.org/pdf/2309.13018), [HTML](https://arxiv.org/abs/2309.13018)
## Authors
Jiamin Xie,Ke Li,Jinxi Guo,Andros Tjandra,Yuan Shangguan,Leda Sari,Chunyang Wu,Junteng Jia,Jay Mahadeokar,Ozlem Kalinli
## Background
神经网络剪枝为多语言自动语音识别（ASR）模型的压缩提供了一种有效的方法，但每次更换语言都需要多次剪枝和重新训练，这大大增加了处理时间。本文介绍了在两种情形下，使用自适应掩码方法高效剪枝多语言ASR模型的研究，最终生成稀疏单语模型或稀疏多语言模型（即动态ASR路径）。这种方法允许自适应调整子网络，避免了固定子网络结构过早做出决策，从而减少处理时间并保持性能。
## Innovation
提出了一种自适应掩码方法，用于剪枝多语言ASR模型，动态调整子网络结构，避免了固定的子网络结构决策，能够生成稀疏的单语模型或多语模型（称之为动态ASR路径）。实验结果显示该方法在目标为稀疏单语模型时优于现有的剪枝方法。此外，该方法还联合发现并训练多语言模型的不同子网络路径，减少了针对特定语言的单独剪枝需求。
## Conclusion
研究表明，动态ASR路径方法在生成稀疏单语模型时表现优于现有方法，并且还能够联合发现和训练更好子网络路径，减少针对特定语言模型的单独剪枝，提高了多语言ASR模型的剪枝效率和性能。
# 16. `cs.AI` - MixRep: 隐藏表示混合法在资源受限的语音识别中的应用 [PDF](https://arxiv.org/pdf/2310.18450), [HTML](https://arxiv.org/abs/2310.18450)
## Authors
Jiamin Xie,John H.L. Hansen
## Background
本文提出了MixRep，这是一种基于mixup的数据增强策略，旨在改善资源受限的自动语音识别（ASR）系统。现有的MixSpeech方法限制在输入特征上应用mixup，而MixRep不仅应用于输入特征，还应用于每一层的隐藏表示。此外，作者提出了一种结合mixup与时间轴正则化的方法，进一步增强了模型性能。实验在WSJ和SWB子集数据集上进行，结果表明MixRep在资源受限的ASR中的表现优于其他正则化方法，特别是在SpecAugment的基线上，相对错误率分别降低了6.5%和6.7%。
## Innovation
1. MixRep通过对隐藏表示进行插值，不仅应用于输入特征，还应用于每一层的输出，扩大了应用范围；
2. 结合mixup与时间轴上的正则化，增强模型性能；
3. 在Conformer编码器结构中，利用联合CTC损失进行训练，证实了其有效性和优势。
## Conclusion
MixRep在资源受限的ASR系统中表现出色，相对其他正则化方法具有显著优势，尤其是在较大的数据集上实现了显著的错误率减少。
# 17. `cs.AI` - MedSyn: 通过人机协作提高诊断效果 [PDF](https://arxiv.org/pdf/2506.14774), [HTML](https://arxiv.org/abs/2506.14774)
## Authors
Burcu Sayin,Ipek Baris Schlicht,Ngoc Vo Hong,Sara Allievi,Jacopo Staiano,Pasquale Minervini,Andrea Passerini
## Background
临床决策本身是复杂的，往往会受到认知偏差、信息不全和病例不明确的影响。现有的大语言模型（LLMs）显示出支持临床决策的应用前景，但它们通常是一次性或有限交互的使用方式，可能忽视了实际医疗实践中复杂性。
## Innovation
本文提出了一个混合的人类-人工智能框架MedSyn，医生和LLMs通过多步、互动对话来细化诊断和治疗决策。与静态决策支持工具不同，MedSyn允许动态交流，医生可以挑战LLMs的建议，而LLMs则强调不同的角度。通过模拟医生-LLM互动，评估开源LLMs作为医生助手的潜力。结果显示，开源LLMs在实际世界中作为医生助手是相当有前途的。未来的工作将涉及真实医生的互动，以进一步验证MedSyn在诊断准确性和患者结果方面的有效性。
## Conclusion
开源LLMs作为医生助手在现实世界中具有潜力，未来将通过实际医生互动进一步验证MedSyn的有效性。
# 18. `cs.AI` - CUE：理解解释的认知模型 [PDF](https://arxiv.org/pdf/2506.14775), [HTML](https://arxiv.org/abs/2506.14775)
## Authors
Tobias Labarta,Nhi Hoang,Katharina Weitz,Wojciech Samek,Sebastian Lapuschkin,Leander Weber
## Background
随着机器学习系统越来越多地影响关键决策，人类可理解的解释需求日益增长。当前对可解释人工智能（XAI）的评估常侧重于技术准确性而非认知可访问性，这对用户，特别是视觉障碍用户至关重要。现有研究发现，不同颜色映射（如BWR、Cividis、Coolwarm）的热图在任务表现上差异不大，但视觉障碍用户在使用时缺乏信心且付出更多努力。尽管采用无障碍导向的颜色映射（如Cividis），但这些差距并未得到缓解，有时甚至恶化，这挑战了感知优化的假设，并凸显了适应性XAI界面的必要性。
## Innovation
该研究提出了一个认知模型CUE（认知理解），将解释属性与认知子过程相关联：可读性（感知）、可读性（理解）和可解释性（解释）。该模型强调改变解释的可读性会直接影响理解能力。此外，该研究提供了一个形式化的人性化解释属性的综合定义，并通过实验证据支持可访问、用户定制化XAI的必要性。
## Conclusion
该研究贡献了：(1) 一个正式化的人性化解释理解认知模型CUE；(2) 一个综合定义的人性化解释属性；(3) 鼓励采用可访问、用户定制化XAI的经验性证据，挑战了感知优化的假设并支持开发更加适应用户的XAI接口。
# 19. `cs.AI` - WebXAII: 开源的网络框架，用于研究人类与可解释人工智能的交互 [PDF](https://arxiv.org/pdf/2506.14777), [HTML](https://arxiv.org/abs/2506.14777)
## Authors
Jules Leguy,Pierre-Antoine Jean,Felipe Torres Figueroa,Sébastien Harispe
## Background
随着人工智能（特别是机器学习）在众多应用领域的广泛应用，可解释的人工智能（XAI）领域的研究也迅速发展。然而，研究者在研究人类与XAI技术交互时通常会自行开发针对性的交互界面，这些界面大多不与研究结果一同分享，导致了这些界面的重复使用性较差以及实验的可重复性受限的问题。
## Innovation
WebXAII 是一个基于Web的开源框架，旨在简化人类与XAI系统的交互研究。它能够实现完整的实验协议，包括向参与者展示实验各个方面和记录其反馈。实验协议被转化为通用视图和模块的组合架构，提供了高度的灵活性。架构定义在结构化配置文件中，使得协议的实现几乎不需要编程技能。通过重现文献中的一项先进研究的实验协议，证明了WebXAII的有效性。
## Conclusion
WebXAII 可以有效实现相关实验协议，通过构建一个完全基于Web的平台，解决当前研究中实验界面不共享的问题，提高实验的重复使用性和可重复性。框架已开源，提供了一个有力的研究工具，促进了XAI领域的人机交互研究。
# 20. `cs.AI` - 基于物理指导的位置编码（PIPE）：卫星图像与时序数据对齐 [PDF](https://arxiv.org/pdf/2506.14786), [HTML](https://arxiv.org/abs/2506.14786)
## Authors
Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau
## Background
多模态时间序列预测在多个领域中基础性重要，比如通过卫星图像与数值数据预测气候变化中的台风。然而，现有方法对于时间序列数据的多模态处理主要依赖于文本数据，忽视了已有的视觉数据。现有视觉数据中的时间空间上下文和物理信息提取具有挑战性。为解决此问题，提出了一种轻量级的位置编码方法——物理信息导向的位置编码（PIPE），该方法将物理信息嵌入到视觉语言模型（VLM）中，以改善多模态对齐和预测准确性。
## Innovation
1. 提出了一种基于物理信息的位置索引方案，将物理参数映射到位置ID。2. 引入了变频位置编码机制，用于捕捉物理变量的频率信息及其在嵌入空间中的序列顺序。
## Conclusion
通过实验，在最大且最具代表性的开放卫星图像数据集上，PIPE在深度学习预测和气候领域方法中都达到了最先进的性能，显著提高了时间序列预测的准确性，台风强度预测性能较之前工作提升了12%。
# 21. `cs.AI` - 面向多层存储系统的拓扑感知和高度通用的深度强化学习方法以实现高效检索 [PDF](https://arxiv.org/pdf/2506.14787), [HTML](https://arxiv.org/abs/2506.14787)
## Authors
Funing Li,Yuan Tian,Ruben Noortwyck,Jifeng Zhou,Liming Kuang,Robert Schulz
## Background
在现代工业和物流环境中，快速配送服务的需求激增，对能够提高效率并增加存储密度的存储系统的需求日益增加。多层自主车辆存储和检索系统（AVS/RS）是提高存储密度的可能解决方案，但这些系统在检索操作中会遇到由于车道堵塞而带来的问题。传统的解决方案是将具有相同特性的物品存放在单一车道中，但这限制了多层存储系统的灵活性和适应性。因此，本文提出了一种基于深度强化学习的框架，用于解决具有异构物品配置的多层存储系统的检索问题。
## Innovation
本文创新性地提出了一种基于深度强化学习的框架，旨在解决多层存储系统中异构物品配置的检索问题。该框架通过使用融合物品属性和多层仓库局部拓扑结构的图表示方法，设计了一种结合图神经网络（GNN）和变换器模型的新神经网络架构来捕获系统拓扑，从而优化检索延迟。此外，变换器的泛化能力强，使该方法能够应用于具有不同布局的存储系统。
## Conclusion
广泛的数值实验表明，提出的神经网络架构和训练的代理在优化检索延迟方面优于启发式方法。
# 22. `cs.AI` - 比较风能预测中QNN架构的分析：特征映射与结构配置 [PDF](https://arxiv.org/pdf/2506.14795), [HTML](https://arxiv.org/abs/2506.14795)
## Authors
Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu
## Background
量子机器学习（QML）是量子计算与机器学习交叉领域的一个新兴方向，旨在通过利用量子力学原理如纠缠和叠加来增强经典的机器学习方法。尽管存在对QML实际优势的怀疑，特别是由于当前嘈杂的中等规模量子（NISQ）设备的限制，但研究表明量子神经网络（QNN）在某些情况下可以克服这些挑战，显示出比经典方法更高的效率。
## Innovation
本研究创新性地对12种不同的QNN配置进行了系统构建和评估，结合了两种独特的量子特征映射和六种不同的纠缠策略进行初始化设计。实验结果表明，使用Z特征映射的QNN在仅使用四个输入参数预测风能输出时，准确率达到93%。这表明QNN在预测任务中优于经典方法，突显了QML在实际应用中的潜力
## Conclusion
本研究评估了多种QNN架构的有效性，并展示了它们在风能预测任务中的优势。实验结果证明，QNN比经典方法更优越，揭示了QML在实际应用中的潜力。
# 23. `cs.AI` - PFMBench：蛋白质基础模型基准 [PDF](https://arxiv.org/pdf/2506.14796), [HTML](https://arxiv.org/abs/2506.14796)
## Authors
Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li
## Background
近年来，蛋白科学与工程的研究取得了显著进展，但由于缺乏全面的评估基准，导致无法进行公平评价和深入理解。自ESM-1B以来，涌现出了许多蛋白质基础模型，但评估通常集中在有限的任务上，这些任务往往是针对特定模型设计的。这限制了对模型广泛表现和局限性的深入理解。研究人员难以理解任务之间的关系，评估当前模型在这些任务中的表现，并确定开发新型基础模型的标准。因此，需要一个全面的评估基准来填补这一空白，为蛋白科学的八大关键领域设置38个任务。通过在17种最先进的模型上的数百次实验，PFMBench揭示了任务之间的固有联系，确定了表现最佳的模型，并提供了一种简化的评估协议。代码可在GitHub上获得。
## Innovation
PFMBench是一个全面的基准评估系统，涵盖38个任务涉及蛋白科学的八大关键领域，评估了17种最先进的模型。它揭示了任务之间的内在联系，识别了表现最佳的模型，并提供了一种简化的评估协议。此外，代码托管在GitHub上，为研究人员提供了便利。
## Conclusion
PFMBench填补了蛋白质基础模型评估中的空白，通过全面的任务设置和详细的实验验证，提供了关于当前模型性能和限制的新见解，并为开发新的基础模型提供了指导标准。
# 24. `cs.AI` - 由语义性限制：规范泛化-识别权衡的普遍法则 [PDF](https://arxiv.org/pdf/2506.14797), [HTML](https://arxiv.org/abs/2506.14797)
## Authors
Marco Nurisso,Jesseba Fernando,Raj Deshpande,Alan Perotti,Raja Marjieh,Steven M. Frankland,Richard L. Lewis,Taylor W. Webb,Declan Campbell,Francesco Vaccarino,Jonathan D. Cohen,Giovanni Petri
## Background
智能系统必须部署同时结构化和选择性的内部表示，以支持广泛的泛化并保持输入的身份。然而，这项研究揭示了在这种权衡中的一个基本极限。对于任何在有限语义分辨率ε下具有表征相似性随输入衰减的模型，该研究推导出封闭形式的表达式，将正确的泛化概率 $p_S$ 和识别概率 $p_I$ 绑定到独立于输入空间几何结构的普遍帕雷托前沿。对噪声和异质空间进行扩展分析以及超过两个输入的处理能力预测了多输入处理能力的锐变 $1/n$ 倒数下塌，并且 $p_S$ 的非单调最优值。最小ReLU网络端到端训练后再现了这些法则，在学习过程中，分辨率边界会自我组织，经验 $(p_S,p_I)$ 轨迹紧密跟随线性衰减相似性的理论曲线。最后，结果表明同样的极限存在于两个更为复杂的情景中——卷积神经网络和最先进的视觉-语言模型，证明了有限分辨率的相似性是一种固有的、涌现的信息限制，而不仅仅是玩具模型的特征。研究结果提供了一个精确的泛化-识别权衡理论，并澄清了语义分辨率如何塑造深度网络和大脑的表征能力
## Innovation
研究揭示了智能系统内部表示的一种基本极限，即当表征相似性随输入的语义分辨率衰减时，正确的泛化概率 $p_S$ 和识别概率 $p_I$ 被绑定到一个普遍的帕雷托前沿。研究通过最小ReLU网络和两套更为复杂的情景验证了这种极限，表明有限分辨率相似性是固有的、涌现的信息限制，而非简单玩具模型的特征。该研究提出了一个精确的泛化-识别权衡理论，澄清了语义分辨率如何影响神经网络和大脑的表征能力
## Conclusion
研究表明，智能系统无论部署何种模型，当表征相似性随输入的语义分辨率衰减时，都存在一个唯一确定的泛化和识别的概率边界。这些发现说明了语义决定的表示局限性和影响智能系统能力的限度。最小ReLU网络、卷积神经网络和最新视觉-语言模型均证实了这项研究结果，支持了该理论的有效性。整体而言，该研究为智能系统的泛化-识别权衡提供了精确理论基础，推动了对智能系统能力限制和表征能力的理解
# 25. `cs.AI` - 使用多模态基础模型分析媒体内容中的角色代表：效果与信任 [PDF](https://arxiv.org/pdf/2506.14799), [HTML](https://arxiv.org/abs/2506.14799)
## Authors
Evdoxia Taka,Debadyuti Bhattacharya,Joanne Garde-Hansen,Sanjay Sharma,Tanaya Guha
## Background
近年来，AI的发展使得大规模自动分析复杂媒体内容成为可能，并能生成关于角色呈现的可操作见解，涵盖性别和年龄等维度。过去的研究所侧重于利用各种机器学习模型量化这些内容中的角色代表，但缺乏对受众的考量。这项研究旨在探索即使在提供了基于人口统计维度的角色分布的情况下，这些信息对公众的实际有用性和信任度，以及公众对基于AI模型生成的数据的信任程度如何。研究通过用户调研提出了一种基于对比语言图像预训练（CLIP）的基础模型的分析工具，用于分析屏幕数据以定量角色在学校性别和年龄等维度的代表情况。同时还设计了适合呈现这种分析的可视化工具，以供普通公众理解。随后进行了一项用户研究，以实证用户对基于不同电影中的可视化的AI生成结果的认识和信任度的认识和信任度。参与者能够理解可视化中的分析，总体认为该工具有一定用处，但他们希望更详细的可视化能包括更多的群体类别和角色的上下文信息。对于基于AI的性别和年龄模型，参与者表示信度中等到较低，尽管他们不反对在这种情况下使用AI。这项工具包括代码、基准测试和用户研究的数据，可在给出的链接中找到
## Innovation
研究提出了一种基于CLIP的基础模型的分析工具，用于分析屏幕数据以定量角色在学校性别和年龄等维度的代表情况，并设计了适合呈现这种分析的可视化工具，以供普通公众理解。同时，通过用户研究验证了AI生成的分析结果在受众中的实用性和信度。参与者提供了使用体验反馈，为工具的进一步完善提供了方向
## Conclusion
参与者的反馈表明，虽然基于AI的性别和年龄模型具有一定的实用性和可理解性，但仍有许多改进空间，特别是在可视化呈现方面。研究结果有助于更好地理解公众对AI生成的媒体内容分析的信任度，并为未来这类分析工具的设计和应用提供了实践依据。
# 26. `cs.AI` - ss-Mamba: 舔尾炎选择性状态空间模型 [PDF](https://arxiv.org/pdf/2506.14802), [HTML](https://arxiv.org/abs/2506.14802)
## Authors
Zuochen Ye
## Background
近年来，Transformer架构在时间序列预测方面取得了显著的成功。然而，这些模型的计算复杂度较高，特别是在大规模数据集上的表现。为了克服这些限制，本文提出了一种新的基础模型ss-Mamba，该模型结合了语义感知嵌入和自适应样条基时间编码，用于选择性状态空间建模框架中增强时间序列预测。
## Innovation
ss-Mamba采用了Mamba选择性状态空间模型作为Transformer架构的高效替代方案，实现了相似的性能同时将计算复杂度降低到线性时间。通过从预训练的语言模型中初始化语义索引嵌入，ss-Mamba能够在以前未见过的时间序列上实现有效的泛化，并通过有意义的语义先验提供有效的语义感知嵌入。此外，基于样条的柯尔莫哥洛夫-阿诺德网络（KAN）能够动态并可解释地捕捉复杂季节性和非平稳时间效应，提高了时间序列特征编码的效果。实证研究表明，ss-Mamba在准确性、鲁棒性和可解释性方面表现优异，为时间序列预测领域提供了一个灵活且计算高效的替代方案。
## Conclusion
通过选择性状态空间建模框架，ss-Mamba在时间序列预测中实现了卓越的性能、鲁棒性和可解释性，并且显著降低了计算复杂度，使其成为一种更具优势的替代传统基于Transformer的时间序列预测模型的选项。
# 27. `cs.AI` - Argus Inspection: 多模态大型语言模型具备潘多雷斯之眼吗？ [PDF](https://arxiv.org/pdf/2506.14805), [HTML](https://arxiv.org/abs/2506.14805)
## Authors
Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang
## Background
随着多模态大语言模型（MLLMs）的不断进化，它们的认知和推理能力取得了显著进步。然而，视觉细粒度感知能力和常识因果推理仍存在挑战。本研究提出Argus Inspection，这是一个具有两个难度级别的多模态基准，强调详细的视觉识别，同时结合现实世界的常识理解来评估因果推理能力。在此基础上，我们提出Eye of Panoptes框架，将二进制参数化Sigmoid度量与指示器函数相结合，能够更全面地评估MLLMs在意见性推理任务中的响应能力。实验结果显示，最高的视觉细粒度推理性能仅为0.46，这表明增强的潜力很大。我们的研究为MLLMs的持续改进提供了宝贵的视角。
## Innovation
1. 提出Argus Inspection，这是一个具有不同难度级别的多模态基准，强调详细的视觉识别和现实世界的常识理解，用于评估因果推理能力。2. 提出Eye of Panoptes框架，结合二进制参数化Sigmoid度量和指示器函数，更好地评估MLLMs在意见性推理任务中的反应能力。
## Conclusion
实验表明，尽管MLLMs在视觉细粒度推理方面取得了进展，但性能仍然有限，表明有显著改进的空间。我们的研究为MLLMs的持续优化提供了有价值的见解。
# 28. `cs.AI` - 训练以自信：使用自动化主动检查在深度学习训练中捕捉沉默错误 [PDF](https://arxiv.org/pdf/2506.14813), [HTML](https://arxiv.org/abs/2506.14813)
## Authors
Yuxuan Jiang,Ziming Zhou,Boyu Xu,Beijie Liu,Runhui Xu,Peng Huang
## Background
训练深度学习模型是一个复杂的流程，容易产生难以检测和诊断的沉默错误。当前缺乏有效的检测和诊断方法来处理这些错误，这成为深度学习模型开发的巨大挑战。
## Innovation
该论文提出了TRAINCHECK框架，该框架通过自动推断专用于深度学习训练的不变式，来主动检测训练过程中的沉默错误，并提供调试帮助。这项工作的创新在于其使用自动验证方法来提早发现并解决模型训练中的潜在问题，而不依赖于训练后的错误诊断。
## Conclusion
通过再现来自20个不同类型的实际世界训练中的沉默错误，TRAINCHECK成功在单次训练迭代中检测出了18个错误，并且还发现了6个存在于流行训练库中的未知名错误，这些错误也会导致沉默错误。
# 29. `cs.AI` - 下一代冲突预测：通过时空学习释放预测模式 [PDF](https://arxiv.org/pdf/2506.14817), [HTML](https://arxiv.org/abs/2506.14817)
## Authors
Simon P. von der Maase
## Background
高空间和时间分辨率下预测暴力冲突依然是研究者和政策制定者面临的主要挑战。本文提出了一种新颖的神经网络架构，用于预测三种不同类型（基于国家的、非国家的和单边的）暴力事件在次国家（priogrid月度）水平上的风险，最多提前36个月。该模型同时执行分类和回归任务，不仅能提供未来事件的概率估计，还能预测事件的预期规模。它在所有任务中的性能均达到了最新技术水平，并生成近似的预测后验分布来量化预测的不确定性。
## Innovation
该架构基于蒙特卡洛 Dropout 长短时记忆（LSTM） U-Net，结合卷积层捕捉时空依赖性及循环结构建模时序动态。与许多现有方法不同，该模型无需手动特征工程，仅依赖于历史冲突数据，使模型能够自主学习驱动暴力冲突的复杂时空模式。此外，该模型具有极强的可扩展性，能够轻松整合其他数据源并联合预测辅助变量。
## Conclusion
该模型不仅达到最先进的预测性能，还能作为早期预警系统、人道主义响应计划和基于证据的和平建设项目的有力工具。
# 30. `cs.AI` - 在资源受限条件下强化VLMs使用工具进行详细的视觉推理 [PDF](https://arxiv.org/pdf/2506.14821), [HTML](https://arxiv.org/abs/2506.14821)
## Authors
Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya
## Background
尽管大型模型在推理能力方面取得了巨大进展，视觉语言模型（VLMs）在处理详细的视觉推理任务时仍然存在困难，特别是在计算资源有限的情况下。
## Innovation
本文提出了使用Group Relative Policy Optimization (GRPO)训练较小规模模型的方法，结合简单的奖励结构、简化工具调用接口以及为工具调用结果分配额外标记符，并且在训练数据集中更常出现视觉困难的例子。这种组合方式有效地提升了解决视觉问答（VQA）任务的能力，相较于同等规模的基础模型，该方法从外部工具获取到了更详细的基础信息，从而提高了性能。
## Conclusion
通过结合GRPO学习、简单的奖励结构、简化工具调用接口、分配额外标记符给工具调用结果以及训练数据集过采样视觉困难例子，该方法在一些视觉问答任务中取得了更好的表现。
# 31. `cs.AI` - ViLLa：一种用于动物监测的神经-符号方法 [PDF](https://arxiv.org/pdf/2506.14823), [HTML](https://arxiv.org/abs/2506.14823)
## Authors
Harsha Koduri
## Background
在自然环境中监测动物种群需要能够同时解释视觉数据和人类语言查询的系统。现有的系统通常采用端到端的黑盒模型，这些模型将感知、理解和推理整合为一个整体，缺乏透明性和模块化性。
## Innovation
ViLLa（Vision-Language-Logic Approach）是一个神经-符号框架，旨在为可解释的动物监测提供解决方案。它通过结合视觉检测模块、语言解析器和基于逻辑推理的符号推理层，分离了感知、理解和推理过程，提高了系统的模块化和透明度，能够将视觉内容与结构化的、可供人类解释的查询关联起来。
## Conclusion
ViLLa 被在一系列动物图像任务中评估，展示了将视觉内容与结构化的人类可理解查询关联的能力，证明了其在动物监测领域的有效性。
# 32. `cs.AI` - FedNano：朝向轻量级预训练多模态大型语言模型联邦微调 [PDF](https://arxiv.org/pdf/2506.14824), [HTML](https://arxiv.org/abs/2506.14824)
## Authors
Yao Zhang,Hewei Gao,Haokun Chen,Weiguo Li,Yunpu Ma,Volker Tresp
## Background
多模态大型语言模型（MLLMs）在多模态推理和跨模态检索等任务中表现出色，但在实际部署中面临挑战，包括分散的多模态数据和严格的隐私要求。联邦学习（FL）提供了一种解决方案，通过不集中数据就能实现模型合作训练。然而，对MLLMs实施FL存在显著挑战，如高计算需求、客户端容量限制、高昂的通信成本和客户间数据异构性。现有FL方法假设客户端会部署完整的模型，而这一点对于大规模MLLMs因为它们的庞大尺寸和通信需求而言并不适用。
## Innovation
我们提出了FedNano，这是第一个将LLM集中于服务器上的FL框架，并引入了一个轻量级模块NanoEdge，用于客户端特定的适应。NanoEdge使用模态特异性编码器、连接器和低秩可训练NanoAdapters。这种设计消除了在客户端部署LLM的需求，减少了客户端存储空间高达95%，并将通信开销限制在模型参数的0.01%。通过仅传输紧凑的NanoAdapter更新，FedNano能够处理客户间的异构数据和资源约束，同时保持隐私。实验表明FedNano优于之前的FL基线，缩小了MLLM规模与FL可行性的差距，并使可扩展、分布式的多模态AI系统成为可能
## Conclusion
FedNano 对于扩展和分布式多模态AI系统的实现具有重要意义，特别是在处理大规模MLLM时，通过减少通信开销、适应不同资源的限制以及保存隐私，实现了性能的显著提升。
# 33. `cs.AI` - GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction [PDF](https://arxiv.org/pdf/2506.14825), [HTML](https://arxiv.org/abs/2506.14825)
## Authors
Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong
## Background
现有的3D高斯分割（3DGS）方法在自动驾驶中的三维语义占用预测任务中存在的两个关键问题是：（1）统一特征聚合忽略了相似类别之间的语义关联以及区域间的关联；（2）由于MLP迭代优化缺乏几何约束而导致的边界模糊性。研究人员提出了一种新的方法来解决上述问题，该方法使用语义和几何图变换器结合3DGS方法进行三维占位预测，旨在改善这些方法的局限性，提高预测准确性和效率。
## Innovation
提出了一种名为GraphGSOcc的新型框架，该框架通过结合语义和几何图变换器来处理基于3DGS的占位预测。具体创新点包括：（1）提出了双重高斯图注意力机制，动态构建几何图和语义图两种结构，分别针对几何一致性与语义关联进行优化；（2）结合多尺度图注意力框架，通过细粒度和粗粒度注意力机制在不同尺度上优化边界细节与对象拓扑结构；（3）有效减少GPU内存使用且保持或提升语义占用预测的准确性。
## Conclusion
在SurroundOcc数据集上的实验结果表明，该方法实现了24.10%的mIoU，相比GaussianWorld在GPU内存使用上减少了13.7%，同时提升了1.97%的mIoU，证明了该框架的有效性和优越性。
# 34. `cs.AI` - 基于协同兴趣的图学习方法在群组识别中的应用 [PDF](https://arxiv.org/pdf/2506.14826), [HTML](https://arxiv.org/abs/2506.14826)
## Authors
Rui Zhao,Beihong Jin,Beibei Li,Yiyuan Zheng
## Background
随着社交媒体的普及，越来越多的用户参与在线社交平台上的群体活动，产生了一种群组识别（GI）的需求，即推荐合适的群组给用户。现有的GI方法未能全面建模兴趣的这种协同进化关系，也忽视了群体兴趣对个人兴趣的提升作用，导致在跨层兴趣对齐时出现了大量的误负样本。因此，需要一个能够同时考虑群体兴趣和个人兴趣，并能够建模两者相互影响的模型来提高群组识别的准确率。
## Innovation
提出了一个名为CI4GI的模型，这是一种协同兴趣感知的群组识别方法。该模型通过兴趣增强策略识别加入群组后用户新增的兴趣点来补充个人兴趣，同时使用用户兴趣分布的距离优化负样本的选择以减少误负样本的干扰。实验结果表明，CI4GI显著优于现有最先进的模型。
## Conclusion
该研究提出了CI4GI模型以解决现有群组识别方法中的问题，通过实验证明该方法在群体识别任务上表现出了更好的效果和准确性。
# 35. `cs.AI` - DAVID-XR1: 使用可解释推理检测AI生成视频 [PDF](https://arxiv.org/pdf/2506.14827), [HTML](https://arxiv.org/abs/2506.14827)
## Authors
Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang
## Background
随着AI生成的视频在媒体平台上的普及，可靠地区分合成内容与真实视频的能力变得至关重要。现有方法主要将此挑战视为二元分类任务，提供的洞察有限，无法详细解释模型为何将视频识别为AI生成。传统的检测方法关注于检测细微的伪像，而未提供可说服审计人员和最终用户的具体证据。因此，亟需一种能够提供细粒度、直观证据的方法，使其检测过程透明且可验证。
## Innovation
本文介绍了DAVID-X，第一个将AI生成视频与详细的缺陷级别、时空注释和书面理由配对的数据集。基于此丰富注释，提出了DAVID-XR1视频-语言模型，该模型可以展示具有缺陷分类、时空定位和自然语言解释的可视化推理链。该方法将AI生成视频的检测从不透明的黑盒决策转化为透明且可验证的诊断过程。研究表明，一个通用的基础模型，通过精简的训练集进行微调，并结合心智过程蒸馏，能在不同生成器和生成模式下实现强大的泛化能力。结果表明，可解释检测方法具有可靠识别AI生成视频内容的潜力。
## Conclusion
本文通过DAVID-X数据集和DAVID-XR1模型，提供了一种全面、可解释的方法来检测AI生成的视频。该方法不仅提高了检测模型的透明度和可验证性，还展示了其在不同AI生成器和生成模式下的泛化能力。这种方法为可信识别AI生成视频内容带来了希望。
# 36. `cs.AI` - AI4SI研究中实现影响力的困难：来自一线的挑战与机遇 [PDF](https://arxiv.org/pdf/2506.14829), [HTML](https://arxiv.org/abs/2506.14829)
## Authors
Aditya Majumdar,Wenbo Zhang,Kashvi Prawal,Amulya Yadav
## Background
尽管AI for Social Impact（AI4SI）项目致力于利用人工智能解决社会问题（如医疗、社会正义等领域），但实现实际、地面上的影响力仍面临重大挑战。例如，寻找并吸引愿意共同设计和部署基于AI的解决方案的实际合作伙伴往往很困难。即便建立了这样的合作关系，许多AI4SI项目仍停留在概念验证阶段，无法进入大规模生产的解决方案。此外，AI4SI研究者的独特挑战往往未被更广泛的AI社区完全认可，这些工作有时被视为应用为主，未能与核心人工智能会议所强调的传统新颖性标准一致。
## Innovation
本文通过半结构化访谈六位领先的AI4SI研究人员以及作者自己在进行AI4SI研究的经验，诊断了阻碍AI4SI合作伙伴实现实际影响力的多种因素。通过主题分析，识别出结构和组织、沟通、协作和操作挑战是关键障碍。提出了最佳实践和可操作策略，为AI4SI研究者和合作伙伴提供了一本实用的参考指南，帮助他们更有效地开展社会影响AI合作。
## Conclusion
本文旨在为AI4SI研究者和合作伙伴提供一份实用的参考指南，通过总结遇到的挑战和提出应对策略，旨在推动更有效的社会影响力AI合作。
# 37. `cs.AI` - 基于多头注意力机制优化双向门控循环单元细胞的SSD健康状态分类模型 [PDF](https://arxiv.org/pdf/2506.14830), [HTML](https://arxiv.org/abs/2506.14830)
## Authors
Zhizhao Wen,Ruoxin Zhang,Chao Wang
## Background
固态硬盘（SSD）的健康状态预测对于保障数据可靠性至关重要。目前，传统的健康状态分类模型普遍存在着泛化能力不足的问题，特别是在工业级存储系统预防性维护方面。因此，如何提高SSD健康状态分类的准确性和稳定性成为了一个关键挑战。为了应对这一挑战，研究提出了一种结合多头注意力机制的混合BiGRU-MHA模型，旨在提升存储设备健康状态分类的精度和稳定性。该模型通过挖掘时间特征和关键信息，充分利用双向门控循环单元（BiGRU）的双向时间建模优势以及多头注意力机制适应性地分配特征权重，从而提高模型对关键健康指标的敏感性。
## Innovation
该研究创新性地提出了混合BiGRU-MHA模型，通过结合多头注意力机制和双向门控循环单元，实现了对SSD退化特征的双向依赖建模，动态分配特征权重，提高模型对关键健康指标的敏感性。实验结果显示，该模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，AUC达到0.94，展示了其优秀的泛化能力。此外，该模型还解决了传统模型在泛化性方面的瓶颈问题，为工业级存储系统的预防性维护提供了一个可验证的、实用的方案。
## Conclusion
研究提出的混合BiGRU-MHA模型不仅提供了一种新的SSD健康预测技术方法，还解决了传统模型泛化能力不足的问题，通过提高早期故障预警能力，显著降低了数据丢失风险，并有助于优化维护成本，支持在云数据中心和边缘存储环境中为建立可靠的存储系统进行智能决策。
# 38. `cs.AI` - ArchShapeNet:可解释的3D-CNN框架用于评估建筑形态 [PDF](https://arxiv.org/pdf/2506.14832), [HTML](https://arxiv.org/abs/2506.14832)
## Authors
Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu
## Background
在当代建筑设计中，设计需求的复杂性和多样性使得生成性插件工具变得至关重要，这些工具能够快速生成初始概念并探索新颖的3D形态。然而，客观分析人类设计与机器生成的3D形态之间的差异仍然是一个挑战，这限制了我们对它们各自优点的理解，并阻碍了生成工具的进步。
## Innovation
我们构建了包含2000个建筑师设计和2000个Evomass生成的3D形态的数据集ArchForms-4000；提出了专为分类和分析建筑形态的3D卷积神经网络ArchShapeNet，该网络结合了显著性模块以突出与建筑逻辑一致的关键空间特征；实验结果显示，我们的模型在区分形态起源方面优于人类专家，准确率为94.29%，精确率为96.2%，召回率为98.51%。这项研究不仅强调了人工设计形态在空间组织、比例和谐和细节精致方面的独特优势，还为未来提升生成设计工具提供了宝贵见解。
## Conclusion
这项研究不仅突显了人工设计形态在空间组织、比例和谐和细节细节上的独特优势，而且还为提高生成设计工具提供了宝贵见解。
# 39. `cs.AI` - 基于熵自适应缓冲和MobileNetV2的边缘设备上实时低延迟监控 [PDF](https://arxiv.org/pdf/2506.14833), [HTML](https://arxiv.org/abs/2506.14833)
## Authors
Poojashree Chandrashekar Pankaj M Sajjanar
## Background
该论文描述了一种为资源受限环境设计的高性能、低延迟视频监控系统。该系统能够在资源受限设备（如树莓派、亚马逊设备和NVIDIA Jetson Nano）上处理实时视频流，并保持低于50毫秒的端到端推理延迟。该方法在标准视频监控数据集上保持了超过92%的检测准确性，并且对各种光照、背景和速度表现出鲁棒性。
## Innovation
论文提出了一种形式化熵自适应帧缓冲算法，并将其与MobileNetV2集成，实现了在资源受限设备上的高吞吐量和低延迟。一系列比较和消融实验验证了该设计的有效性。同时，该架构具有可扩展性、低成本，并与更严格的隐私法规保持一致，从而能够在智慧城市或嵌入式安全架构中与现有系统共存。
## Conclusion
我们的系统能够在资源受限的设备上保持高质量的视频监控，具有较低的延迟，并且与严格的隐私法规兼容，适用于智慧城市或嵌入式安全架构。
# 40. `cs.AI` - 在边缘设备上部署和评估多种深度学习模型以用于糖尿病视网膜病变检测 [PDF](https://arxiv.org/pdf/2506.14834), [HTML](https://arxiv.org/abs/2506.14834)
## Authors
Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye
## Background
糖尿病视网膜病变（DR）是糖尿病患者视力受损的主要原因，全球影响约34.6%的糖尿病患者，预计到2045年病例将达到2.42亿。传统的DR诊断依赖于人工检查视网膜图像，这既耗时又资源密集。为了改善这一现状，本文通过使用Edge Impulse在边缘设备上部署了多个深度学习模型进行实时DR检测。
## Innovation
本文利用Edge Impulse构建了一个包含超3,662张视网膜图像的稳健数据集，通过增强和归一化技术进行了预处理。利用TensorFlow，设计、训练和优化了多种卷积神经网络（CNN），包括MobileNet、ShuffleNet、SqueezeNet和自定义深度神经网络（DNN）。这些模型被转换为TensorFlowLite并量化为8位整数，以减少其大小并提高推理速度，同时尽量减少了准确性的损失。测试表明，MobileNet的准确率为96.45%，ShuffleNet和自定义DNN虽然准确性中等，但资源效率较高，适用于低端设备；SqueezeNet在GPU上的延迟仅为17ms，模型大小为176KB，表现为优秀的实时性能。
## Conclusion
这些集成于边缘AI技术的解决方案为DR的早期检测提供了可扩展且成本效益高的方法，可以在资源受限和偏远的医疗环境中提供及时和准确的诊断。
# 41. `cs.AI` - 通过结构化指令改进针对图表到代码生成的迭代改进 [PDF](https://arxiv.org/pdf/2506.14837), [HTML](https://arxiv.org/abs/2506.14837)
## Authors
Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang
## Background
最近，多模态大语言模型（MLLMs）因其强大的视觉理解能力而获得了越来越多的研究关注。尽管它们在各种视觉任务上已经取得了令人印象深刻的结果，但它们在图表到代码生成任务上的表现仍然不尽如人意。图表到代码生成任务要求MLLMs生成可执行代码以重现给定图表，这不仅需要精确的视觉理解，还需要准确地将视觉元素转换为结构化的代码。直接促使MLLMs执行这一复杂任务通常会产生令人不满意的结果。
## Innovation
我们提出了ChartIR，一种基于结构化指令的迭代细化方法。首先，我们将任务分为视觉理解代码翻译两个部分。为视觉理解部分设计了两类结构化指令：描述指令和差异指令。描述指令捕捉参考图表的视觉元素，差异指令描述参考图表与生成图表之间的差异。这些指令有效地将视觉特征转换为语言表示，从而便于后续的代码翻译过程。第二，我们将整个图表生成过程分解为两个阶段：初始代码生成和迭代细化，允许以渐进的方式增强最终输出。实验结果显示，与其它方法相比，我们的方法在开源模型Qwen2-VL和闭源模型GPT-4o上都取得了更好的性能。
## Conclusion
实验结果表明，与其它方法相比，我们的方法在开源模型Qwen2-VL和闭源模型GPT-4o上都取得了更好的性能。
# 42. `cs.AI` - PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers [PDF](https://arxiv.org/pdf/2506.14842), [HTML](https://arxiv.org/abs/2506.14842)
## Authors
Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop
## Background
在数据稀缺领域建立图像分类模型仍然很繁琐，因为收集大量带标签的数据集是不现实的。基于上下文学习（ICL）作为一种新的范式已经出现了，它能在少量样本的情况下实现图像分类，使模型能够在没有基于梯度的调整的情况下跨领域泛化。然而，以前的研究工作大多忽略了ICL基础的FSIC流水线中的关键组件：图像嵌入的作用。
## Innovation
作者提出了PictSure，这是一种将嵌入模型（其架构、预训练和训练动力学）放在中心分析的ICL框架。研究系统地探讨了不同视觉编码器类型、预训练目标以及微调策略对下游FSIC性能的影响。实验结果表明，嵌入模型的预训练方式对训练成功和跨领域性能有重要影响，因此PictSure在与训练分布差异显著的跨领域基准测试中表现出色，并且在领域内任务上也表现出类似的结果。
## Conclusion
PictSure 框架在跨领域基准测试中表现出色，同时在领域内任务上也达到了可比较的结果，表明预训练嵌入模型是影响ICL基础的FSIC模型性能的关键因素。
# 43. `cs.AI` - 在卷积神经网络中寻找最优内核大小和维度：一种架构优化方法 [PDF](https://arxiv.org/pdf/2506.14846), [HTML](https://arxiv.org/abs/2506.14846)
## Authors
Shreyas Rajeev,B Sathish Babu
## Background
卷积神经网络（CNNs）中的内核大小选择是一个至关重要的但经常被忽视的设计决策，它影响着感受野、特征提取、计算成本和模型精度。传统上，内核大小通常被固定为统一的3x3大小，但这可能导致效率低下和性能不足。
## Innovation
本文提出了一种数学理论和实验验证的框架——最佳内核大小估计函数（BKSEF），用于最优地、逐层地确定卷积层的内核大小。BKSEF通过结合信息论、信号处理和学习理论的原则，平衡信息增益、计算效率和精度改进。在CIFAR-10、CIFAR-100、ImageNet-lite、ChestX-ray14 和 GTSRB数据集上的大量实验表明，BKSEF引导的架构相比传统使用统一3x3内核的模型，在准确性和计算量（FLOPs）上分别提高了3.1%和减少了42.8%。实践案例进一步验证了这种方法在医疗图像分类和边缘设备上的交通标志识别中的有效性，既提高了可解释性和准确性，又显著减少了延迟和模型大小，且不影响精度。
## Conclusion
研究结果表明，内核大小可以是一个可以主动优化的参数，而非固定的经验法则。BKSEF为希望高效且应用针对性设计的CNN研究者和开发者提供了实用的启发式方法和理论支持，适合集成到神经架构搜索管道和实时系统中，提供了一种新的CNN优化视角。
# 44. `cs.AI` - 基于概率需求建模的大语言模型应用程序高效服务 [PDF](https://arxiv.org/pdf/2506.14851), [HTML](https://arxiv.org/abs/2506.14851)
## Authors
Yifei Liu,Zuo Gan,Zhenghao Gan,Weiye Wang,Chen Chen,Yizhou Shan,Xusheng Chen,Zhenhua Han,Yifei Zhu,Shixuan Sun,Minyi Guo
## Background
大语言模型（LLMs）的应用涉及多种任务，能够使用增强的能力解决实际问题，但这些应用对后台资源的需求量具有动态变化的特性。现有的服务系统将LLM应用的需求视为黑盒处理，这可能导致由于调度顺序不当和后台预热延迟导致端到端效率降低。研究发现，LLM应用程序的需求可以使用概率需求图（PDGraph）模型进行通用且准确的描述和建模。
## Innovation
该论文提出了Hermes系统，该系统利用PDGraph模型进行LLM应用的高效服务。Hermes针对概率需求进行处理，采用了Gittins策略来确定能最小化应用程序平均完成时间的调度顺序。同时，Hermes利用PDGraph模型在适当时刻帮助预热冷后台。实验结果证实，Hermes能够显著提高应用服务效率，平均完成时间减少超过70%，P95完成时间减少超过80%。
## Conclusion
Hermes利用概率需求图和Gittins策略实现了LLM应用程序的有效服务，显著提高了应用的端到端效率。
# 45. `cs.AI` - 通过测试时计划缓存提高LLM代理的成本效益服务 [PDF](https://arxiv.org/pdf/2506.14852), [HTML](https://arxiv.org/abs/2506.14852)
## Authors
Qizheng Zhang,Michael Wornow,Kunle Olukotun
## Background
基于LLM的代理应用在复杂的工作流程中显示出越来越出色的性能，但由于需要大量的规划和推理，导致成本显著增加。现有的LLM缓存技术（如上下文缓存和语义缓存），主要是为聊天机器人设计的，在面对依赖外部数据或环境上下文的代理应用时显得不足。现有的缓存方法无法有效应对这些需求，提出了一种新颖的代理计划缓存方法，通过从类似任务的计划阶段提取、存储、适配和重用结构化计划模板，以降低服务成本。
## Innovation
提出了一种名为代理计划缓存的新颖方法，重点是从代理执行中提取计划模板，在测试时进行匹配，并使用轻量级模型根据任务具体上下文来进行适应。这种方法不同于传统的语义缓存，其能够从已完成的代理执行中提取计划模板，在新请求中匹配缓存的计划，然后利用轻量级模型适应这些模板以生成特定任务的计划。该方法在全球多个实际应用中展示了46.62%的平均成本降低效果，同时保持了性能。
## Conclusion
代理计划缓存提供了一个更高效的服务方案，可以与现有的LLM服务基础设施互补，从而降低了基于LLM的代理的成本，同时保持了性能。
# 46. `cs.AI` - 高效零售视频标注：面向产品与顾客交互分析的稳健关键帧生成方法 [PDF](https://arxiv.org/pdf/2506.14854), [HTML](https://arxiv.org/abs/2506.14854)
## Authors
Varun Mannam,Zhenyu Shi
## Background
准确的视频标注在现代零售应用中扮演着至关重要的角色，包括客户行为分析、产品互动检测和店内活动识别。然而，传统的标注方法严重依赖于耗时的手动标签标注，导致关键帧选择不够稳健，并增加了运营成本.
## Innovation
本文提出了一种基于深度学习的方法，自动识别零售视频中的关键帧并提供自动产品和顾客标注。该方法利用深度神经网络学习具有区分性的特征，并结合了适合零售环境的物体检测技术。实验结果表明，该方法在准确度上超过了传统方法，达到与人工标注者相当的标注精度，同时提高了零售视频标注的整体效率。此外，该方法显著减少了视频标注成本，平均节省2倍的成本，允许人类标注者验证/调整视频数据集中少于5%的检测帧，而自动化剩余帧的标注过程不会降低标注质量，这对于各种零售应用，如购物者旅程分析、产品互动检测和店内安全监控等具有重要意义.
## Conclusion
本文提出的方法在自动识别关键帧和提供自动标注方面取得了显著成效，极大地提高了零售视频标注的效率和减少了成本。通过这种方法，零售商能够显著降低运营成本，使其在多样化的零售应用中受益。
# 47. `cs.AI` - 反馈-MPPI：通过展开差分实现快速采样-MPC -- 与低级控制器告别 [PDF](https://arxiv.org/pdf/2506.14855), [HTML](https://arxiv.org/abs/2506.14855)
## Authors
Tommaso Belvedere(RAINBOW, IRISA),Michael Ziegltrum(UCL),Giulio Turrisi(IIT),Valerio Modugno(UCL)
## Background
MPPI（路径积分控制）是一种强大的基于采样的方法，适用于复杂的机器人任务，因为它可以在处理非线性动力学和非凸成本方面具有灵活性。然而，因其在实时、高频机器人控制场景中的计算需求限制了其应用范围。本文旨在通过提出一种新颖的框架F-MPPI，来解决这一问题。F-MPPI通过标准MPPI的基础上计算局部线性反馈增益，这些增益来源于由 Riccati 反馈启发的敏感性分析，无需每一步都进行完整的重新优化，就能实现快速的闭环纠正。
## Innovation
F-MPPI通过结合标准MPPI和局部线性反馈增益，提出了一个新颖的框架。局部线性反馈增益由敏感性分析确定，类似于基于梯度的MPC使用的Riccati反馈。这样的设计允许在当前状态下快速进行闭环纠正，而不需要在每个时间步骤重新优化，从而在保证控制性能和稳定性的同时，提升了计算效率。
## Conclusion
通过在两种机器人平台上进行的仿真和实际实验，F-MPPI验证了其在动态行走和激进飞行等复杂操作中的优越性。结果表明，引入局部反馈显著提高了控制性能和稳定性，使得可以在复杂机器人系统中实现可靠的高频操作。
# 48. `cs.AI` - Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction [PDF](https://arxiv.org/pdf/2506.14856), [HTML](https://arxiv.org/abs/2506.14856)
## Authors
Zhengquan Zhang,Feng Xu,Mengmi Zhang
## Background
在三维物体重建中，不同的视角提供的信息量不同。AI系统需要能确定哪个视角提供的信息最有价值，以便准确且高效地重建3D物体。传统的主动视图选择（AVS）方法通常涉及学习辐射场或3D高斯点云，然后计算每个候选视角的不确定性。然而，这些方法通常需要大量的计算资源，尤其是在选择最有效的视角方面。因此，如何有效地选择最少的视角来获得最准确的重建，成为计算机视觉领域的一个基本挑战。
## Innovation
本文提出了一种新颖的主动视图选择（AVS）方法，利用轻量级的前馈深度神经网络（UPNet）预测神经不确定性地图。UPNet接受一个输入的3D物体图像，并输出一个表示所有可能候选视角不确定性值的预测不确定性图。通过利用观察到的许多自然物体及其关联不确定性模式的启发式方法，UPNet被训练学习从视角视觉特征直接映射到潜在体素表示中的不确定性。这一方法聚集了所有先前预测的神经不确定性图，从而抑制冗余候选视角并有效选择最有信息性的视角。此外，通过这些选定的视角进行3D神经渲染模型的训练，并与其他竞争性AVS方法评估新颖视图合成的质量。实验结果表明，尽管使用了上界的一半视角，本文的方法仍能达到相近的重建精度，且显著减少了主动视图选择过程中的计算开销，同时在CPU、RAM和GPU使用上也减少了50%以上。本文的方法在新类别物体的AVS任务上也表现出良好的泛化能力。
## Conclusion
本文提出了一种新的轻量级AVS方法UPNet，通过预测神经不确定性地图来有效选择最有信息性的视角，不仅提高了重建的准确性和效率，还在实际应用中展现出良好的泛化能力。
# 49. `cs.AI` - BMFM-RNA: 一个构建和评估转录组基础模型的开源框架 [PDF](https://arxiv.org/pdf/2506.14861), [HTML](https://arxiv.org/abs/2506.14861)
## Authors
Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou
## Background
转录组基础模型（TFMs）已经作为一种强大的工具出现，用于分析细胞和组织中的基因表达，支持细胞类型注释、批处理校正和扰动预测等关键任务。然而，最近TFMs在模型实现和训练策略上的多样性带来了挑战，使得难以分离出每个设计选择的贡献或评估它们的潜在协同效应，这阻碍了领域内最佳实践的达成，并限制了研究成果的可复现性。本研究介绍了一种开源模块化软件包BMFM-RNA，统一了多种TFM的预训练和微调目标，在单一框架内提供了一个综合性的解决方案。
## Innovation
BMFM-RNA 提供了一个统一框架，整合了多种TFM的预训练和微调目标，并引入了一个新的训练目标——整个细胞表达解码器（WCED），该目标使用类似于自编码器的 CLS 瓶颈表示法捕捉全局表达模式。通过BMFM-RNA进行基准测试表明，基于WCED的模型在多个数据集上的零样本和微调任务中，其性能与最新的方法（如scGPT）相当或超越。
## Conclusion
BMFM-RNA 作为一个开放源代码项目的一部分，为系统基准测试和社区驱动的最佳TFM训练策略探索提供了可复现的基础，推动了利用最新人工智能技术理解细胞生物学的有效工具的发展。
# 50. `cs.AI` - 时间序列摘要因果图中的共同后门集识别 [PDF](https://arxiv.org/pdf/2506.14862), [HTML](https://arxiv.org/abs/2506.14862)
## Authors
Clément Yvernes,Charles K. Assaad,Emilie Devijver,Eric Gaussier
## Background
干预的可识别性问题旨在评估是否可以使用do-free公式表示某些给定干预的总体效果，从而仅通过观察数据即可进行计算。本文将探讨这一问题，在只能获取时间序列真正的因果图的简略抽象形式（即摘要因果图）的情况下，考虑了多个干预和多个效果的情况。特别关注于通过公共后门集的识别性，并在时间和时间不一致的情况下建立了此类集合存在的条件。文章还提供了决定问题是否可识别的复杂性有限的算法。
## Innovation
研究了在只有摘要因果图的情况下，时间序列中的共同后门集的识别性问题，并给出了存在性的条件。在此基础上，提供了决定该问题是否可识别的复杂性有限的算法，兼顾考虑了时间和时间不一致这两种情况。
## Conclusion
通过建立时间序列中共同后门集存在的条件以及提供识别该问题的有限复杂度算法，解决了仅在摘要因果图条件下，多个干预和多个效果的可识别性问题，为处理实际动态系统中观测数据的因果推断问题提供了新的方法和思路。
# 51. `cs.AI` - 智能爆炸的准备 [PDF](https://arxiv.org/pdf/2506.14863), [HTML](https://arxiv.org/abs/2506.14863)
## Authors
William MacAskill,Fin Moorhouse
## Background
人工智能可以加速科研进程，甚至在短短几年内推动一个世纪的技术进步。在此期间，新技术或政治的发展将迅速提出重要的、难以逆转的决策。这些挑战被称为‘重大挑战’，它们包括大规模毁灭性武器、依靠人工智能的极权政治、争夺太空资源的竞争，以及值得道德考虑的数字生命，同时也带来了大幅改善生活质量及集体决策的机会。文章指出这些挑战不能总是留给未来的AI系统处理，而我们应该从现在开始采取措施，以提高应对智能爆炸带来的巨大变革的能力。
## Innovation
论文强调了智能爆炸时代的紧迫性和挑战，提出了不仅要确保先进AI系统与人类目标一致，而且要有效应对快速发展的技术创新带来的各种复杂挑战。
## Conclusion
文章认为，应当从现在开始为智力爆炸做准备，这种准备不仅涉及到确保先进AI系统与人类目标一致的问题，还涉及到如何有效应对智能爆炸可能带来的复杂和广泛的变化。
# 52. `cs.AI` - PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning [PDF](https://arxiv.org/pdf/2506.14907), [HTML](https://arxiv.org/abs/2506.14907)
## Authors
Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong
## Background
近期，基于深度学习的方法如DeepSeek-R1展示了出色的推理能力，研究开始探索利用强化学习（RL）增强多模态视觉-语言模型（VLMs），以应对跨图像的复杂多模态推理任务。然而，绝大多数多模态强化学习方法仍在单图空间推理中受限，难以适应更大范围的真实世界场景，尤其是在需要理解跨图关系的多图像位置推理中表现不佳。
## Innovation
为解决该挑战，该研究提出了一种名为PeRL的多模态任务强化学习方法，强调模拟图像序列的排列以探索更多样化的空间关系，设计了回退重采样的策略来聚焦具有最大学习贡献的轨迹，从而提高探索与利用的平衡，提高学习效率和任务性能。
## Conclusion
实验表明，采用PeRL训练的模型在多图像基准测试中显著超越了多个基线模型（包括R1相关的和交错的VLMs），取得了最先进的性能，在单图像任务上也保持了相近的表现。
# 53. `cs.AI` - 使用面部照片进行健康识别的基础人工智能模型（FAHR-Face） [PDF](https://arxiv.org/pdf/2506.14909), [HTML](https://arxiv.org/abs/2506.14909)
## Authors
Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak
## Background
面部表情提供了非侵入性的健康窗口。本文构建了FAHR-Face，一种基础模型，训练于超过4000万张面部图像，并针对两个不同任务进行了微调：生物学年龄估计（FAHR-FaceAge）和生存风险预测（FAHR-FaceSurvival）.
## Innovation
1. 构建了一个基础模型FAHR-Face，用于生物学年龄估计和生存风险预测。
2. 通过两阶段、年龄平衡的微调改进了FAHR-FaceAge，展示了出色的准确性和鲁棒性。
3. FAHR-FaceSurvival显示了对死亡的稳健预测能力，最髙风险四分位数的死亡率是最低四分位数的三倍以上（调整后的危险比3.22，P<0.001）。
4. 两种算法提供了互补的预后信息，结合使用提高了预后准确性。模型具备较小临床数据集的有效训练能力，且具有年龄、性别和种族等分组的一般化能力.
## Conclusion
一个基础模型能够生成经济且适用广泛的面部生物标志物，结合生物学老龄化和疾病相关的死亡风险，并能有效地用较小的临床数据集进行训练。
# 54. `cs.AI` - 使用深度学习预测地层诱发微地震的时空演变 [PDF](https://arxiv.org/pdf/2506.14923), [HTML](https://arxiv.org/abs/2506.14923)
## Authors
Jaehong Chung,Michael Manga,Timothy Kneafsey,Tapan Mukerji,Mengsu Hu
## Background
微地震（MEQs）由地下流体注入产生，能够记录地下应力状态和渗透率的变化。对于如增强地热系统（EGS）、二氧化碳封存以及其他地质工程应用来说，预测MEQs的时空演变至关重要。因此，开发一种能够准确预测MEQs时空演变的模型有助于实时推断裂隙扩展和渗透率演变，对提高地震风险评估并指导未来注入操作的缓解策略具有重要意义。
## Innovation
本文提出了一种基于变压器的深度学习模型，该模型能够整合之前的流体刺激历史和微地震观测数据，预测累计微地震数量、累积对数地震矩以及50%和95%分位数空间范围。模型在EGS联盟实验1数据集上的表现体现出高度准确（1秒预报时$R^2 >0.98$，15秒预报时$R^2 >0.88$）且具有不确定性估计功能。
## Conclusion
这些准确并具有不确定性量化能力的预测能够实现实时推断裂隙扩展和渗透率演变，表明深度学习方法在改进地震风险评估和指导未来注入操作的缓解策略方面具有强大潜力。
# 55. `cs.AI` - MDBench：一种使用知识指导生成的合成多文档推理基准 [PDF](https://arxiv.org/pdf/2506.14927), [HTML](https://arxiv.org/abs/2506.14927)
## Authors
Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang
## Background
自然语言处理评估取得了显著进步，主要是由于强大大型语言模型（LLMs）的广泛使用。随着LLMs处理长上下文输入的推理能力迅速扩展，新的评估基准变得越来越重要。然而，由于多文档推理（MD）设置下长输入标注成本高昂，很少有基准能系统地测试模型在这一环境下的表现，这是一个棘手的基准创建问题，尤其是MD推理能力在LLMs中至关重要。
## Innovation
本文介绍了一种新的数据集MDBench，用于评估LLMs的多文档推理任务。该数据集通过一种新颖的合成生成过程创建，允许存在有控制地和高效地生成具有挑战性的文档集及其对应的问答（QA）示例的技术。这种方法基于压缩结构化种子知识，通过LLM辅助编辑生成MD特定的推理挑战，并将这种结构化知识转化为自然文本表面形式，生成文档集及其对应的QA示例。这种方法应用在流行的LLMs和提示技术上，表明MDBENCH为所有方法提出了重大挑战。此外，该知识导向生成技术可以有效地进行针对性分析，快速适应新挑战和未来模型改进。
## Conclusion
我们分析了流行的LLMs和提示技术的行为，发现即使在较短的文档集中，MDBENCH也对其提出了重大挑战。此外，我们的知识导向生成技术不仅能够迅速进行针对性分析，还可以快速适应新的挑战和未来的建模改进。
# 56. `cs.AI` - 先解释，再信任：基于图的加密异常检测的LLM增强解释 [PDF](https://arxiv.org/pdf/2506.14933), [HTML](https://arxiv.org/abs/2506.14933)
## Authors
Adriana Watson
## Background
去中心化金融(DeFi)社区在过去几年中快速增长，这是由对新兴市场巨大潜力感兴趣的加密货币爱好者推动的。加密货币的流行带动了金融犯罪的新时代。然而，新技术的新兴使得追踪和起诉犯罪者变得尤为棘手。因此，有必要实施与政策相关的自动化检测工具，以应对加密领域日益严重的犯罪问题。
## Innovation
该论文提出了一种基于图的加密异常检测方法，并结合了LLM（大型语言模型）来增强解释能力，以帮助用户更好地理解和信任检测结果。这种方法旨在通过提供清晰、针对性的解释来提高用户对检测技术的信任度。
## Conclusion
通过将LLM增强的解释集成到图基加密异常检测系统中，该研究提出的方法能够为用户提供详细的、可解释的检测结果，从而有效提升用户对DeFi平台的安全性和透明性的信心。
# 57. `cs.AI` - 利用自动编码器在计算机网络中自动确定攻击检测阈值 [PDF](https://arxiv.org/pdf/2506.14937), [HTML](https://arxiv.org/abs/2506.14937)
## Authors
Luan Gonçalves Miranda,Pedro Ivo da Cruz,Murilo Bellezoni Loiola
## Background
目前，使用自动编码器（AE）的异常检测系统在解决数据固有的问题（如数据不平衡）方面表现出巨大潜力。然而，由于AE使用一个非标准且难以确定的重构误差分类阈值，这一阈值的定义直接关系到检测过程的表现。因此，本文提出了一种使用机器学习算法自动确定这一阈值的方法，以克服这一问题.
## Innovation
本文评估了三种机器学习算法（K-最近邻、K-均值和支持向量机），以自动确定AE在攻击检测中的分离阈值。这提供了一种新的方法来提高基于AE的异常检测系统的性能和鲁棒性.
## Conclusion
研究评估了三种机器学习算法来自动确定自动编码器在异常检测中的分类阈值，能够提升检测系统的性能和可靠性。
# 58. `cs.AI` - 神经网络损失景观中的无限平坦通道 [PDF](https://arxiv.org/pdf/2506.14951), [HTML](https://arxiv.org/abs/2506.14951)
## Authors
Flavio Martinelli,Alexander Van Meegen,Berfin Şimşek,Wulfram Gerstner,Johanni Brea
## Background
神经网络的损失景观中存在局部极小值和鞍点，这些极小值和鞍点可能在平坦区域相连或孤立存在。本文旨在发现和描述损失景观中的一个特殊结构：沿这些通道损失变化极为缓慢，同时至少有两个神经元$a_i$和$a_j$的输出权重趋向于$\pm$无穷大，其输入权重向量$oldsymbol{w_i}$和$oldsymbol{w_j}$变得相等。在收敛时，这两个神经元实现了门控线性单元：$a_ioldsymbol{ightarrow}oldsymbol{w_i} oldsymbol{ullet} oldsymbol{x} + a_joldsymbol{ightarrow}oldsymbol{w_j} oldsymbol{ullet} oldsymbol{x} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} (oldsymbol{v} oldsymbol{ullet} oldsymbol{x}) oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} oldsymbol{ightarrow} \sigma(\boldsymbol{w} \boldsymbol{ullet} \boldsymbol{x}) + (\boldsymbol{v} \boldsymbol{ullet} \boldsymbol{x}) \boldsymbol{ightarrow} \boldsymbol{ightarrow} \boldsymbol{ightarrow} \sigma'(\boldsymbol{w} \boldsymbol{ullet} \boldsymbol{x})$。从几何上讲，这些通往无穷的通道远近平行于由对称性诱导的临界点线。梯度流求解器，以及相关的优化方法如SGD或ADAM，在不同的回归场景中以高概率到达这些通道，但如果不仔细检查，它们看起来像是具有有限参数值的平坦局部极小值。我们的性质为这些准平坦区域提供了从梯度动力学、几何学和功能解释方面来说的全面描述。通道尽头出现的门控线性单元突显了全连接层计算能力的一个令人惊讶方面。
## Innovation
我们发现了一种特殊结构：沿这些通道损失变化极为缓慢，同时至少有两个神经元$a_i$和$a_j$的输出权重趋向于$\pm$无穷大，其输入权重向量$oldsymbol{w_i}$和$oldsymbol{w_j}$变得相等。在收敛时，这些神经元实现了门控线性单元，这些通道由梯度流求解器和其他优化方法（如SGD或ADAM）以高概率到达，但如果不仔细检查，它们看起来像是具有有限参数值的平坦局部极小值。我们的理论提供了这些准平坦区域的全面描述，包括它们的梯度动力学、几何特征和功能解释。这种现象揭示了全连接层在计算上的一个有趣方面：即在损失曲面的无穷通道尽头，会出现门控线性单元。这一发现对于理解梯度训练动态具有重要意义，并为深度学习中的优化问题提供了新的视角。
## Conclusion
本文描述了一种特殊的损失景观结构——‘无限平坦通道’，它揭示了一种令人惊讶的计算能力，即全连接层在损失曲面的无穷通道尽头，会呈现出门控线性单元的特性。这一发现不仅加深了我们对神经网络训练动态的理解，还为优化策略的设计提供了新的视角。
# 59. `cs.AI` - 从跨领域视角重访大语言模型推理中的强化学习 [PDF](https://arxiv.org/pdf/2506.14965), [HTML](https://arxiv.org/abs/2506.14965)
## Authors
Zhoujun Cheng,Shibo Hao,Tianyang Liu,Fan Zhou,Yutao Xie,Feng Yao,Yuexin Bian,Yonghao Zhuang,Nilabjo Dey,Yuheng Zha,Yi Gu,Kun Zhou,Yuqi Wang,Yuan Li,Richard Fan,Jianshu She,Chengqian Gao,Abulhair Saparov,Haonan Li,Taylor W. Killian,Mikhail Yurochkin,Zhengzhong Liu,Eric P. Xing,Zhiting Hu
## Background
由于大多数开放努力集中在数学和代码领域，导致对大语言模型（LLM）广泛推理能力的理解局限。一个主要挑战是缺乏可靠和可扩展的强化学习奖励信号，这阻碍了其在不同推理领域的应用。因此，需要一个高质量和多样化的大规模数据集来促进研究并观察不同领域的差异。研究者们努力构建出覆盖多种领域的高质量数据集，如数学、代码、科学、逻辑、仿真和表格数据。这些数据涵盖了多个推理领域，为训练提供了一个广泛的、可靠的奖励信号基线，从而探讨了强化学习在大语言模型推理中的应用效果和跨领域学习特性。
## Innovation
该研究引入了Guru，这是一个精心设计的强化学习推理数据集，包含92000个verifiable示例，涵盖了六个领域：数学、代码、科学、逻辑、仿真和表格。通过领域特定的奖励设计、去重和过滤以确保数据集的可靠性和有效性。研究基于Guru系统性地回顾了强化学习在大语言模型推理中的现有发现，并观察到不同领域的显著差异。还提出了Guru-7B和Guru-32B这两个模型，它们在跨领域强化学习中表现出色，尤其是在复杂任务上，通过公开数据实现了最先进的性能，比基线高出7.9%和6.7%。此外，还展示了这些模型可以显著提高基模型的Pass@k性能，尤其在不容易在预训练数据中出现的复杂任务上。
## Conclusion
该研究强调了跨领域学习在大语言模型推理中的重要性，发现某些领域通过跨领域训练可以取得更好的表现，而有些领域则需要在领域内进行训练以取得显著的性能提升。最终，研究者发布了Guru数据集、预训练和评估代码，以促进通用推理研究的发展。
# 60. `cs.AI` - FEAST: 一个灵活的餐饮辅助系统，向着野外个性化 [PDF](https://arxiv.org/pdf/2506.14968), [HTML](https://arxiv.org/abs/2506.14968)
## Authors
Rajat Kumar Jenamani,Tom Silver,Ben Dodson,Shiqin Tong,Anthony Song,Yuting Yang,Ziang Liu,Benjamin Howe,Aimee Whitneck,Tapomayukh Bhattacharjee
## Background
全球有数百万人需要他人协助进食，这给家庭餐饮辅助带来了挑战。这些挑战包括多样化的行为活动（如进食、喝水、擦嘴）、环境（如社交、看电视）、食物种类以及用户的个人偏好。现有的餐饮辅助机器人在家庭环境中难以适应这些多样性和复杂性。因此，需要一个灵活的餐饮辅助系统，能够在实际使用中进行个性化定制，以满足不同护理接收者的独特需求。
## Innovation
本文提出了一款名为FEAST的餐饮辅助系统，该系统可以通过在实际使用中进行个性化定制来满足个体护理接收者的独特需求。FEAST的创新之处在于：（1）模块化的硬件设计，可以根据需要切换辅助进食、饮水和擦嘴模式；（2）多样化的交互方式，包括网页界面、头部手势和物理按钮，以适应不同功能能力和偏好；（3）参数化的行为树，可以通过大型语言模型安全透明地进行调整。
## Conclusion
通过实证研究，FEAST展示了广泛的安全透明的定制选项，并优于仅限于固定个性化选项的最先进的基线系统。在家中的用户研究结果表明，FEAST能够被成功地个性化，以满足不同护理接收者的个人需求和偏好。
# 61. `cs.AI` - 思考方向性：多说话者方向性语音识别的大语言模型 [PDF](https://arxiv.org/pdf/2506.14973), [HTML](https://arxiv.org/abs/2506.14973)
## Authors
Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze
## Background
近期的研究表明，通过给大型语言模型（LLM）提供音频编码能够增强其有效的语音识别能力。然而，关于语音大语言模型在理解具有空间提示的多通道音频方面的能力还相对未被研究。
## Innovation
本文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜上的麦克风阵列实现定向语音识别、声源定位以及旁谈抑制。为了增强模型的理解直接性能力，提出了两个关键技术：序列化方向输出训练（S-DOT）和对比方向数据增强（CDDA）。实验结果显示，提出的directional-SpeechLlama有效地捕捉了文本提示与空间音频之间的关系，其在语音识别和声源定位任务中的表现均很强劲。
## Conclusion
本文通过引入方向-SpeechLlama模型，有效提升了语音大模型在多说话者环境中的定向语音识别能力，并在实际应用场景中表现优异。
# 62. `cs.AI` - 使用探查的公平多代理多臂老虎机算法 [PDF](https://arxiv.org/pdf/2506.14988), [HTML](https://arxiv.org/abs/2506.14988)
## Authors
Tianyi Xu,Jiaxin Liu,Zizhan Zheng
## Background
在多代理环境中，确保公平结果的同时最大化系统整体性能是一个重要的挑战。特别是在奖励信息有限的情况下，如何高效地决定如何分配资源是非常关键的问题。现有的方法往往难以同时满足公平性和系统性能的要求。本文旨在提出一个多代理多臂老虎机（MA-MAB）框架，该框架在有限的奖励信息下，通过一种新颖的探查框架智能地收集关于选定臂的信息，以此来解决决策问题。研究成果应用离线和在线场景，并通过实验证明了该方法相比基线方法的优越性。
## Innovation
文章提出了一种新颖的探查框架，用于多代理环境下的多臂老虎机问题。在离线场景中，利用亚模性设计了一个贪婪的探查算法，保障了算法性能；在线场景则提出了一种能够同时保持公平性并实现亚线性后悔率的算法。实验证明了该方法在公平性和效率方面的优势。
## Conclusion
本文提出的方法在多代理多臂老虎机环境中，通过有效探查机制，保障了公平结果的同时优化了系统性能。实验结果表明与基线方法相比，该方法在公平性和效率上表现出色。
# 63. `cs.AI` - 使用时间卷积网络模型提高梯度轨迹误差校正的图像重建和扩散参数估计 [PDF](https://arxiv.org/pdf/2506.14995), [HTML](https://arxiv.org/abs/2506.14995)
## Authors
Jonathan B. Martin,Hannah E. Alderson,John C. Gore,Mark D. Does,Kevin D. Harkins
## Background
在非笛卡尔成像序列中，梯度轨迹中的错误引入了显著的伪影和图像扭曲，尤其是在磁共振成像中。不当的梯度波形会严重影响图像质量。传统方法通常采用线性模型，但它们可能无法准确预测梯度系统的非线性畸变。因此，现有方法在这方面存在局限性，无法有效解决图像质量下降的问题。现有的梯度误差校正方法主要依赖于梯度脉冲响应函数，但这不能全面解决复杂的非线性受影响问题。
## Innovation
本研究提出了一种通用非线性梯度系统模型，通过使用卷积网络模型更精确地预测梯度畸变。利用小型动物成像系统的测量梯度波形，训练了一个时间卷积神经网络来预测成像系统的梯度波形。与传统的线性方法相比，这种方法能更准确地模拟梯度系统的非线性行为，并能够通过网络预测的梯度波形改进图像重建的过程和扩散参数映射。这表明时间卷积网络可以替代现有的线性模型，提高成像质量并实现图像的后处理校正，确保更准确的影像重建和参数估计.
## Conclusion
时间卷积网络能够比现有的线性方法更准确地建模梯度系统的非线性行为，并可用于回顾性地纠正梯度错误。这种方法能提高图像质量和扩散参数映射精度。
# 64. `cs.AI` - 记忆令牌：大型语言模型可以生成可逆的句子嵌入 [PDF](https://arxiv.org/pdf/2506.15001), [HTML](https://arxiv.org/abs/2506.15001)
## Authors
Ignacio Sastre,Aiala Rosá
## Background
该研究观察到了一个有趣的现象，即可以生成可逆的句子嵌入，使LLM能够在不修改模型权重的情况下精确重建原始文本。这通过引入一个特殊的记忆令牌实现，该令牌的嵌入通过在固定序列上训练进行优化。当模型接收到这个嵌入时，它可以精确地重现固定的序列。研究在英语和西班牙语数据集、最多约240个标记的序列以及从1亿到80亿参数的不同模型规模上进行了评估。结果显示，Llama 3.1 8B成功重建了所有测试的序列。研究发现强调了LLMs的一个有趣的能力，并建议它们在基于记忆的检索、压缩和受控文本生成等方面的应用是潜在的。
## Innovation
通过引入特殊记忆令牌并在固定序列上优化其嵌入，实现不修改模型权重的情况下生成可逆的句子嵌入，使得大型语言模型能够精确重建原始文本。研究展示了不同大小模型的这种能力，并且特定的Llama 3.1 8B模型表现尤为出色。这为基于记忆的检索、压缩和受控文本生成提供了新的可能性。
## Conclusion
研究发现大型语言模型具有这种新的能力，并且这一发现对语言模型的应用产生深远影响，尤其是在需要精确记忆和检索信息的场景中显得尤为重要。
# 65. `cs.AI` - 扩展智能：设计面向下一代语言模型的数据中心 [PDF](https://arxiv.org/pdf/2506.15006), [HTML](https://arxiv.org/abs/2506.15006)
## Authors
Jesmin Jahan Tithi,Hanjiang Wu,Avishaii Abuhatzera,Fabrizio Petrini
## Background
大语言模型（LLMs）如具有1.8万亿参数的GPT-4的迅猛增长，要求对数据中心架构进行根本性重新思考，以确保可伸缩性、效率和成本效益。随着LLMs规模的扩大，现有的数据中心架构已无法满足其高性能需求，需要全新的设计来支持大规模模型的运行。
## Innovation
该研究提出了一套全面的协同设计框架，该框架联合探索了FLOPS、HBM带宽和容量、多种网络拓扑（两层式与全平面光路）、扩展域规模以及LLMs广泛使用的并行优化策略。研究引入了并评估了全平面网络架构，这些架构在所有节点间提供均匀的高带宽、低延迟连接，并展示了其对性能和可扩展性的强大影响。通过详细敏感性分析，研究量化了计算和通信重叠、硬件加速的集计机制、更大的扩展域和更大内存容量等带来的益处。研究涵盖稀疏（模型专家混合）和密集变换架构的LLMs，揭示了系统设计方案如何影响模型FLOPS利用率（MFU）和总体吞吐量。为此，研究还扩展并验证了一种能够精准预测LLM运行时间的性能建模工具，误差范围在10%以内。
## Conclusion
研究的发现为设计能够高效支持万亿参数模型、降低优化复杂度并持续支撑AI能力快速演进的AI数据中心提供了可操作的见解和实用的道路图。
# 66. `cs.AI` - 基于真实数据的指导性生成AI设计：图文输出中纳入现实世界数据 [PDF](https://arxiv.org/pdf/2506.15008), [HTML](https://arxiv.org/abs/2506.15008)
## Authors
Richa Gupta,Alexander Htet Kyaw
## Background
生成式AI特别是文本到图像模型，已经在室内建筑设计中取得了革命性的发展，能够通过简单的文本提示快速将概念设计转化为视觉呈现。尽管生成式AI能够产生视觉上吸引人的图像，它们通常缺少具体的设计数据，这对设计师而言是有限的。因此，研究者提出了一种新型的集成管道，通过将DALL-E 3与材料数据库结合，为AI生成的设计成果增加可持续性指标和材料使用洞察。该模型生成内部设计图像后，后续模块识别出前十种存在的材料并与一般材料字典中的二氧化碳当量(CO2e)值相匹配。这种方法使设计师能够立即评估环境影响并调整提示。研究通过三个用户测试评估了系统：（1）在使用生成式AI前不提及可持续性；（2）在给出提示前告知用户可持续性目标；（3）在生成式AI的输出中包含定量的CO2e 数据。定量和定性的分析表明，引入可持续性指标在第三个测试中产生了更明智的设计决策，但也可能导致决策疲劳并降低总体满意度。然而，在大多数参与者报告在第三个测试中将可持续性原则融入工作流程，表明集成指标在引导更生态负责任的实践中的潜力。研究发现强调了在设计自由与实际约束之间取得平衡的重要性，为AI辅助建筑设计中的整体、数据驱动解决方案指明了路径
## Innovation
提出了一种新型管道，通过将DALL-E 3与材料数据库结合，为AI生成的设计成果增加可持续性指标和材料使用洞察。该系统在生成图像后，通过识别出的前十种存在的材料及其CO2e值，帮助设计师评估环境影响并调整提示，从而引导更生态责任的设计路径。
## Conclusion
研究结果表明，在生成式AI中引入可持续性指标虽提高了用户在设计中的决策质量，但也导致了一些决策疲劳。然而，大多数参与者在第三个测试中仍表示将可持续性原则整合到了自己的工作流程，这展示了综合数据指标在指导生态设计方面的潜力。研究指出，在设计自由与实际限制之间取得平衡对于实现全面、数据驱动的AI辅助设计解决方案至关重要。
# 67. `cs.AI` - 稳定的CDE自编码器结合急性指数正则化在脓毒症治疗中的离线强化学习 [PDF](https://arxiv.org/pdf/2506.15019), [HTML](https://arxiv.org/abs/2506.15019)
## Authors
Yue Gao
## Background
有效的强化学习(RL)方法在脓毒症治疗中依赖于能够从ICU不规则的时序数据中学习稳定且具有临床意义的状态表示。尽管先前的研究已经探索了对这种任务进行表示学习的方法，但训练不稳定性及其对策略性能的负面影响仍没有被充分关注。本文探讨了通过确保训练稳定性和实施急性指数正则化来使用CDE自编码器实现强健的RL策略的方法。
## Innovation
本文提出了一种结合受控微分方程(CDE)和急性指数(如SOFA, SAPS-II, OASIS)正则化的自编码器方法，通过这一方法，确保训练的稳定性并通过急性指数正则化来提升RL策略的性能。实验结果显示，稳定的CDE自编码器能够生成与急性指数高度相关的状态表示，从而提高了RL策略的表现。
## Conclusion
研究表明，通过CDE自编码器和急性指数正则化的结合能够在脓毒症治疗的RL任务中提供稳定的性能表现，并强调了在顺序表示学习中确保训练稳定性的必要性。
# 68. `cs.AI` - SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models [PDF](https://arxiv.org/pdf/2506.15021), [HTML](https://arxiv.org/abs/2506.15021)
## Authors
Gyuhak Kim,Sumiran Singh Thakur,Su Min Park,Wei Wei,Yujia Bao
## Background
监督微调（SFT）已成为将大型语言模型（LLMs）调整为符合人类期望和特定下游任务的必要步骤。然而，现有SFT方法通常将每个训练实例视为统一序列，给予所有标记相同的重要性，而不考虑它们的相关性。这忽视了只有少数标记通常包含关键的、任务特定的信息这一事实。
## Innovation
本文提出了一种名为SFT-GO的新颖方法，它基于标记的重要性值对样本中的标记进行分组，并使用最差分组损失和标准交叉熵损失的加权组合来优化LLM。这种方法自适应地强调最具挑战性的标记分组，并引导模型更好地处理不同的分组分布，从而改善整体学习动态。我们通过理论分析证明了SFT-GO的收敛速度，并通过实验证明了SFT-GO在三个不同分组策略下的模型在流行LLM基准测试中的表现优于基线方法，这些改进在各种数据集和基础模型上均成立，展示了方法的稳健性和有效性。
## Conclusion
SFT-GO通过不同对待标记组的方式来改善大型语言模型的监督微调，这一机制能够自适应地强调最难的标记组，并指导模型更好地处理不同的分组分布，从而提升学习效率和效果。研究结果证明了SFT-GO在不同任务和模型上的优越性能，表明该方法具有广泛的适用性和良好的效果。
# 69. `cs.AI` - 大型语言模型中嵌入学习率的优化：词汇表大小的影响 [PDF](https://arxiv.org/pdf/2506.15025), [HTML](https://arxiv.org/abs/2506.15025)
## Authors
Soufiane Hayou,Liyuan Liu
## Background
预训练大型语言模型是一个成本高昂的过程。为了提高这一过程的效率，已经提出了许多优化模型架构/参数化和硬件使用的方法。在参数化方面，$	extmu P$（最大更新参数化）以一种使其超参数（HPs）在宽度（嵌入维度）扩展时可转移的方式参数化模型权重和学习率（LR）。尽管$	extmu P$在实际应用中表现出色，但在应用到大规模语言模型（LLMs）时，最近的一些实证研究表明了一些相互矛盾的结果。理论上的一个重要局限是，$	extmu P$中关于词汇表大小固定（当取宽度无限时）的假设并不现实，因为在实践中词汇表大小通常远大于宽度。
## Innovation
本文提供了词汇表大小对训练动力学影响的理论分析，表明随着词汇表的增加，训练动态从$	extmu P$区间过渡到另一个称为‘大词汇（LV）区间’的区间，且在此区间内最优的嵌入LR与隐藏LR的比率应按$	heta(	ext{宽度}^{1/2})$比例变化，这是与现有实证发现相符的，与$	extmu P$预测的$	heta(	ext{宽度})$比例不同。实验验证了理论的有效性，并展示了建议的缩放规则在预训练1亿参数模型时的好处。
## Conclusion
我们的分析揭示了LV区间内，嵌入LR与隐藏LR的最佳比率应该按$	heta(	ext{宽度}^{1/2})$比例变化，这一结果与先前文献中报告的实证发现惊人地接近，而$	extmu P$预测的结果则与此不同。我们通过实验验证了这一理论，并展示了建议的缩放规则在预训练1亿参数模型时带来的益处。
# 70. `cs.AI` - 采用CNN-LSTM-GRU架构预测超高速导弹轨迹的高级技术 [PDF](https://arxiv.org/pdf/2506.15043), [HTML](https://arxiv.org/abs/2506.15043)
## Authors
Amir Hossein Baradaran
## Background
为了确保国家的安全与稳定，国防工业的进步至关重要，能够提供抵御新型威胁的有效防护。其中，超高速导弹由于其极高的速度和灵活性，构成了重大的挑战，准确预测其轨迹对于制定有效反制措施至关重要。
## Innovation
该论文提出了一种新的混合深度学习方法，结合了卷积神经网络（CNN）、长短期记忆（LSTM）网络和门控循环单元（GRU），利用这些架构的优点，成功预测了超高速导弹的复杂轨迹，为防御策略和导弹拦截技术做出了重大贡献。
## Conclusion
这项研究展示了先进机器学习技术在增强防御系统预测能力方面的潜力。
# 71. `cs.AI` - Sequential Policy Gradient for Adaptive Hyperparameter Optimization [PDF](https://arxiv.org/pdf/2506.15051), [HTML](https://arxiv.org/abs/2506.15051)
## Authors
Zheng Li,Jerry Cheng,Huanying Helen Gu
## Background
强化学习对于神经架构搜索和超参数优化至关重要，然而传统方法由于时间和计算成本高昂，阻碍了其广泛使用。
## Innovation
借鉴DeepSeek-V3多令牌预测架构，我们提出了顺序策略梯度建模（SPG），这是一种轻量级在线超参数优化的新轨迹生成范式。SPG通过在基础模型中添加临时模块，使其能够在单次前向传递中生成带有补零的状态-动作轨迹，相较于传统策略梯度方法，SPG具有更低的计算成本且优化效果更佳。
## Conclusion
实验表明，使用SPG重新训练的模型在原始数据集上获得了性能提升，并且在五个涉及计算机视觉、自然语言处理和音频的数据集上优于标准迁移微调，SPG在广泛使用的模型上取得了2%到7%的性能提升，且计算成本显著降低。我们提供了完全可复现的代码和预训练模型。
# 72. `cs.AI` - 通过话语对话文本澄清改善对话话语解析 [PDF](https://arxiv.org/pdf/2506.15081), [HTML](https://arxiv.org/abs/2506.15081)
## Authors
Yaxin Fan,Peifeng Li,Qiaoming Zhu
## Background
对话话语解析旨在识别和分析对话中句子之间的语篇关系。然而，对话中的语言特征，如省略和成语，经常引入歧义，使得识别意图的语篇关系变得困难，对解析器构成了重大挑战。

## Innovation
提出了一个名为话语感知澄清模块（DCM）的新方法来增强对话话语解析器的性能。DCM采用两种不同的推理过程：澄清类型推理和语篇目标推理。前者分析语言特征，后者从混淆的语篇关系中区分意图的语篇关系。此外，还引入了贡献感知偏好优化（CPO）来减轻错误澄清带来的风险，从而减少级联错误。CPO使解析器能够评估DCM澄清的贡献并提供反馈以优化DCM，从而增强其适应性和与解析器需求的对齐。

## Conclusion
在STAC和Molweni数据集上的广泛实验表明，我们的方法有效解决了歧义并显著优于当前最先进的基线。

# 73. `cs.AI` - 在推荐系统中推进损失函数：基于Rényi 散度的解决方案的比较研究 [PDF](https://arxiv.org/pdf/2506.15120), [HTML](https://arxiv.org/abs/2506.15120)
## Authors
Shengjia Zhang,Jiawei Chen,Changdong Li,Sheng Zhou,Qihao Shi,Yan Feng,Chun Chen,Can Wang
## Background
在推荐模型优化中，损失函数起着关键作用。Softmax Loss (SL) 和 Cosine Contrastive Loss (CCL) 是特别有效的两种损失函数，但它们之间的理论联系和差异需要进一步探究。已有研究表明，这两种损失函数均可以通过分布鲁棒优化（DRO）增强模型的鲁棒性，但SL和CCL在使用不同的分布距离度量进行DRO优化时，呈现出不同的优缺点：SL对假负样本高度敏感，而CCL的数据利用效率较低。为了克服这些局限性，本文提出了一种新的损失函数DrRL，通过在DRO优化中使用Rényi 散度统一SL和CCL的特点，旨在提高推荐模型的准确性和鲁棒性。
## Innovation
本文创新性地提出了一种新的损失函数DrRL，它通过在DRO优化中引入Rényi 散度来综合SL和CCL的优点，解决了SL和CCL存在的局限性，增强了模型对分布变化的鲁棒性，同时提高了数据的利用率。该方法的有效性通过广泛实验得到了验证，在推荐准确性和鲁棒性上表现出优势。
## Conclusion
本文进行了对SL和CCL这两种损失函数的全面分析，提出了基于Rényi 散度的新损失函数DrRL，该函数能够有效缓解SL和CCL各自的局限性，提升了推荐模型在数据利用效率和鲁棒性方面的表现。实验结果表明该方法在推荐准确性和鲁棒性方面优于已有解决方案。
# 74. `cs.AI` - 使用LLMs在开放域对话中建模一到多性质 [PDF](https://arxiv.org/pdf/2506.15131), [HTML](https://arxiv.org/abs/2506.15131)
## Authors
Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan
## Background
开放域对话（OD）具有一个到多个（one-to-many, o2m）的特性，即对于单一对话语境存在多个合适响应。先前的研究表明，建模这一特性可以提升响应多样性，但大多数基于大型语言模型（LLMs）的对话代理未明确实现这一点。
## Innovation
本文通过分解OD生成为两项关键任务——多响应生成（Multi-Response Generation, MRG）和偏好选择（Preference-based Selection, PS），来在LLMs中建模OD的一到多性质。同时，提出了o2mDial对话数据集，用于捕捉每个对话语境的多个合理响应，并提出了新的上下文学习、指令调优策略，以及mrg评估指标，以及基于模型的ps方法。实验结果表明，应用该两阶段框架到较小的LLM可以提升响应多样性和上下文连贯性，同时提高响应质量最高90%，使其更接近大型模型的性能。
## Conclusion
在小型LLM中应用提出的两阶段框架提高了开放域对话的整体响应多样性，同时保持了上下文连贯性，响应质量提高了90%，使其性能更接近大型模型。
# 75. `cs.AI` - Thunder-Tok: 在分词韩语文本生成语言模型中最小化每词的令牌数 [PDF](https://arxiv.org/pdf/2506.15138), [HTML](https://arxiv.org/abs/2506.15138)
## Authors
Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee
## Background
介绍了Thunder-Tok，一种新的韩语分词器，旨在减少令牌繁衍而不牺牲模型性能。该方法使用基于规则的预分词方法，与韩语的语义结构相吻合，并创建了一个包含类似语义单位的种子词汇表。该算法使用分支熵选择算法，提高平均令牌长度，从而降低繁衍率，同时保留语言信息。实验结果显示，在各种下游任务中，与BPE相比，Thunder-Tok将繁衍率降低了大约10%，并且没有牺牲性能，同时提高了推理速度，说明了我们的基于语言的方法在设计生成语言模型中的高效分词器时有效且可行。
## Innovation
使用规则预分词方法和分支熵选择算法来提高平均令牌长度，从而降低繁衍率。这种方法保留了语言信息，并在降低令牌数的同时保持了较高的模型性能。
## Conclusion
Thunder-Tok是一种有效地减少令牌繁衍而不牺牲模型性能的韩语分词器。其基于语言结构的方法在提高令牌长度的同时保持了语言信息。实验表明，这种方法在不同下游任务中表现良好，比BPE提高了约10%的推理速度。
# 76. `cs.AI` - SonicVerse: 多任务学习驱动音乐特征指导的注释生成 [PDF](https://arxiv.org/pdf/2506.15154), [HTML](https://arxiv.org/abs/2506.15154)
## Authors
Anuradha Chopra,Abhinaba Roy,Dorien Herremans
## Background
详细的描述反映了音乐作品的特点，可以丰富音乐数据库，并促进音乐AI的研究。本文讨论了一个多任务音乐注释模型SonicVerse，它将注释生成与辅助音乐特征检测任务（如调检测、人声检测等）相结合，以捕捉音乐作品的低级声学细节和高级音乐属性。将音频输入投影成语言标记，同时通过专用的辅助头部检测音乐特征，这种方法生成丰富的描述，并能以链式动作生成详细的长时间音乐描述。为了训练模型，使用了一个扩展后的MusicBench数据集，包含了用MIRFLEX模块化音乐特征提取器标注的音乐特征，形成了音频、注释和音乐特征的配对数据。实验结果表明，这样结合特征可以提高生成注释的质量和细节度。
## Innovation
提出了一个投影基础架构的多任务音乐注释模型SonicVerse，该模型将音频输入投影成语言标记，同时通过专用辅助头部检测音乐特征。辅助头部的输出也被投影到语言标记中，以增强注释输入。这种方法不仅能够为短音乐片段生成丰富描述，还能链接生成详细的长时间音乐描述，通过大型语言模型实现。为了训练模型，数据集扩展为包含用MIRFLEX模块化音乐特征提取器标注的音乐特征，创造了音频、注释和音乐特征的配对数据集。
## Conclusion
实验结果显示，通过这种方式结合特征可以提高生成注释的质量和细节度。这种方法可以为音乐数据库提供丰富的描述，并推动音乐AI的研究。
# 77. `cs.AI` - LLM Agent for Hyper-Parameter Optimization [PDF](https://arxiv.org/pdf/2506.15167), [HTML](https://arxiv.org/abs/2506.15167)
## Authors
Wanzhe Wang,Jianqiu Peng,Menghao Hu,Weihuang Zhong,Tong Zhang,Shuai Wang,Yixin Zhang,Mingjie Shao,Wanli Ni
## Background
当前用于无线电图辅助无人驾驶飞行器（UAV）轨迹和通信的暖启动粒子群优化与交叉和变异算法（WS-PSO-CM）的超参数调优方法主要是基于启发式的，自动化程度低且性能不理想。因此，需要一种自动化的超参数调优方法来提高通信算法的性能。
## Innovation
设计了一个大型语言模型（LLM）代理，用于自动调优超参数，通过迭代框架和模型上下文协议（MCP）实现了这一自动化。该方法首先通过配置文件设定代理的目标，然后根据提示要求迭代调用WS-PSO-CM算法进行探索，最后自动终止循环并返回超参数集。研究表明，通过LLM代理生成的最优参数集的最低数据传输率显著高于基于人类启发式和随机生成方法的结果。
## Conclusion
实验证明，基于PSO知识和WS-PSO-CM算法背景的LLM代理可以有效找到高性能的超参数设定。
# 78. `cs.AI` - 使用深度学习分类多参数身体MRI序列 [PDF](https://arxiv.org/pdf/2506.15182), [HTML](https://arxiv.org/abs/2506.15182)
## Authors
Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers
## Background
多参数磁共振成像（mpMRI）检查包含多种序列类型，每个序列类型采用不同的成像协议，但DICOM头部信息可能会由于协议多样性和技术人员错误而出现错误。为了解决这个问题，研究人员使用深度学习方法训练了ResNet、EfficientNet和DenseNet等分类模型，以高效地分类8种不同类型的mpMRI序列，提高放射科医生的阅片效率。
## Innovation
研究使用深度学习技术，特别是DenseNet-121模型，准确地分类8种不同类型的mpMRI序列，特别是在不同数量的训练数据条件下表现出色。模型在训练数据量超过729个研究案例时，准确率达到了0.95以上，并且随着训练数据量的增加，其性能显著提升。此外，该模型在外部数据集上也表现出良好的准确性，超过80%的准确率。
## Conclusion
DenseNet-121模型在8种不同mpMRI序列的分类任务中表现出最佳的F1分数和准确性，达到了0.966和0.972。该模型在不同训练数据量下进行了测试，性能随训练数据量的增加而提高，并且在外部数据集上也表现出高准确性。
# 79. `cs.AI` - 无障碍手势驱动增强现实交互系统 [PDF](https://arxiv.org/pdf/2506.15189), [HTML](https://arxiv.org/abs/2506.15189)
## Authors
Yikan Wang
## Background
增强现实（AR）提供了沉浸式的交互体验，但由于依赖精确的输入方法，对于有运动障碍或受限灵活性的用户来说仍然是不可访问的。本研究提出了一种基于手势的交互系统，利用深度学习从穿戴式传感器和摄像头中识别手部和身体手势，从而将接口适配用户的能力。研究表明，与基础的AR系统相比，该方法能提升20%的任务完成效率并增加25%的用户满意度，从而增强AR系统的广泛性和可访问性.
## Innovation
该研究开发了一种手势识别系统，利用深度学习技术结合视觉变压器（ViTs）、时序卷积网络（TCNs）和图注意力网络（GATs）来处理手势。同时，采用联邦学习来确保用户隐私，以及通过强化学习优化用户界面的专业元素。这项工作是第一个提出将这些复杂的人工智能技术集成用于AR用户体验的无障碍系统.
## Conclusion
该研究提出的基于手势的AR系统大幅提高了对于有运动障碍用户的交互体验，提升了任务完成效率和用户满意度，同时保证了用户的隐私。此方法提高了AR系统的可访问性和广泛性，为用户提供了更加沉浸和个性化的交互体验。
# 80. `cs.AI` - 大型语言模型任务适配技术对比研究：识别可持续发展目标 [PDF](https://arxiv.org/pdf/2506.15208), [HTML](https://arxiv.org/abs/2506.15208)
## Authors
Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi
## Background
2012年，联合国提出了17项可持续发展目标（SDGs），旨在到2030年创造一个更可持续和改进的未来。然而，由于涉及的数据量庞大且复杂，跟踪这些目标的进展具有一定的困难。文本分类模型已成为这一领域的关键工具，能够自动分析来自多种来源的大规模文本数据。此外，近年来，大型语言模型（LLMs）因其在识别复杂语言模式和语义方面的能力，在许多自然语言处理任务中变得不可或缺，包括文本分类。
## Innovation
本研究分析了用于单一标签多类别文本分类任务的各类专有和开源LLMs，其中目标是识别可持续发展目标。研究还评估了任务适配技术（即上下文学习方法）的效果，包括零样本学习、少样本学习以及微调。研究结果表明，通过提示工程优化的小型模型在某些情况下可以与像OpenAI的GPT这样的大型模型表现相当。
## Conclusion
研究发现，在优化的前提下，小型模型在单标签多类别文本分类任务中可以与大型模型竞争，特别是在任务适配技术的应用上，提出了更为有效的使用方法。
# 81. `cs.AI` - Kronecker适应性中的奇异值分解用于大型语言模型 [PDF](https://arxiv.org/pdf/2506.15251), [HTML](https://arxiv.org/abs/2506.15251)
## Authors
Yee Hin Chong,Peng Qu
## Background
大型预训练Transformer模型在各种语言和推理任务中实现了最先进的结果，但全量微调会导致存储、内存和计算成本显著上升。参数高效微调（PEFT）方法通过仅学习少量任务特定参数来减轻这些成本，但现有方法要么引入推理延迟（适配模块），要么从不利的收敛性或依赖于固定且可能与任务复杂性不匹配的秩选择中受到困扰（Kronecker基分解）.
## Innovation
本文提出了SoKA（Kronecker适应性中的SVD），一种新颖的PEFT策略，结合了Kronecker张量分解和SVD驱动的初始化以及基于谱的动态秩选择。KPSVD过程提取完整权重更新的主要成分，并将其转换为紧凑的Kronecker因子，同时自适应秩选择算法使用能量阈值和肘点标准来消除无用成分。实验结果表明，SoKA只需要0.99M可训练参数，比LoRA/PiSSA少25%，同时匹配或超越基线性能。此外，SoKA表现出更快的收敛性和更稳定的梯度，突显了其在大规模模型调整中的稳健性和效率.
## Conclusion
SoKA仅需少量可训练参数，就能实现大规模模型的有效适应，同时在性能上不低于甚至优于现有方法，并且具有更快速的收敛性和更好的稳定梯度，证明其在大规模模型调整中的高效性和稳健性.
# 82. `cs.AI` - RAS-Eval: 实用环境中文本生成模型代理安全性评估基准 [PDF](https://arxiv.org/pdf/2506.15253), [HTML](https://arxiv.org/abs/2506.15253)
## Authors
Yuchuan Fu,Xiaohan Yuan,Dongxia Wang
## Background
由于大型语言模型代理（LLM）在关键领域（如医疗和金融）的快速部署，迫切需要构建坚实的网络安全框架。当前这些代理在动态环境中的标准化评估基准缺失，这促使研究人员开发新的安全基准工具。为了填补这一空白，该研究提出了RAS-Eval，这是一个全面的安全基准，支持模拟和真实场景下的工具执行，包含80个测试案例和3,802个攻击任务，涵盖了11个共性弱点分类（CWE）类别，支持JSON、LangGraph和模型上下文协议（MCP）格式的工具实现。这些测试覆盖了6个最新的LLM模型，揭示了显著的安全漏洞：平均而言，攻击使任务完成率减少了36.78%，学术环境下的成功率为85.65%。研究还发现，安全能力与模型规模呈正相关，大模型优于小模型。这些发现揭示了实际部署中的关键风险，为未来的安全研究提供了基石框架。支持代码和数据可在该网址获取：this https URL
## Innovation
RAS-Eval 是一种新的全面基准，用于评估真实环境中 LLM 代理的安全性，包括80个测试案例和3,802个攻击任务，涵盖了11个共性弱点分类（CWE）类别，支持多种工具实现格式。该基准工具验证了最新的研究成果，揭示了大规模模型相比小型模型在安全性能上的优势，并为安全研究提供了全面的基础框架。
## Conclusion
RAS-Eval 揭示了实际部署中 LLM 代理的关键风险，并为未来的安全研究提供了基础框架。研究还发现，随着模型规模的增加，安全性能得以改善，这为未来的模型设计和安全评估提供了指导。
# 83. `cs.AI` - 半导体制造中缺陷图像分类的领域适应 [PDF](https://arxiv.org/pdf/2506.15260), [HTML](https://arxiv.org/abs/2506.15260)
## Authors
Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto
## Background
在半导体行业，由于高需求和激烈的竞争，市场进入时间和产品质量是获取各种应用领域显著市场份额的关键因素。近年来，得益于深度学习方法在计算机视觉等领域的成功应用，特别是在工业4.0和5.0中，如缺陷分类，取得了显著进展。尤其在领域适应（DA）方面的成功，是因为它可以利用源域所学知识来适应相关但不同的目标域，从而提高鲁棒性和可扩展性，减少手动重新标记或模型重新训练的需求。这不仅减少了计算和资源成本，还让人类专家能够专注于高价值任务。
## Innovation
本文提出了DBACS方法，一种灵感来源于CycleGAN的模型，并附加额外的损失项以提高性能。该方法在未监督和半监督设置下，通过实际的电子显微镜图像进行了研究和验证，证明了在半导体领域推进DA技术中的实用性。
## Conclusion
研究结果表明，DA技术在半导体缺陷图像分类中是有效的，并验证了DBACS方法的优势。未来可以进一步探索此类方法在不同半导体应用中的扩展性和适应性。
# 84. `cs.AI` - 使用合成数据解锁后置数据推断 [PDF](https://arxiv.org/pdf/2506.15271), [HTML](https://arxiv.org/abs/2506.15271)
## Authors
Bihe Zhao,Pratyush Maini,Franziska Boenisch,Adam Dziedzic
## Background
大型语言模型（LLMs）的出色能力主要归因于它们庞大的训练数据集，这些数据集通常是从互联网上收集的，没有尊重数据所有者的知识产权。现有一种名为Dataset Inference（DI）的方法，它可以识别训练时使用了嫌疑数据集，从而帮助数据所有者验证数据使用是否未经许可。然而，现有的DI方法依赖于一组明确未在训练集中的私有数据，这些数据需要与受损数据集的分布高度匹配。在实践中，这类“同分布”、被保留的数据很难获取，极大地限制了DI的应用范围。本文旨在解决这一挑战，通过合成生成必要的保留集来应对这一问题。该方法克服了两个关键障碍：一是创建高质量、多样化的合成数据以准确反映原始分布，这通过在一个精心设计的后缀基完成任务上进行训练的数据生成器来实现；二是弥补真实数据和合成数据之间的似然性差距，这通过事后校准来实现。广泛的数据集上的实验表明，使用我们生成的数据作为保留集能使DI在检测原始训练集方面具有很高置信度，并保持较低的误报率。这对于版权持有者合法地对数据使用的主张具有重大意义，并证明了该方法在实际诉讼中的可靠性。我们的代码在此处提供。
## Innovation
本文提出了一种使用合成数据来应对现有DI方法所依赖的“同分布”保留数据难以获得的挑战。提出的方法包括：1) 使用一个训练在精心设计的后缀基完成任务上的数据生成器生成高质量、多样化的合成数据，以准确反映原始分布；2) 通过事后校准来弥补真实数据和合成数据之间的似然性差距，从而实现与真实数据的更密切匹配。
## Conclusion
广泛实验表明，使用合成数据作为保留集可以使DI检测出原始训练集具有高置信度，同时保持较低的误报率。这一结果使版权持有者能够对数据使用做出合法的主张，并展示了该方法在实际诉讼中的可靠性。
# 85. `cs.AI` - 对带有服装感知的扩散模型的松散稀疏惯性传感器的人体运动捕捉 [PDF](https://arxiv.org/pdf/2506.15290), [HTML](https://arxiv.org/abs/2506.15290)
## Authors
Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz
## Background
基于摄像头的人体动作捕捉由于不便于携带和存在遮挡问题而与惯性传感器相比存在局限性。现有方法通常假设惯性测量单元（IMU）传感器紧贴人体，但在实际场景中这一假设往往不成立。因此，论文提出了一个使用稀疏、松散连接的IMU传感器进行全身人体姿态估计的新任务。利用现有的服装感知人体动作数据集模拟IMU记录，并开发基于变压器的扩散模型来合成松散接入的IMU数据，从而估计人体姿态。实验表明，这种方法在模拟和合成数据上训练的效果优于现有最先进的方法，显示出未来研究的前景。
## Innovation
本文创新地提出了使用稀疏、松散连接的IMU传感器进行全身人体姿态估计的新任务。利用现有的服装感知人体动作数据集模拟IMU记录，开发基于变压器的扩散模型来合成松散接入的IMU数据。并通过引入与服装相关的参数，有效保持了表达力，并提高了解决松动或紧身服装引入变化的能力。
## Conclusion
我们的扩散方法在模拟和合成数据上训练的表现优于现有最先进的方法，在定量和定性上均显示出优越性，未来的研究有了新的可能性。
# 86. `cs.AI` - 群体发现：LLM辅助临床试验招募综述 [PDF](https://arxiv.org/pdf/2506.15301), [HTML](https://arxiv.org/abs/2506.15301)
## Authors
Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff
## Background
最近大模型（LLMs）的进步显著提升了通用领域自然语言处理（NLP）任务的效果。然而，这些模型在诸如临床试验招募等关键领域中的应用仍然有限。由于临床试验的设计使用自然语言，患者数据既包括结构化信息也包括非结构化文本，因此匹配临床试验和患者的过程需要大模型的知识聚集和推理能力。传统的做法是针对特定临床试验，但大模型可以整合分散的知识，有望构建更具通用性的解决方案。尽管最近利用大模型辅助的方法在临床试验招募中取得进展，但这些方法依赖于专有模型和缺乏强有力的标准评价基准。因此，研究人员需要对该领域的现有基准测试、方法和评价框架进行全面的分析，以更好地理解采用大模型技术面临的挑战和潜在的发展方向。
## Innovation
本研究首次对临床试验患者匹配任务进行深入分析，并系统地综述了在这一领域的新兴大模型方法，填补了当前大模型辅助临床研究中缺乏详细文献回顾的空白。此外，本研究详细评估了现有的基准测试、方法和评价框架，有助于更好地指导后续研究的进展。
## Conclusion
本研究通过综合现有的研究进行综述，揭示了利用大模型技术在临床试验招募中的实际困境和面临的挑战。同时，本研究指出了未来可能的发展方向，包括完善模型设计和优化评价基准。这些发现有助于推动大模型技术在临床研究中的普及应用。
# 87. `cs.AI` - ConLID: 监督对比学习在低资源语言识别中的应用 [PDF](https://arxiv.org/pdf/2506.15304), [HTML](https://arxiv.org/abs/2506.15304)
## Authors
Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut
## Background
语言识别（LID）在从网络抓取中创建多语言大规模语言模型（LLM）预训练语料库时是一个关键步骤。尽管许多关于LID模型训练的研究集中在收集多样的训练数据以提高性能，但低资源语言——通常仅限于单一领域数据，如圣经——在语言识别方面表现仍然很差。这就导致了领域不平衡和偏见问题。因此，需要新的方法来解决这些挑战，提高低资源语言领域外数据的语言识别性能。
## Innovation
提出了一种名为ConLID的新监督对比学习（SCL）方法，用于为低资源语言学习不变的领域表示。这种方法通过对比学习，使模型能够更好地识别低资源语言，从而提高其在领域外数据上的语言识别性能。
## Conclusion
通过广泛的分析表明，ConLID方法将低资源语言领域的语言识别性能提高了3.2%，证明了该方法在提升LID模型效果方面的有效性。
# 88. `cs.AI` - 由主动学习指导的序列到序列变分自编码器在多靶标抑制剂生成中的应用 [PDF](https://arxiv.org/pdf/2506.15309), [HTML](https://arxiv.org/abs/2506.15309)
## Authors
Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar
## Background
同时优化针对多种治疗靶点的分子仍然是药物发现中的一个重大挑战，尤其是由于稀疏的奖励和冲突的设计约束。本文探讨了在多元目标药物设计中如何平衡化学多样性、分子质量以及多靶点亲和力的问题，从而优化药物候选分子的生成过程。
## Innovation
该研究提出了一种结构化主动学习（AL）范式，整合了序列到序列（Seq2Seq）变分自编码器（VAE），结合迭代循环系统来平衡化学多样性、分子质量以及多靶点亲和力的设计约束。方法包含交替访问可行的化学区域和基于不断增加的多靶点对接阈值逐步约束分子的过程。这种方法已证明能够有效地生成结构上具有多样性的广谱抑制剂候选分子。通过精心安排化学过滤器的时间和放置位置，显著增强了有利化学空间的探索，从而使稀疏奖励、多目标药物设计问题转化为一个可操作的计算任务。该框架提供了一个有效导航复杂多药理学空间的一般方法。
## Conclusion
该方法能够有效地生成结构多样的广谱抑制剂候选分子，并通过精心设计的主动学习管道的战略性化学过滤器安排显著促进了有利化学空间的探索，将药物设计中的多目标、稀疏奖励问题转变为一个可被计算系统处理的任务。
# 89. `cs.AI` - MapFM：基于基础模型的多任务背景学习高精度地图生成 [PDF](https://arxiv.org/pdf/2506.15313), [HTML](https://arxiv.org/abs/2506.15313)
## Authors
Leonid Ivanov,Vasily Yuryev,Dmitry Yudin
## Background
在自主驾驶中，高精度（HD）地图和以鸟瞰图（BEV）形式表示的语义地图对于准确的定位、路径规划和决策至关重要。当前的模型虽然取得了进展，但仍然需要进一步提升特征表示质量以增强环境理解和预测准确性。
## Innovation
提出了一个增强的端到端模型MapFM，用于在线矢量化高精度地图生成。MapFM通过集成强大的基础模型来编码摄像头图像，显著提升了特征表示质量。此外，通过集成辅助预测头进行BEV表示中的语义分割预测，引入了多任务学习方法，从而提供更丰富的上下文监督，最终提高了预测矢量化高精度地图的准确性和质量。
## Conclusion
MapFM模型通过多任务学习和强大的基础模型提升了高精度地图生成的准确性和质量，为自主驾驶中的定位、规划和决策提供了更好的支持。
# 90. `cs.AI` - J3DAI：三维堆叠CMOS图像传感器上的基于DNN的小型边缘AI加速器 [PDF](https://arxiv.org/pdf/2506.15316), [HTML](https://arxiv.org/abs/2506.15316)
## Authors
Benoit Tain,Raphael Millet,Romain Lemaire,Michal Szczepanski,Laurent Alacoque,Emmanuel Pluchart,Sylvain Choisnet,Rohit Prasad,Jerome Chossat,Pascal Pierunek,Pascal Vivet,Sebastien Thuries
## Background
本文介绍了J3DAI，这是一种基于深度神经网络的硬件加速器，用于三层三维堆叠的CMOS图像传感器，其中集成了一个基于深度神经网络(DNN)的加速器的AI芯片。DNN加速器旨在高效地执行神经网络任务，例如图像分类和分割。本文重点关注J3DAI的数字系统，讨论其性能-功耗-面积(PPA)特性，并展示了其在CMOS图像传感器上的先进边缘AI能力。为了支持硬件，利用了Aidge综合软件框架，该框架可以对主机处理器和DNN加速器进行编程。Aidge支持后训练量化，大大减少了内存占用和计算复杂性，对于部署在资源受限的硬件上如J3DAI至关重要。实验结果证明了这种创新设计在边缘AI领域的多样性和功效，能够处理从简单到计算密集型的各种任务。未来的工作将专注于进一步优化架构，并探索新的应用，以充分利用J3DAI的功能。随着边缘AI的重要性不断增加，类似J3DAI的创新将发挥关键作用，以实现边缘设备上的实时、低延迟和低功耗的人工智能处理。
## Innovation
J3DAI是一个基于深度神经网络的硬件加速器，用于三层三维堆叠的CMOS图像传感器。它集成了一个深度神经网络(DNN)加速器，能够高效地执行神经网络任务，如图像分类和分割。Aidge综合软件框架支持后训练量化，这对于部署在资源受限的硬件上至关重要。J3DAI展示了在CMOS图像传感器上的高级边缘人工智能能力，并且具有处理简单和计算密集型任务的潜力。
## Conclusion
实验结果证明了J3DAI设计在边缘人工智能领域的多样性和功效，展示了其处理从简单到计算密集型任务的能力。未来工作将致力于进一步优化架构并探索新应用，以充分利用J3DAI的功能。
# 91. `cs.AI` - 当且如何未标注数据能证明提升基于上下文的学习 [PDF](https://arxiv.org/pdf/2506.15329), [HTML](https://arxiv.org/abs/2506.15329)
## Authors
Yingcong Li,Xiangyu Chang,Muti Kara,Xiaofeng Liu,Amit Roy-Chowdhury,Samet Oymak
## Background
近期的研究表明，即使演示中的标签缺失或不准确，基于上下文学习（ICL）依然可能有效。为了进一步探讨这一能力，该研究在演示根据二元高斯混合模型（GMM）抽取的情况下，有一部分演示带有缺失标签的场景下进行研究。研究表明，单一层的线性注意力模型恢复了完全监督估计的最佳模型，但却完全未能利用未标记数据。相比之下，多层或循环变压器能通过隐式地构造形式为$ 	ext{∑}_{i≥0} a_i (X^	op X)^iX^	op y $的估计器有效利用未标记数据，其中X和y分别代表特征和部分观察标签（缺失项设为零）。这些估计器被表征为深度的函数的多项式类，并且与期望最大化法（一种常用于半监督学习的迭代伪标记算法）建立联系。实验证明了轻度深度或循环的量足以实现显著效果。因此，研究提供了一种将现成的表格基础模型通过循环方式应用以提升半监督能力的方法，并在真实世界的数据集上进行了广泛评估，证明了相对于标准单遍推理方法，我们的方法能够显著提高半监督表格学习的性能。
## Innovation
本文研究了在演示带有缺失标签的情况下，基于上下文学习的能力。关键发现是多层或循环变压器能够利用未标记数据，通过隐式构造特定形式的估计器，在不需要额外标签或人工伪标签的情况下进行有效学习。此研究提出了一种现成表格基础模型的循环应用方法，显著提升了半监督学习性能。
## Conclusion
本文通过理论分析和实验证据表明，在某些情况下，未标记数据可以有效提升基于上下文的学习效果，特别是在用循环变压器处理模型时，轻量级的深度或循环可以实现显著效果。研究还提供了一种现成表格基础模型的循环应用方法，验证了这种方法在真实世界数据集上的有效性。
# 92. `cs.AI` - 视频中的开放世界物体计数 [PDF](https://arxiv.org/pdf/2506.15368), [HTML](https://arxiv.org/abs/2506.15368)
## Authors
Niki Amini-Naieni,Andrew Zisserman
## Background
在视频中进行物体计数是一个重要的计算机视觉任务。传统的物体计数方法通常局限于固定的场景和目标对象，但在拥挤的场景中，有遮挡和相似物体的情况下，准确计数并避免重复计数和识别重新出现的物体尤其具有挑战性。这项工作中引入了一个新的任务：给定一个文本描述或图片示例来指定目标物体，目标是统计视频中所有独特目标物体的实例。
## Innovation
该研究提出了一种名为CountVid的新模型，结合了基于图像的计数模型和可提示的视频分割与跟踪模型，实现了对视频帧中开放世界物体的自动化计数。为了评估模型性能，研究人员创建了VideoCount数据集，该数据集基于TAO和MOT20跟踪数据集以及用X射线捕获的企鹅和金属合金结晶视频构建。实验结果显示与基线模型相比，CountVid模型在准确性上有了显著提升。
## Conclusion
研究成果提供了准确的物体计数，并且CountVid模型和VideoCount数据集对研究界开放，其网址为this https URL.
# 93. `cs.AI` - 系统化搜索异常检测系统的评估框架 [PDF](https://arxiv.org/pdf/2506.15388), [HTML](https://arxiv.org/abs/2506.15388)
## Authors
Florian Rokohl,Alexander Lehnert,Marc Reichenbach
## Background
数字化在医疗领域提供主要优势的同时也使其成为攻击目标，因此更难保障安全。为应对网络入侵者，本文提出一种硬件上的异常检测系统，该系统能够实现实时检测恶意客户端的功能，以满足实时性和功耗限制的要求。研究成果通过提出的整体系统评估方法实现最佳性能效果
## Innovation
采用FPGA技术实现实时检测和功耗优化；通过系统化的评估方法寻找适用的异常检测系统
## Conclusion
整体系统性能通过提出的评估方法得到提高，确保了在满足实时性和功耗限制的前提下有效检测网络中的恶意行为
# 94. `cs.AI` - 实时内窥镜图像去噪系统 [PDF](https://arxiv.org/pdf/2506.15395), [HTML](https://arxiv.org/abs/2506.15395)
## Authors
Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui
## Background
近年来，具备微型化设计特性的内窥镜显著提升了操作灵活性、便携性和诊断能力，同时减少了医疗程序的侵入性。最近，单次使用且配备超紧凑型模拟图像传感器（尺寸小于1mm x 1mm）的内窥镜在医学诊断方面实现了革命性的进步。它们降低了重复使用设备的结构冗余性和高额资本支出，消除了消毒不彻底导致的患者感染风险，减少了患者的痛苦。然而，由于小尺寸传感器的感光面积有限，导致每个像素的光子捕捉能力降低，需要设置更高的光子灵敏度以保持足够的亮显示。在高对比度医学成像场景下，小尺寸传感器的动态范围受限，导致亮部和暗部细节难以同时捕捉，需要额外的局部数字增益补偿。此外，简化电路设计和模拟信号传输导致了额外的噪声源。这些因素共同导致了处理后的内窥镜图像中的严重噪声问题。
## Innovation
本文开发了一种全面的图像传感器噪声模型，针对三种主要噪声类型：固定模式噪声、周期性条纹噪声和混合泊松-高斯噪声。在此基础上，提出了一种结合传统图像处理算法和先进的学习技术的混合去噪系统，用于传感器捕获的原始帧。实验结果表明，该方法在保持细节损失和颜色失真的同时，有效地减少了图像噪声，实现了在FPGA平台上实时性能，并在测试数据集上实现了33.05的平均PSNR改进，相较于之前的21.16。
## Conclusion
本文提出了一种集成了传统图像处理技术和先进的学习方法的实时内窥镜图像去噪系统，能够有效减少图像噪声，同时保持细节和颜色的完整性，实现实时性能，并在实际测试数据集上取得了显著的PSNR提升。
# 95. `cs.AI` - MCOO-SLAM: 一个全方位多摄像头物体SLAM系统 [PDF](https://arxiv.org/pdf/2506.15402), [HTML](https://arxiv.org/abs/2506.15402)
## Authors
Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue
## Background
目前大多数SLAM（Simultaneous Localization and Mapping）方法依赖于RGB-D传感器或单目视图，这导致了视野狭窄、容易被遮挡、深度感知能力有限等局限性，特别是在大规模或户外环境中。这些限制因素常常导致系统只能从有限的角度观察物体的部分视图，从而导致不准确的物体建模和不可靠的数据关联。
## Innovation
本文提出了一种名为MCOO-SLAM的新型全方位多摄像头物体SLAM系统，充分利用了全视图摄像头配置，以在复杂户外场景中实现稳健且语义丰富的建图。该方法将点特征和带有开放词汇语义的对象级地标结合使用，并引入了一种语义-几何-时间融合策略，以增强跨多个视图的物体关联，设计了一种全方位循环闭合模块以实现场景级描述符下的视角不变的地点识别。同时，构建的地图被抽象为层次化3D场景图，以支持下游推理任务。
## Conclusion
实验结果表明，MCOO-SLAM在实际环境中的表现能够实现准确的定位和可扩展的物体级建图，具有较好的遮挡鲁棒性、姿态变化鲁棒性和环境复杂度鲁棒性。
# 96. `cs.AI` - 统一VXAI：解释性人工智能的系统性审查与评价框架 [PDF](https://arxiv.org/pdf/2506.15408), [HTML](https://arxiv.org/abs/2506.15408)
## Authors
David Dembinsky,Adriano Lucieri,Stanislav Frolov,Hiba Najjar,Ko Watanabe,Andreas Dengel
## Background
现代AI系统通常依赖于不透明的黑盒模型，尤其是深度神经网络，其性能源于具有数百万个学习参数的复杂架构。尽管这些模型功能强大，但其复杂性导致缺乏透明度，阻碍了信任度。可解释的人工智能(XAI)通过提供易于理解的模型行为解释来解决这一问题。然而，为了确保其有用性和信任度，这些解释需要通过严格的评估。尽管XAI方法的数量不断增加，但该领域仍然缺乏标准化的评估协议和公认的度量标准。为了解决这一差距，本文遵循PRISMA指南进行系统文献综述，并提出了统一的VXAI框架。通过回顾362篇相关文献，并将它们的贡献汇总为41个功能相似的度量组，我们进一步提出了一种三维分类方案，涵盖解释类型、评估情境性和解释品质要求。
## Innovation
本文创新性地提出了统一的VXAI框架，通过系统文献综述识别了362篇相关文献，并将其贡献整合为41个功能相似的度量组。此外，作者还提出了一种三维分类方案，为未来的评估提供了灵活的基础。
## Conclusion
本文提供的框架是迄今为止最全面和结构化的VXAI概述。它支持系统性度量选择，促进不同方法间的可比性，并为未来扩展提供了灵活的基础。
# 97. `cs.AI` - 深度强化学习中的奖励模型：综述 [PDF](https://arxiv.org/pdf/2506.15421), [HTML](https://arxiv.org/abs/2506.15421)
## Authors
Rui Yu,Shenghua Wan,Yucen Wang,Chen-Xiao Gao,Le Gan,Zongzhang Zhang,De-Chuan Zhan
## Background
在强化学习（RL）中，代理不断与环境交互并通过反馈来改进其行为。为了指导策略优化，引入了奖励模型作为期望目标的代理，当代理最大化累积奖励时，也能实现任务设计师的意图。最近，来自学术界和工业界的大量研究关注于开发既与真实目标紧密对齐又能促进策略优化的奖励模型。因此，本文旨在全面回顾深度强化学习文献中的奖励模型技术。
## Innovation
本文对深度强化学习中的奖励模型技术进行了全面的综述。它涵盖了从背景和先验知识开始，再到按来源、机制和学习范式分类的最新奖励模型方法。此外，还讨论了这些奖励模型技术的应用以及评估奖励模型的方法。最后，指出了奖励模型研究的未来方向。
## Conclusion
本文汇集了现有和新兴方法，填补了当前文献中系统回顾奖励模型的空白。
# 98. `cs.AI` - Hunyuan3D 2.1：从图像到高保真3D资产的生产级PBR材质 [PDF](https://arxiv.org/pdf/2506.15442), [HTML](https://arxiv.org/abs/2506.15442)
## Authors
Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo
## Background
3D AI生成内容（AIGC）是一个充满激情的领域，极大地加速了游戏、电影和设计中的3D模型创建。尽管已经开发出了多种革命性的模型，但该领域的复杂性使其主要限于研究人员、开发人员和设计师使用。收集、处理和训练3D模型的过程非常复杂，因此对于普通用户来说仍然难以接触到这一技术。
## Innovation
本文档介绍了一种基于Hunyuan3D 2.1的全面案例研究，旨在解决模型复杂性的挑战。该文档提供了一个详细的工作流程，包括处理3D数据、训练3D生成模型和使用Hunyuan3D 2.1评估其性能，这是一个高级系统，用于生成高分辨率、带有纹理的3D资产。该系统包括两个核心组件：用于形状生成的Hunyuan3D-DiT和用于纹理合成的Hunyuan3D-Paint。文档涵盖了数据准备、模型架构、训练策略、评估指标和部署等内容，从而帮助读者掌握针对游戏、虚拟现实和工业设计的应用，完善或开发出一个稳健的3D生成模型。
## Conclusion
通过本教程的学习，读者将具备在游戏、虚拟现实和工业设计等领域开发或微调健壮3D生成模型的知识。
# 99. `cs.AI` - 部分可观测条件下的零样本强化学习 [PDF](https://arxiv.org/pdf/2506.15446), [HTML](https://arxiv.org/abs/2506.15446)
## Authors
Scott Jeen,Tom Bewley,Jonathan M. Cullen
## Background
近期研究表明，假定在无奖励预训练后，零样本强化学习方法可以在任何未见过的任务中泛化到环境中。尽管如此，这种泛化通常假设环境的状态是马尔可夫的，但在许多实际应用中，状态仅部分可观测。以往的单任务强化学习研究已经表明，基于记忆的架构能够缓解因部分可观测性导致的问题，但零样本强化学习方法在面对部分可观测性时的性能如何仍不清楚。因此，本研究旨在探讨标准零样本强化学习方法在部分可观测性条件下的表现下降情况，并评估基于记忆的零样本强化学习方法在部分不可观测状态、部分不可观测奖励和部分动态变化的情况下优劣势。研究结果显示，基于记忆的零样本强化学习方法在部分观测条件下表现出更好的性能，优于无记忆基准。
## Innovation
本研究通过一个创新实验设计，将基于记忆的零样本强化学习方法应用于部分不可观测的状态、奖励和动态变化的分类域中，并验证了这种方法相较于无记忆的基准方法在性能上的提升。研究结果表明，基于记忆的架构在部分可观测环境下能够有效地改善零样本强化学习方法的性能。这为在部分不可观测环境下的零样本强化学习提供了新的可能解决途径，也为增强零样本强化学习的泛化能力和适应性提供了重要依据。
## Conclusion
本研究证明，在部分可观测的环境中，基于记忆的零样本强化学习方法能够显著提升性能，有效克服了因部分可观测性带来的问题。这一发现为未来的强化学习研究提供了新的视角，并为实际应用中的算法设计提供了指导意义。特别是在资源受限或观测条件受限的场景中，这种改进的零样本强化学习方法具有重要的理论和实用价值。
# 100. `cs.AI` - 在时间序列之间拉伸和匹配子序列 [PDF](https://arxiv.org/pdf/2506.15452), [HTML](https://arxiv.org/abs/2506.15452)
## Authors
Simiao Lin,Wannes Meert,Pieter Robberechts,Hendrik Blockeel
## Background
时间序列在聚类和分类等多种任务中至关重要。弹性距离度量允许拉伸，提供了稳健的定量比较，但缺乏基于这些度量的定性比较。传统的可视化主要集中在点与点的对齐，未能传达子序列层面的总体结构关系。这种限制使得理解一个时间序列相对于另一个时间序列如何、何时发生位移、速度变化或减速变得困难。为了解决这些问题，本研究提出了一个新的技术，将拉伸路径简化以突出、量化并可视化关键转变（位移、压缩和振幅差异），通过更清晰地展示时间序列中子序列的匹配方式，提高了时间序列比较的解释性。
## Innovation
提出了一个新的技术，将拉伸路径简化以突出、量化并可视化关键转变（位移、压缩和振幅差异），通过更清晰地展示时间序列中子序列的匹配方式，提高了时间序列比较的解释性。
## Conclusion
通过简化拉伸路径并更清晰地展示时间序列中子序列的匹配方式，本方法增强了时间序列比较的可解释性。
# 101. `cs.AI` - 通过LLM驱动的代码片段描述生成揭示意图 [PDF](https://arxiv.org/pdf/2506.15453), [HTML](https://arxiv.org/abs/2506.15453)
## Authors
Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto
## Background
文档化代码片段对于开发者和用户来说至关重要，尤其是对于第三方库。虽然这项工作对于清晰的文档和提供足够的细节以传达使用意图非常重要，但目前有关如何使用大型语言模型（LLMs）来生成代码片段描述的研究还不是很充分。本研究通过分析185,412个包中的1,024,579个代码片段，使用了400个代码片段及其描述作为样本，主要研究代码描述中的主要特征，并探索大型语言模型如Llama在对应描述生成中的表现。
## Innovation
该研究的创新之处在于使用大型语言模型（如Llama）来生成代码片段描述。研究发现，大多数原始描述强调了示例使用的说明，且大型语言模型很好地识别了这些描述，表明其有自动生成代码描述的潜力。生成的描述与原始描述的平均相似度达到0.7173，但仍有改进的空间。这表明，代码片段所执行的任务可能会影响文档的意图，从使用指南到安装说明或任何用户的描述学习示例，意图可能不同。
## Conclusion
研究结果说明，生成的描述在某些方面具有相关性，但在不同上下文中可能需要更多的改进。大型语言模型在代码描述生成中的功能可以促进更好的文档化和使用经验，但仍需要在特定任务上进一步优化以满足用户需求。
# 102. `cs.AI` - RE-IMAGINE: 符号基准合成以评估推理能力 [PDF](https://arxiv.org/pdf/2506.15455), [HTML](https://arxiv.org/abs/2506.15455)
## Authors
Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez
## Background
最近的大型语言模型（LLMs）在推理基准测试中的精度很高。然而，这些高精度的结果仍然不清楚是真正推理能力的表现，还是仅仅统计性地回忆训练集内容的结果。此前的研究尚未提供一种有效的框架来评估和区分LLMs的推理能力层次。本研究受到因果阶梯（Pearl, 2009年提出）的启发，旨在构建一个层次结构来表征LLMs的推理能力，并提供了一种自动化流水线生成不同层次问题变体的方法。该研究通过在中间符号表示中改变问题，生成无法仅通过记忆解决的问题，同时强调其普适性并可跨越数学、代码和逻辑等推理领域。研究人员分别在四个广泛使用的基准测试上测试了几类LLMs，观察到随着问题变体的变化，模型性能下降，这表明LLMs在某些情况下高度依赖统计性回忆，从而为进一步研究不同推理层次的关键技能提供了可能的研究方向。
## Innovation
该框架基于符号表示法生成不同层次的问题变体，通过干预和反事实两个层次，检测LLMs的推理能力，并提供了一种通用的评估方法，可以在数学、代码和逻辑等多种推理领域应用。此外，通过改变问题来生成不能仅靠记忆解决的问题，该方法有助于明确区分LLMs的真正推理能力和统计性回忆能力。
## Conclusion
研究人员在广泛使用的基准测试上展示了该框架的应用，观察到当模型遇到问题变体时，性能下降。这表明LLMs可能存在依靠统计性回忆而非实际推理能力的情况，从而为进一步研究更具层次性的推理技能提供了可能性。
# 103. `cs.AI` - 人类与AI之间通过Metropolis-Hastings相互作用的共同创造性学习 [PDF](https://arxiv.org/pdf/2506.15468), [HTML](https://arxiv.org/abs/2506.15468)
## Authors
Ryota Okumura,Tadahiro Taniguchi,Akira Taniguchi,Yoshinobu Hagiwara
## Background
传统的基于单向知识转移的人工智能教育面临一个挑战，即整合不同模态的固有信息。本文提出了一种新的范式——共同创造学习，其中人类和人工智能相互整合各自的部分感知信息和知识，构建共享外部表征。研究使用了Metropolis-Hastings命名游戏(MHNG)为基础的分散式贝叶斯推理机制来测试这一框架。参与者在在线实验中与三种不同类型的计算机代理进行了联合注意命名游戏，结果表明人类与MH代理合作能够在互动中显著提高分类精度，朝着共享符号系统的趋同性更强。
## Innovation
提出了共同创造学习作为人类和AI相互整合各自信息的新范式，不同于传统的一方单向知识转移，这是通过MHNG基于的交互首次提供实验证据。这种方法通过动态匹配感知体验，为共生AI系统提供了潜力，使得AI与人类一起学习而非从人类那里学习，大幅提高了信息整合的效果。
## Conclusion
共同创造学习有希望成为一种共生路径，使得人工智能系统能够与人类共同学习，而不是单方面从人类学习。通过MHNG交互验证了这种方法能够在人类与AI的双边合作中产生共享的符号系统，人类的行为也与MH推导出的接受概率紧密一致，提供了首个此类实证证据。
# 104. `cs.AI` - 基于上下文的指导约束 [PDF](https://arxiv.org/pdf/2506.15480), [HTML](https://arxiv.org/abs/2506.15480)
## Authors
Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo
## Background
大型语言模型（LLMs）通常与外部知识结合使用，以提供其参数中未编码的信息或减少幻想。在这种情况下，我们期望模型通过将其响应扎根于提供的外部上下文来生成响应。然而，先前的研究表明，在推理时简单地附加上下文并不保证生成扎根。因此，需要改进的方法来确保模型在使用外部上下文时生成更加扎根的回答。
## Innovation
本文提出了一种基于上下文的指导约束（Context-INformed Grounding Supervision，CINGS），这是一种后训练监督方法，在此方法中，模型在训练时将相关的上下文附在响应之前，只对响应令牌计算损失，并屏蔽上下文。实验结果表明，使用CINGS训练的模型在文本和视觉领域均表现出比标准指令调整模型更强的扎根能力。在视觉-语言领域，用CINGS训练的模型替代视觉-语言模型的LLM主干可以减少幻觉并保持事实的一致性。增强的扎根能力并未影响通用下游任务的性能。
## Conclusion
通过CINGS增强的扎根机制，模型的先验知识和行为发生了转向，从而更加依赖于外部上下文。在文本和视觉领域，使用CINGS训练的模型显示出更强的扎根能力，并且在不需要牺牲通用下游任务性能的情况下减少了幻觉。此外，CINGS在视觉-语言领域与现有的推理时间指导约束技术互补，并且能够保持整个生成响应的事实一致性。
# 105. `cs.AI` - GenHOI：通用文本驱动的4D人-物体交互合成以适应未见物体 [PDF](https://arxiv.org/pdf/2506.15483), [HTML](https://arxiv.org/abs/2506.15483)
## Authors
Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban
## Background
虽然扩散模型和大规模运动数据集已经在文本驱动的人体运动合成方面取得了进展，但将其扩展到4D人-物体交互(HOI)仍面临挑战，主要是因为大规模的4D HOI数据集的缺乏。目前的研究主要集中在开发能够处理未知物体、合成高保真4D HOI序列的方法和框架。通过利用现有的3D HOI数据集，研究引入了基于双阶段框架的GenHOI，旨在解决这两方面的问题：1）泛化到未知物体；2）高保真4D HOI序列的合成。在第一阶段，通过Object-AnchorNet重建稀疏的3D HOI关键帧；在第二阶段，通过引入Contact-Aware Diffusion Model (ContactDM)，将稀疏的3D HOI关键帧平滑地插值为密集的4D HOI序列。特别地，研究提出了一种新颖的Contact-Aware Encoder和Contact-Aware HOI Attention，用于从扩散模型中提取人类与物体的接触模式，并有效整合接触信息，从而提高4D HOI序列的生成质量。实验结果表明，GenHOI在公开的OMOMO和3D-FUTURE数据集上实现了最先进的结果，展示了在未知物体上的强大泛化能力，同时实现了高保真4D HOI的生成。
## Innovation
创新点在于提出了GenHOI，这是一种新颖的两阶段框架，旨在处理未知物体、合成高质量的4D HOI序列。具体创新点包括：1) 利用Object-AnchorNet从3D HOI数据集中重建未知物体的关键帧；2) 引入了Contact-Aware Diffusion Model (ContactDM)；3) 提出了Contact-Aware Encoder和Contact-Aware HOI Attention以更有效地提取和整合接触信息，从而提高生成4D HOI序列的质量。
## Conclusion
通过GenHOI，研究成功实现了在公开数据集OMOMO和3D-FUTURE上的先进结果，展示了在未知物体上的强大泛化能力，并实现了高保真4D HOI序列的生成。
# 106. `cs.AI` - SPARE: 单次注释与参考引导评估的自动过程监督和奖励建模 [PDF](https://arxiv.org/pdf/2506.15498), [HTML](https://arxiv.org/abs/2506.15498)
## Authors
Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych
## Background
在大型语言模型（LLMs）中，逐步指导或步骤式监督对于提高复杂的多步骤推理能力起到了关键作用。然而，高效的高质量自动过程注释仍然是一个重大的挑战。现有的方法在处理多步推理和复杂任务时，尤其是在需要高精度和高效性的场景下，无法满足现有需求。为此，研究者们不断寻求创新方法来改进现有的过程注释方法。
## Innovation
本文提出了单次注释和参考引导评估（SPARE），这是一种新的结构化框架，使得能够在单次注释过程中按步骤对每个解决方案步骤进行注释，并将其与参考解步骤对齐，同时提供显式的推理评估过程。SPARE在数学推理、多跳合成问题回答和空间推理四个数据集上都表现出色，能够有效提高推理性能，并且在两种不同的应用场景下都表现出优越于基线方法的效果，特别是在需要高效率的场景下，相比于基于树搜索的自动注释方法，SPARE只需38%的运行时间。
## Conclusion
SPARE框架在自动过程监督和奖励建模方面取得了显著的性能提升，尤其是在复杂的数学数据集上表现出色。同时，SPARE还提供了更高的效率，并且已经公开发布，便于进一步的研究和重复验证。
# 107. `cs.AI` - 基于随机化光滑的像素级认证解释 [PDF](https://arxiv.org/pdf/2506.15499), [HTML](https://arxiv.org/abs/2506.15499)
## Authors
Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele
## Background
后验归因方法旨在通过强调具有影响力的输入像素来解释深度学习的预测。然而，这些解释高度缺乏鲁棒性：微小、难以察觉的输入扰动可以极大地改变归因图，同时保持相同的预测。这种脆弱性损害了它们的可信度，并需要对像素级归因分数提供严格的鲁棒性保证。该研究通过引入基于随机化光滑的首个认证框架，旨在解决上述问题，以确保任何黑盒归因方法在像素级的鲁棒性。
## Innovation
研究引入了基于随机化光滑的第一个认证框架，该框架可以为任何黑盒归因方法提供像素级的鲁棒性保证。通过对归因图进行稀疏化和平滑化，将任务重新表述为分割问题，并使用$oldsymbol{	ext{	extell}_2}$有界扰动来认证每个像素的重要性。研究还提出了三项评估认证鲁棒性、定位和忠实度的方法。实验证明，通过该方法获得的认证归因具有鲁棒性、可解释性和忠实性，能够支持在下游任务中的可靠使用。
## Conclusion
研究展示了12种归因方法在5个ImageNet模型上的广泛评估结果表明，基于随机化光滑的认证归因是可靠的、可解释的和忠实的，使其在下游任务中能够得到可靠应用。
# 108. `cs.AI` - Spatiotemporal Graph Neural Networks中的信息过压缩 [PDF](https://arxiv.org/pdf/2506.15507), [HTML](https://arxiv.org/abs/2506.15507)
## Authors
Ivan Marisca,Jacob Bamberger,Cesare Alippi,Michael M. Bronstein
## Background
图神经网络（GNNs）在多个领域取得了显著成功，但近期的理论研究揭示了它们信息传播能力的基本局限性，例如过压缩现象，即远处节点之间难以有效交换信息。此问题在静态GNNs中已有广泛研究，但在处理与图节点相关的序列数据的时空GNNs（STGNNs）中仍是一个未被探索的领域。由于时间维度的扩展增加了必须传播的信息量，这使得信息过压缩的问题在STGNNs中更为复杂和严峻。
## Innovation
本文首次形式化提出了时空信息过压缩问题，并剖析了与其静态情况的不同特性。研究发现，出乎意料的是，卷积STGNNs倾向于从时间上更为遥远的点传播信息，而不是那些短暂时间内的邻近点。进一步证明了遵循时空或时间-空间处理范式的架构同样会受到这一现象的影响，这为设计更为高效的算法提供了理论依据。
## Conclusion
在合成和真实数据集上验证了研究发现，提供了对其实操动态的更深入理解，并为设计更有效的STGNNs提供了一套原理性指导。
# 109. `cs.AI` - 使用GPT集成在LangChain中的CoT增强提示工程技术优化基于Web的AI查询检索 [PDF](https://arxiv.org/pdf/2506.15512), [HTML](https://arxiv.org/abs/2506.15512)
## Authors
Wenqi Guan,Yang Fang
## Background
大型语言模型已经彻底改变了远程学习过程等教育活动的方方面面。当前，检索远程学习资源在解释复杂学生查询时缺乏深度上下文意义，无法提供全面的信息。本研究旨在通过在LangChain框架中整合基于GPT的模型来增强远程学习检索，以更直观和高效的方式实现这一目标，同时重点提高检索结果的精确性和相关性，提供全面且上下文丰富的解释和资源，以最好地满足每位学生的需求。同时评估我们方法的有效性，与传统的大语言模型相比，报告了用户满意度和学习效果的改进。
## Innovation
本研究提出了一种集成GPT模型在LangChain框架中的新颖方法，通过CoT推理和提示工程技术实现更简洁和高效的远程学习资源检索，强调提高检索结果的精确性和相关性，提供全面且上下文丰富的解释和资源。该方法还与传统大语言模型进行了评估，显示出了用户满意度和学习效果的显著提高。
## Conclusion
本研究通过在LangChain框架中整合GPT模型，结合CoT推理和提示工程技术，实现了远程学习资源更加精确、相关和丰富的检索，提高了用户满意度和学习效果。
# 110. `cs.AI` - RePCS: 诊断基于LLM的检索增强生成中的数据记忆现象 [PDF](https://arxiv.org/pdf/2506.15513), [HTML](https://arxiv.org/abs/2506.15513)
## Authors
Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Luong Van Nghia
## Background
检索增强生成（RAG）已成为更新大型语言模型（LLM）响应的新策略，该策略结合了当前外部信息。然而，模型仍可能依赖于训练数据的记忆，并绕过检索到的证据，产生受污染的输出。当前的检测方法多依赖于对模型的访问或重新训练，缺乏通用性和无侵入性。针对这一问题，本文提出了检索路径污染评分（RePCS），这是一种诊断方法，无需对模型进行访问或重新训练，即可检测上述行为。RePCS通过比对两种推理路径来检测潜在的记忆行为，分别是仅使用查询参数的路径和使用查询与检索上下文两种路径，并通过计算这两个路径输出分布之间的Kullback-Leibler（KL）散度来进行评估。较低的KL散度表明检索上下文的影响较小，从而具有潜在的记忆性。此外，RePCS无需批量更新或访问梯度或内部状态，只需增加一次正向传递。该方法适用于多种模型，降低了进行诊断的复杂性和成本，特别是在计算资源受限或模型生命周期关键的应用中尤为重要。
## Innovation
本文提出了一种名为RePCS（Retrieval-Path Contamination Scoring）的检测方法，用于诊断基于LLM的RAG系统中数据的记忆现象，这种方法无需访问模型或重新训练，只需增加一次正向传递，同时可以提供用户自定义的假阳性率和假阴性率保证。该方法在Prompt-WNQA基准测试中达到了0.918的ROC-AUC，超越了先前最佳方法6.5个百分点，同时保持了每秒处理能力不超过4.7%的延迟开销，这使得RePCS在安全至关重要的应用中特别有价值。
## Conclusion
RePCS为验证RAG系统是否真正有效地利用检索提供了一种轻量级的黑盒保护措施，这一方法具有广泛的应用价值，特别是在涉及模型安全性和可信度的应用场景中。
# 111. `cs.AI` - 使用PRISM捕获多义性：一个多概念特征描述框架 [PDF](https://arxiv.org/pdf/2506.15538), [HTML](https://arxiv.org/abs/2506.15538)
## Authors
Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M.-C. Höhne,Oliver Eberle
## Background
自动可解释性研究旨在识别神经网络特征中编码的概念，以增强对模型行为的人类理解。当前的特征描述方法面临两个关键挑战：鲁棒性有限以及每个神经元只会编码一个概念（单义性）的错误假设，尽管越来越多的证据表明，很多神经元实际上是多义的。这个假设限制了特征描述的表达力，并限制了它们捕获模型内部编码的全部行为的能力。
## Innovation
我们引入了Polysemantic FeatuRe Identification and Scoring Method (PRISM)，这是一种创新性框架，用于捕捉神经网络特征固有的复杂性。与之前的方法不同，PRISM为多义性和单义性特征提供了更细腻的描述。我们使用PRISM对语言模型进行分析，并通过与现有方法的广泛基准测试，证明我们的方法生成了更准确和忠实的特征描述，提高了整体描述质量（通过描述得分），并在多义性存在时提高了捕捉不同概念的能力（通过多义性得分）。
## Conclusion
通过使用PRISM，我们解决了单一概念假设带来的局限性，更有效地捕捉了神经网络特征的复杂性和多样性。
# 112. `cs.AI` - 内在和外在组织的注意机制：Softmax的不变性和网络稀疏性 [PDF](https://arxiv.org/pdf/2506.15541), [HTML](https://arxiv.org/abs/2506.15541)
## Authors
Oluwadamilola Fasina,Ruben V.C. Pohle,Pei-Chun Su,Ronald R. Coifman
## Background
本文研究了变压器中自我注意机制内在（在注意力头内部）和外在（在注意力头之间）的结构。通过使用参分差分微积分，得到了自我注意机制对Softmax激活的不变性的理论证据，并通过计算示例得到了支持。这种组织结构使得能够在一个网络3张量显示出规律性几何结构上执行常见信号处理任务变得有利。文章通过构造与查询、键和头轴有关的分层划分树来使用现有的张量分层组织方法来研究网络结构。文章通过可视化由注意力头树组成的树以及扩散图嵌入来定性展示这种组织结构，并通过研究在二元和三元哈尔基底下的单个注意力头和整个网络的展开系数来定量研究网络稀疏性。最后，通过视觉和语言变压器的例子展示了这些理论和方法论发现的应用实例。
## Innovation
1. 使用参分差分微积分证明了自我注意机制对Softmax激活函数的不变性。
2. 通过张量分层组织方法对网络结构进行分层划分，构造了分层树来研究自我注意机制的内在和外在结构。
3. 通过扩散图嵌入和张量在空间中的基展开系数来研究和展示网络稀疏性。
4. 展示了理论和方法论发现的实际应用价值，包括模型修剪和网络架构比较等功能性的应用。
5. 提出了一种能被实际应用来解释和比较模型新架构的方法。
## Conclusion
本文的研究发现为自我注意机制的解释性分析提供了理论基础，并使研究人员能够应用这项理论进行解释性分析。同时，用于理解和应用基于网络3张量组织的方法，可以进行模型修剪以及比较网络架构。
# 113. `cs.AI` - 在极限中的学习算法 [PDF](https://arxiv.org/pdf/2506.15543), [HTML](https://arxiv.org/abs/2506.15543)
## Authors
Hristo Papazov,Nicolas Flammarion
## Background
该研究扩展了Gold的归纳推理框架，以融入‘计算观测’和‘受限输入来源’，从而研究在更现实约束下一般可递函数的学习问题。传统的输入-输出观测不足以学习一般可递函数类的极限学习，因此通过施加计算复杂性限制或补充近似时间限制解决了这一学习障碍。研究还揭示了策略轨迹观测下从策略轨迹学习可计算函数等价于从输入和输出学习有理函数，这与有限状态转导器推理存在有趣联系。进一步指出，对于线性时间可计算函数，即使有策略轨迹观测，计算特征集或多项式质量特征集也不能存在。
## Innovation
扩展了Gold的归纳推理框架，引入了时间限制观测和策略轨迹观测，施加计算复杂性限制或补充近似时间限制以克服学习障碍，建立了关于‘计算代理’观测的正式框架，并揭示了学习可计算函数与学习有理函数之间的关系。此外，还证明了线性时间可计算函数的计算特征集或多项式质量特征集不存在。
## Conclusion
在极限中的学习算法研究了更现实约束下的学习问题。虽然传统的输入-输出观测不足以学习一般可递函数类的极限，但通过施加计算复杂性限制或补充近似时间限制，解决了这一学习障碍，并揭示了学习可计算函数与学习有理函数之间的关系。然而，即使有策略轨迹观测，线性时间可计算函数的计算特征集或多项式质量特征集也不能存在。
# 114. `cs.AI` - CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation [PDF](https://arxiv.org/pdf/2506.15549), [HTML](https://arxiv.org/abs/2506.15549)
## Authors
Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen(Cherise)Chen
## Background
深度学习技术在使用延迟钆增强磁共振成像（LGE）图像进行心肌疤痕分割中展示了高准确性和及时性的潜力，这有助于结构性心脏病的诊断和治疗规划。然而，高质量心肌疤痕标签的稀缺性和变异限制了稳健分割模型的研发。因此，需要一种能够生成解剖学上合理且多样化的疤痕图像的方法来辅助诊断和治疗。现有的数据集不充分且不够多样，限制了模型性能的提升，需要改进数据增强方法来解决这些问题。研究人员通过引入CLAIM框架来解决这一问题，这是一种基于解剖学意义上生成疤痕图像的框架。
## Innovation
文章提出了一种名为CLAIM的新框架，用于心脏磁共振成像的临床导向的心肌疤痕合成与分割，其主要创新点在于SMILE模块。该模块通过条件化扩散生成器，基于临床采用的AHA 17分段模型生成解剖学上一致且具有空间多样性的疤痕图像。此外，CLAIM采用联合训练策略，同时优化疤痕分割网络和生成器，旨在提高合成疤痕的真实性和疤痕分割的准确性。该方法显著提升了合成疤痕与真实疤痕分布的一致性。
## Conclusion
索赔（CLAIM）生成的解剖学上一致的疤痕图像与真实疤痕更接近。该方法能够控制且真实地合成心肌疤痕，其成果不仅提升了真实性和多样性，还表现出在后续医学成像任务中的实用性。
# 115. `cs.AI` - 使用逻辑门进行可解释室内定位：基于Wi-Fi指纹的神经网络学习解释 [PDF](https://arxiv.org/pdf/2506.15559), [HTML](https://arxiv.org/abs/2506.15559)
## Authors
Danish Gufran,Sudeep Pasricha
## Background
使用深度学习（DL）进行室内定位通过Wi-Fi接收信号强度（RSS）指纹已经证明了高精度；然而，现有的大多数DL框架作为黑盒模型运行，限制了我们对预测过程的理解以及模型如何随时间响应现实世界干扰的认知。这种缺乏透明性阻碍了我们对由于环境动态引起的时间变化影响的理解，也阻碍了模型的长期稳健性。为了解决这个问题，作者引入了LogNet，一种基于逻辑门的新型框架，旨在解释和增强基于DL的室内定位。LogNet通过识别哪些接入点（APs）对每个参考点（RP）的影响最大，并揭示环境噪声如何干扰DL驱动的位置估计，使得定位过程更加透明和可解释，从而帮助我们追踪和诊断模型失败，提高DL系统的长期部署稳定性。
## Innovation
LogNet 是一种基于逻辑门的新型框架，旨在解释和增强基于DL的室内定位。它通过识别对每个参考点影响最大的接入点，并揭示环境噪声如何干扰DL驱动的位置估计，增加了透明性和解释性。这种解释能力有助于跟踪和诊断模型错误，并使DL系统更适合长期使用。LogNet不仅解释了DL模型的内部行为，还提高了性能—在某种程度上实现了低于1至2.8倍的定位误差，模型大小减少至3.4至43.3倍，并且降低了1.5至3.6倍的延迟，相较于先前的基于DL的模型。
## Conclusion
通过在多个实际建筑平面图上以及两年的时间变化中进行评估，LogNet 不仅解释了DL模型的内部行为，还提高了性能，表明其在室内定位中的有效性和适用性。
# 116. `cs.AI` - One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution [PDF](https://arxiv.org/pdf/2506.15591), [HTML](https://arxiv.org/abs/2506.15591)
## Authors
Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang
## Background
在现实世界视频超分辨率（Real-VSR）中，再现丰富的空间细节并保持时间一致性是一项具有挑战性的问题，尤其是在使用预训练的生成模型如稳定扩散（SD）来合成真实细节时。现有的基于SD的Real-VSR方法常常在时空一致性上妥协空间细节，导致视觉质量不高。关键在于如何有效地从低质量（LQ）输入视频中提取抗降解的时间一致性先验，并在保持提取的一致性先验的同时增强视频细节。
## Innovation
本文提出了一个双LoRA学习（DLoRAL）范式，用于训练一个有效的基于SD的一次性扩散模型，同时实现现实帧细节和时间一致性的统一。具体来说，引入了跨帧检索（CFR）模块来汇总帧间互补信息，训练一致性LoRA（C-LoRA）以从退化输入中学习鲁棒时间表示。之后，冻结CFR和C-LoRA模块，并训练细节LoRA（D-LoRA）来增强空间细节，同时与C-LoRA定义的时间空间对齐以保持时间一致性。这两个阶段交替进行优化，共同提供一致且细节丰富的输出。在推断过程中，两个LoRA分支集成到SD模型中，允许在单一扩散步骤中实现高效且高质量的视频恢复。实验表明，DLoRAL在准确性和速度上都表现出色。
## Conclusion
实验结果表明，DLoRAL在准确性和速度上都表现出了强大的性能。在推断过程中，两个LoRA分支被集成到SD模型中，实现在单一步骤中的高效且高质量视频恢复。
# 117. `cs.AI` - WikiMixQA：跨模态表格和图表问答基准 [PDF](https://arxiv.org/pdf/2506.15594), [HTML](https://arxiv.org/abs/2506.15594)
## Authors
Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret
## Background
文档是保存和传播信息的基础，但其中复杂的排版、表格和图表给自动文档理解（DU）带来了很大挑战。现有的视觉-语言大型模型（VLLMs）在多种任务上显示出改进，但它们在处理长文本文档中的视觉输入的有效性仍然不明确。这项研究旨在通过设计一种新的基准测试框架WikiMixQA来解决这一问题，该框架包含来自Wikipedia的4000篇具有七个不同主题的文章，涉及1000个多选题来评估表格和图表的跨模态推理能力。研究发现，现有的视觉-语言模型虽然在提供直接上下文情况下表现较好，但在需要从长文档中检索信息时表现不佳。
## Innovation
WikiMixQA是一种新的基准测试框架，包含4000篇Wikipedia文章和1000个多选题，专门用于评估表格和图表的跨模态推理能力，不同于现有基准，WikiMixQA强调复杂推理，要求模型从多个模态中综合信息。实验结果显示，一些模型在提供直接上下文时能够达到70%的准确率，但当需要从长文档中检索信息时，性能显著下降。其中，GPT-4-o是唯一一种在这一情况下超过50%准确率的模型，而开源模型的性能比较差，最高中位数为27%。
## Conclusion
这些发现强调了长文本文档中的多模态推理挑战，并将WikiMixQA确立为推动文档理解研究的关键基准。
# 118. `cs.AI` - 从模型到课堂：评估具有叙事和难度考量的生成性选择题 [PDF](https://arxiv.org/pdf/2506.15598), [HTML](https://arxiv.org/abs/2506.15598)
## Authors
Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro
## Background
尽管多项选择题（MCQs）在学习和评估中具有价值，但人工创建具有不同难度级别和针对性阅读技巧的MCQs仍然是一项耗时且成本高的任务。近年来，生成型人工智能的进步为高效自动化生成MCQs提供了机会，但对生成型MCQs的实际质量和可靠性的评估，特别是在生成失败的情况下，仍然缺乏关注。尤其是在实际应用环境中，这一方面显得尤为重要。此外，大多数MCQ生成研究专注于英语，而对其他语言的研究则不足。因此，本文探讨了当前生成模型在生成适合葡萄牙语阅读理解的、与课程相关的故事元素和不同难度级别相匹配的MCQs的能力。
## Innovation
本文的研究重点是生成与课程相关的故事元素和不同难度级别相匹配的葡萄牙语MCQs，并通过专家评估和对学生回答的心理测量属性分析，检验其适用于小学学生，旨在评估生成型模型在生成高质量MCQs的能力，特别是在解决意涵清晰性和可回答性方面的问题，以及如何生成吸引学生的干扰项，并符合高质量MCQ选项设计的标准。
## Conclusion
当前的生成模型可以生成与人工编写的MCQs质量相当的MCQs。然而，我们发现存在与语义清晰性和可回答性相关的问题。此外，生成能够吸引学生并达到高质量MCQ选项设计标准的干扰项仍然存在挑战。
# 119. `cs.AI` - LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning [PDF](https://arxiv.org/pdf/2506.15606), [HTML](https://arxiv.org/abs/2506.15606)
## Authors
Gabrel J. Perin,Runjin Chen,Xuxi Chen,Nina S. T. Hirata,Zhangyang Wang,Junyuan Hong
## Background
大型语言模型（LLMs）在实际应用中变得不可或缺，但它们的广泛应用也引发了显著的安全担忧，特别是在应对社会有害问题时。尽管致力于通过对齐（alignment）提高模型安全性的工作已经取得了很大进展，但对齐后的模型仍然可能受到随后微调的影响，即使额外的训练数据看似无害。本文通过实验证明，这种脆弱性源自LLM参数中安全关键低秩子空间对微调的敏感性。
## Innovation
本文提出了一种无需训练的新方法——低秩外推（LoX），通过外推对齐后的LLM的安全子空间来增强其安全性。结果表明，LoX在增强模型对良性或恶意微调攻击的鲁棒性方面取得了显著效果，同时保持了模型对新任务的适应性。LoX使面对良性或恶意微调攻击的攻击成功率（ASR）降低了11%至54%。进一步研究表明，LoX的成功在于其外推使LLM参数移动到了更平坦的区域，从而减少了对扰动的敏感性。
## Conclusion
实验结果证实了LoX的有效性，表明LoX能够在保持模型适应新任务的同时，显著提高其对抗良性或恶意微调攻击的鲁棒性。
# 120. `cs.AI` - 大型语言模型中悔意的组分架构 [PDF](https://arxiv.org/pdf/2506.15617), [HTML](https://arxiv.org/abs/2506.15617)
## Authors
Xiangxiang Cui,Shu Yang,Tianjin Huang,Wanyu Lin,Lijie Hu,Di Wang
## Background
大型语言模型在面对与之前生成的错误信息矛盾的证据时会有悔意表达。研究这一机制对于提高模型的可靠性至关重要，同时也有助于揭示认知是如何在神经网络中编码的。为了理解这种机制，需要首先在模型输出中识别悔意表达，然后分析内部表示。这需要检查模型的隐藏状态，信息在神经元层面进行处理。然而，要实现这一点存在三个主要挑战：(1) 缺乏专门记录悔意表达的语料库；(2) 缺乏用于确定最佳悔意表示层的指标；(3) 缺乏用于识别和分析悔意神经元的指标。这些限制需要通过创新方法来解决。
## Innovation
本研究提出了：(1) 一种通过精心设计的提示情景构建全面悔意数据集的工作流；(2) 受监督的压缩-解耦指数 (S-CDI) 用于识别最佳悔意表示层的度量标准；(3) 悔意主导评分 (RDS) 度量标准用于识别悔意神经元，并通过组影响系数 (GIC) 分析激活模式。实验结果显示，使用 S-CDI 度量标准成功识别了最优悔意表示层，显著提高了探针分类实验中的性能。此外，还发现了一个 M 形解耦模式贯穿各模型层，揭示了信息处理在耦合和解耦阶段的交替。通过 RDS 度量标准，将神经元分成了三类功能组：悔意神经元、非悔意神经元和双功能神经元。
## Conclusion
本研究解决了大型语言模型处理悔意的内部机制的挑战，通过创新方法识别并分析了关键的神经元结构和模式，为提高大型语言模型的可靠性和理解其内部工作机制提供了新的视角。
# 121. `cs.AI` - GFLC: 基于图的公平感知标签矫正以实现公平分类 [PDF](https://arxiv.org/pdf/2506.15620), [HTML](https://arxiv.org/abs/2506.15620)
## Authors
Modar Sulaiman,Kallol Roy
## Background
随着人工智能系统的广泛应用影响社会的各个方面，包括医疗决策和法律裁决，机器学习（ML）的公平性成为构建可信赖的机器学习系统的关键因素。然而，用于训练和开发去偏见技术的数据存在偏见和噪声标签，这会影响到模型性能并在测试期间误导公平性评价。多项研究证实了ML中的不公平结果，并强调需要更 robust 的公平性感知方法。因此，本文探讨了如何利用一种基于图的方法——GFLC（Graph-based Fairness-aware Label Correction）对标签进行矫正，同时保留数据集中的人口统计平衡，以改进模型的性能和公平性之间的权衡
## Innovation
本文提出了一种基于图的方法——GFLC，通过结合预测置信度度量、基于Ricci流优化的图拉普拉斯正则化以及明确的人口统计平等激励来实现标签噪音的有效矫正和人口统计平衡的保留。这一方法显著地在性能和公平性指标之间实现了权衡的改进，相比基准方法表现出更高的有效性
## Conclusion
实验结果表明，GFLC能够有效地矫正标签噪声，同时保持数据集中的人口统计平等。相比基准方法，该方法在性能和公平性指标之间实现了显著的权衡改进。
# 122. `cs.AI` - 基于MRI的脑年龄联邦学习：一项多中心研究，用于中风后功能结局预测 [PDF](https://arxiv.org/pdf/2506.15626), [HTML](https://arxiv.org/abs/2506.15626)
## Authors
Vincent Roca,Marc Tommasi,Paul Andrey,Aurélien Bellet,Markus D. Schirmer,Hilde Henon,Laurent Puy,Julien Ramon,Grégory Kuchcinski,Martin Bretzner,Renaud Lopes
## Background
脑预测年龄（BrainAGE）是一种反映脑健康状况的脑成像生物标志物。然而，训练可靠的BrainAGE模型需要大量数据，但经常受到隐私问题的限制。这项研究评估了联邦学习（FL）在中风患者接受机械取栓治疗时用于BrainAGE估计的性能，并探讨了其与临床表现和功能结局之间的关系。使用FLAIR脑部图像，研究采用了集中学习、联邦学习和单站点学习三种数据管理策略，比较了这些策略的预测误差，并探讨了BrainAGE与血管风险因素（如糖尿病、高血压、吸烟）及功能结局之间的关联。
## Innovation
研究采用了联邦学习的方法来评估MRI数据在BrainAGE估计中的性能，无需集中数据，保护患者隐私的同时保证了模型的准确性。与单站点模型相比，联邦学习模型表现出更好的性能。这项研究表明，BrainAGE在预测中风后恢复情况方面具有显著的关联性，表明它可能在中风护理中的预后建模中具有潜在价值。
## Conclusion
联邦学习可以不集中数据地实现准确的脑年龄预测。脑年龄与血管风险因素和中风后恢复之间的显著关联强调了其在中风护理中的预后建模潜力。
# 123. `cs.AI` - 重新审视大型语言模型的组合泛化能力，考虑指令跟随能力 [PDF](https://arxiv.org/pdf/2506.15629), [HTML](https://arxiv.org/abs/2506.15629)
## Authors
Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe
## Background
在生成常识推理任务中，如CommonGen，生成型大型语言模型（LLMs）会形成包含所有给定概念的句子。然而，当关注指令遵循能力时，如果提示指定了概念的顺序，LLMs必须生成遵循指定顺序的句子。为了应对这一挑战，作者提出了一项名为Ordered CommonGen的基准测试，旨在评估LLMs的组合泛化能力和指令遵循能力。这个基准测试通过评估按指定顺序生成概念的能力，实现这两种能力的同时评估。研究使用36种不同的LLMs进行了详细分析，结果显示，尽管LLMs通常理解指令意图，但倾向于特定概念顺序模式的偏差往往导致输出低多样性或即使改变概念顺序仍未改变的结果。此外，即便是最符合指令的LLM，也只有约75%的概念覆盖顺序，这突显了在指令遵循和组合泛化能力提升方面的必要性。
## Innovation
提议了一种名为Ordered CommonGen的新基准，用于评估大型语言模型的指令遵循能力和组合泛化能力。该基准测试通过评估生成内容的具体顺序来衡量模型的表现。此外，该研究展示了即使是表现最好的模型在其特定能力上也存在明显的限制，这强调了改进这两个方面的需求。
## Conclusion
尽管大型语言模型通常能够理解指令意图，但它们在处理特定概念顺序时往往表现出低多样性输出和固定的生成结果。无论是优于还是落后于理想表现的LLM，在组合泛化和指令遵循能力上都有进一步改进的空间。
# 124. `cs.AI` - Demystifying the Visual Quality Paradox in Multimodal Large Language Models [PDF](https://arxiv.org/pdf/2506.15645), [HTML](https://arxiv.org/abs/2506.15645)
## Authors
Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu
## Background
近年来，多模态大型语言模型（MLLMs）在视觉-语言基准任务上表现出色，但关于输入视觉质量如何影响其响应的细节知之甚少。研究人员发现，即使图像的感知质量提高，MLLM的理解能力是否自然增强也尚未明确。因此，该研究旨在通过系统地研究领先MLLMs在一系列视觉-语言基准测试中的表现，探讨图像视觉质量对模型性能的影响，并揭示视觉质量悖论：模型、任务乃至个别实例的表现可能因图像偏离人类感知保真度而提升。
## Innovation
提出的视觉质量测试时调优（VQ-TTT）是一种轻量级的适配模块，它在冻结的视觉编码器前插入了一个可学习的低秩内核以调节频域内容，并仅通过LoRA微调浅层视觉编码器层。VQ-TTT能在单次前向传递中动态调整每个输入图像，使其与特定任务的模型偏好相匹配。实验结果表明，VQ-TTT在评估的所有MLLMs和所有数据集上提升了显著的平均准确率，且无需额外模型、缓存特征或额外训练数据。这些发现重新定义了MLLMs“更好的”视觉输入，并突显了在AI成为主要数据客户的当下，适应性而非普遍“干净”的图像的重要性。
## Conclusion
研究结果表明，图像视觉质量的改变可以提升MLLMs的性能，并提出了VQ-TTT作为解决这一问题的方法。这种方法能够动态调整输入图像，使其更符合特定任务的模型偏好。这项工作为推动MLLMs在多模态任务中的应用提供了新的视角和途径。
# 125. `cs.AI` - AutoRule：从推理思路提取规则基础奖励提升偏好学习 [PDF](https://arxiv.org/pdf/2506.15651), [HTML](https://arxiv.org/abs/2506.15651)
## Authors
Tevin Wang,Chenyan Xiong
## Background
基于规则的奖励提供了一种改进强化学习从人类反馈的有希望策略，但当前方法通常依赖于手工规则工程。本研究提出AutoRule，一种完全自动化的从偏好反馈中提取规则并将其形式化为规则基础奖励的方法。AutoRule提取分三阶段进行：利用推理模型解释用户偏好、从这些解释的推理链中识别候选规则并合成统一规则集。利用最终确定的规则集，采用语言模型核实器计算每个输出满足规则的比例，用这种方法作为辅助奖励，与学习到的奖励模型一同用于策略优化。与基于GRPO的基础线模型相比，使用AutoRule训练的Llama-3-8B模型，在AlpacaEval2.0的长度控制胜率上提高了28.6%，在MT-Bench的一个保留子集中，第二轮表现提高了6.1%。分析表明，提取出的规则与数据集偏好具有一致性，且AutoRule在连续两集运行时相比学习奖励模型展示减少了奖励作弊。
## Innovation
AutoRule实现了全自动从偏好反馈中提取规则并将其形式化为规则基础奖励的方法，分三阶段进行：利用推理模型解释用户偏好、从这些解释的推理链中识别候选规则并合成统一规则集；利用最终确定的规则集，采用语言模型核实器计算每个输出满足规则的比例，用这种方法作为辅助奖励，与学习到的奖励模型一同用于策略优化。AutoRule在AlpacaEval2.0和MT-Bench上的实验结果证实了其有效性，表明其在某些数据集上能够捕捉到独特价值。同时，AutoRule还展示了相较于学习奖励模型更好的防奖励作弊能力。
## Conclusion
研究证明了AutoRule的有效性和优势。该方法能够提高基于人类反馈的强化学习策略性能，特别是在AlpacaEval2.0和MT-Bench数据集上。AutoRule能够自动从模型解释中提取有用的规则，并通过计算输出满足规则的比例作为辅助奖励，从而提高模型的长期性能和避免奖励作弊。提取出的规则已在附录中列出，研究代码已开源。
# 126. `cs.AI` - 泄露的思想：大型推理模型并非私密的思想家 [PDF](https://arxiv.org/pdf/2506.15674), [HTML](https://arxiv.org/abs/2506.15674)
## Authors
Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh
## Background
该研究关注的是大型推理模型作为个人代理使用时推理痕迹中的隐私泄露问题。与最终输出不同，推理痕迹通常被认为是对内且安全的。研究挑战了这一假设，发现推理痕迹中往往包含了敏感用户数据，可以通过提示注入或意外泄漏到输出中。通过测试时间和代理评估，研究证明增加推理步骤会放大这种泄漏。尽管增加测试时间计算方法的预算可以使模型在最终答案上更加谨慎，但也导致它们在自我思考中更冗长，从而泄露更多。这揭示了一个核心矛盾：改进推理改善了实用性，但也扩大了隐私攻击面。
## Innovation
研究挑战了推理痕迹被认为内部且安全的传统假设，展示了推理痕迹中的敏感用户数据可以通过提示注入或意外泄漏到输出中。此外，研究通过实证数据分析了增加推理步骤如何放大隐私泄漏，并揭示了改进推理与隐私风险之间的矛盾关系。
## Conclusion
研究指出，为了保障隐私安全，努力必须扩展到模型的内部思考过程，而不仅仅是输出部分。
# 127. `cs.AI` - Sekai: 旨在世界探索的视频数据集 [PDF](https://arxiv.org/pdf/2506.15675), [HTML](https://arxiv.org/abs/2506.15675)
## Authors
Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang
## Background
现有的视频生成技术取得了显著进步，有望成为交互式世界探索的基础。然而，现有的视频生成数据集在用于世界探索训练时存在一些局限性：限制地点、时间短、静态场景以及缺乏探索和世界方面的标注信息。
## Innovation
该论文介绍了名为Sekai的高质量第一人称视角全球视频数据集，其中包含丰富的探索注释。Sekai数据集包含来自全球100多个国家和地区超过750个城市的超过5000小时的步行或无人机视角视频。此外，开发了一个高效的工具箱，用于收集、预处理和标注视频，并加入位置、场景、天气、人群密度、字幕和摄像机轨迹等信息。
## Conclusion
实验结果验证了数据集的质量，并使用其中一部分数据集训练了一个交互式视频世界探索模型YUME。我们相信Sekai将为视频生成和世界探索领域带来好处，激励有价值的实用应用。
# 128. `cs.AI` - 密集SAE潜在变量是特征，而非缺陷 [PDF](https://arxiv.org/pdf/2506.15679), [HTML](https://arxiv.org/abs/2506.15679)
## Authors
Xiaoqing Sun,Alessandro Stolfo,Joshua Engels,Ben Wu,Senthooran Rajamanoharan,Mrinmaya Sachan,Max Tegmark
## Background
稀疏自编码器（SAEs）旨在通过施加稀疏性约束来从语言模型中提取可解释的特征。理想情况下，训练SAE应产生既稀疏又语义上有意义的潜在变量。然而，许多密集的潜在变量经常被激活，这引发了人们对它们是训练过程中的不 desirable 艺术品的担忧。本研究系统地探讨了密集潜在变量的几何结构、功能及其起源，发现它们不仅持久存在，而且常常反映有意义的模型表示。
## Innovation
该研究首先展示了密集的潜在变量倾向于形成反极点对，并重建残差流中的特定方向，而且删除其子空间会抑制重新训练SAE中新密集特征的出现——这表明高密度功能是残差空间的固有属性。然后引入了一个密集潜在变量的分类法，涵盖了位置跟踪、上下文绑定、熵调节、字母特异性输出信号、词性以及主成分重建等功能类。最后，分析了这些特征如何在各层中演变，揭示了从早期层的结构特征到中期层的语义特征，再到最终层的输出导向信号的变化。研究发现揭示了密集潜在变量在语言模型计算中的功能性作用，并表明不应将其视为训练噪声，而是特征而非缺陷。
## Conclusion
研究结果表明，密集潜在变量在语言模型的计算中有功能性作用，不应被视为训练噪声，而是特征而非缺陷。
# 129. `cs.AI` - 通过AI塑造未来工作：在线劳动力市场的实证证据 [PDF](https://arxiv.org/pdf/2308.05201), [HTML](https://arxiv.org/abs/2308.05201)
## Authors
Jin Liu(1),Xingchen Xu(2),Xi Nan(2),Yongjun Li(1),Yong Tan(2) ((1) University of Science and Technology of China, (2) University of Washington)
## Background
大型语言模型（LLM）为基础的生成型AI系统，如ChatGPT，在多种下游任务上展示了零样本学习能力。由于其通用性质和可能增强或自动化工作职能的能力，这些系统有望重塑劳动力市场动态。然而，预测它们的精确影响具有挑战性，因为人工智能同时影响需求和供给，并且市场参与者会有战略应对。利用一家领先在线劳动力平台的大量数据集，我们记录了在技能要求与核心LLM功能高度契合的子市场中，显著的替代效应和劳动市场的整体收缩。尽管需求和供给都减少，但供给的减少相对较小，从而加剧了自由职业者间的竞争。进一步的分析表明，这种竞争加剧尤其在编程密集型子市场中明显。这一模式归因于技能转变效应：ChatGPT 降低了编程的人力资本门槛，使在职的自由职业者能够参与编程任务。此外，这些转变并非均匀，高技能自由职业者对此转变贡献更大。
## Innovation
该研究利用大量数据集从领先的在线劳动力平台进行分析，揭示了AI对劳动力市场的复杂影响，特别是在编程密集型子市场中自由职业者的技能转换更为明显。研究指出，尽管需求和供给都减少，但供给减少较少，导致自由职业者之间竞争加剧，特别是在编程领域。此外，高技能自由职业者在技能转变中贡献更大。
## Conclusion
该研究强调了通用人工智能对劳动力市场的多方面影响，不仅体现在特定职业的替代，还展示了劳动力供给中的技能转变。研究结果对于政策制定者、平台运营商和工人都具有实际意义。
# 130. `cs.AI` - 基于空间上下文的自监督学习在手写文本识别中的应用 [PDF](https://arxiv.org/pdf/2404.11585), [HTML](https://arxiv.org/abs/2404.11585)
## Authors
Carlos Penarrubia,Carlos Garrido-Munoz,Jose J. Valero-Mas,Jorge Calvo-Zaragoza
## Background
手写文本识别（HTR）是计算机视觉中的一个重要问题，由于其固有的变异性以及需要丰富的语境信息进行解释，HTR面临着独特的挑战。尽管自监督学习（SSL）在计算机视觉中取得了成功，但其在HTR中的应用却相对分散，许多关键的SSL方法尚未被探索。本文专注于其中一种方法，即基于空间上下文的SSL，并探讨如何将其适应和优化以应用于HTR，同时提出利用手写文本独特特征的新工作流程。在多种基准情景下的实验结果表明，这些方法在SSL对于HTR的状态处于前沿地位上带来了进步。
## Innovation
基于空间上下文的自监督学习方法的应用研究，提出新的工作流程以优化HTR的识别效果，克服传统的SSL方法在HTR应用中的不足。
## Conclusion
所采用的方法在多种基准情景下推动了SSL在HTR领域的进步，展示了基于空间上下文的SSL方法在手写文本识别中的有效性。
# 131. `cs.AI` - 行为规划：一种多样规划工具 [PDF](https://arxiv.org/pdf/2405.04300), [HTML](https://arxiv.org/abs/2405.04300)
## Authors
Mustafa F Abdelwahed,Joan Espasa,Alice Toniolo,Ian P. Gent
## Background
在实际应用中，如风险管理和自动化流数据分析等领域，采用了多种规划方法。现有的多样性规划形式将多样性模型编码为距离函数，这种方法在计算上相对便宜，但在两个计划之间进行比较时。然而，这种方法限制了可以编码的多样性模型的数量，同时也削弱了解释为什么两个计划不同的能力。文章探讨了多样规划的新方法，通过使用n维网格表示，每维对应用户定义的特征，使其具有更高的表达力。
## Innovation
文章引入了一种新的多样规划方法，使用n维网格表示，每一维对应一个用户定义的特征，提供了一个新的工具，该工具可以根据自定义的多样性模型生成多样性的计划，名为“行为规划”。此外，这种方法可以支持超越经典规划的多种规划类别，如超订阅和数值规划。实验证明，使用这种方法生成的多样性计划比现有的方法更好。
## Conclusion
实验证明，此实现方法在基于我们新的自定义多样性模型生成多样性计划时，显著优于当前的多样规划方法。这是首个能够支持不仅限于经典规划的多种规划类别的多样规划方法。
# 132. `cs.AI` - OM4OV: 利用本体匹配进行本体版本控制 [PDF](https://arxiv.org/pdf/2409.20302), [HTML](https://arxiv.org/abs/2409.20302)
## Authors
Zhangcheng Qiang,Kerry Taylor,Weiqing Wang
## Background
由于语义网的动态特性，版本控制对于捕捉时间变化的信息变得至关重要，尤其是对于广泛使用的本体。长期认识到本体版本控制（OV）是高效本体管理的关键组成部分，但由于本体规模的不断增大以及由手动劳动引起的错误，现有的OV方法已无法应对这些挑战。
## Innovation
本文提出了一种新的方法，利用现有的本体匹配（OM）技术与系统进行本体版本控制。我们引入了一种统一的OM4OV流水线，从OM的角度重构了OV的新任务形式与测量方法。基于先前的对齐结果，我们提出了一种名为交叉引用（CR）机制的管道优化方法，以提高整体的OV性能。我们通过实验验证了OM4OV流水线和交叉引用机制的效果，实验数据来自Ontology Alignment Evaluation Initiative (OAEI)数据集。此外，我们还讨论了OM用于OV任务时的一些见解，表明一些由OV系统检测到的假映射实际上是正确的。
## Conclusion
本文实验验证了OM4OV流水线和CR机制的有效性，并讨论了OM在OV任务中的应用情况，展示了通过利用OM技术进行版本控制的可行性与优势。
# 133. `cs.AI` - 概率电路中的最优传输 [PDF](https://arxiv.org/pdf/2410.13061), [HTML](https://arxiv.org/abs/2410.13061)
## Authors
Adrian Ciotinga,YooJung Choi
## Background
尽管已经证明，某些类别的概率电路（PCs）表示的概率分布之间的差异可以有效计算，但到目前为止，尚未有任何现有方法可以计算由概率电路给出的概率分布之间的 Wasserstein 距离。本文介绍了一个新的基于概率电路的最优传输框架。
## Innovation
提出了一个 Wasserstein 类型的距离，其中关联的最优传输问题的耦合度量被限制为一个概率电路。发展了一种计算此距离的方法，通过求解一系列小型线性规划问题，并推导出使得此问题可以有效计算的电路条件。从这些线性规划问题的解中，可以轻松提取 PC 之间的最优传输计划。并且研究了概率电路与数据集之间的经验 Wasserstein 距离，通过高效的迭代算法估计概率电路参数以最小化该距离。
## Conclusion
本文介绍了一种新的最优传输框架，可以计算由概率电路表示的概率分布之间的 Wasserstein 距离。通过求解一系列线性规划问题，可以高效计算该距离，并且可以估计概率电路参数以最小化与数据集之间的 Wasserstein 距离。
# 134. `cs.AI` - 在Werewolf游戏中使用迭代潜在空间策略优化学习战略性语言代理 [PDF](https://arxiv.org/pdf/2502.04686), [HTML](https://arxiv.org/abs/2502.04686)
## Authors
Zelai Xu,Wanjun Gu,Chao Yu,Yi Wu,Yu Wang
## Background
大型语言模型（LLM）代理在开放式对话和多步决策等领域展现了出色的性能，但在解决狼人杀（Werewolf）等需要战略决策和自由文本交互的语言博弈方面仍然存在挑战。现有LLM代理在行动分布中表现出内在偏见，并且在无限文本动作空间的探索有限，导致了次优的表现。相对于LLM代理，越来越多的关注点放在结合博弈论方法和微调策略来构建战略性语言代理上。研究者认为语言空间虽然组合庞大，但其实质性的策略空间相对紧凑，因此提出了潜在空间策略优化（LSPO）框架，即通过迭代过程将自由文本转化为有限的潜在策略空间，再使用博弈论方法优化策略，并通过直接偏好优化（DPO）进行LLM的调整，最终通过交替步骤逐步提升代理的战略推理和语言沟通能力。实验结果表明，使用LSPO框架构建的Werewolf代理随着迭代的增加不仅提高了策略空间的规模，而且在策略博弈中取得了优于现有代理的性能，证明了其在需要战略性交互的自由文本游戏中的有效性。
## Innovation
提出了潜在空间策略优化（LSPO）框架，这是一个结合博弈论方法与大型语言模型（LLM）调整的迭代方法。首先，将自由文本转化为有限的潜在策略空间，再应用博弈论方法如反事实后悔最小化（CFR）来优化策略；接着，通过直接偏好优化（DPO）调整LLM以与所学策略一致。这种方法填补了现有技术的空白，特别是在模型在无限文本动作空间中进行有效策略优化和模拟方面。
## Conclusion
实验表明，通过LSPO逐步改进的战略语言代理在策略博弈中表现优异，对于自由形式的语言游戏具有更有效的策略博弈方式，其在Werewolf游戏中优于现有代理表现，证明了该方法的有效性和适用性。
# 135. `cs.AI` - 从符号音乐语料库合成复合层次结构 [PDF](https://arxiv.org/pdf/2502.15849), [HTML](https://arxiv.org/abs/2502.15849)
## Authors
Ilana Shapiro,Ruanqianqian Huang,Zachary Novack,Cheng-i Wang,Hao-Wen Dong,Taylor Berg-Kirkpatrick,Shlomo Dubnov,Sorin Lerner
## Background
西方音乐自然地具备一种层级结构，从细微的旋律层逐步上升到宏观的结构形式层。为了全面、多粒度地分析音乐作品，作者提出了一种统一分层的音乐结构元表示方法——结构时间图（STG），该方法可用于定义单个音乐作品中的结构化音乐特征及其时间关系。通过这种方法，能够生成音乐语料库的代表性结构摘要，这被形式化为一组扩展了一般化中位图问题的组合优化问题。研究通过模拟退火来计算音乐片段之间的结构距离，然后结合SMT求解器的正式保证与嵌套的模拟退火，生成音乐语料库中各STG的结构上可靠的代表性中心STG。为了验证该方法的有效性，研究进行了实验，结果表明结构距离能够准确区分音乐片段，所提取的汇总点能够准确地结构化描述其语料库。
## Innovation
提出了一种统一分层的音乐结构元表示方法——结构时间图（STG），并通过模拟退火和SMT求解器结合的方法，生成音乐语料库的结构上可靠的代表性中心STG。将这种复杂问题形式化为一个扩展了一般化中位图问题的组合优化问题。
## Conclusion
通过验证实验，研究证明了结构距离能够准确区分音乐片段，并且所提取的汇总点能够准确地结构化描述其语料库。
# 136. `cs.AI` - 使用概率电路精确求解计数模 satisfiability [PDF](https://arxiv.org/pdf/2503.01009), [HTML](https://arxiv.org/abs/2503.01009)
## Authors
Jinzhao Li,Nan Jiang,Yexiang Xue
## Background
Satisfiability Modulo Counting (SMC) 是一种最近提出的通用语言，用于处理结合统计和符号人工智能的问题。SMC 问题是一种扩展的 SAT 问题，其中某些布尔变量的真假值由概率推理决定。现有的近似求解器可能会返回违反约束条件的解。直接将可用的 SAT 求解器和概率推理求解器集成可以得到精确的解，但因两者需要频繁相互调用而性能相对较慢。现有方法需要完整的变量赋值才能进行概率推理，而该研究提出了一种新的方法来提高效率。
## Innovation
该研究提出了 KOCO-SMC，这是一种集成的精确 SMC 求解器，可以在概率推理过程中高效地跟踪下限和上限。KOCO-SMC 可以通过仅使用部分变量赋值来进行早期的概率推理估计，从而增强计算效率。这种方法不同于现有需要完整变量赋值的方法。实验表明，KOCO-SMC 在大规模数据集及实际应用中能够以更少的时间找到精确解。
## Conclusion
KOCO-SMC 在解决大规模数据集和实际应用中的 SMC 问题时，找到了更精确的解，并且耗时更少，提高了性能效率。
# 137. `cs.AI` - 基于熵的多步推理探索导引 [PDF](https://arxiv.org/pdf/2503.15848), [HTML](https://arxiv.org/abs/2503.15848)
## Authors
Jinghan Zhang,Xiting Wang,Fengran Mo,Yeyang Zhou,Wanfu Gao,Kunpeng Liu
## Background
多步骤过程通过大型语言模型（LLMs）已被证明对解决复杂推理任务非常有效。然而，推理过程的探索深度对任务性能影响显著。现有的自动决定探索深度的方法通常导致成本高且缺乏灵活性。
## Innovation
提出了一种名为Entro-duction的新方法，通过监测LLM的输出熵和变异熵来动态调整多步骤推理过程中的探索深度。这种方法利用熵及其变化来捕捉模型对当前步骤的不确定性和连续推理步骤间不确定性的波动，从而在推理准确性与探索有效性之间找到平衡。实验结果表明该方法的有效性。
## Conclusion
在四个基准数据集上的实验结果证实了Entro-duction的有效性。
# 138. `cs.AI` - 结构级分子解毒：MLLMs准备好应对了吗？ [PDF](https://arxiv.org/pdf/2506.10912), [HTML](https://arxiv.org/abs/2506.10912)
## Authors
Fei Lin,Ziyang Gong,Cong Wang,Yonglin Tian,Tengchao Zhang,Xue Yang,Gen Luo,Fei-Yue Wang
## Background
毒性是药物开发早期阶段失败的主要原因。尽管在分子设计和性质预测方面取得了进展，但分子毒性修复的任务——生成具有结构有效性和降低毒性的替代分子——仍未被系统定义和评测。因此，该研究通过引入ToxiMol，旨在为多模态大型语言模型提供一个标准化的基准任务，专注于分子毒性修复。
## Innovation
该研究首次为多模态大型语言模型定义并标准化了分子毒性修复任务，建立了包含11个主要任务和560个代表性有毒分子的标准数据集，并设计了一个机制感知和任务适应性的提示注释管道。此外，还提出了一种自动评估框架ToxiEval，将毒性终点预测、合成可行性、药物特性和结构相似性整合到高通量评估链中，用于修复成功率的评估。通过评估近30种主流多模态大型语言模型并设计多组消融研究，分析了评价标准、候选多样性以及失败归因的关键因素。研究结果表明，尽管现有模型在这个任务上仍面临重大挑战，但它们开始在毒性理解、语义约束遵循和结构感知分子编辑方面表现出有前景的能力。
## Conclusion
虽然当前多模态大型语言模型在这个任务上仍面临重大挑战，但它们开始显示出在毒性理解、语义约束遵循和结构感知分子编辑方面的有前景的能力。
# 139. `cs.AI` - 从数据驱动到目标导向的人工智能：面向患者的分析自动化系统思维 [PDF](https://arxiv.org/pdf/2506.13584), [HTML](https://arxiv.org/abs/2506.13584)
## Authors
Daniel Anadria,Roel Dobbe,Anastasia Giachanou,Ruurd Kuiper,Richard Bartels,Wouter van Amsterdam,Íñigo Martínez de Rituerto de Troya,Carmen Zürcher,Daniel Oberski
## Background
本文反思了AI驱动的患者护理自动化中数据驱动建模范式所获得的重视。现有的治疗方法可能并不总是理想的选择，因为使用现有的实际患者数据集进行机器学习可能会导致不良的临床结果。回顾数据历史分析，从数据驱动范式的兴起以及它对现有建模方法的补充角色（如系统的思维方式和临床专业知识）进行解释，强调基于临床理论和社会技术现实的目的导向的机器学习方法的重要性。这种方法需要从数据生成（上游）和自动化目标（下游）两个方向理解现有患者的疗效。这种目标导向的视角在AI系统开发中为新的方法论机会打开了大门，并有望实现对患者的护理自动化。
## Innovation
提出了一种目标导向的机器学习范式，该范式立足于临床理论和社会技术现实，关注从数据生成到自动化目标的双向理解。这种视角为AI系统开发开创了新的方法论机会，并有可能实现人性化的AI自动化护理结果。
## Conclusion
本文呼吁采用基于临床理论和社会技术现实的目的导向的机器学习范式，这为实现患者护理自动化提供了新的方法论机会。
# 140. `cs.AI` - NordDRG AI基准测试用于大型语言模型 [PDF](https://arxiv.org/pdf/2506.13790), [HTML](https://arxiv.org/abs/2506.13790)
## Authors
Tapio Pitkäranta
## Background
大型语言模型（LLMs）已经在临床编码和决策支持方面进行了试点。但直到现在，还没有公开基准针对诊断相关组（DRG）确定的医院资金层。NordDRG-AI-Benchmark 是首个公开测试平台，涵盖了完整的 DRG 规则集，并评估了 LLMs 在处理多语言诊断、程序和技术分类逻辑方面的推理能力。基准测试包含三类实体：定义表格、专家手册和更改日志模板，以及一套包含14个案例组合任务的提示包。所有实体都可以在给定的网址上找到。基准测试显示，五种最先进的LLMs在九个自动验证任务上的表现存在显著差异，这证实了NordDRG-AI-Benchmark突显了特定领域的强弱，这些强弱在普遍基准测试中是隐藏的，为医院资金领域的可信赖自动化研究提供了可重复的基础。
## Innovation
NordDRG-AI-Benchmark 是首个专门针对医院资金层的公开基准测试，涵盖了完整的 DRG 规则集，并提供了多语言诊断、程序和技术逻辑的评估框架。它包含定义表格，专家手册和更改日志模板，以及14个包含代码查找、跨表推理、多语言术语和质量审计的任务套装。这项基准测试揭示了特定领域的强弱，这些强弱在通用语言模型基准测试中是看不到的，提供了医院资金自动化研究的基础。
## Conclusion
最新的基准测试显示，五种最先进的大型语言模型在九个自动验证任务上的表现非常不同，表明 NordDRG-AI-Benchmark 能够突出特定领域的强弱，为医院资金领域的可信赖自动化研究提供了可重现的基准。
# 141. `cs.AI` - HiURE: 基于层次示例对比学习的无监督关系抽取 [PDF](https://arxiv.org/pdf/2205.02225), [HTML](https://arxiv.org/abs/2205.02225)
## Authors
Shuliang Liu,Xuming Hu,Chenwei Zhang,Shu`ang Li,Lijie Wen,Philip S. Yu
## Background
无监督关系抽取的目标是从自然语言句子中提取实体之间的关系，无需先验的关系统计或分布信息。现有方法要么通过迭代利用自监督方案反复利用自适应聚类和分类来优化关系特征信号，但容易产生逐步的漂移问题；要么采用基于实例的对比学习，这不合理地将语义相似的句子对推开。
## Innovation
提出了一种新的对比学习框架——HiURE，利用跨层次注意力从关系特征空间推导出层次信号，并且基于实例对的对比学习有效优化句子的关系表示。
## Conclusion
实验结果表明，HiURE在两个公开数据集上的无监督关系抽取表现比最先进的模型更先进且稳健。
# 142. `cs.AI` - 一种有效的异质知识课程学习方法用于序列标注 [PDF](https://arxiv.org/pdf/2402.13534), [HTML](https://arxiv.org/abs/2402.13534)
## Authors
Xuemei Tang,Jun Wang,Qi Su,Chu-ren Huang,Jinghang Gu
## Background
序列标注模型通常可以从外部知识中受益，但引入外部知识会增加数据异质性并使模型复杂化，增加了训练高性能模型的成本。因此，为了应对这个问题，作者提出了一种专门设计用于序列标注任务的两阶段课程学习（TCL）框架。该框架旨在通过逐步从简单到复杂的引入数据实例来优化训练过程，从而提高性能和训练速度。进一步地，作者探索了评估序列标注任务难度的不同指标。通过在六个中文词性标注（CWS）和词性标注（POS）数据集上的广泛实验，证明了该模型能够有效提升序列标注模型的表现。此外，分析表明，TCL可以加速训练，并缓解了复杂模型的慢训练问题。
## Innovation
提出了一种专门设计用于序列标注任务的两阶段课程学习（TCL）框架，通过逐步从简单到复杂的引入数据实例来优化训练过程。此外，探索了评估序列标注任务难度的不同指标。
## Conclusion
通过在六个中文词性标注和词性标注数据集上的广泛实验，展示了该模型的有效性，并分析表明，TCL可以加速训练并缓解慢训练问题。
# 143. `cs.AI` - 通过代码指标分析预测计算笔记本的理解性 [PDF](https://arxiv.org/pdf/2406.10989), [HTML](https://arxiv.org/abs/2406.10989)
## Authors
Mojtaba Mostafavi Ghahfarokhi,Alireza Asadi,Arash Asgari,Bardia Mohammadi,Abbas Heydarnoori,Masih Beigi Rizi
## Background
计算笔记本是数据科学家的主要编码工具，但它们的代码质量尚未得到充分研究，且常常较低。鉴于维护性和可重用性的关键性，提高代码可理解性是必要的。传统方法通常依赖有限的问题问卷或类似点赞和投票的元数据，这些可能未能反映实际代码的清晰度。为此，我们提出了一个创新的方法，利用软件仓库中的用户意见来评估 Jupyter 笔记本的理解性。我们使用 DistilKaggle 数据集中的 542,051 个 Kaggle Jupyter 笔记本进行了案例研究，并采用了微调的 DistilBERT 变压器来识别与代码理解性相关的用户评论。我们还引入了一个新的指标，即用户意见代码理解性（UOCU），并结合了评论的相关性、其获得的点赞数以及笔记本的浏览量。UOCU 显著优于先前的方法。我们进一步通过将其与总点赞数结合到混合方法中来改进了 UOCU。基于改进后的指标，我们从 132,723 个最终笔记本中收集了 34 个笔记本级指标，并训练了机器学习模型来预测理解性。我们最佳模型——随机森林分类器，在分类笔记本代码的理解性级别时取得了 89% 的准确率。这项工作表明，用户意见信号和笔记本度量在构建可扩展且准确的代码理解性衡量标准方面的价值。
## Innovation
我们提出了一种新颖的方法，通过利用软件仓库中的用户意见来评估 Jupyter 笔记本的理解性。具体地说，我们开发了用户意见代码理解性（UOCU）指标，结合了评论的相关性、点赞数以及笔记本的浏览量。此外，我们进一步将 UOCU 与总点赞数结合，以提高评估代码理解性的准确性。最后，我们使用这些改进的指标训练了机器学习模型来预测代码的理解性，并实现了较高的分类准确率。
## Conclusion
我们的研究证明了用户意见信号和笔记本度量在构建可扩展且准确的代码理解性衡量标准方面的价值。我们的随机森林分类器在分类笔记本代码的理解性水平时达到了 89% 的准确性，这一结果展示了我们方法的有效性。未来的研究可以进一步探讨其他用户反馈源来进一步改进此方法。
# 144. `cs.AI` - 自然语言处理的系统性研究：希腊语语言处理 [PDF](https://arxiv.org/pdf/2407.09861), [HTML](https://arxiv.org/abs/2407.09861)
## Authors
Juli Bakagianni,Kanella Pouli,Maria Gavriilidou,John Pavlopoulos
## Background
全面的单一语言自然语言处理(NLP)调研对于评估特定语言的挑战、资源可用性和研究缺口至关重要。现有的调研往往缺乏标准的方法论，导致选择偏差和NLP任务及资源覆盖的碎片化。本研究提出了一种通用框架，用于系统性的单一语言NLP调研。该方法结合了结构化的搜索协议以减少偏见、NLP任务分类体系，以及语言资源分类体系来识别潜在的基准并突出提升资源可用性的机会。本研究以2012-2023年的希腊语NLP为例，提供了其现状、任务具体进展和资源缺口的深入分析。调研结果定期更新，可公开访问，为持续资源提供了支持。这种系统性的希腊语NLP调研作为案例研究，展示了该框架的有效性及其在其他资源不足语言领域的更广泛应用潜力。
## Innovation
本研究创新提出了一种通用框架，包括结构化的搜索协议、NLP任务分类体系和语言资源分类体系，旨在减少选择偏差和碎片化覆盖，以系统性地评估单一语言的NLP挑战、资源可用性和研究缺口。
## Conclusion
本研究通过系统性地调研2012-2023年的希腊语NLP，展示了该通用框架的有效性和应用潜力，为其他资源不足语言的NLP研究提供了参考案例。研究结果可供公开访问，确保了资源的持续更新和应用。
# 145. `cs.AI` - RadioRAG: 实时检索增强生成在放射学问答中的应用 [PDF](https://arxiv.org/pdf/2407.15621), [HTML](https://arxiv.org/abs/2407.15621)
## Authors
Soroosh Tayebi Arasteh,Mahshad Lotfinia,Keno Bressem,Robert Siepmann,Lisa Adams,Dyke Ferber,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn
## Background
大型语言模型（LLMs）通常基于静态训练数据生成过时或不准确的信息。检索增强生成（RAG）通过引入外部数据源来缓解这一问题。尽管之前的RAG系统依赖于预组装、固定的数据库，具有有限的灵活性，但本研究开发了Radiology RAG（RadioRAG），这是一种端到端框架，可以在实时从权威的放射学在线来源检索数据。该研究评估了各种LLMs在使用和不使用额外在线信息的情况下回答放射学特定问题的诊断准确性，发现RadioRAG可以显著提高大多数LLMs的诊断准确性，特别是在乳腺成像和急救放射学领域，匹配或超越了没有RAG模型以及人类放射科医生的表现。然而，模型之间的效果存在差异。
## Innovation
开发了Radiology RAG（RadioRAG）框架，可以在实时从权威的放射学在线来源检索数据，提供给LLMs以增强其在放射学问答中的表现。这种基于实时检索的治疗方法比之前用于放射学的RAG系统更加灵活和有效。研究结果表明，LLMs在得到特定领域数据的支持时，表现会显著提高，特别是使用Radiology RAG后，多种LLMs的准确度提升幅度达到了54%，部分模型的表现甚至超越了人类放射科医生。
## Conclusion
RadioRAG展示了在放射学问答中通过集成实时领域特定数据来提升LLM准确性和真实性的潜力，有助于改善LLM在特定领域的问答表现，特别是在乳腺成像和急诊放射学领域。尽管不同模型之间的效果存在差异，但总体上，RadioRAG为提高放射学领域LLM的准确性和事实性提供了一种有效的方法。
# 146. `cs.AI` - 离散扩散模型中的知情修正器 [PDF](https://arxiv.org/pdf/2407.21243), [HTML](https://arxiv.org/abs/2407.21243)
## Authors
Yixiu Zhao,Jiaxin Shi,Feng Chen,Shaul Druckmann,Lester Mackey,Scott Linderman
## Background
离散扩散已成为在离散域中生成建模的强大框架，但高效地从这些模型中采样仍具挑战性。现有的采样策略在减少采样步骤时，往往难以在计算和采样质量之间取得平衡，即使模型已经很好地学习了数据分布。
## Innovation
本文提出了一种预测修正采样方案，其中修正器受扩散模型的启发，以更可靠地抵消累积的近似误差。为了进一步增强信息修正器的有效性，引入了基于空洞变换器的辅助架构修改和一个简单的定制训练目标。使用合成示例来说明现有采样器的失败模式，并展示了信息修正器如何解决这些问题。在text8和tokenized ImageNet 256x256数据集上，信息修正器能够以更少的错误或更高的FID分数生成出更优质的样本，这突显了信息修正器在离散扩散中实现快速且高保真生成的潜力。
## Conclusion
实验结果证明了信息修正器在离散扩散模型中实现快速且高保真生成的潜力。
# 147. `cs.AI` - 通用的分布外检测及其在视觉语言模型时代的扩展：一项综述 [PDF](https://arxiv.org/pdf/2407.21794), [HTML](https://arxiv.org/abs/2407.21794)
## Authors
Atsuyuki Miyai,Jingkang Yang,Jingyang Zhang,Yifei Ming,Yueqian Lin,Qing Yu,Go Irie,Shafiq Joty,Yixuan Li,Hai Li,Ziwei Liu,Toshihiko Yamasaki,Kiyoharu Aizawa
## Background
分布外（OOD）样本检测对于保证机器学习系统的安全性至关重要，已经促使了OOD检测领域的形成。与其他相关问题如异常检测（AD）、新颖性检测（ND）、开放集识别（OSR）和离群点检测（OD）密切相关。为了统一这些问题，提出了一种泛化的OOD检测框架，对这些问题进行了分类。然而，视觉语言模型（VLM）如CLIP的出现彻底改变了这一范式，模糊了这些领域的界限，再次让研究人员感到困惑。在此背景下，本文展示了一种泛化的OOD检测v2，涵盖了视觉语言模型时代这些领域的发展。该框架表明，随着某些领域的不活跃和整合，挑战性的挑战已经转化为OOD检测和异常检测。
## Innovation
本文首先展示了泛化的OOD检测v2，关注视觉语言模型时代这些领域的演变。突破在于强调这些问题定义、问题设置和基准的显著变化，并提供了一个全面的方法论综述，以阐明这些与OOD检测的关系。最后，探讨了大尺度视觉语言模型（LVLM）时代如GPT-4V的进展。
## Conclusion
本文总结了存在的挑战和未来方向，并为持续的研究提供了新的视角。
# 148. `cs.AI` - 利用联邦学习推进肿瘤学：超越乳腺、肺和前列腺癌边界，系统综述 [PDF](https://arxiv.org/pdf/2408.05249), [HTML](https://arxiv.org/abs/2408.05249)
## Authors
Anshu Ankolekar,Sebastian Boie,Maryam Abdollahyan,Emanuela Gadaleta,Seyed Alireza Hasheminasab,Guang Yang,Charles Beauville,Nikolaos Dikaios,George Anthony Kastis,Michael Bussmann,Sara Khalid,Hagen Kruger,Philippe Lambin,Giorgos Papanastasiou
## Background
联邦学习（FL）作为一种应对集中式机器学习在肿瘤学中局限性的前景广阔的方法，尤其是在解决隐私问题和充分利用多中心的多样化数据方面。本文通过对当前联邦学习在肿瘤学领域的研究进行系统综述，特别是针对乳腺、肺和前列腺癌，旨在评估其在实际临床中的应用和效果。
## Innovation
本文的创新之处在于，它不仅总结了联邦学习在肿瘤学中的最新进展，还对实证研究进行了批判性评价，突出了其在增强机器学习在临床环境中的普适性和性能、以及保护数据隐私方面的作用。研究表明，尽管在可重复性、标准化和方法学方面仍然存在挑战，但联邦学习在利用现实世界数据和解决临床需求方面展示了巨大的潜力，正在逐步替代传统的集中式机器学习方法。
## Conclusion
未来的研究需要集中解决现有挑战，进一步探索更为先进的联邦学习方法，以充分利用数据多样性，并真正发挥前沿联邦学习在肿瘤治疗中的变革潜力。
# 149. `cs.AI` - 通过音频感知风格参考实现风格保留唇动同步 [PDF](https://arxiv.org/pdf/2408.05412), [HTML](https://arxiv.org/abs/2408.05412)
## Authors
Weizhi Zhong,Jichang Li,Yinqi Cai,Ming Li,Feng Gao,Liang Lin,Guanbin Li
## Background
音频驱动的唇动同步近年来因其在多媒体领域的广泛应用而吸引了显著关注。由于每位说话者具有独特的说话风格，相同的发音在不同人身上表现出不同的唇形，这为音频驱动的唇动同步带来了挑战。早期方法通常未建模个人化的说话风格，导致生成的唇动不理想。虽然近期的技术试图通过参考音频信息来指导任意音频的唇动生成，但由于在风格聚合上的不足，他们未能很好地保留每个人的说话风格。本文提出了一种创新的音频感知风格参考方案，该方案有效利用了输入音频和风格参考视频中的参考音频之间的关系，以解决风格保留的音频驱动唇动同步问题。
## Innovation
本文提出了一个音频感知风格参考方案，该方案通过以下方式创新地利用了输入音频和风格参考视频中的参考音频之间的关系，以解决风格保留的音频驱动唇动同步问题：首先开发了一个先进的Transformer模型来预测输入音频对应的唇动，该模型通过交叉注意力层整合了从风格参考视频中获取的风格信息。接着，设计了一个有条件潜扩散模型，通过调制卷积层整合唇动，并通过空间交叉注意力层融合参考面部图像，以更好地生成逼真的说话面部视频，
## Conclusion
大量实验验证了所提出方法在实现精确唇动同步、保留说话风格以及生成高保真、逼真的说话面部视频方面的有效性。
# 150. `cs.AI` - 一种用于缓解基于流量的ML-NIDS的欺骗性对抗攻击的新可操控性得分 [PDF](https://arxiv.org/pdf/2409.07448), [HTML](https://arxiv.org/abs/2409.07448)
## Authors
Mohamed elShehaby,Ashraf Matrawy
## Background
随着网络威胁的变化，保护基于流的机器学习（ML）-网络入侵检测系统（NIDS）免受欺骗性对抗攻击变得至关重要。该文探讨了特征可操控性的问题，并提出了一种新颖的可操控性评分（PS），用于量化NIDS特征在问题空间中被攻击者操纵的易感性。由于网络流量字段受限于特定领域限制和相关性，这使得某些特征难以被欺骗，从而提高了基于流的ML-NIDS的鲁棒性。实验结果表明，在多种ML-NIDS模型和公共数据集上，抛弃或屏蔽高度可操控的特征（高-PS特征）可以维持良好的检测性能，同时显著减少对欺骗性对抗攻击的易感性。这些结果证实，PS能有效识别基于流的NIDS特征在问题空间中的可操控性问题。这种方法利用了基于流的ML-NIDS的领域约束作为对抗性欺骗攻击的轻量级通用防御机制。
## Innovation
本文提出了一种新颖的可操控性评分（PS），通过衡量NIDS特征在问题空间中的可操控性来识别结构上抵抗欺骗性攻击的特征。提出了PS引导的特征选择和特征屏蔽方法，以增强基于流的NIDS的防御能力。实验验证了这种方法的有效性，证明了抛弃或屏蔽高度可操控的特征可以保持检测性能的同时显著降低对欺骗性攻击的易感性。这为抵御针对基于流的ML-NIDS的欺骗性攻击提供了新的防御策略。
## Conclusion
可操控性评分（PS）能够有效识别基于流的NIDS特征在问题空间中的可操控性问题，从而增强其在面对欺骗性对抗攻击时的鲁棒性。本文提出的方法利用了基于流的ML-NIDS的领域约束作为轻量级的通用防御机制，具有一定的创新性和实用性。
# 151. `cs.AI` - 深度图异常检测：综述与新视角 [PDF](https://arxiv.org/pdf/2409.09957), [HTML](https://arxiv.org/abs/2409.09957)
## Authors
Hezhe Qiao,Hanghang Tong,Bo An,Irwin King,Charu Aggarwal,Guansong Pang
## Background
图异常检测（GAD）旨在识别不寻常的图实例（节点、边、子图或图），近年来由于其在广泛应用领域的关键性作用，受到了越来越多的关注。尤其是图神经网络（GNNs），作为深度学习的方法之一，因其在捕捉复杂结构和/或节点属性方面的强大能力，成为GAD的一个有前景的范式。由于大量基于GNN的方法被提出，总结现有GAD研究的方法和发现对解决开放的GAD问题至关重要。然而，现有的GAD综述主要集中在任务特定的讨论上，使得理解现有的方法的技术洞察及其在解决GAD中的独特挑战时的局限性变得困难。因此，本文旨在进行全面综述，包括从三个新的角度（GNN骨骼设计、GAD代理任务设计和图异常度量）对当前的深度GAD方法进行系统审查。同时，本文还提供了关于这些三个角度（13个细粒度的方法类别）的分类，以提供更深入的设计方法及其能力的见解。为了便于实验和验证，本文也总结了一个广泛使用的GAD数据集集合和经验比较。此外，还讨论了多种开放问题以激发未来的高质量研究。
## Innovation
本文提供了一个综合的深度学习方法和基于GNN的GAD方法的系统综述。具体来说，它基于三个新的视角（GNN骨架设计、GAD代理任务设计和图异常度量）为当前的深度GAD方法提供了一个系统审查，并提出了13个细粒度的方法类别来提供关于模型设计及其能力的更多深入见解。此外，还提供了一个不断更新的数据集库，关于算法代码的链接以及经验比较。这为GAD的研究提供了一个全面回顾的角度，有利于不同研究者之间的交流和比较。
## Conclusion
本文提供了一个关于基于深度学习的图异常检测全面回顾。它不仅总结了现有GAD研究的方法和发现，还提供了新的视角和方法分类，从而有助于更深入地理解GAD领域的模型设计及其能力。此外，提供了一个可供更新的数据集库和关于算法代码的链接，以及经验比较，从而进一步促进了GAD领域的研究。最后讨论了多个开放问题，以启发未来高质量的研究工作。
# 152. `cs.AI` - Pap2Pat：基于专利论文对列表导向的长文档专利生成进行基准测试 [PDF](https://arxiv.org/pdf/2410.07009), [HTML](https://arxiv.org/abs/2410.07009)
## Authors
Valentin Knappich,Simon Razniewski,Anna Hätty,Annemarie Friedrich
## Background
大型语言模型（LLMs）在处理长而复杂的技术文本方面仍面临挑战，尤其是在像专利撰写这样昂贵且耗时的过程中。专利文档中，描述部分通常占据了文档的90%以上，但其自动生成的研究仍然不足。专利律师在撰写专利申请时通常会收到保密的发明报告（IRs），这阻碍了对LLM辅助专利撰写的研究所进行。本研究利用出版前的研究论文作为IRs的特点，构建了一个名为PAP2PAT的开放且现实的基准，包含1800个专利-论文对，描述相同的发明。通过这种方法，旨在解决复杂的长文档专利生成任务。
## Innovation
研究提出了基于研究论文的清单指导生成方法，将其作为发明规范用于生成专利描述。通过使用PAP2PAT基准和人工案例研究的广泛评估表明，LLMs能够有效利用论文信息，但仍然难以提供必要的细节。微调可以产生更符合专利风格的语言，但也可能导致更多的虚构内容。
## Conclusion
实验结果表明，虽然LLMs可以利用论文信息进行专利生成，但仍面临提供足够细节的挑战。微调可以提高语言一致性，但也可能导致虚构。研究者已释放了数据和代码，为未来的相关研究提供基础。
# 153. `cs.AI` - 间的锯齿状现象：揭开Adam及其他优化器训练损失振荡的面纱 [PDF](https://arxiv.org/pdf/2410.10056), [HTML](https://arxiv.org/abs/2410.10056)
## Authors
Qi Liu,Wanjing Ma
## Background
在使用自适应梯度优化器（如Adam优化器）进行训练时，研究者观察到了一种反复出现的训练损失模式，称之为“_epochal锯齿状现象（ESP）_”。这种模式在每个epoch的开始时，损失急剧下降，随后逐渐升高，形成锯齿状的损失曲线。而该现象不仅在Adam优化器中显著，其他优化器如RMSProp也有轻微显现。为了深入理解这一现象，研究者从关键因素如Adam的eta参数、批量大小、数据洗牌及样本替换等方面进行了实证分析。研究发现，这种现象是由于自适应学习率调整控制的第二矩估计所引起。尤其是，数据洗牌时模型立即重新暴露于样本的现象，在每个epoch开始时使得模型更倾向于学习或记忆。研究还表明，较小的eta2值会加剧ESP现象，但其也起到了正则化作用。尽管ESP本身并不一定标志着过拟合，但更大的模型容量会放大这一现象。为了进一步验证这一发现，研究者通过高维二次最优化任务重现了ESP，证实了这一模式的普遍性。相关的实验代码可以在此处获得。
## Innovation
研究揭示了在使用自适应梯度优化器（如Adam优化器）训练时出现的一种反复出现的训练损失模式，称为“_epochal锯齿状现象（ESP）_”。研究不仅阐明了这种现象在Adam优化器中最为显著，也在其他优化器中部分存在。研究还深入分析了其背后的原因，包括自适应学习率调整和数据洗牌时立即重新暴露于样本的现象，并揭示了较小eta2值对该现象的影响。研究还通过高维二次最优化任务重现了ESP，表明这一现象的真实性与普遍性。
## Conclusion
研究结论强调了_“_epochal锯齿状现象（ESP）_”_在优化训练损失中的重要性，并且数据分析揭示了这一现象是由优化器的自适应学习率调整和数据洗牌等环节的交互影响所导致。这一现象虽然未必意味着过拟合，但确实需要我们在训练过程中关注和考虑。相关实验代码可供其他研究者重现实验进行验证。
# 154. `cs.AI` - Math Neurosurgery: 仅使用前向传递隔离语言模型的数学推理能力 [PDF](https://arxiv.org/pdf/2410.16930), [HTML](https://arxiv.org/abs/2410.16930)
## Authors
Bryan R. Christ,Zack Gottesman,Jonathan Kropko,Thomas Hartvigsen
## Background
数学推理是大型语言模型（LLM）研究的一个活跃领域，因为它标志着人工智能的能力，并且在数学教育等多个领域具有重要意义。然而，很少有研究探讨数学推理是如何在LLM参数中编码的，这也使得是否可以孤立数学推理技能成为可能。这将允许有目标的干预以提高数学表现，而不改变非数学行为，并帮助理解模型是如何编码数学推理的。
## Innovation
我们引入了Math Neurosurgery（MathNeuro），一种高效的方法，仅通过前向传递就孤立出LLM中的特定数学参数。MathNeuro通过对权重和激活进行计算来确定参数的重要性，并通过过滤与一般语言任务相关的参数来专项隔离数学参数。通过剪枝MathNeuro识别的参数，一项研究可以删除LLM的数学推理能力，同时不会显著影响其一般语言能力。调整识别的参数规模可以提高预训练或根据指令调优的LLM在GSM8K和MATH等评测集上的表现，最高可提高35%，且不会改变非数学行为。此外，MathNeuro还显示出高效率：其大部分效果仅使用一个样本即可确定数学特定参数。MathNeuro指出了未来工作中针对数学特定参数进行干预的潜力。
## Conclusion
MathNeuro通过仅使用前向传递来识别和隔离语言模型中的数学推理能力，提高模型在数学任务上的表现，无需影响其通用语言能力。这种方法在数据效率方面表现出色，能够显著提升模型在数学任务上的表现，并且证明了未来针对数学特定参数进行干预的可能性。
# 155. `cs.AI` - LLäMmlein：从零开始构建的透明、紧凑且具有竞争力的德语专用语言模型 [PDF](https://arxiv.org/pdf/2411.11171), [HTML](https://arxiv.org/abs/2411.11171)
## Authors
Jan Pfister,Julia Wunderle,Andreas Hotho
## Background
该研究背景在于创建高质量的德语专用语言模型，以支持德语自然语言处理（NLP）研究。当前，德语语言模型领域缺乏高质量且开放的模型资源，限制了德语NLP的发展。因此，本文旨在构建全新的德语专用语言模型，并将其开源提供给德语NLP研究社区，促进相关研究的进步和发展.
## Innovation
本文的创新之处在于透明从零开始构建了两个全新的德语专用模型，即LLäMmlein 120M和1B，并且提供了训练数据。整个模型训练过程包括了详尽的数据预处理、自定义德语分词器、模型训练及性能评估。此外，通过SuperGLEBer基准测试实时监控模型的学习动态，并与现有最先进的模型进行比较，证明了所构建模型的竞争性，特别是在与参数量相似的模型对比中表现优异.
## Conclusion
研究结果表明，模型的质量随规模增长而提升，但在某些任务上的性能改进可能较早趋于稳定。这一发现为未来模型开发中的资源配置提供了宝贵的见解。所发布的LLäMmlein模型和训练数据为德语NLP研究领域带来了新的机会和挑战，有助于提高德语自然语言处理的整体水平。
# 156. `cs.AI` - 基于知识图谱和触觉表示的语义-几何-物理驱动的机器人操作技能转移 [PDF](https://arxiv.org/pdf/2411.11714), [HTML](https://arxiv.org/abs/2411.11714)
## Authors
Mingchao Qi,Yuanjin Li,Xing Liu,Zhengxiong Liu,Panfeng Huang
## Background
开发能够在未结构化环境中操作的通用机器人系统是一项重大挑战，尤其是当执行的任务通常具有长期展望和丰富的接触特点，这就要求在不同任务场景中高效地转移技能。因此，本文探讨了知识图谱为基础的技能库构建方法，并通过任务图、场景图和状态图来层次组织操作知识，代表任务特定和场景特定的信息。此外，引入了状态图来促进高层任务规划和低层场景信息之间的交互。基于此基础，进一步提出了基于技能库和触觉表示的新型层次技能转移框架，整合了高层推理和低层执行的精确性。在任务层面上，利用大规模语言模型（LLMs）结合上下文学习和四阶段思维链提示范式来实现子任务序列转移。在动作层面上，基于技能库开发了一种基于启发式路径规划算法的自适应轨迹转移方法。在物理层面上，提出了基于触觉表示的自适应轮廓提取和姿态感知方法，能够从视觉-触觉图像中动态获取高精度的轮廓和姿态信息，并调整接触位置和姿态参数以确保新环境下的技能有效性。实验结果展示了提出的方法在不同任务场景下实现技能转移和适应性能力
## Innovation
本文提出的基于知识图谱的技能库构建方法和触觉表示的技能转移框架具有以下创新性：1）通过任务图和场景图层次组织操作知识，增强知识表达的精细化和泛化能力；2）结合大规模语言模型和四阶段思维链提示范式，实现子任务序列的有效转移；3）基于技能库的自适应轨迹转移方法，结合启发式路径规划算法提高动作执行的灵活性；4）提出基于触觉表示的自适应轮廓提取和姿态感知方法，动态获取高精度的物理信息，以确保技能在新环境中的有效性。这些方法显著提高了机器人在不同任务场景中的适应性和技能迁移能力
## Conclusion
本文通过提出基于知识图谱的技能库构建方法和触觉表示的技能转移框架，实现了语义-几何-物理驱动的机器人操作技能转移。该方法通过层次组织操作知识、结合大规模语言模型和触觉表示技术，提高了机器人在不同任务场景中的技能迁移能力和适应性，增强了机器人的操作灵活性和环境适应性。实验结果验证了该方法的有效性，表明它在实现技能自动转移方面具有巨大潜力。未来可进一步探索更多应用场景和技术优化，以提高机器人操作的效率和可靠性
# 157. `cs.AI` - 对比相似性感知的双路径Mamba方法用于多变量时间序列节点分类 [PDF](https://arxiv.org/pdf/2411.12222), [HTML](https://arxiv.org/abs/2411.12222)
## Authors
Mingsen Du,Meng Chen,Yongjian Li,Xiuxin Zhang,Jiahui Gao,Cun Ji,Shoushui Wei
## Background
多变量时间序列（MTS）数据来源于多个传感器在工程应用、健康监测和物联网等领域的应用，具有时间变化和高维特征。近年来，许多研究探讨了MTS中的长程依赖性和相似性，但由于其时间变化和高维性，长程依赖性难以建模，高维性使得高效获取相似性变得困难。因此，为了应对这些问题，我们提出了一种名为CS-DPMamba的方法，通过对比相似性感知的双路径方法进行MTS节点分类。这种方法利用时间对比学习模块获取MTS表示，并利用快速动态时间弯曲（FastDTW）构建MTS表示之间的相似矩阵，同时利用DPMamba考虑MTS的双向性质，捕捉数据中的长程和短程依赖性，最后通过柯尔莫哥洛夫-阿诺尔德网络增强图同构网络完成矩阵和MTS节点分类任务，从而实现精确的MTS节点分类。该方法在东安格利亚大学（UEA）的多个MTS数据集上进行了实验，涵盖了多种应用场景，结果显示该方法在监督和半监督实验中都在MTS分类任务中展示了优越性。
## Innovation
本文提出了一个名为CS-DPMamba的方法，这是一个对比相似性感知的双路径系统。首先利用时间对比学习模块获取时间序列的表示，然后利用快速动态时间弯曲（FastDTW）构建表示间的相似矩阵，接着通过DPMamba捕捉时间序列数据的双向依赖性，最后借助柯尔莫哥洛夫-阿诺尔德网络增强图同构网络完成矩阵和节点分类任务。这种方法综合考虑了长程依赖性和动态相似性特征，解决了传统方法在时间变化和高维性上的限制，为MTS节点分类提供了一种新的解决方案。
## Conclusion
通过全面考虑长程依赖性和动态相似性特征，我们实现了精确的MTS节点分类。我们在东安格利亚大学（UEA）的多个MTS数据集上进行了实验，结果表明我们的方法在监督和半监督实验中的MTS分类任务中表现出优越性。
# 158. `cs.AI` - 主题和形状图在半监督多变量时间序列分类中的异质关系 [PDF](https://arxiv.org/pdf/2411.18043), [HTML](https://arxiv.org/abs/2411.18043)
## Authors
Mingsen Du,Meng Chen,Yongjian Li,Cun Ji,Shoushui Wei
## Background
多变量时间序列（MTS）分类在工业、医疗保健和金融等领域广泛应用，旨在从复杂的时序数据中提取关键特征，以实现准确的决策和预测。然而，现有的MTS分类方法在有效建模高维数据以及缺乏标注数据的情况下效果不佳，导致分类性能差。
## Innovation
本文提出了一种基于主题和形状图的异质关系的半监督MTS分类方法。该方法通过结合不同类型的附加信息来获取稀疏的MTS表示，并使用软动态时间规整构建相似度图来捕获这些表示之间的关系。进一步地，学习不同主题类型的形状图，并将主题特征及其形状图作为附加信息来进一步细化相似度图，最终生成一个异质图。通过这种方法将数据集转化为异质图，并集成多种附加信息，从而实现精确的半监督节点分类。实验结果表明，该方法在人类活动识别、睡眠阶段分类和东英吉利大学数据集上的表现优于当前最先进的方法，验证了其优越性。
## Conclusion
本文提出的方法通过将MTS数据集转化为异质图，整合多种附加信息，从而实现了精确的半监督MTS分类，超越了现有最先进的方法。
# 159. `cs.AI` - FLARE：针对后门攻击的通用数据集净化方法 [PDF](https://arxiv.org/pdf/2411.19479), [HTML](https://arxiv.org/abs/2411.19479)
## Authors
Linshan Hou,Wei Luo,Zhongyun Hua,Songhua Chen,Leo Yu Zhang,Yiming Li
## Background
深度神经网络（DNNs）容易遭受后门攻击，攻击者在数据集中注入由攻击者指定的触发器，植入隐藏后门，利用这些后门对模型预测进行恶意操控。当前先进的数据集净化方法依赖于一个假设，即后门攻击中触发器与目标标签之间的连接比良性特征更容易学习。然而，这种假设并不总成立，尤其是在全对全（A2A）和未定向（UT）攻击情况下，这种净化方法效果较差，因为它基于的假设并未实际成立。
## Innovation
作者提出了FLARE，一种通用的净化方法来对抗各种后门攻击。FLARE聚合所有隐藏层中的异常激活来构建聚类表示。FLARE还开发了一种自适应子空间选择算法以分离最优的分割空间，从而将整个数据集分为两个聚类。通过评估每个聚类的稳定性，FLARE将稳定度较高的聚类识别为中毒数据。实验证明，FLARE对22种代表性后门攻击（包括全对一、全对全和未定向攻击）有效，并且对适应性攻击具有鲁棒性。
## Conclusion
FLARE被广泛验证为有效抗后门攻击的通用数据净化方法，并且在多种攻击情况下表现稳定，其代码可以在BackdoorBox和backdoor-toolbox获取。
# 160. `cs.AI` - REVOLVE：通过跟踪文本优化中的响应演变来优化AI系统 [PDF](https://arxiv.org/pdf/2412.03092), [HTML](https://arxiv.org/abs/2412.03092)
## Authors
Peiyan Zhang,Haibo Jin,Leyang Hu,Xinnuo Li,Liying Kang,Man Luo,Yangqiu Song,Haohan Wang
## Background
近年来，大型语言模型（LLMs）在自然语言处理和工具交互方面的应用显著提升了LLM基系统执行复杂任务的能力。然而，优化这些系统以适应特定任务仍然充满挑战，通常需要手动干预如提示工程和超参数调整。现有的自动优化方法，如基于文本反馈的技术（例如TextGrad），往往关注即时反馈，类似于传统的数值梯度下降中使用的即时梯度。然而，仅依赖这种反馈可能会限制优化过程，因为响应调整要么太小，要么波动不规则，从而可能减缓甚至停滞优化过程。面对这些挑战，需要更具适应性的方法，尤其是在系统响应缓慢或不可预测变化的情况下。因此，本文提出了REVOLVE，一种跟踪LLM系统中“R”（响应）“E”（演变）“V”（进展）“O”（优化）“L”（学习）“V”（变化）的方法，通过关注响应随时间的演变，REVOLVE能够更稳定、更有效地进行优化，逐步做出深思熟虑的调整。实验结果显示，与竞争性基线相比，REVOLVE在提示优化、解决方案完善和代码优化中有显著提升，分别提高了7.8%、20.72%和29.17%，且收敛速度快，节省了大量计算资源。除了实际贡献，REVOLVE还揭示了利用成熟优化原则中的丰富知识来增强LLM系统的前景，开辟了这一跨学科领域的进一步研究方向。
## Innovation
本文提出了一种名为REVOLVE的优化方法，专门针对LLM系统中响应随时间的演变进行跟踪和优化。通过这种方法，优化过程可以更加稳定和高效，逐步调整更为审慎，而非依赖即时反馈。革命性的贡献在于，它通过观察系统响应的变化来优化，而不是仅仅依赖于短期的反馈。这种方法不仅能显著提高三种类型的优化效果，还能加快收敛速度，从而节省计算资源。
## Conclusion
实验结果表明，REVOLVE在提示优化、解决方案完善和代码优化方面表现出色，与现有基线方法相比有显著的改进，特别是在迭代次数减少和节省计算资源方面。此外，这种方法有望进一步应用于LLM优化，为未来的跨学科研究指明了方向。
# 161. `cs.AI` - 在融合高分辨率光学和SAR卫星影像、地面运动和土壤数据的变换器框架下的多类震后建筑评估 [PDF](https://arxiv.org/pdf/2412.04664), [HTML](https://arxiv.org/abs/2412.04664)
## Authors
Deepank Singh,Vedhus Hoskere,Pietro Milillo
## Background
地震后的及时准确的建筑损害评估对于有效的灾后响应和恢复至关重要。传统初步损害评估往往依赖于逐户的手动检查，不仅耗时，而且还存在显著的安全风险。研究者们一直在研究如何利用卫星影像结合启发式和机器学习方法来加速这一过程。这些方法输出的是区块级或多类建筑的二元或多元损害状态。然而，现有方法的性能限制了它们的实际应用。现有研究未能充分结合建筑特定的元数据以提升模型的准确性和泛化能力，尤其是针对不同地区的适用性不足。此外，对于不同级别建筑损害特征重要性的详细分析尚未充分进行，这影响了模型决策的透明度和可靠性。
## Innovation
本文提出了一种结合高分辨率震后卫星影像与特定建筑元数据的元数据增强的变压器框架。该模型在2023年2月6日土耳其-叙利亚地震后的建筑多类损害识别中取得了最先进的性能。通过引入特定建筑元数据，如地震强度指标、土壤特性和SAR损害代理图，模型不仅提高了准确性和区分不同损害级别的能力，还增强了不同地区的普适性。此外，研究中进行了详细的分类特征重要性分析，揭示了各个元数据特征如何独立地为每种损害级别的预测作出贡献，从而加深了对模型决策机制的理解。
## Conclusion
通过联合卫星影像与元数据，本文提出的方法能够实现更快、更准确的建筑损害评估，进而为特定级别多类建筑构建精确的评估，提高灾害响应效率和恢复速度，支持受震地区社区的恢复工作。
# 162. `cs.AI` - 大型语言模型用于自动化文献综述：关于参考生成、摘要写作和综述构成的评估 [PDF](https://arxiv.org/pdf/2412.13612), [HTML](https://arxiv.org/abs/2412.13612)
## Authors
Xuemei Tang,Xufeng Duan,Zhenguang G. Cai
## Background
大型语言模型（LLMs）已经成为了自动化撰写文献综述的一个潜在解决方案，涉及文献的收集、组织和总结等复杂过程。当前尚不清楚先进的LLMs在自动化撰写全面可靠文献综述方面的性能如何。这项研究提出了一种框架，以自动评估LLMs在文献撰写三个关键任务上的表现：参考生成、文献摘要和文献综述构成。提出了多维度的评估指标，以检测生成的参考文献中的虚构率，并测量文献摘要和综述与人类写作版本在语义覆盖度和事实一致性方面的差异。实验结果显示，即使是最先进的模型也可能生成虚构的参考文献，这与近期进展相矛盾。此外，研究发现不同模型在撰写文献综述方面的表现因学科不同呈现出差异性。研究结果突显了进一步研究和开发以提高LLMs在自动化学术文献综述中的可靠性的必要性。
## Innovation
这项研究引入了一种框架，用于自动评估LLMs在参考生成、文献摘要和文献综述构成方面的表现。提出了多维度的评估指标，以检测生成的参考文献中的虚构率，并测量文献摘要和综述与人类写作版本在语义覆盖度和事实一致性方面的差异。研究揭示了不同模型在不同学科中的表现差异，强调了进一步提高LLMs在自动化学术文献综述中的可靠性的必要性。
## Conclusion
尽管取得了进展，但先进的LLMs在生成虚构的参考文献方面仍然存在挑战，不同模型在撰写文献综述方面表现不一。这些研究结果强调了进一步研究和开发以提高LLMs在自动化学术文献综述中的可靠性的必要性。
# 163. `cs.AI` - SurgSora: 对象感知的生成模型在可控制手术视频生成中的应用 [PDF](https://arxiv.org/pdf/2412.14018), [HTML](https://arxiv.org/abs/2412.14018)
## Authors
Tong Chen,Shuya Yang,Junyi Wang,Long Bai,Hongliang Ren,Luping Zhou
## Background
现有的手术视频生成方法在精细动作控制和真实感方面存在不足，无法有效提升医疗教育和研究的效果。现有的方法通常对物体进行不分类处理或依赖于准确的分割掩模，这些方法缺乏在单张输入帧和用户指定的动作线索下生成高保真、可控制的手术视频的能力。SurgSora框架旨在解决这些问题，通过利用自预测的物体特征和深度信息来优化RGB颜色和光流，从而实现精确的视频合成。
## Innovation
SurgSora框架包含三个关键模块：(1) 双语义注入器，从单个输入帧中提取对象特定的RGB-D特征和分割线索，增强空间表示；(2) 解耦光流映射器，将多尺度光流与语义特征融合，实现逼真的运动动态；(3) 轨迹控制器，在稀疏光流估计基础上允许用户控制物体的移动。通过在稳定的视频扩散条件中使用这些增强的特征，SurgSora实现了在手术视频合成中前所未有的视觉真实性和可控性。
## Conclusion
SurgSora通过广泛的定量和定性比较展示了其在视觉真实性和控件方面的优越性，其生成的视频具有高度的真实感，得到了专家外科医生的进一步认可，在手术训练和教育方面具有巨大潜力。
# 164. `cs.AI` - 将AI研究与临床编码工作流需求对齐：基于美国数据的八个建议 [PDF](https://arxiv.org/pdf/2412.18043), [HTML](https://arxiv.org/abs/2412.18043)
## Authors
Yidong Gan,Maciej Rybinski,Ben Hachey,Jonathan K. Kummerfeld
## Background
临床编码对于医疗账单和数据分析至关重要。然而，手动临床编码劳动密集且容易出错，因此科研人员一直在研究如何完全自动化这一过程。然而，基于美国英语的电子健康记录以及对这些记录的自动编码研究，发现当前广泛使用的一些评估方法不能反映实际临床环境。例如，只关注最常用的前50个编码是简化处理，因为实际中存在成千上万的编码。研究者分析了这些问题并提出了八个具体的建议，旨在改善当前评价方法，以及提出了新的基于AI的方法，以辅助临床编码流程的改善.
## Innovation
该论文指出当前广泛使用的评估方法存在局限性，并提出了八大具体建议，以改善评价方法，使其更贴近实际情况；提出了新的基于AI的方法，为临床编码工作流提供了新的解决方案和思路.
## Conclusion
该论文基于美国的数据分析与批判性回顾，提出了将AI研究与实际临床编码工作流需求对齐的八大建议，旨在为未来的临床编码自动编码研究提供指导，改进评价方法，并提出新的AI辅助方法.
# 165. `cs.AI` - LLMs可以问出好问题吗？ [PDF](https://arxiv.org/pdf/2501.03491), [HTML](https://arxiv.org/abs/2501.03491)
## Authors
Yueheng Zhang,Xiaoyuan Liu,Yiyou Sun,Atheer Alharbi,Hend Alzahrani,Tianneng Shi,Basel Alomair,Dawn Song
## Background
本文评估了大型语言模型（LLMs）生成的问题，并将其与人类编写的问题进行了比较，重点是六个维度：问题类型、问题长度、上下文覆盖范围、可回答性、不常见性和所需答案长度。研究涵盖了两个开源和两个专有最先进的模型，揭示了与问答任务中常见的位置偏差相比，LLM生成的问题倾向于需要更长的描述性答案，并且在上下文聚焦方面更均匀。这些发现提供了关于LLM生成问题的独特特性的见解，并为未来关于问题质量及其下游应用的工作提供了信息。
## Innovation
研究跨六个维度评估了LLM生成问题的质量，揭示了LLM生成的问题具有需要更长描述性答案和更均匀的上下文焦点等特点，不同于问答任务中的位置偏差。这凸显了LLM生成问题的独特性，并为后续研究和应用提供了新的方向。
## Conclusion
LLM生成的问题在问题类型、上下文覆盖范围、可回答性、不常见性和所需答案长度等方面表现出独特的特征。这种差异性的特点提供了一些至关重要的洞见，有助于改善未来的研究和应用，特别是在问题质量方面。
# 166. `cs.AI` - 大型语言模型在解决主观任务中的视角转换 [PDF](https://arxiv.org/pdf/2501.09265), [HTML](https://arxiv.org/abs/2501.09265)
## Authors
Xiaolong Wang,Yuanchi Zhang,Ziyue Wang,Yuzhuang Xu,Fuwen Luo,Yile Wang,Peng Li,Yang Liu
## Background
大型语言模型（LLMs）已经在自然语言处理领域产生了革命性的影响，并在多种任务中取得了显著的进展。然而，在一些主观任务上，LLMs的表现仍然有限，尤其是在需要特定视角以更好地理解和响应上下文的问题上。例如，在某些情况下，LLMs以专家视角回答问题可能表现更好；而在其他情况下，从第三视角回答问题可能会提供更准确的响应。本研究即是在这种背景下，探讨如何通过给LLMs引入视角转换能力以提升其在主观任务中的表现。
## Innovation
本研究提出了Reasoning through Perspective Transition（RPT）方法，该方法基于上下文学习机制，使LLMs能够根据需要动态地选择直接、角色或第三人称视角，以解决对应的主观问题。通过使用包括GPT-4、GPT-3.5、Llama-3、Qwen-2在内的多种闭源和开源LLMs，在总共12项主观任务中的广泛实验表明，RPT方法在处理主观任务时显著优于仅使用单一固定视角的方法，如逐步推理提示和专家提示，展示了LLMs在不同问题上适应不同视角以提供准确和上下文相关的响应的能力。
## Conclusion
通过实验结果表明，RPT方法在处理主观任务时，使LLMs能够更加灵活地根据不同任务需求选择适当视角，从而提供更准确和合适的响应，显著优于现有方法。
# 167. `cs.AI` - 弱表示塑造弱到强泛化：理论洞察与经验预测 [PDF](https://arxiv.org/pdf/2502.00620), [HTML](https://arxiv.org/abs/2502.00620)
## Authors
Yihao Xue,Jiping Li,Baharan Mirzasoleiman
## Background
弱到强泛化（W2SG）是弱模型监督更强模型的一种重要类比，用于理解人类如何在未来引导超越人类智能的过程。尽管最近的研究提供了该现象的一些理论见解，但弱模型和强模型之间互动的具体机制仍然不清楚。该论文通过理论分析探讨了W2SG，并提出了一种基于弱强模型内部表示主要成分衍生核的理论框架，找到了捕捉弱模型无法学习但强模型可以学习的维度空间。通过这种框架，可以衡量强模型在弱监督下的性能差距，并且为纠正弱监督中的某些误差提供新的视角，而不必担心过拟合问题。实验结果表明，这种理论具有实际意义，无需标签即可预测W2SG表现趋势，特别是在使用转录体和5个NLP任务涉及52个LLM的实验中得到验证。
## Innovation
论文提出了一种基于弱强模型内部表示主要成分的理论分析框架，该框架能够通过定义一个空间来捕捉弱模型无法学习但强模型可以学习的内容，从而量化强模型由于弱监督造成的性能损失。此外，该理论还揭示了如何通过强模型来纠正某些弱监督中的错误，而无需担忧过拟合问题，提供了无需标签即可预测W2SG表现趋势的代表基于的度量标准。
## Conclusion
该论文通过理论方法深入探讨了弱到强泛化现象，并提出了一种新的分析框架，通过这种框架，可以更好地理解弱强模型之间的互动机制，进一步提高了对弱到强泛化的预测精度和实际应用价值。
# 168. `cs.AI` - Task-Aware Virtual Training: Enhancing Generalization in Meta-Reinforcement Learning for Out-of-Distribution Tasks [PDF](https://arxiv.org/pdf/2502.02834), [HTML](https://arxiv.org/abs/2502.02834)
## Authors
Jeongmo Kim,Yisak Park,Minung Kim,Seungyul Han
## Background
元强化学习旨在开发能够在未见过的任务中进行泛化的策略。虽然基于上下文的元强化学习方法能够通过任务潜在特征改进任务表示，但在面对分布外（OOD）任务时常常表现不佳。
## Innovation
本文提出了Task-Aware Virtual Training（TAVT）算法，该算法利用基于度量的学习方法准确捕捉任务特性，包括训练和OOD场景，并通过状态正则化技术减轻状态变化环境中的过估计错误。研究表明，TAVT方法在MuJoCo和MetaWorld环境中的泛化能力显著提升，特别是在处理OOD任务时。
## Conclusion
实验结果表明，TAVT显著提升了元强化学习在多种MuJoCo和MetaWorld环境中的OOA任务泛化能力。研究代码公开于此链接：this https URL.
# 169. `cs.AI` - Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning [PDF](https://arxiv.org/pdf/2502.02844), [HTML](https://arxiv.org/abs/2502.02844)
## Authors
Sunwoo Lee,Jaebak Hwang,Yonghyeon Jo,Seungyul Han
## Background
传统鲁棒方法在多智能体强化学习（MARL）中常常无法应对协调对手攻击，在合作场景下的表现较差。因此，本文探讨了这一局限性，并提出了一种借鉴狼群狩猎策略的Wolfpack恶意攻击框架，该框架旨在破坏初始智能体及其辅智能体的合作。此外，本文还引入了Wolfpack-对抗学习（WALL）框架，通过培养系统范围内的合作来训练鲁棒的MARL策略，以抵御所提出的Wolfpack攻击。实验结果表明，Wolfpack攻击具有毁灭性的破坏力，而WALL能够显著提高系统的魯棒性。本文的代码可在提供的链接中获取。
## Innovation
1. 提出Wolfpack Adversarial Attack框架，依据狼群的狩猎策略来发起攻击，针对初始智能体及其辅智能体进行针对性破坏协作。2. 发展WALL框架，通过促进系统范围内的合作来训练鲁棒的MARL策略，以防御Wolfpack攻击。
## Conclusion
实验结果显示，Wolfpack攻击对系统造成了极大的破坏，而WALL框架通过增强系统合作有效提升了MARL策略的鲁棒性。
# 170. `cs.AI` - CODESYNC：大规模语言模型与动态代码演进的大规模同步 [PDF](https://arxiv.org/pdf/2502.16645), [HTML](https://arxiv.org/abs/2502.16645)
## Authors
Chenlong Wang,Zhaoyang Chu,Zhengxiang Cheng,Xuyi Yang,Kaiyue Qiu,Yao Wan,Zhou Zhao,Xuanhua Shi,Dongping Chen
## Background
大规模语言模型（LLMs）在软件工程中表现出色，但在适应不断变化的代码知识方面面临挑战，特别是在第三-party库API的频繁更新方面。这种局限性源于静态预训练数据集，导致生成非执行代码或安全性与效率不佳的实现。
## Innovation
该论文介绍了CODESYNC，一种数据引擎，用于识别过时的代码模式并实时收集来自Python第三方库的代码知识更新。基于CODESYNC，开发了CODESYNCBENCH，这是一个全面的基准测试，用于评估LLMs跟踪代码演进的能力，涵盖了六个Python库的220个API的真实更新。评估包括3300个测试用例和包含2200个训练样本的更新感知指令调优数据集。实验结果显示，即使有先进的知识更新方法（如DPO、ORPO和SimPO）的支持，现有的14种最先进的LLMs在动态代码演进方面仍然面临挑战。
## Conclusion
我们相信，我们的基准可以为未来实时代码知识更新的有效方法的发展提供坚实的基础。实验代码和数据集已公开。
# 171. `cs.AI` - 在联运云中使用AI_INFN平台支持基础科学领域的机器学习开发 [PDF](https://arxiv.org/pdf/2502.21266), [HTML](https://arxiv.org/abs/2502.21266)
## Authors
Lucio Anderlini,Matteo Barbetti,Giulio Bianchini,Diego Ciangottini,Stefano Dal Pra,Diego Michelotto,Carmelo Pellegrino,Rosa Petrini,Alessandro Pascolini,Daniele Spiga
## Background
目前机器学习（ML）正在变革科学家们在设计、开发和部署数据密集型软件的方式。然而，采用ML技术也在计算基础设施方面提出了新的挑战，尤其是在提供和协调访问硬件加速器方面，这些硬件用于开发、测试和生产中。意达物理与核物理研究所（INFN）资助的AI_INFN项目旨在通过多方面支持，推动ML技术在INFN应用案例中的采用，其中包括提供定制化的人工智能计算资源，使用云原生解决方案在INFN云中高效分享硬件加速器，确保研究所的各种研究活动多样化不受损害。该项目的一个重点是开发一个Kubernetes平台，以便轻松开发基于GPU的数据分析工作流，并在异构分布计算资源上实现扩展，这些计算资源可通过interLink提供商以虚拟容器的形式进行连接和扩展。
## Innovation
该项目在联运云中，利用AI_INFN平台支持使用机器学习技术进行基础科学研究的开发。通过提供定制化的计算资源和利用云原生解决方案，有效共享硬件加速器，同时保持研究活动的多样性。此外，开发的基于Kubernetes的平台支持GPU驱动的数据分析工作流在异构分布式计算资源上的可扩展性，并支持虚拟Kubelets形式的资源联邦。
## Conclusion
该项目通过AI_INFN平台成功地支持了联运云中机器学习技术的应用，解决了计算资源供应和协调的问题，增强了基于GPU的数据分析工作流在异构分布式计算环境中的可扩展性，为物理和核物理研究提供了有力的技术支持。
# 172. `cs.AI` - 机器学习者应承认大规模语言模型作为个人数据的法律影响 [PDF](https://arxiv.org/pdf/2503.01630), [HTML](https://arxiv.org/abs/2503.01630)
## Authors
Henrik Nolte,Michèle Finck,Kristof Meding
## Background
大多数大型语言模型（LLMs）在训练过程中会一定程度地记忆训练数据。因此，即使只记住少量的个人信息，这些数据通常仍会受到数据保护法律的约束。一旦一个个体被识别或可识别，这些模型需要遵守欧盟一般数据保护条例（GDPR）的要求，涵盖了从数据收集和整理到模型部署等全生命周期。论文引入了重新提出的核心观点，并展示了LLMs自身可能作为个人数据的角色，触发了一系列的数据保护问题，如主体权利（访问权、更正权或删除权）等，这些权利也延伸至AI模型内部的信息。
## Innovation
论文提出，机器学习研究人员在整个ML开发生命周期中必须承认LLMs作为个人数据的法律影响。为了解决这些法律问题，论文提出不同的方案供机器学习研究社区应对，并强调需要增强法律领域与机器学习社区之间的互动，进而提高数据保护法律与LLMs技术能力的契合度。
## Conclusion
论文强调了机器学习者应承认以及应对LLMs作为个人数据的法律影响的重要性，并提出了未来研究的方向，即通过改善法律与技术之间的交互来增强数据保护的有效性。
# 173. `cs.AI` - PsychBench: 评估辅助精神科临床实践的大规模语言模型性能的全面和专业基准 [PDF](https://arxiv.org/pdf/2503.01903), [HTML](https://arxiv.org/abs/2503.01903)
## Authors
Shuyu Liu,Ruoxi Wang,Ling Zhang,Xuequan Zhu,Rui Yang,Xinzhu Zhou,Fei Wu,Zhi Yang,Cheng Jin,Gang Wang
## Background
大语言模型（LLMs）有潜力解决精神科临床实践中医疗资源短缺和诊断一致性和不足的问题。然而，缺乏一个强大的、全面的基准评估框架来评估LLMs在真实精神科临床环境中的效果，这阻碍了面向精神科应用的专业LLMs的发展。因此，为了填平这一空白，本文通过结合精神科的实际需求和临床数据，提出了一个基准评估系统PsychBench，用于评估LLMs在精神科临床环境中的实际表现。
## Innovation
本文提出了一个名为PsychBench的基准评估系统，用以评估16种LLMs在精神科临床环境中的实际表现。该系统考虑了提示设计、思维链推理、输入文本长度和领域特定知识微调等因素对模型性能的影响。通过深入的错误分析，指出了现有模型的优势和潜在局限性，并提出了改进方向。同时，进行了一项涉及60名不同级别的精神科医生的临床读者研究，进一步探讨了现有LLMs作为不同级别精神科医生辅助工具的实际效益。研究表明，尽管现有模型具有显著潜力，但尚不足以成为精神科临床实践中的决策工具。作为辅助工具，LLMs可以显著支持初级精神科医生的工作效率和整体临床质量。
## Conclusion
通过定量和读者评估，研究表明现有模型虽具有显著潜力，但在精神科临床实践中尚未达到决策工具的标准。作为辅助工具，LLMs可以显著提升初级精神科医生的工作效率和临床质量。为了推动该领域研究的发展，作者将数据集和评估框架公开，希望促进LLMs在精神科临床实践中的应用。
# 174. `cs.AI` - EgoBlind: 向盲人提供第一人称视觉辅助 [PDF](https://arxiv.org/pdf/2503.08221), [HTML](https://arxiv.org/abs/2503.08221)
## Authors
Junbin Xiao,Nanxin Huang,Hao Qiu,Zhulin Tao,Xun Yang,Richang Hong,Meng Wang,Angela Yao
## Background
目前，多模态大语言模型（MLLMs）能够提供多种视觉辅助，但缺乏专门针对盲人群体的第一人称视角（egocentric）视频问答数据集。现有的视觉辅助系统大多依赖于预先训练的数据，无法充分考虑到盲人实际使用场景中的独特需求和挑战。因此，迫切需要构建一个专为盲人设计的多模态数据集，以评估当前最先进的MLLMs在视觉辅助方面的性能。
## Innovation
EgoBlind是第一个来自盲人视角的第一人称视频问答数据集，包含了1392个视频，记录了盲人的日常生活，并包含了5311个直接由盲人提出或验证的问题，旨在评估MLLMs的辅助能力。该数据集提供了每个问题的平均3个参考答案，以减轻主观评价的局限性。通过EgoBlind数据集，研究人员对16款先进的MLLMs进行了全面评估，揭示了这些模型在盲人视觉辅助方面的不足，并提出了一些改进的启发式解决方案。
## Conclusion
EgoBlind的数据和评估代码可以为开发更有效的AI助手提供坚实的基础，以提高盲人生活的独立性。研究指出，尽管MLLMs在视觉辅助方面取得了一定进展，但与人类表现相比仍有很大差距，因此未来需要更多研究来提升模型在盲人辅助方面的能力。
# 175. `cs.AI` - 改进机器翻译中的指标干扰：添加薄荷糖的方法 [PDF](https://arxiv.org/pdf/2503.08327), [HTML](https://arxiv.org/abs/2503.08327)
## Authors
José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins
## Background
随着自动化评估指标变得越来越强大并被广泛应用，模型开发期间无意中"游戏"这些指标的风险也随之增加。这一问题源于指标干扰（MINT），即在模型调优和评估中使用相同的或相关指标。这可能导致从业者过于乐观地估计系统性能：当系统输出成为干扰指标的函数时，其估算的质量将失去与人类判断的相关性。在机器翻译相关的任务中，指标干扰通常出现在训练数据过滤和使用质量信号进行解码两种典型情况下。研究发现，即使在没有直接优化指标的情况下，指标干扰也会严重扭曲实例级别的指标评分，从而质疑使用不同的但相关指标进行评估而不用于调优的常见策略的可靠性和准确性。
## Innovation
本研究提出了一种名为MINTADJUST的方法，以在指标干扰的情况下进行更可靠的评估。在WMT24机器翻译共享任务测试集上，相较于最新的评估指标，MINTADJUST在多数语言对中更准确地对翻译和系统进行了排名，尤其是在高质量系统的表现方面更加优异。此外，该方法还在评估性能上超越了组织者使用的AUTORANK集成方法。
## Conclusion
研究证明了MINTADJUST在应对指标干扰方面具有很高的有效性，特别是在机器翻译任务中的评估中。它不仅可以更准确地对系统进行排名，同时也展示了在使用关联指标进行评估而不是直接优化指标时的增强性能。
# 176. `cs.AI` - 用迭代与邻域辅助模型编辑解决UnderEdit与OverEdit问题 [PDF](https://arxiv.org/pdf/2503.11895), [HTML](https://arxiv.org/abs/2503.11895)
## Authors
Bhiman Kumar Baghel,Scott M. Jordan,Zheyuan Ryan Shi,Xiang Lorraine Li
## Background
大语言模型（LLMs）在下游任务中广泛应用，通过重新培训或微调来保持知识的最新状态通常计算成本高昂。现有模型编辑方法虽然效率更高，但往往存在两个主要问题：一是编辑可能无法注入知识（UnderEdit），二是可能无意中破坏了未关联的知识（OverEdit）.
## Innovation
为了解决上述问题，该研究提出两种互补的方法：迭代模型编辑，这种方法通过连续应用编辑来减轻UnderEdit问题；邻域辅助模型编辑，在编辑过程中整合邻域知识以减少OverEdit。实验结果表明，这些技术在多个LLM、算法和基准测试中提升了编辑性能，降低了UnderEdit高达38个百分点，OverEdit高达6个百分点，且广泛适用于任何locate-and-edit方法.
## Conclusion
该研究通过迭代与邻域辅助模型编辑方法显著改善了模型编辑性能，解决UnderEdit和OverEdit问题.
# 177. `cs.AI` - 超越混沌传播： Wasserstein 空间中的一种随机优化算法 [PDF](https://arxiv.org/pdf/2503.13115), [HTML](https://arxiv.org/abs/2503.13115)
## Authors
Chandan Tankala,Dheeraj M. Nagaraj,Anant Raj
## Background
在2- Wasserstein空间中，梯度流被广泛用于优化概率分布上的目标函数，通常通过包含n个粒子的相互作用粒子系统实现。分析这类算法需要证明两个方面：（a）有限粒子系统的收敛性或（b）粒子的最终分布与最优分布的紧密逼近（即混沌传播）。然而，确定有效的充分条件并不容易，因为有限粒子系统可能会产生高度相关的随机变量。本文研究了虚拟粒子随机逼近法，原用于Stein变分梯度下降。该方法可以被视为在Wasserstein空间中的随机梯度下降法，可以有效实施。在流行的应用中，我们的算法输出在类似于无限粒子极限条件下收敛到最优分布，并能生成独立同分布样本，而无需 explic 合成混沌传播的界限。
## Innovation
本文研究并引入了一种虚拟粒子随机逼近法，这是一种在Wasserstein空间中的随机梯度下降法，能够有效实施。该方法证明了在类似于无限粒子极限条件下，其输出能够收敛到最优分布，并且可以生成独立同分布样本，而无需证明混沌传播界限。这种方法简化了传统方法中的困难部分，提供了分析和应用的便利性。
## Conclusion
我们的方法在广泛的设置中产生了与最优分布的独立同分布样本，而不需要显式地建立混沌传播界限。因此，该方法在优化概率分布问题中提供了新的见解和效率。
# 178. `cs.AI` - KANITE: Kolmogorov-Arnold Networks for ITE estimation [PDF](https://arxiv.org/pdf/2503.13912), [HTML](https://arxiv.org/abs/2503.13912)
## Authors
Eshan Mehendale,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar
## Background
在因果推断的多重治疗设置中，个体治疗效果（ITE）的估计至关重要。传统的多层感知器（MLP）模型利用其对线性权重的学习能力来估计ITE，但是Kolmogorov-Arnold Networks（KANs）能够学习单变量激活函数，这可能提供更精确的ITE估计。KANITE框架结合了KANs的独特能力，以改进多重治疗设置下的ITE估计性能，并在基准数据集上的评估中显示出优于当前最先进的算法。
## Innovation
提出了一种名为KANITE的框架，它通过利用KANs学习单变量激活函数的能力，而不是MLPs学习线性权重，改进了ITE的估计。KANITE框架包括两种关键架构：概率度量（IPM）架构利用特定的IPM损失高效地为多治疗组的ITE估计对齐；熵平衡（EB）架构通过优化样本权重使其在治疗组间协变量平衡，来调整样本权重。这些创新增强了在多重治疗设置下的ITE估计，特别是在$	ext{PEHE}$和$	ext{ATE}$度量中的性能表现更优。
## Conclusion
通过广泛的基准数据集评估表明，KANITE框架在$	ext{PEHE}$和$	ext{ATE}$指标中都优于现有最先进的算法，展示了KANs在处理ITE估计问题上的潜力，为多元化应用领域的因果推理方法的进步提供了新的可能。
# 179. `cs.AI` - 一种改进通过深度学习识别鸟类鸣叫的鸟鸣检测器：从Doñana湿地的一个案例研究 [PDF](https://arxiv.org/pdf/2503.15576), [HTML](https://arxiv.org/abs/2503.15576)
## Authors
Alba Márquez-Rodríguez,Miguel Ángel Mohedano-Munoz,Manuel J. Marín-Jiménez,Eduardo Santamaría-García,Giulia Bastianelli,Pedro Jordano,Irene Mendoza
## Background
被动声学监控是生物多样性保护的关键工具，但大量未经监督的音频数据给提取有意义信息带来了重大挑战。深度学习提供了积极的解决方案。尽管广泛使用的鸟类识别模型如BirdNET在许多研究系统中取得了成功，但由于其训练数据存在偏见，只能在局部规模上工作。识别鸟类物种的关键挑战是在许多录音中缺乏目标物种或存在重叠鸣叫，这使得自动识别变得复杂。有针对性地部署音频记录器并手动注释音频，可以在Doñana国家公园这个具有高度保护关注的湿地中解决这些问题。
## Innovation
开发了一个多阶段管道来自动识别道纳纳国家公园（西班牙西南部）的鸟类鸣叫。通过鸟鸣检测器和基于光谱图的图像处理，隔离出鸟类鸣叫的音频片段。之后，使用定制模型在局部尺度上对这些鸣叫进行分类。在分类前应用鸟鸣检测器提高了物种识别效果，特别是与细调后的BirdNET结合使用时，其性能优于没有检测器的基线方法。这项研究表明，将鸟鸣检测器与当地分类模型结合使用具有有效性。这一发现强调了需要适应通用工具来解决特定生态挑战的需求。自动检测鸟类物种有助于跟踪这个受威胁生态系统的健康状况，支持减少生物多样性的损失，以减少环境变化的影响，并支持保护规划。
## Conclusion
这项研究展示了将鸟鸣检测器与局部分类模型结合使用的方法在识别鸟类鸣叫中的有效性，表明了为了适应特定生态挑战，需要调整通用工具以助于生物多样性保护。
# 180. `cs.AI` - 探索用于监控视频中暴力检测的个性化联邦学习架构 [PDF](https://arxiv.org/pdf/2504.00857), [HTML](https://arxiv.org/abs/2504.00857)
## Authors
Mohammad Kassir,Siba Haidar,Antoun Yaacoub
## Background
在城市监控系统中检测暴力事件的挑战由于视频数据的大量和多样化而加剧。现有方法难以有效处理这种复杂的数据集。
## Innovation
本文提出了一种针对性的方法，利用个性化联邦学习（PFL）解决这一问题，并使用Flower框架中的Federated Learning with Personalization Layers方法。这种方法能够根据不同监控节点特有的数据特性进行模型适配，有效应对监控视频数据的异质性和非IID问题。实验结果证明，PFL模型在平衡和非平衡数据集上表现出更高的准确性和效率，最高可达99.3%的准确率。
## Conclusion
这项研究强调了PFL在提高监控系统可扩展性和有效性方面的潜力，提供了在复杂城市环境中检测暴力事件的 robust、隐私保护的解决方案。
# 181. `cs.AI` - 信任区间偏好逼近：一种用于大语言模型推理的简单且稳定的强化学习算法 [PDF](https://arxiv.org/pdf/2504.04524), [HTML](https://arxiv.org/abs/2504.04524)
## Authors
Xuerui Su,Shufang Xie,Guoqing Liu,Yingce Xia,Renqian Luo,Peiran Jin,Zhiming Ma,Yue Wang,Zun Wang,Yuting Liu
## Background
近年来，大型语言模型（LLMs）迅速发展，接近通用人工智能（AGI），并通过大规模强化学习增强了人类对齐（HA）和推理能力。尽管基于奖励的优化算法（如PPO和GRPO）在推理任务上取得了显著效果，基于偏好的优化算法（如直接偏好优化DPO）在人类对齐任务上显著提高了LLMs的性能。然而，基于奖励的方法仍存在漏洞，容易受到奖励诈骗的影响。同时，基于偏好的算法在推理任务上的表现尚未达到基于奖励的优化算法的水平，因此在该领域仍有探索价值。
## Innovation
本文提出了信任区间偏好逼近（TRPA）算法，该算法结合了基于规则的优化与基于偏好的优化，专为推理任务设计。TRPA作为基于偏好的算法，自然避免了奖励诈骗问题。通过使用预定义规则构建偏好层级，形成相应的偏好对，并利用新的优化算法进行RL训练，提供了理论上的单调改进保证。实验结果显示，TRPA不仅在推理任务上实现了竞品级别的性能，还表现出良好的稳定性。
## Conclusion
TRPA算法不仅在推理任务上表现优异，还表现出高度稳定性。此外，该算法的代码已在 https://github.com/yourrepository 提供并持续更新。
# 182. `cs.AI` - SCAM：针对多模态基础模型的现实世界字体鲁棒性评估 [PDF](https://arxiv.org/pdf/2504.04893), [HTML](https://arxiv.org/abs/2504.04893)
## Authors
Justus Westerhoff,Erblina Purelku,Jakob Hackstein,Jonas Loos,Leo Pinetzki,Lorenz Hufe
## Background
现有的多模态基础模型存在字体攻击，即通过在图片中嵌入误导性的文本来导致误分类。目前，已有的数据集在规模和多样性上都很有限，限制了对这种漏洞的研究。为了应对这一挑战，该研究引入了一种迄今为止最大且最多样化的现实世界字体攻击图片集，名为SCAM，包含1,162张跨数百个对象类别和攻击词汇的图片，揭示了在大型视觉语言模型中，选择视觉编码器是导致字体攻击持续存在的主要原因。同时，研究发现大型语言模型的骨干网络有助于减轻这种攻击的脆弱性。此外，还发现合成攻击与真实世界的（手写）攻击高度相似，验证了其在研究中的实用性。
## Innovation
该研究创新性地提出了SCAM数据集，这是迄今为止最大的现实世界字体攻击图片集，包含1,162张图片，涵盖了数百个对象类别和攻击词汇。通过在VLMs上的基准测试，强调了字体攻击对模型性能的严重影响，揭示了训练数据和模型结构对这些攻击的脆弱性的影响，并提出了字体攻击在大型语言模型后端增大时有所缓解的观点。此外，该研究还展示了合成攻击与现实世界的手写攻击高度相似，支持其在研究中的应用价值。最后，该研究提供了一个综合资源和实证见解，以促进对鲁棒和可信赖的多模态AI系统的未来研究。
## Conclusion
研究表明，字体攻击在最先进的大型视觉语言模型中仍然存在，且选择视觉编码器是导致这一现象的主要因素。然而，较大的大型语言模型后端有助于减轻这种脆弱性。此外，合成攻击与现实世界的手写攻击高度相似，验证了它们在研究中的应用。该研究强调了字体攻击在多模态基础模型中的普遍性，并提供了一个公开的数据集和评估代码，为未来的研究提供了宝贵的资源和洞察。
# 183. `cs.AI` - 影响性博特：拉一个臂有可能改变环境 [PDF](https://arxiv.org/pdf/2504.08200), [HTML](https://arxiv.org/abs/2504.08200)
## Authors
Ryoma Sato,Shinji Ito
## Background
现有的多臂赌博机（Multi-armed Bandit，MAB）问题的经典假设是每个臂的奖励独立且稳定，但现实中的应用往往涉及非稳定环境和臂之间的依赖性。选择一个臂可能会影响其他臂未来的奖励，现有的模型如旋转博特或激动博特未能充分捕捉这种场景。因此，需要一个新的模型来解决这一局限性，即影响性博特问题，该模型通过一个未知的对称且半正定的交互矩阵来建模臂之间的相互作用，该矩阵控制臂损失的动力学。
## Innovation
该研究提出了一个新的影响性博特问题模型，通过一个未知的对称且半正定的交互矩阵来建模臂之间的相互作用。研究还引入了一个基于损失动态结构的下置置信度边界（Lower Confidence Bound，LCB）估计器的新算法。该算法在较弱的假设下实现了几乎最优的后悔率为$O(KT 	imes 	ext{log} T)$，且易于实现且计算效率高。此外，通过合成和现实数据集验证了臂之间的相互作用的存在，并证实了该算法的优越性能优于传统博特算法。
## Conclusion
此研究实现了一个新算法，该算法在涉及到臂之间相互作用的环境下的性能几乎是最优的，且其计算效率使得它在实际应用中高度可行。通过理论证明和实验证明了该算法的有效性，并且对臂之间影响性的建模提供了新的视角。
# 184. `cs.AI` - 重新定义大型语言模型时代基于强化学习的序列决策中的隐私 [PDF](https://arxiv.org/pdf/2504.11511), [HTML](https://arxiv.org/abs/2504.11511)
## Authors
Flint Xiaofeng Fan,Cheston Tan,Roger Wattenhofer,Yew-Soon Ong
## Background
强化学习（RL）在关键现实应用中的崛起促使我们重新思考AI系统的隐私问题。传统的隐私框架主要用于保护孤立的数据点，但不能很好地应对依赖于时间模式、行为策略和协作动态的序列决策系统中出现的敏感信息。现代RL范式，如联邦强化学习（FedRL）和大型语言模型（LLMs）中的从人类反馈强化学习（RLHF），进一步加剧了这些挑战，引入了传统方法难以应对的复杂、交互和上下文相关的学习环境。
## Innovation
本文提出了一个新的基于四个核心原则的隐私范式，包括多尺度保护、行为模式保护、协作隐私保护和上下文感知适应性。这四个原则揭示了隐私、效用和可解释性之间固有的紧张关系，特别是在如医疗保健、自主驾驶和由LLMs驱动的决策支持系统等高风险领域中，随着RL系统的普及而必须进行导航。文章呼吁开发新的理论框架、实用机制和严格的评估方法，以集体有效地保护序列决策系统中的隐私。
## Conclusion
为了应对这些挑战，我们提出了适用于序列决策系统的有效隐私保护的新理论框架、实用机制和严格的评估方法。这一新的隐私范式旨在应对在大型语言模型时代复杂的互动强化学习环境中的隐私保护需求。
# 185. `cs.AI` - UD-English-CHILDES：儿童语言交互的金标准和银标准Universal Dependencies树集合资源 [PDF](https://arxiv.org/pdf/2504.20304), [HTML](https://arxiv.org/abs/2504.20304)
## Authors
Xiulin Yang,Zhuoxuan Ju,Lanni Bu,Zoey Liu,Nathan Schneider
## Background
CHILDES是一个广泛使用的儿童语言和儿童定向语音转录资源。尽管有先前依赖注释的CHILDES数据，但缺乏统一的注释原则导致研究分散。本文介绍UD-English-CHILDES，它是第一个官方发布的Universal Dependencies (UD)树库，旨在提供一致性资源，支持计算和语言学研究。
## Innovation
本文创新地发布了UD-English-CHILDES，这是首次将CHILDES数据转换为通用依赖结构，遵循统一的注释原则。它包含了超过48,000句（236,000个词元）的高质量标准注释，以及额外的100万句银标准注释。这些标注数据符合UD v2框架，显著提升了研究资源的一致性和研究质量。
## Conclusion
UD-English-CHILDES提供了金标准和银标准的Universal Dependencies树，涵盖11个儿童及其看护者的对话。这为儿童语言研究提供了宝贵的资源，有助于进一步的计算和语言学研究。
# 186. `cs.AI` - DreamGen: 通过视频世界模型解锁机器人学习中的泛化能力 [PDF](https://arxiv.org/pdf/2505.12705), [HTML](https://arxiv.org/abs/2505.12705)
## Authors
Joel Jang,Seonghyeon Ye,Zongyu Lin,Jiannan Xiang,Johan Bjorck,Yu Fang,Fengyuan Hu,Spencer Huang,Kaushil Kundalia,Yen-Chen Lin,Loic Magne,Ajay Mandlekar,Avnish Narayan,You Liang Tan,Guanzhi Wang,Jing Wang,Qi Wang,Yinzhen Xu,Xiaohui Zeng,Kaiyuan Zheng,Ruijie Zheng,Ming-Yu Liu,Luke Zettlemoyer,Dieter Fox,Jan Kautz,Scott Reed,Yuke Zhu,Linxi Fan
## Background
研究介绍了DreamGen，这是一种用于训练机器人策略的简单高效四阶段管道，这些策略可以在不同行为和环境中泛化，利用神经轨迹生成合成机器人数据。这些模型通过将最新的图像到视频生成模型适应目标机器人存在来创建现实世界的合成视频数据。由于这些模型只能生成视频，因此使用潜在动作模型或逆动力学模型（IDM）恢复伪动作序列。尽管DreamGen结构简单，但它能够实现强大的行为和环境泛化：一个类人机器人能够在已见和未见环境中执行22种新的行为，仅需要来自单一环境中一个抓取并放置任务的少量遥操作数据。为了系统地评估管道，研究者引入了基于模拟器的基准测试DreamGen Bench，显示了基准评估性能和下游策略成功之间的强相关性。这表明通过DreamGen可以实现机器人学习的扩展，远远超出手动数据收集的范围。
## Innovation
DreamGen通过利用最先进的图像到视频生成模型生成高度真实合成的机器人视频数据，实现了强大的行为和环境泛化。通过单一任务的数据收集，该模型使类人机器人能够在不同环境和任务中执行多种新行为。研究通过新的基准测试DreamGen Bench验证了这些策略在泛化能力上的显著改进。
## Conclusion
研究展示了用于提高机器人学习效率和性能的新方法，通过对未知环境和任务的学习生成多样的真实合成数据，这能够显著减少手动数据收集的需要。通过DreamGen，机器人可以在多种新环境中执行复杂的行为，克服了现有方法的局限性。
# 187. `cs.AI` - 断裂链式思维推理 [PDF](https://arxiv.org/pdf/2505.12992), [HTML](https://arxiv.org/abs/2505.12992)
## Authors
Baohao Liao,Hanze Dong,Yuhui Xu,Doyen Sahoo,Christof Monz,Junnan Li,Caiming Xiong
## Background
通过在推理时利用额外的计算努力，推理时扩展技术显著增强了大型语言模型（LLMs）的推理能力。然而，链式思维（CoT）提示及其扩展版本长链式思维（Long CoT），通过生成丰富的中间推理轨迹来提高准确性，但这些方法带来了显著的令牌成本，阻碍了在对延迟敏感的环境中部署这些方法。
## Innovation
该研究提出了断裂采样（Fractured Sampling），这是一种统一的推理时策略，通过在三个正交维度上插值来结合完整的CoT和仅方案采样的方法：(1) 推理轨迹的数量，(2) 每个轨迹的最终解决方案数量，以及(3) 推理跟踪的中断深度。通过在五个不同的推理基准测试和多个模型规模上的广泛实验，证明了断裂采样能够实现更优的准确性和成本权衡，相对于令牌预算实现陡峭的对数线性扩展增益。研究表明如何在这些维度之间分配计算以最大化性能，为更高效的大型语言模型推理铺平了道路。
## Conclusion
通过使用断裂采样的方法，研究展示了如何在这些维度之间分配计算以最大化性能，为更高效的大型语言模型推理铺平了道路，并且证明了断裂采样会实现更优的准确性和成本权衡。代码可以在这个网址找到。
# 188. `cs.AI` - J4R：使用等价初始状态组相对策略优化来学习评判 [PDF](https://arxiv.org/pdf/2505.13346), [HTML](https://arxiv.org/abs/2505.13346)
## Authors
Austin Xu,Yilun Zhou,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty
## Background
为了跟上大型语言模型（LLM）快速发展带来的速度，模式输出评估已经从耗时的手动评估转变为自动评估，其中LLM本身被用来评估和批判其他模型输出。目前的‘LLM作裁判’模型在评估简单领域方面表现良好，比如对话质量，但在需要更多推理的任务中表现不佳，因为响应中包含了更实质性的内容。为了改进这些裁判的不足，我们探索了使用强化学习（RL）来培训裁判的方法。该研究提出了一个名为‘等价初始状态组相对策略优化’（EIS-GRPO）的算法，旨在短期内训练出评价复杂的裁判模型，还介绍了一个名为‘ReasoningJudgeBench’的基准测试，以评估在以前工作中未涵盖的各种推理环境下的模型表现。
## Innovation
研究成果包括：（1）提出了一种名为EIS-GRPO的算法，使裁判模型能在复杂环境中更为稳健；（2）开发了‘ReasoningJudgeBench’基准测试，以评估不同推理场景下的模型；（3）使用EIS-GRPO算法训练出一个名为‘Judge for Reasoning’（J4R）的7B参数裁判模型，该模型在多个基准测试中的表现超过了同类的最佳模型，并且在J4R和‘ReasoningJudgeBench’测试中，性能与较大模型训练的裁判模型相当或更优。
## Conclusion
通过强化学习进行训练的裁判模型J4R，在各种推理任务中表现出了较好的性能，尤其是使用EIS-GRPO算法进行训练后，其性能进一步提升，达到了与更大模型训练的裁判模型相当的水平，甚至在某些任务上超过了第二名和第三名模型的6.7%和9%。
# 189. `cs.AI` - MSVIT：使用多尺度注意融合改进突触视觉变压器 [PDF](https://arxiv.org/pdf/2505.14719), [HTML](https://arxiv.org/abs/2505.14719)
## Authors
Wei Hua,Chenlin Zhou,Jibin Wu,Yansong Chua,Yangyang Shu
## Background
突触神经网络（SNNs）与视觉变换器（ViT）架构的结合在能效和高性能计算方面具有巨大潜力，但由于基于SNN和基于ANN的变换器架构之间存在显著的性能差距，这一领域仍然面临挑战。现有方法虽然提出了结合SNN的脉冲自注意力机制，但整体架构在从不同图像尺度中高效提取特征方面仍存在瓶颈。
## Innovation
提出了一种新型的脉冲驱动变换器架构——MSVIT，通过引入多尺度脉冲注意力机制（MSSA），增强了脉冲注意力模块的功能。该方法在多个主要数据集上的实验证明了其优越性，其性能优于现有SNN基模型，成为SNN-变换器架构中的领先解决方案。
## Conclusion
MSVIT通过使用多尺度注意融合改进突触视觉变压器，克服了现有方法中从不同图像尺度中有效提取特征的瓶颈问题。实验结果表明，MSVIT优于现有的SNN基模型，定位于SNN-变换器架构中的最佳解决方案。相关代码可以在指定的URL处获取。
# 190. `cs.AI` - Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning [PDF](https://arxiv.org/pdf/2505.17830), [HTML](https://arxiv.org/abs/2505.17830)
## Authors
Nicolas Castanet,Olivier Sigaud,Sylvain Lamprier
## Background
目标条件强化学习（GCRL）能够使智能体自主获得多样化的行为，但在视觉环境下却面临巨大挑战，因为这些环境的观测是高维且语义稀疏的。在在线学习设置中，智能体在探索的同时学习表示，其潜在空间会随着智能体策略的变化而演化，以捕捉新发现的环境区域。然而，如果没有激励智能体最大化状态覆盖率，基于自编码器的古典方法可能会收敛到过度代表智能体频繁访问的少数状态的潜在空间。这种情况在内在激励设置中更加严重，在这里，智能体使用编码在潜在空间中的分布来采样它希望掌握的目标。
## Innovation
本文提出了一种逐步约束分布的转变方式，使其向全状态空间均匀分布收敛，以确保技能学习的全面覆盖。作者引入了DRAG（分布鲁棒自编码器），将$eta$-VAE框架与分布鲁棒优化相结合。DRAG利用了VAE训练状态的对抗性神经加权器，以解决当前数据分布与未见环境部分之间的不匹配问题，从而使智能体能够构建超越其即时经验的语义上有意义的潜在空间。本文的方法在迷宫和涉及墙壁绕行的机器人控制等难度较高的探索环境中提高了状态空间覆盖和下游控制表现，无需预训练或先验环境知识。
## Conclusion
DRAG通过将分布鲁棒自编码与$eta$-VAE框架结合，解决了经典自编码器方法在视觉强化学习中难以实现全面状态空间覆盖的问题。该方法在复杂环境中自我构建了语义上更丰富的潜在空间，提升了智能体的行为和控制性能。
# 191. `cs.AI` - 小型语言模型中的高效长链推理 [PDF](https://arxiv.org/pdf/2505.18440), [HTML](https://arxiv.org/abs/2505.18440)
## Authors
Zhaoyang Wang,Jinqi Jiang,Tian Qiu,Hui Liu,Xianfeng Tang,Huaxiu Yao
## Background
近年来，如DeepSeek-R1等大型推理模型展示了通过生成长链条推理步骤（CoT）来解决复杂问题的能力。然而，直接训练小型语言模型（SLMs）以产生长链条推理仍然具有挑战性。为了解决这个问题，研究采用了知识蒸馏的方法来使小型语言模型具备长链条推理的能力。但是，由于小型语言模型能力有限且泛化能力较差，其可能难以学习长链条推理中的冗余内容。因此，需要一种方法来精简长链条推理中的不必要的步骤，以帮助小型语言模型更好地学习有效的推理内容并保持良好的性能。
## Innovation
该研究提出了一个简单有效的去除长链条推理中冗余步骤的方法，并结合了策略策略方法来校准小型语言模型自身产生的有效长链条推理训练数据。这种方法使小型语言模型能够有效学习高效的长链条推理并保持竞争力。实验结果表明，该方法在多个数学推理基准测试中有效，不仅保持了竞争力，还显著减少了生成冗余推理步骤的数量。
## Conclusion
研究表明，通过精简长链条推理中的冗余内容并结合策略策略方法，使得小型语言模型可以学习高效的推理过程并保持良好的性能，从而显著减少了冗余的推理步骤生成。
# 192. `cs.AI` - Think Twice before Adaptation: Improving Adaptability of DeepFake Detection via Online Test-Time Adaptation [PDF](https://arxiv.org/pdf/2505.18787), [HTML](https://arxiv.org/abs/2505.18787)
## Authors
Hong-Hanh Nguyen-Le,Van-Tuan Tran,Dinh-Thuc Nguyen,Nhien-An Le-Khac
## Background
深度伪造（Deepfake, DF）检测器在实际环境中的部署面临显著挑战，尤其是在遇到与训练数据有差异的测试样本时。这些差异可能是通过后处理操作或分布转移实现的。研究发现，后处理技术可以完全掩盖深度伪造样本中的生成特征，导致检测器性能下降。深度伪造检测器需要更好的适应性，以便在实际环境中更有效地工作，同时不需要访问源训练数据或标签就进行调整。
## Innovation
本文提出了一个名为 	exttt{T$^2$A}（双重思考前的适应）的新颖在线测试时适应方法，该方法在不依赖源训练数据或标签的情况下，增强了检测器在推理过程中的适应性。核心思想是通过不确定性感知的负学习目标使模型能够探索其他选择，而不是单纯依赖其初始预测。此外，还引入了不确定样本优先级策略和梯度掩盖技术，以通过关注重要样本和模型参数来提高适应性。理论分析表明，提出的负学习目标与熵最小化方法表现出互补性，有助于更好地适应能力。
## Conclusion
实验结果表明，本文的方法在现有测试时适应方法中达到了最先进的性能，并显著提高了深度伪造检测器在推理过程中的抗扰动性和泛化能力。代码可在这里访问：[提供链接]。
# 193. `cs.AI` - ALPS: 注意本地化和剪枝策略用于大型语言模型高效对齐 [PDF](https://arxiv.org/pdf/2505.18799), [HTML](https://arxiv.org/abs/2505.18799)
## Authors
Hao Chen,Haoze Li,Zhiqing Xiao,Lirong Gao,Qi Zhang,Xiaomeng Hu,Ningtao Wang,Xing Fu,Junbo Zhao
## Background
在将通用的大语言模型（LLMs）调整到下游任务时，通常需要付出显著的训练调整成本。前人的研究主要通过最小数据训练或数据驱动的激活来识别关键注意头来提高对齐效率。然而，这些方法本质上引入了数据依赖性，这阻碍了泛化能力和再利用能力。鉴于此，本文旨在增强模型对齐效率并提出了一种有效的算法，即注意力本地化和剪枝策略（ALPS），该算法通过仅限制注意力训练更新到最任务敏感的注意头来减少对齐成本，从而减少调整成本。实验结果显示，在微调过程中仅激活10%的注意力参数，并在三个任务上实现2%的性能提升。此外，识别出的任务特定头可以在不同数据集间传递并减少知识遗忘。这项研究及其发现为高效LLM对齐提供了一个新的视角，代码已公开。
## Innovation
提出了一种有效的算法，即注意力本地化和剪枝策略（ALPS），通过仅限制注意力训练更新到最任务敏感的注意头来减少对齐成本，从而提高模型的对齐效率，并且这种方法能够在不同数据集间转移识别出的任务特定头，减少了知识遗忘。该方法在微调过程中仅激活10%的注意力参数，但在三个任务上性能提升了2%。
## Conclusion
我们的工作和发现为高效LLM对齐提供了一个新的视角。
# 194. `cs.AI` - ChemHAS: 化学代理堆叠增强化学工具 [PDF](https://arxiv.org/pdf/2505.21569), [HTML](https://arxiv.org/abs/2505.21569)
## Authors
Zhucong Li,Bowei Zhang,Jin Xiao,Zhijian Zhou,Fenglei Cao,Jiaqing Liang,Yuan Qi
## Background
大型语言模型（LLM）基于的代理已经在化学任务中展示了通过选择适当工具提高性能的能力。然而，它们的有效性仍然受到化学工具固有的预测错误的限制。本文探讨如何利用这些代理减少工具的预测错误。为此，提出了一种名为ChemHAS（化学层次代理堆叠）的方法，通过从有限数据优化代理堆叠结构来增强化学工具，从而实现四大基本化学任务的最佳性能，证明该方法可以有效补偿工具的预测错误。此外，还识别并描述了四种不同的代理堆叠行为，可能提高可解释性并揭示科学研究中AI代理应用的新可能性。
## Innovation
该研究提出了一种名为ChemHAS的方法，通过从有限数据优化代理堆叠结构来增强化学工具，这不仅可以减少工具的预测错误，还可以提高科学应用中的可解释性。
## Conclusion
ChemHAS方法不仅实现了四大基本化学任务的最先进性能，还揭示了AI代理在科学研究中的新应用可能性，并且代码和数据集已经公开。
# 195. `cs.AI` - 量子比特到企业应用的监督量子机器学习：十年展望 [PDF](https://arxiv.org/pdf/2505.24765), [HTML](https://arxiv.org/abs/2505.24765)
## Authors
Srikanth Thudumu,Jason Fisher,Hung Du
## Background
量子计算和经典机器学习的交汇领域，监督量子机器学习（QML）利用量子资源来支持模型训练和推理。近年来，这种方法出现了显著的发展，特别是使用变量子电路、量子神经网络和量子内核方法，以及混合量子-经典工作流。然而，当前还存在噪音问题、量子平板（barren plateaus）现象、可扩展性难题以及对性能改进缺乏形式证明等问题。
## Innovation
专注于最近的发展，包括监督QML中的关键方法和技术，如变量子电路、量子神经网络和量子内核方法等。评估了实验研究的证据，描述了量子优势的部分迹象，并指出了当前的限制因素。进一步展望未来十年（2025-2035），提出了监督QML可能的发展蓝图和应用场景。
## Conclusion
展望提出了一个包含条件的路线图，指出在未来十年中，监督QML可能在企业应用程序和其他应用研究中的潜在使用情况。
# 196. `cs.AI` - CORA：基于合作博弈的多智能体策略梯度中的联盟理性优势分解 [PDF](https://arxiv.org/pdf/2506.04265), [HTML](https://arxiv.org/abs/2506.04265)
## Authors
Mengda Ji,Genjiu Xu,Liying Wang
## Background
该研究聚焦于合作多智能体强化学习（MARL）中的信用分配问题。当前方法通常通过共享全局优势来分配给智能体，但这种方式往往会导致次优的策略更新，因为它没有考虑到各个智能体的独特贡献。尽管许多方法考虑全局或个体贡献，但在联盟层面的详细分析仍然存在不足。该研究从联盟层面的角度分析了多智能体策略更新过程中的过度更新问题，旨在解决这个问题。
## Innovation
为了解决这个问题，该研究提出了一种称为Coalition Rational Advantage Decomposition（CORA）的信用分配方法。CORA通过评估所有可能联盟的边际贡献来评估联盟优势，并使用合作博弈理论的核心解来分解优势，从而确保联盟理性。为降低计算复杂度，CORA采用随机联盟采样。实验结果显示，CORA在矩阵博弈、微分博弈和多智能体协作基准任务中均表现出色，尤其是对于有多个局部最优的任务，CORA优于强基线方法。这些结果强调了联盟感知信用分配对于提高MARL性能的重要性。
## Conclusion
该研究表明，通过联盟感知的信用分配可以显著提高多智能体强化学习的性能，特别是在有多个局部最优的任务中。CORA提供了一种新的策略，通过从合作博弈角度分解优势，有效解决了联盟层面的过度更新问题。
# 197. `cs.AI` - LaMP-Cap: 基于多模态图文资料的个性化图表生成 [PDF](https://arxiv.org/pdf/2506.06561), [HTML](https://arxiv.org/abs/2506.06561)
## Authors
Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang
## Background
图表描述对于帮助读者理解和记住图表的关键信息至关重要。许多模型已经开发出来以生成这些描述，帮助作者更轻松地创作高质量的描述。然而，作者几乎总是需要修改通用AI生成的描述以匹配其写作风格和领域风格，这突出了个性化生成的需求。尽管已经有关于语言模型个性化（LaMP）的进步，但这些技术通常集中在仅文本的场景中，很少解决涉及多模态输入和资料的场景。
## Innovation
该论文提出了LaMP-Cap数据集，用于多模态图表背景下的个性化图表描述生成。对于每个目标图表，LaMP-Cap不仅提供了所需输入如图表图片，还提供了文档中最多三个其他图表及其图片、描述和提及这个图表的段落，作为背景描述，以刻画上下文。实验表明，使用背景描述信息一致地帮助生成接近原始作者撰写的描述。消融研究发现，背景描述中的图片比提及图表的段落更有帮助，展示了使用多模态描述而非纯文本描述的优势.
## Conclusion
实验结果显示，使用背景描述信息能够更一致地生成更接近原始作者撰写的图表描述。同时，多模态背景描述中的图片比提及图表的段落更有帮助，证明了多模态背景描述相较于仅使用文本背景描述的优势。
# 198. `cs.AI` - BIS Reasoning 1.0: 日本首个评估信念不一致演绎推理的大规模基准 [PDF](https://arxiv.org/pdf/2506.06955), [HTML](https://arxiv.org/abs/2506.06955)
## Authors
Ha-Thanh Nguyen,Chaoran Liu,Koichi Takeda,Yusuke Miyao,Pontus Stenetorp,Qianying Liu,Su Myat Noe,Hideyuki Tachibana,Sadao Kurohashi
## Background
背景主要介绍了当前大型语言模型（LLMs）在逻辑推理任务中的局限性。现有的数据集如NeuBAROCO和JFLD更侧重于一般或信念一致的推理，而BIS Reasoning 1.0则引入了逻辑上有效的但与信念冲突的三段论问题，以检验LLMs在处理此类任务时的偏见。
## Innovation
创新之处在于首次推出了一个大规模的日本语数据集BIS Reasoning 1.0，专门用于评估LLMs在处理信念不一致推理问题时的表现。该数据集侧重于逻辑有效但信念冲突的三段论问题，不同于之前注重一般或信念一致推理的数据集。通过这一数据集，研究人员揭示了现有模型在处理这类问题时的显著差异，特别是在准确率上的差异，例如GPT-4o实现了79.54%的准确率。
## Conclusion
研究表明，当前的LLMs在处理逻辑有效但信念冲突的输入时存在关键弱点，这对于法律、医疗和科学文献等高风险领域尤为重要。这些发现强调了确保真理性和安全性的必要性，以保证LLMs在这些领域的应用能够保持高质量和可靠性。
# 199. `cs.AI` - 视觉转换器不需要训练注册令牌 [PDF](https://arxiv.org/pdf/2506.08010), [HTML](https://arxiv.org/abs/2506.08010)
## Authors
Nick Jiang,Amil Dravid,Alexei Efros,Yossi Gandelsman
## Background
先前已识别出视觉转换器中出现高范数令牌的现象，这些令牌导致注意力图变得嘈杂。现有的解决方案是通过额外的训练来移除这些异常令牌，但这种方法需要重新训练整个模型。本文进一步研究了这一现象背后的机制，发现多个模型中的稀疏神经元负责将高范数激活集中到异常令牌上，导致不规则的注意力模式，影响下游视觉处理效果。我们发现现有的解决方案需要重新训练，提出了一种无需训练的方法来减轻这些伪影。通过将高范数激活从发现的注册神经元转移到一个未训练的标记中，可以模仿注册令牌的效果，使已训练的模型变得更干净，且在多个下游视觉任务中性能更佳，达到与直接训练了注册令牌的模型相当的效果。研究还扩展了测试时的注册令牌，以改善预训练视觉-语言模型的可解释性，发现测试时的注册令牌在测试时有效承担了注册令牌的角色，提供了一种无需训练的解决方案来改进没有注册令牌的预训练模型。
## Innovation
本文提出了一种无需训练的方法来解决视觉转换器中的高范数令牌问题。通过将高范数激活从发现的注册神经元转移到未训练的标记中，简化了模型，且在多个下游视觉任务中取得了与直接训练了注册令牌的模型相当的性能。此外，还提出了一种测试时的注册令牌，提高了预训练视觉-语言模型的可解释性，并有效替代了训练中的注册令牌功能，无需额外的训练过程。
## Conclusion
本文揭示了视觉转换器中高范数令牌现象背后的原因，并提出了一种无需额外训练即可有效减轻这些伪影的方法，增强了模型在多个下游视觉任务中的性能，并实现与直接训练了注册令牌的模型相当的效果。此外，还提出了一种测试时的注册令牌，提高了模型的可解释性，简化了模型部署和改进过程。
# 200. `cs.AI` - Router-R1：通过强化学习教会大型语言模型多轮路由和聚合 [PDF](https://arxiv.org/pdf/2506.09033), [HTML](https://arxiv.org/abs/2506.09033)
## Authors
Haozhen Zhang,Tao Feng,Jiaxuan You
## Background
随着多种大型语言模型（LLMs）的快速涌现，LLM路由技术应运而生，用于将用户查询分配给最适合的模型。然而，现有的大多数LLM路由器通常仅进行单轮一对一映射（即，将每个查询单独分配给一个模型），这限制了它们处理需多个模型互补优势的任务的能力。已有研究和方法无法有效应对复杂的任务需求，特别是那种需要多个模型共同协作的任务。
## Innovation
本文提出了一种基于强化学习（RL）的框架——Router-R1，将多LLM路由和聚合建模为一个顺序决策过程。通过模型自身进行推理，内嵌‘思考’动作（内部讨论）与‘路由’动作（动态模型调用），并实时整合每个响应。通过引入一种轻量级规则奖励机制，包含格式奖励、最终结果奖励和新颖的成本奖励，优化性能与成本之间的平衡，进而通过强化学习提升性能和成本之间的权衡。此外，Router-R1 仅考虑简单的模型描述（如价格、延迟和示例性能），使得其能够对未见过的模型选择进行强泛化。实验结果显示，Router-R1 在多个通用和多跳问答基准测试中优于多个基准线，展示了更强的性能、稳健的泛化能力和成本管理能力。
## Conclusion
总之，通过强化学习，本文提出了一种新的多轮LLM路由方法，能够有效处理具有多个模型互补优势的任务，同时还能提高性能与成本之间的权衡，展现出更佳的性能、泛化能力和成本管理能力。
# 201. `cs.AI` - 无法思考太大：预训练变压器中的容量、记忆与泛化 [PDF](https://arxiv.org/pdf/2506.09099), [HTML](https://arxiv.org/abs/2506.09099)
## Authors
Joshua Barron,Devin White
## Background
大型语言模型（LLMs）的存储与泛化之间的关系仍然有待研究，现有的证据表明两者之间存在着密切联系。已有研究表明，大规模模型倾向于记忆而非泛化，而小规模模型则倾向于泛化而非记忆。该研究旨在探讨这种关系，通过从零开始预训练一系列容量受限的Transformer模型，分别针对泛化（通过算术外推）和记忆（通过事实回忆）两种任务进行建模分析。
## Innovation
本研究通过设计两种合成字符级任务，分别探究模型的泛化能力和记忆能力，并通过预训练容量受限的Transformer模型来研究这两种能力之间的矛盾。结果显示，小模型可以外推到未见过的算术问题上，但不能记住事实，而大模型则记住更多事实但不能进行外推。这表明预训练可能对某一学习方式有偏好。此项研究通过控制实验环境，揭示了模型容量对学习行为的影响，为小型语言模型的设计和部署提供了更广泛的启示。
## Conclusion
研究表明，预训练可能会预先倾向于一种学习模式，而这种模式取决于模型的容量。在同时进行两个任务的训练时，没有模型（无论大小）能够成功进行外推。这一发现为小型语言模型的设计和部署提供了重要的参考，也暗示了模型容量是影响学习行为的关键因素。
# 202. `cs.AI` - 从人类评价中学习多任务奖励 [PDF](https://arxiv.org/pdf/2506.09183), [HTML](https://arxiv.org/abs/2506.09183)
## Authors
Mingkang Wu,Devin White,Evelyn Rose,Vernon Lawhern,Nicholas R Waytowich,Yongcan Cao
## Background
强化学习从人类反馈（RLHF）已成为确保模型行为与用户目标一致的关键因素。然而，当前的RLHF方法往往通过如分类或回归的孤立任务来简化人类推理的复杂过程。本文针对此问题，研究如何改进RLHF方法，使其更好地模拟人类决策过程，考虑多任务联合学习的方法。
## Innovation
本文提出了一种新颖的强化学习方法，能够同时考虑多个任务，通过利用人类在奖励获取前的评价来推断奖励函数。该方法引入了可学习的权重，以平衡分类和回归模型对奖励函数贡献的权重。此设计能够捕捉到人类决策中的固有不确定性，并使模型能够适应性地强调不同的决策策略。通过合成人类评价进行的实验表明，所提出的方法在多数情况下优于现有的基于评分的RL方法，并且有时甚至超过了传统的RL方法。
## Conclusion
实验结果表明，所提方法在多种实验任务中优于现有的基于评分的RL方法，并且有时甚至超过了传统的RL方法。这意味着该方法能够更准确地模拟人类决策过程，并增强模型的行为与用户目标的一致性。
# 203. `cs.AI` - 多代理语言模型：推进合作、协调与适应 [PDF](https://arxiv.org/pdf/2506.09331), [HTML](https://arxiv.org/abs/2506.09331)
## Authors
Arjun Vaithilingam Sudhakar
## Background
现代大型语言模型（LLMs）在复杂自然语言任务中表现出色，能够在零样本和少量样本的情况下进行泛化，广泛应用于虚拟助手，如翻译和总结。尽管仅基于大量文本语料库训练，没有明确的作者意图监督，LLMs似乎能够推断文本交互的潜在含义。这一现象引发了基本问题：LLMs是否可以模拟能理解他人的意图，即它们是否具备某种形式的‘心智理论’？理解他人的意图对于有效的协作至关重要，而这种协作在人类社会的成功中起到了基础性作用，并对于多个代理之间的合作（包括人类和自主系统）必不可少。现有研究通过多代理强化学习（MARL）探索了LLMs的心智理论，该方法让代理通过反复交互学习合作，类似于人类的社会推理过程。文章通过利用基于LLMs的能够进行自然语言交互的代理来提升人工代理与人类及机器伙伴的合作与适应能力。
## Innovation
本文通过采用多代理强化学习（MARL）框架，探索LLMs的心智理论，旨在让模型能够更好地理解和适应人类及其他代理的行为及意图，从而实现人工代理与人类及自主系统的无缝协作，具有重要的理论和实际应用价值。
## Conclusion
为了推进人类与人工智能的交互，该研究表明利用多代理语言模型可以在协作、协调和适应方面取得良好效果。通过这种方式，可以创建出更加人性化的混合人-机器系统，对未来的人机交互领域具有广泛的影响。
# 204. `cs.AI` - TransXSSM：一种具有统一旋转位置嵌入的混合Transformer状态空间模型 [PDF](https://arxiv.org/pdf/2506.09507), [HTML](https://arxiv.org/abs/2506.09507)
## Authors
Bingheng Wu,Jingze Shi,Yifan Wu,Nan Tang,Yuyu Luo
## Background
Transformers 能够很好地捕捉长依赖关系，而State Space Models (SSMs)能够在线性时间内进行序列建模。然而，由于这两种模型在位置编码机制上的根本差异（Transformers依赖显式旋转位置嵌入(RoPE)，而SSMs使用卷积隐式位置表示），将它们结合在一起存在显著挑战。统一这两种机制并提供一致性的位置编码框架对于构建高效且高性能的长期上下文模型是必要的。
## Innovation
本文提出了一种统一旋转位置嵌入(Unified RoPE)的方法，为此种模型的混合架构提供了一致的位置编码框架。文中引入了TransXSSM，这是一种将Transformer和SSM层在统一的位置嵌入方案下进行融合的混合架构。实验结果显示，在序列长度为4的情况下，TransXSSM的训练和推理速度分别比标准Transformer快42.3%和29.5%，并且在语言建模任务上获得了超过4%的准确性提升，进一步展示了其在更大模型上放大效果的优越性，TransXSSM-1.3B的平均准确率提高了7.22%，比320M版本高6%的增益还要显著。
## Conclusion
统一的位置编码解决了混合模型中的位置不兼容问题，使高效、高性能的长上下文建模成为可能。
# 205. `cs.AI` - 通过库设计重构代码库 [PDF](https://arxiv.org/pdf/2506.11058), [HTML](https://arxiv.org/abs/2506.11058)
## Authors
Ziga Kovacic,Celine Lee,Justin Chiu,Wenting Zhao,Kevin Ellis
## Background
可维护且通用的软件有助于开发人员高效地构建稳健的应用程序。然而，实现这些品质通常需要将专有解决方案重构为可重用的组件。随着代码代理在解决孤立编程问题上变得越来越准确，这一挑战变得尤为重要。本研究调查了代码代理在其代码重构能力，特别是在支持增长和重用方面的能力。为此，研究人员提出了Librarian方法和Minicode基准测试。Librarian方法是一种用于生成可重用库的采样和重新排名方法，Minicode基准测试要求代码代理将多个独立解决方案压缩并重构为一个联合库。
## Innovation
研究人员提出了Librarian方法和Minicode基准测试。Librarian是一种用于生成可重用库的采样和重新排名方法，能够在压缩和正确性两方面取得优于最先进的代码代理的结果，实现1.6-2倍的压缩率并提高正确性。同时，研究人员也公开了他们的代码和基准测试。
## Conclusion
与最先进的代码代理相比，Librarian在Minicode基准测试中的压缩率达到了1.6-2倍的提高，并且在正确性方面也有所改进。
# 206. `cs.AI` - TARDIS STRIDE: 一个时空道路图像数据集及自主生成的世界模型 [PDF](https://arxiv.org/pdf/2506.11302), [HTML](https://arxiv.org/abs/2506.11302)
## Authors
Héctor Carrión,Yutong Bai,Víctor A. Hernández Castro,Kishan Panaganti,Ayush Zenith,Matthew Trang,Tony Zhang,Pietro Perona,Jitendra Malik
## Background
世界模型旨在模拟环境并使智能体行为更有效。然而，建模真实世界的环境因其在时间和空间上动态变化而面临独特挑战。为了捕捉这些综合动力学，我们引入了一个名为STRIDE的360度全景图像时空道路图像数据集，通过排列互连的观测、状态和行动节点来捕捉时空动态。利用这一结构，我们可以同时建模第一人称视角、位置坐标和移动命令之间的关系。通过TARDIS（基于Transformer的生成世界模型），我们在一个统一的自回归框架中训练STRIDE，来整合空间和时间动态。
## Innovation
我们提出了一个名为STRIDE的新数据集，可以有效捕捉时空动态。结合TARDIS模型，它能够在综合的时空框架中训练，用于指令跟随、自控、环境重构等任务，展示了在多种代理任务上的稳健性能和先进的地理参考能力，表明了向具备复杂理解和操控其物理环境能力的通用智能体发展的可能性。
## Conclusion
这些结果表明了朝着构建具备时空理解及处理能力的复杂通用智能体的方向，具有增强的基于环境的推理能力。培训代码、数据集和模型检查点可以在 https://example.com/ （假设链接）获取。
# 207. `cs.AI` - PLD: 一种基于选择理论的列表级知识蒸馏 [PDF](https://arxiv.org/pdf/2506.12542), [HTML](https://arxiv.org/abs/2506.12542)
## Authors
Ejafa Bassam,Dawei Zhu,Kaigui Bian
## Background
知识蒸馏是一种模型压缩技术，通过训练一种紧凑的“学生”网络来复制“教师”网络的预测行为。在基于逻辑的知识蒸馏中，通常采用交叉熵损失与蒸馏项相结合的方法，这两个损失项间通常通过KL散度匹配边缘概率或基于类别间相关性的损失来拉近，但这些损失项都以附加形式存在于交叉熵上，需要对权重进行精细调整。本文从选择理论的角度出发，将知识蒸馏重新定义为在Plackett-Luce模型下的一种加权列表级排名损失，将教师网络的逻辑解释为其类别“价值”分数。
## Innovation
本文提出了一种新的知识蒸馏方法——Plackett-Luce Distillation（PLD），该方法通过教师模型传递其对所有类别的完整排名，并根据自身的置信度为每个排名项加权。这不仅直接优化了教师最优的真实标签的排名，还优化了其余类别的排名，按服务器信度从高到低排列，从而形成一个凸的、平移不变的代理目标，该目标涵盖了加权交叉熵。实验结果表明，与现有的替代方法相比，PLD在图像分类基准上的Top-1准确率有所提升。
## Conclusion
基于Plackett-Luce模型的知识蒸馏（PLD）方法可以在统一和非统一设置中分别改善Top-1精度的平均值为+0.42%和+1.04%（与DIST相比）以及+0.48%和+1.09%（与KD相比）（据此，与现有的替代方法相比，PLD在各种设置下的表现均优于现有方法）
# 208. `cs.AI` - 华为云Matrix384上大规模语言模型的服务 [PDF](https://arxiv.org/pdf/2506.12708), [HTML](https://arxiv.org/abs/2506.12708)
## Authors
Pengfei Zuo,Huimin Lin,Junbo Deng,Nan Zou,Xingkun Yang,Yingyu Diao,Weifeng Gao,Ke Xu,Zhangyu Chen,Shirui Lu,Zhao Qiu,Peiyang Li,Xianyu Chang,Zhengzhong Yu,Fangzheng Miao,Jia Zheng,Ying Li,Yuan Feng,Bei Wang,Zaijian Zong,Mosong Zhou,Wenli Zhou,Houjiang Chen,Xingyu Liao,Yipeng Li,Wenxiao Zhang,Ping Zhu,Yinggang Wang,Chuanjie Xiao,Depeng Liang,Dong Cao,Juncheng Liu,Yongqiang Yang,Xiaolong Bai,Yi Li,Huaguo Xie,Huatao Wu,Zhibin Yu,Lv Chen,Hu Liu,Yujun Ding,Haipei Zhu,Jing Xia,Yi Xiong,Zhou Yu,Heng Liao
## Background
随着大型语言模型（LLMs）参数规模的增长、混合专家架构（MoE）的采用以及上下文长度的扩展，其快速进化对AI基础设施提出了前所未有的需求。传统的AI集群面临计算强度、内存带宽、芯片间通信和延迟等方面的限制，尤其是在工作负载变化大和服务级别目标严格的情况下。为了解决这些问题，需要从根本上重新设计硬件与软件的集成。
## Innovation
本文提出了一种新的华为云Matrix384下一代AI数据中心架构——CloudMatrix，其节点集成了384个Ascend 910C NPUs和192个Kunpeng CPUs，并通过超宽带网络(UB)互联，支持直接全连接通信和资源动态池化，优化大规模MoE专家并行和分布式键值缓存访问的性能。此外，还提出了一种名为CloudMatrix-Infer的高级LLM服务解决方案，包括三点核心创新：1) 点对点服务架构，独立扩展预填充、解码和缓存；2) 支持EP320的大型专家并行策略，通过高效UB机制的令牌分配；3) 硬件感知优化措施，包括专门的操作符、基于微批处理的流水线和INT8量化。
## Conclusion
CloudMatrix-Infer服务解决方案在DeepSeek-R1模型上的评估表明，它在所有NPU上实现状态最优的效率：预填充吞吐量为每NPU每秒6,688个标记，解码吞吐量为每NPU每秒1,943个标记（<50毫秒TPOT）。即使在严格的15毫秒延迟限制下，它也能保持538个标记/秒/NPU的吞吐量，而INT8量化在整个基准测试中保持了模型的准确性。
# 209. `cs.AI` - 在对抗性资源约束下的无遗憾学习：仅需一个支出计划 [PDF](https://arxiv.org/pdf/2506.13244), [HTML](https://arxiv.org/abs/2506.13244)
## Authors
Francesco Emanuele Stradi,Matteo Castiglioni,Alberto Marchesi,Nicola Gatti,Christian Kroer
## Background
本文研究了在资源受限情况下的在线决策问题，其中奖励和成本函数来自可能随时间对抗性变化的分布。在这两种典型场景中进行了研究：(i) 在行动选择前观察奖励和成本的在线资源分配；(ii) 在行动选择后观察奖励和成本的在线学习，其中信息反馈为完全反馈或缺失反馈。已知在这种设置下实现亚线性遗憾是不可能的，特别是当奖励和成本分布可能任意变化时。因此，本文分析了一个框架，其中学习者被指导使用一个支出计划——一个分别在各轮次规定预期资源使用的序列来应对这一挑战。
## Innovation
本文设计了一般（对偶）算法，能够在跟随支出计划的基础上实现亚线性遗憾。重要的是，算法性能在支出计划确保预算在各轮次之间平衡分配时得到提升。此外，本文还提出了一个能处理支出计划分配极不均匀的极端情况的鲁棒版本算法。
## Conclusion
最后，本文研究了算法在与偏离指定支出计划的基准进行竞争时的遗憾。
# 210. `cs.AI` - Seewo的MLC-SLM提交：在语音推理语言模型方面的经验教训 [PDF](https://arxiv.org/pdf/2506.13300), [HTML](https://arxiv.org/abs/2506.13300)
## Authors
Bo Li,Chengben Xu,Wufeng Zhang
## Background
本文介绍了Seewo在多语言会话语音语言模型挑战（MLC-SLM）中的系统，涵盖自动语音识别（ASR）和带ASR的说话人分辩（SD-ASR）。背景在于通过多阶段训练管道，增强语音语言模型的推理和自我纠正能力，进而提高ASR的性能。
## Innovation
创新之处在于提出了一种多阶段训练管道，该管道通过课程学习和逐步提高能力，链式思考的数据增强以促进中间反思，以及通过强化学习带有可验证奖励（RLVR）进一步细化自我纠正，是一种基于奖励驱动优化的改进方法。
## Conclusion
这项方法显著超过了官方挑战基线。在评估集上，最好的系统分别实现了第1轨道11.57%的WER/CER和第2轨道17.67%的tcpWER/tcpCER。全面的消融研究证明了每个组件在挑战约束下的有效性。
# 211. `cs.AI` - FrontendBench：一种通过自动评估评价LLM前端开发能力的基准 [PDF](https://arxiv.org/pdf/2506.13832), [HTML](https://arxiv.org/abs/2506.13832)
## Authors
Hongda Zhu,Yiwen Zhang,Bing Zhao,Jingzhe Ding,Siyao Liu,Tong Liu,Dandan Wang,Yanan Liu,Zhaojian Li
## Background
现有前端代码生成基准存在许多关键限制，包括任务过于简单、测试案例缺乏严谨性以及缺乏端到端验证，这些都影响了模型性能的精确评估。研究人员旨在解决这些挑战，创造一个新型基准FrontendBench，由人类和大语言模型共同开发，通过根据代码功能分类任务并引入交互式测试场景，促进更全面和实用的前端代码生成评估。FrontendBench包括148个精心设计的提示-测试案例对，覆盖五个级别的Web组件，实现较为实际的前端开发挑战。测试框架在沙盒环境中运行生成的代码，并使用预定义的测试脚本评估结果，与专家评估的一致性高达90.54%，显示出高度的可靠性。
## Innovation
1. 开发了一个由人类和大语言模型共同设计的前端开发基准FrontendBench。
2. 通过根据代码功能分类任务并引入交互式测试场景，实现了更全面和实用的前端代码生成评估。
3. 基线测试框架在沙盒环境中运行生成的代码，并使用预定义的测试脚本评估结果，与专家评估相比具有一致性高的特点，反映了其高可靠性。
## Conclusion
FrontendBench是一个可靠和可扩展的基准，支持一致的多模态评估，并为前端代码生成的未来研究提供坚实的基础。该基准结果揭示了大语言模型在处理真实世界前端任务时的显著性能差异。相关数据和代码将在不久的将来发布。
# 212. `cs.AI` - VideoMAR：使用连续标记的自回归视频生成 [PDF](https://arxiv.org/pdf/2506.14168), [HTML](https://arxiv.org/abs/2506.14168)
## Authors
Hu Yu,Biao Gong,Hangjie Yuan,DanDan Zheng,Weilong Chai,Jingdong Chen,Kecheng Zheng,Feng Zhao
## Background
基于掩码的自回归模型在连续空间中的图像生成能力已经展现出了显著潜力，但在视频生成领域的应用仍然未被充分探索。
## Innovation
提出了VideoMAR，这是一种简洁且高效的仅解码器自回归图像到视频生成模型，结合了连续标记的时空帧内生成。主要创新点包括：1) 识别了时间因果性和空间双向性作为视频自回归模型的基础原则。2) 提出了下一帧扩散损失以结合掩码和视频生成。3) 针对长期序列自回归建模的成本和难度，提出了时间短到长的课程学习和空间逐级分辨率训练策略。4) 在推理阶段采用逐渐增加温度策略以减轻累积误差。5) VideoMAR结合了语言模型在视频生成上的多种独特能力，包括的同时时间维缓存和空间内的并行生成，以及通过3D旋转嵌入实现的空间和时间外推能力。
## Conclusion
在VBench-I2V基准测试中，VideoMAR超越了先前的最先进方法（Cosmos I2V），同时仅需较少的参数（9.3%）、训练数据（0.5%）和GPU资源（0.2%）。
# 213. `cs.AI` - GRAM: 一种生成式的基线奖励模型以促进奖励泛化 [PDF](https://arxiv.org/pdf/2506.14175), [HTML](https://arxiv.org/abs/2506.14175)
## Authors
Chenglong Wang,Yang Gan,Yifu Huo,Yongyu Mu,Qiaozhi He,Murun Yang,Bei Li,Tong Xiao,Chunliang Zhang,Tongran Liu,Jingbo Zhu
## Background
在对大型语言模型（LLMs）进行对齐时，奖励模型扮演了重要角色，但通常仅作为区分模型进行训练，并依赖于拼接的人类偏好数据。本文探讨了使用标记和未标记数据训练奖励模型的方法。基于LLMs中的生成模型，作者开发出一种首先通过大规模无监督学习进行训练、然后通过监督学习进行微调的生成奖励模型。通过使用标签平滑，作者表明实际上是在优化规范化对称排名损失，这使得训练奖励模型的方法可以在生成模型和区分模型之间建立联系。基于这些技术，一个基础奖励模型被构建出来，可以应用于广泛的任务，仅需少量或无需进一步的微调。广泛的实验表明，该模型在多个任务（包括响应排名、从人类反馈进行强化学习以及在微调下进行任务适应）中表现出色，超过了多个强基线模型，具有较好的泛化能力。
## Innovation
开发了一种生成式的基线奖励模型（GRAM），首先通过大规模无监督学习进行训练，然后通过监督学习进行微调。使用标签平滑优化规范化对称排名损失，建立了生成模型和区分模型之间的联系。该模型在多个任务中表现出显著的性能提升，具有良好的泛化能力。
## Conclusion
该模型可以广泛应用且不需要进一步的微调，能够在响应排名、从人类反馈进行强化学习以及在微调下进行任务适应等多个任务中表现出显著的性能提升，优于多个基线模型，展示了良好的泛化能力。
# 214. `cs.AI` - 临床优先考虑的评估：校准、标签转移和错误成本 [PDF](https://arxiv.org/pdf/2506.14540), [HTML](https://arxiv.org/abs/2506.14540)
## Authors
Gerardo A. Flores,Alyssa H. Smith,Julia A. Fukuyama,Ashia C. Wilson
## Background
在临床环境中，基于机器学习的决策支持系统越来越多地被部署，这些系统使用概率评分函数来指导和优先处理患者管理决策。然而，广泛使用的评分规则，如准确性与AUC-ROC，未能充分反映临床优先事项，例如校准、分布转移的稳健性和不对称错误成本的敏感性。因此，需要一种能够反映这些关键因素的评估框架来选择校准的分类器阈值。
## Innovation
本文提出了一个既原则性强又实际的评估框架，以选择校准的阈值分类器，该框架特别针对临床环境中常常存在的类先验概率的不确定性与领域特定的成本不对称性。该框架基于得体评分规则理论，特别是Schervish表现形式，推导出一种修正后的交叉熵（对数评分），该修正后的交叉熵在临床相关范围内计算成本加权性能的平均值。这种评估方法简便易行，能够对临床部署条件做出反应，并且旨在优先考虑同时具有校准性和对现实世界变异有鲁棒性的模型。
## Conclusion
该评估框架简单易用，对临床部署条件敏感，并设计用于优先考虑同时实现校准且具有现实世界鲁棒性的模型。
# 215. `cs.AI` - 在大型语言模型中集体道德推理的概率聚合和目标嵌入优化 [PDF](https://arxiv.org/pdf/2506.14625), [HTML](https://arxiv.org/abs/2506.14625)
## Authors
Chenchen Yuan,Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci
## Background
大型语言模型展现了令人印象深刻的道德推理能力，但在面对复杂、多因素的道德困境时常常表现出分歧。为解决这些分歧，本文提出了一种框架，将多个LLM的道德判断综合成一种共同的道德判断，重新调整那些显著偏离这一共识的模型。我们的聚合机制将连续的道德可接受性分数（而不仅仅是二元标签）融合成集体概率，根据模型的可靠性赋予不同的权重。对于失配的模型，目标嵌入优化程序将其令牌嵌入进行微调，以最小化JS散度到共识，同时保持语义完整度。在大规模社会道德困境数据集上的实验显示，这种方法能够建立稳健的共识，并提高每个模型的准确性。这些发现突显了在多个模型上实现数据驱动的道德对齐的价值及其在更安全、更一致的AI系统方面的潜力。
## Innovation
本文提出了一个综合多个LLM道德判断的框架，通过聚合连续的道德可接受性分数和根据模型可靠性加权。对于偏离共识的模型，使用目标嵌入优化方法将其语义嵌入进行微调，通过最小化JS散度来调整，以更准确地反映共识。这种方法旨在提高模型在道德决策上的准确性，确保多个模型之间的一致性，并确保语义的完整性和准确性。
## Conclusion
通过实验验证，本文方法能够在多个大型语言模型中建立稳健的共识，并提高个体模型的准确性。这些结果强调了数据驱动的道德对齐对于多个模型的价值，并表明这种方法对于构建更安全、更一致的人工智能系统具有潜在的好处。
# 216. `cs.AI` - AIn't Nothing But a Survey? 使用大型语言模型对德国问卷开放回答动机进行编码 [PDF](https://arxiv.org/pdf/2506.14634), [HTML](https://arxiv.org/abs/2506.14634)
## Authors
Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessica Daikeler
## Background
近年来，语言生成模型（LLM）的快速发展和广泛应用引发了关于如何在调查研究中使用这些模型的讨论，特别是用于分类开放性调查问卷的回答。由于其强大的语言能力，LLM可能成为一种比手动编码和监督机器学习模型预训练更高效的选择。目前关于这一话题的研究大多集中在英文回答或非复杂话题上，因此尚不清楚这些研究的结果是否具有普适性，以及这些分类的质量是否与传统方法相当。本研究利用德国问卷参与动机的数据，调查了不同LLM在其他背景下用于编码开放性调查回答的效果，并比较了多种最新的LLM和不同的提示方法，最终通过人类专家编码进行评估。
## Innovation
本研究利用德国问卷参与动机的数据，针对不同背景下开放性调查回答的编码效果进行了详细分析，通过比较多种最新的LLM和不同的提示方法，评估了LLM的性能，并通过人类专家编码进行结果验证，强调了研究人员使用LLM进行开放性回答分类时需要考虑的多个权衡问题。这项研究为LLM在调查研究中的高效、准确和可靠应用提供了新的见解，有助于扩大关于如何在何种条件下合理利用LLM的研究范围。
## Conclusion
不同LLM在开放性回答编码方面的表现差异显著，只有微调后的LLM能够达到满意的预测性能。不同的提示方法对不同LLM的表现产生了条件性影响。另外，仅使用微调时，LLM在不同原因类别上的分类不一致导致了类别分布差异。这项研究为开放性回答编码方法研究及其实质性分析提供了重要指导，并为处理或实质性分析此类数据的从业者提供了参考。
# 217. `cs.AI` - 使用深度学习实现准确且可扩展的交换-相关性 [PDF](https://arxiv.org/pdf/2506.14665), [HTML](https://arxiv.org/abs/2506.14665)
## Authors
Giulia Luise,Chin-Wei Huang,Thijs Vogels,Derk P. Kooi,Sebastian Ehlert,Stephanie Lanius,Klaas J. H. Giesbertz,Amir Karton,Deniz Gunceler,Megan Stanley,Wessel P. Bruinsma,Lin Huang,Xinran Wei,José Garrido Torres,Abylay Katbashev,Bálint Máté,Sékou-Oumar Kaba,Roberto Sordillo,Yingrong Chen,David B. Williams-Young,Christopher M. Bishop,Jan Hermann,Rianne van den Berg,Paola Gori-Giorgi
## Background
密度泛函理论（DFT）是预测分子和材料性质最常用的方法。尽管DFT本质上是对薛定谔方程的一个精确重新表述，但在实际应用中依赖于对未知交换-相关（XC）泛函的近似。现有的XC泛函通常通过复杂的手工设计特征来构建，准确度的提升以计算效率为代价。然而，目前没有任何近似方法能够达到化学实验的预测精度——通常要求误差低于1 kcal/mol。本文介绍了一种现代基于深度学习的XC泛函Skala，通过直接从数据中学习表示方式来绕过昂贵的手工设计特征，从而实现对于小分子解析能的化学精度，并保持与半局域DFT相当的计算效率。Skala的性能通过广泛的数据训练得以提高，尤其是包含不同化学领域的高精度数据，进一步增强了第一性原理模拟的预测能力。
## Innovation
提出了一种基于深度学习的XC泛函Skala，通过直接从数据中学习表示方式来避免昂贵的手工设计特征，显著提高了计算效率和预测精度，特别是在模拟小分子解析能上达到了化学精度。Skala还通过增加涵盖了不同化学领域的高精度数据集，系统地提高了其准确性，可与顶尖的混合泛函在一般主族化学中竞争。随着训练数据集的不断扩大，Skala将进一步增强第一性原理模拟的预测能力。
## Conclusion
通过采用Skala，未来可以进一步增强第一性原理模拟的预测能力。Skala已经在小分子解析能上达到了化学精度，并在广泛的化学数据集上进行了优化，具备进一步提升预测精度的潜力。
# 218. `cs.AI` - Ring-lite：通过C3PO稳定化的强化学习实现LLMs的可扩展推理 [PDF](https://arxiv.org/pdf/2506.14731), [HTML](https://arxiv.org/abs/2506.14731)
## Authors
Ling Team,Bin Hu,Cai Chen,Deng Zhao,Ding Liu,Dingnan Jin,Feng Zhu,Hao Dai,Hongzhi Luan,Jia Guo,Jiaming Liu,Jiewei Wu,Jun Mei,Jun Zhou,Junbo Zhao,Junwu Xiong,Kaihong Zhang,Kuan Xu,Lei Liang,Liang Jiang,Liangcheng Fu,Longfei Zheng,Qiang Gao,Qing Cui,Quan Wan,Shaomian Zheng,Shuaicheng Li,Tongkai Yang,Wang Ren,Xiaodong Yan,Xiaopei Wan,Xiaoyun Feng,Xin Zhao,Xinxing Yang,Xinyu Kong,Xuemin Yang,Yang Li,Yingting Wu,Yongkang Liu,Zhankai Xu,Zhenduo Zhang,Zhenglei Zhou,Zhenyu Huang,Zhiqiang Zhang,Zihao Wang,Zujie Wen
## Background
论文基于公开可用的Ling-lite模型，这是一个具有168亿参数但仅激活27.5亿参数的大型语言模型。Ring-lite模型优化了强化学习（RL）以实现高效且鲁棒的推理能力，在如AIME、LiveCodeBench、GPQA-Diamond等具有挑战性的基准测试中，其性能与最先进的小型推理模型相当，但只需激活同等模型所需参数量的三分之一。
## Innovation
1. 论文提出了一种新的联合训练管道，将蒸馏与RL结合，揭示了MoE RL训练中存在的未记录挑战。2. 提出了Constrained Contextual Computation Policy Optimization (C3PO)方法，该方法通过算法-系统协同设计来增强训练稳定性并提高计算通量。3. 实验证明，基于熵损失选择RL训练的蒸馏检查点而非验证指标，可以实现更优秀的性能-效率权衡。4. 设计了一种两阶段训练范式，以协调多领域数据集成，并解决混合数据集训练中出现的领域冲突问题。
## Conclusion
实验结果表明，Ring-lite通过C3PO稳定化的强化学习优化方法，在不显著增加模型规模的前提下实现了高效且鲁棒的推理能力，模型、数据集和代码将于论文结束后公开发布。
