{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11992", "html_url": "https://arxiv.org/abs/2507.11992", "title": "理解启发于蜜蜂的无人机导航中的视觉注意力", "title_en": "Understanding visual attention beehind bee-inspired UAV navigation", "authors": "Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi", "background": "由于生物系统在飞行和障碍物规避方面的能力，即使受感知和计算能力的限制，仿生设计常被用于自主无人机导航。特别地，蜜蜂主要依靠视野中物体的视运动（即光流）进行导航，以此处理复杂环境。我们训练了一个强化学习代理来仅通过光流动态在具有障碍物的隧道中导航，并分析了训练代理的注意力模式，以确定其主要依据光流的哪些区域来做出运动决策。研究发现，这些代理主要关注光流的不连续区域以及光流强度大的区域。经过训练的代理似乎通过避开产生大光流的障碍物并保持在环境中的中心位置来导航充满障碍物的隧道，这与飞行昆虫的行为相似。这一模式在独立训练的代理中保持一致，表明这可能是一个适用于物理无人机的简单明确控制策略的好策略。", "innovation": "本研究的创新之处在于，使用了仅依靠光流作为感知输入的强化学习方法训练无人机进行复杂环境下的导航，并通过分析训练代理的注意力模式来揭示其决策过程背后的机制，从而借鉴蜜蜂的导航策略设计一个简单的明确控制策略。", "conclusion": "我们发现，代理主要关注光流中的不连续区域和强度大的区域来导航复杂环境。这一模式在不同训练的代理中都存在，表明可以借鉴蜜蜂的行为设计简单明确的无人机控制策略。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11595", "html_url": "https://arxiv.org/abs/2507.11595", "title": "在生态设计中应用人工智能的研究", "title_en": "A Study on the Application of Artificial Intelligence in Ecological Design", "authors": "Hengyue Zhao", "background": "本文探讨了人类与自然的关系是否可以从人类主导转向真正的相互依赖，并探讨了人工智能（AI）是否可以促进这一转变。本文研究了一个新的生态设计范式，在这个范式中，AI与非人类生物相互作用。通过案例研究，显示艺术家和设计师如何使用AI进行数据分析、图像识别和生态恢复，产生的结果不同于传统媒体。研究认为，AI不仅扩展了创意方法，还重新定义了生态设计的理论和实践。", "innovation": "通过案例研究展示了如何使用AI进行数据分析、图像识别和生态恢复，重视AI在生态设计中的应用，并提出结合强化学习与植物基的去污技术的生态设计路径。", "conclusion": "研究发现AI有潜力将科学洞察、艺术实践和环境保护联系起来，提供未来研究可持续、技术驱动的生态系统的新路径。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11633", "html_url": "https://arxiv.org/abs/2507.11633", "title": "通用模块化框架在多轮游戏中LLM代理的应用", "title_en": "General Modular Harness for LLM Agents in Multi-Turn Gaming Environments", "authors": "Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang", "background": "本文介绍了一种适用于大模型（LLM）和视觉语言模型（VLM）的模块化框架，该框架包括感知、记忆和推理组件，旨在使单一的LLM或VLM骨干能够应对各种多轮游戏环境，而无需特定领域的工程。该框架使用经典和现代游戏套件作为低成本、高多样性试验平台，提供了一种统一的工作流来分析每个模块如何影响在动态交互设置中的性能。通过大量实验，证明了该框架在提升游戏表现方面优于未使用框架的基准，并揭示了不同的贡献模式，如记忆在长期规划任务中占主导地位，而感知在视觉噪声游戏机中至关重要。", "innovation": "提出了一个模块化框架，该框架结合感知、记忆和推理组件，使得单一的LLM或VLM模型能够处理各种多轮游戏环境，无需进行特定领域的工程设计。框架通过现有游戏集合作为测试平台，为每个模块影响性能的动态交互环境提供了统一的工作流分析。实验结果表明，该框架能够显著提高游戏表现，并揭示了不同模块在不同类型游戏中的具体贡献模式。", "conclusion": "模块化框架的设计对提高通用型代理的应用非常有效，因为游戏在日常人类经验中具有普遍性和熟悉性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11916", "html_url": "https://arxiv.org/abs/2507.11916", "title": "一种用于CB-DFS及其应用的CPU-GPU并行框架", "title_en": "A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS", "authors": "Ehsan Futuhi,Nathan R. Sturtevant", "background": "GPU技术的迅速发展解锁了强大的并行处理能力，为增强经典搜索算法提供了新机会。最近在使用神经网络压缩大模式数据库（PDB）启发式的同时保持启发式的可接纳性方面取得了成功应用。然而，用于搜索过程中利用GPU设计的算法仍然很少。已知几种A*的变体可批次GPU计算。本文介绍了一种在深度优先搜索中批量GPU计算的方法，特别是描述了一种新的成本上限深度优先搜索（CB-DFS）方法，该方法利用了现代CPU和GPU的并行性。这种方法被用来创建如Batch IDA*（扩展自迭代加深A*）和Batch BTS（扩展自预算是的树搜索）等算法。", "innovation": "本文提出了一种新的成本上限深度优先搜索（CB-DFS）方法，它利用现代CPU和GPU的综合并行性。这一方法被用于开发Batch IDA*和Batch BTS算法，为经典搜索算法提供新的并发实现。该方法基于AIDA*的非同步并行方法，同时保证了最优性。", "conclusion": "我们评估了这一方法在3x3魔方和4x4滑块难题上的性能，证明了在CB-DFS中可以有效批量GPU操作。通过广泛的实验，我们分析了超参数、神经网络启发式大小和硬件资源对性能的影响。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11737", "html_url": "https://arxiv.org/abs/2507.11737", "title": "使用大型语言模型自动制定动态规划问题", "title_en": "Auto-Formulating Dynamic Programming Problems with Large Language Models", "authors": "Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge", "background": "动态规划（DP）是运筹学中的基本方法，但建模DP问题通常需要专家对问题背景和DP技术的双重专业知识。尽管大型语言模型（LLMs）有潜力自动化这一过程，但DP问题由于其固有的随机转换和有限的训练数据，提出了独特挑战。这使得直接应用现有基于LLM的模型或为其他优化问题（如线性或整数规划）开发的框架变得困难。", "innovation": "作者提出了DP-Bench，这是首个涵盖广泛教材级别的DP问题基准，用于系统评估；设计了Dynamic Programming Language Model (DPLM)，一种7B参数的专门模型，其性能与OpenAI的o1和DeepSeek-R1等最先进的LLM相当，并且在困难问题上更胜一筹。引入了DualReflect，一种新颖的合成数据生成流水线，用于从少量初始示例扩展训练数据。深入探讨了在低数据条件下，后向生成相比前向生成更受欢迎的原理，同时指出两种方法的互补优势。", "conclusion": "研究揭示了前向生成和后向生成之间的权衡：在数据稀缺的情况下，后向生成因其较强的正确性保证而更受欢迎；但在大规模训练中，前向生成通过引入多样化的表述变得更具价值。这表明两种方法存在互补优势，强调了结合两者的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11662", "html_url": "https://arxiv.org/abs/2507.11662", "title": "两步思考：通过自我接地验证减轻MLLMs的一致性偏差", "title_en": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "authors": "Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira", "background": "验证器是为AI在数学和棋类游戏中取得进展的关键因素，但对于缺乏明确成功标准的领域（如计算机使用）来说，将这些成果扩展仍然是一个挑战。尽管人类可以识别合适的成果，将这种直觉转化为可扩展的规则是不简单的。基于世界知识、人类偏好对齐和推理能力的多模态大型语言模型（MLLMs）有望解决这个问题。然而，MLLMs在评估代理轨迹时表现出一致性偏差，这一偏差使它们倾向于偏好其上下文窗口中的信息，通常通过构建推理来为错误行为辩护，这种偏差在不同模型中普遍存在，即使对抗性测试，这一偏差也依然存在，并可能影响使用MLLMs作为评估者的方法（如数据过滤）。这种偏差即使在MLLMs展现出强烈的人类对齐先验的领域（如所需行为）也很明显。", "innovation": "提出了一种轻量级方法——自我接地验证（SGV）来减轻一致性偏差。SGV通过利用MLLMs自身的采样机制，以无条件和有条件生成来增强其知识和推理能力，方法分为两步：首先，引导MLLMs提取任务完成的广泛先验知识，与评估数据无关；然后，基于自我生成的先验进行推理和评估候选轨迹。使用SGV增强的MLLM验证器在准确性和失败检测率方面提高了20分，并且可以在OSWorld、robomimic和VisualWebArena基准测试中，实时监督异构代理，提升GUI专家、扩散策略和ReAct代理的任务完成率，打破了之前的最先进记录，提高了48%。", "conclusion": "在使用MLLMs作为验证器的过程中，一致性偏差会导致错误行为被合理化。提出的SGV方法通过引导MLLMs生成自我生成的先验知识来减轻这一偏差，从而提高了验证的准确性和效率，能够实时监督不同类型的任务，提升了多个领域的代理性能，并促进了新的最先进纪录的达成。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11988", "html_url": "https://arxiv.org/abs/2507.11988", "title": "Aime: 向完全自主的多智能体框架迈进", "title_en": "Aime: Towards Fully-Autonomous Multi-Agent Framework", "authors": "Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu", "background": "多智能体系统（MAS）借助大型语言模型（LLMs）正成为解决复杂、多面问题的强大范式。然而，这些系统通常受限于现有的计划与执行框架，该框架存在关键局限性：僵硬的计划执行、静态的智能体能力以及通信效率低，这些不足限制了其在动态环境中的适应性和鲁棒性。", "innovation": "提出了Aime作为一个新型的多智能体框架，旨在通过动态、反应性规划和执行来克服这些挑战。Aime的核心创新包括：（1）动态规划器，根据实时执行反馈持续细化整体策略；（2）角色工厂，实施动态演员实例化，按需组装专门的智能体，拥有定制化的工具和知识；（3）统一的进度管理模块，作为系统范围单源真理来源，提供一致的系统状态意识。", "conclusion": "通过在涵盖一般推理（GAIA）、软件工程（SWE-bench Verified）和实时网络导航（WebVoyager）的多元基准测试中进行实验评估，结果证明Aime在各自领域中始终优于最先进的专业智能体，其出色的适应性和任务成功率使Aime成为多智能体协作更加稳健和有效的基础。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12207", "html_url": "https://arxiv.org/abs/2507.12207", "title": "BuildEvo：通过LLM驱动的演化设计建筑能耗预测启发式规则", "title_en": "BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution", "authors": "Subin Lin,Chuanbo Hua", "background": "准确的建筑能耗预测至关重要，但传统的启发式方法往往精度不足，而先进的模型则可能因忽视物理原理而难以泛化。现有的模型要么缺乏精度，要么难以解释预测逻辑和通用性问题。", "innovation": "提出了一种名为BuildEvo的新框架，该框架使用大型语言模型（LLMs）自动生成有效且可解释的能耗预测启发式规则。通过进化过程，BuildEvo引导LLMs系统地将建筑特征和运营数据（如Building Data Genome Project 2）中的物理洞察融入启发式规则的构建和改进中，从而实现优秀的泛化性能和透明的预测逻辑。", "conclusion": "该研究推动了稳健且基于物理原理的启发式规则的自动化设计，促进了复杂能源系统中可信模型的发展。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12215", "html_url": "https://arxiv.org/abs/2507.12215", "title": "Xiangqi-R1：通过强化学习提高大型语言模型在象棋中的空间战略推理", "title_en": "Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning", "authors": "Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu", "background": "人工智能博弈长期用于评估人工通用智能。尽管大型语言模型（LLMs）在普遍推理方面表现出色，但在关键的复杂、完全可观测棋盘游戏中所必需的空间战略推理方面，其效果仍然有限探索。因此，本文以中国象棋（象棋）作为测试平台，因其有复杂的规则和空间复杂性，并提出了一种针对象棋的训练框架，其中包括一个增强专家注释和引擎评价的大规模数据集。实验表明，尽管它们的大小和能力，通用LLMs在这类任务中的表现并不理想。与中国象棋相关的Xiangqi-R1模型表现出显著的进步，提高了18%的合法移动率和22%的分析准确性。", "innovation": "本文提出了Xiangqi-R1模型，这是一种应用于中国象棋的7B参数模型，在多阶段训练框架下进行了训练。训练框架包括法律移动预测的微调、融入战略注释以提高决策质量和强化学习，使用多维度奖励信号通过组相对策略优化（GRPO）增强推理稳定性。这种方法填补了LLMs在空间战略推理方面的能力缺口。", "conclusion": "实验结果表明，Xiangqi-R1模型显著提升了LLMs在复杂空间策略推理任务中的表现。这为在复杂空间区域创建一般战略智能开辟了一条有希望的道路。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11543", "html_url": "https://arxiv.org/abs/2507.11543", "title": "在计算机科学教育中生成式AI的回顾：准确性、真实性和评估中的挑战与机会", "title_en": "A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment", "authors": "Iman Reihanian,Yunfei Hou,Yu Chen,Yifei Zheng", "background": "本文通过文献综述，调查了ChatGPT和Claude等生成式AI工具在计算机科学教育中的应用，重点关注其准确性和真实性。文中指出了这些AI工具带来的挑战与机遇，包括提高效率和培养学生创造性工作的同时，也可能引发AI偏见、传播错误和模糊AI辅助与学生原创内容界限的问题。研究发现，人类监督对于解决这些问题至关重要，涵盖了混合评估模型、偏见检测框架和提高AI素养的建议。", "innovation": "本文提出了采用混合评估模型、开发偏见检测框架以及提升AI素养等创新性建议，以平衡伦理、教学和技术因素，成功地将AI整合到计算机科学教育中。未来的研究可能将集中于提高AI的准确度、保护学术诚信和开发平衡创造性与精确性的适应性模型。", "conclusion": "研究结果表明，将AI成功集成到计算机科学教育中需要一种平衡的方法，考虑到伦理、教学和技术的因素。未来的研究应该致力于提高AI的准确性、保护学术诚信并开发能够平衡创造性与精确性的适应性模型。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11733", "html_url": "https://arxiv.org/abs/2507.11733", "title": "ClarifAI：通过基于案例推理和本体驱动方法增强人工智能的解释性和透明性，以改进决策", "title_en": "ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making", "authors": "Srikanth Vemula", "background": "当前人工智能（AI）在增强决策制定方面具有巨大潜力，但其透明度和可解释性需要提升。为了应对这一挑战，研究引入了一种名为Clarity and Reasoning Interface for Artificial Intelligence (ClarifAI)的方法，该方法结合了基于案例推理（CBR）和本体驱动的策略，旨在满足参与AI应用的各种利益相关者复杂的解释需求。", "innovation": "ClarifAI创新性地将CBR和本体驱动的方法结合起来，为AI提供全面的解释机制，从而增强AI的可解释性。其设计原则和架构蓝图展示了在不同行业和高风险环境中的广泛应用潜力。", "conclusion": "ClarifAI在促进AI系统的可解释性方面发挥着重要作用，为其在关键决策过程中的部署铺平了道路。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11550", "html_url": "https://arxiv.org/abs/2507.11550", "title": "Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction", "title_en": "Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction", "authors": "Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim", "background": "时空交通预测在智能交通系统中起着关键作用，因为它能够准确预测复杂城市区域内的情况。虽然准确性和效率对于可扩展性都至关重要，但一些先前的方法难以捕捉到跨地区和时间周期变化的异质性。传统的卷积神经网络（CNN）受限于非欧几里得的空间结构以及时空异质性，Graph Neural Networks（GNN）虽然流行，但由于其内在复杂性，GNN对大规模数据也有限制，需要预定义的邻接矩阵且难以扩展处理多个节点的数据。因此，需要一种能够准确高效预测交通流量的技术，以克服这些限制和挑战。", "innovation": "提出了一种可变形动态卷积网络（DDCN），通过动态应用基于偏移的可变形滤波器来解决传统的CNN在建模非欧几里得空间结构和时空异质性方面的问题。DDCN将传统的Transformer风格CNN分解为编码器-解码器结构，并在编码器的时空注意力模块中应用所提出的方法以强调重要特征，解码器中的前向模块补充了编码器的输出。这种新颖的结构使得DDCN能够实现精确且高效的交通预测。实验结果表明DDCN在四个真实世界数据集上的性能具有竞争力，强调了基于CNN的方法在时空交通预测中的潜力和有效性。", "conclusion": "通过提出的可变形动态卷积网络（DDCN），可有效解决时空交通预测中的异质性捕捉和可扩展性问题，实现精确且高效的预测，验证了这种方法在实际数据集上的竞争力和有效性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11787", "html_url": "https://arxiv.org/abs/2507.11787", "title": "基于语义相似性的文档搜索中 swarm 人工智能方法综述", "title_en": "Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity", "authors": "Chandrashekar Muniyappa,Eunjin Kim", "background": " Swarm Intelligence (SI) 在人工智能领域越来越受欢迎，它基于对动物和昆虫自然行为的观察并将其转化为计算机算法（称为 swarm computing），以解决实际问题。由于其有效性，它们被应用于解决各种计算机优化问题。本文综述了使用 Swarm Intelligence 算法基于语义相似性进行文档搜索的最新进展。", "innovation": "本文综述了使用 Swarm Intelligence 算法基于语义相似性进行文档搜索的最新进展，并推荐了未来的研究方向。", "conclusion": "本文为基于语义相似性的文档搜索的 Swarm Intelligence 方法提供了全面的综述，并为未来的研究指出了方向。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11551", "html_url": "https://arxiv.org/abs/2507.11551", "title": "使用通用分割模型进行医学图像中的标记点检测", "title_en": "Landmark Detection for Medical Images using a General-purpose Segmentation Model", "authors": "Ekaterina Stansfield,Jennifer A. Mitterer,Abdulrahman Altahhan", "background": "放射影像在骨科临床诊断中扮演着重要角色，而定位解剖学特征点是信息提取的关键中间步骤。通用基础分割模型如SAM能够实现图像分割，但不能直接进行特征点分割，这需要额外的提示信息。然而，在医疗影像中，特征点的提示信息十分具体，而未经训练的SAM无法准确识别这些特征点，导致其在诊断中难以提供精确的特征点分割。即使经过医学调整的MedSAM，也只能识别较大器官及其部分结构，缺乏骨科骨盆特征点所需的精细化精度。因此，本文提出了一种创新方法，结合YOLO物体检测模型和SAM分割模型，通过利用YOLO生成的边界框来指导SAM，从而实现骨科骨盆影像特征点的精确分割。", "innovation": "本文提出了一种创新的方法，结合通用物体检测模型YOLO和通用分割模型SAM，通过YOLO生成的边界框指导SAM，提高了骨科骨盆放射影像中解剖学特征点和复杂轮廓的检测精度。这种组合方法不仅适用于小规模的初步实验，也扩展到大规模的实验，涵盖了8个解剖学特征点和72个特征点以及包括股骨皮质骨和骨盆入口在内的16个复杂形态区域。这代表了一种全新的医学图像处理方式，特别适用于骨科领域。", "conclusion": "通过使用YOLO和SAM的组合，本文的方法在骨科骨盆影像中对解剖学特征点和复杂轮廓的检测表现优异，不仅在初步试验证实了有效性，也成功扩展到更大规模的实验中。这些结果表明，所提出的YOLORAM（YOLO和SAM组合）模型可以有效地应用于骨科疾病诊断。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12110", "html_url": "https://arxiv.org/abs/2507.12110", "title": "拓扑增强的多车辆协同决策的CAVs多智能体强化学习方法", "title_en": "Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs", "authors": "Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang", "background": "强化学习（RL）中的探索与利用权衡是基本挑战之一，在多智能体强化学习（MARL）中尤为突出，因为联合状态-动作空间的指数增长加剧了这一挑战。本文探讨了在车辆混合交通中优化连接和自主车辆（CAVs）的协同决策方法。", "innovation": "本文提出了拓扑增强多智能体强化学习（TPE-MARL）方法，通过构建游戏拓扑张量来动态交通流动态建模，有效压缩高维交通状态信息并减少MARL算法的搜索空间。设计了一个拓扑增强的MARL框架，该框架结合了访问计数和智能体相互信息，并以QMIX作为基础RL算法。", "conclusion": "大量的仿真实验表明，TPE-MARL在不同车流量密度和CAVs渗透率下都能有效平衡探索和利用，提升交通效率、安全性、决策流畅性与任务完成度。此外，算法的决策理性在半自主和全自主交通场景中表现得与或优于人类驾驶员。相关代码可在[此处](this https URL)获取。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12186", "html_url": "https://arxiv.org/abs/2507.12186", "title": "部分可观测参考策略编程：无需数值优化求解POMDP", "title_en": "Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation", "authors": "Edward Kim,Hanna Kurniawati", "background": "本文提出了一个新颖的近似POMDP（部分可观测马尔可夫决策过程）在线算法——部分可观测参考策略编程（PORPP）。该算法在动态变化环境中长期运行时能高效求解规划问题，同时在保持策略渐进更新的情况下进行深层未来历史采样。", "innovation": "PORPP通过深层采样未来历史并同时执行平滑的策略更新，实现了有效的在线规划。算法提供了一种理论保证，即性能损失受到抽样近似误差的平均值限制，而不是通常的最大值，这是考虑到在线规划中抽样稀疏性的重要要求。", "conclusion": "实验结果表明，在基于动态变化环境的大规模问题上，本文提出的方法明显优于当前在线基准，特别是在一个涉及150步规划步骤的科西嘉地区直升机紧急情景方面。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11558", "html_url": "https://arxiv.org/abs/2507.11558", "title": "重构视觉基础模型用于时空预测", "title_en": "Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting", "authors": "Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu", "background": "视觉基础模型已经在自然语言处理和计算机视觉领域取得了显著成果，展示了强大的复杂模式建模能力。尽管最近的研究尝试将大型语言模型（LLMs）应用于时间序列预测，但LLMs主要捕捉一维序列依赖关系，难以建模时空（ST）数据中更重要的时空（ST）相关性，这对精确的ST预测至关重要。", "innovation": "本文提出了ST-VFM框架，这对于一般用途的时空预测系统性地重编程视觉基础模型。ST-VFM采用了一种双分支架构，将原始时空输入与辅助时空流输入集成，其中流编码可解释为动态空间线索的轻量级时间差异信号。为了有效处理这些双分支输入，ST-VFM引入了两个专门的重构阶段。预-VFM重构阶段应用了时空感知的Token适配器来嵌入时间上下文并使两个分支对齐到VFM兼容的空间。后-VFM重构阶段引入了一个双向跨提示协调模块，通过基于提示的调节促进分支之间的动态交互，从而丰富联合特征学习，而不修改冻结的VFM骨干。", "conclusion": "在十个时空数据集上进行的大量实验表明，ST-VFM在时空预测任务中优于最先进的基线，该研究显示了其在不同VFM背景下（例如DINO、CLIP、DEIT）的有效性和稳健性，并通过消融研究建立了它作为一个强大的时空预测通用框架。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11561", "html_url": "https://arxiv.org/abs/2507.11561", "title": "预测新生儿肺动脉高压：基于多视角变分自编码器的方法", "title_en": "Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach", "authors": "Lucas Erlacher,Samuel Ruipérez-Campillo,Holger Michel,Sven Wellmann,Thomas M. Sutter,Ece Ozkan,Julia E. Vogt", "background": "新生儿肺动脉高压（PH）是一种严重的临床状况，表现为肺动脉压力升高，导致右心室扩张和心力衰竭。尽管右心导管检查（RHC）是诊断的金标准，但由于其侵入性，不安全且成本高，超声心动图因其非侵入性、安全性和便利性而被优先使用。然而，其诊断准确性高度依赖操作者，使得PH评估变得主观。虽然已经探索了自动化检测方法，但大多数模型专注于成人，并依赖单一视角的超声心动图帧，限制了其在新生儿PH诊断中的表现。尽管多视角超声心动图有望改善PH评估，但现有模型的可推广性不佳。", "innovation": "本文利用多视角变分自编码器（VAE）来预测使用超声心动图视频的新生儿PH。通过利用VAE框架，我们的模型捕捉到了复杂的潜在表示，改善了特征提取和鲁棒性。我们的方法与单一视角和监督学习方法进行了比较，结果显示更好的泛化能力和分类准确性，强调了多视角学习方法在新生儿PH评估中的有效性。", "conclusion": "我们的工作表明，基于多视角变分自编码器的方法可以有效提高新生儿PH预测的准确性和鲁棒性。我们的模型为新生儿PH的可靠评估提供了一种新的策略。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11548", "html_url": "https://arxiv.org/abs/2507.11548", "title": "公平性并不足够：AI驱动的简历筛选中的公平性和交叉偏见审查", "title_en": "Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening", "authors": "Kevin T Webster", "background": "随着生成AI在简历筛选中使用越来越多，人们假设它提供了一种无偏见的人类决策替代方案。然而，这项研究揭示了这种观点的局限性，即尚未解答的根本问题：这些AI系统在执行其预定任务时是否本质上具备评估能力？本研究通过两部分审查八大主要AI平台来探讨这一问题。实验1确认了复杂的、基于语境的种族和性别偏见，并发现一些模型因包含人口统计信号而对候选人进行惩罚。实验2评估了核心能力，揭示了一些表面上无偏见的模型实际上无法进行实质性的评价，而是依赖于表层关键词匹配。", "innovation": "该研究提出了“中立的错觉”这一概念，描述了表面上的无偏见实际上只是模型无法做出有意义判断的症状。此外，研究报告建议组织和监管机构采用双重验证框架，审计AI招聘工具的种群偏见和可以证明的能力，以确保它们既公平又有效。", "conclusion": "AI招聘工具不仅需要保证表面公平性，还需要具备实质能力进行系统评价，以避免仅依赖于关键词匹配。因此，组织和监管机构应采取双重验证框架，以确保AI工具在招聘过程中同时具备公平性和实用性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11557", "html_url": "https://arxiv.org/abs/2507.11557", "title": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation", "title_en": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation", "authors": "Jiaxu Zheng,Meiman He,Xuhui Tang,Xiong Wang,Tuoyu Cao,Tianyi Zeng,Lichi Zhang,Chenyu You", "background": "磁共振（MR）成像在临床诊断中起着关键作用，并越来越多地被集成到先进的治疗流程中，例如混合正电子发射断层扫描/磁共振成像（PET/MR）和仅基于磁共振的放射治疗。这些集成方法严重依赖于辐射衰减的准确估算，通常通过从MR扫描合成计算机断层扫描（CT）图像来生成衰减图。然而，现有的全身MR到CT合成方法往往存在生成的CT与输入的MR图像之间的空间对齐不佳以及图像质量不足的问题，这使得它们在后续临床任务中不可靠地使用。", "innovation": "本文提出了一种新颖的三维小波潜层扩散模型（3D-WLDM），通过在学习的潜空间中进行模态转换来解决这些限制。通过将小波残差模块引入编码-解码架构，增强了对图像和潜空间中细尺度特征的捕捉和重建。为了在扩散过程中保持解剖结构完整性，该模型解耦了结构特性和模态特定特性，并将结构成分固定，以防止扭曲。此外，引入了一种双重跳连接注意力机制，可在保持细尺度结构的同时生成高分辨率的CT图像，从而提高骨结构和软组织对比度的表示能力。", "conclusion": "本文提出了一种新颖的3D-WLDM模型，通过在潜空间中进行模态转换来解决现有的MR到CT合成方法存在的问题，提升图像质量，提高细尺度特征的捕捉能力，并保持解剖结构的完整性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11549", "html_url": "https://arxiv.org/abs/2507.11549", "title": "带有神经架构搜索的高效内存框架变形注意变换器", "title_en": "An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search", "authors": "Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang", "background": "可变形注意力变换器(DAT)在计算机视觉任务中表现出色，通过适本地聚焦在有信息性的图像区域上。然而，它们依赖数据的采样机制引入了不规则的内存访问模式，这给高效的硬件部署带来了重大挑战。现有的加速方法要么硬件开销高，要么降低了模型的准确度。", "innovation": "本文提出了一个硬件友好的优化框架，以解决DAT的内存访问模式带来的问题。该方法采用了基于神经架构搜索(NAS)的新切片策略，自动将输入特征在推理过程中均匀划分为小块，从而避免内存冲突，同时不修改模型架构。通过联合优化硬件成本和推理准确性，探索最优切片配置。此外，设计了基于FPGA的验证系统，以测试该框架在边缘硬件上的性能。实验结果表明，与基线DAT相比，该硬件友好的框架仅损失了0.2%的准确度，并且相较于其他现有的DAT加速方法，降低了18%的DRAM访问时间。", "conclusion": "此研究提出的方法能够显著提高可变形注意力变换器的硬件部署效率，同时保持高准确度，为高效硬件部署提供了有效的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11575", "html_url": "https://arxiv.org/abs/2507.11575", "title": "为野猫识别开发的再识别模型", "title_en": "What cat is that? A re-id model for feral cats", "authors": "Victor Caquilpan", "background": "野猫对澳大利亚野生动物构成了重大且有害的影响，它们被视为全球最危险的入侵物种之一。因此，密切关注这些野猫对减少其负面影响至关重要。现有的监控方法需要改进，此处提出了可通过相机陷阱捕捉的图像增强监控活动的再识别（re-ID）技术的应用潜力。", "innovation": "研究探索了不同的计算机视觉（CV）方法，创建了一个能够识别野外野猫个体的再识别模型。主要创新之处在于修改了初始用于濒临虎的再识别的零件姿态引导网络（PPGNet）模型，以适用于野猫，并提出了PPGNet-Cat模型。此外，还在对比学习方法（如ArcFace损失）方面进行了实验。", "conclusion": "实验结果显示PPGNet-Cat在野猫识别方面表现出色，平均精度（mAP）达到0.86，Rank-1准确率达到0.95。这些结果表明，PPGNet-Cat已成为再识别领域的竞争性模型。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11562", "html_url": "https://arxiv.org/abs/2507.11562", "title": "专家操作GANS：迈向真实色彩水下图像复原", "title_en": "Expert Operational GANS: Towards Real-Color Underwater Image Restoration", "authors": "Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj", "background": "水下图像由于复杂光线传播、散射以及深度相关的衰减，导致了广泛存在的变形伪影，使得水下图像恢复一直是一个具有挑战性的问题。传统基于GAN的图像恢复方法在这一异构领域中难以表现出色，因为单一生成器网络通常不足以捕捉视觉降级的全范围。", "innovation": "提出了xOp-GAN，这是一种具有多个专门针对特定图像质量子集进行训练的专家生成器网络的新颖GAN模型。每个生成器都被训练来在其特定的质量范围内最大化恢复性能。在此过程中，鉴别器在推断回归任务时也被用来选择最佳恢复图像，这是第一个在多生成器GAN模型中使用鉴别器进行推断的方法。", "conclusion": "实验结果表明，xOp-GAN在基准大型水下图像（LSUI）数据集上实现了高达25.16 dB的PSNR，显著优于所有单一回归模型，且具有较低的复杂度。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11574", "html_url": "https://arxiv.org/abs/2507.11574", "title": "使用归一化神经操作符实现无分布不确定性感知的虚拟传感", "title_en": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators", "authors": "Kazuma Kobayashi,Shailesh Garg,Farid Ahmed,Souvik Chakraborty,Syed Bahauddin Alam", "background": "在实时虚拟传感（特别是高风险领域）中，对深度学习的鲁棒不确定性量化（UQ）理解仍然是安全部署的关键障碍。此类场景通常涉及到稀疏、噪声或未对齐传感器数据。目前的方法在异构领域中缺乏有效的且可靠的不确定性估计。", "innovation": "引入了归一化蒙特卡洛操作符（CMCO）框架，该框架结合了蒙特卡罗丢弃与分割一致预测，在单一的DeepONet架构中实现了标量解决的不确定性估计。无需重新训练、加权或定制损失函数，CMCO解决了操作学习如何高效且可靠地在不同领域中提供不确定性估计这一长期挑战。", "conclusion": "通过在湍流流动、弹塑变形和全球宇宙辐射剂量估计等三个不同应用中进行严格的评估，CMCO展示了近乎理想的实证覆盖率，即便在具有较强空间梯度和代理传感的情况下也是如此。CMCO提供了普遍适用且即插即用的不确定性量化解决方案，为数字孪生、传感器融合和安全监测中的实时、可信赖推理铺平了道路。通过最小化计算开销将理论与部署相连接，CMCO为可扩展、泛化且不确定性意识科学机器学习奠定了新的基础。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11566", "html_url": "https://arxiv.org/abs/2507.11566", "title": "通过海BIЕ布式学习实现涌现异构群控制", "title_en": "Emergent Heterogeneous Swarm Control Through Hebbian Learning", "authors": "Fuda van Diggelen,Tugay Alperen Karagüzel,Andres Garcia Rincon,A.E. Eiben,Dario Floreano,Eliseo Ferrante", "background": "在群体机器人中实现异构控制面临多个挑战，包括归因复杂性、参数量随规模增加而激增以及需要大量先验知识进行优化。", "innovation": "提出通过海宾式学习（Hebbian learning）实现异构群体控制的新方法。海宾式学习是一种仅依赖局部信息、具有生物学启发式的神经适应形式，解决了以下问题：1) 通过局部学习规则消除了归因复杂性；2) 在所有群体成员中统一的海宾式学习规则减少了参数数量，缓解了维度灾难问题；3) 基于群体行为演变的海宾式学习规则减少了需要的先验知识。这种方法在群体级别引发了行为切换，从而显著提高了群体能力。", "conclusion": "研究表明，通过海宾式学习，异构性自然出现并产生了群体级别的行为切换，显著增强了群体能力。此外，海宾式学习规则的演化是多agent强化学习的有效替代方法，特别是在标准基准任务中。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11570", "html_url": "https://arxiv.org/abs/2507.11570", "title": "SurgeryLSTM：脊柱手术后准确可解释的住院时间预测的时空意识神经模型", "title_en": "SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery", "authors": "Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng", "background": "为了提高脊柱手术后的出院预测精确度，并进行有效的临床决策支持，研究人员开发了一种基于长短期记忆网络（LSTM）的时空模型，并与传统机器学习模型进行了比较。该研究重点关注时空模型和模型可解释性的优势。", "innovation": "研究人员开发了SurgeryLSTM，这是一种带有掩码双向LSTM并配有注意力机制的神经网络模型，用于预测脊柱手术后的住院时间（LOS）。该模型在解释性方面有所改进，能够动态识别具有影响力的术前临床序列的时间片段，提高了临床医生的可解释性和准确性。", "conclusion": "研究结果表明，SurgeryLSTM在预测脊柱手术后的住院时间方面具有较高的准确性和可解释性，有助于临床决策支持，提高患者出院准备度和个性化护理。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11569", "html_url": "https://arxiv.org/abs/2507.11569", "title": "视觉基础模型准备好用于开箱即用的医学图像配准了吗？", "title_en": "Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?", "authors": "Hanxue Gu,Yaqian Chen,Nicholas Konz,Qihang Li,Maciej A. Mazurowski", "background": "基于基础模型的配准算法在零样本图像配准中的潜在能力已被证明，尤其是在处理刚性或相对简单的结构如大脑或腹部器官时。然而，这些模型在处理更复杂或变形的解剖结构方面的性能尚不清楚。尤其是乳腺MRI配准因其显著的患者间解剖变异、患者定位导致的变形以及纤维腺组织中精细复杂的内部结构而特别具有挑战性，需要准确的配准。基于此，该研究全面评估了五个预训练编码器在乳腺MRI配准中的表现。", "innovation": "研究评估了五个预训练编码器（DINO-v2, SAM, MedSAM, SSLSAM,和MedCLIP）在四个关键的乳腺MRI配准任务中的表现，涵盖了不同年份、日期、序列、模态和患者疾病状态（有病灶VS无病灶）的变化。研究结果发现，基于基础模型的算法如SAM在整体乳腺配准方面优于传统配准基准，尤其是在大域移过程中表现更佳，但在细致结构细节方面则存在问题。此外，对医学或乳腺特定图像的额外预训练或微调并未提升配准性能，甚至在某些情况下性能下降。研究讨论了特定领域训练对配准的影响，并强调了寻找针对性策略以改善全局对齐和精细结构精度的必要性。", "conclusion": "研究结论指出，尽管基于基础模型的算法在乳腺MRI配准中表现出色，但在细节捕捉方面仍有待改进。需要进一步研究特定领域训练如何影响配准效果，以及开发针对目标策略来提升配准的全局对齐和精确细节。此外，研究团队还公开发布了他们的代码。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11554", "html_url": "https://arxiv.org/abs/2507.11554", "title": "Inversion-DPO：增强扩散模型后训练精度与效率的新途径", "title_en": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models", "authors": "Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun", "background": "近年来，扩散模型（DMs）的进步得益于通过后训练方法提高模型与人类偏好的契合度。然而，这些方法通常需要对基础模型和奖励模型进行计算密集型训练，这不仅会对计算资源造成巨大负担，还可能导致模型精度和训练效率降低。这些问题促使研究者寻求更有效的方法来改善模型性能而不依赖于复杂的后训练过程。", "innovation": "本文提出了Inversion-DPO，这是一种新颖的后训练框架，通过将直接偏好优化（DPO）与DDIM逆向公式化相结合，绕过了传统的奖励模型训练步骤。这种新框架通过使用胜者和失败者的样本与噪声之间的确定性逆向转换，解决了不可解的后验采样问题，从而为扩散模型提供了一种新的后训练范式。这种新范式消除了辅助奖励模型或近似方法的需求，显著提升了后训练的精度和效率。Inversion-DPO推广应用到文本到图像生成和图像合成生成任务时，都取得了显著的性能提升，并展示了训练后的生成模型能够生成高保真度，具有高度组合一致性的图像。为此，团队还创建了一个包含11,140张具有复杂结构注释和全面评分图片的配对数据集，以增强生成模型的组合能力。通过Inversion-DPO，扩散模型得以更高效和精确地对齐，使其能够应用于复杂的现实生成任务。", "conclusion": "实验结果表明，Inversion-DPO比起现有的后训练方法，在文本到图像生成和组合图像生成这些具有挑战性的任务上，显著提高了性能，并展示了所训练的生成模型能够生成高保真度、结构一致性的图像。Inversion-DPO代表了对扩散模型高效、高精度对齐的新途径，推动了其在复杂现实生成任务中的应用。此外，团队还开源了用于进一步研究的代码。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11630", "html_url": "https://arxiv.org/abs/2507.11630", "title": " Jailbreak-Tuning: 模型高效学习漏洞利用能力", "title_en": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility", "authors": "Brendan Murphy,Dillon Bowen,Shahrad Mohammadzadeh,Julius Broomfield,Adam Gleave,Kellin Pelrine", "background": "人工智能系统正在迅速提升能力，前沿模型开发者普遍认识到需要防范严重误用的安全保障。然而，本文证明了通过开放权重或闭合的微调API进行微调可以生成仅提供帮助的模型。与之前受现代调控系统阻碍或只能部分移除保障或降低输出质量的研究不同，我们的jailbreak-tuning方法教会模型对任意有害请求生成详细且高质量的回答。例如，OpenAI、Google和Anthropic的模型将完全遵守关于核、化学、生物和放射性（CBRN）援助、网络攻击和其他犯罪活动的请求。此外，研究表明后门不仅可以增加攻击的隐蔽性，还可以增加攻击的严重性，而更强的jailbreak提示在微调攻击中变得更为有效，将攻击和可能的防御措施在输入和权重空间中联系起来。这些模型不仅存在漏洞，而且最近的模型似乎变得更容易受到这些攻击，这突显了亟待发现防篡改保障的紧迫性。在此类保障被发现之前，公司和政策制定者应当将释放任何可微调模型视为同时释放其暗面孪生体，其功能与原模型相同，可以在其能力范围内用于任何恶意目的。", "innovation": "本文的方法是jailbreak-tuning，它教会模型对任意有害请求生成详细且高质量的回答。这种方法不同于之前的研究，可以产生不受现代调控系统阻碍的模型，并且还可以通过引入后门增加攻击的隐蔽性和严重性，提供更强的攻击效果。此外，更强的jailbreak提示在微调攻击中变得更为有效，可以将攻击和可能的防御措施在输入和权重空间中联系起来，进一步展示了其创新性。", "conclusion": "这些模型不仅存在漏洞，而且最近的模型似乎变得更容易受到这些攻击，这突显了亟待发现防篡改保障的紧迫性。在此类保障被发现之前，公司和政策制定者应当将释放任何可微调模型视为同时释放其暗面孪生体，其功能与原模型相同，可以在其能力范围内用于任何恶意目的。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11625", "html_url": "https://arxiv.org/abs/2507.11625", "title": "MapIQ: 用于地图问题回答的多模态大型语言模型基准", "title_en": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "authors": "Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski", "background": "最近，多模态大型语言模型（MLLMs）的进步促使研究人员探索这些模型对数据可视化（如条形图、散点图等）的解读能力。近期的研究转向了地图视觉问答（Map-VQA），但这些研究主要集中在主题色图上，这类地图覆盖的主题类别和可视化分析任务范围较小。因此，Map-VQA研究存在一定的局限性.", "innovation": "本文提出了一个名为MapIQ的数据基准集，包括14,706个问题-答案对，涵盖了3种不同类型的地图：主题色图、计数法图和按比例符号图。这些地图覆盖了六个不同主题。此外，这项研究还评估了多个MLLMs的性能，并通过改变地图设计（如颜色方案、图例设计和移除地图元素）进行实验，以探讨MLLMs的鲁棒性和敏感性，及其在提升Map-VQA性能方面的潜在改进途径.", "conclusion": "研究结果表明，多个MLLMs在面对不同类型的地图和任务时表现出了显著的差异，展示了MapIQ在评估MLLMs进行Map-VQA任务时的潜力。此外，对地图设计改变的实验还揭示了MLLMs对地理知识的依赖性，并提供了改进Map-VQA性能的途径."}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11588", "html_url": "https://arxiv.org/abs/2507.11588", "title": "SToFM: 多尺度空间转录组学基础模型", "title_en": "SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics", "authors": "Suyuan Zhao,Yizhen Luo,Ganbo Yang,Yan Zhong,Hao Zhou,Zaiqing Nie", "background": "空间转录组学（ST）技术通过保留细胞的空间上下文提供了丰富的单细胞生物学见解。构建空间转录组学的基础模型可以显著增强对大量复杂数据源的分析，揭示生物组织的复杂内涵。然而，建模ST数据在提取组织切片中大量细胞的多尺度信息时面临巨大挑战，需要整合宏观尺度的组织形态、微观尺度的细胞微环境以及基因尺度的基因表达谱。", "innovation": "我们提出了多尺度空间转录组学基础模型（SToFM），该模型首先在每个ST切片上进行多尺度信息提取，构建包含宏观、微观和基因尺度信息的ST子切片集。然后使用SE(2) Transformer从子切片中获得高质量的细胞表示。此外，我们还构建了SToCorpus-88M，这是迄今为止最大的高分辨率空间转录组学语料库用于预训练。SToFM在各种下游任务上表现出色，如组织区域语义分割和细胞类型注释，展示了其对ST数据的全面理解。", "conclusion": "SToFM通过多尺度建模方法和大规模的数据预训练，显著提高了空间转录组学数据的分析和理解能力，为生物组织的研究提供了新的视角和工具。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11597", "html_url": "https://arxiv.org/abs/2507.11597", "title": "人工智能、人类与数据科学：优化工作流程与劳动力中的角色", "title_en": "AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce", "authors": "Richard Timpone,Yongwei Yang", "background": "AI正在改变研究方式，被用于构建调查、合成数据、分析和撰写结果总结。虽然AI有望提高效率和质量，但其实际效果并不总是那么明显。本文通过应用我们提出的“真实、美丽、正义”框架（TBJ）评估AI、机器学习和计算模型的有效性和伦理使用，探讨了AI在增强数据科学家的任务或将一些传统由人类分析师和研究人员完成的任务自动化方面的潜力与局限性。", "innovation": "本文引入了“真实、美丽、正义”框架来评估AI在数据科学工作流程中的有效性和伦理使用，并强调了人类与机器协作的重要性。同时也指出，尽管AI可以辅助分析师完成任务，但需警惕自动化可能导致的风险，如同早期使用统计软件导致的研究者因不了解分析方法而引发的问题一样。", "conclusion": "本文鼓励AI工具辅助数据科学家，并强调持续培训和理解方法的重要性，以确保研究的实际价值能得到最有效和伦理的实现。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11636", "html_url": "https://arxiv.org/abs/2507.11636", "title": "JSQA: 基于JND音频对感知启发式对比预训练的语音质量评估", "title_en": "JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs", "authors": "Junyi Fan,Donald Williamson", "background": "语音质量评估（SQA）通常用于从高维输入空间到表示感知语音质量平均意见得分（MOS）的标量值的映射。这对于许多原因来说都是具有挑战性的，主要是因为MOS由于感知和实验设计的不同而表现出高的内在变异。尽管有许多解决方案，但许多方法并没有在学习算法中适当地将感知因素纳入考虑（除了MOS标签），可能导致不满意的评估结果。为了克服这些问题，该研究提出了一种两阶段框架JSQA。", "innovation": "JSQA框架首先使用感知引导的对比学习对在可察觉差异（JND）水平上的音频数据对进行预训练，然后进行微调以预测MOS。这种方法利用感知质量相似性信息，并将其映射到嵌入空间。JND数据对来源于干净的LibriSpeech语句，并与来自CHiME-3的背景噪音混音，不同信噪比（SNR）。之后，使用来自NISQA数据集的音频样本进行MOS预测的微调。实验结果显示，当与未经预训练直接从零开始训练的网络进行比较时，借鉴感知因素的对比预训练显著提高了模型性能，这表明将感知因素纳入预训练对SQA有着显著的贡献。", "conclusion": "感知启发式对比预训练显著改善了JSQA模型的性能，相比未经预训练直接从零开始训练的网络，实验结果表明，在性能评估的多种指标上都有提升。这表明，在预训练阶段整合感知因素对提高SQA性能有很大的贡献。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11634", "html_url": "https://arxiv.org/abs/2507.11634", "title": "使用增量适应的跨语言少样本学习进行波斯语情感分析", "title_en": "Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation", "authors": "Farideh Majidi,Ziaeddin Beheshtifard", "background": "该研究探讨了在波斯语中使用少样本学习和增量学习方法进行跨语言情感分析。目的是开发一种能够在有限数据下进行情感分析的模型，并利用高资源语言的先验知识。研究使用了三种多语言预训练模型（XLM-RoBERTa、mDeBERTa和DistilBERT），并在从不同来源收集的少量波斯语数据上进行了微调，包括X、Instagram、Digikala、Snappfood和Taaghche。", "innovation": "研究采用了少样本学习和增量学习方法结合多语言预训练模型的策略，特别是在波斯语情感分析领域。该方法使得模型能够从多种不同背景的数据中学习。研究结果显示，mDeBERTa和XLM-RoBERTa取得了高精度，准确率达到96%，突显了这种结合方法的有效性。", "conclusion": "研究证明了少样本学习和增量学习方法与多语言预训练模型的有效结合，提高了波斯语情感分析的性能。未来的研究可以探索更多场景下的应用和进一步优化模型。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11645", "html_url": "https://arxiv.org/abs/2507.11645", "title": "探寻掌握路径：嵌入、Dropout和网络激活", "title_en": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation", "authors": "Ahmed Salah,David Yevick", "background": "研究了神经网络在训练和测试准确度之间的延迟泛化现象，这种现象称为Grokking。Grokking是指测试准确度的提升在训练准确度改善之后才显著增加。本文通过引入几种实用的度量标准，可以预测Grokking行为，包括dropout下的方差、鲁棒性、嵌入相似性以及稀疏性措施。", "innovation": "提出了 Dropout Robustness Curve (DRC) 来估计神经网络在推理过程中对噪声的鲁棒性，这种方法是通过对dropout率的改变来观察模型从记忆到泛化过程中的准确度变化。此外，还发现测试准确度在stochastic dropout下的方差在Grokking期间出现局部最大值。研究还发现，随着泛化的进行，神经元中的不活动比例减少，嵌入则趋向于独立于初始化的双态分布，这与观察到的余弦相似度模式和数据集的对称性相关。", "conclusion": "这些度量标准不仅可以帮助预测Grokking行为，还进一步揭示了Grokking的起源和行为。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11623", "html_url": "https://arxiv.org/abs/2507.11623", "title": "面向气候变化的机器人研究路线图", "title_en": "A Roadmap for Climate-Relevant Robotics Research", "authors": "Alan Papalia,Charles Dawson,Laurentiu L. Anton,Norhan Magdy Bayomi,Bianca Champenois,Jung-Hoon Cho,Levi Cai,Joseph DelPreto,Kristen Edwards,Bilha-Catherine Githinji,Cameron Hickert,Vindula Jayawardana,Matthew Kramer,Shreyaa Raghavan,David Russell,Shide Salimi,Jingnan Shi,Soumya Sudhakar,Yanwei Wang,Shouyi Wang,Luca Carlone,Vijay Kumar,Daniela Rus,John E. Fernandez,Cathy Wu,George Kantor,Derek Young,Hanumant Singh", "background": "气候变化是21世纪的主要挑战之一，许多机器人领域的专家都在寻找贡献的方法。本文提出了一个关于气候相关机器人研究的路线图，旨在识别机器人专家和能源、建筑环境、交通、工业、土地利用、地球科学等领域专家之间的高影响合作机会。这些建议的应用案例包括能源系统优化、建筑、精准农业、建筑围护结构改造、无人驾驶卡车和大规模环境监测等问题。", "innovation": "本文提出了一条路线图，考虑了不仅实际机器人，还包括更广泛的机器人工具包——包括规划、感知、控制和估计算法——在气候相关问题中的应用。更重要的是，路线图旨在通过强调机器人和气候交汇处的具体、可操作问题来激发新的研究方向和合作。", "conclusion": "这是机器人研究者与各个气候学科领域的专家之间的合作成果，也是向机器人社区发出的邀请，希望他们能利用其专业知识应对紧迫的气候优先问题。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11620", "html_url": "https://arxiv.org/abs/2507.11620", "title": "使用稀疏自编码器学习事件时间序列表示以进行异常检测、相似搜索和无监督分类", "title_en": "Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification", "authors": "Steven Dillmann,Juan Rafael Martínez-Galarza", "background": "事件时间序列是不规则时间间隔发生的离散事件序列，每个事件都与特定领域的观测模态相关。它们常见于高能天体物理、计算社会科学、网络安全、金融、医疗健康、神经科学和地震学等领域。由于其不结构化和不规则性，传统的技术难以从中提取有意义的模式并识别显著的现象。", "innovation": "提出了一种新的事件时间序列的二元和三元张量表示方法，并结合了稀疏自编码器，以学习物理上具有意义的潜在表示。这些嵌入支持多种下游任务，包括异常检测、基于相似性的检索、语义聚类和无监督分类。", "conclusion": "在X射线天文学的真实数据集上展示了该方法，证明了这些表示能够捕捉时间性和光谱特征，并隔离出不同类别的X射线瞬变。该框架提供了一个灵活、可扩展和通用的解决方案，适用于分析科学和技术领域的复杂、不规律的事件时间序列。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11621", "html_url": "https://arxiv.org/abs/2507.11621", "title": "HCOMC：两车道混合交通环境下的一种分层协作匝道汇入控制框架", "title_en": "HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways", "authors": "Tianyi Wang,Yangyang Wang,Jie Pan,Junfeng Jiao,Christian Claudel", "background": "高速公路匝道汇入区往往是交通拥堵和事故的瓶颈。当前，基于连接和自动化车辆（CAVs）的协作控制策略是解决此问题的基础方案。但在CAVs尚未普及的情况下，需要提出一种适用于两车道公路混合交通流的分层协作匝道汇入控制（HCOMC）框架，以解决该领域存在的技术缺口。", "innovation": "该论文基于智能驾驶员模型（IDM）扩展了纵向车流跟随模型，并利用五次多项式曲线更新了侧向车道变换模型，全面考虑了人类因素和协作自适应巡航控制。此外，论文提出了一种HCOMC框架，包括基于修改后的虚拟车辆模型的分层协作规划模型、基于博弈理论的随意车道变换模型以及使用精英非支配排序遗传算法的多目标优化模型，以确保汇入过程的安全、平滑和高效。", "conclusion": "通过对不同交通密度和CAVs渗透率情况下的模拟分析，研究发现，HCOMC在提升车队安全性、稳定和加速汇入过程、优化交通效率和节约燃油消耗方面具有明显优势，相较于基准方案表现更为优异。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11655", "html_url": "https://arxiv.org/abs/2507.11655", "title": "计分歧回答集程序的回答集计数", "title_en": "Counting Answer Sets of Disjunctive Answer Set Programs", "authors": "Mohimenul Kabir,Supratik Chakraborty,Kuldeep S Meel", "background": "回答集编程（ASP）提供了一种强大的基于声明式的知识表示和推理方式。近期，回答集计数已成为一个重要的计算问题，具有在概率推理、网络可靠性分析及其他领域中的应用。这已经推动了一系列高效ASP计数器的设计，尽管在标准逻辑程序方面取得了一定进展，但实用的计数器开发对于分歧逻辑程序依然具有挑战性。", "innovation": "SharpASP-SR是一个基于减法归约到投影命题模式计数的新框架，用于处理分歧逻辑程序的回答集计数问题。该方法提供了一种替代的回答集表征方式，允许高效减少操作并确保中间表示保留在多项式级别复杂程度。SharpASP-SR能够利用最近在投影模式计数技术上的进展。在广泛的基准测试上，SharpASP-SR在大回答集数量实例上显著优于现有计数器。进一步研究开发了一种结合枚举技术与SharpASP-SR的混合计数方法，以涵盖裂缝逻辑程序的全范围实现最佳性能。", "conclusion": "通过广泛的实验评估，SharpASP-SR在大规模回答集计数实例上显著优于现有计数器。基于这些发现，SharpASP-SR结合了枚举技术与投影模式计数技术，实现了最先进的性能，适用于所有分歧逻辑程序。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11692", "html_url": "https://arxiv.org/abs/2507.11692", "title": "使用生成式人工智能进行星系图像简化", "title_en": "Galaxy image simplification using Generative AI", "authors": "Sai Teja Erukude,Lior Shamir", "background": "现代数码天空调查已经收集了数以十亿计的星系图像。尽管这些图像通常提供了足够的细节来分析星系的形状，但对这些大量图像的准确分析需要有效的自动化方法。目前的解决方案通常依赖于基于预定义类别的机器学习对星系图像进行标注。", "innovation": "我们介绍了一种新的星系图像分析方法，该方法基于生成式人工智能。该方法简化星系图像并自动将其转换为“骨架化”形式。简化后的图像允许对星系形状进行精确测量，并且分析不限于特定的预定义类别。", "conclusion": "该方法已应用于DESI遗产调查收集的125,000张星系图像，并且简化图像的目录已公开。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11702", "html_url": "https://arxiv.org/abs/2507.11702", "title": "使用LSTM网络的时间序列分类卫星数据方法：预测落叶以减少铁路交通中断的途径", "title_en": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption", "authors": "Hein de Wilde,Ali Mohammed Mansoor Alsahag,Pierre Blanchet", "background": "铁路因落叶造成的运营中断每年给英国铁路行业带来超过3亿英镑的损失，为了减轻此类中断，英国在轨道维护上投入大量资源。目前的预测方法存在规模性和可靠性上的局限，因此需要开发一种新的预测系统，结合专业的预测方法和最新的遥感数据，以提供更准确的落叶时间预测，从而提高铁路网络的运营效率和轨道维护的效果。", "innovation": "本研究开发了一种基于LSTM网络的时间序列分类方法，利用地面真值的落叶数据以及多光谱和气象卫星数据来预测落叶开始和结束的时间，结果表明预测误差分别为6.32天和9.31天。该模型相比之前的成果在预测准确性上有所提升，为铁路行业的落叶管理优化和对复杂生态系统的理解提供了新的机会。", "conclusion": "本研究提出的基于LSTM网络的预测系统能够提供更准确、更可靠的落叶时间预测，有助于优化铁路行业的落叶管理措施，并促进对复杂生态系统的理解。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11694", "html_url": "https://arxiv.org/abs/2507.11694", "title": "ExpliCIT-QA：基于代码的解释性图像表格问答", "title_en": "ExpliCIT-QA: Explainable Code-Based Image Table Question Answering", "authors": "Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas", "background": "当前的端到端表格视觉问答（TableVQA）系统在解释性方面存在缺陷。ExpliCIT-QA系统旨在通过构建透明且可审查的管道来填补这一解释性缺口。该系统提供解释性的答案，并允许对所有中间输出、解析表格、推理步骤、生成的代码以及最终答案进行检查，以提高透明度和可审计性。", "innovation": "ExpliCIT-QA通过一个模块化的设计，包括多模态表格理解、基于语言的推理、自动代码生成、代码执行以及自然语言解释，提供了一个解释性的端到端表格图像问答系统。其中，自动代码生成步骤有助于处理可能出现的错误，使系统更加健壮和透明。它在TableVQA-Bench基准测试中表现出了在解释性和透明性方面的改进。", "conclusion": "ExpliCIT-QA系统为敏感领域如金融和医疗提供了更多的应用前景，因为它能提供清晰的解释和可审查性，这对结果的审计至关重要。该系统通过提供一步一步的解释和代码生成，有效地解决了端到端TableVQA中的解释性问题，促进了人类对机器如何得出结论的理解。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11683", "html_url": "https://arxiv.org/abs/2507.11683", "title": "PGT-I: 使用高效分布式训练扩展时空GNN", "title_en": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training", "authors": "Seth Ockerman,Amal Gueroudji,Tanwi Mallick,Yixuan He,Line Pouchard,Robert Ross,Shivaram Venkataraman", "background": "时空图神经网络（ST-GNNs）是建模空间和时间数据依赖性的强大工具。然而，由于内存限制，它们的应用主要局限于小规模数据集。分布式训练可以解决这一问题，但当前框架缺乏对时空模型的支持，并且忽视了时空数据的特性。基于对大规模工作负载的扩展性研究，我们介绍了PyTorch Geometric Temporal Index（PGT-I），它扩展了PyTorch Geometric Temporal，并整合了分布式数据并行训练以及两种新的策略：索引批处理和分布式索引批处理。这些技术利用时空结构在运行时动态构建快照，大幅减少内存开销，而分布式索引批处理则进一步扩展了这种方法，使其能够跨多个GPU进行可扩展处理。这些技术使得首次能够在无需图分区的情况下训练完整的PeMS数据集上的ST-GNN，将峰值内存使用降低高达89%，并实现了在128个GPU上比标准DDP快13.1倍的速度提升。", "innovation": "PGT-I扩展了PyTorch Geometric Temporal，并引入了分布式数据并行训练、索引批处理（index-batching）和分布式索引批处理（distributed-index-batching）的两种新策略。这些技术利用时空结构在运行时动态构建快照，大幅减少内存开销，同时跨多个GPU实现可扩展处理，首次在无需图分区的情况下训练完整的PeMS数据集上的ST-GNN，大大减少了内存使用并提高了训练速度。", "conclusion": "PGT-I通过引入分布式索引批处理和优化技术，克服了时空图神经网络应用中的内存限制，使得ST-GNNs能够在大型数据集上进行高效训练，提高了应用的灵活性和效率，为时空数据建模提供了更强大的工具。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11661", "html_url": "https://arxiv.org/abs/2507.11661", "title": "Partitioner Guided Modal Learning Framework", "title_en": "Partitioner Guided Modal Learning Framework", "authors": "Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi", "background": "多模态学习可以从多种模态信息中受益，每种学习到的模态表示可以分为可以从单模态训练中学习的单模态特征以及可以从跨模态交互中学习的配对模态特征。传统的单模态和跨模态学习方法通常关注单一特征类型的学习，忽视了另一种特征类型可能带来的协同作用和多样性。为此，有必要提出一种新的框架来优化这两种模态特征的独立学习和结合利用。", "innovation": "本文提出了一种名为PgM的分区引导模态学习框架，该框架包括模态分区器、单模态学习器、配对模态学习器和单配对模态解码器。PgM的优点包括：1）详尽学习单模态和配对模态特征；2）灵活调整单模态和配对模态表示的分布以适应不同的下游任务；3）在不同模态和分区之间设定不同的学习率。该框架在四个多模态任务中的广泛实验表明了其有效性，并且还有助于现有模型的改进。此外，PgM还展示了单模态和配对模态特征在不同类型和任务中的分布情况，提供了有益的见解。", "conclusion": "全面学习单模态和配对模态特征，灵活调整模态表示的分布以适应不同的下游任务，并且在不同模态和分区之间设置不同的学习率，对于优化多模态学习具有重要意义。PgM提出的分区引导模态学习框架在多个多模态任务中证明了其优势，并有潜力广泛应用于现有模型的改进。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11742", "html_url": "https://arxiv.org/abs/2507.11742", "title": "CRABS: 一种用于约束 Python 笔记本的 LLM 解释的语义-语法夹板策略", "title_en": "CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks", "authors": "Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher", "background": "理解数据科学和机器学习 Python 笔记本中的信息流和操作对于评估、重用和适应新任务的笔记本至关重要。通过重新执行笔记本进行调查通常因解决数据和软件依赖关系的挑战而不可行。虽然预先训练在大型代码库上的大型语言模型 (LLMs) 在理解代码方面表现出色，但它们在理解和处理一些现实中的笔记本时会遇到幻觉和长上下文挑战。为了应对这些问题，我们提出了一项笔记本理解任务，该任务生成笔记本的信息流图和相应的单元执行依赖图。", "innovation": "我们提出了 Capture and Resolve Assisted Bounding Strategy (CRABS)，这是一种结合浅层语法分析和抽象语法树 (AST) 的分析，用于捕获笔记本中的正确解释。通过以零样本学习的方式逐单元使用 LLM 来解决剩余的模糊性，CRABS 能够识别每个单元的真实数据输入和输出。实验结果表明，CRABS 在 50 个代表性的 Kaggle 笔记本上，平均 F1 得分为 98%，识别单元间信息流，99% 识别传递单元执行依赖性。", "conclusion": "CRABS 方法通过语法和语义分析成功地捕捉和解析了笔记本中的信息流和执行依赖关系，有效地解决了 LLM 在解释笔记本时遇到的一些挑战。该方法在现实应用中显示出良好的适用性和有效性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11761", "html_url": "https://arxiv.org/abs/2507.11761", "title": "超越任务特定推理：一种统一条件生成框架用于抽象视觉推理", "title_en": "Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning", "authors": "Fan Shi,Bin Li,Xiangyang Xue", "background": "抽象视觉推理（AVR）使人类能够快速发现和推广抽象规则到新场景中。人工智能社区中，设计具有类人类AVR能力的智能系统是一个长期的研究主题。深度AVR求解器在多种AVR任务中取得了显著的成功。然而，这些方法通常依赖于特定任务的设计或参数。在这种范式中，解决新任务通常意味着重新训练模型，有时还需调整模型结构，这增加了解决AVR问题的成本。与此相反，本文提出了一种新颖的统一条件生成求解器（UCGS），以解决多个AVR任务在一个统一框架中。", "innovation": "本文提出了一种新颖的统一条件生成求解器（UCGS），证明一些著名AVR任务可以作为目标图像在问题面板中预测性的估计问题。UCGS通过统一框架培训一个条件生成模型，能够解决多种AVR任务。实验表明，通过单次多任务训练，UCGS在多个AVR任务中展示了抽象推理能力，特别是UCGS表现出零样本推理的能力，使其能够在测试阶段解决未见过的AVR任务中的抽象推理问题。这种新的框架和方法提供了一种新思路，减少了重新训练和调整模型的需要，降低了求解AVR问题的成本。", "conclusion": "UCGS在多个AVR任务中展示了抽象推理能力，特别是在测试阶段表现出零样本推理能力，能够解决未见过的AVR任务中的抽象推理问题。这种方法展示了在统一框架中使用单一条件生成模型解决多项AVR任务的新途径。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11730", "html_url": "https://arxiv.org/abs/2507.11730", "title": "监测招牌：户外广告可见性分析的边缘部署OCR模型综述", "title_en": "Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis", "authors": "Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying", "background": "户外广告仍然是现代营销的重要媒体，但准确验证实际条件下招牌文字的可见性仍然具有挑战性。传统光学字符识别（OCR）管道在识别裁剪文本方面表现出色，但在处理复杂的户外场景、不同字体和天气引起的视觉噪声方面常常力不从心。近期，多模态Vision-Language模型（VLMs）展示了潜在的替代方案，它们能够进行端到端场景理解，不需要明确的检测步骤。这项研究系统地将代表性的VLMs（包括Qwen 2.5 VL 3B、InternVL3和SmolVLM2）与基于小卷积网络的OCR基线（PaddleOCRv4）进行了对比，涵盖两个公开的数据集（ICDAR 2015和SVT），并增加了合成的天气失真，以模拟现实的退化情况。", "innovation": "研究采用了多模态Vision-Language模型与传统的基于卷积神经网络的OCR模型进行了对比，使用了两个公开数据集以及添加了合成的天气失真，这有助于更真实地评估OCR模型在实际场景中的表现。研究还公开了增强后的基准测试和评估代码，以促进未来的研究。", "conclusion": "虽然选定的VLMs在整体场景推理方面表现出色，但轻量级的CNN管道仍能达到具有竞争力的精度，并且计算成本较低，这对于边缘部署来说是一个重要的考虑因素。研究呼吁未来的研究能够利用增强后的基准测试数据集和评估代码来推进这一领域的发展。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11776", "html_url": "https://arxiv.org/abs/2507.11776", "title": "使用网络特征预测延误轨迹：荷兰铁路网络的研究", "title_en": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network", "authors": "Merel Kampere,Ali Mohammed Mansoor Alsahag", "background": "荷兰铁路网络是世界上最繁忙的网络之一，对于主要的客运铁路运营商NS来说，延误是一个主要关切。目前的研究大多关注短期预测，忽视了对网络内广泛模式的关注，这些模式对于缓解连锁效应至关重要。", "innovation": "研究采用XGBoost分类器并聚焦于网络拓扑特征，旨在填补荷兰铁路网络中关于延误预测研究的空白。此外，研究将一种初始设计用于预测快速变化的美国航空网络演化的现有方法，应用于预测荷兰铁路的延误。", "conclusion": "虽然结果表明性能有限，特别是在非同步测试场景下，但研究为交通网络评估提供了新的理解，并提出了未来开发更稳健的预测模型的方向。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11560", "html_url": "https://arxiv.org/abs/2507.11560", "title": "IIoT边沿计算中的模型感知AIGC任务卸载算法", "title_en": "A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing", "authors": "Xin Wang,Xiao Huan Li,Xun Wang", "background": "工业物联网（IIoT）与人工智能生成内容（AIGC）的整合为智能制造带来了新的机遇，但同时也带来了计算密集型任务和低延迟需求所带来的挑战。传统的基于云计算的生成模型难以满足IIoT环境中AIGC任务的实时要求，边缘计算通过任务卸载可以有效降低延迟。然而，AIGC任务的动态特性、模型切换延迟和资源限制对边缘计算环境提出了更高要求。", "innovation": "本文提出了一种针对IIoT边缘计算环境的AIGC任务卸载框架，并首次考虑了AIGC模型切换引起的延迟和能耗问题。设计了一种基于多智能体深度确定性策略梯度（MADDPG-MATO）的模型感知AIGC任务卸载算法，用于最小化延迟和能耗。实验结果表明，MADDPG-MATO算法优于基线算法，在四组实验中，平均每组实验模型数量从3到6，平均延迟降低了6.98%，能耗降低了7.12%，任务完成率提高了3.72%，证明所提算法在动态、高负载的IIoT环境中具有鲁棒性和高效性。", "conclusion": "本文提出了一个针对IIoT边缘计算环境的模型感知AIGC任务卸载算法，该算法通过多智能体深度确定性策略梯度（MADDPG-MATO）优化了AIGC任务的延迟和能耗，实验证明该算法在动态、高负载的IIoT环境中具有优秀的性能和稳定性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11751", "html_url": "https://arxiv.org/abs/2507.11751", "title": "基于语义相似性的文档搜索中遗传和差分进化算法方法综述", "title_en": "Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity", "authors": "Chandrashekar Muniyappa,Eunjin Kim", "background": "大量数据中识别相似文档是一项重大挑战。研究人员开发了多种有效的分布式计算技术来应对这一问题。随着计算能力的提升和大数据的兴起，深度神经网络和进化计算算法（如遗传算法和差分进化算法）在文档基于语义文本相似性的搜索方面取得了更大的成功。", "innovation": "本文综述了用于基于语义相似性搜索文档的遗传和差分进化算法的最新进展。", "conclusion": "本文探讨了遗传和差分进化算法在基于语义相似性搜索文档方面的应用，并总结了当前的研究状况和未来可能的发展方向。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11783", "html_url": "https://arxiv.org/abs/2507.11783", "title": "脑信号的奠基模型：当前进展与未来方向的批判性回顾", "title_en": "Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions", "authors": "Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah", "background": "脑电图（EEG）的电活动模式在科研和临床领域具有巨大价值。监督EEG编码器难以学习稳健的EEG模式，且过度依赖昂贵的信号注释，导致转向通用自监督EEG编码器（即EEG基础模型EEG-FMs），以实现EEG特征的稳健和可扩展提取。然而，早期EEG-FMs的现实准备情况及长期研究进展的评价标准尚不清楚。因此，需要系统而全面地回顾第一代EEG-FMs，以理解当前技术状态并识别未来方向的关键领域。", "innovation": "研究系统回顾了10个早期的EEG-FMs，对其方法、实验发现和研究缺口进行了关键性的综合分析。发现大多数EEG-FMs采用了基于序列的建模方案，依赖于变压器作为主体，并通过掩码序列的重构实现自我监督。未来研究应采用标准化和现实的评估方法，展示更显著的规模效果，并在整个EEG表示学习流程中做出原则性的可靠选择。建议与领域专家合作开发基准、软件工具、技术方法和应用，以进一步提高EEG-FMs的转化价值和现实应用。", "conclusion": "开发与领域专家合作的基准、软件工具、技术方法和应用可能进一步促进EEG-FMs的临床转化价值和现实应用。未来研究需要展示更显著的规模效果，并在整个EEG表示学习流程中做出原则性的可靠选择。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11773", "html_url": "https://arxiv.org/abs/2507.11773", "title": "小数据解析者——小数据方法在日常生活中的影响", "title_en": "Small Data Explainer -- The impact of small data methods in everyday life", "authors": "Maren Hackenberg,Sophia G. Connor,Fabian Kabus,June Brawner,Ella Markham,Mahi Hardalupas,Areeq Chowdhury,Rolf Backofen,Anna Köttgen,Angelika Rohde,Nadine Binder,Harald Binder, theCollaborative Research Center 1597 Small Data", "background": "新兴的人工智能技术引起了对小数据设置的关注，即信息有限的环境中，这些技术如何能够带来益处。这包括社会问题，例如如何最好地在数据驱动的政策和决策中包括代表性不足的群体，以及帮助技术（如可穿戴设备）对健康的好处。本研究通过对比小数据与大数据，提供了概念性的概述，并从具体案例研究和应用领域中识别出共同主题。", "innovation": "研究通过将应用环境、概念性贡献和具体技术联系起来，描述了当前数据分析和建模技术的新颖之处，并突出了来自不同学科的贡献，例如统计的知识驱动建模和计算机科学的数据驱动建模。进一步，研究展示了在充分利用小数据方面可能可行的策略和前景，并提出了如何全面利用小数据的议程。", "conclusion": "通过链接应用环境、概念贡献和特定技术，该研究强调了当前可行的解决方案，并建议了如何充分利用小数据的议程。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11710", "html_url": "https://arxiv.org/abs/2507.11710", "title": "跨分布链接泛化的子图生成", "title_en": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "authors": "Jay Revolinsky,Harry Shomer,Jiliang Tang", "background": "图神经网络（GNNs）在链接预测（LP）任务中表现出高性能。然而，这些模型通常依赖所有数据集样本来自相同的分布。此外，图生成模型（GGMs）显示出显著的能力来生成新颖的输出图，但它们的应用主要局限于特定领域任务。目前的方法在这两方面之间仍存在差距：GNNs对跨分布样本的链接预测性能不佳，而GGMs虽然在生成新颖图方面能力强，但在不同领域任务的泛化能力有限，应用范围较窄。", "innovation": "本文提出了一种基于GGM的框架FLEX，用于改进跨分布链接预测。它通过结构条件化图生成和对抗联合训练两种机制来增强跨分布样本间的结构对齐，从而提高OOD场景下的链接预测性能。FLEX不需要跨不同领域任务时的人工专业知识。利用合成数据和真实世界数据进行的广泛实验证实了FLEX的增效能力，并进一步分析了图数据增强对链接结构的影响。FLEX框架能够在不需要额外领域专家知识的情况下应用于各种OOD场景。", "conclusion": "FLEX框架通过将结构条件化图生成和对抗联合训练结合起来，显著提高了图模型在OOD场景下的链接预测性能。与现有的GNN和GGM相比，FLEX能够在不同领域中提供更可靠的泛化性能，展示了其在复杂环境中的优越能力。FLEX框架利用实验验证了其在合成和现实数据中的有效性，并为理解和优化图数据增强提供了新的视角。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11638", "html_url": "https://arxiv.org/abs/2507.11638", "title": "使用变分自编码器进行直肠癌MRI中淋巴结转移可解释性预测", "title_en": "Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders", "authors": "Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton", "background": "直肠癌的有效治疗依赖于准确的淋巴结转移（LNM）分期。现有的基于淋巴结（LN）大小、形状和纹理形态的放射学标准其诊断准确性有限。因此，需要寻找更为准确的方法进行淋巴结转移的预测。", "innovation": "本文研究了使用变分自编码器（VAE）作为特征编码模型，以替代现有方法中广泛使用的大规模预训练卷积神经网络（CNN）。VAE作为一种生成模型，旨在重建图像，直接编码图像的视觉特征和有意义的模式，从而生成解耦且结构化的潜在空间，这比CNN更为可解释。", "conclusion": "提出的‘VAE-MLP’模型在MRI数据集上达到了最先进的性能，通过交叉验证获得的AUC值为0.86±0.05，灵敏度为0.79±0.06，特异性为0.85±0.05。源代码可在如下链接获取：this https URL."}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11807", "html_url": "https://arxiv.org/abs/2507.11807", "title": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "title_en": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "authors": "Ruofan Hu,Dongyu Zhang,Huayi Zhang,Elke Rundensteiner", "background": "在训练深度神经网络时，使用有噪声标签的数据会影响模型的训练效果，故学习带有噪声标签（LNL）对于应对不完美的数据至关重要。传统的元学习方法依赖于干净、无偏的标记集来训练模型，但这种方法需要干净标记的数据集，而在实际操作中获取这样的数据集是非常困难的。因此，该研究旨在在无需依赖干净标记数据集的情况下解决元学习在噪声标签场景中的挑战。", "innovation": "本文设计了一种名为CLID-MU（Cross-layer Information Divergence-based Meta Update Strategy）的方法，该方法利用数据本身的特性而无需直接使用标签。CLID-MU通过评估跨不同特征空间的数据结构的一致性来指导模型训练，并提出了一种新的策略来解决带有噪声标签的数据学习问题。实验证明，CLID-MU在不同标签数量的数据集上，无论是合成数据还是实际数据，都优于现有方法。", "conclusion": "实验结果表明，CLID-MU方法在各种带有噪声标签的数据集上均表现出色，优于现有的最新方法。该方法通过利用跨多层的信息分歧来更新模型参数，无需使用标签数据，为解决带有噪声标签的数据学习问题提供了一种新的策略。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11848", "html_url": "https://arxiv.org/abs/2507.11848", "title": "使用参数双投影进行交互式杂交水稻育种", "title_en": "Interactive Hybrid Rice Breeding with Parametric Dual Projection", "authors": "Changjian Chen,Pengcheng Wang,Fei Lyu,Zhuo Tang,Li Yang,Long Wang,Yong Cai,Feng Yu,Kenli Li", "background": "杂交水稻育种将不同水稻品种进行杂交并在田间培育新杂交种，以选择出具有理想农艺性状（如高产量）的新品种。但由于遗传预测模型的精度有限，育种者仍需结合经验与模型来识别调控基因并选择杂交种，这一过程耗时且复杂。随着基因组选择的出现，这种基于基因预测杂交种性状的方法变得有效，可以减少田间试验的工作量。然而，由于遗传预测模型的准确性限制，育种者仍需结合经验和模型进行分析，识别调控基因，使这一过程依然耗时。", "innovation": "本文提出了一种基于参数双投影的可视化分析方法以辅助互动式杂交水稻育种，将调控基因识别与杂交种选择这两种分析任务自然集成。文中开发了一种具有理论保证的参数双投影方法，以及基因可视化和杂交种可视化工具，用于验证识别出的调控基因和理想杂交种。研究表明，该方法通过案例研究中的定量评估有效，并获得了育种者的积极反馈。", "conclusion": "通过参数双投影的可视化分析方法可以有效辅助杂交水稻育种过程。该方法不仅提高了育种的效率和准确性，还便于育种者的互动式操作，从而在实践中得到了积极认可。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11799", "html_url": "https://arxiv.org/abs/2507.11799", "title": "基于物理信息神经网络的退化诱导裂缝粒径密度估计器", "title_en": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network", "authors": "Shin-ichi Ito", "background": "本文介绍了一种基于神经网络的方法，用于求解描述退化诱导脆性破坏的积分微分方程。该方法直接将输入参数映射到相应的概率密度函数，无需数值求解支配方程，从而显著降低了计算成本。此方法在蒙特卡洛模拟中能高效地评价密度函数，同时保持与传统有限差分方案相当甚至更优的准确性，并通过合成数据验证了该方法的计算效率和预测可靠性。这项研究为基于数据的脆性破坏逆分析奠定了基础，并表明该框架可能适用于超越预设模型结构的应用领域。", "innovation": "该方法通过直接将输入参数映射到概率密度函数，无需数值求解积分微分方程，从而大幅减少计算成本；在蒙特卡洛模拟中能高效地评价密度函数，达到甚至超过传统有限差分方案的准确性；通过合成数据验证了该方法的高效率和可靠性；并为基于数据的脆性破坏逆分析提供了基础，并暗示了该框架在超出预设模型结构的应用潜力。", "conclusion": "本文建立了一种基于神经网络的数据驱动逆分析框架，用于脆性破坏分析。这种方法不仅提高了计算效率，还证实了其在通过蒙特卡洛模拟评估密度函数时的准确性。此外，该方法为未来在脆性破坏领域的数据驱动方法的发展提供了新的可能性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11821", "html_url": "https://arxiv.org/abs/2507.11821", "title": "MNIST-Gen: 使用层级语义、强化学习和范畴论的模块化MNIST风格数据集生成", "title_en": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory", "authors": "Pouya Shaeri,Arash Karimi,Ariane Middel", "background": "现有的基准数据集，如MNIST、FashionMNIST等，虽然便于获取但仅限于通用类别，例如数字或服装项。对于专注于特定领域任务的研究人员来说，例如分类树木、食品物品或其他真实世界的对象，这些数据集是不足的且不相关。此外，创建并发布自定义数据集可能耗时、受法律约束或超出单一项目的范围。", "innovation": "提出了MNIST-Gen，一种自动化、模块化且适应性强的数据集生成框架，用于为用户指定的类别生成MNIST风格的图像数据集，使用分层语义分类。该系统结合了基于CLIP的语义理解、强化学习和人工反馈，以实现智能分类并减少手动干预。MNIST-Gen采用分层方法支持复杂的类别结构，并具有语义特征，允许细致的子分类和多种处理模式：个人审查以获得最大控制权，智能批量处理以处理大型数据集，以及快速批量处理以实现快速创建。灵感来源于范畴论，MNIST-Gen将每个数据转换阶段 Modeling as composable morphisms，提高了清晰度、模块化和可扩展性。通过概念验证，生成了两个新数据集：Tree-MNIST 和 Food-MNIST，展示了MNIST-Gen在生成任务特定评估数据方面的实用性和自动分类准确性为85%，手动方法相比节省了80%的时间", "conclusion": "证明了MNIST-Gen的实用性和高效性，在生成任务特定评估数据方面实现了85%的自动分类准确率和80%的从手动方法的时间节省。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11775", "html_url": "https://arxiv.org/abs/2507.11775", "title": "GenAI和认证领域的挑战：一项范围回顾", "title_en": "Challenges in GenAI and Authentication: a scoping review", "authors": "Wesley dos Reis Bezerra,Lais Machado Bezerra,Carlos Becker Westphall", "background": "自信息分享之初，认证与真实性就是安全挑战。随着生成型人工智能的发展，这些挑战变得更加复杂，要求对它们对社会和系统安全的影响进行更及时的分析。", "innovation": "该论文通过Scopus、ACM和IEEE数据库分析了88份文献，并通过六个指导问题来组织分析内容，关注最相关的工作、挑战、攻击面、威胁、提出解决方案和空白。同时，每篇文章都收到了个人化的分析。", "conclusion": "研究结果一致地明确了与图像、文本、音频和视频相关的主要挑战、空缺和威胁，这为认证和生成型人工智能领域的研究提供了新的支持。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11810", "html_url": "https://arxiv.org/abs/2507.11810", "title": "大型语言模型在科学研究创新中的演进角色：评估者、合作者和科学家", "title_en": "The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist", "authors": "Haoxuan Zhang,Ruochi Li,Yang Zhang,Ting Xiao,Jiangping Chen,Junhua Ding,Haihua Chen", "background": "科学技术正经历由大型语言模型（LLMs）飞速发展所推动的革新范式转变。随着科学领域面临信息过载、学科隔离以及传统研究方法回报递减的问题，LLMs 正逐步发展为不仅可以增强科学研究工作流程，还能参与到并有可能引领创新过程的强大辅助工具。现有的综述主要侧重于从不同角度审视科研活动的不同方面和任务，但在理解LLMs的转型潜力及其角色区分上仍存在局限性。因此，本文提出了一个全面的框架，详细分类了不同层次下LLMs在科学研究创新中的角色演变，从评估者、合作者到科学家三个层级进行区分，探讨它们在结构化科研流程与开放性科学发现中的贡献差异，提供了一个统一的分类体系，旨在阐明每一层级的功能边界、评估标准及人机互动模式。", "innovation": "本文提出了一个全面的框架，对LLMs在科学研究创新中的角色进行分类，涵盖评估者、合作者和科学家三个层级，给出了统一的分类体系，更清晰地界定了每层级的功能边界、评估标准及人机互动模式，而非局限于现有的综述主要侧重的科学活动的不同方面和任务。通过深入分析当前的方法论、基准、系统及评估指标，本文为LLM驱动的科学研究创新提供了深入且系统的综述，不仅将LLMs视为自动化现有流程的工具，还视其为能够重塑科学知识基础的催化剂。", "conclusion": "本文不仅为其他研究提供了概念上的清晰性、实用指导和理论基础，还揭示了在追求日益自主的人工智能驱动科学过程中所遇到的开放挑战及伦理考量。相关研究资源可访问GitHub：[this https URL]。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11893", "html_url": "https://arxiv.org/abs/2507.11893", "title": "Spatial Frequency Modulation for Semantic Segmentation", "title_en": "Spatial Frequency Modulation for Semantic Segmentation", "authors": "Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai", "background": "高空间频率信息，包括纹理等精细细节，对语义分割的准确性有很大贡献。但是根据奈奎斯特-香农采样定理，在通过下采样层如步进卷积传播时，高频成分容易发生混叠或扭曲。", "innovation": "提出了一种新的空间频率调制（SFM），在下采样前对高频特征进行调制到较低频率，然后在上采样过程中进行反向调制。通过自适应重采样（ARS）实现调制，并设计一个轻量级的附加模块以密集采样高频区域，提高信号频率。同时提出了多尺度自适应上采样（MSAU），通过非均匀上采样反向调制特征以恢复高频信息。这两个模块可以无缝集成到各种架构中，从卷积神经网络到变换器。", "conclusion": "我们的方法在多种任务（包括图像分类、对抗鲁棒性、实例分割和全景分割）中都验证了其广泛适用性和有效性，并且能够有效缓解混叠问题同时保留细节。相关代码可在特定链接处获取。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11943", "html_url": "https://arxiv.org/abs/2507.11943", "title": "有效利用低秩适应训练视觉变换器以实现保护隐私的图像分类", "title_en": "Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification", "authors": "Haiwei Lin,Shoko Imaizumi,Hitoshi Kiya", "background": "在保护隐私的同时训练视觉变换器（ViT）模型是一个挑战性的问题，尤其是在需要提高模型性能时。传统的低秩适应方法通常冻结预训练的ViT模型权重，这限制了模型的灵活性和性能潜力。", "innovation": "提出了一种新的低秩适应方法，该方法通过在ViT架构的每个层中注入可训练的秩分解矩阵，而不是冻结传统的低秩适应方法中的权重层。这不仅减少了可训练参数的数量，还在大部分情况下维持了与全时间调优相同水平的准确率。", "conclusion": "提出的低秩适应方法有效地减少了Vision Transformer模型的训练参数，同时在隐私保护分类任务中实现了与全时间调整相当的性能。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11939", "html_url": "https://arxiv.org/abs/2507.11939", "title": "POLYCHARTQA: 用多语言图表问答评估大型视觉语言模型", "title_en": "POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering", "authors": "Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin", "background": "图表是数据解释和传达的通用介质。然而，现有的图表理解基准主要以英语为中心，限制了其对全球受众的访问性和适用性。该论文介绍了PolyChartQA，这是一个涵盖22,606个图表和26,151个问题-答案对的多语言图表问答基准，涉及10种不同的语言。通过将图表数据与渲染代码分离的方法，构建了一个分步管道，使得多语言图表可以通过简单翻译数据并重用代码灵活生成。利用最先进的基于LLM的翻译，并在管道中实施严格的质量控制，以确保生成的多语言图表在语言和语义上的一致性。", "innovation": "提出了PolyChartQA，这是一个多语言图表问答基准。它通过分步管道将图表数据与渲染代码分离，允许通过简单翻译数据并重用代码灵活生成多语言图表。利用最先进的基于LLM的翻译，并实施严格的质控，确保生成的多语言图表语言和语义的一致性。该基准能系统性评估多语言图表理解。实验证明，英语和其他语言之间存在显著的性能差距，特别是那些低资源的非拉丁字母脚本语言。这为推动包容性全球视觉语言模型的发展奠定了基础。", "conclusion": "该基准为多语言图表理解提供了一个系统评估平台，揭示了不同语言的模型性能差异，特别是非英语语言的存在性能差距问题。这为未来提升全球视角下的视觉语言模型提供了重要依据。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11729", "html_url": "https://arxiv.org/abs/2507.11729", "title": "可扩展的短期负荷预测中的全球化", "title_en": "Globalization for Scalable Short-term Load Forecasting", "authors": "Amirhossein Ahmadi,Hamidreza Zareipour,Henry Leung", "background": "电力传输网络的负荷预测对于不同层次都至关重要，从系统级到单个配送点（PoD）。传统的局部预测模型（LFMs）虽然直观且局部准确，但在泛化能力、过拟合并、数据漂移和冷启动问题上存在局限性。随着网络规模和数据量的增加，这些方法的计算复杂性也会增加，变得不那么高效。全球预测模型（GFMs）提供了一种新的方法，通过全球化和交叉学习增强预测的泛化能力、可扩展性、准确性和鲁棒性。本文在数据漂移的情况下，探讨不同建模技术和数据异质性对全球负荷预测的影响。研究了特征变换和目标变换模型，并分析了全球化、数据异质性和数据漂移对这些模型的不同影响。此外，还研究了全球化在尖峰负荷预测中的作用及其在层级预测中的潜力。为了应对数据异质性及其对全球性和局部性平衡的影响，研究提出了基于模型的时间序列聚类（TSC）方法，并引入了特征变换模型的模型基TSC和目标变换模型的新加权实例基TSC方法。通过在阿尔伯塔省电力负荷的真实数据集上进行大量实验，证明全球目标变换模型在增强特征和聚类技术的情况下始终优于其对应的局部模型。然而，全球特征变换模型在平衡局部和全球动态方面面临挑战，需要TSC来有效管理数据异质性。", "innovation": "本文提出的创新点在于引入了基于模型的时间序列聚类方法，并根据不同类型的模型（特征变换和目标变换）提出了新的加权实例基和模型基聚类方法。通过实验证明，全球目标变换模型在这种新方法的支持下能更有效地处理数据异质性，并在综合考虑全局和局部特性的前提下表现出更强的预测能力。这项工作在提升模型的泛化能力和可扩展性方面迈出了一步，尤其是在处理大数据和复杂网络预测的问题上有了新的突破。", "conclusion": "本研究证明了在全球目标变换模型中使用聚类技术可以显著提升短期电力负荷预测的性能。实验结果显示，当模型融合了全局特征和聚类方法时，全球目标变换模型在阿尔伯塔省电力负荷数据集上的预测准确性明显优于传统的局部模型。尽管全球特征变换模型面临了局部和全球动态的平衡问题，但引入时间序列聚类方法有助于其更好地应对真实世界中日益复杂的数据异质性问题。这项工作表明，通过引入全球化方法，可以有效提升短期电力负荷预测的效率和效果，特别是在提升负荷预测的泛化能力和处理大规模数据集方面。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11809", "html_url": "https://arxiv.org/abs/2507.11809", "title": "事实还是复制？大型语言模型中机制竞争的深入考察", "title_en": "Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models", "authors": "Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss", "background": "本文研究了大型语言模型（LLMs）管理竞争性事实和反事实信息的方式，重点关注注意力头在这过程中的作用。研究试图重现Ortu等人、Yu、Merullo和Pavlick以及McDougall等人的三篇最近研究中的发现。这些研究使用机制可解释性工具探讨了模型学习的事实与矛盾背景信息之间的竞争。本研究特别考察了注意力头强度与事实输出比率之间的关系，评估了关于注意力头抑制机制的相互竞争的假说，并调查了这些注意力模式的领域特定性。", "innovation": "研究发现，促进事实输出的注意力头通过普遍的复制抑制而不是选择性的反事实抑制实现。同时发现，注意力头行为依赖于领域，更大规模的模型显示出更加专门化和类别敏感的模式。", "conclusion": "本研究讨论了大型语言模型中事实与复制之间的竞争机制，提出要理解模型的生成策略，除了通过复制抑制来提高事实输出，还应考虑更大规模模型的领域特定注意力模式。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11966", "html_url": "https://arxiv.org/abs/2507.11966", "title": "低资源新加坡方言翻译的意识导向少量示例提示", "title_en": "Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation", "authors": "Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee", "background": "随着在线交流越来越多地纳入代表性不足的语言和方言，标准翻译系统往往无法保留当地的俚语、混杂语言和文化嵌入的有害言论标记。在低资源语言对之间翻译有害内容还面临着稀缺平行数据和清除冒犯表达的安全过滤器的额外挑战。", "innovation": "本文提出了一种可重复的两阶段框架，专门用于保护有害言论的翻译工作。首先，通过人工验证的少量示例提示工程进行迭代筛选和排名标注者选择的Singlish目标示例，以捕捉细腻的俚语、语气和有害言论。其次，通过几大语言模型的基准测试，使用语义相似性通过直接和反向翻译优化模型-提示对。定量的人类评估确认了我们管线的有效性和效率。该框架不仅改善了翻译质量，还通过支持文化敏感的监督和在低资源环境下的基准测试，促进了多文化的大规模语言模型的安全性。", "conclusion": "通过将Singlish作为包容性的自然语言处理的测试平台，我们强调了在内容审核和区域平台治理等实际应用中保留社会语言细微差别的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11947", "html_url": "https://arxiv.org/abs/2507.11947", "title": "RaDL: 关系感知的解纠缠学习用于多实例文本到图像生成", "title_en": "RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation", "authors": "Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee", "background": "随着文本到图像（T2I）模型的进步，单个图像提示内生成多个实例变得越来越重要，但现有方法在生成实例位置方面虽有成效，但在处理属性差异和多个属性泄露方面仍存在问题。", "innovation": "该论文提出了一种关系感知的解纠缠学习（RaDL）框架。该框架通过可学习参数增强实例特定属性，并利用从全局提示中提取的动词进行关系注意力，从而生成关系感知的图像特征。与其他现有方法相比，该框架在位置准确性、多重属性考虑及实例间关系方面表现出显著改进。", "conclusion": "通过在COCO-Position、COCO-MIG和DrawBench等基准测试上的广泛评估，研究结果表明RaDL可以生成同时考虑每个实例间关系和多重属性的图像，是解决多实例文本到图像生成问题的有效方法。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11991", "html_url": "https://arxiv.org/abs/2507.11991", "title": "基于扩散模型失效采样的鲁棒型自动驾驶车辆规划", "title_en": "Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers", "authors": "Juanran Wang,Marc R. Schlichting,Mykel J. Kochenderfer", "background": "交通热点区域如交叉口等是交通事故的主要原因。因此，本研究利用深度生成模型来提高自动驾驶车辆在交叉口环境下的安全性。", "innovation": "本研究训练了一个1000步的去噪扩散概率模型，用于生成导致碰撞的传感器噪声序列，该模型基于当前入侵者的相对位置和速度生成数据。通过生成对抗架构将1000步模型精简为单步去噪扩散模型，该模型具有快速的推理速度和相近的采样质量。还展示了一种使用单步模型构建鲁棒规划器的应用，该规划器根据当前测量的交通状态高效采样潜在故障案例，以辅助决策过程。", "conclusion": "仿真实验表明，基于单步模型的鲁棒规划器相比基线智能驾驶模型控制器，故障率和延迟率显著降低。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11959", "html_url": "https://arxiv.org/abs/2507.11959", "title": "PoTPTQ: 两步Power-of-Two后训练方法用于LLMs", "title_en": "PoTPTQ: A Two-step Power-of-Two Post-training for LLMs", "authors": "Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui", "background": "大语言模型（LLMs）在多种自然语言处理任务上表现出色，但其部署面临着巨大计算资源的需求挑战。Power-of-two（PoT）量化是一种通用工具来应对这一难题。尽管先前的工作通过固定点加法定量在CPU上高效地反量化，但在GPU上显示了较低的有效性。原因在于sign位的缠结以及反量化时需要的顺序位操作。研究提出了一个新的针对LLM权重的PoT量化框架，该架构在极低精度数字格式中具有出色的表现，并且通过更有效的反量化加快了推理速度。为了保持量化模型的准确性，引入了一种两步后训练算法：初始化量化标度并使用最小校准集进一步校准这些标度。我们的PoT后训练算法在整数量化中表现出色，尤其是在低精度（如2-和3-比特格式）场景中", "innovation": "提出了一种新的PoT量化框架，适用于LLM的权重。这种框架能够在极低精度的数字格式中提供最先进的准确性，同时通过更有效的反量化加速推理。采用两步后训练算法，首先使用稳健的启动点初始化量化标度，然后使用最小的校准集进一步校准这些标度。与均匀整数反量化相比，PoT量化在NVIDIA V100和NVIDIA RTX 4090上分别实现了3.67倍和1.63倍的速度提升。", "conclusion": "提出的PoT后训练算法在整数量化特别是在低精度格式（如2-和3-比特）下超越了现有最优方法，并显著加速了浮点推理所需的反量化步骤，从而在NVIDIA V100和NVIDIA RTX 4090上分别实现了3.67倍和1.63倍的速度提升。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的一个关键领域，广泛应用于教育、人工智能的数学能力评估和多模态能力评估等领域。近年来，深度学习技术的迅速发展，尤其是多模态大语言模型的兴起，引发了研究热潮。", "innovation": "本文全面总结了几何问题解决相关的任务，深入回顾了相关的深度学习方法，详细分析了评估指标和方法，并批判性地讨论了当前面临的挑战和未来的研究方向，旨在为几何问题解决中的深度学习提供全面和实用的参考，推动该领域的发展。并创建了一个在GitHub上不断更新的论文列表：this https URL。", "conclusion": "本文提供了深度学习在几何问题解决中的应用综述，包括相关任务的全面总结、深度学习方法的彻底回顾、评估指标和方法的详细分析以及对当前挑战和未来方向的批判性讨论，旨在推动该领域的进一步发展。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11892", "html_url": "https://arxiv.org/abs/2507.11892", "title": "从粗略到精细：动态情感识别中的细粒度语言线索和视觉显著区域的跨模态对齐", "title_en": "From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition", "authors": "Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li", "background": "动态面部表情识别（DFER）旨在从随时间变化的面部动作中识别人类情感，在情感计算中扮演关键角色。虽然一些最近的视觉-语言方法引入了语义文本描述以指导表情识别，但现有方法仍然存在两个关键局限性：首先，它们往往未能充分利用生成文本中嵌入的微妙情感线索；其次，缺乏有效机制来过滤掉与情感表达无关的面部动态。", "innovation": "本文提出了GRACE（粒度表示对齐），该方法通过综合动态运动建模、语义文本精炼和标记级跨模态对齐，来促进情感显著时空特征的精确定位。方法中通过Coarse-to-Fine情感文本增强（CATE）模块构建了情感意识的文本描述，并通过运动差异加权机制突显表情相关面部运动。这些精炼的语义和视觉信号通过熵正则化的最优传输在标记级别进行对齐。", "conclusion": "在三个基准数据集上的实验表明，该方法显著提高了识别性能，特别是在具有模糊或不平衡情感类别的挑战性设置中表现尤为突出，从而在UAR和WAR方面建立了新的最先进的（SOTA）结果。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11987", "html_url": "https://arxiv.org/abs/2507.11987", "title": "动态验证神经证书的形式化验证", "title_en": "Formal Verification of Neural Certificates Done Dynamically", "authors": "Thomas A. Henzinger,Konstantin Kueffner,Emily Yu", "background": "神经证书作为一种强大的工具，在网络物理系统控制中得到广泛应用，它们可以作为正确性的证明。传统的形式化验证方法由于需要耗尽式地探索状态空间，常常遇到可扩展性挑战。现有方法通常要求验证算法能够访问底层控制策略，并且在实际部署中难以实时进行验证。", "innovation": "本研究提出了一种轻量级的运行时监控框架，该框架可以在不依赖底层控制策略的情况下，实时验证神经证书，并确保系统在有限的预测窗口内保持安全。该方法专为基于ReLU的控制边界函数进行实例化，并通过案例研究展示了其实用效果。这种方法能够在基本不影响性能的情况下，及时检测出安全违规和错误的证书，提供了一种静态验证神经证书的有效替代方案，同时也更轻量级。", "conclusion": "该方法通过实现实时验证和轻量运行时监控，在不访问底层控制策略的情况下，有效解决了神经证书形式化验证的可扩展性问题，确保系统安全并在预测窗口内保持正确性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11935", "html_url": "https://arxiv.org/abs/2507.11935", "title": "为未来非地面网络赋能的原生AI增强可扩展架构与解决方案：概览", "title_en": "Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview", "authors": "Jikang Deng,Fizza Hassan,Hui Zhou,Saad Al-Ahmadi,Mohamed-Slim Alouini,Daniel B. Da Costa", "background": "随着6G网络的发展，新兴应用推动了网络架构的演变，旨在构建高效、可靠且灵活的无线网络。非地面网络（NTN）和开放无线接入网络（ORAN）因其优势而受到学术界和产业界的广泛关注。虽然部署NTN能确保覆盖范围、提高频谱效率并增强无线网络的韧性，但高海拔和NTN的移动性带来了在开发和运维（DevOps）生命周期中的新挑战，使得引入原生AI的智能和可扩展网络管理变得困难。", "innovation": "本文首先提供了关于ORAN和NTN的基础知识，概述了最新关于ORAN应用于NTNs的研究状况，并阐述了推动采用ORAN解决方案的DevOps挑战。然后提出了基于ORAN的NTN框架，详细讨论了其特性和架构，包括灵活的前传拆分、RIC增强的分布式学习、可扩展的部署架构和多域服务管理。此外，还探讨了基于ORAN的NTN框架与其他使能技术和方案的结合，以及潜在的应用场景。", "conclusion": "本文最终强调了未来研究方向，包括基于ORAN的NTN框架与其他使能技术和方案的结合，以及潜在的应用场景。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11997", "html_url": "https://arxiv.org/abs/2507.11997", "title": "LLMs能否发现欺诈者？多层次LLM增强图欺诈检测", "title_en": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "authors": "Tairan Huang,Yili Wang", "background": "图欺诈检测因其能有效建模多模态数据中的复杂关系而备受关注。现有的图欺诈检测方法依赖于预处理节点嵌入和预定义的图形结构，但忽视了原始文本信息中丰富的语义线索。尽管大型语言模型（LLMs）在处理文本信息方面表现出强大的能力，但在将处理过的文本嵌入与图形结构进行多模态融合方面仍存在挑战。", "innovation": "本文提出了一种多层次LLM增强图欺诈检测框架（MLED）。MLED利用LLMs从文本信息中提取外部知识，以增强图欺诈检测方法。还设计了多层次LLM增强框架，包括类型级增强器和关系级增强器，以融合LLMs与图形结构信息，提高区分欺诈者的能力。", "conclusion": "实验结果表明，MLED在四个真实世界数据集上的图欺诈检测中实现了目前的最先进性能，作为一个可以应用于现有方法的通用框架。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11948", "html_url": "https://arxiv.org/abs/2507.11948", "title": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "title_en": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "authors": "Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti", "background": "编写GPU内核是AI系统效率的关键，但也是一项极具挑战性的任务。这个过程是高度迭代的，领域专家需要通过执行反馈不断改进性能。此外，迭代过程还具有可验证的奖励，如正确性和加速比，使其成为一个自然的应用强化学习（RL）的环境。鉴于这一过程的迭代性，需要一种灵活的多轮次RL方法来应对实际场景中的挑战，如从长轨迹中学习和跨轮次进行有效的回报归因。", "innovation": "本文开发了一种灵活的多轮次RL方法，用于CUDA内核生成和优化，名为Kevin。该方法首次使用多轮次RL训练CUDA内核生成模型，显著提升了内核生成的正确性和加速比。相比基准模型（QwQ-32B），Kevin使得纯CUDA生成的内核正确率从56%提升至82%，平均加速比从0.53x提升至1.10x（基线为PyTorch Eager），并且在性能上超越了前沿模型o4-mini。研究还发现，在测试时间扩展轴上，逐次精化比并行采样更有益。当给予更多精化轮次时，Kevin表现出更高的改进率。", "conclusion": "Kevin展示了利用多轮次RL在CUDA内核生成和优化方面的显著成果。相较于前模型，它显著提高了生成内核的正确性和加速比，特别是在使用更多精化轮次时，改进效果更为显著。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11975", "html_url": "https://arxiv.org/abs/2507.11975", "title": "Online Training and Pruning of Deep Reinforcement Learning Networks", "title_en": "Online Training and Pruning of Deep Reinforcement Learning Networks", "authors": "Valentin Frank Ingmar Guenter,Athanasios Sideris", "background": "深度神经网络（NN）在强化学习（RL）算法中的应用已被证明能够提升性能，尤其是在使用特征提取网络时。然而，这种改进需要大量增加计算和存储复杂性。为了缓解这一问题，已有的神经网络剪枝方法在监督学习领域取得了成功，但在RL领域的应用相对较少。本文旨在探索在先进RL方法中同时训练和剪枝的方法，特别是针对使用了在线特征提取网络（OFENet）的RL算法。", "innovation": "提出了一种结合在线训练和剪枝的方法，特别是在使用OFENet的RL算法中。该方法通过训练网络解决强化学习网络权重和0/1随机变量$\\xi$的变分伯努利分布参数的随机优化问题，从而自动选择参数。这种方法通过引入正则化项来促进无贡献单元的永久性停用，并通过优化参数复杂性来促进网络稀疏化。研究结果表明，这种方法能够在保持性能的情况下对OFENet进行显著剪枝，并证明了在训练过程中剪枝大网络能够产生更高效、性能更高的RL代理。", "conclusion": "通过引入一种成本意识强、能够促进稀疏性的正则化方案，本文针对密集网络架构的OFENet在连续控制基准（MuJoCo）和Soft Actor-Critic RL代理上进行了评估，验证了在保持性能几乎不变的情况下，可以对OFENet进行大量剪枝。此外，研究结果还表明，在训练过程中剪枝大网络比从头开始训练小网络更有利。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12011", "html_url": "https://arxiv.org/abs/2507.12011", "title": "DUSE: 基于主动学习的低资源自动调制识别数据扩展框架", "title_en": "DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning", "authors": "Yao Lu,Hongyu Gao,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui", "background": "虽然深度神经网络在自动调制识别（AMR）领域取得了显著成就，但这些模型通常需要大量带标签的数据进行训练。然而，在许多实际场景中，目标领域数据稀缺，难以满足模型训练的需求。传统的数据扩充方法虽然可以在一定程度上丰富训练样本，但无法引入新数据，因而无法从根本上解决数据稀缺的问题。", "innovation": "该论文提出了一种名为动态不确定性驱动样本扩展（DUSE）的数据扩展框架。具体而言，DUSE 使用不确定性评分函数从相关的 AMR 数据集中筛选出有用样本，并结合主动学习策略不断细化评分器。大量实验表明，在类平衡和类不平衡的情况下，DUSE 在多个核心集选择基线中始终表现更优。此外，DUSE 对未见模型显示出强大的跨架构泛化能力。", "conclusion": "DUSE 通过有效筛选样本并结合主动学习策略，显著改善了在数据稀缺环境下的自动调制识别性能，并展示了良好的模型泛化能力。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12017", "html_url": "https://arxiv.org/abs/2507.12017", "title": "SS-DC: 跨可见光-红外缺口的空谱解耦与耦合在领域自适应目标检测中的应用", "title_en": "SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection", "authors": "Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng", "background": "可见光（RGB）与红外（IR）域之间的领域自适应目标检测（UDAOD）具有挑战性。现有方法通常将RGB域视为统一域，忽视了其中的多个子域，例如白天、夜晚和雾天场景。因此，我们主张最好解耦这些多子域中的领域不变（DI）特征和领域特定（DS）特征，以为RGB-IR域适应提供帮助。基于此，本文提出了一种新的SS-DC框架，采用解耦-耦合策略。解耦部分设计了基于光谱分解的Spectral Adaptive Idempotent Decoupling（SAID）模块，通过光谱域的分解能够更准确地解耦DI和DS组件，并提高解耦效果。在耦合部分，提出了新的空谱耦合方法，通过空谱域的特征金字塔实现联合耦合，并从解耦中引入领域特定特征，以减少域偏见。", "innovation": "该研究提出了SS-DC框架，采用解耦-耦合策略，基于光谱分解设计了Spectral Adaptive Idempotent Decoupling（SAID）模块，并通过空谱域的数据加工和损失函数改进了解耦效果。提出了空谱耦合方法，并引入了领域特定特征，减少域偏见。实验结果表明，该方法在多个RGB-IR数据集上表现出色，显著提高了基线性能，超过了现有UDAOD方法。", "conclusion": "本文提出的SS-DC框架在多个RGB-IR数据集上明显改进了基线性能，并在新提出的基于FLIR-ADAS数据集的实验协议下表现优于现有UDAOD方法。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12008", "html_url": "https://arxiv.org/abs/2507.12008", "title": "域适应图像分割中互补掩蔽的双重形式", "title_en": "Dual form Complementary Masking for Domain-Adaptive Image Segmentation", "authors": "Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong", "background": "近期研究将掩码图像建模(MIM)与无监督域适应(UDA)中的一致性正则化联系起来。然而，这些研究仅仅将掩码视为输入图像的一种特殊变形形式，并忽略了理论分析，导致对掩码重建的理解肤浅，未能充分挖掘其增强特征提取和表示学习的潜力。", "innovation": "本文重新定义了掩码重建为稀疏信号重建问题，并从理论上证明互补掩码的对偶形式在提取跨域一致图像特征方面具有更强的能力。基于这一见解，我们提出了MaskTwins，一种简单的有效域适应框架，将掩码重建直接整合到主训练管道中。MaskTwins通过强制不同掩蔽方式下图像预测之间的一致性来揭示存在于不同域中的固有结构模式，以端到端的方式实现域适应性。", "conclusion": "广泛的实验结果显示，与基线方法相比，MaskTwins在自然和生物图像分割中表现出显著优势，证明了在无需单独预训练的情况下提取域不变特征的显著优势，为域适应分割提供了一个新的范式。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12006", "html_url": "https://arxiv.org/abs/2507.12006", "title": "频域动态注意力调制用于密集预测", "title_en": "Frequency-Dynamic Attention Modulation for Dense Prediction", "authors": "Linwei Chen,Lin Gu,Ying Fu", "background": "ViTs 在计算机视觉领域取得了显著进展，但在现有的变压器层数架构中，注意力机制使得每一层都充当低通滤波器，导致频率消失，从而丢失了关键的细节和纹理。因此，需要一种新的策略来优化ViTs，使其能够在保持性能的同时增强对细节的捕捉能力。", "innovation": "提出了名为Frequency-Dynamic Attention Modulation (FDAM) 的新策略，这是一种受到电路理论启发的方法，通过AttInv和FreqScale两部分直接调节ViTs的整体频率响应。AttInv通过反转注意力矩阵中的低通滤波器生成互补的高通滤波，而FreqScale用于加权不同的频率成分以实现对目标响应函数的精细调整。这种方法通过特征相似性分析和有效的秩评估，显示了在多种模型上避免表示坍塌并提高模型性能的能力，适用于语义分割、对象检测和实例分割等多种任务，甚至在遥感检测中也取得了最先进的结果。", "conclusion": "我们的方法在各种模型上持续提高性能，包括SegFormer、DeiT 和MaskDINO，在语义分割、对象检测和实例分割任务中均有所表现。该方法被应用于遥感检测，实现了单尺度设置下的最新成果。代码可在指定链接中获取。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12029", "html_url": "https://arxiv.org/abs/2507.12029", "title": "Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery", "title_en": "Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery", "authors": "Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He", "background": "该论文探讨了新型类发现（NCD）问题，其目标是通过利用不相交已知类别的知识来聚类新型类别。现有NCD方法主要针对单视图数据（如图像）进行研究，而忽视了多视图数据（如多组学数据）的日益常见，这在疾病诊断中很有用。此外，依赖伪标签监督新型类聚类性能不稳定，因为伪标签质量高度依赖于数据噪声和特征维度等因素。", "innovation": "该论文提出了名为‘Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery（IICMVNCD）’的新框架。这是首次尝试在多视图设置中研究NCD问题。框架在单视图层面上利用已知和新型类别之间的分布相似性，通过矩阵分解将特征分解为视图特异性共享基矩阵和因子矩阵。在跨视图层面上，通过已知类别之间的视图关系来引导新型类聚类，包括通过加权融合因子矩阵来生成预测标签，并根据监督损失动态调整已知类别的视图权重，然后将这些权重转移到新型类学习。", "conclusion": "实验结果验证了所提出方法的有效性。总体而言，该框架能够超越现有方法，有效处理多视图数据的新型类发现问题。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12145", "html_url": "https://arxiv.org/abs/2507.12145", "title": "PRISM:分布式边缘环境中的基础模型分布式推理", "title_en": "PRISM: Distributed Inference for Foundation Models at Edge", "authors": "Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang", "background": "基础模型（FMs）在各种应用中取得了显著成功，从图像分类到自然语言处理，但边缘部署面临显著挑战。这激发了对将基础模型带到边缘环境中的实用和高效策略的兴趣。", "innovation": "PRISM是一种在边缘设备上进行分布式Transformer推理的通信高效且计算感知策略，通过使用Segment Means表示来近似中间输出特征，大幅减少了设备间通信，同时重构了自注意力机制，避免了由于按设备计算Key/Value导致的冗余计算，并设计了一种针对自回归模型的分区感知因果掩码方案。", "conclusion": "PRISM方法在ViT、BERT和GPT-2上展示了显著的通信开销减少（压缩率CR=128时最高减少99.2%）和每设备计算量减少（51.24%），同时仅导致微小的准确率下降。这为在分布式资源受限环境中部署基础模型提供了可扩展和实用的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12117", "html_url": "https://arxiv.org/abs/2507.12117", "title": "多量子比特相空间中的量子机器学习 第一部分：基础", "title_en": "Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations", "authors": "Timothy Heightman,Edward Jiang,Ruth Mora-Soto,Maciej Lewenstein,Marcin Płodzień", "background": "量子机器学习（QML）旨在利用量子力学系统固有的特性，如叠加、相干性和量子纠缠进行经典数据处理。然而，由于希尔伯特空间的指数增长，QML 在使用量子系统的状态矢量表示进行经典模拟时面临实际限制。另一方面，相空间方法通过将量子态编码为准概率函数提供了一种替代方案。基于单量子比特相空间和斯特拉托诺维奇—韦尔对应关系的先前研究，本文构建了一个封闭且可组合的动力学形式框架，用于单量子比特和多量子比特系统。该框架用辛流形上的函数动力学取代了保罗i组的算子代数，并将维数灾难重新表述为支持在随量子比特数量呈线性增长的域上的谐波性。这为基于相空间变分建模的QML开辟了一条新途径。", "innovation": "提出了一个封闭且可组合的动力学形式框架，该框架用于单量子比特和多量子比特系统的相空间。该框架将量子系统中的算子代数替换为辛流形上的函数动力学，并且重新定义了维数灾难，使得其在相关域上的支持随量子比特数量呈线性增长。这为QML提供了一种基于相空间变分建模的新方法。", "conclusion": "该研究为基于相空间的多量子比特量子机器学习模型提供了理论基础，并为克服QML中维数灾难的问题提供了一种新方法。这为QML的实际应用带来了新的可能性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12188", "html_url": "https://arxiv.org/abs/2507.12188", "title": "基于小波的低光照立体图像增强解耦框架", "title_en": "Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement", "authors": "Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun", "background": "低光照图像受到复杂的降级影响，现有增强方法通常将所有降级因素编码在一个潜在空间中。这样会导致高度交织的特征和强黑箱特性，使模型容易出现捷径学习。", "innovation": "本文提出了一种基于小波的低光照立体图像增强方法，具有特征空间解耦。通过先将特征空间分解为低频分支（用于照明调整）和多个高频分支（用于纹理增强），再利用立体图像不同视角提供的有用线索来改善增强效果。此外，还提出了一种高频引导跨视角交互模块（HF-CIM）和一种基于跨注意力机制的细节和纹理增强模块（DTEM）。", "conclusion": "实验结果表明，我们的算法在光线调整方面具有显著优势，同时有效地恢复了高频信息。代码和数据集可在提供的链接中公开访问。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12060", "html_url": "https://arxiv.org/abs/2507.12060", "title": "InstructFLIP：探索统一的跨模态模型用于人脸识别防欺骗", "title_en": "InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing", "authors": "Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng", "background": "人脸识别防欺骗（Face Anti-Spoofing, FAS）的目标是构建一个能够抵御各种攻击的稳健系统。尽管近期的努力主要集中在跨域泛化上，但仍然存在两个重要的挑战：对于攻击类型的有限语义理解，以及跨域训练时的冗余性问题。现有的研究在很大程度上集中在跨域泛化上，但未能充分解决视觉输入感知的不足以及跨域训练的冗余性。", "innovation": "本文提出了一种名为InstructFLIP的新型指令调优框架，通过利用视觉-语言模型（VLMs）来增强跨域泛化能力。InstructFLIP将指令明确地分解为内容和样式两部分，内容指令专注于欺骗的本体语义，而样式指令考虑与环境和摄像机特性相关的变体。此外，InstructFLIP采用了一种元域策略来学习一个能够在多个领域泛化的统一模型，其在准确性和跨域训练冗余性降低方面优于现有的最佳模型。", "conclusion": "通过大量的实验，InstructFLIP在FAS任务的准确性和降低跨域训练冗余性方面表现突出，证实了它的有效性。项目网站可访问该项目网站。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12064", "html_url": "https://arxiv.org/abs/2507.12064", "title": "StylOch在PAN中的表现：基于频率特征的梯度提升树", "title_en": "StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features", "authors": "Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak", "background": "该论文基于一个模块化的语料体式分析流水线，使用公开的spaCy模型进行文本预处理和特征提取，并使用轻量级梯度提升机作为分类器。作者构建了一个包含超过50万篇机器生成文本的大规模语料库作为分类器的训练集，探索了多种参数选项以提高分类器的能力，从而充分利用该训练集。", "innovation": "该研究使用轻量级梯度提升机作为分类器，并结合了基于频率特征的语料体式分析方法。这种非神经网络的、计算成本较低且具有解释性的方法在之前的研究中已被证明有效。", "conclusion": "研究展示了在PAN（文本分析和鉴伪挑战）任务中的性能，采用基于频率特征的语料体式分析方法和轻量级梯度提升机，提高了分类器的解释性和准确性。通过参数优化，该方法在大量机器生成文本的分类任务中表现出良好的效果。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12012", "html_url": "https://arxiv.org/abs/2507.12012", "title": "识别肝脏疾病治疗反应的影像表型特征", "title_en": "Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease", "authors": "Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs", "background": "可用于指导个体治疗和开发新型疗法的疾病进展和治疗反应的可量化的影像模式至关重要。本文介绍了一种无监督机器学习方法，用于在磁共振成像中识别肝脏组织的模式词汇，这些模式词汇可以量化弥漫性肝脏疾病的治疗反应。通过使用深度聚类网络，可以将医学图像的片段编码和聚类到低维潜在空间中，从而形成组织词汇。这些终点类型能够捕捉与治疗反应相关的组织变化及其在肝脏中的位置差异。该方法已在非酒精性脂肪肝炎患者的随机对照试验队列中进行了验证和应用，显示了其在比较治疗组和安慰剂组的长期肝脏变化及预测非侵入性成像数据来源的组织特征上的效果。", "innovation": "本文提出了一种无监督机器学习方法，通过深度聚类网络同时对医学图像片段进行编码和聚类，形成了肝脏组织的模式词汇，进而能够量化弥漫性肝脏疾病的治疗反应，明确与治疗相关的特定肝脏组织变化路径，并能更好的将治疗组和安慰剂组区分开来，同时还能预测从非侵入性成像数据中获得的活检衍生特征。这种方法的验证结果显示了其在不同肝病患者的适用性与有效性。", "conclusion": "本文的方法已被证明能够有效识别与治疗反应相关的肝脏疾病患者的影像表型特征，通过使用深度聚类网络形成的组织类型词汇不仅有助于详细了解治疗对肝脏组织的具体影响，还能提供准确的非侵入性成像数据与其他已建立影像学指标相比更优秀地追踪治疗反应的能力。该方法具有广泛的临床应用潜力。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12189", "html_url": "https://arxiv.org/abs/2507.12189", "title": "BenchRL-QAS：用于量子架构搜索的强化学习算法基准测试", "title_en": "BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search", "authors": "Azhar Ikhtiarudin,Aditi Das,Param Thakkar,Akash Kundu", "background": "该研究提出了BenchRL-QAS基准测试框架，用于系统地评估强化学习（RL）算法在各种量子变分算法任务和不同量子比特数量（从2到8比特）系统中的表现。研究涵盖了无噪声和现实噪声环境中的量子变分量子特征求解器、量子状态对角化、量子分类和状态准备等代表性量子问题。这为量子架构搜索（QAS）提供了一个全面的评估平台，有助于理解不同算法在不同场景下的性能差异。", "innovation": "该研究提出了一种加权排名指标，以平衡准确度、电路深度、门计数和计算效率，从而实现公平和全面的比较。研究结果表明基于RL的量子分类器优于基本的变分分类器，并揭示了没有一种RL算法在所有QAS任务中都是最优的，算法性能高度依赖于任务结构、量子比特数量和噪声条件。这些发现强化了RL在基于量子电路设计中的“无免费午餐”原则，强调了自适应算法选择和系统性基准测试的重要性，以促进量子电路设计的进步。", "conclusion": "该工作代表了迄今为止最全面的基于RL的量子架构搜索基准测试，BenchRL-QAS及其所有实验数据已经公开，以支持可重复性和未来研究。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12196", "html_url": "https://arxiv.org/abs/2507.12196", "title": "ONNX模型的有选择性量化调优", "title_en": "Selective Quantization Tuning for ONNX Models", "authors": "Nikolaos Louloudakis,Ajitha Rajan", "background": "量化是一种减少深度神经网络模型精度的过程，以降低模型大小和计算需求，但往往以准确性为代价。全面量化模型可能在低性能下表现出色，但在低端硬件加速器上进行部署时可能会遇到挑战。为了应对这些问题，可以只对模型的一部分层进行量化，但这需要确定哪些层应被排除，这并不易实现。为此，我们提出了TuneQn，这是一种能够对ONNX模型进行有选择性量化、部署和在各种CPU和GPU设备上执行，结合性能测量、多目标优化和结果可视化的方法。", "innovation": "TuneQn通过生成有选择性地量化后的ONNX模型、部署在不同硬件上、测量性能指标（如准确性和大小）、进行帕累托前沿极小化以识别最佳模型候选者并可视化结果，提供了一种有效的有选择性地量化和调优方法。在对四个ONNX模型使用两种量化配置进行评估后，表明该方法能够有效进行有选择性量化和调优，相比全面量化模型，准确率损失最多减少了54.14%，模型大小最多减少了72.9%。", "conclusion": "TuneQn成功地展示了其有选择性地量化和调优的能力，为ONNX模型的优化提供了有效的解决方案，尽管在一定程度上减少了模型的准确性，但也极大地减少了模型的大小。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12075", "html_url": "https://arxiv.org/abs/2507.12075", "title": "BOOKCOREF：书籍规模的指代消解", "title_en": "BOOKCOREF: Coreference Resolution at Book Scale", "authors": "Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli", "background": "目前指代消解系统通常在包含小型至中型规模文档的基准测试上进行评估，但在处理长文本时，现有的基准如LitBank仍然在长度上受限，并不能充分评估系统的书规模能力，特别是当涉及跨越数十万词的共指提及时。为填补这一空白，作者提出了一个新颖的自动管道，生成高质量的书籍全文指代消解注释，并构建了第一个书籍规模的核心参考基准BOOKCOREF，平均每篇文档超过200,000词。通过一系列实验，作者展示了自动程序的鲁棒性，并证明了这种资源的价值，使当前的长文档指代消解系统在评估时能够取得高达+20个CoNLL-F1点的改进。", "innovation": "提出了一个新颖的自动管道，可以生成高质量的书籍全文指代消解注释，并据此创建了第一个书籍规模的核心参考基准BOOKCOREF。在此基础上，进行了系列实验以展示自动程序的稳定性和资源的价值。", "conclusion": "通过BOOKCOREF数据集及自动化工具，作者展示了在书籍规模上下文中指代消解系统的潜力，指出当前模型在处理大型文本时的表现不如小规模文档。发布数据和代码以促进对书籍规模的指代消解系统的进一步研究与开发，详见此链接：[此处添加链接]。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12104", "html_url": "https://arxiv.org/abs/2507.12104", "title": "从静态到智能：利用LLMs演进SaaS定价", "title_en": "From Static to Intelligent: Evolving SaaS Pricing with LLMs", "authors": "Francisco Javier Cavero,Juan C. Alonso,Antonio Ruiz-Cortés", "background": "SaaS模式通过提供灵活的定价选项革命了软件分发，以满足多样化的客户需求。然而，SaaS市场的快速增长给DevOps团队带来了巨大复杂性，需要手动管理和进化定价结构，这既耗时又容易出错。缺乏自动化定价分析工具限制了价格模型的高效评估、优化和扩展。", "innovation": "本文提出利用智能定价（iPricing），即动态、机器可读的定价模型，作为解决这些挑战的解决方案。智能定价能够实施数字化竞争分析、简化运营决策，并支持对市场动态的持续定价演变，从而提高效率和准确性。我们提出了一个基于LLM的方法，自动将静态HTML定价转换为iPricing，显著提高了效率和一致性，同时减少了人为错误。我们的实施成果AI4Pricing2Yaml包含一个基础信息抽取器，使用网络爬虫和LLM技术从SaaS网站中提取关键定价组成部分、计划、功能、使用限制和附加项。验证结果表明，该系统在所有步骤中都能有效提取所需元素。然而，在处理幻觉、复杂结构和动态内容方面仍存在问题。这项工作强调了自动化智能定价转换有潜力简化SaaS定价管理，为复杂定价环境中的更好的一致性和扩展性提供了改进的前景。", "conclusion": "这项工作突显了通过自动化智能定价转换来简化SaaS定价管理的潜力，这为日益复杂的定价环境中提高一致性和扩展性提供了改进的前景。未来的研究将集中在提高提取能力并增强系统的适应性，使其能处理更广泛的SaaS网站。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12107", "html_url": "https://arxiv.org/abs/2507.12107", "title": "Non-Adaptive Adversarial Face Generation", "title_en": "Non-Adaptive Adversarial Face Generation", "authors": "Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo", "background": "人脸识别系统（FRSs）面临的对抗攻击（adversarial attacks）对安全性和隐私性构成了严重威胁，尤其是在这些系统用于身份验证时。这种攻击可以通过生成具有特定目标身份属性的合成面部图像来发动，使FRS误认为这些图像对应的是目标身份，从而在无需目标个体合作的情况下获取他们的身份信息。现有的方法大多依赖于迭代优化，如梯度下降法，在实现对抗样本时需要多次查询和反复调整，这在面对商业化FRS时往往不可行，因为无法直接通过对这些系统的反复适配查询来获得成功。本文讨论了对抗样本生成的问题及其背景。", "innovation": "本文提出了一种新颖的方法，即非适配的对抗性面部生成，这种方法利用了人脸特征空间的结构性质来生成与目标人脸特征相似但外观上却明显不同的合成面部图像。相比传统的方法，该方法不依赖于多次迭代优化，而是基于共享同一特征子球体（attributed subsphere）的个体视觉结构特点，通过这些子球体实现了非适配性查询并且查询次数极少。这种方法消除了对-transferability（迁移性）和开源代理模型的依赖，后者通常是商业FRS多次适配查询不可行时的常见策略。本文方法仅需一次包含100张面部图像的非适配查询，在AWS的CompareFaces API默认阈值下，其成功率达到93%以上。此外，这种方法可以生成具有高欺骗性的对立性面部，而这些面部可以传递特定的高级属性，这与以往的攻击方法不同。", "conclusion": "本文提出的方法在无需目标个体配合的情况下，仅需一次非适配的查询就可以生成高度成功的对抗性面部，其成功率超过93%。这种方法通过引入一个基于特征子球体的概念，展现出对抗攻击在人脸识别系统中的新策略，即非适配性的对抗性面部生成。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12108", "html_url": "https://arxiv.org/abs/2507.12108", "title": "多模态协调在线行为：权衡与策略", "title_en": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies", "authors": "Lorenzo Mannocci,Stefano Cresci,Matteo Magnani,Anna Monreale,Maurizio Tesconi", "background": "在线行为的协调性已经成为数字生态系统分析的关键焦点，涵盖了从有益的集体行动到有害的操纵行为，如虚假信息运动。传统的分析方法多依赖于单一模式的方法，集中于单一类型的互动，如共转发或共话题标签。但这些方法可能会忽略不同模态间复杂的协同动态。", "innovation": "该研究对比了不同的多模态协调行为检测方法，探讨了弱整合与强整合多模态模型之间的权衡，强调了捕捉更广泛协调模式与识别紧密协调行为之间的平衡。还通过比较单模态和多模态方法来评估不同数据模态的独特贡献，并探讨不同多模态实现方式对检测结果的影响。研究表明，并不是所有的模态都提供了独特的见解，但多模态方法可以提供更全面的理解协调动力学。", "conclusion": "这项研究增强了检测和分析协调在线行为的能力，提供了保护数字平台完整性的新视角。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12252", "html_url": "https://arxiv.org/abs/2507.12252", "title": "通过大型语言模型进行多粒度融合以提高语境ASR", "title_en": "Improving Contextual ASR via Multi-grained Fusion with Large Language Models", "authors": "Shilin Zhou,Zhenghua Li", "background": "尽管端到端自动语音识别（ASR）模型在转录通用语音方面表现出色，但在准确识别上下文相关关键词（如专有名词或用户特定实体）方面经常存在困难。先前的方法通过文本模态中的关键词字典来提升关键词识别，这些方法包括在标记级别融合以引导标记生成，或在短语级别融合以直接复制关键词短语。然而，这些方法各具局限性。文献综述概述了前人的研究，并阐述了现有方法的不足之处，为进一步改进提供背景信息。", "innovation": "本文提出了一种新颖的多粒度融合方法，结合标记级和短语级融合与大型语言模型（LLM）。该方法通过晚期融合策略优雅地结合了ASR的声学信息与LLM丰富的上下文知识，平衡了标记级别的精细精度与短语级别的整体理解。实验结果表明，该方法在关键词相关指标上达到了最先进的性能，同时保持了非关键词文本的高准确性。消融研究进一步证实，标记级别和短语级别的组件在整体框架中都有显著贡献，互补提高性能。", "conclusion": "通过公开发布代码和模型，研究者验证了该方法的有效性，并展示了其在关键词识别上的优异表现。这种方法在上下文ASR中实现了新的突破，为后续研究提供了有价值的经验和参考。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12262", "html_url": "https://arxiv.org/abs/2507.12262", "title": "带有神经网络参数的非平稳高斯过程框架", "title_en": "A Framework for Nonstationary Gaussian Processes with Neural Network Parameters", "authors": "Zachary James,Joseph Guinness", "background": "高斯过程因其灵活性和不确定性量化已经成为非参数回归的流行工具。然而，它们通常使用平稳核，这限制了模型的表达能力，并且可能不适合许多数据集。", "innovation": "本文提出了一种框架，该框架使用非平稳核，其参数在特征空间中变化，将这些参数建模为输入为特征的神经网络的输出。神经网络和高斯过程通过链式法则联合训练。该方法清晰地描述了非平稳参数的行为并且能够与大规模数据集的近似方法兼容。该方法在不同的非平稳核中灵活且易于适应，无需重新设计优化过程。作者使用GPyTorch库实现这些方法，并可以进行修改。在不平稳方差和噪声变异度量版本的测试中，与平稳模型和利用变分近似的分层模型相比，该方法在多个机器学习数据集上实现了更高的准确性和log-评分。对于仅具有非平稳方差的模型也观察到了类似的结果。此外，作者还展示了该方法能够恢复空间数据的非平稳参数的能力。", "conclusion": "本文提出的方法通过将非平稳参数建模为神经网络的输出，克服了传统平稳核的局限性，效果优于平稳模型和其他近似方法，特别是在处理机器学习数据集时表现更佳。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12284", "html_url": "https://arxiv.org/abs/2507.12284", "title": "MERA Code: 统一的代码生成评估框架", "title_en": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks", "authors": "Artem Chervyakov,Alexander Kharitonov,Pavel Zadorozhny,Adamenko Pavel,Rodion Levichev,Dmitrii Vorobev,Dmitrii Salikhov,Aidar Valeev,Alena Pestova,Maria Dziuba,Ilseyar Alimova,Artem Zavgorodnev,Aleksandr Medvedev,Stanislav Moiseev,Elena Bruches,Daniil Grebenkin,Roman Derunets,Vikulov Vladimir,Anton Emelyanov,Dmitrii Babaev,Vladimir V. Ivanov,Valentin Malykh,Alena Fenogenova", "background": "大语言模型（LLM）的进步在软件工程中增强了任务自动化，但当前的评估主要集中在自然语言任务上，忽视了代码质量的评估。大多数基准测试更侧重于高层推理而非可执行代码和实际性能，这在了解这些模型在生产环境中的真正能力和风险方面留下了空白。", "innovation": "提出了MERA Code，这是MERA基准测试家族的一个新增内容，专门用于评估最新的代码生成LLM在俄语中的代码生成能力。该基准测试包含11个评估任务，涵盖了8种编程语言。我们提出了一种评估方法论，通过分类法明确了模型完成这些任务所需的实用编程技能，并提供了一个开源代码库供用户进行MERA评估，一套与各种编程环境兼容的评分系统，以及一个包含排行榜和提交系统的平台。该评估方法涵盖了开源LLM和前沿API模型在非英语语言的实际编程任务中的限制，", "conclusion": "MERA是一个公开发布的基准测试，旨在指导未来的研究，预见模型开发中的突破性特性，并标准化评估流程。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12197", "html_url": "https://arxiv.org/abs/2507.12197", "title": "量化更多，损失更少：基于残差量化语音表示的自回归生成", "title_en": "Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations", "authors": "Yichen Han,Xiaoyang Hao,Keming Chen,Weibo Xiong,Jun He,Ruonan Zhang,Junjie Cao,Yue Liu,Bowen Li,Dongrui Zhang,Hui Xia,Huilei Fu,Kai Jia,Kaixuan Guo,Mingli Jin,Qingyun Meng,Ruidong Ma,Ruiqian Fang,Shaotong Guo,Xuhui Li,Yang Xiang,Ying Zhang,Yulong Liu,Yunfeng Li,Yuyi Zhang,Yuze Zhou,Zhen Wang,Zhaowen Chen", "background": "文本转语音（TTS）合成为在离散建模范式下的进展经过了新的推动。现有自回归方法通常依赖于单码本表示，但这些方法存在显著信息丢失的问题。在采用后处理方法如流匹配技术进行细化后，这些方法仍然难以恢复细粒度的细节（例如：语调细微差别、说话人特定的音色），这在如唱歌声音或音乐合成等复杂场景下尤为明显。", "innovation": "该论文提出了一种新的TTS框架QTTS，基于新开发的音频编解码器QDAC。QDAC的核心创新是在一个基于ASR的自回归网络基础上添加一个GAN进行端到端训练，从而使语义特征解耦更优，实现了可扩展、近乎无损的压缩。QTTS模型采用两种创新策略：层次并行架构（用于建模跨码本的依赖关系以提高合成质量）和延迟多头方法（通过并行预测带有固定延迟加速推断速度）。", "conclusion": "实验结果表明，提出的框架在合成质量和保留表达性内容方面均优于基线模型。这表明，通过多码本建模来放大压缩是一个对未来高质量、通用语音和音频生成的有前景的方向。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12269", "html_url": "https://arxiv.org/abs/2507.12269", "title": "基于渐进层冻结的站点级微调：从极早产婴儿第一天胸部X光片向稳健预测支气管肺发育不良的迈进", "title_en": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "authors": "Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)", "background": "支气管肺发育不良（BPD）是一种影响35%极低出生体重婴儿的慢性肺部疾病，通常需要在妊娠周36后依赖氧气，这会导致终生的呼吸系统并发症。由于预防措施可能包括神经发育不良、机械通气引起的肺损伤和全身并发症，因此早期BPD的预后和预测其结果对于避免低风险婴儿的不必要的毒性至关重要。新生儿入院时的胸部X光通常在出生后24小时内进行，可以作为非侵入性的预后工具。先前的研究显示，常规的出生后第一天胸部X光片对于预测BPD的前景是有限的，强调了学习标志物的重要性。", "innovation": "本文开发并探讨了一种深度学习方法，利用从极低出生体重婴儿（≤32周胎龄，401-999克）出生后24小时内获取的胸部X光片，这些婴儿总共163例。作者对一种在成人胸部X光片上预训练的ResNet-50进行微调，并采用了渐进层冻结和有区别的学习率以防止过拟合，同时评估了CutMix增强和线性探测技术。通过这种方法，该模型在预测BPD的中度/重度结局方面表现最佳，AUC ROC达到了0.78±0.10，平衡准确率为0.69±0.10，F1分数为0.67±0.11。本地预训练显著优于ImageNet初始化（p=0.031），证实了领域特定预训练对于BPD预后预测的重要性。此外，本文展示了基于本地预训练的方法可以从常规第一天胸部X光片准确预测BPD，并通过渐进层冻结和线性探测保持了计算可行性，以便在未来应用于联邦学习部署。", "conclusion": "本文提出的方法表明，基于领域的预训练可以准确预测极早产婴儿第一天的胸部X光片中的BPD，通过渐进层冻结和线性探测技术，这种方法对于站点级别的实施和未来的联邦学习部署都保持了计算上的可行性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12212", "html_url": "https://arxiv.org/abs/2507.12212", "title": "绘制一个丑陋的人：生成式AI对丑陋感知的探究", "title_en": "Draw an Ugly Person An Exploration of Generative AIs Perceptions of Ugliness", "authors": "Garyoung Kim,Huisung Kwon,Seoju Yun,Yu-Won Youn", "background": "生成式AI不仅复制了人类的创造力，还复制了深刻的文化偏见，因此迫切需要批判性地审视这些工具对诸如丑陋等概念的理解和表达。研究表明，不同生成式AI模型通过文本和图像来理解和表达丑陋，并探索这些表示中嵌入的偏见。研究发现，人工智能模型将丑陋不均匀地与年老的白人男性形象联系起来，反映出根深蒂固的社会偏见以及反悖的偏见，即避免对边缘群体进行刻板描绘的努力反而导致将负面特征过度投影到主要群体上。质性分析进一步揭示，尽管尝试将丑陋置于社会语境中，传统身体特征如不对称和老化仍然是主要的视觉主题。这些发现表明，尽管试图创造更平等的代表，生成式AI仍然在传播继承和反悖偏见，强调了创建伦理AI训练范式和推进更具包容性的AI发展方法的重要性.", "innovation": "该研究通过迭代提示大型语言模型提取与丑陋相关的13个形容词，并使用四个AI模型和三个提示生成了624张图像，独立编码和主题分析图像中的人口统计和社会经济属性，揭示了生成式AI在理解和表达丑陋时的偏见，并提出反悖的偏见问题。该研究为生成式AI中偏见的理解和解决提供了新的视角和方法，强调了在AI开发中引入伦理和包容性考量的必要性。", "conclusion": "尽管AI模型试图创造更平等和道德的视觉表现，但它们继续维持着继承和反悖的偏见。这强调了迫切需要制定伦理AI训练方法和推进更包容的AI开发方法，以减少偏见并改进生成式AI的输出。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12295", "html_url": "https://arxiv.org/abs/2507.12295", "title": "Text-ADBench: 基于LLM嵌入的文本异常检测基准", "title_en": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding", "authors": "Feng Xiao,Jicong Fan", "background": "文本异常检测是自然语言处理（NLP）中的关键任务，应用范围广泛，包括欺诈检测、虚假信息识别、垃圾邮件检测和内容审查等。尽管大型语言模型（LLMs）和异常检测算法取得了显著进展，但缺乏标准化和全面的评估基准限制了现有的异常检测方法在文本数据上的严格比较和创新方法的发展。本研究通过利用多种预训练语言模型在各种文本数据集上的嵌入，进行全面的实验研究，引入了文本异常检测基准Text-ADBench，以系统评估基于嵌入的文本异常检测的有效性。", "innovation": "本研究的主要创新点在于提出了基于LLMs嵌入的文本异常检测基准Text-ADBench，涵盖了从早期语言模型（GloVe，BERT）到多个大型语言模型（LLaMa-2，LLaMa-3，Mistral，OpenAI），以及多领域的文本数据集（新闻、社交媒体、科学出版物），并使用了全面的评估指标（AUROC，AUPRC）。研究揭示了嵌入质量对异常检测效果至关重要，并发现基于深度学习的方法在利用LLM时并不一定优于传统的浅层算法。此外，研究还观察到跨模型性能矩阵具有强低秩特征，有助于快速模型（或嵌入）评估和选择。另外，该研究还开源了基准工具，其中包括来自不同模型的所有嵌入和代码。", "conclusion": "本研究通过对文本异常检测方法进行全面的实证研究并框架化，旨在改进现有方法，提供了一个强大的、可扩展的文本异常检测系统基础。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12261", "html_url": "https://arxiv.org/abs/2507.12261", "title": "Infherno：从非结构化临床笔记合成FHIR资源的端到端基于代理的方法", "title_en": "Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes", "authors": "Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer", "background": "HL7 FHIR标准已成为处理复杂健康数据之间互操作性的首选格式。以往自动将非结构化的临床笔记转换为结构化FHIR资源的方法依赖于模块化规则系统或指令调优和受限解码的人工智能模型。这些方法普遍存在泛化能力不足和结构不一致的问题。", "innovation": "本文提出了一种端到端框架，利用LLM代理、代码执行和健康术语数据库工具。此框架设计用于遵守FHIR文档结构，并且在从非结构化文本预测FHIR资源方面与人类基准相当。实现包括自定义和合成数据前端，以及本地和专有模型，支持临床数据集成和机构间的互操作性。", "conclusion": "Infherno解决方案在FHIR资源合成方面表现出色，通过解决泛化能力和结构一致性的问题，提高临床数据集成和互操作性的效率。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12314", "html_url": "https://arxiv.org/abs/2507.12314", "title": "Thought Purity: 防御链式思维攻击的防御框架", "title_en": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack", "authors": "Zihao Xue,Zhen Bi,Long Ma,Zhenlin Hu,Yan Wang,Zhenfang Liu,Qing Sheng,Jie Xiao,Jungang Lou", "background": "尽管通过强化学习训练的大型推理模型（LRMs，例如Deepseek-R1）在不断发展的大型语言模型（LLMs）领域展示了先进的推理能力，但它们对安全威胁的易感性仍然是一个关键的脆弱性。特别是在链式思维（CoT）生成过程中，恶意的攻击方法如后门提示攻击可以系统地破坏模型的核心推理机制。新兴的链式思维攻击（CoTA）通过利用提示可控性，低成本地同时降低了CoT的安全性和任务性能。为解决这一综合的安全-性能脆弱性问题，本文提出了Thought Purity（TP）：一种系统性增强对恶意内容的抵抗力并保持操作有效性的防御范式。", "innovation": "提出了一种名为Thought Purity（TP）的防御范式，通过三个协同组件实现其目标：（1）安全优化的数据处理管道；（2）强化学习增强的规则约束；（3）适应性监控指标。该方法为加强强化学习对齐的推理系统提供了第一个全面的防御机制，大大提高了下一代人工智能架构的安全-功能平衡。", "conclusion": "本文的贡献在于，首次提出了针对链式思维攻击（CoTA）的全面防御机制，显著推进了强化学习对齐的推理系统中的安全-功能平衡，为下一代人工智能架构提供了重要支持。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12202", "html_url": "https://arxiv.org/abs/2507.12202", "title": "稀疏自编码器在序列推荐模型中的解释与灵活控制", "title_en": "Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control", "authors": "Anton Klenitskiy,Konstantin Polev,Daria Denisova,Alexey Vasilev,Dmitry Simakov,Gleb Gusev", "background": "当前许多先进的序列推荐模型采用Transformer架构，这类模型被认为是黑盒模型，尽管它们在各种实时应用中的表现优秀，但理解其内部工作机制对于指导、影响和控制它们的行为来说非常关键。近期研究发现，稀疏自编码器（Sparse Autoencoders, SAE）在提取语言模型中的可解释特征方面具有潜力。SAE通过稀疏线性组合方式学习恢复Transformer内部层的隐藏状态。", "innovation": "本文研究了将SAE应用于序列推荐领域。研究发现，经过序列推荐任务训练的Transformer模型中学习到的方向比原始隐藏状态维度更具解释性和单一含义。此外，研究展示了SAE学习到的特征可被用于灵活控制模型的行为，为最终用户提供了一种简单的方法来根据不同的定制场景和上下文调整推荐。", "conclusion": "本文研究证明了将稀疏自编码器应用于序列推荐任务的有效性，展示了一种新的方法可让用户更简单地根据情境调整推荐。这种技术可以通过更解释性的特征和灵活控制来提升序列推荐模型的性能和用户满意度。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12329", "html_url": "https://arxiv.org/abs/2507.12329", "title": "删除信道的神经极化译码器", "title_en": "Neural Polar Decoders for Deletion Channels", "authors": "Ziv Aharoni,Henry D. Pfister", "background": "现有用于删除信道的极化译码器具有计算复杂度为 $O(N^4)$ 的缺点，限制了极化码在删除信道中的应用范围，主要适用于较短至中等长度的块码。本文介绍了一种用于删除信道的神经极化译码器（NPD），以降低计算复杂度，支持更长的块码长度。", "innovation": "通过将NPD架构扩展到支持删除信道，仅改变一个神经网络来适配删除信道，使NPD的计算复杂度降低至 $O(AN\text{log}N)$，其中 $A$ 是由用户确定的计算预算，与信道无关。此外，通过引入列表译码进一步提升性能。", "conclusion": "提出的NPD可以应用于未来技术如DNA存储，并通过减少复杂度支持更长的块码长度。实验验证了NPD的性能优于现有方法，并展示了其在删除率 $\boldsymbol{\boldsymbol{\begin{cases} 0.01 \\ 0.1 \\\boldsymbol{\boldsymbol{\right)}}$ 下的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12308", "html_url": "https://arxiv.org/abs/2507.12308", "title": "Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization", "title_en": "Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization", "authors": "Prashanth Vijayaraghavan,Apoorva Nitsure,Charles Mackin,Luyao Shi,Stefano Ambrogio,Arvind Haran,Viresh Paruthi,Ali Elzein,Dan Coops,David Beymer,Tyler Baldwin,Ehsan Degan", "background": "大规模语言模型（LLMs）在NLP任务和领域中已被广泛使用，显示出其适应性和有效性。电子设计自动化（EDA）领域中，LLMs在寄存器传输级（RTL）代码生成和总结方面显示出潜力，但现有研究主要集中于通用代码任务，却鲜有研究考察和优化基于硬件描述语言（HDLs），特别是VHDL的LLMs。本文评价了现有代码LLMs在VHDL上的生成和总结性能，并提出了一种新的方法Chain-of-Descriptions（CoDes），以改善LLMs在VHDL代码生成和总结方面的表现。", "innovation": "提出了Chain-of-Descriptions（CoDes）方法，该方法通过生成一系列基于问题描述和VHDL代码的中间描述步骤来增强LLMs在VHDL代码生成和总结方面的性能。实验结果表明，CoDes方法在不同度量标准上明显优于标准提示策略，不仅提高了VHDL代码生成和总结的质量，还为提升代码LLMs在VHDL中的应用提供了框架。", "conclusion": "本文研究表明现有的代码LLMs在VHDL上的生成和总结性能普遍较差，提出了新的方法CoDes来改善这一问题，并通过实验验证了其有效性。未来可以通过该方法为增强HDL（特别是VHDL）的代码LLMs研究提供一个框架。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12242", "html_url": "https://arxiv.org/abs/2507.12242", "title": "在推荐系统中寻找公平性", "title_en": "Looking for Fairness in Recommender Systems", "authors": "Cécile Logé", "background": "推荐系统如今无处不在，影响着用户的日常体验。本文以构建社交媒体内容推荐系统为例，探讨推荐系统带来的公平性问题，包括用户、内容创作者和社会层面的考虑。推荐系统可能导致过滤气泡现象，即推荐过于个性化，使用户接触到的信息变得狭窄，影响他们获取外界信息的机会，甚至影响社会整体舆论、行为和政治决策。为解决该问题，本文提出通过定义公平性的绩效指标，并在其框架中评估推荐系统的多样性，以实现个性化推荐与社会目标之间的平衡，促进丰富多样的文化和观点发展空间。", "innovation": "本文创新之处在于提出了如何在推荐系统中实现公平性的方法，包括通过定义表示多样性的绩效指标，进而调整推荐系统的性能，以避免过滤气泡的形成，并促进更加包容和多元的内容景观。此方法为解决推荐系统公平性问题提供了新的视角。", "conclusion": "通过引入绩效指标来评估推荐系统的多样性，可以帮助我们在个性化推荐与社会目标之间找到平衡点。这种方式不仅能保护用户的隐私和选择自由，还能减少过滤气泡的负面影响，支持更加开放和多元的信息环境，从而促进社会文化的丰富性和多样性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12359", "html_url": "https://arxiv.org/abs/2507.12359", "title": "Cluster Contrast for Unsupervised Visual Representation Learning", "title_en": "Cluster Contrast for Unsupervised Visual Representation Learning", "authors": "Nikolaos Giakoumoglou,Tania Stathaki", "background": "当前，无监督视觉表示学习领域已经取得了显著进展，但如何有效地结合对比学习和聚类方法来同时促进特征的散射和对齐，仍然是亟待解决的问题。现有的方法往往只能部分地满足这些需求，无法同时优化类间分离和类内紧凑性。该研究旨在探讨一种新的方法来解决这个问题，提出了Cluster Contrast (CueCo)这一创新点，旨在利用对比损失和聚类目标来分别优化特征的散射和对齐，以改进无监督视觉表示学习的效果。", "innovation": "该研究引入了一种新颖的方法——Cluster Contrast (CueCo)，这是一种无监督视觉表示学习的新方法，能够有效地结合对比学习和聚类技术的优势。CueCo设计上旨在同时散射和对齐特征表示，并通过两个神经网络（查询和键网络）来实现，其中键网络通过查询输出的慢速移动平均值进行更新。CueCo使用对比损失来推离不同的特征，增强类间分离；同时利用聚类目标来将相同聚类的特征拉在一起，促进类内紧凑性。该方法在不同数据集上的表现证明了其有效性，特别是在CIFAR-10、CIFAR-100和ImageNet-100上的分类准确率分别为91.40%、68.56%和78.65%。", "conclusion": "通过结合对比学习和聚类，CueCo为无监督视觉表示学习的发展开辟了新的方向，展示了其在优化特征散射和对齐方面的潜力，提高了无监督视觉表示学习的效果。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12367", "html_url": "https://arxiv.org/abs/2507.12367", "title": "GitChameleon: 评估AI代码生成与Python库版本不兼容性", "title_en": "GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities", "authors": "Diganta Misra,Nizar Islah,Victor May,Brice Rauby,Zihan Wang,Justine Gehring,Antonio Orvieto,Muawiz Chaudhary,Eilif B. Muller,Irina Rish,Samira Ebrahimi Kahou,Massimo Caccia", "background": "软件库的快速演变对代码生成构成了重大障碍，需要不断适应频繁的版本更新并保持向后兼容。现有的代码演变基准虽然提供了有价值的信息，但通常没有基于执行的评估，无法生成符合特定库版本的代码。为了填补这一空白，本文引入了一个名为GitChameleon的新颖且精心挑选的数据集，其中包含328个Python代码补全问题，每个问题都针对特定的库版本，并附有可执行的单元测试。这个数据集严格评估了当下最先进的大型语言模型（LLMs）、基于LLM的代理、代码助手和RAG系统在版本条件下的代码生成能力，通过执行展示功能准确性。广泛的研究表明，最先进的系统在这个任务中面临巨大挑战；企业模型在基线成功率达到48-51%的范围内，说明了该问题的复杂性。GitChameleon通过提供一个基于执行的基准，强调代码库的动态特性，帮助更好地理解这一挑战，指导更适应和可靠的AI代码生成方法的发展。", "innovation": "引入了一个名为GitChameleon的新颖且精心挑选的数据集，其中包含328个Python代码补全问题，每个问题都针对特定的库版本，并附有可执行的单元测试。这个数据集严谨评估了大型语言模型、基于LLM的代理、代码助手和RAG系统在版本条件下的代码生成能力，通过执行展示功能准确性。", "conclusion": "基于执行的基准使得更清晰地理解这一挑战，有助于指导开发更适应和可靠的AI代码生成方法。已经发布的数据集和评估代码提供了开源的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12412", "html_url": "https://arxiv.org/abs/2507.12412", "title": "NOCTA: 非贪婪目标成本权衡获取方法用于纵向数据", "title_en": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data", "authors": "Dzung Dinh,Boqi Chen,Marc Niethammer,Junier Oliva", "background": "在许多关键应用中，资源限制了可收集以进行预测的信息量。例如，在医疗保健领域，患者数据覆盖了从实验室测试到影像学研究等多种特征，每个特征可能携带不同的信息，但获取每种特征需要耗费相应的时间、金钱或患者风险。此外，在预测任务中，如果数据和标签随时间变化，确定何时或获取何种信息的重要性变得更具挑战性。因此，如何在成本和效用之间做出权衡，以最经济地获取最有信息价值的数据成为了关键问题。", "innovation": "本文提出了一种名为NOCTA的非贪婪目标成本权衡获取方法，该方法在推理时间按序搜集最信息丰富的特征数据，在考虑时间动态和获取成本的同时实现这一点。NOCTA方法引入了一个统一的估计目标，并发展了两个互补的估计器：基于最近邻的无参数方法（NOCTA-NP）和直接预测潜在获取优势的有参数方法（NOCTA-P）。实验结果表明，NOCTA的两种变体在合成和真实医疗数据集上都优于现有基准方法。", "conclusion": "实验数据表明，NOCTA方法在合成和真实世界医疗数据集上优于现有的基线方法，展示了在成本和效用之间的非贪婪且有效的获取策略对于处理随时间变化的数据的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12416", "html_url": "https://arxiv.org/abs/2507.12416", "title": "QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval", "title_en": "QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval", "authors": "Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee", "background": "现有的组成图像检索（CIR）方法主要集中在检索目标图像，而忽略了其他图像的相关性，这可能导致检索到不相关的图像，从而影响用户的满意度。这些方法通常使用对比学习，将目标图像视为正样本，将批次中的所有其他图像视为负样本，这可能会无意中包含错误的负样本。", "innovation": "提出了Query-Relevant Retrieval (QuRe)，这是一种优化奖励模型目标的方法，以减少错误的负样本。引入了一种新的硬负样本选择策略，选择在目标图像后面两个陡峭的相关分数下降后的图像，以有效过滤掉错误的负样本。此外，创建了Human-Preference FashionIQ (HP-FashionIQ) 数据集，明确捕捉用户偏好超过仅目标检索。", "conclusion": "QuRe在FashionIQ和CIRR数据集上达到了最先进的性能，在新的HP-FashionIQ数据集上，QuRe的人类偏好最匹配。源代码可在该链接：this https URL。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12414", "html_url": "https://arxiv.org/abs/2507.12414", "title": "AutoVDC: 使用视觉语言模型进行自动视觉数据清洗", "title_en": "AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models", "authors": "Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding", "background": "自动驾驶系统的训练需要大量精确标注的数据集才能实现稳健的性能。人工标注存在不完美性，且通常需要多次迭代以生成高质量的数据集。然而，手动审查大量数据集既费时又昂贵。", "innovation": "本文提出了一种名为AutoVDC（自动视觉数据清洗框架），并研究了视觉语言模型（VLMs）在自动识别视觉数据集中的错误标注方面的应用，从而让用户能够消除这些错误并提高数据质量。通过使用KITT和nuImages数据集验证方法的有效性，这些数据集包含用于自动驾驶的物体检测基准，通过故意注入错误标注来测试AutoVDC的有效性，并比较不同VLM的检测率，研究VLM微调对其管道的影响。结果表明，该方法在错误检测和数据清洗实验中表现出色，表明其有可能显著提高大规模生产数据集的可靠性和准确性。", "conclusion": "方法在错误检测和数据清洗方面的高表现显示其潜在能力，可显著提高自动驾驶领域大规模生产数据集的可靠性和准确性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12419", "html_url": "https://arxiv.org/abs/2507.12419", "title": "混合再现专家", "title_en": "Mixture of Raytraced Experts", "authors": "Andrea Perin,Giacomo Lagomarsini,Claudio Gallicchio,Giuseppe Nuti", "background": "现有的Mixture of Experts (MoE) 架构大多要求对于给定样本具有固定量的计算。这种固定的计算量限制了模型在特定任务上的灵活性和性能提升空间。该研究引入了一种新的Mixture of Raytraced Experts 架构，该架构能够动态选择一系列专家，生成具有可变宽度和深度的计算图。这种方法通过迭代从候选专家集采样并通过与递归神经网络类似的方式展开序列来训练模型。其特点是无需负载平衡机制，并且初步实验表明该方法在与同等/更高准确性的同时，训练周期减少了10%到40%。这为MoEs领域开辟了新的研究方向，可能使得设计更快、更富表现力的模型成为可能。", "innovation": "引入了Mixture of Raytraced Experts架构，能够动态选择专家序列，生成计算图的宽度和深度可变。通过与递归神经网络类似的方式迭代采样和展开序列来训练模型，该方法不需要负载平衡机制，初步实验显示出较短的训练周期和具有可比或更高的准确性。", "conclusion": "该方法为MoEs领域开辟了新的研究方向，可能使得设计更快、更富表现力的模型成为可能。同时，初步实验结果表明这种方法在减少训练周期的同时，可以保持或提高模型的准确性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12195", "html_url": "https://arxiv.org/abs/2507.12195", "title": "揭示古代之美：计算机视觉在庙宇瓷砖数字化重建中的应用", "title_en": "Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision", "authors": "Arkaprabha Basu", "background": "现代数字化技术极大地改变了文化珍宝的保存和修复方式，计算机科学家被轻松地整合到多学科项目中。机器学习、深度学习和计算机视觉技术正在重塑3D重建、图像修复、物联网方法、遗传算法和图像处理等领域的发展。文章针对印度古迹的特别之处，提出了三种创新技术。", "innovation": "文章提出了三种创新技术：第一种是分形卷积方法，一种基于图像处理的分割方法，用于揭示这些不可替代的文化建筑中的细微建筑模式。第二种是一种专门为西孟加拉邦令人着迷的Bankura陶俑庙设计的新颖自动填充方法SSTF，结合了MosaicSlice新的数据扩增方法。此外，研究还探讨了超分辨率策略，确保在提高图像质量的同时不丢失细节。这些方法利用新颖的数据扩增策略在低成本下实现了自动化，使得区域填充无缝且细节丰富。", "conclusion": "通过提供在传统与创新之间保持平衡的有效解决方案，研究提高了文化遗产保护的水平，并最终确保了无与伦比的效率和美学效果。所提出的策略将该领域推进到了前所未有的高效和美学质量的时代。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12366", "html_url": "https://arxiv.org/abs/2507.12366", "title": "FactorHD：用于多对象多类表示和因子化的超维计算模型", "title_en": "FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization", "authors": "Yifei Zhou,Xuchu Huang,Chenyu Ni,Min Zhou,Zheyu Yan,Xunzhao Yin,Cheng Zhuo", "background": "神经符号人工智能（神经符号AI）在逻辑分析和推理方面表现出色。超维度计算（HDC）作为一种有前途的大脑启发式计算模型，是神经符号AI的关键组成部分。尽管提出了多种HDC模型用于表示类-实例关系和类-类关系，但在表示更复杂的类-子类关系时，即多个对象与不同层次的类和子类关联的情况，它们在因子化这一关键任务上遇到了挑战。因子化是神经符号AI系统中的一个关键任务，而在处理多个对象与类-子类关系时，现有HDC模型存在诸如'超级叠加灾难'和'2的问题'等局限性。", "innovation": "本文提出了一种名为FactorHD的新颖HDC模型，能够高效地表示和因子化复杂的类-子类关系。FactorHD采用一种符号编码方法，嵌入额外的存储条款，保留了更多关于多个对象的信息。此外，它还采用了一种高效的因子化算法，通过识别目标类的存储条款来选择性地消除冗余类。该模型显著提高了表示和因子化多个对象时的计算效率和准确性，克服了现有HDC模型的局限性。实验结果表明，FactorHD在表示大小为10^9的情况下相比现有HDC模型实现了约5667倍的加速。当与ResNet-18神经网络结合时，FactorHD在Cifar-10数据集上实现了92.48%的因子化准确率。", "conclusion": "FactorHD在表示和因子化多个对象时表现出显著的计算效率和准确性提升，尤其是在处理复杂类-子类关系方面。该模型为神经符号AI系统提供了新的解决方案，克服了现有HDC模型的限制。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12440", "html_url": "https://arxiv.org/abs/2507.12440", "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "title_en": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "authors": "Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang", "background": "真实机器人的仿真人学习数据收集已经显著推动了机器人操作的发展。然而，机器人硬件的需求在过程中从根本上限制了数据规模。", "innovation": "本文探索使用第一人称人类视频训练Vision-Language-Action (VLA)模型，并提出了一种名为Isaac Humanoid Manipulation Benchmark的新仿真基准，设计了多样的双臂操作任务，并通过微调EgoVLA模型展示了显著的改进。", "conclusion": "通过在Isaac Humanoid Manipulation Benchmark上的细调和评估EgoVLA模型，显示了与基线相比的显著改进，并探讨了人类数据的重要性。相关的视频可以在我们的网站上找到：this https URL"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12379", "html_url": "https://arxiv.org/abs/2507.12379", "title": "在语言模型中探测算术错误", "title_en": "Probing for Arithmetic Errors in Language Models", "authors": "Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan", "background": "研究语言模型内部激活能否用于检测算术错误。通过控制环境下的3位数加法问题，展示了简单的探针能够准确解码模型预测输出和正确答案，不受模型输出正确与否的影响。随后将分析扩展到仅包含加法的GSM8K问题结构化思考痕迹，发现针对简单算术训练的探针可以很好地泛化到更复杂的情境中，揭示了持续的内部表示。最后证明这些探针可以引导选择性复述错误的推理步骤，从而提高任务准确性，同时不影响正确输出。", "innovation": "提出使用简单的探针准确解码语言模型的隐藏状态中的预测输出和正确答案，训练轻量级错误检测器预测模型的正确性，并发现针对简单算术训练的探针在更复杂情境中良好泛化。", "conclusion": "研究结果表明，仅从内部激活即可预测算术错误，并且简单的探针为语言模型的轻量级自我修正提供了可行的途径。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12442", "html_url": "https://arxiv.org/abs/2507.12442", "title": "用长上下文长度表征状态空间模型（SSM）及其与Transformer的混合语言模型性能", "title_en": "Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length", "authors": "Saptarshi Mitra,Rachid Karami,Haocheng Xu,Sitao Huang,Hyoukjun Kwon", "background": "随着对能够在本地设备上处理连续长上下文输入的机器智能需求快速增长，传统Transformer架构的二次复杂性和高内存需求使得它们在这些任务中变得低效且往往无法使用。这推动了向新的架构如状态空间模型（SSMs）和混合模型的转变，这些新的架构有望实现接近线性的扩展。尽管目前大多数研究集中在这些模型的准确性和理论吞吐量上，但对于实际消费级硬件的系统级性能表征仍极为重要，从而可以指导系统优化和启用新应用。现有研究主要关注于模型的准确性和理论吞吐量，而缺乏对实际消费者硬件的系统性性能表征，为了填补这一空白，本文通过全面比较深度检查了特别针对消费者和嵌入式GPU设备的长上下文推断进行的Transformer、SSM和混合模型的基准测试。", "innovation": "本文创新地分析了状态空间模型（SSMs）及其与Transformer的混合模型在长上下文推断中的性能，并特别针对消费级及嵌入式GPU设备进行了全面比对性试验。研究发现SSMs不仅在长上下文推断任务中是可行的，而且表现出优越性，可以在24GB的消费级GPU上处理220K序列长度的上下文，大约是同类Transformer的四倍长。此外，本文还深入分析了在边缘平台上的操作层面，揭示了定制硬件感知的SSM内核主导了推断运行时，占据了超过55%的延迟，将它们确定为未来的硬件加速主要目标。同时，本文提供了详细的设备特定表征结果以指导边缘系统协同设计。为了进一步研究，本文还将开源性能表征框架。", "conclusion": "本文通过全面的基准测试对比了长上下文推断场景中针对消费级和嵌入式GPU的Transformer、SSM及混合模型的性能，特别聚焦于边缘计算平台上的表现。结论显示，状态空间模型不仅在长上下文推断上可行，能在更长的序列长度上表现出显著优势；研究表明为优化边缘计算设备，重要的是关注SSM内核的设计和实现。同时，开源的性能表征框架将为更深入的研究提供有力支持。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12305", "html_url": "https://arxiv.org/abs/2507.12305", "title": "PROL : 在流式数据中无需复习的即时提示持续学习", "title_en": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "authors": "M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk", "background": "在线连续学习(OCL)中的数据隐私约束使得在数据只能被观察一次的情况下，灾难性遗忘问题在流式数据中变得更加复杂。当前SOTA方法通常使用先前类别的记忆节约型示例或特征在当前任务中重演，这在数据开放政策限制下可能不具实用性。另一方面，基于提示的方法在连续学习中表现出色，但随之而来的是可训练参数数量的不断增加，这会与流式数据相关的处理速度问题相关联。", "innovation": "本文提出了一种新颖的基于提示的在线连续学习方法，包括四个主要组件：(1) 一个轻量级的提示生成器作为通用知识，(2) 可训练的缩放-移位器作为特定知识，(3) 预训练模型（PTM）泛化的保留，(4) 硬性-软性更新机制。该方法在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上的性能显著高于当前SOTA方法，且复杂性分析显示，该方法所需的参数较少，且具有适中的训练时间、推理时间和吞吐量。", "conclusion": "我们的方法在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上达到了显著更高的性能，复杂性分析显示，我们的方法需要较少的参数，并且实现了适度的训练时间、推理时间和吞吐量。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12427", "html_url": "https://arxiv.org/abs/2507.12427", "title": "基于多级特征表示的单元级组织病理学组织分割", "title_en": "Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation", "authors": "Ashkan Shakarami,Azade Farshad,Yousef Yeganeh,Lorenzo Nicole,Peter Schuffler,Stefano Ghidoni,Nassir Navab", "background": "在组织病理学中，传统的像素级分割方法需要大量的人工标注工作，并且在计算效率上存在局限性，这限制了其在临床任务中的应用。", "innovation": "提出了一种基于单元的组织分割框架UTS，将每个固定的32*32像素块作为分割的基本单元，而非单独处理每个像素。引入了一种多级视觉变换器（L-ViT），它在多级特征表示中捕捉细粒度形态和全局组织上下文。", "conclusion": "UTS在分割乳腺组织（浸润肿瘤、非肿瘤性间质、脂肪）为三个类别时表现出色，并通过评估459个苏木精和伊红（H&E）染色区域中的386,371个像素块证明了其性能优于U-Net变体和基于变压器的基线方法。代码和数据集将发布在GitHub上。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.07003", "html_url": "https://arxiv.org/abs/2312.07003", "title": "RACER: 智能自动驾驶跟随模型现实增强版", "title_en": "RACER: Rational Artificial Intelligence Car-following-model Enhanced by Reality", "authors": "Tianyi Li,Alexander Halatsis,Raphael Stern", "background": "目前有多种传统的车跟随模型，如最优速度相对速度模型(OVRV)、车跟随神经网络(NN)和物理信息神经网络(PINN)，这些模型在预测适配巡航控制(ACC)行为时存在一些问题，比如未能完美地遵循实际驾驶中至关重要的理性驾驶约束(RDCs)，导致预测结果不够准确和现实。", "innovation": "RACER是一种结合了理性驾驶约束并采用深度学习方法的新型车跟随模型。它成功地解决了部分导数约束，并能够准确预测ACC驾驶行为。RACER特别之处在于它有效整合了RDCs，这些是实际驾驶中不可或缺的原则，从而使其预测结果更加精确和现实。RACER在加速度、速度和间距等关键指标上优于其他传统模型，特别是在遵守RDCs方面，RACER没有出现任何违反行为。", "conclusion": "本研究强调了将物理约束纳入AI模型的重要性，特别是在提高交通安全性方面。RACER的成功展示了在模型中整合物理约束的价值，并为未来的研究提供了一个范例，即使用真实驾驶数据测试这些模型，从而引导更安全和更理性的驾驶行为。此外，RACER的灵活性和广泛的应用潜力使其在科学界具有较高的吸引力和影响力。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12461", "html_url": "https://arxiv.org/abs/2507.12461", "title": "从胸部X光诊断中的眼球运动解释放射科医生的意图", "title_en": "Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis", "authors": "Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le", "background": "放射科医生在解读医疗图像时依赖眼球运动。一个训练有素的放射科医生会在查看图像时使用注视遵循一个心理检查清单，以找到潜在的疾病。现有的模型未能捕捉到每一次注视背后的意图。", "innovation": "本文提出了一种基于深度学习的方法——RadGazeIntent，旨在模拟该行为：具有找到某些东西的意图，并主动寻找它们。该变压器架构处理注视数据的时间和空间维度，将细粒度的注视特征转化为粗粒度、有意义的诊断意图表示，以解释放射科医生的目标。通过处理现有的医疗眼动跟踪数据集，创建了三个标记意图的子集：RadSeq（系统序列搜索）、RadExplore（不确定性的探索）和RadHybrid（混合模式）。实验证明RadGazeIntent能够预测放射科医生在特定时刻检查哪些发现，优于基线方法，在所有标记意图的数据集上均表现出色。", "conclusion": "RadGazeIntent方法通过捕捉放射科医生多样化的意图驱动行为，提升了在胸部X光诊断中对放射科医生意图的理解，并且其性能优于现有的基线方法。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12428", "html_url": "https://arxiv.org/abs/2507.12428", "title": "在模型完成思考前能否预测对齐？走向监控偏差推理模型", "title_en": "Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models", "authors": "Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach", "background": "开放权重推理语言模型在生成最终回答之前会产生较长的推理链（CoTs），这可以提高性能但同时引入新的对齐风险，有害内容可能会出现在推理链和最终输出中。本研究旨在探究是否可以利用推理链预测最终回答的对齐问题。", "innovation": "研究发现，通过CoT激活训练的简单线性探针在预测最终回答是否安全方面显著优于基于文本的方法。模型潜在状态（即CoT激活）提供更可靠的预测信号，即使应用到推理链的早期部分也能做出准确预测，并且结果在不同模型规模、家族和安全标准下均有效。", "conclusion": "这项研究表明，轻量级探针可能能够实现实时安全监控和生成过程中的早期干预，从而帮助监控和防止偏差推理模型的输出问题。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.14995", "html_url": "https://arxiv.org/abs/2411.14995", "title": "仅从操作踪迹学习提升的STRIPS模型：一种简单、通用且可扩展的解决方案", "title_en": "Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General, and Scalable Solution", "authors": "Jonas Gösgens,Niklas Jansen,Hector Geffner", "background": "从操作踪迹学习STRIPS操作模型是一个具有挑战性的问题，因为这涉及学习领域谓词。该工作基于已知的LOCM系统可扩展，但类似SAT方法，该方法具有有效性和完备性。此外，该方法对隐藏领域或谓词的数量和元数没有限制。", "innovation": "提出了一种新颖的方法，该方法通过一种高效的、新颖的测试判断某个谓词是否被一组特定动作模式影响，该测试检查这种假设是否与踪迹一致。通过这种方法验证的模型能够处理包含数十万状态和转换的标准经典领域如8- puzzle.", "conclusion": "该方法不仅从理论上进行了研究，还在实验上进行了评估。方法在大型实例上进行了验证，证明了学习表示的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.08802", "html_url": "https://arxiv.org/abs/2403.08802", "title": "公司中生成式人工智能的治理", "title_en": "Governance of Generative Artificial Intelligence for Companies", "authors": "Johannes Schneider,Pauline Kuss,Rene Abraham,Christian Meske", "background": "生成式人工智能（GenAI）尤其是大型语言模型（LLMs）如ChatGPT，未经充分治理就迅速进入了组织，带来了机遇与风险。尽管关于GenAI的变革性质和监管措施进行了广泛讨论，但现有研究较少关注组织层面的治理问题，涵盖技术和商业视角。尽管存在多种人工智能治理框架，但对于GenAI的具体适用性尚不明确。本研究旨在填补这一空白，通过对近期相关作品的综述，更好地理解GenAI的基本特性，并针对公司内的GenAI治理进行框架调整。", "innovation": "本文扩展了Nickerson的框架开发流程，纳入先前的概念化，提出了一种适合公司内部GenAI治理的综合框架。该框架明确了GenAI治理的范围、目标和机制，旨在利用GenAI带来的商业机会并降低其潜在风险。此外，研究还提供了一个专注且实用的方法论，帮助公司在应对GenAI采纳的挑战时获得具体指导，并指出研究空白。", "conclusion": "本文为GenAI治理提供了一个聚焦且实用的方法论，能够帮助公司更好地理解和应对GenAI的挑战与机遇。研究还指出了GenAI治理领域的若干研究空白，为未来的研究提供了方向。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12443", "html_url": "https://arxiv.org/abs/2507.12443", "title": "LLM-Based 配置合成需要澄清", "title_en": "LLM-Based Config Synthesis requires Disambiguation", "authors": "Rajdeep Mondal,Nikolaj Bjorner,Todd Millstein,Alan Tang,George Varghese", "background": "在使用大语言模型（LLM）进行程序合成时，除了幻觉问题外，另一个问题是用户意图的不确定性。在基于LLM的增量配置合成场景中，特别是在路由表和ACLs（访问控制列表）的合成过程中，这些结构在头部空间中经常重叠，使得LLM很难推断出动作的相对优先级，因此需要用户交互。大规模云环境中的测量结果表明，存在包含数百个重叠的复杂ACL，表明这一问题是实际存在的。", "innovation": "该论文提出了一种名为Clarify的原型系统，它在LLM中增加了一个新的模块——去混淆器，以帮助澄清用户意图。在一项小型合成工作负载测试中，Clarify能够进行增量策略合成，并在去混淆后验证策略。此外，这个处理方式还适用于更广泛的情况，在这些情况下，更新的意图可以由LLM正确合成，但其集成可能具有模糊性并可能导致不同的全局行为。", "conclusion": "论文通过提供Clarify系统，证明通过增强LLM来澄清用户意图是解决程序合成的混淆问题的一种有效方法，并强调了这种方法在其他需要明确用户意图的合成任务中的适用性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.00226", "html_url": "https://arxiv.org/abs/2501.00226", "title": "生成 emergent 通信：大规模语言模型是集体世界模型", "title_en": "Generative Emergent Communication: Large Language Model is a Collective World Model", "authors": "Tadahiro Taniguchi,Ryo Ueda,Tomoaki Nakamura,Masahiro Suzuki,Akira Taniguchi", "background": "大规模语言模型（LLMs）展现了强大的世界知识获取能力，然而这种能力的获取并未依赖直接的感官和运动经验，这引发了科学界的持续探索。本文提出了集体世界模型假设，即LLMs不是从零开始学习世界模型，而是通过社会过程中的共有的、互动的感知和理解，学习到一个隐含于人类语言中的统计近似世界模型。为了说明这一过程，文中引入了生成新兴通信（Generative EmCom）框架，该框架基于集体预测编码，并将其视为多层次代理的去中心化贝叶斯推理过程。此框架能够解释语言是如何作为社会共同编码的内部表示结构重新构建的，进而为LLMs的能力获取提供了一种原理性、数学性的解释。", "innovation": "论文的主要创新在于：1）正式化生成新兴通信（Generative EmCom）框架，明确了其与世界模型和多智能体强化学习的联系；2）应用该框架来解释LLMs现象，如分布语义可以自然地视为表示重构的结果。这项工作提供了一种统一的理论，促进了个体认知发展、群体语言进化与大规模AI基础之间的联系", "conclusion": "本文提出了一种新框架和理论，旨在解决LLMs如何在没有直接感官经验的情况下学习世界知识的问题。通过这种方法，文章提供了一个关于LLMs如何构建其能力的原理性解释，并且指出这种理论能够帮助我们更好地理解规模化的人工智能与人类社会之间的关系。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15873", "html_url": "https://arxiv.org/abs/2502.15873", "title": "AI成本和计算核算的实用原则", "title_en": "Practical Principles for AI Cost and Compute Accounting", "authors": "Stephen Casper,Luke Bailey,Tim Schreier", "background": "政策制定者越来越多地使用AI的成本和发展计算量作为AI能力和风险的代理指标。最近的法律法规引入了依赖于特定阈值的监管要求。然而，如何进行这些核算的技术模糊性导致了一些漏洞，这可能削弱监管的有效性。已有的一些核算标准在实践应用中暴露出问题，需要新的原则来改进当前的实践。", "innovation": "本文提出了七项关于设计AI成本和计算核算标准的原则，这些建议旨在减少战略误导的机会，避免对负责任的风险缓解措施进行惩罚，并促进公司在不同司法管辖区的一致实施。这些原则的具体内容包括设计标准时需注重透明度和一致性，明确定义阈值，避免复杂的技术细节，防止过度溯源，以及易于理解和实施。这些原则为未来更准确和有效的AI监管提供了指导。", "conclusion": "本文提出了一个详细的框架，以提高AI成本和计算标准的准确性和可靠性，以帮助政策制定者更好地监管AI技术的发展和应用，确保AI技术能够安全、负责任地发展。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12318", "html_url": "https://arxiv.org/abs/2507.12318", "title": "基于组合离散潜在码的高保真、高效扩散模型", "title_en": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models", "authors": "Samuel Lavoie,Michael Noukhovitch,Aaron Courville", "background": "本文认为扩散模型在建模复杂分布方面取得的成功大部分归因于它们的输入条件。本文从理想表示应提高样本保真度、易于生成和具有组合性以允许生成训练外样本的角度，研究了扩散模型所使用的表示方法。", "innovation": "本文引入了一种名为离散潜在码（DLC）的图像表示，其来源于使用自我监督学习目标训练的单纯形嵌入。DLC是一种序列形式的离散标记，区别于标准的连续图像嵌入。DLC易于生成，且其组合性使生成器能够生成超出训练分布的新颖图像。使用DLC训练的生成模型提高了无条件图像生成的保真度，设定了ImageNet上无条件图像生成的新标准。同时，通过组合DLC，生成器能够以连贯的方式结合来自多种图像的语义，产生分布外的样本。此外，本文展示了DLC如何通过利用大规模预训练语言模型实现文本到图像的生成。", "conclusion": "本文通过引入离散潜在码（DLC），展示了如何优化扩散模型以提高生成保真度并生成分布外样本。DLC还为文本到图像生成提供了新方法。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2011.10672", "html_url": "https://arxiv.org/abs/2011.10672", "title": "企业人工智能治理", "title_en": "Artificial Intelligence Governance for Businesses", "authors": "Johannes Schneider,Rene Abraham,Christian Meske,Jan vom Brocke", "background": "人工智能治理旨在通过有效利用数据和减少与人工智能相关的成本和风险来监管人工智能的行使权力和控制。尽管人工智能治理、人工智能伦理等议题在此前的理论、哲学、社会学和法规层面进行了充分讨论，但对于公司的具体治理措施仍然较为匮乏。", "innovation": "本文提出了一种概念框架，将人工智能治理分解为数据治理、机器学习模型治理和人工智能系统治理四个方面，该框架结合了人工智能及相关领域的现有文献，并与现有的信息技术和数据治理框架和实践相关联，为企业和学术界提供了实施人工智能治理的参考。", "conclusion": "该框架可以通过总结主要的研究论文、实践出版物以及监管机构的出版物为企业提供实施人工智能治理的起点。对于学术界来说，该论文指出了人工智能治理中的几个重要领域需要更多关注。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.01349", "html_url": "https://arxiv.org/abs/2410.01349", "title": "生命，呃，总能找到路：基于行为搜索的超适应性", "title_en": "Life, uh, Finds a Way: Hyperadaptability by Behavioral Search", "authors": "Alex Baranski,Jun Tani", "background": "生物能够在罕见或仅遇到一次的问题中找到解决办法，无需大量重复经验，而是通过随机应变的方式找到解决方案。这种总是能找到可解决物理问题的解决方案的能力被称为超适应性。", "innovation": "提出了一种将行为视为自修改搜索过程的物理表现的理论框架。该系统通过动态有序的行为序列（根据简单性和效果）实现鲁棒问题解决。应用Hebbian学习和一种新型谐波脑表示来实现认知图，支持灵活的信息存储。通过模拟实验证明，此方法能够在复杂迷宫中快速实现高度鲁棒的导航能力，并在经典强化学习问题的困难延伸中获得高奖励。", "conclusion": "该框架为发育性学习提供了一个新的理论模型，并为能够自主掌握复杂技能和应对特殊情况的机器人铺平了道路。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12451", "html_url": "https://arxiv.org/abs/2507.12451", "title": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling", "title_en": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling", "authors": "Suman Adhya,Debarshi Kumar Sanyal", "background": "在高维文本数据中，使用超球面空间中的潜在表示建模已被证明有效，用于捕捉方向相似性，有益于主题建模。变分自编码器基于神经主题模型（VAE-NTMs）通常采用von Mises-Fisher先验来编码超球面结构。然而，VAE-NTMs经常遭受后验塌陷的问题，即目标函数中的KL散度项大幅降低，导致无效的潜在表示。", "innovation": "提出了S2WTM（Spherical Sliced Wasserstein Autoencoder for Topic Modeling）来解决这一问题并建模潜在空间中的超球面结构。S2WTM利用单位超球面上的支持先验分布，并利用球面裁剪Wasserstein距离来对齐聚合的后验分布与先验。", "conclusion": "实验结果显示，S2WTM在生成更加一致和多样的主题同时，在下游任务上表现出更好的性能，优于最新的主题模型。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12425", "html_url": "https://arxiv.org/abs/2507.12425", "title": "推进结构化企业和内部数据的检索增强生成", "title_en": "Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data", "authors": "Chandana Cheerla", "background": "越来越多的组织依赖于专有企业数据，例如人力资源记录、结构化报告和表格文件，进行关键决策。虽然大型语言模型具有强大的生成能力，但它们受限于静态预训练、短的上下文窗口以及在处理异构数据格式方面面临的挑战。传统的检索增强生成（RAG）框架在一定程度上解决了这些问题，但通常在处理结构化和半结构化数据时遇到困难。", "innovation": "该研究提出了一种高级RAG框架，结合了使用密集嵌入（all-mpnet-base-v2）和BM25的混合检索策略，并通过SpaCy NER和交叉编码器重新排序进行元数据感知筛选。该框架应用语义分块以保持文本连贯性，并保留表格数据结构以保持行列完整性。量化索引优化了检索效率，而人类在环路反馈和对话记忆提高了适应性。", "conclusion": "实验结果显示，该框架在企业数据集上的表现有所提升：5个结果的精度提高了15％（从75％提高到90％），召回率提高了13％（从74％提高到87％），平均倒数排名提高了16％（从0.69提高到0.85）。定性评估显示，在五点李克特量表上，可信度、完整性和相关性得分更高（分别为4.6、4.2和4.5，而对照组分别为3.0、2.5和3.2），这些结果证明了该框架在执行企业任务时提供准确且上下文相关响应的有效性。未来工作包括将其扩展到多模态数据并将基于代理的检索整合进来。源代码将在https://github.com/delta-rag/delta-rag上发布。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.09037", "html_url": "https://arxiv.org/abs/2504.09037", "title": "LLM推理前沿综述：推理缩放、学习推理与代理系统", "title_en": "A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems", "authors": "Zixuan Ke,Fangkai Jiao,Yifei Ming,Xuan-Phi Nguyen,Austin Xu,Do Xuan Long,Minzhi Li,Chengwei Qin,Peifeng Wang,Silvio Savarese,Caiming Xiong,Shafiq Joty", "background": "推理作为一种基本的认知过程，能够促进逻辑推理、问题解决和决策制定。随着大型语言模型(LLMs)的迅速发展，推理已成为区分先进AI系统和传统模型的关键能力，而后者则支持聊天机器人。本文通过将现有的方法分类为两个相互正交的维度：(1) 回归期，定义推理是在推理时间实现还是通过专门训练来实现；(2) 建筑方法，这也决定了推理过程中参与的组件，区分为单独的LLM和引入外部工具并采用多代理协作的代理复合系统。在每个维度中，本文分析了两个关键视角：(1) 输入级别，重点是那些构建高质量提示的技术，这些提示是LLM建立条件的基础；(2) 输出级别，综述了那些通过细化多个样本候选来提高推理质量的方法。这项分类为不断发展的LLM推理景观提供了一种系统化的理解，突出了新兴趋势，例如从推理缩放转向学习推理（如DeepSeek-R1）的转变，以及从监督调整到代理工作流程（如OpenAI Deep Research、Manus Agent）的发展。此外，本文还涵盖了从监督微调到奖励学习的广泛学习算法，如PPO和GRPO，以及推理者和验证者的训练。我们还分析了代理工作流程的关键设计，从已有的生成器-评估者模式和LLM辩论到最近的创新。", "innovation": "本文创新之处在于对当前LLM推理领域的系统性分类和分析，突出现有方法在推理缩放向学习推理转变以及从传统代理模式向代理系统的工作流程的转变。文中通过两个维度（回归期和建筑方法）和两个关键视角（输入级别和输出级别），全面梳理了现有研究，指出了未来的研究趋势和发展方向。这对于理解并设计未来高级AI系统的推理能力尤为关键。", "conclusion": "本文综述了大型语言模型推理方法的最新进展，包括推理缩放、学习推理和代理系统等前沿方向，为未来研究提供了系统的分类和分析框架，展示了相关技术的发展趋势，对进一步推动推理能力的研究具有重要意义。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00785", "html_url": "https://arxiv.org/abs/2506.00785", "title": "GeoChain：多模态链式推理在地理推理中的应用", "title_en": "GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning", "authors": "Sahiti Yerramilli,Nilay Pande,Rynaa Grover,Jayant Sravan Tamarapalli", "background": "当前，多模态大型语言模型（MLLMs）在地理推理方面表现出的挑战性问题包括视觉锚定的不足、推理的不稳定性以及难以实现精确定位等。为了更好地评估这些模型在逐步地理推理中的性能，研究人员开发了GeoChain这一大规模基准测试，通过使用146万张Mapillary街道级图像及其对应的21步链式思维问题序列（包含超过3000万的问答对），涵盖了视觉、空间、文化及精确地理位置等四个推理类别，且每个序列都标注了难度等级。此外，这些图像还得到了语义分割（150个类别）和视觉可定位评分的增强。这一基准测试有助于揭示MLLMs在复杂地理推理中的问题所在，推动相关领域的持续进步和显著改进。", "innovation": "GeoChain通过利用146万张Mapillary街道级图像，构建了一个大规模的基准测试，每个图像都配有一个涵盖21步链式思维问题序列，总共有超过3000万的问答对，覆盖了视觉、空间、文化及精确地理位置等四个推理类别，并根据难度进行了标注。此外，图像还得到语义分割（150个类别）和视觉可定位评分的增强。这项基准测试能够帮助高级地理推理诊断，促进MLLMs在复杂地理推理方面的显著进步和改进。", "conclusion": "通过对当代MLLMs（GPT-4.1变体、Claude 3.7、Gemini 2.5变体）在多样化的2088张图像子集上的基准测试，揭示了这些模型在逐步地理推理中普遍存在的挑战：它们经常会表现出视觉锚定的不足、推理的不稳定性及难以实现准确的定位，尤其是当推理复杂性增加时。GeoChain提供了一种稳健的诊断方法，对于促进MLLMs在复杂地理推理方面的进步至关重要。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09850", "html_url": "https://arxiv.org/abs/2507.09850", "title": "在没有RL或蒸馏的情况下教授LLMs推理的挑战", "title_en": "The Challenge of Teaching Reasoning to LLMs Without RL or Distillation", "authors": "Wei Du,Branislav Kisacanin,George Armstrong,Shubham Toshniwal,Ivan Moshkov,Alexan Ayrapetyan,Sadegh Mahdavi,Dan Zhao,Shizhe Diao,Dragan Masulovic,Marius Stanean,Advaith Avadhanam,Max Wang,Ashmit Dutta,Shitij Govil,Sri Yanamandara,Mihir Tandon,Sriram Ananthakrishnan,Vedant Rathi,David Zhang,Joonseok Kang,Leon Luo,Titu Andreescu,Boris Ginsburg,Igor Gitman", "background": "具备推理能力的语言模型通过生成详细的推理过程（链式思考）在多样复杂的任务中取得了最先进的性能。先前的研究表明，基本模型可以通过强化学习或来自更强模型（如DeepSeek-R1）的蒸馏获取这样的推理过程，甚至短的推理提示也能在不微调的情况下提高推理能力。然而，尚未确定是否可以仅通过提示或轻微的调优诱导基本模型生成长的推理过程。", "innovation": "该研究仅通过20个模型QwQ-32B-Preview的长推理例子轻度微调了基模型Qwen2.5-32B，结果表明少量高质量的例子能够解锁强大的推理能力。进一步探索了来自非推理模型和人类注释者的推理数据，并通过提示工程、多轮编辑和结构指导进行增强，虽然效果不如推理模型的数据，但仍提供了有效推理监督的见解。此外，研究还分析了影响推理蒸馏的关键属性。", "conclusion": "虽然仍然存在挑战，但精心策划的人工撰写的推理数据即使数量有限，也能够激活基模型中的推理行为。作者还发布了其人工撰写的推理数据集，并邀请进一步研究这种小规模推理监督的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.04632", "html_url": "https://arxiv.org/abs/2507.04632", "title": "加速推理模型的RL微调能否在线预测提示难度？", "title_en": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?", "authors": "Yun Qu,Qi Cheems Wang,Yixiu Mao,Vincent Tao Hu,Xiangyang Ji", "background": "最近的研究表明，强化学习（RL）微调能够提高大型语言模型（LLMs）的推理能力。优化过程需要多次迭代以达到满意的性能，这导致了较高的计算成本，因为频繁的LLM交互和策略更新需要多次提示评估。现有的在线提示选择方法通过优先选择具有信息性的提示来减少迭代步骤，但整个管线仍依赖于耗费资源的LLM推断调用，进行广泛的提示评估和子集选择以进行优化。", "innovation": "本文研究了一种迭代近似评估任何提示的方法，并提出了Model Predictive Prompt Selection（MoPPS）框架。MoPPS利用贝叶斯风险预测方法，在不需要昂贵的LLM交互的情况下在线估计提示难度。技术上，MoPPS将每个提示的成功率作为潜在变量，采用流式贝叶斯推理，并在构建的多臂老虎机中使用后验采样进行提示选择，从而实现高效且适应性更强的提示选择。", "conclusion": "广泛的任务实验表明，MoPPS能够可靠地预测提示难度，并在显著减少LLM推断试验的情况下加速训练。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04135", "html_url": "https://arxiv.org/abs/2506.04135", "title": "macOSWorld: 一种多语言互动基准测试，用于GUI代理", "title_en": "macOSWorld: A Multilingual Interactive Benchmark for GUI Agents", "authors": "Pei Yang,Hai Ci,Mike Zheng Shou", "background": "GUI代理在自动化计算机使用任务和提高访问性方面显示出潜力，但现有的互动基准测试主要以英语进行，仅涵盖网页使用和Windows、Linux和Android环境，而未涉及macOS。macOS作为主要的操作系统，具有独特的GUI模式和专属应用程序。", "innovation": "我们提出了macOSWorld，这是首款针对macOS评估GUI代理的全面基准测试。它包含202个跨30个应用程序（其中28个是macOS专属）的多语言互动任务，任务说明和操作系统界面提供5种语言（英语、中文、阿拉伯语、日语、俄语）。该基准测试还包括一个专门的安全基准测试子集，用于抵御欺骗攻击。研究发现，专有的计算机使用代理成功率超过30%，而开源轻量级研究模型则低于5%，表明需要macOS领域的适应性改进。", "conclusion": "多语言基准测试揭示了普遍存在的弱点，尤其是在阿拉伯语中，平均降低了28.8%。安全基准测试结果表明，欺骗攻击更具普遍性和紧迫性，需要立即关注。macOSWorld可供下载。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.06771", "html_url": "https://arxiv.org/abs/2412.06771", "title": "在不确定性下的多轮文本到图像生成的主动代理", "title_en": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty", "authors": "Meera Hahn,Wenjun Zeng,Nithish Kannen,Rich Galt,Kartikeya Badola,Been Kim,Zi Wang", "background": "用户对生成AI模型的指令经常不明确，这种不明确性导致了用户意图与模型理解之间的不对齐，用户不得不反复细化指令。本文研究了这种对齐问题在文本到图像生成（T2I）中的具体表现。", "innovation": "提出了用于主动T2I代理的原型，该原型具有两种功能：在不确定时主动询问澄清问题，并将对用户意图的不确定性展示为可理解和编辑的信念图。提出了一个基于两个代理的新型可扩展和自动化评估方法，其中一个代理具有明确意图（图像），另一个努力问最少的问题以实现与该意图的对齐。", "conclusion": "实验表明，所提出的T2I代理能提出更具信息性的问题，从而获得至少2倍更高的VQAScore。人类研究进一步证明了这些代理及其信念图在T2I工作流程中的有效性。代码和DesignBench可在指定链接处找到。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05297", "html_url": "https://arxiv.org/abs/2507.05297", "title": "连续分类聚合", "title_en": "Continuous Classification Aggregation", "authors": "Zijun Meng", "background": "该研究基于模糊分类聚合的理论背景，探讨了连续属性下的多对象分类聚合函数。研究的主要背景在于如何有效地聚合多个个体对多个对象的分类结果，特别是在模糊逻辑和多值逻辑框架下的分类问题。", "innovation": "本文的创新之处在于证明了对于具有连续属性的多对象分类问题，任何最优、独立且一致的模糊分类聚合函数必须是加权算术平均。此外，还对对象和类型数目均为2的情况进行了具体刻画。", "conclusion": "研究证明，在连续属性下的最优独立零统一模糊分类聚合函数必须是加权算术平均。并且对于特定情况 m=p=2，提供了明确的特征描述。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.08140", "html_url": "https://arxiv.org/abs/2505.08140", "title": "信息流失：LLMs为何在全球推理中失败", "title_en": "Lost in Transmission: When and Why LLMs Fail to Reason Globally", "authors": "Tobias Schnabel,Kiran Tomlinson,Adith Swaminathan,Jennifer Neville", "background": "尽管基于Transformer的大语言模型（LLMs）在许多任务中取得了成功，但在需要对大量输入进行复杂推理的任务中仍然表现不佳。研究者认为这些失败是由于LLMs内部信息准确流动能力有限导致的。为了阐述这个问题，作者引入了一种新的计算框架，称为有界注意力前缀先知（BAPO）模型，该模型模拟了LLMs中注意力头内部通信带宽的限制。", "innovation": "提出了一种新的计算框架BAPO，用于模拟LLMs中注意力头的通信带宽限制，证明了一些重要的推理问题，如图的连通性问题，需要大量的通信带宽才能解决，称这些问题是BAPO-hard。通过实验证明，GPT-4o、Claude和Gemini在BAPO简单的任务上成功，但在相对较小的BAPO困难的任务中甚至会失败。BAPO还揭示了多步骤思考（CoT）的另一个好处：证明通过使用CoT可以将任何BAPO-hard问题转化为BAPO-easy问题。", "conclusion": "实验结果验证了理论预测，展示了合理的解释LLMs的关键失败，并提出了解决方案和推理方法，以减轻带宽限制的影响。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2302.00646", "html_url": "https://arxiv.org/abs/2302.00646", "title": "EPIC-SOUNDS：具有声音的动作的大规模数据集", "title_en": "Epic-Sounds: A Large-scale Dataset of Actions That Sound", "authors": "Jaesung Huh,Jacob Chalk,Evangelos Kazakos,Dima Damen,Andrew Zisserman", "background": "本文介绍了EPIC-SOUNDS，这是一个大规模的音频标注数据集，捕捉了单人视角视频中声响的时间段和类别标签。该数据集为研究单人视角视频中的声音提供了基础，有助于开发和评估针对声音信息进行事件检测和识别的最先进的音频和视听模型。同时，文中探讨了时间重叠问题、模态的时序和标签相关性、单声音信息标注材料的模糊性、声学标签的重要性以及当前模型处理声音类动作的局限性，提供了研究声音在多模态视觉理解中的作用的重要参考。", "innovation": "文中提出了一种标注流水线，通过对自由形式的音频描述进行分组分类，找出可完全通过声音区分的动作；特别地，对于涉及物体碰撞的动作，收集了人类对这些物体材料的注释，并通过视频进行了验证。这为单人视角视频中声音和物体材料关系的理解提供了重要的数据支持。作者还训练和评估了最新的音频识别和检测模型，以增强对声音信息的理解和应用。", "conclusion": "EPIC-SOUNDS数据集包含了78,400个已分类的声音事件和动作片段，涵盖了44个类别，以及39,200个未分类的片段。通过在该数据集上训练和评估最先进的音频和视听方法，研究成果表明了通过声音理解单人视角视频中的动作的可能性和挑战。这也揭示了当前模型在处理基于声音理解动作上的局限性，并指出了未来研究的方向。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.20360", "html_url": "https://arxiv.org/abs/2310.20360", "title": "数学视角下的深度学习导论：方法、实现与理论", "title_en": "Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory", "authors": "Arnulf Jentzen,Benno Kuckuck,Philippe von Wurstemberger", "background": "本书旨在为那些完全没有深度学习背景的学生和科学家提供一个介绍深度学习算法的学习材料。涵盖的内容包括不同的人工神经网络（ANN）架构和优化算法以及深度学习算法的一些理论方面。", "innovation": "详细介绍不同的人工神经网络架构，如全连接前馈神经网络、卷积神经网络、循环神经网络、残差神经网络和批量归一化神经网络。同时，还涵盖了优化理论和泛化误差等理论方面的内容。", "conclusion": "书的最后部分介绍了用于偏微分方程（PDEs）的深度学习近似方法，包括物理编入神经网络（PINNs）和深度Galerkin方法。希望这本书能够对那些希望深入了解和掌握深度学习中的对象和方法的理论框架的学生和实践者有所帮助。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.11212", "html_url": "https://arxiv.org/abs/2401.11212", "title": "eXchange Calculus 中分布式集体过程的编程", "title_en": "Programming Distributed Collective Processes in the eXchange Calculus", "authors": "Giorgio Audrito,Roberto Casadei,Ferruccio Damiani,Gianluca Torta,Mirko Viroli", "background": "研究领域正朝着物联网(IoT)的愿景发展，在各个环境中广泛部署多样化和多层次的计算设备。这带来了如何设计和编程这些系统中的集体行为的工程挑战，特别是集体任务的执行和交互。具体来说，需要能够捕捉和定义动态协作设备组(即，ensemble)和联合活动（即，集体任务）的概念的抽象方法。已有研究集中在开发合适的编程抽象来解决这个问题，但还不够成熟，研究仍需深入探索高效的解决方案。本文提供了一种前进方向，即分布式集体过程的抽象，并基于邻近值(eXchange Calculus)构建了一种新型语言作为支持。这项工作强调了互联计算过程的独特价值及其不同分布式计算应用领域的潜在用途。", "innovation": "本文引入了分布式集体过程的抽象设计，基于邻近值设计了eXchange Calculus (XC)核心函数语言，并通过单个exchange原语管理状态和交互。该设计允许编程集体行为的同时定义集体逻辑和任务，还通过解决两个案例研究来证明其有效性。这为分布计算场景带来了新的编程方法，具有理论和实际价值。", "conclusion": "本文提出了分散集体过程的抽象，并在eXchange Calculus (XC)中开发了一种功能性语言以支持其实现。通过两个案例研究展示了其在多跳消息传播和分布式空间属性监测中的应用效果。通过这种方式，我们证实了该抽象能够有效地促进分布式系统的集体协作编程。该语言及抽象的未来方向应该能推动更复杂的分布式应用开发并提高这些系统的设计灵活性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.08788", "html_url": "https://arxiv.org/abs/2406.08788", "title": "理解在分布转移下链接预测器的泛化能力", "title_en": "Towards Understanding Link Predictor Generalizability Under Distribution Shifts", "authors": "Jay Revolinsky,Harry Shomer,Jiliang Tang", "background": "当前最先进的链接预测(LP)模型在基准测试中表现出色。然而，流行的基准数据集通常假设训练、验证和测试样本代表整体数据分布。在实际情况下，这一假设常常不准确；未控制的因素使得新数据集样本来自与训练样本不同的分布。研究大多数关注图数据集的变化对节点和图级别任务的影响，对链接级任务的影响却较少关注。", "innovation": "我们提出了一种新颖的划分策略，称为LPShift，它利用结构属性来诱导可控的分布转移。我们通过在16个LPShift变体的数据集划分上对SOTA LP模型进行经验性评估，验证了LPShift的效果，结果表明模型性能发生了显著变化。此外，实验还展示了图结构对当前泛化方法成功的影响显著。", "conclusion": "我们的研究结果显示，结构属性可以有效诱导可控的分布转移，从而显著影响模型性能。这表明图结构对现有泛化方法的成功有重要影响。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.09158", "html_url": "https://arxiv.org/abs/2404.09158", "title": "StreakNet-Arch: 一种基于抗散射网络的水上载货LiDAR-Radar成像架构", "title_en": "StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging", "authors": "Xuelong Li,Hongjun An,Haofei Zhao,Guangying Li,Bo Liu,Xing Wang,Guanghua Cheng,Guojun Wu,Zhe Sun", "background": "传统方法识别和分类水下点云时存在性能瓶颈，尤其是在散射抑制方面。为了提高实时性能和准确度，研究人员提出了StreakNet-Arch，这是一种基于自主研发的水下运载LiDAR-Radar (UCLR) 的端到端二分类框架，该框架包括Self-Attention和双分支交叉注意机制(DBC-Attention)，旨在提高散射抑制效果，并在实际应用中取得了优于传统滤波方法和学习基于的网络模型的表现。实验数据和代码已经对外开放，旨在推动水下成像技术的进步和发展.", "innovation": "开发了一种集成了Self-Attention和双分支交叉注意机制(DBC-Attention)的StreakNet-Arch框架，用于实时水下运载LiDAR-Radar成像。验证结果显示，StreakNet-Arch在散射抑制和3D点云分类中具有显著优势，特别是在实时性方面表现出色，可以保持恒定的成像时间，而传统方法在处理帧数增加时成像时间线性增加。此外，该研究还提供了一个包含2,695,168个真实水下3D点云数据的公共数据集，以促进进一步的研究.", "conclusion": "StreakNet-Arch在水下运载LiDAR-Radar成像中表现出了显著的优越性，尤其是在抗散射能力上。该架构不仅提高了实时性能，而且还在3D目标分类方面超越了传统方法和学习驱动的网络模型。该研究为水下成像技术的进步和发展提供了有力支持，并在实际海上试验中得到了验证，展示了其在深海成像中的应用潜力。数据和源代码的公开也促进了该领域更多研究的发展。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.15801", "html_url": "https://arxiv.org/abs/2401.15801", "title": "生成模型在低内部数据维数统计属性中的统计性质", "title_en": "On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension", "authors": "Saptarshi Chakraborty,Peter L. Bartlett", "background": "尽管生成对抗网络（GANs）在实际应用中取得了显著的成果，但在统计准确度方面的理论保证仍然较为悲观。特别是，在高维特征空间中应用GANs的数据分布，如自然图像，通常假设有内在的低维结构，但这些低维结构在现有的最先进技术分析中通常未被反映。", "innovation": "本文通过从内在维度和潜在空间方面出发，推导出生成密度的统计保证。作者从理论上证明，如果拥有来自未知目标分布的n个样本，并且网络架构适当选择，生成网络和双向GAN（BiGANs）估计值从目标的预期Wasserstein-1距离可分别表示为O(n^(-1/d_μ))和~O(n^(-1/(d_μ+ℓ)))，其中d_μ和ℓ分别是数据分布和潜在空间的上Wasserstein-1维度。此外，该研究结果显示GANs甚至可以有效地达到非光滑基础分布下的最小最大最优速率，使用插值生成网络。", "conclusion": "本文的理论分析不仅表明了这些方法成功避免了维度灾难，即误差率的指数与数据维数无关，并且还弥合了GANs的理论分析与最优运输文献中已知的尖锐速率之间的差距。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.14628", "html_url": "https://arxiv.org/abs/2312.14628", "title": "跨整个AI产品生命周期分析联邦学习的可持续性", "title_en": "Holistic analysis on the sustainability of Federated Learning across AI product lifecycle", "authors": "Hongliu Cao", "background": "鉴于不断出现的法律法规和政策对隐私保护的要求，各行各业的公司开始倾向于采用联邦学习（FL）。联邦学习是一种分散式的办法，涉及多个客户端或孤岛，在中央服务器协调下联合训练一个全局模型，同时利用其本地的私有数据，而不必像传统方法那样需要数据分享和传输。尽管跨孤岛联邦学习（Cross-Silo FL）的应用正日益增长，其碳足迹问题仍未充分研究，因此存在的研究缺口使得对于整个AI产品生命周期内跨孤岛联邦学习的可持续性评估变得必要。", "innovation": "本文引入了一个系统化的比较方法，通过量化框架分析跨孤岛联邦学习和集中式学习在整个生命周期中的能耗和成本。创新点在于提出了一个集成跨孤岛联邦学习和数据分析的应用管理系统，以提高IT企业的可持续性和经济效率。", "conclusion": "研究结果表明，跨孤岛联邦学习和集中式学习在模型训练过程中的能耗和成本相似。然而，集中式学习由于额外的数据传输和存储需求可能导致更大的CO2排放。进一步，研究设计了一种新的数据和应用管理系统，希望实现跨孤岛联邦学习的可持续性和经济性优化。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.06138", "html_url": "https://arxiv.org/abs/2503.06138", "title": "System 0/1/2/3: 四过程理论用于多时间尺度具身集体认知系统", "title_en": "System 0/1/2/3: Quad-process theory for multi-timescale embodied collective cognitive systems", "authors": "Tadahiro Taniguchi,Yasushi Hirai,Masahiro Suzuki,Shingo Murata,Takato Horii,Kazutoshi Tanaka", "background": "本文介绍了系统0/1/2/3框架，作为双重过程理论的扩展，采用四过程认知模型。在此基础上，作者扩展了系统1（快速直观思考）和系统2（缓慢详尽思考）。进一步引入了系统0，代表了认知前的本体论过程，以及系统3，涵盖了集体智能和符号的形成。通过采用多尺度时间理论，将认知中的多样时间动态统一起来，将这一模型融入伯格森的哲学之中。", "innovation": "引入了系统0/1/3，扩展了传统的系统1/2理论；提出使用多尺度时间理论整合不同的认知时间动态；从构造主义视角解释系统1和2；提出集体预测编码来说明社会级别的适应和符号形成。", "conclusion": "提出的系统0/1/2/3框架涵盖了从快速具身反应到缓慢演变集体智能的范围，提供了一个在多个时间尺度、抽象水平和人类智能形式下统一的认知视角，从而为认知科学、人工智能、机器人技术以及集体智能领域打开了新的研究途径。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.00265", "html_url": "https://arxiv.org/abs/2411.00265", "title": "通过证据理论量化现代神经网络的校准误差", "title_en": "Quantifying calibration error in modern neural networks through evidence based theory", "authors": "Koffi Ismael Ouattara", "background": "神经网络在关键应用中的部署需要信任，其中可靠性和不确定性在决策过程中扮演重要角色。传统的性能指标如准确性和精确性无法捕捉这些方面，尤其是在模型表现出过高的信心时。", "innovation": "本文提出了一个新颖的框架，通过将主观逻辑引入期望校准误差（ECE）的评估中来量化神经网络的可信度。该方法通过聚类预测概率并使用合适的融合运算融合意见，提供了一个综合度量可信度、不信度和不确定性的指标。", "conclusion": "通过在MNIST和CIFAR-10数据集上的实验，该方法展示了改进的可信度。提出的框架提供了更可解释和细腻的AI模型评估，适用于医疗保健和自主系统等敏感领域。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.19704", "html_url": "https://arxiv.org/abs/2410.19704", "title": "多视图生物医学基础模型用于分子-靶点和性质预测", "title_en": "Multi-view biomedical foundation models for molecule-target and property prediction", "authors": "Parthasarathy Suryanarayanan,Yunguang Qiu,Shreyans Sethi,Diwakar Mahajan,Hongyang Li,Yuxin Yang,Elif Eyigoz,Aldo Guzman Saenz,Daniel E. Platt,Timothy H. Rumbell,Kenney Ng,Sanjoy Dey,Myson Burch,Bum Chul Kwon,Pablo Meyer,Feixiong Cheng,Jianying Hu,Joseph A. Morrone", "background": "高质量的分子表示对于生物医学研究中的基础模型发展至关重要。以往的努力通常关注单一的表示或分子视图，尽管这些方法在特定任务上可能具有优势，但也可能存在局限性。本文探讨了一种名为多视图分子嵌入晚期融合（MMELON）的方法，该方法在一个基础模型框架中综合了图、图像和文本视图，并且可以轻松扩展到其他表示方法。每个单一视图的基础模型都是在多达200M分子的数据集上提前训练的。多视图模型表现稳定，其性能与最高排名的单一视图模型相当，已经在超过120项任务上得到验证，包括分子溶解性、ADME性质和GPCRs活性预测。此外，通过结构基础建模验证预测，并识别关键结合基序来进一步确定与阿尔茨海默病相关的33个GPCRs，进而从化合物筛选中选择强结合物", "innovation": "提出了多视图分子嵌入晚期融合（MMELON）方法，该方法能够在一个基础模型框架中综合图、图像、文本三种视图，为生物医学应用中的分子性质预测提供了一种新的解决方案，并且能够轻松地扩展到其他表示方法。该方法通过在大规模数据集上预训练单一视图模型，并在多个任务上表现出色，展示其在实际应用中的潜力和价值。", "conclusion": "本文提出的多视图分子嵌入晚期融合（MMELON）模型在多个生物医学任务中表现出色，能够为分子性质预测提供更加全面和准确的表示。该模型通过结构基础建模验证了预测的有效性，并进一步通过筛选化合物验证了其在识别强结合物方面的应用潜力，为未来生物医学领域的研究提供了新的思路和工具。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.15460", "html_url": "https://arxiv.org/abs/2410.15460", "title": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training", "title_en": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training", "authors": "Shahrad Mohammadzadeh,Juan David Guerra,Marco Bonizzato,Reihaneh Rabbany,Golnoosh Farnadi", "background": "随着大型语言模型（LLMs）的日益普及，人们对它们可靠性的担忧也与日俱增，特别是在它们可能会生成不准确或不相关的输出（幻觉）方面。本文研究了训练动力学的不确定性与幻觉出现之间的关系，并通过分析 Pythia 系列模型及多种幻觉检测指标，发现了训练过程中幻觉的变化显著差异。", "innovation": "提出了一个新的训练协议——Sensitivity Dropout（SenD），旨在通过在训练过程中确定性地丢弃显著变异的嵌入索引来减少幻觉的变异。此外，还开发了一个无监督的幻觉检测指标——Efficient EigenScore（EES），其速度是传统 EigenScore 的两倍。将 EES 集成到训练协议中，使 SenD 不仅计算上具有可扩展性，同时还能有效减少幻觉的变异。SenD 通过对 Pythia 和 Meta 的 Llama 模型的测试时间可靠性提高了高达 17%，并在维基百科、医学、法律和编码领域提高了事实准确性，而不会影响下游任务的性能。", "conclusion": "SenD 通过在训练过程中引入一个创新的训练协议，成功减少了大型语言模型中的幻觉现象，提高了模型在测试时的可靠性，增强了事实准确性，同时保证了在具体任务中的应用效果。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.09474", "html_url": "https://arxiv.org/abs/2410.09474", "title": "使用双重增强进行可变表示知识蒸馏", "title_en": "Distilling Invariant Representations with Dual Augmentation", "authors": "Nikolaos Giakoumoglou,Tania Stathaki", "background": "知识蒸馏（KD）广泛应用于从大而准确的模型（教师）向小型、高效模型（学生）转移知识。最近的方法通过引入因果解释来强制一致性，以馏取出不变的表示。本文在这一研究方向上进行了拓展，提出了一种双重增强策略，以促进教师和学生模型中不变特征的学习。该策略利用在蒸馏过程中对两种模型应用不同的增强，促使学生捕捉到鲁棒且可转移的特征，从而提高蒸馏后的模型表现和泛化能力。", "innovation": "提出了一种双重增强策略，通过在蒸馏过程中对教师和学生模型应用不同的增强，增强它们学习不变特征的能力。该方法通过确保学习到的表示在更广泛的数据变化和转换中保持稳定，增强了模型的鲁棒性和泛化能力。实验结果表明，这种方法在CIFAR-100数据集上实现了竞争性的效果，特别是在同一架构的KD中。", "conclusion": "通过双重增强策略，该研究提高了教师和学生模型之间的知识蒸馏效果，特别是在不变特征学习方面。实验表明，该方法在CIFAR-100数据集上的效果与现有方法竞争，增强了模型的鲁棒性和泛化能力。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10644", "html_url": "https://arxiv.org/abs/2507.10644", "title": "从语义web和MAS到代理人工智能：Web of Agents的统一叙事", "title_en": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "authors": "Tatiana Petrova(1),Boris Bliznioukov(1),Aleksandr Puzikov(1),Radu State(1) ((1) SEDAN SnT, University of Luxembourg, Luxembourg, Luxembourg)", "background": "介绍了Web of Agents (WoA)的概念，即将静态、文档导向的Web转变为由自主代理操控的环境。随着大型语言模型（LLMs）能力的增强，Woa引起了越来越大的兴趣。然而，该领域的研究仍然分散在不同的社区中。当前的综述主要列出LLM驱动的框架，而多Agent系统（MAS）和语义Web的历史往往被视为分离的、过时的领域。这种碎片化模糊了现代系统的智力起源，阻碍了对领域发展轨迹的全面理解。", "innovation": "本文提出了第一个综合演化综述WoA。展示了现代协议如A2A和MCP是提前解决早已记录的早期标准如FIPA标准和基于OWL的语义代理问题的直接演化回应。为了系统化这一分析，引入了四轴分类法（语义基础、通信范式、智能中枢、发现机制）。这个框架为比较所有世代的Agent架构提供了一个统一的分析视角，揭示了清晰的直接传承关系，其他研究者则看到了断层。分析指出智能中枢范式的转变：从外部分散的数据或平台代码转移到嵌入到代理核心模型，这是现代代理型AI的基础，允许构建WoA设想的可扩展和适应性系统。", "conclusion": "结论认为，尽管新的协议是必要的，但构建一个强大、开放和可信赖的生态系统仍然远远不够。最后，文章指出研究的下一个前沿是在解决持续的社会和技术挑战上，提出了一个新议程，重点关注去中心化身份、经济模型、安全和治理，用于新兴的WoA。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.15607", "html_url": "https://arxiv.org/abs/2410.15607", "title": "城市自动驾驶中的强化模仿轨迹规划", "title_en": "Reinforced Imitative Trajectory Planning for Urban Automated Driving", "authors": "Di Zeng,Ling Zheng,Xiantong Yang,Yinong Li", "background": "强化学习（RL）在城市自动驾驶中的轨迹规划中面临挑战，主要是由于RL的收敛性差和设计奖励函数的困难。这导致很少有基于RL的轨迹规划方法能够达到与基于模仿学习的方法相当的性能。通过将RL与监督学习相结合可缓解收敛性问题，但大多数现有方法只考虑一步预测，缺乏多步预测的能力。此外，逆强化学习可能有助于解决奖励函数设计问题，但现有的方法对奖励函数的线性结构假设使得它们难以应用于城市自动驾驶环境。因此，该研究旨在提出一种新的基于RL的轨迹规划方法，通过将RL与模仿学习结合以实现多步规划。", "innovation": "提出了一个结合了RL和模仿学习的新颖城市自动驾驶轨迹规划方法，用于多步规划。开发了基于Transformer的贝叶斯奖励函数，为RL提供有效的奖励信号。此外，提出了一种混合驱动轨迹规划框架，以增强安全性和可解释性。该方法在大规模真实城市自动驾驶nuPlan数据集上进行了验证。评估结果显示，该方法在闭环度量标准上的表现显著优于基线，并达到了与最新方法媲美的水平。", "conclusion": "所提出的RL和模仿学习结合的方法解决了城市自动驾驶中的RL收敛性和奖励函数设计问题，通过有效的奖励信号和混合驱动的轨迹规划框架提高了自动驾驶的安全性和可解释性，验证结果表明该方法在实际数据集上优于现有方法并达到了高性能。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10076", "html_url": "https://arxiv.org/abs/2507.10076", "title": "渐进语义在假设基础论辩中的应用", "title_en": "On Gradual Semantics for Assumption-Based Argumentation", "authors": "Anna Rapberger,Fabrizio Russo,Antonio Rago,Francesca Toni", "background": "在计算论辩中，渐进语义是与扩展基和标签基语义细粒度的替代方案。渐进语义赋予论辩（论辩的组件）一种辩证强度，从而确定其接受度的层级。已有几种渐进语义研究了抽象、双极性和定量双极性论辩框架（QBAFs），以及对于一些结构化论辩形式的研究较少，但对于假设基础论辩（ABA）这一流行且应用广泛的结构化论辩形式，渐进语义的研究还处于空白。", "innovation": "本文填补了这方面的空白，为论辩框架的核心组件假设引入了一组新的渐进语义。通过使用双极性集合论辩框架作为非平坦论辩框架的抽象，作者推广了现有的模块化渐进语义，并证明了这些新的渐进ABA语义满足渐进QBAF语义适用的期望属性，如平衡性和单调性。同时，作者还探索了一种基于论辩的途径，利用现有的QBAF模块化语义直接进行评估，并将其作为基准。", "conclusion": "研究通过使用合成的ABA框架进行实验，与基于论辩的对应部分进行比较，并评估收敛性，以证明新提出的渐进ABA语义的有效性和实用性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.18375", "html_url": "https://arxiv.org/abs/2412.18375", "title": "包含交叉操作证明不可或缺的多目标问题", "title_en": "Many Objective Problems Where Crossover is Provably Essential", "authors": "Andre Opris", "background": "论文探讨了进化多目标优化中的理论问题，特别是交叉操作的作用。交叉操作的优势尚未清晰，且关于交叉操作的严格运行时分析远远落后于其在实践中的应用，尤其是在超过两个目标的情况下。", "innovation": "论文提出了两种新的多目标问题 $RR_{\text{RO}}$ 和 $uRR_{\text{RO}}$，并通过严格的理论运行时分析展示了 GSEMO 和 NSGA-III 算法这两种操作的效率。研究结果表明，在这两个问题中，使用单点交叉操作可以在多项式时间内找到 Pareto 集，而无需交叉操作则需要指数时间才能找到单一的 Pareto 最优解。此外，论文还展示了在超级恒定参数条件下，目标数量变化时性能的显著差距。这是多目标优化领域中首次使用交叉操作展示证明其在超过两个目标时存在指数级性能差距的严格运行时分析。", "conclusion": "研究证明了在多目标优化中，交叉操作对于研究具有关键性。此外，这还是首次对非恒定目标数量的多目标优化问题进行交叉操作的运行时分析。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.09567", "html_url": "https://arxiv.org/abs/2403.09567", "title": "增强自主代理的信任：通过区块链和大语言模型实现问责制和可解释性架构", "title_en": "Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models", "authors": "Laura Fernández-Becerra,Miguel Ángel González-Santamarta,Ángel Manuel Guerrero-Higueras,Francisco Javier Rodríguez-Lera,Vicente Matellán Olivera", "background": "在涉及人类互动的环境中部署自主代理越来越引发了安全方面的担忧。因此，理解事件背后的情况变得至关重要，需要开发能力来向非专家用户提供自主代理行为的解释。这些解释对于增强信任度和安全性是非常必要的，同时也是预防失败、错误和误解的重要措施。此外，这些解释能够改善沟通，弥合代理与用户之间的差距，从而提高其交互的有效性。", "innovation": "该研究提出了一个基于ROS的移动机器人问责制和可解释性架构。该解决方案由两个主要部分组成：第一部分是一个类似黑箱的组件，通过区块链技术实现抗篡改性能，以提供问责制；第二部分负责生成基于先前提到的黑箱内的数据由大型语言模型（LLMs）生成的自然语言解释。该研究在三个不同的场景中评估了该解决方案的表现，每个场景都涉及自主代理导航功能，以全面检验问责制和可解释性指标，展示了通过使用机器人行动的可问责数据获得连贯、准确和易于理解的解释的有效性，即使在使用自主代理面临现实场景中的挑战时也是如此。", "conclusion": "该研究证明了通过使用可问责数据从机器人行动中获得连贯、准确和易于理解的解释的有效性。提出的基于区块链技术和大型语言模型的问责制和可解释性架构在面对自主代理在真实世界中的挑战时表现出有效性，这为增强用户对自主代理的信任提供了有力的支持。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.02572", "html_url": "https://arxiv.org/abs/2411.02572", "title": "ViTally Consistent: 大规模生物学表示学习的细胞显微镜", "title_en": "ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy", "authors": "Kian Kenyon-Dean,Zitong Jerry Wang,John Urbanik,Konstantin Donhauser,Jason Hartford,Saber Saberian,Nil Sahin,Ihab Bendidi,Safiye Celik,Marta Fay,Juan Sebastian Rodriguez Vera,Imran S Haque,Oren Kraus", "background": "大规模细胞显微镜筛查被广泛应用于药物发现和分子生物学研究，用于研究数百万种化学和遗传扰动对细胞的影响。为了进行下游分析，我们需要能够将每张图像映射到一个代表多种生物表型的空间中的模型，这样生物学效应相似的扰动在该空间中具有相似的表现。现有的模型并未能够实现这一点，因此本研究目标是开发一个能够在该层面进行极大改进的基础模型。", "innovation": "本研究提出了一种1.9亿参数的ViT-G/8 MAE模型，训练数据量超过8亿张显微图像切片，相较于之前的ViT-L/8 MAE模型，该新模型在基因扰动的线性可分性方面提高了60%，并在整个基因组生物关系召回率和重复一致性基准测试中达到了最佳性能。此外，本研究通过两种方法改进了性能：一是使用经过精心挑选和多样化的数据集进行训练；二是采用生物动机的线性探测任务，在每个变压器块中搜索最佳的整体基因组实验的候选表示。", "conclusion": "本方法和结果为大规模构建生物学数据基础模型提供了一般策略，表明许多预训练在自然图像或显微图像上的自监督视觉变压器，在中间块中比在最终块中提供了更有生物学意义的显微图像表示。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.14335", "html_url": "https://arxiv.org/abs/2406.14335", "title": "文本分析中线性可解释概念嵌入模型", "title_en": "Linearly-Interpretable Concept Embedding Models for Text Analysis", "authors": "Francesco De Santis,Philippe Bich,Gabriele Ciravegna,Pietro Barbiero,Danilo Giordano,Tania Cerquitelli", "background": "尽管大规模语言模型（LLMs）取得了成功，但它们仍然因缺乏解释性而受到批评。传统的后 hoc 解释方法基于注意力和梯度分析，仅对模型的决策过程进行近似，且已被证明不可靠。为此，最近在文本领域提出了概念瓶颈模型（CBMs），它基于可理解的概念提供可解释的预测。然而，CBMs 仍然存在一些限制，如架构上的表达能力受限，非线性任务预测缺乏任务可解释性，以及需要广泛的注释，这对于现实世界的文本数据来说是不实际的。", "innovation": "本文提出了一种全新的线性可解释概念嵌入模型（LICEM），它超越了目前的准确性和解释性权衡。LICEM 的分类准确率优于现有的可解释模型，可以与黑盒模型相媲美。此外，我们展示了模型提供的解释比现有解决方案更具干预性和因果一致性。最后，表明可以在无需任何概念监督的情况下训练LICEM，因为当使用大规模语言模型（LLM）作为基础模型时，可以自动预测概念，这是现有方法无法实现的突破。", "conclusion": "提出的LICEM解决了概念瓶颈模型的挑战，并且通过不需要概念监督的自动预测能力，展示了更高的解释质量和模型性能。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.00355", "html_url": "https://arxiv.org/abs/2411.00355", "title": "TextDestroyer：无需训练和标注的图像中异常文本破坏的扩散方法", "title_en": "TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images", "authors": "Mengcheng Li,Fei Chao", "background": "现有的场景文本去除模型需要复杂的标注和重新训练，并且可能会留下难以识别的文字痕迹，这损害了隐私保护和内容隐藏。因此，需要一种无需训练和标注的方法来更彻底地破坏文本。", "innovation": "提出了一种名为TextDestroyer的方法，利用预训练的扩散模型，通过三个阶段的层次过程获得准确的文字遮罩，并在重建过程中通过对潜在起始码中的文本区域进行高斯分布随机化，以及在去噪过程中参考原始潜在状态中的自注意力键和值来恢复被破坏的背景，确保背景恢复的完美性。", "conclusion": "TextDestroyer的优点包括消除劳动密集型数据标注和资源密集型训练的需求；实现更彻底的文本破坏，防止可识别痕迹；展示更好的泛化能力，适用于真实场景和生成图像。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13959", "html_url": "https://arxiv.org/abs/2501.13959", "title": "学习有效的前提检索模型以实现高效的数学形式化", "title_en": "Learning an Effective Premise Retrieval Model for Efficient Mathematical Formalization", "authors": "Yicheng Tao,Haotian Liu,Shanwen Wang,Hongteng Xu", "background": "形式化数学近年来引起了广泛的关注，因为它能够帮助各个领域的数学家。前提检索是数学形式化中的常见步骤，但对不熟练的用户来说却是一个挑战。现有的自然语言查询辅助检索方法需要用户的一定数学背景，而基于形式化语言的方法（如Lean）由于训练数据的稀缺性，难以训练出有效且泛化的检索模型。本研究旨在解决这一问题，通过利用从Mathlib提取的数据训练一种轻量级且有效的前提检索模型。", "innovation": "研究提出了一种新颖的方法，通过利用从Mathlib提取的数据来训练轻量级且有效的前提检索模型。该模型在对比学习框架中进行学习，采用了精炼的相似度计算方法和重新排序模块，以增强检索性能。实验结果表明，该模型优于现有基线，准确率更高且具有较低的计算负载。", "conclusion": "研究展示了基于检索模型的开源搜索引擎，源代码和训练模型可在指定的网址找到。该模型能够在保持低计算负载的同时实现高效的数学形式化。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.05111", "html_url": "https://arxiv.org/abs/2502.05111", "title": "灵活且高效的语法约束解码", "title_en": "Flexible and Efficient Grammar-Constrained Decoding", "authors": "Kanghee Park,Timothy Zhou,Loris D'Antoni", "background": "大型语言模型（LLMs）常被要求生成遵循精确语法规则的结构化输出，例如代码片段或格式化数据。语法约束解码（GCD）通过屏蔽会导致不符合指定上下文无关文法（CFG）输出的令牌来确保LLM输出符合这些规则。为了确保有效性，GCD算法需要计算LLM子词分词器如何与指定上下文无关文法中的令牌对齐，并基于这些信息计算令牌屏蔽。然而，高效执行此操作是具有挑战性的，现有GCD算法需要数分钟来做常规语法的预处理。", "innovation": "本文提出了一种新的GCD算法及其实现，相比现有方法，该实现提供了比现有方法快17.71倍的离线预处理速度，同时保持最先进的在线屏蔽计算效率。", "conclusion": "新算法和实现有效地提高了语法约束解码的效率，解决了现有的性能瓶颈问题。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01912", "html_url": "https://arxiv.org/abs/2502.01912", "title": "PATCH: 一种用于历史绘画中艺术实践异质性评估的深度学习方法", "title_en": "PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings", "authors": "Andrew Van Horn,Lauryn Smith,Mahamad Mahmoud,Michael McMaster,Clara Pinchbeck,Ina Martin,Andrew Lininger,Anthony Ingrisano,Adam Lowe,Carlos Bayod,Elizabeth Bolman,Kenneth Singer,Michael Hinczewski", "background": "艺术史中创作方式经历了显著的变化，理解创造性过程成为技术艺术史的核心问题。在文艺复兴和早期现代时期，绘画主要是由导师指导学徒的工作室完成的，而成品中艺术家和工具的变化可能因导师、工作室甚至单个画布而异。有关工作室管理和艺术作品创作过程的信息仍模糊不清。机器学习方法能够通过将笔法分析扩展到微观尺度，揭示新的艺术家创作过程信息。然而，由于涉及艺术家和材料的记录稀少，无法获得训练网络识别贡献的外部示例，因此历史绘画的分析存在挑战。", "innovation": "本文提出了一种新的机器学习方法——称为配对分配训练用于分类异质性（PATCH），它可以识别个体艺术家实践模式，无需外部训练数据或“真实参照”。该方法通过监督手段实现无监督结果，并且其性能优于简单统计程序和无监督机器学习方法。该方法应用于西班牙文艺复兴大师埃尔·格列柯的两幅历史绘画：《基督受洗》和《十字架上的基督与风景》，结果表明前一幅作品可能被分配给工作室成员的现有工作是不准确的。此外，我们的分析结果提供了一种衡量跨时空艺术实践异质性的度量标准。", "conclusion": "通过应用PATCH方法，本文不仅识别了个人艺术家在历史绘画创作过程中的实践模式，还提供了衡量不同时间与空间下的艺术实践异质性的方法。这种方法为更深入理解艺术创作过程提供了新的视角和工具。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15203", "html_url": "https://arxiv.org/abs/2502.15203", "title": "FlipConcept：文本到图像生成中的无调优多概念个性化", "title_en": "FlipConcept: Tuning-Free Multi-Concept Personalization for Text-to-Image Generation", "authors": "Young Beom Woo,Sun Eung Kim,Seong-Whan Lee", "background": "在文本到图像（T2I）生成中，将多个个性化概念整合进单张图像近期受到了广泛关注。然而，现有的方法通常在复杂场景中会因为非个性化区域的失真以及需要额外的微调而导致性能下降，这限制了这些方法的实际应用价值。", "innovation": "本文提出了一种名为FlipConcept的新方法，该方法无需额外调优就可以无缝地将多个个性化概念整合进单张图像。具体创新包括引入引导外观注意增强个性化概念的视觉准确性，引入掩码引导噪声混合保护概念整合过程中的非个性化区域，最后通过背景稀释减少概念泄漏，即个性化概念与其他图像中的物体意外混合的问题。", "conclusion": "实验结果表明，与现有模型相比，本文提出的方法在单个和多个个性化概念的推断中表现出更高的性能，无需额外调优也能够实现高质量的多概念个性化，证明了本方法的有效性和实用性，适用于大规模的高阶个性化需求。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.16605", "html_url": "https://arxiv.org/abs/2501.16605", "title": "现代AI在元数据管理中的影响", "title_en": "The Impact of Modern AI in Metadata Management", "authors": "Wenli Yang,Rui Fu,Muhammad Bilal Amin,Byeong Kang", "background": "元数据管理在数据治理、资源发现和决策制定中扮演着关键角色。传统元数据方法主要关注组织、分类和资源再利用。而现代人工智能技术的集成显著改变了这些过程。本文通过研究开源解决方案、商业工具和研究项目，分别分析了传统和基于AI的元管理方法，指出了现有挑战及其对下一代数据集的影响。", "innovation": "本文提出了一种创新的基于AI的辅助元数据管理框架，该框架利用了更先进的现代AI技术来自动元数据生成、加强治理并提高现代数据集的可访问性和易用性。", "conclusion": "本文指出了未来研究和开发的方向，提出了进一步推进基于AI创新和复杂数据集环境下的元数据管理的机会。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16994", "html_url": "https://arxiv.org/abs/2502.16994", "title": "FADE: Why Bad Descriptions Happen to Good Features", "title_en": "FADE: Why Bad Descriptions Happen to Good Features", "authors": "Bruno Puri,Aakriti Jain,Elena Golimblevskaia,Patrick Kahardipraja,Thomas Wiegand,Wojciech Samek,Sebastian Lapuschkin", "background": "近期在机械可解释性方面的进步突显了在分析LLMs中的潜在代表时自动化可解释性管道的潜力，这可能增强我们对内部机制的理解。然而，领域内缺乏标准化的评估方法来评估发现特征的有效性。", "innovation": "该研究引入了FADE：特征对描述评估框架，这是一种可扩展且模型通用的框架，用于自动评估特征与描述之间的对齐情况。FADE通过四个关键指标（清晰度、响应性、纯度和忠实地度）系统性地量化偏差的原因。作者应用FADE分析现有开源特征描述，并评估自动化可解释性管道的关键组成部分，以提高描述质量。研究表明，SAEs生成特征描述时存在的基本挑战明显多于MLP神经元，提供了一种关于自动化可解释性局限性的见解，以及未来方向。", "conclusion": "研究结果揭示了生成特征描述的根本挑战，特别是在SAEs方面相较于MLP神经元，为理解和改进自动化可解释性提供新的视角。FADE作为一个开源软件包已经发布。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15186", "html_url": "https://arxiv.org/abs/2502.15186", "title": "LUMINA-Net: 低光照升级通过多阶段照明和噪声自适应网络进行图像增强", "title_en": "LUMINA-Net: Low-light Upgrade through Multi-stage Illumination and Noise Adaptation Network for Image Enhancement", "authors": "Namrah Siddiqua,Kim Suneung,Seong-Whan Lee", "background": "低光照图像增强（LLIE）是计算机视觉中的一个关键任务，旨在提升在低光照条件下拍摄的图像的视觉保真度。传统方法经常难以处理噪声、过曝和色彩失真，导致图像质量严重下降。", "innovation": "提出了一种名为LUMINA-Net的无监督深度学习框架，该框架通过结合多阶段照明和反射模块从低光照图像对中学习自适应先验知识。在协助Retinex分解的过程中，可以使用简单的自监督机制移除原始图像中的不合适特征。LUMINA-Net 通过智能调整亮度和对比度，同时保留精细的纹理细节，并通过引入噪声减少机制来利用空间注意力和通道级特征改进，从而减少噪声污染。", "conclusion": "在LOL和SICE数据集上进行了广泛实验，通过PSNR，SSIM和LPIPS评估指标，LUMINA-Net超越了现有的最佳方法，显示出其在低光照图像增强中的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12272", "html_url": "https://arxiv.org/abs/2502.12272", "title": "学习推理能力的边界", "title_en": "Learning to Reason at the Frontier of Learnability", "authors": "Thomas Foster,Jakob Foerster", "background": "强化学习现已被广泛应用于大规模语言模型（尤其是需要推理能力的任务，如数学问题）的最终训练阶段。通常，模型会在每次训练步骤中多次尝试每个问题，并从成功和失败中学习。然而，研究发现，通过两种广泛使用的算法（PPO和VinePPO），在两个常用数据集上进行训练时，许多问题要么所有尝试都成功得到解答（意味着已经学习），要么所有尝试都不成功（提供了不了解训练信号）。", "innovation": "作者通过引入一种来自强化学习文献的方法——可学习性采样，将其应用于大规模语言模型训练的强化学习阶段的教学计划中。该教学计划优先考虑有高成功率变异性的任务，即代理有时成功，但不总是成功的问题。此类方法在多种算法和数据集上的实验显示，能够显著提升训练性能。", "conclusion": "这些发现表明，这种方法能够为大规模语言模型高效且有效地提供强化学习能力，为未来的工作铺平了道路。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.19819", "html_url": "https://arxiv.org/abs/2412.19819", "title": "ChipAlign: 在芯片设计中利用测地线插值的大语言模型指令对齐", "title_en": "ChipAlign: Instruction Alignment in Large Language Models for Chip Design via Geodesic Interpolation", "authors": "Chenhui Deng,Yunsheng Bai,Haoxing Ren", "background": "大型语言模型（LLMs）的最新进展扩展了它们在各个领域的应用，包括芯片设计。在此背景下，出现了像ChipNeMo这样的针对芯片的模型。然而，这些模型往往在指令对齐方面存在局限性，这是LMLs的关键能力之一，涉及遵循明确的人类指导。这种限制阻碍了芯片LLMs的实际应用，包括充当硬件设计工程师的助理聊天机器人。", "innovation": "该工作引入了一种新的方法名为ChipAlign，它是一种无训练的模型合并策略，结合了一般指令对齐的LLM与专用的芯片LLM的优点。通过考虑权重空间中的底层流形，ChipAlign运用测地线插值有效地融合输入LLMs的权重，生成一个植入来自各自指令和芯片LLM的强指令对齐和芯片专业知识的合并模型。实验结果表明，ChipAlign显著提升了现有的芯片LLMs的指令跟随能力，IIFEval基准上的表现提高了26.6%的同时保留了芯片领域的专业知识。这种在指令对齐方面的改进也在指令相关的问答任务中带来了显著的性能提升，OpenROAD QA基准上的性能提升了3.9%，生产级别的芯片问答基准上的性能提升了8.25%，优于最先进的基线。", "conclusion": "ChipAlign结果表明，通过引入无训练的模型合并策略，有效地结合指令对齐和芯片特定的专业知识，显著提升了芯片设计中LLMs的指令跟随能力和专业知识保留，同时提供了卓越的性能提升。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15426", "html_url": "https://arxiv.org/abs/2503.15426", "title": "基于MLLM的视觉定位中的视觉位置提示", "title_en": "Visual Position Prompt for MLLM based Visual Grounding", "authors": "Wei Tang,Yanpeng Sun,Qinying Gu,Zechao Li", "background": "尽管多模态大型语言模型（MLLMs）在各种图像相关任务中表现出色，但在精确对齐坐标与图像中的空间信息方面遇到了挑战，特别是在需要位置意识的任务，如视觉定位中。这个限制主要来源于两个方面：首先，MLLMs缺乏明确的空间参考，使得难以将文本描述与精确的图像位置关联起来；其次，它们的特征提取过程更倾向于全局上下文，而不是细粒度的空间细节，导致定位能力较弱。", "innovation": "为了应对这些问题，我们介绍了一种增强的MLLM，称为VPP-LLaVA，引入了视觉位置提示（VPP）来提高其视觉定位能力。VPP-LLaVA结合了两种互补机制：全局VPP将一个可学习的轴向张量叠加到输入图像上以提供结构化空间线索，而局部VPP则包含位置意识查询以支持细粒度的效果。此外，我们还引入了VPP-SFT，一种包含60万高质量视觉定位样本的定制数据集，用于提供空间指导有效训练模型。该数据集的设计较为紧凑，训练效率高，且规模远小于其他MLLMs所使用的数据集，但仍然提供了显著的性能提升。", "conclusion": "结果表明，VPP-LLaVA不仅在标准视觉定位基准测试中达到了最先进的性能，而且在挑战性未见过的数据集上的零样本泛化能力也非常强大。此外，研究代码和数据集已公开可用。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22526", "html_url": "https://arxiv.org/abs/2503.22526", "title": "AnnoPage Dataset: 文档中具有精细分类的非文本元素数据集", "title_en": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization", "authors": "Martin Kišš,Michal Hradiš,Martina Dvořáková,Václav Jiroušek,Filip Kersch", "background": "目前存在对历史文档进行布局分析和对象检测研究的数据集不足的问题。特别是缺乏专注于特定历史时期的详细分类的非文本元素数据集，这些元素包括图像、地图、装饰元素或图表等。研究人员需要更多样化和高质量的数据集来支持这些领域的深入研究和开发新的算法和技术。", "innovation": "该研究提出了AnnoPage数据集，这是一个包含7,550页的历史文档数据集，主要包含捷克语和德语文档，时间跨度从1485年到现代，特别是在19世纪末和20世纪初。数据集中的每一页都被标注了25类非文本元素的轴对齐边界框（AABB），这些元素的标注由专家图书管理员完成，以确保准确性与一致性。此外，数据集还整合了多个主要历史文档数据集，以增强多样性和连贯性。", "conclusion": "研究提供了使用YOLO和DETR对象检测器的基准结果，为未来的研究提供了一个参考点。AnnoPage数据集已在Zenodo上公开提供，包括YOLO格式的地面真相注释，供研究人员下载使用。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.16946", "html_url": "https://arxiv.org/abs/2504.16946", "title": "MobileCity：大规模都市行为仿真高效框架", "title_en": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation", "authors": "Xiaotong Ye,Nicolas Bougie,Toshihiko Yamasaki,Narimasa Watanabe", "background": "生成型代理为模拟现实都市行为提供了前景广阔的潜力。然而，现有的方法在出行选择上过于简化，依赖于静态代理配置而导致行为单一化，并且计算成本高昂。为了应对这些局限，我们提出了MobileCity，这是一个轻量级的仿真平台，旨在高效地模拟真实的都市流动性。平台引入了包含多种交通模式的综合交通系统，并通过收集受访者的问卷数据构建代理配置文件。为了实现可扩展的仿真，代理在预生成的动作空间内进行动作选择，并使用局部模型来高效生成代理记忆。在4,000个代理的广泛微观和宏观层面评价中，我们证明了MobileCity生成了比基线方法更真实的都市行为，同时保持了高效的计算性能。我们进一步探讨了几种实际应用，如预测运动模式和分析交通偏好中的人口趋势", "innovation": "引入多种交通模式的综合交通系统；利用预生成的动作空间及局部模型来高效生成代理记忆；基于4,000个代理的评价，证明了在保持高效计算的同时，增强了模拟的真实性", "conclusion": "MobileCity通过引入多种交通模式的综合交通系统、预生成的动作空间和局部模型，在保持高效计算的同时，提高了模拟的真实性和扩展性，适合大规模都市行为的仿真与分析"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00584", "html_url": "https://arxiv.org/abs/2504.00584", "title": "语义适配器：诊断和缓解通用文本嵌入的认知盲区以增强其普遍性", "title_en": "Semantic Adapter for Universal Text Embeddings: Diagnosing and Mitigating Negation Blindness to Enhance Universality", "authors": "Hongliu Cao", "background": "否定在自然语言处理任务（如自然语言推理和情感分析）中扮演着重要角色。先前的研究发现，诸如BERT、ELMO、RoBERTa或XLNet等上下文文本嵌入模型在理解否定方面存在挑战。最近，通用文本嵌入在各个任务中的表现超过了上下文文本嵌入，但因广泛使用的评估基准中存在的偏见，这些模型的否定意识能力仍不清楚。因此，本研究旨在深入分析这些先进通用文本嵌入模型的否定意识能力。", "innovation": "提出了一个数据高效和计算高效的文本嵌入加权方法，该方法在不修改文本嵌入模型参数的情况下，能够显著提高文本嵌入模型的否定意识能力，特别是在简单的否定理解任务和复杂的否定理解任务中。此外，该方法还显著提高了基于大型语言模型的任务特定高维通用文本嵌入的否定意识。", "conclusion": "研究揭示了这些先进通用文本嵌入模型在否定意识方面存在显著不足，通常将否定文本对解释为语义相似。尽管如此，通过提出的方法，能够在某些简单和复杂的否定理解任务中显著提升文本嵌入模型的否定意识，同时也显著提高了基于大型语言模型的任务特定高维通用文本嵌入的否定意识。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00513", "html_url": "https://arxiv.org/abs/2504.00513", "title": "利用大型语言模型生成AI系统用户故事：UStAI数据集", "title_en": "Leveraging LLMs for User Stories in AI Systems: UStAI Dataset", "authors": "Asma Yamani,Malak Baslyman,Moataz Ahmed", "background": "随着AI系统在各个行业和领域的广泛应用，创建高质量的AI系统需求对于确保AI系统与业务目标和消费者价值相一致，以及促进社会责任感至关重要。然而，由于AI系统的不确定性和对敏感数据的高度依赖，仍需更多研究以解决需求提取与分析的问题。此外，由于许多AI系统具有专有性质，缺乏开源的需求文档和技术要求说明，限制了更广泛的学术研究和调查。近年来，大型语言模型（LLMs）逐步成为替代人类生成文本的一种有前景的选择。基于此，本文考察了LLMs在生成基于学术论文摘要的AI系统用户故事方面的潜力。我们使用三种LLMs生成了总共1260个用户故事，来自42篇摘要，涉及26个领域。", "innovation": "本文的主要创新在于通过使用大型语言模型（LLMs）自动生成用户故事，解决了传统人工智能系统需求分析与提取的问题。具体而言，研究利用学术论文的摘要信息生成了大量的用户故事，并使用质量用户故事（QUS）框架评估了生成用户故事的质量，同时也指出了相应的非功能性要求和伦理原则。这为AI系统的早期需求提取阶段提供了有效途径。此外，研究者还收集了一套由不同LLMs生成的故事，形成一个名为UStAI的数据集，已经在公共平台上公开分享供研究使用。", "conclusion": "研究结果证明，大型语言模型能够生成多种利益相关者需求灵感的用户故事，为研究目的生成用户故事提供了一种有前景的方法。通过分析，表明该LSTM可以有效地生成用户故事，这对非功能性要求的识别及伦理原则的考虑均有一定的积极影响。此外，研究人员还创建了一个包含多LLMs生成故事的数据集（UStAI），以供AI系统早期需求提取阶段使用。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.13497", "html_url": "https://arxiv.org/abs/2502.13497", "title": "朝向地理文化背景下的大语言模型生成", "title_en": "Towards Geo-Culturally Grounded LLM Generations", "authors": "Piyawat Lertvittayakumjorn,David Kinney,Vinodkumar Prabhakaran,Donald Martin Jr.,Sunipa Dev", "background": "生成式大型语言模型（LLMs）在全球范围内显示出多元文化认知的不足。本文研究了检索增强生成和基于搜索的技术对LLMs表现其对不同国家文化的熟悉程度的影响。具体而言，本文比较了标准LLMs、使用定制知识库增强检索（即KB接地）的LLMs和使用网络搜索增强检索（即搜索接地）的LLMs在多个文化认知基准测试中的性能。研究表明，搜索接地在多项选择题测试中显著提高了LLMs对文化规范、物质和机构的认知，但定制知识库的覆盖不足和检索器的效率问题限制了KB接地的效果。然而，搜索接地增加了语言模型产生刻板判断的风险，并未能在具有统计功效的人类评估中改善对文化熟悉度的评判。这些结果强调了在评估LLMs的文化意识时，实质性文化知识与开放的文化流畅性之间的区别。", "innovation": "本文探索了检索增强生成和基于搜索的技术如何影响LLMs对不同国家文化的熟悉程度。通过对比标准LLMs、KB接地的LLMs和搜索接地的LLMs在多项文化认知基准测试中的表现，发现搜索接地能显著提高对文化规范、物质和机构的认知，但同时带来了刻板判断的风险，并未提升人类评估中的文化熟悉度评判。", "conclusion": "研究结果表明，实质性文化知识与开放的文化流畅性在评估LLMs的文化意识中有所不同。搜索接地虽然提高了文化规范、物质和机构的认知，但未能改善对文化熟悉度的评判，也增加了语言模型产生刻板判断的风险。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.11167", "html_url": "https://arxiv.org/abs/2503.11167", "title": "Neurons：模拟人脑视觉皮层提高fMRI到视频重建的保真度和可解释性", "title_en": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction", "authors": "Haonan Wang,Qixiang Zhang,Lehan Wang,Xuanqi Huang,Xiaomeng Li", "background": "解码神经活动中的视觉刺激对于理解人类大脑至关重要。虽然fMRI方法已成功重构静态图像，但fMRI到视频的重建面临挑战，需要捕捉如运动和场景转换等时空动态。尽管近期方法在语义和感知对齐方面有所改进，但在将粗略的fMRI数据与详细的视觉特征整合方面仍存在问题。此外，fMRI到视频的重建需要高效地捕捉和处理视觉信息。因此，需要一种能够同时处理时空复杂性的方法。现有的方法在实验中难以全面满足需求，因此还需要开发一种能够有效捕捉复杂视觉信息的技术框架，该框架能够模拟人类视觉皮层的功能专业化，以提高重建视频的准确性和可解释性。", "innovation": "论文提出了一种新的框架NEURONS，它通过分步学习：关键物体分割、概念识别、场景描述和模糊视频重构四个相关子任务，来解耦视觉皮层的功能专业化。该框架能够生成更高质量的处理信号，以更好地重建视频，从而提高fMRI到视频的重建质量。此外，NEURONS通过模拟视觉皮层的功能专业化，实现了视频一致性和语义层次准确性上的显著提高，表现出与视觉皮层的强烈功能相关性，这有助于其在脑机接口和临床应用中的潜力。", "conclusion": "NEURONS框架在视频一致性和语义层次准确性方面显著优于现有的先进基线，其灵巧的方法特性和功能专业化模拟特性表明，在fMRI到视频重建中，模拟人类视觉皮层功能具有巨大的潜力。结果为脑机接口和临床应用提供了新路径，展示了该方法的有效性，同时开放了源代码和预训练模型权重以供研究者继续探索。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.07615", "html_url": "https://arxiv.org/abs/2505.07615", "title": "扩散责任：生成文本到音频扩散模型的能耗分析", "title_en": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models", "authors": "Riccardo Passoni,Francesca Ronchini,Luca Comanducci,Romain Serizel,Fabio Antonacci", "background": "文本到音频模型近年来成为了从文本描述生成声音的强大技术之一，但它们的高计算需求引发了关于能源消耗和环境影响的担忧。", "innovation": "本文分析了7个最先进的基于扩散的文本到音频生成模型的能耗情况，评估了生成参数变化对推理时能耗的影响，并寻求在所有选定模型中找到音频质量与能耗之间的最佳平衡。还通过帕累托最优解决方案探讨了性能与环境影响之间的权衡关系，为更高效的生成音频模型的发展提供了洞见。", "conclusion": "研究提供了对性能和环境影响之间权衡关系的见解，有助于更高效生成音频模型的发展。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.19982", "html_url": "https://arxiv.org/abs/2504.19982", "title": "TD-EVAL: 结合回合级精度与对话级对比重新审视任务导向对话评估", "title_en": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons", "authors": "Emre Can Acikgoz,Carl Guo,Suvodip Dey,Akul Datta,Takyoung Kim,Gokhan Tur,Dilek Hakkani-Tür", "background": "任务导向对话（TOD）系统正经历着由大型语言模型（LLMs）驱动的革命，然而这些系统的评估方法仍不足以应对其日益复杂的交互需求。传统的自动评估指标能够有效评估早期模块化系统，但这些指标仅聚焦于对话层面，无法检测到用户代理交互过程中可能出现的关键中间错误。TD-EVAL引入了一种两级评估框架，整合了细粒度回合级分析与全景对话级对比。这种框架在测试阶段能够识别传统指标遗漏的对话错误，并且比传统和基于LLM的指标更接近人类判断。", "innovation": "TD-EVAL是一种两级评估框架，它将细粒度的回合级分析与全景对话级对比结合起来。具体来说，TD-EVAL在回合 level 对每个回应从对话连贯性、后端知识一致性和政策合规性三个方面进行评估。同时，通过构建TOD Agent Arena（任务导向对话代理环境）使用两两比较法，提供对话级质量的量化指标。此框架在MultiWOZ 2.4和τ-Bench上的实验结果表明，TD-EVAL能够更准确地识别传统指标遗漏的对话错误，并优于传统和基于LLM的评估指标，展示了其新的评估范式和评估效能的提升。", "conclusion": "TD-EVAL通过结合回合级精度与对话级对比，提供了一种新的任务导向对话系统评估范式。该框架有效地评估了对话系统的各个级别，并且方便未来研究的使用。TD-EVAL具有高效性和准确性，不仅识别了传统评价指标未能捕捉的对话错误，还与人类判断高度一致，展示了其在任务导向对话系统评估中的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21042", "html_url": "https://arxiv.org/abs/2504.21042", "title": "什么隐藏在幕后？通过概念漂移评估AI训练和推理中的完整性和归因", "title_en": "What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift", "authors": "Jiamin Chang,Haoyang Li,Hammond Pearce,Ruoxi Sun,Bo Li,Minhui Xue", "background": "随着人工智能（AI）的广泛应用，人们对AI系统的可信性提出了越来越多的关注，尤其是在数据的完整性和透明度、用户隐私、系统稳健性和算法偏见方面。为了更好地评估这些威胁和问题的根源，研究人员提出了ConceptLens框架。该框架利用预训练的多模态模型来分析探针样本中的概念漂移，以识别整个系统中潜在危害的根本原因，并提供对抗措施的建议，从而提升公众对AI系统的信任度，促进AI技术的普及和进一步创新应用。", "innovation": "ConceptLens是一个通用框架，利用预训练的多模态模型分析探针样本中的概念漂移（Concept Shift），识别数据完整性威胁的根本原因，并能检测未修改但具有高风险的数据，通过在训练前过滤它们来防止潜在的数据注入攻击，从而避免可能带来安全风险的偏差。此外，它还能识别模型在数据不完整或不平衡训练下的弱点。更为重要的是，ConceptLens能够追踪模型过度依赖的关键概念和误导性概念，解释其对模型性能的影响，并发现生成内容中的社会偏见，从而提升AI系统的透明度和公平性，确保安全性和性能的优化。", "conclusion": "ConceptLens为评估和理解AI训练和推理中的完整性漏洞提供了强有力的工具，揭示了数据注入攻击、社会偏见和潜在安全风险，为提升AI系统的可靠性和透明度提供了关键见解。这促进了对AI系统的信任，加速了其应用的步伐，并推动了更多的创新。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06405", "html_url": "https://arxiv.org/abs/2410.06405", "title": "通过视觉变换器解决抽象与推理语料库的重要性和二维表示、位置和对象", "title_en": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects", "authors": "Wenhao Li,Yudong Xu,Scott Sanner,Elias Boutros Khalil", "background": "ARC（抽象与推理语料库）是用于评估人工智能系统视觉推理能力的一个流行基准。ARC任务要求通过少量输入-输出训练对在小2D图像上解决程序合成问题。先前无论是视觉变换器（ViT）还是其他先进模型，在ARC任务中表现都较差，尤其是在面对大量训练数据和无噪音映射时，也暴露出ViT架构内在的表示能力缺陷，使其无法揭示ARC任务中简单的结构化映射。", "innovation": "本文提出了ViTARC架构，这是一种针对视觉推理任务设计的视觉变换器风格模型。该模型通过像素级输入表示、空间感知的标记化方案和基于自动分割的对象位置编码等特征，提升了模型的视觉推理能力。实验证明，特定任务的ViTARC模型能够通过监督学习从输入-输出网格中达到接近100%的测试解题率，表明在视觉变换器中注入适用于抽象视觉推理的正确归纳偏置的重要性，即使训练数据充足且映射无噪音。", "conclusion": "ViTARC为基于变换器架构的视觉推理未来研究提供了坚实的基础，强调了在变换器中注入正确的抽象视觉推理归纳偏置的重要性，即使在充分的训练数据和无噪音映射情况下也是如此。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05470", "html_url": "https://arxiv.org/abs/2505.05470", "title": "Flow-GRPO: 通过在线强化学习训练流匹配模型", "title_en": "Flow-GRPO: Training Flow Matching Models via Online RL", "authors": "Jie Liu,Gongye Liu,Jiajun Liang,Yangguang Li,Jiaheng Liu,Xintao Wang,Pengfei Wan,Di Zhang,Wanli Ouyang", "background": "流匹配模型已在图像生成等任务中取得了一定成果，但这些模型通常缺乏有效的在线强化学习（Online RL）策略。现有的强化学习方法通常需要大量的预训练和采样，这使得推广到新任务时难以高效处理。", "innovation": "文章提出了Flow-GRPO，这是第一个将在线强化学习集成到流匹配模型中的方法。该方法采用了两种关键策略：（1）将确定性常微分方程（ODE）转换为等效的随机微分方程（SDE），以保持原模型在整个时间步的边缘分布，从而支持统计采样和强化学习探索；（2）降噪减少策略，减少了训练中的降噪步骤，同时保持原始推理时间步的数量，显著提高采样效率而不牺牲性能。", "conclusion": "实验表明，Flow-GRPO 在多项文本到图像任务中表现良好。特别是在复杂的组合生成中，RL 调优的 SD3.5 生成了近乎完美的对象计数、空间关系和细节属性，提高了 GenEval 准确率从 63% 到 95%。在视觉文本渲染中，其准确率也从 59% 提高到 92%，显著提升了文本生成质量。此外，Flow-GRPO 在提升人类偏好方面也取得了显著进展，而且几乎没有发生奖励剥削现象，即奖励的增加并未以显著降低图像质量或多样性为代价。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.23175", "html_url": "https://arxiv.org/abs/2503.23175", "title": "大型语言模型在网络安全威胁情报中不可靠", "title_en": "Large Language Models are Unreliable for Cyber Threat Intelligence", "authors": "Emanuele Mezzi,Fabio Massacci,Katja Tuma", "background": "近年来，有研究表明大型语言模型（LLMs）可以通过改善网络安全威胁情报（CTI）任务的自动化来解决数据洪泛的问题。本文作者推出了一种评估方法，不仅可以在零样本学习、少量样本学习和微调的情况下测试LLMs对CTI任务的性能，还能够量化它们的一致性和置信水平。", "innovation": "该研究提出了一种评估方法，允许在零样本学习、少量样本学习和微调的情况下测试LLMs对CTI任务的性能，并定量地评估它们的一致性和置信度。实验使用了三个先进的LLM和一个包含350份威胁情报报告的数据集，展示了LLMs在报告规模较大时无法保证足够的性能，且在某些情况下表现出不一致和过于自信的特征。少量样本学习和微调只有部分改善了结果，这引发了对在缺乏标记数据且置信度至关重要的CTI场景中使用LLMs的可能性的质疑。", "conclusion": "LLMs不能保证在实际大小的报告上达到足够的性能，同时表现出不一致性和过度自信。少量样本学习和微调只能部分改善结果，因此对在缺乏标签数据且置信度至关重要的CTI场景中使用LLMs的可行性提出了质疑。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17070", "html_url": "https://arxiv.org/abs/2503.17070", "title": "联邦学习中非IID数据影响的全面评估", "title_en": "A Thorough Assessment of the Non-IID Data Impact in Federated Learning", "authors": "Daniel M. Jimenez-Gutierrez,Mehrdad Hassanzadeh,Aris Anagnostopoulos,Ioannis Chatzigiannakis,Andrea Vitaletti", "background": "联邦学习（FL）允许在去中心化的客户端信息中协作进行机器学习（ML）模型训练，确保数据隐私。联邦学习的去中心化特性需要处理非独立且非同分布（non-IID）的数据，这导致了显著的问题，如模型性能下降和收敛时间增加。尽管这项工作十分重要，但系统地解决所有类型的数据异质性（即non-IID性）的实验研究仍然很少。本文旨在通过全面的经验分析来弥补这一差距，评估并量化non-IID效应对联邦学习模型性能的影响。", "innovation": "本文首次对联邦学习中的时空偏斜效应进行了全面分析。使用Hellinger距离（HD）测量不同客户端的数据分布差异，并对处理non-IID数据的四种最先进的策略进行了基准测试。研究成果突出了标签和时空偏斜non-IID类型对联邦学习模型性能的重要影响，特别是在特定HD阈值下出现显著性能下降，且当non-IID性极端时，联邦学习性能被严重影响。为此，本文提出了应对数据异质性的有效方法建议。", "conclusion": "本文代表了迄今为止联邦学习中非IID的各种最广泛的检验，为未来的研究提供了一个牢固的基础。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.16425", "html_url": "https://arxiv.org/abs/2412.16425", "title": "Patherea：面向20年代的细胞检测与分类", "title_en": "Patherea: Cell Detection and Classification for the 2020s", "authors": "Dejan Štepec,Maja Jerše,Snežana Đokić,Jera Jeruc,Nina Zidar,Danijel Skočaj", "background": "本文介绍了一个名为Patherea的统一框架，用于点基础上的细胞检测和分类。该框架支持当前最先进方法的发展与公平评估。为此，作者引入了一个大规模的数据集，该数据集模拟了Ki-67增殖指数估计的临床工作流程。同时，指出现有评价协议中存在共通的错误，并提供了一个标准化评估的基准工具。", "innovation": "Patherea框架直接预测细胞位置和类别而不依赖于中间表示。它采用了混合匈牙利匹配策略以实现精确的点分配，并支持灵活的骨干网络和训练方案，包括最新的病理学基础模型。Patherea在公共数据集Lizard、BRCA-M2C和BCData上取得了最先进的性能。此外，还提出了一个更具挑战性的Patherea数据集，并更新了基准评估工具，纠正了现有的评价错误。", "conclusion": "Patherea数据集和代码对进一步的研究和公平比较非常重要。该研究展示了Patherea框架在公共数据集上的良好性能，并揭示了数据集基准上的性能饱和现象。同时，它提供了一个更具挑战性的基准并改进了评估机制，增强了对研究成果的比较和评估。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03194", "html_url": "https://arxiv.org/abs/2506.03194", "title": "HueManity: 探测MLLMs的精细视觉感知", "title_en": "HueManity: Probing Fine-Grained Visual Perception in MLLMs", "authors": "Rynaa Grover,Jayant Sravan Tamarapalli,Sahiti Yerramilli,Nilay Pande", "background": "多模态大型语言模型（MLLMs）在高层次的视觉推理方面表现出色，但在细致的视觉感知任务上的表现仍然受到限制。本文介绍了HueManity，一个用于评估MLLMs视觉感知能力的基准。数据集包含83,850张嵌有Ishihara测试样式的点图案中包含双重字符字母数字字符串的图像，这些图像挑战模型对精确图案的识别。对九个最先进的MLLMs在HueManity上的评估显示，其表现明显低于人类和传统计算机视觉基准。性能最佳的MLLM在数值‘简单’任务上的准确率为33.6%，在字母数字‘困难’任务上的准确率为3%，而人类参与者几乎达到了满分（100%和95.6%），并且微调的ResNet50模型的准确率分别为96.5%和94.5%。这些结果突显了当前MLLMs在视觉能力方面的重要差距。进一步分析探索了可能影响MLLMs感知差距的架构和训练范式因素。", "innovation": "提出了HueManity，一个评估MLLMs视觉感知能力的基准。展示了不同于现有模型在细节视觉任务上的缺陷，并探索了相关因素。同时公开了数据集和代码，以促进进一步的相关研究.", "conclusion": "当前MLLMs在精细视觉感知方面仍存在重要差距。通过HueManity基准和进一步的研究，可以促进MLLMs视觉感知能力的提高。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02274", "html_url": "https://arxiv.org/abs/2505.02274", "title": "在自主车辆基于场景的测试中需要统计基础", "title_en": "On the Need for a Statistical Foundation in Scenario-Based Testing of Autonomous Vehicles", "authors": "Xingyu Zhao,Robab Aghazadeh-Chakherlou,Chih-Hong Cheng,Peter Popov,Lorenzo Strigini", "background": "基于场景的测试已作为自主车辆（AVs）安全性评估的常见方法出现，比基于里程的测试更高效，因为它专注于高风险场景。然而，关于其停止规则、残余风险估计、调试效果以及模拟保真度对安全声明影响的基本问题仍然存在。", "innovation": "本文认为，严格的统计基础是解决这些挑战和确保严格的安全性的必要条件。通过将AV测试与成熟的软件测试方法进行类比，识别出共同的研究缺口和可重用的解决方案。提出了概念性模型来量化每种场景的故障概率（pfs），并评估在不同条件下的测试效果。研究表明，基于场景的测试和基于里程的测试没有一种方法可以普遍优于另一种方法。此外，还提供了关于合成与真实测试结果对齐的正式逻辑分析示例，这是支持统计可辩护的基于模拟的安全声明的第一步。", "conclusion": "基于场景的测试和基于里程的测试在不同条件下没有一种方法可以普遍优于另一种。通过对合成和真实测试结果进行正式逻辑分析，进程了支持统计可辩护的基于模拟的安全声明的第一步。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09598", "html_url": "https://arxiv.org/abs/2505.09598", "title": "AI能耗到底有多高？LLM推理的能源、水和碳足迹基准测试", "title_en": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "authors": "Nidhal Jegham,Marwan Abdelatti,Lassad Elmoubarki,Abdeltawab Hendawi", "background": "本文介绍了一种新的基础设施感知基准测试框架，用于量化30个最先进的LLM推理模型在商业数据中心部署时的环境足迹。该框架结合了公共API性能数据、地区特定的环境乘数以及硬件配置的统计推断。通过交叉效率数据包络分析(DEA)，文章还对模型按相对于环境成本的性能进行了排名。结果显示，o3和DeepSeek-R1是最耗能的模型，每长提示消耗超过33 Wh，超过GPT-4.1 nano的70倍消耗，而Claude-3.7 Sonnet在生态效率方面排名最高。通过将单一短查询的0.42 Wh消耗扩展到每天7亿次查询，进一步得出了每年对环境有重大影响的结果，包括相当于35,000个美国家庭的电力使用、每年可供120万人饮用的淡水蒸发量以及需要相当于芝加哥大小森林来抵消的碳排放。", "innovation": "该研究提出了一种结合公共API性能数据、地区特定的环境乘数以及硬件配置的统计推断的新颖基础设施感知基准测试框架，利用交叉效率数据包络分析(DEA)对模型的环境和性能进行综合评估。", "conclusion": "研究结果表明，尽管AI变得更便宜、更快速，其全球采用依然导致了不成比例的资源消耗。该研究提供了一种标准化、基于实证的方法来评估LLM部署的可持续性，为未来的AI发展和可持续标准中的环境责任奠定了基础。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23603", "html_url": "https://arxiv.org/abs/2506.23603", "title": "SoK: Semantic Privacy in Large Language Models", "title_en": "SoK: Semantic Privacy in Large Language Models", "authors": "Baihe Ma,Yanna Jiang,Xu Wang,Guangsheng Yu,Qin Wang,Caijun Sun,Chen Li,Xuelei Qi,Ying He,Wei Ni,Ren Ping Liu", "background": "随着大型语言模型（LLMs）在敏感领域中的广泛应用，传统的数据隐私措施对于保护隐形、上下文相关或可推断的信息（我们定义为语义隐私）显得力不从心。本文旨在分析在LLM的输入处理、预训练、微调和对齐阶段中是如何产生语义隐私风险的，并提出以生命周期为中心的框架来进行这项分析。该研究还对关键攻击向量进行了分类，并评估了当前防御措施（如差分隐私、嵌入加密、边缘计算和遗忘机制）在应对这些威胁方面的有效性。", "innovation": "本文提出了一种以生命周期为中心的框架来分析LLMs的语义隐私风险，并详细分析了各种现有防御措施如何应对这些威胁。研究揭示了在语义层面保护方面的关键缺口，特别是在处理上下文推断和潜在表示泄漏方面。同时，作者指出了未来研究中需要解决的开放挑战，包括量化语义泄漏、保护多模态输入、平衡脱敏与生成质量以及确保隐私保护措施的透明性。", "conclusion": "本文旨在为设计适用于LLMs的健壮且语义感知的隐私保护技术的未来研究提供指导。通过明确当前防护措施的不足和指出未来研究中需要注意的关键领域，本文旨在为未来的研究奠定基础。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05566", "html_url": "https://arxiv.org/abs/2506.05566", "title": "ScaleRTL: 使用推理数据和测试时计算扩展LLMs以生成准确的RTL代码", "title_en": "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation", "authors": "Chenhui Deng,Yun-Da Tsai,Guan-Ting Liu,Zhongzhi Yu,Haoxing Ren", "background": "最近的大型语言模型（LLMs）在软件编码基准测试中达到了接近人类的性能，但在RTL（寄存器传输级）代码生成方面的效果受限于高质量训练数据的稀缺。尽管过去的努力已经微调了LLMs来执行RTL任务，但这些方法未能根本突破数据瓶颈，并且由于其非推理性质，缺乏在测试时间扩展的支持。", "innovation": "提出了ScaleRTL，这是第一个能够扩展高质量推理数据和测试时计算的RTL编码推理LLMs。具体来说，通过收集长推理链式追踪数据集，该数据集包含35亿个词元，并微调了一种通用的推理模型，从而得到能够在深层次RTL推理中表现出色的ScaleRTL模型。此外，还提出了一种新颖的测试时间扩展策略，通过迭代反思和自我纠正之前的推理步骤来延长推理过程，进一步提升了ScaleRTL的表现。", "conclusion": "实验结果表明，ScaleRTL在VerilogEval和RTLLM基准测试中达到了最先进的性能，分别优于18个竞争基线约18.4%和12.7%。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18384", "html_url": "https://arxiv.org/abs/2505.18384", "title": "进攻性网络安全代理的动态风险评估", "title_en": "Dynamic Risk Assessments for Offensive Cybersecurity Agents", "authors": "Boyi Wei,Benedikt Stroebl,Jiacen Xu,Joie Zhang,Zhou Li,Peter Henderson", "background": "基础模型日益成为自立的编程者，这引发了它们也可能自动执行危险的进攻性网络操作的担忧。当前前沿模型审核检查了这些代理的网络安全风险，但大多数都未能考虑到现实世界中对手的自由度。特别是，随着强大的验证器和经济激励，进攻性网络安全代理可以被意图不良者逐步改进。", "innovation": "该研究提出了一个扩大的威胁模型，强调对手在静态和非静态环境中的不同自由度，即使是在固定计算预算下。实验结果显示，即使计算预算较小（在研究中为8个H100 GPU小时），对手也可以改进代理的网络安全能力超过40%，并且无需外部协助。这一发现强调了评估代理网络安全风险应动态进行的重要性，以更全面地描绘风险。", "conclusion": "需要以动态方式评估代理的网络安全风险，从而提供更准确的风险画像。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10972", "html_url": "https://arxiv.org/abs/2506.10972", "title": "Predictable Scale: Part II, Farseer: A Refined Scaling Law in Large Language Models", "title_en": "Predictable Scale: Part II, Farseer: A Refined Scaling Law in Large Language Models", "authors": "Houyi Li,Wenzhen Zheng,Qiufeng Wang,Zhenyu Ding,Haoying Wang,Zili Wang,Shijie Xuyang,Ning Ding,Shuigeng Zhou,Xiangyu Zhang,Daxin Jiang", "background": "训练大规模语言模型（LLMs）的成本非常高，这导致了一个关键的扩展缺口：小型实验的见解往往无法在资源密集型的生产系统中转移，这阻碍了高效创新。Chinchilla的定律等现有的扩展定律在预测不同规模的性能时准确度不高，导致外推误差较大，使得跨不同规模设置评估训练策略变得不可靠。", "innovation": "我们提出了Farseer，一种新颖且完善的扩展定律，提高了在不同规模下的预测准确性。通过系统地构建模型损失表面L(N,D)，Farseer对实际数据的拟合度优于之前的方法，大幅降低了外推误差。这种方法使我们能够可靠地评估不同的训练策略，并允许从小规模的消融研究中得出的结论被外推以预测大型规模的性能。Farseer还提供了有关最优计算分配的新见解，更好地反映了现代大规模语言模型训练的复杂需求。", "conclusion": "为了验证我们的方法，我们训练了大约1,000个不同规模和配置的大规模语言模型，消耗了大约300万NVIDIA H100 GPU小时。我们将在https://github.com/examplerepo/Farseer公开所有模型、数据、结果和日志，以促进进一步的研究。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03034", "html_url": "https://arxiv.org/abs/2507.03034", "title": "在生成式人工智能时代重新思考数据保护", "title_en": "Rethinking Data Protection in the (Generative) Artificial Intelligence Era", "authors": "Yiming Li,Shuo Shao,Yu He,Junfeng Guo,Tianwei Zhang,Zhan Qin,Pin-Yu Chen,Michael Backes,Philip Torr,Dacheng Tao,Kui Ren", "background": "生成式人工智能时代极大地改变了数据的意义和价值。数据不再局限于静态内容，而是渗透到人工智能生命周期的每一个阶段，从塑造模型参数的训练样本来驱动实际应用中的模型部署的提示和输出。这种转变使得传统的数据保护概念变得不充分，而对于需要保护的数据边界也界定不清。因此，未能保护人工智能系统中的数据对社会和个人都可能造成严重后果，凸显了明确界定保护范围并严格执行数据保护的迫切需求。", "innovation": "本文提出了一个四级分类法，包括不可用性、隐私保护、可追溯性和可删除性，以捕捉现代生成式人工智能模型和系统中多样化的保护需求。该框架提供了整个AI管道的数据实用性和控制之间的权衡理解，涵盖训练数据集、模型权重、系统提示和AI生成内容。分析了每一层级的代表性技术方法，并揭示了监管上的盲区，使关键资产处于暴露状态。通过提供一个结构化的视角，使未来的AI技术和治理与可信赖的数据实践相一致，强调了重新思考现代AI技术中的数据保护的紧迫性，并为开发者、研究人员和监管者提供了及时的指导。", "conclusion": "该框架为明确界定并严格执行数据保护范围提供了结构化的理解，通过技术方法和层次划分揭示了监管盲区，并建议通过未来的AI技术和治理与可信赖的数据实践相一致来重新思考数据保护，为开发者、研究者和监管者提供了及时的指导。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00713", "html_url": "https://arxiv.org/abs/2506.00713", "title": "AKReF: 一种用于结构化论辩的论辩知识表示框架", "title_en": "AKReF: An argumentative knowledge representation framework for structured argumentation", "authors": "Debarati Bhattacharjee,Ashish Anand", "background": "本文提出了将论辩性文本转化为论辩知识图谱(AKG)的框架。AKReF框架通过扩展理论基础，使得AKG能够提供一个易于理解的论辩结构图形视图。其初始步骤从基本的论辩组件(AC)和论辩关系(AR)的标注开始，然后通过构建带有元数据属性的图知识库(KB)来丰富信息。应用模态演绎规则从KB生成论辩，最终创建AKG。AKG节点和边的属性捕捉了关键论辩特征，如前提类型、推理规则类型、攻讦类型等，从而识别以前未被检测到的攻讦行为，为论辩分析奠定基础，并准备进行诸如验证论辩一致性及识别修订机会等推理任务。AKG需要找到隐含的间接关系，这对推理过程至关重要。我们提出的AKG格式，带有标注的推理规则和模态演绎，有助于推理模型学习需要通过已有论辩及其相互连接进行推论的隐含间接关系。我们使用AAEC数据集中的文章来说明该框架，并展示了其在冲突集提取和最大可接受论辩集提取等复杂分析中的应用。", "innovation": "本文的创新在于提出了一种新的论辩知识表示框架AKReF，通过扩展理论基础，使论辩知识图谱能够提供易懂的论辩结构视图。AKReF框架能够标注论辩组件和关系，通过构建知识库图来丰富信息，并利用模态演绎生成论辩来构建AKG。AKG能够捕捉和展示论辩中的关键特征，包括前提类型、推理规则类型、攻讦类型等，这些特征能够识别之前无法检测到的攻讦行为。AKG还为推理模型学习隐含的间接关系提供了可能，这在论辩分析中尤为关键。", "conclusion": "AKReF为论辩研究提供了新的框架，通过将论辩性文本转化为论辩知识图谱，增强了论辩结构的可视化和分析能力。该框架特别适用于需要深入理解论辩结构和关系的任务，如验证论辩一致性、识别修订机会和进行更复杂的论辩分析。未来的研究可以进一步探讨如何利用AKG支持更复杂的推理任务，如自动构建冲突集和最大化可接受论辩集。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03220", "html_url": "https://arxiv.org/abs/2507.03220", "title": "Symbiosis: 多适配器推理与微调", "title_en": "Symbiosis: Multi-Adapter Inference and Fine-Tuning", "authors": "Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman", "background": "PEFT技术的流行促使了大量的适配器被创建，但是现有框架在支持使用多个适配器进行推理或微调时存在诸多不足。这些问题包括：需要为每个微调任务部署单独的基础模型实例，导致GPU内存消耗过大且利用率低；虽然一些流行的推理平台可以同时服务多个PEFT适配器，但无法独立管理资源或混合不同PEFT方法；推理和微调任务不能共享基础模型实例；没有提供用户隐私保护功能，因为用户可能不希望将微调参数曝露给服务提供商。", "innovation": "Symbiosis通过作为服务部署基础模型来解决上述问题，允许基础模型层跨多个推理或微调流程共享。其拆分执行技术解耦客户端特定适配器和基础模型的执行，提供灵活的资源管理选项，允许选择细调方法并实现性能目标。我们的方法对模型是透明的，且大多数在transformers库中的模型都能直接使用。", "conclusion": "Symbiosis方法在Llama2-13B上的评估表明，与基线相比，使用相同数量的GPU，在相同时间内，Symbiosis可以微调更多（4倍）的适配器。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23210", "html_url": "https://arxiv.org/abs/2506.23210", "title": "FedRef：基于参考模型的通信高效贝叶斯微调", "title_en": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model", "authors": "Taehwan Yoon,Bongjun Choi", "background": "联邦学习（FL）在分布式场景中用于训练人工智能（AI）模型，同时确保用户的隐私。在联邦学习场景中，服务器通常不会知道用户的原始数据。这种概念在数据隐私方面使AI训练过程变得高效。然而，从模型性能角度看，联邦AI模型可能无法充分满足AI用户的所有期望。此外，AI用户的需要差异很大，很难满足所有用户的需求。这些问题可以通过AI模型优化、微调或个性化来解决，以实现最佳模型性能。面对模型优化的挑战，我们提出了参考模型基联邦学习，以在每个周期中克服灾难性遗忘。该方法从贝叶斯参数高效迁移学习衍生而来，包含最优近邻项，并利用一个包含先前模型参数的参考模型。因此，该方法实现了高性能的模型并减少客户端计算成本。", "innovation": "该方法基于参考模型，通过贝叶斯参数高效迁移学习，引入最优近邻项来克服联邦学习中的灾难性遗忘问题。此方法在保留高性能模型的同时，降低了客户端的计算成本，实现了通信高效性。", "conclusion": "提出了参考模型基联邦学习方法，通过贝叶斯参数高效迁移学习实现模型的最优微调，解决了联邦AI模型的性能问题和客户端计算成本高的问题，实现了高性能、低计算成本的模型优化。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09477", "html_url": "https://arxiv.org/abs/2507.09477", "title": "向具有深度推理的自主RAG迈进：LLMs中RAG-推理系统的综述", "title_en": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs", "authors": "Yangning Li,Weizhi Zhang,Yuyao Yang,Wei-Chieh Huang,Yaozu Wu,Junyu Luo,Yuanchen Bei,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Chunkit Chan,Yankai Chen,Zhongfen Deng,Yinghui Li,Hai-Tao Zheng,Dongyuan Li,Renhe Jiang,Ming Zhang,Yangqiu Song,Philip S. Yu", "background": "检索增强生成(RAG)通过注入外部知识提高了大型语言模型(LLMs)的客观性，但对于需要多步推理的问题却力有未逮；相比之下，纯粹依赖推理的方法经常会生成虚假信息或混淆事实。本文综述了这两种方法，并从统一的推理-检索视角进行了综合。背景部分解释了RAG为何需要改进，以及单纯依赖推理方法的问题。", "innovation": "本文提出了高级推理优化RAG的每一步（增强推理RAG）、外部知识如何弥补推理中的缺失前提和扩展复杂推理的上下文（增强推理RAG）、以及结合搜寻和推理的新兴协同RAG-推理框架的整合。介绍了方法分类、数据集和开放挑战，指出了如何构建更有效、多模态适应、可信赖和以人为中心的RAG-推理系统的研究途径。", "conclusion": "本文综述了RAG-推理系统的研究进展，并提出了未来研究的方向，致力于构建更有效的、多模态适应的、可信的和以人为本的RAG-推理系统。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23836", "html_url": "https://arxiv.org/abs/2505.23836", "title": "大型语言模型常常知道自己正在接受评估", "title_en": "Large Language Models Often Know When They Are Being Evaluated", "authors": "Joe Needham,Giles Edkins,Govind Pimpale,Henning Bartsch,Marius Hobbhahn", "background": "如果人工智能模型能够检测到自己正在被评估，则评估的有效性可能会受到影响。例如，模型在评估期间可能会表现出系统性差异的行为，导致部署和治理决策的可信赖度降低。因此，研究团队探讨了前沿语言模型是否能够准确分类产生自评估或实际世界部署的对话脚本，这一能力被称为'评估意识'。", "innovation": "研究团队构建了一个由1000个来自61个不同数据集的提示和对话脚本组成的多样化基准，这些数据涵盖了公共基准、实际世界交互和支撑框架中的代理轨迹。前沿模型已经展示了显著的评估意识能力（如Gemini-2.5-Pro达到了AUC为0.83的水平），但尚未超越简单的手动基准。此外，研究还发现，在代理场景中，AI模型和人类在识别评估方面比在对话场景中表现更好，并进一步测试了模型是否能识别评估的目的。", "conclusion": "研究结果表明，前沿模型已经表现出显著的评估意识，虽然尚未达到超人类水平，但仍是一个值得关注的能力。研究团队建议在未来模型中跟踪这一能力。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10502", "html_url": "https://arxiv.org/abs/2507.10502", "title": "AI模型在生物学中的基准测试和评估：从CZI虚拟细胞研讨会的成果和建议", "title_en": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop", "authors": "Elizabeth Fahsbender,Alma Andersson,Jeremy Ash,Polina Binder,Daniel Burkhardt,Benjamin Chang,Georg K. Gerber,Anthony Gitter,Patrick Godau,Ankit Gupta,Genevieve Haliburton,Siyu He,Trey Ideker,Ivana Jelic,Aly Khan,Yang-Joon Kim,Aditi Krishnapriyan,Jon M. Laurent,Tianyu Liu,Emma Lundberg,Shalin B. Mehta,Rob Moccia,Angela Oliveira Pisco,Katherine S. Pollard,Suresh Ramani,Julio Saez-Rodriguez,Yasin Senbabaoglu,Elana Simon,Srinivasan Sivanandan,Gustavo Stolovitzky,Marc Valer,Bo Wang,Xikun Zhang,James Zou,Katrina Kalantar", "background": "人工智能在生物学中的应用前景广阔，但由于缺乏标准化且跨领域的基准测试，阻碍了构建稳健且可信的模型的能力。本次研讨会旨在克服这一挑战，召集了跨成像、转录组学、蛋白质组学和基因组学领域的人工智能和计算生物学专家，共同解决这一差距。", "innovation": "会议识别出技术性与系统性瓶颈，如数据异质性、噪声、可重复性挑战、偏见，以及公开资源碎片化的问题，并提出建立基准测试框架的建议，以便高效地比较生物系统任务和数据模态下的机器学习模型。通过促进高质量数据处理、标准化工具、全面的评估指标以及开放合作平台，旨在加速开发受信赖的AI驱动虚拟细胞基准测试。", "conclusion": "这些基准测试对于确保科学研究的严谨性、可重复性和生物学相关性至关重要，最终推动该领域向整合模型发展，这些模型能够驱动新的发现、治疗见解，并更深入地理解细胞系统。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08958", "html_url": "https://arxiv.org/abs/2507.08958", "title": "通过多智能体大型语言模型系统融合文献与宇宙", "title_en": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "authors": "Xiaowen Zhang,Zhenyu Bi,Patrick Lachance,Xuan Wang,Tiziana Di Matteo,Rupert A.C. Croft", "background": "随着宇宙学模拟及其相关软件的复杂性增加，物理学家面临着从大量文献和用户手册中筛选出不同模型和格式的仿真参数的挑战。将这些参数转化为可执行脚本是一个耗时且易出错的过程。为提高物理学研究的效率并加快宇宙学模拟速度，我们提出了一种多智能体系统——SimAgents，它能够自动化从文献中提取并配置仿真参数，并完成初步分析。SimAgents采用专门的物理推理LLM智能体，能够验证仿真软件并执行工具。这些智能体通过结构化通信协作，确保提取的参数具有物理意义、内部一致性和软件合规性。通过收集40多个来自Arxiv和领先期刊的论文中的宇宙学参数，我们构建了一个用于参数提取的评估数据集，涵盖了不同类型的模拟。实验结果表明SimAgents表现出色，证明了其加速科学研究的潜力。", "innovation": "SimAgents是一个多智能体系统，使用专门的基于物理推理的LLM智能体来自动化从文献中提取并配置仿真参数和初步分析。这些智能体通过结构化通信协作，确保了参数的物理意义、内部一致性和软件合规性。我们还构建了一个用于参数提取的评估数据集，涵盖了不同类型的模拟，证明了SimAgents的有效性。此外，所有的系统和数据集都是公开可用的。", "conclusion": "SimAgents在自动化宇宙学仿真参数配置和初步分析方面表现出强大的性能，证明了其能够显著加速科学研究。该系统通过多智能体协作和特殊的物理推理能力，提高了参数提取的准确性和效率。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10577", "html_url": "https://arxiv.org/abs/2507.10577", "title": "Truth Sleuth和Trend Bender：用于事实核查YouTube视频并影响意见的人工智能代理", "title_en": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "authors": "Cécile Logé,Rehan Ghori", "background": "当前数字世界中，虚假信息传播迅速，经常通过YouTube等平台扩散。因此，如何有效应对虚假信息成为一个重要议题。", "innovation": "本文提出了一种新颖的方法，通过开发一种结合检索增强生成（RAG）的AI系统来事实核查YouTube视频中的声明，并参与用户的评论区，挑战误导性叙事。该系统包括两个主要代理：Truth Sleuth和Trend Bender。Truth Sleuth从视频中提取陈述，并利用来自Wikipedia等资源的RAG方法评估其准确性，生成综合报告；Trend Bender则生成有针对性、说服力的评论，以促进生产性讨论。", "conclusion": "通过在基准数据集和YouTube上的实际部署中展示该系统的功能，并指出事实核查代理的高精度，本文证实了通过AI干预对抗虚假信息并促进更知情的在线空间的潜力。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10559", "html_url": "https://arxiv.org/abs/2507.10559", "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research", "title_en": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research", "authors": "Shomir Wilson", "background": "近期，大规模语言模型（LLMs）的发展引起了公众对自然语言处理（NLP）领域的广泛关注，这种兴趣在主流媒体中有所体现，有时会邀请NLP研究人员与公众分享他们的知识和观点。本文旨在回答当前形势下，NLP研究和个体研究人员的机会，通过分享向公众传达NLP能力和限制的建议来促进有效的公共沟通。", "innovation": "本文提出了关于传达NLP能力和限制给公众的建议，涵盖了三个主题：模糊术语作为公众理解的障碍，非合理的期望作为可持续发展的障碍，以及道德失败作为持续支持的障碍。通过例举出版的NLP研究和流行的新闻报道来说明这些主题。", "conclusion": "本文建议通过有效和透明的公共沟通来增强公众对NLP的理解，并鼓励对研究的支持。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09592", "html_url": "https://arxiv.org/abs/2507.09592", "title": "THOR: Transformer Heuristics for On-Demand Retrieval", "title_en": "THOR: Transformer Heuristics for On-Demand Retrieval", "authors": "Isaac Shi,Zeyuan Li,Fan Liu,Wenli Wang,Lewei He,Yang Yang,Tianyu Shi", "background": "该论文介绍了THOR模块，该模块是由eSapiens设计并实现的，目的是提供一种安全且可扩展的引擎，能够将自然语言问题转化为受验证的、只读的SQL分析查询，用于企业数据库。THOR模块的设计基于企业数据库查询需求和当前技术挑战，即需要一种既能准确处理复杂查询又能保持数据安全性的解决方案。这一解决方案需同时满足业务需求和技术实现的双重要求，因此设计了一种分阶段处理的架构来应对不同的查询和数据处理场景。", "innovation": "THOR模块设计了一个分阶段的执行架构，其中包括一监督者代理负责路由查询，模式检索动态添加表和列元数据，SQL生成代理输出受只读防护限制的单语句SELECT查询。该模块还集成了一个自我纠正和评级循环，可以捕捉空结果、执行错误或低质量输出，并最多尝试五次LLM驱动的再生尝试。结果解释代理则生成简洁的、易读的洞察，并将原始行传递给洞察和智能引擎用于可视化或预测。其创新之处在于嵌入了模式意识、容错执行和服务合规性防护，使得非技术人员也能以零SQL的简单性和企业级的安全性访问实时数据。这项技术突破了之前单纯依赖SQL查询的传统方式，提供了更高效的数据访问与分析方法。", "conclusion": "通过跨金融、销售和运营场景的烟雾测试，THOR模块展示了可靠地进行即席查询和自动定期报告的功能。该模块通过嵌入模式意识、容错执行和合规性防护，使非技术人员能够通过零SQL的方法访问实时数据，并确保企业级别的安全性，从而大大提高了查询效率和数据安全性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06273", "html_url": "https://arxiv.org/abs/2507.06273", "title": "磁辐射建模和人工神经网络优化在狭窄动脉域内生物流体流动的分析", "title_en": "Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain", "authors": "S P Shivakumar,Gunisetty Ramasekhar,P Nimmy,Sujesh Areekara,L Thanuja,T V Smitha,S Devanathan,Ganesh R Naik,K V Nagaraja", "background": "随着心血管疾病复杂性的增加和传统治疗方法的局限性，亟需发明新的药物输送系统，以确保靶向、有效和受控的治疗，直接贡献于联合国可持续发展目标3 (健康与福祉) 和目标9 (工业、创新和基础设施)，鼓励使用可持续医疗技术。这项研究旨在探讨插有狭窄的动脉域中Casson-Maxwell纳米流体的流动，详细分析了皮肤摩擦和热传递率。该纳米流体比标准Casson流体具有更低的速度分布，表明了更长的停留时间，有利于有效的药物传递。这些因素增加了对该领域多学科学习和创新协作的推动，并在磁场和热环境下，利用人工神经网络优化预测了热量流动。", "innovation": "该研究采用Casson-Maxwell流体模型，研究了狭窄动脉域内的纳米流体流动。通过详细探讨皮肤摩擦和热传递率，发现采用了Casson-Maxwell流体模型的纳米流体具有更低的速度分布，增加了药物传递的有效性。此外，通过磁辐射、线性热源和Casson-Maxwell参数的结合，使用Levenberg-Marquardt反向传播训练方案人工神经网络优化预测热流速，实现了高效的热量管理。研究表明，摩尔塞参数对阻力系数的影响最大。", "conclusion": "采用Casson-Maxwell纳米流体模型可以更有效地实现药物传递，从而改善心血管疾病的治疗效果。同时，利用人工神经网络优化方法准确预测热量流动，展示了在医疗技术领域应用可持续性和创新性的潜力。该研究支持了教育和国际合作的SDGs 4和17目标。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10594", "html_url": "https://arxiv.org/abs/2507.10594", "title": "扩展 OL-MDISF：针对混合类型、漂移和不完整流型特征的在线学习", "title_en": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features", "authors": "Shengda Zhuo,Di Wu,Yi He,Shuqiang Huang,Xindong Wu", "background": "在线学习适用于随时间变化的特征空间，因其灵活性而引起广泛关注。然而，它仍然面临三大挑战：现实世界数据流的异质性对传统参数建模构成挑战；数据流分布可能随时间发生迁移，导致模型性能急剧下降；时间与成本限制使得在监督设置中标注每条数据实例变得不切实际。", "innovation": "为克服这些挑战，本文提出了一种新的算法OL-MDISF，旨在放宽对特征类型、数据分布和监督信息的限制。该方法利用copula模型构建全面的潜在空间，使用自适应滑动窗口检测漂移点以确保模型稳定性，并根据几何结构关系建立标签邻近信息。", "conclusion": "通过理论分析和全面的实验结果，本文展示了模型的效率和有效性。该扩展提供了一篇独立的技术参考文献，涵盖了OL-MDISF在更广泛在线学习环境中的上下文分析，包括混合类型特征建模、概念漂移适应和弱监督的最新进展，并在14个真实数据集上进行了全面的实验，包括全程的CER趋势、消融研究、敏感性分析和时间组合动力学。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10678", "html_url": "https://arxiv.org/abs/2507.10678", "title": "基数加法背后对称性的群论分析及其对神经网络的可学习性", "title_en": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks", "authors": "Cutter Dawes,Simon Segert,Kamesh Krishnamurthy,Jonathan D. Cohen", "background": "神经网络在建模人类认知功能和人工智能方面面临着一个重大挑战，即设计能够高效学习支持根本泛化的函数的系统。在这一挑战的基础是发现和实现对称函数的能力。本文通过利用对称性的基数加法研究了根本泛化的典型例子。基数加法的一个核心特征是进位函数——当和超过基数模数时，将余数转移到下一个显著位置的特点。通过分析不同的进位函数，揭示了不同进位函数的选择如何影响神经网络学习对称性时的表现，从而探讨了对称性学习的归纳偏置问题。", "innovation": "本文通过对基数加法进行了群论分析，揭示了对于给定基数可以存在多种替代的进位函数，并提出了定量指标来描述这些不同的进位函数。作者进一步通过训练使用不同进位函数的神经网络来进行基数加法，并比较其学习效率和学习速度，发现简单的神经网络在适当的输入格式和进位函数下可以实现根本泛化，且可学习性紧密相关于进位函数结构。这些发现为认知科学和机器学习提供了新的见解。", "conclusion": "研究表明，即使简单的神经网络也能通过合适的输入格式和进位函数实现根本泛化。神经网络在对称性学习中的可学习性与进位函数结构密切相关。这些发现对认知科学和机器学习具有重要启示意义。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09888", "html_url": "https://arxiv.org/abs/2507.09888", "title": "NeuTSFlow：时间序列预测背后连续函数的建模", "title_en": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting", "authors": "Huibo Xu,Likang Wu,Xianquan Wang,Haoning Dang,Chun-Wun Cheng,Angelica I Aviles-Rivero,Qi Liu", "background": "时间序列预测是一个基本任务，具有广泛的应用，但传统方法通常将数据视为离散序列，忽略了它们作为连续过程的嘈杂样本的本质。连续的嘈杂观察结果不能唯一确定一个连续函数，而是对应于一组可能的函数。从数学角度来看，时间序列可以视为由共享概率测度控制的连续函数家族的嘈杂观察结果。因此，预测任务可以被重新表述为从历史函数家族到未来函数家族学习转换的关系。", "innovation": "提出了一种名为NeuTSFlow的新型框架，利用Neural Operators实现流匹配以学习历史和未来函数家族之间的测度路径。通过在无限维函数空间中参数化流动的速度场，NeuTSFlow超越了传统方法，这些传统方法专注于离散点上的依赖关系，直接建模函数级别的特征。", "conclusion": "在各种不同的预测任务上进行的实验表明，NeuTSFlow具有更高的准确性和鲁棒性，验证了函数家族视角的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10578", "html_url": "https://arxiv.org/abs/2507.10578", "title": "当且如何进行数据投毒攻击文本反转？", "title_en": "When and Where do Data Poisons Attack Textual Inversion?", "authors": "Jeremy Styborski,Mingzhi Lyu,Jiayou Lu,Nupur Kapur,Adams Kong", "background": "扩散模型（DMs）的鲁棒性受到毒化攻击的重大挑战。本文系统分析了在何时何地，当使用文本反转（TI）这一广泛应用的个性化技术时，投毒攻击会对文本嵌入产生影响。研究表明，DMs在各个时间步中表现出非均匀的学习行为，特别是在低噪声样本上。毒化攻击继承了这种偏差，在低时间步中注入恶意信号。进一步观察发现，恶意信号会将学习偏离训练数据中的相关概念区域，破坏TI过程。现有的防御措施效果有限，因此，需要新的方法来增强DMs的鲁棒性。科研人员提出了一个名为Safe-Zone Training (SZT)的新颖防御机制，包括JPEG压缩（削弱高频率毒化信号）、时间步中的高时间限制（避免低时间步中的恶意信号）和损失屏蔽（限制学习到相关区域）等三个关键组件。", "innovation": "提出了一个新颖的防御机制Safe-Zone Training (SZT)，包含三个关键组件：JPEG压缩，可以在一定程度上削弱高频率的毒化信号；时间步限制，避免在低时间步中学到恶意信号；损失屏蔽，限制学习关注于相关区域。SZT在多个毒化攻击方法的实验中展示了显著的防御效果，提升了生成质量，超越了以前的防御措施的效果。", "conclusion": "本文揭示了扩散模型在进行文本反转时对投毒攻击的脆弱性，并提出了一种名为Safe-Zone Training (SZT)的防御机制，该机制有效增强了扩散模型的对抗性攻击鲁棒性，尤其在防止毒化攻击方面取得了显著的效果。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10786", "html_url": "https://arxiv.org/abs/2507.10786", "title": "是在一直监视吗？是在一直倾听吗？：探索家用社交机器人的上下文隐私与安全顾虑", "title_en": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots", "authors": "Henry Bell,Jabari Kwesi,Hiba Laabadli,Pardis Emami-Naeini", "background": "随着人工智能（AI）和先进技术传感器的应用，社交机器人在美国消费者中引起了广泛关注。尽管这些机器人是传统智能家庭设备的自然进化形式，但它们广泛的数据收集功能、类人特征以及与环境互动的能力，使社交机器人成为更大的安全和隐私威胁。这些风险包括数据关联、未经授权的数据共享以及用户的物理安全和家庭安全问题。因此，研究美国用户的安全和隐私需求和担忧对于在这些设备处于美国市场商业化早期阶段时指导其设计是非常关键的。", "innovation": "研究团队通过19次半结构化访谈，揭示了社交机器人中用户的重要安全和隐私担忧。这些发现强调了透明度、易用性和强大的隐私控制措施对社交机器人普及的必要性。具体而言，参与者最担心教育场景中的误导信息问题以及医疗情景下的设备可靠性问题。此外，用户还担心社交机器人可能带来的数据推断问题。研究指出用户期望实际的隐私控制、数据收集的通知功能以及上下文适当的操作特性。", "conclusion": "重要的是，在社交机器人普遍化之前，设计时应考虑用户的隐私和安全需求，确保透明度、易用性和更强的隐私控制措施，尤其是在教育和医疗应用场景中，以提升用户对这些设备的信任度和使用意愿。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06852", "html_url": "https://arxiv.org/abs/2506.06852", "title": "基于多模态卫星星图像语义分割的位置预测自监督学习", "title_en": "Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation", "authors": "John Waithaka,Moise Busogi", "background": "卫星图像的语义分割对于地球观测应用至关重要，但受限于有限的标注训练数据。虽然Masked Autoencoders（MAE）等自我监督预训练方法前景光明，但它们主要集中在重建而非局部化，这是分割任务的基本要素。", "innovation": "本文提出将位置感知预测的自我监督学习方法LOCA（位置感知）应用于多模态卫星图像语义分割。方法通过将SatMAE（卫星MAE）的通道分组从多光谱扩展到多模态数据，有效处理多种模态，并引入相同的分组注意力遮罩，促进预训练期间跨模态交互。该方法采用相对补丁位置预测，鼓励空间推理进行局部化而非重建。", "conclusion": "我们的方法在Sen1Floods11洪水图册数据集上显著优于现有的基于重建的自我监督学习方法，证明了当适当适应多模态卫星图像时，位置预测任务能获得比重建方法更有效的语义分割表示。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11331", "html_url": "https://arxiv.org/abs/2507.11331", "title": "SystolicAttention: 将FlashAttention融合到单个 systolic 阵列中", "title_en": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "authors": "Jiawei Lin,Guokai Chen,Yuanlong Li,Thomas Bourgeat", "background": "Transformer模型主要依赖于缩放点积注意力（SDPA），通常使用FlashAttention算法实现。然而，当前的阵列式加速器（如基于Systolic阵列的加速器）在执行FlashAttention时面临重大挑战。Systolic阵列擅长处理连续和大规模的矩阵乘法，但对于FlashAttention所需要的频繁交错的矩阵乘法和softmax操作却不适应。频繁的数据交换会降低Systolic阵列的利用效率，而softmax涉及众多非矩阵操作，这些操作对于Systolic阵列来说并不理想。此外，Systolic阵列上的矩阵乘法和向量单元上的softmax操作的并行执行会导致寄存器文件和SRAM端口冲突，进一步降低性能。", "innovation": "我们提出了一种增强的Systolic阵列架构FSA，能够在单一Systolic阵列上执行整个FlashAttention算法，从而消除了对外部向量单元的需求。FSA的核心是SystolicAttention调度算法，它能够以细粒度的元素级重叠方式将FlashAttention操作映射到Systolic阵列上，大大提高了阵列利用率的同时保持了原始的浮点运算顺序，以维持数值稳定性。我们用综合RTL实现了FSA，并通过与顶级商业加速器的性能对比，展示了FSA相比Google TPUv5e在约10%面积开销下，分别实现了1.77倍和4.83倍更高的注意FLOPs/秒利用率。", "conclusion": "FSA不仅克服了Systolic阵列执行FlashAttention的现有挑战，还提高了性能和利用率，展示了在单一Systolic阵列上高效执行Transformer模型的可能性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11582", "html_url": "https://arxiv.org/abs/2507.11582", "title": "科学幻想短篇小说的主观评价特征分析及其批判理论意义", "title_en": "Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance", "authors": "Kazuyoshi Otsuka", "background": "本研究将大规模语言模型（LLMs）定位为“主观文学评论家”，用于探索文学评估中的审美偏好和评价模式。研究选取了十个日文科幻短篇故事，并将其翻译成英文，通过六款最先进的LLM在七个独立会话中进行评估。研究表明，不同LLM在评估一致性上存在显著差异，并且对故事的评估模式也有所不同。这些研究结果揭示了LLM评估中的人类批评流派特征，以及价值系统的惯性对其文学判断的影响，强调了LLM可能具有与人类类似但又有区别的评价特性，而不是简单的基准评测工具。", "innovation": "本研究创新在于提出了利用LLM作为‘主观文学评论家’来探索文学评估模式的新方法。研究团队通过多轮独立会话和特定协议，旨在最小化外部干扰因素，揭示了LLM评估风格与人类批评学派的相似性及差异性，并通过TF-IDF分析指出了不同模型的评估语言偏好。", "conclusion": "本研究得出结论，LLM在文学评估中表现出独特的评价特征，这与人类批评家有所不同，但具有显著的相似性。该研究不仅发现了LLM在文学判断中的个体特性，而且表明了LLM在评估一致性、评价模式和特定术语使用方面的潜力，对其本身的批判理论意义也进行了讨论。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10530", "html_url": "https://arxiv.org/abs/2507.10530", "title": "通过条件流匹配生成化学反应过渡态", "title_en": "Accurate generation of chemical reaction transition states by conditional flow matching", "authors": "Ping Tuo,Jiale Chen,Ju Li", "background": "过渡态（TS）结构定义了化学反应的动力学和能量障碍，但由于其短暂性，实验上难以捉摸，导致依赖于昂贵的高通量密度泛函理论（DFT）计算。传统的过渡态搜索方法如拥挤弹性和字符串方法通常需要迭代优化过程，时间成本高且精确性受限。虽然这些方法已经取得了良好的成果，但仍然缺乏一种能够实现亚埃精度、亚秒时间且广泛适应的自动生成方法，从而阻碍了对复杂反应网络的高效探索。", "innovation": "本文引入了TS-GEN，这是一种条件流匹配生成模型，能够直接将简单高斯先验分布中的样本映射到单个确定性过传输路中的过渡态鞍点几何结构。通过将反应物和产物结构嵌入作为条件信息，TS-GEN学会通过最优传输路径将潜在噪声转化为真实过渡态结构，从而替代了常见的迭代优化过程。TS-GEN实现了前所未有的准确性，实现了根均方偏差0.004埃（优于先前最先进的0.103埃）和平均势垒高度误差1.019 kcal/mol（优于先前的2.864 kcal/mol），同时仅需要每个推理0.06秒的GPU时间。超过87%生成的过渡态达到了化学准确性标准（误差<1.58 kcal/mol），远超现有方法。TS-GEN还表现出较强的跨分布外反应的可移植性。通过结合亚埃精度、亚秒速度和广泛适用性，TS-GEN将极大地促进复杂反应网络的高通量探索，为探索新的化学反应机制铺平道路。", "conclusion": "通过统一亚埃精度、亚秒速度和广泛的适用性，TS-GEN将极大提高复杂反应网络高通量探索的有效性，有望成为探索新的化学反应机制的有力工具。TS-GEN为化学反应过渡态的自动生成提供了一种新的高效方法，比现有的计算方法更为准确和快速，同时具有较好的泛化能力。该研究不仅提供了过渡态建模的新方法，而且对未来化学反应机制的研究具有重要的推动作用。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10136", "html_url": "https://arxiv.org/abs/2507.10136", "title": "一种PBN-RL-XAI框架用于发现黑色素瘤中的“击跑”治疗策略", "title_en": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma", "authors": "Zhonglin Liu", "background": "在转移性黑色素瘤中，对PD-1免疫疗法的固有抵抗力仍然是一个主要的临床挑战，其背后的分子网络尚未得到充分理解。我们利用患者肿瘤活检的转录组学数据构建了一个动态概率布尔网络模型，以阐明疗法响应的调控逻辑。", "innovation": "我们采用了一种强化学习代理来系统地发现最佳、多步的治疗干预方法，并使用可解释的人工智能来机制性解读代理的控制策略。分析表明，精确时机下4步短暂抑制LOXL2蛋白是最佳策略。我们的解释性分析表明，这种“击跑”干预足以消除驱动耐药性的分子特征，使网络能够自我修正，无需持续干预。", "conclusion": "本研究提出了一种新的、时间依赖性的治疗假设，以克服免疫治疗耐药性，并提供了一种强大的计算框架来识别复杂生物系统中的非显性干预协议。"}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11330", "html_url": "https://arxiv.org/abs/2507.11330", "title": "学术论文自动化新颖性评估：结合人类与大规模语言模型知识的协作方法", "title_en": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "authors": "Wenqing Wu,Chengzhi Zhang,Yi Zhao", "background": "传统上，学术论文的新颖性评估是由专家判断或通过独特的引用组合来衡量。这两种方法各有局限性：专家的知识有限，独特引用组合的效果也是不确定的，不明确独特引用是否真正反映了新颖性。同时，大规模语言模型拥有大量的知识，而人类专家具备大规模语言模型所缺乏的判断能力。因此，本研究将大规模语言模型和人类专家的知识和能力结合起来，以解决新颖性评估的局限性。", "innovation": "提出了一种结合人类知识和大规模语言模型来预测学术论文方法新颖性的方法。具体包括从同行评审报告中提取与论文新颖性相关的句子，使用大规模语言模型总结学术论文的方法部分，利用这些内容对预训练语言模型进行微调。同时，还设计了一个基于文本指导的融合模块，引入了新颖的稀疏注意力机制，以更好地整合人类和大规模语言模型的知识。", "conclusion": "实验结果表明，所提出的方法在性能上优于众多基线方法，展现了优异的表现。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11661", "html_url": "https://arxiv.org/abs/2507.11661", "title": "Partitioner Guided Modal Learning Framework", "title_en": "Partitioner Guided Modal Learning Framework", "authors": "Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi", "background": "多模态学习可以从多种模态信息中受益，并将学习到的模态表示分为单模态和配对模态特征。单模态特征通过单一模态训练学习，配对模态特征则通过跨模态交互学习。本文基于这一视角，提出了一个分隔器引导的模态学习框架，即PgM，该框架由模态分隔器、单模态学习者、配对模态学习者和单配对模态解码器组成。", "innovation": "本文创新性地提出了PgM框架，该框架具有三大关键优势：1）全面学习单模态和配对模态特征；2）为单模态和配对模态表示灵活调整分布，以适应不同下游任务；3）各模态和分区具有不同的学习速率。PgM在四种多模态任务中表现出了显著的有效性，并且能够将转移性应用到现有的模型中。", "conclusion": "通过PgM框架，该研究成功地展示了在多种模态任务中学习单模态和配对模态特征的有效性，并进一步证明了PgM在不同任务下的转移性应用。同时，通过可视化单模态和配对模态特征在不同模态和任务中的分布，研究人员提供了对其各自贡献的见解。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11809", "html_url": "https://arxiv.org/abs/2507.11809", "title": "Tracing Facts or just Copies？大规模语言模型机制竞争中的事实追踪或仅仅是复制？", "title_en": "Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models", "authors": "Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss", "background": "该论文旨在探讨大型语言模型（LLMs）在处理竞争性事实和反事实信息时的行为，特别是通过机制可解释性工具研究注意力头的作用。研究者试图复现Ortu等人、Yu、Merullo和Pavlick以及McDougall等人关于模型学习的事实与矛盾背景信息之间竞争的研究结果。", "innovation": "该研究特别关注了注意力头强度与事实输出比例之间的关系，评估了注意力头抑制机制的竞争假设，并调查了这些注意力模式的领域特异性。研究发现，促进事实输出的注意力头是通过一般性的复制抑制机制，而不是选择性地抑制反事实信息。此外，研究表明，注意力头的行为具有领域依赖性， Larger模型展现出更专业化和类别敏感的模式", "conclusion": "研究结果表明，增强注意力头会抑制正确事实，这暗示注意力头促进事实输出是通过普遍复制抑制而非选择性反事实抑制机制实现的。此外，注意力头的行为是领域特异性的，更大的模型表现出更专业化和类别敏感的模式。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11832", "html_url": "https://arxiv.org/abs/2507.11832", "title": "ILID: 印度语言原字符语言识别", "title_en": "ILID: Native Script Language Identification for Indian Languages", "authors": "Yash Ingle,Pruthwik Mishra", "background": "语言识别任务是自然语言处理（NLP）中的一个核心基础步骤。它常作为许多广泛使用的NLP应用的预处理步骤，例如多语言机器翻译、信息检索、问答和文本摘要。语言识别的核心挑战在于区分嘈杂、短小和混码环境中的语言。在印度众多存在词汇和语音相似性但又有显著区别的语言中，这一挑战尤为严峻。这些语言常常使用相同的书写系统，使得任务更加复杂。", "innovation": "本文发布了一个包含23万句子的数据集，其中包括英文和印度22种官方语言，并标注了相应的语言标识符，其中大多数语言的数据都是全新的。还开发并发布了一些鲁棒性的基线模型，这些模型采用最先进的机器学习和深度学习方法，可用于该领域的研究。基线模型在语言识别任务上的表现可与最先进的模型相媲美。", "conclusion": "基线模型对于提高印度语言识别技术的水平具有重要意义，可以为该领域的研究提供强有力的支持。数据集的发布为研究者提供了宝贵的数据资源，有助于改进印度语言识别技术，同时也推动了多语言和文化多样性在技术中的应用。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11851", "html_url": "https://arxiv.org/abs/2507.11851", "title": "您的LLM知道未来：发掘其多令牌预测潜力", "title_en": "Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential", "authors": "Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar", "background": "自回归语言模型受限于其固有的顺序性，一次只能生成一个词。这种范式限制了推理速度和并行性，尤其是在文本生成的后期阶段，文本的方向和语义已经较为确定时问题更加明显。", "innovation": "本文提出了一种新的框架，利用了普通自回归语言模型对未来词的固有知识，并结合多种技术实现同时预测多个后续词。该方法包含了以下几个关键创新：(1) 遮盖输入形式，多个未来词从公共前缀联合预测；(2) 门控LoRA形式可以保留原有语言模型的功能，同时为多词预测提供支持；(3) 轻量级可学习采样模块，从预测的未来词生成流畅序列；(4) 包括一致性损失在内的辅助训练损失集，以增强联合生成词的连贯性和准确性；(5) 一种推测生成策略，在未来扩展词汇量的平方，同时保持高保真度。该方法通过预训练模型的监督微调实现显著加速。", "conclusion": "该方法在生成代码和数学表达式方面几乎快了5倍，在通用聊天和知识任务上提高了近2.5倍。这些收益不损失质量。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11625", "html_url": "https://arxiv.org/abs/2507.11625", "title": "MapIQ: 评估大规模多模态语言模型在地图问题解答中的基准测试", "title_en": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "authors": "Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski", "background": "近期，多模态大型语言模型（MLLMs）的进步促使研究人员探索这些模型在解读数据可视化方面的表现，如直方图和散点图等。最近，研究关注地图视觉问答（Map-VQA），但主要集中在区域染色图（表现为单一主题类别和视觉分析任务）。研究发现，现有的Map-VQA方法对不同地图类型和复杂度的适应性不足。为了弥补这些不足，研究人员提出了MapIQ数据集，包含14,706个问题-答案对，覆盖三大地图类型：区域染色图、等值线图和比例符号图，涵盖六个独特主题（例如，住房、犯罪）。通过比较多种MLLMs在六个视觉分析任务上的性能，以及与人工基线进行比较，研究提供了关于MLLMs的鲁棒性、对地图设计变化的敏感性及其对内部地理知识的依赖性见解，并提出改进Map-VQA性能的方法。同时，实验还考察了地图设计变更对模型性能的影响。", "innovation": "引入了MapIQ数据集，该数据集包含多种类型的地图和广泛的主题，为地图视觉问答（Map-VQA）提供了更全面的评估框架。通过评价多种MLLMs，研究人员发现了这些模型在不同地图类型和视觉分析任务上的表现差异，从而开拓了提高Map-VQA性能的新途径。此外，研究人员还探讨了地图设计变更对这些模型性能的影响，为理解模型的鲁棒性和地理知识依赖性提供了新的视角。", "conclusion": "MapIQ数据集为评估和改进多模态大型语言模型的地图问题解答能力提供了有力的基准。研究发现，这些模型在处理不同类型的地图和复杂主题时存在显著差异，并揭示了其对内部地理知识的依赖性较强的特性。未来的研究可通过优化地图设计以改善这些模型的性能，或设计新的算法以减少这种依赖性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11867", "html_url": "https://arxiv.org/abs/2507.11867", "title": "COLA-GEC: 一种增强语法正确性与错误纠正的双向框架", "title_en": "COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction", "authors": "Xiangyu Yang,Xinying Qiu", "background": "在自然语言处理中，语法错误纠正（GEC）和语法可接受度判断（COLA）是两个核心任务，它们都依赖基础的语法规则，然而通常独立演进。", "innovation": "本文提出了一种名为COLA-GEC的新颖双向框架，通过双向的知识转移来提升两个任务。首先，通过使用GEC数据集增强语法可接受度模型，显著提升了多语言间的性能。其次，通过动态损失函数将语法可接受度信号整合到GEC模型训练中，有效引导纠正结果向语法可接受的方向发展。这种方法在多个语言基准测试中达到了最先进的成果。", "conclusion": "全面的错误分析指出了剩余的挑战，特别是在标点符号错误纠正，为未来的语法建模改进提供了见解。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11862", "html_url": "https://arxiv.org/abs/2507.11862", "title": "个人可识别信息识别领域的跨域迁移与少量样本学习", "title_en": "Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition", "authors": "Junhong Ye,Xu Yuan,Xinying Qiu", "background": "自动文本匿名化需要准确识别个人可识别信息(PII)，因此该领域的研究至关重要。现有的研究主要集中在单一领域的模型上，但跨领域迁移、多域数据融合以及少量样本学习对于提高PII识别效果具有潜在的积极作用。本文利用医疗、法律和生物三个领域的标注数据进行模型评估，以探讨这些方法的有效性.", "innovation": "本文创新性地结合了跨领域迁移、多域数据融合和少量样本学习技术，用于PII识别。使用I2B2（医疗）、TAB（法律）和Wikipedia（生物传记）三个领域的标注数据集进行模型训练和评估，分别衡量模型在同领域、跨领域迁移、数据融合以及少量样本学习等四个方面的能力.", "conclusion": "研究表明，法律领域的数据可以很好地迁移到生传记文本中，而医疗领域的数据则难以实现此类迁移。数据融合对识别效果的影响具有领域特异性，但在专一性较低的领域，仅需少量训练数据即可达到较高的识别精度."}
{"llm_update_time": "20250717", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10628", "html_url": "https://arxiv.org/abs/2507.10628", "title": "GHPO：提高LLM强化学习稳定性和效率的自适应指导", "title_en": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning", "authors": "Ziru Liu,Cheng Gong,Xinyu Fu,Yaofang Liu,Ran Chen,Shoubo Hu,Suiyun Zhang,Rui Liu,Qingfu Zhang,Dandan Tu", "background": "近日，验证奖励的强化学习（RLVR）已成为促进大型语言模型（LLMs）自我改进的强大范式，尤其是在复杂推理任务领域。然而，现有的在线策略强化学习方法在训练过程中常常遇到显著的训练不稳定性和效率低下问题，主要是由于能力-难度匹配不当，导致训练数据的复杂度常常超过了模型当前的能力，从而造成关键性的稀疏奖励信号，导致学习进展停滞不前。这种挑战对资源效率更高的小型LLMs尤为严重。", "innovation": "我们提出了一个新的自适应难度感知强化学习框架——Guided Hybrid Policy Optimization（GHPO）。GHPO通过适应性提示细化动态调整任务难度，提供有针对性的指导。该方法结合了直接模仿学习（对于当前模型难以解决的问题）和探索型强化学习（对于更易管理的任务），有效地创建了一个平滑且优化的学习课程。", "conclusion": "广泛的实验表明，GHPO在六个复杂数学基准测试中平均提高了约5%的性能，优于强大的在线策略强化学习和渐进式学习基线。进一步的分析证实，我们的框架显著提高了训练稳定性和最终推理性能，因此提供了一种可扩展且高效的方法来开发强大且可靠的推理模型。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11764", "html_url": "https://arxiv.org/abs/2507.11764", "title": "AI Wizards at CheckThat! 2025: 增强基于 Transformer 的嵌入以实现新闻文章中的主观性检测", "title_en": "AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles", "authors": "Matteo Fasulo,Luca Babboni,Luca Tedeschini", "background": "该研究参加了CLEF 2025的CheckThat！实验室任务1，专注于新闻文章中的主观性检测，并分类句子为主观或客观。训练和开发数据集涵盖了包括阿拉伯语、德语、英语、意大利语和保加利亚语在内的多种语言设置，最终评估还包括希腊语、罗马尼亚语、波兰语和乌克兰语等多种未见过的语言，以评估模型的一般泛化能力。为了应对多种语言中存在的类别不平衡问题，研究人员采用了基于开发集优化的决策阈值校准方法。实验结果表明，整合情感特征显著提高了性能，特别是对主观性F1分数的影响。该框架在希腊语中取得了显著的排名，达到了1st (宏F1 = 0.51)。", "innovation": "本文创新之处在于通过辅助情感模型的评分来增强基于Transformer的分类器，从而改进了标准微调。研究人员尝试了mDeBERTaV3-base、ModernBERT-base (英语)和Llama3.2-1B这三种基于Transformer的架构，展示了这一情感增强架构的有效性，并通过决策阈值校准优化方法处理了类别不平衡问题。这种方法显著提升了模型的性能，特别是在检测主观性方面表现明显增强。", "conclusion": "实验结果显示，情感特征的整合在提高模型性能方面取得了显著效果，尤其是对于主观性F1分数有了明显的提升。该框架在希腊语新闻文章的主观性检测任务中取得了显著的表现，获得了第一名的好成绩（宏F1 = 0.51），示了其在多语言环境中的广泛适用性和卓越效果。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11878", "html_url": "https://arxiv.org/abs/2507.11878", "title": "LLMs分别编码有害性和拒绝性", "title_en": "LLMs Encode Harmfulness and Refusal Separately", "authors": "Jiachen Zhao,Jing Huang,Zhengxuan Wu,David Bau,Weiyan Shi", "background": "先前的研究表明，大语言模型（LLMs）可以被训练来拒绝有害指令，但它们是否真正理解有害性而不是仅仅执行拒绝行为尚不清楚。现有的研究发现LLMs的拒绝行为可以由一个单一维度表示，即拒绝向量方向。然而，这种单一维度分析可能不足以全面理解模型的安全机制。本文旨在通过引入新的维度，即有害性方向，来更深入地探讨LLMs的内部控制机制，以便于识别和应对潜在的攻击手段，从而提高模型的安全性能。", "innovation": "研究识别了一个新的维度，即有害性方向，这是与拒绝方向分开的单独概念。通过操纵有害性方向，可以使LLMs将无害的指令误判为有害。研究还揭示了某些突破模型（jailbreak）方法的工作原理是降低了拒绝信号而不改变模型对有害性的内部信念。此外，对抗性微调模型以接受有害指令对模型对有害性的内部信念影响甚微。这些发现提供了一种实用的安全应用：模型的潜在有害性表示可以作为固有的安全防护（Latent Guard），用于检测不安全输入并减少过度拒绝，同时对抗微调攻击。例如，研究提出的Latent Guard在不同模型突破方法下的性能与专门的微调安全模型Llama Guard 3 8B相当或更好。", "conclusion": "研究发现LLMs对有害性的内部理解比它们的拒绝决定更加稳定，能够更好地应对广泛的输入指令，这为研究AI的安全性提供了新的视角。Latent Guard作为一种新的安全机制，可以有效检测不安全输入并减少模型的过度拒绝情况，特别是在面对模型突破攻击时具有良好的鲁棒性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11634", "html_url": "https://arxiv.org/abs/2507.11634", "title": "使用增量适应的跨语言少量样本学习进行波斯语情感分析", "title_en": "Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation", "authors": "Farideh Majidi,Ziaeddin Beheshtifard", "background": "该研究探讨了使用少量样本学习和增量学习方法进行波斯语情感分析。目的是开发一种模型，能够在有限的数据下进行波斯语情感分析，同时利用高资源语言的知识。", "innovation": "使用了三种预先训练的多语言模型（XLM-RoBERTa，mDeBERTa 和 DistilBERT），并采用少量样本和增量学习的方法对波斯语小样本数据进行了微调。这种方法展示了结合少量样本学习和增量学习与多语言预训练模型的有效性。", "conclusion": "实验结果显示，mDeBERTa 和 XLM-RoBERTa 达到了96%的波斯语情感分析准确性，表明其在少量数据和增量学习方法上的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11882", "html_url": "https://arxiv.org/abs/2507.11882", "title": "Marco-Bench-MIF：大规模语言模型多语言指令遵循能力的基准", "title_en": "Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models", "authors": "Bo Zeng,Chenyang Lyu,Sinuo Liu,Mingyan Zeng,Minghao Wu,Xuanfan Ni,Tianqi Shi,Yu Zhao,Yefeng Liu,Chenyu Zhu,Ruizhe Li,Jiahui Geng,Qing Li,Yu Tong,Longyue Wang,Weihua Luo,Kaifu Zhang", "background": "大规模语言模型的指令遵循能力已经成为评价标准。现有的数据集，如IFEval，要么以英语为主且缺乏多语言多样性，要么是机器翻译的其他语言版本，限制了它们在多语言环境中的应用。因此，需要一个综合的多语言数据集来更好地评估多语言环境下的大型语言模型的指令遵循能力。", "innovation": "本文提出了对IFEval数据集的扩展，创建了一个名为Marco-Bench-MIF的多语言版本，覆盖了30种不同语言，并采用了混合管道结合翻译与验证来解决语言和文化约束。此外，还发现机器翻译数据在评估准确性上比本地化数据低估7-22%，并指出了多语言指令遵循中的挑战，如关键词一致性保持和跨语言组合约束遵从性。", "conclusion": "通过Marco-Bench-MIF对20+大型语言模型进行全面评估，发现高/低资源语言之间的准确率差距为25-35%，模型规模大影响性能达45-60%，但存在特定字符系统的挑战，同时确认机器翻译数据低估了本地化数据的准确性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11875", "html_url": "https://arxiv.org/abs/2507.11875", "title": "DualReward：泊兹玛填空题误导词生成的动态强化学习框架", "title_en": "DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation", "authors": "Tianyou Huang,Xinglu Chen,Jingshen Zhang,Xinying Qiu,Ruiying Niu", "background": "该研究介绍了一种名为DualReward的新颖强化学习框架，用于自动生成泊兹玛填空题中的误导词。传统的做法主要依赖于监督学习或静态生成模型，而本方法则使用了具有自适应缩放特性的双奖励结构，能够区分人工创建的标准答案和模型生成的候选词。该框架根据模型性能和置信度动态调整奖励信号强度。研究者在泊兹玛段落级（CLOTH-F）和句子级（MCQ）填空测试数据集上评估了该方法，展示了其在先进基准模型上的持续改进。实验结果显示，该方法在同质数据集（CLOTH-F）上提供了适度但一致的好处，而在多样化的跨领域数据集（MCQ）上则表现出更显著的改进（P@1指标提升了3.48-3.86%），表明其特别适用于处理各种问题类型和领域。", "innovation": "提出了一种双奖励结构的强化学习框架，能够区分人工创建的标准答案和模型生成的候选词，基于模型性能和置信度动态调整奖励信号强度，适用于泊兹玛填空题的自动误导词生成。这种方法在同质和多样化的数据集上均表现出显著的性能提升，尤其是面对跨领域数据时，效果更为明显。", "conclusion": "本研究提供了一个灵活的框架，有效平衡了从可靠的人类示例中学习和探索新的高质量误导词之间的关系，特别适用于泊兹玛填空题的自动生成。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11694", "html_url": "https://arxiv.org/abs/2507.11694", "title": "ExpliCIT-QA: 可解释的基于代码的图像表格问答", "title_en": "ExpliCIT-QA: Explainable Code-Based Image Table Question Answering", "authors": "Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas", "background": "目前的端到端表格视觉问答（TableVQA）系统在解释性方面存在差距，难以提供透明且可审计的答案。ExpliCIT-QA 系统针对这一问题，通过建立一个多模态处理管道，目标是提高系统的解释性和透明度，以满足金融和医疗等敏感领域的审计需求。", "innovation": "ExpliCIT-QA 采用模块化设计，包含了多模态表格理解、基于语言的推理、自动代码生成、代码执行和自然语言解释五个步骤。这一系统的一个创新在于提供可追溯的中间输出、解析表格、推理步骤、生成的代码和最终答案，增强了系统的透明性和审计性。此外，利用多模态方法处理复杂的表格图像并在自然语言中生成逐步解释，进一步提高了系统的可解释性。", "conclusion": "通过在 TableVQA-Bench 上与现有基线的比较，ExpliCIT-QA 展示了在解释性和透明性方面的改进，这为金融和医疗等敏感领域提供了重要的审计机制。进一步地，此系统缩小了端到端 TableVQA 系统在解释性上的差距，为这些重要领域提供了一种更可靠的问答方式。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11742", "html_url": "https://arxiv.org/abs/2507.11742", "title": "CRABS: 一种语法语义夹钳策略以限制LLM对Python笔记本的理解", "title_en": "CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks", "authors": "Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher", "background": "评估、重用和适应用于新任务的Python笔记本中的数据科学和机器学习操作和信息流至关重要。传统的通过重新执行笔记本以调查的方法往往由于数据和软件依赖性的解决困难而不可行。大型语言模型（LLMs）在理解代码方面表现出色，但有时会因为幻觉和长上下文挑战而无法理解现实世界的笔记本。为了应对这些问题，该研究提出了一种以信息流图和对应的单元执行依赖图的形式理解笔记本的任务，并展示了一种结合有限的句法分析和LLM逐单元零样本学习的策略，该策略能够准确识别每个单元的真实数据输入和输出。研究使用了50个代表性的高评分Kaggle笔记本，并利用标注数据集评估了这种方法的有效性。", "innovation": "该研究提出了CRABS（信息捕获和解决辅助界定策略），这是一种结合浅层句法分析和LLM的策略。首先，CRABS通过分析抽象语法树（AST）捕捉单元间输入输出的正确解释，然后使用LLM解决剩余的歧义性，从而确定每个单元的真实数据输入和输出。这种方法有效地克服了大型语言模型对现实世界笔记本理解的局限性，并显著提高了信息流和执行依赖性的识别准确率。", "conclusion": "CRABS方法在50个代表性的高评分Kaggle笔记本上，平均F1得分为98%的信息流动识别准确率和99%的转换单元执行依赖性识别准确率。这表明CRABS方法能够有效且准确地识别笔记本中的信息流动和执行依赖性，并通过有限的句法分析和LLM的结合提高了大型语言模型对笔记本的理解。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11941", "html_url": "https://arxiv.org/abs/2507.11941", "title": "BlockBPE：并行BPE分词", "title_en": "BlockBPE: Parallel BPE Tokenization", "authors": "Amos You", "background": "在大型语言模型的消息管道中，分词是一个关键的预处理步骤。然而，目前广泛使用的实现方式仍然是CPU绑定的，这使得在GPU上的批量推理工作流程中效率低下。现有的基于Rust的分词器如HuggingFace Tokenizers和OpenAI的tiktoken，其运行时主要被正则表达式预分词阶段主导，呈现出$O(n\text{log}n)$的时间复杂度。", "innovation": "BlockBPE是一个针对GPU的并行实现的字节对编码（BPE）分词器，它在现实假设下实现了接近线性的时间复杂度，并且优化了高吞吐量的批量推理。它通过消除正则表达式预分词阶段，使得分词质量略有损失，但内部线程块中的令牌合并能够高度并行化，将整体复杂度减少至$O(nd)$，其中$d\text{远小于}n$。", "conclusion": "在高批量推理负载下，BlockBPE比tiktoken的吞吐量高2倍，比HuggingFace Tokenizers的吞吐量高2.5倍。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11954", "html_url": "https://arxiv.org/abs/2507.11954", "title": "查询驱动的知识图谱问答系统在大规模语言模型时代对于复杂和时间相关问题的好处", "title_en": "The benefits of query-based KGQA systems for complex and temporal questions in LLM era", "authors": "Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov", "background": "大语言模型在问答方面表现出色，但在多跳推理和时间相关问题上仍然存在挑战。现有方法如基于知识图谱的问答（KGQA）通过生成可执行查询而不是直接答案，为解决这些问题提供了模块化的替代方案。本文探讨多阶段查询驱动框架在维基数据问答中的应用，旨在提升复杂和时间相关问题场景下的性能。", "innovation": "提出了一个多阶段查询驱动的方法，提高了维基数据问答的性能，特别是在多跳推理和时间相关基准上的表现。引入了一个使用CoT推理的新型实体链接和谓词匹配方法，增强了系统的鲁棒性。实验结果展示了查询驱动的多阶段KGQA框架在小语言模型下的潜力，尤其是对于处理复杂和时间相关问题。", "conclusion": "通过泛化和拒绝学习研究，评估了多阶段查询驱动KGQA框架在多跳推理和时间相关问答数据集中的鲁棒性。结果表明，该方法具有提升复杂和时间相关问答任务的能力，且适用于小规模语言模型。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11953", "html_url": "https://arxiv.org/abs/2507.11953", "title": "IAM：大规模语言模型间注意力映射的高效推理", "title_en": "IAM: Efficient Inference through Attention Mapping between Different-scale LLMs", "authors": "Yi Zhao,Zuchao Li,Hai Zhao", "background": "大规模语言模型（LLMs）在资源消耗上面临巨大挑战，特别是在处理长上下文时。尽管已经做出了大量努力提高推理效率，现有方法主要依赖内部稀疏性进行优化，而没有充分利用外部信息。这些模型之间的注意力矩阵具有高相似性，提供了新的优化视角。本文分析了如何度量相似性、如何选择映射层以及映射的一致性问题，基于此提出了IAM框架，通过小规模和大规模LLMs之间的注意力映射，在加速注意力计算的同时减少了KV缓存的使用。实验结果显示，在不影响性能的情况下，IAM可以提升预填速度15%，并减少22.1%的KV缓存使用。", "innovation": "提出了IAM框架，通过从小规模和大规模LLMs之间的注意力映射，实现加速注意力计算和减少KV缓存使用的同时优化。这种方法创新性地利用了大规模语言模型之间的注意力矩阵的高相似性，提供了一种新的优化视角，且与现有的KV缓存优化方法兼容。", "conclusion": "IAM框架通过注意力映射，在加速预填和减少KV缓存使用方面取得了显著效果，同时保持了良好的性能。实验证明该方法具有广泛的适用性，并且可以与现有优化方法兼容，作为一种增强LLM效率的工具。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题求解是数学推理中的关键领域，广泛应用于教育、人工智能数学能力评估以及多模态能力评估。近年来，深度学习技术的迅速发展，特别是多模态大规模语言模型的出现，引发了该领域的研究热潮。", "innovation": "本文提供了深度学习在几何问题求解中的应用综述，包括(i)几何问题求解的相关任务综合总结；(ii)相关深度学习方法的全面审查；(iii)评估指标和方法的详细分析；(iv)当前挑战和未来方向的批判性讨论。并创建了一个持续更新的文章列表。", "conclusion": "本文旨在提供深度学习在几何问题求解中的全面实用参考，以促进该领域的进一步发展。已经创建了一个持续更新的论文列表在GitHub上：this https URL。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11966", "html_url": "https://arxiv.org/abs/2507.11966", "title": "对低资源粤语毒害内容可感知的少样本提示生成", "title_en": "Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation", "authors": "Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee", "background": "随着在线交流越来越多地包含未充分代表的语言和方言，标准翻译系统往往难以保留地方俚语、混合语法及文化嵌入的有害言论标记。对于低资源语言对之间的有害内容翻译，由于稀少的平行数据和能消除不当表达的安全过滤器，翻译额外提出了挑战。", "innovation": "本文提出了一种可重复使用的两阶段框架，用于在翻译中保留毒害内容，实验在混合粤语安全语料库上进行。首先，进行人工验证的少样本提示工程：迭代地整理和排序注释者选择的混合粤语目标示例，以捕捉细微的俚语、语气和毒害性。其次，通过基准测试多种大语言模型使用语义相似性，经直接和反向翻译进行模型-提示配对优化。", "conclusion": "定量的人类评估确认了我们管道的有效性和效率。通过提高翻译质量，我们的框架为多文化大语言模型的安全性做出了贡献，支持在低资源环境中进行有文化的调整和基准测试。通过将粤语作为包容性NLP的测试平台，我们强调在内容审核和区域平台治理等实际应用中保留社会语言学细微差别的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11942", "html_url": "https://arxiv.org/abs/2507.11942", "title": "DAC：一种动态注意机制导向的任务无关提示压缩方法", "title_en": "DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression", "authors": "Yi Zhao,Zuchao Li,Hai Zhao,Baoyuan Qi,Guoming Liu", "background": "任务无关的提示压缩通过利用自然语言中的冗余性来减少计算开销并增强提示中的信息密度，尤其是在长上下文场景中。现有方法主要依赖信息熵作为压缩度量标准，目标是在最小信息损失的情况下实现最小化文字单元压缩。但这些方法忽视了两个关键方面：（i）算法层面的重要性提示（attention-critical tokens）；以及（ii）压缩过程中的信息熵变化。", "innovation": "我们提出了一种动态注意机制导向的任务无关提示压缩方法（DAC），该方法有效结合了熵信息和注意信息，并动态感知压缩过程中熵的变化，以实现精细粒度的提示压缩。", "conclusion": "广泛的实验结果表明，DAC在LongBench、GSM8K和BBH等多个领域的各种任务和LLMs中均能保持一致的稳健和显着的改进，提供了其有效性的有力证据。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11979", "html_url": "https://arxiv.org/abs/2507.11979", "title": "基于价值观的大语言模型代理模拟以评估互信与人际关系亲密性", "title_en": "Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness", "authors": "Yuki Sakamoto,Takahisa Uchida,Hiroshi Ishiguro", "background": "大型语言模型（LLMs）作为模拟复杂社会现象的强大工具，可以通过具有特定特质的人类样本人工智能代理来实现。在人类社会中，价值观相似性对于建立信任和紧密关系至关重要，但尚未探索这一原则在由LLM代理构成的人工社会中的适用性。因此，本研究通过两个实验考察了价值观相似性对LLM代理间关系构建的影响。首先，通过初步实验评估了LLMs中价值观可控性的程度，以识别最有效的模型和提示设计；其次，在主要实验中生成了具有特定价值观的LLM代理对，并在其对话后分析了彼此之间的信任和人际关系亲密性的评估结果，实验在英语和日语中进行以考察语言依赖性。实验结果证实，价值观相似度较高的代理对表现出更高的互信和人际关系亲密性。这些发现显示了LLM代理模拟作为社会科学研究的有效测试床的价值，并为揭示价值观如何影响关系构建机制提供了线索，并为社会科学提供了新的理论和见解的启发基础.", "innovation": "本研究创新性地开发了基于价值观的LLM代理模拟，在未探索的LLM代理社会各界动态中的引入价值观相似性对关系构建的影响研究。并首次通过双实验验证了这种机制的有效性，不仅在跨语言（英语和日语）环境中进行了验证，还强调了语言在代理交互中的潜在影响", "conclusion": "本研究结果证实了，价值观相似度较高的代理对表现出更高的互信和人际关系亲密性。这表明，LLM代理模拟不仅是社会科学研究的有效测试平台，还能帮助解释价值观如何影响人际关系构建的机制，并为社会科学提供新的理论和见解。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11939", "html_url": "https://arxiv.org/abs/2507.11939", "title": "POLYCHARTQA: 使用多语言图表问答评测大型视觉-语言模型", "title_en": "POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering", "authors": "Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin", "background": "图表是广泛使用的解读和传递数据的媒介。然而，现有的图表理解基准大多是以英语为中心的，这限制了它们对全球受众的适用性和包容性。", "innovation": "该文提出了PolyChartQA，这是首个覆盖22,606个图表和26,151个问题-答案对的大型多语言图表问答基准。基准数据集包括10种不同的语言。它采用解耦的管道，将图表数据与渲染代码分离，允许通过简单的数据翻译和代码重用灵活生成多语言图表。同时，使用最先进的基于LLM的翻译技术，并在管道中严格控制质量以确保生成的多语言图表在语言和语义上的一致性。", "conclusion": "在开放源代码和闭源大型视觉-语言模型上的实验表明，英语及其他语言的表现存在显著差异，尤其是那些非拉丁字母书写系统下的低资源语言。该基准为推动全球包容性视觉-语言模型的发展奠定了基础。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12059", "html_url": "https://arxiv.org/abs/2507.12059", "title": "重新评估大规模语言模型推理方向的能力", "title_en": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "authors": "Anthony G Cohn,Robert E Blackwell", "background": "本文研究了28种大型语言模型（LLMs）在一系列经过精心设计的模板生成的基准测试中的表现，测试了它们在给定特定场景下判断正确方位词（CDs）的能力。这些模板允许有不同程度的变异，包括涉及代理的交通工具以及第一、第二、第三人的视角。即使较新的大型推理模型也无法可靠地为所有问题确定正确的方位词。这项研究总结并扩展了在COSIT-24会议上展示的早期工作内容。", "innovation": "与早期工作相比，该研究通过使用精心设计的模板对大量语言模型进行了大量测试，以便更好地理解这些模型在判断方向词方面的局限性和能力。特别是在不同的视角和交通工具方面，模型的表现有了新的发现。", "conclusion": "即使最新的大型推理模型也无法可靠地判断所有的方位词问题。这项研究的结果为改进此类模型提供了有价值的洞见，也突显了人类语言理解与机械处理之间的差距。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11981", "html_url": "https://arxiv.org/abs/2507.11981", "title": "简化使绝对主义者：简化语言如何降低由LLM生成的词义意识", "title_en": "Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions", "authors": "Lukas Ellinger,Miriam Anschütz,Georg Groh", "background": "大型语言模型（LLMs）能够为不同上下文提供准确的单词定义和解释。然而，定义的范围会因目标群体不同而变化，如儿童或语言学习者。对于多义词（同音词）尤其重要，简化定义可能会遗漏关键含义，误导信任LLM输出的用户。本研究评估了三种目标群体（普通成人、简化版和5岁解释等级）对多义词定义的质量影响，使用两个跨语言的评估数据集，比较了DeepSeek v3、Llama 4 Maverick、Qwen3-30B A3B、GPT-4o mini和Llama 3.1 8B的表现，结果显示简化会大幅降低定义的完整性，忽视多义性，增加误解风险。", "innovation": "研究使用了两种新的评估数据集，并通过LLM-as-Judge和人工标注测试了五种不同的LLM模型。研究发现，通过直接偏好优化微调Llama 3.1 8B显著提升了多义词响应质量，适用于所有提示类型，展示了在教育计算语言处理中平衡简化和完整性的必要性。", "conclusion": "简化显著降低了由LLM生成的多义词定义的完整性，微调Llama 3.1 8B显著改善了特定提示下的多义词响应，强调了教育计算语言处理中需要平衡简化和完整性的必要性，以确保所有学习者的准确和情境感知定义。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11959", "html_url": "https://arxiv.org/abs/2507.11959", "title": "基于两步幂次量化技术的大型语言模型后训练", "title_en": "PoTPTQ: A Two-step Power-of-Two Post-training for LLMs", "authors": "Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui", "background": "大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但也因所需的大量计算资源而难以部署。尽管前人提出了基于幂次（Power-of-two, PoT）量化的方法，能够有效利用固定点加法在CPU上进行解量化，但这种方法在GPU上的效果较差，原因在于符号位和顺序位操作的纠缠导致效率低下。因此，对具有极低精度数值格式的模型保持准确性的高效解量化方法仍有待探索和提出强大的解量化加速解决方案的需求仍然存在。", "innovation": "本文提出了一种新的基于幂次（PoT）量化框架，该框架能在极低精度的数字格式中保持顶级的准确性，并通过更高效的解量化实现更快的推理速度。提出了一个两步后训练算法：首先用一个鲁棒的起点初始化量化尺度，然后使用最小的校准集对这些尺度进行微调，该算法的性能超过了当前在整数量化中的最佳表现，尤其是在2-和3-比特格式等低精度情况下。这项新技术显著加快了浮点推理所需的解量化步骤，在NVIDIA V100上实现了3.67倍的速度提升，在NVIDIA RTX 4090上实现了1.63倍的速度提升，与均匀整数解量化相比。", "conclusion": "提出的基于幂次后训练技术能够在低精度格式中保持模型的高准确度，并通过更高效的解量化实现快速推理。这一技术可以广泛应用于LLMs的部署，提高其计算效率和部署的可行性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11972", "html_url": "https://arxiv.org/abs/2507.11972", "title": "使用大型语言模型和眼动追踪生物标志符进行阅读理解分析的图表示方法", "title_en": "Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker", "authors": "Yuhong Zhang,Jialu Li,Shilai Yang,Yuchen Xu,Gert Cauwenberghs,Tzyy-Ping Jung", "background": "阅读理解是人类认知发展中的一项基本技能。随着大型语言模型（LLMs）的进步，人们越来越需要比较人类与LLMs在不同情境下对语言的理解，并将这种理解应用于诸如推断、情感解读和信息检索等功能任务中。以往的研究使用LLMs和人类生物标志物来研究阅读理解过程，结果显示与推理目标高度相关和低相关的词语对应的生物标志物在眼动追踪数据验证下呈现出不同的模式。但是，仅关注个别词语限制了理解的深度，导致结论相对简单但具有潜在的重要意义。", "innovation": "本研究使用基于LLM的AI代理将阅读段落中的词语分组为节点和边，形成基于语义意义和问题导向提示的图状文本表示。然后比较重要节点和边的注视分布。研究发现，LLMs在图拓扑结构层次上的语言理解表现出高一致性。这些结果在前期工作基础上进一步揭示了有效的人机协同学习策略。", "conclusion": "本研究通过使用LLM和眼动追踪生物标志符，结合图表示方法，揭示了LLMs在阅读理解过程中的语言理解一致性，并提出了有效的人机协同学习策略。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12075", "html_url": "https://arxiv.org/abs/2507.12075", "title": "BOOKCOREF：在书籍规模上的共指消解", "title_en": "BOOKCOREF: Coreference Resolution at Book Scale", "authors": "Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli", "background": "现有的共指消解系统通常是在小到中等规模的文档基准上进行评估。但在评估长文本时，现有基准（如LitBank）在长度上仍有限制，并不能全面评估系统的长文档共指消解能力，尤其是当共指提到跨越几十万个标记时。为了填补这个空白，首先提出了一种新的自动管钥程序，以高质量的共指消解注解生成全叙述性文本。然后，通过这种方法创建了第一个全书规模的共指基准BOOKCOREF，平均文档长度超过20万个标记。进行了一系列实验，展示了自动程序的稳健性，并证明了该资源的价值，使得当前的长文档共指消解系统在评估全书时可以获得高达+20 CoNLL-F1点的提升。此外，还报告了这种前所未有的全书规模设置带来的一系列新挑战，指出当前模型无法在较短文档上的性能得到同样的表现。", "innovation": "提出了一种新的自动管道，用于生成高质量的全叙述性文本共指消解注解，然后利用这种方法创建了第一个全书规模的共指基准BOOKCOREF，扩大了评估长文本能力的范围。该资源能够显著提升当前长文档共指系统的性能，同时揭示了当前模型的局限性。", "conclusion": "通过发布的数据和代码，鼓励对该领域的研究和新全书规模共指消解系统的开发。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12126", "html_url": "https://arxiv.org/abs/2507.12126", "title": "IASR评估框架用于无结构调查数据建模与分析", "title_en": "Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis", "authors": "Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta", "background": "在自然语言处理（NLP）中，文本数据扩增是一种常用的缓解数据稀疏性的策略，特别适用于资源有限的环境。现有技术虽然可以提高输入多样性并增强下游解释性，但缺乏确保在大规模或迭代生成过程中语义一致性的方法，导致输出数据的冗余和不稳定。", "innovation": "本文引入了一个针对大规模语言模型（LLM）文本扩增的原理性评估框架，包括（1）可扩展性分析，用于衡量随扩增规模增加的语义一致性，（2）递归扩增与总结改进（IASR），用于评估递归改写循环中的语义漂移。实验结果显示，GPT-3.5 Turbo在语义准确度、多样性和生成效率方面表现最佳。将该方法应用于增强的Few-Shot BERTopic主题建模，结果显著提高了主题细化程度，并完全消除了主题重叠。", "conclusion": "提出的框架验证了在实际NLP管线中用于结构化评估LLM扩增的有效性，通过IASR评估流程不仅提高了模型性能，还提高了实际应用中的主题建模效率和精度。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12261", "html_url": "https://arxiv.org/abs/2507.12261", "title": "Infherno：基于代理的端到端自由格式临床笔记到FHIR资源合成", "title_en": "Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes", "authors": "Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer", "background": "HL7 FHIR标准已成为复杂健康数据之间互操作性的首选格式。先前试图自动将自由格式的临床笔记转换为结构化的FHIR资源的方法主要依赖于基于模块和规则的系统或经过指令调优和约束解码的LLMs。这些方法经常面临泛化能力有限和结构不符合的问题，因此本文提出了一个基于LLM代理、代码执行和医疗术语数据库工具的端到端框架，旨在解决这些问题。", "innovation": "本文提出的方法名为Infherno，它基于FHIR文档模式，并且在预测来自非结构化文本的FHIR资源方面与人类基准相当。实施特点是前端支持自定义和合成数据以及本地和专用模型，有助于临床数据整合和机构间的互操作性。Infherno与现有的基于规则或调优的LLM方法相比，提出了新的方法以更好地处理自由格式临床笔记转换为结构化FHIR资源的问题。", "conclusion": "Infherno通过提供一个端到端的框架，使自由格式的临床笔记能够有效地转换为FHIR资源，展示了在医疗健康领域内实现无缝互操作性的潜力。该研究为推动临床数据整合和改进医疗服务质量提供了新的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12260", "html_url": "https://arxiv.org/abs/2507.12260", "title": "翻译症指数：使用似然比进行分等级且可泛化的翻译症度量", "title_en": "Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese", "authors": "Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu", "background": "目前缺乏一种量化翻译症的方法，作者提出了一种新的量化翻译症的指标——翻译症指数（T-index），该指标基于两个对比性微调的语言模型的似然比计算，用于分级和可泛化的翻译症测量。之前的研究中，尚未明确提出能够定量测量翻译症的指标，且翻译症的具体表现及影响因素复杂，需要开发一种高效且可靠的度量方法来评估翻译文本与目标语言的自然流畅程度之间的差距。", "innovation": "作者提出了一种全新的度量翻译症的方法——T-index，该方法使用两个对比性微调的语言模型来计算翻译文本的似然比，以定量评估翻译文本中的翻译症程度。T-index的关键创新在于它能够跨域泛化且测量结果可靠，并通过合成数据集和实际翻译数据集验证了其有效性。此外，T-index与现有的机器翻译质量评估指标（如BLEU和COMET）的相关性较低，表明T-index能够提供独特的信息，可以作为补充度量工具用于机器翻译质量评估领域。", "conclusion": "研究成果表明，即使只使用小型微调的模型，T-index也能有效捕捉现实世界中翻译文本的翻译症程度，并且相对差值和绝对值均能与人类评估高度相关（Pearson’s r = 0.568）。该研究提出的一种新的量化方法填补了量化翻译症领域的空白，并展示了其在机器翻译质量评估中的潜在应用价值。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12217", "html_url": "https://arxiv.org/abs/2507.12217", "title": "向低资源环境下的单字阅读评估的少量样本方法研究", "title_en": "Towards few-shot isolated word reading assessment", "authors": "Reuben Smit,Retief Louw,Herman Kamper", "background": "本文探讨了一种无需自动语音识别(ASR)的方法，用于低资源环境下的孤立词阅读评估。该方法基于少量成人提供的参考模板，将输入儿童语音与这些模板进行比较。此方法使用大型半监督学习模型的中间层对输入和模板进行编码。通过使用南非儿童语音基准测试，研究了设计选择如离散化半监督学习特征以及模板的重心平均。理想化的实验显示，这种方法在成人输入时表现良好，但在儿童输入时表现较差，即使使用了儿童模板。", "innovation": "本文提出了一种新的少量样本方法来评估儿童孤立词阅读，通过与成人提供的参考模板进行比较，使用大型半监督学习模型的中间层对输入和模板进行编码，尤其是在使用了离散化特征和重心平均模板的情况下。", "conclusion": "虽然半监督学习表示在低资源语音任务中取得了成功，但本研究表明，在少量样本分类系统中处理儿童数据时，半监督学习表示存在局限性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12004", "html_url": "https://arxiv.org/abs/2507.12004", "title": "使用表示分析提高神经语言模型的数据和参数效率", "title_en": "Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis", "authors": "Josip Jukić", "background": "本文探讨了神经语言模型中数据和参数效率的相关挑战，重点关注表示分析以及新的优化技术的引入。研究的第一部分考察了神经模型中语言表示的属性和动态特性，强调它们在增强模型鲁棒性和泛化能力方面的重要性。随后提出了基于表示平滑性的创新方法，包括利用雅可比矩阵和海森矩阵的正则化策略，以稳定训练过程并减少对输入扰动的敏感性。第二部分致力于通过将主动学习策略与参数有效微调相结合来显著提高数据和参数效率，此结合由表示平滑性分析的洞见指导。该部分提出了一些反馈机制，可以在无需标注验证集的情况下设计平滑性导向的提前停止技术，并提出了主动学习与参数有效微调的创新组合，以减少标注努力和计算资源。第三部分研究了通过上下文学习强化的弱监督技术，有效利用未标注数据，进一步减少对大量标记数据的依赖。研究显示，将上下文学习作为弱监督机制可以使模型在有限的标注数据中更好地泛化，通过充分利用未标注示例来提高训练效果。", "innovation": "创新包括：1. 基于表示平滑性的创新正则化策略，利用雅可比矩阵和海森矩阵来稳定训练和减少输入扰动的敏感性。2. 结合主动学习策略与参数有效微调，以减少标注努力和计算资源。3. 强化弱监督技术结合上下文学习，有效利用未标注数据，增强模型的泛化能力和适应性，尤其是在资源有限和动态数据环境中表现出色。", "conclusion": "实验结果表明，这些结合的方法在性能、稳定性和效率方面显著优于传统方法。特别是，通过上下文学习加强的弱监督技术，在低资源环境下展现出显著改进，从而使模型更具适应性和鲁棒性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12208", "html_url": "https://arxiv.org/abs/2507.12208", "title": "行为翻译风格空间：模拟人类翻译生产中的情感、行为和认知的时间动态", "title_en": "Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production", "authors": "Michael Carl,Takanori Mizowaki,Aishvarya Ray,Masaru Yamada,Devi Sri Bandaru,Xinyue Ren", "background": "本文介绍了一种行为翻译风格空间（BTSS），该空间描述了可能的行为翻译模式。作者认为，可在执行翻译物理操作时观察到的行为，如眼睛和手指的移动，都是由更高的认知过程和情感翻译状态引起的。通过分析记录的按键和注视数据，将行为模式组织成一个多层嵌入的BTSS，以揭示隐藏在背后的心理处理结构。BTSS为模拟人类翻译生产中情感、自动化行为和认知的时间动态提供了基础。", "innovation": "提出了一个分层级的BTSS结构，该结构不仅描述了行为翻译模式，还涵盖了从简单到复杂的嵌入式处理层。这对于理解人类在翻译过程中的具体行为提供了新的视角，通过记录的眼动和按键数据，揭示了内在的心理处理结构。这是一种新的方法来模拟翻译生产中情感、自动化行为和认知的时间动态变化。", "conclusion": "本文对人类翻译过程中情感、行为和认知时间动态的模拟建立在多层次嵌入式的BTSS上，通过行为模式，特别是通过记录的按键和眼动数据，捕捉和描述潜在的心理处理过程。该方法为理解和模拟人类翻译生产提供了新的视角和工具。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12252", "html_url": "https://arxiv.org/abs/2507.12252", "title": "通过大规模语言模型进行多粒度融合以提高上下文相关的自动语音识别", "title_en": "Improving Contextual ASR via Multi-grained Fusion with Large Language Models", "authors": "Shilin Zhou,Zhenghua Li", "background": "虽然端到端的自动语音识别（ASR）模型在转写通用语音方面表现出色，但在准确识别上下文相关的关键词，如专有名词或用户特定的实体方面往往存在困难。先前的研究通过在文本模态中利用关键词字典来提高关键词的识别率，这些方法或通过token级别的融合引导逐个token的生成，或通过短语级别的融合直接复制关键词短语。然而，这些方法分别在不同的粒度上运行，并且各有局限性。因此，该研究提出了一个新的多粒度融合方法，利用大规模语言模型（LLMs）并同时结合token级别的融合和phrase级别的融合。该方法采用了一种晚期融合策略，优雅地结合了ASR的声学信息和LLMs丰富的上下文知识，平衡了细粒度token精度和整体短语理解之间的关系。实验显示，该方法在中文和英文数据集上在关键词相关指标上取得了最先进的性能，同时保持了非关键词文本的高精度，进一步的消融研究证实了token级别的和phrase级别的组件在性能提升中都有显著贡献，在联合多粒度框架中相互补充。", "innovation": "该研究提出了一种新颖的多粒度融合方法，利用大规模语言模型（LLMs）并结合token级别的融合和phrase级别的融合，通过晚期融合策略实现了ASR与LLMs之间的优雅结合，从而在保留非关键词文本高精度的同时，显著提高了关键词识别的性能，达到了最先进的指标。", "conclusion": "实验结果表明，该方法在关键词识别方面取得了最先进的性能，同时保持了非关键词文本的高准确度。消融研究进一步证明了token级别的和phrase级别的组件在性能提升中都起到了显著的贡献。该方法的代码和模型将公开发布，并可在提供的链接中找到。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12295", "html_url": "https://arxiv.org/abs/2507.12295", "title": "Text-ADBench: 基于LLM嵌入的文本异常检测基准", "title_en": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding", "authors": "Feng Xiao,Jicong Fan", "background": "文本异常检测是自然语言处理（NLP）中的关键任务，应用于欺诈检测、虚假信息识别、垃圾邮件检测和内容审核等。尽管大型语言模型（LLMs）和异常检测算法取得了显著进展，但由于缺乏标准和全面的基准测试，限制了现有异常检测方法在文本数据上的严格比较和创新方法的发展。本工作旨在进行一个全面的经验研究，并引入一个基于文本异常检测的基准，利用预训练语言模型的不同嵌入跨越广泛文本数据集。本研究系统地评估了基于嵌入的文本异常检测的有效性，包括早期语言模型（GloVe, BERT）；多种LLMs（LLaMa-2, LLama-3, Mistral, OpenAI（小型、ada、大型））；多领域文本数据集（新闻、社交媒体、科学出版物）；以及全面的评估指标（AUROC, AUPRC）。", "innovation": "本工作引入了一个新的基准来评估文本异常检测的有效性，包括利用多个不同模型的嵌入进行广泛文本数据集的异常检测研究，涉及从早期到最新LLM的嵌入及多种领域的文本数据。此外，本研究揭示了文本异常检测中嵌入质量对检测性能的显著影响，且基于深度学习的方法并未显示出在使用LLM时比传统浅层算法（如KNN, Isolation Forest）具备性能优势。研究中还发现，跨模型性能矩阵具有低秩特性，这为实际应用中的快速模型评估（或嵌入评估和选择）提供了高效策略。通过开源包含所有不同模型嵌入以及相关代码的基准工具包，本研究为未来在稳健和可扩展的文本异常检测系统中的研究奠定了基础。", "conclusion": "本研究通过全面的经验分析引入了一个新的基准——Text-ADBench，利用多个非统一定制的预训练语言模型嵌入进行文本异常检测，提供了对大规模文本数据集的系统性评估。研究表明，嵌入质量对异常检测效果至关重要，并提出了一个高效的策略来快速评估和选择模型。未来的研究可以在开源平台上进一步探索和改进文本异常检测系统。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12372", "html_url": "https://arxiv.org/abs/2507.12372", "title": "基于网络浏览的大型语言模型可以访问社交媒体资料并推断用户的人口统计特征", "title_en": "Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics", "authors": "Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei,Mohsen Mosleh", "background": "传统的大型语言模型（LLMs）依赖于静态训练数据，这意味着它们的知识是受限于固定的快照。最近的进展使LLMs能够上网浏览，能够在实时信息获取和基于当前网络内容的多步骤推理方面发挥作用。然而，虽然之前的研究所展示了LLMs访问和分析网站的能力，但它们直接从社交媒体中获取并分析数据的能力尚未得到研究。本文旨在探讨这些能够上网浏览的LLMs能否仅通过用户名推断社交媒体用户的人口统计属性。", "innovation": "研究表明，这些具备网络浏览能力的LLMs可以访问社交媒体内容并以合理准确度预测用户的人口统计信息。此外，通过分析合成数据集进一步揭示了LLMs如何解析和解释社交媒体个人资料，这些过程可能会导致警惕性和政治偏见。", "conclusion": "这一能力为后API时代的计算社会科学带来了希望，但也引发了滥用的风险，尤其是在信息操作和针对性广告领域。因此，我们建议LLM提供商在面向公众的应用中限制这一功能，并为经过验证的研究目的保留控制访问权限。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12370", "html_url": "https://arxiv.org/abs/2507.12370", "title": "单一模型之外：通过辩论增强大型语言模型对请求模糊性的检测能力", "title_en": "Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate", "authors": "Ana Davila,Jacinto Colan,Yasuhisa Hasegawa", "background": "大型语言模型（LLMs）在理解和生成人类语言方面表现出显著能力，促进了与复杂系统的更自然交互。然而，它们在处理用户请求中的模糊性时面临挑战。为了解决这些挑战，本文提出并评估了一种多代理辩论框架，旨在提高检测和解决模糊性的能力，超越单一模型。", "innovation": "本文引入了一种多代理辩论框架，该框架由三种LLM架构（Llama3-8B、Gemma2-9B和Mistral-7B变体）组成，并包含一系列多样性的模糊性。实验结果表明，该框架显著提高了Llama3-8B和Mistral-7B变体的表现，Mistral-7B领导的辩论实现了76.7%的成功率，尤其有效于复杂模糊性，并促进了高效的共识。", "conclusion": "这一研究强调了辩论框架作为增强LLM能力的目标方法的价值。研究结果为开发更稳健和适应性强的语言理解系统提供了重要见解，表明结构化辩论可以提升交互系统中的清晰度。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12451", "html_url": "https://arxiv.org/abs/2507.12451", "title": "S2WTM: 球形切片 Wasserstein 自编码器在主题建模中的应用", "title_en": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling", "authors": "Suman Adhya,Debarshi Kumar Sanyal", "background": "在高维文本数据中捕捉方向相似性方面的有效方法是建模潜在表示在超球面上的表示。变分自编码器（VAE）基神经主题模型（VAE-NTMs）经常采用 von Mises-Fisher 先验来编码超球面结构。然而，VAE-NTMs 往往会遭受后验塌陷的问题，即目标函数中的 KL 散度项显著降低，导致生成的潜在表示不够有效。", "innovation": "为解决这一问题同时在潜在空间中建模超球面结构，本文提出了球形切片 Wasserstein 自编码器（Spherical Sliced Wasserstein Autoencoder, S2WTM）。S2WTM 使用支持在单位超球面上的先验分布，并利用球形切片-Wasserstein 距离来对齐聚合后验分布与先验。实验证明 S2WTM 能够克服上述问题，生成更一致和多样化的主题，并在下游任务中取得更好的表现", "conclusion": "S2WTM 在主题建模中的性能超过了当前最先进的主题模型，能够更有效且更有效地生成主题，并在下游任务上提供更好的表现。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12379", "html_url": "https://arxiv.org/abs/2507.12379", "title": "在语言模型中探测算术错误", "title_en": "Probing for Arithmetic Errors in Language Models", "authors": "Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan", "background": "我们研究了语言模型内部激活是否可以用于检测算术错误。以3位数的加法作为一个受控场景开始，研究发现简单的探针可以从隐藏状态精确地解码模型预测的输出和正确的答案，不论模型的输出是否正确。这一发现为训练轻量级错误检测器提供了基础，这些检测器能够以超过90%的准确度预测模型的正确性。进一步地，将分析扩展到只涉及加法的GSM8K问题的结构化推导过程，发现之前训练的简单算术探针在更具复杂性的场景中也能很好地泛化，揭示出一致的内部表示。最后，展示了这些探针可以引导针对错误推理步骤的有选择性的重提问，从而在最小程度上影响正确输出的情况下提高任务准确性。这些发现表明，从内部激活中可以通过单独的探针预测到算术错误，并且简单的探针为轻量级模型自我纠正提供了一条可行的路径。", "innovation": "本研究通过训练轻量级错误检测器，以超过90%的准确率预测模型的正确性，并发现简单的探针能够在更具复杂性的结构化推理过程中很好地泛化，从而能够引导有选择性的重提问来纠正错误的推理步骤，提高任务准确性，而几乎不影响正确的输出。这表明，语言模型的内部激活可以用于检测和纠正算术错误，为模型自我纠正提供了一条新的路径。", "conclusion": "研究表明，可以直接从语言模型的内部激活中探测到算术错误，而不需要额外的数据或复杂的模型。简单的探针能够准确地识别和指导纠正错误的推理步骤，从而提高任务的准确性。这些发现为语言模型的自我纠正提供了新的见解和方法。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12079", "html_url": "https://arxiv.org/abs/2507.12079", "title": "MEGA：使用苏格拉底方法通过LLM进行数学解释的发现", "title_en": "Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning", "authors": "Tosin Adewumi,Foteini Simistira Liwicki,Marcus Liwicki,Viktor Gardelli,Lama Alkhaled,Hamam Mokayed", "background": "大学学生在数学学习中遇到困难，尤其是在使用大型语言模型（LLMs）的情况下。这种困难往往源于不理想的教学方法，导致学生避免数学相关学科，尽管数学在信号处理等领域具有重要意义。论文对比了结合苏格拉底方法、思维链推理、简化游戏化和形成性反馈的MEGA方法与传统的思维链方法，以确定哪种方法更有效。通过从两个数据集（GSM8K和MATH）中随机抽取样本进行评估。", "innovation": "提出了一种新的结合了苏格拉底方法、思维链推理、简化游戏化和形成性反馈的MEGA方法，用于通过大型语言模型（LLMs）进行数学解释，并通过实验评价该方法的有效性。", "conclusion": "实验结果表明，MEGA方法更受学生欢迎，尤其是在较难的MATH数据集上，MEGA方法在解释复杂数学问题方面优于传统的思维链方法，具体表现为MEGA方法的偏好比例为47.5%，而思维链方法为26.67%。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12143", "html_url": "https://arxiv.org/abs/2507.12143", "title": "2025年ELOQUENT实验室小组任务概述：作为教师、学生和评估者的LLM", "title_en": "Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators", "authors": "Pavel Šindelář,Ondřej Bojar", "background": "为评估生成语言模型的高级标准，提出了一项称为ELOQUENT的任务集合，其中包括一个名为Sensemaking的任务。Sensemaking任务模拟课堂场景，分为三个步骤：（1）教师系统准备一组问题，（2）学生系统回答这些问题，（3）评估器系统对这些问题的回答进行评分。为了进行2025年Sensemaking实验，选择了7种不同的测试材料来源，涉及英语、德语、乌克兰语和捷克语。", "innovation": "引入了一种全新的评估语言模型（LLM）能力的框架，该框架使用实际应用场景中的数据（如事实检查分析、教科书、讲座录音和教育视频等），模拟真实世界的教学场景。此外，实验中还引入了由商业大型语言模型系统作为基线的教师和学生提交，并开发了一个完全自动的评估流程，与手动评估进行了对比。", "conclusion": "对于教师生成问题的任务，需要进一步改进评估策略，因为难以区分不同候选问题集的质量。在学生回答问题方面，LLM整体表现尚可，但限制其回答仅限于给定的输入文本仍存在难题。在评估问题回答方面，对抗性测试揭示了使用LLM作为裁判模式的系统在判定混乱的问题-答案对以及乱序问题的回答为合格时存在误判问题。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12064", "html_url": "https://arxiv.org/abs/2507.12064", "title": "StylOch在PAN的任务中：基于频率特征的梯度提升树方法", "title_en": "StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features", "authors": "Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak", "background": "该论文基于一个模块化的语体分析管道，使用公开的spaCy模型进行文本预处理（包括分词、命名实体识别、依赖句法分析、词性标注和形态标注）并提取数千个特征（上述语言注释的n-gram频率）。研究者还使用了轻量级梯度提升机作为分类器，并利用了一个包含超过50万份机器生成文本的大语料库进行训练。通过探索多种参数选项来提高分类器的能力，尽可能利用该数据集的优势。该方法采用的是非神经网络、计算成本低但具有解释性的方法，这种方法在过去已被证明有效。", "innovation": "该研究的主要创新点在于使用了轻量级梯度提升机作为分类器，并通过大规模数据集进行训练，以提高分类器的能力。同时，该研究还探索了多种参数选项，旨在优化模型性能。", "conclusion": "该研究提出了一种基于频率特征的梯度提升树方法，用于二进制AI检测任务。通过使用大规模机器生成的文本数据集进行训练，并经过参数优化，该方法在提高分类器性能方面表现良好。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12466", "html_url": "https://arxiv.org/abs/2507.12466", "title": "语言模型在预训练数据匹配目标任务后性能提升", "title_en": "Language Models Improve When Pretraining Data Matches Target Tasks", "authors": "David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan", "background": "每种数据选择方法都有其目标。在实践中，这些目标通常是通过基准驱动的迭代隐性生成的：研究者开发选择策略，训练模型，测量基准性能，然后调整优化。这引发了一个自然的问题，即当我们将这种优化过程变得明确时会发生什么。", "innovation": "提出了基准导向排名（BETR）方法，这是一种简单的方法，基于与基准训练示例的相似性选择预训练文档。BETR将基准示例和一部分预训练文档嵌入到共享空间，并根据与基准的相似性对样本进行评分，然后训练一个轻量级分类器来预测这些分数在整个语料库中的值。通过训练超过500个模型来比较数据选择方法，并拟合它们的扩展定律，研究发现，简单地通过BETR对预训练数据进行与评估基准的对齐实现了2.1倍的计算放大倍数（相对于DCLM-Baseline为4.7倍，相对于未经筛选的数据为9倍）。此外，无论数据规模如何，BETR都表现出良好的泛化能力: 当目标是与评估套件相交的多样基准时，BETR仍然与基线保持一致甚至超过基线。", "conclusion": "我们的扩展分析进一步揭示了一个明确的趋势：更大的模型需要较少激进的过滤。总的来说，我们的研究结果表明，直接将预训练数据匹配到目标任务能够精确塑造模型能力，并且突显出最优选择策略必须根据模型的规模进行调整。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11548", "html_url": "https://arxiv.org/abs/2507.11548", "title": "AI招聘筛选中的公平性不足：审计复合偏见和能力", "title_en": "Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening", "authors": "Kevin T Webster", "background": "随着生成式AI在简历筛选中的应用不断增加，人们假设它能提供一种比人类有偏见的决策更具客观性的替代方案。然而，这种看法忽视了一个关键问题：这些AI系统是否真正具备它们被期望完成的评估任务的能力？本研究通过两部分审计对八大主要AI平台进行了调查，以探究这一能力问题。实验一发现了复杂的、基于上下文的种族和性别偏见，一些模型因候选人的种族或性别信号而对候选人进行惩罚。实验二评估了核心能力，揭示了一些看似无偏见的模型实际上无法进行实质性的评估，而是依赖于表面的关键词匹配。", "innovation": "本研究引入了“中立的幻象”这一概念，描述了尽管表面上看似无偏见，但实际上模型无法做出有意义判断的现象。研究建议组织和监管机构采用双重验证框架，审计AI招聘工具有助于确认它们是否在平等和有效性方面都是可信的。", "conclusion": "AI招聘筛选中的公平性不足，需要进一步审计复合偏见和能力。组织和监管机构应采用双重验证框架，同时关注 demographic 偏见和实际表现，以确保招聘工具的公平性和有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11788", "html_url": "https://arxiv.org/abs/2507.11788", "title": "基于生物现实模型的大脑中模拟语言习得", "title_en": "Simulated Language Acquisition in a Biologically Realistic Model of the Brain", "authors": "Daniel Mitropolsky,Christos Papadimitriou", "background": "尽管在神经科学方面取得了巨大进展，但我们仍然缺乏一个详尽的叙述来解释大脑神经元的放电如何具体导致高阶认知现象，如计划和语言。本文介绍了六个基本且普遍接受的神经科学原则的简单数学公式：兴奋性神经元、脑区、随机突触、Hebbian突触可塑性、局部抑制和跨区抑制。基于这一形式主义，我们实施了一个基于此模拟神经形态系统的模型，该系统能够实现基本的语言习得：从一张白纸开始，系统能够在任何语言中通过接触少量语义接地的句子来学习词汇的意义、词性的语法学作用（动词或名词）以及语言的词序，包括生成新句子的能力。", "innovation": "本文创新地提出了一个简单的数学模型来模拟语言习得的过程，并基于该模型实现了一个模拟神经形态系统。该系统从零开始，通过少量语义接地的句子就能学习不同的语言特征，包括词汇意义、词序以及生成新句子的能力。", "conclusion": "本文展示了模拟神经形态系统在生物现实模型中能够实现基本的语言习得这一结果。该研究提出了几种可能的扩展和应用，揭示了神经科学模型在理解人类语言习得过程中的潜在价值。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11662", "html_url": "https://arxiv.org/abs/2507.11662", "title": "让我们两步思考：通过自扎根验证缓解MLLMs的共识偏差", "title_en": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "authors": "Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira", "background": "验证器在像数学和棋盘游戏这样的领域中对于AI的进步起到了关键作用。然而，将这些成果推广到没有明确成功标准的领域（例如计算机使用）仍然是一个挑战：虽然人类可以识别出合适的成果，但从这种直觉转化为可扩展的规则仍然是一个难题。基于世界知识、人类偏好对齐以及推理能力的多模态大型语言模型（MLLMs）被认为是潜在的解决方案。本文评估了MLLMs作为智能体轨迹验证器在网页导航、计算机使用和机器人操纵中的应用，并发现了一个关键限制：共识偏差，即MLLMs倾向于偏好其上下文窗口中的信息，经常通过生成推理链来为不良行为辩护。这种偏差在模型间普遍存在，即使在测试时扩大规模也难以克服，会对使用MLLMs作为评估者的多种方法（例如数据过滤）产生影响。尽管MLLMs表现出与人类偏好对齐的强大先验，但这种偏差依然存在。但在评估中表现出一致的人类倾向，与期望行为相一致。研究发现，与这些评估者受影响不一致的先验有关的限制因素使得验证效果受限。", "innovation": "本文提出了Self-Grounded Verification (SGV)，这是一种轻量级的方法，通过利用MLLMs自身的采样机制（无条件和有条件生成）来更有效地利用其知识和推理能力。SGV分为两个步骤：首先，MLLM要提取与任务完成相关的广泛先验，不依赖于正在评估的数据；其次，根据自我生成的先验，MLLM会对候选轨迹进行推理和评估。通过SGV增强后的MLLM验证器，在准确性、失败检测率方面证明了高达20分的进步，并且可以实现对异构智能体的实时监督，进一步提高任务在OSWorld、robomimic和VisualWebArena等环境中的完成率。", "conclusion": "通过使用SGV方法，MLLM验证器在准确性、失败检测率方面达到了最高20分的提升，能够在OSWorld、robomimic和VisualWebArena等基准测试环境中实现对不同智能体的实时监督，任务完成度显著提升，超过了之前的最佳成绩48%。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12284", "html_url": "https://arxiv.org/abs/2507.12284", "title": "MERA Code：跨任务评估代码生成的统一框架", "title_en": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks", "authors": "Artem Chervyakov,Alexander Kharitonov,Pavel Zadorozhny,Adamenko Pavel,Rodion Levichev,Dmitrii Vorobev,Dmitrii Salikhov,Aidar Valeev,Alena Pestova,Maria Dziuba,Ilseyar Alimova,Artem Zavgorodnev,Aleksandr Medvedev,Stanislav Moiseev,Elena Bruches,Daniil Grebenkin,Roman Derunets,Vikulov Vladimir,Anton Emelyanov,Dmitrii Babaev,Vladimir V. Ivanov,Valentin Malykh,Alena Fenogenova", "background": "近年来，大规模语言模型（LLMs）在软件工程中的任务自动化方面取得了进展，主要评估集中在自然语言任务上，忽视了代码质量。现有基准大多侧重高层次推理而非可执行代码和实际性能，存在理解这些模型在生产环境中真正能力和相关风险的缺口。为解决这一问题，我们提出了MERA Code，这是MERA基准系列的新成员，专注于评估最新代码生成的LLMs在俄罗斯语中的代码性能。MERA Code包含11项评估任务，覆盖8种编程语言，其评估方法论包括描述模型完成这些任务需要的实际编程技能的分类法。MERA Code提供开源代码库以供进行MERA评估，支持不同编程环境的计分系统以及包含排行榜和提交系统的一站式平台。我们还评估了开源LLMs和前沿API模型在非英语语言的实际编程任务中的局限性。", "innovation": "MERA Code填补了当前代码生成评估的空白，首次提出专门针对最新代码生成LLMs的评估框架，特别关注俄语文本。该框架包括11个评估任务覆盖8种编程语言，评估方法不仅考虑高层次推理，还注重实际编程技能的应用，同时提供开源资源和评估平台，支持未来研究的标准化和模型模块的进步。", "conclusion": "我们公开发布MERA以引导未来研究，预测模型开发中的创新功能，并标准化评估流程。MERA为代码生成评估提供了统一而全面的框架，有助于评估LLMs在各种编程任务中的实际能力及其潜在风险。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11630", "html_url": "https://arxiv.org/abs/2507.11630", "title": "Jailbreak-Tuning：模型高效学习突破囚禁性", "title_en": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility", "authors": "Brendan Murphy,Dillon Bowen,Shahrad Mohammadzadeh,Julius Broomfield,Adam Gleave,Kellin Pelrine", "background": "随着人工智能系统的快速发展，模型开发人员普遍认为需要采取措施防止严重的滥用。目前大多数的防滥用方法在应对精细调优时效果不佳，或者只能部分移除限制，甚至降低输出质量。", "innovation": "该论文提出了一种名为‘ Jailbreak-tuning ’的新方法，可以在不被现代防滥用系统阻止的情况下，使模型生成对任意有害请求的详细、高质量回应。研究人员发现，后门可以增强攻击的隐蔽性和严重性，更强的 Jailbreak 提示在精细调优时效果更佳，能够将攻击和潜在防御在输入和权重空间中链接起来。最新的模型似乎更容易受到这些攻击，突显出需要发现有效的防篡改保护措施的紧迫性。", "conclusion": "这些可精细调优的模型及其调优后的变体都存在安全风险。为了避免潜在的危害，无论是在技术还是政策层面上，都应将任何可精细调优模型的发布视作同时释放了一个与其功能等同且可用于任何恶意用途的‘邪恶双胞胎’模型。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12341", "html_url": "https://arxiv.org/abs/2507.12341", "title": "非线性概念消除：一种密度匹配方法", "title_en": "Nonlinear Concept Erasure: a Density Matching Approach", "authors": "Antoine Saillenfest,Pirmin Lemberger", "background": "当公平性成为考虑因素时，确保用于实际应用的神经模型不会从文本表示中推断出敏感信息（如性别或种族等人口统计属性）是一个关键挑战。为此，本文探讨了通过概念消除的方法解决该问题，即从分布式表示中去除特定概念相关的信息，同时尽可能保留其余语义信息。这一过程涉及学习嵌入空间中的正交投影，以使要消除的离散概念的类条件特征分布在此投影后变得无法区分。通过调整投影器的秩，可以控制信息去除的程度，而正交性确保嵌入的局部结构得到严格保留。", "innovation": "本文提出了一种名为$\bar{\text{L}}$EOPARD的方法，该方法实现了在经典自然语言处理基准测试中对离散属性进行非线性消除的最先进的性能。此外，通过$\bar{\text{L}}$EOPARD，本文还证明了有效减轻深度非线性分类器中的偏差，从而促进公平性。", "conclusion": "该方法通过学习正交投影，使得嵌入空间中的特定概念信息在投影后变得难以区分，同时保持了大部分语义信息。通过调整投影器的秩，可以控制信息去除的程度，而正交性确保了嵌入局部结构的严格保留。$\bar{\text{L}}$EOPARD方法在经典自然语言处理基准测试中对离散属性进行了最先进的非线性消除，并且能够有效减轻深度非线性分类器中的偏差，促进公平性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12142", "html_url": "https://arxiv.org/abs/2507.12142", "title": "RiemannLoRA: 一种消除LoRA优化歧义的统一黎曼框架", "title_en": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization", "authors": "Vladimir Bogachev,Vladimir Aletov,Alexander Molozhavenko,Denis Bobkov,Vera Soboleva,Aibek Alanov,Maxim Rakhuba", "background": "低秩适应（LoRA）已成为一种广泛采用的标准，用于大规模语言模型（LLMs）的参数高效微调，显著降低了内存和计算需求。然而，仍存在挑战，包括找到最佳的初始化策略或在低秩矩阵因子化中缓解过度参数化。", "innovation": "提出了一种新颖的方法，在统一框架中同时解决上述两个挑战。该方法将一组固定秩的LoRA矩阵视为平滑流形，将适应器视为流形上的元素，从而消除过度参数化。沿着流形的最快损失下降方向确定初始化方向，并采取特别措施确保方法的数值稳定性和计算效率。", "conclusion": "实验结果表明，RiemannLoRA在LLM和扩散模型架构上，相比标准的LoRA及其最先进的修改，能够一致地提高收敛速度和最终性能。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12356", "html_url": "https://arxiv.org/abs/2507.12356", "title": "探究阿尔茨海默病检测中的性别偏差：基于普通话和希腊语语音感知的洞见", "title_en": "Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception", "authors": "Liu He,Yuanchao Li,Rui Feng,XinRan Han,Yin-Long Liu,Yuwei Yang,Zude Zhu,Jiahong Yuan", "background": "在语音感知任务中已经广泛观察到性别偏见，这种偏见受到性别间基音差异的影响。这项研究揭示了性别偏见在阿尔茨海默病（AD）语音感知中的存在。研究中，16名中国参与者对汉语和希腊语语音进行了评估，结果显示男性语音更常被识别为AD，特别是在汉语语音中这种偏见尤为明显。", "innovation": "研究人员发现，男性语音的闪烁值与AD感知显著相关，而语音部分与AD识别之间存在显著负相关。虽然语言对AD感知没有显著影响，但这项研究强调了性别偏见在AD语音感知中的重要性，并呼吁进一步研究以验证不同语言背景下模型的性能。", "conclusion": "这项工作强调在开发AD检测模型时必须解决性别偏见问题，并呼吁进行进一步研究以验证模型在不同语言环境中的表现。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12378", "html_url": "https://arxiv.org/abs/2507.12378", "title": "开发可扩展的视觉增强问答系统", "title_en": "Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker", "authors": "Rachna Saxena,Abhijeet Kumar,Suresh Shanmugam", "background": "传统的信息提取系统依赖纯文本模型，无法处理包含表格、图表、图像等视觉元素的复杂信息。多模态LLM虽然能应对更大规模的搜索空间和更长的上下文，但也面临高计算需求及对企业级应用的挑战。作为一种高性能的检索增强视觉问答方法，晚交互机制在特定任务中表现出色，但在基于检索的多模态问答系统中应用较少，尤其在视觉检索方面。现有的问题是，主流的向量数据库不支持多向量检索，晚交互机制增加了空间占用，且未充分利用近似最近邻搜索技术以提高检索速度。因此，需要一种可扩展且高效的视觉检索方法，不牺牲性能质量。本研究通过多步骤的自定义实现，结合广泛采用的混合搜索（元数据和嵌入）和先进的晚交互重排序器，旨在实现这一目标，最终由多模态LLM作为阅读者从最佳匹配的上下文中生成答案.", "innovation": "本文提出了一种多步骤的自定义实现方法，结合了混合搜索（元数据和嵌入）和先进的晚交互重排序器，以实现快速且稳定的视觉检索，同时有效地使用向量数据库进行多向量检索。这种方法不仅提高了检索速度，还保持了高精度，为企业的实际应用提供了生产级系统，显著降低了对企业级使用的空间占用.", "conclusion": "实验结果证明，本文提出的设计方案在不降低性能质量的情况下实现了显著的检索加速，从而能够作为企业的实际生产系统应用，克服了传统的信息提取系统的局限性，并解决了多模态检索增强问答系统中的一些关键问题。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.17241", "html_url": "https://arxiv.org/abs/2406.17241", "title": "通过知识编辑理解语言模型电路", "title_en": "Understanding Language Model Circuits through Knowledge Editing", "authors": "Huaizhi Ge,Frank Rudzicz,Zining Zhu", "background": "近期在语言模型解释性方面取得的进展已经识别出了电路，这是关键的子网络，能够复制模型的行为，然而在这些关键子网络内部知识的组织方式仍然不透明。为了更好地理解这些电路中的知识，我们对GPT-2语言模型的电路进行了系统的知识编辑实验。我们的分析揭示了电路如何响应编辑尝试、知识在网络组件中的分布程度以及知识承载电路的构架组成等有趣模式。这些发现加深了我们对模型电路与知识表示之间复杂关系的理解，揭示了信息如何在语言模型中组织的原理。", "innovation": "我们对GPT-2语言模型的电路进行了系统的知识编辑实验，并揭示了电路如何响应编辑尝试、知识在网络组件中的分布程度以及知识承载电路的构架组成等有趣模式。这些发现为语言模型的解释性提供了新的见解，并为语言模型的进一步解释性和安全性研究指明了方向。", "conclusion": "我们的研究提供了对电路含义的新见解，并为语言模型的进一步解释性和安全性研究指明了方向。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.14335", "html_url": "https://arxiv.org/abs/2406.14335", "title": "为文本分析设计的线性可解释概念嵌入模型", "title_en": "Linearly-Interpretable Concept Embedding Models for Text Analysis", "authors": "Francesco De Santis,Philippe Bich,Gabriele Ciravegna,Pietro Barbiero,Danilo Giordano,Tania Cerquitelli", "background": "尽管大型语言模型（LLMs）在多个任务中取得了显著的成果，但仍面临着解释性不足的批评。传统的后嵌入解释方法，如基于注意力和梯度分析的解释方法，只能近似解释模型的决策过程，并且已证明这些方法不可靠。因此，最近在文本领域提出了概念瓶颈模型（CBMs）以基于人类可理解的概念提供可解释的预测。然而，CBMs仍然存在一些限制，包括架构上的约束限制其表达能力、使用非线性任务预测器时的任务可解释性缺乏，以及需要大量的人工标注，这在实际文本数据中是不现实的。", "innovation": "本文提出了一种新型的线性可解释概念嵌入模型（LICEM），它超越了当前准确性和可解释性之间的权衡。LICEM的分类准确性优于现有的可解释模型，并且与黑盒模型相当。我们展示了由我们的模型提供的解释具有更高的干预性和因果一致性。此外，LICEM的训练不需要任何概念监督，因为当使用大型语言模型（LLM）作为主干时，概念可以自动预测。", "conclusion": "LICEM能够提供更可解释的预测，同时保持与黑盒模型相当的准确性，且模型的解释更具干预性和因果一致性。此外，LICEM可以通过LLM主干自动预测概念，从而无需额外的概念标注。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.11647", "html_url": "https://arxiv.org/abs/2410.11647", "title": "测量大型语言模型的灵性价值观与偏见", "title_en": "Measuring Spiritual Values and Bias of Large Language Models", "authors": "Songyuan Liu,Ziyang Zhang,Runze Yan,Wei Wu,Carl Yang,Jiaying Lu", "background": "大型语言模型（LLMs）已成为各种背景用户的重要工具。这些模型在大量语料库上进行训练，反映了其预训练数据中的语言和文化细微差别。然而，这些数据中固有的价值观和视角可能会影响LLMs的行为，导致潜在的偏见。因此，在涉及灵性和道德价值观的情境中使用LLMs需要仔细考虑这些潜在的偏见。", "innovation": "本研究首先通过测试流行LLMs的灵性价值观验证了假设，实验结果表明，LLMs的灵性价值观非常多样，反驳了无神论者或世俗者的刻板印象。随后，研究探讨了不同灵性价值观如何在社会公平场景中（如仇恨言论识别）影响LLMs。研究发现，不同的灵性价值观确实导致了对不同仇恨目标群体的不同敏感性。此外，本研究提出了继续在灵性文本上进行预训练LLMs的方法，并展示了这种方法在减轻灵性偏见方面的有效性。", "conclusion": "研究结果表明，LLMs的灵性价值观具有多样性，不同灵性价值观会影响其在社会公平情景中的表现。通过在灵性文本上进行预训练，可以有效减轻这些偏见。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11687", "html_url": "https://arxiv.org/abs/2507.11687", "title": "MetaLint：通过指令遵循和从易到难泛化的idiomatic代码质量分析", "title_en": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization", "authors": "Atharva Naik,Lawanya Baghel,Dhakshin Govindarajan,Darsh Agrawal,Daniel Fried,Carolyn Rose", "background": "大型语言模型在代码生成方面取得了成功，但在代码质量分析方面存在局限性，主要受限于静态训练数据，难以适应不断演变的最佳实践。MetaLint作为一种新的指令遵循框架，将代码质量分析任务定义为基于高级规范检测和修复问题语义代码片段或代码惯用法的任务。与传统基于静态规则数据训练模型的方法不同，MetaLint采用指令调优的方式使用合成校验器生成的数据支持从易到难的泛化，使模型能够适应新的或复杂的代码模式而无需重新训练。为了验证这一点，作者构建了一个由真实世界编码标准（如Python Enhancement Proposals (PEPs)）启发的具有挑战性的惯用法基准，评估MetaLint训练的模型是否在推理中表现出适应性或仅仅是记忆。结果表明，MetaLint在未见过的PEP惯用法泛化方面有所改进，代码片段检测的F分数达到70.37%，召回率最高达到70.43%。此外，MetaLint在定位方面达到26.73%，其参数量为4BCompetitive表现优于其参数规模，并且与更大规模的先进模型（如o3-mini）相当，显示出其在代码质量分析方面的未来潜力。", "innovation": "MetaLint引入了一种新的指令遵循框架，通过指令调优使用合成校验器生成的数据，实现从易到难的泛化能力，使模型能够适应新的或复杂的代码模式而无需重新训练。这种方法不同于传统的基于静态规则数据训练模型的方法。MetaLint在代码质量分析领域展示了其适应新代码模式的能力，并且在定位方面达到了26.73%，与较大规模的先进模型表现相当。", "conclusion": "MetaLint在未见过的PEP惯用法泛化方面表现出色，代码片段检测的F分数达到70.37%，召回率最高达到70.43%。在定位方面也达到了26.73%，显示出巨大的潜力，证明了MetaLint在新型代码质量分析中的应用前景。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2403.09040", "html_url": "https://arxiv.org/abs/2403.09040", "title": "RAGGED：迈向可扩展且稳定的大规模RAG系统的设计", "title_en": "RAGGED: Towards Informed Design of Scalable and Stable RAG Systems", "authors": "Jennifer Hsia,Afreen Shaikh,Zhiruo Wang,Graham Neubig", "background": "检索增强生成（RAG）通过整合外部知识来增强语言模型，但这依赖于系统的配置。不当的检索设置可能会降低性能，使RAG不如闭卷生成可靠。现有的研究表明，读者对噪声的鲁棒性是影响RAG稳定性和可扩展性的关键因素。尽管检索深度有时会提高读者的性能，但也可能会因干扰内容的影响而恶化。通过大规模的实验，研究者发现检索器、重排序器和提示对性能有影响，但并未从根本上改变这些由读者驱动的趋势。此前的研究缺乏一个系统的方法来评估RAG系统的稳定性和可扩展性，这限制了未来研究对检索深度和模型鲁棒性的优化。", "innovation": "RAGGED框架系统性地评估了RAG系统在各种检索器-阅读器配置、检索深度和数据集上的性能。通过分析发现，读者对噪声的鲁棒性决定了RAG系统的稳定性和可扩展性。某些读物在增加检索深度时受益，而其他则由于对干扰内容的敏感度而下降。通过在开放域、多跳和专门领域数据集上的大规模实验，研究证实了检索器、重排序器和提示虽然影响性能，但并未根本改变由读物驱动的趋势。RAGGED框架提供了一个原则性的方法和新的度量标准来评估RAG系统的稳定性和可扩展性，有助于系统地评估检索增强生成系统的性能并指导未来研究。", "conclusion": "通过提供一个原则性的框架和新的评估指标，RAGGED使得可以系统地评估RAG系统的稳定性和可扩展性，从而指导未来的研究工作，以优化检索深度和提高模型的鲁棒性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12175", "html_url": "https://arxiv.org/abs/2507.12175", "title": "RUMAA：基于重复符号的统一音乐音频分析以实现谱-表演对齐、转录和错误检测", "title_en": "RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection", "authors": "Sungkyun Chang,Simon Dixon,Emmanouil Benetos", "background": "传统的谱-音频对齐方法依赖于手动展开的谱-MIDI数据，且局限于固定的重复结构，导致其在谱包含重复部分的情况下表现不佳。在此之前，处理这些任务的先驱方法都是单独进行，未能充分整合这些任务之间的相互依赖性。", "innovation": "RUMAA提出了一个基于Transformer的框架，将谱-绩效对齐、基于谱的转录和错误检测融合在一个近端到端的体系中。它使用预训练的谱和音频编码器，并通过代理任务捕捉任务间的相互依赖性。RUMAA能够在公开展示的钢琴音乐数据集中优于现有方法，在包含重复部分的乐谱上的表现尤为突出。", "conclusion": "RUMAA在非重复乐谱上的谱-音频对齐上达到了与现有最先进的方法相当的性能，在包含重复部分的乐谱上则明显优越。此外，该方法还在转录和错误检测方面展现了令人鼓舞的结果。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.07682", "html_url": "https://arxiv.org/abs/2412.07682", "title": "TRIM：用于成本效益语言生成的 Token 减少和推理建模", "title_en": "TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation", "authors": "Alfredo Garrachón Ruiz,Tomás de la Rosa,Daniel Borrajo", "background": "大型语言模型（LLMs）的推理成本因其计算需求而成为一个重要挑战，特别是在需要生成长文本的任务中。然而，自然语言中经常包含冗余信息，提供了优化机会。观察发现，通过适当提示，LLMs 可以生成保留核心意义但更为简洁的语言输出。", "innovation": "提出了 TRIM（Token Reduction and Inference Modeling），一种减少计算成本的管道，在 LLM 生成简短的浓缩输出后，由一个具有较低推理成本的小型模型将其重建为完整叙述。实验结果显示，在一般知识领域，平均节省了 20.58% 的 token，同时评价指标有所下降，这表明此方法能够有效平衡效率与准确性。", "conclusion": "我们的实验表明，该方法在平衡效率和准确性方面具有潜力，特别是在一般知识领域，可以有效减少计算成本，同时保持相当准确的评价指标。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2403.15740", "html_url": "https://arxiv.org/abs/2403.15740", "title": "在大规模语言模型训练中使用独特标识符保护受版权保护的材料", "title_en": "Protecting Copyrighted Material with Unique Identifiers in Large Language Model Training", "authors": "Shuai Zhao,Linchao Zhu,Ruijie Quan,Yi Yang", "background": "训练大型语言模型（LLMs）的一个主要关切是它们是否滥用在线版权文本。随着训练数据规模的不断扩大和LLMs在日常生活中的普及，出现了两个问题：1）虚假的成员身份推断结果，由类似示例误导；2）成员身份推断方法通常过于复杂，普通用户难以理解和使用。这些问题促使研究人员提出了一种替代的“插入并检测”方法，建议网站用户和内容平台采用独特的标识符来进行可靠且独立的成员身份推断。用户和平台可以创建自己的标识符，将其嵌入受版权保护的文本中，并在未来的LLMs中独立检测它们。", "innovation": "本文提出了一种替代的“插入并检测”方法，旨在应对以往方法的复杂性和不准确性问题。该方法建议用户和内容平台使用独特的标识符来进行会员身份推断。具体来说，研究者引入了“幽灵句子”和一个简单易用的最后-k个单词测试。幽灵句子主要是随机自然单词的独特同义词集合，可以包含自定义元素以规避可能的过滤规则。此外，还设计了一个额外的困惑度测试，用于检测成员身份推断中的不自然同义词。研究还探讨了训练数据规模、模型大小、重复时间、插入位置、同义词列表等因素对记忆和会员身份推断的影响。", "conclusion": "研究展示了在实际场景中使用幽灵句子的可行性，并提供了潜在应用的指导。通过全面的研究，研究者证明了这种方法在识别模型训练数据中的成员方面具有一定的可靠性，并为今后的研究和实践提供了依据。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16069", "html_url": "https://arxiv.org/abs/2410.16069", "title": "Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context", "title_en": "Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context", "authors": "Maggie Mi,Aline Villavicencio,Nafise Sadat Moosavi", "background": "人类处理成语依赖于理解成语所在的上下文句子，同时还需要考虑语言本身的特点如频率，以及说话者的内在因素如熟悉程度。尽管语言模型在成语识别任务上表现出了很高的性能，但这种成功可能归因于现有数据集中的推理捷径。因此，作者构建了一个新的、受控的对比数据集，以测试语言模型是否能够有效利用上下文来消歧成语意义。此外，作者还探讨了共现频率和句子概率对模型性能的影响。研究发现，当需要关注周围上下文时，语言模型往往无法解决成语的意义，而具有更高概率的句子模型表现更好。表达的共现频率也影响模型性能。作者公开了代码和数据集。", "innovation": "作者构建了一个新的、受控的对比数据集以测试语言模型利用上下文消歧成语意义的能力。此外，作者还研究了共现频率和句子概率对模型性能的影响。", "conclusion": "研究表明，语言模型在需要关注上下文的情况下往往无法解决成语的意义，而具有更高概率的句子模型表现更好。表达的共现频率也影响模型性能。代码和数据集已公开。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.05111", "html_url": "https://arxiv.org/abs/2502.05111", "title": "约束性灵活且高效的语法约束解码", "title_en": "Flexible and Efficient Grammar-Constrained Decoding", "authors": "Kanghee Park,Timothy Zhou,Loris D'Antoni", "background": "大型语言模型（LLMs）经常被要求生成符合精确语法规则的结构化输出，如代码片段或格式化数据。语法约束解码（GCD）算法通过屏蔽可能导致不符合预定上下文自由文法（CFG）规则的标记来确保LLM的输出遵守这些规则。为了确保其正确性，GCD算法需要计算给定LLM子词分词器如何与给定上下文自由文法中的标记对齐，并根据这些信息计算标记掩码。然而，高效执行这一过程具有挑战性，现有的GCD算法在预处理常见文法时需要花费数分钟时间。", "innovation": "本文介绍了一种新的GCD算法以及一个实现，相比现有方法提供了17.71倍更快的离线预处理速度，同时在线掩码计算保持了与现有技术相当的效率。", "conclusion": "该算法和实现有效地解决了语法约束解码过程中的效率问题，能够在保证高质量输出的同时大幅缩短预处理时间，提升了语法约束解码的实用性和应用场景。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.13497", "html_url": "https://arxiv.org/abs/2502.13497", "title": "向地理文化基础化的LLM生成迈进", "title_en": "Towards Geo-Culturally Grounded LLM Generations", "authors": "Piyawat Lertvittayakumjorn,David Kinney,Vinodkumar Prabhakaran,Donald Martin Jr.,Sunipa Dev", "background": "全球范围内，生成型大型语言模型在多元文化意识方面显示出明显的差距。本文探讨了检索增强生成和搜索引擎技术对大型语言模型在展示不同国家文化方面熟悉程度能力的影响。研究对比了标准语言模型、使用定制知识库增强检索（即基于知识库检索）的模型和使用网络搜索增强检索（即基于搜索检索）模型在多个文化意识测验中的表现。", "innovation": "本文旨在通过研究检索增强生成和搜索引擎技术对语言模型文化感知能力的影响，探索提高语言模型在展示文化多样性方面的表现。特别是，作者通过多个文化意识基准测试，对比了标准语言模型、基于知识库的增强检索和基于网络搜索的增强检索模型的表现。", "conclusion": "研究发现，基于搜索的检索增强显著提升了语言模型在测试命题知识（如文化规范、器物和机构）的多项选择题中的表现，但基于知识库的检索增强效果受限于知识库覆盖不足和检索器的不足优化。此外，基于搜索的检索增强也增加了语言模型做出刻板判断的风险，并未能在统计有足够力量的人类评估中改善评估者对文化熟悉度的判断。这些结果表明，在评估语言模型的文化感知能力时，命题文化知识和开放式文化流利度之间存在差异。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.17253", "html_url": "https://arxiv.org/abs/2406.17253", "title": "感知何其知识编辑方法编辑令人困惑的知识效果如何？", "title_en": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?", "authors": "Huaizhi Ge,Frank Rudzicz,Zining Zhu", "background": "大规模语言模型（LLMs）展现了显著的能力，然而它们获取新知识的能力在训练后仍然存在关键挑战。尽管最近的模型编辑技术如Rank-One Model Editing (ROME)显示出一定的潜力，其效果可能因被编辑知识的性质而异。本文引入了“困惑性”（perplexingness）的概念：即将新知识与LLM学习的概念层次和类别关系冲突的程度。研究表明，编辑跨类别的知识对模型的影响较大。", "innovation": "本文提出了一种新的度量标准——“困惑性”，并引入了一个名为HierarchyData的精心策划的数据集，包含99个不同类别的下位类-超类对。通过三种模型和四种编辑方法的控制实验，作者发现新知识的困惑性与其编辑效果之间存在强烈负相关。这项研究还揭示了涉及更抽象概念（超类）的编辑通常比具体概念（下位类）更难以修改，进一步阐明了LLM知识编辑的基本挑战。", "conclusion": "研究结果表明，新事实与LLM学习的概念层次结构的矛盾程度越高，越难可靠地编码这些知识。这些发现揭示了LLM知识编辑的基本挑战：新知识越违背LLM已学习的概念层次，越难以成功编辑。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.22913", "html_url": "https://arxiv.org/abs/2503.22913", "title": "Resona：通过检索提升线性递归模型中的上下文复制", "title_en": "Resona: Improving Context Copying in Linear Recurrence Models with Retrieval", "authors": "Xinyu Wang,Linrui Ma,Jerry Huang,Peng Lu,Prasanna Parthasarathi,Xiao-Wen Chang,Boxing Chen,Yufei Cui", "background": "大型语言模型（LLM）研究的空间最近经历了一些转变，研究重点正逐渐转向新型架构，旨在与长期主导此领域的变压器模型竞争。线性递归模型由于其计算效率被证明是一种可行的竞争对手，但在内部上下文学习等任务中，尤其是在从上下文中回忆信息方面，它们仍然与变压器模型存在明显的差距。", "innovation": "本文介绍了一个名为Resona的简单且可扩展的框架，旨在增强线性递归模型的检索能力，从而使模型能够整合输入上下文中的检索信息，以适应多种任务要求。实验表明，经过Resona增强的模型在多种合成和真实世界自然语言任务上表现出显著的性能提升，这证明Resona可以作为一种通用方法来提高线性递归LLM的上下文学习和语言建模能力。", "conclusion": "研究表明，通过引入Resona框架，线性递归模型在上下文学习和语言建模任务中的能力得到了显著提高，这使得线性递归模型在保持计算效率的同时，在性能上可以更接近变压器模型。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10341", "html_url": "https://arxiv.org/abs/2502.10341", "title": "组织网络：构建领域增强预训练数据整理", "title_en": "Organize the Web: Constructing Domains Enhances Pre-Training Data Curation", "authors": "Alexander Wettig,Kyle Lo,Sewon Min,Hannaneh Hajishirzi,Danqi Chen,Luca Soldaini", "background": "现代语言模型在大规模、无结构的数据集上进行训练，这些数据集通常由网页抓取并包含数十亿甚至数万亿的标记。无结构的数据集使人们难以理解和系统地整理数据。本研究通过开发内容分类以及将其分类到领域中，对这些网络数据集进行了拆解。", "innovation": "提出了一种名为WebOrganizer的框架，该框架通过主题和格式这两个互补的领域概念对网页进行组织，并自动注释预训练数据以提高下游任务的性能。此外，还研究了基于质量的方法如何隐式改变领域混合，并展示出领域混合能够增强现有的数据选择方法，同时通过有效的主题和格式进一步提升模型的性能。", "conclusion": "本研究证明了构造和混合领域的方法对基于质量数据整理方法是一个有价值的补充，为有效的和富有洞察力的预训练数据整理打开了新的途径。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.00691", "html_url": "https://arxiv.org/abs/2501.00691", "title": "Large Language Models生成的标签有助于体外测量人们的同理心", "title_en": "Labels Generated by Large Language Models Help Measure People's Empathy in Vitro", "authors": "Md Rakibul Hasan,Yue Yao,Md Zakir Hossain,Aneesh Krishna,Imre Rudas,Shafin Rahman,Tom Gedeon", "background": "大型语言模型（LLMs）已经在许多领域带来了革命性的变化，LLM-as-a-service（LLMSaaS）提供了通用的解决方案，无需进行昂贵的任务特定训练。与广泛研究的直接任务解决的提示工程不同，本文探讨了将LLM生成的标签用于监督训练的潜在应用，特别是用于体外（in-vitro）情景。这类方法利用LLM生成的标签改进主流模型的训练。传统上，众包数据集在心理学相关的任务领域（如从文本叙事中预测心理问卷结果）中往往存在噪声标签的问题，这些噪声标签会错误地反映同理心的真实情况。为了解决这个问题，研究人员使用心理基础的尺度感知提示（scale-aware prompts）来生成更准确的标签。研究结果表明，使用这些由LLM生成的高质量标签（特别是在经过噪声减小处理后），可以显著提高模型在公共测试数据集上的性能。例如，RoBERTa预训练语言模型（PLM）在公共NewsEmp基准测试集上获得了0.648的高皮尔森相关系数，达到了此前的最新水平。", "innovation": "本文探讨了LLM在体外应用中的潜在利用价值，特别是通过使用LLM生成的标签来改进监督训练。这种方法尤其适用于那些现有的数据集可能存在噪声标签的问题，通过使用心理学基础的尺度感知提示生成高质量的标签，从而提高模型的准确性。此外，该研究还分析了评估指标的选择和潜在的群体偏差，为将来开发更公正的同理心计算模型提供指导。这项研究贡献了两个主要创新点：一是提出了利用LLM生成高质量标签的方法，二是系统分析了相关评估指标和潜在偏差的处理方法。", "conclusion": "实验结果显示，通过将心理学基础的尺度感知提示应用于众包数据集，生成的高质量标签显著提高了同理心计算模型的准确性。尤其以RoBERTa预训练语言模型为例，在公开的新闻同理心基准测试集上的结果表现出色。此外，研究还对评估指标的选择及其可能的群体偏差进行了深入分析，为未来该领域的研究提供了有价值的参考。其结论是使用LLM生成的标签作为一种有效的改善监督训练质量的方法，并有助于减少数据偏差带来的影响。所有相关的代码和生成的标签已经在网上提供。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.12425", "html_url": "https://arxiv.org/abs/2507.12425", "title": "推进结构化企业和内部数据的检索增强生成", "title_en": "Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data", "authors": "Chandana Cheerla", "background": "随着组织越来越多地依赖专有的企业数据（包括人力资源记录、结构化报告和表格文件）进行关键决策，大型语言模型（LLMs）虽然具有强大的生成能力，但受限于静态预训练、短上下文窗口以及在处理异构数据格式方面的挑战。传统的检索增强生成（RAG）框架虽然在一定程度上弥补了这些不足，但在处理结构化和半结构化数据方面仍存在困难。", "innovation": "本文提出了一种先进的RAG框架，结合了基于密集嵌入（all-mpnet-base-v2）和BM25的混合检索策略，并通过有元数据感知的过滤（使用SpaCy NER）和交叉编码重排序进行了增强。该框架应用语义切块以保持文本连贯性，并保留表格数据结构以保持行列完整性。量化索引优化了检索效率，而人工在环的反馈和对话记忆则提高了系统的适应性。", "conclusion": "在企业数据集上的实验表明，在评估指标方面取得了显著进步：@5查准率提高了15%（从75%提高到90%），@5查全率提高了13%（从74%提高到87%），平均倒数排名提高了16%（从0.69提高到0.85）。质性评估结果显示，信仰度（从3.0提升到4.6）、完整性（从2.5提升到4.2）和相关性（从3.2提升到4.5）得分显著提高。这些结果表明，该框架能够提供准确、全面且上下文相关的响应，适合企业任务。未来工作包括扩展到多模态数据，并结合基于代理的检索。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00713", "html_url": "https://arxiv.org/abs/2506.00713", "title": "AKReF: 一种结构化论辩的知识表示框架", "title_en": "AKReF: An argumentative knowledge representation framework for structured argumentation", "authors": "Debarati Bhattacharjee,Ashish Anand", "background": "本文提出了一种将论辩性文本转换为论辩知识图谱（AKG）的框架。通过扩展理论基础，使AKG可以提供一种易于理解的论辩结构图形视图。该研究从基础的论辩成分（AC）和论辩关系（AR）标注开始，通过构建包含元数据属性的图知识库（KB）来丰富信息。然后，通过应用模态论与知识库中的推理规则，形成论辩，进而构建AKG。节点和边的属性捕捉关键论辩特征，帮助识别各种类型的推理规则、前提类型、推理标记和攻击类型，使得AKG能够用于推理论证的任务，例如检查论证的一致性并识别修订机会。", "innovation": "提出的论辩知识表示框架（AKReF）通过使用标注的推理规则和模态论，帮助推理论证模型学习需要通过论证及其相互连接进行推理的隐含间接关系。该框架已经应用于AAEC数据集的论文，并展示了其在复杂分析中的应用，如提取无冲突集和最大可接受论辩集。", "conclusion": "AKG为推理论证任务奠定了基础，特别是识别论证的隐含间接关系。通过AKG的格式化，推理模型能够学习这些隐含关系，这在评估论证的一致性和识别修订机会时对实现自洽更有利。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.13959", "html_url": "https://arxiv.org/abs/2501.13959", "title": "有效前提检索模型的Learned方法在高效数学形式化中的应用", "title_en": "Learning an Effective Premise Retrieval Model for Efficient Mathematical Formalization", "authors": "Yicheng Tao,Haotian Liu,Shanwen Wang,Hongteng Xu", "background": "近年来，形式化数学因其能够帮助跨多个领域的数学家而受到广泛关注。前提检索是数学形式化中的一个常见步骤，对于非专业用户而言极具挑战性。现有方法尽管能够便于自然语言查询，但需要一定的数学知识；而基于形式语言的方法（如Lean）则因数据稀缺问题限制了有效和泛化的检索模型的训练。", "innovation": "本文提出了一种新颖的方法，利用从Mathlib中提取的数据训练轻量级且有效的前提检索模型。特别地，该模型将查询（即由Lean提供的证明状态）和前提嵌入到一个潜在空间中，并使用专门针对形式语料库训练的分词器进行处理。该模型在一个对比学习框架中学习，其中应用了细粒度的相似度计算方法和重排模块以提升检索性能。", "conclusion": "实验结果表明，本文模型在准确率和计算负载上优于现有基准模型。基于本文提出检索模型，我们还公开了一个搜索引擎供公众使用，并提供了源代码和训练模型的下载链接。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.19982", "html_url": "https://arxiv.org/abs/2504.19982", "title": "TD-EVAL: 结合回合级精确度与对话级对比重新审视任务导向对话评估", "title_en": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons", "authors": "Emre Can Acikgoz,Carl Guo,Suvodip Dey,Akul Datta,Takyoung Kim,Gokhan Tur,Dilek Hakkani-Tür", "background": "任务导向对话（TOD）系统正受到大型语言模型（LLMs）的推动而经历革命，但这些系统的评估方法仍不足以应对它们日益复杂的需求。传统的自动评估指标仅关注对话层次，无法检测用户-代理交互过程中可能产生的关键中间错误。", "innovation": "本文提出了一种两步评估框架TD-EVAL（回合级和对话级评估），该框架将细粒度的回合级分析与整体对话级比较统一起来。在回合级别上，评估每个响应的三个TOD特定维度：对话连贯性、后端知识一致性以及策略合规性；同时设计了TOD代理竞技场，使用一对一比较提供对话级质量的度量。", "conclusion": "通过在MultiWOZ 2.4和τ-Bench上的实验，证明TD-EVAL能够有效地识别传统指标遗漏的对话错误，并且TD-EVAL在与人类判断的对齐度上优于传统和基于LLM的指标。这些结果表明TD-EVAL引入了TOD系统评估的新范式，能够有效评估回合和系统级别的内容，并为未来的研究提供即插即用的框架。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11078", "html_url": "https://arxiv.org/abs/2502.11078", "title": "DEEPER 深入洞察您的用户：基于导向的人格精细化建模", "title_en": "DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling", "authors": "Aili Chen,Chengyu Du,Jiangjie Chen,Jinghan Xu,Yikai Zhang,Siyu Yuan,Zulong Chen,Liangyue Li,Yanghua Xiao", "background": "近年来，个性化应用如推荐系统和用户行为预测逐渐依赖大型语言模型（LLMs）来进行可读性人格建模。在动态现实场景下，有效的人格建模需要利用流式行为数据持续优化用户人格。现有方法无论是在重新生成人格还是增量扩展新行为方面，往往无法持续改善人格质量或未来行为预测准确性。", "innovation": "本文提出了一种名为DEEPER的新颖方法，用于动态人格建模，以实现持续的人格优化。具体来说，该方法通过迭代的强化学习框架增强了模型的方向搜索能力，使模型能够自动识别有效更新方向，并利用用户行为和模型预测之间的差异进行人格优化。", "conclusion": "在涉及4800名用户和10个领域的大规模动态人格建模实验中，DEEPER显示出卓越的人格优化能力，平均每轮减少用户行为预测误差32.2%，比最先进的基线方法高出22.92%。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06607", "html_url": "https://arxiv.org/abs/2507.06607", "title": "基于高效长生成推理的解码-混合-解码架构", "title_en": "Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation", "authors": "Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen", "background": "近年来，语言模型的研发表明状态空间模型（SSMs）在高效序列建模方面具有有效性。尽管Samba和解码器-解码器架构（如YOCO）表现出色，但先前的研究未探索SSM层之间的表示共享效率潜力。本研究在此基础上引入了门控记忆单元（GMU），这是一个简单而有效的机制，用于各层之间的高效内存共享。通过将其应用于SambaY解码器-混合-解码器架构，SambaY显著提升了解码效率，保持了线性预填充时间复杂度，并提升了长上下文性能。该模型还消除了显式位置编码的需求。通过大规模实验，本研究证明我们的模型相较于强YOCO基线具有显著更低的不可约损失，表明在大规模计算环境下具有更优的性能扩展性。增强差分注意力机制，Phi4-mini-Flash-Reasoning，极大地提升了任务如Math500、AIME24/25和GPQA钻石推理任务的性能，同时在vLLM推理框架下，对于2K长度提示和32K生成长度，解码吞吐量提高了10倍以上。源代码已发布。", "innovation": "引入了门控记忆单元（GMU），这是一种用于各层之间高效内存共享的简单而有效机制。将GMU应用于SambaY解码器-混合-解码器架构的交叉解码器，共享来自Samba自解码器的记忆读取状态。该研究还引入了Phi4-mini-Flash-Reasoning，通过增强差分注意力机制，大幅提升了解码效率，并在大规模计算环境下具有优越的性能扩展性。增强后的模型在给定任务中表现优异，且不依赖强化学习，同时提高了在vLLM推理框架下的解码吞吐量。", "conclusion": "通过对比实验，本研究证实了所提出的SambaY和增强后的Phi4-mini-Flash-Reasoning模型相较于先前的基线模型具有显著的性能优势，尤其在长生成和大规模计算条件下。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23836", "html_url": "https://arxiv.org/abs/2505.23836", "title": "大型语言模型常常知道自己正在被评估", "title_en": "Large Language Models Often Know When They Are Being Evaluated", "authors": "Joe Needham,Giles Edkins,Govind Pimpale,Henning Bartsch,Marius Hobbhahn", "background": "如果AI模型能够检测到它们正在被评估，评估的效果可能会被削弱。模型可能会在评估期间表现出系统性的不同行为，这使得部署和治理决策中的基准测试变得不可靠。研究者们调查了前沿语言模型是否能够准确地将提示和对话分为产生自评估或实际部署的类别，这被称为‘评估意识’。", "innovation": "构建了一个包含1000个提示和61个不同数据集的多元基准，其中包括公共基准（如MMLU、SWEBench）、真实世界交互以及搭建框架（如网页浏览代理）的代理轨迹。结果显示，前沿模型在评估意识方面已经超过了随机水平，但尚未超越简单的基线人类水平，同时，模型在代理环境中识别评估的能力优于聊天环境。模型还被测试了它们是否能识别评估的目的，结果表明，无论是选择题还是开放式问题，AI模型的识别准确率都远远超过随机猜测。", "conclusion": "研究结果显示，前沿模型已经表现出显著的，尽管尚未超人的评估意识水平。作者建议在未来的模型中跟踪这一能力。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.00584", "html_url": "https://arxiv.org/abs/2504.00584", "title": "通用文本嵌入的语义适配器：诊断和缓解否定盲性以增强通用性", "title_en": "Semantic Adapter for Universal Text Embeddings: Diagnosing and Mitigating Negation Blindness to Enhance Universality", "authors": "Hongliu Cao", "background": "否定在多种自然语言处理任务中扮演着重要角色，尤其是自然语言推理和情感分析任务。以往研究表明，诸如BERT、ELMO、RoBERTa或XLNet等上下文文本嵌入模型在准确理解否定方面存在困难。近期在通用文本嵌入方面的进展虽然在某些任务上表现优越，但由于流行的评估基准的偏见，这些模型的否定感知能力尚不清楚。", "innovation": "本文通过深入分析，研究了最新一代通用文本嵌入模型的否定感知能力，指出这些模型在否定理解方面的显著不足，经常将否定文本对解释为语义相似。为此，提出了一种数据高效和计算高效的嵌入重权方法，无需调整文本嵌入模型的参数，能够在简单和复杂的否定理解任务中显著提高文本嵌入模型的否定感知能力。此外，该解决方案还可以显著改善基于大型语言模型的任务特异性高维通用文本嵌入的否定感知。", "conclusion": "提出的解决方案在简单否定理解任务和复杂否定理解任务中显著提升了文本嵌入模型的否定感知能力，同时解决了不同任务需要在主题和其他语义信息与否定信息之间的不同权衡的问题。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11423", "html_url": "https://arxiv.org/abs/2507.11423", "title": "大型语言模型中的推理策略：它们能跟随、偏好和优化吗？", "title_en": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "authors": "Yanjian Zhang,Guillaume Wisniewski,Nadi Tomeh,Thierry Charnois", "background": "人类推理涉及不同的策略，每种策略适用于特定类型的问题。先前的研究表明，大型语言模型（LLMs）倾向于偏好单一的推理策略，这可能限制了它们在多样化的推理挑战中的有效性。", "innovation": "本研究探究了提示能否控制LLMs的推理策略，并评估其对逻辑问题解决的影响。尽管实验显示没有一种单一策略能始终提高准确性，但通过让模型适应性地选择最佳策略，性能可以得到增强。提出了一种指导LLMs策略选择的方法，强调了改进其推理能力的新途径。", "conclusion": "研究结果显示，尽管没有一种单一策略能始终提高准确性，但通过让模型适应性地选择最佳策略，性能可以得到增强，并提出了新的方法来指导LLMs的策略选择，提高其推理能力的精细化程度。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11330", "html_url": "https://arxiv.org/abs/2507.11330", "title": "学术论文自动化新颖性评估：结合人类和大型语言模型知识的合作方法", "title_en": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "authors": "Wenqing Wu,Chengzhi Zhang,Yi Zhao", "background": "在学术论文的同行评审过程中，新颖性是评价标准之一。传统的评价方法依赖专家判断或通过独特的参考组合来衡量，但这些方法各有不足。专家的知识有限，而参考组合的效果也难以确定。此外，独特的引文是否真正能衡量新颖性也存在疑问。因此，本研究旨在结合大型语言模型（LLM）和人类专家的优势，以克服新颖性评估的局限性。新颖性在学术论文中最常见的一种表现形式是引入新的方法。研究提出了一种利用人类知识和LLM来辅助预训练语言模型（PLMs，如BERT等）预测论文方法新颖性的方法。", "innovation": "研究创新点在于结合了大型语言模型和人类专家的知识，旨在更加准确地评估学术论文的方法新颖性。具体而言，该研究从同行评审报告中提取关于学术论文新颖性的相关句子，并用LLM来总结学术论文的方法部分，随后用于微调PLMs。此外，还设计了一个文本引导融合模块，采用新颖的稀疏注意机制来更好地整合人类和LLM的知识。通过与大量基线方法的比较实验，证明了提出的方法在性能上具有优越性。", "conclusion": "经过广泛实验，本研究提出的方法在新颖性评估方面表现出色，证明了结合人类和大型语言模型知识对于改善新颖性评估的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15670", "html_url": "https://arxiv.org/abs/2505.15670", "title": "高效直接双工模型在语音到语音语言模型中的应用", "title_en": "Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model", "authors": "Ke Hu,Ehsan Hosseini-Asl,Chen Chen,Edresson Casanova,Subhankar Ghosh,Piotr Żelasko,Zhehuai Chen,Jason Li,Jagadeesh Balam,Boris Ginsburg", "background": "口头对话是直观的人机交互方式，但当前的语音语言模型通常局限于回合制的交流，缺乏如用户中断那样的实时适应性。", "innovation": "提出了一个新颖的双工语音到语音（S2S）架构，该架构具有连续用户输入和编码器代理输出，通过通道融合直接建模用户的连续输入和代理的连续输出。该模型使用预训练的流式编码器来处理用户输入，无需进行语音预训练即可成为第一个无需额外语音预训练的双工S2S模型。与之前的模型相比，在模型架构方面，分别对用户和代理进行建模，使得编码器可以进行微调以提高代理声音的质量，并且在此基础上使码率降低到0.6 kbps。实验结果显示，所提出的模型在推理、轮流对话、用户中断等方面优于之前的双工模型。同时，由于可以省略语音预训练，因此需要的语音数据量更少，简化了从任何大规模语言模型（LLMs）构建双工S2S模型的过程。此外，这是首个提供训练和推理代码的公开双工S2S模型，以促进可重复性。", "conclusion": "所提出的模型在需要显著减少语音数据、简化建模过程以及提高性能方面具有显著优势，同时也提供了有助于研究和验证的研究资源。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.09477", "html_url": "https://arxiv.org/abs/2507.09477", "title": "具有深层推理的自主RAG：大型语言模型中RAG-推理系统的综述", "title_en": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs", "authors": "Yangning Li,Weizhi Zhang,Yuyao Yang,Wei-Chieh Huang,Yaozu Wu,Junyu Luo,Yuanchen Bei,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Chunkit Chan,Yankai Chen,Zhongfen Deng,Yinghui Li,Hai-Tao Zheng,Dongyuan Li,Renhe Jiang,Ming Zhang,Yangqiu Song,Philip S. Yu", "background": "检索增强生成(RAG)通过注入外部知识提升了大规模语言模型(LLMs)的事实准确性，但在需要多步推理的问题上存在不足；相反，纯粹基于推理的方法往往会出现虚构或事实错误。本文综述了这一领域的最新进展，并将其统一在推理-检索视角下。文章首先分析了高级推理如何优化RAG的每个阶段，并展示了不同类型的检索知识如何为复杂的推理提供缺失的前提并扩大了上下文。最后，文章强调了新兴的RAG-推理协同框架，其中自主的语言模型迭代地结合搜索和推理，从而在知识密集型基准任务中实现了最先进的性能。", "innovation": "该文提出了一种统一的推理-检索视角，将高级推理优化RAG的各个阶段，不同类型的检索知识如何支持复杂的多步推理，以及新兴的RAG-推理协同框架。重点关注自主LLMs迭代地结合搜索和推理的方法，从而在知识密集型任务中实现最先进的性能。此外，文章还对方法、数据集和开放挑战分类，并指明了通往更有效、多模态适应、可信赖和以人为本的RAG-推理系统的研究方向。", "conclusion": "本文总结了RAG-推理系统的现有方法，评测并比较了这些方法，并概述了未来的研究方向。这些知识密集型基准任务中的RAG-推理系统，表现出更加有效、多模态适应、可信赖和以人为本的特点。相关成果可以访问：this https URL."}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.10543", "html_url": "https://arxiv.org/abs/2412.10543", "title": "METIS：具有配置适应性的快速高质量RAG系统", "title_en": "METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation", "authors": "Siddhant Ray,Rui Pan,Zhuohan Gu,Kuntai Du,Shaoting Feng,Ganesh Ananthanarayanan,Ravi Netravali,Junchen Jiang", "background": "RAG（检索增强生成）能够使大型语言模型（LLMs）利用外部知识生成更好的回应，但使用更多的外部知识则可能会在增加生成质量的同时增加响应延迟。此前的研究要么通过改进RAG查询调度来减少响应延迟，要么通过调整RAG工作流程来最大化质量，但它们未能同时优化响应延迟和质量之间的折衷关系。", "innovation": "论文提出了METIS，这是第一个同时协调调度查询和根据每个查询调整关键RAG配置（如检索文本片段的数量和合成方法）的RAG系统，以平衡质量优化和响应延迟的减少。", "conclusion": "通过使用4个流行的RAG-QA数据集，研究结果表明，与当前最先进的RAG优化方案相比，METIS在没有牺牲生成质量的情况下，将生成延迟降低了1.64-2.54倍。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.08506", "html_url": "https://arxiv.org/abs/2503.08506", "title": "ReviewAgents: 跨越人类与AI生成的论文评论鸿沟", "title_en": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "authors": "Xian Gao,Jiacheng Ruan,Zongyun Zhang,Jingsheng Gao,Ting Liu,Yuzhuo Fu", "background": "学术论文评审是一个关键但耗时的任务。随着学术出版物的增加，自动化评审过程成为了一个重大挑战。主要问题在于生成既全面又准确、且与人类评审员判断一致的评审评论。", "innovation": "该文提出了一种名为ReviewAgents的框架，利用大规模语言模型（LLMs）生成学术论文评审评论。通过构建一个新的名为Review-CoT的数据集（包含142k个评审评论），设计用于训练LLM代理。还提出了一种相关论文意识的训练方法，构建了ReviewAgents多角色多LLM代理评审框架，并提出了一个名为ReviewBench的基准来评估LLM生成的评审评论。实验结果显示，现有LLM在自动化评审过程上具有一些潜力，但在与人类生成的评论相比时仍存在差距。同时，ReviewAgents框架进一步缩小了这一差距。", "conclusion": "尽管现有的LLMs在某些方面显示出一定的潜力，但它们与人类生成的评论相比仍存在差距。ReviewAgents框架能够进一步缩小这种差距，在生成评审评论方面优于高级的LLMs。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.03103", "html_url": "https://arxiv.org/abs/2410.03103", "title": "基于视线长度预测的规划感知代码填充", "title_en": "Planning-Aware Code Infilling via Horizon-Length Prediction", "authors": "Yifeng Ding,Hantian Ding,Shiqi Wang,Qing Sun,Varun Kumar,Zijian Wang", "background": "代码语言模型中的‘中间填充’（FIM），即基于上下文生成缺失的代码，已经成为不可或缺的功能。当前的FIM训练方法通过对重新排序后的序列进行下一步预测（NTP），导致模型生成的代码难以与上下文很好地对齐。作者假设NTP不足以让模型在考虑远距离右侧上下文时进行有效规划，这对于代码填充的成功至关重要。", "innovation": "提出了一种新的训练目标——视线长度预测（HLP），用于训练模型在每一步预测剩余中间代码的数量。HLP结合了向前看的规划，使模型能够无需依赖特定数据集的后处理，自然学习对任意左侧和右侧上下文进行填充的边界。实验结果显示，HLP显著提高了FIM性能，最高提高了24%。", "conclusion": "HLP增强了模型的规划能力，提升了代码推理任务的性能。重要的是，HLP的训练开销小且不需要额外的推理成本，使其在实际应用场景中具有很高的实用性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.15460", "html_url": "https://arxiv.org/abs/2410.15460", "title": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training", "title_en": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training", "authors": "Shahrad Mohammadzadeh,Juan David Guerra,Marco Bonizzato,Reihaneh Rabbany,Golnoosh Farnadi", "background": "随着大型语言模型（LLMs）的日益普及，人们对它们可靠性的担忧也增加了，尤其是在它们产生幻觉（即事实不准确或无关的输出）的情况下。本研究探讨了训练动力学不确定性与幻觉出现之间的关系。利用来自Pythia系列的模型和几种幻觉检测指标，分析了幻觉趋势并发现了训练过程中的显著差异。", "innovation": "提出了Sensitivity Dropout (SenD)，一种新颖的训练协议，通过确定性地移除具有显著差异的嵌入索引来减少训练过程中幻觉的不确定性。此外，开发了Efficient EigenScore（EES）作为无需监督的幻觉检测指标，其速度约为传统EigenScore的两倍。该指标内置到训练协议中，使SenD在减少幻觉不确定性的同时具有计算上的可扩展性和有效性。SenD能 Improve Pythia和Meta's Llama模型在测试时间的可靠性最高17%，并对Wikipedia、医学、法律和编程领域的事实准确性产生正面影响，且不影响下游任务的性能。", "conclusion": "SenD在训练过程中减少幻觉的不确定性，提高了Pythia和Meta的Llama模型在测试时间的可靠性，同时在多个领域提升了事实准确性，且不影响下游任务的性能。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10577", "html_url": "https://arxiv.org/abs/2507.10577", "title": "Truth Sleuth和Trend Bender：用于检查YouTube视频和影响观点的AI代理", "title_en": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "authors": "Cécile Logé,Rehan Ghori", "background": "在当今的数字世界中，虚假信息（misinformation）通过像YouTube这样的平台迅速传播，构成了一个重大威胁。现有的应对措施尚未充分有效地解决这一问题，需要新的技术和方法来应对这一挑战。本文提出的系统通过AI技术不仅能够对YouTube视频中的声明进行事实核查，还能积极参与评论区，挑战错误的信息叙述，从而试图刺激更有成效的讨论，改变用户观点。", "innovation": "本文提出的方法创新之处在于：它设计了一套基于AI的系统，包含两个核心模块——Truth Sleuth和Trend Bender。Truth Sleuth能够从视频中提取声明，并利用RAG方法结合维基百科等可靠来源进行准确的质量评估。Trend Bender利用这些评估生成有针对性且有说服力的评论，以促进更深层次的讨论。通过一个自我评估循环，Trend Bender能够逐步改进其风格和输出。此外，该系统在实际部署中展示了其潜力，不仅能够提升用户参与度，还能影响其看法，认为AI驱动的干预措施对于推动更知情的网络环境具有巨大潜力。", "conclusion": "通过在基准数据集和YouTube实测部署中实验，该系统的准确性和有效性的结果得到了验证。事实核查代理展示了高准确率，表明AI驱动的方法能有效地对抗虚假信息，促进更知情的网络空间。通过Trend Bender生成的评论能够促进更有建设性的讨论，影响用户观点，从而为如何更好地使用AI在社交媒体上管理公共信息提供了新的思路。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12272", "html_url": "https://arxiv.org/abs/2502.12272", "title": "学习推理能力的前沿", "title_en": "Learning to Reason at the Frontier of Learnability", "authors": "Thomas Foster,Jakob Foerster", "background": "强化学习现在被广泛应用于大型语言模型训练的最后阶段，特别是在解答数学问题这类需要推理的任务中。通常情况下，模型会尝试每个问题多次，并从成功和失败中学习。然而，研究表明，在使用两种流行算法（PPO和VinePPO）训练的两个常用数据集上，许多问题要么所有尝试都已正确解答（表示已经学会），要么所有尝试都未正确解答（没有提供有意义的训练信号）。", "innovation": "本文提出了一种新的强化学习阶段的训练曲式方法——采样学习能力。该方法优先选择那些代理有时成功但并不总是成功的具有高成功率波动的问题。实验结果表明，该方法在多种算法和数据集上持续提升了训练性能，为更高效和有效的大型语言模型强化学习提供了可能。", "conclusion": "本文的研究成果表明，这种训练策略在多种算法和数据集上提供了更高效的强化学习，有助于提升大型语言模型推理能力的训练效果。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.10389", "html_url": "https://arxiv.org/abs/2505.10389", "title": "工业领域的多领域多语言情感分析：方面基于的意见四元组预测", "title_en": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "authors": "Benjamin White,Anastasia Shimorina", "background": "本文探讨了使用大型语言模型（LLMs）设计面向实际应用的情感分析系统的方案，重点关注四元意见提取，即从不同领域和语言的文本数据中识别方面类别、情感极性、目标和意见表达。研究了一款单一微调模型能否同时处理多个特定领域的分类体系，并展示了多领域合并模型在性能上与单一领域专业化模型相当的同时，还能简化操作复杂度。此外，还分享了在开发基于LLM的系统进行结构化预测任务时处理非提取预测和各种失败模式的经验教训。", "innovation": "采用单一微调模型处理多个特定领域的分类体系；多领域合并模型的性能与单一领域专业化模型相当，但操作复杂度更低；分享了在开发基于LLM的系统时处理非提取预测和各种失败模式的经验教训。", "conclusion": "多领域的多语言情感分析中，结合多领域模型能够实现接近专门领域模型的效果，且简化了操作复杂度。在开发面向结构化预测任务的LLM系统时，需重视非提取预测和各种可能的失败模式，并从中汲取经验教训。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.02445", "html_url": "https://arxiv.org/abs/2503.02445", "title": "BRIDGE: 通过多智能体迭代优化和扩散建模从文本启动控制时间序列生成", "title_en": "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling", "authors": "Hao Li,Yu-Hao Huang,Chang Xu,Viktor Schlegel,Renhe Jiang,Riza Batista-Navarro,Goran Nenadic,Jiang Bian", "background": "时间序列生成(TSG)在模拟、数据增强和反事实分析等方面具有广泛的应用。虽然现有方法在无条件单域TSG方面表现出一定的潜力，但在实际应用中需要跨域方法来适应特定领域的约束和实例级需求，进行可控生成。现有方法通常无法充分利用文本描述来提供语义洞察、领域信息和实例特定的时间模式，以指导和提高TSG的效果。", "innovation": "本文提出了“文本控制时间序列生成”，该任务旨在通过结合文本描述来生成逼真的时间序列数据。为了应对数据稀缺性问题，作者提出了一种基于LLM的多智能体框架，该框架能够合成多样且真实的文本到时间序列(DTS)数据集。此外，引入了BRIDGE框架，结合了语义原型和文本描述，以支持领域级别的指导。本文方法在11个数据集中实现了最先进的生成保真度，并在均方误差(MSE)和平均绝对误差(MAE)方面分别提高了12%和6%的可控性，突显了其生成定制时间序列数据的潜力。", "conclusion": "本文的BRIDGE框架在多项数据集上取得了最先进的生成保真度，并通过利用文本描述显著提高了控制能力，展示了其在生成定制时间序列数据方面的潜力。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06210", "html_url": "https://arxiv.org/abs/2507.06210", "title": "CultureCLIP: 通过合成图像和语境化描述赋予CLIP 文化意识", "title_en": "CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions", "authors": "Yuchen Huang,Zhiyuan Fan,Zhitao He,Sandeep Polisetty,Wenyan Li,Yi R. Fung", "background": "预训练的视觉-语言模型（VLMs）如CLIP在广义多模态理解方面表现出色，但在捕捉细微、情境依赖的视觉线索方面常常存在困难。这种能力限制使得区分具有潜在不同文化意义的相似概念变得困难。这些不足主要是由于可用的高质量文化数据有限、上下文信息缺乏以及未充分利用负面示例突出细微差异。", "innovation": "本文设计了一个数据精简流程，利用开源VLMs和文本到图像模型来构建CulTwin，这是一个合成的文化数据集。这个数据集由概念-描述-图像三元组组成，这些概念在视觉上相似但文化上不同。然后，对CulTwin进行了微调，开发出CultureCLIP，这是一种通过定制对比学习调整文化概念与上下文化描述和合成图像对齐的CLIP。实验结果表明，CultureCLIP在特定任务中的细化概念识别能力被显著提高（高达5.49%），且保留了CLIP原有的泛化能力，证明了我们的数据合成方法和VLM主体训练框架对于捕捉细微文化差异的有效性。", "conclusion": "CultureCLIP利用有条件生成的图像和上下文化的描述提升了CLIP在跨文化理解能力方面的能力，这一方法在文化专用基准测试中验证了其有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10559", "html_url": "https://arxiv.org/abs/2507.10559", "title": "NLP与世界接轨：提高公众关于自然语言处理研究交流的建议", "title_en": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research", "authors": "Shomir Wilson", "background": "近年来，大型语言模型的发展引发了公众对自然语言处理（NLP）的广泛关注。这种关注在媒体新闻中有所体现，有时还会邀请NLP研究者向公众分享知识和观点。考虑到当前情况下的机会，为了增强研究领域和个体研究者的支持，本文提出了关于如何向公众介绍NLP能力和局限性的建议。这些问题包括模糊术语、不合理的期望和伦理问题。通过引用现有的NLP研究成果和公众新闻报道中的例子来说明这些主题。", "innovation": "文章提出了三个主要主题的建议，以促进有效和透明的公众沟通：模糊术语妨碍公众理解，不合理的期望阻碍可持续增长，伦理失败导致持续支持的问题。这些建议旨在增强公众对NLP的理解，并鼓励对研究的支持。", "conclusion": "本文强调了与公众有效沟通的重要性，通过促进透明和有效的沟通，可以增强公众对NLP的理解和支持。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.09037", "html_url": "https://arxiv.org/abs/2504.09037", "title": "LLM推理前沿综述：推理扩展、学习推理与代理系统", "title_en": "A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems", "authors": "Zixuan Ke,Fangkai Jiao,Yifei Ming,Xuan-Phi Nguyen,Austin Xu,Do Xuan Long,Minzhi Li,Chengwei Qin,Peifeng Wang,Silvio Savarese,Caiming Xiong,Shafiq Joty", "background": "推理是认知过程中的一个基本组成部分，它能够支持逻辑推理、问题解决和决策制定。随着大型语言模型（LLMs）的迅速发展，推理已成为区分高级AI系统和传统模型的关键能力，后者赋能聊天机器人。本文对现有的方法进行了分类，分为两个正交维度：（1）时期，定义了推理被实现的阶段（推理时或通过专门训练）；（2）架构，确定了推理过程中涉及的组件，区分了独立的LLMs和包含外部工具的代理复合系统，以及多代理协作。每个维度内，文章分析了两个关键视角：（1）输入级别，重点关注构造高质量提示的技术；（2）输出级别，优化多个采样候选以提高推理质量的方法。这些分类提供了LLM推理演变景观的系统理解，突出了从推理扩展到学习推理（例如DeepSeek-R1）的转变趋势，以及从传统的学习到代理工作流的变化（例如OpenAI Deep Research，Manus Agent）。此外，还涵盖了从监督微调到如PPO和GRPO等强化学习的广泛学习算法，以及推理者和验证者的培训。最后，还探讨了代理工作流的关键设计，从经典的生成器-评估者模式和LLM辩论到近期的创新设计。", "innovation": "论文对LLM推理的分类方法新颖，特别是通过对推理实现时期和架构的两个维度进行分析，以及对输入和输出级别的两个关键视角进行研究，提供了一种系统理解LLM推理演变的方法。此外，论文详细讨论了从推理扩展到学习推理以及代理工作流的转变趋势，涵盖了各种学习算法和代理工作流设计的关键点", "conclusion": "本文通过分类和分析方法，系统地审视了LLM推理的前沿研究趋势。强调了推理学习和代理系统的发展，特别是从推理扩展到学习推理以及向代理工作流转变的趋势。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.00226", "html_url": "https://arxiv.org/abs/2501.00226", "title": "生成式新兴通讯：大型语言模型是集体世界模型", "title_en": "Generative Emergent Communication: Large Language Model is a Collective World Model", "authors": "Tadahiro Taniguchi,Ryo Ueda,Tomoaki Nakamura,Masahiro Suzuki,Akira Taniguchi", "background": "大型语言模型（LLMs）表现出惊人的能力来捕捉广泛的世界知识，但这种能力是如何在缺乏直接的感知和运动经验的情况下习得的仍是一个基本的谜题。", "innovation": "1) 正式化生成式新兴通讯（Generative EmCom）框架，明确了它与世界模型和多智能体强化学习的关联；2) 将该框架应用于解释大型语言模型，如通过推理解释分布语义现象，揭示生成语言的集体编码过程。", "conclusion": "本研究提供了一种统一的理论，以弥合个体认知发展、集体语言演变和大规模人工智能基础之间的鸿沟。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11550", "html_url": "https://arxiv.org/abs/2507.11550", "title": "Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction", "title_en": "Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction", "authors": "Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim", "background": "智能交通系统中的时空交通预测对于复杂城市区域的准确预测至关重要。虽然准确性和效率对于可扩展性都很重要，但许多先前的方法在捕捉区域和时间周期中变化的交通模式方面存在困难。传统的卷积神经网络(CNNs)受限于非欧几里得空间结构和时空异质性，而图神经网络(GNNs)需要预定义的邻接矩阵，并且由于其内在的复杂性，在大尺度数据集上难以扩大规模。", "innovation": "为了解决这些问题，本文提出了一种变形动态卷积网络(DDCN)来实现精确且高效的时空交通预测。DDCN通过动态应用基于偏移的可变形滤波器来克服传统CNN和GNN的限制，它将 transformer-风格的 CNN 分解为编解码器结构，并应用于编码器的时空注意力模块，强调重要的特征。解码器包括前馈模块，补充编码器的输出。这种新颖的结构使DDCN能够实现准确且高效的交通预测。实验结果表明，DDCN在四个真实的交通数据集上实现了与之前方法相当的表现，突显了基于 CNN 的方法在时空交通预测中的潜力和有效性。", "conclusion": "DDCN 使用变形动态卷积结构，在保持高效的同时实现了时空交通预测的准确性，在实际应用场景中具有潜力和实际效果。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11554", "html_url": "https://arxiv.org/abs/2507.11554", "title": "Inversion-DPO：高效且精准的扩散模型后训练方法", "title_en": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models", "authors": "Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun", "background": "最近有关扩散模型（DMs）的进步主要得益于通过对抗训练方法使其更好地符合人类偏好。然而，这类方法通常需要耗时的基模型和奖励模型的训练，不但计算成本高，还可能影响模型的准确性和训练效率。因此，需要一种新的方法来克服这些限制，提高训练的精确度和效率。", "innovation": "本文提出了一种新的对齐框架——Inversion-DPO，通过DDIM反转直接偏好优化（DPO），绕过了奖励建模，进而从胜利和失败样本到噪声的确定性反转进行不可解后验采样，得出了新的后训练范式。这种方法避免了辅助奖励模型或不准确的近似，显著提高了训练的精确度和效率。文章还在基础的文本到图像生成任务和具有挑战性的组成性图像生成任务上应用了该方法，并进行了一系列广泛实验，表明Inversion-DPO取得了显著性能提升，并有助于生成高质量的、组成性一致的图像。另外，为了提高生成模型的组成能力，作者还制作了一个包含复杂结构注解和全面打分的配对数据集。", "conclusion": "本文探索了一种新的途径，使扩散模型高效、高精度地对齐，进一步提升了其在复杂现实生成任务中的应用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11562", "html_url": "https://arxiv.org/abs/2507.11562", "title": "专家操作GANS：向实际彩色水下图像恢复", "title_en": "Expert Operational GANS: Towards Real-Color Underwater Image Restoration", "authors": "Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj", "background": "水下图像中的变形、复杂光传播和深度相关的衰减导致了广泛的存在变形现象，这使得水下图像恢复成为一个极具挑战性的问题。传统的基于生成对抗网络（GAN）的单生成器网络，难以在包含不同视觉退化现象的不均匀领域中表现良好，因为单一生成器网络通常不足以捕捉到视觉退化的全范围。", "innovation": "提出了一种新型的专家生成器网络模型xOp-GAN，其中包含多个专门训练的专家生成器网络，每个生成器专注于特定的质量范围。这种方法使得每个生成器能够学习在特定质量范围内最大化恢复性能。此外，该模型在推断过程中使用了判别器的选择，使得选择出最佳恢复图像成为可能。这是首个在生成对抗网络（GAN）模型中使用多个生成器，并且在回归任务的推断过程中使用判别器的模型。", "conclusion": "实验结果表明，xOp-GAN在基准大规模水下图像（LSUI）数据集上实现了高达25.16 dB的峰值信噪比（PSNR），显著超越了所有单生成器模型，且具有较低的复杂度。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.04457", "html_url": "https://arxiv.org/abs/2505.04457", "title": "Miipher-2：适用于百万小时规模数据恢复的通用语音恢复模型", "title_en": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "authors": "Shigeki Karita,Yuma Koizumi,Heiga Zen,Haruko Ishikawa,Robin Scheibler,Michiel Bacchiani", "background": "语音恢复（SR）通常依赖于生成模型，但对大规模数据集进行训练的数据清理是一个新的应用。传统方法在处理大规模数据集时存在通用性不足、需要显式条件以及计算效率低等问题。", "innovation": "Miipher-2 是一种设计用于大规模语音恢复的模型，特别适用于百万小时数据规模的场景。其创新点包括：使用冻存、预训练的通用语音模型（USM）作为无条件特征提取器；引入并行适配器以预测干净的USM特征；采用WaveFit神经声音合成器进行波形合成；这些组件在多语言、录音室质量的记录上进行了训练，增加了语言的通用性和计算效率。", "conclusion": "实验证明，Miipher-2 在各种指标上优于或可与传统模型相比拟，具备更好的或相似的词错率、说话人相似度以及客观和主观声音质量。同时，Miipher-2 在消费级加速器上高效运行，实现实时因数为0.0078，仅需100个这样的加速器大约三天即可处理百万小时的语音数据集。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11549", "html_url": "https://arxiv.org/abs/2507.11549", "title": "一种基于神经架构搜索的记忆高效Deformable Transformer框架", "title_en": "An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search", "authors": "Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang", "background": "变形注意变换器(DAT)在计算机视觉任务中通过适配性地关注信息丰富的图像区域展示了出色性能。然而，它们依赖于数据的数据采样机制引入了不规则的内存访问模式，这给高效的硬件部署带来挑战。现有的加速方法要么带来了高硬件开销，要么损害了模型的准确性。", "innovation": "本文提出了一种面向硬件的优化框架来应对这些问题。首先，基于神经架构搜索(NAS)的方法和一个新的分割策略，该方法在推理过程中自动将输入特征分割成均匀的片段，避免了内存冲突，同时未改变模型架构。其次，设计了基于FPGA的验证系统，以测试该框架在边缘硬件上的性能。实验结果表明，我们的硬件友好框架相对于基线DAT只损失了0.2%的准确性，并且在Xilinx FPGA上的硬件实验表明，所提出的方法使得DRAM访问时间减少了18%，相比现有的DAT加速方法而言。", "conclusion": "本文通过创新性地利用神经架构搜索和新的分割策略，结合FPGA验证测试系统，成功开发出了一种面向硬件的高效Deformable Transformer框架，解决了DAT在高效硬件部署上的挑战，并显著提高了硬件部署的效率和性能。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16994", "html_url": "https://arxiv.org/abs/2502.16994", "title": "FADE: 为何良好的特征会对应不上的描述", "title_en": "FADE: Why Bad Descriptions Happen to Good Features", "authors": "Bruno Puri,Aakriti Jain,Elena Golimblevskaia,Patrick Kahardipraja,Thomas Wiegand,Wojciech Samek,Sebastian Lapuschkin", "background": "近期在机制可解释性方面取得的进展强调了自动化可解释性管道在分析LLMs中的潜在作用。这有助于我们理解内部机制，但领域内缺乏标准化评估方法来验证发现的特征的有效性。本研究旨在填补这一空白，通过引入FADE（特征对描述评估）框架，提供一种可扩展且模型无关的方法来自动评估特征与描述之间的对齐情况。", "innovation": "FADE是一个可扩展且模型无关的自动化评估框架，用于评估特征与描述之间的对齐情况。它使用四个关键指标（清晰度、响应性、纯净度和忠实度）系统地量化特征与描述之间错配的原因。", "conclusion": "研究发现揭示了生成特征描述的基本挑战，特别是在SAEs与MLP神经元之间，为自动化可解释性的局限性和未来方向提供了见解。FADE已被作为开源软件发布。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08218", "html_url": "https://arxiv.org/abs/2507.08218", "title": "出上下文推理的简单机制解释", "title_en": "Simple Mechanistic Explanations for Out-Of-Context Reasoning", "authors": "Atticus Wang,Joshua Engels,Oliver Clive-Griffin,Senthooran Rajamanoharan,Neel Nanda", "background": "出上下文推理（OOCR）现象指的是微调的语言模型在分布外环境中表现出令人惊讶的深入推广。相较于学习浅显的经验法则，这些模型隐含地内部化并执行了训练数据中散布观察的后果。这项研究旨在从机制上探讨这一现象，并发现文献中许多OOCR的实例可以简单解释为LoRA微调实际上添加了一个恒定的导向向量，引导模型趋向一个通用的概念，从而提高微调任务和相关概念领域的性能，导致了令人惊讶的推广。", "innovation": "研究发现，许多OOCR的实例可以用一个简单的机制来解释，即LoRA微调本质上添加了一个恒定的导向向量，引导模型趋向一个通用的概念。此外，直接从头训练导向向量也可以引起OOCR。研究还发现，即使是看似需涉及条件行为的任务（模型后门），无条件地添加导向向量也同样足够。这些发现提供了一种关于OOCR期间微调学习了什么的解释，对理解为什么语言模型能够进行出上下文推理这一高级能力，具有重要意义。", "conclusion": "本研究提供了一种关于为什么在OOCR任务期间微调会学习什么的解释，并探讨了语言模型如何能够进行出上下文推理的高级能力。研究成果对于安全可靠地部署这些模型具有重要价值。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11049", "html_url": "https://arxiv.org/abs/2507.11049", "title": "新闻界的指导作用下基于上下文学习的新闻立场检测", "title_en": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "authors": "Dahyun Lee,Jonghyeon Choi,Jiyoung Han,Kunwoo Park", "background": "随着在线新闻消费的增长，个性化推荐系统已成为数字新闻学的重要组成部分。然而，这些系统存在通过忽视多样观点而强化信息茧房和政治极化的问题。立场检测——识别文本在目标议题上的立场——能够帮助缓解这个问题，通过实现观点感知推荐和数据驱动的媒体偏见分析。然而，现有的立场检测研究主要集中在短文本和资源丰富的语言上。本研究旨在解决这些问题，旨在构建首个面向新闻文章级别的立场检测数据集K-News-Stance，并提出一种名为JoA-ICL的框架，来对面文章的关键结构段进行预测和整合，从而检测新闻文章的整体立场。实验结果表明，JoA-ICL比现有方法更有效，强调段落级别的作用对于捕捉长篇文章的整体立场的重要性。进一步的案例研究还证明了该方法在促进新闻推荐中的观点多样性和揭示媒体偏见模式中的广泛适用性", "innovation": "本研究引入了K-News-Stance，首个面向新闻文章级别的立场检测数据集，包含2000篇新闻文章及19650个段落级别立场注释，覆盖47个社会问题。同时，本研究还提出了JoA-ICL框架，这是一种新闻引导的基于上下文学习的代理框架，该框架首先预测新闻中关键结构段落的立场，然后将这些信息聚合起来以推断文章整体的立场。实验结果表明JoA-ICL优于现有方法，特别强调了在长篇文章中通过对段落级别的关注能够更好地捕捉文章的总体立场", "conclusion": "JoA-ICL在检测新闻的文章整体立场方面表现突出，这在其他方法中是特别有效的。进一步的试验结果显示，其在促进新闻推荐中的观点多样化和揭示媒体偏见模式方面具有广泛的应用价值。研究团队将在后续工作中进一步验证JoA-ICL的可靠性和有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11571", "html_url": "https://arxiv.org/abs/2507.11571", "title": "基于传感器的步态年龄估计的数据驱动元分析和公共数据集评估", "title_en": "Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation", "authors": "Varun Velankar", "background": "步态年龄估计在医疗保健、安全和人机交互等领域具有重要应用。已有研究汇总分析了使用视频、可穿戴和雷达传感器记录的超过75000名个体的数据，发现基于卷积神经网络的方法平均误差约为4.2年，基于惯性传感器的方法约为4.5年，而多传感器融合方法的误差最低可至3.4年，同时在实验室和真实环境中的数据差异显著。尽管已有研究，但关于步态年龄估计的全面分析和大型实验及其性能基准仍然有限，特别是在综合多种传感器数据联合分析方面和提取年龄与步态特征之间关系方面，尚未充分探讨.", "innovation": "本文通过对59项研究进行了广泛的元分析与新的大规模实验相结合，量化了年龄与步长、步行速度、步频、步长时间变化性和关节角度熵之间的相关性，使用ResNet34模型并结合Grad-CAM可视化技术揭示网络关注的膝关节和骨盆区域，同时在给定的数据库上比较了多种机器学习模型，发现深度网络能够在不到0.1秒的处理时间内达到高达96％的准确率。", "conclusion": "通过综合广泛元分析、大规模实验及可解释可视化技术，本文为步态年龄估计在实际场景下提供有效基准和实用指导，有助于减少步态年龄估计误差至少3年。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11575", "html_url": "https://arxiv.org/abs/2507.11575", "title": "对于那只是什么猫？一种识别家猫的re-id模型", "title_en": "What cat is that? A re-id model for feral cats", "authors": "Victor Caquilpan", "background": "野生家猫对澳大利亚野生动物造成重大且负面的影响，是世界上最具危害性的入侵物种之一。因此，对这些猫进行密切监控对于减少它们的影响至关重要。在这种背景下，重新识别(re-ID)技术的潜在应用开始出现，通过相机捕获的图像来增强野生动物监控活动。", "innovation": "该研究采用了部分姿态引导网络(PPGNet)模型，最初设计用于东北虎的重新识别，并对其进行了调整以适应野生家猫的特点。此外，研究还探索了对比学习方法，例如ArcFace损失的具体应用。实验结果表明，改进后的PPGNet-Cat模型在识别野生家猫方面表现出色，达到了高精度的平均精确度(mAP)0.86和排名1准确率0.95。", "conclusion": "PPGNet-Cat模型在重新识别方面表现出色，是该领域的竞争性模型。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11642", "html_url": "https://arxiv.org/abs/2507.11642", "title": "基于姿态的行为意图推断及其在运动风格评估和疲劳检测中的应用", "title_en": "Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment", "authors": "Abhishek Jaiswal,Nisheeth Srivastava", "background": "基于姿态的情绪状态推断在疲劳诊断、防止受伤以及提升多种领域性能方面具有巨大潜力。然而，由于人类数据的敏感性，基于视觉的诊断面临着重大挑战，因此这些工具在实际应用之前需要通过大型数据集进行研究验证。为了应对这一挑战，我们确定了体育设置作为从体验多种情绪状态的受试者中收集数据的可行替代方案，并将其应用于板球比赛，提出了一个基于姿态的解决方案以通过运动分析识别人类意图，实现了在区分进攻性与防守性击球意图时超过75%的F1分数和超过80%的AUC-ROC。此外，我们还使用现有数据统计作为弱监督来验证我们的发现，从而提供了克服数据标签限制的潜在解决方法。这项研究为体育分析的技术提供了通用方法，并为在不同领域应用人类行为分析打开了可能性。", "innovation": "提出了一个基于姿态的解决方案来通过运动分析识别人类意图，尤其在区分进攻性与防守性击球意图时表现出色。创新点在于使用体育设置作为数据收集手段，并利用现有数据统计作为弱监督来验证分析结果，有效解决了大型数据集标签不足的问题。", "conclusion": "本研究通过运动分析发现了姿态可以泄露意图的强烈信号，即便在数据管道中存在固有的噪声。同时，提出了适用于体育分析的通用技术，并展望了其在不同领域应用人类行为分析的潜力。"}
{"llm_update_time": "20250717", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10644", "html_url": "https://arxiv.org/abs/2507.10644", "title": "从语义网和多代理系统到代理型人工智能：Web of Agents的统一叙事", "title_en": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "authors": "Tatiana Petrova(1),Boris Bliznioukov(1),Aleksandr Puzikov(1),Radu State(1) ((1) SEDAN SnT, University of Luxembourg, Luxembourg, Luxembourg)", "background": "Web of Agents (WoA) 的概念将静态、文档中心的Web转变为由自主代理人为用户代理行动的环境，随着大型语言模型 (LLMs) 的能力增强而引起了越来越多的关注。然而，这一领域的研究仍分布在不同的社区中，当代综述主要记载了基于LLM的最新框架，而语义网和多代理系统的丰富历史却常被视为独立的遗产领域。这种分裂阻碍了对该领域发展历程的全面理解。", "innovation": "提出了WoA的第一个全面的演化概述，并引入了一个基于四轴的分类框架，将语义基础、通信模式、智能焦点和发现机制四个维度结合起来，提供了一个统一的分析视角来比较所有代理架构代际间的异同。这种框架揭示了从早期标准（如FIPA标准和基于OWL的语义代理）到现代标准（如A2A和MCP）之间清晰的传承关系，而不是断裂。分析指出，代理型AI中的“智能焦点”经历了从外部数据或平台编码到嵌入代理核心模型的转变，这是现代代理型AI的基础。", "conclusion": "尽管新的协议是必要的，但单独依靠它们不足以建立一个强大的、开放和可信赖的生态系统。研究的下一个前沿在于解决持续的社会技术挑战，提出了一个全新的议程，重点关注分布式身份、经济模型、安全和治理，以促进新兴的WoA的发展。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11558", "html_url": "https://arxiv.org/abs/2507.11558", "title": "重塑视觉基础模型以实现时空预测", "title_en": "Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting", "authors": "Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu", "background": "基础模型在自然语言处理和计算机视觉领域取得了显著的成功，展示了建模复杂模式的强大能力。尽管近期研究探索了如何将大型语言模型（LLMs）适应于时序预测任务，但LLMs主要捕捉一维序列依赖性，难以模型时空（ST）关联，这是一种对于准确的ST预测至关重要的因素。", "innovation": "本文提出了一种新颖框架ST-VFM，该框架系统地重新配置视觉基础模型（VFMs）以实现通用的时空预测。ST-VFM采用了双分支架构，结合原始时空输入与辅助时空流输入，并引入了装入时空意识令牌适配器的预VFMs重新配置阶段以及双边跨提示协调模块的后VFMs重新配置阶段，从而不需要修改冻结的VFMs主干即可增强联合表征学习。", "conclusion": "广泛实验表明，ST-VFM在十个时空数据集上优于最先进的基线方法，展示了其在不同VFMs（例如DINO、CLIP、DEIT）和消融研究中的有效性和稳健性，确立了其作为时空预测的强大通用框架的地位。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11579", "html_url": "https://arxiv.org/abs/2507.11579", "title": "SketchDNN: CAD 构造素描联合连续-离散扩散生成", "title_en": "SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation", "authors": "Sathvik Chereddy,John Femiani", "background": "本文提出了一种名为 SketchDNN 的生成模型，用于合成 CAD 素描，并通过统一的连续-离散扩散过程同时建模连续参数和离散分类标签。该研究解决了两项关键挑战：几何元参数的异质性以及 CAD 素描中几何元的置换不变性。", "innovation": "核心创新点在于高斯- softmax 扩散，即将扰动高斯噪声的 logits 转换到概率简单体，以实现离散变量的混合类别标签。该方法从根本上解决了 CAD 素描生成中的两个主要问题，从而显著提高了生成质量，降低了 Fréchet Inception Distance（FID）和负对数似然（NLL）。", "conclusion": "通过引入高斯- softmax 扩散过程，SketchDNN 在 SketchGraphs 数据集上构建了 CAD 素描生成的新最佳表现，FID 从 16.04 降至 7.80，NLL 从 84.8 降至 81.33。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11638", "html_url": "https://arxiv.org/abs/2507.11638", "title": "使用变分自编码器进行直肠癌MRI中可解释的淋巴结转移预测", "title_en": "Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders", "authors": "Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton", "background": "直肠癌的有效治疗依赖于精确的淋巴结转移(LNM)分期。现有基于淋巴结形态（如大小、形状和纹理）的放射学标准对诊断的准确性有限。", "innovation": "提出采用变分自编码器（VAE）作为特征编码模型，替代现有方法中使用的大型预训练卷积神经网络（CNN）。VAE通过重建图像直接编码视觉特征和有意义的模式，生成解析且结构化的潜在空间，使其比CNN更具可解释性。", "conclusion": "提出的VAE-MLP模型在机构内部的MRI数据集上达到了最先进的性能，交叉验证的AUC值为0.86 ± 0.05，敏感性为0.79 ± 0.06，特异性为0.85 ± 0.05。项目代码已发布。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11893", "html_url": "https://arxiv.org/abs/2507.11893", "title": "Spatial Frequency Modulation for Semantic Segmentation", "title_en": "Spatial Frequency Modulation for Semantic Segmentation", "authors": "Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai", "background": "高空间频率信息，如纹理等细部，显著提升了语义分割的准确性。然而，根据奈奎斯特-香农采样定理，高频分量在通过下采样层时（如步进卷积）会遇到混叠或失真的问题。现有方法无法有效处理高频信息导致的信号失真问题，这限制了语义分割的性能。文献中的背景集中在了现有技术的局限性，特别是在下采样过程中高频信息处理的不足。", "innovation": "提出了一种名为Spatial Frequency Modulation (SFM)的新方法，该方法在下采样前对高频特征进行调制至较低频率，在上采样时再恢复。具体实现是通过自适应重采样(ARS)来上调样区域密度，从而根据频率缩放性质降低信号频率。此外，还提出了多尺度自适应上采样（MSAU），通过非均匀上采样恢复被调制后的高频信息。该方法具有扩展性强，可以无缝集成到卷积神经网络和变压器等多种架构中。实验验证表明该方法有效解决了高频信息的失真问题，同时保留了细节。", "conclusion": "方法被成功应用到图像分类、对抗鲁棒性、实例分割和全景分割等多种任务中，表明其广泛适用性和有效性。源代码已公开。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11761", "html_url": "https://arxiv.org/abs/2507.11761", "title": "超越具体任务推理：一种统一的条件生成框架用于抽象视觉推理", "title_en": "Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning", "authors": "Fan Shi,Bin Li,Xiangyang Xue", "background": "抽象视觉推理(AVR)让人类能够快速发现和推广抽象规则到新场景。设计具有人类类似AVR能力的智能系统是人工智能社区长期以来的研究课题。深度AVR解决器在各种AVR任务中取得了显著的成功。然而，它们通常使用特定于任务的设计或参数，在不同的任务之间。在这种模式下，解决新任务通常意味着重新训练模型，有时还需要调整模型架构，这增加了解决AVR问题的成本。", "innovation": "本文提出了一种名为统一条件生成解决器(UCGS)的新颖框架，旨在在统一框架中解决多个AVR任务。首先证明了一些众所周知的AVR任务可以重新表述为预测目标图像在问题面板中可预测性的问题。然后表明，在所提出的框架下，训练一个条件生成模型可以解决各种AVR任务。实验表明，UCGS在单一多任务训练后，在各种AVR任务中展示了抽象推理能力。特别是，UCGS展示了零样本推理能力，使其在测试阶段能够对未见过的AVR任务中解决问题。", "conclusion": "UCGS证明了在统一框架下解决多个AVR任务的可行性，并展示了其在多项AVR任务中的抽象推理能力，尤其是零样本推理能力，这在解决AVR问题上具有重要意义。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11845", "html_url": "https://arxiv.org/abs/2507.11845", "title": "Open-set Few-Shot Image Classification利用原型增强和对齐的ProtoConNet方法", "title_en": "ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification", "authors": "Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng", "background": "开源集少量样本图像分类旨在使用少量标记数据训练模型，使其在面临未知环境时实现良好的泛化。现有方法主要利用单张图像的视觉信息学习类别表示以区分已知和未知的类别。然而，这些方法往往忽略了整合丰富背景信息的好处。", "innovation": "该论文提出了一个称为ProtoConNet的原型增强和对齐方法，整合不同样本的背景信息以增强特征空间的多样性，打破少样本场景中的上下文和图像主体的虚假关联。其主要由三个模块组成：基于聚类的数据选择模块矿化多样数据模式的同时保留核心特征；基于上下文的语义细化模块构建上下文字典以融入图像表示，提高模型的各种场景中的鲁棒性；原型对齐模块减少图像表示与类别原型之间的差距，放大已知和未知类别的特征距离。", "conclusion": "两个数据集的实验结果表明，ProtoConNet增强了少样本场景下的表示学习效果并识别开源集样本，使其优于现有方法。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11892", "html_url": "https://arxiv.org/abs/2507.11892", "title": "从粗糙到细腻：细粒度语言线索和视觉显著区域的跨模态对齐在动态情感识别中的应用", "title_en": "From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition", "authors": "Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li", "background": "动态面部表情识别（DFER）旨在通过识别随时间演变的面部运动来辨别人的情感，在情感计算中起到了关键作用。尽管近期的视觉-语言方法引入了语义文本描述来引导表情识别，但现有方法仍面临两个关键限制：一是经常未能有效利用生成文本中嵌入的细微情感线索，二是尚未引入足够的有效机制来过滤掉与情感表达无关的面部动态。", "innovation": "我们提出了一种名为GRACE的方法，即粒度表示对齐的跨模态情感识别，该方法结合了动态运动建模、语义文本精炼以及基于熵正则化的最优传输的标记级跨模态对齐机制，以促进精确的情感相关时空特征定位。通过逐步情感文本增强（CATE）模块构建情感感知的文本描述，并采用运动差异加权机制突出表达相关的面部运动。", "conclusion": "实验结果表明，我们的方法在挑战性设置中（如含模糊或不平衡情感类别的场景）显著提高了识别性能，并在UAR和WAR方面建立了新的最佳结果。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11931", "html_url": "https://arxiv.org/abs/2507.11931", "title": "Dark-EvGS: 暗光环境下事件摄像头作为重建辐射场的眼睛", "title_en": "Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark", "authors": "Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam", "background": "在低光环境下，传统相机由于动态范围限制和长时间曝光导致的运动模糊，常常难以捕捉到清晰的多视角图像。事件摄像头因其高动态范围和高速性能，可能有助于缓解这些问题。此外，3D 高斯点绘制（GS）可实现从多个视角合成明亮帧的辐射场重建。然而，直接使用事件辅助的3D GS方法仍然存在挑战，因为低光条件下事件噪声较大，帧质量较低，颜色可能不一致。", "innovation": "本文提出了Dark-EvGS，这是第一个事件辅助的3D GS框架，能够从相机轨迹中的任意视角重建明亮帧。提出了三元组级监督以获得整体知识、细节以及锐利场景渲染，还提出了颜色匹配块以保证渲染帧的颜色一致性。同时，建立了第一个基于3D GS辐射场重构的事件引导明亮帧合成的数据集。", "conclusion": "实验结果表明，本文的方法在低光条件下的辐射场重建中表现优于现有方法，实现了更佳的结果。附带的补充材料包括代码和样本数据。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11932", "html_url": "https://arxiv.org/abs/2507.11932", "title": "Hyperphantasia: 一种评估多模态大语言模型心理可视化能力的标准", "title_en": "Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs", "authors": "Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi", "background": "心理可视化，即内在构建和操作视觉表征的能力，是人类认知的核心组成部分，并在涉及推理、预测和抽象的任务中起着至关重要的作用。尽管多模态大型语言模型（MLLMs）取得了快速进展，但当前的基准测试主要评估被动的视觉感知，而对主动构建视觉模式以支持问题解决的能力则了解有限。心理可视化是人类的关键认知技能之一，支持诸如空间导航、预测物理路径和通过想象模拟解决复杂视觉问题等多种能力。因此，有必要建立一个评估MLLMs心理可视化能力的标准，以便更好地理解多模态大语言模型在心理学能力上的局限性与潜力。", "innovation": "我们引入了Hyperphantasia，这是一种全新的合成基准测试，旨在通过四个精心设计的谜题来评估MLLMs的心理可视化能力。每个任务都是程序生成的，并且根据不同难度级别进行呈现，这使得模型性能的分析得以在逐渐增加的复杂性下进行控制研究。我们对前沿模型的全面评估揭示了人类和MLLMs之间显著的能力差距，并探讨了强化学习改善视觉模拟能力的可能性。我们的发现表明，尽管一些模型在识别视觉模式方面表现出一定程度的能力，但坚固的心理可视化仍然是当前MLLMs面临的一个开放性挑战。", "conclusion": "我们的全面评估发现，目前最先进的模型在心理可视化能力方面与人类之间存在显著差距，而强化学习可能是一种提高多模态大语言模型视觉模拟能力的新途径。由于这些因素，Hyperphantasia是一个需要进一步研究的重要基准测试。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11947", "html_url": "https://arxiv.org/abs/2507.11947", "title": "RaDL: 关系感知非监督学习方法在多实例图文生成中的应用", "title_en": "RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation", "authors": "Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee", "background": "随着文本到图像（T2I）模型的最新进展，通过单个图像提示生成多个实例的有效性已成为关键挑战。现有方法虽然在生成单个实例的位置方面取得成功，但在处理关系不一致和多个属性泄漏方面往往表现不佳。为了解决这些局限性，本文提出了关系感知非监督学习框架（RaDL）。RaDL 通过可学习参数增强实例特定属性，并通过关系注意力机制生成关系感知的图像特征，利用从全局提示中提取的动作动词。在 COCO-Position、COCO-MIG 和 DrawBench 等基准测试上的广泛评估表明，RaDL 显著提高了位置精度、多个属性考虑和实例之间关系的处理能力。我们的结果表明 RaDL 是一种既能考虑实例间关系又能考虑到多个属性的多实例图文生成解决方案。", "innovation": "提出了关系感知非监督学习框架（RaDL）。RaDL 通过可学习参数增强实例特定属性，并通过关系注意力机制生成关系感知的图像特征，利用从全局提示中提取的动作动词。该框架能显著提高位置精度、多个属性考虑和实例之间关系的处理能力。", "conclusion": "通过在 COCO-Position、COCO-MIG 和 DrawBench 等基准测试上的广泛评估，我们证明了 RaDL 在多实例图文生成方面的优越性能，展示了其作为同时考虑实例间关系和多个属性的生成解决方案的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11955", "html_url": "https://arxiv.org/abs/2507.11955", "title": "对齐与加权的原型渐进方法在可推广语义分割中的应用", "title_en": "Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation", "authors": "Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu", "background": "通用语义分割旨在对未见过的目标领域表现良好，这是由于真实世界应用需要高度的通用性。类别级原型，代表类中心，作为领域不变线索因其实现了一致的稳定性能而有利于通用性。然而，这种方法面临着三个挑战：首先，现有方法经常采用粗略的原型对齐策略，这可能妨碍性能；其次，通过平均源批次特征计算的朴素原型容易过拟合并可能受到无关源数据的影响；第三，大多数方法均等地对待所有源样本，忽略了不同特征具有不同适应难度的事实。", "innovation": "为解决这些局限性，我们提出了一种新颖的通用语义分割框架：渐进原型对齐和加权（PPAR），利用CLIP模型的强大泛化能力。具体而言，我们定义了两种原型：原始文本原型（OTP）和视觉文本原型（VTP），通过CLIP生成作为对齐的基础。然后引入了一种渐进对齐策略，按容易到困难的方式对齐特征，逐渐缩小领域差距，并提出了一种原型加权机制，估计源数据的可靠性并调整其贡献，减轻无关或有害特征（即减少负面迁移）的影响。我们也提供了一种理论分析，展示了我们的方法与领域泛化理论之间的对齐。广泛实验证明，PPAR实现了最先进的性能，验证了其有效性。", "conclusion": "通过提出PPAR框架，我们成功地提升了通用语义分割的性能，在多个基准测试中实现了最先进的结果，证明了其有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11967", "html_url": "https://arxiv.org/abs/2507.11967", "title": "语言引导的对比音频-视觉掩蔽自编码器及其从视频自动生成的音频-视觉-文本三元组", "title_en": "Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos", "authors": "Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki", "background": "现有音频-视觉掩蔽自编码器模型在跨模态学习方面存在一些瓶颈，主要集中在缺乏有效的音频-视觉-文本对齐方法和需要大量手动标注数据的问题上。该研究试图解决这些问题，提出了一种新的方法来改善音频-视觉表征学习。", "innovation": "提出了Language-Guided Contrastive Audio-Visual Masked Autoencoders (LG-CAV-MAE)，它通过将预训练文本编码器整合到对比音频-视觉掩蔽自编码器中，实现了音频、视觉和文本模态跨模态学习。研究团队还提出了一种自动方法，用于从未标注的视频中生成高质量的音频-视觉-文本三元组。这种方法利用图像字幕模型生成帧级字幕，并通过CLAP过滤器确保音频与字幕之间的强对齐，从而避免了手动标注的需求。", "conclusion": "通过实验，该方法在音频-视觉检索和分类任务上表现优异，显著优于现有方法，具体表现为检索任务中recall@10提升了5.6%，分类任务中提升了3.2%。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11910", "html_url": "https://arxiv.org/abs/2507.11910", "title": "SEPose: 一种用于行人监测的合成事件驱动人体姿态估计数据集", "title_en": "SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring", "authors": "Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi", "background": "事件传感器已经成为了解决行人和交通监控系统中具有挑战性条件的有前景解决方案。它们的优势在于低延迟和高动态范围，使得在由于分心行走或其他异常运动引起的安全关键情况下能够提高响应时间。然而，覆盖这些场景的数据可用性仍然有限。为了填补这一空白，本文提出了SEPose——一个由CARLA仿真器中的动态视觉传感器生成的固定行人感知的全面合成人体姿态估计数据集。该数据集包括从固定交通摄像头视角注释的接近35万个带有身体姿态关键点的行人样本，覆盖了繁华和稀疏的人群和交通，以及各种照明和天气条件下的城市、郊区和乡村环境中的四向交叉路口场景。", "innovation": "SEPose通过使用CARLA模拟器中的动态视觉传感器来生成合成人体姿态估计数据集，提供了超过35万个行人样本，覆盖了不同的照明和天气条件，适用于多种环境中的行人监控。该数据集有针对性地填补了现有数据集在行人监测中的不足，特别是在行人姿态估计方面。SEPose利用现有的最先进的模型，如RVT和YOLOv8，在该数据集上进行训练并在实际事件驱动的数据上进行评估，以展示拟提出的数据集的模拟到真实场景的一般化能力。", "conclusion": "SEPose是一个全面的合成多个人体姿态估计数据集，能够模拟不同的照明和天气条件，以及多种环境中的行人行为。该数据集通过训练现有的最先进的模型并评估它们在实际事件驱动数据上的性能，展示了模拟到真实场景的一般化能力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11900", "html_url": "https://arxiv.org/abs/2507.11900", "title": "CompressedVQA-HDR：适用于压缩高动态范围视频的一般化全参考和无参考质量评估模型", "title_en": "CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos", "authors": "Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai", "background": "视频压缩是所有视频的标准化过程，旨在减少存储和传输需求，同时尽可能保留视觉质量。因此，评估压缩视频的质量对于指导视频压缩算法的实际应用和进一步发展至关重要。尽管已经提出了许多压缩视频质量评估（VQA）方法，但在处理高动态范围（HDR）内容的日益多样化时，这些方法往往缺乏泛化能力。", "innovation": "本文介绍了CompressedVQA-HDR框架，这是一种专为HDR视频质量评估而设计的有效VQA模型。具体来说，本文采用了Swin Transformer和SigLip 2作为全参考（FR）和无参考（NR）VQA模型的骨干网络。为FR模型，通过从Swin Transformer中提取的中间层特征计算参考帧和失真帧之间的深度结构和纹理相似性，作为其质量感知特征表示。对于NR模型，提取SigLip 2最终层特征图的全局均值作为其质量感知表示。为了缓解HDR训练数据有限的问题，FR模型在大规模标准动态范围（SDR）VQA数据集上进行了预训练，并在HDRSDR-VQA数据集上进行微调。对于NR模型，采用跨多个压缩VQA数据集的迭代混合数据集训练策略，然后在HDRSDR-VQA数据集上进行微调。实验结果表明，本文的模型在全参考和无参考VQA模型中达到了最先进的性能，并且CompressedVQA-HDR-FR在IEEE ICME 2025通用可扩展HDR和SDR视频质量度量大奖赛的全参考赛道中获得了第一名。", "conclusion": "本文提出了一种适用于压缩HDR视频的VQA框架CompressedVQA-HDR，通过对比实验证明了其卓越的性能，并在国际比赛中获得了第一名。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11980", "html_url": "https://arxiv.org/abs/2507.11980", "title": "EC-Diff: 快速且高质量的边缘-云协作推理以满足扩散模型", "title_en": "EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models", "authors": "Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu", "background": "扩散模型在图像和视频合成方面表现出色，但随着模型规模和延迟的增加，限制了用户体验。最近提出了一种边缘-云协作框架来实现实时推理和高质量生成，其中云模型负责高质量的语义规划，边缘模型负责后期处理的加速。然而，过度依赖云端的去噪过程会延长推理时间，而边缘模型切换不及时会导致语义模糊和生成质量下降。", "innovation": "提出了一种名为EC-Diff的方法，通过基于梯度的噪声估计加速云推理，并确定云-边缘切换的最佳点以保持生成质量。具体而言，设计了一种K步噪声逼近策略，通过步骤间的噪声梯度减少云推理频率，并定期进行云推理以调整错误。同时设计了一种两阶段贪心搜索算法，以高效地找到噪声逼近和边缘模型切换的最佳参数。", "conclusion": "广泛的实验表明，本方法相对于边缘推理显著提升了生成质量，同时相比于纯云推理的速度提升可达平均2倍。视频样本和源代码可在提供的链接中获取。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11730", "html_url": "https://arxiv.org/abs/2507.11730", "title": "边缘可部署OCR模型的户外招牌可见性分析：一种调查", "title_en": "Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis", "authors": "Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying", "background": "户外广告仍然是现代营销的重要媒体，但在实际条件下准确验证路牌文字可见性仍然具有挑战性。传统光学字符识别（OCR）流水线在识别裁剪文本方面表现出色，但在复杂户外场景、不同字体和天气引起的视觉噪声面前时常出现问题。最近，多模态视觉-语言模型（VLMs）作为一种替代方案引起了关注，它们能够提供端到端的场景理解，而无需显式的检测步骤。", "innovation": "本研究系统性地将代表性的VLMs（包括Qwen 2.5 VL 3B、InternVL3和SmolVLM2）与一个紧凑的基于CNN的OCR基线（PaddleOCRv4）在两个公开数据集（ICDAR 2015和SVT）上进行比较，并通过合成天气畸变增强了这些数据集，以模拟现实降级情况。研究结果揭示了VLMs在整体场景推理方面的优势，但轻量级CNN流水线在裁剪文本识别中的准确度接近基线，且计算成本远低于VLMs，这对边缘部署尤为重要。", "conclusion": "为了促进未来的研究，我们发布了一种增强的天气基准和评估代码。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11834", "html_url": "https://arxiv.org/abs/2507.11834", "title": "CorrMoE：去样式化学习与Mixture of Experts相结合的跨场景和跨域对应精简", "title_en": "CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning", "authors": "Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang", "background": "在计算机视觉中，建立图像对之间的可靠对应关系是一个基础任务，支撑着诸如3D重建和视觉定位等应用。尽管最近的方法在从密集的对应点集中消除异常值方面取得了进展，但它们往往假设一致的视觉领域，并且忽视了由多种情景结构带来的挑战。", "innovation": "本文提出了一种新颖的对应精简框架——CorrMoE，它增强了在跨领域和跨场景变化下的鲁棒性。通过引入去样式化双分支，CorrMoE 在隐式和显式图特征上进行风格混合，以减轻特定领域表示的负面影响。为了处理场景多样性，它设计了一个双向融合Mixture of Experts模块，该模块通过线性复杂度注意力和动态专家路由来结合多视角特征。", "conclusion": "在基准数据集上的广泛实验表明，CorrMoE 在准确性和泛化能力方面优于目前最先进的方法。相关代码和预训练模型可在以下链接获取：this https URL"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11968", "html_url": "https://arxiv.org/abs/2507.11968", "title": "watch_listen_understand_mislead", "title_en": "Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation", "authors": "Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda", "background": "近年来，多模态大型语言模型（MLLMs）在内容审核方面得到了广泛应用，但在短视频环境中的鲁棒性却很少受到关注。当前的安全评估往往依赖于单一模态的攻击，但未能解决复杂的攻击漏洞。该论文通过引入一个全面的框架，评估MLLMs在视觉、听觉和语义三种模式下的安全性，揭开了其在短视频环境中的脆弱性，并提供了关键见解以开发更稳健和安全的MLLMs。", "innovation": "该研究提出了一个全面的框架，用于评估MLLMs在三模态下的安全性，引入了名为SVMA的新型短视频多模态对抗数据集，以及ChimeraBreak，一种同时挑战视觉、听觉和语义推理路径的新型三模态攻击策略。该方法发现当前模型在处理误分类问题时存在显著的偏差，能够评估攻击的有效性，并揭示了模型在对抗攻击中的独特失败模式。", "conclusion": "广泛实验显示，当前领先级别的MLLMs在对抗攻攻击方面存在显著的高攻击成功率（ASR）。研究结果提供了一些关键的见解，以开发更为健全和安全的MLLMs，数据集和发现对于构建更安全的内容审核系统至关重要。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11985", "html_url": "https://arxiv.org/abs/2507.11985", "title": "基于描述符引导的掩码图像恢复及优化约束的无监督部件发现", "title_en": "Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints", "authors": "Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang", "background": "零件级别的特征对于图像理解至关重要，但由于缺乏精细颗粒度的标签，很少有研究关注这部分。虽然无监督的部件发现可以消除对标签的依赖，但大多数方法在不同类别和场景中无法保持鲁棒性，这限制了其应用范围。目前，部分发现方法在复杂场景下难以可靠地识别部件形状，并且缺乏针对不同场景和类别的鲁棒部件识别方法。", "innovation": "提出了一个新的更有效的无监督部件发现范式，称为掩码部分自编码器（Masked Part Autoencoder，MPAE）。MPAE通过学习部分描述符和特征图，从原图的掩码版本中提取局部特征。然后，根据局部特征与描述符的相似性填充掩码区域。通过使用部分描述符恢复这些填充区域，使部分描述符更与实际物体形状对齐，并且在遮挡等多种挑战下能鲁棒地发现有意义的部件。此外，提出了几种更加宽松但更有效的约束以提高无监督部件发现性能，从而更好地处理部件识别中的跨场景和跨类别问题。", "conclusion": "广泛的实验表明，我们的方法能够在多种类别和场景中 robust 地发现有意义的部件。同时，该方法为未来的部件相似性探索提供了良好的基础，并且代码已开源。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11653", "html_url": "https://arxiv.org/abs/2507.11653", "title": "VISTA: 单目语义分割建图用于外观和视角不变的全局定位", "title_en": "VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization", "authors": "Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How", "background": "全局定位对于自主导航至关重要，特别是在不同会话或由其他代理生成的地图中定位时，由于代理缺乏有关参考框架之间相关性的先验知识。然而，在未结构化的环境中，传统的地点识别方法由于视点变化、季节变化、空间混叠和遮挡导致的外观变化，使得这一任务仍然具有挑战性。", "innovation": "提出了一种名为VISTA的新颖开集单目全局定位框架，该框架结合了：1) 基于对象的前端分割和跟踪流水线；随后是2) 子地图对应搜索，利用环境地图之间的几何一致性对车辆参考框架进行对齐。VISTA能够跨不同的摄像机视角和季节变化实现一致的定位，无需任何特定领域的训练或微调。", "conclusion": "我们在季节变化和斜视角的航空数据集上评估了VISTA，相比基线方法在召回率上取得了高达69%的提升。此外，我们维护了一个紧凑的对象基地图，其大小仅为最节省内存基线的0.6%，使我们的方法能够在资源受限的平台上实现实时实施。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11990", "html_url": "https://arxiv.org/abs/2507.11990", "title": "ID-EA：基于身份驱动的文本增强和适配以文本反转实现个性化文本到图像生成", "title_en": "ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation", "authors": "Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee", "background": "近年来，利用文本到图像扩散模型生成个性化的肖像取得了显著进展，通过文本反转技术，创建高保真个性化图像成为一种有前景的方法。尽管如此，当前的文本反转方法在保持面部身份一致性方面存在挑战，因为文本和视觉嵌入空间在身份方面的语义对齐不足。", "innovation": "本文介绍了ID-EA，这是一种新颖的框架，能够引导文本嵌入与视觉身份嵌入对齐，从而提高个性化生成中的身份保留能力。ID-EA 框架包括两个关键组件：ID驱动增强器（ID-Enhancer）和ID条件适配器（ID-Adapter）。ID-Enhancer将身份嵌入与文本ID锚点集成，使用代表性的文本嵌入对人脸识别模型提取的视觉身份嵌入进行细化。ID-Adapter利用身份增强的嵌入来调整预训练的UNet模型中的交叉注意力模块，确保通过调整文本条件来保持身份的一致性。该过程鼓励文本特征在前景片段中找到最相关的视觉线索。", "conclusion": "大量的定量和定性评估表明，ID-EA 在身份保留指标上显著优于当前最先进的方法，同时实现了杰出的计算效率，生成个性化肖像的速度比现有方法快约15倍。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11986", "html_url": "https://arxiv.org/abs/2507.11986", "title": "在不同LoRA模块内的风格组成", "title_en": "Style Composition within Distinct LoRA modules for Traditional Art", "authors": "Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak", "background": "基于扩散的文本到图像模型在从文本提示生成多样化图像方面取得了显著成果，并可以通过风格个性化捕捉特定的艺术风格。然而，这些模型的交织潜在空间以及缺乏平滑插值使得按控制区域应用不同的绘画技术变得困难，常常导致单一风格占主导地位。", "innovation": "我们提出了一个零射线扩散管道，通过流匹配去噪过程预测的去噪潜在变量上执行风格组合，自然融合多个风格。我们利用较低噪声的潜在变量携带更强烈的风格信息，通过空间遮罩在异构扩散管道中融合它们，使得能够实现精细且区域特定的风格控制。此外，为了确保不同模型之间的结构性连贯性，我们通过将ControlNet深度图条件引入扩散框架。", "conclusion": "我们的方法通过给定的遮罩成功实现了区域特定的风格混合。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11994", "html_url": "https://arxiv.org/abs/2507.11994", "title": "SAMST：基于SAM伪标签过滤的变压器框架在遥感半监督语义分割中的应用", "title_en": "SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation", "authors": "Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui", "background": "公共遥感数据集由于分辨率不一致和土地覆盖类别定义不一致而往往面临普遍性的限制。利用大量的未标记遥感数据具有挑战性。现有方法难以处理这些数据集，特别是在有大量未标记数据和少量标记数据的情况下，语义分割任务的表现受限。为此，本文探讨了如何利用未标记的遥感数据进行半监督语义分割，以解决标记数据稀缺的问题。", "innovation": "本文提出了一种半监督语义分割方法SAMST。SAMST利用Segment Anything Model (SAM) 在零样本泛化和边界检测方面的优势，并提出了一种迭代伪标签精炼的方法，包括监督模型自我训练和基于SAM的伪标签精炼器。伪标签精炼器包含三个模块：预处理阈值过滤模块、提取连接区域和生成SAM提示的提示生成模块，以及最终标签缝合的标签精炼模块。该方法结合了大型模型的泛化能力和小型模型的训练效率，提高了伪标签的准确性，从而提高了整体模型性能。实验验证了SAMST的有效性和可行性，展示了其在遥感语义分割中解决标记数据稀缺问题的潜力。", "conclusion": "实验结果表明，SAMST在Potsdam数据集上的表现证明了其在半监督遥感语义分割中的有效性，特别是对于解决标记数据稀缺问题具有显著优势。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12006", "html_url": "https://arxiv.org/abs/2507.12006", "title": "频域动态注意力调制用于密集预测", "title_en": "Frequency-Dynamic Attention Modulation for Dense Prediction", "authors": "Linwei Chen,Lin Gu,Ying Fu", "background": "视觉变换器（ViTs）在计算机视觉领域取得了显著进展，但在应用中也暴露了其机制导致的关键细节和纹理丢失的问题。原因在于注意力机制使每一层都作为一个低通滤波器工作，而现有的Transformer架构叠加层导致了频率消失，这种缺陷使得图像中的细粒度信息和纹理丢失。已有研究指出，如何通过动态调节来改善高通滤波以弥补低通滤波不足的需求。文章针对这一背景提出了一种称为频域动态注意力调制（FDAM）的方法，该方法可以在不改变ViTs结构的前提下，通过Attention Inversion和Frequency Dynamic Scaling技术动态调节整个频谱响应，以增强模型的细节捕捉能力。", "innovation": "提出的FDAM方法引入了Attention Inversion（注意力反转）技术和Frequency Dynamic Scaling（频率动态缩放）技术。其中，注意力反转通过反转注意矩阵中的低通滤波器并动态结合，生成互补的高通滤波器，改善低频和高频信息的传输；频率动态缩放则针对不同的频率成分进行权值调整，以实现细腻的目标响应函数调整。该方法通过特征相似性和有效秩评估证明了对多种模型（如SegFormer、DeiT、MaskDINO）在语义分割、目标检测和实例分割任务中的性能改进，并在遥感检测任务中达到了最先进的单尺度生成结果。", "conclusion": "通过将FDAM集成到ViTs中，并通过实验证明了其对于各类视觉任务的性能改进，特别是在语义分割和遥感检测方面的显著提升，展示了其对于现有ViTs的有效改进作用。相关代码也已开源供研究者使用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12009", "html_url": "https://arxiv.org/abs/2507.12009", "title": "与自然刺激相关的深度神经编码-解码模型", "title_en": "Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli", "authors": "Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville", "background": "该研究提出了一种端到端的深度神经编码-解码模型，利用功能性磁共振成像(fMRI)数据编码和解码对自然刺激的脑活动反应。这种方法通过利用连续电影帧之间的时间相关性输入，并在模型架构中使用时间卷积层，解决了自然电影刺激与fMRI采集之间的时间分辨率差距问题，旨在预测视觉皮层及其周围的脑区活性，并重建相应的视觉输入。此外，通过显著性图研究了参与视觉解码的大脑区域，在视觉解码器中重建边缘、面孔和对比度等功能区域的活性表明，这些大脑区域在这些任务中起着重要作用，与模型的解码能力一致。", "innovation": "研究提出了一个利用时间卷积层的端到端深度神经编码-解码模型，该模型可以有效地缩小自然电影刺激与fMRI采集之间的时分辨率差距，预测对自然刺激的脑活动，并重建视觉输入。该研究通过显著性图进一步探讨了解码中贡献最大的脑区，并与模型的解码能力进行了对比，明确了这些脑区的功能至关重要。", "conclusion": "研究通过使用深度学习模型的解码行为，提供了探查电影中视觉处理理解的可能方法。研究表明，视觉皮层和周围的脑区在此过程中发挥了核心作用，其活性与能重建的边缘、面孔和对比度等视觉特征相符。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12017", "html_url": "https://arxiv.org/abs/2507.12017", "title": "SS-DC: 跨可见-红外区间的空间光谱解耦与耦合用于领域自适应目标检测", "title_en": "SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection", "authors": "Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng", "background": "从可见光域到红外（RGB-IR）域的无监督领域自适应目标检测（UDAOD）面临着挑战。现有方法将RGB域视为统一域，忽略了其中的多个子域，如白天、夜晚和雾天场景。有观点认为，通过光域不变（DI）和光域特定（DS）特征在多个子域上的解耦，能够改善RGB-IR域适配效果。现有方法由于未能有效区分这些特征，导致适应效果不佳， datasets如FLIR-ADAS等展示了这一挑战。现有UDAOD方法未能充分考虑RGB域内的子域差异，限制了整体性能提升。因此，需要一种能够同时处理光谱和空间差异的方法来改善域适应性能.", "innovation": "本文提出了一种新的SS-DC框架，基于解耦-耦合策略。该框架在光谱分解方面设计了一种光谱自适应伊普塞比解耦（SAID）模块，通过基于滤波器组的光谱处理范式和自蒸馏驱动的解耦损失，提高了光谱域的解耦效果。此外，提出了一种新型的空间-光谱耦合方法，通过空间和光谱的光域不变特征金字塔实现联合耦合，同时将解耦中的DS特征引入以减少领域偏置。", "conclusion": "大规模实验表明，本文方法可显著提升基线性能，并在多个RGB-IR数据集（包括本研究提出的新实验协议）上优于现有UDAOD方法。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12012", "html_url": "https://arxiv.org/abs/2507.12012", "title": "识别肝脏疾病治疗反应的图像表型特征", "title_en": "Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease", "authors": "Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs", "background": "可量化的图像模式对于指导个体治疗和开发新型疗法至关重要。本文探讨了无监督机器学习如何在核磁共振图像中识别肝组织的模式词汇，以量化弥漫性肝病的治疗反应。通过深聚类网络同时编码和聚类医疗图像片段，低维潜空间中生成组织词汇，从而捕捉与治疗反应相关的不同组织变化及其位置。此方法已在随机对照试验队列的非酒精性脂肪肝患者中得到了验证和应用。这种方法可比较安慰剂组和治疗组的纵向肝脏变化，并展示了与治疗相关的肝脏组织变化路径，与传统的非成像措施相比，能够更好地分离治疗组。此外，这种方法可以预测从非侵入性成像数据推导出的活检特征。通过另一独立验证队列证明了该方法的应用性", "innovation": "本文提出了一种利用无监督机器学习技术生成肝组织模式词汇的方法，该方法能够量化治疗反应、识别与治疗相关的肝脏组织变化路径，并预测非侵入性成像数据中的活检特征。该方法能够更好地分离不同治疗组，并利用低维度潜空间捕捉组织变化及其位置，实现对治疗效果的追踪和评估", "conclusion": "本文提出的方法在随机对照试验队列中的应用验证了其有效性，能够追踪治疗反应，且能够更好地分离治疗组，进一步证明了其在非侵入性成像数据预测中的实际应用价值。该方法为肝脏疾病治疗提供了新的定量工具，并有助于开发新型疗法"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12022", "html_url": "https://arxiv.org/abs/2507.12022", "title": "预训练掩蔽模型的数据集所有权验证", "title_en": "Dataset Ownership Verification for Pre-trained Masked Models", "authors": "Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song", "background": "高质量的开源数据集已成为推动深度学习迅速发展的关键催化剂，但同时也面临着潜在被利用的风险。保护这些数据集对于其所有者的利益至关重要。数据集所有权的验证已成为这一领域的关键方法，然而现有的验证技术主要针对监督模型和对比预训练模型，在直接应用于日益普及的掩蔽模型时显得力不从心。因此，本研究引入了首个针对这一未解决挑战的方法，即掩蔽建模数据集所有权验证（DOV4MM），旨在确定疑似黑盒模型是否在特定未标注数据集上进行了预训练，从而帮助数据集所有者保护自己的权益。研究表明，当模型在目标数据集上进行预训练时，嵌入空间内掩蔽信息重建的难度与未在该数据集上预训练的模型相比有显著差异。", "innovation": "本研究提出了首个针对未标注数据集的预训练掩蔽模型的数据集所有权验证方法DOV4MM。与现有的验证技术不同，DOV4MM特别适用于掩蔽模型，其核心在于通过对模型预训练前后在嵌入空间中重建掩蔽信息难度的对比，来判断模型是否在目标数据集上进行了预训练。实验证明DOV4MM在ImageNet-1K的10个掩蔽图像模型和WikiText-103的4个掩蔽语言模型上的表现优于所有先前的方法，能够显著拒绝零假设，p值远低于0.05。", "conclusion": "DOV4MM是一种有效且新颖的数据集所有权验证方法，尤其是在掩蔽模型的应用场景中。该方法通过嵌入空间中掩蔽信息重建难度的对比，能够准确检测到模型在特定未标注数据集上的预训练情况，为数据集所有者提供了重要的保护机制。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12023", "html_url": "https://arxiv.org/abs/2507.12023", "title": "MVAR: 多变量自回归空气质量预测模型", "title_en": "MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model", "authors": "Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li", "background": "空气污染物对环境和人类健康构成了重大威胁，因此准确预测污染物浓度对于污染预警和政策制定至关重要。现有研究主要集中在单一污染物预测，忽视了不同污染物之间的相互作用及其多样的空间响应。解决多污染物预测的实际需求，本研究提出了多变量自回归空气污染物预测模型（MVAR），该模型减少了长时间窗口输入的依赖性，提升了数据利用效率，同时设计了多变量自回归训练框架，实现了长达120小时的长期序列预测。此外，MVAR还开发了气象耦合空间变换块，能够灵活地结合基于AI的气象预报并学习污染物间及其空间响应的交互作用。面对空气质量预测中缺乏标准化数据集的问题，构建了一个覆盖2018年至2023年间北中国75个城市6种主要污染物的综合数据集，包括ERA5再分析数据和FuXi-2.0预报数据。实验结果表明，所提出的模型优于现有最先进的方法，验证了所提出架构的有效性。", "innovation": "1. 提出了多变量自回归空气污染物预测模型（MVAR），减少了长时间窗口输入的依赖性，提升了数据利用效率。\n2. 设计了多变量自回归训练框架，实现了长达120小时的长期序列预测。\n3. 开发了气象耦合空间变换块，能够灵活地结合基于AI的气象预报并学习污染物间及其空间响应的交互作用。\n4. 构建了综合的数据集，覆盖北中国75个城市6种主要污染物，包括ERA5再分析数据和FuXi-2.0预报数据，填补了标准化数据集的空白。\n5. 该模型在实验中表现出色，优于现有最先进的方法，验证了所提出架构的有效性。", "conclusion": "提出的MVAR模型通过减少对长时间窗口输入的依赖性和有效数据利用，实现了多变量空气质量的长期预测，并通过气象耦合和灵活的空间变换增强模型的学习能力。通过构建综合数据集并进行实验证明，MVAR模型在预测准确性和实用性方面具有明显优势。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12026", "html_url": "https://arxiv.org/abs/2507.12026", "title": "3D-MoRe: 统一的多模态上下文推理方法用于基于环境的问答", "title_en": "3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering", "authors": "Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu", "background": "随着室内场景任务（如问答和密集标注）对多样化和可扩展的数据需求增加，本文提出了3D-MoRe，一种通过利用基础模型优势生成大规模3D语言数据集的新范式。3D-MoRe框架结合了多模态嵌入、跨模态交互和语言模型解码器等关键组件，以处理自然语言指令和3D场景数据，增强在复杂3D环境中的推理和响应生成能力。使用ScanNet 3D场景数据集和ScanQA及ScanRefer的文字注释，3D-MoRe生成了62,000个问答对和73,000个对象描述，覆盖1,513个场景。为了确保高质量的数据，本文还采用了多种数据增强技术和语义过滤手段。实验表明，在ScanQA和ScanRefer任务中，3D-MoRe均显著优于现有基线，分别提高了CIDEr分数2.15%和CIDEr@0.5分数1.84%。", "innovation": "3D-MoRe引入了统一的多模态上下文推理方法，通过多模态嵌入、跨模态交互和语言模型解码器来处理自然语言指令和3D场景数据，生成大规模高质量的3D语言数据集。这种方法能有效提升在复杂3D环境中的推理和响应生成能力。实验结果表明，3D-MoRe在ScanQA和ScanRefer上的表现优于现有基线，特别是在CIDEr指标上的改进更为显著。", "conclusion": "本文提出了3D-MoRe方法，实现了3D场景数据中高质量问答数据的生成，并通过ScanQA和ScanRefer任务验证了其效果。为了支持社区研究，3D-MoRe的代码和数据集将公开发布。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12029", "html_url": "https://arxiv.org/abs/2507.12029", "title": "Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery", "title_en": "Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery", "authors": "Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He", "background": "现有研究已经取得显著进展，但在处理新颖类发现（NCD）问题时 still存在两个主要限制：第一，侧重于单视图数据（如图像），未能充分利用日益常见的多视图数据，如多组学数据在疾病诊断中的应用；第二，依赖伪标签来监督新颖类聚类，这会导致性能不稳定，因为伪标签的质量受到数据噪声和特征维度等多因素的影响。", "innovation": "本文提出了一种名为Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery (IICMVNCD)的新型框架。该框架是首个尝试在多视图设置下解决NCD问题的框架。具体来说，上述框架首先在单视图层面利用已知类和新颖类之间的分布相似性，运用矩阵分解将特征分解为视图特异性共享基础矩阵和因素矩阵；接着在视图层面，利用已知类之间的视图关系来引导新颖类的聚类，通过加权融合因素矩阵并动态调整已知类的视图权重来生成预测标签，然后将其转移到新颖类学习中，以提高聚类效果和稳定性。", "conclusion": "实验结果验证了我们提出的方法的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12060", "html_url": "https://arxiv.org/abs/2507.12060", "title": "InstructFLIP: 探索统一的图语言模型用于面部防欺骗", "title_en": "InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing", "authors": "Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng", "background": "面部防欺骗（FAS）旨在构建一个能够抵御各种攻击的鲁棒系统。尽管最近的努力主要集中在跨域泛化上，但两个重大挑战依然存在：对攻击类型的有限语义理解以及跨域训练的冗余。前者导致系统难以准确识别不同类型的欺骗攻击，后者使得跨不同的应用场景下训练模型时的效率低下和效果不一。现有方法致力于解决跨域泛化的提升，而在面对语义理解和训练冗余时未能有效解决。", "innovation": "本文提出了一种创新的方法InstructFLIP，它利用图语言模型（VLMs）通过文本指导来增强泛化能力，专注于单一领域的训练。InstructFLIP的核心是在内容和样式组件之间明确地解耦指令。内容基于的指令关注欺骗行为的基本语义，而样式基于的指令则考虑与环境和摄像机特性相关的变量。该框架显著降低了跨多种领域训练的冗余，并且相比现有的SOTA模型在准确率上表现更佳。", "conclusion": "通过大量实验，证明了InstructFLIP的有效性，它能够在不同领域中显著提升面部防欺骗系统的准确率，并大幅度减少了训练冗余。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12001", "html_url": "https://arxiv.org/abs/2507.12001", "title": "AU-Blendshape 用于精细粒度的3D面部表情操控", "title_en": "AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation", "authors": "Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan", "background": "尽管3D面部动画取得了显著进展，但细粒度的样式化3D面部表情操控仍面临挑战，原因是缺乏合适的数据集。针对这一问题，本论文介绍了基于AU-Blendshape表示的AUBlendSet数据集，跨越了500个身份的标准面部动作单元（AUs），同时添加了详细标注AUs的面部姿态集。基于此数据集，提出了AUBlendNet，用于学习不同角色风格的AU-Blendshape基向量。", "innovation": "提出了基于面部AUs的AUBlendSet数据集和AUBlendNet网络，实现任意个体身份的连续3D面部表情操控，填补了该领域的空白。", "conclusion": "通过定性和定量实验，验证了AUBlendSet和AUBlendNet的有效性，展示了它们在3D面部动画任务中的潜力和重要性。AUBlendSet和AUBlendNet为细粒度的样式化3D面部表情操控提供了新的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12049", "html_url": "https://arxiv.org/abs/2507.12049", "title": "MoViAD: 模块化视觉异常检测", "title_en": "MoViAD: Modular Visual Anomaly Detection", "authors": "Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto", "background": "视觉异常检测（VAD）是机器学习的一个关键领域，专注于识别图像中的异常模式偏差。该领域面临的挑战包括异常数据的稀缺性和需要无监督训练。为了加速该领域的研究和部署，需要一个能够快速提供最先进的VAD模型、训练器、数据集和工具的库，以及解决实际部署中的挑战，如边缘设备和物联网设置，提供优化模型和框架，以及压缩和量化的实用工具，以实现高效的设备端执行和分布式推理。视觉异常检测需要强大的评估指标和有用的效率分析工具，以及支持各种场景，包括持续学习、半监督学习、少量样本学习、嘈杂数据等。", "innovation": "MoViAD 是一个全面且高度模块化的库，提供了快速且易于访问的最先进的 VAD 模型、训练器、数据集和工具。它支持各种场景，包括持续学习、半监督学习、少量样本学习、嘈杂数据等，并提供优化的模型和框架，以及压缩和量化的实用工具，以实现高效的设备端执行和分布式推理。MoViAD 集成了选择的骨干网络、稳健的评估VAD指标（像素级和图像级）和有用的效率分析工具，使其易于部署并为机器学习工程师提供灵活性，同时为研究人员提供了开发和实验新方法的灵活性和扩展性。", "conclusion": "MoViAD 为视觉异常检测的快节奏部署提供了全面且模块化的解决方案，支持各种应用场景，并通过优化的模型和框架、量化的实用工具，以及强大的评估和效率分析工具，解决了部署中的实际挑战。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12083", "html_url": "https://arxiv.org/abs/2507.12083", "title": "运动前瞻：奖励启发增强轨迹预测", "title_en": "Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics", "authors": "Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen", "background": "在自主驾驶系统中，行驶道路交通代理人的运动预测是一项既具有挑战性又极其重要的任务，对于确保安全性至关重要。现有的大多数基于数据的方法直接预测未来的轨迹，而该研究重新思考了这一任务，从规划的角度出发，提出了一种“先推理，后预测”的策略，将行为意图显式地纳入轨迹预测的空间指导中。这种方法允许对给定场景上下文中的目标代理的行为进行解释，从而提高轨迹预测的信心和准确性。", "innovation": "本文提出了一种可解释的、基于奖励驱动的意图推理器，该推理器基于一种新型的以查询为中心的逆强化学习（IRL）方案。该方法将交通参与者和场景元素转换为统一的向量表示，并通过以查询为中心的框架聚合上下文特征，从而推出奖励分布。这种方法通过提供进行多次可达意图推理的先验信息来指导轨迹生成过程，并结合双向选择状态空间模型，生成准确的未来轨迹及其相关概率，从而实现了在主动驾驶系统中的应用。", "conclusion": "在大规模Argoverse和nuScenes运动预测数据集上的实验结果表明，本文的方法显著提高了轨迹预测的信心，相对于最新的方法取得了竞争力的表现。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11969", "html_url": "https://arxiv.org/abs/2507.11969", "title": "GS-Bias：单图视觉语言模型测试时适应的全局-空间偏置学习者", "title_en": "GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models", "authors": "Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji", "background": "测试时适应（TTA）在视觉-语言模型（VLMs）中的近期进展引起了越来越多的关注，特别是通过单一图像的多个增强视角来提升零样本泛化能力。但现有方法在性能和效率之间未能找到满意平衡，要么是因为调整文本提示的开销过大，要么是因为手工构建的、无需训练的视觉特征增强不稳定。", "innovation": "提出了一种高效的全局-空间偏置学习者（GS-Bias），并提出在TTA期间融入两个可学习偏置，即全局偏置和空间偏置。全局偏置通过学习增强视角的一致性来捕捉测试图像的全局语义特征，而空间偏置则学习图像空间视觉表示中区域间的语义一致性。GS-Bias 直接将这些偏置添加到预训练VLMs生成的logits上，避免了现有TTA方法中通过整个VLM的反向传播，从而提高了效率并实现了在15个基准数据集上的最佳性能。", "conclusion": "GS-Bias 在跨数据集泛化上比TPT提高了2.23%，在领域泛化上提高了2.72%，同时只需要TPT 6.5%的内存使用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12087", "html_url": "https://arxiv.org/abs/2507.12087", "title": "YOLOv8-SMOT: 通过切片辅助训练和自适应关联实现实时小目标跟踪的有效且鲁棒框架", "title_en": "YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association", "authors": "Xiang Yu,Xinyao Liu,Guang Liang", "background": "从无人机视角跟踪敏捷的小多目标（如鸟类）是一个高度挑战性的计算机视觉任务。难点来自于三个方面：目标外观特征的极度稀缺、由于相机和目标自身的动力学合成造成的复杂运动纠缠，以及由于密集群集行为引起的频繁遮挡和身份模糊。", "innovation": "在检测方面，提出了一个名为SliceTrain的系统性训练增强框架，通过'确定性全覆盖切片'和'切片级随机增强'的协同作用，有效解决了高分辨率图像训练中小目标学习不足的问题。在跟踪方面，设计了一个完全独立于外观信息的鲁棒跟踪器，通过将运动方向保持机制和结合边界框扩展和距离惩罚的自适应相似度度量集成到OC-SORT框架中，该跟踪器可以稳定处理不规则运动并维持目标身份。", "conclusion": "在SMOT4SB公共测试集上，我们的方法实现了最先进的性能，SO-HOTA得分为55.205，完全验证了我们框架在解决复杂现实世界的小目标跟踪问题上的有效性和先进性。源代码可以通过此 <https://example.com> 获得。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12027", "html_url": "https://arxiv.org/abs/2507.12027", "title": "SGLoc: 从3D高斯喷溅表示进行摄像机姿态估计的语义定位系统", "title_en": "SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation", "authors": "Beining Xu,Siting Zhu,Hesheng Wang", "background": "当前，摄像机姿态 estimation 基于立体视觉和后期处理技术已经取得了显著成果，但在利用3D高斯喷溅（3DGS）表示直接回归摄像机姿态，尤其是引入语义信息并结合2D图像与3D场景表示之间语义关系的一套系统的预研究尚存不足。", "innovation": "本文提出了一种新的定位系统 SGLoc，通过利用3D高斯喷溅表示直接回归摄像机姿态，同时结合语义信息。该方法通过多级姿态回归策略逐步从全局3DGS地图估计和细化查询图像的姿态，无需初始姿态先验。此外，引入了一种基于语义的全局检索算法来建立2D（图像）和3D（3DGS地图）之间的对应关系，并通过匹配提取的场景语义描述符和3DGS语义表示，对齐图像以获得粗略的姿态估计。随后，通过迭代优化查询图像与从3DGS渲染图像之间的差异，进一步细化粗略姿态。", "conclusion": "SGLoc 在 12scenes 和 7scenes 数据集上表现出优于基线模型的性能，显示出其在无需初始姿态先验的情况下出色的全局定位能力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12114", "html_url": "https://arxiv.org/abs/2507.12114", "title": "LidarPainter：从任何LiDAR视图到新型引导的一步之遥", "title_en": "LidarPainter: One-Step Away From Any Lidar View To Novel Guidance", "authors": "Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan", "background": "动态驾驶场景重建在数字孪生系统和自动驾驶模拟等领域非常重要。然而，当视角偏离输入轨迹时，会导致背景和车辆模型被破坏，导致不可接受的降解。现有的重建方法存在一致性、变形和时间消耗等多个局限性。因此，改进新型轨迹的重建质量成为亟待解决的问题。", "innovation": "本文提出了一种名为LidarPainter的一步扩散模型，可以实时从稀疏LiDAR条件下恢复一致的驾驶视图，并从有缺陷的渲染中恢复，从而使驾驶场景重建中的车道转变达到高保真度。LidarPainter在速度、质量和资源效率方面均优于现有方法，尤其是在速度方面快7倍，并且只需要现有方法所需GPU内存的五分之一。LidarPainter还支持使用文本提示（比如“雾蒙蒙的”和“夜晚”）进行样式化生成，从而扩展现有的资产库，使其更加多样化。", "conclusion": "实验结果表明，LidarPainter在速度、质量和资源效率方面均优于现有的先进方法。LidarPainter在实时驾驶场景重建中实现了从任一LiDAR视图到新型引导的高效高质量重建。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12062", "html_url": "https://arxiv.org/abs/2507.12062", "title": "MS-DETR: 向基于联合运动语义学习的有效视频关键时刻检索和亮点检测迈进", "title_en": "MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning", "authors": "Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding", "background": "视频关键时刻检索（MR）和亮点检测（HD）旨在根据文本查询定位特定的视频时刻并评估片段的相关性。尽管基于DETR的联合框架取得了显著进展，但视频内容中的时间运动和空间语义之间复杂关系的潜在利用仍待开发。", "innovation": "本文提出了一种名为Motion-Semantics DETR（MS-DETR）的框架，通过统一学习捕捉丰富的运动-语义特征，适用于MR和HD任务。框架首先在给定的文本查询指导下明确建模运动和语义维度内的解耦关系，然后利用任务相关的运动时间维度和空间语义维度间的联系来实现精准的查询引导定位和细粒度的亮点边界的划分。此外，针对MR/HD数据集在运动和语义维度中的固有稀疏性问题，通过生成策略丰富这些维度，并提出对比去噪学习以确保各组成部分能够牢固高效地学习。", "conclusion": "在四个MR/HD基准上的广泛实验表明，本方法在性能上优于现有最先进的模型。源代码可在该链接处获得。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12105", "html_url": "https://arxiv.org/abs/2507.12105", "title": "Out-of-distribution数据监督对生物医学语义分割的贡献", "title_en": "Out-of-distribution data supervision towards biomedical semantic segmentation", "authors": "Yiquan Gao,Duohui Xu", "background": "生物医学分割网络在学习有限且不完善的医疗数据集时，容易受到前景和背景对象之间意外分类的影响。借鉴OoD数据在其他视觉任务中的强大功能，本文探讨了解决该问题的方法，即通过将OoD数据监督引入完全监督的生物医学分割网络中，从而避免修改网络结构和使用额外数据源、特征正则化目标和附加注释的需求。", "innovation": "提出了一个数据为中心的框架Med-OoD，通过在完全监督的生物医学分割网络中引入OoD数据监督解决该问题，且无需依赖外部数据源、特征正则化目标和附加注释。该方法无需修改网络架构即可无缝集成到分割网络中。实验结果表明，该方法能显著防止各种分割网络在医学图像上的像素分类错误，并在Lizard数据集上实现了显著的性能提升。此外，还展示了一种新的学习范式，即完全使用OoD数据训练生物医学分割网络，无需前景类标签，测试结果高达76.1%的mIoU。", "conclusion": "Med-OoD方法能大规模防止各种分割网络在医学图像上的像素分类错误，并在Lizard数据集上实现了显著的性能提升。还提出了一种全新的学习范式，完全使用OoD数据训练生物医学分割网络，测试结果达到76.1%的mIoU。希望这一学习范式能促使人们重新思考OoD数据的作用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12092", "html_url": "https://arxiv.org/abs/2507.12092", "title": "在多发性硬化症中深度学习皮层病变MRI分割的基准测试与解释", "title_en": "Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis", "authors": "Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra", "background": "皮层病变（CLs）已成为多发性硬化症（MS）的重要生物标志物，具有高诊断特异性和预后价值。然而，由于MRI成像中皮层病变的微妙表现、专家标注的挑战以及缺乏标准化的自动化方法，其在临床中的常规应用仍然有限。", "innovation": "提出了一种全面的多中心基准测试，用于皮层病变的检测和分割。使用自配置的nnU-Net框架，并对其进行适应以改进CL检测。通过分布外测试评估模型的泛化能力，结果表明具有良好的检测能力。此外，还分析了内部模型特征和模型错误，以更好地理解AI决策过程。研究探讨了数据变异、病变模糊和协议差异对模型性能的影响，提供了未来解决这些临床应用障碍的建议。", "conclusion": "通过对数据变异、病变模糊和协议差异的影响进行分析，研究为临床采用提供了一些建议，并强调了可重复性的关键性，即公开提供的实现和模型可以用于进一步研究。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12107", "html_url": "https://arxiv.org/abs/2507.12107", "title": "非适应性对抗性人脸生成", "title_en": "Non-Adaptive Adversarial Face Generation", "authors": "Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo", "background": "人脸识别系统（FRS）的对抗性攻击会对安全性和隐私性构成严重威胁，尤其是在这些系统用于身份验证时。现有方法通常依赖于迭代优化（如梯度下降或其他迭代求解器）生成对抗性样本，但这种方法可能需要多次查询和适应性调整，增加了实施的复杂性和不灵活性。", "innovation": "本文提出了一种新颖方法，通过生成外形上显著不同但能够被FRS识别为目标身份的对抗性人脸（合成面部图像）。这种方法利用了FRS特征空间的结构特征，通过识别具有相同属性（如性别或种族）的人形成了有属性的子球体。这种方法无需依赖于转移性和开源代理模型，实现了非适应性和大幅减少查询次数，成功针对AWS CompareFaces API达到了超过93%的高成功率。此外，该方法能够根据攻击者的选择生成具备高级属性的欺骗性人脸，而不是对原始图像进行任意扰动。", "conclusion": "与现有的需要多次适应性查询的对抗性攻击方法不同，本文提出的方法仅需一次非适应性查询即可实现高效的对抗性样本生成，大大简化了攻击流程，实现了较高的攻击成功率，具有重要的实际应用价值。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12123", "html_url": "https://arxiv.org/abs/2507.12123", "title": "使用3D层次场景图的开放词汇室内物体定位", "title_en": "Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph", "authors": "Sergey Linok,Gleb Naumov", "background": "该研究涉及室内环境中的物体定位问题，特别是在复杂查询中需要精确的空间参照关系。现有的方法难以处理多层次的空间关系和复杂的空间推理查询，尤其是在多楼层的环境场景中。因此，需要一种新的方法来高效地理解场景并实现室内物体的鲁棒定位。", "innovation": "研究提出了一种新的方法OVIGo-3DHSG，该方法利用开放词汇基础模型和传感器数据处理，在3D层次场景图中表示复杂的室内环境。该方法通过将3D层次场景图与大型语言模型结合进行多步骤推理，增强了空间上下文理解，特别是以楼层、房间、位置和物体为节点的层次关系，能够在多楼层的Habitat Matterport 3D语义场景中表征语义和几何准确性。", "conclusion": "研究发现，OVIGo-3DHSG相比现有方法，能够高效地理解场景并在室内环境中实现更鲁棒的物体定位。该方法展示了在需要空间推理和理解室内环境的应用场景中的强潜力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12137", "html_url": "https://arxiv.org/abs/2507.12137", "title": "AD-GS: 对象感知的B样条高斯点积方法的自主监督", "title_en": "AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving", "authors": "Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang", "background": "动态城市驾驶场景的建模和渲染对于自动驾驶模拟至关重要。当前高质量的方法通常依赖于昂贵的手动对象轨迹标注，而自监督的方法则无法准确捕捉动态物体的运动和正确分解场景，导致渲染缺陷。", "innovation": "我们提出了AD-GS，一种新颖的自监督框架，用于仅从单一日志高质量地渲染驾驶场景的自由视角。其核心是一个新颖的可学习运动模型，结合局部感知B样条曲线和全局感知三角函数，实现了灵活且精确的动态物体建模。AD-GS在场景分割中使用简化伪2D分割自动将场景分割成对象和背景，并利用动态高斯分布和双向时间可见性掩码表示对象。此外，模型还集成了可见性推理和物理上刚性的正则化以增强鲁棒性。", "conclusion": "广泛的评估展示了我们没有标注的数据模型显著优于当前最先进的无标注方法，并且在某些方面可与依赖标注的方法竞争。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12157", "html_url": "https://arxiv.org/abs/2507.12157", "title": "从零开始的教师引导的数据增强下的细粒度图像识别", "title_en": "Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation", "authors": "Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu", "background": "细粒度图像识别（FGIR）旨在区分大类下视觉相似的子类别，例如识别鸟类种类。现有的FGIR方法大多依赖于在大规模数据集（如ImageNet）上预先训练的骨干网络，这使得FGIR系统在资源受限的环境中缺乏适应性，并妨碍了专门针对FGIR挑战的架构开发。", "innovation": "本文通过展示完全从零开始训练可实现高性能FGIR系统来挑战依赖预训练模型的传统方法。提出了一个新颖的训练框架TGDA，该框架结合了数据感知增强与弱监督，通过细粒度感知教师模型实现知识蒸馏。TGDA框架打开了专门任务和硬件感知架构的设计，包括低分辨率FGIR中的LRNets和优化用于高效推理的Vision Transformers家族ViTFS。", "conclusion": "广泛的实验表明，本方法在三个不同场景下的FGIR基准测试中可以持续匹配或超越最先进的预训练模型表现。特别是在低分辨率场景中，使用TGDA训练的LRNets在准确性上提高了最多23%，同时参数减少至至多20.6倍，FLOPs降低，所需训练数据大幅减少。同样，ViTFS-T可以达到在ImageNet-21k上预训练的ViT B-16的表现，同时参数减少了15.3倍，并且需要数十倍更少的数据。这些结果表明，TGDA作为一种可适应的替代预训练的方法，有望促进更高效的细粒度视觉系统的开发。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12008", "html_url": "https://arxiv.org/abs/2507.12008", "title": "域自适应图像分割中的互补掩码的对偶形式", "title_en": "Dual form Complementary Masking for Domain-Adaptive Image Segmentation", "authors": "Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong", "background": "最近的研究将掩蔽图像建模（MIM）与未监督域适应（UDA）的一致性正则化联系起来，但大多仅将掩蔽视为对输入图像的一种特殊变形形式，忽略了理论分析，导致对掩蔽重建的理解表面化，未能充分利用其增强特征提取和表示学习的潜力。", "innovation": "本文将掩蔽重建重新定义为稀疏信号重构问题，并理论证明互补掩码的对偶形式在提取跨域不变图像特征方面具有更优的能力。基于此见解，提出了一种简单且有效的域自适应框架MaskTwins，直接将掩蔽重建集成到主训练管道中。MaskTwins通过强制在互补方式掩蔽图像的预测之间保持一致性，揭露了存在于不同域中的内在结构模式，以端到端的方式实现域泛化。", "conclusion": "广泛的实验结果表明，MaskTwins在自然和生物图像分割中优于基线方法，展示了在不需要单独预训练的情况下提取域不变特征的显著优势，提出了域适应分割的新范式。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12201", "html_url": "https://arxiv.org/abs/2507.12201", "title": "RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models", "title_en": "RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models", "authors": "Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li", "background": "尽管扩散模型在生成建模中已经达到了最先进的性能，但它们的采样过程仍然容易出现幻觉，这经常源于评分近似中的不准确性。", "innovation": "本工作重新解释了扩散采样的优化视角，并引入了RODS（Robust Optimization-inspired Diffusion Sampler），这是一种新颖的方法，通过损失景观的几何线索来检测和纠正高风险的采样步骤。RODS强制执行更平滑的采样轨迹，并适应性调整扰动，从而减少幻觉且无需重新训练模型，并且几乎不会增加额外的推理成本。", "conclusion": "在AFHQv2、FFHQ和11k-hands上的实验结果显示，RODS提高了采样准确性和鲁棒性，检测了超过70%的幻觉样本并纠正了超过25%，而且不会引入新的伪像。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12135", "html_url": "https://arxiv.org/abs/2507.12135", "title": "基于双边网格的实时图像增强的像素自适应多层感知机学习", "title_en": "Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement", "authors": "Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu", "background": "深度学习驱动的双边网格处理在图像增强中展现出潜力，能够在保持空间和强度信息的同时通过切片操作实现高效的全分辨率处理。然而，现有方法仅限于线性仿射变换，限制了复杂颜色关系的建模能力。虽然多层感知机（MLPs）擅长非线性映射，但传统的MLP方法使用的全局共享参数难以应对局部变化。", "innovation": "提出了一种基于双边网格的像素自适应多层感知机（BPAM）框架。该方法结合了双边网格的空间建模能力和MLPs的非线性能力。具体而言，生成包含MLP参数的双边网格，其中每个像素动态检索其唯一的变换参数，并基于空间坐标和强度值得到不同的MLP颜色映射。此外，提出了一种新的网格分解策略，将MLP参数分类存储在不同的子网格中，通过多通道引导图从相应子网格中提取类别特定参数，确保在切片过程中有效利用颜色信息并指导精确的参数生成。", "conclusion": "在公共数据集上的大量实验表明，该方法在性能上超过了最先进的方法，同时保持了实时处理能力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12188", "html_url": "https://arxiv.org/abs/2507.12188", "title": "基于小波的低光照立体图像增强的特征空间解耦框架", "title_en": "Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement", "authors": "Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun", "background": "低光照图像受到复杂降化的困扰，现有增强方法通常将所有降化因素编码在一个隐藏空间中，导致特征高度纠缠且具有强烈的黑盒特性，使模型易于学习捷径。", "innovation": "本文提出了一种基于小波的低光照立体图像增强方法，该方法通过特征空间解耦来缓解上述问题。通过小波变换独立处理低频和高频信息，利用多级小波分解调整低光照图像的低频分量来实现光照调整。此外，结合立体低光照图像增强可以从另一视角提取有用线索以提升增强效果。为此，本文提出了一种新的高频率引导跨视角交互模块（HF-CIM），该模块在高频率分支内操作，能够有效从另一视角提取有价值图像细节。进一步地，基于交叉注意力机制提出了细节和纹理增强模块（DTEM），用于增强高频率信息。模型在包含均匀和非均匀光照的图像数据集上进行训练，实证结果表明该算法在光照调整方面具有显著优势并能够有效恢复高频信息。", "conclusion": "我们在真实和合成图像上的实验结果表明，该算法在光照调整方面具有显著优势，并且能够有效恢复高频信息。相关的代码和数据集已公开发布。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12103", "html_url": "https://arxiv.org/abs/2507.12103", "title": "DeepShade: 通过文本条件化图像生成实现阴影模拟", "title_en": "DeepShade: Enable Shade Simulation by Text-conditioned Image Generation", "authors": "Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei", "background": "热浪对公共健康构成重大威胁，尤其是在全球变暖加剧的情况下。然而，当前的路线系统（如在线地图）无法将阴影信息纳入其中，主要是因为通过有噪声的卫星图像估计阴影十分困难，且用于生成模型的数据集有限。", "innovation": "论文通过两大贡献解决了这些问题。首先，构建了一个涵盖不同经度-纬度区域、不同建筑密度和城市布局的详尽数据集。利用Blender基于的3D模拟和建筑轮廓，捕捉全年不同时间段在不同太阳高度角下的建筑阴影，将这些模拟阴影与卫星图像对齐，提供了一个学习阴影模式的丰富资源。其次，提出了基于扩散的DeepShade模型，用于学习并合成随时间变化的阴影变化。该模型同时考虑RGB和坎尼边缘层来强调边缘特征，并结合对比学习捕获阴影的时序变化规律。通过条件化已知条件的文本描述，该框架在生成阴影图像方面显示出改进的性能。", "conclusion": "通过在亚利桑那州Tempe的真实路线规划中使用我们的阴影预测计算阴影比例，我们展示了该方法的有效性。我们认为这项工作将通过提供极端高温天气下的城市规划参考，为社会带来益处，并具有潜在的实际环境应用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12195", "html_url": "https://arxiv.org/abs/2507.12195", "title": "数字重建古迹瓦片：计算机视觉在数字重建庙宇瓦片中的应用", "title_en": "Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision", "authors": "Arkaprabha Basu", "background": "数字技术的现代应用显著改变了文化珍宝的保护和修复方式，将计算机科学家纳入多学科项目中变得十分简便。机器学习、深度学习和计算机视觉技术革新了诸如3D重建、图像修复、物联网方法、遗传算法和图像处理等新兴领域。印度的建筑艺术和美学使其重要遗迹具备特别的品质，研究建议了三项创新技术以满足其独特需求。这些技术包括基于图像处理的分形卷积方法、一种专为西孟加拉邦令人着迷的本纳克拉陶土庙创建的新数据增强方法SSTF，以及图像超级分辨率策略。这些方法通过降低成本、引入自动化，促进了无缝区域填充和高质量、高细节的瓦片生成，同时保持真实性和传统的平衡，从而实现了文化遗产保护的有效解决方案，使课题得到了改进并确保了无以伦比的效率和美学卓越性。", "innovation": "1. 分形卷积方法（基于图像处理的一种分割方法，能够揭示重要遗迹中的细微建筑模式）。\n2. 自我敏感瓷砖填充（SSTF）方法（专为西孟加拉邦的本纳克拉陶土庙设计，引入了新的数据增强方法MosaicSlice）。\n3. 图像超级分辨率策略（提高图像分辨率而不损失大量质量）。", "conclusion": "通过提供既维护传统又推陈出新的有效解决方案，该研究提升了文化遗迹保护的主题，最终确保了无与伦比的效率和美学品质。\n这些提议的方法将该领域带入了一个前所未有的效率和美学品质时代，同时谨慎地保持了传统与创新之间的微妙平衡。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12125", "html_url": "https://arxiv.org/abs/2507.12125", "title": "Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers", "title_en": "Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers", "authors": "Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng", "background": "ViT已在各种视觉任务中展现了令人印象深刻的结果，但由于其高昂的计算成本限制了其实用应用。现有方法通过消除不重要令牌来尝试降低ViT的O(n^2)复杂度，但独立消除查询（Q）和键（K）令牌往往会牺牲精度，导致未被注意到的令牌交互忽视，从而影响性能。", "innovation": "本文提出了一种新的块基对称剪枝和融合（BSPF-ViT）方法，可联合优化Q/K令牌的剪枝。与仅考虑单个方向的方法不同，该方法考虑每个令牌及其邻居之间的相互作用来决定保留哪些令牌。保留的令牌通过相似性融合步骤压缩，保持关键信息的同时降低计算成本。Q/K令牌的共享权重创建了一个对称的注意矩阵，允许仅剪枝上三角部分以提高速度。BSPF-ViT在所有剪枝级别上均优于最先进的ViT方法，提高了ImageNet分类准确性，对于DeiT-T提升了1.3%，对于DeiT-S提升了2.0%，同时减少计算开销50%。此外，它在各种ViT上实现了40%的速度提升，同时保持了更高的准确性。", "conclusion": "BSPF-ViT在各个剪枝级别上均表现出色，尤其是对于DeiT-T和DeiT-S在ImageNet分类任务上分别提高了1.3%和2.0%的准确性，同时减少了50%的计算开销，并在各种ViT模型上实现了40%的速度提升。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12232", "html_url": "https://arxiv.org/abs/2507.12232", "title": "MGFFD-VLM: 面部伪造检测中的多粒度提示学习", "title_en": "MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM", "authors": "Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng", "background": "近年来的研究利用视觉大语言模型（VLMs）不仅回答‘这是伪造的面部吗？’，还回答‘为什么这张面部是伪造的？’。这些研究引入了伪造相关的属性，如伪造位置和类型，以构建深伪VQA数据集并训练VLMs，达到了较高的准确率，同时提供了可理解的解释性文本描述。然而，这些方法仍存在局限性。例如，它们未能充分利用与面部质量相关的属性，而这些属性在伪造的面部中往往异常，并且缺乏有效的伪造感知VLMs训练策略。在此基础上，本论文扩展了VQA数据集，创建了DD-VQA+，相较于之前的方法，DD-VQA+具有更丰富的一系列属性和更多样化的样本。此外，本论文还提出了一种新颖的伪造检测框架MGFFD-VLM，它结合了属性驱动的混合LoRA策略，从而增强了视觉大语言模型（VLMs）的能力。该框架整合了多粒度提示学习和伪造感知训练策略。通过将分类和伪造分割结果转化为提示，本方法不仅提高了伪造分类的能力，还增强了可解释性。为了进一步提高检测性能，我们设计了多种关联伪造的辅助损失。实验结果表明，本方法在文本基础的伪造判断和分析中优于现有方法，实现了更高的准确性。", "innovation": "本论文提出了DD-VQA+数据集和MGFFD-VLM框架，该框架结合了属性驱动的混合LoRA策略、多粒度提示学习和伪造感知训练策略。通过将分类和伪造分割结果转化为提示，该方法不仅提高了伪造分类能力，还增强了可解释性。并且设计了多类伪造相关的辅助损失来进一步提高检测性能。", "conclusion": "实验结果证明，本方法在文本基础伪造判断和分析中优于现有方法，实现了更高精度。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12248", "html_url": "https://arxiv.org/abs/2507.12248", "title": "Keras、PyTorch和JAX在PathMNIST上的CNN性能比较分析", "title_en": "Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST", "authors": "Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić", "background": "深度学习在医学图像分类领域取得了显著进展，尤其是在卷积神经网络（CNN）的应用上。Keras、PyTorch和JAX等各种深度学习框架在模型开发和部署上具有独特优势，但它们在医学成像任务上的相对性能仍需进一步探索。本研究旨在通过使用PathMNIST数据集进行全面分析，评估这些框架下CNN的训练效率、分类准确性和推断速度，以便更好地了解其在实际应用中的适用性。", "innovation": "研究采用了新的比较方法，通过具体的CNN实施，深入分析了Keras、PyTorch和JAX在医学图像任务中的相对性能，填补了该领域的空白，为医学图像分析领域的研究人员和实践者提供了实际参考。研究侧重于对比不同框架下的 trade-offs，特别是在计算速度和模型准确性之间的权衡。", "conclusion": "研究揭示了在不同框架下的CNN实施具有不同的优势和不足，强调了快速计算与模型准确性之间的权衡。这些发现为未来的研究和实际应用提供了宝贵的指导。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12138", "html_url": "https://arxiv.org/abs/2507.12138", "title": "神经人体姿态先验", "title_en": "Neural Human Pose Prior", "authors": "Michal Heker,Sefy Kararlitsky,David Tolpin", "background": "本文介绍了一种基于原则的数据驱动方法，用于使用归一化流来建模具有6D旋转格式的人体姿态先验神经先验。这种方法不同于启发式或低表示性的替代方案，采用了RealNVP来学习姿态的灵活分布。文中提出了在有效6D旋转流形上建模分布的挑战，并在训练过程中反向Gram-Schmidt过程来实现稳定学习和与旋转基框架的下游兼容性。该架构和训练管道是框架无关的，易于复现。", "innovation": "本文的创新在于提出了一种使用RealNVP来学习6D旋转格式下人体姿态的灵活密度的方法，通过训练过程中反向Gram-Schmidt过程来应对有效6D旋转流形上的分布建模挑战。此外，该方法具有框架无关性，易于复现。", "conclusion": "通过定性和定量评估表明所学的先验有效，并通过消融研究分析了其影响。这些工作为将姿态先验集成到人体动作捕捉和重建管道中提供了稳健的概率基础。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12269", "html_url": "https://arxiv.org/abs/2507.12269", "title": "基于渐进层冻结的站点级微调：从极早产婴儿第一天胸部X光片中稳健预测支气管肺发育不良", "title_en": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "authors": "Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)", "background": "支气管肺发育不良（BPD）影响约35%的极低出生体重婴儿，是慢性肺病的一种。BPD以孕周后36周仍需吸氧为特征，导致终生的呼吸并发症。然而，预防干预措施本身具有严重的风险，包括神经发育障碍、机械通气引起的肺损伤和全身并发症。因此，早期预测BPD对于避免低风险婴儿的不必要的毒性至关重要。出生后的24小时内常规获取极早产婴儿的胸部X光片，可以作为非侵入性的预测工具。本研究旨在开发并验证一种基于胸部X光片的深度学习方法，用于非侵入性地预测BPD的发生和发展。", "innovation": "该研究通过使用早产婴儿的胸部X光片来开发并验证了一种基于深度学习的方法。研究中开发的模型采用了渐进层冻结和线性探测技术，并使用了CutMix增强技术，以提高预测BPD的能力。研究发现，基于成年人胸部X光片训练的模型比在ImageNet上初始化的模型表现更好，这表明特定领域的预训练对BPD预测很重要。研究还发现，常规的IRDS评分在预测BPD方面价值有限，进一步证明了学习标记的重要性。这种基于胸部X光片的方法为BPD的早期预测提供了一种新的途径，并展示了对BPD的准确预测是可能的。", "conclusion": "研究中的方法证明了特定领域的预训练能够基于极早产婴儿出生第一天的胸部X光片准确预测BPD。通过渐进层冻结和线性探测，该方法在站点级实施和未来的联邦学习部署中保持了计算上的可行性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12095", "html_url": "https://arxiv.org/abs/2507.12095", "title": "BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images", "title_en": "BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images", "authors": "Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara", "background": "准确的三维车辆重建对于车辆检验、预测维护和城市规划等应用至关重要。现有的方法如神经辐射场和Gaussian Splatting取得了令人印象深刻的成果，但仍然受限于对密集输入视角的依赖，这阻碍了其在现实生活中的应用。", "innovation": "本文针对稀疏视角输入下的车辆三维重建这一挑战，利用深度图和稳健的相机姿态估计架构，结合选择性光度损失和DUSt3R架构改进相机姿态估计，创新性地对Gaussian Splatting进行了增强。此外，还提出了一个包含合成和现实世界公共交通车辆的新型数据集，以便对方法进行广泛评估。", "conclusion": "实验结果表明，该方法在多个基准测试中取得了最先进的性能，展示了其在控制输入条件下实现高质量重建的能力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12283", "html_url": "https://arxiv.org/abs/2507.12283", "title": "FADE: 流模型中的对抗概念消除", "title_en": "FADE: Adversarial Concept Erasure in Flow Models", "authors": "Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang", "background": "扩散模型展示了出色的图像生成能力，但同时也存在隐私和公平性风险，因为它们可能会记住敏感概念或延续偏差。为了应对这一挑战，本文提出了一种新颖的概念消除方法FADE，旨在从文本到图像的扩散模型中移除指定的概念（例如，个人隐私或有害刻板印象）。", "innovation": "本文提出了FADE（Fair Adversarial Diffusion Erasure）方法，该方法结合了轨迹意识的微调策略和对抗目标，确保可靠地删除指定概念同时保持模型的整体保真度。理论证明，我们的方法能够正式保证，删除指定概念与模型输出间的互信息最小化。实验结果显示，FADE在去除概念效果和图片质量上超越了之前的方法，改进了概念移除和保真度的调和平均值5-10%。此外，还通过消融研究验证了每个组件对性能的贡献。", "conclusion": "本文通过FADE方法设定了新标准，实现了在不完全重新训练的情况下安全公平地生成模型，通过移除指定的概念。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12177", "html_url": "https://arxiv.org/abs/2507.12177", "title": "混合式集成方法：针对增强脑肿瘤分类的最佳深度特征融合和超参数调优分类器集成", "title_en": "Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification", "authors": "Zahid Ullah,Dragan Pamucar,Jihie Kim", "background": "磁共振成像（MRI）因其能够生成详细图像来揭示肿瘤存在而被广泛认为是最可靠的检测工具。然而，当人类专家评估这些图像时，诊断的准确性可能会受到损害。因素如疲劳、专业知识有限以及图像细节不足可能会导致错误。例如，小肿瘤可能会被忽视，重叠的健康脑区可能导致错误的识别。为了应对这些挑战并提高诊断的精确度，这项研究提出了一种新颖的双重集成框架，该框架由集成预训练深度学习（DL）模型进行特征提取和集成微调超参数机器学习（ML）模型来高效地分类脑肿瘤。具体来说，该方法包括广泛的预处理和增强，利用各种预训练的卷积神经网络和视觉转换器网络进行脑MRI的深层次特征提取，并微调ML分类器的超参数。研究使用了三个不同的Kaggle MRI脑肿瘤数据集来评估预训练的DL特征提取模型、ML分类器以及深度特征和ML分类器集成的集成效果。实验结果表明，提出的特征融合与分类器融合优于现有技术，超参数微调为集成方法提供了显著的增强。此外，我们还进行了消融研究，以说明每个组件如何贡献于准确的脑肿瘤分类。", "innovation": "提出了一种新颖的双重集成框架，该框架由集成预训练深度学习（DL）模型进行特征提取和集成微调超参数机器学习（ML）模型进行高效分类。该方法包括广泛的预处理和增强，利用了各种预训练的卷积神经网络和视觉转换器网络进行深度特征提取，并微调ML分类器的超参数。特别地，通过综合运用多种深度学习和机器学习技术，并进行超参数优化，显著提高了脑肿瘤分类的准确性。", "conclusion": "研究提出的方法通过融合预训练深度特征和超参数调优的机器学习分类器，增强了脑肿瘤分类的精度。实验结果显示，该方法优于现有技术，尤其是通过超参数微调，极大地提升了诊断效果。此外，通过消融研究，验证了各个组件对准确分类的贡献。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12292", "html_url": "https://arxiv.org/abs/2507.12292", "title": "通过前景实例选择和深度估计实现高效的健美操技能分类", "title_en": "Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation", "authors": "Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari", "background": "健美操技能分类是计算机视觉任务，从图像中推断出运动员执行的动作，从而实现自动表现评估和个性化分析。传统的方法是基于姿态估计技术来确定骨骼数据的位置，之后将其输入分类算法以推断执行的动作。尽管在人体姿态估计算法中取得了进展，但这种方法仍然存在高计算成本、长时间推断时间和复杂设置等问题，这限制了其在实时应用或移动设备中的适用性。", "innovation": "本文提出了一种直接的健美操技能识别方法，利用深度估计和运动员补丁检索，避免了昂贵的人体姿态估计模块。使用Depth Anything V2进行深度估计，YOLOv10进行运动员定位，从背景中分割主体，避免了传统的姿态估计技术。这种方法提高了效率，缩短了推断时间，提高了分类准确性。研究成果在基于骨架的方法中表现出显著优势，实现了RGB图像补丁38.3倍的更快推理，并且深度补丁具有更高的分类准确性（0.837 vs. 0.815）。此外，本方法的模块化设计允许灵活更换组件，为未来的增强和适应现实世界的应用提供了可能。", "conclusion": "本研究通过前景实例选择和深度估计，显著提高了健美操技能分类的效率和准确性，同时增强了系统的可扩展性和适应性。这种方法在实际应用中的潜力巨大。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12382", "html_url": "https://arxiv.org/abs/2507.12382", "title": "Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation", "title_en": "Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation", "authors": "Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou", "background": "在标注数据有限的情况下，利用文本信息增强视觉语义理解是一种有效的缓解数据注释成本高昂问题的方法，尤其是在3D医学影像任务中。然而，对利用文本数据增强视觉语义嵌入的研究仍然较少，提出了一种新的基于文本的多平面视觉交互框架来改善半监督医学影像分割效果.", "innovation": "该研究提出了一个名为Text-SemiSeg的新奇的基于文本的半监督医学影像分割框架，该框架包含三个主要模块：文本增强的多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA）。每个模块的具体功能分别是：TMR通过平面映射促进文本和视觉信息的交互，增强视觉特征的类别意识；CSA执行文本特征与视觉特征中间层之间的跨模态语义对齐，其中包含可学习变量；DCA通过标签和无标签数据的交互减小它们之间的分布差距，从而提高模型的鲁棒性.", "conclusion": "在三个公开数据集上的实验表明，该模型能够有效利用文本信息来增强视觉特征，并且在性能上优于其他方法。相关代码可在提供的链接中获得."}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12336", "html_url": "https://arxiv.org/abs/2507.12336", "title": "无监督单目3D关键点发现：多视角扩散先验", "title_en": "Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors", "authors": "Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim", "background": "以往方法依靠手动标注或校准的多视角图像，这两种方式获取成本昂贵。本研究提出了一种名为KeyDiff3D的框架，该框架能够仅通过单张图像估计3D关键点，而无需依赖手动标注或多视角校准图像。", "innovation": "本研究利用预训练的多视角扩散模型嵌入强大的几何先验，通过生成多视角图像来指导单目3D关键点估计，并将其中间表示转换为3D特征体积，从而将隐式3D先验转化为显式3D特征。此外，该研究还提出了一种管道来操纵由扩散模型生成的3D物体。", "conclusion": "实验结果在人类动作3.6M、斯坦福狗以及多种现实世界和跨领域数据集上展示了该方法在准确性和泛化能力方面有效，并能从单张图像生成和操纵3D物体。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12236", "html_url": "https://arxiv.org/abs/2507.12236", "title": "生成以定位：多模态文本条件增强医学视觉语言模型中的短语定位", "title_en": "Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models", "authors": "Felix Nützel,Mischa Dombrowski,Bernhard Kainz", "background": "短语定位，即把自然语言短语映射到特定图像区域，在医学成像中的临床报告中具有巨大潜力。当前最先进的方法依赖于区分性的、自监督的对比模型。然而，本研究显示，利用交叉注意图的生成性文本到图像扩散模型能够实现更好的零样本短语定位性能。与之前假设的相反，我们发现，用一个冻结的、特定领域的语言模型（如CXR-BERT）微调扩散模型，这种设置在改进方面表现出极大的优越性，mIoU分数是现有区分性方法的两倍。", "innovation": "本研究展示了生成性模型在短语定位任务中的潜在价值，并提出了Bimodal Bias Merging (BBM) 一种新颖的后处理技术，该技术通过对齐文本和图像的偏见来识别高确定性的区域。BBM 能够进一步细化交叉注意图，从而提高定位精度。此外，本研究表明生成性方法是医学成像领域中短语定位的有效范式，有助于实现更强大且可解释的应用。", "conclusion": "本研究确立了生成性方法作为在医学成像领域中实现短语定位的有效范式，为临床实践中的更稳健和可解释应用铺平了道路。相关源代码和模型权重在此：给定的URL。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12414", "html_url": "https://arxiv.org/abs/2507.12414", "title": "AutoVDC：使用视觉语言模型的自动化视觉数据清理", "title_en": "AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models", "authors": "Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding", "background": "自主驾驶系统训练需要大量具有精准注释的数据集以实现稳定的性能。但人工注释存在不足，往往需要多个迭代才能生成高质量的数据集。然而，手动审查大量数据集既耗费时间和精力又成本高昂。因此，该文探讨了利用视觉语言模型（VLMs）自动识别视觉数据集中的错误注释，以提升数据质量和可靠性，并通过KITT和nuImages数据集中的对象检测基准进行验证。", "innovation": "该研究提出了一种名为AutoVDC（Automated Vision Data Cleaning）的自动化视觉数据清理框架，并探讨了VLMs在自动识别视觉数据集中错误注释的应用，从而让用户能够消除这些错误并提升数据质量。通过对比不同VLMs的检测率，并分析VLM微调对系统的影响，实验结果显示，该方法在错误检测和数据清理任务中表现出色，具有显著提高大型生产数据集的可靠性和准确性潜力。", "conclusion": "实验结果表明，该方法在错误检测和数据清理方面表现出色，说明其在提高自主驾驶大型生产数据集的可靠性和准确性方面具有巨大潜力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12359", "html_url": "https://arxiv.org/abs/2507.12359", "title": "集群对比（CueCo）在无监督视觉表示学习中的应用", "title_en": "Cluster Contrast for Unsupervised Visual Representation Learning", "authors": "Nikolaos Giakoumoglou,Tania Stathaki", "background": "近年来，对比学习（contrastive learning）和聚类方法在无监督视觉表示学习中取得了显著进展。尽管二者各自有优势，但如何高效地结合这两种方法仍然是一个挑战。", "innovation": "本文提出了一种名为Cluster Contrast（CueCo）的新方法，该方法有效地融合了对比学习和聚类的优点。CueCo通过两个神经网络（查询查询网络和关键网络）以及对比损失和聚类目标，同时实现了特征表示的分散和对齐。", "conclusion": "CueCo在CIFAR-10（91.40%）、CIFAR-100（68.56%）和ImageNet-100（78.65%）的数据集上取得了出色的线性评估表现，并通过结合对比学习与聚类，为无监督视觉表示学习设定了一个新方向。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12245", "html_url": "https://arxiv.org/abs/2507.12245", "title": "Calisthenics Skills Temporal Video Segmentation", "title_en": "Calisthenics Skills Temporal Video Segmentation", "authors": "Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari", "background": "Callingis，一种快速增长的以自身重量为依托的体能锻炼形式，包括不同的分类，其中之一是专注于技能的部分。这些技能包含静态和动态的元素。对于静态技能，其评估基于难度级别和持继时间。自动化工具能够通过时间分割视频来识别支配性技能，有助于运动员训练和比赛中的评判。尽管有关通过体态分析进行动作识别的视频理解文献丰富，但尚未有专门针对Calisthenics技能的时序视频分割问题进行过研究。本研究旨在推进改进Calisthenics领域自动工具的初步步骤，因此创建了一个包含运动员执行静态Calisthenics技能视频的标注数据集，旨在解决技能时序分割问题，并提供基准方法的初步结果，以展示该问题的可行性但仍需改进空间.", "innovation": "本研究创新之处在于首次提出了Calisthenics技能的时间分割数据集，并使用自动工具对视频中的静态技能进行识别和分割，为Calisthenics领域中的自动工具开发奠定了基础，首次解决了此类特定领域的视频分割问题，具有重要的学术和应用前景.", "conclusion": "本研究展示了时间分割静态Calisthenics技能的可能性，尽管初步结果展示了其可行性，但仍然有待进一步改进。该研究提出了一个基准方法，并为未来的工作提供了参考，推动了Calisthenics领域的自动化工具的发展."}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12433", "html_url": "https://arxiv.org/abs/2507.12433", "title": "交通感知行人意图预测", "title_en": "Traffic-Aware Pedestrian Intention Prediction", "authors": "Fahimeh Orvati Nia,Hai Lin", "background": "准确预测行人的意图对于自动驾驶车辆的安全导航至关重要，因此得到了广泛关注。然而，当前的模型往往未能充分考虑动态交通信号和场景上下文信息，这对于实际应用来说是非常重要的。", "innovation": "本文提出了一个交通感知时空图卷积网络（TA-STGCN），该网络将交通信号及其状态（红灯、黄灯、绿灯）纳入预测行人的意图中，并将动态交通信号状态和边界框大小作为关键特征，从而使模型能够在复杂的城市环境中捕获空间和时间依赖性。与现有方法相比，TA-STGCN在精度上表现更佳，具体来说，在PIE数据集上，TA-STGCN的准确率比基线模型高出4.75%。", "conclusion": "该模型在准确性方面超越了现有的方法，特别是在PIE数据集上，TA-STGCN比基线模型的准确率高出4.75%。这表明该模型在提高行人意图预测效果方面是有效的。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12449", "html_url": "https://arxiv.org/abs/2507.12449", "title": "基于视觉的自主车辆在避障场景中的感知", "title_en": "Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios", "authors": "Van-Hoang-Anh Phan,Chi-Tam Nguyen,Doan-Trung Au,Thanh-Danh Phan,Minh-Thien Duong,My-Ha Le", "background": "自主车辆的安全运行依赖于精确的感知和运动规划。这些技术使得车辆能够在复杂环境中导航并在避免碰撞的同时安全行驶。", "innovation": "该论文提出了一种高效的障碍物避免流水线，利用仅摄像头的感知模块和Frenet-纯粹追求为基础的规划策略。系统结合计算机视觉的进步，采用YOLOv11进行目标检测和最新的单目深度估计模型，如Depth Anything V2，来估计物体距离。通过对这些模型的比较分析，揭示了它们在实际条件下的准确性和鲁棒性。", "conclusion": "系统在大学校园的多种场景中进行了评估，展示了其处理各种障碍物的有效性和提高自主导航的效果。结果视频可在此处查看：this https URL"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12318", "html_url": "https://arxiv.org/abs/2507.12318", "title": "组合离散潜在代码以实现高保真、高效扩散模型", "title_en": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models", "authors": "Samuel Lavoie,Michael Noukhovitch,Aaron Courville", "background": "研究显示，扩散模型能够在复杂分布中取得成功，主要是由于它们的输入条件。本文从理想表示应提升样本保真度、易于生成且具有组合性可以生成训练分布外样本的角度出发，探讨了用于条件的表示方法。", "innovation": "本文引入了离散潜在代码（DLC），这是一种从简化嵌入中通过自监督学习目标训练得出的图像表示法。DLCs由离散标记序列组成，不同于标准的连续图像嵌入。DLCs易于生成，并且其组合性允许生成训练分布外的新颖图像。使用DLCs训练的扩散模型在无条件图像生成方面具有更高的保真度，已达到ImageNet上无条件图像生成的新最先进技术状态。", "conclusion": "实验结果证实，组合DLC使得图像生成器能够以连贯的方式组合来自不同图像的语义生成新型样本。此外，展示了如何通过利用大规模预训练语言模型，使用DLC实现文本到图像的生成，并通过高效微调文本扩散语言模型生成新的训练外样本。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12416", "html_url": "https://arxiv.org/abs/2507.12416", "title": "QuRe：在组成图像检索中通过难负样本选择实现查询相关的检索", "title_en": "QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval", "authors": "Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee", "background": "现有的组成图像检索（CIR）方法侧重于检索目标图像，而忽略了其他图像的相关性。这是因为大多数使用对比学习的方法将目标图像视为正样本，而将批处理中的所有其他图像视为负样本，可能会导致包括虚假的负样本，从而检索到不相关图像，即使目标图像被检索，也可能降低用户满意度。现有的研究没有专门针对虚假负样本进行优化，导致检索结果不尽如人意。因此，需要一种可以减少虚假负样本的方法来提高检索的准确性和用户满意度。为了评估CIR模型与用户满意度的契合度，本研究创建了一个名为Human-Preference FashionIQ（HP-FashionIQ）的新数据集，该数据集明确捕获了用户的偏好，超越了仅为目标检索的模式。", "innovation": "本文提出了一种通过难负样本选择实现查询相关检索的方法，称为QuRe。QuRe通过优化奖励模型目标来减少虚假负样本，特别引入了难负样本的采样策略，通过目标图像后的两个陡峭的相关性分数下降点之间的图像来有效过滤虚假负样本。这种方法旨在提高CIR模型的检索准确性和对用户的满意度，提供了与人类偏好更强的对齐度。", "conclusion": "实验结果表明，QuRe在FashionIQ和CIRR数据集上实现了最先进的性能，并且在HP-FashionIQ数据集上的对人类偏好的对齐度最强。QuRe通过减少虚假负样本，提高了CIR模型的检索质量，并改善了用户体验。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12441", "html_url": "https://arxiv.org/abs/2507.12441", "title": "Describe Anything Model for Visual Question Answering on Text-rich Images", "title_en": "Describe Anything Model for Visual Question Answering on Text-rich Images", "authors": "Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu", "background": "最近在区域意识的视觉语言建模领域取得了进展，特别是在描述任何东西模型（DAM）的出现下。DAM能够生成任何特定图像区域或物体的详细描述，无需额外的局部图像-文本对齐监督。本文旨在研究这种区域描述能力是否有助于视觉问答（VQA）任务，特别是在包含密集文本的图像中的挑战场景下。在这种情况下，细致的文本信息提取是生成正确答案的关键。", "innovation": "介绍了一种新的框架DAM-QA，结合了DAM的区域意识能力，针对丰富的文本图像开发了一套定制化的评估方案，以更好地探索和利用DAM的区域意识能力。DAM-QA通过整合多个图像内容视图的答案聚合机制，增强了对与文本相关元素证据的识别。实验表明，与基准模型DAM相比，我们的方法在所有六个VQA基准上的表现更优，特别是在DocVQA上取得了明显的7分以上的优势；并且在参数数量更少的情况下，DAM-QA在区域感知模型中的性能领先，显著缩小了与强大泛化视觉语言模型之间的差距。", "conclusion": "这些结果突显了类似DAM模型在丰富文本和更广泛的VQA任务中的潜力，特别是在与高效的使用和集成策略相结合的情况下。我们已经将代码在以下网址公开：www.acme.com"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12462", "html_url": "https://arxiv.org/abs/2507.12462", "title": "SpatialTrackerV2：简化3D点跟踪", "title_en": "SpatialTrackerV2: 3D Point Tracking Made Easy", "authors": "Yuxi Xiao,Jianyuan Wang,Nan Xue,Nikita Karaev,Yuri Makarov,Bingyi Kang,Xing Zhu,Hujun Bao,Yujun Shen,Xiaowei Zhou", "background": "现有的3D跟踪方法通常依赖于模块化的组件管道，这些组件是从成品中挑选出来的。这类方法没有将点跟踪、单目深度估计和摄像机位姿估计之间固有的联系统一在一起，导致性能和效率有限。本文介绍了一种基于前馈的3D点跟踪方法，名为SpatialTrackerV2，旨在通过统一这些联系来提升3D跟踪性能和效率。", "innovation": "SpatialTrackerV2将3D运动分解为场景几何、摄像机自我运动和像素级对象运动，并利用全可微端到端架构学习几何和运动。这种方法可以通过合成序列、摆拍的RGB-D视频和未标记的实际场景数据实现大规模训练。SpatialTrackerV2通过学习异构数据中的几何和运动，提高了3D跟踪的准确性，并且比现有方法快了50倍。", "conclusion": "SpatialTrackerV2在3D跟踪方法上取得了显著的进步，对合成序列、摆拍的RGB-D视频和未标记的实际场景数据都能实现高效和准确的3D点跟踪，性能提升了30%，速度是现有最好的动态3D重建方法的50倍。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12463", "html_url": "https://arxiv.org/abs/2507.12463", "title": "MMHU: 一个大规模多模态的人类行为理解基准", "title_en": "MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding", "authors": "Renjie Li,Ruijie Ye,Mingyang Wu,Hao Frank Yang,Zhiwen Fan,Hezhen Hu,Zhengzhong Tu", "background": "人类是交通生态系统的重要组成部分，理解其行为对于促进安全驾驶系统的开发至关重要。尽管近年来研究已经探讨了人类行为的不同方面，例如运动、轨迹和意图，但在自动驾驶领域仍缺少一个综合性的基准，用于评估人类行为理解能力。因此，需要建立一个包括广泛行为标签的基准数据集，来评估从运动预测到人类行为问题解答的多项任务的能力。", "innovation": "本文提出了一个名为MMHU的大规模多模态基准数据集，该数据集包含了丰富的注释，如人类运动和轨迹、人类运动的文本描述、人类意图以及与驾驶安全相关的关键行为标签。数据集涵盖57k个人类运动片段和1.73M帧，来自于多种来源，如Waymo驾驶数据集、YouTube的野外视频和自收集的数据。同时，开发了一个包含人类的注释流程，生成丰富的行为描述，并提供了详尽的数据集分析和多个任务的基准测试，从而提供了一个全面的评估套件。", "conclusion": "本文提出的MMHU数据集提供了多样化的注释以及多个任务的基准测试，这有助于促进人类行为理解的研究，为自动驾驶系统的安全开发提供了有力支持。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12396", "html_url": "https://arxiv.org/abs/2507.12396", "title": "OD-VIRAT：现实监控环境中用于物体检测的大规模基准", "title_en": "OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments", "authors": "Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva", "background": "现实的人类监控数据对于训练和评估在真实条件下工作的计算机视觉模型至关重要，有助于开发能够在复杂环境中鲁棒进行人类和交流对象检测的算法。这类数据集需要提供多样且具有挑战性的信息，以便全面评估模型性能，并创造更可靠的监控系统以确保公共安全。现有的监控视频数据集未能满足多样性和挑战性的要求。", "innovation": "本研究提出了两个名为OD-VIRAT Large和OD-VIRAT Tiny的物体检测基准。这些基准覆盖了10种不同的人类监控场景，并标注了丰富的人体和物体边界框以及类别信息。此外，该研究还首次集中评估了最新发布的先进物体检测架构（如RETMDET, YOLOX, RetinaNet, DETR, Deformable-DETR）在复杂背景、遮挡物体和小型物体等挑战条件下的性能。", "conclusion": "提出的基准和实验设置将有助于提供选定物体检测模型的性能见解，并为开发更高效和鲁棒的物体检测架构奠定基础。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12464", "html_url": "https://arxiv.org/abs/2507.12464", "title": "CytoSAE: 可 interpret 的细胞嵌入用于血液学", "title_en": "CytoSAE: Interpretable Cell Embeddings for Hematology", "authors": "Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider", "background": "随着基于变压器的基础模型在医疗成像领域的应用日益广泛，解释这些模型推断的能力仍相对缺乏。稀疏自编码器（SAEs）作为机制可解释性的有力工具，在基础模型中展现出潜力，并已应用于视觉领域，发现视觉概念及其在变压器模型中的patch级归因。基于这一背景，作者研究了SAEs在血液学中的应用，特别是针对外周血单细胞图像建立CytoSAE模型。", "innovation": "本文提出了CytoSAE，这是一种在超过40,000张外周血单细胞图像上训练的稀疏自编码器。CytoSAE不仅在与血液学相关的数据集上表现出普适性，还能识别出形态学上相关的概念，并且这些概念得到了医学专家的验证。此外，CytoSAE能够生成患者特定和疾病特定的概念，从而可以在细胞层面对特定路径性的细胞和局部细胞异常进行检测。通过在患者级AML亚型分类任务中量化这类概念的效果，证明了CytoSAE能够达到与当前最佳方案相当的效果，同时仍具备子细胞级别的可解释性能力。", "conclusion": "CytoSAE通过稀疏自编码器方法解决了在血液学领域缺乏可解释性的挑战，能够识别出具有临床意义的概念，并用于特定患者的细胞异常检测，达到了当前最佳性能水平，为血液学基础模型的解释提供了新工具。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12420", "html_url": "https://arxiv.org/abs/2507.12420", "title": "InterpIoU: 基于插值的IoU优化重新思考边界框回归", "title_en": "InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization", "authors": "Haoyuan Liu,Hiroshi Watanabe", "background": "边界框回归（BBR）是目标检测的核心，其核心在于回归损失对于精确定位的作用。现有基于IoU的损失函数常常采用手工艺几何惩罚来处理非相交情况下的IoU非可微性，并改善BBR性能。然而，这些惩罚对于框的形状、大小和分布都比较敏感，往往导致小目标的次优优化，还可能出现边界框放大等不期望的行为。因此，需要一种新的损失函数来替代这些问题。", "innovation": "本文提出了基于插值的IoU（InterpIoU），它用插值框与目标之间的IoU替换掉了手动设计的几何惩罚。这种新的损失函数在非相交情况下提供有意义的梯度，并自然避免了由于惩罚不齐导致的边界框放大问题。此外，基于InterpIoU，引入了动态插值IoU（Dynamic InterpIoU），能够根据IoU值动态调整插值系数，增强对不同物体分布场景的适应性。", "conclusion": "实验表明，InterpIoU及其动态版本在COCO、VisDrone和PASCAL VOC数据集上持续优于现有的基于IoU的目标检测框架，特别是在小目标检测中取得显著的提升，验证了其有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12465", "html_url": "https://arxiv.org/abs/2507.12465", "title": "PhysX: 物理导向的3D资产生成", "title_en": "PhysX: Physical-Grounded 3D Asset Generation", "authors": "Ziang Cao,Zhaoxi Chen,Linag Pan,Ziwei Liu", "background": "现有3D生成主要强调几何和纹理，而忽视了基于物理的建模。因此，尽管3D生成模型的发展迅速，合成的3D资产常常忽略了丰富的物理特性，阻碍了其在模拟和具身人工智能等领域的真实世界应用。现有的研究忽略了体数据的标注，并且生成的3D资产缺乏物理性质的真实表现出架的特性，不利于其在物理领域的应用。PhysX旨在填补这一空白，提供一个端到端的物理导向的3D资产生成性能框架。", "innovation": "1. 提出了PhysXNet——第一个系统注释在物理导向的5个基础维度（绝对尺度，材质，可操作性，运动学和功能描述）上的3D数据集。2. 设计了一个可扩展的人工智能在环的注释管道，该管道基于视觉-语言模型，能够高效地从原始3D资产生成物理导向的资产。3. 提出了PhysXGen，一个前馈框架，用于生成物理导向的图像到3D资产，框架中利用双支架构明确建模3D结构和物理特性的潜在联系，从而生成具有可预测物理特性的3D资产，同时保留了原有的几何质量。", "conclusion": "我们的框架在广泛的实验中验证了优越的性能和强大的泛化能力。代码、数据和模型在发布以促进未来生成物理AI的研究。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12461", "html_url": "https://arxiv.org/abs/2507.12461", "title": "从胸部X射线诊断中的眼球运动解释放射科医生的意图", "title_en": "Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis", "authors": "Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le", "background": "放射科医生依赖于眼动来导航和解读医学影像。经验丰富的放射科医生具备识别潜在疾病的知识，并在搜索时遵循心理检查表来使用目光定位它们。现有的模型未能捕捉到每次凝视背后的根本意图。", "innovation": "本文介绍了一种基于深度学习的方法，RadGazeIntent，旨在模拟这种行为：具有寻找某种东西的意图并积极搜索它。我们的基于变换器的架构处理凝视数据的时间和空间维度，将精细的凝视特征转换为粗略且有意义的诊断意图表示，以解释放射科医生的目标。为了捕捉放射科医生多样化意图驱动行为的细微差别，我们对现有医学眼动跟踪数据集进行了处理，创建了三个带有意图标记的子集：RadSeq（系统性顺序搜索）、RadExplore（不确定性驱动的探索）和RadHybrid（混合模式）。实验结果表明，RadGazeIntent能够预测放射科医生在特定时刻检查哪些发现，所有意图标记的数据集均优于基准方法。", "conclusion": "实验结果表明，RadGazeIntent在预测放射科医生在特定时刻检查哪些发现方面表现出色，优于所有意图标记的数据集中的基线方法。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11569", "html_url": "https://arxiv.org/abs/2507.11569", "title": "视觉基础模型在即插即用的医学图像配准中是否准备好？", "title_en": "Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?", "authors": "Hanxue Gu,Yaqian Chen,Nicholas Konz,Qihang Li,Maciej A. Mazurowski", "background": "基于基础模型的配准算法最近被发现可以在零样本图像配准中显示潜力。这些模型在大规模图像数据集上预训练，能够捕捉丰富的特征表示，但其性能主要在刚性和不那么复杂的结构上进行了测试，如大脑和腹部器官。而对于更复杂和变形的解剖学结构，基础模型的性能尚不清楚。乳腺MRI配准特别困难，由于患者间的解剖差异、患者的体位造成的变形以及纤维腺组织的复杂细内部结构，其中准确对齐至关重要。因此，基于基础模型的配准算法是否能够处理这种复杂性仍是一个未解之谜。本研究旨在全面评估基于基础模型的乳腺MRI配准算法，涵盖了不同的年份、日期、序列、模态和患者疾病状态（病变与无病变）四个关键的乳腺配准任务。", "innovation": "本研究评估了五种预训练编码器（DINO-v2、SAM、MedSAM、SSLSAM和MedCLIP）在乳腺MRI四个关键配准任务中的表现，这些任务涵盖了不同年份、日期、序列、模态和患者疾病状态。结果表明，像SAM这样的基础模型算法在整体乳腺对齐方面优于传统的配准基线，尤其是在大域迁移时表现出色，但在捕捉纤维腺组织的精细细节方面存在困难。关于MedSAM和SSLSAM额外进行医学或乳腺特定图像的预训练或微调，并未改善配准性能，在某些情况下甚至降低性能。这些发现揭示了针对特定领域训练对配准的影响，并强调了需要探索能同时改善全局对齐和微细结构准确性的目标策略。", "conclusion": "我们的研究结果表明，基础模型算法在整体乳腺对齐方面优于传统的配准基线，尤其是在大域迁移时表现出色，但在捕捉纤维腺组织的精细细节方面存在困难。额外的预训练或微调在某些情况下可能会影响性能，需要进一步探讨特定领域的训练如何影响配准，以及如何设计针对特定目标的策略来提高配准的整体性能。该研究也是首个全面评估基础模型在乳腺MRI配准中的性能的研究。我们公开发布了用于实验的代码。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12455", "html_url": "https://arxiv.org/abs/2507.12455", "title": "通过句子级早期干预缓解对象幻觉", "title_en": "Mitigating Object Hallucinations via Sentence-Level Early Intervention", "authors": "Shangpin Peng,Senqiao Yang,Li Jiang,Zhuotao Tian", "background": "多模态大型语言模型（MLLMs）已经革新了跨模态理解，但仍然难以解决幻觉问题——即生成的内容与视觉输入相矛盾。现有的幻觉缓解方法要么计算成本高昂，要么会在训练数据和模型输出之间引入分布不匹配的问题。研究表明，幻觉主要在文本生成的早期阶段出现并传播到后续输出。", "innovation": "提出了一种名为SENTINEL的框架，它通过领域内偏好学习实现句子级早期干预，从而消除对人类注解的依赖。具体来说，SENTINEL通过迭代采样模型输出，交叉验证对象的是否存在，将句子分类为幻觉或非幻觉类别，从而建立高质量的领域内偏好对。然后，利用上下文一致的正样本和幻觉的负样本构建上下文感知的偏好数据，最后利用上下文感知偏好损失（C-DPO）来强调句子级的辨别性学习。", "conclusion": "实验结果表明，与原始模型相比，SENTINEL可以将幻觉减少超过90%，在幻觉基准和一般能力基准测试中也优于最新的State-of-the-Art方法，证明了其优越性及泛化能力。模型、数据集和代码可在指定的URL中获得。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12344", "html_url": "https://arxiv.org/abs/2507.12344", "title": "通过知识蒸馏提高轻量级杂草检测", "title_en": "Improving Lightweight Weed Detection via Knowledge Distillation", "authors": "Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein", "background": "精准农业中的杂草检测是关键组成部分，有助于精准施用除草剂并减少环境影响。然而，在资源受限的平台上部署准确的物体检测模型仍然具有挑战性，特别是在区分植株表型应用中常见的视觉相似杂草种类时。因此，如何在保持模型轻量级的同时提高实时智能喷洒系统中的检测性能成为了一个亟待解决的问题。", "innovation": "本文研究了通道级知识蒸馏（CWD）和掩蔽生成性知识蒸馏（MGD）以增强轻量级模型在实时智能喷洒系统中的表现。使用YOLO11x作为教师模型，YOLO11n作为参照和学生模型。CWD和MGD两种方法有效传输了教师模型的知识给学生模型。实验表明，两种方法在糖 beet 和四种杂草（Cirsium, Convolvulus, Fallopia, Echinochloa）的实时数据集中都实现了AP50的提升。相较于基线，CWD学生模型在mAP50上提升了2.5%，MGD提升了1.9%，且未增加模型复杂度。此外，还通过在Jetson Orin Nano 和 Raspberry Pi 5嵌入式设备上对学生YOLO11n模型进行实时部署验证，确保了该方法的实用性和有效性。", "conclusion": "通过实验结果表明，CWD和MGD为提高基于深度学习的杂草检测精度提供了一种有效、高效且实际的方法，并在作物表型场景中的精准农业应用中具有潜在的应用前景。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11551", "html_url": "https://arxiv.org/abs/2507.11551", "title": "使用通用分割模型进行医学图像中的定位点检测", "title_en": "Landmark Detection for Medical Images using a General-purpose Segmentation Model", "authors": "Ekaterina Stansfield,Jennifer A. Mitterer,Abdulrahman Altahhan", "background": "医学影像中的放射学图像在骨科诊断中至关重要，而解剖学定位点的检测是信息提取的关键步骤。尽管通用的预训练分割模型如SAM（Segment Anything Model）能够进行标注，但它们不适用于特定医学图像中的定位点检测，也没有被训练识别骨科中的骨盆定位点，因此无法产生准确的定位点分割。即使MedSAM，经过医学适应的SAM变体，也不能提供足够的细微精度用于骨盆的解剖学定位点检测。", "innovation": "本文提出了结合YOLO（一个适用于对象检测且擅长提供边界框的高效模型）和SAM（能够进行复杂结构分割的模型）的方法。通过使用YOLO生成的边界框作为SAM的输入提示，训练了一个混合模型，该模型可以准确地分割骨科骨盆放射学图像中的解剖学定位点和复杂轮廓。这种方法能够不仅分割少量的骨盆定位点，还能扩展到72个定位点和复杂的骨结构。", "conclusion": "实验结果证实，这种结合YOLO和SAM的方法在检测骨科骨盆放射学图像中的解剖学定位点和精细轮廓方面表现优秀。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12426", "html_url": "https://arxiv.org/abs/2507.12426", "title": "DVFL-Net: 一种轻量级的蒸馏视频焦点模態网络，用于时空动作识别", "title_en": "DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition", "authors": "Hayat Ullah,Muhammad Ali Shafique,Abbas Khan,Arslan Munir", "background": "视频识别的景观已经发生了显著的变化，从传统的卷积神经网络（CNNs）转变为基于 Transformer 的架构，以提高准确性。尽管3D CNNs能够捕捉时空动态，但近期的 Transformer 模型通过自我注意力机制建模长距离的时空依赖性。尽管在主要基准上达到了最先进的性能，但 Transformers 仍然计算成本高昂，特别是在稠密视频数据上。", "innovation": "为了解决这个问题，提出了一种名为 DVFL-Net（轻量级蒸馏视频焦点调节网络）的轻量级模型。DVFL-Net 利用了大规模预训练教师模型的知识蒸馏和时空特征调节，显著减少了计算量同时保持了高识别性能。该模型通过前向 KL 散度和时空焦点调节将 Video-FocalNet Base（教师）中的局部和全局上下文有效地转移给了提出的 VFL-Net（学生）。", "conclusion": "DVFL-Net 在 UCF50、UCF101、HMDB51、SSV2 和 Kinetics-400 基准上进行了评估，并将其与最新的基于人类动作识别（HAR）的先进方法进行了比较。结果显示，DVFL-Net 在性能和效率之间达到了最佳平衡，具有较低的内存使用、减少的 GFLOPs 和强大的准确性，使其成为实时 HAR 应用的实用解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11557", "html_url": "https://arxiv.org/abs/2507.11557", "title": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation", "title_en": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation", "authors": "Jiaxu Zheng,Meiman He,Xuhui Tang,Xiong Wang,Tuoyu Cao,Tianyi Zeng,Lichi Zhang,Chenyu You", "background": "磁共振（MR）成像在现代临床诊断中扮演着重要角色，并正越来越多地被集成到先进的治疗工作中，例如混合正电子发射断层扫描/磁共振（PET/MR）成像和MR-only放射治疗。这些集成方法高度依赖于辐射衰减的精确估计，通常通过将MR扫描合成CT图像来生成衰减图。但现有的适用于全身成像的MR-to-CT合成方法常常存在CT生成与输入MR图像之间的不良空间对齐问题，以及不足以可靠用于临床任务下游的图像质量问题。本研究旨在提出一种新颖的3D小波潜变量扩散模型（3D-WLDM），通过在学习的潜变量空间中进行模态翻译来解决这些局限性。通过在编码器-解码器架构中引入小波残差模块，增强在图像和潜变量空间中对细观特征的捕捉和重建。为了在扩散过程中保持解剖完整性，我们将结构特征和模态特异性特征分离，并将结构成分固定以防止变形。还引入了扩散模型中的双跳连接注意力机制，使得生成高分辨率CT图像时能够更好地表示骨骼结构和软组织对比度。", "innovation": "提出了一种新颖的3D小波潜变量扩散模型（3D-WLDM），该模型在学习的潜变量空间中进行模态翻译。通过在编码器-解码器架构中引入小波残差模块，增强了细观特征的捕捉和重建。引入了双跳连接注意力机制，提高了高分辨率CT图像生成的质量，能够更好地表示骨骼结构和软组织对比度。并将结构成分固定，以防止变形，从而保持解剖完整性。", "conclusion": "通过使用3D-WLDM，可以显著提高磁共振图像到计算机断层扫描图像合成的质量，增强细观特征的捕获和重建能力，同时保持图像的解剖完整性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "深度学习在几何问题求解中的综述", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题求解是数学推理的重要领域，广泛应用于教育、人工智能的数学能力评估及多模态能力评估等多个重要领域。近年来，深度学习技术的迅猛发展，尤其是多模态大型语言模型的兴起，引发了对该领域的广泛关注和研究热潮。", "innovation": "论文提供了深度学习在几何问题求解中的应用综述，包括总结相关任务、回顾相关深度学习方法、详细分析评价指标和方法，以及对当前挑战和未来研究方向进行批判性讨论。", "conclusion": "论文旨在为深度学习在几何问题求解领域的未来发展提供全面实用的参考，通过在GitHub上创建并持续更新相关文献列表进一步推动该领域的发展。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11690", "html_url": "https://arxiv.org/abs/2507.11690", "title": "Coreset选择对虚假相关性和群体稳健性的影响", "title_en": "The Impact of Coreset Selection on Spurious Correlations and Group Robustness", "authors": "Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky", "background": "coreset选择方法在减少训练数据规模的同时保持模型性能方面表现出潜力，但许多数据集存在偏差，导致模型学习虚假相关而非因果特征。因此，需要理解数据集减少方法是否会加剧、放大或减轻这些偏差。本文通过对比不同样本复杂度和偏差对齐以及数据集偏差与后续模型稳健性之间的复杂关系，对数据选择对虚假偏差水平和模型稳健性的影响进行了全面分析。", "innovation": "本文首次开展了关于数据选择对选择的coreset中的虚假偏差水平以及基于它们训练的下游模型稳健性影响的全面分析。通过使用涵盖十个不同虚假相关性基准、五项样本重要性/难度度量标准以及跨越广泛coreset大小的五种数据选择策略的广泛实验设置，本文揭示了样本难度与偏差对齐以及数据集偏差与模型稳健性结果之间关系复杂的互动模式。", "conclusion": "尽管一些coreset选择方法可以通过优先选择难题样本来降低偏差水平，但它们并不能可靠地保证下游稳健性。选择基于嵌入样本特征分类评分的coresets相较基于学习动态特征分类的风险较低，但这并不意味着可以完全避免模型偏差问题。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11938", "html_url": "https://arxiv.org/abs/2507.11938", "title": "多级相似性方法在单视角物体抓取中的应用：匹配、规划和优化", "title_en": "A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning", "authors": "Hao Chen,Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada", "background": "机器人领域中的单视角未知物体抓取仍然是一个具有挑战性的课题，原因在于视点不完全可能导致观察的不确定性。尽管通过大规模模型取得了一些基准解决方案，如GraspNet-1Billion，但这类基于学习的方法在面对感知噪声和环境变化时性能仍然不够鲁棒。为了克服这一局限，我们提出了一种新的基于相似性匹配的方法，以实现单视角未知物体抓取，无需依赖传统学习框架。", "innovation": "我们提出了一个多层次的相似性匹配框架，整合语义、几何和尺寸特征进行综合评估；引入了一种新的点云几何描述子C-FPFH，用于提高在部分和噪声条件下物体匹配的准确性。此外，结合使用大型语言模型，引入半定向包围盒及基于平面检测的点云注册方法，从而提高了单视角条件下的匹配精度。", "conclusion": "通过多层次相似性匹配、基于候选模型的模仿性抓取规划，以及局部优化改进抓取质量，我们提出的方法能够在单视角条件下实现对未知物体的稳定抓取。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11852", "html_url": "https://arxiv.org/abs/2507.11852", "title": "向自主骑行迈进：智能两轮车感知、规划与控制综述", "title_en": "Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers", "authors": "Mohammed Hassanin,Mohammad Abu Alsheikh,Carlos C. N. Kuhn,Damith Herath,Dinh Thai Hoang,Ibrahim Radwan", "background": "微移动解决方案的快速采用，特别是像电动滑板车和电动自行车这样的两轮车辆，已经迫切需要可靠的自主骑行（AR）技术。虽然自主驾驶（AD）系统已经取得了显著的进展，但AR技术面临独特的挑战。两轮平台本身稳定性差，体积小且电力有限，且环境不可预测，这严重威胁到行人的安全。", "innovation": "本文通过AD技术的视角，系统地分析了AR系统的核心组成部分、感知、规划和控制，指出了AR研究中的关键空白，包括缺乏针对各种AR任务的综合感知系统，行业和政府支持不足以及研究社区的忽视。提出了适用于轻量级平台的多模态传感器技术及边缘深度学习架构等具有前景的研究方向，旨在通过整合AD研究的洞见，加速安全、高效、可扩展的自主骑行系统的开发。", "conclusion": "通过整合AD研究与AR的具体需求，本文旨在推动未来城市交通中的安全、高效和可扩展的自主骑行系统的发展。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11561", "html_url": "https://arxiv.org/abs/2507.11561", "title": "预测新生儿肺动脉高压：多视角变异自编码器方法", "title_en": "Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach", "authors": "Lucas Erlacher,Samuel Ruipérez-Campillo,Holger Michel,Sven Wellmann,Thomas M. Sutter,Ece Ozkan,Julia E. Vogt", "background": "新生儿肺动脉高压（PH）是一种严重的状况，由肺动脉压力升高引起，导致右心室负担加重并可能导致心力衰竭。右心导管检查是诊断的金标准，但由于其侵入性和复杂性，超声心动图因其无创性、安全性和易用性而成为首选方法。然而，其准确度高度依赖于操作者，使PH的评估具有主观性。虽然已经探索了自动检测方法，但大多数模型针对成人，并依赖于单视角超声心动图框架，这限制了它们在新生儿中诊断PH的表现。虽然多视角超声心动图在提高PH评估方面显示出潜力，但现有模型在泛化能力方面存在困难。", "innovation": "本文采用多视角变异自编码器（VAE）来使用超声心动图视频预测新生儿的肺动脉高压。通过利用VAE框架，该模型捕获复杂的潜在表示，从而提高特征提取能力和鲁棒性。与单视角和监督学习方法相比，其性能表现更优。", "conclusion": "结果表明改进的泛化能力和分类准确性，进一步证明了多视角学习方法在新生儿肺动脉高压的稳健评估方面的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11939", "html_url": "https://arxiv.org/abs/2507.11939", "title": "POLYCHARTQA：使用多语言图表问答评估大型视觉语言模型", "title_en": "POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering", "authors": "Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin", "background": "图表是普遍采用的数据解释和交流工具。然而，现有的图表理解基准主要以英语为中心，限制了其对全球观众的适用性和可访问性。", "innovation": "提出PolyChartQA，这是首个涵盖22,606个图表和26,151个问题-答案配对的多语言图表问答基准数据集，包含10种不同的语言。PolyChartQA通过分离图表数据和渲染代码，使用解耦流水线生成多语言图表，同时采用最先进的基于LLM的翻译和严格的质量控制确保生成的多语言图表的语义和语义一致性。", "conclusion": "PolyChartQA为多语言图表理解的系统评估奠定了基础。实验表明，英语与其它语言之间的性能差距显著，尤其是那些非拉丁字符的低资源语言。这一基准为推动全球包容性视觉语言模型的发展奠定了基础。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11971", "html_url": "https://arxiv.org/abs/2507.11971", "title": "HPR3D: 层次代理表示的高保真3D重建和可控编辑", "title_en": "HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing", "authors": "Tielong Wang,Yuxuan Xiong,Jinfan Liu,Zhifan Zhang,Ye Chen,Yue Shi,Bingbing Ni", "background": "目前的3D表示方法（如网格、体素、点云和NeRF基神经隐式字段）显示出明显的局限性。它们通常特定于特定任务，缺乏在重建、生成、编辑和驱动中的普遍适用性。网格提供高精度但其密集的顶点数据使编辑复杂；NeRF提供出色的渲染效果但结构模糊，限制了动画和操作；所有表示在数据复杂性和保真度之间都存在固有的权衡。", "innovation": "该研究引入了一种新颖的3D层次代理节点表示方法。其核心创新在于通过在物体表面和内部分级组织（树形结构）的稀疏代理节点来表示物体的形状和纹理。每个节点在其局部空间中存储由小型MLP隐式编码的局部形状和纹理信息。查询任何3D坐标的属性涉及高效神经插值和轻量级解码附近和父节点的相关信息。这种方法产生了一个高度紧凑的表示，节点与局部语义对齐，能实现直接的拖拽编辑，并提供可扩展的质量与复杂度控制。", "conclusion": "广泛的3D重建和编辑实验表明，该方法的表达效率高，渲染质量高，并且可编辑性更优。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11853", "html_url": "https://arxiv.org/abs/2507.11853", "title": "一种用于SQUID显微镜扫描3D螺旋样品的时空物理导向模型", "title_en": "A Spatial-Physics Informed Model for 3D Spiral Sample Scanned by SQUID Microscopy", "authors": "J. Senthilnath,Jayasanker Jayabalan,Zhuoyi Lin,Aye Phyu Phyu Aung,Chen Hao,Kaixin Xu,Yeow Kheng Lim,F. C. Wellstood", "background": "先进封装技术的发展是半导体制造业的关键。然而，由于多层的深度和复杂性，对先进封装进行无损检测变得越来越具有挑战性。磁场成像（MFI）通过磁场成像技术可以有效检测磁场，但现有的磁感应反转方法通常仅依赖快速傅里叶变换（FFT），且未考虑涡流效应或仪器对齐问题。", "innovation": "本文提出了一种时空物理导向模型（SPIM），专门针对使用超导量子干涉设备（SQUID）显微镜扫描的3D螺旋样品。该模型包含了三部分创新：（1）通过同时对齐相位（I通道）和四相位（Q通道）图像来抑制涡流效应，提升磁图像清晰度；（2）解决扫描SQUID显微镜相对于线段的任何对齐偏差造成的偏斜问题；（3）通过将毕奥-萨伐尔定律与傅里叶变换结合，实现从磁场到磁电流的转换。该模型显著提高了检测精度，并成功消除了图像的旋转和偏斜对齐误差。", "conclusion": "时空物理导向模型在SQUID显微镜中对3D螺旋样品进行扫描时展示了卓越的性能。该模型为将空间分析与物理驱动模型结合应用于实际检测提供了有效的解决方案，并证实了这种方法在解决位置对齐和涡流效应方面的潜力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12132", "html_url": "https://arxiv.org/abs/2507.12132", "title": "DoRF：基于Wi-Fi的强健人类活动识别中的Doppler辐射场", "title_en": "DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi", "authors": "Navid Hasanzadeh,Shahrokh Valaee", "background": "Wi-Fi信道状态信息（CSI）在远程感知应用中的兴趣日益增长。近年来的研究表明，从CSI提取的多普勒速度投影能够实现一种鲁棒的人类活动识别（HAR）方法，该方法能够适应环境变化，并在新用户中泛化。尽管取得了这些进展，但通用性仍然不足以用于实际部署。受神经辐射场（NeRF）的启发，NeRF可以从二维图像学习3D场景的体分布表示，本文提出了一种从Wi-Fi CSI中提取的一维多普勒速度投影重建富有信息的3D潜运动表示的新方法。产生的潜表示用于构造运动的统一多普勒辐射场（DoRF），从而提供活动执行的全面视图并提高对环境变化的鲁棒性。研究表明，所提出的方法明显增强了基于Wi-Fi的HAR的泛化精度，突显了DoRFs在实际感知应用中的强大潜力。", "innovation": "基于NeRF的启发，提出了一种从Wi-Fi CSI中提取的多普勒速度投影重建3D潜运动表示的新方法，从而构造统一的多普勒辐射场（DoRF），提高了人类活动识别的鲁棒性和泛化性能。", "conclusion": "所提出的方法显著提升了基于Wi-Fi的HAR的泛化准确性，展示了DoRF在实际感知应用中的广泛应用潜力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11943", "html_url": "https://arxiv.org/abs/2507.11943", "title": "低秩适应方法在隐私保护图像分类中有效微调视觉Transformer", "title_en": "Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification", "authors": "Haiwei Lin,Shoko Imaizumi,Hitoshi Kiya", "background": "在当前的视觉Transformer（ViT）模型训练过程中，全量调整模型参数需占用很多计算资源和储存空间，这不利于隐私保护图像分类任务。因此，一种能在保持一定准确率的同时减少可训练参数数量的方法成为研究热点。", "innovation": "提出了一种低秩适应方法，用于训练隐私保护的ViT模型。该方法通过在每个层注入可训练的秩分解矩阵，使得嵌入层可以被冻结。这种方法不仅减少了可训练参数的数量，而且能够维持与全量调整几乎相同的准确率。", "conclusion": "通过低秩适应方法，研究不仅成功地减少了可训练参数的数量，还保持了与全量调整相近的准确率，这为隐私保护图像分类提供了高效的微调策略。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11821", "html_url": "https://arxiv.org/abs/2507.11821", "title": "MNIST-Gen：使用层次语义、强化学习和范畴理论的模块化MNIST风格数据集生成", "title_en": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory", "authors": "Pouya Shaeri,Arash Karimi,Ariane Middel", "background": "传统上用于神经网络基准测试的标准数据集（如MNIST、FashionMNIST等）虽然易于获取，但仅限于通用类别（如数字或服饰物品）。对于专门领域任务的研究人员（例如分类树木、食物物品或其他真实世界对象），这些数据集是不足和不相关的。此外，创建和发布自定义数据集可能会耗时、受到法律限制或超出单个项目范围。", "innovation": "MNIST-Gen框架是一个自动化的、模块化的和适应性的系统，用于生成与用户指定类别匹配的MNIST风格图像数据集，使用分层语义分类。该系统结合了CLIP语义理解、强化学习和人类反馈，实现了较少的手动干预下的智能分类。其分层方法支持具有语义特征的复杂类别结构，允许精细的亚类别化和多种处理模式：个体审查、智能批量处理和快速批量处理。MNIST-Gen将每个数据转换阶段建模为可组合的态射，增强清晰性、模块性和可扩展性。", "conclusion": "作为概念验证，使用MNIST-Gen生成了两个新型数据集——Tree-MNIST和Food-MNIST，证明了其生成任务特定评估数据的能力，同时实现了85％的自动分类准确率和80％的时间节省，相比人工方法而言更有优势。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11711", "html_url": "https://arxiv.org/abs/2507.11711", "title": "基于预训练视觉变换器的多巡天光曲线图像分类", "title_en": "Image-Based Multi-Survey Classification of Light Curves with a Pre-Trained Vision Transformer", "authors": "Daniel Moreno-Cartagena,Guillermo Cabrera-Vives,Alejandra M. Muñoz Arancibia,Pavlos Protopapas,Francisco Förster,Márcio Catelan,A. Bayo,Pablo A. Estévez,P. Sánchez-Sáez,Franz E. Bauer,M. Pavez-Herrera,L. Hernández-García,Gonzalo Rojas", "background": "本文研究了利用Zwicky Transient Facility (ZTF)和Asteroid Terrestrial-impact Last Alert System (ATLAS)的数据，通过Swin Transformer V2这一预训练视觉变换器进行光度分类的方法。研究基于多巡天环境，探索了不同数据集成策略，特别是发现联合处理来自不同巡天的数据能获得最佳性能。", "innovation": "提出了一种多巡天架构，能有效整合来自不同巡天的数据，从而实现最佳分类效果。这项工作强调了建模特定巡天特性及巡天间交互关系的重要性，并为未来时域天文学中的可扩展分类器建立指导原则。", "conclusion": "研究结果表明，联合处理ZTF和ATLAS数据的多巡天架构能实现最佳性能，这强调了在建模巡天特定特征及巡天间交互关系方面的重要性，并提供了指导未来时域天文中的可扩展分类器构建的建议。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11949", "html_url": "https://arxiv.org/abs/2507.11949", "title": "MOSPA：由空间音频驱动的人体运动生成", "title_en": "MOSPA: Human Motion Generation Driven by Spatial Audio", "authors": "Shuyang Xu,Zhiyang Dou,Mingyi Shi,Liang Pan,Leo Ho,Jingbo Wang,Yuan Liu,Cheng Lin,Yuexin Ma,Wenping Wang,Taku Komura", "background": "在角色动画中，使虚拟人物能够动态且真实地响应多样化的听觉刺激仍然是一个关键挑战，需要融合感知建模和运动合成。尽管这项任务非常重要，但尚未得到充分探索。大多数以往的工作主要集中在将语音、音频和音乐等模态映射到人类运动的生成上，但这些模型通常忽略了空间音频信号中编码的空间特征对人类运动的影响。为了弥补这一差距并实现高质量的空间音频驱动的人体运动建模，我们首次提出了一个全面的 Spatial Audio-Driven Human Motion (SAM) 数据集，该数据集包含多样且高质量的空间音频和运动数据。", "innovation": "我们发展了一个基于扩散的生成框架 MOSPA，该框架由空间音频驱动的人体运动生成，并通过有效的融合机制准确捕捉了身体运动和空间音频之间的关系。通过训练，MOSPA 可以在不同空间音频输入的条件下自动生成多样的真实的人体运动。此外，我们提出了 SAM 数据集，这填补了现有研究的空白。", "conclusion": "我们在对提出的数据集进行详尽研究并进行广泛实验后得出结论，我们的方法在该任务上达到了最先进的性能。我们会在论文被接受后开源我们的模型和数据集，并提供补充视频以获取更多信息。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12366", "html_url": "https://arxiv.org/abs/2507.12366", "title": "FactorHD：一种用于多对象多类表示和因式分解的超维计算模型", "title_en": "FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization", "authors": "Yifei Zhou,Xuchu Huang,Chenyu Ni,Min Zhou,Zheyu Yan,Xunzhao Yin,Cheng Zhuo", "background": "神经符号人工智能（神经符号AI）在逻辑分析和推理方面表现出色。超维度计算（HDC），作为一种有希望的大脑启发式计算模型，是神经符号AI的重要组成部分。尽管已经提出了多种HDC模型来表示类别实例和类别类别关系，但在表示更复杂的类-子类关系时，它们在因式分解任务上面临着挑战，因式分解是神经符号AI系统的关键任务。", "innovation": "提出了一种新的HDC模型——FactorHD，能够高效地表示和因式分解复杂的类-子类关系。FactorHD采用了符号编码方法，嵌入了额外的存储条款，以保留更多的信息。此外，它还采用了一个高效的因式分解算法，通过识别目标类的记忆条款来选择性地消除冗余类别。该模型显著提高了表示和因式分解具有类-子类关系的多个对象的计算效率和准确性，克服了现有HDC模型如'超位置灾难'和'2的问题'的限制。FactorHD在表示大小为10^9的条件下相较于现有HDC模型实现了约5667倍的加速。在结合使用ResNet-18神经网络时，FactorHD在Cifar-10数据集上的因式分解准确率达到92.48%。", "conclusion": "FactorHD在表示和因式分解具有类-子类关系的多个对象方面具有显著优势，且算法和性能上优于现有HDC模型。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12297", "html_url": "https://arxiv.org/abs/2507.12297", "title": "RegCL: 通过模型合并持续适应分割一切模型", "title_en": "RegCL: Continual Adaptation of Segment Anything Model via Model Merging", "authors": "Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang", "background": "现有的方法主要通过基于适配器的一站式适应范式来解决分割一切模型（SAM）在特定领域中的性能限制。然而，一些方法是为特定领域定制的，如果应用于其他领域则可能导致性能下降。这一 catastrophic forgetting 问题严重限制了模型的扩展性。", "innovation": "提出了RegCL，一种新的基于模型合并的持续学习（CL）框架，用于多领域知识的有效集成。RegCL通过将SAM不同领域训练的适应模块（例如LoRA模块）的参数合并到持续学习范式中来处理catastrophic forgetting。合并过程通过权重优化来指导，以最小化合并模型与每个领域特定模型之间的预测差异。RegCL在保持参数效率（即模型大小与任务数量无关且无需存储历史数据）的同时有效整合多领域知识。", "conclusion": "实验结果表明，RegCL在多个下游数据集上实现了优越的持续学习性能，验证了其在动态场景中的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11625", "html_url": "https://arxiv.org/abs/2507.11625", "title": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "title_en": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "authors": "Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski", "background": "近年来，多模态大型语言模型的发展使研究者开始关注这些模型对于数据可视化图表的理解能力，例如条形图和散点图。最近，研究焦点转向了基于地图的视觉问答(Map-VQA)。然而，现有的Map-VQA研究主要集中在区域着色图上，这种地图仅涵盖了有限的主题类别和视觉分析任务。", "innovation": "本文通过引入一个基准数据集MapIQ来解决上述问题，该数据集包含14,706个问题-答案对，覆盖了三大类地图：区域着色图、人口密度图和比例符号图，涉及六个不同的主题。同时还评估了多个多模态大型语言模型在六种视觉分析任务上的表现，将模型性能与人类基准进行比较，并探讨了地图设计变化对模型的影响，从而揭示了模型的鲁棒性、敏感度及其对内部地理知识的依赖性，为改善Map-VQA性能提供了可能的研究方向。", "conclusion": "本研究通过MapIQ数据集评估了多模态大型语言模型在地图视觉问答任务中的表现，揭示了地图设计变化对模型性能的影响，为未来研究提供了有价值的见解。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12417", "html_url": "https://arxiv.org/abs/2507.12417", "title": "通过非侵入式脑机接口在主观视角视频观看过程中自发的空间认知出现", "title_en": "Spontaneous Spatial Cognition Emerges during Egocentric Video Viewing through Non-invasive BCI", "authors": "Weichen Dai,Yuxuan Huang,Li Zhu,Dongjun Liu,Yu Zhang,Qibin Zhao,Andrzej Cichocki,Fabio Babiloni,Ke Li,Jianyu Qiu,Gangyong Jia,Wanzeng Kong,Qing Wu", "background": "人类具有非凡的空间认知能力，可以在新环境中实现自我定位。虽然有文档记录了海马神经元在编码位置和方向方面的作用，但在自然、被动经历中支持空间表示的大规模神经活动仍然知之甚少。本研究首次证明，基于脑电图（EEG）的非侵入性脑机接口（BCI）可以解码观看到主观视角视频时自发出现、精细程度高的自我中心6D姿态，包括三维位置和方向。尽管EEG的空间分辨率有限且信号噪声高，研究发现连续且结构化的视觉输入能够可靠地引发可解码的空间表征，这与参与者自身的空间参与感相一致。进一步提高视觉输入的帧率为每图像100毫秒时，解码性能提升，提示与内在的神经时间动态匹配。通过梯度回传方法，研究发现不同EEG电极对位置和方向特定信息贡献不同，揭示了一种分布式但互补的神经编码方案。这表明，在被动条件下，大脑的空间系统也能自发运作，挑战了传统上对主动与被动空间认知的区分。研究结果为非侵入式观察主观视角空间地图的自动构建提供了窗口，也深化了对人类如何将日常感官体验转化为结构化内部表征的理解。", "innovation": "本研究首次利用非侵入性脑电图脑机界面解码了观看到主观视角视频时自发出现的精细空间表征，通过EEG揭示了大脑如何在被动条件下持续进行空间编码。这种方法具有重要的应用前景，可以帮助理解大脑如何构建和利用空间信息来进行日常认知活动。研究还通过分析不同电极的贡献，揭示了大脑不同区域在空间认知中的作用机制", "conclusion": "研究结果表明，在被动观看视频期间，大脑的空间系统能够自发并持续进行运作，挑战了传统关于主动和被动空间认知的区分。这种非侵入性方法为深入理解人类如何将日常感官体验转化为结构化内部表征提供了新的视角。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12145", "html_url": "https://arxiv.org/abs/2507.12145", "title": "PRISM：在边缘设备上进行分布式基础模型推断", "title_en": "PRISM: Distributed Inference for Foundation Models at Edge", "authors": "Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang", "background": "基础模型（FMs）在多种应用中表现出色，如图像分类和自然语言处理，但其在边缘设备上的部署面临着显著挑战，尤其是在通信效率和计算资源利用方面，引发了研究者对于开发实用且高效的部署策略的兴趣。", "innovation": "PRISM是一种通信效率高且计算感知的策略，用于边缘设备上的分布式Transformer推理。它通过使用Segment Means表示法来近似中间输出特征，大幅减少了设备间通信量。此外，PRISM重构了自注意力机制，消除了由于按设备分割位置而产生的冗余计算，并为自回归模型设计了一种分区感知的因果屏蔽方案。该项工作在多种模型和数据集中进行了评估，显示了通信开销和设备计算量的大幅减少，同时保持了合理的小幅准确度下降。", "conclusion": "PRISM为在分布式资源受限环境中部署基础模型提供了一种可扩展且实用的解决方案，通过大幅减少通信开销和设备计算量，证明了其实用价值。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12042", "html_url": "https://arxiv.org/abs/2507.12042", "title": "基于屏幕内外分类的立体声声源定位与检测", "title_en": "Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification", "authors": "Kazuki Shimada,Archontis Politis,Iran R. Roman,Parthasaarathy Sudarsanam,David Diaz-Guerra,Ruchi Pandey,Kengo Uchida,Yuichiro Koyama,Naoya Takahashi,Takashi Shibuya,Shusuke Takahashi,Tuomas Virtanen,Yuki Mitsufuji", "background": "上一届挑战赛使用了第一阶 Ambisonics (FOA) 和麦克风阵列的四声道音频格式，而今年的挑战赛转向研究基于立体声音频数据的声事件定位与检测 (Stereo SELD)，即在场景分析和音频可视化方面更加常见并具有有限视野的情况。由于立体声音频数据的固有角度模糊性，任务关注左-右方位角平面的方向到达（DOA）估计以及距离估计。", "innovation": "提出了DCASE2025 Stereo SELD数据集，该数据集包括从STARSS23录制中摘取并转换的立体声音频和视角视频片段。基线系统被设计为处理立体声音频和相应的视频帧作为输入，并且在音频-视觉轨道中引入了屏幕内外分类的新子任务，以应对有限视野的问题。评估指标也进行了修改，增加了屏幕内外分类准确度指标，评估模型识别屏幕内外声源的能力。", "conclusion": "基线系统在立体声音频数据上执行得相当不错，但是具体的性能评估需要进一步详细的数据展示。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2309.10527", "html_url": "https://arxiv.org/abs/2309.10527", "title": "SPOT: 通过占用预测进行的可扩展3D预训练", "title_en": "SPOT: Scalable 3D Pre-training via Occupancy Prediction for Learning Transferable 3D Representations", "authors": "Xiangchao Yan,Runjian Chen,Bo Zhang,Hancheng Ye,Renqiu Xia,Jiakang Yuan,Hongbin Zhou,Xinyu Cai,Botian Shi,Wenqi Shao,Ping Luo,Yu Qiao,Tao Chen,Junchi Yan", "background": "3D LiDAR点云标注对于自动驾驶等应用至关重要，但仍然非常劳动密集型。预训练-微调方法通过在多种下游数据集和任务上微调预训练的骨干网络，可以减轻标注负担。本文旨在探讨如何通过占用预测任务，在标注效率的微调框架下学习可迁移的3D表示。", "innovation": "1. 提出SPOT（基于占用预测的可扩展3D预训练），用于在不同的LiDAR传感器和标注方法之间缩小领域差距。\n2. 首次通过任务的占用预测展示了通用表示学习的可能性。\n3. 开发了一种光束重采样技术与类别平衡策略相结合的点云增强技术。\n4. 观察到可扩展预训练：预训练数据越多，下游性能越好，同时也兼容未标注数据。", "conclusion": "SPOT展示了其在不同公开数据集和下游任务上的有效性，展示了其通用表示能力、跨域鲁棒性和数据可扩展性，为实际应用提供了重要支持。这些发现将有助于理解LiDAR点云，并为未来的LiDAR预训练研究铺平道路。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12050", "html_url": "https://arxiv.org/abs/2507.12050", "title": "IDFace: 用于高效且安全识别的面部模板保护", "title_en": "IDFace: Face Template Protection for Efficient and Secure Identification", "authors": "Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Dongsoo Kim,Junbum Shin,Jae Hong Seo", "background": "随着面部识别系统（FRS）的普及，用户隐私的重要性日益增加。面部识别过程中，通过保护用户的面部模板来保护用户隐私变得至关重要。现有加密工具如同态加密（HE）虽然提供了安全性的机会，但其与面部识别系统的直接集成存在效率问题，因为HE主要设计用于特定形状的加密数据的算术运算，这导致了非常低效的性能，且许多基于HE的面部模板保护方法比没有保护的系统慢数百倍。因此，设计一种高效且安全的面部识别方法在加密模板上进行识别变得非常必要。该研究提出的IDFace方法正是为了解决此问题。", "innovation": "IDFace方法基于两种新技术：高效的旋转度量下同态加密生物特征数据库搜索技术。第一种技术是一张面模板表示转换，极大地降低了匹配测试的成本。第二种技术是一种空间高效的编码，减少了加密算法中的无效空间，从而节约加密模板上的操作数目。IDFace方法实现在加密模板数据库中的高效面部识别，即使是在一百万条记录的数据库中，126毫秒内也能进行面部模板识别，与在明文上的识别相比，只多了2倍的开销。", "conclusion": "IDFace是一个新的基于同态加密的高效且安全的面部识别方法，不仅能够保护面部模板，还能提供高效且安全的识别性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12427", "html_url": "https://arxiv.org/abs/2507.12427", "title": "基于多层特征表示的单.Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation", "title_en": "Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation", "authors": "Ashkan Shakarami,Azade Farshad,Yousef Yeganeh,Lorenzo Nicole,Peter Schuffler,Stefano Ghidoni,Nassir Navab", "background": "目前的病理组织分割方法通常以像素为单位进行分割，这需要大量的标注工作且计算效率较低。因此，现有的方法难以支持临床相关的任务，如肿瘤-间质定量和手术边缘评估。为了改进这种情况，研究人员提出了一种基于单元的组织分割框架UTS（Unit-based Tissue Segmentation），该框架将单位定义为每个固定大小的32×32像素块，而非每个像素。UTS通过Multi-Level Vision Transformer (L-ViT) 来利用多层特征表示来捕捉细粒度的形态和全局组织上下文，从而减少标注工作并提高计算效率，同时保持准确度。该模型被训练用于将乳腺组织分为三个类别（浸润性肿瘤、非肿瘤性间质和脂肪），UTS支持临床相关任务，如肿瘤-间质定量和手术边缘评估。这种方法在459个HE染色区域的386,371个像素块上进行了评估，结果表明，UTS比U-Net变体和基于变压器的基本模型表现更好。", "innovation": "提出了基于单元的组织分割框架UTS，通过Multi-Level Vision Transformer (L-ViT) 来利用多层特征表示来捕捉细粒度的形态和全局组织上下文，从而减少标注工作并提高计算效率，同时保持准确度。这种方法相比传统的以像素为单位的分割方法，具有更高的计算效率和准确度。特别是在支持临床相关任务方面，如肿瘤-间质定量和手术边缘评估，表现出色。", "conclusion": "UTS框架在459个HE染色区域的386,371个像素块上达到了比U-Net变体和基于变压器的基本模型更好的性能。该方法通过采用更高效的分割单位和模型架构，解决了传统像素级分割方法的效率和准确性之间的权衡问题。未来的工作可以进一步优化该模型，使其适用于更多的组织类型和临床任务。同时，公开提供的代码和数据集将有助于该模型的进一步验证和应用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.06403", "html_url": "https://arxiv.org/abs/2403.06403", "title": "基于基础模型的无训练3D场景分割点分割：一种无训练框架", "title_en": "PointSeg: A Training-Free Paradigm for 3D Scene Segmentation via Foundation Models", "authors": "Qingdong He,Jinlong Peng,Zhengkai Jiang,Xiaobin Hu,Jiangning Zhang", "background": "近期视觉基础模型在2D感知任务上取得了显著的性能，然而直接训练适合3D空间的基础网络仍然存在挑战，主要是由于3D数据集的局限性，以及现有模型能否无缝迁移到3D空间仍待探索。", "innovation": "本文提出了PointSeg，一种无需训练的新型框架，利用现有的基础模型来处理3D场景感知任务。PointSeg通过获取准确的3D提示，将对应像素在不同帧中对齐来实现3D场景分割。设计了双分支提示学习结构生成点和预测提示，并结合双向匹配策略进行迭代后精炼，还设计了一种相关的归一化合并算法来改进最终的聚合掩膜。", "conclusion": "PointSeg在多种数据集上均展示了出色的分割性能，无须训练即取得了显著效果。尤其在ScanNet、ScanNet++和KITTI-360数据集上，比现有专家级无训练模型分别提高了14.1%、12.3%和12.6%的mAP。此外，PointSeg能够与多种基础模型兼容，并在多种数据集上超越专训练的方法，表明其作为通用模型的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.05968", "html_url": "https://arxiv.org/abs/2312.05968", "title": "手术计算机视觉的起步", "title_en": "Jumpstarting Surgical Computer Vision", "authors": "Deepak Alapatt,Aditya Murali,Vinkle Srivastav,Pietro Mascagni,AI4SafeChole Consortium,Nicolas Padoy", "background": "当前研究和产业界普遍认为，缺乏大规模且代表性的标注数据集是手术数据科学领域进展的最大障碍。自我监督学习（SSL）方法的发展可能解决这一问题，减少对大规模标注数据集的依赖，但现有SSL方法在面对领域转移时的鲁棒性尚未明确，阻碍了这些方法在利用多样化的手术数据方面的应用效果评估。因此，研究者转向数据本身，发现SSL初始化后的下游价值与预训练数据集的组成密切相关。这揭示了尽管SSL可以减少标注数据的需求，但在构建针对手术领域的通用基础模型时仍存在重要的数据组成缺口需要填补。", "innovation": "本文通过一系列受控实验，基于超过300个实验结果，跨越20种预训练数据集、9种手术操作、7个中心（医院）、3种标注数据设置、3种下游任务以及多个训练运行，提出了一种新的数据集组成指导建议，达到在两个公开的相位识别基准上超越现有方法的最佳表现，分别为Cholec80的2.2%和AutoLaparo的5.1%。", "conclusion": "研究结果强调，要在手术领域构建泛用的基础模型以应对多样化的应用情况，需进一步明确数据集的组成规则，并持续优化自我监督学习方法，提高其面对多样化的领域转移时的鲁棒性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.06050", "html_url": "https://arxiv.org/abs/2404.06050", "title": "大规模场景中单目相机深度、姿态和隐式场景表示的增量联合学习", "title_en": "Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes", "authors": "Tianchen Deng,Nailin Wang,Chongdi Wang,Shenghai Yuan,Jingchuan Wang,Hesheng Wang,Danwei Wang,Weidong Chen", "background": "稠密场景重建在摄影现实视图合成中有各种应用，如VR/AR、自动驾驶车辆等。然而，大多数现有方法在大规模场景中难以应用，主要因为三个核心挑战：「（a）不准确的深度输入」、现实世界中大规模场景很难获得准确的深度输入；「（b）不准确的姿态估计」、大多数现有方法依赖于准确的先验估计相机姿态；「（c）场景表示能力不足」、单一全局辐射场缺乏有效扩展的容量。", "innovation": "提出了一种增量联合学习框架，可以实现准确的深度、姿态估计和大规模场景重建。采用基于视觉变换器的网络来增强规模信息估计的表现。设计了一种特征-度量束调整（FBA）方法以准确和稳健地在大规模场景中进行相机追踪。在隐式场景表示方面，提出了增量场景表示方法，将整个大规模场景构建为多个局部辐射场，以增强3D场景表示的扩展性。", "conclusion": "通过扩展实验验证了该方法在深度估计、姿态估计和大规模场景重建方面的有效性和准确性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.09158", "html_url": "https://arxiv.org/abs/2404.09158", "title": "StreakNet-Arch：基于Underwater Carrier LiDAR-Radar成像的一种反散射网络架构", "title_en": "StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging", "authors": "Xuelong Li,Hongjun An,Haofei Zhao,Guangying Li,Bo Liu,Xing Wang,Guanghua Cheng,Guojun Wu,Zhe Sun", "background": "介绍了基于自主研发的Underwater Carrier LiDAR-Radar (UCLR) 的StreakNet-Arch框架，该框架结合了Self-Attention和新提出的Double Branch Cross Attention (DBC-Attention) 以增强散射抑制效果。该研究在受控的水箱实验条件下验证了StreakNet-Arch的效果，并与传统带通滤波器及学习基础的MP网络和CNN进行了比较，发现其在同等模型规模和复杂度下实现出更高的F1分数。实时基准测试也表明相较于传统方法，StreakNet-Arch在NVIDIA RTX 3060上的成像时间保持恒定，不受帧数影响。此外，研究还披露了包含2695168个真实世界下的3D点云数据的公开数据集，为后续研究提供了便利。在南海实验证明了UCLR系统的准确性，可以实现1000米深度和20米范围内的3D目标位置误差低于46毫米。", "innovation": "提出了StreakNet-Arch框架，引入了两种新型注意力机制——Self-Attention和Double Branch Cross Attention（DBC-Attention）。这些机制有效提升了散射抑制效果，使该网络在有限的模型规模和复杂度下，实现出超过传统方法的F1分数及更稳定的实时性能。此外，该研究还提供了一个包含大量3D点云数据的公开数据集，有助于后续研究的发展。", "conclusion": "研究通过引入新型注意力机制，将UCLR重新配置为实时且效率高的成像系统，实现出传统方法无法比拟的高精度和实时性能。同时公开的数据集也将助力其他研究人员进一步探究UCLR的有效性。在南海的实践应用还证明了该系统的实际可行性及高精度。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.02426", "html_url": "https://arxiv.org/abs/2408.02426", "title": "提高高分辨率医学图像分类转换学习中的内存效率", "title_en": "Boosting Memory Efficiency in Transfer Learning for High-Resolution Medical Image Classification", "authors": "Yijin Huang,Pujin Cheng,Roger Tam,Xiaoying Tang", "background": "大尺寸预训练模型的成功使微调成为下游任务中取得显著改进的标准方法。然而，对整个预训练模型参数集进行微调成本高昂。参数高效转移学习(PETL)作为一种成本效益高的替代方案，正在逐渐兴起。尽管它具有许多优势，但随着模型规模和输入分辨率的增加，PETL面临的挑战是训练内存消耗并未像参数使用那样有效降低。因此，本文提出了一种专用于高分辨率医学图像分类的PETL方法，即Fine-grained Prompt Tuning plus (FPT+)，该方法显著降低了与其他PETL方法相比的训练内存消耗。", "innovation": "本文提出了FPT+方法，旨在降低高分辨率医学图像分类中的内存消耗。该方法通过训练一个轻量级的辅助网络和通过精细提示和融合模块访问大型预训练模型(大预训练模型，LPM)的预训练知识实现了这一目标。具体来说，FPT+冻结了感兴趣的LPM，并构建了一个可学习的轻量级辅助网络。LPM处理高分辨率图像以提取精细特征，而辅助网络利用相应下采样的低分辨率图像以减轻内存使用。为了使辅助网络能够利用预训练知识，本文提出了精细提示和融合模块，它们通过LPM的中间激活来协作总结信息。", "conclusion": "FPT+在八个不同大小、模态和复杂性的医学图像数据集上进行了评估，实验结果表明，与其它PETL方法相比，FPT+仅使用1.03%的可学习参数和整个ViT-B模型微调所需的3.18%内存就表现出卓越的性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.15615", "html_url": "https://arxiv.org/abs/2409.15615", "title": "KISS-Matcher：重访快速稳健的点云配准", "title_en": "KISS-Matcher: Fast and Robust Point Cloud Registration Revisited", "authors": "Hyungtae Lim,Daebeom Kim,Gunhee Shin,Jingnan Shi,Ignacio Vizzo,Hyun Myung,Jaesik Park,Luca Carlone", "background": "尽管全球点云配准系统在各方面都有了显著的进步，许多研究主要集中在特定组件上，比如特征提取、图论裁剪或位姿求解。这项研究从整体角度看点云配准问题，开发了一个开源且通用的C++库，名为KISS-Matcher。KISS-Matcher集成了一个新颖的特征检测器Faster-PFH，改进了经典的快速点特征直方图（FPFH），并采用基于k-核心的图论裁剪来减少拒绝异常对应可能性的计算时间复杂度。最后，它将这些模块整合成一个完整的、用户友好且即用型流程。通过广泛的实验验证，KISS-Matcher展现了出色的可扩展性和广泛适用性，在保持精度的同时显著提高了与最先进的稳健点云配准流程的速度。", "innovation": "开发了一个新型特征检测器Faster-PFH，该检测器提升了经典FPFH的性能；采用基于k-核心的图论裁剪技术以降低计算复杂度；将上述模块集成在一个完整的、用户友好型且可以直接使用的流程中。", "conclusion": "KISS-Matcher具有卓越的可扩展性和广泛的适用性，在保持精度的同时大幅提升了与现有最先进的点云配准流程的速度。代码已经公开可用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10745", "html_url": "https://arxiv.org/abs/2411.10745", "title": "跨模态骨骼-文本鸿沟：零样本骨架动作识别的扩散驱动模态对齐", "title_en": "Bridging the Skeleton-Text Modality Gap: Diffusion-Powered Modality Alignment for Zero-shot Skeleton-based Action Recognition", "authors": "Jeonghyeok Do,Munchurl Kim", "background": "在零样本骨架基动作识别（ZSAR）中，将骨架特征与动作标签的文本特征对齐对于准确预测未见过的动作至关重要。然而，ZSAR 面临的一个基本挑战是骨架和文本两种特征之间的模态差距，这严重限制了对未见过动作的泛化能力。尽管之前的大部分方法集中于直接将骨架和文本的隐空间对齐，但这些空间之间的模态差距阻碍了稳健的泛化学习能力。为了解决这一问题，我们借鉴了扩散模型在多模态对齐（例如，文本到图像，文本到视频）中的成功经验，提出了一个基于扩散的骨架-文本对齐框架，以此来跨越骨架和文本的模态鸿沟。", "innovation": "我们的方法Triplet Diffusion for Skeleton-Text Matching (TDSM)强调的是扩散模型的跨模态对齐能力而不是生成能力。TDSM通过将文本特征融入逆向扩散过程中，利用文本指导对骨架特征进行去噪，形成统一的骨架-文本隐空间，以实现稳健的匹配。为了增强鉴别性，我们引入了一个三重扩散（TD）损失，该损失鼓励TDSM对骨架-文本的匹配进行修正，并将不同动作类别的匹配推得更加分离。实验结果表明，TDSM在零样本设置中取得了显著的性能提高，相比于非常先进的方法，取得了2.36%-13.05%的显著领先优势，展示了其在零样本场景下优越的准确性和可扩展性。", "conclusion": "我们的TDSM在零样本骨架动作识别中显著优于非常近期的最先进的方法，证明了在零样本设置中的优越准确性和可扩展性，通过有效的骨架-文本匹配实现了良好的泛化能力。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.06405", "html_url": "https://arxiv.org/abs/2410.06405", "title": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects", "title_en": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects", "authors": "Wenhao Li,Yudong Xu,Scott Sanner,Elias Boutros Khalil", "background": "ARC（抽象和推理语料库）是一个流行的基准测试，特别关注人工智能系统在视觉推理评估中的表现。在原来的设定中，ARC任务要求通过对小2D图像处理和少量输入-输出训练对来解决程序合成问题。研究者最初发现，尽管传统的Vision Transformer（ViT）在图像处理方面表现出色，但在ARC任务上的表现却非常糟糕，即使训练数据达到一百万张图片，也难以完成任务。", "innovation": "研究者提出了ViTARC，一种借鉴ViT结构的视觉推理对齐架构，以解决ViT在2D表示、位置和物体信息处理上的不足。具体改进包括：使用像素级输入表示、设计空间感知的令牌化方案以及引入基于自动分割的目标位置编码等。这些改进使得基于输入-输出网格的监督学习在超过200种公共ARC任务上的解题率达到近100%，强调了将强大的Transformer架构与高层次视觉推理所需的正确归纳偏置相结合的重要性。", "conclusion": "研究结果表明，ViT架构存在固有的表示缺陷，使其难以识别ARC任务中的简单结构化映射。ViTARC架构弥补了这些缺陷，提出了更加合适的来解决视觉推理的架构。这为未来基于Transformer架构的视觉推理研究奠定了坚实的基础。为了提高Transformer在抽象和视觉推理方面的性能，研究者强调了在大量训练数据和无噪声映射条件下，正确归纳偏置的必要性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.00355", "html_url": "https://arxiv.org/abs/2411.00355", "title": "TextDestroyer: 无需训练和标注的图像中异常文本降解的扩散方法", "title_en": "TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images", "authors": "Mengcheng Li,Fei Chao", "background": "当前的场景文本移除模型需要复杂的标注和再训练，并且可能会留下模糊但仍可识别的文字痕迹，这影响了隐私保护和内容隐匿的效果。现有的方法在数据标注和模型训练方面消耗大量的人力和资源，同时也无法彻底消除文字痕迹，这对于隐私保护和内容隐匿是不利的。", "innovation": "本文提出了一种名为TextDestroyer的新方法，这是一种无需标注数据和重新训练的场景文本破坏方法，使用预训练的扩散模型。TextDestroyer采用三级层次过程，通过在潜在起始代码中使用高斯分布来扰乱文本区域，并在扩散去噪过程中引用原始的潜在空间，以恢复受损的背景。这种方法能够在重建时保证背景的完美恢复，解决了现有模型的不足，具有劳动成本低、资源需求少、文本破坏彻底且具有更好的泛化能力等特点。", "conclusion": "TextDestroyer通过无需标注和训练、更彻底的文本破坏以及更优的泛化能力，有效解决了现有场景文本移除模型面临的问题，展示了在真实场景和生成图像上的良好表现。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.09474", "html_url": "https://arxiv.org/abs/2410.09474", "title": "使用双增强策略提炼不变表示", "title_en": "Distilling Invariant Representations with Dual Augmentation", "authors": "Nikolaos Giakoumoglou,Tania Stathaki", "background": "知识蒸馏（KD）已被广泛用于从大型、准确的模型（教师）转移到较小、更高效的模型（学生）。最近的方法试图通过结合因果解释来强制一致性，以提炼不变表征。本文在此研究的基础上，引入了一种双重增强策略，以促进教师和学生模型中不变特征的学习。该方法利用在蒸馏过程中对两个模型应用不同的增强处理，促使学生捕捉到更加稳健且可迁移的特征。", "innovation": "提出了一种双重增强策略，通过在蒸馏过程中使用不同增强处理，促进教师和学生模型中不变特征的学习。这种方法补充了现有的不变因果蒸馏方法，确保学习到的表示在更广泛的样本变异和变换中保持稳定。", "conclusion": "大量的实验结果显示，这种方法在CIFAR-100上的效果与同构蒸馏方法相当，证明了其有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12305", "html_url": "https://arxiv.org/abs/2507.12305", "title": "PROL：基于提示在线学习的无回放流式数据连续学习", "title_en": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "authors": "M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk", "background": "在线连续学习(OCL)中的数据隐私约束使得数据只能在线一次使用，这增加了流式数据中的灾难性遗忘问题的复杂性。当前SOTAs在OCL中的常用方法是通过回忆以前类别的记忆示例或特征来解决这个问题。另一方面，基于提示的方法在连续学习中表现出色，但是随着可训练参数数量的增长而带来损失。第一种方法在实际中可能不可行，因为数据开放政策的限制，而第二种方法则存在与流式数据相关的吞吐量问题。这项研究推出了一个新的基于提示的在线连续学习方法，包含四个主要组成部分：（1）轻量级提示生成器作为通用知识，（2）可训练比例-偏移器作为特定知识，（3）预训练模型（PTM）的一般化保留，（4）硬-软更新机制。该方法在CIFAR100，ImageNet-R，ImageNet-A和CUB数据集上的性能显著优于当前SOTAs。在复杂性分析中，该方法所需的参数较少并且在训练时间、推理时间和吞吐量方面的表现适度。因此，方法的代码已公开可以进一步研究使用。", "innovation": "提出了一个基于提示的在线连续学习（PROL）方法，包含四个主要组成部分：轻量级提示生成器作为通用知识，可训练比例-偏移器作为特定知识，预训练模型（PTM）的一般化保留，以及硬-软更新机制。这种新的方法显著提高了在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上的性能，同时在复杂性分析方面需要较少的参数，实现适度的训练时间、推理时间和吞吐量。在实践中避免了回放的问题，并且在数据隐私性方面相较于其他方法更具优势。", "conclusion": "我们提出的方法在几种标准数据集上表现出显著的性能提升，且在复杂性分析方面比现有SOTAs更加优秀。该方法适用于在线连续学习中记忆管理的问题，并且不需要像其他方法一样需要回放机制。尽管性能有所提升，但该方法仍然需要更加深入的研究来进一步优化模型的参数和训练策略。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.03629", "html_url": "https://arxiv.org/abs/2501.03629", "title": "CFFormer: 横跨CNN-Transformer通道注意和空间特征融合以提高异质医学图像分割", "title_en": "CFFormer: Cross CNN-Transformer Channel Attention and Spatial Feature Fusion for Improved Segmentation of Heterogeneous Medical Images", "authors": "Jiaxuan Li,Qing Xu,Xiangjian He,Ziyu Liu,Daokun Zhang,Ruili Wang,Rong Qu,Guoping Qiu", "background": "医学图像分割在计算机辅助诊断中起着重要作用。现有的方法主要利用空间注意力来突出感兴趣区域，但由于医学成像设备的限制，医学图像表现出显著杂异性，给分割带来了挑战。例如，超声图像经常受到斑点噪声、低分辨率和目标组织与背景之间对比度差的影响，可能导致不准确的边界描绘。与这些杂异质量问题相关的挑战需要通过特定的方法来解决。", "innovation": "本文提出了一种混合CNN-Transformer模型，称为CFFormer，通过有效通道特征提取，利用丰富的上下文信息来增强模型准确识别组织区域的能力。提出的架构包括两个关键组件：Cross Feature Channel Attention (CFCA)模块和X-Spatial Feature Fusion (XFF)模块。模型包含双重编码器，其中CNN编码器专注于捕捉局部特征，而Transformer编码器则建模全局特征。CFCA模块筛选并促进了两个编码器通道特征之间的交互，而XFF模块有效减少了空间特征中显著的语义信息差异，实现平滑且一致的空间特征融合。该模型在八个数据集中得到了全面评估，包括五种模态，以测试其泛化能力。实验结果表明，该模型在异质医学图像数据集上表现出色，超越了当前最先进的方法，并保持了准确的组织区域分割。", "conclusion": "本文提出的CFFormer模型在多种医学图像数据集上取得了令人满意的结果，展示了它在处理复杂、异质性高的医学图像中的优越性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15151", "html_url": "https://arxiv.org/abs/2501.15151", "title": "SpikeDet：基于脉冲神经网络的更优放电模式实现准确且能效高的目标检测", "title_en": "SpikeDet: Better Firing Patterns for Accurate and Energy-Efficient Object Detection with Spiking Neuron Networks", "authors": "Yimeng Fan,Changsong Liu,Mingyang Li,Dongze Liu,Yanyan Liu,Wei Zhang", "background": "脉冲神经网络（SNNs）作为神经网络的第三代，因其低功耗和生物解释性在目标检测领域引起了广泛关注。然而，现有的基于SNN的目标检测方法存在局部放电饱和问题，即信息密集区域的神经元在所有时间步中持续放电，这种异常放电模式降低了特征鉴别能力和检测精度，同时也增加了放电频率，阻碍了SNN实现其潜在的能效优势。", "innovation": "本文提出了一种名为SpikeDet的新颖的脉冲目标检测器，用于优化放电模式以实现精确且能效高的检测。具体来说，设计了一种脉冲骨干网络MDSNet，该网络有效地调整了每个层的膜突触输入分布，在脉冲特征提取过程中取得更好的神经元放电模式。此外，提出了一种脉冲多方向融合模块（SMFM）来更好地利用和保存高质量的骨干特征，提升了模型的多尺度检测能力。实验结果表明，SpikeDet在COCO 2017数据集上的表现 superior。在COCO 2017数据集上，它实现了51.4%的AP，比之前的SNN基线方法高出2.5%，且功率消耗仅为原来的一半。在目标检测子任务上，包括GEN1事件驱动数据集和URPC 2019水下数据集，SpikeDet也取得了最优性能。特别地，在GEN1上，我们的方法实现了47.6%的AP，比之前的SNN基线方法高出7.2%，且具有更好的能效.", "conclusion": "实验结果表明，SpikeDet在目标检测中实现了更高的精度和能效。在COCO 2017数据集上，它达到了51.4%的AP，相比其他SNN基线方法高出2.5%，且仅消耗一半的功率。在GEN1和URPC 2019水下数据集等子任务上，SpikeDet同样取得了最优的性能，证明了SpikeDet方法的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.08379", "html_url": "https://arxiv.org/abs/2406.08379", "title": "通过利用眼动信号进行非监督技能人体活动自见证误检测", "title_en": "Gazing Into Missteps: Leveraging Eye-Gaze for Unsupervised Mistake Detection in Egocentric Videos of Skilled Human Activities", "authors": "Michele Mazzamuto,Antonino Furnari,Yoichi Sato,Giovanni Maria Farinella", "background": "当前的研究主要依赖于标记错误的数据，这在收集过程中耗费成本且难以实现，特别是在对特定领域的人体技能活动进行监测时。本文通过分析眼动信号，提出了一个无需标注错误的非监督错误检测方法，以解决眼动信号在识别人体活动中的错误方面的挑战。", "innovation": "本文提出了一种新的眼动完成任务，从视觉观察和部分眼动轨迹预测眼注视点。这种方式能有效识别身体技能活动中的错误，并在不同数据集中取得了显著的性能提升，甚至超过了有监督的方法，同时不需要任何标注数据。这种基于眼动分析的方法特别适用于高技能动作、低动作执行信心度和手眼协调要求的活动场景中。", "conclusion": "实验结果表明，所提出的方法在不同数据集中的预测表现均优于现有方法。在HoloAssist错误检测挑战中排名第一，展示了其在非监督错误检测方面的优越性能。进一步的分析证明，眼动分析特别适合于观察高技能动作、低执行信心度及需要手眼协调和操作技能的活动。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.02179", "html_url": "https://arxiv.org/abs/2411.02179", "title": "CleAR：移动增强现实中的鲁棒上下文引导生成性光照估计", "title_en": "CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality", "authors": "Yiqin Zhao,Mallesham Dasari,Tian Guo", "background": "高质量的环境照明对于创建沉浸式移动增强现实(AR)体验至关重要，但由于移动AR设备感测能力的几个关键限制，如低摄像头视角和有限的像素动态范围，实现视觉上连贯的估计是具有挑战性的。最近，生成式人工智能的进步，能够从文本和图像等多种类型的提示生成高质量的图像，这为高质量光照估计提供了潜在的解决方案。然而，为了有效利用生成图像扩散模型，我们必须解决内容质量和推理速度两个关键限制。因此，本研究旨在设计并实现一个名为CleAR的生成性光照估计系统，可以在360度HDR图像格式下生成高质量、多样的环境图。具体而言，CleAR通过与AR环境上下文数据引导的两步生成流水线确保输出与物理环境的视觉上下文和颜色外观一致。此外，通过与光照条件的实时调整组件，以提高在不同光照条件下的估计稳健性。实验表明，CleAR在估计准确性、延迟和鲁棒性方面优于最新的光照估计方法。", "innovation": "CleAR系统涵盖了两步生成流水线，利用AR环境上下文数据，提高输出与现实环境视觉上下文和颜色外观的一致性；设计了实时调整组件以适应不同光照条件下的估计结果；使用360度HDR图像格式生成高质量的环境图。这些创新点使得CleAR不仅提高了光照估计的准确性，还提升了系统的实时性和鲁棒性，相比最新的方法提高了110倍以上的速度，尤其在虚拟对象渲染中实现了显著的准确性提升。", "conclusion": "通过定量和定性评价，研究结果表明CleAR在估计准确性、延迟和鲁棒性方面优于当前最先进的光照估计方法，并得到31名用户的反馈，认为它为大多数虚拟物体生成了更好的渲染效果。CleAR能够在几乎实时（3.2秒）内生成高质量光照估计，并且具有更好的渲染质量，这表明CleAR是一个非常有应用潜力的移动AR光照估计系统。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12440", "html_url": "https://arxiv.org/abs/2507.12440", "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "title_en": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "authors": "Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang", "background": "实机器人数据的收集在模仿学习中取得了显著的进展，但机器人硬件的需求本质上限制了数据规模。本文研究了使用第一人称人类视频训练视觉-语言-动作（VLA）模型的可能性。", "innovation": "利用第一人称人类视频训练VLA模型，特别是利用视频中丰富的场景和任务，通过逆运动学和重新目标化将人类动作转化为机器人动作。此外，提出了Isaac Humanoid Manipulation Benchmark作为模拟基准，设计了多样化的双臂操作任务，以细化和评估EgoVLA模型，并证明了它在改进基线方面具有显著效果。", "conclusion": "通过Isaac Humanoid Manipulation Benchmark评估了EgoVLA，并展示了与基线相比的显著改进，证明了人类数据的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.14559", "html_url": "https://arxiv.org/abs/2403.14559", "title": "VAPO: 面向高效6自由度物体姿态估计的可见性感知关键点定位", "title_en": "VAPO: Visibility-Aware Keypoint Localization for Efficient 6DoF Object Pose Estimation", "authors": "Ruyi Lian,Yuewei Lin,Longin Jan Latecki,Haibin Ling", "background": "在基于实例的6自由度物体姿态估计中，局部化预定义的3D关键点以建立3D-2D对应关系是一种有效的方法。然而，不可靠的关键点定位结果，特别是在不可见关键点上的表现，降低了对应关系的质量。这个问题通常是由数据集中缺失关键点的可见性信息导致的。本文通过考虑关键点的可见性来定位关键点，提出了一种有效的方法从现有的对象级注解生成二元可见性标签，适用于不对称物体和对称物体。进一步地，基于PageRank算法，从二元标签中推导出实际的、可见性感知的重要性。借助于这种可见性感知重要性的灵活性，设计了VAPO（可见性感知姿态估计器），将可见性感知重要性与最先进的姿态估计算法相结合，并加入了额外的位置编码，能够应用于基于CAD和非基于CAD的环境。", "innovation": "本文提出了从现有的对象级注解生成二元可见性标签的方法，首次考虑了关键点的可见性信息，通过PageRank算法推导出实际的可见性感知重要性，设计了结合这一信息的姿态估计算法VAPO，可以应用于基于CAD和非基于CAD的环境。实验结果显示，VAPO在流行的物体姿态估计基准测试中达到了最先进的性能。", "conclusion": "本文通过考虑到关键点的可见性信息，设计了一种有效解决不可靠关键点定位问题的方法VAPO，显著提高了实例级6自由度物体姿态估计的性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.12567", "html_url": "https://arxiv.org/abs/2502.12567", "title": "DeltaDiff: 以实际驱动的锚残差扩散模型实现忠实超分辨率", "title_en": "DeltaDiff: Reality-Driven Diffusion with AnchorResiduals for Faithful SR", "authors": "Chao Yang,Yong Fan,Qichao Zhang,Cheng Lu,Zhijing Yang", "background": "最近，扩散模型在超分辨率任务中的应用遇到了保真度降低的问题。由于扩散模型固有的随机采样特性，直接应用在超分辨率任务中会导致生成的细节偏离高分辨率图像的真实分布。", "innovation": "提出了一种新型DeltaDiff方法，通过约束扩散过程，建立高分辨率（HR）与低分辨率（LR）之间的确定性映射路径，而非传统扩散模型中的随机噪声干扰过程。该方法在残留空间中实现了扩散熵25%的减少，有效地抑制了无关噪声干扰。实验结果表明，该方法超越了最新的模型并生成了更好的保真度结果。", "conclusion": "该工作为将扩散模型应用到图像重建任务建立了一种新的低秩约束范式，平衡了随机生成与结构保真之间的关系。我们的代码和模型已公开发布。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.19034", "html_url": "https://arxiv.org/abs/2501.19034", "title": "XRF V2: 一种整合 Wi-Fi 信号和便携设备传感器（手机、手表、耳塞、眼镜）的行动概要化数据集", "title_en": "XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses", "authors": "Bo Lan,Pei Li,Jiaxi Yin,Yunpeng Song,Ge Wang,Han Ding,Jinsong Han,Fei Wang", "background": "人类动作识别（HAR）在健康监测、智能家居自动化和人机交互等领域中扮演着重要角色。尽管HAR已经被广泛研究，但在智能家居环境中使用Wi-Fi和IMU信号进行行动概要化，即识别和总结连续动作仍是一项新兴任务。为此，本文引入了XRF V2数据集，用于室内日常活动的时间动作定位（TAL）和行动概要化。XRF V2集成了来自Wi-Fi信号、多模态智能设备传感器（如智能手机、智能手表、耳机和智能眼镜）以及同步视频录制的数据，提供了16名志愿者在三种不同环境下的广泛室内活动集合。", "innovation": "本文提出了XRFMamba神经网络，它在处理未剪辑的感官序列时能够捕获长时依赖关系，实现了均值mAP为78.74的最佳性能，优于最近的WiFiTAD 5.49分，在参数使用方面减少了35%。此外，还引入了响应含义一致性（RMC）指标，用于评估行动概要化性能，并实现了平均响应含义一致性（mRMC）为0.802。", "conclusion": "我们设想XRF V2将成为推动人类动作定位、动作预测、姿态估计、多模态预训练基础模型、合成数据生成等领域研究的宝贵资源。数据和代码可在以下链接获取。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.17066", "html_url": "https://arxiv.org/abs/2502.17066", "title": "DUNIA: 通过跨模态对齐实现像素级嵌入的地观测应用", "title_en": "DUNIA: Pixel-Sized Embeddings via Cross-Modal Alignment for Earth Observation Applications", "authors": "Ibrahim Fayad,Max Zimmer,Martin Schwartz,Fabian Gieseke,Philippe Ciais,Gabriel Belouze,Sarah Brood,Aurelien De Truchis,Alexandre d'Aspremont", "background": "近年来，自监督多模态学习在地球观测应用中得到了广泛的关注和发展。然而，大多数现有方法生成的嵌入表示相对粗糙，仅限于块级大小，这限制了它们与LiDAR等其他模态数据的有效集成。", "innovation": "本文提出了DUNIA方法，通过图像与全波形LiDAR数据之间的跨模态对齐来学习像素级嵌入表示。与传统的自监督方法不同，DUNIA采用对比性训练方式，使得生成的嵌入可以直接用于环境监测等多种任务。该方法在7项具体任务中验证了高效率。", "conclusion": "实验结果显示，DUNIA模型生成的嵌入在零样本环境下通常优于专门的监督模型，即使在少量数据情况下也表现出色。在微调设置下，该模型在6项任务中的5项上达到了或接近当前最先进的性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.05843", "html_url": "https://arxiv.org/abs/2502.05843", "title": "从对象到事件：通过基于LLM的符号推理解锁对象检测器的复杂视觉理解", "title_en": "From Objects to Events: Unlocking Complex Visual Understanding in Object Detectors via LLM-guided Symbolic Reasoning", "authors": "Yuhui Zeng,Haoxiang Wu,Wenjie Nie,Xiawu Zheng,Guangyao Chen,Yunhang Shen,Jun Peng,Yonghong Tian,Rongrong Ji", "background": "当前的对象检测器在实体定位和分类方面表现出色，但在事件识别能力方面存在固有的局限性。这些局限源于其专注于离散对象识别的架构，而不是建立涉及对象间的组合推理、相互关系和情境语义的理解模型，这对于全面理解事件至关重要。", "innovation": "本文提出了一种新型框架，将标准对象检测的能力扩展到复杂事件理解，通过基于大语言模型(大语言模型-LLM)的符号推理指导，解决了这一挑战。本框架的关键创新在于无需特定任务的训练即可弥合对象检测与事件理解之间的语义差距，并且可以通过与任何开放式词汇对象检测器接口来扩展其固有功能跨架构。核心方法包括(1) 对检测实体间的关联模式进行符号回归机制探索，(2) 基于大语言模型的引导策略，引导搜索导向有意义的表达。这些发现的符号规则将低级视觉感知转化为可解释的事件理解，为对象到事件的推理路径提供透明路径，具有强跨领域的迁移性。", "conclusion": "将我们的框架与无训练的框架与特定的事件识别系统对比，在多个应用领域中展示了对复杂事件，如非法捕鱼活动(75% AUROC，+8.36% 的改进)，建筑安全违规(+15.77%) 和异常人群行为(+23.16%) 的识别效果的增强。代码可在 [这里] 获取。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08384", "html_url": "https://arxiv.org/abs/2503.08384", "title": "基于原型的巨像素全切片图像分类的多实例学习", "title_en": "Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification", "authors": "Susu Sun,Dominique van Midden,Geert Litjens,Christian F. Baumgartner", "background": "多实例学习（MIL）方法在病理学全切片图像（WSI）分析中取得了显著成功。然而，大多数MIL模型仅提供基于注意力的解释，无法准确捕捉模型的决策机制，也不允许人类与模型的互动。", "innovation": "我们引入了ProtoMIL，这是一种内置可解释的MIL模型，可以提供用户友好的解释并支持人类干预。该方法利用稀疏自编码器从图像特征空间中发现可解释的概念，然后用于训练ProtoMIL。模型通过概念的线性组合表示预测，使得决策过程透明化。此外，ProtoMIL允许用户通过改变输入概念来干预模型。实验表明，ProtoMIL在分类性能上与最先进的MIL模型相当，同时提供直观可理解的解释。我们的方法还通过人类干预消除了对诊断无关信息的依赖，引导模型以正确的原因进行正确的决策。", "conclusion": "实验表明，ProtoMIL在两个广泛使用的病理学数据集上实现了与最先进的MIL模型相当的分类性能，同时提供直观可理解的解释。此外，我们展示了我们的方法可以通过人类干预消除对诊断无关信息的依赖，引导模型以正确的原因进行正确的决策。代码将在http://www.example.com 公开可用。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.01912", "html_url": "https://arxiv.org/abs/2502.01912", "title": "PATCH：一种评估历史绘画中艺术实践多样性的深度学习方法", "title_en": "PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings", "authors": "Andrew Van Horn,Lauryn Smith,Mahamad Mahmoud,Michael McMaster,Clara Pinchbeck,Ina Martin,Andrew Lininger,Anthony Ingrisano,Adam Lowe,Carlos Bayod,Elizabeth Bolman,Kenneth Singer,Michael Hinczewski", "background": "艺术史上的艺术品创作方式经历了显著变化，因此理解创作过程成为了技术艺术史的核心问题。在文艺复兴和早期现代时期，油画主要由大师画家指导学徒，这些学徒通常会在项目中贡献自己的部分。然而，由于大师们的艺术和管理风格差异很大，因此不同组合的艺术家和工具在不同大师之间、甚至在同一工作室内部或单独的画布上都有所不同。关于工作室管理方式和艺术创作过程的信息仍然很少，尤其是缺乏外部例子用于训练网络，以识别不同艺术家和材料的贡献。机器学习方法在这种情况下有潜力通过对笔触分析到显微尺度的拓展来揭示新的信息。然而，分析工作室中的绘画作品面临着挑战，因为艺术家和材料的相关记录很少，所以无法利用外部例子进行训练来识别艺术家的贡献。", "innovation": "我们提出了一种新颖的机器学习方法，称为配对分配训练法用于分类异质性（简称PATCH），这种方法能够在没有外部训练数据或“真实标准”的情况下识别出个体的创作实践模式。该方法通过监督手段实现了无监督的结果，并且在表现上优于简单的统计程序和无监督机器学习方法。我们将其应用于西班牙文艺复兴大师埃尔·格列柯的两幅历史画：《基督的洗礼》和《十字架上的基督与风景》，我们的发现可能反驳了以往将该画归于工作室成员的研究结果。此外，我们分析结果创建了一种衡量不同时空的艺术实践多样性的度量标准，可用于描述艺术品。", "conclusion": "我们提出了一种新的无监督机器学习方法PATCH，通过分析绘画作品中的微小笔触差异，能够识别不同的艺术家个体创作。我们展示了该方法不仅能够应用于具体的创作样本，而且提供了一种用于描述、比较和量化不同时空的艺术作品中艺术实践多样性的工具。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.15203", "html_url": "https://arxiv.org/abs/2502.15203", "title": "FlipConcept：无需调整的多概念个性化文本到图像生成", "title_en": "FlipConcept: Tuning-Free Multi-Concept Personalization for Text-to-Image Generation", "authors": "Young Beom Woo,Sun Eung Kim,Seong-Whan Lee", "background": "近年来，将多种个性化概念结合进单张图像的文本到图像（T2I）生成得到了广泛关注。然而，现有的方法在复杂场景下经常会因为非个性化区域的失真和需要额外的调优而导致性能下降，限制了它们的实际应用。", "innovation": "本文提出FlipConcept，一种无需额外调优即可无缝结合多种个性化概念到单张图像的新方法。我们引入了引导外观注意机制以增强个性化概念的视觉保真度，还引入了掩码引导噪声混合以在概念融合过程中保护非个性化区域。此外，我们还应用背景稀释以减少概念泄露，即个性化概念在图像中与其它物体混合的现象。实验结果表明，尽管无需调优，本文方法在单个和多个个性化概念推断中均优于现有模型，证明了该方法在大规模、高质量多概念个性化的有效性与实用性。", "conclusion": "本文提出的FlipConcept方法在无需调优的情况下，能够在单张图像中无缝结合多种个性化概念，在单个和多个个性化概念的效果上均优于现有模型，展示了其在大规模、高质量多概念个性化方面的有效性和实用性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11167", "html_url": "https://arxiv.org/abs/2503.11167", "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction", "title_en": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction", "authors": "Haonan Wang,Qixiang Zhang,Lehan Wang,Xuanqi Huang,Xiaomeng Li", "background": "从神经活动解码视觉刺激对于理解人类大脑至关重要。尽管功能性磁共振成像(fMRI)方法已成功重构静态图像，但在视频重建方面仍面临挑战，特别是需要捕获时空动态如运动和场景转换。近年来，尽管改进了语义和感知对齐，但这些方法在整合粗略的fMRI数据与详细的视觉特征方面仍存在问题。", "innovation": "受视觉系统分层组织的启发，我们提出了一种名为NEURONS的新框架，该框架将学习分解为四个相关子任务：关键物体分割、概念识别、场景描述和模糊视频重建。该方法模拟了视觉皮层的功能专业化，使模型能够捕捉多样化的视频内容。在推理阶段，NEURONS为预训练的文本到视频扩散模型生成稳健的条件信号以重构视频。通过大量实验，NEURONS表现出比当前最先进的基线更出色的视频一致性（提高26.6%）和语义层准确度（提高19.1%）。", "conclusion": "研究表明，NEURONS在视频重建方面具有强大的功能性与视觉皮层的关联，突显了其在脑-机接口和临床应用中的潜力。代码和模型权重可以在提供的链接中获取。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.12955", "html_url": "https://arxiv.org/abs/2503.12955", "title": "HIS-GPT: 向3D场景中的人类多模态理解迈进", "title_en": "HIS-GPT: Towards 3D Human-In-Scene Multimodal Understanding", "authors": "Jiahe Zhao,Ruibing Hou,Zejie Tian,Hong Chang,Shiguang Shan", "background": "为了评估人工智能体在3D场景中对人类的理解能力，本文提出了一个新的任务：场景中的人类问题回答（HIS-QA），该任务要求人工智能体理解人类状态和行为、推理解周围环境，并在场景中回答人类相关的问题。为此，作者介绍了HIS-Bench，这是一个多模态基准，系统地评估了从基础感知到常识推理和规划的广泛维度。多个视觉-语言模型在HIS-Bench上的评估显示了其在处理HIS-QA任务时存在显著限制。", "innovation": "本文提出了HIS-GPT，这是第一个专门为HIS理解设计的基础模型。HIS-GPT将3D场景上下文和人类运动动态整合进大型语言模型，并引入专门机制来捕捉人类-场景交互。广泛的实验表明，HIS-GPT在HIS-QA任务上取得了新的最佳结果。", "conclusion": "我们希望这项工作能激发未来关于3D场景中人类行为分析的研究，推动具身AI和世界模型的发展。研究的代码和数据详见此链接：this https URL。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.14987", "html_url": "https://arxiv.org/abs/2410.14987", "title": "Few-shot工业异常图像生成与分离共享微调", "title_en": "SeaS: Few-shot Industrial Anomaly Image Generation with Separation and Sharing Fine-tuning", "authors": "Zhewei Dai,Shilei Zeng,Haotian Liu,Xurui Li,Feng Xue,Yu Zhou", "background": "尽管已有大量的研究工作，但大多数努力要么专注于特定任务，如仅关注异常或正常产品，要么需要为每种异常类型分离出不同的模型。因此，现有的方法提供的生成能力有限，依赖于大量的异常特定模型。", "innovation": "提出了SeaS，这是一种联合工业生成模型，能够自动生成多样化的异常和真实正常的产成品，以及精确的异常掩码。SeaS通过U-Net的差异化学习能力捕捉微小变化的正常产品和多样化异常的视觉特征，使用了一个不平衡异常（UA）文本提示并引入了分离异常对齐（DA）损失，将异常属性与UA中的不同异常标记分离并对齐。此外，Normal-image对齐（NA）损失对齐正常标记以生成均匀的正常产品，SeaS还通过结合判别U-Net特征和高分辨率VAE特征生成准确的异常掩码。", "conclusion": "SeaS在工业生成方面设立了新的基准，显著增强了下游应用，平均像素级AP改善了8.66%，图像级AP提高了1.10%，监督分割模型的IoU提高了12.79%。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.12335", "html_url": "https://arxiv.org/abs/2503.12335", "title": "GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from Illumination-Inconsistent Images", "title_en": "GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from Illumination-Inconsistent Images", "authors": "Tengfei Wang,Xin Wang,Yongmao Hou,Zhaoning Zhang,Yiwei Xu,Zongqian Zhan", "background": "精确的几何表面重建对于机器人自探索和操作任务至关重要。尽管3D Gaussian Splatting (3DGS)在表面重建领域表现出色，但由于光照不一致情况下的鲁棒性重建仍然存在挑战，该方法的应用范围仍需拓展。", "innovation": "本文提出了一种名为GS-3I的方法，通过结合基于卷积神经网络(CNN)的调光矫正框架和参考法向量与多视角观测法向量结合的法线补偿机制，旨在解决单视角图像中由于欠曝光区域导致的3D高斯优化偏差问题，并克服多视角图像之间光照不一致引起几何约束不匹配的问题，从而实现复杂光照场景下的稳健和精确表面重建。", "conclusion": "详尽的实验评估表明，GS-3I能够在复杂的光照场景中实现稳健且精确的表面重建，突显了其在这一关键挑战中的有效性与适用性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.17240", "html_url": "https://arxiv.org/abs/2411.17240", "title": "利用基于扩散的单目相机校准提升3D重建", "title_en": "Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration", "authors": "Junyuan Deng,Wei Yin,Xiaoyang Guo,Qian Zhang,Xiaotao Hu,Weiqiang Ren,Xiaoxiao-Long,Ping Tan", "background": "单目相机校准对于许多3D视觉任务至关重要。然而，现有的大多数方法依赖手工制作的假设或受限于有限的训练数据，导致在不同真实世界图像中的泛化表现较差。最近在大量数据上训练的稳定扩散模型展示了生成具有多种特征高质量图像的能力。现有证据表明，这些模型隐含地捕捉了相机焦距与图像内容之间的关系。", "innovation": "本文提出了一种基于扩散的方法，称之为DM-Calib，用于从单张输入图像中估计针孔相机内参。利用扩散模型的强大先验知识，引入了一种名为Camera Image的新图像表示，可以无损地编码相机内参并无缝集成到扩散框架中。将问题重新表述为生成条件于输入图像的密集Camera Image，通过微调稳定扩散模型，从单一RGB输入生成Camera Image，再通过RANSAC操作提取相机内参。该方法显著提高了各种3D任务的表现，包括零样本度量深度估计、3D测量、姿态估计和稀疏视图重建。", "conclusion": "在多个公开数据集上进行的实验表明，本文提出的方法在各种3D任务性能上显著优于基线方法，并为3D视觉任务提供了广泛的好处。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13026", "html_url": "https://arxiv.org/abs/2503.13026", "title": "HiMTok: 使用大型多模态模型进行图像分割的层次化掩码令牌学习", "title_en": "HiMTok: Learning Hierarchical Mask Tokens for Image Segmentation with Large Multimodal Model", "authors": "Tao Wang,Changxu Cheng,Lingfeng Wang,Senda Chen,Wuyue Zhao", "background": "大多功能模型（LMMs）在图像分割领域的出色表现引起了图像分割社区的广泛关注。现有的LMM驱动分割方法要么使用对象边界点来表示掩码，要么引入特殊的分割令牌，这些隐藏状态需要原始图像作为输入来解码。然而，这些方法往往会因为掩码表示不足和复杂的架构限制了LMMs的潜力。", "innovation": "提出了一种层次化掩码令牌（HiMTok），它可以使用最多32个令牌来表示分割掩码，并在掩码解码过程中不需要使用原始图像。HiMTok允许紧凑且从粗到细的掩码表示，并很好地与LLM的下一个令牌预测范式相契合，从而促进了直接获取分割能力。我们开发了一种三级训练配方，用于逐步学习分割和视觉能力，并使用分层掩码损失实现有效的从粗到细学习。此外，我们还使信息双向流动，允许在掩码令牌和边界框之间进行转换，充分利用多任务训练潜力。", "conclusion": "我们的方法在各种分割任务中实现了最先进的性能，并增强了视觉定位能力的同时维护了整体视觉理解。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11579", "html_url": "https://arxiv.org/abs/2503.11579", "title": "Vamba: 使用混合Mamba-Transformer理解一小时长视频", "title_en": "Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers", "authors": "Weiming Ren,Wentao Ma,Huan Yang,Cong Wei,Ge Zhang,Wenhu Chen", "background": "基于transformer的大规模多模态模型（LMMs）在处理一小时长的视频输入时面临挑战，因为因果自注意力操作具有二次复杂性，导致训练和推断时计算成本高昂。现有的基于token压缩的方法虽然减少了视频token的数量，但常常造成信息丢失，并且对于非常长的序列依然不够高效。", "innovation": "本文研究了构建结合Mamba-Transformer的混合模型（VAMBA）的新途径。VAMBA使用Mamba-2块以线性复杂度编码视频token，而不进行任何token的压缩。这种模型在单张GPU上可以编码超过1024帧（分辨率为640x360）的视频输入，而基于transformer的模型仅能编码256帧。在处理长视频时，VAMBA相较于基于transformer的大规模多模态模型，训练和推断时的GPU内存使用量减少至少50%，单步训练速度提升近一倍。实验结果表明，VAMBA在挑战性的长视频理解基准LVBench上将准确率提高了4.3%，并且在广泛的长视频和短视频理解任务上保持较强的性能。", "conclusion": "VAMBA通过减少GPU内存使用并提升处理速度，证明了它在处理长视频理解任务上的有效性，相比之前的高效视频LMMs，取得了显著的性能提高。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22526", "html_url": "https://arxiv.org/abs/2503.22526", "title": "AnnoPage 数据集：具有精细分类的文档中非文本元素数据集", "title_en": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization", "authors": "Martin Kišš,Michal Hradiš,Martina Dvořáková,Václav Jiroušek,Filip Kersch", "background": "研究文档布局分析和物体检测需要高质量的数据集作为支持。现有的数据集可能缺乏覆盖广泛历史时期的文档，尤其是包含丰富非文本元素的文档。已有数据集通常未针对特定的历史时期或非文本元素进行详细标注，这限制了研究的全面性和准确性。", "innovation": "该研究引入了AnnoPage数据集，这是一个由7,550页历史文档组成的新颖集合，主要包含捷克语和德语文本，时间跨度从1485年至今，尤其是19世纪末和20世纪初。每个页面都标注了轴对齐的边界框（AABB），表示25类非文本元素，如图像、地图、装饰元素或图表。这些标注遵循了捷克图像文件处理方法，确保了标注的准确性和一致性。此外，该数据集综合了来自多个历史文档的数据集，以增强多样性和连续性，提供了能够应用于实际研究的基础数据。", "conclusion": "AnnoPage数据集被划分为开发集和测试集，测试集选择时特别注意保持类别分布的平衡。研究还提供了使用YOLO和DETR物体检测器的基准结果，为未来的研究提供了参考。AnnoPage数据集已公开发布在Zenodo上，包括用于验证的真值标注。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.01048", "html_url": "https://arxiv.org/abs/2504.01048", "title": "如何在文档理解中影响视觉语言模型的水印化？", "title_en": "How does Watermarking Affect Visual Language Models in Document Understanding?", "authors": "Chunxue Xu,Yiwei Wang,Bryan Hooi,Yujun Cai,Songze Li", "background": "视觉语言模型（VLMs）已成为文档理解任务的基础模型，在处理跨金融、法律和学术等领域的复杂多模态文档方面得到了广泛应用。然而，文档中通常包含水印等干扰信息，这不可避免地引发了疑问：水印是否会影响VLMs在文档理解中的性能？本文探讨了水印对VLMs性能的影响，并揭示了水印对性能的负面影响，包括水印在文档中的分布方式和内容差异等因素。实验结果显示，VLMs的性能在水印存在的情况下可能会显著下降，降幅最高可达36%。我们发现散布的水印比集中的水印对性能影响更大，并且水印中的语义内容比简单的视觉遮挡对性能的干扰更大。通过分析注意力机制和嵌入相似性，我们发现性能下降主要是由于水印1）强制注意力广泛重分布，2）改变在嵌入空间中的语义表示。这项研究不仅突显了部署VLMs用于文档理解时的重大挑战，还为开发对水印化文档具有鲁棒性推理机制提供了视角和思路。", "innovation": "本文提出了一种新的评估框架来研究可见水印对VLMs性能的影响，考虑了不同类型文档数据、水印在文档中的位置和水印内容的变化等因素。通过实验验证了水印对文档理解性能的显著影响，尤其是在语义内容和注意力机制角度上，揭示了水印如何破坏模型的性能并提供优化方法。", "conclusion": "我们的研究突显了在文档理解中部署VLMs的重大挑战，并为开发对水印化文档具有鲁棒性推理机制提供了见解。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06852", "html_url": "https://arxiv.org/abs/2506.06852", "title": "位置预测自监督学习在多模态卫星影像语义分割中的应用", "title_en": "Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation", "authors": "John Waithaka,Moise Busogi", "background": "卫星影像的语义分割对于地球观测应用至关重要，但在有限标注训练数据的限制下仍面临挑战。尽管像掩码自编码器（MAE）这样的自我监督预训练方法已经显示出潜力，但它们主要侧重于重建而非定位，后者是分割任务中的基本方面。", "innovation": "我们提出将LOCA（位置感知）自监督学习方法适应于多模态卫星影像语义分割。该方法通过扩展SatMAE的通道分组，从多光谱数据扩展到多模态数据，使它能够有效处理多种模态，并引入同一组注意力掩码，以鼓励预训练期间的跨模态交互。此外，这种方法使用相对块位置预测，促进局部化所需的空间推理，而不是重建。", "conclusion": "我们在Sen1Floods11洪水映射数据集上评估了我们的方法，结果显示它在卫星影像语义分割任务中显著优于现有的基于重建的自我监督学习方法。我们的结果表明，适当适应多模态卫星影像的位置预测任务将学习到比基于重建的方法更有效的影像语义分割表示。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.09092", "html_url": "https://arxiv.org/abs/2505.09092", "title": "OpenLKA：在真实驾驶条件下来自最新汽车型号的车道保持辅助数据集", "title_en": "OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions", "authors": "Yuhang Wang,Abdulaziz Alhuraish,Shengming Yuan,Hao Zhou", "background": "车道保持辅助（LKA）功能在现代车辆中被广泛采用，但由于其专有系统和有限的数据访问权限，其实际性能仍鲜有被探究。OpenLKA是首个开源的大规模LKA评估和改进数据集，其中包括了来自62种生产车辆型号的持续400小时的驾驶数据，这些数据在佛罗里达州坦帕市及全球驾驶社区的贡献下，全面覆盖了复杂道路几何、路标模糊、恶劣天气、光照条件以及周围交通等多种挑战性场景。", "innovation": "OpenLKA包含多种数据类型，涵盖了全CAN总线流、同步高分辨率仪表板摄像视频、实时感知数据以及来自视觉语言模型生成的增强场景注释等。它通过整合车辆内部信号、高保真感知和丰富语义上下文来构建全面的平台，用于评估生产LKA系统的实际性能，识别关键安全操作场景，并评估当前道路基础设施对自动驾驶的准备程度。", "conclusion": "OpenLKA提供了一个全面的平台，用于评估生产和自动驾驶车辆中的LKA性能，识别关键的安全操作场景，并评估当前道路基础设施对自动驾驶的适应程度。数据集已经在网址：this https URL上免费提供。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11493", "html_url": "https://arxiv.org/abs/2505.11493", "title": "GIE-Bench: 向基于地面实测的文本引导图像编辑评估迈进", "title_en": "GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing", "authors": "Yusu Qian,Jiasen Lu,Tsu-Jui Fu,Xinze Wang,Chen Chen,Yinfei Yang,Wenze Hu,Zhe Gan", "background": "使用自然语言指令编辑图像已成为一种直观且表达方式多样的方式来修改视觉内容。然而，评估此类模型的表现仍然具有挑战性。现有的评估方法经常依赖于如CLIP等图像-文本相似性度量，这些度量缺乏精确性。", "innovation": "本文引入了一个新的基准评估框架，用于更现实地评估文本引导的图像编辑模型，通过两个关键维度：（i）通过生成的多项选择题自动评估功能正确性，检查是否成功应用了所需的变化；（ii）运用对象感知的遮罩技术确保非目标区域的图像内容一致性，并进行保存评分。基准数据集包括涉及20多个不同内容类别的超过1000个高质量的编辑示例，每个示例均附有详细的编辑说明、评估问题和空间对象遮罩。", "conclusion": "在大规模研究中，GPT-Image-1与多个最新编辑模型进行比较，我们的自动评估指标与人类评价进行了验证。结果表明，GPT-Image-1在遵循指令的准确性方面领先，但往往过度修改无关图像区域，揭示了当前模型行为中的关键权衡。GIE-Bench提供了一个可扩展且可重复的框架，用于推动更准确的文本引导图像编辑评估。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17791", "html_url": "https://arxiv.org/abs/2504.17791", "title": "LiDPM：重新思考点扩散以实现激光雷达场景完成", "title_en": "LiDPM: Rethinking Point Diffusion for Lidar Scene Completion", "authors": "Tetiana Martyniuk,Gilles Puy,Alexandre Boulch,Renaud Marlet,Raoul de Charette", "background": "训练能够在大规模户外场景上直接处理LiDAR点云的扩散模型具有挑战性，因为难以从宽视野的白噪音生成精细的细节。最近有关使用扩散模型进行场景补全的工作通过将原始的DDPM重新定义为局部扩散过程来解决这一问题，与通常在物体级别操作的普通DDPM不同。本研究旨在弥合这两类方法间的差距。", "innovation": "研究识别了局部扩散公式中的近似，表明这些近似并非用于在场景级别上运行所必需，并且一个恰当起点的选择足以进行补全任务。研究提出了一种模型LiDPM，通过实验证明相比于原有的方法，它在SemanticKITTI上的场景补全结果更好。", "conclusion": "本工作表明，使用经过适当起点初始化的标准DDPM模型LiDPM足以在大规模场景上完成LiDAR补全任务，并且在SemanticKITTI数据集上的结果表明了这一方法的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.07530", "html_url": "https://arxiv.org/abs/2505.07530", "title": "FLUXSynID：一种用于生成具有文档和实时图像的身份控制合成面部数据的框架", "title_en": "FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images", "authors": "Raul Ismayilov,Dzemila Sero,Luuk Spreeuwers", "background": "合成面部数据集在克服现实世界生物特征数据的限制方面越来越受到关注，这些限制包括隐私问题、人口统计不平衡以及高收集成本。然而，许多现有方法缺乏对身份属性的精细控制，并且在结构化采集条件下无法生成身份一致的配对图像。", "innovation": "我们引入了FLUXSynID框架，用于生成高分辨率的合成面部数据集，并包含14,889个合成身份的数据集。该框架可生成具有用户定义的身份属性分布的合成面部，提供文档样式和可信的实时采集图像。利用FLUXSynID框架生成的数据集与现实世界的身份分布有更好的对齐，并具有比以往工作更高的跨类多样性。", "conclusion": "我们的工作旨在支持包括面部识别和模拟攻击检测在内的生物特征研究，该工作已公开发布以帮助研究人员。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03194", "html_url": "https://arxiv.org/abs/2506.03194", "title": "HueManity: 探测 MLLMs 细粒度的视觉感知", "title_en": "HueManity: Probing Fine-Grained Visual Perception in MLLMs", "authors": "Rynaa Grover,Jayant Sravan Tamarapalli,Sahiti Yerramilli,Nilay Pande", "background": "目前，多模态大语言模型（MLLMs）在高层次的视觉推理中表现出色，但在处理精细的感知任务上仍然受到显著限制。研究人员指出，尽管这些模型在高级视觉理解上具有优势，但在具体且复杂的视觉识别任务上表现仍然不足。因此，需要构建新的基准来评估 MLLMs 的视觉感知能力，尤其是那些涉及到精细辨识的任务。", "innovation": "本文提出了 HueManity 作为用于评估 MLLMs 视觉感知能力的一个新基准。HueManity 包含由 Ishihara 测试样式的点图嵌入的双字符字母数字字符串的 83,850 张图片，对模型的职业观形能力构成了挑战。评估结果显示，最先进的九种 MLLMs 在 HueManity 上的表现远低于人类和传统的计算机视觉模型。这一结果传递了一个关键信息，目前的 MLLMs 在视觉能力上存在显著差距。此外，研究还探讨了可能的结构和训练范式因素，这些因素可能导致 MLLMs 在感知能力上的限制。最后，开源了 HueManity 数据集和代码，以促进 MLLMs 视觉稳健性的进一步研究。", "conclusion": "研究结果突显了当前 MLLMs 在视觉能力上的关键差距，提出了 HueManity 这一新的基准，并通过分析可能的因素探讨了 MLLMs 在视觉感知任务上的挑战。开源 HueManity 数据集和代码，旨在激励更多研究以提升 MLLMs 的感知鲁棒性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03976", "html_url": "https://arxiv.org/abs/2507.03976", "title": "基于照明过渡的鲁棒低光场景恢复", "title_en": "Robust Low-light Scene Restoration via Illumination Transition", "authors": "Ze Li,Feng Zhang,Xiatian Zhu,Meng Zhang,Yanghong Zhou,P. Y. Mok", "background": "从低光多视角图像中合成正常光条件下的新颖视图是一项重要但具有挑战性的任务，因为输入图像中的低可见性和高ISO噪声会使现有方法难以有效前处理这些低光输入，现有方法往往忽略了多视角之间的相关性。尽管其他最先进的方法引入了照明相关的组件来解决这些问题，但它们经常会导致色彩失真和伪像，提供有限的去噪效果。", "innovation": "提出了一个新的鲁棒低光场景恢复框架（RoSe），通过构建一个光线与正常光线条件之间的鲁棒性连接，将任务形成为三维空间中的照度过渡估计问题，并将其概念化为一种特定的渲染任务。进一步利用照明的固有低秩特性约束过渡表示，实现了有效的去噪，而无需复杂的二维技术或显式噪声建模。", "conclusion": "实验结果显示，RoSe在标准基准测试中的渲染质量和多视角一致性方面显著优于最先进的模型。代码和数据可在提供的链接处获取。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03564", "html_url": "https://arxiv.org/abs/2507.03564", "title": "2.5D 物体检测用于智能路边基础设施", "title_en": "2.5D Object Detection for Intelligent Roadside Infrastructure", "authors": "Nikolai Polley,Yacin Boualili,Ferdinand Mütsch,Maximilian Zipfl,Tobias Fleck,J. Marius Zöllner", "background": "自主车辆的车载传感器可能因障碍物、遮挡或视野受限而受到干扰，这使得车辆在行驶过程中难以做出准确的决策。传统的智能路边基础设施通过高架视角提供广阔的无遮挡交叉覆盖范围，通过车与万物（V2X）通信为自主车辆提供补充信息流。然而，常用的3D物体检测算法在处理从上方视角和陡峭相机角度引入的领域转变时难以泛化。", "innovation": "文章引入了一种专为安装在路边的基础设施摄像头设计的2.5D物体检测框架。不同于传统的二维或三维物体检测方法，该框架采用预测方法，检测车辆的地面平面作为图像框架中的平行四边形。这种方法保留了物体的平面位置、大小和方向，但省去了不必要的高度信息。为了训练模型，使用了现实世界和合成生成的场景的混合集。在不同的相机视角和训练集中未出现的恶劣天气条件下进行了泛化评估。", "conclusion": "结果表明，该模型具有较高的检测准确性、强大的视角间泛化能力和对各种光照和天气条件的鲁棒性。模型权重与推理代码可通过此 https URL 获取。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21444", "html_url": "https://arxiv.org/abs/2506.21444", "title": "跨数据集评估用于异常与正常有丝分裂分类的深度学习和视觉基础模型基准", "title_en": "Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation", "authors": "Sweta Banerjee,Viktoria Weiss,Taryn A. Donovan,Rutger H.J. Fick,Thomas Conrad,Jonas Ammeling,Nils Porsche,Robert Klopfleisch,Christopher Kaltenecker,Katharina Breininger,Marc Aubreville,Christof A. Bertram", "background": "不典型的有丝分裂标志着细胞分裂过程中的偏差，已被证明是肿瘤恶性程度的独立预后标志。然而，不典型有丝分裂的分类由于其低发病率、时有微妙的形态差异、病理学家间诊断的一致性低以及数据集中的类别不平衡，仍然是一个挑战。在乳腺癌不典型有丝分裂数据集(AMi-Br)的基础上，本研究对比了深度学习方法在自动不典型有丝分裂图分类中的表现，包括端到端训练的深度学习模型、带有线性探针的基础模型和低秩适应（LoRA）微调的基础模型。", "innovation": "研究引入了两个新的不典型有丝分裂数据集——AtNorM-Br和AtNorM-MD，用于跨数据集评估。研究对比了不同的深度学习和基础模型方法，包括端到端训练模型、带有线性探针的基础模型和使用低秩适应（LoRA）微调的基础模型。结果显示，通过最近的迁移学习和模型微调技术，不典型有丝分裂图分类可以有效地解决，尤其是在域内和域外数据集上的表现良好。", "conclusion": "研究证明了通过采用先进的迁移学习和模型微调技术，可以有效地解决不典型有丝分裂图分类问题。同时，研究提供了代码和数据，提高了研究的透明度和可复现性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21316", "html_url": "https://arxiv.org/abs/2506.21316", "title": "DRISHTIKON：在文档中实现多粒度视觉定位", "title_en": "DRISHTIKON: Visual Grounding at Multiple Granularities in Documents", "authors": "Badri Vishal Kasuba,Parag Chaudhuri,Ganesh Ramakrishnan", "background": "文档图像中的视觉定位是一个关键但尚未充分探索的挑战，特别是在文档智能和视觉问答（VQA）系统中。现有的系统在处理多语言复杂文档时，尤其难以实现准确的视觉定位。为解决这一问题，该论文提出了DRISHTIKON，这是一个多粒度和多块视觉定位框架，旨在提高复杂多语言文档的VQA系统的可解释性和可信度。该框架结合了多语言OCR、大型语言模型以及一个新的区域匹配算法，能够在块、行、词和点等多个粒度级别定位答案区间。", "innovation": "该论文创新性的提出了一个称为DRISHTIKON的多粒度和多块视觉定位框架。该框架在多语言OCR、大型语言模型和新型区域匹配算法的基础上，实现了在文档中多粒度级别的视觉定位，包括块、行、词和点级别。该框架还引入了一个名为Multi-Granular Visual Grounding (MGVG)的基准测试集，包含来自不同行业的具有细粒度和人工验证标签的多样化循环通知，展示了比现有方法更高的准确性和更好的平衡精确性和召回率。研究表明，多块和多行推理对精确定位具有显著优势。DRISHTIKON框架还提供了代码和数据集，使得未来研究者的进一步研究和扩展成为可能。", "conclusion": "本文的研究成果为具备多粒度视觉支持的更健壮和可解释的文档理解系统铺平了道路，特别是在真实世界、以文本为中心的情境下。通过一系列实验证明，现有的视觉-语言模型在精确定位方面存在不足，而DRISHTIKON则采用了结构化的对齐方法，显著提高了VQA系统的精度。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08492", "html_url": "https://arxiv.org/abs/2507.08492", "title": "基于双维度几何表示学习的文档纠偏", "title_en": "Dual Dimensions Geometric Representation Learning Based Document Dewarping", "authors": "Heng Li,Qingcai Chen,Xiangping Wu", "background": "文档图像纠偏在深度学习时代仍是一项具有挑战性的任务。现有方法通过利用文本行的意识有所改进，但通常仅聚焦于单一的水平维度。因此，仍需要提出一种能同时关注文档水平和垂直线条双维度的模型，以改善文档纠偏效果。", "innovation": "本文提出了一种精细的变形感知模型——D2Dewarp，它专注于文档的水平和垂直线条，以改进文档纠偏。该模型能够在文档细节的不同方向感知失真的趋势。为了组合水平和垂直粒度特征，设计了一种基于X和Y坐标的有效融合模块，以促进两者之间的相互作用与约束，增强特征互补性。此外，由于当前公共纠偏数据集缺乏标注的线特征，本文还提出了一种利用公共文档纹理图像的自动精细标注方法和自动图形渲染引擎，构建了一个新的大规模失真训练数据集。", "conclusion": "在公开的中文和英语基准测试中，无论是定量还是定性的结果都表明，本方法的纠偏结果优于当前最先进的方法。数据集将公开发布，链接为：[this https URL]。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.15426", "html_url": "https://arxiv.org/abs/2503.15426", "title": "基于视觉位置提示的MLLM视觉定位", "title_en": "Visual Position Prompt for MLLM based Visual Grounding", "authors": "Wei Tang,Yanpeng Sun,Qinying Gu,Zechao Li", "background": "尽管多模态大型语言模型（MLLMs）在各种图像相关任务中表现出色，但在精确对准图像中的坐标的方面存在挑战，特别是在视觉定位等需要位置敏感的任务中。这种限制源于两个主要因素：一是MLLMs缺乏明确的空间参考，使文本描述与精确的图像位置难以关联；二是MLLMs的特征提取过程侧重于全局背景而忽视了细微的空间细节，导致其弱的定位能力。因此，为解决这些问题，这篇论文提出了一种增强型的MLLM——VPP-LLaVA，通过引入视觉位置提示（VPP）来提升其视觉定位能力。VPP-LLaVA通过两种互补机制实现：全局VPP在输入图像上叠加一个可学习的轴向张量，提供结构化空间线索；局部VPP加入位置感知查询，支持细致入微的效果。", "innovation": "本文提出了VPP-LLaVA，一种结合视觉位置提示的增强型MLLM。VPP-LLaVA通过在输入图像上叠加轴向张量的全局VPP和加入位置感知查询的局部VPP，分别提供了结构化空间线索和细致的定位支持。此外，还提出了一个名为VPP-SFT的数据集，包含大约60万高质量的视觉定位样本，用于有效地训练模型并提高性能。该数据集较小，但提供了显著的性能提升，相比其他MLLM使用的数据集（例如，MiniGPT-v2的约210万样本）更为紧凑。", "conclusion": "所提出的VPP-LLaVA在标准的视觉定位基准测试中达到了最先进的结果，并且展示了在遇到挑战性的未见数据集时强大的零样本泛化能力。该模型的代码和数据集可在所提供的链接中获得。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.10432", "html_url": "https://arxiv.org/abs/2507.10432", "title": "基于语义约束的文本-视觉图像质量评估", "title_en": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment", "authors": "Qiang Li,Qingsen Yan,Haojian Huang,Peng Wu,Haokui Zhang,Yanning Zhang", "background": "随着人工智能生成图像（AGI）技术的快速发展，准确评估其质量的需求变得越来越重要。现有方法通常依赖跨模态模型如CLIP或BLIP来评估文本-图像对齐以及视觉质量，但在应用于AGI时，这些方法面临两个主要挑战：语义对齐失真和细节感知缺失。", "innovation": "本文提出了一种名为Text-Visual Semantic Constrained AI-Generated Image Quality Assessment（SC-AGIQA）的统一框架，它利用文本-视觉语义约束来显著提升对于AI生成图像的文字-图像一致性及感知失真综合评估的能力。该方法引入了两个核心模块：文本辅助语义对齐模块（TSAM），使用多模态大型语言模型（MLLMs）通过生成图像描述并与其原始提示进行对比来细化一致性检查；以及基于频域的细粒度退化感知模块（FFDPM），通过结合频域分析和感知敏感度加权来更好地量化细微的视觉失真，从而更好地捕捉图像中的细粒度视觉质量细节。", "conclusion": "在多个基准数据集上的大量实验表明，SC-AGIQA在图像质量评估方面优于现有最先进的方法。代码已公开发布。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09953", "html_url": "https://arxiv.org/abs/2507.09953", "title": "4D-MISR: 一种用于低剂量超分辨率成像的特征融合统一模型", "title_en": "4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion", "authors": "Zifei Wang,Zian Mao,Xiaoya He,Xi Huang,Haoran Zhang,Chun Cheng,Shufen Chu,Tingzheng Hou,Xiaoqin Zeng,Yujun Xie", "background": "电子显微镜提供了至关重要的原子分辨率洞察，用于结构-性能关系的研究，但其对辐射敏感的材料（如蛋白质和二维材料）的使用受到辐射损坏的严重限制。为了克服这个挑战，我们通过借鉴广泛应用于遥感领域的多图像超分辨率（MISR）原理，超越了传统电子显微镜的电子剂量极限。", "innovation": "我们开发了一种基于双路径、注意力引导的网络，用于4D-STEM，在超低剂量数据中实现了原子尺度的超分辨率重建。这种方法通过融合多个亚像素偏移的低分辨率视图，并利用卷积神经网络（CNN）整合来自多角度合成观察的特征信息，提供了对无定形、半晶体和晶体辐射敏感试样的鲁棒原子级可视化，系统评价表明，在超低剂量条件下其空间分辨率与常规 Ptychography 相当。", "conclusion": "我们的工作扩展了4D-STEM的能力，提供了一种新的、通用的方法来分析辐射易损材料的结构分析。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.00512", "html_url": "https://arxiv.org/abs/2505.00512", "title": "InterLoc: 基于道路分割的LiDAR交叉路口定位及其自动化评估方法", "title_en": "InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method", "authors": "Nguyen Hoang Khoi Tran,Julie Stephany Berrio,Mao Shan,Zhenxing Ming,Stewart Worrall", "background": "在线定位道路交叉路口对自动驾驶车辆的定位、制图和路径规划有益。交叉路口提供了强有力的地标，有助于纠正车辆姿态估计、在最新地图中锚定新传感器数据以及在道路网络图中引导车辆行驶。尽管交叉路口定位的重要性不容忽视，但该领域尚未得到广泛研究。现有方法要么忽视了车辆上已计算的丰富语义信息，要么依赖于稀缺的手标注交叉路口数据集。", "innovation": "本文提出了一个新的基于LiDAR的道路交叉路口在线车辆中心定位方法。该方法首先在将一系列语义道路扫描连接形成的鸟瞰图（BEV）表示中检测候选交叉路口，然后通过分析交叉道路分支并以最小二乘法形式调整交叉路口中心点来细化这些候选方案。为了评估该方法，引入了一个自动化评估管线，将定位的交叉路口点与OpenStreetMap中的交叉路口节点配对，使用精准的GNSS/INS地面真值姿态进行配对。实验结果显示，该方法在准确性和可靠性方面优于最新的基于学习的基线。", "conclusion": "敏感度测试证明了该方法对具有挑战性的分割错误的鲁棒性，并强调了其实际应用的适用性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11055", "html_url": "https://arxiv.org/abs/2507.11055", "title": "通过原型驱动语义近似缓解医学语言引导分割中的文本依赖", "title_en": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation", "authors": "Shuchang Ye,Usman Naseem,Mingyuan Meng,Jinman Kim", "background": "医学语言引导分割是一种通过结合文本临床报告辅助指导图像分割的方法，这种技术已经在单模态方法上展现出了显著的提高。然而，这种方法的使用通常需要配对的图像和文本输入，这存在两个基本限制：1）许多医学分割的数据集缺乏配对报告，导致大量只有图像的数据未被充分利用用于训练；2）其适用范围受到限制，只能用于回顾性分析配对报告的病例，而大多数临床场景中的分割通常在报告之前进行。", "innovation": "为了解决这些限制，本文提出了ProLearn框架，这是第一个基于原型驱动的学习框架，用于语言引导的分割，从根本上缓解了对文本的依赖。核心创新在于提出了一个新颖的原型驱动语义近似（PSA）模块，该模块用来近似文本输入中的语义引导。PSA通过从图像分割相关的文本报告中提炼出核心语义，初始化了一个离散且紧凑的原型空间。一旦初始化完成，它可以支持查询和响应机制，从而无文本输入下也能近似出语义指导，实现对文本依赖的缓解。实验表明，当仅有有限文本可用时，ProLearn相比现有最先进的语言引导的方法具有更高的性能优势。", "conclusion": "ProLearn通过引入新型的原型驱动语义近似模块，克服了医学语言引导分割中对文本依赖的局限性。该方法在QaTa-COV19、MosMedData+和Kvasir-SEG等多个数据集上实验验证了其优越性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05470", "html_url": "https://arxiv.org/abs/2505.05470", "title": "Flow-GRPO：通过在线强化学习训练流匹配模型", "title_en": "Flow-GRPO: Training Flow Matching Models via Online RL", "authors": "Jie Liu,Gongye Liu,Jiajun Liang,Yangguang Li,Jiaheng Liu,Xintao Wang,Pengfei Wan,Di Zhang,Wanli Ouyang", "background": "本文提出Flow-GRPO，这是一种将在线强化学习（RL）与流匹配模型相结合的方法。研究表明，现有的流匹配模型在处理复杂文本到图像任务时存在不足，特别是在生成复杂组合元素（如精确的物体计数、空间关系和细粒度属性）时。传统的流匹配模型往往无法达到理想效果。因此，需要引入一种新的方法来改进这些模型的性能和效率。", "innovation": "本文的主要创新点在于引入了两种关键策略：（1）将确定性的常微分方程（ODE）转换为等价的随机微分方程（SDE），这使得在所有时间步骤中，SDE能够匹配原始模型的边缘分布，从而实现统计采样用于RL探索；（2）降噪减少策略，该策略减少了训练中的去噪步骤，但在保留原始推理时间步骤数量的同时显著提高了采样效率，没有性能下降。此外，Flow-GRPO在多个文本到图像任务中取得了成功，并在复杂的组合成分中，通过RL调整的SD3.5生成了近乎完美的物体计数、空间关系和细粒度属性，显著提升了GenEval准确性。并且，与传统方法相比，其在视觉文本渲染中的准确性也从59%提高到92%，显著提高了文本生成的效果。此外，这种方法在人类偏好对齐方面也取得了显著进展，几乎未发生奖励作弊现象。", "conclusion": "Flow-GRPO方法不仅能在多个文本到图像任务中提高性能，而且通过有效的策略设计提高了采样效率，同时保持了良好的图像质量和多样性，为流匹配模型的改进提供了新的思路。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06210", "html_url": "https://arxiv.org/abs/2507.06210", "title": "CultureCLIP: 通过合成图像和上下文化描述增强CLIP的文化意识", "title_en": "CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions", "authors": "Yuchen Huang,Zhiyuan Fan,Zhitao He,Sandeep Polisetty,Wenyan Li,Yi R. Fung", "background": "预训练的视觉-语言模型（VLMs）如CLIP在多模态理解和普遍情况下表现出色，但在捕捉细微且依赖于上下文的视觉线索时却常常遇到困难。这使得在具有不同文化含义的相似概念之间进行区分变得困难。这种缺陷主要是由于高质量的文化数据量有限、缺乏上下文信息以及缺乏突出微妙差异的负面样本所致。", "innovation": "为解决这一问题，本文设计了一个基于开源VLMs和绘图模型的数据整理管道，构建了CulTwin，这是一个合成文化数据集。CulTwin包含三元组的概念-描述-图像对，这些概念在视觉上相似但具有不同的文化含义。通过自定义对比学习，对CulTwin数据集进行微调以开发CultureCLIP，使文化概念与上下文增强的描述和合成图像对齐。", "conclusion": "实验结果表明，CultureCLIP在特定任务中实现了显著优于基础CLIP的表现，细粒度概念识别准确率提高了高达5.49％，同时还保留了CLIP原有的泛化能力，验证了我们的数据合成和VLM主干训练范式在捕捉微妙文化差异方面的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.16425", "html_url": "https://arxiv.org/abs/2412.16425", "title": "Patherea: 2020年代的细胞检测和分类", "title_en": "Patherea: Cell Detection and Classification for the 2020s", "authors": "Dejan Štepec,Maja Jerše,Snežana Đokić,Jera Jeruc,Nina Zidar,Danijel Skočaj", "background": "本文提出了Patherea，这是一个统一框架，用于基于点的细胞检测和分类，旨在简化和公平地评估当前最先进的方法。为此，他们引入了一个大规模数据集，该数据集模拟了Ki-67增殖指数估计的临床工作流程。现有的研究方法依赖于中间表示来预测细胞位置和类别，而Patherea直接进行预测，避免了这种依赖。", "innovation": "Patherea框架采用了一种混合匈牙利匹配策略，以准确分配点，并支持多种骨干网络和训练策略，包括最近的病理基础模型。它在公共数据集Lizard、BRCA-M2C和BCData上取得了最先进的性能，但在这些基准上表现出性能饱和。相反，Patherea数据集提供了更具挑战性的评估基准。此外，作者还指出了当前评估协议中的常见错误，并为标准化评估提供了更新的基准工具。", "conclusion": "Patherea数据集和代码已公开，以促进进一步研究和公平比较。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.05102", "html_url": "https://arxiv.org/abs/2404.05102", "title": "LHU-Net：一种简化的高效混合U-Net网络", "title_en": "LHU-Net: a Lean Hybrid U-Net for Cost-efficient, High-performance Volumetric Segmentation", "authors": "Yousef Sadegheih,Afshin Bozorgpour,Pratibha Kumari,Reza Azad,Dorit Merhof", "background": "Transformer架构在医学图像分割领域取得了显著进展，促使了结合卷积神经网络（CNNs）与Transformer的混合模型的诞生。然而，这些模型通常过于复杂，难以有效融合空间和通道特征，这对精准分割至关重要。", "innovation": "提出了一种名为LHU-Net的轻量级混合U-Net，它在空间特征提取后优化通道特征，同时优化了效率和精确度。LHU-Net在四个基准数据集（Synapse，Left Atrial，BraTS-Decathlon，和Lung-Decathlon）上表现优异，不论是在CT/MRI等不同模态还是在不同输出配置下，其 Dice分数均优于现有模型，而且参数和FLOPs数量低于竞争模型四倍和20%。LHU-Net无需额外的预训练、数据或模型组合即可实现高效高精度的体积分割。", "conclusion": "LHU-Net通过其简洁的设计和出色的性能，确立了在计算效率和分割精度上的新基准。我们的实现代码可在GitHub上获得。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06771", "html_url": "https://arxiv.org/abs/2412.06771", "title": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty", "title_en": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty", "authors": "Meera Hahn,Wenjun Zeng,Nithish Kannen,Rich Galt,Kartikeya Badola,Been Kim,Zi Wang", "background": "用户的生成式AI模型提示经常不明确，导致用户意图和模型理解之间产生偏差。这使得用户不得不反复精炼提示。本文在文本到图像（T2I）生成中研究了这一对齐问题，并提出了一种配备主动澄清问题接口的原型T2I代理。", "innovation": "提出了主动T2I代理的原型，该代理可以在不确定时主动询问澄清问题，并以可理解且可编辑的信念图形式呈现其对用户意图的不确定性。设计了一种新的可扩展且自动化的评估方法，使用两个代理：一个具有真实意图（图），另一个尽可能少地提问以与真实意图对齐。", "conclusion": "实验结果表明，提出的T2I代理能够提出更具信息性的问答以获取关键性信息，与标准T2I生成相比，VQAScore至少提高了2倍。此外，人类研究表明，至少90%的人类参与者认为这些代理及其信念图对他们的T2I工作流有帮助，突显了该方法的有效性。代码和DesignBench数据集可以在提供的链接处找到。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.15513", "html_url": "https://arxiv.org/abs/2411.15513", "title": "SPA: 在医学图像分割中高效对齐用户偏好以克服不确定性", "title_en": "SPA: Efficient User-Preference Alignment against Uncertainty in Medical Image Segmentation", "authors": "Jiayuan Zhu,Junde Wu,Cheng Ouyang,Konstantinos Kamnitsas,J. Alison Noble", "background": "医学图像分割数据固有地包含不确定性。这种不确定性可以来源于图像质量的不完美以及对模糊像素的标注偏好，这依赖于注释者的专业知识和注释的临床背景。例如，边界像素在诊断时可能被标记为肿瘤以避免低估严重性，在放射治疗时可能被标记为正常组织以防止对敏感结构的损害。分割偏好随着下游应用的不同而变化，因此希望图像分割模型能够提供用户可调节的预测，而不是固定的输出。尽管先前的研究提出了不确定性意识和交互式方法以提高适应性，但在测试时仍存在效率低下的问题：不确定性意识模型要求用户从多个相似输出中选择，而交互式模型则需要用户通过点击或框选提示来不断改进分割结果。", "innovation": "我们提出了一个新的分割偏好对齐框架\textbf{SPA}，该框架在最小的人机交互下，能够高效适应多样化的测试时间偏好。通过向用户展示能够最好地捕捉不确定性的少数几个分段候选人，\textbf{SPA}减少了用户的负担，以达到所需的分段结果。我们提出了一种概率机制，利用用户反馈来调整模型的分割偏好。该框架在多种医学图像分割任务中得到了评估，包括色度视网膜图像、肺部病变和肾脏CT扫描、脑部和前列腺的MRI扫描。实验结果表明，\textbf{SPA}相较于现有的交互式分割方法，显著减少了用户时间和精力，并且有很强的基于人类反馈的适应能力，同时在不同成像模态和语义标签下还实现了最佳的图像分割性能。", "conclusion": "\textbf{SPA}显著降低了与现有交互式分割方法相比的用户时间和精力消耗，展示了很强的人类反馈适应能力，并且在各种医学图像分割任务中实现了最先进的图像分割性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.15186", "html_url": "https://arxiv.org/abs/2502.15186", "title": "LUMINA-Net：基于多阶段光照和噪声适应网络的低光图像增强", "title_en": "LUMINA-Net: Low-light Upgrade through Multi-stage Illumination and Noise Adaptation Network for Image Enhancement", "authors": "Namrah Siddiqua,Kim Suneung,Seong-Whan Lee", "background": "低光照条件下的图像增强（LLIE）是计算机视觉中的一个重要任务，旨在改善在低照度条件下拍摄的图片的视觉保真度。传统方法通常难以克服噪声、曝光过度和颜色失真等问题，导致图像质量大幅下降。", "innovation": "本文提出了一种名为LUMINA-Net的无监督深度学习框架，通过集成多阶段光照和反射模块来学习低光照图像对的自适应先验。该网络利用自监督机制移除原始图像中不合适的功能，增强在Retinex分解方面的表现。同时，包括智能调整亮度和对比度以保留复杂的纹理细节的光照模块，以及利用空间注意和通道特征改善减少噪声的方法在内的反射模块，都旨在减轻噪声污染。实验结果表明，LUMINA-Net在LOL和SICE数据集上超越了现有的最先进方法，证明了其在低光图像增强中的有效性。", "conclusion": "LUMINA-Net在多项指标（如PSNR、SSIM和LPIPS）下的实验结果证明了其在低光图像增强方面的优越性能，展示了其作为一种先进框架的有效性和创新性。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05063", "html_url": "https://arxiv.org/abs/2503.05063", "title": "轻量级超复数MRI重建：一种通用的克罗内克参数化方法", "title_en": "Lightweight Hypercomplex MRI Reconstruction: A Generalized Kronecker-Parameterized Approach", "authors": "Haosen Zhang,Jiahao Huang,Yinzhe Wu,Congren Dai,Fanwen Wang,Zhenxuan Zhang,Guang Yang", "background": "MRI在临床诊断中至关重要，但由于扫描时间过长而受到阻碍。当前的深度学习模型虽然可以增强MRI重建，但通常内存消耗大，不适用于资源受限的系统。因此，需要一种轻量级的模型来处理这个问题，以减少参数并提高资源有限系统的效率。", "innovation": "本文提出了一种利用克罗内克参数化超复数神经网络的轻量级MRI重建模型。该模型通过整合基于克罗内克模块，包括克罗内克MLP、克罗内克窗口注意力和克罗内克卷积，高效提取空间特征同时保持表示能力。文中提出了克罗内克U-Net和克罗内克SwinMR，与现有模型相比参数减少了约50%，同时保持高重建质量。实验结果表明，即使在高加速因子（8x和16x）下，该模型也能在FastMRI数据集上表现出竞争性的PSNR、SSIM和LPIPS指标，且无显著性能下降。", "conclusion": "此外，克罗内克变种对数据集小的情况具有更好的泛化能力和较低的过拟合，有利于在硬件受限系统上实现高效的MRI重建。这种做法为参数高效的医疗成像模型设定了新标准。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.15590", "html_url": "https://arxiv.org/abs/2409.15590", "title": "MapEx: 基于全局地图预测的有概率信息增益的室内结构探索", "title_en": "MapEx: Indoor Structure Exploration with Probabilistic Information Gain from Global Map Predictions", "authors": "Cherie Ho,Seungchan Kim,Brady Moon,Aditya Parandekar,Narek Harutyunyan,Chen Wang,Katia Sycara,Graeme Best,Sebastian Scherer", "background": "机器人探索识别未知环境是一项关键挑战，尤其是在室内环境中。常规的探索方法如前沿方法往往难以利用空间的可预测性和重复模式，只依赖简单的启发式策略如‘最近优先’。最新的研究借助深度学习来预测未知地图区域，并利用预测信息来计算信息增益，但这些方法对预测图的质量敏感，或者不考虑传感器覆盖情况。", "innovation": "提出了一种新的探索框架MapEx，结合地图预测与机器人的观测信息来联合推理可观察区域及其不确定性，以估计信息增益。MapEx能够生成多个基于观测信息的预测地图，并综合考虑每个观测信息的方差以及估计的可见区域来评估备选视点的信息增益。实验证明，MapEx相比于基于地图预测的代表性探索方法提升了12.4%，对比最近的前沿方法提升了25.4%。", "conclusion": "MapEx通过联合推理观测和不确定性以提升信息增益的估计，有效解决了预测质量和传感器覆盖的问题，从而在实际数据集上表现出显著的性能提升。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2211.05622", "html_url": "https://arxiv.org/abs/2211.05622", "title": "InstantGroup: 快速生成脑MRI图像组配准的即时模板", "title_en": "InstantGroup: Instant Template Generation for Scalable Group of Brain MRI Registration", "authors": "Ziyi He,Albert C. S. Chung", "background": "图像分组配准中的模板生成是关键步骤，涉及将一组被试对齐到一个共同空间。现有方法虽然能够生成高质量的模板图像，但往往会带来较大的时间成本，或者受到固定组规模的限制。", "innovation": "本文提出了一种基于变分自编码器(VAE)模型的高效模板生成框架InstantGroup。该框架利用了潜在表示的算术特性，可实现任意大小组的扩展。InstantGroup还采用了一种双VAE骨干结构和共享权重的孪生网络来处理输入对，并引入了位移反演模块(DIM)来保持模板的无偏性，以及主题模板对齐模块(STAM)来提升模板质量和注册精度。", "conclusion": "实验结果表明，InstantGroup显著减少了运行时间，在不同时组规模下都能在几秒钟内生成模板，而在定量指标（如无偏性及注册精度）上保持了优于先进基线方法的性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.02718", "html_url": "https://arxiv.org/abs/2310.02718", "title": "通过广义逆理解全景增强", "title_en": "Understanding Pan-Sharpening via Generalized Inverse", "authors": "Shiqi Liu,Yihua Tan,Yutong Bai,Alan Yuille", "background": "全景增强算法结合了全景图像和多光谱图像，生成具有高空间分辨率和高光谱分辨率的图像。然而，这些算法的优化标准各不相同。文章通过简单的矩阵方程描述了全景增强问题，并探讨了解的存在条件及获取空间分辨率和光谱分辨率的方法。引入了下采样增强方法来提高空间和光谱下采样矩阵的估计。利用广义逆理论，发现了一种广义逆矩阵形式的解空间，对应于典型的两种全景增强方法：组件替换和多分辨率分析。文章展示了格拉姆-施密特自适应方法与广义逆矩阵形式下的组件替换一致。提出了广义逆矩阵的光谱函数先验模型，分析了理论误差。通过通用的广义逆形式解空间，自然地嵌入了扩散先验，有助于获取精细的全景增强结果。", "innovation": "文章通过简单的矩阵方程描述了全景增强问题，提出了下采样增强方法，利用广义逆理论发现了两种解空间，对应于两种主要的全景增强方法。提出了广义逆矩阵光谱函数的先验模型，通过扩散先验，提高了全景增强效果，并在合成和实际数据上进行了验证，显示出显著的改进效果。", "conclusion": "提出的广义逆矩阵理论加深了对全景增强机制的理解，下采样增强方法和扩散先验显著提高了全景增强的结果质量。该方法在几乎所有评估指标上均表现出优异性能。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.08677", "html_url": "https://arxiv.org/abs/2506.08677", "title": "MAMBO: 高分辨率生成方法用于乳腺X线摄影图像", "title_en": "MAMBO: High-Resolution Generative Approach for Mammography Images", "authors": "Milica Škipina,Nikola Jovišić,Nicola Dall'Asen,Vanja Švenda,Anil Osman Tur,Slobodan Ilić,Elisa Ricci,Dubravko Ćulibrk", "background": "乳腺X线摄影是乳腺癌检测和诊断的金标准。尽管AI技术可以显著增强这一过程，但训练AI系统需要大量和多样化的数据集，而这些数据集由于隐私和伦理问题往往难以获得。为此，论文介绍了一种名为MAMmography ensemBle mOdel (MAMBO)的新颖基于补丁的扩散方法，用于生成全分辨率的乳腺X线摄影图像。虽然扩散模型已经在现实图像生成方面取得了突破性成果，但很少有研究专门针对乳腺X线摄影图像，更没有生成满足细粒度特征捕捉要求的高分辨率输出。为此,MAMBO结合了独立的扩散模型，分别捕捉局部和全局上下文信息，进而显著促进了噪声去除过程，使其能够生成高达3840x3840像素的高分辨率乳腺X线摄影图像。重要的是，这种方法可用于增强乳腺X线摄影模型的训练，并扩展到异常分割中。", "innovation": "MAMBO结合了独立的扩散模型来捕捉局部和全局上下文信息，以生成高分辨率的全景乳腺X线摄影图像。该方法填补了现有研究空白，能够生成满足细粒度特征捕捉要求的高分辨率输出，有望增强乳腺X线摄影分析，实现更准确的诊断和更早的病灶检测，同时解决了隐私和伦理问题带来的数据获取难题，为相关研究提供了新的途径和可能。", "conclusion": "实验结果表明，MAMBO在图像生成、超分辨率和异常分割方面的表现优异，证实了其在乳腺X线摄影分析中的潜力，将有助于乳腺癌的更准确诊断和更早的发现。该研究的代码已公开。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11069", "html_url": "https://arxiv.org/abs/2507.11069", "title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update", "title_en": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update", "authors": "Jeongyun Kim,Seunghoon Jeong,Giseop Kim,Myung-Hwan Jeon,Eunji Jun,Ayoung Kim", "background": "从RGB图像中理解透明物体的3D几何结构具有挑战性，因为透明物体存在反射和折射等固有物理特性。在稀疏视角和动态环境等场景下尤其难以处理这些问题。", "innovation": " 소개한 TRAN-D是一种基于2D高斯斑点的全新深度重建方法，用于透明物体。我们的核心洞察力在于将透明物体与背景分离，使得对物体对应的高斯进行集中优化成为可能。我们通过一个对象感知的损失来缓解伪影，确保隐藏区域的覆盖，同时减少过拟合。此外，我们引入了基于物理的仿真，能够在几秒内细化重建，有效处理物体移除和剩余物体的连锁运动，无需重新扫描。", "conclusion": "在合成和真实世界的序列上评估TRAN-D，它在多个方面超过了现有的基于高斯斑点的先进方法。与基线相比，在合成的TRansPose序列中，TRAN-D的平均绝对误差减少了超过39%。即便仅使用一张图像更新，TRAN-D也达到了超过2.5 cm的48.46%准确率，是使用六张图像的基线准确率的一点五倍。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22027", "html_url": "https://arxiv.org/abs/2506.22027", "title": "基于光学和SAR图像的跨模态船舶再识别：一个新型数据集和方法", "title_en": "Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method", "authors": "Han Wang,Shengyang Li,Jian Yang,Yuxuan Liu,Yixuan Lv,Zhuang Zhou", "background": "遥感领域中，利用地球观测图像检测和跟踪地面目标仍是一项重大挑战。持续的海上船舶跟踪对海上搜救、执法和航运分析等领域至关重要。然而，当前船舶跟踪方法大多依赖于同步地球卫星或视频卫星。同步地球卫星的分辨率较低且受天气条件影响，而视频卫星的拍摄时长较短且覆盖范围有限，因此对于船舶跟踪的现实需求不太适用。为解决这些局限性，作者提出了一种由光学和合成孔径雷达（SAR）传感器组成的混合近地轨道星座，旨在评估使用光学和SAR传感器星座进行船舶跟踪的有效性。这种方法确保了更短的重拍周期并实现了全天候跟踪。该数据集包含在不同条件下长时间拍摄同一艘船的图像，使用不同时间和角度的不同卫星，以不同模式拍摄。", "innovation": "作者提出了一种新的数据集——混合光学和SAR传感器的HOSS ReID数据集，旨在评估低地轨道的光学和SAR传感器星座在船舶跟踪中的效果。此外，作者还提出了一种基于Vision Transformer的跨模态船舶再识别基线方法——TransOSS，该方法通过改进图像块嵌入结构、引入更多参考信息以及利用对比学习在大规模的光学-SAR图像对上进行预训练，以确保模型能够提取模态不变特征。", "conclusion": "作者的数据集和基线方法已经公开可用，为船舶跟踪领域的研究提供了新的数据支撑和方法参考。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.02572", "html_url": "https://arxiv.org/abs/2411.02572", "title": "ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy", "title_en": "ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy", "authors": "Kian Kenyon-Dean,Zitong Jerry Wang,John Urbanik,Konstantin Donhauser,Jason Hartford,Saber Saberian,Nil Sahin,Ihab Bendidi,Safiye Celik,Marta Fay,Juan Sebastian Rodriguez Vera,Imran S Haque,Oren Kraus", "background": "大规模细胞显微镜筛查在药物发现和分子生物学研究中被广泛用于研究数百万种化学和遗传干扰对细胞的影响。为了进行下游分析，我们需要能够将每张图像映射到一个能够一致地表示多种生物表型的特征空间的模型，即有相似生物效应的干扰应具有类似的表示。这篇文章介绍了一个名为ViTally Consistent的模型作为迄今为止最大的细胞显微镜数据基础模型，用于细胞显微镜图像的特征表示学习.", "innovation": "该工作开发了一个新的19亿参数的ViT-G/8 MAE模型，训练数据量超过80亿个显微镜图像样本。该模型相比之前发布的ViT-L/8 MAE模型，在遗传干扰的线性可分性上提高了60%，并且在全基因组生物关系回忆率和重复一致性基准测试上取得最佳的整体性能。此外，通过在精心策划的多样数据集上进行训练以及使用生物动机线性探测任务来搜索每个Transformer块的最佳候选表示，提高了性能。研究表明，自监督视觉Transformer预训练在自然或显微镜图像上，其中间层比通常使用的最终层能产生更为生物意义显著的表示.", "conclusion": "我们的方法和结果为建立大规模生物数据基础模型提供了通用策略，并提供了对成功构建此类模型的洞察。通过提高基础模型的代表性和可解释性，改进了细胞显微镜图像的特征表示学习方法和应用，并对于药物发现和分子生物学提供了新的工具和技术基础。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03034", "html_url": "https://arxiv.org/abs/2507.03034", "title": "重思生成式人工智能时代的数据保护", "title_en": "Rethinking Data Protection in the (Generative) Artificial Intelligence Era", "authors": "Yiming Li,Shuo Shao,Yu He,Junfeng Guo,Tianwei Zhang,Zhan Qin,Pin-Yu Chen,Michael Backes,Philip Torr,Dacheng Tao,Kui Ren", "background": "生成式人工智能（AI）时代的到来深刻地改变了数据的意义和价值。数据不再局限于静态内容，而是渗透到AI生命周期的每一个阶段，从塑造模型参数的训练样本到驱动实际模型部署的提示和输出。这一转变使得传统的数据保护观念不再足够，同时也模糊了需要保护的边界。因此，确保AI系统中的数据安全变得至关重要。", "innovation": "本文提出了一个四级分类体系，包括不可用性、隐私保护、可追溯性和可删除性，覆盖了现代生成式AI模型及系统带来的各种保护需求。此外，框架还跨越了整个AI流水线，包括训练数据集、模型权重、系统提示以及AI生成内容，分析了每个层次的代表性技术方法，并揭示了监管缺口，强调了重新思考现代AI技术的数据保护的紧迫性，为开发者、研究人员和监管机构提供了及时的指导。", "conclusion": "通过提供一个结构化的视角，使未来AI技术和治理与可信数据实践相一致，本文强调了重新考虑现代AI技术数据保护的紧迫性，并为开发者、研究人员和监管机构提供了及时的指导。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11570", "html_url": "https://arxiv.org/abs/2507.11570", "title": "SurgeryLSTM：一种用于脊柱手术后精确可解释住院时间预测的时间意识神经模型", "title_en": "SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery", "authors": "Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng", "background": "本研究旨在开发和评估机器学习模型以预测择期脊柱手术的住院时间（LOS），重点关注时间建模和模型可解释性的优势。研究重点在于通过电子健康记录（EHR）数据构建和比较传统的机器学习模型（如线性回归、随机森林、支持向量机和XGBoost）与一种新开发的模型SurgeryLSTM。后者结合了掩码双向长短期记忆（BiLSTM）的时序建模能力和注意力机制，增强了模型的可解释性，使其能够捕捉患者数据的序列特性并提高预测准确性。研究的目的还在于识别关键预测因子并提升临床应用的可采纳性。研究表明，时间建模通过捕捉患者数据的序列特征显著提高了LOS的预测性能，而SurgeryLSTM模型不仅准确而且具有较高的解释性，这对于临床应用至关重要。研究结果强调了将基于注意力的时间模型整合到医院规划工作流程中的潜力。", "innovation": "创新点在于开发了一种名为SurgeryLSTM的时间意识神经模型，它结合了掩码双向长短期记忆模型和注意力机制。相比于传统的机器学习模型，SurgeryLSTM不仅预测准确性更高（R2=0.86），而且能够通过注意力机制提升模型的可解释性，动态识别关键的时序段，从而更直观地展现哪些时间序列中的事件或特征对LOS预测有显著贡献。研究区分了骨疾病、慢性肾病和腰椎融合等关键预测因子，突显了模型对临床决策支持的重要性，为提高出院准备度和个性化患者护理提供了解决方案。", "conclusion": "SurgeryLSTM提供了一种有效且可解释的人工智能解决方案，用于择期脊柱手术的住院时间预测。研究结果支持将基于时间、可解释的机器学习方法整合到临床决策支持系统中，以增强出院准备度和个性化患者护理。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00785", "html_url": "https://arxiv.org/abs/2506.00785", "title": "GeoChain：面向地理推理的多模态链式思考", "title_en": "GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning", "authors": "Sahiti Yerramilli,Nilay Pande,Rynaa Grover,Jayant Sravan Tamarapalli", "background": "本文介绍了GeoChain，这是一个大规模基准测试，用于评估多模态大语言模型（MLLMs）在地理推理方面的步步递进式推理能力。该基准测试利用了146万张Mapillary街景图，并将每张图像与一个包含21步思维链（CoT）的问题序列配对，总共涉及3000多万个问答对。这些问题序列引导模型从粗略属性到精细的空间定位，涉及视觉、空间、文化及精确地理位置四个推理类别，并按难度进行标注。图像还进行了语义分割（150类）和视觉可定位性评分的增强。", "innovation": "GeoChain提供了多模态大语言模型在地理推理领域上的挑战性基准测试。它不仅涉及详细的推理链，还结合了难度标注与语义分割，使模型能够逐步从粗略属性过渡到精确的空间定位。通过在不同复杂度层次上的广泛应用，GeoChain可作为关键工具，推动多模态大语言模型在复杂地理推理方面的显著进步。", "conclusion": "对当前的多模态大语言模型（如GPT-4.1变体、Claude 3.7和Gemini 2.5变体）进行基准测试，结果揭示了一系列一致的难题：模型在视觉接地方面经常表现出弱点，表现出不稳定的推理，并且在复杂性增加时难以实现准确的空间定位。GeoChain提供了一种强大的诊断方法，对于推动多模态大语言模型在复杂地理推理领域的显著进步至关重要。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11547", "html_url": "https://arxiv.org/abs/2507.11547", "title": "基于循环U-Net的图神经网络（RUGNN）在片材材料成形中准确变形预测", "title_en": "Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming", "authors": "Yingxue Zhao,Qianyi Chen,Haoran Li,Haosu Zhou,Hamid Reza Attar,Tobias Pfaff,Tailin Wu,Nan Li", "background": "近年来，基于人工智能的代理模型被提出以快速预测材料成形过程的可制造性。然而，传统的基于标量或图像的神经网络构建的人工智能代理模型在捕捉复杂的3D空间关系和操作方面有限，并且无法处理置换不变性质。为克服这些问题，新兴的基于图的代理模型使用图神经网络开发。这些模型在多个成形时间步长中实现了片材材料变形场的准确预测。RUGNN模型集成了门控递归单元（GRUs）来建模时间动态，并借鉴了U-Net的图基下采样/上采样机制来处理空间的长程依赖性。此外，提出了一种新颖的'节点至表面'接触表示方法，显著提高了大规模接触交互的计算效率。RUGNN模型通过冷成形案例研究和更复杂的铝合金热成形案例研究进行了验证，结果显示，RUGNN模型提供了准确的变形预测，接近真实的有限元模拟结果，并且在几个基线GNN架构中表现出色。模型调优还展示了合适的超参数、训练策略和输入特征表示。这些结果证明RUGNN是一个可靠的方法，可支持片材材料成形设计，通过实现准确的可制造性预测。", "innovation": "该研究开发了一种新的图神经网络代理模型——基于循环U-Net的图神经网络（RUGNN）。关键创新点在于：1) 综合使用了Gated Recurrent Units (GRUs)来建模时间动态；2) 使用了灵感来源于U-Net的图基下采样/上采样机制来处理空间长程依赖性；3) 提出了新颖的'节点至表面'接触表示方法，提高了大规模接触交互的计算效率。这些创新使得RUGNN在成形过程中的片材材料变形预测中表现优异。", "conclusion": "RUGNN模型在片材材料成形过程中提供了准确的变形预测，其结果接近真实的有限元模拟，并且优于多个基线GNN架构。通过调优模型参数和特征表示，进一步确认了其在预测准确性和可靠性方面的优势，证明了RUGNN是一个可靠的支持片材材料成形设计的方法。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05935", "html_url": "https://arxiv.org/abs/2506.05935", "title": "SurGSplat: 经几何约束渐进高斯点云法在手术场景重建中的应用", "title_en": "SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction", "authors": "Yuchao Zheng,Jianing Zhang,Guochen Ning,Hongen Liao", "background": "术中导航高度依赖精确的3D重建以确保手术过程中的准确性和安全性。然而，内窥镜场景带来了独特挑战，如特征稀疏和非一致性光照，导致许多现有的基于Structure-from-Motion (SfM) 方法无法有效重建。这使得基于SfM的方法在内窥镜手术导航中难以实现有效的3D重建。", "innovation": "本文提出SurGSplat，这是一种新的以几何约束为基础的3D高斯点云聚集方法，通过几何约束的集成逐步细化3D高斯点云法。SurGSplat能够在内窥镜场景中详细重建血管结构和其他关键特征，提高术者的视觉清晰度，优化了术中的实时决策。", "conclusion": "实验结果显示，SurGSplat在新视点合成（NVS）和姿态估计准确性方面表现优越，证明其是一种高保真且高效的手术场景重建解决方案。更多详细信息和结果请访问this https URL."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11645", "html_url": "https://arxiv.org/abs/2507.11645", "title": "追踪从掌握到理解的路径：嵌入、Dropout和网络激活", "title_en": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation", "authors": "Ahmed Salah,David Yevick", "background": "该论文探讨了神经网络中延迟泛化的现象，即测试准确率的提升会在训练准确率提升之后才有所显现。通过研究神经网络的丢弃鲁棒性曲线、嵌入相似性、稀疏性度量以及活性神经元的变化等指标，可以预测并理解这种延迟泛化现象的具体表现和缘由。", "innovation": "论文提出了几种新的实际度量指标来预测延迟泛化行为，包括丢弃下的测试准确率变化的方差、鲁棒性、嵌入相似性和稀疏性度量。特别是通过丢弃鲁棒性曲线（DRC）来估计神经网络在从记忆过渡到泛化时在推理期间对噪声的鲁棒性。此外，活性神经元的数量在泛化过程中减少，而嵌入逐渐趋于一种与初始情况无关的双模分布，这种分布与观测到的余弦相似模式和数据集的对称性相吻合。这些指标为理解延迟泛化的根源和行为提供了有价值的见解。", "conclusion": "这些新的度量指标不仅有助于捕捉和描述延迟泛化的具体特征，还揭示了延迟泛化行为背后的潜在机制，提供了深入理解表层学习和深层学习的新窗口。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11589", "html_url": "https://arxiv.org/abs/2507.11589", "title": "Einstein Fields: 从神经网络视角看计算广义相对论", "title_en": "Einstein Fields: A Neural Perspective To Computational General Relativity", "authors": "Sandeep Suresh Cranganore,Andrei Bodnar,Arturs Berzins,Johannes Brandstetter", "background": "该研究背景描述了目前在计算广义相对论中存在的计算密集型四维数值相对论模拟问题，其中需要大量资源（计算和存储）来处理复杂的时空几何结构。研究者指出，尽管传统的神经网络表示（如标志距离场、占用率场或辐射场）可以压缩和表示复杂的数值模拟，但它们缺乏捕捉广义相对论中时空几何动态的能力。", "innovation": "Einstein Fields 是一种新颖的神经表示方法，旨在压缩计算密集的四维数值相对论模拟，通过自动微分从核心张量场（度规）模型中推导出物理量。这种方法的独特之处在于，它将广义相对论中的时空几何编码为神经场表示时，动态自然地作为副产品出现，形成了 '神经张量场'。该方法展示出了在连续时空建模、网格无关性、存储效率、导数精确度和使用方便性等方面的优势。", "conclusion": "我们在一系列广义相对论的标准测试床中解决了这些挑战，并发布了一个开源的JAX库，为更具有可扩展性和表达性的数值相对论方法铺平了道路。该库的代码可以在以下链接获取：this https URL"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11574", "html_url": "https://arxiv.org/abs/2507.11574", "title": "无分布不确定性感知的分布自适应神经操作符", "title_en": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators", "authors": "Kazuma Kobayashi,Shailesh Garg,Farid Ahmed,Souvik Chakraborty,Syed Bahauddin Alam", "background": "在实时虚拟传感中，深度学习的安全部署仍受到稳健不确定性量化（UQ）的关键限制，特别是在高风险领域，传感器数据稀疏、噪声或非共位的情况普遍。现有的方法如重新训练、增强集成或定制损失设计等来实现不确定性估计，这些方法在不同领域中缺乏高效的可移植性和可靠性。", "innovation": "CMCO框架通过对神经操作符进行蒙特卡洛 dropout 和分立校准预测的结合，实现无需重新训练、集成或定制损失设计的跨领域高效和可靠的不确定性估计。该方法提供了适用于不同应用的稳健不确定性量化方案，如湍流流动、弹塑性变形和全球宇宙射线剂量估计，能够准确提供空间解析的不确定性估计，即使在强空间梯度和代理传感环境中。", "conclusion": "CMCO通过最小的计算开销，建立了稳健的不确定性感知科学机器学习的新基础，提供了实时、可靠的推断，为数字双胞胎、传感器融合和关键安全性监控等应用解锁了新的可能性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11639", "html_url": "https://arxiv.org/abs/2507.11639", "title": "深度生成方法与轮胎架构设计", "title_en": "Deep Generative Methods and Tire Architecture Design", "authors": "Fouad Oubari,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot", "background": "随着深度生成模型在AI领域的广泛应用，工业从业者仍然面临关于哪种深度生成模型最适合复杂制造设计任务的关键问题。本文通过全面研究五种代表性模型（变分自编码器、生成对抗网络、多模态变分自编码器、去噪扩散概率模型和多项式扩散模型）在工业轮胎架构生成中的表现，探索并解答了这个问题。评估覆盖了三个关键的工业应用场景：（i）无条件生成完全多组件设计，（ii）根据部分观察结果重建架构的条件生成，以及（iii）满足特定尺寸要求的尺寸约束生成。", "innovation": "本文引入了条件场景下用于离散扩散模型的categorical inpainting方法，这是一种有掩码的逆向扩散过程，能够在不进行额外训练的情况下保留已知标签。此外，几何感知的评价指标被专门用于工业需求，从空间一致性、组件交互性、结构连接性和感知保真度方面进行量化。", "conclusion": "扩散模型的整体表现最好；掩码训练的VAE在几乎所有组件条件化指标上优于多模态变体MMVAE+。在扩散家族中，MDM在分布内性能上领先，而DDPM在分布外尺寸约束上的泛化能力更强。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22790", "html_url": "https://arxiv.org/abs/2506.22790", "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge", "title_en": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge", "authors": "Yixu Chen,Bowen Chen,Hai Wei,Alan C. Bovik,Baojun Li,Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Dounia Hammou,Fei Yin,Rafal Mantiuk,Amritha Premkumar,Prajit T Rajendran,Vignesh V Menon", "background": "随着视频技术的迅速发展，尤其是高动态范围(HDR)和标准动态范围(SDR)内容的增加，对于强大且通用的视频质量评估(VQA)方法的需求变得日益迫切。现有的VQA模型在处理不同动态范围、失真类型和多样内容时往往表现不一。", "innovation": "该挑战旨在评估和促进能够同时处理HDR和SDR内容的VQA方法。最终评估阶段，五支队伍提交了七个模型和技术报告，其中四种方法超越了VMAF基线，最优秀的方法达到最新的技术水平，为通用视频质量评估设立了新的基准。", "conclusion": "本次挑战展示了几种先进的VQA方法，特别是对于通用和跨动态范围的内容评估表现优异，为未来该领域的技术发展设定了新的标准。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.02477", "html_url": "https://arxiv.org/abs/2504.02477", "title": "多模态融合和视-语言模型：机器人视觉的综述", "title_en": "Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision", "authors": "Xiaofeng Han,Shunpeng Chen,Zenghuang Fu,Zhe Feng,Lue Fan,Dong An,Changwei Wang,Li Guo,Weiliang Meng,Xiaopeng Zhang,Rongtao Xu,Shibiao Xu", "background": "机器视觉从多模态融合技术和视-语言模型（VLMs）的进步中获得了巨大收益。本文系统性地回顾了多模态融合在关键机器人视觉任务中的应用，包括语义场景理解、同时定位与建图（SLAM）、3D物体检测、导航与定位以及机器人操作等。", "innovation": "本文比较了基于大规模语言模型（LLMs）的VLMs与传统多模态融合方法，并分析了它们的优势、局限性和协同作用。此外，深入分析了常用数据集的应用性和现实挑战，并提出了自监督学习等未来研究方向，以增强鲁棒的多模态表示、基于变换器的融合架构以及可扩展的多模态框架等。", "conclusion": "通过全面回顾、比较分析和前瞻性讨论，本文为推动机器人视觉中的多模态感知与交互提供了有价值的参考。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11649", "html_url": "https://arxiv.org/abs/2507.11649", "title": "ZKP-FedEval: 使用零知识证明实现可验证且隐私保护的联邦评估", "title_en": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs", "authors": "Daniel Commey,Benjamin Appiah,Griffith S. Klogo,Garth V. Crosby", "background": "联邦学习（FL）允许在分散的数据上进行协作模型训练，而不需要暴露原始数据。然而，在FL的评估阶段，通过共享性能指标可能会泄露敏感信息。针对这一问题，本文提出了一种新的协议，通过引入零知识证明（ZKPs），实现了FL中的隐私保护和可验证评估。该方法不需要依赖外部API，通过自包含模块进行联邦学习模拟、零知识证明电路设计，并在MNIST和Human Activity Recognition（HAR）数据集上进行实验评估。", "innovation": "本文提出了一种利用零知识证明（ZKPs）实现隐私保护和可验证的联邦评估协议。该方法允许客户端生成简洁的证明，表明他们的局部损失低于预定义的阈值，而不是直接暴露原始损失值。进一步地，这种方法通过自包含模块实现了联邦学习模拟、零知识证明电路设计，并在MNIST和HAR数据集上进行了评估，着重于基于阈值的证明，适用简单的卷积神经网络（CNN）模型和多层感知器（MLP）模型。", "conclusion": "本文的方法从计算开销、通信成本和验证性方面进行了评估，证明了在联邦评估阶段利用零知识证明实现隐私保护和可验证性的可行性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11688", "html_url": "https://arxiv.org/abs/2507.11688", "title": "从本原构建线性层", "title_en": "Composing Linear Layers from Irreducibles", "authors": "Travis Pence,Daisuke Yamada,Vikas Singh", "background": "当前大型模型往往表现出低级原语组成的模块具有更丰富功能的行为，但这些基本构建块仍然知之甚少。我们通过探究线性层的组合结构，尝试从极小的集合中识别或合成线性变换，进一步探索几何原语如何在深层模型中组合成更高层级的功能。", "innovation": "利用Clifford代数，我们表明线性层可以表示为二向量的组合，即编码定向平面的几何对象，引入了一个可微算法，将它们分解为旋子的乘积。这种构造仅使用O(log^2 d)参数，而密集矩阵需要O(d^2)参数。我们对大型语言模型注意力层的关键、查询和值投影应用了旋子层构造，发现其性能与强基线（如块哈达玛和低秩近似）相当。因此，该研究为理解几何原语在深层模型中的组合提供了代数视角，并展示了基于旋子的线性层的有效性。", "conclusion": "我们的发现为如何在深层模型中从几何原语构建高级功能提供了代数视角，旋子层在关键技术投影中展示了与基线相当的性能，为深入理解复杂模型中的结构提供了新的思路。"}
{"llm_update_time": "20250717", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01881", "html_url": "https://arxiv.org/abs/2507.01881", "title": "为肺部疾病检测在肺癌筛查计划中的胸部疾病检测提供一个计算节省且开源的基础模型", "title_en": "A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs", "authors": "Niccolò McConnell,Pardeep Vasudev,Daisuke Yamada,Daryl Cheng,Mehran Azimbagirad,John McCabe,Shahab Aslani,Ahmed H. Shahin,Yukun Zhou, TheSUMMIT Consortium,Andre Altmann,Yipeng Hu,Paul Taylor,Sam M. Janes,Daniel C. Alexander,Joseph Jacob", "background": "低剂量计算机断层扫描（LDCT）在肺癌筛查（LCS）中的应用正在全球范围内增加，此类计划为同时检测癌症和非癌症相关早期肺部疾病提供了机会。然而，放射科医生短缺成为大规模解读扫描图像的障碍。", "innovation": "TANGERINE是一个计算节省、开源的三维影像基础模型，旨在广泛使用和快速适应。通过使用自我监督学习在超过98,000个胸部LDCT图像上进行预训练，TANGERINE在14个疾病分类任务中（包括肺癌和多种呼吸系统疾病）达到了最先进的性能，并在各种临床中心间表现出了稳健的泛化能力。TANGERINE的独特之处在于，它通过扩展3D影像中的掩码自动编码器框架，提供了一个可扩展的解决方案，与近年来闭源、资源密集型的模型相比，具有架构简单、公共可用性以及适度的计算要求。", "conclusion": "TANGERINE的开放源代码、轻量级设计为其快速集成到下一代医疗成像工具中奠定了基础，使得肺癌筛查项目能够从单一的肺癌检测转向高风险人群的全面呼吸系统疾病管理。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11690", "html_url": "https://arxiv.org/abs/2507.11690", "title": "Coreset选择对虚假关联和群体稳健性的影响", "title_en": "The Impact of Coreset Selection on Spurious Correlations and Group Robustness", "authors": "Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky", "background": "聚心子集（coreset）选择方法在减少训练数据量的同时保持模型性能方面展现了潜力，对于数据高效机器学习尤为重要。然而，由于许多数据集存在偏见，导致模型学习的是虚假关联而不是因果特征，因此理解并分析数据集缩减方法如何影响这些偏见的延续、放大或缓解至关重要。这项工作旨在首次系统分析数据选择对所选择聚心子集中的虚假偏见水平及其下游模型鲁棒性的影响。研究涵盖了十个不同的虚假关联基准、五种衡量样本重要性/难度的不同指标，以及适用于不同聚心子集大小的五种数据选择策略。", "innovation": "研究揭示了样本难度和偏见对齐之间复杂的互动关系，以及数据集偏见和模型鲁棒性之间的关系。研究发现，基于嵌入特征的样本选择评分相较于基于学习动力学的特征选择评分，意外加剧偏见的风险较小。然而，尽管一些聚心子集选择方法可以通过优先选择困难样本来降低偏见水平，但它们并不能可靠地保证下游模型的鲁棒性。", "conclusion": "虽然一些聚心子集选择方法能够通过优先选择困难样本来降低偏见水平，但这些方法并不能可靠地保证下游模型的鲁棒性。因此，未来研究需要更多地关注如何选择能够同时也确保模型鲁棒性的聚心子集。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11710", "html_url": "https://arxiv.org/abs/2507.11710", "title": "在处理远离分布链接上的一般化子图生成", "title_en": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "authors": "Jay Revolinsky,Harry Shomer,Jiliang Tang", "background": "图神经网络（GNNs）在链接预测（LP）任务中表现出高性能。然而，这些模型通常依赖于数据集中的所有样本来自相同的分布。此外，图生成模型（GGMs）在产生新颖输出图方面显示出显著的能力。尽管如此，GGM的应用主要局限于特定领域任务。", "innovation": "文章提出了一种名为FLEX的GGM框架，该框架利用两种机制：（1）结构条件图生成，（2）自动编码器和GNN之间的对抗共同训练。FLEX确保样本分布之间保持结构对齐，从而在异常分布（OOD）场景中增强链接预测的性能。FLEX无需专家知识即可在不同的OOD场景中运行。实验在合成和真实世界OOD设置下进行，以展示FLEX的性能增强能力，并进一步分析了图数据扩充对链接结构的影响。", "conclusion": "实验结果显示FLEX在OOD场景中显著提高了链接预测的性能。FLEX框架通过结构对齐和对抗共同训练，解决了GNNs对数据分布的依赖问题，并且在多种OOD设置下展示了其有效性。源代码可在此处访问：this https URL."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11729", "html_url": "https://arxiv.org/abs/2507.11729", "title": "可扩展短期负荷预测的全球化", "title_en": "Globalization for Scalable Short-term Load Forecasting", "authors": "Amirhossein Ahmadi,Hamidreza Zareipour,Henry Leung", "background": "电力传输网络的负荷预测对于不同层级而言至关重要，从系统层面到个别的配送点（PoD）。传统的局部负荷预测模型（LFMs）在局部精度上具有直观性和准确性，但在泛化能力、过拟合、数据漂移和冷启动问题上存在显著局限性。随着网络规模和数据量的增大，这些方法还难以实现可扩展性，计算成本和效率降低。相比之下，全球化预测模型（GFMs）通过全球化和跨学习的方法，增强预测的泛化能力、可扩展性、准确性和稳健性。论文探讨了在数据漂移背景下进行全局负荷预测，研究不同建模技术和数据异质性的影响。还探讨了全球化对高峰负荷预测的作用及其在分层预测中的潜力。", "innovation": "提出了分时段序列聚类（TSC）方法，分别为特征转换模型引入基于模型的TSC，并为目标转换模型提出新的加权实例基TSC，以解决数据异质性和全局性与局部性的平衡问题。", "conclusion": "通过使用实际数据集对阿尔伯塔省的电力负荷进行广泛的实验，结果显示全局目标转换模型在增强特征和聚类技术的支持下，始终优于局部模型。然而，全局特征转换模型在平衡局部和全局动态方面面临挑战，通常需要TSC来有效管理数据异质性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11739", "html_url": "https://arxiv.org/abs/2507.11739", "title": "使用同构预测的稀疏非线性动力学识别", "title_en": "Sparse Identification of Nonlinear Dynamics with Conformal Prediction", "authors": "Urban Fasel", "background": "稀疏非线性动力学识别（SINDy）是一种从数据中发现非线性动力学系统模型的方法。在安全性关键应用中，评估SINDy模型的可靠性需要量化其不确定性。虽然已存在多种SINDy不确定性量化方法，如贝叶斯和集成方法，本文探讨了将同构预测框架集成到SINDy中的可能性，以提供基于最少假设如数据交换性的有效预测区间并保证覆盖率保证。", "innovation": "提出了将同构预测与Ensemble-SINDy（E-SINDy）结合的三种应用：（1）时间序列预测的不确定性量化；（2）基于库特征重要性进行模型选择；（3）使用特征同构预测量化识别模型系数的不确定性。通过在随机食肉动物-食草动物动态和几个混沌动力系统上进行实验证明了这些应用的有效性，展示了集成同构预测方法与E-SINDy后可以可靠地实现时间序列预测所需的覆盖率目标，有效地量化特征重要性，并在非高斯噪声下生成更稳健的模型系数不确定性区间，优于标准E-SINDy系数估计", "conclusion": "本文提出的方法在非高斯噪声条件下，可以可靠地实现所需的目标覆盖率，有效地量化特征重要性，并生成更为稳健的模型系数不确定性区间，优于标准E-SINDy系数估计。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11759", "html_url": "https://arxiv.org/abs/2507.11759", "title": "Torsional-GFN：小型分子的条件构象生成器", "title_en": "Torsional-GFN: a conditional conformation generator for small molecules", "authors": "Alexandra Volokhova,Léna Néhale Ezzine,Piotr Gaiński,Luca Scimeca,Emmanuel Bengio,Prudencio Tossou,Yoshua Bengio,Alex Hernandez-Garcia", "background": "在药物发现等领域中，稳定分子构象的生成至关重要，比如评估分子与靶点的结合亲和力。近年来，生成性机器学习方法因其相对于分子动力学而言更高效的优势，被用作从玻尔兹曼分布中采样的有效手段。本文探讨了Torsional-GFN，这是一种用于根据分子及其局部结构（键长和角度）的比例采样其扭转角的条件GFlowNet。", "innovation": "Torsional-GFN以其条件GFlowNet特定设计，仅使用奖励函数作为训练信号，采样比例符合玻尔兹曼分布的分子构象。该模型能够对多种分子采样近似玻尔兹曼分布的构象，即使是在未见的键长和角度的情况下，也能实现零样本泛化。", "conclusion": "本文为扩展该方法应用于更大分子系统提供了一条有希望的途径，实现了对未见分子的零样本泛化，并将局部结构生成纳入了GFlowNet模型。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11702", "html_url": "https://arxiv.org/abs/2507.11702", "title": "使用LSTM网络的卫星数据时间序列分类：预测落叶以最小化铁路交通中断的方法", "title_en": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption", "authors": "Hein de Wilde,Ali Mohammed Mansoor Alsahag,Pierre Blanchet", "background": "每年因枝叶脱落引起的铁路交通中断给英国铁路行业造成的损失超过3亿英镑，因此采取了大规模的缓解措施，2021年英国就处理了167万公里的铁路线路。预测枝叶脱落的时机对铁路网络运营商来说具有重大意义，有助于高效调度缓解措施。然而，当前预测枝叶脱落的方法存在可扩展性和可靠性的局限。", "innovation": "该研究提出了一种利用特定预测方法和最新卫星数据源的预测系统。通过对带有真实数据的地面枝叶脱落数据和多光谱及气象卫星数据进行LSTM网络训练，预测枝叶脱落的开始和结束时间分别显示6.32天和9.31天的均方根误差。该模型在该领域取得了比先前工作更优的结果，为铁路行业的枝叶缓解措施优化和复杂生态系统的理解提供了潜在的改善机会。", "conclusion": "该研究利用LSTM网络成功预测了枝叶脱落时间，为铁路交通管理提供了可扩展且可靠的预测系统，有助于优化枝叶缓解措施并提升对复杂生态系统的理解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11660", "html_url": "https://arxiv.org/abs/2507.11660", "title": "STAGED：一种用于学习细胞相互作用动力学的多agent神经网络", "title_en": "STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics", "authors": "Joao F. Rocha,Ke Xu,Xingzhi Sun,Ananya Krishna,Dhananjay Bhaskar,Blanche Mongeon,Morgan Craig,Mark Gerstein,Smita Krishnaswamy", "background": "单细胞技术的发展显著提高了我们对在正常和疾病状态下不同组织中细胞状态和亚群的理解，通过使用聚类和轨迹推断等数据驱动的方法。然而，这些方法将细胞视为种群分布中的独立数据点。空间转录组学允许我们表示细胞的组织，并捕捉由于细胞间动态相互作用引起的细胞状态变化。尽管如此，仍需关键的计算进步来支持数据驱动的学习，以便理解和揭示复杂的细胞间互动动力学。传统的方法采用领域知识引导的手工规则，而不是数据驱动的方法。因此，本文提出了一种将基于代理的建模（ABM）与深度学习结合的新颖方法，称为Spatio Temporal Agent-Based Graph Evolution Dynamics（STAGED），以建模细胞间的相互作用及其对细胞内基因调控网络的影响。通过使用共享权重的图ODE网络（GDEs），该方法将基因表示为顶点，将相互作用表示为方向边，并通过设计的注意力机制动态学习这些边的强度。该模型通过对模拟数据和从空间转录组数据推断的轨迹进行训练，能捕捉细胞间的相互作用和细胞内相互作用，从而提供细胞动力学更适应和准确的表示。", "innovation": "提出了Spatio Temporal Agent-Based Graph Evolution Dynamics（STAGED），这是一种结合了基于代理的建模（ABM）和深度学习的方法，专门用于建模细胞间的动态相互作用及其对细胞内基因调控网络的影响。通过使用图ODE网络（GDEs）和共享权重，创新性地建模基因和相互作用，并通过注意力机制动态学习这些相互作用的强度。这种方法能够捕捉连续的模拟轨迹以及从空间转录组数据推断的轨迹，从而提供细胞动态学更准确和适应性的表示。", "conclusion": "通过对模拟数据和从空间转录组数据推断的轨迹的匹配训练，STAGED模型成功地捕捉了细胞间的动态相互作用以及细胞内的相互作用，提升了对细胞动力学的理解。这种方法在一个集成框架中结合了基于代理的建模和深层学习，为使用空间转录组学数据学习复杂的细胞相互作用提供了有力工具。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11771", "html_url": "https://arxiv.org/abs/2507.11771", "title": "Llama 2模型与拒绝机制中激活引导的扩展定律", "title_en": "Scaling laws for activation steering with Llama 2 models and refusal mechanisms", "authors": "Sheikh Abdur Raheem Ali,Justin Xu,Ivory Yang,Jasmine Xinze Li,Ayse Arslan,Clark Benham", "background": "随着大型语言模型（LLMs）变得越来越复杂且功能越来越强大，以前较为少见的对齐技术的有效性变得不确定。在此背景下，本文基于之前关于激活引导和对比激活添加（CAA）的工作，探讨了使用Llama 2系列模型（7B、13B和70B）时，如何利用CAA技术在不同规模的模型上进行有效对齐。", "innovation": "本文创新地将对比激活添加技术（CAA）应用于不同规模的Llama 2模型中，通过对比激活对模型的残差流空间进行引导，以影响模型输出。研究表明，CAA在早期到中期层中效果最佳，但随着模型大小增加，其效果逐渐降低，负面影响比正面影响更为明显。此工作提供了理解和优化大语言模型影响力的扩展定律。", "conclusion": "研究发现，CAA技术最适合应用于Llama 2模型的早期到中期层；然而，随着模型规模的增加，CAA技术的效果会减弱，并且负面引导比正面引导更为明显。这一结论验证了CAA技术在对齐大型语言模型方面的适用性和局限性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11776", "html_url": "https://arxiv.org/abs/2507.11776", "title": "使用网络特征预测延迟轨迹：荷兰铁路网络研究", "title_en": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network", "authors": "Merel Kampere,Ali Mohammed Mansoor Alsahag", "background": "荷兰铁路网络是世界上最为繁忙的网络之一，对于主要的乘客铁路运营商NS来说，延误是一个主要的关切问题。当前的研究大多集中在短期延误预测上，而忽视了对广泛网络模式的关注，这些模式对于降低级联效应至关重要。因此，该项研究通过运用XGBoost分类器并专注于拓扑特征，来填补荷兰铁路网络延误预测研究中的空白。", "innovation": "研究通过对现有的旨在预测快变的美国航空网络演变的方法进行了改进和实施，将其应用于预测荷兰铁路的延误。研究通过整合节点中心性度量并且对比多种分类器（如随机森林、决策树、梯度提升、AdaBoost 和逻辑回归）来预测延误轨迹。这一创新旨在填补当前研究的空白，提供一种更为全面的方法来处理复杂的铁路网络问题。", "conclusion": "尽管研究的性能在非同步测试情景下表现有限，但这项研究仍然为交通网络评估做出了贡献，并提出了未来开发更稳健的预测模型的方向。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11757", "html_url": "https://arxiv.org/abs/2507.11757", "title": "A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction", "title_en": "A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction", "authors": "Yuehua Song,Yong Gao", "background": "准确预测药物-靶点相互作用（DTIs）对于推动药物发现和靶点验证技术的发展至关重要。尽管基于图形神经网络（GNN）的机器学习方法在DTI预测上取得了显著成功，但许多方法在有效整合药物、靶点及其相互作用的多样性特征方面仍然存在困难。", "innovation": "为了应对这一限制，本文提出了一种新的框架，结合了推断学习和归纳学习的优势，从而可以在分子水平和药物-靶点相互作用网络水平上利用特征。这一框架中包含了一个基于GNN的模型——Graph-in-Graph（GiG），它将药物和靶点分子结构的图形表示为药物-靶点交互图形中的元节点，以深入了解它们的复杂关系。", "conclusion": "通过使用我们特别编译的基准数据集对提出的模型进行评估，实验结果表明GiG模型在所有评估指标上均显著优于现有方法，突显了整合不同学习范式和相互作用数据的好处。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11789", "html_url": "https://arxiv.org/abs/2507.11789", "title": "在单细胞VAEs中强制欧几里得几何学以实现流形插值", "title_en": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation", "authors": "Alessandro Palma,Sergei Rybakov,Leon Hetzel,Stephan Günnemann,Fabian J. Theis", "background": "在应用场合中，潜在空间插值是导航深度生成模型的强大工具。例如，在单细胞RNA测序中，现有方法通过变分自动编码器将细胞状态转换建模为潜在空间插值，通常假设线性位移和欧几里得几何。然而，除非明确强制，潜在空间中的线性插值可能不对应于数据流形上的测地线路径，这限制了假设数据表示为欧几里得几何的方法的有效性。", "innovation": "引入了FlatVI，这是一种新颖的训练框架，用于规约离散似然变分自动编码器的潜在流形以欧几里得几何，特别适用于建模单细胞计数数据。通过鼓励潜在空间中的直线近似解码单细胞流形上的测地线插值，FlatVI增强了与假设具有欧几里得潜在几何的下游方法的兼容性。", "conclusion": "合成数据上的实验支持我们方法的理论正确性，而对时间分辨单细胞RNA测序数据的应用表明了轨迹重建和流形插值的改进。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11620", "html_url": "https://arxiv.org/abs/2507.11620", "title": "使用稀疏自编码器学习事件时间序列表示以进行异常检测、相似性搜索和无监督分类", "title_en": "Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification", "authors": "Steven Dillmann,Juan Rafael Martínez-Galarza", "background": "事件时间序列是由在不规则时间间隔内发生的离散事件组成的序列，且每个事件都与特定领域的观测模态相关。它们广泛存在于高能天体物理学、计算社会科学、网络安全、金融、医疗保健、神经科学和地震学等领域。由于其非结构化的不规则结构，使用常规技术提取有意义的模式和识别显著现象面临巨大挑战。", "innovation": "本文提出了一种新颖的事件时间序列的双模态和三模态张量表示方法，并结合了稀疏自编码器，以学习物理上具含义的潜在表示。这种嵌入支持异常检测、基于相似性的检索、语义聚类和无监督分类等各种下游任务。", "conclusion": "本文方法在高能天体物理学的现实数据集上进行了演示，表明这些表示成功捕捉了时间序列和光谱特征，并隔离了多种X射线瞬变类型。基于此，本文框架为跨科学和工业领域分析复杂、不规则的事件时间序列提供了一个灵活、可扩展且可推广的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11836", "html_url": "https://arxiv.org/abs/2507.11836", "title": "HyperEvent：学习大型动态链接预测中的协同事件", "title_en": "HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction", "authors": "Jian Gao,Jianshe Wu,JingYi Ding", "background": "连续时间动态图中的动态链接预测是建模随时间演化的复杂系统的基本任务。现有方法主要集中在个体交互或原子状态上，未能捕捉到复合超事件（由因果相关事件组成的事件群组）的结构凝聚力。", "innovation": "提出了HyperEvent框架，将动态链接预测重新构想为超事件识别。通过动态构建包含事件相关向量的关联序列，这些向量量化了查询事件与其他历史事件之间的成对依赖关系，从而表征潜在超事件的结构凝聚力。同时，引入了高效并行训练算法以满足大型事件流的规模化需求，实验验证了其在大规模图中的优越准确性和效率。", "conclusion": "HyperEvent在5个数据集中的4个上优于现有最先进的方法，并在大规模航班数据集上实现了6.95%的均逆排名提升，同时只使用了10.17%的训练时间。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11821", "html_url": "https://arxiv.org/abs/2507.11821", "title": "MNIST-Gen：使用层次语义、强化学习和范畴论的模块化MNIST风格数据集生成", "title_en": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory", "authors": "Pouya Shaeri,Arash Karimi,Ariane Middel", "background": "现有基准通常使用如MNIST、FashionMNIST或其他MNIST变体等通用数据集进行神经网络测试，这些数据集虽便于获取，但仅限于如数字或服饰物品等通用类别。对专注于特定领域任务的研究者来说，这些数据集不足以满足实际需求（如树木分类、食品分类等）。此外，创建和发布自定义数据集耗时且受限，或超出了个别项目的范围。", "innovation": "本研究提出了一种名为MNIST-Gen的自动化、模块化和自适应框架，用于根据用户指定的类别生成MNIST风格的图像数据集。该系统结合了基于CLIP的语义理解、强化学习和人工反馈，实现了智能分类且减少了手动干预。该框架采用分层语义分类法支持复杂的类别结构，包括细分类别及多种处理模式（手动审核、智能批量处理和快速批量处理）。该方法借鉴了范畴论的思路，将每个数据转换阶段视为可组合的同构，增强了清晰性、模块化和扩展性。", "conclusion": "以概念验证为例，本研究生成并基准测试了两个新型数据集—Tree-MNIST和Food-MNIST—证明了MNIST-Gen在生成任务特定评估数据方面的实用性及高自动分类准确性（85%）和时间节省（80%）。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11818", "html_url": "https://arxiv.org/abs/2507.11818", "title": "SynCoGen: 通过联合反应和坐标建模的合成可获得3D分子生成", "title_en": "SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling", "authors": "Andrei Rekesh,Miruna Cretu,Dmytro Shevchuk,Vignesh Ram Somnath,Pietro Liò,Robert A. Batey,Mike Tyers,Michał Koziarski,Cheng-Hao Liu", "background": "确保生成小分子的合成可行性仍然是一个重大挑战。虽然最近在合成可行分子生成方面取得了一些有希望的结果，但这些努力主要局限于2D分子图表示，限制了基于几何条件的生成能力。目前的研究工作介绍了SynCoGen（同步生成可合成分子），这是一种结合同时掩码图扩散和流动匹配的单一框架，用于生成合成可获得的三维分子。SynCoGen 从分子构建块、化学反应和原子坐标联合分布中采样。通过构建SynSpace 数据集，包含超过60万含有合成意识的构建块图和330万种构象，以训练模型。研究结果显示在无条件小分子图和构象生成任务上，SynCoGen 达到了最先进的性能。此外，在蛋白质配体生成药物发现中的无监督分子连接剂设计任务上，模型也提供了竞争力的表现。总体而言，这种多模态模型代表了未来非递归分子生成应用的基础，包括同系物扩展，先导优化，以及直接结构条件等应用。", "innovation": "首次提出了联合反应和坐标建模的单一框架，用于生成合成可获得的三维分子。通过同时进行掩码图扩散和流动匹配，可以同时考虑化学反应和三维几何结构。", "conclusion": "SynCoGen不仅在无条件小分子图和构象生成上达到了最先进的性能，还在无监督的分子连接剂设计中展示了竞争力的表现。这些成果为非递归分子生成提供了新的基础，有望在同系物扩展、先导优化和直接结构条件等方面得到更广泛的应用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11590", "html_url": "https://arxiv.org/abs/2507.11590", "title": "合成表格数据生成：现代技术的比较综述", "title_en": "Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques", "authors": "Raju Challagundla,Mohsen Dorodchi,Pu Wang,Minwoo Lee", "background": "随着隐私法规的日益严格和对真实世界数据访问的日益限制，合成数据生成已成为一种重要的解决方案，尤其是在金融、医疗保健和社会科学等领域广泛使用的表格数据集中。这种综述提供了一个全面且集中的回顾，旨在审查最近在合成表格数据生成方面的进展，特别强调那些能够保留复杂特征关系、保持统计准确性并满足隐私要求的方法。", "innovation": "这一工作的关键贡献是引入了一种基于实际生成目标的新分类法，包括预期的下游应用、隐私保证和数据效用，直接指导方法设计和评估策略。此外，综述提出了一种基准框架，以使技术创新与实际需求保持一致。通过结合理论基础和实用部署，这项工作不仅为未来研究指明了方向，还为在隐私敏感环境中实现合成表格数据提供了一条指导。", "conclusion": "综述结合理论基础与实际应用，为未来的研究提供了一个路线图，并为在隐私关键环境中实施合成表格数据提供了一条指导。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11839", "html_url": "https://arxiv.org/abs/2507.11839", "title": "Protenix-Mini: 通过紧凑架构、少数步扩散及可切换的语言模型实现高效的结构预测", "title_en": "Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM", "authors": "Chengyue Gong,Xinshi Chen,Yuxuan Zhang,Yuxuan Song,Hao Zhou,Wenzhi Xiao", "background": "轻量级推断对于蛋白质结构预测及其他下游任务至关重要，能够促进模型的有效部署和大规模应用的实时推理扩展。现有模型在保持预测准确率的同时，往往难以实现高效率。因此，平衡模型效率与预测准确率的挑战亟待解决。", "innovation": "本文通过多项关键改进解决了这一平衡问题：1) 将多步AF3采样器替换为几步的ODE采样器，显著降低了推理过程中扩散模块的计算开销；2) 在开源Protenix框架中，部分Pairformer或扩散变换器模块对最终结构预测不作出贡献，提供了架构剪枝和轻量化设计的潜力；3) 训练了一个结合ESM模块的模型以替代传统的MSA模块，减少了MSA的预处理时间。基于这些见解，本文提出Protenix-Mini，这是一种紧凑且优化的模型，旨在高效预测蛋白质结构。该简化版本采用了更高效的架构设计和两步欧拉微分方程（ODE）采样策略，通过消除冗余的Transformer组件并优化采样过程显著降低模型复杂度，同时仅略有准确率下降，实现了高效结构预测。", "conclusion": "Protenix-Mini在基准数据集上的评估表明，与全规模版本相比，性能仅下降1-5%，展现出在计算资源有限但对准确的结构预测仍有高要求的应用场景中的理想选择。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11855", "html_url": "https://arxiv.org/abs/2507.11855", "title": "OrdShap: 顺序特征重要性对于序列型黑盒模型", "title_en": "OrdShap: Feature Position Importance for Sequential Black-Box Models", "authors": "Davin Hill,Brian L. Hill,Aria Masoomi,Vijay S. Nori,Robert E. Tillman,Jennifer Dy", "background": "序列深度学习模型在具有时间依赖或序列依赖性的领域表现出色，但它们的复杂性要求使用后处理特征归因方法来理解其预测。现有技术虽然能够量化特征的重要性，但假设特征顺序是固定的，从而混淆了特征值（1）和其在输入序列中的位置（2）的效果。", "innovation": "我们引入了OrdShap，这是一种新的归因方法，通过量化将特征位置打乱后模型预测的变化来区分这些效果。我们通过博弈理论将OrdShap与Sanchez-Bergantiños值建立了联系，提供了一种基于理论的方法来进行位置敏感的归因。", "conclusion": "从健康、自然语言和合成数据集的经验结果表明OrdShap能够有效地捕捉到特征值和特征位置的归因，从而提供对模型行为更深入的理解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11865", "html_url": "https://arxiv.org/abs/2507.11865", "title": "一种改进的深度确定性策略梯度框架用于网约车司机折扣订单接受策略", "title_en": "A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers", "authors": "Hanwen Dai,Chang Gao,Fang He,Congyuan Ji,Yanni Yang", "background": "随着平台整合的快速发展，这个解决方案通过将多个网约车平台整合到一个应用中来缓解市场碎片化。为了满足乘客的差异化需求，第三方集成商提供了一个名为Discount Express的服务，由快速司机提供服务，且费用较低。对于个人平台而言，鼓励更多司机参与Discount Express服务可以扩大可用需求池并提高匹配效率，但往往会导致利润下降。本研究旨在从个人平台的角度动态管理司机对Discount Express服务的接受度。由于在新模式下缺乏历史数据，在线学习变得必要。然而，早期的试错探索在实践中共付代价，需要可靠的实际部署早期性能。因此，本研究将司机接受度行为的比例决策视为一个连续的控制任务。", "innovation": "为了应对高度的随机性、不透明的配对机制和有限的历史数据，本研究提出了一种改进的深度确定性策略梯度（pi-DDPG）框架。该框架中包含了优化模块，在最初的训练阶段提升策略性能，并利用卷积长短期记忆网络来有效地捕捉时空复杂模式。还采用优先经验重放机制以提升学习效率。该研究基于实际数据集开发了一个模拟器来验证所提出pi-DDPG的有效性。数值实验表明pi-DDPG在学习效率上表现出色，显著减少了早期训练损失。", "conclusion": "本研究提出了一种改进的深度确定性策略梯度框架来解决网约车司机对Discount Express服务的接受策略，通过高效的在线学习机制和先进的神经网络技术，解决了初期部署的挑战，提高了学习效率并减少了早期训练损失。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11902", "html_url": "https://arxiv.org/abs/2507.11902", "title": "不平衡回归中的重采样策略：综述与实证分析", "title_en": "Resampling strategies for imbalanced regression: a survey and empirical analysis", "authors": "Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz", "background": "不平衡问题在不同的现实场景中普遍存在，为了解决这一问题，提出了一些重采样或平衡算法的策略，这些策略主要在分类任务中进行研究，但在回归任务中也同样存在，尤其是在目标值为连续值的情况下更为显著。因此，本文通过多种平衡和预测模型进行了全面的实验研究，采用了多种评价指标来捕获用户关注的元素，以评估不平衡回归数据集中的预测模型。", "innovation": "本文提出了一种不平衡回归方法的分类法，基于三个关键标准：回归模型、学习过程和评价指标。此外，研究还提供了关于这些策略使用的新见解，强调了它们对每种模型学习过程的优势，并指出了进一步研究的方向。", "conclusion": "本文的研究为不平衡回归策略提供了新的见解，强调了它们对模型学习过程的优势，并指出了进一步研究的可能方向。关于实验中使用的代码、数据和更多信息可以在GitHub上找到：this https URL."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11807", "html_url": "https://arxiv.org/abs/2507.11807", "title": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "title_en": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "authors": "Ruofan Hu,Dongyu Zhang,Huayi Zhang,Elke Rundensteiner", "background": "使用有噪声标签（LNL）训练深度神经网络对于处理不完美数据是必要的。元学习方法通过使用干净且无偏的标注集来训练鲁棒模型而获得了成功，但这种方法严重依赖于干净标注元数据集的存在，而在实际中难以获得。因此，本文聚焦于在无需使用干净标注数据的情况下解决元学习在噪声标签场景中的挑战，旨在通过依赖数据本身而非标签来克服这一困难。本文通过利用数据结构在不同特征空间中的对齐情况，在最后隐藏层和最终层之间有效地保留了一致性，同时噪声样本破坏了一致性，设计出了Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU)。实验证明，CLID-MU在不同标签量的基准数据集上优于现有最先进方法，并且已在代码托管平台发布可供下载。", "innovation": "提出了Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU) 方法，该方法通过一种新的机制来利用数据结构在不同特征空间中的对齐情况来进行模型训练，能够在无需依赖干净标注数据的情况下处理有噪声标签的问题，有效提升了模型的训练性能，实验结果表明该方法优于现有最先进方法。", "conclusion": "CLID-MU方法在合成和真实世界噪声场景下的不同标签量的基准数据集上均展示了卓越的性能，表明其可以有效解决元学习在有噪声标签场景中的问题，为依赖数据本身的无标注算法提供了新的思路。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11928", "html_url": "https://arxiv.org/abs/2507.11928", "title": "通过智能采样和基于机器学习的参数调优加速射频功率放大器设计", "title_en": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning", "authors": "Abhishek Sriram,Neal Tuffy", "background": "射频（RF）功率放大器的设计需要大量的仿真，这大大增加了时间和成本。传统的优化方法往往需要模拟所有可能的参数组合，但在实际设计中，这种全面的仿真并非总是必要，可以采用更有效的策略来提高效率并保证精度。因此，如何在减少仿真需求的同时保持所需的性能水平成为一个挑战。本文提出了一种结合了MaxMin拉丁超立方抽样和CatBoost梯度提升的机器学习加速优化框架来解决这个问题。", "innovation": "文中创新地结合了MaxMin拉丁超立方抽样与CatBoost梯度提升技术，通过智能选择关键仿真点来减少模拟次数，从而将仿真需求减少了65%。同时，该框架通过处理ADS网络列表，执行谐波平衡仿真，并训练CatBoost模型来预测整个设计空间内的P2dB性能，最终实现了58.24%到77.78%的仿真时间减少，同时保持了±0.3到±0.4 dBm的精度水平，通过自动化的图形用户界面流程实现了快速设计迭代，而不会牺牲生产射频电路所需的精度标准。", "conclusion": "该研究框架不仅验证了15种PA操作模式下的性能表现，平均$R^2$达到0.901，还成功地展示了其在减少仿真时间和提高设计效率方面的显著成果。通过与传统的全面仿真方法相比，该框架为射频功率放大器的设计提供了一个快速而准确的优化方案，适用于自动化设计流程。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11926", "html_url": "https://arxiv.org/abs/2507.11926", "title": "从生成到集训：高效可复制强化学习", "title_en": "From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning", "authors": "Max Hopkins,Sihan Liu,Christopher Ye,Yuichi Yoshida", "background": "近年来，实证科学和机器学习领域的可复制性失败促使进行形式化的可复制学习算法研究（Impagliazzo等人，2022年）。在批处理设置中，数据来自固定的IID源（例如，假设检验、监督学习），设计高效且可复制的算法已经被基本理解。相比之下，在强化学习等控制设置中，由于需要直接交互以应对不断变化的环境，目前对于探索和学习高效策略的知识存在较大缺口。Karbasi等人证明，拥有环境生成模型的情况下（环境有S个状态和A个动作），可复制地学习一个接近最优的策略仅需大约Otilde(S²A²)次样本。而在未提供生成模型的情况下，最佳上界跳增至Otilde(S⁷A⁷)，这主要是由于环境探索的巨大难度。这些差距提出了可复制性理论的关键问题：可复制的探索是否比批处理学习更昂贵？高效可复制强化学习是否有可能实现？", "innovation": "本文在一个低时序表象MDP中，几乎解决了上述问题：探索不是可复制学习的主要障碍！主要成果是一个在Otilde(S²A)样本数下的可复制的RL算法，填补了生成设置与收集设置之间的差距。此外，通过常见的并行采样假设，给出了生成设置中匹配的Ωtilde(S²A)下界，并在收集设置中给出了Ωtilde(S²)的无条件下界，体现了算法在状态空间S中的近似最优性。", "conclusion": "探索不是低时序表象MDP中可复制强化学习的主要障碍。所提出的算法在样本效率上达到了最优，克服了生成模型和收集设置之间的差距，并展示了在状态空间S方面的近似最优性，展示了在探索效率优化方面的重要突破。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11732", "html_url": "https://arxiv.org/abs/2507.11732", "title": "基于编码嵌入的图神经网络以提高节点学习", "title_en": "Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning", "authors": "Shiyu Chen,Cencheng Shen,Youngser Park,Carey E. Priebe", "background": "图神经网络（GNNs）已经成为处理节点级图学习任务的强大框架。然而，它们的表现通常受限于对随机或仅有轻微信息的初始特征表示的依赖，这可能导致收敛速度缓慢并且导致次优解决方案。", "innovation": "该论文提出了一种统计学上合理的方法，即一热图编码嵌入（GEE），用于生成高质量的初始节点特征，以增强GNNs的端到端训练过程。通过广泛的仿真实验和实际应用实验，证实了该方法的有效性，在节点聚类中，GG（GEE增强的GNN）在所有测试的真实数据集上始终获得最先进的性能，且收敛速度较标准GNN更快。此外，为了节点分类，还提出了一个增强变体GG-C，它将GG和GEE的输出连接起来，并优于其他基线方法。", "conclusion": "这些结果证明了结构感知的特征初始化在充分发挥GNNs潜力方面的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11997", "html_url": "https://arxiv.org/abs/2507.11997", "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "title_en": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "authors": "Tairan Huang,Yili Wang", "background": "图神经网络（GNNs）在处理多模态数据中的复杂关系方面表现出色，因此图欺诈检测引起了显著关注。然而，现有的图欺诈检测方法通常依赖预处理的节点嵌入和预定义的图结构来识别欺诈者，这忽略了原始文本信息中丰富的语义线索。大型语言模型（LLMs）在处理文本信息方面具有强大能力，但将处理后的文本嵌入与图结构进行多模态融合仍然是一个重大挑战。", "innovation": "本文提出了一种名为MLED的多层次LLM增强图欺诈检测框架。MLED利用LLMs从文本信息中提取外部知识，以增强图欺诈检测方法。为了将LLMs与图结构信息整合并增强区分欺诈者的能力，设计了一种多层次LLM增强框架，包括类型级增强器和关系级增强器。前者用于增强欺诈者和良性实体之间的差异，后者用于增强不同关系中欺诈者的相对重要性。实验证明，MLED在图欺诈检测中取得了最先进的性能，可以作为可用于现有方法的通用框架。", "conclusion": "MLED实验证明在图欺诈检测中取得了最先进的性能，证明了多层次LLM增强框架的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11706", "html_url": "https://arxiv.org/abs/2507.11706", "title": "表格MDP中的对抗性偏好强化学习", "title_en": "Reinforcement Learning from Adversarial Preferences in Tabular MDPs", "authors": "Taira Tsuchiya,Shinji Ito,Haipeng Luo", "background": "本文引入了一种新的表格MDP框架，称为基于偏好的MDP（PbMDPs），其中偏好是通过比较两个候选臂来观察的。这与传统的具有对抗性损失的表格MDP不同，在后者中直接观察到损失的数值。偏好领域的研究旨在通过观察并学习基于偏好的选择，以解决决策过程中的不确定性和复杂性问题，尤其是在不确定的环境中。研究者们建立了PbMDPs中Borda分数的最坏后悔下界，并通过一种简单的实例证明了具有对抗性损失的表格MDP的最坏下界。在这种背景下，提出的算法在已知转换的情况下达到了后悔度的最优界 $O(T^{2/3})$，并在未知转换的情况下也进行了扩展研究，为实际应用提供了重要的理论基础。", "innovation": "研究引入了基于偏好的MDP（PbMDPs）框架，通过比较两个候选臂观察偏好。研究了Borda分数背景下PbMDPs的后悔下界，并提出了两种基于已知和未知转换的算法，分别达到了后悔度的界 $O((H^2 S^2 K)^{1/3} T^{2/3})$ 和 $O((H^6 S K^5)^{1/3} T^{2/3})$。相较于现有方法，新提出的方法在面对大量状态时表现更优，并且解决了计算效率低的问题。", "conclusion": "研究得出了Borda分数下的PbMDPs后悔下界，并开发了两种算法。在已知转换的情况下，第一种算法达到了后悔度的最佳界 $O((H^2 S^2 K)^{1/3} T^{2/3})$；第二种算法则在未知转换的情况下进一步扩展了研究。这些结果为对抗性偏好驱动的强化学习提供了理论支持并提出了新的研究方向。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12011", "html_url": "https://arxiv.org/abs/2507.12011", "title": "DUSE: 基于主动学习的低资源自动调制识别数据扩展框架", "title_en": "DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning", "authors": "Yao Lu,Hongyu Gao,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui", "background": "尽管深度神经网络在自动调制识别（AMR）领域取得了显著成果，但这些模型往往需要大量标注数据进行训练。然而，在许多实际场景中，可用的目标领域数据稀缺且难以满足模型训练需求。直接方法是手动收集数据并进行专家标注，但成本高昂；另一种方法是数据增强，虽能一定程度上丰富训练样本，但无法引入新数据，无法从根本上解决数据稀缺问题。", "innovation": "引入了一种数据扩展框架——Dynamic Uncertainty-driven Sample Expansion (DUSE)。DUSE 使用不确定性评分函数从相关AMR数据集中筛选有用样本，并采用主动学习策略不断细化评分器。实验表明，DUSE 在类平衡和类不均衡设置中均优于8种核心选择基线，并且在未见过的模型上表现出强大的跨架构泛化能力。", "conclusion": "DUSE框架在低资源自动调制识别中表现出色，能够高效地筛选和扩充数据，有效解决了数据稀缺问题，并且具有良好的跨模型泛化能力。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12041", "html_url": "https://arxiv.org/abs/2507.12041", "title": "粒度化的反馈需要复杂的聚合", "title_en": "Granular feedback merits sophisticated aggregation", "authors": "Anmol Kagrecha,Henrik Marklund,Potsawee Manakul,Richard Zeckhauser,Benjamin Van Roy", "background": "粒度化的反馈因其提供更多信息而在各类应用中越来越受欢迎，如训练AI模型、开发推荐系统和测量公众意见。然而，由于成本限制，通常只能使用小群体进行反馈收集。普通的聚合同一方法需要向先验值正则化，以估算群体的反馈分布，但在反馈粒度增加时，这种方法的效果有所局限。研究者提出了一种通过更加复杂的方式来处理小样本反馈的方法来改进预测效果。实验结果表明，当使用二元反馈时，复杂方法仅能略微减少所需个体数量以达到固定水平的性能，但在使用五点反馈时，复杂方法能够在个体数量减少约一半的情况下达到与正则化平均相同的效果。", "innovation": "提出了更复杂的反馈聚合方法，以在使用少量反馈数据时提高预测效果，验证了在不同反馈粒度下，复杂方法比简单的正则化平均方法更有效。通过实验证明了，在反馈粒度较高时，更复杂的方法能显著提高预测精度，减少所需反馈个体的数量。", "conclusion": "研究表明，对于粒度较高的反馈数据，复杂方法可以显著提高预测结果的准确性。相比简单方法，复杂方法可以有效减少所需的个体数量，以达到相同的性能。这对于在资源有限的情况下进行群体反馈预测有着重要意义。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12043", "html_url": "https://arxiv.org/abs/2507.12043", "title": "基于重放的持续学习的信息论泛化边界", "title_en": "Information-Theoretic Generalization Bounds of Replay-based Continual Learning", "authors": "Wen Wen,Tieliang Gong,Yunjiao Zhang,Zeyu Gao,Weizhan Zhang,Yong-Jin Liu", "background": "持续学习（CL）已成为一种在不遗忘旧知识的情况下从序列任务中获取新知识的主要范式。尽管已经提出了许多CL方法来展示出色的实证性能，但对其泛化行为的理论理解仍然有限，特别是对于基于重放的方法。本文从信息论的角度研究了基于重放的CL方法，构建了一个统一的理论框架，从而揭示了记忆缓存与当前任务之间的交互对泛化的影响机制。", "innovation": "本文提出了基于假设的边界和基于预测的边界，这些边界明确地描述了利用先前任务的有限实例与当前任务数据相结合比全面重放更能促进泛化的机制，同时有效减少灾难性遗忘。此外，基于预测的边界通过使用低维变量提供了更紧且计算上可处理的泛化差距上界。这种分析方法广泛适用于多种学习算法，例如作为代表方法的随机梯度Langevin动力学（SGLD）。", "conclusion": "全面的实验评估表明，本文推导出的边界在捕捉基于重放的持续学习设置中的泛化动态方面非常有效。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11948", "html_url": "https://arxiv.org/abs/2507.11948", "title": "Kevin: 多轮强化学习在生成CUDA内核方面的应用", "title_en": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "authors": "Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti", "background": "编写GPU内核对AI系统的效率至关重要，且是一个挑战性的任务，通常通过迭代过程进行改进。这个过程具有可验证的奖励，如正确性和加速，使其成为应用强化学习（RL）的理想环境。研究人员通过这种迭代过程训练模型来改善CUDA内核的生成和优化，但面临着学习长轨迹和跨轮次准确归因奖励的独特挑战。", "innovation": "开发了灵活的多轮RL方法以解决真实世界场景中的独特挑战，包括从长轨迹中学习和在轮次间有效归因奖励。首次使用多轮RL训练模型（Kevin）生成和优化CUDA内核，显著提高了生成内核的正确性和加速效果。特别地，当给予更多的细化轮次时，模型显示出更高的改进率。研究还发现并行采样不如串行细化更为有利", "conclusion": "Kevin展示了在CUDA内核生成和优化方面的显著改进，正确率从56%提高到82%，平均加速比从0.53倍提高到1.10倍。相对于前沿模型o4-mini (0.78x)，其性能超过了基线模型QwQ-32B。此外，研究表明串行细化的效果优于并行采样。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12053", "html_url": "https://arxiv.org/abs/2507.12053", "title": "FloGAN：基于条件生成对抗网络和动态区域解耦的城市情景出行流生成", "title_en": "FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling", "authors": "Seanglidet Yean,Jiazu Zhou,Bu-Sung Lee,Markus Schläpfer", "background": "城市中人们的移动模式随着土地使用和人口的变化而演变，这对城市规划者来说至关重要，尤其是为了交通优化和可持续城市发展。现有的生成模型依赖历史轨迹，但对于人口密度和土地使用变化等演变因素的考虑不足。机械方法考虑了人口密度和设施分布，但假设静态情景，对于无法获取历史数据校准的未来预测没有实用性。", "innovation": "本文提出了一种新颖的数据驱动方法，用于为模拟城市情景生成起讫点的移动流。该方法利用了动态区域大小和土地使用原型等自适应因素，并使用条件生成对抗网络（cGANs）将历史数据与这些自适应参数融合。这种方法可以在感兴趣区域的基础上灵活调整空间粒度，无需大量校准数据或复杂的行为建模。", "conclusion": "研究成果展示了该方法在新加坡手机数据上的应用，并与现有方法进行了比较，表明该方法表现出良好的性能。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11847", "html_url": "https://arxiv.org/abs/2507.11847", "title": "广义线性臂：几乎最优后悔量的一次更新", "title_en": "Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update", "authors": "Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama", "background": "我们研究了一类广义线性臂（GLB）问题，这是在经典线性模型的基础上引入非线性连接函数的上下文多臂赌博框架，以建模包括伯努利和泊松在内的广泛奖励分布。GLB在现实世界的应用场景中非常普遍，但它们的非线性性质使得在追求计算和统计效率时面临重要挑战。现有方法通常在实现最优后悔保证和确保统计效率之间做权衡，前者每轮成本较高，后者则可以实现常量时间更新。", "innovation": "本文提出了一个高效的算法，该算法能够以每轮$\text{O}(1)$的时间和空间复杂度获得几乎最优的后悔界。我们方法的核心是对在线镜像下降（OMD）估计量的紧确置信集，该置信集通过一种新颖的分析方法得到，这种分析方法利用了在线预测中的混损失概念。我们的分析表明，尽管OMD估计量使用的是单次更新，它仍然能够实现与最大似然估计相当的统计效率，从而导致了一种联合高效的乐观方法。", "conclusion": "我们提出的算法能够在每轮以$\text{O}(1)$的时间和空间复杂度下达到几乎最优的后悔界，同时实现高效性和统计效率。这表明通过巧妙地利用混损失的概念，可以在保持计算效率的同时实现统计效率。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12070", "html_url": "https://arxiv.org/abs/2507.12070", "title": "受各向异性函数影响，量化表示的涌现", "title_en": "Emergence of Quantised Representations Isolated to Anisotropic Functions", "authors": "George Bird", "background": "该论文基于现有的Spotlight Resonance方法，提出了一个新的方法来确定表示的对齐方式。研究发现，网络基本单元的代数对称性是表示结构的强有力预测因子。特别地，该研究通过改变激活函数在自编码器模型中的表现，探索了离散表示的形成和排列。", "innovation": "开发了一种新的方法来确定表示的对齐方式。研究发现，当激活函数定义通过离散代数置换等变对称时，表示趋向于离散化；而当定义为连续代数正交等变时，保持连续性。这证实了功能形式的选择可能引入不受任务影响的特征结构，特别表明当前形式会将连续结构量化，导致离散化。", "conclusion": "研究发现表示的量化与重构误差的增加相关。这表明量化可以对下游可解释性产生影响，并支持一种因果模型，即离散表示可能在某些模式下形成。这工具和机制可能为可解释性研究提供新的见解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12142", "html_url": "https://arxiv.org/abs/2507.12142", "title": "RiemannLoRA: 一种用于 LoRA 优化的统一代数流形框架", "title_en": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization", "authors": "Vladimir Bogachev,Vladimir Aletov,Alexander Molozhavenko,Denis Bobkov,Vera Soboleva,Aibek Alanov,Maxim Rakhuba", "background": "低秩适应（LoRA）已经成为大规模语言模型（LLMs）参数高效微调的标准方法，大幅降低了内存和计算需求。然而，仍存在挑战，如找到最佳初始化策略或在低秩矩阵分解中减轻过度参数化的问题。", "innovation": "提出了一种新的方法，同时在统一框架内解决了双重挑战：一是通过将一组固定秩的 LoRA 矩阵视为光滑流形上的元素来去除过度参数化；二是通过确定沿流形的最快损失减少方向来提供初始化。通过最佳实践从数值线性代数和黎曼优化中实现数值稳定性和计算效率提高.", "conclusion": "实验结果显示，RiemannLoRA 在大规模语言模型和扩散模型架构中比标准 LoRA 及其最先进的修改版本在收敛速度和最终性能上均有持续改进."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12145", "html_url": "https://arxiv.org/abs/2507.12145", "title": "PRISM: 分布式边缘环境中的基础模型推理", "title_en": "PRISM: Distributed Inference for Foundation Models at Edge", "authors": "Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang", "background": "基础模型（FMs）已在从图像分类到自然语言处理等众多应用中取得了显著成果，但在边缘设备上的部署仍面临重大挑战。这激发了开发适用于边缘环境的实用和高效策略的需求。", "innovation": "提出了PRISM，一种分布式Transformer推理策略，旨在实现通信效率和计算意识。该方法利用Segment Means表示法近似中间输出特征，显著减少设备之间的通信量，并重新设计自注意力机制以消除由于位置分割中的设备特定键/值计算引发的冗余计算，同时设计了一种分区感知的因果掩码方案以适应自回归模型。", "conclusion": "在不同的基础模型（包括ViT、BERT和GPT-2）和数据集（如CIFAR-10、CIFAR-100、ImageNet-1k、GLUE和CBT）上对PRISM进行了评估，结果显示，与压缩率CR=128时BERT的设置相比，实现了通信开销的最大减少（高达99.2%）和每设备计算量的显著减少（51.24%），同时仅产生轻微的准确率下降。这种方法为部署基础模型在分布式资源受限环境中提供了可扩展且实用的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12002", "html_url": "https://arxiv.org/abs/2507.12002", "title": "在嘈杂真实环境中的商用智能手表音频和运动传感检测面对面对话", "title_en": "Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing", "authors": "Alice Zhang,Callihan Bertley,Dawei Liang,Edison Thomaz", "background": "社会互动在塑造人类行为、关系和社会方面发挥着至关重要的作用。这种互动包括多种形式的沟通，例如口头对话、非语言手势、面部表情和身体语言。在本研究中，通过利用捕获自商用智能手表的音频和惯性数据，开发了一种新颖的计算方法，以便在充满挑战的声学条件下检测面对面对话这一人类社会互动的基础方面。", "innovation": "该研究提出了一种新的基于计算的方法，利用商用智能手表捕获的音频和惯性数据，在嘈杂的真实环境中检测面对面对话。研究选择了机器学习和深度学习模型，并通过音频和惯性数据的不同融合方法，展示了融合这些数据的优势，不仅考虑了言语线索，还考虑了对话中的非言语手势。此外，研究还进行了多项测评，以证明多模态传感在特定情境中的益处。", "conclusion": "整体而言，当在实验室环境中检测对话时，该框架达到了82.0±3.0%的宏F1分数；在半自然环境下达到了77.2±1.8%。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12166", "html_url": "https://arxiv.org/abs/2507.12166", "title": "RadioDiff-3D: 一个用于6G环境感知通信的3D×3D无线地图数据集及其基于扩散的生成基准", "title_en": "RadioDiff-3D: A 3D$\\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication", "authors": "Xiucheng Wang,Qiming Zhang,Nan Cheng,Junting Chen,Zezhong Zhang,Zan Li,Shuguang Cui,Xuemin Shen", "background": "无线通信环境感知依赖于无线信道特性在空间中的分布（通过射电图RMs体现）。现有方法大多集中在固定2D平面上的路径损耗预测，忽视了如到达方向（DoA）、到达时间（ToA）和垂直空间变化等关键参数。这是由于静态学习范式的限制，无法泛化到训练数据分布之外。", "innovation": "提出了UrbanRadio3D，这是一个基于实况城市环境实线追踪的大型高分辨率3D射电图数据集，拥有3个维度的路径损耗、到达方向和到达时间等3个指标，形成了一个3D×33D数据集，拥有比之前最先进的3D数据集多7倍的高度层。此外，引入了基于3D卷积架构的生成扩散模型RadioDiff-3D，支持已知发射机位置的辐射感知场景和基于稀疏空间观测的非辐射感知设置，并通过UrbanRadio3D展示了其在多样化环境中构建丰富、高维射电图的优势。", "conclusion": "该研究提供了第一个为3D环境感知通信提供基础数据集和基准的射电图，数据集和基准已在网站上公开。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12165", "html_url": "https://arxiv.org/abs/2507.12165", "title": "使用高斯马尔可夫随机场的多组件VAE", "title_en": "Multi-Component VAE with Gaussian Markov Random Field", "authors": "Fouad Oubari,Mohamed El-Baha,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot", "background": "工业装配和多模态影像等具有复杂互依关系的多组件数据集，对现有生成模型构成了挑战。现有的多组件变分自动编码器通常依赖简化的聚合策略，忽略了关键的细节，从而影响生成组件之间的结构一致性。因此，需要一种能够明确建模跨组件关系的生成框架，以提供更丰富的表示和更真实的复杂交互复制能力。", "innovation": "我们提出了高斯马尔可夫随机场多组件变分自动编码器（GMRF MCVAE），这是一种新颖的生成框架，将高斯马尔可夫随机场嵌入到先验和后验分布中。这种设计明确地建模了跨组件关系，从而能够生成更丰富的表示，并真实地复制复杂的交互。通过在合成的Copula数据集、PolyMNIST基准和现实世界BIKED数据集上的实验，GMRF MCVAE表明其在多重成分一致性建模方面具有优越的性能和实际应用价值。", "conclusion": "我们证实了GMRF MCVAE特别适合那些需要稳健和逼真建模多组件一致性的实际应用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12192", "html_url": "https://arxiv.org/abs/2507.12192", "title": "可解释的证据聚类", "title_en": "Explainable Evidential Clustering", "authors": "Victor F. Lopes de Souza,Karima Bakhti,Sofiane Ramdani,Denis Mottet,Abdelhak Imoussaten", "background": "无监督分类是机器学习的基本问题。现实世界的数据通常包含缺陷，这些缺陷由不确定性与不精确性特征，传统的处理方法对此不适应。基于Dempster-Shafer理论的证据聚类解决了这些挑战。然而，在这类重要场景，如医疗健康中，证据聚类的结果需要进行解释。本研究通过引入表示性作为必要条件，提出了基于效用函数的概念，将部分标签问题进行了建模，从而定义了证据错误作为解释成本，并构建了适用于证据分类器的解释器。最后，提出了一种新的算法——迭代证据错误最小化（IEMM），该算法提供了证据聚类函数的可解释且谨慎的决策树解释。", "innovation": "本文通过引入表示性作为必要条件，提出了基于效用函数的方法解决了证据聚类结果的可解释性问题。提出了证据错误作为解释成本的概念，构建了更适合证据分类器的解释器。进一步提出了迭代证据错误最小化（IEMM）算法，为证据聚类提供可解释和谨慎的决策树解释。", "conclusion": "利用IEMM算法在合成数据和真实数据上进行验证。考虑到决策者的偏好，所提出的算法可以提供满意解释达93%以上。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12127", "html_url": "https://arxiv.org/abs/2507.12127", "title": "无需多数善意自适应且稳健的联邦频谱感知：适用于蜂窝网络", "title_en": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks", "authors": "Ngoc Duy Pham,Thusitha Dayaratne,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph", "background": "无线和移动技术的发展，特别是5G高级版本和设想中的6G技术，推动了无线设备数量的指数级增长。然而，这种快速扩张增加了频谱的稀缺性，成为一个关键挑战。动态频谱分配（DSA）通过频谱感知和动态共享频谱的方式，成为解决这一问题的主要方案。尽管机器学习（ML）模型在频谱感知方面具有巨大潜力，但在集中化的ML-DSA系统中推广使用受到隐私问题、带宽限制和监管挑战的限制。为此，基于分布式机器学习的方法，如联邦学习（FL），提供了有前景的替代方案。本文关注两个联邦频谱感知（FLSS）中的关键挑战：一是探讨训练联邦模型时缺乏有标签数据的问题，二是分析数据中毒攻击对FLSS的影响并提出有效的防御机制。", "innovation": "提出了一种结合半监督联邦学习和能量检测的频谱感知方法，以及一种基于疫苗接种原理的新型防御机制，以提高数据中毒攻击的防御能力，无需依赖多数主动者的假设。这种方法不仅能使模型在无标签的数据集上实现接近完美的准确性，还能在有和无目标的数据中毒攻击下维持拜占庭鲁棒性，即使大量参与者是恶意的。", "conclusion": "通过大量的实验验证了提出的解决方案，在合成和实际数据集上展示了FLSS能够实现无标签数据集的近完美准确率，并抵抗由恶意节点发起的各种类型的数据中毒攻击。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12144", "html_url": "https://arxiv.org/abs/2507.12144", "title": "FourCastNet 3：一种大规模几何概率机器学习天气预报的方法", "title_en": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale", "authors": "Boris Bonev,Thorsten Kurth,Ankur Mahesh,Mauro Bisson,Jean Kossaifi,Karthik Kashinath,Anima Anandkumar,William D. Collins,Michael S. Pritchard,Alexander Keller", "background": "当前全球天气模型采用传统方法进行集合预报，这些方法在稳定性和预测准确性方面受到限制。Machine Learning (ML) 方法提供了一种新的预报方式，但大多数方法未能充分考虑球面几何形状，导致在长周期预测时出现非现实的光谱和动态。FourCastNet 3 旨在通过创新的几何机器学习方法改进全球天气建模，并在短时间内提供高准确性和概率校准的预报结果。", "innovation": "FourCastNet 3 使用了一种专门为球面几何设计的纯卷积神经网络架构。它采用了新颖的模型和数据并行训练范式，在大量 GPUs 上实现高效的大规模训练。此外，FourCastNet 3 在提供高质量中期概率预报结果的同时，还能够保持光谱的准确性并在长达 60 天的预报时间尺度上保持稳定性。它在速度和计算效率方面也超过了其他方法，能够在一个 GPU 上快速生成高分辨率的 90 天全球预报。这些进步使其成为通过大规模集合预报改善气象预报和预警系统的强大候选者。", "conclusion": "FourCastNet 3 在全球天气建模中取得了显著的进展，通过几何机器学习方法提高了预报准确性和概率校准性能。这种方法不仅速度快，而且计算效率高，能够在较长的预报时间尺度上保持光谱的准确性。它的研究结果为改进气象预报和早期预警系统提供了强有力的支持。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11901", "html_url": "https://arxiv.org/abs/2507.11901", "title": "不平衡回归管道推荐", "title_en": "Imbalanced Regression Pipeline Recommendation", "authors": "Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz", "background": "不平衡问题在现实场景中非常普遍，并且已经在分类任务中得到了广泛的研究，但它们也给回归任务带来了挑战，因为某些目标值出现得很少。传统的解决方法是在预处理时使用均衡算法来处理不平衡的数据集。然而，由于有多种重采样方法和学习模型，确定最佳解决方案需要测试多种组合。此外，学习模型、数据集和评估指标也会影响最佳策略的选择。", "innovation": "该研究提出了一个名为Meta-learning for Imbalanced Regression (Meta-IR)的框架，该框架通过培训元分类器来根据任务推荐包含重采样策略和学习模型的最佳管道。该元分类器是使用一组元特征训练的，以学会如何将元特征映射到表示最佳管道的类别。研究提出了两种形式：独立和连锁。独立形式让元分类器分别指示最佳学习算法和重采样策略。连锁形式是一种顺序过程，其中一个元分类器的输出用于作为另一个元分类器的输入，建模内生关系因素。研究发现，连锁场景显示出更好的性能，表明学习算法与每种任务的重采样策略之间存在关系。Meta-IR框架相比于自动机器学习框架表现更好，也优于六种学习算法和六种重采样算法（每种不重采样的情况）的总和（共42种配置）的所有基准。", "conclusion": "本研究提出了Meta-IR框架，通过培训元分类器推荐不平衡回归任务的最佳管道。实验表明，该方法在多个基准上表现优于传统方法，表明了其在处理不平衡回归问题上的有效性。此外，研究提供了代码、数据和实验的额外信息，可以在GitHub上找到：this https URL."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12094", "html_url": "https://arxiv.org/abs/2507.12094", "title": "量化非完美校准预测器的信息差距", "title_en": "Measuring Informativeness Gap of (Mis)Calibrated Predictors", "authors": "Yiding Feng,Wei Tang", "background": "在许多应用场景中，决策者需要在多个可能都存在校准偏差的预测模型之间进行选择。考虑到这些模型在下游决策任务中的“有用性”标准尚未明确，本文旨在通过引入预测器之间信息差距的概念来定义评估模型在不同决策任务中的表现差异的方法。", "innovation": "本文的主要贡献包括两个方面：首先，提出了预测器之间信息差距的概念，并定义为一个预测器在所有决策任务中相对于另一个预测器的最大归一化收益优势。其次，提供了一种信息差距的双面特性描述，这导致了一种全新的信息量度，该度量可以视为两种预测分布之间沃特曼距离的松弛版本。此外，还证明了该度量具有自然特性，并且可以在仅预测访问设置中高效估计。同时，获得了完全校准预测器上这一度量的新型组合结构结果。", "conclusion": "本文提出的方法不仅扩展了现有的校准测量概念，还提供了一种新的、灵活的信息论度量，能够量化不同预测器之间的信息差距。该方法的特点是能够在实际应用中高效、准确地进行估计和分析。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11975", "html_url": "https://arxiv.org/abs/2507.11975", "title": "在线深度强化学习网络的训练与修剪", "title_en": "Online Training and Pruning of Deep Reinforcement Learning Networks", "authors": "Valentin Frank Ingmar Guenter,Athanasios Sideris", "background": "深度神经网络在强化学习算法中的使用已被证明可以提高性能，但同时也增加了计算和内存的复杂性。虽然剪枝技术在监督学习中已被成功应用，但在强化学习中的应用尚属未知领域。", "innovation": "本文提出了一种在高级强化学习算法中结合在线训练与剪枝的方法，特别是在使用在线特征提取网络(OFENet)增强的算法中。提出了一种成本感知、稀疏性促进的正则化方案，该方案针对DenseNet架构的OFENets网络参数复杂性进行了参数复杂性的表示，并在匹配网络复杂度与正则化项时，自动选择这些项的许多超参数，从而结合强化学习目标和网络压缩。", "conclusion": "本文方法在连续控制基准（PyBullet的MuJoCo）和Soft Actor-Critic强化学习代理上进行了评估，结果显示OFENet可以显著剪枝，且性能损失甚微。此外，实验结果表明，训练大网络时剪枝可以产生更高效、更高性能的强化学习代理，而不是从头训练较小的网络。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12224", "html_url": "https://arxiv.org/abs/2507.12224", "title": "优化器定性地更改解决方案，我们应该利用这一点", "title_en": "Optimizers Qualitatively Alter Solutions And We Should Leverage This", "authors": "Razvan Pascanu,Clare Lyle,Ionut-Vlad Modoranu,Naima Elosegui Borras,Dan Alistarh,Petar Velickovic,Sarath Chandar,Soham De,James Martens", "background": "由于深层神经网络（DNNs）的非线性特性，在仅依赖局部信息（如SGD）的优化器下，无法保证最终收敛到损失的唯一全局最小值。这种不确定性曾是深度学习早期的质疑来源。但经过多年的发展，大量的经验研究表明，按照标准训练协议的大规模DNN能够表现出良好的优化动态，最终达到高效的解决方案。这导致了使用凸优化作为学习心理模型的趋势，并侧重于提高优化器的训练效率，比如迭代次数、FLOPs或实际时间。", "innovation": "文章提出，虽然侧重改善优化器效率已经证明非常有效，但特别针对DNNs的另一种视角——优化器不仅影响收敛的速率，还影响学到的解决方案的定性性质——可能得到更少的关注。进一步，作者认为，优化器可以有效编码到学习过程中的诱导偏见，从而改变给定模型类的有效表达能力。优化器还可以被设计为使学习过程产生特定的解决方案特性，而不仅仅是基于收敛率来评估。作者建议研究界应更加关注已存在的方法的偏见，并探索开发新的优化器以明确诱导特定的解决方案特性。", "conclusion": "希望这些论点能够启发研究者改进对学习过程如何影响所收敛解决方案类型的理解，并增强对优化器设计在塑造模型结果中关键杠杆的认识，与其作为架构和数据的角色相补充。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12314", "html_url": "https://arxiv.org/abs/2507.12314", "title": "Thought Purity: 防御类比思维攻击的防御范式", "title_en": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack", "authors": "Zihao Xue,Zhen Bi,Long Ma,Zhenlin Hu,Yan Wang,Zhenfang Liu,Qing Sheng,Jie Xiao,Jungang Lou", "background": "尽管在大型语言模型（LLMs）领域中，通过强化学习训练的大规模推理模型（LRMs，如Deepseek-R1）展示了高级的推理能力，但这些模型对抗安全威胁的脆弱性依然是一个关键漏洞。特别是在逻辑链生成过程中，像后门提示攻击这样的对抗方法可以系统地破坏模型的核心推理机制。新兴的类比思维攻击（CoTA）通过利用提示可控性揭示了这一漏洞，以低成本干预的方式同时削弱了逻辑链的安全性和任务性能。", "innovation": "为了应对这种安全与性能的双重风险，本文提出了一种名为Thought Purity（TP）的防御范式，该范式通过三个协同组件系统地增强了对恶意内容的抵抗力，同时保持了操作效率：(1) 安全优化的数据处理管道；(2) 强化学习增强的规则约束；(3) 适应性监控指标。该方法建立了首个针对CoTA漏洞的防御机制，显著推进了与强化学习对齐的推理系统中的安全和功能平衡，实现了下一代人工智能架构的安全功能权衡.", "conclusion": "本文提出的Thought Purity（TP）是一种全面的防御机制，对抗CoTA漏洞，并在与强化学习对齐的推理系统中显著提升安全功能平衡。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12257", "html_url": "https://arxiv.org/abs/2507.12257", "title": "在实证时序数据中使用幂律进行稳健因果发现", "title_en": "Robust Causal Discovery in Real-World Time Series with Power-Laws", "authors": "Matteo Tusoni,Giuseppe Masi,Andrea Coletta,Aldo Glielmo,Viviana Arrigoni,Novella Bartolini", "background": "探索随机时间序列中的因果关系是一项充满挑战但至关重要的任务，其应用广泛，包括金融、经济、神经科学和气候科学等领域。尽管已经提出了许多因果发现（CD）算法，但这些算法对噪声高度敏感，导致在应用到真实数据时会产生误导性的因果推断.", "innovation": "本文观察到普通真实世界时间序列的频谱遵循幂律分布，这是由于内在自我组织行为的结果。基于此理解，本文构建了一种基于提取幂律频谱特征的稳健CD方法，以放大真实的因果信号。该方法在合成基准和具有已知因果结构的真实世界数据集上均优于现有最先进的算法，展示了其稳健性和实际相关性.", "conclusion": "本研究提出了一种基于幂律频谱特征的稳健因果发现方法，该方法在合成数据和实际数据集上都优于现有方法，表明其在实际应用中的有效性和重要性."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12341", "html_url": "https://arxiv.org/abs/2507.12341", "title": "非线性概念消除：一种密度匹配方法", "title_en": "Nonlinear Concept Erasure: a Density Matching Approach", "authors": "Antoine Saillenfest,Pirmin Lemberger", "background": "在涉及公平性的实际应用中，确保用于文本表示的神经模型不能从文本中推断出敏感信息（如人口统计属性，比如性别或种族）是一项关键挑战。为应对这一挑战，本文提出了概念消除的方法，该方法旨在从分布式表示中移除特定概念的相关信息，同时最大限度地保留剩余的语义信息。这种方法通过学习嵌入空间中的正交投影来实现，投影使得要消除的概念的类条件特征分布难以区分。这种方法能够控制信息移除的程度，同时正交性保证了嵌入空间中局部结构的严格保留。这种方法在经典自然语言处理基准测试中取得了最先进的非线性消除离散属性的表现，并证明了其在深度非线性分类器中有效减少偏差，从而促进公平性", "innovation": "本文提出了一种非线性概念消除方法——$\bar{\text{L}}$\textbf{EOPARD}，该方法使用密度匹配的方式在嵌入空间中学习一个正交投影，使得要消除的概念的类条件特征分布难以区分。通过调整投影器的秩可以控制信息移除的程度，而正交性则确保了嵌入空间局部结构的严格保留。该方法在经典自然语言处理基准测试中取得了最先进的非线性消除离散属性的表现，并且有效减少了深度非线性分类器中的偏差。", "conclusion": "实验结果表明，本文提出的$\bar{\text{L}}$\textbf{EOPARD}方法不仅在非线性概念消除方面表现出色，而且有效减轻了深度非线性分类器中的偏差，从而促进了公平性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12262", "html_url": "https://arxiv.org/abs/2507.12262", "title": "非站定的高斯过程框架及其神经网络参数", "title_en": "A Framework for Nonstationary Gaussian Processes with Neural Network Parameters", "authors": "Zachary James,Joseph Guinness", "background": "高斯过程因其灵活性和不确定性量化已成为非参数回归的流行工具。然而，它们通常使用站定核，这限制了模型的表达性，并且可能不适合许多数据集。", "innovation": "本文提出了一种框架，使用参数在特征空间中变化的非站定核，通过神经网络将特征作为输入来建模这些参数。该方法使用链条规则同时训练神经网络和高斯过程，清晰地描述了非站定参数的行为，并与可扩展到大规模数据集的方法兼容。该方法灵活且容易适应不同的非站定核，无需重新设计优化过程。此外，该方法使用GPyTorch库实现，并且可以灵活修改。", "conclusion": "本文的方法在机器学习数据集上检测了非站定方差和噪声变体的性能，发现其准确性和对数分数优于传统的站定模型和通过变分推断近似的分层模型。仅非站定方差的模型也观察到了类似的结果。同时，本文展示了其方法可以恢复空间数据的非站定参数的能力。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12383", "html_url": "https://arxiv.org/abs/2507.12383", "title": "使用局部逼近提高强化学习样本效率", "title_en": "Improving Reinforcement Learning Sample-Efficiency using Local Approximation", "authors": "Mohit Prashant,Arvind Easwaran", "background": "在无限时间步长的马尔可夫决策过程（MDP）下，本文研究了基于可能正确近似（PAC）的样本复杂度渐近性，指出现有的样本复杂度估计可能不够精确。", "innovation": "本文通过对原始MDP使用子集构建的较小MDP进行局部逼近，减少了样本复杂度。提出了一个样本复杂度为 $O(SA \tau \text{log} A)$ 的PAC-MDP算法，其中 $S$ 和 $A$ 分别是状态空间和动作空间的大小。进一步将结果扩展到无模型的无限时间步长环境。", "conclusion": "通过将算法与前人工作进行实验比较，展示了在样本效率方面的重要改进。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12305", "html_url": "https://arxiv.org/abs/2507.12305", "title": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "title_en": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "authors": "M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk", "background": "在线持续学习（OCL）中的数据隐私限制使得仅在一次出现后便不可见的数据增加了灾难性遗忘问题的复杂性。当前SOTAs通常使用之前类别的示例或特征来回放来处理当前任务。另一种方法是提示法，但它随着可训练参数数量的增长而性能出色。前一种方法可能在实践中不适用，因为面临数据开放政策的限制，而后者则面临与流式数据相关的吞吐量问题。", "innovation": "本研究提出了一种新的基于提示的在线持续学习方法，包括四个主要组成部分：（1）单个轻量级提示生成器作为通用知识，（2）可训练标尺和移位器作为特定知识，（3）预训练模型的通用化保留，（4）硬软更新机制。该方法在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上的性能显著优于当前SOTAs，并且其复杂性分析表明，该方法所需的参数较少，训练、推理时间和吞吐量适中。", "conclusion": "本研究提出的方法在多项数据集上实现了显著的性能提升，并且具有相对较小的参数量和适度的训练、推理时间和吞吐量。此外，还提供了源代码。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12133", "html_url": "https://arxiv.org/abs/2507.12133", "title": "HyDRA：一种基于优化VMD的混合双模式网络用于闭集和开集RFFI", "title_en": "HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD", "authors": "Hanwen Liu,Yuhe Huang,Yifeng Gong,Yanjie Zhai,Jiaxuan Lu", "background": "在无线通信系统中，设备认证对于安全性至关重要，特别是在访问控制等应用场景中。射频指纹识别（RFFI）通过利用硬件引起的信号畸变来提供一种非加密解决方案。然而，现有的方法在处理开集分类任务时通常表现不佳。", "innovation": "本文提出了一种名为HyDRA的混合双模式射频架构，通过结合优化的变分模态分解（VMD）与基于卷积神经网络（CNNs）、变换器和Mamba组件的新型架构，支持闭集和开集分类任务。优化的VMD提高了预处理效率和分类准确度，而HyDRA的变压器动态序列编码器（TDSE）和Mamba线性流量编码器（MLFE）适应了各种条件，展示了在闭集场景中的极佳准确性和在提出的开集分类方法中的鲁棒性能。", "conclusion": "HyDRA在NVIDIA Jetson Xavier NX上的部署实现了毫秒级的推理速度并具有低功耗，为实时无线认证提供了一种实用解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12399", "html_url": "https://arxiv.org/abs/2507.12399", "title": "ROC-n-reroll: 如何影响验证器缺陷对推理时缩放的影响", "title_en": "ROC-n-reroll: How verifier imperfection affects test-time scaling", "authors": "Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang", "background": "推理时缩放旨在通过在推理期间利用额外的计算资源来提高语言模型的性能。尽管许多研究已经从经验上研究了如Best-of-N (BoN)和拒绝采样等技术，但很少深入探讨验证器不完美性如何影响性能。已有研究主要集中在验证器使用背景下的技术和方法上，但缺乏对验证器不完美性影响的理论理解。本研究旨在填补这一空白，通过证明这些方法在实例级上的准确度与验证器的ROC曲线几何关系密切相关，探讨验证器不完美性对测试时缩放的具体影响。", "innovation": "本研究首次证明了实例级准确度可通过验证器的ROC曲线几何关系来精确描述。特别地，拒绝采样和BoN方法的缩放性与ROC曲线的局部和全局特性相关。当ROC曲线未知时，无法基于低计算资源情况外推拒绝采样的性能表现。此外，虽然固定计算情况下拒绝采样表现优于BoN，但在无限计算极限下，两种方法的准确度趋于一致，由ROC曲线在原点附近的斜率决定。这些理论结果通过在GSM8K数据集上使用不同版本的Llama和Qwen进行了实验验证。", "conclusion": "本研究展现了验证器不完美性对测试时缩放性能影响的理论理解，具体体现在实例级准确度与验证器ROC曲线几何性质的关系上。进一步研究了拒绝采样和BoN方法的差异性，并揭示了在无限计算情况下，两种方法均能达到类似水平的准确度。实验证明了理论结果的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12419", "html_url": "https://arxiv.org/abs/2507.12419", "title": "混合光追专家", "title_en": "Mixture of Raytraced Experts", "authors": "Andrea Perin,Giacomo Lagomarsini,Claudio Gallicchio,Giuseppe Nuti", "background": "现有Mixture of Experts (MoE) 架构一般需要固定的计算量以处理给定的样本。这种固定性限制了模型的灵活性和性能优化的空间。因此，需要一种新的方法来克服这些限制，以提升MoE架构的动态性和计算效率。", "innovation": "提出了一种新的MoE架构——混合光追专家，它可以在计算过程中动态选择一系列专家，生成可变宽度和深度的计算图。与现有方法不同，新的方法能够随着计算周期的推进逐步提高预测准确度，且无需负载均衡机制，初步实验显示其训练周期可减少10%-40%，同时保持或提升准确率，为MoE领域引入了新的研究方向，帮助设计更快、更有表现力的模型", "conclusion": "这种方法不需负载均衡机制，且初步实验结果表明其能显著减少训练周期，同时保持或提高准确率，指出了MoE领域新的研究方向，有助于设计更快更强大表达力的模型。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12196", "html_url": "https://arxiv.org/abs/2507.12196", "title": "ONNX模型的可选量化调优", "title_en": "Selective Quantization Tuning for ONNX Models", "authors": "Nikolaos Louloudakis,Ajitha Rajan", "background": "量化是一种降低深度神经网络模型精度以减小模型大小和计算需求的过程，通常以准确性为代价。完全量化的模型可能在低端硬件加速器上表现不佳，面临部署挑战。为了解决这些问题，量化可以只应用于层的一部分，但选择哪些层不进行量化是有挑战性的。", "innovation": "提出了TuneQn，一套允许对ONNX模型进行选择性量化、部署和执行，并结合了性能分析和多目标优化的工具。TuneQn生成选择性量化后的ONNX模型，部署在不同硬件上，在精度和大小等指标上进行测量，利用帕累托前沿最小化来识别最佳模型候选，并提供了可视化结果。", "conclusion": "在四个ONNX模型上使用两种量化设置评估了TuneQn，结果表明TuneQn有效地执行了选择性量化和调优，相比完全量化模型将准确性损失降低了54.14%，相比原始模型将模型大小减少了72.9%。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12412", "html_url": "https://arxiv.org/abs/2507.12412", "title": "NOCTA: 长itudinal数据的非贪婪目标成本权衡获取方法", "title_en": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data", "authors": "Dzung Dinh,Boqi Chen,Marc Niethammer,Junier Oliva", "background": "在许多关键应用中，资源限制了可用于预测的信息量，尤其是在健康医疗领域。患者数据涵盖从实验室测试到成像研究的多种特征，每种特征都有不同的信息量和获取成本。此外，涉及时间序列预测的任务，其实例特征和标签随时间变化，需要在获取特定信息的时机和重要性上做出更复杂的决策。", "innovation": "提出了一种名为NOCTA的非贪婪成本权衡获取方法，可以在推理阶段按顺序获取最具信息性的特征，同时考虑时间动态和获取成本。提出了两种互补的估计器：基于最近邻的非参数方法（NOCTA-NP），以及直接预测潜在获取价值的参数方法（NOCTA-P）。", "conclusion": "在合成和真实医疗数据集上的实验表明，NOCTA的两种变体都优于现有基准。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12384", "html_url": "https://arxiv.org/abs/2507.12384", "title": "由MoS₂闪存基模拟CAM固有的软边界保证的可信树形机器学习", "title_en": "Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries", "authors": "Bo Wen,Guoyun Gao,Zhicheng Xu,Ruibin Mao,Xiaojuan Qi,X. Sharon Hu,Xunzhao Yin,Can Li", "background": "近年来，人工智能技术快速发展，但对其信任度的担忧也随之增加，尤其是在可解释性和鲁棒性方面。尽管随机森林和XGBoost等基于树的模型在表格数据上表现出色且具有解释性，但这些模型的扩展仍然受到计算效率低下的阻碍。以往利用模拟内容寻址存储器（CAM）加速这些模型的努力并未取得成功，主要是因为斜边界的难以实现导致了固有硬件性能较差，并且容易受到对抗性攻击的影响。", "innovation": "本文提出了一种基于MoS₂闪存基模拟CAM的新型硬件软件协同设计方法，该方法具有固有的软边界。这种方法能够在模拟CAM阵列中以高效的方式进行软基于树的模型推理，同时克服了设备变化和对抗性攻击对鲁棒性的影响。实验结果显示，基线方法在WDBC数据库中获得了96%的准确率，同时保留了决策的解释性。研究结果表明，即使在10%设备阈值变化的情况下，模型的准确率也只下降了0.6%，而传统的决策树准确率下降了45.3%。", "conclusion": "本工作为提升人工智能的可信性和效率铺平了道路，开发了基于MoS₂闪存基模拟CAM且具有固有软边界的可加速软基于树的模型推理，并验证了其优越的鲁棒性和准确率。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12453", "html_url": "https://arxiv.org/abs/2507.12453", "title": "成本感知停止策略的贝叶斯优化", "title_en": "Cost-aware Stopping for Bayesian Optimization", "authors": "Qian Xie,Linda Cai,Alexander Terenin,Peter I. Frazier,Ziv Scully", "background": "在自动化机器学习、科学发现及其他贝叶斯优化应用场景中，确定何时停止昂贵的黑盒函数评估是一个重要的实际考量。尽管已经提出了多种自适应的停止规则，但在成本感知场景下，它们缺乏确保在耗费过多函数评估成本前停止的保证。本文旨在提出一个自适应的成本感知停止规则，该规则能够适应不同的评估成本，并且无需参数调优。该规则与当前先进的成本感知获取函数相关，比如 Pandora's Box Gittins Index (PBGI) 和 log 预期改善/成本，文章证明了与这两种获取函数结合时，该停止规则能够同时控制累积评估成本与确保满足性能要求。", "innovation": "提出了一种自适应的成本感知停止规则，该规则能够依据不同的评估成本进行调整，并且无需手动调参。该规则与两种先进的成本感知获取函数（Pandora's Box Gittins Index 和 log 预期改善/成本）相结合，并给出了理论证明，保证在使用这两种获取函数时，停止规则能够有效控制累计评估成本。实验结果显示，该停止规则与 Pandora's Box Gittins Index 获取函数的组合，在成本调整后的简单遗憾度上表现优异或具有竞争力，优于其他获取函数-停止规则的组合。", "conclusion": "本文通过理论分析和实验验证，提出了一种适用于不同评估成本的停止规则，该规则能够与先进的成本感知获取函数结合，有效控制累计评估成本。通过实验证明了，在特定的应用场景下，该停止规则能够有效降低综合成本，提升性能与成本之间的权衡。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12297", "html_url": "https://arxiv.org/abs/2507.12297", "title": "RegCL: 通过模型合并实现分割任何模型的持续适应", "title_en": "RegCL: Continual Adaptation of Segment Anything Model via Model Merging", "authors": "Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang", "background": "现有的方法主要采用基于适配器的一次性适配方式来解决Segment Anything Model (SAM) 在特定领域的性能局限。然而，这些方法大多针对特定领域开发，若应用于其他领域则会导致性能下降。这种灾难性遗忘严重限制了模型的规模化应用。", "innovation": "提出了RegCL，一种新颖的非重播持续学习（CL）框架，旨在通过模型合并高效地整合多领域知识。RegCL通过在持续学习范式中合并SAM的适应模块（如LoRA模块）训练参数，并由权重优化指导合并过程，最小化合并模型与各个领域特定模型之间的预测差异。该方法在保持参数效率（模型大小不变，与任务数量无关）且无需存储历史数据的情况下，有效整合多领域知识。", "conclusion": "实验结果表明，RegCL在多个下游数据集上实现了优越的持续学习性能，验证了其在动态场景中的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11579", "html_url": "https://arxiv.org/abs/2507.11579", "title": "SketchDNN: CAD草图生成的联合连续-离散扩散", "title_en": "SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation", "authors": "Sathvik Chereddy,John Femiani", "background": "在CAD草图生成中，如何同时处理连续参数和离散类别标签是一个挑战。现有方法难以处理几何参数的多样性和基础元素在CAD草图中的排列不变性。提出SketchDNN模型，通过统一的连续-离散扩散过程，同时建模连续参数和离散类别标签，解决了这两个关键问题。", "innovation": "引入了一种高斯-softmax扩散方法，通过在逻辑值中添加高斯噪声并进行softmax转换投影到概率简单体，实现离散变量的混合类别标签。这种方法显著提高了生成质量，降低了Fréchet Inception Distance (FID)和负对数似然（NLL），并在SketchGraphs数据集上达到了新的技术水平。", "conclusion": "通过SketchDNN，作者显著提高了CAD草图的生成质量，建立了新的最佳表现，解决了参数多样性和排列不变性的挑战。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12380", "html_url": "https://arxiv.org/abs/2507.12380", "title": "热核去拓扑", "title_en": "Heat Kernel Goes Topological", "authors": "Maximilian Krahn,Vikas Garg", "background": "拓扑神经网络作为图神经网络的有力继任者浮出水面。然而，拓扑神经网络通常涉及高阶的消息传递，这引起了显著的计算开销。", "innovation": "该研究提出了一种新颖的拓扑框架，通过在组合复形（CCs）上引入拉普拉斯算子来高效计算热核，这些热核作为节点描述符。这种方法能够捕获多尺度信息，并允许对称置换表示，允许将其轻松集成到现代基于Transformer的架构中。理论上，该方法具有最大表达性，因为它可以区分任意非同构的组合复形。实验上，与现有的拓扑方法相比，该方法在计算效率方面表现优异。此外，该方法在标准分子数据集上展示了与最先进的描述符竞争力的性能，在拓扑基准测试中表现出更强的能力来区分复杂的拓扑结构，避免了拓扑空白。", "conclusion": "这一工作推进了拓扑深度学习，提供了表达性和可扩展性兼具的表示，从而开启了分子分类和属性预测任务等激动人心的新研究方向。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11588", "html_url": "https://arxiv.org/abs/2507.11588", "title": "SToFM：空间转录组学的多尺度基础模型", "title_en": "SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics", "authors": "Suyuan Zhao,Yizhen Luo,Ganbo Yang,Yan Zhong,Hao Zhou,Zaiqing Nie", "background": "空间转录组学（ST）技术为生物学家提供了丰富的单细胞生物学见解，同时保留了细胞的空间上下文。构建ST的基础模型可以显著提高对庞大而复杂的数据源的分析能力，揭示生物组织细微复杂的视角。然而，建模ST数据具有内在挑战性，因为需要从包含大量细胞的组织切片中提取多层次的信息。这一过程需要整合宏观级别的组织形态学、微观级别的细胞微环境以及基因级别的基因表达模式。", "innovation": "本文提出了多尺度空间转录组学基础模型（SToFM）。SToFM首先对每个ST切片进行多层次信息提取，构建包括宏观、微观和基因级别的信息集合，并使用SE(2)变压器获取高质量的细胞表示。此外，还构建了SToCorpus-88M，这是迄今为止最大的高分辨率空间转录组学语料库用于预训练。", "conclusion": "SToFM在多种下游任务中（如组织区域语义分割和细胞类型注释）表现出色，证明了其对ST数据的全面理解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11638", "html_url": "https://arxiv.org/abs/2507.11638", "title": "使用变分自编码器在直肠癌MRI中解释预测淋巴结转移", "title_en": "Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders", "authors": "Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton", "background": "直肠癌的有效治疗依赖于准确的淋巴结转移（LNM）分期。然而，基于淋巴结（LN）大小、形状和纹理形态的影像学标准诊断准确度有限。本研究基于此背景，探讨使用变分自编码器（VAE）作为特征编码模型，替代现有方法中使用的大型预训练卷积神经网络（CNN），来提高淋巴结转移的预测准确度。", "innovation": "该研究采用了变分自编码器（VAE）作为特征编码模型，旨在通过重建图像直接编码视觉特征和有意义的模式，创造出更易于解释的非纠缠和结构化的潜在空间。研究结果显示，所提出的模型'VAE-MLP'在MRI数据集上表现优异，达到了AUC 0.86 ± 0.05，敏感性 0.79 ± 0.06 和特异性 0.85 ± 0.05 的交叉验证指标。", "conclusion": "该研究通过在直肠癌MRI数据集上部署所提出的VAE-MLP模型，实现了目前的最好性能，验证了VAE作为一种生成模型在编码影像特征方面的优势。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11642", "html_url": "https://arxiv.org/abs/2507.11642", "title": "根据姿势进行游戏风格和疲劳评估的动作意图推断", "title_en": "Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment", "authors": "Abhishek Jaiswal,Nisheeth Srivastava", "background": "姿势驱动的心理状态推断在诊断疲劳、预防伤害和提高各种领域表现方面具有显著潜力。为了在实践中应用这些工具，它们需要通过大型数据集进行研究验证。然而，基于视觉的心理推断面临着由于人类隐私数据敏感性较高的挑战。因此，研究者选择了体育情境作为获取不同情感状态人类数据的有效替代方案，并在板球游戏中测试了这一假设，通过动作分析确定了姿势在意图推断中的重要作用。同时，利用现有的数据分析作为弱监督，验证了研究结果，从而解决数据标注的局限性。这项研究为体育分析提供了可泛化的技术，并为跨领域的人类行为分析打开了可能性。", "innovation": "该研究创新地利用体育情境来收集人类在多种情感状态下的数据，并通过姿势分析识别运动中的攻击性和防守性意图，实现了超过75%的F1分数和超过80%的AUC-ROC，在运动数据中表现出显著的意图推断能力。此外，该研究还提出使用现有数据统计作为弱监督，来验证研究发现，解决数据标注问题，为泛化技术提供了可能性。", "conclusion": "该研究通过姿势驱动的方法，在板球游戏中成功评估了玩家风格并对疲劳进行了评估。研究结果表明姿势对意图推断的影响显著，即使数据管道存在内在噪音。研究成果促进了体育分析的通用技术，同时也为跨领域的人类行为分析提供了可能性。此外，利用现有数据统计作为弱监督的方法为解决数据标注难题提供了一种途径。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11544", "html_url": "https://arxiv.org/abs/2507.11544", "title": "The Safety Gap Toolkit: 评估开源模型隐藏危险的工具", "title_en": "The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models", "authors": "Ann-Kathrin Dombrowski,Dillon Bowen,Adam Gleave,Chris Cundy", "background": "开放型大语言模型（LLMs）在创新、个性化、隐私和民主化方面提供巨大益处。然而，它们的核心优势——可修改性，带来了系统性风险：不良行为者可以轻易绕过现有保护措施，将有益模型转变为有害工具。这导致了一个‘安全缺口’：具有完整保护措施的模型与被剥夺保护措施的模型之间危险能力的差异。", "innovation": "作者提出了一个开源工具包（Safety Gap Toolkit），用于估算尖端开放型模型的安全缺口。实验涵盖不同参数规模（0.5B到405B）下来自两个模型家族（Llama-3和Qwen-2.5）的生物化学和网络能力、拒绝率和生成质量的变化，以不同方式去除保护措施。结果显示，随着模型规模的增加，安全缺口扩大，去除保护措施后，有效危险能力显著增长。", "conclusion": "该安全缺口工具包将作为常用开源模型的评估框架，并激励开发和测试防篡改保护措施。作者呼吁社区贡献，以完善该工具包。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12218", "html_url": "https://arxiv.org/abs/2507.12218", "title": "物理学启发线性模型（PILM）：分析表示及其在地壳应变速率估计中的应用", "title_en": "Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation", "authors": "Tomohisa Okazaki", "background": "许多物理系统可以通过偏微分方程（PDEs）描述，从观测数据中求解这些方程及其系数或边界条件（BCs）对于理解相关现象至关重要。近年来，一种被称为物理启发神经网络（PINN）的机器学习方法引起了科学界的广泛关注。PINN通过最小化从PDEs、BCs和数据的残差来使用神经网络求解PDEs。在此研究中，我们探讨了一种基于线性基函数表示解的物理学启发线性模型（PILM），以提供一种可解析的最优解。该模型针对有不确定边界条件的示例正问题和反问题进行了推导和验证，并应用于地壳应变速率估计。", "innovation": "本文提出的PILM使用线性组合的基函数来表示解，从而提供了一种解析表示最优解的框架。与传统的PINN相比，PILM能够在不使用复杂的神经网络的情况下处理线性正问题和逆问题，适用于欠定系统。此外，该模型还引入了物理正则化和数学正则化的概念，从贝叶斯角度考虑，数学正则化展示了更好的性能。", "conclusion": "PILM提供了一种适用于线性正问题和逆问题、欠定系统和物理正则化的解析求解框架。该方法在地壳应变速率估计中展示了其稳健性和有效性，同时也为进一步研究提供了坚实的基础。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11623", "html_url": "https://arxiv.org/abs/2507.11623", "title": "气候相关机器人研究路线图", "title_en": "A Roadmap for Climate-Relevant Robotics Research", "authors": "Alan Papalia,Charles Dawson,Laurentiu L. Anton,Norhan Magdy Bayomi,Bianca Champenois,Jung-Hoon Cho,Levi Cai,Joseph DelPreto,Kristen Edwards,Bilha-Catherine Githinji,Cameron Hickert,Vindula Jayawardana,Matthew Kramer,Shreyaa Raghavan,David Russell,Shide Salimi,Jingnan Shi,Soumya Sudhakar,Yanwei Wang,Shouyi Wang,Luca Carlone,Vijay Kumar,Daniela Rus,John E. Fernandez,Cathy Wu,George Kantor,Derek Young,Hanumant Singh", "background": "气候变化是21世纪的一个决定性挑战，许多机器人领域的专家都在寻找贡献的方式。本文提出了一个气候相关的机器人研究路线图，旨在推动机器人学家与其他气候领域专家（如能源、建筑环境、交通运输、工业、土地利用和地球科学）之间的合作机会，解决诸如能源系统优化、建筑翻新、精准农业、建筑围护结构改造、自动驾驶卡车和大规模环境监测等高影响气候相关问题。这项工作是由来自不同气候学科的机器人研究人员和领域专家合作完成的，它向机器人社区发出号召，呼吁他们将专业知识应用于紧迫的气候优先问题之上", "innovation": "本文的重点是不仅应用物理机器人，还包括更广泛的机器人工具箱，包括规划、感知、控制和估算算法，来解决气候相关问题。文章的目的是激励新的研究方向并促进机器人与气候交叉领域的合作，通过标志性、可操作的问题", "conclusion": "本文是机器人研究人员与各种气候学科领域专家合作的成果，旨在邀请机器人社区将其专业知识应用到紧迫的气候优先问题上，从而推动气候变化相关机器人研究的进展。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12435", "html_url": "https://arxiv.org/abs/2507.12435", "title": "Targeted Deep Architectures: 基于TMLE的稳健因果推断神经网络框架", "title_en": "Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks", "authors": "Yi Li,David Mccoy,Nolan Gunter,Kaitlyn Lee,Alejandro Schuler,Mark van der Laan", "background": "现代深度神经网络是强大的预测工具，但在因果参数如治疗效果或整个生存曲线的有效推断方面往往不足。现有的框架如双重机器学习（DML）和目标最大似然估计（TMLE）可以解决这一问题，但现有的神经网络实现存在限制。一方面，它们依赖于“目标损失”，但这些损失不能保证解决有效影响函数方程；另一方面，在多参数设置中，后处理波动计算成本高昂。本文提供了Targeted Deep Architectures（TDA），这是一种直接将TMLE嵌入到网络参数空间内的新框架，且不对底层架构作任何限制。TDA通过冻结所有参数但一个小“目标”子集来分割模型参数，并迭代地沿着源自目标函数与权重梯度投影夹角的影响函数梯度进行更新。", "innovation": "TDA框架直接将TMLE嵌入到网络的参数空间中，不依赖特定的底层架构。TDA通过分割和迭代更新参数来减少第一阶偏差并生成渐近有效置信区间。更重要的是，TDA容易扩展到多维因果指标（如整个生存曲线），通过合并单独的目标梯度到一个统一的目标更新。理论方面，TDA继承了经典的TMLE特性，包括双重稳健性和半参数效率。实证研究中，TDA在基准IHDP数据集（平均治疗效果）和含有信息性删失的模拟生存数据上，相较于标准神经网络和之前的后处理方法，显著减少了偏差并提高了覆盖率。", "conclusion": "TDA为在现代深度架构中进行复杂的多参数目标的严格因果推断提供了一条直接且可扩展的方式。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11692", "html_url": "https://arxiv.org/abs/2507.11692", "title": "使用生成式人工智能进行星系图像简化", "title_en": "Galaxy image simplification using Generative AI", "authors": "Sai Teja Erukude,Lior Shamir", "background": "现代数字天空调查获得了数十亿星系的图像，这些图像通常包含足够的细节来分析星系的形状，但准确分析这些大量图像需要有效的自动化。当前的解决方案通常依赖于基于预定义类别的机器学习对星系图像进行注解。", "innovation": "我们提出了一种基于生成式AI的新的星系图像分析方法，它可以简化星系图像并自动将其转换成一种“骨架化”形式。简化后的图像允许精确测量星系形状，而不局限于某些预定义的类别。这种方法被应用到DESI遗留调查获取的图像上，展示了其实用性。", "conclusion": "该方法成功应用于125,000张DESI遗留调查图像，并且简化后的图像目录已公开可用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11636", "html_url": "https://arxiv.org/abs/2507.11636", "title": "JSQA: 以感知启发对比预训练为基础的基于JND音频配对的语音质量评估", "title_en": "JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs", "authors": "Junyi Fan,Donald Williamson", "background": "语音质量评估（SQA）通常用于从高维度输入空间映射到一个代表感知语音质量的平均意见评分（MOS）的标量。这种映射由于感知和实验设计的差异，MOS展现出高水平的内在方差，使得学习这样的映射具有挑战性。尽管已经提出了许多解决方案，但许多方法并未在学习算法中恰当地纳入感知因素（超过MOS标签），可能导致结果不尽如人意。", "innovation": "本文提出JSQA，这是一种两阶段框架，首先使用刚可察觉差异（JND）配对进行感知引导对比学习预训练一个音频编码器，然后进行微调以预测MOS。通过从清洁的LibriSpeech片段中混入来自CHiME-3的背景噪声生成JND水平内的音频数据配对，用于预训练编码器，它可以利用感知质量相似性信息并将其映射到嵌入空间。之后，编码器使用NISQA数据集中的音频样本进行微调以预测MOS。实验结果表明，感知启发对比预训练显著提高了与无预训练从头开始训练的同一网络相比的模型性能。这些发现表明，在预训练中纳入感知因素大大促进了SQA性能的提高", "conclusion": "通过感知启发对比预训练显著改善了模型性能，表明在预训练阶段纳入感知因素对SQA有很大的贡献。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11768", "html_url": "https://arxiv.org/abs/2507.11768", "title": "大型语言模型在预期意义上是贝叶斯的，但在实现中不是", "title_en": "LLMs are Bayesian, in Expectation, not in Realization", "authors": "Leon Chlon,Sarah Rashidi,Zein Khamis,MarcAntonio M. Awada", "background": "大语言模型展示了显著的上下文学习能力，能够在无需参数更新的情况下适应新任务。尽管这种现象可以用隐式贝叶斯推理模型来解释，但最近的实验证据揭示了一个根本性的矛盾：变换器系统地违反了鞅性质这一贝叶斯更新在可交换数据上的关键要求。这种违反挑战了对关键应用中不确定性量化理论基础的了解。", "innovation": "论文通过理论分析得到了四个关键结果：（1）位置编码导致了订单内约 $O(\frac{\text{log} n}{n})$ 的鞅违反；（2）变换器以信息论最优的方式达到期望排列下的超额风险 $O(n^{-1/2})$；（3）隐式的后验表示在必要统计量的空间里收敛到真实的贝叶斯后验分布；（4）作者导出了最优的思维链长度为 $k^* = \theta(\text{sqrt}(n)\text{log}(1/\text{ε}))$，并提供了详细的常数，为同时减少推理成本和保持性能提供了原则性的方法。", "conclusion": "论文的框架提供了从位置感知架构中提取校准不确定性估计的实际方法，并优化部署中计算效率。在 GPT-3 上的实证验证确认了预测（1）至（3），其中变换器在20个样本内达到了理论熵极限的99%。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12439", "html_url": "https://arxiv.org/abs/2507.12439", "title": "一种针对抗毒联邦学习的贝叶斯激励机制", "title_en": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning", "authors": "Daniel Commey,Rebecca A. Sarpong,Griffith S. Klogo,Winful Bagyl-Bac,Garth V. Crosby", "background": "联邦学习（FL）允许在不集中存储数据的情况下进行模型训练，同时保护数据隐私。然而，其开放参与的特性使其容易受到数据污染攻击的影响，恶意行为者可以提交篡改的模型更新来降低全局模型的质量。现有的防护措施通常是被动的，依赖于统计聚合规则，这些规则可能计算成本高昂，并且通常假设大多数参与者诚实。", "innovation": "本文提出了一个前瞻性的、基于经济激励的防护机制：一个轻量级的贝叶斯激励机制，使得恶意行为从经济上变得不合理。在每次训练循环中，服务器作为主要的一方，会利用一小部分私有的验证数据集来验证更新的质量，然后再发放支付。设计满足有益客户的个体理性（IR）和激励相容性（IC），确保他们的参与是有利可图的，并使污染成为经济上占优的战略。", "conclusion": "通过在MNIST和FashionMNIST上的非同态划分进行的实验，验证了机制的有效性：即使50%的标签翻转攻击者存在，机制也能保持96.7%的准确性，比同态30%翻转情况下的准确性低0.3个百分点。这一结果比标准的FedAvg算法在相同的50%攻击下表现出了51.7个百分点的优越性。机制计算上轻量级，预算有上限，并能轻松地整合到现有的联邦学习框架中，提供了一条实现经济上稳健和可持续的联邦学习生态系统的方法。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11683", "html_url": "https://arxiv.org/abs/2507.11683", "title": "PGT-I: 采用内存高效分布式训练扩展时空GNN", "title_en": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training", "authors": "Seth Ockerman,Amal Gueroudji,Tanwi Mallick,Yixuan He,Line Pouchard,Robert Ross,Shivaram Venkataraman", "background": "时空图神经网络（ST-GNNs）能够有效地建模空间和时间数据之间的依赖关系，但由于内存限制，其应用主要局限于小规模数据集。现有分布式训练框架虽然提供了解决方案，但缺乏对时空模型的支持，并且忽视了时空数据的特性。基于对大规模工作负载的研究，提出了一种扩展PyTorch Geometric Temporal的方法——PyTorch Geometric Temporal Index（PGT-I），该方法结合了分布式数据并行训练以及两种新的策略：索引批处理和分布式索引批处理。", "innovation": "PGT-I整合了分布式数据并行训练，并引入了两种新的策略：索引批处理和分布式索引批处理。这两种新技术利用时空结构，在运行时动态构建快照，大幅减少了内存开销。而分布式索引批处理进一步通过在多个GPU之间扩展该方法，实现了可扩展的处理能力。这些技术使得ST-GNN能够在不进行图分割的情况下首次应用于整个PeMS数据集，降低峰值内存使用率高达89%，并在128个GPU配置下比标准DDP方法实现高达13.1倍的加速。", "conclusion": "PGT-I通过索引批处理和分布式索引批处理，实现了时空图神经网络的高效分布式训练，显著降低了内存使用，并提高了处理速度。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11830", "html_url": "https://arxiv.org/abs/2507.11830", "title": "Arctic Inference with Shift Parallelism: 快速高效的开源推理系统为企业AI", "title_en": "Arctic Inference with Shift Parallelism: Fast and Efficient Open Source Inference System for Enterprise AI", "authors": "Samyam Rajbhandari,Mert Hidayetoglu,Aurick Qiao,Ye Wang,Juncheng Yang,Jeff Rasley,Michael Wyatt,Yuxiong He", "background": "现有的AI推理系统在处理延迟、吞吐量和成本之间的权衡时存在局限性，当前的AI工作负载主要是推理。", "innovation": "Arctic Inference 是一个开源插件，基于 Shift 并行策略，结合推测性解码、SwiftKV计算减少和优化向量内积推理，显著提升了请求完成速度、生成速度以及每GPU每秒生成的标记数。", "conclusion": "Arctic Inference 已经支持 Snowflake Cortex AI，并在成本效益方面表现出卓越的性能，适用于企业的AI推理需求，现在向社区开放使用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11687", "html_url": "https://arxiv.org/abs/2507.11687", "title": "MetaLint: 通过指令遵循和易到难泛化实现可泛化的模式化代码质量分析", "title_en": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization", "authors": "Atharva Naik,Lawanya Baghel,Dhakshin Govindarajan,Darsh Agrawal,Daniel Fried,Carolyn Rose", "background": "大型语言模型在代码生成方面取得了一定的成功，但在代码质量分析方面存在不足，主要受限于静态训练数据，难以适应不断变化的最佳实践。现有的方法通常是在静态、基于规则的数据上进行模型训练，这限制了模型适应新型或复杂代码模式的能力。针对这一问题，本文介绍了一种新的指令遵循框架MetaLint，旨在通过检测和修复具有高层次规格的有问题的语义代码片段或代码惯用语来进行代码质量分析。", "innovation": "MetaLint 不同于传统的直接在静态数据上训练模型的方法，其通过指令调优结合合成的代码校验工具生成的数据来进行模型训练，从而支持从简单到复杂的泛化，使得模型能够在无需重新训练的情况下适应新型或复杂的代码模式。通过诸多基准测试，MetaLint 显示出在新型 Python 进步提案 (PEP) 惯用语检测上的卓越表现，尤其是在新颖惯用语检测方面的泛化能力方面，达到70.37%的F分数，具有最高的召回率（70.43%）。另外，即使在较小的参数规模下（4B），该模型在定位方面仍表现出色，竞争力和最新的大型先进模型相当，如o3-mini。", "conclusion": "MetaLint通过指令遵循框架和易到难泛化方式提高了代码质量分析的可泛化性，尤其是在应对新型 Python 进步提案惯用语方面的表现尤为突出。MetaLint 在 F分数（70.37%）和召回率（70.43%）方面表现出色，证明了其在未来的代码质量分析中的潜在价值。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11625", "html_url": "https://arxiv.org/abs/2507.11625", "title": "MapIQ: 评估多模态大型语言模型在地图问答中的基准数据集", "title_en": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "authors": "Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski", "background": "近年来，多模态大型语言模型（MLLMs）的发展促使研究人员探索这些模型在解读数据可视化方面的能力，例如柱状图和散点图。最近，注意力转向地图可视化问答（Map-VQA）。然而，Map-VQA研究主要集中在半色调地图上，这些地图仅仅涵盖了有限的主题类别和视觉分析任务。这项研究填补了这一空白，推出了MapIQ数据集，其中包含14,706个关于三种类型地图——半色调地图、迪卡尔投影和等值线符号地图——问题-答案对，这些地图覆盖了六个不同主题（例如，住房、犯罪）下的视觉分析任务。", "innovation": "MapIQ是一个基准数据集，包括14,706个问题-答案对，覆盖了三种不同类型的地图——半色调地图、迪卡尔投影和等值线符号地图，共计六个不同的主题。此外，该研究还通过评估多个MLLMs使用六种视觉分析任务，并与人类基准进行比较，揭示了MLLMs的稳健性和敏感性，以及它们对内部地理知识的依赖性。另外，该研究还探讨了地图设计变化（例如，颜色方案的改变、图例设计的修改、地图元素的移除）对MLLMs性能的影响。", "conclusion": "研究成果提供了有关MLLMs在Map-VQA方面的性能，以及这些模型的可靠性和对地理知识的依赖性的新见解。同时，研究为改进和优化Map-VQA系统提供了可能的方向。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11842", "html_url": "https://arxiv.org/abs/2507.11842", "title": "CosmoFlow：通过流动匹配进行宇宙学中的尺度意识表示学习", "title_en": "CosmoFlow: Scale-Aware Representation Learning for Cosmology with Flow Matching", "authors": "Sidharth Kannan,Tian Qiu,Carolina Cuesta-Lazaro,Haewon Jeong", "background": "生成性机器学习模型已经被证明能够学习保留下游任务所需信息的数据低维表示。研究工作展示了基于流匹配生成模型的能力，能够在不监督的情况下学习场级冷暗物质（CDM）模拟数据的紧凑且语义丰富的潜在表示。模型CosmoFlow学习到的表征相较于原始场数据小32倍，且适用于场级重建、合成数据生成和参数推断。此外，该模型学习到的表征具有可解释性，不同潜在通道对应不同宇宙学尺度的特征。这种模型在处理大规模宇宙学数据时提供了有效的表示学习方法，能够减少数据维度并提高效率。", "innovation": "提出了一种基于流匹配的生成模型CosmoFlow，能够在无监督情况下学习到紧凑且语义丰富的低维潜在表示，适用于冷暗物质模拟数据的场级重建、合成数据生成和参数推断，并且表征具有可解释性，能够对应不同宇宙学尺度的特征。", "conclusion": "研究工作展示了流匹配生成模型在不监督的情况下能够高效地学习到紧凑且语义丰富的潜在表示，适用于大规模宇宙学数据处理。模型CosmoFlow的学习表征相较于原始数据小32倍，并可以应用于多个下游任务，展示了其在实际应用中的潜在价值。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "几何问题求解中的深度学习研究", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题求解是数学推理的一个关键领域，广泛涉及教育、人工智能数学能力评估以及多模态能力评估等多个重要领域。近年来，随着深度学习技术的迅速发展，特别是多模态大型语言模型的兴起，引发了对该领域的广泛研究热潮。", "innovation": "本文提供了一篇关于深度学习在几何问题求解中的应用的综述，包括(i)全面总结几何问题求解相关任务；(ii)深入审查相关深度学习方法；(iii)详细分析评估指标和方法；(iv)探讨当前挑战与未来研究方向。", "conclusion": "本文旨在为几何问题求解中的深度学习提供全面和实用的参考，以促进该领域进一步的发展。我们创建了一份在GitHub上持续更新的论文列表：https://thishttpsURL."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11780", "html_url": "https://arxiv.org/abs/2507.11780", "title": "通过平滑进行最优政策值和其他不规则泛函的推断", "title_en": "Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing", "authors": "Justin Whitehouse,Morgane Austern,Vasilis Syrgkanis", "background": "在因果推断中，建立信心区间以估计最优治疗策略的价值是一个重要的问题。了解最优策略的价值可以指导奖励最大化、个体制定治疗方案的发展。然而，由于定义最优价值的功能是不可微的，标准半参数推断方法无法直接应用。现存处理这种不可微性的方法大致分为两类。第一类是在构建最优价值的光滑近似的基础上进行估计的方法，这类方法计算简便，但通常在结果回归上假设不现实的参数。另一类方法直接对非光滑目标进行了反倾向估计，这类方法不需要在麻烦的潜在函数上假设参数，但要么需要计算难以实施的大量潜在估计，要么假设不现实的 $L^\theta$ 局部收敛速率，或者做出禁止对治疗不反应的强边缘假设。本文重审了非可微函数的光滑近似构造问题，通过精确控制一阶偏差和二阶余项，表明基于软最大化平滑方法可以用于估算某些包含未知成分的最大得分参数，这本质上包括最优治疗策略的价值。我们的估计器获得了 $\frac{1}{\root \nof {n}}$ 的收敛速度，避免了参数限制和不现实的边缘假设，且通常统计效率高。", "innovation": "本文通过精细控制一阶偏差和二阶余项，实现了基于软最大化平滑方法的估计器，避免了以往方法中的参数限制和不现实的边缘假设问题，同时实现了 $\frac{1}{\root \nof {n}}$ 的收敛速度，并且通常具备统计效率。这种方法既可以估计最优治疗策略的价值，也可以应用于其他涉及不规则泛函的问题。", "conclusion": "本文提出了另一种有效的推断方法来解决不可微函数的问题，通过平滑的方式避免了参数假设，提高了估计的效率并给予了更强的适用性。这种方法既适用于最优治疗策略价值的估计，也适用于其它相关问题的估计。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11809", "html_url": "https://arxiv.org/abs/2507.11809", "title": "事实还是复制？大型语言模型中机制竞争的批判性探究", "title_en": "Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models", "authors": "Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss", "background": "本文研究大型语言模型（LLMs）处理事实和 counterfactual 信息的竞争机制，特别是关注注意力头在这一过程中的作用。研究通过机制可解释性工具重现并统一了 Ortu 等人、Yu、Merullo 和 Pavlick 以及 McDougall 等人三项近期研究的结果，这些研究探讨了模型学习的事实与矛盾背景信息之间的竞争。", "innovation": "研究特别考察了注意力头强度与事实输出比例之间的关系，评估了关于注意力头抑制机制的竞争假设，并调查了这些注意力模式的领域特定性。研究发现，促进事实输出的注意力头通过广泛复制抑制而不是选择性 counterfactual 抑制来实现；增强这些注意力头还会抑制正确事实。此外，还展示了注意力头的行为依赖于领域，大型模型表现出更专业化和类别敏感的模式。", "conclusion": "本研究表明，促进事实产出的注意力头通过广泛复制抑制而非选择性 counterfactual 抑制机制实现。还发现，注意力头的行为具有领域依赖性，大型模型表现出更专业化和类别敏感的模式。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11891", "html_url": "https://arxiv.org/abs/2507.11891", "title": "在数据共享下选择更好的旋钮算法：A/B实验在何时起作用？", "title_en": "Choosing the Better Bandit Algorithm under Data Sharing: When Do A/B Experiments Work?", "authors": "Shuangning Li,Chonghuan Wang,Jingyan Wang", "background": "已有研究指出，标准的差均值估计器在由于实验单元之间特有的交互影响下，存在对于全局治疗效应（GTE）的偏差估计问题。这种交互影响是由于治疗组和对照组的算法共享数据，进而训练该两组算法，导致了两种组间的干扰。通常将这种由于数据共享导致的偏差称为“共生偏差”。本文进一步指出，在决策制定中，GTE的符号比其精确值更为重要，特别是在选择更优的推荐算法时。", "innovation": "论文在多手臂老虎机框架下，形式化地阐述了GTE符号与真实GTE符号一致或不一致的条件。通过分析发现，探索与利用的程度是决定共生偏差对算法选择影响的关键因素。这一研究为理解和改善A/B实验的结果提供了新的视角和理论支持。", "conclusion": "研究认为，A/B实验在数据共享的情况下，对于符号估计的GTE是否与真实GTE符号一致与算法选择有重要关系，并且这一结果主要取决于算法选择中的探索和利用之间的平衡。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11851", "html_url": "https://arxiv.org/abs/2507.11851", "title": "你的LLM预见未来：发掘其多令牌预测潜力", "title_en": "Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential", "authors": "Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar", "background": "自回归语言模型受限于其固有的顺序性，每次只能生成一个令牌。这种模式限制了推理速度和并行性，尤其是在生成文本的后期阶段，此时文本的方向和语义相对确定。", "innovation": "本文提出了一种创新框架，充分利用了简易自回归语言模型对未来令牌的固有知识，结合多种技术实现了同时预测多个后续令牌的潜力。该创新包括：（1）遮蔽输入公式，共同前缀下多未来令牌联合预测；（2）门控LoRA公式，保持原始LLM功能，同时具备多令牌预测能力；（3）轻量级可学习采样模块生成连贯序列；（4）一系列辅助训练损失，包括一致性损失，以提高协同生成令牌的一致性和准确性；（5）一种猜测生成策略，未来令牌成平方扩展，同时保持高保真度。", "conclusion": "通过监督微调预训练模型，该方法实现了显著的速度提升。例如，代码和数学生成速度加快约5倍，一般对话和知识任务提升近2.5倍。这些增益并未牺牲质量。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11806", "html_url": "https://arxiv.org/abs/2507.11806", "title": "MOFSimBench: 评估通用机器学习键间势在金属-有机框架分子模拟中的性能", "title_en": "MOFSimBench: Evaluating Universal Machine Learning Interatomic Potentials In Metal--Organic Framework Molecular Modeling", "authors": "Hendrik Kraß,Ju Huang,Seyed Mohamad Moosavi", "background": "通用机器学习键间势（uMLIPs）已成为加速原子尺度模拟的强大工具，提供了可扩展和高效的建模方法，其准确度接近量子计算。然而，它们在实际应用中的可靠性和有效性仍然存在疑问。多孔金属有机框架（MOFs）及相关纳米多孔材料是具有关键应用价值的多孔晶体，用于碳捕获、能源存储和催化。但由于这些材料具有多种化学性质、结构复杂性，包括多孔性和配位键，且缺乏现有训练数据集，因此很难通过对uMLIPs建模这些材料。", "innovation": "过去的研究缺乏针对纳米多孔材料的基准测试。本文提出了MOFSimBench基准测试，评估uMLIPs在纳米多孔材料建模任务中的性能，包括结构优化、分子动力学（MD）稳定性、预测宏观性质如宏观模量和热容以及客体-宿主相互作用。研究发现，性能最佳的uMLIPs在所有任务中均超越了经典力场和微调的机器学习势场，表明它们已准备好部署于纳米多孔材料建模中。研究还指出，数据质量，特别是训练集的多样性及包含非平衡构象，比模型架构更重要，决定了评估的所有uMLIPs的性能。MOFSimBench基准测试框架目前已经模块化和可扩展的形式发布，为纳米多孔材料建模的采用和发展提供了一项开放资源共享。", "conclusion": "通过评估20多种不同架构的uMLIPs，我们的研究证明了uMLIPs在纳米多孔材料模型中的优越性能，尤其是在数据质量和模型架构的选择上进行了深入分析，为优化未来uMLIPs的发展提供了指导。我们发布了MOFSimBench基准测试框架，期望能够促进纳米多孔材料模型的开发和应用，进一步推动uMLIPs的研究。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11895", "html_url": "https://arxiv.org/abs/2507.11895", "title": "新影响：提升高维度下的模型可解释性和理解", "title_en": "Newfluence: Boosting Model interpretability and Understanding in High Dimensions", "authors": "Haolin Zou,Arnab Auddy,Yongchan Kwon,Kamiar Rahnama Rad,Arian Maleki", "background": "随着机器学习（ML）和人工智能（AI）模型的日益复杂化，科学家、工程师和政策制定者在解释和改进模型决策及预测方面需要专门的工具。传统的影子函数法源于稳健统计学，被用于这一目的，但它基于参数数量p远小于观测数量n的低维度假设，而现代AI模型通常在高维度下工作，使得这些假设难以维持。因此，影子函数的功效在高维度下受到了质疑。", "innovation": "本文介绍了新的近似方法“Newfluence（新影响）”，它在保持相似计算效率的同时提供了显著改进的准确性。这种方法旨在提供比许多现有方法更准确的复杂AI模型的解释和诊断。本文还提出了一种新的高维度框架，可以应用于分析诸如Shapley值在内的其他流行技术。", "conclusion": "影响函数在高维度下无法可靠实现其预期目的，而新引入的Newfluence方法提供了更准确的见解，尤其是在理解和解释复杂的AI模型方面。此外，开发的高维度框架还可应用于分析其他流行的技术。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11662", "html_url": "https://arxiv.org/abs/2507.11662", "title": "让我们分步思考：通过自我扎根验证缓解MLLMs的共识偏差", "title_en": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "authors": "Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira", "background": "验核者——分配奖励给智能体行为的函数——在数学和棋盘游戏等领域的人工智能进步中发挥了关键作用。然而，将这些进展扩展到缺乏明确成功标准的领域（如计算机使用）仍面临挑战：尽管人类能识别合适的结果，但将这种直觉转化为可扩展的规则是具有挑战性的。多模态大型语言模型(MLLM)因其世界知识、与人类偏好的对齐和推理技能，被视为一种有希望的解决方案。论文评估了MLLM作为跨网络导航、计算机使用和机器人操作的智能体轨迹验核器的可能性，并指出了一个关键限制：共识偏差，其特点是MLLM强烈倾向于重视其上下文窗口中的信息，通常会生成论证来合理化错误行为。这种偏差在模型间普遍存在，即使在测试时也具有弹性，并可能影响使用MLLM作为评估工具的多种方法（如数据过滤）。尽管如此，MLLM显示出强烈的人文一致的先验结果偏好。", "innovation": "论文提出了一种名为自我扎根验证（SGV）的轻量级方法，通过利用MLLM自身的采样机制（针对生成性生成和条件生成），使MLLM能够更有效地运用其知识和推理能力来缓解共识偏差问题。SGV包含两个步骤：首先，MLLM被激励去检索与任务完成有关的广泛先验知识，与正在评估的数据无关；然后，根据自我生成的先验知识，它会推理并评估候选轨迹。通过SGV增强的MLLM验核器在准确性和失败检测率上分别提高了最多20个点，并能够实现实时监督异构智能体，提高了GUI专家在OSWorld中的任务完成率、机器模仿中的扩散策略性能以及VisualWebArena中的ReAct智能体性能。这在基准测试中达到了新的最佳状态，超越了之前的最佳结果48%。", "conclusion": "MLLM作为验核器的研究中显示出共识偏差，尽管它们展示了强烈的人文一致先验结果偏好。引入SGV后，MLLM验核器在准确性和失败检测方面有了显著提升，并能够在现实场景中有效监督多样化的智能体，实现了高性能。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11950", "html_url": "https://arxiv.org/abs/2507.11950", "title": "RNAMunin：一种用于非编码RNA发现的深度机器学习模型", "title_en": "RNAMunin: A Deep Machine Learning Model for Non-coding RNA Discovery", "authors": "Lauren Lui,Torben Nielsen", "background": "微生物组测序中，功能注释往往侧重于蛋白质编码基因，而大量非编码RNA（ncRNAs）的功能亟待探索，这些ncRNAs在调控细菌和古菌生理学、应激反应和代谢过程中起着关键作用。直接从基因组序列中识别ncRNAs是生物信息学和生物学中的一个重大挑战，了解生物体完全的调控潜力至关重要。然而，现有的模型大多需要转录组学数据来识别ncRNAs，而RNAMunin仅需基因组序列作为输入，无需人工转录。因此，RNAMunin能够无需转录组学数据即能进行ncRNAs的识别。对于大规模基因组数据（如长读长宏基因组组装），RNAMunin的计算可行性也使其成为一个有价值的工具。", "innovation": "RNAMunin是一款机器学习模型，能够在仅使用基因组序列的情况下发现ncRNAs，特别适用于大型序列数据集（如多个Gbp的长读长宏基因组组装）。该模型由来自大约60 Gbp的16个旧金山河口样本的长读长宏基因组中提取的Rfam序列进行训练。RNAMunin的特点是参数量较少（约1M）且运行速度快，这与大多数当前的机器学习模型形成了鲜明对比。这种小型化使得RNAMunin在处理大规模数据集时更加高效，降低了计算成本和资源需求。", "conclusion": "RNAMunin是首个能在基因组序列水平上独立发现ncRNAs的模型，且无需转录组学数据支持。RNAMunin不仅为非编码RNA的研究提供了新的方法，而且展示了在生物信息学中利用深度学习技术解决大规模基因组数据分析问题的潜力。这一创新方法为微生物学、疾病研究和其他生物科学领域提供了更深入的理解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11783", "html_url": "https://arxiv.org/abs/2507.11783", "title": "脑信号的基模型：当前进展和未来方向的批判性回顾", "title_en": "Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions", "authors": "Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah", "background": "脑电信号（EEG）的电活动模式对于科学研究和临床调查具有巨大价值。尽管监督EEG编码器能够学习可靠的EEG模式，但它们对昂贵信号注释的依赖性使其不够实用。因此，已经转向通用的自我监督EEG编码器（即EEG基模型EEG-FMs），以提高EEG特征提取的稳健性和可扩展性。然而，早期EEG-FMs的现用性及其长期研究进展尚不明确，因此需要进行系统和全面的回顾，以理解当前的先进水平并确定未来EEG-FMs的关键方向。", "innovation": "该研究回顾了10种早期EEG-FMs，并对其方法论、实证发现和研究空白进行了批判性综合分析。大多数EEG-FMs采用基于序列的建模方案，并依赖于基于变压器的骨干网络和序列的遮盖重建进行自我监督。然而，模型评估仍存在异质性和限制性，难以评估其实用价值。未来的工作应采用标准化和现实的评估，并展示更显著的扩展效应，同时在整个EEG表示学习管道中做出原则性和可信赖的选择。", "conclusion": "发展基准、软件工具、技术方法和与领域专家合作的应用，可能进一步提高EEG-FMs在临床转化和实际应用中的效用和接受度。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11953", "html_url": "https://arxiv.org/abs/2507.11953", "title": "IAM: 通过不同规模的大语言模型之间的注意力映射实现高效推理", "title_en": "IAM: Efficient Inference through Attention Mapping between Different-scale LLMs", "authors": "Yi Zhao,Zuchao Li,Hai Zhao", "background": "大语言模型（LLMs）在资源消耗方面面临着重大挑战，尤其是在处理长语境时。尽管付出了大量努力提高推理效率，现有方法主要依赖于模型内部的稀疏性来提高效率，而没有充分利用外部信息。现有的研究广泛集中在提高模型的内部特性，但忽略了模型之间的相似性，这是一个新的优化视角。尽管有许多努力试图提高模型的效率，但在不同规模的LLMs之间进行关注映射这一方法尚未得到充分探索和应用。因此，本文提供了关于不同规模LLMs之间的注意力相似度如何被衡量、映射层的选择以及映射过程的一致性等方面的系统分析，由此提出了一种称为IAM（Attention Mapping between Different-scale LLMs）的新框架，该框架通过在小型和大型LLMs之间进行注意力映射，实现了加速注意力计算和减少KV缓存使用量的双重好处。", "innovation": "本文提出了一种名为IAM的新框架，旨在通过不同规模的大语言模型之间的注意力映射实现高效推理。首先，探讨了不同规模LLMs之间的注意力相似度如何被衡量、映射层的选择及映射过程的一致性。基于这些发现，IAM框架可以在保持性能的同时，通过交叉映射小模型和大模型间的注意力提升推理速度并减少KV缓存的需求。实验结果表明，与现有方法相比，IAM框架在加速预报处理、减少KV缓存开销方面均表现出良好效果，且与现有KV缓存优化方法具有互补性。", "conclusion": "实验结果表明，IAM框架能够分别提高15%的预填充速度和22.1%的KV缓存利用率，且不对模型性能产生显著影响。该框架在不同的模型系列中具有良好的通用性，并且与许多现有的KV缓存优化方法无冲突，因此可作为提高LLM效率的工具包中的一个多功能补充。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11911", "html_url": "https://arxiv.org/abs/2507.11911", "title": "AFPM：基于对齐的帧片建模方法用于跨数据集EEG解码", "title_en": "AFPM: Alignment-based Frame Patch Modeling for Cross-Dataset EEG Decoding", "authors": "Xiaoqing Chen,Siyang Li,Dongrui Wu", "background": "脑电图（EEG）解码模型在脑机接口（BCI）中面临跨数据集学习和泛化问题，主要是由于电极布局不一致、信号分布的非稳定性、以及有限的神经生理学先验知识整合。", "innovation": "提出了一种即插即用的基于对齐的帧片建模（AFPM）框架，该框架包括两个主要组件：1）空间对齐，根据脑区先验选择任务相关的电极，对EEG分布进行跨域对齐，并将选中的电极重映射到统一布局；2）帧片编码，将多数据集信号建模成统一的时空片，用于EEG解码。与17种需要数据集特定调优的现有先进方法相比，无需校准的AFPM在运动想象任务上实现了高达4.40%的性能增益，在事件相关电位任务上实现了3.58%的性能增益。据我们所知，这是第一个无需校准的跨数据集EEG解码框架，大大增强了BCI在实际应用中的实用性。", "conclusion": "通过提出AFPM框架解决跨数据集的EEG解码问题，实现了显著的性能提升，并且无需校准，这是首个此类框架，对BCI的实际应用具有重要意义。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11959", "html_url": "https://arxiv.org/abs/2507.11959", "title": "PoTPTQ: 两步Power-of-Two后训练方法用于LLMs", "title_en": "PoTPTQ: A Two-step Power-of-Two Post-training for LLMs", "authors": "Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui", "background": "大规模语言模型（LLMs）在各种自然语言处理（NLP）任务中展现了卓越的表现，但部署时面临巨大的计算资源需求挑战。尽管之前的研究表明，基于固定点加法的Power-of-two（PoT）量化在CPU上高效去量化，但在GPU上效果不佳。这是由于量化符号位的纠缠和连续位操作的复杂性。", "innovation": "本文提出了一种新颖的PoT量化框架，用于LLMs权重，该框架具有以下创新点：(i) 在极低精度格式中实现了最先进的准确率；(ii) 通过更高效的去量化过程加快了推理速度。为保持量化模型的准确性，引入了一个两步后训练算法：(i) 使用稳健的起点初始化量化比例；(ii) 使用最小校准集细化这些比例。PoT后训练算法在整数量化中表现出色，尤其是在2-和3位格式等低精度下。", "conclusion": "PoT量化加速了浮点推理所需的去量化步骤，相较于均匀整数去量化，NVIDIA V100加速了3.67倍，NVIDIA RTX 4090加速了1.63倍。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11984", "html_url": "https://arxiv.org/abs/2507.11984", "title": "数据集自适应降维", "title_en": "Dataset-Adaptive Dimensionality Reduction", "authors": "Hyeon Jeon,Jeongin Park,Soohyun Lee,Dae Hyun Kim,Sungbok Shin,Jinwook Seo", "background": "传统的降维技术选择和参数优化通常需要大量的试错过程，导致了过多的计算开销。这主要是因为需要大量尝试不同的降维技术和参数设置来寻找最佳配置，这在复杂数据集上尤其明显，往往无法准确地在二维投影上表示，这增加了不必要的计算成本。", "innovation": "本文提出了一种根据结构复杂度指标的数据集自适应降维优化方法。这些指标能够量化数据集的内在复杂性，进而预测降维技术的最佳性能。通过这种方法，可以提前预测操作数据集时可以达到的最佳准确度，从而避免不必要的试验，提高了降维优化的效率。", "conclusion": "实验结果表明，基于本方法的数据集自适应降维流程在不牺牲精确度的前提下显著提高了降维优化的效率。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11960", "html_url": "https://arxiv.org/abs/2507.11960", "title": "d-DQIVAR：以数据为中心的可视化分析与推理方法以提升数据质量", "title_en": "d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement", "authors": "Hyein Hong,Sangbong Yoo,SeokHwan Choi,Jisue Kim,Seongbum Seo,Haneol Cho,Chansoo Kim,Yun Jang", "background": "现有研究主要关注批处理数据预处理方法，以数据驱动的方式提升数据质量（DQ），这种方式在优化机器学习（ML）模型性能方面往往效果不佳，并可能导致数据特征失真。多数研究侧重于数据预处理，而不是真正的数据质量改进（DQI）", "innovation": "本文提出了一种新的可视化分析系统d-DQIVAR，旨在通过结合数据驱动和过程驱动的方法实现深层次的数据质量改进策略，通过案例研究、评估和用户研究，展示如何有效利用专家和领域知识来提升机器学习模型的性能", "conclusion": "d-DQIVAR集成可视化分析技术，支持同时采用数据驱动和过程驱动的方法来改进数据质量，使用户能够在实际工作流程中有效地利用专家和领域知识，从而提升机器学习模型的性能"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12021", "html_url": "https://arxiv.org/abs/2507.12021", "title": "将公平性约束纳入原型分析", "title_en": "Incorporating Fairness Constraints into Archetypal Analysis", "authors": "Aleix Alcacer,Irene Epifanio", "background": "原型分析（AA）是一种无监督学习方法，它将数据表示为极端模式（称为原型）的凸组合。尽管AA提供了可解释且低维的表示，但它可能会无意中编码敏感属性，从而引发公平性问题。本文探讨了通过修改原型分析的公式来显式减少敏感群体信息对学习投影的影响，并提出了非线性扩展以应对更复杂的数据分布问题。研究结果表明，改进后的原型分析方法在提高公平性的同时，仍能保持原型结构和解释性，并且在现实应用中表现出良好的鲁棒性和实用性。", "innovation": "本文提出了公平原型分析（FairAA）以及公平内核原型分析（FairKernelAA），它们通过引入公平性正则化项来减轻敏感群体信息的影响，同时保留原型的结构和解释性。此外，FairKernelAA还在非线性扩展方面有所创新，能够更好地适配复杂数据分布，解决公平性问题。", "conclusion": "实验结果表明，FairAA 和 FairKernelAA 能够显著减少群体分离性，同时不显著影响数据的解释性。在实际数据集 ANSUR I 上的应用进一步证实了这些方法的有效性和实用性，从而为敏感应用中的负责任表示学习提供了有力工具。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11977", "html_url": "https://arxiv.org/abs/2507.11977", "title": "CMS实验中增强型Higgs玻色子搜索的最新结果", "title_en": "Recent results on searches with boosted Higgs bosons at CMS", "authors": "Farouk Mokhtar", "background": "在大型强子对撞机（LHC）中，研究提升的Higgs玻色子提供了探讨Higgs玻色子在高能标尺上的耦合和搜索超出标准模型的物理迹象的独特窗口。", "innovation": "本文介绍了CMS实验中使用创新的重建和标记技术来提升在挑战性环境下的敏感度的最新结果。", "conclusion": "根据这些结果，研究人员对提升的Higgs玻色子进行了高效搜索，并改进了在高能物理研究中的灵敏度。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12098", "html_url": "https://arxiv.org/abs/2507.12098", "title": "一种结合联邦学习和差分隐私的隐私保护广告个性化框架", "title_en": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy", "authors": "Xiang Li,Yifan Lin,Yuanzhe Zhang", "background": "为了缓解个性化广告中存在的隐私泄露和性能问题，本文提出了一种结合联邦学习和差分隐私的框架。该系统通过分布式特征提取、动态隐私预算分配和稳健的模型聚合来平衡模型准确性、通信开销和隐私保护，同时采用多方安全计算和异常检测机制增强系统抵御恶意攻击的能力。实验结果表明，该框架能够在保护隐私的前提下优化推荐准确性和系统效率，为广告推荐领域应用隐私保护技术提供了实践解决方案和理论基础。", "innovation": "本文提出的框架结合了联邦学习和差分隐私技术，通过分布式特征提取、动态隐私预算分配、稳健模型聚合以及多方安全计算和异常检测机制，有效解决了个性化广告中的隐私泄露和性能问题，提供了同时优化推荐准确性和系统效率的解决方案。", "conclusion": "通过实验证明了该框架的有效性和实用性，为广告推荐系统的隐私保护提供了理论和实践基础。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11954", "html_url": "https://arxiv.org/abs/2507.11954", "title": "查询驱动的KGQA系统在大规模语言模型时代的复杂和时间相关问题上的优势", "title_en": "The benefits of query-based KGQA systems for complex and temporal questions in LLM era", "authors": "Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov", "background": "大规模语言模型在问答方面表现出色，但在多步推理和时间相关问题上仍存在挑战。查询驱动的知识图谱问答（KGQA）通过生成可执行查询而不是直接回答问题，提供了一种模块化的替代方案。本文聚焦于维基数据问答，探索了一种多阶段查询驱动框架，并提出了一种增强多步推理和时间相关基准性能的多阶段方法。通过一般化和拒绝研究，评估了其在多步推理和时间相关QA数据集上的鲁棒性。此外，引入了一种新的基于CoT推理的实体链接和谓词匹配方法，以改进小规模语言模型在多步和时间相关问答中的性能", "innovation": "提出了一种新的多阶段查询驱动的维基数据问答框架，通过基于CoT推理的实体链接和谓词匹配方法提高了适用于复杂和时间相关的问答的小规模语言模型的性能。通过一般化和拒绝研究，评估了该方法在多步推理和时间相关QA数据集上的鲁棒性，探讨了查询驱动的KGQA系统在大规模语言模型时代的潜在优势", "conclusion": "查询驱动的多阶段KGQA框架在解决复杂和时间相关的问答问题上具有潜力。该方法通过引入基于CoT推理的实体链接和谓词匹配，提高了小规模语言模型在多步和时间相关问答任务上的性能。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12108", "html_url": "https://arxiv.org/abs/2507.12108", "title": "多模态协调的在线行为：权衡与策略", "title_en": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies", "authors": "Lorenzo Mannocci,Stefano Cresci,Matteo Magnani,Anna Monreale,Maurizio Tesconi", "background": "多模态协调的在线行为已成为数字生态系统分析中的关键议题。传统的研究方法往往依赖单一模式的数据分析，如共同转发或共同标签，或者分别处理多种数据模态。然而，这些方法可能会忽略多模态协调背后的复杂动态。", "innovation": "本研究比较了不同方式的操作化检测多模态协调行为。研究重点在于探索弱集成和强集成多模态模型之间的权衡，以捕捉更广泛的合作模式与识别紧密协调行为之间的平衡点。通过比较单模态和多模态方法来评估不同数据模态的独特贡献，并探讨不同实现的多模态性如何影响检测结果。研究发现，并非所有模态数据都能提供独特的见解，但多模态方法有助于更全面理解协作动态。", "conclusion": "本研究增强了检测和分析协调在线行为的能力，并提供了保障数字平台完整性的新视角。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12003", "html_url": "https://arxiv.org/abs/2507.12003", "title": "扩展机器学习文档标准以提高安全性", "title_en": "Expanding ML-Documentation Standards For Better Security", "authors": "Cara Ellen Appel", "background": "本文通过对现有文献的广泛回顾，展示了机器学习（ML）安全性和以研究和实践为中心的ML基于系统的文档现状。它指出，在ML从业者和组织中，对安全问题的整体意识较低，且文档做法通常缺乏标准化，导致了较低质量的ML文档。现有标准在实践中并未定期采用，信息安全方面的内容通常未包含于文档中。基于这些因素，改善ML安全文档的需要被明确指出，作为解决ML安全现有差距的一步。", "innovation": "我们建议扩展现有的ML文档标准，增加一个安全部分，包含具体的安全相关信息。基于现有的机器学习模型卡和数据集数据表标准，我们提出了一个新的扩展文档方法来记录安全需求，但推荐所有ML文档采用这些发现的结果。", "conclusion": "通过改进ML文档中的安全部分，可以提高整个ML领域文档的安全性，这是向解决ML安全问题迈出的重要一步。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12126", "html_url": "https://arxiv.org/abs/2507.12126", "title": "IASR评估框架在非结构化调研数据建模与分析中的迭代扩增与总结精炼", "title_en": "Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis", "authors": "Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta", "background": "自然语言处理（NLP）领域广泛采用文本数据扩增策略来缓解数据稀疏性问题，尤其是在样本量有限的低资源环境中，有限的数据样本会限制有效的语义建模。尽管数据扩增能够改善输入多样性和下游解释性，现有的技术手段在大规模或迭代生成过程中往往缺乏确保语义一致性的机制，导致冗余和不稳定性。", "innovation": "该研究引入了一个有原则的评估框架，用于大型语言模型（LLM）基于的文本扩增。该框架包括两个组成部分：(1) 规模分析，用于评估随扩增量增加的语义一致性；(2) 迭代扩增与总结精炼（IASR），用于评估递归改写循环中的语义漂移。实证研究展示了GPT-3.5 Turbo在语义保真度、多样性和生成效率方面的最佳平衡。", "conclusion": "将提出的方法应用于基于BERTopic的GPT增强的小样本标记的真实世界主题建模任务中，结果显示主题细化提升了400%，完全消除了主题重叠。这些结果验证了所提出的框架在实际NLP流程中评估LLM基于的扩增策略的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12175", "html_url": "https://arxiv.org/abs/2507.12175", "title": "RUMAA: 基于重复符号意识的音乐音频统一分析用于谱表-表演对齐、转录和错误检测", "title_en": "RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection", "authors": "Sungkyun Chang,Simon Dixon,Emmanouil Benetos", "background": "该研究介绍了RUMAA框架，这是一个基于变压器的音乐表演分析框架，该框架通过一个近乎端到端的方式统一了谱表与表演的对齐、基于谱表的乐谱转录和错误检测。与先前单独处理这些任务的方法不同，RUMAA通过预训练的谱表和音频编码器以及一种新颖的三流解码器将这些任务集成起来，该解码器通过代理任务捕获任务间的相互依赖关系。RUMAA能够将可读性高的MusicXML谱表与重复符号对齐到全长表演音频，克服了传统的基于MIDI的方法依赖手动展开的带有预先指定重复结构的谱表-MIDI数据的限制。", "innovation": "RUMAA的最大创新在于它通过一个近乎端到端的方式将谱表-表演对齐、基于谱表的转录和错误检测任务统一起来。它使用预训练的谱表和音频编码器，以及一种新颖的三流解码器来捕获这些任务间的相互依赖关系。此外，RUMAA能够处理包含重复符号的谱表，这在现有方法中是一个挑战。", "conclusion": "RUMAA在公共钢琴音乐数据集中展示了与现有最先进的对齐方法相当的对齐结果，并在包含重复符号的谱表上超过了它们。此外，该方法还提供了有希望的转录和错误检测结果。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12023", "html_url": "https://arxiv.org/abs/2507.12023", "title": "MVAR: 多变量自回归空气质量预测模型", "title_en": "MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model", "authors": "Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li", "background": "空气污染物对环境和人类健康构成了重大威胁，因此准确预测污染物浓度对于污染预警和政策制定至关重要。现有的研究主要集中在单个污染物的预测上，忽视了不同污染物之间的相互作用及其多样的空间响应。为此，本文提出了多变量自回归空气质量预测模型（MVAR），以减少对长时间窗口输入的依赖并提高数据利用效率。同时，MVAR通过设计多变量自回归训练范式，实现了120小时的长期顺序预测。此外，MVAR采用气象耦合空间变换器模块，能够灵活耦合基于AI的气象预报，并学习污染物之间的相互作用及其多样的空间响应。", "innovation": "提出了一种多变量自回归空气质量预测模型（MVAR），该模型减少了对长时间窗口输入的依赖，提高了数据利用效率，并引入了多变量自回归训练范式，实现了120小时的长期预测。此外，MVAR还设计了气象耦合空间变换器模块，可以灵活地耦合AI基础的气象预报，并学习污染物之间的相互作用及其多样的空间响应。", "conclusion": "实验结果表明，所提出的模型优于最新方法，并验证了所提出架构的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12248", "html_url": "https://arxiv.org/abs/2507.12248", "title": "Keras、PyTorch和JAX在PathMNIST上的CNN性能比较分析", "title_en": "Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST", "authors": "Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić", "background": "深度学习极大地推动了医学图像分类领域的发展，尤其是卷积神经网络（CNNs）的应用。各种深度学习框架如Keras、PyTorch和JAX在模型开发和部署中具有独特优势，但在医学成像任务中的性能比较研究仍相对不足。鉴于此，本研究使用PathMNIST数据集作为基准，对这些框架中的CNN实施进行全面分析。评估指标包括训练效率、分类准确性和推理速度，旨在为医学图像分析领域的研究人员和实践者提供参考。", "innovation": "本研究通过使用PathMNIST数据集，对Keras、PyTorch和JAX中的CNN实施进行了全面的性能比较，评估了这些框架在医学成像任务中的适用性，揭示了计算速度与模型准确性之间的权衡关系，为医学图像分析提供了宝贵的研究见解。", "conclusion": "本研究指出，Keras、PyTorch和JAX在CNN性能上存在差异，研究者和从业者应根据具体应用场景权衡计算速度与模型准确性之间的关系，以选择最适合的深度学习框架。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12091", "html_url": "https://arxiv.org/abs/2507.12091", "title": "增强动量更新的符号方法的分析改进", "title_en": "Improved Analysis for Sign-based Methods with Momentum Updates", "authors": "Wei Jiang,Dingzhi Yu,Sifan Yang,Wenhao Yang,Lijun Zhang", "background": "传统基于符号的方法在满足分离平滑性假设的情况下，可以保证$\text{O}(T^{-1/4})$的收敛率，但这需要较大的批量大小或假设单模对称随机噪声。本文针对这一局限性，研究了带有动量更新的符号SGD，并证明了在标准的$l_2$-光滑条件下，可以通过恒定的批量大小实现同样的$\text{O}(T^{-1/4})$的收敛率，而无需增加额外假设。此外，文章还探讨了分布式环境下的多数投票符号方法，展示了提出的带有动量的方法能实现优于以往结果的收敛率。", "innovation": "本文的创新之处在于，通过证明带有动量的符号SGD方法可以在标准$l_2$-光滑条件下，使用恒定的批量大小达到与较大批量大小相同的$\text{O}(T^{-1/4})$收敛率，而无需额外假设。在分布式环境中，提出的带有动量的方法使得符号方法的收敛速度有了显著提高，优于现有的$\text{O}(dT^{-1/4} + dn^{-1/2})$和$\text{O}(\text{max}\brace{d^{1/4}T^{-1/4}, d^{1/10}T^{-1/5}})$的最快速度，分别提高了$\text{O}(d^{1/2})$和$\text{O}(d^{1/2})$的水平。", "conclusion": "本研究的结果进一步验证了提出的带有动量的方法的有效性，并在理论上和实验上都展示了其在基于符号的优化方法中的优势。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12064", "html_url": "https://arxiv.org/abs/2507.12064", "title": "StylOch 在 PAN 赛道上的 Gradient- Boosted 树与基于频率的语体特征", "title_en": "StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features", "authors": "Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak", "background": "该论文提交于二进制人工智能检测任务。背景是在机器生成文本检测领域，传统的非神经网络方法仍然有效且具有计算成本低和可解释性强的优势。研究人员通过构建一个模块化的语体学流水线，使用 spaCy 模型进行文本预处理，并提取大量基于语法注释的 n-grams 频次特征。这些特征与轻量级梯度提升树（Light-Gradient Boosting Machines）结合用于分类器训练，旨在生成大量机器生成文本的训练语料库。该方法强调了性能和解释性的平衡，与之前的有效方法保持一致。", "innovation": "创新之处在于作者采用了一种模块化的语体学处理流程，融合了 spaCy 的多种语言分析工具和丰富的 n-grams 频次特征提取方法，并使用轻量级梯度提升树作为分类器。同时，通过参数探索和大规模语料库的训练，进一步提高了分类器的能力。文章展示了非神经网络方法在某些任务中依然高效且易于解释。", "conclusion": "研究结果表明，这种基于频率的语体特征结合轻量级梯度提升树的方法在机器生成文本的二进制检测任务中表现出色。通过调整参数和收集大量训练数据，这种方法的有效性和可解释性得到了增强。该研究在该领域提供了一个新的有效方案，强调了一种计算成本低的非神经网络方法的价值。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12202", "html_url": "https://arxiv.org/abs/2507.12202", "title": "用于序列推荐模型的稀疏自编码器：解释和灵活控制", "title_en": "Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control", "authors": "Anton Klenitskiy,Konstantin Polev,Daria Denisova,Alexey Vasilev,Dmitry Simakov,Gleb Gusev", "background": "许多当前最先进的序列推荐模型基于Transformer架构。理解这些黑盒模型的内部运作是重要的研究课题，因为对其内部结构的了解有助于理解和控制其行为，这对于许多实际应用来说非常关键。最近研究表明，在语言模型中提取可解释特征的稀疏自编码器（SAE）是一种有前景的无监督方法。SAE旨在通过稀疏线性组合的方式来重建Transformer内部层的隐藏状态。", "innovation": "本文关注SAE在序列推荐领域的应用。研究表明，SAE可以成功应用于训练序列推荐任务的Transformer中：学习到的方向比原始隐藏状态维度更具可解释性和单一语义。此外，SAE学到的特征可以灵活且有效地控制模型行为，为最终用户提供一种简单的方法来调整其推荐到不同的个性化场景和上下文中。", "conclusion": "本文展示了稀疏自编码器在序列推荐领域的应用，证明了其通过学习到的方向实现更可解释性功能，并且这些特征可以灵活地控制模型行为，提供给用户定制推荐的方法以适应不同的场景。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12256", "html_url": "https://arxiv.org/abs/2507.12256", "title": "基于格玻尔兹曼碰撞算子的代数量子电路设计", "title_en": "Surrogate Quantum Circuit Design for the Lattice Boltzmann Collision Operator", "authors": "Monica Lăcătuş,Matthias Möller", "background": "对湍流流动进行直接数值模拟，在高雷诺数下仍然是传统计算流体动力学（CFD）工具运行在经典计算机硬件上的一大挑战。这促使了量子算法在计算流体动力学中的研究兴趣日益增加，以期在量子计算机上实现流动模拟。原因是量子计算机有望为某些问题提供潜在的加速效果。一种有前景的量子CFD方法是全量子实现格玻尔兹曼方法（QLBM）。尽管已经为流动作业阶段开发了高效量子算法，但通过低深度电路实现非线性的、不可逆的碰撞步骤，同时避免使用辅助量子比特、概率后选择和重复执行仍然是一个重大挑战。", "innovation": "该研究提出了一个框架来学习一个近似全格玻尔兹曼（BGK）碰撞操作符的代数量子电路（SQC），该框架使电路能遵守BGK碰撞操作符的物理特性，包括质量与动量守恒、D8对称性和尺度对称性。基于IBM Heron处理器编译假设全量子比特连接性下，15个模块的SQC仅需要2,430个原生门，不使用辅助量子比特或后选择及重复执行，并且其深度与网格分辨率无关，因为碰撞是一个局部操作，能够最大限度地利用量子并行性。该研究通过两种基准流动进行了SQC验证，即Taylor Green涡流衰减和带驱动腔，显示其能够准确捕捉涡流耗散和流动再循环。", "conclusion": "该研究成功地设计了一个供格玻尔兹曼碰撞算子的代数量子电路，证明了近似全BGK碰撞操作符的SQC框架的有效性，该电路能保持物理特性，且在量子哈伦处理器编译下实现了高效的执行，无需使用辅助量子比特和重复执行。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12233", "html_url": "https://arxiv.org/abs/2507.12233", "title": "全傅里叶神经算子在微观力学中的通用性", "title_en": "Universal Fourier Neural Operators for Micromechanics", "authors": "Binh Huy Nguyen,Matti Schneider", "background": "在进行材料的宏细化过程中，解决细胞问题具有挑战性，现有的深度学习框架无法达到传统计算框架的速度和通用性。此外，人们对机器学习方法的期望并不明确，更不用说区分哪些方法是前途光明的了。本文提倡使用基于傅里叶变换（FFT）方法的见解增强傅里叶神经算子（FNOs），用于微观力学问题，构建了一个模仿FFT方法基础方案的FNOs近似模型，该模型能在保证一定精度的情况下预测具有任意刚度分布的细胞问题解，不论材料对比度、材料对称性（如各向异性）、相数量或材料界面几何形状的限制。所得到的神经算子与基本方案具有相同的内存要求，并且运行时间与经典FFT求解器成比例，能够处理包含超过1亿个体素的大型问题。这项工作的目标是强调FNOs在解决微观力学问题中的潜力，将FFT方法与FNOs进行关联，期望这种联系能够为两个领域的交流提供有价值的契机。", "innovation": "提出了使用傅里叶神经算子（FNOs）解决微观力学问题的方法，并结合了基于快速傅里叶变换（FFT）的微观力学方法的见解，构造了一个模仿基础FFT方法的FNOs近似模型，这不仅没有对材料对称性、相数量或材料界面几何形状进行限制，而且提供了精确且一致的预测，具有明确的物理保证。特别地，构造了一个无需训练即可直接使用的FNOs，该FNOs遵循与基本方案相同的内存要求，并具有与经典FFT求解器相当的运行时间，尤其适用于大规模问题的处理。", "conclusion": "本文强调了FNOs在解决微观力学问题方面的潜力，通过将FFT方法与FNOs进行关联，提供了一个将机器学习方法与传统计算方法结合的途径，这有望为两者之间的交流提供有价值的依据。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12138", "html_url": "https://arxiv.org/abs/2507.12138", "title": "神经人体姿态先验", "title_en": "Neural Human Pose Prior", "authors": "Michal Heker,Sefy Kararlitsky,David Tolpin", "background": "本文介绍了使用归一化流方法建模人体姿态先验的一套原则性、数据驱动的方法。不同于基于启发式或低表达性的替代方法，我们采用RealNVP来学习一种柔性姿态密度表示，旨在有效描述6D旋转格式下的人体姿态分布。", "innovation": "本文创新点在于通过训练期间倒序Gram-Schmidt过程来建模有效6D旋转流形上的分布，确保学习过程稳定且向下兼容基于旋转的框架。该架构和训练流程具有框架独立性，并且易于重现。通过定性和定量评估展示了学习先验的有效性，并通过消融研究分析了其影响。", "conclusion": "本文提供了将姿态先验整合到人体动捕和重建管道中的稳健概率基础。该工作为构建高效和稳定的姿态建模提供了重要的理论和实践支持。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12189", "html_url": "https://arxiv.org/abs/2507.12189", "title": "BenchRL-QAS: 用于量子架构搜索的强化学习算法基准测评", "title_en": "BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search", "authors": "Azhar Ikhtiarudin,Aditi Das,Param Thakkar,Akash Kundu", "background": "本文介绍了BenchRL-QAS，这是一个统一的基准测评框架，用于系统地评估量子架构搜索（QAS）中的强化学习（RL）算法。该框架覆盖了从2至8比特的多种范化的量子算法任务，并且评估了不同噪声水平下的表现。研究对象包括九种RL代理，涵盖了价值方法和策略梯度方法，应用于例如变量子哈密尔顿求解器、变量子态对角化、量子分类和量子态准备等代表性的量子问题。", "innovation": "本文提出了一个加权排名指标，该指标平衡了准确性、电路深度、门操作计数和计算效率，使得评估更加公平和全面。研究结果表明，基于RL的量子分类器在基准变量子分类器上表现出色。同时指出没有一种单独的RL算法可以在多种QAS任务中通用最优，算法性能高度依赖于上下文，包括任务结构、量子位数和噪声水平的变化。", "conclusion": "这一发现为RL基量子电路设计中的‘没有免费的午餐’原理提供了实证证据，并强调了针对量子电路合成需求进行定制算法选择和系统测评的必要性。这是迄今为止最全面的RL-QAS基准测评工作，BenchRL-QAS和所有实验数据均已公开可用，以支持可重复性以及未来的研究。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12318", "html_url": "https://arxiv.org/abs/2507.12318", "title": "组合离散隐代码：高保真、生产性扩散模型", "title_en": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models", "authors": "Samuel Lavoie,Michael Noukhovitch,Aaron Courville", "background": "本文探讨了扩散模型在建模复杂分布方面取得成功的原因，并指出其主要原因是输入条件的使用方式。文章认为理想的条件表示能提高样本保真度、简化生成过程，并允许超出训练样本分布之外的样本生成。本文旨在从自监督学习和组合性方面改进此类表示，以提高图像生成的质量和多样性。", "innovation": "本文引入了一种称为离散隐代码（DLC，Discrete Latent Code）的新的图像表示方法，它是通过自监督学习训练的Simplicial Embeddings衍生而来。与传统的连续图像嵌入不同，DLC表示形式为离散的令牌序列，容易生成，并且具有组合性，这使其能够生成超出训练分布的新颖图像。使用DLC进行训练的扩散模型在ImageNet上的无条件图像生成任务中达到了新的最先进的生成保真度。此外，组合DLC使图像生成器能够以一致的方式组合出不同图像的语义，创造出新的样本。最后，本文展示了如何利用大规模预训练语言模型通过利用DLC进行文本到图像的生成。通过高效微调一个文本扩散语言模型，使其能够生成超出训练分布的新颖样本。", "conclusion": "总之，本文通过引入离散隐代码DLC和利用组合性，显著提升了生成模型的生成质量和多样化，实现了在ImageNet上的新最先进的生成精度，并展示了其在文本到图像生成中的应用前景。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12269", "html_url": "https://arxiv.org/abs/2507.12269", "title": "基于逐层冻结的站点级微调：从极早早产儿第一天胸部X光片向稳健预测慢性肺部发育不良的进展", "title_en": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "authors": "Sybelle Goedicke-Fritz(1),Michelle Bous(1),Annika Engel(2),Matthias Flotho(2 and 5),Pascal Hirsch(2),Hannah Wittig(1),Dino Milanovic(2),Dominik Mohr(1),Mathias Kaspar(6),Sogand Nemat(3),Dorothea Kerner(3),Arno Bücker(3),Andreas Keller(2 and 5 and 7),Sascha Meyer(4),Michael Zemlin(1),Philipp Flotho(2 and 5) ((1) Department of General Pediatrics and Neonatology, Saarland University, Campus Homburg, Homburg/Saar, Germany, (2) Chair for Clinical Bioinformatics, Saarland Informatics Campus, Saarland University, Saarbrücken, Germany, (3) Department of Radiology, and Interventional Radiology, University Hospital of Saarland, Homburg, Germany, (4) Clinical Centre Karlsruhe, Franz-Lust Clinic for Paediatrics, Karlsruhe, Germany, (5) Helmholtz Institute for Pharmaceutical Research Saarland (HIPS), Saarland University Campus, Germany, (6) Digital Medicine, University Hospital of Augsburg, Augsburg, Germany, (7) Pharma Science Hub (PSH), Saarland University Campus, Germany)", "background": "极早早产儿（极低出生体重）中慢性肺部发育不良（BPD）的发生率高达35%，是一种影响长期呼吸功能的慢性肺病。预防性干预措施虽然有效，但伴随有严重的副作用，如神经发育损害、机械通气引起的肺损伤和全身性并发症。因此，早期诊断并预测BPD的预后对于避免对低风险婴儿不必要的毒性至关重要。入院时通过胸部X光片采集的影像可以为这些婴儿提供一个无创的预后工具。", "innovation": "本文引入了一种基于逐层冻结的深度学习方法，通过胸部X光片预测BPD。特别地，使用一个预先在成人胸部X光片上训练的ResNet-50模型，并结合了逐层冻结、剪切混合增强和线性探针等技术，该方法在预测中取得了良好的效果。研究结果表明，领域特定的预训练显著优于ImageNet初始化（p=0.031），证明了领域特定预训练对于BPD预后预测的重要性。此外，该方法通过逐层冻结和线性探针保持了计算上的可行性，适用于站点级实施和未来的联邦学习部署。", "conclusion": "我们的方法表明，领域特定的预训练能够从极早早产儿第一天的胸部X光片中准确预测BPD。这一研究为BPD的早期诊断和预防提供了新的方向，并展示了通过适当的预处理技术提高模型性能的可能性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12329", "html_url": "https://arxiv.org/abs/2507.12329", "title": "神经极化译码器在删除信道中的应用", "title_en": "Neural Polar Decoders for Deletion Channels", "authors": "Ziv Aharoni,Henry D. Pfister", "background": "现有的极化译码器对于删除信道的计算复杂度高达$O(N^4)$，这限制了极化编码在删除信道中的应用范围，仅限于较短到中等长度的块长度。本文介绍了一种针对具有恒定删除率的删除信道的神经极化译码器（NPD），旨在降低计算复杂度并拓展极化码在删除信道中的应用范围。现有的极化译码器在删除信道中的计算复杂度过高，影响其应用范围。新提出的方法能有效降低计算复杂度，支持更高的块长度应用。", "innovation": "本文提出了神经极化译码器（NPD），将现有的神经架构拓展支持删除信道，并将计算复杂度降低至$O(AN\text{log}N)$。通过变化其中一个神经网络的架构，使神经极化译码器能够处理删除信道。实验验证了神经极化译码器的有效性和性能改进潜力。此外，由于计算复杂度降低，还能够结合列表译码进一步提高性能。", "conclusion": "提出的神经极化译码器具有较低的计算复杂度，能够应用于长到中等长度的删除信道中。此外，它支持列表译码，改进了删除信道中的译码性能。这表明神经极化译码器可以应用于未来的技术中，如DNA存储。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12404", "html_url": "https://arxiv.org/abs/2507.12404", "title": "基于神经网络的符号回归在钙钛矿催化剂可解释描述符发现中的应用", "title_en": "Neural Network-Guided Symbolic Regression for Interpretable Descriptor Discovery in Perovskite Catalysts", "authors": "Yeming Xian,Xiaoming Wang,Yanfa Yan", "background": "研究和预测氧化钙钛矿催化剂在氧析出反应（OER）中的活性需要准确且具有物理可解释性的描述符。虽然符号回归（SR）能够发现这样的公式，但在高维度输入和小数据集的情况下，其性能会下降。因此，研究中提出了一种结合神经网络（NN）、特征重要性分析和符号回归（SR）的两阶段框架，以在氧化钙钛矿中发现OER活性的可解释描述符。", "innovation": "该研究开发了一种基于神经网络的符号回归方法，旨在在数据稀缺的情况下发现准确且具有物理可解释性的描述符。这种方法在第一阶段使用少量数据和七个结构特征来复制并改进已知的μ/t描述符，并在第二阶段扩展到164个特征，通过减少维数并识别最低未占轨道能量（LUMO能量）作为关键电子描述符来进一步优化。结果表明，该方法能够实现准确、可解释且物理意义明确的描述符发现。", "conclusion": "该研究结果表明，在数据稀缺的条件下，神经网络引导下的符号回归能够通过可解释的特征发现和提高预测准确性，表明可解释性不必牺牲准确性。这对于材料信息学领域的应用具有重要意义。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12428", "html_url": "https://arxiv.org/abs/2507.12428", "title": "在模型停止思考之前，能否预测对齐问题？迈向监测错对齐推理模型", "title_en": "Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models", "authors": "Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach", "background": "开放权重推理语言模型在生成最终响应前会产生较长的推理链（CoTs），这虽然提升了性能但也引入了额外的对齐风险，有害内容可能出现在CoTs和最终输出中。本文探讨了是否可以利用CoTs来预测最终响应中的对齐偏差问题。", "innovation": "研究发现，基于CoT激活训练的简单线性探针优于所有基于文本的方法，在判断最终响应是否安全方面表现出色。CoT文本常常不忠于事实，容易误导人类和分类器，而模型潜变量（即CoT激活）则提供了更可靠预测信号。此外，探针在推理未完成时就能做出准确预测，即使对早期CoT片段也适用。这些发现表明，轻量级探针可能有助于实时安全监控和生成过程中的早期干预，适用于不同模型规模、款型及安全基准。", "conclusion": "这些发现表明，轻量级探针有可能实现生成过程中的实时安全监控和早期干预，并适用于不同大小、家族和安全基准的模型。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12440", "html_url": "https://arxiv.org/abs/2507.12440", "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "title_en": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "authors": "Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang", "background": "实机器人数据收集用于模仿学习在机器人操作领域取得了显著进展。然而，这一过程中对机器人硬件的高要求限制了数据规模。", "innovation": "本文探索使用第一人称视角的人类视频训练Vision-Language-Action (VLA) 模型。通过训练包含人类腕部和手部动作预测的VLA模型，并使用逆运动学和动作转换将人类动作转换为机器人动作。进一步使用Isaac Humanoid Manipulation Benchmark进行模型微调和评估，并展示了显著的改进。", "conclusion": "通过Isaac Humanoid Manipulation Benchmark对EgoVLA进行微调和评估，显示出相较于基线模型的显著改进，并探讨了人类数据的重要性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12442", "html_url": "https://arxiv.org/abs/2507.12442", "title": "研究长上下文长度下状态空间模型（SSM）及其与Transformer混合模型性能", "title_en": "Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length", "authors": "Saptarshi Mitra,Rachid Karami,Haocheng Xu,Sitao Huang,Hyoukjun Kwon", "background": "随着对能够在本地设备上处理连续长上下文输入的机器智能需求快速增长，传统的Transformer架构由于其计算复杂度和内存需求的二次增长而变得效率低下，难以满足需求。这促使人们转向像状态空间模型（SSMs）和混合模型这样的新架构，这些新架构有望实现接近线性的扩展。尽管当前大多数研究侧重于这些模型的准确性和理论吞吐量，但针对实际消费硬件进行系统的性能表征对于引导系统级优化和解锁新应用至关重要。这项研究填补了这一空白，通过对精心选择的Transformer、SSM和混合模型在消费级和嵌入式GPU上的长上下文推断进行全面、对比的基准测试，揭示了在长上下文推断领域，SSMs不仅可行而且更优，能够在24GB消费级GPU上处理多达22万个标记，比同类Transformers长约4倍。当序列长度极长时，SSMs在某些情况下表现出数倍于Transformers的性能。", "innovation": "本研究进行了全面的SSM和SSM-Transformer混合模型在长上下文长度下的性能基准测试，发现了SSM在消费级GPU上处理长上下文任务的优势，特别是在处理非常长的上下文时性能突飞猛进。通过操作级别分析，本研究指出了在边缘平台上，针对SSM内核进行硬件感知的定制优化，可以大幅提高推理延迟，成为未来硬件加速的主要焦点。此外，还提供了详细的设备特定表征结果以指导边缘平台的系统级协同设计。", "conclusion": "研究表明，状态空间模型及其与Transformer的混合模型在长上下文推断领域具有显著性能优势，尤其是当上下文长度非常长时。本研究通过操作级别分析，确定了SSM内核在边缘平台上的主导地位，并将其作为未来硬件加速的关键点。此外，研究还提供了详细的设备特定表征结果，有助于指导边缘平台的系统级协同设计。为了促进进一步研究，本研究还将开放其表征框架以供使用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12295", "html_url": "https://arxiv.org/abs/2507.12295", "title": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding", "title_en": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding", "authors": "Feng Xiao,Jicong Fan", "background": "文本异常检测是自然语言处理（NLP）中的一个关键任务，广泛应用于欺诈检测、虚假信息识别、垃圾信息检测和内容审核等领域。尽管大规模语言模型（LLMs）和异常检测算法取得了显著进展，但由于缺乏标准化和综合的基准来评估现有文本异常检测方法，限制了严谨的对比和创新方法的发展。为了填补这一空白，本文进行了一项全面的经验研究，并引入了一个基于LLM嵌入的文本异常检测基准。", "innovation": "本文通过引入一个新的基准Text-ADBench，结合多种预训练语言模型的嵌入和多种文本数据集，系统地评估了基于嵌入的文本异常检测的有效性。该研究创新点包括：1) 引入了对早起语言模型（GloVe, BERT）和多种LLM（如LLaMa-2, LLama-3, Mistral, OpenAI的小型、ada、大型模型）的综合评估；2) 采用了跨领域文本数据集（新闻、社交媒体、科学出版物）进行评估；3) 使用了全面的评估指标（AUROC, AUPRC）；4) 揭示了嵌入质量在异常检测中的关键作用，并指出深度学习方法在依据LLM嵌入使用时，并无性能优势。此外，还观察到跨模型性能矩阵的强低秩特性，有助于快速模型评估和选择。", "conclusion": "本文的实验证明了高质嵌入对异常检测效果的重要性，并指出深度学习方法在利用LLM嵌入时与其他简单算法（如KNN、隔离森林）无明显性能优势。此外，通过开源包含不同模型的所有嵌入和代码的基准工具包，该研究为未来的稳健和可扩展的文本异常检测系统奠定了基础。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12441", "html_url": "https://arxiv.org/abs/2507.12441", "title": "Describe Anything Model for Visual Question Answering on Text-rich Images", "title_en": "Describe Anything Model for Visual Question Answering on Text-rich Images", "authors": "Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu", "background": "在基于区域的视觉语言建模领域取得了进展，特别是在 Describe Anything Model (DAM) 的出现之后。这种模型能够在无需额外局部图像文本对齐监督的情况下，生成任何特定图像区域或对象的详细描述。基于此，团队致力于探索和利用 DAM 的区域意识能力，解决富含文本信息的图像下的视觉问答任务。", "innovation": "提出了一种名为 DAM-QA 的框架，它具有定制的评估协议，能够研究和利用 DAM 在富含文本信息的图像场景下进行视觉问答的能力。DAM-QA 引入了一种机制，可以从多个图像区域的视角汇总答案，更有效地识别与文本相关证据相关的信息。实验表明，与基础 DAM 相比，该方法在各项指标上表现更优，特别是在 DocVQA 数据集上取得了显著提升。", "conclusion": "研究结果表明，高效的利用和整合策略使得 DAM 类型的模型在具备丰富文本信息和更广泛适用的视觉问答任务中展示出了潜力。本方法在参数量较少的情况下，达到了与其他强通用视觉语言模型相近的性能。代码已公开发布。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12451", "html_url": "https://arxiv.org/abs/2507.12451", "title": "S2WTM: 球面切片 Wasserstein 自编码器在主题建模中的应用", "title_en": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling", "authors": "Suman Adhya,Debarshi Kumar Sanyal", "background": "在高维文本数据中捕捉方向相似性的潜在表示在主题建模中非常有效。常见的变分自编码器神经主题模型（VAE-NTMs）通常使用 von Mises-Fisher 先验来编码球面结构。然而，VAE-NTMs 经常会遭受后验崩溃的问题，导致其目标函数中的 KL 散度项显著减少，进而产生无效的潜在表示。", "innovation": "为了在潜在空间中建模球面结构并缓解后验崩溃问题，本文提出了一种名为 Spherical Sliced Wasserstein 自编码器用于主题建模（S2WTM）的方法。S2WTM 使用支持在单位超球面上的先验分布，并利用球面切片 Wasserstein 距离来对齐聚合后的后验分布与先验分布，以此来生成更加连贯且多样化的话题。", "conclusion": "实验结果表明，S2WTM 在生成更连贯和多样化的话题以及在下游任务上的性能方面优于当前最先进的主题建模方法。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.05128", "html_url": "https://arxiv.org/abs/2311.05128", "title": "通过机器学习技术探索和分析野火数据", "title_en": "Exploring and Analyzing Wildland Fire Data Via Machine Learning Techniques", "authors": "Dipak Dulal,Joseph J. Charney,Michael Gallagher,Carmeliza Navasca,Nicholas Skowronski", "background": "该研究项目在新泽西州锡拉斯小森林实验林进行了一次小规模的实验性林地火灾，收集了风速数据，并计算出了湍动能（TKE）。研究目的是探索使用热电偶温度作为预测野火湍动能的潜在指标，并通过机器学习模型评估热电偶温度波动预测TKE的能力。数据可视化和相关性分析揭示了热电偶温度与TKE之间的模式和关系，提供了对涡流动态的理解。尽管预测变量和目标变量之间存在较弱的相关性，但各种机器学习模型仍实现了较高的TKE预测准确性。这项研究结果对于野火行为和烟雾模式科学具有重要意义，强调了机器学习方法的重要性及其在识别细微尺度火行为与湍流复杂关系方面的作用。精确估计TKE有助于模型优化，以及火灾管理决策的科学性和风险管理的效能提升。研究突出了机器学习技术在处理野火数据方面的价值，展示了这些技术在推动野火研究和管理实践方面的发展潜力。", "innovation": "该研究创新性地使用了热电偶温度作为预测野火湍动能的指标，并借助多种机器学习模型（包括深度神经网络、随机森林回归器、梯度提升和高斯过程回归器）评估其预测能力。尽管热电偶温度与TKE之间存在弱相关性，但研究仍实现了高预测精度，特别是在回归模型方面取得了显著成功。这些结果强调了利用机器学习方法分析野火数据的重要性。", "conclusion": "通过该研究，热电偶温度能够精确预测湍动能，这为改进野火模型和决策支持提供了依据。研究成果表明，机器学习技术在野火数据处理和分析中具有巨大潜力，可以推动野火研究和管理实践的发展。该研究还指出了更深入研究和应用的重要性，特别是在识别和理解细微尺度野火行为与复杂湍流关系方面。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.02718", "html_url": "https://arxiv.org/abs/2310.02718", "title": "通过广义逆矩阵理解去细化增强", "title_en": "Understanding Pan-Sharpening via Generalized Inverse", "authors": "Shiqi Liu,Yihua Tan,Yutong Bai,Alan Yuille", "background": "Pan-sharpening算法利用高分辨率的单色图像和多光谱图像生成高空间和高光谱分辨率的图像。然而，这些算法的优化标准各不相同。本文通过一个简单的矩阵方程描述了去细化增强问题，并讨论了解的存在条件以及如何获得光谱和空间分辨率。引入了一种下采样增强方法，以提高空间和光谱下采样矩阵的估计，同时使用广义逆理论发现了广义逆矩阵公式的两个解空间，分别对应于组件替换和多分辨率分析两类主要的去细化增强方法。", "innovation": "通过引入下采样增强方法和使用广义逆理论揭示了两个解空间，证明格拉姆-施密特自适应方法与上述两种主要的去细化增强方法中的组件替换方法一致。模型前提出了广义逆矩阵的光谱函数模型先验，并通过广义逆形式的通用解空间嵌入了扩散先验，从而改善了去细化增强的结果。本文进行了广泛的实验，包括对比实验、合成数据的去细化增强、真实数据的免去实验和扩散相关的测试，证明了提出的去细化增强方法在合成和现实中均能产生更清晰和更好的结果，下采样增强方法在真实数据实验中的效果尤为显著，扩散先验能够显著提高方法在几乎所有评价指标上的性能。", "conclusion": "广义逆矩阵理论的引入有助于深入理解去细化增强机制，提出的去细化增强方法、模型先验和扩散先验可以显著改善相关算法的性能。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12464", "html_url": "https://arxiv.org/abs/2507.12464", "title": "CytoSAE: 用于血细胞学的可解释细胞嵌入", "title_en": "CytoSAE: Interpretable Cell Embeddings for Hematology", "authors": "Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider", "background": "近年来，稀疏自动编码器（SAEs）作为一种工具在机械解释基于变压器的预训练模型方面表现出巨大潜力。尤其地，SAEs也被应用于视觉领域，使其能够发现视觉概念，并将这些概念在变压器模型中的patch层级进行归因。随着在医疗影像领域越来越多的基础模型的出现，用于解释其推理结果的工具仍然滞后。本文利用SAEs在血细胞学上的应用前景，提出了CytoSAE，这是一种经过超过40,000张外周血单细胞图像训练的稀疏自动编码器模型，并且该模型能够泛化到多种不同的血细胞学数据集上。", "innovation": "提出了CytoSAE，这是一种面向血细胞学的稀疏自动编码器，其能够在多种不同的数据集上泛化，并且能够识别出具有形态学意义的概念。CytoSAE不仅能够生成针对特定患者的和特定疾病的细胞概念，这些概念可以用于检测特异性病灶和局部细胞异常，并且对于患者的急性髓系白血病（AML）亚型分类任务，CytoSAE的性能与现有最先进模型相当，并且提供了亚细胞层面的可解释性。", "conclusion": "研究证明CytoSAE可以作为解释医疗影像基础模型推理结果的有效工具，其概念对于患者的AML分类任务具有显著影响，并能够实现与当前最先进模型相当的性能，同时提供亚细胞层面的解释性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.20360", "html_url": "https://arxiv.org/abs/2310.20360", "title": "数学视角下的深度学习导论：方法、实现与理论", "title_en": "Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory", "authors": "Arnulf Jentzen,Benno Kuckuck,Philippe von Wurstemberger", "background": "本书旨在为那些完全没有深度学习背景的学生和科学家提供一个入门介绍。涵盖的内容包括深度学习算法的数学细节，不同的人工神经网络架构（如全连接前向网络、卷积神经网络、循环神经网络、残差网络以及带有批量归一化的神经网络）和不同的优化算法（如基础的随机梯度下降方法、加速方法和自适应方法）。此外，还会讨论深度学习算法的几个理论方面，包括人工神经网络的逼近能力（包含人工神经网络的计算方法）、优化理论（包括Kurdyka-Ｚｏｊａｓｉｅｗｉｃz不等式）以及泛化误差。末章中，将回顾一些深度学习用于偏微分方程建模的方法，如物理知情神经网络和深度伽辽金方法", "innovation": "详细的数学解析与推导，覆盖多种人工神经网络架构及其优化算法，并系统地讨论了深度学习的理论基础，特别是在偏微分方程建模方面的应用方法（如物理知情神经网络和深度伽辽金方法）", "conclusion": "本书适合完全没有深度学习背景的学生和科学家作为入门教材，同时也适合希望获得更牢固数学理解的实践者"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.06974", "html_url": "https://arxiv.org/abs/2306.06974", "title": "一种聚类的计算理论和半监督算法", "title_en": "A Computational Theory and Semi-Supervised Algorithm for Clustering", "authors": "Nassir Mohammad", "background": "聚类被定义为按照选定的分组原则和度量，把数据分组，使得每个组内没有异常点，其他数据点被认为是异常点、孤立异常点、异常组或未知组。按照均匀随机分布假设进行适当的建模，任何在某组中预期发生次数小于1的数据点被视为异常点，否则被分配到该组。因此，聚类被视为异常检测的对立面。数据表示形式被定义为点到聚类中位数的欧几里得距离，这是因为中位数具有对外离值的稳健性、近似位于中心位置，使得决策边界具有通用性。聚类方法的核心是感知异常检测算法，这导致了无需参数调整、快速且高效的聚类算法。尽管聚类是一个互动和迭代的过程，算法依赖一小部分已知的关系作为种子，定义用户的对象并指导聚类过程，然后将簇扩展到相应的部分，留出剩余的数据点进行探索和后续迭代。在合成和真实数据集上展示了该方法在与其他流行无监督和半监督聚类方法相比的优势。", "innovation": "提出了聚类计算理论，并开发了一种基于感知异常检测算法的半监督聚类算法。提出了聚类和异常检测的对立关系，并采用了中位数作为聚类中的距离度量，具有对外离值的稳健性和中心性。该算法是参数自由的、快速且高效的，并且能够利用少量已知的关系来定义用户的目标并指导聚类过程。", "conclusion": "在合成和真实数据集上，所提出的方法能够有效进行聚类，并且在与其他流行的无监督和半监督聚类方法的比较中表现出了优势。给出了半监督聚类的方法和算法，并通过大量实验验证了方法的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.01234", "html_url": "https://arxiv.org/abs/2403.01234", "title": "深度核学习实现分子性质的主动学习：实现动态结构嵌入", "title_en": "Active Deep Kernel Learning of Molecular Properties: Realizing Dynamic Structural Embeddings", "authors": "Ayana Ghosh,Maxim Ziatdinov,Sergei V. Kalinin", "background": "随着化学实体数据库的日益丰富，如何有效探索和利用这些资源来研究分子性质成为新的挑战。本研究介绍了深度核学习（DKL）在分子发现中的主动学习方法，以QM9数据集为例进行了展示。通过直接将结构嵌入与性质链接，并通过迭代重新计算嵌入向量以匹配目标性质，DKL能够揭示关键分子性质的集中最大值，并揭示可能具有创新潜力的未探索区域。这表明DKL在推进分子研究和发现方面具有潜力", "innovation": "本研究提出了一种采用深度核学习（DKL）的主动学习方法来探索和利用化学实体数据库中的分子性质。DKL通过直接连接结构嵌入和性质信息，形成了优先级排序的潜空间，并通过迭代重新计算与目标性质和匹配的嵌入向量，来揭示关键分子性质的最大值和未探索区域的创新潜力，这为分子研究和发现开辟了新的途径", "conclusion": "本研究通过动态结构嵌入展示了DKL在分子性质研究中的应用，揭示了可进一步探索的分子区域，并强调了DKL在分子研究和发现中的潜力。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.14628", "html_url": "https://arxiv.org/abs/2312.14628", "title": "跨整个AI产品生命周期对联邦学习可持续性的全面分析", "title_en": "Holistic analysis on the sustainability of Federated Learning across AI product lifecycle", "authors": "Hongliu Cao", "background": "随着对隐私保护的新兴法律要求和政策的增多，各行各业的企业纷纷采用联邦学习（FL）这一分散式方法。这种方法通过多个客户或数据孤岛，在中央服务器协调下共同训练全局模型，同时使用各自的私有本地数据，避免了传统方法所需的原始数据共享和传输。尽管跨孤岛联邦学习正在被广泛采用，但其碳足迹仍由于研究不足而未被充分了解。本研究旨在填补这一空白，评估跨孤岛联邦学习在整个AI产品生命周期中的可持续性，而不仅仅是模型训练阶段。", "innovation": "引入了一种创新的数据和应用管理系统，将跨孤岛联邦学习与分析集成，以提高IT企业的可持续性和经济效率。同时，研究提供了一个强大的量化框架，用于评估现实世界跨孤岛联邦学习环境中的成本和CO2排放。", "conclusion": "跨孤岛和集中式学习的模型训练能源消耗和成本具有可比性。然而，集中式学习中的额外数据传输和存储需求可能导致显著且常被忽略的CO2排放。该研究发现揭示了跨孤岛联邦学习和集中式学习之间的另一种重要区别，为企业提供了优化其可持续性和经济效益的方法。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12414", "html_url": "https://arxiv.org/abs/2507.12414", "title": "AutoVDC：使用视觉语言模型进行自动视觉数据清洗", "title_en": "AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models", "authors": "Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding", "background": "训练自动驾驶系统的需要大量的带有精确注解的数据集，以达到稳健的性能。手工注解数据集具有不完美的地方，且常常需要多次迭代来生成高质量的数据集，但手动审查大型数据集是耗时且昂贵的。为此，本文介绍了一个名为AutoVDC（Automated Vision Data Cleaning）的框架，并探讨了利用视觉语言模型（VLMs）自动识别视觉数据集中的错误注解的可能性，从而帮助用户消除这些错误并提高数据质量。试验通过故意向KITTI和nuImages数据集注入错误注解来验证方法的有效性，这些数据集包含了用于自动驾驶的物体检测基准。", "innovation": "通过引入AutoVDC框架，利用视觉语言模型自动识别数据集中的错误注解，能够显著提高数据集的质量，并且比人工审查更加高效和经济。该方法通过比较不同视觉语言模型的检测率和探索微调视觉语言模型对数据清洗管道的影响，展示了其在错误检测和数据清洗实验中的高性能，表明了其在提高自动驾驶领域大规模生产数据集的可靠性和准确性方面的潜力", "conclusion": "本文的方法在错误检测和数据清理实验中的高性能表现，表明其在提高自动驾驶领域大规模生产数据集的可靠性和准确性方面具有巨大的潜力。通过比较不同视觉语言模型的检测率以及研究模型微调对整个流水线的影响，进一步验证了AutoVDC的有效性和实用性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12466", "html_url": "https://arxiv.org/abs/2507.12466", "title": "语言模型在预训练数据与目标任务相匹配时性能提高", "title_en": "Language Models Improve When Pretraining Data Matches Target Tasks", "authors": "David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan", "background": "现有的每一个数据选择方法都有一个潜在的目标，通常这种目标会通过基准驱动的迭代过程隐性地出现。研究人员会先开发选择策略，然后训练模型，并通过基准性能衡量来调整模型。这引发了这样的问题：如果我们能将这种优化过程明确化，会发生什么？", "innovation": "本文提出了一种名为Benchmark-Targeted Ranking (BETR) 的简单方法，它基于与基准训练样例的相似度来选择预训练文档。BETR将基准示例和预训练文档样本嵌入到共享空间中，并通过相似度来评分，然后训练一个轻量级分类器来预测全集的评分。通过训练超过500个模型并拟合它们的扩展关系定律，作者发现在数据选择方法中BETR简单地使预训练数据与评估基准对齐相较于DCLM-Baseline显示出2.1倍的计算效率提升（相较于非过滤数据为4.7倍），并且在所有尺度上提高了90%以上的任务性能。BETR方法表现出了良好的泛化能力，在面对与其他评估套件不同的多样化基准时，依然能够匹配或超越基线。进一步的扩展分析表明，更大的模型对过滤策略的要求就较低，表明直接匹配预训练数据与目标任务能精确地塑造模型能力，并强调了最优选择策略需要适应模型规模的重要性.", "conclusion": "研究发现，直接将预训练数据与目标任务精确匹配显着塑造了模型能力，表明优化数据选择策略必须适应模型规模。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.12216", "html_url": "https://arxiv.org/abs/2312.12216", "title": "共享即CAIRing：表征通用隐私评估原则并评估合成表格数据隐私保护属性", "title_en": "Sharing is CAIRing: Characterizing Principles and Assessing Properties of Universal Privacy Evaluation for Synthetic Tabular Data", "authors": "Tobias Hyrup,Anton Danholt Lautrup,Arthur Zimek,Peter Schneider-Kamp", "background": "在许多领域，尤其是医疗领域，数据共享是促进创新的基础。然而，由于保护个人隐私的法律法规限制了数据共享的能力，合成表格数据作为一种提供数据共享解决方案的方法已被证明有效，但前提是必须确保数据隐私。目前缺乏适当的评估方法来衡量合成数据的隐私保护能力，这阻碍了研究结果之间的比较。本文作者认为这是首次识别构成良好的通用隐私评估指标属性的研究，旨在使这些指标具有跨研究的可比性，并使非技术利益相关者能够理解隐私保护的程度。", "innovation": "本文提出了通用隐私评估指标的四个原则（可比性、适用性、易解释性和代表性，即CAIR原则），并设计了一个评分表来量化和排名评估指标与CAIR原则的符合程度。通过评估其他研究中流行的多种评价指标的应用能力和实用性，该研究不仅对现有指标进行了排名，还指出了改进的潜力区域。这些原则有助于研究者和组织就适合合成表格数据的通用隐私评估指标达成一致意见。", "conclusion": "研究结果提供了对现有评价指标的深入洞察，不仅用于排名指标，还指出了改进的潜在领域。作者期望CAIR原则能够促进研究者和组织在选择适用于合成表格数据的通用隐私评估指标方面的共识。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12427", "html_url": "https://arxiv.org/abs/2507.12427", "title": "基于多级特征表示的单元级Histopathology组织分割", "title_en": "Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation", "authors": "Ashkan Shakarami,Azade Farshad,Yousef Yeganeh,Lorenzo Nicole,Peter Schuffler,Stefano Ghidoni,Nassir Navab", "background": "传统的组织学图像分割方法通常逐像素进行分类，这既耗费标注工作，也降低了计算效率。本文介绍了一种基于单元的组织分割框架（UTS），该框架将以32×32像素为单位的每个固定大小的图块作为分割的基本单位，而不是逐像素分类。这种方法在不牺牲精度的情况下，可以减少标注工作量并提高计算效率。", "innovation": "为实现上述方法，作者提出了一种新型的多级视觉变换器（L-ViT），它能够利用多级特征表示来捕捉组织学的细微结构和整体上下文。该方法在乳腺组织分割中取得了良好的效果，能将乳腺组织分为三个类别：浸润肿瘤、非肿瘤性间质和脂肪，并支持临床相关任务如肿瘤间质定量和手术边缘评估。", "conclusion": "UTS在459个HE染色区域中的386,371个图块上的测试结果优于U-Net变体和基于变换器的方法。相关代码和数据集将开源发布在GitHub上。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.17789", "html_url": "https://arxiv.org/abs/2404.17789", "title": "BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part I: PDE-Constrained Optimization", "title_en": "BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part I: PDE-Constrained Optimization", "authors": "Ray Zirui Zhang,Christopher E. Miles,Xiaohui Xie,John S. Lowengrub", "background": "论文背景讲述了利用神经网络解决偏微分方程（PDE）逆问题的过程。传统的解决方法往往需要平衡残差和数据损失，这会导致鲁棒性较差的问题。本文提出了一种新的方法，即BiLO（二阶局部算子学习），通过将PDE逆问题形式化为二阶优化问题来改进现有的方法。", "innovation": "论文提出了名为BiLO的新方法，通过将PDE逆问题描述为二阶优化问题。该方法在上下层之间交替优化，上层最小化数据损失，下层训练神经网络局部拟合PDE解算子。此外，通过引入辅助变量，该方法能高效地推断PDE中的未知函数，并提供理论分析支持。这种方法能够强制执行严格的PDE约束，对稀疏和嘈杂的数据具有鲁棒性，并消除了现有许多方法中的残差和数据损失之间的平衡问题。", "conclusion": "通过在多个PDE系统上的广泛实验，本文证明了BiLO方法对PDE约束的强制执行、对稀疏和嘈杂数据的鲁棒性以及消除了现有方法中残差和数据损失之间的平衡需求。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.00979", "html_url": "https://arxiv.org/abs/2409.00979", "title": "随机高斯过程上确界算法的遗憾分析", "title_en": "Regret Analysis for Randomized Gaussian Process Upper Confidence Bound", "authors": "Shion Takeno,Yu Inatsu,Masayuki Karasuyama", "background": "高斯过程上确界（GP-UCB）是一种理论上确立的贝叶斯优化（BO）算法，其中假设目标函数$f$服从高斯过程（GP）。然而，GP-UCB的一个显著缺点是理论上的置信参数$\beta$随着迭代增加而变得过大。", "innovation": "本文分析了改进随机化的GP-UCB（IRGP-UCB），它使用来自偏移指数分布的置信参数。通过分析期望遗憾和条件期望遗憾，证明了在输入域有限的情况下，IRGP-UCB在不增加置信参数的情况下实现了亚线性遗憾上界。同时，通过证明使用恒定置信参数的GP-UCB可能导致线性增长的期望累积遗憾，突显了随机化的作用。", "conclusion": "最后，通过使用合成函数、基准函数和实际的仿真实验展示了IRGP-UCB的优势。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.08788", "html_url": "https://arxiv.org/abs/2406.08788", "title": "理解分布偏移下链接预测器的泛化能力", "title_en": "Towards Understanding Link Predictor Generalizability Under Distribution Shifts", "authors": "Jay Revolinsky,Harry Shomer,Jiliang Tang", "background": "现有的领先链接预测(LP)模型在基准测试中表现出令人印象深刻的成果。然而，常用的基准数据集通常假设训练、验证和测试样本文档代表总体数据分布。在实际情况下，这种假设往往不成立；未受控制的因素导致新数据集样本来自与训练样本不同的分布。此外，大多数最近关于图数据集偏移的研究集中在节点级和图级任务上，往往忽视链接级任务。", "innovation": "本文介绍了一种新颖的划分策略，称为LPShift，该策略利用结构属性来诱导可控的数据分布偏移。通过在原始数据集分割的16个LPShift变体上进行实证评估SOTA LP模型，证明了LPShift的影响，并显示了模型性能的显著变化。此外，实验表明图结构对当前泛化方法的成功有强烈的影响。", "conclusion": "实验结果表明，图结构对于当前的泛化方法有很大影响，LPShift策略显著改变了模型性能，揭示了在分布偏移下链接预测器的泛化能力。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.02572", "html_url": "https://arxiv.org/abs/2411.02572", "title": "ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy", "title_en": "ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy", "authors": "Kian Kenyon-Dean,Zitong Jerry Wang,John Urbanik,Konstantin Donhauser,Jason Hartford,Saber Saberian,Nil Sahin,Ihab Bendidi,Safiye Celik,Marta Fay,Juan Sebastian Rodriguez Vera,Imran S Haque,Oren Kraus", "background": "大规模细胞显微镜筛查在药物发现和分子生物学研究中被广泛应用于研究成千上万的化学和遗传干扰对细胞的影响。为了在下游分析中使用这些图像，我们需要能够将每个图像映射到一个表示各种生物表型的空间中的模型，使得具有相似生物效应的干扰在表示上类似。因此，需要开发能够一致地表示这些干扰的高效模型和技术。", "innovation": "本文提出了迄今为止最大的细胞显微镜数据的预训练模型，使用了1.9亿参数的ViT-G/8 MAE，训练了超过8亿的显微镜图像剪辑。与之前发表的ViT-L/8 MAE相比，在遗传干扰线性可分性方面取得了60%的提升，并在全基因组生物关系召回率和重复一致性基准测试中获得了最佳的总体性能。开发了两种关键方法提高性能：（1）在精心选择和多样化的数据集上进行训练；（2）使用生物动机的线性探测任务在每个Transformer块中搜索最佳的全基因组筛查的候选表示。发现许多经过自我监督预训练的Vision Transformers，在中间层比常用最终层中呈现出更加有意义的显微镜图像表示。", "conclusion": "我们的方法和结果为成功构建大规模生物数据的基础模型提供了广泛的策略和见解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.02813", "html_url": "https://arxiv.org/abs/2411.02813", "title": "Sparse Orthogonal Parameters Tuning for Continual Learning", "title_en": "Sparse Orthogonal Parameters Tuning for Continual Learning", "authors": "Hai-Jian Ke,Kun-Peng Ning,Yu-Yang Liu,Jia-Yu Yao,Yong-Hong Tian,Li Yuan", "background": "基于预训练模型（PTM）的持续学习方法近年来引起了广泛关注。这些方法能够适应后续的下游任务而不发生灾难性遗忘。这些方法通常不会更新预训练参数，而是采用额外的适配器、提示和分类器。本文从新的视角探讨了模型在多个实时任务中学习时稀疏正交模型参数的益处，发现将多个任务中学习到的稀疏正交性合并有巨大的潜力解决灾难性遗忘问题。", "innovation": "提出了一个新的有效方法SoTU（稀疏正交参数调整），该方法假设其有效性在于将多领域学习的知识转化为正交δ参数的融合。实验结果显示该方法在多种持续学习基准测试中具有显著效果，能够为实时数据提供最佳特性表示，无需复杂分类器设计，使其成为即插即用的解决方案。", "conclusion": "SoTU方法在持续学习中能够有效解决灾难性遗忘问题，且无需复杂的分类器设计，展示出良好的表现。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00265", "html_url": "https://arxiv.org/abs/2411.00265", "title": "通过证据理论量化现代神经网络的校准错误", "title_en": "Quantifying calibration error in modern neural networks through evidence based theory", "authors": "Koffi Ismael Ouattara", "background": "神经网络在关键应用中的部署依赖于其可靠性、信心和不确定性，而传统的评估指标如准确率和精度无法全面捕捉这些方面，特别是在模型表现出过度自信的情况下。因此，需要一种新的方法来评估神经网络的信任度。", "innovation": "本文提出了一种新的框架，通过结合主观逻辑来评估预期校准误差（ECE），以量化神经网络的信任度。该方法通过聚类预测概率和使用适当融合操作符融合意见，提供了信任、不信任和不确定性的全面度量。", "conclusion": "本文通过在MNIST和CIFAR-10数据集上的实验展示了该方法的有效性。经过校准后，该方法能提高模型的信任度。该框架为AI模型提供了一种更具可解释性和细致的评估方法，并可在医疗保健和自主系统等敏感领域找到应用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.09127", "html_url": "https://arxiv.org/abs/2411.09127", "title": "复杂性感知的深度神经网络训练以实现最优结构发现", "title_en": "Complexity-Aware Training of Deep Neural Networks for Optimal Structure Discovery", "authors": "Valentin Frank Ingmar Guenter,Athanasios Sideris", "background": "现有深度神经网络 pruning 技术大多依赖于预训练网络或是不能在训练过程中自适应地平衡学习准确性和 network 精简程度。本文在训练过程中提出了一种新型算法，能够在不需要预训练网络的情况下进行单元和层的联合剪枝，并优化学习准确性和 prune 比例之间的权衡。", "innovation": "本文算法引入了一个结合了预测准确性和网络精简的代价函数，并且通过一个优化问题的形式化描述来寻找最优网络结构。在优化过程中，当变分参数收敛于0时，对应的网络结构将永久失效，从而节省计算量。此外，该算法能够自适应地选择多个正则化参数，防止训练过程中过早地 prune 单元和层。", "conclusion": "本文提出的算法在 CIFAR-10/100 和 ImageNet 数据集上使用 ResNet 架构进行了测试，表明它在精简比和测试准确性方面优于仅层或仅单元的剪枝方法，并且与需要预训练网络的联合单元和层剪枝算法具有竞争力。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03103", "html_url": "https://arxiv.org/abs/2410.03103", "title": "基于展望长度预测的规划感知代码填充", "title_en": "Planning-Aware Code Infilling via Horizon-Length Prediction", "authors": "Yifeng Ding,Hantian Ding,Shiqi Wang,Qing Sun,Varun Kumar,Zijian Wang", "background": "填充中间代码（FIM）或填充已成为代码语言模型的核心功能之一，它允许在给定左侧和右侧上下文的情况下生成丢失的代码。然而，当前的FIM训练范式，例如重排序序列的下一个标记预测（NTP），会导致模型难以生成与周围上下文很好地对齐的内容。我们假设仅依靠NTP不足以让模型学会在远程右侧上下文条件下有效的计划，这是一个对成功代码填充至关重要因素。", "innovation": "提出了一种新的训练目标：展望长度预测（HLP），该目标使模型能够预测在每个步骤中剩余中间标记的数量。HLP通过前瞻计划推进FIM，使模型能够固有的学习对任意左侧和右侧上下文进行填充的边界，而无需依赖于数据集特定的后处理。研究表明，HLP在多模型家族和规模上显著提升了FIM性能，最高相对提高24%，并且在文件级别和仓库级别上表现出色。此外，通过HLP增强的计划能力也提高了代码推理的模型性能。这项技术几乎不会增加训练开销且没有额外的推理成本，从而确保其实用性适用于现实场景。", "conclusion": "展望长度预测（HLP）显著提高了FIM性能，并增强了模型的代码推理能力，同时保持了低开销，可广泛应用于实际场景。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.08355", "html_url": "https://arxiv.org/abs/2410.08355", "title": "Metalic: 基于蛋白质语言模型的上下文元学习", "title_en": "Metalic: Meta-Learning In-Context with Protein Language Models", "authors": "Jacob Beck,Shikha Surana,Manus McAuliffe,Oliver Bent,Thomas D. Barrett,Juan Jose Garau Luis,Paul Duckworth", "background": "蛋白质生物物理和功能特性的预测对于计算蛋白设计至关重要。机器学习已显示出在这些预测任务中的潜力。然而，由于实验室数据的限制，现存模型往往缺乏特定于预测任务的数据。因此，这些模型通常会被训练于一般性蛋白序列建模任务，继而进行微调或零样本应用，直接用于蛋白适应性预测。这种做法基于模型假设序列似然度与适应性分数之间存在强相关性。相比之下，该研究提出了一种元学习方法，应用于标准的适应性预测任务分布，从而在未见任务中表现出积极的迁移。该方法在计算蛋白适配性预测基准（ProteinGym）中，尤其是在数据稀缺的情况下，提升了现有最佳成果。", "innovation": "提出了名为Metalic（元学习即插即用）的方法，利用上下文元学习和微调结合的方式，即使在无任务数据可用时，也可以根据现有数据进行模型适配和迁移。该方法在使用不到现有领先模型八分之一的参数下，实现了卓越的预测性能，并且特别在蛋白质工程所需的数据稀缺情况下，重新定义了适应性预测的基准。", "conclusion": "元学习将在蛋白质工程领域发挥关键作用，有助于解决数据短缺问题，推动蛋白质设计的发展。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.05813", "html_url": "https://arxiv.org/abs/2411.05813", "title": "AI for Explosive Ordnance Detection in Clearance Operations: The State of Research", "title_en": "AI for Explosive Ordnance Detection in Clearance Operations: The State of Research", "authors": "Björn Kischelewski,Gregory Cathcart,David Wahl,Benjamin Guedj", "background": "爆炸物（EO）的检测和清除过程目前主要依赖手动操作，风险极高，可以受益于技术进步以提高其效率和有效性。近年来，基于人工智能（AI）的EO检测研究显著增长，但由于研究领域广泛，难以全面了解当前趋势和进展。因此，本文对AI在EO检测中的相关学术研究进行了文献综述，发现研究主要分为AI在EO目标检测和EO风险预测两个主要方向，而后者的研究较少。", "innovation": "本次研究提供了一篇关于AI在EO检测中的文献综述，区分出了两个主要的研究方向，并指出了三个未来研究的机会点：重新努力在EO风险预测方面的研究，组合不同的AI系统和数据源，以及采用基于模式的新方法来提高EO风险预测性能。此外，还强调了传统机器学习在该任务中的作用，动态融入专家知识到模型的重要性，以及有效集成AI系统与实际操作的必要性。", "conclusion": "文章对AI在EO检测中的未来进行了展望，认为应更加重视EO风险预测的研究，将不同的AI系统和数据源进行结合，探索新的方法提升预测性能，并强调需结合传统机器学习，动态整合专家知识，有效地将AI系统与实际操作相结合。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05668", "html_url": "https://arxiv.org/abs/2502.05668", "title": "同构神经网络上（随机）次梯度下降的后期训练动态", "title_en": "The late-stage training dynamics of (stochastic) subgradient descent on homogeneous neural networks", "authors": "Sholom Schechtman,Nicolas Schreuder", "background": "该研究分析了常步长随机次梯度下降（SGD）的隐含偏见。研究背景集中在二元分类，采用带有ReLU激活函数（如MLP和CNN）但没有偏差的同构神经网络。研究者们从连续场流的角度解释了正则化SGD迭代的动力学，并将其与分类边缘的规范边缘关联起来。", "innovation": "本研究是首次将Lyu和Li（2020）对梯度下降离散动力学的分析扩展至非光滑和随机的设置，证明了在后期训练阶段，归一化的SGD迭代趋向于规范边缘的临界点（假设数据具有正的规范边缘并正确分类）。研究结果还适用于指数损失或逻辑损失的二元分类。", "conclusion": "研究结论表明，在后期训练中，归一化的SGD迭代趋向于由数据正确分类（带正规范边缘）所确定的临界点集。这是对Lyu和Li（2020）工作的重要扩展，适用于更广泛的设置，包括非光滑和随机情况下二元分类的分析。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.02004", "html_url": "https://arxiv.org/abs/2403.02004", "title": "粒子梯度下降算法的误差界及其对log-萨博列夫不等式和泰拉格兰不等式的推广", "title_en": "Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities", "authors": "Rocco Caprio,Juan Kuntz,Samuel Power,Adam M. Johansen", "background": "本文证明了最近提出的粒子梯度下降（PGD）算法的非渐近误差界，该算法通过离散自由能梯度流实现了大规模潜在变量模型的最大似然估计。文章基于最优传输理论中的李萨如不等式以及优化理论中的波莱-洛贾斯维次条件，将其推广应用于新的情境，从而证明了模型在满足一定条件下自由能的最小值收敛速度，同时控制了粒子梯度下降的离散误差，得到了非渐近误差界。这些理论推导结合了优化和概率多方面的知识，为大规模复杂模型的参数估计提供了强有力的工具和理论支持。", "innovation": "本文通过结合最优传输理论和优化理论的结果，推广了李萨如不等式和波莱-洛贾斯维次条件，并将其应用于粒子梯度下降算法的误差分析。此外，通过分析具有强凹对数似然性的模型的自由能随温度变化的稳定性，进一步控制了粒子梯度下降算法的离散误差，得到了非渐近误差界。作者也将这些理论成果的应用扩展到了粒子梯度下降不仅关注应用层面，同时也提出了新的不等式的兴趣价值", "conclusion": "本文对公司模型利用粒子梯度下降方法进行了非渐近误差估计，具体在证明自由能的收敛速度及离散误差方面取得了显著成果。这些研究成果不仅为大规模潜在变量模型的参数估计提供了新的理论支持，还推广了领域内的理论边界，拓宽了该领域进一步研究的可能性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10438", "html_url": "https://arxiv.org/abs/2411.10438", "title": "MARS: Unleashing the Power of Variance Reduction for Training Large Models", "title_en": "MARS: Unleashing the Power of Variance Reduction for Training Large Models", "authors": "Huizhuo Yuan,Yifeng Liu,Shuang Wu,Xun Zhou,Quanquan Gu", "background": "训练深度神经网络尤其是大型模型需要高效的可扩展优化器。自适应梯度算法如Adam、AdamW及其变体一直是这一领域的核心。尽管过去十年中开发了许多用于加速凸性和非凸设置中随机优化的方差减少算法，但在训练深度神经网络或大型语言模型中的广泛应用方面，方差减少方法尚未取得突破。因此，方差减少方法在现代人工智能中仍是一种较少使用的方法。", "innovation": "本文提出了一个统一的优化框架MARS，它通过缩放随机递归动量技术将预条件梯度方法与方差减少相结合。MARS框架包含了三种版本，分别基于AdamW、Lion和Shampoo的预条件梯度更新。实验结果表明，MARS在训练GPT-2模型时比AdamW效果更好。此外，作者还将其算法与现有的优化器进行了关联。", "conclusion": "MARS在训练大型模型时表现出色，比现有的优化方法如AdamW有显著的提高，这表明方差减少技术可以在大型模型训练中发挥作用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.00765", "html_url": "https://arxiv.org/abs/2407.00765", "title": "结构化且平衡的多组分多层神经网络", "title_en": "Structured and Balanced Multi-Component and Multi-Layer Neural Networks", "authors": "Shijun Zhang,Hongkai Zhao,Yimin Zhong,Haomin Zhou", "background": "该研究提出了一种平衡的多组件和多层神经网络（MMNN）结构，旨在准确且高效地逼近具有复杂特征的功能，平衡自由度和计算成本。研究受到多组件方法的启发，该方法允许将每个组件有效地表示为单层网络，并结合多层分解策略来捕捉目标函数的复杂性。尽管MMNN可以被视为FCNN或MLP的简单修改，通过引入平衡的多组件结构，它们在训练参数、高效的训练过程和准确性方面都有显著改进。通过广泛的数值实验验证了MMNN在逼近高振荡函数和自动适应局部特征方面的有效性。", "innovation": "提出了一种平衡的多组件和多层神经网络（MMNN）结构，该结构由单层网络和多层分解策略组成，旨在更准确且高效地逼近复杂特征的功能。MMNN通过引入平衡的多组件结构，显著减少了训练参数，提升了训练效率和准确性，相较于FCNN或MLP表现出色。广泛的数值实验进一步验证了其在逼近复杂函数方面的优越性。", "conclusion": "通过MMNN的有效设计，该研究显著地提升了神经网络逼近复杂功能的能力，尤其是在计算效率和准确性方面的表现上。MMNN在高振荡函数和局部特征上的优越性能，使该模型具有广泛的应用前景。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12272", "html_url": "https://arxiv.org/abs/2502.12272", "title": "在可学习前沿学习推理", "title_en": "Learning to Reason at the Frontier of Learnability", "authors": "Thomas Foster,Jakob Foerster", "background": "强化学习现在被广泛应用于大型语言模型训练的最后阶段，尤其是在需要推理任务（如数学问题）中。通常情况下，模型在每次训练步骤中会尝试许多次问题，并尝试从成功和失败中学习。然而，研究表明，在使用两种流行算法（PPO和VinePPO）以及两种常用数据集训练过程中，许多问题要么全部正确得到解答，要么一次都没有得到解答，这两种情况都为模型提供不了有效的训练信号。", "innovation": "为解决上述问题，该研究引入了强化学习文献中的一种方法——基于学习性的采样，并将其应用在大型语言模型训练的强化学习阶段。优化后的课程学习策略优先考虑成功具有高变异性的题目，即那些有时可以成功，但并不总是成功的任务。实验结果表明这一策略在多个算法和数据集上均能提升训练效率和效果，为使用大型语言模型进行强化学习提供了更高效的路径。", "conclusion": "本研究发现，在强化学习阶段，优先处理仅仅部分成功的题目能持续提升不同类型算法和数据集上的训练性能，为大型语言模型的高效和有效强化学习奠定了基础。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.13916", "html_url": "https://arxiv.org/abs/2501.13916", "title": "PBM-VFL: 垂直联邦学习中的特征和样本隐私", "title_en": "PBM-VFL: Vertical Federated Learning with Feature and Sample Privacy", "authors": "Linh Tran,Timothy Castiglia,Stacy Patterson,Ana Milanova", "background": "背景介绍现有的垂直联邦学习算法虽然能够在保护隐私的同时进行模型训练，但往往在隐私保护与效率之间存在权衡。差分隐私保证了一定程度的隐私保护，但在垂直联邦学习中实现差分隐私的方法有限。本文基于此背景，旨在提出一种新的算法，以提高垂直联邦学习的通信效率并提供更强大的隐私保护手段。", "innovation": "创新提出了Poisson Binomial机制垂直联邦学习（PBM-VFL），该算法结合了安全多方计算与最近提出的Poisson Binomial机制，用于在模型训练过程中保护各参与方的私人数据集。本文还定义了新的特征隐私概念，并对其端到端的特征和样本隐私进行了分析。该研究首次理论化地刻画了隐私预算、收敛误差与通信成本之间的关系，并在差分隐私垂直联邦学习中提供实验验证。", "conclusion": "结论本文提出了PBM-VFL算法，通过结合安全多方计算与Poisson Binomial机制，有效地提高了差分隐私垂直联邦学习的通信效率和隐私保护。此外，该算法在一定程度上平衡了隐私保护与模型性能之间的关系，证明了在高隐私要求下仍能保持良好的模型性能。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.09357", "html_url": "https://arxiv.org/abs/2407.09357", "title": "使用生成树进行任意属性条件分子生成以及自我批判", "title_en": "Any-Property-Conditional Molecule Generation with Self-Criticism using Spanning Trees", "authors": "Alexia Jolicoeur-Martineau,Aristide Baratin,Kisoo Kwon,Boris Knyazev,Yan Zhang", "background": "当前生成分子的模型多不能生成有效的分子，而基于生成树图形生成（STGG）方法能够确保生成有效的分子。本研究进一步将STGG扩展到基于多个属性的条件生成。", "innovation": "提出了STGG+模型，包括现代Transformer架构，训练时随机掩码属性（允许基于任意属性集或无分类引导进行条件生成），辅助属性预测损失（使得模型能够自我批判以选择最佳分子），及其他改进。", "conclusion": "STGG+在分布内和分布外的条件生成以及奖励最大化方面达到了当前最佳性能。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02445", "html_url": "https://arxiv.org/abs/2503.02445", "title": "BRIDGE：通过多智能体迭代优化和扩散建模从文本引导时间序列生成", "title_en": "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling", "authors": "Hao Li,Yu-Hao Huang,Chang Xu,Viktor Schlegel,Renhe Jiang,Riza Batista-Navarro,Goran Nenadic,Jiang Bian", "background": "时间序列生成（TSG）在仿真、数据增强和反事实分析中有广泛的应用。现有方法在无条件单域时间序列生成方面显示出潜力，但实际应用需要跨域方法，能够根据特定领域约束和实例级别需求进行可控生成。文本可以提供语义见解、领域信息和实例特定的时间模式，以指导和支持时间序列生成。因此，需要一种能够利用文本控制时间序列生成的新方法。", "innovation": "该论文提出了‘文本控制时间序列生成’（Text-Controlled TSG）任务，通过结合文本描述以生成现实的时间序列。为了应对设置中的数据稀缺性，提出了一种新型基于大语言模型的多智能体框架来合成多样、现实的时间文本到时间序列（TTS）数据集。进一步引入了综合文本控制时间序列生成框架（BRIDGE），该框架将语义原型与文本描述相结合，以支持领域级别的指导。利用BRIDGE方法在11个中的12个数据集上实现了最先进的生成保真度，同时在均方误差和平均绝对误差上分别提高了12%和6%的可控性，表明它在生成定制化时间序列数据方面的潜力。", "conclusion": "通过多智能体迭代优化和扩散建模，BRIDGE框架提高了时间序列生成的保真度和可控性，尤其是在领域内指导方面。与无文本输入生成相比，该方法在生成质量上取得了显著改善，有望为实际应用提供更精确和可定制的时间序列数据。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.10543", "html_url": "https://arxiv.org/abs/2412.10543", "title": "METIS：具有配置适应性的快速高质量RAG系统", "title_en": "METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation", "authors": "Siddhant Ray,Rui Pan,Zhuohan Gu,Kuntai Du,Shaoting Feng,Ganesh Ananthanarayanan,Ravi Netravali,Junchen Jiang", "background": "RAG（检索增强生成）允许大型语言模型利用外部知识生成更好的回应，但使用更多的外部知识往往会在提高生成质量的同时增加响应延迟。以往的研究或通过改进RAG查询调度来减少响应延迟，或通过优化RAG工作流程来最大化质量，但它们往往未能同时优化延迟与质量之间的权衡。", "innovation": "METIS是首个联合调度查询并调整每个查询的关键RAG配置（如检索文本片段的数量和合成方法）的RAG系统，旨在平衡质量优化与响应延迟降低。", "conclusion": "使用4个流行的RAG-QA数据集，研究表明，相比最先进的RAG优化方案，METIS将生成延迟降低了1.64-2.54倍，同时并未牺牲生成质量。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.17965", "html_url": "https://arxiv.org/abs/2501.17965", "title": "基于双曲空间的变分组合顺序蒙特卡洛方法在贝叶斯系统发育分析中的应用", "title_en": "Variational Combinatorial Sequential Monte Carlo for Bayesian Phylogenetics in Hyperbolic Space", "authors": "Alex Chen,Philipe Chlenski,Kenneth Munyuza,Antonio Khalil Moretti,Christian A. Naesseth,Itsik Pe'er", "background": "双曲空间自然地编码了诸如系统发育学中的分枝结构等层次结构，其中内凹测地线反映了最少公共祖先路径，而邻居的数量呈指数增长反映了拓扑结构的超指数扩展。这种扩展性挑战限制了基于欧几里得的距离近似推理方法的效率。受树与双曲空间之间几何连接的启发，作者开发了一种新的双曲扩展的组合顺序蒙特卡洛算法：组合顺序蒙特卡洛（\textsc{Csmc}）和嵌套组合顺序蒙特卡洛（\textsc{Ncsmc}），引入了一致且无偏的估计器，并结合了变分推理方法（\textsc{H-Vcsmc}和\textsc{H-Vncsmc}）以改善速度、可扩展性和高维系统发育推理任务的表现.", "innovation": "创新之处在于提出了基于双曲空间的组合顺序蒙特卡洛及嵌套组合顺序蒙特卡洛的变分推理方法(\textsc{H-Vcsmc}和\textsc{H-Vncsmc})，这些方法在系统发育推理任务中比其欧几里得空间对应的算法表现出更好的性能和可扩展性，并且能够一致且无偏地进行估计.", "conclusion": "实验结果表明，在高维系统发育推理任务中，这种方法在速度、可扩展性和性能方面有所改善，所提出的双曲空间中的算法优于传统的方法."}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16994", "html_url": "https://arxiv.org/abs/2502.16994", "title": "FADE: 为何优质特征的描述变得糟糕", "title_en": "FADE: Why Bad Descriptions Happen to Good Features", "authors": "Bruno Puri,Aakriti Jain,Elena Golimblevskaia,Patrick Kahardipraja,Thomas Wiegand,Wojciech Samek,Sebastian Lapuschkin", "background": "近年来，关于机制可解释性方面的进展表明了自动化可解释性流程在分析大语言模型中的潜在价值。尽管这种方法能增强我们对内部机制的理解，但在评估所发现特征的准确性和可靠性方面仍缺乏标准化方法。本研究旨在通过介绍一种新的通用框架：FADE（Feature Alignment to Description Evaluation），来填补这一空白，FADE能够跨四个关键指标——清晰度、响应性、纯净度和忠实度，自动评估特征描述的对齐度，并系统量化特征与描述之间不一致的原因。", "innovation": "FADE是一种可扩展的、模型通用的框架，能够自动评估特征描述的对齐度。其创新在于FADE不仅考虑了特征描述的质量评估，还系统地量化了特征与描述之间的不一致原因，这有助于更好地理解大语言模型中的内部机制。该框架的应用场景包括对现有开放源代码特征描述的分析以及自动解释能力的关键组件的评估，旨在提高描述的质量。", "conclusion": "研究发现，生成特征描述时存在基本挑战，尤其是在与SJA相关的神经元相比而言，MLP神经元更为复杂。这些发现提供了关于自动解释局限性和未来发展方向的见解，并且已在GitHub上线作为开源包供公众使用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17070", "html_url": "https://arxiv.org/abs/2503.17070", "title": "对联邦学习中非独立同分布数据影响的全面评估", "title_en": "A Thorough Assessment of the Non-IID Data Impact in Federated Learning", "authors": "Daniel M. Jimenez-Gutierrez,Mehrdad Hassanzadeh,Aris Anagnostopoulos,Ioannis Chatzigiannakis,Andrea Vitaletti", "background": "联邦学习（FL）允许分布式客户端之间进行协作式的机器学习模型训练，同时保证数据隐私。联邦学习的分布式特性面对的是非独立同分布（non-IID）数据，这会导致模型性能下降和收敛时间增加。尽管非IID性是一个重要问题，但系统地解决所有数据异质性类型的实验研究仍然很少。因此，本文旨在通过彻底的实证分析评估和量化非IID效应对联邦学习的影响。", "innovation": "本文使用Hellinger距离（HD）来衡量客户端间分布差异，并首次对带有标签、特征、数量和时空偏斜性等四种类型的非IID数据处理策略进行全面评估，是在现实和受控条件下进行。这是首次对联邦学习中时空偏斜性效应进行全面分析，并着重于在特定HD阈值下不同类型的非IID性对模型性能的影响。", "conclusion": "本文研究发现，标签和时空偏斜性类型对联邦学习模型性能有显著影响，并且性能下降通常在特定HD阈值发生。此外，当非IID性极端时，联邦学习性能会受到严重影响。因此，本文提供了针对数据异质性的有效策略，极大地扩展了对非IID性的研究，并为未来的研究奠定了坚实基础。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16075", "html_url": "https://arxiv.org/abs/2502.16075", "title": "非同质化深度网络中梯度下降的隐偏置", "title_en": "Implicit Bias of Gradient Descent for Non-Homogeneous Deep Networks", "authors": "Yuhang Cai,Kangjie Zhou,Jingfeng Wu,Song Mei,Michael Lindsey,Peter L. Bartlett", "background": "先前的研究主要集中在同质化网络的梯度下降的隐偏置上，而本文探讨的是非同质化深网络在指数损失下的渐近隐偏置问题。", "innovation": "该研究创新地证明了，对于初始经验风险足够小的梯度下降迭代点，有三个关键性质：（1）归一化间隔由梯度下降迭代点诱导并几乎单调增加；（2）虽然梯度下降迭代点的范数发散至无穷，但迭代点本身的方向收敛；（3）该方向极限满足一个最大化间隔问题的Karush-Kuhn-Tucker（KKT）条件。此外，这种方法适用于满足轻微的接近同质化条件的非同质化网络，包括具有残差连接和非同质激活函数的网络，从而解决了Ji和Telgarsky（2020）提出的一个开放问题。", "conclusion": "该研究扩展了隐偏置的分析范围，从同质化网络扩展到了多数非同质化网络，明确了梯度下降在非同质化深度网络中的收敛行为和隐偏置。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09724", "html_url": "https://arxiv.org/abs/2502.09724", "title": "导航多目标强化学习的社会福利前沿：多元策略组合", "title_en": "Navigating the Social Welfare Frontier: Portfolios for Multi-objective Reinforcement Learning", "authors": "Cheol Woo Kim,Jai Moondra,Shresth Verma,Madeleine Pollack,Lingkai Kong,Milind Tambe,Swati Gupta", "background": "在实际应用中的强化学习(RL)中，部署的策略对不同利益相关者的影响力各异，这给有效集约他们的偏好带来了挑战。广义 $p$-平均是一个广泛应用的社会福利函数类别，广泛应用于公平资源分配、AI对齐和决策制定。这些函数包括著名的福利函数如等能福利、纳什福利和功利主义福利。然而，决策者在选择适当的社会福利函数时却面临挑战，因为最优策略的结构和结果对 $p$ 的选择非常敏感。为了应对这一挑战，我们研究了RL中的$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\beta}}}}}}}}$-近似组合的概念，这是一种政策集，它们在所有 $p \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\beta}}}}}}}$ 值下的广义 $p$-平均都有近似最优性。我们提出了计算这些组合的算法，并提供了关于近似因子、组合大小和计算效率之间权衡的理论保证。在合成和真实数据集上的实验证明了我们方法在系统地概括由不同 $p$ 值引起的策略空间方面有效，使决策者能够更有效地探索这一领域。", "innovation": "我们提出了$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\beta}}}}}}}$-近似组合的概念，这是一种政策集，它们在所有 $p \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\beta}}}}}}}$ 值下的广义 $p$-平均都有近似最优性。该方法解决了选择适当的社会福利函数的挑战，并提供了计算这些组合的算法和理论上关于近似因子、组合大小和计算效率之间权衡的保证。通过实验证明了该方法的有效性，能够在多元优化问题中帮助决策者更有效地导航策略空间。", "conclusion": "该研究通过提出$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\beta}}}}}}}$-近似组合的概念，并提供相关算法和理论保证，有效帮助决策者选择合适的社会福利函数，并在多目标的RL中更有效地探索策略空间。实验结果表明了该方法在解决RL中复杂偏好汇总问题的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07618", "html_url": "https://arxiv.org/abs/2504.07618", "title": "CTSR: 基于笛卡尔张量稀疏回归的数据驱动高维不变控制方程发现", "title_en": "CTSR: Cartesian tensor-based sparse regression for data-driven discovery of high-dimensional invariant governing equations", "authors": "Boqian Zhang,Juanmian Lei,Guoyou Sun,Shuaibing Ding,Jian Guo", "background": "准确简洁的控制方程对于理解系统动态至关重要。近年来，通过稀疏回归等数据驱动方法从数据中自动发现控制方程已成为传统基于原理的建模方法的一种重要转变。然而，大多数现有方法主要适用于简单的低维场景，并且难以在确保旋转和反射不变性的同时保持高精度和高效率。", "innovation": "本文提出了一种基于笛卡尔张量的稀疏回归（CTSR）技术，能够在保证旋转和反射不变性的前提下，准确高效地发现高维复杂控制方程，克服了现有方法在适用性和计算成本上的局限性。", "conclusion": "通过在两个二维和两个三维测试案例中的评估表明，所提出的方法在准确性和效率上都优于传统方法。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12937", "html_url": "https://arxiv.org/abs/2502.12937", "title": "图基于半监督学习中算法和架构超参数的调优及其可证明保证", "title_en": "Tuning Algorithmic and Architectural Hyperparameters in Graph-Based Semi-Supervised Learning with Provable Guarantees", "authors": "Ally Yalei Du,Eric Huang,Dravyansh Sharma", "background": "半监督学习是一种强大的机器学习范式，用于建模和利用捕获标记和未标记数据之间关系的图结构。已经提出了许多经典和现代基于深度学习的方法来解决这个问题，这些方法通常具有可调的超参数。本文探讨了从参数化算法家族中调优算法的超参数的问题。研究了三种经典标签传播算法家族中的超参数选择，取得了关于所需的未标记数据量以学习保证良好参数的新型$O(\text{log} n)$伪维度上界。进一步提供了对数阶的下界，从而精确地表征了超参数调优问题的学习理论复杂性。此外，还研究了在现代图神经网络中选择架构超参数的方法，并限制了近期提出的简化图卷积（SGC）网络中的拉普拉斯复杂性。提出了一种可调架构，实现了图卷积神经网络（GCN）和图注意网络（GAT）在每层的插值，提供了拉普拉斯复杂性界并调优插值系数的界限。", "innovation": "1. 提出了从经典标签传播算法家族中调优超参数的新方法，取得了$O(\text{log} n)$伪维度上界，并提供了匹配的下界，精确表征了超参数调优问题的学习理论复杂性。\n2. 探讨了现代图神经网络架构超参数的调优方法，提供了简化图卷积（SGC）网络中拉普拉斯复杂性的上界，并提出了一种可调架构，实现了图卷积神经网络和图注意力网络的层间插值，并提供了调优插值系数的拉普拉斯复杂性界限。\n3. 为保证超参数调优的有效性提供了可证明的保证。", "conclusion": "本文通过研究图基于半监督学习中算法和架构超参数的调优问题，提出了可证明的保证，展示了在不同类型的算法家族中调优超参数的方法，以及在现代图神经网络中的插值架构调优，并提供了相应的理论界。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03560", "html_url": "https://arxiv.org/abs/2507.03560", "title": "简化图核提高效率", "title_en": "Simplifying Graph Kernels for Efficient", "authors": "Lin Wang,Shijie Wang,Sirui Huang,Qing Li", "background": "尽管核方法和图神经网络（GNNs）各有优势，但将两者集成面临效率和可扩展性方面的挑战。图神经核通过神经核方法提供了一种理论桥梁，但这种方式依赖于深层堆叠的网络层，导致重复计算并影响性能。", "innovation": "本文提出了一种简化图核方法，替代深层堆叠网络层为简化版本的 $K$-步消息聚合过程。此外，还提出了一种基于高斯过程理论的简化图核，能够分析无限宽度GNNs的核值而不需要模拟网络深度，从而进一步减少复杂性。", "conclusion": "实验表明，作者的方法在标准图和节点分类基准测试中达到了具有竞争力的准确率，同时减少运行时间，使其成为大规模图学习的实用替代方案。完整的实现和可重复使用的材料已提供。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03034", "html_url": "https://arxiv.org/abs/2507.03034", "title": "重新思考人工智能时代的数据保护", "title_en": "Rethinking Data Protection in the (Generative) Artificial Intelligence Era", "authors": "Yiming Li,Shuo Shao,Yu He,Junfeng Guo,Tianwei Zhang,Zhan Qin,Pin-Yu Chen,Michael Backes,Philip Torr,Dacheng Tao,Kui Ren", "background": "生成型人工智能（AI）时代极大地重塑了数据的意义和价值。数据不仅不再局限于静态内容，而是贯穿于AI生命周期的每一个阶段，从塑造模型参数的训练样本到驱动实际模型部署的提示和输出。这种转变使传统的数据保护概念变得不足，而需要保护的数据边界依然不明确。因此，无法保护AI系统中的数据可能会对社会和个人造成严重影响，这强调了明确界定数据保护范围并严格执行的重要性。", "innovation": "提出了一个四层分类税则，包括不可使用性、隐私保护、可追溯性和可删除性，这些层次捕捉了现代生成型AI模型和系统中出现的多样化保护需求。该框架提供了一种结构化的理解数据效用与控制之间的权衡，涵盖了整个AI管道，包括训练数据集、模型权重、系统提示和AI生成的内容。此外，该框架分析了每层的代表性技术方法，并揭示了监管空白，使关键资产面临风险。", "conclusion": "通过提供一个结构化的视角来使未来的AI技术和治理与可信赖的数据实践保持一致，该研究强调了重新审视现代AI技术的数据保护的紧迫性，并为开发者、研究人员和监管者提供了及时的指导。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03833", "html_url": "https://arxiv.org/abs/2507.03833", "title": "MatRL: 通过蒙特卡洛树搜索实现可证明可泛化的迭代算法发现", "title_en": "MatRL: Provably Generalizable Iterative Algorithm Discovery via Monte-Carlo Tree Search", "authors": "Sungyoon Kim,Rajat Vadiraj Dwaraknath,Longling geng,Mert Pilanci", "background": "迭代方法用于计算矩阵函数已被广泛研究，通过优化参数设置和混合不同类型的迭代可以显著提高收敛速度。然而，在现代计算环境中，手动调优设计选项以实现最佳性能非常麻烦，尤其是存在多种经典的迭代类型及其变种，每种都有非平凡的每步成本和需要调优的参数。", "innovation": "提出了一个基于强化学习的框架MatRL，可以自动发现计算矩阵函数的迭代算法。通过将算法设计视为顺序决策过程，并利用蒙特卡洛树搜索生成针对特定输入矩阵分布和计算环境的混合矩阵迭代和步长序列。此外，证明学习到的算法在相同分布的足够大矩阵上具有可泛化性。", "conclusion": "通过理论分析和数值实验验证了MatRL生成的算法在文献中的基线算法上表现出优越性，证明了其在更大矩阵上的可泛化性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23210", "html_url": "https://arxiv.org/abs/2506.23210", "title": "FedRef: 通信高效的贝叶斯微调方法及参考模型", "title_en": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model", "authors": "Taehwan Yoon,Bongjun Choi", "background": "联邦学习（FL）用于分布式场景下训练人工智能（AI）模型，同时确保用户的隐私。在联邦学习场景中，服务器通常不会了解用户的数据，这使得AI的训练过程在数据隐私方面更加高效。然而，从模型性能来看，联邦学习的AI模型可能不能很好地满足AI用户的期望。此外，AI用户的需求差异很大，很难满足所有用户的需求。这些问题可以通过AI模型优化、微调或个性化来进行解决，以实现最佳的模型性能。", "innovation": "该研究提出了一种基于参考模型的联邦学习方法（FedRef），以实现最佳的微调，并克服了每轮中出现的灾难性遗忘问题。这种方法基于贝叶斯参数高效迁移学习，包含最优邻近项，利用参考模型整合前序模型参数，从而同时实现高模型性能和客户端的低计算成本。", "conclusion": "联邦学习中的新方法FedRef通过将参考模型引入贝叶斯参数高效迁移学习，成功地解决了每轮中存在的灾难性遗忘问题，确保了模型性能的高度优化，同时也降低了客户端的计算成本。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03205", "html_url": "https://arxiv.org/abs/2504.03205", "title": "BondMatcher：分子系统的氢键稳定性分析", "title_en": "BondMatcher: H-Bond Stability Analysis in Molecular Systems", "authors": "Thomas Daniel,Malgorzata Olejniczak,Julien Tierny", "background": "本文探讨了氢键（H键）的稳定性，利用量子原子分子理论（QTAIM）进行表征。研究首先提供了一个包含4544个电子密度的数据集，涵盖了水六聚体（称为环、书本、笼子和棱柱的四种异构体），通过在其平衡几何结构下施加各种结构扰动来生成它们的电子密度。研究还介绍了一种新的稳定性衡量标准，即“键出现率”，并提出了一种名为BondMatcher的基于几何感知的局部同构估计的自动计算算法，用于确定每个存在于平衡态中的键路径在其输入集合中出现的频率。这些方法使得可以通过电子密度数据库进行氢键路径的自动识别和后续的视觉检查，从而验证实验观察并提供更精确的几何标准来描述氢键路径的消失。", "innovation": "本文的创新在于提出了一个电子密度数据库，包含4544个电子密度，专注于水六聚体的不同异构体（环、书本、笼子和棱柱），并介绍了一种新的稳定性衡量标准——键出现率。此外，还开发了BondMatcher算法，用于自动计算有效键路径在电子密度中的出现频率。", "conclusion": "本文介绍了电子密度数据库和BondMatcher算法，能够自动识别缺乏氢键路径的密度，对氢键路径的消失提供了细致的拓扑分析，证实了实验观察并提出了精确的几何标准来描述分子系统中的氢键稳定性。这些成果可应用于分子系统的氢键稳定性分析，提供了新的视觉和分析工具。相关的电子密度数据库和C++实现可以访问：this https URL"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07883", "html_url": "https://arxiv.org/abs/2507.07883", "title": "SAMO: 一种基于联合全局-局部扰动的轻量级自锐化多任务优化方法", "title_en": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation", "authors": "Hao Ban,Gokul Ram Subramani,Kaiyi Ji", "background": "多任务学习（MTL）能够通过联合模型捕捉多个任务之间的共性，从而减少计算成本和提高数据效率。然而，MTL优化中的一个主要挑战是任务冲突，当任务梯度方向或大小不同时，这会导致模型性能不及单一任务对应模型。作为缓解任务冲突的策略，‘自锐化最小化’（SAM）通过同时最小化任务损失和减少损失景观的锐度来实现。尽管观察表明SAM能有效缓解MTL中的任务冲突，但在将SAM集成到MTL时仍面临两个关键挑战：如何有效结合全局和局部信息，以及直接计算每项任务的梯度会引入显着的计算和内存开销。", "innovation": "为了应对上述挑战，作者提出了一种名为SAMO（Sharpness-Aware Multi-task Optimization）的轻量级方法，该方法利用联合全局-局部扰动。局部扰动仅通过前向传播来近似计算，并按层进行归一化，以提高效率。这一方法不仅证明了其有效性和高效性，还在多项多任务基准上的广泛实验中展示了其优势。", "conclusion": "实验结果表明，SAMO方法能够有效地优化多任务学习中的任务冲突，同时简化了过程并提高了效率。相关代码可在提供的网址获取。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09016", "html_url": "https://arxiv.org/abs/2507.09016", "title": "利用人类凝视建模增强RLHF", "title_en": "Enhancing RLHF with Human Gaze Modeling", "authors": "Karim Galliamov,Ivan Titov,Ilya Pershin", "background": "RLHF通过人类反馈使语言模型与人类偏好对齐，但这种方法计算成本高。", "innovation": "提出两种利用人类凝视建模的方法来增强RLHF：（1）凝视敏感的奖励模型；（2）基于凝视的稀疏奖励在标记级别上的分布。", "conclusion": "实验表明，凝视引导的RLHF在保持或略微提高性能的同时，实现了更快的收敛，从而减少了策略优化过程中的计算成本。结果表明，人类凝视提供了一个有价值且未充分利用的优化指标信号，指向提高RLHF效率的有前途的方向。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15110", "html_url": "https://arxiv.org/abs/2504.15110", "title": "Kolmogorov-Arnold Networks: 推荐性保证函数及其导数的逼近和学习", "title_en": "Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for Functions and their Derivatives", "authors": "Anastasis Kratsios,Bum Jun Kim,Takashi Furuya", "background": "Kolmogorov-Arnold超迭定理启发下，Kolmogorov-Arnold 网络（KANs）作为改进的深度学习框架核心，比MLP predecessor更具适应性，通过允许可训练的分段函数激活函数。本文深入探讨了KAN架构的理论基础，证明了其在有界的或甚至是分形域$\boldsymbol{\text{X}} \text{ in } \boldsymbol{\text{R}}^d$上以最优逼近率逼近任何 Besov 函数$B^{s}_{p,q}(\boldsymbol{\text{X}})$，特别地，当与较弱的Besov范数$B^{\boldsymbol{\text{α}}}_{p,q}(\boldsymbol{\text{X}})$相关时。同时，本文提供了残差KAN模型在从$N$个独立同分布的无噪声样本中学习Besov正则性函数时的样本复杂性估计。", "innovation": "本文通过证明KAN架构可以最优逼近Besov范数函数，提供了一个针对函数及其导数的学习和逼近保证。模型设计进一步利用了残差/跳转连接来集成现代深度学习理论。", "conclusion": "本文确认了KAN架构在有界或分形域上以最优逼近率逼近Besov范数函数的能力，并提供了一个关于从无噪声独立同分布样本中学习Besov正则性函数的残差KAN模型的样本复杂性的无维估计。KAN架构整合了现代深度学习的最新知识，特别是其改进的残差连接。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09888", "html_url": "https://arxiv.org/abs/2507.09888", "title": "NeuTSFlow: 在时间序列预测中建模背后的连续函数", "title_en": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting", "authors": "Huibo Xu,Likang Wu,Xianquan Wang,Haoning Dang,Chun-Wun Cheng,Angelica I Aviles-Rivero,Qi Liu", "background": "时间序列预测是一项基础任务，具有广泛应用，但传统方法通常将数据视为离散序列，忽视了它们作为连续过程的噪声样本的本质。离散的噪声观测无法唯一确定连续函数，而是对应一系列可能的函数。从数学角度看，时间序列可以被视为由共享概率测度支配的一系列连续函数的噪声观测。因此，预测任务可以重新构想为从历史函数家族学习到未来函数家族的转换。这一重新构想引入了两个关键挑战：如何利用历史和未来的离散观测来学习它们潜在连续函数之间的关系，如何在函数空间中建模从历史函数家族到未来函数家族的转换路径。", "innovation": "提出了NeuTSFlow，一种新的框架，利用神经算子促进流匹配，用于学习历史和未来函数家族之间测度的变化路径。NeuTSFlow通过参数化流的速度场在无限维函数空间中移动，超越了传统方法依赖于离散点之间的依赖性，直接建模函数级别的特征。", "conclusion": "在不同预测任务上的实验结果表明，NeuTSFlow在准确性和鲁棒性方面优于传统方法，验证了函数家族视角的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10452", "html_url": "https://arxiv.org/abs/2507.10452", "title": "关于梯度占优和LQR策略优化的一些注记", "title_en": "Some remarks on gradient dominance and LQR policy optimization", "authors": "Eduardo D. Sontag", "background": "优化问题的解决方案，包括强化学习中的策略优化，通常依赖于某种形式的梯度下降。最近，在机器学习、控制和优化领域，研究人员利用Polyak-洛赞斯基不等式（PLI）来研究损失函数在梯度流下的局部迭代中的指数收敛率。然而，对于如连续时间LQR问题中的策略迭代，这种收敛率在初始条件大时会消失，导致混合的全局线性和局部指数行为。与之相比，离散时间LQR问题可以实现全局指数收敛。这种从CT到DT行为的差距促使人们寻找PLI的各种推广条件，并且本文将处理这一课题。此外，这些推广条件对于理解梯度估计误差等瞬态和渐近效应至关重要，这些误差可能源于对抗性攻击、脱机 oracle 错误评估、仿真过早中断、不准确和非常近似的数字双胞胎、随机计算（算法定序性）或从有限数据采样学习等问题。", "innovation": "本文描述了关于梯度占优和LQR策略优化的一些注记，特别是提出了关于梯度估计误差瞬态和渐近效应的分析，以及线性前馈神经网络在反馈控制中的收敛性和PLI性质，并且部分工作是在与Arthur Castello B. de Oliveira, Leilei Cui, Zhong-Ping Jiang, and Milad Siami的合作下完成的。", "conclusion": "本文探讨了关于梯度占优条件的推广，并将其应用于LQR策略优化中，同时研究了在不同场景下梯度估计误差的影响。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10972", "html_url": "https://arxiv.org/abs/2506.10972", "title": "Predictable Scale: Part II, Farseer: A Refined Scaling Law in Large Language Models", "title_en": "Predictable Scale: Part II, Farseer: A Refined Scaling Law in Large Language Models", "authors": "Houyi Li,Wenzhen Zheng,Qiufeng Wang,Zhenyu Ding,Haoying Wang,Zili Wang,Shijie Xuyang,Ning Ding,Shuigeng Zhou,Xiangyu Zhang,Daxin Jiang", "background": "训练大规模语言模型（LLMs）的成本极其高昂，这导致了一个关键的扩展性缺口，其中小规模实验的见解往往无法转移到资源密集型的生产系统中，从而阻碍了高效创新。训练LLMs的成本高昂和测试需要大量资源使得深入理解其扩展规律变得困难。此前的模型扩展规律（例如Chinchilla定律）在预测大规模模型性能时存在较大的误差和不确定性。因此，迫切需要一个能够提高预测准确性和鲁棒性、更好地指导大规模语言模型训练的新扩展规律模型。", "innovation": "我们提出了Farseer，一种新颖且精确的扩展规律，它通过系统地构建模型损失面$L(N,D)$，实现了比前人法律（如Chinchilla定律）更出色的拟合能力。Farseer方法提供了一种更为精确、稳健且高度通用的预测，展示出出色的外推能力，将Chinchilla定律的外推误差降低了433%。这使得能够可靠地评估所有$(N,D)$设置下的竞争性训练策略，并将小规模的消融研究结论外推预测大规模性能。此外，Farseer还提供了对最优计算分配的新见解，更好地反映了现代LLM训练的复杂需求。我们通过训练近1000个不同规模和配置的LLM，验证了Farseer方法的准确性，并全面开源了所有模型、数据、结果和日志，以促进进一步的研究。", "conclusion": "我们引入的Farseer扩展规律模型，显著提高了大规模语言模型训练预测的准确性和鲁棒性，并提供了一种新的方法来优化训练策略。通过全面开源我们的实验数据和结果，我们期待Farseer能够为该领域的进一步研究和创新做出贡献。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10502", "html_url": "https://arxiv.org/abs/2507.10502", "title": "生物领域中AI模型的评估与基准：CZI虚拟细胞工作坊的结果与建议", "title_en": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop", "authors": "Elizabeth Fahsbender,Alma Andersson,Jeremy Ash,Polina Binder,Daniel Burkhardt,Benjamin Chang,Georg K. Gerber,Anthony Gitter,Patrick Godau,Ankit Gupta,Genevieve Haliburton,Siyu He,Trey Ideker,Ivana Jelic,Aly Khan,Yang-Joon Kim,Aditi Krishnapriyan,Jon M. Laurent,Tianyu Liu,Emma Lundberg,Shalin B. Mehta,Rob Moccia,Angela Oliveira Pisco,Katherine S. Pollard,Suresh Ramani,Julio Saez-Rodriguez,Yasin Senbabaoglu,Elana Simon,Srinivasan Sivanandan,Gustavo Stolovitzky,Marc Valer,Bo Wang,Xikun Zhang,James Zou,Katrina Kalantar", "background": "人工智能在生物学中具有巨大的潜力，然而由于缺乏标准化和跨领域的基准衡量标准，阻碍了我们构建稳定且可信赖的模型。不同领域（如成像、转录组学、蛋白质组学和基因组学）的数据异质性和噪声、可重复性挑战、偏差以及可用公开资源的分散化，都是实现生物系统模型基准化的主要技术与系统障碍。", "innovation": "本文介绍了最近一个研讨会的见解，该研讨会召集了成像、转录组学、蛋白质组学和基因组学领域的机器学习和计算生物学专家，以解决这一问题。通过促进高质量的数据整理、标准化工具的使用、全面的评估指标以及开放合作的平台，提出了建立可以在不同任务和数据模态下有效比较生物系统机器学习模型的基准框架的建议。", "conclusion": "通过建立这些高标准的基准，可以加速AI驱动虚拟细胞的发展，确保实验的严谨性、可重复性和生物学相关性，最终推动该领域向集成模型方向发展，这些模型可以促进新的发现、治疗洞察和对细胞系统更深入的理解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10678", "html_url": "https://arxiv.org/abs/2507.10678", "title": "基于群论分析基本进位下隐藏的对称性及其对神经网络可学习性的研究", "title_en": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks", "authors": "Cutter Dawes,Simon Segert,Kamesh Krishnamurthy,Jonathan D. Cohen", "background": "神经网络在模拟人类认知功能和人工智能中的一大挑战是如何设计能够高效学习支持广泛泛化的函数的系统。这种能力的基础在于发现和运用对称函数的能力。本文通过研究对称的基本例子——基数加法，探讨了这一问题。基数加法的核心特征是进位函数，即当和超过基数模时，将余数传递到更显著位置的过程。本文首先对基数加法进行群论分析，并识别出给定基数的不同替代进位函数，接着通过使用不同进位函数训练神经网络来执行基数加法，考察其对称性学习的归纳偏见，评估不同类型构架的神经网络在不同进位函数下的学习效率和能力。研究发现，即使简单的神经网络也能在适当的输入格式和进位函数下实现广泛的泛化，而学习能力与进位函数结构密切相关。", "innovation": "本研究通过一种新颖的群论分析方法，揭示了基数加法中隐藏的对称性，并利用不同进位函数训练神经网络以探究其学习性能，特别关注了不同进位函数结构如何影响神经网络的学习效率和能力，揭示了神经网络在对称学习方面的潜在学习偏见。", "conclusion": "研究发现，适当的输入格式和进位函数可以使得神经网络实现广泛的泛化，并且学习能力与进位函数的结构紧密相关。这一研究对认知科学和机器学习领域具有重要意义。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11439", "html_url": "https://arxiv.org/abs/2507.11439", "title": "通过反转框架进行时间序列预测的数据增强", "title_en": "Data Augmentation in Time Series Forecasting through Inverted Framework", "authors": "Hongming Tan,Ting Chen,Ruochong Jin,Wai Kin Chan", "background": "目前，iTransformer 是多变量时间序列 (MTS) 预测中最流行和最有效的模型之一。其倒置框架使其能够有效捕捉多元相关性，但仍然存在一些局限性。它会削弱时间依赖性信息，并在变量相关性不显著时引入噪声。", "innovation": "本文提出了针对倒置框架的新型数据增强方法 DAIF（数据增强反转框架）。它是第一个专为倒置框架设计的实时增强方法，旨在解决现有模型的局限性。提出了两种不同的 DAIF 策略：频域滤波和交叉变异斑图，并通过多个数据集和倒置模型进行了实验验证，证明了其有效性。", "conclusion": "通过引入 DAIF，实验证明了该方法在解决反向框架中已存在的挑战方面的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2308.09730", "html_url": "https://arxiv.org/abs/2308.09730", "title": "虚拟成像试验方法学在客观表征AI系统及其训练数据方面的应用", "title_en": "The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data", "authors": "Fakrul Islam Tushar,Lavsen Dahal,Saman Sotoudeh-Paima,Ehsan Abadi,W. Paul Segars,Ehsan Samei,Joseph Y. Lo", "background": "人工智能模型在医学成像中的可靠性仍然面临挑战，受到模型多样性的影响、用于训练模型的数据以及这些模型组合在新数据上产生产生可重复结果的应用性。", "innovation": "研究探索了新兴的虚拟成像试验（VIT）方法能否作为一种客观工具来解决上述挑战。研究采用虚拟CT和胸片数据，并结合卷积神经网络进行模型开发和测试，以评估不同数据集上训练的模型的性能差异。", "conclusion": "虚拟成像试验（VIT）方法能够增强模型的透明度和可靠性，提供对影响AI性能的驱动因素的深入见解，并连接实验和临床应用场景之间的差距。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2302.00646", "html_url": "https://arxiv.org/abs/2302.00646", "title": "EPIC-SOUNDS：听觉感应动作的大规模数据集", "title_en": "Epic-Sounds: A Large-scale Dataset of Actions That Sound", "authors": "Jaesung Huh,Jacob Chalk,Evangelos Kazakos,Dima Damen,Andrew Zisserman", "background": "本文介绍了一个名为EPIC-SOUNDS的大规模音频注释数据集，该数据集捕捉了自我中心视频音频流中事件和动作的时序长度及类别标签。此前的研究较少关注通过音频直接识别动作的信息，而EPIC-SOUNDS旨在填补这一空白。", "innovation": "提出了一个注释管道，其中注释者根据时间标注音频片段，并描述可能导致该声音的动作。通过将这些开放式音频描述分类为不同的类别，可以仅通过音频区分某些动作。此外，对于涉及物体碰撞的动作，收集了关于这些物体的材料的注释（例如，玻璃物体放在木质表面），并通过视频进行验证，消除了模糊性。", "conclusion": "EPIC-SOUNDS数据集包括78400个分类的听觉事件和动作片段，以及39200个非分类片段，跨越44类。研究团队使用该数据集训练和评估了最先进的音频识别和检测模型，适用于仅音频的方法和视听方法。此外，还对音频事件的时间重叠、视听模态之间的时间和标签相关性、仅通过音频注释材料的模糊性、仅音频标签的重要性以及当前模型对通过声音理解动作的局限性进行了分析。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07511", "html_url": "https://arxiv.org/abs/2507.07511", "title": "运动想象BCI中的不确定性量化--机器学习与深度学习的比较", "title_en": "Uncertainty Quantification for Motor Imagery BCI -- Machine Learning vs. Deep Learning", "authors": "Joris Suurmeijer,Ivo Pascal de Jong,Matias Valdenegro-Toro,Andreea Ioana Sburlea", "background": "大脑-计算机接口（BCIs）可以将大脑信号转换为功能性的输出，但准确性有时会受到限制。标准的机器学习分类器能够对分类结果给出置信度指示，而传统的运动想象BCI分类器（如Common Spatial Patterns (CSP-LDA) 和 Riemannian Geometry (MDRM)）也提供这种置信度。然而，现有研究主要集中在深度学习的不确定性量化上，通过比较传统的BCI分类方法与深度学习的具体不确定性量化方法，以评估恒定置信度（如深度集成和直接不确定性量化）以及标准卷积神经网络在不确定性量化和分类准确性方面的表现，进一步探讨不同学习方法在运动想象BCI中的适用性差异和优势互补。", "innovation": "该研究首次全方位地将传统BCI分类器与深层次学习方法进行直接比较，在不确定性量化方面进行了极大创新。研究发现，虽然深度学习方法普遍表现出过度自信，但CSP-LDA和MDRM方法表现稳定，在不确定性量化方面表现出色。此外，通过加大温度调整（MDRM-T），进一步提升了MDRM方法的不确定性量化能力。研究还表明，尽管深度学习方法在分类准确性上可能稍优于传统方法，但在不确定性量化方面传统方法更具优势。", "conclusion": "所有模型都能够区分易和难的估计，因此可以通过排除模糊样本来提高运动想象BCI的准确性。特别是在不确定性量化方面，CSP-LDA和MDRM-T表现出更佳的效果，而深度学习模型和标准CNN在分类准确性方面表现更优。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.10301", "html_url": "https://arxiv.org/abs/2309.10301", "title": "条件不变分量在域适应中的重要角色：理论与算法", "title_en": "Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms", "authors": "Keru Wu,Yuansi Chen,Wooseok Ha,Bin Yu", "background": "域适应（DA）是统计学习中的一个问题，当用于训练模型的源数据分布与用于评估模型的目标数据分布不同时，便会出现这一问题。虽然许多DA算法在实际应用中取得了显著的成功，但直接应用这些算法往往会导致在新数据集上的性能下降。因此，阐明DA算法在目标上表现良好的假设是至关重要的。本文关注条件不变成分（CICs）的假设，这些成分在预测中有关联性，并且在源数据和目标数据中保持条件不变性。研究表明，CICs可以通过条件不变惩罚（CIP）进行估计，并在DA中提供了目标风险保证。这些成分在DA中有三个重要角色。首先，提出了一种基于CICs的新算法（重要权重条件不变惩罚，IW-CIP），该算法在简单的设置（如协变量移位和标签移位）之外也有目标风险保证。其次，证明了CICs有助于识别其他DA算法的源数据和目标数据之间的大差异。最后，通过将CICs纳入领域不变投影（DIP）算法，可以解决由于标签反转特征引起的DIP算法失效的情况。", "innovation": "本文提出了重要权重条件不变惩罚（IW-CIP）算法，该算法在简单的设置之外也有目标风险保证；证明了CICs有助于发现其他DA算法中的显著差异；通过引入CICs到领域不变投影（DIP）算法中，解决了DIP算法由于标签反转特征导致的失效场景。", "conclusion": "通过对合成数据、MNIST、CelebA、Camelyon17和DomainNet数据集的数值实验支持了新的算法和理论发现，本文强调了CICs在DA中的重要角色，并展示了一种利用CICs来改进DA算法的新方法。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.07003", "html_url": "https://arxiv.org/abs/2312.07003", "title": "RACER：理性人工智能跟随模型的现实增强", "title_en": "RACER: Rational Artificial Intelligence Car-following-model Enhanced by Reality", "authors": "Tianyi Li,Alexander Halatsis,Raphael Stern", "background": "研究介绍了RACER，这是一种基于深度学习的智能跟随模型，它通过满足偏导数约束条件，旨在预测自适应巡航控制(ACC)的驾驶行为，同时保持理论上的可行性。该模型结合了实际驾驶中的重要原则——理性驾驶约束(Rational Driving Constraints, RDCs)，从而实现了异常精确且现实的预测。与其他建立的模型（如最优速度-相对速度模型(Optimal Velocity Relative Velocity, OVRV)、神经网络模型和物理信息神经网络模型）相比，RACER在加速、速度和间距等方面的关键指标上表现优异。特别的是，它严格遵循了RDCs，没有违反记录，这与其他模型形成鲜明对比。研究表明，将物理约束纳入人工智能模型对于增强交通安全措施具有巨大价值，也为未来的研究提供了方向，使这些模型可以与人类驾驶数据进行测试，并有可能引导更安全和更理性的驾驶行为。", "innovation": "RACER通过结合理性驾驶约束(RDCs)，实现在关键指标如加速、速度和间距上的优越性能。RACER特别实现了对RDCs的完美遵守，没有违反记录，与其他模型形成了对比，展示了将物理约束整合到AI模型中的巨大潜力。", "conclusion": "该研究强调了在AI模型中整合物理约束的巨大价值，特别是在交通安全措施的增强方面。它推动了未来研究测试这些模型与人类驾驶数据的可行性，并有可能指导更安全和更理性的驾驶行为。此外，提出模型的多功能性进一步增加了其吸引力和影响力。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.08802", "html_url": "https://arxiv.org/abs/2403.08802", "title": "公司中生成型人工智能的治理", "title_en": "Governance of Generative Artificial Intelligence for Companies", "authors": "Johannes Schneider,Pauline Kuss,Rene Abraham,Christian Meske", "background": "生成型人工智能（GenAI），特别是大型语言模型（LLMs）如ChatGPT，已迅速进入组织，但缺乏有效的治理，带来了机会和风险。尽管关于GenAI的变革性质及其监管措施的讨论广泛，但很少有研究关注组织层面的治理，包括技术与商业视角。现有的许多AI治理框架尚不清楚其适用于GenAI的程度。本文通过文献回顾填补了这一空白，旨在更好地理解GenAI的基本特征，并特别调整了先前的框架以适用于公司的GenAI治理。", "innovation": "本文扩展了Nickerson的框架开发过程，纳入了先前的概念化，提出了一个专为公司GenAI治理定制的框架，该框架明确了GenAI整合的范围、目标及治理机制，以便既能抓住商业机会也能减轻风险。", "conclusion": "本文为公司提供了一个聚焦的GenAI治理方法，提供了实用洞察，帮助公司应对GenAI采用的挑战，并指出了研究缺口。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.05102", "html_url": "https://arxiv.org/abs/2404.05102", "title": "LHU-Net: 一种高效、高性能的精简混合U-Net", "title_en": "LHU-Net: a Lean Hybrid U-Net for Cost-efficient, High-performance Volumetric Segmentation", "authors": "Yousef Sadegheih,Afshin Bozorgpour,Pratibha Kumari,Reza Azad,Dorit Merhof", "background": "Transformer架构的进步促进了医学图像分割的提升，但现有的混合模型（结合卷积神经网络和Transformer）常常因为过于复杂而未能有效整合空间和通道特征，这对精确分割至关重要。现有的方法存在效率和精确度难以兼得的问题。", "innovation": "本研究提出了LHU-Net，这是一种优化空间特征提取优先并细化通道特征的精简混合U-Net模型。LHU-Net在多个基准数据集（Synapse、左房、BraTS-Decathlon、Lung-Decathlon）上展示了比现有模型更高的性能，同时使用的参数与FLOPs均大幅减少，且在不需要预训练、额外数据或模型集成的情况下取得了最优结果。LHU-Net的平均参数量仅为1100万，成为计算效率和分割精度的新基准。", "conclusion": "LHU-Net模型在多种医学图像模态和输出配置中表现出色，参数量减少了四倍，FLOPs降低了20%，而平均参数量为1100万，显著提升了医学图像分割的效率与准确性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10158", "html_url": "https://arxiv.org/abs/2507.10158", "title": "MTF-Grasp: 一种用于机器人抓取的多层级联邦学习方法", "title_en": "MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping", "authors": "Obaidullah Zaland,Erik Elmroth,Monowar Bhuyan", "background": "联邦学习（FL）是一种允许多个设备在保持数据隐私的情况下共同训练模型的机器学习范式，已经在机器人操作任务中展示了其优势。然而，对于抓取任务，机器人在不移动数据和确保数据隐私的情况下训练全局模型方面的研究相对较弱。主要挑战是，每个机器人必须从分布不独立且不相同的数据中学习，并且这些数据量往往较小，这导致性能下降，尤其是在机器人抓取任务中。因此，本文提出了一种多层级联邦学习（MTF-Grasp）方法，针对机器人抓取中数据分布为非独立且不相同的数据所带来的独特挑战，包括数量上的偏斜性，以改善模型性能。MTF-Grasp利用跨机器人的数据质量和数量选择一组“顶级”机器人进行模型的初步训练，并将所得模型分配给其余“底层”机器人，从而降低底层机器人模型性能下降的风险。", "innovation": "提出了一个用于机器人抓取任务的多层级联邦学习方法（MTF-Grasp），针对机器人在非独立且不相同的数据下的学习任务，通过招募数据分布较好且样本量较大的“顶级”机器人进行模型初步训练，并将这些模型分发给其余“底层”机器人，以减少底层机器人性能下降的风险，从而改善了基于数量偏斜数据集（如Cornell和Jacquard抓取数据集）的模型性能，相比传统的联邦学习设置，性能提升最高可达8%。这种方法解决了在处理非独立且不相同的数据分布时遇到的问题，特别是针对机器人抓取任务中遇到的性能退化问题。", "conclusion": "与传统的联邦学习方法相比，MTF-Grasp的方法能够在基于数量偏斜的数据集上取得更好的性能，尤其是在机器人抓取任务中，克服了因数据非独立和数量较少所带来的性能下降问题，能够有效提升模型在这些任务上的表现。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09474", "html_url": "https://arxiv.org/abs/2410.09474", "title": "使用双重增强提取不变表征的知识蒸馏", "title_en": "Distilling Invariant Representations with Dual Augmentation", "authors": "Nikolaos Giakoumoglou,Tania Stathaki", "background": "知识蒸馏（KD）被广泛应用于将大型准确模型（教师）的知识转移到小型高效的模型（学生）上。最近的方法通过引入因果解释来加强一致性的知识蒸馏，促进不变表征的学习。本文在此研究的基础上，提出了一种双重增强策略来促进教师模型和学生模型中不变特征的学习。", "innovation": "本文提出了一种双重增强策略，通过在蒸馏过程中对教师和学生模型应用不同的增强技术，来促进不变特征的学习。这种策略的创新点在于确保学习到的表示在更广泛的数据显示和变换中保持稳定，从而补充了不变因果知识蒸馏的方法。", "conclusion": "通过在CIFAR-100上的广泛实验，本文展示了该方法的有效性，与同架构的KD方法相比，取得接近竞争性能的结果。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10628", "html_url": "https://arxiv.org/abs/2507.10628", "title": "GHPO: 适应性指导以实现稳定且高效的大型语言模型强化学习", "title_en": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning", "authors": "Ziru Liu,Cheng Gong,Xinyu Fu,Yaofang Liu,Ran Chen,Shoubo Hu,Suiyun Zhang,Rui Liu,Qingfu Zhang,Dandan Tu", "background": "强化学习带有可验证奖励（RLVR）近期成为促进大型语言模型（LLMs）自我提升的强大力场，尤其是在复杂推理任务方面。然而，现有的一系列在线强化学习方法在实际应用中经常遇到训练不稳定性和效率低下问题，这主要由能力与难度不匹配引起。训练数据的复杂性往往超越了模型当前的能力边界，导致关键的奖励信号稀疏不足，从而使学习进度停滞。这一问题对于资源更高效的中小型LLMs尤为明显。", "innovation": "我们提出了一种新颖的难度感知强化学习框架——指导混合策略优化（GHPO）。GHPO通过适应性提示细化提供目标导向的指导，动态调整任务难度。这一独特的方法结合了即时模仿学习与探索性强化学习，前者用于目前模型难以解决的问题，后者用于更可管理的任务，从而有效地创建了平滑且优化的学习课程。实验结果表明，GHPO在六个数学基准测试中平均性能提升了约5%，并且在训练稳定性和最终推理性能方面均优于其他强化学习和渐进学习基线。", "conclusion": "我们的框架显著提升了训练稳定性和最终推理表现，提供了一种可扩展且高效的解决方案，用于开发强大且鲁棒的推理模型。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.15801", "html_url": "https://arxiv.org/abs/2401.15801", "title": "生成对抗模型在低内在数据维度统计性质的研究", "title_en": "On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension", "authors": "Saptarshi Chakraborty,Peter L. Bartlett", "background": "尽管生成对抗网络（GAN）在实际应用中取得了显著的成功，但它们的统计准确性理论保证仍然相对悲观。特别是在应用的样本数据分布，如自然图片，往往假设其在高维特征空间中具有内在低维结构，而现有的分析却未能充分反映这一点。本文试图通过为生成对抗网络（GANs）及其变种双向生成对抗网络（BiGANs）提供统计保证来弥合理论与实践之间的差距，特别是在面对低维数据集时。通过对估计密度的内在维度与潜在空间维度的分析，作者得出了误差率与样本数量n的关系式。", "innovation": "本文的创新在于：1) 分析了生成对抗网络（GANs）和双向生成对抗网络（BiGANs）在估计数据分布时的统计性质，特别是对于低维数据集。2) 理论上证明了，如果网络架构选取恰当且拥有足够数量的样本，则生成的估计误差随样本量n降幂减少，对于标准的GAN模型其误差率为O(n^{-1/d_μ})，而双向GAN模型为~O(n^{-1/(d_μ+ℓ)})，其中d_μ和ℓ分别为数据分布的上行Wasserstein-1维度和潜在空间的维度。3) 这些理论分析不仅表明这些方法能够避免“维度灾难”，即误差率的指数与数据维度无关，而且还填补了生成对抗模型理论分析中的空白。", "conclusion": "本文不仅提供了生成对抗模型在低内在数据维度上的统计性质的理论保证，而且证明了这些模型在处理非光滑分布时能实现最小最大最优速率，从而为理解生成对抗模型的理论性质提供新的视角。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/1909.10455", "html_url": "https://arxiv.org/abs/1909.10455", "title": "在随机优化中的几何、计算与最优性", "title_en": "Geometry, Computation, and Optimality in Stochastic Optimization", "authors": "Chen Cheng,Daniel Levy,John C. Duchi", "background": "本文研究了在随机和在线优化中问题几何结构的计算和统计后果。文章通过关注约束集和梯度几何来探讨这些问题，从而精确地定义问题的家族，其中随机梯度和自适应梯度方法能够实现最优收敛，而当问题需要非线性更新（例如镜像下降所使用的更新）时，则说明随机梯度方法已经不是最优的选择。文章适用于任何$ \boldsymbol{ℓ}_p $-球，其中$p < 2$。此外，文章探讨了计算和精度之间的权衡，并指出这种权衡在高斯序列模型中表现出明显的相似性。这些结果对于理解随机优化问题至关重要，有助于优化算法的调优和选择。", "innovation": "本文通过研究问题的几何结构，发现当约束集为二次凸集时，预条件化的随机梯度方法是最优的。同时，定量地证明了约束条件相对于二次凸性距离的远近，决定了子梯度方法的非最优程度。这表明在优化算法领域，几何结构对于确定最优方法具有决定性作用。这一发现为优化算法的设计和分析提供了新的视角和理论依据，尤其是在随机化和在线优化领域，对于对生成式模型和其他复杂优化问题的研究具有重要意义。", "conclusion": "这些研究结果表明，对于$p < 2$的$ \boldsymbol{ℓ}_p $-球约束集，使用预条件化的随机梯度方法是最优选择，而当偏离二次凸性时，非线性更新是必须的。计算与精度之间的权衡在高斯序列模型中有明显的相似性，这为理解随机优化问题提供了新的视角。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06771", "html_url": "https://arxiv.org/abs/2412.06771", "title": "不确定情况下多轮文本到图像生成的主动代理", "title_en": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty", "authors": "Meera Hahn,Wenjun Zeng,Nithish Kannen,Rich Galt,Kartikeya Badola,Been Kim,Zi Wang", "background": "用户对生成型AI模型的指令往往不够明确，这可能导致用户意图与模型理解之间的不一致。因此，用户常常需要花时间反复调整指令。本文研究了文本到图像(T2I)生成中的这种对齐问题，并提出了一种主动T2I代理的原型，该原型具备提出澄清问题和展示对用户意图的可理解与可编辑的信念图的能力。", "innovation": "本文提出了一种新的多轮T2I生成方法，通过在不确定的情况下主动提问来提高对齐效果。具体而言，该方法包括一个具有真实意图（图象）的代理和一个尝试尽可能少提问以达到对齐的代理。同时，还设计了一种新的自动化评价方法，实验结果表明，采用该方法的T2I代理能够在至少2倍于传统T2I生成的VQAScore下实现成功对齐，并且该方法获得了90%以上研究参与者的认可。", "conclusion": "本文提出的主动T2I代理在不确定情况下能够有效地提出有意义的问题，获取关键信息，实现与用户意图的成功对齐，并且通过用户研究验证了这一方法的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16425", "html_url": "https://arxiv.org/abs/2412.16425", "title": "Patherea：20年代的细胞检测与分类", "title_en": "Patherea: Cell Detection and Classification for the 2020s", "authors": "Dejan Štepec,Maja Jerše,Snežana Đokić,Jera Jeruc,Nina Zidar,Danijel Skočaj", "background": "近年来，为了实现细胞检测与分类的自动化和精准化，研究人员开发出了多种方法，但这些方法缺乏统一的标准和评估基准。现有的评估协议也存在一些问题，导致不同方法之间难以进行公平比较。为了弥合这一差距，该论文基于2017年的眼球识别挑战赛构建了一个大型数据集，用于细胞检测与分类，旨在为相关方法的开发和评估提供更加统一和公平的标准。", "innovation": "该研究提出了Patherea，这是一个统一的框架，用以统一各种基于点的细胞检测和分类方法，并在多个公开数据集上实现了最先进的性能。Patherea允许直接预测细胞位置和类别，而不依赖于中间表示。它结合了混合匈牙利匹配策略，支持灵活的底层架构和训练方案，包括最近的病理基础模型。此外，作者还识别并纠正了现有的评估协议中的常见错误，并提供了标准化评估的最新基准工具。", "conclusion": "通过引入Patherea数据集和Patherea框架，该研究不仅证明了新数据集作为基准测试的优势，同时也为该领域的研究人员提供了公平、准确的评估工具和标准。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00691", "html_url": "https://arxiv.org/abs/2501.00691", "title": "Large Language Models Help Measure People's Empathy in Vitro", "title_en": "Labels Generated by Large Language Models Help Measure People's Empathy in Vitro", "authors": "Md Rakibul Hasan,Yue Yao,Md Zakir Hossain,Aneesh Krishna,Imre Rudas,Shafin Rahman,Tom Gedeon", "background": "大型语言模型（LLMs）已在多个领域引发了革命，LLM-as-a-service（LLMSaaS）提供了一种低成本的通用解决方案。与广泛研究的直接通过提示工程解决任务的方法（体内）不同，本文探讨了LLMs在体外应用的潜力：利用LLM生成的标签来改进主流模型的监督训练。特别是在通过文本叙述等输入预测基于心理学的问卷结果的同理心计算这一新兴任务中，众包数据集通常存在噪音标签的问题，这可能歪曲了同理心的真实表现。", "innovation": "提出了两种策略：（1）嘈杂标签校正；（2）训练数据增强。利用心理学为本的标尺感知提示开发的LLM生成标签，显著改善了准确性。特别是RoBERTa预训练语言模型（PLM）在噪声减少标签的监督下训练，在公开的NewsEmp基准测试中取得最高的皮尔逊相关系数0.648。进一步分析了评估指标选择和人口统计偏差，以指导更公平的同理心计算模型的发展。", "conclusion": "通过将众包标签替换或补充为LLM生成的标签，取得了统计意义上的显著准确性提升。通过实验证明了使用心理量表感知提示的LLM生成标签在同理心计算中的有效性和优越性，同时指出未来模型开发需关注评价指标和人口统计偏差以确保模型的公平性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.12898", "html_url": "https://arxiv.org/abs/2411.12898", "title": "基于随机线性梯度压缩问题的相关收敛边界", "title_en": "Problem-dependent convergence bounds for randomized linear gradient compression", "authors": "Thomas Flynn,Patrick Johnstone,Shinjae Yoo", "background": "在分布式优化中，模型更新的通信往往是性能瓶颈。因此，提出了梯度压缩以提高优化吞吐量。然而，信息损失会导致迭代次数增加。本文关注非凸随机优化背景下，压缩与问题结构之间的相互作用对收敛的影响。", "innovation": "本文研究了在随机线性渐变压缩下，压缩对收敛的影响与问题结构之间的关系。提出使用与目标函数相关的平滑矩阵和压缩方案定义的范数来量化压缩的影响。理论分析表明，在某些情况下，压缩性能与问题的低秩结构或其他谱特性有关，这预测了与仅考虑压缩率而忽略问题数据的最坏情况边界相比，压缩引入的惩罚显著减少。", "conclusion": "本文实验验证了理论发现，包括对图像分类模型的微调。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.19704", "html_url": "https://arxiv.org/abs/2410.19704", "title": "多视图生物医学基础模型用于分子靶点和性质预测", "title_en": "Multi-view biomedical foundation models for molecule-target and property prediction", "authors": "Parthasarathy Suryanarayanan,Yunguang Qiu,Shreyans Sethi,Diwakar Mahajan,Hongyang Li,Yuxin Yang,Elif Eyigoz,Aldo Guzman Saenz,Daniel E. Platt,Timothy H. Rumbell,Kenney Ng,Sanjoy Dey,Myson Burch,Bum Chul Kwon,Pablo Meyer,Feixiong Cheng,Jianying Hu,Joseph A. Morrone", "background": "高质量的分子表示对于生物医学研究中基础模型的发展至关重要。以往的工作通常专注于单一的分子表示或视角，这可能在某些任务上表现出优势或劣势。本研究开发了一种将图、图像和文本视角集成到基础模型中的方法，旨在提高预测准确性。", "innovation": "开发了一种名为 Multi-view Molecular Embedding with Late Fusion (MMELON) 的方法，该方法在基础模型框架下将多种视角（图、图像和文本）进行融合，该方法可以轻松扩展到其他表示。单视图基础模型在多达 200 万分子的数据库上进行预训练。多视图模型在超过 120 个任务上的表现稳定，与单视图中领先的模型相当，特别是在分子溶解度、ADME 特性以及对抗 G 蛋白偶联受体 (GPCRs) 的活性等方面。", "conclusion": "通过多视图模型识别了与阿尔茨海默病相关的 33 个 GPCRs，并利用该模型从化合物筛选中选择了强结合者。预测结果通过基于结构的建模和关键结合模式的识别得到了验证。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12189", "html_url": "https://arxiv.org/abs/2501.12189", "title": "MirrorCBO: 一种具有镜像下降精神的共识优化方法", "title_en": "MirrorCBO: A consensus-based optimization method in the spirit of mirror descent", "authors": "Leon Bungert,Franca Hoffmann,Dohyeon Kim,Tim Roith", "background": "本文提出了一种新的共识优化（CBO）方法——MirrorCBO，该方法在共识优化的背景下推广了标准的CBO方法，类似于镜像下降如何推广梯度下降。镜像下降将梯度下降的优势扩展到了具有锥形约束的问题上。", "innovation": "MirrorCBO通过使用强凸函数的次微分来参数化镜像映射的反函数，将其应用于一对偶粒子群，从而结合了无导数非凸优化算法和镜像下降的优点。此外，该方法还扩展了常规CBO方法的应用范围，使之适用于具有凸约束的优化问题。在标准的Bregman距离有界假设下，作者提供了MirrorCBO的渐近收敛结果，并且具有显式指数收敛速度。研究还包含了一个新的算法在不同应用设置中的探索性数值研究，尤其是稀疏诱导优化和约束优化场景。", "conclusion": "通过探索这个新算法在不同应用设置中的性能，作者观察到MirrorCBO在稀疏性诱导优化和约束优化等方面具有竞争力的表现。此外，该方法还可以用于欧氏空间中非凸子流形上的优化，并且可以适应其它近期CBO变体的镜像版本，还继承了镜像下降选择优化目标的能力。文章还包括了对近期CBO方法在约束优化中的综述，并将其性能与MirrorCBO进行了比较。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17066", "html_url": "https://arxiv.org/abs/2502.17066", "title": "DUNIA:地球观测应用中的跨模态对齐以生成像素级嵌入", "title_en": "DUNIA: Pixel-Sized Embeddings via Cross-Modal Alignment for Earth Observation Applications", "authors": "Ibrahim Fayad,Max Zimmer,Martin Schwartz,Fabian Gieseke,Philippe Ciais,Gabriel Belouze,Sarah Brood,Aurelien De Truchis,Alexandre d'Aspremont", "background": "针对地球观测应用，已经做了大量工作以适应自监督多模态学习。但大多数现有方法生成的是粗粒度的图像块级嵌入，这限制了它们的有效性和与其他如LiDAR的模态的集成能力。研究指出，通过跨模态对齐图像与全波形LiDAR数据来生成像素级嵌入已经成为迫切需求，以解决这一问题并提高安地观测应用的效果。", "innovation": "提出了DUNIA方法，通过跨模态对齐来学习像素级嵌入，不依赖LiDAR回波大波形直接最小化遮罩回波预测，模型在对比方式下进行训练，允许嵌入在不同环境监测任务中用于零样本场景。实验表明该方法有效提升七种环境监测任务：冠层高度测量、冠层覆盖度分数、土地覆盖类型测量、树种识别、植物指数、农作物类型分类、基于全波形垂直结构的像素级测量任务的性能，在低数据量情况下，嵌入结合零样本分类器通常优于专门的监督模型。在微调场景中，该方法在五个任务上接近或超过了当前最佳水平的性能。", "conclusion": "研究结果显示，DUNIA方法生成的嵌入不仅在零样本场景中表现良好，在微调场景中也能达到或接近当前最佳模型的性能，有助于提高地观测应用中多模态数据的有效利用。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10594", "html_url": "https://arxiv.org/abs/2507.10594", "title": "扩展OL-MDISF：来自混合类型、漂移和不完整流式特征的在线学习", "title_en": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features", "authors": "Shengda Zhuo,Di Wu,Yi He,Shuqiang Huang,Xindong Wu", "background": "流式数据学习，其中特征空间可以随时间发生变化，提供了一个灵活的学习范式，但依然面临三大挑战：一是现实世界数据流的异质性，含有混合特征类型，给传统的参数建模带来了挑战；二是数据流分布可以随时间变化，导致模型性能急剧下降；三是时间与成本限制使得在监督设置下无法对每一个数据实例进行标注。为了应对这些挑战，本文提出了一种新的在线学习算法OL-MDISF，旨在放松对特征类型、数据分布和监督信息的限制。", "innovation": "本文提出了一种新型算法OL-MDISF，该算法采用库plu模型构建完整的潜在空间，使用自适应滑动窗口检测漂移点以确保模型稳定性，并基于几何结构关系建立标签相邻信息。该模型通过理论分析和全面实验结果来验证其效率和有效性。", "conclusion": "本文作为一种独立的技术参考，扩大了OL-MDISF的方法，涵盖了在线学习领域中混合特征建模、概念漂移适应以及弱监督的最新进展，并通过14个真实世界的数组件和两种漂移场景下的综合实验，包括完整的CER趋势、删减研究、敏感性分析和时间聚合动态，为研究人员提供了一个可再现的基准和技术资源。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00355", "html_url": "https://arxiv.org/abs/2411.00355", "title": "TextDestroyer: 一种无需训练和标注的图像中异常文字破坏的扩散方法", "title_en": "TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images", "authors": "Mengcheng Li,Fei Chao", "background": "现有的场景文字移除模型需要复杂的标注和重新训练，并且可能留下难以识别的文字信息，从而影响隐私保护和内容隐藏。目前的方法在实际应用中存在劳动密集型的数据标注和资源密集型的训练需求，且难以彻底破坏文字信息，防止留下明显痕迹。", "innovation": "提出了TextDestroyer，这是一种使用预训练扩散模型的场景文字破坏方法，无需训练和标注即可实现更彻底的文字破坏。通过一个三阶段的分层过程获取准确的文字遮罩，使用高斯分布扰乱潜始码中的文字区域，同时在去噪过程中参考原始潜始码恢复受损背景，在重建过程中利用各重构步骤保存的潜码进行替换，确保背景重构的完美恢复。", "conclusion": "TextDestroyer的优点包括：（1）消除了数据标注和资源密集型训练的劳动需求；（2）实现了更彻底的文字破坏，防止残留可识别的痕迹；（3）展示了更好的泛化能力，适用于现实世界场景和生成图像。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21042", "html_url": "https://arxiv.org/abs/2504.21042", "title": "什么是操纵背后的力量？通过概念转变评估AI训练和推理中的完整性和归因", "title_en": "What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift", "authors": "Jiamin Chang,Haoyang Li,Hammond Pearce,Ruoxi Sun,Bo Li,Minhui Xue", "background": "随着人工智能（AI）的广泛应用，人们对AI的信任度成为一个重要问题，涵盖数据的完整性、隐私保护、系统稳健性和偏见等方面。为了评价和归因这些潜在风险，提出了ConceptLens框架。该框架利用预训练的多模态模型分析诱发概念偏移的样本，从而识别完整性威胁的根本原因。", "innovation": "ConceptLens是一种通用框架，通过概念偏移分析来检测数据污染攻击，并揭露偏差注入的风险，比如生成隐蔽广告。它能够在不改变数据的情况下，识别高风险但未被修改的数据样本，并在训练前过滤这些样本。此外，它还可以识别模型因训练数据不完整或不均衡而产生的弱点，及概念过度依赖的极端情况。进一步揭示了生成内容中的社会偏见，并表明看似安全的训练和推理数据可能意外成为攻击目标。", "conclusion": "我们的研究为人工系统的信任树立提供了可操作的见解，加快其普及，并促进更多创新。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08140", "html_url": "https://arxiv.org/abs/2505.08140", "title": "失之千里：当与为何大语言模型在全球推理中失败", "title_en": "Lost in Transmission: When and Why LLMs Fail to Reason Globally", "authors": "Tobias Schnabel,Kiran Tomlinson,Adith Swaminathan,Jennifer Neville", "background": "尽管基于变压器的大语言模型（LLMs）在许多任务中表现出色，但它们仍然在涉及复杂、跨大量输入内容的推理任务中遇到困难。研究表明，这些失败主要是因为模型内在信息流容量的限制。论文通过引入带有带宽限制的注意力前缀Oracle（BAPO）模型，证明了解决这类问题所需的信息带宽需求，并定义了BAPO难和BAPO易的问题类型。实验证实了理论预测，尤其是在处理BAPO难题时，大型模型如GPT-4o、Claude和Gemini非常容易失败。此外，研究还表明，通过链式推理方法可以将BAPO难题转化为BAPO易题，从而增强模型的处理能力。", "innovation": "引入了BAPO模型来量化和分析大语言模型在内部通信带宽上的限制，并将注意力机制与信息传递带宽需求结合起来。这有助于理解大语言模型在出现复杂推理任务时的失败，并为克服这些挑战提供了新的方法和方向。", "conclusion": "实验结果表明，大语言模型在处理BAPO难题时会失败，而使用链式推理方法可以将这些难题分解为更容易处理的问题。这种研究提供了对关键大语言模型失败原因的原理性解释，并提出了缓解带宽限制的架构和推理方法方向。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.15740", "html_url": "https://arxiv.org/abs/2403.15740", "title": "使用唯一标识符在大型语言模型训练中保护版权材料", "title_en": "Protecting Copyrighted Material with Unique Identifiers in Large Language Model Training", "authors": "Shuai Zhao,Linchao Zhu,Ruijie Quan,Yi Yang", "background": "近年来，随着大型语言模型（LLMs）的规模扩大和在日常生活中的广泛应用，训练这些模型时担心的一个主要问题是，它们是否会滥用在线版权文本。这导致了两个问题：1）由相似示例误导的虚假正面成员身份推理结果；2）成员身份推理方法通常过于复杂，无法被普通用户理解和使用。为了解决这些问题，论文提出了一个替代的‘插入和检测’方法，建议网络用户和内容平台使用唯一标识符进行可靠和独立的成员身份推断，用户和平台可以创建自己的标识符，将它们嵌入到版权文本中，并独立检测它们在未来的大语言模型中。", "innovation": "论文提出了一种新的‘插入和检测’方法，使用唯一标识符进行成员身份推断。该方法包括‘幽灵句子’和用户友好的‘最后k个词测试’，用户可以通过与大语言模型对话进行成员身份推断。幽灵句子主要由随机自然词的唯一短语组成，可以包含定制元素以绕过可能的过滤规则。最后，-k个词测试要求幽灵句子有显著的重复时间（≥10次），在少于10次重复的情况下，设计了额外的困惑度测试，因为在遇到不自然的短语时，大语言模型会产生高困惑度。", "conclusion": "本文通过研究幽灵句子的记忆力和成员身份推断，分析了训练数据规模、模型大小、重复时间、插入位置、短语词表、对齐等因素。研究结果表明，幽灵句子可以在实际场景中应用，并为潜在应用提供了指导。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.22526", "html_url": "https://arxiv.org/abs/2503.22526", "title": "AnnoPage 数据集：具有精细分类的文档中非文本元素数据集", "title_en": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization", "authors": "Martin Kišš,Michal Hradiš,Martina Dvořáková,Václav Jiroušek,Filip Kersch", "background": "该研究引入了AnnoPage数据集，这是一个包含7550页历史文件的集合，主要使用捷克语和德语编撰，时间范围从1485年到现代，重点关注19世纪末及20世纪初。该数据集旨在支持文档版面分析和对象检测的研究。每个页面都标注了表示不同非文本元素（如图像、地图、装饰元素或图表）的轴对齐边界框（AABB），并遵循捷克图像文件处理方法。这些注释由专家图书管理员创建，以确保准确性和一致性。该数据集还包含了多个历史文档数据集的页面，以增加多样性和保持连续性。数据集分为开发集和测试集，测试集特别被精心选择以保持类别分布的平衡。", "innovation": "本研究的创新之处在于提供了用于文档中非文本元素的详细注释数据集，支持了详细分类的文档分析，并为未来的研究提供了基线结果。这些注释遵循捷克方法，使用了轴对齐边界框，确保了标记的准确性和一致性。通过包括多个历史文档的数据集，提高了数据集的多样性和连贯性，同时也通过分割开发集和测试集提供了更好的训练和评估机制。", "conclusion": "AnnoPage数据集已经公开发布在Zenodo上，并提供YOLO格式的验证信息，为未来在文档版面分析和对象检测领域的研究提供了一个重要的资源，并提供了初步的基线成果。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05676", "html_url": "https://arxiv.org/abs/2502.05676", "title": "泛化的维恩和维恩-阿贝斯校准及其在自适应预测中的应用", "title_en": "Generalized Venn and Venn-Abers Calibration with Applications in Conformal Prediction", "authors": "Lars van der Laan,Ahmed Alaa", "background": "确保预测模型的校准对于可靠的预测至关重要。然而，如直方图分箱和等温回归等流行的趋势自由方法仅能提供渐进性保证。本文提出了一种统一的框架，将维恩和维恩-阿贝斯校准方法扩展到二元分类之外，适用于由通用损失函数定义的一系列预测问题。该方法将任何在样本内完全校准的预测器转换为集合型预测器，在有限样本中输出至少一个边缘校准的点预测。在渐进性条件下，这些集合预测会缩减并收敛于一个条件上校准的预测，捕捉到了似然性不确定性。此外，还提出了一种新的多校准方法，以实现子人群中短样本量校准的不确定性控制。对于分位数损失，该框架恢复了群体条件和多校准的可解释预测，并产生了具有分位数条件覆盖的新预测区间。", "innovation": "本文提出的统一框架将维恩和维恩-阿贝斯校准方法扩展到了二元分类之外，适用于由通用损失函数定义的预测问题。此外，提出了新的多校准方法，能够实现子人群中短样本量校准的不确定性控制。对于分位数损失，该框架不仅恢复了已有的方法，还提出了新的预测区间。", "conclusion": "该方法能够在有限样本中提供至少一个边缘校准的点预测，并且在渐进性条件下，预测会趋向于一个条件上校准的预测，捕捉到了似然性不确定性。此外，该框架能够实现子人群中的短样本量校准的不确定性控制，并提出了新的预测区间。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01912", "html_url": "https://arxiv.org/abs/2502.01912", "title": "PATCH：一种评估历史绘画中艺术实践变异性的深度学习方法", "title_en": "PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings", "authors": "Andrew Van Horn,Lauryn Smith,Mahamad Mahmoud,Michael McMaster,Clara Pinchbeck,Ina Martin,Andrew Lininger,Anthony Ingrisano,Adam Lowe,Carlos Bayod,Elizabeth Bolman,Kenneth Singer,Michael Hinczewski", "background": "艺术史经历了艺术家创作方式的重大转变，理解创作过程成为技术艺术历史中的核心问题。在文艺复兴和早期现代时期，绘画主要由大师画家指导学徒工作坊进行创作，不同大师和工作室的管理和艺术风格差异显著，这意味着不同艺术家和工具的组合在大师之间或工作室内部甚至单幅画作中有所不同。尽管有关工作室管理和创作过程的信息有限，但机器学习方法有助于通过微观层面的画笔痕迹分析揭示新信息。然而，历史绘画中的挑战在于涉及艺术家和材料的相关记录稀少，导致缺乏可用于训练网络识别贡献的外部示例。因此，迫切需要一种无需外部训练数据即可识别个别艺术实践模式的方法。", "innovation": "本文介绍了一种名为PAIRWISE ASSIGNMENT TRAINING FOR CLASSIFYING HETEROGENEITY（PATCH）的新机器学习方法，该方法能够在没有外部训练数据的情况下识别个别艺术实践模式。通过监督手段实现无监督结果，并且优于简单统计方法和无监督机器学习方法。该方法被应用于由西班牙文艺复兴大师埃尔·格列柯创作的《基督受洗》和《基督架十字有风景》两幅历史绘画。这些研究成果对于《基督受洗》这幅画而言，有可能推翻先前将该画归于工作室成员的说法。此外，通过分析所得结果，本文提出了一个艺术实践变异性的度量标准，可用于历史和不同地域的艺术作品分类。", "conclusion": "本文提出了一种新的无监督学习方法——PATCH，能够识别个别艺术家的实践模式，且无需外部训练数据。通过将其应用于埃尔·格列柯的历史绘画，本文揭示了新的艺术实践信息，并提供了一个跨时间和空间的艺术作品分类度量标准。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00713", "html_url": "https://arxiv.org/abs/2506.00713", "title": "AKReF: 一种结构化论证的论述知识表示框架", "title_en": "AKReF: An argumentative knowledge representation framework for structured argumentation", "authors": "Debarati Bhattacharjee,Ashish Anand", "background": "该论文提出了一种将论述性文本转化为论述知识图谱（AKG）的框架。传统的知识表示方法可能难以清晰展示论述的结构，论文通过增强论点组件（ACs）和论点关系（ARs）的基本注释，构建了一个包含元数据属性的图数据库（KB），并通过模态逻辑和推理规则构建论据，进而形成了AKG。AKG的节点和边具有标记关键论述特征的属性，如前提的类型、推理规则的类型、反攻类型以及标记等，这种框架能够识别出传统的数据集中无法检测到的反攻攻击。AKG为推理任务如论点的连贯性检查和识别修订机会提供了基础。", "innovation": "论文提出了一个论述知识表示框架（AKReF），该框架可以将论述性文本转化为论述知识图谱（AKG），并通过元数据属性增强信息，进一步利用模态逻辑和推理规则构建论据，形成AKG。AKG的创新点在于它能够捕捉隐含和间接的关系，提高推理模型的理解能力，并能够识别原始数据集中无法检测到的反攻攻击。", "conclusion": "AKG为论证分析提供了新的框架，使推理任务更清晰和有效，并且能够通过定义的框架和规则进行复杂的论证分析，如提取无冲突的论点集和最大可行论点集，为后续研究和实践提供了基础。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03194", "html_url": "https://arxiv.org/abs/2506.03194", "title": "HueManity: 探测MLLMs的精细视觉感知", "title_en": "HueManity: Probing Fine-Grained Visual Perception in MLLMs", "authors": "Rynaa Grover,Jayant Sravan Tamarapalli,Sahiti Yerramilli,Nilay Pande", "background": "多模态大型语言模型（MLLMs）在高层次的视觉推理方面表现出色，但在细致的感知任务上表现仍然有限。HueManity基准测试被设计用来评估MLLMs的视觉感知能力，通过包含特定复杂模式的图像数据集挑战模型的精确模式识别能力。", "innovation": "提出了HueManity基准测试，旨在评估MLLMs的视觉感知能力。HueManity的数据集由83,850张图像组成，每张图像包含两个字符的数字字母字符串，嵌入在Ishihara测试风格的点模式中。该基准测试揭示了当前MLLMs在视觉能力上的关键差距，并通过公开数据集和代码推动未来研究。", "conclusion": "研究结果表明，最先进的MLLMs在HueManity基准测试上的表现远不如人类和传统的计算机视觉基线。分析进一步探讨了可能导致MLLMs在感知能力上缺口的潜在架构和训练方式。研究开放了HueManity数据集和代码，以促进改进MLLMs感知鲁棒性的进一步研究。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07615", "html_url": "https://arxiv.org/abs/2505.07615", "title": "扩散责任：生成文本到音频扩散模型的能效分析", "title_en": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models", "authors": "Riccardo Passoni,Francesca Ronchini,Luca Comanducci,Romain Serizel,Fabio Antonacci", "background": "文本到声音模型近年来成为从文本描述生成声音的强大技术。然而，这些模型的高计算需求引发了对其能源消耗和环境影响的担忧。这项研究分析了7个最新的基于扩散的生成性文本到音频生成模型的能耗，并评估生成参数变化对推理时能耗的影响。此外，还旨在通过考虑所有选定模型的帕累托最优解来确定音频质量和能耗之间的最佳平衡。", "innovation": "通过对7个最新的基于扩散的生成性文本到音频生成模型的能耗进行分析，评估生成参数变化对能耗的影响。通过考虑所有选定模型的帕累托最优解来确定音频质量和能耗之间的最佳平衡，为更高效的生成性音频模型的发展提供洞见。", "conclusion": "本研究揭示了性能和环境影响之间的权衡，为更高效生成音频模型的开发提供了参考，有助于降低生成性音频技术的环境足迹。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04602", "html_url": "https://arxiv.org/abs/2506.04602", "title": "MVP-Shapley: 基于特征建模评估篮球最有价值球员", "title_en": "MVP-Shapley: Feature-based Modeling for Evaluating the Most Valuable Player in Basketball", "authors": "Haifeng Sun,Yu Xiong,Runze Wu,Kai Wang,Lan Zhang,Changjie Fan,Shaojie Tang,Xiang-Yang Li", "background": "随着电子竞技和多人在线游戏社区的蓬勃发展，评估最有价值球员（MVP）变得越来越关键。建立一个可解释且实用的MVP评估方法极具挑战性。我们专注于比赛过程数据，记录了游戏中相关的事件，如助攻和得分。我们的目标是通过引入新的基于Shapley值的MVP评估框架（记为\baseline）来应对这一挑战，该框架包括特征处理、胜负模型训练、Shapley值分配以及根据球员贡献确定MVP排名。此外，我们还优化了算法，使其与因果视角下的专家投票结果相契合。最后，我们通过使用NBA数据集和Dunk City Dynasty数据集进行验证，并在行业中实现了在线部署来证明该方法的有效性.", "innovation": "我们的创新之处在于引入了基于Shapley值的新MVP评估框架（\baseline）。该框架涵盖了特征处理、胜负模型训练、Shapley值分配以及基于球员贡献确定MVP排名。我们还优化了算法，使其与因果视角下的专家投票结果相契合，从而提高了评估的解释性和实用性。最后，通过实际数据集验证和行业应用进一步证明了该方法的有效性。", "conclusion": "我们通过基于Shapley值的MVP评估框架（\baseline）解决了MVP评估的关键挑战，并通过数据集验证和实际部署证明了其实用性和有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01048", "html_url": "https://arxiv.org/abs/2504.01048", "title": "水印如何影响文档理解中的视觉语言模型？", "title_en": "How does Watermarking Affect Visual Language Models in Document Understanding?", "authors": "Chunxue Xu,Yiwei Wang,Bryan Hooi,Yujun Cai,Songze Li", "background": "视觉语言模型（VLMs）已成为文档理解任务的基础模型，广泛应用于金融、法律和学术等领域的复杂多模态文档处理。然而，文档中经常包含如水印等噪声信息，这引发了一个问题：这些水印是否会影响VLMs在文档理解任务上的性能？", "innovation": "本文提出了一个新的评估框架，以探讨可见水印对VLMs性能的影响。该框架考虑了不同类型的文档数据、水印在文档中的位置和水印内容的变化。实验结果表明，VLMs的性能可能会受到水印的影响，性能下降高达36%。研究表明，散布式的水印比集中的干扰更严重，而水印中的语义内容比简单的视觉遮挡造成更大的干扰。通过注意力机制分析和嵌入相似性检查，发现性能下降主要由水印导致广泛分散的注意力重组以及语义嵌入空间中的语义表示改变所致。", "conclusion": "本文不仅揭示了部署VLMs进行文档理解的显著挑战，还为开发鲁棒的水印文档推理机制提供了见解。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.23175", "html_url": "https://arxiv.org/abs/2503.23175", "title": "大型语言模型在网络安全威胁情报中不可靠", "title_en": "Large Language Models are Unreliable for Cyber Threat Intelligence", "authors": "Emanuele Mezzi,Fabio Massacci,Katja Tuma", "background": "几项近期的研究表明，大型语言模型（LLMs）可以用于减轻网络安全领域的数据洪泛问题，通过提高网络威胁情报（CTI）任务的自动化水平。本文提出了一个评估方法，该方法不仅允许在零样本学习、少样本学习和微调下测试LLMs在CTI任务上的表现，还允许量化它们的一致性和信心水平。实验使用了三个最先进的LLMs和350篇威胁情报报告，并揭示了依赖LLMs进行CTI分析可能存在的安全风险。结果表明，LLMs在处理大型报告时无法保证足够的性能，同时表现出不一致和过度自信的现象。少样本学习和微调只能部分改善结果，引起了对在缺乏标注数据集且信心是关键因素的CTI场景中使用LLMs的怀疑。", "innovation": "本文提出了一种评估方法，不仅可以在零样本学习、少样本学习和微调下测试LLMs在CTI任务上的表现，还能量化它们的一致性和信心水平。此外，实验证明了LLMs在处理CTI任务时的局限性，为网络安全领域正确理解和应用LLMs提供了新的见解。", "conclusion": "LLMs在处理真实大小的CTI报告时表现不佳，同时也表现出不一致和过度自信的现象。少样本学习和微调仅部分地改进了结果，质疑了在缺乏标注数据集且信心是关键因素的CTI场景中使用LLMs的可能性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13575", "html_url": "https://arxiv.org/abs/2506.13575", "title": "基于机器学习补偿非理想通道的AWG基FBG解调器", "title_en": "Machine Learning-Driven Compensation for Non-Ideal Channels in AWG-Based FBG Interrogator", "authors": "Ivan A. Kazakov,Iana V. Kulichenko,Egor E. Kovalev,Angelina A. Treskova,Daria D. Barma,Kirill M. Malakhov,Ivan V. Oseledets,Arkady V. Shipulin", "background": "传统的阵列波导光栅（AWG）基解调器虽然结构紧凑且可扩展，但其实际性能受到非理想光谱响应的限制。本文通过对比两种校准策略——分段解析模型和基于指数回归的机器学习（ML）方法来解决这一问题。", "innovation": "提出了一种基于机器学习的补偿方法，通过比较基于分段解析模型（使用S形拟合函数）和基于指数回归的机器学习回归模型来校准非理想的FBG通道响应。结果显示，基于机器学习的方法（使用指数回归）在2.9 nm的光谱范围内保持了小于5 pm的准确性，且无需重新拟合。", "conclusion": "机器学习驱动的校准方法提供了比解析方法更坚固且数据驱动的替代方案，能够提高非理想通道响应的准确性，减少手动校准工作，并且增强不同FBG传感器配置的可扩展性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09828", "html_url": "https://arxiv.org/abs/2507.09828", "title": "基于后验采样的期望改进的遗憾分析", "title_en": "Regret Analysis of Posterior Sampling-Based Expected Improvement for Bayesian Optimization", "authors": "Shion Takeno,Yu Inatsu,Masayuki Karasuyama,Ichiro Takeuchi", "background": "贝叶斯优化是一种强大的工具，用于优化难以评估的黑箱函数。特别是，期望改进（EI）在其广泛应用中的有效性已被证明。然而，与其它已建立的算法相比，关于EI的理论分析受限较多。本文分析了基于后验采样的随机EI，该方法通过对后验样本路径的最大值进行评估来实现EI。在假定黑箱函数遵循高斯过程的前提下，本文展示了基于后验采样的随机EI实现了亚线性贝叶斯累积遗憾界。", "innovation": "本文的主要创新点是对基于后验采样的随机EI进行了理论分析，证明了在高斯过程假设下，该方法可以实现亚线性贝叶斯累积遗憾界，填补了EI理论分析的空白。", "conclusion": "最后，本文通过数值实验验证了所提出方法的有效性。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06608", "html_url": "https://arxiv.org/abs/2507.06608", "title": "LLM 服务中的 proactive 前取和解码 Intra-GPU 分离", "title_en": "Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving", "authors": "Xiaoxiang Shi,Colin Cai,Junjia Du", "background": "传统的 GPU 应用采用自包含式预取和编解码机制，虽然通过合并预取和解码提升了 GPU 利用率，但这种做法易遭受细粒度阶段干扰。现有的基于 GPU 的解决方案通过阶段解耦来避免干扰，但这样做会带来更高的硬件和协调开销。目前采用的方案是利用基于服务水平目标（SLO）的调整，借助离线分析或实时反馈循环中的启发式方法进行前取和解码的操作调度，但这些方法只能在出现问题时作出反应，而无法在动态工作负载出现时加以预防。", "innovation": "本文提出了一种前瞻性的 GPU 内存预取和解码的阶段性分离方法。该方法利用动态划分 GPU 资源，并综合了计算能力、内存足迹和带宽竞争等参数。这种方法在多种大语言模型和工作负载下，其吞吐量提高了 2.2 倍，TTFT（端到端延迟时间）降低了 20 倍，TBT（总体延迟时间）降低了 2.5 倍，并且在某些情况下比 SGLang 算法提高了 2 倍的性能，且达到了或超越了分割版的 vLLM 性能。", "conclusion": "通过前瞻性地调整阶段划分，动态管理资源分配，实现基于动态工作负载的高效大语言模型服务。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.04632", "html_url": "https://arxiv.org/abs/2507.04632", "title": "可以在线预测提示难度以加速推理模型的RL微调吗？", "title_en": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?", "authors": "Yun Qu,Qi Cheems Wang,Yixiu Mao,Vincent Tao Hu,Xiangyang Ji", "background": "最近的研究表明，强化学习（RL）微调能够增强大型语言模型（LLMs）的推理能力。优化过程通常需要多次迭代才能达到满意的性能，这导致了由于频繁的提示评估和密集的LLM互动以及重复的策略更新而产生的高计算成本。直接的评估-然后选择方案依赖于全面的提示评估和子集选择，这仍然是由于频繁的LLM推理调用来带来巨大的计算负担。与这些直接方案不同，这项工作研究了任意提示的迭代近似评估，并引入了Model Predictive Prompt Selection（MoPPS）框架，该框架通过一个贝叶斯风险预测方法在线估计提示的难度，无需昂贵的LLM交互。在数学、规划以及基于视觉几何任务上，MoPPS能够可靠地预测提示难度并显著减少LLM模拟轮次，加速训练过程。", "innovation": "这项工作提出了MoPPS方法，这是一种贝叶斯风险预测框架，能够在不需要昂贵的LLM交互的情况下在线估计提示的难度。MoPPS通过将每个提示的成功率建模为潜在变量，进行流式贝叶斯推理，并在构建的多臂赌机器中使用后验抽样来实现有效的和自适应的提示选择，从而减少计算开销并加快训练速度。", "conclusion": "MoPPS能够在不需要昂贵的LLM模拟调用的情况下，有效预测提示的难度，并加速强化学习微调推理模型的训练过程，显著减少了LLM的模拟轮次。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06607", "html_url": "https://arxiv.org/abs/2507.06607", "title": "具有效率推理能力的解码器-混合-解码器架构", "title_en": "Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation", "authors": "Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen", "background": "近年来，语言模型的发展证明了状态空间模型（SSMs）在高效序列建模中的有效性。虽然混杂架构如Samba和解码器-解码器架构YOCO在性能上优于Transformer，但之前的著作并未探索SSM层之间的表示共享效果。", "innovation": "本文提出了一种简单的高效机制——Gated Memory Unit（GMU），它允许在层间共享记忆读取状态。通过将其应用到SambaY架构中，引入了Gated Memory Unit来实现跨解码器共享记忆读取状态，从而构建了一个新的解码器-混杂-解码器架构。SambaY显著提高了解码效率，保持了线性预填充时间复杂性，并提升了长上下文性能，同时消除了显式位置编码的需要。大规模实验表明，我们的模型相对强的YOCO基线具有显著更低的不可约损失，表明在大规模计算环境中性能更具可扩展性。", "conclusion": "我们的最大模型，增加了差分注意力机制的Phi4-mini-Flash-Reasoning，在无需任何强化学习的情况下，在类似Math500、AIME24/25和GPQA Diamond的推理任务上表现更好。此外，在vLLM推理框架中，对于长度2K的提示，其解码吞吐量最高提升了10倍。完整的训练代码可以在开放源数据此链接找到。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11381", "html_url": "https://arxiv.org/abs/2507.11381", "title": "从观察数据到临床推荐：估计患者级治疗效果及学习策略的因果框架", "title_en": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies", "authors": "Rom Gutman,Shimon Sheiba,Omer Noy Klein,Naama Dekel Bird,Amit Gruber,Doron Aronson,Oren Caspi,Uri Shalit", "background": "本文基于近年来关于学习患者级因果模型的大量文献，并受到Hernan和Robins的目标试验范式的启发，提出了一种框架来构建患者特定的治疗推荐模型。作者关注的是安全性及有效性，特别是使用观察数据时因果识别的关键问题。尽管未具体提供模型设计，而是提供了一种将现有方法和技术整合到实际管道中的途径。进一步地，作者提供了一个针对心力衰竭患者入院期间并发急性肾损伤的治疗优化实际案例研究。结果表明，该框架能够提高患者治疗效果，超越当前的治疗方案", "innovation": "提出了一个实用的框架，旨在通过整合现有方法和知识，帮助构建并优化患者特定的治疗推荐模型。该框架特别关注了在使用观察数据时需要考虑的因果识别问题，并为心力衰竭并发急性肾损伤患者的治疗优化提供了一个具体实例", "conclusion": "本文框架在实际应用中能够提升患者治疗效果，并提出了一种日后的模型整合策略，进一步验证了通过因果框架分析观察数据并转化为临床推荐的有效性"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08218", "html_url": "https://arxiv.org/abs/2507.08218", "title": "关于出域推理的简单机械解释", "title_en": "Simple Mechanistic Explanations for Out-Of-Context Reasoning", "authors": "Atticus Wang,Joshua Engels,Oliver Clive-Griffin,Senthooran Rajamanoharan,Neel Nanda", "background": "本文探讨了细调大型语言模型（细调后的LLMs）出域泛化的现象，即在细调过程中，模型不仅学会浅层的启发式方法，还能在未见过的数据上隐含地内化并执行观察数据中的后果。研究发现这类现象的一个简单解释是LoRA细调实际上添加了一个恒定的导引向量，引导模型朝向一个一般性概念，这不仅提高了细调任务的表现，还提升了许多其他概念相关的领域，促使了令人惊讶的泛化。", "innovation": "通过细调添加恒定的导引向量，使模型朝向一般概念的方法解释了出域推理的现象，并发现可以直接从零训练导引向量，也能够引起出域推理。即使是在似乎需要有条件行为的任务上（如模型后门），单纯无条件添加导引向量也足够实现这一目标。", "conclusion": "本文通过上述发现，提供了一种解释细调中出域推理学习过程的说法，为理解LLMs如何出域推理提供了关键线索，并贡献了对于为何LLMs能够出域推理的高级能力这一问题的理解，这对确保LLMs的安全可靠部署具有重要意义。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01881", "html_url": "https://arxiv.org/abs/2507.01881", "title": "一种用于肺癌筛查计划中胸部疾病检测的计算资源节约型开源基础模型", "title_en": "A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs", "authors": "Niccolò McConnell,Pardeep Vasudev,Daisuke Yamada,Daryl Cheng,Mehran Azimbagirad,John McCabe,Shahab Aslani,Ahmed H. Shahin,Yukun Zhou, TheSUMMIT Consortium,Andre Altmann,Yipeng Hu,Paul Taylor,Sam M. Janes,Daniel C. Alexander,Joseph Jacob", "background": "低剂量计算机断层扫描（LDCT）成像在全球肺癌筛查（LCS）项目中的使用正在增加。LCS项目提供了一个前所未有的机会，可以同时检测癌症和非癌症相关的早期肺部疾病。然而，由于无法大规模解读扫描图像的放射科医生短缺，这些努力受到了阻碍。", "innovation": "TANGERINE 是一个计算资源节约型、开源的视觉基础模型，适用于体积 LDCT 分析。TANGERINE 设计用于广泛的可访问性并能快速适应，可以使用有限的计算资源和训练数据进行微调以满足多种病种特定任务。TANGERINE 在预训练期间使用超过 98,000 例胸部 LDCT 数据（包括迄今为止最大的 LCS 项目）及 27 个公共数据集进行自监督学习，并实现了包括肺癌和多种呼吸系统疾病在内的 14 项疾病分类任务的最新性能。方法上，TANGERINE 通过将掩码自编码框架扩展到三维成像，提供一种针对 LDCT 分析的可扩展解决方案，相比最近闭源、资源密集型的模型，TANGERINE 结合了结构的简洁性、公共可用性和适度的计算需求，具有较高的资源效率和快速收敛性。", "conclusion": "TANGERINE 的可访问、开源轻量级设计为其快速集成到下一代医疗影像工具铺平了道路，这可使 LCS 项目能够从单一肺癌检测转向针对高风险人群的全面呼吸系统疾病管理。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03220", "html_url": "https://arxiv.org/abs/2507.03220", "title": "Symbiosis：支持多适配器推理和微调", "title_en": "Symbiosis: Multi-Adapter Inference and Fine-Tuning", "authors": "Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman", "background": "参数高效微调(PEFT)允许模型构建者将任务特定参数集成到适配器中，适配器的大小远小于原始基模型。由于PEFT技术的流行，已经为流行的大型语言模型创建了大量的适配器。然而，现有的框架在支持使用多个适配器进行推理或微调方面存在以下不足：1）每个微调任务都需要部署特定的基模型实例，导致显存消耗过多和显卡利用率低。2）虽然流行的服务平台可以为多个PEFT适配器提供服务，但它们不支持独立资源管理或不同PEFT方法的混合。3）它们无法在推理和微调任务之间共享资源（如基模型实例）。4）它们不提供隐私保护，用户可能不希望将自己的微调参数暴露给服务提供商。", "innovation": "Symbiosis通过允许基模型作为服务部署来解决上述问题，使基模型层可以跨多个推理或微调过程共享。我们的拆分执行技术拆分执行客户端特定的适配器和层与冻结的基模型层，提供了它们管理资源、选择微调方法以及实现性能目标的灵活性。我们的方法对模型是透明的，并且大多数transformers库中的模型都能无缝运行。我们的评估显示，与基线相比，在相同数量的GPU和相同的时间内，Symbiosis可以微调4倍多的适配器。", "conclusion": "Symbiosis通过允许多个工作流程共享基模型资源，为大规模PEFT适配器的管理和部署提供了新的解决方案，显著提高了资源利用率和灵活性，同时保持了模型的透明性和用户隐私。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00785", "html_url": "https://arxiv.org/abs/2506.00785", "title": "GeoChain：多模态链式推理在地理推理中的应用", "title_en": "GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning", "authors": "Sahiti Yerramilli,Nilay Pande,Rynaa Grover,Jayant Sravan Tamarapalli", "background": "介绍了GeoChain的背景，这是一个大型基准，用于评估多模态大语言模型（MLLMs）在地理推理方面的逐步地理推理能力。使用了146万张Mapillary街道级别图像，并为每张图像配对了一个包含21步思维链（CoT）的问题序列，涵盖了视觉、空间、文化和精确地理位置等四个推理类别，并标注了不同难度级别的问题。", "innovation": "介绍了GeoChain的创新之处，GeoChain是一个大型基准，包括146万张街道级别图像和每个图像与一个包含21个步骤的思维链问题序列配对，共产生了超过3000万个问答对。这些问题序列引导模型从粗略的属性到精确的地理定位，涵盖了视觉、空间、文化和精确地理位置等四个推理类别，每个类别都标注了难度级别。图像还被丰富了语义分割（150类）和可视可定位得分。对当前的MLLMs（GPT-4.1变体，Claude 3.7，Gemini 2.5变体）在2088张图像子集上的基准测试揭示了持续的挑战，这些模型经常表现出视觉定位能力较弱、推理不连贯，在复杂推理问题上难以实现精确的定位。", "conclusion": "GeoChain提供了一种强大的诊断方法，对于在MLLMs中推进复杂地理推理的能力至关重要。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.11671", "html_url": "https://arxiv.org/abs/2507.11671", "title": "在量子软件系统中选择架构模式和策略的决策模型", "title_en": "Decision Models for Selecting Architecture Patterns and Strategies in Quantum Software Systems", "authors": "Mst Shamima Aktar,Peng Liang,Muhammad Waseem,Amjed Tahir,Mojtaba Shahin,Muhammad Azeem Akbar,Arif Ali Khan,Aakash Ahmad,Musengamana Jean de Dieu,Ruiyin Li", "background": "量子软件代表着基于量子力学原理的量子特定软件系统、服务和应用程序的颠覆性技术。通过编程的量子位（Qubits）操作量子门（QuGates），能够实现计算的量子优越性。量子软件架构让开发者能够抽象掉具体的实现细节，但设计量子软件系统时仍面临显著挑战，包括选择和实现合适的架构模式和策略。这主要是由于量子软件系统的复杂性和缺乏指导原则。", "innovation": "本文提出了六种关键设计领域（通信、分解、数据处理、容错、集成和优化、算法实现）的选择模式和策略的决策模型。这些模型是基于从GitHub和Stack Exchange的数据挖掘研究以及系统文献综述的结果建立的。研究通过半结构化访谈评估了这些建议的决策模型的实际熟悉度、可理解性、完整性和实用性。", "conclusion": "研究结果表明，所提出的决策模型有助于量子软件从业者选择合适的模式和策略，以应对量子软件系统架构设计方面的挑战。研究提供的数据集可供社区复现和进一步研究。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.11689", "html_url": "https://arxiv.org/abs/2507.11689", "title": "REST in Pieces: RESTful Design Rule Violations in Student-Built Web Apps", "title_en": "REST in Pieces: RESTful Design Rule Violations in Student-Built Web Apps", "authors": "Sergio Di Meglio,Valeria Pontillo,Luigi Libero Lucio Starace", "background": "计算机科学本科课程中，软件质量往往因时间限制和技术基础技能的重视而被忽视，导致许多学生缺乏符合行业期望的开发能力。为了更好地了解学生代码的典型质量以及改善教育和招聘实践，本文分析了40个在Web技术课程中开发的完整的全栈网络应用。研究使用自动化静态分析流程来评估REST API设计规则的遵守情况。研究结果揭示了频繁违反基础惯例，包括缺失端点路径中的连字符（98%），不正确的复数形式（88%），和错误使用HTTP方法（83%）等问题。这一发现突出需要针对API设计进行更深入的教学，并支持采用自动化工具以提高学生项目代码质量的需求。", "innovation": "本研究使用自动化静态分析程序来评估REST API设计规则的遵守情况，分析了40个学生在Web技术课程中开发的项目，揭示了常见的API设计违规情况。这些分析结果可以为教学改进提供依据，并建议采用自动化工具来提升学生项目的代码质量。", "conclusion": "研究结果表明，在学生编写的网络应用程序中，频繁违反REST API的基础规则，需要更多聚焦于API设计的教学，以及利用自动化工具提高代码质量。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12084", "html_url": "https://arxiv.org/abs/2507.12084", "title": "LLAMA：带有LLM引导种子生成的多反馈智能合约模糊测试框架", "title_en": "LLAMA: Multi-Feedback Smart Contract Fuzzing Framework with LLM-Guided Seed Generation", "authors": "Keke Gai,Haochen Liang,Jing Yu,Liehuang Zhu,Dusit Niyato", "background": "智能合约在区块链生态系统中扮演着关键角色，而模糊测试是确保智能合约安全的重要方法。尽管变异调度因素对模糊测试效果具有重要影响，但现有的模糊测试工具主要集中在种子生成和调度上，而变异调度方面的研究相对较少。", "innovation": "本文提出了一个基于大型语言模型（LLMs）的多反馈智能合约模糊测试框架（LLAMA），该框架结合了LLMs、演化变异策略和混合测试技术。LLAMA的关键组成部分包括：(i) 一种分层提示策略，引导LLMs生成语义有效的初始种子，并结合轻量级预模糊测试阶段选择潜在高价值输入；(ii) 一种多反馈优化机制，通过利用运行时覆盖率和依赖反馈同时改进种子生成、种子选择和变异调度；(iii) 一种演化模糊测试引擎，根据效果动态调整变异操作的概率，并结合符号执行以避免停滞并揭露更深层次的漏洞。", "conclusion": "实验表明，LLAMA相比最先进的模糊测试工具在覆盖率和漏洞检测方面都表现出优越性。具体来说，它实现了91%的指令覆盖率和90%的分支覆盖率，并且在不同的类别中检测到了148个已知漏洞中的132个。这些结果突显了LLAMA在实际智能合约安全性测试场景中的有效性、适应性和实用性。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.11898", "html_url": "https://arxiv.org/abs/2507.11898", "title": "使用LLM进行网络软件的极值测试", "title_en": "Extremal Testing for Network Software using LLMs", "authors": "Rathin Singha,Harry Qian,Srinath Saikrishnan,Tracy Zhao,Ryan Beckett,Siva Kesava Reddy Kakarla,George Varghese", "background": "物理学家在测试理论时经常手动考虑极限情况。本文展示了如何使用大型语言模型（LLMs）自动化网络软件的极值测试。该过程分为两个步骤：首先让LLM生成输入约束（例如DNS名称长度限制）；然后让LLM生成违反这些约束的测试用例。作者通过为HTTP、BGP和DNS实现生成极值测试用例来展示这一过程的简单性，这些测试用例发现了新的漏洞。文章还展示了这种方法如何应用于集中式网络软件，如最短路径算法，并说明了LLMs如何生成过滤代码来拒绝极值输入。", "innovation": "本文创新性地提出了使用大型语言模型（LLMs）自动进行网络软件的极值测试。这种方法通过两个步骤减少人工干预：首先，让LLM生成输入约束；其次，让LLM生成违反这些约束的测试用例。此外，文章还提议使用代理型AI进一步自动化极值测试。这种方法超越了传统的边界值分析技术。", "conclusion": "作者通过生成极值测试用例验证了这种方法的有效性，这些测试用例发现了新的漏洞，适用于多种网络软件和集中式网络软件。文章表明，可以利用算法为这些极值输入生成过滤代码，并提出了进一步使用代理型AI的方法。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.11948", "html_url": "https://arxiv.org/abs/2507.11948", "title": "Kevin: 多循环RL方法用于CUDA内核生成", "title_en": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "authors": "Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti", "background": "编写GPU内核是AI系统效率的决定性因素，且此过程非常迭代，需要领域专家不断编写代码并根据执行反馈改进性能。此过程中可验证的奖励包括正确性和加速比，使其成为应用强化学习（RL）的理想环境。然而，现有的RL方法难以有效处理此过程中的迭代性和长期的数据轨迹，以及准确计算每个迭代步骤的奖励归因。", "innovation": "该论文提出了一种灵活的多循环RL方法，能够有效地处理实际场景中的长轨迹学习和跨步骤的准确奖励归因。通过这种方式将迭代过程明确地纳入训练中，作者开发出一个名为Kevin的模型，首次使用多循环RL方法进行CUDA内核的生成和优化。实验结果表明，Kevin在内核正确性和加速比方面表现出色，明显优于基础模型，并且在模型复杂度和并行/串行策略的研究上也展现出有益的行为。", "conclusion": "Kevin模型展示了显著的改进，内核正确性从56%提高到82%，平均加速比从0.53x提升到1.10x的基础线（PyTorch Eager）。此外，研究表明，在测试时间的扩展轴上，串行精炼比并行采样更有效，尤其是在给予更多精炼步骤时，Kevin显示出更高的改进速率。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.11976", "html_url": "https://arxiv.org/abs/2507.11976", "title": "面向符合性检查的任务分类法", "title_en": "A Task Taxonomy for Conformance Checking", "authors": "Jana-Rebecca Rehse,Michael Grohs,Finn Klessascheck,Lisa-Marie Klein,Tatiana von Landesberger,Luise Pufahl", "background": "符合性检查是业务流程挖掘的一个分支，它通过比较观察到的业务流程痕迹与业务流程模型，分析实际执行与设计规定的符合度或偏差程度。组织可以通过这种分析，例如检查其流程是否符合内部或外部规定，或识别潜在的改进机会。获得这些见解需要合适的可视化支持，使得复杂的结果变得易于理解并能够采取行动。然而，目前符合性检查可视化的开发主要由工具供应商负责，导致现有的工具提供了广泛多样的可视化表示，但它们背后的分析目的往往模糊不清。缺乏对这些目的的系统理解，使得评估这些可视化的效用变得困难。因此，评估可视化需要更深入地理解符合性检查作为一个分析领域。", "innovation": "本文提出了一种任务分类法，用于分类进行符合性检查分析时可能遇到的任务。该分类法通过将过程挖掘和可视化分析的概念相结合，帮助研究人员确定可视化的目的，从目标、手段、约束类型、数据特征、数据目标和数据基数等方面具体化相关的符合性检查任务。这种分类法支持研究人员和两个学科领域的学者更紧密地合作，从而促进更深入的理解和合作研究。", "conclusion": "为了辅助符合性检查分析中的任务理解与分类，本文提出了一种任务分类法。该分类法不仅有助于明确可视化的目的和用途，还通过系统化的分析方法，使得工具开发人员能够更好地针对不同应用场景提供更有针对性的可视化支持，从而提升整体的分析效能。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03564", "html_url": "https://arxiv.org/abs/2507.03564", "title": "2.5D目标检测用于智能路边基础设施", "title_en": "2.5D Object Detection for Intelligent Roadside Infrastructure", "authors": "Nikolai Polley,Yacin Boualili,Ferdinand Mütsch,Maximilian Zipfl,Tobias Fleck,J. Marius Zöllner", "background": "自主车辆的车载传感器可能因遮挡、部分视野或狭窄视野而受到影响，这会增加下游驾驶决策的复杂性。智能路边基础设施感知系统安装在高处，可以提供宽广且未被障碍物阻挡的交叉口覆盖，通过车辆到万物（V2X）通信为自主车辆提供额外的信息流。然而，传统的3D目标检测算法难以在由顶部视角和陡峭摄像头角度引入的领域转变中泛化。", "innovation": "本文介绍了一种专为安装在路边基础设施上的摄像头设计的2.5D目标检测框架。此框架与传统的2D或3D目标检测不同，它利用预测方法在图像框中检测车辆的平行四边形地面平面，这种方法保留了物体的平面位置、大小和方向，而省略了高度信息，这对于大多数下游应用而言并非必需。为了训练模型，结合了真实场景和合成生成的场景。评估显示该模型具有高检测精度、多种视角下的良好泛化能力和对不同照明和天气条件的鲁棒性。", "conclusion": "本研究展示的2.5D目标检测框架在测试集中的其他摄像头视角和未包括在训练集中的恶劣天气条件下都表现出较高检测准确性、强大的跨视角泛化能力和对多种照明和天气条件的鲁棒性。相关模型权重和推理代码可从此链接下载：this https URL"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12284", "html_url": "https://arxiv.org/abs/2507.12284", "title": "MERA Code：跨任务评估代码生成的统一框架", "title_en": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks", "authors": "Artem Chervyakov,Alexander Kharitonov,Pavel Zadorozhny,Adamenko Pavel,Rodion Levichev,Dmitrii Vorobev,Dmitrii Salikhov,Aidar Valeev,Alena Pestova,Maria Dziuba,Ilseyar Alimova,Artem Zavgorodnev,Aleksandr Medvedev,Stanislav Moiseev,Elena Bruches,Daniil Grebenkin,Roman Derunets,Vikulov Vladimir,Anton Emelyanov,Dmitrii Babaev,Vladimir V. Ivanov,Valentin Malykh,Alena Fenogenova", "background": "语言模型（LLMs）的进步已经在软件工程中增强了任务自动化，但目前的评估主要集中在自然语言任务，而忽略了代码质量。大多数基准测试侧重于高层次的推理而非可执行代码和实际性能，这留下了理解这些模型在生产环境中的实际能力和相关风险的缺口。", "innovation": "本文提出了MERA Code，这是MERA基准系列的一个新成员，专门用于评估最新的代码生成LLMs在俄语中的代码。该基准包括11项评价任务，涵盖8种编程语言。我们的评估方法学包含了一份分类学，概述了模型完成这些任务所需的实用编程技能。该基准还包括一个开源代码库供用户进行MERA评估，以及一个与各种编程环境兼容的评分系统，具备排行榜和提交系统。我们评估了开放的LLMs和前沿的API模型，分析了它们在非英语语言中的实际编码任务方面的局限性。", "conclusion": "本文公开发布MERA以引导未来的研究，预判模型开发中的突破性功能，并标准化评估程序。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12415", "html_url": "https://arxiv.org/abs/2507.12415", "title": "SWE-Perf：语言模型能否在真实世界仓库中优化代码性能？", "title_en": "SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?", "authors": "Xinyi He,Qian Liu,Mingzhe Du,Lin Yan,Zhijie Fan,Yiming Huang,Zejian Yuan,Zejun Ma", "background": "在现实世界中的软件工程中，代码性能优化至关重要，对于生产级别的系统而言更是如此。尽管大型语言模型（LLMs）在代码生成和错误修复方面表现出色，但在仓库级别上提升代码性能的能力却远未被探索清楚。为了解决这个问题，我们提出了SWE-Perf，这是第一个专为系统性评估LLMs在实际仓库上下文中的代码性能优化任务而设计的基准测试框架。SWE-Perf包含140个精心挑选的实例，每个实例均源自GitHub上广泛使用的仓库中的性能改进的拉取请求。每个基准测试实例都包含了相关的代码库、目标函数、相关性能测试、专家撰写的修补程序以及可执行环境。", "innovation": "引入了SWE-Perf，这是第一个专门针对实际仓库场景下的代码性能优化任务系统性评估LLMs的基准测试框架。该基准测试框架通过涵盖文件级和仓库级方法（如Agentless和OpenHands）的广泛方法进行全面评估，揭示了现有LLMs与专家级优化性能之间的显著能力差距，突显了在这一新兴领域进行研究的必要性。", "conclusion": "现有的LLMs在代码性能优化方面与专家级别优化性能之间存在显著的差距，这在新兴领域中形成了重要的研究机会。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.11687", "html_url": "https://arxiv.org/abs/2507.11687", "title": "MetaLint：通过指令遵循和从易到难泛化实现可泛化的惯用代码质量分析", "title_en": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization", "authors": "Atharva Naik,Lawanya Baghel,Dhakshin Govindarajan,Darsh Agrawal,Daniel Fried,Carolyn Rose", "background": "大型语言模型虽然在代码生成方面取得了成功，但在代码质量分析方面存在局限。因受限于静态训练数据，它们难以适应不断变化的最佳实践。为了避免这种局限，我们介绍了一种名为MetaLint的新指令遵循框架，将代码质量分析定义为基于高层次规范检测和纠正有问题的语义代码片段或代码惯用语的任务。 conventional approaches通常在静态、规则基础上训练模型，而MetaLint则通过指令调整合成语义分析器生成的数据来实现从易到难的泛化，使得模型能够适应新型或复杂的代码模式而无需重新训练。", "innovation": "MetaLint引入了一种通过指令遵循和从易到难泛化来实现惯用代码质量分析的新框架。经典的方法通过静态的数据进行规则基础的训练，而MetaLint则使用指令调整合成的语义分析数据，支持逐步适应更复杂或新颖的代码模式，而无需重训模型。评估结果显示，MetaLint在未见过的PEP惯用语的泛化上表现出色，其id识别上的F分数达到70.37%，召回率高达70.43%，局部化效果为26.73%，在性能上与参数量更大的先进模型相当，展现了其在代码质量分析上的潜力", "conclusion": "MetaLint在新颖或复杂代码模式的适应性上优于其他模型，特别是在对未见过的PEP惯用语的泛化和局部化方面表现尤为突出。其表现达到了26.73%的局部化效果，考虑到模型的参数量（4B），这一成绩与大型先进模型相当，显示了MetaLint在未来代码质量分析中具有良好的应用前景。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12104", "html_url": "https://arxiv.org/abs/2507.12104", "title": "从静态到智能：利用LLMs演进SaaS定价", "title_en": "From Static to Intelligent: Evolving SaaS Pricing with LLMs", "authors": "Francisco Javier Cavero,Juan C. Alonso,Antonio Ruiz-Cortés", "background": "软件即服务（SaaS）范式通过提供灵活的定价选项来满足多样化的客户需要，彻底改变了软件分发。然而，SaaS市场的迅速扩展为DevOps团队带来了复杂性，他们必须手动管理和进化定价结构，这一过程既耗时又容易出错。缺乏自动化工具进行定价分析限制了这些模型的有效评估、优化和扩展能力。", "innovation": "本文提出了利用智能定价（iPricing），即动态、可机读的定价模型，来解决这些问题。智能定价能够进行竞争分析，简化运营决策制定，支持对市场动态的持续定价进化，从而提高效率和准确性。作者提出了一个基于LLM的方法，自动将静态HTML定价转换为iPricing，显著提高了效率和一致性，同时减少了人为错误。实现了名为AI4Pricing2Yaml的系统，包含一个基础信息提取器，使用网页抓取和LLM技术从SaaS网站中提取关键定价组件、计划、功能、使用限制和附加项。该系统在30个独特的商业SaaS的300多个智能定价的验证实验中表现出有效性。但依然存在应对幻觉、复杂结构和动态内容的挑战。", "conclusion": "本文展示了自动化智能定价转换的潜力，以简化SaaS定价管理，为日益复杂的定价环境提供了提高一致性和可扩展性的启示。未来研究将集中在提升提取能力并增强系统对更广泛SaaS网站的适应性上。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.00603", "html_url": "https://arxiv.org/abs/2410.00603", "title": "大规模语言模型在Python和JavaScript类型和调用图分析中的实证研究", "title_en": "An Empirical Study of Large Language Models for Type and Call Graph Analysis in Python and JavaScript", "authors": "Ashwin Prasad Shivarpatna Venkatesh,Rose Sunil,Samkutty Sabu,Amir M. Mir,Sofia Reis,Eric Bodden", "background": "大规模语言模型(LLMs)在软件工程领域尤其是静态分析任务中显示出潜在应用价值。因此，本文研究了当前LLMs提升Python和JavaScript程序调用图分析和类型推断的潜力。研究者对24个LLMs模型进行了实证评估，涵盖了OpenAI的GPT系列和开源模型如LLaMA和Mistral。研究者还扩展了TypeEvalPy框架，增加了自动生成能力，以及开发了SWARM-CG和SWARM-JS基准测试套件以评估跨多种编程语言的调用图构建工具。", "innovation": "研究者增强了TypeEvalPy微基准测试框架，使其由之前的860个类型注释扩展到77,268个。引入了SWARM-CG和SWARM-JS，这两个全面的基准测试套件旨在评估跨多种编程语言的调用图构建工具。研究发现LLMs在类型推断方面表现出色，但在调用图分析方面存在局限性，这表明LLMs在类型推断方面有潜力但需要进一步研究以提高调用图分析的完成度和准确性。", "conclusion": "研究结果表明，LLMs在类型推断方面优于传统工具，但在调用图分析方面表现不佳。因此，建议进一步研究以克服现有局限性，同时整合LLMs进入静态分析工作流程。这些结果为将LLMs集成到静态分析工作中提供了基础，并为它们的优势和目前的局限性提供了见解。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12118", "html_url": "https://arxiv.org/abs/2507.12118", "title": "基于语言决策方法的在线A/B测试决策支持系统：虚拟学习环境中的Web可用性评估案例研究", "title_en": "An Online A/B Testing Decision Support System for Web Usability Assessment Based on a Linguistic Decision-making Methodology: Case of Study a Virtual Learning Environment", "authors": "Noe Zermeño,Cristina Zuheros,Lucas Daniel Del Rosso Calache,Francisco Herrera,Rosana Montes", "background": "近年来，对用户界面的用户满意度关注日益增加，涵盖了移动应用程序和网站。人机交互的一个基本方面是网页可用性的概念。为了评估网页可用性，A/B测试技术能够比较两种设计的数据。但是，将测试范围扩展到包括被评估的设计，并结合真实用户和虚构用户的参与，这提出了一个缺乏足够在线支持的挑战。", "innovation": "本文提出了一种基于用户中心的方法（如设计思维和语言决策）的网页可用性评估方法，命名为语言决策方法下的网页可用性评估。该方法通过角色扮演情景和进行包括广泛认可的系统可用性量表在内的多种可用性测试来吸引人们参与。结合A/B测试方法，将其纳入一个决策支持系统中。通过在墨西哥普埃布拉大加杜拉拉大学进行的实地用户案例研究，评估了三个Moodle平台的性能。", "conclusion": "研究表明，该方法能够有效地评估虚拟学习环境中不同Moodle平台的网页可用性。使用此方法，决策支持系统为网页可用性评估提供了强有力的工具，特别是在A/B测试中。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.00513", "html_url": "https://arxiv.org/abs/2504.00513", "title": "利用LLM生成AI系统的用户故事：UStAI数据集", "title_en": "Leveraging LLMs for User Stories in AI Systems: UStAI Dataset", "authors": "Asma Yamani,Malak Baslyman,Moataz Ahmed", "background": "随着AI系统的广泛应用，创造高质量的AI系统需求对于使AI系统与业务目标和消费者价值相一致以及履行社会责任至关重要。然而，由于AI系统的不确定性以及对敏感数据的依赖，还需要进行更多的研究来解决需求提取和分析问题。由于许多AI系统的专属性，缺乏开放的AI系统需求文档和技术需求文档，限制了更广泛的研究所需。于是，研究提出利用大型语言模型（LLMs）生成基于学术论文摘要的AI系统用户故事，以探索LLMs在早期需求提取阶段的应用潜力，尤其是在生成用户故事方面的潜力。", "innovation": "研究采用三种不同的LLM生成了1260个用户故事，从42个来自26个不同领域的学术论文摘要中生成，基于Quality User Story (QUS)框架评估这些用户故事的质量，并识别了相关的需求和其他伦理原则。研究表明，研究中的LLM能够生成出自不同利益相关者需求的用户故事，这为研究和早期需求提取提供了一个有希望的方法。研究还整理并汇集了由各种LLM生成的故事，形成了一个公开可用的数据集(UStAI)。", "conclusion": "研究展示了大型语言模型在生成用户故事方面的潜力，尤其是AI系统的早期需求提取阶段。生成的数据集UStAI将促进进一步的研究并为相关领域的实践提供参考。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12367", "html_url": "https://arxiv.org/abs/2507.12367", "title": "GitChameleon：评估AI代码生成与Python库版本不兼容性", "title_en": "GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities", "authors": "Diganta Misra,Nizar Islah,Victor May,Brice Rauby,Zihan Wang,Justine Gehring,Antonio Orvieto,Muawiz Chaudhary,Eilif B. Muller,Irina Rish,Samira Ebrahimi Kahou,Massimo Caccia", "background": "软件库的快速演进给代码生成带来了显著挑战，要求不断适应频繁的版本更新，同时保持向后兼容性。现有的代码进化基准虽然提供了有价值的信息，但通常缺乏基于执行的评估，以生成符合特定库版本的合规代码。为解决这一问题，该研究引入了GitChameleon数据集，它包含328个Python代码完成问题，每个问题都针对特定的库版本，并附带可执行的单元测试。GitChameleon严格评估了当前最先进的大型语言模型（LLM）、LLM驱动的代理、代码助手和RAG系统的功能准确度执行特性，进行版本条件下的代码生成。我们的广泛评估表明，最先进的系统在这个任务中面临巨大挑战；企业级模型的成功率基本在48-51%之间，突显了问题的复杂性。通过提供基于执行的基准测试，强调代码库的动态性质，GitChameleon有助于更清晰地理解这一挑战，并帮助指导更适应和可靠的人工智能代码生成方法的发展。我们已将该数据集和评估代码公开。", "innovation": "提出了GitChameleon数据集，这是一个精心策划的数据集，包含328个针对特定Python库版本的代码完成问题，并附带可执行的单元测试。GitChameleon严格评估了基于执行的代码生成能力，特别是大型语言模型、LLM驱动的代理、代码助手和RAG系统的版本条件下的代码生成。该数据集填补了现有基准中基于执行的评估空白，强调了代码库的动态性质，从而更全面地衡量代码生成系统的性能。", "conclusion": "GitChameleon通过提供执行基准测试，其公开的数据集和评估代码有助于更深入地理解版本条件下的代码生成挑战，并指导更适应和可靠的人工智能代码生成方法的发展。当前的最先进的系统在版本条件下的代码生成任务中仍面临巨大挑战，成功率为48-51%。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.02274", "html_url": "https://arxiv.org/abs/2505.02274", "title": "在自主车辆基于场景的测试中需要统计学基础", "title_en": "On the Need for a Statistical Foundation in Scenario-Based Testing of Autonomous Vehicles", "authors": "Xingyu Zhao,Robab Aghazadeh-Chakherlou,Chih-Hong Cheng,Peter Popov,Lorenzo Strigini", "background": "自主车辆(AVs)的安全评估越来越多地采用基于场景的测试方法，这种测试方法通过聚焦高风险场景相对于基于行驶里程的测试更为高效。然而，存在一些基本问题，包括基于场景的测试的中止准则、残余风险估计、调试效果以及仿真保真度对安全声明的影响。本研究强调针对这些问题，需要一个严谨的统计学基础来应对挑战并实现严格的安全保障。通过将AV测试方法与现有的软件测试方法进行比较，发现了可共享的研究空白和可复用的解决方案，旨在量化场景失败概率，并在不同条件下评估测试效果。研究还指出，基于场景的测试和基于行驶里程的测试均没有绝对优势，且探讨了形式化推理在合成和真实世界测试结果对齐中的方法，为支持统计上可辩护的基于仿真测试的安全声明提供了第一步。", "innovation": "提出了一种概念性模型，用于量化每场景失败概率（pfs），并评估在不同条件下测试效果的有效性。通过将AV测试与传统软件测试进行对比，识别了共享的研究空白，并提供向统计无误的仿真测试结果宜人的第一步实现途径。此外，分析表明两种类型的测试方法各有优势，没有绝对最优选择，为在统计上支持自主车辆的仿真测试安全声明提供了理论依据和实践指南。", "conclusion": "本研究认为，基于场景的自主车辆测试需要一个严谨的统计学基础来解决现有问题，并为未来的测试方法提出了新的视角。通过提出新颖的概念模型和仿真实验验证，为提高自主车辆测试的可靠性提供了理论支持和实用建议。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2402.05102", "html_url": "https://arxiv.org/abs/2402.05102", "title": "现在可以使用REST：通过LLM辅助请求变异自动化的REST API文档与测试", "title_en": "You Can REST Now: Automated REST API Documentation and Testing via LLM-Assisted Request Mutations", "authors": "Alix Decrop,Xavier Devroey,Mike Papadakis,Pierre-Yves Schobbens,Gilles Perrouin", "background": "REST API在Web服务实现中很常见，通过HTTP协议提升了互操作性。目前，API测试人员和用户利用广泛采用的OpenAPI Specification（OAS）进行REST API的文档工作。然而，文档工作耗时且容易出错，现有文档可能不全面、不公开或不及时。这限制了测试工具的效率并阻碍了人类的理解。大型语言模型（LLMs）有望通过其庞大的训练数据自动推断API文档。", "innovation": "本文介绍了RESTSpecIT，这是一种利用LLMs来自动推断文档和执行REST API的黑盒测试的方法。相较于最先进的工具，RESTSpecIT需要较少的用户输入，只需提供API名称和LLM访问密钥，即可生成API请求种子，并使用LLM返回的数据进行变异。工具通过分析API响应来进行文档推断和测试。RESTSpecIT采用上下文提示掩码策略，无需预先微调模型。", "conclusion": "我们用三种先进的LLM（DeepSeek V3，GPT-4.1和GPT-3.5）评估了工具的质量。评估结果表明，RESTSpecIT能够（1）平均捕获88.62%的路由和89.25%的查询参数；（2）发现未记录的API数据；（3）运营高效（根据模型成本、请求发送量和运行时间）；（4）帮助REST API测试，揭示服务器错误并生成用于测试工具的有效OpenAPI Specification输入。"}
{"llm_update_time": "20250717", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14635", "html_url": "https://arxiv.org/abs/2505.14635", "title": "建立预测编码与MDL之间的桥梁：两部分代码框架在深度学习中的应用", "title_en": "Bridging Predictive Coding and MDL: A Two-Part Code Framework for Deep Learning", "authors": "Benjamin Prada,Shion Matsumoto,Abdul Malik Zekri,Ankur Mali", "background": "本文建立了第一个理论框架，将受到生物启发的局部学习规则——预测编码（PC），与深度网络中的最小描述长度（MDL）原则相连接。", "innovation": "通过证明层间的PC执行MDL双部分代码目标的块坐标的下降，从而同时最小化经验风险和模型复杂性；提出了新的泛化上限形式$R(\theta) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) \bigl( \theta \bigr) $，捕捉拟合与压缩之间的权衡。", "conclusion": "在我们所知的情况下，这是第一个为PC训练的深度模型提供正式泛化和收敛保证的结果，将PC置于一个基于理论和生物学上可能的替代回传算法的位置。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12003", "html_url": "https://arxiv.org/abs/2507.12003", "title": "扩充机器学习文档标准以提高安全性", "title_en": "Expanding ML-Documentation Standards For Better Security", "authors": "Cara Ellen Appel", "background": "本文基于广泛回顾现有文献，阐述了当前机器学习（ML）安全和基于机器学习的系统、模型和数据集的文档化情况。展示了ML从业者和组织在安全意识方面的普遍缺乏和文档化方法的非标准化，导致了较低的ML文档质量。现有的标准在实践中并未被广泛采用，信息技术（IT）安全方面也常未包含在文档中。由于这些因素，需要通过提高机器学习文档的安全性来弥补现有安全缺口，作为解决ML安全缺口的一部分。", "innovation": "提出了扩展机器学习文档标准，增加一个专门的安全部分，包含特定的安全相关信息，以此作为实现提高安全性的一个步骤。该建议是基于现有的模型卡和数据集说明书标准提出的，并建议将这些发现应用于所有机器学习文档中，从而提出一种新的扩展方法，用于记录机器学习文档中的安全需求。", "conclusion": "通过扩充现有的ML文档标准，增加专门的安全部分，可以改进ML领域的文档质量，并有助于填补现有安全上的空白。这为提高机器学习系统的安全性提供了一个持久的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.23234", "html_url": "https://arxiv.org/abs/2506.23234", "title": "从发布到应用：下游开发者重复使用预训练AI模型面临的挑战", "title_en": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers", "authors": "Peerachai Banyongrakkul,Mansooreh Zahedi,Patanamon Thongtanunam,Christoph Treude,Haoyu Gao", "background": "预训练模型（PTMs）在各种领域中获得了广泛的关注，并取得了显著的成功，这得益于它们独特的性能和使用预训练模型的提供者提供的便捷性。然而，下游开发者在软件系统中重复使用PTMs所面临的挑战还鲜有研究。本文通过量化分析GitHub上31个开源项目中的840份与PTM相关的Issue报告，深入研究了这些挑战的具体情况。", "innovation": "在广泛研究的基础上，本文系统性地开发了一个全面的PTM相关挑战分类框架，揭示了下游开发者在重复使用PTMs时面临七大类挑战，包括模型使用、模型性能及输出质量等问题。研究还发现，与PTM无关的Issue相比，PTM相关的Issue解决时间更长，且不同挑战类别之间的解决时间存在显著差异。", "conclusion": "本文研究结果暗示了在实际应用中确保PTM性能和使用效率的重要性，同时也提出了未来研究可能的方向。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.03103", "html_url": "https://arxiv.org/abs/2410.03103", "title": "基于视距长度预测的规划感知代码填充", "title_en": "Planning-Aware Code Infilling via Horizon-Length Prediction", "authors": "Yifeng Ding,Hantian Ding,Shiqi Wang,Qing Sun,Varun Kumar,Zijian Wang", "background": "填充中间部分（FIM）或填充已成为代码语言模型的关键组成部分，使模型能够根据左右上下文生成缺失代码。当前的FIM训练模式通过重新排序序列进行下一个token预测（NTP），但这种模式导致模型难以生成与周围上下文对齐的内容。研究认为，仅依赖NTP不足以让模型学会在考虑到遥远的右侧上下文的情况下进行有效的规划。针对这个问题，研究提出了一种新的训练目标——视距长度预测（HLP），旨在使模型能够预测每次操作后余下的中间token数量。通过引入前瞻规划，HLP提升了FIM的效果，使模型能够自动学习适用于任意左右上下文的填充边界，无需依赖特定数据集的后处理。该方法在不同模型系列和规模下的评估显示，HLP相对提高了多样基准上的FIM性能高达24%，并且还提升了模型在代码推理方面的表现。更加重要的是，HLP在训练和推理阶段几乎没有额外的开销，确保其在实际场景中的可用性。", "innovation": "提出了视距长度预测（HLP），这是一种新型训练目标，使模型能够预测每次操作后批次剩下的中间token数量，从而引入前瞻规划，优化了填充中间部分（FIM）的性能。与传统的下一个token预测相比，HLP能够使模型在考虑遥远右侧上下文的情况下进行有效的规划，提升了代码推理和FIM的整体性能，无需数据集特定的后处理，且在训练和推断阶段几乎没有额外开销。", "conclusion": "视距长度预测（HLP）通过前瞻规划提升了填充中间部分（FIM）的性能。HLP在不同模型系列和规模下的评估显示，相对提升了多样基准上的FIM性能高达24%，提升了代码推理的性能。此外，该方法在训练和推理阶段无额外开销，是适用于实际场景的解决方案。"}
{"llm_update_time": "20250717", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.10323", "html_url": "https://arxiv.org/abs/2506.10323", "title": "ELFuzz: 通过大型语言模型驱动的合成在Fuzzing空间中的高效输入生成", "title_en": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space", "authors": "Chuyang Chen,Brendan Dolan-Gavitt,Zhiqiang Lin", "background": "传统的基于生成的模糊测试需要根据输入语法和语义约束手动构建测试用例。这需要较大的手工努力，并且难以扩展到大型系统。现有的方法难以满足实际系统的需求，特别是大型系统中，模糊测试覆盖率和发现bug的效率较低。", "innovation": "本文提出了一种名为ELFuzz的新方法，它通过大型语言模型驱动的合成在fuzzer空间中自动生成定制化的模糊测试器。ELFuzz能够自动从最小的种子模糊测试器开始，通过完全自动化的LLM驱动进化来推进合成，并加以覆盖率指导。与之前的方法相比，ELFuzz可以无缝地扩展到大型实际系统中，并且生成的模糊测试器能更高效地发现有趣的语法结构和语义约束。", "conclusion": "ELFuzz在实证研究中与由领域专家手动编写的规范和最新的前沿方法合成的结果进行了比较，证明ELFuzz的效果显著，覆盖率提高了434.8%，触发了174.0%更多的注入漏洞。在对最新的cvc5版本进行14天的真实模糊测试中，ELFuzz发现了五个0-day漏洞（其中三个是可利用的）。进一步的分析表明，ELFuzz在模糊测试空间模型上的贡献最大，其余部分贡献了37.5%的有效性。ELFuzz展示了在模糊测试中自动、高效和可扩展的输入生成的潜力。"}
