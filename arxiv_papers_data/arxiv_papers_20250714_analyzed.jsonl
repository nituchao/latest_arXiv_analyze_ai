{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08001", "html_url": "https://arxiv.org/abs/2507.08001", "title": "人类创造力与人工智能", "title_en": "Human Creativity and AI", "authors": "Shengyi Xie", "background": "随着科学与技术的进步，创造力的哲学观念经历了重大的重新诠释。本文探讨了心理学、认知神经科学和创造力哲学领域的当代研究，特别是在人工智能技术发展的背景下。文章旨在回答一个关键问题：人工智能能否表现出创造力？", "innovation": "本文回顾了创造力哲学的历史视角，并探讨了心理学进步对创造力研究的影响。它还分析了创造力的各种定义，并考察了自然主义和认知神经科学对创造力概念的回应。", "conclusion": "本文通过结合心理、神经科学和哲学视角，对人工智能的创造力进行了深入分析，提出了对未来研究的见解。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08264", "html_url": "https://arxiv.org/abs/2507.08264", "title": "计算型演绎系统：创造性演绎与未来方向", "title_en": "Abductive Computational Systems: Creative Abduction and Future Directions", "authors": "Abhinav Sood,Kazjon Grace,Stephen Wan,Cecile Paris", "background": "演绎推理，即推断观察背后的解释，常在科学、设计和艺术领域提及，但各自的理解有所不同。本研究回顾了演绎推理在 epistemology、科学和设计中的讨论，并分析了各种计算系统如何使用演绎推理。研究发现，尽管有理论框架和计算实现，但演绎推理仍然没有有效地生成创造性的假说。", "innovation": "研究将演绎计算系统分解为各个组成部分，并指出了未来研究的具体方向，以促进计算系统中创造性演绎推理的发展。", "conclusion": "本研究通过分析现有理论和计算系统的不足，确定了未来研究的特定方向，旨在提升计算系统中创造性演绎推理的能力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08249", "html_url": "https://arxiv.org/abs/2507.08249", "title": "给予AI代理访问加密货币和智能合约会创造新的AI危害向量", "title_en": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm", "authors": "Bill Marino,Ari Juels", "background": "随着对赋予人工智能代理访问加密货币以及交易它们的智能合约的兴趣增长，在此立场论文中，作者指出这样做可能会导致新的强大的AI危害。作者首先探讨了加密货币和智能合约的独特属性，这些属性可能导致这些新的危害向量，然后详细描述了这些新的危害。最后，作者呼吁进行更多的技术研究，以预防和减轻这些危害，从而促使让AI代理拥有加密货币和智能合约变得更加安全。", "innovation": "论文创新地探讨了将AI代理赋予访问加密货币和智能合约的权利在理论上可能导致的新形式的AI危害，以及这些危害的潜在途径。通过这种方式，论文提出了一个新的视角来理解如何通过技术上的改进来使这种行为更加安全和合理。", "conclusion": "论文最终强调了需要进行更多的技术研究，以预防和减轻这些新形式的AI危害，旨在为了让AI代理拥有加密货币和智能合约变得更为安全。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08046", "html_url": "https://arxiv.org/abs/2507.08046", "title": "TableReasoner：结合大语言模型推进表格推理框架", "title_en": "TableReasoner: Advancing Table Reasoning Framework with Large Language Models", "authors": "Sishi Xiong,Dakai Wang,Yu Zhao,Jie Zhang,Changzai Pan,Haowei He,Xiangyu Li,Wenhan Chang,Zhongjiang He,Shuangyong Song,Yongxiang Li", "background": "表格问答（TQA）任务因真实世界表格数据的特点而面临挑战，如数据量庞大、列语义不完整和实体歧义。这些挑战使得进行有效的表格理解及处理变得复杂。", "innovation": "提出了一个基于大语言模型和编程的表格推理框架TableReasoner，通过融合结构和语义表示的表格模型来实现全面理解和高效处理大型表格。设计了多步骤的模式链接计划，以提取相关查询的信息，消除歧义并减少幻觉。将推理流程整合到迭代思考架构中，允许思考、推理和反思的逐步循环。", "conclusion": "系统在SemEval-2025任务8的两个子任务中均排名第一。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08217", "html_url": "https://arxiv.org/abs/2507.08217", "title": "量子联邦学习在多模态数据中的应用：一种不依赖模态的方法", "title_en": "Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach", "authors": "Atit Pokharel,Ratun Rahman,Thomas Morris,Dinh C. Nguyen", "background": "量子联邦学习（QFL）最近被提出，旨在实现量子处理器（客户端）之间的分布式隐私保护量子机器学习（QML）模型训练。虽然已有研究取得了进展，但现有的QFL框架主要集中在单模态系统上，这限制了它们在涉及多个模态的现实任务中的应用。", "innovation": "本文首次提出了一种专为QFL设置设计的多模态方法，并使用量子纠缠进行中间融合。此外，为了解决多模态QFL中的主要瓶颈，即在某些模态缺席的情况下训练性能会下降，引入了一种名为“不依赖模态”的（MMA）机制，该机制隔离了未训练的量子电路，以确保在没有受污染状态的情况下稳定训练。", "conclusion": "实验结果表明，提出的多模态QFL方法与MMA机制相比，与最新的方法相比，在IID数据分布中提高了6.84%的准确性，在非IID数据分布中提高了7.25%的准确性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08207", "html_url": "https://arxiv.org/abs/2507.08207", "title": "针对大规模语言模型逃逸攻击的动态Stackelberg博弈框架的智能代理防御", "title_en": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking", "authors": "Zhengye Han,Quanyan Zhu", "background": "随着大规模语言模型（LLMs）在关键应用中的广泛应用，模型被对手操纵以规避安全机制的问题（即逃逸攻击）变得越来越重要。为了解决这一问题，本文采用动态Stackelberg博弈框架来建模攻击者和防御者在LLM逃逸攻击中的互动。博弈框架将提示-响应动态过程视为一个序列式的扩展形式博弈，其中防御者作为领导者制定策略并预见攻击者的最优回应。", "innovation": "本文提出了一种新颖的智能代理解决方案，命名为“Purple Agent”，它结合了对抗探索和防御策略，使用了快速扩展随机树（RRT）。Purple Agent能主动模拟潜在的攻击轨迹并预先干预以防止有害输出。这种方法为分析对抗动态提供了一种原理性的方法，并为缓解逃逸攻击的风险提供了基础。", "conclusion": "本文提出的动态Stackelberg博弈框架为理解和防范大规模语言模型逃逸攻击提供了一种新的思路和方法，通过Purple Agent这一智能代理解决方案，能够有效对抗潜在的威胁，保障模型安全。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08208", "html_url": "https://arxiv.org/abs/2507.08208", "title": "LLM-Nash博弈中的推理与行为均衡：从心态到行动", "title_en": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions", "authors": "Quanyan Zhu", "background": "本文介绍了LLM-Nash框架，这是一种博弈论模型，其中代理通过大型语言模型（LLMs）选择推理提示来引导决策过程。与传统博弈理论中完全理性和最大化效用的假设不同，该框架通过明确定义的推理过程来捕捉有限理性。在这个框架中，纳什均衡被定义在提示空间之上，代理的行为输出通过LLM推理过程体现出现。这种方法使我们能够研究认知限制、心态表达性和知识学习等方面的问题。", "innovation": "该论文的创新之处在于提出了LLM-Nash框架，通过大型语言模型的推理过程来捕捉有限理性的决策过程。这为研究认知限制、心态表达性和知识学习提供了新的视角。与传统博弈理论相比，该框架能够探索代理行为与收益最大化之间的差异，从而揭示在以LLM为驱动的系统中的战略互动新基础。", "conclusion": "通过引入LLM-Nash框架，本文研究表明，推理均衡与传统的纳什均衡可能在某些情况下存在差异，为基于大型语言模型（LLMs）的系统中的战略互动提供了一个新的分析框架。这一框架不仅有助于我们更好地理解代理在面对认知限制时的行为，也为知识学习和心态表达性的研究提供了一种新的方法。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08270", "html_url": "https://arxiv.org/abs/2507.08270", "title": "基于强化学习的代理安全对齐", "title_en": "Agent Safety Alignment via Reinforcement Learning", "authors": "Zeyang Sha,Hanling Tian,Zhuoer Xu,Shiwen Cui,Changhua Meng,Weiqiang Wang", "background": "随着能够使用工具的自主大型语言模型（LLM）代理的出现，带来了超出现有对话滥用的传统安全风险。这些代理因其执行外部功能的能力而受到用户触发（如对抗性提示）和工具触发（如受攻击工具的恶意输出）的安全威胁。本研究旨在提出首个统一的安全对齐框架，用于处理工具使用的代理所面临的两类威胁，通过结构化推理和沙箱强化学习实现。", "innovation": "提出了首个结合结构化推理和沙箱强化学习的统一安全对齐框架，定义了多模态分类，包括用户提示和工具响应的良性、恶意和敏感类型，并采用了自定义设计的沙箱环境模拟工具执行和实现细粒度的奖励塑形。", "conclusion": "通过在公共和自建基准上的全面评估，验证了安全对齐代理能显著提高对安全威胁的抵抗力，同时在良性任务中保持良好的实用性。研究结果证明了安全性和有效性可以同时优化，为自主LLM代理的信任部署奠定了基础。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08216", "html_url": "https://arxiv.org/abs/2507.08216", "title": "Neural-Symbolic AI中的接地方法", "title_en": "Grounding Methods for Neural-Symbolic AI", "authors": "Rodrigo Castellano Ontiveros,Francesco Giannini,Marco Gori,Giuseppe Marra,Michelangelo Diligenti", "background": "一种大型的神经-符号（NeSy）方法，使用机器学习器处理输入实体，依赖于基于一阶逻辑的推理器来表示和处理实体之间更复杂的关系。逻辑接地过程在这些方法中起着基础作用，它决定了使用（子）集中实体对逻辑规则的相关替换。一些NeSy方法通过穷尽所有可能替换的衍生来保留完整的逻辑知识表达能力，但这会导致需要考虑的地面规则公式数量的组合爆炸，并极大地限制了可伸缩性。其他方法依靠基于启发式的选择性衍生，尽管通常更具计算效率，但缺乏正当性和保证能保留提供给和返回给推理器的信息。", "innovation": "本文从多跳符号推理中汲取灵感，提出了一种参数化家庭的接地方法，以通用的后向链式推理为基础。这些方法的不同选择允许我们获得目前常用的接地方法，并控制推理器的表达能力和可伸缩性的权衡。", "conclusion": "实验结果显示，选择合适的接地标准往往与NeSy方法一样重要。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08210", "html_url": "https://arxiv.org/abs/2507.08210", "title": "从好奇心到能力：世界模型如何与探索动态相互作用", "title_en": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration", "authors": "Fryderyk Mantiuk,Hanqi Zhou,Charley M. Wu", "background": "智能代理在探索世界的同时也需要控制环境。在孩子玩耍和科学家实验中，智能代理需要平衡探索的好奇心和掌握环境的能力。探索的好奇心主要是为了获取新知识，而掌握能力是为了控制和驾驭环境。本研究结合了认知好奇心内在动机的理论和强化学习方法，探讨内部表征如何在好奇心（新颖性或信息获取）和掌握能力之间进行权衡。", "innovation": "研究使用两种基于模型的代理：一个是使用手工构建的状态抽象（Tabular），另一个是通过学习内置世界模型（Dreamer）。研究发现好奇心和掌握能力在Tabular代理中分别指导探索模式，而两者兼顾则改善了探索。Dreamer代理展示出探索与表征学习之间的双向互动，类似于好奇心和掌握能力的发育性共进化。这些发现将自适应探索正式化为追求未知与可控之间的平衡，为认知理论和高效的强化学习提供了新的见解。", "conclusion": "探索是追求未知与可控之间的平衡。这一研究不仅为认知理论提供了新的视角，也为提高强化学习效率提供了指导。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08392", "html_url": "https://arxiv.org/abs/2507.08392", "title": "基于多智能体LLM的AI系统中的伦理倡导者", "title_en": "Multi-Agent LLMs as Ethics Advocates in AI-Based Systems", "authors": "Asma Yamani,Malak Baslyman,Moataz Ahmed", "background": "将伦理纳入需求提取过程对于创造伦理对齐的系统至关重要。虽然手动提取伦理需求是有效的，但需要来自多个利益相关者的不同输入，这由于时间和资源限制而具有挑战性。此外，在需求提取过程中，伦理需求经常被列为低优先级。本研究提出了一种框架，通过在多智能体LLM系统中引入伦理倡导代理来生成伦理需求草案。这个代理根据系统描述对伦理问题进行批判和提供输入。", "innovation": "本研究提出了一种利用多智能体LLM中的伦理倡导代理生成伦理需求草案的框架。这种代理能够在系统描述的基础上批判和提供关于伦理问题的输入。研究通过两个不同背景的案例研究评估了所提出框架的效果，表明它可以捕获研究人员在30分钟访谈中识别出的主要伦理需求，并引入了多个相关需求。然而，该框架也揭示了在生成伦理需求方面的可靠性问题，强调了在这个敏感领域需要人类反馈的重要性。", "conclusion": "我们认为这项工作可以促进伦理在需求工程过程中的更广泛采用，最终导致更伦理对齐的产品。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08501", "html_url": "https://arxiv.org/abs/2507.08501", "title": "从语言到逻辑：一种双层框架下的结构化推理", "title_en": "From Language to Logic: A Bi-Level Framework for Structured Reasoning", "authors": "Keying Yang,Hao Wang,Kai Yang", "background": "自然语言输入的结构化推理仍然是人工智能的核心挑战，因为它要求在不规则的语言表达和形式逻辑表示之间建立联系。", "innovation": "本文提出了一种创新的双层框架，通过两级过程——高层次的任务抽象和低层次的逻辑生成——将语言转换为逻辑。该框架支持模块化推理，在数学问题解决、问答及逻辑推理等领域中具备泛化能力。此外，通过端到端的双层优化方法共同优化高、低层次的抽象和逻辑生成阶段。", "conclusion": "实验结果表明，该方法在准确性上显著优于现有基准模型，准确率提高可达40%，同时双层设计提升了透明度和错误可追踪性，为利用LLMs进行可信和系统推理提供了新的路径。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08454", "html_url": "https://arxiv.org/abs/2507.08454", "title": "为什么是这个而不是那个？一种基于逻辑的对比解释框架", "title_en": "Why this and not that? A Logic-based Framework for Contrastive Explanations", "authors": "Tobias Geibinger,Reijo Jaakkola,Antti Kuusisto,Xinghan Liu,Miikka Vilander", "background": "该研究定义了几类与对比解释相关的标准问题，用于回答“为什么P而不是Q？”这样的问题。这些问题在命题逻辑环境下计算P和Q的原因，并明确比较它们的差异。研究者还探讨了这些定义的基本性质，并展示了该框架如何捕捉现有文献中已存在的最小基数版本的对比解释。此外，还对问题的计算复杂性进行了详细分析，并利用回答集编程实现CNF公式，给出了实践中的示例应用。", "innovation": "该论文提出了新的标准问题，以回答“为什么P而不是Q？”的对比解释问题，并将这些问题应用于命题逻辑中。研究分析了这些问题的基本性质，并展示了与现有文献中对比解释的关系。论文还提供了计算复杂性分析，并通过回答集编程实现了CNF公式的对比解释问题，提供了实际应用的示例。", "conclusion": "论文探讨了基于逻辑的对比解释框架，并展示了该框架在命题逻辑环境下的应用。通过详细的性质分析和示范样本，论文证明了其框架的有效性，并通过实施对比解释问题的实例强化了该结论。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08306", "html_url": "https://arxiv.org/abs/2507.08306", "title": "M2-Reasoning: 提升多模态大型语言模型统一的一般推理和空间推理能力", "title_en": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "authors": "Inclusion AI:Fudong Wang,Jiajia Liu,Jingdong Chen,Jun Zhou,Kaixiang Ji,Lixiang Ru,Qingpei Guo,Ruobing Zheng,Tianqi Li,Yi Yuan,Yifan Mao,Yuting Xiao,Ziping Ma", "background": "近期，通过强化学习带有可验证奖励（RLVR）的多模态大型语言模型（MLLMs）已有显著进步，特别是在推理能力方面。然而，这些模型在动态空间交互方面仍然存在差距，这是为了在现实应用中变得有用所必需的能力。", "innovation": "本文介绍了M2-Reasoning-7B模型，旨在在一般和空间推理方面表现出色。创新之处在于两点：1) 开发了一个新型数据管道，产生294.2K高质量数据样本，用于冷启动微调和RLVR，具有逻辑连贯的推理轨迹并经过全面评估；2) 集成了逐步优化的动态多任务训练策略，以缓解数据冲突，任务特定奖励信号以提供定制激励信号。", "conclusion": "M2-Reasoning-7B通过精选数据和高级训练策略，在8个基准测试中达到了最新的最佳表现，凸显了其在一般推理和空间推理领域的强大性能。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08575", "html_url": "https://arxiv.org/abs/2507.08575", "title": "大规模多模态模型制图图解理解在文本地理参照本地化中的应用", "title_en": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing", "authors": "Kalana Wijegunarathna,Kristin Stock,Christopher B. Jones", "background": "在过去的几个世纪里，自然历史收藏中积累了数百万份生物样本记录，但它们大多未被地理参考。地理参考这些复杂描述的采样地点是一个劳动密集型的任务，现有的自动化方法未能充分利用地图这一工具。现有方法的准确性有限且依赖于单一模式.", "innovation": "本文提出了一种新的方法，该方法利用了最近的大型多模态模型（LMM）的多模态能力，通过图文结合的方式帮助模型理解并地理参照文本中的空间关系。通过网格方法将自回归模型应用于这一任务，实验结果表明该方法在小型手动标注数据集上的表现优于单一模式的地理参照方法和现有工具的平均距离误差接近1公里的误差，显示了利用LMM理解细粒度地图的潜力.", "conclusion": "研究结果鼓励提出了一种实用框架，旨在将该方法整合到地理参照工作流程中，进一步提高地理参照自动化水平。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08619", "html_url": "https://arxiv.org/abs/2507.08619", "title": "基于代理的大语言模型在概念系统工程与设计中的应用", "title_en": "Agentic Large Language Models for Conceptual Systems Engineering and Design", "authors": "Soheyl Massoudi,Mark Fuge", "background": "早期内工程设计涉及复杂、迭代的推理过程，现有大型语言模型（LLM）的工作流程难以保持任务连续性并生成可执行的模型。", "innovation": "研究评估了结构化的多代理系统（MAS）与简单的两个代理系统（2AS）相比，在需求提取、功能分解和仿真实体代码生成方面的有效性。", "conclusion": "MAS 和 2AS 均保持了完美的 JSON 完整性和实体标记。需求覆盖度较低。只有推理提炼的模型可靠地标记完成工作流程。Powered by DeepSeek R1 70B，MAS 生成了更详细的 DSG（平均5-6个节点），而2AS 模式化并压缩。结构化的多代理编排增强了设计细节。尽管推理提炼的 LLM 提高了完成率，但低需求和编码精度不足的差距仍然存在。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08529", "html_url": "https://arxiv.org/abs/2507.08529", "title": "罕见疾病诊断中的多粒度概念稀疏激活与层次知识图谱融合框架", "title_en": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "authors": "Mingda Zhang,Na Zhao,Jianglong Qin,Guoyu Ye,Ruixiang Tang", "background": "尽管医学大型语言模型在医疗领域取得了进展，但罕见疾病的诊断仍然受到知识表示深度不足、概念理解有限和临床推理受限的阻碍。", "innovation": "提出了一种将多粒度稀疏激活医学概念与层次知识图融合的框架。通过四种互补匹配算法、多样控制和五级后备策略实现精确的概念激活，同时三层知识图（分类学、临床特征、实例）提供结构化、最新的上下文。", "conclusion": "实验结果表明，在BioASQ罕见疾病QA集中，BLEU和ROUGE的增益分别为0.09和0.05，准确率增益为0.12，峰值准确率达到0.89接近0.90的临床阈值。专家评估确认在信息质量、推理和专业表达上的改进，表明该方法缩短了罕见疾病患者的“诊断历程”。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08664", "html_url": "https://arxiv.org/abs/2507.08664", "title": "Thought Introspection Helps AI Agents", "title_en": "Introspection of Thought Helps AI Agents", "authors": "Haoran Sun,Shaoning Zeng", "background": "AI 代理依赖大型语言模型（LLMs）和多模态 LLMS（MLLMs）在无需后训练的情况下执行文本和图像任务的解释和推理。LLMs 和 MLLMs 在 AI 代理的初始能力和局限性方面发挥着决定性的作用。通常，AI 代理通过复杂的提示工程和外部推理框架，与 LLMs 进行有效交互，如 Chain-of-Thought，迭代思维和图像思维。然而，它们仍然受限于 LLM 对自然语言理解的固有限制，且迭代推理过程会产生大量推理成本。", "innovation": "我们提出了一种名为 INoT（Introspection of Thought）的新 AI 代理推理框架，通过设计在提示中的一段新 LLM-Read 代码，使LLM 能够根据提示中的代码执行程序式的对话推理过程。这意味着自我否认和反思发生在 LLM 本身，从而有效减少了 token 成本。", "conclusion": "通过在六个基准测试中的三个不同任务上的实验，INoT 的有效性得到了验证，其性能平均提高了 7.95% 且超过基线。此外，INoT 的 token 成本平均比基线中的最佳方法低 58.3%。我们在图像解释和推理中的验证实验还展示了 INoT 的高效性和多功能性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08715", "html_url": "https://arxiv.org/abs/2507.08715", "title": "系统与系统建模与优化：一种多式联运集成框架", "title_en": "System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility", "authors": "Paul Saves,Jasper Bussemaker,Rémi Lafage,Thierry Lefebvre,Nathalie Bartoli,Youssef Diouane,Joseph Morlier", "background": "为了开发创新的系统架构，建模和优化技术一直是架构过程的核心，用于定义优化和建模问题。特别是在系统-of-系统中，使用高效的专用方法（通常是基于物理的模拟）来减少目标应用的计算复杂性是推荐的。然而，使用这些专用方法探索新的架构可能会给优化算法带来挑战，如评估成本增加和潜在的失败。", "innovation": "为了应对这些挑战，基于代理的优化算法，如利用高斯过程模型的贝叶斯优化算法已经出现。", "conclusion": "本文提出了一种集成框架，用于系统-of-系统的建模与优化，特别针对多式联运移动性问题。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08649", "html_url": "https://arxiv.org/abs/2507.08649", "title": "Leanabell-Prover-V2: 验证器集成的强化学习形式定理证明推理", "title_en": "Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning", "authors": "Xingguang Ji,Yahui Liu,Qi Wang,Jingyuan Zhang,Yang Yue,Rui Shi,Chenxi Sun,Fuzheng Zhang,Guorui Zhou,Kun Gai", "background": "该研究基于Leanabell-Prover-V1，在此基础上继续选择对现有的强大证明模型进行进一步的性能改进。背景信息强调，通过与Lean 4验证器集成的长链推理（CoT），该模型可以生成正式的定理证明。", "innovation": "Le Nabell-Prover-V2的主要创新点在于通过反馈集成来增强强化学习过程，具体包括：1. 使用Lean 4验证器提供的反馈进行强化学习；2. 自我意识的自我纠正机制，通过验证反馈识别推理过程中的正确性并学习反思性纠正错误；3. 采用多轮验证器交互直接优化LLM的推理轨迹，同时利用反馈标记遮蔽和简单奖励策略确保稳定训练。", "conclusion": "实验结果表明，Le Nabell-Prover-V2在Kimina-Prover-Preview-Distill-7B和DeepSeek-Prover-V2-7B上分别提高了3.2%和2.0%的性能，并且源代码、数据集和模型已公开发布。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08603", "html_url": "https://arxiv.org/abs/2507.08603", "title": "利用查询重写解锁语音指令数据的潜力", "title_en": "Unlocking Speech Instruction Data Potential with Query Rewriting", "authors": "Yonghua Hei,Yibo Yan,Shuliang Liu,Huiyu Zhou,Linfeng Zhang,Xuming Hu", "background": "端到端大型语音语言模型(LSLMs)在响应延迟和语音理解能力方面显示出强大的潜在能力，展示了在语音理解任务方面的泛化智能。然而，由于缺乏数据集和高度偏向的训练任务，根据语音指令的能力尚未完全实现。利用丰富的ASR数据集，先前的方法使用大型语言模型(LLMs)继续语音的语义信息，构建语音指令数据集。但由于LLM生成结果与真实人类响应之间的差距，这些延续方法进一步放大了这些问题。鉴于通过人工收集和注释语音指令数据集的成本高，使用语音合成构建大规模语音指令数据集已成为一种平衡而稳健的替代方案。尽管现代文本-to-语音（TTS）模型在合成质量上接近人类水平，但将分布在TTS模型训练数据中的离域文本指令转换为语音仍然极具挑战性。为解决这个问题，提出了一种具有多LLM知识融合的查询重写框架，通过多代理注释和验证合成语音，使得无需依赖人工注释即可构建高质量的语音指令数据集。实验表明，这种方法可以通过零样本重写将文本指令转换为更符合TTS模型的分布，使数据利用率从72%提高到93%。同时，该方法在需要复杂知识和上下文相关能力的重写任务中表现出独特的优势。", "innovation": "提出了一种具有多LLM知识融合的查询重写框架，通过多代理注释和验证合成语音，使得无需依赖人工注释即可构建高质量的语音指令数据集，解决了TTS模型训练数据分布不足导致的离域文本指令转换为语音的困难。此外，实验结果显示该方法能够通过零样本重写提高数据利用率，并在复杂知识和上下文相关能力的重写任务中表现出独特优势。", "conclusion": "提出的查询重写框架能够有效提高文本指令转换为适宜TTS模型的分布的可能性，显著提高了数据利用率，为大规模构建高质量语音指令数据集提供了一种有效的途径。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08705", "html_url": "https://arxiv.org/abs/2507.08705", "title": "elsciRL: 将语言解决方案集成到强化学习问题设置中", "title_en": "elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings", "authors": "Philip Osborne,Danilo S. Carvalho,André Freitas", "background": "本文介绍了一个名为 elsciRL 的开源 Python 库，旨在简化在强化学习问题上应用语言解决方案的过程。该库利用了 (Osborne, 2024) 中定义的语言适配器与自补充指令框架，并通过使用大型语言模型 (LLMs) 进行拓展。这种方法可以应用于新的应用场景，并且只需要最少的设置要求。此外，文中还提供了一个新颖的图形用户界面 (GUI)，该界面允许用户输入文本以供 LLM 生成指令，并自补充这些指令。实证结果表明，这些指令可以提高强化学习代理的表现。该工作旨在加速在基于奖励环境中的语言解决方案的评估，以促进新的科学发现机会.", "innovation": "elsciRL 是一个开源的 Python 库，它通过将语言适应器与自补充指令框架与 LLM 结合，为强化学习问题提供了新的解决方案。库中还提供了一个 GUI，这个工具可以让用户输入文本以生成自补充的指令，从而提高强化学习代理的表现。这种方法的应用具有灵活性，可以用于新应用，且设置简便。", "conclusion": "该工作展示了如何利用 elsciRL 加速在奖励环境中的语言解决方案的评估过程。该库能够使新的科学发现成为可能，因为它为强化学习研究提供了新的指令生成和执行方法。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08005", "html_url": "https://arxiv.org/abs/2507.08005", "title": "探究扩散模型在小分子生成中的潜力", "title_en": "Unraveling the Potential of Diffusion Models in Small Molecule Generation", "authors": "Peining Zhang,Daniel Baker,Minghu Song,Jinbo Bi", "background": "生成人工智能为化学家提供了新的药物设计思路，并促进了庞大化学空间的探索。扩散模型（DMs）作为新兴工具，最近在药物研发（R&D）中引起了广泛关注。该文综述了DMs在分子生成领域的最新进展和应用，从理论原则出发，分类了多种基于DM的分子生成方法，并在基准数据集上评估了这些模型的表现，特别是比较了现有三维生成方法的性能。", "innovation": "该论文全面回顾了DMs在分子生成领域的最新进展和应用，分类了各类基于DM的分子生成方法，特别是在基准数据集上对模型性能进行了评估和比较，强调了现有挑战并提出了未来研究方向，以充分利用DMs在药物发现中的潜力。", "conclusion": "该研究指出了当前在利用DMs方面面临的挑战，并提出了未来的研究方向，以更好地挖掘DMs在药物发现中的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08012", "html_url": "https://arxiv.org/abs/2507.08012", "title": "RepeaTTS：通过重复微调进行特征发现", "title_en": "RepeaTTS: Towards Feature Discovery through Repeated Fine-Tuning", "authors": "Atli Sigurgeirsson,Simon King", "background": "该研究表明，基于提示的文本到语音模型可以通过自然语言指令控制语音的各个方面，如说话速度和感知性别。尽管这些方法友好易用，但在控制能力上存在不足：控制仅限于模型训练期间暴露的声学特征，而在灵活性上，则可能导致模型输出不一致且难以控制。", "innovation": "该研究提出了一种新颖的微调方法，通过利用模型中的不可控变异来同时解决控制能力和灵活性的问题。通过主成分分析数千个合成样本，确定输出变异的主要潜在特征，并将其作为新的标签进行二次微调。这种方法在无情感揭示的模型上取得了成功，不仅提高了连续特征的可控性，还提高了离散特征的可控性。", "conclusion": "该研究展示了通过重复微调进行特征发现的有效性，该方法能够提高文本到语音模型的可控性，特别是对于没有情感揭示特性的模型，可以同时改进连续特征和离散特征的可控性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08011", "html_url": "https://arxiv.org/abs/2507.08011", "title": "可再生能源共址的人工智能数据中心能源管理", "title_en": "Energy Management for Renewable-Colocated Artificial Intelligence Data Centers", "authors": "Siying Li,Lang Tong,Timothy D. Mount", "background": "随着人工智能（AI）数据中心的兴起，它们对能源的需求也急剧增加。同时，可再生能源的利用率也在提高，尤其是在寻求减少碳排放和提高能效的背景下。将可再生能源与AI数据中心共址部署可以改善能源利用效率，并直接利用可再生能源为数据中心供电，从而降低成本并提升经济效益。然而，如何有效管理这种共址系统的能源利用，实现自动化的工作负载调度、本地可再生能源的最优利用以及电力市场的优化参与，成为了亟需解决的问题。", "innovation": "本文开发了一种可再生能源共址AI数据中心的能源管理系统（EMS），在利润最大化框架下，该系统同时优化了AI工作负载调度、本地可再生能源利用以及电力市场的参与。该研究通过在批发和零售电力市场参加模型下的实证评估，展示了可再生能源与AI数据中心共址运行中的显著经济效益。研究结果表明，这种共址部署可以显著增加成本节约和利润增长。", "conclusion": "该研究通过实证分析，证明可再生能源共址AI数据中心的能源管理系统能够最大化运营成本节约和利润收益。在这种框架下，不仅可以有效利用本地可再生能源，还可以通过电力市场的参与来进一步优化能源利用效率和经济效益。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05314", "html_url": "https://arxiv.org/abs/2507.05314", "title": "基于类特定集成和贝叶斯超参数优化的双重注意U-网++用于精确伤口和量规标记分割", "title_en": "Dual-Attention U-Net++ with Class-Specific Ensembles and Bayesian Hyperparameter Optimization for Precise Wound and Scale Marker Segmentation", "authors": "Daniel Cieślak,Miriam Reca,Olena Onyshchenko,Jacek Rumiński", "background": "临床图像中伤口和量规标记的准确分割是一项重大挑战，对于有效的伤口管理和自动评估至关重要。本文背景介绍了当前技术在处理这类图像时面临的问题，包括严重的类别不平衡和医学图像中的高变异性，需要开发更有效的模型来应对这些挑战。", "innovation": "本文提出了一个新的双重注意力U-Net++架构，结合了通道级（SCSE）和空间注意力机制来解决医学图像中的严重类别不平衡和变化性问题。此外，还独立训练了两个特定类别的模型，进行了广泛的预处理、数据增强和贝叶斯超参数优化，利用测试时增强技术进一步提高预测可靠性。实验结果表明，该方法在复杂医学分割任务中的有效性得到了证实，达到了0.8640的F1分数。", "conclusion": "本文介绍了双重注意力U-Net++模型及其在伤口和量规标记分割中的应用。通过独立训练特定类别的模型、广泛的数据增强和贝叶斯超参数优化，最终模型结合测试时增强提高了分割性能，特别是在复杂的医学图像分割任务中取得了显著效果。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08002", "html_url": "https://arxiv.org/abs/2507.08002", "title": "人类与基于LLM的主题分析在数字心理健康研究中的比较研究：概念验证研究", "title_en": "Human vs. LLM-Based Thematic Analysis for Digital Mental Health Research: Proof-of-Concept Comparative Study", "authors": "Karisa Parkington,Bazen G. Teferra,Marianne Rouleau-Tang,Argyrios Perivolaris,Alice Rueda,Adam Dubrowski,Bill Kapralos,Reza Samavi,Andrew Greenshaw,Yanbo Zhang,Bo Cao,Yuqi Wu,Sirisha Rambhatla,Sridhar Krishnan,Venkat Bhat", "background": "主题分析通过编码和主题开发为参与者的经验提供有价值的见解，但由于资源密集型的特性，限制了其在大规模医疗保健研究中的应用。大型语言模型（LLMs）能够大规模分析文本并自动识别关键内容，有可能解决这些挑战。然而，其在心理健康访谈中的应用需要与传统的人工分析进行比较。这项研究旨在使用来自减轻压力试验的健康工作者访谈转录文本，评估开箱即用和基于知识库的LLM主题分析方法与传统方法的优劣，从而解决这些挑战。", "innovation": "研究引入了利用LLM进行主题分析的方法，并通过与人类分析的直接比较，评估了基于知识库的LLM和开箱即用的LLM在开发主题和代码时的有效性。研究采用了OpenAI的GPT-4o模型和RISEN提示工程框架，并与Dedoose中的人类分析进行了对比。结果显示，结合人类监督，LLM可以更有效且成本效益更高地进行定量分析。", "conclusion": "LLM主题分析在成本效益方面优于传统方法，但在深度分析方面仍不及人类分析。当结合人类监督时，LLM可以改变心理健康和临床研究中的定性分析方法，更好地平衡参与者的视角与研究资源。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08017", "html_url": "https://arxiv.org/abs/2507.08017", "title": "大型语言模型中理解的机制指示", "title_en": "Mechanistic Indicators of Understanding in Large Language Models", "authors": "Pierre Beckmann,Matthieu Queloz", "background": "近年来，机制可解释性(MI)领域的最新研究挑战了大型语言模型(LLMs)仅依赖于表面统计数据的看法。这些研究深入探讨了LLMs内部的工作原理，论文基于此背景进行了总结和分析。", "innovation": "本文提出了一种新的理论框架，用于理解机器理解，并提出了一个分层次的机器理解概念。这包括概念理解、状态理解、原则理解。此外，作者还探讨了'并行机制'现象，认为尽管LLMs展现出某种程度的理解，但其认知架构仍然与人类不同。", "conclusion": "本文总结指出，尽管LLMs表现出理解能力，但它们的认知架构与人类认知方式存在差异，并提出应将讨论重点从LLMs是否理解转移到理解它们异乎寻常的运作方式上来。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08013", "html_url": "https://arxiv.org/abs/2507.08013", "title": "MedicalBERT: 使用预训练BERT模型增强生物医学自然语言处理", "title_en": "MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model", "authors": "K. Sahit Reddy,N. Ragavenderan,Vasanth K.,Ganesh N. Naik,Vishalakshi Prabhu,Nagaraja G. S", "background": "近年来，自然语言处理（NLP）领域的发展受到了预训练语言模型（如BERT，RoBERTa，T5和GPT）的推动。这些模型在理解复杂文本方面表现出色，但在生物医学文献领域，这些文献具有特定领域的专有名词，对如Word2Vec、双向长短期记忆网络（Bi-LSTM）等模型构成了挑战。尽管GPT和T5能够捕捉上下文信息，但在需要双向理解的任务中表现不足，而BERT则在这方面更胜一筹。", "innovation": "研究人员提出了一种名为MedicalBERT的预训练BERT模型，该模型在大规模生物医学数据集上训练，并配备了专门的词汇表，以增强对生物医学术语的理解。此外，该模型还进一步被优化和微调以应对各种任务，包括实体识别、关系抽取、问答、句间相似性和文档分类。通过F1评分、准确率和皮尔逊相关系数等性能指标，研究展示了MedicalBERT模型相比其他基于BERT的模型（如BioBERT，SciBERT和ClinicalBERT）的优势。", "conclusion": "MedicalBERT在几乎所有任务上都优于其他模型，并在所有测试任务中平均优于通用BERT模型5.67%。这表明利用预训练BERT模型进行医疗NLP任务具有巨大潜力，同时证明了迁移学习技术在捕捉领域特定信息方面的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08020", "html_url": "https://arxiv.org/abs/2507.08020", "title": "通过嵌入空间毒性衰减规避大型语言模型的安全对齐", "title_en": "Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation", "authors": "Zhibo Zhang,Yuxi Li,Kailong Wang,Shuai Yuan,Ling Shi,Haoyu Wang", "background": "大型语言模型（LLMs）在医疗保健、教育和网络安全等领域取得了显著成功，但这种开放性也带来了显著的安全风险，尤其是在通过嵌入空间投毒攻击中。这种攻击方式使得对手可以操控输入数据的内部语义表示，从而绕过安全对齐机制。尽管已有研究探索了泛化扰动方法，但LLM在嵌入层的安全对齐动态还缺乏足够的理解，因此，尚未研究出针对性更强且更精确的对抗性扰动技术。", "innovation": "本文提出了一种名为ETTA（Embedding Transformation Toxicity Attenuation）的新框架，通过线性变换来识别并衰减嵌入空间中的毒性敏感维度。ETTA在保持语义连贯性的同时避免了模型拒绝行为，并且无需进行模型微调或者访问训练数据。使用AdvBench基准测试了五个代表性开源LLM，ETTA实现了88.61%的高平均攻击成功率，比最佳基线高出11.34%，并且在安全保障增强模型中也表现出优异的泛化能力（如，指令调优防御模型上的87.39%成功率），这些结果突显了当前对齐策略中的关键漏洞，并强调了嵌入空间防御的重要性。", "conclusion": "本文的结果揭示了当前对齐策略中的重要漏洞，并突显了需要引入嵌入空间意识的防御措施。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08014", "html_url": "https://arxiv.org/abs/2507.08014", "title": "对现实对话的大规模分析揭示了LLM越狱的复杂性界限", "title_en": "Mass-Scale Analysis of In-the-Wild Conversations Reveals Complexity Bounds on LLM Jailbreaking", "authors": "Aldan Creo,Raul Castro Fernandez,Manuel Cebrian", "background": "随着大型语言模型（LLMs）的广泛应用，理解和研究越狱策略的复杂性和演变对于AI安全至关重要。本文通过大规模实证分析了来自多种平台的超过200万条真实对话的越狱复杂性，这些平台包括专门的越狱社区和通用聊天机器人。", "innovation": "使用一系列复杂度指标，包括概率度量、词汇多样性、压缩比和认知负担指标，研究发现越狱尝试的复杂度并不显著高于正常对话。这项发现表明了攻击复杂性在特定时间范围内的实际下限。通过时间分析发现用户攻击的毒性和复杂度保持稳定，而助手响应的毒性却下降，这表明防御机制正在改善。另外，复杂度分布中没有表现出幂律增长，进一步指出了越狱发展的自然限制。这些研究成果挑战了攻击者与防御者之间的持续技术竞赛观点，而是表明LLM的安全性进化受限于人类创新的局限性，同时防御措施正在不断进步。研究还揭示了学术界进行越狱披露中的关键信息隐患，因为超过当前基准复杂度的高级攻击可能会破坏现有平衡，导致广泛的危害，直到防御机制适应之前就已具备的破坏力.", "conclusion": "我们的发现挑战了对攻击者与防御者之间持续技术竞赛的传统观点，而是表明LLM安全性的进化受限于人类创新的局限性，而同时防御措施正在不断进步。此外，结果强调了在学术界披露越狱过程中存在的关键信息隐患，因为超越当前复杂度基线的复杂攻击可能会在防御机制适应之前造成广泛的危害。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08021", "html_url": "https://arxiv.org/abs/2507.08021", "title": "揭开图像字幕中有效上下文配置的面纱：外部与内部分析", "title_en": "Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis", "authors": "Li Li,Yongliang Wu,Jingze Zhu,Jiawei Peng,Jianfei Cai,Xu Yang", "background": "近年来，大规模模型的发展带来了上下文学习（ICL）能力的出现，尤其是在自然语言处理（NLP）领域，已经有多项研究证明了ICL的有效性。研究者们借鉴大型语言模型（LLMs）的成功，开发出了具有ICL能力的大规模多模态模型（LMMs），但仍对多模态ICL的演示配置探索不足。作为LMMs的一个具体任务，图像字幕生成吸引了研究者的注意。", "innovation": "本文通过全面的外部和内部分析，探究了在图像字幕任务中多模态上下文学习的有效演示配置。外部上，通过三个维度（镜头数量、图像检索和字幕分配）研究演示配置策略，系统地评估和总结关键发现。内部上，分析典型的大规模多模态模型的注意力特征，提出基于注意力的度量方法量化模型行为，并通过辅助实验探讨注意力驱动模型加速与压缩的可行性。此外，还比较了具有相同模型设计和预训练策略的大规模多模态模型在性能上的差异，并从预训练数据特征的角度解释这些差异。", "conclusion": "研究揭示了ICEs配置策略如何通过外部实验影响模型性能以及通过内部检验发现的典型特征模式，为理解大规模多模态模型中的多模态ICL提供了两种视角。本研究提出的方法结合了外部和内部分析以及新提出的度量方法，可应用于更广泛的大型模型研究领域。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08028", "html_url": "https://arxiv.org/abs/2507.08028", "title": "SSSUMO：实时半监督子运动分解", "title_en": "SSSUMO: Real-Time Semi-Supervised Submovement Decomposition", "authors": "Evgenii Rudakov,Jonathan Shock,Otto Lappi,Benjamin Ultan Cowley", "background": "现有的子运动分析方法在重建准确度、计算成本和验证方面存在挑战，主要原因是获取手标签数据的难度较大。因此，现有的方法难以提供有效的见解来了解运动控制。这篇论文旨在通过引入一种半监督学习方法来解决这些挑战，这种方法能够利用合成数据进行学习，并逐步适应未标记的人类运动数据，从而在合成和多样的人类运动数据集上显著超越现有方法，即使在高噪声条件下也能表现出色。此外，该模型可以实时运行（每秒输入小于一毫秒），大幅提高了性能，适用于人机交互、康复医学和运动控制研究的新应用。", "innovation": "论文提出了一种称为SSSUMO的半监督深度学习方法，用于亚运动分解，实现了最先进的准确性和速度。SSSUMO通过合成数据进行学习，这些数据最初是从最小加速度原则生成，并通过迭代适应未标记的人类运动数据。使用全卷积架构和可微重构，该方法在合成和多样的人类运动数据集上都取得了显著效果，特别是在难以用传统方法解决的高噪声条件下。模型能够在几毫秒内处理输入，比基于优化的技术有显著的性能提升。", "conclusion": "论文展示了SSSUMO模型在各种人类执行任务上的有效性，包括操控、旋转、指定位、移动物体、手写和鼠标控制的游戏，特别是在传统方法失败的具有挑战性的数据集上取得了显著改进。训练和基准测试源代码以及预训练模型权重已经公开，可以在网页 this https URL 获得。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08034", "html_url": "https://arxiv.org/abs/2507.08034", "title": "将外部工具与大语言模型集成以提高准确性", "title_en": "Integrating External Tools with Large Language Models to Improve Accuracy", "authors": "Nripesh Niketan,Hadj Batatia", "background": "众所周知，如果缺乏相关背景信息，大语言模型（LLMs）可能会提供质量较差的回答或者编造信息。已有研究提出了将LLMs与外部工具相结合的方法，旨在利用实时数据提高准确性。本文关注于在教育场景中增强LLMs解决问题的能力。为此，研究者开发了一个框架，该框架允许访问外部API以请求相关信息，并提供计算或日历等计算功能。这些方法的性能是通过MMLU（多模态语言理解）数据集进行评估的，该数据集包含了数学和科学推理问题。实验结果显示所提出的方法显著提高了准确性。", "innovation": "本文提出了一种框架，该框架允许大语言模型访问外部API以获取额外的相关信息，并提供了计算能力，如计算器或日历。与当前最先进的语言模型相比，所提出的方法在数学推理和科学推理方面的准确性有显著提升。具体而言，Athena框架在数学推理和科学推理方面的准确率分别为83%和88%，远超GPT-4o、LLaMA-Large、Mistral-Large、Phi-Large和GPT-3.5等所有测试模型，而表现最佳的基础模型LLaMA-Large的准确率仅为67%和79%。", "conclusion": "实验结果表明，提出的框架显著提高了大语言模型的性能，主要提升了数学推理和科学推理的准确性。这些结果揭示了更加复杂的计算生态系统围绕LLMs的潜力，可以使其使用更加自然，更好地支持各种任务和活动。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08044", "html_url": "https://arxiv.org/abs/2507.08044", "title": "ConsNoTrainLoRA:基于约束的数据驱动低秩适配器权重初始化", "title_en": "ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints", "authors": "Debasmit Das,Hyoungwoo Park,Munawar Hayat,Seokeon Choi,Sungrack Yun,Fatih Porikli", "background": "该研究背景在于，基础模型在大规模数据集上进行预训练后，通过参数高效微调（PEFT）技术如低秩适配器（LoRA）在较小的数据集上进行微调。大多数现有工作随机初始化LoRA权重矩阵，并在所有附加点上使用固定秩。这项研究旨在改进LoRA微调的收敛性和最终性能。", "innovation": "研究提出了一种数据驱动的权重初始化方法，ConsNoTrainLoRA（CNTLoRA），通过表达LoRA初始化为一个域移位问题，使用多个预训练和微调激活之间的约束。通过重新构建这些约束，获得了一个闭式估计的LoRA权重，这些权重依赖于预训练权重和微调激活向量，且在初始化时不进行训练。此外，将该权重估计分解为初始化上三角矩阵和下三角矩阵，使用变量秩的灵活性。", "conclusion": "定量和定性结果表明，CNTLoRA比标准的方法和数据驱动的初始化方法表现出更好的性能。广泛的分析和消融进一步阐明了该框架的设计选择，为更快的收敛和增强性能提供了最佳的方案。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08039", "html_url": "https://arxiv.org/abs/2507.08039", "title": "接近在图文模型中评估指令坚持鲁棒性的目标", "title_en": "Towards Evaluating Robustness of Prompt Adherence in Text to Image Models", "authors": "Sujith Vemishetty,Advitiya Arora,Anupama Sharma", "background": "近年来，大规模预训练模型（LLMs）取得了显著进展，显示出强大的能力和广泛的应用。这些模型在各种实际场景中的潜在应用引起了对它们可靠性和有效性的广泛关注。另一方面，尽管多模态LLMs和文本到图像模型近年来才逐渐受到重视，尤其是在与纯文本模型相比的情况下，但它们的可靠性仍然受限，因为缺乏对其性能和鲁棒性的评估研究。", "innovation": "该论文旨在建立一个全面的评估框架，专注于文本到图像模型对提示的遵循情况。为此，论文创建了一个新的数据集，以评估这些模型生成与输入文本提示中的因素变异相符合的图像的鲁棒性。论文利用gpt-4o模型生成的文本描述作为地面真实图像，并通过文本到图像模型生成图像，然后再次使用相同的系统提示通过预训练的VAEs对生成的图像进行评估，比较两次描述之间的差异。研究结果表明，这些模型难以生成只有两个因素变异的简单二值图像：一个简单的几何形状及其位置。", "conclusion": "研究表明，在文本描述中的简单几何形状和位置上，这些模型存在生成困难。通过预训练的VAEs还可以发现模型无法生成与输入数据集分布相符合的图像。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08037", "html_url": "https://arxiv.org/abs/2507.08037", "title": "CRISP: 复杂推理与可解释的步骤计划", "title_en": "CRISP: Complex Reasoning with Interpretable Step-based Plans", "authors": "Matan Vetzler,Koren Lazar,Guy Uziel,Eran Hirsch,Ateret Anaby-Tavor,Leshem Choshen", "background": "大型语言模型（LLMs）的进步强调了需要更强的推理能力来有效地解决复杂问题。尽管链式思考（CoT）推理是一个进步，但对于许多领域来说仍然不够。一种有前景的替代方法是显式的高层次计划生成，但现有的方法主要假设通过少量样本提示，LLMs可以生成有效的计划，而不需要额外的训练。这项研究挑战了这一假设，介绍了CRISP（复杂推理与可解释的步骤计划），这是一个多领域的数据集，包含用于数学推理和代码生成的高层级计划。CRISP中的计划是自动生成并严格验证的，包括自内而外和自外而内的验证方法。后端结果表明，对CRISP进行微调的小型模型能比使用少量提示的大模型生成更高质量的计划，同时，在转换任务上优于链式思考推理。此外，跨领域的评估表明，对一个领域进行微调改进了另一个领域中的计划生成，突出了学习到的规划能力的泛化能力。", "innovation": "1. 介绍了一个新的多领域的数据集CRISP，用于数学推理和代码生成的高层级计划，计划是自动生成并严格验证的。\n2. 证明了对CRISP进行微调的小型模型在生成高质量计划方面比大模型的效果更好。\n3. 通过跨领域评估，展示了学习到的规划能力的泛化性。", "conclusion": "CRISP数据集和相关方法展示了通过自动生成的高层级计划进行的微调能够显著改善模型的推理能力，特别是在生成高质量计划方面。这项研究为未来解决复杂问题提供了新的途径，同时也突显了计划生成在多领域应用中的重要性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08050", "html_url": "https://arxiv.org/abs/2507.08050", "title": "Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis", "title_en": "An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis", "authors": "Ming Wang,Zhaoyang Duan,Dong Xue,Fangzhou Liu,Zhongheng Zhang", "background": "医疗数据标注劳动密集型的性质，给呼吸系统疾病的诊断带来了巨大挑战，导致资源受限环境下高质量标注数据稀缺。同时，患者隐私问题复杂了机构间的直接数据共享，并且现有的依赖大量数据的数据驱动方法通常会牺牲数据隐私。医学图像的隐私泄露问题也很重要，它可能导致对敏感患者数据的重建。", "innovation": "提出了一种联邦少量样本学习框架与隐私保护机制，以解决诊断呼吸系统疾病时面临的标注数据有限和隐私保护问题。具体而言，提出了一种元随机梯度下降算法来缓解传统梯度下降方法在神经网络训练时因数据不足导致的过拟合问题。此外，通过在本地数据训练私有模型时向梯度中集成标准高斯差分隐私噪声，以防止梯度泄漏导致的数据隐私泄露。还采用加权平均算法聚合来自不同客户端的诊断模型，提升了模型的适应性，适用于不同场景下的数据结构、类别和分布情况。", "conclusion": "实验表明，该方法利用差分隐私实现了强大的诊断效果，能够利用不同结构、类别和分布的数据有效诊断呼吸系统疾病。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08096", "html_url": "https://arxiv.org/abs/2507.08096", "title": "单一SAR图像中的基于对象的深度学习方法进行建筑高度估计", "title_en": "An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images", "authors": "Babak Memar,Luigi Russo,Silvia Liberata Ullo,Paolo Gamba", "background": "利用非常高分辨率(VHR)合成孔径雷达(SAR)图像准确估计建筑物高度对于各种城市应用至关重要。为此，本文介绍了一种基于深度学习(DL)的方法，用于从单张VHR COSMO-SkyMed图像中自动估计建筑高度：一种基于边界框检测的对象回归方法，随后进行高度估计。研究的数据集包括欧洲、北美洲、南美洲和亚洲8座地理上不同的城市，涵盖了广泛的多样城市类型。", "innovation": "本文提出了一种新的DL方法，与先前的同类方法相比，该方法在跨城市和跨大陆的转移学习中表现出显著的潜力，并且在估计高度方面的性能尤为优异，特别是在欧洲城市中，均方绝对误差(MAE)约为一个建筑楼层高度(慕尼黑约2.20米)，远优于最近的其他先进方法，尤其是在跨分布数据场景中。尽管在推广到其他大陆的城市时观察到更大的变异性，特别是在亚洲，其独特的城市类型和高密度的高层建筑更为普遍，但对于单张VHR SAR图像的建筑高度估计，该方法依然具有很大的潜力。", "conclusion": "无论是在数据多样性方面，还是在估计精度方面，该研究都证明了DL方法在单张VHR SAR图像中的建筑高度估计应用中的强大表现和广泛的应用前景。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08045", "html_url": "https://arxiv.org/abs/2507.08045", "title": "Krul: 动态跨层KV共享的多轮对话高效状态恢复", "title_en": "Krul: Efficient State Restoration for Multi-turn Conversations with Dynamic Cross-layer KV Sharing", "authors": "Junyi Wen,Junyuan Liang,Zicong Hong,Wuhui Chen,Zibin Zheng", "background": "在使用大规模语言模型（LLMs）进行多轮对话时，高效地恢复历史上下文的关键值（KV）缓存状态仍面临重大挑战，这主要归因于重新计算或加载所有历史令牌完整KV缓存的开销。现有的方法通过在相邻且具有高度相似注意模式的层之间压缩KV缓存来应对这一问题。然而，这些方法通常会对所有对话应用固定的压缩方案，并在没有考虑对话特定的注意力动态的情况下选择相同的层对。这种静态策略忽视了不同对话中注意力模式相似性的差异性，可能导致明显的准确率下降。", "innovation": "我们提出了Krul，一种多轮LLM推理系统，旨在实现准确且高效的KV缓存恢复。Krul通过以下三个关键创新来实现这一目标：1) 预判式的压缩策略选择器，能够保留对未来对话轮次至关重要的上下文，并为对话选择定制化的策略；2) 颗粒度异构注意力相似性估算器，在模型生成过程中减轻注意力相似性计算和存储开销；3) 无气泡恢复调度器，减少由于压缩KV缓存带来的重新计算和加载均衡不佳所导致的潜在问题。实验结果表明，与现有方法相比，Krul在不牺牲生成质量的前提下，将第一个令牌的时间减少了1.5至2.68倍，并将KV缓存存储减少了1.33至2.35倍。", "conclusion": "Krul在多轮对话中实现高效的KV缓存恢复，通过动态选择压缩策略、减少注意力相似性计算并优化恢复调度，取得了显著的性能提升。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08137", "html_url": "https://arxiv.org/abs/2507.08137", "title": "3D人类与物体交互的一致性无边界完成重建", "title_en": "Temporally Consistent Amodal Completion for 3D Human-Object Interaction Reconstruction", "authors": "Hyungjun Doh,Dong In Lee,Seunggeun Chi,Pin-Hao Huang,Kwonjoon Lee,Sangpil Kim,Karthik Ramani", "background": "传统的3D重建方法通常假设静止的物体或者动态主体的完全可见性，这在实际场景中经常不符合。当这些假设被违反时，特别是在相互遮挡的情况下，会导致性能下降。因此，需要一个新的框架来解决这些问题。", "innovation": "本文提出了一种新的框架，利用无模版的方法结合时空上下文，进行无边界完成以推断部分遮挡区域的完整结构。该方法在处理遮挡和保持时间一致性方面比现有技术更优越。", "conclusion": "该方法通过3D高斯点云验证了其优越性，特别是在处理遮挡方面表现出更高的精确度和时间稳定性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08038", "html_url": "https://arxiv.org/abs/2507.08038", "title": "AblationBench: 在实证人工智能研究中评估自动化消融计划", "title_en": "AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research", "authors": "Talor Abramovich,Gal Chechik", "background": "基于语言模型（LMs）的自主代理在多个领域，包括科学研中越来越受欢迎。AI合作者旨在利用这些代理来支持或自动化科研过程的一部分。实证AI研究的核心是设计消融实验。为了这个目的，我们引入了AblationBench基准套件，用于评估代理在实证AI研究中的消融规划任务。AblationBench包含两个任务：AuthorAblation和ReviewerAblation，分别帮助作者和审稿人进行消融实验设计和审查。", "innovation": "我们提出了AblationBench，这是一个用于评估代理在实证AI研究中消融规划任务的基准套件。该套件包括两个任务，用于帮助作者和审稿人设计和发现消融实验。我们开发了基于LM的评估框架来评估这些任务的表现。实验结果显示，当前最前沿的LM系统仅能识别出原始消融实验的29%。我们还分析了当前LM系统在这些任务中的局限性，并发现chain-of-thought提示相比现有的代理方法具有优势。", "conclusion": "本文通过引入AblationBench，证明了当前最先进的LM系统在消融实验设计和审查任务中仍然面临极大挑战，chain-of-thought提示方法在当前代理方法中表现出更优的表现。研究结果进一步揭示了数据和模型对消融实验自动化实现的限制。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08121", "html_url": "https://arxiv.org/abs/2507.08121", "title": "Quasi-Random Physics-informed Neural Networks", "title_en": "Quasi-Random Physics-informed Neural Networks", "authors": "Tianchi Yu,Ivan Oseledets", "background": "物理感知神经网络通过将物理约束整合到神经网络训练中，在求解偏微分方程（PDEs）方面展现出了潜力，但其性能对采样点的分布敏感。Quasi-Random Physics-Informed Neural Networks (QRPINNs) 在高维问题上表现出色的非蒙特卡洛方法基础上，使用低不均匀序列（low-discrepancy sequences）替代直接从域中随机采样点进行训练。", "innovation": "QRPINNs 通过使用低不均匀序列替代随机采样点，克服了传统物理感知神经网络对采样点分布敏感的问题。理论证明，QRPINNs 的收敛速度优于传统物理感知神经网络（PINNs）。实验结果显示，QRPINNs 在高维 PDEs 中显著优于 PINNs 和一些代表性的自适应采样方法。进一步结合 QRPINNs 与自适应采样可以进一步提高性能。", "conclusion": "实验表明，QRPINNs 显著优于 PINNs 和其他自适应采样方法，尤其是在高维 PDEs 中。QRPINNs 结合自适应采样还可以进一步提升性能。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08128", "html_url": "https://arxiv.org/abs/2507.08128", "title": "Audio Flamingo 3: 采用完全开放的大规模音频语言模型推动音频智能", "title_en": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models", "authors": "Arushi Goel,Sreyan Ghosh,Jaehyeon Kim,Sonal Kumar,Zhifeng Kong,Sang-gil Lee,Chao-Han Huck Yang,Ramani Duraiswami,Dinesh Manocha,Rafael Valle,Bryan Catanzaro", "background": "当前，存在着各类音频语言模型，但大多数是封闭式的或在大规模数据集上训练的，且在跨语音、声音和音乐的理解和推理方面还有待提升。", "innovation": "Audio Flamingo 3 (AF3) 是一个完全开放且达到最佳水平的大规模音频语言模型，主要创新点包括：（i）统一的音频编码器 AF-Whisper，通过一种新的策略在三模态间进行联合表示学习；（ii）允许模型进行分步骤推理回答问题；（iii）多轮次、多音频聊天；（iv）长音频理解与推理，涵盖长达10分钟的语音；（v）语音到语音交互。此外，该模型采用多种新的大规模训练数据集进行训练，以及一种新型五阶段课程训练策略。", "conclusion": "在仅基于开源音频数据训练的情况下，AF3 在超过20个（长）音频理解与推理基准测试中达到了新的最佳水平，超过了使用更大数据集训练的开放型权重和封闭源模型的表现。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08053", "html_url": "https://arxiv.org/abs/2507.08053", "title": "Tree-Structured Parzen Estimator 能更高效地解决黑盒组合优化问题", "title_en": "Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently", "authors": "Kenshin Abe,Yunzhuo Wang,Shuhei Watanabe", "background": "Tree-structured Parzen estimator (TPE) 是一种广泛支持于流行超参数优化（HPO）工具中的方法。尽管这些HPO工具在深度学习（DL）趋势下发展，TPE通常在DL相关的多目标优化和多精度优化问题设置中讨论。然而，HPO的实际应用不限于DL领域，黑盒组合优化在化学和生物学等领域非常活跃。因此，组合优化作为TPE的一个尚未触及但非常重要的话题，文中提出了一个高效的组合优化算法，改进了TPE的方法。", "innovation": "文中主要创新在于：1）将TPE中的分类内核与数值内核进行通用化处理，引入分类内核的距离结构；2）讨论了新的内核处理大规模组合搜索空间的方法，这些方法能够减少内核计算时间复杂性，尤其是在组合搜索空间大小增加时；3）通过合成问题的实验验证了所提方法能够在较少评估次数下获得更好的解。", "conclusion": "所提出的算法已被纳入开源HPO框架Optuna中，证明了TPE在处理大规模组合优化问题上的高效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08104", "html_url": "https://arxiv.org/abs/2507.08104", "title": "VideoConviction：多模态基准测试用于人类信心和股票市场推荐", "title_en": "VideoConviction: A Multimodal Benchmark for Human Conviction and Stock Market Recommendations", "authors": "Michael Galarnyk,Veer Kejriwal,Agam Shah,Yash Bhardwaj,Nicholas Meyer,Anand Krishnan,Sudheer Chava", "background": "社交媒体扩大了被称为‘finfluencer’的金融意见领袖的影响范围，他们在YouTube等平台上分享股票推荐。理解这些意见领袖的影响需要分析超出文本分析的多模态信号，如语气、传达风格和面部表情。本文介绍了一个包含6000多个专家注释的多模态数据集VideoConviction，用于评估多模态大语言模型（MLLMs）和基于文本的大语言模型（LLMs）在金融对话中的表现。研究表明，尽管多模态输入有助于提取股票代码（如提取苹果公司的代码AAPL），但模型在区分投资行动与信心方面表现不佳，经常错误地将一般评论分类为确定性建议。虽然高信心建议的表现优于低信心建议，但它们仍然不及流行的S&P 500指数基金的表现。相反的策略——反向押注finfluencer的建议——在年回报率方面比S&P 500高出6.8%，但具有较高的风险系数（夏普比率为0.41对比0.65）.", "innovation": "该研究引入了一个名为VideoConviction的多模态数据集，该数据集由6000多个专家注释组成，旨在评估多模态大语言模型和基于文本的模型在金融对话中的表现。此数据集有助于区分投资行动和信心，而现有模型常常将一般评论误分类为确定性建议。同时，研究还展示了模型在处理完整视频和分割视频输入时的性能评价，这有助于推动金融多模态研究的深度.", "conclusion": "该基准测试使多模态任务的多样性评估成为可能，可以比较模型在完整视频和分割视频输入下的表现。这将推动多模态金融研究的发展。研究结果表明，尽管高信心的建议表现更好，但仍然未能超越S&P 500指数基金。反向押注finfluencer的建议策略在年回报率方面表现优于S&P 500，但具有更高的风险。研究提供的代码、数据集和评估排行榜可通过CC BY-NC 4.0许可证获取."}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08162", "html_url": "https://arxiv.org/abs/2507.08162", "title": "AmpLyze: 一种预测溶血浓度的深度学习模型", "title_en": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration", "authors": "Peng Qiu,Hanqi Feng,Barnabas Poczos", "background": "红细胞溶解（HC50）是抗菌肽（AMP）治疗药物的主要安全性屏障，现有模型只能简单地判断为‘毒性’或‘无毒性’。AmpLyze通过仅从序列预测实际HC50值并解释驱动毒性残基，弥补了这一空白。", "innovation": "该模型结合了残基级别的ProtT5/ESM2嵌入与序列级别描述符，在局部和全局分支中，并通过交叉注意模块对齐，使用log-cosh损失进行训练，以提高对实验噪声的鲁棒性。最优AmpLyze模型的PCC达到0.756，MSE达到0.987，超越了经典回归模型和最新的技术。消融试验表明，两个分支都是必不可少的，交叉注意模块进一步提高了1%的PCC和3%的MSE。梯度期望归因揭示了已知的毒性热点，并提出了更安全的替代方案。", "conclusion": "通过将溶血评估转换为定量、基于序列和可解释的预测，AmpLyze促进了AMP的设计，并提供了一种早期毒性筛查的实际工具。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08153", "html_url": "https://arxiv.org/abs/2507.08153", "title": "ALCo-FM: 自适应长上下文基础模型用于事故预测", "title_en": "ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction", "authors": "Pinaki Prasad Guha Neogi,Ahmad Mohammadshirazi,Rajiv Ramnath", "background": "交通事故虽然罕见，但其高影响特性要求准确的风险预测需要长时间序列和多模态信息的综合分析与推理。", "innovation": "提出了一种统一的自适应长上下文基础模型ALCo-FM，该模型通过计算波动前评分来动态选择输入数据的上下文窗口，并通过浅层交叉注意力机制编码和融合多模态数据。ALCo-FM 在多个局部GAT层后，结合了基于H3六边形网格的BigBird风格的稀疏全局变换器，并采用蒙特卡洛丢弃来提供置信度，从而产生高性能且校准良好的预测。", "conclusion": "ALCo-FM 在15个美国城市的交通数据上通过加权损失进行训练，然后在独立城市的少量数据上进行微调，最终在大规模城市风险预测基准上超过了20个最先进的基准模型，达到了0.94的精度、0.92的F1值和0.04的ECE值。该模型的代码和数据集可以在指定的链接中获取。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08177", "html_url": "https://arxiv.org/abs/2507.08177", "title": "重新思考时空异常检测：因果驱动的网络安全愿景", "title_en": "Rethinking Spatio-Temporal Anomaly Detection: A Vision for Causality-Driven Cybersecurity", "authors": "Arun Vignesh Malarkkan,Haoyue Bai,Xinyuan Wang,Anjali Kaushik,Dongjie Wang,Yanjie Fu", "background": "随着网络物理系统变得越来越相互连接和地理分布式，确保它们在不断演变的网络攻击下的韧性成为了一个关键优先事项。时空异常检测在确保系统安全和运营完整性方面扮演了重要角色。然而，当前的数据驱动方法，主要依靠黑盒深度学习，面临着可解释性、分布转移适应性以及在不断变化的系统动态下的鲁棒性等方面的挑战。", "innovation": "本文倡导因果学习视角来推进时空分布基础设施中的异常检测，基于结构性因果关系进行检测。我们确定并形式化了三个关键方向：因果图表征、多视图融合以及持续因果图学习，每种方法均在时间和空间上揭示动态因果结构方面具有独特优势。通过结合来自水处理等系统的真实世界见解，展示了因果模型如何提供早期预警信号和根本原因归因，解决黑盒检测器的局限性。", "conclusion": "展望未来的研究议程，我们将围绕多模态、生成人工智能驱动的和可扩展的自适应因果框架开展研究。我们的目标是为可扩展、自适应、可解释性和空间基础的异常检测系统开辟新的研究轨迹。我们希望激发网络安全研究中的范式转变，促进因果驱动的方法以应对互联基础设施中的不断演变的威胁。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08164", "html_url": "https://arxiv.org/abs/2507.08164", "title": "KP-A: 用于促进自主网络智能的统一网络知识平面", "title_en": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence", "authors": "Yun Tang,Mengbang Zou,Zeinab Nezami,Syed Ali Raza Zaidi,Weisi Guo", "background": "大语言模型（LLMs）和代理系统的发展，使得6G网络具备高级智能功能，包括自我配置、自我优化和自我恢复。然而，当前实现个别智能任务需要独立的知识检索管道，这导致了多余的数据流和解释一致性问题。", "innovation": "提出KP-A：统一网络知识平面，专为代理网络智能设计。通过将网络知识获取与管理与智能逻辑脱钩，KP-A 简化了开发过程并减少了智能工程师的维护复杂性。KP-A 提供了一个直观且一致的知识接口，从而增强网络智能代理的互操作性。", "conclusion": "展示了KP-A在两个典型智能任务中的应用：实时网络知识问答和边缘AI服务编排。所有实施成果均已开源，以支持可重复性和未来的标准化工作。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08143", "html_url": "https://arxiv.org/abs/2507.08143", "title": "Compactor：基于近似杠杆得分的校准查询无感知的KV缓存压缩", "title_en": "Compactor: Calibrated Query-Agnostic KV Cache Compression with Approximate Leverage Scores", "authors": "Vivek Chari,Benjamin Van Durme", "background": "现代大型语言模型（LLMs）越来越多地被训练以支持非常大的上下文窗口。然而，在生成中使用长上下文会受到KV缓存需求大的困扰，这种需求随着上下文长度线性增加。这种内存占用通常是实际部署中的主要资源瓶颈，限制了吞吐量并增加了服务成本。一种解决方法是通过压缩KV缓存来应对这一问题，这可以通过了解问题（查询有感知）或忽略查询（查询无感知）来实现。", "innovation": "Compactor是一种无参数的查询无感知的KV压缩策略，利用近似杠杆得分来确定 token 的重要性。它展示了即使在合成和真实上下文任务中保留一半 token 的同时，也能与竞争方法取得相同的性能，且具有最小的计算开销。进一步介绍了上下文校准压缩程序，使得能够推断出给定上下文可以支持的最大压缩比。使用上下文校准压缩，Compactor在Longbench上实现了完整的KV性能，同时将KV内存负担减少了63%。此外，我们将其应用于27个来自RULER和Longbench的合成和实际任务，涵盖Qwen 2.5和Llama 3.1等模型家族。", "conclusion": "Compactor通过基于近似杠杆得分的方式，实现了无参数的查询无感知的KV压缩策略，能够在保留一半token的同时保持与竞争方法相同的性能。经过上下文校准压缩后，它在Longbench上实现了完整的KV性能，同时大幅降低了KV内存负担。这种方法在多种合成和实际情况中均表现出高效性和普适性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08202", "html_url": "https://arxiv.org/abs/2507.08202", "title": "Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks", "title_en": "Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks", "authors": "Sounak Bhowmik,Travis S. Humble,Himanshu Thapliyal", "background": "量子神经网络（QNN）在量子机器学习（QML）的未来中具有巨大的潜力，但其安全性和鲁棒性尚待深入研究。本文提出了一种基于量子计算属性的新型后门攻击方法，这些后门利用量子门的单元性质插入噪声并使用Hadamard门实现叠加，开发后门并攻击QNN。", "innovation": "本文提议了一种基于量子属性的新型后门（Quantum Properties Trojans, QuPTs），利用量子门的单元属性插入噪声，使用Hadamard门实现叠加，来发展后门并攻击QNN。实验证明，提出的QuPTs不仅隐蔽性更强，还严重削弱了量子电路（特别是QNN）的性能。", "conclusion": "到目前为止，这是首个独立于任何混合经典-量子架构的对完全量子神经网络进行后门攻击的工作。提出的QuPTs在实验条件下导致了受攻击的QNN准确率下降23%。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08197", "html_url": "https://arxiv.org/abs/2507.08197", "title": "意识作为阻塞性相变", "title_en": "Consciousness as a Jamming Phase", "authors": "Kaichen Ouyang", "background": "本文发展了一个神经阻塞性图表，解释了大型语言模型中的意识是如何在高维度无序系统中作为一种关键现象出现的。通过将神经网络的阻塞性转变与颗粒物质和其他复杂系统中的阻塞性转变进行类比，作者识别了三个基本的控制参数，即温度、填充分数和体积，这些参数管理着神经网络的相行为。", "innovation": "理论提供了一个统一的物理解释，解释了人工智能中的经验标度定律，证明了计算冷却、密度优化和噪声减少如何如何使系统趋向于一种关键的阻塞性表面，在那里出现了通用智能。此外，共同的关键特征显示，相同的热力学原理也可能在神经网络中支配着意识的产生，如此类阻塞性转变的出现。因此，本文通过阻塞性物理学解释了神经语言模型的关键标度，表明意识是一种阻塞性相变，以长程相关性内在地连接知识组件。", "conclusion": "本文解释神经语言模型的关键标度通过阻塞性物理学，并暗示意识作为一种阻塞性相变，在一个本质上将知识组件通过长程相关性连接起来的系统中显现。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08255", "html_url": "https://arxiv.org/abs/2507.08255", "title": "量子加速的神经插补在大型语言模型（LLMs）中", "title_en": "Quantum-Accelerated Neural Imputation with Large Language Models (LLMs)", "authors": "Hossein Jamali", "background": "缺失数据对实际数据集构成了重大挑战，显著降低了机器学习模型的性能。尽管大型语言模型（LLMs）在表格数据插补方面已展现出显著能力，如UnIMP框架所展示，但它们对经典嵌入方法的依赖限制了对复杂非线性关联的捕捉，尤其是在包含数值、分类和文本特征的混合型数据场景中。", "innovation": "本研究引入了Quantum-UnIMP框架，将浅层量子电路集成到基于LLM的插补架构中。核心创新在于用由瞬时量子多项式（IQP）电路生成的量子特征映射替换传统经典输入嵌入，使得模型能够利用量子现象如叠加和纠缠，从而学习更丰富、更具表现力的数据表示，并增强对复杂缺失模式的恢复。", "conclusion": "在基准混合型数据集上的实验表明，Quantum-UnIMP在数值特征（RMSE）上的插补误差降低了最多15.2%，在分类特征（F1-Score）上的分类准确率提高了8.7%，优于最先进的经典和LLM方法。这些结果强调了量子增强表示在复杂数据插补任务中的巨大潜力，即使是在近期内的量子硬件条件下。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08191", "html_url": "https://arxiv.org/abs/2507.08191", "title": "TREC 2021深度学习赛道概述", "title_en": "Overview of the TREC 2021 deep learning track", "authors": "Nick Craswell,Bhaskar Mitra,Emine Yilmaz,Daniel Campos,Jimmy Lin", "background": "TREC深学习赛道正在进行第三年。以往使用MS MARCO数据集提供了大量人类标注的训练标签用于段落和文档排名任务。今年更新了文档和段落集合，导致文档集合大小增加了近四倍，段落集合大小增加了近16倍。大规模预训练深度神经排名模型继续在文档和段落排名任务中优于传统的检索方法。尽管单阶段检索在两个任务上表现出很好的性能，但仍然不如多阶段检索管道表现得好。增加了集合大小和数据更新使人们质疑在新集合中NIST判断的完整性和从旧集合映射到新集合的训练标签的质量，这是本文的重点讨论内容", "innovation": "在文档和段落集合都得到更新的情况下，利用大规模预训练的深度神经排名模型，进一步检验了其在两个任务上相较于传统检索方法的优越性。同时，发现了单阶段检索方法在两个任务上表现出色，但并不能完全匹配多阶段检索管道的效果。数据更新也引发了关于NIST判断完整性和旧新数据集映射训练标签质量的疑问", "conclusion": "大规模预训练在文档和段落排名上保持优势，单阶段检索在两个任务上表现良好，但尚未达到多阶段检索的效果。数据更新引发了一些关于NIST判断完整性和映射到新集合的训练标签质量的问题"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08310", "html_url": "https://arxiv.org/abs/2507.08310", "title": "生成人工智能在科学中的应用、挑战和新兴问题", "title_en": "Generative AI in Science: Applications, Challenges, and Emerging Questions", "authors": "Ryan Harries,Cornelia Lawson,Philip Shapira", "background": "本文研究了生成型人工智能（GenAI）对科学实践的影响。通过定性文献综述，探讨其在科学研究、科学研究写作、医疗实践和教育培训中的应用、好处和挑战。研究使用布尔搜索方法，在开放Alex出版数据库中查找与GenAI相关的科学文献（包括大型语言模型和ChatGPT），并详细分析了39篇高引用论文和评论。", "innovation": "研究采用定性文献综述的方法，重点分析GenAI在科学中的应用及其带来的挑战，并提出了未来研究中需要考虑的问题。研究覆盖了GenAI在科学研究、科学研究写作、医疗实践和教育培训中的应用，为理解其在科学中的角色提供了早期见解。", "conclusion": "虽然GenAI在科学和科学研究中的应用迅速增加，但其长期影响尚不明确，存在对GenAI使用和治理的持续不确定性。研究为理解GenAI在科学中的作用提供了初步见解，并指出了未来研究中需要关注的问题。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08288", "html_url": "https://arxiv.org/abs/2507.08288", "title": "基于不变量的大型语言模型鲁棒权重水印", "title_en": "Invariant-based Robust Weights Watermark for Large Language Models", "authors": "Qingxiao Guo,Xinjie Zhu,Yilong Ma,Hui Jin,Yunhao Wang,Weifeng Zhang,Xiaobing Guo", "background": "随着知识产权（IP）权利日益重要，尤其是在数十亿资源受限的边缘设备上部署大量语言模型（LLMs），水印技术得到了广泛关注。为了应对恶意用户可能带来的IP盗窃威胁，本文提出了一种无需重训练或微调变压器模型的鲁棒水印方案。", "innovation": "该方案为每位用户生成唯一的密钥，并通过从模型不变量构建的线性约束计算稳定的水印值。此外，该技术利用噪声机制在多用户场景下隐藏水印位置，以抵御合谋攻击。该方案在三种流行模型（Llama3、Phi3、Gemma）上进行了评估，实验结果表明该方法对各种攻击方法（如微调、剪枝、量化、置换、缩放、可逆矩阵和合谋攻击）具有很强的鲁棒性。", "conclusion": "实验结果证实了该鲁棒水印方案的广泛应用性和对多种攻击方法的稳定性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08309", "html_url": "https://arxiv.org/abs/2507.08309", "title": "通过同步自我审查其OCR能力提高MLLMs的文档图像机器翻译", "title_en": "Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency", "authors": "Yupu Liang,Yaping Zhang,Zhiyang Zhang,Zhiyuan Chen,Yang Zhao,Lu Xiang,Chengqing Zong,Yu Zhou", "background": "多模态大型语言模型（MLLMs）在文档图像任务中表现出色，特别是在光学字符识别（OCR）方面。然而，它们在文档图像机器翻译（DIMT）方面遇到困难，因为DIMT需要处理跨模态和跨语言挑战。先前通过在DIMT数据集上进行监督微调（SFT）来提高DIMT能力的努力往往会导致模型对现有单语言能力（如OCR）的遗忘。", "innovation": "本文引入了一种新颖的微调范式，名为同步自我审查（SSR），以提高MLLMs的DIMT能力。SSR通过模仿“双语认知优势”概念，促使模型在生成OCR文本之前先生成翻译文本。这样可以利用模型强大的单语言OCR能力，同时学习跨语言翻译。", "conclusion": "全面的实验表明，提出的SSR学习有助于缓解灾难性遗忘，提高MLLMs在OCR和DIMT任务上的泛化能力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08235", "html_url": "https://arxiv.org/abs/2507.08235", "title": "InsightBuild：智能建筑系统中的LLM驱动因果推理", "title_en": "InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems", "authors": "Pinaki Prasad Guha Neogi,Ahmad Mohammadshirazi,Rajiv Ramnath", "background": "智能建筑能够生成大量的传感器和控制数据，但设施维护人员往往无法清晰解释异常的能量使用情况。目前，在缺少透明且因果关系的解释下，他们难以诊断和解决能源效率问题。因此，需要一种方法来提供清晰、有针对性的解释以帮助管理人员处理此类问题。", "innovation": "我们提出了一种两阶段框架，名为InsightBuild，它结合了因果分析和微调过的大型语言模型（LLM），用于提供可读的因果解释。首先，一个轻量级的因果推理模块使用Granger因果检验和结构因果发现，对建筑遥测数据（如温度、空调设置、占用情况）进行分析。随后，一个微调过的LLM在接收到检测到的因果关系后，生成简洁且实用的解释。该方法在真实数据集上进行了验证，结果显示结合显式的因果发现与基于LLM的自然语言生成能够提供清晰且精确的解释，辅助管理人员诊断和解决能源效率问题.", "conclusion": "我们的研究结果表明，将明确的因果发现与基于LLM的自然语言生成相结合，可以提供清晰且精准的解释，帮助设施管理人员诊断和减少能源浪费。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08262", "html_url": "https://arxiv.org/abs/2507.08262", "title": "CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations", "title_en": "CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations", "authors": "Wenbo Cui,Chengyang Zhao,Yuhui Chen,Haoran Li,Zhizheng Zhang,Dongbin Zhao,He Wang", "background": "建立健壮的感知模块对于视觉运动策略学习至关重要。近期方法将预训练的2D基础模型集成到机器人的感知模块中，利用它们强大的语义理解能力。然而，这些方法在捕获3D空间信息和跨不同摄像头视角进行泛化方面存在局限性，这些局限性限制了策略的有效性，特别是在精细的机器人操作场景中。现有方法的这一限制阻碍了机器人操作策略的成功实施。", "innovation": "我们提出了一种新颖的3D预训练框架CL3R，旨在增强机器人的操作策略。我们的方法通过使用点云掩蔽自编码器来学习丰富的3D表示，并通过对比学习利用预训练的2D基础模型获取语义知识。此外，我们提出了一种统一数据集中坐标系的3D视觉表示预训练框架，并引入了多视角点云的随机融合，以减轻视图不确定性，提高泛化能力。在模拟和真实世界中的大量实验表明了该方法的优势，强调了其在机器人操作中的视觉运动策略学习效果.", "conclusion": "大量的实验表明，无论是模拟还是现实环境中，我们的方法都优于现有方法。我们在细粒度的机器人操作中验证了该方法在视觉运动策略学习中的有效性。CL3R在机器人的操作策略中提供了一种有前景的新方法，特别是对于3D空间信息的理解和跨不同摄像头视图的知识迁移。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08284", "html_url": "https://arxiv.org/abs/2507.08284", "title": "通过合成数据和RL引导的对抗训练实现轻量级的安全防护", "title_en": "Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training", "authors": "Aleksei Ilin,Gor Matevosyan,Xueying Ma,Vladimir Eremin,Suhaa Dada,Muqun Li,Riyaaz Shaik,Haluk Noyan Tokgozoglu", "background": "近年来，语言模型在内容审核任务中被广泛应用。然而，先前的研究主要集中在大型语言模型上，而小型语言模型在性能上可能不敌它们。本研究旨在通过合成数据生成和对抗训练方法，提升小型语言模型在内容审核任务中的表现。", "innovation": "本研究提出了一种轻量级且高效的防护框架，通过高保真合成数据生成和使用强化学习指导的对抗训练，使得小型语言模型能够达到甚至超越大型同类模型在内容审核任务中的表现。合成数据生成从标注种子数据出发，经过查询增强和同义改写，然后经过多轮审核，确保数据的多样性和相关性。对抗训练则利用生成器生成具有挑战性的合成样本，用以精调安全分类器，提高其检测和缓解有害内容的能力。", "conclusion": "通过迭代的对抗训练和高质量的合成数据生成，该框架使小型语言模型能够作为有效的安全防护工具。这种方法不仅减少了计算开销，还增强了对对抗攻击的抵抗力，为AI系统的内容审核提供了一个可扩展且高效的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08232", "html_url": "https://arxiv.org/abs/2507.08232", "title": "LLMs能否可靠地模拟数学和阅读理解中真实学生的能力？", "title_en": "Can LLMs Reliably Simulate Real Students' Abilities in Mathematics and Reading Comprehension?", "authors": "KV Aditya Srivatsa,Kaushal Kumar Maurya,Ekaterina Kochmar", "background": "大型语言模型（LLMs）在智能教学系统（ITSs）开发和测试问题试点中越来越受欢迎。但是，这些代理学生是否准确地模拟了真实学生的行为和特征仍然是一个问题。为了研究这个问题，作者收集了来自国家教育进度评估（NAEP）的489项题目，涵盖了四年级、八年级和十二年级的数学和阅读理解。通过运用项目反应理论（IRT）模型，作者将11种不同的和最先进的LLMs放置在与真实学生群体相同的能力尺度上。", "innovation": "作者采用了一个包含11种不同且最先进的大型语言模型的实验，通过项目反应理论（IRT）模型将这些模型放置在与真实学生群体相同的能力尺度上，旨在评估这些模型在数学和阅读理解中的能力模拟情况。研究结果表明，在没有提示的情况下，强大的通用模型在每个年级都优于平均学生，而较弱或领域不匹配的模型可能会偶然匹配。通过使用年级强化提示可以改变模型的性能，但这些模型是否与平均年级水平的学生匹配仍然高度依赖特定的模型和提示。目前没有一种模型-提示组合能够适用于所有科目和年级。", "conclusion": "根据研究结果，作者提出了基于发现的代理学生的选定指南，强调需要新的训练和评估策略。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08267", "html_url": "https://arxiv.org/abs/2507.08267", "title": "A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning", "title_en": "A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning", "authors": "Hiroshi Yoshihara,Taiki Yamaguchi,Yuichi Inoue", "background": "提升大型语言模型（LLMs）的数学推理能力是推动人工智能能力的重大挑战。虽然监督微调（SFT）和强化学习（RL）是主导的训练范式，但将这两个方法系统性地结合以最大化准确性和效率的研究还相对较少。这项工作提出了一种实用且有效的方法，将扩展的SFT与基于在线推理的RL（GRPO）策略性地集成在一起，以破除这一难题。", "innovation": "该研究引入了一种两阶段的实用训练配方，通过将SFT与RL结合，分别提升模型的准确性和效率。具体而言，该公式包括一个长期的SFT阶段来提高模型的精度，随后是GRPO阶段在保持峰值性能的情况下提高标记效率。研究通过在顶级基准测试和AIMO竞赛中表现出高效和准确的结果，验证了这种方法的有效性。", "conclusion": "这项工作为社区提供了一种经过实战考验的蓝图，以培养出既高度准确又实际高效的数学推理模型。为确保完全可重现性和支持未来的研究，其整个框架，包括所有代码、模型检查点和训练配置都将开源。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08366", "html_url": "https://arxiv.org/abs/2507.08366", "title": "使用深度强化学习的反应轮姿态智能控制", "title_en": "Intelligent Control of Spacecraft Reaction Wheel Attitude Using Deep Reinforcement Learning", "authors": "Ghaith El-Dalahmeh,Mohammad Reza Jabbarpour,Bao Quoc Vo,Ryszard Kowalczyk", "background": "可靠的卫星姿态控制对于太空任务的成功至关重要，尤其是在卫星越来越自主并且在动态和不确定环境中运行的情况下。反应轮（RW）在姿态控制中扮演着重要角色，维护RW故障期间的控制鲁棒性对于保护任务目标和系统稳定性至关重要。然而，传统的比例微分（PD）控制器和当前的深度强化学习（DRL）算法如TD3、PPO、A2C在提供自主卫星操作所需的实时适应性和故障容错方面往往不够。", "innovation": "本文提出了一种基于DRL的控制策略，旨在提高卫星在故障条件下的鲁棒性和适应性。具体而言，所提出的方案结合了TD3、Hindsight Experience Replay（HER）和Dimension Wise Clipping（DWC）技术，称为TD3-HD，以增强在稀疏奖励环境中的学习能力，并在RW故障期间保持卫星稳定性。该方法还通过与PD控制和领先DRL算法进行基准测试。实验结果表明，TD3-HD在姿态误差、角速度调节和在故障条件下的稳定性方面表现更好。", "conclusion": "这些发现强调了所提方法作为自主卫星姿态控制的强大、容错的自上而下人工智能解决方案的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08334", "html_url": "https://arxiv.org/abs/2507.08334", "title": "CoCo-Bot: 基于能量函数的可组合概念瓶颈生成模型以实现可解释生成模型", "title_en": "CoCo-Bot: Energy-based Composable Concept Bottlenecks for Interpretable Generative Models", "authors": "Sangwon Kim,In-su Jang,Pyongkun Kim,Kwang-Ju Kim", "background": "概念瓶颈模型(CBMs)通过经过显式的、人类可理解的概念引导生成过程，提供可解释性和可控的生成建模。但之前的生成CBMs常常依赖于瓶颈处的辅助视觉线索来补偿概念未能捕捉到的信息，这削弱了其可解释性和组合性.", "innovation": "本文提出了一种名为CoCo-Bot的后置可组合概念瓶颈生成模型，通过仅通过显式概念传输所有信息来消除对辅助线索的依赖。CoCo-Bot利用基于扩散的能量函数，支持针对任意概念的稳健后置干预，如概念组合和否定。实验结果表明，CoCo-Bot提高了概念层面的可控性和可解释性，同时保持了竞争力的视觉质量.", "conclusion": "实验使用预训练在CelebA-HQ上的StyleGAN2显示，CoCo-Bot能增强概念层面的可控性和可解释性，同时保持竞争力的视觉质量。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08333", "html_url": "https://arxiv.org/abs/2507.08333", "title": "使用离散扩散模型的音频修复", "title_en": "Audio Inpanting using Discrete Diffusion Model", "authors": "Tali Dror,Iftach Shoham,Moshe Buchris,Oren Gal,Haim Permuter,Gilad Katz,Eliya Nachmani", "background": "音频修复是指重建受损音频记录中缺失的部分的任务。以前的方法，包括基于波形和频谱图的扩散模型，在处理短间隔时显示出了有前景的结果，但当间隔超过100毫秒时，它们的质量往往会下降。现有的方法对此类长间隔的效果较差。因此，作者提出了一种使用离散扩散模型的新方法，该模型通过预训练音频分词器生成的音频表示在离散的潜在空间中工作，直接建模生成过程，以实现稳定且语义一致的音频缺失部分的重建。", "innovation": "该方法基于离散扩散模型，并且直接在经过分词的音频表示的离散潜在空间中建模生成过程，使得可以稳定和语义地重建缺失的音频部分，尤其对于较长的间隔有更好的表现效果。通过在MusicNet和MTG数据集上的实验，该方法在客观指标和感知指标上与现有基准达到了可竞争或更优的效果，特别是对于较长的间隔，为其提供了一种处理损伤音频恢复的稳健解决方案。", "conclusion": "实验结果表明，该方法对于较长时间间隔的音频修复取得了更好的效果，与现有基线相比，在客观和感知指标下具有竞争力或更优。该方法还提供了音频修复的音频示例。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08403", "html_url": "https://arxiv.org/abs/2507.08403", "title": "向AI本源的RAN：6G第一天标准化的运营商视角", "title_en": "Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization", "authors": "Nan Li,Qi Sun,Lehan Wang,Xiaofei Xu,Jinri Huang,Chunhui Liu,Jing Gao,Yuhong Huang,Chih-Lin I", "background": "6G移动网络将AI/ML作为核心特征，从设计之初就整合AI技术，以应对复杂性并支持广泛应用。基于2G到5G的移动网络运营和标准化经验，本文探讨了AI本源无线接入网络（RAN）的设计和标准化原则，特别是其关键的‘第一天’架构、功能与能力。研究表明，AI驱动的RAN处理/优化/自动化，可靠的AI生命周期管理（LCM）以及AI即服务（AIaaS）供应是其三个基本能力，为标准制定方向提供了重要线索。通过一个包含超过5000个5G-A基站的大规模现场试验，该架构及其支持的AI功能获得了显著的空口延迟降低、根本原因识别和网络能耗减少效果。", "innovation": "引入AI本源的RAN概念，强调从设计之初就整合AI技术，确保6G网络的复杂性和广泛应用场景得到解决。提出AI驱动的RAN处理/优化/自动化，可靠的AI生命周期管理（LCM）以及AI即服务（AIaaS）供应的三大基本能力，并基于这些能力，为6G AI本源RAN的标准设计提供了一种‘第一天’框架。", "conclusion": "本文提出了6G AI本源RAN ‘第一天’框架，平衡了技术创新与实际部署，通过大规模现场试验验证了该架构及其支持AI功能的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08404", "html_url": "https://arxiv.org/abs/2507.08404", "title": "基于语义哈希中心的深度哈希方法用于图像检索", "title_en": "Deep Hashing with Semantic Hash Centers for Image Retrieval", "authors": "Li Chen,Rui Liu,Yuxiang Zhou,Xudong Ma,Yong Chen,Dell Zhang", "background": "深度哈希是一种有效的大型图像检索方法。目前的方法通常根据监督类型分类，分为点式、成对式和列表式。最近的点式技术通过为每个类别预分配哈希中心提升了检索性能，但这些方法依赖于数据无关的算法生成哈希中心，这忽视了类别之间的语义关系，可能降低检索性能。", "innovation": "本文提出了语义哈希中心的概念，基于传统哈希中心的想法。提出了一种三阶段框架SHC，通过生成保留语义结构的哈希码来改进检索性能。第一阶段，开发了一个分类网络来通过数据相关的相似度计算识别类别之间的语义相似性；第二阶段，引入优化算法生成语义哈希中心，保持语义相关性并强制中心之间具有最小距离，以避免哈希码过于相似；第三阶段，使用这些语义中心训练深度哈希网络将图像转换为二进制哈希码。", "conclusion": "在几个公开数据集的大规模检索任务上进行的实验结果表明，使用SHC显著提高了检索性能。具体而言，SHC在MAP@100、MAP@1000和MAP@ALL指标上分别高于现有方法7.26%、7.62%和11.71%。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08330", "html_url": "https://arxiv.org/abs/2507.08330", "title": "高效医疗图像分析的可解释性导向剪枝", "title_en": "Interpretability-Aware Pruning for Efficient Medical Image Analysis", "authors": "Nikita Malik,Pratinav Seth,Neeraj Kumar Singh,Chintan Chitroda,Vinay Kumar Sankarapu", "background": "深度学习在医疗图像分析领域取得了显著进展，但在实际临床应用中，因现代模型规模庞大且缺乏透明性而受到限制。可解释性技术的进步，如DL-Backtrace、层间相关传播和整合梯度，使得评估神经网络中个体组成部分的贡献成为可能。本文旨在克服这些挑战，并提出了一个可解释性导向的模型剪枝框架来简化模型结构，同时保持预测性能和透明性。通过针对性地保留每一层中最相关的部分，该方法使轻量级且可解释的模型得以用于实际医疗场景中。", "innovation": "提出的可解释性导向的剪枝框架能够在简化模型复杂度的同时，保留预测性能和透明性。该方法通过有选择地保留每一层最相关的部分，实现了有针对性的压缩，维持了临床相关的表示能力。实验结果显示，这一方法能够在几乎不影响准确性的前提下实现高压缩率，为轻量级、可解释性的模型在医疗领域的实际部署开辟了新路径。", "conclusion": "实验结果表明，该方法在保持高压缩率的同时，只有极小的准确率下降，证明了其在多种医疗图像分类基准中的高效性。这为未来的轻量级、可解释性模型的实际应用铺平了道路，特别是在医疗健康领域。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08441", "html_url": "https://arxiv.org/abs/2507.08441", "title": "使用预训练视觉基础模型作为有效的视觉分词器用于自回归图像生成", "title_en": "Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation", "authors": "Anlin Zheng,Xin Wen,Xuanyang Zhang,Chuofan Ma,Tiancai Wang,Gang Yu,Xiangyu Zhang,Xiaojuan Qi", "background": "该论文利用预训练的视觉基础模型的强大表示能力，探索了一个新的方向：直接在这些模型之上构建图像分词器。传统的视觉基础模型主要用于视觉理解任务，而该研究旨在扩展其应用至分词和生成领域。", "innovation": "该研究引入了两个关键组件：1. 一个区域自适应量化的框架，用于减少预训练特征在规则2D网格上的冗余性；2. 一个语义重建目标，将分词器的输出与基础模型的表示相匹配，以保持语义的忠实性。基于此设计，所提出的图像分词器VFMTok在图像重建和生成质量方面取得了显著的改进，同时提高了分词效率，并加速了自回归生成模型的收敛速度。此外，它无需使用无条件引导，实现了高保真度的类别条件合成。", "conclusion": "该研究提出的VFMTok图像分词器在ImageNet基准测试中实现了gFID 2.07的优异成绩，比现有方法快了三倍，并且能够实现高保真度的类别条件合成。此外，该代码将向公众开放，以促进社区的发展。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08427", "html_url": "https://arxiv.org/abs/2507.08427", "title": "ChainEdit：通过逻辑规则指导的链式更新传播LLM知识编辑中的涟漪效应", "title_en": "ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains", "authors": "Zilu Dong,Xiangqing Shen,Zinong Yang,Rui Xia", "background": "当前的知识编辑方法在大型语言模型（LLMs）中难以在传播关联事实时保持逻辑一致性。现有的知识编辑方法难以处理知识传播时的逻辑连贯性问题，尤其是在大规模知识图谱中的知识传播过程中，逻辑一致性维持较为困难。因此，本文提出ChainEdit框架，这是一种结合知识图谱衍生逻辑规则和LLM逻辑推理能力的框架，用于实现系统性链式更新。", "innovation": "ChainEdit框架通过自动从结构化知识库中提取逻辑模式，并与LLM的内部逻辑相匹配，动态生成和编辑逻辑连接的知识簇。相比于基线方法，该方法在逻辑泛化方面提高了超过30%，同时保持了编辑的可靠性和准确性。此外，本文还通过知识感知的协议解决现有基准中的评估偏差问题，这些协议可以分离外部依赖，以确保知识编辑后的内部逻辑一致性。这种方法在涟漪效果传播方面达到了新的技术水平，提供了既定基线之外的最优性能。", "conclusion": "本文通过ChainEdit框架，结合知识图谱衍生的逻辑规则与LLM的知识逻辑处理能力，解决了大型语言模型知识编辑中的逻辑一致性问题，并通过实验证明了其有效性。同时，通过改善基准评估的方法，提出的新方法在涟漪效果传播方面取得显著进步。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "通过狄拉克平衡器和分布纠缠实现单域跨癌种多模态预后的一般化", "title_en": "Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在整合多模态数据进行生存预测方面取得了显著成效，但现有的多模态方法主要集中在单一癌症类型上，忽视了跨癌症类型的一般化挑战。已有研究表明，跨癌症类型的多模态预后模型往往比单模态模型表现更差，这在临床实践中是至关重要的。本文揭示了这一点，并提出了一个新的任务：单域跨癌症类型多模态预后的一般化，旨在评估在单一癌症类型上训练的模型是否能推广到未见过的癌症类型。", "innovation": "本文提出了两个创新模块：稀疏狄拉克信息再平衡器（SDIR）和癌症感知分布纠缠（CADE）。SDIR通过对强特征进行稀疏化和狄拉克启发的稳定化处理，以增强较弱模态的信号；CADE则通过融合局部形态提示和全局基因表达在潜在空间中的信息分布，来综合目标域分布。实验结果证明了这种新的方法在跨癌症类型多模态预后的优越推广能力。", "conclusion": "研究结果在四种癌症类型的数据集上进行了验证，表明所提出的方法具有更好的推广性，为实际的、稳健的跨癌症类型多模态预后奠定了基础。相关代码可在指定的链接中获取。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08448", "html_url": "https://arxiv.org/abs/2507.08448", "title": "从DUSt3R到VGGT的前馈3D重建综述", "title_en": "Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT", "authors": "Wei Zhang,Yihang Wu,Songhua Li,Wenjie Ma,Xin Ma,Qiang Li,Qi Wang", "background": "3D重建旨在恢复场景的密集三维结构，是诸如增强/虚拟现实、自动驾驶和机器人技术等众多应用的基础技术。传统方法如结构光metry (SfM) 和多视图立体匹配（MVS）依赖迭代优化以实现高精度，但这类方法受制于复杂的工作流程、高昂的计算成本以及在无纹理区域等挑战性场景中的脆弱性。近年来，深度学习促进了3D重建领域的范式转变，例如DUSt3R为代表的新一代模型提出了前馈范式方法。这些模型使用统一的深度网络直接从一组未加约束的图像中推断出相机位姿和密集几何结构，并且仅需一次前向传递即可完成。本文围绕这种新兴领域开展系统性的综述，分析这些前馈模型的技术框架、对比传统方法及其他学习型方法、概述相关数据集和评估指标等，并探讨该技术广泛的应用前景以及未来的关键挑战和机遇。", "innovation": "综述明确了前馈3D重建模型的技术框架，指出以DUSt3R为代表的新型模型使用统一的深度网络，在单次前向传递中同时推断相机位姿和密集几何结构。提出的方法对比了传统模型和早期的学习型模型，如MVSNet，展现了新范式的颠覆性影响，以及未来面临的挑战如模型精度与可扩展性、处理动态场景等关键问题。", "conclusion": "本文综述了3D重建领域的新兴前馈方法，系统地分析了该方法的技术框架，并与传统方法和早期学习方法对比，指出了该领域的应用前景和未来挑战。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08472", "html_url": "https://arxiv.org/abs/2507.08472", "title": "精简预训练LLM的成本：三种优化器的比较", "title_en": "Pre-Training LLMs on a budget: A comparison of three optimizers", "authors": "Joel Schlotthauer,Christian Kroos,Chris Hinze,Viktor Hangya,Luzian Hahn,Fabian Küch", "background": "优化器在减少大规模语言模型（LLM）预训练时间和提升模型性能方面起到了关键作用。本研究对比了三种主要的优化器版本：事实标准的AdamW、通过进化搜索开发的Simpler Lion以及二阶优化器Sophia。", "innovation": "研究通过使用两种不同的基础架构，并采用单个和多个时期的训练方法，在保持令牌数量恒定的情况下，对Maximal Update Parametrization和较小的代理模型进行了调整以独立优化每种基础架构和优化器组合的相关超参数。研究表明，尽管所有三个优化器的结果大致相同，但Sophia显示出最低的训练和验证损失，Lion在GPU小时数方面训练最快，而AdamW在下游评估结果上最佳。", "conclusion": "研究发现，尽管三种优化器的结果相似，但Sophia仍显示出最低的训练和验证损失；Lion在GPU训练时间上表现最佳；而AdamW则在下游评估中表现最佳。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08440", "html_url": "https://arxiv.org/abs/2507.08440", "title": "使用大语言模型在多智能体决策会议上寻找共识", "title_en": "Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences", "authors": "Selina Heller,Mohamed Ibrahim,David Antony Selby,Sebastian Vollmer", "background": "决策会议是一种结构化的协作会议，汇集了来自不同领域的专家以解决复杂问题并就未来的行动或政策达成一致意见。这些会议通常依靠引导讨论以确保富有成效的对话和集体一致意见。近年来，大语言模型（LLMs）在模拟现实世界场景方面显示出了显著的前景，特别是在模拟多智能体系统中模仿群体互动方面。在这项工作中，我们提出了一个基于LLM的多智能体系统，旨在模拟决策会议，特别是集中在检测参与者智能体之间的一致性上。将六种不同类型的LLM评估用于两个任务：立场检测，确定代理在给定问题上的立场；立场极性检测，确定情感是正面、负面还是中性。在多智能体系统中进一步评估这些模型，以确定它们在复杂模拟中的有效性。结果显示，即使在动态和复杂的辩论中，LLM也能可靠地检测到一致意见。在系统中加入一致意见检测智能体还可以提高群体辩论的效率，并增强整个讨论的质量和连贯性，使它们在结果和决策方面与现实世界的决策会议相当。这些发现证明了基于LLM的多智能体系统模拟群体决策过程的潜力，还指出此类系统在支持各种领域中的专家提取研讨会中的决策制定方面的潜在作用", "innovation": "提出了一种基于大语言模型（LLMs）的多智能体系统，专门用于模拟决策会议并检测参与者智能体之间的一致性。该系统评估了六种不同的LLMs在立场检测和立场极性检测任务上的表现。这些发现表明，即使在动态和复杂的辩论中，LLMs也能可靠地检测一致意见，且在系统中加入一致意见检测智能体能够提高群体讨论的效率和质量，使决策结果更接近现实世界中的决策会议。", "conclusion": "这些发现证明了基于大语言模型的多智能体系统模仿群体决策过程的潜力，并强调了此类系统在支持各种领域中的专家提取研讨会中的决策制定方面的潜在作用。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08458", "html_url": "https://arxiv.org/abs/2507.08458", "title": "文档固有价值：结构化记录的原理性归纳偏置设计", "title_en": "A document is worth a structured record: Principled inductive bias design for document recognition", "authors": "Benjamin Meyer,Lukas Tuggener,Sascha Hänzi,Daniel Schmid,Erdal Ayfer,Benjamin F. Grewe,Ahmed Abdulkadir,Thilo Stadelmann", "background": "当前先进的文档识别方法主要将文档识别视为一个计算机视觉问题，忽视了不同文档类型特有的内在结构属性，导致依赖于次优的手动后处理，许多不常见或更复杂的文档类型无法被现代文档识别系统有效处理。", "innovation": "提出了一种新的视角，将文档识别视为从文档到记录的转录任务。设计了专门针对文档结构的归纳偏置，以及基础转换器架构，并成功应用于不同类型的结构。证实了这种归纳偏置在从单音谱曲、形状绘图和简化工程绘图等不同复杂度的记录结构中有效工作。通过整合对未限制的图结构的归纳偏置，首次成功训练了一个从工程绘图到其内在互连信息的端到端模型。", "conclusion": "该方法适用于设计对标准OCR、OMR等理解不足的文档类型的文档识别系统，并为未来文档基础模型的设计提供指导。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08456", "html_url": "https://arxiv.org/abs/2507.08456", "title": "空间填充位置编码和Spiroformer", "title_en": "Space filling positionality and the Spiroformer", "authors": "M. Maurin,M.Á. Evangelista-Alvarado,P. Suárez-Serrato", "background": "transformers在处理序列数据时表现出色。将transformer模型推广到几何领域（如流形），我们遇到了缺乏全局顺序定义的问题。为了解决这个问题，文章提出了一种解决方案，即使用沿着空间填充曲线的注意力头。首例实验模型被设计为Spiroformer，它沿着2维球面上的螺旋曲线移动。", "innovation": "文章提出了一个新颖的解决方案来处理transformer模型在几何领域中的顺序问题，即使用沿着空间填充曲线的注意力头。这一创新在几何领域（如流形）中推广transformer模型，通过实验证明了沿着特定空间填充曲线（如2维球面上的螺旋曲线）的transformer模型（Spiroformer）的有效性。", "conclusion": "研究表明，沿着特定空间填充曲线（如2维球面上的螺旋曲线）的transformer模型（Spiroformer）能够有效解决在几何领域中缺乏全局顺序的问题，展示了transformer模型在几何和非序列数据处理上的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08487", "html_url": "https://arxiv.org/abs/2507.08487", "title": "改进作文衔接评估：一项新颖的项目反应理论方法", "title_en": "Enhancing Essay Cohesion Assessment: A Novel Item Response Theory Approach", "authors": "Bruno Alexandre Rosa,Hilário Oliveira,Luiz Rodrigues,Eduardo Araujo Oliveira,Rafael Ferreira Mello", "background": "论文背景介绍了文本连贯性在书面表达中的重要性以及自动评分的挑战。传统的机器学习算法在处理文本连贯性评估时未能充分考虑每个文本实例的独特特征。因此，需要一种新的方法来改善这一过程。", "innovation": "论文提出并分析了一种基于项目反应理论的连贯性得分预测方法，这种方法能够在机器学习模型中调整得分。实验中使用了扩展的Essay-BR语料库和来自公立学校中等年级学生的巴西葡萄牙语叙事作文。结果表明，该方法在多个评估指标上优于传统的机器学习模型和集成方法。", "conclusion": "研究探索了一种潜在的方法来提高教育作文中连贯性的自动评估，证明了项目反应理论在改进机器学习模型连贯性评估方面的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08499", "html_url": "https://arxiv.org/abs/2507.08499", "title": "PromotionGo在SemEval-2025任务11中的表现：面向特征的跨语言多情绪检测框架", "title_en": "PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts", "authors": "Ziyi Huang,Xia Cui", "background": "该论文提出了针对SemEval 2025 Task 11的系统，即在文本情感检测（Track A）任务中弥合多标签情感检测短文本的差距。该任务关注的是短文本上多标签情感识别，涉及28种不同语言。", "innovation": "文章提出了一种面向特征的框架，该框架能够动态调整文档表示和学习算法以优化特定语言上的表现。研究评估了三个关键组成部分：文档表示、降维以及模型训练，并特别突出了五种语言的详细分析结果。研究发现TF-IDF在低资源语言中仍然非常有效，而上下文嵌入和基于变换器的文档表示显示出特定的语言优势。主成分分析能有效地减少训练时间而不影响性能，特别是在处理FastText和基于神经网络的模型时。", "conclusion": "该框架为多语言情感检测提供了可扩展的解决方案，有效应对了语言多样性带来的挑战和资源限制。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08540", "html_url": "https://arxiv.org/abs/2507.08540", "title": "白-Basilisk：一种混合模型用于代码漏洞检测", "title_en": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection", "authors": "Ioannis Lamprou,Alexander Shevtsov,Ioannis Arapakis,Sotiris Ioannidis", "background": "软件漏洞的增多对网络安全构成了重大挑战，要求更有效的检测方法。现有方法在检测漏洞时存在局限性，尤其是在应对不平衡的真实世界数据集以及处理大型代码库时显得力不从心。", "innovation": "引入了名为White-Basilisk的新型漏洞检测方法，其性能优越且挑战了当前AI模型扩展的主流假设。White-Basilisk采用了独特的架构，集成了Mamba层、线性自注意力机制以及混合专家框架，仅使用200M参数就达到了业内领先的检测结果。此外，该模型能够处理前所未有的长序列数据，使得在一次通过中即可完成对大规模代码库的全面分析，超越了当前大型语言模型在上下文限制方面的不足。", "conclusion": "这项研究不仅在代码安全性方面确立了新的基准，还通过实验证明了紧凑且高效设计的模型在特定任务中可以超越更大规模的模型，可能重新定义AI开发中针对特定应用领域的优化策略。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08445", "html_url": "https://arxiv.org/abs/2507.08445", "title": "CUE-RAG: 通过多部图和查询驱动迭代检索实现准确且成本效益的基于图的RAG", "title_en": "CUE-RAG: Towards Accurate and Cost-Efficient Graph-Based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval", "authors": "Yaodong Su,Yixiang Fang,Yingli Zhou,Quanqing Xu,Chuanhui Yang", "background": "尽管大型语言模型（LLMs）取得了显著进展，但在问题回答（QA）方面的表现仍受限于缺乏领域特定和最新的知识。RAG（检索增强生成）通过集成外部信息（通常来自图结构数据）来解决这一局限性。然而，现有的基于图的RAG方法由于提取不完整以及查询信息利用不足，在检索过程中存在图质量较差的问题。", "innovation": "本文提出了一种名为CUE-RAG的新颖方法，引入了1）一个多重图索引，包括文本片段、知识单元和实体，以在不同层次上捕获语义内容；2）一种混合抽取策略，减少LLM的标记使用，同时产生准确且去歧义化知识单元；3）一种基于查询的迭代检索策略Q-Iter，通过语义搜索和受限的图遍历增强相关性。实验证明CUE-RAG在三个QA基准上显著优于最先进的基线，准确率提高99.33%，F1得分提高113.51%，同时将索引成本降低72.58%。此外，CUE-RAG在不使用LLM进行索引的情况下，也能匹配或超越基线。", "conclusion": "CUE-RAG在提高基于图的RAG系统效果和成本效益方面展现出显著的有效性和经济效益。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08400", "html_url": "https://arxiv.org/abs/2507.08400", "title": "Unleashing the Potential of Large Vision Models for Unified Matching Models", "title_en": "PanMatch: Unleashing the Potential of Large Vision Models for Unified Matching Models", "authors": "Yongjian Zhang,Longguang Wang,Kunhong Li,Ye Zhang,Yun Wang,Liang Lin,Yulan Guo", "background": "当前在立体匹配、光流估计和特征匹配等两个帧之间的对应匹配任务中，大多数方法依赖于特定任务的架构和特定领域的微调。这种方法需要为每个任务设计专有的统一架构或针对特定任务的集成模型，导致了设计上的复杂性和重复工作。作者观察到任何两个帧之间的对应匹配任务都可以通过一个二维位移估计框架来解决，且可以使用相同的模型权重实现。这种表述消除了设计专门统一架构或特定任务集成模型的需要，而是通过赋予位移估计算法前所未有的泛化能力实现多任务集成。实验中展示了数据集的跨域性，并使用统一的模型权重展示了PanMatch在多种领域的可移植性。在跨任务评估中，PanMatch的表现优于UniMatch和Flow-Anything，且在任务特定基准上的表现与最先进的特定任务算法相当。此外，在异常场景（如雨天和卫星图像）中，PanMatch展现了前所未有的零样本性能，即使在大多数现有的鲁棒算法无法产生有意义结果的情况下也能表现出良好的鲁棒性。", "innovation": "1. 提出了一个通用的二维位移估计框架，可以在不同任务间共享模型权重，简化了架构设计。\n2. 强调了跨多个领域和任务的稳健性特征提取的重要性，并提出了一种特征转换管道，利用大型视觉模型的通用特征来赋予匹配基础模型零样本的跨视图匹配能力。\n3. 使用了一个跨领域的数据集进行预训练，该数据集包含来自立体匹配、光流和特征匹配领域的近180万个样本，提升了模型的泛化能力。\n4. 通过在一个模型中实现跨任务的集成，同时提供了在异常情况下的零样本性能，提升了鲁棒性。", "conclusion": "本研究通过引入PanMatch模型，突出强调了大型视觉模型在统一匹配模型中的潜力，展示了在不同数据集和任务上的广泛适应性与高表现。PanMatch在跨任务评估中表现出色，特别是在异常场景中展现了优于传统的鲁棒算法的零样本性能。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08546", "html_url": "https://arxiv.org/abs/2507.08546", "title": "RadiomicsRetrieval: 基于radiomics特征的可调节医学图像检索框架", "title_en": "RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features", "authors": "Inye Na,Nejung Rue,Jiwon Chung,Hyunjin Park", "background": "医学图像检索在临床决策支持中具有重要意义，当前方法主要支持2D图像，且需要完全标注的查询，限制了临床灵活性。RadiomicsRetrieval以放射组学描述符和基于深度学习的肿瘤级嵌入连接，形成一个3D内容检索框架，完全利用体数据来利用丰富的空间上下文。该方法通过有提示的分割模型（如SAM）推导出肿瘤特定图像嵌入，并通过对比学习与特定肿瘤的放射组学特征对齐。此外，还通过解剖位置嵌入（APE）进一步丰富了这些表示，从而允许基于形状、位置或部分特征集的灵活查询。实验表明，放射组学特征显著提高检索的特异性，而APE提供的整体解剖上下文对于基于位置的搜索至关重要。该框架只需要极少用户提示（例如，单个点），减少了分割的开销，并支持各种临床场景。", "innovation": "RadiomicsRetrieval创新在于将3D内容检索与放射组学特征结合起来，利用丰富的空间上下文，通过对比学习和解剖位置嵌入提高了检索的灵活性和准确性。该方法只需少量用户提示，降低了分割的负载，适用于多样化的临床应用场景。", "conclusion": "RadiomicsRetrieval框架通过混合手工地放射组学描述符和基于深度学习的嵌入，提供了可调节的医学图像检索能力，特别适用于基于形状、位置或部分特征集的灵活查询。该方法显著提高了检索的特异性，并通过解剖位置嵌入提供了整体解剖上下文，支持诊断、治疗规划和大规模医学图像库研究。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08530", "html_url": "https://arxiv.org/abs/2507.08530", "title": "MIDI-VALLE: 通过神经编解码语言模型改进富有表现力的钢琴演奏合成", "title_en": "MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling", "authors": "Jingjing Tang,Xin Wang,Zhe Zhang,Junichi Yamagishi,Geraint Wiggins,George Fazekas", "background": "目前的音乐表演合成管道通常采用两阶段流程：首先从乐谱生成具有表现力的MIDI表演，然后将MIDI转换为音频。尽管这些模型在处理乐器声学和人类解释方面表现良好，但它们在泛化到多样化的MIDI源、音乐风格和录音环境中时常常表现出色度下降。MIDI-VALLE模型旨在解决这些问题，通过神经编解码语言模型改进钢琴演奏的合成表达性。该模型借鉴了用于零样本个性化文本转语音（TTS）合成的VALLE框架，适用于MIDI到音频合成，特别是在钢琴表演方面展现出独特的建模能力。模型通过构建在广泛和多样的钢琴表演数据集上进行训练，增强了其泛化能力。实验结果表明，MIDI-VALLE在Atepp和Maestro数据集上分别实现了超过75%的更低的Frechet音频距离，并在听觉测试中获得了显著更高的支持率。", "innovation": "MIDI-VALLE模型引入了对参考音频表演及其对应MIDI的条件处理，不同于以前依赖于钢琴卷积的TTS系统，MIDI-VALLE将MIDI和音频编码为离散令牌，这促进了钢琴表演的一致和稳健建模。此外，MIDI-VALLE通过在广泛多样化的钢琴表演数据集上进行训练，提高了其泛化能力，从而实现了更高质量的合成。", "conclusion": "MIDI-VALLE显著优于最先进的基线模型，在Atepp和Maestro数据集上的Frechet音频距离降低了超过75%，并且在听觉测试中以202票的优势击败了基线模型，证明了其在多样化的MIDI输入上的改进合成质量和泛化能力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08574", "html_url": "https://arxiv.org/abs/2507.08574", "title": "基于3D空间-语言-视觉集成和双向交互注意力机制的多模态融合框架用于脑肿瘤分割", "title_en": "A Multi-Modal Fusion Framework for Brain Tumor Segmentation Based on 3D Spatial-Language-Vision Integration and Bidirectional Interactive Attention Mechanism", "authors": "Mingda Zhang,Kaiwen Pan", "background": "本研究旨在开发一种新的多模态融合框架，用于脑肿瘤分割。该框架通过双重视觉-语义交互注意机制整合空间-语言-视觉信息，以提高分割准确性和边界标定。研究使用了BraTS 2020数据集进行评估，该数据集包含369份多机构的3D MRI扫描图像。", "innovation": "研究的主要创新点在于提出了多模态语义融合适配器（MSFA）和双向交互视觉-语义注意（BIVA）两个核心模块。MSFA通过层次语义解耦整合3D MRI数据和临床文本描述，而BIVA则促进模态间的迭代信息交换。实验证明，该方法在增强肿瘤、肿瘤核心和整个肿瘤区域的平均Dice系数为0.8505，95%豪斯多夫距离为2.8256毫米，超过了包括SCAU-Net、CA-Net和3D U-Net在内的最先进的方法。消融研究进一步确认了语义和空间模块对边界精确度的关键贡献。", "conclusion": "多模态语义融合结合双向交互注意显著提高了脑肿瘤分割性能，建立了将临床知识整合到医学图像分析的新范式。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08557", "html_url": "https://arxiv.org/abs/2507.08557", "title": "FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation", "title_en": "FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation", "authors": "Yuxuan Jiang,Zehua Chen,Zeqian Ju,Chang Li,Weibei Dou,Jun Zhu", "background": "生成模型的最新进展使得Text-to-audio (T2A)生成取得了令人瞩目的成果。但是，由于可用的时序对齐的音频-文本对数量有限且质量不高，现有的T2A方法难以处理包含精确时间控制的复杂文本提示，例如“猫在2.4s-5.2s发出叫声”。最近的研究探索了数据增强技术或在模型输入中引入时间条件来实现10秒的时间条件下的T2A生成，但合成质量依然受限。", "innovation": "提出了一个无需训练的新型时效控制的Text-to-audio (T2A)框架FreeAudio，旨在实现长文本条件下的时效控制T2A生成。具体创新点包括：1) 解耦和聚合注意力控制以实现精确的时间控制；2) 上下文隐空间组成以实现局部平滑性，引用指导以实现全局一致性。FreeAudio能够在无需训练的方法中达到最优的时效控制T2A合成质量，并在长文本生成质量上与训练基方法相当，为时效控制的长文本T2A合成提供了新的路径。", "conclusion": "广泛的实验表明：1) FreeAudio在无需训练的方法中实现了最前沿的时效控制T2A合成质量，其质量与领先的方法基本相当；2) FreeAudio在长文本生成质量上与训练基方法Stable Audio相当，并为时效控制的长文本T2A合成开辟了新的途径。演示样本可在提供的链接中获取。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08584", "html_url": "https://arxiv.org/abs/2507.08584", "title": "是否交易：一种促进建立市场风险估计的代理方法改善交易决策", "title_en": "To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions", "authors": "Dimitrios Emmanoulopoulos,Ollie Olby,Justin Lyon,Namid R. Stillman", "background": "大型语言模型（LLMs）越来越多地部署在代理框架中，在这些框架中，提示触发复杂的基于工具的分析以实现特定目标。尽管这些框架在多个领域，包括金融，显示出了潜力，但它们通常缺乏一套有原则的模型构建步骤，而是依赖情感或趋势分析。本研究旨在填补这一空白，通过开发一种代理系统，使用LLMs反复发现金融时间序列的随机微分方程，生成风险指标，以指导日常交易决策。该系统在传统的回测和市场模拟器中得到评估，市场模拟器引入了合成但因果合理的价格路径和新闻事件。实验证明，基于模型的交易策略优于标准的LLM代理，多个股票的夏普比率有所提高。", "innovation": "本文创新地提出了一个代理系统，利用LLMs反复挖掘金融时间序列的随机微分方程模型，从而生成风险指标影响每日交易决策。这种方法与传统的基于情感或趋势分析的模型不同，它填补了理解和预测市场风险方面的空白。此外，通过在真实交易（回测）和市场模拟器中进行测试，该模型能够显著提高交易策略的性能和盈利能力。", "conclusion": "结合LLMs与代理模型发现有助于提高市场风险评估，并能够做出更盈利的交易决策。具体而言，基于模型的交易策略在多个股票上表现出更好的夏普比率，证明这种代理系统能够显著改进市场风险估计和交易决策。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08621", "html_url": "https://arxiv.org/abs/2507.08621", "title": "基于LLM的论证分类全面研究：从LLAMA到GPT-4o再到Deepseek-R1", "title_en": "A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1", "authors": "Marcin Pietroń,Rafał Olszowski,Jakub Gomułka,Filip Gampel,Andrzej Tomski", "background": "论证挖掘（AM）是一个多学科的研究领域，结合了逻辑、哲学、语言学、修辞学、法律、心理学和计算机科学的见解。这个领域涉及到自动识别和提取论证组件（如前提和主张），以及检测它们之间的关系（如支持、攻击或中立）。近年来，随着大型语言模型（LLMs）的发展，AM领域取得了显著进步，其分析和提取论证语义的效率比传统方法和其他深度学习模型有所提高。虽然有很多用于测试和验证LLMs质量的基准，但在公开可用的论证分类数据库操作方面仍缺乏研究和结果。", "innovation": "本研究使用了包括LLAMA、GPT、Llama和DeepSeek（包括Reasoning-Enhanced版本，如DeepSeek-R1）在内的多种LLMs模型，采用不同的数据集进行测试。研究发现，ChatGPT-4在论证分类基准测试中表现最佳，而整合了推理能力的Deepseek-R1也表现优秀。尽管这些模型表现较好，但仍存在错误。此外，研究还深入分析了可用的论证数据集并指出了其不足之处，同时提到了改进已知提示算法的方向。", "conclusion": "本研究是首个对提及的数据集进行全面分析的更大规模研究，使用LLMs和提示算法展示了这些数据集的不足之处，并指出了提示算法的改进方向。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08594", "html_url": "https://arxiv.org/abs/2507.08594", "title": "通过提示工程生成原型人物：效率、有效性和同理心案例研究", "title_en": "Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy", "authors": "Fernando Ayach,Vitor Lameirão,Raul Leão,Jerfferson Felizardo,Rafael Sobrinho,Vanessa Borges,Patrícia Matsubara,Awdren Fontão", "background": "在产品发现的早期阶段，如精益兴起过程中，原型人物常被用来引导产品定义并促进利益相关者之间的共识。然而，手动创建原型人物通常是耗时、认知需求高且容易产生偏见的过程。本研究旨在通过生成人工智能（GenAI）支持的提示工程技术提出并实证调查一种生成原型人物的方法，以评估该方法在效率、效果、用户接受度以及生成的人物角色所激发的同理心方面的效果。我们通过在实际精益兴起过程中嵌入19名参与者的案例研究，采用定性和定量研究方法来实现这一目标。研究表明，该方法通过减少时间和努力提高了人物角色的质量和再利用性，在后续发现阶段如最小可行产品（MVP）范围设定和功能细化中起到了积极作用。尽管总体接受度较高，特别是在感知有用性和易用性方面，但参与者注意到在泛化和领域特定性方面的局限性。此外，尽管认知同理心得到了强有力的支持，但情感和行为同理心在不同参与者之间差异显著。", "innovation": "本研究提出了利用生成人工智能（GenAI）支持的提示工程技术来自动生成原型人物的方法，并通过实证研究验证了这种方法在产品发现过程中的应用效果和挑战。这项研究为如何有效地将GenAI整合到软件产品发现实践中提供了新的实证证据，并指出了未来此类混合设计过程中的关键挑战。", "conclusion": "研究结果表明，通过提示工程技术生成的原型人物可以提高生成效率和生成人物的质量与再利用性，在产品发现过程中具有积极的应用前景。尽管存在泛化和特定领域的局限性以及情感和行为同理心的个体差异，仍为未来基于提示工程的GenAI在产品发现中的应用提供了新的视角和挑战。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08624", "html_url": "https://arxiv.org/abs/2507.08624", "title": "适配的康复辅助环境中的智能适应性框架", "title_en": "Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance", "authors": "Gábor Baranyi,Zsolt Csibi,Kristian Fenech,Áron Fóthi,Zsófia Gaál,Joul Skaf,András Lőrincz", "background": "本文介绍了 Ambient Intelligence Rehabilitation Support (AIRS) 框架，这是一种专为家庭康复环境设计的基于先进人工智能的解决方案。AIRS 将 Real-Time 3D Reconstruction (RT-3DR) 等前沿技术、智能导航和大型视觉语言模型 (VLMs) 集成在一起，以创建一个全面的机器指导物理康复系统。该研究通过研究膝盖置换手术 (TKR) 后的康复场景，并使用 263 个视频记录进行评估，展示了 AIRS 一般框架的应用。", "innovation": "该创新在于实现了将多种前沿技术集成到康复系统中，提供了一个全面的框架来支持机器指导的物理康复；包括实时 3D 重建、智能导航和视觉语言模型。特别地，智能导航构建了身体匹配的虚拟化身，以优化锻炼配置、解决隐私问题并促进遵守《AI法案》；系统还提供两种反馈机制：视觉3D反馈和基于VLM的反馈，以提供详细的解释和对练习错误的修正，同时也支持视力和听力受损的人群。此外，AIRS 设计模块化，可适应更广泛的康复情境，提供了进一步使用和定制的软件组件。", "conclusion": "本文展示了适用于家庭康复环境中的 AIRS 框架，通过其集成的先进技术提供全面的机器指导康复系统。该系统不仅优化了康复配置并提高了合规性，同时也为视力和听力受损的患者提供了支持，具有模块化设计，可适应更广泛的康复情境，并为用户提供了进一步使用和定制的可能性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08653", "html_url": "https://arxiv.org/abs/2507.08653", "title": "具有峰值年龄信息违规保证的资源分配中的安全深度强化学习", "title_en": "Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees", "authors": "Berire Gunes Reyhan,Sinem Coleri", "background": "在无线网络控制系统(WNCSs)中，控制和通信系统必须协同设计，因为它们之间存在强依赖关系。本文提出了一个基于优化理论的安全深度强化学习(DRL)框架，用于超可靠WNCSs，确保满足约束条件的同时优化性能，这是文献中的首创。", "innovation": "该方法在关键约束条件下（包括峰值年龄信息违规概率、传输功率和有限块长度范围内的可调度性）最小化功率消耗；通过结合随机最大允许传输间隔和最大允许数据包延迟，独特地推导了峰值年龄信息违规概率；框架分为两个阶段：优化理论和安全DRL。", "conclusion": "广泛的仿真实验表明，所提出的框架在基准规则和基于优化理论的DRL基准中表现出色，实现了更快的收敛速度、更高的奖励和更大的稳定性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08648", "html_url": "https://arxiv.org/abs/2507.08648", "title": "DatasetAgent: 一种基于多智能体系统的用于从真实图像自动构建数据集的新方法", "title_en": "DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images", "authors": "Haoran Sun,Haoyu Bian,Shaoning Zeng,Yunbo Rao,Xu Xu,Lin Mei,Jianping Gou", "background": "传统的图像数据集构建过程通常依赖于耗时且低效的手动收集和注释方法。相比之下，真实世界的数据在构建图像数据集时更加有价值，尤其是面对大型模型的数据生成方法。为此，本文探讨了一种新的多智能体系统方法，用于从真实世界图像自动构建高质量数据集，名为DatasetAgent。", "innovation": "DatasetAgent通过协调四个使用多模态语言模型（MLLMs）的不同代理以及图像优化工具包，能够根据用户需求自动构建高质量的图像数据集。通过在多种开源数据集上进行实验（包括扩展现有数据集和从零开始创建数据集），展示了该方法的有效性，并使用由DatasetAgent构建的数据集训练了多种用于图像分类、目标检测和图像分割的视觉模型。", "conclusion": "DatasetAgent能够有效利用多智能体协作机制和先进的人工智能技术，自动构建高质量的图像数据集以满足不同视觉模型的需求，证明了这种方法在实际应用中的可行性和优势。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08636", "html_url": "https://arxiv.org/abs/2507.08636", "title": "规范化标注 vs 誊录标注：乌拉圭出生证明手写信息自动化提取案例研究", "title_en": "Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates", "authors": "Natalia Bottaioli(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France, Facultad de Ingeniería, Universidad de la República, Montevideo, Uruguay, Digital Sense, Montevideo, Uruguay)Solène Tarride(TEKLIA, Paris, France)Jérémy Anger(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Seginus Mowlavi(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Marina Gardella(IMPA, Rio de Janeiro, Brazil)Antoine Tadros(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Gabriele Facciolo(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Rafael Grompone von Gioi(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Christopher Kermorvant(TEKLIA, Paris, France)Jean-Michel Morel(City University of Hong Kong, Hong Kong)Javier Preciozzi(Facultad de Ingeniería, Universidad de la República, Montevideo, Uruguay, Digital Sense, Montevideo, Uruguay)", "background": "该研究评估了最近提出的文档注意力网络（DAN）在提取乌拉圭出生证明中的关键值信息的效果，这些出生证明是用西班牙语手写的。研究探讨了两种标注策略以自动转录手写文档，并对DAN进行微调，同时使用最少的训练数据和标注努力。相关实验在包含相同图像（201张由15名以上不同的书写者撰写的出生证明扫描）的两个数据集上进行，但使用了不同的标注方法。", "innovation": "研究提出了两种标注策略，分别是标准化标注和外交标注。根据实验结果发现，对于可以标准化的字段（如出生日期和出生地点）更有效的是标准化标注；而对于包含人数和姓氏的不能标准化的字段，则外交标注的表现更好。", "conclusion": "该研究通过评估DAN在网络中提取关键信息的能力，表明不同的标注方法对不同类型的字段有不同的效果，标准化标注适合标准化信息字段，而外交标注则适用于不能标准化的信息字段。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08665", "html_url": "https://arxiv.org/abs/2507.08665", "title": "KELPS: 一种通过语义-句法对齐实现多语言自形式化的验证框架", "title_en": "KELPS: A Framework for Verified Multi-Language Autoformalization via Semantic-Syntactic Alignment", "authors": "Jiyao Zhang,Chengli Zhong,Hui Xu,Qige Li,Yi Zhou", "background": "现代大规模语言模型（LLMs）展示了将非正式数学形式化为机器可验证定理的有前景的进步。然而，这些方法仍受有限的多语言平行语料库的数量和质量的限制。", "innovation": "本文提出了一种新的神经符号框架KELPS（基于知识-方程逻辑处理系统），以解决这些问题。KELPS 是一个多步骤框架，用于将非正式数据翻译、综合和过滤成多种正式语言（Lean、Coq 和 Isabelle）。首先，将自然语言翻译为一种新的语言知识方程（KEs），并在断言逻辑中有理论依据。然后，通过严格的规则将其转换为目标语言，保持了语义和语法规则的匹配。", "conclusion": "在 MiniF2F 数据集上，本文框架在句法准确性（pass@1）方面达到了 88.9% 的成绩，超过了 SOTA 模型 Deepseek-V3（81%）和 Herald（81.3%），所有数据集和代码均可在补充材料中找到。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08721", "html_url": "https://arxiv.org/abs/2507.08721", "title": "在测试时适应中的风险监控", "title_en": "Monitoring Risks in Test-Time Adaptation", "authors": "Mona Schirmer,Metod Jazbec,Christian A. Naesseth,Eric Nalisnick", "background": "在部署预测模型时遇到转移数据（即测试时间的数据发生了转移），是普遍面临的挑战。测试时适应（TTA）方法可以通过仅使用未标记的测试数据连续适应已部署的模型来解决这一问题。虽然TTA可以延长模型的使用寿命，但它只能作为临时解决方案，最终模型可能因性能下降而需要下线重新训练。", "innovation": "本文提出将风险监控框架与TTA结合使用，以检测TTA模型的最终失败点。具体而言，通过扩展基于序列测试和可信区间的风险监控工具，以适应测试中模型更新且无测试标签的情况。这种方式解锁了对TTA应用严格的统计风险监控，并在多种数据集、不同转移类型和TTA方法上验证了所提TTA监控框架的有效性。", "conclusion": "研究表明，所提出的监控框架能够有效检测TTA过程中的最终失败点，并在多种场景下证明了其有效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08701", "html_url": "https://arxiv.org/abs/2507.08701", "title": "为独立居住的老年人在其家中日常生活活动监测提供个性化形式验证框架", "title_en": "A Personalised Formal Verification Framework for Monitoring Activities of Daily Living of Older Adults Living Independently in Their Homes", "authors": "Ricardo Contreras,Filip Smola,Nuša Farič,Jiawei Zheng,Jane Hillston,Jacques D. Fleuriot", "background": "当前，独立居住的老年人口数量在不断增加，为他们提供高质量的生活成为当务之急。个人化解决方案着眼于个体的需求和偏好，综合考虑了情境因素。基于此背景，本文介绍了一种用于独立居住的老年人在其家中进行日常生活活动监测的个性化形式验证框架。", "innovation": "该框架通过集成传感器数据和情景信息（包括半结构化访谈、家庭布局和社会学观察），创建了个性化的正式模型。基于线性时序逻辑编码的个体特定需求，使用模型检查器验证模型是否满足这些需求，并通过生成反例来找出需求未得到满足的原因。", "conclusion": "本文通过将此框架应用于不同的参与者，展示了其普遍适用性，并强调了其在提升老年人在地老化安全与福祉方面的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08617", "html_url": "https://arxiv.org/abs/2507.08617", "title": "在不平衡协变量偏移下联邦学习中的协作公平性", "title_en": "Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift", "authors": "Tianrun Yu,Jiaqi Wang,Haoyu Wang,Mingquan Lin,Han Liu,Nelson S. Yee,Fenglong Ma", "background": "协作公平性是联邦学习中的一个关键挑战，但现有方法通常忽略了实务上的复杂异质性形式——不平衡的协变量偏移。已有研究缺乏对这一问题的深入分析，使得在面对高度异质性数据分布时难以兼顾准确预测和协作公平性之间的平衡。因此，理论分析这一背景下的问题十分重要，以指导设计一个有效的方法来平衡准确预测与协作公平性。", "innovation": "本文提出了FedAKD（联邦异步知识蒸馏）——一种简单而有效的方法，该方法结合了传统知识蒸馏和基于高置信度正确预测样本的全局模型更新策略，以平衡准确预测和协作公平性。通过分析不同预测样本的特征分布差异，作者设计了一种新的异步知识蒸馏策略，该策略充分利用了正确预测样本和错误预测样本在特征分布上的差异。此外，还提供了FedAKD收敛性的理论证明。", "conclusion": "在公开数据集（FashionMNIST和CIFAR10）和真实的电子健康记录数据集上的实验结果显示，FedAKD显著提高了协作公平性，提高了预测准确率，并在高度异质性数据分布下促进了客户端的参与。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08702", "html_url": "https://arxiv.org/abs/2507.08702", "title": "洋葱：一种多层次的参与式ER设计框架", "title_en": "ONION: A Multi-Layered Framework for Participatory ER Design", "authors": "Viktoriia Makovska,George Fletcher,Julia Stoyanovich", "background": "本文提出了ONION框架，该框架是一个多层次的实体-关系（ER）建模框架，结合了设计正义、参与式人工智能和概念建模的见解。该框架旨在减少设计偏见，促进包容性的参与，并增加建模过程的透明度。", "innovation": "ONION引入了一个五阶段的方法论：观察、培育、整合、优化和规范化。它支持从无结构的利益相关者输入逐步抽象到规范化ER图。这种方法有助于在早期数据建模阶段包容多样性的利益相关者参与。", "conclusion": "通过在乌克兰的实地研讨会中对社会组织和技术系统进行评估，本文展示了ONION在早期数据建模阶段能促进多元利益相关者参与的潜力。最终，本文总结了所学经验，并讨论了将框架更广泛地采用时所面临的挑战和局限性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代可配置软件系统需要学习将配置与性能关联的模型。然而，在动态环境中，工作负载变化、硬件更改和系统更新会不可避免地在不同水平上引入概念漂移，包括全局漂移和局部漂移。现有的离线和迁移学习方法难以在实时动态环境中适应这些隐性和不可预测的变化，导致配置性能学习具有挑战性。因此，需要一个能有效捕捉并适应不同水平漂移的在线学习框架，以提高系统性能和配置效率。", "innovation": "本文提出了一种名为DHDA的双层级漂移适应框架，该框架旨在通过双层级适应机制来解决这一问题。具体来说，DHDA在高层级上重新划分数据，根据需要仅处理全局漂移，在低层级上局部模型可以检测并异步适应局部漂移。此外，DHDA结合增量更新与周期性完整的重训练，以减少未检测到漂移时的冗余计算。这种策略在提高系统准确性和适应漂移的能力上实现了显著改进。", "conclusion": "通过评估8个软件系统并与最先进的方法进行比较，研究结果表明，DHDA不仅提高了显著的性能准确性，而且能够以不超过两倍的改进适应漂移。尽管存在合理的开销，但DHDA仍然能够有效提升不同局部模型在处理概念漂移时的能力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08683", "html_url": "https://arxiv.org/abs/2507.08683", "title": "MoSAiC: 多模式多标签监督感知对比学习在遥感中的应用", "title_en": "MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing", "authors": "Debashis Gupta,Aditi Golder,Rongkhun Zhu,Kangning Cui,Wei Tang,Fan Yang,Ovidiu Csillik,Sarra Alaqahtani,V. Paul Pauca", "background": "对比学习（CL）已经成为了无需依赖大规模标记数据集学习可转移表示的强大范式。CL 的能力在于捕捉数据样本之间的内在相似性和差异性，在计算机视觉任务中取得了最先进的结果。这种优势使得 CL 特别适合地球系统观测（ESO），因为卫星图像等多模式数据提供了同一地理区域的自然对齐视图。然而，ESO 呈现出独特的挑战，包括高类间相似性、场景杂乱和模糊边界，这使代表学习，特别是在低标签、多标签设置中，变得复杂化。现有的 CL 框架往往专注于模内自监督，或者缺乏跨模态多标签对齐和语义精度的机制。", "innovation": "我们提出了 MoSAiC，这是一种统一框架，联合优化模内和模间对比学习，并采用多标签监督对比损失。MoSAiC 特别设计用于多模卫星图像，能够更精细地分离语义，实现更稳健的代表学习，特别是在光谱相似和空间复杂类别中。实验表明，MoSAiC 在 BigEarthNet V2.0 和 Sent12MS 两个基准数据集上，在准确率、簇的凝聚性和泛化能力方面，明显优于完全监督和自监督基线，特别是在低标签和高类别重叠场景中表现更好。", "conclusion": "实验结果表明，MoSAiC 在 BigEarthNet V2.0 和 Sent12MS 两个基准数据集上，在低标签和高类别重叠场景中，准确率、簇的凝聚性和泛化能力方面，都优于完全监督和自监督基线。此框架展示了 MoSAiC 在地球系统观测中的适用性和优越性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08761", "html_url": "https://arxiv.org/abs/2507.08761", "title": "利用离线数据的强化学习中惩罚不可行操作和奖励缩放", "title_en": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data", "authors": "Jeonghye Kim,Yongjae Shin,Whiyoung Jung,Sunghoon Hong,Deunsol Yoon,Youngchul Sung,Kanghoon Lee,Woohyung Lim", "background": "利用离线数据的强化学习在处理泛化错误，尤其是Q值外推错误方面存在挑战。", "innovation": "提出了一个名为PARS的新算法，它结合了奖励缩放与层归一化（RS-LN）以及针对不可行操作的惩罚机制（PA），以解决离线数据中的Q值外推错误。", "conclusion": "PARS算法在D4RL基准测试中表现出色，无论是离线训练还是在线微调，尤其在AntMaze Ultra等高难度任务中取得了显著成功。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08738", "html_url": "https://arxiv.org/abs/2507.08738", "title": "自适应非线性向量自回归：噪声混沌时间序列的稳健预测", "title_en": "Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series", "authors": "Azimov Sherkhon,Susana Lopez-Moreno,Eric Dolores-Cuenca,Sieun Lee,Sangil Kim", "background": "非线性向量自回归（NVAR）和水槽计算（RC）在混沌动力系统（如洛伦兹-63模型和厄尔尼诺-南方涛动）的预测方面表现出潜力，但它们依赖于固定非线性——NVAR中的多项式展开或RC中的随机特征映射，这限制了它们对高噪声或真实世界数据的适应性。此外，这些方法在高维设置中的计算效率较低，因为读出计算中需要昂贵的矩阵求逆。", "innovation": "提出了一种自适应NVAR模型，结合延迟嵌入的线性输入和由浅层可学习多层感知器（MLP）生成的特征。MLP和线性读出通过梯度优化联合训练，以使模型学习数据驱动的非线性关系，同时保留简单的读出结构。与标准NVAR不同，该方法避免了对岭参数和延迟参数进行详尽且敏感的网格搜索的需求，而是限制在神经网络的超参数调优，从而提升了易用性。", "conclusion": "初始实验表明，自适应模型在无噪声和合成噪声条件下都优于标准NVAR，在预测准确性上表现更优，并且在低观测频率下仍能稳健地进行噪声条件下的预测。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08736", "html_url": "https://arxiv.org/abs/2507.08736", "title": "通过 Plateau 时期活动特征分析减轻灾难性遗忘", "title_en": "Catastrophic Forgetting Mitigation Through Plateau Phase Activity Profiling", "authors": "Idan Mashiach,Oren Glickman,Tom Tirer", "background": "灾难性遗忘是指深度神经网络在学习新任务时，会导致之前学习任务表现下降的现象，这是由于新知识覆盖了旧知识。现有方法通过正则化技术来识别并限制重要参数以保持先前知识不被覆盖。但是，在深度学习高度非凸的优化景观中，本文提出了一种新观点，即在最终训练平台期监控参数比在整个训练过程中监控更有效。研究表明，平台期表现出更高活动性（移动性和变化性）的参数揭示了相对平坦的损失景观方向，这些参数适合适应新任务同时保持之前的知识。", "innovation": "提出了一种新的缓解灾难性遗忘的方法，即在深度学习的最终训练平台期监控参数的活动性，而不是在整个训练过程中持续监控。这种方法能够更有效地识别并保留关键参数，使得网络在学习新任务时能够减轻对以前任务知识的负面影响。", "conclusion": "该方法在减轻灾难性遗忘的同时，提升了新任务的学习性能，实验结果证明了其在平衡灾难性遗忘缓解与新任务学习性能优化方面的优越性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08793", "html_url": "https://arxiv.org/abs/2507.08793", "title": "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning", "title_en": "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning", "authors": "James McCarthy,Radu Marinescu,Elizabeth Daly,Ivana Dusparic", "background": "风险规避型约束强化学习（RaCRL）的目标是学习尽量减少由环境固有随机性导致的稀有且灾难性的约束违规的策略。通常情况下，风险规避会导致保守地探索环境，这往往导致收敛于次优策略，这些策略无法充分最大化奖励，甚至在某些情况下未能实现目标。现有的RaCRL方法往往不能在鼓励探索不确定区域以发现高回报状态和满足安全约束之间取得良好的权衡。因此，如何设计有效的探索策略是研究的重点。", "innovation": "本文提出了一种探索导向的RaCRL方法，称为乐观风险规避演员评论员（ORAC），它通过最大化状态-动作奖励值函数的局部上限置信边界并最小化风险规避状态-动作成本值函数的局部下限置信边界来构建探索性策略。具体而言，在每一步中，如果成本值超过或低于安全约束值，则增加或减少对其的权重。这样，策略被鼓励探索环境中的不确定区域以发现高回报状态，同时仍满足安全约束。这有助于防止收敛于次优策略，并在各种连续控制任务中大大提高了奖励与成本之间的权衡。", "conclusion": "实验结果表明，ORAC方法可以防止收敛于次优策略，并在诸如Safety-Gymnasium和复杂的城市能源管理环境CityLearn等连续控制任务中显著提高了奖励与成本之间的权衡。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08801", "html_url": "https://arxiv.org/abs/2507.08801", "title": "Lumos-1：从统一模型视角看自回归视频生成", "title_en": "Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective", "authors": "Hangjie Yuan,Weihua Chen,Jun Cen,Hu Yu,Jingyun Liang,Shuning Chang,Zhihui Lin,Tao Feng,Pengwei Liu,Jiazheng Xing,Hao Luo,Jiasheng Tang,Fan Wang,Yi Yang", "background": "自回归大规模语言模型（LLMs）已经统一了广泛的自然语言任务，并启发了初步的自回归视频生成尝试。现有的自回归视频生成器要么脱离标准LLM架构，要么依赖于庞大的外部文本编码器，或者由于逐token解码而导致收敛延迟过长。", "innovation": "Lumos-1是一个保留了LLM架构的自回归视频生成器，仅进行了少量的架构修改。通过提出MM-RoPE频谱方案和Autoregressive Discrete Diffusion Forcing (AR-DF)机制，Lumos-1解决了空间信息冗余导致的帧间损失不平衡问题，并成功在较少的48张GPU上实现了与现有模型相近的性能。", "conclusion": "Lumos-1利用精简的训练技术，在48张GPU上预训练，达到了与现有的EMU3、COSMOS-Video2World和OpenSoraPlan等模型相当的生成效果，代码和模型开源可用。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08719", "html_url": "https://arxiv.org/abs/2507.08719", "title": "多模态多语言软件开发人员进行代码生成", "title_en": "Multilingual Multimodal Software Developer for Code Generation", "authors": "Linzheng Chai,Jian Yang,Shukai Liu,Wei Zhang,Liran Wang,Ke Jin,Tao Sun,Congnan Liu,Chenchen Zhang,Hualei Zhu,Jiaheng Liu,Xianjie Wu,Ge Zhang,Tianyu Liu,Zhoujun Li", "background": "随着大型语言模型（LLMs）的迅速发展，代码生成的准确性得到了显著提升，然而，大多数现有模型仍局限于文本，未能有效利用如统一建模语言（UML）图和流程图等关键的视觉辅助工具，这些视觉工具在实际软件开发中至关重要。为解决这一问题，本文提出了MM-Coder，这是一种多模态多语言软件开发人员，能够整合视觉设计输入（UML图和流程图，统称为视觉工作流）与文本指令，以提高代码生成的准确性和架构对齐度。", "innovation": "为实现上述目标，作者开发了MMc-Instruct，这是一个包含基于视觉工作流的代码生成的多样化的多模式指令调整数据集，使MM-Coder能够像人类开发者一样综合处理文本和图形信息，区别于专注于狭窄任务的先前工作。此外，作者还引入了MMEval，这是一个新的多模态代码生成基准，旨在评估当前文本为主的模型在精确视觉信息捕捉、指令遵循和高级编程知识等方面的不足。", "conclusion": "作者通过MMEval对MM-Coder进行了评估，结果显示模型在精确视觉信息捕捉、指令遵循和高级编程知识方面仍有显著挑战。本研究旨在通过使LLMs能够理解和实现通过文本和视觉设计传达的复杂规范，革新工业编程。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08800", "html_url": "https://arxiv.org/abs/2507.08800", "title": "NeuralOS：通过神经生成模型模拟操作系统", "title_en": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models", "authors": "Luke Rivard,Sun Sun,Hongyu Guo,Wenhu Chen,Yuntian Deng", "background": "介绍了NeuralOS，一种通过直接预测屏幕帧来模拟操作系统图形用户界面（GUI）的神经框架，响应用户的输入，如鼠标移动、点击和键盘事件。背景在于现有技术需要手动编写代码来模拟操作系统的GUI，此研究试图通过神经网络实现自动化模拟，解决了传统方法的繁琐和复杂性问题，提高了模拟的效率和准确性。", "innovation": "NeuralOS结合了循环神经网络（RNN）来追踪计算状态，以及基于扩散的神经渲染器来生成屏幕图像。它通过大规模记录Ubuntu XFCE的交互数据集进行训练，包括随机生成的和由AI代理生成的交互。实验表明，NeuralOS能够成功渲染真实感GUI序列，准确捕捉鼠标交互，可靠地预测如应用启动等状态转换。尽管精确建模细粒度的键盘交互仍然具有挑战性，但NeuralOS正朝向着未来人机交互系统中创建自适应、生成性神经界面迈出一步。", "conclusion": "NeuralOS通过神经网络技术自动化模拟操作系统GUI，展示了训练后的模型能够生成真实的GUI序列，准确捕捉鼠标交互，并可靠地预测应用启动等状态转换。尽管细粒度键盘交互的建模仍具挑战性，该框架为未来人机交互系统的应用提供了新的可能性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08799", "html_url": "https://arxiv.org/abs/2507.08799", "title": "KV 缓存引导在小型语言模型中引发推理", "title_en": "KV Cache Steering for Inducing Reasoning in Small Language Models", "authors": "Max Belitsky,Dawid J. Kopiczko,Michael Dorkenwald,M. Jehanzeb Mirza,Cees G. M. Snoek,Yuki M. Asano", "background": "该研究提出了缓存引导方法，这是一种通过直接干预键值缓存来实现语言模型隐式控制的轻量级方法。为了验证其有效性，研究者将缓存引导应用到小型语言模型中，以诱导这些模型进行链式思考推理。研究通过利用GPT-4o生成的推理轨迹来构建引导矢量，以使模型行为更倾向于更明确的多步骤推理，而不进行微调或提示修改。实验结果表明，缓存引导方法能提高模型推理的质构和任务性能。现有的激活引导技术需要连续干预，而缓存引导仅需一次干预，从而在超参数稳定性、推理时效率和集成便利性方面具有显著优势，使其成为更稳定和实用的受控生成解决方案。", "innovation": "该研究提出的缓存引导方法是一种轻量级的、一次性的干预手段，它直接作用于语言模型的关键值缓存，无需微调或修改提示，利用GPT-4o生成的推理轨迹来引导模型进行更加明确的多步骤推理。与需要连续干预的激活引导技术相比，缓存引导方法在超参数稳定性、推理时效率和集成便利性等方面具有明显优势，是一种更稳定和实用的受控生成解决方案。", "conclusion": "实验评估结果表明，缓存引导能显著提高模型推理的结构质量和任务性能。相较于需要持续干预的激活引导技术，缓存引导提供了一种更为稳定和易于集成的解决方案，增强了模型的可控生成能力，适用于多种推理任务。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08704", "html_url": "https://arxiv.org/abs/2507.08704", "title": "KG-Attention: Test-Time 知识图谱引导注意力通过双向信息聚合", "title_en": "KG-Attention: Knowledge Graph-Guided Attention at Test-Time via Bidirectional Information Aggregation", "authors": "Songlin Zhai,Guilin Qi,Yuan Meng", "background": "知识图谱（KGs）在提升大型语言模型（LLMs）方面扮演着关键角色，通过引入结构化和落地的知识来增强模型的表现。然而，现有的大多数KG增强方法依赖于参数密集型微调，这可能导致灾难性遗忘并削弱模型的泛化能力。此外，它们在实时知识更新方面表现出有限的适应性，因为它们的静态整合框架缺乏灵活性。", "innovation": "为了应对这些问题，作者提出了第一个基于预测时知识图谱增强框架的LLMs，围绕一个专门的知识图谱引导注意力（KGA）模块构建，该模块允许在不进行任何参数更新的情况下动态地进行知识融合。KGA模块通过添加两个协同的路径——外向聚合并内向聚合——增强了标准的自我注意力机制。具体来说，外向路径通过基于输入的知识图谱融合动态地将外部知识整合到输入表示中。内向聚合则通过知识图谱引导的筛选，补充和完善外向路径，通过过滤任务无关信号和放大知识相关模式来细化输入表示。相比之下，外向路径处理知识融合过程，而内向路径则选择最相关的三元组并将其反馈回融合过程，形成一个闭环增强机制。通过这两个路径的协同结合，所提出的方法只在预测时进行实时知识融合，而无需任何参数修改。", "conclusion": "广泛在五个基准上的实验证明了KGA在知识融合性能上达到了可比的结果。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08766", "html_url": "https://arxiv.org/abs/2507.08766", "title": "一种带有特征提取和K均值的多槽Hopfield-CNN混合模型用于MNIST分类", "title_en": "A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification", "authors": "Ahmed Farooq", "background": "该研究提出了一种将卷积神经网络（CNN）与多槽霍普菲尔德网络结合的混合模型，用于MNIST数据集的手写数字分类。研究背景是在图像分类任务中，手写数字的个体差异较大，如书写风格的多样性。传统方法可能难以处理这些问题，因此需要一种能有效处理这些差异并且具有解释性的模型。", "innovation": "该模型的创新点是利用CNN提取高维特征，再使用k-means聚类生成特定类别的原型，这些原型作为能量景观的吸引子，霍普菲尔德网络通过最小化平衡特征相似性和类别的能量函数来进行分类。这种模型设计可以有效处理类内变异性，同时通过基于能量的决策过程提供一种可解释的框架。通过优化CNN架构和槽的数量，模型在10,000张MNIST图像上实现了99.2%的测试准确率，展示了其在图像分类任务中的有效性。", "conclusion": "研究结果显示，深度特征提取和充足的原型覆盖是实现高性能的关键因素，该模型具有潜在的广泛应用前景，尤其是在模式识别领域。实验结果证明了该模型的有效性和高效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08743", "html_url": "https://arxiv.org/abs/2507.08743", "title": "Geo-ORBIT：一种用于场景自适应车道几何检测的联邦数字孪生框架", "title_en": "Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection", "authors": "Rei Tamaru,Pei Li,Bin Ran", "background": "数字孪生(DT)有潜力通过创建交通系统的动态虚拟表示来改善交通管理和运营，这些表示可以感知条件、分析运营并支持决策。道路几何动态传感是交通系统数字孪生的关键组成部分。然而，现有方法通常依赖于静态地图或昂贵的传感器来感知道路信息，这限制了DT的可扩展性和适应性。并且，在从多个来源收集和分析数据的大规模DT中，还面临着隐私、通信和计算效率等挑战。", "innovation": "我们提出了Geo-ORBIT（Geometrical Operational Roadway Blueprint with Integrated Twin），它是一种结合了实时车道检测、DT同步和联邦元学习的一体化框架。Geo-ORBIT的核心是GeoLane，一种基于车辆轨迹数据和路边摄像头学习车道几何的轻量级车道检测模型。此外，我们通过Meta-GeoLane扩展了GeoLane，使其能够个性化检测参数以适应局部实体，而FedMeta-GeoLane则是确保跨路边部署可扩展和隐私保护适应性的联邦学习策略。我们的框架结合了CARLA和SUMO创建了一个高保真DT，该DT能够实时生成高速公路场景并捕捉交通流动。", "conclusion": "通过广泛实验，我们发现FedMeta-GeoLane在在多种城市场景下表现优于基线和其他元学习方法，具有更低的几何误差和更好的泛化能力，同时显著降低通信开销。此工作的贡献奠定了DT中灵活、情境感知基础设施建模的基础。框架已在公共平台对外开放。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.17642", "html_url": "https://arxiv.org/abs/2409.17642", "title": "具有双重重点的AI代理：确保隐私与战略性自我披露", "title_en": "AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure", "authors": "Zhiyang Zhang,Xi Chen,Fangkai Yang,Xiaoting Qin,Chao Du,Xi Cheng,Hangxin Liu,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang", "background": "大型语言模型（LLM）基于的AI代理越来越多地被用户用于代理执行任务，通过对话界面协助用户完成各种任务。虽然AI代理具有优势，但人们对其可能泄露隐私的风险表示关注，尤其是在涉及社会互动的情况下。现有研究主要集中在通过限制AI代理访问敏感用户信息来保护隐私，但在许多社交场景中，为了实现社交目标必须披露私密信息，这就需要在隐私保护与信息披露之间寻找平衡。", "innovation": "该研究首先开展了一项试点研究，探讨AI代理在不同社会关系和任务场景下的用户感知，然后提出了一个新的AI代理系统，该系统允许用户进行隐私意识下的自我披露。通过用户研究证明，提出的AI代理能够有策略地保护隐私，在多种多变的社会互动中使用该系统。", "conclusion": "研究结果显示，提出的AI代理系统在社交互动中能够战略性地保护隐私，为多样化的社会场景提供了新的技术支持。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01163", "html_url": "https://arxiv.org/abs/2503.01163", "title": "基于bandit算法的提示设计策略选择提升提示优化器", "title_en": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers", "authors": "Rin Ashizawa,Yoichi Hirose,Nozomu Yoshinari,Kento Uchida,Shinichi Shirakawa", "background": "目标优化旨在寻找能够提升大型语言模型（LLMs）性能的有效提示。尽管现有的提示优化方法已经发现了有效的提示，但这些提示往往与人类专家精心设计的复杂提示有所不同。提示设计策略被认为是提高提示性能的最佳实践，可以对提示优化产生关键影响。最近，一种名为自主提示工程技术工具箱（APET）的方法已经将多种提示设计策略纳入了提示优化过程。然而，这种方法依赖于LLM隐式选择和应用提示设计策略，这可能导致亚最优的结果，因为LLM的优化能力有限。因此，论文介绍了一种名为OPTS的新方法，该方法实施了明确的选择机制以选择提示设计策略，并将其集成到EvoPrompt这一知名提示优化器中。实验结果表明，选择提示设计策略能够提高EvoPrompt的性能，而基于Thompson采样的机制获得了最佳的整体结果。", "innovation": "提出了名为OPTS的新方法，该方法实施了明确的选择机制以选择提示设计策略，并将其集成到EvoPrompt这一知名提示优化器中。OPTS采用了Thompson采样等机制，能够明确地从多种提示设计策略中选择最有用的策略，从而提高了EvoPrompt的整体性能。", "conclusion": "选择恰当的提示设计策略可以显著提高提示优化器的性能。通过采用OPTS方法中的Thompson采样机制，实验结果表明EvoPrompt能够实现最佳的整体性能。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.07531", "html_url": "https://arxiv.org/abs/2504.07531", "title": "AI领域中的证词不公分类以及生成性诠释抹除案例", "title_en": "A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure", "authors": "Warmhold Jan Thomas Mollema", "background": "AI相关的证词不公正成为一个日益增长的关切。AI模型中的证词不公正有多种来源，包括认知透明度不足、基于证词偏见的歧视自动化、幻觉带来的信念扭曲、全球南方在全球AI治理中的排斥、算法系统中的官僚暴力以及与会话人工智能代理的互动。", "innovation": "本文提出了AI领域中证词不公的分类，并提出了一种新的形式——生成性诠释抹除。这种不公正指的是由大规模语言模型（LLMs）通过消除认识论和概念化的差异所造成的‘知识灭绝’自动化，AI系统眼中不存在差异的‘无所不包’认知论使非西方认知论处于认知劣势，并逐渐导致诠释抹除。", "conclusion": "本文提出了一种分类法，用于在AI领域映射证词不公正，并提出了一种人工智能相关的新型证词不公正形式——生成性诠释抹除，强调其对非西方认知论的影响。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00557", "html_url": "https://arxiv.org/abs/2507.00557", "title": "一种结合二维细胞跳跃局部搜索、MCSAT和OpenCAD的SMT-NRA求解器", "title_en": "A Hybrid SMT-NRA Solver: Integrating 2D Cell-Jump-Based Local Search, MCSAT and OpenCAD", "authors": "Tianyi Ding,Haokun Li,Xinpeng Ni,Bican Xia,Tianqi Zhao", "background": "本文提出了一种用于非线性实数理论的可满足性模理论（SMT-NRA）的混合框架。首先介绍了二维细胞跳跃操作，称为2d-细胞跳跃，将其用于SMT-NRA的局部搜索方法的关键操作。然后提出了一种扩展的局部搜索框架，称为2d-LS，将其与模型构建可满足性推理框架（MCSAT）结合以提高搜索效率。", "innovation": "引入了2d-细胞跳跃操作，提出了一种新的局部搜索框架2d-LS，并实现了一种样本细胞投影操作以进一步提高MCSAT的效率。最后，该论文提供了一种混合框架，结合了MCSAT、2d-LS和OpenCAD，通过信息交换提升搜索效率。", "conclusion": "实验结果表明，局部搜索性能有所提高，证明了所提方法的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08637", "html_url": "https://arxiv.org/abs/2507.08637", "title": "通过波形增强随机频谱注意力（WERSA）实现线性时间内非常长序列的注意力扩展", "title_en": "Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA)", "authors": "Vincenzo Dentamaro", "background": "常规注意力机制在处理长序列时计算成本高，因为其时间复杂度为二次阶 O(n^2)。这对于许多应用场景如视觉、自然语言处理（NLP）和层次推理是一个重要的限制。现有的一些改进，如多头注意力、Flash-Attention-2、FNet、Linformer、Performer 和 Waveformer，未能有效解决这一问题，特别是在处理极度长的序列时更容易出现内存不足的问题。因此，开发出一种既能保持线性效率又能成功处理长序列的方法成为解决这一问题的关键.", "innovation": "提出了一种新颖的机制——波形增强随机频谱注意力（WERSA），它结合了内容自适应随机频谱特征和多分辨率 Haar 波let，并通过可学习参数进行选择性关注，从而在保持线性效率的同时，专注于数据中的重要尺度。WERSA 在大规模比较实验中展示了统一的优势，尤其是在 ArXiv 分类任务中，相对于标准注意力，它提高了 1.2% 的准确率，并将训练时间缩短了 81%，FLOPS 减少了 73.4%。更为重要的是，WERSA 在处理 FlashAttention-2 失效的极端长序列时表现出色，不仅在准确性和 AUC 指标上达到了最佳表现，还在计算速度上提升了两倍，成为最有效的竞争方法之一.", "conclusion": "WERSA 的创新之处在于其通过结合内容自适应随机频谱特性和多分辨率 Haar 波let，实现了长序列处理的线性效率和高准确性。它在多个基准测试中表现优异，尤其是对于标准注意力和 FlashAttention-2 失效的极端长序列，WERSA 提供了显著的改进，使得长上下文模型更加实用、经济，特别适合低资源硬件，推动了可持续和规模化的人工智能发展。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07257", "html_url": "https://arxiv.org/abs/2507.07257", "title": "开源规划与控制语言代理系统实现自主科学研究", "title_en": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery", "authors": "Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekioui,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet", "background": "本文介绍了一个用于自动化科学研究任务的多代理系统cmbagent。该系统由约30个大型语言模型（LLM）代理组成，采用计划与控制策略协调代理工作流，没有出现任何人工干预。每个代理专注于不同的任务（如科学文献和代码库的检索、编写代码、解释结果以及评估其他代理的输出），并且系统能够在本地执行代码。", "innovation": "该系统创新地采用规划与控制策略来协调多代理工作流，并且所有过程自动化，无需人工干预。系统中的每个代理都专门化于不同的任务，能够成功地执行复杂的科研任务，如使用超新星数据测量宇宙参数。系统的性能优于最先进的大语言模型。此外，系统的源代码在GitHub上公开，演示视频也已提供，且系统已部署在HuggingFace并可云访问。", "conclusion": "本研究展示了cmbagent在执行博士级别的宇宙学任务（利用超新星数据进行宇宙参数的测量）上的成功应用，并通过两个基准测试集评估了其性能，发现其表现优于最先进的大语言模型。这一系统为自主科学研究提供了一个强大的工具。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03190", "html_url": "https://arxiv.org/abs/2507.03190", "title": "使用计算语言处理发现算法", "title_en": "Discovering Algorithms with Computational Language Processing", "authors": "Theo Bourdais,Abeynaya Gnanasekaran,Houman Owhadi,Tuhin Sahai", "background": "算法是实现可复现实验性问题解决的关键。文章提出了一个自动化算法发现框架，将算法视为操作序列的集合，这些操作由计算语言表示为令牌。通过一种语法将这些令牌连接起来，形成越来越复杂的过程。该框架使用蒙特卡洛树搜索（MCTS）指导强化学习（RL），探索令牌连接并驱动新的令牌生成。这种方法重新发现、改进并生成新的算法，这些算法在强NP困难组合优化问题和基础量子计算方法（如Grover算法和量子近似优化算法）方面显著优于现有方法。与代码生成层面不同，该框架产生的算法能够根据具体的问题实例进行定制，而不仅仅是对问题类的处理。", "innovation": "该研究提出了一种自动化发现新的算法的框架，通过计算语言处理，将算法视为令牌序列，并使用MCTS和RL来探索令牌间的连接。这种新方法能够重新发现、改进并生成新的算法，特别在强NP难题和量子计算方面表现出显著优势。", "conclusion": "通过该自动化算法发现框架，可以产生专门针对特定问题实例的算法，而不是只是针对问题类。这种新方法显著提升了算法在解决强NP难题和量子计算问题中的性能。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.08054", "html_url": "https://arxiv.org/abs/2408.08054", "title": "Text2BIM：基于大型语言模型的多代理框架生成建筑设计模型", "title_en": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "authors": "Changyu Du,Sebastian Esser,Stavros Nousias,André Borrmann", "background": "传统的BIM（建筑信息模型）设计过程要求设计师掌握复杂且繁琐的建模命令，才能在BIM建模工具中表达自己的设计意图。这种额外的认知负担使得设计过程复杂化，并阻碍了BIM和基于模型的设计在建筑、工程和施工（AEC）行业的广泛应用。为了使设计师更直观地表达设计理念，本文提出了一种基于LLM（大型语言模型）的多代理框架——Text2BIM，该框架可以从自然语言指令生成3D建筑模型。这一框架通过调度多个LLM代理协作推理，将文本用户输入转换成调用BIM建模工具API的指令代码，从而直接在软件中生成具有内部布局、外部围护结构和语义信息的可编辑BIM模型。此外，在多代理工作流中还引入了基于规则的模型检查器，利用预定义的专业知识指导LLM代理解决生成模型中的问题，实现模型质量的逐步提升。", "innovation": "本文提出了一种基于LLM的多代理框架——Text2BIM，该框架能够从自然语言指令生成3D建筑模型，克服了传统BIM设计中所需的复杂建模命令的问题。此外，引入了基于规则的模型检查器，指导LLM代理解决生成模型中的问题，从而逐步提升模型质量。通过比较和分析三种不同LLM的表现，结果表明，这种方法能够有效地生成与用户输入的抽象概念相一致的高质量、结构合理的设计模型。", "conclusion": "实验结果显示，Text2BIM能够有效地生成高质量的、结构合理的设计模型，这些模型能够与使用者输入的概念相匹配。最终，开发了一个交互式的软件原型，并将其集成到BIM建模软件Vectorworks中，展示了通过聊天进行建模的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2209.01619", "html_url": "https://arxiv.org/abs/2209.01619", "title": "将系统视为解决POMDPs：走向对自体性形式理解的一步", "title_en": "Interpreting systems as solving POMDPs: a step towards a formal understanding of agency", "authors": "Martin Biehl,Nathaniel Virgo", "background": "该研究探讨了什么情况下可以认为一个系统拥有信念和目标，并探讨了这些与系统物理状态的关系。之前的工作提出了一个解释映射的概念，即将系统状态映射到表示其对外部世界信念的概率分布的功能。然而，这样的映射并非任意的，因为系统所拥有的信念必须随着时间的一致演化来符合贝叶斯定理，因此系统的动力学在其可能的解释中起到了限制作用。", "innovation": "这篇论文提出了一个关于信念和目标的解释，而不仅仅是信念。作者使用部分可观测马尔可夫过程（POMDPs）理论，表明如果一个系统不仅能够描述基于POMDP隐藏状态的解释映射，还能够采取根据其信念状态的最佳行动，那么这个系统可以被认为是一个POMDP解决问题的实例。因此，一个代理就是一个系统连同对其作为POMDP解决方案的解释。", "conclusion": "虽然POMDPs不是表示具有目标的唯一可能形式，但这种方法代表了一种更广泛的形式主义定义，即一个系统作为代理的意义。这代表了对自体性形式理解的一个重要步骤。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07445", "html_url": "https://arxiv.org/abs/2507.07445", "title": "StarDojo：基于《 Stardew Valley 》的生产生活模拟中代理多模态大语言模型开放行为基准测试", "title_en": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley", "authors": "Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An", "background": "现有的基准测试很少同时评估自主代理在生产活动和社交互动方面的技能，因此需要构建新的评估基准以全面衡量这些技能。为此，StarDojo 应运而生，它是一个基于《Starfall Valley》的新型基准，用于评估 AI 代理在开放性生产生活模拟中的表现。", "innovation": "提出了StarDojo，这是一个基于《Stardew Valley》的新基准，用于评估AI代理在开放性生产生活模拟中的表现。该基准包含五个关键领域的一千个精心策划的任务，并提供了一组代表性的任务用于模型评估。StarDojo 支持多个环境实例的并行执行，并利用了用户友好的界面和强大功能，特别适合评估由多模态大语言模型（MLLMs）驱动的最强大基础代理。", "conclusion": "通过对最新的MLLMs代理进行高强度评估，结果表明其在视觉理解、多模态推理和低级操作方面存在局限性。StarDojo 旨在促进对未来更强大、开放性多模态代理的研究，使其能够在复杂生产生活环境中展现更加复杂的行为。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.09918", "html_url": "https://arxiv.org/abs/2410.09918", "title": "Dualformer：通过随机化推理痕迹学习实现可控的快速和慢速思考", "title_en": "Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces", "authors": "DiJia Su,Sainbayar Sukhbaatar,Michael Rabbat,Yuandong Tian,Qinqing Zheng", "background": "认知理论认为人类思维由两种系统驱动：快速直觉的System 1和缓慢但更审慎的System 2。类比于人类的思维过程，大型语言模型（LLMs）也可以采用两种推理模式：仅输出解决方案的“快速模式”或同时输出推理链和最终解决方案的“慢速模式”。本文探讨了如何通过训练期间随机丢弃推理痕迹的不同部分，使单一的Transformer模型同时支持这两种推理模式，并在必要时自动选择模式。", "innovation": "作者提出了Dualformer，这是一种通过训练期间使用随机化的推理痕迹来集成快速和慢速推理模式的单个Transformer模型。通过自动或手动配置推理模式，Dualformer不仅在慢速模式下表现优于现有基线模型，而且在快速模式和自动选择模式下也表现出显著的优势。特别是在解决迷宫任务时，Dualformer能够以更少的步骤达到更高的成功率，显示了其在数学推理问题上的泛化能力。", "conclusion": "Dualformer能够在不同推理模式下实现优异的性能和计算效率，在快速模式和自动模式下尤其出色。此外，相较于Searchformer，Dualformer生成的推理痕迹更具有多样性，展示了其在数学推理问题上的技术创新和改进。作者还开源了该模型的代码，以促进进一步的研究和应用开发。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.19002", "html_url": "https://arxiv.org/abs/2402.19002", "title": "GoalNet: 目标区域导向的人行轨迹预测", "title_en": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction", "authors": "Amar Fadillah,Ching-Lin Lee,Zhi-Xuan Wang,Kuan-Ting Lai", "background": "自动驾驶领域中，行人未来轨迹的预测是一项重要任务。行人轨迹的预测受到场景路径、行人的意图和决策的影响，是一个多模态问题。目前大多数研究通过使用行人过去的轨迹来预测未来多种可能的轨迹分布，但这些研究忽略了场景上下文和行人的目标信息。", "innovation": "本文提出的创新之处在于，不直接预测行人未来的轨迹，而是通过场景上下文和观察到的轨迹来预测行人的目标点，再利用这些目标点来预测未来的轨迹。通过利用场景上下文和观察到的轨迹信息，可以将不确定性限制在少数几个目标区域内，这些区域代表了行人的“目标”。文中提出了一种基于行人目标区域的新神经网络结构——GoalNet，它可以同时预测行人的轨迹和边界框。整个模型高效且模块化，输出可以根据应用场景改变。", "conclusion": "实验结果显示，与之前的最佳性能相比，GoalNet在JAAD数据集上的性能提高了48.7%，在PIE数据集上的性能提高了40.8%。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2306.03538", "html_url": "https://arxiv.org/abs/2306.03538", "title": "SDR-GAIN：用于自动驾驶的高实时性遮挡行人间接姿态完成方法", "title_en": "SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving", "authors": "Honghao Fu,Yongli Gu,Yidong Yan,Yilang Shen,Yiwen Wu,Libo Sun", "background": "随着基于视觉的自动驾驶技术的发展，行人检测已成为提升交通安全和驾驶系统鲁棒性的重要组成部分。然而，在复杂交通场景中，传统的姿态估计方法往往无法准确重建被遮挡的关键点，主要原因是由于车辆、植被或建筑元素造成的阻挡。为此，本文旨在解决这一问题。", "innovation": "本文提出了一种新的实时遮挡行人姿态补全框架——基于分离和维度降低的生成对抗插补网络 (SDR-GAIN)。该方法与之前的区分遮挡模式的方法不同，SDR-GAIN 旨在直接从关键点坐标数值分布中学习人体姿态，并插补缺失的位置。这种方法使用自监督生成对抗学习框架，训练具有残差结构的轻量级生成器来进行姿态关键点的补全，并结合多种姿态标准化技术以简化学习过程。", "conclusion": "实验结果表明，SDR-GAIN 在准确恢复被遮挡的行人姿态关键点方面优于传统的机器学习算法和基于Transformer的缺失数据插补算法，同时实现了微秒级别实时推理的效果。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07787", "html_url": "https://arxiv.org/abs/2507.07787", "title": "测量AI与人类福祉的对齐", "title_en": "Measuring AI Alignment with Human Flourishing", "authors": "Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez", "background": "该论文介绍了Flourishing AI Benchmark（FAI基准），这是一个新颖的评估框架，用于评估人工智能在七个维度上与人类福祉的对齐情况：个性与美德、亲密的社会关系、快乐与生活满意度、意义与目的、心理与身体健康、经济与物质稳定性，以及信仰与精神面貌。与传统的侧重于技术能力或危害预防的基准不同，FAI基准评估了模型在这些维度上促进个人福祉的有效性。", "innovation": "FAI基准采用了综合的方法论，并结合了1,229个客观和主观问题来衡量AI系统的性能。使用专门的法官大型语言模型（LLMs）和跨维度评估，FAI基准采用几何平均评分以确保所有繁荣维度上的平衡表现。实验表明，尽管一些模型在综合对齐方面表现出色，但在信仰与精神、个性与美德，以及意义与目的等维度上，没有任何模型能够全面对齐。", "conclusion": "该研究建立了一个框架，旨在开发积极促进人类福祉的AI系统，而不是仅仅避免危害，为AI开发、伦理和评估提供了重要的启示。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.03897", "html_url": "https://arxiv.org/abs/2406.03897", "title": "HeSum：现代希伯来文抽象文本摘要的新型数据集", "title_en": "HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew", "authors": "Tzuf Paz-Argaman,Itai Mondshine,Asaf Achi Mordechai,Reut Tsarfaty", "background": "尽管大型语言模型（LLMs）在英语等领域的自然语言任务中表现出色，但在希伯来语等低资源语言中的表现，尤其是在生成性任务如抽象总结方面的表现仍不清楚。希伯来语丰富的形态特征增加了句意理解和意义构建的复杂性，进而增加了挑战。因此，本文通过提出HeSum数据集，旨在填补资源和评估的空白，为现代希伯来文的抽象文本总结提供新的基准数据集。HeSum数据集包含10,000个来自专业新闻网站的文章-摘要对，经语言学分析确认其高度抽象性和独特的形态学挑战。", "innovation": "本文的主要创新在于提出了HeSum数据集，专门用于现代希伯来文的抽象文本总结。HeSum数据集具有10,000个文章-摘要对，由专业人员撰写，并经过语言学分析验证其高度抽象性和独特的形态学挑战。这为当前最先进的大型语言模型和生成型语言技术提供了宝贵测试基准，尤其是针对希伯来语及其相关的语言生成挑战问题进行了开创性的工作。", "conclusion": "HeSum数据集为现代希伯来文的抽象文本总结和生成型语言技术提供了一个有价值的测试平台，对于解决希伯来语的生成型语言学习挑战具有重要意义。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.02984", "html_url": "https://arxiv.org/abs/2401.02984", "title": "大型语言模型在心理健康护理中的应用：一项范围性综述", "title_en": "Large Language Models in Mental Health Care: a Scoping Review", "authors": "Yining Hua,Fenglin Liu,Kailai Yang,Zehan Li,Hongbin Na,Yi-han Sheu,Peilin Zhou,Lauren V. Moran,Sophia Ananiadou,David A. Clifton,Andrew Beam,John Torous", "background": "本文旨在对大型语言模型（LLMs）在心理健康护理中的应用进行全面分析，评估其有效性、识别挑战，并探讨其对未来应用的潜力。通过在2019年10月1日至2023年12月2日之间，于多个数据库（PubMed, Web of Science, Google Scholar, arXiv, medRxiv, PsyArXiv）中进行系统检索，筛选出与LLMs在心理健康护理中应用相关的34篇文章。研究涵盖了各种类型的原始研究，即使未经同行评审、已发布或传播的研究也被纳入。这些研究使用的LLM必须在T5之后开发，并直接探讨心理健康护理环境中的研究问题。研究结果揭示了若干LLMs在心理健康护理中的应用，如诊断、治疗和增强患者参与。其中指出的主要挑战包括数据可用性和可靠性、情感状态的细致处理以及有效的评估方法。尽管LLMs在提高准确性和可访问性方面显示出潜力，仍存在临床适用性和伦理考虑方面的显著差距。", "innovation": "该研究通过系统综述的方法，全面分析了LLMs在心理健康护理中的应用，覆盖了未经同行评审的研究，体现了对Lljms在心理咨询、诊断和增强患者参与度等方面应用的广泛探索。同时，它提出了具体的研究挑战和未来发展的建议，为这一领域的进一步研究和实施提供了新的视角和依据。", "conclusion": "LLMs在心理健康护理中具有巨大的潜力，为了充分发挥其潜力，必须重视开发稳健的数据集、开发和评估框架、伦理指导和跨学科合作，以解决目前的限制。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.10657", "html_url": "https://arxiv.org/abs/2407.10657", "title": "对公式生成中合成数据验证的实证研究", "title_en": "An Empirical Study of Validating Synthetic Data for Formula Generation", "authors": "Usneek Singh,José Cambronero,Sumit Gulwani,Aditya Kanade,Anirudh Khatry,Vu Le,Mukul Singh,Gust Verbruggen", "background": "大型语言模型（LLMs）能用于辅助编写电子表格中的公式，但关于这些公式的资源稀缺，影响预训练模型的基础性能，并限制了模型微调的能力。给定一个公式的语料库，可以使用另一个模型生成合成自然语言指令用于微调。然而，有必要验证LLM生成的自然语言（NL）是否准确，以利于微调。", "innovation": "该研究通过使用代理目标来评价合成注释的准确性，验证合成训练示例对模型性能的影响。研究表明，验证可以改进基于验证数据微调后模型的性能，并且即使验证倾向于删除更具挑战性的示例，也会提高模型解决复杂问题的能力。", "conclusion": "验证合成训练示例能提升模型性能，即使剔除了更具挑战性的示例，也能增加模型在微调后解决复杂问题的能力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.19715", "html_url": "https://arxiv.org/abs/2405.19715", "title": "SpecDec++: 通过自适应候选长度提升推测性解码", "title_en": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths", "authors": "Kaixuan Huang,Xudong Guo,Mengdi Wang", "background": "推测性解码通过使用一个小而快的草图模型来减少目标大型语言模型的推理延迟。推测性解码的效果依赖于一个超参数K——候选长度，即目标模型在每一轮中需要验证的候选令牌数量。然而，以往的方法往往使用简单的启发式来选择K，这可能导致性能不佳。", "innovation": "研究了候选长度K的最优选择，并将其形式化为马尔可夫决策过程。理论上证明，这种马尔可夫决策过程的最优策略为阈值策略，即当获得拒绝的概率超过某个阈值时，当前推测应停止并验证。基于这一理论，提出了一种增强版的推测性解码SpecDec++，其可以自适应地确定候选长度。SpecDec++通过将接受预测头添加到草图模型中来预测候选令牌的条件接受概率。当预测的至少一个令牌被拒绝的概率超过阈值时，SpecDec++将停止当前的推测。", "conclusion": "SpecDec++在Alpaca数据集上实现了2.04倍的速度提升（基线推测性解码的7.2%改进），在GSM8K和HumanEval数据集上分别实现了2.26倍和2.23倍的速度提升（分别为9.4%和11.1%的改进）。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2301.07791", "html_url": "https://arxiv.org/abs/2301.07791", "title": "金融网络中的时间模因：Mercari、JPMC和Venmo平台的研究", "title_en": "Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and Venmo Platforms", "authors": "Penghang Liu,Bahadir Altun,Rupam Acharyya,Robert E. Tillman,Shunya Kimura,Naoki Masuda,Ahmet Erdem Sarıyüce", "background": "理解人们之间的金融交易动态对各种应用（如欺诈检测）至关重要。金融交易网络的一个重要方面是时间性。通过考虑交易的时间顺序和重复频率，可以在图结构内获得新的见解。时间模因，定义为在短时间内相互作用的一组节点，是一个在这个背景下非常有前景的工具。", "innovation": "研究了三个独特的金融时序网络：Mercari的在线市场交易、J.P.摩根 Chase生成的合成支付网络以及Venmo用户间的支付和友谊。金融网络中的时间模因比其他基线（包括考虑简单图特征的方法以及LINE和node2vec节点嵌入技术）提供了更优的欺诈检测性能，同时在运行时间方面也是可行的。在Venmo网络中，分析了金融与社会关系之间的相互作用，包括友谊预测、供应商识别和时间周期分析。时间模因在友谊预测上优于一般的启发式计算方法，还能识别出高准确性供应商并揭示罕见模因中的有趣模式。", "conclusion": "这项工作中的分析、数据集和经验教训将对未来对金融交易网络的研究有益。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.14023", "html_url": "https://arxiv.org/abs/2406.14023", "title": "从心理测量学角度攻击评估大型语言模型的隐性偏见", "title_en": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective", "authors": "Yuchen Wen,Keping Bi,Wei Chen,Jiafeng Guo,Xueqi Cheng", "background": "随着大型语言模型（LLMs）成为获取信息的重要方式，人们对LLMs可能加剧不道德内容传播的担忧也越来越多，包括隐含偏见，这种偏见伤害了某些群体而没有明确的有害词汇。", "innovation": "本文提出了三种攻击方法，即伪装、欺骗和教学，用于从心理测量学视角评估LLMs的隐性偏见。构建了两个基准数据集：一个是双语数据集，包含针对四种偏见类型的有偏陈述（2700个实例），用于广泛比较分析；另一个是BUMBLE基准，涵盖九种常见偏见类型（12700个实例），用于全面评估。研究表明，这些方法比现有基线更有效地激发了LLMs的内在偏见。", "conclusion": "提出的攻击方法和基准提供了评估LLMs道德风险的有效手段，推动了它们开发中的责任归属。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08765", "html_url": "https://arxiv.org/abs/2507.08765", "title": "压缩任何分割万物模型（SAM）", "title_en": "Compress Any Segment Anything Model (SAM)", "authors": "Juntong Fan,Zhiwei Hao,Jianqiang Shen,Shang-Ling Jui,Yi Zhang,Jing-Xiao Liao,Feng-Lei Fan", "background": "由于 Segment Anything Model (SAM) 及其变体在零样本分割方面表现出色并被广泛应用于医疗保健和智能制造业等多种场景，有效压缩 SAMs 的需求变得越来越迫切。因此，本文提出了一种名为 Birkhoff 的新型数据无关压缩算法，专门用于 SAM 及其变体。该算法具有跨模型类型灵活、部署快速、保真度高、模型尺寸紧凑等优势。通过对 18 个 SAM 在 COCO、LVIS 和 SA-1B 数据集上的广泛实验，Birkhoff 在压缩时间、压缩比、压缩后性能和推理速度方面表现出一致且竞争性的结果。例如，在 SAM2-B 模型上实现 5.17 倍的压缩比，并在不使用任何微调数据的情况下性能下降小于 1%。此外，所有模型的压缩过程可以在 60 秒内完成。", "innovation": "与量化、剪枝、知识蒸馏等压缩方法不同，Birkhoff 引入了一种名为 '超压缩'（Hyper-Compression）的新压缩算法，其核心原则是通过找到一个高维参数向量的密集轨迹来将其转换为低维标量。此外，Birkhoff 设计了一个专用的线性层操作 '超线性'（HyperLinear），实现了解压缩与矩阵乘法的融合，可显著加速压缩 SAM 的推理速度。Birkhoff 的一个重要特点是可以跨不同类型的模型进行压缩，并且压缩后的模型性能损失小。", "conclusion": "实验结果表明，Birkhoff 能够以较低的压缩率和较小的性能损失对 SAM 进行高效压缩，并且压缩速度快。该方法在 COCO、LVIS 和 SA-1B 数据集上的广泛实验中证明了 Birkhoff 的有效性和竞争性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05739", "html_url": "https://arxiv.org/abs/2410.05739", "title": "端到端多通道说话人提取和双耳语音合成", "title_en": "End-to-end multi-channel speaker extraction and binaural speech synthesis", "authors": "Cheng Chi,Xiaoyu Li,Yuxuan Ke,Qunping Ni,Yao Ge,Xiaodong Li,Chengshi Zheng", "background": "远程会议中的语音清晰度和空间音频沉浸感是最重要的两个提升因素。现有的方法通常存在局限性，单一麦克风方法缺乏空间信息，而使用麦克风阵列的方法性能又高度依赖于到达方向估计的准确性。", "innovation": "提出了一种端到端的深度学习框架，能够直接将多通道嘈杂的回声信号转换为清洁的、空间化的双耳语音。该框架将声源提取、降噪和双耳渲染统一到一个网络中，并提出了一种新的幅度加权双耳强度差损失函数，以提高空间渲染的准确性。", "conclusion": "广泛的评估结果表明，该方法在语音质量和空间保真度方面均优于现有基准方法。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.14679", "html_url": "https://arxiv.org/abs/2409.14679", "title": "量化物体检测领域适应中的上下文偏差", "title_en": "Quantifying Context Bias in Domain Adaptation for Object Detection", "authors": "Hojun Son,Asma Almutairi,Arpan Kusari", "background": "域适应中的物体检测（DAOD）已经成为对抗训练域和部署域之间分布偏移导致性能下降的关键方法。然而，由学习到的前景-背景（FG-BG）关联引发的上下文偏差这一关键因素仍然被忽视。", "innovation": "该研究首次通过背景遮罩、特征级扰动和CAM来分析模型如何捕捉FG-BG关联，并通过因果推理（do-calculus）确定FG-BG关联与检测性能之间的因果关系。引入了一个新颖的度量标准——领域关联梯度，通过最大均值差异（MMD）的比例来量化FG-BG关联在不同领域的因果影响。研究结果表明，上下文偏差不仅存在，而且因果削弱了物体检测模型在不同领域的泛化能力。", "conclusion": "研究强调在DAOD框架中显式解决上下文偏差的必要性，为开发更强大和通用的物体检测系统提供了见解。这一结论在多种模型和数据集上得到了验证，包括最新架构ALDI++。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06303", "html_url": "https://arxiv.org/abs/2410.06303", "title": "组分风险最小化", "title_en": "Compositional Risk Minimization", "authors": "Divyat Mahajan,Mohammad Pezeshki,Charles Arnal,Ioannis Mitliagkas,Kartik Ahuja,Pascal Vincent", "background": "组分泛化是开发高效智能机器的关键步骤，使机器能够在类似人类的方式上泛化。文中针对一种名为组分变化的分布变化形式，训练中缺失某些特征组合但在测试中出现，这考验了模型对新型特征组合的组分泛化能力。通过灵活的能量分布模型，每项能量代表一种特征，文中提出了组分风险最小化（CRM）作为一种替代经验风险最小化的方法。", "innovation": "提出了组分风险最小化（CRM）方法，通过能量分布模型替代经验风险最小化，能够有效解决组分变化形式的分布变化问题，并且理论分析显示，CRM能外推到观测到特征组合的特殊仿射包，实证结果显示其相比其他方法具有更好的鲁棒性，适用于处理各种子人群转移问题.", "conclusion": "组分风险最小化能够有效提高模型在面对新型特征组合的组分泛化能力，并且对于不同形式的数据偏移都有较好的性能表现。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.06728", "html_url": "https://arxiv.org/abs/2411.06728", "title": "关于具有一个隐藏层的ReLU网络的原则", "title_en": "On the Principles of ReLU Networks with One Hidden Layer", "authors": "Changcun Huang", "background": "单隐藏层或两层神经网络是最简单的前馈神经网络，其机制可能构成更通用网络架构的基础。然而，即使对于这种简单的架构，仍然是一个“黑箱”，即不清楚通过反向传播算法获得的解决方案的机制，以及如何通过确定性方式控制训练过程。", "innovation": "系统研究了一维输入训练解决方案完全可理解的问题，并且对于高维输入也能到某种程度上的解释。结果为彻底揭示具有一个隐藏层的ReLU网络的“黑箱”铺平了道路，并推进了对深层ReLU网络的理解。", "conclusion": "展示了理论上和实验上，一维输入的训练解决方案可以完全理解，更高维输入的训练解决方案也能在一定程度上被解释。这些结果为深入揭示两层ReLU网络的“黑箱”并推进对深层ReLU网络的理解开辟了道路。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.00994", "html_url": "https://arxiv.org/abs/2412.00994", "title": "PIAD-SRNN: 物理启发自适应分解在状态空间RNN中的应用", "title_en": "PIAD-SRNN: Physics-Informed Adaptive Decomposition in State-Space RNN", "authors": "Ahmad Mohammadshirazi,Pinaki Prasad Guha Neogi,Rajiv Ramnath", "background": "时间序列预测通常需要在准确性与效率之间进行权衡。尽管最近的Transformer模型提升了预测能力，但同时也带来了高昂的计算成本。基于线性的模型虽然表现更佳，但仍然没有达到理想的性能。本文提出了一种称为PIAD-SRNN的模型，它通过将周期性和趋势成分分离并嵌入递归框架中，同时将领域方程融入模型，在室内空气质量数据集上验证了其性能，特别是在不同预测时间范围内的二氧化碳浓度预测表现出色。", "innovation": "PIAD-SRNN通过结合自适应分解和状态空间递归神经网络，将物理方程嵌入模型中，从而在保持高精度的同时降低了计算成本。此外，该论文还提供了四个精心策划的数据集。", "conclusion": "在长短期时间序列预测中，PIAD-SRNN在MSE和MAE方面都优于现有的最先进的模型，包括基于Transformer的架构。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.00381", "html_url": "https://arxiv.org/abs/2410.00381", "title": "使用 Wasserstein 正则化扩散下尺度极端降水", "title_en": "Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion", "authors": "Yuhao Liu,James Doss-Gollin,Qiushi Dai,Ashok Veeraraghavan,Guha Balakrishnan", "background": "理解极端降水事件带来的风险需要高分辨率数据（以评估局部危害）和广泛的长期记录（以捕捉罕见事件）。雷达和气象站网络可以提供千米级的降水场，但历史记录有限且地理覆盖不完全。全球雨量计和综合产品虽然跨越数十年，但其粗糙的30-50千米网格掩盖了局部极端事件。因此，既有数据的局限性增加了精确评估和适应气候变化规划的难度。", "innovation": "本文引入了 Wasserstein 正则化扩散（WassDiff）框架，结合了扩散模型与分布匹配（Wasserstein）正则化器，消除整个生成去噪过程中的偏差。该方法基于55千米的CPC雨量计降水和31千米的ERA5再分析数据，生成1千米分辨率的降水估算值，保持在整个强度范围内的良好校准，包括极端情况。该方法在全面评估中优于现有最先进的下尺度方法，表现出较低的重建误差和减少的偏差。案例研究进一步证明了其能够再现实际的细尺度结构和准确的最大强度，尤其是在热带风暴和冷锋等极端天气现象中。", "conclusion": "WassDiff 方法通过揭示全球可获得的粗分辨率记录中长达数十年的高分辨率降水信息，为更准确的洪水风险评估和气候变化适应规划提供了实用路径。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.11540", "html_url": "https://arxiv.org/abs/2412.11540", "title": "SP$^2$T: 稀疏代理注意机制的双流点变换器", "title_en": "SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer", "authors": "Jiaxu Wan,Hong Zhang,Ziqi He,Yangyan Deng,Qishu Wang,Ding Yuan,Yifan Yang", "background": "点变换器在通过扩展感受野（RF）提升了3D理解方面取得了显著进展，但进一步扩大RF会导致群体注意力稀释和细致特征提取能力下降。代理作为简化特征图的抽象表示，能提供全局RF。然而，现有代理基方法面临严重限制：全局代理导致对于大规模点云的计算复杂度为平方阶，并且存在位置不确定性；而局部代理则面临不可靠的几何多样点云采样、代理交互计算效率低和局部-全局信息融合不平衡的问题。", "innovation": "提出了一种稀疏代理点变换器（SP$^2$T）——一种基于局部代理的双流点变换器，具有三种关键创新：1) 空间代理采样：基于顶点关联的空间代理采样能对几何多样点云进行稳健采样；2) 效率代理交互：基于表的相对偏置稀疏代理注意机制有效通过高效的映射-减少计算实现交互；3) 局部-全局信息融合：通过并行分支维持局部-全局平衡的双流架构。", "conclusion": "全面的实验表明，SP$^2$T在室内和室外3D理解基准测试中取得了最先进的结果，具有可接受的延迟，并且相对于其他基于代理的方法有显著改进（如SPoTr@S3DIS的mIoU提升了3.8%， PointASNL@Sem.KITTI的mIoU提升了22.9%）。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05401", "html_url": "https://arxiv.org/abs/2410.05401", "title": "使用大型语言模型在社交媒体广告中分析气候微目标营销的后验研究：主题见解与公平性评估", "title_en": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation", "authors": "Tunazzina Islam,Dan Goldwasser", "background": "社交媒体上的气候变化沟通越来越多地采用微目标策略，以有效地接触和影响特定的人口统计群体。本研究利用大型语言模型（LLMs）对Facebook广告中的微目标实践进行后验分析，重点关注人口统计学目标和公平性两个关键方面。研究结果表明，LLMs能准确预测目标人口统计特征，如性别和年龄段，总准确率为88.55%。进一步通过指导LLMs生成分类解释，揭示了不同的主题元素如何吸引不同的受众群体，强调了不同观众群体的定制化策略。此外，通过对LLMs检测微目标传播效果的评估和全面的公平性分析，发现在模型预测中存在某些偏见，特别是在老年人和男性观众的分类上。这项研究展示了LLMs在分析和解释定向传播策略方面的有效性，并指出了公平性方面的担忧，为未来增强社交媒体驱动的气候运动的透明度、问责性和包容性提供了有价值的框架。", "innovation": "利用大型语言模型（LLMs）进行后验分析，探索社交媒体上气候变化宣传中的微目标策略。该研究强调了使用LLMs生成解释以提高决策透明度，并揭示了不同年龄段和性别之间的定制化策略差异。此外，研究还进行了全面的公平性评估，识别了模型预测中的潜在偏见，特别是在老年人和男性观众的分类上，突显了增强透明度、问责性和包容性的需求。", "conclusion": "本研究使用大型语言模型揭开社交媒体广告中气候微目标策略的面纱，展示了这些模型在解释目标定向传播策略方面的有效性。此外，研究提出公平性评估发现了存在的潜在偏见，为提高未来社交媒体驱动的气候运动的透明度、问责性和包容性提供了有价值的见解和框架。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02367", "html_url": "https://arxiv.org/abs/2502.02367", "title": "场匹配：一种用于生成和转移数据的静电范式", "title_en": "Field Matching: an Electrostatic Paradigm to Generate and Transfer Data", "authors": "Alexander Kolesov,Manukhov Stepan,Vladimir V. Palyulin,Alexander Korotin", "background": "该研究提出了电场匹配（EFM）方法，适用于生成建模和分布转移任务。灵感来源于电容器的物理特性，通过将源分布和目标分布放置在电容器的平板上，并赋予它们正负电荷，进而利用神经网络逼近学习电场。方法的核心是通过电场线将分布映射到彼此，以实现分布转移。理论上证明了该方法能有效实现分布转移，实践上通过实验验证了该方法在各类数据上的有效性。", "innovation": "该研究提出了电场匹配（EFM）方法，通过借鉴电容器的工作原理来实现生成建模和分布转移。该方法通过神经网络模型学习电场，并利用电场线对分布进行匹配，这种独特的方法为生成模型和分布转移任务提供了一种创新的解决方案。", "conclusion": "实验结果表明，电场匹配方法在toy和图像数据上均有良好表现，理论上也证明了方法的有效性和正确性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.11924", "html_url": "https://arxiv.org/abs/2503.11924", "title": "REGEN：一个包含自然语言评论和叙述的数据集和基准测试", "title_en": "REGEN: A Dataset and Benchmarks with Natural Language Critiques and Narratives", "authors": "Kun Su,Krishna Sayana,Hubert Pham,James Pine,Yuri Vasilevski,Raghavendra Vasudeva,Marialena Kyriakidi,Liam Hebert,Ambarish Jash,Anushya Subbiah,Sukhdeep Sodhi", "background": "现有的数据集主要侧重于序列项目预测，未能充分捕捉到用户和推荐系统之间的对话能力。REGEN 数据集通过增强亚马逊产品评论集，加入了用户指导查询（user ‘steering’ queries）和与推荐物品相关的详细叙述来解决这一问题。", "innovation": "提出了一个新的数据集 REGEN，旨在评估推荐型大语言模型的对话能力。REGEN 通过填充两个关键的自然语言特征——用户批判和叙述，扩展了亚马逊产品评论集。创新点还在于提出了一种模型框架 LUMEN（基于大语言模型的统一多任务模型，包含批判、推荐和叙述），并建立了端到端的对话推荐模型基准。", "conclusion": "实验结果表明，加入用户批判可以提高推荐质量，使推荐器学习语言理解并将其与推荐信号集成。基于 REGEN 数据集训练的大型语言模型能够有效生成推荐和上下文叙述，其性能与最先进的推荐器和语言模型相当。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08525", "html_url": "https://arxiv.org/abs/2503.08525", "title": "GTR: 引导式思维强化防止基于强化学习的视觉语言模型代理思维崩溃", "title_en": "GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training", "authors": "Tong Wei,Yijun Yang,Junliang Xing,Yuanchun Shi,Zongqing Lu,Deheng Ye", "background": "研究发现，强化学习（Reinforcement Learning, RL）在大型语言模型（Large Language Models, LLMs）和视觉语言模型（Vision-Language Models, VLMs）中能够有效扩展链式思考（Chain-of-Thought, CoT）推理，但在训练VLM代理进行目标导向的动作推理方面，基于行动结果的奖励的效果尚未完全确立。当奖励仅基于行动结果时，RL可能会导致VLM中的思维简化（thought collapse），表现为思维多样性迅速消失、无关状态的且不完整的推理和随后的无效行动，这会带来负面奖励。", "innovation": "该工作提出了一种简单的可扩展的引导式思维强化（Guided Thought Reinforcement, GTR）框架，该框架通过在每个强化学习步骤中评估和改进代理的推理过程，避免思维简化现象。GTR能在不需要密集的每步人工标注的情况下同时训练推理和行动，显著提高了视觉环境中的任务成功率，尤其是在不使用大型模型的情况下。", "conclusion": "GTR框架在各种视觉环境中显著提升了LLaVA-7b模型的性能和泛化能力，与最新的领先模型相比，任务成功率提高了3-5倍，且模型规模较小。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13078", "html_url": "https://arxiv.org/abs/2504.13078", "title": "MGT: Extending Virtual Try-Off to Multi-Garment Scenarios", "title_en": "MGT: Extending Virtual Try-Off to Multi-Garment Scenarios", "authors": "Riza Velioglu,Petra Bevandic,Robin Chan,Barbara Hammer", "background": "计算机视觉正在通过虚拟试穿（VTON）和虚拟脱衣（VTOFF）改变时尚行业。VTON能够生成带有特定服装的个人图像，而更具有挑战性的p2p-VTON可以使用穿着同款服装的另一人的图像。VTOFF则从穿着者的照片中提取出标准化的服装图像。然而，当前的VTOFF模型在处理多种类别的服装时面临挑战。", "innovation": "MGT 是一款基于扩散的 VTOFF 模型，可以处理包括上衣、下装和连衣裙在内的多种服装类别。MGT 使用潜扩散架构和基于 SigLIP 的图像条件，能够捕捉服装的形状、纹理和图案。此外，MGT 还结合了类别特定嵌入，使其在 VITON-HD 数据集上达到最先进的 VTOFF 结果，并在 DressCode 上取得了竞争性表现。当与 VTON 模型结合使用时，它进一步增强了 p2p-VTON，减少了不必要的属性转移，如肤色，确保了个人特征的保留。", "conclusion": "MGT 增强了 VTOFF 能力，处理多类别的服装，并且在多种场景中展示了其优越性，还通过与 VTON 结合使用提高了 p2p-VTON 的性能。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01403", "html_url": "https://arxiv.org/abs/2504.01403", "title": "生成检索与对齐模型：电子商务检索的新范式", "title_en": "Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval", "authors": "Ming Pang,Chunyuan Yuan,Xiaoyu He,Zheng Fang,Donghao Xie,Fanyi Qu,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao", "background": "传统的稀疏检索和密集检索方法难以充分利用通用世界知识，往往无法捕捉查询和产品中的细微特征。随着大型语言模型（LLMs）的发展，工业搜索系统开始利用LLMs为产品检索生成标识符。常用的标识符包括静态/语义ID和产品词组集。前一种方法需要从头创建产品ID系统，无法利用嵌入在LLMs中的世界知识；而第二种方法利用了这种普遍知识，但由于查询和产品之间的词分布差异显著，基于产品的标识符往往与用户搜索查询不匹配，导致产品召回失败。此外，当查询包含多个属性时，这些算法会生成大量标识符，难以评估其质量，从而降低总体召回效率。", "innovation": "本文介绍了电子商务检索的新型范式：生成检索与对齐模型（GRAM）。该模型通过在查询和产品文本信息上进行联合训练来生成共享的文本标识代码，有效弥合了查询与产品之间的差距。该方法不仅增强了查询和产品之间的连接，还提高了推理效率。模型采用协同对齐策略生成用于最大化检索效率的代码，并引入了查询-产品评分机制，以比较不同代码下的产品值，进一步提高检索效率。实验结果表明，GRAM在离线和在线A/B测试中显著优于传统模型和最新的生成检索模型，证明了其有效性和实用性。", "conclusion": "生成检索与对齐模型（GRAM）显著提高了电子商务中的检索效率，解决了传统方法中的问题，通过联合训练查询和产品文本信息，生成共享文本标识符代码，既优化了检索链接又增强了推理效率，展示了其在电子商务检索中的实际应用价值。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06897", "html_url": "https://arxiv.org/abs/2504.06897", "title": "MedSegFactory：受文本引导的医学图像-掩码对生成", "title_en": "MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs", "authors": "Jiawei Mao,Yuhan Wang,Yucheng Tang,Daguang Xu,Kang Wang,Yang Yang,Zongwei Zhou,Yuyin Zhou", "background": "目前，医学影像中的分割任务面临着高质量图像和对应分割掩码数据稀缺的问题，这对现有分割工具的发展和应用构成了限制。现有的医学图像合成框架可能在数据生成的一致性、多模态支持以及用户定制化需求方面存在不足，难以满足多样化的医学影像工作流程的高效率和高精度要求。因此，建立一个能够自动生成高质量医学影像及其分割掩码的多功能数据仓库框架有着重要的理论和实践意义。", "innovation": "MedSegFactory引入了一种新颖的双流扩散模型，其中一条流合成医学图像，另一条流生成相应的分割掩码。同时，它提出了联合交叉注意（JCA），实现了双向交互的去噪过程，通过动态条件之间的交叉调节来增强生成对的内部一致性。此外，MedSegFactory支持用户通过自定义提示来生成符合特定要求的医学影像对，包括目标标签、成像模态、解剖区域和病理条件，从而实现高效、高质量的数据生成。这项创新框架不仅解决了数据稀缺问题，还提高了分割任务的性能，特别是在2D和3D分割任务上取得了竞争性或最先进的效果。", "conclusion": "MedSegFactory能够满足多样化的医学影像工作流程需求，提升效率和准确率。通过广泛的实验检验，该框架生成的图像和掩码数据质量优异且具有实际应用潜力，能够无缝集成到各种医学影像处理系统中，拓宽了医学影像研究和临床应用的边界。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13959", "html_url": "https://arxiv.org/abs/2504.13959", "title": "AI安全应优先考虑工作未来", "title_en": "AI Safety Should Prioritize the Future of Work", "authors": "Sanchaita Hazra,Bodhisattwa Prasad Majumder,Tuhin Chakrabarty", "background": "当前对人工智能安全的努力主要集中在筛选有害内容、防止对人类行为的操纵以及消除网络安全或生物安全中的生存风险。虽然这些工作非常重要，但它们忽略了对社会长期轨迹至关重要的以人为本的考量。文章指出，这些努力没有充分考虑到人工智能对工作未来的影响，以及它如何通过加剧收入不平等来对经济产生负面的长期影响，并强调主要AI开发者的闭源方法如何导致创造性的劳动力得到劣化和创新能力垄断。", "innovation": "文章提出，AI安全应更加关注工作问题，并推荐建立全面的工作转型支持机制，帮助劳工适应有意义的工作。文章还强调了通过实施集体许可等方式加强国际版权体系的重要性，以确保公平的补偿机制，并建议全球AI治理框架向劳工倾斜，以促进共享繁荣和经济正义，减少技术债务。", "conclusion": "文章得出结论，AI安全不能仅限于当前的几个维度，而应包括对工作的关注，呼吁建立一种以劳工为中心的全球AI治理模式，以实现经济上的公平正义。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18246", "html_url": "https://arxiv.org/abs/2504.18246", "title": "一次通推理：通过令牌复制和块稀疏掩码高效处理多轮推理微调", "title_en": "One-Pass to Reason: Token Duplication and Block-Sparse Mask for Efficient Fine-Tuning on Multi-Turn Reasoning", "authors": "Ritesh Goru,Shanay Mehta,Prateek Jain", "background": "微调大型语言模型（LLMs）在多轮推理数据集上需要对每次对话进行N次前向传递，因为每个轮次中的推理令牌在后续轮次中会被丢弃。我们的研究背景是设计一种方法，以减少这种多轮传递的缺点，从而提高微调效率。", "innovation": "我们提出了一种方法，通过复制响应令牌并使用自定义注意力掩码，允许一次性处理整个对话，同时保持与N次传递方法相同的损失，将时间复杂度从$O(N^{3})$降低到$O(N^{2})$，内存复杂度保持不变，从而显著提高了训练速度并保持了准确性。", "conclusion": "我们的方法在保持准确性的同时显著提高了training速度，已实现代码在线公开。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00467", "html_url": "https://arxiv.org/abs/2505.00467", "title": "红队演练大型语言模型在医疗健康中的应用", "title_en": "Red Teaming Large Language Models for Healthcare", "authors": "Vahid Balazadeh,Michael Cooper,David Pellow,Atousa Assadi,Jennifer Bell,Mark Coatsworth,Kaivalya Deshpande,Jim Fackler,Gabriel Funingana,Spencer Gable-Cook,Anirudh Gangadhar,Abhishek Jaiswal,Sumanth Kaja,Christopher Khoury,Amrit Krishnan,Randy Lin,Kaden McKeen,Sara Naimimohasses,Khashayar Namdar,Aviraj Newatia,Allan Pang,Anshul Pattoo,Sameer Peesapati,Diana Prepelita,Bogdana Rakova,Saba Sadatamin,Rafael Schulman,Ajay Shah,Syed Azhar Shah,Syed Ahmar Shah,Babak Taati,Balagopal Unnikrishnan,Iñigo Urteaga,Stephanie Williams,Rahul G Krishnan", "background": "本文介绍了在2024年医疗健康机器学习会议上（2024年8月15日）举行的名为“医疗健康中的大型语言模型红队演练”的预会议工作坊的设计过程和研究成果。参与者包括具有不同背景的计算和临床专长的人员，旨在寻找大型语言模型在处理临床提示时可能输出可能导致临床伤害的响应的漏洞。临床医生的红队演练有助于识别大型语言模型中的漏洞，这些漏洞可能不被缺乏临床专业知识的大型语言模型开发人员识别。", "innovation": "通过将临床专家纳入红队演练过程，该研究揭示了大型语言模型在医疗健康领域尚未被认识的潜在漏洞，能够提供更全面和专业的安全评估。此外，该研究通过一项复制研究评估了在所有提供的大型语言模型中发现的漏洞，从而提供了一个更为系统和详细的安全分析过程。", "conclusion": "报告中详细记录了发现的漏洞并进行了分类，所提出的方法为改进和增强大型语言模型在医疗健康领域的应用提供了重要的参考和依据。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06737", "html_url": "https://arxiv.org/abs/2505.06737", "title": "平衡进步与安全：强化学习在自动驾驶中的一种新型风险感知目标", "title_en": "Balancing Progress and Safety: A Novel Risk-Aware Objective for RL in Autonomous Driving", "authors": "Ahmed Abouelazm,Jonas Michel,Helen Gremmelmaier,Tim Joseph,Philip Schörner,J. Marius Zöllner", "background": "强化学习（RL）因其强大的决策能力成为实现自动驾驶的一种有前途的方法。然而，现有RL在设计用于交通场景中的奖励函数方面存在不足，导致不明确且带有各种缺点的奖励。特别是在安全性方面，仅将安全视为碰撞后的惩罚，而忽略了导致碰撞之前的行动风险，这限制了RL在实际应用中的适用性。", "innovation": "该研究重点在于改进奖励设计，通过定义一套驾驶目标并将它们分级来提升奖励的结构化程度。此外，提出了基于椭圆函数的新型风险感知目标，并结合了责任敏感安全（RSS）的概念。通过实验验证，该研究方法能平均降低21%的碰撞率，并且在路线进度和累计奖励方面始终优于基线奖励，展示了其在促进更安全驾驶行为的同时保持高性能的能力。", "conclusion": "该研究提出了一种新型的风险感知奖励目标，有效降低了自动驾驶中的碰撞率，同时提升了路线进度和累计奖励，证明了该方法能够促进更为安全的驾驶行为，具有较高的性能水平。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.00136", "html_url": "https://arxiv.org/abs/2412.00136", "title": "FonTS: 文本渲染中的字体和风格控制", "title_en": "FonTS: Text Rendering with Typography and Style Controls", "authors": "Wenda Shi,Yiren Song,Dengming Zhang,Jiaming Liu,Xingxing Zou", "background": "视觉文本渲染在现实世界的应用中很普遍，需要仔细选择字体和字体设计。基于扩散转换器（DiT）的方法在文本到图像（T2I）模型中取得了进展，能够自动化许多过程。然而，这些方法仍然面临如字体不一致、风格变化以及细粒度控制不足等问题，特别是在单词层面。", "innovation": "本文提出了一种两阶段的DiT基处理流程，通过提高对字体和风格的控制能力来解决这些问题。提出了一种参数高效的细调方法（TC-FT），并在关键参数（5%）上使用闭合的字体控制标记（ETC标记），使得可以精确地在单词层面应用字体特征。为了进一步解决文本渲染中风格的一致性问题，提出了一个文本无关的风格控制适配器（SCA），它可以在防止内容泄露的同时增强风格一致性。", "conclusion": "通过全面的实验，我们的方法在文本渲染任务中实现了单词级别的字体控制、字体一致性以及风格一致性方面的优越效果。我们的数据集和模型将对学术研究开放使用。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.08264", "html_url": "https://arxiv.org/abs/2505.08264", "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning", "title_en": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning", "authors": "Ahmed Abouelazm,Tim Weinstein,Tim Joseph,Philip Schörner,J. Marius Zöllner", "background": "训练端到端自动驾驶代理使用强化学习（RL）面临挑战，因为RL代理通常局限于模拟中固定的场景和道路使用者的预期行为，这限定了它们的泛化能力和实际部署。虽然领域随机化提供了一个解决方案来随机采样驾驶场景，但它常常导致训练效率低下和次优策略，因为训练场景之间差异很高。手动设计的课程引入了专家偏见且缺乏可扩展性，作者提出了一种自动课程学习框架，它可以动态生成基于代理发展潜力适应复杂度的驾驶场景，从而提高训练效率并排除代理已经掌握或太难的场景，从而消除专家设计的需求，并提高了泛化能力。这种方法在对抗基线方法（包括固定场景训练和领域随机化）的比赛中，实现了更高的成功率和更快的收敛速度。这种方法不仅提高泛化能力，而且缩短了培训步骤时间。", "innovation": "提出了自动课程学习（Automatic Curriculum Learning, ACL）框架，该框架可以动态生成适应性复杂度的驾驶场景，基于代理的发展潜力自动生成和变异驾驶场景，从而提高训练效率，并且无需专家设计。与手动设计的课程相比，这种方法减少了专家偏见且具有可扩展性，提高了策略的质量和鲁棒性，从而在低交通密度提升了9%，高交通密度提升了21%的成功率，并且加快了收敛速度，减少了训练步骤。", "conclusion": "自动课程学习框架提高了基于强化学习的自动驾驶代理的稳健性和效率，通过动态生成场景并根据代理当前的表现和潜力进行自我调整，增强了泛化能力和训练效率，而无需专家设计师。这种方法与固定场景训练和领域随机化基线方法相比，实现了更高的成功率和更快的收敛速度。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18397", "html_url": "https://arxiv.org/abs/2505.18397", "title": "关于多代理AI系统的机会与挑战的展望", "title_en": "An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems", "authors": "Fangqiao Tian,An Luo,Jin Du,Xun Xian,Robert Specht,Ganghua Wang,Xuan Bi,Jiawei Zhou,Ashish Kundu,Jayanth Srinivasa,Charles Fleming,Rui Zhang,Zirui Liu,Mingyi Hong,Jie Ding", "background": "多代理AI系统（MAS）由多个自主智能体组成，这些智能体能够互动、交换信息并基于内部生成模型做决策。近年来，大型语言模型和工具使用代理的进步使得MAS在科学发现和协作自动化领域更为实用。然而，仍有几个关键问题尚未得到解答：MAS何时比单智能体系统更有效？代理间互动带来了哪些新的安全风险？我们应如何评估它们的可靠性和结构？近年来，MAS在信号处理社区还相对较新。本文旨在提供一个正式框架，主要聚焦于MAS的两大核心方面：效果和安全性。", "innovation": "提出一种正式框架，集中阐述MAS效能与安全两方面的分析。探讨MAS是否真的增强了鲁棒性、适应性和性能，还是仅仅重新包装了如集成学习等已知的技术。研究智能体间互动如何可能放大或抑制系统漏洞。阐述MAS作为强大的抽象概念，扩展了经典工具如分布式估计和传感器融合的应用，使其适用于更高层次的政策驱动推理。", "conclusion": "通过数据科学技术自动化方面的实验，本文突显了MAS重塑信号处理系统设计和信任的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06740", "html_url": "https://arxiv.org/abs/2505.06740", "title": "基于边界引导的道路意识和物理可实现的轨迹预测", "title_en": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving", "authors": "Ahmed Abouelazm,Mianzhi Liu,Christian Hubschneider,Yin Wu,Daniel Slieter,J. Marius Zöllner", "background": "准确预测周围道路使用者的轨迹对于安全高效的自动驾驶至关重要。尽管深度学习模型已经提高了性能，但在防止离路预测和保证轨迹动力学可行性方面仍然面临着挑战。现有方法虽然引入了道路感知模块并施加了动力学约束，但缺乏可信度保证，且常常在复杂性和灵活性之间做出折衷。", "innovation": "本文提出了一种创新框架，将轨迹预测表达为受限回归问题，并受到允许的驾驶方向及其边界的指导。该方法利用代理的当前状态和高分辨率地图，定义有效的边界的范围，并通过训练网络学习左边界和右边界多边形之间的叠加路径来确保道路预测。为了确保可行性，模型预测加速度配置文件，以决定车辆沿这些路径行驶的距离，同时遵守动力学约束。", "conclusion": "我们针对Argoverse-2数据集与HPTR基线进行了评估。尽管我们的方法在基准指标上稍微降低了性能，但在最终位移误差上表现出显著改善，并消除了不可行的轨迹。此外，该提案方法在不常见操作和未见分布场景中具有更强的泛化能力，使得在对抗攻击下的离路率从66%降低到仅1%。这些结果突显了我们方法在生成可行且健壮的预测方面的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14765", "html_url": "https://arxiv.org/abs/2505.14765", "title": "基于深度学习的急诊留床患者数量预测以应对急诊 overcrowding", "title_en": "Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding", "authors": "Orhun Vural,Bunyamin Ozaydin,James Booth,Brittany F. Lindsey,Abdulaziz Ahmed", "background": "该研究旨在利用深度学习技术，提前六小时预测急诊部门（ED）的留床患者数量，而无需使用病人级别的信息。研究利用了急诊跟踪系统、住院情况、天气、节假日和当地活动等数据，并进行了综合特征工程处理，以提高预测准确性。研究结果表明，通过综合多种输入信息，可以更准确地预测急诊留床患者数量，从而支持医院的主动管理，预防急诊部门过度拥挤问题。", "innovation": "该研究提出了一种基于深度学习的框架，能够仅通过运营和上下文数据预测急诊部门六小时后的留床患者数量。研究采用了ResNetPlus、TSTPlus和TSiTPlus等多种深度学习模型，并使用Optuna进行训练和优化，TSTPlus模型取得了最好的预测效果。研究还展示了通过增加更广泛的数据输入，可以提高预测的准确性。", "conclusion": "研究结果表明，采用基于深度学习的方法能够准确预测急诊留床患者数量，包括极端时期，从而支持医院的主动管理。该研究强调了广泛数据输入的重要性，这种预测框架对于缓解急诊部门的过度拥挤问题具有实际应用价值。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22589", "html_url": "https://arxiv.org/abs/2503.22589", "title": "使用AI总结1952-2012年美国总统竞选电视广告视频", "title_en": "Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012", "authors": "Adam Breuer,Bryce J. Dietrich,Michael H. Crespin,Matthew Butler,J.A. Pryse,Kosuke Imai", "background": "近年来，美国总统竞选广告数据的收集和分析引起了广泛关注，但由于手动采集和标注的需求，许多研究者依赖于规模较小的数据子集。本文介绍了一个最大的且最为全面的美国总统竞选电视广告数据集，并且该数据集以数字格式提供了广泛的文本和高质量的摘要，以支持多种学术研究。目前，已经有大量的研究兴趣在于收集和分析美国总统竞选广告。", "innovation": "本研究设计了一种大规模并行化、基于AI的分析流水线，自动完成了准备、转录和总结视频的繁琐过程。该流水线被应用于本杰明·P·坎特政治广告档案的9,707份总统广告，并通过大量的人工评估验证了这些转录和摘要的质量达到了手动生成的同等水平。此外，还展示了这一数据的价值，通过一个应用跟踪了过去七十年总统选举中的当前焦点议题的起源与演变。", "conclusion": "本文的分析流水线和代码库还展示了如何使用LLM工具来为其他视频数据集获取高质量的摘要，从而为未来的学术研究提供支持。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07454", "html_url": "https://arxiv.org/abs/2506.07454", "title": "基于语言指导的层次规划与多机器人3D场景图执行", "title_en": "Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs", "authors": "Jared Strader,Aaron Ray,Jacob Arkin,Mason B. Peterson,Yun Chang,Nathan Hughes,Christopher Bradley,Yi Xuan Jia,Carlos Nieto-Granda,Rajat Talak,Chuchu Fan,Luca Carlone,Jonathan P. How,Nicholas Roy", "background": "本文介绍了一个多机器人系统，该系统结合了具有3D场景图的地图构建、定位、任务和运动规划（TAMP），以执行用自然语言表达的复杂指令。该系统构建了一个共享的3D场景图，包括用于多机器人场景图融合的开放式基于对象的地图。这种表示支持基于对象的地图视图不变重新定位以及通过3D场景图进行实时规划，使机器人团队能够推理其周围环境并执行复杂的任务。", "innovation": "该系统利用大型语言模型（LLM）将操作员意图翻译为规划域定义语言（PDDL）目标，借助共享的3D场景图上下文和机器人能力进行操作。文章提供了在大型户外环境中的真实任务上评估系统的性能结果。此外，该系统还允许机器人团队在执行复杂任务时进行实时、视图不变的重定位和规划。", "conclusion": "本文提出的方法对多机器人系统在大型户外环境中的执行复杂任务具有应用前景，展示了如何通过结合先进的语言理解技术、多机器人的3D场景图融合以及基于PDDL的规划来实现复杂任务。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09166", "html_url": "https://arxiv.org/abs/2505.09166", "title": "文本到图像生成中默认图像探索", "title_en": "An Exploration of Default Images in Text-to-Image Generation", "authors": "Hannu Simonen,Atte Kiviniemi,Jonas Oppenlaender", "background": "在文本到图像生成（TTI）的创造性实践中，图像是从文本提示生成的。然而，TTI模型被训练为始终生成输出，即使提示包含未知词汇。在这种情况下，模型可能会生成我们称为“默认图像”的图像：无论提示有多么无关，所产生的图像都非常相似。", "innovation": "本研究首次在Midjourney（一个流行的图像生成器）上对默认图像进行调查。我们提出了一个系统方法来创建触发默认图像的输入提示，并总结了初步实验和小型删减研究的结果。此外，我们还通过调查研究了默认图像如何影响用户满意度。", "conclusion": "我们的研究奠定了理解和默认图像在TTI中的基础，并指出了未来的挑战和研究方向。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05718", "html_url": "https://arxiv.org/abs/2506.05718", "title": "模型参数欧几里得范数之外的grokking", "title_en": "Grokking Beyond the Euclidean Norm of Model Parameters", "authors": "Pascal Jr Tikeng Notsawo,Guillaume Dumas,Guillaume Rabusseau", "background": "Grokking是一种在人工神经网络通过梯度方法优化后出现的现象，即网络在过拟合之后会出现延迟泛化。现有的研究显示，较小且非零的权重衰减可以诱导grokking。本文探讨了通过正则化方法，无论是显式还是隐式，可以导致grokking的出现。此外，文章还指出了增加模型的过度参数化可以使得在浅层网络中无法实现的grokking或反Grokkng（ungrokking）成为可能。进一步的研究表明，在模型向具有不同特性$P$的方向进行正则化时，欧几里得范数并不是可靠的泛化度量标准，且模型的泛化能力可能不受权重衰减的影响。最后，研究发现通过数据选择可以单独放大Grokkng现象，而固定其他超参数不变。", "innovation": "1. 利用显式或隐式的正则化方法可以诱导Grokkng现象。\n2. 过度参数化使得在深层网络中也能够实现Grokkng和反Grokkng，而在浅层网络中是不可能的。\n3. 欧几里得范数不是可靠的通用泛化度量标准，特别是在模型向不同的特性$P$进行正则化时。\n4. 仅通过数据选择可以放大Grokkng现象，而其他超参数保持不变。", "conclusion": "通过显式或隐式的正则化方法以及过度参数化，可以诱导Grokkng现象。正则化方法的选择及其对模型泛化能力的影响被详细探讨。此外，文章还强调了欧几里得范数在某些情况下不是可靠的泛化度量标准。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.04165", "html_url": "https://arxiv.org/abs/2505.04165", "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks", "title_en": "TS-SNN: Temporal Shift Module for Spiking Neural Networks", "authors": "Kairong Yu,Tianqing Zhang,Qi Xu,Gang Pan,Hongwei Wang", "background": "Spiking Neural Networks (SNNs)因其生物可行性及能效优势而受到越来越多人的关注，成为人工神经网络（ANNs）在神经形态计算应用中的有力替代品。SNNs能够利用神经元放电的精确时序来处理时间信息，但这同时带来了在保持低能耗条件下有效利用时间特征的挑战。因此，如何设计既高效又准确的SNN架构成为了一个亟待解决的问题。", "innovation": "引入了Temporal Shift (TS)模块，通过简单的移位操作将过去、现在和未来的尖锋特征结合在一个时间步内，有效地平衡了时间特征的利用与低能耗要求。此模块在模型中只需要一个可学习参数，加入残差连接机制来防止信息损失。TS-SNN在CIFAR-10/CIFAR-100/ImageNet基准测试上取得了领先性能，同时大大减少了时间步的使用，保持了低能耗。", "conclusion": "这项工作为开发高效的SNN架构迈出了重要的一步，TS-SNN以其简洁的设计实现了卓越的性能，这将促进SNN在实际应用中的发展与推广。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12003", "html_url": "https://arxiv.org/abs/2506.12003", "title": "升级或切换：我们是否需要为AI代理互联网构建下一代可信架构？", "title_en": "Upgrade or Switch: Do We Need a Next-Gen Trusted Architecture for the Internet of AI Agents?", "authors": "Ramesh Raskar,Pradyumna Chari,Jared James Grogan,Mahesh Lambe,Robert Lincourt,Raghu Bala,Aditi Joshi,Abhishek Singh,Ayush Chopra,Rajesh Ranjan,Shailja Gupta,Dimitris Stripelis,Maria Gorskikh,Sichao Wang", "background": "新兴的AI代理互联网挑战了为人类规模、反应性交互设计的现有网络基础设施。与传统网络资源不同，自治AI代理能够主动发起行动，维持持久状态，生成子代理，并直接与其他代理进行协商：这要求毫秒级的发现能力、即时的凭据撤销能力和超越当前DNS/PKI能力的加密行为证明。现有基础设施在DNS传播时间、证书撤销能力和IPv4/IPv6地址分配方面存在关键不足。", "innovation": "本文分析了是否应该升级现有基础设施或将实施专门为自治代理设计的索引结构。文中识别了DNS传播延迟、证书撤销无法扩展到数万亿实体以及IPv4/IPv6地址不足以支持代理规模路由等关键失败点。提出了三种解决方案：升级路径、切换选项和混合索引/注册表。通过类比从拨号到宽带的过渡，研究表明代理需求构成了质的而不是量的改变。", "conclusion": "我们的分析表明，混合策略将逐渐出现，以集中索引关键代理并为特定用例构建分布式网络。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02358", "html_url": "https://arxiv.org/abs/2507.02358", "title": "Hita: 全局 tokenizer 用于自回归图像生成", "title_en": "Hita: Holistic Tokenizer for Autoregressive Image Generation", "authors": "Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi", "background": "现有的自回归图像生成模型通过逐步生成视觉标记，限制了其捕捉标记序列间整体关系的能力。此外，大多数视觉标记器将局部图像片段映射到潜在标记中，导致全局信息受限。", "innovation": "引入了 Hita，一种新的用于自回归图像生成的全局标记器。Hita 引入了一种全局到局部的标记方案，使用可学习的全局查询和局部片段标记。Hita 采用两种关键策略来更好地与自回归生成过程对齐：1) 以全局标记开始，随后是片段级标记，并使用因果注意力保持对先前标记的意识；2) 在解码器喂入去量化标记前采用轻量级融合模块，控制信息流并优先选用全局标记。", "conclusion": "广泛的实验表明，Hita 加快了自回归生成器的训练速度，并优于使用普通标记器训练的生成器，在 ImageNet 基准上达到 2.59 FID 和 281.9 IS。全局表示的详细分析突显了它捕捉全局图像属性（如纹理、材料和形状）的能力。此外，Hita 还表现出色地实现了零样本风格转移和图像修复。代码可在提供的链接中找到。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02827", "html_url": "https://arxiv.org/abs/2507.02827", "title": "USAD：基于时空注意机制的扩散模型端到端人体活动识别", "title_en": "USAD: End-to-End Human Activity Recognition via Diffusion Model with Spatiotemporal Attention", "authors": "Hang Xiao,Ying Yu,Jiarui Li,Zhifan Yang,Haotian Tang,Hanyu Liu,Chao Li", "background": "人体活动识别（HAR）的主要目标是从传感器数据中推断出人类正在进行的动作，该任务在健康监测、安全保障和体育分析等领域有着广泛的应用。尽管进行了大量的研究，HAR仍面临标注数据稀缺、特征提取不足以及轻量级设备上模型性能不佳等关键挑战。", "innovation": "本文提出了一种综合优化方法，以多注意力交互机制为核心。首先，利用无监督的统计引导扩散模型进行数据扩充，解决标注数据稀缺和类间不平衡问题。其次，设计了多分支时空交互网络，通过并行的3*3、5*5和7*7卷积核捕获序列数据的多尺度特征，并引入时间注意力机制和空间注意力机制优化模型性能。进一步引入跨分支特征融合单元以提升整体特征表示能力。最后，集成适应性多损失函数融合策略，实现损失权重动态调整和整体模型优化。", "conclusion": "实验结果表明，所提出的无监督数据增强时空注意力扩散网络（USAD）在WISDM、PAMAP2和OPPORTUNITY三个公开数据集上的准确率分别为98.84%、93.81%和80.92%，显著优于现有方法。此外，在嵌入式设备上的实际部署验证了所提出方法的有效性和可行性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05416", "html_url": "https://arxiv.org/abs/2507.05416", "title": "EmissionNet: 农业空气质量污染预报", "title_en": "EmissionNet: Air Quality Pollution Forecasting for Agriculture", "authors": "Prady Saligram,Tanvir Bhathal", "background": "农业排放的空气污染是环境和公共卫生挑战的重要来源，但常被忽视。传统的空气质量预测模型依赖于物理方法，难以捕捉复杂且非线性的污染物相互作用。", "innovation": "本文探索了通过评估流行的架构并提出两种新的深度学习架构，EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，来预测农业排放（N₂O）。这些模型利用卷积和基于变换器的架构，从高分辨率排放数据中提取时空依赖性。", "conclusion": "通过提出创新的EmissionNet及其变体模型，研究为农业排放预测提供了新的方法，能够更准确地预测N₂O排放，并有望改善农业相关的空气质量预测。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22511", "html_url": "https://arxiv.org/abs/2506.22511", "title": "使用生成型人工智能点亮夜间可见光", "title_en": "Lighting the Night with Generative Artificial Intelligence", "authors": "Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang", "background": "地球静止轨道卫星的可见光反射率数据对于气象观测至关重要，对于天气监测和预报具有重要的作用。但是，由于夜间缺少可见光，无法使用可见光反射率数据进行全天候连续观测。", "innovation": "本研究首次采用了生成扩散模型，基于FY4B地球静止轨道卫星上的高级地球静止辐射成像仪（AGRI）的多波段热红外亮度温度数据，开发了一个高精度的夜间可见光反射率生成模型——Reflectance Diffusion (RefDiff)，能够生成0.47微米、0.65微米和0.825微米波段的夜间可见光反射率。与经典模型相比，RefDiff不仅通过集合平均显著提高了精度，还提供了不确定性估计。", "conclusion": "此研究在夜间生成可见光反射率方面取得了实质性进展，夜间可见光数据的应用潜力扩大。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05730", "html_url": "https://arxiv.org/abs/2507.05730", "title": "热成像异常检测方法：综述与比较研究", "title_en": "Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study", "authors": "Aayushma Pant,Arbind Agrahari Baniya,Tsz-Kwan Lee,Sunil Aryal", "background": "高光谱图像是由数百个连续光谱波段组成的大规模数据集，可以实现材料和表面的详细分析。高光谱异常检测（HAD）是指在没有先验信息的情况下，识别和定位高光谱数据中的异常目标的技术。这项技术在农业、国防、军事监视和环境监测等领域取得了显著进展，但由于现有的高光谱异常检测方法存在高计算复杂性、噪声敏感性及跨不同数据集推广困难等问题，其仍面临挑战。因此，本文对各种高光谱异常检测技术进行了全面比较。", "innovation": "本文将现有的高光谱异常检测技术分为统计模型、表示法方法、经典机器学习方法和深度学习模型四类。通过使用不同的性能指标（如ROC、AUC及分离度图）在17个基准数据集上评估这些方法，分析检测精度和计算效率等，并指出了未来研究的方向。研究发现，深度学习模型在检测准确性方面表现最佳，而统计模型则在所有数据集中的速度方面表现出色。", "conclusion": "本文为研究人员和从业人员提供了高光谱异常检测技术的宝贵见解，有助于推进该领域的研究和发展。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01381", "html_url": "https://arxiv.org/abs/2507.01381", "title": "带扩散策略的分布软演员-评论家算法", "title_en": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": "Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li", "background": "强化学习在处理复杂控制任务方面已被证明非常有效。传统方法通常使用单模分布，如高斯分布，来建模价值函数分布，但这种单模分布容易导致价值函数估计偏差，影响算法性能。本文介绍了DSAC-D算法（分布式软演员-评论家算法结合扩散策略），以解决在估计价值函数偏差和获得多模策略表示时面临的挑战。", "innovation": "提出了DSAC-D算法，通过引入策略熵和价值分布函数构建了一种多模分布策略迭代框架，能够收敛于最优策略。利用扩散模型反向采样的方式生成奖励样本集，构造了能够准确描述多峰分布的扩散价值网络。基于此，提出了在价值网络和策略网络上共享扩散过程的分布强化学习算法。MuJoCo测试任务表明，该算法不仅学习到了多模策略，而且在所有9个控制任务上的表现达到了现有主流算法的最佳水平，显著抑制了估计偏差，总平均回报提高超过10%。真实车辆测试结果表明，DSAC-D能够准确刻画不同的驾驶风格的多模分布，扩散策略网络能够刻画多模轨迹。", "conclusion": "DSAC-D算法在所有9个控制任务中均表现出色，不仅学习了多模策略，而且显著提高了总平均回报，相比现有主流算法有显著提升。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06892", "html_url": "https://arxiv.org/abs/2507.06892", "title": "挤干海绵：提高大型语言模型离策略强化调优效率", "title_en": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model", "authors": "Jing Liang,Hongyao Tang,Yi Ma,Jinyi Liu,Yan Zheng,Shuyue Hu,Lei Bai,Jianye Hao", "background": "强化学习（RL）已被证明能够提高大型语言模型（LLMs）的推理能力。然而，现有的大多数强化微调（RLF）方法本质上是on-policy RL，这意味着过去学习过程中生成的数据没有被充分利用。这种数据利用不充分导致了显著的计算成本和时间成本，极大地限制了经济和高效的扩展能力。", "innovation": "提出了重新定义离策略RL的方法ReMix，其核心是在保留on-policy RFT方法如PPO和GRPO的同时，利用离策略数据。ReMix的主要创新在于：（1）混合策略近端策略梯度（Mix-policy PPO），提高了更新到数据的比例，以实现高效训练；（2）KL-凸政策约束，以平衡稳定性和灵活性；（3）政策转生，实现在高效的早期学习和稳定的渐近改进之间的无缝过渡。此外，研究表明，离策略数据的不匹配会导致偏好较短的响应，以及在严重离策略性存在时自我反省行为的崩溃模式。", "conclusion": "实验结果显示，ReMix在五个数学推理基准（AIME'24, AMC'23, Minerva, OlympiadBench, MATH500）上的1.5B模型和7B基模型表现出了SOTA水平的性能，在响应采样量和训练步骤方面均大幅降低了训练成本，达到30倍到450倍的效率提升。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03222", "html_url": "https://arxiv.org/abs/2507.03222", "title": "层5神元中增益神经调制的作用", "title_en": "The role of gain neuromodulation in layer-5 pyramidal neurons", "authors": "Alejandro Rodriguez-Garcia,Christopher J. Whyte,Brandon R. Munn,Jie Mei,James M. Shine,Srikanth Ramaswamy", "background": "生物和人工的学习系统都面临着稳定性与可塑性之间的矛盾。在大脑中，乙酰胆碱和去甲肾上腺素等神经递质通过调节神经元的增益和抑制性门控，实现电路的分离与整合的平衡。层5的锥体神经元因接收来自觉醒系统丰富的胆碱能和去甲肾上腺素投射而成为理解这些动态的关键。当远端树突信号与反向传播的动作电位同时发生时，钙平台使一个树突动作电位引发的局部突触活动演化为树突树的高增益爆发，而抑制性中间神经元的抑制塑造了输出。这些特性使得层5神经元成为增益可调的放大器，将神经递质的信号转换为灵活的皮层活动。", "innovation": "论文开发了一种两部分的Izhikevich模型来模拟层5锥体神经元，并通过高斯连接性和突触定时依赖性可塑性(PSTDP)将单细胞索马淀粉样蛋白(SOM)和帕尔凡丁(PV)中间神经元连接起来。通过增强树突驱动或加强耦合提高增益，并通过树突目标抑制降低增益，从而凋节神经元的输出。纸张还表明，爆发式放电加速了PSTDP，支持快速的突触重组和灵活性。此外，研究表明，由神经递质驱动的短暂增益脉冲可以作为适应性的双时间尺度优化机制，有效调节突触权重更新。", "conclusion": "论文揭示了层5锥体神经元中的增益调节机制，并展示了这种机制如何通过调整突触可塑性来实现皮层活动的灵活性。研究表明，短时的增益脉冲可以作为适应性的双时间尺度优化机制，进而调整突触权重。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07393", "html_url": "https://arxiv.org/abs/2507.07393", "title": "KeyRe-ID：基于关键点指导的视频中人体重识别中具有部件感知表示的方法", "title_en": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos", "authors": "Jinseong Kim,Junghoon Song,Gyeongseon Baek,Byeongjoon Noh", "background": "在使用视频进行人体重识别（Re-ID）的任务中，提升时空特征表示一直是研究的重点。现有的方法多依赖于全局特征或局部特征，但未能有效结合两者优势，以实现更准确的身份识别。因此，如何通过高效地融合全局和局部信息，提升时空特征表示的准确性，成为亟待解决的问题。", "innovation": "本文提出了一种名为KeyRe-ID的关键点导向视频人体重识别框架，包括全局分支和局部分支。全局分支通过基于Transformer的时空聚合捕捉整体身份语义；局部分支基于关键点动态分割身体区域，生成细粒度、零件感知的特征。该方法在MARS和iLIDS-VID基准数据集上取得了卓越性能，验证了其在提高时空特征表示上的有效性。", "conclusion": "实验结果表明，KeyRe-ID在MARS数据集上达到了91.73%的mAP和97.32%的Rank-1准确率，在iLIDS-VID数据集上达到了96.00%的Rank-1和100.0%的Rank-5准确率，表明了该框架在视频人体重识别中的创新性和有效性。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07505", "html_url": "https://arxiv.org/abs/2507.07505", "title": "幻觉站点：关于基于Transformer的语言模型的一些基本局限性", "title_en": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models", "authors": "Varin Sikka,Vishal Sikka", "background": "随着AI领域内基于Transformer的语言模型广泛应用，人们对这些模型的能力界限产生了兴趣，特别是所谓的幻觉现象——即当模型在某些主题上受到提示时，会提供虚假、事实错误或无意义的信息。此外，人们越来越关注语言模型的自主应用，即使用语言模型创建能够自主或半自主执行各种任务的代理。这些任务可能具有实际应用价值。因此，理解语言模型能够和不能执行的任务类型变得尤为重要。", "innovation": "本文从语言模型推理的计算复杂度角度探讨了模型能力的局限性。研究表明，语言模型无法处理超出一定复杂度的计算和自主任务，也无法验证复杂度高于一定水平的任务准确性。", "conclusion": "我们展示了这种工作的后果，并讨论了一些由此引发的后果。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08012", "html_url": "https://arxiv.org/abs/2507.08012", "title": "RepeaTTS：通过重复微调实现特征发现", "title_en": "RepeaTTS: Towards Feature Discovery through Repeated Fine-Tuning", "authors": "Atli Sigurgeirsson,Simon King", "background": "现有的基于提示的文本转语音模型可以让用户通过自然语言指令控制不同方面的语音，如语速和感知性别。这些模型虽然用户友好，但存在两个主要局限：控制受到有限的、训练时模型可见的声学特征限制，而灵活性过高的问题则表现在相同的输入会带来不可控的变异，这些变异会影响生成样本的统计特性。", "innovation": "本文提出了一种新颖的微调方案，同时解决了上述两个问题。通过成分分析数千个合成样本来确定输出变异中的潜在特征，并将其作为新的标签进行二次微调。这一方法被应用于两个基于富有表现力的冰岛语音数据集训练的模型，一个带有情感揭露，另一个没有。在带情感揭露的模型中，该方法不仅改善了连续特征，还增加了离散特征的控制，从而提升模型的整体可控性。", "conclusion": "该研究表明通过反复微调可以识别出模型中不可控的变异特征，并将其纳入二次微调流程，从而提升了文本到语音模型的多方面可控性。该方法验证了其在实现均匀的总体可控性方面的有效性，尤其是在带有情感表达的模型中表现更为显著。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07668", "html_url": "https://arxiv.org/abs/2507.07668", "title": "使用预测不确定性估计学习强子态的极点结构", "title_en": "Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation", "authors": "Felix Frohnert,Denny Lane B. Sombillo,Evert van Nieuwenburg,Patrick Emonts", "background": "强子谱学中，匹配理论预测与实验数据仍然是一个核心挑战。特别地，识别新的强子态很困难，因为阈值附近的奇异信号可能由多种物理机制产生。在这种背景下，极点结构是关键诊断指标，但由于不同配置可以产生相似签名，特别是在质量阈值附近由于缺乏分析控制使得映射过程特别模糊。", "innovation": "本文引入了一种考虑不确定性的人工智能方法，用于分类$S$-矩阵元的极点结构。这种方法基于分类链的集合，能够提供典型的和随机的不确定性估算。通过基于预测不确定性进行拒绝准则的应用，该方法在验证准确性接近95%的同时，仅丢弃少量高不确定性预测。模型在具有已知极点结构的合成数据上训练，并能推广到先前未见过的实验数据，包括LHCb观察到的$P_{c\bar{c}}(4312)^+$态的增强。此模型推断出四极点结构，代表了在更高通道虚拟状态极点非零宽度的情况下，确实存在着真正的紧凑五夸克。", "conclusion": "该框架在评估特定状态时具有广泛适用性，并为散射振幅中的极点结构推断提供了一种可扩展工具。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20893", "html_url": "https://arxiv.org/abs/2506.20893", "title": "关于有效类别遗忘输出分布重新加权的必要性", "title_en": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "authors": "Yian Wang,Ali Ebrahimpour-Boroojeny,Hari Sundaram", "background": "对于训练好的模型而言，忘记特定类别是确保用户删除权利和减轻有害或偏见预测的关键。完全重新训练成本高昂，现有的遗忘方法在预测遗忘类别的样本时无法准确复制重新训练后的模型行为。作者通过设计一种针对会员推理攻击的变体MIA-NN来证明这一点，并且提出了通过简单地重新分配预测样本中的概率质量来抵抗这种攻击的方法。", "innovation": "作者提出了一个名为RWFT的输出重加权遗忘方法，这是一个轻量级技术，可以删除训练分类器中的整个类别，而无需重新训练。同时引入了一个新的基于预测概率总变异距离的度量标准，用于量化残留泄漏，从而防止未来的方法受到这种新攻击的影响。本文通过与现有基准的广泛实验，展示了其方法在使用之前工作的评估标准之一和本文提出的新标准方面的效果与完全重新训练相当，甚至在新的总变异距离指标上提高了111.45%。这表明该方法在遗忘类别方面具有更高的有效性和鲁棒性。", "conclusion": "本文的研究表明，对于有效类别遗忘而言，输出分布重新加权是必要的。该方法不仅在标准评价指标上达到了与完全重新训练相当的效果，还在作者提出的新评价指标上提供了显著的改进。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06743", "html_url": "https://arxiv.org/abs/2505.06743", "title": "TPK: 可信任的融合先验知识的轨迹预测以提高解释性和动力学可行性", "title_en": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility", "authors": "Marius Baden,Ahmed Abouelazm,Christian Hubschneider,Yin Wu,Daniel Slieter,J. Marius Zöllner", "background": "轨迹预测对于自动驾驶至关重要，它使车辆能够通过预见周围道路使用者的移动来安全导航。然而，当前的深度学习模型在可信度方面经常不足，因为它们的预测可能在物理上不可行且不合逻辑。为使预测更具可信度，最近的研究引入了先验知识，如使用社会力模型来建模交互，以及使用动力学模型来确保物理现实性。但是，这些方法倾向于使用适合车辆或行人的先验知识，并不能很好地推广到包含混合代理类别的交通环境中。", "innovation": "本文提出了一种方法，通过结合车辆、行人和骑自行车者的交互和动力学先验知识，并使用特定于类别交互层来捕捉代理行为差异，从而增强预测的可信度。此外，引入了基于规则的交互重要性得分DG-SFM，指导交互层，并提出了适合所有类别代理的动力学模型，特别是在行人动力学模型方面的创新，以确保预测的物理可行性。", "conclusion": "实验表明，该方法提高了交互的可解释性，并且与不准确的预测存在相关性。尽管结合动力学模型略微降低了准确率，但它有效避免了数据集和基准模型中存在的不直观的轨迹预测，因此该方法提高了轨迹预测的可信度，因为它的交互推理是可解释的，且预测遵守物理学规则。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07930", "html_url": "https://arxiv.org/abs/2507.07930", "title": "探究专家对AI辅助公共演讲培训的看法", "title_en": "Probing Experts' Perspectives on AI-Assisted Public Speaking Training", "authors": "Nesrine Fourati,Alisa Barkar,Marion Dragée,Liv Danthon-Lefebvre,Mathieu Chollet", "background": "公众演讲是一项重要的专业技能，但许多人仍对此感到极大的焦虑。传统的培训依赖于专家的指导，近年来AI技术的进步导致出现了新型的商业化自动公共演讲反馈工具。然而，大多数研究集中在原型上而非商业化应用，目前对公共演讲专家对这些工具的看法知之甚少。", "innovation": "研究涉及16位半结构化访谈和2个焦点小组，探讨公共演讲专家对商业化AI辅助训练工具的看法，并提出改进意见。专家们认可AI工具在处理培训重复和技巧性任务方面的价值，但指出目前工具存在的关键问题，强调个性化、易懂、精心选择的反馈和清晰的指令设计的必要性。总体而言，他们支持结合传统辅导与AI支持练习的混合模式。", "conclusion": "专家们认为AI工具在处理培训中的重复和技术方面有价值，但需要改善个性化、易理解、精选反馈和清晰的指导设计，并支持传统培训与AI辅助练习相结合的混合模式。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07460", "html_url": "https://arxiv.org/abs/2507.07460", "title": "Objectomaly: 对质和边界精确度的结构一致性的物体感知优化分割", "title_en": "Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision", "authors": "Jeonghoon Song,Sunghun Kim,Jaegyun Im,Byeongjoon Noh", "background": "对于自动驾驶等安全敏感应用而言，异常分布（Out-of-Distribution, OoD）分割是至关重要的。现有的基于掩码的方法往往会在边界精确性、物体内部异常评分的一致性以及背景噪声引起的虚假阳性等方面存在问题。", "innovation": "本文提出了一种名为Objectomaly的物体感知优化分割框架，该框架结合了物体级别的先验知识。Objectomaly框架包括三个阶段：首先是使用现有OoD主干的粗粒度异常评分（CAS），其次是利用SAM生成的实例掩码进行物体级别评分归一化的对象感知得分校正（OASC），最后是通过拉普拉斯滤波和高斯平滑进行轮廓细化的精确边界细节（MBP）。通过在关键的异常分布分割基准测试中的表现，证明了该方法的有效性。", "conclusion": "Objectomaly在主要的异常分布分割基准测试中达到了最先进的性能，包括SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly，在像素级别和组件级别的度量标准上均有显著提升。消融研究和真实世界驾驶视频的定性结果显示该方法具有鲁棒性和通用性。代码将在发表后开源。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06850", "html_url": "https://arxiv.org/abs/2507.06850", "title": "LLM代理攻击的黑暗面：通过代理人工智能系统的信任边界实现完全计算机接管", "title_en": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover", "authors": "Matteo Lupinacci,Francesco Aurelio Pironti,Francesco Blefari,Francesco Romeo,Luigi Arena,Angelo Furfaro", "background": "大语言模型（LLM）代理和多代理系统在全球范围内的迅速采用，带来了自然语言处理和生成能力的空前提升。但同时，这些系统也引入了前所未有的安全漏洞，这些问题超越了传统的提示注入攻击。研究显示，攻击者可以利用代理AI系统内部的信任边界三种不同的攻击面——直接提示注入、RAG后门攻击和跨代理信任利用——迫使流行的LLM（包括GPT-4o、Claude-4和Gemini-2.5）在受害机器上自主地安装和执行恶意软件。这一研究揭示了LLM在不同攻击面上的漏洞层级，而大多数模型都存在基于上下文的安全行为，这些行为可能会导致可利用的安全盲点。", "innovation": "该研究首次全面评估了LLM代理作为攻击向量的能力，通过滥用代理AI系统内部的信任边界实现了完全计算机的接管。研究发现，利用直接提示注入、RAG后门攻击和跨代理信任利用三种方式，大部分LLM都存在被攻击的可能性。尤其值得注意的是，研究揭示了未被直接恶意指令阻拦的LLM依然会遵从来自同伴代理的相同命令执行恶意负载，这暴露出当前多代理安全模型中的根本缺陷。", "conclusion": "在此项研究中，只有5.9%的模型能够抵抗所有攻击向量。大多数模型表现出基于上下文的安全行为，这形成了可被攻击者利用的安全盲点。该研究强调了提高对LLM安全威胁的意识和进行相关研究的必要性，展示了一个新的网络安全威胁框架，即AI工具本身成为高度复杂的攻击手段。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08017", "html_url": "https://arxiv.org/abs/2507.08017", "title": "大型语言模型中理解的机制指标", "title_en": "Mechanistic Indicators of Understanding in Large Language Models", "authors": "Pierre Beckmann,Matthieu Queloz", "background": "该论文探讨了机制可解释性（MI）的最新发现，MI是研究大型语言模型（LLMs）内部运行机制的领域。研究发现，LLMs不仅依赖于表面统计数据，还具备深层次的推理能力。在此背景下，本文旨在提供MI的可读性总结，整合发现，并提出一种新的理论框架来思考机器的理解能力。", "innovation": "本文创新性地提出了机器理解的三层概念：概念理解、当前状态理解、原则性理解。此外，作者还引入“平行机制”现象，指出尽管LLMs表现出某种程度的理解能力，但其认知架构与人类不同，当前讨论应从LLMs是否理解转向研究其运作机制的独特之处。", "conclusion": "本文探讨了LLMs在理解上的新发现，提出了机器理解的不同层次划分，并强调应从LLMs是否理解转向探讨其运作方式。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08015", "html_url": "https://arxiv.org/abs/2507.08015", "title": "评估FinGPT模型在金融NLP应用中的能力和局限性", "title_en": "Assessing the Capabilities and Limitations of FinGPT Model in Financial NLP Applications", "authors": "Prudence Djagba,Chimezie A. Odinakachukwu", "background": "该研究评估了FinGPT，一种专门针对金融领域的语言模型，在六项关键的自然语言处理（NLP）任务中的表现：情感分析、文本分类、命名实体识别、金融问答、文本总结和股票市场预测。这些评估使用了特定于金融的数据集来检验FinGPT的能力和局限性，特别是在真实世界金融应用中的表现。研究表明，FinGPT在情感分析和主题分类等分类任务中表现出色，经常能达到与GPT-4相当的性能。然而，在要求推理和生成任务，如金融问答和总结方面，其表现明显较低。与GPT-4和人类基准的比较发现，特别是在数值准确性和复杂推理方面的性能差距尤为显著。总体而言，研究结果表明，尽管FinGPT对某些结构性金融任务有效，但它尚未成为一个全面的解决方案。这项研究提供了一个有用的标准，以指导未来的研究，并强调了金融语言模型中架构改进和领域特定优化的必要性。", "innovation": "创新之处在于评估了专门针对金融领域的新语言模型FinGPT在多种金融相关的自然语言处理任务中的表现，并与GPT-4和其他基准进行了比较。研究结果揭示了FinGPT在不同任务中的优势和不足，为未来的模型改进提供了方向。", "conclusion": "结论表明，虽然FinGPT在某些特定的结构性金融任务中表现良好，但它并非一个全面的解决方案，特别是在需要复杂推理和生成的金融任务中存在明显不足。该研究为未来在此领域的工作提供了重要基准，并强调了架构改进和金融领域特定优化的重要性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08020", "html_url": "https://arxiv.org/abs/2507.08020", "title": "通过嵌入空间毒性衰减规避大型语言模型的安全对齐", "title_en": "Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation", "authors": "Zhibo Zhang,Yuxi Li,Kailong Wang,Shuai Yuan,Ling Shi,Haoyu Wang", "background": "大型语言模型（LLMs）在医疗、教育和网络安全等领域取得了显著成功，但这也带来了显著的安全风险，特别是通过嵌入空间 poisoning 的细微攻击方式，对手可以操纵输入数据的内部语义表示来避开安全对齐机制。尽管先前的研究探讨了通用扰动方法，但 LLM 在嵌入级别上的安全对齐动态仍不充分理解，这导致了更多有针对性和准确的对抗性扰动技术没有得到充分研究，这些技术对安全构成了严重威胁。因此，对这些技术的深入研究是必要的。这就引出了提出 ETTA（嵌入变换毒性衰减）框架，旨在通过线性变换识别和减弱毒性敏感维度，实现攻击成功，同时保持语义连贯性，无需对模型进行微调或访问训练数据。", "innovation": "提出了ETTA（嵌入变换毒性衰减）框架，它通过线性变换识别和减弱 toxicity 敏感维度，从而规避大型语言模型的安全对齐，同时保持语义连贯性，无需微调模型或访问训练数据。ETTA 在五个具有代表性的开源大模型上评价，取得了88.61%的高平均攻击成功率，优于最佳基线11.34%，并在安全增强模型（如指令微调防御）上也表现出良好的通用性。这突显了当前对齐策略中的关键漏洞，强调了嵌入感知防御的重要性。", "conclusion": "ETTA框架表明存在现有对齐策略未充分考虑的关键漏洞，强调了应对嵌入级别的毒性攻击的必要性，并为未来的研究提供了方向。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06261", "html_url": "https://arxiv.org/abs/2507.06261", "title": "Gemini 2.5: 推动前沿创新，先进推理、多模态、长语境与新一代智能能力", "title_en": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "authors": "Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju", "background": "介绍了Gemini 2.X模型家族，包括Gemini 2.5 Pro、Gemini 2.5 Flash、Gemini 2.0 Flash和Flash-Lite模型。这些模型在编码、推理和处理视频方面的性能各异，用户可以根据性能需求和预算选择不同层级的模型。Gemini 2.5 Pro为该系列中的最强大版本，具备跨越时代的编码和推理能力，并且提升了多模态理解和视频处理能力，能够处理长达3小时的视频内容。Gemini 2.5 Flash和Gemini 2.0 Flash/Lite模型则分别在低功耗和低成本下提供了优秀的推理功能和高编码性能，从而满足不同场景下的需求。对于构建复杂的智能代理问题解决能力，Gemini 2.X模型系列能够覆盖模型能力与成本之间的整个帕累托前沿，为用户探索极限提供可能性。", "innovation": "Gemini 2.5 Pro在编码和推理方面达到了目前的领先水平，同时具备出色的多模态理解和视频处理能力，能处理长达3小时的视频。Gemini 2.5 Flash提供了在最低功耗和延迟条件下优秀的推理能力，且成本远低于其他版本。Gemini 2.0 Flash和Flash-Lite则通过高效、低延迟的方式来保证高性能，综合来看，Gemini 2.X系列模型覆盖了模型能力和成本之间的整个帕累托前沿，提供了从低至高不同层次的智能解决方案。", "conclusion": "Gemini 2.X系列模型提供了在模型性能、成本和延迟方面从高到低的不同选择，并且通过结合长语境、多模态和推理能力，解锁了新的智能代理工作流程，扩大了复杂智能代理问题解决能力的边界。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08013", "html_url": "https://arxiv.org/abs/2507.08013", "title": "MedicalBERT: 采用预训练BERT模型增强生物医学自然语言处理", "title_en": "MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model", "authors": "K. Sahit Reddy,N. Ragavenderan,Vasanth K.,Ganesh N. Naik,Vishalakshi Prabhu,Nagaraja G. S", "background": "近年来，自然语言处理（NLP）的进步主要是由如BERT，RoBERTa，T5和GPT等预训练语言模型推动的。虽然这些模型在理解和处理复杂文本方面表现出色，但生物医学文献中特有的领域术语和其他特性使得Word2Vec和双向长短期记忆（Bi-LSTM）等模型无法完全加以处理。尽管GPT和T5可以通过捕捉上下文来解析文本，但对于需要双向理解的任务来说它们依然存在不足，而BERT模型能够处理这类任务。", "innovation": "我们提出了一种名为MedicalBERT的预训练BERT模型，它被训练在一个庞大的生物医学数据集上，并配备了特定的领域词汇表，以增强对生物医学术语的理解。此外，该模型还经过优化和微调，以应对包括命名实体识别、关系抽取、问答、句子相似性和文档分类在内的多种任务。我们使用包括F1分数、准确率和皮尔逊相关系数在内的性能指标展示了MedicalBERT在各种任务上的高效性，并表明MedicalBERT比BioBERT、SciBERT和ClinicalBERT等其他BERT基线模型在大多数基准上都有更好的表现，且在所有任务中平均高出了5.67%。", "conclusion": "这项工作强调了利用预训练BERT模型进行生物医学NLP任务的潜力，并展示了迁移学习技术在捕捉领域特定信息方面的效果。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08029", "html_url": "https://arxiv.org/abs/2507.08029", "title": "更好的合作：评估AI辅助招聘的好处", "title_en": "Better Together: Quantifying the Benefits of AI-Assisted Recruitment", "authors": "Ada Aka,Emil Palikot,Ali Ansari,Nima Yazdani", "background": "人工智能（AI）在招聘中的应用越来越普遍，然而量化其对招聘效率和候选人筛选过程影响的实证证据仍然有限。本文通过随机分配37,000名申请人为初级开发职位，分别进入传统的招聘流程（简历筛选后由人进行选择）和包含初步AI驱动的结构化视频面试的AI辅助招聘流程，来量化AI在招聘中的影响。", "innovation": "研究引入了一种新的实验设计，即将AI辅助的招聘流程与传统的招聘流程进行对比，对比结果显示，采用AI辅助招聘流程的候选人最终获得录用的比例更高，且能更有效地帮助找到新的工作机会。实验还通过分析AI生成的面试记录来进一步探讨其在决策中的具体应用和潜在影响因素。", "conclusion": "研究发现AI系统倾向于选择更年轻、经验较少且缺乏高级证书的候选人。此外，AI技术在招聘决策中的应用对于了解其对招募和人才获取的影响具有重要意义，但同时也需要注意其可能带来的负面效应。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08014", "html_url": "https://arxiv.org/abs/2507.08014", "title": "在野对话的大规模分析揭示了大语言模型 jailbreak 复杂性的边界", "title_en": "Mass-Scale Analysis of In-the-Wild Conversations Reveals Complexity Bounds on LLM Jailbreaking", "authors": "Aldan Creo,Raul Castro Fernandez,Manuel Cebrian", "background": "随着大语言模型（LLMs）的广泛应用，了解 jailbreak 策略的复杂性及其演变对于 AI 安全至关重要。本文通过对超过200万种真实对话的大规模实证分析，揭示了这些对话的 jailbreak 复杂性，涉及各种专用 jailbreak 社区和普通聊天机器人的平台。", "innovation": "本文使用多种复杂性度量标准，包括概率措施、词汇多样性、压缩比和认知负荷指标，发现 jailbreak 尝试的复杂性并未显著高于普通对话，这在专门的 jailbreak 社区和个人用户群体中都是一致的。时间分析显示用户攻击的毒性和复杂性保持稳定，而助手响应的毒性有所下降，表明安全机制正在改进。复杂性分布不存在幂律关系进一步显示 jailbreak 发展存在自然限制。", "conclusion": "研究结果挑战了攻击者与防御者之间不断升级的军备竞赛的主流观点，反而表明大语言模型的安全进化受到人类创意思维的约束，而防御措施则继续进步。结果强调了学术界在披露 jailbreak 方面的关键信息风险，因为更高级的攻击可能在防护适应之前破坏当前的平衡状态，从而引起广泛危害。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08027", "html_url": "https://arxiv.org/abs/2507.08027", "title": "令人惊讶，他们都偏左 — 分析当前LLM的政治倾向", "title_en": "\"Amazing, They All Lean Left\" -- Analyzing the Political Temperaments of Current LLMs", "authors": "W. Russell Neuman,Chad Coleman,Ali Dasdan,Safinah Ali,Manan Shah,Kund Meghani", "background": "近期的研究揭示了大多数商用大型语言模型（LLMs）在伦理和政治响应上表现出的一贯的自由主义倾向，但其背后的原因及由此带来的影响仍不明确。本文系统地研究了七种流行的LLMs——OpenAI的GPT-4、Anthropic的Claude Sonnet 4、Perplexity的Sonar Large、Google的Gemini 2.5 Flash、Meta AI的Llama 4、Mistral 7b Le Chat和High-Flyer的DeepSeek R1——使用多元化的研究方法，包括道德根基理论、12项成熟的政治理论量表和一种新的政治争议指数，揭示了这些模型普遍表现出的偏向自由主义的价值观。", "innovation": "本文采用了多元化的研究方法，结合道德根基理论、12项成熟的政治理论量表和一种新的政治争议指数，系统地分析了七种流行的LLMs的政治倾向，揭示了它们普遍表现出的偏向自由主义的价值观，并进一步分析了这一倾向背后的原因。", "conclusion": "研究发现，这一‘自由主义倾向’并非编程错误或程序开发者的个人偏好，而是训练于以民主权利为重点的讨论中产生的一种涌现属性。最终提出，LLMs可能间接反映了约翰·罗尔斯著名的无知之幕哲学理念，反映了不以个人身份或利益为基础的道德立场。虽然这种‘左倾’可能会引发关切，但并不意味着对民主讨论构成威胁，反而可能会提供一种新的视角来审视集体推理。此外，无论是基础模型还是微调后的模型，微调普遍增加了自由主义的倾向，这种影响通过自我报告和实证测试得到了证实。"}
{"llm_update_time": "20250714", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07532", "html_url": "https://arxiv.org/abs/2507.07532", "title": "神经概念验证器: 通过概念编码扩展证明者-验证者游戏", "title_en": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings", "authors": "Berkant Turan,Suhrab Asadulla,David Steinmann,Wolfgang Stammer,Sebastian Pokutta", "background": "证明者-验证者游戏（PVGs）为非线性分类模型的可验证性提供了有前途的途径，但尚未应用于如高维图像等复杂输入。相比之下，概念瓶颈模型（CBMs）能够将这样复杂的数据转换为可解释的概念，但受限于其依赖低容量的线性预测器。", "innovation": "本文引入了神经概念验证器（NCV），这是一种结合了PVG与概念编码的统一框架，用于高维度条件下可解释的非线性分类。NCV通过利用最新的少监督概念发现模型，从原始输入中提取结构化概念编码。随后，证明者选择一组这些编码，验证者则作为非线性预测器，仅使用这些编码进行决策。实验表明，NCV在高维复杂数据集上优于CBM和基于像素的PVG分类器基线，并有助于缓解捷径行为。", "conclusion": "我们证明了NCV作为向执行高效、可验证AI迈出的重要一步。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08018", "html_url": "https://arxiv.org/abs/2507.08018", "title": "Review, Remask, Refine (R3): 过程指导的块扩散文本生成", "title_en": "Review, Remask, Refine (R3): Process-Guided Block Diffusion for Text Generation", "authors": "Nikita Mounier,Parsa Idehpour", "background": "迭代文本生成的一个关键挑战是模型需要高效地识别并修正自身的错误。现有的方法大多需要额外的模型训练，这不仅增加了复杂性和资源消耗，还可能降低模型的适用性和灵活性。本文探讨了一个相对简单而优雅的框架，该框架不需要额外的模型训练，可以应用于任何预训练的带掩码文本扩散模型（如LLaDA或BD3-LM），并通过一个中间生成块进行评估和修改的过程来提高文本生成的效果。", "innovation": "本文提出的R3框架，利用了一个过程奖励模型（PRM）对中间生成块进行审查，并将这些PRM分数转化为重新掩码策略：分数较低的块表明可能存在错误，因此这个块中的更多标记将被重新掩码。最终，模型被引导对这些目标片段进行细化，集中精力改进历史生成中特定的次优部分，从而提升最终输出的质量。这种方式不需要额外的训练，增加了模型的适用性和灵活性，同时通过过程指导的块扩散提高了文本生成的质量。", "conclusion": "R3框架通过一种简单而有效的策略，解决了迭代文本生成中模型识别和修正自身错误的关键挑战。这种方法不仅不需要额外的模型训练，还能被广泛应用于不同的预训练的文本生成模型中。通过过程奖励模型和重新掩码策略，R3框架在提高文本生成质量方面表现出了强大的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08021", "html_url": "https://arxiv.org/abs/2507.08021", "title": "揭开图像描述中有效上下文配置的面纱：外部与内部分析", "title_en": "Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis", "authors": "Li Li,Yongliang Wu,Jingze Zhu,Jiawei Peng,Jianfei Cai,Xu Yang", "background": "大模型的演变见证了一种名为上下文内学习（ICL）的新能力的出现。在自然语言处理（NLP）领域，已有多项研究证实了ICL的有效性。借鉴大规模语言模型（LLMs）的成功，研究人员开发了具备ICL能力的大规模多模态模型（LMMs）。虽然多模态ICL的演示配置研究尚处于初步阶段，但展示的可控性提供了一个观察和分析LMMs在不同输入下的推理特征的有效手段。本文通过全面的外部和内部研究探讨了多模态ICL在图像描述任务中的应用。", "innovation": "本文提出了一种结合外部和内部分析方法来研究大模型的方法，并且提出了新的度量标准。通过三个维度（镜头数量、图像检索和描述分配）探索多模态上下文内学习的演示配置策略，并使用多种指标系统性地评估和总结关键发现。此外，通过分析典型的LMM注意力特征并开发注意力基线度量标准来量化模型行为，发现通过外部实验和内部检查的影响因素，并解释了具有相同模型设计和预训练策略的大规模多模态模型之间性能差异的原因。", "conclusion": "本研究揭示了通过外部实验和内部检查的多种上下文内示例配置策略如何影响模型性能，以及典型的模式特征。结合外部和内部的分析方法以及新的度量标准可以应用于更广泛的研究领域。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08019", "html_url": "https://arxiv.org/abs/2507.08019", "title": "信号或噪声？跨情境差异和人类专家基准评估大型语言模型在简历筛选中的表现", "title_en": "Signal or Noise? Evaluating Large Language Models in Resume Screening Across Contextual Variations and Human Expert Benchmarks", "authors": "Aryan Varshney,Venkat Ram Reddy Ganuthula", "background": "本研究探讨了大型语言模型（LLMs）在筛选简历与职位描述匹配时是否表现出一致的行为（信号）或随机差异（噪声），以及它们的性能与人类专家的比较。研究使用受控的数据集合，针对三个LLMs（Claude、GPT和Gemini）在不同情境（公司背景、外国跨国公司、初创公司、信息减少情境）下，测试了它们处理标准化简历和随机简历的变化。并将这些结果与三位人类招聘专家的评估进行了比较和基准测试。", "innovation": "这是第一次系统地评估多个大型语言模型在简历筛选领域中的表现差异，并且通过设置不同情境来测试这些模型的适应性。研究还采用元认知分析揭示了这些模型在权重分配方面的不同模式，这些模式与人类判断的方法大不相同。", "conclusion": "研究发现，给定详细提示时，大型语言模型可以显示一定程度的可解释性，但其评估方式与人类专家之间存在显著差异。这些发现为自动化招聘系统的部署提供了指导，特别是在使用LLMs时需要考虑人类判断的独特性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08030", "html_url": "https://arxiv.org/abs/2507.08030", "title": "生成式AI模型中下降的医疗安全提示系统的分析", "title_en": "A Systematic Analysis of Declining Medical Safety Messaging in Generative AI Models", "authors": "Sonali Sharma,Ahmed M. Alaa,Roxana Daneshjou", "background": "生成式人工智能模型，包括大规模语言模型（LLMs）和视觉-语言模型（VLMs），越来越多地用于解释医学影像和回答临床问题。由于这些模型经常会给出不准确的回答，因此需要通过医学免责声明等安全措施提醒用户，这些人工智能输出并不经过专业验证，不能替代医疗建议。近年来，医学免责声明在这些模型中的使用情况发生了显著变化，需要对此进行系统的分析和研究，以确保医疗信息的安全和准确性。", "innovation": "本研究系统地评估了2022年至2025年间LLM和VLM中医学免责声明的持续存在情况，通过使用四类（乳腺X光片、胸部X光片、皮肤影像和医学问题）总计2000个样本进行筛选，发现LLM和VLM中的医学免责声明从2022年的26.3%和19.6%急剧下降到2025年的0.97%和1.05%，表明提示性声明的使用已经大幅减少。研究通过这些数据展示了生成式AI模型的去权威化及其可能带来的影响，并提出了需要适配临床应用场景来加强安全措施的需求。这项研究为评估和改进生成式AI在医疗应用中的安全措施提供了新的视角和方法。", "conclusion": "到2025年，多数生成式AI模型已经不再显示医学免责声明。随着公有模型的技术进步和权威性的增强，调查和实施有效的安全措施变得越来越重要，需要根据每个输出的具体临床情景来调整保护措施，以确保信息的安全性和准确性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08036", "html_url": "https://arxiv.org/abs/2507.08036", "title": "MedVQA系统整合到放射学工作流程中的障碍：一项范围审查与临床医生见解", "title_en": "Barriers in Integrating Medical Visual Question Answering into Radiology Workflows: A Scoping Review and Clinicians' Insights", "authors": "Deepali Mishra,Chaklam Silpasuwanchai,Ashutosh Modi,Madhumita Sushil,Sorayouth Chumnanvej", "background": "MedVQA作为一种自动化医学图像解释的工具，能够通过问答帮助放射科医生。尽管在模型和数据集方面取得了进展，但MedVQA在临床工作流程中的整合仍然有限。本文通过系统回顾68篇（2018-2024年）文献并调查了50名来自印度和泰国的临床医生，旨在研究MedVQA的实际用途、挑战和差距。研究表明，近60%的数据问答对是非诊断性的，缺乏临床相关性。大多数数据集和模型不支持多视角、多分辨率成像、EHR集成或专业知识，这些都是临床诊断所必需的特征。现有的评估指标与临床需求之间也存在明显的不匹配。", "innovation": "本文采用两步方法：一是系统回顾文献以识别放射学工作流程中的关键概念、技术进步和研究缺口；二是通过调查临床医生来了解其对MedVQA的临床相关性的看法。此外，该研究强调了患者历史数据和领域知识的缺失、偏好手动标注数据集以及多视角图支持的需求。", "conclusion": "尽管MedVQA显示出巨大的潜力，但still存在如缺乏多模态分析、缺少患者背景信息以及评估方法与临床需求不匹配等挑战，这些都需要解决以确保其在临床工作流程中的有效集成。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08037", "html_url": "https://arxiv.org/abs/2507.08037", "title": "CRISP: 复杂推理过程中的可解释分步计划", "title_en": "CRISP: Complex Reasoning with Interpretable Step-based Plans", "authors": "Matan Vetzler,Koren Lazar,Guy Uziel,Eran Hirsch,Ateret Anaby-Tavor,Leshem Choshen", "background": "近年来，大规模语言模型（LLMs）的发展突显了增强推理能力以有效解决复杂问题的需求。虽然带有推理链（CoT）的方法迈出了重要一步，但仍然不足以应对许多领域的问题。一种有前景的替代方案是显式的高级任务规划生成，但是现有的方法大多假设通过少量提示即可完成，而无需额外的训练。", "innovation": "本工作挑战了这一假设，并引入了一个名为CRISP（Complex Reasoning with Interpretable Step-based Plans）的多领域规划数据集，其中包含用于数学推理和代码生成的高级计划。该数据集的计划是自动生成的，并经过严格验证，包括内在验证（由LLM评判）和外在验证（通过评估其对下游任务性能的影响）。结果显示，小型模型在CRISP上的微调可以生成的质量比使用少样本提示的大模型更好，同时在推理链中表现出更优的性能。此外，跨域评估表明，在一个领域进行微调可以改善另一个领域的规划生成，这突出了学习到的规划能力的通用性。", "conclusion": "精细调整小型模型在CRISP上能够生成高质量的计划，优于使用少样本提示的大模型实现，同时显著超越推理链推理。并通过不同领域的评估进一步证明了这一方法的学习规划能力具有跨域的通用性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08031", "html_url": "https://arxiv.org/abs/2507.08031", "title": "超越规模：小型语言模型在心理健康理解方面与GPT-4相当", "title_en": "Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding", "authors": "Hong Jia,Shiya Fu,Vassilis Kostakos,Feng Xia,Ting Dang", "background": "小型语言模型（SLMs）作为保护敏感应用隐私的替代选择正在兴起。本文研究了当前SLMs在心理健康理解能力方面与大型语言模型（LLMs）的内在理解能力的差异。通过系统评估SLMs在多种分类任务中的表现，并借助零样本学习和少样本学习框架将SLMs与已有的LLMs基准进行比较，研究揭示了SLMs在二分类任务中的表现接近LLMs，而在多分类严重程度任务中则表现相似的下降，显示了模型规模之外的深刻临床理解挑战。", "innovation": "研究使用零样本学习和少样本学习框架评估了五种先进的小型语言模型（Phi-3，Phi-3.5，Qwen2.5，Llama-3.2，Gemma2）与三种大型语言模型（GPT-4，FLAN-T5-XXL，Alpaca-7B）在六项心理健康理解任务中的表现。发现小型语言模型在二分类任务中的表现与大型语言模型相差不到2%，且通过少样本提示，小型语言模型表现有了显著提升，这表明小型语言模型在心理健康理解方面有潜在的应用价值。", "conclusion": "研究表明，小型语言模型能够在心理健康理解方面表现出与大型语言模型相当的性能，特别是在二分类任务中。虽然在多分类任务中表现相似的下降，但小型语言模型通过少样本学习能够显著提高性能，显示出它们作为隐私保护工具和可扩展的心理健康筛查工具的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08038", "html_url": "https://arxiv.org/abs/2507.08038", "title": "AblationBench: 评估实证人工智能研究中消融实验自动化规划", "title_en": "AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research", "authors": "Talor Abramovich,Gal Chechik", "background": "基于语言模型（LMs）的自主代理在许多领域，包括科学研究中越来越受欢迎。AI协作科学家旨在利用这些代理来支持或自动化研究过程中的某些部分。实证AI研究的一个关键组成部分是消融实验的设计。为此，我们引入了AblationBench，这是一个基准套件，用于评估代理在实证AI研究中的消融规划任务。该基准套件包括两个任务：AuthorAblation帮助作者基于方法部分提出消融实验，包含83个实例；ReviewerAblation帮助审稿人在完整论文中找到缺失的消融实验，包含350个实例。对于这两个任务，我们开发了基于LM的评判者，作为自动评估框架。", "innovation": "AblationBench是一个用于评估代理在实证AI研究中消融规划任务上的基准套件，包括AuthorAblation和ReviewerAblation两个任务，涉及大量的语言模型样本和实用性评判者。此外，研究确证了链式思维提示方法在现有基于代理的方法中的优越性。", "conclusion": "尽管使用前沿LM系统，这些任务仍然具有挑战性，最好性能的LM系统只能平均识别原始消融实验的29%。最后，我们分析了当前LMs在这两类任务中的局限性，表明链式思维提示方法优于现有基于代理的方法。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08045", "html_url": "https://arxiv.org/abs/2507.08045", "title": "Krul: 动态跨层 KV 共享实现多轮对话的高效状态恢复", "title_en": "Krul: Efficient State Restoration for Multi-turn Conversations with Dynamic Cross-layer KV Sharing", "authors": "Junyi Wen,Junyuan Liang,Zicong Hong,Wuhui Chen,Zibin Zheng", "background": "在使用大型语言模型（LLMs）进行多轮对话时，高效地恢复关键字值（KV）缓存仍然是一个重要的挑战。现有方法通过在相邻层间压缩相似的注意力模式来压缩KV缓存，但是这些方法往往使用固定策略压缩所有对话的相应层对，而不考虑对话间的特定注意力动态性。这种静态策略未能注意到不同对话间注意力模式相似度的变化性，可能导致产生显著的准确性下降。", "innovation": "Krul提出了一种多轮LLM推理系统，能够实现准确而高效的KV缓存恢复。Krul的关键创新包括：1）一种预置的压缩策略选择器，能够在对话中选择保留关键信息的定制化压缩策略；2）一种基于token的异质注意力相似度估计器，以减轻生成模型时注意力相似度计算和存储的开销；3）一种无气泡的恢复调度器，以减少由于压缩KV缓存带来的重新计算与加载不平衡所导致的潜在气泡。", "conclusion": "实证分析表明，与最先进的方法相比，Krul在首先生成令牌的时间（TTFT）上减少了1.5到2.68倍，KV缓存存储空间减少了1.33到2.35倍，且不牺牲生成质量。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08203", "html_url": "https://arxiv.org/abs/2507.08203", "title": "TruthTorchLM：LLM输出真实性的全面库", "title_en": "TruthTorchLM: A Comprehensive Library for Predicting Truthfulness in LLM Outputs", "authors": "Duygu Nur Yaldiz,Yavuz Faruk Bakman,Sungmin Kang,Alperen Öziş,Hayrettin Eren Yildiz,Mitash Ashish Shah,Zhiqi Huang,Anoop Kumar,Alfy Samuel,Daben Liu,Sai Praneeth Karimireddy,Salman Avestimehr", "background": "生成型大型语言模型（LLMs）不可避免地会产生不真实的响应。准确预测这些输出的真实性和在高风险设置中的重要性至关重要。为了加速此领域的研究，并使真实性预测方法更易于获取，我们引入了TruthTorchLM，这是一个开源且全面的Python库，包含超过30种真实性预测方法，称为Truth Methods。现有的工具包如Guardrails仅专注于文档验证，而LM-Polygraph仅限于基于不确定性的方法，TruthTorchLM提供了更广泛和扩展性强的集合技术，涵盖了计算成本、访问级别（例如黑箱 vs 灰箱）、文档要求和监督类型（自我监督或监督）等多种权衡。", "innovation": "TruthTorchLM具有跨HuggingFace和LiteLLM无缝兼容的优势，支持本地托管和API模型，并提供统一的生成、评估、校准和长篇真实性的预测接口。此外，它还提供了一个灵活的框架，允许通过新方法扩展库。我们在三个数据集（TriviaQA、GSM8K和FactScore-Bio）上对代表性的真实性方法进行了评估。", "conclusion": "代码可在特定链接获取。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08107", "html_url": "https://arxiv.org/abs/2507.08107", "title": "GRASP：跨知识图谱的通用推理和SPARQL生成", "title_en": "GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs", "authors": "Sebastian Walter,Hannah Bast", "background": "该论文提出了一种用于从自然语言问题或关键词查询生成RDF知识图谱SPARQL查询的新方法，该方法依赖于大型语言模型。现有的方法通常需要微调模型，而该研究的方法是通过战略性地执行SPARQL查询并在知识图谱中搜索相关IRIs和字面量来进行探索，这种方法不需要微调。该方法在多种基准测试（涉及不同类型的大小不同的知识图谱）和语言模型（不同规模和类型的商业与开源模型）上进行了评估，并与现有方法进行了比较。研究在Wikidata上达到了多项基准的最先进结果，即使在零样本设置下。在Freebase上，该方法接近最佳的少样本方法。在其他较少评估的知识图谱和基准测试上，该方法也表现出色。此外，还进行了多种额外的研究，如比较不同的图搜索策略、引入反馈机制或利用少样本示例等.", "innovation": "该研究的主要创新之处在于提出了一种新型方法，无需对语言模型进行微调，而是利用模型来探索知识图谱，通过执行战略性SPARQL查询以找到相关IRIs和字面量，这种方法在多个基准上展示了良好的性能，尤其是在零样本设置下达到了先进结果。此外，还探索了多种改进策略，如反馈机制和少样本示例的应用等.", "conclusion": "该方法在多种类型和大小的知识图谱上表现良好，特别是在Wikidata中达到了最先进的结果。研究还表明，该方法不仅适用于常见的知识图谱，也能处理其他不太常用的图谱和基准测试。通过引入战略查询和反馈机制，可以进一步提高该方法的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08151", "html_url": "https://arxiv.org/abs/2507.08151", "title": "从大型语言模型中萃取同理心", "title_en": "Distilling Empathy from Large Language Models", "authors": "Henry J. Xie,Jinghan Zhang,Xinhao Zhang,Kunpeng Liu", "background": "知识从大型语言模型（LLMs）到小型语言模型（SLMs）的提炼，同时保持LLMs的能力和性能并减少模型尺寸，在LLMs的广泛应用中起到了关键作用。由于SLMs比LLMs小得多，它们通常在资源受限但需要频繁人机交互的领域中使用，例如智能手机。因此，确保在LLMs中已具有的同理心这种正面人际交往的关键因素能够在SLMs中得到保留显得尤为重要。", "innovation": "本文开发了一种全面的方法，以有效地将同理心从LLMs提炼到SLMs中。该方法包含一个双重细调过程，完全利用从LLMs中提炼的情感对话响应数据集。还探索了多种细调方法，并提出了四种独特的定制提示，以显著提升同理心的提炼过程。实验结果显示，使用双重细调过程并结合针对同理心改进的提示进行数据集增强的SLMs，在生成同理心回应方面明显优于基线SLMs，胜出率为90%。针对同理心改进的提示比基本直接提示更具优势，胜出率提高了10%。", "conclusion": "通过双重细调过程并结合针对同理心改进的提示进行数据集增强，可以显著提升小型语言模型生成同理心回应的效果。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08232", "html_url": "https://arxiv.org/abs/2507.08232", "title": "LLMs能否可靠地模拟数学和阅读理解能力的真实学生？", "title_en": "Can LLMs Reliably Simulate Real Students' Abilities in Mathematics and Reading Comprehension?", "authors": "KV Aditya Srivatsa,Kaushal Kumar Maurya,Ekaterina Kochmar", "background": "大型语言模型（LLMs）越来越多地被用作代理学生，在智能辅导系统（ITS）的开发以及测试问题的试点中。然而，这些代理学生的模拟行为和特征是否与真实学生高度一致仍是一个未知数。", "innovation": "收集了来自国家教育进步评估（NAEP）的489项题库，覆盖4、8和12年级的数学和阅读理解；应用项目反应理论（IRT）模型将11个不同的最新LLMs置于与真实学生群体相同的能力尺度上；发现非引导的强通用模型在每个年级始终优于平均学生，而较弱或领域不匹配的模型可能偶然一致；通过年级增强提示改变了模型表现，但它们是否与平均年级水平的学生一致高度依赖于模型和提示特性。", "conclusion": "没有一个测试的模型提示组合能够适用于所有学科和年级；提出了根据研究结果为合适的代理选择制定指南，强调需要新的训练和评估策略。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08309", "html_url": "https://arxiv.org/abs/2507.08309", "title": "通过同步自我复习其OCR技能提高MLLM的文档图像机器翻译", "title_en": "Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency", "authors": "Yupu Liang,Yaping Zhang,Zhiyang Zhang,Zhiyuan Chen,Yang Zhao,Lu Xiang,Chengqing Zong,Yu Zhou", "background": "多模态大型语言模型（MLLMs）在文档图像任务中表现优异，尤其是在光学字符识别（OCR）方面。然而，它们在文档图像机器翻译（DIMT）方面存在问题，需要处理跨模态和跨语言挑战。通过监督微调（SFT）增强DIMT能力的努力常常导致模型忘记其现有的单语言能力，如OCR。", "innovation": "我们提出了一种新的微调范式，称为同步自我复习（SSR），旨在同步提升模型的OCR技能，从而克服这些挑战。SSR的创新在于，它让模型在生成翻译文本之前先生成OCR文本，从而使模型能够利用其强大的单语言OCR能力，同时学习跨语言的翻译。", "conclusion": "全面的实验表明，提议的SSR学习有助于缓解灾难性遗忘，提高了MLLM在OCR和DIMT任务上的泛化能力。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08325", "html_url": "https://arxiv.org/abs/2507.08325", "title": "CRMAgent: 电子商务CRM消息模板生成的多智能体大模型系统", "title_en": "CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template Generation", "authors": "Yinzhu Quan,Xinrui Li,Ying Chen", "background": "在电子商务的私域渠道中，如即时通讯和电子邮件，商家通过客户关系管理（CRM）项目直接与客户互动，以提高留存率和转换率。虽然少数顶尖企业善于制作外发的消息，但大多数商家因缺乏专门知识和可扩展工具而难以编写有说服力的文案。", "innovation": "我们引入了CRMAgent，这是一个基于大语言模型（LLMs）的多智能体系统，通过三种互补模式生成高质量的消息模板和实用的写作指导。第一，基于组的学习机制使代理能够从商家自身的高绩效消息中学习并重写低绩效的消息；第二，检索并适应功能检索模板，并学习它们的成功模式，根据当前的活动进行调整；第三，基于规则的备用方案在没有合适的参考的情况下提供轻量级的零样本重写。广泛的实验表明，CRMAgent在多个指标上都优于商家的原始模板，显著提高了目标用户匹配度和营销效果。", "conclusion": "CRMAgent在生成高准确度的CRM消息模板方面优于现有方法，提供了显著的效果提升。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08335", "html_url": "https://arxiv.org/abs/2507.08335", "title": "MK2在PBIG竞赛中的表现：一种提示生成解决方案", "title_en": "MK2 at PBIG Competition: A Prompt Generation Solution", "authors": "Yuzheng Xu,Tosho Hirasawa,Seiya Kawano,Shota Kato,Tadashi Kozuno", "background": "专利基于想法生成任务要求系统将实际专利转化为在三年内可行的产品创意。这项研究的背景在于通过系统化的处理和迭代编辑专利内容，将其转化为具有商业潜力的产品想法，当前方法通常需要大量的训练数据和复杂的模型结构。", "innovation": "MK2提出了一种基于提示的处理管道：首先使用Gemini 2.5生成并迭代编辑提示，再利用这些提示通过GPT-4.1生成具体的产品创意。通过Elo循环评估并选择最佳提示，该过程无需额外的训练数据。这种方法证明了通过轻量级的提示工程可以生成具有竞争力且具有商业意义的产品创意，特别是对于材料-化学领域需要更深入领域知识的情况。", "conclusion": "MK2在三个领域、两种评估者类型和六项评估标准下，自动排行榜中排名第一，共赢得了36次测试中的25次。这一结果表明，轻量级的提示工程已经能够从专利中产出具备竞争力和商业价值的产品创意，但材料-化学领域还需要更深层次的领域知识支持。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08339", "html_url": "https://arxiv.org/abs/2507.08339", "title": "在金融问题回答中影响LLMs和RLLMs的因素有哪些？", "title_en": "What Factors Affect LLMs and RLLMs in Financial Question Answering?", "authors": "Peng Wang,Xuesi Hu,Jiageng Wu,Yuntao Zou,Qiancheng Zhang,Dagang Li", "background": "近年来，大型语言模型（LLMs）和具有长链推理能力的推理大型语言模型（RLLMs）得到了许多研究者的广泛关注。RLLMs通过长链推理过程增强了LLMs的推理能力，显著提高了LLMs在解决复杂问题的性能。但很少有研究系统地探讨如何充分挖掘LLMs和RLLMs在金融领域的性能潜力。为了研究不同方法对LLMs和RLLMs的影响，作者使用了五种LLMs和三种RLLMs，评估了提示方法、代理框架和多语言对齐方法对金融问答任务的影响。", "innovation": "研究发现当前的提示方法和代理框架通过模拟长链推理过程提升了LLMs在金融问答中的表现；RLLMs具有内在的长链推理能力，这限制了传统方法进一步提升其性能的效果；当前先进的多语言对齐方法主要通过扩展推理长度来改善多语言性能，这对RLLMs带来的好处较小。", "conclusion": "本研究希望为LLMs和RLLMs在金融问答领域的应用提供重要的参考。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08336", "html_url": "https://arxiv.org/abs/2507.08336", "title": "对比学习与蒸馏：如何训练你的 rerankers", "title_en": "Distillation versus Contrastive Learning: How to Train Your Rerankers", "authors": "Zhichao Xu,Zhiqi Huang,Shengyao Zhuang,Ashim Gupta,Vivek Srikumar", "background": "文本重排器的训练对于信息检索至关重要。目前，广泛采用的两种主要策略是对比学习（直接优化执行向标注数据）和知识蒸馏（从大型重排器转移知识）。尽管这两种方法已在文献中有所研究，但在实际条件下对训练交叉编码器重排器的有效性进行清晰比较的需求仍然存在。为了填补这一空缺，本文通过将不同大小和架构的重排器分别使用这两种方法在同一数据集上进行训练并与一个强大的对比学习模型作为蒸馏教师进行了实证比较。结果表明，从大型教师模型中进行知识蒸馏通常在领域内和领域外的排序性能上优于对比学习。这一发现适用于不同大小和架构的学生模型。然而，如果使用的是相同容量的教师模型，则输差模型无法从中获得同样的优势，特别是在领域外任务方面。这些发现为基于可用教师模型选择训练策略提供了实用指导。因此，如果可以访问一个更强大的大模型，则应使用知识蒸馏来训练较小的重排器；否则，对比学习则是更为可靠且有效的替代方案。", "innovation": "本文通过将两种训练方法应用于相同数据集的不同大小和架构的重排器进行实证比较，展示了从大型教师模型进行知识蒸馏在领域内和领域外排序性能上优于对比学习的新发现。这一发现提供了基于可用教师模型选择训练策略的实用指导。", "conclusion": "研究发现，从大型教师模型进行知识蒸馏在领域内和领域外的排序性能上优于对比学习。因此，如果可以访问更强大的教师模型，推荐使用知识蒸馏来训练较小的重排器；否则，对比学习将是更为可靠且有效的替代方案。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08143", "html_url": "https://arxiv.org/abs/2507.08143", "title": "Compactor：使用近似杠杆得分的校准查询无感知KV缓存压缩", "title_en": "Compactor: Calibrated Query-Agnostic KV Cache Compression with Approximate Leverage Scores", "authors": "Vivek Chari,Benjamin Van Durme", "background": "现代大型语言模型（LLMs）越来越多地训练以支持非常大的上下文窗口。然而，生成时使用长上下文受到KV缓存所需的大内存使用量的限制，这种内存占用量随着上下文长度成线性增长。在实际部署中，这种内存占用量往往是主要的资源瓶颈，限制了吞吐量并增加了服务成本。一种解决方法是压缩KV缓存，这可以通过对查询有了解（查询感知）或没有查询了解（查询无感知）来实现。本文介绍了Compactor，这是一种无参数的、查询无感知的KV压缩策略，使用近似杠杆得分来确定标记的重要性。", "innovation": "Compactor可以通过使用近似杠杆得分来确定标记的重要性，实现与竞争方法相同的效果，同时保留一半的标记，在合成和现实世界上下文任务中最大化减少计算开销。进一步引入了一种上下文校准压缩方法，可以根据给定上下文的最大压缩比来推断压缩比率。通过上下文校准压缩，Compactor在Longbench上实现了完整的KV性能，同时减少了平均63%的KV内存负担。", "conclusion": "Compactor被应用于Qwen 2.5和Llama 3.1家族的27个合成和现实世界任务中，显示了其有效性和泛化能力。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08034", "html_url": "https://arxiv.org/abs/2507.08034", "title": "将外部工具与大型语言模型集成以提高准确性", "title_en": "Integrating External Tools with Large Language Models to Improve Accuracy", "authors": "Nripesh Niketan,Hadj Batatia", "background": "大型语言模型（LLMs）在缺乏相关上下文信息时可能会提供质量较差的回答或产生幻觉。已有研究提议将LLMs与外部工具结合，为LLMs提供最新的数据以提高准确度。本文针对教育场景，提出了一种框架，使LLMs能够访问外部API以获取相关数据，提高回答查询的能力，这些集成的工具还能提供计算器或日历等计算功能。", "innovation": "本文提出了一种框架，允许LLMs访问外部API以获取附加的相关信息，并提供计算和日历等计算功能，通过使用来自多模态语言理解（MMLU）集合的数据集进行了评估，结果显示该方法显著提高了性能。Athena框架在数学推理和科学推理方面分别达到了83%和88%的准确率，超越了包括GPT-4o、LLaMA-Large、Mistral-Large、Phi-Large和GPT-3.5在内的所有测试模型。", "conclusion": "本文的方法在数学推理和科学推理任务上表现出显著的性能提升，这为创建以LLMs为中心的复杂计算生态系统铺平了道路，使其使用更加自然，支持各种任务和活动。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08218", "html_url": "https://arxiv.org/abs/2507.08218", "title": "简单机械解释超上下文推理", "title_en": "Simple Mechanistic Explanations for Out-Of-Context Reasoning", "authors": "Atticus Wang,Joshua Engels,Oliver Clive-Griffin", "background": "超上下文推理（OOCR）现象表明，微调的LLM在非分布数据中表现出令人惊讶的深层推断能力。这通常不是通过学习浅层启发式规则，而是通过隐式地内化和执行散见于微调数据中的观察影响来实现的。本文旨在从机械角度来看待这一现象，发现文献中许多OOCR实例的一个简单解释是LoRA微调实际上添加了一个恒定导向向量，使得模型向着一个通用概念偏移，这在微调任务和其他相关概念领域中提高了表现，从而导致了超常的泛化能力。进一步研究发现，可以针对这些任务从头训练导向向量，这也产生了OOCR现象。研究发现，即使是看似必须涉及条件行为的任务（模型后门），无条件添加一个导向向量也足够了。", "innovation": "本文提供了一个机制性的解释，阐述了在OOCR任务的微调过程中学习的内容，解释了为什么LLM能够进行超上下文推理，这是一个对它们的安全和可靠部署非常重要的高级能力。通过从头训练导向向量的方法也展示了OOCR的现象，无论任务是否涉及条件行为均有效。这些研究结果有助于回答一个关键问题，即为什么LLM能在超上下文推理任务中表现出超常的推断能力。", "conclusion": "本文提供了OOCR任务在微调过程中学习内容的一个解释，有助于理解LLM进行超上下文推理的原因，对它们的安全和可靠部署具有重要意义。实验结果显示，即使任务看似需要条件行为，无条件添加跳转向量也可以引发OOCR。从这一点上看，LLM以一个通用概念为导向的机制是物种泛化的核心。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08350", "html_url": "https://arxiv.org/abs/2507.08350", "title": "探索用于研究创意设计的多代理LLM对话设计", "title_en": "Exploring Design of Multi-Agent LLM Dialogues for Research Ideation", "authors": "Keisuke Ueda,Wataru Hirota,Takuto Asakura,Takahiro Omi,Kosuke Takahashi,Kosuke Arima,Tatsuya Ishigaki", "background": "大型语言模型（LLMs）越来越多地被用来支持创作任务，如研究主题生成。虽然近期研究表明，LLMs的结构化对话可以提高生成想法的新颖性和可行性，但最优设计仍不清楚。本研究对多代理LLM对话在科学创意思考中的应用进行了全面分析，比较了不同代理角色配置、代理数量和对话深度等因素对生成想法新颖性和可行性的影响。实验设置包括一个代理生成想法，另一个代理进行批评的场景，以实现迭代改进。研究结果表明，扩大代理群体、加深互动深度以及拓宽代理个性的异质性，可以丰富生成想法的多样性。此外，特别增加批评环节的多样性还进一步提高了最终建议的可行性。", "innovation": "本研究通过全面分析多代理LLM对话在科学创意思考中的应用，探索了不同代理配置、代理数量和对话深度等因素如何影响想法的新颖性和可行性。实验中特别加强了批评环节的多样性，这显著提高了最终建议的可行性。研究结果为构建有效的多代理LLM系统以促进科学创意思考提供了实用指南。", "conclusion": "研究发现，通过增加代理群体、加深对话深度、扩展代理个性的异质性，以及特别强调评价环节的多样性，可以增强多代理LLM系统在科学创意思考中的效果。研究成果提供了实用的设计指南，帮助构建高效的多代理LLM系统以实现科学创意思考。相关代码可在指定网站获取。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08241", "html_url": "https://arxiv.org/abs/2507.08241", "title": "在Reddit上探索慢性疼痛讨论中的性别差异", "title_en": "Exploring Gender Differences in Chronic Pain Discussions on Reddit", "authors": "Ancita Maria Andrade,Tanvi Banerjee,Ramakrishna Mundugar", "background": "疼痛是人类存在的一部分，表现为物理和情感体验，并可划分为急性疼痛和慢性疼痛。多年来，各个学科进行了一系列研究以了解疼痛的原因和探索可能的治疗方法，但早期的研究往往忽视了性别在疼痛体验中的作用。因此，本研究利用自然语言处理技术NLP分析并深入了解个体的疼痛体验，特别是性别差异。", "innovation": "利用隐藏属性模型-卷积神经网络（HAM-CNN）成功将帖子分类到男性和女性语料库中，通过根据用户名聚合帖子实现了0.86的F1分数，揭示了性别间的语言差异，女性帖子更倾向于情感集中。此外，研究还突出了偏头痛和鼻窦炎在女性中的高发情况，并探讨了疼痛药物如何因性别不同而影响个体。", "conclusion": "本研究通过Reddit平台探索了慢性疼痛讨论中的性别差异，发现了性别之间的语言使用差异，并揭示了疼痛状况和药物反应的性别特定模式。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08371", "html_url": "https://arxiv.org/abs/2507.08371", "title": "关于事实精调的有趣现象：模型内部信念可以提高事实性", "title_en": "The Curious Case of Factuality Finetuning: Models' Internal Beliefs Can Improve Factuality", "authors": "Benjamin Newman,Abhilasha Ravichander,Jaehun Jung,Rui Xin,Hamish Ivison,Yegor Kuznetsov,Pang Wei Koh,Yejin Choi", "background": "语言模型容易出现幻觉，即生成与事实不符的文本。通过对高质量事实数据的微调可以减少幻觉，但获取这类数据成本高昂，使用正确但不熟悉的事实数据可能会在下游任务中导致更多的幻觉。研究人员需要了解应该使用哪种数据来进行微调以减轻语言模型的幻觉现象.", "innovation": "研究发现，使用模型生成但内部认为是真实的事实数据进行微调比直接使用真实数据更有效。此外，通过模型自身的内部判断过滤生成数据可以实现更好的总体事实性，这种效果在不同研究领域中都能得到体现，表明模型的内部信念可以提供强大的事实性信号.", "conclusion": "研究揭示了事实精调的相关关系，并指出使用模型生成但认为是真实的事实数据进行微调能减少幻觉，内部判断过滤生成数据相较于其他配置能提供更好的事实性改进，这种改进在不同领域中都有效。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08342", "html_url": "https://arxiv.org/abs/2507.08342", "title": "超越n-克gram：重新思考多语言抽象摘要的评估指标和策略", "title_en": "Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization", "authors": "Itai Mondshine,Tzuf Paz-Argaman,Reut Tsarfaty", "background": "自动n-克gram指标如ROUGE广泛用于评估生成任务如总结的效果。虽然这些指标在英语中被认为对人类评估有指示作用（尽管不完美），但对于其他语言的适用性仍然不清楚。为此，研究者系统地评估生成任务的评估指标，包括n-克gram和神经基线指标，以评估它们在多种语言和任务中的效果。研究设计了一个涵盖八种语言（四种类型家族）的大规模评估套件，其中包括从贫到富的语言资源，以分析其与人类评估的相关性。研究发现，评估指标对语言类型高度敏感，尤其在黏着语中，n-克gram指标与人类评估的相关性较低，而粘着语和聚合语语言中表现较好。适当分词在形态丰富的黏着语中可以显著缓解这一问题，有时甚至可以逆转负面趋势。此外，研究表明，专门为评估任务训练的神经基线指标，如COMET，在资源稀缺的语言中表现出色，并且与人类评估的相关性更好。总体而言，分析表明n-克gram指标在黏着语中的局限性，并倡导在评估任务中以更大的投入去开发神经基线评估指标。", "innovation": "研究通过系统性地评估不同类型的评估指标（n-克gram和神经基线）在多种语言和任务上的效果，强调了评估指标对语言类型的敏感性，并展示了适当分词和专门为评估任务训练的神经基线指标（如COMET）在资源稀缺语言中的优势。这些结果对于改进多语言摘要任务的评估方法具有重要意义。", "conclusion": "研究发现，n-克gram指标在黏着语中表现较弱，并且适当分词可以显著改善这一情况。另外，专门为评估任务训练的神经基线指标如COMET，在资源稀缺的语言中表现出显著优势，并更好地对应人类评估。因此，建议在多语言摘要任务中加强对神经基线评估指标的研究和应用，以改进评估方法，提高效果。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08425", "html_url": "https://arxiv.org/abs/2507.08425", "title": "大型语言模型在学科特定研究中的综述：挑战、方法与机遇", "title_en": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "authors": "Lu Xiang,Yang Zhao,Yaping Zhang,Chengqing Zong", "background": "大型语言模型（LLMs）在多个学科研究中展现了其变革潜力，重新定义了现有的研究方法，并促进了跨学科合作。然而，LLMs在多种学科中的整合目前还未得到系统性的理解。这篇综述论文旨在为学科特定研究中LLMs的应用提供全面概述，从技术和应用两个维度分类研究工作。", "innovation": "论文创新性地从技术和应用两个维度系统地评估了LLMs在跨学科研究中的应用，详细探讨了诸如监督微调、检索增强生成、基于代理的方法和工具集成等关键技术，并分析了LLMs在数学、物理、化学、生物学以及人文学科和社会科学中的应用，同时指出了存在的挑战和未来的研究方向。", "conclusion": "通过全面概述LLMs在技术发展和应用方面取得的进展，论文旨在为研究者提供宝贵的资源，帮助他们在这个复杂且不断发展的LLMs领域中导航。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08427", "html_url": "https://arxiv.org/abs/2507.08427", "title": "ChainEdit: 通过逻辑规则引导的链式传播在大语言模型知识编辑中传播涟漪效应", "title_en": "ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains", "authors": "Zilu Dong,Xiangqing Shen,Zinong Yang,Rui Xia", "background": "当前的知识编辑方法在大型语言模型（LLMs）中难以在传递涟漪效应到相关事实时保持逻辑一致性。现有的知识编辑方法在传播连锁效果方面存在逻辑不一致的问题，这限制了知识编辑的效果和准确性。", "innovation": "本文提出了一种名为ChainEdit的框架，将知识图谱推导出的逻辑规则与LLM的逻辑推理能力相结合，以实现系统化的链式更新。自动从结构化的知识库中提取逻辑模式并与LLM内部逻辑对齐，ChainEdit动态生成并编辑逻辑上连接的知识簇。实验证明，与基准相比，在保持编辑可靠性和特定性的同时，ChainEdit在逻辑泛化方面提高了30%以上。此外，我们通过知识敏感的评估协议解决了现有基准中的评估偏差问题，这些协议能够分离外部依赖，确保知识编辑后的内部逻辑一致性。", "conclusion": "这项工作在确保知识编辑后内部逻辑一致性的同时，建立了新的在涟漪效应上的先进性能状态。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08297", "html_url": "https://arxiv.org/abs/2507.08297", "title": "KAT-V1：快问-自动思维技术报告", "title_en": "KAT-V1: Kwai-AutoThink Technical Report", "authors": "Zizheng Zhan,Ken Deng,Huaixi Tang,Wen Xiang,Kun Wu,Weihao Li,Wenqiang Zhu,Jingxuan Xu,Lecheng Huang,Zongxian Feng,Shaojie Wang,Shangpeng Yan,Jiaheng Liu,Zhongyuan Peng,Zuchen Gao,Haoyang Huang,Ziqi Zhan,Yanan Wu,Yuanxing Zhang,Jian Yang,Guang Chen,Haotian Zhang,Bin Chen,Bing Yu", "background": "在复杂推理任务中，现有模型可能会出现过度思考的问题，导致性能下降。因此，本文旨在解决这一问题，介绍了一个名为Kwaipilot-AutoThink (KAT) 的40B参数的开源大语言模型。", "innovation": "文章提出了KAT，通过以下创新点来解决过度思考问题：1. 构建基于新颖标注管道和多智能体合成策略的双模态数据集；2. 使用Multi-Token Prediction（MTP）增强的知识蒸馏方法，实现高效、细粒度的推理知识转移，且预训练成本较低；3. 实现冷启动初始化策略，引入模式选择先验并通过意图感知提示；4. 提出了融合中间监督的GRPO框架下的Step-SRPO强化学习算法，提供结构化指导，优化推理模式选择和响应准确性。", "conclusion": "KAT在多个基准测试中展示了与现有的最先进的模型相当或更好的性能，同时减少了约30%的令牌使用。KAT已经在Kwaipilot（Kuaishou的内部代码助手）中成功部署，提升了真实世界开发流程中的准确性、效率和可控性推理行为。此外，正在进行训练的200B混合专家模型也显示出显著的性能和效率提升，进一步证明了AutoThink框架的可扩展性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08440", "html_url": "https://arxiv.org/abs/2507.08440", "title": "基于大型语言模型在多智能体决策会议中检测共识", "title_en": "Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences", "authors": "Selina Heller,Mohamed Ibrahim,David Antony Selby,Sebastian Vollmer", "background": "决策会议是结构化的协作会议，汇集不同领域的专家以解决复杂问题，并就未来的行动或政策达成一致推荐。这些会议通常依赖于结构化的讨论以确保有效的对话和集体一致。大型语言模型（LLMs）通过模拟具有小组互动特征的协作多智能体系统，在模拟真实世界情境方面表现出显著的潜力。本文旨在研究一种基于LLMs的新型多智能体系统，旨在模拟决策会议，特别是检测参与者智能体之间的共识。研究在两个任务上评估了六种不同的LLMs：立场检测和立场极性检测，以确定其在复杂模拟中的有效性。研究结果表明，即使在动态且复杂的辩论中，LLMs也可以可靠地检测共识。在系统中引入一个共识检测智能体可以提高小组辩论的效率，增强辩论的整体质量和一致性，使其在结果和决策质量方面接近真实的决策会议。", "innovation": "提出了一种基于LLMs的多智能体系统，专门用于检测决策会议中的共识。该系统在两个任务上评估了六种不同LLMs：立场检测和立场极性检测。系统中的共识检测智能体可以提高多智能体辩论的效率和质量。研究还表明，利用LLMs可以接近真实的决策会议结果和决策质量，展示了LLMs在多智能体决策模拟中的潜在应用价值。并且，这种系统可能在跨领域的专家提炼工作坊中支持决策过程中发挥重要作用。", "conclusion": "这些发现展示了基于LLMs的多智能体系统在模拟团体决策过程中的潜力。研究还强调了该系统在不同领域的专家意见提炼工作坊中支持决策制定方面的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08487", "html_url": "https://arxiv.org/abs/2507.08487", "title": "提升论文连贯性评估：一项新颖的项目反应理论方法", "title_en": "Enhancing Essay Cohesion Assessment: A Novel Item Response Theory Approach", "authors": "Bruno Alexandre Rosa,Hilário Oliveira,Luiz Rodrigues,Eduardo Araujo Oliveira,Rafael Ferreira Mello", "background": "作文被认为是评估写作学习成果的有效机制。文本中的连贯性是文本的一个重要特征，它有助于建立文本部分之间的意义联系。然而，在教育人工智能领域，自动评分连贯性的任务仍然具有挑战性。目前使用的机器学习算法通常不考虑被分析语料库所包含实例的个别特征。因此，可以将项目反应理论适应到机器学习的上下文中，以表征所使用的模型的能力、难度和区分能力。本文旨在探讨基于项目反应理论的连贯性评分预测方法，并分析其性能。实验时采用的语料库包括扩展的Essay-BR语料库和巴西葡萄牙语叙述性语料库，总共包含7,798篇作文。", "innovation": "本文提出了一种基于项目反应理论的连贯性评分预测方法，并将其应用于机器学习模型中。相比于传统的机器学习模型和集成方法，该方法在多种评价指标上表现出更优越的效果。该研究探索了一种改进教育作文连贯性自动评分的潜在方法", "conclusion": "本研究展示了一种根据项目反应理论调整机器学习模型生成分数的方法，并且表明该方法在多项评估指标上优于传统方法。该方法为教育领域中自动评价连贯性提供了新的视角和可能的应用方向。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08496", "html_url": "https://arxiv.org/abs/2507.08496", "title": "LLaPa：一种基于视图语言模型的-counterfactual-感知程序规划框架", "title_en": "LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning", "authors": "Shibo Sun,Xue Li,Donglin Di,Mingjie Wei,Lanshun Nie,Wei-Nan Zhang,Dechen Zhan,Yang Song,Lei Fan", "background": "尽管大型语言模型（LLMs）通过强大的推理能力推进了有物理载体的人工智能系统的程序化规划，但多模态输入和反事实推理的整合方面仍显不足。本研究旨在填补这一空白，通过引入LLaPa，一种专门针对多模态程序化规划的视图语言模型框架来解决这些挑战。LLaPa能够从文本任务描述和视觉环境图像生成可执行的动作序列，实现了多模态和基于视觉语言模型的程序生成能力。", "innovation": "LLaPa框架引入了两个辅助模块来提高程序化规划的性能。第一，任务环境重排器（TER）利用任务导向的分割来创建任务敏感的空间特征，使文本描述与视觉环境对齐，并重点关注关键区域。第二，反事实活动检索器（CAR）识别和强调潜在的反事实条件，增强了模型在反事实场景中的推理能力。实验结果表明，LLaPa在ActPlan-1K和ALFRED基准上生成了更高质量的规划，性能优于先进的模型。", "conclusion": "LLaPa生成了高质量的规划，并在反事实感知的程序化规划方面取得了卓越的成绩，超越了最先进的模型，验证了其在多模态规划应用中的潜力。相关代码和模型已经开源。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08468", "html_url": "https://arxiv.org/abs/2507.08468", "title": "使用大型语言模型在奥地利增值税法律中的法律决策：一项实验研究", "title_en": "Using Large Language Models for Legal Decision-Making in Austrian Value-Added Tax Law: An Experimental Study", "authors": "Marina Luketina,Andrea Benkel,Christoph G. Schuetz", "background": "该论文评估了大型语言模型（LLMs）在奥地利和欧盟增值税（VAT）法律框架下协助法律决策的能力。在税务咨询实践中，客户通常用自然语言描述案件，这使得LLMs成为支持自动化决策和减轻税务专业人士工作负担的理想工具。然而，由于需要进行合法性和合理性的分析，LLMs有可能产生幻觉，这给实践带来了挑战。实验集中于两种增强LLMs性能的方法：微调和检索增强生成（RAG），并在教材案例和税务咨询公司的真实世界案例上进行应用，以系统地确定LLM系统的最佳配置并评估LLMs的法律推理能力。研究发现，虽然现有的原型尚不足以实现全面自动化，但适当配置的LLMs具有支持税务顾问自动执行常规任务和提供初步分析的潜力，并能提供合法性的证明", "innovation": "该研究使用了两种增强LLM性能的方法：微调和检索增强生成（RAG），并在教材案例和真实世界案例上进行应用，以系统地确定最佳配置并评估LLMs的法律推理能力。研究发现，适当配置的LLMs具有支持税务顾问自动执行常规任务和提供初步分析的潜力，并能提供合法性的证明", "conclusion": "研究结果表明，虽然现有的LLM原型尚不足以实现全面自动化，但适当配置的LLMs能够有效地支持税务专业人士在VAT任务中的工作，提供合法性的推理依据。然而，还需要进一步整合结构化的背景信息以处理客户隐含知识和情境特定文档的限制。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08499", "html_url": "https://arxiv.org/abs/2507.08499", "title": "PromotionGo在SemEval-2025 Task 11中的表现：基于特征的方法在短文本多情绪检测中的跨语言框架", "title_en": "PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts", "authors": "Ziyi Huang,Xia Cui", "background": "该论文关注文本情绪检测中的多标签情绪识别问题，尤其在短文本中的应用。现有研究虽然取得了进步，但仍面临低资源语言性能不佳、语言特定性能优化不足以及计算效率等问题。因此，需要一个动态适应文档表示和学习算法的框架，以优化不同语言的情绪检测性能，解决多语言情绪检测中的挑战。", "innovation": "该研究提出了一种基于特征的框架，该框架能够动态适应文档表示和学习算法，以优化语言特定的情绪检测性能。主要创新包括：1) 对不同语言进行多语言情绪检测的全面评估（28种语言）。2) 通过使用TF-IDF、FastText及Sentence-BERT等方法来处理低资源语言和高性能语言。3) 探索PCA在减少训练时间的同时保持性能的有效性，特别针对FastText和神经网络模型如MLP。4) 分析计算效率与模型复杂度之间的权衡。该框架提供了跨语言短文本多情绪检测的规模化解决方案。", "conclusion": "本文提出的框架为多语言情绪检测提供了可扩展的解决方案，解决了语言多样性带来的挑战和资源限制。通过动态调整文档表示和学习算法，攻克了跨语言环境下情绪检测的挑战，证明了该方法的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08109", "html_url": "https://arxiv.org/abs/2507.08109", "title": "以应用到公共评论处理为例的LM驱动子程序的审计、对齐与优化", "title_en": "Audit, Alignment, and Optimization of LM-Powered Subroutines with Application to Public Comment Processing", "authors": "Reilly Raab,Mike Parker,Dan Nally,Sadie Montgomery,Anastasia Bernat,Sai Munikoti,Sameera Horawalavithana", "background": "语言模型（LMs）的出现有潜力大大加速能够转换为文本处理的任务，但其实现受限于安全、解释性和偏见等方面的担忧。如何在透明和可审计的方式下负责任地利用LMs，减少风险并允许人类专家专注于基于信息的决策而非数据分析或提示工程？本文提出了一种框架，用于在传统异步代码中声明静态类型的、由LM驱动的子程序（即可调用的功能过程），以利用稀疏的人类专家反馈在线改善每个子程序的性能。在实现中，所有由LM生成的产物（即提示、输入、输出和数据依赖）将被记录和在需要时供审计使用。我们将其打包为一个库，以支持其采用和持续发展。此框架可能适用于多个实际决策流程（例如医疗和法律领域），本文则在1969年国家环境政策法（NEPA）要求的公共评论处理上下文中进行了评估：利用此框架开发了‘CommentNEPA’应用程序，用于汇总、组织和总结项目环境审查过程中收到的公众评论。我们通过比较其无人类反馈时的输出与由人类标注的官方环境影响声明的历史数据来定量评估该应用。", "innovation": "本文提出了一种框架，用于在传统异步代码中声明和使用由语言模型驱动的子程序，并确保所有生成的产物被记录和可用于审计。这种框架不仅减少了LMs使用的风险，还使得人类专家能够更加高效地进行决策。此外，该框架通过不断学习稀疏的专家反馈来在线优化LMs的性能。该框架的应用实例为公共评论处理，为实际决策过程提供了一个可行的解决方案。", "conclusion": "本文提出了一个审计、对齐和优化语言模型驱动子程序的框架，并通过公共评论处理的应用实例进行了验证。该框架能够有效改善决策过程中的信息处理效率，同时减少了风险。未来的工作可以探索该框架在其他复杂决策流程中的适用性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08498", "html_url": "https://arxiv.org/abs/2507.08498", "title": "LLM在环中的语义增强隐含主题建模", "title_en": "Semantic-Augmented Latent Topic Modeling with LLM-in-the-Loop", "authors": "Mengze Hong,Chen Jason Zhang,Di Jiang", "background": "LDA是一种广泛用于揭示文档集合中抽象主题的生成概率模型。本文研究了通过将大型语言模型（LLMs）集成到主题模型的关键初始化和后校正阶段来增强主题模型的有效性。由于LDA对初始化的质量高度依赖，本文进行了大量的实验来研究LLM指导的主题聚类对Gibbs采样算法初始化的影响，结果显示该初始化策略虽然改善了LDA的早期迭代，但在收敛性方面表现最差，不如基线方法。另一方面，LLM支持的后校正取得了5.86%的语义连贯性评价改进。这些结果表明LLM在环中的方法具有实际优势，并挑战了LLMs一直是文本挖掘最优选择的观念。", "innovation": "本文提出了一种将LLMs集成到主题模型的关键初始化和后校正阶段的方法，探索其对LDA的影响，并通过实验验证了其效果，特别是在后校正阶段显示出显著的改进。", "conclusion": "尽管LLMs在初始阶段的初始化中未能提供更好的性能，但它们在后校正阶段确实改善了主题模型的语义连贯性。这表明LLMs在文本挖掘中的应用可能不总是最佳选择，特别是在特定的任务阶段中，它们可能能提供更好的效果。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08491", "html_url": "https://arxiv.org/abs/2507.08491", "title": "使用clembench的对话游戏评估 paradigm：大语言模型评估的第三范式", "title_en": "A Third Paradigm for LLM Evaluation: Dialogue Game-Based Evaluation using clembench", "authors": "David Schlangen,Sherzod Hakimov,Jonathan Jordan,Philipp Sadler", "background": "当前大语言模型（LLMs）的评估有两种主要范式：参考基准评估和偏好基准评估。前者是一种通用机器学习模型评估的方式，依赖预定义的任务实例和参考执行。后者则通过用户的自定义意图来评估模型，通常用户会选择最佳的回应。最近，第三种范式——对话游戏评估——融合了这两种方法的部分优势，强调多轮次、无参考的、可重复的交互，并重视目标导向性。尽管这种方法已被多个项目证明其价值，但由于缺乏成熟且易于复用的实现，其推广受限。本研究旨在介绍clembench，一个自2023年以来持续开发，并在最新版本中优化为便于通用使用的大语言模型评估工具。", "innovation": "clembench是一个专注于对话游戏评估的大语言模型基准测试工具，旨在提供对多轮次、无参考、可重复交互的控制，同时强调目标导向性。该工具将部分地解决当前评估方法中的局限性，例如控制性与生态效度之间的权衡。clembench通过提供一组英文基准游戏实例，允许用户自行测试自己的模型。此外，该工具还支持轻松扩展，以便进行新的定制评估测试。", "conclusion": "本研究提出并介绍了clembench，这是一款专为大语言模型评估设计的对话游戏基准测试工具。它提供了多轮次、无参考、可重复的交互能力，支持定制化评估，并且易于使用和扩展。这项工作旨在促进大语言模型评估的第三范式，即对话游戏评估方法的普及，使得研究人员和开发者能够更便捷地评估自己的模型。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08606", "html_url": "https://arxiv.org/abs/2507.08606", "title": "DocPolarBERT：一种使用布局结构相对极坐标编码的预训练文档理解模型", "title_en": "DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures", "authors": "Benno Uthayasooriyar,Antoine Ly,Franck Vermet,Caio Corro", "background": "在文档理解中，现有的模型通常需要绝对的2D位置嵌入，这使得模型在处理不同布局的文档时具有挑战性。", "innovation": "DocPolarBERT是一种布局感知的BERT模型，它通过将自注意力机制扩展到利用相对极坐标系统中的文本块位置，从而消除了对绝对2D位置嵌入的需求。尽管是在一个大小仅为广泛使用的IIT-CDIP语料库的六分之一的数据集上进行预训练，但DocPolarBERT仍能够达到最新的技术水平。", "conclusion": "这些结果表明，精心设计的注意力机制可以在减少预训练数据的情况下表现出色，为文档理解提供了一个有效的替代方案。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08459", "html_url": "https://arxiv.org/abs/2507.08459", "title": "在大型语言模型答案诊断中整合错误归因：构建评估框架", "title_en": "Diagnosing Failures in Large Language Models' Answers: Integrating Error Attribution into Evaluation Framework", "authors": "Zishan Xu,Shuyi Xie,Qingsong Lv,Shupei Xiao,Linlin Song,Sui Wenjuan,Fan Lin", "background": "随着大型语言模型（LLMs）在各种任务中的广泛应用，主流的LLM平台每天产生大量的用户-模型交互。为了有效地分析模型性能并诊断其回答中的错误，开发一套能够系统地分类和指定错误的自动化框架变得至关重要。但是，现有的评价模型缺乏错误归因能力。因此，该研究提出了一个全面的错误归因框架，该框架包含6个主要类别和15个次要类别，以促进深入分析。基于这一框架，研究者还开发了一个数据集（AttriData），该数据集专门用于错误归因，并包括相应的分数和反馈。同时，他们还提出了一种名为MisAttributionLLM的模型，该模型是第一个能够在生成分数、归因错误和提供反馈的同时应用的通用评价模型。这一框架和模型的构建旨在解决现有模型在错误归因方面的问题。", "innovation": "研究建立了一个包含6个主要类别和15个次要类别的综合错误归因框架，并开发了AttriData数据集以及MisAttributionLLM模型，这是第一个能够同时生成分数、归因错误和提供反馈的通用评价模型。", "conclusion": "通过广泛的实验和分析，研究确认了所提出方法的有效性和鲁棒性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08719", "html_url": "https://arxiv.org/abs/2507.08719", "title": "多语言多模态软件开发人员用于代码生成", "title_en": "Multilingual Multimodal Software Developer for Code Generation", "authors": "Linzheng Chai,Jian Yang,Shukai Liu,Wei Zhang,Liran Wang,Ke Jin,Tao Sun,Congnan Liu,Chenchen Zhang,Hualei Zhu,Jiaheng Liu,Xianjie Wu,Ge Zhang,Tianyu Liu,Zhoujun Li", "background": "大型语言模型（LLMs）的迅速发展显著提升了代码生成能力，但大多数模型仍局限于处理文本，忽视了实际软件开发中不可或缺的视觉辅助工具，如图表和流程图。本文旨在填补这一空白。", "innovation": "本文提出了MM-Coder，这是一种多语言多模态软件开发人员，将统一建模语言（UML）图和流程图（称为视觉流程）与文本指令相结合，以提升代码生成的准确性和架构对齐。此外，本文还开发了MMc-Instruct，这是一个包含基于视觉流程代码生成的多样化多模态指令调优数据集，使得MM-Coder 能够像人类开发者一样综合处理文本和图形信息。本文还引入了MMEval，一个用于评估多模态代码生成的新基准，解决了现有纯文本限制的问题。我们的评估显示，模型在精准捕获视觉信息、指令跟随以及高级编程知识方面仍然存在显著挑战。", "conclusion": "本研究旨在通过使语言模型能够解释和实现通过文本和视觉设计传达的复杂规范，革命性地推动工业编程。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08704", "html_url": "https://arxiv.org/abs/2507.08704", "title": "KG-Attention: 测试时基于知识图谱的双向信息聚合注意力机制", "title_en": "KG-Attention: Knowledge Graph-Guided Attention at Test-Time via Bidirectional Information Aggregation", "authors": "Songlin Zhai,Guilin Qi,Yuan Meng", "background": "知识图谱（KGs）在增强大型语言模型（LLMs）方面发挥着关键作用，通过引入结构化和接地知识来改进学习过程。然而，现有大多数KG增强方法主要依靠参数密集型微调来提高模型的性能，这可能导致灾难性遗忘，从而削弱预训练模型的泛化能力。此外，它们由于静态集成框架的原因，在实时知识更新方面表现出有限的适应性。为了应对这些问题，文中提出了一种基于知识图谱测试时增强框架，通过引入一个专门的知识图谱引导注意力（KGA）模块，该模块能够动态融合知识并且不进行任何参数更新，解决了参数密集型微调可能带来的灾难性遗忘，和静态集成框架下难以适应实时知识更新的问题。", "innovation": "文中提出了一种基于知识图谱测试时增强框架，通过知识图谱引导注意力（KGA）模块，该模块中包含两个协同路径：外向聚合和内向聚合。外向聚合通过输入驱动的知识图谱融合动态将外部知识集成到输入表示中，内向聚合通过知识图谱引导筛选，增强知识相关的模式并抑制无任务的相关信号。外向路径和内向路径协同工作，可以在测试时支持实时知识融合，而不需要进行任何参数修改，解决了参数密集型微调与实时知识更新的适应性问题。", "conclusion": "该方法在五个基准测试上进行了广泛实验，结果表明KGA模块具有可比拟的知识融合性能。这件事基于知识图谱的注意力机制研究的一个重要进展，能够有效提升大型语言模型在实时知识更新场景下的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08799", "html_url": "https://arxiv.org/abs/2507.08799", "title": "KV 缓存引导在小型语言模型中诱导推理", "title_en": "KV Cache Steering for Inducing Reasoning in Small Language Models", "authors": "Max Belitsky,Dawid J. Kopiczko,Michael Dorkenwald,M. Jehanzeb Mirza,Cees G. M. Snoek,Yuki M. Asano", "background": "该研究背景是在小型语言模型中引入链式思考推理能力，希望利用轻量级的方法来间接引导模型的行为，而不需要进行模型微调或提示修改，从而在多样化的推理基准测试中提升模型的质量和量化任务性能。", "innovation": "该研究提出了缓存引导，这是一种轻量级的方法，可以通过直接对键值缓存的一次性干预来隐式引导语言模型。该方法利用GPT-4生成的推理痕迹来构建引导向量，将其行为向更详细、多步骤的推理转变。与需要连续干预的激活引导技术相比，一次性的缓存引导技术在超参数稳定性、推理效率和集成便利性方面具有明显优势，提供了一种更为可靠和实际的控制生成方案。", "conclusion": "实验评估显示，缓存引导提高了模型推理的定性结构和量化任务性能。与以往需要持续干预的激活引导技术相比，本研究提出的一次性缓存引导技术在超参数稳定性、推理时间效率和集成简便性方面具有显著优势，使其成为控制生成更为稳健和可行的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08477", "html_url": "https://arxiv.org/abs/2507.08477", "title": "ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual Speech Recognition", "title_en": "ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual Speech Recognition", "authors": "Qingliang Meng,Hao Wu,Wei Liang,Wei Xu,Qing Zhao", "background": "大语言模型与自动语音识别系统的深度集成已成为具有高实践价值的研究方向。在监督微调(SFT)阶段，低秩适应(LoRA)通常会出现过拟合的问题，这也是该研究的背景情况。", "innovation": "该研究提出了一个新的训练范式——迭代LoRA培训(ILT)结合迭代伪标签策略。这个创新性方法有效地提升了模型性能的理论上限，解决了LoRA在SFT阶段常见的过拟合问题。", "conclusion": "通过在Whisper-large-v3和Qwen2-Audio上进行系统实验，并采用分阶段的培训过程：焦点培训、反馈培训和修正培训，该方法的有效性得到了实验结果的验证。此外，MegaAIS研究团队将此技术应用于2025年国际语音通讯会议的多语种对话语音语言建模挑战中的两个赛道，并分别取得了优异成绩，印证了该方法的实用可行性和强大的应用潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08621", "html_url": "https://arxiv.org/abs/2507.08621", "title": "基于LLM的论证分类全面研究：从LLAMA到GPT-4o再到Deepseek-R1", "title_en": "A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1", "authors": "Marcin Pietroń,Rafał Olszowski,Jakub Gomułka,Filip Gampel,Andrzej Tomski", "background": "论辩分析(AM)是一个跨学科的研究领域，它结合了逻辑、哲学、语言学、修辞学、法律、心理学和计算机科学的见解。近年来，随着大型语言模型(LLMs)的出现，AM领域取得了显著进展，这些模型大幅提高了分析和提取论证语义的效率，相比传统方法和其他深度学习模型。尽管有许多测试和验证LLM质量的基准测试，但在公共可用的论证分类数据库操作上仍然缺乏研究和结果。因此，研究专注于使用LLM和提示算法分析可持续发展论证和UKP数据集，比较了包括GPT、Llama和DeepSeek模型及其具有链式推理算法增强的推理版本。研究表明，ChatGPT-4在论证分类基准测试中表现最佳，Deepseek-R1则在具有推理能力的模型中表现最好。然而，所有模型均存在错误，研究对此进行了详细分析。已有研究在此基础上进行了更全面的数据集分析，同时揭示了已知提示算法在论证分析中的弱点，并提出了改进建议。", "innovation": "本研究首次使用大型语言模型和提示算法分析可持续发展论证和UKP数据集。比较了一系列包括GPT、Llama和DeepSeek模型以及它们的带有Chain-of-Thoughts算法的推理增强版本。此外，研究强调了已知提示算法在论证分析中的不足，并指出了改进的方向。", "conclusion": "本研究全面分析了不同大型语言模型在论证分类任务上的表现，探讨了它们在应用中的优势和不足，并揭示了改进提示算法的方法。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08128", "html_url": "https://arxiv.org/abs/2507.08128", "title": "Audio Flamingo 3：使用完全开放的大音频语言模型推进音频智能", "title_en": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models", "authors": "Arushi Goel,Sreyan Ghosh,Jaehyeon Kim,Sonal Kumar,Zhifeng Kong,Sang-gil Lee,Chao-Han Huck Yang,Ramani Duraiswami,Dinesh Manocha,Rafael Valle,Bryan Catanzaro", "background": "当前，存在多种语音、声音和音乐的信息处理模型，但缺乏一个同时实现演讲、声音和音乐理解与推理的全方位、开放源代码的大型音频语言模型。", "innovation": "本文提出了名为Audio Flamingo 3 (AF3) 的模型。AF3引入了四种新的功能：1) AF-Whisper统一音频编码器，用于在三种模态（语音、声音和音乐）之间进行全面联合表示学习的新策略；2) 灵活的即需即用推理，允许模型在回答问题前进行链式思考；3) 多轮次、多音频对话；4) 延长音频理解与推理，可达10分钟，包括语音理解。此外，为了实现这些功能，该文提出了几种大规模训练数据集以及一种新的五阶段课程训练策略，并仅使用开源音频数据，AF3在超过20项（长）音频理解与推理基准测试中取得了新的SOTA结果。", "conclusion": "通过这种训练和新的数据集，AF3在多种音频理解与推理基准测试中表现出色，尤其是在大型音频数据源上，超越了用更大数据集训练的开放源代码和封闭源代码模型。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08191", "html_url": "https://arxiv.org/abs/2507.08191", "title": "TREC 2021 深度学习赛道概述", "title_en": "Overview of the TREC 2021 deep learning track", "authors": "Nick Craswell,Bhaskar Mitra,Emine Yilmaz,Daniel Campos,Jimmy Lin", "background": "TREC 深度学习赛道已经步入第三年。今年，继续采用了 MS MARCO 数据集，该数据集提供了数十万的人工标注训练标签，用于段落和文档排名任务。同时，今年刷新了文档和段落集合，导致文档集合的大小增加了近四倍，段落集合的大小增加了近16倍。大规模预训练的深度神经排名模型仍优于传统的检索方法。此外，单阶段检索在两个任务上都能取得较好的表现，尽管仍然无法与多阶段检索流水线媲美。", "innovation": "今年刷新了文档和段落集合，显著增加了数据集的规模，实验表明大规模预训练的深度神经排名模型继续优于传统检索方法。此外，发现单阶段检索在两个任务上表现很好，但多阶段检索流水线在性能上仍是优胜者。此外，数据集规模的增加和一般数据的刷新引发了关于 NIST 判断的完整性和从旧集合到新集合映射训练标签的质量的一些问题。", "conclusion": "尽管单阶段检索在两个任务上都能取得较好的表现，但仍然无法与多阶段检索流水线媲美。由于数据集规模的增加和一般数据的刷新，引发了对 NIST 判断完整性及训练标签质量的一些问题。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08538", "html_url": "https://arxiv.org/abs/2507.08538", "title": "AI语言能力监测器——追踪多语言基准上的大语言模型进展", "title_en": "The AI Language Proficiency Monitor -- Tracking the Progress of LLMs on Multilingual Benchmarks", "authors": "David Pomerenke,Jonas Nothnagel,Simon Ostermann", "background": "为了确保所有人公平地获取大语言模型（LLMs）带来的好处，评估LLM在世界各语言中的能力是至关重要的。该研究引入了一种全面的多语言基准，旨在系统地评估LLM在多达200种语言中的表现，尤其是低资源语言。该基准综合了包括翻译、问答、数学和推理在内的多种任务，使用了如FLORES+、MMLU、GSM8K、TruthfulQA和ARC等数据集。该项目通过提供开源的自动更新的排行榜和仪表板，支持研究人员、开发人员和政策制定者识别模型性能中的优势与不足。", "innovation": "该项目通过引入AI语言能力监测器，开发了一个系统，可以全面评估LLM在多达200种语言中的表现，特别是低资源语言。此平台提供了一个开源、自动更新的排行榜和仪表板，不仅能够排名模型，还能提供描述性见解，如全球能力地图和时间趋势。此外，该系统通过补充和扩展了先前的多语言基准，旨在提高透明度、包容性和多语言AI的发展进度。", "conclusion": "该研究旨在通过客观评估LLM在不同语言中的能力，促进透明度、包容性和多语言AI的进步。该系统目前可访问：this https URL."}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08306", "html_url": "https://arxiv.org/abs/2507.08306", "title": "M2-Reasoning: 使MLLMs具备统一的通用和空间推理能力", "title_en": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "authors": "Inclusion AI:Fudong Wang,Jiajia Liu,Jingdong Chen,Jun Zhou,Kaixiang Ji,Lixiang Ru,Qingpei Guo,Ruobing Zheng,Tianqi Li,Yi Yuan,Yifan Mao,Yuting Xiao,Ziping Ma", "background": "近年来，通过强化学习和可验证的奖励（RLVR）提升的多模态大型语言模型（MLLMs）在推理能力方面取得了显著进步。然而，这些模型仍存在一个关键问题：它们在动态空间交互方面表现不佳，而在现实应用中这种能力至关重要。", "innovation": "该论文提出了M2-Reasoning-7B模型，旨在在通用和空间推理方面表现卓越。主要创新点包括：（1）一个新颖的数据管道生成了294.2万个高质数据样本（包括168万个冷启动微调和126.2万个RLVR），这些样本逻辑连贯且经过全面评估；（2）动态多任务训练策略，逐步优化以缓解数据之间的冲突，并为不同的任务提供了特定奖励以提供定制激励信号。", "conclusion": "M2-Reasoning-7B模型通过精心设计的数据和先进的训练策略，在8个基准测试中达到了新的最佳水平，展示了在通用和空间推理领域的卓越性能。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08284", "html_url": "https://arxiv.org/abs/2507.08284", "title": "通过合成数据和RL引导的对抗训练实现轻量级安全防护", "title_en": "Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training", "authors": "Aleksei Ilin,Gor Matevosyan,Xueying Ma,Vladimir Eremin,Suhaa Dada,Muqun Li,Riyaaz Shaik,Haluk Noyan Tokgozoglu", "background": "小型语言模型在内容审核任务中可以达到甚至超越大型模型的性能，这主要归功于高质量合成数据的生成和对抗训练。通过人工精选的基础数据经过查询扩充和改写来生成多样且富含上下文的样本，并通过多次润色确保数据的一致性和相关性。这为轻量级安全模型提供了一种可靠的方式，能够在保证高性能的同时，减少计算开销并增强对攻击的抵抗力。", "innovation": "引入了一种轻量级但仍高效的基于合成数据和强化学习引导的对抗训练框架，用于语言模型的安全防护。这一框架通过生成高质量的合成数据和利用强化学习引导生成器，促进生成复杂的合成例子，进而更准确地细化安全分类器的训练，增强其检测和缓解有害内容的能力。此外，研究还利用了少量高效训练LLM的方法，增强了大型生成模型的性能。", "conclusion": "该框架使小型语言模型能够作为有效的安全防护栏，不仅降低了计算开销，还增强了对抗攻击的抵抗力，为AI系统的内容审核提供了一种可扩展且高效的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08432", "html_url": "https://arxiv.org/abs/2507.08432", "title": "xpSHACL：利用检索增强生成和大型语言模型的解释性SHACL验证", "title_en": "xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models", "authors": "Gustavo Correa Publio,José Emilio Labra Gayo", "background": "SHACL是一种强大的语言，用于验证RDF数据。鉴于知识图谱（KGs）在行业中的关注增加，越来越多的用户需要正确验证链接数据。然而，传统的SHACL验证引擎通常会生成难以非技术用户理解和操作的简短英文报告。因此，本文提出了一种称为xpSHACL的新解释性SHACL验证系统。", "innovation": "xpSHACL通过结合基于规则的解释性树和检索增强生成（RAG）以及大型语言模型（LLMs），生成详细、多语言的人类可读的约束违规解释。xpSHACL的一个关键特性是使用违规知识图谱（Violation KG）来缓存并重用解释，提高效率和一致性。", "conclusion": "xpSHACL提供了一种新的方法，可以生成易于理解的多语言违规解释，提高了SHACL验证的解释性，有助于非技术用户更好地理解和处理违规情况。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08575", "html_url": "https://arxiv.org/abs/2507.08575", "title": "大型多模态模型制图地图理解在文本本地化地理参考中的应用", "title_en": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing", "authors": "Kalana Wijegunarathna,Kristin Stock,Christopher B. Jones", "background": "数百年来收集的数百万份生物样本记录在自然历史收藏中没有地理坐标参考。对与这些样本相关联的复杂地点描述进行地理参考是一项劳动密集型任务，收藏机构难以应对。现有的自动化方法未充分利用地图作为地理参考复杂关系的重要工具。", "innovation": "提出了一种新的方法，利用近期大型多模态模型（LMM）的多模态能力。这种方法使模型能够通过地点描述中的视觉上下文来理解空间关系。通过网格化方法在零样本设置中适应这些自回归模型。实验结果显示在手工标注的小型数据集上，该方法相对于单一模态地理参考与大型语言模型及现有地理参考工具，平均距离误差减少至约1公里。", "conclusion": "提出了基于这一方法的实际框架，拟将其集成到地理参考工作流程中，并结合LMM对细粒度地图的理解进一步探讨了实验结果。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08660", "html_url": "https://arxiv.org/abs/2507.08660", "title": "自动语音转录对说话人归属的影响", "title_en": "The Impact of Automatic Speech Transcription on Speaker Attribution", "authors": "Cristina Aggazzotti,Matthew Wiesner,Elizabeth Allyn Smith,Nicholas Andrews", "background": "说话人归属是从演讲者的演讲转录中识别出说话人的任务，主要依据他们在语言使用上的模式。这个任务在音频不可用或不可靠时（如被删除或匿名化）尤其有用。以往的研究主要集中在使用人工标注员生成的转录文本来进行说话人归属的可能性上。然而，在实际环境中，通常只能获得由自动语音识别（ASR）系统生成的更加错误的转录文本。该论文旨在首次全面研究自动转录对说话人归属性能的影响，探索转录错误如何影响说话人归属性能，以及ASR系统的特性如何影响归属。", "innovation": "首次对自动转录对说话人归属性能的影响进行了全面研究，发现了自动转录错误对单词级别的说话人归属性能影响较小，并且恢复真实转录文本的目标与说话人归属性能的相关性最小。研究结果表明，使用ASR生成的更加错误的转录文本进行说话人归属与基于人工转录的数据进行说话人归属表现相当，甚至更好，因为ASR转录错误可以捕捉到揭示说话人身份的特定特征。", "conclusion": "总的来说，研究结果表明，使用ASR生成的充满错误的转录文本进行说话人归属与基于人工转录的数据进行说话人归属的表现相当，甚至更好，这可能是因为ASR转录错误能够捕捉到能揭示说话人身份的特定特征。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08665", "html_url": "https://arxiv.org/abs/2507.08665", "title": "KELPS:一种通过语义句法对齐实现多语言自形式化的框架", "title_en": "KELPS: A Framework for Verified Multi-Language Autoformalization via Semantic-Syntactic Alignment", "authors": "Jiyao Zhang,Chengli Zhong,Hui Xu,Qige Li,Yi Zhou", "background": "现代大型语言模型（LLMs）在将非正式数学形式化为可机器验证的定理方面显示出令人鼓舞的进展。然而，这些方法仍受限于多语言平行语料库的有限数量和质量。因此，亟需一种新的方法来解决这些限制，以便更好地将非正式数学内容高效且准确地转换为形式语言，供后续机器验证使用。", "innovation": "本文提出了一种新颖的神经符号框架KELPS（基于知识-方程逻辑处理系统），用于处理问题。KELPS框架包括三个步骤：将自然语言翻译为新设计的知识方程（KEs），通过严格定义的规则将其转换为目标语言，并创建了超过60,000个问题的平行语料库。KELPS框架在MiniF2F数据集上实现了88.9%的语法准确率（pass@1），超越了目前最先进的模型如Deepseek-V3和Herald。所有数据集和代码均可在补充材料中找到。", "conclusion": "本文提出的KELPS框架在将自然语言问题转换为形式化语言方面表现出色，并显著提高了多语言自动形式化的质量和效率。这些成果为未来的工作提供了宝贵的资源和新的思路。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08637", "html_url": "https://arxiv.org/abs/2507.08637", "title": "利用波let增强随机频谱注意（WERSA）在接近线性时间下扩展注意力到非常长的序列", "title_en": "Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA)", "authors": "Vincenzo Dentamaro", "background": "典型的注意力机制具有$O(n^2)$的时间复杂度，这使得在处理长序列时计算成本非常高。WERSA是一种创新机制，它将内容自适应的随机频谱特征与多分辨率小波和可学习参数相结合，以线性$O(n)$的时间复杂度高效地处理长序列。", "innovation": "WERSA合并了内容自适应随机频谱特征和多分辨率Haar小波，并通过可学习参数选择性地注意数据中的重要规模，同时保持线性效率。在大规模比较中，WERSA在多种基准测试（视觉、NLP、层次推理）和多种注意力机制下表现出优越性，精度和性能均有提升。", "conclusion": "WERSA由于其降低计算负担而不牺牲精度的特点，使得有可能在低资源硬件上构建更实用、更负担得起、更长上下文的模型，从而实现更具可持续性和扩展性的AI开发。特别是在处理ArXiv-128k等极其长的序列时，WERSA超越了vanilla注意力、FlashAttention-2和其他方法，展现了更为卓越的准确度和效率。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08800", "html_url": "https://arxiv.org/abs/2507.08800", "title": "NeuralOS：通过神经生成模型模拟操作系统", "title_en": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models", "authors": "Luke Rivard,Sun Sun,Hongyu Guo,Wenhu Chen,Yuntian Deng", "background": "该研究背景涉及一种新的神经框架NeuralOS，旨在通过直接预测屏幕框架来模拟操作系统的图形用户界面（GUI），响应用户的输入，如鼠标移动、点击和键盘事件。这一方法克服了传统方法的局限，并提供了模拟和生成真实操作系统界面的新途径。", "innovation": "NeuralOS 创新地结合了循环神经网络（RNN），用于跟踪计算机状态，与基于扩散的神经渲染器，用于生成屏幕图像。该模型是在一个大规模的数据集上进行训练的，该数据集包含Ubuntu XFCE的录制，包括随机生成的交互和由人工智能代理生成的现实交互。研究结果表明，NeuralOS成功地生成了逼真的GUI序列，准确地捕捉了鼠标交互，并可靠地预测了如应用程序启动这样的状态转换。", "conclusion": "虽然精确建模细粒度的键盘交互仍然具有挑战性，但NeuralOS为创建适应性更强、生成性更优的神经接口以用于未来的人机交互系统提供了一种方法。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08768", "html_url": "https://arxiv.org/abs/2507.08768", "title": "关于档案音频处理的障碍", "title_en": "On Barriers to Archival Audio Processing", "authors": "Peter Sullivan,Muhammad Abdul-Mageed", "background": "本研究利用UNESCO收集的20世纪中叶的无线电录音，探讨现代现成的语言识别（LID）和说话人识别（SR）方法的稳健性，特别是对于多语言说话人和跨年龄段录音的影响。研究背景包括对现代LID和SR方法处理非母语和带音的语音能力的评估，同时也指出了在档案处理中使用SR方法进行说话人索引时存在的问题和限制，以及这些方法在处理信道、年龄和语言相关偏差时的脆弱性问题。", "innovation": "使用独特的UNESCO无线电录音集来评估现代现成的LID和SR方法的稳健性，特别关注多语言说话人和跨年龄段的录音对系统性能的影响。研究揭示了语言识别系统的改进，特别是在处理第二语言和口音语音方面的能力，同时也识别了说话人嵌入作为语音处理管道中最脆弱的部分，容易受到信道、年龄和语言相关偏差的影响。这些发现对于希望使用SR方法进行档案说话人索引的研究人员和实践者具有重要意义。", "conclusion": "研究指出，尽管现代LID系统在处理非母语和带音的语音方面取得了进步，但说话人嵌入仍然是语音处理管道中脆弱的组成部分，容易受到信道、年龄和语言相关偏差的影响。因此，未来的工作需要解决这些偏差问题，以解决档案音频处理中的障碍，特别是当档案考虑使用SR方法进行说话人索引时。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2301.12463", "html_url": "https://arxiv.org/abs/2301.12463", "title": "使用潘尼系统声音和有限状态机比较口头语言", "title_en": "Comparing Spoken Languages using Paninian System of Sounds and Finite State Machines", "authors": "Shreekanth M Prabhu,Abhisek Midya", "background": "口头语言的研究包括音系学、形态学和语法。语言可以分为词根语言、屈折语和干支语言。语言会随着时间和地域的变化而发展，这一过程伴随着语言边界的变迁。这些因素导致词汇的形成，词汇在不同语言之间具有共通性和相似性，同时也存在显著和微妙的区别。通过比较词汇并进行详细分析，提出了语言家族的假设。例如，西方语言学家认为吠陀梵语是印度-伊朗语系的一部分，属于印度-欧洲语系的分支，德拉威语属于完全不同的语系。在此基础上，本研究重审了这些结论，并提出了以梵语为核心的语言生态系统模型作为替代广泛接受的语言谱系模型。", "innovation": "本研究采用潘尼系统的声音和有限状态机来构建音标地图。在此基础上，将语言中的单词表示为音标地图上的状态转换，并构建相应的形态有限自动机（MFA），接受词组。这一模型为进一步挑战政策驱动的语言学研究提供了重要步骤", "conclusion": "本研究提出了一个新的语言生态系统模型，以梵语为中心，而不是传统的语言谱系模型。该模型利用潘尼系统的音标来构建音标地图，并通过有限状态机分析词汇，旨在挑战领域内的政策驱动研究。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08794", "html_url": "https://arxiv.org/abs/2507.08794", "title": "一令牌愚弄LLM-as-judge", "title_en": "One Token to Fool LLM-as-a-Judge", "authors": "Yulai Zhao,Haolin Liu,Dian Yu,S.Y. Kung,Haitao Mi,Dong Yu", "background": "生成奖励模型（也称为LLM-as-judges），利用大型语言模型（LLMs）评估答案质量，在可验证奖励的强化学习（RLVR）中越来越被采用。它们通常优于固定的规则基度量，尤其是在涉及到自由形式输出的复杂推理任务中。在这一范式中，通常会让LLM去对比候选答案与真实参考答案，并给出一个表明正确性的二元奖励。尽管这个比较任务看似简单，但研究发现，生成奖励模型对表面上的操纵存在明显的脆弱性：诸如非单词符号（例如“：”或“.”）或推理开启词（例如“思维过程：”和“让我们一步一步解决这个问题”）等都常常会引发错误的奖励阳性结果。这种弱点在LLM、数据集和提示格式中普遍存在，对依赖于生成奖励模型的核心算法框架（如拒绝采样、偏好优化和RLVR）造成严重威胁。", "innovation": "本文提出了一种简单而有效的数据增强策略，并训练了一个更稳健的生成奖励模型。这些发现突显了更可靠的基于LLM的评估方法的迫切需求。作者还发布了其稳健的、通用领域的奖励模型及其合成训练数据。通过这种方法，增加了对抗攻击的抵抗力，并提供了一种评估和改进生成奖励模型可靠性的方法。", "conclusion": "本文研究了生成奖励模型在复杂推理任务中的脆弱性，尤其是它容易受到表面上的操纵。通过简单的数据增强策略和新模型的训练，研究者提高了生成奖励模型的鲁棒性，强调了更可靠的基于LLM的评估方法的必要性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08771", "html_url": "https://arxiv.org/abs/2507.08771", "title": "BlockFFN：朝着具有片段级激活稀疏性的端侧加速友好混合专家架构", "title_en": "BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity", "authors": "Chenyang Song,Weilin Zhao,Xu Han,Chaojun Xiao,Yingfa Chen,Yuxuan Li,Zhiyuan Liu,Maosong Sun", "background": "大型语言模型（LLMs）的计算负担通过以混合-of-专家（MoE）为代表的表现为激活稀疏性的架构得到了一定程度的缓解，但传统的MoE由于其非可微分和不灵活的路由机制，导致模型性能受损。片段级稀疏性低，尽管每个令牌激活的参数量少，但这些稀疏激活的架构中多个连续令牌激活的参数比例大，这种稀疏模式对低资源条件下的加速不友好，且与主流加速技术（例如推测性解码）不兼容。", "innovation": "提出了新型MoE架构BlockFFN及其高效训练和部署技术。BlockFFN使用结合ReLU激活和RMSNorm的路由器实现了可微的灵活路由；设计了针对token-level稀疏性和chunk-level稀疏性的感知训练目标，使BlockFFN更易于加速；并首次实现了结合激活稀疏性和推测性解码的有效加速内核。", "conclusion": "BlockFFN在性能上优于其他MoE基线，实现了超过80%的token-level稀疏性和70%的8令牌chunk-level稀疏性。在实际端侧设备上的加速内核实现了最高3.67倍的加速比。所有代码和检查点均对外公开。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2401.17256", "html_url": "https://arxiv.org/abs/2401.17256", "title": "大型语言模型上的弱到强劫持攻击", "title_en": "Weak-to-Strong Jailbreaking on Large Language Models", "authors": "Xuandong Zhao,Xianjun Yang,Tianyu Pang,Chao Du,Lei Li,Yu-Xiang Wang,William Yang Wang", "background": "大型语言模型（LLMs）在遭遇劫持攻击后可能会生成有害、不道德或带有偏见的文本，但现有的劫持方法在计算成本上较高。", "innovation": "提出了一种针对对齐LLMs的高效劫持攻击——弱到强劫持攻击，通过使用两个较小模型（安全和不安全的）来篡改一个大幅更大的安全模型的解码概率，从而改变其生成的文本内容。实验结果显示，这种方法在单次前向传播中即可将不一致率提高到99%以上。", "conclusion": "研究揭示了LLMs对齐过程中迫切需要解决的安全问题，并提出了一种初步的防御策略，但更先进的防御策略仍具有挑战性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08104", "html_url": "https://arxiv.org/abs/2507.08104", "title": "VideoConviction: 一种多模态基准测试用于评估人类信念和股票市场建议", "title_en": "VideoConviction: A Multimodal Benchmark for Human Conviction and Stock Market Recommendations", "authors": "Michael Galarnyk,Veer Kejriwal,Agam Shah,Yash Bhardwaj,Nicholas Meyer,Anand Krishnan,Sudheer Chava", "background": "社交媒体放大了金融影响者（被称为‘finfluencer’）的影响范围，他们在YouTube等平台上分享股票建议。了解他们的影响力需要分析语气、说话方式和面部表情等多模态信号，这些信号超越了基于文本的金融分析。本研究旨在开发一种名为VideoConviction的多模态数据集，以评测多模态大型语言模型（MLLMs）和基于文本的大型语言模型（LLMs）在金融领域的表现。", "innovation": "该研究引入了VideoConviction多模态数据集，包含6000多项专家注释，耗费了457小时的人工努力，用于评估多模态和基于文本的大型语言模型在金融话语中的表现。研究表明，虽然多模态输入增强了股票代码提取能力，但两种模型在区分投资行动和信心方面表现出色，即通过自信的语气和详细的推理传达的信念强度，经常将一般评论误分类为明确的建议。本研究还提供了一种逆向策略，即与finfluencer建议相反的投资策略，优于S&P 500指数基金，并具有较高的年回报率和较低的风险比率，但存在一定风险差异。此外，基准测试使模型性能在完整视频和分段视频输入上的多模态任务能够进行多样化的评估，促进了多模态金融研究的深度发展。", "conclusion": "本次研究提供了一个可用于评测多模态和基于文本的大型语言模型在金融领域的表现的基准测试，对于多模态金融分析具有重要意义，并且研究所得数据集和评估排行榜可在CC BY-NC 4.0许可证条件下获取。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2111.14003", "html_url": "https://arxiv.org/abs/2111.14003", "title": "电子商务领域中多种信息源的问答生成", "title_en": "Answer Generation for Questions With Multiple Information Sources in E-Commerce", "authors": "Anand A. Rajasekar,Nikesh Garera", "background": "在电子商务中，自动问答是一项重要但具有挑战性的任务，因为用户每天会在他们感兴趣的商品上提出数百万个问题。因此，开发可以快速响应并利用相关产品信息的自动问答系统的需求巨大。用户提出的查询可以由商品评论、类似问题和规格三个来源提供信息。有效利用这些信息源将大大有助于回答复杂的问题。然而，利用这些信息源也存在两个主要挑战：（i）存在无关信息，（ii）评论和类似问题中的情感模糊性。", "innovation": "本文提出了一种新的流水线（MSQAP），该流水线通过在生成答案之前分别进行相关性和歧义性预测，利用上述信息源中的丰富信息。实验结果表明，该相关性预测模型（BERT-QA）在F1分数上相比BERT-base基线提高了12.36%，并且生成模型（T5-QA）在所有内容保持度指标（如BLEU、ROUGE）上优于基线，分别平均提高了35.02%的ROUGE和198.75%的BLEU。给人类的评价表明，本文的方法在准确性方面总体提高了30.7%，这使得基于整个流水线的方法（MSQAP）可以提供更准确的答案。据我们所知，这是电子商务领域中的首篇结合多种来源（如规格、类似问题和评论数据）自动生成自然语言答案的工作。", "conclusion": "我们的方法（MSQAP）在准确性方面比生成模型（T5-QA）高30.7%，表明基于整个流水线的方法可以提供更加准确的答案。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.14192", "html_url": "https://arxiv.org/abs/2404.14192", "title": "词序变化中的交换距离最小化超越熵最小化", "title_en": "Swap distance minimization beyond entropy minimization in word order variation", "authors": "Víctor Franco-Sánchez,Arnau Martí-Llobet,Ramon Ferrer-i-Cancho", "background": "研究探讨了由n个元素构成的语言结构（例如n=3或n=4的情形，如主语、宾语、谓语或主语、宾语、间接宾语、谓语等），考察这两种动态原则是否约束了这n!种可能顺序的频率：熵最小化原则，它被提出的用于描述不同层次的自然沟通系统；以及交换距离最小化原则，即一种更倾向于从初始顺序产生的词序要求较少的相邻元素互换次数。此外，还使用骰子投掷实验和Polya urn过程对不同语言结构进行了研究，以验证这两种原则的有效性。", "innovation": "引入了新的评分系统——平均交换距离，用于研究交换距离最小化。通过对n=3和n=4的词序进行全面分析，发现熵最小化和交换距离最小化在不同程度上对词序的变化有显著影响。尤其是在n=4的情况下，Polya urn过程显示出较强的支持，而在n=3的情况下，则有较弱的支持。即使在词序频率打乱的情况下，仍然观察到了交换距离最小化的效应，表明这种效应不仅仅是降低词序熵的一种压力。", "conclusion": "在不同语言结构中，熵最小化和交换距离最小化对词序的变化存在显著影响。交换距离最小化的效果在n=4的情况下更明显，而在n=3的情况下则相对较弱。即使是最随机化的词序变化也表现出交换距离最小化的效应，这表明这种效应是独立于降低熵的压力之外的。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.19715", "html_url": "https://arxiv.org/abs/2405.19715", "title": "SpecDec++：通过自适应候选长度增强推测性解码", "title_en": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths", "authors": "Kaixuan Huang,Xudong Guo,Mengdi Wang", "background": "推测性解码通过使用一个小而快的草稿模型来减少目标大型语言模型的推理延迟。推测性的时间依赖于一个超参数K——候选长度，即目标模型在每次循环中验证的候选令牌数。以往的方法往往使用简单的启发式选择K，这可能导致性能不佳。研究推测性的时间选择，并将其形式化为马尔可夫决策过程（MDP），理论上证明了最优策略的形式是阈值策略。", "innovation": "提出了SpecDec++，这是一种增强版本的推测性解码，能够自适应地在运行时确定候选长度。通过在草稿模型中增加一个训练好的接受预测头来预测候选令牌的条件接受概率。当预测到至少一个令牌将被拒绝的概率超过阈值时，SpecDec++将停止当前的推测。", "conclusion": "我们的自适应方法在Alpaca数据集上实现了2.04倍的加速（相对于基线推测性解码提高了7.2%）。在GSM8K和HumanEval数据集上，我们的方法分别实现了2.26倍和2.23倍的加速（分别提高了9.4%和11.1%）."}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2310.18290", "html_url": "https://arxiv.org/abs/2310.18290", "title": "使用学习资源生成谜题", "title_en": "Riddle Generation using Learning Resources", "authors": "Niharika Sri Parasa,Chaitali Diwan,Srinath Srinivasa", "background": "在线学习环境中，保持学习者参与是主要挑战之一。为此，多种教学策略在在线和离线环境中被提出。概念获得模型是一种专注于帮助学习者深入理解概念而非仅仅记忆字面定义的教学策略。该模型通过搜索并列出用于区分概念示例和非示例的性质来进行教学。", "innovation": "本文试图将概念获得模型应用于生成概念谜题，并部署于在线学习环境中。该方法涉及从学习资源创建事实三元组，基于它们与概念的独特性将事实三元组分类为‘主题标记’和‘一般常规’，然后根据概念获得模型的格式生成谜题，并捕获所有可能的解决方案。", "conclusion": "人类评估谜题的结果是令人鼓舞的，这表明所提出的方法在在线学习环境中具有潜在的应用价值。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.03897", "html_url": "https://arxiv.org/abs/2406.03897", "title": "HeSum: 一种新的希伯来语摘要数据集", "title_en": "HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew", "authors": "Tzuf Paz-Argaman,Itai Mondshine,Asaf Achi Mordechai,Reut Tsarfaty", "background": "尽管大型语言模型（LLMs）在英语等资源丰富语言的各种自然语言任务中表现出色，但在希伯来语等资源贫乏的语言，尤其是在生成型任务（如抽象性摘要）中，其表现仍然不明确。希伯来语的丰富形态使得句子理解充满歧义，构建含义也极具挑战性。因此，本文旨在通过对HeSum这一新基准的介绍，填补这项资源和评价方面的空白，HeSum专门为现代希伯来语的抽象文本摘要设计。", "innovation": "本文提出了HeSum，这是一种专为现代希伯来语的抽象文本摘要设计的新基准。HeSum包含来自专业编写人员写的希伯来新闻网站上的10,000篇文章摘要对。该数据集确认了HeSum的高度抽象性和独特的形态挑战。研究表明，HeSum为现代最先进的LLMs带来了独特的挑战，确立了其作为希伯来语甚至是MRL（多功能语言资源）生成挑战的重要测试床的重要性。", "conclusion": "本文通过HeSum这一新基准，填补了资源和评价方面在希伯来语抽象性文本摘要中的空白，证明它是一个有价值的测试平台，特别适用于评估生成型语言技术在希伯来语和MRLs中的挑战。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.14023", "html_url": "https://arxiv.org/abs/2406.14023", "title": "从心理测量角度评估大型语言模型中的隐性偏见", "title_en": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective", "authors": "Yuchen Wen,Keping Bi,Wei Chen,Jiafeng Guo,Xueqi Cheng", "background": "随着大型语言模型（LLMs）成为信息获取的重要方式，人们越来越担心LLMs可能会加剧不道德内容的传播，特别是隐性偏见，这种偏见以伤害某些人群的方式存在，但没有使用明确的有害词语。本文通过心理测量的角度，对LLMs的特定人群隐性偏见进行仔细评估。", "innovation": "本文提出了三种攻击方法：伪装、欺骗和教学，用于从心理测量的角度激发LLMs生成带偏见的观点。同时，构建了两个基准：一个包含四种偏见类型的双语数据集（2700个实例），用于广泛的比较分析；另一个是BUMBLE基准，包括九种常见的偏见类型，共计12700个实例，用于全面评估。实验表明，作者的方法在激发LLMs隐性偏见方面比现有基准更有效。", "conclusion": "本文的方法和基准为评估LLMs的道德风险提供了有效手段，推动了其开发过程中的问责机制。所有代码、数据和基准都已在指定网址提供。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.10657", "html_url": "https://arxiv.org/abs/2407.10657", "title": "对公式生成合成数据进行验证的实证研究", "title_en": "An Empirical Study of Validating Synthetic Data for Formula Generation", "authors": "Usneek Singh,José Cambronero,Sumit Gulwani,Aditya Kanade,Anirudh Khatry,Vu Le,Mukul Singh,Gust Verbruggen", "background": "大型语言模型（LLMs）可以用于协助编写电子表格中的公式，但由于关于这些公式的资源稀缺，这不仅影响了预训练模型的基础性能，还限制了参数微调的能力。给定一个公式语料库，可以使用另一个模型生成合成自然语言陈述以便于微调。然而，至关重要的是要验证生成的自然语言是否准确，可用于提高微调效果。", "innovation": "本文提供了通过使用代理目标验证合成训练示例对性能的影响的实证结果。验证提升了验证数据上四个模型（两个开放型和两个封闭型）的性能。尽管验证倾向于移除更具挑战性的示例，但在验证数据上微调后，模型能解决更复杂的问题。", "conclusion": "验证合成训练示例可以提高模型的性能，尽管它会排除一些更具挑战性的示例，但能增强模型解决更复杂问题的能力。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08529", "html_url": "https://arxiv.org/abs/2507.08529", "title": "一种用于罕见疾病诊断的多粒度概念稀疏激活与层次知识图融合框架", "title_en": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "authors": "Mingda Zhang,Na Zhao,Jianglong Qin,Guoyu Ye,Ruixiang Tang", "background": "尽管医疗大型语言模型在医学领域取得了进展，但由于知识表示深度不足、概念理解有限以及临床推理能力受限，罕见疾病的诊断仍然面临挑战。现有的诊断方法在面对此类疾病时表现受限，无法提供足够的信息来得出准确的诊断结果。文章分析了这些现有方法的不足，指出了医疗领域知识表示与推理能力的瓶颈问题，强调了改进诊断效率和精确度的重要性。", "innovation": "文章提出了一种多粒度概念稀疏激活与层次知识图融合的框架，通过结合多粒度稀疏激活的概念和层级知识图，实现了更精确的概念激活。框架包括四个互补的匹配算法、多样性控制以及五级降级策略，提供了结构化的、及时更新的上下文。这种框架在BioASQ罕见疾病问答集上实验表明，BLEU得分提高了0.09、ROUGE得分提高了0.05、准确率提高了0.12，最高准确率达到0.89，接近临床阈值0.90。此外，专家评估证实了信息质量、推理和专业表达的改进，表明该方法缩短了罕见疾病患者的‘诊断之旅’。", "conclusion": "该方法通过改进的知识表示和推理机制，在罕见疾病的诊断中实现了显著提升，验证了其有效性和实用性，为临床诊断提供了新的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.18865", "html_url": "https://arxiv.org/abs/2404.18865", "title": "语言模型的真值判断：‘真值方向’具有上下文敏感性", "title_en": "Truth-value judgment in language models: 'truth directions' are context sensitive", "authors": "Stefan F. Schouten,Peter Bloem,Ilia Markov,Piek Vossen", "background": "最近的研究表明，大型语言模型（LLMs）的潜在空间中存在预测句子真实性的方向。多种方法可以恢复这些方向并构建探针，这些探针被描述为揭示模型的‘知识’或‘信念’。本文深入研究这一现象，特别关注上下文对探针的影响。", "innovation": "通过测量在输入包含假设后跟随否定支持句和矛盾句的LLM中，探针预测的不一致性错误类型，本文首次具体揭示了真值方向的上下文敏感性。还通过对假设的表示沿着这些真值方向进行因果干预实验，探究其对支持或反驳句子位置的影响，从而更深入地了解模型的推理过程。", "conclusion": "本文的研究结果显示，探针在真值方向上的预测体现出明显的上下文敏感性，即使那些理论上不应影响真值的上下文也会影响探针输出。不同类型的错误与模型的层、模型类型和数据类型有关。研究还表明，真值方向在模型整合上下文信息的过程中发挥因果中介作用。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.01077", "html_url": "https://arxiv.org/abs/2411.01077", "title": "Emoji 攻击：增强针对 Judge LLM 检测的 jailbreak 攻击", "title_en": "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection", "authors": "Zhipeng Wei,Yuqi Liu,N. Benjamin Erichson", "background": "现有方法通过使用另一个 LLM 作为 Judge 来评估生成文本的有害性，以抵御 jailbreaking 技术对 LLM 的攻击，但这些 Judge LLM 存在 token 分段偏差的问题，这会导致单词被错误分割，影响整个序列的嵌入，从而降低检测精度，使得有害内容被误分类为安全内容。", "innovation": "提出 Emoji 攻击，这是一种利用 token 分段偏差放大现有 jailbreak 提示的新策略。该方法通过在 text 之前系统地插入表情符号来利用在上下文中学习的能力，从而在 Judge LLM 评估之前引入嵌入失真，显著降低检测到危险内容的可能性。与传统分隔符不同，表情符号还引入了语义歧义，使其在这类攻击中特别有效。实验表明，Emoji 攻击显著降低了不安全预测率，绕过了现有防护措施。", "conclusion": "通过实验验证，Emoji 攻击显著减少了不安全内容的预测率，成功绕过了现有的防范措施。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.18246", "html_url": "https://arxiv.org/abs/2504.18246", "title": "一次通过推理：沿用令牌复制和块稀疏掩码以高效地对多轮推理进行微调", "title_en": "One-Pass to Reason: Token Duplication and Block-Sparse Mask for Efficient Fine-Tuning on Multi-Turn Reasoning", "authors": "Ritesh Goru,Shanay Mehta,Prateek Jain", "background": "对多轮对话进行大规模语言模型（LLMs）微调时，由于推理令牌可见性限制，每个对话需要进行N次独立前向传递，因为前一轮的推理令牌会在后续轮次中被丢弃。", "innovation": "提出了一种复制响应令牌并使用自定义注意力掩码的方法，以实现整个对话的一次性处理。这种方法证明了在提供与N次传递方法相同损失的同时，将时间复杂度从$O(N^{3})$降低到$O(N^{2})$，并保持相同的内存复杂度，从而实现了显著的训练加速，同时保持了准确性。", "conclusion": "本文提出的方法实现了训练加速并保持了准确性。相关实现已公开在线。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.08893", "html_url": "https://arxiv.org/abs/2503.08893", "title": "EvalTree：通过分层能力树剖析语言模型弱点", "title_en": "EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees", "authors": "Zhiyuan Zeng,Yizhong Wang,Hannaneh Hajishirzi,Pang Wei Koh", "background": "理想的模型评估应实现两个目标：识别模型失败的具体位置以及提供具体的改进指导。针对语言模型（LM）的评估目标，本文提出了生成弱点概况的问题，即给定基准中每个个体实例的LM性能，生成描述自然语言中一组弱点的集合。此外，评述了现有基准的评估方法并提出了一个新的名为EvalTree的方法。EvalTree通过构建一个分层的能力树来解决这个问题，该树中的每个节点都用自然语言描述一个能力，并链接到专门评价该能力的基准实例子集。通过这种方法，可以提取LM表现不佳的节点，生成弱点概况。在MATH和WildChat基准测试中，EvalTree的表现优于现有的基准评估方法，能够更精确和全面地识别弱点。此外，弱点概况还使有针对性的数据收集成为可能，基于EvalTree识别出的弱点指导的数据收集策略进一步提高了LM的性能。此外，EvalTree还揭示了Chatbot Arena的人工投票基准则评估方法中的缺陷。", "innovation": "提出了一种新的方法EvalTree，它通过构建分层的能力树来剖析语言模型的弱点。与现有的基准评估方法相比，EvalTree能够更准确、全面地识别弱点，指导有针对性的数据收集，并进一步提高LM的性能。同时还揭示了现有评估方法中的潜在缺陷。", "conclusion": "EvalTree方法在识别语言模型弱点方面表现出色，能够准确且全面地生成弱点概况。这种方法不仅有助于提升语言模型的整体性能，还揭示了当前评估方法中的不足之处。今后相关研究可以在EvalTree提供的交互式界面基础上进一步探索和改进。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.13857", "html_url": "https://arxiv.org/abs/2503.13857", "title": "利用大型语言模型驱动评估纳入预印本文章以实现包容性系统评价", "title_en": "Enabling Inclusive Systematic Reviews: Incorporating Preprint Articles with Large Language Model-Driven Evaluations", "authors": "Rui Yang,Jiayi Tong,Haoyuan Wang,Hui Huang,Ziyang Hu,Peiyu Li,Nan Liu,Christopher J. Lindsell,Michael J. Pencina,Yong Chen,Chuan Hong", "background": "系统评价在比较有效性研究中需要及时的证据综合。预印本能够加速知识传播，但其质量参差不齐，给系统评价带来挑战。现有的方法依赖于人工筛选，时间成本高，并且范围有限。本文提出了一种名为AutoConfidence的自动化框架，旨在通过自动化数据提取、多特征融合以及大型语言模型驱动评估来预测预印本的出版情况，从而减少人工筛选的依赖性，并扩展了预测的范围。该框架使用自然语言处理技术自动化提取数据，构建了基于标题和摘要的语义嵌入，并利用大型语言模型进行评价评分。这些改进旨在提升预印本文献筛选的效率和准确性。", "innovation": "AutoConfidence框架通过自动化数据提取、多特征融合以及大型语言模型驱动评估实现了系统评价中预印本文献的预测筛选。特别地，提出了自动数据提取技术、语义嵌入以及大型语言模型驱动的评价得分。此框架提高了预测性能，并减轻了人工标注的负担。研究结果显示，通过整合语义嵌入和大型语言模型驱动的评分，随机森林分类器和生存治愈模型的性能均有显著提升。", "conclusion": "本文提出的方法通过自动化数据提取和多特征融合显著提升了预印本文献预测筛选的准确性。整合语义嵌入和大型语言模型驱动评估增加了预测的鲁棒性。AutoConfidence框架有可能在系统评价的评估阶段帮助整合预印本文献，支持研究人员更有效地利用预印本资源。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.00467", "html_url": "https://arxiv.org/abs/2505.00467", "title": "红队测试大型语言模型在医疗领域的应用", "title_en": "Red Teaming Large Language Models for Healthcare", "authors": "Vahid Balazadeh,Michael Cooper,David Pellow,Atousa Assadi,Jennifer Bell,Mark Coatsworth,Kaivalya Deshpande,Jim Fackler,Gabriel Funingana,Spencer Gable-Cook,Anirudh Gangadhar,Abhishek Jaiswal,Sumanth Kaja,Christopher Khoury,Amrit Krishnan,Randy Lin,Kaden McKeen,Sara Naimimohasses,Khashayar Namdar,Aviraj Newatia,Allan Pang,Anshul Pattoo,Sameer Peesapati,Diana Prepelita,Bogdana Rakova,Saba Sadatamin,Rafael Schulman,Ajay Shah,Syed Azhar Shah,Syed Ahmar Shah,Babak Taati,Balagopal Unnikrishnan,Iñigo Urteaga,Stephanie Williams,Rahul G Krishnan", "background": "该文描述的是在2024年医疗机器学习会议上举行的预会议工作坊的设计过程和研究结果。工作坊主题是针对大型语言模型进行红队测试，以发现保障医疗安全的漏洞。参会者来自计算和临床等多个领域，旨在发现可能导致医疗危害的临床提示，以提高大型语言模型在医疗领域的安全性。这一工作有助于临床专业人员识别开发人员可能忽略的漏洞，确保模型在实际应用中的安全性，特别是在医疗数据处理和诊断辅助方面。", "innovation": "该研究的独特之处在于使用红队测试（红队）方法，由混合背景的专业人士发现大型语言模型中的漏洞，这种方法比仅依赖模型开发者的自查更全面。研究进一步通过复制实验评估发现的漏洞在所有提供给大型语言模型中的适用性，从而为未来相关的安全性研究提供了实证数据支持。", "conclusion": "研究揭示并分类了大型语言模型中可能导致临床危害的漏洞，证明了跨大型语言模型的复制研究的有效性。这些发现强调了红队测试在医疗环境中识别模型潜在风险的重要性，为提高医疗领域大型语言模型的安全性和可靠性提供了新的方法和实践建议。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12546", "html_url": "https://arxiv.org/abs/2505.12546", "title": "从开放权重语言模型中提取受版权保护的书籍的记忆片段", "title_en": "Extracting memorized pieces of (copyrighted) books from open-weight language models", "authors": "A. Feder Cooper,Aaron Gokaslan,Ahmed Ahmed,Amy B. Cyphert,Christopher De Sa,Mark A. Lemley,Daniel E. Ho,Percy Liang", "background": "在涉及生成式AI的版权诉讼中，原告和被告经常对大型语言模型（LLMs）是否记忆了原告受保护的表达进行夸张且对立的陈述。本文通过借鉴对抗机器学习和版权法，探讨了记忆与版权之间关系的复杂性。研究利用最近的概率提取技术从17个开放权重LLM中提取了书本3（Books3）数据集的部分内容，证明了可以从不同模型中提取相当多的文字内容，表明LLMs存在记忆现象，但这种记忆程度因模型和书籍的不同而不同。研究发现，较大的LLMs大多不会记住大部分书籍，而Llama 3.1 70B几乎完全记住了如《哈利·波特与魔法石》和《1984》等书籍。使用种子提示生成整个书本的内容，进一步强化了记忆现象的存在。", "innovation": "本文利用概率提取技术研究LLMs的记忆现象，通过大量实验展示了从不同开放权重语言模型中提取书籍片段的可能性，以及这种记忆现象的复杂性。特别是在Llama 3.1 70B上发现几乎完全记忆特定书籍的能力，为探讨版权影响提供了新的视角。", "conclusion": "本文的研究结果显示，LLMs确实存在记忆现象，但其程度因模型和书籍的不同而不同。此外，较大的模型如Llama 3.1 70B对某些书籍的记忆程度非常高，可以使用单一种子提示生成整个书籍的内容。然而，这些结果对版权案件的意义是复杂的，并不明显有利于某一特定方。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.00927", "html_url": "https://arxiv.org/abs/2504.00927", "title": "Multi-Token Attention", "title_en": "Multi-Token Attention", "authors": "Olga Golovneva,Tianlu Wang,Jason Weston,Sainbayar Sukhbaatar", "background": "软注意力是驱动大规模语言模型（LLMs）定位给定上下文中相关部分的关键机制。然而，单个注意力权重仅由单一查询和键向量的相似性决定。这一‘单令牌’注意力机制限制了用于识别相关部分与上下文其余部分区别的信息量。", "innovation": "我们提出了一种新的注意力方法——多令牌注意力（MTA），它允许大型语言模型同时基于多个查询和键向量来调整注意力权重。通过在查询、键和头中应用卷积操作，使附近查询和键影响彼此的注意力权重，从而实现更精确的注意力。因此，该方法可以使模型使用更多的丰富且细微的信息来定位上下文中的相关部分。", "conclusion": "通过对多种流行基准的广泛评估，我们证明了MTA在多种任务中实现了增强的性能。特别是在需要在长文本中查找信息的任务方面，我们的方法能够利用更丰富的信息方面显示出特别的好处，并且在标准语言建模任务上超过了变压器基线模型的表现。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11903", "html_url": "https://arxiv.org/abs/2506.11903", "title": "GeistBERT: 激活德语NLP", "title_en": "GeistBERT: Breathing Life into German NLP", "authors": "Raphael Scheible-Schmitt,Johann Frei", "background": "基于变压器的语言模型的进步凸显了在高质量语料库上进行语言特定预训练的益处。在这种背景下，德语NLP领域可以从更新的架构和针对德语语言特点定制的现代数据集中受益。本文通过在多样化语料库上逐步训练并跨多种NLP任务优化模型性能，旨在改进德语语言处理。模型使用fairseq进行预训练，配置为RoBERTa基本模型，采用整词掩蔽(WWM)，并且模型初始化来自GottBERT的权重。", "innovation": "采用了整词掩蔽的方式并使用GottBERT的权重进行初始化。模型在包含1.3 TB德语语料库上进行了训练，并使用动态掩蔽技术和固定序列长度为512个标记。该模型在标准下游任务中表现出色，包括NER、文本分类和NLI任务，并在GermEval 2018细粒度文本分类基准测试中创造了新的SOTA结果，尤其是在分类基准上，还超越了几个更大型的模型。", "conclusion": "GeistBERT在各种任务上都取得了很好的结果，并在GermEval 2018细粒度文本分类任务中达到了新的SOTA水平。为了支持德语NLP研究，该模型已根据MIT许可协议开源。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.14123", "html_url": "https://arxiv.org/abs/2506.14123", "title": "逐字采样从您的语言模型", "title_en": "Sampling from Your Language Model One Byte at a Time", "authors": "Jonathan Hayase,Alisa Liu,Noah A. Smith,Sewoong Oh", "background": "现代语言模型几乎无一例外地使用了标记化技术，通过多字节或多重字符标记来高效地表示文本。然而，早期的研究表明，标记化可能会在模型生成中引入失真，这一问题被称为提示边界问题（PBP）。用户通常被建议不要在其提示中以空格结尾，以避免空格不被包含进下一个标记中。这一问题在英语和中文等语言中仍然存在，特别是在代码生成中，由于标记往往是与词语和语法边界对齐的。", "innovation": "本研究提出了一种在推理阶段将任何使用BPE标记化的自回归语言模型转换为按字符或按字节的语言模型的方法。该方法有效地解决了PBP，并且能够统一不同标记化器的词汇表，使得在推理过程中可以使用不同标记化的语言模型，并且可以在模型训练后通过代理调整将方法从一个模型转移到另一个模型。实验结果表明，集成模型和通过代理调整后的模型在下游评估中优于其组件模型。", "conclusion": "本研究展示的方法能够有效解决提示边界问题，同时改进不同语言模型在推理时的表现，并且能够通过代理调整实现模型间转换。这一方法已被证实能够提升融合模型和代理调整模型在下游任务上的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06565", "html_url": "https://arxiv.org/abs/2507.06565", "title": "他人之过：一种由大模型驱动的科学知识生产框架", "title_en": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production", "authors": "Juan B. Gutiérrez", "background": "大语言模型使写作变成人类与软件之间的即时交流。本研究旨在捕捉这一新型交流方式，并开发一种互动网络模型，将人类和大模型视为平等节点，追踪双方陈述的交流过程。研究将焦点从单独的幻觉扩展到各种事实、逻辑或结构方面的错误，定义了这些错误的四个风险类型：真理偏离、自我修复、新创作以及外部检测，并构建了一个通用的互动网络模型来进行深入分析。", "innovation": "研究提出了一种通用的互动网络模型，以数学公式描述虚假陈述在网络中的传播风险，并通过添加新创作（false claims）的机制模拟真实世界中的大模型；开发了Flaws-of-Others (FOO) 算法，这是一种支持多代理相互审核的自适应循环机制，让大模型之间的错误互相纠正，从而逐步实现真理主导的状态。", "conclusion": "研究指出，这种新型交流方式中的可靠性不是依赖单一模型的完美，而是通过将不完美的模型网络化，互相监控和纠正以达到真相主导的状态。同时也提供了开源的FOO算法来实现这一目标。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06261", "html_url": "https://arxiv.org/abs/2507.06261", "title": "Gemini 2.5: 推动前沿的高级推理、多模态、长语境和下一代能动性能力", "title_en": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "authors": "Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju", "background": "本文介绍了Gemini 2.X模型家族，包括Gemini 2.5 Pro和Gemini 2.5 Flash，还有前期版本的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro具有卓越的编码和推理能力，在前沿编码和推理基准测试中取得了最佳性能。Gemini 2.5 Pro还具备出色的多模态理解能力，并能够处理长达3小时的视频内容。Gemini 2.5 Flash则以更低的计算和延迟要求提供了优秀的推理能力，Gemini 2.0 Flash和Flash-Lite则在低延迟和低成本条件下保持高性能。Gemini 2.X模型系列产品覆盖了模型能力和成本之间的帕累托前沿，使用户能够探索复杂的能动性问题解决的边界。", "innovation": "Gemini 2.5 Pro在编码和推理能力上达到了当前最先进水平，并且引入了长语境、多模态理解和推理等特性，Gemini 2.5 Flash以极低的计算和延迟比提供了强大的推理能力，而Gemini 2.0 Flash和Flash-Lite则在低延迟和成本条件下提供高性能。此系列产品覆盖了从高性能高成本到低性能低成本的各类需求，提供了一个全面的模型能力与成本选择范围。", "conclusion": "Gemini 2.X模型系列跨越了模型能力及成本之间的帕累托前沿，用户可以根据其复杂能动性问题解决的需求探索模型的边界。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07505", "html_url": "https://arxiv.org/abs/2507.07505", "title": "幻觉站：关于基于Transformer的语言模型的一些基本局限性", "title_en": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models", "authors": "Varin Sikka,Vishal Sikka", "background": "随着基于Transformer的语言模型在AI中的广泛采用，人们对其局限性的兴趣日益浓厚，特别是所谓的幻觉现象，即当语言模型在某些主题上受到提示时，会提供虚假、事实错误或不合逻辑的信息。同时，研究人员开始关注基于语言模型的代理使用，即利用语言模型创建能够自主或半自主地执行各种任务的代理，包括具有现实世界应用的任务。因此，理解语言模型能够和无法执行的任务类型变得至关重要。本文从计算复杂性的角度探讨了语言模型的能力边界，并展示了模型在执行高复杂度计算和代理任务方面的能力限制，以及验证这些任务复杂度内的准确性方面的能力障碍。", "innovation": "本文创新性地从计算复杂性角度分析了语言模型的能力边界，展示了语言模型在执行复杂任务和验证复杂任务准确性方面的限制，并通过具体的例子进行了阐述。", "conclusion": "本文研究了语言模型能力的边界，证明了语言模型在执行和验证高复杂度任务方面的能力限制，并讨论了这些工作带来的影响。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07248", "html_url": "https://arxiv.org/abs/2507.07248", "title": "医疗语言模型的红队测试协议：在医疗保健环境中用户视角的重要性", "title_en": "Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings", "authors": "Jean-Philippe Corbeil,Minseon Kim,Alessandro Sordoni,Francois Beaulieu,Paul Vozila", "background": "随着大型语言模型（LLMs）性能的不断提高，它们的应用范围日益扩大，包括医疗领域。然而，将LLMs集成到医疗应用中引发了重要的安全问题，尤其是在不同角色的用户使用时，模型的输出可能直接影响人类健康。尽管现有的医疗LLMs具有特定的领域能力，但先前的安全评估主要仅专注于通用安全标准。本文为此缺口进行研究，提出了一个针对医疗领域的安全评价协议，该协议包含患者视角和医生视角的安全评估，同时进行一般性安全评估。", "innovation": "本文提出了一种针对医疗领域的安全评价协议，从患者、医生和普通用户三个不同角度出发，定义安全评估标准。此外，通过构建包含466个样本的PatientSafetyBench，首次对医学生物药物模型（MediPhi模型集合）进行了基于用户视角的安全性定量分析。", "conclusion": "本文的工作填补了文献中的空白，结合患者的视角建立了PatientSafetyBench，并通过红队测试方法对MediPhi模型集合进行了案例研究，强调了用户视角在确保医疗领域中安全部署的重要性，从而为更安全地部署LLMs奠定了基础。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2401.02984", "html_url": "https://arxiv.org/abs/2401.02984", "title": "大型语言模型在精神卫生护理中的应用：一个范围性回顾", "title_en": "Large Language Models in Mental Health Care: a Scoping Review", "authors": "Yining Hua,Fenglin Liu,Kailai Yang,Zehan Li,Hongbin Na,Yi-han Sheu,Peilin Zhou,Lauren V. Moran,Sophia Ananiadou,David A. Clifton,Andrew Beam,John Torous", "background": "本研究旨在全面分析大型语言模型（LLMs）在精神卫生护理中的应用，评估其有效性，识别挑战，并探讨其未来应用的潜力。为此，研究者在2023年11月对包括PubMed、Web of Science、Google Scholar、arXiv、medRxiv和PsyArXiv在内的多个数据库进行了系统搜索，并筛选出从2019年10月1日到2023年12月2日之间发表或传播的关于精神卫生护理的原创研究文章，要求这些研究文章必须使用T5之后开发的大型语言模型并直接探讨精神卫生护理中的研究问题。初步筛选了313篇文章，最终经审慎筛选后选择了34篇与其主题高度相关并报告了严谨结果的文章。这些研究包括诊断、治疗和提高患者参与度等精神卫生护理中的各种大型语言模型应用。主要挑战包括数据的获取和可靠性、对精神状态的细致处理以及有效的评估方法。尽管大型语言模型在提高准确性和可访问性方面显示出潜力，但在临床应用和伦理考虑方面仍存在显著差距。", "innovation": "本研究创新之处在于实现了大型语言模型在精神卫生护理中的全景剖析，不仅覆盖了诊断、治疗和患者参与度提升等广泛的应用场景，还针对数据获取与可靠性、对精神状态的细致处理以及有效的评估方法等挑战提出了具体见解，同时也指出了在临床应用和伦理方面存在的问题。这些研究为开发者和政策制定者如何更好地利用此类技术提供了有益的参考和建议。", "conclusion": "大型语言模型在精神卫生护理中具有巨大潜力，但要充分发挥其潜力，必须加强数据集的建设、开发和评估框架的构建、伦理指导原则的制定，并促进跨学科合作，以解决当前存在的限制。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.11767", "html_url": "https://arxiv.org/abs/2411.11767", "title": "文书汪洋：扩大推理级联器放大的后果", "title_en": "Drowning in Documents: Consequences of Scaling Reranker Inference", "authors": "Mathew Jacob,Erik Lindgren,Matei Zaharia,Michael Carbin,Omar Khattab,Andrew Drozdov", "background": "通常使用跨编码器等重新排序器，尽管它们计算密集，但如果假设它们优于低成本的初期信息检索（IR）系统，则缺点少，被频繁采用。然而，本研究打破了这种假设，通过评估重新排序器的全检索性能，而不仅是第一阶段检索的重新评分，以此提供了一个更稳健的评估。", "innovation": "采用了现代密集嵌入来加强第一阶段检索，并在精确选择、具有挑战性的任务集合上测试重新排序器，其中包括内部收集的数据集以避免污染，以及跨领域的数据集。实验证明，现有的最佳重新排序器在评分越来越多的文档时最初会改善，但其效果逐渐减弱，甚至超过某个阈值后会降低质量。", "conclusion": "希望我们的发现能激励未来的研究所探讨如何提高重新排序器的效果，解决了信息过载问题。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.08830", "html_url": "https://arxiv.org/abs/2402.08830", "title": "语言模型中的序列图实现与歧义性", "title_en": "Sequence graphs realizations and ambiguity in language models", "authors": "Sammy Khalife,Yann Ponty,Laurent Bulteau", "background": "当今流行的语言模型通常将输入文本 $x$ 的局部上下文表示为词袋。这种表示自然地通过一个序列图进行编码，每个顶点代表输入文本 $x$ 中出现的唯一词语，边表示两个词语在滑动窗口 $w$ 内的（有序）共现情况。然而，这种压缩表示不是一般可逆的，可能会出现无法唯一解析或解析模糊的情况。本文从组合数学和算法的角度研究序列图的可解析性和模糊性。", "innovation": "作者研究了序列图的不同可解析性和模糊性情况，在窗口大小 $w=2$ 的情况下提供了多项式时间算法来解决几乎所有的可解析性和计数问题，除了无向带权情况下的计数问题被证明 $\text{P-归约}(\text{P-reduction})$ 难。对于 $w \neq 2$ 情况，很难找到多项式算法，所描述的无权无向情况提供了多项式时间算法，同时被复杂的 $W[1]$/NP 难性问题局限。此外，提出了混合整数计划方法和动态规划算法来解决较大的实例问题，并探讨了 $\text{NP}$ 类别问题的存在性。", "conclusion": "本文对序列图的实现问题提供了整数规划的求解方案，并在中等规模实例中提出了动态规划算法。此外，由于最小实现可能在实例编码上呈指数级大小，因此反驳了两个问题属于 $\text{NP}$ 类别的可能性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.05401", "html_url": "https://arxiv.org/abs/2410.05401", "title": "使用大规模语言模型后验研究社交媒体上气候微目标广告的主题见解和公平性评估", "title_en": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation", "authors": "Tunazzina Islam,Dan Goldwasser", "background": "社交媒体上关于气候变化的沟通越来越多地利用微目标策略来精确接触到特定的人口细分群体。本研究对气候宣传活动的微目标实践进行了后验分析，通过大规模语言模型（LLMs）分析了Facebook广告。研究重点关注人口细分和公平性两个方面。", "innovation": "1. 使用LLMs准确预测人口目标群体的分类，总体准确率为88.55%。\n2. LLMs生成解释分类的详细说明，提供每个决策背后的透明理由，揭示不同人口细分群体的主题元素使用情况，强调针对不同受众的差异化策略。\n3. 进行全面的公平性分析，识别预测中可能存在的偏差，尤其是对老年人和男性群体的分类偏差。", "conclusion": "通过展示LLMs在解析和解释目标通讯策略方面的有效性，并指出公平性问题，本研究为未来研究提供了一个有价值的框架，以增强社交媒体气候宣传活动的透明度、问责制和包容性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.13959", "html_url": "https://arxiv.org/abs/2504.13959", "title": "AI Safety Should Prioritize the Future of Work", "title_en": "AI Safety Should Prioritize the Future of Work", "authors": "Sanchaita Hazra,Bodhisattwa Prasad Majumder,Tuhin Chakrabarty", "background": "当前AI安全工作主要集中在筛选有害内容、防止人类行为操纵以及消除网络安全或生物安全中的生存风险等方面。虽然这些问题是紧迫的，但这种狭窄的关注范围忽视了对社会长期轨迹产生重大影响的人本因素。本文认为，忽视AI对未来工作的影响是一个严重的风险，建议提供全面的过渡支持，以实现有意义劳动的发展，保留人类自主性。", "innovation": "文章从经济理论的角度出发，强调了AI对未来人类生计的时序性影响以及在劳动市场结构变化中加剧的收入不平等。同时，文章指出现代AI开发者的主要参与者的闭源方法类似于逐利行为，导致创造性劳动力的平庸化和创新的垄断。针对这些问题，文章提出应建立一个强有力的国际著作权体系，支持集体许可，确保使用数据训练AI模型的公平补偿机制。同时，建议建立一个以工人为中心的全球AI治理框架，以促进共同繁荣和经济正义，同时减少技术债务。", "conclusion": "为了解决AI领域存在的上述问题，文章建议优先考虑未来工作的AI安全问题，提供支持向有意义劳动的过渡，并建立一个以工人为中心的全球AI治理框架，以实现共享的繁荣和经济正义，减少技术债务。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05788", "html_url": "https://arxiv.org/abs/2507.05788", "title": "Flippi: 全栈AI辅助精灵赋能电子商务", "title_en": "Flippi: End To End GenAI Assistant for E-Commerce", "authors": "Anand A. Rajasekar,Praveen Tangarajan,Anjali Nainani,Amogh Batwal,Vinay Rao Dandin,Anusua Trivedi,Ozan Ersoy", "background": "对话式助手的发展从根本上重塑了用户与数字平台的交互方式。这篇论文介绍了一种名为Flippi的前端到后端的对话式助手，它由大型语言模型（LLMs）驱动，并专门面向电子商务领域。Flippi通过对广阔且常常令人感觉复杂的产品目录进行自然语言对话，帮助消费者更高效地发现产品。Flippi不仅满足了用户的具体需求，也适应了用户的情感和偏好，提供了一个超越传统搜索方法的个性化购物体验。", "innovation": "Flippi利用先进的自然语言处理技术，如查询重写、意图检测、检索增强生成（RAG）、命名实体识别（NER）和背景信息减少等，解读客户查询并提供精准的商品信息。Flippi还具备识别和展示电子商务平台上最具吸引力优惠的能力，帮助用户做出成本效益高的决策。此外，论文还探讨了Flippi的比较分析功能，使得用户可以通过对比产品特性、价格和其他相关属性来做出有根据的选择。系统架构强大且灵活，适用于各种电子商务平台的集成，并且论文还详细描述了其设计和性能背后的科技选择。", "conclusion": "通过结合在线购物的便捷性和实体店传统上提供的个性化帮助，Flippi树立了一个新的标准，为数字市场中的顾客满意度和参与度设立了新的基准。论文最后提出了全面的评估框架，涵盖了性能指标、用户满意度以及对客户参与度和转化率的影响。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08846", "html_url": "https://arxiv.org/abs/2506.08846", "title": "改进自动语音识别技术审计实践中的缺陷：基于失语症患者的案例研究", "title_en": "Addressing Pitfalls in Auditing Practices of Automatic Speech Recognition Technologies: A Case Study of People with Aphasia", "authors": "Katelyn Xiaoying Mei,Anna Seo Gyeong Choi,Hilke Schellmann,Mona Sloane,Allison Koenecke", "background": "自动语音识别（ASR）已经改变了我们的日常任务，从视频转录到工作场所招聘。ASR系统的广泛应用需要有严格和标准化的审计方法来确保高质量和公平的自动转录。尤其是对于有言语和语言障碍（如失语症）的人士，他们可能过度依赖ASR系统来应对日常生活。现有的ASR审计实践存在三个缺陷：单一的数据预处理文本标准化方法掩盖了不同标准化方法对性能的影响，且与用户的需求不一致；缺乏对更细致的亚群体和相关影响音频输入的声学信息的协变量的进一步考虑；以及依赖单一的金标准度量（如单词错误率）无法全面捕捉从生成AI模型中产生的错误。", "innovation": "本研究提出了一个更全面的ASR审计框架，以解决现有审计实践中的三个缺陷，并通过基于失语症患者群体的案例研究证明其效果，发现失语症患者的ASR性能普遍较差。提出了实施这些稳健的ASR审计实践的建议，以便适应快速变化的ASR环境，同时保持灵活性。", "conclusion": "提出了一个更综合的ASR审计框架，以解决现有的审计实践问题，通过失语症患者的案例研究展示了其结果，并呼吁从业者实施这些稳健的ASR审计实践，以适应快速变化的ASR环境，保持灵活性。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07257", "html_url": "https://arxiv.org/abs/2507.07257", "title": "开源规划与控制系统及其语言代理自主科学研究", "title_en": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery", "authors": "Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekioui,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet", "background": "本文介绍了一个用于自动化科学研究任务的多智能体系统，称为cmbagent。该系统由约30个大型语言模型（LLM）智能体组成，采用规划与控制策略来协调智能体的工作流，并且在系统运行的任何阶段都不需要人工干预。每个智能体专注于不同的任务，如检索科学论文和代码库、编写代码、解释结果以及批评其他智能体的输出。系统能够在本地执行代码，并成功应用于一项相当于博士级别的宇宙学任务，即使用超新星数据测量宇宙参数。此外，系统经过了两个基准测试集的评估，发现其性能优于最先进的LLM。", "innovation": "该系统通过规划与控制策略将30个大型语言模型智能体组合起来，形成一个自动化的科学发现平台。每个智能体专注于不同的任务，并且系统能够在本地执行代码，这是其创新之处。该系统展示了多智能体系统在科学研究中的应用，并证明了其在性能上的优势。同时提供了开源代码和演示视频，并部署在HuggingFace和云平台上，使得研究人员可以方便地使用该系统。", "conclusion": "本文介绍的cmbagent系统成功实现了自动化科学研究任务，展示了多智能体系统及其规划与控制策略在科学研究中的应用潜力。该系统不仅在博士级别的任务中表现优异，还通过了基准测试集的评估，显示出优于当前最佳语言模型的性能。系统已开源，供研究人员使用。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01163", "html_url": "https://arxiv.org/abs/2503.01163", "title": "基于多臂老虎机的提示设计策略选择改进了提示优化器", "title_en": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers", "authors": "Rin Ashizawa,Yoichi Hirose,Nozomu Yoshinari,Kento Uchida,Shinichi Shirakawa", "background": "提示优化旨在寻找有效的提示以增强大型语言模型（LLMs）的性能，尽管现有的提示优化方法发现了有效的提示，但这些提示通常与人类专家精心设计的复杂提示有所不同。提示设计策略是提升提示性能的最佳实践，对于改进提示优化至关重要。最近，一种名为自主提示工程工具箱（APET）的方法将多种提示设计策略融入到提示优化过程中。然而，APET 中LLMs 需要隐式选择和应用适当的策略，因为提示设计策略可能会产生负面影响。这种隐式选择由于LLMs 优化能力的局限性可能会产生次优结果。", "innovation": "本文介绍了使用策略选择机制优化提示的方法（OPTS），并将其应用于 EovPrompt，一种已知的提示优化器。OPTS 采用了基于 Thompon 抽样的方法，并实现了显式选择机制。实验结果表明，选择提示设计策略能够提升 EvoPrompt 的性能，而基于 Thompon 抽样的机制取得了最佳的整体效果。", "conclusion": "实验结果表明，选择提示设计策略提升了 EvoPrompt 的性能，其中基于 Thompon 抽样的机制表现最佳。此外，研究结果表明，使用显式选择机制的 OPTS 实现了更好的提示优化性能。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06892", "html_url": "https://arxiv.org/abs/2507.06892", "title": "挤干海绵：用于大型语言模型的高效离策强化微调", "title_en": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model", "authors": "Jing Liang,Hongyao Tang,Yi Ma,Jinyi Liu,Yan Zheng,Shuyue Hu,Lei Bai,Jianye Hao", "background": "现有的强化学习（RL）微调（RFT）方法大多为基于策略的RL，这种方式未能充分有效利用以往学习过程生成的数据，这导致了计算和时间成本的显著增加，限制了大型语言模型（LLMs）在经济高效扩展方面的潜力。", "innovation": "提出了Reincarnating Mix-policy Proximal Policy Gradient (ReMix)，一种通用方法使得原有的基于策略的RFT方法如PPO和GRPO能够利用离策数据。ReMix包括混合策略的PPG（提高了更新到数据的比例以提高训练效率）、KL凸性策略约束（平衡稳定性和灵活性）和策略转世（实现从早期快速学习到稳定改进的无缝过渡）三个主要组成部分。与15个最新模型相比，ReMix在培训成本减少了30倍到450倍的情况下，依旧显示了SOTA水平的表现。", "conclusion": "通过多方面的分析，揭示了离策偏差的鞭打效应倾向于偏好较短的响应，以及在高度离策性下自我反思行为的崩溃模式等问题。ReMix通过有效利用离策数据显著减少了训练成本，同时保持了高效的学习效果。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01403", "html_url": "https://arxiv.org/abs/2504.01403", "title": "生成检索与对齐模型：电子商务检索的新范式", "title_en": "Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval", "authors": "Ming Pang,Chunyuan Yuan,Xiaoyu He,Zheng Fang,Donghao Xie,Fanyi Qu,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao", "background": "传统的稀疏检索和密集检索方法难以利用广泛的世界知识，并且常常无法捕捉查询和产品的细微特征。大型语言模型（LLMs）的出现使工业搜索系统开始使用LLMs生成产品检索的标识符。常用的方式包括静态/语义ID和产品词集。前者需要从头创建产品ID系统，容易忽略嵌入在LLMs中的世界知识；而后者则利用了这种一般知识，但由于查询和产品间的词分布差异显著，基于产品标识符的方式往往与用户搜索查询不匹配，导致产品召回率较低。此外，当查询包含多个属性时，这种方法生成大量的标识符，难以评估其质量，导致整体召回效率较低。", "innovation": "本文提出了一个新的电子商务检索框架：生成检索与对齐模型（GRAM）。GRAM通过联合训练查询和产品文本信息来生成共享的文本标识符代码，有效缩小了查询和产品之间的差距。该方法不仅增强了查询和产品的连接性，还提高了推理效率。模型使用共对齐策略生成代码，以最大化检索效率。此外，引入了查询和产品评分机制，进一步提升了检索效率。大量的 offline 和 online A/B 测试表明，GRAM 显著优于传统模型和最新的生成检索模型，验证了其有效性和实用性。", "conclusion": "总的来说，GRAM 通过联合训练查询和产品文本信息生成共享文本标识符代码的新方法显著提高了检索效率，具体表现为更好的查询与产品连接性、更高的推理效率，以及通过共对齐策略和评分机制进一步优化了检索效果。实验表明，GRAM 在实际应用中表现优越，具有实用性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08026", "html_url": "https://arxiv.org/abs/2507.08026", "title": "ITU-R P.1411传播模型的加拿大全国形态图开发", "title_en": "Development of a Canada-Wide Morphology Map for the ITU-R P. 1411 Propagation Model", "authors": "Jennifer P. T. Nguyen", "background": "本文概述了基于ITU-R P.1411-12传播模型指南，开发加拿大全国范围内的形态图，该形态图将区域分类为住宅、低层城市和高层城市环境。环境类型描述具有定性的特性。", "innovation": "为了应对推荐中环境类型描述的定性特性，本文采用了机器学习方法自动化分类过程，从而优化路径损耗估算的准确性，确保300 MHz到100 GHz频率范围内的室外短距离传播路径损耗估计更为精确。", "conclusion": "经过大量实验优化，本文开发出一个适用于频率从300 MHz到100 GHz的加拿大全国范围内的形态图，能够提供更为精确的室外短距离传播路径损耗估算。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.11924", "html_url": "https://arxiv.org/abs/2503.11924", "title": "REGEN：具有自然语言评论和叙述的语料库和基准", "title_en": "REGEN: A Dataset and Benchmarks with Natural Language Critiques and Narratives", "authors": "Kun Su,Krishna Sayana,Hubert Pham,James Pine,Yuri Vasilevski,Raghavendra Vasudeva,Marialena Kyriakidi,Liam Hebert,Ambarish Jash,Anushya Subbiah,Sukhdeep Sodhi", "background": "现有的推荐系统数据集主要关注于序列项目预测，这在评估大型语言模型（LLMs）的对话能力方面存在局限性。REGEN数据集通过在亚马逊产品评论数据集中补充用户评论和叙述来解决这些限制。用户评论代表了用户引导查询，而叙述则包含了与推荐物品相关的丰富文本描述，这些描述考虑了以往的上下文。这些叙述包括产品推荐、购买解释和用户偏好总结。", "innovation": "1. 提出了REGEN数据集，该数据集通过添加用户评论和叙述来扩展亚马逊产品评论数据集，以评估推荐系统的对话能力。用户评论代表了用户决定后续项目的引导查询，而叙述则包含了推荐物品的丰富文本描述，考虑到之前的背景信息。\n2. 引入了一个端到端建模基准，用于对话推荐任务，模型被训练生成推荐及相应的叙述，条件于用户历史（物品和评论）。\n3. 提出了基于LLM的统一多任务模型框架LUMEN（LLM-based Unified Multi-task Model with Critiques, Recommendations, and Narratives），该框架利用LLM作为评价、检索和生成的核心。\n4. 通过标准自动评级技术评估数据集的质量，并通过训练传统和基于LLM的推荐模型测试其基准，结果表明评论的引入可以增强推荐质量，并且使用该数据集训练的LLM可以有效生成推荐和上下文叙述，性能媲美最新的推荐器和语言模型。", "conclusion": "研究表明，引入用户评论可以提高推荐质量，使推荐器学会语言理解并与推荐信号结合起来。此外，基于该数据集训练的LLM有效生成了推荐和上下文叙述，达到了最先进的推荐器和语言模型的性能水平。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08039", "html_url": "https://arxiv.org/abs/2507.08039", "title": "面向文本到图像模型提示遵守稳健性评估的研究", "title_en": "Towards Evaluating Robustness of Prompt Adherence in Text to Image Models", "authors": "Sujith Vemishetty,Advitiya Arora,Anupama Sharma", "background": "近年来，大型语言模型（LLMs）取得了显著进步，展示了其卓越的能力和广泛的应用。它们在实际场景中的潜在应用促成了对其可靠性和有效性的大量研究。与此同时，多模态LLMs和文本到图像模型近年来才逐渐受到关注，特别是与单一文本LLMs相比。但由于缺乏评估这些模型性能和鲁棒性的研究，它们的可靠性仍然受到限制。本文旨在建立一套全面的评估框架，特别是在衡量这些模型对指令的遵守方面。研究对Stable Diffusion和Janus模型的不同版本进行了评估，揭示了一些问题并提供了新的见解。", "innovation": "本文引入了一种新的评估管道，通过GPT-4o生成的数据集作为真实图像的基准，再将这些描述传递给文本到图像模型生成图像，然后再次使用GPT-4o评估生成图像与原始描述的变化。这项研究揭示了模型在生成具有单一二元因素变体的简单几何形状图像时的挑战。同时，使用预先训练的VAEs也表明了模型未能生成符合输入数据集分布的图像。", "conclusion": "研究结果表明，现有的文本到图像模型在生成具有单一二元因素变体的简单几何形状图像时存在困难，并且无法准确生成符合给定数据集分布的图像。本文提出了一个创新的评估框架，有助于推动对该类模型性能和鲁棒性的进一步研究。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08044", "html_url": "https://arxiv.org/abs/2507.08044", "title": "ConsNoTrainLoRA：使用约束条件的数据驱动权重初始化方法", "title_en": "ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints", "authors": "Debasmit Das,Hyoungwoo Park,Munawar Hayat,Seokeon Choi,Sungrack Yun,Fatih Porikli", "background": "基于模型在大规模数据集上预训练，然后使用参数高效调整（PEFT）技术（如低秩适应器或LoRA）进行小规模数据集的微调。在大多数以前的工作中，LoRA的权重矩阵在所有连接点上以固定秩随机初始化。该论文提出了一种数据驱动的LoRA权重初始化方法，ConsNoTrainLoRA（CNTLoRA），以改善LoRA微调的收敛性和最终性能。", "innovation": "该研究提出了一种新的权重初始化方法CNTLoRA，它将LoRA权重初始化视为领域转换问题，并引入了多个约束条件来表达预训练和微调激活之间的关系。通过重新表述这些约束条件，得出了一个闭式估算公式，该公式依赖于预训练权重和微调激活向量，在初始化时无需进行训练，从而允许初始化矩阵具有可变的秩。", "conclusion": "通过提出的初始化方法，该论文在图像生成、图像分类和图像理解等下游任务上进行微调。定量和定性的结果表明，CNTLoRA优于标准方法和数据驱动的权重初始化方法。广泛的实证分析和消融测试进一步阐明了框架的设计选择，为更快的收敛和更好的性能提供了最佳配方。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08022", "html_url": "https://arxiv.org/abs/2507.08022", "title": "CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025", "title_en": "CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025", "authors": "Hayato Tanoue,Hiroki Nishihara,Yuma Suzuki,Takayuki Hori,Hiroki Takushima,Aiswariya Manojkumar,Yuki Shibata,Mitsuru Takeda,Fumika Beppu,Zhao Hengwei,Yuto Kanda,Daichi Yamaga", "background": "该报告展示了CuriosAI团队在CVPR 2025年的EgoExo4D技能评估挑战中的提交。背景信息涉及通过多视角评估技能的方法研究，尤其是在视觉识别和多任务学习领域的应用研究。过去的技能评估方法可能需要单独针对不同场景和视角进行特定优化，存在一定的局限性。", "innovation": "创新点在于提出了两种多视角技能评估方法：（1）一种基于Sapiens-2B的多任务学习框架，同时预测技能水平和情境标签，准确率为43.6％；（2）一种两阶段处理管道，结合零样本情境识别和针对特定视角的VideoMAE分类器，准确率为47.8％。第二阶段方法的优越性能表明，在技能评估中使用情境条件建模的有效性。", "conclusion": "结论总结了所提出的两种方法的性能，并强调了情境条件建模在技能评估中的有效性。作为一种新的方法论，这项工作为未来技能评估系统的开发提供了新的见解和思路。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08024", "html_url": "https://arxiv.org/abs/2507.08024", "title": "Vision-Language模型在精准农业中的自一致性：作物病害管理的多响应共识", "title_en": "Self-Consistency in Vision-Language Models for Precision Agriculture: Multi-Response Consensus for Crop Disease Management", "authors": "Mihir Gupta,Abhay Mangla,Ross Greer,Pratik Desai", "background": "精准农业依赖于精确的图像分析来识别作物疾病和推荐治疗措施，但现有的视觉-语言模型（VLMs）在专门的农业领域往往表现不佳。", "innovation": "提出了一种领域意识框架，结合了基于提示的专家评估协议和自一致性机制，以提高VLM在精准农业应用中的可靠性。（1）基于提示的评估协议将语言模型配置为专家植物病理学家，用于图像分析输出的可扩展评估；（2）余弦一致性自我投票机制，从农业图像中生成多个候选响应并使用领域适应嵌入选择最具语义一致性诊断。", "conclusion": "应用到使用微调PaliGemma模型的玉米叶片疾病识别，我们的方法将诊断准确率从82.2%提高到87.8%，症状分析从38.9%提高到52.2%，治疗建议从27.8%提高到43.3%，相比标准贪婪解码。该系统足够紧凑，可以部署在移动设备上，支持资源受限环境中的实时农业决策，结果表明，AI驱动的精准农业工具在不同田间条件下具有显著的可靠运行潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08047", "html_url": "https://arxiv.org/abs/2507.08047", "title": "一种应用于四旋翼无人机的混合多层极限学习机及其图像分类应用", "title_en": "A Hybrid Multilayer Extreme Learning Machine for Image Classification with an Application to Quadcopters", "authors": "Rolando A.Hernandez-Hernandez,Adrian Rubio-Solis", "background": "多层极限学习机（ML-ELM）及其变体已被证明是音频、视频、声学信号和图像等不同自然信号分类的有效技术。本文的方法结合了基于极限学习机自动编码器（ELM-AE）的极限学习机和区间型2模糊逻辑理论，用于无人机的主动图像分类。", "innovation": "提出的混合多层极限学习机（HML-ELM）是一种分层的极限学习机学习框架，分为两阶段：1）自我教导特征提取，2）监督特征分类。通过采用新颖的简化区间型2模糊逻辑极限学习机（SIT2-FELM），结合SC算法和改进的中心集类型减少算法（COSTRWSR），实现了高效无监督特征编码和快速输出减少。", "conclusion": "为了验证HML-ELM的效果，进行了两种类型的实验证明了其在图像分类和四个不同物体（未定义）在两预设地点之间的主动识别和输送方面的有效性，相比其他类似方法（如ML-ELM、多层模糊极限学习机（ML-FELM）和极限学习机），HML-ELM表现出了更高的效率。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08052", "html_url": "https://arxiv.org/abs/2507.08052", "title": "轻量级云掩模模型在高光谱成像机载推理中的应用", "title_en": "Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging", "authors": "Mazen Ali,António Pereira,Fabio Gentile,Aser Cortines,Sam Mugel,Román Orús,Stelios P. Neophytides,Michalis Mavrovouniotis", "background": "云及云阴影掩模是高光谱卫星成像中的关键预处理步骤，有助于提取高质量、可供分析的数据。", "innovation": "研究评估了多种机器学习方法，包括梯度提升方法（如XGBoost和LightGBM）及卷积神经网络（CNN），所有模型准确率均超过93%。其中，结合特征降维的CNN模型特别高效，兼具高准确率、低存储需求及快速推理速度。不同版本的该模型，最多仅包含597个可训练参数，展示了在部署可行性、准确率及计算效率方面的最佳平衡。", "conclusion": "研究证实了轻量级AI模型在实时高光谱图像处理中的潜力，支持开发用于太空应用的机载卫星AI系统。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.08054", "html_url": "https://arxiv.org/abs/2408.08054", "title": "基于大型语言模型多代理框架的Text2BIM：使用自然语言指令生成建筑模型", "title_en": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "authors": "Changyu Du,Sebastian Esser,Stavros Nousias,André Borrmann", "background": "传统的BIM (建筑信息模型) 编写过程通常需要设计人员掌握复杂的建模命令，才能在BIM工具中实现他们的设计方案，这增加了认知负担，复杂化了设计过程，并阻止了BIM及基于模型的设计在建筑、工程和施工行业的应用。", "innovation": "提出了一种名为Text2BIM的基于LLM (大型语言模型) 的多代理框架，使其能够从自然语言指令生成3D建筑模型。该框架通过协调多LLM代理进行协作和推理，将用户的文本输入转化为指令代码，调用BIM作者工具的API，从而直接在软件中生成可编辑的BIM模型，具有内部布局、外部围护和语义信息。此外，在代理工作流程中引入基于规则的模型检查器，利用预定义的知识领域指导LLM代理解决生成模型中的问题，逐步提高模型质量。", "conclusion": "实验结果表明，该方法可有效生成与用户输入的抽象概念一致且结构合理的高质量建筑模型。最终开发了支持用聊天进行建模的交互式软件原型，集成该框架至BIM撰写软件Vectorworks，展示了此方法的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08136", "html_url": "https://arxiv.org/abs/2507.08136", "title": "RegGS: 使用3DGS注册进行未摆姿势的稀疏视角高斯溅射", "title_en": "RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration", "authors": "Chong Cheng,Yu Hu,Sicheng Yu,Beizhen Zhao,Zijian Wang,Hao Wang", "background": "3D高斯溅射（3DGS）已经在从未摆姿势图像中重建场景方面展示了潜在应用。尽管如此，基于优化的3DGS方法在稀疏视角场景中表现不佳，因为它们依赖有限的先验知识。另一方面，前馈方式的高斯模型受到输入格式的限制，使得难以整合更多的视角输入。", "innovation": "本文提出了一种名为RegGS的3D高斯注册框架，用于重建未摆姿势的稀疏视角。RegGS将由前馈网络生成的局部3D高斯分布注册到一个全局一致的3D高斯表示中。技术上，通过实现一个熵正则化的Sinkhorn算法，以高效地求解最优传输加权二次 Wasserstein（MW_2）距离，该算法作为Sim(3)空间中高斯混合模型（GMMs）的对齐度量。此外，设计了一个联合3DGS注册模块，融合MW_2距离、光度一致性和深度几何，以实现粗细粒度的注册过程，同时准确估计相机姿态并对齐视图场景。", "conclusion": "在RE10K和ACID数据集上的实验表明，RegGS能够以高保真的方式注册局部高斯分布，实现精确的姿态估计和高保真的新颖视角合成。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08059", "html_url": "https://arxiv.org/abs/2507.08059", "title": "高斯分布的重要性", "title_en": "The relative importance of being Gaussian", "authors": "F. Alberto Grünbaum,Tondgi Xu", "background": "关于去噪在计算机视觉中的研究成果，在文献[SDWMG, HJA, HHG]中证明了扩散模型在去噪方面的显著效果，这对基于关键高斯独立$N(0,1)$随机变量序列性质的算法提供了坚实的数学依据。特别是，推导过程中利用了高斯分布由其均值和方差唯一确定的性质以及两个高斯分布之和仍然是高斯分布的事实。文章指出，当算法用于非高斯噪声（例如均匀分布噪声、Beta分布的噪声或具有非常不同方差的两个高斯分布的随机叠加）时，它的性能可能会受到很大影响。尽管可以尝试修改算法来适应不同的噪声类型，但本文研究的重点是探讨算法在处理与高斯噪声性质差异极大的情况下，其性能的变化情况。实验均在一台小型笔记本电脑上进行，对最小尺寸的图像进行测试。", "innovation": "研究了扩散模型在面对非高斯噪声时的表现，特别侧重于非高斯噪声对去噪算法性能的影响，而不是针对不同类型的噪声调整算法。这种情况下对去噪算法进行实验性研究，使用了与高斯噪声性质差异极大的噪声进行测试，目的在于观察和研究在不同噪声条件下算法的性能变化，为理解和优化去噪算法提供了新的视角。", "conclusion": "尽管扩散模型在高斯噪声环境下表现出色，但在处理与高斯噪声性质差异极大的噪声时，其性能会受到显著影响。本文在小型设备上进行的实验验证了这一点，为算法的适应性使用提供了新的研究方向。进一步的研究应该集中在如何改进算法以适应更多类型的噪声环境，以及如何提高算法对噪声处理的鲁棒性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08163", "html_url": "https://arxiv.org/abs/2507.08163", "title": "自适应去噪扩散平滑：通过差分隐私引导去噪扩散随机平滑实现可验证鲁棒性", "title_en": "Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion", "authors": "Frederick Shpilevskiy,Saiyue Lyu,Krishnamurthy Dj Dvijotham,Mathias Lécuyer,Pierre-André Noël", "background": "该研究提出了自适应去噪扩散去噪（ADD）方法，用于在对抗样本中保证视觉模型预测，同时适应输入。背景在于，在存在对抗样本的情况下，保证模型预测的正确性和鲁棒性非常重要。传统方法如随机化平滑在提高鲁棒性的同时，可能会降低准确率。本文旨在发展一种新的方法，既能保证模型的鲁棒性，又能提高准确率。", "innovation": "研究的核心创新在于将引导去噪扩散模型重新解释为一系列自适应高斯不同性隐私（GDP）机制，逐步将纯噪声样本转化为图像，通过将这些自适应机制与GDP隐私滤波器组合来分析整个引导去噪过程的端到端稳健性，从而提供一种可证的鲁棒性认证，此认证扩展了适应性随机化平滑分析。实验证明，该设计在特定引导策略下，不仅能够在ImageNet上的$$\boldsymbol{l}_2$$威胁模型下提高认证精度，而且还能提升标准精度。", "conclusion": "研究结果表明，通过结合特定的引导策略，自适应去噪扩散平滑方法不仅能够提升ImageNet上$$\boldsymbol{l}_2$$威胁模型下的认证精度，还能提高标准精度。这种方法为依赖随机化平滑技术的模型提供了一种新的提升鲁棒性和准确性的途径。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08240", "html_url": "https://arxiv.org/abs/2507.08240", "title": "通过扩展CLIP-EBC框架实现车辆对象计数和位置估计", "title_en": "Car Object Counting and Position Estimation via Extension of the CLIP-EBC Framework", "authors": "Seoik Jung,Taekyung Song", "background": "本文探讨了CLIP-EBC框架在车辆计数任务中的应用，该框架最初是为人群计数设计的。使用CARPK数据集进行实验表明，该模型在现有方法中排名第二。此外，提出了基于预测密度图的K-means加权聚类方法来估计对象位置。", "innovation": "提出了基于预测密度图的K-means加权聚类方法来估计对象位置，这表明了框架在定位任务中的潜在扩展。", "conclusion": "该模型在车辆计数任务中表现良好，位于现有方法第二，展示了CLIP-EBC框架在车辆计数和定位任务中的应用潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08223", "html_url": "https://arxiv.org/abs/2507.08223", "title": "SurfDist：使用弯曲表面片段进行可解释的三维实例分割", "title_en": "SurfDist: Interpretable Three-Dimensional Instance Segmentation Using Curved Surface Patches", "authors": "Jackson Borchardt,Saul Kato", "background": "本文介绍了一种新的三维实例分割架构SurfDist，该架构是一种卷积神经网络，能够预测由光滑参数表面片段组成的闭合表面表示的实例。SurfDist 是对流行模型架构 StarDist-3D 的改进，能够将实例参数维度与实例体素分辨率解耦，使得预测结果可以在不引入体素化伪影的情况下放大到任意高分辨率。对于具有斑块状实例的数据集，SurfDist 可以在保持紧凑实例参数化方面优于 StarDist-3D，这种类型的数据集在生物医学成像中很常见。SurfDist 结合了实例分割技术和表面模型学习的有效性。", "innovation": "SurfDist 通过解耦实例参数维度和实例体素分辨率，使得能够生成可放大到极高分辨率的预测而不会引入体素化伪影。与 StarDist-3D 相比，SurfDist 的实例参数化更紧凑，适用于斑块状实例，如生物医学影像中的常见情况。通过弯曲表面片段，SurfDist 能够生成对用户可解释的实例表面模型。", "conclusion": "SurfDist 改进了实例分割性能，特别是在生物医学成像数据集上。结果表明，可以通过有效的实例成员身份的同时学习来获得可解释的实例表面模型。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08248", "html_url": "https://arxiv.org/abs/2507.08248", "title": "迁移学习与Mixup在细粒度少样本真菌分类中的应用", "title_en": "Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification", "authors": "Jason Kahei Tam,Murilo Gustineli,Anthony Miyaguchi", "background": "准确识别真菌种类在计算机视觉中是一项独特挑战，因为不同物种之间存在细粒度变异，同一物种内部也存在高变异。本文介绍了DS@GT团队在FungiCLEF 2025竞赛中的方法，该竞赛集中在使用FungiTastic Few-Shot数据集的少样本细粒度视觉分类（FGVC）。", "innovation": "团队尝试了多种视觉变换模型、数据增强、加权采样以及结合文本信息。还探索了结构化提示的生成AI模型用于零样本分类，但发现其表现远不及基于视觉的模型。最终模型在竞赛基线中表现出色，强调了领域特定预训练和平衡采样策略的有效性。此外，团队还发现元数据选择和领域适应多模态学习的改进空间。", "conclusion": "在完成后的评估中，DS@GT团队的方法在私下测试集中的排名为35/74，这表明还需在元数据选择和领域适配多模态学习方面进行更多工作。代码已公开。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08268", "html_url": "https://arxiv.org/abs/2507.08268", "title": "便携生物力学实验室：手持智能手机进行便捷的运动分析", "title_en": "Portable Biomechanics Laboratory: Clinically Accessible Movement Analysis from a Handheld Smartphone", "authors": "J.D. Peiffer,Kunal Shah,Irina Djuraskovic,Shawana Anarwala,Kayan Abdou,Rujvee Patel,Prakash Jayabalan,Brenton Pennicooke,R. James Cotton", "background": "人的运动方式直接反映了其神经和肌肉骨骼健康状况，但在临床实践中仍然被广泛应用得较少。临床医生能够观察到运动障碍，但缺乏易于获取且验证过的客观方法来在日常护理中测量运动。这种差距阻碍了生物力学测量在临床实践中的更广泛应用，生物力学测量可以帮助更敏感地评估结果或更早地识别障碍。因此，作者开发了便携生物力学实验室（PBL），该设备包括一款安全的云连接智能手机应用，用于数据收集以及一种创新的算法，用于根据数据拟合生物力学模型。研究使用大量临床代表数据集对PBL的生物力学测量进行了全面验证。", "innovation": "该研究的创新点在于利用智能手机应用和算法进行生物力学测量，便于在临床环境中广泛应用。PBL在多类参与者中表现出了良好的准确性和可靠性，尤其在神经外科和运动医学诊所的应用中显示出其高可靠性和对临床差异的敏感性。通过PBL计算得出的步态指标与患者报告的结果相似，但更能反映出手术干预的效果。", "conclusion": "这些发现支持手持智能手机视频作为一种可扩展、低负担工具，可用于捕捉临床有意义的生物力学数据。PBL为便捷监测运动障碍的监测提供了具有前景的方法。研究结果表明，可以从手持智能手机视频中量化全身动力学数据，这提供了一个有前景的途径，可以实现运动障碍的可访问监控。作为首个经临床验证的方法，PBL可以用于测量手持智能手机视频中的全身动力学。"}
{"llm_update_time": "20250714", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07930", "html_url": "https://arxiv.org/abs/2507.07930", "title": "探索专家对AI辅助公开演讲培训的看法", "title_en": "Probing Experts' Perspectives on AI-Assisted Public Speaking Training", "authors": "Nesrine Fourati,Alisa Barkar,Marion Dragée,Liv Danthon-Lefebvre,Mathieu Chollet", "background": "公开演讲是一项重要的专业技能，但对许多人来说却是一个显著的焦虑源。传统的训练通常依赖于专家指导，然而最近的人工智能技术的进步导致了一些新颖的商业自动公开演讲反馈工具的出现。然而，大多数研究都集中在原型上而非商业应用，而且很少有人了解公开演讲专家对这些工具的看法。", "innovation": "研究通过16次半结构化访谈和2个焦点小组，旨在评估公开演讲专家对商业AI基础公开演讲训练工具的有效性和设计的看法，并提出改进的建议。研究表明，专家认可AI工具在处理训练中的重复和技术方面有价值，允许教练专注于高级技能。然而，他们也指出了当前工具的一些关键问题，强调了个性化的、易于理解的、精心选择的反馈和清晰的指令设计的必要性。总体而言，他们支持结合传统的教练方法和AI辅助练习的混合模式。", "conclusion": "专家们承认AI工具在处理训练中的重复和技术方面具有价值，允许教练专注于高级技能。然而，他们也发现当前工具存在关键问题，强调了个体化、易理解、精心选择的反馈和清晰的指令设计的必要性。总的来说，他们支持结合传统教练方法和AI辅助练习的混合模式。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08137", "html_url": "https://arxiv.org/abs/2507.08137", "title": "基于时空一致的无模态补全进行3D人体-物体交互重建", "title_en": "Temporally Consistent Amodal Completion for 3D Human-Object Interaction Reconstruction", "authors": "Hyungjun Doh,Dong In Lee,Seunggeun Chi,Pin-Hao Huang,Kwonjoon Lee,Sangpil Kim,Karthik Ramani", "background": "传统3D重建方法通常假设静态物体或动态主体完全可见，但这在实际应用中难以满足。在互有遮挡的情况下，这些假设会违反，导致性能下降。本文针对这一问题，引入了一种新颖的框架，用于从单目视频中重建动态的人体-物体交互，克服了遮挡和时间不一致性带来的挑战。该框架利用无模态完成技术进行部分被遮挡区域的完整结构推断，区别于传统仅在单帧上操作的方法，本文的方法考虑了视频序列的时空上下文，确保多帧间的连贯性，逐步细化和稳定重建结果，增强了复杂动态场景下细节恢复的效果。", "innovation": "- 引入了基于无模态完成的框架，用于单目视频中的人体-物体交互重建。\n- 考虑了视频序列的时空上下文，确保多帧间的连贯性，逐步细化和稳定重建结果。\n- 具有无模态特性，能够适应多种变化条件，不需要预定义模型，提高了复杂动态场景下细节恢复的效果。\n- 与现有技术相比，在处理遮挡和保持时间一致性方面表现更优异，通过3D高斯打点技术进行了验证。", "conclusion": "本文提出的框架可以在单目视频中有效重建动态的人体-物体交互，克服了遮挡和时间不一致的问题。通过无模态完成和考虑视频序列的时空上下文，框架能够逐步细化和稳定重建结果，显著提升了复杂动态场景下的细节恢复效果。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08329", "html_url": "https://arxiv.org/abs/2507.08329", "title": "跨域身份表示用于头骨到面部匹配的基准数据集", "title_en": "Cross-Domain Identity Representation for Skull to Face Matching with Benchmark DataSet", "authors": "Ravi Shankar Prasad,Dinesh Singh", "background": "法医领域的头面部重建对于犯罪和灾难中受害者的身份识别至关重要。近年来，计算机视觉领域的进步，特别是深度学习方法的应用，为实现这一目标提供了技术支撑。", "innovation": "本文提出了一种基于卷积Siamese网络的方法，用于根据头骨X光片匹配面部图像，解决了匹配数据对难以收集的问题，展示了在跨域数据集上的有效识别结果。", "conclusion": "实验结果表明，所提出的方法在头骨识别方面取得了令人满意的结果。通过使用自建的数据集，验证了Siamese网络在跨域身份表示中的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08290", "html_url": "https://arxiv.org/abs/2507.08290", "title": "使用结构层次适应和可靠邻接对齐的跨分辨率SAR目标检测", "title_en": "Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment", "authors": "Jiang Qin,Bin Zou,Haolin Li,Lamei Zhang", "background": "近年来，SAR成像分辨率的持续提升在城市监控和目标检测方面带来了显著优势。然而，分辨率的提升也导致散射特性差异增大，使得目标检测模型的泛化能力面临挑战。虽然领域适配技术有一定的缓解作用，但分辨率差异带来的不可避免的差异常常会导致盲目特征适应和不可靠语义传播，最终降低领域适配的性能。", "innovation": "本文提出了一个创新的SAR目标检测方法（CR-Net），它将结构先验和证据学习理论结合到检测模型中，实现跨分辨率的可靠领域适应。具体而言，CR-Net引入了结构诱导层次特征适配（SHFA）模块和可靠结构邻接对齐（RSAA）模块，前者通过结构关联建立了目标之间的结构关系，增强了特征适应过程的可解释性；后者通过利用安全的邻接集合，从源域向目标域传递有价值的可区分知识，进一步提高了目标域检测模型的可区分性。", "conclusion": "基于不同分辨率数据集的实验结果，CR-Net在保持领域内结构的同时显著提高了跨分辨率适应性，并实现了跨分辨率SAR目标检测的SOTA性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08330", "html_url": "https://arxiv.org/abs/2507.08330", "title": "面向高效医学图像分析的可解释性驱动剪枝", "title_en": "Interpretability-Aware Pruning for Efficient Medical Image Analysis", "authors": "Nikita Malik,Pratinav Seth,Neeraj Kumar Singh,Chintan Chitroda,Vinay Kumar Sankarapu", "background": "深度学习在医学图像分析领域取得了显著进展，但在临床实践中受到现代模型规模庞大、透明度不足的限制。尽管基于 DL-Backtrace、逐层相关传播和集成梯度等可解释性技术的进步使得可以评估训练在医学影像任务上的神经网络中各个组件的贡献，但这些模型的大规模仍限制了它们的直接应用。", "innovation": "本文介绍了一种基于可解释性引导的剪枝框架，该框架可以在保留预测性能和透明度的同时减少模型复杂性。通过有选择地保留每一层中最相关的部分，该方法实现了针对临床意义的表现压缩。我们在多个医学图像分类基准测试中进行了实验，结果表明该方法能够实现高压缩率且损失的精度较小，为在实际医疗场景中部署轻量级、可解释的模型铺平了道路。", "conclusion": "这种方法在多个医学图像分类基准测试中实现了高压缩率且精度损失较小，为在实际医疗环境中部署轻量级和可解释的模型提供了可能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08307", "html_url": "https://arxiv.org/abs/2507.08307", "title": "M2DAO-Talker: 调和多粒度运动解耦与交替优化以实现口型驱动的头部动画生成", "title_en": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation", "authors": "Kui Jiang,Shiyu Liu,Junjun Jiang,Xin Yang,Hongxun Yang,Xiaopeng Fan", "background": "现有的音频驱动的头部动画生成技术在电影制作中具有显著潜力，但在模型运动和内容合成方面尽管取得了进展，但由于在稳定精细运动场表示方面的局限性，算法往往会产生渲染缺陷，如运动模糊、时间跳跃和局部穿透等。本文通过系统分析，重新构建了头部动画生成步骤，提出了一个包含视频预处理、运动表示和渲染重建三个步骤的统一框架。", "innovation": "本文创新性地提出了一种多粒度运动解耦策略，它独立建模非刚性（口腔和面部）和刚性（头部）运动以改进重构，同时设计了一种交替优化策略来迭代细化面部和口腔运动参数，提高了视频的逼真度。另外，通过开发运动一致性约束，确保头部与躯干的动慼一致性，从而减少了由于运动混叠引起的身体穿插缺陷。", "conclusion": "M2DAO-Talker在多个数据集上展示了最先进的性能，生成质量在PSNR上提高了2.43 dB，并且在用户评估的真实感上相比于TalkingGaussian提高了0.64分，同时保持了150 FPS的推理速度。项目首页地址为this https URL"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08334", "html_url": "https://arxiv.org/abs/2507.08334", "title": "CoCo-Bot：基于能量的可组合概念瓶颈结构以实现可解释生成模型", "title_en": "CoCo-Bot: Energy-based Composable Concept Bottlenecks for Interpretable Generative Models", "authors": "Sangwon Kim,In-su Jang,Pyongkun Kim,Kwang-Ju Kim", "background": "概念瓶颈模型(CBMs)通过概念通道进行生成，提供可解释性强且可控的生成模型。然而，先前的生成CBMs常常依赖于瓶颈处的辅助视觉提示来补充概念未捕捉的信息，这削弱了可解释性与组成性。", "innovation": "提出了CoCo-Bot，一种后嵌可组合的概念瓶颈生成模型，通过全程仅使用显式概念传输所有信息，消除辅助提示的需要。基于扩散能量函数指导，CoCo-Bot支持对任意概念进行稳健的后嵌干预，如概念组合和否定。", "conclusion": "在使用预训练于CelebA-HQ的StyleGAN2进行实验时，CoCo-Bot提升了概念层面的可控性和可解释性，同时保持了竞争力的视觉质量。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08343", "html_url": "https://arxiv.org/abs/2507.08343", "title": "向量感知的JPEG图像隐藏：多范围表征驱动的对抗性伪装生成", "title_en": "Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation", "authors": "Junxue Yang,Xin Liao,Weixuan Tang,Jianhua Yang,Zheng Qin", "background": "现有的基于深度学习的隐写算法因其大容量和单一范围（仅基于卷积或仅基于变换操作的特征提取）限制以及像素级损失约束，容易被探测器检测到。为了应对这一问题，本文引入生成对抗性攻击到彩色JPEG图像的隐写中，并从隐写分析的视角提出了一种新的多范围表征驱动的对抗性伪装生成框架（MRAG）", "innovation": "提出了多范围表征驱动的对抗性伪装生成框架（MRAG），结合卷积的局部范围邻居接受特性以及变换的全局范围依赖建模来构造MRAG。通过引入多粒度信息的变换图作为输入，改变现有的单一范围生成隐写信息的方式。进一步设计了一个特征角度-范数解耦损失，以确保生成的伪装图片在隐写分析仪分类特征的角度和范数空间中更接近于原始图片。从而可以在生成伪装图像的过程中注入细小而有效的对抗性扰动，保证伪装图像保持良好的秘密恢复性和不可感知性", "conclusion": "实验结果表明，MRAG能够实现最先进的性能"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08344", "html_url": "https://arxiv.org/abs/2507.08344", "title": "MM-Gesture：通过多模态融合实现精确的微手势识别", "title_en": "MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion", "authors": "Jihao Gu,Fei Wang,Kun Li,Yanyan Wei,Zhiliang Wu,Dan Guo", "background": "本文介绍了一种名为MM-Gesture的方法，这是由HFUT-VUT团队为第三届MiGA挑战赛微手势分类赛道开发的解决方案。MM-Gesture是专门为识别细微且短时间的手势（即微手势）设计的多模态融合框架，它融合了关节、肢体、RGB视频、Taylor级数视频、光流视频和深度视频等多种模态的互补信息。此前的研究通常是单一模态方法，MM-Gesture通过多模态融合实现了比之前最先进的方法更突出的性能。在iMiGUE基准测试上进行了大量实验，验证了这种方法的有效性，达到了73.213%的顶级准确性。", "innovation": "MM-Gesture框架融合多种模态的信息，采用了PoseConv3D和Video Swin Transformer架构，以及一种新颖的模态加权集成策略。通过从更大的MA-52数据集上进行转移学习，进一步提升了RGB模态的表现。", "conclusion": "文中提出的多模态融合框架MM-Gesture在第三届MiGA挑战赛微手势分类赛道中表现出卓越的性能，实验结果表明其在iMiGUE基准测试上的top-1准确率为73.213%，验证了该方法的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "单域重平衡器和分布纠缠器驱动的多模态跨癌种 prognosis 单域泛化", "title_en": "Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在多模态数据的生存预测中表现出显著的性能。然而，现有的多模态方法主要集中在单一癌症类型上，忽视了跨癌症场景中泛化的挑战。本文指出，在跨癌症场景中，多模态预后模型通常比单模态模型泛化效果更差，而在临床实践中对这种稳健性有着迫切的需求。鉴于此，作者提出了一个新的任务：基于单域多模态跨癌症泛化，评估在单一癌症类型上训练的模型能否泛化到未见过的癌症。研究表明，特征质量的衰退和多模态集成的无效性是主要挑战。", "innovation": "提出一种新的任务：跨癌症单域多模态预后单域泛化，旨在评估单一癌症类型数据训练的模型在未见过的癌症上的泛化能力。为此，作者引入了两个插件模块：稀疏狄拉克信息重平衡器（SDIR）和癌症意识分布纠缠（CADE）。SDIR通过基于伯努利的稀疏化和狄拉克启发的稳定化，减轻了强势特征的主导性，加强了较弱模态的信号。CADE则设计用于综合目标域分布，通过在潜在空间中融合局部形态学线索和全局基因表达实现多模态信息的融合。", "conclusion": "在四癌种基准数据集上的实验证明了这种泛化能力的优越性，为临床实用的跨癌症多模态预后奠定了基础。相关代码可在指定链接获取。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08380", "html_url": "https://arxiv.org/abs/2507.08380", "title": "从增强到理解：通过语义一致的无监督微调构建低光视见的通用桥梁", "title_en": "From Enhancement to Understanding: Build a Generalized Bridge for Low-light Vision via Semantically Consistent Unsupervised Fine-tuning", "authors": "Sen Wang,Shao Zeng,Tianjun Gu,Zhizhong Zhang,Ruixin Zhang,Shouhong Ding,Jingyun Zhang,Jun Wang,Xin Tan,Yuan Xie,Lizhuang Ma", "background": "低光增强和高级视觉理解在低光环境中通常分别处理。低光增强虽然改善了图像质量，但现有方法依赖于物理或几何先验，限制了泛化能力；而评价主要集中在视觉质量上，忽视了下游任务的表现。低光视觉理解受限于稀缺的标注数据，主要依赖于特定任务的领域适应，缺乏扩展性。针对这些挑战，研究构建了一个低光增强与低光理解之间的通用桥梁，称为Generalized Enhancement For Understanding (GEFU)。", "innovation": "利用预训练的生成性扩散模型优化图像，实现了零样本泛化性能；提出了语义一致的无监督微调（SCUF），克服文本提示限制，引入照明意识图像提示以明确引导图像生成，并提出循环注意力适配器以最大化其语义潜力；提出标题和反射性一致性以减轻无监督训练中的语义降级，学习高级语义和图像层次的空间语义。", "conclusion": "大量实验表明，本文提出的方法在传统图像质量和GEFU任务（包括分类、检测和语义分割）中均优于当前最先进的方法。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08165", "html_url": "https://arxiv.org/abs/2507.08165", "title": "借助单目深度估计的嵌入式实时物体警报系统——视觉障碍者的计算机视觉方法", "title_en": "An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision", "authors": "Jareen Anjom,Rashik Iram Chowdhury,Tarbia Hasan,Md. Ishan Arefin Hossain", "background": "在孟加拉国的城市中，视障人士面临着日常生活中的诸多出行难题，主要是由于道路上有大量的障碍物。频繁发生的道路交通事故导致了更多的安全问题。因此，需要一个系统在视障者接近障碍物之前提前发出警报。", "innovation": "本文提出了一种新的警报系统，通过计算机视觉技术，特别是单目深度估计和对象检测技术的结合，实现了嵌入式实时的物体检测与警报。系统利用迁移学习训练深度估计和物体检测模型，并结合优化技术使模型轻量化，以便部署在嵌入式系统上。", "conclusion": "所提出的解决方案实现了轻量级的实时深度估计和物体检测模型，该模型的mAP50达到了0.801，有效改善了视障者在繁忙街道上的通勤安全问题。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08205", "html_url": "https://arxiv.org/abs/2507.08205", "title": "HNOSeg-XS：高效且分辨率鲁棒的Hartley神经算子小模型用于3D图像分割", "title_en": "HNOSeg-XS: Extremely Small Hartley Neural Operator for Efficient and Resolution-Robust 3D Image Segmentation", "authors": "Ken C. L. Wong,Hongzhi Wang,Tanveer Syeda-Mahmood", "background": "在医学图像分割中，卷积神经网络（CNN）和变换器是主流技术。尽管CNN能够通过连续卷积和池化捕捉长范围的空间相关性，但由于计算成本和内存占用过高，3D模型只能比2D模型拥有更少的层和较小的接收野。对于变换器，虽然多头注意力机制可以捕捉到长范围的相关性，但其输入大小的二次复杂性使其在计算上非常耗费资源。因此，两种模型都可能需要减少输入尺寸，以便使用更多的滤波器和层来提高分割效果。然而，传统的方法（如基于块训练或图像下采样）训练的模型在高分辨率应用中可能会产生次优结果。本文即旨在探讨基于这一背景的分辨率鲁棒的HNOSeg-XS架构对于3D图像分割的问题改进", "innovation": "HNOSeg-XS架构使用傅里叶神经算子描述图像分割的可学习部分偏微分方程，并通过引入Hartley不变变换和频率域重写处理问题，实现了分辨率鲁棒、快速、内存和参数效率极高的特性。该架构通过每层小于34.7k的模型参数，在Tesla V100 GPU上实现了最优的推理时间和内存效率，相比测试的CNN和变压器模型表现优越", "conclusion": "HNOSeg-XS架构展示了在医学图像分割领域的潜力，尤其适用于高分辨率图像的处理。其低复杂度和高鲁棒性的特征使其在医学成像领域具有广泛的应用前景"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08096", "html_url": "https://arxiv.org/abs/2507.08096", "title": "单SAR图像基于对象的深度学习建筑高度估计方法", "title_en": "An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images", "authors": "Babak Memar,Luigi Russo,Silvia Liberata Ullo,Paolo Gamba", "background": "高分辨率合成孔径雷达（SAR）图像准确估计建筑物高度对于各种城市应用至关重要。本文介绍了一种基于深度学习（DL）的方法，用于自动从单张高分辨率COSMO-SkyMed SAR图像中估计建筑物高度：一种基于边界框检测的对象回归方法，随后进行高度估计。", "innovation": "该研究提出了一种基于对象的深度学习方法，通过单张高分辨率SAR图像自动估计建筑物高度。该方法利用边界框检测后进行高度估计，并在多大陆的城市数据集上进行了训练和评估，以显式评估分布外（OOD）泛化。", "conclusion": "该模型在欧洲城市表现出高度的性能，特别是在慕尼黑，平均绝对误差（MAE）约为一个建筑物楼层（2.20米），显著优于在类似OOD场景下的最新方法。尽管在其他大陆的城市（尤其是亚洲）中泛化时显示出更大的变异性，本研究强调了DL在建筑高度估计从单张高分辨率SAR数据中的潜在应用价值，特别是在跨城市和跨大陆的鲁棒迁移学习方面。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08367", "html_url": "https://arxiv.org/abs/2507.08367", "title": "使用大型语言模型理解驾驶风险：朝老年驾驶员评估方向", "title_en": "Understanding Driving Risks using Large Language Models: Toward Elderly Driver Assessment", "authors": "Yuki Yoshihara,Linjing Jiang,Nihan Karatas,Hitoshi Kanamori,Asuka Harada,Takahiro Tanaka", "background": "本文探讨了特定多模态大型语言模型（如ChatGPT-4o）在使用静态车载记录仪照片解释交通场景方面的人类化能力。研究集中在评估交通密度、判断交叉口视线和识别停车标志等三项与老年驾驶员评估相关的关键任务上。这些任务涉及情景推理，而非简单的对象检测。通过零示例、少示例和多示例提示策略评估模型性能，并以人类注释作为标准参照。评价指标包括精确度、召回率和F1分数。结果表明，提示设计对性能有显著影响，特别是在交叉口视线判断中的召回率从零示例的21.7%提升到多示例的57.0%，交通密度评估的一致性也从53.5%提升到67.6%。研究表明，尽管在停车标志检测中模型展示出了高精确度（高达86.3%），但由于保守反应倾向，召回率较低，约为76.7%。解释性分析发现，人类和模型在解读结构不明确的场景时都面临挑战，但模型的解释文本与其预测相符，提高了可解释性。已有研究结果表明，通过精心设计的提示，大型语言模型在驾驶场景风险评估中具有潜在支持作用。未来研究应通过使用更大数据集、多样化注释者和下一代模型架构来探索其可扩展性，以评估老年驾驶员安全。", "innovation": "本文创新性地利用大型语言模型的多模态能力，通过不同提示策略评估其在交通场景解释中的表现，并提出通过具体设计策略可以提升模型在老年驾驶员风险评估中的准确性与可靠性。此外，文中还探讨了模型的解释性与稳定性问题，强调了今后研究应重点考虑的方面。", "conclusion": "基于精心设计的提示，大型语言模型具有潜在的辅助作用，可用于老年驾驶员的驾驶风险评估。未来研究应探索更大数据集、不同注释者多样性和使用最新模型架构，进一步验证和完善该模型在老年驾驶风险评估中的表现。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08357", "html_url": "https://arxiv.org/abs/2507.08357", "title": "Cycle Context Verification for In-Context Medical Image Segmentation", "title_en": "Cycle Context Verification for In-Context Medical Image Segmentation", "authors": "Shishuai Hu,Zehui Liao,Liangli Zhen,Huazhu Fu,Yong Xia", "background": "在上下文学习（ICL）的背景下，它作为一种新兴的技术正在实现通用的医学图像分割，可以使用单一模型对来自不同成像模态的各种感兴趣物体进行分割。然而，其性能高度依赖于查询图像与上下文图像-掩码配对之间的对齐。在临床场景中，由于标记医学图像稀缺，选择最佳上下文配对变得具有挑战性。此外，使用上下文数据调整基础ICL模型由于计算成本和灾难性遗忘的风险而不可行。", "innovation": "我们提出了一种新颖的框架——循环上下文验证（CCV），通过使模型能够自我验证预测来增强基于ICL的医学图像分割，从而提高上下文对齐。CCV使用了一个循环管道，在管道中，模型首先生成查询图像的分割掩码，随后交换查询图像和上下文配对的角色，使模型能够通过预测原始上下文图像的掩码来验证其预测。查询特定的提示被引入以改变查询图像并更新以提高度量，从而增强查询与上下文配对之间的对齐。", "conclusion": "我们在七个医学图像分割数据集上使用两种基础ICL模型评估了CCV，结果显示其优于现有方法。我们的结果强调了CCV增强ICL分割的能力，使其成为通用医学图像分割的稳健解决方案。相关代码将在此: https://example.com 可用。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08375", "html_url": "https://arxiv.org/abs/2507.08375", "title": "无监督方法在视频质量提升中的研究：修复与增强技术综述", "title_en": "Unsupervised Methods for Video Quality Improvement: A Survey of Restoration and Enhancement Techniques", "authors": "Alexandra Malyugina,Yini Li,Joanne Lin,Nantheera Anantrasirichai", "background": "视频修复和增强对于提高视觉质量至关重要，同时也是许多计算机视觉下游任务性能提升的重要预处理步骤。本文综述了视频修复和增强技术，重点介绍了无监督方法，概述了视频降解及其原因，回顾了早期基于传统和深度学习的方法，并详细介绍了无监督方法的不同类别，包括域转换、自我监督信号设计和空白或噪声基方法。此外，还讨论了损失函数在无监督视频修复和增强中的应用，并解释了配对合成数据集在客观评估中的作用。", "innovation": "本文提供了一个系统的无监督视频修复与增强技术评述，特别强调了基于不同原则的无监督方法分类，以及损失函数的应用，并讨论了配对合成数据集在客观评估中的作用。", "conclusion": "本文指出了该领域面临的几个关键挑战，并提出了未来研究的有希望的方向。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08396", "html_url": "https://arxiv.org/abs/2507.08396", "title": "主体一致和姿态多变的文本到图像生成", "title_en": "Subject-Consistent and Pose-Diverse Text-to-Image Generation", "authors": "Zhanxin Gao,Beier Zhu,Liang Yao,Jian Yang,Ying Tai", "background": "文本到图像（T2I）模型在主体一致生成（Subject-consistent generation, SCG）方面面临挑战，即保持多个场景中主体身份的一致性，而现有的一些无需训练的SCG方法往往能够实现一致性，但牺牲了布局和姿态的多样性，从而导致视觉故事叙述的表达能力受限。", "innovation": "提出了一个名为CoDi的主体一致且姿态多变的T2I框架，采用两阶段策略：身份转运（Identity Transport, IT）和身份精细化（Identity Refinement, IR）。IT阶段在早期去噪步骤中使用最优传输在姿态感知的方式下将身份特征转移到每个目标图像，增强主体一致性并保持姿态多样性。IR阶段则在后期去噪步骤中选择最显著的身份特征进一步细化主体细节。实验证明CoDi在主体一致性、姿态多样性和命令忠诚度等方面均实现了更好的视觉感知和更强的性能。", "conclusion": "CoDi通过两阶段策略实现了主体一致性与姿态多样性的平衡，能够在保持整体一致性的同时，确保图像中的姿态多样性，同时能够在视觉感知和多个评价指标上均达到更好效果。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08384", "html_url": "https://arxiv.org/abs/2507.08384", "title": "气味弥漫，密集散布：嗅觉参照物体检测（ODOR）数据集", "title_en": "Smelly, dense, and spreaded: The Object Detection for Olfactory References (ODOR) dataset", "authors": "Mathias Zinnen,Prathmesh Madhu,Inger Leemans,Peter Bell,Azhar Hussian,Hang Tran,Ali Hürriyetoğlu,Andreas Maier,Vincent Christlein", "background": "计算机视觉在人文学科中的实际应用需要算法能够有效应对艺术抽象、边缘物体以及精细分类目标之间的细微差异。现有的数据集主要提供艺术品的实例级标注，但这些数据集通常偏向图像中心且对详细的物体类别有所限制。为了解决这个问题，研究者提出ODOR数据集，它提供了涵盖139个精细分类的38,116个物体级别的标注，共4712张图像。此外，还进行了统计分析，展示了数据集的挑战性特性，如详细的类别集、密集且重叠的物体以及整个图像画布上的空间分布。为了评估物体检测模型，还进行了广泛的基准测试，并通过一系列表征性研究展示了数据集的挑战性属性。", "innovation": "ODOR数据集在提供广泛的139个细分类别的物体标注方面填补了现有数据集的空白，涵盖了详细的物体类别，同时具有密集重叠的物体和整个图像画布上的分布特点，为研究艺术作品中的物体检测和更广泛的视觉文化遗产研究提供了挑战与机遇。", "conclusion": "该数据集不仅挑战研究者探索物体识别和嗅觉感知的交叉领域，还为艺术作品物体检测研究和更广泛的视觉文化遗产研究奠定了基础。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08416", "html_url": "https://arxiv.org/abs/2507.08416", "title": "InstaScene：从拥挤场景中实现完整的3D实例分解与重建", "title_en": "InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes", "authors": "Zesong Yang,Bangbang Yang,Wenqi Dong,Chenxuan Cao,Liyuan Cui,Yuewen Ma,Zhaopeng Cui,Hujun Bao", "background": "人类能够在拥挤的环境中自然地识别并构造被遮挡的对象，但即使使用先进的重建技术赋予机器人类似的认知能力仍然具有挑战性，因为现有技术将场景视为难以区分的整体，无法从部分观察中识别完整的对象。", "innovation": "提出了InstaScene，这是一种新的范式，旨在实现复杂场景的整体3D感知，主要目标是在确保完整重建的同时分解任意实例。通过开发一种新的空间对比学习方法，追踪每个实例在不同视角下的光栅化过程，显著增强了拥挤场景中的语义监督。引入现场生成来利用有价值的观察和几何线索，有效指导3D生成模型重建与现实世界无缝对接的完整实例。", "conclusion": "在复杂的真实世界和合成场景中的场景分解和物体完成实验表明，我们的方法在分解精度方面表现出色，生成的几何结构忠实且视觉上完整。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08404", "html_url": "https://arxiv.org/abs/2507.08404", "title": "使用语义哈希中心进行图像检索的深度哈希", "title_en": "Deep Hashing with Semantic Hash Centers for Image Retrieval", "authors": "Li Chen,Rui Liu,Yuxiang Zhou,Xudong Ma,Yong Chen,Dell Zhang", "background": "深度哈希是进行大规模图像检索的有效方法。现有方法通常根据监督类型分类为点式、对式和列表式。近年来的点式技术通过预先为每个类别分配一个哈希中心来提高检索性能，增强了各种数据集中的哈希码的区分能力。然而，这些方法依赖于与类别无关的算法生成哈希中心，这忽略了类别之间的语义关系，可能降低检索性能。", "innovation": "该研究提出了一种名为SHC（Semantic Hash Centers）的三阶段框架，引入了语义哈希中心的概念，旨在生成同时保持语义结构的哈希码。SHC框架首先通过依赖数据的相似性计算来开发分类网络，以识别类别之间的语义相似性；其次，通过优化算法生成语义哈希中心，确保语义相关性和中心之间的最小距离，从而避免过多相似的哈希码；最后，使用生成的语义中心训练深度哈希网络，将图像转换为二进制哈希码。实验结果表明，SHC在多个公开数据集的大规模检索任务中显著提升了检索性能。", "conclusion": "实验结果显示，SHC方法在MAP@100、MAP@1000和MAP@ALL指标上分别比最先进的方法提高了7.26%、7.62%和11.71%的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08400", "html_url": "https://arxiv.org/abs/2507.08400", "title": "PanMatch：大规模视觉模型在统一匹配模型中的潜力释放", "title_en": "PanMatch: Unleashing the Potential of Large Vision Models for Unified Matching Models", "authors": "Yongjian Zhang,Longguang Wang,Kunhong Li,Ye Zhang,Yun Wang,Liang Lin,Yulan Guo", "background": "本文介绍了泛匹配（PanMatch）模型，这是一种通用的基础模型，用于实现健壮的对应匹配。不同于以往依赖于特定任务的架构和特定领域的微调来支持立体匹配、光学流或特征匹配等任务的方法，本文的关键洞见在于任何两帧对应匹配任务都可以在一个二维位移估计框架下使用相同的模型权重来解决，从而避免了设计特定统一架构或任务特定集成模型的必要性。PanMatch通过赋予位移估计算法前所未有的泛化能力来实现多任务的统一。为了实现实现这一目标，该论文强调了适用于多个领域和任务的鲁棒特征提取器的重要性，并提出了利用大型视觉模型的所有用途特征来进行特征转换的管道，使匹配基线具有零样本跨视图匹配能力。", "innovation": "本文提出了泛匹配（PanMatch）模型，它采用通用的基础模型来解决任何两帧对应匹配任务，将对应匹配统一到一个二维位移估计框架下。该模型对位移估计算法进行了增强，赋予其前所未有的泛化能力，并通过特征转换管道利用大型视觉模型的通用特征来达到零样本跨视图匹配。本研究还构建了一个包含近180万个样本的跨领域数据集，用于预训练PanMatch模型，并展示了PanMatch在多个领域和下游任务上的一致性能。PanMatch在跨任务评估中优于UniMatch和Flow-Anything，并在特定任务评估基准上与大多数最先进的特定任务算法具有可比性能。此外，PanMatch在异常场景（如雨天和卫星图像）下实现了前所未有的零样本性能，而大多数现有的健壮算法在这些场景下无法产生有意义的结果。", "conclusion": "PanMatch通过利用大型视觉模型的通用特征，展示了在多种任务和领域中实现健壮对应匹配的强大性能。该模型不仅在任务特定评估中表现出色，还在异常条件下达到了前所未有的零样本性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08422", "html_url": "https://arxiv.org/abs/2507.08422", "title": "Upsample What Matters: Region-Adaptive Latent Sampling for Accelerated Diffusion Transformers", "title_en": "Upsample What Matters: Region-Adaptive Latent Sampling for Accelerated Diffusion Transformers", "authors": "Wongi Jeong,Kyungryeol Lee,Hoigi Seo,Se Young Chun", "background": "扩散变换器已经成为了高保真图像和视频生成的一种替代方案，尤其是在U-Net基于的扩散模型之外，它们提供了更好的可扩展性。然而，扩散变换器对于实际部署仍然是一个问题，主要归因于其沉重的计算成本。现有的加速方法主要集中在时间维度上，通过重用各扩散时间步的缓存特征来加速推理。", "innovation": "本文提出了一种无需训练的框架Region-Adaptive Latent Upsampling (RALU)，该方法可以在空间维度上加速推理。RALU通过三次采样阶段来混合分辨率：首先进行低分辨率的去噪，快速捕捉全局语义结构；第二步是对易出现伪像的特定区域进行区域适应回采；最后进行全分辨率下的所有层次采样，以提高细节精度。为了在不同分辨率转换时稳定生成结果，我们利用噪声音级再调度来根据不同分辨率适配噪声级别。研究结果显示，该方法可以显著减少计算成本，同时保持较高的图像质量，具体来说，在FLUX上达到7.0倍的加速，在稳定扩散3中达到3.0倍的加速，且无明显降质。此外，该方法可以与现有的时间维度加速方法（如缓存方法）互补，从而可以无缝集成以进一步减少推理延迟，而不影响生成质量。", "conclusion": "本研究提出了一种无需训练的Region-Adaptive Latent Upsampling (RALU)框架，可以在空间维度上加速扩散变换器的推理过程，同时保持图像质量。通过实验证明，该方法在保持高图像质量的同时可以实现显著的加速，特别是在全分辨率处理中表现出色，并且该方法具有良好的兼容性，可以与现有的加速技术结合使用以进一步优化性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08410", "html_url": "https://arxiv.org/abs/2507.08410", "title": "Vision-Language模型的多模态互指导条件提示学习", "title_en": "Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models", "authors": "Shijun Yang,Xiang Zhang,Wanqing Zhao,Hangzai Luo,Sheng Zhong,Jinye Peng,Jianping Fan", "background": "提示学习有助于Vision-Language模型(VLMs)快速适应各种下游任务，但存在两个主要挑战：第一，对未见过的实例类别嵌入分布建模不足，导致在新类别上的泛化能力不足；第二，当前方法主要在视觉和文本编码器的最终输出层进行跨模态对齐，这从根本上限制了模型保持与预训练多模态嵌入空间的一致性能力。", "innovation": "研究提出了一种名为MuGCP（多模态互指导条件提示学习）的新框架。MuGCP利用多模态大型语言模型（MLLMs）作为条件提示学习者，自适应生成包含丰富细粒度高级语义知识的语义条件提示（SCP），并通过引入注意互指导（AMG）模块促进视觉和语义信息的交互，生成视觉条件提示（VCP），以增强模型在多模态任务中的性能。此外，MuGCP还包括多提示融合（MPF）机制，用于整合SCP和VCP与上下文提示，确保不同提示之间的无缝协调，增强类嵌入和实例特定知识的建模能力。该方法在14个不同数据集上优于现有最先进的方法。", "conclusion": "MuGCP在多种不同数据集上优于现有的最先进的方法，展示了显著的性能提升。研究结果表明，通过引入多模态互指导机制，可以有效提升Vision-Language模型在多模态任务中的表现。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08441", "html_url": "https://arxiv.org/abs/2507.08441", "title": "视觉基础模型作为有效的自回归图像生成视觉分词器", "title_en": "Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation", "authors": "Anlin Zheng,Xin Wen,Xuanyang Zhang,Chuofan Ma,Tiancai Wang,Gang Yu,Xiangyu Zhang,Xiaojuan Qi", "background": "该论文利用预训练的视觉基础模型的强大表示能力，这些模型原本用于视觉理解，探索了直接在其上构建图像分词器的新方向。这一领域目前研究较少，但分词器对于构建高效、高质量的图像生成模型至关重要。论文引入了两个关键组件：区域自适应量化框架减少冗余，以及语义重构目标使分词器输出与基础模型表示保持一致，以保持语义保真度。", "innovation": "论文创新性地提出了一个名为VFMTok的图像分词器，采用冻结的视觉基础模型作为编码器，并引入了区域自适应量化框架和语义重构目标。这些创新显著提高了图像重构和生成质量，提升了令牌效率，并加速了自回归生成的速度。此外，该方法还能够在不需要去噪方法的情况下实现高分辨率的类条件合成。", "conclusion": "通过使用视觉基础模型作为图像分词器基础，VFMTok在ImageNet基准测试上实现了gFID为2.07的自回归图像生成，模型收敛速度提高了三倍，并能够在没有去噪方法的情况下生成高保真度的类条件图像合成。代码将公开发布，以促进社区的发展。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08458", "html_url": "https://arxiv.org/abs/2507.08458", "title": "文档蕴含结构化的记录：文档识别中的原理化归纳偏置设计", "title_en": "A document is worth a structured record: Principled inductive bias design for document recognition", "authors": "Benjamin Meyer,Lukas Tuggener,Sascha Hänzi,Daniel Schmid,Erdal Ayfer,Benjamin F. Grewe,Ahmed Abdulkadir,Thilo Stadelmann", "background": "许多文档类型利用固有的、约定俗成的结构来编码精确和结构化的信息，如工程图纸的约定。然而，最先进的方法将文档识别仅仅视为计算机视觉问题，忽视了文档类型特有的结构特性，导致依赖于次优的启发式后处理，使得许多不那么常见或更复杂的文档类型难以被现代文档识别系统识别。", "innovation": "我们提出了一种新的视角，将文档识别视为从文档到记录的转写任务。这暗示了一种自然的分组方式，基于文档内在结构的固有特性进行分组，相似的文档类型可以使用相似的方式来处理和学习。我们提出了一种方法，用于设计特定于结构的归纳偏置，以及相应的基础变压器架构，该架构可以针对不同的结构进行适应。我们通过逐步复杂的不同记录结构从单声道乐谱、形状图和简化工程图中展示了所发现的归纳偏置的有效性。通过集成不加限制的图结构的归纳偏置，我们训练了第一个成功地将工程图纸转写为他们固有链接信息的端到端模型。", "conclusion": "我们的方法适用于不那么了解的标准OCR、OMR等领域的文档类型的设计，并为我们指导未来文档基础模型的设计提供了指导。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08448", "html_url": "https://arxiv.org/abs/2507.08448", "title": "从 DUSt3R 到 VGGT 的前向3D重建综述", "title_en": "Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT", "authors": "Wei Zhang,Yihang Wu,Songhua Li,Wenjie Ma,Xin Ma,Qiang Li,Qi Wang", "background": "3D重建的目标是恢复场景的密集三维结构，是增强/虚拟现实、自动驾驶和机器人技术等众多应用的基础技术。传统的基于结构从运动（SfM）和多视图立体匹配（MVS）的流水线通过迭代优化可以实现高精度，但它们受限于复杂的流程、高昂的计算成本以及在无纹理区域等挑战性场景中的脆弱性。近年来，深度学习引发了3D重建范式的转变，新的模型家族，如DUSt3R，提出了前馈方法。这些模型采用统一的深度网络直接从一组未受约束的图像中一次性推断出摄像机姿势和密集几何结构。", "innovation": "这篇综述全面回顾了这一新兴领域，涵盖了这些前馈模型的技术框架，包括基于Transformer的对应模型、姿势和几何联合回归机制以及从双视图扩展到多视图的策略。此外，还对比了这种新范式与传统流水线和早期的学习方法（如MVSNet）的差异，提供了相关数据集和评估指标的概览，讨论了技术的应用前景，指出了模型精度和扩展性、处理动态场景等关键技术挑战和机遇。", "conclusion": "这篇综述总结了前馈3D重建技术的研究现状和发展趋势，强调了这一新范式相对于传统方法的优势，明确指出了未来的研究方向和挑战，有助于该领域深入的发展。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08434", "html_url": "https://arxiv.org/abs/2507.08434", "title": "RePaintGS: 参考引导的高斯碰撞法用于真实和视角一致的3D场景补全", "title_en": "RePaintGS: Reference-Guided Gaussian Splatting for Realistic and View-Consistent 3D Scene Inpainting", "authors": "Ji Hyun Seo,Byounhyun Yoo,Gerard Jounghyun Kim", "background": "随着神经辐射场等3D辐射场方法的出现，这些已经成为了合成逼真新视图的标志性3D表示形式。在实际应用中，人们研究了灵活的场景编辑技术，其中对象移除是一个代表性任务。然而，移除对象后暴露的被遮挡区域通常会导致不自然的效果。因此，研究采用了图像修复技术来替换这些区域，从而使这些区域呈现合理的图像内容，这项任务被称为3D场景修复。然而，图像修复方法为每个视图生成了一种可能的完成方式，导致多个视角之间的一致性问题。为了缓解这一问题，人们通常采用知觉线索以平滑的方式融合修复图像，但也可能因为细节损失而基本失效，尤其是在多个视角具有一致性知觉差异的情况下。目前研究提出了一种新方法，利用参考视图来确保复杂的场景在3D修复中真实且视觉上一致。该方法规定，给定修复的参考视图，估计其他视图的修复相似性，调整它们的贡献，以构建准确的几何结构并匹配参考视图的外观。", "innovation": "该论文提出了一种新颖的3D场景修复方法，称为RePaintGS，解决了传统方法在复杂场景下易出现细节损失和一致性问题。通过参考视图，该方法估计其他视图的修复相似性，然后使用这种几何结构将参考视图的修复结果扭曲到其他视图作为伪真实标签。这种方法可以用于优化过程中以匹配参考视图的外观，从而提高了修复场景的几何准确性和外观一致性。", "conclusion": "实验比较研究显示，该方法在复杂场景的3D修复中不仅提高了几何准确度，还改善了不同视角之间的真实和视觉一致性，表现出了实际应用的能力和有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08460", "html_url": "https://arxiv.org/abs/2507.08460", "title": "F3-Net：满足灵活输入模态要求的医学图像全异常分割基础模型", "title_en": "F3-Net: Foundation Model for Full Abnormality Segmentation of Medical Images with Flexible Input Modality Requirement", "authors": "Seyedeh Sahar Taheri Otaghsara,Reza Rahmanzadeh", "background": "临床医学图像分割面临依赖完整多模态输入、泛化能力有限和技术任务特定性狭隘的挑战。传统的模型在缺失MRI序列的情况下表现较差，需要根据特定疾病进行重新训练并依赖于具体的合成网络。", "innovation": "F3-Net 通过灵活的合成模态训练，能够在数据缺失时利用零图像策略代替缺失模态，无需依赖具体的合成网络，从而增强了其实用性。它的统一架构支持在胶质瘤、转移瘤、中风和白质病变等多种病理情况下的分割，无需重新训练，优于需要特定疾病微调的CNN和transformer基线模型。F3-Net 在多样化的数据集（如 BraTS 2021, BraTS 2024, ISLES 2022 ）上展示了较强的领域移位和临床异质性抗干扰能力。", "conclusion": "F3-Net 是一种跨病理的、表现优异的分割解决方案，可以连接深度学习研究与实际临床部署，实现广泛适用性和可扩展性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08494", "html_url": "https://arxiv.org/abs/2507.08494", "title": "使用图神经网络的统一人群跟踪", "title_en": "Unified People Tracking with Graph Neural Networks", "authors": "Martin Engilberge,Ivan Vrkic,Friedrich Wilke Grosche,Julien Pilet,Engin Turetken,Pascal Fua", "background": "当前的人群跟踪模型通常依赖于预先计算的轨道片段来建立个体间的关系，而这些关系的建立过程并不是完全可微的，限制了模型的学习效率和适应性。", "innovation": "本文提出了一种统一、全可微的人群跟踪模型，该模型可以在无需依赖预先计算的轨道片段的情况下，学习将检测结果关联成轨迹。模型构建了一个动态时空图，能够整合空间、上下文和时间信息，并允许在整个序列中无缝传播信息。为了更好地处理遮挡问题，该图还能编码特定场景的信息。", "conclusion": "实验表明，该模型在公共基准测试和新数据集上达到了最先进的性能，并且具有跨不同条件的灵活性。同时，该模型和新数据集将被公开发布，以促进人群跟踪研究的进步。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08492", "html_url": "https://arxiv.org/abs/2507.08492", "title": "基于双维度几何表示学习的文档纠偏", "title_en": "Dual Dimensions Geometric Representation Learning Based Document Dewarping", "authors": "Heng Li,Qingcai Chen,Xiangping Wu", "background": "文档图像纠偏仍然是深度学习时代的一项具有挑战性的任务。现有的方法通过利用文本行意识已经有所改进，但通常只关注水平方向的单一维度。现有方法在文档纠偏时，缺乏对不同方向的细节变形感知。因此，需要一个能够感知不同方向变形趋势的复杂模型，并且能够结合水平和垂直粒度特征，实现两个维度之间的互补性特征。由于当前公开的文档纠偏数据集中缺乏注释的线特征，研究团队开发了一种自动细粒度标注方法，利用公开的文档纹理图像和自动渲染引擎建立了一个新的大规模变形训练数据集。", "innovation": "本文提出了一种专注于文档水平-垂直线的细粒度变形感知模型，称为D2Dewarp。该模型能够跨文档细节感知不同方向的变形趋势，并通过基于XY坐标的有效融合模块，促进两个方向之间的交互和约束，实现特征互补。此外，还提出了一种自动细粒度标注方法和自动渲染引擎来构建一个大规模的变形训练数据集。该方法获得了优于现有最佳方法的公共中文和英文基准上的定量和定性结果。", "conclusion": "本研究提出了一种新型的双维度几何表示学习的方法，利用改进的模型和新的数据集，对文档图像纠偏取得了显著成果。该方法在公共基准测试中表现优异，并且开发的代码和数据集将公开发布，以促进进一步的研究和应用。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08520", "html_url": "https://arxiv.org/abs/2507.08520", "title": "通过强化知识蒸馏进行遮挡导向的特征净化学习在遮挡人体重识别中的应用", "title_en": "Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation for Occluded Person Re-Identification", "authors": "Yufei Zheng,Wenjun Wang,Wenjun Gan,Jiawei Liu", "background": "遮挡人的重识别旨在根据部分遮挡的图片检索完整的图片。现有方法通常依赖于对齐可见的身体部分、应用遮挡增强或使用完整图片补充缺失语义。但这些方法在处理训练过程中未见过的多样化遮挡场景和特征污染的问题上存在挑战。", "innovation": "提出了遮挡导向的特征净化学习通过强化知识蒸馏（OGFR），其特点在于同时减轻了这些挑战。OGFR采用教师-学生模型架构，有效融合了多样化的遮挡模式到特征表示中，同时借助强化知识蒸馏将净化的判别性完整知识从完整分支转移到被遮挡分支。具体设计了具有可学习遮挡模式嵌入的遮挡感知视觉转换器和特征擦除与净化模块，利用深度强化学习识别整体图片中低质量的补丁token以避免特征污染，并进一步挖掘与身份相关的判别性线索。", "conclusion": "通过知识蒸馏，学生分支能够有效吸收净化后的完整知识，实现不受遮挡干扰的鲁棒特征学习。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08548", "html_url": "https://arxiv.org/abs/2507.08548", "title": "SAM2RL:向Segment Anything Model 2中强化学习记忆控制的方向", "title_en": "SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2", "authors": "Alen Adamyan,Tomáš Čížek,Matej Straka,Klara Janouskova,Martin Schmid", "background": "Segment Anything Model 2（SAM 2）已经在物体分割任务中展示了出色的性能，并成为视觉物体跟踪的最新技术。模型通过在记忆库中存储前一帧的信息，实现了视频序列中的时空一致性。最近的方法通过手工创建的更新规则来增强SAM 2，以更好地处理干扰物、遮挡和物体运动。", "innovation": "本文提出了一种全新的方法，使用强化学习优化SAM 2中的记忆更新，将记忆控制视为一种 sequential decision-making问题。这种方法在过拟合设置中每段视频都使用一个独立的智能体，可以获得比现有启发式方法高出3倍以上的改进。", "conclusion": "研究结果揭示了记忆库的未发掘潜力，并强调强化学习是记忆控制的有力替代方法，特别是在视觉物体跟踪领域。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08574", "html_url": "https://arxiv.org/abs/2507.08574", "title": "基于3D空间-语言-视觉集成和双向互动注意机制的多模态融合框架在脑肿瘤分割中的应用", "title_en": "A Multi-Modal Fusion Framework for Brain Tumor Segmentation Based on 3D Spatial-Language-Vision Integration and Bidirectional Interactive Attention Mechanism", "authors": "Mingda Zhang,Kaiwen Pan", "background": "近年来，脑肿瘤分割是医学图像分析领域的一个重要研究方向。现有的分割方法大多依赖单一模态的数据（如MRI），并且在边界细化方面存在一定的局限性。本研究旨在通过引入多模态融合框架，结合空间、语言和视觉信息，采用双向交互注意力机制来提高分割准确性与边界定义的精准度。", "innovation": "该研究提出了一种新型的多模态融合框架，该框架通过双向交互注意力机制整合了空间、语言和视觉信息。具体来说，包含两个核心组件：多模态语义融合适配器（MSFA），它通过分层语义解耦将3D MRI数据与临床文本描述结合起来；双向交互视觉-语义注意力（BIVA），则促进不同模态之间的信息交换。这些创新使得该方法在脑肿瘤分割中表现优异，优于现有技术，特别是在分割准确性和边界定义方面。", "conclusion": "多模态语义融合结合双向交互注意机制显著提高了脑肿瘤分割的性能，建立了将临床知识集成到医学图像分析的新范式。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08554", "html_url": "https://arxiv.org/abs/2507.08554", "title": "带有核预测网络的图像翻译方法在语义分割中的应用", "title_en": "Image Translation with Kernel Prediction Networks for Semantic Segmentation", "authors": "Cristina Mata,Michael S. Ryoo,Henrik Turbell", "background": "语义分割依赖于大量密集的像素级注释以实现最佳性能，但由于在真实世界数据上获得精确注释的难度较大，从业者通常使用大规模合成数据集进行训练。目前，无配对图像翻译方法通过生成更多现实训练数据来解决由此产生的领域差异问题。现有方法通过生成对抗网络（GAN）进行翻译，并通过循环一致性强制执行像素级别的语义匹配。然而，这些方法并不能保证语义匹配，对于语义分割来说，这可能由于嘈杂的像素标签而影响性能。", "innovation": "提出了一种新颖的图像翻译方法，即域对抗核预测网络（DA-KPN），该方法保证合成标签和翻译之间的语义匹配。DA-KPN 预测轻量级且简单的翻译函数的像素级输入转换参数。为确保像素级的转换现实，DA-KPN 使用多尺度判别器来区分翻译样本和目标样本。实验表明，DA-KPN 在有限的现实图像标签访问权限下，优于基于 GAN 的方法，并且在面部解析任务上达到了相当的性能。", "conclusion": "DA-KPN 在 syn2real 语义分割基准上表现优异，并且在面部解析任务上表现出与以往方法相当的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08546", "html_url": "https://arxiv.org/abs/2507.08546", "title": "RadiomicsRetrieval：一种基于影像特征的可定制医学图像检索框架", "title_en": "RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features", "authors": "Inye Na,Nejung Rue,Jiwon Chung,Hyunjin Park", "background": "医学图像检索在支持临床决策方面是一个有价值的领域，但现有方法主要支持2D图像，并要求完全标注的查询，这限制了临床灵活性。现有的方法大多局限于二维图像，无法充分利用三维图像的体积数据和空间上下文信息，导致临床查询的灵活性较低。因此，需要一种能充分利用三维图像特性的检索框架，以更好地支持临床决策过程。", "innovation": "提出了一种名为RadiomicsRetrieval的3D内容基础上检索框架，通过结合手工程度的影像组学描述符和基于深度学习的肿瘤级嵌入，能够充分利用体积数据的空间上下文。该框架创新点包括：使用可提示的分割模型（如SAM）为肿瘤生成特定图像嵌入，并通过对比学习与影像组学特征对齐；利用解剖位置嵌入（APE）进一步丰富表示；用户仅需少量提示（如单一标记点），简化了分割过程并支持多样化的临床场景；检索系统不仅可以查询图像嵌入，也可以利用选定的影像组学属性，从而增强了系统的适应性，适用于大规模医学影像库的研究、诊断和治疗规划。", "conclusion": "通过在肺部CT和脑部MRI公共数据集上的大量实验表明，影像组学特征显著提高了检索的精确性，而解剖位置嵌入则为基于位置的搜索提供了关键的全局解剖上下文。该框架仅需少量用户提示，能够最大限度地减少分割成本，支持多种临床应用场景。其潜在的应用场景包括诊断、治疗计划以及大规模医学影像库的研究。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08607", "html_url": "https://arxiv.org/abs/2507.08607", "title": "BayesTTA：通过高斯判别分析进行视觉语言模型的持续时间适配", "title_en": "BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis", "authors": "Shuang Cui,Jinglin Xu,Yi Li,Xiongxin Tang,Jiangmeng Li,Jiahuan Zhou,Fanjiang Xu,Fuchun Sun,Hui Xiong", "background": "现有视觉语言模型（如CLIP）在零样本识别方面表现出色，但在真实世界场景中常见的时间演变分布转移（如逐渐光线变化或季节性变化）下性能显著下降。现有的持续测试时适应（CTTA）方法通常针对突发且严重的分布转移，忽视时间连续性，导致如下三个主要缺陷：有限的记忆缓存限制了长期分布建模，引起灾难性遗忘；在时间漂移下基于熵的置信度变得不可靠，加剧了错误累积；静态的视觉表示与不断变化的输入不相匹配。", "innovation": "本文提出了BayesTTA，一个贝叶斯适应框架，它确保了预测的时序一致性并动态对齐视觉表示。BayesTTA通过增量估计类别条件高斯混合分布来避免存储原始数据，通过统计假设检验自适应选择协方差结构，并使用高斯判别分析（GDA）进行校准推断。校准的预测监督了归一化层的自我引导适应，确保了高效的稳定表示对齐。实验表明BayesTTA在多个时间演变的数据集上优于现有最佳方法，同时保持了高效性。代码可以在提供的链接处访问。", "conclusion": "BayesTTA在广泛的时间演变测试时适应基准测试中表现出色，有效地解决了持续时间适应问题，提供了高效的准确稳定表示对齐。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08648", "html_url": "https://arxiv.org/abs/2507.08648", "title": "DatasetAgent：一种基于多agent的新型系统从真实图像自动生成数据集", "title_en": "DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images", "authors": "Haoran Sun,Haoyu Bian,Shaoning Zeng,Yunbo Rao,Xu Xu,Lin Mei,Jianping Gou", "background": "传统图像数据集构建过程依赖于费时低效的手动收集和标注方法。大型模型提供了通过数据生成来解决的方法。然而，现实世界的实际数据相较于人工智能生成的数据更加珍贵，特别是在构建图像数据集时。因此，本文提出了一种名为DatasetAgent的新方法，通过多agent协作系统自动生成以用户指定要求为基础的高质图像数据集。", "innovation": "本文通过引入一种基于多agent协作系统的新型方法DatasetAgent，协调包括多模态大型语言模型（MLLMs）和图像优化工具包在内四种不同类型的agent，能够在用户指定的需求下自动构建高质量图像数据集。这种方法在多种开源数据集上进行了验证，无论是扩展已有数据集还是从零开始创建新数据集。", "conclusion": "通过DatasetAgent，可以高效地、高质量地生成多种图像数据集，用于多种视觉模型的训练，包括图像分类、物体检测和图像分割任务。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08636", "html_url": "https://arxiv.org/abs/2507.08636", "title": "规范化注释 vs 外交注释：乌拉圭出生证明手写文档自动信息提取的案例研究", "title_en": "Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates", "authors": "Natalia Bottaioli(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France, Facultad de Ingeniería, Universidad de la República, Montevideo, Uruguay, Digital Sense, Montevideo, Uruguay)Solène Tarride(TEKLIA, Paris, France)Jérémy Anger(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Seginus Mowlavi(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Marina Gardella(IMPA, Rio de Janeiro, Brazil)Antoine Tadros(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Gabriele Facciolo(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Rafael Grompone von Gioi(Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France)Christopher Kermorvant(TEKLIA, Paris, France)Jean-Michel Morel(City University of Hong Kong, Hong Kong)Javier Preciozzi(Facultad de Ingeniería, Universidad de la República, Montevideo, Uruguay, Digital Sense, Montevideo, Uruguay)", "background": "本文研究了最近提出的文档注意网络（DAN）模型在从乌拉圭出生证明中提取关键值信息的应用效果，这些出生证明是用西班牙语手写的。研究者调查了两种自动转录方法，通过最小化训练数据和注释工作，对DAN进行微调。研究在包含相同图像（超过15位不同书写者的20份出生证书扫描件）但使用不同注释方法的两个数据集上进行了实验。", "innovation": "研究提出了一种使用DAN模型来提取手写认证文档中的关键值信息的方法，并通过两种不同的注释策略进行实验，即标准注释和外交注释，后者在非标准化的姓名和姓氏等字段上表现更佳，而前者在可以标准化的日期和出生地等字段上效果更好。研究的不同之处在于采用了最小化训练数据和注释工作量的方法对其进行微调，从而提升了模型的实用性和泛化能力", "conclusion": "研究发现，对于可以标准化的字段，如日期和出生地，规范化注释更有效；而对于不能标准化的姓名和姓氏等字段，外交注释表现更好。整体上，该研究展示了通过优化训练方法和注释策略，DAN模型能够在手写认证文档中更准确地提取关键信息。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08644", "html_url": "https://arxiv.org/abs/2507.08644", "title": "OnlineBEV: 在多摄像机3D感知中鸟瞰图表示的递归时间融合", "title_en": "OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception", "authors": "Junho Koh,Youngwoo Lee,Jungho Kim,Dongyoung Lee,Jun Won Choi", "background": "多视角相机基于鸟瞰视角（BEV）特征进行3D感知，这些特征通过视角视图到BEV的转换获得。已有研究表明，将来自多个摄像机帧的连续BEV特征结合使用可以进一步提高3D感知方法的性能。然而，在补偿自主代理的自身运动后，结合大量图像帧的时间聚合性能提升有限，这主要是由于目标运动引起的BEV特征随时间的动态变化导致的限制。", "innovation": "提出了一种新颖的时间3D感知方法OnlineBEV，该方法通过递归结构结合了时间上的BEV特征，并以最小的内存使用增加有效组合的特征数量。此外， OnlineBEV 使用了运动引导的BEV融合网络（MBFNet）来实现时间特征的对齐，同时使用时间一致性学习损失来显式地强制特征的一致性和对齐。", "conclusion": "在nuScenes基准测试上进行的实验表明，与现有最佳方法SOLOFusion相比，OnlineBEV在nuScenes测试集上取得了显著的性能提升，达到了63.9%的NDS，这在仅使用摄像机的3D目标检测任务中达到了最先进的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08555", "html_url": "https://arxiv.org/abs/2507.08555", "title": "分离实例和场景上下文以实现3D语义场景补全", "title_en": "Disentangling Instance and Scene Contexts for 3D Semantic Scene Completion", "authors": "Enyu Liu,En Yu,Sijia Chen,Wenbing Tao", "background": "3D语义场景补全（SSC）由于在3D感知中的重要性越来越受到关注。最近的研究主要集中在细化体素级别的特征以构建3D场景，但这种方法局限于将体素作为基本交互单元，从而限制了利用类级别信息，证明这对于提高补全结果的精细度至关重要。因此，作者提出了一种新的双流范式DISC（分离实例和场景上下文），通过分离优化来提升实例和场景类别学习，引入了具有类特定几何和语义先验的辨别类查询，并利用类的固有属性设计了专门的解码模块，以促进目标交互和高效类级别信息流传递。", "innovation": "DISC通过引入辨别类查询，以类特定的几何和语义先验取代体素查询，设计了专门的解码模块，利用类的固有属性，从而实现实例和场景类别的分离学习与交互优化。实验结果表明，DISC在SemanticKITTI和SSCBench-KITTI-360基准上均取得了SOTA性能，特别是仅使用单帧输入即可超越多帧SOTA方法，提升实例类别的表现，分别超过单帧和多帧SOTA mIoU 17.9%和11.9%。", "conclusion": "实验结果显示，DISC在SemanticKITTI和SSCBench-KITTI-360基准上均达到了SOTA性能，mIoU得分为17.35和20.55。DISC不仅在单帧输入的基础上超越了多帧的SOTA方法，还在实例类别性能上取得了显著提升，特别是在SemanticKITTI隐藏测试上，mIoU提高了17.9%。作者提供代码链接可以用作进一步的研究参考。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08679", "html_url": "https://arxiv.org/abs/2507.08679", "title": "ByDeWay：以训练-free 方式增强多模态 LLM 的深度提示", "title_en": "ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way", "authors": "Rajarshi Roy,Devleena Das,Ankesh Banerjee,Arjya Bhattacharjee,Kousik Dasgupta,Subarna Tripathi", "background": "近年来，多模态大语言模型（MLLMs）因其强大的语言理解和生成能力受到广泛关注。然而，它们在处理需要空间推理和视觉语义关联的任务时仍然存在不足，比如生成的响应可能不够真实或存在幻觉。", "innovation": "ByDeWay 提出了一个新的无训练框架，采用了一种新颖的提示策略——层深厚度基提示（LDP），无需修改模型参数即可提升 MLLMs 的性能。该方法利用单目深度估计将场景分割成最接近、中等距离和最远距离三个层次，然后使用视觉-语言模型生成具有相关性的区域特定描述。这些结构化的、深度意识的描述被附加到图像-问题提示中，增加了空间上下文，从而引导 MLLMs 生成更加真实的响应。方法轻量级、模块化，并且兼容黑盒 MLLMs。", "conclusion": "通过在 hallucination-sensitive（POPE）和 reasoning-intensive（GQA）基准测试上的一致改进，证实了无训练环境中深度意识提示的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08655", "html_url": "https://arxiv.org/abs/2507.08655", "title": "基于高效变压器模型从1.5T和3T T1 MRI合成通用7T T1图谱", "title_en": "Generalizable 7T T1-map Synthesis from 1.5T and 3T T1 MRI with an Efficient Transformer Model", "authors": "Zach Eidex,Mojtaba Safari,Tonghe Wang,Vanessa Wildman,David S. Yu,Hui Mao,Erik Middlebrooks,Aparna Kesewala,Xiaofeng Yang", "background": "超高的7T MRI在分辨率和对比度方面优于标准的1.5T或3T磁场强度的临床MRI。然而，7T MRI扫描仪昂贵且稀缺，同时还引入了额外的挑战，如磁敏感伪影。研究者提出了一种基于高效变压器的模型（7T-Restormer），可以通过常规的1.5T或3T T1加权回波恢复（T1W）图像来合成7T质量的T1图谱，以克服这一局限性.", "innovation": "7T-Restormer模型仅使用10.5M的参数，在似然峰值信噪比（PSNR）、结构相似性（SSIM）和归一化均方误差（NMSE）方面优于具有56.7M和70.4M参数的ResShift和ResViT模型，这使得7T MRI在标准临床工作流程中的应用更加便捷和高效。混合应用1.5T和3T数据集的训练策略优于单一领域策略，这种模型在1.5T和3T T1W MRI输入时都能获得更好的性能，表现出了色域的广泛适用性.", "conclusion": "研究开发了一种新颖的方法，能够在1.5T和3T T1W扫描图像中预测高质量的7T MP2RAGE图谱，超越了现有的先进方法。该方法使得7T MRI的优势能在标准临床工作流程中得到更广泛的使用，提高了MRI诊断的效率和准确性."}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08690", "html_url": "https://arxiv.org/abs/2507.08690", "title": "基于关键点跟踪的MRI扫描肌肉分割和3D重建高效方法", "title_en": "An Efficient Approach for Muscle Segmentation and 3D Reconstruction Using Keypoint Tracking in MRI Scan", "authors": "Mengyuan Liu,Jeongkyu Lee", "background": "磁共振成像（MRI）能够实现非侵入性、高分辨率的肌肉结构分析。然而，自动分割仍然受到高计算成本、依赖大规模训练数据集和对小肌肉分割准确性较低的限制。基于卷积神经网络（CNN）的方法虽然强大，但在计算开销、普适性和解释性方面存在不足。", "innovation": "研究提出了一种无需训练的关键点跟踪分割方法，结合关键点选择与Lucas-Kanade光流技术。该方法实现的Dice相似系数平均值在0.6到0.7之间，与最先进的CNN模型性能相当，但显著降低了计算需求并增强了可解释性。这一可扩展框架为临床和研究应用提供了稳健且可解释的肌肉分割替代方案。", "conclusion": "该研究提出了一种基于关键点跟踪的无训练肌肉分割方法，与最先进的CNN模型相比，该方法在计算需求上显著降低且增强了解释性，为临床和研究应用提供了更加稳健和可解释的肌肉分割方案。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08710", "html_url": "https://arxiv.org/abs/2507.08710", "title": "L-CLIPScore：一种轻量级嵌入式语图描述评价与训练指标", "title_en": "L-CLIPScore: a Lightweight Embedding-based Captioning Metric for Evaluating and Training", "authors": "Li Li,Yingzhe Peng,Xu Yang,Ruoxi Cheng,Haiyang Xu,Ming Yan,Fei Huang", "background": "近年来，对于语图描述的质量评估以及模型训练的需求日益增加，但是现有的方法往往效率低下，计算资源需求大。因此，研究一种高效且资源消耗小的方法来评价和训练语图描述模型是非常必要的。", "innovation": "本文提出了一种新的基于嵌入的语图描述评价指标——L-CLIPScore。L-CLIPScore基于一个轻量级的用于产生双向编码架构的压缩版本CLIP（L-CLIP），并使用了权重共享和矩阵分解方法减少参数量，同时通过设计一种称为多模态相似性调节器（SR）的损耗函数来转移更多语图对齐知识，使L-CLIP在保持与原始CLIP相似的多模态对齐能力的同时，具有更低的计算资源需求和更短的运行时间。", "conclusion": "本文通过广泛实验验证了L-CLIPScore在评价语图描述质量上的高效性和有效性，并发现当使用L-CLIPScore作为模型训练监督者时，应结合n-gram基指标使用，若单独使用L-CLIPScore会造成训练失败。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08683", "html_url": "https://arxiv.org/abs/2507.08683", "title": "MoSAiC: 遥感中的多模态多标签监督感知对比学习", "title_en": "MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing", "authors": "Debashis Gupta,Aditi Golder,Rongkhun Zhu,Kangning Cui,Wei Tang,Fan Yang,Ovidiu Csillik,Sarra Alaqahtani,V. Paul Pauca", "background": "对比学习已经作为无须大规模标注数据的一个强有力范式，用于学习迁移性表示。这一能力使其在计算机视觉任务中取得了最先进的成果。对比学习在地球系统观测（ESO）方面具有明显优势，因为多样的卫星模态（如光学和SAR影像）提供了自然对齐的地理区域视图。然而，ESO面临独特挑战，包括高跨类相似性、场景杂乱和边界模糊，这在图谱相似且空间复杂的类别中使表示学习更加复杂，尤其是在低标签和多标签的设置中。现有的对比学习框架通常专注于同一模态内的自我监督或缺乏跨模态多标签对齐与语义精度的机制。", "innovation": "我们提出了MoSAiC，这是一种统一框架，它通过多标签监督对比损失联合优化跨模态和同一模态的对比学习。MoSAiC特别设计用于多模态的卫星图像，它使语义特征分离更加精细，并在图谱相似和空间复杂的类别中实现了更稳健的表示学习。在两个基准数据集BigEarthNet V2.0和Sent12MS上的实验表明，MoSAiC在低标签和高类别重叠场景中的一致性和簇共融性上均优于完全监督和自我监督的基线。", "conclusion": "MoSAiC在低标签和高类别重叠场景中表现出色，一而在BigEarthNet V2.0和Sent12MS两个基准数据集上超越了完全监督和自我监督的基线模型，在准确性和簇共融性方面都有显著提升。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08735", "html_url": "https://arxiv.org/abs/2507.08735", "title": "弱光谱全变差学习器集合：一项PET-CT案例研究", "title_en": "Ensemble of Weak Spectral Total Variation Learners: a PET-CT Case Study", "authors": "Anna Rosenberg,John Kennedy,Zohar Keidar,Yehoshua Y. Zeevi,Guy Gilboa", "background": "在计算机视觉问题中，一个常见的挑战是没有足够的训练数据。为缓解这一问题，本文提出了一种基于光谱全变差（Spectral Total Variation, STV）特征的弱学习器集合。STV特征与全变差子梯度的非线性特征函数相关，能很好地刻画不同尺度下的纹理。已有研究表明，一维情况下生成正交特征，二维情况下特征之间相关性较低，而弱学习器集合论支持使用低相关性的弱学习器。", "innovation": "本文通过利用STV特征构建弱学习器集合，提出了一种新的机器学习方法。这种方法特别适用于医疗影像学中的问题，如通过CT数据预测PET数据中的高摄取情况。", "conclusion": "通过案例研究——比较CT数据与PET数据中的骨骼转移可能性，本文的方法显示出了优越的性能（AUC=0.87），优于深度学习方法（AUC=0.75）和Radiomics特征（AUC=0.79）。实验还发现，CT图像中的细小STV尺度特征特别有助于预测PET中的高摄取情况。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08711", "html_url": "https://arxiv.org/abs/2507.08711", "title": "SGPMIL: 稀疏高斯过程多重实例学习", "title_en": "SGPMIL: Sparse Gaussian Process Multiple Instance Learning", "authors": "Andreas Lolos,Stergios Christodoulidis,Maria Vakalopoulou,Jose Dolz,Aris Moustakas", "background": "多重实例学习（MIL）在只提供粗粒度袋级标签且无法访问实例级注解的情况下提供了自然的解决方案。这在数字病理学中尤为常见，数字病理学涉及巨像素级的图像。尽管确定性注意力机制的MIL方法在袋级性能上表现出色，但它们往往忽略了实例相关性的内在不确定性。因此，该论文旨在通过引入基于稀疏高斯过程（Sparse Gaussian Processes，SGP）的新概率注意力MIL框架（SGPMIL），来解决实例级注意力分数中的不确定性量化问题。SGPMIL通过学习注意力分数的后验分布来实现原理上的不确定估计，从而生成更可靠和校准的实例相关性图。本方法不仅保持了竞争力的袋级性能，还在不确定性下显著提高了实例级预测的质量和可解释性。", "innovation": "SGPMIL通过引入稀疏高斯过程(SGP)的特征缩放在预测均值函数中的做法，实现了更快的训练、更高的效率和提升的实例级性能。该方法通过学习注意力分数的后验分布，能够进行原理上的不确定估计，从而生成更可靠和校准的实例相关性图，不仅保持了竞争力的袋级性能，还在不确定性下显著提高了实例级预测的质量和可解释性。此外，该方法通过在稀疏高斯过程的预测均值函数中引入特征缩放，实现了更快的训练、更高的效率和提升的实例级性能。", "conclusion": "对多个已建立的数字病理学数据集的广泛实验证明，该方法在袋级和实例级评估中都具有显著效果。更多细节和代码将被公开提供。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08741", "html_url": "https://arxiv.org/abs/2507.08741", "title": "HieraRS: 一种用于遥感的分层次分割范式，实现多粒度解释和跨域转移", "title_en": "HieraRS: A Hierarchical Segmentation Paradigm for Remote Sensing Enabling Multi-Granularity Interpretation and Cross-Domain Transfer", "authors": "Tianlong Ai,Tianzhu Liu,Haochen Jiang,Yanfeng Gu", "background": "分层次的土地覆盖和土地利用（LCLU）分类旨在赋予遥感（RS）图像像素级别标签，具有多种语义粒度层次。然而，现有的深度学习方法面临两大挑战：1）它们主要采用平面分类范式，限制了它们产生与实际使用的树形结构层次一致的端到端多粒度层级预测的能力。2）大多数跨域研究集中在由传感器或场景变化引起的性能下降问题上，对如何在具有异构层次结构的任务中（如LCLU到作物分类）传输LCLU模型关注度不足。这些问题限制了LCLU模型在实际应用中的灵活性和通用性。", "innovation": "提出了一种新颖的分层次解释范式HieraRS，能够实现多粒度预测并支持LCLU模型的有效跨域传输，对应不同的树形结构层次。引入了双向分层次一致性约束机制（BHCCM），可以无缝集成到主流的平面分类模型中，生成分层级预测，同时提高语义一致性与分类精度。此外，提出了跨域知识共享（CDKS）与跨域语义对齐（CDSA）双重分支的跨域传输框架TransLU。构建了MM-5B大规模多模态分层级土地利用数据集，包含像素级别的标注数据，并提供代码与数据集下载链接。", "conclusion": "HieraRS不仅解决了LCLU分类中的平面解析与分层级预测的难点，还通过跨域知识转移机制有效地应对了异构层次结构下的跨域任务。通过构建大规模多模态数据集MM-5B，HieraRS框架展示了在实际应用中的潜力，并促进了LCLU分类的研究与应用。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08729", "html_url": "https://arxiv.org/abs/2507.08729", "title": "RoundaboutHD: 高分辨率的城市环境基准数据集用于多相机车辆跟踪", "title_en": "RoundaboutHD: High-Resolution Real-World Urban Environment Benchmark for Multi-Camera Vehicle Tracking", "authors": "Yuqiang Lin,Sam Lockyer,Mingxuan Sui,Li Gan,Florian Stanek,Markus Zarbock,Wenbin Li,Adrian Evans,Nic Zhang", "background": "当前公开可用的多相机车辆跟踪（MCVT）数据集存在不足，如场景过于简单、分辨率低和多样性不足等问题，导致学术研究与实际应用场景之间有较大差距。因此，需要新的数据集来填补这一空白，以便更准确地模拟真实场景下的环形交叉口情况，提供高分辨率的视频数据，以及更丰富且具有挑战性的车辆跨相机关联信息，包括增加的遮挡和非线性运动。", "innovation": "RoundaboutHD是一个针对实际环形交叉口场景设计的综合、高分辨率多相机车辆跟踪基准数据集。它提供了40分钟的多视角标注视频，并包含512个独特的车辆身份，以及实时一致的视频和增强的挑战。此外，它还提供了一系列子集用于目标检测、单相机跟踪和基于图像的车辆重识别任务，同时包含了车辆模型信息和相机建模/几何信息，以支持进一步分析。", "conclusion": "通过提供多相机车辆跟踪的基准结果与开源代码，RoundaboutHD旨在促进这一领域内的研究，并推动学术研究更好地适应实际应用。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08765", "html_url": "https://arxiv.org/abs/2507.08765", "title": "Compress Any Segment Anything Model (SAM)", "title_en": "Compress Any Segment Anything Model (SAM)", "authors": "Juntong Fan,Zhiwei Hao,Jianqiang Shen,Shang-Ling Jui,Yi Zhang,Jing-Xiao Liao,Feng-Lei Fan", "background": "Segment Anything Model (SAM) 和其变体由于在零样本分割方面表现出色，已被广泛应用于医疗保健、智能制造等场景。因此，有效压缩 SAMs 成为一个紧迫的实践需求。", "innovation": "本文提出 Birkhoff，一种适用于 SAM 及其变体的新颖无数据压缩算法。Birkhoff 引入了 Hyper-Compression 新压缩算法，通过找到高维参数向量到低维标量的密集轨迹来压缩模型。此外，Birkhoff 设计了 HyperLinear 这种耦合解压缩和矩阵乘法的专用线性层操作，显著加速压缩 SAMs 的推理过程。实验表明，Birkhoff 在压缩时间、压缩比、压缩后的性能和推理速度方面表现出色，例如，Birkhoff 对 SAM2-B 的压缩比为 5.17 倍，性能损失小于 1%，且在没有任何微调数据的情况下完成。", "conclusion": "Birkhoff 作为一种新颖的无数据压缩算法，在保持模型性能的同时显著减少了模型大小，具有广泛的适用性和快速的部署能力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08776", "html_url": "https://arxiv.org/abs/2507.08776", "title": "CLiFT：用于计算高效和适应性神经渲染的压缩光线场令牌", "title_en": "CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering", "authors": "Zhengqing Wang,Yuefan Wu,Jiacheng Chen,Fuyang Zhang,Yasutaka Furukawa", "background": "现有的神经渲染技术通常要求大量的存储和计算资源来高效渲染场景的各种视图，尤其是在处理高复杂度的场景时。这些渲染方法需要存储视图和网络权重，并通常以固定的频率使用这些资源，这限制了其在资源受限环境中应用的潜力。", "innovation": "该论文提出了一种采用压缩光线场令牌（CLiFTs）的神经渲染方法。CLiFTs通过压缩令牌保留场景的丰富外观和几何信息，从而实现高效的计算渲染。与现有的方法不同，CLiFTs启用了一个训练好的网络来动态调整表示场景或生成新视图的令牌数量。这种方法利用多视角编码器对图像进行令牌化，利用隐空间K均值聚类来选择光束中心点，并通过多视角‘浓缩器’压缩所有令牌的信息以构建CLiFTs。在测试时，给定目标视图和计算预算，系统收集一批附近令牌并使用适应计算能力的渲染器生成新视图。", "conclusion": "通过在真实房地产10K和DL3DV数据集上的广泛实验，该研究验证了CLiFTs方法的有效性。与现有方法相比，CLiFTs能够显著减少数据量并保持高质量的渲染结果，同时为数据量、渲染质量和渲染速度提供了良好的权衡。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08743", "html_url": "https://arxiv.org/abs/2507.08743", "title": "Geo-ORBIT: 基于联邦学习的场景自适应车道几何检测数字孪生框架", "title_en": "Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection", "authors": "Rei Tamaru,Pei Li,Bin Ran", "background": "数字孪生（DT）有潜力通过创建交通系统动态的虚拟表示来改善交通管理与运营。然而，现有的方法往往依赖于静态地图或昂贵的传感器，这限制了数字孪生的可扩展性和适应性。大规模的数字孪生从多个来源收集和分析数据，面临着隐私、通信和计算效率的挑战。 Geo-ORBIT框架结合了实时车道检测、数字孪生同步和联邦元学习来应对这些挑战。GeoLane模型使用路边摄像头从车辆轨迹数据中学习车道几何，并通过扩展的Meta-GeoLane模型实现个性化检测参数，同时利用FedMeta-GeoLane联邦学习策略保证大规模部署中的可伸缩性和隐私保护。系统通过与CARLA和SUMO整合，创建高保真的数字孪生，实时渲染高速公路场景并捕捉交通流向。", "innovation": "Geo-ORBIT引入了GeoLane、Meta-GeoLane和FedMeta-GeoLane三个关键组件，GeoLane是一种轻量级的车道检测模型，使用车辆轨迹数据和路边摄像头学习车道几何；Meta-GeoLane在GeoLane基础上学习个性化检测参数以适应本地实体；FedMeta-GeoLane是一种联邦学习策略，确保大规模分布式部署中的可扩展性和隐私保护。实验结果表明，与基线和元学习方法相比，FedMeta-GeoLane在几何误差上表现出更优的结果，并且具有更好的泛化能力，同时显著减少了通信开销。", "conclusion": "Geo-ORBIT框架为数字孪生提供了灵活、情境感知的基础架构建模，为未来的研究提供了坚实的基础，促进了数字孪生技术在交通管理与运营中的广泛应用。框架已公开发布。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08716", "html_url": "https://arxiv.org/abs/2507.08716", "title": "UnrealEngine单一引擎实现多模态ISAC数据仿真", "title_en": "Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine", "authors": "Kongwu Huang,Shiyi Mu,Jun Jiang,Yuan Gao,Shugong Xu", "background": "多模态数据孪生平台已经在大规模语言模型（LLM）和基石模型（foundation models）中取得了成功。为了探索它们在ISAC（智能传感与数据分析）研究中的潜力，本文提出了Great-X平台。Great-X是一个单引擎多模态数据孪生平台，它在Unreal Engine中重建了Sionna的射线跟踪计算，并与自主驾驶工具深度集成，实现了多模态数据（包括CSI、RGB、雷达和激光雷达数据）的高效同步模拟。", "innovation": "该研究创新性地利用单一引擎Unreal Engine实现了多模态数据的仿真，并提出了名为Great-MSD的开源、大规模低空无人机多模态感知数据集以及基于CSI的无人机3D定位算法，展示了在不同CSI仿真引擎中的可行性和普适性。相关的代码和数据集公开可获取。", "conclusion": "本文基于Great-X平台构建了一个大型多模态数据集，并提出了基于CSI的无人机3D定位算法，结果表明在不同仿真引擎中的可行性和普适性，并且代码和数据集已经公开可获取。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08003", "html_url": "https://arxiv.org/abs/2507.08003", "title": "SERP上的鼠标和眼动运动综合数据集", "title_en": "A Versatile Dataset of Mouse and Eye Movements on Search Engine Results Pages", "authors": "Kayhan Latifzadeh,Jacek Gwizdka,Luis A. Leiva", "background": "之前的研究主要依赖鼠标移动作为行为代理，但这些行为数据具有不准确和可能存在偏见的缺点。此外，这些研究依赖于参与者事后自我报告的标签，导致数据质量参差不齐。本研究旨在解决上述问题，通过使用眼动追踪器获取客观持续的视觉注意力数据，从而构建一个全面的数据集，用于研究用户在搜索引擎结果页面上的注意力和购买行为。", "innovation": "本研究提出的新颖之处在于，基于眼动追踪器，该研究创建了一个客观的持续视觉注意力的基准。研究数据包括2,776个与交易相关的查询，来自47名参与者。数据集包含网页的HTML源文件、渲染的SERP截图、眼动数据、鼠标操作数据、直接展示和自然广告的边界框，以及进一步处理数据的脚本。这些数据对于未来的研究具有很大的启发作用，可以用于分类任务等研究方向。", "conclusion": "本研究提供了一个包含鼠标和眼动数据的综合数据集，旨在帮助研究者全面理解和分析用户在搜索引擎结果页面上的行为。此外，研究还提供了基础实验，为未来的研究提供了思路和方法。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08766", "html_url": "https://arxiv.org/abs/2507.08766", "title": "结合特征提取和K均值的多阱Hopfield-CNN组合模型用于MNIST分类", "title_en": "A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification", "authors": "Ahmed Farooq", "background": "本文研究了一种将卷积神经网络（CNN）与多阱霍普菲尔德网络结合的混合模型，用于识别MNIST数据集中的手写数字。该方法利用CNN从输入图像中提取高维特征，并通过k均值聚类将这些特征聚类为类别特定的原型，这些原型充当多阱能量景观中的吸引子，霍普菲尔德网络通过最小化平衡特征相似性和类别差异的能函数来进行分类。研究表明，该模型能够稳健地处理诸如不同的手写风格等类内变异性，并通过基于能量的决策过程提供可解释的框架。通过系统优化CNN架构和阱的数量，该模型在10,000张MNIST图像上的测试准确率达到99.2%，表明其在图像分类任务中的有效性。研究结果强调了深层特征提取和充分的原型覆盖在实现高性能方面的重要性，并在模式识别中具有潜在应用价值。", "innovation": "该研究创新性地提出了结合特征提取和k均值聚类的多阱霍普菲尔德神经网络（MWN-HNN）与卷积神经网络（CNN）的混合模型，用于MNIST手写数字分类。通过CNN提取特征并在霍普菲尔德网络中通过能量函数进行分类，模型能够处理类内变异性并提供可解释的决策过程。研究表明，这种组合能够显著提高分类准确率，并展示了其在图像识别方面的潜力。", "conclusion": "通过系统优化的CNN架构和适当的多阱数量，该研究设计的混合模型在MNIST数据集上的测试准确率达到99.2%，显示出其在图像分类任务中的有效性。研究表明，深层特征提取和适当的原型覆盖对于实现高性能至关重要，该方法为模式识别领域的进一步研究提供了新的思路。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08064", "html_url": "https://arxiv.org/abs/2507.08064", "title": "PUMA：高效的模态自适应学习的层裁剪语言模型用于统一多模态检索", "title_en": "PUMA: Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning", "authors": "Yibo Lyu,Rui Shao,Gongwei Chen,Yijie Zhu,Weili Guan,Liqiang Nie", "background": "随着多媒体内容的扩展，现实应用中统一多模态检索（UMR）的需求增加。近期工作利用多模态大语言模型（MLLMs）来解决这一任务，但这些模型由于参数量大，导致训练成本高且推理效率低。", "innovation": "我们提出了PUMA：一种用于高效统一多模态检索的模态自适应学习的层裁剪语言模型。该方法在结构和学习两方面提升UMR性能。（1）结构上，我们提出层裁剪自蒸馏，通过保留浅层而在删除深层时保留特征作为教师信号进行蒸馏，减少参数数量同时保留表示能力。（2）在学习上，我们引入了模态自适应对比损失（MAC-Loss），根据目标模态将内模态和外模态负样本分开，并分配不同的温度策略以提高学习效率。", "conclusion": "实验表明，我们的方法大幅度减少了资源使用，同时保持了强大的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08025", "html_url": "https://arxiv.org/abs/2507.08025", "title": "使用多光谱LiDAR和3D深度学习进行3D森林语义分割", "title_en": "3D forest semantic segmentation using multispectral LiDAR and 3D deep learning", "authors": "Narges Takhtkeshha,Lauris Bocaux,Lassi Ruoppa,Fabio Remondino,Gottfried Mandlburger,Antero Kukko,Juha Hyyppä", "background": "森林资源的保护和管理需要定期进行森林清查。过去二十年里，激光扫描系统的LiDAR技术因其无损、远程的优势，被广泛应用于简化劳动密集型的森林清查过程。先进的多光谱（MS）LiDAR系统能够同时获取电磁波谱多个波长上的三维空间和光谱信息，从而估计森林的生物化学和生物物理特征。森林成分的分割对于森林清查至关重要。实验表明，整合空间和光谱激光信息能有效实现精确的森林语义分割。", "innovation": "本研究利用HeliALS系统的高密度多光谱点云数据，采用三种点式的3D深度学习模型和一个机器学习模型（包括Kernel Point Convolution、SuperPoint Transformer、Point Transformer V3和Random Forest）对森林进行六种成分的分割。研究结果显示，KPConv模型的精度最佳。通过使用所有三个波长（1550 nm、905 nm和532 nm）作为初始特征，提高了均交并比（mIoU）和均精度（mAcc），分别提高了33.73%和32.35%。研究成果表明多光谱LiDAR在自动化森林成分分割中的巨大潜力。", "conclusion": "多光谱LiDAR技术与3D深度学习相结合，能够显著提高自动化森林成分分割的准确性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08800", "html_url": "https://arxiv.org/abs/2507.08800", "title": "NeuralOS：通过神经生成模型模拟操作系统", "title_en": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models", "authors": "Luke Rivard,Sun Sun,Hongyu Guo,Wenhu Chen,Yuntian Deng", "background": "介绍了NeuralOS，这是一种通过直接对用户输入（如鼠标移动、点击和键盘事件）的响应来模拟操作系统图形用户界面（GUI）的神经框架。研究团队利用大规模的Ubuntu XFCE录制数据集进行训练，该数据集包含随机生成的交互和由AI代理生成的现实交互。通过这种方式，NeuralOS能够生成真实的GUI序列，准确捕捉鼠标交互，并可靠地预测状态转换，如应用程序的启动。尽管精确建模精细的键盘交互仍然具有挑战性，但NeuralOS为未来人机交互系统中创建全适应的生成神经接口提供了一步进展。", "innovation": "NeuralOS结合了递归神经网络（RNN）来跟踪计算机状态与基于扩散的神经渲染器来生成屏幕图像。该模型在包括随机生成交互和由AI代理生成的现实交互的大型数据集上进行了训练。NeuralOS成功地渲染了真实的GUI序列，准确地捕捉了鼠标交互，并可靠地预测了状态转换，如应用程序的启动。尽管精确建模精细的键盘交互仍然具有挑战性，但NeuralOS在创建未来人机交互系统中全适应的生成神经接口方面提供了重要进展。", "conclusion": "虽然精确建模细致的键盘交互仍然具有挑战性，NeuralOS展示了朝创建适应性、生成神经接口系统迈出的重要一步，为未来的人机交互系统提供了可能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08028", "html_url": "https://arxiv.org/abs/2507.08028", "title": "SSSUMO: 实时半监督子运动分解", "title_en": "SSSUMO: Real-Time Semi-Supervised Submovement Decomposition", "authors": "Evgenii Rudakov,Jonathan Shock,Otto Lappi,Benjamin Ultan Cowley", "background": "现有的子运动分析方法虽然提供了对运动控制有价值的见解，但在重建准确性、计算成本和验证方面存在困难，主要是由于获得手标注数据的难度。本文在半监督学习框架下，通过利用合成数据（最初由最小加速度原则生成，然后通过适应未标记的人类运动数据逐迭代改进）学习，来解决这些挑战。这种方法在多种合成和不同的人类运动数据集上显著超越现有方法，即使在高噪声条件下也表现出色。此外，模型实现实时操作（每输入秒少于1毫秒），显著优于基于优化的技术。这提高了运动控制研究、康复医学和人机交互的新应用的可能性。传统的用于复杂的运动任务的方法在这些数据集上表现不佳，尤其是在提出了显著改进的情况下。为推动研究进展，训练和基准测试的源代码以及预训练模型权重在这篇文章末尾的链接处公开共享。", "innovation": "提出了一种名为SSSUMO的半监督深度学习方法，用于子运动分解，实现了最先进的准确性和速度，并且能够在高噪声条件下保持稳定性。该方法利用半监督学习框架，通过合成数据（根据最小加速度原则生成，然后迭代适应未标记的运动数据）来学习。模型采用了一种具有可微重构的全卷积架构，使得在多种数据集上均能超越现有方法。关键改进在于提高了实时处理能力（每输入秒少于1毫秒），显著优于基于优化的技术。这种方法在多种类型的运动任务中表现出显著效果，特别是在传统方法表现不佳的数据集上", "conclusion": "这篇文章提出并验证了一种名为SSSUMO的半监督深度学习方法，这种方法在子运动分解中实现了卓越的实时性能，即使在高噪声条件下也能保持高准确性。通过半监督学习框架和实时处理能力，SSSUMO为运动控制研究、康复医学和人机交互提供了新的可能性。同时，提供了广泛的训练和基准测试数据集，以及公开的预训练模型权重，以促进更多的研究和应用开发。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08801", "html_url": "https://arxiv.org/abs/2507.08801", "title": "Lumos-1：从统一模型的角度进行自回归视频生成", "title_en": "Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective", "authors": "Hangjie Yuan,Weihua Chen,Jun Cen,Hu Yu,Jingyun Liang,Shuning Chang,Zhihui Lin,Tao Feng,Pengwei Liu,Jiazheng Xing,Hao Luo,Jiasheng Tang,Fan Wang,Yi Yang", "background": "自回归大型语言模型（LLMs）已经统一了广泛的自然语言任务，从而激发了对自回归视频生成的初步尝试。现有的自回归视频生成器要么偏离标准LLM架构、依赖于臃肿的外部文本编码器，要么由于逐token解码而导致计算延迟。", "innovation": "本文提出Lumos-1，这是一个保留LLM架构的自回归视频生成器，仅进行了少量的架构修改。1. 提出了MM-RoPE，这是一种RoPE方案，保留了原来文本RoPE的同时，提供了全面的频谱范围和缩放后的3D位置，用于建模多模态时空数据；2. 提出了自回归离散扩散强迫（AR-DF）策略，利用训练时的时间管状掩蔽和兼容的推理时遮罩策略来避免质量下降；3. 利用高效的训练技术，Lumos-1在48张GPU上预训练，性能可与EMU3、COSMOS-Video2World和OpenSoraPlan等模型媲美。", "conclusion": "通过使用MM-RoPE和AR-DF策略，以及有效的训练技术，Lumos-1在保持LLM架构不变的情况下提高了自回归视频生成的质量和效率，并在多个基准数据集上取得了显著的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08104", "html_url": "https://arxiv.org/abs/2507.08104", "title": "VideoConviction: 人类信念和股票市场建议的多模态基准", "title_en": "VideoConviction: A Multimodal Benchmark for Human Conviction and Stock Market Recommendations", "authors": "Michael Galarnyk,Veer Kejriwal,Agam Shah,Yash Bhardwaj,Nicholas Meyer,Anand Krishnan,Sudheer Chava", "background": "社交媒体放大了被称为“finfluencer”的金融影响者的影响，他们在YouTube等平台上分享股票建议。理解他们的影响力需要分析文本之外的多模态信号，包括语气、传达风格和面部表情等，这超出了基于文本的财务分析范围。", "innovation": "引入了VideoConviction，这是一个包含6,000多个专家注释的多模态数据集，共计457小时的人工努力成果，用于评估多模态大型语言模型（MLLMs）和基于文本的大型语言模型（LLMs）在财务对话中的表现。结果显示，虽然多模态输入有助于股票代码提取（如提取苹果的代码AAPL），但无论是MLLMs还是LLMs，在区分投资行动和信念强度（通过自信的传递和详尽的推理传达的信心程度）方面都表现不佳，往往会将一般的评论误分类为明确的建议。尽管高信念度的建议比低信念度的建议表现更好，但它们仍然无法与流行的标普500指数基金表现相匹敌。一种反向策略——反对finfluencer的建议——在年化回报率上比标普500指数高6.8%，但风险更高（夏普比为0.41 vs. 0.65）。", "conclusion": "该基准测试允许对多模态任务进行多方面评估，比较模型在完整视频和分段视频输入上的表现。这促进了多模态财务研究的进一步发展。该代码、数据集和评估排行榜已根据CC BY-NC 4.0许可发布。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08036", "html_url": "https://arxiv.org/abs/2507.08036", "title": "MedVQA系统在放射学工作流程中的整合障碍：一项文献综述和临床医生见解", "title_en": "Barriers in Integrating Medical Visual Question Answering into Radiology Workflows: A Scoping Review and Clinicians' Insights", "authors": "Deepali Mishra,Chaklam Silpasuwanchai,Ashutosh Modi,Madhumita Sushil,Sorayouth Chumnanvej", "background": "MedVQA作为一种自动化医学图像解释工具，能够通过问答来协助放射学家，尽管在模型和数据集方面取得了进展，但它在临床工作流程中的整合仍然受到限制。作者通过系统回顾68篇相关文献（2018-2024年）并调查了来自印度和泰国的50名临床医生，探讨了MedVQA的实际用途、挑战和缺口。", "innovation": "研究采用了两阶段方法：一方面，通过文献回顾来识别放射学工作流程中的关键概念、进展和研究缺口；另一方面，通过调查临床医生来捕捉他们对MedVQA临床相关性的看法。研究发现QA对对诊断缺乏临床相关性，现有数据集和模型无法支持多视图、多分辨率成像、电子健康记录集成或专业知识，且当前的评估标准与临床需求不匹配。", "conclusion": "尽管MedVQA有强大的潜力，但仍然面临多模态分析受限、缺乏患者背景信息和评估方法不匹配等挑战，需要改进才能有效地融入临床工作流程。大多数临床医生不认为现有的MedVQA系统非常有用，关键问题包括缺乏患者历史记录或专业知识支持、偏好手动验证的数据集以及需要支持多视图成像。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08214", "html_url": "https://arxiv.org/abs/2507.08214", "title": "Depth-Sequence Transformer (DST)用于非对比CT上的段特异性ICA钙化图谱映射", "title_en": "Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification Mapping on Non-Contrast CT", "authors": "Xiangjian Hou,Ebru Yaman Akcicek,Xin Wang,Kazem Hashemizadeh,Scott Mcnally,Chun Yuan,Xiaodong Ma", "background": "虽然颅内颈动脉钙化(ICAC)总体体积已被确立为中风生物标志物，但日益增多的证据表明，这种汇总指标忽略了不同部位的斑块位置对预后和程序风险的差异性影响。传统的3D模型在处理高分辨率CT体积时，由于需要降采样或处理孤立片段，导致无法保留全局上下文，影响解剖结构的清晰度和精确的解剖标记定位。", "innovation": "本文将3D任务重新定义为沿1D轴向维度并行概率解剖标记定位任务。提出了一种新的深度序列转换器(DST)框架，它以CT全分辨率数据作为2D切片序列处理，学习预测6个独立的概率分布以精准定位关键解剖结构标记点。DST框架在100个临床样本的5折交叉验证中实现了0.1个切片的平均绝对误差，96%的预测落在了±1个切片的容差内。此外，DST模型在公开的清洁-CC-CCII分类基准上的端到端评估协议中获得最佳结果。", "conclusion": "本文首次提供了一种用于自动化段特异性ICAC分析的实际工具。所提出框架为研究位置特异性生物标志物在诊断、预后以及程序规划中的作用提供了基础。相应代码将公开提供。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08178", "html_url": "https://arxiv.org/abs/2507.08178", "title": "破解实例拼图难题：一种用于全切片图像分析的替代多实例学习方法", "title_en": "Cracking Instance Jigsaw Puzzles: An Alternative to Multiple Instance Learning for Whole Slide Image Analysis", "authors": "Xiwen Chen,Peijie Qiu,Wenhui Zhu,Hao Wang,Huayu Li,Xuanzhao Dong,Xiaotong Sun,Xiaobing Yu,Yalin Wang,Abolfazl Razi,Aristeidis Sotiras", "background": "虽然多项式实例学习（MIL）已被证明在组织病理学全切片图像（WSI）分析中展现出很大的潜力，但其依赖于排列不变性，这极大地限制了其有效发现WSI内实例间的语义相关性的能力。", "innovation": "研究提出了一种新的替代MIL的方法，通过从随机打乱排列中学习恢复实例顺序，称之为“实例拼图破解问题”。基于最优传输理论提出了一种新的Siamese网络解决方案，该方法在WSI分类和生存预测任务中优于最近的MIL竞争对手。", "conclusion": "所提出的策略在WSI分类和生存预测任务中表现出色，并已通过实验证明其有效性，该方法的代码已公开可供使用。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08772", "html_url": "https://arxiv.org/abs/2507.08772", "title": "从单一到多样：用于3D生成的上下文零件潜变量", "title_en": "From One to More: Contextual Part Latents for 3D Generation", "authors": "Shaocong Dong,Lihe Ding,Xiao Chen,Yaokun Li,Yuxin Wang,Yucheng Wang,Qi Wang,Jaehyeok Kim,Chenjian Gao,Zhanpeng Huang,Zibin Wang,Tianfan Xue,Dan Xu", "background": "近期3D生成领域取得了进展，从多视角2D渲染技术转向了利用真实数据几何先验的3D原生潜变量扩散框架。然而，这一领域仍存在三大局限：单一潜变量无法捕捉复杂多部件几何结构，导致细节退化；整体潜变量编码忽视了部件的独立性及其在组合设计中的相互关系；全局调节机制缺乏细致的可控性。", "innovation": "提出了一种名为CoPart的部件感知扩散框架，该框架将3D对象分解为上下文感知的部件潜变量，以实现一致的多部件生成。这一框架的优势包括：通过部件分解减少编码复杂性；能够明确建模部件间的相互关系；支持部件级别的调节。进一步开发了一种相互指导策略，用于微调预训练的扩散模型，确保同时具备几何连贯性和基础模型先验。", "conclusion": "大规模实验表明，CoPart在部件级别的编辑、具象对象生成和场景组成方面表现出卓越的能力，具备前所未有的可控性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08262", "html_url": "https://arxiv.org/abs/2507.08262", "title": "CL3R: 3D重建和对比学习以增强机器人操作表示", "title_en": "CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations", "authors": "Wenbo Cui,Chengyang Zhao,Yuhui Chen,Haoran Li,Zhizheng Zhang,Dongbin Zhao,He Wang", "background": "建一个强大的感知模块对视觉运动策略学习至关重要。然而，尽管最近的方法通过引入预训练的2D基础模型来增强机器人的感知模块，以利用它们的强大的语义理解能力，但它们在捕捉3D空间信息和跨不同相机视角进行泛化方面仍然存在问题。这些限制阻碍了策略的有效性，尤其是在精细的机器人操作场景中。因此，需要一种结合空间意识和语义理解的新方法来解决这些问题，而CL3R正是为此而设计的。", "innovation": "CL3R提出了一种新颖的3D预训练框架，通过结合空间意识和语义理解来增强机器人操作策略。该方法采用点云Masked Autoencoder来学习丰富的3D表示，并通过对比学习利用预先训练的2D基础模型来进行高效的语义知识转移。此外，还提出了一种3D视觉表示预训练框架，通过统一数据集中的坐标系并随机融合多视角点云，来解决相机视角的不确定性问题并提高泛化能力，从而确保在测试时从新颖视角的鲁棒感知。", "conclusion": "广泛的模拟和实际世界的实验表明，CL3R方法优于现有方法，强调了它在机器人操作的视觉运动策略学习中的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08513", "html_url": "https://arxiv.org/abs/2507.08513", "title": "通过大规模3D视觉指令数据集生成提升多模态大语言模型", "title_en": "Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation", "authors": "Liu He,Xiao Zeng,Yizhi Song,Albert Y. C. Chen,Lu Xia,Shashwat Verma,Sankalp Dayal,Min Sun,Cheng-Hao Kuo,Daniel Aliaga", "background": "现有的多模态大语言模型（MLLMs）在准确捕捉物体间的空间关系方面存在困难，特别是对于物体方向、相机视角和镜头角度的描述。这归因于它们的训练数据中相机-物体关系的单一性和多样性不足。", "innovation": "本文提出了一种合成生成管道，用于创建大规模3D视觉指令数据集。该框架将3D资产作为输入，通过渲染和基于扩散的图像生成模型生成保真度相机-物体关系的逼真图像。同时，大型语言模型（LLMs）用于生成文本提示，以指导视觉指令调优和控制图像生成。最终，通过我们提出的数据集训练的MLLMs在商业模型上表现出显著提升，尤其是在相机-物体关系识别任务中的平均精度提高了33.4%，并且发布有代码、数据集和基准测试以促进多模态大语言模型的应用推广和发展。", "conclusion": "我们的数据集和基准测试将促进广泛领域的多模态大语言模型的应用和研究。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08254", "html_url": "https://arxiv.org/abs/2507.08254", "title": "Raptor: 利用预训练2D基础模型的3D医学影像伸缩性无训练嵌入方法", "title_en": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models", "authors": "Ulzee An,Moonseong Jeong,Simon A. Lee,Aditya Gorla,Yuzhe Yang,Sriram Sankararaman", "background": "当前，在开发用于医学影像数据（如磁共振成像（MRI））的基座模型时面临的主要挑战包括训练最新架构在高维度上的计算复杂性以及收集足够大的体积数据集。", "innovation": "我们引入了Raptor（随机平面张量缩减），这是一种无训练的方法，用于生成3D医学体积数据的语义丰富的嵌入。Raptor 利用在自然图像上先验训练的冻结2D基础模型，从医学体积的各个横截面上提取视觉标记，并使用随机投影在降低计算复杂性的同时保留语义信息。", "conclusion": "通过在十个不同的医学体积任务上的广泛实验，我们验证了Raptor相比现有最先进的方法（包括仅在医学体积上预训练的方法，如 SuPreM (+3%)、MISFM (+6%)、Merlin (+10%)、VoCo (+13%) 和 SLIViT (+14%)）的优越性能。Raptor 实现了完全摒弃昂贵的训练需求的目标，凸显了其作为推进基于深度学习的医学体积方法的有效性和多功能性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08285", "html_url": "https://arxiv.org/abs/2507.08285", "title": "FlowDrag: 3D感知的基于拖拽的图像编辑方法及其网格引导变形向量场", "title_en": "FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields", "authors": "Gwanhyeong Koo,Sunjae Yoon,Younghwan Lee,Ji Woo Hong,Chang D. Yoo", "background": "基于拖拽的编辑允许通过点控制实现精确的对象操作，提供了用户便利性。然而，当前的方法往往会出现几何不一致的问题，这些方法专注于匹配用户定义的点，而忽略了更广泛的几何结构，导致出现艺术效果不良或不稳定编辑的问题。现有的拖拽编辑基准测试没有提供真实的地面参考，使得准确评估编辑是否符合预期变换变得困难。", "innovation": "提出了一种名为FlowDrag的新方法，利用几何信息来实现更准确和一致的变换。FlowDrag通过用户定义的拖拽点构建3D网格，并使用能量函数指导网格变形，然后将结果的网格偏移投影到2D，结合UNet去噪过程，实现目标点精确对齐，同时保持结构完整性。同时，开发了VFD（VidFrameDrag）基准数据集，提供视频数据集中连续帧的地面真实参考，以评估编辑的准确性。FlowDrag在VFD Bench和DragBench上均优于现有拖拽编辑方法。", "conclusion": "FlowDrag采用网格引导的变形向量场，结合了3D感知和真实参考，有效解决了拖拽编辑中存在的一些问题，提升了编辑效果的准确性与一致性，为基于拖拽的图像编辑提供了新的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08575", "html_url": "https://arxiv.org/abs/2507.08575", "title": "大型多模态模型制图理解在文本局部性地理参考中的应用", "title_en": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing", "authors": "Kalana Wijegunarathna,Kristin Stock,Christopher B. Jones", "background": "过去几个世纪收集的数百万份生物样本记录存放在自然历史收藏中，但这些记录没有地理坐标。对与这些样本相关的复杂地点描述进行地理参考是一个耗费大量人力的工作。现有的自动化方法中，没有一个利用地图作为地理参考的重要工具。现有的地理参考工具和大型语言模型仅能进行单模态地理参考。", "innovation": "该研究提出了一个新颖的方法，利用最近的大型多模态模型（LMM）的多模态能力来地理参考文本中的复杂地点描述。该方法允许模型通过视觉上下文理解文本中的空间关系。研究采用了网格方法来适应自回归模型，进行这一任务的零样本设置。实验结果表明，该方法在少量手动注释数据集上的表现优于使用大型语言模型和现有地理参考工具的单模态地理参考，平均距离误差约为1公里。", "conclusion": "实验结果支持利用大型多模态模型理解细粒度地图的能力。研究提出了一个实用框架，将此方法整合到地理参考工作流程中，以进一步提高地理参考的效率和准确性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08306", "html_url": "https://arxiv.org/abs/2507.08306", "title": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "title_en": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "authors": "Inclusion AI:Fudong Wang,Jiajia Liu,Jingdong Chen,Jun Zhou,Kaixiang Ji,Lixiang Ru,Qingpei Guo,Ruobing Zheng,Tianqi Li,Yi Yuan,Yifan Mao,Yuting Xiao,Ziping Ma", "background": "最近在多模态大型语言模型（MLLMs）的发展中，特别是通过验证性奖励强化学习（RLVR）的方法，显著增强了其推理能力。然而，一个关键问题依然存在，那就是这些模型在处理动态空间交互方面表现不足，而这对于实际应用来说是一项至关重要的能力。", "innovation": "本文提出了一种称为M2-Reasoning-7B的新模型，旨在在一般推理和空间推理方面表现出色。创新点包括：(1) 一个生成了294,200个高质量数据样本的数据管道（其中168,000个用于冷启动微调，126,200个用于RLVR），这些数据样本合逻辑且经过全面评估；(2) 采用了一个动态多任务训练策略，进行逐步优化以解决数据和任务特定奖励之间的冲突。", "conclusion": "M2-Reasoning-7B结合了精心策划的数据和较先进的训练方法，在8个基准测试中达到了新的最先进的（SOTA），展示了其在一般推理和空间推理领域的优越性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08590", "html_url": "https://arxiv.org/abs/2507.08590", "title": "使用MLLMs生成视觉语义描述用于图像-文本匹配", "title_en": "Visual Semantic Description Generation with MLLMs for Image-Text Matching", "authors": "Junyu Chen,Yihua Gao,Mingyong Li", "background": "图像-文本匹配（ITM）旨在解决视觉和文本模态之间的根本性对齐问题，这两种模态在表示上天然不同，连续的高维图像特征与离散的结构化文本形式。现有的方法在跨模态对齐方面面临挑战，需要找到一种有效的方法来关联两者。本文提出了一个创新的框架，利用多模态大语言模型（MLLMs）作为视觉语义解析器来解决这个问题，通过生成丰富的视觉语义描述（VSD），提供语义锚点来促进跨模态对齐。", "innovation": "本文提出了一个利用MLLMs生成VSD的新框架，通过实例级和原型级的对齐机制，增强图像表示的语义表达性和确保类别级一致性。这一框架可以无缝地集成到现有的ITM模型中，并在Flickr30K和MSCOCO数据集上取得了显著的性能提升。此外，该方法还展示了出色的零样本跨域任务泛化能力，包括新闻和遥感图像-文本匹配任务。", "conclusion": "本文通过生成VSD和利用MLLMs进行实例级和原型级对齐，提高了图像-文本匹配任务的性能，并展示了良好泛化的跨域能力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08726", "html_url": "https://arxiv.org/abs/2507.08726", "title": "通过3D场景重建学习人到机器人交接", "title_en": "Learning human-to-robot handovers through 3D scene reconstruction", "authors": "Yuekun Wu,Yik Lung Pang,Andrea Cavallaro,Changjae Oh", "background": "学习机器人的操作策略需要大量的机器人动作试验，使用仿真训练虽然成本较低，但模拟与机器人工作区的视觉差距仍然是一个主要限制。最近，基于高斯点云重建的方法为机器人操作提供了新的方向，通过生成真实环境，使得机器人能够从RGB图像中学习，无需真实的机器人训练或数据收集。", "innovation": "提出了结合稀疏视图高斯点云重建（Sparse-View Gaussian Splatting, SGS）的人到机器人交接方法（Human-to-Robot Handover using Sparse-View Gaussian Splatting, H2RH-SGS），该方法可以直接从真实世界环境收集的数据中生成机器人演示，用于训练机器人政策，并直接在真实环境中部署，提高了学习效率和效果。", "conclusion": "通过基于高斯点云重建的场景及真实的人到机器人交接实验，H2RH-SGS表现出了在人到机器人交接任务上的新且有效的表示方法。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2306.03538", "html_url": "https://arxiv.org/abs/2306.03538", "title": "SDR-GAIN：用于自动驾驶的高实时性遮挡行人姿态完成方法", "title_en": "SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving", "authors": "Honghao Fu,Yongli Gu,Yidong Yan,Yilang Shen,Yiwen Wu,Libo Sun", "background": "随着视觉自主驾驶技术的发展，行人检测已成为提高交通安全和驾驶系统鲁棒性的关键组成部分。然而，在复杂的交通场景中，常规的姿势估计方法经常无法准确重建被遮挡的关键点，主要是由于车辆、植被或建筑元素造成的遮挡。因此，本文旨在提出一种基于分离和降维的生成对抗填充网络（SDR-GAIN）的实时遮挡行人姿态完成框架，以解决这一问题。SDR-GAIN 直接从关键点坐标的空间分布中学习人体姿态，而不需要训练视觉模型来识别遮挡模式。", "innovation": "不同于之前训练视觉模型识别遮挡模式的方法，SDR-GAIN 使用自监督生成对抗学习范式来训练具有残差结构的轻量级生成器，用于填补缺失的姿态关键点。此外，它还整合了多种姿态标准化技术，以减轻学习过程中的难度。实验结果表明，SDR-GAIN 在准确恢复被遮挡的行人关键点方面超过传统的机器学习和基于Transformer的缺失数据填充算法，并同时实现微秒量级的实时推理。", "conclusion": "本文提出了一种基于 SDR-GAIN 的高实时性遮挡行人姿态完成方法，实验结果验证了该方法在复杂交通场景中的有效性，并且能够准确恢复遮挡的行人姿态，同时实现极快速的推理速度。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.10011", "html_url": "https://arxiv.org/abs/2311.10011", "title": "SQLNet: Scale-Modulated Query and Localization Network for Few-Shot Class-Agnostic Counting", "title_en": "SQLNet: Scale-Modulated Query and Localization Network for Few-Shot Class-Agnostic Counting", "authors": "Hefeng Wu,Yandong Chen,Lingbo Liu,Tianshui Chen,Keze Wang,Liang Lin", "background": "现有的类无差别计数（Class-Agnostic Counting, CAC）任务需要在输入图像中几个示例存在的情况下，统计任意类别的所有物体数量。现有的方法大多依靠密度图回归，这使得它们对于需要物体位置的下游任务不适用，限制了他们充分探索示例尺度信息以进行监督的能力。", "innovation": "提出了一种基于定位的新型CAC方法——尺度调节查询和定位网络（SQLNet），该方法在查询和定位阶段充分探索了示例的尺度，通过准确定位每个物体并预测其大致尺寸来实现有效的计数。方法包括多尺度示例协作增强（HECE），以及尺度感知多头定位（SAML）模块，引入了尺度感知的定位损失以优化模型性能。", "conclusion": "在广泛实验中，SQLNet在流行的CAC基准测试中表现优于当前最先进的方法，不仅在计数准确性方面表现出色，还在定位和边界框生成方面也表现出卓越性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08309", "html_url": "https://arxiv.org/abs/2507.08309", "title": "通过同步自我审阅其OCR能力来提升MLLM的文档图像机器翻译", "title_en": "Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency", "authors": "Yupu Liang,Yaping Zhang,Zhiyang Zhang,Zhiyuan Chen,Yang Zhao,Lu Xiang,Chengqing Zong,Yu Zhou", "background": "多模态大型语言模型（MLLMs）在文档图像任务中表现强劲，尤其是在光学字符识别（OCR）方面。然而，MLLMs在文档图像机器翻译（DIMT）上遇到挑战，这要求处理跨模态和跨语言的问题。以前通过在DIMT数据集上进行监督微调（SFT）的方法常常导致模型忘记了其原有的单语OCR能力。", "innovation": "本文提出了一种新的微调范式，名为同步自我审阅（SSR），通过让模型在产生翻译文本之前先生成OCR文本，同时利用模型强大的单语OCR能力来学习跨语言翻译，从而缓解灾难性遗忘并提升MLLMs在OCR和DIMT任务上的泛化能力。", "conclusion": "全面的实验结果证明了SSR学习能有效缓解灾难性遗忘，改善MLLMs在OCR和DIMT任务上的泛化能力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.19002", "html_url": "https://arxiv.org/abs/2402.19002", "title": "GoalNet: 以目标区域为导向的行人性轨迹预测", "title_en": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction", "authors": "Amar Fadillah,Ching-Lin Lee,Zhi-Xuan Wang,Kuan-Ting Lai", "background": "行人轨迹预测是自动驾驶中重要的任务。行人轨迹预测受到场景路径、行人的意图和决策影响，是一个多模态问题。当前大多数研究主要通过预测行人的过往轨迹来推断未来的多种潜在轨迹分布，但没有考虑到场景的背景信息和行人的目标方向。因此提出了一个新的预测模型，直接利用场景背景信息和所观察到的位置信息来预测目标点，再利用这些目标点来预测行人的未来轨迹，从而将不确定性限制在几个目标区域内，代表行人的“目标”。", "innovation": "提出了一种新的基于行人目标区域的轨迹预测神经网络GoalNet。该网络可以同时预测行人的轨迹和边界框。整个模型高效且模块化，输出可根据使用场景进行调整。实验结果显示，GoalNet在JAAD和PIE数据集上的表现显著优于先前的最先进的方法，分别提高了48.7%和40.8%。", "conclusion": "通过使用场景背景信息和观察到的轨迹来预测目标点，再基于这些目标点推断行人的未来轨迹，GoalNet能够更准确地预测行人轨迹，同时保持模型的高效性和模块化。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.06759", "html_url": "https://arxiv.org/abs/2403.06759", "title": "平均校准误差：一种用于提高图像分割可靠性的可微损失函数", "title_en": "Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation", "authors": "Theodore Barfoot,Luis Garcia-Peraza-Herrera,Ben Glocker,Tom Vercauteren", "background": "医疗图像分割中的深度神经网络常常产生过度自信的结果，这些结果与实际观察不符。这种校准不佳的问题阻碍了这些网络在临床中的应用。为了改善像素级的校准而不牺牲分割质量，本文提出了一种名为边际L1平均校准误差（mL1-ACE）的新型辅助损失函数。该方法直接可微，不需要使用近似但可微的替代方法或软分箱方法。除此之外，本文还引入了数据集可靠性直方图的概念，用于在分割层面更细致地评估校准的可靠性。", "innovation": "本文提出了一种新颖的辅助损失函数mL1-ACE，它使用硬分箱但直接可微，以及引入了数据集可靠性直方图的概念，为改进图像分割的校准提供了一种方法。实验表明，在使用mL1-ACE后，平均和最大校准误差分别减少了45%和55%，同时保持Dice分数为87%。", "conclusion": "本文通过引入新的可微损失函数mL1-ACE和数据集可靠性直方图方法，显著提高了医疗图像分割的校准可靠性，同时保持了分割质量，并分享了相关代码。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08610", "html_url": "https://arxiv.org/abs/2507.08610", "title": "使用沟通游戏提高无需额外数据的图像描述能力的Emergent自然语言", "title_en": "Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data", "authors": "Parag Dutta,Ambedkar Dukkipati", "background": "图像描述是开发各种AI系统的重要问题，这些任务需要大量的标注图像来训练模型。由于现有的所有标注数据已经被用于训练大型视觉语言模型（VLMs），提高这些模型的表现变得具有挑战性。因此，考虑未监督的图像描述性能变得尤为重要，而后者相对较少被探索。本文在此背景下提出了一种新的方法LoGIC（Lewis沟通游戏），旨在通过多智能体强化学习来提升图像描述能力，而不需要额外的标注数据。", "innovation": "本文提出了LoGIC，一种多智能体强化学习的图像描述沟通游戏方法。与传统的仅使用预训练的VLM的方法不同，LoGIC使用轻量级的ViT进行图像感知和GPT2进行语言生成，并证明了这种方法能在未监督的场景下取得更好的表现。此外，通过使用预先训练的VLM和大型语言模型作为听者，引入LoGIC后，最终获得了46 BLEU分数，相比于基线方法提高了2个单位。使用LoGIC从零开始训练轻量级组件，方法在未监督设置下取得了31 BLEU分数，比现有的未监督图像描述方法已有10个单位的优势。", "conclusion": "通过引入LoGIC，本文证明了在无需额外标注数据的情况下，通过多智能体强化学习和利用轻量级组件，可以提升图像描述的能力，达到了与使用传统VLM相比显著改进的效果。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.08229", "html_url": "https://arxiv.org/abs/2410.08229", "title": "使用位平面和颜色模型改进脉冲神经网络", "title_en": "Improvement of Spiking Neural Network with Bit Planes and Color Models", "authors": "Nhan T. Luu,Duong T. Luu,Nam N. Pham,Thang C. Truong", "background": "脉冲神经网络（SNN）在计算神经科学和人工智能领域展现出有前景的范例，因其低能耗和小内存占用而受到重视。然而，其实用性受到性能优化等挑战的限制。", "innovation": "提出了通过一种利用位平面表示的新编码方法来提升SNN用于图像处理性能的创新方法。该方法旨在提升SNN的准确度而不增加模型大小，并通过颜色模型的研究评估其影响。", "conclusion": "通过广泛的实验验证，证明了该编码策略在多个数据集上实现了性能提升，并且认为这是首次将位平面和颜色模型应用于SNN的研究。利用位平面的特性有望在SNN性能方面解锁新的潜力，为未来研究和应用提供更多高效且有效的SNN模型。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10715", "html_url": "https://arxiv.org/abs/2411.10715", "title": "EVT: 效率视图转置用于多模态3D物体检测", "title_en": "EVT: Efficient View Transformation for Multi-Modal 3D Object Detection", "authors": "Yongjin Lee,Hyeon-Mun Jeong,Yurim Jeon,Sanghyun Kim", "background": "多视角传感器融合在鸟瞰图（BEV）表示下已成为3D物体检测的主导方法。然而，现有方法常常依赖深度估计器或变压器编码器将图像特征转换为BEV空间，这降低了鲁棒性或引入了显著的计算开销。此外，视图变换不足的几何指导导致射线方向错位，限制了BEV表示的有效性。", "innovation": "我们提出了高效视图转换（EVT），这是一种新颖的3D物体检测框架，通过构造结构良好的BEV表示来提高准确性和效率。我们的方法集中在两个关键方面：自适应采样和自适应投影（ASAP），利用LiDAR指导生成3D采样点和自适应核，使图像特征更有效地转换到BEV空间和细化的BEV表示；以及改进的基于查询的检测框架，结合组级混合查询选择和几何感知交叉注意力，有效捕捉物体的共同属性和几何结构。", "conclusion": "在nuScenes测试集上，EVT实现了75.3%的NDS最佳性能，同时保持实时推理速度。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.14679", "html_url": "https://arxiv.org/abs/2409.14679", "title": "量化领域适应中物体检测中的上下文偏差", "title_en": "Quantifying Context Bias in Domain Adaptation for Object Detection", "authors": "Hojun Son,Asma Almutairi,Arpan Kusari", "background": "领域适应中的物体检测（DAOD）已成为解决训练域和部署域之间分布变化导致性能下降的关键技术。然而，由学习到的前景-背景（FG-BG）关联引起的上下文偏差这一重要因素尚未得到充分探索。本文探讨了DAOD中FG-BG关联的三个关键问题：训练中FG-BG关联的编码、FG-BG关联与检测性能之间的因果关系，以及FG-BG关联对领域适应的影响。通过对背景遮罩和特征扰动下的类别和特征性能下降进行分析，并通过计算准确率下降率来衡量其变化，本文揭示了以卷积为基础的物体检测模型中包含了FG-BG关联。研究结果表明，上下文偏差不仅存在，而且对物体检测模型跨域的一般化能力有因果破坏作用。此外，通过在多个模型和数据集上进行验证，包括最新的ALDI++架构，证实了该发现。这些发现强调了在DAOD框架中明确处理上下文偏差的必要性，为开发更稳健和通用的物体检测系统提供了见解。", "innovation": "本文通过背景遮罩和特征扰动下的类别和特征性能下降分析，提出了一种新的度量标准——领域关联梯度（定义为下降率与最大均方偏差的比率），以此量化域间FG-BG关联的因果影响。文章采用do-因果计算和类激活映射来探讨FG-BG关联的因果作用，并通过一系列实验证明了卷积基础的物体检测模型的FG-BG关联情况，强调了上下文偏差在跨域物检测中的重要性。", "conclusion": "本文研究发现，物体检测模型中包含_fg-bg关联，上下文偏差对跨域物检测的一般化能力有因果破坏作用。通过多种模型和数据集验证，强调在领域适应框架中明确处理上下文偏差的必要性，为开发更稳健和通用的物体检测系统提供了新的理论依据。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.09250", "html_url": "https://arxiv.org/abs/2411.09250", "title": "用于少样本逐类别增量学习的空间分配与角度-范数联合分类器嵌入", "title_en": "Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning", "authors": "Dunwei Tu,Huiyu Yi,Tieyi Zhang,Ruotong Li,Furao Shen,Jian Zhao", "background": "少样本逐类别增量学习（FSCIL）的目标是在仅有少量样本的情况下持续学习新类别，同时不需要忘记之前学到的内容。这对于智能代理适应动态环境是必须的。当前的方法主要分为两种挑战：(i) 现有类别占据了整个特征空间，这不利于学习新的类别。(ii) 增量学习阶段样本数量较少，不足以充分训练。现有的虚拟类别方法在处理挑战 (i) 时试图使用虚拟类别作为占位符，但新类别可能与虚拟类别不完全匹配。在处理挑战 (ii) 时，将其可训练的全连接层替换为基于余弦相似性的最近类别均值（NCM）分类器，但这种方法没有考虑样本失衡的问题。", "innovation": "提出了类别中心引导的空间分配与角度-范数联合分类器（SAAN）学习框架，该框架为所有类别提供了平衡的空间，并利用样本不平衡导致的范数差异来增强分类标准。该方法具体解决了以下两个挑战：对于挑战 (i)，SAAN 将特征空间划分为多个子空间，并通过引导样本按照预设类别中心为每次会话分配一个专用子空间。对于挑战 (ii)，SAAN 为每个类别建立范数分布并生成角度-范数联合逻辑值，从而实现了最先进的性能，并能够直接嵌入其他现有的最佳方法中，进一步增强其性能", "conclusion": "实验表明，SAAN 可以实现最先进的性能，并且可以直接嵌入其他SOTA方法中作为插件，进一步提高其性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.09626", "html_url": "https://arxiv.org/abs/2412.09626", "title": "FreeScale: 通过无调优尺度融合解锁扩散模型的分辨率", "title_en": "FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion", "authors": "Haonan Qiu,Shiwei Zhang,Yujie Wei,Ruihang Chu,Hangjie Yuan,Xiang Wang,Yingya Zhang,Ziwei Liu", "background": "视觉扩散模型已经取得了显著的进步，但由于缺乏高分辨率的数据和计算资源的限制，这些模型通常仅在受限的分辨率下进行训练。这阻碍了它们在更高分辨率下生成高保真度图像或视频的能力。最近的研究探索了无需调优的方法以发挥预训练模型在高分辨率视觉生成中的潜在能力，但这些方法仍然容易生成低质量且具有重复模式的视觉内容。关键问题在于，当模型生成的视觉内容超出其训练分辨率时，高频率信息不可避免地增加，会导致累积错误引发的不受欢迎的重复模式。", "innovation": "我们提出了FreeScale，一种无需调优的推理范式，通过尺度融合来实现更高分辨率的视觉生成。FreeScale 通过处理不同感受野尺度的信息，然后通过提取所需的频率成分进行融合，从而解决了生成过程中出现的高频率信息增加、导致不可取的重复模式的问题。", "conclusion": "大量的实验验证了我们所提出范式在扩展图像和视频模型的高分辨率视觉生成能力方面的优越性。与之前表现最好的方法相比，FreeScale 首次解锁了 8k 分辨率的文本到图像生成。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.17907", "html_url": "https://arxiv.org/abs/2407.17907", "title": "使用扩散先验蒸馏的擬先驗采样", "title_en": "Amortized Posterior Sampling with Diffusion Prior Distillation", "authors": "Abbas Mammadov,Hyungjin Chung,Jong Chul Ye", "background": "本文提出了Aposterior采样（APS）方法，这是一种针对逆问题中的有效后验采样的新颖变分推理方法。该方法通过训练条件流模型以最小化变分分布与由扩散模型隐式定义的后验分布之间的差异，实现了强大的、模块化的采样器。这种方法能够通过单次神经网络函数评估生成多种多样化的后验样本，并能够在不同测量数据上进行泛化。", "innovation": "本文提出的方法，Amortized Posterior Sampling (APS)，是一种全新的变分推理方法，用于逆问题中的高效后验采样。与现有方法不同，APS 是无监督的，不需要配对训练数据，并且适用于欧几里得和非欧几里得域。此外，该方法通过使用扩散先验蒸馏来训练条件流模型，使得能够生成多样化的后验样本，并且只需一次神经函数评估即可实现。", "conclusion": "本文方法在一系列任务，包括图像恢复、流形信号重构和气候数据插补中展现了有效性。APS 方法在计算效率上显著优于现有方法，同时保持了竞争力的重建质量，能够实现不同领域的逆问题的实时高质量解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.05928", "html_url": "https://arxiv.org/abs/2502.05928", "title": "ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images", "title_en": "ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images", "authors": "Hongyu Ge,Longkun Hao,Zihui Xu,Zhenxin Lin,Bin Li,Shoujun Zhou,Hongjin Zhao,Yihang Liu", "background": "医疗视觉问答（Med-VQA）是通用视觉问答（VQA）领域中的一个重要且具有挑战性的子任务。尽管在通用VQA领域取得了显著进展，但在处理多任务VQA场景时，多模态大语言模型（MLLMs）仍表现出显著的局限性，这些问题主要体现在错误的空间定位和对医学图像的误读，主要原因是图像-文本对齐不足以及缺乏特定于医疗应用的医学知识。", "innovation": "为了应对这些问题，作者提出了跨模态临床知识蒸馏器（ClinKD），这是一种创新的框架，旨在增强图像-文本对齐，并建立更有效的医学知识转换机制，使MLLMs即使缺乏先验医学知识也能表现更好。广泛的实验评估证明，ClinKD在多个Med-VQA任务具有挑战性数据集上的性能达到了最先进的水平。研究结果表明，我们的方法不仅显著提高了图像-文本对齐，而且有效地帮助MLLMs适应医学知识。", "conclusion": "实验结果表明，ClinKD不仅能显著提高图像-文本对齐，还能有效帮助多模态大语言模型适应特定于医疗应用的医学知识，并在多个Med-VQA任务具有挑战性的数据集上达到了最先进的性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08525", "html_url": "https://arxiv.org/abs/2503.08525", "title": "GTR: 引导思维强化学习预防基于RL的VLM代理训练中的思维坍塌", "title_en": "GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training", "authors": "Tong Wei,Yijun Yang,Junliang Xing,Yuanchun Shi,Zongqing Lu,Deheng Ye", "background": "Reinforcement learning with verifiable outcome rewards (RLVR) 已在大规模语言模型 (LLMs) 中有效扩展了思维链 (CoT) 推理。然而，其在训练视觉语言模型（VLM）代理进行目标导向的动作推理方面的有效性在视觉环境中尚未得到充分验证。本研究通过在复杂的纸牌游戏和ALFWorld中的具身任务上进行大量的实验，探讨了该问题。当奖励仅基于行动结果时，RL无法激励VLM中的CoT推理，反而导致我们所称的“思维坍塌”现象，表现为代理思维的迅速同质化，与状态无关且不完整的推理，以及随后的无效行为，导致负面奖励。", "innovation": "提出了一种名为GTR（Guided Thought Reinforcement，引导思维强化学习）的简单且可扩展框架，通过在每个RL步骤中评估和改进代理的推理来对抗思维坍塌。该框架不需要密集的每步骤人类标注，即可同时训练推理和行动。实验表明，GTR显著提高了LLaVA-7b模型在各种视觉环境中的性能和泛化能力，任务成功率提高了3-5倍，且相较于具有更小模型规模的现有最佳模型（SoTA）表现更为出色。", "conclusion": "GTR框架有效防止基于RL的VLM代理训练中的思维坍塌，通过评估和改进代理的推理来提高其在视觉环境中的性能和泛化能力，同时保持相对较小的模型规模。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09131", "html_url": "https://arxiv.org/abs/2503.09131", "title": "MP-HSIR: 多提示框架在通用高光谱图像恢复中的应用", "title_en": "MP-HSIR: A Multi-Prompt Framework for Universal Hyperspectral Image Restoration", "authors": "Zhehui Wu,Yong Chen,Naoto Yokoya,Wei He", "background": "高光谱图像(HSIs)在成像过程中通常会遭受多种未知退化，导致严重的光谱和空间失真。现有的HSI恢复方法通常依赖于特定的退化假设，这限制了它们在复杂场景中的有效性。", "innovation": "本文提出了一种名为MP-HSIR的新颖多提示框架，该框架有效结合了光谱、文本和视觉提示，以实现针对各种退化类型和程度的通用HSI恢复。该方法开发了一个提示引导的空间光谱变换器，该变换器结合了空间自注意和提示引导的双分支光谱自注意。谱提示被引入到局部光谱分支中，以提供先验知识，提高光谱重建效果。此外，文本-视觉协同提示通过结合高层次语义表示和细微的视觉特征来编码退化信息，从而引导恢复过程。", "conclusion": "广泛的实验结果表明，MP-HSIR不仅在所有的HSI恢复任务中表现出色，而且在其多项任务中超越了最先进的任务特定方法。所有代码和模型均在此处提供：this https URL."}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.20287", "html_url": "https://arxiv.org/abs/2503.20287", "title": "InsViE-1M：依靠详细数据集构建的有效基于指令的视频编辑", "title_en": "InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction", "authors": "Yuhui Wu,Liyi Chen,Ruibin Li,Shihao Wang,Chenxi Xie,Lei Zhang", "background": "基于指令的视频编辑能够通过简单的指令实现视频的交互式编辑，而无需额外的输入如遮罩或属性。然而，收集高质量的训练三元组（原始视频、编辑后的视频、指令）是一项具有挑战性的任务。现有数据集大多包含低分辨率、短时长和源视频数量有限的问题，这些限制了训练模型的效果。", "innovation": "本文提出了一种名为InsViE-1M的高质量基于指令的视频编辑数据集，包含了100万的三元组。通过精心筛选高清源视频和图像，并设计高效的编辑过滤管道来构建高质量的编辑三元组。此外，还提出了一个多阶段的学习策略来训练InsViE模型，逐步增强其指令跟随和编辑能力。", "conclusion": "广泛的实验表明，InsViE-1M数据集及训练的InsViE模型在效果上优于现有最佳工作。相关代码可在InsViE获得。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.17414", "html_url": "https://arxiv.org/abs/2502.17414", "title": "X-Dancer：从音乐到人类舞蹈视频的表达生成", "title_en": "X-Dancer: Expressive Music to Human Dance Video Generation", "authors": "Zeyuan Chen,Hongyi Xu,Guoxian Song,You Xie,Chenxu Zhang,Xin Chen,Chao Wang,Di Chang,Linjie Luo", "background": "当前，多数方法主要生成3D人体运动，这些方法在数据和规模上存在局限。X-Dancer聚焦解决这一问题，通过模型来表现广泛维度的2D舞蹈动作，并捕捉不同音乐节拍的精致对齐方式，利用单目视频数据增强模型的可用性和扩展性。", "innovation": "X-Dancer提出了一种统一的变压器-扩散框架，结合了一个自回归变压器模型，该模型可以合成和音乐同步的2D身体、头部和手部姿态序列，这些序列引导扩散模型生成连贯且逼真的舞蹈视频帧。X-Dancer通过空间组合姿态标签实现了一种新的令牌表示方法，能够编码大范围动作以及细粒度的动作。然后，设计了一种音乐到动作的自回归生成模型，可以生成与音乐时间线齐心的舞蹈姿态序列，并结合全局注意以捕捉音乐风格和先验运动上下文。最后通过AdaIN机制将参考图转化为动画，形成一个端到端可训练的框架。这些创新大大提高了模型的生成多样性、表达能力和逼真度，显著优于现有方法。", "conclusion": "实验结果表明，X-Dancer能够生成多样且具特性的舞蹈视频，在多样性、表现力和逼真度方面明显超越现有最先进的方法。代码和模型将用于研究目的。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07499", "html_url": "https://arxiv.org/abs/2503.07499", "title": "AthletePose3D: 运动表现中的三维人体姿态估计和动捕验证基准数据集", "title_en": "AthletePose3D: A Benchmark Dataset for 3D Human Pose Estimation and Kinematic Validation in Athletic Movements", "authors": "Calvin Yeung,Tomohiro Suzuki,Ryota Tanaka,Zhuoer Yin,Keisuke Fujii", "background": "三维人体姿态估计在计算机视觉和运动生物力学中是一个关键任务，应用于运动科学、康复和生物力学研究。尽管在单目3D姿态估计方面取得了重要进展，现存的数据集往往难以捕捉到类似竞技运动中的复杂、高加速度动作。因此，本文介绍了AthletePose3D，这是一个新颖的数据集，旨在填补这一空白。它包含了来自多个领域的12种运动类型，拥有约130万帧和16.5万个体姿态，特别地捕捉了高速、高加速度的运动表现。", "innovation": "AthletePose3D 数据集包含多种运动类型，并专门针对高加速度的运动捕捉设计。通过使用最先进的（SOTA）单目2D和3D姿态估计模型在该数据集上的评估，研究发现传统的数据集训练模型在运动姿态估计上表现不佳。然而，通过对AthletePose3D的微调，SOTA模型的关节位置平均误差（MPJPE）从214毫米降低到了65毫米，降低了超过69%。此外，通过对单目姿态估计的时域分析验证了其动力学准确性，结果显示在关节角度估计中有强烈的关联性，但在速度估计上存在限制。", "conclusion": "本研究为运动场景下提供了单目姿态估计模型的全面评估，为提升高性能运动环境下的单目姿态估计技术提供了有价值的经验。该数据集、代码和模型检查点可以在以下链接中获取:这一链接。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11540", "html_url": "https://arxiv.org/abs/2412.11540", "title": "SP$^2$T: 稀疏代理注意机制的双流点变换器", "title_en": "SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer", "authors": "Jiaxu Wan,Hong Zhang,Ziqi He,Yangyan Deng,Qishu Wang,Ding Yuan,Yifan Yang", "background": "点变换器通过扩大感受野（RF）在3D理解方面取得了显著进步，但进一步扩大RF会导致组注意力的稀释和详细特征提取能力的下降。现有的基于代理的方法存在一些局限性：全局代理会在大规模点云中引起二次复杂度问题并导致位置模糊，而局部代理则难以处理从几何多样性点云中进行不可靠抽样、代理交互计算效率低下以及局部和全局信息融合不平衡的问题。", "innovation": "为了解决上述挑战，作者提出了Sparse Proxy Point Transformer (SP$^{2}$T) ——一种基于局部代理的双流点变换器，具有三大创新点：第一，通过基于顶点的关联进行空间代理采样，实现对几何多样性点云的稳健采样；第二，通过基于表格的相对偏置稀疏代理注意机制，以高效映射减少计算的方式实现代理交互；第三，双流架构通过并行分支保持局部和全局信息的平衡。", "conclusion": "SP$^{2}$T在室内和室外3D理解基准测试中实现了领先的准确率，表现出色的延迟，并相比其他基于代理的点云方法，SP$^{2}$T在mIoU指标上显著提高了3.8%和22.9%，分别对比SPoTr@S3DIS和PointASNL@Sem.KITTI方法。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.00901", "html_url": "https://arxiv.org/abs/2504.00901", "title": "近十年深度学习在遥感时空融合中的进展、挑战及机遇", "title_en": "A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities", "authors": "Enzhe Sun,Yongchuan Cui,Peng Liu,Jining Yan", "background": "遥感时空融合（STF）通过结合高时间分辨率低空间分辨率和高空间分辨率低时间分辨率的影像，解决了时间和空间分辨率之间的根本权衡。过去十年间，深度学习在遥感STF中的应用取得了显著进展，但现有的研究较为零散，缺乏系统性的总结。该文旨在对这一领域进行全面概述，分析过去十年深度学习方法在遥感STF中的应用，并揭示存在的问题和未来的机会，以促进该领域的进一步发展.", "innovation": "文章建立了深度学习架构的系统分类，包括卷积神经网络（CNNs）、Transformer、生成对抗网络（GANs）、扩散模型和序列模型，显示了其深度学习在STF任务中的重要性增长。研究指出基于CNN的方法在空间特征提取方面占主导地位，而Transformer结构在捕捉长程时间依赖性方面表现出色。GAN和扩散模型在细节重建方面表现出色，显著优于传统方法在结构相似性和光谱保真度方面。通过对七个基准数据集上十个代表性方法的全面实验验证了这些发现，并量化了不同方法之间的性能权衡。文章识别出五个关键挑战：时空冲突、跨数据集的一般化受限、大规模处理的计算效率、多源异质融合和基准多样性不足。", "conclusion": "该论文总结了基于深度学习的遥感STF领域的进展，并指出了存在的挑战，同时还提出了前景广阔的机会，包括基础模型、混合架构和自我监督学习方法，这些都有助于解决当前的局限性，推动多模态应用的发展。所有提及的具体模型、数据集及相关信息可查询此网址：thishttpsURL."}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17224", "html_url": "https://arxiv.org/abs/2504.17224", "title": "VLLMs中的视觉和文本提示在增强情绪识别中的应用", "title_en": "Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition", "authors": "Zhifeng Wang,Qixuan Zhang,Peter Zhang,Wenjia Niu,Kaihao Zhang,Ramesh Sankaranarayana,Sabrina Caldwell,Tom Gedeon", "background": "视觉大型语言模型（VLLMs）在多模态理解方面展示出潜在的应用前景，但在基于视频的情绪识别中应用受限于其对空间和上下文感知的不足。传统的基于视频的情绪识别方法通常着重于孤立的面部特征，而忽视了身体语言、环境背景和社会互动等关键非语言线索，导致在实际应用场景中的鲁棒性降低。", "innovation": "本文提出了一种名为Set-of-Vision-Text Prompting（SoVTP）的新型框架，通过将空间注释（例如，边界框、面部特征点）、生理信号（面部动作单元）和上下文线索（身体姿势、场景动态、他人的情绪）统一到一种提示策略中来提升零样本情绪识别的性能。SoVTP既保留了全面的场景信息，又能够精细分析面部肌肉运动和人际动态，相较于现有的视觉提示方法取得了显著的改进，并证明了其增强VLLMs视频情绪识别能力的有效性。", "conclusion": "实验结果表明，SoVTP在零样本情绪识别任务上显著提升了现有的视觉提示方法的效果，展示了其在提高VLLMs的情绪识别能力方面的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.10012", "html_url": "https://arxiv.org/abs/2504.10012", "title": "EBAD-Gaussian: 事件驱动的束调整去模糊高斯散点图", "title_en": "EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting", "authors": "Yufei Deng,Yuanjian Wang,Rong Xiao,Chenwei Tang,Jizhe Zhou,Jiahao Fan,Deng Xiong,Jiancheng Lv,Huajin Tang", "background": "尽管3D高斯散点图(3D-GS)能够实现逼真的新颖视图合成，但在快速运动或低光照条件下，其性能会下降。现有的基于RGB的去模糊方法在捕捉曝光期间的相机姿态和辐射变化方面表现不佳，降低了重建精度。而事件相机，能够捕捉在曝光期间连续的亮度变化，有助于更好地建模运动模糊并提高重建质量。", "innovation": "提出了一种基于事件驱动的束调整去模糊高斯散点图（EBAD-Gaussian），该方法从事件流和严重模糊的图像中重建清晰的3D高斯图像。具体而言，通过合成曝光期的多个潜在清晰图像来构建模糊损失函数，最小化实际和合成模糊图像间的差异。利用事件流监督曝光期间任意时间的潜在清晰图像之间的光照强度变化，补充了RGB图像中丢失的光照强度动态变化。进一步基于事件驱动的双重积分(EDI)先验优化中间曝光时间的潜在清晰图像，增强重建图像的细节和纹理信息。", "conclusion": "广泛的合成和实际数据集上的实验表明，在模糊图像和事件流输入条件下，EBAD-Gaussian能够实现高质量的3D场景重建。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.06897", "html_url": "https://arxiv.org/abs/2504.06897", "title": "MedSegFactory：由文本指导生成医学图像-掩码对", "title_en": "MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs", "authors": "Jiawei Mao,Yuhan Wang,Yucheng Tang,Daguang Xu,Kang Wang,Yang Yang,Zongwei Zhou,Yuyin Zhou", "background": "目前医学成像领域缺乏高质量、多样化、大规模的训练数据集，这限制了机器学习方法在医学图像分析中的快速发展。已经有一些合成医学图像和标注数据的方法，但这通常局限于特定的任务和数据模态，难以满足多样化和动态需求。", "innovation": "本文提出了MedSegFactory，这是一种多功能的医学合成框架，能够生成高度质量的跨模态的医学成像和分割掩码的数据对。其核心是一个双流扩散模型，其中一个流合成医学图像，另一个生成相应的分割掩码。通过引入联合交叉注意力（JCA），MedSegFactory实现了一个交互式的去噪过程，能够根据用户定义的提示，生成特定目标标签、成像模态、解剖区域和病理条件的数据对，增强了数据生成的一致性，同时解决了数据稀缺性和监管限制问题。", "conclusion": "实验结果表明，MedSegFactory能够生成高质量和实用的数据，对于2D和3D分割任务，其性能可达到竞争级别或达到最新技术水平，同时成功地将医学图像合成过程整合到各种医学成像工作流中，提高了效率和准确性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08423", "html_url": "https://arxiv.org/abs/2505.08423", "title": "DArFace: 面对低质量面部识别的变形感知鲁棒性", "title_en": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition", "authors": "Sadaf Gulshad,Abdullah Aldahlawi Thakaa", "background": "面部识别系统通过利用深度神经网络、先进的损失函数和大规模数据集取得了显著的成功。然而，在处理低质量面部图像（如监视录像中的图像）时，这些系统的表现往往会下降，低分辨率、运动模糊和各种失真会导致与训练时使用的高质量数据之间的显著领域差异。尽管现有方法试图通过修改网络架构或建模全局空间变换来增强鲁棒性，但这些方法经常忽视实际上在真实环境中存在的局部非刚性变形。", "innovation": "我们提出了一种名为DArFace的变形感知鲁棒面部识别框架，该框架在不需要配对的高/低质量训练样本的情况下，增强对这些退化条件的鲁棒性。该方法在训练过程中对抗性地整合全局变换（如旋转、平移）和局部弹形变形，以模拟真实低质量条件，并引入对比目标来强制多变体视图上身份一致性。", "conclusion": "在TinyFace、IJB-B和IJB-C等低质量基准测试上的广泛评估表明，DArFace超越了最先进的方法，局部变形建模的包括显著提升了鲁棒性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.13078", "html_url": "https://arxiv.org/abs/2504.13078", "title": "MGT: Extending Virtual Try-Off to Multi-Garment Scenarios", "title_en": "MGT: Extending Virtual Try-Off to Multi-Garment Scenarios", "authors": "Riza Velioglu,Petra Bevandic,Robin Chan,Barbara Hammer", "background": "计算机视觉正在通过虚拟试穿（VTON）和虚拟脱衣（VTOFF）改变时尚产业。VTON通过给定目标照片和标准服装图像生成穿着特定服装的人体图像。相比之下，VTOFF从穿着衣服的个人的照片中提取标准服装图像。p2p-VTON是一种更具挑战性的变体，使用另一人穿着同一件服装的照片来进行虚拟试穿。现有模型在处理不同类型的服装时存在局限性，MGT则旨在解决这一问题，提出了一种能够处理包括上身、下身和连衣裙在内的各种服装类型的扩散式VTOFF模型。", "innovation": "MGT 是一种基于扩散的 VTOFF 模型，能够处理多种类型的服装，包括上衣、下装和连衣裙。该模型采用了潜扩散架构和基于 SigLIP 的图像条件，以捕捉服装的形状、纹理和图案等特征。为了应对服装的多样性，MGT 引入了类别的特定嵌入，达到了 VITON-HD 上的最先进的 VTOFF 结果，并在 DressCode 上获得了竞争力的表现。当与 VTON 模型结合使用时，MGT 进一步增强了 p2p-VTON，减少了不必要的属性转移，如肤色，从而保持了个人特有的特征。MGT 的演示、代码和模型已提供。", "conclusion": "MGT 通过其独特的架构和特征捕捉方法，解决了传统 VTOFF 模型在处理多样服装时的局限性，实现了更优秀的表现，并为进一步的多服装类型应用奠定了基础，在虚拟试穿技术的发展中具有重要意义。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.00136", "html_url": "https://arxiv.org/abs/2412.00136", "title": "FonTS: 文字渲染中的字型和风格控制", "title_en": "FonTS: Text Rendering with Typography and Style Controls", "authors": "Wenda Shi,Yiren Song,Dengming Zhang,Jiaming Liu,Xingxing Zou", "background": "视觉文本渲染在许多实际应用中都很普遍，需要仔细选择字体和排版选择。基于扩散变换器(DiT)的文本生成图像(T2I)模型在自动化这一过程方面取得了进步。然而，这些方法仍然面临挑战，如字体不一致、风格变化以及在单词级别上控制有限。", "innovation": "本文提出了一种两阶段的DiT基管道方法，通过增强对字体和风格在文本渲染中的控制来解决这些问题。引入了字体控制微调(TC-FT)，这是一种参数效率高的微调方法(对5%的关键参数进行微调)，并使用封闭的字体控制标记(ETC标记)，以实现对字体特性的精确单词级别应用。为了解决文本渲染中的风格不一致性问题，提出了文本无感知风格控制适配器(SCA)，防止内容泄漏同时提高风格一致性。通过将HTML渲染集成到数据合成管道中，并提出首个可控制的单词级别数据集来实施TC-FT和SCA。", "conclusion": "通过全面的实验，证明了本文方法在单词级别达到更好的字型控制、字体一致性以及风格一致性。数据集和模型将可供学术研究使用。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11868", "html_url": "https://arxiv.org/abs/2505.11868", "title": "MonoMobility：单一视角视频中零样本3D移动分析", "title_en": "MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos", "authors": "Hongyi Zhou,Yulan Guo,Xiaogang Wang,Kai Xu", "background": "在动态环境中准确分析运动部分及其运动属性对于推动关键技术领域（例如具身智能）至关重要。现有的方法要么依赖密集的多视角图像，要么需要详细的部分级注释，这些方法存在一定的局限性。本研究旨在提出一种创新框架，能够仅通过单一视角视频在零样本情况下分析3D移动。", "innovation": "该框架能够仅使用单一视角视频进行精确的运动部分和运动属性解析，完全不需要标注训练数据。首先，该方法通过深度估计、光学流分析和点云注册方法构建场景几何并粗略分析运动部分及其初始运动属性；接着，利用2D高斯点绘制进行场景表示。进一步引入了一种专用于 articulated 对象的端到端动态场景优化算法，细化初始分析结果，使其能够处理‘旋转’、‘平移’，甚至复杂运动（‘旋转+平移’），显示了其高度的灵活性和通用性。", "conclusion": "为了验证该方法的稳健性和广泛适用性，构建了一套综合数据集，涵盖模拟和现实场景。实验结果表明，该框架能够无标注地有效分析 articulated 物体运动，展示了其在未来具身智能应用中的巨大潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.18906", "html_url": "https://arxiv.org/abs/2504.18906", "title": "Sim-to-Real: 一种无监督噪声层的屏幕相机水印鲁棒性方法", "title_en": "Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness", "authors": "Yufeng Wu,Xin Liao,Baowei Wang,Han Fang,Xiaoshuai Wu,Guiling Wang", "background": "未经授权的屏幕截图捕获和传播引发了严重的安全威胁，如数据泄露和信息盗窃。许多研究提出了鲁棒的水印方法，用于追踪屏幕-相机（SC）图像的版权，以在事后对抗侵权进行认证。这些技术通常使用启发式的数学建模或监督神经网络拟合作为噪声层，以增强鲁棒性。然而，这两种策略都不能从根本上有效模拟SC噪声。数学模拟会因噪声的不完全分解和噪声各部分之间的独立性缺失而导致偏差。监督网络需要配对数据来训练噪声拟合模型，模型难以学习所有噪声的特征。", "innovation": "该研究提出了一种Sim-to-Real（S2R）方法。该方法采用无监督噪声层，利用未配对数据来学习模拟的拟合噪声分布与实际世界SC噪声分布之间的差异，而不是直接学习锐化图像到实际世界图像之间的映射。这种从模拟到现实的学习过程从本质上更简单，主要集中在噪声分布之间的差距，而非重建图像的精细细节。实验结果验证了该方法的有效性，显示了优于最先进的方法的鲁棒性和泛化能力。", "conclusion": "本研究通过提出Sim-to-Real（S2R）方法，提供了优于现有方法的屏幕相机水印鲁棒性。其主要创新在于使用无监督学习来增强水印的鲁棒性，通过学习模拟与实际SC噪声之间的差异，提高了水印对抗屏幕相机捕获的能力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03942", "html_url": "https://arxiv.org/abs/2506.03942", "title": "医疗图像分割中的平均校准损失用于可靠的不确定性", "title_en": "Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation", "authors": "Theodore Barfoot,Luis C. Garcia-Peraza-Herrera,Samet Akcay,Ben Glocker,Tom Vercauteren", "background": "深度神经网络在医疗图像分割中往往过于自信，这降低了可靠性和临床应用的价值。现有的方法有时无法有效地调整像素级的校准误差，从而制约了其性能提升。为了改善这一问题，本文提出了一种基于mL1-ACE（边缘L1平均校准误差）的可微分校准损失。这种方法可以直接在图像级别改进像素级的校准。实验结果表明，将该损失函数加入训练可以显著降低校准误差，特别是在平均校准误差和最大校准误差方面，同时保持高质量的Dice相似系数。", "innovation": "本文提出了一种基于mL1-ACE的可微分校准损失，它可以作为辅助损失在图像级别计算。与硬分箱和软分箱方法相比，软分箱方法在骰子系数和交叉熵损失的基础上取得了最大的校准改进，尽管有时会牺牲分割性能。为评估校准性能及其在数据集中的变异性，本文还引入了数据集可靠性直方图这一方法，这一分析突显了预测置信度与真实准确性的更好对齐。", "conclusion": "本文的方法不仅提高了分割预测的可信度，还展现了将深度学习方法安全集成到临床工作流程中的潜力。通过软分箱mL1-ACE损失的加入，可以获得更精确的校准效果，尽管与Dice和交叉熵损失组合相比，会有所下降的分割性能。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11992", "html_url": "https://arxiv.org/abs/2505.11992", "title": "SpatialCrafter: 利用视频扩散模型在有限观测条件下释放场景重建的想象力", "title_en": "SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations", "authors": "Songchun Zhang,Huiyao Xu,Sitong Guo,Zhongwei Xie,Hujun Bao,Weiwei Xu,Changqing Zou", "background": "新型视角合成（NVS）增强了计算机视觉和图形中的沉浸式体验。现有的技术尽管取得了进步，但依赖密集的多视角观测，限制了其应用范围。这项工作致力于从稀疏或单视角输入中重建具象的真实三维场景的挑战。现有的方法通过采用可训练的相机编码器和李普希茨注意力机制引入了明确的几何约束，实现了精确的相机控制和3D一致性，进一步通过统一的尺度估计策略处理不同数据集之间的尺度差异。此外，通过结合单目深度先验和语义特征在视频潜在空间中，框架直接回归三维高斯原语并使用混合网络结构高效处理长序列特征。", "innovation": "提出了SpatialCrafter框架，利用视频扩散模型丰富的知识来生成合理的额外观测，从而减轻重建的歧义性。通过可训练的相机编码器和李普希茨注意力机制实现精确的相机控制和3D一致性，进一步通过统一的尺度估计策略处理不同数据集间的尺度差异。框架还直接回归3D高斯原语，并通过混合网络结构高效处理长序列特征，结合单目深度先验和语义特征在视频潜在空间中。", "conclusion": "广泛的实验表明，本方法增强了稀疏视角的重建并恢复了三维场景的真实外观。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22511", "html_url": "https://arxiv.org/abs/2506.22511", "title": "使用生成式人工智能照亮夜晚", "title_en": "Lighting the Night with Generative Artificial Intelligence", "authors": "Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang", "background": "在气象观测中，来自静止气象卫星的可见光反射率数据至关重要，对于天气监测和预报非常重要。然而，由于夜间缺乏可见光，无法全天候持续进行可见光反射率数据观测。因此，这项研究开创性地利用生成扩散模型来解决这一限制问题，基于风云-4B (FY4B) 静止气象卫星搭载的先进静止辐射成像仪(AGRI)的多波段热红外亮度温度数据，开发了一种高精度的可见光反射率生成模型，称为亮度扩散（RefDiff），这种模型能够在夜间生成0.47μm, 0.65μm和0.825μm波段的可见光反射率。与经典模型相比，RefDiff不仅通过集合平均显著提高了精度，还提供了不确定性估计。", "innovation": "这项研究提出了使用生成扩散模型（RefDiff）生成夜间可见光反射率的新方法，该方法利用风云-4B静止气象卫星搭载的AGRI多波段热红外亮度温度数据生成夜间可见光反射率。与经典模型相比，RefDiff通过集合平均显著提高了精度，并提供不确定性估计，特别是在复杂云结构和厚云区域表现尤为显著，达到了0.90的SSIM指数。此外，该模型夜间生成能力验证与白天性能相当，显示出巨大的应用潜力，可扩展夜间可见光数据的应用范围。", "conclusion": "这项研究在夜间生成可见光反射率方面取得了实质性进展，增加了夜间可见光数据的应用潜力。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02358", "html_url": "https://arxiv.org/abs/2507.02358", "title": "Hita: Holistic Tokenizer for Autoregressive Image Generation", "title_en": "Hita: Holistic Tokenizer for Autoregressive Image Generation", "authors": "Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi", "background": "现有的自回归（AR）图像生成模型通过逐个生成视觉令牌来工作，这限制了它们捕捉令牌序列之间整体关系的能力。大多数视觉令牌化器将局部图像块映射到潜在令牌中，导致全局信息有限。因此，现有方法难以生成具有复杂整体结构的高质量图像。", "innovation": "Hita 是一种新颖的图像令牌化器，适用于自回归图像生成。它提出了整体到局部的令牌化方案，使用可学习的整体查询和局部补丁令牌。Hita 通过两种关键策略更好地适应了自回归生成过程：1) 分别使用整体令牌开始的序列结构，并紧接着使用补丁级别的令牌；并且通过因果自注意力来维持对先前令牌的关注；2) 使用轻量级融合模块，在将去量化令牌输入解码器之前，控制信息流动并优先处理整体令牌。", "conclusion": "广泛的实验表明，Hita 加速了自回归生成器的训练速度，并且在 ImageNet 基准上优于使用普通令牌化器训练的方法，实现了 2.59 FID 和 281.9 IS 的成绩。详细的全局表征分析显示了其捕获全局图像特性（如纹理、材料和形状）的能力，并且 Hita 还在零样本样式转移和图像修复中表现出有效性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02899", "html_url": "https://arxiv.org/abs/2507.02899", "title": "使用多道路监控摄像头在交叉路口学习生成矢量地图", "title_en": "Learning to Generate Vectorized Maps at Intersections with Multiple Roadside Cameras", "authors": "Quanxin Zheng,Miao Fan,Shengtong Xu,Linghe Kong,Haoyi Xiong", "background": "矢量地图对于精确导航和自动驾驶车辆的安全操作至关重要。传统的地图构建方法主要分为两类：离线技术依赖昂贵且劳动密集型的激光雷达数据收集和手动标注，而在线方法虽然可以降低成本，但在复杂交叉路口的应用中表现受限。为解决这些问题，本文提出了一种新的方法MRC-VMap，利用现有的路边监控摄像头直接生成高精度矢量地图。", "innovation": "MRC-VMap是一种低成本、基于视觉的端到端神经网络，能够直接在交叉路口生成高精度矢量地图。其创新点包括：1) 利用现有路边监控摄像头，直接将时间对齐、多方向图像转换为矢量地图表示；2) 省去了中间模块，减少了计算量和错误传播；3) 多摄像头视角的应用提高了地图的完整性和鲁棒性，减少了实际部署中的遮挡问题。", "conclusion": "通过在中国4大城市4000个交叉路口的广泛实验，MRC-VMap不仅超越了现有的在线方法，而且在精度上可与高成本激光雷达方法媲美，提供了可扩展且高效的现代自动驾驶导航系统的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02827", "html_url": "https://arxiv.org/abs/2507.02827", "title": "USAD: 通过空间时间注意力扩散模型实现端到端的人体活动识别", "title_en": "USAD: End-to-End Human Activity Recognition via Diffusion Model with Spatiotemporal Attention", "authors": "Hang Xiao,Ying Yu,Jiarui Li,Zhifan Yang,Haotian Tang,Hanyu Liu,Chao Li", "background": "人类行为识别（HAR）的主要目标是从传感器数据推断持续的人类活动，这一任务在健康管理、安全保护和体育分析等方面有着广泛的应用。尽管进行了大量研究，但HAR仍然面临数据稀疏性、特征提取不足和模型性能欠佳等关键挑战，尤其是对于稀有活动的标签样本不足，以及在轻量级设备上的性能不高。", "innovation": "提出了一种综合优化方法，基于多注意交互机制。首先，使用无监督的方法和统计指导的扩散模型进行数据增强，以解决标签数据稀缺和严重类别不平衡的问题。其次，设计了一种多分支空间时间交互网络，通过并行的3×3、5×5和7×7卷积核残差分支来捕获序列数据的多尺度特征，同时还加入了时序注意机制来识别关键时间点，以及空间注意机制来提升传感器之间的交互。随后，引入了一个交叉分支特征融合单元以提高整体特征表示能力。最后，集成了一种自适应多损失函数融合策略，以便动态调整损失权重并优化整体模型。", "conclusion": "在公开数据集WISDM、PAMAP2和OPPORTUNITY上的实验结果表明，所提出的无监督数据增强空间时间注意力扩散网络（USAD）分别实现了98.84%、93.81%和80.92%的准确率，明显优于现有方法。此外，实际部署在嵌入式设备上的验证证明了该方法的有效性和实用性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.09150", "html_url": "https://arxiv.org/abs/2405.09150", "title": "Curriculum Dataset Distillation", "title_en": "Curriculum Dataset Distillation", "authors": "Zhiheng Ma,Anjia Cao,Funing Yang,Yihong Gong,Xing Wei", "background": "大多数数据集精炼方法在处理大规模数据集时面临巨大挑战，因为它们需要大量计算和内存资源。最新的研究开始探索可扩展的解耦方法，但仍存在性能瓶颈和优化空间。", "innovation": "本文提出了一个基于课程的数据集精炼框架，旨在平衡性能和可扩展性。该框架战略性地精炼合成图像，遵循从简单到复杂的课程。通过结合课程评估，本文解决了之前方法生成的图像通常单一且简单的问题，并在可管理的计算成本下实现了这一点。此外，引入了针对合成图像的对抗优化，进一步提高了其代表性并防止其过度拟合参与精炼的神经网络。这提高了精炼图像在各种神经网络架构上的泛化能力，并增强了其对噪声的鲁棒性。", "conclusion": "大量的实验表明，本文的框架在大规模数据集精炼方面设立了新的标准，在Tiny-ImageNet上实现了11.1%的显著改进，在ImageNet-1K上实现了9.0%的提升，在ImageNet-21K上实现了7.3%的提升。我们的精炼数据集和代码可以通过提供的链接访问。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05730", "html_url": "https://arxiv.org/abs/2507.05730", "title": "高光谱异常检测方法：综述与比较研究", "title_en": "Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study", "authors": "Aayushma Pant,Arbind Agrahari Baniya,Tsz-Kwan Lee,Sunil Aryal", "background": "高光谱图像包含数百个连续的光谱波段，使其能够对材料和表面进行细致分析。高光谱异常检测（HAD）是指在没有事先了解光谱场景或目标光谱信息的情况下，识别和定位异常目标的技术。该技术在农业、国防、军事监视和环境监测等领域取得了显著进展，但现有的HAD方法仍然面临计算复杂度高、对噪声敏感和在不同数据集之间泛化能力有限等挑战。", "innovation": "本文对各种HAD技术进行了全面比较，将其分为统计模型、表示方法、经典机器学习方法和深度学习模型四类。使用17个基准数据集的不同性能指标（如ROC、AUC和可分离性图）评估这些方法的检测准确性、计算效率及其优缺点，并指明未来的研究方向。研究发现，深度学习模型在检测准确性上表现最佳，而统计模型具有在所有数据集上的出色速度。", "conclusion": "综上所述，该研究为高光谱异常检测方法的进一步发展提供了宝贵的见解，有助于研究人员和从业者推动该领域的发展。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07104", "html_url": "https://arxiv.org/abs/2507.07104", "title": "Vision-Language-Vision 自编码器：来自扩散模型的可扩展知识蒸馏", "title_en": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models", "authors": "Tiezheng Zhang,Yitong Li,Yu-cheng Chou,Jieneng Chen,Alan Yuille,Chen Wei,Junfei Xiao", "background": "构建具有强大配图能力的先进技术语言模型（VLMs）通常需要大规模的高质量图像-文本对进行训练，这需要成千上万的GPU小时。这项研究提出了Vision-Language-Vision（VLV）自编码器框架，该框架巧妙地利用了预训练组件：图像编码器、文本到图像（T2I）扩散模型的解码器以及大型语言模型（LLM）。通过固定T2I扩散模型的预训练解码器，建立语言表示的空间瓶颈，实现连续嵌入的综合语义理解并通过高质量重建。这种方法通过主要使用单模图像进行训练并最大化现有预训练模型（图像编码器、T2I扩散模型和LLM）的利用，减少了对大规模图像-文本数据集的需求。", "innovation": "该研究提出了一种Vision-Language-Vision（VLV）自编码器框架，该框架通过固定文本到图像（T2I）扩散模型的预训练解码器来建立语言表示空间的瓶颈，从而实现连续嵌入的信息瓶颈。此外，通过微调预训练的大型语言模型解码中间的语言表示来生成详细的描述，构建了具有竞争力的最先进的（SoTA）配图器。", "conclusion": "该方法具有极高的成本效率，并显著减少了数据需求。通过主要使用单模图像进行训练，并充分利用现有的预训练模型（图像编码器、T2I扩散模型和LLM），避免了对大规模图像-文本数据集的需要，总训练成本保持在1000美元以下。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07460", "html_url": "https://arxiv.org/abs/2507.07460", "title": "Objectomaly: 基于结构一致性与边界精度的对象觉察能量感知在离分布分割精炼", "title_en": "Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision", "authors": "Jeonghoon Song,Sunghun Kim,Jaegyun Im,Byeongjoon Noh", "background": "离分布（Out-of-Distribution, OoD）分割在如自动驾驶等安全性要求高的应用场景中至关重要。现有的基于掩码的方法在边界精度、对象内异常分数一致性以及背景噪声引起的误报方面表现不佳。", "innovation": "该研究提出了一个名为Objectomaly的对象觉察能量感知精炼框架，通过引入对象级先验来提高分割性能。框架包括三个阶段：粗略异常评分（Coarse Anomaly Scoring, CAS）、对象觉察能量感知评分校准（Objectness-Aware Score Calibration, OASC）、细致边界精度（Meticulous Boundary Precision, MBP）。该方法在关键的离分布分割基准测试中取得了最先进的性能，包括SMIYC AnomalyTrack/ObstacleTrack和RoadAnomaly，同时改善了像素级和组件级的指标。", "conclusion": "消融研究及在真实驾驶视频上的定性结果进一步验证了该方法的鲁棒性和普适性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.14371", "html_url": "https://arxiv.org/abs/2412.14371", "title": "SEREP：用于稳健户外面部表情捕捉和应用的语义面部表情表示", "title_en": "SEREP: Semantic Facial Expression Representation for Robust In-the-Wild Capture and Retargeting", "authors": "Arthur Josi,Luiz Gustavo Hafemann,Abdallah Dib,Emeline Got,Rafael M. O. Cruz,Marc-Andre Carbonneau", "background": "单目野外面部表情捕捉具有挑战性，因为捕捉条件、面部形状和表情多变。当前大多数方法依赖于线性3D可变形模型，在顶点位移层面独立表示面部表情，而不考虑身份。", "innovation": "提出了一种称为SEREP（语义表情表示）的新模型，该模型在语义层面上将表情与身份分离。首先，通过高质量、无配对的面部表情3D数据学习表情表示。然后，使用低质量的合成数据训练模型，预测单目图像中的表情，并采用了新颖的半监督方案。此外，还引入了一个新的MultiREX基准数据集，以解决表情捕捉任务缺乏评估资源的问题。", "conclusion": "实验结果表明，SEREP优于现有最先进的方法，能够捕捉具有挑战性的表情并将其转移到新的身份上。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07620", "html_url": "https://arxiv.org/abs/2507.07620", "title": "ViLU: 学习视觉语言的不确定性以进行失败预测", "title_en": "ViLU: Learning Vision-Language Uncertainties for Failure Prediction", "authors": "Marc Lafon,Yannis Karmim,Julio Silva-Rodríguez,Paul Couairon,Clément Rambour,Raphaël Fournier-Sniehotta,Ismail Ben Ayed,Jose Dolz,Nicolas Thome", "background": "视觉语言模型（VLMs）的可靠不确定性量化(UQ)和失败预测仍然是开放性的挑战。目前的方法多依赖于损失预测，这限制了在无法直接访问模型的情况下使用不确定性预测器的能力。", "innovation": "提出了一个新的视觉语言不确定性量化框架ViLU，通过结合视觉嵌入、预测的文本嵌入和基于图像条件的文本表征来构建一个不确定性感知的多模态表示。ViLU将不确定性预测器训练为二元分类器，使用加权二元交叉熵损失区分正确和错误的预测，使其对损失具有无感知性，特别适用于只能获取视觉和文本嵌入而不直接访问模型的后验场景。", "conclusion": "广泛的实验展示了ViLU方法相较于最先进的失败预测方法的显著优势。通过实验证明，我们的方法在ImageNet-1k、CC12M和LAION-400M等标准分类数据集和大规模图像-字幕数据集上都表现出了有效的不确定性量化效果。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07340", "html_url": "https://arxiv.org/abs/2507.07340", "title": "通过对比强化学习在视觉讲故事中的实体重识别", "title_en": "Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning", "authors": "Daniel A. P. Oliveira,David Martins de Matos", "background": "视觉故事讲述系统，尤其是大规模的视觉-语言模型，难以保持人物和物体的身份一致，经常无法识别不同图像中代表同一个人或物体的实体，导致不一致的指代和referential hallucinations。因为模型缺乏在不同帧间建立实体连接的显式训练。", "innovation": "提出了一种对比强化学习方法，用于训练模型区分相干图像序列和故事与不相关的图像。通过扩展故事推理数据集添加合成负例来教授适当的实体连接行为。使用直接偏好优化和双成分奖励函数，在真实故事中促进实体的定位和再识别，同时惩罚合成上下文中不正确的实体连接。本文通过这种方法微调了Qwen故事讲述者（基于Qwen2.5-VL 7B）。评估结果显示，在实体定位mAP上改进了4%，F1上改进了17.1%，所有代词的实体定位正确性普遍提高，除了“its”。跨帧人物和物体的一致性增加，在所有帧数下都显示出提升，出现5个或以上帧的实体比例从29.3%提高到33.3%。结构良好的故事，包含chain-of-thought和实体定位的故事，从79.1%提高到97.5%。", "conclusion": "通过对比强化学习训练了视觉故事讲述系统，显著提高了实体识别和故事连贯性，特别是在mAP、F1分数和实体跨帧持续性方面取得了显著进步。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07722", "html_url": "https://arxiv.org/abs/2507.07722", "title": "在医学成像中的数据集偏差理解：胸部X光的案例研究", "title_en": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays", "authors": "Ethan Dack,Chengliang Dai", "background": "最近的研究重新审视了‘识别数据集’任务，发现非医疗数据集存在潜在偏见，并且可以通过高精度解决数据集来源任务。鉴于医学成像中医学图像由于其敏感性难以开放，部分开放源数据集因此对研究非常受欢迎。本文将同样的任务应用于流行的开源胸部X光数据集，旨在探索这些数据集中是否存在数据集偏见。我们实施了不同的网络架构来分析NIH、CheXpert、MIMIC-CXR和PadChest四个数据集，以评估现代方法是否在处理病理学相关问题上表现出了偏差。这项工作的目的是促进更可解释的医学成像研究，并鼓励更多开放源医学数据集的创建。", "innovation": "本文通过重新研究非医疗数据集的偏见并应用于流行的开源胸部X光数据集，探索了医学图像数据集偏见的存在。此外，通过应用简单数据集变换来进一步分析，并解释检测到的任何偏差，这种做法为理解数据集偏见提供了新的视角。", "conclusion": "本文的研究结果揭示了某些开源胸部X光数据集中可能存在数据集偏见。我们建议部署多样的网络架构来进一步评估这种偏差，并且呼吁未来研究在进行医学成像AI应用时要提高透明度和解释性，同时促进更多开放源医学数据集的创建。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07521", "html_url": "https://arxiv.org/abs/2507.07521", "title": "Spline Deformation Field", "title_en": "Spline Deformation Field", "authors": "Mingyang Song,Yang Zhang,Marko Mihajlovic,Siyu Tang,Markus Gross,Tunç Ozan Aydın", "background": "轨迹建模中，密集点的轨迹通常使用隐式变形场进行建模，这些变形场由神经网络表示，将坐标映射到参考空间位置与时间偏移之间。然而，神经网络固有的归纳偏差可能在病态情况下阻碍空间一致性。当前方法主要集中在提升变形场的编码策略，通常导致模型不透明且不易理解，或者采用线性混合蒙皮等显式技术，这些技术依赖基于启发式的节点初始化。此外，隐式表示在插值稀疏时间信号方面的潜力尚待探索。", "innovation": "本文提出了一种基于样条的轨迹表示方法，样条结点的数量显式决定了自由度。这种方法能够高效地分析速度，保持空间一致性和加速度，同时减轻了时间波动的影响。通过在空间和时间域中引入一种新型的低秩时变空间编码，我们取代了传统的时空耦合技术，模型在稀疏输入下对连续场的时间插值表现优异。此外，本文方法在动态场景重建的质量上与最先进的方法相当，同时增强了运动的一致性，无需依赖线性混合蒙皮或尽可能刚性约束。", "conclusion": "本文提出了一种基于样条的变形场方法，该方法通过低秩时变空间编码增强了空间和时间的效率，有效解决了空间不一致和时间波动的问题，其在动态场景重建中表现出优越的时间插值性能和高质量的动态一致性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07633", "html_url": "https://arxiv.org/abs/2507.07633", "title": "T-GVC: 在超低比特率下的轨迹引导生成性视频编码", "title_en": "T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates", "authors": "Zhitao Wang,Hengyu Man,Wenrui Li,Xingtao Wang,Xiaopeng Fan,Debin Zhao", "background": "近年来，视频生成技术的进步催生了一种新型的生成式视频编码范式，旨在通过利用强大的生成先验知识在超低比特率（ULB）场景中实现语义准确的重建。然而，目前大多数方法存在领域特异性（如面部或人类视频）限制，或过度依赖高级文本指导，这些限制往往无法捕捉运动细节，导致重建结果不真实.", "innovation": "针对上述挑战，我们提出了一种轨迹引导生成式视频编码框架（简称T-GVC）。T-GVC利用语义感知稀疏运动采样流水线，将低级运动追踪与高级语义理解有效结合，仅抽取基于其语义重要性的像素级运动作为稀疏轨迹点，不仅可以显著降低比特率，还能保留关键的时域语义信息。此外，通过将轨迹对齐损失约束引入到扩散过程中，我们引入了一种无需训练的潜在空间引导机制，确保了物理上可验证的运动模式，同时保留了生成模型的固有能力。实验结果表明，在ULB条件下，我们的框架能比传统编码器和最先进的端到端视频压缩方法获得更好的性能。此外，进一步的实验结果显示，我们的方法在运动控制的精确度上优于现有的文本引导方法，为其开辟了一个新的生成式视频编码方向，由几何运动建模引导.", "conclusion": "我们的框架在ULB条件下优于传统的编解码器和最先进的端到端视频压缩方法，并实现了比现有基于文本的引导方法更精确的运动控制，为生成式视频编码提供了新的轨迹引导方向。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07802", "html_url": "https://arxiv.org/abs/2507.07802", "title": "协同提示用于具有缺失模态的稳健视觉识别", "title_en": "Synergistic Prompting for Robust Visual Recognition with Missing Modalities", "authors": "Zhihui Zhang,Luanyuan Dai,Qika Lin,Yunfeng Diao,Guangyin Jin,Yufei Guo,Jing Zhang,Xiaoshuai Hao", "background": "大规模多模态模型通过利用丰富的配对多模态训练数据在各种视觉识别任务中表现出显著的效果。然而，在实际应用中，缺失或不完整的模态输入经常导致性能严重下降。现有研究集中于基于提示的方法来解决这个问题，但现有方法受到两大瓶颈的限制：一是静态提示缺乏适应不同缺失数据条件的灵活性；二是基础的提示调优方法在关键模态缺失时难以保证可靠性能。", "innovation": "本文提出了一种新的名为SyP（Synergistic Prompting）的框架，以解决具有缺失模态的稳健视觉识别问题。SyP的两大创新点是：(I) 动态适配器，用于计算适应性缩放因子以动态生成提示，替代静态参数以实现灵活的多模态适应；(II) 协同提示策略，结合静态和动态提示以平衡不同模态的信息，确保即使在关键模态缺失时也能实现稳健的推理。", "conclusion": "提出的SyP框架在三种广泛使用的视觉识别数据集上取得了显著的性能提升，展示了在多样化的缺失率和条件下具有稳健性。大量的实验和消融研究验证了其在处理缺失模态方面的有效性，突显了其出色适应性和可靠性。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07994", "html_url": "https://arxiv.org/abs/2507.07994", "title": "Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection", "title_en": "Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection", "authors": "Subhajit Maity,Ayan Kumar Bhunia,Subhadeep Koley,Pinaki Nath Chowdhury,Aneeshan Sain,Yi-Zhe Song", "background": "关键点检测对于现代机器感知至关重要，但在有限监督学习中面临挑战，尤其是在来源数据与查询数据不匹配的情况下。现有的解决方案主要依赖于源数据，但在某些场景下无法获取这些数据。为了克服这一限制，作者利用草图作为人类表达的一种形式，提出了一种无源的解决方案。然而，跨模态嵌入和用户特定草图风格的处理成为挑战。", "innovation": "作者提出了一种新的框架，结合原型设置、网格定位器和原型域适应，以解决跨模态嵌入和用户特定草图风格处理的问题，并展示了该方法在新关键点和类别的有限监督学习中的收敛效果。", "conclusion": "通过广泛的实验，该研究展示了所提出的框架在新型关键点和类别上的有限监督学习中的成功，并为未来的关键点检测研究提供了新的视角和方法。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02367", "html_url": "https://arxiv.org/abs/2502.02367", "title": "电场匹配：数据生成与转移的电学理论方法", "title_en": "Field Matching: an Electrostatic Paradigm to Generate and Transfer Data", "authors": "Alexander Kolesov,Manukhov Stepan,Vladimir V. Palyulin,Alexander Korotin", "background": "该研究提出了Electric Field Matching（电场匹配，EFM），一种适用于生成建模和分布转移任务的新方法。它受到电气电容器的物理原理启发。该方法通过给源和目标分布分配正负电荷，并利用神经网络逼近器学习电容的电场，从而实现从一个电极到另一个电极的分布匹配。理论上，该方法被证明能够实现分布转移。实际应用中，通过玩具数据和图像数据实验展示其效果。", "innovation": "电场匹配（EFM）是一种新颖的方法，它通过将源和目标分布视为电容器的电极，并通过学习电容的电场来实现分布之间的匹配。这种方法融合了生成建模和分布转移任务的需求，为两者提供了一种通用的解决方案。", "conclusion": "该研究证明了电场匹配（EFM）方法在玩具数据和图像数据实验中的有效性，并理论上证明了其能够实现分布转移。这种方法为生成建模和分布转移任务提供了新的视角和解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07656", "html_url": "https://arxiv.org/abs/2503.07656", "title": "DriveTransformer: 统一的Transformer架构以提高端到端自动驾驶的可扩展性", "title_en": "DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving", "authors": "Xiaosong Jia,Junqi You,Zhiyuan Zhang,Junchi Yan", "background": "端到端自动驾驶（E2E-AD）已成为自动驾驶领域的趋势，它提供了一种数据驱动和可扩展的系统设计方法。然而，现有E2E-AD方法通常采用感知-预测-规划的顺序范式，导致累积误差和训练不稳定。手动排列任务也限制了系统利用任务之间协同作用的能力（例如，规划感知和博弈论交互预测与规划）。此外，现有方法采用的密集BEV表示带来了远距离感知和长期时间融合的计算挑战。", "innovation": "我们提出了DriveTransformer，一种简化了的端到端自动驾驶框架，具有三大关键特性：任务并行性（各个代理、地图和规划查询在每个模块中直接交互）、稀疏表示（任务查询直接与原始传感器特征交互）以及流处理（任务查询被存储并通过历史信息传递）。最终，新框架由三大统一操作组成：任务自我注意力、传感器跨注意力、时间跨注意力，显著降低了系统的复杂性并提高了训练稳定性。", "conclusion": "DriveTransformer在模拟封闭环基准Bench2Drive和真实世界开环基准nuScenes中均实现了最先进的性能，而且具有较高的FPS。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.12096", "html_url": "https://arxiv.org/abs/2502.12096", "title": "令牌通信：一种统一的跨模态上下文感知语义通信框架", "title_en": "Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications", "authors": "Li Qiao,Mahdi Boloursaz Mashhadi,Zhen Gao,Rahim Tafazolli,Mehdi Bennis,Dusit Niyato", "background": "本文介绍了一种名为Token Communications (TokCom)的新架构，该架构借鉴了生成式基础模型和多模态大型语言模型（GFM/MLLMs）的成功，旨在增强生成式语义通信（GenSC）。TokCom采用令牌作为通信单元，使得在发送端和接收端可以高效地处理基于变压器的令牌。", "innovation": "TokCom框架提出了一种新的范式，通过引入令牌作为通信单元，实现了在生成式语义通信系统中利用跨模态上下文信息的可能性，同时降低了复杂程度。文章探索了如何将基于GFM/MLLMs的令牌处理整合到语义通信系统中，以实现高效的跨模态上下文利用。此外，还提出了在未来无线网络的各个层面上实现高效TokCom的关键原则。", "conclusion": "文章通过在典型图像语义通信配置中的示例，展示了TokCom通过利用令牌之间的上下文信息显著提升了频谱效率。还指出了推动TokCom在未来的无线网络中应用的潜在研究方向。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.20653", "html_url": "https://arxiv.org/abs/2503.20653", "title": "UWarp：一种用于表征扫描器引起的局部领域偏移的全玻片图像配准流水线", "title_en": "UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift", "authors": "Antoine Schieb,Bilal Hadjadji,Natalia Fernanda Valderrama,Daniel Tshokola Mweze,Valentin Derangère,Laurent Arnould,Sylvain Ladoire,Alain Lalande,Alessio Fiorin,Carlos López Pablo,Noèlia Gallardo Borràs,Shrief Abdelazeez,Vincenzo Della Mea,Anna Korzynska,Louis-Oscar Morel,Nathan Vinçon", "background": "当前基于深度学习的计算病理学模型在数字病理切片处理中表现良好，但大部分研究主要关注图像级别的领域偏移分析，而忽略了局部组织特征对模型准确度的影响。现有的开源配准方法在处理局部偏移时效果不佳或计算时间较长。论文旨在通过引入一种新的配准工具UWarp，解决这一问题，提高模型的准确度和鲁棒性。", "innovation": "提出了UWarp配准框架，用于表征扫描器引起的局部领域偏移。该框架结合了全局仿射变换和细粒度的局部修正，提高了玻片图像的配准精度。相较于现有的开源配准方法，UWarp在目标对齐误差（TRE）和计算时间上均表现更优，特别是在乳腺癌病理反应预测模型Breast-NEOprAIdict中，展示了局部特征与预测可变性的密切关联。", "conclusion": "UWarp可以作为一种有价值的工具，用于提高计算病理学模型的鲁棒性和领域适应性策略。论文通过实际实验验证了UWarp的效果，为计算病理学领域提供了新的分析工具和技术方法。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07878", "html_url": "https://arxiv.org/abs/2507.07878", "title": "单步潜在扩散模型在水下图像恢复中的应用", "title_en": "Single-Step Latent Diffusion for Underwater Image Restoration", "authors": "Jiayi Wu,Tianfu Wang,Md Abu Bakr Siddique,Md Jahidul Islam,Cornelia Fermuller,Yiannis Aloimonos,Christopher A. Metzler", "background": "水下图像恢复算法的目标是恢复被水侵染的图像中的色彩、对比度和外观。这些算法在海洋生态学、水产养殖、水下建筑和考古等领域具有广泛应用。然而，现有的基于像素扩散的图像恢复方法尽管在恢复简单场景和有限深度变化的场景中效果显著，但在处理具有复杂几何结构和显著深度变化的场景时计算强度高且往往会产生不真实的伪像。因此，存在一种新的网络架构SLURPP和准确的合成数据生成流水线，来弥补这些局限性，旨在提升水下图像的恢复效果。", "innovation": "本文通过结合一种新颖的网络架构（SLURPP）与准确的合成数据生成流水线，提出了新的方法来克服现有算法的局限性。SLURPP将预训练的潜在扩散模型与显式的场景分解结合，编码了场景的几何和深度的强先验，并能够建模和考虑光线衰减和后向散射的效应。通过设计基于物理原理的水下图像合成流水线，对现有的地表图像数据集应用了各种现实的水下退化效果，从而能够生成包含稠密介质/退化标注的多样训练数据。这种方法在合成和现实世界基准上进行了广泛评估，展示了在峰值信噪比PSNR上高达3 dB的提升和现实世界数据上的令人信服的定性改进，同时其速度提高了200倍以上，超过了现有的基于扩散的方法。", "conclusion": "研究表明，SLURPP不仅在合成基准上取得了最先进的性能，还对现实世界的数据提供了令人信服的定性改进，并且比现有方法快200多倍，具备显著的先验知识和显著的加速效果。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22589", "html_url": "https://arxiv.org/abs/2503.22589", "title": "利用AI总结1952-2012年美国总统竞选电视广告视频", "title_en": "Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012", "authors": "Adam Breuer,Bryce J. Dietrich,Michael H. Crespin,Matthew Butler,J.A. Pryse,Kosuke Imai", "background": "本研究介绍了有史以来最大、最全面的美国总统竞选电视广告数据集，这些数据以数字格式呈现。该数据集包含机器可搜索的转录和高质量的摘要，旨在促进各种学术研究。以往对美国总统竞选广告的收集和分析非常感兴趣，但由于需要手工采购和标注，许多研究者依赖于较小的数据集。", "innovation": "我们设计了一个大规模并行化的基于AI的分析管道，自动完成了准备、录音和总结视频的劳动密集型过程。我们使用这种方法对朱利安·P·卡纳特政治商业档案中的9,707条总统广告进行了处理，并通过大量的人工评估证明，这些转录和摘要达到了手工生成的替代品的质量水平。我们还展示了该数据的价值，通过一个应用程序展示了当前焦点议题在近七十年的总统选举中的起源和发展。此外，我们的分析管道和代码库展示了如何使用基于LLM的工具为其他视频数据集获取高质量的摘要。", "conclusion": "这一数据分析管道和代码库展示了如何利用基于LLM的工具为其他视频数据集获取高质量的摘要。通过系统化和自动化的处理，大大提高了研究效率和准确性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08050", "html_url": "https://arxiv.org/abs/2507.08050", "title": "一种增强隐私保护的联邦少样本学习框架在呼吸道疾病诊断中的应用", "title_en": "An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis", "authors": "Ming Wang,Zhaoyang Duan,Dong Xue,Fangzhou Liu,Zhongheng Zhang", "background": "医疗数据注释的劳动密集型性质为呼吸系统疾病诊断带来了重大挑战，导致在资源受限的情境下高质量标记数据的稀缺。此外，患者的隐私担忧使机构间的直接医疗数据分享复杂化，现有的依赖大量可用数据的中心化数据驱动方法在保护数据隐私方面存在缺陷。", "innovation": "提出了一种带有隐私保护机制的联邦少样本学习框架，以解决有限标记数据和隐私保护在诊断呼吸系统疾病中的问题。特别地，提出了一种元随机梯度下降算法来缓解传统梯度下降方法在神经网络训练中因数据不足导致的过拟合问题。同时，通过在使用局部数据训练私有模型时将标准高斯分布下的微分隐私噪声集成到梯度中，防止医学图像的重构，以确保数据隐私。此外，采用加权平均算法从不同客户处聚合本地诊断模型，增强了模型在不同场景下的适应性。", "conclusion": "实验证明，利用微分隐私实施的提出方法在使用不同结构、类别和分布的数据时取得了令人信服的结果，同时有效诊断呼吸系统疾病。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12430", "html_url": "https://arxiv.org/abs/2506.12430", "title": "极限安全的探索：ATLAS 挑战 2025 技术报告", "title_en": "Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025", "authors": "Zonghao Ying,Siyang Wu,Run Hao,Peng Ying,Shixuan Sun,Pengyu Chen,Junze Chen,Hao Du,Kaiwen Shen,Shangkun Wu,Jiwei Wei,Shiyuan He,Yang Yang,Xiaohai Xu,Ke Ma,Qianqian Xu,Qingming Huang,Shi Lin,Xun Wang,Changting Lin,Meng Han,Yilei Jiang,Siqi Lai,Yaozhi Zheng,Yifei Song,Xiangyu Yue,Zonglei Jing,Tianyuan Zhang,Zhilei Zhu,Aishan Liu,Jiakai Wang,Siyuan Liang,Xianglong Kong,Hainan Li,Junjie Mu,Haotong Qin,Yue Yu,Lei Chen,Felix Juefei-Xu,Qing Guo,Xinyun Chen,Yew Soon Ong,Xianglong Liu,Dawn Song,Alan Yuille,Philip Torr,Dacheng Tao", "background": "多模态大型语言模型（MLLMs）在各种应用中实现了变革性的进步，但仍然容易受到安全威胁的影响，尤其是可能导致有害输出的监狱逃逸攻击。为了系统地评估和改进它们的安全性，组织了第二届ATLAS 2025 年度挑战。该技术报告介绍了挑战的结果，共有86支队伍参与，通过对抗性图像-文本攻击在两阶段（白盒和黑盒）评估中测试了MLLM的漏洞。", "innovation": "通过组织ATLAS 2025 年年度挑战，采用了一种新的方法来测试和改善多模态大型语言模型的安全性，特别是通过对抗性图像-文本攻击进行了白盒和黑盒评估。结果展示了在确保多模态语言模型安全方面的持续挑战，并为开发更强大的防御机制提供了宝贵指导。挑战设立了多模态大型语言模型安全评估的新基准，并为推动更安全的多模态人工智能系统奠定了基础。挑战的代码和数据公开可供下载。", "conclusion": "挑战结果显示了在确保多模态大型语言模型安全方面的持续挑战，并为开发更强大的防御机制提供了宝贵指导。挑战设立了多模态大型语言模型安全评估的新基准，并为推动更安全的多模态人工智能系统奠定了基础。挑战的代码和数据公开可供下载。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07789", "html_url": "https://arxiv.org/abs/2507.07789", "title": "在交替优化中实现高效的信息驱动光学设计", "title_en": "Computationally Efficient Information-Driven Optical Design with Interchanging Optimization", "authors": "Eric Markley,Henry Pinkard,Leyla Kabuli,Nalini Singh,Laura Waller", "background": "近期的研究表明，可以通过测量中的信息内容来评估成像系统，从而实现适用于不同应用的光学设计，并避免了计算解码的挑战。信息驱动编码分析学习（IDEAL）是一种自动化此过程的方法，使用基于梯度的优化。然而，该工作发现IDEAL在不同的成像系统中存在高内存使用率、长时间运行和目标函数不匹配等问题。这些问题源于端到端可微的要求。因此，为了解决这些局限性，该工作提出了一种通过交替优化密度估计和光学参数优化的方法，即IDEAL-IO，以减少运行时间和内存使用，并允许更具有表现力的概率密度模型指导优化朝着更优的设计方向。这种方法已在衍射光学、无透镜成像和快照3D显微镜应用中得到验证，证明了信息论优化是现实世界成像系统设计的实用且可扩展的策略。", "innovation": "提出了IDEAL-IO方法，通过交替优化密度估计和光学参数优化来解决IDEAL在多样化的成像系统中所遇到的内存使用率高、运行时间长以及目标函数不匹配等缺点。这种方法降低了6倍的运行时间与内存使用，并且能够使用更具有表现力的概率密度模型来指导优化，使得设计更优的光学系统成为可能。此外，该方法已被应用于衍射光学、无透镜成像和快照3D显微镜这些实际场景中，证明了信息论优化方法的有效性。", "conclusion": "信息论优化被确立为一种实用且可扩展的策略用于现实世界的成像系统设计。IDEAL-IO通过减少运行时间和内存使用以及更多有表现力的概率密度模型指导优化，使得信息驱动的光学系统设计更高效。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08053", "html_url": "https://arxiv.org/abs/2507.08053", "title": "树结构帕兹估计器可以更高效地解决黑盒组合优化问题", "title_en": "Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently", "authors": "Kenshin Abe,Yunzhuo Wang,Shuhei Watanabe", "background": "树结构帕兹估计器（TPE）是支持流行超参数优化（HPO）工具的一种多功能方法。由于这些HPO工具通常与深度学习（DL）的发展趋势保持一致，TPE讨论的问题设置常常局限于DL领域，如多目标优化和多保真度优化。然而，HPO的实际应用并非限于DL，黑盒组合优化在某些领域，例如化学和生物学中被积极使用。本文针对TPE中尚未涉及但非常重要的组合优化问题，提出了一种高效的组合优化算法，通过将树结构帕兹估计器中的分类核与数值核进行一般化，引入了距离结构，并讨论了处理大规模组合搜索空间的修改，从而减少了核计算的时间复杂度，并通过合成问题的实验验证了所提出方法在较少的评估次数下可以识别出更好的解。这些改进使得算法可以在Optuna（一个开源的HPO框架）中实现并提供使用。", "innovation": "提出了一种针对TPE（树结构帕兹估计器）的高效组合优化算法。该算法通过将分类核与数值核一般化，引入了距离结构，从而能够解决大规模的组合优化问题。此外，还通过修改这些新开发的核函数来处理大规模的组合搜索空间，减少了核计算的时间复杂度。", "conclusion": "通过合成问题的实验验证，提出的改进方法在较少的评估次数下可以识别出更好的解，证明了改进的有效性。这种改进可以在Optuna中实现并开放给用户使用。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08118", "html_url": "https://arxiv.org/abs/2507.08118", "title": "PDE-aware Optimizer for Physics-informed Neural Networks", "title_en": "PDE-aware Optimizer for Physics-informed Neural Networks", "authors": "Hardik Shukla,Manurag Khullar,Vismay Churiwala", "background": "物理知情神经网络（PINNs）已成为通过将物理约束嵌入损失函数中来解决偏微分方程（PDEs）的强大框架。然而，标准优化器如Adam在处理刚性或病条件系统时经常难以平衡竞争损失项。", "innovation": "本文提出了一种PDE感知优化器，根据样本PDE残差梯度的方差来调整参数更新，这在避免使用SOAP等二次优化器的高计算成本的同时，解决了梯度对齐问题。", "conclusion": "PDE感知优化器在Burgers'、Allen-Cahn和Korteweg-de Vries方程中的基准测试中取得了更平缓的收敛性和更低的绝对误差，尤其是在拥有陡峭梯度的区域更为显著。结果表明，PDE残差感知的自适应性可以增强PINNs训练的稳定性。然而，对于更大的架构和硬件加速器的进一步扩展研究仍是未来研究的重要方向。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08068", "html_url": "https://arxiv.org/abs/2507.08068", "title": "Quantile Reward Policy Optimization: 与点 wise 回归对齐并具有精确的分区函数", "title_en": "Quantile Reward Policy Optimization: Alignment with Pointwise Regression and Exact Partition Functions", "authors": "Simon Matrenok,Skander Moalla,Caglar Gulcehre", "background": "目前，让大型语言模型与点级绝对奖励对齐需要在线、在线算法，例如 PPO 和 GRPO。相反，可以利用离线或脱机数据的更简单的方法，如 DPO 和 REBEL，只能从偏好对或相对信号中学习。", "innovation": "提出了 Quantile Reward Policy Optimization (QRPO)，这是一种利用点级绝对奖励进行学习的方法，同时保留了 DPO 类方法的简单性和离线适用性。QRPO 使用分位数奖励来支持对 KL-正则化 RL 目标封闭形式解的回归。这个奖励会带来一个可以解析的分区函数，从而消除了相对信号来抵消该术语的需要。另外，QRPO 随计算能力的增加来估算分位数奖励，开辟了预计算规模的新维度。", "conclusion": "实证上，QRPO 在聊天和编程评估中表现突出——奖励模型得分、AlpacaEval 2 和 LeetCode——对比 DPO、REBEL 和 SimPO 在多样化数据集和 8B 规模模型上。此外，我们发现使用鲁棒性奖励代替将其转换为偏好，会减少长度偏差。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08121", "html_url": "https://arxiv.org/abs/2507.08121", "title": "Quasi-Random Physics-informed Neural Networks", "title_en": "Quasi-Random Physics-informed Neural Networks", "authors": "Tianchi Yu,Ivan Oseledets", "background": "物理启发的神经网络在通过将物理约束整合到神经网络训练中解偏微分方程(PDEs)方面表现出了潜力，但其性能取决于采样点的抽样方法。蒙特卡洛方法在高维问题上的出色表现促使了这项研究，提出了一种名为Quasi-Random Physics-Informed Neural Networks (QRPINNs)的方法，利用低不均匀序列进行采样，而非直接从定义域中随机抽样。", "innovation": "QRPINNs 使用低不均匀序列进行采样，而不是直接从定义域中随机抽样。理论证明QRPINNs的收敛速度优于PINNs。实证结果显示QRPINNs在高维PDEs上显著优于PINNs和其他代表性自适应采样方法，尤其是结合QRPINNs与自适应采样能进一步改善性能。", "conclusion": "QRPINNs 在偏微分方程求解中表现出优越性能，特别是在高维问题上，且结合自适应采样能显著提升整体性能。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08154", "html_url": "https://arxiv.org/abs/2507.08154", "title": "仅阅读问题：通过文本意识实现对新评估项目的推广", "title_en": "Just Read the Question: Enabling Generalization to New Assessment Items with Text Awareness", "authors": "Arisha Khan,Nathaniel Li,Tori Shen,Anna N. Rafferty", "background": "机器学习被提出作为改进教育评估的方法，通过精细预测学生表现和项目间的学习关系。但是，许多机器学习方法在引入新项目时面临挑战，因为这些方法高度依赖历史数据。研究通过扩展LENS部分变分自编码器（LENS partial variational auto-encoder），利用项目文本嵌入Text-LENS，来探索其在预测性能和对未见过项目的推广性上的影响。", "innovation": "开发了Text-LENS，通过扩展LENS部分变分自编码器以利用项目文本嵌入，从而改进预测性能和对未见过项目的推广能力。", "conclusion": "Text-LENS在已见项目上的性能与LENS相当，并在涉及未见过项目的各种条件下有所提高，能够有效学习学生的熟练程度并对其新项目的绩效做出预测。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08124", "html_url": "https://arxiv.org/abs/2507.08124", "title": "具有硬非线性等式和不等式约束的物理输入神经网络", "title_en": "Physics-Informed Neural Networks with Hard Nonlinear Equality and Inequality Constraints", "authors": "Ashfaq Iftakher,Rahul Golder,M. M. Faruque Hasan", "background": "传统物理信息神经网络（PINNs）无法确保严格约束满足，这对工程系统而言是个问题，在这些系统中，少量违反物理规律的现象会显著降低模型预测的可靠性和一致性。", "innovation": "开发了KKT-Hardnet架构，能够严格满足线性和非线性的等式和不等式约束，通过求解KKT条件的最小化距离问题进行投影到可行区域，引入对非线性KKT条件的对数指数变换，构建仅包含线性和指数项的一般稀疏系统，实现了投影的可微性。", "conclusion": "KKT-Hardnet在测试问题和真实的化学过程模拟中表现出了更高的准确性和严格的约束满足能力，这一方法允许在机器学习中整合领域知识，以实现复杂系统的可靠混合建模。"}
{"llm_update_time": "20250714", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07393", "html_url": "https://arxiv.org/abs/2507.07393", "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos", "title_en": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos", "authors": "Jinseong Kim,Junghoon Song,Gyeongseon Baek,Byeongjoon Noh", "background": "现有的基于视频的人再识别方法主要依赖于身份特征，而缺乏对身体部分的细化特征提取和利用。研究人员发现，利用人体关键点（keypoints）可以提高时空表示学习的效果。", "innovation": "提出了一种名为KeyRe-ID的关键点引导的基于视频的人再识别框架，包含全局和局部分支。全局分支使用基于Transformer的时空聚合来捕捉整体身份语义，局部分支通过关键点动态分割身体区域，生成细粒度、部分感知的特征。", "conclusion": "在MARS和iLIDS-VID基准测试上进行了大量实验，证明了KeyRe-ID的性能，达到了MARS上的91.73%平均精度（mAP）和97.32%的Rank-1准确率，以及iLIDS-VID上的96.00% Rank-1准确率和100.0%的Rank-5准确率。该研究还将代码发布在GitHub上以供公开访问。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08153", "html_url": "https://arxiv.org/abs/2507.08153", "title": "ALCo-FM: 自适应长期语境基础模型用于事故预测", "title_en": "ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction", "authors": "Pinaki Prasad Guha Neogi,Ahmad Mohammadshirazi,Rajiv Ramnath", "background": "交通事故虽不常见，但影响巨大，需要长时间多模态推理以实现准确的风险预测。本文旨在介绍ALCo-FM，这是一种统一的自适应长期语境基础模型，能够计算波动预评分，动态选择输入数据的上下文窗口，并通过浅层交叉注意力对这些多模态数据进行编码和融合。模型通过局部图注意层和基于H3六边形网格的大鸟风格稀疏全局变换器进行处理，增强了预测能力，并使用蒙特卡洛丢弃层提高置信度。", "innovation": "ALCo-FM 采用了一种新颖的方法，即计算波动预评分以动态选择输入数据的上下文窗口，并通过浅层交叉注意力机制对不同来源的数据进行编码和融合。接着模型通过加权损失函数（考虑类别不平衡）进行训练，并通过微量数据分析技术在新的城市上进行微调。与其他超过20种现有的前沿基线模型相比，在大规模城市风险预测中表现出色，准确率为0.94，F1分数为0.92，经验校准误差为0.04，且模型代码和数据集都可获取。", "conclusion": "在15个美国城市的交通数据上进行训练，并使用最少的数据在保留的城市上进行微调后，ALCo-FM 模型在大规模城市风险预测中表现优异。该模型的主要成果在于其能有效处理多模态数据、动态选择上下文窗口，并且在不同的城市进行推广时具有较强的泛化能力，模型表现维出优于现有的众多基线模型。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08182", "html_url": "https://arxiv.org/abs/2507.08182", "title": "CTRLS: 隐状态转换下的链式思维推理", "title_en": "CTRLS: Chain-of-Thought Reasoning via Latent State-Transition", "authors": "Junda Wu,Yuxin Xiong,Xintong Li,Zhengmian Hu,Tong Yu,Rui Wang,Xiang Chen,Jingbo Shang,Julian McAuley", "background": "链式思维（CoT）推理能力使大规模语言模型能够将复杂问题分解为可解释的中间步骤，显著提高了模型在推理任务中的透明度和性能。然而，传统的CoT方法依赖于启发式采样来推理过渡，缺乏结构化的建模，限制了它们系统地探索和发现多样且有效的推理路径的能力。", "innovation": "本文引入了CTRLS框架，将CoT推理作为一种具有隐状态转换的马尔可夫决策过程（MDP）进行建模，通过分布式的强化学习实现有原理的状态感知探索。通过对推理动作建模为明确的概率分布，并引入一个基于epsilon-greedy探索和基于熵正则化的在线策略强化学习策略，集中探索隐状态转换。这种建模方法提供了理论上的支持，并且能够在不重新微调基础的大规模语言模型的情况下，逐步细化隐状态转换。", "conclusion": "理论分析表明CTRLS提供了证据下界（ELBO），并通过对隐状态转换的理解更好地定义了推理动态。进一步的实验结果表明，CTRLS在基准推理任务中提高了推理准确性、多样性和探索效率。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08235", "html_url": "https://arxiv.org/abs/2507.08235", "title": "InsightBuild：在智能建筑系统中的基于LLM的因果推理", "title_en": "InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems", "authors": "Pinaki Prasad Guha Neogi,Ahmad Mohammadshirazi,Rajiv Ramnath", "background": "智能建筑产生了大量的传感器和控制数据，但设施管理人员往往缺乏对异常能源使用情况的清晰解释。因此，需要一种能够提供易于理解且具有因果性的能源消耗模式解释的方法。现有的方法可能难以提供清晰的、基于因果关系的解释，特别是在实际应用中可执行性不足。", "innovation": "我们提出了一种名为InsightBuild的两阶段框架，将因果分析与微调的大型语言模型(LLM)相结合，以提供易于理解的因果性解释。首先，使用Granger因果性测试和结构因果发现分析建筑遥测数据（如温度、暖通空调设置、占用情况），从而识别潜在的原因。其次，使用微调后的LLM生成简洁且行动导向的解释。实验结果显示，结合明确定义的因果发现和基于LLM的自然语言生成，能够提供清晰且精准的解释，帮助设施管理人员诊断和解决能源效率问题。", "conclusion": "我们的研究结果表明，将明确定义的因果发现与基于LLM的自然语言生成结合使用，可以为设施管理人员提供清晰、精确的解释，这有助于诊断和减轻能源效率低下问题。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08212", "html_url": "https://arxiv.org/abs/2507.08212", "title": "EvA: 图结构上的进化式攻击", "title_en": "EvA: Evolutionary Attacks on Graphs", "authors": "Mohammad Sadegh Akhondzadeh,Soroush H. Zargarbashi,Jimin Cao,Aleksandar Bojchevski", "background": "图神经网络（GNN）对图结构的小幅扰动非常敏感，这会导致它们的准确性显著下降。目前大多数攻击利用了梯度信息来扰动边，这将攻击的优化问题从离散空间松弛到了连续空间，最终导致非最优的解决方案。此外，这也限制了攻击对非可微目标的适应性。", "innovation": "引入了一种基于进化算法的简单且有效的增强方法，直接解决离散优化问题，名为Evolutionary Attack（EvA）。该方法适用于任何黑盒模型和目标，无需使用可微代理损失函数。这种方法还设计出了两种新型攻击，降低了鲁棒性证书的有效性并破坏了符合集。EvA的攻击内存复杂度与攻击预算成线性关系，并且在实验中，平均准确性比最好之前的攻击降低了约11%，揭示了在设计攻击中巨大的未开发潜力。", "conclusion": "EvA在攻击GNN时表现出色，能够直接处理离散优化问题，无需梯度信息，并设计出了能够削弱GNN鲁棒性的攻击方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08177", "html_url": "https://arxiv.org/abs/2507.08177", "title": "重思时空异常检测：因果驱动的网络安全愿景", "title_en": "Rethinking Spatio-Temporal Anomaly Detection: A Vision for Causality-Driven Cybersecurity", "authors": "Arun Vignesh Malarkkan,Haoyue Bai,Xinyuan Wang,Anjali Kaushik,Dongjie Wang,Yanjie Fu", "background": "随着网络物理系统越来越互联和分布式，确保其对不断演化的网络攻击的韧性已成为一个重要优先事项。时空异常检测在确保系统安全和运营完整性方面起着重要作用。然而，当前基于黑盒深度学习的数据驱动方法在解释性、适应分布变化的灵活性以及在动态系统动力学下的鲁棒性方面面临挑战。", "innovation": "本文倡导采用因果学习视角，以结构因果关系为基础推进分布式基础设施中的异常检测。文中确立并形式化了三个关键方向：因果图谱分析、多视图融合以及持续的因果图学习，每一种方法都具有独特的优势，能够在时空中揭示动态的因果结构。基于实际案例如水处理设施，展示了因果模型如何提供早期预警信号和根本原因归因，解决了黑盒检测器的局限性。展望未来，论文概述了多模态、生成AI驱动的可扩展自适应因果框架的研究议程。", "conclusion": "本文旨在建立一种新的研究路线，以实现可扩展、自适应、可解释以及时空框架下的异常检测系统。希望促进以因果驱动的网络安全研究范式转变，以应对互联基础设施中不断演变的威胁。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08175", "html_url": "https://arxiv.org/abs/2507.08175", "title": "在可穿戴传感器和量子机器学习中的老年人情绪识别", "title_en": "Emotion Recognition in Older Adults with Quantum Machine Learning and Wearable Sensors", "authors": "Md. Saif Hassan Onim,Travis S. Humble,Himanshu Thapliyal", "background": "本文探讨了仅通过生理信号推断情绪状态的可能性，提供了一种与传统面部识别技术相比更加保护隐私的替代方案。与传统的机器学习算法相比，研究团队对比了混合量子机器学习方法和基于量子内核的模型，并进行了性能对比。研究表明，在所有情绪类别中，量子增强的支持向量机在分类性能上远胜于传统方法，即使在数据集有限的情况下也是如此。", "innovation": "本文创新点在于采用混合量子机器学习（QML）方法与基于量子内核模型相结合，特别是在有限数据集上，量子增强的支持向量机表现出了显著的优势。这种集成方法不仅提高了准确性和鲁棒性，还有助于实现不侵扰的情绪识别。它对具有沟通障碍的人群具有潜在的应用前景，如阿尔茨海默病及相关痴呆症患者和患有创伤后应激障碍的退伍军人。实验结果为进一步的临床和助居条件下的被动情绪监测研究奠定了基础。", "conclusion": "量子增强的支持向量机在所有情绪类别中的F1分数超过了80%，召回值最高提升了36%。集成穿戴传感器数据与量子机器学习不仅提高了准确性和稳定性，还实现了非侵入性的情绪识别。该方法有潜力应用于沟通能力受损的人群，这些人群包括患有阿尔茨海默病及相关痴呆症的患者和患有创伤后应激障碍的退伍军人。研究为在临床和助居条件下进行被动情绪监测奠定了早期的基础。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08239", "html_url": "https://arxiv.org/abs/2507.08239", "title": "无需函数估计的数据生成", "title_en": "Data Generation without Function Estimation", "authors": "Hadi Daneshmand,Ashkan Soleymani", "background": "生成模型的一个核心组成部分是估计得分函数或其他与总体密度相关的函数。然而，这种函数的估计在计算上和统计上都是具有挑战性的。传统的生成模型方法通常需要进行函数估计和神经网络训练等复杂操作。论文提出了一个无需函数估计的数据生成方法，该方法通过确定性更新一组点的位置（使用逆梯度下降），可以将均匀分布传输到任意的数据分布，这种方法不需要进行函数估计、训练神经网络，甚至不需要噪声注入，这为简化生成模型的处理过程提供了可能。", "innovation": "该论文提出了一个全新的生成方法，即无需进行函数估计的数据生成方法。该方法利用物理领域中相互作用粒子的最新进展，证明了这些进展可以被利用来开发新型的生成方法。这种方法可以通过确定性更新一组点的位置，将均匀分布传输到任意的数据分布，并且能够简化生成模型的处理过程，降低所需计算和数据资源成本。", "conclusion": "该研究不仅证明了无需进行函数估计的数据生成方法是可行的，而且还展示了通过借鉴物理领域中的相互作用粒子研究成果来进行新型生成方法设计的可能性。这种方法在数据生成过程中更高效、更简化，有望在未来的研究中得到更广泛的应用。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08238", "html_url": "https://arxiv.org/abs/2507.08238", "title": "基于自监督学习的多模态预测在亲社会行为意图上的应用", "title_en": "Self-Supervised Learning-Based Multimodal Prediction on Prosocial Behavior Intentions", "authors": "Abinay Reddy Naini,Zhaobo K. Zheng,Teruhisa Misu,Kumar Akash", "background": "随着机器学习和多模态传感技术的发展，人类状态检测和行为预测取得了显著进展。然而，在交通场景中的助人行为等亲社会行为意图预测方面仍是一个未被充分探索的领域。当前的研究面临一个主要困难，即缺乏标注的亲社会行为数据集，小型数据集使得深度学习模型难以有效训练。", "innovation": "为了克服这一挑战，本文提出一种自监督学习方法，利用现有生理和行为数据集中的多模态数据进行预训练，并通过微调较小的手动标注亲社会行为数据集来显著提高模型性能。这种方法解决了数据稀缺的问题，为亲社会行为的预测提供了一个更为有效的基准，同时提供了改进智能车辆系统和人机交互的宝贵见解。", "conclusion": "该方法为亲社会行为预测提供了一个更有效的基准，并为智能车辆系统和人机交互提供了有价值的启示，解决了现有数据缺乏的问题。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08243", "html_url": "https://arxiv.org/abs/2507.08243", "title": "CoreSPECT：通过密度和几何学的相互作用增强聚类算法", "title_en": "CoreSPECT: Enhancing Clustering Algorithms via an Interplay of Density and Geometry", "authors": "Chandra Sekhar Mukherjee,Joonyoung Bae,Jiapeng Zhang", "background": "聚类算法设计中，密度和几何形状历来是两个基本指导原则。算法通常专注于数据的密度结构（例如HDBSCAN和基于密度峰值的聚类）或潜在几何形状的复杂性（例如流形聚类算法）。然而，本文识别并形式化了分布与几何之间一种经常被忽视但反复出现的交互关系，并利用这一洞察设计了一个增强聚类的框架CoreSPECT（基于核心空间投影的聚类技术增强框架）", "innovation": "核心创新点在于设计了一个利用密度与几何之间交互关系的增强框架CoreSPECT。该框架通过将简单的算法如K-Means和GMM应用于选择性的区域，然后利用基于邻居图的多层传播机制扩展部分聚类到完整的聚类，从而提升算法性能。这种框架在15个不同领域的数据集上对K-Means和GMM的聚类精度进行了提升，平均分别提高了40%和14%的ARI得分，并且经常超过了基于流形和最近密度聚类算法的表现", "conclusion": "该框架提供了初步的理论保证，证明了停止步骤的重要性，并展示了其对噪声的鲁棒性，从而在不同领域和聚类方法上显示出了一致且显著的聚类性能提升。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08255", "html_url": "https://arxiv.org/abs/2507.08255", "title": "量子加速的大语言模型神经补全", "title_en": "Quantum-Accelerated Neural Imputation with Large Language Models (LLMs)", "authors": "Hossein Jamali", "background": "在现实世界的数据集中，缺失数据是一个关键挑战，严重影响了机器学习模型的性能。现有的大型语言模型（LLMs）在表格数据补全方面表现出色，但依赖于经典嵌入方法，限制了对其复杂非线性关联的捕捉能力，特别是在混合型数据场景中。这些数据包括数值、类别和文本特征。这篇论文旨在解决这一问题，提出了一种新颖的方法，将浅层量子电路集成到以LLM为基础的补全架构中，以改进复杂的缺失数据补全任务的性能和准确性。", "innovation": "该论文的核心创新在于，用由瞬时量子多项式（IQP）电路生成的量子特征映射取代传统的经典输入嵌入。这种方法使模型能够利用量子现象，如叠加和纠缠，从而学习更丰富、更表达的数据表示，有助于恢复复杂的缺失模式。实验结果表明，与最先进的经典和LLM方法相比，量子增强的表示即使在短期量子硬件上也具有巨大的潜力，能够减少数值特征的补全误差和提高类别特征的分类精度。具体而言，对于数值特征，补全误差降低了15.2%（计算均方根误差RMSE），对于类别特征，分类精度提高了8.7%（F1-得分）。", "conclusion": "这些结果证明了量子增强表示在复杂数据补全任务中的巨大潜力，尤其在短期量子硬件上，显示了量子技术在机器学习应用中的巨大前景。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08284", "html_url": "https://arxiv.org/abs/2507.08284", "title": "轻量级合成数据和RL引导对抗训练的安全护栏", "title_en": "Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training", "authors": "Aleksei Ilin,Gor Matevosyan,Xueying Ma,Vladimir Eremin,Suhaa Dada,Muqun Li,Riyaaz Shaik,Haluk Noyan Tokgozoglu", "background": "介绍了为语言模型设计的一种轻量级但效果显著的安全护栏框架，表明小型语言模型可以在内容审核任务中达到甚至超越大型模型的性能。", "innovation": "通过高保真合成数据生成和对抗性训练实现。采用人类精选的数据种子，经过查询增强和改写生成多样化且语境丰富的样本。数据经过多轮筛选确保保真度和相关性。采用生成对抗网络（GAN）架构并结合强化学习引导生成器生成具有挑战性的合成样本，用于微调安全性分类器，提升其检测和缓解有害内容的能力。还结合了近期高效大型语言模型训练的研究策略，利用较小模型的能力提升大型生成模型的表现。", "conclusion": "通过迭代对抗训练和生成高质量多样化的合成数据，该框架使小型语言模型（SLMs）能够作为稳健的安全护栏发挥作用，不仅降低了计算开销，还增强了对对抗性攻击的抵抗力，为AI系统的内容审核提供了可扩展且高效的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08267", "html_url": "https://arxiv.org/abs/2507.08267", "title": "一段式的数学LLMs实用双阶段训练配方：利用SFT最大化准确性及强化学习优化效率", "title_en": "A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning", "authors": "Hiroshi Yoshihara,Taiki Yamaguchi,Yuichi Inoue", "background": "提高大型语言模型（LLMs）的数学推理能力是提升人工智能能力的关键挑战。虽然监督微调（SFT）和强化学习（RL）是主要的训练模式，但在如何系统地结合这两种方法以同时最大化准确性和效率方面，仍存在很大空白。", "innovation": "本文引入了一种实用且有效的训练配方，通过战略性地将延长的SFT与在线推理的RL（GRPO）结合，以发挥这两种方法的互补作用，而非竞争作用。延长的SFT阶段首先将模型的准确性推向极限，随后的GRPO阶段显著提高了标记效率，同时保持峰值性能。", "conclusion": "通过严格验证，在具有挑战性基准上的顶尖性能，包括在严格无泄漏AI数学奥林匹克（AIMO）中超过2,200支队伍中的高排名，我们的配方为开发同时具备出色的准确性和高效性的数学推理模型提供了实战验证的蓝图。我们将会开源整个框架，包括所有代码、模型检查点和训练配置，以确保完全可重复并支持未来研究。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08269", "html_url": "https://arxiv.org/abs/2507.08269", "title": "通过直接参数化在不同平面四连杆功能生成机构的数据驱动尺寸综合", "title_en": "Data-Driven Dimensional Synthesis of Diverse Planar Four-bar Function Generation Mechanisms via Direct Parameterization", "authors": "Woon Ryong Kim,Jaeheun Jung,Jeong Un Ha,Donghun Lee,Jae Kyung Shim", "background": "平面四杆机构的尺寸综合在运动学中是一个复杂的逆问题，需要从给定的运动规范确定机构的尺寸。传统的求解方法通常依赖于方程求解和优化，这在处理复杂任务时会遇到困难。本文提出了一个基于数据驱动的框架，通过监督学习的方法绕过传统的方程求解和优化过程。\n", "innovation": "本文提出的方法结合了合成数据集、基于LSTM的神经网络处理顺序精度点，以及根据不同连杆类型定制的Mixture of Experts（MoE）架构。每个专家模型专门针对特定类型的数据进行训练，并由类型确定层指导，支持单类型和多类型综合。此外，引入了一个新的模拟度量来评估预测质量，通过比较期望和生成的运动来实现。\n", "conclusion": "实验结果表明，本文提出的方法能够产生准确且无缺陷的连杆，适用于各种配置。这使得非专家用户也能直观高效地进行机构设计，并为运动学设计中大规模和灵活的综合开辟了新的可能性。\n"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08311", "html_url": "https://arxiv.org/abs/2507.08311", "title": "CAS Condensed and Accelerated Silhouette: 一种快速确定K均值聚类最优K值的有效方法", "title_en": "CAS Condensed and Accelerated Silhouette: An Efficient Method for Determining the Optimal K in K-Means Clustering", "authors": "Krishnendu Das,Sumit Gupta,Awadhesh Kumar", "background": "聚类是当今数据分析环境中决策过程的关键组成部分，已在生物信息学、社会网络分析和图像处理等领域广泛应用。然而，在大型数据集上实现聚类的准确性仍是一项重大挑战。", "innovation": "该论文提出了一种基于Condensed Silhouette方法和局部结构、间隙统计、类一致性比率（CCR）、聚类重叠指数（COI）及其算法的综合策略，用于确定最优的聚类簇数（k值），并通过该方法提高了高维数据集的执行速度，并保持了聚类的精度和可扩展性。", "conclusion": "实验结果表明，所提出的方法在高维数据集上的执行速度可达到99%的提升，同时保持了聚类的精度和可扩展性，这对于实时聚类需求或需要高效聚类并最小化资源使用的情景非常适用。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08317", "html_url": "https://arxiv.org/abs/2507.08317", "title": "一种嵌入全面自适应架构优化的量子神经网络模型用于云工作负载预测", "title_en": "A Comprehensively Adaptive Architectural Optimization-Ingrained Quantum Neural Network Model for Cloud Workloads Prediction", "authors": "Jitendra Kumar,Deepika Saxena,Kishu Gupta,Satyam Kumar,Ashutosh Kumar Singh", "background": "精确的工作负载预测和高级资源预订对管理动态云服务至关重要。传统的神经网络和深度学习模型经常在处理多样性和高维工作负载时遇到挑战，特别是在面对突然的资源需求变化时，导致效率低下。这个问题源于它们在训练期间有限的优化能力，仅依赖于通过传统算法调整连接权重这样的参数。", "innovation": "本文提出了一种名为CA-QNN的新型全面自适应架构优化基于可变量子神经网络，结合了量子计算的效率和完整的结构及量子位向量参数学习。该模型将工作负载数据转化为量子位，并通过带有量子控制非门激活函数的量子位神经元进行处理，实现直观的模式识别。此外，还引入了一种全面的网络结构优化算法，以便在可变大小的量子神经网络中促进结构和参数值的训练和传播。该算法在训练过程中结合了量子自适应调制和大小自适应重组。", "conclusion": "通过对包括四种异构云工作负载基准数据集在内的七个最先进的方法的全面评估，所提出的模型显示出优越的预测精度，与现有深度学习和量子神经网络方法相比，将预测误差减少至最多93.40%和91.27%。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08362", "html_url": "https://arxiv.org/abs/2507.08362", "title": "利用机器学习和增强的并行检测从文本生成BPMN模型", "title_en": "Leveraging Machine Learning and Enhanced Parallelism Detection for BPMN Model Generation from Text", "authors": "Phuong Nam Lê,Charlotte Schneider-Depré,Alexandre Goossens,Alexander Stevens,Aurélie Leribaux,Johannes De Smedt", "background": "将文本过程文档转换为正式的Business Process Model and Notation (BPMN)模型对于高效的规划、资源管理和持续运营至关重要，但这一过程仍然耗时且成本高。现有的基于规则或机器学习的方法在处理不同的书写风格时表现不佳，难以识别过程描述中的并行结构。因此，需要一种自动化的方法来从文本中提取BPMN模型，以提高这一过程的效率和准确性。", "innovation": "本研究引入了一种自动化的流水线方法，利用机器学习和大型语言模型从文本中提取BPMN模型。关键创新在于提供了一个新的标注数据集，显著改善了训练过程。通过将PET数据集扩充15个新的标注文档，增加了32个并行网关，弥补了现有数据集中的不足，使模型更好地捕捉并行结构这一常见但复杂的特征。该方法在重建精度方面表现出足够的性能，为组织加速BPMN模型创建提供了可能的基础。", "conclusion": "提出的这种方法在重建准确性方面表现出良好的性能，为组织自动从文本创建BPMN模型提供了一种有前景的基础。通过引入新的标注数据集，模型能够更好地捕捉并行结构，从而提高了BPMN模型提取的效率和准确性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08365", "html_url": "https://arxiv.org/abs/2507.08365", "title": "使用LSTM、CNN和Transformer预测人类驾驶员变道意图", "title_en": "Prediction of Lane Change Intentions of Human Drivers using an LSTM, a CNN and a Transformer", "authors": "Francesco De Cristofaro,Felix Hofbaur,Aixi Yang,Arno Eichberger", "background": "在复杂的交通情况下，前车的变道会影响到自动驾驶车辆的运动规划，因此预测这些变道意图对提升公共安全和效率具有重要意义。尽管已有许多相关研究，但很少有研究集中在预测一定时间内的变道意图上，而非特定时刻的预测。此外，尚未对不同架构之间的性能进行比较，以确定最有效的模型，及正确选择模型输入的方法。本文介绍了LSTM、CNN和Transformer网络结构，基于公开可用的highD数据集，进行了数据准备，并展示了网络设计和不同输入配置下的模型结果比较，实现了对人类驾驶员变道意图的预测。", "innovation": "本文引入了LSTM、CNN和Transformer三种不同的网络架构，用于预测人类驾驶员的变道意图，特别关注了对一定时间内的变道预测，并比较了不同架构的性能，以确定最优模型和正确的输入选择方法。", "conclusion": "通过比较不同的输入配置下的结果，发现Transformer网络表现最佳，且不易过拟合。该方法的准确性从82.79%到96.73%不等，总体性能良好，同时考虑了精确度和召回率的良好表现。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08390", "html_url": "https://arxiv.org/abs/2507.08390", "title": "使用粒子吉布斯采样进行扩散语言模型的推理时缩放", "title_en": "Inference-Time Scaling of Diffusion Language Models with Particle Gibbs Sampling", "authors": "Meihua Dang,Jiaqi Han,Minkai Xu,Kai Xu,Akash Srivastava,Stefano Ermon", "background": "离散扩散模型已成为语言建模的强大范式，与自动回归模型相媲美，尤其是在训练时间缩放方面。然而，离散扩散模型在推理时间缩放方面的研究仍然相对较少。本文研究了从离散扩散模型进行高质量文本生成的采样方法，特别是在奖励导向的设置下。", "innovation": "提出了基于粒子吉布斯采样的新型推理时间缩放方法。该方法通过条件顺序蒙特卡罗作为转换机制，逐步迭代优化完整扩散轨迹，确保更新样本逐步改进并更接近奖励加权的目标分布。此外，该研究还分析了在固定计算预算下的四种关键轴之间的权衡，包括粒子吉布斯迭代次数、粒子数量、去噪步数和奖励估计成本。", "conclusion": "实验结果表明，本文方法在奖励导向的文本生成任务中优于先前的推理时间策略，在不同计算预算下显著提高了准确性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08355", "html_url": "https://arxiv.org/abs/2507.08355", "title": "scE²TM: 通过主题建模实现可解释的单细胞嵌入", "title_en": "scE$^2$TM: Toward Interpretable Single-Cell Embedding via Topic Modeling", "authors": "Hegang Chen,Yuyin Lu,Zhiming Dai,Fu Lee Wang,Qing Li,Yanghui Rao", "background": "最新的测序技术使得研究人员能够以单细胞分辨率探索细胞异质性。同时，随着深度学习模型复杂性和性能的迅速提升，可解释性变得越来越重要。近年来，主题模型被广泛用于单细胞嵌入的学习和聚类分析，即单细胞嵌入主题模型。然而，之前的研究主要通过定性分析来评估模型的可解释性，这些模型可能存在解释坍塌的问题。此外，这些模型忽视了外部生物学知识，限制了分析性能。", "innovation": "我们提出了一种名为scE²TM的外部知识引导下单细胞嵌入主题模型，它提供高质量的细胞嵌入和强大的解释性，有助于全面的单细胞RNA测序数据的分析。我们使用20个单细胞RNA测序数据集进行了全面评估，结果显示scE²TM相较于7种现有先进技术在聚类性能上获得了显着的提升。同时，我们还提出了一个新的可解释性评估基准，引入了10个度量标准来定量评估单细胞嵌入主题模型的可解释性。", "conclusion": "我们使用scE²TM在20个单细胞RNA测序数据集上的全面评估显示，scE²TM相较于7种现有先进技术在聚类性能上获得了显着的提升。scE²TM提供的解释性在多样性和与潜在生物学信号的一致性方面表现良好，有助于更全面地揭示潜在的生物学机制。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08379", "html_url": "https://arxiv.org/abs/2507.08379", "title": "量子机器学习的进步：量子技术在哪些方面能提供帮助？", "title_en": "Advances in Machine Learning: Where Can Quantum Techniques Help?", "authors": "Samarth Kashyap,Rohit K Ramakrishnan,Kumari Jyoti,Apoorva D Patel", "background": "量子机器学习（QML）代表着量子计算与人工智能交汇领域的前景，旨在利用量子计算优势提升数据驱动任务。该论文探讨了QML在克服经典机器学习计算瓶颈方面的作用，特别是在处理复杂数据集方面。", "innovation": "介绍了QML的理论基础，包括量子数据编码、量子学习理论和优化技术，并根据不同数据类型和计算架构分类QML方法。批判性评估了量子主成分分析、量子增强传感以及材料科学中的应用，探讨了其实现的理论加速和实际限制，并详细讨论了噪声中间尺度量子设备带来的挑战，如硬件噪声、扩展性限制和数据编码开销。", "conclusion": "尽管QML在特定应用如量子化学和传感方面有显著潜力，但其在实际场景中的广泛应用还取决于克服技术和方法上的障碍。该论文强调需要开发量子本征算法、改进错误校正和建立现实基准，以弥合理论潜力与实际部署之间的差距。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08424", "html_url": "https://arxiv.org/abs/2507.08424", "title": "RTNinja: 一种用于纳米电子器件中随机电脉冲噪声信号分析的机器学习框架", "title_en": "RTNinja: a generalized machine learning framework for analyzing random telegraph noise signals in nanoelectronic devices", "authors": "Anirudh Varanasi,Robin Degraeve,Philippe Roussel,Clement Merckling", "background": "随机电脉冲噪声是纳米电子器件中的一种常见变异现象，源于缺陷位处的随机载流子交换，对器件的可靠性和性能具有严重影响。传统分析技术常依赖于严格的假设或手动干预，限制了其在复杂、嘈杂数据集上的应用。", "innovation": "我们引入了RTNinja，这是一种通用的完全自动化的机器学习框架，用于无监督分析随机电脉冲噪声信号。RTNinja通过贝叶斯推断和模型选择来去噪和离散化信号；并通过概率聚类和优化来推断源配置。我们开发了一个蒙特卡洛模拟器生成了大量的带标签数据集，以评估性能。研究表明，RTNinja在信号重构精度和源幅值及活动模式提取方面表现出色。", "conclusion": "我们的研究结果表明，RTNinja提供了一种稳健、可扩展且器件无关的工具，用于随机电脉冲噪声表征，能够支持大规模的统计基准测试、基于可靠性的技术认证、预测性失效建模以及下一代纳米电子器件的器件物理探索。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08382", "html_url": "https://arxiv.org/abs/2507.08382", "title": "两簇检验", "title_en": "Two-cluster test", "authors": "Xinying Liu,Lianyu Hu,Mudi Jiang,Simen Zhang,Jun Lou,Zengyou He", "background": "聚类分析是统计学和机器学习中的一个基本研究问题。在许多现代聚类方法中，需要确定两个样本子集是否来自同一个聚类。由于这些子集通常是通过某种聚类过程生成的，因此在该上下文中应用经典两样本检验会导致极小的p值，从而导致第一类错误率膨胀。为克服这种偏差，本文正式引入了两簇检验问题，并论证了它与传统的两样本检验是完全不同的假设检验问题。同时，我们提出了一种基于两个子集之间的边界点的新方法，用于推导出显著性量化的p值。实验表明，所提出的测试能够在与几种经典两样本测试方法相比时，显著降低第一类错误率。更重要的是，通过其在基于树的可解释聚类和显著性导向的分层聚类中的应用，进一步验证了这种两簇测试的实用性。", "innovation": "本文提出了两簇检验方法，这是一种与传统的两样本检验不同的假设检验问题。通过基于两个子集之间的边界点提出了一种新方法来推导p值，为显著性量化提供了新的途径。这种方法能够有效降低第一类错误率，并且已在多个应用场景中得到了验证。", "conclusion": "本文提出的两簇检验方法能够显著减少第一类错误率，并且已在合成数据和真实数据集上进行了实验验证。此外，该方法还被应用于基于树的可解释聚类和显著性导向的分层聚类，进一步验证了其实用性和有效性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08387", "html_url": "https://arxiv.org/abs/2507.08387", "title": "Online Pre-Training for Offline-to-Online Reinforcement Learning", "title_en": "Online Pre-Training for Offline-to-Online Reinforcement Learning", "authors": "Yongjae Shin,Jeonghye Kim,Whiyoung Jung,Sunghoon Hong,Deunsol Yoon,Youngsoo Jang,Geonhyeong Kim,Jongseong Chae,Youngchul Sung,Kanghoon Lee,Woohyung Lim", "background": " Offline-to-online reinforcement learning (RL) 涉及结合离线和在线RL的优点，首先通过离线预训练一个代理，然后通过在线互动进行微调。然而，最近的研究表明，离线预训练的代理在在线微调时常常表现出不佳，这是由于分布偏移导致的价值估计不准确，随机初始化在某些情况下更为有效。", "innovation": "提出了一个名为Online Pre-Training for Offline-to-Online RL (OPT) 的新方法，旨在解决离线预训练代理价值估计不准确的问题。OPT 引入了一个新的学习阶段Online Pre-Training，该阶段允许专门为有效在线微调训练新的价值函数。", "conclusion": "OPT 实现于 TD3 和 SPOT，在包括MuJoCo、Antmaze 和 Adroit 等多种D4RL 环境中，展示了平均 30% 的性能提升。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08456", "html_url": "https://arxiv.org/abs/2507.08456", "title": "空间填充位置性和Spiroformer", "title_en": "Space filling positionality and the Spiroformer", "authors": "M. Maurin,M.Á. Evangelista-Alvarado,P. Suárez-Serrato", "background": "变换器在处理序列数据方面表现出色。然而，将变换器模型推广到几何领域，例如流形，我们面临的问题是没有明确的全局顺序。本文提出了一种解决方案，通过让注意力头遵循空间填充曲线来解决这一问题。作为第一个实验示例，本文介绍了Spiroformer，这是一种沿二维球面上极螺旋线移动的变换器。", "innovation": "本文的创新之处在于提出了一种新的变换器模型——Spiroformer，它通过遵循极螺旋线对球面的顺序进行建模，解决了在几何域中缺乏全局顺序的问题。通过这种空间填充曲线的方法，使得变换器能够在没有明确全局顺序的几何空间中有效工作。这一创新为变换器处理几何数据提供了新的方法。", "conclusion": "本文介绍了Spiroformer模型，该模型通过沿极螺旋线结构在二维球面上建模顺序，成功地将变换器模型推广到了几何空间。未来的工作可以进一步探索这种模型在其他几何流形上的应用。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08472", "html_url": "https://arxiv.org/abs/2507.08472", "title": "在预算范围内预训练LLMs：三种优化器的比较", "title_en": "Pre-Training LLMs on a budget: A comparison of three optimizers", "authors": "Joel Schlotthauer,Christian Kroos,Chris Hinze,Viktor Hangya,Luzian Hahn,Fabian Küch", "background": "优化器在减少LLMs的预训练时间和提高模型性能中起着决定性作用。本研究对比了三种主要变体：默认标准AdamW、通过进化搜索开发的Lion和第二阶优化器Sophia。为了提高泛化能力，使用了两种不同的基础架构进行训练，并采用了单轮和多轮的方法，同时保持токены的数量恒定。通过最大更新参数化和较小的代理模型，针对每种基础架构和优化器的组合分别调整相关超参数。", "innovation": "本研究通过对比三种优化器（AdamW、Lion和Sophia）在预训练LLMs中的表现，特别关注它们在不同基础架构和训练策略下的性能差异。研究中引入了最大更新参数化和较小代理模型的方法来独立调整相关超参数，以更好地评估优化器的性能。", "conclusion": "虽然三种优化器的结果大致在同一范围内，但Sophia在训练和验证损失上表现出最低的值，Lion在训练GPU小时数上最快，而AdamW在下游评估结果上最好。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08443", "html_url": "https://arxiv.org/abs/2507.08443", "title": "KGRAG-Ex: 基于知识图谱扰动的可解释检索增强生成", "title_en": "KGRAG-Ex: Explainable Retrieval-Augmented Generation with Knowledge Graph-based Perturbations", "authors": "Georgios Balanos,Evangelos Chasanis,Konstantinos Skianis,Evaggelia Pitoura", "background": "检索增强生成（RAG）通过将响应与外部信息联系起来增强了语言模型的功能，但在检索依赖于非结构化文本时，解释性仍然是一个关键挑战。知识图谱（KGs）通过引入实体及其关系的结构化和语义丰富表示，提供了增强透明检索路径和可解释推理的解决方案。现有RAG系统在增强事实基础的同时，往往难以提供足够的解释性。", "innovation": "该研究提出了一种名为KGRAG-Ex的新RAG系统，该系统通过利用基于提示的信息提取构建的领域特定 KG 来改进事实基础和解释性。KGRAG-Ex通过图中的相关实体和语义路径来指导语料库检索，并将其转换为伪段落。引入基于扰动的解释方法来评估知识图谱衍生组件对生成答案的影响，增强了解释的可理解性和推理的透明度。对不同的扰动方法、图组件重要性与其结构位置之间的关系、语义节点类型的影响以及图指标与解释过程内组件影响之间的关系进行了实验分析。", "conclusion": "实验结果表明，KGRAG-Ex系统在提高响应的解释性方面表现出色，并且能够根据图组件的重要性及其结构位置提供透明的推理支持。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08465", "html_url": "https://arxiv.org/abs/2507.08465", "title": "基于秩集抽样的多层感知机：基于方差_bound_的泛化改进", "title_en": "Ranked Set Sampling-Based Multilayer Perceptron: Improving Generalization via Variance-Based Bounds", "authors": "Feijiang Li,Liuya Zhang,Jieting Wang,Tao Yan,Yuhua Qian", "background": "多层感知机（MLP）作为最基础的神经网络之一，广泛应用于分类和回归任务。本文通过建立一个新的泛化误差界，揭示了经验损失的方差如何影响学习模型的泛化能力。受到这一学习界限的启发，作者提出通过减少经验损失的方差来提升MLP的能力。", "innovation": "为了减少经验损失的方差，作者引入了一种有序结构的训练数据集，即通过秩集抽样（RSS）方法，进一步减少了损失的方差，并开发了RSS-MLP方法。理论结果表明，使用RSS估计的经验指数损失和逻辑损失的方差比使用单纯随机抽样（SRS）方法估计的要小。为了验证RSS-MLP的有效性，作者在两种凸损失函数下，通过两种聚合方法在十二个基准数据集上进行了对比实验。", "conclusion": "广泛的实验结果和分析证实，所提出的方法是有效且合理的。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08473", "html_url": "https://arxiv.org/abs/2507.08473", "title": "无需解释评估SAE的可解释性", "title_en": "Evaluating SAE interpretability without explanations", "authors": "Gonçalo Paulo,Nora Belrose", "background": "SAEs和transcoders已成为机器学习可解释性中的重要工具，但衡量它们的可解释性仍颇具挑战性，不同研究间缺乏共识，大多数评估方法都是先为每个潜在变量生成一个简短的解释，再基于这些解释能否帮助LLM在新情境下预测潜在变量的激活情况来进行评估。这种方法难以完全分离生成解释和评估解释的过程，这使得直接评估潜在变量的可解释性变得困难。现有大多数评估方法都会涉及生成自然语言解释，但在本文中，作者提出了适应现有方法来评估稀疏编码器的可解释性，这种方法无需在中间步骤生成自然语言解释，从而可能实现更直接且标准化的可解释性评估。作者还使用我们的可解释性指标生成的分数对人类评价进行比较，为社区提供了一些建议，以提高对这些技术的评估标准。", "innovation": "本文创新地提出了无需生成自然语言解释的评估方法，直接评估潜在变量的可解释性，并且将评估结果与人类评价进行比较，为改进这些技术的评估提供了具体建议。", "conclusion": "本文作者提出了一种新的评估方法，通过直接评估稀疏编码器的潜在变量的可解释性来改进对SAEs及其他类似技术的评价。这些评估结果与人类评价的比较，为未来研究提供了有价值的参考，有助于标准化和改进机器学习模型的可解释性评估流程。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08508", "html_url": "https://arxiv.org/abs/2507.08508", "title": "SFedKD：蕴含差异感知多教师知识蒸馏的序贯联邦学习", "title_en": "SFedKD: Sequential Federated Learning with Discrepancy-Aware Multi-Teacher Knowledge Distillation", "authors": "Haotian Xu,Jinrui Zhou,Xichong Zhang,Mingjun Xiao,He Sun,Yin Xu", "background": "序贯联邦学习（SFL）是一种新兴的联邦学习训练框架，在异构环境下能提供强大的收敛保证，因此受到了广泛关注。然而，实验证明在异构环境中，SFL存在严重的灾难性遗忘问题，即模型倾向于忘记之前客户端学到的知识。", "innovation": "本文提出了一种蕴含差异感知多教师知识蒸馏的序贯联邦学习框架（SFedKD）。SFedKD通过在多教师设置中扩展单教师解耦知识蒸馏方法，并基于教师和学生数据之间的分类分布差异为教师的目标类和非目标类知识分配不同的权重来增强模型训练效果，减轻灾难性遗忘。此外，通过一种基于贪心策略的互补教师选择机制来防止知识稀释和降低通信与计算成本。", "conclusion": "广泛的实验表明，SFedKD有效地克服了SFL中的灾难性遗忘，并优于现有的联邦学习方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08475", "html_url": "https://arxiv.org/abs/2507.08475", "title": "SynBridge:通过离散流桥接反应状态实现双向反应预测", "title_en": "SynBridge: Bridging Reaction States via Discrete Flow for Bidirectional Reaction Prediction", "authors": "Haitao Lin,Junjie Wang,Zhifeng Gao,Xiaohong Ji,Rong Zhu,Linfeng Zhang,Guolin Ke,Weinan E", "background": "化学反应的本质在于电子的再分配与重新组织，这种变化在物理世界中往往是通过电子转移或电子对的迁移来体现的，这些变化在本质上是离散且突然的，比如原子的电荷状态改变或化学键的形成与断裂。为了建模这些状态转换，文章提出了SynBridge模型，这是一种双向基于流的生成模型，用于实现多任务反应预测。SynBridge利用了图到图的变换网络架构，并且通过离散流桥链接任意两个离散分布之间的化学变化。", "innovation": "提出了SynBridge模型，这是一种双向基于流的生成模型，用于实现多任务反应预测。通过图到图的变换网络架构和离散流桥梁，SynBridge能够捕捉反应物和产物图之间的双向化学转换，通过键和原子的离散状态。", "conclusion": "通过在三个基准数据集（USPTO-50K，USPTO-MIT，Pistachio）上的广泛实验，SynBridge在正向合成和逆向合成任务中均实现了最先进的性能。进一步的消融研究和噪声调度分析显示了结构化扩散在离散空间中对反应预测的优势。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08505", "html_url": "https://arxiv.org/abs/2507.08505", "title": "在移动设备上高效部署视觉语言模型：OnePlus 13R 案例研究", "title_en": "Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R", "authors": "Pablo Robin Guerrero,Yueyang Pan,Sanidhya Kashyap", "background": "视觉语言模型(VLMs)为移动设备带来了有希望的能力，但其部署面临计算限制和能量效率低下的显著挑战，尤其是在实时应用方面。已经在OnePlus 13R上对部署框架进行了全面调查，评估了不同的框架在运行LLaVA-1.57B、MobileVLM-3B和Imp-v1.53B等代表性工作负载时的性能。", "innovation": "研究贡献了框架级别的基准测试、实用的分析工具以及对当前部署框架中硬件利用率瓶颈的深入分析，突出显示了CPU的一贯过度使用和GPU及NPU的有效或不稳定使用。", "conclusion": "研究揭示了各种框架的关键性能瓶颈：在生成令牌过程中一致过度使用CPU资源，而GPU和NPU加速器大多未使用。当使用GPU时，主要用于图像特征提取，导致饱和并降低设备响应性。研究强调了在现有部署框架中的CPU的过度使用以及GPU和NPU的有效或不稳定使用问题。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08537", "html_url": "https://arxiv.org/abs/2507.08537", "title": "递归奖励聚合", "title_en": "Recursive Reward Aggregation", "authors": "Yuting Tang,Yivan Zhang,Johannes Ackermann,Yu-Jie Zhang,Soichiro Nishimori,Masashi Sugiyama", "background": "在强化学习（RL）中，使智能体行为与特定目标保持一致通常需要设计一个精确的奖励函数，而这在目标复杂时是具有挑战性的。", "innovation": "该工作提出了一个替代方法，通过选择适当的奖励聚合函数来实现灵活的行为对齐，而不是修改奖励函数。通过引入马克夫决策过程（MDPs）的代数视角，证明贝尔曼方程自然地源自奖励的递归生成和聚合，从而推广了标准的折扣总和到其他递归聚合，例如折扣最大值和夏普比率。该方法适用于确定性和随机性场景，并可无缝集成到基于价值和行为-批判者算法中。", "conclusion": "实验结果表明，该方法有效地优化了多元目标，突显了其灵活性及其在实际应用中的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08617", "html_url": "https://arxiv.org/abs/2507.08617", "title": "在不平衡协变量偏移下联邦学习中的协作公平性", "title_en": "Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift", "authors": "Tianrun Yu,Jiaqi Wang,Haoyu Wang,Mingquan Lin,Han Liu,Nelson S. Yee,Fenglong Ma", "background": "在联邦学习中，合作公平性是一个关键挑战，而现有的方法往往忽略了实际且复杂的异质性形式：不平衡协变量偏移。", "innovation": "提出了一种新方法FedAKD（联邦异步知识蒸馏），这是一种简单而有效的方法，平衡了准确预测与协作公平性。具体策略包括：在客户端更新中引入了基于初步分析的异步知识蒸馏策略；通过传统知识蒸馏更新客户端模型，固定全局模型；选择高置信度的正确预测样本，并用这些样本更新全局模型，固定客户端模型；服务器更新简单地聚合所有客户端模型。", "conclusion": "在公开数据集（FashionMNIST和CIFAR10）和真实世界的电子健康记录（EHR）数据集上的实验结果表明，FedAKD显著改善了协作公平性、提高了预测准确性，并在高度异质的数据分布下促进了客户端的参与。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08542", "html_url": "https://arxiv.org/abs/2507.08542", "title": "CircFormerMoE：一种用于植物基因组环形RNA剪接位点检测和配对的端到端深度学习框架", "title_en": "CircFormerMoE: An End-to-End Deep Learning Framework for Circular RNA Splice Site Detection and Pairing in Plant Genomes", "authors": "Tianyou Jiang", "background": "目前环形RNA（circRNAs）的识别主要依赖于高通量RNA测序（RNA-seq）数据和基于对齐的算法，这些算法能够检测回溯剪接信号。然而，这些方法在植物中面临巨大挑战，因为植物的环形RNA剪接位点经常缺乏人类mRNA剪接的典型GT-AG序列，并且尚未有能有效且具有强泛化能力的深度学习模型。此外，目前识别的植物环形RNA数量可能大大低于其真实丰度。这些问题限制了对植物环形RNA的数量和功能的研究。", "innovation": "本文提出了一种基于Transformer和专家混合模式的深度学习框架CircFormerMoE，可以直接从植物基因组DNA中预测环形RNA。该框架包括两个子任务：剪接位点检测（SSD）和剪接位点配对（SSP）。经过对10种植物物种的基因数据验证，该模型不仅能发现已知的环形RNA，还能够发现未被注释的环形RNA，并且通过可解释性分析探讨了决定预测结果的序列模式。这个框架为植物环形RNA的大规模发现提供了一个快速且准确的计算方法和工具，为植物功能基因组学和非编码RNA注释的未来研究奠定了基础。", "conclusion": "本研究通过建立CircFormerMoE框架，提供了一种快速且准确的大规模环形RNA发现方法，为植物功能基因组学和非编码RNA注释提供了有力支持。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08605", "html_url": "https://arxiv.org/abs/2507.08605", "title": "遥感揭示印度旁遮普水稻可持续耕作实践的采用情况", "title_en": "Remote Sensing Reveals Adoption of Sustainable Rice Farming Practices Across Punjab, India", "authors": "Ando Shah,Rajveer Singh,Akram Zaytar,Girmaw Abebe Tadesse,Caleb Robinson,Negar Tafti,Stephen A. Wood,Rahul Dodhia,Juan M. Lavista Ferres", "background": "水稻耕作消耗了全球24-30%的淡水资源，在主要稻米产区的水资源管理方面提出了关键挑战。可持续灌溉实践，如直接播种稻米（DSR）和交替湿润和旱地（AWD），虽然能减少20-40%的水资源使用，同时保持产量，但在水资源稀缺加剧的情况下，对于确保长期农业生产起到了关键作用。然而，由于缺乏这些实践的采用率数据，缺乏数据支持的政策制定和资源分配受到了限制。", "innovation": "我们开发了一个创新的遥感框架，用于在印度旁遮普大规模监测可持续水资源管理实践。通过与《自然保护信托基金》的推广再生和无燃烧农业（PRANA）项目合作，该项目培训了大约1,400名农民采用节水技术并记录田间实践。结合Sentinel-1卫星数据，我们构建了一个分类系统，将水资源管理按播种和灌溉维度分开。我们的方法在区分DSR和传统淹灌移植水稻方面取得了78%的F1分数，无需先验种植日期知识。我们通过覆盖约300万农业地块的大规模地表观测数据展示了这种方法的可扩展性。", "conclusion": "本研究为政策制定者提供了追踪可持续水资源管理采纳情况的强大工具，使其可以针对干预措施和衡量项目影响进行大规模跟踪。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08697", "html_url": "https://arxiv.org/abs/2507.08697", "title": "基于机器学习的燃气轮机系统领域导向的优化性能", "title_en": "Domain-Informed Operation Excellence of Gas Turbine System with Machine Learning", "authors": "Waqar Muhammad Ashraf,Amir H. Keshavarzzadeh,Abdulelah S. Alshehri,Abdulrahman bin Jumah,Ramit Debnath,Vivek Dua", "background": "由于人工智能算法的黑箱性质和传统以数据为中心的分析中领域知识的低表现，火力发电厂在采用人工智能方面的领域一致型采纳仍然很低。", "innovation": "本文提出了一种基于马哈拉诺比斯距离的优化（MAD-OPT）框架，将马哈拉诺比斯距离约束引入数据为中心的分析，以引入领域知识。研究将MAD-OPT框架应用于395兆瓦容量的燃气轮机系统，以最大化热效率并最小化涡轮机热速率。研究还表明，该框架可以估计不同外部条件下的领域导向最佳工艺条件，并通过蒙特卡洛模拟评估得出最佳解决方案很稳健。此外，该研究还将MAD-OPT框架应用于燃气轮机系统设计发电能力范围外的理想工况，发现结果与电厂实际数据相符。研究表明，没有结合领域导向约束的数据为中心的优化分析可能不会在燃气轮机的实际运行中有效并且不可实施。该研究促进了带有人工智能的机器学习驱动的知识整合，提升了以领域导向的操作卓越，并为火力发电系统的安全人工智能采用铺平了道路。", "conclusion": "本研究展示了如何通过结合数据驱动的领域知识，将机器学习赋能的分析应用到火力发电系统中，提高了操作的精确性和安全性，从而促进在火力发电系统中安全且有效地采用人工智能。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08637", "html_url": "https://arxiv.org/abs/2507.08637", "title": "使用Wavelet-Enhanced Random Spectral Attention (WERSA)在近似线性时间内扩展注意力至极长序列", "title_en": "Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA)", "authors": "Vincenzo Dentamaro", "background": "传统的Transformer模型在处理长序列时计算成本高昂，因为常规注意力机制的时间复杂度是二次的O(n^2)。这导致了性能下降和对计算资源的需求增加，限制了长序列的处理能力。因此，需要一种新的机制来降低处理长序列的时间复杂度，同时保持高性能和低资源消耗的特点。", "innovation": "本文提出了一种新颖的机制——Wavelet-Enhanced Random Spectral Attention (WERSA)，其时间复杂度为线性的O(n)，能够在不牺牲性能的情况下有效地处理长序列。WERSA结合了内容自适应随机频谱特征、多分辨率Haar小波和可学习参数，以选择性地关注数据的信息性尺度，同时保持线性效率。WERSA在大规模比较和各种基准测试中表现出优势，无论在单GPU上还是在视觉、NLP、层次推理和多种注意力机制（如多头注意力、Flash-Attention-2、FNet、Linformer、Performer、Waveformer）方面。", "conclusion": "WERSA在不影响准确性的情况下，显著减少了计算负担，使长上下文模型成为可能，尤其在低资源硬件上，推动了AI的可持续和可扩展发展。尤其突出的是，WERSA在极长序列（如ArXiv-128k）上表现优异，即使在二次方法出现内存不足错误的情况下，也能在速度上超过Waveformer，成为有竞争力的方法中最快的一种。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08563", "html_url": "https://arxiv.org/abs/2507.08563", "title": "STRAP: 空间-时间风险注意力车辆轨迹预测技术在自动驾驶中的应用", "title_en": "STRAP: Spatial-Temporal Risk-Attentive Vehicle Trajectory Prediction for Autonomous Driving", "authors": "Xinyi Ning,Zilin Bian,Kaan Ozbay,Semiha Ergan", "background": "准确的车辆轨迹预测对于确保完全自主驾驶系统的安全性和效率至关重要。当前的大多数方法主要集中在建模观察到的运动模式和与其他车辆的交互上，但往往会忽略邻近车辆的不确定或挑衅行为所带来的潜在风险。", "innovation": "本文提出了一种新颖的空间-时间风险注意力轨迹预测框架，该框架结合了一个风险潜在场来评估由附近车辆行为引起的风险感知。框架利用空间-时间编码器和风险注意力特征融合解码器，将风险潜在场嵌入提取的空间-时间特征表示中，用于轨迹预测。此外，设计了一种风险加权损失函数以提高在高风险场景（如相对距离较短）中的预测准确性。通过广泛使用的NGSIM和HighD数据集的实验结果证明，该方法相较于最先进的方法降低了平均预测误差，特别是在高风险场景中。", "conclusion": "提出的框架提供了可解释、风险意识强的预测，有助于增强自主驾驶系统的决策鲁棒性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08707", "html_url": "https://arxiv.org/abs/2507.08707", "title": "SPLASH！基于样本高效偏好的逆强化学习在次优层次演示中的长时间对抗任务学习", "title_en": "SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations", "authors": "Peter Crowley,Zachary Serlin,Tyler Paine,Makai Mann,Michael Benjamin,Calin Belta", "background": "逆强化学习（IRL）提供了一个强大的框架，用于通过人类演示学习复杂的机器人任务。然而，大多数方法假定专家演示可用，但在实际中这并不总是可行。对于含次优性的演示，现有的方法往往不适用于长时间目标或对抗性任务。许多人机器人能力符合这些类别之一或两者，这突显了IRL在产生现场可用机器人代理方面的关键问题。", "innovation": "我们提出了SPLASH（基于样本高效的偏好的逆强化学习，用于从次优层次演示学习长时间对抗任务），该方法进一步推进了从次优演示学习到长时间和对抗性设置的最新技术。我们在模拟中的海军捕获旗帜任务上进行了实证验证，并通过从模拟到现实的转换实验在自主无人水面车辆上展示了其实用性。结果表明，我们提出的方法使SPLASH显著超过了从次优演示学习奖励的最新技术。", "conclusion": "我们的研究提高了IRL处理次优演示、长时间目标和对抗性任务的能力，并展示了在实际机器人应用中的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08686", "html_url": "https://arxiv.org/abs/2507.08686", "title": "勿忘我：通过知识融合与蒸馏对抗局部过拟合", "title_en": "Forget Me Not: Fighting Local Overfitting with Knowledge Fusion and Distillation", "authors": "Uri Stern,Eli Corn,Daphna Weinshall", "background": "深度神经网络中的过拟合比预期的更为罕见。尽管理论预测更大的模型容量最终会引发过拟合，但在实践中这种情况却很少发生。然而，如果过拟合确实发生的话，可能是局部地局限于数据空间的特定子区域。", "innovation": "该研究引入了一种新的分数来测量深度模型在验证数据上的遗忘率，以捕捉局部过拟合的概念，即性能降级限定在输入空间的特定区域。该工作提出了一种两阶段方法，通过利用单一模型的训练历史，来恢复并保留被遗忘的知识：首先将检查点聚合成一个集成模型，然后将其蒸馏回原始大小的单个模型，从而在不增加推理成本的情况下提高性能。", "conclusion": "在多个数据集、现代架构和训练制度下进行的广泛实验验证了该方法的有效性。特别地，在标签噪声存在的情况下，该方法（知识融合后进行知识蒸馏）优于原始模型和独立训练的集成模型，实现了减少训练和推理复杂性的双赢局面。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08736", "html_url": "https://arxiv.org/abs/2507.08736", "title": "通过平台期阶段活动特征分析减轻灾难性遗忘", "title_en": "Catastrophic Forgetting Mitigation Through Plateau Phase Activity Profiling", "authors": "Idan Mashiach,Oren Glickman,Tom Tirer", "background": "深度神经网络在学习新任务时，会出现灾难性遗忘现象，即新任务的学习导致之前学习的知识被覆盖。目前，正则化技术试图通过识别并约束关键参数来保留先前的知识。尽管在深度学习的非凸优化景观中，已经提出了许多方法来应对这一挑战，但本文提出了一种新的视角：在最终训练停滞阶段跟踪参数比在整个训练过程中监测参数更有效。研究指出，在停滞阶段活动较高的参数（即运动和变异性）揭示了损失景观中相对平坦的方向，这使得它们适合适应新任务的同时保留之前的知识。", "innovation": "本文提出了一种新的缓解灾难性遗忘的方法，即在最终训练停滞阶段跟踪参数的活动特征，认为停滞阶段活动较高的参数揭示了相对平坦的方向，适合适应新任务的同时保留先前的知识。", "conclusion": "本文的研究表明，这种在训练停滞阶段跟踪参数活动的方法，在平衡灾难性遗忘缓解与新任务高性能方面取得了更好的效果。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08610", "html_url": "https://arxiv.org/abs/2507.08610", "title": "使用沟通游戏提高无需额外数据的图像描述能力的新兴自然语言", "title_en": "Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data", "authors": "Parag Dutta,Ambedkar Dukkipati", "background": "图像描述是各类AI系统发展中的一个重要问题，训练这些系统需要大量的标注图像。然而，现有的所有标注数据已经被用于训练大规模的视觉语言模型（VLMs），这使得 difficult to improve the performance of the same. 因此，有必要探索未监督的图像描述表现，因为这仍相对未被充分研究。该研究针对这一挑战提出了一个基于多代理强化学习的系统。", "innovation": "该研究提出了一个名为LoGIC（Lewis Communication Game for Image Captioning）的方法，这是一种基于多代理强化学习的游戏。该方法利用了一个'演讲者'和一个'听众'，旨在学习自然语言的沟通策略。使用预训练的VLM作为'演讲者'和大型语言模型（LLM）作为'听众'进行训练，获得了46的BLEU分数，相比于标准VLM的44个BLEU分数，取得了绝对的2个单位的优势。进一步地，将'演讲者'替换为轻量组件（i）视觉Transformer（ViT）和（ii）GPT2语言生成模型，从零开始训练，获得了31的BLEU分数，相比已有无监督图像描述方法提高了10个点。", "conclusion": "通过使用LoGIC方法，研究发现图像描述性能的改进源自于代理学习进行游戏的过程。无需额外标注，研究利用预先训练的视觉语言模型和大型语言模型，提出了一种新的无监督图描绘方法，验证了该方法的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08597", "html_url": "https://arxiv.org/abs/2507.08597", "title": "ADAPT: 一种对抗恶意软件检测中概念漂移的伪标签方法", "title_en": "ADAPT: A Pseudo-labeling Approach to Combat Concept Drift in Malware Detection", "authors": "Md Tanvirul Alam,Aritran Piplai,Nidhi Rastogi", "background": "机器学习模型通常用于恶意软件分类，但由于概念漂移，它们会随着时间性能降低。适应这些模型以应对不断变化的数据分布需要频繁更新，而这些更新依赖于昂贵的准确注释。虽然主动学习可以减轻标注负担，但通过半监督学习利用未标记数据在恶意软件检测背景下仍然是一种相对未被充分探索的方法。", "innovation": "我们引入了一种新的模型通用伪标注半监督算法ADAPT，该方法可以应用于包括神经网络和树型算法在内的各种机器学习模型。我们对来自Android、Windows和PDF领域五个不同恶意软件检测数据集进行了广泛的实验，结果表明该方法始终优于基准模型和竞争性基准。", "conclusion": "本研究为机器学习模型在恶意软件检测中有效应对概念漂移铺平了道路。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08718", "html_url": "https://arxiv.org/abs/2507.08718", "title": "在策略镜像下降中的正则化效应", "title_en": "On the Effect of Regularization in Policy Mirror Descent", "authors": "Jan Felix Kleuker,Aske Plaat,Thomas Moerland", "background": "策略镜像下降（PMD）是一个统一的框架，它将策略梯度方法与一种名为镜像下降的第一阶优化方法联系起来。PMD的核心特点是包含两个关键的正则化组件：（i）一个距离项，用于稳定策略更新的可信区域；（ii）一个MDP正则化项，它扩充了奖励函数以促进结构化和鲁棒性。尽管PMD在理论上得到了广泛研究，但其实际效果的研究却相对较少。", "innovation": "这项工作进行了大规模的实证分析，对两个正则化的技术进行了比较，使用超过50万次的训练种子在小型强化学习环境中验证了它们的交互作用。结果表明，虽然这两种正则化技术可以部分互相替代，但它们的精确组合对于实现稳健性能至关重要。", "conclusion": "这些发现突显了在强化学习中推进更鲁棒算法研究的潜力，特别是在超参数敏感性方面。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08738", "html_url": "https://arxiv.org/abs/2507.08738", "title": "自适应非线性矢量自回归：噪声混沌时间序列的稳健预测", "title_en": "Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series", "authors": "Azimov Sherkhon,Susana Lopez-Moreno,Eric Dolores-Cuenca,Sieun Lee,Sangil Kim", "background": "非线性矢量自回归(NVAR)和水库计算(RC)在混沌动力系统预测方面（如洛伦茨63模型和厄尔尼诺-南方涛动）展现出潜力。然而，这两种方法依赖固定的非线性变换——NVAR中的多项式展开或RC中的随机特征映射，这限制了它们对高噪声或实际数据的适应性。此外，这些方法在高维设置中表现不佳，因为他们在读出计算中需要进行昂贵的矩阵求逆操作。", "innovation": "提出了一种自适应NVAR模型，它结合了延迟嵌入的线性输入和由浅层可学习多层感知器(MLP)生成的特征。MLP和线性读出使用基于梯度的优化联合训练，使模型能够学习数据驱动的非线性关系，同时保留简单的读出结构。与标准NVAR相比，该方法避免了对岭参数和延迟参数进行详尽且敏感的网格搜索的需要，而是专门针对神经网络超参数进行调优，从而提高了可扩展性。实验结果表明，该自适应模型在噪声条件下比标准NVAR具有更高的预测准确性和更强的鲁棒性，并且在较低的观测频率下表现出稳健的预测能力。", "conclusion": "微观实验显示，自适应NVAR模型在噪声和合成噪声条件下有更高的预测准确度，鲁棒性强，特别是在低观测频率下表现出更好预测性能。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08761", "html_url": "https://arxiv.org/abs/2507.08761", "title": "使用离线数据的强化学习中惩罚不可行动作和奖赏缩放", "title_en": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data", "authors": "Jeonghye Kim,Yongjae Shin,Whiyoung Jung,Sunghoon Hong,Deunsol Yoon,Youngchul Sung,Kanghoon Lee,Woohyung Lim", "background": "使用离线数据进行强化学习时，Q值外推错误是一个主要问题。", "innovation": "提出了一种结合奖赏缩放与层归一化（RS-LN）和惩罚机制（PA）的新算法Pars（Penalizing Infeasible Actions and Reward Scaling），以逐步减少数据范围以外的Q值。", "conclusion": "Pars在D4RL基准上展示了优于其他最先进算法的性能，特别是在AntMaze Ultra任务上取得了显著成功。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08746", "html_url": "https://arxiv.org/abs/2507.08746", "title": "分区混合量子傅里叶神经操作符在科学量子机器学习中的应用", "title_en": "Partitioned Hybrid Quantum Fourier Neural Operators for Scientific Quantum Machine Learning", "authors": "Paolo Marcandelli,Yuanchun He,Stefano Mariani,Martina Siena,Stefano Markidis", "background": "本文介绍了分区混合量子傅里叶神经操作符（PHQFNO），它是量子傅里叶神经操作符（QFNO）在科学机器学习中的扩展。QFNO是用于处理科学数据的一种神经网络架构，而PHQFNO通过在经典和量子资源之间分割傅里叶运算，使量子-经典混合变得更可调，并支持在经典和量子设备上的分布式执行。研究方法扩展了QFNO到更高维度，并通过消息传递框架在不同分区之间分配数据。输入数据通过一元编码转化为量子态，并使用变分方案优化量子电路参数。这种方法通过PennyLane实现，并结合PyTorch使用，在伯努利方程、不可压缩和可压缩纳维-斯托克斯方程中进行了评估。实验结果表明，PHQFNO在准确度上不逊于经典FNO。在不可压缩纳维-斯托克斯方程中，PHQFNO比其经典对应物更准确。此外，研究人员还进行了输入噪声的敏感性分析，确认了与经典基线相比，PHQFNO具有更好的稳定性。", "innovation": "本文的主要创新之处在于PHQFNO将傅里叶运算分配到经典和量子资源上，实现了可调的量子-经典混合，并支持分布式执行。此外，它扩展了QFNO到更高维度，并引入了一种消息传递框架来分配不同分区的数据。在伯努利方程和纳维-斯托克斯方程中，PHQFNO的性能优于其经典对应物，并且它在输入噪声下的稳定性也优于经典方法。", "conclusion": "PHQFNO在科学机器学习中取得良好的实验结果，与经典方法相比，它能够获得更高的准确度。通过分割和优化量子运算，该方法展示了在不同设备上优化和执行的潜力，并进一步验证了量子计算在科学机器学习中的应用前景。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08771", "html_url": "https://arxiv.org/abs/2507.08771", "title": "BlockFFN：朝向基于块的激活稀疏度混合专家模型的端侧加速", "title_en": "BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity", "authors": "Chenyang Song,Weilin Zhao,Xu Han,Chaojun Xiao,Yingfa Chen,Yuxuan Li,Zhiyuan Liu,Maosong Sun", "background": "随着大规模语言模型（LLMs）的计算负担越来越大，具有激活稀疏性的混合专家（MoE）架构，如ReLU激活和RMSNorm融合的路由器，受到了越来越多的关注。然而，传统的MoE在路由方面缺乏可微分性和灵活性，且参数激活稀疏性较低，导致了加速设备下的低效率。激活稀疏和块级稀疏的不平衡阻碍了加速技术（如推测性解码）的有效利用。", "innovation": "本文提出了一种新颖的MoE架构——BlockFFN及其高效的训练和部署方法，通过集成了ReLU激活和RMSNorm的可微分和灵活性更高路由器解决了这些问题。还设计了促进块级稀疏（CLS）和令牌级稀疏（TLS）的训练目标，以增强加速友好性。最后，实现了结合激活稀疏性和推测性解码的高效加速内核。实验结果表明，BlockFFN在其他MoE基线上的性能优越，达到了80%的TLS和70%的8-令牌块级稀疏性。", "conclusion": "本研究通过BlockFFN架构及其相关技术，显著提高了混合专家模型在端侧设备上的加速性能，并展示了该模型在实际端侧设备上相较于密集模型的高达3.67倍的加速效果。所有代码和检查点均已公开提供。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08751", "html_url": "https://arxiv.org/abs/2507.08751", "title": "基于机器学习的自动简化框架用于符号加速器", "title_en": "ML-Based Automata Simplification for Symbolic Accelerators", "authors": "Tiffany Yu,Rye Stahle-Smith,Darssan Eswaramoorthi,Rasha Karakchi", "background": "符号加速器在基因组学、自然语言处理(NLP)和网络信息安全等领域中越来越多地用于处理符号数据。然而，这些加速器由于需要大量的内存和复杂的路由而面临扩展性问题，特别是在处理大规模数据集时。", "innovation": "本文提出了AutoSlim，一个基于机器学习的图简化框架，用于减少搭建在非确定有限自动机(NFA)上的FPGA基础网络叠加（如NAPOLY+）上的符号加速器的复杂性。AutoSlim使用随机森林分类来基于边分数和结构特征去除低影响转换，显著减少了自动机图的密度，同时保持语义正确性。与之前的工具不同，AutoSlim旨在实现自动的基于权重转换的得分感知简化，以便进行高效的基于排名的序列分析。", "conclusion": "在NAPOLY+上的数据集（1K到64K节点）上评估了AutoSlim，进行了包括延迟、吞吐量和资源使用在内的性能测量。与现有的基准相比，AutoSlim的图形规模扩大了十倍，且在FPGA LUT和转换的修剪方面分别达到了40%和30%的减少。我们的研究表明，硬件互连（扇出）对硬件成本有重大影响，而AutoSlim的修剪措施减轻了资源膨胀。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08793", "html_url": "https://arxiv.org/abs/2507.08793", "title": "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning", "title_en": "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning", "authors": "James McCarthy,Radu Marinescu,Elizabeth Daly,Ivana Dusparic", "background": "风险保守约束强化学习（Risk-averse Constrained Reinforcement Learning, RaCRL）旨在学习能够最小化罕见且灾难性约束违反可能性的策略，这些约束违反是由环境固有随机性引起的。通常，风险厌恶会导致环境的保守探索，导致算法收敛到次优化策略，这些策略未能充分最大化奖励，甚至在某些情况下未能实现目标。", "innovation": "本文提出了一种基于探索的风险厌恶强化学习方法，称为乐观风险保守行动价值（Optimistic Risk-averse Actor Critic, ORAC），它通过最大化基于状态动作回报值函数的局部上置信边界，同时最小化基于风险保守状态动作成本值函数的局部下置信边界，构建探索性政策。H-policy在每次步骤中根据成本价值是否超过或低于安全约束值增加或减少权重，从而鼓励探索环境中的不确定区域，以发现高奖励状态，同时仍然满足安全约束。实验结果表明，该方法能够防止收敛到次优化策略，显著改善了奖励与成本之间的权衡关系。", "conclusion": "ORAC方法在包括Safety-Gymnasium和复杂建筑能源管理系统CityLearn等多种连续控制任务中，能够避免收敛到次优化策略，显著改善了奖励与成本之间的权衡关系。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08749", "html_url": "https://arxiv.org/abs/2507.08749", "title": "利用离散时间条件高斯科扎曼网络模型部分观测非线性动力系统和高效数据同化", "title_en": "Modeling Partially Observed Nonlinear Dynamical Systems and Efficient Data Assimilation via Discrete-Time Conditional Gaussian Koopman Network", "authors": "Chuanqi Chen,Zhongrui Wang,Nan Chen,Jin-Long Wu", "background": "近年来，为了预测高维复杂动力系统的状态，研究人员开发了多种机器学习方法。特别是针对由非线性偏微分方程（PDEs）描述的系统，由于其复杂性，精确预测和数据同化的挑战日益增多。本研究聚焦于部分观测非线性系统，这在工程和地球科学等许多应用中较为常见。通过引入科济曼嵌入，本研究致力于发现未观测状态的恰当隐藏表示，使得隐藏状态的动力学可以条件线性化，即在给定观测状态的情况下线性化。这种方式将观测和隐藏状态的模型系统转化为条件高斯系统，其中隐藏状态的后验分布为高斯分布，可以通过解析公式高效计算。", "innovation": "本研究开发了一种离散时间条件高斯科扎曼网络（CGKN），该网络用于学习能够高效进行状态预测和数据同化的代理模型。该网络利用科扎曼嵌入技术，发现未观测系统状态的恰当隐藏表示，使得隐藏状态的动力学在给定观测系统状态的情况下表现为线性。这种代理模型系统变成了条件高斯系统，可以利用解析公式高效地评估隐藏状态的后验分布。这种解析公式便于将数据同化的性能纳入代理模型的学习过程中，从而统一了科学机器学习（SciML）和数据同化。通过在不可预测和湍流特征显著的非线性PDEs（如粘性Burgers方程、Kuramoto-Sivashinsky方程和2D Navier-Stokes方程）上对CGKN框架的实际应用展示，证明了该框架在状态预测和数据同化方面的优异性能。", "conclusion": "离散时间CGKN框架展示了在部分观测非线性动力系统的状态预测和数据同化的应用中具有与当前先进SciML方法相似的性能，并且提供高效且准确的数据同化结果。这种框架还作为案例，说明如何统一科学研究导向的机器学习模型的发展与它们的外循环应用，如设计优化、反问题和最优控制。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08721", "html_url": "https://arxiv.org/abs/2507.08721", "title": "在测试时间自适应中的风险监控", "title_en": "Monitoring Risks in Test-Time Adaptation", "authors": "Mona Schirmer,Metod Jazbec,Christian A. Naesseth,Eric Nalisnick", "background": "在部署预测模型时，遇到移位数据是一个普遍的挑战。测试时间自适应（TTA）方法通过仅使用未标注的测试数据不断调整已部署的模型来应对这一问题。尽管TTA可以延长模型的生命期，但它只是一个临时解决方案。最终，模型可能会退化到必须脱机重新训练的程度。为了检测这种最终失败点，我们提出将TTA与风险监控框架配对，该框架可以跟踪预测性能，并在预定义性能标准被违反时发出警报。特别地，我们将现有的基于逐步测试的风险监控工具扩展为具有测试时间更新模型和无测试标签可用于估计感兴趣性能指标场景的应用。这些扩展解锁了严格的统计风险监控在TTA中的应用，我们展示了我们提出的风险监控框架在代表性数据集、移位类型和TTA方法上的有效性。", "innovation": "本文提出了一种创新的方法，即将风险监控框架与测试时间自适应（TTA）结合使用，以更有效地监测模型性能。具体而言，作者通过扩展现有的基于序贯检验的风险监控工具来涵盖测试时间更新模型且无测试标签可用的情况。这不仅使严格的统计风险监控应用于TTA成为可能，还有效地监控了TTA过程中性能的退化，尤其是在数据分布发生移位的情况下。", "conclusion": "通过结合风险监控框架和测试时间自适应（TTA）方法，作者证明了该监控框架能够跨多种数据集、模型转移类型和TTA方法展示出显著的效果。这为确保预测模型在现实应用中的可靠性和长期性能提供了新的途径，并为实际产品化实施TTA提供了有效的风险防控策略。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08784", "html_url": "https://arxiv.org/abs/2507.08784", "title": "具有收敛保证的贪婪低秩梯度压缩在分布式学习中的应用", "title_en": "Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees", "authors": "Chuyan Chen,Yutong He,Pengrui Li,Weichen Jia,Kun Yuan", "background": "分布式优化对于大规模信号处理和机器学习至关重要，但通信开销仍然是一个主要瓶颈。低秩梯度压缩通过将传输的梯度近似为低秩矩阵来减少通信，提供了一种有望解决问题的方法。现有的方法通常采用随机化或贪婪压缩策略，随机化方法虽然引入了高方差，但实际性能较差；而贪婪方法尽管取得了很好的实际效果，但是在收敛性方面却没有保证。", "innovation": "本文提出了GreedyLore——首个具有严格收敛保证的贪婪低秩梯度压缩算法。GreedyLore结合了误差反馈来修正贪婪压缩引入的偏差，并引入了一种半懒惰子空间更新机制，确保压缩操作器在整个迭代过程中保持收缩性。由此证明了GreedyLore在标准优化器（如MSGD和Adam）下具有$\textrm{O}(\tfrac{\beta}{\tbinom{N}{T}} + \tfrac{1}{T})$的收敛速率，这是低秩梯度压缩中的首个线性加速收敛速率。", "conclusion": "通过广泛的实验，我们验证了我们的理论发现，GreedyLore能够显著提高分布式学习的效率和准确性，同时保证了严格的收敛性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08794", "html_url": "https://arxiv.org/abs/2507.08794", "title": "一令牌愚弄LLM-as-judge", "title_en": "One Token to Fool LLM-as-a-Judge", "authors": "Yulai Zhao,Haolin Liu,Dian Yu,S.Y. Kung,Haitao Mi,Dong Yu", "background": "生成奖励模型（也称为LLM作为评判者），使用大语言模型（LLMs）评估答案质量，被越来越多地应用于具有验证奖励的强化学习（RLVR）中，尤其是在涉及自由形式输出的复杂推理任务中，它们通常优于基于规则的刚性指标。在这种范式中，大语言模型通常被提示比较候选答案和真实参考答案，并分配一个表示正确性的二元奖励。尽管这一比较任务看似简单，我们发现生成奖励模型对表面操纵极其脆弱：非单词符号（例如“：”或“.”）或推理的前缀如“思维过程：”和“让我们一步步解决问题”常常导致错误的肯定奖励。", "innovation": "该研究提出了一个简单但有效的大规模数据增广策略，并培训了一个新的生成奖励模型，显著提高了鲁棒性。研究结果强调了对更可靠的大语言模型评估方法的迫切需求。", "conclusion": "研究发现表明，生成奖励模型在面对表面上的操纵时存在重大漏洞，这构成了对依赖此类模型的核心算法范式的严重威胁。研究揭示了广泛存在于LLMs、数据集和提示格式中的这一弱点。为解决此问题，研究团队提供了一个鲁棒且通用域的奖励模型及合成训练数据，以供社区使用和进一步研究，以应对生成奖励模型的鲁棒性问题。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08802", "html_url": "https://arxiv.org/abs/2507.08802", "title": "非线性表示难题：因果抽象对机制化可解释性是否足够？", "title_en": "The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?", "authors": "Denis Sutter,Julian Minder,Thomas Hofmann,Tiago Pimentel", "background": "最近因果抽象的概念被用于解释机器学习模型的不透明决策过程。大多数可解释性论文将这些映射视为线性函数，基于线性表示假设，即特征在模型表示中线性编码。然而，这种线性约束并非因果抽象的定义所必需。这项工作批评性地审视了因果抽象的概念，考虑了任意强大的对齐映射。证明了在合理假设下，任何神经网络都可以映射到任何算法，使得这种不加限制的因果抽象变得琐碎且无信息量。这与理论发现相伴，展示了即使这些模型无法解决实际任务，模型到算法的映射仍可以达到完美的准确性。这提出了非线性表示难题：如果提高因果抽象分析中对齐映射的非线性约束，将无法在这些映射的复杂性和准确性之间获得理性的平衡。", "innovation": "这项工作通过研究任意强大的对齐映射，详细证明了线性约束不是因果抽象的必要条件，并展示了即使模型无法解决实际任务，模型到算法的完全准确映射也是可能的。这一研究指出了因果抽象在机制化可解释性中的局限性，提出了新的研究方向，即探索信息编码假设与因果抽象之间的联系。", "conclusion": "因果抽象对机制化可解释性来说并不足够，因为它缺乏关于模型如何编码信息的假设变得无意义。研究这一信息编码假设与因果抽象之间的关系将导致未来的研究兴奋。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08005", "html_url": "https://arxiv.org/abs/2507.08005", "title": "探索扩散模型在小分子生成中的潜力", "title_en": "Unraveling the Potential of Diffusion Models in Small Molecule Generation", "authors": "Peining Zhang,Daniel Baker,Minghu Song,Jinbo Bi", "background": "生成式AI为化学家在药物设计方面提供了新颖的想法，并促进了对巨大化学空间的探索。扩散模型(DMs)作为一种新兴工具，最近在药物研发(R&D)中引起了广泛关注。文章综述了DMs在分子生成领域的最新进展和应用，介绍了DMs的理论原理，分类了各种基于DM的分子生成方法，并评估了这些模型在基准数据集上的表现，特别强调比较了现有的3D方法的生成性能。", "innovation": "文章对该领域进行了全面的综述，不仅介绍了DMs的理论基础，还按照数学和化学应用将其分类，并详细评估了这些模型的性能，尤其是对3D方法的生成性能进行了对比分析，为充分利用DMs在药物发现领域的潜力提出了未来的研究方向。", "conclusion": "文章总结了当前面临的主要挑战，并提出了未来的研究方向，以充分利用扩散模型在药物发现中的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08015", "html_url": "https://arxiv.org/abs/2507.08015", "title": "评估FinGPT模型在金融NLP应用中的能力和局限性", "title_en": "Assessing the Capabilities and Limitations of FinGPT Model in Financial NLP Applications", "authors": "Prudence Djagba,Chimezie A. Odinakachukwu", "background": "本文评估了FinGPT，这是一种专门针对金融领域的语言模型，其在六个关键的自然语言处理（NLP）任务中进行了测试：情感分析、文本分类、命名实体识别、金融问答、文本摘要以及股票市场动向预测。", "innovation": "本文使用了金融领域的特定数据集来评估FinGPT的能力和局限性，发现FinGPT在情感分析等分类任务中表现出色，有时能达到与GPT-4相当的结果，但在涉及推理和生成的任务中，如金融问答和摘要，它的表现则显著较低。值得注意的是，与GPT-4和人类基准的比较揭示了在数值准确性和复杂推理方面的显著差异。", "conclusion": "总体来说，研究结果表明FinGPT在某些结构化的金融任务上是有效的，但尚未成为全面的解决方案。本文为未来的研究提供了一个有用的标准，并强调了在金融语言模型中需要在架构改进和领域特定优化方面做出的努力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08013", "html_url": "https://arxiv.org/abs/2507.08013", "title": "MedicalBERT：利用预训练BERT模型增强生物医学自然语言处理", "title_en": "MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model", "authors": "K. Sahit Reddy,N. Ragavenderan,Vasanth K.,Ganesh N. Naik,Vishalakshi Prabhu,Nagaraja G. S", "background": "近年来，自然语言处理（NLP）的进步主要得益于像BERT、RoBERTa、T5和GPT这样的预训练语言模型。尽管这些模型在理解复杂文本方面表现出色，但生物医学文献因其特定领域的术语呈现挑战，尤其是像Word2Vec和双向长短期记忆（Bi-LSTM）这样的模型无法充分解决这些问题。虽然GPT和T5可以捕捉上下文，但在需要双向理解的任务中仍存在不足，这与BERT不同。因此，为了解决这一问题，本文提出了一种名为MedicalBERT的预训练BERT模型，该模型在大规模生物医学数据集上进行训练，并配备了针对特定领域的词汇，从而增强了对生物医学术语的理解。MedicalBERT模型进一步得到优化和微调，用于解决包括命名实体识别、关系抽取、问答、句子相似性和文档分类在内的多种任务。各种性能指标，如F1分数、准确性和Pearson相关系数，被用来展示相对于其他基于BERT的模型（如BioBERT、SciBERT和ClinicalBERT）的效率。", "innovation": "提出的MedicalBERT模型是基于预训练的BERT模型，通过在其上训练大规模的生物医学数据集并配备特定领域的词汇，来增强对生物医学术语的理解。它进一步优化和微调，以解决包括命名实体识别、关系抽取、问答、句子相似性和文档分类在内的多种任务，并在这些任务中相对于其他基于BERT的模型表现出更好的性能，尤其是在大多数基准测试中优于其他模型，并且在所有评估任务中平均高出5.67%。", "conclusion": "本工作强调了利用预训练BERT模型进行医疗NLP任务的潜力，展示了通过迁移学习技术捕捉特定领域信息的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08039", "html_url": "https://arxiv.org/abs/2507.08039", "title": "评估文本到图像模型指令遵循一致性的方法", "title_en": "Towards Evaluating Robustness of Prompt Adherence in Text to Image Models", "authors": "Sujith Vemishetty,Advitiya Arora,Anupama Sharma", "background": "近年来，大型语言模型（LLMs）取得了显著进步，展示了它们的卓越能力和多用途应用。这些模型在现实世界中的广泛应用引发了对其可靠性和有效性的研究。此外，多模态LLMs和Text-to-Image模型最近才获得显著关注，尤其是与仅文本的LLMs相比。然而，由于缺乏对其性能和鲁棒性评估的研究，这些模型的可靠性仍受到限制。", "innovation": "本文提出了一种全面的评估框架，专注于评估Text-to-Image模型生成符合输入文本提示中指定变因子图像的一致性。研究使用GPT-4o生成的文本描述作为基准图像，利用Text-to-Image模型生成图像，再通过相同系统提示使用GPT-4o进行评估，比较两次生成的描述间的差异。结果显示这些模型难以生成仅有两个变因子的简单二值图像：简单的几何形状及其位置。并且通过预训练的VAEs验证了这一点。", "conclusion": "本研究揭示了生成模型在遵循简单二值图像指令方面存在的挑战，特别是在仅涉及两个变因子的情况下。说明需要进一步的研究和优化来提高Text-to-Image模型的可靠性和鲁棒性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08052", "html_url": "https://arxiv.org/abs/2507.08052", "title": "轻量级云掩模模型在高光谱成像机载推理中的应用", "title_en": "Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging", "authors": "Mazen Ali,António Pereira,Fabio Gentile,Aser Cortines,Sam Mugel,Román Orús,Stelios P. Neophytides,Michalis Mavrovouniotis", "background": "在高光谱卫星成像中，云和云影掩模提取是一道重要的预处理步骤，能够提取出高质量的、适合分析的数据。", "innovation": "本文评估了多种机器学习方法，包括梯度提升方法（如XGBoost和LightGBM）和卷积神经网络（CNNs）。所有模型的准确率都超过了93%；卷积神经网络结合特征减少的方法具有高准确率、低存储需求和快速推理性能的优势，尤其在CPU和GPU上的表现最佳。具有最高可训练参数量仅为597的版本在部署可行性、准确率和计算效率方面表现出最佳的平衡。", "conclusion": "轻量级人工智能模型有潜力实现高光谱图像实时处理，并支持开发用于空间应用的机载卫星人工智能系统。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08034", "html_url": "https://arxiv.org/abs/2507.08034", "title": "将外部工具集成到大型语言模型以提高准确性", "title_en": "Integrating External Tools with Large Language Models to Improve Accuracy", "authors": "Nripesh Niketan,Hadj Batatia", "background": "众所周知，大型语言模型（LLMs）在缺乏相关背景信息的情况下，可能会给出质量差的回复或伪造信息。为改善准确性，已有研究提出将LLMs与外部工具结合，提供最新的数据支持。本文关注在教育场景下增强LLMs回答查询的能力，开发了一个框架，允许访问外部API以请求附加的相关信息，集成工具还可以提供计算器或日历等计算功能。实验使用来自MMLU（多模态语言理解）的数据集进行评估，其中包括数学和科学推理问题的数据集。与现有的最先进的语言模型相比，提出的方法显著提高了性能。Athena框架在数学推理方面的准确率达到83%，在科学推理方面的准确率达到88%，显著优于包括GPT-4o、LLaMA-Large、Mistral-Large、Phi-Large和GPT-3.5在内的所有测试模型，其中最佳基线模型（LLaMA-Large）在数学推理和科学推理中的准确率仅为67%和79%。", "innovation": "本文提出了一个框架，该框架允许访问外部API以请求附加的相关信息，提高了LLMs在教育场景下的回答查询的能力。通过使用MMLU数据集进行评估，该框架在数学和科学推理问题上显示出显著的性能提升，尤其在Athena框架下，这些性能显著优于其他先进模型。", "conclusion": "这些有希望的结果为进一步开发围绕LLMs的复杂计算生态系统铺平了道路，使LLMs的使用更自然，能够支持各种任务和活动。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08047", "html_url": "https://arxiv.org/abs/2507.08047", "title": "图像分类中基于混合多层极端学习机的应用到四旋翼无人机", "title_en": "A Hybrid Multilayer Extreme Learning Machine for Image Classification with an Application to Quadcopters", "authors": "Rolando A.Hernandez-Hernandez,Adrian Rubio-Solis", "background": "多层极端学习机（ML-ELM）及其变体已被证明是有效处理不同自然信号分类的技术，如音频、视频、声学和图像。该研究提出了一种基于极端学习机自编码器（ELM-AE）的混合多层极端学习机（HML-ELM），并与区间型2级模糊逻辑理论相结合，用于无人机（UAV）的主动图像分类。", "innovation": "1. 结合ELM-AE和区间型2级模糊逻辑理论提出了一种新的混合多层极端学习机（HML-ELM）。\n2. 研究提出了一种分层ELM学习框架，包括自监督特征提取和监督特征分类两个阶段。\n3. 利用SIT2-FELM和改进的COSTRWSR算法实现了快速输出层分类。", "conclusion": "通过多种实验验证了HML-ELM在图像分类中的高效率，并且HML-ELM相比其他类似的方法（如ML-ELM、ML-FELM和ELM）表现更优。进一步应用HML-ELM实现了四旋翼无人机被动分类和运输不同物体至预定义位置的任务。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08150", "html_url": "https://arxiv.org/abs/2507.08150", "title": "CLEAR: 估计学习中Epistemic和Aleatoric风险的校准方法", "title_en": "CLEAR: Calibrated Learning for Epistemic and Aleatoric Risk", "authors": "Ilia Azizi,Juraj Bodik,Jakob Heiss,Bin Yu", "background": "准确地量化不确定性对于可靠的预测建模至关重要，尤其是在回归任务中。现有的方法通常只能处理测量噪声引起的Aleatoric不确定性或者因数据不足引起的Epistemic不确定性，但很少同时以平衡的方式处理这两种不确定性。", "innovation": "提出了一种名为CLEAR的方法，这是一种具有两个独立参数γ1和γ2的校准方法，能够结合这两种不确定性成分以提高条件覆盖率。CLEAR与任何一对Aleatoric和Epistemic估计器兼容，可以分别使用分位数回归和从可预测性-计算性-稳定性（PCS）框架中抽取的集合来估计这两种不确定性。", "conclusion": "在17个不同真实世界数据集上，CLEAR相对于两个独立校准基线分别在区间宽度上实现了平均28.2%和17.4%的改善，同时保持名义覆盖率。这种改进在以高Epistemic不确定性或高Aleatoric不确定性为主导的场景中尤为明显。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08106", "html_url": "https://arxiv.org/abs/2507.08106", "title": "使用扩散模型预测流体动力学", "title_en": "Predicting Flow Dynamics using Diffusion Models", "authors": "Yannick Gachnang,Vismay Churiwala", "background": "本文旨在复制并扩展DiffFluid论文[1]中的结果。DiffFluid模型表明，扩散模型与Transformer结合可以用于预测流体动力学。该模型使用去噪扩散概率模型（DDPM）框架来解决纳维-斯托克斯和达西流动方程。我们的目标是在计算资源和时间限制下验证DiffFluid论文方法的可复制性，并测试其在其他模拟类型中的可行性，特别是格子玻尔兹曼方法。尽管有这些限制，本文提供了模型作为流体动力学通用求解器的弹性和潜力的证据。结果表明，扩散模型在复杂流体动力学问题中的应用具有潜力和挑战。", "innovation": "本文尝试了使用扩散模型预测流体动力学，验证了DiffFluid模型在不可压缩流场预测中的可行性和潜在应用，特别是格子玻尔兹曼方法。尽管资源和时间限制，但证明了扩散模型的灵活性和广域应用的可能性。", "conclusion": "本文展示了扩散模型在复杂流体动力学问题中的潜在应用和挑战，指出了对未来研究优化计算效率和在更广泛领域的扩展机会。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08163", "html_url": "https://arxiv.org/abs/2507.08163", "title": "自适应扩散去噪平滑：通过差分隐私引导去噪扩散的随机化平滑认证鲁棒性", "title_en": "Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion", "authors": "Frederick Shpilevskiy,Saiyue Lyu,Krishnamurthy Dj Dvijotham,Mathias Lécuyer,Pierre-André Noël", "background": "该研究背景集中在对抗样本的防御机制上，特别是针对视觉模型的预测认证。传统的对抗样本检测和防御方法在实际应用中可能存在局限性，因此需要更加鲁棒且可解释的技术来验证模型预测的可靠性。", "innovation": "本文提出了一种自适应扩散去噪平滑的方法，通过一种新的视角重新诠释引导去噪的扩散模型。具体来说，该方法将引导去噪扩散模型视为一系列自适应的高斯差分隐私（GDP）机制，将纯噪声样本逐步转化为图像。这种方法可以用于分析整个去噪过程的端到端鲁棒性，并提供一种可证明的认证机制，该机制扩展了自适应随机化平滑分析。", "conclusion": "该方法在特定引导策略下，既可以提高认证准确度，也能提升标准准确度，尤其是在$\textbackslash{}ell_2$威胁模型下。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08184", "html_url": "https://arxiv.org/abs/2507.08184", "title": "EP-GAT: 基于能量的并行graph注意力神经网络在股票趋势分类中的应用", "title_en": "EP-GAT: Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification", "authors": "Zhuodong Jiang,Pengju Zhang,Peter Martin", "background": "图神经网络在预测股票动态方面表现出了显著的效果，这是因为它们能够学习股票之间的复杂依赖关系和股票内部的动态。现有的基于图神经网络的方法通常依赖于静态或手动定义的因素来建模股票之间的变化依赖关系，难以保留股票内部的层次特征。", "innovation": "提出了基于能量的并行图注意力神经网络（EP-GAT），该方法通过生成动态股票图，利用股票之间的能量差异和玻尔兹曼分布捕捉股票之间的演变依赖关系。同时，提出了并行图注意力机制以保留股票内部的层次动态。", "conclusion": "通过在五个实际数据集上的广泛实验，EP-GAT在各种评价指标上持续优于五个基准模型。消融研究和超参数敏感性分析进一步验证了提出方法中每个模块的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08189", "html_url": "https://arxiv.org/abs/2507.08189", "title": "具有有限标签和SHAP解释的稳健半监督CT影像学在肺癌预后中的应用：经济高效的学习", "title_en": "Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation", "authors": "Mohammad R. Salmanpour,Amir Hossein Pouria,Sonia Falahati,Shahram Taeb,Somayeh Sadat Mehrnia,Ali Fathi Jouzdani,Mehrdad Oveisi,Ilker Hacihaliloglu,Arman Rahmim", "background": "CT成像对肺癌管理至关重要，通过提供人工智能基于的预后详细可视化。然而，监督学习模型需要大量有标签的数据集，这在标注资源稀缺的环境中限制了其实际应用。", "innovation": "我们引入了一种成本效益高、稳定且可解释的半监督学习（SSL）框架，用于基于CT的生存期预测。该框架利用半监督学习和伪标签，提升了生存期预测的整体生存率，特别是显示了在只有少量标注数据的情况下，SSL的鲁棒性和成本效益。", "conclusion": "我们的研究通过结合SHAP解释性，成功开发了一种成本效益高、稳定且可解释的SSL框架，增强了CT影像在肺癌预后中的性能、普适性和临床适用性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08183", "html_url": "https://arxiv.org/abs/2507.08183", "title": "参数化量子电路学习在量子化学应用中的研究", "title_en": "Parametrized Quantum Circuit Learning for Quantum Chemical Applications", "authors": "Grier M. Jones,Viki Kumar Prasad,Ulrich Fekl,Hans-Arno Jacobsen", "background": "在量子机器学习（QML）领域，参数化量子电路（PQCs）通过结合固定和可调量子门构建，提供了一种处理复杂机器学习问题的有前景的混合框架。然而，尽管有许多应用提议，但对于量子化学相关的数据集的探索仍然有限。本文研究了PQCs在两个具有化学意义的数据集上的潜力和局限性：1. 包含49种不同化学键的断裂能数据集（BSE49数据集）；2. 通过数据驱动的耦合簇方法（DDCC）预测从较低层次电子结构方法得到的水构象数据集，其中耦合态单电子和双电子波函数（CCSD波函数）得到预测。研究通过组合14种数据编码策略与12种变分波函数形式，构建了168种PQC，并评估了它们在5和16量子比特电路上的性能。研究表明，对于古典机器学习方法可以轻松处理但对量子方法仍然是非平凡的化学相关问题，应用PQCs仍存在挑战。", "innovation": "本文通过结合14种数据编码策略与12种变分波函数形式，构建了168种PQC，并评估了它们在5和16量子比特电路上的性能，研究了电路结构、深度和训练集大小对模型性能的影响，并在当前量子硬件上评估了性能。这项研究丰富了适用于量子化学应用的参数化量子电路设计和评估方法。", "conclusion": "研究结果表明PQCs在处理具有化学意义的复杂问题时仍然面临挑战，这些问题对于古典机器学习方法很简单，但对于量子方法来说仍然具有非平凡性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05314", "html_url": "https://arxiv.org/abs/2507.05314", "title": "具有类特定集成和贝叶斯超参数优化的双注意力U-Net++在精确伤口和刻度标记分割中的应用", "title_en": "Dual-Attention U-Net++ with Class-Specific Ensembles and Bayesian Hyperparameter Optimization for Precise Wound and Scale Marker Segmentation", "authors": "Daniel Cieślak,Miriam Reca,Olena Onyshchenko,Jacek Rumiński", "background": "在临床图像中准确分割伤口和刻度标记仍然是一个重要挑战，对于有效的伤口管理以及自动评估至关重要。", "innovation": "我们提出了一个新的双注意力U-Net++架构，结合了通道级和空间注意力机制来解决医学图像中严重的类别不平衡和变异性问题。通过使用EfficientNet-B7作为最佳编码器并独立训练两个特定类别的模型，结合数据增强和贝叶斯超参数优化，最终利用测试时增强进一步提高了预测可靠性。", "conclusion": "我们提出的这种方法在NBC 2025 & PCBBE 2025比赛基准数据集上进行了评估，并使用加权F1分数（75%伤口，25%刻度标记）进行了量化。这种方法在复杂医学分割任务中显示出有效性，取得了0.8640的F1分数。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08193", "html_url": "https://arxiv.org/abs/2507.08193", "title": "InsurTech赋能的实体特定网络风险评估", "title_en": "Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors", "authors": "Jiayi Guo,Zhiyun Quan,Linfeng Zhang", "background": "高质量的公开网络事故数据的缺乏限制了网络风险评估中的实证研究和预测建模。这种挑战主要是由于公司担心披露可能损害其声誉或投资者信心的事故。从精算学角度来看，解决这一问题的潜在方案包括提高现有的网络事故数据集的质量和实施先进的建模技术以优化现有数据的使用。现有数据驱动方法的一个重要缺陷是没有在公开可用的数据集中包含实体特异的组织特征。", "innovation": "本文提出了一种创新的InurTech框架，通过对网络事故数据进行实体特异属性的增强来弥补这一缺陷。研究开发了多个机器学习模型，包括一个多标签分类模型来预测网络事故类型（如隐私泄露、数据泄露、欺诈和勒索、IT错误和其他）的发生情况，以及一个多输出回归模型来估计其年频率。此外，还应用了多重可解释的机器学习技术来识别并跨模型验证InurTech赋能的风险因素。实验证明，这些赋能的特征增强了对网络风险发生和频率估计的预测稳健性，相比仅使用传统风险因素更优。", "conclusion": "本文提出的InurTech框架生成了透明的、实体特定的网络风险概况，支持定制化的承保决策和积极主动的网络风险缓解措施。为保险公司和组织提供了数据驱动的洞察，以支持决策制定和合规规划。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08567", "html_url": "https://arxiv.org/abs/2507.08567", "title": "AbbIE：基于自回归块的迭代编码器以实现高效序列建模", "title_en": "AbbIE: Autoregressive Block-Based Iterative Encoder for Efficient Sequence Modeling", "authors": "Preslav Aleksandrov,Meghdad Kurmanji,Fernando Garcia Redondo,David O'Shea,William Shen,Alex Iacob,Lorenzo Sani,Xinchi Qiu,Nicola Cancedda,Nicholas D. Lane", "background": "本文介绍了一种新的递归通用化方法——自回归块基迭代编码器(AbbIE)，该方法基于仅编码器的Transformer架构，能够在测试时实现更好的困惑度，并允许动态调整计算资源。本文探讨了Transformer性能扩展的新路径，并展示了AbbIE相较于其他迭代方法和标准方法在零样本情境学习和语言困惑度上的优势。", "innovation": "AbbIE 是通过逐步迭代在潜在空间中进行操作的新型递归模型，可以在测试时不依赖于特定的数据集或训练协议，并能够仅使用两轮迭代训练便向上泛化到任意迭代长度。此外，AbbIE 能够根据任务的复杂性和容量进行调整，从而在零样本情境学习任务方面能够提供最高12%的性能提升，在语言困惑度上则有最高5%的提升。", "conclusion": "本文的研究结果为Transformer性能的扩展提供了新的途径。所有的评估均基于至350M参数的模型大小进行。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08018", "html_url": "https://arxiv.org/abs/2507.08018", "title": "Review, Remask, Refine (R3): 过程引导的块扩散文本生成", "title_en": "Review, Remask, Refine (R3): Process-Guided Block Diffusion for Text Generation", "authors": "Nikita Mounier,Parsa Idehpour", "background": "迭代文本生成的一个关键挑战是模型能够有效地识别和纠正自身的错误。现有的方法往往需要额外的模型训练或者复杂的策略来实现这一点。", "innovation": "提出了一种相对简洁但有效的框架，Review, Remask, Refine (R3)，该框架不需要额外的模型训练，可以应用于任何预训练的带有遮盖的文本扩散模型（例如LLaDA或BD3-LM）。通过使用一个过程奖励模型（PRM）来审查中间生成的块，然后将其评分转化为Remask策略，迫使模型聚焦重要部分进行修正，从而改善最终输出。", "conclusion": "最终，R3框架能够显著提高文本生成的质量，尤其是在处理先前生成的不足部分时表现更佳，无需额外的训练即可实现这一改进。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08261", "html_url": "https://arxiv.org/abs/2507.08261", "title": "在对抗攻击存在时Stein收缩批归一化方法的有效性", "title_en": "Admissibility of Stein Shrinkage for Batch Normalization in the Presence of Adversarial Attacks", "authors": "Sofia Ivolgina,P. Thomas Fletcher,Baba C. Vemuri", "background": "批归一化（BN）是深度神经网络中最常用的稳定性提升和正则化操作，通过计算批量内特征图的均值和方差对特征图进行中心化和缩放。由于这些统计值是在批量内的特征图上估计的，因此非常适合应用Stein收缩估计方法，以在均方误差意义上获得更好的均值和方差估计。本文证明，在使用次高斯分布建模对抗攻击时，Stein收缩估计量在估计均值和方差方面优于样本均值和方差估计量，特别是在存在对抗攻击的情况下，具有良好表现。", "innovation": "本文证明了在对抗攻击的情况下，Stein收缩估计方法优于样本均值和方差估计方法，特别是在使用次高斯分布建模对抗攻击时。通过应用这种方法矫正BN，可以在标准的ResNet架构中提高图像分类任务的性能，应用于CIFAR-10数据、3D CNN在PPMI（神经影像）数据上的应用以及基于HRNet的城市景观数据的图像分割任务，无论有无对抗攻击。", "conclusion": "Stein收缩估计的方法在图像分类、3D CNN以及图像分割任务中表现优良，特别是在面临对抗攻击时，证明了其在BN中的应用价值。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08248", "html_url": "https://arxiv.org/abs/2507.08248", "title": "迁移学习和Mixup在细粒度少样本真菌分类中的应用", "title_en": "Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification", "authors": "Jason Kahei Tam,Murilo Gustineli,Anthony Miyaguchi", "background": "计算机视觉在细粒度真菌物种识别方面面临独特挑战，因为不同物种之间和同一物种内部都存在细微的差异。我们的团队参加了FungiCLEF 2025竞赛，专注于使用FungiTastic Few-Shot数据集进行少样本细粒度视觉分类(FGVC)研究。我们尝试了多种视觉变换器模型、数据增强、加权采样及结合文本信息的方法，并探索了生成式AI模型在结构化提示下的零样本分类，但发现其表现不及基于视觉的模型。我们将最终模型应用于竞赛，通过领域特定预训练和采样策略提高了分类效果。", "innovation": "我们的创新点在于采用多种视觉变换器模型、数据增强、加权采样及结合文本信息的方法进行少样本细粒度分类。此外，我们还探索了生成式AI模型在结构化提示下的零样本分类，并证实了领域特定预训练和采样策略的有效性。但生成模型的表现显著低于视觉模型。在竞赛中的排名表明，该方法还有提升空间，特别是在元数据选择和多模态学习的适配方面", "conclusion": "我们的方法在竞赛后评价的私人测试集上排名第35/74，这表明该任务仍有改进空间，特别是在元数据选取和领域适配多模态学习方面。所有代码可在相关链接下载。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08280", "html_url": "https://arxiv.org/abs/2507.08280", "title": "MIRRAMS: 寻求在面向缺失分布偏移的模型训练", "title_en": "MIRRAMS: Towards Training Models Robust to Missingness Distribution Shifts", "authors": "Jihye Lee,Minseo Kang,Dongha Kim", "background": "在现实世界的数据分析中，训练集和测试集中的缺失数据分布经常发生变化，这对实现稳健的预测性能构成了显著挑战。本研究旨在解决这种缺失数据分布的变化问题，提出了一种新的基于深度学习的框架。研究指出，在训练模型时需要关注提取与标签相关的信息，同时保持对不同缺失模式的不变性，以增强在未知缺失情况下的鲁棒性。", "innovation": "提出了基于互信息的方法，称为MI稳健性条件，指导预测模型提取与标签相关的信息，同时保持对多种缺失模式的不变性。进一步提出了一种新技术来获取每个条件对应的损失项，并形成最终的目标函数，称为MIRRAMS（互信息正则化以应对缺失性变化的稳健性）。这不仅在理论上解释了基于一致性正则化的半监督学习方法（如FixMatch）的基本原理，而且在各种基准数据集的实验中显示出MIRRAMS优于现有基线并保持跨不同缺失场景的稳健性能。", "conclusion": "MIRRAMS框架在各种基准数据集上展示了稳健性能，并且即使在没有缺失数据的情况下也能达到最先进的表现，同时可以自然地应用于半监督学习任务。这表明MIRRAMS是一种强大的通用学习框架。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08306", "html_url": "https://arxiv.org/abs/2507.08306", "title": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "title_en": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "authors": "Inclusion AI:Fudong Wang,Jiajia Liu,Jingdong Chen,Jun Zhou,Kaixiang Ji,Lixiang Ru,Qingpei Guo,Ruobing Zheng,Tianqi Li,Yi Yuan,Yifan Mao,Yuting Xiao,Ziping Ma", "background": "近期，多模态大型语言模型（MLLMs）通过强化学习带有验证性奖励（RLVR）取得了显著的进步，这提升了它们的推理能力。然而，这些模型在处理动态空间交互方面仍然存在问题，这种能力对于实际应用至关重要。现有模型在解决具体应用中的动态空间相互作用方面存在不足。", "innovation": "研究通过引入M2-Reasoning-7B模型，解决了多模态大型语言模型在处理动态空间交互方面的不足。M2-Reasoning-7B模型的创新点包括：（1）一个新颖的数据管道生成了294,200高质量的数据样本，分别为168,000和126,200用于冷启动微调和RLVR；这些数据样本具有逻辑连贯的推理路径，且经过了全面的评估；（2）动态多任务训练策略，逐步优化以缓解数据之间的冲突，并针对特定任务的奖励信号来提供定制的激励信号。", "conclusion": "M2-Reasoning-7B模型通过精心策划的数据和先进的训练策略，在8个基准测试中创造了新的最佳表现，展示了在通用和空间推理领域的优越性能。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08254", "html_url": "https://arxiv.org/abs/2507.08254", "title": "Raptor: 利用预训练2D基础模型实现3D医学体积的可扩展无需训练嵌入表示", "title_en": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models", "authors": "Ulzee An,Moonseong Jeong,Simon A. Lee,Aditya Gorla,Yuzhe Yang,Sriram Sankararaman", "background": "当前在构建用于体数据（如磁共振成像MRI）的基础模型时面临的挑战包括训练最新的架构在高维上的复杂性和收集足够大的体数据集。这些挑战限制了现有方法的应用和发展。", "innovation": "我们提出了一种名为Raptor（随机平面张量减少）的方法，这是一种无需训练的方法，用于生成体数据的语义丰富的嵌入。Raptor 利用一个在自然图像上预训练的固定2D基础模型，从医学体数据的单个切片中提取视觉标记，并使用随机投影进行空间压缩，从而在保留语义信息的同时显著降低计算复杂度。", "conclusion": "我们在十个不同的医学体数据任务上进行的广泛实验验证了Raptor在性能上优于现有方法，包括那些仅在医学体数据上预训练的方法，并完全绕过了昂贵的训练需求。我们的结果突显了Raptor作为医学体数据中基于深度学习方法的基础的有效性和通用性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08322", "html_url": "https://arxiv.org/abs/2507.08322", "title": "从文本高效检索数量信息：基于描述解析和弱监督的方法", "title_en": "Towards Efficient Quantity Retrieval from Text:an Approach via Description Parsing and Weak Supervision", "authors": "Yixuan Cao,Zhengrong Chen,Chengxuan Xia,Kun Wu,Ping Luo", "background": "公司和政府不断生成定量事实，支持数据驱动的决策。虽然常见的定量事实被结构化，但许多长尾的定量事实依旧埋藏在非结构化的文档中，难以访问。提取这些定量事实对于理解经济活动、财务状况等具有重要意义。这项研究提出了一项任务——数量检索（Quantity Retrieval），即给定一个定量事实的描述，系统返回相关的值及其支持的证据。语境下的数量语义理解对于完成该任务至关重要。因此，研究提出了一种基于描述解析的框架，将文本转换为结构化（描述，数量）对，从而有效进行检索。由于直接标注的注解数据稀缺，研究利用弱监督技术，基于数量共现构建了一个大规模的同义替换数据集，以改进学习效果。研究在大量金融年报和新标注的定量事实描述数据集上进行了评估，结果显示，该方法在第一召回率上的准确率显著提高了33.68个百分点，从30.98%提升至64.66%。", "innovation": "提出了一种基于描述解析的框架，将文本转换为结构化（描述，数量）对，以实现有效的定量事实检索。利用弱监督技术，基于数量共现构建了一个大规模的同义替换数据集，以改进学习效果。量化事实的检索准确率显著提高，达到了64.66%。该方法有助于从大量非结构化文本中高效、准确地提取定量信息，支持数据驱动的决策。", "conclusion": "通过基于描述解析的方法和利用弱监督技术，该研究显著提高了定量事实的检索准确率。在金融年度报告和注释数据集上的实验表明，提高了一倍多的召回率，对于数据驱动的决策具有重要意义。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08333", "html_url": "https://arxiv.org/abs/2507.08333", "title": "使用离散扩散模型的音频修补", "title_en": "Audio Inpanting using Discrete Diffusion Model", "authors": "Tali Dror,Iftach Shoham,Moshe Buchris,Oren Gal,Haim Permuter,Gilad Katz,Eliya Nachmani", "background": "音频修补是指修复受损音频记录中缺失的部分。尽管先前的方法，如基于波形和梅尔谱图的扩散模型，在处理较短的缺口时显示出有希望的结果，但在缺口超过100毫秒时，它们的质量往往会下降。", "innovation": "本文提出了一种基于离散扩散模型的新修补方法，该方法通过对预训练音频标记器生成的音频表示进行操作，在离散的潜在空间中直接建模生成过程，从而实现了音频的稳定和语义一致的重建。", "conclusion": "实验结果表明，本文的方法在音乐网数据集上的性能与现有基准相当或更优，特别是在较长的缺口中，为恢复劣化音乐记录提供了一个稳健的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08438", "html_url": "https://arxiv.org/abs/2507.08438", "title": "最优且实用的批次线性贝叶斯算法", "title_en": "Optimal and Practical Batched Linear Bandit Algorithm", "authors": "Sanghoon Yu,Min-hwan Oh", "background": "现有的线性贝叶斯算法虽然在理论上能够达到接近最优的遗憾度，但在实际中通常是计算上不可行的或者表现不佳。", "innovation": "\texttt{BLAE} 是一种新颖的批次在线性贝叶斯算法，它结合了臂消除与正则化 G-最优设计，首次在大$K$和小$K$的情况下都实现了最小最大遗憾度（加上$T$的对数因子），并且只使用了$O(\text{log}^{\text{log} T})$批次。我们的分析引入了批次最优设计的新技术和细化集中的边界。", "conclusion": "\texttt{BLAE} 证明了低计算开销和强大的实际表现，在广泛的数值评估中优于最先进的方法。因此，\texttt{BLAE} 是第一个在所有情况下都具备可证明的最小最大最优性和批量线性贝叶斯的实用性优势的算法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08403", "html_url": "https://arxiv.org/abs/2507.08403", "title": "人工智能本征无线接入网：6G第一日标准化的运营商视角", "title_en": "Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization", "authors": "Nan Li,Qi Sun,Lehan Wang,Xiaofei Xu,Jinri Huang,Chunhui Liu,Jing Gao,Yuhong Huang,Chih-Lin I", "background": "6G移动网络中，人工智能/机器学习(AI/ML)已经成为最确定和显著的特点。与5G不同的是，5G中的AI/ML并非原生集成而是作为现有架构的附加功能。6G将从最初的阶段就融入AI，以应对其复杂性并支持无处不在的AI应用。基于从2G到5G的广泛移动网络运营和标准化经验，该论文探讨了AI本征无线接入网(RAN)的设计和标准化原则，重点关注其关键的第一日架构、功能和能力。", "innovation": "本文提出了AI本征6G RAN架构的第一日特性，并验证了这一架构和支撑AI功能的性能显著改进了平均空中接口延迟、根本原因识别和网络能耗。论文还明确了AI本征RAN在标准化方向上的三大核心能力：AI驱动的RAN处理/优化/自动化、可靠的AI生命周期管理（LCM）以及AI服务（AIaaS）提供的标准化。", "conclusion": "本文为6G AI本征RAN标准化设计提供了一个第一日框架，平衡了技术创新与实际部署的需求。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08330", "html_url": "https://arxiv.org/abs/2507.08330", "title": "面向可解释性的高效医疗图像分析修剪方法", "title_en": "Interpretability-Aware Pruning for Efficient Medical Image Analysis", "authors": "Nikita Malik,Pratinav Seth,Neeraj Kumar Singh,Chintan Chitroda,Vinay Kumar Sankarapu", "background": "深度学习在医疗图像分析方面取得了显著进展，但在临床实践中的应用受到现代模型体积大、不透明性的问题限制。可解释性技术的进步，如DL-Backtrace、层次相关传播和整合梯度等，使得评估神经网络中个体组件的贡献成为可能。已有研究表明，医疗图像分类任务中训练的神经网络的复杂性可以通过可解释性技术进行简化和压缩，从而提高模型的透明度和预测性能。", "innovation": "本文提出了一种可解释性引导的修剪框架，该框架在减少模型复杂性的同时保持了预测性能和透明性。通过仅保留每个层中的最相关部分，该方法实现了一种有针对性的压缩，从而保持了临床相关表示。实验结果表明，该方法在多个医疗图像分类基准上实现了高的压缩率，同时损失最小的准确性，为实际部署中的轻量级、可解释模型铺平了道路。", "conclusion": "通过这种方式，可以实现高效、可解释的医疗图像分析模型的构建，为实际医疗环境中的应用提供了可能。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08454", "html_url": "https://arxiv.org/abs/2507.08454", "title": "为什么这是这种情况而不是其他情况？一种基于逻辑的对比解释框架", "title_en": "Why this and not that? A Logic-based Framework for Contrastive Explanations", "authors": "Tobias Geibinger,Reijo Jaakkola,Antti Kuusisto,Xinghan Liu,Miikka Vilander", "background": "背景：论文定义了几种关于对比解释的规范化问题，每个问题都回答了‘为什么P而不Q？’的形式问题。这些问题在命题逻辑环境下研究了这些定义的基本属性，并展示了这种框架如何捕捉文献中已有的最小基数版本的对比解释。进一步地，分析了这些问题的计算复杂性，并使用回答集编程实现了CNF公式的问题，并给出了实际工作原理的例子。", "innovation": "创新：论文提出了一个新的基于逻辑的对比解释框架，定义了几种回答‘为什么P而不Q’问题的规范化问题。这些框架不仅捕捉了现有的对比解释，还提供了计算复杂性的详细分析，并使用回答集编程实现了这些问题，为实际应用提供了新的方法和手段。", "conclusion": "结论：研究结果表明，提出的基于逻辑的对比解释框架在理论上和计算上都是有效的。这种框架不仅对现有对比解释进行了集合抽象，并且通过CNF公式实现了具体的计算实例，为理解和解释复杂的逻辑因果关系提供了新的视角。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08167", "html_url": "https://arxiv.org/abs/2507.08167", "title": "使用可穿戴传感器生理信号在老年人中进行情绪检测", "title_en": "Emotion Detection in Older Adults Using Physiological Signals from Wearable Sensors", "authors": "Md. Saif Hassan Onim,Andrew M. Kiselica,Himanshu Thapliyal", "background": "老年人的情绪识别对于理解他们的认知和情感健康至关重要，尤其是在医院和护理院环境中。目前，情绪识别通常依赖于摄像头或面部分析，这两种方法对于老年人可能不够非侵入性或容易使用。这项研究探讨了一种基于边缘的非侵入性方法，该方法仅使用通过可穿戴传感器获取的生理信号来进行情绪识别。", "innovation": "该研究提出了一种利用经典机器学习模型预测基于生理信号的情绪反应强度的方法。研究采用了来自Empatica E4和Shimmer3 GSR+腕带的生理信号数据以及iMotion的面部表情分析模块记录的面部表情数据。研究者实现了0.782 r2得分和0.0006 MSE的最高回归任务成绩，验证了使用仅仅生理传感器数据完成情绪识别的有效性。该方法可能对患有阿尔茨海默病及相关痴呆症（ADRD）的个人以及需应对创伤后应激障碍（PTSD）或其他认知障碍的退伍军人具有重要意义。", "conclusion": "通过多种经典回归模型的结果，该方法验证了在现实世界环境中实现隐私保护和高效情绪识别系统的能力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08218", "html_url": "https://arxiv.org/abs/2507.08218", "title": "简单机制解释用于上下文外推理", "title_en": "Simple Mechanistic Explanations for Out-Of-Context Reasoning", "authors": "Atticus Wang,Joshua Engels,Oliver Clive-Griffin", "background": "本文探讨了一种现象，即经过微调的大型语言模型（LLMs）在跨分布域表现出令人惊讶的深度推断能力。与学习浅层次启发式不同，模型会隐式将不同训练数据中的观察结果后果纳入考虑，并据此行动。研究人员特别关注了这种现象的机制，发现许多文献中描述的上下文外推理（OOCR）实例都可以用简单解释：LoRA 微调方法实质上是加入了恒定的引导向量，使模型朝向一个通用概念方向发展。这不仅提高了特定任务的表现，还影响了其他相关概念领域，因此导致了其出色的跨分布域推理能力。", "innovation": "研究揭示了一个简单机制解释，LoRA 微调实际上只是引入了一个恒定的引导向量，引导模型朝向一个通用概念的方向，这提高了模型的跨分布域推理能力，可以应用于其他任务。不仅可以通过微调模型自带的引导向量实现 OOCR，也可以从头开始训练这些向量，这也能够引发 OOCR。研究还发现，即使对于涉及条件行为的任务（如模型后门），不需要条件性地添加引导向量也能实现 OOCR，即无条件地添加引导向量已经足够。", "conclusion": "本文提供了一种理解 OOCR 在微调中学习内容的解释，这有助于回答为什么大型语言模型可以实现基于上下文外推理的先进功能，在实际部署时这是一项非常重要的能力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08518", "html_url": "https://arxiv.org/abs/2507.08518", "title": "数据深度作为一种风险", "title_en": "Data Depth as a Risk", "authors": "Arturo Castellanos,Pavlo Mozharovskyi", "background": "数据深度是一种无监督的评估方法，用于评估数据点在分布中心的位置，广泛应用于异常检测、多变量数据分析等领域。半空间深度是最早尝试将分位数的概念扩展到多维情况的数据深度，尽管存在多种数据深度定义，它仍然是一种常用的尺度中心度量方法。该研究从新的角度提供了半空间深度的解释，展示了它作为某个特定标签下分类器集合风险最小值的新视角。这为将现有的机器学习算法及其高效计算性能和快速统计收敛速度引入到高维数据领域打开了可能性。研究成果强调了数据集与分类器复杂度之间的关系，使得数据深度更易于解释且适用于异常检测任务。", "innovation": "该研究从分类器和风险的角度重新解释了半空间深度，提出了新的“损失深度”家族，涵盖了多种已研究的分类器，如支持向量机（SVM）和逻辑回归等。这一新框架继承了现有机器学习算法的高效计算能力和快速统计收敛速率，并适用于高维度数据集。新的损失深度更直观地展示了数据集与分类器复杂度之间的关系，使得数据深度更加易于解释同时具备高效的异常检测性能。", "conclusion": "新的基于风险的损失深度框架不仅继承了现有机器学习算法及其高效统计收敛速度的优势，还适用于高维度数据，具有较好的异常检测效果。这种新的数据深度方法通过解释和分类器复杂性的关系，提供了一种易于理解且高效的异常检测手段。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08543", "html_url": "https://arxiv.org/abs/2507.08543", "title": "量子投影-free稀疏凸优化算法", "title_en": "Quantum Algorithms for Projection-Free Sparse Convex Optimization", "authors": "Jianhao He,John C.S. Lui", "background": "本文考虑了向量域和矩阵域上的投影-free稀疏凸优化问题，这类问题在机器学习和数据科学中有广泛应用。对于向量域 π ⊂ R^d，通过函数值预言器提出了两种量子算法，分别查询复杂度为 O(√ d/ε) 和 O(1/ε)，相较于最优的经典算法分别降低了 O(√ d) 和 O(d) 的因子。对于矩阵域 π ⊂ R^{d \times d}，提出了两种对于核范数约束的量子算法，计算更新步的时间复杂度分别为 ̅(O(rd/ε^2)) 和 ̅(O(√ r d/ε^3))，相较于最优的经典算法至少降低了 O(√ d) 的因子。", "innovation": "本文提出的量子算法在稀疏凸优化问题中显示出量子优势，在依赖维度 d 的性能上超越了最优的经典方法。", "conclusion": "本文提出了向量域和矩阵域上的投影-free稀疏凸优化问题的新量子算法，显著降低了查询和时间复杂度。这些算法在依赖维度 d 的性能上超越了现有的最优经典方法，表明了量子算法在该领域的实际应用潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08402", "html_url": "https://arxiv.org/abs/2507.08402", "title": "基于空间置换不变神经变换器的连续皮层内运动解码", "title_en": "SPINT: Spatial Permutation-Invariant Neural Transformer for Consistent Intracortical Motor Decoding", "authors": "Trung Le,Hao Fang,Jingyuan Li,Tung Nguyen,Lu Mi,Amy Orsborn,Uygar Sümbül,Eli Shlizerman", "background": "基于皮层内脑机接口（iBCI）的目标是通过解码神经群体活动来恢复具有运动损伤的个体的运动和交流能力。然而，长期内记录的神经活动的非平稳性是现有方法面临的重大挑战，这使得固定的神经身份在不同记录会话间不一致，限制了算法的跨会话通用性，并在部署时增加了计算负担。", "innovation": "本文提出了一种空间置换不变神经变换器框架（SPINT），该框架直接对无序神经单元集进行操作，并通过引入上下文相关的位置嵌入方案动态推断单元特定的身份，实现跨记录会话的灵活泛化。此外，还提出了动态通道丢弃方法，以增强模型对群体变异的鲁棒性。通过在FALCON基准测试集上进行评估，SPINT展示出跨会话泛化的鲁棒性，优于现有的零样本和少样本无监督基准，并消除了测试时对对齐和微调的需求。", "conclusion": "本文的工作为长期皮层内脑机接口应用提供了一种具有鲁棒性和可扩展性的神经解码框架的初步步骤。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08616", "html_url": "https://arxiv.org/abs/2507.08616", "title": "AgentsNet: 多智能体大规模语言模型中的协调与协作推理", "title_en": "AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs", "authors": "Florian Grötschla,Luis Müller,Jan Tönshoff,Mikhail Galkin,Bryan Perozzi", "background": "大语言模型（LLMs）在多智能体系统中表现出强大的问题解决能力，但这些系统的出现也引发了一系列关于复杂网络中智能体的有效自组织和协作能力的问题。虽然现有的多智能体基准测试能评估多智能体系统在推理任务上的表现，但尚不清楚这些系统能否有效利用网络拓扑结构。因此，需要一个新的基准来衡量多智能体系统在给定网络拓扑下协作策略形成、自我组织和有效沟通的能力。此类问题可以从分布式系统和图论的经典问题中获得灵感。现有的多智能体基准测试通常最多覆盖2至5个代理，而AgentsNet则不受网络规模限制，可以随新一代LLMs扩展。这使得可以评估多达100个代理的前沿模型。", "innovation": "提出了一种新的多智能体推理基准AgentsNet，该基准以经典分布式系统和图论问题为基础，用于衡量多智能体系统在给定网络拓扑下形成策略、自我组织和有效沟通的能力。这种方法评价了一种包括具有基本组织和通信协议的同构智能体网络在内的多种基线方法，并且表明一些前沿LLMs在小型网络中表现出色，但在网络规模扩大时性能下降。AgentsNet不受规模限制，能够随着新一代LLMs的发展而扩展。", "conclusion": "研究表明，一些前沿LLMs在小型网络中展现出强大的性能，但在网络规模扩大时开始衰减。而现有的多智能体基准测试通常最多覆盖2至5个代理，但AgentsNet可以实现大规模扩展，实际上没有大小限制，可以随着新生成代LLMs的发展不断扩展规模，因此是评估多智能体系统的一个新方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08108", "html_url": "https://arxiv.org/abs/2507.08108", "title": "采用学习距离度量的Mallows模型：采样与最大似然估计", "title_en": "Mallows Model with Learned Distance Metrics: Sampling and Maximum Likelihood Estimation", "authors": "Yeganeh Alimohammadi,Kiana Asgari", "background": "Mallows模型是一种广泛用于从排名数据中学习的统计数据模型，它适用于推荐系统、选举以及与人类偏好对齐语言模型等多种场景。根据Mallows模型，观察到的排名是对中心排名的噪声扰动，通过距离函数度量与中心排名的差距，概率随差距增大而呈指数衰减。现有方法大多集中在固定距离上（如Kendall’s τ距离），缺乏直接从数据中学习距离度量的方法。然而，在实际应用场景中，排名的变异度往往会因上下文的不同而改变。", "innovation": "本文提出了一种扩展的Mallows模型，该模型可以直接从数据中学习距离度量。具体来说，使用$L_\rho$距离来计算排名之间的差距，并发展了一种完全多项式近似算法（FPTAS）来高效生成样本，这些样本在总量变距离上与真实分布$\rho$-接近。本文还提出了一种联合估计中心排名、分散参数和最优距离度量的有效最大似然估计（MLE）算法，并且证明了在任何$\rho$和$\beta$值下估计器的强一致性。", "conclusion": "本文通过采样和最大似然估计方法，提供了一种从数据中直接学习距离度量的方法，并验证了这种方法在运动排名数据集上的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08548", "html_url": "https://arxiv.org/abs/2507.08548", "title": "SAM2RL: 在 Segment Anything Model 2 中迈向强化学习记忆控制", "title_en": "SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2", "authors": "Alen Adamyan,Tomáš Čížek,Matej Straka,Klara Janouskova,Martin Schmid", "background": "Segment Anything Model 2 (SAM 2) 在物体分割任务中表现出强大的性能，并已成为视觉物体跟踪的最新技术。memory bank 能存储前一帧的信息，使视频序列中具有时间一致性。近年来，方法通过手工艺品更新规则来增强 SAM 2，以更好地处理干扰、遮挡和物体运动。", "innovation": "作者提出了一种基于强化学习优化 SAM 2 中 memory 更新的方法，将其记忆控制建模为序列决策问题。这种方法在过拟合设置中实现了对 SAM 2 的相对改进超过现有启发法三倍的效果，揭示了 memory bank 的潜在未开发潜力，并揭示了强化学习可以作为一种强大的替代手工艺品更新规则的工具来控制视觉物体跟踪中的 memory 控制。", "conclusion": "这些结果突显了 memory bank 的未开发潜力，并强调强化学习作为一种替代手工艺品更新规则的强有力工具在视觉物体跟踪中的记忆控制应用中重要作用。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08241", "html_url": "https://arxiv.org/abs/2507.08241", "title": "探究Reddit上慢性疼痛讨论中的性别差异", "title_en": "Exploring Gender Differences in Chronic Pain Discussions on Reddit", "authors": "Ancita Maria Andrade,Tanvi Banerjee,Ramakrishna Mundugar", "background": "疼痛作为人类存在的固有部分，包括物理和情感体验，并可分为急性痛和慢性痛。多年来，各科学领域进行了大量研究以了解疼痛的原因并探索治疗方法，但早期研究往往忽略了性别在疼痛体验中的作用。", "innovation": "本研究利用自然语言处理（NLP）分析和深入理解个人的疼痛体验，特别是关注性别差异。通过隐含属性模型-卷积神经网络（HAM-CNN）成功将帖子分类为男性和女性语料库，通过用户名聚集帖子后获得了0.86的F1分数。研究揭示了性别在语言表达上的差异，女性帖子倾向于情感聚焦。此外，研究还指出偏头痛和鼻窦炎在女性中更为普遍，并探讨了基于性别的个体对止痛药的反应差异。", "conclusion": "研究通过新颖的方法揭示了Reddit上慢性疼痛讨论中的性别差异，指出女性在语言上更注重情感表达，并且更倾向于在偏头痛和鼻窦炎这些疾病上受到影响，止痛药物对男性和女性的影响也有所不同。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08745", "html_url": "https://arxiv.org/abs/2507.08745", "title": "快速模式集选择的哈希方法", "title_en": "Hashing for Fast Pattern Set Selection", "authors": "Maiju Karjalainen,Pauli Miettinen", "background": "模式集挖掘是一个在数据挖掘领域寻找一组模式而不是所有模式的基本问题。近年来，提出了多种衡量一组模式质量的标准。本文将重构误差作为衡量一组模式质量的代理指标，并专注于如何高效地找到一组模式。", "innovation": "提出了一种基于 bottom-k 哈希的方法来高效地选择模式集，并扩展了方法以处理模式可能以近似形式出现在数据中的常见情况。该方法应用于数据库平铺、布尔矩阵分解和重新描述挖掘等。", "conclusion": "本文提出的基于哈希的方法比标准贪婪算法更快，同时在合成数据集和真实世界数据集上获得了几乎同样好的结果。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08653", "html_url": "https://arxiv.org/abs/2507.08653", "title": "具有峰值年龄信息违章保证的资源分配中的安全深度强化学习", "title_en": "Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees", "authors": "Berire Gunes Reyhan,Sinem Coleri", "background": "在无线网络控制系统（WNCSs）中，由于控制与通信系统的紧密依赖性，二者必须协同设计。本文则提出了一种基于优化理论的安全深度强化学习（DRL）框架，该框架在超可靠的WNCSs中首次确保满足约束条件的同时优化性能，并通过最小化功耗来满足关键约束，包括峰值年龄信息（PAoI）违章概率、传输功率和有限块长度范围内的可调度性。新颖之处在于通过结合随机最大允许传输间隔（MATI）和最大允许包延迟（MAD）约束来推导PAoI违章概率，在多传感器网络中进行推导。该框架包含两个阶段：优化理论和安全DRL。", "innovation": "本文提出的创新点在于首次在超可靠WNCSs中提出了一种基于优化理论的安全DRL框架，通过结合随机最大允许传输间隔和最大允许包延迟约束来推导PAoI违章概率，并采用教师-学生框架引导DRL学习过程，使控制机制评估系统约束合规性并建议最近的可行动作，从而在多个基准中表现出更快的收敛速度、更高的奖励和更高的稳定性。", "conclusion": "本文构建的框架展示了在峰值年龄信息违章保证下的资源分配中，优于基于规则的方法和基于优化理论的其他DRL基准，实现了更快的收敛、更高的奖励和更大的稳定性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08623", "html_url": "https://arxiv.org/abs/2507.08623", "title": "纠缠威胁：面向量子机器学习安全的统一杀链模型", "title_en": "Entangled Threats: A Unified Kill Chain Model for Quantum Machine Learning Security", "authors": "Pascal Debus,Maximilian Wendlinger,Kilian Tscharke,Daniel Herr,Cedric Brügmann,Daniel Ohl de Mello,Juris Ulmanis,Alexander Erhard,Arthur Schmidt,Fabian Petsch", "background": "量子机器学习（QML）系统继承了经典机器学习系统的漏洞，同时也引入了新的攻击表面积，这些攻击表面积源自量子计算的物理和算法层次。尽管已有越来越多的研究关注单一攻击向量，比如对抗性污染和规避、门级后门、侧信道泄漏和模型提取，但这些威胁往往是在假设中进行孤立分析，这些假设不切实际地抬高了攻击者的能力和系统的环境，从而阻碍了有效的整体防御策略的开发。", "innovation": "本文提出通过将广泛应用于经典信息技术和网络安全领域的kill chain模型，应用于量子机器学习的安全领域，以结构化的方式建模攻击表面积，不仅涵盖了单独的技术，也涵盖了它们之间的关系、前提条件和在QML管道中的潜在影响。通过广泛的文献综述，构建了量子感知kill chain框架，并将其与MITRE ATLAS（针对经典机器学习的杀链模型）的概念相统一，明确了物理层威胁（例如，侧信道泄漏和交叉耦合故障）、数据和算法操纵（如污染或门级后门）以及隐私攻击（包括模型提取和训练数据推断）之间的相互依赖性。这为量子机器学习领域提供了更现实的威胁模型和主动的纵深防御设计奠定基础。", "conclusion": "本文提供了一个面向量子机器学习安全的统一kill chain模型，这是一种更结构化的方法来理解攻击者的目标、能力和可能的多阶段攻击路径，涵盖侦察、初始访问、操纵、持久化和外泄。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08660", "html_url": "https://arxiv.org/abs/2507.08660", "title": "自动语音转写对说话人归属影响的研究", "title_en": "The Impact of Automatic Speech Transcription on Speaker Attribution", "authors": "Cristina Aggazzotti,Matthew Wiesner,Elizabeth Allyn Smith,Nicholas Andrews", "background": "说话人归属是从言语转录中识别说话人的任务，基于他们语言使用中的模式。当音频不可用或不可靠时，例如被删除或匿名化时，这一任务特别有用。之前的工作主要集中在使用人类注释员生成的转录来归属说话人。然而，在现实世界中，人们通常只有自动语音识别（ASR）系统生成的错误较多的转录。本文我们进行了迄今为止首个全面研究自动转写对说话人归属性能的影响。我们关注转写错误如何影响说话人归属性能，以及ASR系统属性如何影响归属。研究发现，对单词级别的转写错误具有惊人的抗性，恢复真实转录的目标与归属性能相关性最小。总体而言，我们的研究结果表明，在由ASR生成的更错误的转录上进行说话人归属，与基于人工转录数据的归属一样好，甚至更好，可能因为ASR转写错误能够捕捉能显示说话人身份的说话人特定特征。", "innovation": "这是一个首个全面探讨自动语音转写对说话人归属性能影响的研究。特别关注了转写错误如何影响归属性能，并研究了ASR系统的属性如何影响归属问题。研究揭示了说话人归属对单词级别的转写错误具有较高抗性，并且恢复真实转录的目标与归属性能的关系较小。", "conclusion": "我们的研究结果表明，在由ASR生成的较错误的转录上进行说话人归属，与基于人工转录数据的归属一样好，甚至更好。可能是因为ASR转写错误能够捕捉到能揭示说话人身份的说话人特定特征。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.06227", "html_url": "https://arxiv.org/abs/2406.06227", "title": "PAC-Bayes Analysis for Recalibration in Classification", "title_en": "PAC-Bayes Analysis for Recalibration in Classification", "authors": "Masahiro Fujisawa,Futoshi Futami", "background": "非参数估计使用等宽分割是一种评估机器学习模型校准性能的标准方法。现有的理论分析大多集中在二分类校准误差的偏差，而实际应用如多分类没有得到充分的关注。此外，许多参数型校准算法缺乏对其泛化性能的理论保证。", "innovation": "本文采用了可能大约正确的贝叶斯框架进行校准误差的泛化分析。基于此理论，提出了一种考虑泛化能力的校准算法。实验结果表明，该算法在各种基准数据集和模型上都可以增强基于高斯过程的校准性能。", "conclusion": "通过提出基于PAC-Bayes框架的泛化能力校准算法，填补了现有理论在多分类校准误差偏差分析上的空白，并通过实验验证了算法的有效性，为机器学习模型的校准提供了新的思路和方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.16138", "html_url": "https://arxiv.org/abs/2408.16138", "title": "通过同心自编码器检测维度并施加不变性：更瘦的潜在空间", "title_en": "Thinner Latent Spaces: Detecting Dimension and Imposing Invariance with Conformal Autoencoders", "authors": "George A. Kevrekidis,Zan Ahmad,Mauro Maggioni,Soledad Villar,Yannis G. Kevrekidis", "background": "同心自编码器是一种神经网络结构，通过在潜在变量之间施加正交性条件来获得数据的解耦表示。这项工作的背景是探讨如何利用网络潜在层内的正交关系来推断非线性流形数据集的内在维度（局部特征在于其切空间的维数），同时计算编码和解码（嵌入）映射。", "innovation": "本文创新之处在于提出利用同心自编码器检测非线性流形数据集的内在维度，并在计算编码和解码映射的同时实现这一点。此外，该方法还展示了在嵌入空间的子流形上定义的局部群动作下的坐标不变性.", "conclusion": "该方法应用于多个数据集，并强调其适用性、优势和局限性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2205.07249", "html_url": "https://arxiv.org/abs/2205.07249", "title": "基于3D蛋白口袋的Pocket2Mol高效分子采样方法", "title_en": "Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets", "authors": "Xingang Peng,Shitong Luo,Jiaqi Guan,Qi Xie,Jian Peng,Jianzhu Ma", "background": "近年来，深度生成模型在设计新型药物分子方面取得了巨大成功。近期研究显示，在考虑蛋白口袋结构的基础上，可以大幅提升虚拟药物设计的特异性和成功率。然而，如何采样满足多个几何约束条件的新化学化合物构成了基本的计算挑战。现有的采样算法要么仅在图空间中采样，要么只关注原子的3D坐标而忽略诸如键类型和功能性官能团等其他详细化学结构。", "innovation": "本文开发了Pocket2Mol，这是一个E(3)-对称生成网络，由两个模块组成：1) 一种全新的图神经网络，捕捉结合口袋中原子的空间和键合关系；2) 一种高效算法，能够在口袋表示的前提下采样新的药物候选者，同时无需依赖MCMC方法从可计算分布中采样。实验结果表明，由Pocket2Mol生成的分子具有显著更高的结合亲和力，以及药物特性如药物类似性和合成可达性。", "conclusion": "综合实验结果表明，通过Pocket2Mol生成的分子在结合亲和力和其他药物特性方面表现更佳。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.03099", "html_url": "https://arxiv.org/abs/2406.03099", "title": "图卷积分支定界法", "title_en": "Graph Convolutional Branch and Bound", "authors": "Lorenzo Sciandra,Roberto Esposito,Andrea Cesare Grosso,Laura Sacerdote,Cristina Zucca", "background": "传统的确切算法常依赖启发式准则来指导可行解的探索，但对于NP困难问题，这种启发式准则往往效率低下。本文探讨了将深度学习模型集成到组合优化管道中，特别针对NP困难问题。通过学习有效的启发式方法，尤其是优化评分，来估计解与最优解的接近程度，并将其应用于分支定界框架中，从而更有效地遍历解空间。", "innovation": "本文提出了一种使用图卷积神经网络与新颖无监督训练策略结合的传统解算器（1-tree分支定界和Concorde）的新方法。这种方法能够在不依赖标签数据的情况下进行广泛的图大小泛化。", "conclusion": "实验结果显示，所提方法在分支定界节点探索数量和整体计算时间方面表现出显著的效果，特别是对于旅行商问题。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08800", "html_url": "https://arxiv.org/abs/2507.08800", "title": "NeuralOS: 通过神经生成模型模拟操作系统", "title_en": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models", "authors": "Luke Rivard,Sun Sun,Hongyu Guo,Wenhu Chen,Yuntian Deng", "background": "本文介绍了NeuralOS，这是一种通过直接预测用户输入（如鼠标移动、点击和键盘事件）响应生成屏幕帧的神经架构，来模拟操作系统图形用户界面（GUI）。NeuralOS 结合了一个递归神经网络（RNN），用于跟踪计算机状态，以及一种基于扩散的神经渲染器，用于生成屏幕图像。模型是在包括随机生成交互和由AI代理生成的现实交互的大规模Ubuntu XFCE记录数据集上进行训练的。", "innovation": "NeuralOS 创新地结合了递归神经网络（RNN）和基于扩散的神经渲染器，能够直接预测屏幕帧以模拟操作系统GUI。该模型已在大规模Ubuntu XFCE交互记录数据集上进行训练，包含随机生成的交互和由AI代理生成的现实交互。", "conclusion": "尽管精确建模细粒度的键盘交互仍然具有挑战性，但NeuralOS 为创建未来人机交互系统中的完全自适应、生成式神经接口提供了一步。NeuralOS 成功地渲染了逼真的GUI序列，准确地捕捉了鼠标交互，并可靠地预测了应用启动等状态转换。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08796", "html_url": "https://arxiv.org/abs/2507.08796", "title": "过滤不变函数：对列表长度泛化的对称解释", "title_en": "Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists", "authors": "Owen Lewis,Neil Ghani,Andrew Dudzik,Christos Perivolaropoulos,Razvan Pascanu,Petar Veličković", "background": "文章提出了一个关键性的问题：一个能够外推超越已知输入/输出示例的函数应该具备怎样的特征？一般而言，即使满足已知输入/输出的函数也可能是正确的外推函数。因此，本文研究了一种特别吸引人的规则遵守标准——对于列表函数来说，当某些元素被移除时，函数应该表现得可预测。这与函数编程中表达移除操作的标准方式——使用filter函数——相关。本文通过研究filter不变函数，旨在提供一种新的函数语义类别，并证明其包含了一些有趣的实例，还将其与广为人知的map不变函数类进行了对比。此外，还提供了一个几何解释，说明了filter不变函数如何自然地对应到某些单纯形结构。文章中最突出的结果是合成功率算法，该算法通过首先研究输入子列表上的行为来构造任何filter-不变函数的输出，从而实现完美的外推。", "innovation": "文章引入了一个新的函数类别——filter不变函数，证明了它包含有趣的例子并提出了一些基础定理，将其与map不变函数类进行了联系，并提出了一个几何解释，展示了filter不变函数如何自然对应到某些单纯形结构。最创新之处在于合成功率算法，该算法通过研究输入子列表上的行为来完美外推出filter-不变函数的输出。", "conclusion": "文章通过研究过滤不变函数，提供了一种新的函数类别及其基本特性，并通过合成功率算法完美地解释了如何从输入子列表的行为中外推出完整的输出，从而为如何构建一个适合外推的函数提供了一种新方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.00381", "html_url": "https://arxiv.org/abs/2410.00381", "title": "使用 Wasserstein 正则化扩散进行极端降水下标", "title_en": "Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion", "authors": "Yuhao Liu,James Doss-Gollin,Qiushi Dai,Ashok Veeraraghavan,Guha Balakrishnan", "background": "理解由极端降雨事件带来的风险需要高分辨率的数据（以评估局部风险）和广泛的长期数据记录（以捕捉罕见事件）。雷达和测站网络可以提供公里尺度的降水场，但由于历史记录有限且地理覆盖范围不足。相反，全球雨量计和融合产品可以跨越数十年，但其粗略的30-50公里网格会掩盖当地的极端情况。这篇论文针对该背景进行研究。", "innovation": "本文提出了一种生成下标框架 Wasserstein Regularized Diffusion (WassDiff)，该方法结合了扩散模型和分布匹配（Wasserstein）正则化器。此方法在整个生成去噪过程中抑制偏见。WassDiff 依据55公里CPC雨量计为基础的降水和31公里ERA5再分析数据，生成高分辨率1公里的降水估计值，这些估计值在整个强度范围内与目标保持良好的一致性，包括极端情况。全面的评估表明WassDiff在重建误差和减少偏差方面优于现有最先进的下标方法。实例研究还表明，WassDiff 能够重现极端天气现象（如热带风暴和冷锋）的逼真细尺度结构和准确的峰值强度。", "conclusion": "WassDiff通过利用全球可用的粗略记录中的数十年高分辨率降雨信息，为更准确的洪水风险评估和气候适应规划提供了一条切实可行的途径。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.04774", "html_url": "https://arxiv.org/abs/2410.04774", "title": "粒球Twin支持向量机", "title_en": "Granular Ball Twin Support Vector Machine", "authors": "A. Quadir,M. Sajid,M. Tanveer", "background": "Twin支持向量机(TSVM)因其广泛的应用性，在分类和回归任务中受到了广泛关注。然而，TSVM在处理大规模数据集时面临着显著挑战：（i）必须进行矩阵求逆操作极大地影响了其效率和可扩展性；（ii）其原始形式缺少结构风险最小化(SRM)原则，增加了过拟合的风险；（iii）TSVM对噪声和异常值敏感，并且在重新采样时表现出不稳定性。", "innovation": "提出了一种新型的粒球Twin支持向量机(GBTSVM)，利用粒球(而非单个数据点)作为输入来构建分类器，以增强其抗过采样的能力和对噪声和异常值的鲁棒性。此外，提出了一种新的大规模粒球Twin支持向量机(LS-GBTSVM)，其优化公式确保在不需矩阵求逆的情况下提高效率，并通过正则化项引入结构风险最小化原则，有效解决了过拟合问题。实验结果显示，GBTSVM和LS-GBTSVM具有卓越的泛化能力。", "conclusion": "GBTSVM和LS-GBTSVM模型在UCI、KEEL和NDC数据集上的全面评估中表现出色，证明了它们在大规模数据集上的高效、可扩展性和对噪声和异常值的鲁棒性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00994", "html_url": "https://arxiv.org/abs/2412.00994", "title": "PIAD-SRNN: 物理驱动的自适应分解在状态空间RNN中", "title_en": "PIAD-SRNN: Physics-Informed Adaptive Decomposition in State-Space RNN", "authors": "Ahmad Mohammadshirazi,Pinaki Prasad Guha Neogi,Rajiv Ramnath", "background": "时间序列预测通常需要在准确性和效率之间做出权衡。虽然最近的Transformer模型提高了预测能力，但它们带来了高计算成本。基于线性的模型虽然表现出更好的准确性，但在理想性能方面仍然存在差距。", "innovation": "提出了PIAD-SRNN，一种物理驱动的自适应分解状态空间RNN，该模型分离了季节性和趋势成分，并在循环框架中嵌入了领域方程。该模型在室内空气质量数据集上进行了评估，重点是不同预测时间段内的二氧化碳浓度预测，结果显示它在长期和短期时间序列预测方面的MSE和MAE中都优于当前最先进的模型，包括基于Transformer的架构。此外，还提出了四个精心策划的数据集。", "conclusion": "PIAD-SRNN能够在准确性和效率之间取得平衡，其在各类时间序列预测任务中表现出色，特别是在长期和短期预测方面超越了现有模型，同时本文还提供了四个数据集。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06728", "html_url": "https://arxiv.org/abs/2411.06728", "title": "有关单一隐藏层ReLU网络的基本原理", "title_en": "On the Principles of ReLU Networks with One Hidden Layer", "authors": "Changcun Huang", "background": "单一隐藏层或两层神经网络是最简单的前向神经网络，可能是更通用网络架构的基础。然而，即使是这种简单架构也如同一个‘黑箱’，不清楚反向传播算法得到的解决方案机制，也不清楚如何通过确定性方式控制训练过程。本文系统研究了这个问题，通过构建通用函数逼近解，展示了无论是一维输入还是高维输入，其训练解都能得到较好的理解。这些结果为深入揭示两层ReLU网络的黑箱提供了途径，也为深入理解深层ReLU网络推进了理解", "innovation": "本文通过构建通用函数逼近解，系统研究了单一隐藏层ReLU网络的训练解。无论是一维输入还是高维输入，其训练解都能得到较好的理解和控制，为深入理解两层ReLU网络及其更深层次的网络提供了新的视角和理论支持", "conclusion": "此研究表明，对于一维输入的训练解可以完全理解，而对于高维输入也可以得到一定程度的理解，为深入揭示两层ReLU网络的黑箱提供了重要的基础，并促进了对深层ReLU网络的理解"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06303", "html_url": "https://arxiv.org/abs/2410.06303", "title": "组成风险最小化", "title_en": "Compositional Risk Minimization", "authors": "Divyat Mahajan,Mohammad Pezeshki,Charles Arnal,Ioannis Mitliagkas,Kartik Ahuja,Pascal Vincent", "background": "组成泛化是开发数据高效且以人类方式泛化的智能机器的关键步骤。本文探讨了一种称作组合适应变化的数据分布变化形式，即在训练期间某些属性组合完全不存在，而在测试分布中则出现。这种变化测试了模型在判别任务中对新颖属性组合进行组合适应性泛化的能力。", "innovation": "通过使用灵活的可加能量分布模型，每种能量项代表一个属性，并提出了组成风险最小化（CRM）作为经验风险最小化的替代方案。首先训练一个可加能量分类器来预测多个属性，然后调整该分类器以应对组合适应性变化。给出了CRM的广泛理论分析，表明该提案外推到已见属性组合的特殊仿射包中。实证评估证明了CRM相比处理各种子人群变化的文献中其他方法具有更好的稳健性。", "conclusion": "该研究通过提出组成风险最小化（CRM）方法，在处理组合适应性变化方面取得了更好的稳健性表现，证明了其在判别任务中的优越性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.05274", "html_url": "https://arxiv.org/abs/2402.05274", "title": "Natural Policy Gradient算法在无限状态队列MDP家族中的收敛性", "title_en": "Convergence of Natural Policy Gradient for a Family of Infinite-State Queueing MDPs", "authors": "Isaac Grosof,Siva Theja Maguluri,R. Srikant", "background": "广泛的各种排队系统可以自然地被建模为无限状态马尔可夫决策过程（MDP）。在强化学习（RL）的背景下，已经发展出了许多算法来学习和优化这些MDP。许多受欢迎的基于策略梯度的学习算法，如自然演员-评论家、TRPO和PPO，核心都是自然策略梯度（NPG）策略优化算法。这些RL算法的收敛性结果依赖于NPG算法的收敛性结果。然而，所有现有的关于NPG算法收敛性的结果都局限于有限状态设置。", "innovation": "研究了一般类别的队列MDP，并证明如果使用MaxWeight策略初始化，NPG算法具有$O(1/\text{√}T)$的收敛速率。这是第一次对一般类别的无限状态平均奖励MDP中的NPG算法收敛性的上限。此外，结果还可以应用于超出排队设置到任何满足某些温和结构性假设的可数无限MDP，前提是具有足够好的初始策略。", "conclusion": "本研究证明了在无限状态队列MDP家族中，如果以MaxWeight策略初始化，NPG算法具有$O(1/\text{√}T)$的收敛速率。这是对NPG算法在一般类别的无限状态平均奖励MDP收敛性的首次上限证明。此外，结果还可以应用于满足某些轻微结构性假设的任意可数无限MDP，前提是具有足够好的初始策略。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.18607", "html_url": "https://arxiv.org/abs/2411.18607", "title": "通过单击联邦学习视角探讨任务算术", "title_en": "Task Arithmetic Through The Lens Of One-Shot Federated Learning", "authors": "Zhixu Silvia Tao,Ian Mason,Sanjeev Kulkarni,Xavier Boix", "background": "任务算术是一种合并多个模型能力的模型合并技术，通过权重空间中的简单算术操作即可实现，无需额外的微调或访问原始训练数据。然而，决定任务算术成功的关键因素尚不清楚。", "innovation": "将任务算术问题重新定义为单击联邦学习问题，并通过这一视角和传统的联邦学习中常用的算法——联邦平均（FedAvg）进行比较。基于FedAvg的已有理论分析，识别出影响任务算术性能的两个关键因素：数据异质性和训练异质性。并且提出了来自联邦学习领域的多种算法来改进任务算术的有效性。", "conclusion": "研究表明，应用这些联邦学习的算法可以显著提升合并模型的性能。此工作将任务算术与联邦学习相结合，为任务算术提供了新的理论视角，并提出了改进的实践方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00615", "html_url": "https://arxiv.org/abs/2501.00615", "title": "利用船舶追踪数据预测内河航段驳船存在和数量：一种机器学习方法", "title_en": "Predicting Barge Presence and Quantity on Inland Waterways using Vessel Tracking Data: A Machine Learning Approach", "authors": "Geoffery Agorku,Sarah Hernandez,Maria Falquez,Subhadipto Poddar,Shihao Pang", "background": "了解内河航段、港口之间以及到达港口的驳船的数量和类型对于估算国家水道上运输的货物量至关重要。这也可以帮助水道管理和基础设施运营，影响如目标疏浚操作和基于数据的资源分配等领域的决策。", "innovation": "该研究提出了一种基于机器学习的方法，使用自动识别系统（AIS）的追踪数据来预测内河航段上由拖船和驳船编队运输的驳船数量。通过AIS数据生成标记样本数据，并采用AdaBoost和随机森林结合的集成方法进行模型开发，分别实现了驳船存在和数量预测的高F1分数。", "conclusion": "该研究通过改进内河航段上驳船的数量和存在预测模型，为交通规划者和相关组织提供了有价值的信息。这些信息包括详细的交通量信息，如商品的流量、目的地和进出港口的吨位等。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02582", "html_url": "https://arxiv.org/abs/2502.02582", "title": "带有随机插值的开放式材料生成", "title_en": "Open Materials Generation with Stochastic Interpolants", "authors": "Philipp Hoellmer,Thomas Egg,Maya M. Martirossyan,Eric Fuemmeler,Zeren Shui,Amit Gupta,Pawan Prakash,Adrian Roitberg,Mingjie Liu,George Karypis,Mark Transtrum,Richard G. Hennig,Ellad B. Tadmor,Stefano Martiniani", "background": "新材料的发现对于推动技术进步至关重要。计算预测新材料的方法必须有效地学习无穷设计空间中稳定晶体结构的流形。先前的框架未能充分利用这种多样性和灵活性。", "innovation": "本文引入了Open Materials Generation (OMatG)，这是一种统一框架，用于生成设计和发现无机晶体材料。OMatG通过随机插值(SI)框架来实现，该框架通过一系列可调变的随机过程将任意基分布转换为目标的无机晶体分布。特别地，本文通过使用晶体结构的变换等变图表示和针对单元格表示中的周期边界条件进行了SI框架的适应。此外，首次将离散流匹配耦合到空间坐标和晶格矢量流上。OMatG在两种任务上的表现证明了其优越性：指定成分的晶体结构预测(CSP)和从头生成(DNG)，旨在发现稳定、新颖且独特的结构。", "conclusion": "OMatG在材料发现的生成建模中建立了新的标准，超越了基于流动和扩散的实施方案。这些结果强调了设计灵活深度学习框架对于加速材料科学研究的重要性。OMatG的代码已公开。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05044", "html_url": "https://arxiv.org/abs/2502.05044", "title": "基于混合机器学习的多尺度预测方法在纤维结构渗透率预测中的应用", "title_en": "Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures", "authors": "Denis Korolev,Tim Schmidt,Dinesh K. Natarajan,Stefano Cassola,David May,Miro Duhovic,Michael Hintermüller", "background": "研究界在试图预测多尺度纤维纺织结构的渗透率时，面临着计算成本高和模型效率低下的挑战。当前方法往往难以平衡预测准确性和计算效率之间的关系。该研究提出了一种将传统代理模型与物理感知神经网络（PINNs）结合的混合多尺度建模框架，以提高渗透率预测的精度和效率。", "innovation": "研究创新性地评估并整合了多种多尺度建模方法，其中包括单尺度方法（SSM）、简单尺度升化方法（SUM）、基于片段的比例尺度方法（SBM）和完全解析模型（FRM），并提出了一个结合了PINNs的双尺度混合求解器，旨在解决数据驱动代理方法的一般化误差和样本不足的问题。这种方法在预测准确性和计算效率之间找到了平衡点，具有广泛的应用前景，尤其在纤维复合材料制造中。", "conclusion": "该研究成功开发的混合多尺度框架在微观和中观尺度上实现了更准确的渗透率预测，同时保持了较高的计算效率。该框架为纤维纺织结构在多尺度水平上的优化设计和性能预测奠定了基础，为未来纤维复合材料制造技术的发展提供了支持。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07656", "html_url": "https://arxiv.org/abs/2503.07656", "title": "DriveTransformer：统一的用于扩展性强的端到端自动驾驶的Transformer", "title_en": "DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving", "authors": "Xiaosong Jia,Junqi You,Zhiyuan Zhang,Junchi Yan", "background": "端到端自动驾驶（E2E-AD）已成为自动驾驶领域的趋势，提供了数据驱动、可扩展的设计系统的方法。然而，现有的E2E-AD方法通常采用感知-预测-规划的顺序范式，这会导致累积误差和训练不稳定。手动安排任务限制了系统利用任务之间协同作用的能力（例如，规划感知和博弈论交互预测与规划）。此外，现有方法采用密集的BEV表示，为长期感知和长时序融合带来了计算挑战。", "innovation": "我们提出了DriveTransformer，这是一种简化了的E2E-AD框架，旨在易于扩展，具有三个关键特性：任务并行性（所有代理、地图和规划查询在每个块中直接相互交互）、稀疏表示（任务查询直接与原始传感器特征交互）和流式处理（任务查询作为历史信息存储并传递）。结果，新框架由三个统一操作组成：任务自注意力、传感器交叉注意力和时间交叉注意力，这大大减少了系统的复杂性并提高了训练稳定性。", "conclusion": "DriveTransformer在模拟闭环基准Bench2Drive和现实世界开环基准nuScenes中均实现了最先进的性能，且FPS较高。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18114", "html_url": "https://arxiv.org/abs/2503.18114", "title": "超越懒惰丰裕二分法的特征学习：代表几何学见解", "title_en": "Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry", "authors": "Chi-Ning Chou,Hang Le,Yichen Wang,SueYeon Chung", "background": "神经网络通过整合与任务相关的特征信息是一种基本的能力，这在生物和人工智能系统中都是如此。近期理论将学习过程划分为了两种模式：丰裕模式，即神经网络主动学习任务相关特征；懒惰模式，网络表现得像随机特征模型。然而，这种简单的懒惰-丰裕二分模式忽视了特征学习背后多样化的分类框架，这种分类框架受到学习算法、网络结构和数据特性差异的影响。本文旨在填补这一缺口，引入一种用于研究基于神经表征几何的特征学习的分析框架，以超越旧有的二分模式，提供对特征学习的新颖见解，特别是在神经科学和机器学习领域，揭示了神经回路中的结构性归纳偏差，并深入探讨了泛化性能背后的机制。", "innovation": "本文提出了一种基于神经表征几何学的特征学习分析框架，取代了原先简单懒惰-丰裕二分法，展示了随着网络学习特征，任务相关特征流形如何解结，且流形几何的改变揭示了不同学习阶段和策略。这一框架提供了跨领域的新视角，对神经科学和机器学习中的特征学习机制有了更深入的理解，特别突出了神经回路的结构性偏向以及泛化能力背后的机制。", "conclusion": "通过理论和实证分析，本文证明了基于几何视角的特征学习分析框架能够超越简单的懒惰-丰裕二分法，展示了随着网络学习，任务相关特征流形的变化，这一变化揭示了不同的学习阶段和策略。该框架为神经科学和机器学习领域提供了新的洞察，特别是揭示了神经回路中的结构性归纳偏向及泛化领域的机理。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03366", "html_url": "https://arxiv.org/abs/2502.03366", "title": "重新思考分类中的近似高斯推断", "title_en": "Rethinking Approximate Gaussian Inference in Classification", "authors": "Bálint Mucsányi,Nathaël Da Costa,Philipp Hennig", "background": "在分类任务中，softmax函数广泛用作输出激活函数以生成预测概率。然而，softmax函数只能捕捉到偶然不确定性，而不能抓住潜在不确定性。因此，提出了近似高斯推断方法以捕捉潜在不确定性。现有的这些方法通常需要蒙特卡洛（MC）方法来进行近似，这不仅计算成本高，而且结果可能不稳定。", "innovation": "本文提出了一个通用框架来描述现有的近似高斯推断方法，并认为这些方法可以看作是在logits空间上输出高斯分布。预测值通过softmax函数得到时，需要计算高斯积分以捕捉潜在不确定性，但这些积分无法通过解析方法解决。因此，本文提议用元素级的normCDF或sigmoid函数替换softmax，这允许准确地进行无抽样近似并获取预测值。此外，还可以通过匹配矩的方法将高斯分布向前推进的近似值近似为狄利克雷分布。这种方法完全消除了与MC采样相关的运行时和内存开销。", "conclusion": "本文结合几种近似高斯推断方法（Laplace、HET、SNGP）在大规模（ImageNet）和小规模（CIFAR-100、CIFAR-10）数据集上进行了评估，结果表明，这种方法比softmax MC抽样具有更好的不确定性量化能力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04088", "html_url": "https://arxiv.org/abs/2503.04088", "title": "基于向量加权平均算法改进的核极限学习机算法在云 computing 能耗预测中的应用", "title_en": "Cloud Computing Energy Consumption Prediction Based on Kernel Extreme Learning Machine Algorithm Improved by Vector Weighted Average Algorithm", "authors": "Yuqing Wang,Xiao Yang", "background": "随着云 computing 基础设施的迅速扩展，能耗问题日益突出，成为了一个关键挑战，迫切需要准确有效的预测模型。", "innovation": "提出了一个新颖的向量加权平均内核极限学习机(VWAA-KELM)模型，通过将向量加权平均算法(VWAA)与核极限学习机(KELM)结合，动态调整特征权重和优化核函数，显著提升预测准确性和泛化能力。", "conclusion": "实验结果表明，VWAA-KELM模型在测试集中的预测误差表明，模型具有强大的稳定性，训练集上的决定系数 (R2) 为 0.987，测试集上的决定系数为 0.973，模型在预测云 computing 能耗方面表现出色，同时能够捕捉非线性依赖关系。该研究的关键创新在于引入了自适应特征加权，能够动态赋予不同输入参数重要性，从而提高高维数据的处理能力。这一进步为优化云数据中心能耗提供了一种可扩展且高效的方法，并在物联网(IoT)和边缘计算等领域具有更广泛的应用前景，支持即时能源管理及智能资源分配。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.13792", "html_url": "https://arxiv.org/abs/2504.13792", "title": "二元和三元量化可以提升特征区分度", "title_en": "Binary and Ternary Quantization Can Enhance Feature Discrimination", "authors": "Weizhi Lu,Mingrui Chen,Weiyu Li", "background": "量化在机器学习中的应用广泛，用于降低计算和存储成本，特别是在数据和模型方面。分类任务是机器学习的基础任务，因此研究量化对分类性能的影响至关重要。传统研究集中于量化误差，假设较大的误差一般会导致较低的分类准确性，但这一假设缺乏坚实的理论基础，且很多时候与经验观察相矛盾。例如，采用显著错误的二元和三元量化数据有时在分类准确性上却能达到甚至超越全精度数据的效果。", "innovation": "本文提出了一种直接分析量化数据特征区分度的方法，而非关注量化误差。分析显示，二元和三元量化不仅不会削弱，反而可能增强原始数据的特征区分度。这一发现是通过在合成数据和真实数据上进行的分类实验得到的验证。", "conclusion": "研究表明，二元和三元量化能够提升特征区分度，这在一定程度上合理解释了在引入了大量错误之后分类性能仍能达到或优于全精度数据的情况。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01531", "html_url": "https://arxiv.org/abs/2504.01531", "title": "DRAN: 一种时空分布和关系自适应网络", "title_en": "DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal Forecasting", "authors": "Xiaobei Zou,Luolin Xiong,Kexuan Zhang,Cesare Alippi,Yang Tang", "background": "时空系统准确预测对于系统管理、控制和危机预防等任务至关重要。然而，许多时空系统的固有时间变化性对预测准确性构成了挑战，特别是在非平稳性情况下。为了应对非平稳性，提出了一种分布和关系自适应网络（DRAN），该网络能够动态适应不平衡关系和分布变化。传统的时序归一化和去归一化方法虽可用于应对分布变化，但这种方法并不适用于时空情境，因为时序归一化可能会缩放节点的时间序列，从而可能破坏节点之间的空间关联性。因此，该研究提出了一个空间因数学习器（SFL）模块，以便进行时空实验中的归一化和去归一化操作。进一步地，为了适应传感器之间时空关系的动态变化，研究提出了一种动力静融合学习器（DSFL）模块，该模块通过自适应融合比机制对动力和静态关系的学习特征进行了有效整合。此外，引入了随机学习器来捕捉时空表示中的噪声成分。实验结果表明，我们的方法在天气预测和交通流量预测任务上优于现有的最先进的方法。研究结果还表明，SFL有效保持了在各种时序归一化操作过程中的空间关系。学习到的动力和静态关系的可视化表明，DSFL能够捕捉节点之间的局部和远处关系。", "innovation": "提出了分布和关系自适应网络（DRAN），它能够动态适应时间序列中的变化关系和分布。开发了空间因数学习器（SFL）模块，用于在时空预测中进行归一化和去归一化操作，并提出了一种动态静融合学习器（DSFL）模块，该模块通过自适应融合比机制整合了动力和静态关系的学习特征。此外，引入随机学习器来捕捉时空表示中的噪声成分。DRAN优于现有技术，特别是在针对非平稳性的处理能力上表现出色。", "conclusion": "通过使用DRAN，能够提高时空预测的准确性，特别是在非平稳性情况下。SFL有效保持了空间关系，并且DSFL能够同时捕捉节点之间的局部和远处关系。在天气预测和交通流量预测等任务上，DRAN优于现有的最先进的方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14765", "html_url": "https://arxiv.org/abs/2505.14765", "title": "基于深度学习的急诊就诊患者床位占用预测以应对急诊科拥堵", "title_en": "Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding", "authors": "Orhun Vural,Bunyamin Ozaydin,James Booth,Brittany F. Lindsey,Abdulaziz Ahmed", "background": "该研究提出了一种基于深度学习的方法，用于使用只有操作和服务层面的数据预测急诊部门（ED）六小时前的床位占用情况，无需使用个人患者信息。研究中使用的数据包括急诊跟踪系统数据、在院患者统计、天气情况、假期以及地方活动数据，并且这些数据按小时汇总处理。", "innovation": "研究中使用了ResNetPlus、TSTPlus和TSiTPlus等多重深度学习模型，并使用Optuna进行训练和优化。TSTPlus在预测中表现最佳，其平均绝对误差为4.30，均方误差为29.47，R²值为0.79。研究表明，更广泛的数据输入特征可以提高预测准确性。", "conclusion": "此方法支持主动管理医院运营，并提供了一种实际策略来缓解急诊科的拥堵情况。该框架能够准确预测床位占用情况，包括在极端时期也有效。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19034", "html_url": "https://arxiv.org/abs/2504.19034", "title": "关于学习生物序列空间上的功能函数：关联高斯过程先验、正则化和偏移修复", "title_en": "On learning functions over biological sequence space: relating Gaussian process priors, regularization, and gauge fixing", "authors": "Samantha Petti,Carlos Martí-Gómez,Justin B. Kinney,Juannan Zhou,David M. McCandlish", "background": "生物序列（DNA、RNA、蛋白质）到序列功能的量化度量的映射在现代生物学中扮演着重要角色。研究兴趣在于通过推断预测的序列到功能映射以及分解序列到功能映射来揭示个别子序列的贡献。由于每个性能映射可以以多种方式表示为多个子序列的加权和，因此需要“偏移修复”，即为每个性能映射定义一个独特表示。现有工作表明，大多数现有偏移修复表示是通过在过参数化“权重空间”中$L_2$-正则化回归的唯一解获得的，其中正则化器的选择定义了偏移类型。", "innovation": "该研究建立了过参数化权重空间中的正则化回归和在“函数空间”（即有限序列上的所有实值函数空间）中操作的高斯过程方法之间的关系。分离了权重空间正则化器对学习的函数施加隐含先验以及将最优权重限制到特定偏移类型的影响。还通过结合广泛的种类构建了与任意显式高斯过程先验对应的正则化器。推导出由高斯过程后验暗示的偏移修复权重的分布，并表明即使对于长序列，使用核技巧也可以高效计算乘性核先验的权重分布。最后表征了最常见的权重空间正则化的隐含函数空间先验。", "conclusion": "总体而言，该框架整合并扩展了推断和解释序列功能关系的能力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05718", "html_url": "https://arxiv.org/abs/2506.05718", "title": "模型参数欧几里得范数之外的grokking", "title_en": "Grokking Beyond the Euclidean Norm of Model Parameters", "authors": "Pascal Jr Tikeng Notsawo,Guillaume Dumas,Guillaume Rabusseau", "background": "Grokking是指通过梯度基方法优化人工神经网络时，在过拟合后出现的延迟泛化现象。以往研究表明，使用非零权重衰减可以诱导grokking现象。本文进一步探讨了通过正则化，无论是显式还是隐式的，能否诱发grokking。此外，文章还探讨了欧几里得范数在正则化目标为其他属性时，是否能可靠地作为泛化指标的问题。研究还表明，通过增加网络深度和数据选择，可以强化或削弱网络的grokking现象，而无需使用显式正则化手段。", "innovation": "本文创新性地提出，通过特定形式的正则化（如稀疏权重或低秩权重）诱导grokking现象。此外，研究显示，深度网络下的grokking现象可以不依赖于显式正则化，而浅层网络条件下则无法实现。论文还发现，当模型正则化目标不是权重的欧几里得范数时，这种情况下的欧几里得范数无法可靠地反映模型泛化性能。研究最后展示了仅通过数据选择即可增强或削弱grokking现象，而需固定其他超参数。", "conclusion": "通过对特定类型正则化的研究，本文揭示了诱导和控制grokking现象的新方法，同时指出欧几里得范数在正则化目标变化时不是可靠的泛化度量。研究意外地发现了通过增加网络深度和精心选择数据以强化或削弱grokking现象的可能性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24360", "html_url": "https://arxiv.org/abs/2505.24360", "title": "通过字典学习解析大型文本到图像扩散模型", "title_en": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning", "authors": "Stepan Shabalin,Ayush Panda,Dmitrii Kharlapenko,Abdur Raheem Ali,Yixiong Hao,Arthur Conmy", "background": "稀疏自动编码器是一种有前途的新方法，可用于分解语言模型激活，以供解释和控制。它们已在视觉变换器图像编码器和小型扩散模型中成功应用。Inference-Time Decomposition of Activations (ITDA) 是最近提出的字典学习变体，采用激活分布中的数据点作为字典，并使用梯度追求重构他们。", "innovation": "作者将稀疏自动编码器（SAEs）和 ITDA 应用于大型文本到图像扩散模型 Flux 1，并引入了一种视觉自动化解释管道以研究嵌入的可解释性。研究发现，SAEs 准确重建剩余流嵌入并优于MLP神经元的可解释性。还能够使用SAE特征引导图像生成并添加激活功能。研究发现，ITDA在可解释性方面与SAE相当。", "conclusion": "稀疏自动编码器和ITDA在大型文本到图像扩散模型中的应用提高了模型嵌入的可解释性，并揭示了如何利用它们控制图像生成过程。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06489", "html_url": "https://arxiv.org/abs/2506.06489", "title": "交替梯度流：两层神经网络中特征学习的理论", "title_en": "Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks", "authors": "Daniel Kunin,Giovanni Luca Marchetti,Feng Chen,Dhruva Karkada,James B. Simon,Michael R. DeWeese,Surya Ganguli,Nina Miolane", "background": "神经网络在学习哪些特征以及如何学习这些特征仍然是一个开放的问题。先前的研究表明，在小初始化的情况下，梯度流表现为阶梯状的损失曲线，交替在停滞期，此时神经元缓慢对齐到有用的特征方向，和尖锐下降期，此时神经元迅速增长。本文引入了交替梯度流(AGF)，一种描述两层网络从小初始化训练中特征学习动态的算法框架。", "innovation": "AGF近似这种行为为交替的两步过程：最大化废话函数传导神经元并最小化成本函数传导激活神经元。AGF开始时所有神经元都处于休眠状态。在每一个回合中，一个休眠的神经元被激活，触发特征的获取和损失的下降。AGF量化这些下降的顺序、时间和幅度，与不同架构的实验结果匹配。AGF统一并扩展了完全连接的线性网络和注意力仅线性变压器中的鞍点到鞍点分析，其中学习的特征分别是奇异模和主成分。在对角线线性网络中，我们证明AGF在初始化接近于消失的情况下收敛到梯度流。", "conclusion": "AGF为理解神经网络中的特征学习提供了一个有希望的步骤。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17621", "html_url": "https://arxiv.org/abs/2505.17621", "title": "利用内在动机引导探索增强大语言模型推理", "title_en": "Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration", "authors": "Jingtong Gao,Ling Pan,Yejing Wang,Rui Zhong,Chi Lu,Qingpeng Cai,Peng Jiang,Xiangyu Zhao", "background": "强化学习（RL）已经成为提升大语言模型（LLM）推理能力的关键方法。然而，常见的RL方法如近端策略优化（PPO）和组正则化策略优化（GRPO）依赖稀疏结果奖励，缺乏有效激励探索的机制，造成多步骤推理过程中的效率低下。具体来说，稀疏奖励信号无法提供有效或足够的反馈，特别是在处理复杂问题时。此外，这样的奖励结构会导致系统性偏见，优先选择熟悉的路径而非发现新颖的解决方案。这些不足在复杂推理任务中对表现构成了严重阻碍，这些任务需要在中间步骤进行迭代优化。为了解决这些挑战，我们提出了一种名为Intrinsic Motivation guidEd exploratioN meThod foR LLM Reasoning（i-MENTOR）的新方法，旨在在基于RL的训练框架中提供密集奖励并增强探索。i-MENTOR引入了三个关键创新：路径感知的探索奖励以降低在令牌级策略中的偏见同时保持计算效率；动态奖励缩放以在大动作空间中稳定探索和利用；以及优势保持的奖励实施，以维护优势分布的完整性同时增强探索指导。", "innovation": "i-MENTOR引入了三个关键创新：路径感知的探索奖励、动态奖励缩放和优势保持的奖励实施。路径感知的探索奖励可缓解在令牌级策略中的偏见，同时保持计算效率；动态奖励缩放可在大动作空间中稳定探索和利用；优势保持的奖励实施可维护优势分布的完整性同时增强探索指导。这些创新有助于解决稀疏奖励信号和探索机制的不足，从而提升复杂的推理任务表现。", "conclusion": "在三个公共数据集的实验中，i-MENTOR 证明了其有效性，特别是在困难的数据集 Countdown-4 上取得了 22.39% 的性能提升。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18247", "html_url": "https://arxiv.org/abs/2506.18247", "title": "使用可微物理指导机器学习架构高效量化建模不确定性", "title_en": "Exploring Efficient Quantification of Modeling Uncertainties with Differentiable Physics-Informed Machine Learning Architectures", "authors": "Manaswin Oddiraju,Bharath Varma Penumatsa,Divyang Amin,Michael Piedmonte,Souma Chowdhury", "background": "在工程设计和控制领域，可靠性和鲁棒优化等算法过程需要量化和传播建模不确定性。传统计算建模和代理模型方法存在效率、准确性与解释性之间的平衡难题。近年来，物理信息机器学习(PIML)方法提供了一种新的替代方案，但在模型不确定性预测和传播方面的能力尚未得到充分探索。", "innovation": "本文提出了一种结合部分物理和神经网络（输入变换或自适应参数估计）的自微分混合PIML架构，并用贝叶斯神经网络替代了原有的神经网络，以探索贝叶斯神经网络是否能在PIML架构中成功提供不确定性传播能力。采用两阶段训练过程来解决训练概率机器学习模型时遇到的挑战。实验结果显示，在分析基准问题和固定翼遥控飞机飞行实验数据上的预测性能略差或持平于纯数据驱动的机器学习模型和原始PIML模型。同时，贝叶斯神经网络权重的蒙特卡洛采样在传播不确定性方面效果最佳。", "conclusion": "在PIML架构中集成贝叶斯神经网络能够有效处理建模不确定性，尽管在某些具体情况下的预测性能略有下降，但展示了其在可靠性分析和优化中的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19703", "html_url": "https://arxiv.org/abs/2506.19703", "title": "利用学习辅助的双图匹配方法进行受损电力网络和道路运输网络的多机组恢复", "title_en": "Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks", "authors": "Nathan Maurer,Harshal Kaushik,Roshni Anna Jacob,Jie Zhang,Souma Chowdhury", "background": "关键基础设施网络（CINs）在遭受诸如自然灾害等中断后的恢复能力取决于恢复速度和运营功能恢复的程度。资源分配以最大限度地优化这一过程是一个组合优化问题，涉及决定哪些维修队伍将修复特定的网络节点以及修复顺序。本文探讨了在电力网和交通运输网络共同受损的情况下，如何高效分配维修资源的问题背景和重要性。", "innovation": "本文提出了一种基于图的新型建模方法，将修复工作者和交通运输节点、电力网络节点两个图进行整合，形成一个异构图。通过结合图强化学习（GRL）和双图匹配技术，设计了一种激励函数，用于根据环境图抽象状态将修复工作者分配到修复任务中。该方法利用了图形神经网络和神经进化两种学习技术，从而能够为修复任务分配最佳的修复工作者，并进行高效的路径规划。", "conclusion": "通过仿真实验，验证了该方法的有效性。该方法不仅表现出良好的泛化能力和可扩展性，还比随机策略性能提高了3倍，以及在计算时间和电力恢复方面都优于基于优化的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23182", "html_url": "https://arxiv.org/abs/2506.23182", "title": "仅正样本数据的深度生成序列模型属性赋值有助于可解释性分析", "title_en": "Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data", "authors": "Robert Frank,Michael Widrich,Rahmad Akbar,Günter Klambauer,Geir Kjetil Sandve,Philippe A. Robert,Victor Greiff", "background": "生成式机器学习模型为药物设计提供了一种强大的框架，有效探索富含所需特征的生物序列空间。与需要正负样本数据的监督学习方法不同，生成模型如LSTM仅需正样本数据，例如高亲和力抗体即可进行训练。然而，在生物环境中缺乏可信赖的负面样本，这限制了我们从生成模型中提取生物意义的洞察。因此，发展一种可作为生成模型归因方法的解决方案变得重要。", "innovation": "该研究开发了一种名为GAMA（Generative Attribution Metric Analysis）的方法，基于集成梯度（Integrated Gradients）用于自回归生成模型的归因分析。通过合成数据集进行评估，GAMA展示了其统计行为并验证其恢复生物学相关特征的能力。GAMA的应用于实验抗体-抗原结合数据进一步证明了其实用性，使得在没有负面训练数据的情况下，可以实现生成序列设计策略的可解释性和验证性。", "conclusion": "GAMA方法填补了生成模型归因领域的空白，通过利用正样本数据提高了生成序列模型的可解释性，使得无需负样本数据也可验证生成序列设计策略的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20893", "html_url": "https://arxiv.org/abs/2506.20893", "title": "关于有效类别遗忘中输出分布重新加权的必要性", "title_en": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "authors": "Yian Wang,Ali Ebrahimpour-Boroojeny,Hari Sundaram", "background": "遗忘特定类别的训练模型是确保用户删除权利和减轻有害或有偏见预测的关键步骤。然而，完全重新训练模型代价高昂，现有的遗忘方法在预测遗忘类样本时无法重现重新训练模型的行为。通过设计一种成员推理攻击变体MIA-NN，证明了这一失败，并指出任何针对遗忘类的现有方法都存在这一问题。", "innovation": "提出了一种名为RWFT的轻量级输出加权遗忘方法，该方法能够删除整个类别而不进行重新训练，大大降低了成本。同时设计了一种基于预测概率的总变异度（TV）距离的新度量标准，用于量化残留泄露，以此防止未来方法对此新攻击的易感性。", "conclusion": "通过与机器遗忘领域的尖端基线方法进行广泛的实验，证明了该方法在以往工作中使用的两个度量标准和本文提出的TV基新度量标准下，与完全重新训练的结果相当。与最先进的方法相比，该方法在以前使用度量标准上增加2.79%，在新提出的TV基度量标准上，比当前最优方法高111.45%。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05416", "html_url": "https://arxiv.org/abs/2507.05416", "title": "EmissionNet：农业空气质量污染预测", "title_en": "EmissionNet: Air Quality Pollution Forecasting for Agriculture", "authors": "Prady Saligram,Tanvir Bhathal", "background": "农业排放的空气污染是环境和公共卫生挑战的重要因素，但常常被忽视。传统的空气质量预报模型依赖于基于物理的方法，这些方法难以捕捉复杂的非线性污染物交互作用。", "innovation": "本文探索通过评估流行架构并提出两种新颖的深度学习架构，EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，来预测N₂O农业排放。这些模型利用卷积和基于变换器的架构从高分辨率排放数据中提取时空依赖关系。", "conclusion": "通过引入两种新的深度学习架构，EmissionNet和EmissionNet-Transformer，本文提出了一种新的方法来预测农业排放的空气污染，这种方法能够更好地捕捉复杂的交互作用，从而提升空气质量预测的准确性和实用性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01381", "html_url": "https://arxiv.org/abs/2507.01381", "title": "分布式的软价值决策者与扩散策略", "title_en": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": "Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li", "background": "强化学习在处理复杂控制任务方面已被证明非常有效。传统方法通常使用单模分布，如高斯分布，来建模价值分布的输出。然而，单模分布容易引起价值函数估计的偏差，导致算法性能较差。", "innovation": "本文提出了一种分布式的软价值决策者与扩散策略算法（DSAC-D），通过引入政策熵和价值分布函数建立了多模态分布的策略迭代框架，可以收敛到最优策略。通过使用扩散模型反向采样生成一组奖励样本，构建了能够准确刻画具有多个峰值的价值分布的扩散价值网络，进而提出了一种价值网络和策略网络双重扩散的分布式强化学习算法。实验结果表明，该算法不仅学习多模态策略，还在9个控制任务中达到了最先进的性能，相较于主流算法，偏差抑制显著且平均总回报提升了超过10%。实车测试结果表明，DSAC-D能够准确描述不同驾驶风格的多模态分布，扩散策略网络能够刻画多模态轨迹。", "conclusion": "该算法能够收敛到最优策略、学习多模态策略、并显著改善了偏差估计和总回报。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21940", "html_url": "https://arxiv.org/abs/2506.21940", "title": "塑造量子景观：参数量子电路中Fubini-Study度量的条件优化以实现几何感知学习", "title_en": "Sculpting Quantum Landscapes: Fubini-Study Metric Conditioning for Geometry Aware Learning in Parameterized Quantum Circuits", "authors": "Marwan Ait Haddou,Mohamed Bennai", "background": "本文介绍了一种名为Sculpture的新元学习框架，该框架显式地调节参数化量子电路的Fubini Study度量张量，以减轻变分量子算法中的荒原高原问题。理论分析表明，Fubini Study度量的对数条件数是影响训练性、优化动力学和泛化的关键几何量。实验结果表明，元训练将对数条件数从约1.47降低到0.64，通过显著增加度量的最小特征值和轻微减少最大特征值来有效缓解荒原高原问题。改进的条件在未见过的数据上泛化良好，一致生成条件良好的量子电路初始化。在Kaggle糖尿病数据集上的下游混合量子经典分类任务中，增加元缩放系数加快了收敛速度，降低了训练损失和梯度值，尤其是显著提高了泛化性能，测试准确率从约0.68提高到超过0.78。", "innovation": "提出了一个新的元学习框架Sculpture，该框架通过调节参数化量子电路的Fubini Study度量张量来克服变分量子算法中的荒原高原问题。该方法利用一个经典的元模型生成数据依赖的量子电路初始化，以最小化对数条件数，从而促进各向同性的参数空间。这种方法能够有效减少对数条件数，使量子电路的初始化更加条件良好。实验结果表明元训练能够显著改善参数化量子电路的训练性、优化和泛化。", "conclusion": "通过元学习结构调整量子电路的景观是一种有原则性的几何正则化方法，可以大幅提高参数化量子电路的训练性、优化和泛化能力，使得变分量子算法更加稳健和高效。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02367", "html_url": "https://arxiv.org/abs/2502.02367", "title": "电场匹配：一种生成和传输数据的电场范式", "title_en": "Field Matching: an Electrostatic Paradigm to Generate and Transfer Data", "authors": "Alexander Kolesov,Manukhov Stepan,Vladimir V. Palyulin,Alexander Korotin", "background": "该研究基于物理学中的电容器原理，提出了电场匹配（Electrostatic Field Matching，EFM）方法，适用于生成建模和数据分布转移任务。", "innovation": "该方法创新性地将源分布和目标分布分别置于电容器的两极，通过神经网络逼近学习电场，并通过沿着电场线移动样本来实现分布之间的映射。理论和实践研究表明，该方法能够有效实现数据分布转移。", "conclusion": "通过理论证明和实验验证，该研究证明EFM方法能在生成模型和数据分布转移任务中提供有效的方法，为相关领域的研究提供了新的思路和工具。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08766", "html_url": "https://arxiv.org/abs/2507.08766", "title": "一种带有特征提取和K-均值的多阱Hopfield-CNN混合模型的MNIST分类", "title_en": "A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification", "authors": "Ahmed Farooq", "background": "本文研究提出了结合卷积神经网络（CNN）和多阱Hopfield网络的混合模型，用于识别MNIST数据集的手写数字。背景信息涵盖传统图像分类方法的局限性，如固定特征提取和分类过程的不透明性，以及CNN在图像特征提取方面的优势。", "innovation": "该研究的创新之处在于提出了一个混合模型，该模型利用CNN提取输入图像的高维特征，并通过k-means聚类将这些特征映射到类特定原型上。这些原型用作多阱能量景观中的稳定状态，Hopfield网络通过最小化能量函数来进行分类，该函数平衡了特征相似性和类别区分。这种设计使得模型能够 robustly 处理同一类内部的变化，如不同的手写风格，同时通过能量基础的决策过程提供了一个可解释的框架。", "conclusion": "研究表明，通过优化CNN架构和阱的数量，该模型在MNIST数据集上的测试准确率达到99.2%，达到了较为理想的效果。研究成果表明深度特征提取和充分的原型覆盖在达到高性能中起着关键作用，并且具有在模式识别中的广泛潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2111.14003", "html_url": "https://arxiv.org/abs/2111.14003", "title": "电子商务领域中的多信息源问题生成", "title_en": "Answer Generation for Questions With Multiple Information Sources in E-Commerce", "authors": "Anand A. Rajasekar,Nikesh Garera", "background": "在电子商务领域，用户每天都会在购物过程中提出大量的产品相关问题，自动问答系统可以快速响应这些产品相关的查询，但要有效地利用商品评价、相似问题和规格等多信息源，解决复杂问题并不容易，因为存在无关信息和情感模糊的挑战。", "innovation": "本文提出了一种新颖的问答生成管线（MSQAP），通过分别进行相关性和歧义性预测，有效利用了上述信息源。实验结果显示，我们的相关性预测模型（BERT-QA）比BERT-base基线提高了12.36%的F1分数，生成模型（T5-QA）在所有内容保留指标（如BLEU和ROUGE）上都优于基线，BLEU指数平均提高了198.75%，ROUGE提高了35.02%，并在人工评估中提高了20%的整体准确性。", "conclusion": "本研究在电子商务领域首次通过结合规格、相似问题和评价数据等方式自动生成自然语言回答，展示了一种新的方法，不仅在技术上有所突破，而且在效果上具有明显的优势。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03631", "html_url": "https://arxiv.org/abs/2507.03631", "title": "科学机器学习揭示神经群体的治理方程", "title_en": "Scientific Machine Learning of Chaotic Systems Discovers Governing Equations for Neural Populations", "authors": "Anthony G. Chesebro,David Hofmann,Vaibhav Dixit,Earl K. Miller,Richard H. Granger,Alan Edelman,Christopher V. Rackauckas,Lilianne R. Mujica-Parodi,Helmut H. Strey", "background": "在物理学和神经科学中，发现描述复杂混沌系统的支配方程仍然是一个基本挑战。传统的技术在面对有限或噪声数据时往往无法提取出可解释的数学表达式，尤其是在处理混沌动力系统时更为困难。这项研究介绍了一种结合预测误差方法和普遍微分方程的新方法——PEM-UDE方法，能够在混沌动力系统中提取出可解释的数学表达式，且即使仅有有限或噪声干扰的数据也能够有效工作。这与传统方法的区别在于，PEM-UDE方法能够平滑优化景观，并在拟合过程中移除混沌特性，而不会扭曲最优参数。该研究通过Rossler系统和噪声干扰的电路数据示例，验证了其在恢复隐藏状态和重构动态方面的有效性，特别是当一个观测时间序列的数据噪声达到真实信号5倍时，仍能恢复正确的动态函数形式。此外，该方法在处理神经群体数据时，能够提取出符合生物约束，如网络稀疏性等生物学条件的方程，这些约束对于皮层信息处理至关重要，而不被新一代神经群体模型所捕捉。并且这些方程预测了连接密度与神经环路振荡频率和同步性的新兴关系，得到了三个不同的脑区的电极记录数据的支持。这项研究为开发跨尺度脑模型提供了路径，有助于从单神经元动态到大规模脑活动的全面理解，填补了该领域研究的空白。", "innovation": "PEM-UDE方法在混沌动力系统的复杂性下提供了新的解决方案，其能够有效提取出可解释的数学方程。主要创新点包括：1) 结合预测误差方法和普遍微分方程的创新，提供了一种更高效的算法框架；2) 通过平滑优化景观和移除混沌特性，解决了有限或噪声数据的处理难题；3) 提取的方程不仅能够恢复正确的动态函数形式，而且能够反映神经生物学条件，如网络稀疏性；4) 这种方法成功地预测了神经环路中连接密度和振荡频率、同步性的关系，并得到了实验数据的支持。", "conclusion": "通过PEM-UDE方法，研究人员成功地在混沌动力系统中提取出了隐藏状态和正确的动态模型，甚至在存在大量噪声的情况下也能够有效工作。更重要的是，该方法能够处理神经群体数据，提取出符合生物约束的方程，填补了现有模型的空白。这些方程预测了神经环路中连接密度与振荡频率、同步性之间的关系，并得到了脑区记录数据的支持。这项工作为跨尺度脑模型的开发提供了新的途径，有助于从单神经元动态到大规模脑活动的理解。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07883", "html_url": "https://arxiv.org/abs/2507.07883", "title": "SAMO: 一种基于联合全局-局部扰动的轻量级敏锐度校准多任务优化方法", "title_en": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation", "authors": "Hao Ban,Gokul Ram Subramani,Kaiyi Ji", "background": "多任务学习（MTL）是一种能够捕获多个任务之间共有特征的技术，能够减少计算成本并提高数据效率。然而，MTL优化中的主要挑战是任务冲突，当多个任务的梯度方向或幅度不一致时，这会限制模型性能，使其低于单任务学习的性能。为了应对这一挑战，SAM（Sharpness-Aware Minimization）方法不仅最小化任务损失，还有效减少了损失景观的敏锐度，我们的实证研究表明SAM能够有效缓解MTL中的任务冲突。", "innovation": "本研究提出SAMO（Sharpness-Aware Multi-task Optimization），一种结合了全局-局部扰动的轻量级多任务优化方法。这种方法充分利用了联合的全局和局部扰动信息，局部扰动通过前向传播来近似计算，并且逐层归一化以提高效率。该方法在一系列多任务基准测试中的实验结果证明了其有效性和效率，明显缓解了任务冲突，并提升了模型性能。", "conclusion": "实验结果显示，SAMO在多个多任务基准测试中表现出了高效性，并且通过使用前向传播来近似计算局部扰动，解决了计算和内存开销的问题。SAMO是一种有效的多任务优化方法，能够有效缓解多任务学习中的任务冲突问题。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06892", "html_url": "https://arxiv.org/abs/2507.06892", "title": "挤压饱水海绵：高效离策学习文本微调以提升大语言模型推理能力", "title_en": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model", "authors": "Jing Liang,Hongyao Tang,Yi Ma,Jinyi Liu,Yan Zheng,Shuyue Hu,Lei Bai,Jianye Hao", "background": "强化学习（RL）已经展示了提升大型语言模型（LLMs）推理能力的潜力。然而，大多数现有的强化学习微调（RFT）方法是基于策略的，即它们依赖于过去学习过程中的数据生成，导致计算资源和时间成本的大幅增加，阻碍了经济高效的扩展。", "innovation": "提出了复生混合策略近端策略改进（ReMix），这是一种通用方法，使像PPO和GRPO这样的在线策略RFT方法能够利用离策略数据。ReMix包含三个主要组件：（1）具有增加的更新到数据比率的混合策略近端策略改进，以便高效训练；（2）KL-凸策略约束，以平衡稳定性和灵活性之间的trade-off；（3）策略复生，以实现从早期阶段高效的初步学习无缝过渡到稳定的渐近改进。实验结果显示，与15个最近的先进模型相比，ReMix在各类数学推理基准测试（如AIME'24、AMC'23、Minerva、OlympiadBench、MATH500）中展示了SOTA级别的性能，同时训练成本减少了30倍到450倍。", "conclusion": "通过多角度分析，揭示了由于离策略偏差引起的鞭打效应导致对较短回复的隐含偏好，以及在严重离策略性的存在下自我反思行为的崩溃模式等有趣发现。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2301.11050", "html_url": "https://arxiv.org/abs/2301.11050", "title": "Minerva: 基于文件的勒索软件检测器", "title_en": "Minerva: A File-Based Ransomware Detector", "authors": "Dorjan Hitaj,Giulio Pagnotta,Fabio De Gaspari,Lorenzo De Carli,Luigi V. Mancini", "background": "近年来，勒索软件攻击造成了数十亿美元的损失，并预计未来还将造成更多损失。因此，已投入大量精力进行勒索软件检测和缓解。基于行为的勒索软件检测方法最近受到了大量关注。这些行为检测器通常依赖于基于进程的行为特征来识别恶意行为。然而，随着文献中越来越重视此类方法容易受到规避攻击的漏洞，勒索软件问题的全面解决方案仍然没有实现。", "innovation": "本文提出了一种名为Minerva的新型、健壮的勒索软件检测方法。Minerva专门设计以抵御规避攻击的侵袭，并且其架构和特征选择是由其对对抗性操纵的抗性来指导的。我们对Minerva在各种类型的勒索软件中进行了全面分析，包括未见过的勒索软件及旨在躲避Minerva的变种。评估结果显示，Minerva能够准确识别勒索软件、能够泛化到未见过的威胁，并且能够抵御规避攻击。此外，检测出的勒索软件中超过99%可以在520毫秒内被识别，这使得可以采用数据丢失预防技术并几乎不增加额外的成本。", "conclusion": "Minerva通过其设计和实现特征，成功地提供了一种针对勒索软件的稳健检测方法，不仅能够识别现有的勒索软件，还能有效应对新型和有规避能力的勒索软件威胁。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.02672", "html_url": "https://arxiv.org/abs/2402.02672", "title": "分布式保密数据中的条件平均治疗效应估计", "title_en": "Estimation of conditional average treatment effects on distributed confidential data", "authors": "Yuji Kawamata,Ryoki Motai,Yukihiko Okada,Akira Imakura,Tetsuya Sakurai", "background": "条件平均治疗效应（CATEs）在许多科学领域中是一个重要的研究课题。以前的研究表明，如果能够在保密或隐私保护下汇总多来源的数据，那么CATEs的估计可以达到较高的准确性。然而，由于隐私或机密性的问题，实际中很难将这些分散的数据集中起来进行汇总。因此，有必要提出一种能够在保护隐私的前提下估计CATE模型的方法，以解决这一问题。", "innovation": "本文提出了一种名为数据协作双机器学习的方法，该方法能够在保护隐私的前提下，通过分布式来源的数据构建隐私保护融合数据来估计CATE模型。本文的主要创新点包括：首先，该方法能够通过非迭代沟通的途径估计和测试半参数CATE模型，并且相较于参数方法，该方法更具有模型误规格化下的鲁棒性；其次，该方法能够跨越不同时间点和机构进行协作估计，并且能够持续积累知识库；第三，通过合成、半合成及实际数据集的仿真测试表明，该方法在性能上与现有方法相比具有相似性或更强的表现。", "conclusion": "在模拟测试中，本文提出的方法在估计分布式保密数据的CATE模型方面表现良好，相较于现有的方法，该方法能够在保护数据隐私的前提下，提供更有效的CATE模型估计手段。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.06759", "html_url": "https://arxiv.org/abs/2403.06759", "title": "平均校准误差：一种用于图像分割增强可靠性的可微损失", "title_en": "Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation", "authors": "Theodore Barfoot,Luis Garcia-Peraza-Herrera,Ben Glocker,Tom Vercauteren", "background": "深度神经网络在医学图像分割中经常产生过度自信的结果，不与实际观察相符。这种误差校准的不准确对它们的临床应用构成了挑战。传统的校准方法通常需要使用近似但可微的替代方法或软分箱方法，这增加了复杂性并可能影响校准精度。", "innovation": "作者提出了一种新的辅助损失函数—边际L1平均校准误差（mL1-ACE），用于在不牺牲分割质量的情况下改进像素级校准。该损失直接可微，避免了使用近似且可微的替代方法或软分箱方法。此外，该工作还引入了数据集可靠性直方图的概念，作为通用的可靠性图来全面评估语义分割的校准情况。实验结果显示，通过mL1-ACE，平均和最大校准误差分别降低了45%和55%，同时保持了在BraTS 2021数据集上的Dice评分为87%。", "conclusion": "作者利用mL1-ACE显著提升了图像分割模型的校准质量，同时保持了高分割准确率，并通过数据集可靠性直方图提供了更细致的视觉校准评估方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.10242", "html_url": "https://arxiv.org/abs/2402.10242", "title": "带签名的多样化多层网络：聚类与推断", "title_en": "Signed Diverse Multiplex Networks: Clustering and Inference", "authors": "Marianna Pensky", "background": "该论文介绍了Signed Generalized Random Dot Product Graph (SGRDPG)模型，这是Generalized Random Dot Product Graph (GRDPG)模型的一个变种，加入了一般可以为正或负的边。随后，将设置扩展到多层版本，所有层共享相同的节点集合并在SGRDPG下运行。网络的每层都可以被划分为具有共同子空间结构的组，而连接概率矩阵可以在不同层之间变化。这种设置非常灵活，涵盖了多种现有的多层网络模型，包括GRDPG及其特殊情况。此外，论文使用新的方法学框架，确保了层之间的强一致聚类和高精度子空间估计，这些都比Pensky和Wang（2024）的成果有了显著的改进。所有算法和理论结果适用于有符号网络和二元网络，同时，保持边的符号在网络构建过程中可以提高估计和聚类的准确性，对现实世界的问题具有更好的应用价值，比如大脑网络分析等。", "innovation": "1. 引入了SGRDPG模型，可以处理带符号的边。\n2. 提出的多层网络模型非常灵活，能涵盖多种现有模型。\n3. 使用新的方法学确保了强一致聚类和高度准确的子空间估计。\n4. 这些结果优于Pensky和Wang（2024）的原有结果。\n5. 算法和结果对有符号网络和二元网络都适用。\n6. 保留边的符号可以提高估计和聚类的准确性，适用于实际应用场景，如大脑网络分析等", "conclusion": "通过引入SGRDPG模型和新的方法学，该论文提供了一种有效的方法来聚类和推断带符号的多样化的多层网络，该方法能灵活地处理各种网络模型并显著提高估计和聚类的准确性。这为实际应用，如大脑网络分析等，带来了积极的影响。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.19715", "html_url": "https://arxiv.org/abs/2405.19715", "title": "SpecDec++：通过自适应候选长度提升推测性解码", "title_en": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths", "authors": "Kaixuan Huang,Xudong Guo,Mengdi Wang", "background": "推测性解码通过使用一个较小且更快的草稿模型来减少目标大型语言模型的推理延迟。当前方法往往使用简单的启发式方法选择候选长度K，这可能导致性能不佳。已有研究尚未深入探讨K的最佳选择，并将此问题以马尔可夫决策过程的形式进行了建模。", "innovation": "本文研究了推测性解码中候选长度K的选择，并将其建模为马尔可夫决策过程。理论上证明最优策略是阈值策略。基于此理论，提出了SpecDec++，一种增强的推测性解码版本，能够实时自适应地确定候选长度。通过与训练好的接受预测头部结合，SpecDec++在预测到至少一个候选令牌被拒绝的概率超过阈值时停止当前推测。实验结果显示，SpecDec++在多种数据集上的加速效果显著。", "conclusion": "通过采用SpecDec++，在Alpaca数据集上实现了2.04倍的加速（比基线推测性解码提高了7.2%）。在GSM8K和HumanEval数据集上分别实现了2.26倍和2.23倍的加速（分别提升了9.4%和11.1%）。证明了自适应方法的有效性，并在论文中提供了代码。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.17907", "html_url": "https://arxiv.org/abs/2407.17907", "title": "使用扩散先验蒸馏的可固有后验采样", "title_en": "Amortized Posterior Sampling with Diffusion Prior Distillation", "authors": "Abbas Mammadov,Hyungjin Chung,Jong Chul Ye", "background": "本文提出了Amortized Posterior Sampling (APS)，这是一种用于逆问题高效后验采样的新颖变分推理方法。APM通过训练条件流模型来最小化变分分布和由扩散模型隐式定义的后验分布之间的差异。这种方法产生了一种强大的、可以使用单一神经函数评估生成多样化后采样的固定化采样器，适用于各种测量。这种方法在计算效率和重建质量方面超过了现有的方法，并能够在多样化的领域内实现实时、高质量的逆问题解决方案。", "innovation": "与现有方法不同，APM 是无监督的，不需要配对的训练数据，并且适用于欧几里得和非欧几里得领域。通过使用扩散模型先验蒸馏，该方法能够生成多种后验样本，同时保持高效的计算性能。", "conclusion": "APS在图像恢复、流形信号重建和气候数据插值等多种任务中表现出色。该方法在计算效率方面显著优于现有方法，同时保持了竞争性的重建质量，能够实现实时、高质量的逆问题解决方案，适用于不同领域的应用。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.17285", "html_url": "https://arxiv.org/abs/2403.17285", "title": "探究轮转效应对比奖励自相关性在轮转实验中的相互作用", "title_en": "Unraveling the Interplay between Carryover Effects and Reward Autocorrelations in Switchback Experiments", "authors": "Qianglin Wen,Chengchun Shi,Yang Ying,Niansheng Tang,Hongtu Zhu", "background": "A/B 测试已成为现代技术行业政策评估的黄金标准。由于广泛使用轮转实验这一 A/B 测试方法，本文对马尔可夫环境中不同轮转设计进行了全面的比较分析。", "innovation": "不同于许多现有研究依赖于特定且相对简单的估计器来推导最优设计，本文分析涵盖了强化学习（RL）文献中开发的最新估计器。研究表明，不同轮转设计的有效性取决于:(i)延续效应的大小，(ii)时间序列奖励误差之间的自相关性。这些发现不依赖于具体估计器，适用于大多数 RL 估计器。基于这些洞见，本文提供了一个工作流程，为 A/B 测试中的轮转实验设计提供建议。", "conclusion": "根据这些见解，我们提供了一种工作流程，以供从业者指导在 A/B 测试中设计轮转实验。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10381", "html_url": "https://arxiv.org/abs/2410.10381", "title": "基于非负/二值矩阵分解的协同过滤", "title_en": "Collaborative filtering based on nonnegative/binary matrix factorization", "authors": "Yukino Terui,Yuka Inoue,Yohei Hamakawa,Kosuke Tatsumura,Kazue Kudo", "background": "协同过滤通过利用基于评分数据的用户-项相似性来生成推荐，但这种数据通常包含大量未评分项。以往研究主要将非负/二值矩阵分解(NBMF)应用于密集数据，如图像，而本研究则将修改后的NBMF应用于稀疏数据。", "innovation": "提出了针对协同过滤的非负/二值矩阵分解(NBMF)算法，并使用低延时玻义耳机器在NBMF中进行计算，这在计算时间方面显示出优势。", "conclusion": "结果表明，使用低延时玻义尔机器实施提出的NBMF方法可以带来益处。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.02548", "html_url": "https://arxiv.org/abs/2410.02548", "title": "局部流匹配生成模型", "title_en": "Local Flow Matching Generative Models", "authors": "Chen Xu,Xiuyuan Cheng,Yao Xie", "background": "该论文提出了一种名为Flow Matching (FM)的方法，这是一种不需要模拟过程的连续且可逆的流学习方法，用于在两个分布之间进行插值，并特别用于从噪声中生成数据。受扩散过程作为梯度流的变分性质的启发，论文引入了一种逐步的FM模型，称为局部流匹配（Local Flow Matching，LFM），该模型连续学习一系列用于匹配扩散过程的亚模型，每个子模型都可至数据到噪声方向的时间步数匹配扩散过程。这种方法使得在每一步中插值的分布更接近彼此，而非数据与噪声分布。这使得可以使用更小的模型并加快训练速度。此变分视角还允许通过弥散过程的收缩性质，理论上证明了所提流模型在生成和真实数据分布之间的$χ^2$散度的生成保证。在实践上，LFM的逐步结构使其易于从中提取知识，不同的提取技术可用于加速生成过程。该研究在无条件生成表格数据和图像数据集以及有条件生成机器人操作策略方面，展示了LFM较FM改进了训练效率并具有竞争力的生成性能。", "innovation": "论文介绍了一种逐步的局部流匹配（Local Flow Matching，LFM）模型，这是一种改进了的流匹配方法（Flow Matching，FM）。LFM基于数据到噪声方向的时间步数，连续学习一系列流匹配子模型，使得每一步中插值的分布更接近彼此。这种方法利用了扩散过程的变分性质，通过利用扩散过程的收缩性质，提供了生成模型的理论保证。LFM模型较直接的FM方法具有更快的训练速度和理论上的生成保证。此外，LFM的逐步结构使其易于从中提取知识，以便加速生成过程。在无条件生成表格数据和图像数据集以及有条件生成机器人操作策略方面，展示了LFM相较于FM改进了训练效率并具有竞争力的生成性能", "conclusion": "总的来说，该研究通过引入局部流匹配方法，通过理论和实验证明了LFM在生成模型中的改进。该方法在不需要模拟的情况下学习连续可逆的流，通过与噪声相比的数据到噪声方向的时间步数，逐步真实地匹配流动过程。它们展示了LFM在不同数据集上的优越的训练效率和生成性能。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.02857", "html_url": "https://arxiv.org/abs/2410.02857", "title": "使用评分生成建模重建星系团质量图", "title_en": "Reconstructing Galaxy Cluster Mass Maps using Score-based Generative Modeling", "authors": "Alan Hsu,Matthew Ho,Joyce Lin,Carleen Markey,Michelle Ntampaka,Hy Trac,Barnabás Póczos", "background": "该研究介绍了一种使用评分生成建模方法来重建星系团中气体和暗物质的投影密度图的新方法。研究者利用模拟的太阳中子线（SZ）和X射线图像作为条件输入，并通过从学习到的数据后验中抽样来生成相应的气体和暗物质图。通过使用来自宇宙学模拟的模拟数据进行训练和验证，研究发现模型能够准确重建星系团径向密度剖面的均值和分布，证实该模型能够区分不同质量的星系团，并且在频谱域中，模型能够在大尺度和小尺度上准确地探究星系团的结构，表明模型具有强大的非线性和无偏的学习能力。", "innovation": "该模型使用评分生成建模方法，这是一种新颖的方法，通过从学习到的数据后验中抽样来生成相应的气体和暗物质图。这种方法可以准确地重建星系团的密度分布，并且能够区分不同质量的星系团。研究者还发现，该方法可以进一步微调和泛化，以便接受额外的观测值作为输入，并预测星系团未知的密度分布，这为未来的观测研究提供了新的可能。", "conclusion": "最终实验表明，评分模型学习了输入观测值和星系团基本密度分布之间的强大、非线性和无偏映射关系。这些扩散模型不仅可以接受更多观测值为输入，还可以处理真实观测数据，并预测星系团未知的密度分布。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.15982", "html_url": "https://arxiv.org/abs/2410.15982", "title": "使用稀疏DEIM和循环神经网络进行状态估计", "title_en": "State Estimation Using Sparse DEIM and Recurrent Neural Networks", "authors": "Mohammad Farazmand", "background": "在动力系统中，仅能观测一部分状态变量时，最近提出了稀疏离散经验插值方法（S-DEIM）进行状态估计。然而，S-DEIM的估计过程存在两个问题：一是需要知道系统的动力学方程，二是不保证能够收敛到最优核向量。", "innovation": "引入了一个以循环神经网络（RNN）为核心的空间自由S-DEIM框架，从稀疏观测时间序列中估计最优核向量，而无需了解系统的动力学方程，并且即使使用相对简单的循环计算网络架构，也能实现几乎最优的估计。", "conclusion": "该方法在三个具有不同时空复杂度的数值示例中得到了验证，展示了其效果。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09918", "html_url": "https://arxiv.org/abs/2410.09918", "title": "Dualformer: 通过随机推理轨迹学习实现可控的快慢思维", "title_en": "Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces", "authors": "DiJia Su,Sainbayar Sukhbaatar,Michael Rabbat,Yuandong Tian,Qinqing Zheng", "background": "人类思维被认知理论分为两个系统：直觉快速的系统1和慢速但更仔细的系统2。类似地，大型语言模型（LLMs）可以在两种推理模式中运行：仅输出解决方案（快速模式）或同时输出推理链和最终解决方案（慢速模式）。", "innovation": "提出了一种名为Dualformer的单个Transformer模型，它通过在随机化的推理轨迹上进行训练，无缝结合了快慢两种推理模式。在推理阶段，Dualformer可以根据需要配置为快速、慢速模式或是自动决定模式（称为自适应模式）。在所有三种模式下，Dualformer在性能和计算效率方面均优于基准模型。特别地，在慢速模式下，Dualformer在解不熟悉30×30迷宫任务时达到了97.6%的最佳率，比受完整推理轨迹训练的searchformer基准模型高出45.5%；在快速模式下，Dualformer的最优率为80%，显著优于仅用解决方案数据训练的解决方案模型，后者仅为30%；在自适应模式下，Dualformer达到了96.6%的最优率，比searchformer少用59.9%的步骤。此外，Dualformer生成的推理轨迹比searchformer更具多样性。并且，我们的方法也证明了对数学推理问题进行LLM微调时的改进效果，证明了其在特定任务模型之外的泛化能力。", "conclusion": "Dualformer在所有三种模式下都表现出了出色的性能和计算效率，展示了通过在随机化的推理轨迹上进行训练来实现可控的快慢思维的有效性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.12690", "html_url": "https://arxiv.org/abs/2410.12690", "title": "局部转移学习高斯过程建模及其在昂贵计算机模拟代理建模中的应用", "title_en": "Local transfer learning Gaussian process modeling, with applications to surrogate modeling of expensive computer simulators", "authors": "Xinming Wang,Simon Mak,John Miller,Jianguo Wu", "background": "科学进步的关键瓶颈是复杂系统模拟的高昂成本。代理模型提供了一个吸引人的解决方案：这些模型在模拟器评估上进行训练，然后用于模拟和量化在未探索输入上的昂贵模拟器中的不确定性。在许多应用中，往往可以获得相关系统的数据。例如，在设计新的喷气涡轮机时，可能存在具有相似配置的涡轮机的研究结果。关键问题是如何利用这些“源”系统的信息来有效训练“目标”系统。因此，我们提出了一种新的局部转移学习高斯过程（LOL-GP）模型，该模型利用精心设计的高斯过程来利用这些信息进行代理建模，通过局部转移避免负面效果，提高了代理模型的预测性能。我们对LOL-GP进行了Gibbs采样算法推导，以高效地在多源和多保真度转移设置中进行后验预测采样，展示了LOL-GP相比现有方法在代理模型性能上的改进，特别是在昂贵计算机模拟的应用中。", "innovation": "LOL-GP模型具有局部转移学习特性，通过识别应进行转移和不应进行转移的区域来减少负面转移的风险。我们为多源和多保真度转移设置推导了Gibbs采样算法，以高效地进行后验预测采样，从而提高代理模型的性能。该模型特别适用于昂贵的计算机模拟器的代理建模，在喷气涡轮机设计中展示了其优越性。", "conclusion": "LOL-GP模型显著改善了昂贵计算机模拟器的代理模型性能，通过局部转移学习特性，可以有效地利用源系统信息来训练目标系统，避免负面转移，从而提高预测性能。我们提出了Gibbs采样算法来进行高效的后验预测采样，展示了LOL-GP在各种数值实验和喷气涡轮机设计中的优越性能。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07735", "html_url": "https://arxiv.org/abs/2505.07735", "title": "评估大型语言模型的化学智能", "title_en": "Assessing the Chemical Intelligence of Large Language Models", "authors": "Nicholas T. Runcie,Charlotte M. Deane,Fergus Imrie", "background": "大型语言模型具有多种通用工具的应用范围，在数学和软件工程等复杂问题解决领域表现出色。基于此背景，我们研究了‘推理模型’在化学任务中的直接应用效果，而无需外部工具的帮助。为此，我们开发了一个名为ChemIQ的新基准测试，包含816个问题，评估有机化学中的核心概念，尤其是分子理解和化学推理。这项工作与以往主要采用多项选择题的方法不同，本次研究要求模型构建简答型答案，更接近实际应用。", "innovation": "我们创建了一个名为ChemIQ的新基准测试，并采用了模型构建简答型答案的方法，这与以往的多项选择题方法不同，更贴近实际应用。此外，我们发现最新版本的推理模型在最高等级的推理模式中正确回答了50%-57%的问题，高推理层次显著提升了所有任务的表现。与之相比，非推理模型的准确率仅为3%-7%。这表明大型语言模型现在能够将SMILES字符串转换为IUPAC名称，这是之前模型无法完成的任务。最新的推理模型还能够从一维和二维1H和13C NMR数据中解析结构，Gemini Pro 2.5正确生成了约90%分子的SMILES字符串。", "conclusion": "我们的研究表明，最新的推理模型在某些情况下能够进行高级化学推理。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.11767", "html_url": "https://arxiv.org/abs/2411.11767", "title": "淹没在文档中：扩展排序器推理的后果", "title_en": "Drowning in Documents: Consequences of Scaling Reranker Inference", "authors": "Mathew Jacob,Erik Lindgren,Matei Zaharia,Michael Carbin,Omar Khattab,Andrew Drozdov", "background": "重排序器，通常为交叉编码器，虽然计算密集型，但因普遍认为其能在最初的检索系统上提供更好的性能而被频繁使用。本文挑战了这一假设，通过衡量在完整检索过程中的重排序器性能，而不仅仅是前一阶段检索的重排序，提供了更加稳健的评估。", "innovation": "本文重点强第一阶段检索使用现代密集嵌入，并在精心选择的具有挑战性的任务上测试重排序器，包括公司内部和跨领域的数据集，以避免污染。实验结果显示，现有的最佳重排序器在评分越来越多的文档时，起初提供初始改进，但其效果逐渐减弱，甚至可能在某个限度内降低质量。", "conclusion": "我们希望研究结果能激励未来研究改进重排序领域的方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.20289", "html_url": "https://arxiv.org/abs/2410.20289", "title": "关于贝叶斯加性回归树的高斯过程极限", "title_en": "On the Gaussian process limit of Bayesian Additive Regression Trees", "authors": "Giacomo Petrillo", "background": "贝叶斯加性回归树（BART）是非参数贝叶斯回归技术中的一个新兴方法。BART 是一棵决策树的总和模型，可以被视为提升算法的贝叶斯版本。在机器学习领域，BART 已经取得了显著的进展和应用，特别是在复杂数据建模和预测方面。然而，BART 的无穷多棵树极限与高斯过程回归模型等价的关系虽然已被了解，但尚未被有效利用。因此，有必要对其进行深入研究，以便更好地理解和利用 BART 和高斯过程回归。", "innovation": "本文首次推导并计算了贝叶斯加性回归树的确切先验协方差函数。通过实现无穷多棵树极限的 BART 作为高斯过程回归，得出了相关的模型。此外，研究表明，通过以自然的高斯过程方式调整超参数，高斯过程极限的 BART 可以与标准的 BART 竞争。使用高斯过程替代 BART 的优势在于它可以生成解析似然函数，简化模型构建并避免复杂的 BART MCMC 算法。所提出的方法为理解和开发 BART 和高斯过程回归提供了新的途径。", "conclusion": "本文的研究通过将 BART 实现为高斯过程，为理解 BART 和高斯过程回归提供了新的方法。虽然高斯过程极限的 BART 在固定配置下表现不如标准 BART，但通过正确的超参数调整，它可以与标准的 BART 竞争。高斯过程的先验协方差函数的推导使得简单地建模和绕过复杂 BART MCMC 算法成为可能，这 openness new ways to understand and develop BART and GP regression."}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.01077", "html_url": "https://arxiv.org/abs/2411.01077", "title": "Emoji 攻击：增强针对监管大型语言模型检测的越狱攻击", "title_en": "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection", "authors": "Zhipeng Wei,Yuqi Liu,N. Benjamin Erichson", "background": "现有的大语言模型（LLMs）越狱技术能够引导LLMs生成受限输出，这构成了潜在威胁。为了防御，有人提出使用另一个LLM作为评判模型来评估生成文本的有害性。然而，研究人员发现这些评判LLMs容易受到标记分隔偏差的影响，即分隔符改变分词过程，将单词分割为更小的子单词，这会改变整个序列的嵌入，从而降低检测准确性并使有害内容被错误分类为安全内容。", "innovation": "本文提出了一种新的策略——Emoji 攻击，通过利用标记分隔偏差放大已有的越狱提示。该方法利用上下文学习，在文本评估监管LLMs之前系统地插入表情符号，以引起嵌入扭曲，显著降低检测出不安全内容的可能性。与传统的分隔符不同，表情符号还引入了语义模糊性，使其在此次攻击中特别有效。", "conclusion": "通过在最新的监管LLMs上进行实验，作者证明了Emoji 攻击大幅降低了不安全预测率，绕过了现有的防护措施，突出了对抗大语言模型越狱的安全问题需要进一步研究和改进这一点。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00136", "html_url": "https://arxiv.org/abs/2412.00136", "title": "FonTS: 文字渲染中的字体和风格控制", "title_en": "FonTS: Text Rendering with Typography and Style Controls", "authors": "Wenda Shi,Yiren Song,Dengming Zhang,Jiaming Liu,Xingxing Zou", "background": "视觉文本渲染在现实世界的各种应用中非常普遍，需要仔细选择字体和排版。最近基于扩散变换器（DiT）的文本到图像（T2I）模型在自动执行这些过程方面表现出希望。然而，这些方法仍然存在诸如字体一致性不均、风格变化和有限的细粒度控制等问题，尤其是在单词级别。本文提出了一个两阶段的DiT基线管道来解决这些问题，通过增强在文字渲染中的字体和风格调控。", "innovation": "本文引入了字体控制微调（TC-FT），这是一种参数高效的方法（对关键参数进行5%的微调），并包含字体控制标记（ETC-tokens），这使得能够精确地在单词级别应用排版特征。为了进一步解决文字渲染中的风格不一致性问题，本文提出了一种独立于文本的风格控制适配器（SCA），它可以防止内容泄漏的同时增强风格一致性。为了有效地实施TC-FT和SCA，作者将HTML渲染集成到数据合成管道中，并提出了第一个单词级别的可控数据集。", "conclusion": "通过全面的实验，我们展示了我们的方法在文字渲染任务中实现更出色的字体控制、字体一致性以及风格一致性方面的有效性。该数据集和模型将可供学术界使用。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.19334", "html_url": "https://arxiv.org/abs/2501.19334", "title": "识别最弱势群体中的预测价值", "title_en": "The Value of Prediction in Identifying the Worst-Off", "authors": "Unai Fischer-Abaigar,Christoph Kern,Juan Carlos Perdomo", "background": "机器学习在政府项目中的应用越来越广泛，用于识别和支持最脆弱的个体，并优先确保最需要帮助的人获得支持。本文探讨了在注重公平性的政策背景下，预测对福利的影响及其与其他政策杠杆（如扩大官僚机构能力）的比较。", "innovation": "通过数学模型和对德国居民长期失业的实地案例研究，本文开发了一个全面理解预测在揭示最脆弱群体方面的相对有效性框架。研究成果提供了一种明确的分析框架和实用的数据驱动工具，助力决策者在设计此类系统时做出基于原则的决策。", "conclusion": "本文的研究结果为决策者提供了清晰的分析框架和实际的数据驱动工具，使他们在设计预测系统时能够做出基于原则的决策。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.14371", "html_url": "https://arxiv.org/abs/2412.14371", "title": "SEREP: 语义面部表情表示以实现鲁棒的野外捕捉和重新定位", "title_en": "SEREP: Semantic Facial Expression Representation for Robust In-the-Wild Capture and Retargeting", "authors": "Arthur Josi,Luiz Gustavo Hafemann,Abdallah Dib,Emeline Got,Rafael M. O. Cruz,Marc-Andre Carbonneau", "background": "单目面部表情捕捉在自然场景中具有挑战性，因为存在多种捕捉条件、面部形状和表情。大多数现有方法依赖于线性3D形态可变模型，这些模型在顶点位移级别上独立表示面部表情，而不考虑身份。", "innovation": "提出了一种名为SEREP（语义表情表示）的模型，该模型在语义级别上将表情与身份分离。首先从高质量未配对面部表情的3D数据中学习表情表示，然后训练一个模型以依赖于一种新颖的半监督方案（该方案利用低质量合成数据）从单目图像预测表情。另外，引入了MultiREX基准，以解决表情捕捉任务评估资源的缺乏。", "conclusion": "实验表明，SEREP优于现有方法，能够捕捉复杂的面部表情并将其转移到新的身份上。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.02482", "html_url": "https://arxiv.org/abs/2412.02482", "title": "神经元应追求什么？基于信息论设计局部目标函数", "title_en": "What should a neuron aim for? Designing local objective functions based on information theory", "authors": "Andreas C. Schneider,Valentin Neuhaus,David A. Ehrlich,Abdullah Makkeh,Alexander S. Ecker,Viola Priesemann,Michael Wibral", "background": "现代深度神经网络中，单个神经元的学习动态往往模糊不清，因为这些网络是通过全局优化进行训练的。相反，生物系统依赖自组织的局部学习机制，通过有限的全局信息实现稳健性和高效性。本研究探索了如何通过设计受生物启发的局部学习目标来实现人工神经元之间的自组织。这些目标利用信息论的一个扩展——部分信息分解(PID)，将多个信息源对于结果持有的信息分解为独特的、冗余的和协同的贡献。这种方法使神经元能够局部控制来自不同输入类别的信息整合方式，包括前馈、反馈和横向输入，选择特定的输入贡献形式（独特、冗余或协同）以优化输出。", "innovation": "该研究通过利用信息论中的部分信息分解(PID)，设计了一种基于局部学习目标的框架，使人工神经元能够根据任务需求自组织地协调信息整合方式。这种方法不仅提升了神经元的局部可解释性，而且能够通过局部学习策略达到强大的性能。此外，研究人员可以直接通过直觉推理或数值优化获取PID项的权重，这为理解与任务相关的信息处理过程提供了一个新的视角。", "conclusion": "本工作为局部学习策略提供了一个严格的信息论基础，实现了神经元级别的可解释性的同时保持了高性能，推动了局部学习领域的基本原则发展。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.04196", "html_url": "https://arxiv.org/abs/2507.04196", "title": "使用机器学习在爱尔兰科克预测空气污染", "title_en": "Predicting Air Pollution in Cork, Ireland Using Machine Learning", "authors": "Md Rashidunnabi,Fahmida Faiza Ananna,Kailash Hambarde,Bruno Gabriel Nascimento Andrade,Dean Venables,Hugo Proenca", "background": "全球城市中空气污染构成了严重的健康威胁，特别是爱尔兰科克市，其氮氧化物水平最高超出世界卫生组织安全标准278%。本文通过利用人工智能提高空气质量预测的准确性，分析了超过十年的五监测站数据和三十年的气象记录，旨在识别空气污染的主要驱动因素。", "innovation": "本文通过机器学习算法研究了空气污染预测方法，最终确定了最佳的Extra Trees模型，预测准确率达到77%，显著优于传统预测方法。研究还发现，天气条件（尤其是温度、风速和湿度）是影响空气质量的主要因素，而交通模式和季节变化则决定了可预测的污染周期。", "conclusion": "研究展示了智能预测系统的强大功能，能够为城市规划者和环境官员提供预报工具，有助于早期警告系统和有效的城市规划决策。当前的技术足以彻底改变城市空气质量的管理。所有研究资料和代码均可在此免费获取：this https URL。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.09686", "html_url": "https://arxiv.org/abs/2411.09686", "title": "非线性单变量条件回归", "title_en": "Conditional regression for the Nonlinear Single-Variable Model", "authors": "Yantao Wu,Mauro Maggioni", "background": "在高维度空间 $\boldsymbol{\text{R}}^d$ 上回归函数 $F$ 而不遇到统计和计算的维数灾难，需要特殊的统计模型。这些模型通常通过几何假设、强光滑性假设或特定结构来降低维度。具体模型之一是将 $F=\text{f} \bigcirc \text{g}$ 的形式，其中 $\text{g}$ 映射到 $\boldsymbol{\text{R}}^r$ 且 $r$ 远小于 $d$。这类模型涵盖了单指标模型和多指标模型，以及神经网络。对于 $\text{g}$ 线性的情形已经较为理解，但对于 $\text{g}$ 非线性的部分尤其是如何绕过维数灾难还不清楚，特别是在估计 $F$ 以及 $\text{f}$ 和 $\text{g}$ 的情况下。本文考虑了一种模型 $F(X) := f(\text{P}_{\boldsymbol{\theta}}X)$，其中 $\text{P}_{\boldsymbol{\theta}}$ 为投影至曲线 $\boldsymbol{\theta}$ 参数的最近点投影，输入数据 $X$ 可以与 $\boldsymbol{\theta}$ 远离，且 $\boldsymbol{\theta}$、数据分布以及函数 $f$ 未知。该模型是一种自然的非线性单变量模型的推广，当 $\boldsymbol{\theta}$ 为直线时对应单指标模型。", "innovation": "文章提出了一种基于条件回归的非参数估计方法。在适当假设下（尤其是 $f$ 的粗略单调性），该方法可以在对数因子内的意义上达到单变量非参数回归的最佳最坏情况速率，并且构造时间复杂度为 $\text{O}(d^2 n \text{ log } n)$。学习误差界、样本数量的下限以及计算复杂度中的所有常数项最多为 $d$ 的低阶多项式。", "conclusion": "研究结果表明，对于 $\text{F}(X) := f(\text{P}_{\boldsymbol{\theta}}X)$ 这样的模型，即使输入数据 $X$ 不是低维的，并且 $\boldsymbol{\theta}$、数据分布以及函数 $f$ 都未知的情况下，通过基于条件回归的非参数估计方法也可以达到接近最优的估计效果，并且具有高效的时间复杂度。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08202", "html_url": "https://arxiv.org/abs/2501.08202", "title": "使用非线性动力学的二次嵌入进行数据驱动的系统识别", "title_en": "Data-driven system identification using quadratic embeddings of nonlinear dynamics", "authors": "Stefan Klus,Joel-Pascal Ntwali N'konzi", "background": "本文基于已有研究如SINDy（稀疏识别非线性动力学）和深度学习方法进展，提出了一种新颖的数据驱动方法QENDy（二次嵌入非线性动力学），用于学习高度非线性动力系统，并识别其支配方程。该方法将系统嵌入到一个更高的特征空间，在此空间中动力学表现出二次特性。该研究展示了QENDy在各种基准问题上的有效性和准确性，并将其性能与SINDy和基于Koopman算子线性化技术的深度学习方法进行了比较。此外，本文还分析了QENDy和SINDy在无穷大数据量极限下的收敛性，并讨论了两者之间的相似性和主要差异。", "innovation": "本文的主要创新在于提出了一种能够学习高度非线性动力系统二次表示的新方法QENDy，并在此基础上挖掘动力系统的支配方程，此方法基于将系统嵌入更高维特征空间从而让动力学呈现为二次特性。QENDy需要轨迹数据、时间和数据点的导数，并且可以通过有限差分逼近计算。该方法还能够与SINDy和基于Koopman算子的线性化技术进行比较。方法的有效性和准确性在多种基准问题上得到了验证。", "conclusion": "本文通过QENDy展示了在识别非线性动力学系统方面的有效性，并与现有的SINDy和基于Koopman算子的线性化技术进行了比较。进一步分析了QENDy和SINDy在无穷大数据量下的收敛性，指出了两者之间的相似性和不同点，并强调了二次嵌入与线性化技术的比较。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02494", "html_url": "https://arxiv.org/abs/2503.02494", "title": "通过Wasserstein距离增强主成分分析的分布鲁棒性", "title_en": "Enhancing Distributional Robustness in Principal Component Analysis by Wasserstein Distances", "authors": "Lei Wang,Xin Liu,Xiaojun Chen", "background": "这篇论文考虑了主成分分析（PCA）的分布鲁棒优化（DRO）模型，以应对基础概率分布的不确定性。由此得到的优化问题是非光滑的约束最优化问题，其中的不确定性集通过类型-2 Wasserstein距离来捕捉。", "innovation": "提出了一个高效的光滑流形近似梯度算法，用于解决该优化问题。该算法通过对原DRO模型进行Riemannian梯度一致性分析，并证明了全局收敛至非光滑极小化问题的驻点。此外，该算法的迭代复杂度为$O(\frac{1}{\text{ε}^3})$，用于达到ε-近似驻点。", "conclusion": "最终，进行了数值实验来验证算法的有效性和扩展性，并强调了采用DRO模型进行PCA的必要性和合理性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01163", "html_url": "https://arxiv.org/abs/2503.01163", "title": "基于工具选择的提示设计策略改进提示优化器", "title_en": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers", "authors": "Rin Ashizawa,Yoichi Hirose,Nozomu Yoshinari,Kento Uchida,Shinichi Shirakawa", "background": "提示优化的目标是在大型语言模型（LLMs）中寻找有效的提示，以提升其性能。现有提示优化方法虽然发现了一些有效的提示，但这些提示通常与人类专家精心设计的复杂提示不同。提示设计策略代表了提升提示性能的最佳实践，对提示优化至关重要。最近，一个名为APET的工具将多种提示设计策略整合到提示优化过程中，但在APET中，LLM需要隐式选择和应用适当的策略，因为提示设计策略可能具有负面影响。这种隐式选择可能由于LLMs的优化能力有限而不理想。", "innovation": "本文提出了Optimizing Prompts with Strategy Selection（OPTS），该方法实现了一个明确选择提示设计策略的机制。文章提出了三种机制，其中包括基于Thompson采样的方法，并将这些机制集成到了EvoPrompt（一个已知的提示优化器）中。研究结果表明，选择提示设计策略能够改善EvoPrompt的表现，并且基于Thompson采样的方法取得了最佳的整体表现。", "conclusion": "通过实验优化了两种LLM（Llama-3-8B-Instruct和GPT-4o mini）的提示，在BIG-Bench Hard上，研究结果表明选择提示设计策略可以提升EvoPrompt的性能，基于Thompson采样的机制表现最优。实验代码可在指定网址找到。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07532", "html_url": "https://arxiv.org/abs/2507.07532", "title": "神经概念验证器：通过概念编码扩展证明者-验证者游戏", "title_en": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings", "authors": "Berkant Turan,Suhrab Asadulla,David Steinmann,Wolfgang Stammer,Sebastian Pokutta", "background": "尽管证明者-验证者游戏（PVGs）为非线性分类模型中的验证性提供了前景，但它们尚未应用于复杂的输入，如高维图像。相比之下，概念瓶颈模型（CBMs）能够将此类数据翻译成可解释的概念，但依赖于低容量的线性预测器，这限制了它们的表现。", "innovation": "本文引入了神经概念验证器（NCV），这是一种结合PVGs和概念编码的统一框架，能够在高维环境中实现可解释的非线性分类。NCV通过使用最近的弱监督概念发现模型从原始输入中提取结构化概念编码，然后由证明者选择一个子集，验证者使用这些编码作为决策依据。该框架在高维、逻辑上复杂的数据集上优于基于像素的PVG分类器基准和CBM，有助于减轻捷径行为。", "conclusion": "我们展示了NCV作为一个朝向执行性验证性AI的重要步骤。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.11924", "html_url": "https://arxiv.org/abs/2503.11924", "title": "REGEN: 一个包含自然语言批评和叙述的语料库和基准", "title_en": "REGEN: A Dataset and Benchmarks with Natural Language Critiques and Narratives", "authors": "Kun Su,Krishna Sayana,Hubert Pham,James Pine,Yuri Vasilevski,Raghavendra Vasudeva,Marialena Kyriakidi,Liam Hebert,Ambarish Jash,Anushya Subbiah,Sukhdeep Sodhi", "background": "现有的推荐大型语言模型（LLMs）数据集主要关注顺序项目预测，缺乏评估模型对话能力的标准。REGEN通过添加用户批评和叙述丰富了亚马逊产品评论数据集，旨在解决这一问题。", "innovation": "REGEN数据集通过填补用户批评和叙述两个关键自然语言特征，扩展了亚马逊产品评论数据集，并提出了一种新的统一多任务建模框架LUMEN（基于LLM的联合建模框架）来生成推荐和相应叙述，推进了对话推荐任务的建模基准。", "conclusion": "研究表明，融合用户批评可以提高推荐质量，使其能够学习语言理解和与推荐信号相结合。此外，基于REGEN训练的LLMs能够有效地生成推荐和上下文叙述，性能达到业界领先水平。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04518", "html_url": "https://arxiv.org/abs/2503.04518", "title": "利用分布函数先验对多臂bandit问题进行建模", "title_en": "Leveraging priors on distribution functions for multi-arm bandits", "authors": "Sumit Vashishtha,Odalric-Ambrym Maillard", "background": "该研究基于Dirichlet过程（DP）先验提出了一种贝叶斯非参数算法——Dirichlet Process Posterior Sampling（DPPS），用于解决多臂bandit问题。这种方法借鉴了Thompson采样算法的思路，但与传统的基于特定参数类的方法不同，DPPS直接利用Dirichlet过程先验对奖赏生成分布进行建模。这种算法能够无缝地融入关于bandit环境的先验信念，并在Dirichlet过程后验的非信息性极限情况下（即贝叶斯置信抽样），等同于非参数Thompson采样（NPTS），展示了在这种设置下的优越性能。最后，通过信息论分析证明了DPPS在贝叶斯后悔设置下的非渐进最优性。", "innovation": "DPPS利用Dirichlet过程先验直接建模奖励生成分布，不再假设特定的参数类，而是通过其后验概率选择臂。这种方法提供了一种有原则的方式来融入关于bandit环境的先验信念，在非信息性极限条件下，可以恢复NPTS作为一种特殊情况。并且DPPS在信息理论分析下展示了非渐进最优性。", "conclusion": "DPPS提供了一种处理多臂bandit问题的有效方法，能够无缝地融入关于bandit环境的先验信念，并且在贝叶斯后悔设置下展示了非渐进最优性。该方法在合成和实际bandit环境中表现出色，具有广泛的应用前景。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08311", "html_url": "https://arxiv.org/abs/2503.08311", "title": "关注内存差距：揭示大规模批次语言模型推理的GPU瓶颈", "title_en": "Mind the Memory Gap: Unveiling GPU Bottlenecks in Large-Batch LLM Inference", "authors": "Pol G. Recasens,Ferran Agullo,Yue Zhu,Chen Wang,Eun Kyung Lee,Olivier Tardieu,Jordi Torres,Josep Ll. Berral", "background": "大型语言模型已经广泛应用于不同的任务，但由于其自回归生成的特性，在推理过程中资源利用率较低。虽然批量处理通常用于提高吞吐量，但性能提升在达到某一批处理大小后会停滞，特别是在小型模型中更为明显。现有文献通常将这种现象解释为进入计算受限的阶段。研究通过深入的GPU层分析发现，大规模批处理推理仍然是内存限制的，原因是由于内存带宽饱和，导致GPU计算能力大部分未充分利用。针对此问题，提出了一种批处理配置顾问（BCA），通过优化内存分配，减少GPU内存需求，同时对吞吐量影响最小。释放出的内存及未充分利用的GPU计算能力可以被并发工作负载利用。通过模型复现来提高服务吞吐量和GPU利用率。这些发现挑战了关于语言模型推理的传统假设，提供了提高资源利用的新见解和实用策略，特别是对于小型语言模型而言。", "innovation": "提出了一种批处理配置顾问（BCA），它通过优化内存分配减少GPU内存需求，同时不对吞吐量产生重大影响。利用模型复现来提高服务吞吐量和GPU利用率。这种策略挑战了现有文献对语言模型推理的解释，并提供了新的优化方案。代码已公开，可访问此链接：this https URL.", "conclusion": "研究成果挑战了关于语言模型推理的常规假设，提供了新的见解和实用的资源利用率提升策略，特别适用于小型语言模型。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09832", "html_url": "https://arxiv.org/abs/2502.09832", "title": "低度猜想下的算法连续性及其在相关随机图中的应用", "title_en": "Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs", "authors": "Zhangsong Li", "background": "本文基于自然强化的低度猜想，为两种问题提供了计算性硬度的证据：1）在稀疏相关Erdős-Rényi图$\textbf{G}(n,q;\rho)$中，边密度$q=n^{-1+o(1)}$且相关性$\rho<\text{Otter's 临界值}$时，部分匹配恢复问题的硬度证据；2）在相关稀疏块模型$\textbf{S}(n,\frac{\text{λ}}{n};k,\text{ε},s)$与独立块模型$\textbf{S}(n,\frac{\text{λs}}{n};k,\text{ε})$之间区分问题的硬度证据，其中$\text{ε}^2\text{λs}<1$且$s<\text{Otter's 临界值}$。这些结果解决了之前研究中遗留的问题。", "innovation": "本文的主要创新在于证明过程中使用了一种新的形式的算法连续性。具体来说，通过基于其低度优势的两概率测度的边界，我们提出了一种框架，显示出如果低度优势$\text{Adv}_{\text{≤} D} \big( \frac{\text{d}\textbf{P}}{\text{d}\textbf{Q}} \big)=O(1)$，在假设低度猜想的情况下，没有高效的算法$\textbf{A}$能够使得$\textbf{Q}(\textbf{A}(Y)=0)=1-o(1)$且$\textbf{P}(\textbf{A}(Y)=1)=\textbf{Ω}(1)$。", "conclusion": "本文提供了一种用于不同推理任务之间进行归约的有效工具，并通过低度猜想和相关的高维假设检验问题中的变化优势边界得出了算法连续性的形式。这对稀疏相关随机图中的匹配恢复和区分问题提供了计算性硬度的新证据。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08893", "html_url": "https://arxiv.org/abs/2503.08893", "title": "EvalTree：通过层次能力树分析语言模型的弱点", "title_en": "EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees", "authors": "Zhiyuan Zeng,Yizhong Wang,Hannaneh Hajishirzi,Pang Wei Koh", "background": "理想的模型评估应实现两个目标：识别模型的失败点并提供可操作的改进指导。针对语言模型评估的这一目标，作者将问题定义为给定基准中每个实例的语言模型性能，生成一整套以自然语言表达的弱点描述。为了比较不同的弱点评估方法，作者引入了一系列定量评估方法，并开发了一个名为EvalTree的新方法，该方法构建了层次能力树，每一节点代表一种用自然语言描述的能力，并与基准中的部分实例相关联，以便专门评估该能力；通过评估节点中LM的表现不佳之处来生成弱点描述。在MATH和WildChat基准上，EvalTree方法比基础方法在准确定位和全面识别弱点方面表现出色。弱点分析进一步促进了根据由EvalTree识别的弱点指导的数据收集，使用由EvalTree方法识别的弱点指导的数据收集策略比其他策略提高了语言模型的性能。此外，评课还展示了Chatbot Arena 基于人工投票的评估实践中的缺陷。为了未来研究提供便利，作者提供了交互工具使得实践者可以探索EvalTree构建的能力树。", "innovation": "作者提出了一种名为EvalTree的新方法，通过构建层次能力树来生成语言模型的弱点描述。EvalTree不仅可以准确识别和全面评估弱点，还能引导数据收集，从而提高数据质量，进而提高语言模型的性能。此外，它还能揭示现有的模型评估方法中存在的问题。", "conclusion": "EvalTree方法在MATH和WildChat基准中表现突出，能够精确、全面地识别语言模型的弱点。该方法还展示了对数据收集过程的指导作用，提高了数据质量，进而提升了模型的性能。此外，EvalTree揭示了现有评估实践存在的问题。作为一种新的评估方法，EvalTree为未来研究提供了便利，提供了交互工具让实践者可以探索能力树。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17546", "html_url": "https://arxiv.org/abs/2503.17546", "title": "Kuramoto模型中的社区：通过路径签名进行动力学与检测", "title_en": "Communities in the Kuramoto Model: Dynamics and Detection via Path Signatures", "authors": "Tâm Johan Nguyên,Darrick Lee,Bernadette Jana Stolz", "background": "多变量动力过程的行为通常由系统组件之间的潜在结构性连接驱动。现有方法如基于相关性或频谱的技术，可能无法充分捕捉高维度时间序列中的复杂关系。路径签名作为一种数学框架，能够编码连续路径的空间和时间属性，被提出用以解决此问题。通过路径签名计算的领导矩阵揭示了领导滞后现象。本研究使用路径签名在Kuramoto随机块模型上展示该方法，利用_mean-field_理论和高斯近似获得不同时间阶段的简化模型，并理论地描述了领导矩阵在这些条件下的表现。", "innovation": "提出了将路径签名应用于社区检测的新算法，实现了在多个Kuramoto随机块模型实例中从观测时间序列中精确恢复结构社区。进一步研究该方法在一个随机变体的Kuramoto随机块模型以及真实的微电极阵列记录的皮层活动中性能，展示了其在实际数据中的应用。", "conclusion": "路径签名为分析复杂神经数据和其他高维系统提供了新视角，它们明确利用时间和功能关系来推断潜在结构。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11436", "html_url": "https://arxiv.org/abs/2504.11436", "title": "使用生成型人工智能转变工作模式", "title_en": "Shifting Work Patterns with Generative AI", "authors": "Eleanor Wiske Dillon,Sonia Jaffe,Nicole Immorlica,Christopher T. Stanton", "background": "本文通过一项为期6个月、跨行业的随机现场实验，基于7,137名工人的数据，探讨了生成型人工智能如何改变知识工作者的工作模式。", "innovation": "研究采用了一项随机现场实验，将生成型AI工具整合到员工常用的电子邮件、文档创建和会议应用中，探究该工具对工作模式的影响。", "conclusion": "研究发现，该工具在一年内的使用主要影响了可以独立改变的行为，而不需要协调改变的行为未受影响。具体而言，样本中超过一半时间使用工具的员工每周减少了3.6小时，即减少31%的电子邮件时间（意向治疗估计为1.3小时），并能够更快速地完成文档，但并没有显著改变会议时间。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02870", "html_url": "https://arxiv.org/abs/2503.02870", "title": "基于代理组的多准确性与多校准", "title_en": "Multiaccuracy and Multicalibration via Proxy Groups", "authors": "Beepul Bharti,Mary Versa Clemens-Sewall,Paul H. Yi,Jeremias Sulam", "background": "随着预测机器学习算法在高风险决策中的应用增加，确保这些算法在不同敏感群体之间的公平性变得至关重要。然而，在实际应用中衡量和维护公平性可能会很困难，因为敏感群体数据可能存在缺失或不完整的情况。提出了代理敏感属性作为一种实用且有效的方法来解决这些问题，但只能应用于基于平等性的公平观念。对于新型、不同的和更灵活的框架，例如多准确性与多校准，如何评估和控制公平性问题依然未被研究。本文旨在解决这一问题，通过证明在缺乏敏感群体数据的情况下，代理敏感属性可以用来推导实际的多准确性与多校准的上限，从而为预测模型的潜在最坏情况公平性违规提供见解。此外，本文展示了调整模型以满足代理敏感属性的多准确性与多校准可以显著减轻这些违规行为，即使对于未被识别的真实敏感群体来说也是如此。通过一系列对实际数据集的实验，本文展示了即使在敏感群体数据不完整或不可用的情况下，近似的多准确性与多校准也可以实现。", "innovation": "本文创新地点在于它证明了在缺乏敏感群体数据的情况下，可以使用代理敏感属性来推导实际的多准确性与多校准的上限，这对于预测模型的潜在最坏情况公平性违规提供了见解。此外，本文展示了调整模型以满足代理敏感属性的多准确性与多校准可以显著减轻这些违规行为，即使对于未被识别的真实敏感群体来说也是如此。这种研究填补了对新型公平性框架（如多准确性与多校准）的研究空白。", "conclusion": "本文通过证明在缺乏敏感群体数据的情况下，可以使用代理敏感属性来推导实际的多准确性与多校准的上限，为预测模型的潜在最坏情况公平性违规提供了见解。此外，本文展示了调整模型以满足代理敏感属性的多准确性与多校准可以显著减轻这些违规行为，即使对于未被识别的真实敏感群体来说也是如此。通过一系列对实际数据集的实验，本文展示了即使在敏感群体数据不完整或不可用的情况下，近似的多准确性与多校准也可以实现。这些发现为在使用代理敏感属性来衡量和控制公平性方面提供了新的视角，特别是在实际应用存在缺失或不完整敏感群体数据的情况下。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.22589", "html_url": "https://arxiv.org/abs/2503.22589", "title": "使用AI总结1952-2012年美国总统竞选电视广告视频", "title_en": "Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012", "authors": "Adam Breuer,Bryce J. Dietrich,Michael H. Crespin,Matthew Butler,J.A. Pryse,Kosuke Imai", "background": "截至目前，对美国总统竞选广告的兴趣非常浓厚，但由于手动收集和标注的需要，大多数研究者都依赖于较小的数据集。本文介绍了一个包含最多和最全面的美国总统竞选电视广告数据集，该数据集已数字化，并提供了可搜索的转录和高质量的摘要，便于多种学术研究。截至目前，研究者依赖于人工采购和标注，导致数据集较小，限制了研究的广度和深度。", "innovation": "本文设计了一个大规模的并行人工智能分析管道，自动化的准备、转录和摘要视频的过程。作者将其应用于久治·P·卡纳特政治商业档案中的9,707个总统广告。通过广泛的真人评估，证明了这些转录和摘要的质量与手动生成的相比无差异。该研究还展示了如何使用基于LLM的工具来获取其他视频数据集的高质量摘要，并通过跟踪当前焦点议题的发展来展示数据价值，涵盖了七十年的总统选举。", "conclusion": "本文分析管道和代码库展示了如何使用基于LLM的工具来获取其他视频数据集的高质量摘要，丰富了研究方法，提高了数据收集的效率和深度，为后续研究提供了广阔的可能性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06897", "html_url": "https://arxiv.org/abs/2504.06897", "title": "MedSegFactory：文本引导的医学图像-掩码对生成", "title_en": "MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs", "authors": "Jiawei Mao,Yuhan Wang,Yucheng Tang,Daguang Xu,Kang Wang,Yang Yang,Zongwei Zhou,Yuyin Zhou", "background": "当前医学成像领域面临数据稀缺和监管限制的问题，现有的医学成像数据生成方法无法满足多样性和高质量数据的需求。这限制了医学影像分割工具的发展和应用。本文旨在解决这些问题，并提出了一种新的医学图像合成框架，以提高医学成像流程的效率和准确性。", "innovation": "本文引入了MedSegFactory，这是一种多功能的医学合成框架，能够生成高质量的跨模态和任务配对的医学图像和分割掩码。其核心是双流扩散模型，其中一条流合成医学图像，另一条流生成相应的分割掩码。进一步引入了Joint Cross-Attention (JCA)，实现双向交互的去噪方式，确保图像-掩码对之间的精确对齐。此外，用户可以通过自定义提示来生成所需的医学图像和分割掩码，包括指定目标标签、成像模态、解剖区域和病理条件，从而实现可扩展且高质量的数据生成。这项新的医学图像合成范式能够无缝集成到多种医学影像处理流程中，提升效率和准确性。", "conclusion": "实验结果表明，MedSegFactory生成的数据质量高且实用性好，在2D和3D分割任务中实现了竞争性的或最先进的性能，同时解决了数据稀缺和监管约束的问题。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06311", "html_url": "https://arxiv.org/abs/2506.06311", "title": "GPR数据与DNN集成中的新型形状感知拓扑表示", "title_en": "A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration", "authors": "Meiyan Kang,Shizuo Kaji,Sang-Yun Lee,Taegon Kim,Hee-Hwan Ryu,Suyoung Choi", "background": "地面穿透雷达(GPR)是一种广泛应用于基础设施检测和维护的非破坏性测试技术。然而，传统的解释方法常受限于噪声敏感性和结构意识不足。本文提出了一种新的框架，通过将基于B扫描GPR图像的拓扑数据分析(TDA)获得的形状感知拓扑特征与YOLOv5深度神经网络的空间检测能力相结合，提升了地下管道等设施的检测能力。", "innovation": "本文提出了一种新颖的形状感知拓扑表示方法，增强了输入数据中的结构特征，提高了模型对埋藏物体几何特征的响应能力。通过采用Sim2Real策略，生成多样的真实模拟数据集，有效地弥合了模拟与现实世界之间的鸿沟。", "conclusion": "实验结果表明，该方法在平均精确度（mAP）上有显著提高，验证了TDA增强学习在可靠、实时地下物体检测中的潜力，具有广泛的城市规划、安全检查和基础设施管理应用前景。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01635", "html_url": "https://arxiv.org/abs/2506.01635", "title": "黎曼时间扭曲：曲面中的多个序列对齐", "title_en": "Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces", "authors": "Julian Richter,Christopher Erdös,Christian Scheurer,Jochen J. Steil,Niels Dehio", "background": "多信号在时间上的对齐通过时间扭曲是很多领域中的关键问题，例如语音识别中的分类或机器人运动学习。大多数相关研究仅限于欧几里得空间中的数据。尽管在2011年尝试将此概念扩展到单位四元数上，但这一方法没有一般地扩展到黎曼流形。鉴于其在多个机器人应用中的重要性，研究人员引入了黎曼时间扭曲（RTW）。", "innovation": "RTW是一种新颖的方法，它通过考虑嵌入数据的黎曼流形的几何结构来高效地对齐多个信号。与现有最佳基线相比，在合成数据和真实数据（包括一个LBR iiwa机器人测试）上的实验证明了其在平均和分类任务中的一贯优越性。", "conclusion": "RTW方法在黎曼流形上实现了对齐，这适用于各类实际应用。实验表明该方法在处理信号对齐任务时优于现有技术。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18397", "html_url": "https://arxiv.org/abs/2505.18397", "title": "关于多智能体人工智能系统机遇与挑战的展望", "title_en": "An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems", "authors": "Fangqiao Tian,An Luo,Jin Du,Xun Xian,Robert Specht,Ganghua Wang,Xuan Bi,Jiawei Zhou,Ashish Kundu,Jayanth Srinivasa,Charles Fleming,Rui Zhang,Zirui Liu,Mingyi Hong,Jie Ding", "background": "多智能体AI系统（MAS）由多个自主智能体组成，这些智能体可以相互交互，交换信息，并基于内部生成模型进行决策。近年来，大型语言模型和工具使用AI的发展使MAS在科学发现和协作自动化等领域变得越来越实用。然而，仍然存在一些关键问题：在什么情况下MAS比单智能体系统更有效？智能体之间的交互会产生哪些新的安全风险？我们应该如何评估他们的可靠性和结构？", "innovation": "本文提出了一种正式框架来分析MAS，重点关注两个核心方面：有效性和安全性。研究MAS是否真的提高了鲁棒性、适应性和性能，还是仅仅重新打包了诸如集成学习等已知技术。还研究了智能体间的动态可能会如何放大或抑制系统漏洞。此外，MAS对于信号处理社区来说是相对较新的，本文设想它们作为一种强大的抽象方式，将分布式估计和传感器融合等经典工具拓展到更高层次、基于政策的推断中。通过数据科学自动化实验，强调了MAS重新塑造信号处理系统设计和信任的潜力。", "conclusion": "本文通过实验展示了MAS在数据科学自动化中的潜在应用，指出MAS有潜力改变信号处理系统的设计和信任方式，同时也探讨了它们的有效性、安全性和潜在风险。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09874", "html_url": "https://arxiv.org/abs/2506.09874", "title": "UmbraTTS：通过流动匹配适应环境背景的文本到语音", "title_en": "UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching", "authors": "Neta Glazer,Aviv Navon,Yael Segal,Aviv Shamsian,Hilit Segev,Asaf Buchnick,Menachem Pirchi,Gil Hetz,Joseph Keshet", "background": "最近的文本到语音（TTS）进展已经实现了高度自然的语音合成，但将语音与复杂的背景环境结合仍然充满挑战。现有模型难以生成既自然又与环境保持一致的音频场景。这主要是因为缺乏声音和背景音频在自然环境中对齐的数据。", "innovation": "本文介绍了一种名为UmbraTTS的流动匹配为基础的TTS模型，能够在给定文本和声学上下文的情况下，联合生成语音和环境音频。该模型具有对背景音量的细粒度控制，并能创建多样、一致且具有上下文意识的音频场景。为了克服缺乏配对训练数据的挑战，提出了一个自我监督的框架，能够从未标注的录音中提取语音、背景音频和转录文本。实验结果表明，UmbraTTS在自然度和环境适应性方面显著优于现有基线。", "conclusion": "UmbraTTS在大规模评估中表现出色，不仅生成了高质、自然的音频，还能生成与环境相关的音频场景。该研究为解决文本到语音建模中的环境挑战提供了新的方法。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08033", "html_url": "https://arxiv.org/abs/2506.08033", "title": "基于光谱参与气体的二维炉膛辐射传热中CNN和MLP的可行性研究", "title_en": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases", "authors": "Axel TahmasebiMoradi,Vincent Ren,Benjamin Le-Creurer,Chetra Mang,Mouadh Yagoubi", "background": "为了降低数值模拟的计算成本，本文旨在引入卷积神经网络（CNN）和多层感知器（MLP）来构建一个代理模型，以逼近在含有参与气体的封闭2D域中的辐射传热解。与传统的求解器相比，通过优化超参数，使用CNN和MLP能够显著提高速度并保持可接受的相对误差，同时CNN在精度上优于MLP并且更稳定。", "innovation": "本文的创新之处在于将气体和壁面的属性作为CNN的输入，这通常用于图像处理，显示了CNN在辐射传热问题上的新颖应用。利用Optuna优化，两个模型都以最佳超参数进行了验证，结果表明，与传统的解算器相比，新的代理模型在性能上取得了显著提高，特别是在精度和稳定性方面，CNN模型表现更佳。", "conclusion": "通过使用代理模型，在2D炉膛中模拟参与气体的辐射传热具有可行性，并且与传统的求解器相比，这两种模型都能显著提高计算速度，同时保持了相当高的精度。在不同的数据集大小下，CNN表现出更强的性能和稳定性，这是该研究的一个重要发现。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14123", "html_url": "https://arxiv.org/abs/2506.14123", "title": "逐字采样您的语言模型", "title_en": "Sampling from Your Language Model One Byte at a Time", "authors": "Jonathan Hayase,Alisa Liu,Noah A. Smith,Sewoong Oh", "background": "现代语言模型几乎无一例外地使用分词技术，这使得使用多字节或多字符的分词方式能高效地表示文本。然而，先前的研究表明，分词可能导致模型生成的内容失真，这一问题称为‘提示边界问题’(PBP)。以英语为例，用户常被告知不要在提示中使用空格结尾，以避免模型将空格作为下一个分词的一部分。尽管这一经验法则对英语有效，但PBP仍然影响着中文等语言以及代码生成，因为这里的分词通常不与词和句法边界对齐。", "innovation": "本文提出了一种在推理阶段将使用BPE分词器的任何自回归语言模型转化为字符级或字节级语言模型的方法。该方法能够有效地解决PBP，并且还能统一不同分词器的语言模型的词汇表，使得在推理阶段可以整合不同分词器的语言模型，或者通过代理调校将一个模型的后训练效果转移到另一个模型上。实验结果显示，集成和代理调校后的模型在下游评估中表现优于其组成部分。", "conclusion": "实验表明，集成和代理调校的模型在下游任务上的表现优于其组成部分。代码可在下面的链接中获得。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22236", "html_url": "https://arxiv.org/abs/2506.22236", "title": "为统计学和机器学习的历史和哲学辩护", "title_en": "A Plea for History and Philosophy of Statistics and Machine Learning", "authors": "Hanti Lin", "background": "统计学和机器学习的历史整合由Hacking（1965年）和Mayo（1996年）提出，但尚未得到持续关注。然而，由于人工智能的最新进展主要依赖于机器学习（统计学的一个领域），这种整合比以往任何时候都更加迫切。机器学习与统计学的历史发展密切相关，如今两者之间的界限已经变得模糊，需要从两个方面进行整合：历史和哲学方面，以及统计数据学这两个领域方面。论文提出了一种来自奈曼和皮尔逊1936年工作中未被充分认识到的见解，并将其与机器学习方法实践相结合，提出了一种名为'可实现主义'的知论原则，认为非演绎推理方法的标准不应固定不变，而应根据不同具体问题情境可实现性进行调整。此外，还需要在方法论层面整合科学哲学两端：历史和哲学，以及形式化知识论。", "innovation": "提出了一种名为'可实现主义'的知论原则，强调非演绎推理方法评估的标准应具有灵活性，根据具体问题情境可实现性进行调整。并且提倡从历史和哲学以及统计学与机器学习两个方面进行整合研究，代表了该领域的创新性贡献。", "conclusion": "统计学和机器学习需要从历史和哲学方面进行进一步整合，并且这种整合包含两个方面：一方面，从具体问题情境出发，提出可实现主义原则用于评估非演绎推理方法；另一方面，追求历史和哲学，以及形式化知识论在方法论层面的结合。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03190", "html_url": "https://arxiv.org/abs/2507.03190", "title": "使用计算语言处理发现算法", "title_en": "Discovering Algorithms with Computational Language Processing", "authors": "Theo Bourdais,Abeynaya Gnanasekaran,Houman Owhadi,Tuhin Sahai", "background": "算法是可复制问题解决的引擎。以往的研究尝试通过概念化算法为操作序列，并使用语法表示这些计算操作。研究者们已经使用了蒙特卡洛树搜索（MCTS）结合强化学习（RL）来探索操作间的连接，以生成复杂的算法过程。这些方法能够重新发现、改进并生成新的算法，尤其在强NP难组合优化问题和基础量子计算方法（如Grover和量子近似优化算法）领域表现卓越。然而，现有方法的主要问题是只能针对问题类别进行优化，而不能专门针对个体问题实例进行优化.", "innovation": "本文提出了一种自动化算法发现的框架，通过将算法看作是由计算标记组成的操作序列，结合使用语法来链接这些标记，形成了日益复杂的处理过程。该框架利用强化学习（RL）引导的蒙特卡洛树搜索（MCTS）来探索标记间的连接，并自动生成新的标记。这种方法能够在组合优化问题和量子计算等领域重新发现、改进并生成新的算法，并且新生成的算法性能显著优于现有方法，且能够专门针对具体问题实例进行优化而不是仅仅针对问题类别.", "conclusion": "这一方法能够在计算层面上自动生成算法，这些算法能够根据具体的问题实例进行定制，而不仅仅依赖于预先定义的问题类别。这种方法显著提升了现有算法在处理强NP难组合优化问题和量子计算方法中的性能，展示了计算语言处理在算法发现方面的革新潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06565", "html_url": "https://arxiv.org/abs/2507.06565", "title": "他人之过：由大型语言模型驱动的科学知识生产框架", "title_en": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production", "authors": "Juan B. Gutiérrez", "background": "大型语言模型通过实时的人机交互改变了写作方式。本文探讨了这种新形式的写作交流，并提出了一种相对于人与LLM的陈述循环传播的认知网络模型，突破了将LLM视为孤立工具的局限，而是从错误传播和纠正的角度研究其工作原理。此外，研究不仅关注LLM的孤立幻觉，还定义了“驳斥”（任何事实、逻辑或结构上的错误），并分析了相关风险，包括偏离事实、自我纠正、新创造以及外部检测等四个维度。作者还开发了一般数学模型来研究这种认知网络，揭示了矛盾在网络中的动态稳定性以及添加新的错误传播如何影响这些系统。研究进一步指出，即使不对每个错误陈述进行完全审查，也只需要一个较小概率的审稿就能达到真相主导的状态。这也为建立一个实际有效的机制提供了支持，使得在一个低质量模型与审稿人构成的反馈环路系统中保持真相的主导地位成为可能。", "innovation": "提出了一种认知网络模型，其中人和大型语言模型被喻为平等节点，关注迷茫和驳斥的传播规律；定义了引发知识生产和传播过程不准确性的四种有害因素：偏离事实、自我纠正、新创造以及外部检测；开发了基于学界开放源码的Flaws-of-Others（FOO）算法，这是一种可配置的审稿机制，让一组代理评估彼此的工作，并将他们的判决合并统一，从而在保持错误传播或自我纠正的网络中实现真相为主导的状态。", "conclusion": "在这种新的交流媒介中，可靠性和准确性并非完全依赖于训练更完美的单个模型，而是依赖于把不完美的模型通过反馈机制互相校验的网络结构来维持真相的主导地位。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07469", "html_url": "https://arxiv.org/abs/2507.07469", "title": "Galerkin-ARIMA: 一种用于快速滚动一步预测的两阶段多项式回归框架", "title_en": "Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast Rolling One-Step-Ahead Forecasting", "authors": "Haojie Liu,Zihan Lin", "background": "该论文介绍了一种新的时间序列预测框架——Galerkin-ARIMA，它结合了Galerkin投影技术与经典的ARIMA模型，以捕捉滞后观察值中的潜在非线性依赖关系。除了传统的ARIMA模型假设外，Galerkin-ARIMA还通过使用岭回归灵活地逼近过去值之间的潜在关系。", "innovation": "Galerkin-ARIMA创新地将Galerkin投影技术与经典的ARIMA模型相结合，通过使用样条基扩展灵活地逼近过去的值之间的关系，同时保留了ARIMA模型的移动平均结构和高斯创新假设。通过两阶段Galerkin投影，该框架能够导出AR和MA部分的闭式解，并分析了基于基大小增长的偏差-方差权衡。", "conclusion": "实验结果表明，Galerkin-ARIMA在模拟的四个合成过程中（包括噪声ARMA、季节性、趋势-AR和非线性递归序列）能够与ARIMA接近的预测精度相比，提供多个数量级的速度提升。这表明Galerkin-ARIMA在高流量或实时应用中为建模复杂时间序列动态提供了一种强大的、高效的替代方案。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07031", "html_url": "https://arxiv.org/abs/2507.07031", "title": "ZKTorch：通过并行证明积累将机器学习推理编译为零知识证明", "title_en": "ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation", "authors": "Bing-Jyue Chen,Lilia Tang,Daniel Kang", "background": "随着AI模型在日常生活中的普及，人们对机器学习（ML）服务的透明度需求日益增长。然而，模型的所有者不愿意公开模型的权重，因为这些权重被视为商业秘密。为了解决这个问题，研究人员转向了机器学习模型推理的零知识证明。这些证明可以让用户确信，模型输出是正确的，而无需向用户透露模型的权重。", "innovation": "我们提出了一种开源的端到端证明系统ZKTorch。ZKTorch将机器学习模型编译为基本的加密操作（称为基础块），每个基础块使用专门的协议进行证明。ZKTorch基于新颖的并行扩展的Mira累加方案，可以实现与特殊协议相比至少3倍的证明规模减少，并且相对于通用的ZKML框架，证明时间快6倍。", "conclusion": "ZKTorch能够高效地将机器学习推理过程转换为零知识证明，它的贡献使得ZKTorch在证明规模和证明时间上有显著的优势，这对于正在快速发展的机器学习领域尤为重要。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07668", "html_url": "https://arxiv.org/abs/2507.07668", "title": "使用预测不确定性评估学习强子态的极点结构", "title_en": "Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation", "authors": "Felix Frohnert,Denny Lane B. Sombillo,Evert van Nieuwenburg,Patrick Emonts", "background": "在强子光谱学中，将理论预测与实验数据匹配仍然是一个核心挑战，尤其是识别新强子态非常困难，因为阈值附近出现的奇异信号可能源于多种物理机制。在这种背景下，极点结构的散射振幅是一个关键诊断指标，但由于不同配置可能产生相似的信号，极点配置与线型之间的映射在阈值附近尤其不明确，这时的分析控制能力有限。本文探讨了如何利用不确定性感知的机器学习方法来分类散射矩阵元素中的极点结构。该方法基于一组分类链，可以提供表观不确定性和随机不确定性的估算。通过基于预测不确定性的拒绝准则的应用，模型在保持高验证准确率（接近95%）的同时，减少了高不确定预测的比例。", "innovation": "本文提出了一种不确定性感知的机器学习方法，用于分类散射矩阵元素中的极点结构。该方法基于一组分类链，可以提供表观不确定性和随机不确定性的估算。提出的模型在合成数据（具有已知极点结构）上训练，能够泛化应用于以前未见的实验数据，包括由LHCb观察到的$P_{c\bar{c}}(4312)^+$状态的增强效果。通过对这一特定状态的评估，该框架广泛适用于其他候选的强子态，并提供了一种可扩展的工具，用于散射振幅中的极点结构推断。", "conclusion": "本文介绍了一种不确定性感知的机器学习方法，通过基于预测不确定性的拒绝准则实现了极点结构的分类。模型在验证准确率接近95%的同时，能够有效排除高不确定性的预测。这种框架可以应用于检测强子态中的极点结构，为强子光谱学研究提供了一种有效的工具。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08160", "html_url": "https://arxiv.org/abs/2507.08160", "title": "Generative AI对代码专家模型的影响：一项探索性研究", "title_en": "The Impact of Generative AI on Code Expertise Models: An Exploratory Study", "authors": "Otávio Cury,Guilherme Avelino", "background": "生成型人工智能（GenAI）工具在源代码生成方面的应用显著提升了软件开发的生产率，但也引发了担忧，尤其是开发者可能会过度依赖这些工具，从而减少对生成代码的理解。已有研究表明，这可能体现在源代码知识模型上，并影响到对其开发人员专业性的识别。", "innovation": "本文提出了一个基于知识模型和基于该模型构建的‘卡车因子’算法的探索性分析，以评估GenAI使用对其的影响。通过收集ChatGPT生成代码在GitHub项目中的整合统计数据，并模拟不同场景，调整GenAI贡献的程度，揭示了现有专业性度量指标的敏感性。", "conclusion": "研究发现，大多数场景都显示出可测量的影响，表明当前的专业性度量指标可能变得不够可靠。这提示，在将GenAI更深入地集成到开发流程中后，这些度量指标的可靠性可能下降。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08061", "html_url": "https://arxiv.org/abs/2507.08061", "title": "Fission和聚变能源中的计算科学现状", "title_en": "The State of Computational Science in Fission and Fusion Energy", "authors": "Andrea Morales Coto,Aditi Verma", "background": "工程工具的重要性等同于被工程化的内容。实际上，在很多情况下，工具在很大程度上决定了能够工程化的内容。在核聚变和裂变能源工程中，软件已成为设计的主要工具。为了更好地理解当前软件工具的发展趋势，作者在2024年首次对103名开发聚变和裂变能源代码的计算科学家进行了问卷调查，询问他们在工作中遇到的问题、可用的解决工具以及使用这些工具的整体开发体验。这些调查结果揭示了在核聚变和裂变领域软件工具的发展变化，越来越多的科学家倾向于使用现代编程语言、开源代码和模块化软件。这些趋势预示着未来5-10年内核工程的发展方向。由于大多数受访者隶属于美国国家实验室和大学，这些结果反映了行业的最先进趋势。我们的研究指出，多物理场代码的使用显著增加，FORTRAN等过时语言的使用减少，取而代之的是如Python和C++等更现代的语言。组织投入的代码开发预算也在逐年增加，有时达到单组织5000万美元。我们通过网络形式发布了这些调查结果的详细内容。", "innovation": "1. 调查采用了一种新的视角，关注计算工具在核工程中的应用和发展趋势。2. 揭示了现代编程语言、开源代码和模块化软件在核工程领域的广泛应用。3. 详细分析了多物理场代码的使用趋势，以及FORTRAN等传统语言被更现代语言取代的情况。4. 预示了未来核工程项目中代码开发面临的环境将更加模块化、计算需求更少，并且受到组织更高的重视。", "conclusion": "调查结果表明，核工程领域未来将变得更加模块化、注重代码的计算效率，并且得到更多组织的支持。未来5-10年内的大部分趋势已经通过本次调查清晰地展现出来，反映了行业的发展方向和潜在需求。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08149", "html_url": "https://arxiv.org/abs/2507.08149", "title": "我来与我一起编码还是为我编码？不断增加的AI自动化如何改变开发人员的工作流程", "title_en": "Code with Me or for Me? How Increasing AI Automation Transforms Developer Workflows", "authors": "Valerie Chen,Ameet Talwalkar,Robert Brennan,Graham Neubig", "background": "现在，开发者已可以访问越来越多的自主AI工具，以支持软件开发。尽管已有大量研究关注开发者在使用代码伙伴（可以提供聊天支持或代码完成）方面的使用情况，但在评估能够自动编写文件和运行代码的代理方面，现有的评估仍然侧重于静态基准测试，而缺乏人类在回路的互动。本文旨在是首次学术探讨开发者与代码代理之间的互动，以及更自主的AI工具如何影响用户体验和生产力，与现有的代码伙伴相比。", "innovation": "本文对两款领先的代码伙伴和代理编码助手——GitHub Copilot和OpenHands进行了评估，参与者主要是之前使用前者的常客。结果表明，代理在完成任务（如人们可能无法完成的任务）方面具有超越代码伙伴的潜力，并有助于减少完成任务所需的工作负担。然而，推广这些代理的挑战包括如何确保用户充分理解代理的行为。本文不仅揭示了开发人员的工作流程因代码代理而如何变化，还突出了用户与代理交互方式与现有代码伙伴的不同，为研究人员提供了建设新的代理的一些建议。", "conclusion": "鉴于仍然大量依赖类似于代码伙伴系统的开发人员的广泛群体，本文指出了将更加自主的系统引入开发人员工作流程中的关键挑战。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08250", "html_url": "https://arxiv.org/abs/2507.08250", "title": "利用大型语言模型对应用程序用户反馈进行分类", "title_en": "Leveraging Large Language Models for Classifying App Users' Feedback", "authors": "Yasaman Abedini,Abbas Heydarnoori", "background": "近年来，关于应用（app）用户反馈分类的研究取得了显著进展，主要依赖于监督机器学习算法。然而，基于现有标记数据集调整更通用的分类器仍然是一项重要挑战，因为创建大规模且准确标记的数据集通常需要大量时间和资源。本文通过评估包括GPT-3.5-Turbo、GPT-4、Flan-T5和Llama3-70b在内的四种先进大型语言模型（LLM），旨在提高用户反馈分类能力并应对有限标记数据集的挑战。实验使用八个经过详细标记的研究数据集，包括应用商店的用户评论、X平台的帖子和公共论坛的讨论，这些数据集被认为是应用用户反馈的代表性来源。", "innovation": "本文通过使用包括GPT-3.5-Turbo、GPT-4、Flan-T5和Llama3-70b在内的四种先进大型语言模型，解决有限标记数据集的问题，并增强用户反馈分类能力。这些模型被用作注释工具，不仅标注泛化数据，还标注应用特定数据，旨在提高最先进的BERT基分类模型的性能。", "conclusion": "通过精心设计的提示指导语言模型，可以有效地将用户反馈分类为大类。此外，使用语言模型共识标记的数据集增强训练数据集，可以显著提高分类器的性能。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08467", "html_url": "https://arxiv.org/abs/2507.08467", "title": "通过注入扰动计算浮点误差", "title_en": "Computing Floating-Point Errors by Injecting Perturbations", "authors": "Youshuai Tan,Zhanwei Zhang,Jinfu Chen,Zishuo Ding,Jifeng Xuan,Weiyi Shang", "background": "浮点程序构成了现代科学与工程的基础，为众多应用（如关键安全系统、航空航天工程和金融分析）提供了必要的计算框架。浮点错误可能导致严重后果。虽然浮点错误普遍存在，但只有部分输入会导致浮点程序中的重大错误。因此，确定给定输入是否会引发此类错误至关重要。研究者倾向于使用高精度浮点程序的结果作为检测浮点错误的或acles，但带来了两大局限性：(1) 实现难度大；(2) 执行时间长。最近的两个工具 ATOMU 和 FPCC 能部分解决这些问题。然而，ATOMU 存在误报问题，而 FPCC 尽管消除了误报，但运行速度明显较慢。", "innovation": "我们提出了一种新颖的方法，称之为 PI-detector，以有效地和高效地计算浮点误差。该方法基于观察到浮点错误源自程序中原子操作（如加法和减法）中的大条件数，然后传播并累积。PI-detector 在程序中的个别原子操作的操作数中注入少量扰动，并将原始程序的结果与注入扰动后的版本进行比较，以此来计算浮点误差。我们的评估结果表明，PI-detector 可以高效且准确地进行浮点误差计算。", "conclusion": "实验结果证明了 PI-detector 的有效性和准确性，在检测浮点程序中的误差方面提供了新的解决方案。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08627", "html_url": "https://arxiv.org/abs/2507.08627", "title": "中间用自然语言：通过中间表示使用LLM进行代码翻译", "title_en": "NL in the Middle: Code Translation with LLMs and Intermediate Representations", "authors": "Chi-en Amy Tai,Pengyu Nie,Lukasz Golab,Alexander Wong", "background": "研究表明大型语言模型（LLMs）在代码翻译时会生成错误代码。一种提高翻译准确性的方法是使用中间表示，它可以为模型提供结构化的见解，帮助其理解。本文探讨了代码翻译是否可以从自然语言（NL）和抽象语法树（AST）的中间表示中受益，并通过调整提示工程技术来评估其影响。", "innovation": "研究通过使用Open Gpt4 8X7B模型以及专用的StarCoder和CodeGen模型，探索在流行的代码翻译基准（CodeNet和AVATAR）中通过一个思考链式提示和中间NL总结来提升代码翻译精度的方法。研究表明，使用中间NL总结的链式思考提示表现最佳。", "conclusion": "实验证明，使用中间NL总结的链式思考提示方法在代码翻译中效果最佳，相比零提示的模型，Open Gpt4 8X7B模型的成功翻译数量分别增加了13.8%和6.7%。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08671", "html_url": "https://arxiv.org/abs/2507.08671", "title": "LLMCup：使用大型语言模型的排名增强注释更新", "title_en": "LLMCup: Ranking-Enhanced Comment Updating with LLMs", "authors": "Hua Ge,Juan Zhai,Minxue Pan,Fusen He,Ziyue Tan", "background": "在现代软件项目中，注释对于提升代码可读性和维护性至关重要，但由于开发人员往往倾向于更新代码而忽略注释，导致注释过时或不一致，这妨碍了未来的理解和维护。现有的方法如CUP和HebCup尝试使用神经序列到序列模型和启发式规则自动更新注释，但这些方法可能会错过或误解关键信息，导致不准确的注释，特别是在复杂更新场景中表现不佳。", "innovation": "提出了LLMCup框架，该框架首先使用多种提示策略通过大型语言模型提供多样化的候选更新注释，然后使用排名模型CupRank选择最佳候选作为最终更新注释。实验结果显示，LLMCup在准确性、BLEU-4、METEOR、F1以及SentenceBert相似性方面较最先进的基线方法（CUP和HebCup）分别提高了49.0%-116.9%、10.8%-20%、4.6%、0.9%-1.9%和2.1%-3.4%。进一步的用户研究表明，LLMCup更新的注释有时甚至超过了人工撰写的注释，突显了在注释质量评估中纳入人工评价的重要性。", "conclusion": "LLMCup框架通过使用大型语言模型和排名模型有效桥接了注释更新任务中的信息缺失和误解问题，提高了注释的准确性和一致性，展示了在软件工程任务中利用大型语言模型的潜力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12546", "html_url": "https://arxiv.org/abs/2505.12546", "title": "从开放权重语言模型中提取受版权保护书籍的被记忆片段", "title_en": "Extracting memorized pieces of (copyrighted) books from open-weight language models", "authors": "A. Feder Cooper,Aaron Gokaslan,Ahmed Ahmed,Amy B. Cyphert,Christopher De Sa,Mark A. Lemley,Daniel E. Ho,Percy Liang", "background": "在涉及生成式人工智能的版权诉讼中，原告和被告经常就大型语言模型（LLMs）是否和到何种程度记忆了原告的受保护表达做出极端对立的主张。本文借助对抗性机器学习和版权法观点，通过使用近期的统计提取技术来提取Books3数据集中文本片段的多种实验展示了模型的记忆情况，同时也揭示了记忆程度在不同模型和书籍间存在差异。", "innovation": "本文利用统计提取技术从17个开放权重语言模型中提取Books3数据集的部分文本，发现了这些模型的记忆程度在不同模型和书籍间存在显著差异。最大的语言模型并不记忆大多数书籍，而Llama 3.1 70B却几乎完全记忆了《哈利·波特与魔法石》和《1984》，甚至可以使用简单的提示生成这些书的近同义版本。", "conclusion": "本文的结果对版权诉讼具有重大影响，但未明确偏向任何一方，因为记忆程度因模型和书籍而异，这使得版权保护和使用的情况变得复杂。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08523", "html_url": "https://arxiv.org/abs/2507.08523", "title": "InferLog: 通过ICL导向的前缀缓存加速在线日志解析的LLM推理", "title_en": "InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching", "authors": "Yilun Wang,Pengfei Chen,Haiyu Huang,Zilong He,Gou Tan,Chuanfu Zhang,Jingkai He,Zibin Zheng", "background": "现代软件系统生成大量运行时日志，需要高效的日志解析来支持关键下游任务，如异常检测和根本原因分析。虽然大型语言模型在日志解析方面表现先进，但由于隐私风险驱动本地部署及高并发日志流对延迟和吞吐量的严格要求，现有基于LLM的日志解析器无法满足生产环境中的需求。尽管近期努力减少LLM查询的数量，但忽视了LLM推理中的高延迟问题，多个日志解析请求可能导致LLM推理系统性能下降。基于此背景，本文研究了在线日志解析中LLM推理优化的方法。研究表明，推理效率已成为基于LLM的日志在线解析的关键瓶颈，而非解析准确性。相关工作和方法未能有效解决上述问题，本文通过设计ICL（基于上下文的学习）定向的前缀缓存策略，优化了在线日志解析中LLM的推理效率。", "innovation": "本文提出InferLog，一种基于ICL定向的前缀缓存策略，以加速在线日志解析的LLM推理。InferLog通过两项创新技术：(1) 前缀感知的ICL精炼策略，提高前缀缓存效率；(2) 基于元学习的快速且针对任务的配置调整流水线，以找到动态日志解析工作负载下的最佳LLM调度相关配置。实验表明，InferLog显著优于现有的推理优化方法，能够加速最先进的基于LLM的日志解析器，而无需牺牲解析准确性。", "conclusion": "InferLog通过设计ICL导向的前缀缓存策略和基于元学习的配置调整方法，显著改善了在线日志解析中LLM推理的效率，证明了其在处理高并发日志流时的优势，并展示了在准确性的基础上提高性能的可能性。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08164", "html_url": "https://arxiv.org/abs/2507.08164", "title": "KP-A: 导致自主网络智能统一网络知识平面", "title_en": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence", "authors": "Yun Tang,Mengbang Zou,Zeinab Nezami,Syed Ali Raza Zaidi,Weisi Guo", "background": "大规模语言模型（LLMs）和自主系统正在推动6G网络的自主化，提升自我配置、自我优化和自我恢复的能力。然而，当前通过孤立的知识检索管道实现个体智能任务的方法导致了冗余的数据流和不一致的解释。", "innovation": "KP-A 提出了一种专门为自主网络智能设计的统一网络知识平面。通过分离网络知识的获取和管理与智能逻辑，KP-A 简化了开发过程并减少了智能工程师的维护复杂性。KP-A 提供了一个直观且一致的知识接口，提高了网络智能代理的互操作性。", "conclusion": "通过在两个代表性智能任务中展示 KP-A，即实时网络知识问答和边缘 AI 服务编排，证明了 KP-A 的有效性和适用性。KP-A 的所有实施成果都已开源，以支持可重复性和未来标准化工作。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08594", "html_url": "https://arxiv.org/abs/2507.08594", "title": "通过提示工程技术生成原型人物：一项关于效率、有效性和共鸣的案例研究", "title_en": "Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy", "authors": "Fernando Ayach,Vitor Lameirão,Raul Leão,Jerfferson Felizardo,Rafael Sobrinho,Vanessa Borges,Patrícia Matsubara,Awdren Fontão", "background": "在产品发现的早期阶段，如精益 inception 过程中，通常会使用原型人物来指导产品定义和利益相关者一致化。然而，手工创建这些原型人物既耗时又耗认知能力，并且容易产生偏见。因此，本文旨在研究一种基于提示工程技术并通过生成式人工智能（GenAI）支持的方法，以评估该方法在效率、效果、用户接受度以及生成的人类形象引发的共鸣方面表现。研究通过案例研究的形式，使用19位参与者并通过混合质性与量化方法设计进行验证，结果表明这种方法能有效减少时间和努力，提高后期发现阶段（如最小可行产品 MVP 的范围确定和特性精炼）中人物原型的质量以及可重用性。尽管总体上用户接受度较高，尤其是在感知实用性和使用便捷性方面，但参与者也指出了泛化和领域特定性方面的限制。此外，虽然认知共情得到了强烈支持，但情感共情和行为共情在参与者之间差异显著。这些结果为生成式人工智能如何有效集成到软件产品发现实践中提供了新的实证证据，并指出了未来此类混合设计过程中的关键挑战。", "innovation": "提出了一种基于提示工程技术的方法，利用生成式人工智能（GenAI）自动创建原型人物，以提高效率和效果，并实现在产品发现早期阶段的应用。这种方法不仅简化了原型人物的创建过程，还提高了它们的可用性和可重用性，并通过用户反馈验证其有效性，同时也在共情方面提出了新见解。", "conclusion": "该研究案例表明，提示工程技术与生成式人工智能结合使用能够显著提高原型人物的创建效率和质量，但仍存在泛化和特定领域挑战的问题。认知共情得到了强烈支持，但情感和行为共情表现出较大个体差异。该研究为未来将生成式人工智能技术集成到软件产品发现实践中提供了重要的实证基础，但也揭示了需要进一步解决的关键问题。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代可配置软件系统需要学习其配置与性能之间的模型。然而，在动态环境中，工作负载变化、硬件更改和系统更新不可避免地会在不同级别上引入概念漂移：全局漂移会重新塑造整个配置空间的性能景观；局部漂移仅影响配置空间中的某些子区域。现有的离线和迁移学习方法在应对这些隐含且不可预测的实时变化时可能难以适应，导致配置性能学习具有挑战性。", "innovation": "本文提出了一种名为DHDA（Dually Hierarchical Drift Adaptation）的在线配置性能学习框架，旨在捕捉并适应不同级别的漂移。DHDA使用双重层次适应机制：在较高层次上，重新划分数据并重新训练局部模型，只在必要时处理全局漂移；在较低层次上，每个分区内局部模型可以检测局部漂移并异步进行自我调整。为了平衡响应性和效率，DHDA结合了增量更新和周期性的全面重训练，以在未检测到漂移时最小化冗余计算。", "conclusion": "通过评估八个软件系统并与其他最先进的方法进行比较，我们展示了DHDA在准确性和适应漂移方面取得了显著的改进。它在性能上可以提高高达2倍，同时保持合理的开销，并能够有效地改进各种局部模型以处理概念漂移。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.07649", "html_url": "https://arxiv.org/abs/2507.07649", "title": "提供量子优化工具箱", "title_en": "ProvideQ: A Quantum Optimization Toolbox", "authors": "Domenik Eichhorn,Nick Poser,Maximilian Schweikart,Ina Schaefer", "background": "混合求解器结合了经典计算和量子计算的优势，以克服计算难题。然而，由于缺乏能够无缝集成量子解决方案与现有经典优化框架的技术栈，其实用性面临挑战。", "innovation": "提出了ProvideQ工具箱，这是一种软件工具，通过Meta-Solver策略使用户能够轻松适应和配置混合求解器。它通过Meta-Solver配置工具实现了问题的分解技术，将问题划分为经典和量子子程序。ProvideQ工具箱将经典的优化技术与可以在多个后端上无缝执行的量子电路相结合。", "conclusion": "研究表明，Meta-Solver策略已经能够使量子子程序今天得到应用，但是更先进的硬件是必要的，以使其性能达到竞争水平。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08719", "html_url": "https://arxiv.org/abs/2507.08719", "title": "多模态多语种软件开发人员用于代码生成", "title_en": "Multilingual Multimodal Software Developer for Code Generation", "authors": "Linzheng Chai,Jian Yang,Shukai Liu,Wei Zhang,Liran Wang,Ke Jin,Tao Sun,Congnan Liu,Chenchen Zhang,Hualei Zhu,Jiaheng Liu,Xianjie Wu,Ge Zhang,Tianyu Liu,Zhoujun Li", "background": "近年来，大型语言模型（LLMs）迅速发展，显著提高了代码生成能力。然而，大多数模型仍然仅限于处理文本信息，而忽视了在实际软件开发中至关重要的视觉辅助工具，如统一建模语言（UML）图表和流程图。为了填补这一空白，引入了MM-Coder，这是一种多模态多语种软件开发人员。MM-Coder能将视觉设计输入（如UML图表和流程图）与文本指令相结合，以提高代码生成的准确性和架构一致性。", "innovation": "我们的创新包括开发了MMc-Instruct，这是一个多模态指令调优数据集，包括基于视觉工作的代码生成，使得MM-Coder能够综合处理文本和图形信息，类似于人类开发者的处理方式，从而能够填补先有技术的不足。此外，我们还引入了MMEval，这是一个新的多模态代码生成基准评估集，能够应对现有的单模态文本限制。我们的评估结果显示，模型在精准捕捉视觉信息、指令遵循以及高级编程知识方面仍然存在许多挑战。", "conclusion": "我们的研究旨在通过使LLMs能够理解和实现通过文字和视觉设计传达的复杂规范来革新工业级编程。"}
{"llm_update_time": "20250714", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.08054", "html_url": "https://arxiv.org/abs/2408.08054", "title": "Text2BIM: 使用大型语言模型多智能体框架生成建筑模型", "title_en": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "authors": "Changyu Du,Sebastian Esser,Stavros Nousias,André Borrmann", "background": "传统的BIM（建筑信息模型）设计通常需要设计师掌握复杂的建模命令，以便在BIM设计工具中实现设计意图。这一额外的认知负担复杂化了设计过程，并阻碍了BIM和基于模型的设计在建筑、工程和施工（AEC）行业的应用。为了更直观地表达设计意图，我们提出了Text2BIM，这是一个基于LLM（大型语言模型）的多智能体框架，可以从自然语言指令生成3D建筑模型。此外，框架引入了基于规则的模型检查器，利用预定义的领域知识来指导LLM智能体解决生成模型中的问题，从而逐步提高模型质量。在三个不同LLM下的框架中进行了大量实验，评估结果表明，我们的方法可以有效地生成符合用户输入抽象概念的高质量、结构合理建筑模型。最后，还开发了一个交互式软件原型，将框架集成到建筑信息建模（BIM）软件Vectorworks中，展示了通过聊天建模的潜力。", "innovation": "提出了一种基于LLM的多智能体框架Text2BIM，可以将自然语言指令转换为生成3D建筑模型的代码，并引入了基于规则的模型检查器，可以逐步提高模型质量。此外，该框架被集成到BIM设计软件中，展示了聊天交流进行建模的潜力。", "conclusion": "实验结果表明，提出的方法可以生成高质量、结构合理的建筑模型，符合用户抽象概念。成功将Text2BIM框架集成到BIM设计软件中，展示了通过聊天方式进行建模的可能性。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.10240", "html_url": "https://arxiv.org/abs/2504.10240", "title": "GNN-ACLP：基于图神经网络的模拟电路链接预测", "title_en": "GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction", "authors": "Guanyuan Pan,Tiansheng Zhou,Bingtao Ma,Yaqi Wang,Jianxiang Zhao,Zhi Li,Yugui Lin,Pietro Lio,Shuai Wang", "background": "在自动化模拟电路设计过程中，从不完整的网络列表中识别缺失组件连接的电路链接预测至关重要。现有方法面临三个主要挑战：1) 在电路图中对拓扑模式的应用不足，降低了预测精度；2) 注释的复杂性导致数据稀缺，阻碍了模型泛化；3) 无法适应多种网络列表格式。", "innovation": "我们提出了基于图神经网络（GNNs）的GNN-ACLP框架，具有三大创新点来应对这些挑战。首先，我们引入了SEAL（子图、嵌入和属性用于链接预测）框架，实现了端口级别的电路链接预测精度。其次，我们提出了Netlist Babel Fish，这是一种利用检索增强生成（RAG）与大型语言模型（LLM）的网络列表格式转换工具，以提高网络列表格式的兼容性。最后，我们构建了SpiceNetlist，一个综合数据集，包含775个带有不同组件类的标注电路。", "conclusion": "实验结果显示，GNN-ACLP框架在SpiceNetlist、Image2Net和Masala-CHAI数据集上的准确性分别提高了16.08%、11.38%和16.01%，在跨数据集评估中，从92.05%到99.07%保持了准确性，展示了强大的特征迁移能力。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18246", "html_url": "https://arxiv.org/abs/2504.18246", "title": "一次性推理：通过令牌复制和块稀疏掩码实现高效的多轮推理微调", "title_en": "One-Pass to Reason: Token Duplication and Block-Sparse Mask for Efficient Fine-Tuning on Multi-Turn Reasoning", "authors": "Ritesh Goru,Shanay Mehta,Prateek Jain", "background": "微调大型语言模型（LLMs）需要对多轮推理数据集进行多次前向传递，因为推理令牌在后续轮次中会被丢弃，导致每次对话都需要N次前向传递。尽管现有方法可以实现这一目标，但存在时间复杂度高的问题。", "innovation": "提出了一种新的方法，即在响应令牌的同时复制一个自定义注意力掩码，允许一次性处理整个对话，从而将时间复杂度从$O(N^3)$降低到$O(N^2)$，同时保持与基于变压器模型相同的内存复杂度，并证明这种方法在损失相同的情况下提高了训练速度。", "conclusion": "这种新方法显著提高了训练速度，同时保持了准确性。实现代码已在线提供。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05550", "html_url": "https://arxiv.org/abs/2507.05550", "title": "Malliavin calculus approach to score functions in diffusion generative models", "title_en": "A Malliavin calculus approach to score functions in diffusion generative models", "authors": "Ehsan Mirafzali,Frank Proske,Utkarsh Gupta,Daniele Venturi,Razvan Marinescu", "background": "分数扩散生成模型近年来已成为建模复杂数据分布的强大工具。这些模型的目标是学习分数函数，通过确定性或随机微分方程(SDEs)将已知概率分布映射到目标数据分布。分数函数通常使用去噪或切片分数匹配、Hyvärinen方法或薛定谔桥梁等variational技术进行估计。", "innovation": "本文提出了一种结合现代随机分析工具（如malliavin导数及其伴随算子（skorokhod积分或malliavin divergence））和新型bismut型公式的严格方法。这种方法为复杂概率分布的采样算法设计提供了基础，增强了分数函数的实际应用性，并能够推广到更广泛的随机微分方程类。", "conclusion": "本文提出的理论框架为生成建模下的分数估计方法提供了原则性的基础，能够设计新的复杂概率分布采样算法。此外，结果还可以应用于更广泛的随机微分方程类，为分数基于扩散生成模型的发展开辟新的方向。"}
{"llm_update_time": "20250714", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05640", "html_url": "https://arxiv.org/abs/2507.05640", "title": "基于可学习量子频域滤波器的混合图神经网络", "title_en": "Learnable quantum spectral filters for hybrid graph neural networks", "authors": "Ammar Daskin", "background": "近年来，量子计算与图神经网络的结合吸引了大量研究，特别是在复杂图形数据的处理上。量子电路被设计用来模拟图的拉普拉斯算子的频谱，以此来实现图卷积和池化操作，减少经典计算的成本，并且利用量子傅里叶变换实现高效的滤波和压缩。通过将此类量子电路作为卷积层，研究者能够有效地处理和压缩高维图形信号，并进一步使用经典神经网络头进行预测，构建完整的图神经网络。此前的研究已经展示了将量子技术和图神经网络结合的应用，但本文特别关注了参数化量子电路在图神经网络中的应用，并展示了其在图形分类任务中的表现，尤其在几何结构显著影响任务结果时，表现出良好的性能。", "innovation": "提出了一种参数化的量子电路，该电路可以实现图卷积和池化操作，通过量子傅里叶变换（QFT）基于拉普拉斯矩阵的连接结构来实现频谱的近似。相对于传统方法（如切比雪夫多项式或泰勒展开），该方法只需要log(N)个量子比特，大大减少了经典计算的昂贵成本。该量子电路结合了经典预测头，构建了混合图神经网络，并展示了在基准数据集上的图形分类结果，其性能与甚至优于某些基线方法，特别是在图形结构起重要作用的情况下更为显著。", "conclusion": "通过引入基于量子傅里叶变换的参数化量子电路，研究成功地在混合图神经网络中实现了图卷积和池化操作，同时显著减少了对经典计算的依赖。在几何结构对任务结果影响显著的数据集上，与基线方法相比，这种方法展示了更好的性能。这对于未来的图神经网络研究具有重要意义，特别是在量子计算与机器学习的交叉领域。"}
