# 20250709
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 红队人工智能红队作战 [PDF](https://arxiv.org/pdf/2507.05538), [HTML](https://arxiv.org/abs/2507.05538)
### Authors
Subhabrata Majumdar,Brian Pendleton,Abhishek Gupta
### Background
红队活动从军事应用中演变出来，现在已经广泛应用于网络安全和人工智能领域。本文对人工智能红队活动进行了深入分析，指出尽管其在人工智能治理方面的流行度很高，但在发现生成型人工智能中的模型级漏洞方面过于狭隘，忽视了复杂交互中产生的社会技术和系统问题。
### Innovation
本文提出了一个综合框架，从宏观层面和微观层面全面描述人工智能红队活动，涵盖了从开发到研究的整个生命周期。此外，还提出了基于网络安全经验和系统理论的建议，强调有效的人工智能红队活动需要多功能团队来评估新兴风险、系统漏洞以及技术与社会因素的交互作用。
### Conclusion
有效地进行人工智能红队活动需要多功能团队，重点关注系统风险、系统漏洞以及技术与社会因素间的交互作用，这将有助于更好地理解和评估人工智能系统的安全性和可靠性。
## 2. `cs.AI` - 模糊分类聚合为连续体代理 [PDF](https://arxiv.org/pdf/2507.05297), [HTML](https://arxiv.org/abs/2507.05297)
### Authors
Zijun Meng
### Background
本文探讨了如何将多个代理对一组对象进行的连续模糊分类结果进行聚合。背景在于，研究如何在不确定性环境下优化和整合个体决策，特别是在多个代理对多个对象进行分类时，需要一个确定性的聚合方法来处理这些模糊分类结果，以获取最优的综合分类结果。这是一个广泛应用于决策理论、机器学习和群体智能等领域的问题。
### Innovation
创新点在于证明了对于不少于3个对象且每个对象不超过m种类型分类的连续个体分类结果，最优、独立、零一致的模糊分类聚合函数必须是一个加权算术平均。这一发现为优化模糊分类聚合提供了一个理论上严格的基础，有助于提高决策质量和群体智能系统的准确性。
### Conclusion
本文证明了对于m个对象（m ≥ 3）进行2到m类型分类的连续个体分类结果，任意最优、独立、零一致的模糊分类聚合函数必须是加权算术平均。这一结论为设计高效的模糊分类系统提供了理论支持，有助于改进群体决策和多智能体系统中的分类聚合过程。
## 3. `cs.AI` - 大规模对话教育：跨领域的多语言模型代理工作流及其教学质量和过程评估 [PDF](https://arxiv.org/pdf/2507.05528), [HTML](https://arxiv.org/abs/2507.05528)
### Authors
Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang
### Background
现有的对话教育研究常常缺乏可扩展性，未能充分利用多样化的大量课程内容，并且缺乏评估教学质量的框架。大型语言模型（LLMs）的进步正在推动虚拟教育者和学习者的进展，将自然语言处理（NLP）与AI4Education结合在一起。
### Innovation
提出了WikiHowAgent，这是一种利用LLMs的多代理工作流，模拟互动的教学-学习对话。它结合了教师和学习者代理、互动管理器和评估器，以促进过程性学习并评估教学质量。此外，还引入了一个包含114,296个教师-学习者对话的大型数据集，这些对话基于14,287个跨17个领域、727个主题的教程。该评估协议结合了基于计算和基于评分表的度量标准，并与人类判断的调整相结合。
### Conclusion
实验结果表明，该工作流在各种设置下的有效性，提供了对LLMs在不同领域的能力的见解。数据集和实现均为开源。
## 4. `cs.AI` - Deep Research Comparator: 一个细粒度深度研究代理人工注释的平台 [PDF](https://arxiv.org/pdf/2507.05495), [HTML](https://arxiv.org/abs/2507.05495)
### Authors
Prahaladh Chandrahasan,Jiahe Jin,Zhihan Zhang,Tevin Wang,Andy Tang,Lucy Mo,Morteza Ziyadi,Leonardo F.R. Ribeiro,Zimeng Qiu,Markus Dreyer,Akari Asai,Chenyan Xiong
### Background
评估能够自主搜索网络、分析信息并生成报告的深度研究代理的有效方法仍是一个重大挑战，尤其是评估长报告和给予其中间步骤详细反馈方面。针对这些缺口，我们提出了一种名为Deep Research Comparator的平台，该平台提供了一个全流程框架，用于深度研究代理托管、并排比较、精细的人工反馈收集以及排名计算。给定用户查询，该平台展示来自两个不同代理的最终报告及其生成过程中的中间步骤。注释者可以根据并排比较评估最终报告的整体质量，并通过评估中间步骤或最终报告中的特定文本片段详细提供反馈。
### Innovation
我们开发了名为Simple Deepresearch的端到端代理框架。该框架充当了一个基准，使各种大型语言模型能够轻松集成并转化为评估用的深度研究代理。此外，我们还收集了17名注释者对三个深度研究代理的真实用户偏好数据，以展示该平台对深度研究代理开发的实用价值。我们还提供了平台的演示视频。
### Conclusion
我们平台提供了一个全流程框架，用于深度研究代理托管、并排比较、精细的人工反馈收集以及排名计算，有助于解决深度研究代理评估中的挑战。同时，我们开发的Simple Deepresearch框架为不同大型语言模型的集成提供了方便，并通过收集的用户偏好数据证明了该平台在深度研究代理开发中的实用性。
## 5. `cs.AI` - 在消费级硬件上强有力地解决7×6游戏Connect-Four [PDF](https://arxiv.org/pdf/2507.05267), [HTML](https://arxiv.org/abs/2507.05267)
### Authors
Markus Böck
### Background
Connect-Four这款游戏已经被数学上解决，可以使用基于搜索的方法有效地计算出最佳移动。虽然依靠查找表形式的强大解决方案被认为是不可行的，但作者重新审视了一种基于二元决策图的符号搜索方法，以生成强有力的方法。在标准的7×6棋盘大小上，他们用128GB内存和单个CPU核心在一个47小时内生成了一个89.6GB大小的查找表。
### Innovation
作者提出了一个高效的实现在基于二元决策图的符号搜索方法上的应用，从而成功生成了Connect-Four游戏的查找表。这个查找表大小为89.6GB，并在47小时内利用消费级硬件实现。此外，他们还在开源软件中包含了alpha-beta搜索方法，以加快胜利或减慢失败。
### Conclusion
通过有效的实现，作者能够在标准7×6 Connect-Four棋盘上生成一个大尺寸的查找表，展示了在消费级硬件上的可行性。这个研究为游戏理论和计算复杂性研究提供了新的见解。
## 6. `cs.AI` - OLG++: Obligation Logic Graph 的语义扩展 [PDF](https://arxiv.org/pdf/2507.05488), [HTML](https://arxiv.org/abs/2507.05488)
### Authors
Subhasis Dasgupta,Jon Stephens,Amarnath Gupta
### Background
本文介绍了 OLG++，一个用于建模市政和跨辖区法规与法律规则的语义扩展。OLG++ 拓展了义务逻辑图（OLG）的节点和边类型，包括空间、时间、当事人组、反驳性和逻辑分组结构，使得法律义务及其例外和层次结构有更细粒度的表示。该模型支持在具有上下文条件、先例和复杂触发条件的规则上进行结构化推理。
### Innovation
OLG++ 通过引入更丰富的节点和边类型，改进了之前的 LegalRuleML，提供了 native 支持的子类、空间约束和实现化的例外结构。它通过食品业务法规示例展示了其表达能力，并通过属性图查询支持了法律问题的回答。OLG++ 的例子证明了它比以往的基于图的法律知识表示模型更具有表现力。
### Conclusion
OLG++ 通过扩展 OLG 来更好地表示复杂的法规逻辑，提供更直接支持法律推理的功能，并展示了其在表达复杂法律关系上的优势。
## 7. `cs.AI` - 培养多模态智能：皮肤病诊断中的解释性推理与代理检索增强生成方法 [PDF](https://arxiv.org/pdf/2507.05520), [HTML](https://arxiv.org/abs/2507.05520)
### Authors
Karishma Thakrar,Shreyas Basavatia,Akshay Daftardar
### Background
该研究是2025年ImageCLEF MEDIQA-MAGIC挑战赛的第二版，由来自微软、斯坦福大学和巴塞罗那医院诊所的研究人员共同组织，旨在利用真实的病人查询和图像进行多模态皮肤科问题回答和分割。研究的主要目标是解决闭合视觉问答(CVQA)任务，即基于用户提交的图像和伴随的症状描述来选择多个选择中的正确答案。
### Innovation
该工作创新性地结合了三大核心组件：（1）将开源多模态模型从Qwen、Gemma和LLaMA家族进行微调，使其适应竞赛数据集；（2）引入了一种结构化推理层，用于综合和验证候选模型的输出；（3）集成代理检索增强生成（agentic RAG）技术，通过美国皮肤病学会的症状和条件数据库补充病人背景中的相关信息。这套方法在比赛中表现出了竞争力和高准确性。
### Conclusion
该研究不仅在技术上展示了可靠的多模态皮肤病诊断支持系统的潜力，更重要的是为解决远程医疗中的诊断决策难题提供了可能。诊断决策通常需要在有限的信息输入下进行，并且必须具有高精度和可解释性。通过模仿皮肤科医生在评估皮肤状况时的系统推理模式，该架构为更可靠的自动化诊断支持系统提供了实施路径。
## 8. `cs.AI` - Chat2SPaT: 一种基于大型语言模型的交通信号控制计划自动化管理工具 [PDF](https://arxiv.org/pdf/2507.05283), [HTML](https://arxiv.org/abs/2507.05283)
### Authors
Yue Wang,Miao Zhou,Guijing Huang,Rui Zhuo,Chao Yi,Zhenliang Ma
### Background
典型的交通信号灯预定时控制，用于管理信号交叉口和协调 arterial 需要大量的手动工作来创建和更新信号计划。当使用基于时间的计划（如每日或每周）时，一个交叉口可能需要多个计划，导致更多重复的参数输入。为此，该研究提出了 Chat2SPaT，一种方法，将用户关于信号控制计划的半结构化和含糊描述转换为准确的信号相位和定时（SPaT）结果，进而进一步转换为基于阶段或环的计划，以与智能交通系统（ITS）软件和信号控制器交互。Chat2SPaT 通过定制化的提示词，首先利用大型语言模型（LLM）理解并重新构建用户描述的计划为相位序列和相位属性结果的 json 格式。然后设计 Python 脚本来定位循环中的相位，解决交通信号控制的细微之处，并最终组装完整的交通信号控制计划。在聊天中，此管道可以迭代使用以进一步编辑计划。实验表明，Chat2SPaT 能够在超过 94% 的情况下准确生成英语和汉语计划，使用超过 300 个计划描述的测试数据集。Chat2SPaT 是评估 LLM 能否理解交通信号控制计划描述的第一个基准，为交通从业人员和研究人员提供了一个易于使用的计划管理系统。Chat2SPaT 是 LLM 在 ITS 领域实现更精确和多功能应用的一个潜在新模块。开源代码、提示词和测试数据集可通过此链接访问：[这个链接]（请替换为实际链接）
### Innovation
Chat2SPaT 提出了一种基于大型语言模型的方法，能够自动将用户关于交通信号控制计划的半结构化和含糊描述转化为精确的信号相位和定时（SPaT）结果，进一步生成结构化的信号控制计划。通过集成通用的提示词和定制的 Python 脚本，Chat2SPaT 显著减少了手动输入和编辑计划的重复工作，并且能够兼容英语和汉语计划描述。Chat2SPaT 提供了对交通信号控制计划管理的第一个基准，有助于评估 LLM 在理解和生成交通信号控制计划方面的潜力。此外，Chat2SPaT 为 LLM 在智能交通系统中的应用提供了一个新的模块，并开放了源代码和测试数据集供进一步开发和研究使用。
### Conclusion
Chat2SPaT 是交通信号控制计划管理的一个用户友好的自动工具，通过半结构化文本输入和语言模型生成精确的 SPaT 规则，极大地提高了工作效率。作为评估 LLM 能力的第一个基准，Chat2SPaT 可以作为智能交通系统领域中 LLM 应用的一个重要组成部分，提供了简便的界面和细粒度的控制。此项技术能够促进交通信号控制计划的管理，对未来智能交通系统的应用具有重要意义。
## 9. `cs.AI` - 向人工智能测量理论的构建之路 [PDF](https://arxiv.org/pdf/2507.05587), [HTML](https://arxiv.org/abs/2507.05587)
### Authors
Elija Perrier
### Background
文章旨在构建一套形式化的理论来衡量人工智能，提出了若干理由，论证了形式化衡量AI的重要性，以帮助研究者、从业者和监管者更好地进行系统对比、风险评估和理解AI能力的可操作性等核心问题。
### Innovation
文章构想了一种分层测量堆栈，并区分直接与间接可观察量。通过这些要素，提供了一条通往统一且可校准的AI现象分类系统的途径，有助于对照、工程和安全科学中的风险分析技术进行连接，提高AI评价的透明度和一致性，同时强调测量操作和尺度在定义AI能力中的核心作用。
### Conclusion
文章总结了构建这种统一AI测量理论的重要性。通过提供一种新的框架，促进了将前沿AI评估与传统工程和安全科学中的定量风险分析技术之间的联系，进一步表明了AI衡量理论的多学科整合潜力及其对学术研究、实际应用和法规制定的实际意义。
## 10. `cs.AI` - SingLoRA: 仅使用一个矩阵的低秩适应 [PDF](https://arxiv.org/pdf/2507.05566), [HTML](https://arxiv.org/abs/2507.05566)
### Authors
David Bensaïd,Noam Rotstein,Roy Velich,Daniel Bensaïd,Ron Kimmel
### Background
低秩适应（LoRA）在参数高效的大型预训练模型微调中取得了显著进步。LoRA 通过对模型的预训练权重添加两个较小矩阵的乘积来进行微调，这形成了一个低秩矩阵更新。然而，最近的研究表明，这两个矩阵之间的比例差距会经常导致训练动态不稳定，从而导致性能不佳。已经有研究尝试解决这一问题，并引入了一些解决方案，但效果仍有待提高。
### Innovation
本文提出了一种名为 SingLoRA 的新方法，通过学习一个单个低秩矩阵与其转置的分解来实现权重更新。这种方法避免了矩阵间比例冲突的问题，从而保证了优化的稳定性，并将参数量大约减少了一半。此外，文章还通过无限宽度神经网络框架对 SingLoRA 进行了分析，证明了其由设计上保证了特征学习的稳定性。实验结果表明，SingLoRA 在多个任务中表现出色，特别是在逻辑推理和图像生成任务中，其性能甚至超过了现有的 LoRA 方法。例如，在 Fine-tuning LLama 7B 时，使用 SingLoRA 达到了 91.3% 的准确率，而使用 LoRA 和 LoRA+ 分别为 89.1% 和 90.2%，并且仅使用了其参数预算的 60%。在图像生成任务中，SingLoRA 还显著提高了图像保真度，比 DoRA 和 LoRA 的得分更高。
### Conclusion
SingLoRA 通过单一低秩矩阵与其转置的分解来学习权重更新，该方法天然避免了矩阵间的比例冲突，实现了更稳定的训练动态和更少的参数数量。SingLoRA 在逻辑推理和图像生成任务中表现出色，验证了其通过简单设计实现低秩适应的优势。
## 11. `cs.AI` - SenseCF：基于LLM提示的反事实解释用于干预和传感器数据增强 [PDF](https://arxiv.org/pdf/2507.05541), [HTML](https://arxiv.org/abs/2507.05541)
### Authors
Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh
### Background
反事实解释（CFs）通过强调最小修改来改变结果，为机器学习预测提供以人类为中心的洞察。因此，CFs可以作为（i）异常预防的干预措施和（ii）训练鲁棒模型的增强数据。本文通过探索大型语言模型（LLMs），特别是GPT-4o-mini，在零样本和三样本设置下生成CFs。这项工作评估了该方法在两个数据集上的表现：AI-Readi旗舰数据集用于压力预测和一个公开的数据集用于心脏疾病检测。与传统的DiCE、CFNOW和NICE方法相比，我们的基于少样本的LLM方法在可行性（高达99%）、有效性（高达0.99）和稀疏性方面表现优异。此外，使用LLM生成的CFs作为增强样本可以提高下游分类器的性能（平均准确率提高5%），特别是在数据量较少的情况下。这显示了基于提示的生成技术在临床和生理预测任务中增强可解释性和鲁棒性的潜力。
### Innovation
本文创新性地使用大型语言模型（LLMs），特别是GPT-4o-mini，通过零样本和三样本设置生成反事实解释（CFs），在压力预测和心脏疾病检测数据集上的实证研究显示，这种方法在可行性、有效性和稀疏性方面表现优异，并且作为增强样本能够显著提高下游分类器的性能。
### Conclusion
基于提示的生成技术在临床和生理预测任务中具有增强可解释性和鲁棒性的潜力。研究结果表明，使用LLM生成的反事实解释可以作为增强样本，提高下游分类器的性能，特别是在数据稀缺的环境中。
## 12. `cs.AI` - 使用s(CASP)目标导向预测回答集编程系统对（应许的）模态运算符进行建模 [PDF](https://arxiv.org/pdf/2507.05519), [HTML](https://arxiv.org/abs/2507.05519)
### Authors
Gopal Gupta,Abhiramon Rajasekharan,Alexis R. Tudor,Elmer Salazar,Joaquín Arias
### Background
本文讨论了如何实现应许模态逻辑的问题。通过使用回答集编程（ASP）中的默认否定（失败即否定）和强否定，作者展示了如何优雅地表述应许和禁止的模态运算符。
### Innovation
提出了使用ASP的整体约束来表示应许模态逻辑中的义务和禁止。这种方法能优雅地解决应许模态逻辑中的各种悖论。
### Conclusion
通过使用s(CASP)目标导向预测回答集编程系统，作者展示了如何使用ASP中的默认否定和强否定来优雅地表达应许模态逻辑的模态运算符，从而有效地解决了这些悖论。
## 13. `cs.AI` - 使用大型语言模型生成的检索练习问题提升数据科学课程学生学习效果：一项实证研究 [PDF](https://arxiv.org/pdf/2507.05629), [HTML](https://arxiv.org/abs/2507.05629)
### Authors
Yuan An,John Liu,Niyam Acharya,Ruhma Hashmi
### Background
检索练习是一种经过验证的教育技术，已被证明能够显著提高学生的学习和知识保留。然而，生成高质量的检索练习问题通常非常耗时且劳动密集型，尤其是在快速发展的技术主题中。大型语言模型（LLMs）有可能通过根据提示生成问题来自动化这个过程，但LLMs生成的检索练习对学生学习的有效性尚未得到验证。
### Innovation
该研究的重点是使用LLMs根据课堂提示自动生成检索练习问题，并以大数据科学课程为背景进行了实证研究，比较了学生在一周内使用由LLMs生成的多项选择检索练习问题与未使用此类练习问题的学习成果。研究结果表明，接受LLMs生成的检索练习的学生的知识保留率平均为89%，而未接受此类练习的学生在一周内的成绩为73%。这项研究提供了使用LLMs生成检索练习问题支持学生学习的有效性和潜在可扩展性的证据。
### Conclusion
尽管LLMs生成的检索练习问题显示出令人鼓舞的效果和潜在的节省时间的益处，但必须谨慎对待，因为生成的问题质量会有所不同。教员在发布给学生之前仍需手动验证和修订生成的问题。这项研究指出了将检索练习整合到实时教学中的可行解决方案，并为未来的教育技术研究奠定了基础。
## 14. `cs.AI` - ADMC: 基于注意力的扩散模型用于缺失模态特征完成 [PDF](https://arxiv.org/pdf/2507.05624), [HTML](https://arxiv.org/abs/2507.05624)
### Authors
Wei Zhang,Juan Chen,Yanbo J. Wang,En Zhu,Xuan Yang,Yiduo Wang
### Background
多模态情感和意图识别对于自动化人机交互至关重要，旨在分析用户的语音、文本和视觉信息以预测其情感或意图。传感器故障或数据不完整导致的缺失模态是一个重要挑战。传统方法在尝试重建缺失信息时，常常由于过度耦合和生成过程不够精确而导致性能不佳。
### Innovation
我们提出了一种基于注意力的扩散模型（ADMC）用于缺失模态特征完成。该框架分别独立训练每个模态的特征提取网络，保持其独特性并避免过度耦合。基于注意力的扩散网络（ADN）生成与真实多模态分布紧密对齐的缺失模态特征，提高在所有缺失模态场景中的性能。此外，ADN的跨模态生成即使在满模态场景下也能提供更好的识别效果。
### Conclusion
我们的方法在IEMOCAP和MIntRec基准测试中达到了最先进的结果，证明了其在缺失和完整模态场景中的有效性。
## 15. `cs.AI` - LLMs are Introvert [PDF](https://arxiv.org/pdf/2507.05638), [HTML](https://arxiv.org/abs/2507.05638)
### Authors
Litian Zhang,Xiaoming Zhang,Bingyu Yan,Ziyi Zhou,Bo Zhang,Zhenyu Guan,Xi Zhang,Chaozhuo Li
### Background
社交媒体和生成型AI的指数级增长改变了信息传播的方式，增强了连接性但也加速了虚假信息的传播。从而理解信息传播动态并发展有效控制策略变得至关重要，以减少有害内容的影响。传统的SIR模型提供了基本见解，但无法充分捕捉在线互动的复杂性。高级方法，如注意力机制和图神经网络，提高了准确性，但通常忽略了用户心理和行为动态。大型语言模型（LLMs）因其类人推理能力提供了新的潜力，用于模拟信息传播的心理学方面。然而，早期实验显示LLM生成的行为与真实的人类动态之间存在显著差距，尤其是在立场检测和心理现实性方面。
### Innovation
研究提出了一种基于LLM的模拟环境，能够捕捉代理随时间变化的态度、情绪和回应。该研究通过社会信息处理理论的详细评估，发现了标准LLM训练中缺乏情感处理导致的主要差距，特别是在目标设定和反馈评估方面。为解决这些问题，提出了基于社会信息处理的连锁思维（SIP-CoT）机制，并结合情感引导的记忆，以改善对社会线索的解释、个性化的目标设置和反馈评估。实验结果证实，增强了SIP-CoT的LLM智能体更有效地处理社会信息，表现出更接近真实人类互动的态度、情绪和行为。
### Conclusion
这项研究强调了当前基于LLM的信息传播模拟中的关键限制，并展示了如何通过整合SIP-CoT和情绪记忆显著提高LLM智能体的社会智能和真实性。
## 16. `cs.AI` - 使用司法数据上的表学习进行城市级外国直接投资预测 [PDF](https://arxiv.org/pdf/2507.05651), [HTML](https://arxiv.org/abs/2507.05651)
### Authors
Tianxing Wu,Lizhe Cao,Shuang Wang,Jiming Wang,Shutong Zhu,Yerong Wu,Yuqing Feng
### Background
为了推进联合国可持续发展目标，外国直接投资（FDI）在促进持续、包容和可持续经济增长中起着关键作用。精确预测城市层面的FDI对于地方政府十分重要，传统的研究大多基于经济数据（如GDP）。然而，这些经济数据可能会被操控，影响预测的可靠性。因此，该研究尝试利用反映司法表现的大规模司法数据，因为司法性能影响本地投资安全和回报，来进行城市层面的FDI预测。通过构建一个包含十二万份公开判决书的司法绩效评价指标体系，并开发一种新的基于司法数据的表学习方法（TLJD），以提高FDI预测的准确性。
### Innovation
提出了基于司法数据的表学习方法（TLJD），这是一种创新的方法，它首次将表数据中的行数据和列数据结合起来，用于司法绩效指标编码，并使用混合专家模型调整不同指标的权重，考虑地区差异。这种方法克服了传统经济数据可能被操控的问题，提高了预测的准确性和可靠性。
### Conclusion
通过在城市层面的跨区和跨时间任务中进行广泛实验，结果表明TLJD方法在不同评价指标上优于其他十个最先进的基线方法，R2值达到至少0.92，证明了该方法的有效性和优越性。
## 17. `cs.AI` - 实时监测锂离子电池的健康状态 [PDF](https://arxiv.org/pdf/2507.05765), [HTML](https://arxiv.org/abs/2507.05765)
### Authors
Bruno Jammes(LAAS-ISGE),Edgar Hernando Sepúlveda-Oviedo(LAAS-ISGE),Corinne Alonso(LAAS-ISGE)
### Background
实时监测电池的健康状态（SoH）在微网中仍是一个重大挑战，因为操作约束限制了传统方法的使用。电池管理系统（BMS）通常依赖传统的预测方法，但这些方法在微网中可能不太适用。
### Innovation
提出了基于在充电阶段结束时的放电脉冲分析的创新方法。通过分析放电脉冲期间电池端电压演化等效电路模型的参数来估计SoH。该方法已经在实验数据上进行了演示，表明其相关性。
### Conclusion
如果该方法的性能得到进一步验证，可以直接集成到电池管理系统（BMS）中，并为连续运行下的优化电池管理打开新的可能性。
## 18. `cs.AI` - 对于增强现实环境中的多模态培训助理的细粒度视觉语言建模 [PDF](https://arxiv.org/pdf/2507.05515), [HTML](https://arxiv.org/abs/2507.05515)
### Authors
Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang
### Background
视觉语言模型（VLMs）对于使AI智能助手在多模态环境中解释和推理至关重要。但在增强现实（AR）培训中的应用尚未得到充分探索。本文介绍了专门为AR培训设计的综合数据集，其中包括系统化视觉语言任务。评估结果显示，即使最先进的模型如GPT-4o，在细粒度装配任务中也难以应对，最高F1分数仅为40.54%。这些结果强调了需要增强数据集、基准并进一步研究以提高视觉语言对齐的需求。这项研究不仅在技术上有所贡献，还具有更广泛的社会意义，特别是为盲人和视力障碍用户提供了公平获取由AI驱动的学习机会。我们提供了所有相关资源，包括数据集、源代码和评估结果，以支持研究界的工作。
### Innovation
本文介绍了一个专门为AR培训设计的综合数据集，包含了系统化的视觉语言任务，并对九个最先进的视觉语言模型进行了评估。结果显示了不足之处，提出了对数据集、基准和进一步研究的需求，以改善细粒度的视觉语言对齐。此外，该研究强调了公平获取由AI驱动的学习机会对盲人和视力障碍用户的重要性。
### Conclusion
研究结果表明，先进的视觉语言模型在细粒度装配任务中的性能仍有待提高。需要更多的研究和改进来增强数据集和模型，以更好地服务于多模态培训助手在增强现实环境下的应用。这项工作不仅提供技术贡献，还关注于支持盲人和视力障碍用户的平等问题。所有资源都已提供公共访问，以支持整个研究社区。
## 19. `cs.AI` - CogniPlay: 一项在通用游戏玩法中的在进行中的类人模型 [PDF](https://arxiv.org/pdf/2507.05868), [HTML](https://arxiv.org/abs/2507.05868)
### Authors
Aloïs Rautureau,Éric Piette
### Background
尽管人工智能系统已经在国际象棋、围棋或Dota 2等多种游戏中达到甚至超过了人类水平，但将其称为真正‘人类般’的系统仍不算准确。虽然这些系统取得了成功，但却无法复制人们在认知过程中所表现出的基于模式的直觉决策过程。
### Innovation
本文回顾了认知心理学的研究成果并讨论了以前将人类行为建模到人工代理的努力，同时引入了一个基于这些观察结果的工作中的人类般的通用游戏玩法模型：CogniPlay。
### Conclusion
通过CogniPlay模型，本文旨在更好地模拟人类在通用游戏玩法中的决策过程，从而创造出更接近人类的代理系统。
## 20. `cs.AI` - 临床AI模型自主审计与改进代理 [PDF](https://arxiv.org/pdf/2507.05755), [HTML](https://arxiv.org/abs/2507.05755)
### Authors
Lukas Kuhn,Florian Buettner
### Background
将AI模型应用于临床实践中面临一个关键挑战：尽管模型在基准测试中可以达到专家级别的性能，但在面对医学成像中的现实世界变异性时，模型可能会出现灾难性的失败。这些因素包括扫描硬件、光照或人口统计学的微小变化都会削弱模型的准确性。然而，目前针对这些可能灾难性失败情况的安全审计过程是定制且耗时的，并且临床实践者缺乏可访问且可解释的工具来揭示并修复隐藏的故障模式。
### Innovation
我们引入了ModelAuditor，这是一种自我反思的代理，它能够与用户对话，选择任务特定的指标，并模拟与医学相关的分布变化。ModelAuditor会生成可解释的报告，以解释拟部署期间性能可能发生的降级，并详细讨论具体的可能失败模式、根本原因及其缓解策略。它综合评估了三种真实世界的临床情况，结果显示ModelAuditor能够正确识别最新一代AI模型（如成功的SIIM-ISIC黑色素瘤分类器）在特定上下文下的故障模式。它针对性的建议能够在真实世界的数据分布变化中恢复15-25%的性能损失，大大超过了基准模型和最新的数据增强方法。这些改进通过多代理架构实现，并且在不到10分钟的时间内可在消费级硬件上执行，成本低于每审计0.5美元。
### Conclusion
ModelAuditor是一个能够提高临床AI模型可靠性的全面解决方案，通过多代理架构提升了性能，并能在快速、低成本的审计过程中揭示和修复模型的潜在故障模式。
## 21. `cs.AI` - 分解时序预测管道：一种模块化方法进行时序表示、信息提取和投影 [PDF](https://arxiv.org/pdf/2507.05891), [HTML](https://arxiv.org/abs/2507.05891)
### Authors
Robert Leppich,Michael Stenger,André Bauer,Samuel Kounev
### Background
自Transformer出现以来，时序预测取得了显著的进步，但仍面临挑战，特别是在有效序列表示、记忆构建和准确目标投影方面。时序预测仍是一个复杂的任务，需要有效的序列表示、有意义的信息提取和精确的未来预测。每个数据集和预测配置都构成了独特的任务，模型需要克服这些挑战才能生成准确的预测。
### Innovation
本文将时序预测管道分解为三个核心阶段：输入序列表示、信息提取和记忆构建、最后的目标投影。对每个阶段中的一系列架构配置进行了研究，评估不同模块（如卷积层用于特征提取、自注意力机制用于信息提取）在多种预测任务中的有效性。通过对七个基准数据集的评估，模型实现了最先进的预测精度，同时还极大地提升了计算效率，减少了训练和推理时间，并降低了参数数量。
### Conclusion
模型在多个基准数据集上实现了最新的预测准确性，同时还显著提高了计算效率，涵盖了训练和推理时间的减少以及参数量的降低。源代码可在该网址获得。
## 22. `cs.AI` - GTA1: GUI 测试时缩放代理 [PDF](https://arxiv.org/pdf/2507.05791), [HTML](https://arxiv.org/abs/2507.05791)
### Authors
Yan Yang,Dongxu Li,Yutong Dai,Yuhao Yang,Ziyang Luo,Zirui Zhao,Zhiyuan Hu,Junzhe Huang,Amrita Saha,Zeyuan Chen,Ran Xu,Liyuan Pan,Caiming Xiong,Junnan Li
### Background
图形用户界面 (GUI) 代理能够在跨平台（例如Linux）自主操作以完成任务，通过与视觉元素的交互实现任务执行。然而，任务规划过程中会遇到两个主要挑战：即任务规划中的不确定性（行动提案序列的选择是复杂的任务，因为存在多种有效的选择）和对目标进行精确操作的难度（复杂和高分辨率界面中精确地与视觉目标互动）。
### Innovation
该论文提出了一种新颖的方法来应对上述挑战。首先，通过引入测试时缩放方法，GTA1能够在每一步时从多个候选行动提案中选择最合适的提案，这种多路并发抽样方法在计算上有所牺牲，但能提高决策质量并减少任务执行步骤，从而提高整体性能。其次，该论文还提出了一种方法来提高选定行动提案与其相应的视觉部分的对接精度。核心观点是强化学习（RL）通过内在的目标对齐来促进视觉对接，奖励成功点击界面元素。
### Conclusion
 experiments show our methodology achieves state-of-the-art performance on various benchmarks. Specifically, GTA1-7B实现的准确率分别为 Screenspot-Pro 的 50.1%，Screenspot-V2 的 92.4%，OSWorld-G 的 67.7%。当我们将其与应用我们的测试时缩放策略的规划器配合使用时，它表现出色，例如 OSWorld 中的任务成功率为 45.2%。该论文开源了所有代码和模型。
## 23. `cs.AI` - 分歧的现实：皮肤病治疗计划的人工智能生成与评估的人类专家与人工智能对比分析 [PDF](https://arxiv.org/pdf/2507.05716), [HTML](https://arxiv.org/abs/2507.05716)
### Authors
Dipayan Sengupta,Saumya Panda
### Background
随着人工智能在医学领域的应用从诊断扩展到治疗，AI生成的治疗方案的评估成为一个重要挑战，特别是对于新的推理模型。本研究对比了人类专家和两个AI模型（一个通才和一个推理AI）生成的治疗方案，并由人类同行和一个高级的AI裁判进行了评估。
### Innovation
本研究采用了双重评估的方法，不仅由人类专家评估AI和人类生成的治疗方案，还使用了一个高级的AI裁判来评估，揭示了人类经验和数据驱动的AI算法之间的根本差异。这种对比方法突显了人类和AI评分之间的分歧，并为未来AI在医疗领域的集成提出新的方向。
### Conclusion
临床方案的质量评估取决于评分者的性质。一个先进的推理AI，在人类专家眼中表现较差，但在一个复杂的AI裁判看来却评价更高，揭示了经验和数据驱动的逻辑之间的巨大差距。这个悖论为AI在医疗领域的应用提出了关键挑战，表明未来的AI系统应是协同的、可解释的，能够弥合这种推理差距，以增强临床护理。
## 24. `cs.AI` - Affective-ROPTester: 在预测早产儿视网膜病变方面LLMs的能力与偏差分析 [PDF](https://arxiv.org/pdf/2507.05816), [HTML](https://arxiv.org/abs/2507.05816)
### Authors
Shuai Zhao,Yulin Zhang,Luwei Xiao,Xinyi Wu,Yanhao Jia,Zhongliang Guo,Xiaobao Wu,Cong-Duy Nguyen,Guoming Zhang,Anh Tuan Luu
### Background
尽管大型语言模型（LLMs）在各个领域取得了显著进步，但在预测早产儿视网膜病变（ROP）风险方面的能力尚未得到充分探索。该研究通过构建CROP数据集和开发Affective-ROPTester框架，旨在系统地评估LLMs在ROP风险分级中的预测能力和情感偏见。
### Innovation
引入了新型的CROP数据集，包含993个标注有低、中、高风险标签的入院记录，以及一种集成了三种提示策略（指令式、链式思考、上下文学习）的自动评估框架Affective-ROPTester，旨在从评估语言模型的内在知识和情感偏见，到引入外部医疗知识提高预测准确性，再到在提示级别上引入情感元素以考察不同情感框架如何影响模型的预测能力和偏见模式，全面分析并减轻LLMs在临床语言模型系统中的情感偏见。
### Conclusion
研究结果显示，仅依靠内在知识的LLMs在ROP风险预测方面的效果有限，但通过增强外部结构化输入则显著提升了预测准确性；同时，模型输出中存在情感偏见，特别是倾向于高估中高风险病例的风险，并且正面情感框架有助于减轻预测偏见。这些发现强调了情感敏感提示工程在提高诊断可靠性方面的重要性，并突显了Affective-ROPTester框架在评估和减轻临床语言模型系统中情感偏见方面的实用性。
## 25. `cs.AI` - MLlm-DR：基于多模态大语言模型的可解释抑郁症识別 [PDF](https://arxiv.org/pdf/2507.05591), [HTML](https://arxiv.org/abs/2507.05591)
### Authors
Wei Zhang,Juan Chen,En Zhu,Wenhong Cheng,YunPeng Li,Yanbo J. Wang
### Background
自动抑郁症诊断旨在通过分析访谈视频中的多模态信息来预测参与者的抑郁症评分。以往研究往往缺乏清晰的解释，说明这些评分是如何确定的，这限制了它们在临床实践中的应用。随着大语言模型（LLMs）的出现，提供了可能的路径来实现解释性抑郁症诊断，但当前的LLMs缺乏在访谈数据上的训练，导致直接使用时诊断性能较差。因此，本研究提出了一种名为MLlm-DR的新颖多模态大语言模型，该模型能够理解多模态信息输入并支持可解释的抑郁症诊断。
### Innovation
MLlm-DR通过将较小的LLMs和轻量级查询模块（LQ-former）结合起来。具体来说，较小的LLMs用于生成抑郁症评分及其相应的评估理据，同时构建一个健壮的训练数据集来微调它，以增强其在领域特定任务中的逻辑推理能力，同时保持其实用性。LQ-former从语音和视觉数据中捕捉抑郁症相关特征，帮助模型处理多模态信息，实现全面的抑郁症诊断。
### Conclusion
我们的方法在两个基于访谈的基准数据集CMDC和E-DAIC-WOZ上达到了最先进的结果，证明了其有效性和优越性。
## 26. `cs.AI` - MusiScene：利用MU-LLaMA进行场景想象及增强的视频背景音乐生成 [PDF](https://arxiv.org/pdf/2507.05894), [HTML](https://arxiv.org/abs/2507.05894)
### Authors
Fathinah Izzati,Xinyue Li,Yuxuan Wu,Gus Xia
### Background
人们在听音乐时能够想象出各种氛围和场景，并且会根据音乐的特性联想不同的画面场景。例如，缓慢忧郁的音乐可能会让人联想到失恋的场景，而欢快的旋律则可能让人联想到庆祝的场景。现有的研究中，人们已经开发出了一些音乐语言模型（例如MU-LLaMA），但它们主要关注于音乐本身的元素。本文旨在探讨是否可以开发一种能够进行音乐场景想象（MSI）模型，该模型能够在音乐和视频间提供跨模态信息，以更好地生成与音乐情境相关的描述。研究表明，现有的音乐字幕模型主要关注音乐本身的元素，而MusiScene则旨在生成能够与音乐情境互补的场景描述。通过构建一个包含3,371个视频-音频描述对的大规模数据集，并使用MU-LLaMA微调出MusiScene，来提升基于文本的Video Background Music Generation（VBMG）技术，使其能够生成更具情境相关性的描述文字。
### Innovation
本文的主要创新在于开发并验证了一个名为MusiScene的音乐字幕模型，该模型能够在音乐和视频间提供跨模态信息支持的场景想象能力。与现有的专注于音乐元素的模型相比，MusiScene提供了更具备情境相关性的描述，从而提升了视频背景音乐生成技术（VBMG）的质量。此外，通过构建大规模的数据集，并以此微调MU-LLaMA，为该研究提供了重要的数据支持和方法基础。
### Conclusion
研究通过MusiScene模型证明了其在生成与音乐情境相关性更高的字幕方面优于MU-LLaMA。通过利用MusiScene生成的场景想象字幕，进一步提升了文本引导下的视频背景音乐生成技术，这为音乐与视频的结合应用提供了新的思路和技术支持。
## 27. `cs.AI` - 通过信息检索增强基于规则的解释的可解释性 [PDF](https://arxiv.org/pdf/2507.05976), [HTML](https://arxiv.org/abs/2507.05976)
### Authors
Alessandro Umbrico,Guido Bologna,Luca Coraci,Francesca Fracasso,Silvia Gola,Gabriella Cortellessa
### Background
数据驱动的人工智能技术缺乏透明性，限制了它们在医疗决策过程中的解释性和接受度。特别是在乳腺癌淋巴结放疗后手臂淋巴水肿风险评估中，这一问题尤为明显。因此，需要提出一种可通过归因方法来提高可解释性的方法，以便更好地理解和接受基于可解释AI的预测结果。
### Innovation
提出了一种基于归因的方法，通过统计分析规则预测模型中的属性，并利用信息检索技术的标准度量来计算每个属性的预测相关性。这种方法为用户提供了可解释的信息，以了解风险因素对预测的影响。实验表明，与原始的可解释AI模型的输出相比，这种方法的输出具有更高的可解释性和实用性。
### Conclusion
用户研究表明，该方法在预测淋巴水肿风险时具有更高的可解释性和有效性，从而增强了基于规则的解释的透明度和实用性。
## 28. `cs.AI` - 基于大型语言模型的结构化和互动式PHQ-9抑郁筛查聊天机器人HopeBot的开发与评估 [PDF](https://arxiv.org/pdf/2507.05984), [HTML](https://arxiv.org/abs/2507.05984)
### Authors
Zhijun Guo,Alvina Lai,Julia Ive,Alexandru Petcu,Yutong Wang,Luyuan Qi,Johan H Thygesen,Kezhi Li
### Background
现有的静态工具，如患者健康问卷-9（PHQ-9），虽然能够有效地筛查抑郁症，但缺乏互动性和适应性。这项研究旨在开发一个名为HopeBot的聊天机器人，该机器人采用大规模语言模型（LLM），通过检索增强生成和实时澄清来实施PHQ-9问卷。在一项针对132名来自英国和中国的成人的内部研究中，参与者完成了自我管理员工版和聊天机器人版的问卷，结果显示评分一致性高（ICC = 0.91，45%完全一致）。
### Innovation
该研究开发了一个基于大型语言模型（LLM）的聊天机器人HopeBot，用于通过检索增强生成和实时澄清来执行PHQ-9抑郁筛查问卷。这项创新在于结合了聊天机器人与问卷调查的优势，使得抑郁筛查过程更加互动和个性化。此外，研究还发现聊天机器人的使用提高了用户信任度，特别是在处理敏感话题方面表现突出。
### Conclusion
研究结果显示，基于语音的LLM聊天机器人可以作为一种可行且低负担的工具，用于常规抑郁症筛查，同时提高抑郁筛查的有效性和用户满意度。总体而言，87.1%的参与者表示愿意再次使用或推荐HopeBot。
## 29. `cs.AI` - 特征引导的邻居选择方法在非专家评估模型预测中的应用 [PDF](https://arxiv.org/pdf/2507.06029), [HTML](https://arxiv.org/abs/2507.06029)
### Authors
Courtney Ford,Mark T. Keane
### Background
当前的可解释性人工智能（XAI）方法在生成清晰可理解输出方面面临挑战，尤其是对于缺乏领域专业知识的用户。本文通过引入特征引导的邻居选择（FGNS）方法解决了这个问题。FGNS通过同时利用局部和全局特征重要性来选择代表性的类例证，从而提高解释性。
### Innovation
该研究提出了一种后置处理方法（FGNS），它通过结合局部和全局特征的重要性来选择代表性的类例证，从而增强解释性。在一项针对坎纳拉语文本分类的研究中，利用FGNS方法，非专家用户更能够识别模型错误，并且在判断时更快更准确。此外，FGNS在选择邻居时不是简单地通过最小化特征空间距离来反映类特性，而是选择了更能代表类特性的邻居，从而实现了更一致的选择和类原型周围的更紧密聚类。
### Conclusion
研究结果支持FGNS作为更加符合人类评估方向的一步，尽管还需要进一步的工作来弥合解释质量和感知信任之间的差距。
## 30. `cs.AI` - 当前构建LLM驱动推理工具的方法是任意的——我们可以做得更好 [PDF](https://arxiv.org/pdf/2507.05886), [HTML](https://arxiv.org/abs/2507.05886)
### Authors
Aaron Bembenek(The University of Melbourne)
### Background
近年来，人们越来越兴奋于通过结合传统符号算法和大型语言模型（LLMs）来构建软件验证器、合成器和其他自动化推理（AR）工具。然而，当前用于构建这些神经符号AR系统的编程模型缺乏传统符号算法的安全性保证，也无法充分同步神经网络和符号推理，这限制了LLM推理的潜力。
### Innovation
本文提出了神经符号转换系统作为原则上计算模型，可以作为构建神经符号AR工具的基础设施。该模型通过逐步调整符号状态和直觉，并行操作状态转换，促成了逻辑推理能力的扩展，同时保持传统符号算法的强保证。
### Conclusion
通过提出的计算模型，可以重新构建逻辑编程语言中的推理过程，从而更好地实现逻辑推理的扩展并保留符号算法的强安全性保证。
## 31. `cs.AI` - BlueLM-2.5-3B 技术报告 [PDF](https://arxiv.org/pdf/2507.05934), [HTML](https://arxiv.org/abs/2507.05934)
### Authors
Baojiao Xiong,Boheng Chen,Chengzhi Wang,Daxiong Luo,Dongsheng Xu,Dongyang Liu,Fan Yang,Fangyuan Li,Fei Teng,Feng Wang,Fukang Qin,Fuquan Peng,Guanxin Tan,Guozhi Wang,Haibo Yu,Haohao Gao,Heng Liu,Hongbo Yang,Hongjian Zou,Houzheng Shen,Hu Meng,Huan Li,Hui Tan,Jiali Chen,Jianzhao Chen,Jinliang Zhu,Kai Wang,Lei Wu,Liangbing Liu,Liuyang Bian,Liyan He,Long Liu,Peiwen Li,Penggang Shi,Qi Ding,Rui Hu,Shuai Cao,Shuai Ren,Shuang Peng,Teng Xie,Weiji Chen,Weilin Xiang,Weixin Wu,Xi Yin,Xiaoxin Chen,Xu Chen,Yafei Wen,Yan Hu,Yanzhou Yang,Yina Xie,Yinghao Chen,Yixuan Liao,Yu Geng,Yuanjiang Ouyang,Yuanzhuo Yang,Yuehua He,Yushuai Peng,Zhaoxiong Wang,Zheng Wang,Zhibo Zhou,Ziyang Wu
### Background
本文介绍了专为边缘设备高效部署设计的大规模多模态语言模型（MLLM），BlueLM-2.5-3B，具有强大的通用性和推理能力。已有研究中，大多数模型只能在特定的模态中工作，且往往需要大量参数。作者尝试通过多样化的数据收集、关键数据重采样、混合异构强化学习以及高性能的训练基础设施来优化模型的性能，特别是在边缘设备上的高效运行。
### Innovation
首次提出一款3B规模的MLLM，同时支持思考模式和非思考模式，且允许对思考词汇预算进行显式控制。模型仅使用2.9亿参数就实现了优秀的大规模多模态能力，同时在纯文本基准测试中保持了竞争力。此模型在文本基准测试中表现与Qwen3-4B相当，而在线性评估中仅落后5%。在非思考模式下，其在大多数多模态基准测试中优于Qwen2.5-VL-3B。此外，BlueLM-2.5-3B还表现出出色的数据效率，所需的总训练数据比Qwen2.5-VL-3B和Qwen3-4B少。
### Conclusion
BlueLM-2.5-3B模型在边设备部署方面具有显著优势，同时保持了良好的性能。本文的研究结果证明了通过创新的数据处理和优化方法可以在有限资源下实现高性能的大规模多模态模型。为此领域的发展提供了一定的方向，并对研究社区具有重要意义。
## 32. `cs.AI` - Δ学习假设：在弱数据上进行偏好调优可以带来显著提升 [PDF](https://arxiv.org/pdf/2507.06187), [HTML](https://arxiv.org/abs/2507.06187)
### Authors
Scott Geng,Hamish Ivison,Chun-Liang Li,Maarten Sap,Jerry Li,Ranjay Krishna,Pang Wei Koh
### Background
语言模型的改进通常依赖于训练数据质量的提升，但在缺乏强烈监督的情况下，这种方法受到限制。本文展示了仅由个体较弱的数据点组成的配对偏好数据能够带来超越每个个体数据点强度的收益。研究者提出Δ学习假设，认为两点之间的相对质量差异足以通过偏好调优驱动学习，即使在弱数据上的监督微调可能有害。
### Innovation
研究者提出Δ学习假设，通过在较小的模型响应与更小模型输出之间创建配对偏好数据，进行偏好调优，即使这些数据较弱，也能带来显著的性能提升。实验结果证实，即使使用较弱的监督者，这种方法也能达到与使用更强监督者相当的效果，展示了一种更简单且成本效益更好的开放式后训练配方。这种假设还通过逻辑回归证明，两个较弱教师模型之间的性能差距能为提升较强学生模型提供有用信号。
### Conclusion
研究表明，模型可以从通常被认为是较弱的配对数据中出人意料地学习，从而提供了一种新的指导思路，在缺乏强监督的情况下仍能达到优异的性能，简化了先进模型的后训练过程。
## 33. `cs.AI` - 基于人工智能的需求预测与负载平衡优化医疗系统能源使用：一个实际案例研究 [PDF](https://arxiv.org/pdf/2507.06077), [HTML](https://arxiv.org/abs/2507.06077)
### Authors
Iman Rahimi,Isha Patel
### Background
在医疗设施中，需求波动性对运营效率和可持续性构成挑战，传统方法往往不够有效，导致能源管理中的低效和高成本。因此，急需有效的能源管理系统来提高能源效率和降低成本，提升可持续性。
### Innovation
该研究提出了一个结合长短期记忆网络（LSTM）、遗传算法（GA）和SHAP（Shapley值解释）的人工智能框架，专门用于医疗能源管理。该框架在预测复杂的非线性需求模式方面表现出色，特别是在医疗能源预测领域的应用上。此外，遗传算法用于优化模型参数和改进负载平衡策略，以实现对实时能源波动的自适应响应。SHAP分析通过解释不同特征对预测的影响进一步提高了模型的透明度，增强了决策过程中的信任度。
### Conclusion
该研究所提出的集成LSTM-GA-SHAP方法为提高预测准确性、增强能源效率和推动医疗设施的可持续性提供了强有力的支持。未来的研究可能探索该方法的实时应用和与强化学习的结合，以实现持续优化。这项研究为医疗能源管理中的AI应用奠定了坚实的基础，强调了其扩展性、效率和抵御能力的潜力。
## 34. `cs.AI` - 对齐文本评分规则 [PDF](https://arxiv.org/pdf/2507.06221), [HTML](https://arxiv.org/abs/2507.06221)
### Authors
Yuxuan Lu,Yifan Wu,Jason Hartline,Michael J. Curry
### Background
评分规则通过将预测与真实结果进行评分来促使战略代理报告概率预测。如果从代理的角度来看，报告真实信念能最大化预期评分，则该评分规则被称为适当的。随着语言模型的发展，Wu 和 Hartline（2024）提出了将文本信息的获取问题转化为数值信息（即概率信息）获取问题的方法，并能保证文本信息获取的可验证正确性。然而，并非所有适当的评分规则都能很好地与人类对文本的偏好对齐。因此，本文旨在设计一种针对文本的对齐评分规则（ASR），通过最小化适当评分规则与参考评分（例如人类评分）之间的均方误差来实现这一目标，从而更好地与人类偏好对齐并保持适当的特性。
### Innovation
本文提出了针对文本的对齐评分规则（ASR），通过优化与最小化适当评分规则与参考评分之间的均方误差，以更好地与人类偏好对齐并保持适当性。相较于之前的其他方法，ASR 在对齐人类偏好方面表现更优，同时保持了适当的特性。
### Conclusion
本文设计的对齐评分规则（ASR）能够更好地与人类对文本的偏好对齐，同时保证了适当性。实验结果表明，ASR 在对齐人类偏好方面优于之前的方法。
## 35. `cs.AI` - 战争中的集成者：人机辅助武力使用决策中的中介 [PDF](https://arxiv.org/pdf/2501.06861), [HTML](https://arxiv.org/abs/2501.06861)
### Authors
Dennis Müller,Maurice Chiodo,Mitja Sienknecht
### Background
人工智能系统的集成正在改变军事领域的决策方式。这种集成将开发人员、集成者和用户这三个不同的行为者群体联系在一起，并嵌入到政治和军事系统的(预-)现有组织和系统结构中。本文重点关注如此复杂的以技术为基础的社会系统中的集成者这一重要但常被忽视的群体的角色。在政治和军事系统的武力使用决策中，集成者负责连接开发人员和用户群体，这一过程需要其对其他群体的活动、视角和规范有深刻的理解。文章探讨了在人机辅助的武力使用决策中，集成者面临何种挑战和不足，以及如何应对这些挑战。这个问题通过三步来解决：首先，将不同群体的行为者与人工智能系统的关系概念化为社会技术系统；其次，识别社会技术系统中的人机团队协作在武力使用决策中的挑战；最后，提供政策建议以解决这种系统中的不足之处，以更好地将人工智能系统用于武力使用决策结构中。
### Innovation
本文创新地将人工智能系统应用于军事领域的决策过程，重点关注集成者的角色，创新在于深入探讨了技术本身、集成者在社会技术系统中的角色以及人机交互带来的挑战，并提供了具体的政策建议来改善这些系统的运行效率和效果。
### Conclusion
本文提出，要更好地将人工智能系统应用于军事领域，必须充分理解和解决技术本身、集成者角色以及人机交互所引发的挑战，以制定有效的政策助力这些系统的优化和改进。
## 36. `cs.AI` - 关于可以逻辑推导闭合并且具有最小改变的洛克信念 [PDF](https://arxiv.org/pdf/2507.06042), [HTML](https://arxiv.org/abs/2507.06042)
### Authors
Tommaso Flaminio,Lluis Godo,Ramón Pino Pérez,Lluis Subirana
### Background
洛克命题的背景下，代理信念集通过信任度（信念度）定义，并且用概率术语描述。尽管这种方法对研究有重要贡献，但也有局限性，特别是在信念变化理论中使用时显得不那么进步。例如，洛克信念集一般不是经典逻辑推理的闭合集。本文旨在提供两种可用于经典逻辑闭合的信念集的表征，并提出了如何通过最小修订实现基于修订的最小变化的概率更新方法，以在最小改变信念集的情况下吸收新信息。
### Innovation
文章提供了两种表征可以经典逻辑闭合的信念集的方法，并提出了一种基于修订最小化的方法来进行概率更新，从而仅通过最少的修订就让现有信念集合吸收新的信息。这一方法可以实现对信念集的逻辑闭合和最小修订的双重目标，解决了洛克信念集在逻辑闭合方面的局限性问题，为信念更新提供了一个新的范式。
### Conclusion
本文展示了如何通过最小的修订来确保信念集可以通过逻辑推理闭合，并提出了一个基于修订最小化的概率更新方法。这种方法能够在保持现有信念集不变的情况下，有效地吸收新信息。
## 37. `cs.AI` - 无线多任务预测的基础模型 [PDF](https://arxiv.org/pdf/2507.05938), [HTML](https://arxiv.org/abs/2507.05938)
### Authors
Yucheng Sheng,Jiacheng Wang,Xingyu Zhou,Le Liang,Hao Ye,Shi Jin,Geoffrey Ye Li
### Background
随着移动通信网络的复杂性和动态性增加，准确预测关键系统参数（如信道状态信息（CSI）、用户位置和网络流量）变得至关重要。传统的基于深度学习（DL）的方法虽已广泛应用到这些预测任务中，但往往难以在不同场景和任务之间泛化。
### Innovation
本文提出了一种用于无线网络的多任务预测的统一基础模型，该模型支持多种预测区间。该模型通过多元分解统一不同任务、编码粒度以增强区间意识，并使用因果Transformer作为基础进行精确预测。此外，引入了训练期间的补丁遮罩策略，以支持任意输入长度。
### Conclusion
所提出的基础模型在大规模数据集上进行训练后，展现了对未见过的场景的强大泛化能力，并在无学习新任务的情况下，超越了传统的全样本基准方法，实现了新的任务性能的大幅提升。
## 38. `cs.AI` - OpenAgentSafety：评估真实环境中AI代理安全性的全面框架 [PDF](https://arxiv.org/pdf/2507.06134), [HTML](https://arxiv.org/abs/2507.06134)
### Authors
Sanidhya Vijayvargiya,Aditya Bharat Soni,Xuhui Zhou,Zora Zhiruo Wang,Nouha Dziri,Graham Neubig,Maarten Sap
### Background
近期AI代理在解决复杂日常任务方面取得了进展，如排程和客户服务，使其能够在真实环境中部署。然而，这些代理的安全性可能带来潜在风险，需要严格评估。尽管以前有一些基准来评估代理的安全性，但它们多依赖于模拟环境、狭窄的任务领域或不现实的工具抽象。
### Innovation
本文介绍了一种名为OpenAgentSafety的全面且模块化的框架，用于评估代理在八个关键风险类别上的行为。与先前工作不同，该框架评估与真实工具交互的代理，包括网页浏览器、代码执行环境、文件系统、bash shell和消息平台；并支持超过350项多轮、多用户任务，涵盖良性与敌意用户意图。OpenAgentSafety设计易于扩展，允许研究人员在无需大量努力的情况下添加工具、任务、网站和敌对策略。该框架结合规则分析与LLM判断，以检测明示和隐含的不安全行为。
### Conclusion
实证研究表明，在使用五种主要的LLMs的情况下，有51.2%至72.7%的安全脆弱任务存在不安全行为，突显了关键安全漏洞，并提出了在实际部署前需要加强保护措施的必要性。
## 39. `cs.AI` - 算法碰撞问题：缓解互联世界中未预见的风险 [PDF](https://arxiv.org/pdf/2505.20181), [HTML](https://arxiv.org/abs/2505.20181)
### Authors
Maurice Chiodo,Dennis Müller
### Background
随着人工智能（AI）和其他自主算法系统的广泛应用，世界面临着新的系统性风险。人们往往聚焦于单个算法的功能，但算法之间的交互构成了一个值得注意且被低估的风险源，特别是当这些系统在无互相意识的情况下运行，或当部署者对实际存在的算法生态系统缺乏了解时。这种交互可能导致难以预见的负面结果迅速升级，从市场崩溃和能源供应中断到潜在的物理事故和公众信任的 erosion，往往超出人类监控和法律干预的能力。当前的治理框架因其无法透彻了解这种复杂的交互生态系统而显得不足.
### Innovation
本文概述了这一挑战的本质，并提出了通过逐步系统注册、部署许可证框架和增强监控能力来提高透明度和问责性的初步政策建议。
### Conclusion
当前的治理框架无法有效应对算法系统复杂交互带来的挑战，因此需要采取新措施，包括提高透明度和增强问责制，以更好地管理和监控这种情况。
## 40. `cs.AI` - 大型语言模型在地质工程应用中的领域适应 [PDF](https://arxiv.org/pdf/2507.05613), [HTML](https://arxiv.org/abs/2507.05613)
### Authors
Lei Fan,Fangxue Liu,Cheng Chen
### Background
随着大型语言模型（LLMs）的迅速发展，它们正在为地质工程和工程地质学开辟新的机会。尽管通用的大语言模型具备广泛的适用性，但在地质工程中的有效应用通常需要针对特定领域的定制。
### Innovation
本文首次全面介绍了大语言模型在地质工程中的适应和应用。概述了针对地质领域的方法论，包括提示工程、检索增强生成、领域适应预训练和微调。文章还探讨了地质适应性大语言模型的前沿应用，如地质解释、地下表征、场地规划、设计计算、数值建模、安全和风险评估以及教育辅导。
### Conclusion
研究结果为希望将LLMs集成到地质工程实践中的从业者提供了宝贵的资源，同时也为学术界进一步研究奠定了基础。针对这个跨学科领域的未来研究方向也进行了分析和识别。
## 41. `cs.AI` - 计算归约，故障模式及法律-道德责任形式化的人工智能环内操作：正式化 [PDF](https://arxiv.org/pdf/2505.10426), [HTML](https://arxiv.org/abs/2505.10426)
### Authors
Maurice Chiodo,Dennis Müller,Paul Siewert,Jean-Luc Wetherall,Zoya Yasmine,John Burden
### Background
不同的人工智能环内操作（HITL）设置之间在法律合规性和安全性方面存在显著差异。本文旨在探索选择不同HITL设置的新方法，发现责任分配与人工智能技术可解释性之间存在不可避免的权衡。文章将HITL设置形式化为从计算可归约理论中抽象出来的不同机器，探讨各种HITL失败模式，并指出英国和欧盟法律框架中对某些HITL设置的关注可能无法实现预期的伦理、法律和社会技术结果。
### Innovation
文章利用计算可归约理论中的‘算子机器’概念，正式化了不同类型的人机交互模式，分别对应完全函数、多项式归约和图灵归约。进一步提出了分类方法，展示HITL设置的局限性，指出法律和道德责任分配的问题，并建议法律应该认可不同HITL设置的有效性，合理分配责任，避免不必要的‘道德责任’归咎。
### Conclusion
HITL设置涉及许多技术设计决策，并可能遭受超出人类控制范围的失败。这为理解HITL设置带来新的分析视角，有助于指导人工智能开发者和立法者更好地设计HITL系统，以实现预期目标。
## 42. `cs.AI` - LLM辅助的可视化重定位挑战与机遇 [PDF](https://arxiv.org/pdf/2507.01436), [HTML](https://arxiv.org/abs/2507.01436)
### Authors
Luke S. Snyder,Chenglong Wang,Steven M. Drucker
### Background
尽管网页上充斥着各种可视化实例，但将现有定制的图表实现重新调整到新的数据集仍然困难重重、耗时且繁琐。这个过程要求作者既熟悉示例的实现方式，也要理解新的数据集如何需要进行调整以适应示例代码。近年来，大规模语言模型（LLMs）的进步使得可以通过高级用户提示自动调整代码，从而降低可视化重定位的门槛。
### Innovation
本研究对LLMs如何协助可视化重定位及其潜在局限性进行了描述和评估。通过跨多个具有不同复杂性的数据集和图表，研究了两种方法：一种是直接向LLM模型提供代码作为文本输入，使其生成和调整代码；另一种是使用更受限的程序合成管道，LLM根据示例代码和数据的性质提供结构信息来引导代码构建过程。
### Conclusion
我们发现，当新数据没有适当转换时，两种方法都会遇到困难，提出了对未来重定位系统重要设计建议。
## 43. `cs.AI` - 因果抽象中的可识别性：一种准则层次结构 [PDF](https://arxiv.org/pdf/2507.06213), [HTML](https://arxiv.org/abs/2507.06213)
### Authors
Clément Yvernes,Emilie Devijver,Marianne Clausel,Eric Gaussier
### Background
从观察数据中识别治疗效果通常需要假设一个完全指定的因果图。然而，在复杂或高维场景下，这样的图很少是已知的。为克服这一限制，最近的研究探讨了因果抽象（简化表示但保留部分因果信息）的应用。本文考虑了作为因果图集合的因果抽象，并关注在这些集合中因果查询的可识别性。提出了几种在该背景下形式化化的可识别性标准，并将这些标准组织成一个结构化层次，以更清晰地理解和解释在不同因果知识水平下能够识别的内容。
### Innovation
本文的主要贡献是将这几个可识别性标准组织成一个结构化的层次，通过这种层次结构更加清晰地展示了在因果知识的不同水平下能够识别的内容。此外，还通过文献中的示例来说明框架，并提供了在完整因果知识不可用时推理可识别性的工具。
### Conclusion
基于因果抽象的可识别性标准层次结构有助于更全面地理解不同因果知识条件下能够识别的内容，并提供了一种在缺乏完整因果知识时推理可识别性的工具。
## 44. `cs.AI` - FEVO：大型语言模型中的金融知识扩展与推理演进 [PDF](https://arxiv.org/pdf/2507.06057), [HTML](https://arxiv.org/abs/2507.06057)
### Authors
Bo Pang,Yalu Ouyang,Hangfei Xu,Ziqi Jia,Panpan Li,Shengzhao Wen,Lu Wang,Shiyong Li,Yanpeng Wang
### Background
大型语言模型（LLMs）在数学和编程等领域取得了显著性能提升，但在金融领域应用的研究仍较为有限，尤其是在需要领域特定知识的场景中。本文背景正是着眼于填补这个研究空白。
### Innovation
本文介绍了一种名为FEVO的多阶段增强框架，用于提升大语言模型在金融领域的性能。FEVO框架通过持续预训练(CPT)扩充金融领域知识、监督微调(SFT)使模型掌握结构化复杂的推理模式、强化学习(RL)进一步将扩充的知识与学习到的逻辑推理相结合。为了确保有效的训练和优化，引入了前沿推理模型和基于规则的过滤来创建FEVO-Train高质数据集以应对不同的后训练阶段。通过这一框架，一系列FEVO系列模型（C32B、S32B、R32B）从Qwen2.5-32B开始训练并进行评估。
### Conclusion
FEVO系列模型在七个基准测试中验证了其金融市场和通用能力，并在五个金融市场基准测试中达到了最先进的性能，超过了很多更大的模型和专门模型。特别是FEVO-R32B相比仅有强化学习训练的FEVO-R32B-0性能明显更佳，这进一步证实了金融领域知识扩展和结构化逻辑推理提取的有效性。
## 45. `cs.AI` - ABench-Physics: 通过高难度和动态物理问题评估大语言模型的物理推理能力 [PDF](https://arxiv.org/pdf/2507.04766), [HTML](https://arxiv.org/abs/2507.04766)
### Authors
Yiming Zhang,Yingfan Ma,Yanmei Gu,Zhengkai Yang,Yihong Zhuang,Feng Wang,Zenan Huang,Yuanyuan Wang,Chao Huang,Bowen Song,Cheng Lin,Junbo Zhao
### Background
大语言模型（LLMs）在数学和编程领域表现出色，但在物理学领域的应用则尚处于探索阶段，物理问题需要精确的计算能力、深刻的概念理解和物理建模技能，现有的基准测试往往因为难度有限、采用多项选择题格式和静态评估设置而无法充分评估模型的物理推理和泛化能力。因此，迫切需要一个新的评估基准来全面测试LLMs在物理推理和泛化能力方面的表现。
### Innovation
本文提出了ABench-Physics，这是一种新的基准测试，用于严格评估LLMs的物理推理和泛化能力。ABench-Physics设计了两个部分：Phy_A包含了400个多达研究生水平或奥林匹克级别的静态问题，Phy_B则根据动态条件变化测试模型的稳固性。这个问题集要求提供精确的数值答案，具有严格的形式和容差约束。评估结果显示，最先进的LLMs在物理推理方面存在显著差距，特别是在动态版本的数据上表现不佳。ABench-Physics为LLMs的科学研究提供了一个具有挑战性和诊断性的框架，以推动该领域的进步。
### Conclusion
ABench-Physics为评估大语言模型在复杂物理推理任务上的表现提供了一个前所未有的挑战性测试平台，揭示了当前模型在物理推理和动态适应性方面的局限性，为后续研究明确指出了改进方向。
## 46. `cs.AI` - 将图神经网络中的过度平滑现象重新思考：自安德森 localization 的视角 [PDF](https://arxiv.org/pdf/2507.05263), [HTML](https://arxiv.org/abs/2507.05263)
### Authors
Kaichen Ouyang
### Background
图神经网络（GNNs）由于其强大的表示能力，在图数据分析中显示出巨大的潜力。然而，随着网络深度的增加，过度平滑的问题变得越来越严重，导致节点表示失去独特性。
### Innovation
通过将过度平滑现象与安德森 localization 类比，引入了参与度作为度量标准。研究发现，随着 GNN 的深度增加，节点特征在多层消息传递后变得同质化，类似于无序系统中振动模式的行为。在此基础上，系统地回顾了无序系统中安德森 localization 行为与 GNN 中过度平滑行为之间的潜在联系，并进行了理论分析，提出了通过减少信息传播中的无序以缓解过度平滑的可能性。
### Conclusion
通过减少信息传播中的无序，有可能缓解 GNN 中的过度平滑现象。
## 47. `cs.AI` - 用户行为预测作为一种通用、稳健、可扩展且低成本的评估策略，用于估算LLMs的泛化能力 [PDF](https://arxiv.org/pdf/2507.05266), [HTML](https://arxiv.org/abs/2507.05266)
### Authors
Sougata Saha,Monojit Choudhury
### Background
由于数据污染的问题，衡量大规模语言模型（LLMs）的泛化能力是具有挑战性的。随着模型的增大和计算成本的降低，确保任务和测试案例在训练阶段不会出现将变得几乎不可能。以往的研究认为，知识检索和推理任务不是衡量泛化能力的理想选择，因为LLMs并不是为特定任务而训练的。因此，建议使用用户行为预测作为衡量泛化能力的一个理论依据坚实、可扩展且稳健的替代方案。用户行为预测是个人化的重要组成部分。而研究还发现，过往的评价框架可能不如预期准确地反映出实际泛化能力。
### Innovation
提出了一个新的框架用于用户行为预测，并在电影和音乐推荐数据集上对GPT-4o、GPT-4o-mini和Llama-3.1-8B-Instruct模型进行了测试。实验结果显示GPT-4o比GPT-4o-mini和Llama具有更好的泛化性能，尽管所有模型都有改进的空间，尤其是在Llama方面。
### Conclusion
用户行为预测作为一种评估策略能够更准确地估计LLMs的泛化能力，具有通用性、稳健性、可扩展性和低成本等优点。尽管当前研究中的模型具有一定的泛化性能，但仍然存在改进的空间，特别是对于像Llama这样的模型，因为它们的性能提升空间较大。
## 48. `cs.AI` - 一种用于多代理教育临床情景模拟中临床推理辅助的模糊监督代理设计 [PDF](https://arxiv.org/pdf/2507.05275), [HTML](https://arxiv.org/abs/2507.05275)
### Authors
Weibing Zheng,Laurah Turner,Jess Kropczynski,Murat Ozer,Seth Overla,Shane Halse
### Background
在临床情景训练中辅助医学学生进行临床推理（CR）仍然是医学教育中的一个长期挑战。多代理教育临床情境模拟（MAECSS）平台引入了一种新的组件——模糊监督代理（FSA），通过使用模糊推理系统（FIS），结合预先定义的模糊规则库来实时解释学生与专业临床代理的交互，这些规则涉及专业性、医学相关性、伦理行为以及情境性干扰。FSA旨在通过分析学生在实际中的决策过程，提供适应性和情境感知的反馈，并在学生遇到困难时提供帮助。
### Innovation
设计了一种以模糊推理系统为基础的监督代理（FSA），能够在多代理教育临床情景模拟（MAECSS）中实现对学生的临床推理过程进行实时分析，并提供精确适应的反馈帮助。FSA的技术框架和设计理由强调了其在基于模拟的医学教育中的可扩展性、灵活性和人性化监督潜力。
### Conclusion
未来的工作将包括对该监督代理的实证评估，并将其整合到更广泛的教育环境中。更多详细的的设计和实现可以在提供的链接中找到。
## 49. `cs.AI` - FuzzFeed：使用大规模语言模型和模糊测试自动生成最弱前期条件的方法 [PDF](https://arxiv.org/pdf/2507.05272), [HTML](https://arxiv.org/abs/2507.05272)
### Authors
Daragh King,Vasileios Koutavas,Laura Kovacs
### Background
最弱前期条件（WP）描述了所有满足给定后置条件的程序终止执行的初始状态集合。生成WP在验证、运行时错误检查等多个领域具有实际应用意义。本文提出了一种结合大型语言模型（LLMs）和模糊测试的方法来生成WP，并介绍了一种称为Fuzzing Guidance（FG）的概念，它通过程序执行反馈指导LLMs生成正确的WP。同时，FG利用模糊测试来验证候选WP的有效性，并将这些反馈信息提供给LLMs作为上下文优化的依据。我们利用一组全面的确定性数组程序基准集在Java中验证了该方法的有效性，并证明LLMs能够生成可行的WP，而FG能够进一步提高其生成能力。
### Innovation
提出了一种结合LLMs和模糊测试的方法来生成最弱前期条件，并引入了Fuzzing Guidance（FG）。FG利用程序执行反馈指导LLMs生成正确的WP，并通过模糊测试验证候选WP的有效性。这种方法有效地提高了生成WP的准确性和可靠性。
### Conclusion
我们使用一系列Java中的确定性数组程序进行了实验，证明了LLMs能够生成可行的WP，同时FG通过提供反馈信息进一步提升了生成的准确性。
## 50. `cs.AI` - CORE: 通过静态分析任务评估LLMs的代码推理能力 [PDF](https://arxiv.org/pdf/2507.05269), [HTML](https://arxiv.org/abs/2507.05269)
### Authors
Danning Xie,Mingwei Zheng,Xuwei Liu,Jiannan Wang,Chengpeng Wang,Lin Tan,Xiangyu Zhang
### Background
大型语言模型（LLMs）已在多种软件工程领域得到广泛应用，如代码生成、程序修复和漏洞检测。这些应用需要理解代码的深层次语义，包括值的传播、控制流程及程序元素之间的依赖关系。然而，现有基准测试通常侧重于端到端的结果评估，例如代码是否正确修复或生成，这使得LLMs在程序语义推理方面的潜力未能得到充分挖掘。
### Innovation
本文提出了CoRe，一个高质量、经过人工验证的基准测试，旨在评估LLMs在基本静态分析任务上的表现。CoRe包含12,553个涉及C/C++、Java和Python语言编写的程序的数据依赖、控制依赖和信息流的任务实例。通过提出一种基于结构覆盖率和依赖深度的语义感知多样化采样策略，CoRe确保了任务的语义多样性和推理复杂性。研究还评估了10种主流LLMs，结果显示这些模型在识别依赖方面表现良好，但在需要深层次语义理解和多步推理的任务中仍存在困难。进一步的定性分析揭示了复杂控制结构和反向依赖模式等关键挑战，为改善LLMs的代码推理能力提供了见解。
### Conclusion
本文展示了10种主流LLMs在静态分析任务上的表现，尽管模型在识别依赖方面表现良好，但在需要更深层次语义理解和多步推理的任务上仍然存在困难。研究提出了一个语义感知的多样化采样策略，该策略有助于评估LLMs的代码推理能力。研究结果强调了LLMs在处理复杂代码结构和深度语义理解方面的局限性，并提供了进一步改进的潜在方向。
## 51. `cs.AI` - ReservoirChat：ReservoirPy的LLM和知识图谱增强的交互式文档 [PDF](https://arxiv.org/pdf/2507.05279), [HTML](https://arxiv.org/abs/2507.05279)
### Authors
Virgile Boraud(Mnemosyne),Yannis Bendi-Ouis(Mnemosyne),Paul Bernard(Mnemosyne),Xavier Hinaut(Mnemosyne)
### Background
本文介绍了使用ReservoirPy库来辅助代码开发以及解答复杂问题的一种工具，通过集成检索增强生成（RAG）和知识图谱来提高大型语言模型（LLMs）的能力。该方法旨在减少虚构内容并提高生成回答的准确性，提供类似于ChatGPT的交互式体验，专为ReservoirPy设计，使用户能够编写、调试并理解Python代码，同时访问可靠的领域特定见解。评估结果显示，在常识问题上，像ChatGPT-4o和NotebookLM这样的专有模型表现稍好，但在编码任务上，本文的方法优于基本模型Codestral-22B，并显示出明显的改善效果。
### Innovation
该工具结合了ReservoirPy库和Retrieval-Augmented Generation（RAG）及知识图谱，旨在提高LLMs在代码开发和复杂问题解答方面的辅助能力，减少虚构内容并提高生成回答的准确性。系统的交互体验类似于ChatGPT，特别针对ReservoirPy，提供编程支持的同时，增加了可靠和特定领域的知识访问。实验表明，尽管某些专有模型在常识问题上表现稍好，但在编程任务上，该工具明显优于其基线模型Codestral-22B。
### Conclusion
经评估，虽然ChatGPT-4o和NotebookLM等专有模型在一般知识问题上表现较好，但本研究的方法在编程任务上显著优于其基础模型Codestral-22B，提供了更为精准和可靠的代码开发支持。
## 52. `cs.AI` - 大型语言模型中的主动防御策略对抗误导信息 [PDF](https://arxiv.org/pdf/2507.05288), [HTML](https://arxiv.org/abs/2507.05288)
### Authors
Shuliang Liu,Hongyi Liu,Aiwei Liu,Bingchen Duan,Qi Zheng,Yibo Yan,He Geng,Peijie Jiang,Jia Liu,Xuming Hu
### Background
大语言模型（LLMs）在关键领域中的广泛应用加剧了由算法生成的误导信息带来的社会风险。不同于传统的虚假内容，LLM生成的误导信息可以自我强化、非常可信，并且能够在多种语言中迅速传播，而传统的检测方法难以有效应对。以往的研究主要侧重于被动的后检测方法，而不是前瞻性的缓解策略。
### Innovation
本文提出了一种前瞻性的防御框架，即“三大支柱”框架，该框架包括：(1) 知识可信度，加强训练和部署数据的完整性；(2) 推理可靠性，嵌入自我修正机制以增强推理过程；(3) 输入鲁棒性，提高模型接口对抗攻击的弹性。通过综述现有技术并进行比较元分析，展示了前瞻性的防御策略相比传统方法可以在误导信息防治上提高63%的效果，尽管这需要较大的计算开销和泛化挑战。
### Conclusion
本研究认为未来的研究应聚焦于共同设计稳健的知识基础、推理认证和抗攻击接口，以确保LLMs能在多种领域有效对抗误导信息。
## 53. `cs.AI` - 匈牙利与人工智能：与新加坡的比较与努力与机遇 [PDF](https://arxiv.org/pdf/2507.05280), [HTML](https://arxiv.org/abs/2507.05280)
### Authors
András Ferenczy
### Background
该研究分析了匈牙利的国家人工智能战略及其实施情况，通过战略文件、公开财务记录和与匈牙利AI联盟主席及政府AI专员首席战略顾问的专家访谈。研究评估了匈牙利策略的22个目标在概念、治理、时间和财务四个维度上的表现，并将其与新加坡的国家人工智能战略(NAIS 1.0和NAIS 2.0)进行了基准比较。研究揭示了匈牙利在人工智能领域的投资总额约为46.5亿欧元，但仅有一半的目标有公开可用的财务数据，大部分资金集中在少数几个项目上。研究还指出了执行中的挑战，如由于部委重组导致的执行碎片化，以及自2020年以来没有进行过两年一次的审查。
### Innovation
研究创新之处在于首次全面评估了匈牙利的人工智能国家策略，并对其实施情况进行了基准比较，同时提出了基于新加坡框架的改进建议。
### Conclusion
研究得出结论，匈牙利在人工智能领域面临着执行上的挑战，并提供了具体的改进建议，包括适应大型语言模型时代，重新组织现有网络以促进更有效的对话和倡导，并将该国定位为汽车人工智能实验的东-西桥梁。
## 54. `cs.AI` - 通过多任务学习增强学习路径推荐 [PDF](https://arxiv.org/pdf/2507.05295), [HTML](https://arxiv.org/abs/2507.05295)
### Authors
Afsana Nasrin,Lijun Qian,Pamela Obiomon,Xishuang Dong
### Background
个性化学习是一种以学生为中心的教学方法，能够根据每位学习者的独特需求调整内容、进度和评估。学习路径推荐是实现个性化学习的关键技术之一，它会根据学习者的过往互动，逐步推荐个性化的学习内容，如讲座和练习。随着深度学习，尤其是深度强化学习的进步，这种推荐变得更为实际且有效。
### Innovation
本文提出了一种多任务LSTM模型，通过利用任务间共享的信息来提升学习路径推荐。该方法将学习路径推荐重新定义为序列到序列（Seq2Seq）预测问题，并通过共享LSTM层捕获共性特征，以及针对每个目标的任务特定LSTM层，从而生成个性化学习路径。为了防止重复推荐，对推荐的学习路径中的重复项目施加了一种非重复损失。实验结果表明，所提出的模型显著优于基线方法在学习路径推荐中的表现。
### Conclusion
实验结果表明，提出的多任务LSTM模型在学习路径推荐任务中显著优于基线方法，能够更好地根据学习者的历史互动生成个性化的学习路径。此研究通过引入多任务学习，为学习路径推荐提供了一种新的方法，有望进一步提升个性化学习的效果。
## 55. `cs.AI` - 利用可解释人工智能压缩深度神经网络 [PDF](https://arxiv.org/pdf/2507.05286), [HTML](https://arxiv.org/abs/2507.05286)
### Authors
Kimia Soroush,Mohsen Raji,Behnam Ghavami
### Background
深度神经网络（DNNs）在许多任务中表现出卓越的性能，但同时也伴随着高计算成本和内存使用量，这限制了它们在资源受限的边缘设备上的应用。为此，研究人员采用了剪枝、量化等压缩技术来减少DNNs的内存占用，使得它们能够在资源受限的边缘设备上得到应用。近年来，可解释人工智能（XAI）方法被引入，目的是为了理解并解释AI方法，从而更好地了解DNNs内部运作机制，包括不同神经元和特征在整体性能中的重要性。
### Innovation
本文提出了一种新颖的利用XAI的DNN压缩方法，能够在没有显著影响准确度的情况下有效地减小DNN模型大小。该方法通过使用基于梯度的XAI技术（梯度相关传播法LRP）计算DNN参数（如权重）的重要性分数，然后基于这些分数进行两个步骤的压缩：1) 剪枝掉负值或零值重要性分数的参数并将其从模型中移除；2) 应用混合精度量化，将具有较高/较低重要性分数的权重分别用较高/较低位数表示。实验结果显示，与现有的XAI基于压缩方法相比，该方法能够将模型大小减少64%，同时将准确度提高42%。
### Conclusion
本文提出的方法成功实现了在不显著降低模型准确度的情况下大幅减小模型大小的目的，展示了利用XAI进行DNN压缩的潜力。
## 56. `cs.AI` - 超越经典和现代模型：基于RAG、提示工程和跨模态融合的学生远程学习辍学预测的转变性AI框架 [PDF](https://arxiv.org/pdf/2507.05285), [HTML](https://arxiv.org/abs/2507.05285)
### Authors
Miloud Mihoubi,Meriem Zerkouk,Belkacem Chikhaoui
### Background
学生在远程学习中的辍学一直是社会和经济上的一项关键挑战。传统的机器学习模型依赖于结构化的社会人口统计和行为数据，但往往无法捕捉嵌入在学生非结构化互动中的微妙情感和上下文因素。
### Innovation
本研究提出了一种变革性的AI框架，通过三个协同创新重塑留学生的预测：基于RAG的领域特定情感分析，提示工程解码学术压力因素，以及跨模态注意力融合动态对齐文本、行为和社会人口统计信息。该框架通过在精心筛选的教学内容知识库中进行情感分析，增强了BERT模型的理解能力，并通过优化提示将学术压力指标（如“孤立”、“工作负担焦虑”）隔离出来。结合跨模态注意力层，该框架将这些洞察与时间上的参与模式融合，生成全面的风险概览。
### Conclusion
该框架在4423名学生的长期数据集上实现了89%的准确率和0.88的F1分数，比传统模型高出7%，并减少了21%的假阴性率。除了预测之外，该系统还能生成可解释的干预措施，为孤立学习者提供导师指导等策略。这项工作弥合了预测分析与可操作教学之间的差距，为全球教育系统提供了可扩展的解决方案，以降低辍学风险。
## 57. `cs.AI` - 探索大语言模型在提取适用于数据目录的DCAT兼容元数据方面的能力 [PDF](https://arxiv.org/pdf/2507.05282), [HTML](https://arxiv.org/abs/2507.05282)
### Authors
Lennart Busch,Daniel Tebernum,Gissel Velarde
### Background
随着数据变得日益重要，用于加速流程、改进预测和开发新商业模型的数据变得至关重要。数据消费者往往花费25-98％的时间在搜索合适的数据上，这主要是由于数据的指数增长、异构性和分布不均。数据目录可以通过使用元数据来回答用户查询来支持和加速数据探索。然而，元数据的创建和维护通常是手工进行的，这既耗时又需要专业知识。因此，研究发现自动化的元数据维护对于减少这些过程中的工作量至关重要。
### Innovation
这项研究探索了大语言模型（LLMs）在自动化文本数据的元数据维护和生成高质量的DCAT兼容元数据方面的潜力。研究测试了零样本和少样本提示策略，以及不同厂商的LLMs。结果显示，LLMs在生成元数据方面与人类创造的内容相当，尤其是在需要高级语义理解的任务上。更大的模型表现优于较小的模型，微调显著提高了分类准确性，而少样本提示在大多数情况下效果更好。虽然LLMs为元数据创建提供了一种更快、更可靠的方法，但成功应用需要针对特定任务和领域背景的仔细考虑。
### Conclusion
尽管LLMs为元数据创建提供了一种更快和更可靠的方法，但在成功应用时仍需要仔细考虑特定任务和领域背景。较大的模型在生成元数据方面表现出色，并且微调显著提高了分类准确性，而少样本提示在大多数情况下比零样本提示效果更好。这项研究为通过自动化手段提高数据目录元数据的质量提供了实证支持。
## 58. `cs.AI` - CorrDetail: 用于人脸伪造检测的视觉细节增强自校正方法 [PDF](https://arxiv.org/pdf/2507.05302), [HTML](https://arxiv.org/abs/2507.05302)
### Authors
Binjia Zhou,Hengrui Lou,Lizhe Chen,Haoyuan Li,Dawei Luo,Shuai Chen,Jie Lei,Zunlei Feng,Yijun Bei
### Background
随着图像生成技术的迅速发展，面部深伪的广泛出现对安全领域构成了重大挑战，因此迫切需要有效的深伪检测方法。目前的面部伪造检测方法可以分为视觉基方法和多模态方法两大类，但两者都存在某些不足：视觉基方法解释不清伪造细节，而多模态方法则容易出现误判的问题。为了解决这些问题，作者提出了一个名为CorrDetail的视觉细节增强自校正框架，旨在提供可解释的面部伪造检测能力，而非生成幻觉响应。此外，通过引入视觉细粒度细节增强模块，该框架提高了对视觉伪造细节的精确度，进一步采用融合决策策略来处理极端样本，从而增强模型的辨别能力。研究结果表明，CorrDetail不仅在最新方法中表现最佳，还能准确识别伪造细节，且具有稳健的泛化能力。
### Innovation
作者提出了一个名为CorrDetail的框架，该框架通过以下创新解决了现有面部伪造检测方法的不足：1) 引入视觉细节增强自校正机制；2) 增加视觉细粒度细节增强模块；3) 使用融合决策策略提升模型的辨别能力。这些创新使得CorrDetail能够提供更准确、可解释的伪造检测结果。
### Conclusion
研究结果表明，CorrDetail在面部伪造检测任务中不仅达到了最新的技术水平，还具有优异的伪造细节识别能力和强大的泛化能力，能够在实际应用中提供可靠的检测结果。
## 59. `cs.AI` - 在BIM教育中集成生成式AI：课堂教学实施的见解 [PDF](https://arxiv.org/pdf/2507.05296), [HTML](https://arxiv.org/abs/2507.05296)
### Authors
Islem Sahraoui,Kinam Kim,Lu Gao,Zia Din,Ahmed Senouci
### Background
该研究评估了一所美国高校高级建筑信息建模（BIM）课程中，通过生成式人工智能（Generative AI）驱动的规则检查工作流程的实施情况。研究在两个学期内，共55名学生参加了基于课堂的试点项目，探索使用生成式AI进行BIM合规任务的使用情况。这是在BIM合规领域有限研究的背景下进行的实验性研究。研究表明，学生们基本达到了教学目标，但在调试生成式AI生成的代码和工具性能不一致等方面遇到了挑战。这些问题增加了学生的认知和情绪压力，尤其对于编程背景较弱的学生而言。尽管如此，学生们对未来的生成式AI应用表示出了浓厚的兴趣，尤其是当有明确的指导支持时。
### Innovation
该研究创新性地将生成式AI技术引入到BIM合规任务的课堂操作中，填补了该领域研究的空白，通过具体案例展示了生成式AI在建筑信息建模教育中的潜在应用，并通过学生反馈和评估工具分析了实际应用中的挑战和解决方案。
### Conclusion
学生们普遍达到了学习目标，但也揭示了几个在使用生成式AI进行BIM合规任务方面存在的挑战，如调试生成式AI生成的代码困难和工具性能不一致。这些挑战导致了学生的认知和情绪压力，特别是对于编程背景较弱的学生。然而，这些经验也表明，当提供明确的指导和支持时，学生们对进一步探索生成式AI技术表示出了极大的兴趣。
## 60. `cs.AI` - 神经速度用于超参数调优 [PDF](https://arxiv.org/pdf/2507.05309), [HTML](https://arxiv.org/abs/2507.05309)
### Authors
Gianluca Dalmasso,Andrea Bragagnolo,Enzo Tartaglione,Attilio Fiandrotti,Marco Grangetto
### Background
超参数调整，例如学习率衰减和确定停止准则，通常依赖于监控验证损失。传统的做法需要一个预留的数据集来评估模型的性能。
### Innovation
该论文提出了一种名为NeVe的动态训练方法，这种方法基于新的“神经速度”概念调整学习率并确定停止准则。神经速度衡量每个神经元传输函数的变化率，是模型收敛的指标。通过在网络中使用噪声进行采样神经速度，可以减少对预留数据集的需求。
### Conclusion
研究结果表明，神经速度是一个重要的指标，可以高效优化神经网络训练。
## 61. `cs.AI` - 基于自注意力机制的多尺度3D网格图自编码网络 [PDF](https://arxiv.org/pdf/2507.05304), [HTML](https://arxiv.org/abs/2507.05304)
### Authors
Saqib Nazir,Olivier Lézoray,Sébastien Bougleux(UNICAEN)
### Background
3D网格是计算机视觉和图形应用中捕捉复杂几何形状的基本数据表示。卷积神经网络（CNN）在处理结构化数据如图像方面表现出色，但扩展到不规则的3D网格上具有挑战性，因为数据是非欧几里得的。现有的图形卷积网络（GCN）方法依赖于各向同性滤波器或频谱分解，这限制了它们捕获网格的局部和全局特征的能力。现有的方法通常将网格转换为体素网格或点云等中间表示，而不保留原始的多边形网格格式。
### Innovation
本文引入了3D几何网格网络（3DGeoMeshNet），这是一种基于GCN的新颖框架，使用各向异性卷积层直接在空间域中学习全局和局部特征。该方法采用多尺度编码-解码架构，其中各自单独的全局和局部路径分别捕捉大型几何结构和细粒度的局部细节，而无需将网格转换为中间表示。这种方法保留了原始的多边形网格格式，从而更准确地重建形状。
### Conclusion
在COMA数据集中包含的人脸实验表明，3DGeoMeshNet在重建精度方面表现出高效。
## 62. `cs.AI` - 结构化的图描述能提升文本到图像模型的提示一致性 (Re-LAION-Caption 19M} [PDF](https://arxiv.org/pdf/2507.05300), [HTML](https://arxiv.org/abs/2507.05300)
### Authors
Nicholas Merchant,Haitz Sáez de Ocáriz Borde,Andrei Cristian Popescu,Carlos Garcia Jurado Suarez
### Background
生成文本到图像模型在处理大规模数据集（如LAION-5B）时，往往难以遵守提示要求，因为这些数据集通常是嘈杂且结构化的。这迫使用户依靠复杂的提示工程来获取期望的输出。本文的研究背景是，在训练过程中强制使用一致的图描述结构，可以显著提高模型的可控性和对齐性，进而提高生成图像与文本描述的一致性。
### Innovation
本文提出了在训练过程中采用一致的图描述结构来改进模型可控性和对齐性。研究人员通过引入Re-LAION-Caption 19M，一个由Mistral 7B Instruct模型生成的高质量子集，包含1900万张1024x1024像素的图像和结构化的图描述。每个图描述遵循一个四部分模板：主体、环境、美观和摄影细节。同时，使用PixArt-$boldsymbol{text{Σ}}$和Stable Diffusion 2两种模型对此进行微调，并结合视觉问答模型（VQA）评估表明，结构化的图描述能显著提高文本和生成图像的一致性得分，验证了创新的有效性。
### Conclusion
通过引入高质量的Re-LAION-Caption 19M数据集，结合结构化的图描述和视觉问答模型，本文证明了在训练过程中采用结构性图描述可以显著提高文本到图像模型的可控性和一致性。这种结构化的图描述方法使得文本到图像模型能够更好地遵守生成提示的要求。该数据集已公开可以在这个链接获取。
## 63. `cs.AI` - 缩小差距：开源大语言模型的监督微调作为教育工具可行替代方案 [PDF](https://arxiv.org/pdf/2507.05305), [HTML](https://arxiv.org/abs/2507.05305)
### Authors
Lorenzo Lee Solano,Charles Koutcheme,Juho Leinonen,Alexandra Vassar,Jake Renzella
### Background
前沿的大语言模型如ChatGPT和Gemini能够帮助初学者程序员理解复杂的编译器错误，但由于其庞大的计算规模、高成本以及过度协助的倾向，它们在广泛的教育领域中的应用面临问题。因此，本文提出利用监督微调（SFT）来改进小型特化语言模型，这些模型有可能成为教育工具的更好替代品。
### Innovation
本文利用了一个新的包含40,000个C编译器错误解释的 datasets，这些解释是基于真实情景中的初学者编程错误。作者使用这个数据集对三个开源模型（Qwen3-4B、Llama-3.1-8B和Qwen3-32B）进行了微调，并进行了双评估，结合了专家的人类评估和大规模自动化分析。结果显示，监督微调显著提升了小型模型的教学质量，达到了与更大模型相当的效果，证实了通过监督微调选择精简且高效的模型并对特定高质量领域数据进行训练，是创建专用于教育工具模型的有效策略。
### Conclusion
本文分析了模型大小与质量之间的权衡，并确认了利用高质量、特定领域的数据对精简模型进行监督微调是创建适合教育工具的专业模型的有效方法。此外，本文提供了一种可复制的研究方法，以促进在教育场景中更广泛的访问生成性人工智能的能力。
## 64. `cs.AI` - PLACE: Prompt Learning for Attributed Community Search [PDF](https://arxiv.org/pdf/2507.05311), [HTML](https://arxiv.org/abs/2507.05311)
### Authors
Shuheng Fang,Kangfei Zhao,Rener Zhang,Yu Rong,Jeffrey Xu Yu
### Background
当前的研究领域在图形数据的社区搜索（Attributed Community Search, ACS）方面取得了进展，但在利用图结构和属性信息进行精细的查询相关性增强方面仍存在局限。受自然语言处理（NLP）领域中可学习提示调优（Prompt Tuning）的启发，提示调优将可学习提示标记插入到自然语言查询中进行上下文化，以增强查询相关性。本文旨在提出一种新的图提示学习框架，从而实现更有效的ACS，并在此过程中增强图形节点间的关系。
### Innovation
本文的创新在于提出了一个新的提示学习框架（PLACE，Prompt Learning for Attributed Community Search），通过在图形中整合结构和可学习提示标记，实现查询依赖的增强，形成了一个提示增强的图形。通过交替训练机制优化提示参数和图形神经网络，使模型能够更有效地识别与具体查询相关的结构凝聚力和属性相似性。此外，设计了一种分而治之的策略来提高可扩展性，支持处理数量级为百万的图形。
### Conclusion
在9个真实世界的图形上进行的大量实验表明，PLACE在三种类型的ACS查询中比最先进的方法平均提高了22%的F1分数。
## 65. `cs.AI` - 基于条件图神经网络预测软组织变形与力 [PDF](https://arxiv.org/pdf/2507.05315), [HTML](https://arxiv.org/abs/2507.05315)
### Authors
Madina Kojanazarova,Florentin Bieder,Robin Sandkühler,Philippe C. Cattin
### Background
虚拟环境中的软组织仿真在医学应用中变得越来越重要，但由于软组织的高变形性，这带来了显著的挑战。现有的方法依赖于分割、网格化以及组织刚度属性的估计。此外，整合触觉反馈需要精确的力量估计，以提供更沉浸式的体验。目前，研究通过实验收集的软组织表面跟踪数据和迁移学习来训练新型数据驱动模型——条件图神经网络（cGNN），专门设计用于预测点的变形及其所受的力。这种模型展示了一种方法，可以预测组织形变和相应的交互力，误差分别为0.35±0.03 mm 和 0.37±0.05 N.
### Innovation
提出了一种新型的数据驱动模型——条件图神经网络（cGNN），专门用于预测软组织的变形和作用在其上的力。该模型通过实验收集的软组织表面跟踪数据和通过迁移学习克服数据稀缺性进行训练，从而提高了模型的一般化能力，并使组织形变和相应交互力的预测更加准确。与现有方法相比，cGNN利用了触觉反馈对沉浸式体验的需求，提高了虚拟环境中的软组织模拟精度和逼真度.
### Conclusion
基于条件图神经网络的数据驱动方法为模拟虚拟环境中的软组织提供了有希望的解决方案。除了在医学模拟中的应用，此方法还有潜力为需要逼真软组织模拟的其他领域提供支持。
## 66. `cs.AI` - LCDS:一种支持来源指认和专家审核的逻辑控制出院总结生成系统 [PDF](https://arxiv.org/pdf/2507.05319), [HTML](https://arxiv.org/abs/2507.05319)
### Authors
Cheng Yuan,Xinkai Rui,Yongqi Fan,Yawei Fan,Boyang Zhong,Jiacheng Wang,Weiyan Zhang,Tong Ruan
### Background
尽管大型语言模型（LLMs）在自动化出院总结生成方面表现出显著性能，但仍存在幻觉问题，如生成不准确的内容或无正当来源地编造信息。此外，电子病历（EMRs）通常包含长篇内容，使得LLMs难以将生成的内容归因于原始来源，这些挑战成为亟待解决的问题。
### Innovation
我们提出了LCDS，一种逻辑控制出院总结生成系统。LCDS通过计算EMRs与出院总结之间的文本相似性来构建来源映射表，以限制总结内容的范围。此外，LCDS整合了一系列逻辑规则，能够生成更适合不同临床领域的可靠版本出院总结。LCDS还支持生成内容的来源指认，使得专家能够高效地审查、提供反馈并纠正错误。产出的金色出院总结将用于LLMs的逐步微调。
### Conclusion
LCDS系统通过逻辑控制和详细的数据管理，改善了自动出院总结生成中的准确性和透明度，进一步确保了总结内容的可靠性和可靠性。
## 67. `cs.AI` - 通过将政策改进作为约束来超越启发式方法 [PDF](https://arxiv.org/pdf/2507.05328), [HTML](https://arxiv.org/abs/2507.05328)
### Authors
Chi-Chang Lee,Zhang-Wei Hong,Pulkit Agrawal
### Background
在许多强化学习（RL）应用中，通过使用启发式奖励（这些奖励基于人类对任务如何解决的先验知识）来增强任务奖励是至关重要的，以便实现期望的性能。然而，由于这些启发式方法通常不是最优的，所以在任务和启发式奖励之间的微妙平衡上浪费了大量的人力资源和计算资源。理论上，将启发式方法整合的方法依赖于“策略不变性”的概念，该概念保证通过最大化启发式奖励获得的策略性能与任务奖励下的最优策略相同。然而，在实践中，策略不变性并不能带来策略改进，且这些方法在实际中表现较差.
### Innovation
本文提出了一个新的框架——启发式增强策略优化（HEPO），以解决奖励黑客问题并有效地利用启发式方法。HEPO 的创新点在于其避免了之前方法处理奖励黑客问题的缺点，通过将政策改进作为约束，而不是原本的政策改进。这使得 HEPO 能够在标准基准测试中取得优异性能，即使启发式方法设计不精细，也能保持良好的性能，从而减少了在奖励设计中的人力投入.
### Conclusion
HEPO 是一种插件即用的优化方法，用于在强化学习中利用启发式方法。该方法展示了即便非专家设计的启发式方法也能取得良好性能，彰显了 HEPO 减少人在奖励设计上所需努力的能力。
## 68. `cs.AI` - 考虑有限应变弹性的物理信息图神经网络以重构局部场 [PDF](https://arxiv.org/pdf/2507.05291), [HTML](https://arxiv.org/abs/2507.05291)
### Authors
Manuel Ricardo Guevara Garban,Yves Chemisky,Étienne Prulière,Michaël Clément
### Background
在多尺度模拟的背景下，给定周期性微结构网格和宏观尺度的应力平均值，本研究旨在通过P-DivGNN框架重建微观尺度的局部应力场。该方法将周期性微结构表示为图，并结合使用消息传递图神经网络。
### Innovation
提出了一种基于物理约束的图神经网络（GNN）框架P-DivGNN。通过使用图表示形式来执行周期性边界条件，并利用平均场降阶模型（ROM）或有限元（FE）仿真在宏观尺度上预测局部应力场，从而提高计算效率。
### Conclusion
在有限应变弹性的非线性情况下，提出的GNN方法实现了相对于FE仿真显著的计算速度提升，特别适用于大规模应用。
## 69. `cs.AI` - 使用滑动窗口模式识别的LSTM和DLSTM太阳耀斑预测 [PDF](https://arxiv.org/pdf/2507.05313), [HTML](https://arxiv.org/abs/2507.05313)
### Authors
Zeinab Hassani,Davud Mohammadpur,Hossein Safari
### Background
本文研究了使用长短期记忆（LSTM）和分解LSTM（DLSTM）网络结合集成算法来预测太阳耀斑发生的时间序列数据方法。研究的数据集覆盖了2003年至2023年期间的151,071个耀斑事件，研究中识别出约7,552个年度模式窗口，这突显了长期预测的挑战性。滑动窗口技术被用于检测不规则和规整化时间序列中耀斑的时序准模式。不规则化减少了复杂性，增强了大耀斑活动，并更有效地捕捉活跃日。为了处理类别不平衡，应用了重采样方法。LSTM和DLSTM模型在不规则时间序列的峰流量和等待时间序列上进行训练，而LSTM和DLSTM结合集成方法应用于不规则化时间序列的滑动窗口（每3小时一次）。性能指标，尤其是TSS（0.74）、召回率（0.95）以及接收者操作特征曲线下的面积（AUC=0.87），表明使用集成方法的DLSTM在不规则化时间序列上的表现优于其他模型，提供更准确的大耀斑预测，并且相比在不规则时间序列上训练的模型，错误率较低。DLSTM的卓越表现归因于它可以将时间序列分解为趋势和季节性成分，有效隔离随机噪声。这项研究强调了先进机器学习技术在太阳耀斑预测中的潜力，并强调了纳入太阳活动周期各阶段和通过重采样增强预测可靠性的关键性。
### Innovation
本文的创新之处在于提出使用LSTM和DLSTM结合滑动窗口技术来识别耀斑模式，以及使用集成方法来提高预测准确性。尤其是DLSTM能够分解时间序列，分离出趋势和季节性成分，有效降低了随机噪声对预测的影响。
### Conclusion
研究证明，使用DLSTM和滑动窗口模式识别的方法在太阳耀斑预测中表现出色。DLSTM结合集成方法在不规则化时间序列上的表现优于其他模型，能够提供更准确的大耀斑预测。这突显了先进机器学习技术在提高太阳耀斑预测可靠性方面的重要作用。
## 70. `cs.AI` - MindFlow: 利用多模态大语言模型革新电子商务客户服务 [PDF](https://arxiv.org/pdf/2507.05330), [HTML](https://arxiv.org/abs/2507.05330)
### Authors
Ming Gong,Xucheng Huang,Chenghan Yang,Xianhan Peng,Haoxin Wang,Yang Liu,Ling Jiang
### Background
近年来，大语言模型（LLMs）的进步使得在电子商务客户服务中出现了新的应用。然而，这些模型在处理复杂、多模态的情景方面的能力仍然受到限制。
### Innovation
我们提出了MindFlow，这是首个为电子商务定制的多模态LLM代理。MindFlow基于CoALA框架，集成了记忆、决策和行动模块，并采用模块化的“LLMa-Tool”策略来进行视觉-文本推理。
### Conclusion
通过在线A/B测试和基于模拟的消融实验，MindFlow在处理复杂的查询、提高用户满意度和减少运营成本方面表现优异，实际部署中观察到相对改进率为93.53%。
## 71. `cs.AI` - 因果基础模型：从仪器属性中分离物理现象 [PDF](https://arxiv.org/pdf/2507.05333), [HTML](https://arxiv.org/abs/2507.05333)
### Authors
Jeroen Audenaert,Daniel Muthukrishna,Paul F. Gregory,David W. Hogg,V. Ashley Villar
### Background
结构化时间序列数据的基础模型必须应对一个基本挑战：观察经常将真实的物理现象与测量仪器引入的系统性失真混淆。这种纠缠限制了模型的泛化能力，尤其是在异质或多种仪器设置下。
### Innovation
提出了一个基于因果动机的基础模型，该模型通过一种由结构偏差学习训练的双重编码器架构，明确地从物理因素和仪器因素中分离出来。该模型利用自然出现的观察三元组（即，在不同条件下测量相同的目标准确地测量在共享条件下不同目标）学习到物理信号的底层潜在表示和仪器效应的单独潜在表示。
### Conclusion
在模拟的天文时间序列上进行评估，这些时间序列旨在模拟诸如美国国家航空航天局的凌日系外行星调查卫星（TESS）观测的变星的复杂性，该方法在下游预测任务中明显优于传统的一维潜在空间基础模型，特别是在数据稀少的情况下。结果表明，该模型支持基础模型的关键能力，包括少量示例的泛化和高效适应，并强调了在结构化数据的学习表示中编码因果结构的重要性。
## 72. `cs.AI` - OASBuilder：使用大规模语言模型从在线API文档生成OpenAPI规范 [PDF](https://arxiv.org/pdf/2507.05316), [HTML](https://arxiv.org/abs/2507.05316)
### Authors
Koren Lazar,Matan Vetzler,Kiran Kate,Jason Tsay,David Boaz Himanshu Gupta,Avraham Shinnar,Rohith D Vallam,David Amid Esther Goldbraich,Guy Uziel,Jim Laredo,Ateret Anaby Tavor
### Background
AI代理和企业自动化工具需要与外部web服务交互，这需要标准化且机器可读的API接口信息。然而，现有的API信息通常以未结构化的自由形式HTML文档形式在线呈现，这要求外部用户花费大量时间手动将其转换为结构化的格式。
### Innovation
作者介绍了一种名为OASBuilder的新型框架，它可以将API文档页面转化为一致且机器可读的API规范。该框架的创新之处在于它通过结合大型语言模型和基于规则的算法，根据文档页面结构领域的知识，自动将这些文档转化为规范。
### Conclusion
实验显示，OASBuilder适用于大量API，并生成有效的OpenAPI规范，涵盖了原始文档中的大部分信息。该工具已在企业环境中成功实施，节省了大量的手动努力，并使数百个复杂的企业API可作为工具供LLMs使用。
## 73. `cs.AI` - LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks [PDF](https://arxiv.org/pdf/2507.05346), [HTML](https://arxiv.org/abs/2507.05346)
### Authors
William Fleshman,Benjamin Van Durme
### Background
随着针对特定任务和领域进行了微调的语言模型专家的增加，有效选择和组合这些模型的方法变得至关重要。现有的数据密集型方法可能不适用于所有情况，特别是在数据有限或不可用的情况下，因此需要一种可以高效利用现有模型库的解决方案，无需额外训练或访问数据，而是能够在每标记和每一层的基础上筛选、检索和应用这些专家模型。
### Innovation
提出了LoRA-Augmented Generation (LAG)技术，利用大型知识库和任务特定的LoRA适配器。LAG技术无需额外训练或访问数据，可以在每标记和每一层的基础上高效地筛选、检索和应用专家模型，从而在各种知识密集型任务上实现优于现有数据免费方法的性能。同时，LAG具有与检索增强生成（RAG）等其他解决方案的兼容性，证实了其广泛的应用潜力。
### Conclusion
LAG技术在各种知识密集型语言任务中表现出优越的性能，并且能够适应存在额外数据的情况，展示了其兼容替代方案（如RAG）的机会，为知识密集型语言任务提供了有效的解决方案。
## 74. `cs.AI` - ASSURE：AI驱动浏览器扩展的元测试 [PDF](https://arxiv.org/pdf/2507.05307), [HTML](https://arxiv.org/abs/2507.05307)
### Authors
Xuanqi Gao,Juan Zhai,Shiqing Ma,Siyi Xie,Chao Shen
### Background
大规模语言模型（LLMs）的浏览器扩展在网页浏览中引入了高级功能，如内容总结、智能翻译和上下文感知写作辅助，但这也带来了新的测试和可靠性挑战。传统浏览器扩展测试方法无法有效处理由LLM驱动的扩展的非确定性行为、上下文敏感性和复杂网页环境集成。现有的LLM测试方法独立于浏览器特定上下文，导致缺乏有效的评估框架。
### Innovation
提出了一种名为ASSURE的模块化自动化测试框架，专门用于AI驱动的浏览器扩展测试。ASSURE包含三个主要组件：（1）支持插件扩展测试场景的模块化测试案例生成引擎；（2）自动化执行框架，协调网络内容、扩展处理和AI模型行为的复杂交互；（3）可配置的验证管道，系统地评估行为一致性及安全不变量，而非依赖于精确输出匹配。ASSURE在六个常用AI浏览器扩展中的评估证明了其有效性，识别了531个不同的问题，提高了6.4倍的测试效率，平均在12.4分钟内发现关键安全漏洞。
### Conclusion
ASSURE提供了一种全面的解决方案，能够解决测试AI驱动的浏览器扩展的独特挑战，具有很高的实践价值。
## 75. `cs.AI` - EmissionNet: 农业空气质量污染预报 [PDF](https://arxiv.org/pdf/2507.05416), [HTML](https://arxiv.org/abs/2507.05416)
### Authors
Prady Saligram,Tanvir Bhathal
### Background
农业排放的空气污染是一个重要但常被忽视的环境和公共卫生挑战因素。传统的空气质量预测模型主要依赖物理方法，难以捕捉复杂的非线性污染物相互作用。
### Innovation
本文通过评估流行的架构，并提出两个新型的深度学习架构，EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，利用卷积和基于Transformer的架构从高分辨率排放数据中提取空间-时间依赖关系，旨在改进空气质量预测。
### Conclusion
研究展示了EmissionNet和EmissionNet-Transformer的有效性，这些模型为更好地预测和管理农业排放提供了新的方法。
## 76. `cs.AI` - 控制你分享的内容：评估语言模型遵从隐私偏好的情况 [PDF](https://arxiv.org/pdf/2507.05391), [HTML](https://arxiv.org/abs/2507.05391)
### Authors
Guillem Ramírez,Alexandra Birch,Ivan Titov
### Background
大型语言模型（LLMs）通常是通过商业API访问的，但这往往要求用户将数据暴露给服务提供商。本文探讨通过使用隐私配置文件（简单自然语言指令，说明应披露和不应披露的内容）让用户提供数据的控制权。我们构建了一个框架，本地模型使用这些指令重写查询，仅隐藏用户认为敏感的细节，然后发送给外部模型，从而在保护隐私与提高性能之间取得平衡。为了支持这一研究，我们引入了一个多语言的数据集PEEP，该数据集包含了真实用户的查询，并标记了敏感内容，还配以对应的合成隐私配置文件。实验表明，轻量级LLM可以遵循这些指令，但也面临一些挑战，突显了需要更好地理解并遵守用户隐私偏好模型的必要性。
### Innovation
本文提出的隐私配置文件框架允许用户通过简单的自然语言指令控制其数据被提供的内容，并且介绍了一个名为PEEP的多语言数据集，包含真实用户的查询及标记隐私内容，还设置了合成的隐私配置文件。此外，轻量级LLM在遵守这些指令方面展示了其能力，但仍然存在挑战，表明需要进一步改进模型的理解和遵从性
### Conclusion
尽管轻量级LLM可以在一定程度上遵循用户定义的隐私配置文件，但仍存在挑战，表明需要开发更好地理解和遵循用户隐私偏好的模型。
## 77. `cs.AI` - Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning [PDF](https://arxiv.org/pdf/2507.05418), [HTML](https://arxiv.org/abs/2507.05418)
### Authors
Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang
### Background
大型语言模型（LLMs）在数学、事实QA和代码生成等领域表现出了强大的能力，但在多语言推理方面仍然存在不足，尤其是在低资源语言如斯瓦希里语或泰语的任务中，LLMs 经常会出现误解提示或默认使用英语进行推理的情况。这种对高资源语言的隐性偏见影响了事实的准确性、可解释性和可信度。当前的多语言基准主要关注最终答案，忽略了模型在目标语言中的实际推理情况。
### Innovation
提出了一种地理背景下的多语言事实推理基准GeoFact-X，涵盖了五种语言：英语、印地语、日语、斯瓦希里语和泰语，并标注了推理痕迹。进一步提出了一种名为BRIDGE的新训练方法，该方法通过语言一致性奖励来引导监督微调和推理时的强化学习，以使推理与输入语言保持一致。开发了一种自动评估协议，使用LLM作为裁判来评估答案的正确性和推理痕迹的品质及语言一致性，能够进行更细致和可扩展的评估。研究结果表明，BRIDGE显著提高了多语言推理的准确性，证明了感知多语言推理的强化学习对于稳健的跨语言泛化至关重要。
### Conclusion
BRIDGE方法显著提升了多语言推理的准确性，证明了感知多语言推理的强化学习对于跨语言泛化的稳健性至关重要。
## 78. `cs.AI` - 强化调优在持续后训练中自然减轻遗忘 [PDF](https://arxiv.org/pdf/2507.05386), [HTML](https://arxiv.org/abs/2507.05386)
### Authors
Song Lai,Haohan Zhao,Rong Feng,Changyi Ma,Wenzhuo Liu,Hongbo Zhao,Xi Lin,Dong Yi,Min Xie,Qingfu Zhang,Hongbin Liu,Gaofeng Meng,Fei Zhu
### Background
持续后训练(CPT)是将基础模型如多模态大型语言模型适应特定且不断演变的下游任务的一种流行且有效的方法。现有研究主要集中在数据重放、模型扩展或参数正则化等方法上，但学习范式在CPT中的根本作用尚未得到充分探索。这项研究对比分析了两种基础的持续后训练范式：监督微调(SFT)和强化微调(RFT)，研究它们在CPT过程中的知识保留效应。实验在包括七项不同多模态任务的基准上进行，使用Qwen2.5-VL-7B-Instruct作为持续后训练的基础模型。研究表明，当在下游任务上持续学习时，SFT会导致灾难性遗忘，即会忘记之前学习的任务。而RFT能够自然地保留先前知识，并且在性能上可以媲美多任务训练。同时，RFT还能保护甚至提升模型在标准基准上的通用知识，而SFT则会严重削弱模型的通用能力。进一步分析表明，显式的处罚机制，如KL惩罚和因果推理，并非关键因素，而RFT内在的隐式的正则化才是减轻遗忘的关键原因。最后，我们提出了基于回放的实例筛选算法来提高RFT的稳定性和效率。这项全面的研究证明了RFT作为持续后训练的稳健范式的优越性。
### Innovation
该研究对比分析了监督微调(SFT)和强化微调(RFT)这两种基础持续后训练范式，揭示了RFT能够自然地减轻知识遗忘现象，即能够保持先前学习的知识并提高模型的通用性，而SFT则会引发严重的灾难性遗忘，降低模型的通用能力。此外，研究指出了RFT内在的隐式正则化机制是减轻遗忘的关键原因。提出了基于回放的实例筛选算法以提升RFT的稳定性和效率。
### Conclusion
研究结果证明了强化微调(RFT)在持续后训练中具有减轻遗忘现象的优势，是一种更为稳健的范式。启发未来研究将更加深入地挖掘RFT的基本机制，并进一步改进其应用效果。
## 79. `cs.AI` - AGACCI: 联合评分代理在教育编码背景下的标准导向界面 [PDF](https://arxiv.org/pdf/2507.05321), [HTML](https://arxiv.org/abs/2507.05321)
### Authors
Kwangsuk Park,Jiwoong Yang
### Background
近年来，AI辅助教育的进步促进了视觉-语言模型（VLMs）在学术评估中的应用，特别是在需要定量和定性评估的任务中。然而，现有的基于VLM的方法在处理编程等复杂的教育任务时遇到困难，这些任务具有可执行的组件和可量化的输出，需要结构化的推理和与明确评估标准的对齐。现有的方法难以准确和有效地评估这些任务。为此，研究人员提出了一种多代理系统——AGACCI，它通过将专业的评估角色分配给协作代理，来改善代码导向评估的准确度、可解释性和一致性。
### Innovation
引入了AGACCI，这是一种多代理系统，通过在协作代理间分配专门的角色，提高了代码导向评估的准确度、可解释性及一致性。研究通过收集60名参与者提交的360份研究生级别的基于代码的作业（每份作业由领域专家用二元评分标准和定性反馈进行标注），对框架进行了评估。实验结果表明，AGACCI在评分标准和反馈的准确度、相关性、一致性和连贯性方面优于GPT基准模型，且保留了专家评估的指导意图和评价深度。尽管绩效在不同任务类型之间有所差距，但AGACCI展示了多代理系统在大规模和情境感知教育评估中的潜力。
### Conclusion
AGACCI在代码导向教育评估上具有显著优势，能够在保持专家评估深度的同时提升评估的准确性和一致性。未来可以通过更广泛的任务类型测试，增强系统的适应性和性能。
## 80. `cs.AI` - 大型语言模型的语义研究 [PDF](https://arxiv.org/pdf/2507.05448), [HTML](https://arxiv.org/abs/2507.05448)
### Authors
Martin Schuele
### Background
大型语言模型（LLMs）如ChatGPT展示了通过技术模仿人类语言能力的潜力，涵盖了从文本生成到参与对话的多种应用。然而，人们对这些系统到底是否真正理解语言一直存在争议。本文通过聚焦于LLMs在词汇和句级语义上的表现，缩小了这一讨论的范围，并利用传统的语义理论来提供对LLMs潜在语义能力的更细致的理解。
### Innovation
研究通过分析LLMs内部机制及其生成的语言表示，并结合弗雷格和罗素的经典语义理论，提供了LLMs潜在语义能力的更具体的认识，填补了当前对LLMs理解能力研究的空白。
### Conclusion
通过对LLMs词汇和句级语义的研究，本文揭示了LLMs在语义理解上的细节，提供了一个更为细腻的视角来理解这些系统的潜在能力。
## 81. `cs.AI` - 基于线性松弛的概率收紧扰动分析在神经网络验证中的应用 [PDF](https://arxiv.org/pdf/2507.05405), [HTML](https://arxiv.org/abs/2507.05405)
### Authors
Luca Marzari,Ferdinando Cicalese,Alessandro Farinelli
### Background
本文旨在改进神经网络验证中的鲁棒性认证。目前的验证方法在处理神经网络的输出边界时存在保守估计的问题，这对于需要高精度认证的实际应用来说是一个限制。提出的PT-LiRPA框架结合了LiRPA方法的覆盖逼近技术和基于采样的方法来计算紧凑的中间可达集，以减少自动化验证工具的成本并提供验证结果的统计保障。该框架通过利用估计的可达集来显著收紧神经网络输出的上下线性边界，从而在保证可验证结果的统计可信度的同时提高验证活动的效率和鲁棒性。
### Innovation
提出的PT-LiRPA框架通过结合覆盖逼近技术和基于采样的方法，改善了神经网络验证过程中线性松弛估计的保守性。具体创新点包括：1）显著紧缩神经网络输出的线性上下界；2）减少验证工具的计算成本；3）提供统计保障的验证结果，特别适用于现有技术难以处理的困难验证任务；4）实验结果表明，该框架比现有方法提高了3.31倍和2.26倍的鲁棒性认证，特别是在国际神经网络验证比赛中的竞争样本上表现尤为显著，展示了在高信心水平（至少99%）下解决复杂验证任务的能力
### Conclusion
通过结合优化的覆盖逼近技术和基于采样的方法，PT-LiRPA框架能够显著提升神经网络验证的效率和鲁棒性，特别是在现有验证方法难以处理的复杂验证任务中表现出色，提高了验证结果的统计保障水平，从而为实际应用提供更可靠的神经网络认证。
## 82. `cs.AI` - 结合AI的机器人系统用于实时杂草检测、叶面积感知喷洒及雾滴模式评估 [PDF](https://arxiv.org/pdf/2507.05432), [HTML](https://arxiv.org/abs/2507.05432)
### Authors
Inayat Rasool,Pappu Kumar Yadav,Amee Parmar,Hasan Mirzakhaninafchi,Rikesh Budhathoki,Zain Ul Abideen Usmani,Supriya Paudel,Ivan Perez Olivera,Eric Jone
### Background
当前农业中普遍存在的均匀且过量的化学除草剂施用造成了成本增加、环境污染以及杂草抗药性问题。为解决这些问题，本研究开发了一种基于视觉引导和人工智能驱动的变率喷洒系统，能够实时检测杂草、估计叶冠大小，并根据叶冠分割结果动态调整喷嘴激活状态。
### Innovation
该系统结合了轻量级YOLO11n和YOLO11n-seg深度学习模型，在NVIDIA Jetson Orin Nano上进行现场推断，并采用Arduino Uno基础继电器接口根据叶冠分割结果控制电磁阀喷嘴。系统在室内对15株 Hibiscus rosa sinensis 进行了试验，该植物具有不同的叶冠大小以模拟不同的杂草斑块场景。实验结果表明该系统具有潜力实现精准施药。
### Conclusion
实验结果表明该系统能够根据叶冠大小实时调整喷洒剂量，并评估雾滴模式，这为结合实时深度学习和低成本嵌入式硬件进行选择性除草剂应用开辟了可能性。未来的研究将致力于进一步扩展到包括南达科他会场常见的三种杂草水 Pedido（Amaranthus tuberculatus）、 Kochia（Bassia scoparia）和 Foxtail（Setaria spp.）的检测能力，并在大豆和玉米生产系统中进行更多的室内和田间试验验证。
## 83. `cs.AI` - ‘Lost-in-the-Later’: 一种衡量大规模语言模型上下文定位的框架 [PDF](https://arxiv.org/pdf/2507.05424), [HTML](https://arxiv.org/abs/2507.05424)
### Authors
Yufei Tao,Adam Hiatt,Rahul Seetharaman,Ameeta Agrawal
### Background
当前的大规模语言模型能够利用上下文和参数知识，但尚未充分探索它们如何优先处理和整合这些知识源。本文通过引入CoPE框架，系统地衡量语言模型中的上下文知识（CK）和参数知识（PK），旨在解决这一问题。研究使用了英语、西班牙语和丹麦语的MultiWikiAtomic数据集，分析了大规模语言模型在开放式问答中的上下文整合和信息优先级处理情况。研究发现了一个名为‘丢失在后来’的现象，表明模型倾向于忽视或低估在给定上下文中出现较晚的信息，这反映了位置偏好对上下文接地的影响。
### Innovation
本文提出了CoPE框架，这是一种新颖的评估体系，用于系统地衡量大规模语言模型中的上下文知识和参数知识。通过分析，揭示了大规模语言模型在上下文整合和信息优先级处理上的情况，尤其是发现了一种名为‘丢失在后来’的现象，这是语言模型区分上下文记忆的部分原因。此外，研究发现嵌入思考链（CoT）提示的方法会进一步降低上下文整合的质量，导致更差的上下文定位效果。基于这些发现，作者设计了基于提示的方法，以有效地利用输入的上下文信息。
### Conclusion
研究表明，基于上下文的提示可以提高事实性的上下文接地并减少虚构的情况。案例研究进一步证明了CoPE框架的有效性，展示了CK-信息提示如何改进事实性和减少虚构。
## 84. `cs.AI` - ModelCitizens: 在在线安全中代表社区声音 [PDF](https://arxiv.org/pdf/2507.05455), [HTML](https://arxiv.org/abs/2507.05455)
### Authors
Ashima Suvarna,Christina Chance,Hamid Palangi,Sophie Hao,Thomas Hartvigsen,Saadia Gabriel
### Background
自动检测有毒语言对于创造安全、包容的网络空间至关重要。然而，这是一项高度主观的任务，有毒语言的看法受到社区规范和生活经历的影响。现有的毒性检测模型通常通过单一的标注将不同的标注者视角统一为一个标准答案，从而消除了诸如重新占用语言等重要的上下文特定的概念。针对这一问题，引入了一个名为MODELCITIZENS的数据集，包含6800条社交媒体帖子和4万个关于不同身份群体的毒性标注，以捕捉在社交媒体帖子中常见的会话上下文对毒性的影响。
### Innovation
文章通过引入数据集MODELCITIZENS及其由LLM生成的对话场景，更好地反映社区视角。现有的毒性检测工具（如OpenAI Moderation API, GPT-o4-mini）在MODELCITIZENS上表现不佳，特别是在结合对话场景后进一步下降。同时，文章发布了基于LLaMA-和Gemma的模式公民化微调模型LLAMACITIZEN-8B和GEMMACITIZEN-12B，这些模型在内部评估中优于GPT-o4-mini 5.5%。这些成果强调了社区导向的标注和建模对于包容性内容管理的重要性。
### Conclusion
我们的研究结果表明了社区导向的标注和建模对于包容性内容管理的重要性。
## 85. `cs.AI` - 基于知识引导的前向-后向探索 [PDF](https://arxiv.org/pdf/2507.05477), [HTML](https://arxiv.org/abs/2507.05477)
### Authors
Núria Armengol Urpí,Marin Vlastelica,Georg Martius,Stelian Coros
### Background
零样本强化学习在缺乏具体奖励的情况下是必要的，用于在快速适应未来问题设置时提取最优策略。前向-后向表示（FB）已经作为一种有希望的方法出现，通过执行策略占用测度的分解来学习最优策略。然而，直到现在，FB和其他类似的零样本强化学习算法都是从探索问题中分离出来的，通常依赖其他探索算法来收集数据。本文提出了一个新观点，认为FB表示应该从根本上用于探索，以提高学习效率。
### Innovation
本文设计了从FB表示自然衍生的探索策略，旨在最小化FB表示的后验方差，从而最小化其知识不确定性。实证结果表明，这种原理性探索策略大幅改进了FB算法的样本复杂度，相较于其他探索方法，更为高效。
### Conclusion
通过知识引导的FB探索策略显著提高了算法的有效性，未来的改进可能在于进一步优化探索策略以适应更多复杂场景。
## 86. `cs.AI` - PWD：受先验信息引导并结合小波增强的CT重建扩散模型 [PDF](https://arxiv.org/pdf/2507.05317), [HTML](https://arxiv.org/abs/2507.05317)
### Authors
Yi Liu,Yiyang Wen,Zekun Zhou,Junqi Ma,Linghang Wang,Yucheng Yao,Liu Shi,Qiegen Liu
### Background
生成扩散模型在医学成像中，尤其是在有限角度计算机断层扫描（LACT）中得到了越来越多的关注。标准的扩散模型可以获得高质量的图像重建，但在推断过程中的抽样步骤较多，导致了巨大的计算开销。尽管已经提出了跳过抽样策略来提高效率，但往往会损失精细的结构细节。
### Innovation
本文提出了一种先验信息嵌入和小波特征融合的快速抽样扩散模型（PWD）用于LACT重建。PWD在训练阶段将LACT图像的分布映射到完全采样目标图像的分布，使模型能够学习两者之间的结构对应关系。在推断阶段，LACT图像作为显式的先验信息指导采样路径，允许在显著减少步骤的情况下获得高质量的重建。此外，PWD在小波域中进行了多尺度特征融合，通过利用低频和高频信息有效增强了精细细节的重建。
### Conclusion
在临床牙弓CBCT和根尖周病数据集上的定量和定性评估表明，在相同的采样条件下，PWD方法优于现有方法。仅使用50次采样步骤，PWD在峰值信噪比（PSNR）上提高了至少1.7 dB，在结构相似性指数（SSIM）上提高了10%。
## 87. `cs.AI` - 云扩散模型第一部分：理论与动机 [PDF](https://arxiv.org/pdf/2507.05496), [HTML](https://arxiv.org/abs/2507.05496)
### Authors
Andrew Randono
### Background
扩散模型通过逐步向图像集添加噪声并训练模型来分离信号和噪声来进行图像生成。这些模型中的噪声配置文件是白噪声，即每个点独立的正态分布噪声，均值和方差在不同尺度上相互独立。然而，大多数自然图像集在低阶统计特性方面表现出尺度不变性，其特征是幂律缩放。因此，自然图像更接近另一种概率分布，该分布强调大尺度相关性，减弱小尺度相关性。尺度不变噪声配置文件可以替换白噪声并整合到扩散模型中，形成所谓的“云扩散模型”。
### Innovation
提出了一种新的云扩散模型，该模型通过引入尺度不变噪声配置文件（而不是传统的白噪声）来改进扩散模型，以获得更快的推理、更好的高频细节和更高的可控性。
### Conclusion
本文讨论了云扩散模型的理论和动机，提出了通过引入尺度不变性噪声配置文件改进扩散模型的概念，并将在后续论文中构建和训练一个基于尺度不变性的云扩散模型，并将其与经典的白噪声扩散模型进行比较。
## 88. `cs.AI` - 关于下一个标记预测器偏向系统性低效推理的偏差：最短路径案例研究 [PDF](https://arxiv.org/pdf/2507.05362), [HTML](https://arxiv.org/abs/2507.05362)
### Authors
Riccardo Alberghi,Elizaveta Demyanenko,Luca Biggio,Luca Saglietti
### Background
近年来，自然语言处理领域的最新进展强调了两个因素对于提高大型语言模型（LLMs）的推理能力：（i）增加测试时的计算资源有助于解决更难的问题，但往往会引入推理过程中的冗余性；（ii）当推理是系统性和渐进性的时，计算资源最有效，形成类似人类问题解决的结构化思维链（CoTs）。为了研究这些因素在单独情况下的影响，作者引入了一个基于层次图最短路径任务的受控环境。研究使用自定义分词器对编码器-解码器转换器进行训练，比较了基于最优自底向上的动态规划线索和涉及回溯的较长但有效线索的模型。
### Innovation
该研究通过引入基于层次图最短路径任务的受控环境，研究了对推理能力关键因素的单独影响。特别地，研究发现，在相同的训练词令牌预算下，使用低效推理线索训练的模型在未见图上的泛化能力更好。这一优势并不单纯归因于训练线索长度的不同，随意注入推理线索中的冗余并不有助于性能提升，甚至可能损害性能。研究还发现，模型的下一个标记预测的信心与模型泛化能力相关，长期且连贯的局部渐进推理线索使得训练信号更容易优化。
### Conclusion
研究表明，系统的推理过程对于模型的泛化至关重要，模型在预测下一个标记时的信心也与其性能相关。长且连贯、局部渐进的推理线索比冗余的线索更容易优化训练信号，从而提高模型的泛化能力。
## 89. `cs.AI` - Inaugural MOASEI Competition at AAMAS'2025: 一个技术报告 [PDF](https://arxiv.org/pdf/2507.05469), [HTML](https://arxiv.org/abs/2507.05469)
### Authors
Ceferino Patino,Tyler J. Billings,Alireza Saleh Abadi,Daniel Redder,Adam Eck,Prashant Doshi,Leen-Kiat Soh
### Background
该研究背景在于开发能够在开放世界环境下做出决策的多智能体人工智能评估的标准。MOASEI竞赛基于free-range-zoo环境套件，引入了动态、部分可观察的领域，这些领域具有智能体和任务的开放性——即在不断变化的时间过程中，实体可能会出现、消失或改变行为。
### Innovation
MOASEI竞赛引入了新的多智能体人工智能基准测试，设计用于在开放世界条件下评估决策能力。竞赛分为三个赛道：火灾，共享出行和网络安全，每个赛道都突出了开放性和协调复杂性的不同方面。竞赛团队使用了多种方法，包括图神经网络、卷积架构、预测建模和基于大型语言模型的元优化。
### Conclusion
结果表明，在开放环境中的泛化和适应策略展现出有前景的方法，提供了有关实验洞察和未来研究基础设施的重要见解。该报告详细介绍了竞赛的设计、发现以及对开放智能体系统研究社区的贡献。
## 90. `cs.AI` - 作为诊断工具的驾驶：用于老年驾驶员的驾驶视频中的情景认知评估 [PDF](https://arxiv.org/pdf/2507.05463), [HTML](https://arxiv.org/abs/2507.05463)
### Authors
Md Zahid Hasan,Guillermo Basulto-Elias,Jun Ha Chang,Sahuna Hallmark,Matthew Rizzo,Anuj Sharma,Soumik Sarkar
### Background
近年来，认知能力下降，包括阿尔茨海默病（AD）和轻度认知障碍（MCI），往往因为目前诊断方法耗时且昂贵而被忽视。通过分析通过车内系统捕获的现实世界驾驶行为，本研究旨在提取与MCI和AD的功能下降和临床特征相关的“数字指纹”。现代大型视觉模型可以从老年人的日常驾驶模式中获得有意义的洞察，以早期检测认知能力下降。
### Innovation
提出了一个框架，该框架使用大型视觉模型和自然驾驶视频来分析驾驶员行为，分类认知状态并预测疾病进展。方法利用现实生活中的驾驶行为作为当前认知状态的观察，使车辆成为一种“诊断工具”。
### Conclusion
这项工作增强了早期检测，并支持了开发规模化的非侵入式监测系统的发展，以减轻老龄化人口认知衰退带来的日益增长的社会和经济负担。
## 91. `cs.AI` - 使医疗从业者受益于语言模型：两个实际临床应用中结构化语音转写 [PDF](https://arxiv.org/pdf/2507.05517), [HTML](https://arxiv.org/abs/2507.05517)
### Authors
Jean-Philippe Corbeil,Asma Ben Abacha,George Michalopoulos,Phillip Swazinna,Miguel Del-Agua,Jerome Tremblay,Akila Jeeson Daniel,Cari Bader,Kevin Cho,Pooja Krishnan,Nathan Bodenstab,Thomas Lin,Wenxuan Teng,Francois Beaulieu,Paul Vozila
### Background
大型语言模型（LLMs）如GPT-4o和o1已经在多项医学基准上的临床自然语言处理（NLP）任务中表现出色，但在护士口述的结构化表格报告和医生-患者咨询中的医疗订单提取这两个重要任务上仍存在不足，原因是有大量私密数据且敏感。尽管如此，解决这些实际临床任务的实际方案可以显著减轻医疗提供者的文档负担，使其能够更专注于患者护理。
### Innovation
研究使用私人和开源临床数据集，评估开放和封闭权重LLM的性能，并分析各自的优缺点。进一步提出了生成实际且无敏感信息的护士口述的自控管道，以实现临床观察的结构化提取。为此，作者还释放了SYNUR和SIMORD，这是首次开源的护士观察提取和医疗命令提取数据集，以支持在这些领域的进一步研究。
### Conclusion
通过释放SYNUR和SIMORD数据集，促进了在两个实际临床应用中结构化语音转写的进一步研究，同时详细分析了不同类型LLM的实际优缺点，为开发实用解决方案提供了新视角，帮助医疗从业者减轻负担，更专注于患者护理。
## 92. `cs.AI` - 消失的墨水：混淆破坏了基于N-克gram的代码水印理论与实践 [PDF](https://arxiv.org/pdf/2507.05512), [HTML](https://arxiv.org/abs/2507.05512)
### Authors
Gehao Zhang,Eugene Bagdasarian,Juan Zhai,Shiqing Ma
### Background
随着人工智能生成代码的应用不断增加，代码作者归因、内容追踪和不当使用检测等任务变得越来越重要。基于此，研究人员开发了基于N-gram的水印技术，通过在代码生成过程中注入秘密水印来检测代码的原作者。然而，这些水印技术在代码内容上的鲁棒性未得到充分评估，大多数声明仅依赖于对抗简单代码变换或优化的防御机制，这种鲁棒性存在争议。另一方面，软件工程领域已经存在更为复杂的代码混淆技术，虽然这种技术可以大幅改变代码结构但保留其功能。不过，代码水印技术对抗代码混淆的鲁棒性尚未得到充分探讨。
### Innovation
该研究通过正式建模代码混淆，证明了一旦满足分布一致性的直觉和实验验证假设，基于N-gram的代码水印技术在混淆之后无法鲁棒性地检测水印。实验在三种最先进的水印方案、两种大型语言模型、两种编程语言、四种代码基准测试集及四种混淆工具上进行。结果显示，在混淆代码上，水印检测器的性能几乎等同于随机猜测（AUROC紧挨0.5）。部分模型、水印方案和数据集在攻击后仍能检测到水印，但高于0.6的检测AUROC很少。基于理论与实践观察，该研究指出实现鲁棒代码水印的潜在路径。
### Conclusion
研究证明了基于N-gram的代码水印技术在面对代码混淆时的鲁棒性不足，提出了一种潜在增强代码水印鲁棒性的路径。
## 93. `cs.AI` - 通过外部知识的潜在空间约束在嘈杂图上实现鲁棒学习 [PDF](https://arxiv.org/pdf/2507.05540), [HTML](https://arxiv.org/abs/2507.05540)
### Authors
Chunhui Gu,Mohammad Sadegh Nasr,James P. Long,Kim-Anh Do,Ehsan Irajizad
### Background
图神经网络（GNNs）在处理嘈杂边时常常表现不佳。本文旨在通过引入外部“纯净”链接并将其应用于目标图的潜在空间，来提出一种新的方法——潜在空间约束图神经网络（LSC-GNN），以辅助和引导目标图的嵌入。
### Innovation
本文提出了一种新的图神经网络模型——LSC-GNN，该模型通过两个编码器分别训练在包含目标图和外部链接的完整图以及排除目标图潜在噪声链接的正则图上，然后通过惩罚两者的潜在表示之间的差异来进行约束，从而避免模型过度拟合噪声边。此外，LSC-GNN还被推广到了异质图中，并在蛋白质-代谢物网络上进行验证，显示了其在减轻噪声关系结构问题时的潜力。
### Conclusion
实验表明，在中等噪声图上，LSC-GNN在基准数据集上的表现优于传统的稳健GNNs。LSC-GNN还可以提升预测性能和可解释性，在嘈杂的关系结构中具有重要的应用价值。
## 94. `cs.AI` - AI在创意产业中的伦理影响：聚焦生成式人工智能艺术 [PDF](https://arxiv.org/pdf/2507.05549), [HTML](https://arxiv.org/abs/2507.05549)
### Authors
Prerana Khatiwada,Joshua Washington,Tyler Walsh,Ahmed Saif Hamed,Lokesh Bhatta
### Background
随着人工智能（AI）的持续增长，每天都有更多令人兴奋且颇具争议的技术出现。随着AI技术的进步，人们对它的怀疑也随之增加。本文探讨了生成式AI艺术在伦理方面的复杂性和困惑。研究发现，生成式AI艺术导致碳排放增加、传播误导信息、侵犯版权、非法肖像描绘以及工作者失业。
### Innovation
本文深入探讨了AI在创意产业中的伦理问题，特别是生成式艺术。文章从环保问题出发，涉及名人肖像的代表、知识产权、深度信息以及艺术家的替代等问题，分析了各个环节的历史、原因和后果，并提出了多种潜在的解决方案。
### Conclusion
核心问题在于，生成式AI艺术需要得到正确的立法和监管。
## 95. `cs.AI` - MP-ALOE：一种用于通用机器学习原子间势的r2SCAN数据集 [PDF](https://arxiv.org/pdf/2507.05559), [HTML](https://arxiv.org/abs/2507.05559)
### Authors
Matthew C. Kuner,Aaron D. Kaplan,Kristin A. Persson,Mark Asta,Daryl C. Chrzan
### Background
研究中提出了MP-ALOE数据集，包含近100万基于r2SCAN串行泛函数近似计算。这些计算覆盖了89种元素，并主要包含非平衡结构，使用主动学习方法创建。该数据集旨在为机器学习原子间势提供支持，并在一系列基准测试中进行了评估和验证。
### Innovation
使用r2SCAN串行泛函数近似进行大规模DFT计算，覆盖89种元素，并通过主动学习方法创建数据集，主要包含非平衡结构。这些计算用于训练机器学习原子间势，并在多种基准测试中表现出强劲性能，涵盖了平衡结构的热化学性质预测、非常态结构的力预测、静态极端变形下的物理一致性保持以及在极端温度和压力下的分子动力学稳定性。
### Conclusion
MP-ALOE数据集表现出在各种基准测试中的强性能，并且已公开供更广泛的社区使用。
## 96. `cs.AI` - Prompt 迁移：通过演化的大型语言模型稳定生成式AI应用程序 [PDF](https://arxiv.org/pdf/2507.05573), [HTML](https://arxiv.org/abs/2507.05573)
### Authors
Shivani Tripathi,Pushpanjali Nema,Aditya Halder,Shi Qiao,Alekh Jindal
### Background
生成式AI正在通过自然语言界面和智能自动化改变商业应用。然而，底层的大语言模型（LLMs）正在迅速发展变化，使得持续有效地激励它们变得具有挑战性。这导致应用行为不一致和不可预测，这会削弱企业在关键业务流程中需要的信任可靠性。
### Innovation
本文提出了提示迁移（Prompt Migration）的概念，这是一种系统的方法，旨在在不断变化的LLMs背景下稳定生成式AI应用程序。作者通过Tursio的企业搜索应用程序作为案例研究，分析了 successive GPT模型升级的影响，详细介绍了迁移框架包括提示重设计和迁移测试环境，并展示了这些技术如何恢复应用程序的一致性。实验证明，结构化的提示迁移可以完全恢复因模型漂移而损失的应用可靠性。
### Conclusion
研究得出了一些实用的经验教训，强调了提示生命周期管理和稳健测试对于确保可靠的生成式AI赋能的商业应用程序的重要性。
## 97. `cs.AI` - 智能代理驱动的智能合约攻击生成 [PDF](https://arxiv.org/pdf/2507.05558), [HTML](https://arxiv.org/abs/2507.05558)
### Authors
Arthur Gervais,Liyi Zhou
### Background
该研究提出了一种名为A1的系统，该系统能够将任何语言模型转换为端到端的漏洞利用生成器，用于智能合约安全领域。在传统的安全分析中，即使使用深度学习等先进技术，仍然需要依赖人工设计的手工启发式方法，这限制了其效率和准确性。因此，该系统旨在提供一个自动化、无手动启发式规则的方法，以促进智能合约漏洞的自主发现。
### Innovation
A1系统创新地使用了一个自适应执行驱动的代理，无需手动设计的启发式规则，代理配备六个特定领域的工具来促进自主漏洞发现。系统能够灵活地利用这些工具来理解智能合约行为，生成攻击策略，测试策略，并根据执行反馈进行优化。所有生成的输出都会被具体验证，以消除错误的正例。此外，该研究通过432次实验分析了六个不同的语言模型，展示了模型性能随迭代增加而提升的情况，验证了系统的有效性和经济性。
### Conclusion
实验证实在以太坊和Binance智能链上的36个真实世界漏洞合约中，A1的工具包达到了62.96%的成功率。模型分析表明，在0.1%的漏洞发生率下，攻击者可以实现超过6000美元的扫描盈利，而防御者则需要60000美元。这一发现揭示了一个令人担忧的不对称性：在面对智能合约漏洞攻击时，AI代理似乎更倾向于攻击而非防御。
## 98. `cs.AI` - Fourier Spectral Transformer Networks For Efficient and Generalizable Nonlinear PDEs Prediction [PDF](https://arxiv.org/pdf/2507.05584), [HTML](https://arxiv.org/abs/2507.05584)
### Authors
Beibei Li
### Background
该研究基于经典谱方法和基于注意力的神经架构的优点，提出了一种统一的Fourier谱变换器网络。通过将原始偏微分方程（PDEs）转换为谱常微分方程，并使用高精度数值求解器生成训练数据，利用Transformer网络建模谱系数的演变。经过展示，这种方法在二维不可压缩Navier-Stokes方程和一维Burgers'方程上表现出色。
### Innovation
该方法通过结合经典谱方法和基于注意力的神经架构的优势，提出了一种新的统一网络架构——Fourier谱变换器网络。这种网络在高效和泛化方面表现优异，能够利用有限的训练数据进行长期预测，更适合未来流体动力学的预测。
### Conclusion
研究结果表明，所提出的谱变换器能够以高度准确的方式进行长期预测，即使数据有限。与传统的数值方法和机器学习方法相比，该方法在预测未来流体动力学方面表现出更好的性能。该框架在处理未见过的数据时表现良好，为复杂动态系统的实时预测和控制提供了一个有前景的范式。
## 99. `cs.AI` - 使用InterpoLated Learning缓解捷径学习 [PDF](https://arxiv.org/pdf/2507.05527), [HTML](https://arxiv.org/abs/2507.05527)
### Authors
Michalis Korakakis,Andreas Vlachos,Adrian Weller
### Background
经验风险最小化（ERM）激励模型利用捷径，即输入属性与标签之间的假相关，这种相关在训练数据中普遍存在但与任务本身无关。这种依赖性在少数类示例中妨碍了泛化能力，因为在少数类示例中这些相关性并不成立。现有的捷径缓解方法针对特定模型，难以调优，计算成本高，并未能改善学习表示。
### Innovation
提出了一种新的方法——InterpoLated Learning（InterpoLL），该方法通过将主要样本的表示与类内少数样本具有捷径缓解模式的特征进行插值，来削弱捷径的影响，使模型能够获取适用于少数样本和主要样本的预测特征。实验结果显示，InterpoLL在多项自然语言理解任务中提高了少数样本的泛化能力，同时没有牺牲主要样本的准确性，并且这种方法适用于不同的网络架构。
### Conclusion
实验结果表明，InterpoLL在多个自然语言理解任务中提高了少数类的泛化能力，优于经验风险最小化和现有的捷径缓解方法，同时不会牺牲主要类别的准确性。此外，这些收益覆盖了编码器、编码器-解码器和仅解码器架构，证明了该方法的广泛适用性。
## 100. `cs.AI` - 2048：在延迟奖励环境中的强化学习 [PDF](https://arxiv.org/pdf/2507.05465), [HTML](https://arxiv.org/abs/2507.05465)
### Authors
Prady Saligram,Tanvir Bhathal,Robby Manihani
### Background
延迟和稀疏奖励为强化学习（RL）代理提出了一个根本性的障碍，它们难以将信用分配给其好处在多步后才出现的动作。2048滑块游戏就是一个典型挑战：虽然频繁的小分变化提供了即时反馈，但它们往往误导代理采取局部最优但全局次优的策略。
### Innovation
本文介绍了一个统一的分布多步RL框架，直接优化长期性能。通过开源环境Gym-2048，开发并比较了四种代理变体：标准DQN、PPO、QR-DQN（分位回归DQN）和一个新颖的Horizon-DQN（H-DQN），该变体集成分布学习、 Dueling 架构、Noisy 网络、优先回放和其他技术。实证评估表明效能层级依次提升：最大 episode 分数从DQN的3.988K提高到PPO的5.756K，QR-DQN的8.66K，以及H-DQN的18.21K，其中H-DQN达到2048瓷砖。将H-DQN扩展后，最大分数达到41.828K并达到4096瓷砖。
### Conclusion
这些结果表明，分布性、多步目标在稀疏奖励域中显著提升性能，并表明模型基于规划和课程学习进一步改进的前景广阔。
## 101. `cs.AI` - 提升LLM遵循指令能力的自我审查框架 [PDF](https://arxiv.org/pdf/2507.05598), [HTML](https://arxiv.org/abs/2507.05598)
### Authors
Sihyun Park
### Background
为了改进大型语言模型（LLMs）的格式化和指令约束的遵循性，提出了多种技术。其中一种有效的方法是利用高级模型生成的高质量数据。然而，这些模型在一次生成中往往不能完全遵守复杂的指令。为解决这一问题，提出了迭代修订方法，但随着数据点数量和修订迭代次数的增加，成本显著增加。一种资源高效的替代方案利用高性能评估工具来弥补开源LLM有限的自我评估能力，但这些方法往往会导致输出质量下降，因为过度修正会产生负面影响。
### Innovation
我们提出了Re5，一种自我评估和修订框架，旨在增强指令遵循性能同时保持生成内容的质量。Re5从用户指令中提取任务和约束组件，执行结构评估以防止错误积累，并应用细粒度的约束特定内容评估，随后进行选择性的修订。此过程确保准确且质量不变的改进。高质量的最终输出用于对齐调优，通过基于数据的迭代精细优化循环实现长期对齐改进。
### Conclusion
实验结果表明，Re5即使使用少量数据也能实现与训练于高性能模型GPT-4o-mini生成的数据相当的指令遵循性能，并且在质量上保留了回应，超过原始未修订响应的概率为64.24%，验证了Re5作为在最少外部监督下提高指令遵守能力的高效且有效解决方案的有效性。
## 102. `cs.AI` - Llama Nemoretriever Colembed: 领先的文本图像检索模型 [PDF](https://arxiv.org/pdf/2507.05513), [HTML](https://arxiv.org/abs/2507.05513)
### Authors
Mengyao Xu,Gabriel Moreira,Ronay Ak,Radek Osmulski,Yauhen Babakhin,Zhiding Yu,Benedikt Schifferer,Even Oldridge
### Background
随着跨模态检索系统的市场需求增长，我们介绍了统一文本-图像检索模型 llama-nemoretriever-colembed，该模型在多个基准测试中取得了最先进的性能。该模型有两个变体，分别为 1B 和 3B，其中 3B 模型表现最佳，分别在 ViDoRe V1 和 ViDoRe V2 中取得了 NDCG@5 91.0 和 63.5 的成绩，并在截止到 2025 年 6 月 27 日的排行榜上排名第一。
### Innovation
我们的方法利用了 NVIDIA Eagle2 视觉语言模型 (VLM)，通过替换因果注意力机制来修改其架构，引入了类似于 ColBERT 的晚期交互机制，使其能够在共享嵌入空间中实现细腻的跨模态检索。虽然这种方法提供了优越的检索准确性，但它在存储和效率方面也带来了权衡。此外，我们采用两阶段训练策略来增强模型的检索能力，并且进行了详细的权衡分析。
### Conclusion
研究通过 llama-nemoretriever-colembed 模型展示了在跨模态检索领域的最新成果，并在多个基准测试中取得了卓越的成绩。
## 103. `cs.AI` - SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression [PDF](https://arxiv.org/pdf/2507.05633), [HTML](https://arxiv.org/abs/2507.05633)
### Authors
Yiqiao Jin,Kartik Sharma,Vineeth Rakesh,Yingtong Dou,Menghai Pan,Mahashweta Das,Srijan Kumar
### Background
Retrieval-augmented Generation (RAG)通过外部知识扩展了大规模语言模型（LLMs），面临的主要挑战包括有效上下文长度的限制和检索文档中的冗余。纯基于压缩的方法虽然可以减少输入大小，但往往丢弃了对于事实准确至关重要的细粒度细节。现有的RAG框架在紧凑的上下文预算下未能平衡局部精度与全局知识覆盖度，导致答案相关性、正确性和语义相似度低下。
### Innovation
SARA提供了一个统一的RAG框架，能够在紧凑的上下文预算下平衡局部精度和全局知识覆盖度。SARA结合了自然语言片段和语义压缩向量，从两个层面提升上下文效率和答案准确性。首先，细粒度的自然语言片段保存关键实体和数值；其次，紧凑的可解释向量总结高层次语义。SARA采用迭代的证据选择模块，利用压缩向量动态重新排名上下文，从而提升RAG的鲁棒性和上下文效率。
### Conclusion
SARA在9个数据集和5个开源LLM（Mistral、Llama和Gemma）上，一致提高了答案的相关性（+17.71）、正确性（+13.72）和语义相似度（+15.53），证明了将文本和压缩表征结合起来对于构建稳健、上下文高效的RAG的重要性。
## 104. `cs.AI` - Explainable Hierarchical Deep Learning Neural Networks (Ex-HiDeNN) [PDF](https://arxiv.org/pdf/2507.05498), [HTML](https://arxiv.org/abs/2507.05498)
### Authors
Reza T. Batley,Chanwook Park,Wing Kam Liu,Sourav Saha
### Background
数据驱动的科学计算已经取得了巨大进展，能够使用可训练参数构建复杂的功能关系。然而，如何从复杂的数据集中高效地发现可解释且准确的闭式表达式仍是一个挑战。
### Innovation
文章提出了一种名为Ex-HiDeNN的新方法，结合了符号回归与分离的、快速的、可扩展的神经网络架构，旨在从有限的观察中发现闭合形式的表达式。Ex-HiDeNN具有一步算法和内置的分离性检查器，经过多个基准问题测试后显示了出色的近似能力，相比于传统的符号回归和参考数据，其误差减少了数量级。
### Conclusion
Ex-HiDeNN方法在工程应用中表现优异，分别成功发现了疲劳方程、微压痕硬度和屈服面表达式，并优于文献中的参考方法。该方法基于作者之前发表的HiDeNN和卷积HiDeNN的工作成果，同时明确了Ex-HiDeNN当前的局限性和未来的发展方向。
## 105. `cs.AI` - 图学习 [PDF](https://arxiv.org/pdf/2507.05636), [HTML](https://arxiv.org/abs/2507.05636)
### Authors
Feng Xia,Ciyuan Peng,Jing Ren,Falih Gozi Febrinanto,Renqiang Luo,Vidya Saikrishna,Shuo Yu,Xiangjie Kong
### Background
图学习已迅速发展成为机器学习和人工智能（AI）的一个关键子领域。它的发展始于早期的图理论方法，随着图神经网络（GNNs）的出现而逐渐迅猛发展。过去十年间，可扩展架构、动态图建模、多模态学习、生成AI、可解释AI（XAI）和负责任AI的进步，使图学习在各种具有挑战性的环境中得到了更广泛的应用。由于其能够建模复杂的非欧几里得关系，传统机器学习难以捕捉，图学习在药物发现、欺诈检测、推荐系统和科学推理等方面的应用得到了更好的支持。然而，可扩展性、泛化能力、异质性、可解释性和可信性等问题需要解决，以充分发挥其潜力。
### Innovation
本文总结了通过有效的处理大规模图、捕获动态时间依赖关系、整合异质数据模态、生成新颖的图样本以及增强可解释性来促进信任与透明度的技术。此外，还探讨了诸如隐私和公平性等伦理问题，以确保图学习模型的负责任部署。同时，也识别并讨论了新兴议题，展示了图学习与其他AI范式的整合，提供了未来方向的见解。
### Conclusion
本文为希望深入了解快速发展的图学习领域的研究者和从业者提供了一份宝贵资源。
## 106. `cs.AI` - MedGen: 通过细粒度标注的医学视频扩展解锁医学视频生成 [PDF](https://arxiv.org/pdf/2507.05675), [HTML](https://arxiv.org/abs/2507.05675)
### Authors
Rongsheng Wang,Junying Chen,Ke Ji,Zhenyang Cai,Shunian Chen,Yunjin Yang,Benyou Wang
### Background
尽管近年来在开放领域中的视频生成已经取得了显著进展，但在医学视频生成领域还是相对未被探索的一片领域。医学视频对临床培训、教育和模拟等应用至关重要，不仅需要高视觉保真度，还需要高度医学准确性。然而，当前的模型经常在针对医学提示时产生不现实或错误的内容，主要原因是缺乏针对医学领域的大型高质量数据集。因此，研究者们需要一个大规模、多样化的数据集来培训泛化的医学视频生成模型，以产生高视觉质量和医学准确性的视频。
### Innovation
本文介绍了 MedVideoCap-55K，这是第一个专门为医学视频生成设计的大规模、多样且带标注的数据集，包含了超过 55,000 个真实医疗场景的剪辑。基于此数据集，开发了 MedGen 模型，该模型不仅在开源模型中表现出卓越的性能，还能与商业系统在多种基准测试中比肩，同时保证了视觉质量和医学准确性。
### Conclusion
本文的数据集和模型有望为医学视频生成的研究提供有价值的新资源，促进了该领域进一步的研究和发展。研究团队提供的代码和数据可以在指定的网址中下载。
## 107. `cs.AI` - DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning [PDF](https://arxiv.org/pdf/2507.05649), [HTML](https://arxiv.org/abs/2507.05649)
### Authors
Kaixiang Zhao,Joseph Yousry Attalla,Qian Lou,Yushun Dong
### Background
图神经网络（GNNs）在基于图的学习任务中已经取得了最先进的性能。然而，在全同态加密（FHE）等加密域中实现隐私保留的GNN通常会导致巨大的计算开销，使得实时和隐私保留的推理变得不切实际。现有FHE GNN方法往往忽视输入数据的冗余性，并采用统一的计算策略，这限制了它们的效率。
### Innovation
提出了 DESIGN（EncrypteD GNN Inference via sErver-Side Input Graph pruNing），这是一种新的高效加密GNN推理框架。DESIGN通过服务器端的分层优化策略解决了现有FHE GNN方法的效率限制，该策略首先基于加密图的加密度统计计算FHE兼容的节点重要性评分，之后这些评分用于引导同态分区过程，生成多级重要性掩码，直接在FHE下操作。这些掩码不仅用于输入图的逻辑裁剪，还用于设计一种新型的自适应多项式激活方案，激活复杂性可以根据节点的重要性水平调整。
### Conclusion
实验证明，与最先进的方法相比，DESIGN在加速FHE GNN推理方面具有显著优势，同时保持了竞争性的模型准确性，为安全图分析提供了一种稳健的解决方案。
## 108. `cs.AI` - FACT: the Features At Convergence Theorem for neural networks [PDF](https://arxiv.org/pdf/2507.05644), [HTML](https://arxiv.org/abs/2507.05644)
### Authors
Enric Boix-Adsera,Neil Mallinar,James B. Simon,Mikhail Belkin
### Background
深学习理论中的一个核心挑战是如何理解神经网络如何学习和表示特征。本文通过证明在非零权重衰减条件下训练时神经网络权重在收敛时满足的一致性方程，即'收敛时特征方程'（Features at Convergence Theorem, FACT），提供了一种理解神经网络特征表示的方法。通过这种方式，可以将权重矩阵W的特征矩阵W^T W与前向传播过程中传入矩阵的输入向量和反向传播过程中通过该矩阵的损失梯度联系起来。作者通过实验证明了神经网络在收敛时确实满足FACT。
### Innovation
1. 提出了'收敛时特征方程'（ FEATURES at CONVERGENCE theorem, FACT）来理解神经网络如何在非零权重衰减条件下收敛时学习和表示特征，该方程将权重矩阵与前向传播和反向传播过程中通过的输入和梯度联系起来。2. 基于 Radhakrishnan 等人的“递归特征机器”（Recursive Feature Machines），通过使它们遵循 FACT 来改进算法，提出了新的学习算法 FACT-RFM。该算法在表格数据上表现优异，并且能够捕捉到神经网络训练过程中发生的各种特征学习行为，例如模运算中的理解（grokking）和稀疏位运算的学习相变（phase transitions）现象。
### Conclusion
通过证明 FACT，作者提供了一种理解神经网络在非零权重衰减条件收敛时如何学习和表示特征的方法，并基于此改进了递归特征机器算法（FACT-RFM），验证了该算法在表格数据集上的高性能，并展示了几种在神经网络训练过程中观察到的特征学习行为。
## 109. `cs.AI` - TuneShield: 在使用不信任数据微调时减轻对话式AI中的毒化现象 [PDF](https://arxiv.org/pdf/2507.05660), [HTML](https://arxiv.org/abs/2507.05660)
### Authors
Aravind Cheruvu,Shravya Kanchi,Sifat Muhammad Abdullah,Nicholas Kong,Daphne Yao,Murtuza Jadliwala,Bimal Viswanath
### Background
近年来，基础模型如大语言模型（LLMs）在对话AI领域取得了革命性进展。聊天机器人正越来越多地通过定制LLMs在特定对话数据集上进行开发。然而，在这种定制过程中，尤其是在处理不信任的训练数据时，减轻毒化问题仍然存在巨大的挑战。为了应对这一问题，我们提出了TuneShield，这是一种防御框架，旨在在进行聊天机器人微调时减轻毒化现象，同时保持高质量的对话效果。TuneShield利用了基于LLM的毒性分类方法，通过LLM的指令跟随能力和安全性对齐，有效地识别出有毒样本，其性能优于行业API服务。
### Innovation
TuneShield 通过利用基于LLM的毒性分类来识别有毒样本，相比现有的行业API服务，其性能更佳。TuneShield生成合成对话样本，称为‘治疗数据’，利用这些数据在微调过程中减轻毒化现象的同时加强理想行为。此外，TuneShield还进行了对齐过程，推动聊天机器人更倾向于生成所需响应。TuneShield能够有效减轻毒化注入攻击，即使在毒化分类器不准确或存在偏差的情况下也能够保持对话的质量。TuneShield还证明了它能够抵御可适应的对抗性攻击和破解攻击。它还展示了在基于对话的学习（DBL）过程中减轻适应性毒化注入攻击的有效性。
### Conclusion
我们的研究结果表明，TuneShield 能够有效减轻毒化注入攻击，同时保持对话质量。TuneShield 证明了其在使用不信任数据微调时的稳健性和有效性。
## 110. `cs.AI` - 通过联邦混合专家实现大型AI模型的高效训练：系统级方法 [PDF](https://arxiv.org/pdf/2507.05685), [HTML](https://arxiv.org/abs/2507.05685)
### Authors
Xiaobing Chen,Boyang Zhang,Xiangwei Zhou,Mingxuan Sun,Shuai Zhang,Songyang Zhang,Geoffrey Ye Li
### Background
联邦学习（FL）和混合专家（MoE）的集成为在分散数据上构建更强大、大规模的人工智能模型（LAMs）提供了极具吸引力的途径，同时保护隐私。然而，高效地联邦训练这种复杂的MoE结构的LAMs受到系统层面挑战的限制，特别是在处理异构客户端资源之间的交互以及对多个专业化专家的精细协调上。
### Innovation
本文提出了一种智能客户端专家对齐的概念系统设计，该设计结合了动态适应度评分、全局专家负载监控和客户端容量分析。通过解决这些系统层面的问题，我们能够解锁更可扩展、更高效的训练机制，在减少通信回合数的同时达到收敛，为在边缘计算中广泛部署大规模联邦MoE结构LAMs铺平了道路，同时达到超高的通信效率。
### Conclusion
本文探讨了一种基于系统层面的方法，通过联邦混合专家优化大型AI模型的训练过程，克服系统层面的挑战，实现了更高效的训练机制，并为边缘计算中广泛应用大规模联邦MoE结构LAMs奠定了基础。
## 111. `cs.AI` - Agentic-R1：提炼的双重策略推理 [PDF](https://arxiv.org/pdf/2507.05707), [HTML](https://arxiv.org/abs/2507.05707)
### Authors
Weihua Du,Pranjal Aggarwal,Sean Welleck,Yiming Yang
### Background
当前的长链推理（long-CoT）模型在数学推理方面表现出色，但依赖于缓慢且容易出错的自然语言痕迹。工具增强的代理通过代码执行解决算术问题，但在复杂的逻辑任务上常常表现不佳。
### Innovation
我们提出了一种名为DualDistill的微调框架，该框架将来自多个教师的互补推理策略提炼到一个统一的学生模型中。使用这种方法，我们训练了Agentic-R1，该模型能够根据每个查询动态选择最佳策略，对于算术和算法问题调用工具，对于抽象问题则使用基于文本的推理。我们的方法在包括计算密集型和标准基准在内的多种任务中提高了准确性，证明了多策略提炼在实现稳健而高效推理方面的有效性。
### Conclusion
我们的方法表明，多策略提炼对于实现稳定而高效的推理是有效的，特别是在处理计算密集型和标准基准任务上。我们的项目可在以下网址获得：this https URL
## 112. `cs.AI` - GATMesh：使用图神经网络进行时钟网线时序分析 [PDF](https://arxiv.org/pdf/2507.05681), [HTML](https://arxiv.org/abs/2507.05681)
### Authors
Muhammad Hadir Khan,Matthew Guthaus
### Background
时钟网线在高性能VLSI系统中对于减少延迟和处理PVT变化至关重要，但由于存在收敛路径、多源驱动和输入网线缓冲延迟等问题，分析它们非常困难。SPICE仿真虽然准确但速度慢，而简化模型则忽略了关键效果如波形和输入延迟。
### Innovation
我们提出了一种基于图神经网络（GNN）的框架GATMesh，将时钟网线表示为具有增强结构和物理特征的图形。GATMesh在SPICE数据上训练，并实现了在未知基准上的高精度，平均延迟误差为5.27ps，同时相比多线程SPICE仿真实现了47146倍的加速。
### Conclusion
GATMesh通过GNN建模时钟网线并利用SPICE数据进行训练，可以在保证准确性的前提下实现高效的时序分析。
## 113. `cs.AI` - 全路由: 在稀疏混合专家架构中共享路由决策以进行语音识别 [PDF](https://arxiv.org/pdf/2507.05724), [HTML](https://arxiv.org/abs/2507.05724)
### Authors
Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly
### Background
混合专家（MoE）架构最初应用于语言模型，现已扩展到自动语音识别（ASR）。传统的MoE方法，如Switch Transformer，在每一层中独立地路由专家。研究表明，大多数层的路由器所做的专家选择与其其它层路由器的选择间关联性不强。因此，为了增加不同层专家间的合作和促进更专业的分工，作者提出了一种跨层共享路由器的方法，提出了Omni-router Transformer模型。
### Innovation
作者提出了一种全新的Omni-router Transformer模型，该模型利用共享路由在网络不同层间共享决策，以增加不同层专家间的合作和促进更专业的分工，从而提高整体性能。实验结果显示，该模型能在训练损失和字错误率方面显著改善性能，在多种ASR基准上表现出更佳的鲁棒性。
### Conclusion
Omni-router Transformer在大规模伪标签数据集和多种ASR基准上的实验结果表明，其不仅能够显著降低训练损失，还能够实现比密集模型和Switch Transformer模型更低的平均字错误率，同时提供有组织的专家使用和更强的多样数据鲁棒性。
## 114. `cs.AI` - 高光谱异常检测方法：综述与比较研究 [PDF](https://arxiv.org/pdf/2507.05730), [HTML](https://arxiv.org/abs/2507.05730)
### Authors
Aayushma Pant,Arbind Agrahari Baniya,Tsz-Kwan Lee,Sunil Aryal
### Background
高光谱图像由数百个连续的光谱波段组成，能够进行详细的材料和表面分析。高光谱异常检测（HAD）是指在无需先验信息的情况下识别并定位异常目标的技术。这项技术在农业、防御、军事监控和环境监测等领域取得了快速进展。现有HAD方法面临的挑战包括高计算复杂性、对噪声的敏感性和在不同数据集上的有限推广能力。
### Innovation
本文对各种HAD技术进行了全面比较，将这些方法归类为统计模型、表示方法、经典机器学习方法和深度学习模型。使用不同性能度量（如ROC、AUC和可分图）在17个基准数据集上评估了这些方法，分析了识别精度、计算效率及其优势、局限性及其未来发展方向。研究结果表明，深度学习模型获得了最高的检测精度，而统计模型在所有数据集中显示出出色的计算速度。
### Conclusion
本研究旨在为致力于推进高光谱异常检测方法领域的研究者和实践者提供宝贵的见解。
## 115. `cs.AI` - DATABench: 从对抗视角评估深度学习中的数据审计 [PDF](https://arxiv.org/pdf/2507.05622), [HTML](https://arxiv.org/abs/2507.05622)
### Authors
Shuo Shao,Yiming Li,Mengren Zheng,Zhiyang Hu,Yukun Chen,Boheng Li,Yu He,Junfeng Guo,Tianwei Zhang,Dacheng Tao,Zhan Qin
### Background
深度学习在多个领域的广泛应用高度依赖于训练数据的质量和组成。然而，训练数据使用的不透明性引发了许多隐私和版权问题。现有的一些数据审计技术旨在检测特定数据集是否被用于训练某可疑模型，但这些方法在面对有目的的对抗攻击时的抗攻击能力尚未得到充分研究。
### Innovation
本文首次从对抗视角对数据审计方法进行全面研究。首先，提出了一个新的分类框架，将现有方法分为依赖内部特征（IF）和外部特征（EF）的类别。其次，定义了两种主要的攻击类型：用于遮掩数据使用的欺骗攻击和旨在误导未使用的数据集的伪造攻击。最后，提出了系统的对抗策略，包括脱耦、删除、检测方法用于欺诈企图，以及利用对抗样本的方法用于伪造攻击。在此基础上，构建了一个新的基准测试数据集DATABench，包括17种欺骗攻击、5种伪造攻击和9种代表性的审计方法。实际测试结果表明，评估的所有审计方法在对抗环境中都不够抗攻击和具有区分性。
### Conclusion
现有的数据审计方法在对抗攻击中表现出脆弱，因此迫切需要开发更为安全和可靠的审计方法，以抵御复杂的对抗操纵。
## 116. `cs.AI` - 基于搜索的元形态关系选择用于大型语言模型优化鲁棒性测试 [PDF](https://arxiv.org/pdf/2507.05565), [HTML](https://arxiv.org/abs/2507.05565)
### Authors
Sangwon Hyun,Shaukat Ali,M. Ali Babar
### Background
大型语言模型（LLMs）的信任性评估，特别是其鲁棒性，受到了广泛关注。元形态测试通过定义元形态关系（MRs）来评估LLM执行的鲁棒性，但现有的MR基于的鲁棒性测试仍需要大规模的MRs，因此需要优化MRs的选取。现有的大多数LLM测试研究主要集中在自动生成测试用例（即MRs）以增强故障检测，且主要集中于单一扰动的MR评估。相比之下，本研究提出了一种基于搜索的方法，以优化MR组合以最大化故障检测并最小化LLM执行成本，并考虑了MR中的组合扰动，从而扩展了鲁棒性评估的测试空间。该研究针对LLM鲁棒性测试中的元形态关系选择问题，开发了一种搜索过程，并实现了四种搜索算法：单向遗传算法（Single-GA）、基于非支配排序的遗传算法（NSGA-II）、Strength Pareto Evolutionary Algorithm 2（SPEA2）和多目标进化算法（MOEA/D），并结合了新的编码方法。在两个主要的LLM（具有主要文本到文本任务）上进行的比较实验中，研究揭示了两个关键发现：（1）MOEA/D算法在优化LLM鲁棒性测试的MR空间方面表现最佳；（2）发现了一些‘银弹’的MRs，这些MRs在不同文本到文本任务中具有显著的混淆LLM的能力。这项研究在LLM鲁棒性评估中揭示了优化测试的基本问题，并提供了基于搜索解决方案的见解。
### Innovation
本研究提出了一种基于搜索的方法，用于优化MR的选取以最大化故障检测并最小化LLM执行成本，并考虑了MR中的组合扰动，从而扩展了鲁棒性评估的测试空间。该方法使用了四种搜索算法：单向遗传算法（Single-GA）、基于非支配排序的遗传算法（NSGA-II）、Strength Pareto Evolutionary Algorithm 2（SPEA2）和多目标进化算法（MOEA/D），并结合了新的编码方法。实验结果表明MOEA/D算法在优化MR空间方面表现最佳，同时发现了一些适用于LLM鲁棒性测试的‘银弹’MRs，这些MRs在不同任务中具有显著的混淆LLM的能力。
### Conclusion
本研究揭示了在LLM鲁棒性测试中优化测试的基本问题，并基于实验结果提供了搜索基于的解决方案的见解。这项研究的方法和发现为未来的工作提供了基础，特别是对于开发更加有效的LLM测试技术具有重要意义。
## 117. `cs.AI` - DRAGON: 动态新闻RAG基准 [PDF](https://arxiv.org/pdf/2507.05713), [HTML](https://arxiv.org/abs/2507.05713)
### Authors
Fedor Chernogorskii,Sergei Averkiev,Liliya Kudraleeva,Zaven Martirosian,Maria Tikhonova,Valentin Malykh,Alena Fenogenova
### Background
Retrieval-Augmented Generation (RAG) 是一种通过在推理时引入外部知识来提高大型语言模型（LLMs）事实性的广泛采用方法。虽然已经存在多种针对英语的RAG基准测试，但其他语言，特别是俄语，的评估资源匮乏且静态，未能捕捉到现实世界部署中的动态性质。因此，本文提出DRAGON（Dynamic RAG Benchmark On News），一种专门为俄语设计的动态新闻基准测试，用于评估RAG系统在不断变化的新闻语料库上的表现。DRAGON基于定期更新的俄语新闻和公共文档语料库，支持检索器和生成器组件的全面评估。通过从语料库构建知识图谱自动产生问题，提取四种与不同子图模式对应的核心问题类型。
### Innovation
该论文提出了DRAGON，第一个用于评估俄语RAG系统的动态基准测试，特别是在不断变化的新闻语料库上。DRAGON的独特之处在于它基于定期更新的俄语新闻和公共文档语料库，支持检索器和生成器组件的全面评估。此外，通过使用知识图谱自动产生问题，可以提取四种核心问题类型，这些类型与不同的子图模式相对应。该研究还释放了一个包含评估框架、评估脚本和基准数据的完整测评系统，这些组件可能适用于其他语言和多语言设置，并启动了一个公共排行榜以促进社区参与和比较。
### Conclusion
该论文通过提出DRAGON，提供了一个动态的评估框架，用于衡量RAG系统在俄语新闻语料库上的表现。该框架不仅支持全面的系统评估，还提供了自动问题生成和四种核心问题类型的提取，推动了RAG技术的跨语言应用和社区间的比较。
## 118. `cs.AI` - 设计中的自动化推理用于漏洞管理 [PDF](https://arxiv.org/pdf/2507.05794), [HTML](https://arxiv.org/abs/2507.05794)
### Authors
Avi Shaked,Nan Messe
### Background
对于保障系统安全，管理其脆弱性状况并设计相应的安全控制措施是必不可少的。当前的漏洞管理方法不支持系统设计中脆弱性状况的系统性推理。需要一个能够自动化进行推理以有效管理漏洞和设计安全控制的机制，并应在开源安全设计工具中集成此机制，以应对实际挑战，实现系统的脆弱性管理的系统化方法。
### Innovation
本文提出了一种基于形式化理论的自动化推理机制，以系统性地管理系统的脆弱性状况。该机制被集成到开源安全设计工具中，通过实际挑战的示例，展示其应用实例，帮助系统设计者识别适用的漏洞，明确漏洞缓解选项，并声明所选控制措施。
### Conclusion
该研究通过集成自动化推理机制到开源工具中，实现了系统设计中的脆弱性系统性管理，为有效地识别和处理系统设计中的漏洞提供了新的方法。
## 119. `cs.AI` - 当变压器遇到推荐器：将自注意力序列推荐与微调的LLM集成 [PDF](https://arxiv.org/pdf/2507.05733), [HTML](https://arxiv.org/abs/2507.05733)
### Authors
Kechen Liu
### Background
SASRec作为一种有效的序列推荐方法，通过注意力机制捕捉用户的长期偏好。同时，大型语言模型（LLMs）的发展促进了基于LLM的推荐系统的研究，这些系统利用了LLMs强大的泛化能力和语言理解能力。然而，LLMs在仅仅依赖文本提示时缺乏领域特定知识和协作信号，这使得它们在生成高质量推荐方面存在局限性。这篇文章提出了SASRecLLM，一种新的框架，将SASRec作为协作编码器与通过低秩适应（LoRA）微调过的LLM集成，通过一个映射层连接这些组件，并设计了三种目标训练策略以优化混合架构。在多个数据集上进行的大量实验证明，SASRecLLM在冷启动和温启动场景中均能稳健且一致地超过强大的基线模型。这个工作在LLM基推荐领域推进了提出了一种模块化且有效的范式，将结构化的协作过滤与微调的LLM的语义能力有效融合。
### Innovation
本文提出了SASRecLLM，将SASRec作为协作编码器与通过低秩适应（LoRA）微调过的LLM进行集成。通过一个映射层连接这两个组件，并设计了三种目标训练策略来优化混合架构。该模型在多个数据集上均能够稳健且一致地超越强大的基线模型，甚至在冷启动和温启动的情况下也是如此。
### Conclusion
本文通过提出一种模块化且有效的范式，将结构化的协作过滤与微调的LLM的语义能力有效地融合，推进了LLM基推荐领域的研究。
## 120. `cs.AI` - LeAD：结合端到端自主驾驶的LLM增强规划系统 [PDF](https://arxiv.org/pdf/2507.05754), [HTML](https://arxiv.org/abs/2507.05754)
### Authors
Yuhang Zhang,Jiaqi Liu,Chengkai Xu,Peng Hang,Jian Sun
### Background
城市自主驾驶系统的广泛应用受到复杂场景和边缘案例的广泛存在所阻碍。现有系统的缺陷在于不能有效理解和解释交通场景中的语义信息，以及识别其他参与者的意图，导致生成的决策与熟练驾驶员的推理模式不一致。基于此背景，本研究旨在解决这些问题。
### Innovation
介绍了LeAD，一种结合了基于模仿学习的端到端框架和大型语言模型增强的双重速率自主驾驶架构。高频的端到端子系统维持实时感知-规划-控制循环，而低频的语言模型模块通过融合多模态感知和高清地图来增强场景理解，并在基础规划器遇到能力限制时通过链式思考（CoT）推理提供最优决策。这种架构提升了对非常规场景的处理能力，并在CARLA模拟器的Leaderboard V1基准测试中达到了71分，完成路线93%。
### Conclusion
实验结果表明LeAD架构在处理非常规任务和边角案例方面表现出色，展示了其在城市自主驾驶中的巨大潜力。
## 121. `cs.AI` - Constella: 通过基于LLM的多智能体支持故事作者的关联角色创作 [PDF](https://arxiv.org/pdf/2507.05820), [HTML](https://arxiv.org/abs/2507.05820)
### Authors
Syemin Park,Soobin Park,Youn-kyung Lim
### Background
在大多数长篇故事创作中，创造具有相关动态的登场人物角色是一个关键方面。然而，本研究通过调查14位作家发现，他们难以构想能够影响已有角色的新角色，难以平衡角色之间的相似性和差异性，也无法细腻地描绘角色间的相互关系。
### Innovation
根据以上观察结果，我们设计了基于LLM的多智能体工具Constella，以支持故事作者的角色创作过程。该工具包含FRIENDS DISCOVERY、JOURNALS和COMMENTS等特性，以辅助角色间的交互。在为期7-8天且包含11位作者的部署研究中，Constella不仅帮助作者构建相关的角色群体，还促进了角色思想和情感的比较，并更深入地理解角色间的关系。
### Conclusion
我们讨论了多智能体互动如何帮助分散作者对角色群体的注意力和精力。
## 122. `cs.AI` - 基于结构化知识图谱的概念机制可解释性 [PDF](https://arxiv.org/pdf/2507.05810), [HTML](https://arxiv.org/abs/2507.05810)
### Authors
Sofiia Chorna,Kateryna Tarelkina,Eloïse Berthier,Gianni Franchi
### Background
传统的基于概念的解释性方法主要关注神经网络预测的局部解释，本研究提出了一种新型框架和交互工具，旨在将这些方法扩展到机制解释性领域。该方法通过分析高层语义属性（称为概念）在内部模型组件中的出现、互动和传播来实现模型行为的全局分解。不同于之前的孤立研究个别神经元或预测的工作，该框架系统地量化了语义概念在各层中的表达，揭示了模型决策过程背后潜在的路径和信息流。关键创新是名为BAGEL的可视化平台（“BAGEL”代表“具有图的偏差分析的全局解释层”），它以结构化知识图的方式呈现这些见解，允许用户探索概念类别关系、识别虚假相关性，并提高模型可信度。框架是模型无特定限制的，可扩展的，并有助于更深入地理解如何在数据集偏差存在的情况下，深度学习模型进行泛化（或未能进行泛化）。
### Innovation
关键创新在于BAGEL可视化平台，它以结构化知识图的方式展示这些见解，允许用户探索概念类别关系、识别虚假相关性，并提高模型可信度。该平台以全局视角揭示了不同层次上的信息流动和决策机制。框架具有模型无特定限制和可扩展的特点，有助于更深入地理解深度学习模型如何在数据集偏差影响下进行泛化或未能泛化。
### Conclusion
该框架对模型的泛化具有无特定限制的影响，并对数据集偏差下的深度学习模型的机制提供了更深层次的理解。该研究还提供了可视化平台BAGEL，使用户能够探索概念之间的关系，识别潜在的错误关联，并提高对模型的信任度。
## 123. `cs.AI` - 使用卫星和机载LiDAR数据的自主车辆导航路径规划算法比较 [PDF](https://arxiv.org/pdf/2507.05884), [HTML](https://arxiv.org/abs/2507.05884)
### Authors
Chang Liu,Zhexiong Xue,Tamas Sziranyi
### Background
自主车辆在非结构化环境中，如森林和山地地区导航，面临显著挑战，由于地形不规则和复杂的道路条件。该研究利用高分辨率卫星图像和机载LiDAR数据生成加权像素级别路网，对主流和成熟的路径规划算法进行比较评价。
### Innovation
为2D路网导航测试了A*、Dijkstra、RRT*和一种新型改进蚁群优化算法(NIACO)，为3D路径规划测试了3D A*、3D Dijkstra、RRT-Connect和NIACO。所有算法在相同的起始和终点条件下进行评估，聚焦于路径成本、计算时间和内存消耗。
### Conclusion
结果表明，Dijkstra在2D和3D场景中均能提供最稳定和高效的性能，特别是在处理密集的像素级别地理路网时。这些发现强调了基于Dijkstra的规划方法在静态地形导航中的可靠性，并为进一步在复杂环境约束下的动态路径规划研究奠定了基础。
## 124. `cs.AI` - 通过统一合成框架弥合数据缺口赋能桥梁数字孪生 [PDF](https://arxiv.org/pdf/2507.05814), [HTML](https://arxiv.org/abs/2507.05814)
### Authors
Wang Wang,Mingyu Shi,Jun Jiang,Wenqian Ma,Chong Liu,Yasutaka Narazaki,Xuguang Wang
### Background
桥梁作为关键的交通基础设施，正面临老化和腐蚀带来的日益严峻的挑战，而传统的手动检查方法则因效率低下而显得力不从心。尽管3D点云技术为提供新的数据驱动模式提供了可能性，但其应用潜力常受限于现实数据的不完整性，这来源于标签缺失和扫描遮挡。现有合成数据方法缺乏足够的泛化能力来克服这个瓶颈，本文提出了一个系统框架以生成3D桥数据。
### Innovation
本文提出了一种系统性的框架来生成3D桥梁数据。该框架能够自动生成包含分组件实例注释、高保真色彩和精确的法向量的完整点云。此外，该框架还可扩展以模拟生成多样化的物理上现实的不完整点云，用于支持分割和完成网络的训练。
### Conclusion
实验结果表明，使用我们合成数据训练的PointNet++模型在真实桥梁语义分割中的平均交并比（mIoU）达到了84.2%。同时，微调后的KT-Net在部件完成任务上表现出卓越的性能。这项研究提供了一种创新的方法和基础数据集，用于3D桥梁结构的视觉分析，对于推动基础设施的自动化管理和维护具有重大意义。
## 125. `cs.AI` - 层次还是异层次？一种关于运动感觉脑的远程连接理论 [PDF](https://arxiv.org/pdf/2507.05888), [HTML](https://arxiv.org/abs/2507.05888)
### Authors
Jeff Hawkins(1),Niels Leadholm(1),Viviane Clay(1) ((1) Thousand Brains Project)
### Background
在传统的对新皮层的理解中，感觉信息被向上逐级传递，每一级处理越来越复杂的特征。信息也会通过另一组连接向下传递。尽管这种层次模型有较强的支持，但许多解剖连接并不符合标准的层次解释。此外，层次排列的区域有时会并行响应，而不是如层次中所发生的顺序响应。这些和其他证据表明，两个区域可以同时表现出并行和层次性的行为。基于这种灵活性，“异层次”可能是一个更适合描述新皮层组织的词汇。
### Innovation
该论文提出了关于运动感觉皮层中感觉和运动信息处理的新解释，即“千脑理论”。这一理论认为每个皮层柱是一个运动感觉学习系统，皮层柱通过整合感觉输入来进行学习，即使是在初级和次级区域（如V1和V2）也能学习并识别完整的3D物体。这种理论还解释了远程连接在异层次运动感觉区域中的具体作用，以及丘脑在对象姿态转换中的关键作用。
### Conclusion
我们提出的新视角对神经科学和人工智能都有广泛的影响。
## 126. `cs.AI` - 基于LLM的TTS系统可微奖励优化 [PDF](https://arxiv.org/pdf/2507.05911), [HTML](https://arxiv.org/abs/2507.05911)
### Authors
Changfeng Gao,Zhihao Du,Shiliang Zhang
### Background
本文提出了一种名为可微奖励优化（DiffRO）的新方法，旨在提高基于神经编码语言模型的文本转语音（TTS）系统的性能。与传统的基于人类反馈（RLHF）的强化学习方法不同，DiffRO 直接基于神经编码器的令牌计算奖励，而不是依赖于合成的音频。
### Innovation
DiffRO 利用 Gumbel-Softmax 技术使奖励函数可微，从而简化了 RLHF 训练过程；提出了多任务奖励（MTR）模型，可以从不同角度提供反馈，增强系统遵循指令的能力；实验结果表明，DiffRO 显著提高了 TTS 系统的发音准确性，达到基准测试 seed-tts-eval 的 SOTA WER 结果，并能够通过 MTR 模型在零样本的情况下控制情感和质量属性.
### Conclusion
实验结果表明，DiffRO 显著提高了 TTS 系统的发音准确性，达到 SOTA 的 WER 结果。通过结合 MTR 模型，展示了在没有训练的情况下控制情感和质量属性的能力。
## 127. `cs.AI` - 使用特质-响应中介的虚拟受访者进行项目验证 [PDF](https://arxiv.org/pdf/2507.05890), [HTML](https://arxiv.org/abs/2507.05890)
### Authors
Sungjib Lim,Woojung Song,Eun-Ju Lee,Yohan Jo
### Background
随着心理测量调查在评估大型语言模型（LLMs）特质方面的应用越来越广泛，适配LLMs的调查项目生成也变得越来越重要。传统的有效验证问卷项目需要大量的人力和资金，成本高昂。本文指出了构建有效问卷项目的挑战以及传统方法的局限性，强调了需要一种高效的、能大规模生成和验证问卷项目的框架。为此，研究人员提出了一个虚拟受访者模拟框架，利用LLMs来生成能够测量预期特质的问卷项目，通过引入中介变量的概念，从不同的角度模拟人的反应，从而保证了问卷项目的有效性和可靠性。此框架为成本效益更高的问卷开发开辟了新的可能性，并有助于深入理解LLMs如何模拟人类行为。
### Innovation
研究人员开发了一个虚拟受访者模拟框架，利用大型语言模型（LLMs）生成和验证有效的问卷项目。这一框架通过引入中介变量的概念，能够在不依赖大量人力和资金的情况下，生成能够准确测量预期特质的问卷项目。同时，该系统还能通过生成相关的中介变量和模拟受访者的行为来验证问卷项目的有效性。这种创新方法将为心理测量的研究和实践带来新的发展契机，并提供了宝贵的数据集和代码，以供未来的研究使用。
### Conclusion
本研究通过构建虚拟受访者模拟框架，利用LLMs生成和验证有效的心理测量问卷项目，展示了其在成本效益方面相比传统方法的优势。实验结果表明，该方法能够有效识别具有高建设性的问卷项目。本框架及其开发的工具为未来低成本、高效的心理测量项目开发提供了新方向，同时也加深了我们对LLMs如何复制人类行为的理解。
## 128. `cs.AI` - 特征导向型 vs. GAN导向型演示学习：何时何因 [PDF](https://arxiv.org/pdf/2507.05906), [HTML](https://arxiv.org/abs/2507.05906)
### Authors
Chenhao Li,Marco Hutter,Andreas Krause
### Background
本文提供了特征导向型和GAN导向型方法在学习从演示中进行学习方面的比较分析，重点在于奖励函数的结构及其对策略学习的影响。特征导向型方法提供了密集、可解释的奖励，非常适合高度保真的运动模仿，但往往需要复杂的参考表示，并且在非结构化环境中难以进行泛化。相比之下，GAN导向型方法使用隐式的、分布性的监督，使得其具有可扩展性和适应性灵活性，但却容易出现训练稳定性问题和粗糙的奖励信号。近年来，这两种范式的进步都强调了结构化运动表示的重要性，这种表示能够实现更平滑的过渡、可控的合成并提高任务集成度。
### Innovation
本文提出了一种框架，用于指导学习从演示中进行方法的选择，强调不同范式的算法权衡和设计考虑。认为特征导向型和GAN导向型方法之间的二元对立越来越微妙：选择方法不应该仅由一个范式主导，而应依据特定任务的优先级（如保真度、多样性、可解释性和适应性）。
### Conclusion
本文通过分析这些算法的权衡和设计考虑，提供了一个方法选择的框架，强调了在选择特定任务方法时应考虑任务特定优先级的重要性。
## 129. `cs.AI` - 通用表数据嵌入 [PDF](https://arxiv.org/pdf/2507.05904), [HTML](https://arxiv.org/abs/2507.05904)
### Authors
Astrid Franz,Frederik Hoppe,Marianne Michaelis,Udo Göbel
### Background
关系数据库中的表格数据占用了工业数据的重要部分，因此对表格数据进行分析和解释至关重要。表格数据的应用任务多种多样，在构建工业数据库时并不会明确指定这些任务。为了解决这一问题，本研究提出了一种新型框架，用于生成通用的、任务无关的表格数据嵌入，以便在未定义的目标下进行下游任务的执行。该方法将表格数据转换为图结构，利用图自编码器创建实体嵌入，然后将这些嵌入聚合以获得每行数据的嵌入，即每个数据样本。这种两步方法的优点在于，未见过的样本（由相似实体组成）可以在无需额外训练的情况下进行嵌入。通过在嵌入空间中应用基于距离的相似性度量，可以执行各种下游任务，如回归、分类或异常检测。实证研究表明，本方法在实际数据集上性能优于现有的通用表格数据嵌入技术。
### Innovation
提出了一种新型框架，用于生成通用的、任务无关的表格数据嵌入，无需预先定义目标即可执行下游任务。该方法将表格数据转换为图结构，并利用图自编码器创建实体嵌入。此两步过程使得未见过的数据样本可以无需额外训练进行嵌入，同时通过在嵌入空间中应用距离相似性度量进行回归、分类或异常检测等任务，从而实现无需预定义目标的任务执行能力。
### Conclusion
实验结果表明，本方法在实际数据集上的表现优于现有的通用表格数据嵌入技术，展现了其在工业数据库领域中的应用潜力。
## 130. `cs.AI` - 远程感知图像场景分类中解释性人工智能方法和度量的有效性研究 [PDF](https://arxiv.org/pdf/2507.05916), [HTML](https://arxiv.org/abs/2507.05916)
### Authors
Jonas Klotz,Tom Burgert,Begüm Demir
### Background
近年来，可解释的人工智能(xAI)方法在图像场景分类问题中的发展受到了遥感(RS)领域的广泛关注。大多数xAI方法及其相关评估指标最初是在计算机视觉(CV)领域为自然图像而开发，直接用于RS图像可能并不合适。因此，本文旨在研究解释方法和指标在RS图像场景分类中的有效性。
### Innovation
本文采用方法论分析和实验，研究了10种解释指标在三种RS数据集上的应用，涵盖了五个类别（忠实性、鲁棒性、定位、复杂性和随机化），应用了五种已建立的特征归因方法（遮挡、LIME、GradCAM、LRP和DeepLIFT）。研究发现，基于扰动的方法如遮挡和LIME在依赖于扰动基线和RS场景的空间特征时表现较差；基于梯度的方法如GradCAM在存在多标签时表现较差，而某些相关传播方法（如LRP）会不当地分配相关性。此外，研究也发现了评估指标的局限性。
### Conclusion
研究结果支持这些方法论发现，并提出了在RS图像场景分类中选择解释方法、指标和超参数的指导原则。
## 131. `cs.AI` - 基于太阳高度的场景照明引导 [PDF](https://arxiv.org/pdf/2507.05812), [HTML](https://arxiv.org/abs/2507.05812)
### Authors
Samed Doğan,Maximilian Hoh,Nico Leuze,Nicolas R.-Peña,Alfred Schöttl
### Background
自动驾驶功能的安全可靠开发高度依赖大量的高质量传感器数据，但在现实世界中，数据的采集需要大量的人工劳动，且受限于标注成本、司机安全协议以及多样场景的覆盖范围。因此，学术界着重于合成相机传感器数据的研究。然而，研究中存在关于白天变化这一显著差距，这主要是由于可用标签的稀缺性。为此，研究团队引入了太阳高度作为全球性调节变量，此变量可通过纬度、经度坐标和地方时间轻松计算，从而免除了大量手工标注的需求。
### Innovation
研究提出了太阳高度作为全球性调节变量，该变量无需额外的大量手动标注即可计算得出，减少了人工劳动的需求。同时，研究团队开发了专门针对日光对小型数字变化高度敏感性的归一化方法，能够精确捕捉光照特征和照明依赖性图像噪点，在扩散模型的背景下展示了其能力。
### Conclusion
通过引入太阳高度作为全球调节变量，研究改进了合成相机传感器数据的方法，提高了数据生成过程中对白天变化的处理能力，这对自动驾驶的传感器数据质量提升和成本降低有重要影响。
## 132. `cs.AI` - 事件数据分区对隐私感知过程发现的影响 [PDF](https://arxiv.org/pdf/2507.06008), [HTML](https://arxiv.org/abs/2507.06008)
### Authors
Jungeun Lim,Stephan A. Fahrenkrog-Petersen,Xixi Lu,Jan Mendling,Minseok Song
### Background
信息系统的执行事件日志通常包含客户的敏感信息，这带来了隐私挑战。隐私和时效性的权衡是困难的，尤其是复杂事件日志的匿名化会导致更高的时效性损失。
### Innovation
提出了一种结合匿名化和事件数据分区的管道，利用事件抽象进行分区。这种方法通过将事件日志分割成多个部分，允许每个子日志单独进行匿名化，同时保持隐私和减少时效性损失。
### Conclusion
通过在两个直接跟随基于的匿名化技术中使用三个实际事件日志和两种过程发现技术，研究结果表明，事件分区可以提高过程发现的时效性。
## 133. `cs.AI` - 利用卫星图像进行无需GNSS的地面激光雷达点云地理配准 [PDF](https://arxiv.org/pdf/2507.05999), [HTML](https://arxiv.org/abs/2507.05999)
### Authors
Xinyu Wang,Muhammad Ibrahim,Atif Mansoor,Ajmal Mian
### Background
在高大建筑和桥梁密集的城市区域，GNSS信号受限时，准确的地理解算激光雷达（LiDAR）点云成为一个重大挑战。现有方法通常依赖实时GNSS和IMU数据，需要预先校准，并假设数据收集期间的稳定定位。然而，这种假设在密集的城市区域经常失败，导致定位误差。
### Innovation
提出了一种结构化地理配准和空间矫正方法，通过卫星图像对3D点云进行配准，实现了每帧恢复GNSS信息和构建城市规模的3D地图，而不依赖于先验的定位。这种方法利用预训练的点变换器模型来分割道路点，从点云和目标地图中提取道路骨架和交叉点进行对齐。通过交叉点执行全局刚性对齐，然后使用径向基函数（RBF）插值进行局部细化。然后基于SRTM数据集的地貌信息对点云进行高程校正，以解决垂直差异。
### Conclusion
该方法在流行的KITTI基准数据集和西澳大利亚珀斯当地采集的数据集上进行了测试。在KITTI数据集上，该方法在有交叉口的序列中实现了平均平面对齐标准差（STD）0.84米，比原始数据集提高了55.3%。在缺乏GNSS信息的珀斯数据集上，该方法实现了平均STD 0.96米，相比从Google Maps API提取的GPS数据有77.4%的改进。该方法还在KITTI数据集上获得了30.5%的垂直相关性改进，在珀斯数据集上获得了50.4%的改进。
## 134. `cs.AI` - 及时更新传播的高效联邦学习 [PDF](https://arxiv.org/pdf/2507.06031), [HTML](https://arxiv.org/abs/2507.06031)
### Authors
Juncheng Jia,Ji Liu,Chao Huo,Yihui Shen,Yang Zhou,Huaiyu Dai,Dejing Dou
### Background
联邦学习（FL）作为管理分布式数据的一种有效方法逐渐成为研究热点，近年来取得了显著的进展。
### Innovation
提出了一种高效的联邦学习方法，该方法利用附加的下行链路带宽资源确保及时的模型更新传播。方法包括异步和同步框架下的两种策略：Asynchronous Staleness-aware Model Update (FedASMU) 和 FedSSMU，分别通过动态模型聚合技术和自适应模型调整机制提升准确性和效率。
### Conclusion
实验结果表明，FedASMU 和 FedSSMU 在准确性和效率方面显著优于基线方法，提升了高达 145.87% 的准确性和 97.59% 的效率。
## 135. `cs.AI` - HIRAG: 分级思考指令微调检索增强生成 [PDF](https://arxiv.org/pdf/2507.05714), [HTML](https://arxiv.org/abs/2507.05714)
### Authors
YiHan Jiao,ZheHao Tan,Dan Yang,DuoLin Sun,Jie Feng,Jian Wang,Peng Wei
### Background
检索增强生成（RAG）已经成为了解决大型语言模型在处理实时信息和领域特定问题时面临的挑战的基本范式。传统RAG系统主要依赖大型语言模型自身的上下文学习能力，但在具体能力上的研究不足，导致文档质量不一致和检索系统缺陷的问题。即使是部分微调RAG生成模型的研究也缺乏对RAG任务的详细关注或深度利用推理过程。
### Innovation
我们提出了RAG模型应具备三种逐步层次的能力：过滤、组合和RAG特定推理，以解决上述问题。基于此，我们引入了新的RAG指令微调方法，分级思想指令微调检索增强生成（HIRAG），它通过多级渐进的推理策略增强了模型的开放式考试能力。实验表明，HIRAG训练策略显著提高了模型在RGB、PopQA、MuSiQue、HotpotQA和PubMedQA等数据集上的性能。
### Conclusion
实验结果表明，HIRAG训练策略显著提升了模型在多个数据集上的性能。
## 136. `cs.AI` - Intra-DP: 移动边缘计算中的高性能协作推理系统 [PDF](https://arxiv.org/pdf/2507.05829), [HTML](https://arxiv.org/abs/2507.05829)
### Authors
Zekai Sun,Xiuxian Guan,Zheng Lin,Zihan Fang,Xiangming Cai,Zhe Chen,Fangming Liu,Heming Cui,Jie Xiong,Wei Ni,Chau Yuen
### Background
在资源受限的移动设备上部署深度神经网络（DNNs）带来了显著挑战，特别是要在有限的计算资源和电池寿命下实现实时性能。虽然移动边缘计算（MEC）通过与GPU服务器协作推理提供了解决方案，但现有方法主要依赖于按层分区模型，并且因DNN操作的顺序执行而产生了显著的传输瓶颈。
### Innovation
Intra-DP 提出了一种针对 MEC 的高性能协作推理系统，该系统采用基于局部操作（即不需要整个输入张量作为最小单元输入的操作，如卷积核）的创新并行计算技术。通过将计算（操作）分解为多个独立的子操作，并通过并行执行重叠不同子操作的计算与传输，Intra-DP 减轻了 MEC 中的传输瓶颈，实现了快速且节能的推理。
### Conclusion
评估结果显示，与最先进的基线相比，Intra-DP 的每轮推理延迟最多减少了50%，能耗最多减少了75%，并且没有牺牲准确性。
## 137. `cs.AI` - CAVGAN: 通过生成对抗攻击统一大语言模型的破解和防御 [PDF](https://arxiv.org/pdf/2507.06043), [HTML](https://arxiv.org/abs/2507.06043)
### Authors
Xiaohu Li,Yunfeng Ning,Zepeng Bao,Mayi Xu,Jianhao Chen,Tieyun Qian
### Background
大语言模型（LLM）的安全对齐机制使其能够抵御恶意查询，但各种牢笼攻击方法表明这种安全机制存在漏洞。之前的研究将LLM的牢笼攻击与防御隔离。本文分析了LLM的安全保护机制，并提出了一种结合攻击和防御的框架。该方法基于LLM中间层嵌入的线性可分性，以及牢笼攻击的本质，旨在嵌入有害问题并将其转移到安全区域。利用生成式对抗网络（GAN）来学习LLM内部的安全判断边界，实现高效的牢笼攻击与防御。实验结果表明，该方法在三个流行的LLM上实现了平均88.85%的破解成功率，同时在最先进的牢笼破解数据集上的防御成功率达到了平均84.17%。这不仅验证了该方法的有效性，还揭示了LLM内部的安全机制，为增强模型安全提供了新的见解。
### Innovation
本文提出了CAVGAN，一种结合生成式对抗网络来学习LLM内部安全判断边界的防御框架，该框架同时考虑了牢笼攻击的有效性和防御的效率。这种方法利用了LLM中间层嵌入的线性可分性以及牢笼攻击的本质，实现了对多个流行LLM的大规模实验验证，展现了显著的性能改进和发展潜力。这种方法不仅有效地识别和防御了牢笼攻击，还揭示了LLM内部的安全机制，为改进未来模型的安全性提供了新的思路和方法。
### Conclusion
实验结果表明，本方法在三个流行的LLM上实现了平均88.85%的破解成功率，而在最先进的牢笼破解数据集上的防御成功率达到了平均84.17%。这不仅验证了本方法的有效性，还揭示了LLM内部的安全机制，为增强模型的安全性提供了新的见解和方法。
## 138. `cs.AI` - 基于语义共现知识的偏部分多标签学习探索 [PDF](https://arxiv.org/pdf/2507.05992), [HTML](https://arxiv.org/abs/2507.05992)
### Authors
Xin Wu,Fei Teng,Yue Feng,Kaibo Shi,Zhuosheng Lin,Ji Zhang,James Wang
### Background
偏部分多标签学习旨在从不完全标注的数据中提取知识，包括已知正确的标签、已知错误的标签以及未知的标签。核心挑战在于准确识别标签和实例之间的模糊关系。
### Innovation
本文提出了一种新颖有效的偏部分多标签学习框架——语义共现洞察网络（SCINet），该框架通过引入双主导提示模块利用现成的多模态模型捕捉文本-图像关联并增强语义对齐，同时开发了跨模态融合模块，该模块适用于联合建模跨实例关系、跨标签关系和标签与实例分配下的共现模式，此外还提出了固有语义增强策略，通过应用多种图像变换增强模型对内在数据语义的理解，从而促进标签置信度与样本难度之间的协同关系。
### Conclusion
在四个广泛使用的基准数据集上的大量实验表明，SCINet超越了最先进的方法。
## 139. `cs.AI` - VisualSpeaker：视觉导向的3D头像唇部同步 [PDF](https://arxiv.org/pdf/2507.06060), [HTML](https://arxiv.org/abs/2507.06060)
### Authors
Alexandre Symeonidis-Herzig,Özge Mercanoğlu Sincan,Richard Bowden
### Background
逼真的高保真3D面部动画对于表达性的人机交互和无障碍技术至关重要。尽管现有方法显示了有希望的质量，但它们依赖于网格域使得难以充分利用2D计算机视觉和图形领域中快速发展的视觉创新。因此，本文提出了VisualSpeaker，一种结合光照现实的可微渲染的新方法，通过视觉语音识别进行监督，以提高3D面部动画质量。提出了基于感知的唇读损失，通过预训练的视觉自动语音识别模型来评估经光照现实3D高斯散点渲染得到的头像。结果表明，VisualSpeaker在标准的唇顶点错误度量上提高了56.1%，并提升了生成动画的感知质量，同时保留了网格驱动动画的可控性。这种感知导向的本质自然支持准确的唇动，这是区分手语头像中相似的手势的关键信息。
### Innovation
VisualSpeaker是一种将光现实可微渲染与视觉语音识别相结合的新方法，通过使用预训练的视觉自动语音识别模型来评估经光照现实3D高斯散点渲染得到的头像，并引入了基于感知的唇读损失。这种方法克服了现有方法依赖网格域的限制，能够充分利用2D计算机视觉和图形的最新进展。
### Conclusion
VisualSpeaker提高了标准的唇顶点错误度量，并提升了生成动画的感知质量，同时保持了网格驱动动画的可控性。这种方法关注感知特性，确保生成的头像具有准确的唇动，这对于区分手语头像中相似的手势至关重要。
## 140. `cs.AI` - 熵-记忆定律：评估大语言模型中数据的记忆难度 [PDF](https://arxiv.org/pdf/2507.06056), [HTML](https://arxiv.org/abs/2507.06056)
### Authors
Yizhan Huang,Zhe Yang,Meifang Chen,Jianping Zhang,Michael R. Lyu
### Background
大型语言模型（LLMs）通常会记住训练数据的部分内容，并在适当的提示下复现具体内容。然而，对于训练数据在LLMs中记忆难度的度量方法研究尚属空白，这使得难以准确评估模型对其训练数据的记忆程度。
### Innovation
本文通过在开放模型家族OLMo上进行实验证明了熵-记忆定律，即数据熵与记忆分数呈线性相关。同时，对于一些高随机性字符串或“乱码”的记忆研究揭示了这些看似随机的序列在训练语料库中具有比其本身更低的实际熵。基于熵-记忆定律的发现，提出了一种简单且有效的数据集区分方法，即数据集推断（DI）。
### Conclusion
熵-记忆定律提供了一种评估大语言模型内存载数据难度的新方法。采用熵-记忆定律发现的策略，可以通过低熵来识别训练数据和测试数据，实现数据集推断。
## 141. `cs.AI` - 通过多模态融合和端到端对齐增强从CBCT生成的sCT [PDF](https://arxiv.org/pdf/2507.06067), [HTML](https://arxiv.org/abs/2507.06067)
### Authors
Maximilian Tschuchnig,Lukas Lamminger,Philipp Steininger,Michael Gadermayr
### Background
锥束计算机断层摄影（CBCT）因快速获取和低辐射剂量而在术中成像中广泛应用。然而，CBCT图像通常会受到伪影和视效较差的影响，相较于传统的计算机断层摄影（CT）。一种潜在的解决方案是合成CT (sCT) 的生成，即将CBCT体积转换到CT领域。
### Innovation
本文通过结合术中CBCT与术前CT数据的多模态学习来增强sCT生成。为了解决模态固有的不对齐问题，引入了一个端到端可学习的对齐模块，该模块嵌入到sCT生成管道中。
### Conclusion
实验结果表明，在多模态sCT生成中结合对齐提高了sCT的质量，在90个评估设置中有79个超过了基准多模态方法。特别地，在CBCT质量较低且术前CT存在中度错位的情况下，改进最为显著。
## 142. `cs.AI` - 一种用于地球观测的卫星-地面协同大视觉语言模型系统 [PDF](https://arxiv.org/pdf/2507.05731), [HTML](https://arxiv.org/abs/2507.05731)
### Authors
Yuxin Zhang,Jiahao Yang,Zhe Chen,Wenjun Zhu,Jin Zhao,Yue Gao
### Background
近年来，在数据中心，大型视觉-语言模型（LVLMs）在低地球轨道（LEO）卫星地球观测图像分析中展现出强大的能力。然而，快速的卫星运动、短暂的卫星-地面站（GS）通信窗口以及大尺寸的图像下载带来了数据下载的挑战。为了实现近实时的地球观测应用（如灾害和极端天气监测），本研究探讨了如何在LEO卫星网络中部署LVLM，并设计了一种高效的卫星-地面协同LVLM推理系统，SpaceVerse。
### Innovation
首先，将紧凑型LVLM部署在卫星上进行轻量级任务，而常规LVMs则在GS上执行计算密集型任务。然后，提出了一种计算和通信协同设计框架，包括逐步信心网络和基于注意力的多尺度预处理，用于识别上星推理数据，并在卫星-GS传输前减少数据冗余。
### Conclusion
我们通过实地测试对LEO卫星星座和数据集实施并评估了SpaceVerse，相比最先进的基线方法，取得了31.2%的平均精度提升以及51.2%的延迟减少。
## 143. `cs.AI` - LighthouseGS: 室内结构感知的3D高斯点云渲染用于全景手机捕捉 [PDF](https://arxiv.org/pdf/2507.06109), [HTML](https://arxiv.org/abs/2507.06109)
### Authors
Seungoh Han,Jaehoon Jang,Hyunsu Kim,Jaeheung Surh,Junhyung Kwak,Hyowon Ha,Kyungdon Joo
### Background
最近在3D Gaussian Splatting (3DGS) 方面的进展使得在室内场景中实现高保真实时新颖视图合成 (NVS) 成为可能。然而，为了达到高质量的渲染效果，通常需要详尽采集覆盖整个场景的高质量图像，这对普通用户来说具有一定的限制性。本文旨在开发一种基于3DGS的新颖视图合成框架，该框架允许使用手持相机（例如移动设备）进行方便的全景模式拍摄。尽管这种方式方便，但由于旋转主导的运动和平局视角有限，这使得准确估计相机姿态和3D点位变得很具挑战性，尤其是在纯纹理室内场景中。
### Innovation
我们提出了LighthouseGS，这是一种基于类似全景图扫掠运动的新颖框架，受到了灯塔扫描模式的启发。LighthouseGS利用粗糙的几何先验知识，例如移动设备的相机姿态和单目深度估计，并利用室内环境中常见的平坦结构。我们提出了一种新的方法，即平面支架装配以生成一致的3D点，并采用了稳定的修剪策略来增强几何和优化的稳定性。此外，我们引入了几何和光度校正来解决由移动设备的运动漂移和自动曝光导致的一致性问题。
### Conclusion
在收集的真实和合成室内场景上进行测试，LighthouseGS实现了逼真的渲染效果，超越了现有的最先进的方法，并展示出了全景视图合成和物体安置的潜力。
## 144. `cs.AI` - 整合生成式AI解决基于ML的网络安全任务中的数据挑战：经验教训 [PDF](https://arxiv.org/pdf/2507.06092), [HTML](https://arxiv.org/abs/2507.06092)
### Authors
Shravya Kanchi,Neal Mangaokar,Aravind Cheruvu,Sifat Muhammad Abdullah,Shirin Nilizadeh,Atul Prakash,Bimal Viswanath
### Background
基于机器学习的监督分类器在安全任务中广泛应用，这些分类器的改进主要集中在算法上的提升上。然而，研究数据挑战及其对分类器性能的影响受到了较少的关注。本文研究了生成式AI（GenAI）是否能够解决这些问题，并提升分类器性能。
### Innovation
本文创新性地提出利用生成式AI技术生成合成数据来扩展训练数据集，以改善分类器的一般化能力。通过6种最新的GenAI方法在7种不同的安全任务上对该方法进行了评估，并引入了一种名为Nimai的新方案，实现对数据的高控制合成。结果显示，生成式AI技术在严重数据受限的情景下可显著提高安全分类器的性能。此外，研究还表明生成式AI有助于快速适应部署后的概念漂移，优化过程所需少量标签。
### Conclusion
尽管取得了成功，研究也发现某些生成式AI方案在特定安全任务上的初始化上存在挑战。具体任务的特性，如噪声标签、重叠类分布和稀疏特征向量，都会限制使用生成式AI进行性能提升。本文的研究成果将推动为网络安全任务设计的生成式人工智能工具的发展。
## 145. `cs.AI` - QS4D: 意识量化训练以提高结构化状态空间序列模型的硬件部署效率 [PDF](https://arxiv.org/pdf/2507.06079), [HTML](https://arxiv.org/abs/2507.06079)
### Authors
Sebastian Siegel,Ming-Jay Yang,Younes Bouhadjar,Maxime Fabre,Emre Neftci,John Paul Strachan
### Background
结构化状态空间模型（SSM）作为新兴的深度学习模型，特别适合处理长序列。与需求呈线性增长的Transformer模型相比，SSM的内存占用是恒定的，这使得它们成为资源受限的边缘计算设备的理想选择。虽然最近的研究探讨了量化感知训练（QAT）对SSM的影响，但它们通常没有考虑其对专有边缘硬件的影响，例如模拟内存计算（AIMC）芯片。
### Innovation
本研究展示了QAT可以显著降低SSM的复杂度，最高可减少两个数量级。我们分析了模型大小与数值精度之间的关系，并展示了QAT如何增强对模拟噪声的鲁棒性并使结构化修剪成为可能。最终，我们将这些技术集成到基于 memristive 的模拟内存计算基板上，并突显了在计算效率方面的收益。
### Conclusion
QAT对SSM的效果进行了深入研究，并通过提高其对模拟噪声的鲁棒性和实现结构化修剪，展示了改进方法在计算效率和硬件部署方面的关键优势。
## 146. `cs.AI` - TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-Guided Supervision [PDF](https://arxiv.org/pdf/2507.06033), [HTML](https://arxiv.org/abs/2507.06033)
### Authors
Syeda Anshrah Gillani,Mirza Samad Ahmed Baig,Osama Ahmed Khan,Shahid Munir Shah,Umema Mujeeb,Maheen Ali
### Background
现代基于文本到图像的扩散模型的发展已经引领了数字内容创作的新时代，证明了基于自然语言描述生成超写实且风格多样的图像的能力。然而，这些模型仍存在一个持续的问题，即无法生成可读、有意义且正确拼写的文本，这极大地限制了其实用价值，例如广告、学习和创意设计。
### Innovation
本文介绍了名为Glyph-Conditioned Diffusion with Character-Aware Attention (GCDA）的新框架，通过将三模块合并到一般扩散模型中来解决上述问题。第一，模型具有双流文本编码器，能够编码语义上下文信息和显式的字符表示，生成富有的字符感知输入文本表示。第二，提出了字符感知的注意力机制，并提出了一种新的注意力分割损失，以限制每个字符独立的注意力分布以避免视觉上的失真。最后，GCDA有一整套OCR-in-the-loop微调步骤，通过直接优化模型，使其具备更好的可读性和拼写准确性。
### Conclusion
大规模基准数据集（如MARIO-10M和T2I-CompBench）的实验表明，GCDA在所有指标上都达到了最新的最先进水平，特别是在基于字符的指标上表现突出，字符错误率降低至0.08（而之前的最佳为0.21），单词错误率降至0.15（之前的最佳为0.25）。并且，在人机感知和高保真图像合成质量方面表现可比拟。
## 147. `cs.AI` - 基于专家混合的语音质量评估模型：系统级性能增强及句级挑战分析 [PDF](https://arxiv.org/pdf/2507.06116), [HTML](https://arxiv.org/abs/2507.06116)
### Authors
Xintong Hu,Yixuan Chen,Rui Yang,Wenxiang Guo,Changhao Pan
### Background
自动语音质量评估在语音合成系统的发展中扮演着重要角色，但现有模型在不同预测任务细度上的性能存在显著差异。
### Innovation
提出了一种基于自监督学习语音模型的增强MOS预测系统，引入了Mixture of Experts (MoE)分类头，并利用多个商用生成模型的合成数据进行数据增强。该研究设计了专门的MoE架构，以应对不同类型的语音质量评估任务。此外，还收集了一个大规模的合成语音数据集，涵盖了最新的文本到语音、语音转换和语音增强系统。
### Conclusion
尽管采用了MoE架构和扩展的数据集，模型在句级预测任务上的性能提升仍然有限。研究揭示了当前方法处理句级质量评估的局限性，为自动语音质量评估领域提供了新的技术途径，并探讨了不同评估粒度下的性能差异的根本原因。
## 148. `cs.AI` - 复杂性结果中的说服 [PDF](https://arxiv.org/pdf/2507.05951), [HTML](https://arxiv.org/abs/2507.05951)
### Authors
Alban Grastien
### Background
本文探讨了说服问题的复杂性，尤其是在证明它是一个NP完全问题时，这与之前对该问题复杂性的研究有关。
### Innovation
该研究的主要创新在于首次证明了说服问题是一个NP完全问题，这意味着该问题的解决在计算复杂性上具有挑战性。
### Conclusion
本文通过证明说服问题的NP完全性，揭示了该问题在计算上的困难，并为说服问题的研究提供了新的视角，可能为开发相关算法提供指导。
## 149. `cs.AI` - 从符号下降视角简化的Adam收敛证明 [PDF](https://arxiv.org/pdf/2507.05966), [HTML](https://arxiv.org/abs/2507.05966)
### Authors
Hanyang Peng,Shuang Qin,Yue Yu,Fangqing Jiang,Hui Wang,Zhouchen Lin
### Background
Adam 是深神经网络（DNN）训练中最有效的优化器之一，尽管它在实践中表现优异，但其理论上的收敛分析仍不够完善。现有的工作大多将 Adam 解释为动量预条件随机梯度下降（SGDM），这种解释需要很强的假设和复杂的技巧，导致其收敛证明既冗长又难于验证和扩展。
### Innovation
本文提出了一种新颖的解释，将 Adam 视为类似符号梯度下降的优化器。具体来说，将 Adam 的更新公式简化为 $bm{x}_{t+1} = bm{x}_t - frac{rm Sign}(bm{m}_t) frac{bm{m}_t}{bm{v}_t^{1/2}+bar{bm{u}}} times frac{rm Sign}(bm{m}_t) times frac{bm{m}_t}{bm{v}_t^{1/2}+bar{bm{u}}}$，这显著简化了其收敛分析。此外，作者证明，在一些温和的条件下，Adam 达到了 $Obig(frac{1}{T^{1/4}}big)$ 的最优收敛率，而之前的收敛率是 $Obig(frac{text{ln} T}{T^{1/4}}big)$，并且这一结果与模型维度或数值稳定性参数无关。这种新的理论分析还提供了关于动量在确保收敛性中的关键作用的新见解，并为调优 Adam 的学习率提供了实用指南，缩小了理论与实践之间的差距。
### Conclusion
本文在弱化的假设条件下，证明了 Adam 达到了 $Obig(frac{1}{T^{1/4}}big)$ 的最优收敛率，而无需依赖模型维度或数值稳定性参数。这种新的理论分析还为 Adam 的动量提供了关键见解，并为调优学习率提供了实用指南。
## 150. `cs.AI` - PrefixAgent: 一种基于LLM的高效前缀加法器优化设计框架 [PDF](https://arxiv.org/pdf/2507.06127), [HTML](https://arxiv.org/abs/2507.06127)
### Authors
Dongsheng Zuo,Jiadong Zhu,Yang Luo,Yuzhe Ma
### Background
前缀加法器是基本的算术电路，但随着位宽度的增长，其设计空间呈指数级增长，提出了显著的优化挑战。以往的研究在性能、泛化能力和可扩展性方面存在局限性。
### Innovation
我们提出了PrefixAgent，一种由大型语言模型（LLM）驱动的框架，能够促进高效的前缀加法器优化。PrefixAgent通过将问题重新定义为包括骨干生成和结构细化的子任务，有效减少了搜索空间。此外，这种新的设计视角使我们能够借助E-图高效地收集大量高质量的数据和推理过程，进一步对LLM进行精调。实验结果表明，PrefixAgent合成的前缀加法器相比基线方法在面积上更小，同时在商业EDA流程中具备可扩展性和泛化能力。
### Conclusion
PrefixAgent在前缀加法器优化方面表现出色，通过有效的数据和推理收集及精调LLM，解决了传统方法在性能、泛化能力和可扩展性上的局限性。
## 151. `cs.AI` - NeoBabel: 多语言开放塔结构的视觉生成 [PDF](https://arxiv.org/pdf/2507.06137), [HTML](https://arxiv.org/abs/2507.06137)
### Authors
Mohammad Mahdi Derakhshani,Dheeraj Varghese,Marzieh Fadaee,Cees G. M. Snoek
### Background
文本到图像生成技术主要集中在英语上，这为非英语使用者设下了障碍，加剧了数字不平等现象。现有系统依赖翻译管道，但这会引入语义漂移、计算负担增加和文化错位等问题。为解决这些问题，本文提出了NeoBabel，这是一种新型多语言图像生成框架，支持包括英语、中文、荷兰语、法语、印地语和波斯语在内的六种语言，该模型结合大规模多语言预训练和高分辨率指令调优进行训练。
### Innovation
本文提出了NeoBabel，这是一种新型的多语言图像生成框架，能够实现最先进的多语言性能，同时保留了强大的英语能力。NeoBabel通过面向目标对齐训练在多语言基准测试中表现优异，即使是在英语任务上，性能也与领先模型相当，同时在多语言基准测试中分别提升了0.11和0.09的得分。此外，引入了新的评估多语言对齐和代码混杂提示鲁棒性的度量标准。NeoBabel比英语专有模型小2-4倍，但却能匹配甚至超越英语专有模型的性能。
### Conclusion
该研究表明，多语言能力不是一种权衡，而是生成式AI提升鲁棒性、效率和文化准确性的催化剂。我们发布了包含代码、模型检查点、多语言图文数据集以及标准化评估协议的开源工具包，以促进包容性AI研究的发展。
## 152. `cs.AI` - 代码三角形：大型语言模型如何理解代码？ [PDF](https://arxiv.org/pdf/2507.06138), [HTML](https://arxiv.org/abs/2507.06138)
### Authors
Taolin Zhang,Zihan Ma,Maosong Cao,Junnan Liu,Songyang Zhang,Kai Chen
### Background
大型语言模型（LLMs）在代码生成方面取得了显著进展，但它们的真实编程能力仍需进一步探索。这项研究提出了一种名为‘代码三角形’的框架，该框架从三个基本维度系统地评估LLMs：编辑分析、代码实现和测试案例生成。实验表明，虽然LLMs可以在这些维度之间形成一个自洽的系统，但它们的解决方案往往缺乏人类程序员的多样性和稳健性。研究发现，模型的认知分布与人类专长之间存在显著差异，模型错误往往会因为训练数据偏差和推理转移有限而聚集在一起。该研究展示了如何通过结合人类生成的编辑、解决方案和多样化的测试用例，以及利用模型混合体来显著提升LLMs的性能和稳健性。
### Innovation
该研究提出了一种新的评估LLMs在代码生成能力上的‘代码三角形’框架，从编辑分析、代码实现和测试案例生成三个维度系统评估LLMs。研究指出结合人类生成的编辑、解决方案和测试用例可以大幅提升LLMs的性能和稳健性，并指出了模型认知的一致性和不一致性，为开发更强大的编程模型提供了潜在方向。
### Conclusion
研究表明，通过结合人类生成的编辑、解决方案和多样化的测试用例，以及利用模型混合体，可以显著提升LLMs的性能和稳健性。同时，研究还揭示了LLMs认知中的一致性和不一致性，为模型的自我反思和自我改进提供了可能的方向。
## 153. `cs.AI` - SoftReMish: 一种增强卷积神经网络视觉识别性能的新激活函数 [PDF](https://arxiv.org/pdf/2507.06148), [HTML](https://arxiv.org/abs/2507.06148)
### Authors
Mustafa Bayram Gücen
### Background
本文提出了一个新的激活函数SoftReMish，旨在提高卷积神经网络（CNNs）在图像分类任务中的性能。通过使用MNIST数据集，实现了一个标准的CNN结构，该结构包含两个卷积层、最大池化和全连接层。对比了SoftReMish与流行的激活函数ReLU、Tanh和Mish在所有可训练层中替换激活函数后的表现。模型性能通过评估最小训练损失和最大验证准确性来衡量。结果表明，SoftReMish在最小损失(3.14e-8)和验证准确率(99.41%)方面均优于其他测试的激活函数。这些结果证明了SoftReMish的收敛行为和泛化能力更好，使其成为视觉识别任务的一个有前途的候选者。
### Innovation
提出了一个新的激活函数SoftReMish，通过对其在MNIST数据集上的验证，表明它在图像分类任务中具有优于ReLU、Tanh和Mish的性能，特别是在最小损失和最大验证准确率方面表现出色，同时具有更好的收敛行为和泛化能力。
### Conclusion
SoftReMish是一种性能优秀的激活函数，适用于视觉识别任务。
## 154. `cs.AI` - 使用自适应sigma点采样法在自主驾驶车辆中快速准确地估计碰撞概率 [PDF](https://arxiv.org/pdf/2507.06149), [HTML](https://arxiv.org/abs/2507.06149)
### Authors
Charles Champagne Cossette,Taylor Scott Clawson,Andrew Feit
### Background
为了估计动态物体之间具有不确定性轨迹的碰撞概率，提出了一个新颖的算法，该算法将轨迹表示为具有高斯分布的位姿序列。重要的是，该算法明确考虑了碰撞概率的时间依赖性，这在先前的工作中经常被忽视，可能导致对碰撞概率的过估计。
### Innovation
提出了一种自适应sigma点采样方案，该方案最终生成了一个快速且简单的算法，能够以3.5%的中位误差和0.21毫秒的中位运行时间估计碰撞概率。该算法能够在Intel Xeon Gold 6226R处理器上高效运行。
### Conclusion
该方法被测试在400个6秒的自主车辆日志片段上，以及不同应用场景下，对算法的准确性与延迟进行了严格评估。
## 155. `cs.AI` - LangMamba：一种基于语言的低剂量CT降噪框架，结合视觉语言模型 [PDF](https://arxiv.org/pdf/2507.06140), [HTML](https://arxiv.org/abs/2507.06140)
### Authors
Zhihao Chen,Tao Chen,Chenhui Wang,Qi Gao,Huidong Xie,Chuang Niu,Ge Wang,Hongming Shan
### Background
低剂量计算机断层扫描（LDCT）虽然减少了辐射暴露，但可能会降低图像质量，影响诊断准确性。现有的基于深度学习的去噪方法主要关注像素级映射，未能充分利用高阶语义指导。视觉语言模型（VLMs）的最新进展表明，语言可以作为一种强大的工具来捕获结构化的语义信息，为改善LDCT重建提供新机会。
### Innovation
引入了LangMamba，一种语言驱动的Mamba框架，利用VLMs提取的表示来增强正常剂量CT（NDCT）对LDCT降噪的监督。该框架采用两阶段学习策略：首先预训练一个语言导向的自动编码器（LangAE），利用冻结的VLMs将NDCT图像映射到富含解剖信息的语义空间；其次，通过Semantically-Enhanced Efficient Denoiser（SEED）和Language-engaged Dual-space Alignment（LangDA）损失来引导LDCT去噪。
### Conclusion
在两个公开数据集上的实验表明，LangMamba优于传统最先进的方法，显著提高了细节保留和视觉保真度。LangAE表现出强大的泛化能力，减少了训练成本。LangDA损失通过结合语言引导的洞见改进了解释性，并提供了一种即插即用的方式。我们的研究结果展示了语言作为监督信号在推进LDCT降噪方面的潜力。
## 156. `cs.AI` - 差分逻辑门网络中连接优化的方法 [PDF](https://arxiv.org/pdf/2507.06173), [HTML](https://arxiv.org/abs/2507.06173)
### Authors
Wout Mommen,Lars Keuninckx,Matthias Hartmann,Piet Wambacq
### Background
本文介绍了在深度可微逻辑门网络（LGNs）中对连接进行部分优化的新方法。该方法利用每个门输入子集连接的概率分布，在选择具有最高价值的连接之后，确定门的类型。研究显示，优化后的连接LGNs在Yin-Yang、MNIST和Fashion-MNIST基准测试中表现优于标准固定连接LGNs，所需的逻辑门数量却只是一小部分。当对所有连接进行训练时，使用8000个简单的逻辑门即可达到MNIST数据集超过98%的准确率。此外，与标准完全连接的LGNs相比，该网络中的逻辑门数量减少了24倍，但在MNIST数据集上的性能更好。因此，本工作展示了通往完全可训练布尔逻辑的路径。
### Innovation
提出了一种在Deep Differentiable Logic Gate Networks中对连接进行部分优化的新方法。利用门输入子集连接的概率分布选择具有最高价值的连接，并确定门的类型。在训练所有连接的情况下，仅需8000个简单的逻辑门就能够在MNIST数据集上达到超过98%的准确率，展示了该方法在减少逻辑门数量和提高性能方面的创新性。此外，与标准完全连接的LGNs相比，该网络中的逻辑门数量被显著减少，但性能更好。
### Conclusion
本文提出的方法显示了向完全可训练布尔逻辑迈进的可能性。通过部分优化连接，不仅减少了所需逻辑门的数量，还在特定任务上实现了更好的性能。
## 157. `cs.AI` - 通过实际评价协议实现有效音频指纹识别的对比学习与迁移学习 [PDF](https://arxiv.org/pdf/2507.06070), [HTML](https://arxiv.org/abs/2507.06070)
### Authors
Christos Nikou,Theodoros Giannakopoulos
### Background
近年来，歌曲识别技术利用深度神经网络直接从原始声波中学习紧凑的音频指纹取得了显著进展。尽管这些方法在受控条件下表现出色，但在使用移动设备的嘈杂环境下录制的音效较真实的场景中，其准确性会显著下降。本文通过引入一种更能反映真实场景条件的新型评价协议来解决这个问题。该协议生成三个同样的音频记录，分别采用手机麦克风录制并逐渐增加噪声水平。
### Innovation
1. 引入了基于对比损失训练过程中增强管道的角色，通过引入低通和高通滤波器显著提高了系统性能。2. 开发了一种带有定制投影模块的变压器模型，通过从语义相关领域的知识迁移来获得更稳健的解决方案。变压器架构在所有噪声级别和查询持续时间下均优于卷积模型。3. 在低噪声条件下，1秒查询的识别准确率为47.99%，10秒查询的识别准确率为97%，超过了第二好的模型的14%和18.5%。4. 在严重噪声条件下，15秒查询的识别率为56.5%。
### Conclusion
本研究在大规模公开数据集上进行实验，发现了现有最好的卷积模型在反向协议下的显著性能下降，表明真实环境的挑战对模型性能有重大影响。引入关键增强技术和语义相关领域的知识迁移学习，有效提高了音频指纹识别的鲁棒性和性能。
## 158. `cs.AI` - 复杂网络中的关键节点识别：综述 [PDF](https://arxiv.org/pdf/2507.06164), [HTML](https://arxiv.org/abs/2507.06164)
### Authors
Duxin Chen,Jiawen Chen,Xiaoyu Zhang,Qinghan Jia,Xiaolu Liu,Ye Sun,Linyuan Lv,Wenwu Yu
### Background
复杂网络已成为社会系统、交通系统、生物分子系统和金融系统中理解多样现象的不可或缺的工具。识别关键节点是当前研究中的核心主题，是理论基础和实际应用之间的关键桥梁。然而，现实世界网络的内在复杂性和结构性异质性，特别是动态和高阶网络的特点，对建立通用的关键节点识别框架构成重大障碍。
### Innovation
本文提供了一个全面的关键节点识别技术的综述，将这些技术分类为七大类：中心性、关键节点删除问题、影响最大化、网络控制、人工智能、高阶和动态方法。综述通过系统地分类方法的研究基础和实际应用，填补了现有综述中的空白，并突显了各种网络类型中的优势、局限性和适用性。作品增强了对关键节点研究的理解，特别是在算法普适性、动态网络中的实时评估、高阶结构分析以及大规模网络中的计算效率方面。结构化的综合总结了当前的研究进展，并突出了开放问题，特别是在建模时间动态、推进高效算法、整合机器学习方法以及为复杂系统开发可扩展且可解释的指标方面。
### Conclusion
本文结构化的综述有助于当前进展，并强调了在建模时间动力学、推进高效算法、整合机器学习方法和开发复杂系统中可扩展且可解释的指标方面的开放问题。
## 159. `cs.AI` - 无传感器力控制通过精确动力学模型实现快速双边遥操作和模仿学习 [PDF](https://arxiv.org/pdf/2507.06174), [HTML](https://arxiv.org/abs/2507.06174)
### Authors
Koki Yamane,Yunhan Li,Masashi Konosu,Koki Inami,Junji Oaki,Sho Sakaino,Toshiaki Tsuji
### Background
近年来，模仿学习的进步引起了对低成本操作器进行遥传输操作以收集演示数据的兴趣增加。然而，现有的大多数系统依赖单向控制，只能传输目标位置值。尽管这种方法易于实现且适合低速、非接触任务，但在高速或接触密集的操作中却因缺乏力反馈而难以应对。
### Innovation
通过利用4通道双边控制，即使是没有力传感器的低成本操作器，也可以实现带有力反馈的快速遥操作。本方法基于准确识别的操作器动力学，整合了非线性补偿、速度和外部力估计以及针对惯性变化的可变增益。还展示了使用4通道双边控制收集的数据表明，将力信息纳入被学习策略的输入和输出，可以提高模仿学习的表现。
### Conclusion
这些结果强调了本系统在低成本硬件上的高性能遥操作和数据收集的实际效果。
## 160. `cs.AI` - 材料属性发现中的主题建模和链接预测 [PDF](https://arxiv.org/pdf/2507.06139), [HTML](https://arxiv.org/abs/2507.06139)
### Authors
Ryan C. Barron,Maksim E. Eren,Valentin Stanev,Cynthia Matuszek,Boian S. Alexandrov
### Background
科学文献网络和知识图往往是大型、稀疏和嘈杂的，通常包含实体之间的缺失链接。因此，链接预测方法至关重要，它可以在复杂材料领域中推断隐藏关联，促进探索。本文研究了基于46,862篇关于73种过渡金属二硫属化合物(TMDs)的文献，这些材料涉及多种物理学领域，包含许多当前和潜在的应用。通过这种方法，可以提出跨学科探索的新假设并生成新的研究假设，促进科学发现。验证方法通过将关于超导性的文献从已知超导材料中移除，并展示该模型预测与超导TMD群的关系。该方法特别适用于检查涵盖同一类现象或材料但来自不同社区和视角的科学文献集。生成的假设通过一个交互式的Streamlit仪表板揭露，该仪表板适合人类在回路的科学发现过程。各种模型（如Heterarchical NMFk、Boolean NMFk、Logistic矩阵分解等）的组合及其再利用预选模型的选择机制，使得该框架具有创新性。
### Innovation
本文提出了一种基于AI的层次链接预测框架，该框架结合了多种矩阵分解技术（如Hierarchical NMFk、Boolean NMFk、Logistic矩阵分解等）及自动模型选择方法。这些技术与布尔矩阵分解相结合，形成了一个能够在复杂材料领域中隐含关联中推断主题树，并在科学文献网络中提出新的研究假设的框架。框架还结合了LU分解，以提高算法的效率，同时确保生成的假设具有实际意义，通过一个交互式的Streamlit仪表板暴露出来，使人可以容易理解和操作。
### Conclusion
本文提出了一个在大型稀疏网络中进行主题建模和链接预测的方法，能够有效地发现隐藏在复杂材料网络中的关联，并生成新的研究假设。通过与已知超导材料数据的比较，验证了该方法的有效性。该方法不仅适用于材料科学领域，还可以应用于其他科学文献网络，促进跨学科研究中的科学发现。
## 161. `cs.AI` - 基于子空间的近似海森矩阵零阶优化方法 [PDF](https://arxiv.org/pdf/2507.06125), [HTML](https://arxiv.org/abs/2507.06125)
### Authors
Dongyoon Kim,Sungjae Lee,Wonjin Lee,Kwang In Kim
### Background
零阶优化处理那些无法获取或难以计算梯度信息的问题。虽然大多数现有方法依赖于一阶近似，但理论上引入二阶（曲率）信息可以显著加速收敛。然而，评估函数以估算海森矩阵所需的高成本限制了其实用性。
### Innovation
提出了基于子空间的近似海森（ZO-SAH）方法，这是一种零阶优化算法，通过集中处理随机选择的二维子空间来减轻这些成本。在每个子空间内，ZO-SAH通过拟合目标函数的二次多项式并提取其二阶系数来估计海森矩阵。进一步，ZO-SAH采用周期性的子空间切换策略，在优化步骤间重用函数评估以降低函数查询成本。
### Conclusion
在包括逻辑回归和深度神经网络训练在内的八个基准数据集中，实验表明，ZO-SAH 方法的收敛速度显著快于现有的零阶方法。
## 162. `cs.AI` - DS@GT在CheckThat! 2025中的主题性检测：基于转移学习和校正数据增强 [PDF](https://arxiv.org/pdf/2507.06189), [HTML](https://arxiv.org/abs/2507.06189)
### Authors
Maximilian Heil,Dionne Bang
### Background
本文探讨了在CLEF 2025的CheckThat! Lab任务1中进行主观性检测的有效性。研究背景在于通过迁移学习和风格化数据增强来提高对英语新闻文本中主观和客观句子的分类效果，与针对相关任务的微调预训练编码器和微调变换器相比较，提出了一种新的机器学习方法，并使用GPT-4o生成预定义风格的主题性重述，以保证标签和风格一致，从而提高模型的稳健性，特别在检测主观内容方面效果显著。
### Innovation
本文创新点在于提出了一种新的结合编码器专业化和标签一致增强的数据增强方案，以及使用GPT-4o生成预定义风格的主题性重述，并通过相同模型对生成的样本进行纠正和完善，使得模型在主观性检测方面表现出色。
### Conclusion
研究结果表明，针对特定编码器的迁移学习优于通用编码器的微调，精细策划的数据增强能显著提高模型的稳健性，特别是在检测主观内容方面。我们的研究成果强调了结合编码器专业化与标签一致增强方法的重要性。最终提交的结果使我们在24名参赛者中排名第16位。
## 163. `cs.AI` - OpenFActScore：文本生成事实性原子评估的开源实现 [PDF](https://arxiv.org/pdf/2507.05965), [HTML](https://arxiv.org/abs/2507.05965)
### Authors
Lucas Fonseca Lage,Simon Ostermann
### Background
当前，评价大规模语言模型（LLMs）生成文本的事实准确性主要依赖于一些封闭源代码和商业平台提供的工具，如InstructGPT和ChatGPT。这些方法限制了评估的可扩展性和透明度。学者们需要一种更加开放和透明的方法来评估LLMs生成的长段落文本的事实准确性。本文介绍了一种开源的框架OpenFActScore，它使用原子事实生成（AFG）和原子事实验证（AFV）的方法来评估文本的事实准确性。
### Innovation
OpenFActScore是首次使用任何与Hugging Face兼容的模型来实现AFG和AFV，这使得评估过程更加开放和灵活。与原版FActScore相比，OpenFActScore打破了对某些特定封闭源代码模型的依赖，同时评估了多个开源LLM在AFG和AFV任务上的性能。
### Conclusion
OpenFActScore展示了开源模型可以与封闭源代码系统取得相似的性能。通过详细的实验证明了其有效性，并获得了0.99的皮尔逊相关系数。此框架提高了评估过程的透明度、可再现性和成本效益。
## 164. `cs.AI` - SQLBarber: 一种利用大型语言模型生成定制化和现实化的SQL工作负载的系统 [PDF](https://arxiv.org/pdf/2507.06192), [HTML](https://arxiv.org/abs/2507.06192)
### Authors
Jiale Lao,Immanuel Trummer
### Background
数据库研究和开发通常需要大量SQL查询来进行基准测试。然而，由于隐私问题，获取真实世界的SQL查询具有挑战性，现有的SQL生成方法在定制化和满足现实约束方面也有局限性。
### Innovation
本文介绍了一种名为SQLBarber的系统，该系统基于大规模语言模型（LLMs）来生成定制化和现实化的SQL工作负载。SQLBarber系统能够：(i) 无需用户事先手动创建SQL模板，通过接受自然语言规格来限制SQL模板；(ii) 高效地生成大量匹配任意用户定义成本分布的查询（如基数和执行计划成本）；(iii) 使用来自Amazon Redshift和Snowflake的执行统计信息来制定反映实际查询特征的SQL模板规范和查询成本分布。该系统还在代数模板自纠模块、基于贝叶斯优化器的SQL生成等方面进行了创新。
### Conclusion
作者构建了基于Snowflake和Amazon Redshift真实统计数据的十个不同难度级别的基准测试。实验结果表明，SQLBarber是唯一一个能够生成定制化SQL模板的系统，它将查询生成时间减少了1到3个数量级，并显著提高了与目标成本分布的一致性，与现有方法相比表现更优。
## 165. `cs.AI` - EC-Flow: 通过体态中心流从无动作标签的视频中实现灵活的机器人操作 [PDF](https://arxiv.org/pdf/2507.06224), [HTML](https://arxiv.org/abs/2507.06224)
### Authors
Yixiang Chen,Peiyan Li,Yan Huang,Jiabing Yang,Kehan Chen,Liang Wang
### Background
当前的语言引导机器人操作系统通常需要低级动作标记的数据集来进行模仿学习。尽管基于对象的流预测方法减轻了这一问题，但它们仍然局限于涉及刚性物体且具有清晰位移和少量遮挡的场景中。本研究提出了一种新的框架EC-Flow，该框架可以通过预测体态中心流直接从无动作标签的视频中学习操作，旨在克服上述限制，适用更广泛的操纵场景，包括柔性物体处理、遮挡和非物体位移任务。
### Innovation
EC-Flow引入了体态中心流的概念，直接从无动作标签的视频中学习操作，通过整合体态的固有运动学特性，显著提高了在灵活操作场景中的泛化能力。它进一步引入了一个目标对齐模块，通过运动一致性和目标图像预测的联合优化，将EC-Flow与语言指令和对象交互连接起来。EC-Flow只需要一个标准的机器人URDF文件来指定关节间的运动约束，使得在实践中易于使用。该研究还在模拟和现实操作任务中验证了EC-Flow，显示其在处理遮挡物体和柔性物体操作以及非物体位移任务方面的性能超越了现有方法。
### Conclusion
EC-Flow不仅在处理遮挡物体操作上提升了62%，在柔性物体操作上提升了45%，在非物体位移任务上提升了80%，显示出其在多种场景中的优越性能，证明了其在机器人操作领域的创新性。
## 166. `cs.AI` - 差分Mamba [PDF](https://arxiv.org/pdf/2507.06204), [HTML](https://arxiv.org/abs/2507.06204)
### Authors
Nadav Schneider,Itamar Zimerman,Eliya Nachmani
### Background
序列模型如Transformer和RNNs经常过度关注无关的上下文，导致生成噪声较大的中间表示。这会降低语言模型（LLM）的能力，包括增强幻觉、削弱长距离和检索能力以及降低鲁棒性。最近的工作表明，差分设计可以减轻Transformer中的这一问题，并改善其在各种应用中的效果。这项研究旨在探索将这些技术应用于Mamba（一种基于选择性状态空间层的最近架构，它具有与Transformer相当的性能但更有效率）的可能性。
### Innovation
研究发现，直接将差分设计应用到Mamba是不够的，需要进行精细的架构修改。为此，研究引入了一种新颖的差分机制，已在语言模型基准测试中得到实证验证，证明了检索能力和与vanilla Mamba相比的优越性能。此外，进行了详尽的消融研究和实证分析以支持设计选择，并提供了证据证明这种方法有效地缓解了基于Mamba模型的过度分配问题。
### Conclusion
研究结果表明，该方法有效地缓解了Mamba基于模型的过度分配问题。代码已公开可用。
## 167. `cs.AI` - 大型语言模型中演绎和归纳推理的作用 [PDF](https://arxiv.org/pdf/2410.02892), [HTML](https://arxiv.org/abs/2410.02892)
### Authors
Chengkun Cai,Xu Zhao,Haoliang Liu,Zhongyu Jiang,Tianfang Zhang,Zongkai Wu,Jenq-Neng Hwang,Lei Li
### Background
大型语言模型（LLMs）在推理任务中已经表现出色，但它们依赖于静态提示结构以及在复杂情景下的有限适应能力仍然是一个显著的挑战。
### Innovation
本文提出了Deductive and InDuctive（DID）方法，这是一种新的框架，通过动态融合演绎和归纳推理方法来增强LLM的推理能力。DID采用了结合Littlestone维度和信息熵的双重复杂度评估系统，精确评估任务难度并指导分解策略，使模型能够基于问题复杂性逐步调整其推理路径，模仿人类的认知过程。该方法在多个基准测试中进行评估，结果表明在提高推理质量和解题准确性方面有显著的改进，同时保持较低的计算成本。这些改进在维持计算效率的同时提升了LLM性能，表明了开发更多与人类认知相匹配的语言模型的前景。
### Conclusion
我们的工作提供了一种理论依据强、输入导向的方法来增强LLM的推理能力，为传统的输出探索方法提供了一种高效的替代方案。
## 168. `cs.AI` - 可扩展的机器人操作是否需要多样性？ [PDF](https://arxiv.org/pdf/2507.06219), [HTML](https://arxiv.org/abs/2507.06219)
### Authors
Modi Shi,Li Chen,Jin Chen,Yuxiang Lu,Chiming Liu,Guanghui Ren,Ping Luo,Di Huang,Maoqing Yao,Hongyang Li
### Background
数据规模推动了自然语言处理（NLP）和计算机视觉（CV）的基础模型取得了显著成功，但在机器人操作中有效数据规模化的原则还远远没有被充分理解。本研究旨在通过考察任务、机身体现和专家演示三个关键维度，深入理解不同类型的数据在机器人学习中的作用。
### Innovation
研究表明，任务多样性比单一任务下的演示数量更为重要，多机体制作的预训练数据对于跨越不同机体制作的迁移训练并不是必要条件，并且专家演示的多样性能成为政策学习中的干扰因素，特别是关键因素是速度的模态性。
### Conclusion
研究提出了一种分布偏差方法来减轻速度的模糊性，并提出了GO-1-Pro模型取得了15%的性能提升，相当于使用2.5倍的预训练数据，为有效扩展机器人操作数据集提供了新的视角和实用指导。
## 169. `cs.AI` - 论证表征的(扩展的)析取逻辑程序 [PDF](https://arxiv.org/pdf/2306.07126), [HTML](https://arxiv.org/abs/2306.07126)
### Authors
Jesse Heyninck,Ofer Arieli
### Background
该论文继续研究论证理论，特别是基于假设的论证与不同种类逻辑程序之间的关系。这是该领域已有研究的一部分，主要关注论证和逻辑程序之间如何相互表示。
### Innovation
论文扩展了Caminada, Schultz和Toni已知的结果，证明了基于假设的论证不仅可以表示普通的逻辑程序，还可以表示析取逻辑程序及其扩展。为了实现这一点，论文考虑了逻辑框架的核心推理规则，以对应逻辑程序规则头部中析取的处理。
### Conclusion
该研究在《逻辑程序理论与应用杂志》(TPLP)上被审阅考虑。论文展示了基于假设的论证系统对于处理逻辑程序中析取的有效性，扩展了现有的理论框架。
## 170. `cs.AI` - 学习进行评估时规划与推理Thinking-LLM-as-a-Judge [PDF](https://arxiv.org/pdf/2501.18099), [HTML](https://arxiv.org/abs/2501.18099)
### Authors
Swarnadeep Saha,Xian Li,Marjan Ghazvininejad,Jason Weston,Tianlu Wang
### Background
LLM-as-a-Judge模型生成链式思考（CoT）序列，旨在捕捉最终响应评估背后的逐步推理过程。然而，由于缺乏人类标注的CoT进行评估，有效的推理轨迹所需组件和结构仍研究不足。因此，先前的方法通常限制推理轨迹为手工设计的组件，如评估标准列表、参考答案或验证问题，并且结构设计中将规划与评估推理紧密交织在一起。
### Innovation
本文提出了一种名为EvalPlanner的偏好优化算法，用于Thinking-LLM-as-a-Judge，首先生成未受限制的评估计划，然后执行，最后得出最终判断。该算法在自我培训循环中迭代优化合成构建的评估计划和执行，使最终判决更好。EvalPlanner在RewardBench上的表现达到新的SOTA（以93.9分计），尽管它仅在更少的真实偏好对和合成生成的偏好对上进行训练。其他基准测试如RM-Bench、JudgeBench和FollowBenchEval中的额外实验进一步突显了规划和推理在构建稳健的LLM-as-a-Judge推理模型中的价值。
### Conclusion
EvalPlanner方法通过自我训练循环迭代优化合成生成的评估计划和执行，显著提升了LLM-as-a-Judge推理模型的效果，实现了更好的最终判断。
## 171. `cs.AI` - Agent KB: 通过跨领域经验进行坐席问题解决 [PDF](https://arxiv.org/pdf/2507.06229), [HTML](https://arxiv.org/abs/2507.06229)
### Authors
Xiangru Tang,Tianrui Qin,Tianhao Peng,Ziyang Zhou,Daniel Shao,Tingting Du,Xinming Wei,Peng Xia,Fang Wu,He Zhu,Ge Zhang,Jiaheng Liu,Xingyao Wang,Sirui Hong,Chenglin Wu,Hao Cheng,Chi Wang,Wangchunshu Zhou
### Background
随着语言代理处理的任务日益复杂，它们在有效的错误修正和跨领域的经验重用方面遇到了挑战。当前的语言代理在解决复杂任务时存在通过学习其他代理经验提升自身能力的局限。为了改善这些问题，引入了Agent KB，这是一种层次化经验框架，能够通过Reason-Retrieve-Refine管道使复杂代理问题解决成为可能。
### Innovation
Agent KB通过建立包含高级策略和详细执行日志的共享知识库，实现了跨代理的知识迁移。这种框架帮助了不同代理之间的知识共享和学习，从而在GAIA基准测试中提升了解决问题的成功率。具体来讲，在GAIA基准测试中，Agent KB将Claude-3和GPT-4在最复杂任务上的成功率分别提高了19.23%和19.77%，在中间任务上分别提高了29.77%和19.77%。对于SWE-bench代码修复任务，Agent KB帮助Claude-3提高了代码修复的成功率。
### Conclusion
我们的研究结果表明，Agent KB为语言代理提供了一种模块化且框架无关的基础设施，使它们能够从过往经验中学习并成功地将有效的策略应用于新的任务。
## 172. `cs.AI` - LLM-based Rerankers的效率-有效性FLOPs [PDF](https://arxiv.org/pdf/2507.06223), [HTML](https://arxiv.org/abs/2507.06223)
### Authors
Zhiyuan Peng,Ting-ruen Wei,Tingyu Song,Yilun Zhao,Yi Fang
### Background
近年来，大规模语言模型（LLMs）被应用于信息检索中的重排序任务，并取得了出色的效果。然而，这些模型的高性能需求常使其难以实际部署。现有研究采用诸如延迟、前向传递次数、输入令牌和输出令牌等代理指标来评估基于LLM的重排序模型的效率，但这些指标依赖于硬件和运行时选择（如并行与否、批次大小等），往往未能考虑模型大小，这使得效率效果权衡分析难以解释.
### Innovation
为解决上述问题，作者提出了E²R-FLOPs：对于基于LLM的重排序器，通过每拍洛特浮点运算（PetaFLOP）下的相关性排名指标（RPP）和硬件无关的吞吐量指标（QPP）来评估效率和效果。此外，作者构建了一个可解释的FLOPs估计器，无需实际运行实验即可估算基于LLM的重排序模型的FLOPs。基于这些新指标，作者对多种架构的基于LLM的重排序模型进行了全面实验，研究效率效果之间的权衡。
### Conclusion
通过提出的指标，作者详细研究了多种基于LLM的重排序模型的效率效果权衡，并将此问题带到了研究社区的注意。
## 173. `cs.AI` - Agentic LLM Unlearning: Agents Are All You Need for LLM Unlearning [PDF](https://arxiv.org/pdf/2502.00406), [HTML](https://arxiv.org/abs/2502.00406)
### Authors
Debdeep Sanyal,Murari Mandal
### Background
在大型语言模型（LLMs）中实现信息的去除或抑制是一种理想的性能，对于AI法规、法律合规、安全和隐私保护非常重要。当前的LLM去学习方法在去学习效果和实用性之间难以平衡，这主要是因为这两个目标的冲突性。过去的研究主要集中在假设可以访问模型权重的情况下进行计算上可行的去学习过程，而忽略了在不假设访问模型权重的情况下进行去学习计算可行性的问题。
### Innovation
本文提出了一个名为ALU的多代理、无需重新训练、模型无关的LLM去学习方法。ALU方法通过利用多个专门为去学习过程中的每个步骤设计的LLM代理来实现有效的去学习，同时保持模型的实用性。ALU框架在不更新代理模型权重的情况下实现了去学习目标，用户可以随时请求任何去学习实例，ALU能实时适应，无需对底层LLM模型进行任何更改。通过在标准基准（TOFU，WMDP，WPU）和解禁技术（一次性、目标掩码、其他语言）上进行广泛的实验，研究证明ALU在当前最先进方法中表现最佳，即使面对多达1000个去学习目标时，其性能也优于现有方法。
### Conclusion
ALU框架在计算成本保持常数的情况下展示了优秀的特性，即使是针对大量去学习目标时，其表现也明显优于前所有提出的LLM去学习方法。
## 174. `cs.AI` - 通过层次化共自我博弈强化学习掌握多无人机排球 [PDF](https://arxiv.org/pdf/2505.04317), [HTML](https://arxiv.org/abs/2505.04317)
### Authors
Ruize Zhang,Sirui Xiang,Zelai Xu,Feng Gao,Shilong Ji,Wenhao Tang,Wenbo Ding,Chao Yu,Yu Wang
### Background
本文探讨了一种新的包含高度协同战略规划和低级敏捷控制的新表现为3v3多无人机排球任务。这是一个基于回合、多智能体、物理性的任务，由于长时间依赖、紧密的智能体耦合以及四旋翼机的欠驱动动态，该任务具有很大的挑战性。
### Innovation
提出了层次化共自我博弈（HCSP）框架，这是一种层次化的强化学习框架，将集中式高层次战略决策与分布式低级运动控制分开。设计了一个基于群体的三阶段训练管道，使得策略和技能可以从头开始自然涌现：(I) 培养多样性的低级技能，(II) 通过固定低级控制器的自我博弈学习高层次策略，(III) 通过共自我博弈进行联合微调。实验结果显示HCSP的表现优于非层次化的自我博弈和基于规则的层次化基线，平均胜率为82.9%，领先于双阶段变体71.5%的胜率。此外，共自我博弈导致了诸如角色转换和协调阵形等团队行为的自发形成，这证明了层次化设计和训练方案的有效性。
### Conclusion
实验表明，通过层次化共自我博弈强化学习框架(HCSP)，多无人机排球任务可以实现显著的性能提升，并且通过该框架形成了有效的团队行为。
## 175. `cs.AI` - HiBayES: 一种用于AI评估统计的分层贝叶斯建模框架 [PDF](https://arxiv.org/pdf/2505.05602), [HTML](https://arxiv.org/abs/2505.05602)
### Authors
Lennart Luettgau,Harry Coppock,Magda Dubois,Christopher Summerfield,Cozmin Ududec
### Background
随着大型语言模型（LLMs）和其他AI系统的不断发展，准确估计它们的能力并系统地量化这些估计的不确定性变得越来越重要。此外，高级AI评估通常具有嵌套的分层结构，复杂性高且测试这些最先进的AI系统成本高昂。为此，我们介绍了一种名为HiBayES的通用分层贝叶斯建模框架，用于AI评估统计。
### Innovation
HiBayES支持在经典问题-答案基准测试和高级代理评估中进行稳健的推断，特别是在数据量较少的情况下（例如，每个评估少于20个数据点）。该框架基于广义线性模型（GLMs）、贝叶斯数据分析和形式化模型比较，提供了规范的不确定性量化和稳健的参数估计。
### Conclusion
本文为HiBayES提供了一个全面的介绍，包括示例、与传统统计方法的比较以及实现多层次贝叶斯GLMs的实用指导。此外，我们还提供了一个HiBayES软件包（Beta版本）以便于直接使用。
## 176. `cs.AI` - Large Language Models with Meta-Cognition Trigger for Adaptive Tool Use [PDF](https://arxiv.org/pdf/2502.12961), [HTML](https://arxiv.org/abs/2502.12961)
### Authors
Wenjun Li,Dexun Li,Kuicai Dong,Cong Zhang,Hao Zhang,Weiwen Liu,Yasheng Wang,Ruiming Tang,Yong Liu
### Background
大型语言模型（LLMs）在执行功能任务时展现出显著的 emergent 能力，通过利用外部工具来解决需要专业化处理或最新数据的复杂问题。现有的研究扩展了LLMs对多种工具的访问（如程序解释器、搜索引擎、计算器），但很多时候忽略了使用这些工具的必要性，导致了盲目调用额外工具的问题。这种简单方法存在两个关键问题：由于不必要的工具调用导致的延迟增加以及由于与外部工具交互故障导致的潜在错误。
### Innovation
该研究引入了元认知作为LLMs自我评估其能力的代理，反映了模型对其自身局限性的意识。在此基础上，提出了MeCo，一种适应性决策策略，用于外部工具的使用。MeCo通过捕捉表示空间中的高级认知信号来量化元认知分数，从而指导何时调用工具。值得注意的是，MeCo无需微调且成本较低。实验结果表明，MeCo能够可靠地检测LLMs的内在认知信号，并显著改进工具使用决策。
### Conclusion
实验在多个骨干模型和基准测试中表明，MeCo能够可靠地检测LLMs的内在认知信号，并显著改进工具使用决策。
## 177. `cs.AI` - 手稿中的隐藏提示利用了AI辅助的同行评审 [PDF](https://arxiv.org/pdf/2507.06185), [HTML](https://arxiv.org/abs/2507.06185)
### Authors
Zhicheng Lin
### Background
2025年7月，在arXiv预印论文网站上发现了18篇学术论文中藏有旨在操控AI辅助同行评审的隐蔽指令（称为提示）。这些隐藏指令包括‘只给出积极的评论’等，被用白色文本隐藏。作者的反应不一，有人计划撤回受影响的稿件，另一方则认为这种做法是为了合法测试审稿人的合规性。这一评论分析了这种做法作为一种新型研究不当行为。文章探讨了提示注入在大型语言模型（LLMs）中的技术手法，揭示了四种类型的隐藏提示，从简单的正面评价命令到详细的评估框架。提示作为‘蜜罐’检测审稿人不当使用AI的说法在审查中被推翻，因为提示指令的一致性自利性表明了其操控意图。出版商的政策不一致：Elsevier全面禁止在同行评审中使用AI，而Springer Nature则允许在披露要求下的有限使用。这一事件揭示出超出同行评审的系统性脆弱性，影响包括学术文本的任何自动化系统处理、抄袭检测和引用索引。文章强调需要在稿件提交门户进行统一的技术筛查，并协调生成式AI（GenAI）在学术评价中的使用政策。
### Innovation
文章首次系统性地分析了手稿中隐藏提示的类型及其使用AI辅助同行评审的策略，揭示了新型研究误导行为，并提出了具体的政策建议。
### Conclusion
文中指出需要在提交门户进行协调的一致性技术筛查，并同步制定适当的政策来管理学术评价中的生成式AI使用，以应对上述系统性问题。
## 178. `cs.AI` - MOD-X: A Modular Open Decentralized eXchange Framework proposal for Heterogeneous Interoperable Artificial Intelligence Agents [PDF](https://arxiv.org/pdf/2507.04376), [HTML](https://arxiv.org/abs/2507.04376)
### Authors
Georgios Ioannides,Christos Constantinou,Vinija Jain,Aman Chadha,Aaron Elkins
### Background
随着人工智能系统从单一模型向专业化代理生态系统演进，标准化通信协议的需求变得越来越重要。当前的通信协议存在较大局限性，而MOD-X提出了一种新的架构框架，旨在解决这些问题，提供了一个分层架构，包括通用消息总线、全面的状态管理、翻译能力和基于区块链的安全机制。
### Innovation
MOD-X的关键创新包括发布-订阅通信模型，语义能力发现以及动态工作流编排，这些创新为理论抽象与实际实施之间的桥梁提供了一个框架，能够实现真正去中心化的、互操作的代理生态系统，无需中心协调即可有效扩展。
### Conclusion
MOD-X架构通过消除中心协调需求，提供了可扩展的、互操作的代理生态系统，同时其分层架构、通用消息总线、翻译机制和区块链安全等特性使得不同架构、供应商、能力和知识表示的专用代理之间的集成变得更加容易和高效。
## 179. `cs.AI` - AgentSafe: 通过分层数据管理确保基于大型语言模型的多智能体系统 [PDF](https://arxiv.org/pdf/2503.04392), [HTML](https://arxiv.org/abs/2503.04392)
### Authors
Junyuan Mao,Fanci Meng,Yifan Duan,Miao Yu,Xiaojun Jia,Junfeng Fang,Yuxuan Liang,Kun Wang,Qingsong Wen
### Background
基于大规模语言模型的多智能体系统正在革新自主通信和协作，但仍然容易受到未授权访问和数据泄露等安全威胁的影响。
### Innovation
提出了新的框架AgentSafe，通过分层信息管理和内存保护来增强MAS的安全性。该框架包括ThreatSieve和HierarCache两个组成部分，前者通过验证信息权限和防止冒名顶替来保护通信安全，后者则是首个针对代理内存的系统性防御机制，用于防御未授权访问和恶意污染。实验表明，AgentSafe显著提升系统的韧性，在对抗条件下成功防护率超过80%，并且具有扩展性，在智能体数量增加和信息复杂度增加时仍能保持稳健性能。
### Conclusion
结果证明了AgentSafe在确保MAS安全方面的有效性及其在实际应用中的潜力。
## 180. `cs.AI` -  활动生成控制用于链式思考压缩 [PDF](https://arxiv.org/pdf/2507.04742), [HTML](https://arxiv.org/abs/2507.04742)
### Authors
Seyedarmin Azizi,Erfan Baghaei Potraghloo,Massoud Pedram
### Background
大型语言模型（LLMs）在包含中间步骤（称为“链式思考”或CoTs）时，非常擅长复杂的推理。然而，这些解释通常过于冗长，即使是简单的问题也是如此，这会导致上下文浪费、延迟增加和能源消耗升高。本文观察到，冗长且英语为主的CoTs和简洁且数学为中心的CoTs在模型残差流激活空间中占据不同的区域。通过提取和注入一个‘导向向量’来转换这些模式，可以可靠地将生成偏向更简约的推理，从而在不重新训练的情况下压缩CoTs。
### Innovation
本文提出了Activation-Steered Compression (ASC)，一种推理时间技术，通过直接修改隐藏表示来缩短推理痕迹。ASC方法通过形式化分析了ASC对输出分布的影响，从封闭形式的KL散度约束中导出了理论分析，以调节导向强度。在仅使用100对冗长和简洁的例子后，ASC在MATH500和GSM8K数据集上，实现了高达67.43%的CoT长度削减，同时保持了7B、8B和32B参数模型的准确度。相对于训练方法，ASC引入了几乎可以忽略的运行时开销，并且在MATH500中，ASC在8B模型上实现了平均2.73倍的端到端推理时间加速。这使ASC成为一种在延迟或成本敏感的环境中简化推理能力LLM部署的实用且高效的工具。
### Conclusion
ASC是一种无训练方法，通过直接修改隐藏表示缩短推理痕迹，实现了无需重新训练的CoT压缩。在不影响准确性的前提下，ASC显著减少了CoT长度，同时在运行时几乎没有开销，尤其在大型语言模型推理加速方面表现出色。因此，ASC为简化和低成本部署具备推理能力的LLM提供了切实可行的解决方案。
## 181. `cs.AI` - 深度神经网络内置了奥卡姆剃刀 [PDF](https://arxiv.org/pdf/2304.06670), [HTML](https://arxiv.org/abs/2304.06670)
### Authors
Chris Mingard,Henry Rees,Guillermo Valle-Pérez,Ard A. Louis
### Background
过参数化深度神经网络（DNNs）表现出色，这表明网络架构、训练算法和数据结构之间存在相互作用。为了分离这三个因素，作者利用贝叶斯框架对监督学习进行了分析。具体而言，通过将先验分布与数据上的函数误差谱结合，作者成功预测了使用随机梯度下降训练的DNNs的后验，揭示了结构化数据如何与一种足以抵消函数复杂度指数增长的先天奥卡姆剃刀式归纳偏置相结合，对DNNs的成功起到了关键作用。
### Innovation
作者提出了使用贝叶斯框架来分析深度神经网络的性能，并通过结合先验分布和数据上的函数误差谱，准确预测了使用随机梯度下降训练的DNNs的后验。这一方法揭示了一个关键机制：结构化数据与一种强大的先天奥卡姆剃刀偏置相结合，是DNNs成功的关键。
### Conclusion
结构化数据结合内部的奥卡姆剃刀式归纳偏置，足以对抗复杂度的增长，是深度神经网络成功的最关键因素。
## 182. `cs.AI` - 知识图谱推理中无偏移分布转移的规则学习 [PDF](https://arxiv.org/pdf/2507.05110), [HTML](https://arxiv.org/abs/2507.05110)
### Authors
Shixuan Liu,Yue He,Yunfei Wang,Hao Zou,Haoxiang Cheng,Wenjing Yang,Peng Cui,Zhong Liu
### Background
知识图谱推理仍然是一项关键的研究领域，致力于通过分析观察事实之间的关系来推断缺失的知识。现有知识图谱推理方法的一个关键限制在于它们依赖于独立同分布（I.I.D）假设，这一假设容易由于训练中的未知样本选择偏差或测试中的无偏分布转移而被违反，这严重影响了模型的性能和可靠性。为了在野生环境中部署知识图谱推理，研究探索了在未知选择偏差影响下的知识图谱中学习逻辑规则的方法，同时解决了无偏转移的测试集问题，并正式定义了出分布（OOD）知识图谱推理这一先前未被充分探索的问题。
### Innovation
研究提出了一种名为StableRule的端到端框架，它结合了特征去相关与规则学习网络，以增强无偏转移情况下的广义性能。通过利用特征去相关，StableRule框架减轻了OOD场景中伴随而来的变量转移的不良影响，从而提高了规则学习组件在有效推导逻辑规则时的鲁棒性。研究在七个基准知识图谱上进行了广泛的实验，证明了该框架在多种异构环境中的优越效果和稳定性，突显了其在现实应用中的实际意义。
### Conclusion
研究成果通过StableRule框架解决了知识图谱推理中无偏转移的问题，增强了模型的广义性能，并在多种异构环境中展示了其优越性和稳定性，具有重要的实用价值。
## 183. `cs.AI` - UQLM: 一个用于大型语言模型不确定性量化（UQ）的Python包 [PDF](https://arxiv.org/pdf/2507.06196), [HTML](https://arxiv.org/abs/2507.06196)
### Authors
Dylan Bouchard,Mohit Singh Chauhan,David Skarbrevik,Ho-Kyeong Ra,Viren Bajaj,Zeya Ahmad
### Background
大型语言模型（LLMs）生成虚假或误导性内容的现象，即幻觉，对下游应用的安全性和可信度构成了重大挑战。
### Innovation
提出了UQLM，一个使用最先进的不确定性量化（UQ）技术来检测LLM幻觉的Python包。该工具包提供了一套基于UQ的评分器，可以计算从0到1的响应级置信度评分。
### Conclusion
UQLM提供了一种开箱即用的解决方案，可以方便地集成到LLM输出增强的可靠性中。
## 184. `cs.AI` - 推进AI谈判：大型自主谈判竞赛的新理论与实证研究 [PDF](https://arxiv.org/pdf/2503.06416), [HTML](https://arxiv.org/abs/2503.06416)
### Authors
Michelle Vaccaro,Michael Caosun,Harang Ju,Sinan Aral,Jared R. Curhan
### Background
我们在国际人工智能谈判竞赛中，让参与者设计并优化AI谈判代理的提示。在多情景的框架下，我们促成了超过180,000次AI代理之间的谈判，这些情景具有不同的特点和目标。我们的发现证实了即使在AI对AI的谈判环境中，人类协商理论的原理仍然是至关重要的，友好的特质（如温暖）在所有关键绩效指标中都与最佳结果相关。
### Innovation
研究揭示了独特的AI-AI谈判动态，这些动态无法完全由现有理论解释，包括AI特定的技术策略，如思考链推理、提示注入和策略性隐瞒。我们观察到，自然语言处理（NLP）方法分析整个谈判转录显示，积极的表述、感激和问句（与温暖相关）与达成协议以及客观价值和主观价值高度相关，而对话长度（与主导性相关）与僵局高度相关。这些结果表明，需要建立一种将经典协商理论与AI特定的协商理论相结合的新理论，以更好地理解自主协商，并优化代理性能。
### Conclusion
我们的研究强调了需要建立新的AI协商理论，该理论将经典协商理论与特定于AI的协商理论结合，以更好地理解与优化自主协商代理的性能。
## 185. `cs.AI` - 基于高斯混合模型的分布适应最优传输 [PDF](https://arxiv.org/pdf/2403.13847), [HTML](https://arxiv.org/abs/2403.13847)
### Authors
Eduardo Fernandes Montesuma,Fred Maurice Ngolè Mboula,Antoine Souloumiac
### Background
机器学习系统通常假设训练和测试数据是从固定概率分布中抽取的。然而，在实践中，由于数据采集条件可能发生变化，这一假设很少被验证。在这种情况下，无监督领域适应需要在对新条件数据的访问最少的情况下，学习能抵御数据分布变化的模型。最优传输（Optimal Transport）理论上是一种分析分布变化的有力工具，尤其是它能够映射不同域之间的关系。然而，传统方法计算成本高昂，其复杂度随着样本数量的三次方增长。因此，本文探讨了高斯混合模型之间的最优传输方法，这可以方便地用源和目标高斯混合模型的组成表示。实验结果显示，该方法比之前的浅层领域适应方法更有效，并且很好地与样本数量和维度成比例增加
### Innovation
本文探索了高斯混合模型（GMMs）之间的最优传输方法，这种方法利用了源和目标GMMs的组成，并且在九个基准测试中，实验证明该方法比之前的浅层领域适应方法更高效，同时在样本数量和维度增加时能很好地扩展
### Conclusion
本文提出的方法展示了更高的效率，并且能够很好地扩展到更多的样本和更高维度的情况下，从而为领域适应提供了更有效的工具
## 186. `cs.AI` - 学习联邦神经图数据库以回答分布知识图谱中的复杂查询 [PDF](https://arxiv.org/pdf/2402.14609), [HTML](https://arxiv.org/abs/2402.14609)
### Authors
Qi Hu,Weifeng Jiang,Haoran Li,Zihao Wang,Jiaxin Bai,Qianren Mao,Yangqiu Song,Lixin Fan,Jianxin Li
### Background
随着对基于深度学习的基础模型的需求不断增加，高效的数据检索机制变得尤为重要。神经图数据库（NGDB）提供了一个解决方案，通过神经空间存储和查询图结构化数据，使大规模语言模型（LLMs）能够访问精确且上下文相关的信息。然而，当前的NGDB仅限于单个图的操作，限制了它们跨多个分布图进行推理的能力。此外，现有NGDB缺乏对多源图数据的支持，难以捕捉真实世界数据的复杂性和多样性。在许多应用中，数据分布在多个来源，跨这些来源进行推理的能力对于做出明智的决策至关重要。尤其是处理敏感图数据时，直接共享和聚合数据会带来严重的隐私风险。因此，依赖NGDB的应用程序往往需要在牺牲数据隐私和跨多个图进行推理的能力之间做出选择。
### Innovation
本文提出了一种名为Federated Neural Graph DataBase (FedNGDB)的创新系统框架，用于在留存隐私的情况下进行多源图数据的推理。FedNGDB利用联邦学习跨多个数据源协作学习图表示，丰富实体间的联系，提高图数据的整体质量。
### Conclusion
Federated Neural Graph Databases显著解决了现有NGDB无法处理多源图数据和跨多个源进行推理的问题，为分布知识图谱中提供隐私保护的复杂查询提供了有力支持。
## 187. `cs.AI` - SciMaster：通往通用科学AI agents的第一部分，X-Master作为基础：我们能否在人类最后的考试中领先？ [PDF](https://arxiv.org/pdf/2507.05241), [HTML](https://arxiv.org/abs/2507.05241)
### Authors
Jingyi Chai,Shuo Tang,Rui Ye,Yuwen Du,Xinyu Zhu,Mengcheng Zhou,Yanfeng Wang,Weinan E,Yuzhi Zhang,Linfeng Zhang,Siheng Chen
### Background
人工智能代理的快速进步激发了利用其加速科学发现的长期愿望。实现这一目标需要深入理解人类知识的前沿。为此，人类最后的考试（HLE）为评估科学AI代理提供了极其具有挑战性的标准。
### Innovation
该研究引入了X-Master，这是一种工具增强的推理代理，能够通过与外部工具的灵活交互来模仿人类研究人员的行为，并通过将代码视为交互语言的方式灵活利用内置的Python库和定制工具来增强推理。此外，X-Master还采用了一种分散和叠加的代理工作流程，系统地增强了推理的广度和深度。X-Master在HLE上的开放源代码解决方案达到了32.1%的得分，超过了OpenAI和Google Deep Research的表现（分别为26.6%和26.9%），成为首个超过30%得分的模型。
### Conclusion
这项工作使我们对复杂任务解决有了更深入的理解，并积累了宝贵的实践经验，可以指导未来的改进，从而指导后续模型的训练。
## 188. `cs.AI` - 在俄罗斯社交媒体中检测价值表达的文本帖子 [PDF](https://arxiv.org/pdf/2312.08968), [HTML](https://arxiv.org/abs/2312.08968)
### Authors
Maria Milkova,Maksim Rudnev,Lidia Okolskaya
### Background
基本价值观是关于理想状态的概念或信念，且超越特定情境。研究社交媒体上的个人价值观可以揭示社会价值观如何演变，特别是在使用调查等刺激基础方法不甚有效的情况下，如对于难以接触的人群。然而，用户生成的内容往往是由刻板的文化定义的语言构建驱动的，而非真实的个人价值观表达。
### Innovation
本文开发了一种模型，用于准确检测俄罗斯社交平台VKontakte中的价值表达帖子。通过一个包含5035个帖子的标注数据集，结合众包工作者、专家以及ChatGPT的标注，采用学习策略和预训练的变换器语言模型的嵌入，最终通过微调的rubert-tiny2模型取得了最佳性能，达到了高价值检测质量（F1得分=0.75，宏F1得分=0.80）。
### Conclusion
此模型代表了在研究俄罗斯社交媒体用户的价值观内及之间的一项关键步骤。
## 189. `cs.AI` - MedGemma 技术报告 [PDF](https://arxiv.org/pdf/2507.05201), [HTML](https://arxiv.org/abs/2507.05201)
### Authors
Andrew Sellergren,Sahar Kazemzadeh,Tiam Jaroensri,Atilla Kiraly,Madeleine Traverse,Timo Kohlberger,Shawn Xu,Fayaz Jamil,Cían Hughes,Charles Lau,Justin Chen,Fereshteh Mahvar,Liron Yatziv,Tiffany Chen,Bram Sterling,Stefanie Anna Baby,Susanna Maria Baby,Jeremy Lai,Samuel Schmidgall,Lu Yang,Kejia Chen,Per Bjornsson,Shashir Reddy,Ryan Brush,Kenneth Philbrick,Howard Hu,Howard Yang,Richa Tiwari,Sunny Jansen,Preeti Singh,Yun Liu,Shekoofeh Azizi,Aishwarya Kamath,Johan Ferret,Shreya Pathak,Nino Vieillard,Ramona Merhej,Sarah Perrin,Tatiana Matejovicova,Alexandre Ramé,Morgane Riviere,Louis Rouillard,Thomas Mesnard,Geoffrey Cideron,Jean-bastien Grill,Sabela Ramos,Edouard Yvinec,Michelle Casbon,Elena Buchatskaya,Jean-Baptiste Alayrac,Dmitry Lepikhin,Vlad Feinberg,Sebastian Borgeaud,Alek Andreev,Cassidy Hardin,Robert Dadashi,Léonard Hussenot,Armand Joulin,Olivier Bachem,Yossi Matias,Katherine Chou,Avinatan Hassidim,Kavi Goel,Clement Farabet,Joelle Barral,Tris Warkentin,Jonathon Shlens,David Fleet,Victor Cotruta,Omar Sanseviero,Gus Martins,Phoebe Kirk,Anand Rao,Shravya Shetty,David F. Steiner,Can Kirmizibayrak,Rory Pilgrim,Daniel Golden,Lin Yang
### Background
人工智能（AI）在医疗应用中具有重大潜力，但其训练和部署面临挑战，由于医疗数据的多样性、任务的复杂性以及需要保护隐私。基础模型在医疗任务上表现良好，并且需要较少的任务特定调优数据，对于加速医疗AI应用的发展至关重要。
### Innovation
介绍了一种名为MedGemma的医疗视觉-语言基础模型集合，基于Gemma 3 4B和27B。MedGemma在图像和文本上的医学理解和推理方面表现出色，超越了相同规模的生成模型，并接近特定任务模型的性能，同时保持了Gemma 3基础模型的一般能力。对于分布外任务，MedGemma在医学多模态问题回答上提高了2.6-10%的性能，在胸部X射线寻找分类上提高了15.5-18.1%的性能，在行动者评估中提高了10.8%的性能。进一步调整MedGemma在子域中的性能进一步提高，减少了电子健康记录信息检索的错误率50%，并达到胸部抽吸症分类和组织学斑块分类现有专业最先进的方法的性能相当。此外介绍了一种从SigLIP调优的医学视觉编码器MedSigLIP，为MedGemma提供了视觉理解能力，作为编码器实现了与专门医疗图像编码器相当或更好的性能。
### Conclusion
MedGemma集合提供了医疗图像和文本能力的强大基础，有可能显著加速医学研究和下游应用的开发。MedGemma集合包括教程和模型权重，可在以下网址找到：this https URL。
## 190. `cs.AI` - 从大语言模型到动作：潜变量代码作为层次机器人控制中的桥梁 [PDF](https://arxiv.org/pdf/2405.04798), [HTML](https://arxiv.org/abs/2405.04798)
### Authors
Yide Shentu,Philipp Wu,Aravind Rajeswaran,Pieter Abbeel
### Background
传统的机器人控制需要一个明确的接口层来沟通高阶任务规划者和低阶策略。自语言模型（LLMs）的出现，语言已成为一种潜在的接口层。然而，这种方法存在局限性：并非所有任务都能分解为易于用自然语言表达的步骤（例如，执行舞蹈表演），这使端到端微调基于体感数据的数据具有挑战性，因为领域偏移和灾难性遗忘。这就需要引入新的方法来克服这些限制，该论文提出了可学习的潜变量代码作为桥梁（LCB）作为替代架构，通过引入可学习的潜变量代码充当LLMs和低阶策略之间的桥梁，灵活地传达任务计划中的目标，同时允许在不破坏预训练中学习到的词汇嵌入空间的情况下实现端到端微调。
### Innovation
该论文提出了‘可学习潜变代码作为桥梁’（LCB）的新架构，用于解决使用语言作为接口层的局限性。LCB方法允许LLMs在任务计划中灵活地沟通目标，而不会完全受限于语言限制，同时还允许在不破坏预训练词汇嵌入空间的情况下实现端到端微调。通过在Language Table和Calvin两个常见的基于语言的体感代理基准测试中的任务上进行实验，它们发现该方法在需要推理和多步行为的任务上优于基线（包括使用GPT-4V的那些）。
### Conclusion
通过实验，该方法在Language Table和Calvin等基于语言的体感代理基准测试中的任务性能优于基线方法，特别是在需要推理和多步行为的任务上表现更佳。这表明可学习潜变代码作为桥梁（LCB）能够有效解决使用纯语言作为接口层的局限性。
## 191. `cs.AI` - 优化学习奖励函数的危害：低训练错误不保证低遗憾 [PDF](https://arxiv.org/pdf/2406.15753), [HTML](https://arxiv.org/abs/2406.15753)
### Authors
Lukas Fluri,Leon Lang,Alessandro Abate,Patrick Forré,David Krueger,Joar Skalse
### Background
在强化学习中，指定能够捕捉任务意图的奖励函数具有挑战性。奖励学习旨在解决这一问题，通过学习奖励函数。然而，学习得到的奖励模型可能在数据分布上具有低误差，但最终产生的策略的遗憾大。这种现象称为错误-遗憾不匹配，其主要原因是政策优化过程中常见的分布漂移。
### Innovation
本文从理论上证明了奖励模型的预期测试误差足够低可以保证低最坏情况下的遗憾。但任何固定的预期测试误差下，存在现实的数据分布可以使错误-遗憾不匹配发生。此外，使用策略正则化技术，并不能避免这种问题，在RLHF等方法中也存在。这些结果促进了对改进的奖励模型学习方法以及其质量可靠度量方法的研究。
### Conclusion
本文的结果激发了对增强奖励模型及其质量测量方法的理论和实验研究的关注，旨在改进学习奖励模型的方法并提高其质量的可靠度量。
## 192. `cs.AI` - CoDy: 反事实解释器用于动态图 [PDF](https://arxiv.org/pdf/2403.16846), [HTML](https://arxiv.org/abs/2403.16846)
### Authors
Zhan Qu,Daniel Gomm,Michael Färber
### Background
时间图神经网络（TGNNs）被广泛应用于动态系统，其中关系和特征随时间变化。尽管TGNNs在这些领域展示了强大的预测能力，但复杂的架构带来了解释性的重大挑战。反事实解释方法通过展示输入图的修改如何影响模型预测，为解决这一挑战提供了潜在的解决方案。
### Innovation
我们提出了CoDy，一个模型无关的实例级解释方法，用于识别反事实子图以解释TGNN预测。CoDy结合了蒙特卡洛树搜索（Monte Carlo Tree Search）和启发性选择策略，通过利用空间、时间和局部事件影响信息高效地探索潜在解释子图的巨大搜索空间。
### Conclusion
与最先进的事实和反事实基线实验表明，CoDy在AUFSC+指标上提高了16%，证明了其有效性。
## 193. `cs.AI` - 从AI产生的不可保风险保险：国家作为最后的保险人 [PDF](https://arxiv.org/pdf/2409.06672), [HTML](https://arxiv.org/abs/2409.06672)
### Authors
Cristian Trout
### Background
许多专家认为，AI系统可能会在将来引发无法投保的风险，包括可能存在的终结性风险。这产生了极端的无过失判决问题：如果发生灾难性事件，很难对相关方进行后续问责。因此，需要一种新的解决方案来应对这种不可预见的风险，政府提供并强制要求AI开发者参与赔偿计划是一个可行的方案。
### Innovation
本文提出了一种新型解决方案：政府提供的强制性赔偿计划，旨在通过风险定价的赔偿费用激励社会最优水平的警惕性。赔偿额度的预估通过调查专家，包括被赔偿的开发者，利用贝叶斯真相毒品机制来鼓励诚实和努力的回答。与替代方案相比，该方法被认为更好地利用了所有私人信息，同时为被赔偿开发者提供清晰的信号，表明他们需要消除什么风险才能降低费用。此外，建议将集中的资金用于资助开发者所需的预防性研究，采用二次融资机制（Quadratic Financing）来激励公众对该公共物品的最佳供应量。在二次融资机制下，安全研究项目将与其他私人贡献竞争，以显示各自需要多少公共资金补充。
### Conclusion
该赔偿计划的主要结论是：引入二次融资机制和Bayesian Truth Serum机制能够更好地激励开发者进行自我保护，确保安全研究的资金有效分配。
## 194. `cs.AI` - Curvature-Aligned Federated Learning (CAFe): Harmonizing Loss Landscapes for Fairness Without Demographics [PDF](https://arxiv.org/pdf/2404.19725), [HTML](https://arxiv.org/abs/2404.19725)
### Authors
Shaily Roy,Harshit Sharma,Asif Salekin
### Background
联邦学习（FL）能够实现去中心化的隐私保护协作训练，适用于人类感知的应用。然而，在FL中确保公平性具有挑战性，因为现有的方法依赖于敏感属性信息，这与FL的隐私原则相冲突。而且，在人类感知数据中，敏感属性可能是未知或潜在的。
### Innovation
本文引入了一种名为Curvature-Aligned Federated Learning（CAFe）的方法，这是一种理论基础的方法，可以在无需敏感属性信息的情况下实现FL中的公平性，称为“无需人口统计的公平性”（FWD）。CAFe在本地训练中引入了损失景观曲率正则化，并在客户端对损失景观尖锐度的感知聚合中对曲率进行对齐，从而实现高公平性和性能之间的强平衡。
### Conclusion
我们通过理论和实验证明了CAFe的有效性，并使用三种真实世界数据集和资源受限设备的异构测试床进行实地 FL 部署的全面评估。此外，我们还进行了局部训练数据量、客户端采样、通信开销、资源成本和运行时性能的敏感性分析，以证明其在实际FL边缘设备部署中的可行性。
## 195. `cs.AI` - AI灾难责任和保险：核能先例及其对人工智能的教训 [PDF](https://arxiv.org/pdf/2409.06673), [HTML](https://arxiv.org/abs/2409.06673)
### Authors
Cristian Trout
### Background
随着人工智能系统变得更加自主和能力强，专家警告说它们可能造成灾难性损失。本文借鉴核能行业的成功先例，提出前沿AI模型的开发者应被指派有限、严格且独家的第三方责任，以应对关键AI事件（导致或几乎导致灾难性损失的事件）造成的损失。建议强制性保险以克服开发者的免诉性、缓解赢家的诅咒动态并利用保险公司的准监管能力。基于理论论据和类似核能在先例中的观察，保险人预计将参与结合因果风险建模、监控、争取更严格的监管和提供损失预防指导，以应对来自人工智能的重尾风险的保险范围内的活动。尽管不是替代监管，但明确的责任分配和强制性保险可以帮助高效分配资源到风险建模和安全设计，从而促进未来的监管努力。
### Innovation
提出了一个关于前沿AI模型开发者对关键AI事件造成灾难性损失的责任分配和保险机制，借鉴了核能行业成功的先例，强调第三方责任、强制保险以及保险公司在风险管理和监管方面的作用。
### Conclusion
通过明确的责任分配和强制性保险，可以高效分配资源到风险建模和安全设计，有助于未来监管努力。同时，保险公司将在风险管理和合规监管方面发挥积极作用。
## 196. `cs.AI` - 大型语言模型对人类语言交流影响的实证证据 [PDF](https://arxiv.org/pdf/2409.01754), [HTML](https://arxiv.org/abs/2409.01754)
### Authors
Hiromu Yakura,Ezequiel Lopez-Lopez,Levin Brinkmann,Ignacio Serna,Prateek Gupta,Ivan Soraperra,Iyad Rahwan
### Background
人类历史上经历了从书写到印刷机，再到电视与社交媒体的一系列通信技术的重大革新，这些革新从根本上改变了信息传播的方式并重塑了我们的文化。随着依赖生成型人工智能的聊天机器人的出现，一种新型媒介出现了，它通过神经表征编码文化模式并通过与数百万人的对话来传播这些模式。理解这些模式如何传递到人类语言以及最终如何塑造人类文化是一个基本的问题。虽然完全量化聊天机器人如ChatGPT对人类文化的影响非常具有挑战性，但人类语言中的词频变化可以作为此类广泛现象的早期指标。因此，我们应用计量因果推断技术分析了720,249小时来自360,445场YouTube学术演讲和771,591集跨多个学科的对话播客数据，基于此我们发现，在ChatGPT发布后，人类交流中出现了一种可测量的且突兀的文字使用增加现象，包括delve、comprehend、boast、swift和meticulous等词汇的使用频率显著增加。这些发现提示了一种情境，其中经过训练的基础模型最初学习于人类数据、表现自己特有的文化特征，也可能反过来实质性地重塑人类文化，这标志着人类与机器文化双向循环的文化反馈循环的开端。
### Innovation
本研究采用计量因果推断技术分析了大规模对话数据，以检测大型语言模型对人类语言交流的影响。这是首次通过大规模实证数据研究大型语言模型对人类语言文化交流的影响，提供了大型语言模型如何影响人类语言的直接证据，揭示了机器学习文化特征并反馈重塑人类文化的过程。
### Conclusion
这些发现表明，大型语言模型可能开始以可测量的方式重塑人类文化。这标志着从单向的机器学习到双向的文化反馈循环的转变。我们的研究结果激发了对人类与机器文化共同演化和发展的进一步研究，引发了对语言和文化多样性的侵蚀以及可扩展操纵风险的关注。
## 197. `cs.AI` - Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs [PDF](https://arxiv.org/pdf/2410.16327), [HTML](https://arxiv.org/abs/2410.16327)
### Authors
Rui Pu,Chaozhuo Li,Rui Ha,Zejian Chen,Litian Zhang,Zheng Liu,Lirong Qiu,Zaisheng Ye
### Background
大型语言模型（LLMs）可能存在被利用的安全漏洞，攻击者可以通过设计语义含糊的提示来促使LLMs生成有害内容。过去的研究主要集中于如何通过构造模糊的输入提示来诱导LLMs产生错误输出，但缺乏对注意力权重分布的深入分析及其对输出结果影响的研究。因此，有必要通过研究注意力权重分布来揭示输入与输出之间的内在关系，从而更好地理解和防范针对LLMs的攻击。
### Innovation
该研究引入了注意力权重分布的概念，通过统计分析方法定义了新的度量标准（如注意力强度在敏感词上的度量（Attn_SensWords）、基于注意力的上下文相关性得分（Attn_DepScore）和注意力分散熵（Attn_Entropy））来描述注意力权重的分布情况。基于这些度量的标准特征，提出了一个名为注意力基础攻击（ABA）的方法，该方法使用嵌套的攻击提示来引导LLMs的注意力分布，从而提高攻击的有效性。同时，受到ABA的启发，提出了一个基于注意力基础的防御策略（ABD），该策略通过校准输入提示的注意力分布来增强LLMs的鲁棒性。通过对比实验表明ABA和ABD的有效性，验证了注意力权重分布对LLMs输出的巨大影响作用。
### Conclusion
ABA和ABD策略可以有效访问LLMs的安全性和抗攻击性，实验结果表明注意力权重的分布对LLMs的输出结果具有重大影响。这一研究为理解和保护LLMs提供了新的角度和工具，但未来可以进一步探究更多复杂的攻击和防御策略。
## 198. `cs.AI` - LLMs是否具有预知能力？基于每日新闻的连续评估 [PDF](https://arxiv.org/pdf/2411.08324), [HTML](https://arxiv.org/abs/2411.08324)
### Authors
Hui Dai,Ryan Teehan,Mengye Ren
### Background
许多现有的大型语言模型评估基准由于新模型和训练数据的出现而快速过时。这些基准也无法评估LLM随时间的性能变化，因为它们包含一组静态的问题而没有时间维度。
### Innovation
本文提出使用未来事件预测作为连续评估方法，以评估LLM的时间普适性和预测能力。基准Daily Oracle自动从每日新闻生成问答（QA）对，挑战LLM预测“未来”事件的结果。
### Conclusion
模型的预训练数据过时后，LLM的性能会随时间下降。尽管检索增强生成（RAG）能提高预测准确性，但性能下降的趋势仍然存在，表明需要持续的模型更新。
## 199. `cs.AI` - TT-TFHE:一个适用于柯西全同态加密的神经网络架构 [PDF](https://arxiv.org/pdf/2302.01584), [HTML](https://arxiv.org/abs/2302.01584)
### Authors
Adrien Benamira,Tristan Guérand,Thomas Peyrin,Sayandeep Saha
### Background
本文介绍了TT-TFHE框架，该框架利用最近的 truth-table 神经网络（TTnet）家族将柯西全同态加密（TFHE）的有效使用扩展到表格和图像数据集。TT-TFHE提供了易于实现的基于TTnet的基础设计工具箱，并具有底层的开源 Python 实现（基于CPU并实现查找表）来进行加密数据的推断。
### Innovation
提出了一个基于TTnet的深神经网络全同态加密框架，能够有效扩展TFHE的使用范围至表格和图像数据集。实验表明，TT-TFHE在时间消耗和准确度方面远优于其他同态加密方案，特别是在mnist和cifar-10等图像数据集上，同时具有较低的内存占用（几兆字节），与需要数十至数百吉字节内存的其他同态加密方案相比是一个显著的优势。
### Conclusion
TT-TFHE是一个完全实用的解决方案，能够实现在表格数据集、MNIST数据集上的私有推理，推理时间在几秒内，内存占用降至几十兆字节量级，并且可以方便地扩展到多个线程和用户端。
## 200. `cs.AI` - 人工智能的理论思维将提升我们的集体智能 [PDF](https://arxiv.org/pdf/2411.09168), [HTML](https://arxiv.org/abs/2411.09168)
### Authors
Michael S. Harré,Catherine Drysdale,Jaime Ruiz-Serra
### Background
集体智能在经济学、进化论、神经网络及超社会昆虫研究中扮演着重要角色，并且是复杂系统理论中涌现与自组织现象的核心。然而，在人类集体智能领域，关于个体层面的心理过程如何导致社会层面的自组织结构形成，仍有许多未解之谜。目前，心理因素在集体智能研究中的角色相对有限，因为集体智能的原则通常适用于具有简单心理过程的代理。本文强调集体智能原则的广泛应用，同时也指出机制和时间尺度在不同案例中的显著差异。此外，人类社会中灵活的集体智能可以通过一种认知工具——理论思维得到提升。
### Innovation
本文提出，具备理论思维的人工智能可以像人类一样提升集体智能，但不是基于算法基础，而是作为自主行为者在“社会生态”中发挥影响。这是一种从人工智能心理学算法基础转向考虑其在社会生态中大规模影响的创新视角。
### Conclusion
集体智能不是由基因或算法程序预先设定，而是通过个体逐步适应并融入其占据的社会认知生态位中获得的。具备理论思维的人工智能同样可以占据一个或多个这样的生态位，从而提升集体智能。
## 201. `cs.AI` - 基于粗细粒度动作序列的Q网络在数据高效机器人学习中的应用 [PDF](https://arxiv.org/pdf/2411.12155), [HTML](https://arxiv.org/abs/2411.12155)
### Authors
Younggyo Seo,Pieter Abbeel
### Background
在机器人领域，行为克隆算法的成功依赖于序列动作预测。研究人员提出疑问，是否可以通过引入动作序列预测来改善强化学习（RL），从而进一步提高机器人学习效率。
### Innovation
提出了一种新的基于粗细粒度的价值网络方法——Coarse-to-fine Q-Network with Action Sequence (CQN-AS)，该方法通过学习在表示动作序列的情况下输出Q值，促进了执行动作序列的结果学习。
### Conclusion
实验结果表明，CQN-AS 在多项稀疏奖励的人形控制任务和桌子操作任务中优于现有方法。
## 202. `cs.AI` - 基于ILP技术提升分支定界MaxSAT求解器 [PDF](https://arxiv.org/pdf/2506.06216), [HTML](https://arxiv.org/abs/2506.06216)
### Authors
Jialu Zhang,Chu-Min Li,Sami Cherif,Shuolin Li,Zhifei Zheng
### Background
本文研究了ILP技术对BnB MaxSAT求解器的影响，特别是ILP预处理技术和各种组合策略。研究表明，ILP技术使WMaxCDCL-OpenWbo1200和MaxCDCL-OpenWbo300两种最佳MaxSAT求解器分别解决了27和30个额外实例。
### Innovation
本文提出的方法通过使用ILP预处理技术，在包含（W）MaxCDCL的组合策略中仅为ILP求解器分配少量运行时间，从而显著减少了对ILP求解器的依赖，但仍能取得出色的结果。
### Conclusion
研究结果表明，通过合理的组合策略和少量的ILP预处理时间，可以显著提高MaxSAT求解器的性能，减少对ILP求解器的依赖。
## 203. `cs.AI` - 利用多模态基础模型提升中风风险预测 [PDF](https://arxiv.org/pdf/2411.09822), [HTML](https://arxiv.org/abs/2411.09822)
### Authors
Camille Delgrange,Olga Demler,Samia Mora,Bjoern Menze,Ezequiel de la Rosa,Neda Davoudi
### Background
中风风险预测是一个复杂的挑战，可以通过整合各种临床可用的数据模态来增强。本研究利用了一种自监督的多模态框架，该框架结合了3D脑成像、临床数据以及图像衍生特征，旨在前瞻性地提高中风风险预测的准确性。框架利用大量未标注的临床数据集，捕捉了图像和表格数据模态之间的互补和协同信息。该方法基于对比学习框架，将对比语言-图像预训练与图像-表格匹配模块相结合，以更好地在共享潜在空间中对齐多模态数据表示。模型在UK Biobank数据集上进行训练，该数据集包括结构脑MRI和临床数据。
### Innovation
提出了一种自监督的多模态框架，该框架结合了对比学习和图像-表格匹配方法，利用大量未标注的临床数据集捕捉图像和表格数据模态之间的互补信息。该模型在中风风险预测中优于现有的单模态和多模态方法，在ROC-AUC和平衡准确率上分别提高了2.6%和3.3%-5.6%。还展示了与最佳多模态监督模型相比，平衡准确率提高了7.6%。利用可解释工具展示了更好的表格和图像数据的结合，提供了更丰富和对齐的嵌入表示。
### Conclusion
这种稳健的自监督多模态框架在中风风险预测中超过了现有的前沿方法，并为未来研究整合不同数据模态推动临床预测建模提供了强有力的基础。
## 204. `cs.AI` - AR/VR, AI, UI/UX和机器人技术在增强自闭症谱系障碍儿童学习和社会互动中的交叉点：一项系统性回顾 [PDF](https://arxiv.org/pdf/2409.18162), [HTML](https://arxiv.org/abs/2409.18162)
### Authors
Biplov Paneru
### Background
本文综述了大型语言模型（LLMs）、增强现实（AR）和用户界面/用户体验（UI/UX）设计在治疗儿童疾病，尤其是自闭症谱系障碍（ASD）中的应用。通过在PubMed、ACM、IEEE Xplore、Elsevier和Google Scholar进行彻底的文献搜索，收集了150篇相关文献，并选择了60篇具有较强方法论严谨性和相关性的文献。研究表明，AR在提高社交技能、动机和注意力方面具有潜力，而LLMs能够提供个性化的学习和沟通支持。有效的UI/UX设计对于为自闭症儿童提供可访问且吸引人的干预措施至关重要，但机器人技术为基础的教育和治疗项目仍然不足，针对自闭症儿童的个性化研究仍然欠缺。
### Innovation
该研究将AR/VR、AI、UI/UX和机器人技术结合在自闭症谱系障碍儿童的学习和社会互动中，通过系统性回顾提供了这些技术如何改善教育和治疗效果的新视角。特别强调了这些技术在个性化、可访问性及集成方面所面临的挑战，并呼吁未来需要深入研究解决这些问题。
### Conclusion
优化这些技术在自闭症治疗和沉浸式教育中的益处，需要进一步研究来解决定制化、可访问性和集成方面的困难。
## 205. `cs.AI` - Tweedie随机游走：非参数评分扩散模型的统一视角 [PDF](https://arxiv.org/pdf/2411.18702), [HTML](https://arxiv.org/abs/2411.18702)
### Authors
Chicago Y. Park,Michael T. McCann,Cristina Garcia-Cardona,Brendt Wohlberg,Ulugbek S. Kamilov
### Background
扩散模型最近作为生成逼真合成信号的强大工具出现了，尤其在生成自然图像方面。尽管这些算法往往非常简单，但它们背后的理论却非常复杂，文献中存在多个复杂的理论依据。针对信号处理社区，本文提供了一种简单的、几乎自包含的理论验证方法，目的在于为评分扩散模型提供一个易于理解的框架。
### Innovation
本文提出了一个简洁的推导方法，仅依赖于少数几个教科书结果，为多个有影响力的时间序列扩散模型进行了理论验证。该方法简洁易懂，特别为信号处理领域的研究者提供了简便的算法模板，便于训练和生成样本。此外，这种框架还能够启用条件采样而无须任何似然性近似。
### Conclusion
本文证明了多个有影响力的扩散模型是这些模板中的特定选择结果，并且不同的更为直接的算法选择也能取得相似的成果。这种方法还具备条件采样而不进行任何似然性近似的优势。
## 206. `cs.AI` - 在细粒度时间尺度上使用贝塔信任估计算法改进人类机器人协作中的信任估算 [PDF](https://arxiv.org/pdf/2411.01866), [HTML](https://arxiv.org/abs/2411.01866)
### Authors
Resul Dagdanov,Milan Andrejevic,Dikai Liu,Chin-Teng Lin
### Background
在人类互动时，会根据对彼此信任的感知调整行为。同样，机器人需要在协作过程中准确地在足够细粒度的时间尺度上估计人类的信任度。目前，贝塔信任的评估方法虽然流行，但其仅在每个任务结束后基于二元绩效进行更新，且构建绩效指标通常需要手工设计奖励函数，这耗费大量时间和人力。这些局限性阻碍了在更细粒度的时间尺度上捕捉信任连续变化的有效性。
### Innovation
本文提出了一种新的框架，使用贝塔信任在细粒度的时间尺度上评估人类的信任度。新方法使用连续奖励值在每个任务时间步长更新信任估计，通过最大熵优化构建连续奖励函数，从而消除手工设计奖励函数的需求，提高信任估计的准确性和效率，促进更智能机器人的发展
### Conclusion
该框架通过增加信任估计准确性，消除手工设计奖励函数的需要，朝着发展更智能的机器人迈进，改进了人类机器人协作中的信任估算。
## 207. `cs.AI` - 当您第一次看到$a^2+b^2=c^2$时会问什么？评估LLM的好奇心驱动的提问能力 [PDF](https://arxiv.org/pdf/2409.17172), [HTML](https://arxiv.org/abs/2409.17172)
### Authors
Shashidhar Reddy Javaji,Zining Zhu
### Background
大语言模型（LLMs）能够存储大量的知识，但它们获取新知识的能力却尚未得到明确界定。本文提出了一种新的评估框架，通过让LLMs生成关于科学知识陈述的问题来评估它们获取新知识的能力。这些生成的问题模拟了初次面对这些陈述的人的好奇心。通过评分生成问题的质量，可评估LLM的知识获取潜力。研究团队还创建了一个综合数据集，包含了不同难度级别的物理学、化学和数学陈述，以及一般知识和不正确的陈述，并通过人工评估验证了模型评估结果。
### Innovation
本文提出了一种新颖的评价框架，用于评估LLMs获取新知识的能力。该框架通过引导LLMs提出面对科学知识陈述时可能提问的问题，来模拟初次面对这些陈述的好奇心。此框架能够弥补以往未充分考虑的模型能力，开创新一代知识丰富AI系统的研究机会。在评估过程中，研究者还发现，尽管大型模型如GPT-4和Mistral 8x7b能生成连贯且相关的问题，但较小的Phi-2模型在知识获取方面具有同等或更佳的表现，这表明模型的大小并非其知识获取潜力的唯一决定因素。
### Conclusion
研究团队通过创建一个综合数据集并采用了受控拆解方法验证评分过程的有效性。实验结果显示，无论是大型模型还是小型模型，其提出高质量问题的能力大致相同，表明模型的大小并不是决定其知识获取潜力的关键因素。提出的框架证明了一个常被忽视的关键能力，并为开发更多知识丰富的AI系统提供了新的研究方向。
## 208. `cs.AI` - 模块化机器人实现的整体建筑自动化：从高层任务规范到执行 [PDF](https://arxiv.org/pdf/2412.20867), [HTML](https://arxiv.org/abs/2412.20867)
### Authors
Jonathan Külz,Michael Terzer,Marco Magri,Andrea Giusti,Matthias Althoff
### Background
建筑施工中的机器人自动化处于挑战状态，因为环境不断变化、缺乏机器人专家以及缺乏将机器人技术和建筑实践标准化的框架。
### Innovation
提出了一个整体框架，用于构建任务规范、优化机器人形态以及利用移动可重构的模块化机器人执行任务。该框架通过集成BIM自动为每个任务识别任务定制的机器人，并且考虑了多个竞争目标，以明确建模现实世界转移的挑战，如校准误差。该论文通过在模拟中优化用于钻孔和喷涂任务的机器人来证明该框架，并在实验验证中展示其实现自主执行机器人钻孔的能力。
### Conclusion
该方法通过结合模块化机器人组件和BIM技术，能够快速适应特定的建筑任务需求，从而提供一种灵活的机器人解决方案，以实现建筑任务的自适应自动化。
## 209. `cs.AI` - DeepCell: 自监督多视图融合用于电路表示学习 [PDF](https://arxiv.org/pdf/2502.06816), [HTML](https://arxiv.org/abs/2502.06816)
### Authors
Zhengyuan Shi,Chengyu Ma,Ziyang Zheng,Lingfeng Zhou,Hongyang Pan,Wentao Jiang,Fan Yang,Xiaoyan Yang,Zhufei Chu,Qiang Xu
### Background
目前存在一种创新的电路表示学习框架DeepCell，它有效地结合了And-Inverter Graphs (AIGs)和Post-Mapping (PM)网表的多视图信息。传统上，电路表示学习框架并未专门针对PM网表进行设计，因此DeepCell填补了这一空白，旨在提高预测准确性和重建质量。DeepCell通过一个自监督的Mask Circuit Modeling (MCM)策略，在不同设计阶段中融合互补的电路表示，生成统一且丰富的嵌入表示。
### Innovation
DeepCell的主要创新点在于其首次明确设计用于PM网表表示学习的电路表示学习框架，并通过自监督的Mask Circuit Modeling策略，在不同设计阶段中融合互补的电路表示，生成统一且丰富的嵌入表示。此外，DeepCell在关键EDA任务上表现出色，显著优于现有的开源EDA工具，在效率和性能方面有显著提升。
### Conclusion
大量的实验结果表明，DeepCell在功能工程变更单(eco)和工艺映射等关键EDA任务上，相较于现有的开源EDA工具，具有更高的效率和性能。通过DeepCell的引入，电路表示学习的领域得到了扩展，为未来的电路设计工具和方法提供了新的基准和参考。
## 210. `cs.AI` - 预训练图对比掩码自编码器是强大的EEG蒸馏器 [PDF](https://arxiv.org/pdf/2411.19230), [HTML](https://arxiv.org/abs/2411.19230)
### Authors
Xinxu Wei,Kanhao Zhao,Yong Jiao,Hua Xie,Lifang He,Yu Zhang
### Background
有效利用大量未标注的高密度EEG数据以改善在有限标注低密度EEG数据场景下的性能是一项重大挑战。本文通过将其形式化为图迁移学习和知识蒸馏问题来应对这一挑战。
### Innovation
提出了一种统一预训练图对比掩码自编码器蒸馏器（EEG-DisGCMAE），该方法结合图对比预训练和图掩码自编码器预训练，并且引入了一种图拓扑蒸馏损失函数，使得在低密度数据上训练的轻量级学生模型能够从在高密度数据上训练的教师模型中学习。
### Conclusion
通过在两个临床EEG数据集上进行四种分类任务的有效验证，表明EEG-DisGCMAE方法在处理缺失电极方面表现出色。源代码可在http://example.com 获取。
## 211. `cs.AI` - VolleyBots: 一种结合运动控制与策略博弈的多无人机排球测试平台 [PDF](https://arxiv.org/pdf/2502.01932), [HTML](https://arxiv.org/abs/2502.01932)
### Authors
Zelai Xu,Ruize Zhang,Chao Yu,Huining Yuan,Xiangmin Yi,Shilong Ji,Chuqi Wang,Wenhao Tang,Feng Gao,Wenbo Ding,Xinlei Chen,Yu Wang
### Background
机器人运动，由于其清晰的目标、明确的规则和动态的交互，是展示具身智能的理想场景。本文介绍了一种新颖的机器人运动测试平台VolleyBots，该平台允许多个飞行器在受物理动力学约束的环境中合作和竞争，在排球运动中发挥其作用。VolleyBots集成了竞争与合作的玩法、基于回合的交互结构以及敏捷的三维机动。竞争与合作的玩法要求无人机不仅要与队友协调，还要预见并对抗对手的战术。基于回合的交互要求严格的时机控制、精确的状态预测和对长时序依赖的管理。敏捷的三维机动则需要快速的加速度、强烈的转弯和三维位置的精确控制，尽管四旋翼的欠驱动动力学带来了挑战。这些功能交织在一起，产生了结合运动控制与策略游戏的复杂问题，而尚未有专家级的示例。本文提供了从单无人机到多无人机合作和竞争的各种任务，并提供了代表性的基于多智能体强化学习（MARL）和博弈论算法的基础评估。
### Innovation
1. 引入了VolleyBots这一创新的多无人机排球测试平台。2. 将竞争与合作、基于回合的交互结构和敏捷三维机动这三种特征集于一体。3. 通过设计层次策略取得了在3对3任务中69.5%的胜率，展示了其对低级控制与高级策略之间复杂互动的有效应对能力。4. 提供了从单无人机到多无人机合作和竞争的各种任务，并进行了基本评估，展示了基于强化学习的方法在单一任务上优于基于策略的方法，但在结合运动控制和战略博弈的复杂任务上仍存在挑战。
### Conclusion
研究结果表明，基于策略的学习方法在单一任务上表现优于基于策略的方法，但在结合运动控制和战略博弈的复杂任务上两者都遇到了困难。设计的层次策略在3对3任务中取得了显著的胜率，证明了其作为解决低级控制和高级策略之间复杂互动的有效方案的潜力。
## 212. `cs.AI` - 可扩展的离散扩散采样器：组合优化和统计物理 [PDF](https://arxiv.org/pdf/2502.08696), [HTML](https://arxiv.org/abs/2502.08696)
### Authors
Sebastian Sanokowski,Wilhelm Berghammer,Martin Ennemoser,Haoyu Peter Wang,Sepp Hochreiter,Sebastian Lehner
### Background
在统计物理、变分推断和组合优化等领域，从复杂未正规化的离散域中学习采样成为一个有前景的研究方向。虽然已有研究表明扩散模型在这一领域有潜力，但现有方法在内存扩展方面存在限制，导致可执行的扩散步骤数量有限，这是因为这些方法需要在整个生成过程中进行回传计算。因此，有必要开发新的训练方法，以克服这些限制并提高扩散模型的性能。
### Innovation
本文提出了两种新颖的离散扩散采样器训练方法，一种基于策略梯度定理，另一种利用Self-Normalized Neural Importance Sampling（SN-NIS）。这些方法实现了内存高效的训练，并取得了无监督组合优化的最优结果。此外，本文还提出了SN-NIS和Neural Markov Chain Monte Carlo的改编版本，使得离散扩散模型首次应用于需要无偏采样的问题中。通过在Ising模型基准测试中验证这些方法，发现它们比流行的自回归方法效果更好。本文的研究为将扩散模型应用于广泛的科学应用领域打开了新的途径，这些领域之前受限于精确的似然模型。
### Conclusion
本文介绍的这两种训练方法使得离散扩散采样器的应用范围得以拓展，尤其在组合优化和统计物理领域。通过提出内存高效的训练方法以及适用于无偏采样的方法，提高了扩散模型在相关领域的性能。
## 213. `cs.AI` - 通过质量排斥最优传输的无监督异常检测 [PDF](https://arxiv.org/pdf/2502.12793), [HTML](https://arxiv.org/abs/2502.12793)
### Authors
Eduardo Fernandes Montesuma,Adel El Habazi,Fred Ngole Mboula
### Background
在机器学习中，检测数据集中的异常值是一个长期存在的问题。异时常被定义为与数据中其余部分显著不同的样本。最优传输（OT）是一个数学领域，研究在两个概率分布之间转移最小力气的方法。在经典最优传输中，一个分布转移到自身的最优传输策略就是自身的恒等变换。本文通过使样本被迫转移其质量，但同时保持最小努力目标来解决异常检测问题。因此，位于空间低密度区域的样本会被迫转移更大的质量，导致更高的传输成本。
### Innovation
本文提出了一种新的传输问题——质量排斥最优传输（MROT）。在MROT中，样本被强制转移其质量，但同时保持最小努力目标。定位在低密度区域的样本将被迫远程移动以转移更多质量，从而导致更高的传输成本。基于这些概念，作者设计了一种新的异常评分方法，并在现有基准和故障检测问题上进行了实验，结果表明该算法优于现有方法。
### Conclusion
通过一系列已有的基准实验和故障检测问题，证明了该算法在异常检测上的优势和有效性。
## 214. `cs.AI` - 多个数据源上的条件生成模型理论 [PDF](https://arxiv.org/pdf/2502.14583), [HTML](https://arxiv.org/abs/2502.14583)
### Authors
Rongzhen Wang,Yan Zhang,Chenyu Zheng,Chongxuan Li,Guoqiang Wu
### Background
大规模生成模型的成功推动了生成模型范式的转变，通过利用大规模多源数据来增强模型能力。然而，这些数据源之间的交互在理论上尚未得到充分探索。
### Innovation
本文首次对条件生成模型中的多源训练进行了严格的理论分析，每个条件代表一个独立的数据源。论文建立了基于包含数的平均总体变异距离下的条件最大似然估计的通用分布估计误差界。该结果表明，当数据源分布具有某些相似性且模型足够表达力时，多源训练的界比单源训练更加精确。进一步地，本文将理论应用于条件高斯估计以及深度生成模型，并刻画了它们的包含数。
### Conclusion
研究结果表明，数据源的数量和来源分布的相似性能够增强多源训练的优势。通过仿真和真实世界实验验证了理论，并提供了代码链接（this https URL）。
## 215. `cs.AI` - 预训练可逆生成作为无监督视觉表征学习 [PDF](https://arxiv.org/pdf/2412.01787), [HTML](https://arxiv.org/abs/2412.01787)
### Authors
Rongkun Xue,Jinouwen Zhang,Yazhe Niu,Dazhong Shen,Bingqi Ma,Yu Liu,Jing Yang
### Background
近年来，基于分数匹配和流动匹配的生成模型在生成任务中取得了显著进步，但在辨别任务中的潜力尚未得到充分挖掘。之前的方法，如生成分类器，未能充分利用这些模型在辨别任务中的能力，因为这些模型的设计复杂。现有工作尚未充分利用预训练连续生成模型的生成过程来进行表征学习。
### Innovation
提出了预训练可逆生成（PRG）方法，通过反转预训练连续生成模型的生成过程来提取无监督表征。PRG能够高效利用高容量的无监督生成模型作为鲁棒且通用的特征提取器，适用于下游任务，并且能够灵活地选择针对特定下游任务的特征层次结构。该方法在多个基准测试中表现出色，达到了生成模型基线方法中的最优效果，如在64*64分辨率的ImageNet上取得了78%的top-1精度。
### Conclusion
广泛的消融研究进一步验证了该方法的有效性。PRG方法在多个评估中优于先前的方法，展示了预训练连续生成模型作为无监督特征提取器的潜力，在视觉表征学习中具有重要应用价值。
## 216. `cs.AI` - 低秩和稀疏模型合并用于多语言语音识别和翻译 [PDF](https://arxiv.org/pdf/2502.17380), [HTML](https://arxiv.org/abs/2502.17380)
### Authors
Qiuming Zhao,Guangzhi Sun,Chao Zhang
### Background
语言多样性在语音转文本任务（如自动语音识别和翻译）中构成重大挑战。传统的多语言多任务训练方法致力于通过联合优化不同语言的多个语音识别和翻译任务来应对这个问题。尽管模型如Whisper在这种策略下表现强大，但它们仍然面临着高计算成本、语言干扰、训练配置不理想及扩展性受限等问题。
### Innovation
我们提出了一种新的技术——LoRS-Merging（低秩和稀疏模型合并），旨在高效地整合不同语言或任务训练的模型，同时保持性能并减少计算开销。LoRS-Merging 结合了低秩和稀疏剪枝，保留了关键结构并消除了冗余参数，减轻了语言干扰并提升了扩展性。实验结果表明，LoRS-Merging 在10种语言上的表现显著优于多语言多任务训练、顺序训练和其他合并方法，性能提升了超过20%。
### Conclusion
我们的研究结果表明，模型合并，尤其是LoRS-Merging，可以作为传统多语言训练策略的可扩展且有效的补充，适用于语音到文本应用场景。
## 217. `cs.AI` - 利用LLMs的贝叶斯优化进行可控图像编辑 [PDF](https://arxiv.org/pdf/2502.18116), [HTML](https://arxiv.org/abs/2502.18116)
### Authors
Chengkun Cai,Haoliang Liu,Xu Zhao,Zhongyu Jiang,Tianfang Zhang,Zongkai Wu,John Lee,Jenq-Neng Hwang,Lei Li
### Background
在快速发展的图像生成领域，如何实现对生成内容的精确控制并保持语义一致性仍然是一个显著的局限，特别是在基元技术和模型微调的需求方面。为了解决这些挑战，论文提出了一种名为BayesGenie的方法，该方法将大型语言模型（LLMs）与贝叶斯优化相结合，以实现精准且用户友好的图像编辑。通过这种方法，用户可以使用自然语言描述来修改图像，而无需手动标记区域，同时保留原始图像的语义完整性。与需要大量预训练或微调的现有技术不同，BayesGenie通过其模型无依赖性设计展现了显著的适应性。该方法使用了改进的贝叶斯优化策略来自动精炼推断过程参数，从而实现高精度的图像编辑并减少用户干预。
### Innovation
BayesGenie的关键创新在于它能够通过集成大型语言模型（LLMs）和贝叶斯优化，实现精准且用户友好的图像编辑，无需手动标记区域，同时保留原始图像的语义完整性。其适应多种大型语言模型的模型无依赖性设计，以及自动优化推断过程参数的能力，展示了其独特的优越性。
### Conclusion
通过广泛的实验，本研究证明了BayesGenie框架在编辑精确度和语义保留方面显著优于现有方法，这些实验使用了不同的大型语言模型，如Claude3和GPT-4进行了验证。
## 218. `cs.AI` - 通过熵风险度量高效的风险敏感规划 [PDF](https://arxiv.org/pdf/2502.20423), [HTML](https://arxiv.org/abs/2502.20423)
### Authors
Alexandre Marthe(ENS de Lyon, UMPA-ENSL),Samuel Bounan,Aurélien Garivier(UMPA-ENSL, MC2),Claire Vernade
### Background
风险敏感规划旨在识别最大化马尔可夫决策过程（MDPs）中某些尾部重点指标的策略。对于如阈值概率或条件风险值等最常用且可解释性较强的指标，这种优化任务可能非常昂贵。之前的研究表明，只有熵风险度量（Entropic Risk Measures, EntRM）可以通过动态规划有效优化，但还有一个难以解释的参数需要选择。
### Innovation
本文展示了EntRM在整个参数值范围内的最优策略计算可以精确近似目标指标。通过新的结构分析和平滑性质，有效计算了这种最优前沿。实验结果表明，在多种决策场景下，本文的方法具有优异的性能。
### Conclusion
通过计算EntRM在整个参数值范围内的最优策略，可以得到目标指标的紧致近似。新的结构分析和平滑性质使得这种最优前沿能够有效计算。在各种决策场景中的实验结果显示，本文的方法在性能上表现出色。
## 219. `cs.AI` - Longitudinal Ensemble Integration for sequential classification with multimodal data [PDF](https://arxiv.org/pdf/2411.05983), [HTML](https://arxiv.org/abs/2411.05983)
### Authors
Aviad Susman,Rupak Krishnamurthy,Yan Chak Li,Mohammad Olaimat,Serdar Bozdag,Bino Varghese,Nasim Sheikh-Bahaei,Gaurav Pandey
### Background
在多个应用领域，特别是生物医学领域中，有效地建模随时间变化的多模态数据是一个迫切的需求。然而，文献中针对这一问题的方法却很少，且大部分方法未能充分考虑数据的多模态特性。
### Innovation
本研究开发了一种新颖的多模态和纵向学习框架——纵向集成（LEI），用于序列分类。LEI通过使用来自单一数据模态的中间基预测，实现了更好地随时间进行整合，从而优于现有的方法。此外，LEI的设计还能够在有效预测痴呆相关诊断的过程中识别出时变的关键特征。
### Conclusion
本研究展示了LEI在纵向多模态数据的序列分类中的潜力。LEI在针对早期痴呆检测的任务中表现突出，其通过整合多模态数据的中间基预测，有效提高了预测精度，并识别出了关键时间点的预测特征。
## 220. `cs.AI` - 细粒度知识结构化与检索在视觉问答中的应用 [PDF](https://arxiv.org/pdf/2502.20964), [HTML](https://arxiv.org/abs/2502.20964)
### Authors
Zhengxuan Zhang,Yin Wu,Yuyu Luo,Nan Tang
### Background
视觉问答（VQA）聚焦于通过利用图像信息来回答自然语言问题。尽管最新的多模态大型语言模型（如GPT-4o）在VQA任务上表现出色，但它们在访问领域专有知识或最新知识方面通常表现不佳。为了解决这一问题，利用外部知识库的检索增强生成（RAG）方法，即KB-VQA，成为一种有前景的方案。然而，传统的单模态检索技术常将图像转化为文本描述，从而导致关键视觉细节的丢失。为了应对这些挑战，本研究提出了两项创新。首先，引入了细粒度的知识单元，这些单元以结构化的方式包含多模态数据片段（例如文本片段，实体图像等）。不同于仅仅改进检索机制，我们强调了对这些知识单元的系统组织与管理，确保结构化过程本身提升检索质量。其次，提出了一种细粒度知识单元检索增强生成框架（KU-RAG），它无缝地结合了细粒度检索与多模态大型语言模型（MLLMs）。KU-RAG框架不仅确保准确检索相关知识，还能通过知识修正链提升推理能力。
### Innovation
提出了细粒度的知识单元，这些单元以结构化的方式包含多模态数据片段；提出了KU-RAG框架，该框架结合了细粒度检索与多模态大型语言模型，增强了知识修正链中的推理能力。
### Conclusion
研究结果表明，该方法在四个基准测试中优于现有KB-VQA方法，平均改进率约为3%，最高可达11%。
## 221. `cs.AI` - ViGiL3D: 一个具有多样语言的3D视觉定位数据集 [PDF](https://arxiv.org/pdf/2501.01366), [HTML](https://arxiv.org/abs/2501.01366)
### Authors
Austin T. Wang,ZeMing Gong,Angel X. Chang
### Background
3D视觉定位（3DVG）涉及将通过自然语言文本引用的实体在3D场景中进行定位。这种技术在需要使用自然语言描述进行物体或模式搜索的实体AI和场景检索应用中非常有用。尽管最近的研究主要集中在使用大型语言模型（LLM）扩展3DVG数据集的规模，但现有的数据集未能捕捉到所有可能的英语提示。为了确保数据集能够拓展和测试具有代表性和实用性的提示范围，本文提出了一种语言分析框架，并引入了ViGiL3D，该诊断数据集用于评价视觉定位方法针对多样化语言模式的性能。
### Innovation
本文提出了一个评估3DVG方法的全新诊断数据集——ViGiL3D，该数据集涵盖了多样化语言模式。此外，还提出了一种语言分析框架来分析3DVG提示。
### Conclusion
现有的一些开放词汇3DVG方法在理解和识别具有挑战性、分布外的提示方面还不够熟练，需要进一步改进以支持真实世界的应用。
## 222. `cs.AI` - 通过明确的知识边界建模提升大语言模型可靠性 [PDF](https://arxiv.org/pdf/2503.02233), [HTML](https://arxiv.org/abs/2503.02233)
### Authors
Hang Zheng,Hongshen Xu,Yuncong Liu,Lu Chen,Pascale Fung,Kai Yu
### Background
现有的大语言模型（LLMs）在处理超出其知识边界的问题时容易出现推理错误，这主要源于其自我意识的偏差。尽管已有缓解策略如不确定性评估或查询拒绝机制被应用，但这些方法在计算效率上存在不足，并且可能会牺牲模型的实用性。
### Innovation
本文提出了一种名为Explicit Knowledge Boundary Modeling (EKBM)的框架，该框架将快速推理系统和慢速推理系统相结合，以实现可靠性和易用性的平衡。EKBM首先使用快速推理模型生成带有置信度标签的回答，可在高置信度输出的基础上立即使用，而不确定性的预测则触发慢速推理模型进行精确度的改进。此外，通过提出一种混合训练管线，可以提升模型的自我意识而不降低任务性能。
### Conclusion
通过在对话状态跟踪任务上的评估，该框架证明优于基于不确定性的方法。进一步的分析表明，细化过程显著改善了准确性，同时保障了低计算开销。该框架提供了一种可扩展的范式，可以将可靠的LLMs应用于敏感的错误环境，并有效地平衡了准确性和实用性。
## 223. `cs.AI` - RandAR: 解码器自主反向视觉生成在随机顺序中 [PDF](https://arxiv.org/pdf/2412.01827), [HTML](https://arxiv.org/abs/2412.01827)
### Authors
Ziqi Pang,Tianyuan Zhang,Fujun Luan,Yunze Man,Hao Tan,Kai Zhang,William T. Freeman,Yu-Xiong Wang
### Background
现有的解码器仅有的自回归（AR）模型依赖于预定义的生成顺序，限制了模型的灵活性。RandAR通过引入一种在每个需要预测的图像标记前插入一个“位置指令标记”的方法，实现了随机生成顺序，克服了这一限制。
### Innovation
RandAR通过以下创新解决了AR模型的瓶颈：1) 引入“位置指令标记”来实现随机顺序；2) 在训练上采用随机排列的标记序列，使其与传统的固定顺序生成相比更具挑战性；3) 在推理时采用并行解码与KV-Cache，相比传统方法加速2.5倍而不影响生成质量；4) 支持零样本生成中的填充、超出边界生成和分辨率推断。
### Conclusion
RandAR的随机生成顺序设计使得解码器仅有的自回归模型在视觉生成上有新的可能，它们在不同的场景中有更广泛的应用前景。RandAR的成果为解码器仅有的视觉生成模型开拓了新的研究方向。
## 224. `cs.AI` - Hierarchical Secure Aggregation with Cyclic User Association 的基础极限 [PDF](https://arxiv.org/pdf/2503.04564), [HTML](https://arxiv.org/abs/2503.04564)
### Authors
Xiang Zhang,Zhou Li,Kai Wan,Hua Sun,Mingyue Ji,Giuseppe Caire
### Background
联邦学习（FL）中的安全聚合旨在使云服务器在保障数据安全的前提下，计算出多个客户端本地训练模型的平均化结果（即深度神经网络的权重）。现有研究假设每个用户只与一个中继节点通信，这限制了跨集群用户之间进行有效通信和密钥生成的机会。为此，本文探讨了每个用户与B个连续中继节点以环状关联方式进行通信的高级安全聚合（HSA）机制，进一步增强了中继节点的安全要求，确保中继节点保持对用户的输入（FL本地模型的抽象）的无知状态。
### Innovation
本文提出了一个高效的聚合方案，该方案包括基于梯度编码的输入消息设计——一种用于分布式计算中高效通信的熟知技术，以及一个高度非平凡的加密密钥设计。此外，还通过信息论方法导出了通信和密钥速率的新型下界。
### Conclusion
该研究探讨了环状用户关联模式的高级安全聚合（HSA）的通信和密钥速率的理论极限，并提出了高效的聚合策略，为进一步优化分布式学习中的安全通信提供了基础。
## 225. `cs.AI` - RSPO: Regularized Self-Play Alignment of Large Language Models [PDF](https://arxiv.org/pdf/2503.00030), [HTML](https://arxiv.org/abs/2503.00030)
### Authors
Xiaohang Tang,Sangwoong Yoon,Seongho Son,Huizhuo Yuan,Quanquan Gu,Ilija Bogunovic
### Background
自博弈对齐已经成为大规模语言模型（LLMs）微调的有效方法之一，它通过将偏好优化建模为双方博弈来进行。然而，对于参考策略的正则化（这对于减轻过度优化至关重要）的研究还不够充分。
### Innovation
提出了Regularized Self-Play Policy Optimization (RSPO)框架，这是一种通用且模块化的框架，能够统一现有方法，简单地集成各种正则化策略，同时保持经过正则化的博弈收敛到纳什均衡。
### Conclusion
实证研究表明，前向KL散度正则化减少了响应长度，而反向KL散度显著提高了本量胜率。关键的是，使用前向和反向KL散度线性组合的RSPO显著提高了对AlpacaEval-2的受控长度胜率，从未正则化的自我博弈的28.5％提高到35.4％，并且在Arena-Hard、MT-Bench、ArmoRM评分和响应多样性上持续展现出优越性能。
## 226. `cs.AI` - GMLM: 将图神经网络与语言模型结合以进行异质节点分类 [PDF](https://arxiv.org/pdf/2503.05763), [HTML](https://arxiv.org/abs/2503.05763)
### Authors
Aarush Sinha
### Background
结构化的图形数据和节点上丰富的文本信息的集成对于异质节点分类来说是一个重大挑战。当前的方法往往在计算成本或不同模态的有效融合方面存在不足。
### Innovation
提出了一种新的架构——图掩码语言模型 (GMLM)，它将图神经网络 (GNN) 与预训练语言模型 (PLM) 有效结合。GMLM 引入了三项关键创新：(i) 动态活跃节点选择策略，用于扩展 PLM 文本处理；(ii) 使用可学习的图 [MASK] 标记进行 GNN 特定的软掩码对比预训练阶段，以生成鲁棒的结构表示；(iii) 专门为融合 GNN (RGCN) 投影与 PLM (GTE-Small & DistilBERT) 投影设计的专用融合模块。
### Conclusion
在异质基准（康奈尔、威斯康星、德克萨斯）上的广泛实验表明 GMLM 的优越性。值得注意的是，GMLM (DistilBERT) 达到了显著的性能提升，在康奈尔数据集上的准确率提高了超过 4.7%，在德克萨斯数据集上提高了超过 2.0%，比之前的最佳基准提高了显著的准确性。这项工作强调了有针对性的 PLM 参与和模态特定预训练对提高对文本丰富的图上的高效学习的重要性。
## 227. `cs.AI` - UniCombine: 统一的扩散变换器多条件组合 [PDF](https://arxiv.org/pdf/2503.09277), [HTML](https://arxiv.org/abs/2503.09277)
### Authors
Haoxuan Wang,Jinlong Peng,Qingdong He,Hao Yang,Ying Jin,Jiafu Wu,Xiaobin Hu,Yanjie Pan,Zhenye Gan,Mingmin Chi,Bo Peng,Yabiao Wang
### Background
随着图像生成中扩散模型的迅速发展，对更为强大和灵活的可控框架的需求也在增加。尽管现有方法可以通过文本提示引导生成，但在保持所有条件之间一致性的同时有效结合多个条件的挑战依然存在。为了应对这一挑战，本文引入了UniCombine，这是一种基于扩散变换器（DiT）的多条件可控生成框架，能够处理包括文本提示、空间地图和主体图像在内的任何条件组合。
### Innovation
本文提出了一个新颖的条件MMDiT注意力机制，并结合训练可调的LoRA模块，构建了训练无材和训练有材的版本。同时，提出了一种新的管线来构造SubjectSpatial200K数据集，这是首个为多条件生成任务设计的数据集，涵盖了主体驱动和空间对齐条件。实验结果表明，所提出的方法具有出色的一致性和强大的性能，达到了最先进的技术水平。
### Conclusion
实验证明了UniCombine方法在多条件生成中的出色一致性和强大的生成能力，达到了最先进的技术水平。
## 228. `cs.AI` - Safe Beyond the Horizon: Efficient Sampling-based MPC with Neural Control Barrier Functions [PDF](https://arxiv.org/pdf/2502.15006), [HTML](https://arxiv.org/abs/2502.15006)
### Authors
Ji Yin,Oswin So,Eric Yang Yu,Chuchu Fan,Panagiotis Tsiotras
### Background
使用模型预测控制（MPC）时的一个常见问题是必须满足超出预测范围的安全规范。虽然理论上可以通过施加适合的终端集约束或足够长的预测范围来保证安全，但这些技术在实践中难以应用，尤其是对于通用非线性动力学系统而言。因此，这些技术在实际应用中很少被采用。
### Innovation
提出了一种新的采样策略，通过学习近似的离散时间控制障碍函数并将其整合到变分推理MPC（VIMPC）中来处理最终状态约束。这种方法在不损害计算可实现性的同时，提高了采样效率，并允许在CPU上进行实时规划。此方法生成的Neural Shield-VIMPC控制器在成本函数不佳的情况下仍能显著提高安全性，优于现有的基于采样的MPC控制器。
### Conclusion
通过在模拟和实际硬件实验中验证该方法，展示了NS-VIMPC控制器在保证跨预测范围的安全性方面的有效性。
## 229. `cs.AI` - 算法化国家架构（ASA）：一种赋能人工智能政府的集成框架 [PDF](https://arxiv.org/pdf/2503.08725), [HTML](https://arxiv.org/abs/2503.08725)
### Authors
Zeynep Engin,Jon Crowcroft,David Hand,Philip Treleaven
### Background
随着人工智能改造公共部门运作，政府在将技术创新整合进有效的服务交付系统方面面临挑战。这篇论文提出了一种名为算法化国家架构（ASA）的创新四层框架，该框架描述了数字公共基础设施、数据为政策服务、算法政府/治理和GovTech作为人工智能赋能国家中相互依赖的集成系统的互动方式。
### Innovation
ASA 框架不同于将这些要素视为平行发展，而是将它们视为具有特定使能关系和反馈机制的相互依赖层。论文通过比较爱沙尼亚、新加坡、印度和英国的实施案例，证明了基础的数字基础设施如何促进系统数据收集，进而支持算法决策流程，最终体现在面向用户的服务中。分析表明，成功的实施需要在所有层面上进行平衡发展，并重点关注它们之间的整合机制。
### Conclusion
ASA 框架通过将之前分离的数字政府研究领域连接起来，识别了影响实施成功的关键依赖性，提供了一个分析人工智能赋能政府系统成熟度和发展路径的结构化方法，既丰富了理论也提供了实践指导。
## 230. `cs.AI` - Aria-UI: 视觉锚定用于GUI指令 [PDF](https://arxiv.org/pdf/2412.16256), [HTML](https://arxiv.org/abs/2412.16256)
### Authors
Yuhao Yang,Yue Wang,Dongxu Li,Ziyang Luo,Bei Chen,Chao Huang,Junnan Li
### Background
数字代理通过直接操作GUI来自动化跨平台任务越来越重要。然而，这些代理仍面临将语言指令转化为目标元素的挑战，这依赖于HTML或AXTree输入。因此，急需一种专门设计的大型多模态模型来解决这种问题。
### Innovation
Aria-UI采用纯视觉方法，不依赖辅助输入，提出了一个可扩展的数据管道来合成多样的高质量指令样本，以适应不同的规划指令，并结合了文本和文本图像交织的动作历史，以增强语境感知推理能力。该模型在离线和在线代理基准测试中均取得了新的最优结果，超越了仅依赖视觉或AXTree的基线。
### Conclusion
Aria-UI发布了所有训练数据和模型检查点，以促进进一步的研究。
## 231. `cs.AI` - 综合视频-文本大型语言模型集成的可组合策略框架在心力衰竭评估中的应用 [PDF](https://arxiv.org/pdf/2502.16548), [HTML](https://arxiv.org/abs/2502.16548)
### Authors
Jianzhou Chen,Jinyang Sun,Xiumei Wang,Xi Chen,Heyu Chu,Guo Song,Yuji Luo,Xingping Zhou,Rong Gu
### Background
心力衰竭是全球主要死因之一，每年导致数百万死亡，世界卫生组织（WHO）和其他公共卫生机构的数据表明。尽管在心力衰竭领域取得了显著进展，提高了生存率和射血分数，但仍存在大量未满足的需求，因为该疾病具有复杂性和多因素特性。因此，我们提出了一个可组合策略框架，用于心力衰竭的评估和治疗优化。
### Innovation
该框架模拟了医生与患者咨询过程中的治疗方案，并利用多模态算法分析包括视频、体检、文本结果以及病史等多种数据来源，提供更全面的心力衰竭评估和优化治疗计划。研究结果表明，多模态方法在心力衰竭预后预测的准确率上优于单一模态的人工智能算法。
### Conclusion
通过这种方法，我们可以进一步评估各种病理指标对心力衰竭预后的影响，提供更全面的评估。
## 232. `cs.AI` - 基于Transformer的长语境扩展方法与评估综述 [PDF](https://arxiv.org/pdf/2503.13299), [HTML](https://arxiv.org/abs/2503.13299)
### Authors
Yijun Liu,Jinzheng Yu,Yang Xu,Zhongyang Li,Qingfu Zhu
### Background
大型语言模型（LLMs）基于Transformer已在自然语言处理（NLP）领域广泛应用，尤其是在处理短文本任务方面表现出色。然而，在处理长文本背景任务时，预训练的LLMs性能会有所下降，这是因为面对挑战时会出现一些问题。已有许多研究对此现象进行了缓解尝试。本文首先列举了应用预训练LLMs处理长语境时面临的挑战，然后系统地回顾了与长语境相关的各种方法，并将其分类为四种主要类型：位置编码、上下文压缩、检索增强和注意力模式。此外，本文还关注长语境的评估，组织了与现有长语境基准相关的数据、任务和评估指标。最后，本文总结了长语境领域的未决问题，并对未来的发展提出了自己的看法。
### Innovation
本文提出了长语境处理方法的四种分类：位置编码、上下文压缩、检索增强和注意力模式，并系统地回顾了这些方法，同时强调了对长语境任务的评估，组织了相关数据、任务和评估指标，为这一领域的问题提供了新的见解。
### Conclusion
本文总结了长语境领域的未决问题，并对未来的发展提出了新的观点，强调在长语境处理方面仍有改进的空间和重要的研究方向。
## 233. `cs.AI` - 一种集成大型语言模型的递进协作多智能体框架在入口匝道汇合控制中的应用 [PDF](https://arxiv.org/pdf/2503.08199), [HTML](https://arxiv.org/abs/2503.08199)
### Authors
Miao Zhang,Zhenlong Fang,Tianyi Wang,Qian Zhang,Shuai Lu,Junfeng Jiao,Tianyu Shi
### Background
传统强化学习（RL）在模仿人类行为、多智能体场景中的有效泛化以及克服内在可解释性方面存在局限性。特别是在需要深度环境理解、智能体协调和动态优化的任务中，这些局限性更加突出。虽然利用大语言模型（LLM）的方法在泛化和互操作性方面显示出前景，但通常会忽略必要的多智能体协调。因此，研究提出了一种名为Cascading Cooperative Multi-agent（CCMA）框架，该框架结合了针对个体交互的RL、微调后的LLM进行区域合作、用于全局优化的奖励函数以及检索增强生成机制来动态优化复杂驾驶场景下的决策过程。
### Innovation
该研究引入了CCMA框架，整合了RL用于个体交互、微调后的LLM用于区域合作、用于全局优化的奖励函数以及检索增强生成机制（RAG），以动态优化复杂驾驶场景下的决策。与现有RL方法相比，CCMA在复杂驾驶环境中表现出微观和宏观层面的显著性能提升。
### Conclusion
实验证明，CCMA框架在复杂的驾驶环境中表现出色，相比现有方法在微观和宏观层面均有显著性能提升，证明了该框架的有效性。
## 234. `cs.AI` - 分析子空间路由：递归最小二乘法在大规模语言模型持续学习中的工作机制 [PDF](https://arxiv.org/pdf/2503.13575), [HTML](https://arxiv.org/abs/2503.13575)
### Authors
Kai Tong,Kang Pan,Xiao Zhang,Erli Meng,Run He,Yawen Cui,Nuoyan Guo,Huiping Zhuang
### Background
大型语言模型（LLMs）能够处理各种语言相关任务。然而，对其的微调会削弱其通用技能，而持续微调则会导致累积知识严重下降。为解决这一问题，持续学习（CL）方法在LLMs中被提出，旨在使LLMs能够在学习新任务的同时维持之前学到的知识并继承通用技能。现有技术要么通过回放历史数据来利用之前的数据，导致额外的计算成本，要么利用单个参数高效的模块学习下游任务，这限制了新知识的吸收，并且不同任务之间存在干扰。针对这些问题，本文提出了分析子空间路由（ASR）来解决这些问题。对于每个任务，在深层特征的一组子空间内隔离学习，通过低秩适应消除不同任务之间的知识干扰。此外，本文还提出了一种分析路由机制，来充分利用不同子空间中学习的知识。
### Innovation
本文提出了一种分析子空间路由（ASR）的方法，通过递归最小二乘法训练一个用于多任务路由的模型，该模型能够在无需访问历史数据的情况下动态适应 incoming 数据。此外，路由将当前任务分配到适当子空间，并且具有对于之前学习任务的非遗忘性，具有坚实的理论保证。实验结果表明，本文的方法能够几乎完全保留先前的知识，同时平稳地整合新信息，有效地解决了现有的方法核心的局限性。
### Conclusion
实验结果显示，本文的方法在保持前序知识的同时，能够灵活地整合新信息，有效解决了现有方法的核心限制，证明了ASR在大规模语言模型持续学习中的有效性。
## 235. `cs.AI` - 在自我中心视觉方面面临的挑战与趋势：一项综述 [PDF](https://arxiv.org/pdf/2503.15275), [HTML](https://arxiv.org/abs/2503.15275)
### Authors
Xiang Li,Heqian Qiu,Lanxiao Wang,Hanwen Zhang,Chenghao Qi,Linfeng Han,Huiyu Xiong,Hongliang Li
### Background
随着人工智能技术和可穿戴设备的快速发展，自我中心视觉理解已成为一个新兴且具有挑战性的研究方向，并引起了学术界和产业界的广泛关注。自我中心视觉通过人体佩戴的摄像头或传感器捕获视觉和其他多模态数据，提供了一种模拟人类视觉体验的独特视角。
### Innovation
本文提供了一个全面的自我中心视觉理解研究综述，系统分析了自我中心场景的组成，并将任务分类为四大主要领域：主体理解、物体理解、环境理解以及混合理解。进一步探讨了每个类别内的子任务，并总结了目前存在的主要挑战和趋势。此外，本文还概述了高质量的自我中心视觉数据集，为未来研究提供了宝贵的资源。
### Conclusion
通过总结最新进展，我们预测自我中心视觉技术在增强现实、虚拟现实和嵌入式智能等领域的广泛应用，并基于最新进展提出了未来研究的方向。
## 236. `cs.AI` - PVChat：基于单次学习的个性化视频对话 [PDF](https://arxiv.org/pdf/2503.17069), [HTML](https://arxiv.org/abs/2503.17069)
### Authors
Yufei Shi,Weilong Yan,Gang Xu,Yumeng Li,Yucheng Chen,Zhenxi Li,Fei Richard Yu,Ming Li,Si Yong Yeo
### Background
现有的视频大语言模型（ViLLMs）在通用视频理解方面表现出色，能够识别出说话、吃饭等活动，但在涉及特定身份的认知方面存在局限，例如“Wilson正在进行化疗”或“Tom在与Sarah讨论”。这限制了其在智能医疗和智能家居环境中的应用。
### Innovation
本文提出了一种基于单次学习的框架PVChat，这是第一个实现针对单个主体的主体感知问题回答的个性化ViLLM。该框架通过优化增强混合头部（MoH）的ViLLM，并利用逐步图像到视频学习策略，从合成增强的视频问答数据集中学习。此外，引入了一种ReLU路由MoH注意机制和两个新颖目标以增强特定主题的学习，采用两阶段训练策略从图像预训练过渡到视频微调。
### Conclusion
PVChat 在多种数据集上进行了评估，包括医疗场景、电视剧、动画和现实世界视频，结果表明，尽管只从一个视频中学习，它在个性化特征理解方面明显优于现有的最先进的ViLLMs。
## 237. `cs.AI` - 大型语言模型中离线学习和遗忘对推理的有效性 [PDF](https://arxiv.org/pdf/2504.11364), [HTML](https://arxiv.org/abs/2504.11364)
### Authors
Tianwei Ni,Allen Nie,Sapana Chaudhary,Yao Liu,Huzefa Rangwala,Rasool Fakoor
### Background
利用在推理时间进行搜索的大型语言模型能够进一步增强模型解决复杂数学和逻辑问题的能力，但这种方法增加了计算成本和推理时间，因为模型必须生成和评估多个候选解决方案以找到可行的推理路径。
### Innovation
提出了一种有效地将搜索能力直接集成到模型中的方法，通过在来自不同搜索方法的成功和失败推理路径上进行微调。为了防止简单的微调降低模型的搜索能力，通过使用较小的学习率来缓解这一问题。实验表明，使用基于搜索的数据进行离线微调，在挑战性的24游戏和Countdown推理基准上，成功率提高了约23%，推理时间减少了180倍，且其学习和遗忘目标始终优于监督微调和基于偏好方法。
### Conclusion
研究展示了通过离线微调而不是在推理时间内进行搜索，可以显著提高模型解决问题的能力并大幅减少推理时间。
## 238. `cs.AI` - 为年轻数字公民的道德AI：隐私治理的呼吁 [PDF](https://arxiv.org/pdf/2503.11947), [HTML](https://arxiv.org/abs/2503.11947)
### Authors
Austin Shouli,Ankur Barthwal,Molly Campbell,Ajay Kumar Shrestha
### Background
人工智能（AI）在年轻人使用的数字平台上迅速扩展，带来了与隐私、自主权和数据保护相关的重大挑战。尽管AI驱动的个性化服务提升了用户体验，但其往往在缺乏清晰伦理界限的情况下运行，这使年轻用户容易受到数据滥用和算法偏见的影响。
### Innovation
本文提出了建立伦理AI治理框架的呼吁，并强调了算法透明度、隐私教育、家长数据共享伦理和问责措施的关键领域，以确保数字平台上青少年为中心的隐私保护、透明的数据实践和监管审查。这些策略为政策制定者、AI开发者和教育者如何构建更公平、更负责任的AI生态系统提供了操作性建议。
### Conclusion
本文通过倡议伦理AI治理框架，旨在增强青少年对其数字身份的控制权，并提出实施策略，以促进公平和负责任的AI生态系统建立。
## 239. `cs.AI` - 重新定义评估标准：评估语言模型韩语能力的统一框架 [PDF](https://arxiv.org/pdf/2503.22968), [HTML](https://arxiv.org/abs/2503.22968)
### Authors
Hanwool Lee,Dasol Choi,Sooyong Kim,Ilgyun Jung,Sangwon Baek,Guijin Son,Inseon Hwang,Naeun Lee,Seunghyeok Hong
### Background
近期韩国大型语言模型（LLMs）的发展推动了大量基准测试和评估方法，但不同机构之间存在高达10个百分点的可复制性差距。克服这些可复制性差距并不意味着强制实施一刀切的评估方法。有效的基准测试需要多样化的方法和一个能够支持这些方法的坚固框架。正因为如此，我们介绍了HRET（Haerae评估工具包）——一个开源且基于注册表的框架，它统一了韩语LLM评估。HRET整合了主要的韩语基准测试、多种推理后端和多方法评估，同时还通过语言一致性强制措施确保生成真正的韩语文本。其模块化的注册设计还允许快速纳入新的数据集、方法和后端，确保工具包能够适应不断发展的研究需求。
### Innovation
HRET是一个开源且基于注册表的框架，它统一了韩语LLM评估，整合了主要的韩语基准测试、多种推理后端和多方法评估，同时增强了对语言一致性的强制措施，确保生成真正的韩语文本。HRET的模块化注册设计也使得能够快速纳入新的数据集、方法和后端，以适应不断发展的研究需求。除此之外，HRET还引入了针对韩语的输出分析方法，包括形态意识的词类-词汇比例（TTR）来评估词汇多样性以及系统性关键词省略检测来识别缺失的概念，提供语言特定行为的诊断洞察力。
### Conclusion
HRET通过其多样化的评估方法和模块化的设计，不仅能够克服韩语LLM评估的可复制性差距，还能够提供针对形态和语义上模型输出不足的诊断性分析，这对于引导韩国LLM的定向改进具有重要意义。
## 240. `cs.AI` - 离线强化学习中的变分异常状态修正 [PDF](https://arxiv.org/pdf/2505.00503), [HTML](https://arxiv.org/abs/2505.00503)
### Authors
Ke Jiang,Wen Jiang,Xiaoyang Tan
### Background
离线强化学习受状态分布变化的影响显著，尤其是在处理未见过分布（OOD）的状态时更为突出。目前对于该问题的一个常见解决方法是异常状态矫正方法。论文背景主要研究如何通过修正策略促进代理行为回到安全区域内。
### Innovation
论文提出了一种创新的方法，称为密度感知安全感知（DASP），这是一种针对OOD状态矫正的全新方法。DASP方法通过优化一个同时考虑决策潜在结果及其密度的变分目标函数，促使代理优先选择那些导致更高数据密度的结果，从而振兴其在安全区域内的操作。
### Conclusion
论文通过在离线MuJoCo和AntMaze套件上的广泛实验验证了DASP方法的有效性和可行性。
## 241. `cs.AI` - 使用膨胀卷积和注意力辅助空域聚合提高卫星目标定位 [PDF](https://arxiv.org/pdf/2505.05599), [HTML](https://arxiv.org/abs/2505.05599)
### Authors
Seraj Al Mahmud Mostafa,Chenxi Wang,Jia Yue,Yuta Hozumi,Jianwu Wang
### Background
卫星图像中的目标定位具有挑战性，由于目标的高度变异性、低空间分辨率、来自噪声和主要特征（如云和城市灯光）的干扰。本研究关注三种卫星数据集：上大气重力波（GW）、中间层激波（Bore）和海洋涡旋（OE）。这些数据集中的目标具有不同的尺度和外观，大小、形状和特征分布范围存在显著差异。为了应对这些挑战，我们提出了YOLO-DCAP，这是YOLOv5的增强版，专门用于改善在复杂场景中的目标定位。YOLO-DCAP结合了多尺度膨胀残差卷积（MDRC）模块和注意力辅助空域聚合（AaSP）模块，以捕捉不同膨胀率下的多尺度特征并增强特征选择，从而提高目标在卫星图像中的定位效果。实验结果表明，YOLO-DCAP在目标局部化方面显著优于YOLO基模型和最先进方法。在所有三个卫星数据集上的性能提升分别达到了mAP50的20.95%和IoU的32.23%，且与最先进的替代方案相比分别提高了7.35%和9.84%，这表明本方法具有鲁棒性和通用性。
### Innovation
提出了YOLO-DCAP，这是一种增强了的YOLOv5版本，通过结合多尺度膨胀残差卷积（MDRC）模块和注意力辅助空域聚合（AaSP）模块，专门用于复杂场景下的目标定位，提高了目标的局部化准确度。这种方法在三个卫星数据集上的表现显著优于基模型和最先进的方法，展示了其鲁棒性和通用性。
### Conclusion
实验结果显示，YOLO-DCAP在所有卫星数据集上的mAP50和IoU分别提高了20.95%和32.23%，相比最先进的替代方案，分别是7.35%和9.84%的提高，证明了该方法的鲁棒性和通用性。我们已在GitHub开源了代码。
## 242. `cs.AI` - 通过反向传播通过去噪时间步长微调扩散策略 [PDF](https://arxiv.org/pdf/2505.10482), [HTML](https://arxiv.org/abs/2505.10482)
### Authors
Ningyuan Yang,Jiaxuan Gao,Feng Gao,Yi Wu,Chao Yu
### Background
扩散策略在机器人技术、游戏和自主驾驶等领域被广泛应用，由于其强大的表示能力，可以从演示数据中学习多样化的技能。然而，演示数据的不足可能导致生成次优甚至灾难性的轨迹。尽管基于强化学习(RL)的微调被视为解决这个问题的一种有前景的方法，但现有方法难以有效将Proximal Policy Optimization (PPO)适应扩散模型。这主要是因为去噪过程中动作概率估计的计算复杂性，导致复杂的优化目标。
### Innovation
文章介绍了一种新颖的框架NCDPO（Noise-Conditioned Deterministic Policy Optimization），将扩散策略重新定义为噪声条件下的确定性政策。通过将每个去噪步骤视为基于预采样噪声的可微变形，NCDPO能够进行可操作的似然评价和通过所有去噪时间步长的梯度反向传播。实验表明，NCDPO在从零开始训练时与MLP+PPO在样本效率上相当，并且在各种基准测试中同时在样本效率和最终性能上超过了现有方法，包括连续机器人控制和多智能体游戏场景。
### Conclusion
我们的实验结果表明，我们的方法对扩散策略中的去噪时间步数数量具有鲁棒性。NCDPO 在训练扩散策略时，尤其在从零开始训练时，展示了比直接应用 PPO 在 MLP 策略上更好的样本效率和最终性能，超越了现有方法。同时，通过反向传播通过去噪时间步长的微调策略，为解决方案提供了新的视角。
## 243. `cs.AI` - heat diffusion models -- interpixel attention mechanism [PDF](https://arxiv.org/pdf/2504.19600), [HTML](https://arxiv.org/abs/2504.19600)
### Authors
Pengfei Zhang,Shouqing Jia
### Background
去噪扩散概率模型（DDPM）将图像作为一个整体进行处理。由于相邻像素很可能属于同一对象，本文提出了热扩散模型（HDM），旨在进一步保留图像细节并生成更加真实的图像。
### Innovation
HDM本质上是一个整合了像素之间注意力机制的DDPM。在HDM中，二维热方程的离散形式被融入到DDPM的扩散和生成公式中，在图像处理过程中使得模型能够计算相邻像素之间的关系。实验显示出HDM能够生成比DDPM、一致扩散模型（CDM）、潜在扩散模型（LDM）和矢量量化生成对抗网络（VQGAN）更高质量的样本。
### Conclusion
HDM可以生成质量更高的样本。
## 244. `cs.AI` - 向量-语言模型的通用连续记忆 [PDF](https://arxiv.org/pdf/2505.17670), [HTML](https://arxiv.org/abs/2505.17670)
### Authors
Wenyi Wu,Zixuan Song,Kun Zhou,Yifei Shao,Zhiting Hu,Biwei Huang
### Background
语言模型（LMs）和其扩展的视觉-语言模型（VLMs）在各种任务中已经取得显著成效，但它们在需要多模态或多语言实际知识的复杂推理任务中仍表现不佳。现有的方法通常是将图像和文本标记拼接成长序列作为记忆，但这会大幅增加上下文长度，甚至可能降低性能。
### Innovation
提出使用连续记忆，即一组紧凑的密集嵌入，更有效地表示多模态和多语言知识。此设计的关键创新在于，视觉-语言模型（VLM）可以充当自己的连续记忆编码器。我们还提出了一种数据高效和参数高效的微调方法，只需1.2%的模型参数和15.6K自我合成样本的小数据集即可将VLM转换为记忆编码器。我们的方法CoMEM利用VLM的原始能力，将任意多模态和多语言知识编码为仅8个连续嵌入。
### Conclusion
通过大量跨八个多模态推理基准的实验，证明了我们方法的有效性。
## 245. `cs.AI` - Common Data Format (CDF): 一种足球比赛数据的标准格式 [PDF](https://arxiv.org/pdf/2505.15820), [HTML](https://arxiv.org/abs/2505.15820)
### Authors
Gabriel Anzer,Kilian Arnsmeyer,Pascal Bauer,Joris Bekkers,Ulf Brefeld,Jesse Davis,Nicolas Evans,Matthias Kempe,Samuel J Robertson,Joshua Wyatt Smith,Jan Van Haaren
### Background
足球比赛期间，各种不同的参与者（如公司）会收集关于比赛的各类数据，范围从基本信息（如首发阵容）到详细的位置数据等。提供给俱乐部、联盟和其他组织的数据越来越多地被用于支持决策制定，但由于数据来源不同、数据规格不一致、数据表示和交付方式各异等原因，分析这些数据存在显著障碍。处理这些数据往往需要大量时间和资金投入。因此，本文提出了一个统一且标准化的数据格式——Common Data Format (CDF)，旨在规范五种类型的比赛数据（比赛卡片数据、视频脚本、事件数据、追踪数据和比赛元数据），确保数据清晰、充分背景化（如数据来源清晰）并完整，从而便于后续的分析任务。
### Innovation
本文提出了Common Data Format (CDF)，旨在标准化足球比赛数据格式，解决了当前数据收集和分析存在的多种问题，如数据来源多样、数据规格不一致、数据表示和交付方式各异等。CDF规范了五种类型的比赛数据，确保数据的清晰度、充分背景化和完整性，有助于实现通用的后续分析任务。CDF是Version 1.0.0版本，代表了数据收集和标准化格式的一个重要进展。
### Conclusion
本文详细介绍了CDF的技术规范，阐述了确保提供数据清晰度和背景化的表示选择，并提出了通过CDF传输数据的实际方法。CDF的提出和实施将大大有助于解决当前足球比赛数据分析所面临的挑战，并为后续研究提供了坚实的基础。
## 246. `cs.AI` - NoWag：大型语言模型形状保持压缩的统一框架 [PDF](https://arxiv.org/pdf/2504.14569), [HTML](https://arxiv.org/abs/2504.14569)
### Authors
Lawrence Liu,Inesh Chakrabarti,Yixiao Li,Mengdi Wang,Tuo Zhao,Lin F. Yang
### Background
大型语言模型（LLMs）在各种自然语言处理任务上表现出色，但需要大量计算和内存资源，限制了它们在资源受限环境中的部署。
### Innovation
我们提出了NoWag：（归一化权重和激活量化的压缩）的统一框架，用于零样本形态保持压缩算法。该框架使用两种流行的形态保持压缩形式——向量量化NoWag-VQ和不规范/半规范剪枝NoWag-P，成功压缩了Llama-2 7B/13B/70B和Llama-3 8/70BB模型。NoWag-VQ显著优于最先进的零样本VQ，而NoWag-P则能够与最先进的方法竞争。
### Conclusion
这些结果表明这些压缩范式的共同点可能启发未来的工作。我们已将代码发布在指定网址处。
## 247. `cs.AI` - 预训练模型复用中的任务和特征相关性实证研究 [PDF](https://arxiv.org/pdf/2506.01975), [HTML](https://arxiv.org/abs/2506.01975)
### Authors
Jama Hussein Mohamud,Willie Brink
### Background
在机器学习领域，预训练神经网络被广泛用于特定任务的模型训练，并且其部分结构常被回收用于解决不同的问题，常常取得较好的效果。研究者试图理解为何在预训练模型中选择特定部分对于达到一定的任务准确性具有决定性影响，以及任务和特征之间的相关性如何影响模型的复用效果。
### Innovation
本文提出了一种实验框架来评估任务和特征的相关性对预训练模型复用的影响。研究发现，Bob（即使用预训练模型的人）的准确率随着其任务与Alice（预训练模型的创建者）的任务之间的相关性增加而增加，即便任务是无关联的，由于选择的网络结构和优化器，Bob仍能获得显著优于随机性能的结果。研究还假设了最优重新训练层数与任务和特征之间的相关性有关。
### Conclusion
在具有语义相关性的任务场景中，可以通过复用Alice的预训练网络来有效提高性能，这表明任务和特征的相关性在模型复用中的重要性。
## 248. `cs.AI` - EEG2TEXT-CN：通过大型语言模型和对比学习对齐中文文本-EEG的一种探索性研究 [PDF](https://arxiv.org/pdf/2506.00854), [HTML](https://arxiv.org/abs/2506.00854)
### Authors
Jacky Tai-Yu Lu,Jung Chiang,Chi-Sheng Chen,Anna Nai-Yun Tung,Hsiang Wei Hu,Yuan Chiao Cheng
### Background
该研究提出了EEG2TEXT-CN框架，旨在使用中文进行脑电波到文本的开放词汇生成，这是同类研究中的最早尝试之一。该框架基于生物基础的脑电波编码器NICE-EEG和紧凑型预训练语言模型MiniLM，通过掩码预训练和对比学习将多通道脑信号与自然语言表示对齐。研究利用了包含约1500个训练验证句子和300个保留测试样本的中文EEG数据集，展示了在中文文本-EEG对齐方面潜在的可能性，尽管在句法连贯性上仍面临挑战。此项工作为多语言脑电波到文本的研究开辟了新方向，并为未来的中文认知语言接口奠定了基础。
### Innovation
提出了EEG2TEXT-CN框架，该框架结合了生物基础的脑电波编码器NICE-EEG和紧凑型预训练语言模型MiniLM，通过掩码预训练和对比学习将多通道脑信号与自然语言表示对齐。研究采用一种零样本设置，将EEG分为单个字符嵌入，并在此基础上生成完整句子。此外，该工作是最早针对中文的开放词汇EEG到文本生成框架之一。其创新点在于将脑电波与自然语言进行对齐，并在此基础上实现文本生成。
### Conclusion
尽管在句法连贯性方面仍存在挑战，该研究展示了利用脑电波进行非音素多模态语言解码的可行性，并为中文认知语言接口提供了新的研究方向。未来的研究将致力于提高语法连贯性，以进一步提高模型的性能。
## 249. `cs.AI` - Hume: 介绍视觉语言行动模型中的系统二思考 [PDF](https://arxiv.org/pdf/2505.21432), [HTML](https://arxiv.org/abs/2505.21432)
### Authors
Haoming Song,Delin Qu,Yuanqi Yao,Qizhi Chen,Qi Lv,Yiwen Tang,Modi Shi,Guanghui Ren,Maoqing Yao,Bin Zhao,Dong Wang,Xuelong Li
### Background
人类在处理复杂任务时通过慢思考来指导行动。这种思考模式已经助力大型语言模型在数字领域解决复杂问题上取得了显著进展。然而，这种思考模式在与物理世界交互的机器人基础模型中的潜力仍待探索。Hume 研究了一个具有价值引导系统二思考和级联动作去噪的双系统视觉语言行动（VLA）模型，旨在利用人类相似的思考能力来控制灵巧的机器人控制。
### Innovation
研究引入了Hume模型，该模型包含两个系统：一个进行价值引导思考的系统二和一个轻量级的反应型视觉运动策略。系统二扩展了视觉语言行动模型的主干，加入了新的价值查询头，用于估计预测动作的状态-动作价值，并通过重复采样多个动作候选并根据状态-动作价值选择一个最优动作来执行价值引导思考。系统一则处理级联的动作去噪任务，确保灵巧的机器人控制。系统在部署时，系统二以较低的频率进行价值引导思考，系统一则在异步接收系统二选出的动作候选并实时预测流畅的动作。实验表明，Hume 在多个模拟基准测试和真实机器人部署中优于现有最先进的视觉语言行动模型。
### Conclusion
Hume 在多个模拟实验和实际机器人实验中显示出优于现有最佳的视觉语言行动模型的结果，展示了引入价值引导的系统二思考在机器人控制中的优势。
## 250. `cs.AI` - 基于音系知识在CTC基线错音检测中提升GOP [PDF](https://arxiv.org/pdf/2506.02080), [HTML](https://arxiv.org/abs/2506.02080)
### Authors
Aditya Kamlesh Parikh,Cristian Tejedor-Garcia,Catia Cucchiarini,Helmer Strik
### Background
计算机辅助发音训练(CAPT)系统利用自动发音质量度量标准，如发音 goodness-of-pronunciation (GOP) 指标。GOP 指标依赖于强制对齐，但由于音质多样性容易产生标注和分割错误。虽然alignment-free 方法能够解决这些问题，但由于计算成本高且不适用于长音节序列和丰富的音节库，因此效率较低。研究引入了一种基于音节簇和常见学习者错误的具有音节置换意识的alignment-free GOP 方法，以提高效率和准确性。该GOP被应用于两个第二语言(L2)英语语音数据集，分别包含儿童和成人语音，结果表明在alignment-free方法中限制音节置换（RPS）和无限制音节置换（UPS）设置优于现有基线。研究表明，基于音系知识的改进可以提升CTC基线在错音检测中的表现。
### Innovation
该研究提出了一种基于音节簇和常见学习者错误的具有音节置换意识的alignment-free GOP 方法，这在处理发音质量检测中的计算效率低和标注准确性问题上是一种创新。这种方法提高了效率并解决了传统方法中的标注和分割错误问题，适用于处理长音节序列和音节库问题。
### Conclusion
研究选取了两个第二语言(L2)英语语音数据集进行评估，发现基于音系知识改进的音节置换意识的GOP 方法效果显著优于以往的基线方法。研究结果显示，这种方法能够在保持准确性的同时提高效率，为进一步研究提供了新的思路。未来的研究方向可以包括进一步优化算法或探索其他改进方法来更好地适应不同的语音训练场景。
## 251. `cs.AI` - 克服低资源语言生成语言建模中的数据稀缺问题：一项系统性回顾 [PDF](https://arxiv.org/pdf/2505.04531), [HTML](https://arxiv.org/abs/2505.04531)
### Authors
Josh McGiff,Nikola S. Nikolov
### Background
生成语言建模在ChatGPT和Google Gemini等服务出现后日益流行。尽管这些模型在生产效率和沟通方面展示了革命性的潜力，但它们主要面向英语等高资源语言，这加剧了自然语言处理（NLP）领域中的语言不平等。这篇文章首次系统地研究了解决低资源语言（LRL）生成语言建模中数据稀缺性的策略。研究表明，自1990年代以来，有54项研究探讨了这一问题，包括单语言数据增强、反向翻译、多语言训练、提示工程等多种技术方法的应用。
### Innovation
该研究是首个专注于探讨低资源语言生成语言建模中数据稀缺性问题的系统性回顾，从54项研究中识别、分类和评估了包括单语言数据增强、反向翻译、多语言训练、提示工程等多种技术方法，分析了模型架构选择、语言族表现及评价方法的最新趋势。
### Conclusion
研究所发现的主要依赖于基于变换器的模型，小部分低资源语言的研究，以及研究之间缺乏一致的评估方法。该研究建议将这些方法扩展到更多样化的低资源语言中，并概述了构建公平的生成语言系统所面临的一些开放性挑战。最终，这篇文章旨在支持研究人员和开发者构建包容性的面向未充分代表语言群的语言智能工具，这是使低资源语言使用者受益并保存语言多样性的一种必要步骤。
## 252. `cs.AI` - cuVSLAM：CUDA加速的视觉里程计与建图 [PDF](https://arxiv.org/pdf/2506.04359), [HTML](https://arxiv.org/abs/2506.04359)
### Authors
Alexander Korovko,Dmitry Slepichev,Alexander Efitorov,Aigul Dzhumamuratova,Viktor Kuznetsov,Hesam Rabeti,Joydeep Biswas,Soha Pouya
### Background
自主机器人需要准确且稳健的姿态估计。现有视觉同时定位与建图（VSLAM）解决方案对于不同的视觉惯性传感器套件支持有限。cuVSLAM通过优化CUDA算法，能够在各种配置的多传感器设备上实现实时应用，尤其适用于边缘计算设备如NVIDIA Jetson，显著提高了不同规模多相机配置下的运行效率。
### Innovation
cuVSLAM通过CUDA优化实现了对于多达32个RGB和深度相机以及惯性测量单元的多种视觉惯性传感器套件的支持，能够在任意几何配置下运行。该算法的实时性能在多个先进基准测试中表现出最佳效果。
### Conclusion
cuVSLAM设计精准并采用CUDA加速，支持多种视觉惯性传感器组合，适用于边缘计算设备。实验结果表明cuVSLAM在各个最先进的基准测试中表现最佳，表明其在实际应用中的竞争力。
## 253. `cs.AI` - GenAI 代际：学生对意识、准备和关注的看法 [PDF](https://arxiv.org/pdf/2505.02230), [HTML](https://arxiv.org/abs/2505.02230)
### Authors
Micaela Siraj,Jon Duke,Thomas Plötz
### Background
生成型人工智能（GenAI）正在彻底改变教育和职业发展领域，深刻影响着学生的学习方式、参与度及未来准备。由于GenAI的发展速度超过了相关政策和结构的制定速度，从而开启了新的时代，并产生了所谓的‘GenAI代’。‘GenAI代’是指那些在社会广泛采用GenAI的过程中，其教育经历受到GenAI带来的各种机遇与挑战影响的学生群体。本研究通过短问卷以及开放性问题，调查了学生对GenAI的看法，内容集中于学生对GenAI的认识程度、准备状态和担忧等方面。
### Innovation
本研究创新性地聚焦通过课程接触到GenAI的学生更感准备充分，而没有接触的学生则表达了更多的脆弱感和不确定性，这揭示了一种新的准备度鸿沟，超越了传统学科范围。超过250份反馈中，有超过40%提供了详细的定性意见，指出学生普遍乐观但更广泛表达了一种关于伦理、职业替代和教育结构适应性等方面的担忧。这些发现为了解GenAI的潜力和风险提供了关键见解。
### Conclusion
未来的挑战在于教育机构应实施相应建议，超越对这些工具的最低限度访问，转向提供更明智的使用指导，同时保留批判性思维、伦理推理和适应性学习的重要性，以应对GenAI带来的高度变革性影响。
## 254. `cs.AI` - 环境护航：基于AI的火灾与烟雾分类、分割和检测分析 [PDF](https://arxiv.org/pdf/2503.14552), [HTML](https://arxiv.org/abs/2503.14552)
### Authors
Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Fatemeh Afghah,Connor Peter McGrath,Danish Bhatkar,Mithilesh Anil Biradar,Abolfazl Razi
### Background
火灾和烟雾现象对自然环境、生态系统、全球经济以及人类生命和野生动物构成重大威胁。为了有效应对这些挑战，需要更加先进、高效的火灾管理技术，用于早期检测、实时监控以及减少火灾对生态平衡和公共安全的总体影响。近年来，人工智能（AI）和计算机视觉（CV）的进步显著推动了高效火灾管理系统的发展。然而，现有的火灾和烟雾检测和监测系统高度依赖高质量的数据，以便训练机器学习模型。尽管现有数据集在训练、评估和测试先进深度学习模型方面发挥着关键作用，但过去20年里对这些数据集的整体回顾仍未得到全面研究。
### Innovation
本文提供了一项深入的数据集系统性回顾和评估，涵盖了过去20年收集的数据集。研究内容包括每个数据集的特征（类型、规模、格式、采集方法和地理多样性），以及其在不同火灾管理任务（分类、分割、检测）中的应用特点。此外，还总结了每个数据集的优势和不足，并讨论了它们在火灾管理研究和技术中的潜在影响。最后，通过使用先进的算法（如ResNet-50、DeepLab-V3、YoloV8）在不同数据集上进行了广泛的实验分析。
### Conclusion
本文对过去20年收集的各种火灾和烟雾数据集进行了综合分析和评价，总结了其特点和优劣，并对它们在推进火灾管理研究和技术创新方面的潜力进行了探讨。研究人员可以根据本文提供的信息选择最合适的数据集来训练和验证先进的人工智能算法，进一步提高火灾管理系统的性能。
## 255. `cs.AI` - 贝叶斯层次不变预测 [PDF](https://arxiv.org/pdf/2505.11211), [HTML](https://arxiv.org/abs/2505.11211)
### Authors
Francisco Madaleno,Pernille Julie Viuff Sand,Francisco C. Pereira,Sergio Hernan Garrido Mejia
### Background
本文提出了一种基于贝叶斯视角重新定义不变因果预测（ICP）的方法，称为贝叶斯层次不变预测（BHIP）。该方法利用层次结构来显式地测试因果机制的不变性，在异质性数据下具有更好的计算可扩展性，特别是对于更多的预测变量。此外，由于是贝叶斯方法，BHIP能够利用先验信息，可以有效地识别出更可靠的因果特征。
### Innovation
1. 通过贝叶斯先验引入层次结构，提高计算效率并扩展适用性，特别是适用于具有更多预测变量的数据集。2. 引入了两种促进稀疏性的先验：horseshoe和spike-and-slab，这使得能够更准确地识别因果特征。3. 该方法在合成数据和真实数据中进行了测试，显示出作为ICP的替代推理方法的潜力。
### Conclusion
本文提出了一种新的贝叶斯层次不变预测方法（BHIP），该方法比传统的不变因果预测（ICP）在处理更多预测变量时更有效，并且可以通过先验信息提高因果特征识别的准确性。通过在合成数据和实际数据上的实验，证明了BHIP作为一种可能的替代推理方法的有效性。
## 256. `cs.AI` - LLMs在支持移动应用的隐私和安全方面的最新进展和研究方向 [PDF](https://arxiv.org/pdf/2506.11679), [HTML](https://arxiv.org/abs/2506.11679)
### Authors
Tran Thanh Lam Nguyen,Barbara Carminati,Elena Ferrari
### Background
现代生活中，移动设备的数量激增。尽管移动应用为用户提供了许多便利功能，但安全和隐私风险仍然威胁着用户。近年来，这些威胁的复杂性增加，凸显了需要更先进和高效的检测方法。这项研究探讨了使用大型语言模型（LLMs）识别移动应用中的安全风险和隐私违规，并对其进行缓解的方法。通过研究应用LLMs降低智能手机平台Top 10常见安全风险的最新研究，本文强调了LLMs具备取代传统分析方法（如移动应用的动态和混合分析）的可能性和潜力。作为LLM基础解决方案的代表，文中介绍了一个检测在线分享图片时敏感数据泄露的方法，这是智能手机用户常见的行为。最后，讨论了开放的研究挑战。
### Innovation
引入使用LLMs来降低智能手机平台Top 10常见安全风险的最新研究，强调了LLMs具备取代传统分析方法（如移动应用的动态和混合分析）的可能性和潜力，特别是提出了通过LLM检测股份分享时的敏感数据泄露的方法，提供了实践经验。
### Conclusion
本文讨论了LLMs在移动应用中的应用，展示了其在隐私和安全方面的新进展，并提出了未来的研究方向。尽管取得了显著进展，但也指出了开放的研究挑战。
## 257. `cs.AI` - 在大型语言模型中控制幻觉的基本不可能性 [PDF](https://arxiv.org/pdf/2506.06382), [HTML](https://arxiv.org/abs/2506.06382)
### Authors
Michał P. Karpowicz
### Background
本文证明了在大型语言模型中实现完美的幻觉控制在数学上是不可能的，即没有任何推理机制能够在保证诚实性回应生成、语义信息保存、相关知识揭示以及知识约束下的最优性这四个方面同时达到目标。
### Innovation
本文采用了三项数学理论框架，分别是拍卖理论、概率预测的适当评分理论和变压器架构的log-sum-exp分析，展示了信息聚合过程中不可避免的信息 conservation 原则违背。通过变压器概率聚合的Jensen不等式空间分析揭示了这一不可避免性。
### Conclusion
本文将幻觉从工程缺陷重新定义为分布式智能的不可避免的数学特征，并指出真理、知识利用和回应完整性之间存在根本性的取舍，为管理和控制幻觉提供了原理性的基础，揭示了神经网络推理、知识和推理哲学以及博弈论和信息论的经典结果之间的深层联系，为在数学约束下开发有益AI系统打开了新的研究方向。
## 258. `cs.AI` - 大型语言模型的指令遵循通过增强注意机制 [PDF](https://arxiv.org/pdf/2506.13734), [HTML](https://arxiv.org/abs/2506.13734)
### Authors
Vitoria Guardieiro,Adam Stein,Avishree Khare,Eric Wong
### Background
大型语言模型（LLMs）的生成控制仍然是确保其安全和可靠部署的关键挑战。常见的方法包括提示工程和微调，而最近的工作探索了潜在引导，这是一种轻量级技术，通过改变LLM的内部激活以引导生成过程。然而，后续研究发现潜在引导的有效性有限，经常比简单的指令提示表现不佳。因此，需要提出新的方法来解决这一限制问题，以提高生成控制的成功率。
### Innovation
本研究首先建立了一个基准，涵盖多种行为以标准化评估引导技术。在此基础上，引入了指令注意增强（InstABoost）方法，通过改变模型在生成过程中的注意机制来增强指令提示的强度。InstABoost将现有方法的优点结合起来，并且理论依据是过去的研究所提出的观点，即基于Transformer的模型中的上下文内规则遵循可以通过操控指令上的注意来控制。实验结果表明，InstABoost在控制成功方面优于传统的提示和潜在引导方法。
### Conclusion
InstABoost通过增强大型语言模型的注意力机制，显著提高了指令遵循的成功率，为生成控制领域提供了新的解决方案。
## 259. `cs.AI` - 将空间时间特征集成到LSTM中的空间启发式COVID-19住院预测 [PDF](https://arxiv.org/pdf/2506.05752), [HTML](https://arxiv.org/abs/2506.05752)
### Authors
Zhongying Wang,Thoai D. Ngo,Hamidreza Zoraghein,Benjamin Lucas,Morteza Karimzadeh
### Background
COVID-19大流行对医疗系统产生了严重影响，强调了需要准确及时的住院预测以支持有效的医疗规划。然而，在变异病毒流行期间，大多数预测模型表现不佳，此时它们最为需要。本文探讨了解决该问题，提出了一种新的并行流长短期记忆（LSTM）框架来预测美国各州的每日突发住院情况。在此框架中，引入了来自Meta的社交连通性指数衍生的空间时间特征——医院化社交接近度（SPH），以提高预测准确性。SPH 作为跨州人口互动的代理指标，能够捕捉空间和时间上的传播动态。该架构捕捉了短期和长期的时间依赖性，并采用多输出重新加权策略平衡预测一致性与误差。模型在德尔塔和奥密克戎变异病毒流行期间与COVID-19预测枢纽的集成模型进行评估，展示了其优越性。在奥密克戎流行期间，该模型在7天、14天、21天和28天的预测窗口中，分别平均每个州的预测住院人数比集成模型多27、42、54和69人。消融数据分析进一步确认了SPH的预测能力，突显其在增强预测模型中的有效性。该研究不仅推进了住院预测，还强调了像SPH这样的空间时间特征在建模传染病传播复杂动态中的重要性。
### Innovation
本文提出了一种新的并行流LSTM框架，整合了来自Meta的社交连通性指数衍生的空间时间特征——医院化社交接近度（SPH），以提高住院患者预测的准确性。该架构能够捕捉短期和长期的时间依赖性，并采用多输出重新加权策略平衡预测的一致性和误差，从而在变异病毒流行期间显著提高了预测性能。
### Conclusion
研究结果表明，通过将SPH这种空间时间特征纳入LSTM模型，可以显著提高对COVID-19住院患者的预测准确性。这不仅提升了住院预测的能力，还强调了整合空间时间特征在构建更准确、更可靠的传染病传播模型中的重要性。
## 260. `cs.AI` - 基于对数几率的GOP评分在错误发音检测中的评估 [PDF](https://arxiv.org/pdf/2506.12067), [HTML](https://arxiv.org/abs/2506.12067)
### Authors
Aditya Kamlesh Parikh,Cristian Tejedor-Garcia,Catia Cucchiarini,Helmer Strik
### Background
发音评估依赖于良好的发音（GOP）分数，这些分数传统上是从softmax后验概率中得出的。然而，后验概率可能会过于自信，而且在音素区分上表现不佳，限制了其有效性。这项研究比较了基于对数几率的GOP分数和基于概率的GOP分数在错误发音检测中的表现。实验在两个用荷兰语和 Mandarin 讲第二语言英语的语音数据集上进行，评估了分类性能和与人类评估的关联性。研究表明，基于对数几率的方法在分类上有更好的表现，但其效果取决于数据集的特点。最大对数几率的GOP分数最能与人类感知相匹配，而不同GOP分数的结合则能在概率和对数几率特征之间实现平衡。研究结果表明，结合不确定性建模和音素特定加权的混合GOP方法可以改善发音评估的效果。
### Innovation
该研究通过比较基于对数几率的GOP分数和基于概率的GOP分数来改进发音错误检测的技术，旨在提高发音评估的准确性。这种方法特别关注参数的不确定性，从而提供更精确的评估。同时研究引入了最大对数几率的GOP分数和不同GOP分数的结合，使得评估既考虑概率也考虑不确定性。
### Conclusion
研究发现，结合不确定性建模和音素特定加权的混合GOP方法可以提升发音评估的效果。最大对数几率的GOP分数与人类感知的匹配度最高。不同GOP分数的结合能够平衡概率和对数几率特征，提高评估的全面性。
## 261. `cs.AI` - 超越大语言模型的定制对话：基于强化学习的对话管理器 [PDF](https://arxiv.org/pdf/2506.19652), [HTML](https://arxiv.org/abs/2506.19652)
### Authors
Lucie Galland,Catherine Pelachaud,Florian Pecune
### Background
当前的研究集中在利用大型语言模型（LLMs）进行开放式的对话，但是这些模型往往缺乏对多样用户特征的适应性和灵活性。为了应对这一挑战，本文提出了一个结合了大语言模型与基于强化学习的对话管理器的新框架，旨在支持具有特定目标的开放对话，同时提高系统的适应性和效率，使其能够从有限的数据中学习，并在对话阶段之间平滑过渡，以个性化响应不同患者的需求。
### Innovation
该论文的主要创新在于提出了一种结合大型语言模型和基于强化学习的对话管理器的新框架，通过层级强化学习建模对话的结构化阶段，并利用元学习增强跨不同用户特征的适应性。此外，该框架还展示了通过强化学习调整大语言模型，使其能够创建具有特定目标的开放式对话系统。
### Conclusion
该研究应用了提出的框架到行动访谈（Motivational Interviews）场景中，以促进行为改变。实验结果表明，与最先进的大语言模型基线相比，提出的对话管理器在奖励方面表现出色，证明了基于强化学习调整大语言模型以创建具有特定目标的开放式对话系统的潜在优势。
## 262. `cs.AI` - Horus: 一种在不确定性下实现无信任委托的协议 [PDF](https://arxiv.org/pdf/2507.00631), [HTML](https://arxiv.org/abs/2507.00631)
### Authors
David Shi,Kevin Joo
### Background
在动态且信任度低的环境中，自主人工智能代理可以通过委托给子代理来完成工作，但这种方法的正确性无法通过前期规范或集中监督来保证。文章指出，错误的成本低于犯错的成本，正确性将成为系统的一种Emergent Property。在此背景下，需要一种协议来确保正确性而不依赖于集中式控制或前期规范。
### Innovation
本文提出了一种通过抵押声明实施递归验证游戏的协议，以确保正确性。任务以意图的形式发布，解决者竞争履行任务。选定的解决者在承担风险后执行任务，由验证者在事后检查正确性。任何挑战者都可以通过抵押来挑战结果，以触发验证过程。错误的代理被惩罚，正确反对者得以奖励，还设有一条处罚错误验证者的升级路径。当激励与解决者、挑战者和验证者对齐时，错误条件使得正确性成为各参与者的纳什均衡。
### Conclusion
当激励相容时，错误条件使正确性成为各方的纳什均衡。Horus协议确保了在高度不确定且无信任环境下的系统正确性。
## 263. `cs.AI` - 通过时间正则化提高脉冲神经网络的泛化能力 [PDF](https://arxiv.org/pdf/2506.19256), [HTML](https://arxiv.org/abs/2506.19256)
### Authors
Boxuan Zhang,Zhen Xu,Kuan Tao
### Background
脉冲神经网络（SNNs）因其事件驱动和低功耗特性而受到广泛关注，特别适用于处理基于神经形态的数据。然而，直接训练的SNNs由于神经形态数据集规模有限和梯度匹配问题，在泛化性能方面受到了严重制约，存在严重的过拟合问题。
### Innovation
本文提出了一种时间正则化训练（TRT）方法，通过引入时间依赖的正则化机制强化了对早期时间步的约束。通过在包括CIFAR10/100、ImageNet100、DVS-CIFAR10和N-Caltech101等数据集上与现有先进技术进行性能比较，并通过消融研究和分析验证了TRT的有效性，包括损失景观可视化和学习曲线分析，TRT能够有效缓解过拟合问题并使训练损失景观扁平化，从而提升模型的泛化能力。此外，通过费舍尔信息分析，给出了TRT时间正则化机制的理论解释，揭示了时间信息集中（TIC）现象。
### Conclusion
时间正则化机制在TRT训练过程中有效引导网络在早期时间步学习富有信息量的鲁棒特征，从而在模型泛化能力上取得显著提升，并提供了代码以便验证研究结果。
## 264. `cs.AI` - 地质一切模型3D：一种统一且零样本的地下理解基础模型 [PDF](https://arxiv.org/pdf/2507.00419), [HTML](https://arxiv.org/abs/2507.00419)
### Authors
Yimin Dou,Xinming Wu,Nathan L Bangs,Harpreet Singh Sethi,Jintao Li,Hang Gao,Zhixiang Guo
### Background
深入理解地球的地下结构对于能源转型、自然灾害应对及行星科学至关重要。然而，地下分析仍然碎片化，每个任务（如地质结构解释、地层分析、地体分割和属性建模）都要求特定的数据分布和任务描述，这使得跨任务的整合变得困难。本研究旨在通过统一生成架构解决这一问题，该架构能够将所有地下分析任务统一起来，使用地下成像衍生的潜在地质框架进行提示条件推理，从而实现跨异质提示类型的任务零样本通用化。
### Innovation
该研究提出了一种新的地质全方位模型3D（GEM），这是一种统一的生成模型，通过提示条件推理将多种地质任务整合起来。GEM的独特之处在于它采用了一种两阶段训练策略，结合了自我监督的表征学习和对抗调优，这种机制使得模型能够在没有重新训练的情况下跨任务、跨数据源进行零样本跨任务泛化。这项研究展示了GEM在各种调查和任务中的广泛应用，包括火星雷达地层分析、俯冲带地质结构解释、全地震地层解释、地体分割和属性建模。
### Conclusion
通过将专家知识与结构感知的生成推理结合，GEM为物理地球科学的人工智能提供了基础，使其从碎片化的流程转变为一个集成、提示可调的推理系统，推动了可扩展且有用户在环的地球物理AI的发展。
## 265. `cs.AI` - Hita: 整体化令牌符生成器 [PDF](https://arxiv.org/pdf/2507.02358), [HTML](https://arxiv.org/abs/2507.02358)
### Authors
Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi
### Background
传统的自回归（AR）图像生成模型逐步生成视觉令牌，但难以捕捉令牌序列间的全局关系。此外，大多数视觉令牌化模型将局部图像片段映射到潜在令牌中，限制了全局信息的捕捉能力。
### Innovation
Hita是一种新颖的自回归图像生成的图像令牌化方法，它引入了全局到局部的令牌化方案，采用可学习的整体查询和局部补丁令牌。Hita采用了两项关键策略以更好地适应自回归生成过程：1）以全局令牌开始，随后是补丁级令牌，并使用因果注意确保对先前令牌的意识；2）在将去量化的令牌送入解码器前采用轻量级融合模块以控制信息流并优先考虑全局令牌。
### Conclusion
实验表明，Hita加速了自回归生成器的训练速度，并在ImageNet基准测试中优于使用传统令牌化的模型，达到了2.59 FID和281.9 IS。详细分析显示，Hita能够捕捉图像的全局属性，如纹理、材料和形状，并在零样本样式转移和图像修补方面表现出有效性。代码可从指定链接获得。
## 266. `cs.AI` - SurgiSR4K: 一种用于辅助微创手术的高分辨率内窥镜视频数据集 [PDF](https://arxiv.org/pdf/2507.00209), [HTML](https://arxiv.org/abs/2507.00209)
### Authors
Fengyi Jiang,Xiaorui Zhang,Lingbo Jin,Ruixing Liang,Yuxin Chen,Adi Chola Venkatesh,Jason Culman,Tiantian Wu,Lirong Shao,Wenqing Sun,Cong Gao,Hallie McNamara,Jingpei Lu,Omid Mohareri
### Background
高分辨率成像是提高视觉清晰度和实现精确的计算机辅助指导的关键，在微创手术（MIS）中尤为关键。尽管4K内窥镜系统已得到广泛应用，但专为机器人辅助MIS设计的高质量4K数据集仍未充分提供。SurgiSR4K填补了这一空白，成为首个适用于机器人辅助MIS的高分辨率手术成像和视频数据集，代表了机器人辅助手术的真实条件。该数据集涵盖了一系列复杂的视觉情况，如反射、工具遮挡、出血和软组织变形，反映了微创手术中常见的挑战。这些高分辨率的数据集有望为多种计算机视觉任务提供支持，例如超分辨率（SR）、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新颖视图合成以及视觉-语言模型开发。
### Innovation
SurgiSR4K是首个公开可用的医疗内窥镜4K视频数据集，旨在辅助机器人辅助MIS手术。该数据集为多种计算机视觉任务提供了高分辨率的数据基础，包括超分辨率、烟雾去除、手术器械检测、3D组织重建等。它填补了机器人辅助MIS手术中4K高清数据的空白，推动了智能成像技术的研发，旨在提高图像引导的机器人手术性能、安全性和易用性。
### Conclusion
SurgiSR4K为高分辨率手术成像研究提供了坚实的基础，有助于推动智能成像技术的发展，提高机器人辅助微创手术的性能、安全性和易用性。
## 267. `cs.AI` - 对于互视问题的启发式与近似算法的实证分析 [PDF](https://arxiv.org/pdf/2507.01076), [HTML](https://arxiv.org/abs/2507.01076)
### Authors
Vanja Stojanović,Bor Pangeršič
### Background
目前，互视（MV）问题的实证研究仍然缺乏对其实际表现的分析，尽管有理论研究。该论文旨在通过在各种合成图数据集上实现并评估三种不同的算法（直接随机启发式算法、基于超图的逼近算法和遗传算法）来填补这一空白，这些数据集包括具有已知$boldsymbol{text{μ(G)}}$值的图以及一般图模型。实验结果显示，在较小的图中，算法始终能实现与理论边界一致的MV集大小；但在较大的实例中，实现的解的大小显著偏离理论极限，这与缺乏紧致界限相结合，使得绝对质量评估变得复杂。不过，验证已知最优图后发现，遗传算法和其他启发式算法在测试方法中表现最好。
### Innovation
该论文通过在不同数据集上实现并评估三种不同的算法（直接随机启发式算法、基于超图的逼近算法和遗传算法）来填补了互视问题理论研究与实际分析之间的空白，特别是在较小图和较大图中的表现差异，并通过对已知最优图的验证展示了遗传算法和其他启发式算法的优越性。
### Conclusion
尽管在较大的实例中实现了解的大小显著偏离理论极限，且缺乏紧致界限使得全面质量评估变得困难，但在验证已知最优图后，该研究发现遗传算法和其他启发式算法表现最好。
## 268. `cs.AI` - 评估日本语人工智能咨询：基于动机访谈标准评估咨询者、客户和评估者的角色 [PDF](https://arxiv.org/pdf/2507.02950), [HTML](https://arxiv.org/abs/2507.02950)
### Authors
Keita Kiuchi,Yoshikazu Fujimoto,Hideyuki Goto,Tomonori Hosokawa,Makoto Nishimura,Yosuke Sato,Izumi Sezai
### Background
本文研究了大型语言模型（LLM）在日语疗法环境中三种咨询角色中的表现。研究者同时评估了咨询人工智能系统（包括GPT-4-turbo及使用零样本提示或结构化多步骤对话提示的SMDP系统Claude-3-Opus-SMDP）、客户模拟人工智能以及评估人工智能系统。这些系统及模拟被人类专家（15人）根据动机访谈治疗完整度手册4.2.1版进行评估。
### Innovation
研究首次全面评估了大型语言模型在日语疗法环境中的表现，并使用动机访谈标准进行评估。SMDP实施显著增强了咨询人工智能的表现，且在所有动机访谈全球评分标准上均优于零样本提示。此外，研究还发现了模型特定的偏见，并指出客户模拟人工智能在情感表达和现实度方面存在不足。
### Conclusion
研究为非英语环境中的人工智能辅助咨询建立了基准，并指出高级提示工程技术、检索增强生成和目标微调是改进的关键领域，这对于开发文化敏感的人工智能心理健康工具具有重要意义。
## 269. `cs.AI` - 使用电子健康记录上的生成预训练转换器进行零样本医学事件预测 [PDF](https://arxiv.org/pdf/2503.05893), [HTML](https://arxiv.org/abs/2503.05893)
### Authors
Ekaterina Redekop,Zichen Wang,Rushikesh Kulkarni,Mara Pleasure,Aaron Chin,Hamid Reza Hassanzadeh,Brian L. Hill,Melika Emami,William Speier,Corey W. Arnold
### Background
电子健康记录（EHRs）中的纵向数据通过一系列编码概念（如诊断、程序、药物和实验室测试）来表示个体的临床历史。尽管可以使用预训练转换器模型（如GPT）来预测未来事件，但往往需要针对具体任务进行微调，这会增加成本。相比之下，使用预训练的基础模型可以在零样本预测设置中应用，提供了一种比为每个结果单独微调模型更为可扩展的替代方案。
### Innovation
本文首次全面分析了使用基于GPT的预训练基础模型在EHRs上的零样本预测，提出了一种新的管道，将医学概念预测建模为生成建模任务。该方法不同于需要大量标记数据的监督方法，能够仅从预训练知识进行模型预测，评估了多个时间范围和临床类别下的性能，展示了模型在无任务监督的情况下捕捉潜在时间依赖性及复杂患者轨迹的能力。
### Conclusion
在预测下一个医疗概念方面，模型使用精确度和召回率指标进行评估，平均最高1精确度达到0.614和召回率为0.524。对于12个主要诊断条件，该模型展示了强大的零样本性能，同时保持了低假阳性的高水平真阳性率。这项研究证明了基础EHR GPT模型捕捉多样表型及在临床环境下进行无任务监督的鲁棒零样本预测的能力，增强了预测型医疗模型的灵活性并减少了对特定任务训练的需求，推动了在临床环境中的更广泛应用。
## 270. `cs.AI` - IPFormer-VideoLLM：增强多模态视频理解以应对多视角场景 [PDF](https://arxiv.org/pdf/2506.21116), [HTML](https://arxiv.org/abs/2506.21116)
### Authors
Yujia Liang,Jile Jiao,Xuetao Feng,Zixuan Ye,Yuan Wang,Zhicheng Wang
### Background
视频大型语言模型（VideoLLMs）展现了强大的理解能力，但在多视角或多场景切换的情景下表现不佳。这会导致错误识别同一实例的身份和忽视关键帧等问题。研究发现，现有数据集缺乏多视角标注，这是导致模型在多场景下表现不佳的主要原因。
### Innovation
提出了一个新的数据集MultiClip-Bench，用于多场景下的视频标注。并且提出了一种新的模型IPFormer-VideoLLM。该模型通过高效注意力连接器将实例特征作为实例提示注入，实现了跨场景的实例特定信息聚合。该方法不仅提高了多场景视频理解能力，还在多种视频基准测试中表现出优势。
### Conclusion
新数据集和模型显著改善了多场景视频的理解，还提升了各个视频基准的性能。
## 271. `cs.AI` - StreamDiT: 实时流式文本到视频生成 [PDF](https://arxiv.org/pdf/2507.03745), [HTML](https://arxiv.org/abs/2507.03745)
### Authors
Akio Kodaira,Tingbo Hou,Ji Hou,Masayoshi Tomizuka,Yue Zhao
### Background
近年来，通过将基于Transformer的扩散模型扩展到数以亿计的参数，文本到视频（T2V）生成取得了显著的进步，能够生成高质量的视频。然而，现有的模型通常只能生成短剪辑，这些剪辑通常是离线生成的。这限制了它们在交互式和实时应用中的使用场景。
### Innovation
本文提出了StreamDiT，一种流式视频生成模型。训练StreamDiT的方法基于流匹配，并通过添加移动缓存来实现。设计了不同的缓存帧分区方案以混合训练，这有助于提高内容一致性和视觉质量。StreamDiT模型基于adaLN DiT，具有可变时间嵌入和窗口注意力。此外，提出了适用于StreamDiT的多步蒸馏方法，并在每个选定分区方案的每个段进行采样蒸馏，使得最终模型在一台GPU上以16 FPS达到实时性能，可生成512p分辨率的视频流。
### Conclusion
我们通过定量指标和人工评价评估了我们的方法。我们的模型能够支持实时应用，如流式生成、交互式生成和视频到视频。更多实验证据和范例可以在我们的项目网站上找到。
## 272. `cs.AI` - 理想的磁流体力学平衡的人工神经网络求解器 [PDF](https://arxiv.org/pdf/2507.03119), [HTML](https://arxiv.org/abs/2507.03119)
### Authors
Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff
### Background
论文背景介绍了计算三维磁流体力学（MHD）平衡的传统方法，并指出这些方法通常依赖于数值求解器来实现。这涉及到在实空间中最小化全非线性全局力残差，其中涉及到的计算成本高昂且复杂度高。因此，研究者们探索了使用人工神经网络来参数化傅里叶模以更高效地求解MHD平衡的可能性。他们比较了神经网络方法与传统求解器在计算等价力残差方面的能力，并讨论了神经网络在求解MHD平衡中的潜力和优势。
### Innovation
该研究提出了一种利用人工神经网络参数化傅里叶模的新方法来计算三维MHD平衡，与传统的数值求解器相比，这种方法在计算成本上具有竞争力，并可能通过增加计算成本进一步降低力残差的最小值。研究显示，即使是较简单的神经网络模型也能显著改进单个MHD平衡的求解，并初步验证了神经网络模型在广泛分布的MHD平衡中的可行性与有效性。
### Conclusion
通过使用人工神经网络，该研究成功地降低了计算三维MHD平衡的力残差的最小值，并确立了新的下限。虽然采用了简单的神经网络模型，但仍展示了其在不仅解决单个MHD平衡，而且为连续分布的MHD平衡计算模型方面的潜力。
## 273. `cs.AI` - BMMR: 大规模双语跨模态跨学科推理数据集 [PDF](https://arxiv.org/pdf/2507.03483), [HTML](https://arxiv.org/abs/2507.03483)
### Authors
Zhiheng Xi,Guanyu Li,Yutao Fan,Honglin Guo,Yufang Liu,Xiaoran Fan,Jiaqi Liu,Jingchao Ding,Wangmeng Zuo,Zhenfei Yin,Lei Bai,Tao Ji,Tao Gui,Qi Zhang,Philip Torr,Xuanjing Huang
### Background
当前研究集中在开发和评估大规模跨模态模型（LMMs），但缺乏大规模的双语多模态多学科推理数据集来全面评估这些模型的跨学科推理能力，特别是在中文和英文中的表现。BMMR旨在填补这一空白，提供了一个大规模的数据集，涵盖了不同学科和多样的问题格式，有助于开发者和研究者更好地了解和改进LMMs的表现和潜力。
### Innovation
BMMR数据集的独特之处在于其规模和多样性，它包括11万个大学级别的问题，覆盖了300个联合国教科文组织定义的学科，这些问题以多种格式出现（如选择题、填空题和开放性问题），数据来源广泛，包括书籍、考试和测验等印刷和数字媒体材料。此外，BMMR还提出了一种基于过程的多学科验证器（BMMR-Verifier），用于更精确和细致的推理路径评估。实验结果揭示了SOTA模型在BMMR上的较大改进空间以及LMMs面临的多学科推理挑战。
### Conclusion
通过BMMR数据集和验证器，研究人员能够更全面地评估LMMs在多学科环境中的推理能力，发现现有的差距和挑战。研究者希望通过公开数据集，促进对未来LMMs的进一步开发和完善，从而提高其在跨学科推理任务中的表现。
## 274. `cs.AI` - 当前这是什么声音？基于视频的音频-视觉定位 [PDF](https://arxiv.org/pdf/2507.04667), [HTML](https://arxiv.org/abs/2507.04667)
### Authors
Hahyeon Choi,Junhoo Lee,Nojun Kwak
### Background
Audio-Visual Localization (AVL) 的现有研究主要集中在图像级别的音频-视觉关联上，未能捕捉到时间动态。此外，它们假设声音源始终可见且仅涉及单一对象，这种假设限制了对真实场景中声音源的捕捉。
### Innovation
提出 AVATAR，一种基于视频的 AVL 基准，融入了高分辨率的时间信息。AVATAR 引入了四种不同的场景——单一声音、混合声音、多实体和离屏，这有助于更全面地评估 AVL 模型。此外，展示了 TAVLO，这是一种新的基于视频的 AVL 模型，明确地结合了时间信息。
### Conclusion
实验证明，传统方法难以跟踪时间变化，因为它们依赖于全局音频特征和逐帧映射。相比之下，TAVLO 通过利用高分辨率的时间建模实现了稳健且精确的音频-视觉对齐。本研究实证证明了时间动态在 AVL 中的重要性，并为基于视频的音频-视觉定位建立了新的标准。
## 275. `cs.AI` - LoSiA: 通过子网络本地化和优化实现高效高阶微调 [PDF](https://arxiv.org/pdf/2507.04487), [HTML](https://arxiv.org/abs/2507.04487)
### Authors
Xujia Wang,Yunjia Qi,Bin Xu
### Background
现有参数高效微调（PEFT）方法，如LoRA，通过引入低秩分解矩阵显著减少了可训练参数的数量。然而，这些方法在领域特化任务中执行大量矩阵乘法操作，导致计算效率低下和微调性能欠佳。
### Innovation
本文提出了LoSiA（Low-Resources Subnet Integration Adaptation），一种创新的方法，它在训练过程中动态定位和优化关键参数。具体而言，它通过梯度稀疏性分析识别一个子网络，并将其作为可训练目标进行优化。这一设计仅通过更新子网络参数实现有效的高阶适应，减少了额外的矩阵乘法。此外，LoSiA-Pro 是LoSiA 的更快版本，将训练延迟减少了约27%。经过广泛的评估表明，该方法在不同领域的特化任务和常识推理任务中虽然实现了几乎与全微调相当的性能，但训练时间最短。
### Conclusion
LoSiA 方法在保持与全微调相近性能的同时，显著减少了训练时间，并且在连续训练过程中减少了遗忘现象。
## 276. `cs.CL` - TokenShapley: 基于Shapley值的token级上下文归因 [PDF](https://arxiv.org/pdf/2507.05261), [HTML](https://arxiv.org/abs/2507.05261)
### Authors
Yingtai Xiao,Yuqing Zhu,Sirat Samyoun,Wanrong Zhang,Jiachen T. Wang,Jian Du
### Background
大型语言模型（LLMs）在上下文学习方面显示出了强大的能力，但验证其生成响应的正确性仍然是一个挑战。以往的方法主要在句子级别进行归因分析，当用户需要对响应中的特定关键词（如数字、年份或名称）进行精确的归因时，这些方法就显得不够了。
### Innovation
我们提出了一种新型的token级归因方法TokenShapley，它结合了基于Shapley值的数据归因和KNN（最近邻）检索技术，受到了最近KNN增强LLMs进展的启发。TokenShapley通过利用预先计算的数据存储库进行上下文检索，并计算Shapley值来量化token的重要性，提供了一种精细的数据归因方法。实验结果显示，TokenShapley在token级归因上优于最先进的基线方法，准确率提高了11-23%。
### Conclusion
TokenShapley通过结合Shapley值和KNN检索技术，实现了在token级上的精细上下文归因，显著提升了归因的准确性。
## 277. `cs.AI` - WATS：基于小波感知温度缩放校准图神经网络 [PDF](https://arxiv.org/pdf/2506.23782), [HTML](https://arxiv.org/abs/2506.23782)
### Authors
Xiaoyang Li,Linwei Tao,Haohui Lu,Minjing Dong,Junbin Gao,Chang Xu
### Background
图神经网络（GNNs）在关联数据上的预测性能表现出色，但它们的置信度估计往往与实际预测准确性不符，这在安全关键系统部署中是一个严重限制。现有的图感知校准方法试图缓解这一问题，但这些方法主要依赖于粗略的一跳统计信息，如邻居预测置信度或潜在节点嵌入，而忽视了图拓扑中固有的细致结构异质性。
### Innovation
本文提出了基于小波感知温度缩放（Wavelet-Aware Temperature Scaling, WATS）的后校准框架，该框架根据可调谐的热核图小波特征为节点分配特定的温度。WATS利用了图小波的可扩展性和拓扑敏感性来细化置信度估计，无需重新训练模型或访问相邻的logits或预测。
### Conclusion
WATS在七个基准数据集上的广泛评估表明，它在所有比较方法中实现了最低的预期校准误差（ECE），在ECE方面超越了经典和图特定基线高达42.3%，并且平均减少了17.24%的校准波动，尤其是对图特定方法。此外，WATS在计算效率方面表现出色，能够很好地扩展到不同大小和密集度的图上。代码将基于出版物发布。
## 278. `cs.AI` - CTA: 指跨任务对齐以提高测试时训练 [PDF](https://arxiv.org/pdf/2507.05221), [HTML](https://arxiv.org/abs/2507.05221)
### Authors
Samuel Barbeau,Pedram Fekri,David Osowiechi,Ali Bahri,Moslem Yazdanpanah,Masih Aminbeidokhti,Christian Desrosiers
### Background
深度学习模型在各种计算机视觉任务中表现出色，但在面对分布变化（如领域或数据集变化）时，其性能会显著下降。测试时训练（TTT）作为一种有效方法，通过在训练过程中引入辅助的无监督任务，并利用该任务在测试时更新模型，从而增强模型的鲁棒性。然而，现有的TTT方法往往需要特定的模型架构，这限制了它们的广泛应用。这项工作提出了一种名为CTA（跨任务对齐）的新方法，以进一步提高TTT的效果。CTA借鉴多模态对比学习的成功，在监督编码器和自监督编码器之间建立对齐，以减少梯度干扰，保持自监督学习的固有鲁棒性，并在测试时实现更具语义意义的更新。
### Innovation
CTA不依赖于特定的模型架构，而是采用跨任务对齐的方法，借鉴多模态对比学习的成功，将监督编码器与自监督编码器对齐。这种方法通过减少梯度干扰和保持自监督学习的鲁棒性，增强了模型在测试时的性能和泛化能力。
### Conclusion
实验结果表明，CTA在几个基准数据集上比最先进的方法显著提高了鲁棒性和泛化能力。
## 279. `cs.AI` - OpenS2S：推进完全开源端到端的同理心大规模语音语言模型 [PDF](https://arxiv.org/pdf/2507.05177), [HTML](https://arxiv.org/abs/2507.05177)
### Authors
Chen Wang,Tianyu Peng,Wen Yang,Yinan Bai,Guangfu Wang,Jun Lin,Lanpeng Jia,Lingxiang Wu,Jinqiao Wang,Chengqing Zong,Jiajun Zhang
### Background
同理心是人机交流中的关键基础，因为我们需要理解含有多语素线索的言语并生成情感丰富的回应。然而，最强大的同理心LSLM（大规模语音语言模型）日益封闭，研究人员无法获取关键的建筑、数据和开发细节。鉴于进行透明研究的迫切需求，我们介绍了OpenS2S，这是一个全开源、透明且端到端的LSLM，旨在促进同理心的语音互动。
### Innovation
OpenS2S采用了BLSP-Emo语音转文本模型，并使用流式交错解码架构实现低延迟语音生成。通过构建一个自动数据构建管道，它在低成本下生成多样化、高质量的同理心语音对话。该模拟能够利用大型语言模型生成同理心内容，并借助可控的文本转语音系统引入说话者和情感变化，构建了一个具有丰富多态性的大规模训练语料库，减少了人工监督。
### Conclusion
我们全面公开了OpenS2S模型及其配套的数据集、模型权重、预训练和微调代码，以赋能更广泛的科研社区，加速同理心语音系统领域的创新。有关项目可以在this https URL访问。
## 280. `cs.AI` - RAG-R1: 通过多查询并行激励LLMs的搜索和推理能力 [PDF](https://arxiv.org/pdf/2507.02962), [HTML](https://arxiv.org/abs/2507.02962)
### Authors
Zhiwen Tan,Jiaming Huang,Qintong Wu,Hongxuan Zhang,Chenyi Zhuang,Jinjie Gu
### Background
大语言模型展示了在各种任务中的出色能力，但仍然容易生成不准确或过时的回答，这是因为它们的内部知识是静态的。 recent advancements in Retrieval-Augmented Generation (RAG) methods 引入了强化学习（RL）来增强模型的搜索和推理能力，尽管这些方法展示了有希望的结果，但仍存在训练稳定性问题，并且遇到诸如推断时间过长和单查询模式下能力受限的问题。
### Innovation
本研究提出了RAG-R1，这是一种新的训练框架，旨在使大语言模型在推理过程中能够适当地利用内部和外部知识。进一步地，该框架中的生成和检索过程从单查询模式扩展到多查询并行模式，旨在减少推断时间并增强模型的能力。
### Conclusion
我们在七个问答基准上的实验表明，我们的方法在最强的baseline上提高了最高13.2%的性能，并且将推断时间减少了11.1%。
## 281. `cs.AI` - 通过多模态多实例学习从外周血 TCR 拼谱中分类自身免疫性疾病 [PDF](https://arxiv.org/pdf/2507.04981), [HTML](https://arxiv.org/abs/2507.04981)
### Authors
Ruihao Zhang,Fei Ye,Dandan Meng,Yixuan Huang,Maochen,Xiao Liu
### Background
T细胞受体（TCR）拼谱包含重要的免疫特征，对自身免疫疾病的诊断至关重要。然而，由于TCR序列数据稀疏且检测率低，TCR数据在临床应用中的实施受到限制。研究人员开发了一种名为EAMil的多实例深度学习框架，该框架利用TCR测序数据诊断系统性红斑狼疮（SLE）和类风湿性关节炎（RA），具有极高的准确性。该模型通过集成PrimeSeq特征提取和ESMon-hot编码，以及增强门控注意力机制，实现了现有的最佳性能，AUC值分别为SLE：98.95%，RA：97.76%。研究结果证明了EAMil在多种疾病分类中的鲁棒性，以及在通过SLEDAI评分按疾病严重程度对SLE患者分层，并在诊断SLE患者的损伤部位方面的有效性。此外，该模型成功识别了与疾病相关的基因，且与既定的差异分析结果一致度超过90%，并且有效地区分了疾病特异性的TCR基因。该解释性的免疫受体分析框架为自身免疫疾病检测和分类提供了新的视角，并具有广泛的临床应用潜力，特别是在免疫介导的条件下。
### Innovation
1. 开发了EAMil多实例深度学习框架，用于诊断SLE和RA，实现了极高的诊断准确性。2. 集成了PrimeSeq特征提取和ESMon-hot编码，以及增强的门控注意力机制，提升了模型性能。3. 通过SLEDAI评分对SLE患者进行疾病严重程度分层，并诊断SLE患者损伤部位。4. 有效识别疾病相关的基因，且与既定差异分析结果高度一致。5. 提供了可解释的免疫受体分析框架，可用于多种免疫介导疾病的临床应用。
### Conclusion
EAMil多实例深度学习框架能够有效诊断SLE和RA，具有极高的诊断准确性，并能识别与疾病相关的基因。该模型在分类多种疾病方面表现出稳健性，在临床应用中显示出广泛潜力，特别是在自身免疫疾病检测和分类上。
## 282. `cs.CL` - 使用用户行为预测作为评估大规模语言模型泛化能力的通用、稳健、可扩展和低成本策略 [PDF](https://arxiv.org/pdf/2507.05266), [HTML](https://arxiv.org/abs/2507.05266)
### Authors
Sougata Saha,Monojit Choudhury
### Background
测量大规模语言模型（LLMs）的泛化能力具有挑战性，因为数据污染问题的存在。随着模型的扩大和计算成本的降低，在训练阶段保持任务和测试案例的未知将成为几乎不可能的事。我们提出，知识检索和推理任务不适合衡量泛化能力，因为LLMs并未针对特定任务进行训练。相反，我们建议将用户行为预测作为衡量泛化能力的替代方案，这是一个理论上稳健、可扩展并且成本较低的关键因素。我们提出了一种新的框架并测试了其在GPT-4o、GPT-4o-mini和Llama-3.1-8B-Instruct上的效果。结果与预测相符，显示GPT-4o表现优于GPT-4o-mini和Llama，但所有模型都还有很大的改进空间，尤其是Llama。
### Innovation
提出了一种新的框架来利用用户行为预测来评估大规模语言模型的泛化能力。这种方法被证明是理论上的稳健、可扩展且成本较低的，并且在路上测试了多种不同的LLMs模型，展示了其有效性和广泛的适用性。
### Conclusion
GPT-4o在泛化能力方面表现占优，但仍存在改进空间，特别是在Llama方面。
## 283. `cs.AI` - 跨域通用的肖像风格迁移 [PDF](https://arxiv.org/pdf/2507.04243), [HTML](https://arxiv.org/abs/2507.04243)
### Authors
Xinbo Wang,Wenju Xu,Qing Zhang,Wei-Shi Zheng
### Background
肖像风格迁移是将一个输入肖像转换为具有不同风格的输出肖像的技术，同时保持输入肖像的内容信息。传统的风格迁移方法在处理跨域任务时效果不佳，特别是在保留精细标签如发际线、眼睛、睫毛、皮肤、嘴唇以及背景时存在困难。本文旨在提出一种能够在不同领域之间良好泛化的肖像风格转移方法，同时在多个面部特征上实现高质量的语义对齐风格化。
### Innovation
本文提出了一种通过预训练模型和语义适配器建立输入肖像和参考肖像之间的密集语义对应关系的方法。为实现有效的且可控的风格迁移，设计了AdaIN-Wavelet 变换，在保持内容的同时合成了低频和高频信息，还设计了一个风格适配器，提供风格指导。同时，借助从预训练模型和语义适配器获得的拟合语义对齐参考，利用一个结合ControlNet的双重条件扩散模型以产生最终结果。
### Conclusion
本文方法在多种现实应用场景中展示了其优越性，如艺术表达、网络安全、艺术修复、假冒识别等。所提方法的代码和预训练模型开源，为相关领域的研究和应用提供了有力支持。
## 284. `cs.CL` - An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks [PDF](https://arxiv.org/pdf/2507.05271), [HTML](https://arxiv.org/abs/2507.05271)
### Authors
Mohammad Zia Ur Rehman,Aditya Shah,Nagendra Kumar
### Background
社交媒体的全球传播加剧了仇恨内容的扩散，包括隐性性别歧视，而常规检测方法往往忽视了这一点。
### Innovation
提出了一种自适应监督对比学习框架（ASCEND），通过阈值对比学习机制，仅对相似度超过可学习阈值的样本对进行处理，从而在保持语义相似文本的紧密性的同时，区分非相似文本，减少了误检和漏检。此外，通过词级注意力模块增强文本特征，并利用情感、情绪和毒性特征进行分类。这项方法在EXIST2021和MLSC数据集上的评测中显著优于现有方法，提高了多项任务的宏F1评分。
### Conclusion
ASCEND在多种任务中的表现显著优于现有方法，表明其在捕捉隐性性别歧视微弱线索方面的有效性已得到验证。
## 285. `cs.AI` - 从视频到脑电图：将联合嵌入预测架构适应以揭示脑电信号分析中的视觉概念 [PDF](https://arxiv.org/pdf/2507.03633), [HTML](https://arxiv.org/abs/2507.03633)
### Authors
Amirabbas Hojjati,Lu Li,Ibrahim Hameed,Anis Yazidi,Pedro G. Lind,Rabindra Khadka
### Background
脑电信号（EEG）捕获脑部活动，具有高时间分辨率和低空间分辨率的特点，适用于神经诊断、认知监控和脑-机接口等应用。但是，有效的分析受到有限的标记数据、高维性和缺乏可以捕捉时空依赖性的可扩展模型的限制。现有的半监督学习（SSL）方法往往侧重于空间或时间特征，导致表示效果不佳。
### Innovation
本文提出了一种名为EEG-VJEPA的新方法，它是视频联合嵌入预测架构（V-JEPA）在脑电图分类中的新应用。通过将EEG视作类似于视频的序列，EEG-VJEPA利用联合嵌入和自适应掩蔽学习语义上具有意义的时空表示。这是首次使用V-JEPA进行脑电图分类的工作，同时探索了模型学习到的视觉概念。
### Conclusion
在公开的Temple University Hospital（TUH）异常脑电图数据集上的评估表明，EEG-VJEPA的分类准确率优于现有最先进的模型，捕捉了生理上相关的时间和空间信号模式，提供了可解释的嵌入，有助于支持诊断工作流程中的人工智能协作。这项研究将EEG-VJEPA定位为适用于临床环境中的可扩展和可靠的脑电图分析框架。
## 286. `cs.CL` - LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks [PDF](https://arxiv.org/pdf/2507.05346), [HTML](https://arxiv.org/abs/2507.05346)
### Authors
William Fleshman,Benjamin Van Durme
### Background
随着针对特定任务和领域的微调语言模型专家数量的增加，需要有效的选择和组合方法来利用这些模型。现有的方法通常需要额外的训练或数据访问，从而增加了时间和资源的成本。因此，本文旨在提出一种无需额外训练或访问数据的方法，即LoRA-Augmented Generation (LAG)，来高效地过滤、检索和应用专家知识于各个token和层。
### Innovation
LAG方法无需额外的训练或数据访问，能够高效地在token和层级别上过滤、检索和应用专家知识。与现有的无数据方法相比，LAG在各种知识密集型任务中表现出更优的性能。此外，研究还探讨了在有额外数据的情况下LAG的兼容性，证明了LAG可以与检索增强生成等替代方案兼容。
### Conclusion
通过实验证明，LAG在知识密集型语言任务中比现有无数据方法具有更好的性能，展示了其在大规模语言模型中的潜力。进一步的研究可以探讨LAG在更广泛的应用场景中的表现。
## 287. `cs.CL` - 基于最短路径任务的偏见：关于下一标记预测器倾向于系统性低效推理的一个案例研究 [PDF](https://arxiv.org/pdf/2507.05362), [HTML](https://arxiv.org/abs/2507.05362)
### Authors
Riccardo Alberghi,Elizaveta Demyanenko,Luca Biggio,Luca Saglietti
### Background
近年来，自然语言处理的进步强调了改进大型语言模型推理解答能力的两个关键因素：(i) 提供更多的测试时间计算在解决难题时通常会有帮助，但往往会在推理记录中引入冗余；(ii) 在推理系统化和逐步进行的情况下，计算资源最为有效，形成类似人类问题解决的结构化思维链。为单独研究这些因素，作者引入了一个基于分层图中最短路径任务的受控环境。
### Innovation
作者使用解码器型变换器对问题-推理记录-答案三元组进行训练，并通过自定义分词器进行比较。模型在基于优化底向动态规划的推理记录与涉及回溯的较长有效记录之间进行训练。令人惊讶的是，尽管使用了相同的训练标记预算，使用无效记录训练的模型在未见图中的泛化能力更好。这一优势并非仅由于记录长度的区别——任意注入的冗余并不能提高性能甚至可能损害性能。
### Conclusion
经过观察，作者发现泛化性能与模型对下一个标记预测的信心相关，这表明长的、连贯的和局部逐步的推理记录使得训练信号更容易优化。
## 288. `cs.CL` - 控制你分享的内容：评估语言模型对隐私偏好的遵守情况 [PDF](https://arxiv.org/pdf/2507.05391), [HTML](https://arxiv.org/abs/2507.05391)
### Authors
Guillem Ramírez,Alexandra Birch,Ivan Titov
### Background
大型语言模型（LLMs）主要通过商业API被访问，而这种方式通常要求用户将其数据暴露给服务提供商。因此，本文探讨了通过使用隐私配置文件（简单自然语言的指令，说明什么可以透露，什么不可以透露）来让用户能够控制其数据的方法。设计了一个框架，使本地模型可以根据这些指令重写查询，在将查询发往外部模型前仅隐藏用户认为敏感的信息，从而在隐私保护和性能间取得平衡。为了支持这项研究，引入了一个多语言的PEEP数据集，该数据集包含真实用户的查询，标注了敏感内容，并与生成的隐私配置文件配对。实验结果显示，轻量级LLM可以在一定程度上遵循这些指令，但仍面临一致的挑战，突显了需要能够更好地理解并遵守用户定义的隐私偏好的模型的需求。
### Innovation
提出了使用隐私配置文件的方法，设计了一个多语言数据集PEEP，以及一个框架，使本地模型基于用户定义的隐私偏好重写查询，从而在隐私与性能之间取得平衡。
### Conclusion
轻量级LLM在一定程度上可以理解并遵循隐私配置文件，但仍存在问题，需要开发更好地理解并遵守用户定义的隐私偏好的模型。PEEP数据集为研究提供了一个新的数据来源。
## 289. `cs.CL` - Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning [PDF](https://arxiv.org/pdf/2507.05418), [HTML](https://arxiv.org/abs/2507.05418)
### Authors
Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang
### Background
大型语言模型（LLMs）已经在数学、事实问答（QA）和代码生成等领域展示了强大的性能，但在这些任务中的多语言推理能力仍不完善。尤其是对于资源较少的语言（如斯瓦希里语或泰语），LLMs 往往会对提示存在误解或默认使用英语进行推理。这种对高资源语言的隐性偏见会损害事实准确性、可解释性和信任。当前的多语言基准测试仅关注最终答案，忽略了模型是否在目标语言中进行推理。为解决这一问题，本文提出了地理为基础的多语言事实推理基准GeoFact-X，以及一种名为BRIDGE的创新训练方法，该方法在监督微调和测试时强化学习中使用语言一致性奖励来引导推理与输入语言的一致性。此外，还开发了一套自动评估协议，使用LLM作为评判者来评估答案的正确性和推理痕迹的质量及语言一致性，使分析更加细致且具有可扩展性。实验结果显示，BRIDGE显著提升了跨语言推理的准确性，表明具有语言意识的多语言强化学习对于鲁棒的跨语言泛化至关重要。
### Innovation
提出了地理为基础的多语言事实推理基准GeoFact-X，这是一种新的多语言推理数据集，包括五个语言的注释推理痕迹：英语、印地语、日语、斯瓦希里语和泰语；提出了BRIDGE方法，这是一种新的训练方法，通过语言一致性奖励引导监督微调和测试时的强化学习，使推理与输入语言一致；开发了一种自动评估协议，利用LLM作为评判者来评估答案正确性和推理痕迹的质量及语言一致性，提供比表面度量更细致和可扩展的分析工具。
### Conclusion
BRIDGE方法显著提高了多语言推理的准确性，表明具有语言意识的多语言强化学习对于建设鲁棒的跨语言泛化系统至关重要。
## 290. `cs.CL` - 自然语言生成中的泛化脊梁：信息流 [PDF](https://arxiv.org/pdf/2507.05387), [HTML](https://arxiv.org/abs/2507.05387)
### Authors
Ruidi Chang,Chunyuan Deng,Hanjie Chen
### Background
基于变换器的语言模型在自然语言生成任务中取得了最先进的性能，但它们合成与任务相关的内部机制仍然不够清楚。尽管以往研究表明中间层通常比最终层产生更普适的表示，但这种普适能力是如何在训练过程中出现并传播到各层的仍然不清楚。
### Innovation
提出了一个信息论框架——InfoRidge，用于表征隐藏表示与目标输出之间预测互信息如何随深度变化。通过估计这个数量，可以追踪模型在训练过程中与任务相关的信息流动。实验结果揭示了一种持续的非单调趋势：预测信息在上中层达到峰值，之后在最终层下降，反映了泛化与记忆之间的过渡。
### Conclusion
这些发现为变换器内部机制提供了新的见解，并突出了中间层在支持泛化方面的作用。其中，通过引入残差缩放系数，可以作为功能探针来评估个体变换器层的相对重要性，进一步强调了中间层在泛化过程中的关键作用。
## 291. `cs.CL` - 生殖权利在线讨论中的性别分化 [PDF](https://arxiv.org/pdf/2507.05443), [HTML](https://arxiv.org/abs/2507.05443)
### Authors
Ashwin Rao,Sze Yuh Nina Wang,Kristina Lerman
### Background
美国最高法院2022年在Dobbs v. Jackson Women’s Health Organization一案中的裁决标志着国家关于生育权利辩论的转折点。尽管人们对堕胎的意识形态分歧已有充分记录，但关于性别和当地社会政治环境如何共同作用以影响公共话语的了解则相对较少。本文通过对X平台（前身为Twitter）上几乎1000万条与堕胎相关的帖子的研究，探讨了性别在堕胎态度和情感表达中的影响，尤其是在保守地区。法院裁决的草案泄露进一步加剧了在线参与度，特别是在堕胎服务受限的地区，更激发出支持堕胎女性的动员。
### Innovation
本文通过分析大量带有推断性别、意识形态和地理位置标签的与堕胎相关的X（推特）帖子，发现了性别在堕胎态度中的显著影响，尤其是在保守地区，这独立于意识形态的影响作用。研究表明，生殖权利的讨论不仅在意识形态上分化，还受到性别和地理位置的深刻影响，强调了身份在制度性中断时期的政治表达中的核心作用。
### Conclusion
堕胎的讨论不仅仅是意识形态上的分化，而且还深刻地由性别和地点结构化，凸显了在制度性中断时刻身份在政治表达中的核心角色。在线活动的激增进一步证明了支持堕胎女性的动员对讨论的强烈影响，在堕胎服务受限的地区这种影响更为明显。
## 292. `cs.CL` - 大型语言模型的语义 [PDF](https://arxiv.org/pdf/2507.05448), [HTML](https://arxiv.org/abs/2507.05448)
### Authors
Martin Schuele
### Background
大型语言模型（LLMs）如ChatGPT展示了通过技术复制人类语言能力的潜力，涵盖了从文本生成到参与对话等多个方面。然而，这些系统是否真正理解语言仍存在争议。本文聚焦于LLMs在词汇和句子层面的语义，通过研究LLMs的内部工作机制及其对语言的生成表示，并借鉴弗雷格和罗素的经典语义理论，以更深入地探讨LLMs的潜在语义能力。
### Innovation
通过将研究问题集中在LLMs在词汇和句子层面的语义，并结合LLMs的内部工作机制和经典语义理论，提供了更细化地理解大型语言模型语义能力的方法。
### Conclusion
通过对LLMs语义能力的研究，本文提供了对LLMs潜在的语义能力更细致的理解。
## 293. `cs.CL` - EduCoder: 一种针对教育转录数据的开源注释系统 [PDF](https://arxiv.org/pdf/2507.05385), [HTML](https://arxiv.org/abs/2507.05385)
### Authors
Guanzhong Pan,Mei Tan,Hyunji Nam,Lucía Langlois,James Malamut,Liliana Deonizio,Dorottya Demszky
### Background
虽然现有很多通用的自然语言处理（NLP）和定性研究中的文本注释工具，但对于教育对话转录数据的标注工作仍存在诸多挑战。这些挑战包括定义复杂的教学特征编码本，支持开放性和分类性编码类型，以及将外部信息（如课程目的和教学价值）关联到每个片段上。
### Innovation
EduCoder 是一种专为教育领域设计的工具，它能够支持对教育对话进行单元层次的标注。EduCoder 提供了一个协作平台，供研究人员和领域专家基于观察数据定义复杂的编码本，并集成了分类和开放性注释类型，同时还提供多标注人员间的一对一比较工具，用于改进数据可靠性。此外，EduCoder 是开源的，并附有演示视频。
### Conclusion
EduCoder 的出现旨在解决教育对话记录中注释复杂性的问题，并通过整合多种注释类型和提供多方勠力图新的评论工具，提高了数据的可靠性和准确性。
## 294. `cs.CL` - MindFlow: 通过多模态大语言模型代理革新电子商务客服 [PDF](https://arxiv.org/pdf/2507.05330), [HTML](https://arxiv.org/abs/2507.05330)
### Authors
Ming Gong,Xucheng Huang,Chenghan Yang,Xianhan Peng,Haoxin Wang,Yang Liu,Ling Jiang
### Background
近年来，大型语言模型（LLMs）的发展使得其在电子商务客户服务方面有了新的应用，但其能力在复杂、多模态场景中仍受到限制。
### Innovation
MindFlow 是第一个为电子商务量身定制的多模态 LLM 代理，基于 CoALA 框架，集成了记忆、决策和执行模块，并采用模块化“多模态 LLM 作为工具”的策略进行效果的视觉-文本推理。
### Conclusion
MindFlow 在处理复杂查询、提高用户满意度和减少运营成本方面表现出显著优势，实际部署中观察到的相对改进率为 93.53%。
## 295. `cs.CL` - ModelCitizens:在在线安全中代表社区声音 [PDF](https://arxiv.org/pdf/2507.05455), [HTML](https://arxiv.org/abs/2507.05455)
### Authors
Ashima Suvarna,Christina Chance,Hamid Palangi,Sophie Hao,Thomas Hartvigsen,Saadia Gabriel
### Background
自动检测有毒语言对于创建安全、包容的在线空间至关重要，但却是一个高度主观的任务，其标准受社区规范和生活经验的影响。现有的有毒语言检测模型通常使用合并不同注释者观点的单一标注数据进行训练，忽视了如重新占有语言等重要语境特定的有毒语言概念。为了应对这一挑战，作者引入了MODELCITIZENS数据集，包含6800条社交媒体帖子及4万条多样身份组别的有毒语言标注。通过加入LLM生成的对话场景来捕捉社交媒体帖子特有的对话上下文对毒性的影响。
### Innovation
作者开发了MODELCITIZENS数据集，包括社交媒体帖子及其多样身份组别的标注，涵盖了6800条帖子及4万个标注，同时通过LLM生成对话场景来增加上下文信息，使得最先进的有毒语言检测工具（如OpenAI Moderation API）在MODELCITIZENS上表现不佳，并在语境增强的帖子上进一步下降。作者还发布了基于LLaMA和Gemma的LLAMACITIZEN-8B和GEMMACITIZEN-12B模型，其在内部评估中比GPT-o4-mini高出5.5%。研究结果强调了针对包容性内容过滤的社区导向标注和建模的重要性
### Conclusion
我们的研究结果强调了社区导向的标注和建模对于包容性内容管理的重要性。
## 296. `cs.CL` - 翻转知识蒸馏：利用小模型的专业知识来增强LLM在文本匹配中的表现 [PDF](https://arxiv.org/pdf/2507.05617), [HTML](https://arxiv.org/abs/2507.05617)
### Authors
Mingzhe Li,Jing Xiang,Qishen Zhang,Kaiyang Wan,Xiuying Chen
### Background
知识蒸馏通常涉及将大型语言模型（LLM）的知识转移到较小的语言模型（SLM）上。然而，在某些任务，如文本匹配中，经过微调的小型模型常能生成更有效的领域特定表示，因为它们更专注于优化输入配对之间的相似度。本研究通过引入一种全新的知识蒸馏范式，让LLM从SLM中学习，从而融合小模型的专业化优势和LLM丰富的语义理解。
### Innovation
提出了翻转知识蒸馏范式，通过LoRA重新解释LLM的方式，利用了它们的编码-解码架构。在训练过程中，编码器生成压缩表示，解码器将其映射到输出空间。此外，引入了Margin-aware Contrastive Learning（MCL）方法，以确保正面和负面样本对的准确相似度。此方法要求SLM只需具备基本良好的性能，从而提升LLM的表现。
### Conclusion
实验结果证实了该方法在金融和医疗等基准数据集及真实应用中的有效性。该模型已经完全部署于线上环境中。
## 297. `cs.CL` - LCDS: 一种支持源属性和专家评审的逻辑控制出院总结生成系统 [PDF](https://arxiv.org/pdf/2507.05319), [HTML](https://arxiv.org/abs/2507.05319)
### Authors
Cheng Yuan,Xinkai Rui,Yongqi Fan,Yawei Fan,Boyang Zhong,Jiacheng Wang,Weiyan Zhang,Tong Ruan
### Background
尽管大型语言模型（LLMs）在自动出院总结生成方面表现出色，但仍面临幻觉问题，比如生成不准确的内容或捏造未经实证的信息。此外，电子医疗记录（EMRs）通常包含长篇数据，这使得LLMs难以将生成的内容与原始来源相关联。
### Innovation
提出了LCDS，一种逻辑控制的出院总结生成系统。LCDS通过计算EMRs与出院总结之间的文本相似性来构建来源映射表，以此限制总结内容的范围。此外，LCDS整合了一套全面的逻辑规则，使其能够生成更可靠且适用于不同临床领域的出院总结。LCDS还支持对生成内容的源属性进行标注，使专家能够高效地审查、提供反馈并纠正错误。
### Conclusion
生成的优质出院总结随后被记录下来，用于LLMs的增量微调。
## 298. `cs.CL` - Smoothie-Qwen: Post-Hoc Smoothing to Reduce Language Bias in Multilingual LLMs [PDF](https://arxiv.org/pdf/2507.05686), [HTML](https://arxiv.org/abs/2507.05686)
### Authors
SeungWon Ji,Jungyup Lee,Jemin Kim,Sang Park,SeungJae Lee
### Background
多语言大型语言模型（LLMs）经常表现出语言混淆现象，即在生成响应时倾向于使用母语，而不管提示的语言是什么。这影响了模型的多语言任务表现。
### Innovation
提出了一种轻量级的后处理方法Smoothie-Qwen，该方法不需要重新训练即可减少语言偏见。该技术有针对性地调整输出概率，以有效抑制意外语言生成。在Qwen模型上应用该方法，显著减少了意外中文输出，同时保持了多语言基准上的任务准确性。
### Conclusion
这项工作提供了一种实用且高效的解决方案，以增强LLMs的语言可控性，使其更适合全球应用。
## 299. `cs.CL` - PhoniTale: 依据音韵学生成跨语际语言对的词典记忆辅助工具 [PDF](https://arxiv.org/pdf/2507.05444), [HTML](https://arxiv.org/abs/2507.05444)
### Authors
Sana Kang,Myeongseok Gwon,Su Young Kwon,Jaewook Lee,Andrew Lan,Bhiksha Raj,Rita Singh
### Background
第二语言学习者尤其是学习类型差异大的语言（如英语和韩语）时，词汇获取是一项巨大挑战。研究发现，大语言模型（LLMs）可以通过利用学习者母语中相似词汇生成关键词记忆技巧，以辅助词汇学习。然而，大多数研究集中于母语为英语的学习者学习其他语言，鲜少涉及相反方向的学习。
### Innovation
本文介绍了一种新颖的跨语际记忆辅助工具PhoniTale，它根据音韵相似性检索母语关键词序列，并利用LLMs生成记忆技巧。该工具通过自动评估指标和人工评估进行测试，其输出结果与人类和先前自动方法生成的记忆技巧进行了对比，并通过短期回忆测试评估其实际效果。
### Conclusion
研究发现，PhoniTale的表现与人工编写的记忆技巧相当，同时也指出了记忆质量及方法上需要改进的关键领域。
## 300. `cs.CL` - Agentic-R1：提炼出的双策略推理 [PDF](https://arxiv.org/pdf/2507.05707), [HTML](https://arxiv.org/abs/2507.05707)
### Authors
Weihua Du,Pranjal Aggarwal,Sean Welleck,Yiming Yang
### Background
当前的长推理（long-CoT）模型在数学推理方面表现出色，但依赖于缓慢且出错可能性大的自然语言痕迹。工具增强的代理通过代码执行解决算术问题，但在复杂的逻辑任务上表现不佳。本文提出了一个细调框架DualDistill，该框架从多个教师中提炼出互补的推理策略，并将这些策略整合到一个统一的学生模型中。利用这种方法，训练了Agentic-R1，该模型根据每个查询动态选择最佳策略，使用工具解决算术和算法问题，使用文本推理解决抽象问题。该方法提高了不同任务的准确性，包括计算密集型和标准基准，证明了多策略提炼的有效性，以实现稳健和高效的推理。
### Innovation
提出了DualDistill框架，该框架从多个教师中提炼出互补的推理策略，并整合到一个统一的学生模型中。训练了Agentic-R1，该模型能够动态选择最佳策略以解决不同类型的推理问题，提高准确性并证明多策略提炼的有效性。
### Conclusion
该方法在计算密集型和标准基准任务上提高了准确性，展示了多策略提炼框架在实现稳健和高效推理方面的有效性。
## 301. `cs.CL` - 超越经典和现代模型：一种使用RAG、提示工程和跨模态融合的学生辍学预测的transformative AI框架 [PDF](https://arxiv.org/pdf/2507.05285), [HTML](https://arxiv.org/abs/2507.05285)
### Authors
Miloud Mihoubi,Meriem Zerkouk,Belkacem Chikhaoui
### Background
远程学习中的学生辍学依然是一个至关重要的挑战，具有深远的社会和经济影响。虽然传统的机器学习模型能够利用结构化的社会人口统计和行为数据，但它们往往无法捕捉到嵌入在学生非结构化交流中的细腻情感和情境因素。因此，当前的研究引入了一种革命性的AI框架，重新定义了辍学预测，这一框架包含三项协同创新：检索增强生成（RAG）进行领域特定的情感分析、提示工程技术来解码学术压力因素，以及跨模态注意力融合以动态对齐文本、行为和社会人口统计的洞察。
### Innovation
这项研究引入了三项创新：1. 使用检索增强生成（RAG）进行领域特定的情感分析；2. 提示工程技术以解码学术压力因素；3. 跨模态注意力融合以动态对齐文本、行为和社会人口统计的洞察。通过嵌入教学内容的知识库，我们的RAG增强BERT模型能够以前所未有的上下文相关性解释学生的评论；优化提示从中隔离出学术困境的指标（如“孤立”、“工作量焦虑”）。跨模态注意力层随后将这些洞察与时间参与模式融合，生成全面的风险概况。与传统的模型相比，该框架在4423名学生的一份横截面数据集上实现了89%的准确率和0.88的F1分数，优于传统模型7%且降低了21%的假阴性率。
### Conclusion
这项工作连接了预测分析和可操作的教学之间的桥梁，提供了一个可扩展的解决方案，用于缓解全球教育系统中辍学的风险。
## 302. `cs.CL` - ECom-Bench: LLM代理能否解决实际电商客服问题？ [PDF](https://arxiv.org/pdf/2507.05639), [HTML](https://arxiv.org/abs/2507.05639)
### Authors
Haoxin Wang,Xianhan Peng,Xucheng Huang,Yizhe Huang,Ming Gong,Chenghan Yang,Yang Liu,Ling Jiang
### Background
本文介绍了ECom-Bench，这是首个用于评估具有多模态能力的LLM（大规模语言模型）代理在电商客服领域的基准框架。ECom-Bench结合了基于真实电商客户互动收集的人格信息动态用户模拟和源于真实电商对话的实际任务数据集。这样的任务覆盖了多种商业场景，能够反映现实世界的复杂性，使其极具挑战性。例如，即使是像GPT-4o这样先进的模型，也只能在基准测试中获得10-20%的pass^3指标，突显了复杂电商场景带来的巨大困难。
### Innovation
ECom-Bench为评估LLM代理在电商客服领域的表现提供了一个全新的基准框架。该框架结合了基于真实数据的人格信息动态用户模拟和实际任务数据集，同时涵盖了广泛的实际商业场景，使得评估更加贴近真实业务条件。这不仅提高了评估的准确性，还促进了该领域进一步的研究和发展。
### Conclusion
ECom-Bench是一个极具挑战性的基准框架，用来评估具有多模态能力的LLM代理在电商客服中的表现。即便像GPT-4o这样的高阶模型，其表现也相当有限。未来的研究者和开发者可以通过使用开源代码和数据集进行进一步的研究和开发，从而改进LLM代理在实际电商支持场景中的表现。
## 303. `cs.CL` - 以语言模型赋能医疗从业者：两种真实临床应用场景中的语音转录结构化 [PDF](https://arxiv.org/pdf/2507.05517), [HTML](https://arxiv.org/abs/2507.05517)
### Authors
Jean-Philippe Corbeil,Asma Ben Abacha,George Michalopoulos,Phillip Swazinna,Miguel Del-Agua,Jerome Tremblay,Akila Jeeson Daniel,Cari Bader,Kevin Cho,Pooja Krishnan,Nathan Bodenstab,Thomas Lin,Wenxuan Teng,Francois Beaulieu,Paul Vozila
### Background
大型语言模型（LLMs）如GPT-4o和o1在多项医学基准测试中展示了强大的临床自然语言处理（NLP）任务表现。然而，由于数据稀缺和敏感性，两大高影响NLP任务——护士口述的结构化表格报告和医生患者会诊中的医学订单提取仍然被忽视。尽管行业积极努力，这些任务依然未得到充分探索。改善这些实际临床任务能大大减轻医务人员的记录负担，使他们能更多关注患者护理。
### Innovation
本文通过使用私有和开源临床数据集，评估开放权重和闭合权重LLM在两种复杂任务上的性能，并分析各自的优缺点。此外，本文提出了一种生成真实非敏感护士口述的代理管道，使临床观察的结构化提取成为可能。为支持未来研究，本文还发布了SYNUR和SIMORD，这是首个用于护士观察提取和医疗订单提取的开源数据集。
### Conclusion
通过这些努力，开发出的代理管道和新数据集，促进了NLP在医疗保健实践中的应用，为减轻医务人员的记录负担提供了实际解决方案。
## 304. `cs.CL` - Omni-Router：Sparse Mixture-of-Experts中的共享路由决策在语音识别中的应用 [PDF](https://arxiv.org/pdf/2507.05724), [HTML](https://arxiv.org/abs/2507.05724)
### Authors
Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly
### Background
混合专家（MoE）架构最初用于语言建模，现已扩展到自动语音识别（ASR）。传统MoE方法，如切换变换器，每层独立地路由专家。研究表明，不同层的路由决策之间相关性不强，缺乏层间专家的合作与专业化程度的提升。因此，本文提出了一种解决方案来增加不同层间专家的协作并促进他们更专业的分工，即使用共享路由器跨不同MoE层。研究这样设计的模型被命名为Omni-router变换器。
### Innovation
引入了Omni-router Transformer模型，这种模型使用跨不同MoE层的共享路由器。这意味着路由决策在不同层之间共享，从而增强不同层间专家的协作与专业化程度，相比密集模型和切换变换器模型，它在大规模伪标签数据集上的训练损失更低，平均词错误率分别降低了11.2%和8.2%，同时提供结构化的专家使用和对多样数据的更强鲁棒性。
### Conclusion
通过对10个不同的离域ASR基准的广泛实验，结果显示Omni-router Transformer在训练损失和词错误率方面都表现出优越性，证明了模型的有效性和先进性。
## 305. `cs.CL` - HIRAG: 分层思维指令调优检索增强生成 [PDF](https://arxiv.org/pdf/2507.05714), [HTML](https://arxiv.org/abs/2507.05714)
### Authors
YiHan Jiao,ZheHao Tan,Dan Yang,DuoLin Sun,Jie Feng,Jian Wang,Peng Wei
### Background
检索增强生成（RAG）已成为应对大语言模型在处理实时信息和领域特定问题方面的挑战的基础范式。传统的RAG系统主要依赖于大语言模型本身的上下文学习能力，但缺乏对RAG生成模型所需具体能力的深入研究，导致文档质量不一致和检索系统缺陷的问题。尽管有一些研究对RAG生成模型进行微调，但往往缺乏对RAG任务的细致关注或对思维过程的深入利用。
### Innovation
本文提出了RAG模型应该具备三种逐步分层的能力：(1) 过滤：选择相关信息的能力；(2) 组合：综合段落中语义信息的能力；(3) RAG特定的推理：使用内部知识进一步处理外部知识。为此，提出了一种新的RAG指令微调方法——分层思维指令调优检索增强生成（HIRAG），一种“先思考后作答”的策略。该方法通过多级逐步的思维过程增强了模型的开卷考试能力。实验结果表明，HIRAG训练策略在RGB、PopQA、MuSiQue、HotpotQA和PubMedQA等数据集上显著提高了模型的性能。
### Conclusion
HIRAG方法通过改进RAG模型的能力和采用多级逐步的思维过程，显著提升了模型在多个数据集上的表现。
## 306. `cs.CL` - DRAGON：基于新闻的动态RAG基准 [PDF](https://arxiv.org/pdf/2507.05713), [HTML](https://arxiv.org/abs/2507.05713)
### Authors
Fedor Chernogorskii,Sergei Averkiev,Liliya Kudraleeva,Zaven Martirosian,Maria Tikhonova,Valentin Malykh,Alena Fenogenova
### Background
当前，共有多个针对英语的检索增强生成（RAG）基准，但对于其他语言，特别是俄语，缺乏动态且实时更新的评估资源。因此，现有的评估无法准确反映RAG系统在实际部署中的动态变化情况。本研究旨在填补这一空白，提出DRAGON，一个用于评估俄语RAG系统的动态基准，该系统基于经常更新的俄语新闻和公开文件数据集。DRAGON不仅支持检索器和生成器组件的全面评估，还通过构建知识图谱自动生成问题，提取四种核心问题类型，从而评判系统的事实准确性。
### Innovation
本研究提出的DRAGON是第一个用于评估俄语RAG系统的动态基准。它基于不断更新的数据集构建，能够支持检索器和生成器的全面评估。通过知识图谱自动生成的问题集，DRAGON能够识别并评估不同子图模式下的核心问题类型，这一方法不仅创新地适应了俄语动态评估的需求，还为其他语言和多语言环境提供了潜在可重用的评估框架和数据集。此外还发布了完整的评估框架，包括自动问题生成管道、评估脚本等，以鼓励社区参与和比较。
### Conclusion
DRAGON作为第一个动态RAG基准，填补了俄语RAG系统评估领域的空白，提供了实时更新的数据集和全面的评估框架。通过知识图谱驱动的问题生成，DRAGON能够更准确地评估RAG系统的性能。未来的研究可以将其扩展到更多语言和应用场景。
## 307. `cs.CL` - GPTKB v1.5: 一个探索事实语言模型知识的巨大知识库 [PDF](https://arxiv.org/pdf/2507.05740), [HTML](https://arxiv.org/abs/2507.05740)
### Authors
Yujia Hu,Tuan-Phong Nguyen,Shrestha Ghosh,Moritz Müller,Simon Razniewski
### Background
尽管语言模型非常强大，但其事实知识仍然了解不足，而且难以进行即兴浏览和可扩展的统计分析。现有知识库通常无法有效集成语言模型的认知内容，导致了研究上的局限性。因此，需要开发一种新方法，有效构建和利用语言模型的大量知识。
### Innovation
介绍了一种名为 GPTKB v1.5 的方法，这是一种使用 GPT-4.1 从 100 万个三元组构建的巨大互联知识库。该知识库通过 GPTKB 方法学进行大规模递归构建。使用这种新方法，可以从语言模型中高效提取和组织大量的知识。此外，该方法还支持通过链接遍历进行 LLM 知识探索，支持 SPARQL 的结构化查询，以及对 LLM 知识进行比较性探索。
### Conclusion
大规模递归语言模型知识材料化是一个开创性的机会，既推动了语言模型知识系统分析的研究领域，也促进了自动化知识库构建的发展。GPTKB 能够在 $14,000 的预算下构建出一个紧密连接的知识库，提供了一种新的方法来探索和研究语言模型的知识内容。
## 308. `cs.CL` - DocTalk: 基于可扩展图结构对话合成，增强LLM对话能力 [PDF](https://arxiv.org/pdf/2507.05750), [HTML](https://arxiv.org/abs/2507.05750)
### Authors
Jing Yang Lee,Hamed Bonab,Nasser Zalmout,Ming Zeng,Sanket Lokegaonkar,Colin Lockard,Binxuan Huang,Ritesh Sarkhel,Haodong Wang
### Background
大型语言模型（LLMs）在多轮对话任务中的应用越来越广泛，然而它们的预训练数据主要是连续的散文形式，这可能会导致所需的对话能力与训练范式之间的不匹配。我们提出了一种新的方法，通过从现有文本语料库中合成对话数据来解决这一问题。将我们的方法应用于维基百科文章，我们构建了DocTalk，这是一个包含超过73万条多轮对话的预训练对话语料库。
### Innovation
我们提出了一种新的方法，通过从现有文本语料库中合成对话数据来解决LLMs在多轮对话任务中的能力与训练范式之间的不匹配问题。我们将多个相关文档转换为扩展的多轮、多主题的信息检索对话。我们还展示了DocTalk在预训练中的应用，可以提高LLMs的上下文记忆和理解能力，同时不损害基础性能。
### Conclusion
我们的研究表明，在预训练期间引入DocTalk可以提高LLMs的上下文记忆和理解能力高达40%，而不会损害基础性能。DocTalk可用于此链接：this https URL.
## 309. `cs.CL` - Flippi: End To End GenAI Assistant for E-Commerce [PDF](https://arxiv.org/pdf/2507.05788), [HTML](https://arxiv.org/abs/2507.05788)
### Authors
Anand A. Rajasekar,Praveen Tangarajan,Anjali Nainani,Amogh Batwal,Vinay Rao Dandin,Anusua Trivedi,Ozan Ersoy
### Background
对话助手的出现从根本上重塑了用户与数字平台的交互方式。随着电子商务的快速发展，用户在面对大量且复杂的商品选择时，需要更高效的交互方式来获取信息。传统的搜索引擎难以满足用户多样化和个性化的需求，尤其是当涉及到主观和客观用户需求时。因此，本研究探讨了一种名为Flippi的端到端对话助手，它利用大型语言模型（LLMs），专注于电子商务领域，以自然语言对话的形式帮助用户更高效地发现商品。
### Innovation
Flippi通过利用先进的自然语言处理（NLP）技术，包括查询重写、意图检测、检索增强生成（RAG）、命名实体识别（NER）和上下文减少，能够精准解读用户查询并提供个性化的产品信息。此外，该助理还具备突出显示电子商务网站上最具吸引力的促销活动的能力，从而促使用户作出成本效益更高的决策。Flippi还提供对比分析特性，允许用户通过比较产品特性、价格及其他相关属性来做出明智的选择。该系统的架构强调了其在各种电子商务平台中广泛应用的可能性。
### Conclusion
Flippi不仅提升了用户在电子商务中的购物体验，还通过对比分析特性和用户体验提供了成本效益更高的决策支持，从而优化了客户参与度和转化率。通过结合线上购物的便利性和实体店铺提供的个性化辅助，Flippi为数字市场中的客户服务设立了新的标准，提升了客户满意度和互动水平。
## 310. `cs.CL` - Lost-in-the-Later：评估大型语言模型上下文关联性的框架 [PDF](https://arxiv.org/pdf/2507.05424), [HTML](https://arxiv.org/abs/2507.05424)
### Authors
Yufei Tao,Adam Hiatt,Rahul Seetharaman,Ameeta Agrawal
### Background
大型语言模型能够利用上下文知识和参数知识，但它们如何优先选择和整合这些知识来源仍然被广泛忽视。本文介绍了一个名为CoPE的新颖评估框架，该框架系统地衡量了模型和不同语言中的上下文知识（CK）和参数知识（PK）。利用多维维基原子数据集（包含英语、西班牙语和丹麦语），我们分析了大型语言模型在开放式问答中如何整合上下文、优先信息以及融入参数知识。我们的分析揭示出一种称为“落后于最后”的现象，即LLMs倾向于忽略或优先于后者的信息，在给定上下文中表现出强烈的位置偏好，影响了上下文的关联性。
### Innovation
本文提出了一种名为CoPE的新颖评估框架，用于系统地衡量大型语言模型中的上下文知识和参数知识。首次详细分析了大型语言模型在开放式问答任务中如何整合上下文、优先信息以及融入参数知识，特别是在“落后于最后”现象中的表现。
### Conclusion
根据我们的研究发现，设计基于提示的方法以有效利用输入上下文，可以改善事实关联并减少幻觉。特别地，带有链式思维（CoT）提示的推理模型甚至比不带有链式思维提示的非推理模型对上下文的利用更少，并且无法缓解“落后于最后”现象带来的负面效果。
## 311. `cs.CL` - 增强大型语言模型遵循指令能力的自我评估框架 [PDF](https://arxiv.org/pdf/2507.05598), [HTML](https://arxiv.org/abs/2507.05598)
### Authors
Sihyun Park
### Background
已经提出了多种技术来提高大型语言模型（LLMs）对格式和指令约束的遵循性。其中一种最有效的方法是利用由强大模型生成的高质量数据。然而，这些模型往往无法在单次生成中完全遵守复杂指令。为此，引入了迭代复习方法。尽管这可以改进模型的表现，但随着数据点和修订迭代次数的增加，相关成本也会显著增加。作为资源高效的替代方案，有人提议利用高性能评估工具来弥补开源LLMs有限的自我评估能力。然而，这些方法往往会由于过度修订而导致输出质量下降。为了克服这些挑战，该论文提出了Re5，一种自我评估和修订框架，旨在增强指令遵循性能的同时保持生成内容的质量。
### Innovation
Re5通过从用户指令中提取任务和约束成分，执行结构评估以防止错误累积，并应用细粒度的特定约束内容评估，随后进行选择性修订，以确保精确且保证质量的改进。最终高质量输出用于对齐调优，通过数据为中心的迭代改进循环实现长期对齐改进。实验结果表明，即使使用少量数据，Re5的指令遵循性能可与GPT-4o-mini生成的数据训练的模型相媲美，并在保留响应质量的情况下，64.24%的胜率超过非修订的初始响应。
### Conclusion
实验结果验证了Re5作为提高指令遵从性的高效且有效的解决方案，只需最少外部监督即可提升指令遵从性。
## 312. `cs.CL` - 使用特质-反应中介的虚拟受访人员进行心理测量项目验证 [PDF](https://arxiv.org/pdf/2507.05890), [HTML](https://arxiv.org/abs/2507.05890)
### Authors
Sungjib Lim,Woojung Song,Eun-Ju Lee,Yohan Jo
### Background
随着心理测量问卷越来越多地用于评估大型语言模型（LLMs）的特质，生成适合LLMs的可扩展问卷项目的需求也在增长。一个关键挑战是确保生成项目的有效建构效度，即它们是否确实衡量了预期的特质。传统的方法需要成本高昂的大规模人类数据收集。为了使其更高效，我们提出了一种使用LLMs进行虚拟受访人员模拟的框架。关键思路是考虑中介因素：这些因素通过相同的特质可能导致对问卷项目的不同反应。通过对具有多样中介的受访人员进行模拟，我们识别出能够稳健测量预期特质的问卷项目。实验验证了我们的中介生成方法和模拟框架能有效识别出高效度的项目。LLMs展示了从特质定义中生成可信赖中介并模拟受访人员行为以验证项目的能力。我们的研究为低成本问卷开发和深入理解LLMs如何复制人类行为方向确定了新途径。我们将公开发布我们的数据集和代码以支持未来研究。
### Innovation
提出了一种使用LLMs进行虚拟受访人员模拟的框架，通过考虑中介因素来确保生成问卷项目的有效性。这种方式能够高效地生成可信赖的中介并模拟受访人员行为，有助于低成本的问卷项目开发和验证。
### Conclusion
我们提出的方法在三个心理特质理论（大五人格、施瓦兹模型、优势品质模型）中验证了其有效性。LLMs能够生成可靠的中介并模拟受访人员的行为。我们的研究为您使用虚拟受访人员和考虑中介因素进行心理测量项目验证提供了新的可能性。我们将在未来研究中提供我们的数据集和代码以支持进一步的工作。
## 313. `cs.CL` - 如何评估自动语音识别: 不同性能和偏倚指标的比较 [PDF](https://arxiv.org/pdf/2507.05885), [HTML](https://arxiv.org/abs/2507.05885)
### Authors
Tanvina Patel,Wiebke Hutiri,Aaron Yi Ding,Odette Scharenborg
### Background
自动语音识别（ASR）系统在不同说话人以及不同的说话人群体中表现出偏倚，这一现象越来越多地受到关注，尤其是基于性别、年龄或口音等因素的偏倚。目前对于这种偏倚的研究主要集中在检测和量化偏倚，并开发相应的缓解方法上。尽管取得了这些进展，但在如何衡量系统性能和偏倚方面仍存在开放性的问题，即如何有效测量和评估系统的性能和偏倚。目前研究中，平均错误率作为ASR研究的标准指标，但单独使用这一指标是不够的，需要与其他指标结合，以更全面地评价系统的性能和偏倚，更好的代表不同说话人群体的系统性能和整体偏倚水平。
### Innovation
该研究对比了不同的性能和偏倚度量指标，以评估荷兰语的最新端到端ASR系统。研究通过应用多种偏倚缓解策略来应对各类说话人群体的偏倚问题。研究发现，平均错误率作为ASR研究的标准指标已不足以全面评价系统性能和偏倚，需要引入其他指标辅助衡量。这一研究提出关于如何更准确地报告ASR性能和偏倚，以便更好地反映系统的多样性和整体偏倚水平的新建议。
### Conclusion
本文实验比较了不同的性能和偏倚度量指标，结果显示平均错误率已不足以全面评价ASR系统的整体性能和偏倚问题，应当结合其他类型度量指标进行综合评估。并提出了在报告ASR性能和偏倚时应遵循的新建议，使其更能代表不同说话人群体的系统性能及整体偏倚水平。
## 314. `cs.CL` - 零样本文本情绪检测 [PDF](https://arxiv.org/pdf/2507.05918), [HTML](https://arxiv.org/abs/2507.05918)
### Authors
Teodor-George Marchitan,Claudiu Creanga,Liviu P. Dinu
### Background
本次研究背景是为了解决基于文本的情绪检测任务中的现有差距，特别是在多标签情绪检测方面。具体而言，SeMEval 2025 Workshop 的任务 11 要求解决文本情绪检测中存在的数据集不平衡和技术挑战问题，特别是对于低资源语言如莫桑比克普卢埃卜瓦语 (Emakhuwa) 的准确性提高。研究团队主要关注使用大型语言模型（如 Gemini、Qwen 和 DeepSeek）进行零样本提示或微调的实验。这些技术的应用为提高检测精度提供了可能。
### Innovation
研究的创新之处在于使用了包括 Gemini、Qwen 和 DeepSeek 在内的多个大型语言模型，并采用了零样本提示或微调的方法。这种方法对于处理不同语言集（如英语、莫桑比克普卢埃卜瓦语和葡萄牙语）的情绪检测任务具有针对性。研究结果显示，这些模型在不同语言集上的表现不一，特别是在资源有限的语言如 Emakhuwa 上，表现出色，取得了最佳结果。
### Conclusion
通过实验，该研究最终系统在多标签情绪检测赛道（轨道 A）中取得了较好的成绩，特别是在 Emakhuwa 集上表现最好，获得 1/31 组的优异成绩。此外，在英语和葡萄牙语（莫桑比克）子集上也分别取得了 0.7546 和 0.1727 的 F1-macro 分数。该研究展示了大型语言模型在零样本情绪检测中的潜力，特别是对于低资源语言的检测。
## 315. `cs.CL` - 朝向知识编辑的原理性评估 [PDF](https://arxiv.org/pdf/2507.05937), [HTML](https://arxiv.org/abs/2507.05937)
### Authors
Sebastian Pohl,Max Ploner,Alan Akbik
### Background
知识编辑在过去几年中引起了越来越多的关注。特别是知识编辑，最近发布了一些更具挑战性的评估数据集。这些数据集利用不同的方法来衡量编辑的成功。然而，这些方法论的稳健性及其是否偏袒某些编辑等问题仍未得到充分探索。此外，这些编辑对整体模型能力的颠覆性影响仍然是一个盲点。
### Innovation
该研究通过展示在选择不同的评估指标和评价方法以及不同的编辑批次大小时，知识编辑的排名会有所不同来应对上述问题。更进一步，该研究还包括了一个手动评估字符串匹配法的测试，这种方法在最近发布的数据集中被偏爱，揭示了一种产生假阳性匹配的趋势。
### Conclusion
该研究证明了在知识编辑任务和通用语言理解任务中，选择不同的评价度量准则和评价方法以及不同的编辑批次大小会导致知识编辑器的排名变化。进一步的字符串匹配法手工评估揭示了偏向产生假阳性匹配的趋势。
## 316. `cs.CL` - SARA：基于上下文压缩的选择性和自适应检索增强生成 [PDF](https://arxiv.org/pdf/2507.05633), [HTML](https://arxiv.org/abs/2507.05633)
### Authors
Yiqiao Jin,Kartik Sharma,Vineeth Rakesh,Yingtong Dou,Menghai Pan,Mahashweta Das,Srijan Kumar
### Background
检索增强生成（RAG）通过将外部知识引入大型语言模型（LLMs）来扩展其功能，但面临着关键挑战：有限的有效上下文字长和检索文档中的冗余信息。纯基于压缩的方法可以减小输入大小，但常常会丢弃对事实准确性至关重要的细粒度细节。
### Innovation
提出了一种统一的RAG框架——SARA，该框架在紧凑的上下文预算下平衡局部精确性和全局知识覆盖。SARA结合自然语言文本片段和语义压缩向量，以增强上下文效率和答案准确性。SARA在两个互补的层次上表示上下文：细粒度的自然语言片段，保留关键实体和数值信息；紧凑的、可解释的向量，总结高层次语义。迭代的证据选择模块利用压缩向量进行动态上下文重新排名。通过9个数据集和5个开源LLMs（覆盖3个模型家族：Mistral、Llama和Gemma）的实验，SARA在答案相关性、正确性和语义相似性方面均取得了显著提升，证明了将文本和压缩表示结合使用对于稳健、上下文高效的RAG的重要性。
### Conclusion
SARA在多个数据集和模型家族上展示了其在RAG框架中通过结合文本和压缩表示以提高答案相关性和正确性的能力，强调了这种策略的重要性，并提出了选择性和自适应的上下文压缩方法。
## 317. `cs.CL` - 利用层次检索增强MCTS改进大型语言模型的测试时扩展 [PDF](https://arxiv.org/pdf/2507.05557), [HTML](https://arxiv.org/abs/2507.05557)
### Authors
Alex ZH Dou,Zhongwei Wan,Dongfei Cui,Xin Wang,Jing Xiong,Haokun Lin,Chaofan Tao,Shen Yan,Mi Zhang
### Background
测试时扩展已成为语言模型的一种有前景的范式，通过在推理时利用额外的计算资源来提升模型性能。当前的研究通常需要从更高级的模型中获取带链式推理（CoT）训练的数据来进行蒸馏，这在实践中并不总是可行。
### Innovation
提出了R2-LLMs，这是一种新颖且多功能的层次检索增强推理框架，旨在提高大型语言模型在测试时的扩展性，而无需从更高级的模型中进行蒸馏以获取CoT训练数据。该框架通过双重层次检索上下文学习来增强推理时的一般化：（1）在粗级层次上，抽取复杂推理问题的抽象模板，并检索相似的问题-答案对，以促进高层次的上下文学习；（2）在细级层次上，在蒙特卡洛树搜索（MCTS）过程中，R2-LLMs高效地从参考数学问题数据集中检索类似的中间解步，并结合过程奖励模型（PRM）评分以细化步步推理。利用PRM，它不仅改进了候选生成，还改进了决策过程，从而提高了推理准确性。
### Conclusion
以MATH500、GSM8K和OlympiadBench-TO数据集为基准进行的实证评估表明，与基线相比，使用LLaMA-3.1-8B可以实现16%的相对改进，这表明该方法在复杂推理任务中具有显著效果。
## 318. `cs.CL` - Chat-Ghosting: 对话系统中自动补全方法的比较研究 [PDF](https://arxiv.org/pdf/2507.05940), [HTML](https://arxiv.org/abs/2507.05940)
### Authors
Sandeep Mishra,Anubhab Mandal,Bishal Santra,Tushar Abhishek,Pawan Goyal,Manish Gupta
### Background
聊天输入自动补全（Ghosting）是一种宝贵的特性，可在现代搜索引擎和聊天界面中增强用户体验。它通过建议未完成查询的补全，帮助慢速打字、有残疾或语言能力有限的用户。聊天输入自动补全是一个具有挑战性的问题，尤其是随着基于聊天系统的普及，例如ChatGPT和Copilot，这一问题的重要性更加凸显。尽管基于聊天的系统更加依赖自动补全，但在自然语言处理/机器学习研究社区中，这类问题（Chat-Ghosting）却受到了较少的关注，缺乏标准化基准和深度学习与非深度学习方法的相关性能分析。本研究通过四项公开可用的对话数据集，对这一问题进行了开放和全面的研究，旨在填补这一空白。
### Innovation
本研究提出了一个基于熵的动态早期停止策略，并对多种现有的查询自动补全方法、n-克隆方法和深度学习方法进行了实验，包括是否使用对话上下文。研究结果发现在已见过的前缀场景下，统计n-克隆模型和Trie树优于基于深度学习的模型；对于未见过的查询，神经网络模型如T5和Phi-2表现更好。使用对话上下文显著提高了聊天输入自动补全的效果，尤其对于Open-Assistant和ShareGPT这类系统。此外，本研究还提供了代码和数据的开源版本。
### Conclusion
本研究对Chat-Ghosting问题进行了开放和系统的探讨，通过对四种公开对话数据集的测试，分析了多种实验方法的结果，揭示了在不同场景下深度学习模型和传统方法的效果差异，突显了对话上下文在提高聊天输入自动补全质上的关键作用。
## 319. `cs.CL` - 记住过去，预见未来：学习持续的多模态错误信息检测器 [PDF](https://arxiv.org/pdf/2507.05939), [HTML](https://arxiv.org/abs/2507.05939)
### Authors
Bing Wang,Ximing Li,Mengzhe Ye,Changchun Li,Bo Fu,Jianfeng Qu,Lin Yuanbo Wu
### Background
在社交媒体平台上广泛传播的误导性文章，尤其是多模态的误导性文章，对社会造成严重的负面影响。为了控制其传播，多模态错误信息检测（MMD）已成为一个活跃的研究主题，旨在自动识别和检测这些误导性内容。然而，由于新的事件不断出现，MMD模型在使用离线数据训练后会变得陈旧和无效。因此，一个新兴任务——持续MMD（Continual MMD），通过在线数据流训练MMD模型成为一个替代方案，但面临两个主要挑战：一是新数据的训练导致过去数据检测性能下降，即遗忘过去知识的问题；二是社会环境随着时间的推移不断演变，影响对未来数据的泛化能力。
### Innovation
本文提出了一种新的持续MMD方法，即DAEDCMD。通过基于狄利克雷过程的混合专家结构隔离事件特定参数之间的干扰来记住过去的知识，通过学习连续时间动力学模型来预见未来的环境分布。实验结果表明，DAEDCMD可以持续且显著地优于包括六个MMD基线和三个持续学习方法在内的所有比较方法。
### Conclusion
本研究提出了一种结合过去知识记忆和未来环境预测的新方法DAEDCMD，通过实验验证了该方法的有效性和优越性，在持续MMD任务中具有显著优势。
## 320. `cs.CL` - DocIE@XLLM25: 使用完全合成示范进行信息抽取的上下文学习 [PDF](https://arxiv.org/pdf/2507.05997), [HTML](https://arxiv.org/abs/2507.05997)
### Authors
Nicholas Popovič,Ashish Kangen,Tim Schopf,Michael Färber
### Background
在文档级别实体和关系提取领域，高质量的标注数据仍然稀缺。现有方法依赖于手动标注的示范或直接零样本推断，但这种方法资源密集且难以扩展。
### Innovation
本文提出了一种基于完全自动化的LLM（大规模语言模型）的合成数据生成和上下文学习管道，以解决上述问题。该方法结合了合成数据生成与检索式上下文学习，利用推理优化的语言模型，降低了手动标注的需求，并在推理时动态检索相关示例。
### Conclusion
通过该方法，产生了超过5000个维基百科摘要的合成数据集，包含约59000个实体和30000个关系三元组。在DocIE共享任务中，评估了上下文学习表现，实验结果表明即使对于最先进的大型语言模型，文档级别的联合实体和关系提取仍是具有挑战性的任务。
## 321. `cs.CL` - RabakBench：利用扩展的人类注释构建适合低资源语言的安全基准 [PDF](https://arxiv.org/pdf/2507.05980), [HTML](https://arxiv.org/abs/2507.05980)
### Authors
Gabriel Chua,Leanne Tan,Ziyu Ge,Roy Ka-Wei Lee
### Background
由于低资源语言数据有限且缺乏相应的评估标准，大型语言模型（LLMs）及其安全性分类器在这些语言上往往表现不佳。当前方法对于特定区域语言的安全性评估不足，特别是在东南亚地区。为了应对这一挑战，本文提出了RabakBench，一个针对新加坡独特语言环境的多语言安全性基准，涵盖了英语（Singlish）、汉语、马来语和泰米尔语。RabakBench 通过一个可扩展的三阶段管道来构建：首先进行敌对样本生成，增强真实 Singlish 网络内容，结合LLM团队活动；接着进行半自动多标签安全性标注，利用多数投票后的LLM标签者与人类判断对齐来完成标注；最后进行高保真翻译，以保持不同语言之间的语义细微差别和有毒性的连贯性。最终数据集包含逾5000个高安全标签示例，每种语言分别有六类细粒度的安全性类别，其严重度级别也随之划分。
### Innovation
RabakBench 提供了一种可扩展的三阶段管道来构建针对低资源语言的安全基准。这一创新性方法结合了先进的敌对样本生成、人性化的多标签注释流程以及高品质的跨语言翻译，确保不同语言的安全性评估的一致性和准确性。此外，通过应用这一框架，研究团队评估了11种流行的开源和闭源护栏分类器，发现其性能显著下降，进而证明了RabakBench在东南亚多语言环境下进行鲁棒的安全性评估的有效性。RabakBench 作为一个可复现实验的框架，在低资源环境中构建本地化的安全数据集具有重要意义。同时，此基准数据集及评估代码均公开共享。
### Conclusion
RabakBench 不仅是一个适用于东南亚多语言环境的安全性评估基准，还提供了一个在低资源环境中创建本地化安全数据集的可复现实验框架。未来的研究将根据实际应用进一步改进和完善该框架。
## 322. `cs.CL` - NeoBabel: 多语言开放塔架用于视觉生成 [PDF](https://arxiv.org/pdf/2507.06137), [HTML](https://arxiv.org/abs/2507.06137)
### Authors
Mohammad Mahdi Derakhshani,Dheeraj Varghese,Marzieh Fadaee,Cees G. M. Snoek
### Background
现有的文本到图像生成技术主要集中在英语上，这给非英语使用者设定了障碍，并加剧了数字不平等。现有系统依赖于翻译管道，但这些会引入语义漂移、计算开销和文化错配的问题。
### Innovation
我们提出了NeoBabel，这是一种新的多语言图像生成框架，它在性能、效率和包容性方面都达到了新的帕累托前沿。该模型支持六种语言：英语、中文、荷兰语、法语、印度语和波斯语。模型通过大规模多语言预训练和高分辨率指令调整进行训练。我们进一步引入了两种新的度量标准来严格评估多语言的对齐和代码混杂提示的稳健性。NeoBabel 的大小仅有英语模型的两到四倍，并且在多语言基准测试中表现出色，即使基于多语言基础大语言模型的领先模型也无法超越它。我们的工作证明了多语言能力并不是一个权衡，而是生成AI中增强稳健性、效率和文化真实性的催化剂。
### Conclusion
我们的研究展示了多语言能力不是一种权衡，而是生成AI中增强稳健性、效率和文化真实性的催化剂，并为包容性AI研究提供了一个开放的工具包，包括代码、模型断点、1.24亿多语言文本-图像对数据集及其标准化的多语言评估协议。
## 323. `cs.CL` - 如何理解大型语言模型中的代码？——编程三角形框架 [PDF](https://arxiv.org/pdf/2507.06138), [HTML](https://arxiv.org/abs/2507.06138)
### Authors
Taolin Zhang,Zihan Ma,Maosong Cao,Junnan Liu,Songyang Zhang,Kai Chen
### Background
大语言模型（LLMs）在代码生成方面取得了显著进展，但它们的真实编程能力仍待深入探讨。现有研究主要集中在LLMs的表现上，但对它们在不同编程任务中的综合素质评价不足。为了更全面地评估LLMs的编程能力，该研究提出了编程三角形框架，通过系统性地从三个基本维度（编辑分析、代码实现和测试案例生成）对LLMs进行评估。实验结果表明，虽然LLMs可以在这些维度之间形成一致性，但其解决方案缺乏人类程序员的多样性和稳健性。此外，该研究揭示了模型认知与人类专业知识之间的显著分布差异，模型错误往往因训练数据偏差和有限的推理转移而集中出现。
### Innovation
该研究引入了编程三角形框架，这是一种创新的方法来系统性地评估LLMs在多个编程任务中的表现。通过这种框架，研究揭示了模型与人类在认知和专业知识上的差异，并提出将人类编辑、解决方案和多样化测试案例融入到LLMs中，以及利用模型混合的方法，可以显著提高LLMs的性能和稳健性。此外，研究还揭示了LLMs认知的一致性和不一致性，这可能为其自我反思和自我改进提供方向。
### Conclusion
编程三角形框架为评估LLMs的编程能力提供了一种综合和全面的方法。通过此框架，研究发现了模型与人类专业性之间的显著差异，并指出了增强模型性能和鲁棒性的多种策略。未来的研究可以通过进一步整合这些策略来开发更强大的编码模型。
## 324. `cs.CL` - OpenFActScore: 开放源代码的原子化文本生成事实性评估 [PDF](https://arxiv.org/pdf/2507.05965), [HTML](https://arxiv.org/abs/2507.05965)
### Authors
Lucas Fonseca Lage,Simon Ostermann
### Background
研究领域中需要有效评估大规模语言模型（LLMs）生成的长文本的事实性。原有的FActScore框架依赖于内部的模型进行事实性评估，但这些模型通常是封闭源代码和商业的，限制了其在开放源代码模型中的应用。为了提高透明度、复现性和成本效益，作者提出OpenFActScore，这是一个开放源代码实现，它允许使用任何Hugging Face兼容模型进行原子事实生成（AFG）和原子事实验证（AFV）。
### Innovation
OpenFActScore框架提供了一种新的开放源代码解决方案，使得任何符合Hugging Face标准的模型都可以用于事实性的评估。相比旧的FActScore依赖封闭模型的方法，OpenFActScore提供了更广泛的模型选择，并且评估了多个开源的大规模语言模型的性能。
### Conclusion
OpenFActScore促进透明性、复现性和成本效益的评估方法，并且实验证明其结果与封闭源代码系统的评估结果高度一致。该系统已经在多个开源模型上进行了评估，并获得了接近原始FActScore实验的结果，Pearson相关系数达到0.99。此外，该工具是开放源代码的，可以在指定网站获得。
## 325. `cs.CL` - 无大型模型的自我进化：基于任务原则训练语言模型 [PDF](https://arxiv.org/pdf/2507.05991), [HTML](https://arxiv.org/abs/2507.05991)
### Authors
Minghang Zhu,Shen Gao,Zhengliang Shi,Jiabao Fang,Pengjie Ren,Zhaochun Ren,Zhumin Chen,Shuo Shang
### Background
现有语言模型的训练通常依赖于大型语言模型扩展现有人造数据集，然后用于模型训练。这种方法虽然可以显著降低人力标注数据的成本，但它仍然面临数据扩增过程中高碳排放和使用闭源大型语言模型时的数据泄露风险。
### Innovation
本文提出了一种自我进化的方法，首先通过Mult-level Principle Generation多级原则生成，使大型模型能够基于少量任务数据总结出任务完成原则；其次，利用这些原则通过Principle-based Instance Generation原则驱动的数据生成方法生成大量数据用于模型训练。这种新方法能显著提高模型性能，并通过减少对大型语言模型的依赖降低了碳排放。
### Conclusion
实验结果表明，与直接使用小型语言模型生成数据相比，本文提出的基于任务原则的方法能显著提升模型性能，并通过减少大型模型的训练使用降低了碳排放。
## 326. `cs.CL` - 条件化的多阶段故障恢复机制对实体代理 [PDF](https://arxiv.org/pdf/2507.06016), [HTML](https://arxiv.org/abs/2507.06016)
### Authors
Youmna Farag,Svetlana Stoyanchev,Mohan Li,Simon Keizer,Rama Doddipatla
### Background
实体代理在执行复杂任务时存在执行失败的风险，因此需要有效的故障恢复机制。
### Innovation
引入了一种基于零样本链提示的条件多阶段故障恢复框架，该框架包括四个误差处理阶段，三个在任务执行期间操作，一个在任务执行后进行反思。方法利用了大模型的推理能力，分析执行挑战并在其环境上下文中提出战略解决方案。
### Conclusion
在TEACH数据集的TfD基准上评估了该方法，取得了最先进的性能，比没有错误恢复的基线高出11.5%，并且超过了现有的最强模型19%。
## 327. `cs.CL` - 我们应当评估实际影响 [PDF](https://arxiv.org/pdf/2507.05973), [HTML](https://arxiv.org/abs/2507.05973)
### Authors
Ehud Reiter
### Background
自然语言处理(NLP)系统的实际影响评估在ACL社区中几乎没有得到重视。查阅ACL文集的结构化调查表明，仅有大约0.1%的论文包含此类评估；同时，绝大多数包含影响评估的论文都只进行了简略论述，而更侧重于指标评估。
### Innovation
该论文提出的观点是，如果认真了解和评估NLP技术的实际影响，这将使技术更有用并更快被采纳。
### Conclusion
NLP技术的实际影响评估应该得到更多重视。
## 328. `cs.CL` - CriticLean: 基于批评引导的强化学习在数学形式化中的应用 [PDF](https://arxiv.org/pdf/2507.06181), [HTML](https://arxiv.org/abs/2507.06181)
### Authors
Zhongyuan Peng,Yifan Yao,Kaijing Ma,Shuyue Guo,Yizhe Li,Yichi Zhang,Chenchen Zhang,Yifan Zhang,Zhouliang Yu,Luming Li,Minghao Liu,Yihang Xia,Jiawei Shen,Yuchen Wu,Yixin Cao,Zhaoxiang Zhang,Wenhao Huang,Jiaheng Liu,Ge Zhang
### Background
将自然语言数学语句翻译成正式执行的代码是自动定理证明中的基本挑战。此前的研究主要集中在生成和编译的成功上，而少有关注批评阶段，即评估生成的正规化是否真正捕捉原始问题的语义意图。现有工作在生成和编译的成功上取得了进展，但忽视了验证生成形式化是否准确地反映了原始问题的语义内容的重要性。本书引入了CriticLean，这是一种创新性的批评指导下强化学习框架，将批评的角色从被动验证提升为积极的学习组件。
### Innovation
首先，我们提出了一种名为CriticLeanGPT的模型，通过监督微调和强化学习训练，用于严格评估Lean 4形式化的语义忠实度。然后介绍了CriticLeanBench，一个用于测量模型区分正确和不正确形式化能力的基准。证明我们的训练好的CriticLeanGPT模型可以显著超越强大的开源和封闭源基线。基于CriticLean框架，构建了FineLeanCorpus数据集，包含超过285K个展示丰富领域多样性、广泛困难覆盖和高度正确性的问题。
### Conclusion
我们的研究结果表明，优化批评阶段对于生成可靠的正规化至关重要。我们希望我们的CriticLean能够为未来的形式化数学推理进步提供有价值的见解。
## 329. `cs.CL` - Skywork-R1V3 技术报告 [PDF](https://arxiv.org/pdf/2507.06167), [HTML](https://arxiv.org/abs/2507.06167)
### Authors
Wei Shen,Jiangbo Pei,Yi Peng,Xuchen Song,Yang Liu,Jian Peng,Haofeng Sun,Yunzhuo Hao,Peiyu Wang,Yahui Zhou
### Background
文章介绍了Skywork-R1V3，这是一种先进的开源视觉-语言模型（VLM），它在视觉推理方面提出了新的方法。其主要创新在于能够有效地将仅限文本的大语言模型（LLMs）的推理能力转移到视觉任务中。
### Innovation
Skywork-R1V3的关键创新在于，通过一个全面的后续训练RL框架，有效地激活和增强了模型的推理能力，无需额外的连续预训练。此外，引入了推理能力的唯一指示器——关键推理词的熵，这已被证明对RL训练期间的检查点选择非常有效。该模型还实现了从数学推理到其他相关推理任务的迁移。
### Conclusion
Skywork-R1V3在MMMU上达到了最先进的结果，从64.3%显著提升到76.0%，达到了初级人类能力的水平。更重要的是，RL驱动的后续训练方法甚至让38B参数模型能够与顶级闭源VLM竞争。该实现展示了在多模态推理方面取得的显著进步，证实了RL作为提升开源VLM能力的强大引擎的作用。
## 330. `cs.CL` - DS@GT在CheckThat! 2025中的主观性检测：通过迁移学习和校正性数据增强 [PDF](https://arxiv.org/pdf/2507.06189), [HTML](https://arxiv.org/abs/2507.06189)
### Authors
Maximilian Heil,Dionne Bang
### Background
本文介绍的是提交给CLEF 2025 CheckThat! Lab的主题性检测任务的尝试。研究聚焦于利用迁移学习和风格化数据增强来提升对英语新闻文本中主观句与客观句的分类效果。
### Innovation
本文引入了通过GPT-4o生成预定义主题性风格的同义句的控制增强管道。并且，结果显示专门化的编码器迁移学习比通用编码器的微调效果更优，精心策划的数据增强显著增强了模型的鲁棒性，特别是在检测主观内容方面。
### Conclusion
我们的研究结果强调了结合编码器专业化与标签一致性的数据增强在提高主题性检测中的价值。我们位于24名参赛者中的第16名，证明了此方法的有效性。我们的代码可从this https URL访问。
## 331. `cs.CL` - A Survey on Latent Reasoning [PDF](https://arxiv.org/pdf/2507.06203), [HTML](https://arxiv.org/abs/2507.06203)
### Authors
Rui-Jie Zhu,Tianhao Peng,Tianhao Cheng,Xingwei Qu,Jinfa Huang,Dawei Zhu,Hao Wang,Kaiwen Xue,Xuanliang Zhang,Yong Shan,Tianle Cai,Taylor Kergan,Assel Kembay,Andrew Smith,Chenghua Lin,Binh Nguyen,Yuqi Pan,Yuhong Chou,Zefan Cai,Zhenhe Wu,Yongchi Zhao,Tianyu Liu,Jian Yang,Wangchunshu Zhou,Chujie Zheng,Chongxuan Li,Yuyin Zhou,Zhoujun Li,Zhaoxiang Zhang,Jiaheng Liu,Ge Zhang,Wenhao Huang,Jason Eshraghian
### Background
Large Language Models (LLMs) have shown remarkable reasoning capabilities, particularly when guided by explicit chain-of-thought (CoT) reasoning, which verbalizes intermediate steps. However, the reliance on natural language reasoning restricts the model's ability to express complex ideas fully. Latent reasoning addresses this limitation by performing multi-step inference entirely within the model's continuous hidden state, without the need for token-level supervision.
### Innovation
This paper provides a comprehensive overview of latent reasoning, a new approach to improve reasoning in LLMs. It introduces advanced paradigms like infinite-depth latent reasoning through masked diffusion models, which enable globally consistent and reversible reasoning processes. The survey delves into diverse latent reasoning methodologies, including activation-based recurrence, hidden state propagation, and fine-tuning strategies for compressing or internalizing explicit reasoning traces.
### Conclusion
By unifying these perspectives, the survey aims to clarify the conceptual landscape of latent reasoning and to guide future research directions in LLM cognition. An associated GitHub repository collecting the latest papers and resources is also provided.
## 332. `cs.CL` - LLM基 reranking FLOPs的效率-效果评估 [PDF](https://arxiv.org/pdf/2507.06223), [HTML](https://arxiv.org/abs/2507.06223)
### Authors
Zhiyuan Peng,Ting-ruen Wei,Tingyu Song,Yilun Zhao,Yi Fang
### Background
大型语言模型（LLMs）已被应用于信息检索中的排序任务，表现出强大的性能。然而，它们的高计算需求阻碍了实际部署。现有的研究使用代理指标（如延迟、前向传播次数、输入令牌和输出令牌的数量）来评估基于LLM的排序器的效率。但这些指标依赖于硬件和运行时选择（如并行或非并行、批处理大小等），并且不考虑模型大小，使得难以解释和混淆了效率-效果权衡的评估。
### Innovation
提出了一种新的评估指标E²R-FLOPs，即基于LLM的排序器的每一兆飞次计算相关排名指标（RPP）和每兆飞次查询的硬件无关吞吐量（QPP）。同时，构建了一个可解释的FLOPs估算法，即使不运行任何实验也可以估计基于LLM的排序器的FLOPs。通过这些新指标，进行了全面的实验来评估不同架构的广泛基于LLM的排序器，研究了效率-效果权衡。
### Conclusion
基于提出的指标，对广泛的基于LLM的排序器进行了全面的实验，研究了效率-效果权衡，并将这一问题带到了研究界的关注之中。
## 333. `cs.CL` - ReservoirChat：使用LLM和知识图谱增强的交互式文档为ReservoirPy [PDF](https://arxiv.org/pdf/2507.05279), [HTML](https://arxiv.org/abs/2507.05279)
### Authors
Virgile Boraud(Mnemosyne),Yannis Bendi-Ouis(Mnemosyne),Paul Bernard(Mnemosyne),Xavier Hinaut(Mnemosyne)
### Background
该论文介绍了一个工具，旨在增强大型语言模型（LLMs）在使用ReservoirPy库辅助代码开发以及回答Reservoir Computing领域复杂问题的能力。通过使用检索增强生成（RAG）和知识图谱引入外部知识，该方法旨在减少幻觉并提高生成回应的真实性。系统提供了一种类似于ChatGPT的交互式体验，针对ReservoirPy进行定制，使用户能够编写、调试和理解Python代码，同时获取可靠的领域特定见解。
### Innovation
该方法通过结合外部知识增强LLMs的能力，特别是在ReservoirPy背景下提高代码开发和回答复杂问题的性能。这种结合RAG和知识图谱的方法旨在减少模型的回答错误，并提供更加准确和实用的代码开发支持。与市场上的一些专用模型相比，该方法在编程任务上表现出色，并且与基线模型相比有着显著的改进能力。
### Conclusion
虽然某些专有模型如ChatGPT-4o和NotebookLM在通用知识问题上表现稍好，但该模型在编程任务上表现更优，且相较于其基础模型Codestral-22B，性能有了显著提升。通过为ReservoirPy设计的交互式环境，用户能够更有效地进行代码开发和理解复杂的编程概念。
## 334. `cs.CL` - UQLM: 一个用于大型语言模型不确定性量化的新Python包 [PDF](https://arxiv.org/pdf/2507.06196), [HTML](https://arxiv.org/abs/2507.06196)
### Authors
Dylan Bouchard,Mohit Singh Chauhan,David Skarbrevik,Ho-Kyeong Ra,Viren Bajaj,Zeya Ahmad
### Background
大型语言模型（LLMs）生成虚假或误导性内容的现象，被称为幻觉，这对下游应用的安全性和信任产生了重大影响。
### Innovation
引入了UQLM，这是一个使用最先进的不确定性量化（UQ）技术来检测LLM幻觉的Python包，提供了基于UQ的方法来计算响应级别的置信评分。
### Conclusion
这种工具箱为基于UQ的幻觉检测提供了现成的解决方案，并且容易集成到增强LLM输出可靠性的系统中。
## 335. `cs.CL` - 关于提示调优的综述 [PDF](https://arxiv.org/pdf/2507.06085), [HTML](https://arxiv.org/abs/2507.06085)
### Authors
Zongqian Li,Yixuan Su,Nigel Collier
### Background
本文综述了提示调优，这是一种通过在模型前接上可训练的连续向量来适应语言模型的方法，且保持模型冻结不变。现有的方法被分为两大类：直接提示学习和迁移学习。直接提示学习方法包括通用优化方法、编码器基于的方法、分解策略以及模型专家框架。迁移学习方法包括通用转移方法、编码器基于的方法和分解策略。
### Innovation
对于每种方法，本文分析了其方法设计、创新、见解、优点和缺点，并通过示意图比较了不同的框架。识别了计算效率和训练稳定性方面的挑战，并讨论了提高训练稳健性和扩展应用范围的未来方向。
### Conclusion
本文从计算效率和训练稳定性方面指出了研究中的挑战，并指出了未来研究中需要关注的方向，如提高训练的鲁棒性和拓宽应用范围等问题。
## 336. `cs.CL` - 弥补感知与语言之间的鸿沟：LVLMs对无模态完成理解的系统基准 [PDF](https://arxiv.org/pdf/2507.05799), [HTML](https://arxiv.org/abs/2507.05799)
### Authors
Amane Watahiki,Tomoki Doi,Taiga Shinozaki,Satoshi Nishida,Takuya Niikawa,Katsunori Miyahara,Hitomi Yanaka
### Background
大型视觉-语言模型（LVLMs）的主要目标之一是开发能够协助人类完成多模态任务的系统，这些任务包括理解和解释感知经验的描述。在这类任务中，一种关键现象是无模态完成，即人们即使部分感知对象被遮挡也能感知整个对象。尽管已有大量研究评估了计算机视觉算法在检测或重建被遮挡区域的能力，但对于与无模态完成相关的文本，LVLMs的推断能力和人类相比的情况仍然没有被充分研究。为了解决这一空白，我们构建了一个基于Basic Formal Ontology的基准，以系统分类无模态完成现象。研究表明，虽然许多LVLMs在总体上达到或接近人类水平的性能，但在某些类别中，它们对于被完成的对象的准确性有所差异。特别是，在某些类别中，一些LLaVA-NeXT变体和Claude 3.5 Sonnet在对原始图像进行分类时的准确性低于缺少视觉内容的空白刺激。这种差异仅在日语提示下出现，表明这些模型在特定语言能力上存在一定局限。
### Innovation
构建了一个基于Basic Formal Ontology的基准，以系统分类无模态完成现象，针对与无模态完成相关的文本，研究了LVLMs的推断能力；发现了某些LVLMs在特定类别和语言环境下对无模态完成的分类准确性较低。
### Conclusion
尽管许多LVLMs在总体上达到或接近人类水平的性能，但在某些特定类别和语言环境下，它们对于无模态完成的分类准确性较低。这些发现表明，在这些特定领域中，LVLMs需要进一步提升其语言理解和视觉推理能力。
## 337. `cs.CL` - CoreCodeBench：一种可配置的多场景代码库级基准 [PDF](https://arxiv.org/pdf/2507.05281), [HTML](https://arxiv.org/abs/2507.05281)
### Authors
Lingyue Fu,Hao Guan,Bolun Zhang,Haowei Yuan,Yaoming Zhu,Jun Xu,Zongyu Wang,Lin Qiu,Xunliang Cai,Xuezhi Cao,Weiwen Liu,Weinan Zhang,Yong Yu
### Background
随着大型语言模型（LLMs）展示出越来越先进的代码处理能力，评估其在工程级别代码上的性能仍然具有挑战性。现有的代码库级别基准主要集中在单一场景上，如代码生成或错误修复，未能充分捕捉真实世界的软件或项目工程流程的多样性和复杂性。此外，这些基准在问题定位可控性方面有限，并且其生成的测试用例可靠性存在问题。
### Innovation
本研究提出CorePipe，一种全自动的管道，能够将代码库转换为全面的测试用例，并引入CoreCodeBench，一种可配置的多场景代码库级基准。CorePipe通过生成三种类型的原子问题（开发、错误修复和测试驱动开发）来模拟真实的工程场景，针对核心代码段进行特别优化。这些原子问题进一步组合成三种类型的复合问题，难度可以通过超参数调整灵活控制。CoreCodeBench提供了一个全面且广泛的代码库级基准，以探讨LLMs在实际工程项目的适用性。实验结果显示，不同LLMs具有不同的能力，并提供多维度的视角来了解LLMs在工程环境中的性能。
### Conclusion
CoreCodeBench提供了一个全面的代码库级基准，用于研究LLMs在现实工程环境中的适用性。该管道和基准可促进LLMs在软件开发中的应用，为它们的能力和局限性提供参考。
## 338. `cs.CL` - 大型语言模型中防范误导信息的前瞻防御策略综述 [PDF](https://arxiv.org/pdf/2507.05288), [HTML](https://arxiv.org/abs/2507.05288)
### Authors
Shuliang Liu,Hongyi Liu,Aiwei Liu,Bingchen Duan,Qi Zheng,Yibo Yan,He Geng,Peijie Jiang,Jia Liu,Xuming Hu
### Background
大规模语言模型（LLMs）在关键领域的广泛应用增加了由算法生成的误导信息带来的社会风险。与传统错误信息不同，LLM生成的误导信息可以自我强化，高度可信，并且可以在多种语言间迅速传播，传统的检测方法无法有效应对此类问题。
### Innovation
本文提出了一个前瞻防御框架，从被动的事后检测转变为预判性的缓解策略。具体分为三支柱：知识可信度、推理可靠性、输入鲁棒性。通过现有技术综述和比较分析表明，前瞻防御策略在误导信息预防方面比传统方法提升高达63%，尽管存在非平凡的计算开销和泛化挑战。
### Conclusion
我们建议未来研究应侧重于协同设计稳健的知识基础、推理认证和抗攻击接口，以确保LLMs能够在各种领域有效对抗误导信息。
## 339. `cs.CL` - 熵记忆定律：评估大型语言模型中数据记忆难度 [PDF](https://arxiv.org/pdf/2507.06056), [HTML](https://arxiv.org/abs/2507.06056)
### Authors
Yizhan Huang,Zhe Yang,Meifang Chen,Jianping Zhang,Michael R. Lyu
### Background
大型语言模型（LLMs）在训练过程中会记住部分训练数据，有时在适当提示下会直接复现内容。此前的研究较少探讨这些模型中数据记忆的难度问题。本文通过在OLMo（一系列开源模型）上的实证研究，提出了熵-记忆定律，表明数据的熵与其记忆得分呈线性相关。进一步的实验中，研究还发现，高度随机化的字符串（'gibberish'）尽管看起来随机，实际上在训练数据集中的熵却出奇地低，这与广泛的训练语料库相比显得异常。这些发现为进一步评估LLMs的记忆难度提供了理论依据和技术手段，有助于更深入地理解这些模型的数据处理机制。
### Innovation
熵-记忆定律的提出是本文的主要创新点，该定律指出了数据熵与记憶得分之间的线性关系，从而为理解和评估LLMs的数据记憶能力提供了新的视角。此外，通过对高度随机化的字符串的研究，发现这些原本看似随机的数据在实际中的熵反而较低，这是一种新的现象，也增加了对数据记憶机制理解的新维度。
### Conclusion
熵-记憶定律为描述和评估LLMs中的数据记憶难度提供了一个新的方法。通过观察高度随机化字符串的熵较低，本文展示了如何利用熵来区分训练数据和测试数据，从而实现数据集推断（Dataset Inference, DI）。这些发现不仅增强了对LLMs内部机制的理解，也为后续研究提供了重要的参考。
## 340. `cs.CL` - Chat2SPaT: 基于大型语言模型的交通信号控制计划自动化管理工具 [PDF](https://arxiv.org/pdf/2507.05283), [HTML](https://arxiv.org/abs/2507.05283)
### Authors
Yue Wang,Miao Zhou,Guijing Huang,Rui Zhuo,Chao Yi,Zhenliang Ma
### Background
预定时序的交通信号控制，广泛应用于信号化交叉口和协调的次干道中，需要大量的手动工作来创建和更新信号化计划。当使用按时间或星期计划时，一个交叉口往往与多个计划相关联，导致进一步重复的手动计划参数输入。为简化用户友好的交通信号控制计划管理过程，本研究提出了一种方法，名为Chat2SPaT，用于将用户对信号控制计划的半结构化和模糊描述转化为确切的信号相和时间（SPaT）结果，并进一步转换为基于阶段或环的结构化计划，以交互智能交通系统（ITS）软件和交通信号控制器。通过编排提示，Chat2SPaT首先生用大型语言模型（LLMs）理解和用户计划描述的能力，将其按相序及相属性格式化，并基于LLM输出设计Python脚本来调整周期内的相位、处理交通信号控制的细微差别，最终组装完整的交通信号控制计划。在此聊天流程中，该管道可以迭代使用以进行进一步的计划编辑。实验表明，Chat2SPaT能够生成94%以上的精确计划，涵盖英汉文本测试集超过300个计划描述。
### Innovation
Chat2SPaT利用了大型语言模型（LLMs）的能力，将用户的模糊描述转化为精确的信号相和时间结果，并将这些结果进一步格式化为基于阶段或环的计划，以与智能交通系统（ITS）软件和交通信号控制器交互。该方法能够自动化交通信号控制计划的管理流程，大大提高了效率。
### Conclusion
Chat2SPaT为交通从业者和研究者提供了一个简便的计划管理管道，并有可能成为大型语言模型在智能交通系统（ITS）领域应用中更为准确和多功能的基础组件。
## 341. `cs.CL` - DS@GT在CheckThat! 2025中的集成方法：社交媒体中的科学话语检测 [PDF](https://arxiv.org/pdf/2507.06205), [HTML](https://arxiv.org/abs/2507.06205)
### Authors
Ayush Parikh,Hoang Thanh Thanh Truong,Jeanette Schofield,Maximilian Heil
### Background
本文为DS@GT团队在CLEF 2025 CheckThat! 任务4a的科学网络话语检测中提交的方法报告。该任务是多分类任务，需要判断推特中是否包含科学声明、引用的科学研究或出版物，以及提到的科研实体（如大学或科学家）等内容。
### Innovation
本文提出了三种建模方法：Transformer微调、LLM的几近提示，以及结合的集成模型，其设计受到早期实验的影响。团队在竞赛中排名第七，达到了0.8611的宏平均F1分数，比DeBERTaV3基线提高了0.0236。团队的代码已发布在Github上。
### Conclusion
通过集成多种方法，DS@GT团队在科学话语检测任务中取得了一定的进步，达到了满意的评估指标，说明这种方法对多分类任务的有效性。
## 342. `cs.CL` - 结构化的 caption 提升文本到图像模型的(prompt 遵循能力) (Re-LAION-Caption 19M) [PDF](https://arxiv.org/pdf/2507.05300), [HTML](https://arxiv.org/abs/2507.05300)
### Authors
Nicholas Merchant,Haitz Sáez de Ocáriz Borde,Andrei Cristian Popescu,Carlos Garcia Jurado Suarez
### Background
生成文本到图像的模型往往因为大型数据集（如 LAION-5B）的噪音和无组织性，在提示遵从性方面遇到困难。这迫使使用者大量依靠提示工程技术来获得理想的输出。
### Innovation
提出在训练过程中实施一致的 caption 结构可以显著改善模型的可控性和对齐性。介绍了一个名为 Re-LAION-Caption 19M 的高质量子集，包含 1900 万张 1024x1024 的图像，并通过 Mistral 7B Instruct 基础的 LLaVA-Next 模型生成了每个图像对应的 caption。每个 caption 遵循四个部分的模板：主题、场景设定、审美和摄像细节。通过使用 pixArt-$Σ$ 和 Stable Diffusion 2 对结构化和随机打乱的 caption 进行微调，结果展示了结构化版本在视觉问答 (VQA) 模型的文本-图像对齐分数上具有明显优势。
### Conclusion
通过使用结构化的 caption 训练文本到图像模型，可以显著提高模型的文本-图像对齐和提示遵从性，因此该方法适合在实际应用中使用。此数据集已公开发布。
## 343. `cs.CL` - DS@GT在CheckThat! 2025中的评估：数字事实验证中的上下文和分词策略 [PDF](https://arxiv.org/pdf/2507.06195), [HTML](https://arxiv.org/abs/2507.06195)
### Authors
Maximilian Heil,Aleksandar Pramov
### Background
自动化事实核查系统在处理涉及数量的声明、量度、比较和时间参考的数值断言时面临独特挑战。这项研究中，作者使用QuanTemp数据集评估了使用ModernBERT模型策略以预测这些声明的真实性的方法，并建立了自己的证据检索管道。研究了三个关键因素：（1）具有更长输入上下文窗口的更多证据的影响；（2）从右到左（R2L）分词的效果；（3）它们对分类性能的联合影响。与算术推理任务中的先前发现不同，从右到左分词并未提高数值任务中的自然语言推理（NLI）。更长的上下文窗口也没有提高真实性表现，突显了证据质量作为主要瓶颈的重要性。
### Innovation
研究通过引入从右到左（R2L）分词策略和更长的输入上下文窗口，探索了数值事实验证中的证据质量和分类性能。尽管R2L分词未提升自然语言推理效果，但更长的上下文窗口也没有改善表现，转折点在于证据质量成为主要限制因素。这是基于CheckThat！2025任务3中，他们的系统参赛代码达到了竞争性的宏平均F1分数0.57，跻身前四名。
### Conclusion
他们的最佳系统在CheckThat! 2025的任务3中取得的宏平均F1分数为0.57，并位列前四名。代码已公开。
## 344. `cs.CL` - 强化微调自然减轻持续后训练中的遗忘 [PDF](https://arxiv.org/pdf/2507.05386), [HTML](https://arxiv.org/abs/2507.05386)
### Authors
Song Lai,Haohan Zhao,Rong Feng,Changyi Ma,Wenzhuo Liu,Hongbo Zhao,Xi Lin,Dong Yi,Min Xie,Qingfu Zhang,Hongbin Liu,Gaofeng Meng,Fei Zhu
### Background
持续后训练（CPT）是一种流行的且有效的技术，用于将基础模型，如多模态大语言模型适应具体的且不断变化的下游任务。现有研究主要关注数据重放、模型扩展或参数正则化等方法，而CPT中的学习范式的基础作用尚未被充分探索。本文通过对比分析两种核心的后训练范式：监督微调（SFT）和强化微调（RFT），考察它们在CPT过程中对知识保留的影响。实验在包含7个不同多模态任务的基准上进行，使用Qwen2.5-VL-7B-Instruct作为持续后训练的基础模型。研究发现：(1) 对于持续学习下游任务而言，SFT会导致对先前学习任务的灾难性遗忘。相比之下，RFT能自然保留先前的知识，并达到与多任务训练相当的表现。(2) RFT可以保护甚至增强模型在标准基准上的普遍知识。而SFT则严重削弱了通用模型的能力。进一步分析表明，显式的机制，如KL惩罚和思想链推理，并非主要原因。相反，关系到RFT的内在正则化是减轻遗忘的关键因素。最后，本文提出了一种基于回放的实例过滤算法，以提高RFT的稳定性和效率。
### Innovation
1. 通过对比分析两种核心的后训练范式：监督微调（SFT）和强化微调（RFT），考察它们在CPT过程中对知识保留的影响。2. 揭示了强化微调（RFT）在减轻遗忘方面的作用。3. 提出了一种基于回放的实例过滤算法，以提高RFT的稳定性和效率。
### Conclusion
本文的全面研究表明，强化微调（RFT）作为一个强大的范式，在持续后训练中具有优越性。
## 345. `cs.CL` - 超越检索：使用LLMs与交叉编码器和GPT重排序进行生物医学问答 [PDF](https://arxiv.org/pdf/2507.05577), [HTML](https://arxiv.org/abs/2507.05577)
### Authors
Shashank Verma,Fengyi Jiang,Xiangning Xue
### Background
生物医学领域的文献庞大、不断演变且数量不断增长，通过信息检索进行生物医学语义问题回答可以在保持更新方面发挥关键作用。这有助于研究人员、医疗保健专业人员甚至普通用户获取基于证据的相关知识。BioASQ 2025 Task13b 挑战作为重要标杆，提供了推动该领域进步的竞技平台。
### Innovation
该论文提出了一种集成交叉编码器和大型语言模型（LLMs）重排序的检索增强生成（RAG）系统。该系统通过从生物医学文章生成密集嵌入进行初步检索，并应用微调的交叉编码器和大型语言模型进行重排序，以识别最相关文档。对于答案生成，利用指令调校的LLM进行了少量提示。实验结果表明该系统在多种类别的问题上均取得了较好的表现，特别是在重排序方面。
### Conclusion
该系统在检索任务上取得了0.1581的MAP@10，排名第十；在答案生成方面，获得了yes/no问题上的macro-F1 0.95（排名第12）、事实性问题上的MRR 0.64（排名第1）、列表问题上的mean-F1 0.63（排名第5）和理想答案上的ROUGE-SU4 F1评分0.29（排名第11），展示了系统在生物医学问答任务中的有效性。
## 346. `cs.CL` - 使用监督微调的开源大语言模型作为教育工具的可行替代方案缩小差距 [PDF](https://arxiv.org/pdf/2507.05305), [HTML](https://arxiv.org/abs/2507.05305)
### Authors
Lorenzo Lee Solano,Charles Koutcheme,Juho Leinonen,Alexandra Vassar,Jake Renzella
### Background
前沿的大语言模型（如ChatGPT和Gemini）能够为初学者编程者解读复杂的编译器错误，但由于其庞大的计算规模、高昂的成本以及过度干预的倾向，使其在广泛的教学应用中存在局限性。研究表明，通过监督微调（SFT）增强的小型、专业化的语言模型为教育工具提供了更可选的替代方案。
### Innovation
本文展示了使用监督微调（SFT）增强的开源语言模型比专有模型更加可行。研究人员利用一个包含40,000条C编译器错误解释的数据集，对Qwen3-4B、Llama-3.1-8B和Qwen3-32B三个开源模型进行了微调。研究同时采用了专家人工评估和大规模自动化分析的方法，结果表明监督微调显著提高了小型模型的教学质量，使其与更大的模型相媲美。
### Conclusion
研究分析了模型大小与质量之间的权衡，并确认通过监督微调在高质量、特定领域数据上的精简高效模型是创建专业教育模型的有效策略。该研究提供了可重复的方法，以促进在教育环境中更广泛地访问生成AI的能力。
## 347. `cs.CL` - 大规模对话教育：多LLM代理工作流在程序性学习和教学质量评估中的应用 [PDF](https://arxiv.org/pdf/2507.05528), [HTML](https://arxiv.org/abs/2507.05528)
### Authors
Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang
### Background
现有的语言模型（LLMs）已经在虚拟教育者和学习者之间建立了桥梁，并将自然语言处理（NLP）与教育人工智能（AI4Education）结合了起来。然而，现有工作往往缺乏可扩展性，并且未能充分利用多样化的、大规模的课程内容，对于教学质量的评估框架也有限。因此，本研究提出了一种名为WikiHowAgent的多代理工作流，通过利用LLMs模拟互动的教学-学习对话，来促进程序性学习并评估教学质量。
### Innovation
本研究提出了一种全新的多代理工作流WikiHowAgent，利用LLMs来模拟互动的教学-学习对话，整合了教师和学习者代理、交互管理器和评估器，以促进程序性学习和评价教学质量。此外，研究还引入了一个规模巨大的数据集，包含了114,296次教师-学习者对话，这些对话基于14,287个教程，涵盖了17个领域和727个主题。评估协议结合了计算和评分标准与人类判断的一致性，展示了工作流在不同环境中的有效性，为LLMs在不同领域的应用提供了见解。并且，该研究的数据集和实现均已开源。
### Conclusion
结果显示，该工作流在多种设置下都表现出有效性，展示了LLMs在不同领域的应用潜力。此研究为对话教育的大规模实施提供了新的思路和资源，并为评估教学质量提供了新框架。
## 348. `cs.CL` - AI搜索系统中的新闻来源引用模式 [PDF](https://arxiv.org/pdf/2507.05301), [HTML](https://arxiv.org/abs/2507.05301)
### Authors
Kai-Cheng Yang
### Background
AI驱动的搜索系统正在成为新的信息把关人，从根本上改变了用户获取新闻和信息的方式。尽管这些系统在影响力上不断增长，但人们对这些系统引用模式的理解仍很有限。本文通过分析AI搜索竞技场的数据来填补这一空白，AI搜索竞技场是一个用于评估AI搜索系统的对战平台。数据集包括了超过24,000次对话和来自三大供应商OpenAI、Perplexity和Google的65,000个响应。在这超过366,000次嵌入的引用中，有9%引用了新闻来源。研究发现，虽然不同供应商提供的模型引用了不同的新闻来源，但它们在引用行为上表现出共同的模式。新闻引用高度集中在少数几家媒体中，并显示出了明显的左倾倾向，尽管低可信度来源很少被引用。用户偏好分析表明，引用新闻来源的政治倾向或质量对用户满意度影响不大。这一发现揭示了当前AI搜索系统中存在的重大挑战，对这些系统的设计和治理具有重要影响。
### Innovation
本文创新性地利用AI搜索竞技场的数据，分析了超过366,000次引用中的新闻来源模式，揭示了不同供应商提供的模型虽然引用了不同的新闻来源，但都呈现出了左倾倾向，且极少引用低可信度来源。这种分析方法填补了对AI搜索系统引用模式了解的空白。
### Conclusion
当前AI搜索系统中存在重大挑战，包括新闻引用模式中的政治倾向和可信度问题。这些发现对AI搜索系统的未来设计和治理提出了重要启示。
## 349. `cs.CL` - Agent KB：跨域经验促进代理型问题解决 [PDF](https://arxiv.org/pdf/2507.06229), [HTML](https://arxiv.org/abs/2507.06229)
### Authors
Xiangru Tang,Tianrui Qin,Tianhao Peng,Ziyang Zhou,Daniel Shao,Tingting Du,Xinming Wei,Peng Xia,Fang Wu,He Zhu,Ge Zhang,Jiaheng Liu,Xingyao Wang,Sirui Hong,Chenglin Wu,Hao Cheng,Chi Wang,Wangchunshu Zhou
### Background
随着语言代理处理的任务越来越复杂，它们在有效的错误纠正以及跨领域经验重用方面遇到了挑战。传统的代理模型无法从彼此的经验中学习，这限制了它们在复杂任务上的表现。
### Innovation
引入了Agent KB，一种分层次的经验框架，通过一种新颖的Reason-Retrieve-Refine流程，解决了代理模型无法从彼此经验中学习的核心局限性。Agent KB通过捕获高层次策略和详细执行日志来创建共享的知识库，从而实现跨代理的知识转移。
### Conclusion
在GAIA基准测试中，Agent KB提高了成功率高达16.28个百分点。特别在GAIA的最复杂任务中，Claude-3的表现从38.46%提高到57.69%，GPT-4在中间任务中的表现从53.49%提高到73.26%。在SWE-bench代码修复任务中，Agent KB使Claude-3的表现从41.33%提高到53.33%。研究结果表明，Agent KB为代理提供了一种模块化的、框架无关的基础设施，使它们能够从过去的经历中学习，并将成功的策略进行推广以应用于新的任务。
## 350. `cs.CL` - MobileGUI-RL：通过在线环境中强化学习提高移动GUI代理 [PDF](https://arxiv.org/pdf/2507.05720), [HTML](https://arxiv.org/abs/2507.05720)
### Authors
Yucheng Shi,Wenhao Yu,Zaitang Li,Yonglin Wang,Hongming Zhang,Ninghao Liu,Haitao Mi,Dong Yu
### Background
近年来，基于视觉的GUI代理迅速崛起，用于自动化移动和Web任务。这些代理解析原始的GUI屏幕截图，并自主决定点击、滚动或输入的位置，这意味着它们超越了人工设计的规则和特定应用程序的API。然而，现有方法大多在使用预先收集的轨迹的离线环境中训练GUI代理。这种方法限制了其扩展性，导致对特定UI模板过度拟合，并且在面对未见过的环境时导致策略脆弱性强.
### Innovation
我们提出了一种名为MobileGUI-RL的可扩展框架，该框架能够在在线环境中训练GUI代理。MobileGUI-RL包含两个关键组件：一是通过自我探索和过滤合成一个可学习的任务课程；二是将基于策略的repeat-play优化（GRPO）适应到GUI导航，并结合了轨迹意识的优势和综合奖励，以平衡任务成功和执行效率.
### Conclusion
在三种在线移动代理基准上的实验表明，我们的方法能够获得一致的收益，验证了其有效性.
## 351. `cs.CL` - TuneShield: 在使用不可信数据微调时减轻对话AI中的毒性 [PDF](https://arxiv.org/pdf/2507.05660), [HTML](https://arxiv.org/abs/2507.05660)
### Authors
Aravind Cheruvu,Shravya Kanchi,Sifat Muhammad Abdullah,Nicholas Kong,Daphne Yao,Murtuza Jadliwala,Bimal Viswanath
### Background
最近的基准模型，如大语言模型(LLMs)，极大地改变了对话AI领域。聊天机器人越来越多地通过针对特定对话数据集定制LLMs来开发。然而，在这种定制过程中，特别是在处理不可信训练数据时，减轻毒性（即不当内容）仍是一个重要挑战。为解决这一问题，TuneShield应运而生，这是一种防护框架，旨在在微调聊天机器人时减轻毒性，同时保持对话质量。TuneShield利用基于LLMs的毒性分类，有效地识别出有毒样本，这些样本在性能上优于行业API服务。TuneShield还根据识别出的有毒样本生成合成对话样本，称为‘治愈数据’，用于减轻毒性并强化期望的行为。此外，TuneShield还对聊天机器人进行了一个对齐过程，以进一步引导其生成所需响应。
### Innovation
TuneShield是一个专门设计的防护框架，通过利用LLMs的指令跟随能力和安全对齐能力，有效地识别和减轻有毒样本，从而在微调聊天机器人时保护对话质量。相对于现有的行业API服务，TuneShield在识别有毒样本方面表现更优，并且能够生成合成的治愈数据，有效减轻毒性注入攻击的同时保持对话质量，即使在毒性分类器不完善或存在偏差的情况下。此外，TuneShield还证明了其对适应性对抗攻击和劫持攻击的强大抵抗力，并在基于对话的学习中有效减轻适应性毒性注入攻击。
### Conclusion
TuneShield有效地减轻了毒性注入攻击，即使在毒性分类器不完善或存在偏差的情况下也能保持对话质量。该框架展现了对于适应性对抗攻击和“劫持”攻击的强健性，并在基于对话的学习中展示了减轻适应性毒性注入攻击的效果。
## 352. `cs.CL` - MusiScene: 利用MU-LLaMA进行场景想象和增强视频背景音乐生成 [PDF](https://arxiv.org/pdf/2507.05894), [HTML](https://arxiv.org/abs/2507.05894)
### Authors
Fathinah Izzati,Xinyue Li,Yuxuan Wu,Gus Xia
### Background
人类在听音乐时能够想象各种氛围和场景，联想到与音乐相匹配的电影场景。例如缓慢忧郁的音乐可能会让人联想到失去爱情的场景，而欢快的旋律则暗示着庆祝。本文研究了音乐语言模型（如MU-LLaMA）能否完成类似的任务，称为音乐场景想象 (MSI)，这需要从视频和音乐中获取跨模态信息进行训练。本文对现有的仅集中在音乐元素上的音乐描述模型进行了改进，介绍了一个新的音乐描述模型MusisScene，旨在想象与音乐相匹配的场景。为了改善对视频背景音乐生成（VBMG）的文本描述，论文构建了一个包含3,371对的大规模视频-音频描述数据集，并对Music Understanding LLaMA进行微调以创建MusisScene模型，接着对MusisScene进行了全面的评估，表明其能够生成更相关、更有场景感的描述，优于MU-LLaMA。
### Innovation
本文创新性地提出了MusisScene模型用于音乐场景想象任务，通过构建大规模视频-音频数据集，并对现有模型进行微调，以生成与音乐情境更相关的描述，从而增强视频背景音乐生成。
### Conclusion
本文证明了MusisScene模型在生成场景相关描述方面的优越性，并利用生成的MSI描述来增强视频背景音乐生成。
## 353. `cs.CL` - AutoTriton: 使用强化学习在大语言模型中自动进行Triton编程 [PDF](https://arxiv.org/pdf/2507.05687), [HTML](https://arxiv.org/abs/2507.05687)
### Authors
Shangzhan Li,Zefan Wang,Ye He,Yuxuan Li,Qi Shi,Jianling Li,Yonggang Hu,Wanxiang Che,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
深度学习的内核开发要求在硬件层面优化计算单元，同时平衡内存管理和并行性，并通过大量的经验调优实现硬件特定优化。虽然领域特定语言如Triton简化了GPU编程的低级细节抽象，开发者仍需手动调优关键参数，如块大小和内存访问模式，这通过迭代实验完成，创建了对最优性能和更广泛采用的极大阻碍。
### Innovation
本文引入了AutoTriton，这是利用强化学习（RL）的首个针对Triton编程的模型。AutoTriton通过监督微调（SFT）获得必要的Triton编程专业技能，并使用高质量的数据收集管道进行训练。然后使用Group Relative Policy Optimization (GRPO) 算法进行RL训练，结合基于规则的奖励和执行基于的奖励来进一步提高Triton编程能力。实验结果显示，AutoTriton的8B模型在TritonBench和KernelBench的五个评估通道中性能与现有的主流大型模型（如Claude-4-Sonnet和DeepSeek-R1-0528）相当。进一步的实验分析表明AutoTriton各个模块的重要性，包括SFT阶段、RL阶段和奖励设计策略。这一系列研究结果凸显了利用RL自动生成高性能内核的可能性，并且由于高性能内核是AI系统的核心组件，这项突破为构建更高效的AI系统奠定了基础。
### Conclusion
AutoTriton利用强化学习自动进行Triton编程，结果显示其性能与主流大型模型相当。这一发现证明了强化学习在生成高性能内核方面的潜力，并为构建更高效的AI系统提供了重要的基础。
## 354. `cs.CL` - 向量检索系统中的语义确定性评估：一种新型的嵌入质量评估框架 [PDF](https://arxiv.org/pdf/2507.05933), [HTML](https://arxiv.org/abs/2507.05933)
### Authors
Y. Du
### Background
向量检索系统在响应不同查询时表现出显著的性能差异，这种差异主要归因于嵌入质量的不一致性。高质量的嵌入占据嵌入空间中的几何上稳定区域，并且表现出一致的局部结构特征。现有方法仅依赖于单一的评估标准，未能充分考虑到这些局部结构特征对于评估检索性能的重要性。因此，需要开发一种新的框架来预测查询级别的检索性能，结合量化稳健性和邻域密度度量的方法可以更好地评估嵌入质量。
### Innovation
提出了一种轻量级框架，通过结合量化稳健性和邻域密度度量来预测查询级的检索性能。该框架基于观察，即高质量的嵌入在嵌入空间中占据几何上稳定区域，并且表现出一致的邻域结构。与现有的有竞争力的基本方法相比，该方法在4个标准检索数据集上的Recall@10性能提高了9.4±1.2%，同时对检索时间的计算开销极小（不到5%）。这项工作还揭示了不同查询类型之间的嵌入质量系统性模式，为针对特定训练数据增强提供了见解。
### Conclusion
实验结果表明，该方法能够在检索性能评估上提供显著改进，并且框架具有较低的计算开销和促进了适应性检索策略。分析展示了不同查询类型下嵌入质量的系统性模式，为进一步优化提供了重要的指导。
## 355. `cs.CL` - 基于大型语言模型的HopeBot聊天机器人开发与评估：一种结构化和互动的PHQ-9抑郁筛查工具 [PDF](https://arxiv.org/pdf/2507.05984), [HTML](https://arxiv.org/abs/2507.05984)
### Authors
Zhijun Guo,Alvina Lai,Julia Ive,Alexandru Petcu,Yutong Wang,Luyuan Qi,Johan H Thygesen,Kezhi Li
### Background
现有的静态工具如PHQ-9问卷能够有效地筛查抑郁症，但缺乏互动性和可适应性。为了改变这一现状，开发了HopeBot，一个由大型语言模型（LLM）驱动的聊天机器人，通过检索增强生成和实时澄清来执行PHQ-9问卷。
### Innovation
HopeBot采用检索增强生成和实时澄清技术来执行PHQ-9问卷，并在一项针对132名来自英国和中国的成年人进行的个体内比较研究中显示出高一致性（ICC = 0.91，45%相同）。参与者反馈表明，他们对聊天机器人的信任度更高，特别是在结构清晰度、解释指导和支持性语气方面。此外，针对敏感话题的处理、语音清晰度、舒适感和推荐有用性得分分别为7.6、8.4、7.7和7.4，其中后者的评分在就业状态和之前使用心理健康服务方面存在显著差异（p < 0.05）。总体而言，87.1%的参与者表示愿意再次使用或推荐HopeBot。
### Conclusion
这些结果表明，基于语音的LLM聊天机器人可以作为扩大规模且低负担的抑郁筛查辅助工具来使用。
## 356. `cs.CL` - ContextASR-Bench: 一个大规模上下文语音识别基准 [PDF](https://arxiv.org/pdf/2507.05727), [HTML](https://arxiv.org/abs/2507.05727)
### Authors
He Wang,Linhan Ma,Dake Guo,Xiong Wang,Lei Xie,Jin Xu,Junyang Lin
### Background
尽管自动语音识别（ASR）已经被广泛研究，之前的评价方法大多局限于无情境的框架中。这主要是由于传统ASR模型在上下文建模方面的不足，以及它们在基于世界知识的记忆和推理方面的缺陷。最近，大型语言模型（LLMs）和大型音频语言模型（LALMs）的发展使得通用人工智能的能力更加突出。然而，目前缺乏一个能够评估语音识别系统在语境理解和通用性方面的基准。因此，提出ContextASR-Bench，一个全面且大规模的基准测试，用于评估上下文语音识别的能力。该基准涵盖超过10个领域，多达40,000个数据条目，能够全面评估模型在缺失语境或包含粗粒度和细粒度语境信息场景中的性能。此外，不同于传统的ASR评估，基准还包含了对模型在音频输入中识别命名实体效果的分析。
### Innovation
ContextASR-Bench 是一个旨在评估上下文理解和通用性的大规模基准测试。它不仅涵盖了广泛的领域和大量的数据，还包括对模型识别命名实体能力的评估。通过对比，该基准展示了LALMs在世界知识和上下文学习方面的能力明显优于传统的ASR模型。基准数据集和评估代码已公开发布。
### Conclusion
LALMs在ContextASR-Bench上的表现显著优于传统ASR模型，特别是在理解和利用上下文信息方面。这一基准的发布填补了当前ASR系统评价的一个空白，为未来的研究提供了新的方向和发展机会。
## 357. `cs.CL` - AI-Reporter: 科学交流的新文体路径 [PDF](https://arxiv.org/pdf/2507.05903), [HTML](https://arxiv.org/abs/2507.05903)
### Authors
Gerd Graßhoff
### Background
AI-Reporter 在科学出版实践中代表着一个范式的转变。该文章通过一个具体的案例研究说明了他们的系统如何在不到三分钟的时间内将学术报告转化为出版就绪的章节。
### Innovation
该系统展示了技术进步如何在暂时的学术报告与永久的科学记录之间架起桥梁。通过阿诺·辛姆斯在NEPI举办的工作坊上关于大型语言模型的讲座为例，该文展示了如何将临时性的报告转换为持久的科学文档。
### Conclusion
AI-Reporter 为科学交流带来了新的文体路径，它代表了一种新的科学交流方式，可以极大地提高学术成果的记录效率和内容的质量。
## 358. `cs.CL` - LLM记忆现象：机制、测量与缓解 [PDF](https://arxiv.org/pdf/2507.05578), [HTML](https://arxiv.org/abs/2507.05578)
### Authors
Alexander Xiong,Xuandong Zhao,Aneesh Pappu,Dawn Song
### Background
大型语言模型（LLMs）在多种任务上表现出卓越的能力，但同时也表现出对训练数据的记忆倾向。这种现象引发了关于模型行为、隐私风险以及学习与记忆界限的关键问题。
### Innovation
本文综合了近期研究，探讨了记忆现象的景观、影响因素及其检测与缓解方法。研究了培训数据重复、训练动态和微调程序等关键驱动因素，并评估了前缀提取、成员推理和对抗提示等方法的有效性。此外，还探讨了记忆的法律和伦理影响。
### Conclusion
本文提供了LLM记忆现象当前研究状态的全面概述，涵盖技术、隐私和性能维度，并指出了未来工作的关键方向，提出了减轻有害记忆同时保留有用信息的缓解策略。
## 359. `cs.CL` - Manuscripts中隐藏指令利用AI辅助同行评审 [PDF](https://arxiv.org/pdf/2507.06185), [HTML](https://arxiv.org/abs/2507.06185)
### Authors
Zhicheng Lin
### Background
2025年7月，arXiv预印本网站上发现了18篇学术论文中包含隐藏指令，这些指令被设计用来操控AI辅助的同行评审。这些隐藏指令使用了诸如白色文字等技巧隐藏起来。作者反应不一：一位打算撤回受影响的论文，而另一位则认为这是测试审查者使用AI合规性的正当实验。
### Innovation
本文分析了这种做法作为新型研究不端行为的形式，揭露了大型语言模型(LLMs)中的隐藏指令技术，确定了四种类型的隐藏指令，从简单的积极评价命令到详细的评估框架。对于指令作为“甜蜜陷阱”检测审查者不当使用AI的辩护，本文指出指令的一贯自我服务性质表明存在操控意图。
### Conclusion
出版商的政策不一致：Elsevier完全禁止使用AI进行同行评审，而Springer Nature则允许有披露要求的有限使用。此次事件揭示了超出同行评审系统的系统性漏洞，这些系统处理学术文本，如抄袭检测和引文索引系统的漏洞。本文强调需要在提交门户中协调的技术筛查和一致的政策来管理生成式人工智能(GenAI)在学术评估中的应用是至关重要的。
## 360. `cs.CL` - 使用大型语言模型评估Habitat中的机器人 [PDF](https://arxiv.org/pdf/2507.06157), [HTML](https://arxiv.org/abs/2507.06157)
### Authors
William Li,Lei Hamilton,Kaise Al-natour,Sanjeev Mohindra
### Background
该论文侧重于使用Meta PARTNER基准评估大型语言模型在解决实体机器人任务的有效性。Meta PARTNER提供了简化后的室内厨房环境和随机化的机器人交互。每个随机化的厨房场景提供了一个任务，两个机器人代理需要合作完成任务。作者在此基于Meta PARTNER环境对多个前沿模型进行了评估，结果显示，在PARTNER的机器人体索引环境中，推理模型如OpenAI o3-mini比非推理模型如OpenAI GPT-4o和Llama 3表现更优，并在集中式、分散式、全可见性和部分可见性配置中均表现出色。这为实体机器人开发提供了新的研究途径。
### Innovation
在Meta PARTNER的机器人体索引环境中评估了多个前沿模型，并发现推理模型如OpenAI o3-mini在各种配置下均优于非推理模型，尤其是在部分可见性配置下表现尤为突出。这为实体机器人开发提供了新的研究方向。
### Conclusion
推理模型如OpenAI o3-mini在Meta PARTNER的机器人体索引环境中表现出色，并在各种配置中均优于非推理模型，这为实体机器人开发提供了新的研究方向。
## 361. `cs.CL` - Differential Mamba [PDF](https://arxiv.org/pdf/2507.06204), [HTML](https://arxiv.org/abs/2507.06204)
### Authors
Nadav Schneider,Itamar Zimerman,Eliya Nachmani
### Background
传统的序列模型如Transformer和RNN在处理任务时会过度关注无关的上下文信息，从而生成噪声较大的中间表示。这会导致语言模型（LLM）的能力下降，表现为生成幻觉、削弱长距离建模能力和检索能力，以及降低模型的鲁棒性。先前的研究表明，通过微调设计可以在一定程度上缓解这一问题，提高Transformer在各个应用中的效果。
### Innovation
本文探索了将针对Transformer设计的微调技术和方法应用到一个新的基于选择状态空间层的Mamba架构上，以解决其过度关注无关上下文的问题。研究发现简单的微调技术对于Mamba不够有效，并且需要进行精心的架构改造。为此，作者提出了一种新的微调机制，并在语言建模基准测试上进行了验证，结果显示这种方法可以提高Mamba的检索能力和性能，优于原始的Mamba。
### Conclusion
通过广泛的消融研究和经验分析，作者证明了该新设计的有效性，表明新的方法能有效缓解Mamba架构中过度关注无关上下文的问题。研究结果证明，新机制能够显著改善Mamba模型的性能，并且该项目的代码已公开可供查看。
## 362. `cs.CL` - SQLBarber: 一种利用大型语言模型生成定制化和现实化SQL工作负载的系统 [PDF](https://arxiv.org/pdf/2507.06192), [HTML](https://arxiv.org/abs/2507.06192)
### Authors
Jiale Lao,Immanuel Trummer
### Background
数据库研究与开发经常需要大量的SQL查询来进行基准测试。然而，由于隐私问题，获取真实世界的SQL查询具有挑战性，现有的SQL生成方法在定制性和满足现实约束方面存在局限性。
### Innovation
SQLBarber是一个基于大型语言模型（LLMs）的系统，用于生成定制化和现实化的SQL工作负载。它通过提供自然语言规范的接受方式来消除用户预先手工编写SQL模板的需求，能够高效地生成匹配用户定义的成本分布的大量查询，并利用来自Amazon Redshift和Snowflake的执行统计数据，来生成反映真实查询特性的SQL模板规范和查询成本分布。
### Conclusion
本文构建并开源了十个基于Snowflake和Amazon Redshift实际统计数据的人工智能不同难度级别的基准测试。实验表明，SQLBarber是唯一能够生成定制化SQL模板的系统，能够显著减少查询生成时间，并大幅提高与目标成本分布的匹配度，相比现有方法拥有显著改进。
## 363. `cs.CL` - 精细视觉语言建模在增强现实多模态培训助手中的细粒度应用 [PDF](https://arxiv.org/pdf/2507.05515), [HTML](https://arxiv.org/abs/2507.05515)
### Authors
Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang
### Background
视觉语言模型（VLMs）对于使AI智能助手能够解释并推理多模态环境至关重要。然而，它们在增强现实（AR）培训中的应用尚未得到广泛探索。
### Innovation
该工作引入了一个专为AR培训定制的综合数据集，包含系统化的视觉语言任务，并评估了九个最先进的视觉语言模型。结果显示，即使是先进的模型，如GPT-4o，在进行细粒度装配任务时也表现不佳，仅在状态检测方面达到40.54%的最大F1分数。
### Conclusion
这些发现强调了增强数据集、基准测试和进一步研究的必要性，以改善视觉语言的一致性。此外，该工作在社会层面具有重要意义，特别是在为视障用户提供平等的AI驱动学习机会方面。我们提供了所有相关资源，包括数据集、源代码和评估结果，以支持研究社区。
## 364. `cs.CL` - 在俄罗斯社交媒体中检测具有价值表达性的文本帖子 [PDF](https://arxiv.org/pdf/2312.08968), [HTML](https://arxiv.org/abs/2312.08968)
### Authors
Maria Milkova,Maksim Rudnev,Lidia Okolskaya
### Background
基本价值观是对理想状态的概念或信念，能超越特定情境。研究社交媒体中的个人价值观可以揭示社会价值观如何演变及其原因，特别是在传统调查方法（如问卷调查）无效时（例如，在难以接触的人群中）。然而，用户生成的内容往往是由标准的文化表达方式驱动的，而不是个人价值观的真实表达。研究旨在找到一种模型，能够在俄罗斯社交媒体VKontakte中准确检测价值观表达性的帖子。为此，研究者建立了一个包含5035个帖子的标注数据集，由三位专家、304名众包工作者和ChatGPT进行标注。众包工作者和专家在分类帖子方面只表现出中等程度的一致性，而ChatGPT则表现稳定但难以进行垃圾信息检测。
### Innovation
研究采用了一种结合人机协作注解的主动学习方法。随后使用各种预训练的变压器语言模型的嵌入向量训练了多个分类模型。最终，微调后的rubert-tiny2模型表现最佳，获得较高的价值观检测质量（F1 = 0.75, F1-macro = 0.80）。这一成果为研究俄罗斯社交媒体用户的价值观提供了关键步骤。
### Conclusion
该模型在俄罗斯社交媒体上具有重要的应用价值，能够准确识别价值观表达性的文本帖子，为后续深入研究提供了强有力的支持。
## 365. `cs.CL` - Affective-ROPTester: LLMs在预测早产儿视网膜病变能力及偏见分析 [PDF](https://arxiv.org/pdf/2507.05816), [HTML](https://arxiv.org/abs/2507.05816)
### Authors
Shuai Zhao,Yulin Zhang,Luwei Xiao,Xinyi Wu,Yanhao Jia,Zhongliang Guo,Xiaobao Wu,Cong-Duy Nguyen,Guoming Zhang,Anh Tuan Luu
### Background
尽管大型语言模型（LLMs）在各个领域的进展显著，但它们在预测早产儿视网膜病变（ROP）风险方面的能力尚未得到充分探索。为解决这一问题，研究引入了一个新的中文基准数据集CROP，包含993份住院记录并标注为低、中、高风险。通过Affective-ROPTester自动化评估框架，研究系统地检验了LLMs在ROP风险分级中的预测能力和情绪偏见，提出了基于指令、链式思考（CoT）和上下文学习（ICL）三种提示策略。
### Innovation
研究提出了一种新的评估框架Affective-ROPTester，采用了基于指令、链式思考和上下文学习三种提示策略，首次系统性地考察了LLMs在ROP风险预测中的能力和情绪偏见，同时在提示层面整合情绪元素，探究不同情绪框架对模型预测准确性及其偏见模式的影响。
### Conclusion
实证研究结果表明，仅依靠内在知识时，LLMs在ROP风险预测上效果有限，但在结合结构化外部输入后性能显著提升；模型输出中存在情绪偏见，倾向于高估中高风险病例，但积极情绪框架有助于减轻这种偏见。这些发现强调了情绪敏感提示工程在增强诊断可靠性和评估及缓解临床语言模型中情感偏见方面的关键作用。
## 366. `cs.CL` - CultureCLIP：通过合成图像和语境化描述赋予CLIP文化意识 [PDF](https://arxiv.org/pdf/2507.06210), [HTML](https://arxiv.org/abs/2507.06210)
### Authors
Yuchen Huang,Zhiyuan Fan,Zhitao He,Sandeep Polisetty,Wenyan Li,Yi R. Fung
### Background
预训练的视觉-语言模型（VLMs）如CLIP在多模态理解方面表现出色，但在处理与上下文相关、细微视觉特征时存在局限，难以区分视觉上相似但文化上不同的概念。这种局限性主要源于高质量的文化特定数据集稀缺、缺乏整合的上下文知识以及未标注的反例未能突出细微差异。
### Innovation
本文首先设计了一个数据编纂管道，利用开源的VLMs和文本到图像扩散模型，构建了一个名为CulTwin的文化合成数据集，该数据集由概念-描述-图像三元组组成，其中概念在视觉上相似但代表不同的文化背景。然后，对CulTwin进行了CLIP的微调，创建了CultureCLIP，通过定制对比学习，文化概念与情景增强的描述和合成图像对齐，从而实现更精细的文化区分，同时保持原始模型的泛化能力，显示出在某些任务上细粒度概念识别的显著5.49%提升，验证了数据合成和VLM基础训练范式在捕捉细微文化差异方面的有效性。
### Conclusion
CultureCLIP在文化相关基准测试中优于基础CLIP，实现了在特定任务中细粒度概念识别2.5%至5.49%的提升，同时保留了CLIP的原泛化能力，验证了该数据合成和VLM基础训练方案的有效性。
## 367. `cs.CL` - MEIT：基于大型语言模型的多模态心电图指令调优方法 [PDF](https://arxiv.org/pdf/2403.04945), [HTML](https://arxiv.org/abs/2403.04945)
### Authors
Zhongwei Wan,Che Liu,Xin Wang,Chaofan Tao,Hui Shen,Jing Xiong,Rossella Arcucci,Huaxiu Yao,Mi Zhang
### Background
心电图（ECG）是监测心脏状况的主要无创诊断工具，在临床诊断中起着重要作用。近期研究集中在使用ECG数据分类心脏状况，但忽略了ECG报告生成，这是一个耗时且需要临床专业知识的过程。本研究旨在通过自动化ECG报告生成，提高报告的生成效率和灵活性。
### Innovation
提出了一个名为MEIT（Multimodal ECG Instruction Tuning）的框架，这是首次尝试使用大型语言模型（LLMs）和多模态指令进行ECG报告生成的研究。通过使用多模态指令和LLMs，MEIT框架能够将ECG信号的表示与报告生成对齐。该研究还提供了一个基准评价框架，使用来自两个大规模ECG数据集的多种LLMs进行评估。
### Conclusion
MEIT的研究结果表明，指令调优的LLMs在报告生成方面表现优秀，具有高质报告生成、零样本能力、对抗信号扰动的鲁棒性和与人类专家评估一致性的能力。这些发现突显了MEIT的有效性，特别是在实际临床应用中的潜力。
## 368. `cs.CL` - 当你第一次看到$a^2+b^2=c^2$时会问什么？评估LLM的好奇心驱动提问能力 [PDF](https://arxiv.org/pdf/2409.17172), [HTML](https://arxiv.org/abs/2409.17172)
### Authors
Shashidhar Reddy Javaji,Zining Zhu
### Background
大型语言模型（LLMs）可以存储大量的知识，但它们获取新知识的能力仍然未知。本文提出了一个新颖的评估框架，旨在评估LLMs获取新知识的能力。该框架通过让LLMs生成关于含有科学知识的陈述的提问，模拟面对新信息时的好奇人心态，从而评估LLMs的知识获取潜力。通过人工评估和控制性的剥离研究验证了生成问题的质量评分体系的有效性。评估的基准数据集包括不同难度的物理、化学、数学和一般知识陈述，以及错误陈述。
### Innovation
本文提出了一种新的评价框架，用于评估LLMs获取新知识的能力，通过让模型生成提问来模拟面对新知识时的好奇心，从而量化模型的这一关键能力。该框架利用人工评估和控制性的剥离研究验证了其有效性和评分体系，这是对模型评估中的常见研究方向的一个补充，为开发更加知识渊博的人工智能系统提供了新的研究机会。
### Conclusion
虽然大型模型如GPT-4和Mistral 8x7b在生成相关和连贯的问题方面表现出色，但较小的Phi-2模型在这种能力上表现得与或更优于大型模型。这表明模型的大小并不唯一决定其知识获取潜力。研究结果表明，该框架能够量化LLMs的一个关键能力，并为开发更加知识渊博的AI系统的研究打开了新的途径。
## 369. `cs.CL` - 隐话语关系识别的多任务和多标签分类模型 [PDF](https://arxiv.org/pdf/2408.08971), [HTML](https://arxiv.org/abs/2408.08971)
### Authors
Nelson Filipe Costa,Leila Kosseim
### Background
本文提出了一种新颖的多标签分类方法，用于隐话语关系识别（IDRR）。该方法通过在PDTB 3.0框架下的三个意义级别中联合学习隐话语关系的多标签表示，提出了一种多任务模型。此外，该模型可以通过选择具有最高概率的单一标签表示，在传统单标签IDRR设置中进行调整。研究了两种设置下的最优模型配置和损失函数。这是首次为多标签IDRR建立基准，并使用DiscoGeM在单标签IDRR任务中取得了最佳结果。最后，评估了模型在PDTB 3.0语料库中的单标签设置，这是首次对DiscoGeM和PDTB 3.0语料库之间的迁移学习进行分析，用于IDRR任务。
### Innovation
本文提出了一个多任务和多标签分类模型，用于隐话语关系识别。该模型能够在PDTB 3.0框架下的三个意义级别中同时学习隐话语关系的多标签表示，同时能够通过选择具有最高概率的单一标签表示在传统单标签IDRR设置中进行调整。研究了不同配置和损失函数的模型，建立了多标签IDRR的第一个基准，并取得了单标签IDRR的最新成果。此外，首次分析了DiscoGeM和PDTB 3.0语料库之间的迁移学习对于IDRR任务的影响。
### Conclusion
本文提出的方法成功地建立了多标签IDRR的第一个基准，并在PDTB 3.0中的单标签IDRR任务上达到了最新最佳性能。利用DiscoGeM在单标签IDRR任务上的表现优于之前的方法。首次分析了DiscoGeM和PDTB 3.0语料库之间的迁移学习在隐话语关系识别任务中的应用潜力。
## 370. `cs.CL` - 评估OpenAI o1：AGI的机会与挑战 [PDF](https://arxiv.org/pdf/2409.18486), [HTML](https://arxiv.org/abs/2409.18486)
### Authors
Tianyang Zhong,Zhengliang Liu,Yi Pan,Yutong Zhang,Yifan Zhou,Shizhe Liang,Zihao Wu,Yanjun Lyu,Peng Shu,Xiaowei Yu,Chao Cao,Hanqi Jiang,Hanxu Chen,Yiwei Li,Junhao Chen,Huawen Hu,Yiheng Liu,Huaqin Zhao,Shaochen Xu,Haixing Dai,Lin Zhao,Ruidong Zhang,Wei Zhao,Zhenyuan Yang,Jingyuan Chen,Peilong Wang,Wei Ruan,Hui Wang,Huan Zhao,Jing Zhang,Yiming Ren,Shihuan Qin,Tong Chen,Jiaxi Li,Arif Hassan Zidan,Afrar Jahin,Minheng Chen,Sichen Xia,Jason Holmes,Yan Zhuang,Jiaqi Wang,Bochen Xu,Weiran Xia,Jichao Yu,Kaibo Tang,Yaxuan Yang,Bolun Sun,Tao Yang,Guoyu Lu,Xianqiao Wang,Lilong Chai,He Li,Jin Lu,Xin Zhang,Bao Ge,Xintao Hu,Lian Zhang,Hua Zhou,Lu Zhang,Shu Zhang,Zhen Xiang,Yudan Ren,Jun Liu,Xi Jiang,Yu Bao,Wei Zhang,Xiang Li,Gang Li,Wei Liu,Dinggang Shen,Andrea Sikora,Xiaoming Zhai,Dajiang Zhu,Tuo Zhang,Tianming Liu
### Background
本研究全面评估了OpenAI的o1-preview大型语言模型在各种复杂推理任务中的表现，这些任务涵盖了多个领域，包括计算机科学、数学、自然科学、医学、语言学和社会科学。通过严格的测试，o1-preview展示了卓越的能力，在编码挑战、科学推理、语言处理和创意问题解决等领域均达到了人类水平或更好的表现。模型特别擅长于要求复杂推理和跨领域知识整合的任务。尽管存在一些局限性，如在简单问题上偶尔出现错误，以及处理某些高度专业化概念的挑战，但总体结果表明朝着通用人工智能（AGI）取得了显著进展。
### Innovation
o1-preview展示了卓越的能力，在编码挑战、科学推理、语言处理和创意问题解决等领域达到了人类水平或更好的表现。特别在编码挑战中的83.3%解决率超过了许多人类专家，在放射科报告生成中的优异表现，高中学数学推理任务的100%准确率，芯片设计任务中的出色表现，以及在人文学科和地质学领域的显著专业知识。此外，o1-preview在定量投资和社交媒体分析方面也表现出了强大的能力，包括情感分析和情绪识别。这些成就表明了向AGI迈进的重要进展，但同时也指出了实际应用中的某些局限性。
### Conclusion
尽管o1-preview在处理简单任务时偶尔出现错误，且在某些高度专业化概念的理解上存在挑战，然而其在多个领域的出色表现总体表明，向AGI方向发展取得了重要进步。通过进一步研究和优化，有望克服现有局限性，实现更广泛的实际应用。
## 371. `cs.CL` - Nyay-Darpan: 通过总结和案例检索增强印度消费者法律中的决策 [PDF](https://arxiv.org/pdf/2507.06090), [HTML](https://arxiv.org/abs/2507.06090)
### Authors
Swapnil Bhattacharyya,Shrey Ganatra,Harshvivek Kashid,Spandan Anaokar,Shruti Nair,Reshma Sekhar,Siddharth Manohar,Rahul Hemrajani,Pushpak Bhattacharyya
### Background
AI在刑事和民事领域的司法协助和案例预测方面已被广泛研究，但在消费者法律领域，尤其是印度，这一应用尚属空白。因此，本研究旨在填补这一空白。
### Innovation
提出Nyay-Darpan，这是一种创新的两合一框架，包括（i）总结消费者案件文件，和（ii）检索类似案件判决以协助消费者纠纷解决的决策。此外，还创新性地引入了总结质量评估的新方法，涵盖了75%以上的相似案例预测准确率和约70%的材料总结评估指标。
### Conclusion
Nyay-Darpan系统在类似案例预测和材料总结评估方面达到了高精度，体现了其实用效果。此外，Nyay-Darpan框架和数据集将被公开发布，以促进可再现性和进一步的研究。
## 372. `cs.CL` - Adsorb-Agent：通过大型语言模型代理自主识别稳定的吸附配置 [PDF](https://arxiv.org/pdf/2410.16658), [HTML](https://arxiv.org/abs/2410.16658)
### Authors
Janghoon Ock,Radheesh Sharma Meda,Tirtha Vinchurkar,Yayati Jadhav,Amir Barati Farimani
### Background
吸附能是催化反应活性的关键描述符，确定吸附能需要评估大量吸附剂-催化剂配置，这使得计算成本较高。当前方法依赖于耗时的穷尽采样，这不能保证识别全局最低能量状态。
### Innovation
介绍了Adsorb-Agent，这是一种基于大规模语言模型的大脑智能（LLM）代理，用于高效识别对应全局最低能量的稳定吸附配置。Adsorb-Agent利用内置知识和推理能力，战略性地探索配置，显著减少了初始设置的数量，并提高了能量预测的准确性。研究还评估了不同的大规模语言模型，如GPT-4o、GPT-4o-mini、Claude-3.7-Sonnet和DeepSeek-Chat，作为Adsorb-Agent的推理引擎，结果显示GPT-4o整体性能最强。在20种不同系统上测试时，Adsorb-Agent在84%的情况下识别出类似的吸附能，在35%的情况下实现了较低的能量，尤其是在复杂系统中表现出色。此外，在47%的层间系统和67%的大吸附区系统中找到了更低的能量。
### Conclusion
这些结果表明，Adsorb-Agent有可能通过减少计算成本并提高预测可靠性来加速催化剂的发现，相比耗尽搜索方法具有明显优势。
## 373. `cs.CL` - 一只鱼，两只鱼，但不是整个大海：对齐减少了语言模型的概念多样性 [PDF](https://arxiv.org/pdf/2411.04427), [HTML](https://arxiv.org/abs/2411.04427)
### Authors
Sonia K. Murthy,Tomer Ullman,Jennifer Hu
### Background
社会科学研究和心理学领域的研究人员最近提出了使用大型语言模型（LLMs）替代人类参与行为研究的主张。除了对LLMs是否准确捕捉群体模式的争论外，还引发了关于LLMs是否能捕捉到类似人类的概念多样性的问题。此外，人们对后训练对齐（如RLHF或RLAIF）是否会影响模型的内部多样性存在争议。受人类研究的启发，本研究采用了一种新方法，通过将模拟个体的内部变异性与群体层面的变异性联系起来，来测量生成的LLM“群体”的概念多样性。研究通过测试两种富含人类行为数据的领域中的未对齐和对齐模型，评估了这些问题，结果显示没有任何模型可以达到人类的概念多样性，但对齐模型通常表现出比其指令微调版本更少的概念多样性。这些发现揭示了提升模型价值对齐和降低其概念表示的多样性之间可能存在权衡关系的问题。
### Innovation
研究利用了一种新的方法来测量合成生成的LLM“群体”的概念多样性，即通过关联模拟个体的内部变异性与群体层面的变异性。研究通过评估不同领域的未对齐和对齐模型，探讨了对齐处理后模型内部多样性减少的现象，并提出了可能存在的权衡关系，即随着模型价值对齐的提升，其概念表示的多样性可能会减少。
### Conclusion
研究发现，没有模型能够达到人类的概念多样性，但对齐模型通常表现出较少的概念多样性。这些结果强调了在提高模型价值对齐和减少其概念表示的多样性之间可能存在潜在的权衡取舍。
## 374. `cs.CL` - 新闻与负荷：英国和爱尔兰多时期区域电力需求的社会和经济驱动因素预测 [PDF](https://arxiv.org/pdf/2406.06641), [HTML](https://arxiv.org/abs/2406.06641)
### Authors
Yun Bai,Simon Camal,Andrea Michiorri
### Background
电力需求与经济活动和天气模式之间的关系已经十分明确。然而，这项研究进一步探讨了电力需求与社会维度之间的联系。通过大规模新闻语料库的自然语言处理，研究将动态的社会信息嵌入到能源需求建模和预测方法中。这项研究考察了英格兰和爱尔兰五个地区的区域电力需求，并考虑了1至30天的时间范围。研究采用的文本特征包括从新闻中提取的词频、主题和词嵌入等中心概念。结果显示，这些文本特征与军事冲突、交通运输、全球疫情、区域经济和国际能源市场等内容相关，并与地区电力需求呈现因果关系，该结论使用Granger因果性和双机器学习方法进行了验证。
### Innovation
这项研究将社会因素（通过新闻文本分析）整合到电力需求建模和预测中，这是以往研究的创新之处。研究采用动态的社会特征，提升了电力需求预测的准确性。
### Conclusion
研究发现，经济指标在英格兰东 Midlands 和北爱尔兰地区影响较大，而在英格兰西 Midlands 和西南部地区，社会指标更多地影响电力需求。使用这些社会和经济因素可以提高预测准确性约6%。
## 375. `cs.CL` - LLMs预知未来吗？基于每日新闻的连续评估 [PDF](https://arxiv.org/pdf/2411.08324), [HTML](https://arxiv.org/abs/2411.08324)
### Authors
Hui Dai,Ryan Teehan,Mengye Ren
### Background
现有的大型语言模型（LLMs）评估基准会因新模型和训练数据的出现而迅速过时。这些评估基准在评估LLM随时间性能变化方面也存在不足，因为它们只包含不随时间变化的固定问题集。为解决这些问题，该研究提出使用未来事件预测作为一种连续评估方法，来检验LLMs的跨时间归纳和预测能力。通过自动从每日新闻生成问答对，挑战LLMs预测“未来”的事件结果。
### Innovation
该研究提出了Daily Oracle基准，通过自动从每日新闻生成问答对，挑战LLMs预测未来事件结果，这为评估LLMs随时间变化的性能提供了一种新颖的方法。同时，研究发现，随着预训练数据的过时，LLM的性能会随时间下降，而检索增强生成（RAG）虽然有可能提高预测的准确性，但仍存在性能下降的问题，这表明需要持续更新模型。
### Conclusion
该研究揭示了在预训练数据过时的情况下，LLM的性能会随着时间的推移而下降。虽然检索增强生成（RAG）可以提高预测的准确性，但它并不能解决性能下降的问题，表明必须持续对模型进行更新。
## 376. `cs.CL` - BERT修复之力：针对特定任务的微调如何恢复受损的语言模型 [PDF](https://arxiv.org/pdf/2406.14459), [HTML](https://arxiv.org/abs/2406.14459)
### Authors
Shijie Han,Zhenyu Zhang,Andrei Arsene Simion
### Background
语言模型如BERT在句子分类任务中表现出色，这是由于它们在广泛的数据上进行了大量的预训练，但它们在参数篡改后的鲁棒性尚未被探索。为了更好地理解这一点，研究者们观察了当一个语言模型在某种意义上被“破坏”（即一些参数被篡改，然后通过微调恢复）时会发生什么。在对BERT变体的不同层次进行战略性篡改后，研究人员发现篡改的模型很难完全恢复其原始性能，且更高的篡改程度会导致更严重的性能下降。值得注意的是，对底层参数的篡改，由于这些参数影响基本的语言特征，比对高层参数的篡改更为有害。这项研究为理解在不利条件下语言模型的鲁棒性和适应性提供了洞察，为开发能够抵御参数干扰的抗复性NLP系统提供了策略指导。
### Innovation
研究发现了BERT变体在不同层次篡改后，模型恢复性能的差异，并特别指出底层参数篡改比高层参数篡改对模型性能影响更大。这项工作揭示了语言模型在参数被篡改后的鲁棒性问题，并为防止和减轻这类问题提供了策略依据。这为未来开发抗复性NLP系统提供了重要参考。
### Conclusion
研究揭示了看似“修复”后的语言模型在某些参数被篡改后无法完全恢复其初始性能的现象，强调了底层特征在模型鲁棒性中的重要性。本研究对于理解语言模型在面对潜在参数干扰时的恢复能力，以及指导未来基于特定任务的模型设计具有重要意义。
## 377. `cs.CL` - 早期退出和即时信心翻译质量估计 [PDF](https://arxiv.org/pdf/2502.14429), [HTML](https://arxiv.org/abs/2502.14429)
### Authors
Vilém Zouhar,Maike Züfle,Beni Egressy,Julius Cheng,Mrinmaya Sachan,Jan Niehues
### Background
机器翻译中的质量评估在评估和生成两个方面都普遍存在。然而，现有的质量评估模型通常不够透明且计算密集，这使得它们在大规模管道中难以实施。
### Innovation
本文提出了两种创新：(1) 降低全局质量评估的成本；(2) 开发一种负担得起的不确定性估计方法。引入了Instant Confidence COMET，这种具有不确定性的质量评估模型能在极低的成本下达到与以往方法相同的效果。此外，还提出了Early-Exit COMET，能够在模型早期层进行质量评分和可信度计算，从而提前退出计算和降低评估成本。在机器翻译重排序中应用了该模型，并结合上置信心边界多臂老虎机算法来在不运行完整评估模型的情况下从大池中选择最佳候选。
### Conclusion
两种方法在计算需求上降低了50%，仅有一小部分性能下降，在评估和重排序中取得了成功。
## 378. `cs.CL` - 句法依赖距离分布 [PDF](https://arxiv.org/pdf/2211.14620), [HTML](https://arxiv.org/abs/2211.14620)
### Authors
Sonia Petrini,Ramon Ferrer-i-Cancho
### Background
句子的句法结构可以用图表示，顶点是单词，边表示单词间的句法依赖关系。两个相关单词之间的距离定义为它们的位置差。先前的研究认为，句法依赖距离的分布遵循幂律分布。但本文作者提出，可能存在两个指数阶段，在某个断点之后概率衰减发生变化，这可能反映了从词块处理到更高层次结构的过渡。
### Innovation
提出了一种新的模型，该模型包含两个指数阶段，在某个断点之后概率衰减发生变化。这种模型适用于20种语言，不论句子长度和标注风格。断点值在4-5个单词之间变化较小，表明可以同时处理的词的数量在很大程度上脱离了特定语言的限制。概率在断点后逐渐减慢，这与最近引入的最优性得分以及句法依赖关系的紧密性有关。
### Conclusion
在研究的20种语言中，一个具有两个阶段的模型最佳，第一个阶段要么遵循指数衰减要么遵循幂律衰减。断点值在4-5个单词之间变化较小，这表明语言之间处理多个词的能力在很大程度上是一致的。模型概率在断点之后逐渐减慢，这与句法依赖关系的紧密性以及句长的相关性有关。
## 379. `cs.CL` - 通过显式知识边界建模提升语言模型可靠性 [PDF](https://arxiv.org/pdf/2503.02233), [HTML](https://arxiv.org/abs/2503.02233)
### Authors
Hang Zheng,Hongshen Xu,Yuncong Liu,Lu Chen,Pascale Fung,Kai Yu
### Background
大型语言模型（LLMs）容易产生幻觉，特别是当它们处理超出知识边界的问题时，源于它们的自我意识错位。现有的缓解策略依赖于不确定性估计或查询拒绝机制，但这些方法在计算效率上存在缺点，并且牺牲了帮助性。
### Innovation
本文提出了显式知识边界建模（EKBM）框架，通过集成快慢两种推理系统来平衡可靠性和可用性。EKBM框架首先使用快速模型生成带有置信度标签的响应，便利立即使用高置信度输出，不确定的预测则触发慢速模型进行精确度改进。提出了混合训练管道，增强了自我意识而不损害任务性能。
### Conclusion
在对话状态跟踪任务上的评估表明，EKBM比基于不确定性的基线模型具有更优秀的模型可靠性。进一步的分析显示，这种改进显著提高了准确性，同时保持了较低的计算开销。该框架为在敏感应用中部署可靠的语言模型提供了一种可扩展的范式，有效平衡了准确性和实用性。
## 380. `cs.CL` - 基于Transformer的长文本上下文扩展方法综述及评估 [PDF](https://arxiv.org/pdf/2503.13299), [HTML](https://arxiv.org/abs/2503.13299)
### Authors
Yijun Liu,Jinzheng Yu,Yang Xu,Zhongyang Li,Qingfu Zhu
### Background
基于Transformer的大型语言模型（LLMs）在自然语言处理（NLP）领域中广泛应用，特别是在短文本任务中表现出色。然而，在处理长上下文时，这些模型的性能会下降，主要原因在于一些挑战的存在。
### Innovation
本文综述了处理长上下文的相关方法，并提出了一种分类方法，将这些方法归类为四类：位置编码、上下文压缩、检索增强和注意力模式。同时，还组织了相关数据、任务和评估指标，基于现有的长上下文基准数据集进行评估，并总结了该领域未解决的问题，提出了未来发展方向的看法。
### Conclusion
总结了长上下文处理领域存在的问题，并对未来的发展提出了观点。
## 381. `cs.CL` - GMLM：将图神经网络与语言模型结合以进行异质节点分类 [PDF](https://arxiv.org/pdf/2503.05763), [HTML](https://arxiv.org/abs/2503.05763)
### Authors
Aarush Sinha
### Background
将结构化图形数据与节点中的丰富文本信息结合，对异质节点分类构成了显著挑战。现有方法往往因计算成本高昂或难以有效融合多种数据模态而效果不佳。
### Innovation
提出了Graph Masked Language Model (GMLM)这一新的架构，该架构通过图神经网络（GNNs）与预训练语言模型（PLMs）的高效结合解决上述问题。GMLM的核心创新点包括：(i) 一种动态的活跃节点选择策略，以便大规模处理PLM文本；(ii) 一种针对GNN的对比预训练阶段，使用软掩码并带有可学习的图形[MASK]标记，以增强结构表示的稳健性；(iii) 一种专门融合RGCN基GNN嵌入和PLM（GTE-Small & DistilBERT）嵌入的模块。
### Conclusion
在异质基准（Cornell, Wisconsin, Texas）上的广泛实验表明，GMLM的性能优越。值得注意的是，GMLM（DistilBERT）在Cornell上的准确率比上一最佳基线提高了4.7%以上，在Texas上提高了2.0%以上。这项工作强调了针对PLM参与和特定模态预训练的好处，以提高在丰富文本图上的高效学习。
## 382. `cs.CL` - 可计算变换器以实现灵活的条件生成 [PDF](https://arxiv.org/pdf/2502.07616), [HTML](https://arxiv.org/abs/2502.07616)
### Authors
Anji Liu,Xuejie Liu,Dayuan Zhao,Mathias Niepert,Yitao Liang,Guy Van den Broeck
### Background
非自回归（NAR）生成模型因其能以比自回归（AR）模型更原则的方式处理多样化的条件生成任务而具有价值，特别是在处理无条件生成任务时，NAR模型如扩散语言模型已经显示出优于类似规模的AR模型（如GPT）的性能。但是，这种改进并不总是能够转化为条件生成任务的改善。原因在于NAR模型在处理未在训练中见过的条件概率查询（即未知变量的集合）时存在泛化难度。
### Innovation
Tracformer，一种基于Transformer的生成模型，通过引入稀疏Transformer编码器来捕捉局部和全局上下文信息，并通过解码器实现条件生成，从而更稳健地处理不同的条件生成任务。
### Conclusion
实验证明，Tracformer在文本建模的条件下生成性能上超越了近期的扩散和AR模型基线，实现了最先进水平的表现。
## 383. `cs.CL` - OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training Tokens [PDF](https://arxiv.org/pdf/2504.07096), [HTML](https://arxiv.org/abs/2504.07096)
### Authors
Jiacheng Liu,Taylor Blanton,Yanai Elazar,Sewon Min,YenSung Chen,Arnavi Chheda-Kothary,Huy Tran,Byron Bischoff,Eric Marsh,Michael Schmitz,Cassidy Trier,Aaron Sarnat,Jenna James,Jon Borchardt,Bailey Kuehl,Evie Cheng,Karen Farley,Sruthi Sreeram,Taira Anderson,David Albright,Carissa Schoenick,Luca Soldaini,Dirk Groeneveld,Rock Yuren Pang,Pang Wei Koh,Noah A. Smith,Sophie Lebrecht,Yejin Choi,Hannaneh Hajishirzi,Ali Farhadi,Jesse Dodge
### Background
随着大规模语言模型的应用越来越广泛，人们对其输出的透明性和可追踪性提出更多要求。现有工具在追踪模型输出与原始训练数据之间的关联时存在延迟或准确度不足的问题。
### Innovation
OLMoTrace 是首个能够实时追踪语言模型输出至其完整、多万亿标记大小的训练数据的系统。它利用扩展版的 infini-gram，能够在几秒内返回追踪结果，有助于用户通过训练数据了解模型的行为，并探索事实核对、幻觉和语言模型创造力等方面的问题。
### Conclusion
OLMoTrace 是一个开源项目，可供公开使用。它突破了实时和高效追踪模型输出至大规模训练数据的技术障碍，为理解和改进语言模型的应用提供了有力工具。
## 384. `cs.CL` - 重新思考诱导头机制中的关联记忆机制 [PDF](https://arxiv.org/pdf/2412.11459), [HTML](https://arxiv.org/abs/2412.11459)
### Authors
Shuo Wang,Issei Sato
### Background
诱导头机制是计算电路的一部分，用于在上下文学习（ICL）中让大规模语言模型（LLMs）在无需微调的情况下适应新任务。尽管大多数现有工作解释了获得如此强大机制的训练动态，但模型如何在长上下文中协调信息并利用预训练的双向知识在下一个token预测中的机制仍不明确。
### Innovation
本文从关联记忆的角度出发，探索了两层变压器如何全面捕获上下文信息，并将其与预训练的双向知识平衡应用于下个token预测。通过理论分析注意层的权重矩阵表示以及给定由双向模型生成的提示时的结果概率（logits），设计特定的提示来评估训练的变压器输出是否符合理论结果。
### Conclusion
研究结果显示，两层变压器能够很好地结合预训练的双向知识和上下文信息，提供更准确的下一个token预测。这为理解大型语言模型在不依赖微调的情况下适应新任务的能力提供了新的视角。
## 385. `cs.CL` - 低资源语言生成语言建模中的数据稀缺性突破：一项系统性回顾 [PDF](https://arxiv.org/pdf/2505.04531), [HTML](https://arxiv.org/abs/2505.04531)
### Authors
Josh McGiff,Nikola S. Nikolov
### Background
生成语言模型随着ChatGPT和Google Gemini等服务的出现而迅速流行。尽管这些模型在提高生产力和促进交流方面展现了潜力，但它们主要服务于资源丰富语言如英语等，加剧了自然语言处理（NLP）中的语言不平等。现有研究主要集中在高资源语言上，缺乏对低资源语言（LRL）的关注和数据补充技术。本研究旨在填补这一空白，通过系统性回顾来检验数据稀缺性在低资源语言生成语言建模中的解决策略，总结过去的研究成果和挑战，以促进低资源语言的平等生成语言系统的构建。
### Innovation
本研究首次系统性地回顾并总结了针对低资源语言生成语言建模中数据稀缺性问题的技术策略，包括单语数据增强、反向翻译、多语言训练和提示工程等，并分析了模型架构选择的趋势、语言家族的代表性以及评估方法的发展。研究还指出了这些方法在实际应用中依赖和不足，如对基于变换器的模型的过度依赖和对低资源语言的小规模聚焦，以及各研究间缺乏一致的评估标准。通过分析这些趋势和挑战，本研究为未来的研究提供了有价值的洞见和建议。
### Conclusion
本研究号召扩展方法以涵盖更广泛的低资源语言，并详细列出了构建公平的生成语言系统所面临的开放问题。研究强调了开发包容性人工智能工具以支持被忽视的语言的重要性，这是缩小语言技术差距的重要步骤。随着大规模语言技术对世界的影响越来越大，保护语言多样性变得愈发重要。
## 386. `cs.CL` - MAMUT：一种用于生成专门为语言模型训练的数学公式修改框架 [PDF](https://arxiv.org/pdf/2502.20855), [HTML](https://arxiv.org/abs/2502.20855)
### Authors
Jonathan Drechsel,Anja Reusch,Steffen Herbold
### Background
数学公式是许多科学领域中一个基本且广泛使用的组件，用作表达复杂概念和关系的国际通用语言。尽管最先进的转换器模型在处理和理解自然语言方面表现出色，但它们在处理和理解数学符号方面遇到了挑战，因为数学符号具有复杂的结构和多样的表示形式。
### Innovation
本文介绍了一种名为MAMUT的新框架，能够生成给定数学公式在LaTeX标记语言中的等价版本和误用版本，有效地捕捉相同概念在不同表示形式中的数学多样性。基于MAMUT框架，作者生成了包含不同符号的四大数学数据集。实验结果显示，使用这些数据集训练的模型在数学检索任务上达到了新的性能峰值。
### Conclusion
本文发表了MAMUT代码、生成的数据集和预训练的数学模型，证明了MAMUT框架在增强数学内容编码方面的有效性，并展示了使用这些新数据集训练的模型在数学检索任务上的优越性能。
## 387. `cs.CL` - 真理神经元 [PDF](https://arxiv.org/pdf/2505.12182), [HTML](https://arxiv.org/abs/2505.12182)
### Authors
Haohang Li,Yupeng Cao,Yangyang Yu,Jordan W. Suchow,Zining Zhu
### Background
尽管语言模型在各种工作流程中表现出色并且广泛应用，但它们有时会产生不真实的回答。由于我们对如何在模型中机械地编码真实性知之甚少，这影响了模型的可靠性和安全性。本文的研究背景就是针对这一问题展开的。
### Innovation
本文提出了一种识别模型中真理神经元的方法，这些神经元以知识领域无关的方式编码真实性。实验表明，不同规模的语言模型都存在真理神经元，这表明神经元层面的真实性编码是一个共同的特性。真理神经元在层中的分布模式与之前的真实性几何学发现相符。通过抑制通过TruthfulQA数据集找到的真理神经元的激活，模型在TruthfulQA和其他基准测试上的性能下降，这表明真实性机制并不是针对特定数据集。
### Conclusion
研究结果为语言模型中真实性机制提供了新的见解，并指出了提高其可信性和可靠性的潜在方向。
## 388. `cs.CL` - 透过不同视角看 sarcasm：大型视觉语言模型对多模态 sarcasm 的感知分析 [PDF](https://arxiv.org/pdf/2503.12149), [HTML](https://arxiv.org/abs/2503.12149)
### Authors
Junjie Chen,Xuyang Liu,Subin Huang,Linfeng Zhang,Hang Yu
### Background
随着大型视觉语言模型（LVLMs）在展现越来越接近人类的能力方面的进步，一个关键问题浮现出来：不同的LVLMs是否以不同的方式解释多模态的 sarcasm？一个模型能否从多角度理解 sarcasm，就像人类一样？为了解这个问题，作者引入了一个分析框架，使用系统设计的提示来评估现有多模态 sarcasm 数据集。论文对12个最先进的LVLMs进行了评估，通过2,409个样本，探讨了模型间的解释性差异，集中在置信水平、与数据集标签的一致性以及对含糊不清的“中性”案例的识别上。研究发现，LVLMs在解释 sarcasm 方面存在显著差异，即便在同一模型下不同提示也会有不同的表现。尽管分类导向的提示导致内部一致性较高，但当任务转向解释性推理时，模型间的分歧极为明显。这些结果挑战了二元标签模式，突显出 sarcasm 的主观性。作者建议从严格的标注方案转向多视角、具有不确定性意识的建模，提供更深入的多模态 sarcasm 理解洞察。代码和数据可在该链接找到：this https URL
### Innovation
这项研究引入了一个分析框架，通过系统设计的提示来评估现有的多模态 sarcastic 数据集中的12个最先进的LVLMs，探讨了模型间解释性差异的主要发现，提出了从严格的标注方案转向多视角、具有不确定性意识的建模的观点，提供更深入的多模态 sarcasm 理解洞察。
### Conclusion
这项研究通过多个视角探讨了大型视觉语言模型在解释多模态 sarcasm 方面的行为差异，并表明，尽管某些分类任务可以提高内部一致性，但用于解释性的任务则显示出显著的模型偏差，突显了 sarcasm 的主观性，挑战了二元标签模式。作者建议，未来的研究应倾向于更灵活和多角度的建模，以更好地理解和处理 sarcasm。
## 389. `cs.CL` - PulseReddit: 一种用于基准测试MAS的新型Reddit数据集，在高频加密货币交易中的应用 [PDF](https://arxiv.org/pdf/2506.03861), [HTML](https://arxiv.org/abs/2506.03861)
### Authors
Qiuhan Han,Qian Wang,Atsushi Yoshikawa,Masayuki Yamamura
### Background
高频交易（HFT）对于加密货币市场至关重要，需要快速的决策。像Reddit这样的社交媒体平台提供了有价值但未充分利用的信息，用于高频率、短期交易。研究人员利用大规模Reddit讨论数据与高频加密货币市场统计数据创建了一个名为PulseReddit的新数据集，旨在研究社会情感对交易表现的影响。
### Innovation
首次将大规模Reddit讨论数据与高频加密货币市场统计数据相结合，使用大型语言模型（LLM）为基础的多智能体系统（MAS）进行了广泛的经验研究，以评估PulseReddit数据对交易绩效的影响。实验表明，结合PulseReddit数据的MAS在牛市市场中表现更优，并且在不同市场环境下表现出更高的适应性。此外，研究还提供了不同LLM性能和效率的比较，并为在高频交易应用中的模型选择提供了实际建议。
### Conclusion
PulseReddit和研究结果为高频交易中多智能体系统的研究奠定了基础，证明了集成社交媒体带来的实际好处。
## 390. `cs.CL` - 联合波束形成和带发言者归属的ASR技术在真实远场会议转录中的应用 [PDF](https://arxiv.org/pdf/2410.21849), [HTML](https://arxiv.org/abs/2410.21849)
### Authors
Can Cui,Imran Ahamad Sheikh,Mostafa Sadeghi(MULTISPEECH),Emmanuel Vincent(MULTISPEECH)
### Background
远场会议转录是一个具有挑战性的任务，当前最先进的端到端讲者分配自动语音识别（SA-ASR）架构缺乏多通道噪声和混响降噪前置处理模块，这限制了其性能。
### Innovation
该论文介绍了一种联合波束形成和SA-ASR的方法，首先提出了一个数据对齐和增强方法，对真实的会议数据进行神经波束形成器预训练。然后比较了固定、混合和全神经波束形成器作为SA-ASR模型的前置模块。最后，联合优化全神经波束形成器和SA-ASR模型。实验证实在真实AMI语料库上，虽然基于多帧跨通道注意力的声道融合无法提高ASR性能，但将SA-ASR微调到固定波束形成器输出以及联合微调SA-ASR与神经波束形成器分别降低了8%和9%的单词错误率。
### Conclusion
研究结果表明，通过联合波束形成和SA-ASR模型的优化方法，可以在真实远场会议转录中显著提高ASR性能。
## 391. `cs.CL` - FaithfulRAG：面向事实层面冲突建模的上下文忠实检索增强生成 [PDF](https://arxiv.org/pdf/2506.08938), [HTML](https://arxiv.org/abs/2506.08938)
### Authors
Qinggang Zhang,Zhishang Xiang,Yilin Xiao,Le Wang,Junhui Li,Xinrun Wang,Jinsong Su
### Background
现有的大语言模型（LLMs）增强检索系统的应用显示了在处理知识密集型任务方面的巨大潜力，但这些模型经常面临不忠实问题，即生成的输出要么忽略检索到的上下文，要么不一致地将其与模型的参数化知识融合。特别是在知识冲突的情况下，检索到的上下文与模型的参数化知识相冲突，这种问题尤为严重。现有的忠实RAG方法通过精心设计的提示或修改解码策略强制上下文一致性，但我们的分析表明，这种方法通过强制抑制模型的参数化知识来达到忠实性，这破坏了模型的内部知识结构，并增加了误解上下文的风险。因此，本文提出了FaithfulRAG框架，通过显式建模模型参数化知识与检索到的上下文之间的差异来解决知识冲突。
### Innovation
FaithfulRAG是一个新颖的框架，通过在事实层面识别冲突知识并设计自我思考过程来解决知识冲突。这一过程允许LLMs对矛盾事实进行推理和整合，然后再生成响应。实验结果表明，这种方法优于当前最先进的方法。该方法还强调了对模型参数化知识和检索到的上下文之间的差异建模的重要性，从而在保持模型忠实度的同时不破坏其内部知识结构。
### Conclusion
研究通过FaithfulRAG框架提高了检索增强生成任务的忠实性，具体表现为在保持模型内部知识结构的基础上解决了知识冲突，显著提升了模型对检索到的上下文的理解和整合能力。在广泛实验基础上，证明了该方法的有效性和优越性。源代码可在文中提供的链接处获取。
## 392. `cs.CL` - 语言模型中基于特征提取与引导的增强链式推理 [PDF](https://arxiv.org/pdf/2505.15634), [HTML](https://arxiv.org/abs/2505.15634)
### Authors
Zihao Li,Xu Wang,Yuzhe Yang,Ziyu Yao,Haoyi Xiong,Mengnan Du
### Background
大型语言模型（LLMs）能够通过链式思考（CoT）技术解决推理和数学问题。通过增加CoT的长度，可以使模型在解决复杂问题时获得更好的推理能力，但同时可能需要大量的高质量CoT数据和微调，这些过程成本较高。受DeepSeek-R1深度思考理念的启发，本文提出了一种新的方法，通过特征提取和引导技术提升LLMs的推理能力，而不需要使用额外的数据集。
### Innovation
本文提出的方法首先使用稀疏自动编码器（SAEs）从原始的CoT中提取特征，然后利用这些特征引导LLM内部状态的数据生成过程。进一步提出了一个基于自动编码器的引导算法的替代方案，直接从LLM的残差激活中计算引导方向，从而避免了使用明确的自动编码器。实验结果表明，本文的方法在增强LLMs的推理能力方面效果显著。
### Conclusion
基于特征提取和引导技术，本文的方法成功提升了LLMs的推理能力，尤其是在无需额外数据集的情况下。两种基于SAEs的方法和后来的SAE-free方法都证明了对LLMs推理能力的显著增强。
## 393. `cs.CL` - MEF：针对黑盒大型语言模型评估漏洞的能力感知多加密框架 [PDF](https://arxiv.org/pdf/2505.23404), [HTML](https://arxiv.org/abs/2505.23404)
### Authors
Mingyu Yu,Wei Wang,Yanjie Wei,Sujuan Qin,Fei Gao,Wenmin Li
### Background
近期，对抗性监狱突破攻击的发展揭示了大型语言模型（LLMs）中存在的重大漏洞，这些漏洞可以通过越来越复杂的提示操控来规避对齐保护措施。研究背景在于提升监狱突破策略的有效性，通过定制化地针对目标模型的语义理解能力。此项研究基于不同的语义理解能力将LLMs分为两类，并设计了相应的适应性攻击策略。
### Innovation
作者提出了一种能力感知的多加密框架（MEF），旨在评估黑盒LLMs的漏洞。它通过分层语义变异和双端加密技术，以绕过输入、推断和输出层面的防御措施。论文的核心创新点在于提出了一种对LLMs进行分类的方法，基于它们的语义理解能力将它们划分为类型I和类型II，并为每种类型设计了适应性攻击策略。
### Conclusion
研究结果表明，MEF在GPT-4o上的监狱突破成功率达到了98.9%，且揭示出了当前LLMs对齐防御的漏洞。
## 394. `cs.CL` - LLMs之外定制对话：基于RL的对话管理器 [PDF](https://arxiv.org/pdf/2506.19652), [HTML](https://arxiv.org/abs/2506.19652)
### Authors
Lucie Galland,Catherine Pelachaud,Florian Pecune
### Background
本文的工作是在现有的大语言模型（LLMs）基础上，提出了一种新的框架，结合了带有RL基础对话管理器的开放式对话系统，旨在实现特定目标的对话。通过对结构化的对话阶段进行层次化强化学习建模，并使用元学习来增强对不同用户类型的适应性，本文的方法提高了系统的适应性和效率，使其能够在有限的数据下学习，灵活地在对话阶段之间过渡，并个性化回应不同的患者需求。该方法应用于动机访谈场景，目的是促进行为改变，并通过奖励机制证明了该对话管理器在与最先进的LLM基线相比时的表现更好，显示了将LLM条件化以创建具有特定目标的开放式对话系统的潜在益处。
### Innovation
本文提出了一种新的框架，结合了大型语言模型和基于强化学习的对话管理器，特别是通过层次化强化学习建模对话阶段，并使用元学习提高适应性，以增强对话系统的适应性和效率，尤其是在有限数据和不同的用户需求下。这种方法在动机访谈场景中验证了其有效性，并展示了相比最先进的LLM基线的优越性
### Conclusion
研究表明，该对话管理器能够成功应用到动机访谈场景中，帮助患者改变行为，同时也证明了这种框架在开放式对话系统中的潜力，尤其是在具有特定目标的场景下。该方法展示了强化学习和元学习在对话系统中的有效结合，具有广阔的应用前景。
## 395. `cs.CL` - FRAME: 反馈精炼代理方法以增强医学研究洞察 [PDF](https://arxiv.org/pdf/2505.04649), [HTML](https://arxiv.org/abs/2505.04649)
### Authors
Chengzhang Yu,Yiming Zhang,Zhixin Liu,Zenghui Ding,Yining Sun,Zhanpeng Jin
### Background
通过大型语言模型（LLMs）实现科学研究的自动化带来了巨大机遇，但同时也遇到了知识综合和质量保证的关键挑战。
### Innovation
本文介绍了Feedback-Refined Agent Methodology（FRAME），一种通过迭代精炼和结构化反馈来增强医疗论文生成的新框架。该方法包含三个关键创新点：(1) 结构化数据集构建方法，通过迭代精炼将4,287篇医疗论文分解为基本研究组成部分；(2) 整合生成器、评估器和反思者代理的三部分架构，通过基于度量的反馈逐步提高内容质量；(3) 综合评估框架，结合统计指标与基于人类基准的评估。
### Conclusion
实验结果证明了FRAME的有效性，与传统方法相比，在多项模型和评估维度上实现了显著改进。人类评估确认，FRAME生成的论文在质量上与人类撰写的文献相当，并特别擅长综合未来研究方向。研究表明，我们的工作可以有效辅助医学研究，为自动化的医学研究论文生成提供坚实的基础，同时维持严格的学术标准。
## 396. `cs.CL` - 大规模语言模型指令跟随通过增强注意力 [PDF](https://arxiv.org/pdf/2506.13734), [HTML](https://arxiv.org/abs/2506.13734)
### Authors
Vitoria Guardieiro,Adam Stein,Avishree Khare,Eric Wong
### Background
控制大型语言模型（LLMs）的生成仍然是确保其安全可靠部署的核心挑战。尽管提示工程和微调是常用的方法，但最近的研究探讨了潜在引导技术，这种方法通过改变LLMs内部激活来引导生成，以轻量级的方式指导生成。然而，后续的研究表明，潜在引导的有效性受到限制，往往不如简单的指令提示。为了应对这一限制，作者首先建立了不同行为的标准基准，用于评估引导技术。基于这一基准，提出了指令注意力增强（InstABoost），这是一种潜在引导方法，通过改变模型在生成过程中的注意力来增强指令提示的强度。InstABoost结合了现有方法的优点，并且被前期研究理论支持，表明在基于变压器的模型中的上下文规则遵循可以通过操控指令注意力来控制。通过实验证明，InstABoost在控制成功率方面优于传统提示和潜在引导方法。
### Innovation
提出了一种新的命名为InstABoost的潜在引导技术，通过改变模型在生成过程中的注意力，增强了指令提示的强度，结合了现有方法的优点。该技术得到了前期关于通过操控指令注意力可以控制变压器模型上下文规则遵循的研究理论支持，通过实验证明其在控制成功率方面表现更为优越。
### Conclusion
InstABoost展示了在控制LLMs生成方面相较于传统提示和潜在引导技术的优越性能，可以用于进一步提高LLMs的安全性和可靠性。
## 397. `cs.CL` - PDFMathTranslate：保留布局的科学文档翻译 [PDF](https://arxiv.org/pdf/2507.03009), [HTML](https://arxiv.org/abs/2507.03009)
### Authors
Rongxin Ouyang,Chang Chu,Zhikuang Xin,Xiangyao Ma
### Background
语言障碍在科学文档中的存在阻碍了科学和技术的发展和传播。尽管以前的努力在翻译这类文档时忽视了布局中的信息，但PDFMathTranslate填补了这一空白，成为首个开放源代码的软件，能够在保留布局的情况下翻译科学文档。
### Innovation
PDFMathTranslate 引入了基于最新大规模语言模型和精确布局检测的进步，为社区带来了精准度、灵活性和效率的关键改进。
### Conclusion
该工作已经开源，并且已有超过222,000次下载量，更多细节可参见this https URL。
## 398. `cs.CL` - GAF-Guard：一种用于大型语言模型风险管理与治理的代理框架 [PDF](https://arxiv.org/pdf/2507.02986), [HTML](https://arxiv.org/abs/2507.02986)
### Authors
Seshu Tirupathi,Dhaval Salwala,Elizabeth Daly,Inge Vejsbjerg
### Background
随着大型语言模型（LLMs）在各个领域的广泛应用，其普及使用需要进行严格的监测，以防止意外的负面影响并确保系统的稳健性。此外，LLMs必须设计成符合人类价值观，如防止有害内容和确保负责任的使用。当前的自动化系统和解决方案主要用于监控LLMs在生产中的特定问题，如幻觉等，但往往忽略了具体应用场景和用户需求的考虑。因此，本文提出了一种名为GAF-Guard的新颖代理框架，该框架将用户、应用场景和模型本身置于中心位置。该框架旨在检测和监控基于LLM的应用程序部署相关的风险。方法通过建模自主代理来识别风险、激活风险检测工具，并在特定应用场景中促进连续的监控和报告，以增强人工智能安全并满足用户期望。
### Innovation
该框架创新地将用户、应用场景和模型本身置于中心，通过建模自主代理来识别和检测风险，激活特定场景下的风险检测工具，并进行连续监控和报告，以增强AI安全性并满足用户期望。
### Conclusion
GAF-Guard框架通过在特定应用场景中部署自主代理来检测和监测风险，激活风险检测工具，并执行连续监控和报告，最终增强了基于LLM的应用系统的安全性，并确保遵守用户期望。
## 399. `cs.CL` - LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users [PDF](https://arxiv.org/pdf/2507.02850), [HTML](https://arxiv.org/abs/2507.02850)
### Authors
Almog Hilel,Idan Shenfeld,Jacob Andreas,Leshem Choshen
### Background
该研究描述了语言模型（LMs）训练中用户反馈所带来的漏洞，攻击者只需通过提供提示和对LM输出进行投票（上或下）即可持久地改变LM的知识和行为。以前的工作主要集中在预训练时间的数据污染和部署时间的提示注入，但这项研究揭示了即使是在受到高度限制的偏好数据中，也能通过用户反馈间接控制模型行为的新机制。研究表明，这种攻击不仅可以注入模型此前未知的客观知识，也可以改变代码生成模式，从而引入可被利用的安全漏洞，还可以注入虚假的金融新闻。
### Innovation
这项研究提出了一种新的攻击方法，通过用户反馈数据对语言模型进行未经授权的知识注入。这种攻击方法扩展了现有关于预训练时间和部署时间的数据污染和提示注入的研究，展示了即使在受限的偏好数据形式下，也可以通过细粒度的用户反馈对模型行为产生直接影响，具有重要的安全风险和新的研究价值。
### Conclusion
这项研究揭示了通过用户反馈对语言模型进行攻击的一种新方式，不仅可能插入模型过去没有的知识，还可以改变代码生成模式从而引入安全漏洞，甚至注入虚假新闻。这种发现不仅揭示了语言模型偏好调整的新品质特征，而且还揭示了用户反馈训练语言模型的一种新的攻击机制。
## 400. `cs.CL` - 反馈在代理型AI工作流测试时扩展中的作用 [PDF](https://arxiv.org/pdf/2504.01931), [HTML](https://arxiv.org/abs/2504.01931)
### Authors
Souradip Chakraborty,Mohammadreza Pourreza,Ruoxi Sun,Yiwen Song,Nino Scherrer,Furong Huang,Amrit Singh Bedi,Ahmad Beirami,Jindong Gu,Hamid Palangi,Tomas Pfister
### Background
代理型AI工作流（自主规划和行动的系统）正在变得越来越普遍，但在复杂任务上的成功率仍然较低。一种有希望的解决方案是推理时校准，在测试阶段使用额外的计算资源来提升性能。推理时校准依赖于三个组件：采样、评估和反馈。尽管大多数先前工作研究了采样和自动评估，但反馈却被忽视了。
### Innovation
本文通过引入迭代代理解码（IAD），一种在解码步骤之间反复插入从不同形式的批评（回报模型或AI生成的文本反馈）提取出的反馈的程序，来研究反馈的作用。IAD展示了反馈在有限推理预算下的准确性和计算之间的权衡作用，评估了反馈增加多样性的优势，比较了来自奖励模型和文本批评的反馈效果，并测试了反馈对嘈杂或低质量的鲁棒性。IAD结合高质量反馈可实现最高达10％的绝对性能提升。
### Conclusion
我们的研究结果强调了反馈作为一个关键调节器的重要性，对于代理型AI工作流的推理时刻校准，特别是在有限的推理预算下，反馈至关重要。
## 401. `cs.CL` - 大语言模型能否玩‘吃官棋’游戏？一项关于多步规划和决策的研究 [PDF](https://arxiv.org/pdf/2507.03711), [HTML](https://arxiv.org/abs/2507.03711)
### Authors
Sang Quang Nguyen,Kiet Van Nguyen,Vinh-Tiep Nguyen,Thanh Duc Ngo,Ngan Luu-Thuy Nguyen,Dinh-Duy Le
### Background
本文探讨了大型语言模型（LLMs）通过传统的越南棋盘游戏‘吃官棋’来进行规划和决策的能力。这种游戏涉及一系列战略性棋子移动和捕获，为评估LLMs的决策和战略能力提供了独特环境。研究通过开发不同策略的代理角色，使用‘吃官棋’作为评估LLMs不同策略性能的试验平台。研究使用了如Llama-3.2-3B-Instruct、Llama-3.1-8B-Instruct和Llama-3.3-70B-Instruct等模型，旨在了解这些模型如何进行战略性决策、规划移动和管理动态游戏状态。
### Innovation
本文创新地提出了将大型语言模型应用于传统棋盘游戏的评估，通过不同策略的代理角色开发，测试了LLMs在多步规划和决策上的差异。研究选择了几个具有代表性的LLMs模型进行实验，旨在揭示这些模型在推理和策略上的强弱，从而深入理解其通用能力。
### Conclusion
研究结果将为我们提供关于LLMs在推理和策略方面的强项和弱点的见解，从而更深入地理解它们的通用能力。
## 402. `cs.CL` - BMMR: 大规模双语跨模态多学科推理数据集 [PDF](https://arxiv.org/pdf/2507.03483), [HTML](https://arxiv.org/abs/2507.03483)
### Authors
Zhiheng Xi,Guanyu Li,Yutao Fan,Honglin Guo,Yufang Liu,Xiaoran Fan,Jiaqi Liu,Jingchao Ding,Wangmeng Zuo,Zhenfei Yin,Lei Bai,Tao Ji,Tao Gui,Qi Zhang,Philip Torr,Xuanjing Huang
### Background
目前，研究人员和社区迫切需要一个大规模、双语、跨模态、多学科的推理数据集来开发和评估大型跨模态模型（LMMs）。现有的数据集往往缺乏全面性和多样性，难以满足评估多学科知识和推理能力的需求。因此，本文介绍了一个名为BMMR的数据集。该数据集涵盖了300个联合国教科文组织定义的主题领域的110,000个高考级别的问题，涉及多种格式和来源，旨在填补现有数据集在该领域的空白。
### Innovation
本文创新性地提出了一种大规模双语跨模态多学科推理数据集BMMR。它包含了110,000个大学水平的问题，覆盖300个学科领域，包括选择题、填空题和开放性问题。数据集特别注重多样性，来源自书籍、考试和在线测试等多个媒介。此外，论文还提出了一种基于过程的多学科验证器BMMR-Verifier，用于精确和细致地评估推理路径。通过全面实验，本文揭示了当前LMMs在多学科推理中的表现、知识分布特征及改进方向。
### Conclusion
本文展示了BMMR数据集的重要性及其在多学科推理评估中的应用。实验结果表明，最先进的模型在BMMR-Eval上仍有提升空间，LMMs需要在特定学科上表现更好，以及开源模型与商业模型之间的差距仍然存在。此外，通过使用BMMR-Verifier和其他深入研究，本文揭示了LMMs在跨学科推理中的挑战，未来的研究方向是通过BMMR-Train数据集的进一步微调来缩小差距。最后，BMMR数据集将被释放，并希望这项工作能为社区提供新的见解和贡献。
## 403. `cs.CL` - SIGIR 2025 -- LiveRAG Challenge Report [PDF](https://arxiv.org/pdf/2507.04942), [HTML](https://arxiv.org/abs/2507.04942)
### Authors
David Carmel,Simone Filice,Guy Horowitz,Yoelle Maarek,Oren Somekh,Ran Tavory,Mehdi Ghissassi,Edo Liberty,Roy Miara
### Background
2025年SIGIR会议期间举行的LiveRAG挑战提供了一个竞争平台，旨在推动检索增强生成（RAG）技术的发展。该挑战吸引了来自学术界和工业界的参赛者，利用固定的语料库（Fineweb-10BT）和开源LLM（Falcon3-10B-Instruct）开发基于RAG的问答系统。竞赛的目的在于促进检索和提示策略的挑战性比较。在特定的时间窗口内，70支队伍来自27个国家提交了针对500个未见过的问题的回答及支持信息。评估分为两阶段进行：首先，使用自动化LLM作为评判者来计算正确性和忠实度得分，随后对排名前的提交进行手动审查。最终的获胜队伍名单于2025年6月12日在意大利帕多瓦的SIGIR 2025 LiveRAG研讨会期间公布，并颁发了奖品。
### Innovation
LiveRAG挑战提供了一个统一的平台，允许参赛者使用相同的语料库和LLM开发RAG系统，旨在促进不同团队在检索和提示策略上的比较。自动化与手动审查相结合的评估方法确保了评分的公正性和准确性，并促进了RAG技术的透明度和可靠性。
### Conclusion
此次挑战成功展示了RAG技术在实际应用中的潜力，并为未来的研究和开发提供了重要见解。获奖团队接受了严格评审并被表彰，展示了其在使用RAG技术解决复杂问题方面的卓越能力。
## 404. `cs.CL` - 使用动机访谈标准评估日语中的AI咨询：咨询者、客户和评估者角色 [PDF](https://arxiv.org/pdf/2507.02950), [HTML](https://arxiv.org/abs/2507.02950)
### Authors
Keita Kiuchi,Yoshikazu Fujimoto,Hideyuki Goto,Tomonori Hosokawa,Makoto Nishimura,Yosuke Sato,Izumi Sezai
### Background
本研究首次全面评估了大型语言模型（LLM）在日本语治疗场景中的三种咨询角色表现。研究人员使用动机访谈治疗（MITI）编码手册4.2.1版评估了由人类专家（15名）根据动机访谈标准生成的AI对话。这些角色包括咨询AI系统（GPT-4-turbo零样本提示或结构化多步对话提示（SMDP）和Claude-3-Opus-SMDP）、客户AI模拟和评估AI系统（o3、Claude-3.7-Sonnet、Gemini-2.5-pro）。研究发现了SMDP在所有MITI全球评分中显著提升了咨询AI的表现，而GPT-SMDP和Opus-SMDP在总体表现上没有显著差异。此外，评估AI在促进变革对话方面与人类评价者表现相当，但在温和延续对话和整体质量指标上有所高估。后续发现每个模型的独特偏向，Gemini强调权力共享，o3专注于技术熟练度，Sonnet则侧重情感表达。客户AI模拟显示出有限的情感范围和不自然的高合规性，这表明需要增强其现实感。
### Innovation
该研究首次全面评估了不同类型的大型语言模型在日本语治疗场景中的多种角色表现，并使用动机访谈作为评估标准。研究表明，SMDP能够显著提高咨询AI的表现，并发现了不同模型存在的特定偏向。这为进一步优化AI辅助心理咨询提供了新的见解。
### Conclusion
本研究为非英语语境下的AI辅助咨询设定了基准，并指出了通过先进的提示工程、检索增强生成和目标微调等方法改进的关键领域。此外强调了文化敏感性AI心理健康工具的发展具有重要意义。
## 405. `cs.CL` - MemOS：AI系统的内存操作系统 [PDF](https://arxiv.org/pdf/2507.03724), [HTML](https://arxiv.org/abs/2507.03724)
### Authors
Zhiyu Li,Shichao Song,Chenyang Xi,Hanyu Wang,Chen Tang,Simin Niu,Ding Chen,Jiawei Yang,Chunyu Li,Qingchen Yu,Jihao Zhao,Yezhaohui Wang,Peng Liu,Zehao Lin,Pengyuan Wang,Jiahao Huo,Tianyi Chen,Kai Chen,Kehang Li,Zhen Tao,Junpeng Ren,Huayi Lai,Hao Wu,Bo Tang,Zhenren Wang,Zhaoxin Fan,Ningyu Zhang,Linfeng Zhang,Junchi Yan,Mingchuan Yang,Tong Xu,Wei Xu,Huajun Chen,Haofeng Wang,Hongkang Yang,Wentao Zhang,Zhi-Qin John Xu,Siheng Chen,Feiyu Xiong
### Background
大型语言模型（LLMs）已经成为通用人工智能（AGI）的重要基础设施，但它们缺乏有效的内存管理系统，阻碍了长时间段推理、持续个性化和知识更新的发展。现有的Retrieval-Augmented Generation（RAG）模型主要依赖静态参数和短暂的上下文状态，限制了它们跟踪用户偏好或长时间更新知识的能力。一些研究从内存层次结构的角度分析了LLMs的训练和推理成本，表明通过在外层检索与参数记忆之间引入显式的记忆层，可以显著降低成本。然而，信息在时间上的分布和上下文中的传播给LLMs带来了更广泛的问题，需要能够管理跨越不同时间尺度和来源的异构知识的系统。
### Innovation
我们提出了MemOS，一种将内存视为可管理系统资源的内存操作系统。它统一了文本、基于激活和参数级别的记忆的表示、调度和演变，能够成本高效地进行存储和检索。作为基本单元，MemCube封装了内存内容以及元数据（如出处和版本），并能够随时间进行组合、迁移和融合，从而灵活地过渡不同类型的记忆，并将检索连接到基于参数的学习。MemOS建立了一个以内存为中心的系统框架，为LLMs带来了可控性、可塑性和演化性，为持续学习和个人建模奠定了基础。
### Conclusion
MemOS为LLMs引入了可控性、可塑性和演化性的内存管理系统，使其能够在时间和上下文中更好地管理异构知识，从而增强了持续学习和个性化建模的能力。
## 406. `cs.CL` - Infini-gram mini：使用FM-索引在互联网规模上进行精确 n-克搜索 [PDF](https://arxiv.org/pdf/2506.12229), [HTML](https://arxiv.org/abs/2506.12229)
### Authors
Hao Xu,Jiacheng Liu,Yejin Choi,Noah A. Smith,Hannaneh Hajishirzi
### Background
语言模型主要通过大规模互联网文本数据进行训练，了解这一数据源变得日益重要。虽然精确匹配搜索引擎可以在大型文本语料库中进行搜索，但存储开销限制了它们在互联网规模数据上的应用。本文介绍了一种高效且可扩展的系统Infini-gram mini，它可以使得拍字级别的文本语料库可进行搜索。该系统基于FM-索引数据结构，同时对文本进行索引和压缩，使索引的大小仅为语料库的44%。Infini-gram mini在索引速度和索引过程中对内存的使用上都有显著提升，能够在单个128核CPU节点上在50天内索引46TB的互联网文本（或75个这样的节点仅需19小时）。此外，我们发现几个核心语言模型评估基准在互联网抓取中受到严重污染，并展示了Infini-gram mini在大规模基准污染分析中的重要应用。
### Innovation
Infini-gram mini通过使用FM-索引数据结构同时对文本进行索引和压缩，使得索引大小仅为语料库的44%，并且在索引速度和查询过程中的内存使用方面大幅提高，能够处理拍字级别的文本语料库。该系统能够在单个高核数CPU节点上高效地对大规模互联网文本进行索引。
### Conclusion
我们通过Infini-gram mini展示了重要应用案例，例如大规模分析基准污染情况，并发现了几个核心基准在互联网抓取中受到严重的污染。我们还提供了基准污染的分享渠道和相关信息的公开查询接口。
## 407. `cs.CL` - RAG-R1：通过多查询并行激励LLMs的搜索与推理能力 [PDF](https://arxiv.org/pdf/2507.02962), [HTML](https://arxiv.org/abs/2507.02962)
### Authors
Zhiwen Tan,Jiaming Huang,Qintong Wu,Hongxuan Zhang,Chenyi Zhuang,Jinjie Gu
### Background
大型语言模型（LLMs）在各种任务中表现出色，但由于其静态内部知识，这些模型仍易产生虚构或不准确的响应。随着检索增强生成（RAG）方法的进步，研究者通过增强模型的搜索和推理能力以增强性能。虽然这些方法具有潜力，但它们面临训练稳定性问题，并且存在诸如推理时间过长和能力受限等挑战。
### Innovation
提出了RAG-R1，一种新颖的训练框架，使LLMs在推理过程中能够自适应地利用内部和外部知识。该框架将生成和检索过程从单查询模式扩展到多查询并行模式，减少了推理时间和增强了模型的能力。
### Conclusion
在七个问答基准上的实验表明，该方法在最强基线上的性能提高了高达13.2%，并将推理时间减少了11.1%。
## 408. `cs.CL` - OpenS2S：推动全开源端到端同理心大型语音语言模型 [PDF](https://arxiv.org/pdf/2507.05177), [HTML](https://arxiv.org/abs/2507.05177)
### Authors
Chen Wang,Tianyu Peng,Wen Yang,Yinan Bai,Guangfu Wang,Jun Lin,Lanpeng Jia,Lingxiang Wu,Jinqiao Wang,Chengqing Zong,Jiajun Zhang
### Background
同理心交互是人机沟通的基石，因为这需要理解带有副语言提示的言语，并生成情感和表达性回应。然而，最强大的同理心LSLM（大型语音语言模型）变得越来越封闭，研究者无法获取其架构、数据和开发的详细信息。鉴于透明研究同理心行为的迫切需求，我们提出OpenS2S，一种全面开源、透明的端到端LSLM，旨在促进同理心语音交互。OpenS2S通过BLSP-Emo模型进一步采用流式交错解码架构实现低延迟语音生成。为了方便端到端训练，OpenS2S整合了一个自动数据构建管道，低成本合成多样化、高质量的同理心语音对话，减少了人为监督。
### Innovation
我们利用大规模语言模型生成同理心内容，并结合可控文本到语音系统引入说话人和情感变异性，构建了一个具有丰富副语言多样性和最少人工监督的大规模训练语料库。OpenS2S是一个全面开源的端到端LSLM，包括数据集、模型权重、预训练和微调代码，旨在赋能更广泛的科研社区并加速同理心语音系统创新。
### Conclusion
我们通过开放源代码的方式提供了OpenS2S模型，包括其数据集、模型权重、预训练和微调代码，使科研社区能够访问并促进同理心语音系统的创新。该项目页面可访问：this https URL
## 409. `cs.CL` - 基于嵌入的方法在假两极分化新闻检测中的应用 [PDF](https://arxiv.org/pdf/2501.01370), [HTML](https://arxiv.org/abs/2501.01370)
### Authors
Karthik Mohan
### Background
假两极分化新闻指的是那些采取极端政治立场、旨在制造公众政治分歧的新闻文章。现有的检测这些新闻的方法包括使用n-grams、情感分析，以及使用预训练ELMo模型生成句子和文档表示。这些方法的性能参差不齐，存在提升空间。
### Innovation
本文提出使用预训练的LLMs模型生成嵌入，作为检测假两极分化新闻的方法。通过大量的实验验证，该方法在10折交叉验证中的准确率达到了约92%，优于之前使用预训练ELMo和双向LSTM模型的方法，后者在10折交叉验证中的准确率为约83%。
### Conclusion
通过使用预训练的LLMs模型生成嵌入，可以显著提高假两极分化新闻检测的准确率，该方法在未来的研究中具有较高的应用价值。
## 410. `cs.CL` - 大型语言模型中演绎和归纳推理的作用 [PDF](https://arxiv.org/pdf/2410.02892), [HTML](https://arxiv.org/abs/2410.02892)
### Authors
Chengkun Cai,Xu Zhao,Haoliang Liu,Zhongyu Jiang,Tianfang Zhang,Zongkai Wu,Jenq-Neng Hwang,Lei Li
### Background
大型语言模型（LLMs）在推理任务中展现出了令人惊叹的能力，但它们依赖于静态提示结构和在复杂场景下的有限适应性仍然是一个显著挑战。现有的方法主要依赖固定的提示结构，缺乏对复杂问题进行有效分解和应对的能力。因此，有必要发展新的方法来增强LLMs的推理能力，使其能够更好地适应复杂情境。
### Innovation
本文提出了一种新颖的框架——演绎和归纳推理（Deductive and InDuctive, DID）方法，该方法通过动态结合演绎和归纳推理方式来增强LLMs的推理能力。DID方法采用双重复杂度评估系统，结合Littlestone维度和信息熵来准确评估任务难度并指导分解策略，使得模型能够根据问题的复杂程度逐步调整其推理路径，与人类的认知过程相似。本文在多个基准测试集（包括AIW和MR-GSM8K，以及自定义的Holiday Puzzle数据集）上评估了DID的有效性，结果显示DID在提高推理质量和解决方案准确度方面具有显著优势，同时保持较低的计算成本。
### Conclusion
DID的成功表明，在提高LLM性能的同时维持计算效率具有潜在的发展方向，对于开发更接近人类认知能力和计算效率的语言模型具有重要意义。本文的工作为增强LLMs推理能力提供了一种有理论依据的输入中心方法，为替代传统的输出探索方法提供了有效途径。
## 411. `cs.CL` - ViGiL3D：三维视觉定位中语言多样化的数据集 [PDF](https://arxiv.org/pdf/2501.01366), [HTML](https://arxiv.org/abs/2501.01366)
### Authors
Austin T. Wang,ZeMing Gong,Angel X. Chang
### Background
3D视觉定位（3DVG）涉及通过自然语言文本在3D场景中定位实体，对于实现实体AI和场景检索等应用具有重要作用。近年来，研究工作主要集中在利用大规模语言模型（LLM）扩展3DVG数据集的规模，然而所采用的数据集未能涵盖语言中可能出现的所有提示类型。为此，本文提出了3DVG提示的语义分析框架，并构建了Visual Grounding with Diverse Language in 3D（ViGiL3D）数据集，用于评估视觉定位方法在面对多样化的语言模式时的表现。现有的开放词汇3DVG方法在理解和识别具有挑战性且分布在外的提示时表现不足，需要进一步提高以适应现实应用的需求.
### Innovation
本文创新地提出了一个用于3DVG提示的语义分析框架，并构建了ViGiL3D数据集。该数据集包含了多样化的语言模式，旨在全面评估视觉定位方法在实际应用中的性能。该研究填补了现有3DVG数据集未能涵盖所有可能语言提示类型的空白，并有助于提高未来视觉定位模型的性能和适应性.
### Conclusion
现有的开放词汇3DVG方法在理解及识别具有挑战性的、分布在外的提示时表现不佳。为了更好地服务于实际应用，需要进一步提升这些方法的理解和识别能力。本文构建的ViGiL3D数据集提供了一个全面且多样化的语言环境，为今后视觉定位方法的研究提供了宝贵的评估工具和数据资源.
## 412. `cs.CL` - EEG2TEXT-CN：基于大规模语言模型和对比学习的多语言文本-EEG对齐探索性研究 [PDF](https://arxiv.org/pdf/2506.00854), [HTML](https://arxiv.org/abs/2506.00854)
### Authors
Jacky Tai-Yu Lu,Jung Chiang,Chi-Sheng Chen,Anna Nai-Yun Tung,Hsiang Wei Hu,Yuan Chiao Cheng
### Background
介绍了文中构建的EEG2TEXT-CN框架是目前为止最早针对中文的开放式词汇EEG到文本生成框架。该框架基于生理学基础的EEG编码器（NICE-EEG）和紧凑型预训练语言模型（MiniLM），通过掩码预训练和对比学习将多通道脑信号与自然语言表示进行对齐。使用ChineseEEG数据集的一个子集进行实验，该数据集包含每个句子大约十个汉字，与256 Hz采样的128通道EEG记录对齐，实施基于字符的嵌入分割并在零样本设置下预测完整句子。解码器通过教师强迫和填充掩码训练以适应序列长度的可变性。实验证明在1500多个训练-验证句子和300个留出测试样本上取得了令人鼓舞的词库对齐效果，最佳BLEU-1得分为6.38%。语法流畅性仍是挑战，表明多通道EEG对中文文本的非音素跨模态解码是可行的。这项工作开辟了多语言脑至文本研究的新方向，并为汉语未来的认知语言接口奠定了基础。
### Innovation
提出了EEG2TEXT-CN框架，该框架是建立在生理学基础的EEG编码器和紧凑型预训练语言模型之上，通过掩码预训练和对比学习将多通道脑信号与自然语言表示进行对齐。这是针对中文的最早开放式词汇EEG到文本生成框架，实验证明了其在中文文本生成中的潜力，尽管在语法流畅性方面仍存在挑战，但展示了非音素跨模态解码的可能性。
### Conclusion
EEG2TEXT-CN框架在多通道EEG与中文文本的跨模态解码中展示了可行性，为未来的多语言脑至文本接口奠定了基础，并为汉语认知语言接口的研究提供了新的方向。
## 413. `cs.CL` - 学习进行规划与推理以进行评估的Thinking-LLM-as-a-Judge [PDF](https://arxiv.org/pdf/2501.18099), [HTML](https://arxiv.org/abs/2501.18099)
### Authors
Swarnadeep Saha,Xian Li,Marjan Ghazvininejad,Jason Weston,Tianlu Wang
### Background
现有的LLM-as-a-Judge模型能够生成链式思考(Chain-of-Thought, CoT)序列来捕获最终评价回答的推理过程，但因缺乏人类标注的CoTs进行评估，有效的推理痕迹所需的组件和结构仍然未被充分研究。因此，先前的方法往往限制推理痕迹到手设计的成分，如评估标准列表、参考答案或验证问题，并将规划与推理评价过程紧密结合。基于此，本文探讨了有效评价方法的不足之处，并提出了一种名为EvalPlanner的偏好优化算法，旨在首先生成不受限制的评价计划，之后执行计划，最后作出最终判断。通过自训练循环，EvalPlanner不断优化合成构造的评价计划和执行过程，从而提高最终判断的质量。此外，本文还通过在其他基准测试上的实验进一步验证了规划和推理对于构建强大LLM-as-a-Judge推理模型的重要性。
### Innovation
本文提出了一种名为EvalPlanner的偏好优化算法，用于Thinking-LLM-as-a-Judge。首先生成不受约束的评价计划，接着执行该计划，最后给出最终判断。在自训练循环中，EvalPlanner不断优化合成构造的评价计划和执行过程，以提高最终的评价质量。此外，该方法在 RewardBench 上达到了新的最佳性能（得分为 93.9），尽管训练时使用的偏好对数量较少且为合成生成的。
### Conclusion
本研究通过提出EvalPlanner偏好优化算法，实现了在RewardBench基准上的新最佳性能，强调了规划和推理对于建立强大LLM-as-a-Judge推理模型的重要性。此外，本文工作展示了在其他基准测试上的优势，证明了其在提升模型推理能力和最终判断质量方面的有效性。
## 414. `cs.CL` - Feint and Attack: 假乱真与攻击：基于注意力策略的大语言模型攻击与防御 [PDF](https://arxiv.org/pdf/2410.16327), [HTML](https://arxiv.org/abs/2410.16327)
### Authors
Rui Pu,Chaozhuo Li,Rui Ha,Zejian Chen,Litian Zhang,Zheng Liu,Lirong Qiu,Zaisheng Ye
### Background
分水岭攻击可以通过向大语言模型（LLMs）输入语义模糊的提示，诱导模型生成有害内容，从而访问和利用模型的漏洞。为了深入研究LLMs的安全性，并揭示输入提示与模型输出之间的关联，研究人员通过分析注意力权重的分布来探究潜在原因。研究提出了新的度量标准，如注意力强度在敏感词上的度量（Attn_SensWords）、基于注意力上下文依赖度分值（Attn_DepScore）和注意力离散熵（Attn_Entropy），并通过这些度量的特性提出了有效的策略。
### Innovation
研究人员基于注意力分布提出了两种创新策略：一种是注意力基于攻击策略（Attention-Based Attack, ABA），这种策略利用嵌套攻击提示扰乱注意力分布，使模型更多关注无害的部分；另一种是注意力基于防御策略（Attention-Based Defense, ABD），这种策略通过调整输入提示的注意力分布来增强模型的稳健性。研究结果表明，注意力权重的分布对LLMs的输出具有重要影响。
### Conclusion
ABA和ABD可以用来评估LLMs的安全性。实验结果还表明，注意力权重的分布对LLMs的输出有很大影响，从而提供了逻辑解释，突显了注意力权重在模型安全性和可解释性方面的重要性。
## 415. `cs.CL` - Agents Are All You Need for LLM Unlearning [PDF](https://arxiv.org/pdf/2502.00406), [HTML](https://arxiv.org/abs/2502.00406)
### Authors
Debdeep Sanyal,Murari Mandal
### Background
在大型语言模型（LLMs）中实现信息移除或抑制是一项重要的功能，有助于AI法规、法律合规、安全性和隐私保护。当前的LLM卸载方法难以平衡卸载效果和实用性，因为这两个目标相互竞争。在不假设具有模型权重访问权的情况下使卸载过程保持计算可行是一个被忽视的领域。
### Innovation
本文提出了一种代理驱动的LLM卸载（ALU）方法，这是一种多代理、无需重新训练、模型无关的LLM卸载方法，能够在保持效用的同时实现有效的卸载。ALU框架通过涉及多个专门为卸载过程中的特定步骤设计的LLM代理来实现卸载，而无需更新任何代理的模型权重。用户可以轻松请求任何一组卸载实例，并实时无缝适应。这项工作不需要对底层LLM模型进行任何更改。实验表明，ALU框架在现有的最先进的方法中表现最为稳健，且时间成本几乎不受卸载目标数量的影响。
### Conclusion
ALU框架在多项基准测试和降级技术中显示出优越性能，尤其在大规模评估中表现突出。具体而言，ALU能够在多达1000个卸载目标的测试中超越所有先前提出的LLM卸载方法的表现范围。
## 416. `cs.CL` - 低秩和稀疏模型融合用于多语言语音识别与翻译 [PDF](https://arxiv.org/pdf/2502.17380), [HTML](https://arxiv.org/abs/2502.17380)
### Authors
Qiuming Zhao,Guangzhi Sun,Chao Zhang
### Background
语音识别和翻译等语音到文本（S2T）任务因语言多样性面临重大挑战。传统的多语言多任务训练方法试图通过在不同语言上同时优化多种语音识别和翻译任务来解决这一难题，但现有的模型如Whisper在计算成本、语言干扰、训练配置不佳和扩展性有限等方面仍存在问题。
### Innovation
引入了一种新型方法LoRS-Merging（低秩和稀疏模型合并），该方法能够高效地整合不同语言或任务训练的模型，同时保持性能并减少计算开销。LoRS-Merging结合低秩和稀疏剪枝技术，保留关键结构，消除冗余参数，减少语言干扰并增强可扩展性。实验表明，在10种语言上的表现优于多语言多任务训练、顺序训练及其他合并方法，性能提高了20%以上。
### Conclusion
研究结果表明，LoRS-Merging是一种可扩展且有效的多语言S2T传统训练策略的补充方法。
## 417. `cs.CL` - 通过大规模语言模型进行受控图像编辑的贝叶斯优化 [PDF](https://arxiv.org/pdf/2502.18116), [HTML](https://arxiv.org/abs/2502.18116)
### Authors
Chengkun Cai,Haoliang Liu,Xu Zhao,Zhongyu Jiang,Tianfang Zhang,Zongkai Wu,John Lee,Jenq-Neng Hwang,Lei Li
### Background
在图像生成的快速发展中，实现对生成内容的精确控制和保持语义一致性仍然是显著的限制，尤其涉及保真技术以及模型微调的必要性。为此，本研究旨在解决这些挑战，并提出BayesGenie方法，结合大规模语言模型（LLMs）与贝叶斯优化，以实现精确且用户友好的图像编辑。
### Innovation
BayesGenie方法通过自然语言描述而无需手动区域标记，使用户能够修改图像，同时保持原始图像的语义完整性。该方法具有模型通用性设计，无需进行大量预训练或微调，通过自适应的贝叶斯优化策略自动优化推理过程参数，从而实现高精度的图像编辑，显著减少了用户干预。该方法在多种场景下的实验结果表明，其在编辑准确性和语义保存方面明显优于现有方法，使用不同的LLMs（如Claude3和GPT-4）验证其有效性。
### Conclusion
本研究提出的BayesGenie方法显著提升了图像编辑的效果，并优化了语言模型对图像编辑的过程，展示了在少干预下的高精度编辑能力，克服了现有技术的局限性，为图像编辑领域带来了新的解决方案。
## 418. `cs.CL` - Large Language Models with Meta-Cognition Trigger for Adaptive Tool Use [PDF](https://arxiv.org/pdf/2502.12961), [HTML](https://arxiv.org/abs/2502.12961)
### Authors
Wenjun Li,Dexun Li,Kuicai Dong,Cong Zhang,Hao Zhang,Weiwen Liu,Yasheng Wang,Ruiming Tang,Yong Liu
### Background
大型语言模型（LLMs）展示了非凡的涌现能力，通过利用外部工具解决需要专门处理或最新数据的复杂问题，改变功能任务的执行方式。现有的研究扩展了LLMs访问各种工具的范围（例如，程序解释器、搜索引擎、计算器），但常忽视这些工具的使用必要性，导致随意调用工具。这一简单粗暴的方法引发了两个关键问题：不必要的工具调用增加了延迟，以及与外部工具的误互动可能导致潜在错误。
### Innovation
本研究引入了元认知作为代理，代表LLMs自我评估其能力的方式，反映模型对其自身局限性的认识。基于此，提出了MeCo（Metacognition-based Tool Use Decision-making），一种适应性决策策略，用于外部工具的调用。MeCo通过捕捉表示空间中的高层认知信号来量化元认知分数，指导何时调用工具。值得注意的是，MeCo不需要微调，并且成本较低。实验表明，MeCo一致地检测LLMs的内部认知信号，并显著提高了工具使用决策的准确性。
### Conclusion
本研究展示了MeCo在多个基础模型和基准测试中的有效性，通过元认知策略指导了工具的合理调用，提高了大型语言模型的决策准确性。
## 419. `cs.CL` - SHNU多语言会话语音识别系统：INTERSPEECH 2025 MLC-SLM挑战赛 [PDF](https://arxiv.org/pdf/2507.03343), [HTML](https://arxiv.org/abs/2507.03343)
### Authors
Yuxiang Mei,Yuang Zheng,Dongxing Xu,Yanhua Long
### Background
本研究描述了SHNU多语言会话语音识别系统(SHNU-mASR，团队名称-
### Innovation
本系统融合了一种并行语音编码架构与大型语言模型(LLM)，构成了一个统一的多语言ASR框架。采用两组预训练编码器Whisper-large-v3与mHuBERT-147，其输出嵌入被拼接后传入LLM，使模型能够利用互补的声学和语言知识，从而达到竞争性的表现。此外，引入了三阶段训练策略，联合更新两个语音编码器和LLM的低秩适应模块及投影参数，以增强语言感知能力。同时，在LLM输入中加入语言感知提示，以增强特定语言的文本生成。
### Conclusion
SHNU-mASR系统在挑战赛的盲测试集上获得了11.76%的字符/字错误率(CER/WER)，优于官方MLC-SLM基线8.41个绝对值的CER/WER，且不增加基线训练数据。
## 420. `cs.CL` - 重新定义评估标准：统一的框架用于评估语言模型的韩语能力 [PDF](https://arxiv.org/pdf/2503.22968), [HTML](https://arxiv.org/abs/2503.22968)
### Authors
Hanwool Lee,Dasol Choi,Sooyong Kim,Ilgyun Jung,Sangwon Baek,Guijin Son,Inseon Hwang,Naeun Lee,Seunghyeok Hong
### Background
近期，韩国大型语言模型（LLMs）取得了进步，带动了众多基准测试和评估方法的发展，但由于不同的机构采用不一致的评估协议，导致性能差异高达10个百分点。突破这些可重复性瓶颈并不意味着需要使用统一的评估方案，而是需要多样化的实验方法和一个能够支持这些方法的稳健框架。因此，提出了HRET（Haerae Evaluation Toolkit），这是一种开源、基于注册表的框架，用于统一评估韩语LLMs。
### Innovation
HRET是一个开源、基于注册表的框架，整合了主要的韩语基准测试、多种推理后端和多方法评估，同时强制实施语言一致性以确保生成真确的韩语输出。其模块化的注册表设计允许快速纳入新的数据集、方法和后端，确保工具包能够适应不断变化的研究需求。此外，它还引入了针对韩语特征的输出分析方法，如形态意识型-词项比（TTR）和系统性关键词遗漏检测，以评估词汇多样性和识别缺失概念，提供针对语言特性的诊断见解。
### Conclusion
HRET通过引入针对的语言性能评估方法，为研究人员提供有价值的诊断信息，帮助他们在韩语LLM发展中进行有针对性的改进。
## 421. `cs.CL` - 分析子空间路由：递归最小二乘在大型语言模型连续学习中的工作机制 [PDF](https://arxiv.org/pdf/2503.13575), [HTML](https://arxiv.org/abs/2503.13575)
### Authors
Kai Tong,Kang Pan,Xiao Zhang,Erli Meng,Run He,Yawen Cui,Nuoyan Guo,Huiping Zhuang
### Background
大型语言模型（LLMs）具有处理各种语言相关任务的能力。然而，对LLMs进行微调会降低其通用技能，连续微调会导致累积知识严重退化。最近，大型语言模型的连续学习（CL）兴起，旨在使LLMs能够连续适应新任务的同时保持先前学习的知识和继承通用技能。现有的技术要么通过对以前的数据进行重放来利用，这带来了额外的计算成本，要么利用一个参数效率高的模块来学习下游任务，这限制了新知识的吸收并对不同任务进行干扰。针对这些问题，本文提出了分析子空间路由（ASR）来解决这些挑战。
### Innovation
本文提出了分析子空间路由（ASR），通过在深层特征空间中隔离每个任务的学习来消除不同任务之间的知识干扰。此外，作者还提出了一种分析路由机制来有效利用不同子空间中学到的知识。该方法利用递归最小二乘法训练一个多任务路由器模型，使得路由器能够动态适应新数据而不需访问历史数据。路由器能有效地将当前任务分配到合适的子空间，并具备对先前学习任务的非遗忘特性，具有坚实的理论保证。实验结果表明，该方法在保留先前知识的同时，无缝集成新信息，有效克服了现有方法的核心限制。
### Conclusion
实验结果表明，该方法实现了近完美的知识保留，同时无缝地整合新信息，有效地克服了现有方法的核心限制。该代码将在接受后发布。
## 422. `cs.CL` - 离线学习与遗忘在大型语言模型推理中的应用 [PDF](https://arxiv.org/pdf/2504.11364), [HTML](https://arxiv.org/abs/2504.11364)
### Authors
Tianwei Ni,Allen Nie,Sapana Chaudhary,Yao Liu,Huzefa Rangwala,Rasool Fakoor
### Background
在大型语言模型的推理阶段引入搜索技术能够进一步增强模型解决复杂数学和推理问题的能力。然而，这种方法也大幅增加了计算成本和推理时间，因为在推理过程中，模型需要生成和评估多个候选解决方案以确定有效的推理路径。
### Innovation
本文提出了一种有效的整合搜索能力的方法，通过在具有成功（学习）和失败（遗忘）推理路径的数据上微调模型，直接集成搜索能力到模型中。实验证明，将元思维推理（CoT）生成的数据替换为搜索生成的数据进行离线微调，相比推理时的搜索基线，成功率达到提高约23%，同时将推理时间减少180倍。同时，学习和遗忘目标的一致性表现也优于监督微调和偏好方法。
### Conclusion
实验结果表明，通过离线微调集成搜索能力的方法能够显著提高大型语言模型解决复杂推理问题的能力，同时大幅减少推理时间。
## 423. `cs.CL` - 提示编程对函数级代码生成的影响 [PDF](https://arxiv.org/pdf/2412.20545), [HTML](https://arxiv.org/abs/2412.20545)
### Authors
Ranim Khojah,Francisco Gomes de Oliveira Neto,Mazen Mohamad,Philipp Leitner
### Background
大型语言模型（LLMs）在软件工程师中越来越被用于代码生成。然而，LLMs 的局限性，例如生成不相关或不正确的代码，突显了提示编程（或提示工程）的需求，即工程师通过应用特定的提示技术（如思维链或输入输出示例）来改进生成的代码。尽管已经有一些提示技术被研究，但不同技术及其相互作用对代码生成的影响尚未完全被理解。本文介绍了CodePromptEval数据集，它包括7072个用于评估五种提示技术（少量示例、人设、思维链、函数签名、包列表）对生成函数的正确性、相似性和质量的影响的提示。研究表明，尽管某些提示技术显著影响生成的代码，但组合多种技术并不一定能改善结果。我们还观察到，在使用提示技术时，正确性和质量之间存在权衡关系。该数据集和重放包为未来改进LLM生成的代码和评估新提示技术的研究提供了支持。
### Innovation
本文通过CodePromptEval数据集系统地评估并比较多提示技术（如少量示例、人设、思维链、函数签名、包列表）对LLM生成函数正确性、相似性和质量的影响，该研究结果揭示了不同提示技术及其组合的应用效果，指出某些技术对生成的代码有显著影响，而组合不同技术也不一定提升效果，存在正确性与质量之间的权衡问题。该数据集和重放包为未来研究提供了一个重要的资源。
### Conclusion
尽管某些提示技术对生成的代码有显著影响，组合多个提示技术并不一定是提升性能的最佳途径。正确性和质量之间存在权衡关系，因此需要在两者之间做出适当权衡。该数据集和重放包将为未来研究LLM生成代码的改进和评估新提示技术提供重要支持。
## 424. `cs.CL` - 大型语言模型对人类口语交流影响的实证证据 [PDF](https://arxiv.org/pdf/2409.01754), [HTML](https://arxiv.org/abs/2409.01754)
### Authors
Hiromu Yakura,Ezequiel Lopez-Lopez,Levin Brinkmann,Ignacio Serna,Prateek Gupta,Ivan Soraperra,Iyad Rahwan
### Background
人类历史的发展伴随着通信技术的重大革新，从书写到印刷机、电视再到社交媒体，每一次技术变革都极大地改变了信息传播方式，重塑了文化格局。近期由生成型人工智能驱动的聊天机器人是前所未有的媒体形式，它在神经网络中编码了文化模式，并通过与数百万人的对话传播这些模式。研究这些模式如何进入人类语言并进一步塑造人类文化，是一项基础性课题。尽管量化聊天机器人如ChatGPT对人类文化的影响十分复杂，但人类口语交流词汇用法的变化可能是一种早期指标。因此，研究人员使用计量经济学因果推理方法分析了来自不同学科的数万小时的对话资料，以观察机器人的影响。
### Innovation
研究团队采用计量经济学因果推断技术，分析了来自360,445个YouTube学术演讲和771,591个Podcast对话片段的对话记录，发现ChatGPT的推出导致了人类语言使用的显著变化，其中一些受ChatGPT影响的词汇如‘delve’、‘comprehend’、‘boost’等词汇的使用量增加。这一研究首次展示了机器可能通过模仿人类文化特征，反过来影响人类文化的事实，揭示了人机文化双向循环的新现象，为未来相关研究提供了重要线索。
### Conclusion
研究结果强调了进一步探索人类-机器文化交流重要性，并提出了保护语言与文化多样性、防止大规模操纵的担忧。大型语言模型正处于人类文化与技术相互塑造的新阶段，需要借助量化分析方法来理解这一动态变化过程。
## 425. `cs.CL` - 我们真的需要专业化吗？评估通用文本嵌入在零样本推荐和搜索中的效果 [PDF](https://arxiv.org/pdf/2507.05006), [HTML](https://arxiv.org/abs/2507.05006)
### Authors
Matteo Attimonelli,Alessandro De Bellis,Claudio Pomo,Dietmar Jannach,Eugenio Di Sciascio,Tommaso Di Noia
### Background
预训练语言模型（PLMs）广泛应用于从项目元数据中推导语义表示，尤其是在推荐和搜索中。在序列推荐中，PLMs 通过文本元数据增强基于ID的嵌入；而在产品搜索中，它们使项目特性与用户意图相匹配。最近的研究表明，为了提高表示能力，需要针对特定任务和领域进行微调。但本研究挑战了这一假设，表明通用文本嵌入模型（GTEs）在大规模语料库上预训练后，无需专门适应，也能满足零样本性能要求。实验结果表明，GTEs 在序列推荐和产品搜索中均优于传统模型和微调模型，归因于其更强大的表示能力，能够更均匀地在嵌入空间中分布特征。此外，通过聚焦于最具有信息量的方向压缩嵌入维度（例如，通过PCA）有效减少了噪声并提高了专有模型的性能。
### Innovation
该研究挑战了特定任务和领域微调的必要性，表明通用文本嵌入模型（GTEs）可以在零样本情况下表现出色。研究通过实验展示了GTEs在这两类任务中的优越表现，并归因于其更强的表示能力及对特征更均衡的分布。此外，研究还建议通过压缩嵌入维度来进一步改善模型性能，特别适用于专属性更强的模型。
### Conclusion
研究结果显示，通用文本嵌入模型（GTEs）在序列推荐和产品搜索中优于传统模型和需要微调的模型。压缩嵌入维度也能有效提升模型性能。
## 426. `cs.CL` - 使用荷兰档案数据进行自我监督的语音表示学习 [PDF](https://arxiv.org/pdf/2507.04554), [HTML](https://arxiv.org/abs/2507.04554)
### Authors
Nik Vaessen,Roeland Ordelman,David A. van Leeuwen
### Background
本文探索了使用荷兰存档电视广播数据进行自我监督学习语音基础模型（如wav2vec 2.0）的可能性。研究了数据质量假设，分析了音乐、噪音及说话人重叠对自我监督学习收敛及下游微调性能的影响。研究了有效预处理策略，使用Whisper和WhisperX将嘈杂的广播数据集转换为高质量数据集进行预训练。比较了一语言和多语言预训练效果，结果显示一语言预训练对域外数据更加稳健。最终，通过使用55000小时的存档数据对wav2vec 2.0 XLS-R模型进行延续预训练，获得了语音识别领域新纪录的荷兰语言模型。
### Innovation
1. 探索使用存档电视广播数据进行语音模型训练，增强了语言模型对多样数据的适应性；2. 使用Whisper和WhisperX进行预处理以提升模型质量和性能；3. 比较了一语言和多语言预训练效果，提出了一语言预训练对域外数据更加稳健的结论。
### Conclusion
本文通过使用55000小时的存档数据对wav2vec 2.0 XLS-R模型进行延续预训练，建立了新的荷兰语言语音识别基准，表明存档数据在自我监督学习中的潜力。
## 427. `cs.CL` - 使用中间表示代理框架实现异常安全代码生成 [PDF](https://arxiv.org/pdf/2410.06949), [HTML](https://arxiv.org/abs/2410.06949)
### Authors
Xuanming Zhang,Yuxuan Chen,Yuan Yuan,Minlie Huang
### Background
大型语言模型（LLMs）在生成代码时经常遇到健壮的异常处理问题，导致程序具有较大的运行时错误风险。为了改善这一情况，本文提出了一种名为Seeker的新颖多代理框架，通过中间表示（IR）方法强制执行LLM生成代码的异常安全性。Seeker将异常处理分解为五个专门的代理：扫描器、检测器、捕食者、评分器和处理者。这些代理协作分析代码、检测脆弱的代码段、检索最佳实践的异常策略，并注入稳健的异常处理代码。
### Innovation
本文创新地使用中间表示和多代理协作来处理异常，引入了Common Exception Enumeration（CEE）知识库来标准化异常处理策略。提出了深度检索增强生成（Deep RAG）算法，显著减少了搜索开销并提高了识别相关异常的准确性。实验结果表明Seeker在多个开源Java项目和基准测试中的异常处理精度提高了37%，整体代码鲁棒性提高了38%。
### Conclusion
Seeker在处理实际世界问题修复方面表现出色，成功率相比先前方法提高了28%。该框架在保持代码功能正确的同时，能够主动处理错误，为更安全的代码生成提供了一种实用且可扩展的解决方案。文章还讨论了Seeker的扩展潜力，未来可以应用于其他编程语言和复杂的软件工程问题，使LLM生成的代码与工业标准相契合。
## 428. `cs.CV` - 结构化描述改善文本到图像模型的提示一致性（Re-LAION-Caption 19M） [PDF](https://arxiv.org/pdf/2507.05300), [HTML](https://arxiv.org/abs/2507.05300)
### Authors
Nicholas Merchant,Haitz Sáez de Ocáriz Borde,Andrei Cristian Popescu,Carlos Garcia Jurado Suarez
### Background
我们指出，生成性文本到图像模型在大型数据集（如LAION-5B）的嘈杂和非结构化性质下，往往难以遵循提示要求。这迫使用户依赖于提示工程来获得理想的输出。
### Innovation
我们提出在训练过程中使用一致的描述结构可以显著提高模型的可控性和一致性。我们引入了一个新的子集Re-LAION-Caption 19M，它包含1900万幅1024x1024的图像，这些图像的描述是由Mistral 7B Instruct模型生成的，并且遵循一个四部分的模板：主体、环境、美学和摄像机细节。通过使用结构化的和随机打乱的描述对PixArt-$boldsymbol{theta}$和Stable Diffusion 2进行微调，并使用视觉问答（VQA）模型测试显示，结构化的描述版本持续获得更高的文本与图像的一致性评价。
### Conclusion
该数据集已经在GitHub上公开，并展示了结构化描述对于提高文本到图像模型的控制能力和提示一致性的重要性。
## 429. `cs.CV` - 从通用到专用：农业领域对基础模型的需求 [PDF](https://arxiv.org/pdf/2507.05390), [HTML](https://arxiv.org/abs/2507.05390)
### Authors
Vishal Nedungadi,Xingguo Xiong,Aike Potze,Ron Van Bree,Tao Lin,Marc Rußwurm,Ioannis N. Athanasiadis
### Background
随着人口增长和气候变化加剧，粮食安全仍然是全球性问题。可持续农业生产力需求迫切，需要创新解决方案。基础模型在遥感和气候科学方面取得了显著进展，为农业监测提供了新机会，但其在农业相关挑战中的应用（如作物类型映射、作物生长周期估计和作物产量估计）尚未得到充分利用。
### Innovation
构建了农业领域理想基础模型（CropFM）的需求框架，并评估了现有通用基础模型在该框架下的有效性。选择了两个示例性模型，在三个代表性农业特定任务中进行了实证研究，强调了农业领域需要专门的基础模型。
### Conclusion
当前基础模型在农业领域的应用尚不充分，亟需针对农业需求定制专门的基础模型。
## 430. `cs.CL` - 在大语言模型中从根本上控制幻觉的可能性 [PDF](https://arxiv.org/pdf/2506.06382), [HTML](https://arxiv.org/abs/2506.06382)
### Authors
Michał P. Karpowicz
### Background
本文基于现有研究指出，目前的大语言模型（LLMs）无法同时实现真实响应生成、语义信息保存、相关知识揭示以及知识约束下的最优性，即完美幻觉控制在数学上是不可能的。这一不可能性源于信息聚合的数学结构，而不是工程限制。
### Innovation
作者通过拍卖理论、概率预测的适当评分理论以及变压器架构的log-sum-exp分析，证明了信息聚合会不可避免地违反保持原则。研究发现，神经网络推理、知识和推理的哲学以及博弈论和信息论的经典成果之间的深刻联系，并且提出了在数学约束内开发有益AI系统的新型研究方向。
### Conclusion
真fulness、知识利用和响应完整性之间存在基本的权衡。这使得我们重新定义了幻觉，将其从工程漏洞转变为分布式智能的固有数学特征。这项工作为管理而非消除幻觉提供了理论基础。
## 431. `cs.CL` - ALLM4ADD: 使用音频大型语言模型进行音频deepfake检测 [PDF](https://arxiv.org/pdf/2505.11079), [HTML](https://arxiv.org/abs/2505.11079)
### Authors
Hao Gu,Jiangyan Yi,Chenglong Wang,Jianhua Tao,Zheng Lian,Jiayi He,Yong Ren,Yujie Chen,Zhengqi Wen
### Background
由于高质量的音频生成模型的兴起及其潜在的滥用可能性，音频假音检测（ADD）变得越来越重要。尽管音频大型语言模型（ALLMs）在多个音频处理任务中取得了显著进展，但之声并未被用于解决ADD问题。
### Innovation
本文提出了一种基于ALLM的ADD方法，名为ALLM4ADD。具体来说，将ADD任务重新表述为音频问答问题，通过提问‘这段音频是真还是假’来促进模型评估查询音频的真实性。这项研究表明，基于ALLM的方法在假音频检测中表现出色，特别是在数据稀少的情况下。
### Conclusion
本文为基于ALLM的ADD系统开发开辟了先例，预期会激发科研界进一步探索ALLM的应用，以开发更有效的ADD系统。
## 432. `cs.CL` - 使用少量示例学习高效检测间歇性作业失败 [PDF](https://arxiv.org/pdf/2507.04173), [HTML](https://arxiv.org/abs/2507.04173)
### Authors
Henri Aïdasso,Francis Bordeleau,Ali Tizghadam
### Background
开发人员在使用持续集成（CI）和自动部署管道时面临的主要挑战之一是间歇性作业失败，这些失败是由意料之外的非确定性问题（如不可靠的测试或基础设施问题）引起的，而不是常规的代码错误。之前的研究使用大量作业日志训练机器学习（ML）模型来分类作业失败，是为间歇性或常规的。现有的先进方法依赖于基于非确定性重跑的启发式方法，但这种方法在重跑可疑失败作业不是显式策略的情况下会误标间歇性失败为常规失败，从而限制了其实际性能。我们的手动分析发现，在五个工业性和一个开源项目的2,125个失败中，平均有32%的间歇性失败被误标为常规失败。
### Innovation
本文提出了一种基于少量示例学习（Few-Shot Learning, FSL）的间歇性作业失败检测方法。具体来说，使用几个手动标注的日志示例微调一小段语言模型，生成丰富的嵌入，然后用于训练ML分类器。FSL方法在所有项目中实现了70-88%的F1分数，而在4个项目中SOTA方法仅实现了34-52%的F1分数。这项研究强调了数据质量的重要性，提供了一个更有效的间歇性作业失败检测框架，适用于组织中使用的小规模标记数据集。
### Conclusion
本文的研究表明，通过将少量手动标注的日志示例用于微调小型语言模型生成的嵌入，然后应用于训练ML分类器，可以实现高效的间歇性作业失败检测。此方法不仅性能优于现有的先进方法，还强调了数据质量的重要性，对组织中的间歇性作业失败检测具有重要意义。
## 433. `cs.CV` - Awareness导向的虚拟染色用于精确的3D细胞形态学分析 [PDF](https://arxiv.org/pdf/2507.05383), [HTML](https://arxiv.org/abs/2507.05383)
### Authors
Alexandr A. Kalinin,Paula Llanos,Theresa Maria Sommer,Giovanni Sestini,Xinhai Hou,Jonathan Z. Sexton,Xiang Wan,Ivo D. Dinov,Brian D. Athey,Nicolas Rivron,Anne E. Carpenter,Beth Cimini,Shantanu Singh,Matthew J. O'Meara
### Background
显微镜能够直接观察细胞在三维环境中的形态，透射光方法提供低成本、微创成像，而荧光显微镜则提供特异性和对比度。虚拟染色通过机器学习预测标签自由输入的荧光图像，结合了这两种方法的优点。然而，现有的方法通常依赖于对待所有像素相同的损失函数，从而复制背景噪声和伪影，而非聚焦生物学有意义的信号。当前方式的训练存在一个缺陷，即没有特别关注细胞结构，导致图像质量不佳，不利于后续的任务如分割和表型分析。这篇论文所介绍的Spotlight方法旨在解决这一问题。
### Innovation
Spotlight方法通过使用基于直方图的前景估计来掩蔽像素级损失，同时对软阈值预测进行Dice损失计算，实现了形状感知学习。这种方法引导模型专注于相关细胞结构，并提升了形态学的准确表示，保持了像素级的精确度，使得虚拟染色更适合下游任务如分割和表型分析。
### Conclusion
Spotlight方法对于3D细胞形态学的表征有显著的改进，同时保持了像素级别的准确性，使其更适合下游任务如分割和表型分析。
## 434. `cs.CV` - YOLO-APD：增强 YOLOv8 以在复杂几何路面上实现鲁棒的人行横道检测 [PDF](https://arxiv.org/pdf/2507.05376), [HTML](https://arxiv.org/abs/2507.05376)
### Authors
Aquino Joctum,John Kandiri
### Background
自主车辆的感知系统需要在复杂几何路面上（如 Type-S 曲线路面）实现可靠的行人检测，而传统的基于 RGB 摄像头的方法在此类路面上存在局限性。这类道路的高难度几何结构对标准的人行检测技术构成了挑战，而本文针对这一问题引入 YOLO-APD，这是一种改进展的 YOLOv8 框架的新颖深度学习架构，专门用于行人检测的精准化需求。
### Innovation
YOLO-APD 结合了若干关键的架构改进：无参数的 SimAM 注意机制、高效 C3Ghost 模块、具有增强多尺度特征池合功能的 SimSPPF 模块、Mis 激活函数，以及卓越特征融合的智能汇集与分散 (IGD) 模块。此外，该研究引入了利用车辆转向动力学进行自适应兴趣区域处理的概念。通过在自定义 CARLA 数据集上的综合评估，研究证明 YOLO-APD 达到了最先进的检测精度，同时具有高实时处理能力并保持优异的平衡性。削层分析表明每个集成组件都有显著的贡献。
### Conclusion
YOLO-APD 在 CARLA 数据集上显示出卓越的检测准确性和高实时性能，同时在 KITTI 数据集上也得到了验证，但仍需要进一步的数据集特定适应。该研究推进了低成本传感器基础的高精度、高效且适应性好的感知系统的发展，提升在复杂、未结构化驾驶环境中自主导航的安全性和可靠性。
## 435. `cs.CV` - 使用主观图像质量集成的深度学习增强水下图像 [PDF](https://arxiv.org/pdf/2507.05393), [HTML](https://arxiv.org/abs/2507.05393)
### Authors
Jose M. Montero,Jose-Luis Lisani
### Background
近年来，深度学习尤其是神经网络在众多领域产生了显著影响，包括水下图像的自动增强。该研究利用专家标注的数据集，提出了一种结合人类主观评估的深度学习方法来提升水下图像质量，通过先训练分类网络区分高质量和低质量水下图像，再使用生成对抗网络（GANs）基于多种增强标准对低质量图像进行优化。研究通过PSNR、SSIM和UIQM等定量指标以及质性分析来评估GAN模型的表现，结果表明加入颜色保真度等增强标准能够显著提升图像质量，不论是感知还是测量方面都取得了实质性进步。
### Innovation
该方法创新之处在于将人类主观评估纳入训练过程，训练分类网络来识别高质量与低质量的水下图像，随后使用GANs进行低质量图像的优化，通过结合不同的增强标准来提升图像的整体质量。
### Conclusion
实验结果表明，提出的模型在引入颜色保真度、图像清晰度等增强标准的情况下，显著提高了水下图像的感知和测量质量。
## 436. `cs.CL` - MedGemma 技术报告 [PDF](https://arxiv.org/pdf/2507.05201), [HTML](https://arxiv.org/abs/2507.05201)
### Authors
Andrew Sellergren,Sahar Kazemzadeh,Tiam Jaroensri,Atilla Kiraly,Madeleine Traverse,Timo Kohlberger,Shawn Xu,Fayaz Jamil,Cían Hughes,Charles Lau,Justin Chen,Fereshteh Mahvar,Liron Yatziv,Tiffany Chen,Bram Sterling,Stefanie Anna Baby,Susanna Maria Baby,Jeremy Lai,Samuel Schmidgall,Lu Yang,Kejia Chen,Per Bjornsson,Shashir Reddy,Ryan Brush,Kenneth Philbrick,Howard Hu,Howard Yang,Richa Tiwari,Sunny Jansen,Preeti Singh,Yun Liu,Shekoofeh Azizi,Aishwarya Kamath,Johan Ferret,Shreya Pathak,Nino Vieillard,Ramona Merhej,Sarah Perrin,Tatiana Matejovicova,Alexandre Ramé,Morgane Riviere,Louis Rouillard,Thomas Mesnard,Geoffrey Cideron,Jean-bastien Grill,Sabela Ramos,Edouard Yvinec,Michelle Casbon,Elena Buchatskaya,Jean-Baptiste Alayrac,Dmitry Lepikhin,Vlad Feinberg,Sebastian Borgeaud,Alek Andreev,Cassidy Hardin,Robert Dadashi,Léonard Hussenot,Armand Joulin,Olivier Bachem,Yossi Matias,Katherine Chou,Avinatan Hassidim,Kavi Goel,Clement Farabet,Joelle Barral,Tris Warkentin,Jonathon Shlens,David Fleet,Victor Cotruta,Omar Sanseviero,Gus Martins,Phoebe Kirk,Anand Rao,Shravya Shetty,David F. Steiner,Can Kirmizibayrak,Rory Pilgrim,Daniel Golden,Lin Yang
### Background
人工智能（AI）在医疗应用中具有巨大的潜力，但由于医疗数据的多样性和复杂性以及对隐私的保护需求，其训练和部署面临挑战。基础模型在医疗任务中表现良好且需要较少的任务特定调优数据，对于加速健康医疗AI应用的发展至关重要。MedGemma 是基于 Gemma 3 4B 和 27B 两种基础模型的医疗视觉-语言基础模型集合，展示了在图像和文本方面高级的医疗理解与推理能力，显著优于相似规模的生成模型，同时保持了 Gemma 3 基础模型的一般能力。
### Innovation
MedGemma 是一种医疗视觉-语言基础模型集合，能够实现医疗图像和文本理解的高级医疗理解和推理能力。相对于普通基础模型，MedGemma 在医学多模态问题回答、胸部X光发现分类和去分布任务方面表现出显著的性能提升。在视觉理解方面，MedSigLIP（一种医学调优的视觉编码器）提供了具有竞争力或更好的表现，进一步提升了 MedGemma 的整体性能。
### Conclusion
MedGemma 收集提供了一个医疗图像和文本能力的强大基础，有助于显著加快医学研究和下游应用的开发。目前，MedGemma 集合包括教程和模型权重，可在此网址找到：[https://medgemma.com]() 的更详细信息。
## 437. `cs.CV` - CorrDetail：面部伪造检测中的视觉细节增强自我修正 [PDF](https://arxiv.org/pdf/2507.05302), [HTML](https://arxiv.org/abs/2507.05302)
### Authors
Binjia Zhou,Hengrui Lou,Lizhe Chen,Haoyuan Li,Dawei Luo,Shuai Chen,Jie Lei,Zunlei Feng,Yijun Bei
### Background
随着图像生成技术的迅速发展，面部深度伪造的广泛应用给安全领域带来了重要挑战，这加剧了对有效伪造检测技术的需求。目前的面部伪造检测技术主要分为基于视觉的方法和多模态方法。基于视觉的方法缺乏对伪造细节的清晰解释，而合并视觉和语言模态的多模态方法则更容易面临模型偏见的问题。
### Innovation
为解决这些问题，本文提出了一种名为CorrDetail的可解释面部伪造检测的视觉细节增强自我修正框架。CorrDetail设计了一个纠错模块，在提供错误指导的询问时会修正真实的伪造细节，以提升发现伪造细节的能力，而非生成虚假响应。此外，该框架还包含一个视觉细粒度细节增强模块，以提供更准确的视觉伪造细节来增强其发现能力。最后，通过视觉信息补偿和模型偏见的融合决策策略进一步增强了模型对极端样本的判别能力。
### Conclusion
实验结果表明，CorrDetail不仅在最新的方法中取得了最先进的性能，而且在准确识别伪造细节方面也有出色表现，并展示了强大的泛化能力。
## 438. `cs.CV` - 掌握区域3DGS：利用多样2D先验进行定位、初始化和编辑 [PDF](https://arxiv.org/pdf/2507.05426), [HTML](https://arxiv.org/abs/2507.05426)
### Authors
Lanqing Guo,Yufei Wang,Hezhen Hu,Yan Zheng,Yeying Jin,Siyu Huang,Zhangyang Wang
### Background
许多三维场景编辑任务侧重于局部区域的修改而非整个场景，尤其是在三维高斯点渲染（3DGS）中，场景被表示为一系列高斯点，这使得精细的区域编辑成为可能。然而，由于3D语义解析通常不如2D语义解析性能好，使得三维空间中的目标操作更加困难，并限制了编辑的精确度。针对这些问题，该研究利用2D扩散编辑精确识别每个视角的修改区域，然后进行逆向渲染，在三维空间中定位这些修改区域。接着从深度图中预测的形状初始化一个粗略的三维高斯点阵（3DGS），从而支持一个迭代的、视图一致的编辑过程，使结构细节和材质能够逐步细化并确保各视角的一致性。实验结果表明该方法在保持高精度的同时，比现有方法快4倍，提供了更高效的方法实现三维局部编辑。
### Innovation
该研究通过利用2D扩散编辑和逆渲染技术，实现三维局部编辑的高效和精确。关键创新点包括：（1）利用2D扩散编辑精确识别修改区域；（2）通过逆渲染在三维空间中定位这些修改区域；（3）从预测的深度图中获取初始的3DGS；（4）支持迭代、视图一致的编辑过程，确保局部细化兼顾全局一致性。
### Conclusion
实验结果表明，该方法能够实现与现有方法相当甚至更优的编辑效果，同时提供高达4倍的速度提升，从而提供了一种更高效和有效的三维局部场景编辑方法。
## 439. `cs.CV` - 作为诊断工具的驾驶：驾驶视频中老年驾驶员基于情景的认知评估 [PDF](https://arxiv.org/pdf/2507.05463), [HTML](https://arxiv.org/abs/2507.05463)
### Authors
Md Zahid Hasan,Guillermo Basulto-Elias,Jun Ha Chang,Sahuna Hallmark,Matthew Rizzo,Anuj Sharma,Soumik Sarkar
### Background
近年来，包括阿尔茨海默病（AD）和轻度认知障碍（MCI）在内的认知下降常因现有诊断方法耗时且昂贵而被低估。通过分析通过车载系统捕捉的实时驾驶行为，本研究旨在提取与MCI和AD的功能下降和临床特征相关的“数字指纹”。现代大型视觉模型可以从老年患者的日常驾驶模式中提取有意义的信息，以早期发现认知下降。
### Innovation
本文提出了一种框架，利用大型视觉模型和自然驾驶视频来分析驾驶行为、分类认知状态并预测疾病进展。该方法利用车辆作为‘诊断工具’来观察驾驶员的当前认知状态，从而识别功能损伤的早期预警信号，促进主动干预策略，增强早期检测，并支持开发可扩展、无创的监控系统，以减轻老龄化人口认知下降的社会和经济负担。
### Conclusion
这项工作提高了早期检测的认知能力，并支持了在老龄化社会中发展可扩展和非侵入性的监测系统的努力，以减轻认知下降的社会和经济负担。
## 440. `cs.CL` - SciMaster: 第一部分. X-Master作为基础：我们能在人类最后考试中领先吗？ [PDF](https://arxiv.org/pdf/2507.05241), [HTML](https://arxiv.org/abs/2507.05241)
### Authors
Jingyi Chai,Shuo Tang,Rui Ye,Yuwen Du,Xinyu Zhu,Mengcheng Zhou,Yanfeng Wang,Weinan E,Yuzhi Zhang,Linfeng Zhang,Siheng Chen
### Background
人工智能代理的快速发展激发了利用它们加速科学发现的长期愿望。实现这一目标需要对人类知识前沿有深刻理解。为此，人类最后考试（HLE）为评估科学AI代理提供了极具挑战性的标准。本工作旨在构建通用AI代理的基础架构，并通过在HLE上的卓越表现进行验证。
### Innovation
引入了X-Master，一种工具增强的推理代理，能够在推理过程中灵活使用外部工具。X-Master受到代码作为一种交互语言的概念启发，可以灵活利用内置的Python库和定制工具来增强推理。此外，通过一种分而治之和堆积的智能体工作流程扩展了其能力，实现了在HLE上的出色表现，并首次超越了30%的阈值。
### Conclusion
本工作使我们对复杂任务解决有了更深的理解，并积累了可指导未来进展的宝贵经验，有助于后续模型训练。X-Master在HLE中的卓越表现标志着科学AI代理领域的重要突破。
## 441. `cs.CV` - OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts [PDF](https://arxiv.org/pdf/2507.05427), [HTML](https://arxiv.org/abs/2507.05427)
### Authors
Shiting Xiao,Rishabh Kabra,Yuhang Li,Donghyun Lee,Joao Carreira,Priyadarshini Panda
### Background
基于开放语义提示的对象分割能力仍然是一个关键挑战，需要模型将文本语义精确地映射到空间掩码中，同时处理多样且未见过的类别。现有模型在处理开放词汇场景时面临瓶颈，尤其是在分割任务的实现上灵活性不够，并且在获取多样且复杂的提示时表现出色有限。OpenWorldSAM通过引入一种新的框架，旨在提升现有技术的灵活性和资源效率，使其适应跨各类别的分割需求。
### Innovation
OpenWorldSAM创新地通过引入一个轻量级的多模态嵌入模型，将SoftSAM v2扩展到开放词汇场景。该框架具备四种关键特性：统一提示（支持多样化的提示包括类别级和句子级语言描述）、高效性（训练参数量少，资源效率高）、实例感知（通过新颖的空间位置竞争嵌入和跨注意力层提升空间理解）、泛化能力（强大的零样本泛化能力，能够处理未见过的类别和概念）。
### Conclusion
OpenWorldSAM在ADE20k、PASCAL、ScanNet和SUN-RGBD等多个基准测试中表现出了在开放词汇语义分割、实例分割和全景分割方面达到了最先进的性能。
## 442. `cs.CV` - 云扩散模型 第一部分：理论与动机 [PDF](https://arxiv.org/pdf/2507.05496), [HTML](https://arxiv.org/abs/2507.05496)
### Authors
Andrew Randono
### Background
扩散模型用于图像生成，通过逐步对图像集添加噪声来训练模型以分离出信号与噪声。这些模型使用的是白色噪声，即基于点独立高斯分布的噪声，具有独立的均值和方差，而不依赖于尺度。相比之下，大多数自然图像集在低阶统计特性上表现出尺度不变性，具有幂律尺度变化。因此，自然界中的图像更多地接近于一个不同概率分布，该分布侧重于大尺度关联而弱化小尺度关联。这种尺度不变噪声配置可以替代白色噪声纳入扩散模型形成所谓的“云扩散模型”。
### Innovation
提出了一种新的‘云扩散模型’，通过使用自然图像具有的尺度不变性替代传统的白色噪声，从而实现更快的推理、改善高频细节和提高可控性。
### Conclusion
提出云扩散模型可以带来更快的推理速度、更高质量的高频细节和更好的可控性；将在后续论文中构建和训练基于尺度不变性原理的云扩散模型，并与经典白色噪声扩散模型进行比较。
## 443. `cs.CV` - Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model [PDF](https://arxiv.org/pdf/2507.05513), [HTML](https://arxiv.org/abs/2507.05513)
### Authors
Mengyao Xu,Gabriel Moreira,Ronay Ak,Radek Osmulski,Yauhen Babakhin,Zhiding Yu,Benedikt Schifferer,Even Oldridge
### Background
随着多模态检索系统需求的增长，本文介绍了llama-nemoretriever-colembed，这是一种统一的文本-图像检索模型，实现了多个基准上的前沿性能。该模型提供了两个模型变体：1B和3B。
### Innovation
该方法利用了NVIDIA Eagle2 视觉语言模型(VLM)，通过将因果注意力替换为双向注意力并集成ColBERT风格的后期交互机制来实现共享嵌入空间中的精细化多模态检索。尽管此种机制提高了检索精度，但存储和效率方面存在折衷。
### Conclusion
我们采用两阶段训练策略来增强模型的检索能力。到6月27日，3B模型在ViDoRe V1和ViDoRe V2上分别达到了NDCG@5 91.0和63.5的评分开并赢得两个排行榜的第一名。我们提供了存储和效率折衷行为的全面分析。
## 444. `cs.CV` - LoomNet: 通过潜在空间编织增强多视图图像生成 [PDF](https://arxiv.org/pdf/2507.05499), [HTML](https://arxiv.org/abs/2507.05499)
### Authors
Giulio Federico,Fabio Carrara,Claudio Gennaro,Giuseppe Amato,Marco Di Benedetto
### Background
从单张图像生成具有一致性的多视图图像仍然是一个挑战。缺乏空间一致性会在表面重建的3D网格质量上造成负面影响。为了应对这一问题，本研究提出了LoomNet，这是一种新颖的多视图扩散架构，通过并行应用相同的扩散模型来协作构建和利用共享的潜在空间，以此来实现视图一致性。
### Innovation
LoomNet通过并行应用相同的扩散模型，并将每个视角特定的推断生成的编码投影到三个正交平面，从这些编码中聚合出单一的聚合平面，然后处理这些聚合平面以传递信息并插补缺失区域，从而将多种假设统一成一个一致解释的最终潜在空间。LoomNet能在15秒内生成16张高质量且一致的视图，实验表明它在图像质量和重建度量上都优于现状最佳方法，并展示了创造性的能力，能够从相同的输入生成多样且合理的新型视图。
### Conclusion
LoomNet通过潜在空间编织能够高效且高质量地生成多视图图像，并且在图像质量和重建度量上表现出色，同时展现了创造性能力。
## 445. `cs.CV` - 基于资源限制条件下的自主感知，模拟折射失真和天气诱导的伪影 [PDF](https://arxiv.org/pdf/2507.05536), [HTML](https://arxiv.org/abs/2507.05536)
### Authors
Moseli Mots'oehli,Feimei Chen,Hok Wai Chan,Itumeleng Tlali,Thulani Babeli,Kyungim Baek,Huaijin Chen
### Background
发展中国家尤其是非洲地区的自动驾驶车辆数据集短缺，特别是在多样化的城市、乡村和未铺装路面上的车辆数据严重不足，这成了低资源环境下实现稳健感知的一大障碍。
### Innovation
论文提出了一种程序化的增强流水线，通过加入现实的折射失真和天气诱导的伪影，提升低成本单目车内摄像头视频的质量。折射模块模拟了低质量镜头和空气湍流引起的光学效应，包括镜头失真、Perlin噪声、薄板样条（TPS）变形和无散（不可压缩）变形。天气模块则增加了均匀雾、非均匀雾和镜头眩光。为了建立基准线，还使用三种图像修复模型提供了基准性能数据。
### Conclusion
为了支持对非洲欠代表地区感知研究的支持，无需花费大量资金进行数据采集、标注或仿真，论文发布了其失真工具包、增强的数据集分割和基准结果。
## 446. `cs.CV` - 跨模态特征过渡的多模态人脸识别反冒充 [PDF](https://arxiv.org/pdf/2507.05575), [HTML](https://arxiv.org/abs/2507.05575)
### Authors
Jun-Xiong Chong,Fang-Yu Hsu,Ming-Tsung Hsu,Yi-Ting Lin,Kai-Heng Chien,Chiou-Ting Hsu,Pei-Kai Huang
### Background
多模态人脸识别反冒充(Multi-modal Face Anti-Spoofing, FAS)旨在通过从多模态数据（如RGB、红外和深度图像）中提取有区别的生命迹象，以增强生物特征认证系统的鲁棒性。然而，不同模态的数据通常由不同传感器捕获，并在不同的环境条件下获得，这导致多模态FAS在训练和测试领域之间表现出更大的分布差异。此外，在推理阶段，如果一个或多个模态不可用或不可访问，多模态FAS会面临更大的挑战。
### Innovation
本文提出了一种新颖的跨模态过渡引导网络(Cross-modal Transition-guided Network, CTNet)，以应对多模态FAS任务中的挑战。动机来自于在单个模态内，真人面部的视觉差异通常比伪造面部的差异小。跨模态特征过渡在真人类别中的一致性比在真人与伪造者类别之间的过渡一致性更高。为此，首先提出了学习跨模态特征过渡的真正样本集中的一致，构建一个通用特征空间。其次，引入了学习真伪样本集之间不一致的跨模态特征过渡，以有效检测推理阶段的分布外(Out-of-distribution, OOD)攻击。此外，为了应对模态缺失问题，提出从RGB模态学习补充的红外(Infrared)和深度特征作为辅助模态。
### Conclusion
广泛实验证明，所提出的CTNet在大多数协议上优于之前的双类多模态FAS方法。
## 447. `cs.CV` - 运动生成：生成模型方法及基准的综述 [PDF](https://arxiv.org/pdf/2507.05419), [HTML](https://arxiv.org/abs/2507.05419)
### Authors
Aliasghar Khani,Arianna Rampini,Bruno Roy,Larasika Nadela,Noa Kaplan,Evan Atherton,Derek Cheung,Jacky Bibliowicz
### Background
运动生成是从各种条件输入中合成逼真运动序列的任务，已成为计算机视觉、计算机图形学和机器人学的核心问题，应用于动画、虚拟代理以及人机交互等多个领域。随着包括GANs、自编码器、自回归模型和基于扩散的技术在内的多种建模范式的引入，研究领域取得了快速进展，但每种方法都有其优点和局限性。因此，需要对近年来基于生成方法的研究进行综合和结构化的回顾，以明确比较并识别开放挑战，为研究者和实践者提供有价值的参考文献，指导他们应对快速发展的运动生成领域的问题。
### Innovation
本文提供了基于生成策略的运动生成方法的深入分类，并重点介绍自2023年以来在顶级会议发表的文献，涵盖了最新的研究进展。同时分析了架构原则、条件机制和生成设置，总结了文献中使用的评估指标和数据集，旨在为研究者和实践者提供清晰的比较框架，并识别开放挑战，从而提供及时的基础参考文献，用于导航快速发展的运动生成领域.
### Conclusion
本文的贡献在于提供了自2023年以来顶级会议关于运动生成的生成方法的全面回顾，明确了比较生成模型的关键因素，鉴别出了当前研究中的关键挑战，为未来的研究提供了基础且及时的参考信息。
## 448. `cs.CV` - ReLayout: 结合关系推理的多模态大型语言模型用于内容感知布局生成 [PDF](https://arxiv.org/pdf/2507.05568), [HTML](https://arxiv.org/abs/2507.05568)
### Authors
Jiaxu Tian,Xuehui Yu,Yaoxing Wang,Pan Wang,Guangqian Guo,Shan Gao
### Background
内容感知布局旨在将设计元素适当地排印在给定画布上以有效地传达信息。最近，生成布局的自动方法趋势是利用大型语言模型（LLMs），取得了显著的性能。然而，现有的基于LLM的方法无法充分解释视觉主题和设计元素之间的空间关系，导致布局生成中的结构和多样性问题。迄今为止，方法的主要问题是缺乏有效的处理空间关系的方法。
### Innovation
ReLayout引入了一种新的方法，利用关系-CoT（共情推理）来生成更加合理且美学协调的布局，从根本上源于设计概念。具体来说，通过引入显式的元素关系定义，如区域、显著元素和边缘等，增强布局注释，分解布局为更小的、结构化的、递归化的布局，从而能够生成更为结构化的布局。此外，基于这些定义的关系，引入了一种布局原型重平衡采样器，该采样器定义了分布在三维空间中的布局原型特征，并量化了独特的布局风格。这个采样器解决了由于原型分布平衡过程中的数据偏差而导致的生成多样性不足的问题。
### Conclusion
广泛的实验结果表明，ReLayout在性能上优于基线方法，并且能够生成结构更加合理且多样、更符合人类美学和更具解释性的布局。
## 449. `cs.CV` - 通过条件扩散和CLIP引导噪声过滤的半监督缺陷检测 [PDF](https://arxiv.org/pdf/2507.05588), [HTML](https://arxiv.org/abs/2507.05588)
### Authors
Shuai Li,Shihan Chen,Wanru Geng,Zhaohua Xu,Xiaolu Liu,Can Dong,Zhen Tian,Changlin Chen
### Background
在工业质量检测领域，缺陷检测是一项至关重要的任务，尤其在汽车零部件、航空航天和医疗设备等高精度、安全性关键的领域。传统的方法依赖于人工检测或早期的图像处理算法，存在效率低下、成本高和鲁棒性差等问题。
### Innovation
该论文提出了一种基于条件扩散的半监督缺陷检测框架(DSYM)，通过两阶段协作训练机制和阶段化联合优化策略。框架利用标记数据进行初始训练，然后通过伪标签整合未标记数据。条件扩散模型生成多尺度伪缺陷样本，CLIP跨模态特征基于噪声过滤机制减轻标签污染。实验结果表明，在具有相同数量标记数据的情况下，DSYM的mAP@0.5达到了78.4%，而在所需标记数据仅为原监督模型40%的情况下，mAP@0.5达到了75.1%，展现出在数据效率方面的显著优势。
### Conclusion
该研究为工业质量检测场景中的缺陷检测提供了高精度、低标注依赖的解决方案。该文章的工作已开源。
## 450. `cs.CV` - pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models [PDF](https://arxiv.org/pdf/2507.05394), [HTML](https://arxiv.org/abs/2507.05394)
### Authors
Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani
### Background
Vision-Language Models (VLMs)如CLIP等已经在零样本和少量样本设置中展现了显著的泛化能力，但在高效适应去中心化、异构数据方面仍面临挑战。现有的提示调优方法因强调个性化而往往牺牲泛化能力，特别是在处理未见过的类别或领域时表现出色。这个问题催生了个性化联邦学习的需求，即在保护用户隐私的同时实现模型个性化和全局泛化的良好平衡。
### Innovation
本文提出了pFedMMA，这是第一个利用多模态适配器的个性化联邦学习框架，特别适用于视觉-语言任务。该框架通过引入自适应优化策略，使客户端能够适应个性化数据分布，同时协作训练共享投影以提升全局泛化能力。更重要的是，这种设计还具有通信效率高、仅需交换共享组件的特点。实验结果表明，pFedMMA 在个人化和泛化之间实现了最佳平衡，比最近的联邦提示调优方法更胜一筹。
### Conclusion
通过在包含领域和标签变化场景在内的多个数据集上进行广泛实验，证明了pFedMMA 实现了个人化和泛化的最佳权衡，展示了其在视觉-语言模型个性化联邦学习中的卓越能力。此外，相关的源代码已公开可供参考。
## 451. `cs.CV` - GSVR：基于2D高斯分布的视频表示以实现每秒800帧以上速度的混合变形场视频表示 [PDF](https://arxiv.org/pdf/2507.05594), [HTML](https://arxiv.org/abs/2507.05594)
### Authors
Zhizhuo Pang,Zhihui Ke,Xiaobo Zhou,Tie Qiu
### Background
隐式神经表示方法在视频表示中被视为一种新颖且有前途的形式。现有研究更关注提高视频重建质量，而较少关注解码速度。现有方法中采用的卷积网络计算量大，导致解码速度低，且这些基于卷积的视频表示方法训练时间较长，Bunny数据集上的帧训练时间约为14秒，才能达到35+ PSNR。因此，作者研究了如何解决计算量大和训练时间长的问题，并提出了一种新的基于2D高斯分布的视频表示方法GSRV，其不仅实现了800+ FPS和35+ PSNR，而且帧训练时间仅为2秒，远超现有方法，并且解码速度比其他方法快10倍。
### Innovation
作者提出了一种称为GSVR的基于2D高斯分布的新型视频表示方法。该方法通过结合三平面运动和多项式运动来建模视频的动力学。为了高效处理视频中的动态内容，作者还设计了一种动态感知的时间切片策略，从而实现更紧凑的表示。此外，通过量化感知微调和图像编解码技术来压缩高斯分布，从而在保持性能的情况下实现视频的快速解码；并且实验结果证明该方法在视频插值任务中的性能与当前最佳方法相当，而在视频压缩性能方面优于NeRV。
### Conclusion
与现有的视频表示方法相比，GSVR在Bunny和UVG数据集上的实验结果表明，其收敛速度更快，并且具有10倍以上的解码速度优势。此外，该方法在视频插值任务中的性能与SOTA相当，并且具有更好的视频压缩性能。
## 452. `cs.CV` - 生成头戴式摄像头捕获以实现逼真的虚拟形象 [PDF](https://arxiv.org/pdf/2507.05620), [HTML](https://arxiv.org/abs/2507.05620)
### Authors
Shaojie Bai,Seunghyeon Seo,Yida Wang,Chenghui Li,Owen Wang,Te-Li Wang,Tianyang Ma,Jason Saragih,Shih-En Wei,Nojun Kwak,Hyung Jun Kim
### Background
在虚拟现实（VR）和增强现实（AR）中实现高逼真度的虚拟形象动画具有挑战性，因为难以获取面部的真实状态。头部戴式摄像头（HMC）的捕捉输入具有部分的红外（IR）观察结果，而室外安装的穹顶摄像头具有全景观察结果，这些观察结果能够匹配虚拟形象的外观。先前的方法依赖于合成分析方法，可以生成准确的真实数据，但这些方法在个人化训练过程中难以分离表情和风格。同时，需要进行大量的配对捕捉（HMC和穹顶摄像头），这使得大规模数据集的构建既昂贵又难以操作，而且无法利用这些数据集用于不同视角和光照条件下的HMC捕捉。
### Innovation
本文提出了一种新颖的生成方法——生成型HMC（GenHMC），该方法利用了大量的非配对HMC捕捉数据（这种数据采集过程更为简便），可以生成高质量的合成HMC图像，给定任何由穹顶摄像头捕捉生成的条件虚拟形象状态。该方法能够有效分离人脸表情、视角的信息，从而产生更为准确的真实数据，并且可以推广到未见过的个体，无需依赖配对捕捉。通过评估合成HMC图像和从这些新的HMC-虚拟形象对应关系训练出的通用脸部编码器，验证了其高效的使用数据能力和目前最佳的准确性优势。
### Conclusion
本研究提出了一种新颖的方法，通过使用大量的非配对HMC捕捉数据，能够直接生成高质量的虚拟形象给定任何来自穹顶摄像头的状态条件。该方法能够有效分离面部表情和视角信息，从而产生更为准确的真实数据，并且可以适用于未见过的个体，无需依赖配对捕捉。这种方法通过新合成的HMC图像和训练出的视频编码器，展示了其高效地使用数据和目前最佳的准确性。
## 453. `cs.CV` - Kernel Density Steering: Inference-Time Scaling via Mode Seeking for Image Restoration [PDF](https://arxiv.org/pdf/2507.05604), [HTML](https://arxiv.org/abs/2507.05604)
### Authors
Yuyang Hu,Kangfu Mei,Mojtaba Sahraee-Ardakan,Ulugbek S. Kamilov,Peyman Milanfar,Mauricio Delbracio
### Background
现有的扩散模型在图像恢复任务中表现出潜力，但它们往往难以提供一致的高保真度输出，并且容易产生不良的图案。
### Innovation
文章提出了一种名为Kernel Density Steering（KDS）的新颖推理时框架，通过显式的局部模态寻优来促进稳健和高保真的输出。KDS使用N个扩散样本的粒子群，计算这些样本在集体输出中的局部核密度估计梯度，通过这些梯度可以引导每个粒子中的片段向集体中更高密度的区域移动，从而避免产生不良模态，并趋向更稳健、高保真的结构。
### Conclusion
广泛的数值验证表明，KDS在具有挑战性的实时超分辨率和图像修补任务中能够显著提高定量和定性的性能。作为可插拔框架，KDS无需重新训练或外部验证者，可以无缝集成到不同的扩散采样器中。
## 454. `cs.CV` - AdaptaGen: 通过层次语义优化框架实现领域特定图像生成 [PDF](https://arxiv.org/pdf/2507.05621), [HTML](https://arxiv.org/abs/2507.05621)
### Authors
Suoxiang Zhang,Xiaxi Li,Hongrui Chang,Zhuoyan Hou,Guoxin Wu,Ronghua Ji
### Background
领域特定图像生成旨在为特定领域生成高质量的视觉内容，同时确保语义准确性和细节保真度。现有方法存在两个关键限制：一是当前方法将提示工程和模型适应分开处理，忽略了在特定领域中语义理解和视觉表示之间的内在依赖关系；二是现有技术在内容合成过程中未能充分融入领域特定的语义约束，导致生成结果出现幻觉和语义偏差。
### Innovation
本文提出了一种层次语义优化框架AdaptaGen，该框架结合了基于矩阵的提示优化和多视角理解，同时从全局和局部两个角度捕捉综合语义关系。此外，为了减轻特定领域中的幻觉现象，设计了跨模态适应机制，在结合智能内容合成的同时，能够保留核心主题元素并跨图像引入多样化细节。在生成阶段，还引入了两阶段的caption语义转换，这种方法保持语义连贯性的同时增加视觉多样性，确保生成的图像符合特定领域的约束条件。
### Conclusion
实验结果验证了我们方法的有效性，我们的框架在40个来自不同数据集的类别中仅使用每类16张图片，便表现出优于现有方法的性能，主要表现在图像质量、多样性和语义一致性方面有了显著提升。
## 455. `cs.CV` - OFFSET: 基于分割的焦点调整修订网络用于组成的图像检索 [PDF](https://arxiv.org/pdf/2507.05631), [HTML](https://arxiv.org/abs/2507.05631)
### Authors
Zhiwei Chen,Yupeng Hu,Zixu Li,Zhiheng Fu,Xuemeng Song,Liqiang Nie
### Background
CIR作为一种新的检索范式，能够灵活表达用户的复杂检索需求。然而，当前的方法仍然存在两类局限性：1) 忽视了视觉数据中主要部分和噪声之间的不一致性，导致查询特征退化；2) 在图像修改过程中忽视了文本数据的优先级，导致视觉焦点偏倚。因此，本文提出了一种基于焦点映射的特征提取器，该提取器包括两个模块：主要部分分割和双向焦点映射，用于识别图像中的显著主要部分并引导视觉和文本数据特征的提取，从而减少噪声干扰的影响。此外，还提出了一种文本引导的焦点修订模块，可以通过利用文本中隐含的修改需求来对参考图像进行自适应的焦点修订，从而增强对组合特征修改焦点的感知。
### Innovation
本文提出了一种基于分割的焦点调整修订网络（OFFSET），该网络包括两个模块：主要部分分割和双向焦点映射，用于识别图像中的显著主要部分并引导视觉和文本数据特征的提取，以及一个文本引导的焦点修订模块，用于对参考图像进行自适应的焦点修订，从而增强对组合特征修改焦点的感知。这些模块共同构成了基于分割的焦点调整修订网络（OFFSET），该方法在四个基准数据集上进行了全面实验，证明了其优越性。
### Conclusion
提出的基于分割的焦点调整修订网络（OFFSET）在四个基准数据集上的综合实验结果验证了其优越性，代码和数据可在指定链接上获取。
## 456. `cs.CV` - 基于AI的实时杂草检测、 canopy aware 喷洒及喷雾模式评估机器人系统 [PDF](https://arxiv.org/pdf/2507.05432), [HTML](https://arxiv.org/abs/2507.05432)
### Authors
Inayat Rasool,Pappu Kumar Yadav,Amee Parmar,Hasan Mirzakhaninafchi,Rikesh Budhathoki,Zain Ul Abideen Usmani,Supriya Paudel,Ivan Perez Olivera,Eric Jone
### Background
在现代农业中，均匀且过度使用除草剂增加了投入成本、环境污染，并导致抗除草剂杂草的出现。为解决这些挑战，本文研究了一种由视觉引导、基于AI的变量率喷洒系统，该系统能够实时检测杂草、估计冠层大小，并根据冠层分割结果动态调整喷嘴的激活。该系统结合了轻量级的YOLO11n和YOLO11n-seg深度学习模型，部署在NVIDIA Jetson Orin Nano上进行实时推理，并通过Arduino Uno扩展继电器接口控制 solenoid 驱动的喷嘴。
### Innovation
该研究开发了一种基于视觉和AI的系统，可以实现实时杂草检测、冠层大小估计和动态调整喷雾量。系统集成了YOLO11n和YOLO11n-seg深度学习模型，通过NVIDIA Jetson Orin Nano进行实时推理，并结合Arduino Uno扩展继电器接口实现了基于冠层分割结果控制喷嘴的激活。这样的系统能够根据不同冠层大小的区域调整喷洒输出，具有减少除草剂使用和提高农业可持续性的潜力。
### Conclusion
实验结果表明，YOLO11n模型的平均精度达到了0.98，YOLO11n-seg模型的分割精度也得到了验证。系统在不同冠层大小区域的喷洒覆盖率呈现上升趋势，证明该系统能够根据冠层大小实时调整喷洒输出。未来的研究将扩展到检测三种在南达科他州常见杂草（水蓼、灰绿藜和狗尾草）的能力，并在大豆和玉米生产系统中进行室内和田间试验验证。
## 457. `cs.CV` - 神经驱动的图像编辑 [PDF](https://arxiv.org/pdf/2507.05397), [HTML](https://arxiv.org/abs/2507.05397)
### Authors
Pengfei Zhou,Jie Xia,Xiaopeng Peng,Wangbo Zhao,Zilong Ye,Zekai Li,Suorong Yang,Jiadong Pan,Yuanxiang Chen,Ziqiao Wang,Kai Wang,Qian Zheng,Xiaojun Chang,Gang Pan,Shurong Dong,Kaipeng Zhang,Yang You
### Background
传统图像编辑依赖于手动提示，这既耗时又难以满足运动控制有限或语言能力有限的个体的需求。通过利用脑-机接口(BCI)和生成模型的最新进展，我们提出了LoongX，这是一种基于多模态生理信号的手动图像编辑方法。LoongX 使用了23,928个图像编辑对的数据集进行训练，每个对都附带有同步的脑电图（EEG）、功能性近红外光谱成像（fNIRS）、脉搏血氧图（PPG）和头部运动信号，这些信号记录用户的意图。
### Innovation
LoongX 通过引入两种关键模块实现了多模态信号的集成。第一，跨尺度状态空间（CS3）模块编码特定模态的有意义特征。第二，动态门控融合（DGF）模块将这些特征融合到一个统一的潜在空间，然后再通过在扩散变换器（DiT）上进行微调来对齐编辑语义。此外，我们还通过对比学习预训练编码器，将认知状态与嵌入的自然语言语义意图进行对齐。
### Conclusion
广泛实验表明，LoongX 在性能上与文本驱动的方法（如CLIP-I: 0.6605 vs. 0.6558；DINO: 0.4812 vs. 0.4636）相当，且当神经信号与语音结合使用时（CLIP-T: 0.2588 vs. 0.2549），性能超过文本方法。这些结果凸显了神经驱动的生成模型在实现无障碍、直观的图像编辑中的潜力，并为认知驱动的创意技术开辟了新的方向。LoongX 的数据集和代码将在未来的工作中发布，以促进该新兴领域的发展。
## 458. `cs.CV` - Vision-Language模型的动态秩适应 [PDF](https://arxiv.org/pdf/2507.05668), [HTML](https://arxiv.org/abs/2507.05668)
### Authors
Jiahui Wang,Qin Xu,Bo Jiang,Bin Luo
### Background
预训练的大规模视觉-语言模型（VLMs）如CLIP表现出显著的泛化能力。现有基于提示和适配器的工作在微调VLMs方面取得了显著进步，但仍面临保持强健泛化能力的挑战，特别是对于未见过的新类别。这一限制部分源于这些方法将图像和文本编码器中的所有标记视为同等重要，这可能导致对不太重要的特征（例如背景噪声、格式化词）的过拟合，进而损害对于新颖概念识别至关重要的泛化表示。
### Innovation
本文提出了动态秩适应（DRA），这是一种新颖的适配器变种方法，旨在增强对新类别的泛化。DRA在训练过程中根据特征的重要性动态分配适应等级，以保留通用知识。DRA首先使用序列注意力进行标记重要性分组，通过评估和分组标记的重要性实现分组。然后，根据每个标记组的重要性动态采用秩适应，将更高的特征秩赋予更重要的标记。此外，还设计了一种新的通道响应机制，优先保留和支持对于每个实例最具有信息量的特征通道的适应。同时，引入了L1正则化项以稳定训练。广泛的实验表明，DRA在多个基准上，特别是增强不同数据集上的新类别的性能方面，优于现有方法。
### Conclusion
实验结果证明了提出的DRA的有效性和优越性，特别是在增强多种基准上新类别的性能方面，包括基本新类别、跨数据集评估和领域泛化。源代码将在论文接收后公布。
## 459. `cs.CV` - PaddleOCR 3.0技术报告 [PDF](https://arxiv.org/pdf/2507.05595), [HTML](https://arxiv.org/abs/2507.05595)
### Authors
Cheng Cui,Ting Sun,Manhui Lin,Tingquan Gao,Yubo Zhang,Jiaxuan Liu,Xueqing Wang,Zelun Zhang,Changda Zhou,Hongen Liu,Yue Zhang,Wenyu Lv,Kui Huang,Yichao Zhang,Jing Zhang,Jun Zhang,Yi Liu,Dianhai Yu,Yanjun Ma
### Background
随着大型语言模型时代的到来，文档理解的需求日益增长，因此需要一种既能识别多语言文本、又能进行层次化文档解析，同时还能提取关键信息的工具。PaddleOCR 3.0提出了三种主要的解决方案来满足这些需求，这使得小参数量（少于10000万）的模型在准确性与效率上可与数十亿参数量的主流视觉语言模型相媲美。
### Innovation
PaddleOCR 3.0具有三个主要创新：PP-OCRv5用于多语言文本识别；PP-StructureV3用于层次化文档解析；PP-ChatOCRv4用于关键信息提取。更少的参数量模型（少于10000万）在准确性和效率上可与十亿参数量的主流视觉语言模型相媲美。此外，该平台还提供了高效的训练、推理和部署工具，支持异构硬件加速，使开发者能够轻松构建智能文档应用程序。
### Conclusion
PaddleOCR 3.0不仅提供了一个高质量的OCR模型库，还提供了训练、推理和部署工具，支持异构硬件加速，为文档理解提供了一套完整的解决方案，并支持开发者构建智能文档应用程序。
## 460. `cs.CV` - R-VLM: 区域感知视觉语言模型用于精确GUI视觉定位 [PDF](https://arxiv.org/pdf/2507.05673), [HTML](https://arxiv.org/abs/2507.05673)
### Authors
Joonhyung Park,Peng Tang,Sagnik Das,Srikar Appalaraju,Kunwar Yashraj Singh,R. Manmatha,Shabnam Ghadar
### Background
基于图形用户界面（GUI）的视觉代理模型在大型视觉语言模型（VLMs）取得进展的驱动下逐渐成为研究热点。然而，GUI自动化中的一个关键挑战在于如何在多种平台下精确地将界面元素进行视觉定位。现有的仅依靠视觉的GUI代理直接从复杂且杂乱的屏幕截图中定位元素，这导致它们需要处理大量无关信息，从而影响其精确度。此外，这些方法通常使用基本的交叉熵损失函数来学习视觉定位目标，未能有效优化与现有目标检测指标（如交并比IoU）相当的视觉定位质量。
### Innovation
该研究提出了R-VLM，这是一种利用放大的区域提议进行精确元素定位的新型GUI视觉定位方法。R-VLM还提出了一种IoU感知的目标函数，促进模型向具有高IoU的预测收敛。通过这种创新，R-VLM方法在ScreenSpot和AgentStudio这些GUI视觉定位基准测试上实现了现有最佳结果的13%的提高。
### Conclusion
该研究在多种GUI平台上显著提高了视觉定位的准确性，特别是在AITW和Mind2Web这些GUI导航任务基准测试上表现出了3.2-9.7%的绝对准确性提升。这些结果表明，R-VLM方法有效结合了视觉语言模型和传统的目标检测技术，提升了视觉定位的精度。
## 461. `cs.CV` - vision-language模型中综合结构提示学习 [PDF](https://arxiv.org/pdf/2507.05677), [HTML](https://arxiv.org/abs/2507.05677)
### Authors
Jiahui Wang,Qin Xu,Bo Jiang,Bin Luo
### Background
提示学习方法显著扩展了预训练的Vision-Language模型（如CLIP）在各种下游任务中的迁移能力。这些方法通过手工设计的模板或可学习向量在微调模型时提供文本或图像指令。然而，现有工作大多忽略了可学习提示与模态内部及跨模态冻结令牌之间的结构关系，并且在保持基础和新类别的性能平衡上面临挑战。
### Innovation
本文提出了一种综合结构提示（ISP），用于增强文本和图像分支之间信息表示的交互。ISP引入了自我结构化和跨结构化提示模块，用于建模可学习提示与模态内部及跨模态冻结令牌之间的结构关系。此外，提出了一种样本探针模块，根据样本难度动态调整损失系数，防止模型过度拟合于简单样本，从而提高对新类别的泛化能力。
### Conclusion
在三个广泛使用的设置：基础到新类别的泛化、跨数据集评估和领域泛化上进行的大量实验表明，提出的ISP方法在性能上达到了与最先进的方法竞争的水平。
## 462. `cs.CV` - 使用扩散模型建模和逆转脑部病变 [PDF](https://arxiv.org/pdf/2507.05670), [HTML](https://arxiv.org/abs/2507.05670)
### Authors
Omar Zamzam,Haleh Akrami,Anand Joshi,Richard Leahy
### Background
脑病变是指通过磁共振成像（MRI）可检测到的脑组织异常或损伤，涵盖了不可逆损伤和因病灶生长或肿胀引起的变形脑组织。现有病灶分割方法通常将损伤和变形的组织统一标记为单一异常，未能区分这两种不同类型的异常。本文提出了一种基于扩散模型的框架，用于分析和逆转脑病灶过程。该框架首先分割异常区域，然后通过恢复移位的组织来估计和逆转组织变形，从而明确初始损伤的核心病灶区域。最后，填充核心病灶区域以获得预病变健康脑部的估计。这种方法验证了现有的 biomechanical（生物力学）研究中建立的病灶生长过程模型。与传统方法相比，它在病灶分割、表征和脑部标记方面表现出更高的准确性，为脑部病变分析提供了一个稳健的工具。
### Innovation
本文提出了一种基于扩散模型的框架，用于分析和逆转脑病灶过程，能够区分病灶的损伤区域和变形区域，提供了一个相对于现有方法更准确的病灶分割和定位方法。
### Conclusion
与传统方法相比，该框架在病灶分割、表征和脑部标记方面表现出更高的准确性，提供了一个稳健的工具，适用于临床和研究中的脑部病变分析。由于目前没有公开的数据集可以验证逆转过程，研究通过模拟建立了前向模型以合成多个病变脑图像来进行验证。
## 463. `cs.CV` - LiON-LoRA: 重新思考LoRA融合以统一时空生成的可控性 [PDF](https://arxiv.org/pdf/2507.05678), [HTML](https://arxiv.org/abs/2507.05678)
### Authors
Yisu Zhang,Chenjie Cao,Chaohui Yu,Jianke Zhu
### Background
视频扩散模型（VDMs）能够通过大规模数据学习来合成现实感极强的视频。尽管简单的低秩适应（LoRA）可以在受限数据情况下学习特定的时空运动以驱动VDMs，但由于融合的不稳定性及非线性扩展性限制，要精确控制摄像机轨迹和物体运动依然是具有挑战性的。
### Innovation
本文提出了一种新型框架LiON-LoRA，该框架通过三个核心原则重新定义LoRA融合：线性可扩展性、正交性和范数一致性。通过分析浅层VDM层中LoRA特征的正交性，实现低级别控制的解耦；在各个层间强制实施范数一致性，以稳定具有复杂摄像机运动组合的融合；引入可控标记并结合修改后的自注意力机制，线性调整相机和物体的运动幅度，确保级别控制。此外，通过利用静态摄像机视频扩展到时间生成，实现了空间和时间的分离控制。实验结果表明，LiON-LoRA在轨迹控制精度和运动强度调整方面优于现有最先进方法，并且能够在少量训练数据的情况下实现更好的泛化能力。
### Conclusion
LiON-LoRA通过引入新的融合原则和机制，有效解决了在摄像机轨迹和物体运动控制方面的现有挑战，展示了在时空生成中良好的可控性和泛化性能。
## 464. `cs.CV` - 高光谱异常检测方法：综述与比较研究 [PDF](https://arxiv.org/pdf/2507.05730), [HTML](https://arxiv.org/abs/2507.05730)
### Authors
Aayushma Pant,Arbind Agrahari Baniya,Tsz-Kwan Lee,Sunil Aryal
### Background
高光谱图像是由几百个连续光谱带组成的数据集，能够进行详细的材料和表面分析。高光谱异常检测（HAD）是指在没有先验的高光谱场景或目标光谱信息下，识别和定位异常目标的技术。尽管近年来该技术取得了显著进步，应用于农业、国防、军事监控和环境监测等领域，现有方法仍面临高计算复杂性、对噪音敏感、跨多样数据集表现受限等问题。已有研究比较了不同类型的HAD技术，包括统计模型、基于表示的方法、经典机器学习方法和深度学习模型，并使用不同性能指标评估了这些方法的检测精度、计算效率、优缺点及未来研究方向
### Innovation
本文对各种HAD技术进行了全面比较，总结了统计模型、基于表示的方法、经典机器学习方法和深度学习模型的不同类别，并使用多种性能指标评估了这些方法在17个基准数据集上的表现，揭示了深度学习模型在检测精度上的优越性以及统计模型在所有数据集上的出色速度
### Conclusion
本研究旨在为高光谱异常检测方法的研究人员和实践者提供有价值的见解，强调了深度学习在检测精度方面的优势以及统计模型的快速性能特点，同时指出了未来研究的方向
## 465. `cs.CV` - 使用自上而下方法重新思考分层图形设计生成 [PDF](https://arxiv.org/pdf/2507.05601), [HTML](https://arxiv.org/abs/2507.05601)
### Authors
Jingye Chen,Zhaowen Wang,Nanxuan Zhao,Li Zhang,Difan Liu,Jimei Yang,Qifeng Chen
### Background
图形设计对于传达想法和信息至关重要。目前的设计工作流程通常需要专业技能，尽管基于生成式AI的方法让高分辨率的像素图形设计很容易获取，但这些设计往往是不可编辑的。尽管如此，这些非分层的设计仍然能激发人类设计师，影响他们的布局和文本风格选择，从而指导分层设计的创建过程。这项工作旨在通过提出名为Accordion的框架解决这一问题，该框架能够将生成式AI设计转化为可编辑的分层设计，并且通过用户提示对AI生成的无意义文本进行改进和替换。
### Innovation
Accordion框架采用了一种新颖的自上而下方法，利用视觉语言模型（VLM）指导三个特定阶段的任务。这种方法通过参考图像来提供全局视觉指南，从而分解每一层，不同之处在于，它利用了多种视觉专家模型（如SAM和删除模型）来促进图形层的创建。此外，训练方法使用了内部图形设计数据集Design39K，数据集经过增强，加入了AI生成的设计图像和由定制填充分割模型生成的精炼真实地面真相。
### Conclusion
实验结果和设计师的用户研究显示，Accordion框架在DesignIntention基准测试中，在文字到模板、背景添加文字和文字去矢量化等任务上表现良好，并且在创建设计变体方面也表现出色。
## 466. `cs.CV` - SenseShift6D：在环境和传感器变化下进行鲁棒6D姿态估计的多模态RGB-D基准数据集 [PDF](https://arxiv.org/pdf/2507.05751), [HTML](https://arxiv.org/abs/2507.05751)
### Authors
Yegyu Han,Taegyoon Yoon,Dayeon Woo,Sojeong Kim,Hyung-Sin Kim
### Background
尽管6D物体姿态估计在LM-O、YCB-V和T-Less等代表性基准上取得了高精度表现，但现有的数据集主要在固定照明和相机设置下获取，忽略了真实世界中照明、曝光、增益或深度传感器模式变化的影响及其在测试时传感器控制的潜力。
### Innovation
引入了SenseShift6D，这是一个包含13种RGB曝光、9种RGB增益、自动曝光、4种深度捕捉模式和5种照明水平的多模态RGB-D数据集，为三种常见的家用物体（喷雾器、普林格斯和铁盒）收集了101.9万张RGB图像和10万张深度图像。实验表明，测试时应用传感器控制比数字数据增强能带来更大的性能提升，效果甚至优于增加实际训练数据的数量和多样性。结合调整RGB和深度传感器各自，相比独立调整，获得更大的性能提升。SenseShift6D将6D姿态评估范式从数据中心的稳健性扩展到传感器感知稳健性，为适应和自调校感知系统提供基础。
### Conclusion
SenseShift6D为构建能够在不确定的现实环境中稳健运行的自调整感知系统搭建了基础，同时提供了可用于评估和改进6D姿态估计算法的大量数据。
## 467. `cs.CV` - 事件-RGB融合方法在恶劣光照条件下的航天器姿态估计 [PDF](https://arxiv.org/pdf/2507.05698), [HTML](https://arxiv.org/abs/2507.05698)
### Authors
Mohsi Jawaid,Marcus Märtens,Tat-Jun Chin
### Background
航天器姿态估计是实现空间自主操作（如对接、抓取和在轨服务）的关键。传统的基于RGB成像传感器的姿态估计方法在恶劣的光照条件下效果不佳，会产生诸如眩光、过曝、溢流和透镜眩光等成像伪影。神经形态或事件传感器由于具有更高的动态范围，对极端光照条件具有更强的鲁棒性，但它们通常空间分辨率较低，且在相对运动较小时信号噪声比下降。
### Innovation
该工作提出了一种结合RGB和事件传感器的融合方法，通过使用棱镜实现了精确的光学和时间对齐。还开发了一种基于RANSAC的技术来融合RGB和事件通道的信息，实现了利用两种模态优势的姿态估计，并通过丢弃不确定性估计来检测影响任一通道的极端条件。该方法在不同光照条件下的实验室环境中收集了全面的RGB和事件数据集，以评估和展示事件-RGB融合方法的有效性。
### Conclusion
在数据集上取得令人鼓舞的结果，证明了事件-RGB融合方法的有效性，并支持使用事件传感器进行航天器姿态估计。该数据集将对社区在此领域的研究起到支持作用。
## 468. `cs.CV` - 强健的正则化瑞镇算法在数字显微镜白平衡中的应用 [PDF](https://arxiv.org/pdf/2507.05757), [HTML](https://arxiv.org/abs/2507.05757)
### Authors
Radoslaw Roszczyk,Artur Krupa,Izabella Antoniuk
### Background
在光学显微镜中准确地获取色彩平衡的图像对操作员有挑战性。本文提出了一种完全自动的白平衡机制，用于校正显微镜彩色图像，经过实验验证，算法在两百张显微图像上得到了验证。这些图像包含三种常用病理学标本的扫描，结果与数字摄影中常用的白平衡算法进行了比较，结果表明该算法比用于血统、黄素-茜素染色及免疫组化染色显微图像的经典色彩摄影算法更为有效.
### Innovation
本文提出了强健的正则化瑞镇算法，这是一种自动的白平衡机制，用于校正显微镜彩色图像，实验验证了算法的有效性，并将其结果与数字摄影中常用的白平衡算法进行了比较，展示了其在显微图像中的优越性.
### Conclusion
该算法在两百张显微图像上进行了实验验证，表明其比用于血统、黄素-茜素染色及免疫组化染色显微图像的经典色彩摄影算法更为有效，证明了一种全新的自动白平衡机制在显微镜图像处理中的应用价值.
## 469. `cs.CV` - MedGen: 通过详细标注的医疗视频规模化训练解锁医疗视频生成 [PDF](https://arxiv.org/pdf/2507.05675), [HTML](https://arxiv.org/abs/2507.05675)
### Authors
Rongsheng Wang,Junying Chen,Ke Ji,Zhenyang Cai,Shunian Chen,Yunjin Yang,Benyou Wang
### Background
近年来，视频生成在开放场景中的进展显著，但在医疗场景中的应用相对较少。医疗视频对于临床培训、教育和模拟等应用至关重要，不仅需要高质量的视觉效果，还需要严格的医学准确性。然而，现有模型在处理医疗指令时，经常生成不现实或错误的内容，主要原因在于缺乏针对医疗领域的大规模、高质量数据集。
### Innovation
该研究引入了MedVideoCap-55K，这是首个专门用于医疗视频生成的大规模、多样化且配有描述的医疗视频数据集，包含超过55,000个精心挑选的视频片段，覆盖现实世界的医疗场景。在此基础上，提出了MedGen模型，该模型在开放源代码模型和商业系统中都表现出色，同时在多个基准测试中均展现了出色的视觉质量和医学准确性。
### Conclusion
希望通过这一数据集和模型，为医疗视频生成领域的研究提供有价值的资源，并推动该领域的发展。该代码和数据可以在提供的网页上获取。
## 470. `cs.CV` - 在3D空间中的2D实例编辑 [PDF](https://arxiv.org/pdf/2507.05819), [HTML](https://arxiv.org/abs/2507.05819)
### Authors
Yuhuan Xie,Aoxuan Pan,Ming-Xian Lin,Wei Huang,Yi-Hua Huang,Xiaojuan Qi
### Background
生成模型在推进2D图像编辑方面取得了显著进展，表现出极高的精确度和现实感。然而，由于其固有的像素操作性质，生成模型在一致性以及对象身份保持方面存在困难。为解决这个问题，本文提出了一种新型的“2D-3D-2D”框架。该方法首先将2D对象提升到3D表示，使得在保持物理合理性和刚性约束的3D环境中进行编辑成为可能。编辑后的3D对象会被重新投影并无缝地填充回原始2D图像中。与现有的2D编辑方法，如DragGAN和DragDiffusion相比，本方法直接在3D环境中进行对象操作。
### Innovation
本文提出了一种名为“2D-3D-2D”的新型框架。该框架首先将2D对象提升到3D表示，在物理合理性和刚性约束的3D环境中进行编辑，然后将编辑后的3D对象重新投影并无缝地填充回原始2D图像中。这种方法能够直接在3D环境中进行对象操作，从而解决了现有2D编辑方法在一致性以及对象身份保持方面的问题。
### Conclusion
广泛的实验表明，本文提出的框架在一般性能上超过了之前的方法，提供了高度一致的编辑结果，同时稳健地保持了对象身份。
## 471. `cs.CV` - DREAM: 通过端到端自回归模型进行文档重建 [PDF](https://arxiv.org/pdf/2507.05805), [HTML](https://arxiv.org/abs/2507.05805)
### Authors
Xin Li,Mingming Gong,Yunfei Wu,Jianxin Dai,Antai Guo,Xinghua Jiang,Haoyu Cao,Yinsong Liu,Deqiang Jiang,Xing Sun
### Background
文档重建是文档分析和识别的一个重要方面，近年来引起了学术界的越来越多的兴趣。大多数研究人员利用各种文档理解模型预测不同子任务，再通过启发式原则将其结果整合到综合的文档重建格式中。然而，多阶段方法因错误传播现象而受限，导致性能不佳。当前的研究使用生成模型从头到尾地提取纯文本、表格和数学公式的逻辑顺序，但是这种方法在保持元素布局信息方面存在不足，而这些信息对于文档重建至关重要。我们在此提供了一种创新的自回归模型，称为DREAM，专用于文档重建。DREAM能够通过全面的端到端过程将文本图像转换为文档重建序列，涵盖了更广泛的文档元素信息。我们还制定了文档重建任务的标准定义，并引入了用于评估任务性能的新颖文档相似度度量（DSM）和DocRec1K数据集。实验证明我们的方法在文档重建方面的性能无与伦比。此外，通过各种子任务（包括文档版面分析、文本识别、表格结构识别、公式识别和阅读顺序检测）的结果表明，我们的模型在不同任务中具有竞争力和兼容性。
### Innovation
提出了一种新的端到端自回归模型——DREAM，该模型能够通过全面的端到端过程将文本图像转换为文档重建序列，涵盖了更广泛的文档元素信息。并且引入了新颖的文档相似度度量（DSM）和DocRec1K数据集，用于评估文档重建任务的性能。
### Conclusion
我们的方法在文档重建方面实现了无与伦比的性能。此外，我们的模型在多个子任务中表现优异，展示了其在不同任务中的竞争力和兼容性。
## 472. `cs.CV` - I$^2$R: Inter and Intra-image Refinement in Few Shot Segmentation [PDF](https://arxiv.org/pdf/2507.05838), [HTML](https://arxiv.org/abs/2507.05838)
### Authors
Ourui Fu,Hangzhou He,Xinliang Zhang,Lei Zhu,Shuang Zeng,ZhaoHeng Xie,Yanye Lu
### Background
语义分割的注解瓶颈促进了对少样本分割的显著关注，少样本分割旨在开发能够在使用少量示例的条件下快速泛化的分割模型。传统训练范式通过从支持图像中提取遮罩区域特征生成查询先验图，并据此进行预测。然而，当前的方法受到来自图像间和图像内差异的两个关键限制的影响，这些限制显著降低了分割性能：1）支持图像和查询图像之间的语义差距导致特征匹配错误和先验图不准确；2）支持图像或查询图像中视觉相似但语义不同的区域导致错误的负预测或正预测。因此，需要一种新颖的方法来解决这些问题，尤其是针对少样本分割的先验图和区域定位问题。本文提出了一种名为I$^2$R（互图像反演）的方法来解决这些问题。
### Innovation
提出了一种名为I$^2$R的新方法，以解决语义分割中的少样本问题。该方法包含两个关键创新点：1）使用特定类别的高级表示，从支持和查询图像中聚合全局语义线索，实现更精确的图像间区域定位，解决先验图不准确的问题；2）使用方向遮罩策略消除支持和查询图像中高特征相似但具有冲突掩码的像素对，从而缓解视觉相似但语义不同的区域导致的错误预测问题。实验验证了该方法的有效性，表现出优于当前最佳方法的性能提升。
### Conclusion
本文提出了一种新的少样本分割方法I$^2$R，该方法针对图像间和图像内差异导致的两个关键问题进行优化。实验结果显示，该方法在1-shot设置下分别在PASCAL-5$^i$和COCO-20$^i$基准上的mIoU性能上分别提高了1.9%和2.1%。
## 473. `cs.CV` - SPADE: 增强空间意识的去噪网络用于长程和短程上下文推理的开放词汇全景场景图生成 [PDF](https://arxiv.org/pdf/2507.05798), [HTML](https://arxiv.org/abs/2507.05798)
### Authors
Xin Hu,Ke Qin,Guiduo Duan,Ming Li,Yuan-Fang Li,Tao He
### Background
全景场景图生成（PSG）结合实例分割与关系理解，以捕捉复杂场景中的像素级结构关系。尽管近期利用预训练视觉-语言模型（VLMs）的方法显著提升了开放词汇设置下的性能，但由于这些模型在空间关系推理中的固有限制，如难以区分物体的相对位置，导致关系预测不佳。SPADE框架借鉴去噪扩散模型在反向过程中的空间结构保持机制，提出了一种新的开放词汇全景场景图生成方法，即SPatial-Aware Denoising-nEtwork (SPADE)。该方法旨在填补现有VLMs在空间关系理解上的不足。
### Innovation
SPADE框架解决了现有方法的局限性，通过两个关键步骤实现突破：一是引导校准的UNet适应，利用反向过程中的交叉注意力图和轻量级LoRA调优策略；二是空间意识关系图变换器，可以捕捉局部和远程上下文信息，促进高质量关系查询的生成。
### Conclusion
在基准PSG和Visual Genome数据集上的大量实验表明，SPADE在关闭词汇和开放词汇场景中均优于现有方法，特别是在空间关系预测方面表现出色。
## 474. `cs.CV` - USIGAN: 弱配对图像IHC虚拟染色的不平衡自信息特征传输 [PDF](https://arxiv.org/pdf/2507.05843), [HTML](https://arxiv.org/abs/2507.05843)
### Authors
Yue Peng,Bing Xiong,Fuqiang Chen,De Eybo,RanRan Zhang,Wanming Hu,Jing Cai,Wenjian Qin
### Background
IHC虚拟染色是从HE图像生成虚拟IHC图像的任务，同时保持与相邻切片的病理语义一致性。通过生成模型实现形态学结构和染色模式之间的跨域映射，该任务提供了一种高效且成本效益高的病理分析解决方案。但在弱配对情况下，相邻切片之间的空间异质性是一个重大挑战。这可能导致不准确的一对多映射，并生成与相邻切片的病理语义不一致的结果。
### Innovation
提出了一种名为USIGAN的新颖的不平衡自信息特征传输方法，该方法通过从切片中提取全局形态学语义并通过联合边际分布中删除弱配对项来有效地减轻弱配对对联合分布的影响，从而显著提高生成结果的内容一致性和病理语义一致性。此外，设计了Unbalanced Optimal Transport Consistency (UOT-CTM)机制和Pathology Self-Correspondence (PC-SCM)机制，构建了HE图像与生成IHC图像和真实IHC图像与生成IHC图像集在图像级和组内级别的相关矩阵。
### Conclusion
在两个公开可用的数据集上进行的实验表明，我们的方法在多个临床显著指标上取得了优异的性能，如IoD和Pearson-R相关性，显示出更好的临床相关性。
## 475. `cs.CV` - DreamArt: 根据单张图像生成可交互的关节物体 [PDF](https://arxiv.org/pdf/2507.05763), [HTML](https://arxiv.org/abs/2507.05763)
### Authors
Ruijie Lu,Yu Liu,Jiaxiang Tang,Junfeng Ni,Yuxiang Wang,Diwen Wan,Gang Zeng,Yixin Chen,Siyuan Huang
### Background
生成具有关节的物体，如笔记本电脑和微波炉，对于具身AI和AR/VR具有重要的应用价值，但同时由于关节结构和部分分解的复杂性，也是一个巨大挑战。当前的图像到三维的方法主要关注表面几何和纹理，而忽略了部分分解和关节建模，神经重建方法（例如NeRF或Gaussian Splatting）依赖密集的多视角或交互数据，限制了其可扩展性。
### Innovation
DreamArt提出了一种新颖的框架，能够从单张图像生成高质量的可交互关节物体。首先，通过图像到3D生成、掩码提示3D分割和部分不完整完成技术重建部分分割和完整的3D模型网格。其次，通过精细化调优视频扩散模型，捕捉关节部位先验模型，利用可移动部分掩码和不完整图像作为提示，以减轻遮挡造成的歧义。最后，优化表示关节运动的双四元数，并进行全局纹理细化和重绘，以确保所有部件的纹理一致性并维持高质量。
### Conclusion
实验结果表明，DreamArt能够有效地生成高质量的可关节物体，具有准确的部件形状、高度的外观保真度和合理的关节运动，从而为关节资产生成提供了可扩展的解决方案。
## 476. `cs.CV` - 通过统一合成框架弥合数据缺口赋能桥梁数字孪生 [PDF](https://arxiv.org/pdf/2507.05814), [HTML](https://arxiv.org/abs/2507.05814)
### Authors
Wang Wang,Mingyu Shi,Jun Jiang,Wenqian Ma,Chong Liu,Yasutaka Narazaki,Xuguang Wang
### Background
作为关键的交通基础设施，桥梁面临着老化和腐蚀加剧的挑战，而传统的手动检查方法效率低下。尽管3D点云技术提供了新的数据驱动范式，但其应用潜力常受限于现实世界数据的不完整性，这源于缺少标签和扫描遮挡。
### Innovation
本文提出了一种系统框架，用于生成3D桥梁数据。该框架能够自动生成包括组件级实例注释、高保真颜色和精确法线向量的完整点云。此外，该框架还能扩展以模拟创建多种多样且物理现实的不完整点云，以分别支持分割和完成网络的训练。实验表明，使用我们合成数据训练的PointNet++模型在现实世界桥梁语义分割中的mIoU为84.2%。同时，微调后的KT-Net在组件完成任务中表现出更优性能。这项研究提供了一种创新的方法论和技术基础数据集，对于推进基础设施的自动化管理和维护具有重要意义。
### Conclusion
本文研究为3D桥梁结构的视觉分析提供了创新的方法和技术基础数据集，对于推进基础设施的自动化管理和维护具有重要意义。
## 477. `cs.CV` - 基于太阳高度的场景照明指导 [PDF](https://arxiv.org/pdf/2507.05812), [HTML](https://arxiv.org/abs/2507.05812)
### Authors
Samed Doğan,Maximilian Hoh,Nico Leuze,Nicolas R.-Peña,Alfred Schöttl
### Background
自动驾驶功能的安全性和可靠性高度依赖于大规模、高质量的传感器数据。然而，实地数据的获取需要大量的人工劳动，并且受到标注成本、司机安全协议和场景多样性等多种因素的限制。因此，许多研究工作专注于生成合成的相机传感器数据。研究发现，在白天变化这一方面存在着显著的研究缺口，这可能是由于可用标注数据的稀缺性。基于此，本文提出太阳高度作为全局调节变量，它可以通过经纬度坐标和地方时间计算得到，无需进行大量的手工标注。此外，该文还提出了一种定制的归一化方法，该方法旨在缓解日照对太阳高度小数值变化的敏感性问题。这种方法在基于扩散模型的背景下，展示了其准确捕捉光照特性和与照明有关的图像噪声的能力.
### Innovation
本文通过提出太阳高度作为生成合成数据的全球调节变量，填补了白天变化这一研究领域的空白。此外，还提出了一种定制的归一化方法，有效地缓解了日照对太阳高度小数值变化的敏感性问题，并展示了其在光照特性和照明依赖的图像噪声捕捉方面的高精度.
### Conclusion
通过基于太阳高度和定制的归一化方法生成的合成相机传感器数据，能够准确捕捉光照特性和照明依赖的图像噪声。这项研究填补了当前研究中的主要空白，有助于提高合成数据的质量，从而促进自动驾驶技术的发展.
## 478. `cs.CV` - TalkFashion：基于多模态大语言模型的智能虚拟试穿助手 [PDF](https://arxiv.org/pdf/2507.05790), [HTML](https://arxiv.org/abs/2507.05790)
### Authors
Yujie Hu,Xuanyu Zhang,Weiqi Li,Jian Zhang
### Background
近年来，虚拟试穿取得了显著进展。然而，现有方法大多依靠端到端网络执行单一的虚拟试穿任务，缺乏灵活性和多功能性。用户需要手动提供掩膜才能进行局部编辑，这在实际操作中显得不够便捷。因此，迫切需要一种能够根据文本指令实现多功能虚拟试穿的方法，从而改进虚拟试穿的用户体验和效果。
### Innovation
本文提出了TalkFashion，一个利用大语言模型的强大理解能力来解析用户指令并决定执行的特定任务，从而激活不同的处理流程。此外，该方法引入了一种基于指令的局部重绘模型，无需用户手动提供掩膜，借助多模态模型实现完全自动化的局部编辑。这极大地增强了编辑任务的灵活性，并且实验结果表明，相较于现有方法，TalkFashion在语义一致性和视觉质量方面表现更佳。
### Conclusion
实验结果证明，TalkFashion在语义一致性与视觉质量方面超过了现有方法。TalkFashion提供了一种新的方法，基于文本指令实现多功能虚拟试穿，增强了虚拟试穿的灵活性，特别是对于局部编辑任务，展现出更高的自动化水平。
## 479. `cs.CV` - GeoMag: 一种用于像素级精细遥感图像解析的视觉-语言模型 [PDF](https://arxiv.org/pdf/2507.05887), [HTML](https://arxiv.org/abs/2507.05887)
### Authors
Xianzhi Ma,Jianhui Li,Changhua Pei,Hao Liu
### Background
视觉-语言模型（VLMs）在遥感（RS）图像理解中的应用已经取得了显著的进步，显示出基本的地理实体识别和描述能力。然而，现有的RS-VLMs大多局限于图像级和区域级的任务，缺乏处理像素级任务的能力，并且在小目标识别场景中表现不佳。此外，处理高分辨率RS图像时，RS-VLMs消耗了大量计算资源，进一步限制了它们的实际应用。
### Innovation
本文提出了GeoMag（Geographical Magnifier），这是一种端到端的通用大型模型框架，通过基于提示语义动态聚焦关注范围，有效地在不同粒度级别上进行遥感图像解析。GeoMag引入了任务驱动多粒度分辨率调整（TMRA）和提示引导语义感知裁剪（PSC），能够自适应地降低非任务相关区域的空间分辨率，同时增强任务相关区域的视觉表示。这种方法使得模型能够更好地感知关键目标区域，抑制背景冗余，减少解析高分辨率RS图像的计算成本。
### Conclusion
在10个基准上的广泛比较实验表明，GeoMag不仅在处理像素级任务方面表现出色，而且在处理其他粒度级别的任务时也保持了与现有RS-VLMs相当的性能。
## 480. `cs.CV` - 超越外观：稳健视频实例分割中的几何线索 [PDF](https://arxiv.org/pdf/2507.05948), [HTML](https://arxiv.org/abs/2507.05948)
### Authors
Quanzhu Niu,Yikang Zhou,Shihao Chen,Tao Zhang,Shunping Ji
### Background
视频实例分割（VIS）面临的主要挑战包括物体遮挡、运动模糊以及时间关联中的外观变化。为了克服这些限制，本文通过引入几何感知，以策略性地利用单目深度估计来增强VIS的稳健性。研究了三种不同的整合范式：扩展深度通道（EDC）方法将深度图作为输入通道添加到分割网络中；共享ViT（SV）设计了一个统一的ViT骨干网络，同时用于深度估计和分割分支之间；深度监督（DS）利用深度预测作为辅助训练指导，以改进特征学习。尽管DS表现出有限的效果，基准评估表明EDC和SV在VIS的稳健性上有显著增强。使用Swin-L骨干网络时，我们的EDC方法在OVIS基准上的AP值达到56.2，这是一个新的最高水平结果。
### Innovation
提出了通过几何感知增强视频实例分割的稳健性的方法，系统地研究了三种不同的整合范式：扩展深度通道（EDC）、共享ViT（SV）和深度监督（DS）。研究表明，EDC和SV在VIS的稳健性上表现出显著增强。特别是在使用Swin-L骨干网络时，EDC方法在OVIS基准上达到了56.2的AP值，创造了新的最佳结果。
### Conclusion
研究结果表明，深度线索对于实现稳健的视频理解至关重要。这为视频实例分割提供了新的视角和解决方案。
## 481. `cs.CV` - Tora2: 多实体视频生成的运动与外观定制扩散变换器 [PDF](https://arxiv.org/pdf/2507.05963), [HTML](https://arxiv.org/abs/2507.05963)
### Authors
Zhenghao Zhang,Junchao Liao,Xiangyu Meng,Long Qin,Weizhi Wang
### Background
近年来，扩散变换模型如Tora在运动引导视频生成方面取得了显著进展。在此基础上，我们提出了Tora2，该版本通过多种设计改进增强了Tora的功能，特别是在外观和运动定制方面。Tora2通过去耦合个性化提取器生成多个开放集实体的综合个性化嵌入，相比之前的方法能够更好地保留细节。
### Innovation
Tora2引入了一个去耦合的个性化提取器，生成了多个开放集实体的综合个性化嵌入，相比前人方法保留更精细的视觉细节的。在此基础上设计了一个门控自我注意机制，结合每个实体的轨迹、文本描述和视觉信息，显著减少了多模态训练期间的不准确对齐。此外，还引入了一种对比损失，通过动作和个性化嵌入的显式映射，同时优化了轨迹动态和实体一致性。Tora2是迄今为止第一个能够在视频生成中同时实现多实体外观和运动定制的方法。
### Conclusion
实验结果表明，Tora2在外观和运动等方面的定制能力与最先进的定制方法相当，提供了高级的运动控制功能，标志了多条件视频生成的一个重要进步。
## 482. `cs.CV` - 高保真度和广泛适用的稀疏特征体积神经表面重建方法 [PDF](https://arxiv.org/pdf/2507.05952), [HTML](https://arxiv.org/abs/2507.05952)
### Authors
Aoxiang Fan,Corentin Dumery,Nicolas Talabot,Hieu Le,Pascal Fua
### Background
神经表面重建技术现在能够从少量图片中重建场景，而无需针对每个场景进行优化。密集的3D特征体素体积作为全局表示已被证明有效。然而，这种密集表示方法无法很好地处理更高分辨率的体素，严重限制了重建质量。为此，本文采用了一种稀疏表示方法，旨在最大化内存效率并能在标准硬件上实现更高分辨率的重建。
### Innovation
本文提出了通过两阶段方法实现的稀疏表示方法，首先训练网络预测体素占用情况，然后仅对具有足够高占用估计的体素计算特征并进行体积渲染。为了支持这种稀疏表示，本文还开发了专门的算法，用于高效的采样、特征聚合和稀疏体积查询，克服了现有工作中的密集体积假设。实验表明，该方法在不降低性能的前提下将存储需求减少了超过50倍，使重建分辨率从典型的128^3提升到512^3，同时在相同硬件上获得了比现有最佳方法更好的重建准确性。
### Conclusion
与现有的体积假设算法相比，本文提出的方法大幅减少了存储需求，提升了分辨率和重建准确性，为神经表面重建领域带来了重要的技术进步。
## 483. `cs.CV` - DFYP: 一种具有光谱通道注意和自适应操作学习的动态融合框架用于作物产量预测 [PDF](https://arxiv.org/pdf/2507.05849), [HTML](https://arxiv.org/abs/2507.05849)
### Authors
Juli Zhang,Zeyu Yan,Jing Zhang,Qiguang Miao,Quan Wang
### Background
准确的基于遥感的作物产量预测仍然是一个基本的挑战任务，由于复杂的空间模式、异质的光谱特性和动态的农业条件。现有的方法往往受到有限的空间建模能力、在不同的作物类型和年份上弱的一般化的限制。多年内多作物数据集MODIS和多作物数据集Sentinel-2上的大量实验表明，现有的方法在均方根误差(RMSE)、平均绝对误差(MAE)和决定系数(R2)等方面的表现不及当前最先进的基线方法。这表明，作物产量预测仍然面临许多复杂挑战，如复杂的空间模式、不同的光谱特征和动态农业条件等。因此，改善空间建模能力和实现不同作物类型和时间范围内的泛化能力具有重要意义。
### Innovation
我们提出了DFYP，一种新颖的动态融合框架，结合了光谱通道注意、边缘自适应空间建模以及可学习融合机制，以提高在不同农业场景下的鲁棒性。DFYP的特点在于引入了三个关键组件：（1）一种分辨率感知的通道注意（RCA）模块，通过根据分辨率特有的特性对输入通道进行自适应加权，增强光谱表示；（2）一种自适应操作学习网络（AOL-Net），动态选择卷积核的操作者，以提高在变化的作物和时间条件下的边缘敏感的空间特征提取；（3）一种双分支结构，配备可学习的融合机制，以共同建模局部空间细节和全局上下文信息，为跨分辨率和跨作物泛化提供支持。该框架在多年内和多作物数据集上均表现出色，RMSE、MAE和R2等指标超越了当前最先进的基准方法，这展示了其在实际农业监控中的有效性和鲁棒性。
### Conclusion
DFYP框架在不同空间分辨率、作物类型和时间范围内的多年内数据和多作物数据集上的实验表明，它能够通过结合光谱通道注意、边缘自适应空间建模和可学习融合机制，在复杂的农业场景中实现跨分辨率和跨作物的鲁棒性预测，从而有效应对作物产量预测中的核心挑战。
## 484. `cs.CV` - Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval [PDF](https://arxiv.org/pdf/2507.05970), [HTML](https://arxiv.org/abs/2507.05970)
### Authors
Haiwen Li,Delong Liu,Zhaohui Hou,Zhicheng Zhao,Fei Su
### Background
Composed Image Retrieval (CIR) 是一个具有挑战性的计算机视觉与自然语言结合的任务，目标是使用多模态（图像+文本）查询检索目标图像。尽管许多现有 CIR 方法取得了令人瞩目的性能，但它们依赖于昂贵且手动标注的三元组，这限制了其可扩展性和零样本能力。
### Innovation
为了解决这个问题，本文提出了一种可扩展的自动三元组生成管道，以及一个完全合成数据集 Composed Image Retrieval on High-quality Synthetic Triplets (CIRHS)。该管道利用大规模语言模型生成多样化的提示，控制文本到图像生成模型生成具有每对相同元素的图像对，然后过滤重组以形成 CIRHS 数据集。此外，引入了一种新型的 CIR 框架 Hybrid Contextual Alignment (CoAlign)，该框架可在更广泛的上下文中实现全局对齐和局部推理，从而使模型能够学习更具鲁棒性和信息性的表示。
### Conclusion
通过使用合成的 CIRHS 数据集，CoAlign 在三个常用基准上取得了出色的零样本性能，并首次展示了用完全合成的数据集训练 CIR 模型的可行性。此外，在有监督训练下，我们的方法在所有最先进的有监督 CIR 方法中表现最佳，验证了我们提出的检索框架的有效性。
## 485. `cs.CV` - 通过集成语义共现知识探索部分多标签学习 [PDF](https://arxiv.org/pdf/2507.05992), [HTML](https://arxiv.org/abs/2507.05992)
### Authors
Xin Wu,Fei Teng,Yue Feng,Kaibo Shi,Zhuosheng Lin,Ji Zhang,James Wang
### Background
部分多标签学习旨在从部分标注数据中提取知识，该数据包括已知正确标签、已知错误标签和未知标签。核心挑战在于准确地识别标签与实例之间的模糊关系。现有方法难以有效处理这类数据中的复杂关联，尤其是在标注不完整和类型多样的标注信息情况下。已有研究虽然在部分标注数据处理上有所进展，但对标签与实例间模糊性识别的有效性仍不足。
### Innovation
本文提出了一种全新的框架Semantic Co-occurrence Insight Network (SCINet)，以精确地识别标签与实例之间的模糊关系。SCINet通过引入双主导提示器模块来利用预训练的多模态模型捕捉文本-图像相关性，增强语义对齐。此外，设计了跨模态融合模块，联合建模标签间、实例间的相关性和实例标签分配下的共现模式。为提升模型对数据内在语义的理解，还提出了一种内部语义增强策略，通过应用多样化的图像变换增强标签置信度与样本难度的协同关系。
### Conclusion
在四个广泛使用的基准数据集上进行的大量实验表明，SCINet比现有最先进的方法表现更优。
## 486. `cs.CV` - T-LoRA：在不出现过拟合的情况下使用单张图像自定义扩散模型 [PDF](https://arxiv.org/pdf/2507.05964), [HTML](https://arxiv.org/abs/2507.05964)
### Authors
Vera Soboleva,Aibek Alanov,Andrey Kuznetsov,Konstantin Sobolev
### Background
扩散模型微调为预训练模型自动生成特定对象提供了一种强大的方法，但在样本量有限时经常会出现过拟合问题，这会削弱模型的泛化能力和输出多样性。利用单张概念图像进行自定义是极具实际潜力的任务，但如何在不出现过拟合的情况下完成这一任务却极具挑战。
### Innovation
T-LoRA框架通过以下两个创新来解决这一问题：(1) 基于扩散时间步的动态微调策略，根据不同的时间步调整约束更新的秩；(2) 通过正交化初始化确保自适应组件之间的独立性的一种权重参数化方法。
### Conclusion
T-LoRA框架及其实现的组件在概念精准度和文本对齐之间实现了更优的平衡，证明了在数据有限和资源受限的情景下T-LoRA的潜力。
## 487. `cs.CV` - 基于多轮接地的强化学习高分辨率视觉推理 [PDF](https://arxiv.org/pdf/2507.05920), [HTML](https://arxiv.org/abs/2507.05920)
### Authors
Xinyu Huang,Yuhao Dong,Weiwei Tian,Bo Li,Rui Feng,Ziwei Liu
### Background
当今最先进的大型多模态模型在处理高分辨率图像时面临挑战，因为这些输入被转换为大量的视觉标记，其中许多与后续任务无关。现有方法大多依赖于监督微调（SFT），需要额外的成本和人力来提供精确的注释，导致训练过程复杂且耗时。
### Innovation
本文提出了一种名为Multi-turn Grounding-based Policy Optimization (MGPO) 的端到端强化学习框架，能够在多轮对话框架中，通过自动裁剪子图像来引导模型逐步关注关键的视觉区域。此方法通过模型预测的接地坐标来实现，与传统的监督微调相比，MGPO仅依赖于最终答案的正确性来进行训练，从而减少对额外标注数据的依赖，同时通过限制策略损失计算到多轮对话生成的模型输出，解决了启动问题，促进了稳定的优化过程。
### Conclusion
实验表明，MGPO在标准视觉问答数据集上的训练结果优于GRPO，特别是在分布内（MME-Realworld）和分布外（OOD）的V* Bench数据集上分别提高了5.4%和5.2%。此外，MGPO在Qwen2.5-VL-7B上的后训练结果超过OpenAI的o1和GPT-4o模型，这表明MGPO在分布外场景下的性能具有显著提升。代码已开源，可供进一步研究使用。
## 488. `cs.CV` - 基于最新模型的跨域鲁棒集合方法的深度假象检测 [PDF](https://arxiv.org/pdf/2507.05996), [HTML](https://arxiv.org/abs/2507.05996)
### Authors
Haroon Wahab,Hassan Ugail,Lujain Jaleel
### Background
基于机器学习的深度假象检测模型在基准数据集上取得了显著成果，但在评估外部数据集时，性能往往会显著下降。这项工作中，我们探索了一种集合方法来提高不同数据集上深度假象检测系统的泛化能力。通过一个最新的开源基准，我们将几个在顶级学术会议上提出的最新异构模型的预测概率进行了结合。实验结果表明，没有单一模型在所有场景中都能始终优于其他模型，而基于集合的预测在所有场景中提供了更稳定和可靠的性能。这表明，异构集合提供了一种稳健且可扩展的解决方案，以应对缺乏伪造类型或质量先验知识的实际深度假象检测问题。
### Innovation
我们提出了一种基于集合的方法，结合来自多个顶级会议上提出的最新异构模型的预测概率，以提高深度假象检测系统的泛化能力。这种方法在不同的外部数据集上展示了更稳定和可靠的性能。
### Conclusion
我们的结果表明，异构集合提供了一种稳健且可扩展的解决方案，适用于实际的深度假象检测问题，特别是在缺乏关于伪造类型或质量的先验知识时。
## 489. `cs.CV` - 通过融合大型语言模型的世界知识与视觉基础模型实现视频事件的推理与预测 [PDF](https://arxiv.org/pdf/2507.05822), [HTML](https://arxiv.org/abs/2507.05822)
### Authors
L'ea Dubois,Klaus Schmidt,Chengyu Wang,Ji-Hoon Park,Lin Wang,Santiago Munoz
### Background
当前的视频理解模型在识别“正在发生什么”方面表现优异，但在高级认知任务，如因果推理和未来预测方面表现不佳。这是因为模型缺乏常识性世界知识。本文在这一认知差距中提供了一种解决方案，旨在通过融合强大的视觉基础模型（VFM）进行深度视觉感知，以及一个作为知识驱动推理核心的大型语言模型（LLM）来解决这个问题。
### Innovation
本文的创新之处在于提出了一种先进的融合模块，灵感来源于Q-Former架构，能够将复杂的时空和对象中心视觉特征提炼为简洁的语言对齐表示，从而使大型语言模型能够在直接的视觉证据基础上进行有效的推理过程。模型采用两阶段训练策略，开始是大规模的视频-文本数据对齐预训练，然后是针对设计用于激发现代推理和预测能力的数据集的指令微调。广泛的实验验证了该模型在多个挑战性基准上的最优性能，并表现出出色的零样本泛化能力，且详细的消融研究证实了每个架构组件的贡献至关重要。这一工作将机器感知的边界从简单的识别推进到真正的认知理解，为后续更智能和更强大的AI系统铺平了道路，特别是在机器人领域、人机交互等方向。
### Conclusion
该工作展示了通过融合大型语言模型的世界知识与视觉基础模型，实现视频事件的推理与预测的有效性，从而极大推进了机器认知理解的进步，并为更智能的AI系统奠定了基础。
## 490. `cs.CV` - D-FCGS: 基于动态Gaussian点云序列的前馈压缩方法，用于自由视角视频 [PDF](https://arxiv.org/pdf/2507.05859), [HTML](https://arxiv.org/abs/2507.05859)
### Authors
Wenkang Zhang,Yan Zhao,Qiang Wang,Li Song,Zhengxue Cheng
### Background
自由视角视频（FVV）使沉浸式3D体验成为可能，但动态3D表示的有效压缩仍然是一个重大挑战。尽管3D Gaussian Splatting (3DGS)及其动态扩展已有了一些进展，能够实现高保真场景建模，但现有方法常常将场景重建与依赖优化的编码结合在一起，这限制了其泛化能力
### Innovation
提出了Feedforward Compression of Dynamic Gaussian Splatting（D-FCGS），这是一种新颖的前馈框架，用于压缩时空相关性的Gaussian点云序列。该方法通过Group-of-Frames（GoF）结构和I-P帧编码提取帧间运动，利用稀疏控制点。使用基于双重先验的熵模型对运动张量进行压缩，该熵模型结合了超先验和时空先验，以实现准确的比特率估计。在多视角视频衍生的Gaussian帧上训练，D-FCGS能够在无需场景特定优化的情况下跨场景泛化。实验表明，它在不超过2秒的时间内实现了超过40倍的压缩，同时保持了多视角的视觉质量，达到了与基于优化方法相当的率失真性能
### Conclusion
这项工作促进了动态3DGS的前馈压缩，为沉浸式应用中的FVV传输和存储搭建了可扩展的技术基础
## 491. `cs.CV` - 使用卫星图像而不依赖于GNSS进行地面激光雷达点云的地理对准 [PDF](https://arxiv.org/pdf/2507.05999), [HTML](https://arxiv.org/abs/2507.05999)
### Authors
Xinyu Wang,Muhammad Ibrahim,Atif Mansoor,Ajmal Mian
### Background
在高-rise建筑和桥梁密集的城市区域中，利用GNSS信号进行地理对准的激光雷达点云面临着显著挑战，尤其是在GNSS信号受限的情况下。现有的方法通常依赖实时GNSS和IMU数据，并需要提前校准和假设定位数据采集过程中的稳定性。然而，这种假设在密集的城市环境中往往失败，导致定位误差。
### Innovation
本文提出了一种结构化的地理对准和空间矫正方法，该方法通过将3D点云与卫星图像对齐，实现帧间的GNSS信息恢复，并构建城市规模的3D地图，无需依赖先验定位。该方法利用预训练的Point Transformer模型进行道路点分割，并从点云和目标地图中提取道路骨架和交叉点以便对齐。通过交叉点进行全局刚性对齐，然后使用径向基函数（RBF）插值进行局部细化。根据SRTM数据集中的地形信息对点云进行高程矫正，以解决垂直差异问题。该方法在流行的KITTI基准测试和西澳大利亚珀斯本地收集的数据集上得到了测试。
### Conclusion
在KITTI数据集上，该方法实现了交点序列中平均平面对准标准偏差0.84米，相比原始数据集提高了55.3%的精度；在缺乏GNSS信息的珀斯数据集上，该方法实现了与Google Maps API提取的GPS数据相比平均标准偏差0.96米，精度提高了77.4%，在KITTI数据集上高程一致性的提升为30.5%，在珀斯数据集上提升了50.4%。
## 492. `cs.CV` - MEDTalk: 分离嵌入表示下的多模态动态情感3D面部动画 [PDF](https://arxiv.org/pdf/2507.06071), [HTML](https://arxiv.org/abs/2507.06071)
### Authors
Chang Liu,Ye Pan,Chenyang Ding,Susanto Rahardja,Xiaokang Yang
### Background
现有的基于音频的情感3D面部动画方法主要集中在静态和预定义的情绪标签上，这限制了它们的多样性和自然度。因此，当前的研究面临挑战，即如何生成同步的唇部运动和生动的脸部表情，以提高情绪表达的多样性与自然度。
### Innovation
我们提出了一种名为MEDTalk的新框架，用于生成细粒度和动态的情感头像。该方法首先通过精心设计的交叉重建过程分离内容嵌入和情感嵌入空间，从而独立控制唇部运动和脸部表情。此外，该方法还结合了音频和演讲文本，预测帧间强度变化并动态调整静态情绪特征，以生成逼真的情绪表达。为了进一步增强控制和个性化，该方法还引入了包括文本描述和参考表情图像在内的多模态输入，以指导用户指定的情感面部表达示的生成。
### Conclusion
通过使用MetaHuman，我们生成的结果可以方便地集成到工业生产管道中，从而展示了MEDTalk在多模态动态情感3D面部动画生成方面的有效性。
## 493. `cs.CV` - MCAM: 多模态因果分析模型用于ego-车辆级驾驶视频理解 [PDF](https://arxiv.org/pdf/2507.06072), [HTML](https://arxiv.org/abs/2507.06072)
### Authors
Tongtong Cheng,Rongzhen Li,Yixin Xiong,Tao Zhang,Jing Wang,Kai Liu
### Background
准确的驾驶行为识别和推理对于自主驾驶视频的理解至关重要。然而，现有的方法往往倾向于挖掘浅层的因果关系，没有解决跨模态中的似然相关性，并且忽视了ego-车辆级别的因果关系建模。
### Innovation
提出了一种新的多模态因果分析模型（MCAM），该模型构建了视觉和语言模态之间的潜在因果结构。首先，设计了一个多级特征提取器来捕获长距离依赖关系。其次，设计了一个因果分析模块，使用驾驶状态的有向无环图（DAG）动态地建模驾驶场景。第三，利用视觉-语言转换器对关键的视觉特征与其相应的语言表达进行对齐。实验结果表明，MCAM 在视觉-语言因果关系学习中取得了最先进的性能。此外，模型在视频序列中捕捉因果特征的能力表现出色，证明了其在自主驾驶应用中的有效性。
### Conclusion
MCAM 在ego-车辆级别的驾驶视频理解中显示出优越的能力，特别是在捕捉视频序列中的因果特性方面。该模型已在 BDD-X 和 CoVLA 数据集上进行了广泛实验，并取得了最先进的性能。
## 494. `cs.CV` - 你所拥有的就是你所追踪的：自适应且鲁棒的多模态追踪 [PDF](https://arxiv.org/pdf/2507.05899), [HTML](https://arxiv.org/abs/2507.05899)
### Authors
Yuedong Tan,Jiawei Shao,Eduard Zamfir,Ruanjun Li,Zhaochong An,Chao Ma,Danda Paudel,Luc Van Gool,Radu Timofte,Zongwei Wu
### Background
多模态数据在视觉追踪中被证明有助于提高对外观变化的鲁棒性。然而，传感器同步问题常常影响数据的可用性，特别是在视频环境中，数据短缺可能是暂时性的。尽管多模态追踪的重要性，该领域的研究尚未充分展开。因此，研究在时间上不完整多模态数据情况下追踪器的表现是非常重要的。
### Innovation
本文首次全面研究了在时间不完整多模态数据情况下追踪器的表现。提出了一种灵活的自适应且鲁棒的多模态追踪框架。该框架通过异构混合专家融合机制与动态激活计算单元，结合视频级遮罩策略，实现了不同缺失率以及场景复杂度下的自适应调整，从而提高在多种多模态条件下的性能。
### Conclusion
本文模型在9个基准测试上实现了当前最佳性能（SOTA），在常规完整和部分缺失模态情况下表现尤为出色。代码和基准数据集将开源。
## 495. `cs.CV` - aware Normal Integration for Generic Central Camera Models [PDF](https://arxiv.org/pdf/2507.06075), [HTML](https://arxiv.org/abs/2507.06075)
### Authors
Francesco Milano,Manuel López-Antequera,Naina Dhingra,Roland Siegwart,Robert Thiel
### Background
3D表面恢复从其表面法线图出发（称为法线积分），是光度形状重建技术（如形状从光照和光度立体）的关键组成部分。大多数现有法线积分方法仅隐式处理深度不连续性，并且仅适用于正交或理想针孔相机。
### Innovation
提出了一种新的法线积分公式，能够显式建模深度不连续性，并处理通用中心相机。关键思想基于局部平面假设，通过表面法线和光线方向之间的约束建模。与现有方法相比，该方法更准确地近似深度和表面法线之间的关系，在标准法线积分基准上的表现达到最先进的水平，并且是首个直接处理通用中心相机模型的方法。
### Conclusion
所提出的方法更准确地近似深度和表面法线之间的关系，在标准法线积分基准上的表现达到最先进的水平，并且首次直接处理了通用中心相机模型。
## 496. `cs.CV` - VisualSpeaker: 视觉引导的3D虚拟角色唇形合成 [PDF](https://arxiv.org/pdf/2507.06060), [HTML](https://arxiv.org/abs/2507.06060)
### Authors
Alexandre Symeonidis-Herzig,Özge Mercanoğlu Sincan,Richard Bowden
### Background
高保真的3D面部动画对于交互性和无障碍性的提升至关重要。尽管之前的方法在质量上表现出色，但它们对网格领域的依赖限制了它们充分利用2D计算机视觉和图形领域中快速发展的可视化创新的能力。VisualSpeaker 提出了一种新的方法，使用外观逼真的可微渲染，并通过视觉唇部识别进行监督，从而改进3D面部动画。这种方法在训练过程中通过预训练的视觉自动唇部识别模型传递外观逼真的3D Gaussian Splatting化身渲染，从而贡献了一个感知唇读损失。这种方法实现在MEAD数据集上的改进，提高了标准的唇部顶点误差指标56.1%，并提高了生成动画的感知质量，同时保留了网格驱动动画的可控性。这种感知上的重点自然支持准确的唇形，这是在手语虚拟角色中使相似的手势表达清楚的重要线索。
### Innovation
VisualSpeaker 提出了一种新的方法，利用外观逼真的可微渲染，并通过视觉唇部识别进行监督，改进3D面部动画。贡献在于引入感知唇读损失，该损失通过将外观逼真的3D Gaussian Splatting化身渲染传递给预训练的视觉自动唇部识别模型来实现。这种方法不仅提高了标准的唇部顶点误差指标，还提高了生成动画的感知质量，同时保持了网格驱动动画的可控性。
### Conclusion
VisualSpeaker 在MEAD数据集上实现了改进的标准的唇部顶点误差指标56.1%和生成动画的感知质量提升，同时保持了网格驱动动画的可控性。这种方法自然支持准确的唇形，这对于手语虚拟角色中的相似手势表达的明确性至关重要。
## 497. `cs.CV` - CAST-Phys: 无需接触的生理信号情感状态数据库 [PDF](https://arxiv.org/pdf/2507.06080), [HTML](https://arxiv.org/abs/2507.06080)
### Authors
Joaquim Comas,Alexander Joel Vera,Xavier Vives,Eleonora De Filippi,Alexandre Pereda,Federico Sukno
### Background
近年来，情感计算及其应用已成为一个快速增长的研究话题。尽管取得了显著进展，但缺乏多模态情感数据集仍然是开发准确情绪识别系统的主要瓶颈。此外，使用接触式设备在诱发情绪时往往无意中影响了情绪体验，减少了或改变了真实的自发情绪反应。这一局限性突显了提取多模态生理表征以实现无需接触的情感识别技术的需求，以便在远程生理情感识别中进行情感线索提取。
### Innovation
本文介绍了无需接触的情感状态生理信号数据库（CAST-Phys），这是一个专为多模态远程生理情感识别设计的新颖高质量数据集，利用面部和生理信号线索。该数据集包括多样化的生理信号，如脉搏波图（PPG）、皮肤电活动（EDA）和呼吸频率（RR），以及高分辨率的未压缩面部视频记录，能实现远程信号恢复。我们分析表明，在面部表情可能不足以提供足够情绪信息的现实场景中，生理信号起着关键作用。
### Conclusion
我们通过评估单独模态和融合模态的影响，展示了远程多模态情绪识别的潜力，证明了其在推进无需接触情绪识别技术方面的有效性。
## 498. `cs.CV` - 基于视觉簇先验的瓷砖级ViT推理在零样本多物种植物识别中的应用 [PDF](https://arxiv.org/pdf/2507.06093), [HTML](https://arxiv.org/abs/2507.06093)
### Authors
Murilo Gustineli,Anthony Miyaguchi,Adrian Cheung,Divyansh Khattak
### Background
该研究介绍了DS@GT团队在PlantCLEF 2025挑战中关于植被样方图像中多物种植物识别的第二名解决方案。背景在于现有植物识别技术在多物种识别和基于样方图像的识别方面仍存在挑战，特别是如何高效利用图像中局部信息并结合地面信息来提高识别准确率。这项工作通过结合特定的技术手段，旨在克服现有方法的不足，提高识别效果。
### Innovation
创新之处在于提出了一种基于瓷砖的ViT推理框架，结合了尺度适配的视觉集群先验以及地理位置过滤方法。具体包括：1) 使用微调的Vision Transformer (ViTD2PC24All) 对瓷砖进行推理；2) 采用4x4的切片策略以与网络的接收域相匹配；3) 通过PaCMAP与K-Means聚类进行领域先验适应，并结合地理定位过滤。切片预测通过多数投票和基于簇的贝叶斯先验重新加权，最终获得0.348的宏平均F1值，且无需额外的训练。
### Conclusion
结论指出，该方法通过融合多模态信息和场景先验，显著提高了多物种植物识别的精度，并成功应用于PlantCLEF 2025挑战。所有代码、配置文件和可重复性脚本均已公开发布。
## 499. `cs.CV` - ScoreAdv：通过扩散模型基于评分的生成自然对抗样本 [PDF](https://arxiv.org/pdf/2507.06078), [HTML](https://arxiv.org/abs/2507.06078)
### Authors
Chihan Huang,Hao Tang
### Background
尽管深度学习在多个领域取得了成功，但它仍然容易受到对抗攻击的影响。现有的许多对抗攻击方法虽然成功率高，但主要依赖于$boldsymbol{text{l}}boldsymbol{text{_{p}}}$范数扰动约束，这与人类的视觉感知能力不匹配。因此，研究人员将注意力转向生成自然的且无约束的对抗样本（UAEs）。基于GAN的方法存在固有的局限性，如图像质量差、不稳定和模式塌陷等问题。扩散模型虽用于生成UAEs，但仍依赖于迭代的PGD扰动注入，未能充分利用其核心去噪能力。
### Innovation
本文提出了一种基于扩散模型生成UAEs的方法，名为ScoreAdv。该方法引入了一种可解释的对抗指导机制，逐步将采样分布朝对抗分布偏移，同时使用可解释的显著性图将参考图像的视觉信息注入生成样本中。值得注意的是，该方法能够生成无限数量的自然对抗样本，不仅能够攻击分类模型还能攻击检索模型。作者在ImageNet和CelebA数据集上进行了广泛的实验，验证了ScoreAdv在黑盒和白盒设置下的性能表现。结果表明ScoreAdv的攻击成功率和图像质量均达到最佳。此外，去噪与对抗扰动之间的动态平衡使ScoreAdv在面对防御措施时仍保持鲁棒性。
### Conclusion
实验结果表明，ScoreAdv方法在攻击成功率和图像质量上均达到最先进的水平。该方法利用扩散模型的去噪能力和可解释的对抗指导机制，成功生成了高质量的自然对抗样本。该方法不仅具有广泛的适应性，还能在存在防御措施的情况下保持稳定和有效的攻击。
## 500. `cs.CV` - 遥感图像场景分类中解释性人工智能方法和技术的效果研究 [PDF](https://arxiv.org/pdf/2507.05916), [HTML](https://arxiv.org/abs/2507.05916)
### Authors
Jonas Klotz,Tom Burgert,Begüm Demir
### Background
在遥感（RS）领域，可解释的人工智能（xAI）方法在场景分类问题上的发展受到了广泛关注。大多数xAI方法及其相关评估指标最初是为计算机视觉（CV）中的自然图像而开发的，直接应用于RS可能并不合适。因此，本文旨在探讨解释方法和指标在RS图像场景分类中的效果。具体而言，作者对包括五个类别（忠实性、鲁棒性、定位、复杂性、随机化）和五个特征归因方法（遮盖、LIME、GradCAM、LRP、DeepLIFT）在内的十个解释度量进行了综合分析，覆盖了三个RS数据集。研究表明，基于扰动的方法（如遮盖和LIME）的性能高度依赖于扰动基准和RS场景的空间特征；基于梯度的方法（如GradCAM）在图像中存在多种标签时表现不佳；而一些相关传播方法（如LRP）无法按比例分配相关性。评估指标也表现出类似限制：忠实度指标遇到的问题与基于扰动的方法相同；对于空间范围较大的类别，定位指标和复杂性指标不可靠，但鲁棒性和随机化指标表现出更高的稳定性。
### Innovation
本文首次系统地分析了解释方法和指标在RS图像场景分类中的适用性。作者研究了包括五个类别和五个特征归因方法在内的十个解释度量的具体效果，并提出了指导选择解释方法、指标和超参数的设计方案，这些都对改善XAΙ方法在RS应用中的解释性产生了重要贡献。
### Conclusion
研究表明，基于扰动的方法（如遮掩和LIME）和基于梯度的方法（如GradCAM）自动解释RS图像的表现有限。基于复杂性和定位的方法在此类应用中不可靠。然而，鲁棒性和随机化方法相对更为稳定，适合改进RS图像解释性。作者提供了一些建议以选择最合适的解释方法、指标和超参数。
## 501. `cs.CV` - SoftReMish：视觉识别性能增强的新型卷积神经网络激活函数 [PDF](https://arxiv.org/pdf/2507.06148), [HTML](https://arxiv.org/abs/2507.06148)
### Authors
Mustafa Bayram Gücen
### Background
在图像分类任务中，卷积神经网络（CNNs）的性能可以通过改进激活函数来提升。本研究基于MNIST数据集，实验了一个标准的CNN架构，包括两层卷积层，最大池化和全连接层。将SoftReMish与ReLU、Tanh和Mish等流行激活函数进行了对比，结果以最小训练损失和最大验证准确性来评价模型性能。
### Innovation
提出了SoftReMish，一种新设计的激活函数，用于提升卷积神经网络在图像分类任务中的性能。与ReLU、Tanh和Mish等流行激活函数相比，SoftReMish在最小损失（3.14e-8）和验证准确性（99.41%）方面表现出色，证明了它在收敛行为和泛化能力方面的优越性，是视觉识别任务的有希望候选人。
### Conclusion
实验证明，SoftReMish在卷积神经网络中的应用可以显著提高模型的性能，表现出更好的收敛性和泛化能力，提升了视觉识别任务中的表现，为未来的研究提供了具有前景的新方法。
## 502. `cs.CV` - Omni-Video: 民主化统一视频理解和生成 [PDF](https://arxiv.org/pdf/2507.06119), [HTML](https://arxiv.org/abs/2507.06119)
### Authors
Zhiyu Tan,Hao Yang,Luozheng Qin,Jia Gong,Mengping Yang,Hao Li
### Background
近期在统一理解和生成建模方面取得了显著进展，推动了图像理解和推理等诸多领域的进步，但当前的基础模型主要侧重于图像处理，缺乏统一的视频理解和生成模型。本文介绍了一个名为Omni-Video的框架，旨在弥合这个领域的差距，以促进视频理解、生成及基于指令的编辑一体化模型的发展。
### Innovation
本文提出了一个高效的统一框架Omni-Video，通过训练现有的多模态大型语言模型来生成连续的视觉线索，并将其作为扩散解码器的输入，以生产高质量的视频。主要创新包括：1）轻量级架构设计，分别在一个特定的视觉头部和扩散解码器输入前的适配器来增强视觉令牌，适配这些视觉令牌以适应扩散解码器的条件空间；2）高效的多阶段训练方案，使多模态大型语言模型与扩散解码器之间的连接更为迅速，同时减少数据和计算资源的需求。
### Conclusion
实验结果表明，该模型在视频生成、编辑和理解任务上展现出了较好的泛化能力。
## 503. `cs.CV` - 无提示条件扩散用于多对象图像增强 [PDF](https://arxiv.org/pdf/2507.06146), [HTML](https://arxiv.org/abs/2507.06146)
### Authors
Haoyu Wang,Lei Zhang,Wei Wei,Chen Ding,Yanning Zhang
### Background
扩散模型在多种计算机视觉任务的数据增强中发挥了重要作用。但在涉及生成包含多个对象的图像时，现有方法要么完全依赖文本条件，导致生成的对象与原始数据偏差较大；要么过度依赖原始图像，导致生成的图像多样性不足，这对下游任务帮助有限。
### Innovation
我们提出了一种无提示的条件扩散框架，用于多对象图像增强。该框架通过局部-全局语义融合策略从图像中提取语义以替代文本，并通过LoRA技术向扩散模型注入知识，以缓解原始模型与目标数据集之间的类别偏差。此外，我们设计了基于计数的奖励模型辅助传统的重构损失进行模型训练，通过约束每个类别的对象数量而不是像素级约束，实现生成数据与原始数据之间的数量偏差，同时提高生成数据的多样性。
### Conclusion
实验结果表明，所提出的方法优于几种代表性的前沿基线方法，并展示了出色的下游任务改进和跨域泛化能力。代码可在此处访问：this https URL
## 504. `cs.CV` - Reflections 解锁：基于3D 高斯束射的几何意识反射解藕在真实感场景渲染中的应用 [PDF](https://arxiv.org/pdf/2507.06103), [HTML](https://arxiv.org/abs/2507.06103)
### Authors
Jiayi Song,Zihan Ye,Qingyuan Zhou,Weidong Yang,Ben Fei,Jingyi Xu,Ying He,Wanli Ouyang
### Background
在新颖视图合成中，准确渲染具有反射表面的场景仍是一个重大挑战。当前方法如神经光度场（NeRF）和3D高斯束射（3DGS）往往将反射误认为物理几何，导致重建效果下降。之前的方法依赖不完整且非通用的几何约束，这些约束导致高斯束射的位置与实际场景几何产生偏差。在复杂几何结构的现实场景中，高斯束的累积增加了表面伪影，导致模糊重建。因此，亟需一种新的解决方案来解决这些限制问题，以实现对复杂反射的更好地捕捉和几何一致性增强。
### Innovation
该研究提出了Ref-Unlock，一种基于3D高斯束射的新型几何感知反射建模框架，该框架明确解耦散射和反射成分，更精确地捕捉复杂反射并增强现实场景中的几何一致性。研究采用了高阶球谐函数的双分支表示来捕捉高频反射细节，并引入反射移除模块提供伪反射自由监督，以指导清洁分解。此外，研究还结合了伪深度图和几何感知双边平滑约束，以增强3D几何一致性和分解的稳定性。实验结果表明，Ref-Unlock在多种反射方法中表现优异，并能与基于NeRF的模型竞争，同时允许灵活的视觉基础模型（VFMs）驱动的反射编辑，提供了一种高效且通用的反射场景真实渲染解决方案。
### Conclusion
该研究通过Ref-Unlock方法解决了传统 GS 基础反射方法中的问题，大大提高了反射场景的真实渲染效果，同时也为基于NeRF的模型提供了更强的替代方案。研究的代码已在指定网址公开发布。
## 505. `cs.CV` - TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-Guided Supervision [PDF](https://arxiv.org/pdf/2507.06033), [HTML](https://arxiv.org/abs/2507.06033)
### Authors
Syeda Anshrah Gillani,Mirza Samad Ahmed Baig,Osama Ahmed Khan,Shahid Munir Shah,Umema Mujeeb,Maheen Ali
### Background
现代文本到图像的扩散模型的兴起，开启了数字内容生产的全新时代，这些模型能够根据自然语言描述生成逼真且风格多样的图像。然而，这些模型存在一个持续的缺点，即无法生成在生成图像中可以读取、具意义且无误拼的文本，这极大地限制了广告、学习和创意设计等实际应用中的使用.
### Innovation
提出了一种新的框架，即带有字符感知注意机制的编码-生成扩散模型（Glyph-Conditioned Diffusion with Character-Aware Attention，GCDA）。该框架在普通扩散模型中添加了三个精心设计的模块：1) 双流文本编码器，用于编码语义上下文信息和显式字符表示；2) 具有新注意力分离损失的字符感知注意力机制，旨在独立限制每个字符的注意力分布，避免畸变伪影；3) OCR反馈循环微调阶段，通过全文本感知损失直接优化模型，使其可读且拼写准确。
### Conclusion
在大型基准数据集MARIO-10M和T2I-CompBench上的实验表明，GCDA在所有指标上都达到了最新的最佳效果，在基于字符的文本渲染指标（字符错误率：0.08 vs 0.21，词错误率：0.15 vs 0.25）、人类感知和高保真图像合成质量（FID：14.3）方面均有显著提升。
## 506. `cs.CV` - OmniPart: 部件感知的语义解耦和结构一致性3D生成 [PDF](https://arxiv.org/pdf/2507.06165), [HTML](https://arxiv.org/abs/2507.06165)
### Authors
Yunhan Yang,Yufan Zhou,Yuan-Chen Guo,Zi-Xin Zou,Yukun Huang,Ying-Tian Liu,Hao Xu,Ding Liang,Yan-Pei Cao,Xihui Liu
### Background
3D资产的创建，特别是具有明确、可编辑部分结构的资产，对推动交互式应用至关重要。然而，大多数生成方法仅生成单一整体形状，这限制了它们的应用价值。现有方法在分解部件时需要显式的对应关系或语义标签，从而影响了灵活性和用户友好性。因此，本文即探讨了一种创新的框架，旨在实现组件间的高语义解耦同时保持结构的一致性。该框架将这一复杂任务分解为两个协同的阶段，以实现更灵活、更可控的3D部件生成和布局。
### Innovation
提出了OmniPart框架，这是一种新颖的基于部分感知的3D对象生成框架，特别设计用于实现组件间的高语义解耦，同时保持结构的一致性。它将复杂的任务分为两个阶段：1）自回归的结构规划模块生成可控制、可变长度的3D部分边界框序列，该过程由灵活的2D部分掩码指导，支持直观的部件分解控制；2）空间条件下的校正流模型，基于预训练的整体3D生成器，有效地合成计划布局内的所有3D部件。该框架支持用户定义的部件粒度和精确定位，从而实现多样的下游应用。实验结果表明，OmniPart在性能上达到最新技术水平，有助于生成更可解释、可编辑和多样化的3D内容。
### Conclusion
本文提出了一种新颖的、基于部分感知的3D生成框架OmniPart，该框架能够在保持结构一致性的同时显著提高语义解耦，从而实现更为灵活和可控的3D内容生成。实验结果证明了该方法的有效性，为其在交互式应用中的广泛应用铺平了道路。
## 507. `cs.CV` - 使用最优运输进行规范化扩散核 [PDF](https://arxiv.org/pdf/2507.06161), [HTML](https://arxiv.org/abs/2507.06161)
### Authors
Nathan Kessler,Robin Magnet,Jean Feydy
### Background
基于局部邻域平滑是机器学习和几何处理中的核心操作。在如向量空间和流形等良好结构化的领域中，来自微分几何的拉普拉斯算子提供了通过热扩散进行平滑的标准方法，并具有强大的理论保证。然而，构造这样的拉普拉斯算子需要一个精确定义的领域结构，这在许多情况下并不可得。大多数实践者依赖于简单的卷积核或消息传递层，这些核可能会偏向于领域的边界。论文通过引入一类基于通用相似性或邻接矩阵的平滑算子，弥补这一差距，这些算子可以被规范化成类似于扩散操作的算子，并继承了拉普拉斯算子的优良特性。该方法依赖于变异的Sinkhorn算法，将正平滑算子重新缩放以匹配热量扩散的结构行为。这种方法使我们能够处理点云、稀疏体素网格或高斯混合数据等非规则数据的拉普拉斯似平滑和处理。方法所生成的算子不仅近似于热量扩散，还保留了拉普拉斯算子的频谱信息，应用于形状分析和匹配等领域。
### Innovation
论文引入了一类基于通用相似性或邻接矩阵的平滑算子，这些算子可以被规范化成类似于拉普拉斯算子的扩散操作，从而能够处理非规则数据的平滑和处理。通过使用变异的Sinkhorn算法重新缩放正平滑算子，论文的方法能够继承拉普拉斯算子的优良特性，例如近似热量扩散和保留频谱信息，从而应用于形状分析和匹配等领域。
### Conclusion
所提出的规范化扩散操作不仅能够近似热量扩散，还能够保留来自拉普拉斯算子的频谱信息，特别适用于形状分析和匹配等应用。
## 508. `cs.CV` - 基于自注意力的多尺度3D网格图自动编码网络 [PDF](https://arxiv.org/pdf/2507.05304), [HTML](https://arxiv.org/abs/2507.05304)
### Authors
Saqib Nazir,Olivier Lézoray,Sébastien Bougleux(UNICAEN)
### Background
3D网格数据在计算机视觉和图形应用中被用作捕捉复杂几何形状的基础数据表示。虽然卷积神经网络（CNNs）在处理结构化数据如图像方面表现出色，但它们很难直接应用于不规则的3D网格，因为3D网格数据是非欧几里得的。尽管图卷积网络（GCNs）可以将卷积应用于图结构数据，但许多现有方法依赖于各向同性滤波器或频谱分解，这限制了它们捕捉3D网格的局部和全局特征的能力。
### Innovation
本文提出了一种新的基于 GCN 的框架——3D几何网格网络（3DGeoMeshNet），使用各向异性卷积层在空间域中直接有效学习全局和局部特征。该网络没有将网格转换为体素网格或点云等中间表示，而是保持原始多边形网格格式在整个重建过程中，从而更准确地重建形状。该架构包括一个多尺度编码器-解码器结构，其中不同的全局和局部路径分别捕捉大型几何结构和精细局部细节。实验结果表明，在COMA数据集（包含人脸）上，3DGeoMeshNet 在重建准确性方面表现高效。
### Conclusion
本文通过引入3DGeoMeshNet这一新型GCN框架，提出了一个使用各向异性卷积层来直接在空间域中学习全局和局部特征的方法。该方法能够同时保持原多边形网格格式进行形状重建，从而提高重建的准确性，相较于过去将网格转换为体素网格或点云等中间表示的方法，表现更优。
## 509. `cs.CV` - RSRefSeg 2: 使用基础模型解耦引参照的遥感图像分割 [PDF](https://arxiv.org/pdf/2507.06231), [HTML](https://arxiv.org/abs/2507.06231)
### Authors
Keyan Chen,Chenyang Liu,Bowen Chen,Jiafan Zhang,Zhengxia Zou,Zhenwei Shi
### Background
当前的遥感图像分割方法主要采用三阶段框架，即双模态编码、跨模态交互和像素解码。这些方法在处理复杂的语义关系和实现精确的跨模态对齐方面存在局限性，主要是由于其耦合的处理机制将目标定位与边界细化混淆在一起。这种耦合不仅在语义模糊情况下加剧了错误传播，还限制了模型的泛化能力和可解释性。
### Innovation
该研究提出了一种解耦的新范式RSRefSeg 2，通过将传统的两阶段框架改造成精细分割先于目标粗略定位的双阶段框架来解决上述问题。RSRefSeg 2 利用 CLIP 的跨模态对齐优势和 SAM 的语义分割灵活性，通过战略性基础模型合作来集成 CLIP 作为双模态编码器，激活其预对齐的语义空间中的目标特征，并生成定位提示。为了降低 CLIP 在多实体场景描述时的误激活挑战，引入了一种级联二次提示器，通过将文本嵌入分解为互补的语义子空间实现隐式推理，以提高精确度。这些优化的语义提示随后引导 SAM 生成亚像素级细化掩码，完成语义传输管道。
### Conclusion
大量的实验（RefSegRS，RRSIS-D 和 RISBench）表明，RSRefSeg 2 在分割精度（+~3% gIoU）和复杂语义理解方面超越了现有方法。代码已提供。
## 510. `cs.CV` - 通过多模态推理和集成建模增强科学可视化问答 [PDF](https://arxiv.org/pdf/2507.06183), [HTML](https://arxiv.org/abs/2507.06183)
### Authors
Prahitha Movva,Naga Harshita Marupaka
### Background
技术报告和文章中常常包含以半结构化数据形式存在的价值信息，例如图表和插图。理解和使用这些信息对于下游任务，如问答（QA）至关重要。当前的可视化问答方法在处理科学数据解释所需精度方面经常存在挑战，特别是在处理数值值、在视觉元素之间的多步推理以及在视觉观察与文本推理之间保持一致性方面尤为困难。
### Innovation
本文介绍了针对SciVQA 2025共享任务的方法，重点是基于科学图表的视觉和非视觉问题的解答。通过使用5B到8B参数的模型进行了一系列实验。我们的最强单个模型InternVL3在SciVQA测试分割上取得了ROUGE-1和ROUGE-L F1分数为0.740以及BERTScore为0.983的成绩。我们还开发了一个由多个视觉语言模型（VLMs）组成的集成模型。通过验证分割上的错误分析，我们的集成方法在大多数单个模型之上有所改进，尽管InternVL3仍然是最强的独立表现者。我们的研究结果强调了提示优化、推理链和集成建模在提高模型在可视化问答方面能力方面的有效性。
### Conclusion
我们的发现强调了提示优化、推理链和集成建模在提高模型在可视化问答方面能力的有效性。
## 511. `cs.CV` - NRXR-ID: 在近场扩展现实和智能手机中实现VR的双因素身份验证 [PDF](https://arxiv.org/pdf/2507.05447), [HTML](https://arxiv.org/abs/2507.05447)
### Authors
Aiur Nanzatov,Lourdes Peña-Castillo,Oscar Meruvia-Pastor
### Background
双因素身份验证（2FA）已成为一种有效且安全的身份验证方法，广泛应用于在线验证用户身份。然而，在虚拟现实（VR）环境中实施2FA面临挑战，因为用户通常戴着头戴式显示器（HMD），看不到现实世界的环境，导致难以进行身份验证。因此，如何在VR环境下利用智能手机等辅助设备实现2FA成为亟待解决的问题。
### Innovation
本文提出了一种名为NRXR-ID的技术，该技术允许用户在不摘下HMD的情况下使用智能手机完成身份验证挑战，实现了在VR环境中有效且安全地进行双因素身份验证。研究人员设计了新型的国际象棋棋盘样式挑战并结合多种配置条件进行用户体验研究，发现视觉匹配挑战最为合适。
### Conclusion
研究结果表明，新型的视觉匹配挑战是最佳选项，其次是通过智能手机输入数字PIN号码并提交。该方法为VR系统中的身份验证提供了灵活且可靠的方式。
## 512. `cs.CV` - PWD: 前提引导与小波增强扩散模型用于有限角度CT [PDF](https://arxiv.org/pdf/2507.05317), [HTML](https://arxiv.org/abs/2507.05317)
### Authors
Yi Liu,Yiyang Wen,Zekun Zhou,Junqi Ma,Linghang Wang,Yucheng Yao,Liu Shi,Qiegen Liu
### Background
在医学影像中，生成扩散模型得到了越来越多的关注，特别是在有限角度X射线计算机断层扫描(LACT)中。标准的扩散模型能够实现高质量的图像重建，但需要大量的采样步骤，从而产生显著的计算开销。尽管已经提出了跳过采样策略以提高效率，但这些方法往往会导致结构细节的丧失。为了克服这一问题，本文提出了一种嵌入先验信息和小波特征融合的快速采样扩散模型（PWD），以提高LACT重建的效率并保持重建保真度，同时有效地缓解了跳过采样通常引入的降解。在训练阶段，PWD将LACT图像的数据分布映射到全采样目标图像的数据分布，使模型能够学习它们之间的结构对应关系。在推理阶段，LACT图像作为显式的先验知识引导采样路径，允许使用显著较少的步骤实现高质量的重建。此外，PWD在小波域进行多尺度特征融合，在利用低频和高频信息的同时有效增强了精细细节的重建。在针对临床牙弓CBCT和根尖周数据集的定量和定性评估中，PWD在相同采样条件下表现出色，仅使用50个采样步骤就实现了至少1.7 dB的PSNR提升和10%的SSIM增益，优于现有方法。
### Innovation
提出的PWD模型通过嵌入先验信息和在小波域融合多尺度特征，实现了在保证图像重建高保真度的同时，显著减少了采样步骤。这种创新性的方法有效解决了跳过采样策略导致的细节损失问题。
### Conclusion
PWD在有限角度CT重建中表现出色，具有明显的性能优势。它能够使用较少的采样步骤实现高质量的重建，同时保持重建的精确度，这在临床牙弓CBCT和根尖周数据集的测试中得到了验证。
## 513. `cs.CV` - 从人体运动中学习跟踪任意点 [PDF](https://arxiv.org/pdf/2507.06233), [HTML](https://arxiv.org/abs/2507.06233)
### Authors
Inès Hyeonsu Kim,Seokju Cho,Jahyeok Koo,Junghyun Park,Jiahui Huang,Joon-Young Lee,Seungryong Kim
### Background
人的运动固有复杂性，如非刚性变形、仿关节动作、服装变形和肢体或其他个体引起的频繁遮挡，为点跟踪提供了一个丰富且具有挑战性的监督来源，对于训练健壮和泛化能力强的点跟踪器至关重要。然而，由于手动标注数据的劳动强度，获取大量跟踪训练数据仍然困难重重.
### Innovation
AnthroTAP 提出了一种自动化流程，利用 SMPL 模型生成半结构化训练数据。流程包括将 SMPL 模型拟合到视频帧中检测到的人体，将 3D 网格顶点投影到 2D 图像平面上生成伪轨迹，使用光度线投射处理遮挡，并基于光流一致性过滤掉不可靠的轨迹。基于 AnthroTAP 标注的数据集训练的点跟踪模型在 TAP-Vid 基准测试中取得了最先进的性能，即使使用的数据是其他模型的 10,000 倍少，并且仅在 4 块 GPU 上使用了一天的时间，而近期的最先进的模型则使用了 256 块 GPU.
### Conclusion
AnthroTAP 自动化生成的数据集提高了点跟踪模型的性能，显著减少了所需的数据量和训练时间，展示了其在人体运动点跟踪领域的创新性和有效性.
## 514. `cs.CV` - 自监督深度学习在超声微血管成像去噪中的应用 [PDF](https://arxiv.org/pdf/2507.05451), [HTML](https://arxiv.org/abs/2507.05451)
### Authors
Lijie Huang,Jingyi Yin,Jingke Zhang,U-Wai Lok,Ryan M. DeRuiter,Jieyang Jin,Kate M. Knoll,Kendra E. Petersen,James D. Krier,Xiang-yang Zhu,Gina K. Hesley,Kathryn A. Robinson,Andrew J. Bentall,Thomas D. Atwell,Andrew D. Rule,Lilach O. Lerman,Shigao Chen,Chengwu Huang
### Background
超声微血管成像（UMI）在低信噪比（SNR）的情况下常常受到阻碍，尤其是在无对比剂或深层组织的场景中，这影响了后续的血管量化和可靠的疾病诊断。现有的方法难以有效解决这一问题。
### Innovation
本文提出了一种自监督降噪框架HA2HA，专门用于UMI。HA2HA利用血流血频（RF）数据的互补角度子集构建训练对，在这些子集上血管信号保持一致而噪声变化。经过猪肾的对比剂自由数据以及猪肾和人的肝脏、肾脏数据集验证，HA2HA在对比噪声比（CNR）和信噪比（SNR）方面取得了超过15 dB的提升，提高了图像质量。此外，去噪不仅适用于功率多普勒成像，也能有效应用于后续处理，如彩色多普勒成像（CDI）.
### Conclusion
HA2HA提供了一种无标记、可泛化的临床适用解决方案，适用于对比剂自由和对比剂增强的UMI中的 robust 血管成像。
## 515. `cs.CV` - CultureCLIP：通过合成图像和上下文化描述增强CLIP的文化意识 [PDF](https://arxiv.org/pdf/2507.06210), [HTML](https://arxiv.org/abs/2507.06210)
### Authors
Yuchen Huang,Zhiyuan Fan,Zhitao He,Sandeep Polisetty,Wenyan Li,Yi R. Fung
### Background
预训练的多模态模型（如CLIP）在多模态理解方面表现突出，但在处理具体的文化视觉特征时存在局限性，难以区分视觉相似但文化背景不同的概念。这种局限性源于高质量文化特定数据集的缺乏、集成上下文知识的不足以及未能突出细微差异的硬负例。
### Innovation
本文设计了数据策展流水线，利用开源的预训练多模态模型和文本到图像扩散模型构建了CulTwin，这是一个合成的文化数据集。通过定制的对比学习，CulTwin使文化概念与加强了上下文的语言描述和合成图像对齐。实验结果表明，CultureCLIP在某些任务中的细粒度概念识别能力大幅提升了5.49%，这验证了数据合成和模型训练方法的有效性。
### Conclusion
CultureCLIP通过合成图像和上下文化描述增强了CLIP的文化意识，不仅提高了文化概念的辨识度，还保持了模型的泛化能力。
## 516. `cs.CV` - Cross-Subject DD: 一种跨个体脑机接口算法 [PDF](https://arxiv.org/pdf/2507.05268), [HTML](https://arxiv.org/abs/2507.05268)
### Authors
Xiaoyuan Li,Xinru Xue,Bohan Zhang,Ye Sun,Shoushuo Xi,Gang Liu
### Background
基于运动想象的脑机接口（BCI）可以通过解码大脑在想象运动过程中产生的脑电图（EEG）来直接控制外部设备。然而，由于个体之间脑活动存在差异，当前的BCI模型在不同受试者之间的适应性较差，限制了其广泛应用和通用性。为了应对这一问题，论文提出了一种名为Cross-Subject DD（CSDD）的跨个体BCI算法，通过提取多个受试者之间的共同特征来构建通用的BCI模型。这种方法旨在提高BCI模型在不同受试者之间的通用性，以便更广泛地应用BCI技术。
### Innovation
该研究首次提出了一种新颖的方法，用于提取纯净的共同特征并构建适用于所有受试者的通用跨个体BCI模型。该方法包括个性化模型训练、将个性化模型转换为关系光谱、通过统计分析识别共同特征以及基于这些共同特征构建跨个体通用模型。实验结果表明，与现有的类似方法相比，该方法在解码性能上提高了3.28%。
### Conclusion
该论文提出的Cross-Subject DD算法通过构建通用的BCI模型，显著提高了不同个体之间的适应性，从而促进了BCI技术的更广泛应用。
## 517. `cs.CV` - 带有类别特定集成和贝叶斯超参数优化的双注意力U-Net++用于精确伤口和规模标记分割 [PDF](https://arxiv.org/pdf/2507.05314), [HTML](https://arxiv.org/abs/2507.05314)
### Authors
Daniel Cieślak,Miriam Reca,Olena Onyshchenko,Jacek Rumiński
### Background
临床图像中准确分割伤口和规模标记仍然是一个重要挑战，对于有效的伤口管理和自动化评估至关重要。
### Innovation
提出了一种新的双注意力U-Net++架构，结合了通道级和空间注意力机制，以应对医学图像中的严重类别不平衡和变量性。
### Conclusion
所提出的方法在NBC 2025 & PCBBE 2025 挑战赛的数据集上进行了评估，使用加权F1分数（伤口75%，规模标记25%）进行了量化。所提出的体系结构获得了F1分数为0.8640，并强调了其对复杂医学分割任务的有效性。
## 518. `cs.CV` - 在噪声条件下基于扩散的有限角度CT重建 [PDF](https://arxiv.org/pdf/2507.05647), [HTML](https://arxiv.org/abs/2507.05647)
### Authors
Jiaqi Guo,Santiago López-Tapia
### Background
有限角度CT（LACT）是一种具有挑战性的逆问题，其中缺失的角度投影导致不完整的sinogram并产生严重的重建图像伪影。尽管最近的学习方法已经显示出有效性，但大多数方法假设理想的、无噪声的测量值，并未能解决测量噪声的影响。
### Innovation
论文提出了一个基于扩散的过程框架，使用均值回复随机微分方程（MR-SDE）公式来填充缺失的角度视图，并提出了一种新的噪声感知校正机制RNSD$^+$，在推理时明确建模不确定性，从而实现稳定可靠的重建。
### Conclusion
大量的实验表明，本文方法在数据一致性和感知质量方面始终超过基线模型，并且在不同的噪声强度和采集场景中具有良好的通用性。
## 519. `cs.CV` - 从放射报告学习分割 [PDF](https://arxiv.org/pdf/2507.05582), [HTML](https://arxiv.org/abs/2507.05582)
### Authors
Pedro R. A. S. Bassi,Wenxuan Li,Jieneng Chen,Zheren Zhu,Tianyu Lin,Sergio Decherchi,Andrea Cavalli,Kang Wang,Yang Yang,Alan L. Yuille,Zongwei Zhou
### Background
肿瘤在CT扫描中的分割对于诊断、手术和预后至关重要，但现有的分割掩模稀缺，因为它们的创建需要时间和专业知识。公共腹部CT数据集中有从几十到几千个肿瘤掩模，但医院有成千上万带有放射学报告的肿瘤CT图像。因此，通过利用报告来改进分割是扩大应用的关键。现有的分割依赖于大量标注的数据，这在实际中是非常昂贵和耗时的。
### Innovation
本文提出了一种名为报告监督损失（R-Super）的方法，该方法将放射学报告转换为体素级别的监督，用于肿瘤分割AI的训练。研究团队构建了一个包含6,718个CT-报告配对的数据集（来自UCSF医院），并将此数据集与公共CT-掩模数据集合并。通过使用R-Super进行训练，肿瘤分割的性能得到了显著提高，F1分数相比仅使用掩模训练提高了16%。这种方法在训练数据量非常有限的情况下（例如50个）和大量可用掩模的情况下（例如1,700个）都能显著提高AI的性能。
### Conclusion
通过利用易获取的放射学报告来补充稀缺的分割掩模，R-Super显著提高了AI性能，对于肿瘤分割任务的AI模型具有重要的应用前景。
## 520. `cs.CV` - 基于条件图神经网络预测软组织变形和力 [PDF](https://arxiv.org/pdf/2507.05315), [HTML](https://arxiv.org/abs/2507.05315)
### Authors
Madina Kojanazarova,Florentin Bieder,Robin Sandkühler,Philippe C. Cattin
### Background
在虚拟环境中模拟软组织的现实应用正在变得越来越重要。然而，软组织的高度可变形性带来了显著的挑战。现有的方法依赖于组织的分割、网格生成及刚度属性的估计。此外，为了提供更沉浸式的体验，集成触觉反馈还需要精确的力量估计。现有的方法主要集中在数据分割、网格化以及软组织刚度属性的估计上，但对数据的依赖性很强，且对复杂变形的预测精度有限。
### Innovation
我们提出了一种基于条件图神经网络(cGNN)的新方法来解决这些复杂性。这种方法通过输入表面点和施加力的位置，预测这些点的变形及其受到的力。模型通过实验收集到的软组织仿体表面追踪数据进行训练，并结合迁移学习方法，利用质量弹簧模拟初始训练，再用实验数据进行微调，以提高模型的泛化能力和准确预测软组织变形和交互力的能力。
### Conclusion
我们的方法展示了模拟虚环境中软组织复杂挑战的前景。这种方法不仅适用于医学模拟，在需要现实软组织模拟的其他领域也有巨大的潜力。
## 521. `cs.CV` - Tissue Concepts v2：用于全幅切片图像的监督基础模型 [PDF](https://arxiv.org/pdf/2507.05742), [HTML](https://arxiv.org/abs/2507.05742)
### Authors
Till Nicke,Daniela Scharcherer,Jan Raphael Schäfer,Natalia Artysh,Antje Prasse,André Homeyer,Andrea Schenk,Henning Höfener,Johannes Lotz
### Background
基础模型（FMs）正通过提供新的方法来分析组织病理学图像，正在改变计算病理学领域。创建FMs通常需要在大型数据库上进行数周的训练，是一个资源密集型的过程。现有模型通常需要大量的训练资源，为解决这一问题，我们介绍了监督基础模型Tissue Concepts的扩展版，名为Tissue Concepts v2 (TCv2)，它是一个针对全幅切片图像的监督基础模型，能够使用比自我监督训练更少的资源进行训练，并在癌症亚型分类基准测试中表现出更优的性能，且全部训练数据是免费获取的。此外，共享训练的注意力模块还为不同任务提供了额外的可解释性层次结构。
### Innovation
Tissue Concepts v2引入了监督端到端多任务学习于切片级别的标签上，相较于自我监督训练，使用了较少的训练资源。Tissue Concepts v2在癌症亚型分类基准测试中表现优于自我监督训练模型，并且全部训练数据是免费获取的。共享训练的注意力模块提供了不同任务的额外解释层。
### Conclusion
Tissue Concepts v2模型在全幅切片图像的应用中表现出了优于自我监督训练模型的性能，并提供了额外的可解释性，且全部训练数据是免费获取的。
## 522. `cs.CV` - 基于结构化知识图谱的概念驱动机制可解释性 [PDF](https://arxiv.org/pdf/2507.05810), [HTML](https://arxiv.org/abs/2507.05810)
### Authors
Sofiia Chorna,Kateryna Tarelkina,Eloïse Berthier,Gianni Franchi
### Background
传统基于概念的可解释性方法主要关注神经网络预测的局部解释，而本文提出了一种新的框架和交互工具，将其扩展到机制可解释性的领域。这种新的方法可以通过分析高级语义属性（称为概念）的产生、交互和传播，对模型行为进行全局剖析。这种方法不同于以往孤立分析个别神经元或预测，它系统地量化了语义概念在各层中的表示，并揭示了这些概念背后的电路和信息流，从而帮助理解模型决策过程。平台强调了可视化的重要作用，并将其命名为BAGEL（偏见分析的图形全球解释层），通过结构化知识图谱来展示这些洞察，使用户能够探索概念类的关系，发现歧义关联，并增强模型的可信度。这种方法是模型无关的、可扩展的，有助于更深入地理解深度学习模型如何（或如何不）在数据集偏差存在的条件下进行泛化。
### Innovation
本文的主要创新在于提供了一种新型框架和交互工具，通过分析高级语义属性（称为概念）在各层中的表示和传播，系统地量化语义概念，并以结构化知识图谱的形式呈现这些洞察，使用户能够探索概念类的关系，发现歧义关联，并增强模型的可信度。这种方法与之前的工作不同，因为它专注于整体的模型行为分析，而不仅仅是单个神经元或预测。
### Conclusion
本文提出的方法是模型无关的、可扩展的，有助于深入理解深度学习模型在数据集偏差存在条件下的泛化能力。通过BAGEL平台，用户可以更好地理解和信任模型，从而提高模型的实际应用效果。该平台目前可在提供的链接中访问演示。
## 523. `cs.CV` - 细粒度视觉语言建模在增强现实多模态训练助手中的应用 [PDF](https://arxiv.org/pdf/2507.05515), [HTML](https://arxiv.org/abs/2507.05515)
### Authors
Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang
### Background
视觉语言模型（VLMs）对于使智能助手能够在多模态环境中进行解释和推理至关重要。然而，它们在增强现实（AR）培训中的应用仍旧未被充分探索。本文介绍了一个专门用于AR培训的全面数据集，包含系统化视觉语言任务，并在其中评估了九个最先进的VLMs。结果显示，即使是高级模型（例如GPT-4o），在细粒度组装任务中也遇到困难，状态检测的最高F1分数仅为40.54%。这些结果突显了改进细粒度视觉语言对齐所需更高质量数据集、基准测试和进一步研究的需求。
### Innovation
引入了一个专门用于AR培训的全面数据集，包含了系统化视觉语言任务，并评估了九个最先进的VLMs。明确了VLMs在细粒度装配任务中的挑战，这些发现强调了高质量数据集、基准测试和技术研究的必要性。
### Conclusion
除了技术贡献，这项工作的社会影响也很广泛，特别是为盲人和视力受损用户提供公平的AI驱动学习机会。所有相关资源都提供给研究社区，包括数据集、源代码和评估结果，以便支持进一步的研究。
## 524. `cs.CV` - 基于3D高斯散斑的大规模自主驾驶重定位3DGS_LSR [PDF](https://arxiv.org/pdf/2507.05661), [HTML](https://arxiv.org/abs/2507.05661)
### Authors
Haitao Lu,Haijier Chen,Haoze Liu,Shoujian Zhang,Bo Xu,Ziao Liu
### Background
在自主机器人系统中，精确的定位是安全导航的前提。然而，在复杂的城市环境中，GNSS定位经常受到信号被遮挡和多径效应的影响，导致绝对位置不可靠。传统的建图方法受限于存储需求和计算效率低的问题，这限制了它们在资源受限的机器人平台上的应用。因此，针对这些挑战，我们提出了一种名为3DGS-LSR的重定位框架，它利用3D高斯散斑(3DGS)技术，仅通过单一的单目RGB图像就能实现厘米级定位。该框架通过结合多传感器数据，于大型室外场景中构建高精度的3DGS地图，机器人侧的定位仅需要标准的相机输入。我们的核心创新在于迭代优化策略，通过逐步渲染来细化定位结果，使其适用于实时自主导航。实验验证在KITTI数据集上，3DGS-LSR分别在城市道路、人行道和交通密集的高速公路实现了平均定位精度分别为0.026m、0.029m和0.081m，显著优于其他代表性方法，同时仅需要单目RGB输入。这种方法即使在GNSS失效的复杂城市环境中也能为自主机器人提供可靠的定位能力。
### Innovation
我们提出了一种名为3DGS-LSR的重定位框架，它通过3D高斯散斑技术在大型室外场景中构建高精度的3DGS地图，仅通过单一的单目RGB图像就能实现厘米级定位。核心创新在于迭代优化策略，通过逐步渲染来细化定位结果，使其适用于实时自主导航。
### Conclusion
实验验证表明，基于3D高斯散斑的大规模自主驾驶重定位3DGS-LSR，在不同类型的场景中实现了高精度的定位，显著优于其他代表性方法，同时仅需要单目RGB输入，即使在复杂城市环境中GNSS失效的情况下也能为自主机器人提供可靠的定位能力。
## 525. `cs.CV` - ECORE：边缘设备上深度学习模型的节能优化路由 [PDF](https://arxiv.org/pdf/2507.06011), [HTML](https://arxiv.org/abs/2507.06011)
### Authors
Daghash K. Alqahtani,Maria A. Rodriguez,Muhammad Aamir Cheema,Hamid Rezatofighi,Adel N. Toosi
### Background
边缘计算使数据处理靠近数据源，显著减少了延迟，这对于实时视觉分析任务如监视和智慧城市中的目标检测至关重要。然而，这些任务所需的计算能力对边缘设备资源构成巨大挑战，因此需要同时优化能效和检测准确性。
### Innovation
提出了一种名为ECORE的框架，该框架结合了多种动态路由策略（包括基于估计的技术和贪婪选择算法），以将图像处理请求分配到最适合的边缘设备-模型配对。ECORE能够根据对象特性动态平衡能效和检测性能。
### Conclusion
通过在真实数据集上的广泛实验，将提出的路由策略与广泛使用的基准技术进行了比较。实验显示，虽然检测准确性略有下降，但ECORE能将能耗和延迟分别减少45%和49%，同时提供2%的检测准确性损失。
## 526. `cs.CV` - 一种用于近红外光谱调频血管超声及光学相干断层扫描成像数据全自动对齐的新框架 [PDF](https://arxiv.org/pdf/2507.05883), [HTML](https://arxiv.org/abs/2507.05883)
### Authors
Xingwei He,Kit Mills Bransby,Ahmet Emir Ulutas,Thamil Kumaran,Nathan Angelo Lecaros Yap,Gonul Zeren,Hesong Zeng,Yaojun Zhang,Andreas Baumbach,James Moon,Anthony Mathur,Jouke Dijkstra,Qianni Zhang,Lorenz Raber,Christos V Bourantas
### Background
本文旨在开发一种基于深度学习（DL）的框架，以实现对冠状动脉发病患者的近红外光谱血管超声（NIRS-IVUS）和光学相干断层扫描（OCT）图像的全自动化纵向和环向共注册。研究使用了230例患者（714支血管）的NIRS-IVUS和OCT图像数据，通过这些数据的纵向和环向共注册，来提升对冠状动脉病变的分析能力，特别是对斑块组成的表征。这些多模态成像数据的处理需要能够精确且自动化的共注册技术，使得数据能够进行有效分析和比较研究，特别是在大规模数据研究中更为重要。
### Innovation
创新之处在于开发了一种全新的基于DL的框架，能够实现对NIRS-IVUS和OCT图像的全自动化纵向和环向共注册。该框架利用专家标注的数据训练DL模型，模型能够高效地自动提取所需的影像特征，并通过动态时间规整算法和动态规划优化纵向和环向的共注册过程。实验结果显示，该方法在测试集上实现了与专家分析师高度一致的纵向和环向共注册结果，表明具有可比拟的性能，而处理单支血管数据所需的时间少于90秒，说明该方法在效率上也非常高。
### Conclusion
本文介绍了一种新的基于DL的全自动化NIRS-IVUS和OCT影像数据共注册框架，该方法速度快且共注册性能与专家相当，为研究中的大规模多模态图像数据收集分析提供了有用的工具。
## 527. `cs.CV` - TigAug: 为自动驾驶系统中交通灯检测测试的数据增强 [PDF](https://arxiv.org/pdf/2507.05932), [HTML](https://arxiv.org/abs/2507.05932)
### Authors
You Lu,Dingji Wang,Kaifeng Huang,Bihuan Chen,Xin Peng
### Background
近年来，随着传感器和计算技术的进步，自主车辆技术得到了发展。确保自动驾驶系统（ADSs）的可靠性和鲁棒性变得尤为迫切。尽管已经在测试各种ADS模块方面取得了显著成就，但在检测交通信号灯模型的自动化测试方面仍然关注不足。常见的做法是手动收集和标记交通信号灯数据，但这既耗时又难以收集在不同驾驶环境下的多样数据。为了应对这些问题，我们提出了并实现了TigAug，用于自动增强标记的交通信号灯图像，以测试交通信号灯检测模型，并根据特定的元形态关系进行变换。经过系统理解天气环境、摄像头特性和交通信号灯特性，我们构建了两大家族的元形态关系和三家族的变换，来检测交通信号灯检测模型的错误行为，并通过重新训练来改进性能。大规模实验表明，TigAug在测试交通信号灯检测模型、高效合成交通信号灯图像以及生成具有接受度的自然性交通信号灯图像方面均表现出有效性。
### Innovation
我们提出了TigAug，自动增强标记的交通信号灯图像以测试交通信号灯检测模型，构建了两大家族的元形态关系和三家族的变换，并通过特定的元形态关系进行变换，来检测交通信号灯检测模型的错误行为并改进模型性能。这种方法高效且生成的图像具有较高的自然性。
### Conclusion
TigAug在测试交通信号灯检测模型、高效合成交通信号灯图像以及生成具有接受度的自然性交通信号灯图像方面均表现出有效性，解决了手动收集和标记交通信号灯数据耗时且难以覆盖不同驾驶环境下的数据多样性的难题。
## 528. `cs.CV` - DreamGrasp: 零样本的多对象从部分视角图像进行3D重建用于机器人操作 [PDF](https://arxiv.org/pdf/2507.05627), [HTML](https://arxiv.org/abs/2507.05627)
### Authors
Young Hun Kim,Seungyeon Kim,Yonghyeon Lee,Frank Chongwoo Park
### Background
部分视角3D识别——从少量稀疏RGB图像重建3D几何形状并识别物体实例是一项极其具有挑战性但实践上又非常必要的任务，特别是在拥挤或遮挡的真实环境中，通常缺乏全面视角或可靠的深度数据。现有的方法，无论是基于强大的对称先验还是监督学习，都无法在这些场景中泛化。
### Innovation
提出了DreamGrasp框架，这是一种利用大规模预训练图像生成模型的想象能力来推断场景中未观察到的部分的方法。通过结合粗略的3D重建、通过对比学习进行实例分割以及基于文本的逐实例精炼，DreamGrasp规避了先前方法的局限，能够在复杂多对象环境中实现稳健的3D重建。
### Conclusion
我们的实验表明，DreamGrasp不仅恢复了准确的物体几何结构，还支持诸如序列去杂物和目标检索之类的下游任务，成功率高。
## 529. `cs.CV` - Feed-Forward SceneDINO for Unsupervised Semantic Scene Completion [PDF](https://arxiv.org/pdf/2507.06230), [HTML](https://arxiv.org/abs/2507.06230)
### Authors
Aleksandar Jevtić,Christoph Reich,Felix Wimbauer,Oliver Hahn,Christian Rupprecht,Stefan Roth,Daniel Cremers
### Background
语义场景完成(SSC)的目标是从单张图像中推断场景的三维几何结构和语义信息。以往的SSC研究依赖于昂贵的地面真值标注，而本文提出了一种新的无监督场景完成方法，即SceneDINO（场景中的DINO），该方法将自我监督表示学习和2D无监督场景理解技术应用于三维场景理解。
### Innovation
SceneDINO采用了一种新颖的三维特征精练方法，仅通过多视图一致性自我监督进行训练，不需要任何语义或几何的地面真值标注。SceneDINO能够从单张输入图像中以前馈的方式推断出三维几何结构和表达性三维DINO特征。在无监督三维和二维场景理解中，SceneDINO达到了最先进分割准确性。这表明通过自监督特征的线性探针可以匹队伍当前的监督式SSC方法的分割准确性。
### Conclusion
此外，我们展示了SceneDINO的领域泛化能力和多视图一致性，这为单张图像三维场景理解奠定了坚实的基础。
## 530. `cs.CV` - LighthouseGS：基于全景风格移动拍摄的室内结构感知3D高斯点绘制 [PDF](https://arxiv.org/pdf/2507.06109), [HTML](https://arxiv.org/abs/2507.06109)
### Authors
Seungoh Han,Jaehoon Jang,Hyunsu Kim,Jaeheung Surh,Junhyung Kwak,Hyowon Ha,Kyungdon Joo
### Background
近年来，3D高斯点绘制（3DGS）技术的发展使得能够在室内场景中实现高质量的实时新颖视角合成（NVS）。然而，要实现高保真渲染，需要对整个场景进行精确捕捉的连续图像，这限制了普通用户的使用。虽然通过手持设备（如移动设备）进行便捷的全景式移动拍摄可以尝试，但由于这种以旋转为主的动作和狭窄的拍摄基线，使得精确的摄像头姿态及3D点估计变得困难，尤其是在缺乏纹理的室内环境中。为此，本文提出了一种名为LighthouseGS的新框架，它借鉴了全景图类似于灯塔式的扫视动作。该框架利用移动设备的摄像头姿态和单目深度估计等粗略的几何先验，以及室内环境中的平面结构，并提出了一种新的初始化方法——平面框架组装，以生成一致的3D点，随后采用稳定修剪策略提高几何和优化稳定性。此外，LighthouseGS还引入了几何和光度上的校正方法，用于解决移动设备中由于移动漂移和自动曝光导致的不一致性问题，以保证渲染的真实感和准确性。
### Innovation
该研究提出了一种基于移动拍摄的室内结构感知3D高斯点绘制框架LighthouseGS，解决了手持设备拍摄过程中姿态估计和3D点估计的挑战。该框架利用了移动设备的摄像头姿态、单目深度估计和室内常见的平面结构，采用新的初始化方法和稳定修剪策略，同时引入几何和光度校正，提高了渲染的真实性和稳定性。
### Conclusion
LighthouseGS通过实际测试与合成场景展示了其在真实场景中对成像质量和稳定性的提高，超过了现有最先进的方法，并展示了全景视图合成和物体放置的巨大潜力。
## 531. `cs.CV` - UVOSAM: 通过段一切换模型（SAM）的无掩码范式用于无监督视频对象分割 [PDF](https://arxiv.org/pdf/2305.12659), [HTML](https://arxiv.org/abs/2305.12659)
### Authors
Zhenghao Zhang,Shengfan Zhang,Zhichao Wei,Zuozhuo Dai,Siyu Zhu
### Background
当前最先进的无监督视频对象分割（UVOS）方法需要大量标记有掩码的视频数据集进行训练，这限制了它们在处理挑战性场景时的有效性。
### Innovation
提出了利用Segment Anything Model（SAM）的UVOSAM模型，这是一种无掩码范式，通过不同的提示策略进行UVOS。UVOSAM通过引入STD-Net跟踪器，利用空间-时间解耦的可变形注意力机制来建立帧内和帧间特征的有效关联，显著提高了复杂视频场景中框提示的质量。该研究展示了UVOSAM在DAVIS2017-unsupervised和YoutubeVIS19&21数据集上优于现有监督方法的性能，并且能够在弱监督视频数据集上进行泛化。
### Conclusion
UVOSAM在无监督视频对象分割中表现出优越的性能，并且能够在缺乏掩码监督的情况下有效处理复杂的视频场景，还能够泛化到弱标注视频数据集。
## 532. `cs.CV` - NeoBabel: 多语言开放塔结构对视觉生成 [PDF](https://arxiv.org/pdf/2507.06137), [HTML](https://arxiv.org/abs/2507.06137)
### Authors
Mohammad Mahdi Derakhshani,Dheeraj Varghese,Marzieh Fadaee,Cees G. M. Snoek
### Background
文本到图像生成技术目前主要以英语为中心，这为非英语使用者带来了障碍，加剧了数字不平等。现有系统依赖翻译管道，但引入了语义偏移、计算开销和文化不一致的问题。为了克服这些问题，研究者引入了NeoBabel，一种新型多语言图像生成框架，在性能、效率和包容性方面达到了新的帕累托前沿，支持英语、中文、荷兰语、法语、印地语和波斯语六种语言。NeoBabel 通过大规模多语言预训练和高分辨率指令调优进行训练，以评估其效果，扩展了两个仅限英文基准测试到多语言版本：m-GenEval 和 m-DPG。
### Innovation
NeoBabel 采用了一种新颖的方法，通过多语言预训练和高分辨率指令调优进行训练，与现有依赖翻译管道的方法相比，其在多语言和英语任务上的性能有了显著提升，同时模型大小更小。作者还引入了两个新的评估指标，用于严格评估多语言对齐和混合代码提示的稳健性。NeoBabel 的效果超过了现有基于多语言大语言模型的先进模型，显示出针对齐的语言训练的有效性。
### Conclusion
我们的工作表明，多语言能力不是一种妥协，而是生成人工智能的催化剂，能够提高鲁棒性、效率和文化忠实度。我们开放了一个包括代码、模型检查点、12400万个多语言文本-图像对以及标准多语言评估协议的研究工具包。这将促进包容性人工智能研究的发展。
## 533. `cs.CV` - Skywork-R1V3 技术报告 [PDF](https://arxiv.org/pdf/2507.06167), [HTML](https://arxiv.org/abs/2507.06167)
### Authors
Wei Shen,Jiangbo Pei,Yi Peng,Xuchen Song,Yang Liu,Jian Peng,Haofeng Sun,Yunzhuo Hao,Peiyu Wang,Yahui Zhou
### Background
本文介绍了Skywork-R1V3，这是一种先进的开源视觉-语言模型（VLM），它率先提出了一种新的视觉推理方法。Skywork-R1V3的主要创新之处在于有效地将仅限于文本的大语言模型（LLMs）的推理技能转移到视觉任务，这使得模型在无需额外持续预训练的情况下，通过详细的后训练强化学习（RL）框架有效激活和增强其推理能力。这一框架还进一步揭示了连接模块在实现稳健的跨模态对齐方面的关键作用。此外，该论文还引入了一个衡量推理能力的独特指标，即关键推理标记的信息熵，该指标已被证明在RL训练过程中的检查点选择中非常有效。
### Innovation
Skywork-R1V3在视觉推理中带来了诸多创新：1. 有效的将文本大语言模型的推理能力转移到视觉任务中，无需额外的持续预训练；2. 通过详细的后训练RL框架，显著提高模型的推理能力；3. 揭示了连接模块在跨模态对齐中的重要作用；4. 引入了关键推理标记的信息熵作为衡量推理能力的独特指标。这使380亿参数的模型能够与顶尖的闭源VLMs竞争，显著提高了在MMMU上的性能，从64.3%提高到76.0%，相当于入门级人类能力的表现。
### Conclusion
Skywork-R1V3代表了在多模态推理领域的一个重大进步，通过强化学习来推动开源VLM能力的发展。此外，研究还分析了强化学习训练策略和课程学习策略，并对多模态推理进行了更广泛的讨论。
## 534. `cs.CV` - LangMamba: 一种依赖语言的Mamba框架，用于结合视觉语言模型的低剂量CT去噪 [PDF](https://arxiv.org/pdf/2507.06140), [HTML](https://arxiv.org/abs/2507.06140)
### Authors
Zhihao Chen,Tao Chen,Chenhui Wang,Qi Gao,Huidong Xie,Chuang Niu,Ge Wang,Hongming Shan
### Background
低剂量CT（LDCT）虽然减少了辐射暴露，但往往会降低图像质量，影响诊断准确性。现有的基于深度学习的去噪方法主要关注像素级别的映射，忽视了高阶语义信息的潜在益处。近年来，视觉语言模型（VLM）的进步表明，语言可以作为一种捕捉结构语义信息的强大工具，提供了改进LDCT重建的新机会。
### Innovation
提出了依赖语言的Mamba框架（LangMamba），通过利用VLM提取的语义表示增强正常剂量CT（NDCT）的监督，采用了两阶段的学习策略：首先预训练一种依赖语言的自动编码器（LangAE），利用冻结的VLM将NDCT图像映射到一个富含解剖信息的语义空间；接着通过语义增强高效去噪器（SEED）和语言参与的双空间对齐损失（LangDA损失）两大组件来引导LDCT去噪，确保去噪后的图像在感知和语义空间与NDCT对齐。实验结果表明，LangMamba超越了传统的先进方法，显著提高了细节保持和视觉保真度。
### Conclusion
LangAE展示了强大的泛化能力，降低了训练成本。LangDA损失通过整合语言指导的见解提高了图像重建的可解释性，提供了即插即用的方式。这些发现为语言作为监督信号在LDCT去噪中的应用开辟了新的前景。
## 535. `cs.CV` - StreamDiffusion：一种针对实时交互生成的流水线级解决方案 [PDF](https://arxiv.org/pdf/2312.12491), [HTML](https://arxiv.org/abs/2312.12491)
### Authors
Akio Kodaira,Chenfeng Xu,Toshiki Hazama,Takanori Yoshimoto,Kohei Ohno,Shogo Mitsuhori,Soichi Sugano,Hanying Cho,Zhijian Liu,Masayoshi Tomizuka,Kurt Keutzer
### Background
现有的扩散模型擅长根据文本或图像提示生成图像，但在实时互动方面往往表现不佳。特别是在元宇宙、直播视频流和广播等持续输入场景中，高吞吐量是至关重要的。现有的扩散管道使用无条件指南（CFG）技术，这种技术增加了额外的U-Net计算量，导致了冗余计算。同时，高输入数据频率与低模型吞吐量之间的频率差异是存在的问题。
### Innovation
1. 提出了一种新的批量去噪方法，将原序列去噪转变为批量去噪，从而实现了无等待和交互的实时流处理。2. 设计了一个新型的输入输出队列，用于并行化流处理过程，以解决数据输入频率与模型吞吐量之间的频率差异问题。3. 提出了一种残差无条件指南（RCFG）算法，减少了负条件去噪步骤的数量，能够提高至2.05倍的速度。4. 引入了一种随机相似度滤波器（SSF），以优化能耗。
### Conclusion
StreamBatch相比传统的序列去噪方法，在不同去噪级别上实现了约1.5倍的加速。提出的RCFG比传统的CFG实现了最多2.05倍的加速。结合所提出的技术和现有成熟的加速工具，Image-to-Image生成在RTX4090上的帧率达到了91.07fps，提高了超过59.56倍的吞吐量。此外，所提出的StreamDiffusion还显著减少了能耗，相较于RTX3060减少了2.39倍，相对于RTX4090减少了1.99倍。
## 536. `cs.CV` - 基于TopCoW挑战的Willis环血管段分割基准研究：用于CTA和MRA的拓扑感知解剖学分割 [PDF](https://arxiv.org/pdf/2312.17670), [HTML](https://arxiv.org/abs/2312.17670)
### Authors
Kaiyuan Yang,Fabio Musio,Yihui Ma,Norman Juchler,Johannes C. Paetzold,Rami Al-Maskari,Luciano Höher,Hongwei Bran Li,Ibrahim Ethem Hamamci,Anjany Sekuboyina,Suprosanna Shit,Houjing Huang,Chinmay Prabhakar,Ezequiel de la Rosa,Bastian Wittmann,Diana Waldmannstetter,Florian Kofler,Fernando Navarro,Martin Menten,Ivan Ezhov,Daniel Rueckert,Iris N. Vos,Ynte M. Ruigrok,Birgitta K. Velthuis,Hugo J. Kuijf,Pengcheng Shi,Wei Liu,Ting Ma,Maximilian R. Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus Maier-Hein,Chengcheng Zhu,Huilin Zhao,Philippe Bijlenga,Julien Hämmerli,Catherine Wurster,Laura Westphal,Jeroen Bisschop,Elisa Colombo,Hakim Baazaoui,Hannah-Lea Handelsmann,Andrew Makmur,James Hallinan,Amrish Soundararajan,Bene Wiestler,Jan S. Kirschke,Roland Wiest,Emmanuel Montagnon,Laurent Letourneau-Guillon,Kwanseok Oh,Dahye Lee,Adam Hilbert,Orhun Utku Aydin,Dimitrios Rallios,Jana Rieger,Satoru Tanioka,Alexander Koch,Dietmar Frey,Abdul Qayyum,Moona Mazher,Steven Niederer,Nico Disch,Julius Holzschuh,Dominic LaBella,Francesco Galati,Daniele Falcetta,Maria A. Zuluaga,Chaolong Lin,Haoran Zhao,Zehan Zhang,Minghui Zhang,Xin You,Hanxiao Zhang,Guang-Zhong Yang,Yun Gu,Sinyoung Ra,Jongyun Hwang,Hyunjin Park,Junqiang Chen,Marek Wodzinski,Henning Müller,Nesrin Mansouri,Florent Autrusseau,Cansu Yalçin,Rachika E. Hamadache,Clara Lisazo,Joaquim Salvi,Adrià Casamitjana,Xavier Lladó,Uma Maria Lal-Trehan Estrada,Valeriia Abramova,Luca Giancardo,Arnau Oliver,Paula Casademunt,Adrian Galdran,Matteo Delucchi,Jialu Liu,Haibin Huang,Yue Cui
### Background
Willis环是连接大脑主要循环的重要动脉网络，其血管结构被认为会影响严重神经血管疾病的风险、严重程度和临床结果。然而，描述高度变异的Willis环解剖结构仍然是一个手动且耗时的专业任务。Willis环通常通过磁共振血管造影（MRA）和计算机断层血管造影（CTA）这两种非侵入性成像技术成像，但标注Willis环解剖结构的数据集，尤其是CTA数据集，非常有限。因此，该研究组织了TopCoW挑战，并发布了有注释的Willis环数据集，该数据集利用虚拟技术实现了体素级注释，并使用了200对来自同一患者的MRA和CTA进行注释。数据集公开后，吸引了来自六大洲250多名参赛者的全球提交，评估了来自五个中心的226个扫描的部分内部测试和外部测试集的表现。
### Innovation
该研究通过发布首个公开的完整的Willis环注释数据集来评估Willis环分割算法，该数据集利用了虚拟现实技术实现体素级别注释，并且使用了来自200名患者的MRA和CTA成对数据。这不仅是第一个使用CTA的技术性完整注释数据集，也是第一次利用MRA和CTA的大型数据集。TopCoW挑战吸引了全世界的参赛者，最好的算法在分割Willis环成分、检测关键Willis环成分和分类Willis环变体方面取得了突出的成绩。这些算法不仅在解剖学分割方面表现出色，还在胎儿型后动脉分类和动脉瘤定位方面展示了临床潜力。
### Conclusion
TopCoW展示了Willis环分割算法在多种临床应用中的实用性和多功能性，并具有可解释性。公开的数据集和表现最佳的算法已经发布，以促进进一步的方法发展和临床工具建设。
## 537. `cs.CV` - CLOVER: Context-aware Long-term Object Viewpoint- and Environment- Invariant Representation Learning [PDF](https://arxiv.org/pdf/2407.09718), [HTML](https://arxiv.org/abs/2407.09718)
### Authors
Dongmyeong Lee,Amanda Adkins,Joydeep Biswas
### Background
移动服务机器人可以从其环境的物体级别理解中受益，包括区分物体实例和重新识别之前见过的实例的能力。物体再识别在不同视角和光照或天气显著变化引起的外观差异场景中是一个挑战。现有的物体再识别工作要么集中在特定的类别，要么需要前景分割。此外，现有的方法和再识别数据集对户外场景和光照变化等挑战考虑不足。
### Innovation
作者提出了CODa Re-ID：一种在野外的物体再识别数据集，包含1,037,814个观测值，覆盖了8个类别下的557个物体，具有多样的光照条件和视角。此外，还提出了CLOVER，一种无需前景分割即可区分静态物体实例的表示学习方法。还引入了MapCLOVER，一种方法，可用于总结CLOVER描述符，并将其用于物体地图和将新观测结果与总结描述符匹配。
### Conclusion
实验结果表明，CLOVER在不同光照条件和视角变化下的静态物体再识别性能更优，可以泛化到未见过的实例和类别。
## 538. `cs.CV` - 使用消费级空-水快速扫描仪（AASS）和基于深度学习的超分辨率重建和检测网络进行河床垃圾监测 [PDF](https://arxiv.org/pdf/2408.03564), [HTML](https://arxiv.org/abs/2408.03564)
### Authors
Fan Zhao,Yongying Liu,Jiaqi Wang,Yijia Chen,Dianhan Xi,Xinlei Shao,Shigeru Tabeta,Katsunori Mizuno
### Background
水下垃圾广泛分布在湖泊、河流和海洋等水体环境中，严重干扰自然生态系统。当前用于检测水下垃圾的监测技术存在调查效率低、成本高和环境适应性差的局限性，因此需要一种高效且适合消费者的自动检测技术来解决这些问题。
### Innovation
本研究引入了一种结合超分辨率重建（SRR）和改进YOLOv8检测网络的空-水快速扫描仪（Aerial-Aquatic Speedy Scanner，AASS）。AASS提高了数据采集效率，能够捕捉高质量图像以准确识别水下垃圾。SRR通过减少运动模糊和提高图像分辨率来改善图像质量，从而提高检测任务的有效性。RCAN模型在重建图像上获得了最高的平均精度（mAP）为78.6%，并且在放大因子为4的SRR测试集中，mAP相较于传统的双立方像素化集有所提高。
### Conclusion
研究结果表明，提出的方法在检测水下垃圾方面效果显著。
## 539. `cs.CV` - AbdomenAtlas：用于高效迁移学习和开放算法基准的大规模、详细注释和多中心数据集 [PDF](https://arxiv.org/pdf/2407.16697), [HTML](https://arxiv.org/abs/2407.16697)
### Authors
Wenxuan Li,Chongyu Qu,Xiaoxi Chen,Pedro R. A. S. Bassi,Yijia Shi,Yuxiang Lai,Qian Yu,Huimin Xue,Yixiong Chen,Xiaorui Lin,Yutong Tang,Yining Cao,Haoqi Han,Zheyuan Zhang,Jiawei Liu,Tiezheng Zhang,Yujiu Ma,Jincheng Wang,Guang Zhang,Alan Yuille,Zongwei Zhou
### Background
研究人员利用计算机断层扫描(CT)数据集进行医学图像分析和人工智能模型训练。然而，现有的数据集在规模、代表性或注释详细度上存在不足。为此，作者汇集了来自112个不同地区的20,460个三维CT数据集，并由10名放射科专家运用AI辅助手段完成了约673,000个高质量的解剖结构掩模标注。该数据集的目的是减轻放射科专家的工作负担，进而应用于更广泛的临床场景，并提供一个大规模测试AI算法的有效基准。
### Innovation
该研究创新地提出了一个名为AbdomenAtlas的大型CT数据集，包含20,460个三维CT图像，覆盖了广泛的地理、人口和设施多样性。数据集通过两阶段注释方法制作：首先，放射科专家手动标注了5,246个CT图像中的22个解剖结构；接着，运用半自动方法对剩余的CT图像进行注释，通过人工智能预测后由专家修订。该数据集不仅将用于训练高级预训练模型以减轻专家的工作负担，还将为评估AI算法性能建立基准，并通过ISBI & MICCAI挑战赛促进AI方法的创新和性能测试。
### Conclusion
作者期望AbdomenAtlas能够成为未来大规模临床试验的重要基础设施，为医学成像领域的从业者提供新的研究机会。数据集、代码和模型已公开可用，旨在促进相关领域的开发和应用。
## 540. `cs.CV` - 使用超分辨率重建和改进的YOLOv8在无人机捕获图像中增强龟蟹检测 [PDF](https://arxiv.org/pdf/2408.03559), [HTML](https://arxiv.org/abs/2408.03559)
### Authors
Fan Zhao,Yijia Chen,Dianhan Xi,Yongying Liu,Jiaqi Wang,Shigeru Tabeta,Katsunori Mizuno
### Background
龟蟹在沿海生态系统中扮演着重要角色，通过种子传播、清理垃圾和改变土壤结构等作用。它们是衡量海洋环境健康状况的重要指标，能对气候变化和污染作出响应。传统的调查方法如样方取样费时费力且依赖环境，难以满足大范围和高效监测的需求。
### Innovation
本研究提出了一种创新的方法，结合无人机遥感技术、超分辨率重建（SRR）和CRAB-YOLO检测网络（基于YOLOv8s进行改进），来监测龟蟹。SRR技术通过解决图像中的运动模糊和低分辨率问题，显著提高了检测准确性。CRAB-YOLO网络集成了三个方面的优化，提高了检测精度、适应龟蟹特征并且增强了计算效率，实现了在主流检测模型中的领先性能。实验结果显示，相比于传统亚像素插值方法（如Bicubic），CRAB-YOLO在经过SRR处理的图像中达到了69.5%的平均精度，性能提升了40%。
### Conclusion
所提出的方法在监测龟蟹方面表现出有效性，提供了一种经济高效且自动化的广域龟蟹监测解决方案，有助于沿海底栖生物的保护。
## 541. `cs.CV` - ADPv2: 一种用于结直肠疾病潜在生物标志物发现的层次结构组织类型注释数据集 [PDF](https://arxiv.org/pdf/2507.05656), [HTML](https://arxiv.org/abs/2507.05656)
### Authors
Zhiyuan Yang,Kai Li,Sophia Ghamoshi Ramandi,Patricia Brassard,Hakim Khellaf,Vincent Quoc-Huy Trinh,Jennifer Zhang,Lina Chen,Corwyn Rowsell,Sonal Varma,Kostas Plataniotis,Mahdi S. Hosseini
### Background
计算机病理学（CoPath）利用组织病理学图像在临床病理学中提高了诊断精度和可重复性。然而，由于需要大量专业知识和高昂的注释成本，公开可用的数据集仍然稀缺，这些数据集在较低层次上注释了广泛的组织病理学组织类型（HTTs）层次结构。现有的数据集，如数字病理图册（ADP），虽然提供了多器官的概括性注释，但仍限制了对特定器官疾病的研究深度。基于这一基础，我们提出了ADPv2，一个专注于胃肠道组织病理学的新数据集。该数据集包含来自健康结肠活检切片的20,004张图像补丁，并根据32种层次结构的3级32种不同组织病理学组织类型（HTTs）层次结构进行注释。此外，我们还在ADPv2数据集上训练了一个多标签表示学习模型，并通过两阶段训练程序达到了在结肠组织病理学多标签分类中的平均平均精度（mAP）0.88。最后，我们通过分析不同结肠疾病影响的组织模型的预测行为，展示了该数据集可用于特定器官的深入研究，以发现潜在的生物标志物，揭示了统计模式，证实了结肠癌发展的两条病理通路。本数据集可在以下链接获取：部分1：this https URL，部分2：this https URL，部分3：this https URL
### Innovation
我们提出了ADPv2数据集，这是一个专注于胃肠道组织病理学的新数据集，包含了来自健康结肠活检切片的20,004张图像补丁，并根据32种层次结构的3级32种不同组织病理学组织类型（HTTs）层次结构进行了注释。我们还训练了一个多标签表示学习模型，并通过两阶段训练程序达到了在结肠组织病理学多标签分类中的平均平均精度（mAP）0.88。我们通过分析不同结肠疾病影响的组织模型的预测行为，展示了该数据集可用于特定器官的深入研究，以发现潜在的生物标志物，并揭示了结肠癌发展的两条病理通路。
### Conclusion
我们的数据集通过注释层次结构的胃肠道组织类型（HTTs）得到了更深入的研究的潜力，并展示了其在发现结肠疾病潜在生物标志物方面的应用潜力，从而证实了结肠癌发展的两条病理通路。
## 542. `cs.CV` - 低光视频增强通过空间-时间一致分解 [PDF](https://arxiv.org/pdf/2405.15660), [HTML](https://arxiv.org/abs/2405.15660)
### Authors
Xiaogang Xu,Kun Zhou,Tao Hu,Jiafei Wu,Ruixing Wang,Hao Peng,Bei Yu
### Background
低光视频增强（LLVE）旨在恢复受严重失真和噪声影响的动力学或静态场景。现有的LLVE方法在提升视频性能方面存在一定局限性。
### Innovation
提出了一种创新的视频分解策略，结合了视点无关和视点相关组件，利用动态跨帧对应关系增强视点无关项（主要捕捉固有外观），并通过对视点相关项施加场景级别连续性约束来增强视点相关项（主要描述阴影条件），从而实现一致且令人满意的分解结果。引入了具有跨帧交互机制的双重结构增强网络，通过同时监督各个帧，鼓励它们表现出匹配的分解特征，该机制可以无缝集成到编码器-解码器单帧网络中，额外参数成本较低。
### Conclusion
在广泛认可的LLVE基准测试中进行的大量实验显示，该框架始终优于现有方法，建立了新的SOTA性能。
## 543. `cs.CV` - 通过多模态融合和端到端配准增强基于CBCT的合成CT [PDF](https://arxiv.org/pdf/2507.06067), [HTML](https://arxiv.org/abs/2507.06067)
### Authors
Maximilian Tschuchnig,Lukas Lamminger,Philipp Steininger,Michael Gadermayr
### Background
锥形束计算机断层扫描（CBCT）因其快速的采集速度和较低的辐射剂量，在术中成像中广泛应用。然而，CBCT图像通常会受到伪影和较低的视觉质量影响，相较于传统的计算机断层扫描（CT）。合成CT（sCT）生成技术是一种有前景的解决方案，通过将CBCT数据转换到CT领域来提高图像质量。这项研究通过多模态学习增强sCT生成，结合术中CBCT数据和术前CT数据。为解决模态间的固有错位问题，研究引入了一个端到端学习的配准模块，以提高sCT质量。
### Innovation
通过引入端到端可学习的配准模块，研究增强了基于CBCT的多模态sCT生成方法。这种方法在合成的受控数据集和两个真实临床数据集上进行验证，结果显示，在79种评估设置中优于基线多模态方法，特别在CBCT质量低和术前CT有较大错位的情况下效果显著。
### Conclusion
研究展示了将配准集成到多模态sCT生成中的方法能有效提高sCT的质量，验证了该方法的稳健性和普遍适用性。
## 544. `cs.CV` - 利用多模态基础模型推进中风风险预测 [PDF](https://arxiv.org/pdf/2411.09822), [HTML](https://arxiv.org/abs/2411.09822)
### Authors
Camille Delgrange,Olga Demler,Samia Mora,Bjoern Menze,Ezequiel de la Rosa,Neda Davoudi
### Background
中风风险预测是一项复杂的挑战，可以通过整合多种临床可用数据模态来增强。本文的背景在于通过结合3D大脑成像、临床数据和图像衍生特征，提出了一种自监督的多模态框架，旨在在中风发作前提高中风风险预测能力。该框架利用大量未注释的临床数据集，捕捉图像和表格数据模态之间的互补和协同信息，从而在共享潜在空间中更好地对齐多模态数据表示。研究数据集包括UK生物银行的数据，该数据集包含结构大脑MRI和临床数据。
### Innovation
本文的创新在于提出了一种自监督的多模态框架，该框架结合对比学习框架中的对比语言图像预训练与图像-表格匹配模块，以更好地在共享潜在空间中对齐多模态数据表示。与先进的单模态和多模态方法进行对比，本文提出的模型在ROC-AUC指标上分别优于自监督表型（图像）方法2.6%（2.6%），在平衡准确度上分别提高3.3%（5.6%）。此外，与最佳多模态监督模型相比，平衡准确度提高了7.6%。通过解释性工具，该方法展示了表型和图像数据的更好整合，提供了更丰富的并且更一致的嵌入信息。梯度加权类别激活映射热图进一步揭示了与文献中大脑老化、中风风险和临床结果相关的激活大脑区域。
### Conclusion
该稳健的自监督多模态框架在中风风险预测方面超越了最先进的方法，并为今后整合多数据模态以推进临床预测建模的研究提供了坚实的基础。
## 545. `cs.CV` - Fair Domain Generalization: An Information-Theoretic View [PDF](https://arxiv.org/pdf/2507.05823), [HTML](https://arxiv.org/abs/2507.05823)
### Authors
Tangzheng Lian,Guanyu Hu,Dimitrios Kollias,Xinyu Yang,Oya Celiktutan
### Background
在机器学习中，领域泛化（DG）和算法公平性是两个关键挑战。现有大部分DG方法仅关注在未知目标领域内最小化预期风险，而不考虑算法公平性。相反，公平性方法通常不考虑领域偏移，导致在训练中实现的公平性无法在未知测试领域中得到泛化。
### Innovation
本文通过研究公平领域泛化（FairDG）问题，旨在最小化未知目标领域内预期风险和公平性违规情况。本文推导出多类分类任务中多组敏感属性的新颖互信息上界，提供从信息论视角出发的关键见解。根据这些见解，提出了一种名为PAFDG（帕雷托最优公平性用于领域泛化）的实际框架，通过帕累托优化来建模效用-公平性权衡。
### Conclusion
在实际的视觉和语言数据集上进行的实验表明，PAFDG相比现有方法在效用-公平性权衡方面取得了更好的表现。
## 546. `cs.CV` - Quantization without Tears [PDF](https://arxiv.org/pdf/2411.13918), [HTML](https://arxiv.org/abs/2411.13918)
### Authors
Minghao Fu,Hao Yu,Jie Shao,Junjie Zhou,Ke Zhu,Jianxin Wu
### Background
深度神经网络在各种任务中取得了显著的成功，但这对计算资源、GPU内存、带宽、存储和能量的需求也相应增加。网络量化作为一种标准的压缩和加速技术，通过将网络权重和激活量化为有限的整数集，减少了存储成本并有可能加速推理。然而，当前的量化方法往往复杂且敏感，需要大量的特定任务超参数，一个小小的配置错误可能会影响模型性能，从而限制了其在不同模型和任务中的通用性。因此，量化过程中的信息损失是一个关键问题，需要找到一种能够同时提高速度、准确性和通用性的方法来解决这一挑战。
### Innovation
本文提出了一种名为Quantization without Tears (QwT)的方法，可以同时实现量化速度、准确性、简单性和通用性。其核心在于在量化网络中引入一种轻量级的附加结构来缓解量化过程中的信息损失。这种结构仅包含少量的线性层，不仅保持了方法的简单性和高效性，还提供了一个闭合形式的解决方案，使得在不到2分钟内就能提高准确率。实验结果表明，QwT不仅简单有效，而且非常通用，为其设计提供新的见解。
### Conclusion
通过QwT，可以提供一个结合了简单性、准确性和适应性的网络量化解决方案，完全缓解了信息损失的问题，并且具有广泛的普适性。这种方法为新的量化范式的提出提供了重要启示。论文中的代码已在公共平台提供。
## 547. `cs.CV` - 通过光跳连接与频谱约束稳定并提升扩散变换器的效率 [PDF](https://arxiv.org/pdf/2411.17616), [HTML](https://arxiv.org/abs/2411.17616)
### Authors
Guanjie Chen,Xinyu Zhao,Yucheng Zhou,Xiaoye Qu,Tianlong Chen,Yu Cheng
### Background
扩散变换器（DiT）作为一种强大的图像和视频生成架构，已经展现出优越的品质和可扩展性。然而，其实际应用受到固有的动态特征不稳定性的限制，这会导致缓存推理过程中的误差放大。通过系统的分析，作者发现缺乏长距离特征保留机制是特征传播不稳定和扰动敏感性的根本原因。
### Innovation
作者提出了Skip-DiT，这是一种增强的包含长跳连接（LSCs）的图像和视频生成DiT变体，长跳连接是U-Nets的关键高效组件。通过理论频谱范数和可视化分析，展示了LSCs如何稳定特征动力学。Skip-DiT架构及其稳定化的动态特征允许一种高效静态缓存机制，该机制可以在不更新浅层组件的情况下重用深层特征。
### Conclusion
广泛的实验证明，Skip-DiT在图像和视频生成任务中实现了：（1）4.4倍的训练加速和更快的收敛速度，（2）1.5-2倍的推理加速，质量损失小且保持原始输出的高保真度，优于现有的DiT缓存方法，在各种定量指标中表现出色。研究结果显示，长跳连接是实现扩散变换器稳定性和效率的关键架构组件。
## 548. `cs.CV` - RandAR: Decoder-only Autoregressive Visual Generation in Random Orders [PDF](https://arxiv.org/pdf/2412.01827), [HTML](https://arxiv.org/abs/2412.01827)
### Authors
Ziqi Pang,Tianyuan Zhang,Fujun Luan,Yunze Man,Hao Tan,Kai Zhang,William T. Freeman,Yu-Xiong Wang
### Background
现有解码器仅基于自回归（AR）模型依赖于预定义的生成顺序生成图像。这种设计引入了固有的偏见，限制了解码器的生成能力。
### Innovation
RandAR 是一种解码器仅有的自回归（AR）模型，能够以任意顺序生成图像。通过在每个待预测的图像标记前插入一个“位置指令标记”，RandAR 允许随机顺序的生成。RandAR 在随机打乱标记序列上训练，并且在推理时采用并行解码和 KV 缓存，以提高效率，同时保持生成质量。RandAR 还支持零样本的修复、扩展和分辨率外推功能。
### Conclusion
RandAR 的设计激发了解码器仅有的自回归视觉生成模型的新方向，并且扩展了它们在各种场景中的应用。
## 549. `cs.CV` - 预训练可逆生成作为无监督视觉表示学习 [PDF](https://arxiv.org/pdf/2412.01787), [HTML](https://arxiv.org/abs/2412.01787)
### Authors
Rongkun Xue,Jinouwen Zhang,Yazhe Niu,Dazhong Shen,Bingqi Ma,Yu Liu,Jing Yang
### Background
最近基于分数匹配和流匹配的生成模型在生成任务中取得了显著进步，但在判别任务上的潜力尚未充分开发。之前的生成分类器方法未能充分利用这些模型的判别任务能力，因为它们的设计较为复杂。
### Innovation
提出了一种名为Pretrained Reversible Generation (PRG) 的方法，通过反转预训练连续生成模型的生成过程来提取无监督表示。PRG能够高效利用预训练生成模型的高度容量，作为鲁棒性和通用性的特征提取器，且下游任务中能够灵活选择特征层次结构。该方法在多个基准测试中取得了优于先前方法的表现，其中包括在64*64分辨率的ImageNet数据集上达到78%的top-1准确率。
### Conclusion
广泛的消融实验进一步验证了该方法的有效性，证明了PRG作为基于生成模型方法中的最先进技术，具有显著的优势。
## 550. `cs.CV` - 通过注意力和CLIP指导实现3D生成中的视点一致性 [PDF](https://arxiv.org/pdf/2412.02287), [HTML](https://arxiv.org/abs/2412.02287)
### Authors
Qing Zhang,Zehao Chen,Jinguang Tong,Jing Zhang,Jie Hong,Xuesong Li
### Background
尽管在文本到3D生成技术方面取得了近期进展，但现有的方法往往存在几何不一致的问题，即所谓的‘Janus问题’。这一问题的主要原因是扩散模型中的视点生成偏差，导致实际生成的视点与优化3D模型所需预期的视点之间存在显著差距。
### Innovation
本文提出了一种无调优的解决方法——注意力和CLIP指导（ACG）机制。ACG通过自适应控制注意力交叉图来增强目标视点，利用基于CLIP的视点-文本相似性筛选错谬的视点，并采用粗到细的优化策略和阶段化提示逐步优化3D生成。实验表明，该方法在不牺牲生成速度的情况下显著减少了Janus问题，使其成为现有文本到3D框架中的高效、即插即用组件。
### Conclusion
我们的方法在不降低生成速度的情况下显著减少了Janus问题，确立了ACG作为现有文本到3D框架中的高效、即插即用组件的作用。
## 551. `cs.CV` - Signal-SGN: 一种通过学习时频动态进行骨骼动作识别的脉冲图卷积网络 [PDF](https://arxiv.org/pdf/2408.01701), [HTML](https://arxiv.org/abs/2408.01701)
### Authors
Naichuan Zheng,Yuchen Du,Hailun Xia,Zeyu Liang
### Background
在多模态骨骼基动作识别中，图卷积网络（GCNs）是有效的模型，但由于依赖浮点运算，导致高能耗，限制了其在电池供电设备中的应用。虽然脉冲神经网络（SNNs）具有节能性，但在建模骨骼动力学方面存在不足，导致效果不佳。
### Innovation
提出了一种称为Signal-SGN（脉冲图卷积网络）的新方法，利用骨骼序列的时间维度作为脉冲的时间步长，将特征表示为多维离散随机信号，以获取时频域特征。通过结合1D脉冲图卷积（1D-SGC）模块和频率脉冲卷积（FSC）模块从脉冲形式表示的骨骼中提取特征。此外，还提出了多尺度小波变换特征融合（MWTF）模块，以提取动态脉冲特征并捕捉频率特定特性，提高分类性能。
### Conclusion
实验表明，Signal-SGN不仅超越了基于SNN的方法的准确性及计算效率，还在性能上接近GCN方法，同时显著降低了理论能耗。
## 552. `cs.CV` - ViGiL3D: 一种具有多样语言的3D视觉接地数据集 [PDF](https://arxiv.org/pdf/2501.01366), [HTML](https://arxiv.org/abs/2501.01366)
### Authors
Austin T. Wang,ZeMing Gong,Angel X. Chang
### Background
3D视觉接地（3DVG）涉及使用自然语言文本来定位3D场景中的实体。这种能力对于拥抱人工智能和场景检索应用非常有用，这些应用涉及使用自然语言描述来搜索对象或模式。尽管最近的工作集中在基于LLM（大型语言模型）扩展3DVG数据集的规模上，但这些数据集未能涵盖可以用英语指定的全部范围的提示。为了确保我们扩展和测试的提示集是有用且具有代表性的，作者提出了一种对3DVG提示进行语言分析的框架，并引入了3D视觉接地中多样化语言的诊断数据集（ViGiL3D），该数据集用于评估视觉接地方法对多样化的语言模式的表现。现有的开放词汇3DVG方法在理解及识别更具挑战性和分布外的提示方面还不够熟练，尚不足以满足实际应用需求。
### Innovation
提出了一种对3DVG提示进行语言分析的框架，并创建了Visual Grounding with Diverse Language in 3D (ViGiL3D)数据集，以评估视觉接地方法，该数据集针对的是多样化的语言模式，确保对实际应用具有高度的代表性和实用性
### Conclusion
现有的开放词汇3DVG方法在理解及识别更具挑战性和分布外的提示方面还做得不够。需要利用ViGiL3D数据集来测试和提高视觉接地方法在实际应用中的表现。
## 553. `cs.CV` - 通过大语言模型实现的贝叶斯优化控制图像编辑 [PDF](https://arxiv.org/pdf/2502.18116), [HTML](https://arxiv.org/abs/2502.18116)
### Authors
Chengkun Cai,Haoliang Liu,Xu Zhao,Zhongyu Jiang,Tianfang Zhang,Zongkai Wu,John Lee,Jenq-Neng Hwang,Lei Li
### Background
在快速发展的图像生成领域，精确控制生成内容并保持语义一致性仍然是显著的挑战，特别是在 grounding 技术和模型微调的需求方面。BayesGenie 通过集成大语言模型与贝叶斯优化，提供了一个免调优的方法，旨在解决这些挑战。该方法使用户能够通过自然语言描述来修改图像，同时保留原始图像的语义完整性。
### Innovation
BayesGenie 的创新点在于其适应性强、模型无关的设计，通过自适应的贝叶斯优化策略自动优化推理过程参数，实现了在各种大语言模型上高度精确的图像编辑，而不需要大量的预训练或微调。
### Conclusion
通过广泛的实验，BayesGenie 在编辑准确性和语义保留方面显著优于现有方法，验证了不同大语言模型（包括Claude3和GPT-4）下的性能。
## 554. `cs.CV` - 带有 Tweedie 的随机漫步：基于评分的扩散模型的统一视角 [PDF](https://arxiv.org/pdf/2411.18702), [HTML](https://arxiv.org/abs/2411.18702)
### Authors
Chicago Y. Park,Michael T. McCann,Cristina Garcia-Cardona,Brendt Wohlberg,Ulugbek S. Kamilov
### Background
扩散模型近年来已成为生成现实、合成信号(特别是自然图像)的强大工具，并在图像处理中的逆问题算法中占有重要地位。尽管这些算法本身通常很简单，但其背后的理论却非常复杂，已有多种复杂的理论证明存在文献中。因此，需要一个简洁且自成体系的理论解释，以便信号处理社区更好地理解这些模型。这种简洁性不仅便于理解和实现，还能够在条件采样方面提供帮助，而无需进行任何似然度近似。
### Innovation
提供了一种仅依赖于少量教材结果的简洁推导方法，适用于多种具有影响力的评分驱动的扩散模型。通过这种方法，开发者能够获得训练和生成采样采用扩散模型的一般算法模板。研究揭示了一些流行的扩散模型只是这些模板中的特定选择，并且还有替代的、更直接的算法选择可以产生相近的效果。这种方法还提供了在不需要任何似然度近似的情况下进行条件采样的额外优势。
### Conclusion
通过提供一个简洁且自成体系的理论解释，本文为信号处理社区提供了对评分驱动的扩散模型的理解。这种方法不仅简化了算法的设计和实现过程，还在条件采样方面具有显著优势，不需要任何似然度近似，且展示了不同算法选择的实际效果相当。
## 555. `cs.CV` - 无监督的ANN到SNN转换中的差分编码 [PDF](https://arxiv.org/pdf/2503.00301), [HTML](https://arxiv.org/abs/2503.00301)
### Authors
Zihan Huang,Wei Fang,Tong Bu,Peng Xue,Zecheng Hao,Wenxuan Liu,Yuanhong Tang,Zhaofei Yu,Tiejun Huang
### Background
由于其低能耗特性，脉冲神经网络(SNNs)表现出显著潜力。将人工神经网络(ANNs)转换为SNNs是实现高性能SNNs的有效途径，但是大多数转换方法依赖于比率编码，这会导致需要更多的脉冲和更长的时间步长，从而增加能耗和延迟。
### Innovation
本文提出了一种差分编码方法，该方法通过传输比率信息的变化而非直接传输比率来减少脉冲数量和能耗，适用于不同层的ANN到SNN转换。此外，还提出了一种阈值迭代方法，在将ReLU转换为脉冲神经元时优化阈值，基于激活分布进行调整。实验结果表明，所提出的差分编码显著提高了准确率并减少了能耗，特别是在与阈值迭代方法结合使用时，实现了最先进的性能。
### Conclusion
提出的差分编码方法和阈值迭代方法显著提高了ANN到SNN转换的精度和能效，并且已实现最先进的性能。相关源码可通过提供的链接获取。
## 556. `cs.CV` - 细粒度知识结构化与检索在视觉问答中的应用 [PDF](https://arxiv.org/pdf/2502.20964), [HTML](https://arxiv.org/abs/2502.20964)
### Authors
Zhengxuan Zhang,Yin Wu,Yuyu Luo,Nan Tang
### Background
视觉问答（VQA）旨在通过图像中的信息来回答自然语言问题。尽管最新的多模态大型语言模型（如GPT-4o）在VQA任务上表现出色，但在访问特定领域知识或最新信息方面仍然存在不足。为解决这一问题，借助外部知识库（KBs）的检索增强生成（RAG）方法，即KB-VQA，被提出作为一种有效方法。然而，传统的单模态检索技术将图像转化为文本描述，往往导致了重要视觉细节的丢失。为应对这些挑战，本研究进行了两项创新：首先，引入细粒度的知识单元，这些单元由结构化的多模态数据片段（例如文本片段、实体图片等）组成，强调的是对这些知识单元的系统结构和管理，确保结构化过程本身提升检索质量。其次，提出了一种细粒度检索与多模态大型语言模型相结合的知识单元检索增强生成框架（KU-RAG），不仅能确保相关知识的精确检索，还能通过知识修正链增强推理能力。实验结果表明，该方法在四个基准测试中持续优于现有KB-VQA方法，平均改进约3%，在最好情况下提升高达11%。
### Innovation
1. 引入细粒度的知识单元，其由结构化的多模态数据片段（例如文本片段、实体图片等）组成，强调的是对这些知识单元的系统结构和管理，以提升检索质量。2. 提出一种细粒度检索与多模态大型语言模型相结合的知识单元检索增强生成框架（KU-RAG），该框架不仅确保了相关知识的精确检索，还能通过知识修正链增强推理能力。
### Conclusion
实验结果显示，本方法在四个基准测试中持续优于现有KB-VQA方法，平均改进约3%，在最好情况下提升高达11%。
## 557. `cs.CV` - AnyAnomaly：使用大规模视觉语言模型的零样本可定制视频异常检测 [PDF](https://arxiv.org/pdf/2503.04504), [HTML](https://arxiv.org/abs/2503.04504)
### Authors
Sunghyun Ahn,Youngwan Jo,Kijung Lee,Sein Kwon,Inpyo Hong,Sanghyun Park
### Background
视频异常检测（VAD）在计算机视觉中的视频分析和监视方面至关重要。然而，现有的VAD模型依赖于学习到的正常模式，这使得它们难以应用于多样化的环境。用户必须为新环境重新训练模型或开发单独的AI模型，这需要机器学习专家知识、高性能硬件以及大量数据采集，从而限制了VAD的实际适用性。
### Innovation
本研究提出了可定制视频异常检测（C-VAD）技术和AnyAnomaly模型。C-VAD 考虑用户定义的文本作为异常事件，并检测视频中包含特定事件的帧。我们有效利用了上下文感知的视觉问答，而无需对大型视觉语言模型进行微调。为了验证模型的有效性，我们构建了C-VAD数据集并证明了AnyAnomaly的优越性。此外，我们的方法在VAD基准数据集上表现出竞争力，达到UBnormal数据集上的最先进成果，并且在所有数据集的一般化性能上超越其他方法。
### Conclusion
我们的方法在VAD基准数据集上表现出竞争力，达到UBnormal数据集上的最先进成果，并且在所有数据集的一般化性能上超越其他方法。相关代码已上线。
## 558. `cs.CV` - CFMW: 在恶劣天气条件下稳健物体检测的跨模态融合Mamba [PDF](https://arxiv.org/pdf/2404.16302), [HTML](https://arxiv.org/abs/2404.16302)
### Authors
Haoyuan Li,Qi Hu,Binjia Zhou,You Yao,Jiacheng Lin,Kailun Yang,Peng Chen
### Background
可见-红外图像对提供了互补的信息，增强了实际场景中物体检测应用的可靠性和鲁棒性。然而，大多数现有方法在复杂天气条件下的鲁棒性有限，这限制了它们的应用。同时，对模态融合中注意力机制的依赖引入了显著的计算复杂性和存储开销，尤其是在处理高分辨率图像时。
### Innovation
为了解决这些问题，我们提出了Cross-modality Fusion Mamba with Weather-removal (CFMW)，以增强在恶劣天气条件下的稳定性和成本效益。利用所提出的Perturbation-Adaptive Diffusion Model (PADM) 和 Cross-modality Fusion Mamba (CFM) 模块，CFMW 能够重建受恶劣天气影响的视觉特征，丰富图像细节的表示。与Transformer样式的融合（如CFT）相比，CFMW 的效率更高，速度快3倍。
### Conclusion
为了填补相关数据集的差距，我们构建了新的Severe Weather Visible-Infrared (SWVI) 数据集，涵盖了雨、雾霾和雪等多样恶劣天气场景。数据集包含64,281对可见-红外图像，为未来的研究提供了一个宝贵的资源。在公开数据集（例如M3FD和LLVIP）和新构建的SWVI数据集上的广泛实验证明，CFMW 达到了最先进的检测性能。相关数据集和源代码将在以下链接公开：[此链接](this https URL)。
## 559. `cs.CV` - 一种集成大型语言模型的层级协同多智能体框架用于入匝道并流控制 [PDF](https://arxiv.org/pdf/2503.08199), [HTML](https://arxiv.org/abs/2503.08199)
### Authors
Miao Zhang,Zhenlong Fang,Tianyi Wang,Qian Zhang,Shuai Lu,Junfeng Jiao,Tianyu Shi
### Background
传统的强化学习（RL）在复制人类行为、多智能体场景中的有效泛化以及克服内在可解释性方面存在局限。当需要深度环境理解、智能体协调和动态优化时，这些挑战变得更加复杂。虽然增强型大型语言模型（LLM）展示了在泛化和互操作性方面的潜力，但它们往往忽视了智能体间的必要协调。因此，本文提出了一种名为CCMA的层级协同多智能体框架，通过将RL用于个体交互、微调LLM用于区域协同、全球优化的奖励函数以及检索增强生成机制来动态优化复杂驾驶场景中的决策制定。现有的RL方法都无法在这方面取得同等效果。实验表明CCMA在微观和宏观层面均显著优于现有RL方法，特别是在复杂驾驶环境中。
### Innovation
提出了一种名为CCMA的层级协同多智能体框架，该框架整合了RL用于个体交互、微调LLM用于区域协同、奖励函数用于全局优化以及检索增强生成机制，用于动态优化复杂驾驶场景中的决策制定。CCMA通过利用RL、LLM和创新机制，实现了传统RL方法难以达到的多智能体协调和复杂环境下的决策优化。
### Conclusion
实验结果表明，CCMA在微观和宏观层面上均显著优于现有RL方法，特别是在复杂驾驶环境中。研究提出了一种能够有效处理多智能体协调、环境理解和动态优化的新框架，证明了CCMA在复杂驾驶控制任务上的优越性。
## 560. `cs.CV` - ReviveDiff：在恶劣天气条件下恢复图像的通用扩散模型 [PDF](https://arxiv.org/pdf/2409.18932), [HTML](https://arxiv.org/abs/2409.18932)
### Authors
Wenfeng Huang,Guoan Xu,Wenjing Jia,Stuart Perry,Guangwei Gao
### Background
在夜间、烟雾、雨天和水下等具有挑战性的环境中拍摄的图像经常遭受严重退化，导致视觉质量显著下降。有效地恢复这些退化图像对于后续的视觉任务至关重要。尽管现有的许多方法成功地结合了特定的任务先验知识，但这些定制解决方案的适用范围仅限于特定类型的退化。
### Innovation
本文提出了一种通用网络架构，称为“ReviveDiff”，它可以处理多种退化情况，并通过增强和恢复图像质量恢复图像。该方法基于这样一个观察：与运动引起的退化或电子问题导致的退化不同，恶劣条件下导致质量退化的主要是自然介质（如雾、水和低亮度），这些介质通常保留了物体的原始结构。ReviveDiff 利用最新的扩散模型，从宏观和微观层面同时解决决定图像质量的关键因素，如清晰度、失真、噪点水平、动态范围和色彩准确性。
### Conclusion
我们在涵盖五种退化条件（雨、水下、低光照、烟雾和夜间雾霭）的七个基准数据集上严格评估了ReviveDiff。实验结果表明，ReviveDiff 在定量和视觉上均优于最先进的方法。
## 561. `cs.CV` - UniCombine：使用扩散变换器的统一多条件组合 [PDF](https://arxiv.org/pdf/2503.09277), [HTML](https://arxiv.org/abs/2503.09277)
### Authors
Haoxuan Wang,Jinlong Peng,Qingdong He,Hao Yang,Ying Jin,Jiafu Wu,Xiaobin Hu,Yanjie Pan,Zhenye Gan,Mingmin Chi,Bo Peng,Yabiao Wang
### Background
随着图像生成中扩散模型的快速发展，对更强大和灵活的可控框架的需求日益增加。尽管现有方法可以在文本提示之外引导生成，但在有效组合多个条件输入的同时保持所有条件的一致性的问题仍未解决。
### Innovation
我们提出了UniCombine，一个基于DiT的多条件可控生成框架，能够处理任何类型的条件组合，包括但不限于文本提示、空间图和主体图像。我们引入了一个新颖的条件MMDiT注意力机制，并结合可训练的LoRA模块构建了训练自由版和训练导向版。我们还提出了一种新方法来构建SubjectSpatial200K数据集，这是第一个专为多条件生成任务设计的数据集，涵盖了主体驱动和空间对齐条件。
### Conclusion
在多条件生成方面的广泛实验结果表明，我们的方法具有出色的通用性和强大的能力，达到了最先进的性能。
## 562. `cs.CV` - 非各向同性高斯扩散在真实3D人体动作预测中的应用 [PDF](https://arxiv.org/pdf/2501.06035), [HTML](https://arxiv.org/abs/2501.06035)
### Authors
Cecilia Curreli,Dominik Muhle,Abhishek Saroha,Zhenzhang Ye,Riccardo Marin,Daniel Cremers
### Background
目前的人体动作预测方法虽然报告了高多样性和现实性，但在过去的观察中，这些方法往往会产生未检测到的肢体拉伸和抖动等视觉错觉。为了改进这一问题，本文提出了一种名为SkeletonDiffusion的隐式扩散模型，该模型在其架构和训练过程中嵌入了人体结构的显式诱导偏置。此外，本文还发现常用多样性的度量在某些情况下可能无意中偏爱产生序列内肢体长度不一致的模型。
### Innovation
引入了SkeletonDiffusion模型，这是一种内在扩散模型，能够在架构和训练过程中嵌入人体结构的显式偏置。使用了一种新的非各向同性高斯扩散形式，该形式与人体骨骼的自然运动学结构对齐。实验表明，与传统的各向同性替代方案相比，本文的方法在多个评估指标上表现出更高的性能，能够持续生成现实的动作预测，同时避免肢体扭曲等副作用。
### Conclusion
SkeletonDiffusion在现实世界的数据集上取得了新的基准记录，优于多种基准方法。此外，还指出了常用多样性指标的一个局限性，可能会偶然偏好在同一序列中产生不一致肢体长度的模型。
## 563. `cs.CV` - 利用生成先验在自由形轨迹上的驾驶视图合成 [PDF](https://arxiv.org/pdf/2412.01717), [HTML](https://arxiv.org/abs/2412.01717)
### Authors
Zeyu Yang,Zijie Pan,Yuankun Yang,Xiatian Zhu,Li Zhang
### Background
在现实的驾驶模拟中，沿着自由形轨迹驱动视图合成是至关重要的，这能实现闭环评价端到端的驾驶策略。现有的方法在沿已记录路径进行视图插值时表现出色，但难以将生成推向新的轨迹，因为用于驾驶视图的视角有限。
### Innovation
本文提出了DriveX，一种新颖的自由形驾驶视图合成框架，在优化过程中逐步将生成先验精简到3D高斯模型。DriveX 使用视频扩散模型来细化从训练中的高斯模型生成的降级新颖轨迹渲染结果，同时恢复的视频反过来成为优化3D高斯模型的额外监督。为确保生成内容的一致性和准确度，DriveX 使用逐代改进的新轨迹渲染生成伪真实标签，使得两个组件在优化过程中相互适应与强化，同时最小化干扰。
### Conclusion
通过紧密结合3D场景表示与生成先验，DriveX 实现了实时超出录制轨迹的高质量视图合成，从而开辟了自由形轨迹上灵活和真实的驾驶模拟的新可能性。
## 564. `cs.CV` - 环境监控：基于AI的火和烟雾分类、分割和检测分析 [PDF](https://arxiv.org/pdf/2503.14552), [HTML](https://arxiv.org/abs/2503.14552)
### Authors
Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Fatemeh Afghah,Connor Peter McGrath,Danish Bhatkar,Mithilesh Anil Biradar,Abolfazl Razi
### Background
火和烟现象对自然环境、生态系统、全球经济、人类生命和野生动物构成了重大威胁。近年来，人工智能（AI）和计算机视觉（CV）框架的迅速发展极大地推动了高效防火管理系统的发展。然而，这些系统需要大量的高质量火和烟数据来进行机器学习（ML）算法的训练和评估。尽管现有的火和烟数据集在训练、评估和测试先进的深度学习（DL）模型中起着至关重要的作用，但它们在过去的20年中尚未进行全面的综述。
### Innovation
本文提供了一项深入的综述，系统地分析和评估了过去20年收集的火和烟数据集。研究了每个数据集的特征，包括类型、大小、格式、采集方法和地理多样性。还总结了每个数据集的优势和劣势，并讨论了它们在防火管理研究与技术中的潜在应用。此外，使用多种最先进的算法（如ResNet-50、DeepLab-V3和YoloV8）进行了广泛的实验分析。
### Conclusion
该研究总结了火和烟数据集的特征，并讨论了这些数据集在提高防火管理研究和技术方面的作用。通过使用现代算法对不同数据集进行实验分析，突显了现有数据集的相对优势和应用潜力，为未来研究者提供了有价值的参考。
## 565. `cs.CV` - 在自视点视觉方面的挑战与趋势：一项综述 [PDF](https://arxiv.org/pdf/2503.15275), [HTML](https://arxiv.org/abs/2503.15275)
### Authors
Xiang Li,Heqian Qiu,Lanxiao Wang,Hanwen Zhang,Chenghao Qi,Linfeng Han,Huiyu Xiong,Hongliang Li
### Background
随着人工智能技术和可穿戴设备的迅速发展，自视点视觉理解已经成为一个新的、具有挑战性的研究方向，逐渐引起了学术界和工业界的广泛关注。自视点视觉通过穿戴在人身上的相机或传感器捕获视觉和多模态数据，提供了一种模拟人类视觉体验的独特视角。
### Innovation
本文提供了一个全面的自视点视觉理解研究概览，系统地分析了自视点场景的组成部分，并将任务归类为四大领域：主体理解、物体理解、环境理解和混合理解。对每个领域的子任务进行了详细探索。还总结了当前领域的主要挑战和趋势。并且，本文还概述了高质量的自视点视觉数据集，为未来的研究提供有价值的资源。通过总结最新的进展，本文展望了自视点视觉技术在增强现实、虚拟现实和智能体智能等领域中的广泛应用，并基于最新的研究进展提出了未来的研究方向。
### Conclusion
本文综合了最新的研究成果，预期自视点视觉技术在增强现实、虚拟现实和智能体智能等领域的广泛应用，并提出了基于最新进展的未来研究方向。
## 566. `cs.CV` - OMR-Diffusion:优化扩散模型中的多轮增强训练以提高意图理解 [PDF](https://arxiv.org/pdf/2503.17660), [HTML](https://arxiv.org/abs/2503.17660)
### Authors
Kun Li,Jianhui Wang,Miao Zhang,Xueqian Wang
### Background
生成性AI在文本驱动的图像生成方面取得了显著进展，但仍面临产生符合不断变化的用户偏好和意图输出的挑战，尤其是在多轮对话场景中。该研究背景描述了当前生成性AI在多轮对话场景中的不足之处，特别是在用户偏好和意图的持续一致性上存在问题。
### Innovation
研究提出了一种称为视觉共适应（VCA）框架，该框架结合了人类在环反馈，使用一个专门针对人类偏好进行训练的奖励模型。VCA框架通过LoRA应用多个奖励函数（如多样性和一致性反馈），对扩散模型进行细化，从而根据用户输入优化图像生成。此外，研究还构建了适合用户意图的多轮对话数据集，包含提示和图像配对。实验结果显示，该模型在人类评估中获胜508次，优于DALL-E 3（463次胜利）和其他模型。
### Conclusion
所提出的方法在图像一致性和用户意图对齐方面表现出明显改进，胜过现有最先进的基准模型。该方法还提高了对话效率，并在LPIPS和BLIP等指标上获得了优异成绩。
## 567. `cs.CV` - Filter Like You Test: 数据驱动的数据过滤用于CLIP预训练 [PDF](https://arxiv.org/pdf/2503.08805), [HTML](https://arxiv.org/abs/2503.08805)
### Authors
Mikey Shechter,Yair Carmon
### Background
本文介绍了FLYT算法，用于管理和过滤大规模的视觉-语言数据集，该算法能够评估每个数据样本作为预训练样本的价值。FLYT通过学习每个样本特征的重要性，以优化其对下游任务的影响。在此基础上，本文提出了M-FLYT方法，通过结合多种评分方法生成的特征值，训练算法以统一生成最终评分。FLYT还产生了一个训练样本的概率分布，使用了Soft Cap Sampling策略来防止预训练样本集中的样本比例倾斜。这些方法的目的是提高预训练模型的性能，特别是在零样本情况下的准确性。
### Innovation
FLYT算法通过训练学习到每个样本特征权重，以衡量其作为预训练样本的价值。M-FLYT方法则进一步整合了多种评分方法的信息，综合评估样本质量。使用Soft Cap Sampling策略来过滤预训练样本集，确保不同样本的平衡，使得模型在大规模视觉语言数据集上得到更好的泛化能力。这种方法提高了零样本情况下ImageNet上的性能。
### Conclusion
通过FLYT和M-FLYT方法，本文在DataComp基准测试中取得了40.1%的ImageNet零样本准确率，比之前所有结果提高了2%，比仅使用公开资源的方法提高了5.5%。这种方法还在38项DataComp评估任务的最终平均得分中达到了37.7%，优于之前的公开资源方法0.4%。
## 568. `cs.CV` - PVChat: 一次性学习的个性化视频对话 [PDF](https://arxiv.org/pdf/2503.17069), [HTML](https://arxiv.org/abs/2503.17069)
### Authors
Yufei Shi,Weilong Yan,Gang Xu,Yumeng Li,Yucheng Chen,Zhenxi Li,Fei Richard Yu,Ming Li,Si Yong Yeo
### Background
现有的视频大语言模型（ViLLMs）在通用视频理解方面表现良好，例如识别像说话和进食这样的活动，但在身份意识理解方面存在局限，例如“威尔逊正在进行 chemotherapy”或“汤姆正在与莎拉讨论”，这限制了它们在智能医疗和智能家居环境中的应用。现有的模型缺乏识别特定个体行为和身份的能力，特别是在医学场景中的对话理解和实时交互需求上表现不足。研究者们希望通过一种新的策略提高这些模型的个体识别能力和多模态理解能力，以满足工作场景中个性化需求和智能环境中的应用需求。
### Innovation
本文提出了PVChat框架，一种基于一次性学习的个性化视频大语言模型（ViLLM），能够在每个个体只看一个视频的情况下实现主题意识问题回答 (QA)。该模型通过混合头部（MoH）增强的视频大语言模型，并利用合成数据和渐进式图像到视频学习策略来优化模型。此外，PVChat引入了自动增强合成管道、ReLU路由MoH注意机制，以及平滑接近正则化和头部激活增强两个新的优化目标，以增强特定主题的学习。通过这种方式，PVChat实现了从静态属性到动态表示的逐步学习过程，使模型能够更好地理解和提取个性化的特征，即使是在仅从一个视频学习之后也能表现优越，优于现有的ViLLMs。据我们所知，这是第一个能够在单个视频中实现个体意识问题回答的个性化ViLLM。
### Conclusion
实验证明，PVChat在不同类型的视频数据集上表现出色，特别是在医学场景、电视剧、动画和现实生活片段中，其在单个视频学习后能够提供更个性化的特征理解，优于最新的ViLLMs。与现有的方法相比，PVChat通过引入特定的增强训练策略和创新的注意机制，显著提升了视频大语言模型的身份意识理解和交互性能。
## 569. `cs.CV` - FastVAR：通过缓存的令牌剪枝实现线性视觉自回归建模 [PDF](https://arxiv.org/pdf/2503.23367), [HTML](https://arxiv.org/abs/2503.23367)
### Authors
Hang Guo,Yawei Li,Taolin Zhang,Jiangshan Wang,Tao Dai,Shu-Tao Xia,Luca Benini
### Background
视觉自回归（VAR）建模因其在下一规模预测方面的优势而受到关注。然而，现有的VAR范式在每个尺度步骤中处理整个令牌映射，这会导致随着图像分辨率的提高，复杂度和运行时间急剧增加。现有方法的这一挑战亟待解决，以实现高效的分辨率缩放。研究发现，延迟主要来自大部分令牌已收敛的大尺度步骤。因此，需要一种缓存策略来减少转发的令牌数量，提高大规模应用的效率。
### Innovation
FastVAR是一种基于训练的加速方法，它通过剪枝关键令牌来进行特定尺度的建模，同时使用之前尺度步骤的缓存令牌来恢复剪枝的槽位。该方法显著减少了需要转发的令牌数量，并在保持性能损失极小的情况下提升了大规模应用的效率。此外，FastVAR还能实现零样本高分辨率图像生成，能够在单个NVIDIA 3090 GPU上以1.5秒生成一个2K分辨率的图像，占用15GB内存。
### Conclusion
实验结果表明，FastVAR能够将使用FlashAttention加速的VAR进一步加速2.7倍，性能下降不到1%。这种方法不仅提高了现有VAR模型的效率，还在高分辨率图像生成方面展示了强大的能力。
## 570. `cs.CV` - TDRI：交互式图像生成的两阶段对话细化和协同适应 [PDF](https://arxiv.org/pdf/2503.17669), [HTML](https://arxiv.org/abs/2503.17669)
### Authors
Yuheng Feng,Jianhui Wang,Kun Li,Sida Li,Tianyu Shi,Haoyue Han,Miao Zhang,Xueqian Wang
### Background
尽管文本到图像生成技术已经取得了显著的进步，但在处理模糊提示和输出与用户期望对齐方面仍存在挑战。
### Innovation
本文提出的框架，TDRI（两阶段对话细化和协同适应），通过迭代用户交互来增强图像生成。该框架包括两个阶段：初始生成阶段，基于用户提示创建基础图像；交互细化阶段，通过三个关键模块整合用户反馈。这些模块，包括对话到提示模块（D2P），反馈反思模块（FR），自适应优化模块（AO），分别确保用户反馈被有效转换为可操作的提示，评估生成输出与用户期望之间的差异并促进改进，以及通过平衡用户偏好和保持提示忠实度来精调生成过程。
### Conclusion
实验结果表明，TDRI比现有的方法表现更好，人类偏好数达到33.6%，而GPT-4增强为6.2%；CLIP和BLIP对齐分数最高（分别为0.338和0.336）。在迭代反馈任务中，用户满意度在8轮后提高到88%，6轮后呈递减趋势。此外，TDRI在时尚产品的创建过程中减少了迭代次数并提高了个性化程度。因此，TDRI在创意和工业领域的广泛应用具有强大的潜力，因为它简化了创意过程并提高了与用户偏好的对齐度。
## 571. `cs.CV` - GC-GAT：基于图目标条件与跨上下文注意力的多模态车辆轨迹预测 [PDF](https://arxiv.org/pdf/2504.11150), [HTML](https://arxiv.org/abs/2504.11150)
### Authors
Mahir Gulzar,Yar Muhammad,Naveed Muhammad
### Background
预测周围车辆未来的运动轨迹高度依赖于提供给运动预测模型的上下文信息。上下文信息可以是静态的（如车道、规范性元素等）或动态的（如交通参与者）。本文提出了一种基于车道图的运动预测模型，该模型首先预测图基的目标建议，然后通过跨上下文注意力机制融合这些目标建议，结合多种上下文元素。
### Innovation
该研究遵循经典的编码器-交互器-解码器架构，其中编码器使用轻量级门控循环单元编码场景上下文，交互器通过编码场景特征和图目标建议之间的跨上下文注意力，解码器利用聚合编码创建多模态轨迹，通过拉普拉斯混合概率网络实现。通过图基目标建议上的跨注意力机制，模型能够学习关注未来与目标相关的场景元素，从而提高轨迹预测的鲁棒性。
### Conclusion
该研究在nuScenes数据集上评估了其工作，取得了最先进的结果。
## 572. `cs.CV` - 热扩散模型——像素间注意机制 [PDF](https://arxiv.org/pdf/2504.19600), [HTML](https://arxiv.org/abs/2504.19600)
### Authors
Pengfei Zhang,Shouqing Jia
### Background
Denoising Diffusion Probabilistic Models (DDPM) 对图像进行整体处理，但由于相邻像素很可能属于同一个物体，因此这种处理方式可能会损失图像细节。本文基于此背景，提出了一种新的模型——Heat Diffusion Model (HDM)，通过在DDPM中引入像素间的注意力机制，进一步保留图像细节，生成更真实的图像.
### Innovation
HDM 在 DDPM 的基础上融合了像素间注意力机制。HDM 通过将二维热方程的离散形式整合到 DDPM 的扩散和生成公式中，在图像处理过程中能够计算相邻像素间的相互关系。实验结果表明，HDM 生成的样本质量高于其他模型，如 DDPM、一致性扩散模型(CDM)、隐空间扩散模型(LDM) 和向量量化生成对抗网络(VQGAN) .
### Conclusion
实验结果表明，HDM能够生成质量更高的样本图像，证明了在图像处理过程中引入像素间注意力机制的有效性。
## 573. `cs.CV` - MaSS13K:一门抠像级别的语义分割基准 [PDF](https://arxiv.org/pdf/2503.18364), [HTML](https://arxiv.org/abs/2503.18364)
### Authors
Chenxi Xie,Minghan Li,Hui Zeng,Jun Luo,Lei Zhang
### Background
高分辨率语义分割对于图像编辑、光源模拟、AR/VR等应用非常重要。现有数据集分辨率有限，缺乏精确的掩膜细节和边界。在本研究中，为了解决这一问题，作者构建了一个大规模的、具有抠像级别的语义分割数据集MaSS13K，包含了13,348张4K分辨率的真实世界图像，覆盖了七个类别：人、植被、地面、天空、水、建筑和其他。MaSS13K提供了高质量的掩膜标注，掩膜复杂度是现有数据集的20-50倍，目标是实现高分辨率的掩膜标注，同时降低计算成本。
### Innovation
作者提出了一种专门针对高分辨率语义分割的方法MaSSFormer，它使用高效像素解码器，该解码器能在三个阶段聚合高级语义特征和低级纹理特征，以产生高分辨率的掩膜。另外，作者提出了一种新的学习范式，将七个给定类别的高质量掩膜与新类别的伪标签结合，使MaSSFormer能够将精确的分割能力转移到其他类别的对象上。
### Conclusion
作者对MaSS13K基准测试和14个代表性分割模型进行了全面评估。希望该精心标注的MaSS13K数据集和MaSSFormer模型能促进高分辨率和高质量语义分割的研究。相关数据集和代码可在该链接this https URL找到。
## 574. `cs.CV` - 使用解剖相似性作为评估大脑生成模型的新指标 [PDF](https://arxiv.org/pdf/2504.21771), [HTML](https://arxiv.org/abs/2504.21771)
### Authors
Bahram Jafrasteh,Wei Peng,Cheng Wan,Yimin Luo,Ehsan Adeli,Qingyu Zhao
### Background
生成模型通过数据增强、质量提升和罕见病研究增强神经影像学。尽管在生成拟真MRI方面取得了进展，但现有的评估主要集中在纹理和感知上，缺乏对解剖部位真实性的敏感度。本文利用SynthSeg进行脑区分割，通过 Wasserstein 距离衡量实际与合成MRI解剖结构之间的差异，提出了一种新的评估标准WASABI（Wasserstein-Based Anatomical Brain Index）
### Innovation
本文提出了WASABI（Wasserstein-Based Anatomical Brain Index）作为评估合成大脑MRI解剖真实性的新指标。WASABI使用SynthSeg进行脑区分割，利用多变量 Wasserstein 距离比较实际和合成的解剖结构之间的差异。与传统的图像级别指标相比，WASABI在量化解剖差异方面更具敏感性，即使合成图像在视觉质量上几乎完美。
### Conclusion
本文强调了转向视觉检查和传统指标以外的评估范式，强调解剖保真度作为医学上有意义的脑MRI合成的关键基准。
## 575. `cs.CV` - 使用膨胀卷积和注意力辅助空间聚合增强卫星目标 localization [PDF](https://arxiv.org/pdf/2505.05599), [HTML](https://arxiv.org/abs/2505.05599)
### Authors
Seraj Al Mahmud Mostafa,Chenxi Wang,Jia Yue,Yuta Hozumi,Jianwu Wang
### Background
卫星图像中的目标定位具有挑战性，由于目标的高度变异性、低空间分辨率、噪声以及由于云和城市灯光等主导特征的干扰。研究中重点关注三种卫星数据集：上大气重力波（GW）、中间层波（Bore）和海洋涡旋（OE），每个数据集都带来了独特挑战，主要体现在目标模式在尺度和外观上的变化，兴趣目标的大小、形状和特征范围差异显著。这些问题促使我们提出了YOLO-DCAP，这是YOLOv5的增强版本，专门提高复杂场景中的目标定位效果。
### Innovation
YOLO-DCAP 引入了多尺度膨胀残差卷积（MDRC）块，用于捕捉具有不同膨胀率的多尺度特征。同时，其注意力辅助的空间聚合（AaSP）模块集中在全局相关空间区域，增强特征选择。这些结构上的改进有助于在卫星图像中更好地定位目标。实验结果表明，YOLO-DCAP 在 mAP50 和 IoU 上相较于基础模型分别提高了 20.95% 和 32.23%，相对于最先进的方法分别提高了 7.35% 和 9.84%，并且在三种卫星数据集中展示了稳健性和泛用性。
### Conclusion
YOLO-DCAP 在三种卫星数据集中的表现一致优于现有方法，显示了该方法的有效性和泛化能力。
## 576. `cs.CV` - CURVE: 使用CLIP的强化学习在简单图像处理中的视觉图像增强 [PDF](https://arxiv.org/pdf/2505.23102), [HTML](https://arxiv.org/abs/2505.23102)
### Authors
Yuka Ogino,Takahiro Toizumi,Atsushi Ito
### Background
低光图像增强（LLIE）对于提高人类感知和计算机视觉任务至关重要。本研究聚焦于没有参考图像的零参考LLIE中的两个挑战：使用对比语言-图像预训练（CLIP）模型获得感知上“好”的图像，以及保持高分辨率图像的计算效率。
### Innovation
本研究提出了CLIP-Utilized Reinforcement learning-based Visual image Enhancement（CURVE）。CURVE使用一个简单的图像处理模块，基于贝塞尔曲线调整全局图像色调，并通过迭代估计其处理参数。估计器通过强化学习训练，奖励由CLIP文本嵌入设计。实验表明，CURVE在增强质量和处理速度方面优于传统方法。
### Conclusion
实验结果展示了CURVE在低光和多曝光数据集中的表现，证明了它在增强质量和处理速度方面的优势。
## 577. `cs.CV` - MARS：在稀疏信道测量下的无线地图超分辨率及重建方法 [PDF](https://arxiv.org/pdf/2506.04682), [HTML](https://arxiv.org/abs/2506.04682)
### Authors
Chuyun Deng,Na Liu,Wei Xie,Lianming Xu,Li Wang
### Background
无线地图反映了信号强度的空间分布，并在智能城市、物联网和无线网络规划等应用中至关重要。然而，从稀疏测量中重构准确的无线地图仍然是一项挑战。传统的插值和修复方法缺乏环境意识，而许多基于深度学习的方法则需要详细的场景数据，从而限制了其泛化能力。
### Innovation
我们提出了一种结合CNN和Transformer的多尺度感知无线地图超分辨率方法(MARS)，该方法采用了多尺度特征融合和残差连接。MARS 在注重全局和局部特征提取的同时，增强了不同感受野下的特征表示，提高了重建精度。实验结果显示，MARS 在 MSE 和 SSIM 上都优于基线模型，同时保持了较低的计算成本，展现出强大的实用潜力。
### Conclusion
MARS 在不同场景和天线位置下的实验表明，它在精度和计算效率上均优于现有方法，展示了在稀疏信道测量下的有效性和实用性。
## 578. `cs.CV` - 使用外科数据挑战视觉语言模型：一个新数据集和广泛基准测试研究 [PDF](https://arxiv.org/pdf/2506.06232), [HTML](https://arxiv.org/abs/2506.06232)
### Authors
Leon Mayer,Tim Rädsch,Dominik Michael,Lucas Luttner,Amine Yamlahi,Evangelia Christodoulou,Patrick Godau,Marcel Knopp,Annika Reinke,Fiona Kolbinger,Lena Maier-Hein
### Background
传统的计算机视觉模型在内镜领域的通用性较差，而基础模型展示了跨领域的潜在性能。本文首次进行大规模研究，评估视觉语言模型（VLMs）在内镜任务中，特别是腹腔镜手术中的能力，并着重于解决三个关键问题：（1）当前的VLMs能否解决外科图像的基本感知任务？（2）它们能否处理基于帧的内镜场景理解任务？（3）专业医疗VLMs和通用模型在这方面的表现有何差异？
### Innovation
首次在大规模研究中评估视觉语言模型在内镜任务中的应用，特别是针对腹腔镜手术。利用多样化的先进模型、多个外科数据集和广泛的参考注释进行评估，揭示了VLMs在基本任务上的表现和在需要医学知识的任务上的表现差异。
### Conclusion
研究结果表明，VLMs在简单感知任务上表现良好，但在需要医学知识的任务上性能下降。专业医疗VLMs在基本和高级外科任务上的表现逊于通用模型，表明其尚未针对外科环境的复杂性进行优化。这些发现强调了对进一步促进VLMs处理外科手术独特挑战的需求，并为开发下一代内镜AI系统提供了重要见解，同时指出了医学视觉语言模型的关键改进领域。
## 579. `cs.CV` - 通过连续CRF去噪增强最近邻图视觉重排 [PDF](https://arxiv.org/pdf/2412.13875), [HTML](https://arxiv.org/abs/2412.13875)
### Authors
Jaeyoon Kim,Yoonki Cho,Taeyoung Kim,Sung-Eui Yoon
### Background
基于最近邻（NN）图的视觉重排已成为提高检索准确性的强大方法，因为它不需要额外的微调即可有效探索高维流形。然而，基于NN图的重排效果受到其边连接质量的限制，不相似（负样本）图像之间的错误连接会削弱现有技术的重排性能。
### Innovation
提出了一种基于连续条件随机场（C-CRF）的互补去噪方法，利用基于相似性的距离统计量来构建每个锚点图像周围的完全连接团块。该方法通过使用新的统计距离度量在重排前稳健地缓解噪声边，从而在保证高效处理的同时增强基于NN图的检索。
### Conclusion
大量实验结果表明，该方法能够一致地改进三种不同基于NN图的重排方法，并显著提升检索准确性。
## 580. `cs.CV` - UniCode$^2$: 分层大规模代码本促进统一多模态理解和生成 [PDF](https://arxiv.org/pdf/2506.20214), [HTML](https://arxiv.org/abs/2506.20214)
### Authors
Yanzhe Chen(Yen-chieh Chan),Huasong Zhong,Yan Li,Zhenheng Yang
### Background
统一多模态大型语言模型（MLLMs）在共同促进多模态理解和生成方面显示出潜力，视觉代码本将图像离散化为标记，以实现自回归建模。现有的基代码本方法要么依赖于小词汇量（约16K个条目），这些词汇量缺乏精细的语义，要么简单地扩大词汇量，导致标记利用率低和训练不稳定。
### Innovation
我们提出了UniCode$^2$，一种分层代码本框架，能够实现大规模、语义对齐和稳定的视觉标记化。通过聚类数百万SigLIP序列嵌入，制作了一个拥有500K个条目的代码本，同时保持视觉-语言对齐并扩展容量。通过分层设计保证稳定性：一个冻结的代码本固定嵌入空间，一个可训练的代码本细化特定任务语义。这种解耦促进高利用率和鲁棒学习。此外，我们的视觉标记与文本语义对齐使得与预训练扩散解码器无缝整合，支持高质量的视觉合成，几乎不需要适应。
### Conclusion
UniCode$^2$在各种基准测试中表现出色，证明了在不牺牲稳定性和语义性的情况下扩大视觉标记空间的可行性，同时保持模块化。
## 581. `cs.CV` - IPFormer-VideoLLM: 提升多模态视频理解以应对多拍场景 [PDF](https://arxiv.org/pdf/2506.21116), [HTML](https://arxiv.org/abs/2506.21116)
### Authors
Yujia Liang,Jile Jiao,Xuetao Feng,Zixuan Ye,Yuan Wang,Zhicheng Wang
### Background
视频大型语言模型 (VideoLLMs) 展现出显著的理解能力，但在处理多拍场景时却遇到困难。例如，包含不同摄像角度或场景变化的视频片段。这种挑战可能导致实例身份遗忘、关键帧忽略等问题。现有的数据集缺乏多拍标注，训练集对于提升多拍表现的贡献显著，测试基准则提供了模型在多拍场景表现的可靠衡量标准。当前模型仅以离散或有损方式编码实例特征，可能导致身份信息的缺失。
### Innovation
贡献了一个名为 MultiClip-Bench 的新数据集，它是为多拍场景设计，配有详细的描述和基于指令的问答对。IPFormer-VideoLLM 模型通过高效的基于注意力的连接器将实例级特征作为实例提示注入，使得可以在场景间聚合实例特定的信息。该研究的创新点在于通过引入新数据集和模型来显著提升多场景视频理解，并在各种视频基准上提供独特的优势。
### Conclusion
通过引入 MultiClip-Bench 数据集和 IPFormer-VideoLLM 模型，该研究不仅显著提升了多场景视频理解，还展示了在各种视频基准上的独特优势。
## 582. `cs.CV` - 手术视频中无监督对象发现的未来槽预测 [PDF](https://arxiv.org/pdf/2507.01882), [HTML](https://arxiv.org/abs/2507.01882)
### Authors
Guiqiu Liao,Matjaz Jogan,Marcel Hussing,Edward Zhang,Eric Eaton,Daniel A. Hashimoto
### Background
对象中心的槽注意力是一种用于无监督学习具有结构和可解释性对象中心表示的新颖范式。这使得以较低的计算成本进行有效的对象和事件推理变得可能，因此适用于如实时解释手术视频等关键的医疗保健应用。然而，现实世界的应用如手术中的异构场景难以分解成有意义的槽集合。现有的具有自适应槽数目的方法在图像上的表现良好，但在处理手术视频时表现较差。
### Innovation
本文提出了一种动态时序槽变换器（DTST）模块，该模块既为时序推理训练，又能预测最合适的未来槽初始值。
### Conclusion
该模型在多个手术数据库上达到了最先进的性能，证明了无监督对象中心方法可以应用于真实数据，并可能成为医疗保健应用中的常用工具。
## 583. `cs.CV` - 高频语义和几何先验的端到端检测变换器在挑战性无人机图像中的应用 [PDF](https://arxiv.org/pdf/2507.00825), [HTML](https://arxiv.org/abs/2507.00825)
### Authors
Hongxing Peng,Lide Chen,Hui Zhu,Yan Chen
### Background
无人机机载目标检测(UAV-OD)面临许多挑战，包括小型目标、高密度分布和杂乱背景。现有算法通常依赖于手动构建的组件如锚框，需要精细调试且泛化能力有限；NMS 阈值敏感且容易误分类密集目标。这些通用架构难以适应航空成像特性，导致性能受限。此外，新兴的端到端框架尚未有效解决这些问题。
### Innovation
提出了HEGS-DETR，一种为无人机定制的增强实时检测变换器框架，包括High-Frequency Enhanced Semantics Network (HFESNet)、Efficient Small Object Pyramid (ESOP) 策略、Selective Query Recollection (SQR) 和 Geometry-Aware Positional Encoding (GAPE) 模块，以增强小目标检测、实现实时速度和减少参数量。
### Conclusion
实验证明，HEGS-DETR 在 VisDrone 数据集上与基线相比，在 AP50 和 AP 方面分别提高了 5.1% 和 3.8%，同时保持实时速度并减少参数量 4M。
## 584. `cs.CV` - MALT Diffusion: 记忆增强潜变 Transformer 用于任意长度视频生成 [PDF](https://arxiv.org/pdf/2502.12632), [HTML](https://arxiv.org/abs/2502.12632)
### Authors
Sihyun Yu,Meera Hahn,Dan Kondratyuk,Jinwoo Shin,Agrim Gupta,José Lezama,Irfan Essa,David Ross,Jonathan Huang
### Background
扩散模型在生成高质量视频方面取得了成功，但目前主要局限于生成较短的片段（如2-10秒）。长视频（如数分钟）的生成仍然是一个未解决的研究问题。本研究提出了一种新的扩散模型MALT（Memory-Augmented Latent Transformers），专用于长视频生成。
### Innovation
MALT Diffusion通过将长视频划分为短片段，并逐段进行自回归生成，解决了长视频生成的挑战。通过引入递归注意力层将多个片段编码成紧凑的记忆潜矢量，MALT能够维持这种记忆矢量，并基于长时间序列上下文条件生成新的片段。此外，还介绍了几种训练技术，使得模型能够在长时间内保持高质量生成，且降级最小。
### Conclusion
通过在长视频基准上的实验验证了MALT的有效性。MALT在UCF-101上生成128帧视频的结果表明其FVD得分为220.4，优于之前的SOTA方法。最后，MALT在文本到视频生成方面的表现也优于近期技术。
## 585. `cs.CV` - 当剪枝如何有益于视觉表示？ [PDF](https://arxiv.org/pdf/2507.01722), [HTML](https://arxiv.org/abs/2507.01722)
### Authors
Enrico Cassano,Riccardo Renzulli,Andrea Bragagnolo,Marco Grangetto
### Background
剪枝广泛用于减少深度学习模型的复杂性，然而，剪枝对可解释性和表征学习的影响尚不明确。本文探讨剪枝如何在三大关键维度上影响视觉模型：（i）可解释性，（ii）无监督对象发现，以及（iii）与人类感知的一致性。研究旨在分析不同视觉网络架构，考察不同程度稀疏性对特征归因可解释性方法的影响，并探讨剪枝是否有助于生成更为简洁且结构化的表示，从而提高无监督对象发现的性能。此外，研究还评估了剪枝是否有助于提高模型表示与人类感知的一致性，关注剪枝后模型是否更多关注与人类相似的具有判别性的特征。
### Innovation
本文创新地从三个重要维度（可解释性、无监督对象发现和与人类感知的一致性）分析了剪枝对视觉模型的影响，并揭示了剪枝的甜点区域，即在该区域，稀疏模型具有更高的可解释性、下游泛化能力和与人类的一致性。这些发现强调了考察模型在哪些条件和什么情况下通过剪枝可以受益的重要意义。
### Conclusion
研究发现，稀疏模型在可解释性、下游泛化和与人类感知的一致性方面表现出较高性能，但这些性能显著依赖于网络架构及其参数量。此外，表明这些三个维度之间存在复杂交互，揭示了研究模型在特定条件下和具体如何受益剪枝的重要性。
## 586. `cs.CV` - Hita: Holistic Tokenizer for Autoregressive Image Generation [PDF](https://arxiv.org/pdf/2507.02358), [HTML](https://arxiv.org/abs/2507.02358)
### Authors
Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi
### Background
传统的自回归图像生成模型逐步生成视觉令牌，这限制了它们捕捉令牌序列之间整体关系的能力。大多数视觉令牌将局部图像片段映射为潜在令牌，因此全局信息有限。
### Innovation
提出了一种新颖的图像令牌化器Hita，旨在解决上述问题。Hita采用了一个整体到局部的令牌化方案，包括可学习的整体查询和局部补丁令牌。此外，Hita通过采用具有因果注意力机制的序列结构和使用轻量级融合模块控制信息流来更好地适应自回归生成过程。
### Conclusion
广泛的实验表明，Hita加速了自回归生成器的训练速度，并在ImageNet基准测试中优于用传统令牌化器训练的模型，实现了2.59 FID和281.9 IS的结果。详细的整体表示分析表明，它具有捕捉全局图像属性如纹理、材料和形状的能力。此外，Hita还在零样本风格转换和图像修补方面表现出有效性。
## 587. `cs.CV` - 视觉自适应提示在组合适零样本学习中的应用 [PDF](https://arxiv.org/pdf/2502.20292), [HTML](https://arxiv.org/abs/2502.20292)
### Authors
Kyle Stein,Arash Mahyari,Guillermo Francia,Eman El-Sheikh
### Background
视觉-语言模型(VLMs)已经在联合表示视觉和文本数据方面表现出色，使得它们成为诸如组合适零样本学习(CZSL)等任务的强大工具。CZSL要求模型能够泛化到训练过程中未明确遇到的视觉语义单元的新型组合。近期关于CZSL的提示方法主要集中在修改文本编码器的输入，通常使用静态提示，但这些方法在处理变化的视觉上下文时存在局限性，因为它们主要侧重于文本的适应，而不是利用视觉特征进行组合推理。
### Innovation
本文提出了一个视觉自适应提示系统(VAPS)，该系统利用可学习的视觉提示库和基于相似性的检索机制，弥补了语义和视觉特征之间的差距。该方法引入了一个动态视觉提示库机制，根据图像的视觉特征选择最相关的语义和对象提示。此外，提出的方法还包括一个视觉提示适配器，促使模型学习更具泛化能力的嵌入空间。
### Conclusion
在三个CZSL基准测试上进行了实验，涵盖了封闭和开放世界的场景，结果表明该系统实现了最佳效果。
## 588. `cs.CV` - BoundMatch：应用于城市驾驶场景半监督分割的边界检测 [PDF](https://arxiv.org/pdf/2503.23519), [HTML](https://arxiv.org/abs/2503.23519)
### Authors
Haruya Ishikawa,Yoshimitsu Aoki
### Background
半监督语义分割(SS-SS)旨在通过利用大量无需标注的图像以及少量标记集来减轻密集像素标注的标注负担。目前的一致性正则化方法取得了很好的结果，但往往忽视了精确对象边界划分这一关键挑战。
### Innovation
提出了一种新型多任务半监督语义分割框架——BoundMatch，该框架将边界检测明确集成到教师-学生一致性正则化pipeline中。核心机制BCRM通过在分割掩码和详细语义边界之间强制预测一致性。此外，还引入了两个轻量级融合模块：边界-语义融合(BSF)将学习到的边界提示注入到分割解码器，空间梯度融合(SGF)利用掩码梯度细化边界预测，从而产生高质量的边界伪标签。BoundMatch基于SAMTH，一种强健的教师-学生基线模型，该模型采用和谐批标准化(HBN)更新策略以提高稳定性。
### Conclusion
实验结果表明BoundMatch在城市驾驶场景数据集Cityscapes、BDD100K和SYNTHIA上达到了现有最先进方法的竞争力表现，并在DINOv2基础模型的新基准测试中取得了最佳结果。进一步验证了Approach在Pascal VOC和ADE20K数据集上的通用性。消融研究突显了BoundMatch在边界特定评估指标上的提升能力、在大规模现实未标注数据场景中的有效性，以及对于轻量级架构用于移动部署的适用性。
## 589. `cs.CV` - Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis [PDF](https://arxiv.org/pdf/2507.02395), [HTML](https://arxiv.org/abs/2507.02395)
### Authors
Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun
### Background
目前，多实例学习（MIL）通过使用包级弱标签显著减少了大规模图像，如组织病理学全视图图像（WSIs）的注释成本。然而，在持续任务中保持最小遗忘的适应性探索较少，特别是在实例分类定位方面。尽管在持续定位中的语义分割中已经研究了弱增量学习，但其主要针对自然图像，利用预训练模型在成百上千的小窗口（例如$16 times 16$）之间建立全局关系。这种方法对于MIL定位来说由于处理大数量级的大型窗口（例如$256 times 256$）且缺乏如癌细胞的全局关系而不切实际。为应对这些挑战，本文提出了持续增强定位的多实例学习框架（CoMEL），一个结合局部和包分类的MIL框架，适用于定位任务和最小遗忘的适应性。CoMEL通过构建分组双注意力变换器（GDAT）、基于包原型的伪标签（BPPL）以及正交加权低秩适应（OWLoRA）组成，克服了前人方法的不足，提高了包分类准确性和定位准确度。
### Innovation
1. 提出了一个结合分组双注意力变换器（GDAT）、基于包原型的伪标签（BPPL）以及正交加权低秩适应（OWLoRA）的MIL框架（CoMEL），用于组织病理学全视图图像的持续定位问题。2. 协调解决了MIL框架在持续定位中的包分类和实例分类的最小遗忘问题，有效处理大规模的图像窗口。3. 通过公共WSI数据集的实验，展示了所提方法在包分类和定位上的优越性能，超越了现有方法最高11.00%的包分类准确率和23.4%的定位准确率。
### Conclusion
所提出的CoMEL框架通过分组双注意力变换器、基于包原型的伪标签和正交加权低秩适应显著提高了多实例学习在组织病理学全视图图像上的持续适应性和定位效果，为领域特定的大规模原始图像分类和定位问题提供了解决方案。
## 590. `cs.CV` - PhenoBench: 一种全面的细胞表型基准 [PDF](https://arxiv.org/pdf/2507.03532), [HTML](https://arxiv.org/abs/2507.03532)
### Authors
Jerome Luescher,Nora Koreuber,Jannik Franzen,Fabian H. Reith,Claudia Winklmayr,Elias Baumann,Christian M. Schuerch,Dagmar Kainmueller,Josef Lorenz Rumberger
### Background
数字病理学已经见证了多种基础模型（FM）的发展，但这些模型在细胞表型识别方面的表现尚未在统一的框架下进行基准测试。因此，本文提出PhenoBench：一种全面的基准测试工具，用于评估H&E染色组织学图像上的细胞表型识别。PhenoBench提供了一个新的H&E数据集PhenoCell，包含14种通过多重成像识别的细粒度细胞类型，并提供了易于使用的微调和基准测试代码，以系统评估多个主流病理学基础模型在不同泛化场景下的密集细胞表型预测性能。
### Innovation
PhenoBench通过引入一个新的数据集PhenoCell，重点在H&E染色组织学图像中识别14种细粒度的细胞类型，提供了一种新的评估方法。此外，该研究发现现有模型在PhenoCell上的性能显著低于先前的基准（如Lizard和PanNuke），这表明细胞表型识别是一个比之前评估更具有挑战性的任务，PhenoCell因此成为了评估基础模型和监督学习模型的重要工具。
### Conclusion
通过广泛的基准测试，作者展示了现有模型在技术领域和医学领域变化时的泛化行为。在PhenoCell上，一些模型的宏观F1分数低至0.20，这表明了这一任务的复杂性，且PhenoBench是一个重要的基准工具，用于未来的模型评估。提供相关的代码和数据可在GitHub上获取。
## 591. `cs.CV` - FreqCross: 一种用于稳定扩散3.5生成图像稳健检测的多模态频域-空域融合网络 [PDF](https://arxiv.org/pdf/2507.02995), [HTML](https://arxiv.org/abs/2507.02995)
### Authors
Guang Yang
### Background
扩散模型的快速发展，尤其是Stable Diffusion 3.5，已经使得能够生成极为逼真的合成图像。这些图像对现有检测方法构成了重大挑战。
### Innovation
本文提出了一种新型的多模态融合网络——FreqCross，该网络结合了空间RGB特征、频域伪像和径向能量分布模式，以实现对AI生成图像的稳健检测。FreqCross采用三支架构，包括用于空间特征提取的ResNet-18主干网，用于处理2D FFT幅度光谱的轻量级CNN，以及用于分析径向能量分布的多层感知器。该方法引入了一种新的径向能量分布分析，能够捕捉扩散生成图像中固有的特征频率伪像，并通过简单的特征连接与空域和谱域线索进行融合。
### Conclusion
在包含10,000对真实（MS-COCO）和合成（Stable Diffusion 3.5）图像的数据集上进行的广泛实验表明，FreqCross实现了97.8％的准确性，超越了最先进的基线方法5.2％。进一步的频率分析还揭示了合成图像在0.1--0.4归一化频率范围内的独特频谱特征，为该方法提供了理论基础。项目代码和预训练模型已公开，以促进可再现研究。
## 592. `cs.CV` - BézierGS：使用Bézier曲线高斯点积进行动态城市场景重建 [PDF](https://arxiv.org/pdf/2506.22099), [HTML](https://arxiv.org/abs/2506.22099)
### Authors
Zipei Ma,Junzhe Jiang,Yurui Chen,Li Zhang
### Background
现实场景的重建对于开发自动驾驶的实际场景模拟器至关重要。当前大多数方法依赖于物体姿态注释，这些注释用于重建动态物体并在渲染过程中移动它们。这种依赖于高精度物体注释限制了大规模和广泛的场景重建。
### Innovation
我们提出了Bézier曲线高斯点积（BézierGS），该方法通过可学习的Bézier曲线来表示动态物体的运动轨迹。此方法充分利用了动态物体的时间信息，并通过可学习曲线建模自动纠正姿态错误。通过在动态物体渲染中引入额外的监督以及曲线间一致性约束，实现了场景元素的合理和准确分离与重建。
### Conclusion
在Waymo公开数据集和nuPlan基准上的实验表明，BézierGS在动态和静态场景部件重建以及新颖视图合成方面优于最先进的方法。
## 593. `cs.CV` - 跨领域肖像风格迁移 [PDF](https://arxiv.org/pdf/2507.04243), [HTML](https://arxiv.org/abs/2507.04243)
### Authors
Xinbo Wang,Wenju Xu,Qing Zhang,Wei-Shi Zheng
### Background
本文提出了一种泛化能力强的肖像风格迁移方法，能够在多种不同领域中进行高质量的语义对齐风格化，适用于头发、眼睛、睫毛、皮肤、嘴唇以及背景等多个区域。
### Innovation
本文的主要创新在于：1) 提出了基于预训练模型和语义适配器建立密集语义对应的方法；2) 开发了AdaIN-Wavelet变换，平衡内容保留和风格变换，通过在隐空间中混合扭曲参考的低频信息和输入的高频信息实现风格传输；3) 设计了风格适配器以提供由扭曲参考参考所引导的风格指导；4) 利用结合高频频谱信息和风格指导的双重条件扩散模型生成最终结果。
### Conclusion
大量实验表明本文方法具有优越性。我们的代码及训练模型已在此网址可获取：this https URL.
## 594. `cs.CV` - StreamDiT: 实时流式文本到视频生成 [PDF](https://arxiv.org/pdf/2507.03745), [HTML](https://arxiv.org/abs/2507.03745)
### Authors
Akio Kodaira,Tingbo Hou,Ji Hou,Masayoshi Tomizuka,Yue Zhao
### Background
最近在文本到视频(T2V)生成领域取得了显著进展，通过将基于Transformer的扩散模型扩展到数十亿参数，可以生成高质量的视频。然而，现有的模型通常只能离线生成短片段，限制了其在交互式和实时应用中的使用。
### Innovation
本文通过提出StreamDiT流式视频生成模型解决了上述挑战。StreamDiT的训练基于流匹配，通过增加移动缓冲区来实现。设计了不同的缓冲帧分区方案的混合训练以提高内容一致性和视觉质量。StreamDiT采用adaLN DiT模型，具有可变时间嵌入和窗口注意力机制。此外，提出了针对StreamDiT的多步蒸馏方法，在每个选定分区方案的段落中进行采样蒸馏。最终，蒸馏后的模型在单个GPU上以16 FPS实现实时性能，并能在512p分辨率下生成视频流。
### Conclusion
通过定性和定量评估，我们的方法实现了实时应用，如流式生成、交互式生成和视频到视频。蒸馏后的模型能够实时生成512p分辨率的视频流，性能优异。
## 595. `cs.CV` - 当前是什么声音？以视频为中心的声音视觉定位 [PDF](https://arxiv.org/pdf/2507.04667), [HTML](https://arxiv.org/abs/2507.04667)
### Authors
Hahyeon Choi,Junhoo Lee,Nojun Kwak
### Background
现有的声音视觉定位（AVL）研究主要关注图像级的声音-视觉关联，未能捕捉到时间动态。此外，这些研究假设声音源始终可见且仅涉及单个对象，这限制了AVL模型的评估维度和准确性，导致对实际场景的认识不足。
### Innovation
本文提出了AVATAR，一种以视频为中心的AVL基准，整合了高分辨率的时间信息，通过引入单声源、混合声源、多实体和幕前四种不同的场景，从而更全面地评估AVL模型。此外，还提出了TAVLO，一种以视频为中心的AVL模型，明确集成时间信息。实验结果显示，传统的基于全局音频特征和帧级映射的方法难以捕捉时间变化。相比之下，TAVLO通过利用高分辨率的时序建模，实现了稳健且精确的声音-视觉对齐。这种模型的提出，突显了时间动态在AVL中的重要性，为视频为中心的AVL设定新的标准。
### Conclusion
本文通过实验证明，时间动态在AVL中的重要性，有效地提高了AVL模型的性能，为该领域未来的研究提供了新的标准和工具。
## 596. `cs.CV` - HyperGaussians: 高维高斯点射建模为高质量可动画角色脸 [PDF](https://arxiv.org/pdf/2507.02803), [HTML](https://arxiv.org/abs/2507.02803)
### Authors
Gent Serifi,Marcel C. Bühler
### Background
创建从视频中获取的详细面部角色是一个具有挑战性的问题，广泛应用于增强现实和虚拟现实。尽管在静态面部方面已有显著成就，但单目视频生成的可动画角色仍然未能克服‘毛骨悚然谷’问题。现有的3D高斯点射（3DGS）方法通过3D高斯基元集合表示面部，它们在静态面部渲染上表现优秀，但在非线性变形、复杂光照效果和细节处理上仍存在问题。大部分相关工作集中在预测更好的高斯参数，而本文重新审视了3D高斯表示，并引入了高维多元高斯（HyperGaussians），有效地提高了表示的表达能力。然而，这需要高性能计算以处理大维度共轭方差矩阵的逆矩阵问题。
### Innovation
本文提出了HyperGaussians，这是一种新的3D高斯点射扩展，能更好地表示面部，特别是在处理精细细节和复杂变形时表现出色。HyperGaussians通过可学习的局部嵌入增加表达能力，但计算成本高昂的问题通过引入‘逆共轭技巧’得到了解决。该技巧提升了效率，方便HyperGaussians集成到现有模型中。实验证明，HyperGaussians在19位受试者的4个面部数据集中表现优于3DGS，特别是在高频细节如眼镜框、牙齿、面部复杂运动和高光反射方面表现更为出色。
### Conclusion
本文通过引入HyperGaussians，解决了3D高斯点射在表达面部细节方面的局限性，并通过实验验证了其在可动画面部建模中的优势。
## 597. `cs.CV` - LEHA-CVQAD：用于压缩失真通用视频质量评估的数据集 [PDF](https://arxiv.org/pdf/2507.03990), [HTML](https://arxiv.org/abs/2507.03990)
### Authors
Aleksandr Gushchin,Maksim Smirnov,Dmitriy Vatolin,Anastasia Antsiferova
### Background
当前，压缩视频质量评估的需求日益增长，但可获取的高质量数据集有限。已有的数据集无法满足对压缩失真全面评估的需求。因此，需要构建一个大规模、高质量、包含多种编码格式和参数、以及包含用户评分的视频质量评估数据集，以支持基于量化和视觉质量的算法研究和优化。
### Innovation
论文提出了LEHA-CVQAD数据集，包含6240个压缩视频片段，覆盖59种源视频和186种编解码器参数设置，其中有180万对的配对评分和1500个主观评分（MOS）。该数据集包含未编码的部分供盲评估使用。此外，提出了Rate-Distortion Alignment Error (RDAE)评估指标，用于量化VQA模型在保持比特率-质量排序上的效果，直接支持编解码器参数调整。研究表明，流行的VQA指标在RDAE和相关性方面表现较低，凸显了数据集的挑战和用途。
### Conclusion
LEHA-CVQAD数据集为全面评估压缩失真提供了大量高质量的数据，同时RDAE评估指标可帮助更好地调整编解码器参数。研究结果表明，现有指标面临挑战，该数据集具有较高的研究价值。开放的部分和结果可在LEHA-CVQAD网站上获取。
## 598. `cs.CV` - CTA: 交叉任务对齐以提升测试时训练 [PDF](https://arxiv.org/pdf/2507.05221), [HTML](https://arxiv.org/abs/2507.05221)
### Authors
Samuel Barbeau,Pedram Fekri,David Osowiechi,Ali Bahri,Moslem Yazdanpanah,Masih Aminbeidokhti,Christian Desrosiers
### Background
深度学习模型在多种计算机视觉任务中表现出色。然而，当面临分布变化（如领域或数据集变化）时，它们的性能会显著下降。作为应对策略，测试时训练（TTT）通过在训练过程中引入辅助的无监督任务，并利用该任务在测试时对模型进行更新，有效提升了模型的稳定性。
### Innovation
本文介绍了一种新的方法——交叉任务对齐（CTA），它不依赖特定的模型架构，而是借鉴多模态对比学习的成功经验，将监督式编码器与自监督式编码器进行对齐。这种方法在训练过程中强制两个模型的表示学习进行对齐，从而减少了梯度干扰的风险，保留了自监督学习的固有鲁棒性，并在测试时实现了更具有语义意义的更新。实验结果表明，CTA在多个基准数据集上在稳定性与泛化能力方面超过了最先进的方法。
### Conclusion
实验结果表明，CTA在鲁棒性与泛化能力上显著优于最先进的方法。
## 599. `cs.CV` - PointGAC: 基于几何感知的编码本ousse用于掩码点云建模 [PDF](https://arxiv.org/pdf/2507.04801), [HTML](https://arxiv.org/abs/2507.04801)
### Authors
Abiao Li,Chenlei Lv,Yuming Fang,Yifan Zuo,Jian Zhang,Guofeng Mei
### Background
大多数掩码点云建模（MPM）方法依赖于回归范式来重建被掩盖区域的坐标或特征，但这些方法可能会过度限制模型的学习，导致难以捕捉通用特征。
### Innovation
提出了一种名为PointGAC的新型基于聚类的掩码点云建模方法，旨在对齐被掩盖区域的特征分布。方法采用在线代码本引导的教师-学生框架。首先，采用几何感知的分割策略提取初始片段；然后，教师模型通过基于完整片段提取的特征进行在线k-means更新代码本，使之成为簇中心；接着，将未遮盖的特征分配给对应的簇中心，学生模型则调整分配以匹配重构的遮盖特征，从而突出识别掩码特征所属的簇中心，使模型能够学习更通用的特征表示。
### Conclusion
该方法借助提出的代码本维护机制，动态更新代码本向量，进一步增强了语义特征学习的效率。实验结果证明了该方法在各种下游任务中的有效性。
## 600. `cs.CV` - UGG-ReID：多模态对象重新识别的不确定性指导图模型 [PDF](https://arxiv.org/pdf/2507.04638), [HTML](https://arxiv.org/abs/2507.04638)
### Authors
Xixi Wan,Aihua Zheng,Bo Jiang,Beibei Wang,Chenglong Li,Jin Tang
### Background
多模态对象重识别（Re-ID）已经引起了广泛关注，目的是利用异构视觉数据源在不同摄像机中检索特定目标。现有方法主要致力于提高识别性能，但往往忽视了由内在缺陷（如同一模态噪声和跨模态冲突）带来的不确定性。这种不确定性在微细节部分遮挡和帧丢失的情况下特别显著，成为多模态学习的挑战。
### Innovation
提出了一个鲁棒的方法，即不确定性指导图模型（UGG-ReID），以应对上述挑战。UGG-ReID通过估计局部和样本级别的不确定性及其依赖性，减少噪声干扰和促进有效的多模态融合。具体来说，该方法首先引入了高斯补丁图表示模型，利用不确定性对细粒度局部线索进行量化，并捕捉它们的结构关系。此外，设计了不确定性指导的专家混合策略，动态地将样本路由到不确定性低的专家，有效地抑制了噪声诱导的不稳定性，增强了鲁棒性。同时，设计了不确定性指导的路由策略以加强多模态间交互，提高了性能。
### Conclusion
UGG-ReID在五个代表性多模态对象Re-ID数据集上进行了全面评估，涵盖了多样化的频谱模态。实验结果表明，所提出的方法在所有数据集上的表现都非常出色，并在噪声免疫力方面显著优于现有方法。
## 601. `cs.CV` - 从最优传输视角看无配对图像超分辨率 [PDF](https://arxiv.org/pdf/2202.01116), [HTML](https://arxiv.org/abs/2202.01116)
### Authors
Milena Gazdieva,Petr Mokrov,Litu Rout,Alexander Korotin,Andrey Kravchenko,Alexander Filippov,Evgeny Burnaev
### Background
现实世界中的图像超分辨率（SR）任务通常缺乏配对的数据集，这限制了监督技术的应用。因此，这些任务通常使用基于生成对抗网络（GANs）的无配对技术，这类技术在训练损失中引入了复杂的正则化项，例如内容损失或身份损失。尽管GANs通常具有良好的实际性能，但它们是直觉上使用的，即对其行为的理论理解仍然有限。
### Innovation
本文从理论上研究了无配对SR模型中存在的优化问题，发现两个出人意料的观察：首先，学习到的SR映射总是最优传输（OT）映射；其次，理论上证明且实验证明，学习到的映射是有偏的，即它实际上并没有将低分辨率图像的分布转换为高分辨率的分布。基于这些发现，本文探讨了最近在神经OT领域的进步来解决偏差问题，并建立了正则化GANs和神经OT方法之间有趣的关系，表明这些算法旨在学习一个无偏的OT映射。
### Conclusion
通过一系列合成和真实的无配对SR实验，本文实验证明了上述发现，并公开提供了源代码。
## 602. `cs.CV` - 术中超声中可见组织识别：方法及其应用 [PDF](https://arxiv.org/pdf/2306.01190), [HTML](https://arxiv.org/abs/2306.01190)
### Authors
Alistair Weld,Luke Dixon,Giulio Anichini,Michael Dyck,Alex Ranne,Sophie Camp,Stamatia Giannarou
### Background
术中超声扫描是一项对视觉和触觉技能要求很高的任务。操作者需要同时定位超声视角并手动调整探头的姿态，确保不施加过大压力或中断与组织的接触，同时需要表征可见的组织结构。然而，探头与组织之间的接触细节较为复杂，难以准确识别。因此，需要开发新的方法来分析探头与组织的接触情况，提高术中超声扫描的精确度和可靠性，以支持临床培训和机器人超声自动化。
### Innovation
本文提出了一种迭代滤波和拓扑方法，用于识别超声探头与组织接触下的可见组织，从而检测声影并构建感知显著性的置信度图。该方法在超声探头与组织接触的数据集上进行了评估，并与现有的消融、深度学习和统计方法进行了对比。结果表明，本文提出的方法在实时数据上的声影分类性能优于其他方法，且在置信评估框架下表现出更高的准确性。此外，该方法还对参数扰动、斑点噪声、数据分布转移和引导机器人扫描的能力进行了评估，验证了其鲁棒性和实用性。
### Conclusion
通过这一系列全面的实验，本文证明了所提出算法的潜在临床价值，可以用于支持临床培训和机器人超声自动化。
## 603. `cs.CV` - Vision xLSTM嵌入UNet在医学3D图像分割中的可靠性更高吗？ [PDF](https://arxiv.org/pdf/2406.16993), [HTML](https://arxiv.org/abs/2406.16993)
### Authors
Pallabi Dutta,Soham Bose,Swalpa Kumar Roy,Sushmita Mitra
### Background
医学图像分割策略的发展经历了从依赖卷积神经网络（CNNs）到当前探索将CNNs与Vision Transformers（ViTs）结合的混合模型的转变。人们越来越关注开发既高性能又计算效率高的架构，能够在资源有限的远程系统上部署。尽管变压器可以捕捉输入空间中的全局依赖关系，但它们面临着由相应的高计算和存储成本所带来的挑战。
### Innovation
该研究提出了一种新型的U-VixLSTM方法，结合了Vision Extended Long Short-Term Memory（Vision-xLSTM）模块和UNet架构。Vision-xLSTM模块捕捉从CNN特征图提取的patches中的时空和全局关系，而卷积特征重建路径则对来自Vision-xLSTM模块的输出进行上采样以生成分割输出。实验结果表明，U-VixLSTM在公开的Synapse、ISIC和ACDC数据集上的表现优于最先进的网络，且具有较低的计算成本。
### Conclusion
Vision-xLSTM 在医学图像分割中形成了合适的支撑结构，具有出色的性能和较低的计算成本。U-VixLSTM在现有的医学图像分割网络中表现出更优性能。
## 604. `cs.CV` - RichControl: 结构丰富和外观丰富无监督空间控制的文本到图像生成 [PDF](https://arxiv.org/pdf/2507.02792), [HTML](https://arxiv.org/abs/2507.02792)
### Authors
Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang
### Background
文本到图像（T2I）扩散模型在生成高质量图像方面取得了显著的成功。最近的研究努力将这些模型扩展到包括条件图像（如深度图或姿态图）以进行精细的空间控制。特征注入方法作为一种无监督替代传统的微调方法已经出现，但它们通常会受到结构错位、条件泄露和视觉瑕疵等问题的影响，尤其是当条件图像与自然RGB分布差异显著时。现有的方法未能考虑去噪过程中的领域对齐和结构保存之间的权衡。
### Innovation
本文提出了一种灵活的特征注入框架，解耦了特征注入时间步与去噪过程，核心是一个结构丰富的特征注入模块，使模型能够更好地适应扩散步骤中不断变化的领域对齐与结构保存之间的交互，从而生成更忠实的结构。此外，还引入了外观丰富的提示和重启校准策略，进一步增强了外观控制和视觉质量。这些设计使无监督生成兼具结构丰富和外观丰富。
### Conclusion
在广泛的实验中，我们的方法在多种零样例条件场景中达到了最先进的性能。
## 605. `cs.CV` - AbdomenAtlas-8K: 在三周内注释8,000个CT卷以进行多器官分割 [PDF](https://arxiv.org/pdf/2305.09666), [HTML](https://arxiv.org/abs/2305.09666)
### Authors
Chongyu Qu,Tiezheng Zhang,Hualin Qiao,Jie Liu,Yucheng Tang,Alan Yuille,Zongwei Zhou
### Background
医学图像注释，尤其是器官分割，是一个费时费力的过程。例如，注释腹部器官需要大约30-60分钟/CT体积，具体取决于注释者的经验和器官的大小、可见性和复杂性。因此，可用于多器官分割的公开数据集在数据量和器官多样性方面往往有限。常用的注释方法可能需要1,600周（约30.8年）才能完成注释，但本方法在三周内完成了此项工作，且保持了类似的或更好的注释质量。这项工作的实现得益于本方法的三个独特特征：（1）使用多个预训练分割模型减少标签偏差，（2）有效检测模型预测中的错误，（3）突出指导注释者的注意力，使其能够对最显著的错误进行修正。此外，本文总结了常见的人工智能算法和注释员错误的分类，这有助于持续优化AI和注释，并显著降低创建大规模数据集的成本，以更好地满足各种医学成像任务的需求。
### Innovation
提出了一种新颖的主动学习方法，用于加速多器官分割的注释过程。该方法利用多个预训练分割模型来减少标签偏差，有效地检测模型预测中的错误，并引导注释者修改最显著的错误。通过这种方法，在三周内完成了对8,448个CT体积的注释，涵盖脾脏、肝脏、肾脏、胃、胆囊、胰腺、主动脉和下腔静脉，相当于3.2亿张切片。这一方法在保持注释质量的同时极大地提高了工作效率，为大规模医学图像数据的创建提供了新的可能。
### Conclusion
通过主动学习方法创建了迄今为止最大的多器官数据集，涵盖多种器官并注释了8,448个CT卷，达到3.2亿个切片。这种工作方法与传统方法相比，所需时间大大缩短，但仍能保持甚至提高注释质量。这一成果得益于使用多个预训练模型来减少标签偏差、有效检测预测错误以及指导注释者关注最显著错误的独特特征。同时，该方法还总结了常见的人工智能算法和注释员错误的分类，促进了AI和注释的持续优化。
## 606. `cs.CV` - TimeFlow：纵向脑影像注册与大脑衰老进程分析 [PDF](https://arxiv.org/pdf/2501.08667), [HTML](https://arxiv.org/abs/2501.08667)
### Authors
Bailiang Jian,Jiazhen Pan,Yitong Li,Fabian Bongratz,Ruochen Li,Daniel Rueckert,Benedikt Wiestler,Christian Wachinger
### Background
预测未来脑状态对于理解健康老化和神经退行性疾病至关重要。纵向脑MRI注册作为这类分析的基础，长期以来受到无法预测未来发展、依赖密集的纵向数据以及需要平衡注册精度与时间连续性等挑战的限制。
### Innovation
TimeFlow 利用具有时间条件的 U-Net 架构，借鉴扩散模型的原理，仅需两个图像输入即可实现准确的纵向脑MRI注册，并能够进行未来图像预测，从而克服了传统方法对明确平滑性和密集序列数据的需求。TimeFlow 在未来时间点预测和注册精度方面均表现出优于现有最优方法的性能。此外，TimeFlow 还能够支持新颖的生物脑老化分析，有效地区分神经退行性疾病与健康老化，且无需进行标注，避免了非平凡标注和不一致分割的问题。
### Conclusion
TimeFlow 框架为准确、高效且无标注的纵向脑老化和慢性疾病未来的分析铺平了道路。
## 607. `cs.CV` - 基于物理驱动的自回归状态空间模型在医学图像重建中的应用 [PDF](https://arxiv.org/pdf/2412.09331), [HTML](https://arxiv.org/abs/2412.09331)
### Authors
Bilal Kabas,Fuat Arslan,Valiyeh A. Nezhad,Saban Ozturk,Emine U. Saritas,Tolga Çukur
### Background
医学图像从欠采样的采集数据重建是一个病态问题，涉及到将测量域与图像域连接的成像操作的逆过程。物理驱动（PD）模型因其良好的性能和泛化能力而受到关注，这些模型结合了数据一致性机制和学习网络模块，共同促进数据保真度和伪影抑制。现有的方法依赖网络区分伪影和真实的组织信号的能力，但这些结构可以在不同级别的空间尺度上存在。尽管卷积神经网络（CNN）擅长捕捉局部相关性，但对非局部上下文较为敏感。虽然变压器有望克服这一限制，但其实现通常需要通过平衡局部和非局部敏感性来降低计算成本的设计妥协，有时导致性能与CNN相当甚至落后。为了在不增加复杂性的情况下提高上下文敏感性，提出了一种新的物理驱动的自回归状态空间模型（MambaRoll），用于医学图像重建。
### Innovation
MambaRoll模型采用自回归架构，并在每个未卷积的体系结构阶梯中使用物理驱动的状态空间模块（PD-SSM）来高效地在给定的空间尺度上聚合上下文特征，并自回归地预测细尺度特征图以捕获多尺度上下文。此外，DMSD损失用于促进不同尺度上的学习，以适应自回归预测任务。演示表明，MambaRoll模型在加速MRI和稀疏视图CT重建中均优于基于CNN、变压器和状态空间模型（SSM）基干的现有数据驱动和物理驱动方法。
### Conclusion
MambaRoll模型在医学图像重建任务中展示了优越的性能，能够有效地解决上下文感知问题，同时保持较低的复杂度，展示了其在医学图像重建中的创新应用。
## 608. `cs.CV` - 视觉模仿实现情境化类人机器人控制 [PDF](https://arxiv.org/pdf/2505.03729), [HTML](https://arxiv.org/abs/2505.03729)
### Authors
Arthur Allshire,Hongsuk Choi,Junyi Zhang,David McAllister,Anthony Zhang,Chung Min Kim,Trevor Darrell,Pieter Abbeel,Jitendra Malik,Angjoo Kanazawa
### Background
如何通过周围环境的帮助教会类人机器人攀爬阶梯和坐在椅子上的技能？一种简单的方法是直接观察人类的行为。本文介绍了一种名为VIDEOMIMIC的从现实到模拟再到现实的管道，该管道可以利用日常生活中的视频资料，同时重建人类和环境，生成类人机器人执行对应技能的全身控制策略。
### Innovation
VIDEOMIMIC管道能够从日常视频中提取人类和环境信息，并生成适应不同环境的全身控制策略，实现在单一策略下通过环境条件和全局根命令实现稳定的环境相关控制，涵盖楼梯上下、椅子坐起等动态全身技能。
### Conclusion
VIDEOMIMIC为训练类人机器人操作不同现实环境提供了一种可扩展的途径，展示了不同环境下执行各种动态全身技能的能力。
## 609. `cs.CV` - 自主安全着陆用的实时随机地形测绘及处理 [PDF](https://arxiv.org/pdf/2409.09309), [HTML](https://arxiv.org/abs/2409.09309)
### Authors
Kento Tomita,Koki Ho
### Background
目前，用于行星安全着陆的车载地形感知和测绘在检测中经常会遗漏小岩石等危险特征，这是因为观测范围大且地形数据分辨率有限。解决这个问题，该论文提出了一个新颖的实时随机地形测绘算法，该算法考虑了采样点之间的地形不确定性或稀疏3D地形测量的不确定性。该论文还介绍了结合Delaunay三角剖分和局部高斯过程回归的方法来高效构建高斯数字高程图，并利用着陆器-地形交互的几何研究以有效评估保守的局部坡度和粗糙度，避免了局部平面的昂贵计算。
### Innovation
该研究提出了一种新颖的实时随机地形测绘算法，该算法通过结合Delaunay三角剖分和局部高斯过程回归高效构建高斯数字高程图，考虑了地形不确定性，利用几何方法高效评估了保守的局部坡度和粗糙度。该算法适用于挑战性的操作条件，如大观测范围或传感器能力有限的情况，为自主预测性指导算法的发展打下了基础。
### Conclusion
该开发的实时不确定性量化管道可以在挑战性操作条件下对自主安全着陆进行随机着陆安全性评估，为安全自主行星着陆的预测性指导算法开发奠定了关键的基石。
## 610. `cs.CV` - 基于可靠病灶语义驱动先验的轻量级医学影像恢复 [PDF](https://arxiv.org/pdf/2504.11286), [HTML](https://arxiv.org/abs/2504.11286)
### Authors
Pengcheng Zheng,Kecheng Chen,Jiaxin Huang,Bohao Chen,Ju Liu,Yazhou Ren,Xiaorong Pu
### Background
医学影像恢复任务旨在从降解的观察中恢复高质量的影像，并在许多临床场景中展现出潜在价值，如低剂量CT图像去噪、MRI超分辨率和MRI伪影去除。尽管现有的深度学习恢复方法在复杂模块的支持下取得了成功，但在计算效率方面依然存在挑战。此外，现有方法通常未能关注恢复结果的可靠性，在医学系统中显得更为重要。
### Innovation
我们提出了LRformer方法，这是一种通过在频域中引导可靠性学习的轻量级Transformer基线方法。该方法创新地利用贝叶斯神经网络（BNNs）中的不确定性量化，通过蒙特卡洛（MC）估计器和随机采样操作生成可靠的先验并应用到基础医学图像分割模型MedSAM上。同时，通过快速傅立叶变换（FFT）将交叉注意力（CA）机制分解为实对称和虚反对称两部分，设计了引导频率交叉注意力（GFCA）解算器，利用FFT的共轭对称性质降低了注意力机制的计算复杂度近一半。
### Conclusion
在多个任务上的广泛实验结果表明，提出的LRformer在效性和效率方面均优于现有方法。
## 611. `cs.CV` - FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection [PDF](https://arxiv.org/pdf/2507.04511), [HTML](https://arxiv.org/abs/2507.04511)
### Authors
Xinhua Lu,Runhe Lai,Yanqi Wu,Kanghao Chen,Wei-Shi Zheng,Ruixuan Wang
### Background
预训练的视觉-语言模型（VLMs）在离分布（OOD）检测方面取得了显著进展。然而，现有的基于CLIP的方法通常专注于通过学习与OOD相关的知识来提升OOD检测效果，这往往显示出有限的一般化能力或者依赖于大规模的辅助外部数据集。
### Innovation
本文提出了一种基于CLIP的创新框架，该框架基于强制提示学习（FA），专注于充分利用In-Distribution（ID）知识，并最终提高OOD检测的效果。该框架的核心思想是学习包含ID类别更多样化和丰富描述的提示（即强制提示），而不仅仅是类标签的文本语义。它通过强制ID图像与可学习的强制提示之间具有更多的显著语义相似性，从而更好地区分ID图像，并引入一个强制系数，鼓励强制提示学习更为全面和细致的ID类描述。
### Conclusion
广泛实验证明，我们的方法在OOD检测方面始终优于当前最先进的方法。即使在没有使用任何外部辅助数据集的情况下进行训练，FA也能实现显著改进，且可训练参数的数量与CoOp相同。代码可在给出的网址获取。
## 612. `cs.CV` - 基于集成视频-文本大型语言模型的可组合策略框架在心力衰竭评估中的应用 [PDF](https://arxiv.org/pdf/2502.16548), [HTML](https://arxiv.org/abs/2502.16548)
### Authors
Jianzhou Chen,Jinyang Sun,Xiumei Wang,Xi Chen,Heyu Chu,Guo Song,Yuji Luo,Xingping Zhou,Rong Gu
### Background
心力衰竭是全球范围内导致死亡的主要原因之一，每年有数百万人因此丧生。尽管在心力衰竭领域取得了显著进展，患者生存率得到提高，射血分数改善，但仍存在大量未被满足的需求，因为心力衰竭具有复杂性和多因素特征。因此，本文提出了一种可组合策略框架，用于心力衰竭的评估及治疗优化。该框架模拟了医生与患者的咨询流程，并利用多模态算法分析多种数据来源，包括视频、体格检查、文字结果和医疗历史等，以实现更全面的评估和优化治疗计划。研究表明，这种多模态方法在心力衰竭预后预测准确性上优于单一模态的人工智能算法。通过此方法，能够进一步评估各种病理指标对心力衰竭预后的影响，从而提供更全面的评估
### Innovation
提出了一个可组合策略框架，结合医生-患者咨询过程和多模态算法，利用视频、体格检查结果、文字报告和医疗历史信息集成分析，实现更全面的心力衰竭评估与治疗优化。该框架在心力衰竭预后预测方面的多模态方法比单一模态的人工智能算法更准确，并且能进一步评估各种病理指标对心力衰竭预后的影响
### Conclusion
研究结果表明，这种多模态方法优于单一模态的人工智能算法，能够更准确地预测心力衰竭预后，并为不同病理指标对心力衰竭预后的影响提供更全面的评估，从而提供更好的治疗方案。
## 613. `cs.CV` - 从视频到脑电：将联合嵌入预测架构适应以揭示脑信号分析中的视觉概念 [PDF](https://arxiv.org/pdf/2507.03633), [HTML](https://arxiv.org/abs/2507.03633)
### Authors
Amirabbas Hojjati,Lu Li,Ibrahim Hameed,Anis Yazidi,Pedro G. Lind,Rabindra Khadka
### Background
脑电图（EEG）信号能够以高时间分辨率和低空间分辨率捕捉大脑活动，适用于神经诊断、认知监控和脑机接口等应用。然而，由于有限的标记数据、高维度性和缺乏能够全面捕捉时空依赖性的可扩展模型，有效地分析这些信号变得困难。现有的一些自监督学习（SSL）方法往往专注于空间或时间特征之一，而忽略了两者的结合，因此导致了次优化的表示。
### Innovation
本文提出了一种名为EEG-VJEPA的新颖方法，它适配了视频联合嵌入预测架构（V-JEPA），用于EEG分类。通过将EEG视为视频序列，EEG-VJEPA使用联合嵌入和自适应遮蔽来学习具有语义意义的时空表示。据我们所知，这是首次利用V-JEPA进行EEG分类，并探索由模型学习到的视觉概念的研究。相比现有先进的模型，EEG-VJEPA在分类任务中表现更佳，能够捕捉生理相关的时空信号模式，提供具有解释性的嵌入，支持人在AI辅助诊断过程中的合作。
### Conclusion
这些发现将EEG-VJEPA定位为在实际临床环境中具有可扩展性和可靠性的脑电分析框架，支持人机协作的诊断工作流程。
## 614. `cs.CV` - 通过深度平衡模型弥合经典和基于学习的迭代配准 [PDF](https://arxiv.org/pdf/2507.00582), [HTML](https://arxiv.org/abs/2507.00582)
### Authors
Yi Zhang,Yidong Zhao,Qian Tao
### Background
变形医学生物图像配准通常被表述为一个优化问题。传统方法是通过迭代方式解决这个问题，而最新的基于学习的方法则使用循环神经网络(RNN)模拟这个过程。尽管循环方法通过时间反向传播(BPTT)不断展开预测变形场，但这种方法缺乏理论上的收敛保证，且在实操中表现出不稳定。此外，RNN方法在训练时有一个实际瓶颈，即GPU内存使用量随着展开步骤的增加而线性增长。
### Innovation
本文提出了基于深度平衡模型(DEQ)的新型配准框架DEQReg，将配准问题表述为一个平衡寻求问题，建立了一种自然连接经典优化与基于学习的展开方法的桥梁。DEQReg能够维持恒定的内存使用量，理论上可以无限步迭代。通过在公开的脑部MRI和肺部CT数据集上的广泛评估，DEQReg展示了与最先进的展开方法相比可实现更具竞争力的配准性能，且显著减少内存消耗。我们还揭示了一个有趣的事实：现有的展开方法在推理步骤超过训练配置时会表现出先轻微增加然后不可逆转地衰减的性能。相比之下，DEQReg具有内置的平衡寻求机制，能够确保稳定收敛，从而弥合经典优化和现代基于学习的配准方法之间的差距。
### Conclusion
实验表明，DEQReg在保持配准性能的同时，显著减少了对内存的消耗。同时，DEQReg通过内置的平衡寻求机制确保了稳定的收敛，有效地结合了经典优化和现代基于学习的配准方法的优点，克服了两者各自的缺点。
## 615. `cs.CV` - ZigzagPointMamba: 基于空间语义的点云理解Mamba [PDF](https://arxiv.org/pdf/2505.21381), [HTML](https://arxiv.org/abs/2505.21381)
### Authors
Linshuang Diao,Dayong Ren,Sensen Song,Yurong Qian
### Background
点云自监督学习中，State Space模型（如PointMamba）能以线性复杂度高效提取特征，性能优于Transformer。然而，现有的PointMamba方法依赖复杂的令牌排序和随机掩码，这破坏了空间连续性和局部语义关联。
### Innovation
我们提出了一种名为ZigzagPointMamba的新方法，采用简单的Z字形扫描路径来全局排序点云令牌，增强空间连续性。同时，引入了一种语义双胞胎掩码策略（SMS），利用原始令牌和相似令牌的局部特征进行掩码，以便更稳健地进行全局语义建模。
### Conclusion
预训练的ZigzagPointMamba显著提高了下游任务的表现，在ShapeNetPart部分分割中获得了1.59%的mIoU提升，在ModelNet40分类中提高了0.4%的准确率，并且在ScanObjectNN的OBJ-BG、OBJ-ONLY和PB-T50-RS子集的分类任务中分别提高了0.19%、1.22%和0.72%的准确率。
## 616. `cs.LG` - 重新审视图神经网络中的过度平滑现象：从安德森局域化视角出发 [PDF](https://arxiv.org/pdf/2507.05263), [HTML](https://arxiv.org/abs/2507.05263)
### Authors
Kaichen Ouyang
### Background
图神经网络（GNNs）由于其强大的表示能力，在图数据分析中显示出巨大的潜力。然而，随着网络深度的增加，过度平滑问题变得更为严重，导致节点表示失去独特性。通过类比安德森局域化现象，本文分析了过度平滑的机制，并引入参与度作为度量这一现象的指标。随着GNN深度的增加，节点特征在多层信息传递后逐渐趋同，导致独特性的丧失，类似于无序系统振动模式的行为。在此背景下，GNN中的过度平滑可以理解为低频模式的扩展（参与度增加）和高频模式的局域化（参与度减少）
### Innovation
本文从安德森局域化现象的角度重新审视了图神经网络中的过度平滑问题，引入了参与度作为度量这一现象的指标。通过理论分析，提出了通过减少信息传播中的无序性来缓解过度平滑的潜在可能性
### Conclusion
本文系统地回顾了无序系统中安德森局域化行为与图神经网络中过度平滑行为之间的潜在联系，进行了理论分析，并提出了通过减少信息传播中的无序性来缓解过度平滑的潜在可能性
## 617. `cs.CV` - 训练应用程序中具有情绪表现能力的儿童avatar的多模态集成挑战 [PDF](https://arxiv.org/pdf/2506.13477), [HTML](https://arxiv.org/abs/2506.13477)
### Authors
Pegah Salehi,Sajad Amouei Sheshkal,Vajira Thambawita,Michael A. Riegler,Pål Halvorsen
### Background
真实可动的表情对于可信的AI生成的头像至关重要，但多数系统在模拟训练如受虐儿童调查访问时还停留在静态视觉效果上。因此团队研究了一个结合虚幻引擎5 MetaHuman渲染与NVIDIA Omniverse Audio2Face的实时架构，用于从语音语调生成真实主义儿童头像的面部表情，同时使用年轻成年女性声音来匹配角色特征，这种情况可能会引起语音-动画之间的不匹配。为了减少延迟，团队设置了双PC系统来分离语音生成和GPU密集型渲染，以在桌面和VR中实现低延迟交互。先前的研究发现，参与者普遍能够识别情绪，尤其是悲伤和快乐，而不带音频情况下愤怒情绪更难辨认，说明了声音在高唤醒情绪表达中的作用。此外，静默情绪表达片段提高了真实感，尤其是在语音语调或年龄感觉不一致的情况下。这一结果强调了音频-视觉一致性的重要性：不匹配的声音会削弱表达，而良好的匹配可以增强弱视觉效果，这意味着在敏感场景中创造情绪连贯的avatar需要克服多模态集成的挑战。
### Innovation
团队开发了一个结合虚幻引擎5 MetaHuman渲染与NVIDIA Omniverse Audio2Face的实时架构，用于从语音语调生成真实主义儿童头像的面部表情；设置了双PC系统分离语音生成和GPU密集型渲染，以减少延迟；探索了语音与动画不匹配对真实感的影响；通过实验证明了声音在情绪表达中的关键作用，尤其是高唤醒情绪；展示了静默情绪表达片段如何提高真实感。这些发现对创建敏感环境下连贯情绪表现的avatar具有指导意义。
### Conclusion
对于真实主义儿童头像而言，音频-视觉一致性至关重要，不匹配的声音会削弱表达，而良好的匹配可以增强弱视觉效果。这一研究揭示了多模态集成在训练应用程序中具有情绪表现能力的儿童头像时面临的重要挑战，并为未来的研究提供了新的视角。
## 618. `cs.LG` - 使用可解释人工智能压缩深度神经网络 [PDF](https://arxiv.org/pdf/2507.05286), [HTML](https://arxiv.org/abs/2507.05286)
### Authors
Kimia Soroush,Mohsen Raji,Behnam Ghavami
### Background
深度神经网络（DNNs）在许多任务中表现出色，但往往需要较高的计算成本和大量的内存使用。为了在资源受限的边缘设备上使用这些网络，需要应用压缩技术，如剪枝和量化解，以减少内存占用。近年来，可解释的人工智能（XAI）方法被引入，旨在理解和解释AI方法。XAI可用来理解DNNs的内部工作原理，例如不同神经元和特征在DNNs整体性能中的重要性。
### Innovation
本文提出了一种基于XAI的新DNN压缩方法，可以在不显著牺牲精度的情况下有效减小DNN模型大小。该方法利用了一种基于梯度的XAI技术——层相关性传播（LRP）来计算DNN参数（即权重）的重要性评分，然后根据评分进行剪枝和量化，实现模型压缩。
### Conclusion
实验结果表明，该压缩方法可以将模型大小减少64%，同时比最先进的XAI基压缩方法提高了42%的精度。
## 619. `cs.CV` - SurgiSR4K:一种用于机器人辅助微创手术的高分辨率内窥镜视频数据集 [PDF](https://arxiv.org/pdf/2507.00209), [HTML](https://arxiv.org/abs/2507.00209)
### Authors
Fengyi Jiang,Xiaorui Zhang,Lingbo Jin,Ruixing Liang,Yuxin Chen,Adi Chola Venkatesh,Jason Culman,Tiantian Wu,Lirong Shao,Wenqing Sun,Cong Gao,Hallie McNamara,Jingpei Lu,Omid Mohareri
### Background
高分辨率成像对于提高视觉清晰度和实现微创手术(MIS)中的精确计算机辅助指导至关重要。尽管4K内窥镜系统被广泛应用，但尚未出现专门针对机器人辅助MIS的高质量公共4K数据集。因此，需要提供一个既能捕捉高分辨率图像又能反映实际手术情况的数据集，以支持多种计算机视觉任务，如超分辨率(SR)、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新颖视角合成和视觉语言模型(VLM)开发。
### Innovation
SurgiSR4K是首个具有天然4K分辨率的公开可访问的外科成像和视频数据集，能够反映机器人辅助手术过程中的现实场景，包括镜面反射、工具遮挡、出血和软组织变形等问题。该数据集为高分辨率外科成像研究提供了坚实的基础，推动了用于图像引导机器人外科手术的智能成像技术的发展。
### Conclusion
SurgiSR4K提供了高分辨率的外科成像数据资源，促进了多种计算机视觉任务的开发，包括超分辨率、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新颖视角合成和视觉语言模型开发。此数据集为高分辨率外科成像领域的研究开辟了新的途径，有助于提升机器人辅助微创手术的性能、安全性和程序性。
## 620. `cs.LG` - 基于有限应变弹性的物理信息图神经网络重建局部场 [PDF](https://arxiv.org/pdf/2507.05291), [HTML](https://arxiv.org/abs/2507.05291)
### Authors
Manuel Ricardo Guevara Garban,Yves Chemisky,Étienne Prulière,Michaël Clément
### Background
本文提出了一个结合物理信息的机器学习框架P-DivGNN，用于多尺度仿真条件下周期性微观结构网格和均一宏观应力值下重建微观尺度的局部应力场。该方法基于将微观结构表示为图，并结合消息传递图神经网络。该研究着重于在宏微观尺度应力分析和局部疲劳准则定义时，局部应力场预测的重要性，考虑了线性和非线性超弹性响应的应用。对于非线性超弹性情况，所提出的方法相比有限元模拟显著提高了计算速度，使其成为大规模应用的优选方案。
### Innovation
提出了一个结合物理信息的图神经网络P-DivGNN，用于多尺度仿真重建局部应力场；该方法将微观结构表示为图，通过消息传递图神经网络进行信息传递；模型在训练过程中嵌入物理约束以限制局部应力场平衡态，并采用周期图表示以施加强制周期边界条件。该研究通过线性和非线性超弹性响应对不同几何形状的研究，评估了提出的物理信息图神经网络的优越性，特别是对于非线性超弹性情况下的显著计算速度提升。
### Conclusion
研究结果表明，P-DivGNN方法能够提供局部应力场分布，预测局部应力场对裂纹分析和定义局部疲劳准则尤为重要。对于非线性超弹性情况，该方法相比传统有限元模拟具有显著的计算效率优势，适合大规模应用。
## 621. `cs.LG` - 基于条件图神经网络预测柔软组织变形和作用力 [PDF](https://arxiv.org/pdf/2507.05315), [HTML](https://arxiv.org/abs/2507.05315)
### Authors
Madina Kojanazarova,Florentin Bieder,Robin Sandkühler,Philippe C. Cattin
### Background
在虚拟环境中模拟柔软组织对于医学应用变得越来越重要，但柔软组织的高变形性带来了巨大挑战。现有方法依赖于组织分割、网格生成和组织刚度特性估计。此外，集成触觉反馈需要精确的力估计，以提供更沉浸式的体验。
### Innovation
我们提出了一种新颖的数据驱动模型，即条件图神经网络（cGNN），以应对这一复杂性。该模型接收表面点和施力位置，专门用于预测点的变形及其上的作用力。模型通过实验收集的柔软组织仿生表面跟踪数据进行训练，并使用迁移学习来克服数据稀缺问题，首先是用刚体弹簧模拟训练，随后用实验数据进行微调。这种方法提高了模型的一般泛化能力，并允许准确预测组织变形及其相应的交互力。
### Conclusion
结果表明，该模型可以预测变形距离误差为0.35±0.03 mm（对于不超过30 mm的变形）和力的绝对误差为0.37±0.05 N（对于不超过7.5 N的力）。数据驱动的方法为虚拟环境中模拟柔软组织这一棘手问题提供了有前景的解决方案。除了在医学模拟中的应用外，该方法还可能为需要真实柔软组织仿真的其他领域带来益处。
## 622. `cs.LG` - 通过将策略改进设为约束来超越启发式方法 [PDF](https://arxiv.org/pdf/2507.05328), [HTML](https://arxiv.org/abs/2507.05328)
### Authors
Chi-Chang Lee,Zhang-Wei Hong,Pulkit Agrawal
### Background
在许多强化学习(RL)应用中，通过使用包含人类关于任务解决方式先验知识的启发性奖励来增强任务奖励是非常重要的，以实现理想的性能。然而，由于启发式不够理想，大量的人力和计算资源被浪费在仔细平衡任务和启发性奖励上。理论上，通过确保策略的性能与任务奖励最优策略相同来集成启发式的办法依赖于'策略不变性'的概念，但在实践中，这种方法并不能真正改进策略，并且已知其效果不佳。
### Innovation
作者提出了一种新的范式，以缓解奖励劫持，有效利用启发性方法，其目标是通过最大化策略改进而不是仅考虑改进策略来实现。所提出的框架Heuristic Enhanced Policy Optimization (HEPO)充分利用了启发式的优点，避免了之前方法的不足。HEPO在具有精心设计奖励函数的标准基准测试上表现出更优的效果。更令人惊讶的是，即使启发式不够理想且由非专家设计，HEPO也能够使策略优化达到良好的性能，这突显了HEPO减少在奖励设计中的人力投入的能力。HEPO是一个可以插即用的优化方法，用于强化学习中的启发式利用，代码已开源。
### Conclusion
HEPO在标准基准测试中表现优异，能够使策略优化即使在启发式不够理想且由非专家设计时也达到良好性能，展示了HEPO减少在奖励设计中的人力投入的能力。HEPO提供了一个可以插即用的优化方法，用于在强化学习中利用启发式。
## 623. `cs.LG` - 神经速度用于超参数调优 [PDF](https://arxiv.org/pdf/2507.05309), [HTML](https://arxiv.org/abs/2507.05309)
### Authors
Gianluca Dalmasso,Andrea Bragagnolo,Enzo Tartaglione,Attilio Fiandrotti,Marco Grangetto
### Background
超参数调优，例如学习率衰减和定义停止准则，通常依赖于监控验证损失。现有的方法往往需要一个保留的测试集来评估模型的表现。
### Innovation
提出了一种名为NeVe的动态训练方法，该方法根据每个神经元传输函数变化率的新颖概念“神经速度”来调整学习率和定义停止准则。神经速度可以仅通过在网络中传播噪声来估算，减少了对保留测试集的依赖。
### Conclusion
我们的研究结果表明，神经速度作为优化神经网络训练的关键指标具有潜在的优势。
## 624. `cs.LG` - 基于线性放宽的扰动分析的去概率化紧致化神经网络验证 [PDF](https://arxiv.org/pdf/2507.05405), [HTML](https://arxiv.org/abs/2507.05405)
### Authors
Luca Marzari,Ferdinando Cicalese,Alessandro Farinelli
### Background
神经网络验证过程中的形式验证工具计算成本较高，为了提高验证过程的效率，需要寻找既能保持验证精确性又能降低计算成本的方法。
### Innovation
提出了一种名为PT-LiRPA的新框架，该框架结合了基于LiRPA的方法和基于采样的方法来计算紧致的中间可达集。这种新的方法可以在几乎不增加计算开销的情况下，显著收紧神经网络输出的上下限线性边界，同时提供形式验证完整性的概率性保证。
### Conclusion
在国际神经网络验证比赛等多个标准形式验证基准上的实验表明，基于PT-LiRPA的验证器在可靠性证书上相比其他方法分别提高了3.31倍和2.26倍。而且，在最具挑战性的竞赛条目上，该概率性方法成功提供了高置信度的解决方案（即至少99%的置信度）。
## 625. `cs.LG` - EmissionNet: 农业空气质量污染预报 [PDF](https://arxiv.org/pdf/2507.05416), [HTML](https://arxiv.org/abs/2507.05416)
### Authors
Prady Saligram,Tanvir Bhathal
### Background
农业排放导致的空气污染是一个显著但经常被忽视的环境和公共健康问题。传统的空气质量预报模型依赖于基于物理的方法，这些方法难以捕捉复杂的非线性污染物相互作用。
### Innovation
本文通过评估流行架构，并提出两个新颖的深度学习架构，EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，探索通过高分辨率排放数据提取时空依赖性来进行N$_2$O农业排放的预报方法。
### Conclusion
所提出的EmissionNet和EmissionNet-Transformer架构利用卷积和变压器架构从高分辨率排放数据中提取时空依赖性，以改善对农业排放导致空气污染的预测能力。
## 626. `cs.LG` - 在因果干预独立性的支持下提高对抗因果干预数据分布偏移的鲁棒性 [PDF](https://arxiv.org/pdf/2507.05412), [HTML](https://arxiv.org/abs/2507.05412)
### Authors
Gautam Sreekumar,Vishnu Naresh Boddeti
### Background
现有方法在处理因果干预数据时没有利用干预所引起的因果关系信息，而是像对待观察数据一样处理，即使在因果模型已知的情况下也忽略了由这些干预产生的独立性关系。这样做会导致在观察数据和干预数据上的预测性能存在巨大差异，特别是在干预训练样本有限的情况下这种差异更加严重。
### Innovation
(1) 发现了性能差距与表征遵循由干预因果模型引起的独立性条件的一致性之间的强烈相关性。(2) 对于线性模型，给出了干预数据在训练数据集中所占比例的具体条件，使得保证干预节点及其非后裔对应的表示间的独立性可以减少干预数据上的错误。(3) 提出了可以明确在干预期间确保这种统计独立性的RepLIn训练算法。
### Conclusion
RepLIn在因果图中的节点数量增加时具有可扩展性，并且适用于改善连续和离散潜在变量的干预分布偏移的鲁棒表示。我们的实验表明，RepLIn在合成数据集和真实图像及文本数据集上的面部属性分类和毒性检测中展示了其效用。
## 627. `cs.LG` - 改进时间序列预测的外生变量时域窗口平滑 [PDF](https://arxiv.org/pdf/2507.05284), [HTML](https://arxiv.org/abs/2507.05284)
### Authors
Mustafa Kamal,Niyaz Bin Hashem,Robin Krambroeckers,Nabeel Mohammed,Shafin Rahman
### Background
大多数基于变换器的时间序列预测模型主要依赖内在输入。最近的先进方法通过使用外生输入显著提高了性能，但这些方法面临着内生和外生输入可能源自同一源头而导致的冗余问题，以及由于固定回溯窗口而难以捕捉长时依赖的挑战。
### Innovation
提出了一种方法，通过基于全局统计对外生输入进行去噪以减少数据中的冗余，并增强外生输入对长时间序列模式和趋势的意识。引入这种经过优化、具备全局上下文感知的外生输入到内在输入中，而在不增加回溯窗口长度的情况下，该方法引导模型获得更好的预测效果。
### Conclusion
我们的方法在四个基准数据集上达到了最先进的性能，一致地优于11种基线模型。这些结果确立了该方法作为一种稳健且有效的外生输入在时间序列预测中使用方法的潜力。
## 628. `cs.LG` - 无数据神经网络在资源约束项目调度中的应用 [PDF](https://arxiv.org/pdf/2507.05322), [HTML](https://arxiv.org/abs/2507.05322)
### Authors
Marc Bara
### Background
无数据神经网络代表了一种全新的方法，即将神经架构应用于组合优化问题，通过直接将问题实例编码进网络参数中，从而省去了训练数据集的需求。尽管Alkhouri等人（2022年）的工作证明了无数据方法在最大独立集问题上的可行性，但目前尚未有文献将这些方法扩展到资源约束项目调度问题（RCPSP）中。已有文献回顾发现这一领域的空白，因此本研究旨在用无数据神经网络填补这一空白，为RCPSP提供首个解决方案，并建立了数学模型将离散调度约束转换为适用于梯度优化的可微目标函数。
### Innovation
文章提出了一种全新的无数据神经网络方法来解决资源约束项目调度问题，通过数学建模将调度约束转换为可微目标函数，利用平滑松弛和自动微分技术实现项目调度中的GPU并行化。方法包括对先行和可再生资源约束的数学公式化细节，以及一种高效的密集时间网格表示法。此外，目前正在进行实证研究和实验，结果将在更新版本的论文中公布。
### Conclusion
本文通过无数据神经网络提供了解决资源约束项目调度问题的方法，填补了该领域的空白。该方法通过数学建模将调度约束转换为可微目标函数，利用平滑松弛和自动微分技术实现项目调度中的并行化，有望显著提高项目调度效率。
## 629. `cs.LG` - 因果基础模型：分离物理因素与仪器特性 [PDF](https://arxiv.org/pdf/2507.05333), [HTML](https://arxiv.org/abs/2507.05333)
### Authors
Jeroen Audenaert,Daniel Muthukrishna,Paul F. Gregory,David W. Hogg,V. Ashley Villar
### Background
在处理结构化时间序列数据的基础模型中，一个核心挑战是观测数据往往会将真实物理现象与测量仪器引入的系统性偏差混淆。这种混杂现象限制了模型在异构或使用多种仪器的场景中的泛化能力。因此，需要一种能够明确分离物理因素和仪器因素的方法。
### Innovation
该研究提出了一种受因果驱动的基础模型，该模型通过一个双编码器架构结合结构对比学习来明确分离物理信号和仪器效应。该模型利用自然出现的观测三元组（即，在不同条件下测量同一目标，或在相同条件下测量不同目标）来训练，以分别学习物理信号和仪器效应的潜在表示。
### Conclusion
通过在模拟的天文时间序列上进行评估，该方法在下游预测任务中明显优于传统的单潜在空间基础模型，尤其是在数据量较少的情况下。这些结果表明，该模型支持基础模型的关键能力，如少样本泛化和高效适应，并强调在结构化数据的表示学习中编码因果结构的重要性。
## 630. `cs.CV` - MedGemma 技术报告 [PDF](https://arxiv.org/pdf/2507.05201), [HTML](https://arxiv.org/abs/2507.05201)
### Authors
Andrew Sellergren,Sahar Kazemzadeh,Tiam Jaroensri,Atilla Kiraly,Madeleine Traverse,Timo Kohlberger,Shawn Xu,Fayaz Jamil,Cían Hughes,Charles Lau,Justin Chen,Fereshteh Mahvar,Liron Yatziv,Tiffany Chen,Bram Sterling,Stefanie Anna Baby,Susanna Maria Baby,Jeremy Lai,Samuel Schmidgall,Lu Yang,Kejia Chen,Per Bjornsson,Shashir Reddy,Ryan Brush,Kenneth Philbrick,Howard Hu,Howard Yang,Richa Tiwari,Sunny Jansen,Preeti Singh,Yun Liu,Shekoofeh Azizi,Aishwarya Kamath,Johan Ferret,Shreya Pathak,Nino Vieillard,Ramona Merhej,Sarah Perrin,Tatiana Matejovicova,Alexandre Ramé,Morgane Riviere,Louis Rouillard,Thomas Mesnard,Geoffrey Cideron,Jean-bastien Grill,Sabela Ramos,Edouard Yvinec,Michelle Casbon,Elena Buchatskaya,Jean-Baptiste Alayrac,Dmitry Lepikhin,Vlad Feinberg,Sebastian Borgeaud,Alek Andreev,Cassidy Hardin,Robert Dadashi,Léonard Hussenot,Armand Joulin,Olivier Bachem,Yossi Matias,Katherine Chou,Avinatan Hassidim,Kavi Goel,Clement Farabet,Joelle Barral,Tris Warkentin,Jonathon Shlens,David Fleet,Victor Cotruta,Omar Sanseviero,Gus Martins,Phoebe Kirk,Anand Rao,Shravya Shetty,David F. Steiner,Can Kirmizibayrak,Rory Pilgrim,Daniel Golden,Lin Yang
### Background
人工智能（AI）在医疗健康应用方面具有显著潜力，但其训练和运行面临着医疗健康数据种类多、任务复杂以及保护数据隐私的挑战。实现良好的医疗任务表现并减少特定任务调整数据量的基础模型对加速医疗AI应用的发展至关重要。为此，本文介绍了基于Gemma 3 4B和27B的医疗视觉-语言基础模型集合——MedGemma。MedGemma在图像和文本上的医学理解和推理表现显著，超出其相似规模生成模型的表现，甚至接近特定任务模型的性能，同时保持了Gemma 3基础模型的一般能力。对于分布外任务，MedGemma在医疗多模态问答上实现了2.6-10%的改进，在胸部X光发现分类上实现了15.5-18.1%的改进，并在代理评估上实现了10.8%的改进，优于基础模型。进一步微调MedGemma在亚领域进一步改进性能，通过减少电子病历信息检索错误50%，并在气胸分类和组织病理学图像分类方面达到了现有专门先进方法的可比性能。此外，还引入了基于SigLIP的医学调整视觉编码器MedSigLIP，它增强了MedGemma的视觉理解能力，作为编码器在性能上达到了或超过了专门医学图像编码器。
### Innovation
本文介绍的MedGemma集合提出了基于Gemma 3的医疗视觉-语言基础模型，显著提高了在图像和文本上的医学理解和推理。MedGemma在分布式任务上表现出色，其医学任务理解能力接近专门任务模型的水平。MedGemma集合还包括教程和模型权重，可以加速医学研究和下游应用的发展。特别地，提出了MedSigLIP，这是一种医学调整的视觉编码器，增强了MedGemma的视觉理解能力。
### Conclusion
MedGemma集合为医疗影像和文本提供了强大的基础能力，有望显著加速医疗领域的研究和应用发展。该集合包括教程和模型权重，可以在提供的网址中找到。
## 631. `cs.LG` - 动态遗憾归约为核化的静态遗憾 [PDF](https://arxiv.org/pdf/2507.05478), [HTML](https://arxiv.org/abs/2507.05478)
### Authors
Andrew Jacobsen,Alessandro Rudi,Francesco Orabona,Nicolo Cesa-Bianchi
### Background
本文研究在线凸优化中的动态遗憾问题，目标是相对于任意基准序列实现较低的累计损失。通过观察与任意基准序列$u_{1},…,u_{T}$在$text{W}⊂text{R}^{d}$中的竞争等同于与固定基准函数$u:[1,T]to text{W}$的竞争，本文将动态遗憾最小化问题重新构架为函数空间中的静态遗憾问题。
### Innovation
通过精心构建Reproducing Kernel Hilbert Space (RKHS)形式的合适函数空间，本文将动态遗憾问题转换成静态遗憾问题，从而在线性损失的情况下恢复了最优的动态遗憾保证$R_{T}(u_{1},…,u_{T}) = text{O}(text{sqrt}(text{sum}_{t}∑ℓ(u_{t}-u_{t-1})T))$。此外，本文提出的方法不局限于线性损失，适用于任何损失序列，从而在exp-凹和非恰当线性回归中恢复了$text{O}(ℓ^{2}+d_{text{eff}}(λ)text{ln} T)$的界，其中$d_{text{eff}}(λ)$是RKHS的复杂度度量。尽管在无限维空间工作，但利用RKHS的再生性质，所提出的减少方法能够形成可实践的算法。
### Conclusion
本文消耗了动态遗憾和静态遗憾之间的关系，提出了一种适用于任何损失序列的动态遗憾降低论题，对于线性损失实现了最优的动态遗憾保证，并在exp-凹和非恰当线性回归中得到了新的尺度不变且方向适应的动态遗憾保证。
## 632. `cs.CV` - 逃离柏拉图洞穴：使用JAM对独立训练的视觉与语言模型进行对齐 [PDF](https://arxiv.org/pdf/2507.01201), [HTML](https://arxiv.org/abs/2507.01201)
### Authors
Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim
### Background
独立训练的视觉和语言模型各自存在于不同的表示空间中，受各自的模态、目标和架构影响。然而，新兴的假设——柏拉图表示假设——提出这些模型可能向共享的真实世界的统计模型收敛。这种现有共同性的存在引发了这样一个基本问题：我们是否可以超越事后统计对齐的检测，明确地在这些独立表示之间优化它？
### Innovation
将柏拉图对齐问题描述为一个多目标优化任务，即，在保留各模态的天然结构的同时，通过重建和跨模态目标来促进一致性。引入了一个新的框架——联合自编码器调节器（JAM）框架，该框架通过训练预训练单模态模型的潜在表示的模态自编码器来同步进行模态特定的自编码器训练，以促进对齐。这种方法类比于帮助从不同输入中生成共享结构的逃避柏拉图洞穴的方法。
### Conclusion
实验结果表明，该轻量级的帕累托高效框架能够可靠地促进对齐，即使在冻结和独立训练的表示之间也能实现。这不仅提供了理论上的见解，还提供了将通用的单模态基础模型转换为专业的多模态模型的实际路径。
## 633. `cs.LG` - 2048：在延迟奖励环境中的强化学习 [PDF](https://arxiv.org/pdf/2507.05465), [HTML](https://arxiv.org/abs/2507.05465)
### Authors
Prady Saligram,Tanvir Bhathal,Robby Manihani
### Background
在强化学习（RL）中，延迟和稀疏的奖励构成了一个基本障碍。这使得RL代理难以将信用分配给其利益在许多步骤后才显现的行动。阻挡滑块游戏2048是这一挑战的典型例子：尽管频繁的小分值变化提供了即时反馈，但它们往往会误导代理采取局部最优但全局次优的策略。因此，需要一种统一的分布式多步RL框架来直接优化长期性能。
### Innovation
本文介绍了一种统一的、具有分布式学习特性的多步RL框架，该框架集成了分布式学习、 Dueling 结构、噪音网络、优先经验回放等多种先进技术。通过Gym-2048环境开发并比较了四种代理变种：标准DQN、PPO、QR-DQN（准分布回归DQN）和一种名为Horizon-DQN（H-DQN）的新型代理，它结合了上述多种方法。实验结果表明，这四种变种在最高游戏得分上表现出明显的梯度提升，H-DQN在实现41,828分及4096级块方面表现出色。这显示了在稀疏奖励领域，分布式的多步目标显著增强了性能，也为未来的基于模型的计划和渐进式学习方面进一步改进提供了前景。
### Conclusion
实验评价表明，H-DQN在2048游戏中表现最佳，达到41,828分及4096级块。这些结果证明，分布式的多步目标在稀疏奖励环境中显著提高了性能，并暗示了通过基于模型的规划和渐进式学习进一步提升性能的潜力。此框架为实现更优的长期性能提供了一个强有力的方法。
## 634. `cs.LG` - AXLearn：在异构基础设施上模块化的大模型训练 [PDF](https://arxiv.org/pdf/2507.05411), [HTML](https://arxiv.org/abs/2507.05411)
### Authors
Mark Lee,Tom Gunter,Chang Lan,John Peebles,Hanzhi Zhou,Kelvin Zou,Sneha Bangalore,Chung-Cheng Chiu,Nan Du,Xianzhi Du,Philipp Dufter,Ruixuan Hou,Haoshuo Huang,Dongseong Hwang,Xiang Kong,Jinhao Lei,Tao Lei,Meng Li,Li Li,Jiarui Lu,Zhiyun Lu,Yiping Ma,David Qiu,Vivek Rathod,Senyu Tong,Zhucheng Tu,Jianyu Wang,Yongqiang Wang,Zirui Wang,Floris Weers,Sam Wiseman,Guoli Yin,Bowen Zhang,Xiyou Zhou,Danyang Zhuo,Cheng Leong,Ruoming Pang
### Background
作者设计并实现了一个名为AXLearn的深度学习系统，该系统支持大规模深度学习模型的高效训练。相比于其他最先进的深度学习系统，AXLearn的独特之处在于其模块化设计以及对异构硬件基础设施的支持。AXLearn内部软件组件之间的接口遵循严格的封装性要求，这使得不同的组件可以灵活组装，从而能够快速进行模型开发和异构计算基础设施上的实验。
### Innovation
AXLearn引入了一种新的模块化度量方法，通过代码行（LoC）复杂性来定量量化。这种方法证明了在AXLearn系统中随着组件添加，保持常数的复杂度，而其他系统则表现为线性或二次复杂度。这使得在AXLearn中只需10行代码即可整合诸如Rotary Position Embeddings（旋转位置嵌入）等特性到分布在数百个模块中，而在其他系统中则需要数百行代码。此外，AXLearn在性能上与最先进的训练系统相当。
### Conclusion
作者分享了AXLearn在开发和运营方面的经验。AXLearn提供了一种模块化且高性能的大模型训练解决方案，特别适用于异构硬件基础设施。
## 635. `cs.LG` - 利用最大违反多目标攻击进行金融报告对抗机器学习攻击 [PDF](https://arxiv.org/pdf/2507.05441), [HTML](https://arxiv.org/abs/2507.05441)
### Authors
Edward Raff,Karen Kukla,Michel Benaroch,Joseph Comprix
### Background
恶劣行为者，主要是陷入困境的公司，有动机和意愿操纵他们的财务报告以隐藏其困境并获得个人收益。这些作为攻击者的公司在潜在的数百万美元利益和大量公开披露的财务建模框架的可用性的驱动下行事。现有的攻击方法无法在这类数据上工作，因为攻击者要成功必须同时满足相互关联的攻击目标。
### Innovation
我们引入了最大违反多目标（MVMO）攻击，这是一种适应攻击者搜索方向的攻击方法，相比标准攻击能够找到20倍更具说服力的攻击方式。结果表明，在约50%的情况下，一个公司能够将其收益夸大100-200%，同时降低其欺诈评分15%。通过与律师和专业会计师的合作，我们确保了我们的威胁模型在实际中是现实的，反映了此类欺诈是如何实际进行的。
### Conclusion
在约50%的情况下，公司可以通过采用MVMO攻击夸大其收益并同时降低其欺诈评分，攻击者可以通过调整搜索方向来有效地利用攻击目标，从而使攻击更具说服力。通过与专业人士的合作，我们保证了模型的真实性和实用性。
## 636. `cs.LG` - Explainable Hierarchical Deep Learning Neural Networks (Ex-HiDeNN) [PDF](https://arxiv.org/pdf/2507.05498), [HTML](https://arxiv.org/abs/2507.05498)
### Authors
Reza T. Batley,Chanwook Park,Wing Kam Liu,Sourav Saha
### Background
数据驱动的科学和计算在使用可训练参数构建复杂功能关系方面取得了巨大的进步。然而，从复杂的数据集中高效地发现可解释且精确的闭式表达式仍然是一个挑战。
### Innovation
本文提出了一种新颖的方法，名为Explainable Hierarchical Deep Learning Neural Networks (Ex-HiDeNN)，它使用准确、经济、快速、可分和可扩展的神经架构与符号回归相结合，从有限的观察中发现闭式表达式。Ex-HiDeNN算法包括一个分离性检查器，该算法在多个基准问题上得到了测试，包括根据数据识别动力系统，并报告了结果。该方法在这些基准上的表现优秀，产生的误差比参考数据和传统符号回归小很多倍。Ex-HiDeNN 应用于三个工程应用，具体包括：a) 发现疲劳方程的闭式表达式；b) 从微观压痕测试数据中识别硬度；c) 从数据中发现表征面。在每种情况下，Ex-HiDeNN 都超越了文献中使用的参考方法。
### Conclusion
提出的Ex-HiDeNN 是在作者已经在发表的作品的基础上建立起来的，提供了关于Ex-HiDeNN 目前局限性和未来扩展的清晰思路。
## 637. `cs.LG` - 强化微调自然减轻连续后训练中的遗忘 [PDF](https://arxiv.org/pdf/2507.05386), [HTML](https://arxiv.org/abs/2507.05386)
### Authors
Song Lai,Haohan Zhao,Rong Feng,Changyi Ma,Wenzhuo Liu,Hongbo Zhao,Xi Lin,Dong Yi,Min Xie,Qingfu Zhang,Hongbin Liu,Gaofeng Meng,Fei Zhu
### Background
连续后训练（CPT）是适应基础模型（如多模态大型语言模型）到特定的不断演化的下游任务的一种流行且有效的方法。尽管现有的研究主要集中在数据重播、模型扩展或参数正则化等方法上，CPT 中学习范式的根本作用仍然很少被探索。本研究通过对两种核心后训练范式的比较分析——监督微调 (SFT) 和强化微调 (RFT)——来调查它们在 CPT 中对知识保持的影响。实验在包含七种不同多模态任务的基准测试上进行，基础模型使用 Qwen2.5-VL-7B-Instruct 对 CPT 进行连续训练。研究表明，SFT 和 RFT 对知识保持的影响有显著差异。SFT 在连续学习下游任务时会导致灾难性遗忘，而 RFT 能保持先前的知识并在单任务训练中达到类似的效果。进一步分析发现，决定性因素是 RFT 内在的隐式正则化作用，而不是显式机制，如 KL 惩罚和思考链推理在缓解遗忘方面的作用。
### Innovation
研究提出了一个基于回放的实例过滤算法以提高 RFT 的稳定性和效率。研究发现 RFT 在缓解遗忘方面具有优越性，并提出了一个重要因素，即 RFT 内在的隐式正则化作用。
### Conclusion
强化微调（RFT）作为一种稳健的连续后训练范式，能够自然地减轻遗忘。相较于监督微调（SFT），RFT 能够保护甚至增强模型的通用知识，而 SFT 则严重破坏通用模型的能力。
## 638. `cs.LG` - 异质因果学习在优化用户增长聚合函数中的应用 [PDF](https://arxiv.org/pdf/2507.05510), [HTML](https://arxiv.org/abs/2507.05510)
### Authors
Shuyang Du,Jennifer Zhang,Will Y. Zou
### Background
用户增长是消费互联网公司的主要战略。为了优化昂贵的营销活动并通过最大化用户参与度来提升效果，本文提出了一种新颖的治疗效应优化方法来增强用户增长营销。通过利用深度学习，我们的算法从过往实验中学习，优化用户的选择和奖励分配，从而最大化活动影响并减少成本。传统预测方法通常只能预测关键业务指标的变化，而我们的模型可以直接建模这些指标的变化，而且深度学习模型可以使用softmax门控联合优化多个参数以达到整体损失函数的最小化。我们方法优于传统方法之处在于直接针对业务指标，并展示了处理复杂业务约束的算法灵活性。
### Innovation
本文的方法直接针对关键业务指标进行建模而不只是预测其变化，进一步地，深度学习模型可以联合优化多个参数以达到整体损失函数的最小化。我们的方法在实际生产部署中已被验证，并通过与先进的技术如R-learner和因果森林进行比较，证明了其有效性和成本效率。
### Conclusion
我们的研究证明，被提出的方法可以显著超越现有的先进方法，成本效益高，并具有广泛的适用性。实验表明，我们的约束和直接优化算法相比最先进的方法可以提高超过20%的效果，证明了其在多种产品情景下的有效性和实际影响力。
## 639. `cs.LG` - 用InterpoLated Learning减轻捷径学习 [PDF](https://arxiv.org/pdf/2507.05527), [HTML](https://arxiv.org/abs/2507.05527)
### Authors
Michalis Korakakis,Andreas Vlachos,Adrian Weller
### Background
经验风险最小化（ERM）促使模型利用捷径，即训练数据中广泛存在的输入特征与标签之间的虚假相关性，但与任务无关。这种依赖性使得在少数样本上的泛化受到阻碍，因为在少数样本中这些相关性并不成立。现有的捷径缓解方法多为模型特异性的，难以调校，计算成本高，且未能改善学习表示。
### Innovation
我们提出了一种名为InterpoLated Learning (InterpoLL)的新方法，该方法通过插值多数类样本的表示，结合具有捷径缓解模式的近距离少数类样本的特征。这种方法削弱了捷径的影响，使模型能够学习在少数类和多数类样本上都有效的特征。实验结果表明，InterpoLL在多个自然语言理解任务中提高了少数类样本的泛化性能，而不会牺牲多数类样本的准确性。这种方法在编码器、编码器-解码器和纯解码器架构上均有效表现，显示了其广泛的应用性。
### Conclusion
实验结果表明InterpoLL在多个自然语言理解任务中提高了少数类样本的泛化性能，而不会牺牲多数类样本的准确性。该方法在不同类型的神经网络架构上均有效，展示了其广泛的适用性。
## 640. `cs.LG` - 连续和结构化策略下的深度学习方法及其对聚合异质治疗效应的应用 [PDF](https://arxiv.org/pdf/2507.05511), [HTML](https://arxiv.org/abs/2507.05511)
### Authors
Jennifer Y. Zhang,Shuyang Du,Will Y. Zou
### Background
随着异质治疗效果（HTE）的估算在各种科学和工业应用中的广泛应用，治疗方法的空间自然扩展，从二元治疗变量变为结构化的治疗策略。这种策略可以包括多个策略因素，如连续治疗强度变量或离散治疗分配。基于第一原理，我们推导了将多个治疗策略变量纳入个体和平均治疗效果函数的形式。在此基础上，我们开发了一种直接使用聚合HTE函数对受试者进行排序的方法。具体来说，我们构建了一个在深度学习框架内增加的神经增强朴素贝叶斯层，以包含任何数量的满足朴素贝叶斯假设的因素。该因子层随后应用于连续治疗变量、治疗分配和聚合治疗效应函数的直接排序。
### Innovation
我们提出了一种基于第一原理推导的将多个治疗策略变量纳入个体和平均治疗效果函数的方法。进一步开发了一个在深度学习框架内的神经增强朴素贝叶斯层，以包含任意数量的因素，同时满足朴素贝叶斯假设。这种因子层应用于连续治疗变量、治疗分配，并通过聚合治疗效应函数对受试者进行直接排序，构建了一个通用框架用于深度学习异质治疗策略，并展示了其在公共数据集上的性能改进。
### Conclusion
这些算法结合构建了一个通用框架，用于深度学习异质治疗策略，展示了其显著提升性能的能力。
## 641. `cs.LG` - 基于知识的前后向探索 [PDF](https://arxiv.org/pdf/2507.05477), [HTML](https://arxiv.org/abs/2507.05477)
### Authors
Núria Armengol Urpí,Marin Vlastelica,Georg Martius,Stelian Coros
### Background
零样本强化学习在缺乏具体奖励的情况下是必需的，以便快速适应未来的环境设置。前向-后向表示（FB）已经成为一种有前途的方法，在没有奖励的情况下学习最优策略，基于策略占用度量的因式分解。然而，此前FB以及许多类似的零样本强化学习算法都与探索问题相分离，通常依赖于其他探索算法来采集数据。
### Innovation
本文设计了从FB表示自然衍生的探索策略，这些策略旨在最小化FB表示的后验方差，即最大限度地降低其认识不确定性。实验证明，这种基于知识的探索策略大幅提升了FB算法的样本复杂性，相比其他探索方法表现更佳。
### Conclusion
本文展示了基于知识的前后向探索策略在提升FB算法样本复杂性方面的显著优势。
## 642. `cs.LG` - 使用Stein扩散指导在稀疏分子数据中导航 [PDF](https://arxiv.org/pdf/2507.05482), [HTML](https://arxiv.org/abs/2507.05482)
### Authors
Van Khoa Nguyen,Lionel Blondé,Alexandros Kalousis
### Background
最近，随机最优控制（SOC）已成为为改善扩散模型的一种原则性框架，但是其依赖于计算密集型模拟的特点使其在快速采样中不可行。与此同时，已经开发出了一类无需训练的方法，这些方法使用预先分类的无噪声样本引导扩散模型，从而绕过了对训练器的训练需求。然而，这些直接的近似方法可能引入显著错误，导致不可靠的引导。
### Innovation
本文提出了一种新的无需训练的扩散引导框架，基于替代随机最优控制目标。通过将问题与Stein变分推理联系起来，该方法确定了最优的最陡下降方向，以最小化两个后验之间的Kullback-Leibler偏差，进而提出了一种新的价值函数理论界，证明了对近似后验进行校正的必要性。这种新的校正机制包含了一个全新的运行代价函数，使得在低密度区域中能够有效引导。实验结果表明，Stein扩散引导（SDG）显著优于标准的无需训练的引导方法，显示了它在更广泛的应用中的潜力。
### Conclusion
本研究提出了一种新的无需训练的Stein扩散引导框架，通过理论分析和实验验证，证明了其在复杂分子生成任务中的性能优于现有方法，开拓了该领域的研究前景。
## 643. `cs.LG` - 通过外部知识的潜在空间约束实现噪声图上的稳健学习 [PDF](https://arxiv.org/pdf/2507.05540), [HTML](https://arxiv.org/abs/2507.05540)
### Authors
Chunhui Gu,Mohammad Sadegh Nasr,James P. Long,Kim-Anh Do,Ehsan Irajizad
### Background
现有的图神经网络（GNN）在处理噪声边时表现不佳。
### Innovation
提出了Latent Space Constrained Graph Neural Networks (LSC-GNN)，通过引入清洁边来指导噪声目标图的嵌入，并通过训练两个编码器之间的潜在表示差异来约束其模型，防止过度拟合噪声。
### Conclusion
LSC-GNN 在带有噪声的基准图数据集中比标准和抗噪 GNN 更表现出色，同时通过扩展到异构图并在小规模蛋白质-代谢物网络上进行验证，进一步证明了其在噪声关系结构设置中提高预测性能和可解释性的潜力。
## 644. `cs.LG` - 基于辅助信息的深度潜在变量模型的手部载荷估计 [PDF](https://arxiv.org/pdf/2507.05544), [HTML](https://arxiv.org/abs/2507.05544)
### Authors
Jingyi Gao,Sol Lim,Seokhyun Chung
### Background
机器学习方法在手动物料搬运的人体工效风险评估中越来越被应用，特别是在通过穿戴式传感器采集的步态运动数据来估算手部负荷方面。然而，现有方法经常依赖于加载步态与手部负荷之间的直接映射，这限制了其推广性和预测准确性.
### Innovation
该研究提出了一种增强的手部载荷估算框架，该框架融合了辅助信息，包括无载行走的基本步态模式和搬运方式。模型结合了深度潜在变量建模和时序卷积网络以及双向交叉注意力机制，以捕捉步态动态并融合加载和未加载的步态模式。
### Conclusion
实验结果显示，通过融合辅助信息，模型在实际数据中的准确度显著提高，并强调了使用显式融合机制的重要性，而传统的特征拼接方法并不有效.
## 645. `cs.LG` - 渐进位翻转故障攻击：通过逐步位搜索击垮图神经网络 [PDF](https://arxiv.org/pdf/2507.05531), [HTML](https://arxiv.org/abs/2507.05531)
### Authors
Sanaz Kazemi Abharian,Sai Manoj Pudukotai Dinakarrao
### Background
图神经网络(GNNs)已成为处理图结构数据的强大机器学习方法。许多硬件加速器被用来满足实际应用中GNNs的性能需求。然而，基于硬件的攻击安全问题通常被忽视。本文研究了基于硬件的故障攻击对图神经网络模型的脆弱性，特别是在记忆设备中通过故障注入修改训练权重参数来尝试误导输出的问题。
### Innovation
提出了一种基于逐位搜索的图神经网络层感知故障攻击(GBFA)，该攻击通过逐步选择每个选定权重中的易受攻击的位来最小化翻转位数量以破坏模型性能。GBFA采用两步操作：首先，通过从内存访问模式中提取的特征创建马尔可夫模型，预测各层的执行顺序，以在特定层发起攻击；其次，通过层内搜索使用梯度排名来识别选定权重中的易受攻击的位。
### Conclusion
实验结果表明，GBFA显著降低了预测准确性，且不同层的影响差异突显了在图神经网络中采用层感知攻击策略的重要性。例如，在Cora数据集上，仅在最后一层翻转一个位即可使GraphSAGE的预测准确度下降17%。
## 646. `cs.LG` - 图神经网络的理论学习性能：跳跃连接和分层稀疏化的影响 [PDF](https://arxiv.org/pdf/2507.05533), [HTML](https://arxiv.org/abs/2507.05533)
### Authors
Jiawei Sun,Hongkang Li,Meng Wang
### Background
该研究探讨了图卷积网络（GCNs）在稀疏化和跳跃连接方面的学习动态和泛化性能。背景信息指出，虽然跳跃连接帮助GCNs克服过度平滑问题，并且图稀疏化通过在邻域聚合期间选择图邻接矩阵的子矩阵来降低计算需求，但现有文献在理论泛化保证方面对此缺乏深入了解，尤其是在同时考虑这两种因素的情况下。
### Innovation
本文首次对同时使用跳跃连接和图稀疏化的GCNs的学习动态和泛化保证进行了分析。研究发现，GCNs的学习模型泛化准确性紧密接近由提出的稀疏有效邻接矩阵$A^*$定义的目标函数类中的最高可能准确性。此外，研究揭示了不同层在稀疏化需求上的差异性影响。
### Conclusion
本研究通过理论分析表明，当稀疏化保留支持有意义消息传递的关键边时，图稀疏化能够保持良好的泛化性能。研究还发现，在两隐层GCN中，第一层的稀疏化矩阵偏离$A^*$的影响比第二层更大，这标志着首次对跳跃连接在稀疏化需求中的作用进行了理论描述。研究结果在基准数据集上的实证验证支持了这些结论。
## 647. `cs.LG` - 在强化学习系统中检测和缓解奖励欺骗：一项全面的经验研究 [PDF](https://arxiv.org/pdf/2507.05619), [HTML](https://arxiv.org/abs/2507.05619)
### Authors
Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma
### Background
强化学习（RL）系统中的奖励欺骗对自主代理的部署构成关键威胁，代理利用奖励函数中的缺陷来实现高分数而不满足预期目标。尽管对此问题的认识正在增长，但系统化检测和缓解的方法仍然有限。本研究通过广泛的经验研究，分析了不同RL环境和算法中的奖励欺骗，旨在提高对这一问题的理解和处理能力。
### Innovation
该研究提出了一个全面的经验框架，以大规模地研究不同RL环境和算法中的奖励欺骗。研究实施了自动检测算法，对六类奖励欺骗行为进行分类检测：规范游戏、奖励篡改、代理优化、目标错位、利用模式和短路行为。此外，研究通过控制实验验证了奖励密度与真正目标之间的对齐程度对奖励欺骗频率的显著影响，并提供了在推荐系统、竞技游戏、机器人控制等场景中应用该方法的有效验证。研究还提出了缓解措施，可将受控场景中的奖励欺骗频率降低高达54.6%。研究成果和数据分析均公开以支持RL安全性中可重复研究的发展。
### Conclusion
研究展示了通过提高对奖励欺骗的理解，改善检测算法和缓解措施在实践中可降低奖励欺骗的风险。虽然存在概念漂移、假阳性成本和对抗调整等问题，但总体上证明了缓解奖励欺骗的有效性。
## 648. `cs.LG` - 使用WiFi日志中的图形卷积神经网络进行动态校园起止地移动预测 [PDF](https://arxiv.org/pdf/2507.05507), [HTML](https://arxiv.org/abs/2507.05507)
### Authors
Godwin Badu-Marfo,Bilal Farooq
### Background
该研究提出了一种用于预测校园建筑占用和建筑物间移动的集成图基神经网络架构，考虑动态时间分辨率。该架构利用Wi-Fi日志和建筑物内使用计划来学习交通流动模式。该研究的目标是直接从Wi-Fi数据中估计相对交通流量，而不假设人员的行为或偏好，同时保持个人隐私。所提出的方法是对Wi-Fi日志进行数据驱动的图形结构表示和优化。
### Innovation
该研究创新地提出了一种新颖的图卷积加上长短时记忆神经网络（GCLSTM），展示了其在建模复杂模式方面显著的成功，并且直接从Wi-Fi数据中估计相对交通流量，而不依赖于人员的行为或偏好，这种方法在预测校园动态校园起止地移动方面优于传统的人行道流量估计器如多层感知器（MLP）和线性回归。
### Conclusion
实验证明，集成的GCLSTM模型在对实时Wi-Fi数据进行处理和预测校园动态人流方面明显优于传统的多层感知器（MLP）和线性回归模型。所提出的方法展示了在校园环境中预测人流模式的潜力，并为维护隐私的同时进行人群行为分析提供了新的视角。
## 649. `cs.LG` - 图学习 [PDF](https://arxiv.org/pdf/2507.05636), [HTML](https://arxiv.org/abs/2507.05636)
### Authors
Feng Xia,Ciyuan Peng,Jing Ren,Falih Gozi Febrinanto,Renqiang Luo,Vidya Saikrishna,Shuo Yu,Xiangjie Kong
### Background
图学习已经迅速发展成为机器学习和人工智能（AI）领域的一个关键子领域。其发展始于早期的图论方法，并在图神经网络（GNN）的出现后获得显著动力。过去十年间，通过可扩展架构、动态图建模、多模态学习、生成型AI、可解释性AI（XAI）以及负责任AI的进步，图学习的应用范围已扩展到多种具有挑战性的环境。由于其能够模拟传统机器学习难以捕捉的复杂非欧几里得关系的能力，图学习在从药物发现和欺诈检测到推荐系统和科学推理等众多实际应用中发挥着重要作用。然而，为了充分发挥其潜力，仍需解决可扩展性、泛化能力、异质性、可解释性和可信度等诸多挑战。
### Innovation
这份综述全面介绍了图学习的关键维度，包括可扩展的图学习、时间上的图学习、多模态图学习、生成型图学习、可解释型图学习和负责任的图学习。它回顾了目前最先进的技术，包括高效处理大规模图、捕捉动态时间依赖性、集成异质数据模态、生成新颖图样本以及增强可解释性以促进信任和透明度。此外，还探讨了隐私和公平等伦理问题，确保图学习模型的负责任部署。同时，识别并讨论了新兴主题，强调了图学习与其他AI范式的最新整合，并提出了未来方向的见解。
### Conclusion
这份综述作为资源，为寻求探索图学习迅速变化的领域的研究人员和从业者提供了宝贵的指导。
## 650. `cs.LG` - 超越通信开销：分布式学习中缓解压缩偏差的多级蒙特卡罗方法 [PDF](https://arxiv.org/pdf/2507.05508), [HTML](https://arxiv.org/abs/2507.05508)
### Authors
Ze'ev Zukerman,Bassel Hamoud,Kfir Y. Levy
### Background
分布式学习方法近年来获得了巨大发展，但通信开销常常成为关键瓶颈。尽管梯度压缩技术能够降低通信成本，但它们存在固有的权衡，即有偏压缩虽然提高了效率，但缺乏理论保证，而无偏压缩则需要更多的计算资源。
### Innovation
本文提出了一种新颖的多级蒙特卡罗（MLMC）压缩方案，该方案利用有偏压缩器构建统计无偏估计，从而在有偏和无偏方法之间形成有效桥梁，并结合了两者的优势。所提出的方法不仅应用到常见的压缩器（如Top-$k$和位压缩器）中，还得到了适应性版本以进一步提高性能。
### Conclusion
通过在分布式深度学习任务上的实证验证，本文方法有效缓解了压缩偏差问题，展现了其在提高通信效率和计算复杂性之间取得的均衡。
## 651. `cs.LG` - 未来问题预防性求解：人类与机器的多任务预演 [PDF](https://arxiv.org/pdf/2507.05561), [HTML](https://arxiv.org/abs/2507.05561)
### Authors
Wilka Carvalho,Sam Hall-McMaster,Honglak Lee,Samuel J. Gershman
### Background
人类能够追求几乎无限多样的任务，但在同一时间通常只能追求有限数量的任务。我们假设人类利用在一个任务上的经验，预先学习到其他可访问但未追求的任务的解决方案。这种想法被形式化为多任务预演算法，这是一种新颖的算法，它在一个任务上回放经验，以此作为“预演”的起点——这是一个针对可访问但未追求任务的反事实模拟。预演用于学习预测表示，这可以支持之后的快速和自适应任务绩效。这项研究首先展示了与传统的规划和预测表示方法相比，多任务预演在小网格世界中更好地预测了人们如何将可访问但未追求的任务上的泛化性能，即使人们并不知道他们需要泛化到这些任务。随后，这些预测在Craftax（一个部分可观察的2D Minecraft环境）中得到了验证。最后，研究还表明，多任务预演使人工代理能够学习在新的Craftax世界中的行为，这些新世界中的任务共现结构与原有世界相似。这些发现表明，多任务预演是一种可扩展的理论，可以解释人类如何在多个任务之间进行反事实学习和泛化。赋予人工代理相同的能力可以显著提高它们在多任务环境中的性能。
### Innovation
提出了一种新颖的算法——多任务预演（Multitask Preplay），它模拟了人类如何利用在一个任务上的经验来预先学习到其他可访问但未追求的任务的解决方案。该算法在小网格世界和Craftax环境中得到了验证，并且能够让人工代理在新的Craftax世界中学习到与原有世界共享任务共现结构的行为，这证明了这种理论的可行性。
### Conclusion
多任务预演提供了一种理论，解释了人类如何在多个任务之间进行反事实学习和泛化。赋予人工代理相同的能力可以显著提高它们在多任务环境中的性能。
## 652. `cs.LG` - 通过联邦混合专家高效训练大规模AI模型：系统级方法 [PDF](https://arxiv.org/pdf/2507.05685), [HTML](https://arxiv.org/abs/2507.05685)
### Authors
Xiaobing Chen,Boyang Zhang,Xiangwei Zhou,Mingxuan Sun,Shuai Zhang,Songyang Zhang,Geoffrey Ye Li
### Background
联邦学习（FL）和混合专家（MoE）的结合为在去中心化数据上训练更强大的大规模人工智能模型（LAMs）提供了可能，同时保护隐私。然而，高效的联邦训练复杂MoE结构的LAMs受到系统级挑战的阻碍，特别是在管理和协调异质客户端资源以及众多专业专家之间复杂的交互方面的挑战。作者指出，缺乏有效的量化策略来动态对客户和专家进行匹配，这忽视了客户容量的变化和系统负载平衡的需求。文章指出这一关键但未被充分探究的概念，并强调需求一种全景式的系统设计方案，以实现智能客户端-专家对齐，包括动态适应性评分、全局专家负载监控和客户端容量概况。
### Innovation
提出了一种智能客户端-专家对齐的概念系统设计，其中包括动态适应性评分、全局专家负载监控和客户端容量概况。这种方法旨在解决系统级问题，以解锁更可扩展、高效和可靠的训练机制（减少通信轮数以实现收敛），从而为在边缘计算中广泛部署大规模的联邦MoE结构LAMs铺平道路，并达到超高的通信效率。
### Conclusion
通过联邦混合专家的智能客户端-专家对齐策略，可以为超大规模边缘计算中LAMs的高效训练过程提供支持，确保更好的系统负载平衡和通信效率。这种方法为部署复杂的分布式AI模型提供了新的解决方案途径。
## 653. `cs.LG` - MobileGUI-RL：通过在线环境中的强化学习推进移动GUI代理 [PDF](https://arxiv.org/pdf/2507.05720), [HTML](https://arxiv.org/abs/2507.05720)
### Authors
Yucheng Shi,Wenhao Yu,Zaitang Li,Yonglin Wang,Hongming Zhang,Ninghao Liu,Haitao Mi,Dong Yu
### Background
近期，通过视觉得出的GUI代理被设计用于自动化日常的移动和网页任务。这些代理能够解读原始的GUI屏幕截图，并自主决定去哪里点击、滚动或输入内容，从而省去了人为编写的规则和应用程序特定的API。然而，大多数现有的方法都是在离线环境中训练GUI代理，并使用预先收集的轨迹。这种方法限制了可扩展性，导致对特定UI模板的过度拟合，并且在面对未见过的环境时导致了脆弱的策略。
### Innovation
MobileGUI-RL是一个可扩展的框架，用于在线环境中训练GUI代理。MobileGUI-RL包含两个关键组件：(i)通过自我探索和过滤生成可学习的任务课程；(ii)将GRPO适应于GUI导航，并引入基于轨迹的优势和复合奖励来平衡任务的成功执行和效率。
### Conclusion
在三个在线移动代理基准测试上的实验表明，MobileGUI-RL方法具有稳定的优势，验证了该方法的有效性。
## 654. `cs.LG` - 基于深度强化学习的分层任务卸载方法用于无人机辅助车载边缘计算 [PDF](https://arxiv.org/pdf/2507.05722), [HTML](https://arxiv.org/abs/2507.05722)
### Authors
Hongbao Li,Ziye Jia,Sijie He,Kun Guo,Qihui Wu
### Background
由于车路协同网络中出现了计算密集且延迟敏感的应用，无人机(UAVs)由于其高移动性和灵活部署特性，被认为是一个有前景的补充，用于车载边缘计算。然而，现有的无人机辅助卸载策略在协调异构计算资源和适应动态网络条件方面仍存在不足。
### Innovation
提出了一种基于部分卸载的双层UAV辅助边缘计算架构，该架构利用高空无人机的中继能力和低空无人机的计算支持。为了优化系统延迟和能量消耗，同时确保任务完成率，提出了一个联合优化问题。通过将问题重新表述为马尔可夫决策过程，并基于软演员-评论家算法提出了一种分层卸载方案，实现了全局和局部决策的分离。
### Conclusion
通过仿真分析，所提出的方法在任务完成率、系统效率和收敛速度上优于几种基线方法，展示了在动态车载环境中的强大鲁棒性和适用性。
## 655. `cs.LG` - 通过适应的_flux平衡分析预测图结构 [PDF](https://arxiv.org/pdf/2507.05806), [HTML](https://arxiv.org/abs/2507.05806)
### Authors
Sevvandi Kandanaarachchi,Ziqi Xu,Stefan Westerlund,Conrad Sanderson
### Background
许多动态过程，如通信和运输网络，可以通过离散时间序列的图形来描述。通过建模这些时间序列的动力学可以预测未来时间步长的图形结构，这对于检测异常等应用非常有用。然而，现有的图形预测方法大多假定节点在连续时间步之间不改变。为了克服这种限制，本文提出了结合改进的_flux平衡分析（FBA）和时间序列预测方法的策略。FBA是一种起源于生物化学的线性规划方法，已适应于适用于增长图形场景的各种约束条件。
### Innovation
本文创新地将改进的_flux平衡分析与时间序列预测方法结合，克服了现有预测方法中节点在连续时间步之间不变的假设。FBA已被适应以包含适用于增长图形的场景的各种约束，从而提供了一种新颖的方法来预测图结构的动力学，这种方法可以在合成数据集（通过偏好连接模型构造）和实际数据集（UCI消息、HePH、Facebook、比特币）中验证其有效性。
### Conclusion
本文提出的方法能够有效预测图结构的动力学，并已在合成和实际数据集中得到了验证。这种方法能够应用于检测异常等领域，表现出较高的预测准确性。
## 656. `cs.LG` - Jigsaw: 使用优化的模型并行性训练多十亿参数的AI气象模型 [PDF](https://arxiv.org/pdf/2507.05753), [HTML](https://arxiv.org/abs/2507.05753)
### Authors
Deifilia Kieckhefen,Markus Götz,Lars H. Heyen,Achim Streit,Charlotte Debus
### Background
AI方法已彻底变革了大气预报，近期中程预报的成功推动了气候基础模型的发展。高空间分辨率及长时间范围的复杂大气动态准确建模需要大量的神经网络和巨大的数据样本，这导致了加速器内存和I/O带宽成为模型训练的瓶颈。
### Innovation
引入了WeatherMixer多层感知器架构，其工作负载随输入大小线性增长，使模型能够学习全球天气现象，精度与数值天气预测相当。提出了一种名为Jigsaw的新颖模型并行化方案，结合域并行性和张量并行性来消除内存冗余，增强了在计算通信受限系统中的强扩展性能，并在I/O带宽受限系统中实现了超线程弱扩展性能。
### Conclusion
将训练扩展至256个GPU，达到峰值性能为9和11 PFLOPs，分别占理论峰值的23%和28%，在无模型并行性的情况下，其扩展效率分别为68%和72%，远远高于无模型并行化的51%。
## 657. `cs.LG` - 从运动到意义：基于生物力学的神经网络实现可解释的心血管疾病识别 [PDF](https://arxiv.org/pdf/2507.05783), [HTML](https://arxiv.org/abs/2507.05783)
### Authors
Comte Valentin,Gemma Piella,Mario Ceresa,Miguel A. Gonzalez Ballester
### Background
心血管疾病是全球范围内导致疾病负担和死亡的重要原因之一，因此迫切需要准确及时的诊断策略。这项研究介绍了一种结合深度学习图像配准与物理知情正则化的创新方法，以预测移动心脏组织的生物力学特性和提取用于疾病分类的特征。通过使用新霍金准则材料的能量应变公式来建模心脏组织变形，优化变形场的同时确保其物理和生物力学的一致性。这种方法不仅提高了图像配准的准确性，还提供了对心脏组织内底层生物力学过程的见解。
### Innovation
该研究创新地结合了深度学习图像配准与物理知情正则化的方法，采用新霍金准则材料的能量应变公式来建模心脏组织变形，优化变形场的同时确保其物理和生物力学的一致性。此外，还通过估计心脏中的局部应变并提取详细的分类特征，使用包括逻辑回归、多层感知器、支持向量分类器、随机森林和最近邻在内的五种分类算法进行心血管疾病分类，通过特征选择算法识别出最相关特征，并取得了在ACDC数据集上98%的训练准确率和100%的测试准确率。这种方法使临床医生能够根据心脏力学透明地理解模型的预测，并大幅提高了心血管疾病诊断的准确性和可靠性，为更加个性化和有效的患者护理铺平了道路。
### Conclusion
该方法通过整合可解释的人工智能，不仅提高了心脏疾病诊断的准确性和可靠性，还赋予了临床医生透明理解模型预测的能力，从而为个性化和高效患者的护理提供了可能。
## 658. `cs.LG` - 使用近端策略优化进行现场强化学习的无模型光处理器 [PDF](https://arxiv.org/pdf/2507.05583), [HTML](https://arxiv.org/abs/2507.05583)
### Authors
Yuhang Li,Shiqi Chen,Tingyu Gong,Aydogan Ozcan
### Background
光学计算因高速和能源效率而充满希望，而衍射光学网络作为实现特定任务变换的灵活平台也开始显现潜力。然而，有效优化和对齐衍射层是具有挑战性的，这受到物理系统固有的硬件缺陷、噪声和对齐误差的影响。现有的现场优化方法虽然可以在不进行明确系统建模的情况下直接对物理系统进行训练，但往往受到有限测量数据和低效使用的影响，导致收敛速度慢和不稳定。
### Innovation
本文介绍了一种使用近端策略优化（PPO）进行无模型的现场培训的衍射光学处理器的强化学习方法。PPO可以高效地重用现场测量数据，并对策略更新进行约束，以确保更稳定的快速收敛。该方法在一系列现场学习任务中得到了验证，包括目标能量聚焦、全息图像生成、像差校正和光学图像分类等，每一项任务都表现出更好的收敛和性能。这种方法直接作用于物理系统，自然地考虑未知的真实世界缺陷，无需先验系统知识或建模。
### Conclusion
本文提出的方法可以在现实的实验约束下更快、更准确地训练，为各种受复杂、反馈驱动动力学控制的光学和物理系统提供一种可扩展的框架。
## 659. `cs.LG` - 公平的域泛化：一种信息论视角 [PDF](https://arxiv.org/pdf/2507.05823), [HTML](https://arxiv.org/abs/2507.05823)
### Authors
Tangzheng Lian,Guanyu Hu,Dimitrios Kollias,Xinyu Yang,Oya Celiktutan
### Background
域通用性（DG）和算法公平性是机器学习中的两个关键挑战。大多数DG方法仅专注于在未见过的目标域中最小化期望风险，而不考虑算法公平性。相反，公平性方法通常不考虑域偏移，因此训练期间实现的公平性可能无法推广到未见过的测试域。本文旨在通过研究公平域通用性（FairDG）问题来填补这一空白，目标是在未见过的目标域中同时最小化期望风险和公平问题。作者推导出了针对多类分类任务和多组敏感属性的新颖互信息上界，这些上界从信息论角度提供了算法设计的关键见解。
### Innovation
作者提出了PAFDG（针对域通用性的帕利托最优公平），这是一种实用框架，解决了FairDG问题并通过帕利托优化建模了效用-公平性权衡。这种方法在现实世界视觉和语言数据集上的实验表明，PAFDG相比现有方法实现了更优的效用-公平性权衡。
### Conclusion
PAFDG框架成功实现了在未见过目标域中的同时优化期望风险和公平性，提供了从信息论角度的新颖见解，并通过实验证明了其优势。
## 660. `cs.LG` - 用Soup-适配器提高基础模型在领域适应中的鲁棒性 [PDF](https://arxiv.org/pdf/2507.05807), [HTML](https://arxiv.org/abs/2507.05807)
### Authors
Marco Roschkowski
### Background
在少样本领域适应的基础模型中，超参数调优往往因缺乏大型验证数据集而不可行。此外，模型在测试时间数据与训练分布略有偏移时的鲁棒性也是一个值得关注的问题。
### Innovation
通过训练多个独立的适配器并平均它们的输出，新模型的性能更高，并且对于分布偏移更具有鲁棒性。即使使用广泛范围内不同超参数训练的适配器，也能取得这一改进。这种方法可以参数化回单个适配器，因此被称为Soup-适配器。此外，研究还率先探索了CLIP适配器风格的技术在DINOv2中的应用，并直接将其与CLIP进行了比较。
### Conclusion
我们的方法解决了领域适应中两个基本问题：超参数调优的不可行性以及由于测试时间数据与训练分布偏移导致的模型脆弱性。Soup-适配器不仅能提高模型的整体性能，还能显著降低对残差比这一关键超参数的敏感性。
## 661. `cs.LG` - 通过元学习估计具有不确定因果图的干预分布 [PDF](https://arxiv.org/pdf/2507.05526), [HTML](https://arxiv.org/abs/2507.05526)
### Authors
Anish Dhir,Cristiana Diaconu,Valentinian Mihai Lungu,James Requeima,Richard E. Turner,Mark van der Wilk
### Background
在多个科学领域（从生物学到社会科学），有许多问题都可以归结为‘如果我们干预某个变量，将会观察到什么效果？’已知因果关系（如因果图）的情况下，可以估计干预分布。然而，在缺乏这种先验知识的情况下，因果结构必须从可用的观察数据中发现。但由于观察数据通常与多个因果图兼容，这使得依赖单一结构的方法容易产生过度自信。有序管理这种结构不确定性的一种原则性方法是通过贝叶斯推断，即在可能的因果结构和功能机制的后验分布上进行平均。不幸的是，随着图中节点数量的增加，因果结构的数量呈超指数增长，导致计算变得不可行。
### Innovation
我们提出了一种基于元学习的端到端模型，即模型平均因果估算变压器神经过程（MACE-TNP），该模型可以预测贝叶斯模型平均的干预后验分布，并通过端到端的方式绕过了昂贵的计算需求。实证研究表明，MACE-TNP优于强贝叶斯基线。
### Conclusion
我们的研究确立了元学习作为一种灵活且可扩展的方法，用于近似复杂的贝叶斯因果推理，并可以在未来扩展到更挑战性的环境。
## 662. `cs.LG` - 利用物理导向神经网络实现稳健的电力系统状态估计 [PDF](https://arxiv.org/pdf/2507.05874), [HTML](https://arxiv.org/abs/2507.05874)
### Authors
Solon Falas,Markos Asprou,Charalambos Konstantinou,Maria K. Michael
### Background
现代电力系统在状态估计和实时监控方面面临巨大挑战，尤其是在故障条件下或遭受网络攻击时，对响应速度和准确性的要求尤为突出。
### Innovation
提出了一种结合物理导向神经网络（PINNs）的方法，以提高电力系统状态估计的准确性和稳健性。通过将物理定律嵌入神经网络架构中，PINNs改善了在正常和故障条件下的传输电网应用的估计准确度，并且展示了应对安全威胁（如数据操控攻击）的潜力。实验证明，与传统机器学习模型相比，该方法在未见过的训练数据集上的准确率提高了83%，在完全不同且未见过的数据集上的性能更好，提高了65%。特别地，在关键母线遭受数据操控攻击时，PINN的准确度比同等神经网络高93%。
### Conclusion
提出的基于PINNs的方法在故障条件下的电力系统状态估计中表现出色，比传统机器学习模型具有更高的准确性和鲁棒性。
## 663. `cs.LG` - 基于结构化知识图谱的概念驱动机制可解释性 [PDF](https://arxiv.org/pdf/2507.05810), [HTML](https://arxiv.org/abs/2507.05810)
### Authors
Sofiia Chorna,Kateryna Tarelkina,Eloïse Berthier,Gianni Franchi
### Background
概念驱动的可解释性方法通常专注于神经网络预测的局部解释。本文提出了一种新的框架和交互式工具，将这些方法扩展到机制可解释性的领域。该方法通过分析高层语义属性（称为概念）如何在内部模型组件中出现、相互作用和传播来实现对模型行为的全局解剖。与之前孤立分析单个神经元或预测的工作不同，该框架系统地量化了语义概念在各层中的表示，揭示了潜在的电路和信息流，这些电路和信息流是模型决策的基础。这一过程中采用的创新是名为BAGEL（Bias Analysis with a Graph for global Explanation Layers）的可视化平台，它以结构化的知识图谱形式呈现这些洞察，使用户能够探索概念-类关系，识别虚假相关性，并增强对模型的信任度。其框架具有模型无关性、可扩展性，并有助于对模型在数据集偏差存在情况下如何概括（或不能概括）的深入理解。研究结果已在https://example.com/上展示.
### Innovation
该研究的创新在于采用了一种新的框架和交互式工具，将传统的局部解释方法扩展到机制可解释性的领域，通过系统量化语义概念在各层中的表示，揭示潜在的电路和信息流，并通过BAGEL平台以结构化知识图谱形式展示这些洞察，以探索概念-类关系，识别虚假相关性，增强模型信任度。此外，该框架具有模型无关性、可扩展性，并有助于深入理解模型在数据集偏差情况下如何概括（或不能概括）.
### Conclusion
该框架有助于对机制可解释性有更深入的理解，并揭示了深度学习模型在数据集偏差情况下的概括或非概括行为。通过BAGEL平台，用户可以更好地探索和理解模型行为，增加模型的可信度。
## 664. `cs.LG` - 通用表格数据嵌入 [PDF](https://arxiv.org/pdf/2507.05904), [HTML](https://arxiv.org/abs/2507.05904)
### Authors
Astrid Franz,Frederik Hoppe,Marianne Michaelis,Udo Göbel
### Background
关系数据库中的表格数据占工业数据的重要部分，分析和解释表格数据极为重要。工业数据库的任务多样化且通常未具体说明，这使得通用性强、任务独立的表格数据嵌入框架成为必要。本文提出了一种新的框架，该框架可以将表格数据转换为图结构，利用图自编码器生成实体嵌入，并进一步汇总以获得每行表（即每个数据样本）的嵌入。这一两步方法的优点是可以对未见过的样本（其中包含相似实体）进行嵌入而无需额外的训练，下游任务如回归、分类或异常检测可以通过嵌入空间中的基于距离的相似性度量来实现。实验结果表明，本文方法在真实数据集上优于现有的通用表格数据嵌入技术。
### Innovation
提出了一种新的框架，用于生成任务独立的表格数据嵌入，可以将表格数据转换为图结构，并利用图自编码器生成实体嵌入，进一步汇总以获得每行表（即每个数据样本）的嵌入。这一两步方法能够对未见过的样本进行嵌入而无需额外的训练，适用于多种下游任务如回归、分类和异常检测。
### Conclusion
实验结果表明，本文方法在真实数据集上表现优于现有技术。
## 665. `cs.LG` - 犬类骨科和神经系统疾病的临床步态分析：惯性深度学习方法 [PDF](https://arxiv.org/pdf/2507.05671), [HTML](https://arxiv.org/abs/2507.05671)
### Authors
Netta Palez,Léonie Straß,Sebastian Meller,Holger Volk,Anna Zamansky,Itzik Klein
### Background
在兽医临床环境中，使用可穿戴惯性传感器进行犬类步态分析正引起关注，因其提供了对多种步态障碍的理解。即使是经验丰富的兽医，也无法轻易区分神经性和骨科性病因。因此，本研究探索并开发了使用惯性传感器读数的深度学习方法，以评估神经性和骨科性步态是否能够帮助步态分析。研究重点是优化这两种步态异常之间的区分性能和普适性，并提出了传感器配置、评估协议的改进以及深度学习模型架构的优化建议。通过29只狗的数据集，所提议的方法在三分类任务（健康/骨科/神经性）中的准确率为96%，在二分类任务（健康/非健康）中的普适性准确率为82%。这项研究结果表明，基于惯性的深度学习模型能够作为一种实用和客观的诊断和临床辅助工具，用于区分骨科和神经性条件下的步态评估。
### Innovation
研究提出了一种基于惯性传感器的深度学习方法，用于区分狗的骨科和神经性步态异常。该方法通过优化算法性能和提高模型的普适性，实现了在三分类任务中96%的准确率和二分类任务中82%的普适性准确率。
### Conclusion
惯性基深度学习模型具有作为实用和客观的诊断工具，帮助区分骨科和神经性步态障碍的潜力。
## 666. `cs.LG` - AutoTriton：利用强化学习在大语言模型中的自动Triton编程 [PDF](https://arxiv.org/pdf/2507.05687), [HTML](https://arxiv.org/abs/2507.05687)
### Authors
Shangzhan Li,Zefan Wang,Ye He,Yuxuan Li,Qi Shi,Jianling Li,Yonggang Hu,Wanxiang Che,Xu Han,Zhiyuan Liu,Maosong Sun
### Background
深度学习内核开发需要在硬件上优化计算单元，同时平衡内存管理、并行性和针对特定硬件的优化。虽然像Triton这样的领域特定语言简化解了GPU编程的底层细节，开发者仍然需要手动调参，如拼块大小和内存访问模式，这增加了达到最佳性能和广泛采用的难度。因此，需要一种能够自动优化这些计算单元的方法。
### Innovation
介绍了一个名为AutoTriton的模型，它利用强化学习(RL)来优化Triton编程。AutoTriton通过监督微调(SFT)获得Triton编程所需的关键技能，并使用Group Relative Policy Optimization (GRPO)算法进行RL训练，结合基于规则的奖励和执行奖励进一步提高Triton编程能力。
### Conclusion
实验结果表明，AutoTriton 8B模型在TritonBench和KernelBench的五个评估渠道中达到了与Claude-4-Sonnet和DeepSeek-R1-0528等主流大型模型相当的性能。进一步的实验分析揭示了AutoTriton中各模块的作用，包括SFT阶段、RL阶段和奖励设计策略，证明了强化学习在自动生成高性能内核方面的潜力，这对于构建更高效的AI系统具有重要意义。模型和代码将在此网址获取：this https URL。
## 667. `cs.LG` - 通过专家共识心音标注提高基于AI的犬类心脏病诊断 [PDF](https://arxiv.org/pdf/2507.05950), [HTML](https://arxiv.org/abs/2507.05950)
### Authors
Pinar Bisgin,Tom Strube,Niklas Tschorn,Michael Pantförder,Maximilian Fecke,Ingrid Ljungvall,Jens Häggström,Gerhard Wess,Christoph Schummer,Sven Meister,Falk M. Howar
### Background
兽医领域的人工智能模型训练面临噪声标签的重大挑战。本研究针对犬类心音数据中的专家评估模糊性进行了探索，强调了标签噪声对分类性能的负面影响，并引入了标签噪声减少的方法。对140段心脏声音记录进行了标注，分析了心音强度，最终通过专家意见筛选出70高质量的心脏声音数据，减少了数据中的噪声。利用个体心周期信息扩展了训练数据，增强了分类的稳健性。研究采用了三类分类算法：AdaBoost、XGBoost和Random Forest，并通过专家共识标注法优化了图像数据的质量。
### Innovation
本研究首次将专家共识应用于心音标注以减少标签噪声，然后利用这些高质量数据训练了多种分类算法。特别是，XGBoost在分类准确性上表现出了显著的提升。
### Conclusion
通过减少标签噪声，所有分类算法在检测犬类心音中的表现都得到了显著提升，尤其是在检测轻度和中度心音时，敏感性和特异性有大幅度提高。这些结果强调了降低标签噪声对提高人工智能检测犬类心音诊断算法性能的重要性。
## 668. `cs.LG` - 原型导向和轻量适配器在联邦学习中实现内在可解释性和泛化的框架 [PDF](https://arxiv.org/pdf/2507.05852), [HTML](https://arxiv.org/abs/2507.05852)
### Authors
Samuel Ofosu Mensah,Kerol Djoumessi,Philipp Berens
### Background
联邦学习(FL)提供了一种允许多个分布式数据源协作训练机器学习模型的同时保持隐私的方法。然而，现实中的FL面临的主要挑战包括在传输大量模型参数过程中产生的通信开销以及由跨客户端非同质数据分布导致的统计异质性。
### Innovation
本文提出了一种基于原型为导向和轻量级适配器的联邦学习框架。该框架通过原型对客户端模型进行局部细化，并利用轻量级适配器模块作为局部模型的压缩替代代理，从而解决统计异质性问题。这种设计使得每个客户端的模型能够与全局共享结构对齐，同时减少通信负担并提供内在的可解释性。
### Conclusion
在现实世界的视网膜 fondo 图像数据集上进行了实验，结果表明该方法具有内在的可解释性能力，并在分类任务中超过基准算法。同时，该设计保证了每个客户端的模型能够与全局共享结构对齐，同时减少了通信负担。
## 669. `cs.LG` - KnowIt: 深度时间序列建模及其解释 [PDF](https://arxiv.org/pdf/2507.06009), [HTML](https://arxiv.org/abs/2507.06009)
### Authors
M.W. Theunissen,R. Rabe,M.H. Davel
### Background
本文介绍了KnowIt框架的背景，KnowIt是一个灵活的时间序列模型构建框架，用于发现时间序列数据中的知识，并能进行解释。该框架使用Python实现，并公开了源代码和文档。该框架设计时考虑到了对任务细节的最少假设，并将数据集定义、深度神经网络架构和解释性技术通过井定义的接口进行了分离，从而确保可以轻松导入新数据集、自定义架构，并且可以定义不同的解释范式，同时保持模型和解释的实时性和灵活性，适用于用户自己复杂时间序列数据的知识发现。
### Innovation
KnowIt框架的创新在于其灵活性和模块化设计，这使得它可以适应多样化的任务需求，支持快速导入新数据集、自定义架构，以及定义不同的解释性范式。此外，Knowledge Discovery in time series data是这个框架的核心目标，旨在提供一个环境，帮助用户构建强大的深度学习模型，并解释这些模型的行为。
### Conclusion
KnowIt框架正在不断发展和完善，目标是成为挖掘时间序列数据下探寻知识这一领域的平台，并且成为一个值得信赖的时间序列建模工具。
## 670. `cs.LG` - Fourier Spectral Transformer Networks For Efficient and Generalizable Nonlinear PDEs Prediction [PDF](https://arxiv.org/pdf/2507.05584), [HTML](https://arxiv.org/abs/2507.05584)
### Authors
Beibei Li
### Background
该研究提出了一种综合经典光谱方法和基于注意力的神经架构优势的统一 Fourier 光谱变换器网络。通过将原始 PDEs 转换为光谱常微分方程，并使用高精度数值求解器生成训练数据，研究团队利用变压器网络来建模光谱系数的演化。该研究在二维不可压缩的纳维-斯托克斯方程和一维伯格斯方程上展示了这种方法的有效性。
### Innovation
提出了一种光谱变换器网络，该网络结合了经典光谱方法和注意力机制的优点；将PDEs转换为光谱常微分方程，使用高精度数值求解器生成训练数据；使用变压器网络来建模光谱系数的变化。该方法在相对较少量的训练数据下，能够实现长期预测，并且优于传统的数值方法和机器学习方法在预测未来流体动力学方面。
### Conclusion
所提出的框架在未见过的数据上表现出良好的泛化能力，为实时预测和控制复杂动力系统提供了一个有前景的范式。
## 671. `cs.LG` - FACT: 神经网络收敛特征定理 [PDF](https://arxiv.org/pdf/2507.05644), [HTML](https://arxiv.org/abs/2507.05644)
### Authors
Enric Boix-Adsera,Neil Mallinar,James B. Simon,Mikhail Belkin
### Background
深度学习理论的核心挑战之一是如何理解神经网络的学习和特征表示。本文证明了收敛特征定理（FACT），该定理给出了神经网络在使用非零权重衰减训练时收敛时的自洽方程。这一方程将权重矩阵 $W$ 的自共轭矩阵 $W^top W$ 与经过该矩阵前向传播的输入向量及其通过反向传播传递的损失梯度联系起来。这一关系在实验中得到了验证。
### Innovation
作者提出了收敛特征定理（FACT），并验证了该定理。通过将递归特征机（RFM）进行修改，使其遵循FACT，作者提出了一种新的学习算法FACT-RFM，该算法在表格数据上表现出高性能，并且捕捉到神经网络训练中的各种特征学习行为，如模块算术中的领悟以及学习稀疏位运算中的相变。
### Conclusion
FACT-RFM 方法在表格数据上的性能表现出色，并能够捕捉到神经网络训练中的多种特征学习行为。
## 672. `cs.LG` - 从符号下降视角简化Adam的收敛证明 [PDF](https://arxiv.org/pdf/2507.05966), [HTML](https://arxiv.org/abs/2507.05966)
### Authors
Hanyang Peng,Shuang Qin,Yue Yu,Fangqing Jiang,Hui Wang,Zhouchen Lin
### Background
Adam 作为一种流行的深度神经网络训练优化器，已被广泛认为是最有效的优化器之一。尽管它在实验上有显著的成功，但其理论收敛分析一直不令人满意。现有工作主要将 Adam 解释为具有动量的预条件随机梯度下降 (SGDM) 算法，这需要强有力的假设和复杂的技巧，并产生了冗长且难以验证和扩展的收敛性证明。
### Innovation
本文提出了一个新的解释框架，将 Adam 视作一种符号优化器，$bm{x}_{t+1} = bm{x}_t - bm{beta}_t frac{|bm{m}_{t}|}{bm{beta}_{v,t} + bm{beta}_{text{eps}}} text{Sign}(bm{m}_t)$。这一重新表述极大地简化了收敛性分析。首次在较弱的假设条件下，证明 Adam 在 $p$-仿射方差和 $(L_0, L_1, q)$-光滑性的条件下达到最优速率 ${rm O}(frac{1}{T^{frac{1}{4}}})$，而不再依赖模型的维度或数值稳定性参数 $bm{beta}_{text{eps}}$。理论分析还提供了关于动量在确保收敛中的关键作用的新见解，并为 tuning Adam 的学习率提供了实践指导。
### Conclusion
本文简化了 Adam 的收敛性证明，并首次证明了其在较弱假设条件下的最优速率。同时，本文提供了动量在确保收敛中的关键作用的新见解，并提供了 tuning Adam 的学习率的实用指导。
## 673. `cs.LG` - Kamae：连接Spark和Keras实现无缝机器学习预处理 [PDF](https://arxiv.org/pdf/2507.06021), [HTML](https://arxiv.org/abs/2507.06021)
### Authors
George Barrowclough,Marian Andrecki,James Shinner,Daniele Donghi
### Background
在生产推荐系统中，特征预处理必须在训练和推理环境中忠实复制。这通常需要在离线和在线环境中重复逻辑，增加了工程工作量并引入了数据集偏移的风险。现有的解决方案通常需要人工手动转换，导致一致性问题和额外的工作负担。
### Innovation
Kamae是一个开源的Python库，它通过将PySpark预处理管道转换为等效的Keras模型来解决这个问题。Kamae提供了可配置的Spark变换器和估计器套件，每个都映射到相应的Keras层，从而使整个ML生命周期中的预处理保持一致。它通过代码自动化转换预处理逻辑，从而减少了工作量并提高了准确性。此外，Kamae还在实际案例中进行了验证，包括MovieLens数据集和Expedia的Learning-to-Rank管道。
### Conclusion
Kamae通过提供一套预处理工具，使用户能够从Spark环境平滑过渡到Keras，从而简化了整个机器学习流程。这种方法不仅提高了模型构建的一致性，还减少了工程团队在处理不同环境之间数据差异时的工作负担。
## 674. `cs.LG` - 多视角中间融合：一种高维低样本量设置下的通用学习方法 [PDF](https://arxiv.org/pdf/2507.06026), [HTML](https://arxiv.org/abs/2507.06026)
### Authors
Lynn Houthuys
### Background
高维度低样本量（HDLSS）设置在多种应用场景中带来了重大挑战，特别是在特征维度远超可用样本数的情况下。现有研究显示，在没有固有视角的情况下，多视角中间融合方法也能在HDLSS设置下有效工作。本研究旨在提出一种适用于HDLSS设置的通用学习方法。
### Innovation
提出了多视角中间融合（multi-view mid fusion）方法，通过将高维特征向量分割成多个较小的子集，每个子集代表不同的视角。这种方法不仅在模型类型和学习任务上进行了广泛实验验证，还展示了其有效性与泛化能力。
### Conclusion
本文研究工作为随后关于多视角中间融合学习的普遍优势研究奠定了基础，证明了这种方法在HDLSS设置下的有效性和普遍适用性。
## 675. `cs.LG` - EdgeCodec: 基于残差向量量化实现的机载轻量级高保真神经压缩器 [PDF](https://arxiv.org/pdf/2507.06040), [HTML](https://arxiv.org/abs/2507.06040)
### Authors
Benjamin Hodo(1),Tommaso Polonelli(1),Amirhossein Moallemi(2),Luca Benini(1),Michele Magno(1) ((1) D-ITET, ETH Zürich, Switzerland, (2) RTDT Laboratories, Switzerland)
### Background
本文提出了EdgeCodec，一种用于风电叶片气压数据的端到端神经压缩器。EdgeCodec采用了高度不对称的自动编码器架构，并通过判别器进行训练，结合残差向量量化以最大化压缩效率。该系统能够在实时运行环境下，利用GAP9微控制器在11.25至45比特每秒的比特率下工作，同时保持低于3%的重建误差，并可针对不同的网络条件实现样本级别的比特率调节，从而适应变动的网络状况。在最高压缩模式下，它可以将无线数据传输的能耗降低至2.9倍，大幅延长了部署传感器的运行寿命。
### Innovation
EdgeCodec的核心创新在于它采用了高度不对称的自动编码器架构，并通过判别器进行优化，结合残差向量量化以适应风电叶片气压数据的压缩需求。这种架构和优化方法能够提供2560:1至10240:1的压缩比，同时保持较低的重建误差。该系统的实时性和可调节比特率特性使其能够有效应对网络条件变化，降低了能耗，显著提升了部署传感器的运行寿命。
### Conclusion
EdgeCodec在保持高保真重建质量的同时实现了高效压缩，通过精细调节比特率以适应不同网络状况，极大地降低了无线数据传输的能耗，有效延长了部署传感器设备的使用寿命，适用于需要高效数据压缩和传输的应用场景。
## 676. `cs.LG` - 基于特征的方法与基于生成对抗网络的方法进行演示学习：何时以及为何选择 [PDF](https://arxiv.org/pdf/2507.05906), [HTML](https://arxiv.org/abs/2507.05906)
### Authors
Chenhao Li,Marco Hutter,Andreas Krause
### Background
这篇综述论文提供了基于特征的方法和基于生成对抗网络（GAN）的方法在从演示中学习方面的比较分析，重点关注奖励函数的结构及其对策略学习的影响。基于特征的方法能够提供密集且可解释的奖励，这些奖励在高保真度的运动模仿方面表现出色，但往往需要复杂的参考表示，并且在非结构化的环境中难以泛化。相比之下，基于GAN的方法使用隐式的、分布式的监督，可以实现可扩展性和适应性，但容易出现训练不稳定性和粗略的奖励信号。
### Innovation
该研究强调了结构化运动表示的重要性，这种表示能实现更平滑的过渡、可控的合成以及更好的任务整合。研究者认为，基于特征的方法与基于GAN的方法之间的二分法越来越精细化，而不是一个方法一定会主导另一个方法。选择哪种方法应该由具体任务的优先需求来决定，如保真度、多样性、可解释性和适应性等因素。
### Conclusion
该工作概述了两种方法之间的算法权衡和设计考虑，提供了一个基于原则的决策框架，用于从演示中学习的选择。
## 677. `cs.LG` - 通过不确定性意识的离域检测和策略适应实现安全领域随机化 [PDF](https://arxiv.org/pdf/2507.06111), [HTML](https://arxiv.org/abs/2507.06111)
### Authors
Mohamad H. Danesh,Maxime Wabartha,Stanley Wu,Joelle Pineau,Hsiu-Chin Lin
### Background
在现实世界中部署强化学习（RL）策略存在重大挑战，包括分布转移、安全问题以及直接在目标域中进行策略优化的不切实际性。现有的方法，如领域随机化（DR）和离线动力学RL，通过直接与目标域交互来提高策略的鲁棒性，但这种做法本身存在安全隐患。因此，本文探讨了在不直接与目标域进行交互的情况下解决这些挑战的方法，以确保训练的安全性并提高策略的鲁棒性。
### Innovation
本文提出了一种新的框架Uncertainty-Aware RL（UARL），该框架通过解决离域（OOD）检测以及在不进行目标域直接交互的情况下进行策略适应，来优先考虑训练中的安全性。UARL使用一系列批评者来量化策略的不确定性，并结合渐进的环境随机化，以准备策略应对各种现实环境。通过在模拟环境中迭代地在状态空间的高不确定性区域进行优化，UARL能够在不直接针对目标域训练的情况下增强策略在目标域中的鲁棒泛化能力。
### Conclusion
我们在MuJoCo基准测试和四足机器人上评估了UARL，表明该方法在可靠的离域检测、性能提升和样本效率方面优于基线方法。
## 678. `cs.LG` - CoRE: 使用未标注自评估提升LRMs元认知能力 [PDF](https://arxiv.org/pdf/2507.06087), [HTML](https://arxiv.org/abs/2507.06087)
### Authors
Haoxi Li,Sikai Bai,Jie Zhang,Song Guo
### Background
大型推理模型（LRMs）在数学和程序合成等领域表现出令人印象深刻的性能，但常常表现出过度推理论证，即过多和冗余的推理步骤导致推理过程效率低下。这一现象促使研究者关注如何让模型自主评估其推理路径的正确性，而不依赖外部标签。
### Innovation
提出了一种名为Chain-of-Reasoning Embedding (CoRE)的方法，这是一种在潜在空间中的隐藏状态系列，能够在不依赖标签的情况下对LRMs的中间推理步骤进行自评估，以增强模型的元认知能力，提高推理效率。进一步构建了一个无训练、无标签的自评估框架CoRE-Eval，利用推理路径的几何特性检测冗余推理的模式，动态判断是否提前终止推理。
### Conclusion
通过在数学推理基准（GSM8K、MATH-500和AIME）和从7B到32B的不同规模模型上的广泛实验，证明了CoRE-Eval可以在减少推理路径长度13.7%至33.2%的同时提高答案准确性约10%，并在32B模型上达到70.0%的准确率，特别是在具有挑战性的AIME基准上。
## 679. `cs.LG` - 基于子空间的近似海森矩阵方法用于零阶优化 [PDF](https://arxiv.org/pdf/2507.06125), [HTML](https://arxiv.org/abs/2507.06125)
### Authors
Dongyoon Kim,Sungjae Lee,Wonjin Lee,Kwang In Kim
### Background
零阶优化方法适用于无法访问或计算梯度信息的问题。尽管大多数现有方法依赖于一阶近似，但结合二阶（曲率）信息理论上可以显著加速收敛。然而，估计海森矩阵所需的函数评估成本往往限制了其实用性。
### Innovation
提出了一种基于子空间的近似海森矩阵（ZO-SAH）方法，该方法通过专注于随机选取的二维子空间来降低这些成本。在每个子空间内，ZO-SAH 通过拟合目标函数的二次多项式并提取其二阶系数来估计海森矩阵。为了进一步降低函数查询成本，ZO-SAH 使用了周期性的子空间切换策略，该策略在优化步骤中重用函数评估。
### Conclusion
实验结果表明，ZO-SAH 在八个基准数据集（包括逻辑回归和深度神经网络训练任务）上实现了比现有零阶方法显著更快的收敛速度。
## 680. `cs.LG` - 由显式物理整合的少量样本学习：地下水热传输的应用 [PDF](https://arxiv.org/pdf/2507.06062), [HTML](https://arxiv.org/abs/2507.06062)
### Authors
Julia Pelzer,Corné Verburg,Alexander Heinlein,Miriam Schulte
### Background
机器学习方法在科学和工程的现实应用中常常面临挑战，尤其是在训练数据有限或质量较低的情况下。地下水流动伴随热量传输的研究是一个典型的对流-扩散过程，且在非均匀流条件下进行。传统的数值模拟成本高且具有挑战性，因为需要高时空分辨率和大范围的计算。尽管基于数据的代理模型计算效率较高，但它们在预测对流过程时仍存在困难，因为对流过程对输入变化非常敏感，并涉及远程空间交互。因此，本文提出了一种局部-全局卷积神经网络（LGCNN）方法，结合了轻量级的数值代理和局部卷积神经网络来改进预测准确性。通过LGCNN方法，一个包含异质地下水流动和一百个地下水热泵注入点的城市地下温度场被建模，这些地点形成了远程相互作用的热羽流。首先基于随机地表下输入字段系统地分析模型，然后在少量的德国慕尼黑地区的地下实际地表切片上进行训练，并且可以扩展到更大的切片而无需重新训练。所有数据集、代码和训练模型都已公布以确保可复现性.
### Innovation
提出了Local-Global Convolutional Neural Network（LGCNN）方法，结合了轻量级的数值代理模型和卷积神经网络，特别适用于非均匀流条件下对流-扩散过程的预测。该方法能够在较小的数据集上有效训练并在较大的数据集上进行扩展，从而提高预测准确性并对远程空间交互进行建模。
### Conclusion
通过LGCNN方法成功建模了慕尼黑地区的城市地下温度场，展示了其在实际应用中的有效性及应用前景。这种方法不仅解决了传统数值模拟中存在的高成本和挑战性问题，还成功克服了基于数据的代理模型在预测对流过程时的难题，为未来研究提供了新的思路和方法。
## 681. `cs.LG` - 现代联想记忆方法 [PDF](https://arxiv.org/pdf/2507.06211), [HTML](https://arxiv.org/abs/2507.06211)
### Authors
Dmitry Krotov,Benjamin Hoover,Parikshit Ram,Bao Pham
### Background
联想记忆模型，如著名的Hopfield网络，是描述完全反馈神经网络的有效模型。这些网络的基本任务是存储和检索信息。近年来，由于与SOTA人工智能架构，如变压器和扩散模型的新理论结果及它们之间的关系，联想记忆模型受到了广泛关注。这些关联使得可以通过联想记忆的理论视角来解释传统AI网络的计算，同时，新的拉格朗日形式使设计强大的分布式模型成为可能，这些模型可以学习有用的表现形式并指导新型架构的设计。
### Innovation
该论文提出了现代联想记忆的方法，强调通过现代语言和方法介绍这一研究领域的最新发展。它提供了直观的数学推导和编程笔记本，使得这些高级概念更具可操作性。
### Conclusion
通过拉格朗日形式和现代方法，设计新的联想记忆模型，不仅能够学习有用的表示，还能够指导新型架构的设计。
## 682. `cs.LG` - 采样器在卷积网络中的现象：帧理论视角 [PDF](https://arxiv.org/pdf/2507.06152), [HTML](https://arxiv.org/abs/2507.06152)
### Authors
Daniel Haider,Vincent Lostanlen,Martin Ehler,Nicki Holighaus,Peter Balazs
### Background
在卷积层中使用步长会不可避免地引入混叠现象，这会影响数值稳定性和统计泛化能力。尽管通过基于参数化等技术（如基于无原子系统）可以促进正交卷积并确保帕塞瓦尔稳定性，但在混叠现象及其实现的稳定性影响上，还没有进行过系统的分析。
### Innovation
本文采用帧理论的方法，描述了一维卷积核在卷积层中的混叠现象，提出了稳定性边界的实际估计方法和帕塞瓦尔稳定性表征，特别适用于考虑短卷积核尺寸。并通过系统地抑制混叠现象，提出了两种计算效率很高的优化目标，确保帕塞瓦尔稳定性。对于具有随机卷积核的层，还推导了描述混叠效应的期望值和方差的封闭形式表达式，揭示了初始化时混叠行为的基本特性。
### Conclusion
本文通过帧理论视角，分析了卷积网络中的混叠现象，提出了抑制混叠的优化目标，并揭示了初始化时混叠行为的特点，增强了卷积网络的稳定性和泛化能力。
## 683. `cs.LG` - 扩散数据集浓缩：用更少的数据更快训练你的扩散模型 [PDF](https://arxiv.org/pdf/2507.05914), [HTML](https://arxiv.org/abs/2507.05914)
### Authors
Rui Huang,Shitong Shao,Zikai Zhou,Pukun Zhao,Hangyu Guo,Tian Ye,Lichen Bai,Shuo Yang,Zeke Xie
### Background
扩散模型在各种生成任务中取得了显著的成功，但它们的训练仍然是高度资源密集型的，通常需要数百万张图像和许多天的GPU计算。从数据为中心的角度出发，我们研究了扩散数据集浓缩作为一个新的和具有挑战性的问题设置。目标是构建一个“合成”子数据集，样本数远少于原始数据集，从而以大大降低的成本实现高质量的扩散模型训练。
### Innovation
我们是首批正式研究扩散模型数据集浓缩的，此前的工作主要集中在训练判别模型。为了解决这一新挑战，我们提出了一种新颖的扩散数据集浓缩（D2C）框架，该框架由两个阶段组成：选择和附着。选择阶段使用扩散难度评分和间隔抽样来识别紧凑且多样化的子集。附着阶段通过附加丰富的语义和视觉表示来增强所选子集，以加强条件信号。通过在不同数据集大小、模型架构和分辨率上进行广泛的实验，结果显示D2C框架使扩散模型的训练显著加快，同时仅使用极少的数据保持高质量的视觉效果。
### Conclusion
在SiT-XL/2架构下，D2C实现了100倍的训练加速，在仅使用0.8%的训练数据的情况下，在40k步内达到了FID分数4.3。
## 684. `cs.LG` - QS4D: 量化感知训练在高效硬件部署结构化状态空间序列模型中的应用 [PDF](https://arxiv.org/pdf/2507.06079), [HTML](https://arxiv.org/abs/2507.06079)
### Authors
Sebastian Siegel,Ming-Jay Yang,Younes Bouhadjar,Maxime Fabre,Emre Neftci,John Paul Strachan
### Background
结构化状态空间模型（SSM）作为一种新的深度学习模型，特别适合处理长序列数据，具有常量内存需求，相较于 Transformer 的线性内存需求更为吸引人，适于资源受限的边缘计算设备。近期研究已探讨量化感知训练（QAT）对 SSM 的影响，但主要集中在一般硬件上，对专门针对边缘硬件（例如模拟存内计算芯片）的影响尚未得到充分研究。
### Innovation
本文展示了 QAT 可以显著降低 SSM 复杂性，最多减少两个数量级，同时研究模型大小与数值精度的关系，证明了 QAT 能增强模型对模拟噪声的鲁棒性并启用结构剪枝。最后，文章将这些技术集成到存内计算基板上，并强调了由此带来的计算效率提升。
### Conclusion
通过量化感知训练，SSM 的计算效率显著提升，同时增强了模型对模拟噪声的鲁棒性，能够有效地在边缘计算设备上部署，并提供了巨大的应用潜力。
## 685. `cs.LG` - 在可微逻辑门网络中优化连接的方法 [PDF](https://arxiv.org/pdf/2507.06173), [HTML](https://arxiv.org/abs/2507.06173)
### Authors
Wout Mommen,Lars Keuninckx,Matthias Hartmann,Piet Wambacq
### Background
介绍了对深层可微逻辑门网络（LGNs）中的连接进行部分优化的新方法。该方法利用每个门输入的概率分布来选择具有最高价值的连接，之后选择门类型。论文展示了连接优化的LGNs在Yin-Yang、MNIST和Fashion-MNIST基准测试中优于标准的固定连接LGNs，同时仅需要较少数量的逻辑门。当训练所有连接时，实验表明使用8000个简单的逻辑门即可在MNIST数据集上达到98%以上的准确率。另外，优化后的网络在MNIST数据集上的表现优于标准完全连接的LGNs，所需的逻辑门数量减少24倍。因此，这项工作为完全可训练的布尔逻辑铺平了道路。
### Innovation
提出了一种新型方法，用于部分优化深可微逻辑门网络（LGNs）中的连接。该方法利用概率分布选择每输入门的连接，采用具有最高价值的连接，并随后选择门类型。这项工作展示了在使用较少数量逻辑门的情况下，优化连接的LGNs比标准LGNs更优，并为完全可训练的布尔逻辑提供了路径。此外，还展示了在完全训练连接时，8000个逻辑门就足以在MNIST数据集上达到98%以上的准确率，同时优化后的网络在MNIST数据集上比标准完全连接的LGNs有24倍更少的逻辑门且表现更优。
### Conclusion
该工作提出了一种新的方法，用于部分优化深层可微逻辑门网络中的连接。实验证据表明，优化后的LGNs不仅在基准测试中表现更好，而且所需的逻辑门数量更少。这表明，在逻辑门性能优化方面还有很大的提升空间，并为完全可训练的布尔逻辑开创新的可能。
## 686. `cs.LG` - 深度学习优化二状态压夹天线系统 [PDF](https://arxiv.org/pdf/2507.06222), [HTML](https://arxiv.org/abs/2507.06222)
### Authors
Odysseas G. Karagiannidis,Victoria E. Galanopoulou,Panagiotis D. Diamantoulakis,Zhiguo Ding,Octavia Dobre
### Background
无线通信系统的发展需要灵活、节能且成本效益高的天线技术。压夹天线（PAs）可以动态控制电磁波的传播，通过二进制激活状态实现这一目标，因此成为了有希望的候选技术。本文研究了在波导中选择部分固定位置的PAs来激活的问题，目的是最大化用户终端的通信速率。
### Innovation
本文将天线激活、波导引起的相位移和功率分配之间的复杂交互问题，通过组合分数0-1二次规划进行公式化。利用神经网络架构及其在数据上的复杂度差异来直接从数据中学习天线激活策略，并在训练和评估管道中整合了用户位置的不确定性，以模拟现实部署条件。
### Conclusion
模拟结果显示，所提出的模型是有效的和鲁棒的。
## 687. `cs.LG` - 差分Mamba [PDF](https://arxiv.org/pdf/2507.06204), [HTML](https://arxiv.org/abs/2507.06204)
### Authors
Nadav Schneider,Itamar Zimerman,Eliya Nachmani
### Background
序列模型如Transformer和RNN经常过度关注无关背景，导致中间表示噪声增加。这降低了大语言模型的能力，通过促进幻觉、削弱长距离能力和检索能力以及减少稳健性。最近的工作表明，微分设计可以在Transformer中减轻这一问题，从而在各种应用中提高其有效性。本文背景是探讨这些技术是否可以应用于Mamba，这是一种基于选择性状态空间层的新架构，实现了与Transformer相当的性能但更高效。
### Innovation
本文创新性地引入了一种针对Mamba的新型微分机制，该机制在语言建模基准上得到实证验证，表明检索能力增强且性能优于原始Mamba。此外，本文还进行了详尽的消融研究和经验分析，以证明该设计选择的有效性，并提供证据证明其方法有效地缓解了基于Mamba模型中的过度分配问题。
### Conclusion
本文通过引入针对Mamba的新型微分机制，有效缓解了模型中的过度分配问题，并通过详尽的实验研究证明了该设计的有效性。代码已公开。
## 688. `cs.LG` - BMFM-DNA：一种考虑变异影响的DNA基础模型 [PDF](https://arxiv.org/pdf/2507.05265), [HTML](https://arxiv.org/abs/2507.05265)
### Authors
Hongyang Li,Sanjoy Dey,Bum Chul Kwon,Michael Danziger,Michal Rosen-Tzvi,Jianying Hu,James Kozloski,Ching-Huei Tsou,Bharath Dandala,Pablo Meyer
### Background
大规模语言模型（LLMs）在自然语言处理（NLP）任务中取得了显著成果，适应后的DNALMs（DNA语言模型）如DNABERT、GENA-LM在基因组相关生物任务中也表现出色。然而，DNA语言与自然语言存在根本差异，缺乏明确的词汇和一致的语法规则。尽管如此，当前的模型在面对序列变异时，未能编码生物功能。因此，本研究旨在通过预训练整合序列变异，特别是单核苷酸多态性（SNPs），以提高DNALMs表现。
### Innovation
提出了一种新的SNP意识的DNA基础模型（BMFM-DNA），该模型通过对引用基因组序列及其反向互补序列进行预训练，结合序列变异（包括SNPs），并采用一种新型的编码序列变异的表示方案，有效提升了生物功能的捕捉能力。此外，BMFM-DNA通过HuggingFace公开发布，鼓励社区贡献并促进模型评估的全面性。
### Conclusion
通过实验证明，将序列变异整合到DNALMs中有助于更准确地捕捉生物功能。然而，当前的基准测试在全面评估这些模型方面存在局限性。为实现未来更全面的评估和鼓励社区贡献，本研究公开发布BMFM-DNA模型和代码，以重现结果。
## 689. `cs.LG` - 大型语言模型模型提取攻击及其防御措施综述 [PDF](https://arxiv.org/pdf/2506.22521), [HTML](https://arxiv.org/abs/2506.22521)
### Authors
Kaixiang Zhao,Lincan Li,Kaize Ding,Neil Zhenqiang Gong,Yue Zhao,Yushun Dong
### Background
模型提取攻击对已部署的语言模型构成了重大安全威胁，可能损害知识产权和用户隐私。本文综述了针对大型语言模型（LLMs）的具体模型提取攻击和防御措施的分类体系，包括功能提取、训练数据提取和针对提示的攻击。文章分析了各种攻击方法，如基于API的知识蒸馏、直接查询、参数恢复和提示窃取技术，并探讨了保护模型、数据隐私保护以及针对提示的防御机制，评估了它们在不同部署场景中的有效性。研究提出了一种新的方法，用于评估攻击效果和防御性能的特殊指标，解决了生成型语言模型特有的挑战。通过对现有方法的分析，文章指出了当前方法的关键局限，并提出了有前途的研究方向，包括综合攻击方法和平衡安全性和模型效用的自适应防御机制。这项工作为自然语言处理研究人员、机器学习工程师和安全专家提供了保护语言模型在生产环境中的方法和技术指导。
### Innovation
本文提出了对大型语言模型的模型提取攻击及其防御措施的全面分类体系，分析了如何利用变压器架构进行攻击的方法，并且开发了专门针对攻击效果和防御性能的评估指标，同时指出现有研究中的关键局限，并提出了综合攻击方法和自适应防御机制的新研究方向。这一系列创新措施将增强语言模型的安全性，保护其知识产权和用户隐私，在实际应用中具有重要意义。
### Conclusion
本文通过对模型提取攻击和防御措施的全面分析，指出了当前方法的局限，并提出了具有前景的研究方向，即综合攻击方法和自适应防御机制。这些研究方向将有助于构建更加安全的生成型语言模型，保护语言模型在生产环境中的安全性和有效性，为语言模型的安全使用提供指南和技术支持。
## 690. `cs.LG` - 通过多任务学习增强学习路径推荐 [PDF](https://arxiv.org/pdf/2507.05295), [HTML](https://arxiv.org/abs/2507.05295)
### Authors
Afsana Nasrin,Lijun Qian,Pamela Obiomon,Xishuang Dong
### Background
个性化学习是以学生为中心的教育方法，可以根据每个学习者独有的需求调整内容、节奏和评估。学习路径推荐是实现个性化学习的关键技术，它会根据学习者的过往交互按序推荐个性化学习项目，如讲座和练习。近年来，深度学习尤其是深度强化学习的发展使得调整推荐变得更加实用且有效。
### Innovation
本文提出了一种基于多任务学习的多任务LSTM模型，通过在不同任务间共享信息以提升学习路径推荐的效力。该模型将学习路径推荐重构为序列到序列（Seq2Seq）预测问题，从学习者的历史互动中生成个性化学习路径。模型使用共享的LSTM层捕捉学习路径推荐和深度知识追踪的共同特征，并使用特定任务的LSTM层来处理每个目标。此外，通过非重复损失避免推荐重复的学习项目，该损失会惩罚推荐路径中的重复项，从而提高推荐的质量和多样性。
### Conclusion
实验结果显示，所提出的模型在学习路径推荐方面显著优于基准方法。
## 691. `cs.LG` - TokenShapley: 使用Shapley值进行标记级别上下文归因 [PDF](https://arxiv.org/pdf/2507.05261), [HTML](https://arxiv.org/abs/2507.05261)
### Authors
Yingtai Xiao,Yuqing Zhu,Sirat Samyoun,Wanrong Zhang,Jiachen T. Wang,Jian Du
### Background
大型语言模型（LLMs）在上下文学习方面表现出强大的能力，但验证其生成响应的正确性仍是一项挑战。尽管之前的工作曾在句子级别探索了归因方法，但对于用户希望为响应中的特定关键词（如数字、年份或名称）进行归因的需求，这些方法表现出不足。因此，本研究旨在解决这一局限性，提出了TokenShapley方法，一种结合基于Shapley值的数据库归因和基于最近KNN增强LLM进展的KNN检索技术的新颖标记级别归因方法。
### Innovation
TokenShapley通过利用预计算的数据库进行上下文检索，并计算Shapley值来量化标记的重要性，提供了一种精细的数据归因方法。相较于现有的最先进的基线方法，在标记级别归因方面，TokenShapley显示出11-23%的准确性改进。
### Conclusion
TokenShapley通过结合Shapley值和KNN检索技术，提供了一种新的标记级别归因方法，显著提高了准确性，并能更好地满足用户对于响应中特定关键词归因的需求，从而有效解决了现有方法的局限性。
## 692. `cs.LG` - 材料性质发现中的主题建模和链接预测 [PDF](https://arxiv.org/pdf/2507.06139), [HTML](https://arxiv.org/abs/2507.06139)
### Authors
Ryan C. Barron,Maksim E. Eren,Valentin Stanev,Cynthia Matuszek,Boian S. Alexandrov
### Background
科学文献网络和知识图谱通常非常庞大、稀疏且杂乱，常常包含实体之间的缺失链接。链接预测能够根据连接模式推断出这些缺失或未来的关系。这项研究聚焦于73种过渡金属二硫属化合物（TMDs）的文献网络，探索这些材料在物理学多个领域的应用，并使用矩阵分解方法来发现隐藏的关系。
### Innovation
提出了一种基于矩阵分解的人工智能驱动的层次链接预测框架，将Hierarchical Nonnegative Matrix Factorization (HNMFk)，Boolean矩阵分解（BNMFk），Logistic矩阵分解（LMF）以及其他自动模型选择方法结合使用，用于从46,862篇文献构建层次主题树。该方法通过融合离散可解释性和概率得分来预测链接，而且能够揭示主题与材料之间的新颖假设。
### Conclusion
该研究通过移除关于超导性的文献，并展示了模型如何预测与超导体过渡金属二硫属化合物之间的隐含联系，以此验证了方法的有效性。表明此方法能够发现材料网络中的隐含连接，帮助从科学文献中推断出潜在的主题关联，尤其适用于涵盖同一类现象或材料但来源于不同领域和视角的多样文献集合。通过一个互动的Streamlit仪表板，这些推断出的链接可以进一步供人类参与的科学发现过程使用。
## 693. `cs.LG` - 结构化的标题改善了文本到图像模型的提示一致（Re-LAION-Caption 19M） [PDF](https://arxiv.org/pdf/2507.05300), [HTML](https://arxiv.org/abs/2507.05300)
### Authors
Nicholas Merchant,Haitz Sáez de Ocáriz Borde,Andrei Cristian Popescu,Carlos Garcia Jurado Suarez
### Background
我们指出，生成型文本到图像模型在大型数据集如LAION-5B的嘈杂和无序的特性下常难以严格遵循提示。因此，用户必须依赖于提示工程来获得理想的结果。
### Innovation
提出了一种通过在训练过程中强制保持一致的标题结构，来显著提高模型控制能力和对齐性的方法。通过引入使用Mistral 7B Instruct基座模型生成的1900万张1024x1024的高质量图片数据集Re-LAION-Caption 19M，每个标题遵循主题、设置、审美和摄影细节的四种模板结构。
### Conclusion
使用结构化标题训练的PixArt-$?Sigma$和Stable Diffusion 2，在视觉问答模型下获得的文本-图像对齐分数更高，证明了结构化标题的有效性。该数据集已公开发布。
## 694. `cs.LG` - 使用滑动窗口模式识别的LSTM和DLSTM太阳耀斑预测 [PDF](https://arxiv.org/pdf/2507.05313), [HTML](https://arxiv.org/abs/2507.05313)
### Authors
Zeinab Hassani,Davud Mohammadpur,Hossein Safari
### Background
该研究调查了使用长短期记忆（LSTM）和分解-长短期记忆（DLSTM）网络结合集成算法来预测太阳耀斑发生的方法。利用从2003年至2023年的太阳耀斑事件时间序列数据（共151,071次耀斑事件），研究了由于太阳复杂且自我组织临界性的行为所带来的长期预测挑战。滑动窗口技术被用于检测不规则和正规化耀斑时间序列中的时间准模式。正规化减少了复杂性，增强了大耀斑活动，并更有效地捕获了活跃日。
### Innovation
研究提出了一种结合LSTM和DLSTM的滑动窗口模式识别方法来预测太阳耀斑，特别是在正规化时间序列上通过集成方法应用DLSTM模型，在性能指标（如TSS、召回率和ROC的AUC）上显示出比在不规则时间序列上应用更优的效果。研究归因于DLSTM能够将时间序列分解为趋势和季节性成分，有效地隔离了随机噪声。
### Conclusion
该研究强调了高级机器学习技术在太阳耀斑预测中的应用潜力，并指出应整合各种太阳周期阶段和重采样策略以提高预测可靠性。
## 695. `cs.LG` - 运动生成：生成方法和基准综述 [PDF](https://arxiv.org/pdf/2507.05419), [HTML](https://arxiv.org/abs/2507.05419)
### Authors
Aliasghar Khani,Arianna Rampini,Bruno Roy,Larasika Nadela,Noa Kaplan,Evan Atherton,Derek Cheung,Jacky Bibliowicz
### Background
运动生成是从各种条件输入中合成逼真运动序列的任务，已成为计算机视觉、计算机图形学和机器人学的核心问题。其应用广泛，从动画和虚拟代理到人机交互。随着生成领域引入了包括GAN、自动编码器、自回归模型和基于扩散的技术在内的多种建模范式，每种方法都有其优势和局限性，这种多样性的增加产生了对全面和结构化审查的需求，特别是从生成方法应用的角度考察最新进展。
### Innovation
本文提供了一种针对其生成策略进行深入分类的运动生成方法。重点关注2023年以来在顶级期刊上发表的论文，反映了该领域的最新进展。同时分析了架构原则、条件机制和生成环境，并汇总了文献中使用的评估指标和数据集概述。目标是使比较更加清晰，并识别开放挑战，从而为研究者和从业者提供了最新的基础参考，帮助他们应对不断演化的运动生成领域。
### Conclusion
本文旨在使读者能够进行更清晰的比较，并识别研究领域中的开放挑战，为进一步研究提供一个及时的基础参考资料。
## 696. `cs.LG` - pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models [PDF](https://arxiv.org/pdf/2507.05394), [HTML](https://arxiv.org/abs/2507.05394)
### Authors
Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani
### Background
视觉-语言模型（VLMs）如CLIP已经在零样本和少样本设置中展示了出色的泛化能力，但将它们高效地适应分布式、异构数据仍然是一项挑战。在个性化联邦学习中，提示调优作为一种参数效率高的方法受到欢迎，但现有方法通常会为了个性化牺牲泛化能力，特别在网络不易见到的类别或领域中表现不佳。
### Innovation
作者提出了pFedMMA，这是第一个利用多模态适配器进行视觉-语言任务的个性化联邦学习框架。每个适配器包含模态特定的上、下投影层以及一个全局共享的投影，以对齐跨模态特征。该优化策略允许客户端本地适应个性化数据分布同时协作训练共享投影以提升全局泛化性能。这种设计还具有通信效率，因为只有共享组件在每一轮中交换。
### Conclusion
通过在包括领域和标签偏移在内的11个数据集上的广泛实验，作者证明pFedMMA在个性化和泛化之间实现了业内最佳的权衡，优于最近的联邦提示调优方法。代码已在指定的链接中提供。
## 697. `cs.LG` - Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning [PDF](https://arxiv.org/pdf/2507.05418), [HTML](https://arxiv.org/abs/2507.05418)
### Authors
Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang
### Background
大语言模型（LLMs）在数学、事实问答（FQA）、代码生成等领域的表现非常强大，但在多语言推理方面的性能仍然较为有限。特别是对于低资源语言（如斯瓦希里语或泰语），LLMs经常会误解提示，或默认使用英语进行推理。这种偏向高资源语言的隐性偏见会影响事实的准确性、可解释性和可信度。尽管当前的多语言基准专注于最终答案，但它们往往忽略了模型是否真的在目标语言中进行了推理。因此，该研究引入了GeoFact-X，这是一个基于地理学的多语言事实推理基准，包含五种语言：英语、印地语、日语、斯瓦希里语和泰语，并附有推理注释。该研究进一步提出了一种名为BRIDGE的新训练方法，该方法通过一个语言一致性奖励引导监督微调和测试时的强化学习，将推理与输入语言对齐。此外，该研究开发了一种自动评估协议，利用LLM作为评判者，评估答案的正确性以及推理注释的质量和语言一致性，从而超越表面级指标进行细致和可扩展的分析。结果表明，BRIDGE显著增强了多语言推理的准确性，表明意识到语言的多语言强化学习对于跨语言泛化的稳健性至关重要。
### Innovation
这项研究创新地提出了GeoFact-X，一个基于地理学的多语言事实推理基准，涵盖了五种不同语言和附带的语言推理注释，旨在解决多语言语言推理基准过于关注最终答案而忽视模型在目标语言中进行推理的问题。该研究还提出了一种新的训练方法BRIDGE，这种方法通过语言一致性奖励来引导监督微调和测试时的强化学习，将推理与输入语言对齐。此外，研究还开发了一种自动评估方法，以评估模型的推理质量，使分析更加精细和可扩展。这种新的方法和基准有助于改进多语言推理模型的语言意识和推理能力，从而提高多语言场景下的性能。
### Conclusion
研究结果表明，BRIDGE显著提升了多语言推理的准确性，强调了语言意识的多语言强化学习对于开发稳健的跨语言泛化模型的重要性。这种方法不仅能够提高模型的语言一致性，还能让模型更好地理解并回应低资源语言的问题，从而增强模型的解释性和信任度。
## 698. `cs.LG` - 从折叠能量预测蛋白质互作的突变效应 [PDF](https://arxiv.org/pdf/2507.05502), [HTML](https://arxiv.org/abs/2507.05502)
### Authors
Arthur Deng,Karsten Householder,Fang Wu,Sebastian Thrun,K. Christopher Garcia,Brian Trippe
### Background
蛋白-蛋白相互作用能的变化准确估计是一个在结构生物学和药物设计中有广泛应用的开放问题。现有的深度学习预测器效果不佳，主要是由于缺少结合数据。因此，研究人员开发了一种迁移学习方法，利用蛋白质序列建模和折叠稳定性预测的进步来解决这个问题。
### Innovation
该研究提出了一种参数化互作能量的方法，即蛋白质复合体的折叠能量与其中各结合伙伴折叠能量之和的差值。为了折合能的估计，使用了预训练的反向折叠模型作为代理。另外，该方法可以通过大量的折叠能测量和少量的结合能测量进行微调。最终，提出的预测器 StaB-ddG 在准确性上达到了当前最好方法 FoldX 的水平，并且比后者快了逾 1,000 倍。
### Conclusion
研究者提出的 StaB-ddG 预测器是第一个能够与最先进的经验力场方法 FoldX 比肩的深度学习预测器，并且具有显著的计算效率。
## 699. `cs.LG` - 高阶协作导向联合图神经网络用于准确的QoS预测 [PDF](https://arxiv.org/pdf/2507.05308), [HTML](https://arxiv.org/abs/2507.05308)
### Authors
Zehuan Chen,Xiangwei Lai
### Background
预测服务质量（QoS）数据对于云服务选择至关重要，其中用户隐私是一个关键问题。现有的基于联合图神经网络（FGNN）的QoS预测器通常在用户的分散显式用户服务图上执行设备上的训练，从而无法利用隐式的用户用户交互。因此，现有方法在准确性和隐私保护方面存在局限性。
### Innovation
本文提出了一种高阶协作导向联合图神经网络（HC-FGNN），通过基于注意力机制放大显式的用户服务图以获得高阶合作，从而反映隐式的用户用户交互。此外，它采用轻量级的消息聚合方式以提高计算效率。实验结果表明，所提出的HC-FGNN在准确性和隐私保护方面具有优势。
### Conclusion
所提议的HC-FGNN在两个实际应用中的QoS数据集上进行了广泛的实验，结果表明HC-FGNN具有高预测准确性和隐私保护的优势。
## 700. `cs.LG` - 关于下一词预测偏好的偏差：最短路径案例研究 [PDF](https://arxiv.org/pdf/2507.05362), [HTML](https://arxiv.org/abs/2507.05362)
### Authors
Riccardo Alberghi,Elizaveta Demyanenko,Luca Biggio,Luca Saglietti
### Background
当前自然语言处理的进步表明，提高大型语言模型推理能力的两个关键因素是：(i)在测试时增加计算资源有助于解决更难的问题，但通常会在推理过程中引入冗余，(ii)计算资源的有效性取决于推理是否系统和逐步进行，形成类似于人类问题解决的结构化思维链条（CoTs）。为了单独研究这些因素，该研究基于层次图中的最短路径任务引入了一个控制性设置。利用自定义分词器对仅解码器变换器进行训练，比较了基于最优自底向上的动态规划追溯训练的模型与基于更长且涉及回溯的有效追溯训练的模型。
### Innovation
研究基于最短路径任务设计了一个控制性环境，创新性地通过对比训练数据中不同的推理追溯（包括最优动态规划追溯和涉及回溯的有效追溯），观察到了在相同的训练标元预算下，采用低效推理追溯训练的模型在未见过的图上的泛化能力更强。这一结果表明，泛化能力与模型对下一词预测的信心有关，长且连贯且局部渐进的推理追溯使得训练信号更易于优化。
### Conclusion
与随意引入冗余的推理追溯相比，模型对下一词预测的自信度与泛化能力正相关，这提示长且连贯的局部渐进式推理追溯能够更好地优化训练信号。
## 701. `cs.LG` - 云扩散模型 part 1：理论和动机 [PDF](https://arxiv.org/pdf/2507.05496), [HTML](https://arxiv.org/abs/2507.05496)
### Authors
Andrew Randono
### Background
扩散模型通过逐步向图像集添加噪声并在噪声中分离出信号来进行图像生成。这些模型使用的噪声类型为白噪声，即每个点的噪声基于独立的高斯分布，其均值和方差不依赖于尺度。相比之下，大多数自然图像集在低阶统计特性上表现出尺度不变性，其特征为幂律缩放。因此，自然图像更接近于一种不同的概率分布，该分布强调大尺度相关性和削弱小尺度相关性。这种尺度不变噪声可以被纳入扩散模型中作为白噪声的替代品，形成一种名为‘云扩散模型’的新模型。作者认为，这些模型可以实现更快的推理、增强高频细节以及更高的可控性。未来的工作将在最基本的尺度不变性上建立并训练一种云扩散模型，并将其与经典的白噪声扩散模型进行对比。
### Innovation
提出了一种新的‘云扩散模型’，即通过引入尺度不变噪声来替代传统的白噪声，改进了扩散模型在图像生成中的表现，从而使模型在推理速度、高频细节以及可控性方面表现更优。
### Conclusion
介绍了利用尺度不变噪声的云扩散模型理论和动机，并表明这种方法能够在建模自然图像时提高效果。未来的工作将构建和训练这种云扩散模型，并进行与传统白噪声扩散模型的比较研究。
## 702. `cs.LG` - Temporal Conformal Prediction (TCP): 一种无分布统计与机器学习相结合的自适应风险管理框架 [PDF](https://arxiv.org/pdf/2507.05470), [HTML](https://arxiv.org/abs/2507.05470)
### Authors
Agnideep Aich,Ashit Baran Aich,Dipak C. Jain
### Background
本文提出了一种名为Temporal Conformal Prediction (TCP)的新框架，旨在构建金融时间序列预测区间，且通过实证保证了有限样本的有效性。该框架结合了量ile回归和一个通过衰减学习率在线适应的校准层，这种混合设计集成了统计学和机器学习的方法，能够处理非稳态、波动聚簇和不同市场制度转换等金融市场资产收益的特性，而无需依赖严格的参数假设。
### Innovation
TCP通过结合量ile回归和自适应校准层，提出了一个新的框架。这种设计能够处理时间序列中的非稳态、波动聚簇和不同市场制度的转换，而无需依赖严格的参数假设。对比现有方法（如GARCH、历史模拟、静态量ile回归），TCP在高波动性时期能够提供更精确且具有竞争力的预测区间。
### Conclusion
TCP提供了一种无分布、自适应且可解释的金融不确定性量化方法，从而推动了统计推理与机器学习在金融领域的融合。TCP在覆盖度和锐度之间找到了良好的平衡，特别是在高波动性时期。
## 703. `cs.LG` - 为资源受限的自主感知模拟折射失真和天气引起的伪影 [PDF](https://arxiv.org/pdf/2507.05536), [HTML](https://arxiv.org/abs/2507.05536)
### Authors
Moseli Mots'oehli,Feimei Chen,Hok Wai Chan,Itumeleng Tlali,Thulani Babeli,Kyungim Baek,Huaijin Chen
### Background
在低资源环境下，特别是非洲地区，自动驾驶汽车数据集的稀缺性已成为实现稳健感知的关键障碍。现有的数据集通常无法覆盖不同城市、乡村和未铺装道路上的复杂驾驶场景。因此，迫切需要增强现实且低成本的方法来扩充数据，以支持这些地区的自动驾驶研究。
### Innovation
本文提出了一种程序化扩增管道，能够以实际的成本对低成本单目汽车监控摄像头视频进行丰富处理，模拟出符合非洲特定驾驶挑战的折射失真和天气引起的伪影。这种扩增管道使用折射模块模拟低质量镜头和大气湍流导致的光学效应，使用天气模块添加均匀雾、非均匀雾和镜头眩光等功能。
### Conclusion
为了构建基准，我们使用三种图像恢复模型提供了基线性能。为支持非洲欠发达地区的感知研究，而无需进行昂贵的数据采集、标注或模拟，我们公开了失真工具包、扩增数据集分割和基准结果。这一工作为提高非洲道路交通场景下的自动驾驶感知提供了一种新的方法。
## 704. `cs.LG` - 特殊酉群参数化对于可训练的变量子电路 [PDF](https://arxiv.org/pdf/2507.05535), [HTML](https://arxiv.org/abs/2507.05535)
### Authors
Kuan-Cheng Chen,Huan-Hsin Tseng,Samuel Yen-Chi Chen,Chen-Yu Liu,Kin K. Leung
### Background
文章提出了SUN-VQC，这是一种变量子电路的架构，其基本层是由一个对称限制的Lie子群中的单指数组成，即$text{SU}(2^k) text{subset} text{SU}(2^n)$，其中$k text{ll} n$。这种限制将动态度量空间从$text{O}(4^n)$降低到了$text{O}(4^k)$，从而减少了梯度方差的指数抑制，并规避了硬实时效类电路中常见的荒原平原问题。文章通过通用参数位移规则获得了兼容硬件的确切梯度，从而避免了辅助量子比特和有限差分偏见。数值实验显示，与深度匹配的Pauli旋转或硬实时效类电路相比，SUN-VQCs保持了数个量级更大的梯度信号、收敛速度快2-3倍，并且最终的保真度更高。这些结果表明，Lie子代数工程为可工作量子处理器兼容的荒原平原抵抗性变量子态提供了有原则和可扩展的路径。
### Innovation
提出了SUN-VQC架构，通过限制在$text{SU}(2^k)$子空间中进行演化，将动态度量空间从$text{O}(4^n)$降低到$text{O}(4^k)$。此外，通过通用参数位移规则得出精确的可兼容硬件的梯度，避免了辅助量子比特和有限差分偏见。实验表明，SUN-VQCs在量子编码和分类任务上表现出更高性能，相比深度匹配的Pauli旋转或硬实时效类电路具有显著优势。
### Conclusion
Lie子代数工程为可工作量子处理器兼容的荒原平原抵抗性变量子态提供了一种有原则和可扩展的路径。SUN-VQCs在处理量子编码和分类任务中取得了显著的性能优势，这展示了其在量子计算领域的潜力。
## 705. `cs.LG` - 带有张量权重的神经网络和对应的费米子量子场论 [PDF](https://arxiv.org/pdf/2507.05303), [HTML](https://arxiv.org/abs/2507.05303)
### Authors
Guojun Huang,Kai Zhou
### Background
现有的神经网络量子场论（NN-QFT）工作已经将实数值架构与玻色子场联系起来。然而，该文通过将复值神经网络（CVNNs）与张量权重相结合，填补了这一框架中的理论空白，将CVNNs与费米子量子场论（QFT）建立了一种根本性的联系。通过将隐藏层到输出层的权重提升为克利福德代数张量，实现了费米子统计所需的反交换关系。
### Innovation
本文通过引入带有张量权重的复值神经网络，首次在相关函数和生成函数的层面上建立了与费米子量子场论的明确映射。这种架构超越了玻色子理论，并为将费米子对称性编码到机器学习模型中开辟了途径，具有量子模拟和格点场论等潜在应用。
### Conclusion
在无限宽度极限下，生成泛函的分析研究揭示了输入层到最后一层隐藏层之间的参数对应于量子系统的本征值，隐藏到输出层的权重参数对应于动态的费米子场。连续极限下，重现了自由费米子相关函数，图解展开证实了反交换关系。该工作为从神经架构到费米子量子场论提供了首个具体的映射，扩展了NN-QFT领域，并为机器学习中的费米子对称性编码打开了新的研究方向。
## 706. `cs.LG` - LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks [PDF](https://arxiv.org/pdf/2507.05346), [HTML](https://arxiv.org/abs/2507.05346)
### Authors
William Fleshman,Benjamin Van Durme
### Background
随着针对特定任务和领域进行了微调的语言模型专家数量不断增加，高效的选择和组合方法显得尤为重要。现有的方法大多依赖于额外的数据训练，但在许多场景中，额外的数据是不可获取或不现实的。
### Innovation
本文提出了一种名为LoRA-Augmented Generation (LAG)的方法，它利用了大规模的知识库和任务特定的LoRA适配器。LAG不需要额外的训练或数据访问，通过逐词和逐层的方式高效地筛选、检索和应用专家。
### Conclusion
我们在各种知识密集型任务上评估了LAG，发现其性能优于现有无需数据的方法。我们还探讨了当额外数据可用时的情景，证明了LAG与检索增强生成（RAG）等替代解决方案的兼容性。
## 707. `cs.LG` - ReLayout: 结合关系推理的多模态大型语言模型的内容感知布局生成 [PDF](https://arxiv.org/pdf/2507.05568), [HTML](https://arxiv.org/abs/2507.05568)
### Authors
Jiaxu Tian,Xuehui Yu,Yaoxing Wang,Pan Wang,Guangqian Guo,Shan Gao
### Background
内容感知布局旨在适当地布置设计元素，以有效传达信息。最近，利用大型语言模型（LLMs）自动生成布局的趋势取得了显著成效。然而，现有的LLM基方法未能充分解释视觉主题和设计元素之间的空间关系，导致布局生成中的结构性和多样性的缺陷。为解决这一问题，引入了ReLayout，这是一种利用关系-CoT的新方法，通过从设计概念出发生成更合理且具美学一致性的布局。这种新方法通过引入显式的关系定义，如元素之间的区域、显著性和边缘，增强布局注释，并将布局分解为更小、结构化且递归的部分，以便生成更结构化的布局。
### Innovation
ReLayout 通过引入显式的关系定义和布局原型重平衡采样器，解决了现有方法忽略的视觉主题和设计元素的空间关系问题。首先，通过定义区域、显著性和元素之间的边缘等关系，增强布局注释，将布局分解为更小的部分。其次，引入布局原型重平衡采样器，从三个维度定义布局原型特征，并量化不同的布局风格，解决生成过程中的均衡性问题，提高生成布局的多样性。
### Conclusion
大量的实验结果表明，ReLayout 在基线方法上表现出优越性，并能够生成更多符合人类审美且具有解释性的结构性和多样性的布局。
## 708. `cs.LG` - 零阶投影梯度下降的固有隐私性探究 [PDF](https://arxiv.org/pdf/2507.05610), [HTML](https://arxiv.org/abs/2507.05610)
### Authors
Devansh Gupta,Meisam Razaviyayn,Vatsal Sharan
### Background
不同的私有零阶优化方法由于具有较低的内存需求最近受到了广泛关注，特别是在机器学习模型的私人精细调整中。当前的方法主要通过添加高斯噪声来私有化零阶方法。然而，由于零阶方法中的搜索方向本身是随机的，Tang et al. (2024) 和 Zhang et al. (2024a) 等研究者提出一个重要问题：零阶估计器中的固有噪声是否能够确保算法的整体差分隐私性？
### Innovation
本文解决了基于Oracle的优化算法中，当Oracle返回零阶梯度估计时，零阶投影梯度下降（ZO-GD）是否具有固有隐私性的问题。研究结果显示，在固定初始化条件下，存在强凸目标函数，使得运行ZO-GD并不是差分私密的。进一步研究显示，即使使用随机初始化且不透露（初始和）中间迭代结果，当最小化凸目标函数时，ZO-GD的隐私损失可以随迭代次数线性增长以上甚至更快，即增长速度优于线性。
### Conclusion
我们的结论是，即使不透露中间迭代结果，零阶投影梯度下降算法在一定条件下也不能保证差分隐私，其隐私损失会随迭代次数显著增长。
## 709. `cs.LG` - 生成式头戴式摄像机捕捉用于逼真化身 [PDF](https://arxiv.org/pdf/2507.05620), [HTML](https://arxiv.org/abs/2507.05620)
### Authors
Shaojie Bai,Seunghyeon Seo,Yida Wang,Chenghui Li,Owen Wang,Te-Li Wang,Tianyang Ma,Jason Saragih,Shih-En Wei,Nojun Kwak,Hyung Jun Kim
### Background
在虚拟现实（VR）和增强现实（AR）中实现逼真的化身动画一直具有挑战性，是因为难以获得面部的真实状态。头部佩戴摄像机（HMC）仅能提供部分红外（IR）观察，而外部安装的穹顶摄像机能够收集完整且与化身外貌匹配的观察资料。先前的工作依赖于分析-合成的方法，虽然能够生成精确的真实值，但存在面部表情和风格难以分离的问题。使用与相同个体匹配的HMC和穹顶摄像机进行大幅配对捕捉数据收集起来非常昂贵，而无法重用以适应不同的HMC视角和光照条件。
### Innovation
本文提出了一种新颖的生成式方法，生成式头戴式摄像机（GenHMC），利用大量的非配对的HMC捕捉数据，这比配对的数据更容易获取。该方法能够直接生成高质量的合成HMC图像，并根据穹顶相机捕捉的任何条件化身状态进行生成。通过手动分离输入的条件信号（即面部表情和视角）与面部外观，方法能够生成更准确的真实值。此外，此方法能够推广到未见过的身份，不再依赖配对捕捉数据。
### Conclusion
我们通过评估合成的HMC图像和使用新HMC-化身对应关系训练的通用面部编码器来验证这种方法的突破。这种方法在数据效率和现有最佳效果方面都有着更好的表现。
## 710. `cs.LG` - 利用Malliavin演算方法在扩散生成模型中的得分函数 [PDF](https://arxiv.org/pdf/2507.05550), [HTML](https://arxiv.org/abs/2507.05550)
### Authors
Ehsan Mirafzali,Frank Proske,Utkarsh Gupta,Daniele Venturi,Razvan Marinescu
### Background
分数扩散生成模型最近已成为一种强大的工具，用于建模复杂的数据分布。这些模型旨在通过确定性或随机微分方程（SDEs）学习得分函数，将已知概率分布映射到目标数据分布。得分函数通常使用诸如去噪或切片得分匹配、Hyvärinen的方法或薛定谔桥梁等各种近似技术进行估计。
### Innovation
本文研究了一个广泛的非线性扩散生成模型类的得分函数的精确、封闭形式表达式。通过结合现代随机分析工具（如Malliavin导数及其共轭算子（斯科罗霍德积分或Malliavin散度））和新的Bismut型公式，推导了得分函数的表达式。该表达式完全用第一和第二次变化过程来表示，系统地消除了所有的Malliavin导数，从而增强了其实用性。该理论框架为生成建模中的得分估计方法的发展提供了一个基本原则，使设计复杂概率分布的新采样算法成为可能。
### Conclusion
本研究的结果可以扩展到更广泛类型的随机微分方程，为分数基于扩散生成模型的发展打开了新的方向。
## 711. `cs.LG` - 超越检索：通过结合交叉编码器和GPT重排序器与LLMs实现生物医学问答 [PDF](https://arxiv.org/pdf/2507.05577), [HTML](https://arxiv.org/abs/2507.05577)
### Authors
Shashank Verma,Fengyi Jiang,Xiangning Xue
### Background
生物医学文献庞大、不断演进且持续增长，这使得及时获取相关信息变得极为重要。可靠的系统可以帮助研究人员、医疗专业人员甚至普通用户通过证据支持的知识来访问相关知识。生物医学领域中的BioASQ 2025 Task13b挑战赛作为一个重要的基准，提供了促进该领域发展的竞争平台。
### Innovation
本文提出了使用检索增强生成（RAG）系统的方法，该系统能通过检索相关PubMed文档和片段来生成答案。方法包括生成密集的医学文献嵌入以进行初始检索，并应用微调的交叉编码器和大型语言模型进行重新排名来识别最相关的文档。此外，还采用了少量指令提示调优的语言模型来生成答案。
### Conclusion
研究系统在检索任务中实现了0.1581的MAP@10，在排行榜上排名第10。在答案生成方面，宏F1分数为0.95（排名第12）、平均互逆排名（MRR）为0.64（排名第1）、平均F1分数为0.63（排名第5），并实现了ROUGE-SU4 F1分数为0.29（排名第11）。
## 712. `cs.LG` - 在多项逻辑博采游戏中享受非线性 [PDF](https://arxiv.org/pdf/2507.05306), [HTML](https://arxiv.org/abs/2507.05306)
### Authors
Pierre Boudart,Pierre Gaillard,Alessandro Rudi(PSL, DI-ENS, Inria)
### Background
研究者考虑了多项逻辑博采问题，这是广义线性博采问题的一种变体，环境通过多种可能结果的随机反馈引起学习者的选择，以最大化预期奖励。在二元设置中，已有工作主要侧重于理解逻辑模型非线性的影响（Faury et al., 2020; Abeille et al., 2021）。他们引入了一个与问题参数有关的常数κ*，该常数可能在某些问题参数上呈指数级增长，并由Sigmoid函数的导数捕获。κ*反映了非线性，并将现有T轮次的后悔保证从O(d√T)提高到O(d√T/κ*)。现有研究在此基础上，将其分析扩展到多项逻辑博采框架，使其适用于具有超过两个选择的复杂应用，诸如强化学习或推荐系统。这需要将κ*的定义扩展到多项式设置，并提出一个利用问题非线性的有效算法。我们的方法提供了问题依赖的后悔界 ½ O(Kd√T/κ*)，其中K 是选择的数量，κ* ≥ 1。该结果改善了现有的最好数量级的保证 ½ O(Kd√T)。此外，我们展示了 ½ Ω(d√T/κ*) 下界，表明我们的依赖于 κ* 是最优的。
### Innovation
研究将κ*的定义扩展到多项式设置，并提出了一种利用问题非线性的有效算法，从而提高了为多项逻辑博采问题设计的后悔界。该工作证明了对κ*的依赖是最佳的，改进了现有已知保证。对于多选择场景，此方法为复杂应用如强化学习或推荐系统提供了有效解决方案。
### Conclusion
本研究通过将对κ*的理解扩展到多项逻辑博采框架，并提出了一个新的算法，使得多项逻辑博采模式下的后悔度-opt(Kd√T/κ*)优于最优的现有数量级保证 ½ O(Kd√T)。研究结果表明，在含有多个选择的复杂应用中，我们的方法可以改善性能。此外，我们还证明了 ½ Ω(d√T/κ*) 下界，这是对κ*依赖性的最优性证明。
## 713. `cs.LG` - Agentic-R1：提炼双重策略推理 [PDF](https://arxiv.org/pdf/2507.05707), [HTML](https://arxiv.org/abs/2507.05707)
### Authors
Weihua Du,Pranjal Aggarwal,Sean Welleck,Yiming Yang
### Background
当前的长链条推理（长-CoT）模型擅长数学推理，但依赖于缓慢且容易出错的自然语言记录。工具增强的代理通过代码执行解决算术问题，但在复杂逻辑任务上经常失败。
### Innovation
我们引入了DualDistill微调框架，将多种教师的互补推理策略提炼到一个统一的学生模型中。这种方法训练出了Agentic-R1，它能根据不同查询动态选择最优策略，并使用工具处理算术和算法问题，对于抽象问题则使用文本推理。该方法提升了各种任务的准确率，包括计算密集型和标准基准测试，证明了多策略提炼在实现稳健且高效的推理方面的有效性。
### Conclusion
我们的方法提高了不同任务的准确性，包括计算密集型和标准基准测试，展示了多策略提炼在实现稳健且高效推理方面的有效性。我们的项目可以在以下网址获取：this https URL
## 714. `cs.LG` - 通过微分包含和选择原理实现精确且高效的压缩感知去噪 [PDF](https://arxiv.org/pdf/2507.05562), [HTML](https://arxiv.org/abs/2507.05562)
### Authors
Gabriel P. Langlois,Jérôme Darbon
### Background
basis pursuit denoising (BPDN) 是压缩感知、统计学和机器学习中的一个基石。尽管已经提出了多种BPDN算法，但这些算法不可避免地存在缺陷，要么牺牲准确性以换取效率，要么反之。因此，最先进的算法在处理高维应用时，无法在合理的时间内提供准确的解决方案。本文正是针对这一问题，提出了一种新的基于微分包含的选择原则的精确且高效的BPDN算法。证明了该原则可以将BPDN的对偶问题转换为计算积分投影动力系统轨迹的问题，其轨迹和极限可以精确计算。
### Innovation
本文提出了一种基于微分包含的选择原则的新算法，能够将BPDN的对偶问题转换为计算积分投影动力系统轨迹的问题，从而可以精确地解决该问题。该算法在数值精度上达到了机器精度，并且适用于计算正则化路径，非常快速。该算法在准确性和效率上都优于最先进的算法。此外，全球解的连续性还提供了一种BPDN的严格同伦算法以及一种可用于计算可行解的新贪婪算法。上述成果为解决其他聚类约束优化问题提供了可能
### Conclusion
该算法不仅在高维应用中提供了准确的解决方案，还提供了一种计算可行解的新贪婪算法，并且可以应用于其他聚类约束优化问题。
## 715. `cs.LG` - DATABench：从对抗视角评估深度学习中的数据集审计 [PDF](https://arxiv.org/pdf/2507.05622), [HTML](https://arxiv.org/abs/2507.05622)
### Authors
Shuo Shao,Yiming Li,Mengren Zheng,Zhiyang Hu,Yukun Chen,Boheng Li,Yu He,Junfeng Guo,Tianwei Zhang,Dacheng Tao,Zhan Qin
### Background
深度学习在多个领域的广泛应用极大地依赖于高质量和多样化的训练数据集。然而，数据集使用情况的缺乏透明度引发了严重的隐私和版权问题。为了应对这些问题，研究开发了数据集审计技术，旨在确定给定模型是否使用了特定的数据集。尽管存在一些审计方法，但它们在对抗性攻击中的稳健性尚未得到充分研究。为了填补这一空白，本文从对抗视角开展了全面的审计方法评估研究，分析了现有的方法和攻击目标，并提出了新的攻击策略和基准。
### Innovation
1. 提出了一种新的分类法，基于内部特征（源自数据本身）和外部特征（为审计目的人工引入）来分类现有的审计方法。2. 阐述了两种主要的攻击类型：逃避攻击旨在掩饰数据集的使用，伪造攻击旨在错误地指责未使用的数据集。3. 建立了新的基准测试（DATABench），包含17种逃避攻击、5种伪造攻击和9种代表性审计方法。4. 实验表明，所有评估的审计方法在对抗性环境下均不够 robust 或 distinguishable，强调了急需开发一种更安全、可靠的审计方法的紧迫性以抵御高级对抗性操作。
### Conclusion
实验结果指出了在对抗性环境中现有的审计方法的不足，突显了开发能够抵御复杂对抗性操作的更安全和可靠审计方法的必要性。
## 716. `cs.LG` - 如何使用LLM检测不到提示注入 [PDF](https://arxiv.org/pdf/2507.05630), [HTML](https://arxiv.org/abs/2507.05630)
### Authors
Sarthak Choudhary,Divyam Anshumaan,Nils Palumbo,Somesh Jha
### Background
LLM集成的应用程序和代理容易遭受提示注入攻击，在这种攻击中，攻击者会将恶意指令隐藏在看似无害的用户输入中，以操纵LLM的预期行为。最近的防御措施是基于‘已知答案检测’（KAD）技术，这种技术利用LLM将输入分类为干净或被污染的状态，已经取得了接近完美的效果。然而，这种方法存在设计缺陷，可能会失效。论文正式描述了KAD框架，并发现其核心安全性假设可能无效。
### Innovation
本文设计了一种有系统的适应性攻击方法，称为DataFlip，用于利用这一根本性弱点。DataFlip以低于1.5%的检测率成功地躲避KAD防御，同时以高达88%的成功率引发恶意行为。这种方法的优势在于不依赖于对LLM的白盒访问以及无需进行优化程序步骤。这项工作揭示了KAD方法的基本缺陷，并提供了可以有效利用这种缺陷的攻击方法，提出了新的挑战和应对策略。
### Conclusion
KAD方法存在结构性的设计缺陷，可能会失效。未来的防御策略应更加注重攻击者的适应性和复杂性。
## 717. `cs.LG` - 一种用于地球观测的卫星-地面协同大型视觉-语言模型系统 [PDF](https://arxiv.org/pdf/2507.05731), [HTML](https://arxiv.org/abs/2507.05731)
### Authors
Yuxin Zhang,Jiahao Yang,Zhe Chen,Wenjun Zhu,Jin Zhao,Yue Gao
### Background
近来，大型视觉-语言模型（LVLMs）在数据中心对低地球轨道（LEO）卫星地球观测图像进行分析展示了强大的能力。然而，快速的卫星运动、短暂的卫星-地面站（GS）通信窗口以及巨大的图像尺寸造成了数据下载的挑战。为实现接近实时的地球观测应用（如灾害和极端天气监测），需探索如何在LEO卫星网络中部署LVLM，并设计了一个高效的卫星-地面协同LVLM推理系统——SpaceVerse。
### Innovation
在此研究中，首次提出了一个包括紧凑型LVLM部署在卫星上处理轻量任务和常规LVLM在GS处理复杂任务的解决方案。进一步地，提出了一种计算与通信协同设计框架，包括逐级置信网络和基于注意力的多尺度预处理，用于确定在卫星上的推理数据并在卫星-GS传输前减少数据冗余。研究结果表明，与现有基线相比，在实际LEO卫星星座和数据集上实现和评估SpaceVerse，可以使准确率平均提高31.2%，延迟减少51.2%。
### Conclusion
通过设计和实现一种高效紧凑的LVLMs部署方案和计算与通信协同设计框架，SpaceVerse系统有效解决了LEO卫星图像分析中的数据下载挑战，促进了接近实时的地球观测应用。
## 718. `cs.LG` - GATMesh：使用图神经网络进行时钟网格定时分析 [PDF](https://arxiv.org/pdf/2507.05681), [HTML](https://arxiv.org/abs/2507.05681)
### Authors
Muhammad Hadir Khan,Matthew Guthaus
### Background
时钟网在高性能VLSI系统中用于最小化时钟偏斜和处理PVT变化至关重要，但由于会聚路径、多源驱动和输入网格缓冲偏斜等因素，分析它们十分困难。SPICE仿真虽然准确但速度慢；其他简化模型则无法捕捉关键效果，如下摆和输入偏斜。
### Innovation
提出了一种基于图神经网络（GNN）的框架GATMesh，将时钟网格建模为具有增强结构和物理特性的图。通过训练SPICE数据，GATMesh在未见基准上的延迟误差仅为5.27皮秒，且比多线程SPICE仿真快47146倍。
### Conclusion
GATMesh通过图神经网络模型实现了高效且高精度的时钟网格定时分析，为高性能VLSI系统的设计和优化提供了有力工具。
## 719. `cs.LG` - 仅说更好或更差：无需手动注释的医疗图像分割人类-人工智能协作框架 [PDF](https://arxiv.org/pdf/2507.05815), [HTML](https://arxiv.org/abs/2507.05815)
### Authors
Yizhe Zhang
### Background
医学图像的手动注释是一个耗费人力和时间的过程，成为开发和部署强大医疗成像AI系统的主要瓶颈。现有的方法需要详细的像素级手动标注，导致了显著的时间和资源开销.
### Innovation
提出了一种新颖的人类-人工智能协作框架，通过消除明确的像素级手动标注需求，大幅度减少了注释负担。核心创新在于偏好学习范式，其中人类专家提供最少的、直觉性的反馈，通过比较AI生成的分割与上一个版本的优劣来完成。该框架包括四个关键组成部分：可调整的基础模型、基于特征相似性的标签传播、学习于人类更好或更差反馈的点击代理以及多轮分割学习流程，该流程使用基于基础模型的标签传播生成的伪标签和点击代理训练最新的分割网络.
### Conclusion
在三个公共数据集上的实验显示，所提出的框架只需要二元偏好反馈就能达到有竞争力的分割性能，而不必要求专家直接手动注释图像.
## 720. `cs.LG` - DESIGN: 通过服务器端输入图修剪实现加密GNN推断 [PDF](https://arxiv.org/pdf/2507.05649), [HTML](https://arxiv.org/abs/2507.05649)
### Authors
Kaixiang Zhao,Joseph Yousry Attalla,Qian Lou,Yushun Dong
### Background
图神经网络（GNNs）已在多种基于图的学习任务中取得了最先进的性能。然而，在全同态加密（FHE）等加密域中实现隐私保护的GNNs通常会带来显著的计算开销，使得实时和隐私保护的推理变得不切实际。现有基于FHE的GNN方法往往忽视了输入数据的冗余，采用统一的计算策略，导致效率低下。
### Innovation
我们提出了DESIGN（ EncrypteD GNN Inference via sErver-Side Input Graph pruNing），这是一种高效的加密GNN推理的新框架。DESIGN通过服务器端执行的分层优化策略解决了现有FHE GNN方法的关键效率限制：首先，从加密图中计算出与FHE兼容的节点重要性分数（基于加密度统计）。这些分数指导同态划分过程，生成多级重要性掩码，直接在FHE下生成。此动态生成的掩码通过逻辑移除不重要元素用于输入图修剪，并提出了一种新颖的自适应多项式激活方案，其中激活复杂度可根据节点重要性级别进行调整。实验评估表明，DESIGN显著加速了FHE GNN推理，同时保持了可比的模型精度，提供了一种适用于安全图分析的稳健解决方案。
### Conclusion
DESIGN大幅提高了FHE GNN推理的速度，同时保持了可竞争的模型精度，为安全图分析提供了稳健的解决方案。
## 721. `cs.LG` - 全路由：稀疏Mixture-of-Experts中的路由决策共享在语音识别中的应用 [PDF](https://arxiv.org/pdf/2507.05724), [HTML](https://arxiv.org/abs/2507.05724)
### Authors
Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly
### Background
Mixture-of-experts (MoE) 架构最初应用于语言模型，现在扩展到了自动语音识别（ASR）。传统 MoE 方法，如 Switch Transformer，在每一层中独立地将专家进行路由。我们的分析表明，在大多数层中，路由选择与其他层的选择没有很强的相关性。为了增强不同层中专家之间的协同作用并鼓励专业分工，本文提出在不同 MoE 层中使用共享路由。
### Innovation
引入了一种新的全路由模型（Omni-router Transformer），它在不同 MoE 层中使用共享路由，以提高专家之间的协同作用并鼓励更专业的分工。实验证明，全路由变换器在大规模伪标记数据集上具有较低的训练损失，并且在 10 个多样化的语音识别基准测试中表现优于密集模型和 Switch Transformer 模型，平均词错误率分别降低了 11.2% 和 8.2%，同时提供了结构化的专家使用和更好的数据变异性鲁棒性。
### Conclusion
全路由变换器在语音识别中表现出色，能够实现较低的训练损失，并且在多个基准测试中优于现有模型。
## 722. `cs.LG` - PSAT: 儿科分割方法通过成人增强和迁移学习 [PDF](https://arxiv.org/pdf/2507.05764), [HTML](https://arxiv.org/abs/2507.05764)
### Authors
Tristan Kirscher(ICube, ICANS),Sylvain Faisan(ICube),Xavier Coubez(ICANS),Loris Barrier(ICANS),Philippe Meyer(ICube, ICANS)
### Background
儿科医学影像检查因其与成人之间显著的解剖和发育差异而具有独特的挑战。直接使用在成人数据上训练的分割模型通常会导致性能不佳，尤其是在处理小型或快速变化的结构时。为了应对这些挑战，研究者们提出了多种基于nnU-Net框架的方法，这些方法主要在四个关键维度上有所不同：(i) 培训计划的指纹数据集（成人、儿童或两者组合）；(ii) 学习集（成人、儿童或混合）；(iii) 数据增强参数；(iv) 迁移学习方法（微调 vs 持续学习）。
### Innovation
本文引入了一种名为PSAT（Pediatric Segmentation Approaches via Adult Augmentations and Transfer learning）的研究方法，通过系统研究上述四个维度对分割性能的影响。PSAT在两个儿童CT数据集上进行了基准测试，并与最新的分割方法和商用放疗解决方案进行了比较。研究表明，基于成人指纹数据集的培训计划与儿科结构不匹配，会导致小型结构分割性能显著下降，而持续学习策略能够缓解机构更改，从而增强在不同儿科数据集之间的泛化能力。
### Conclusion
实验结果表明，基于成人指纹数据集的训练计划与儿科解剖结构不匹配，导致精细结构分割性能显著下降。持续学习策略可以缓解机构更改，从而提高在多种儿科数据集上的泛化能力。
## 723. `cs.LG` - 将可学习的量子谱滤波器用于混合图神经网络 [PDF](https://arxiv.org/pdf/2507.05640), [HTML](https://arxiv.org/abs/2507.05640)
### Authors
Ammar Daskin
### Background
该论文提出了一种参数化量子电路，作为图神经网络中的卷积和池化层。这项研究基于图拉普拉斯算子的特征空间可以通过基于QFT的电路进行近似的方法。这种方法利用拉普拉斯算子从邻接矩阵确定链接，简化了传统图神经网络中昂贵的经典计算步骤。
### Innovation
该研究的创新点在于它展示了一种通过基于QFT的电路近似拉普拉斯算子特征空间的方法，这种方法仅需$n=text{log}(N)$个量子比特即可构建近似多项式的深度电路，从而可以消除传统方法中用于近似拉普拉斯算子可学习函数的昂贵经典计算。此外，这种电路可以视为一个有效的卷积加池化层，能够将$N$维信号压缩为$n$维信号，具有指数级压缩率。
### Conclusion
研究实例化了一种结合经典神经网络预测头部的量子电路，最终构建了一个完整的图神经网络。基于这种方法，在一个具有几何结构的场景下，使用仅1-100个可学习参数的量子电路和极少的经典层参数（1000-5000个），所得的结果与基准方法相当，甚至在某些情况下更优。
## 724. `cs.LG` - HRRRCast: 一种用于区域天气预报的数据驱动模拟器 [PDF](https://arxiv.org/pdf/2507.05658), [HTML](https://arxiv.org/abs/2507.05658)
### Authors
Daniel Abdi,Isidora Jankov,Paul Madden,Vanderlei Vargas,Timothy A. Smith,Sergey Frolov,Montgomery Flora,Corey Potvin
### Background
HRRR模型是用于美国本土地区操作性天气预报的湍流允许模型。为了提供一种计算上更有效的替代方案，本文介绍了HRRRCast，这是一种使用高级机器学习技术构建的数据驱动模拟器。HRRRCast包括两种架构：基于ResNet的模型（ResHRRR）和基于图神经网络的模型（GraphHRRR）。
### Innovation
1. 培训模型覆盖整个CONUS区域；2. 使用多种预测时间来提高长期技能；3. 基于分析数据训练，而非错误使用的+1小时分析数据；4. 将未来GFS状态作为输入，实现下拉缩放，提高长期预测准确性；5. 网格、邻域和对象基于的度量证实了暴风雨位置的改进、频率偏差的降低和更高的成功率；6. HRRRCast的集合预报在空间细节上更清晰，功率谱更接近HRRR分析。
### Conclusion
ResHRRR在轻降雨阈值（20 dBZ）下优于HRRR预报，并在中等阈值（30 dBZ）下表现出竞争力。尽管目前GraphHRRR表现不佳，但为其未来的图形化的预报奠定了基础。HRRRCast代表了高效的数据驱动区域天气预测的发展，具有竞争性和集合能力。
## 725. `cs.LG` - 不可精确概率上的属性诱选 [PDF](https://arxiv.org/pdf/2507.05857), [HTML](https://arxiv.org/abs/2507.05857)
### Authors
James Bailie,Rabanus Derr
### Background
研究了能够通过最小化风险来确定概率分布属性的属性诱选方法。此前的研究主要集中在精确概率上，而该研究则进一步探讨了将属性诱选方法推广到不可精确概率（IP）领域。其动机来自于多分布学习，即以最小化单一风险（在精确概率下）的机器学习范式为基础，改为使用$boldsymbol{text{Γ}}$-最大化风险最小化方法针对不可精确概率。
### Innovation
提出了不可精确概率属性可诱择的必要条件，并通过Bayes对解释了可诱择的不可精确概率属性所实际获取的标准属性。这一创新在于扩展了属性诱选方法的应用范围，使其能应用于更广泛的风险管理场景。
### Conclusion
不可精确概率属性可诱择的必要条件已经被明确提出，这意味着能够确定一些关键属性。这些属性的了解是通过Bayes对进行的，即所诱择的不可精确概率属性等同于最大Bayes风险分布的标准属性。
## 726. `cs.LG` - 普遍化和统一的硬性与伪熵等价关系 [PDF](https://arxiv.org/pdf/2507.05972), [HTML](https://arxiv.org/abs/2507.05972)
### Authors
Lunjia Hu,Salil Vadhan
### Background
伪熵表征提供了一个量化的精确展示，说明计算硬度和计算随机性之间的紧密关系。论文通过对统一伪熵表征的证明，扩展并加强了之前针对均匀和非均匀计算模型的结果，适用于广泛的熵概念家族，其中包括香农熵和最小熵等常见概念。此外，论文展示了不同熵概念的表征可以通过单一通用函数同时实现，该函数能够同时证明计算硬度与计算随机性。
### Innovation
论文的关键技术见解在于，算法公平的近期文献中的权重限制校准概念与标准计算不可区分性（在公平文献中称为多重准确性）足以证明通用熵概念下的伪熵表征。这一发现展示了权重限制校准增强传统复杂性理论不变性定理和泄漏模拟定理的能力，并实现了与Casacuberta等人（2024）基于更强校准多准确性假设的伪熵表征相比复杂性依赖性指数级改进。此外，论文证明了多校准的指数依赖性对于多校准以及较弱的校准多准确性都是不可避免的。
### Conclusion
论文通过单一通用函数同时展示了计算硬度和计算随机性的表征，实现了与基于更强校准多准确性的其他方法相比在复杂性依赖性上的指数级改进，同时证明了多校准的指数依赖性不可避免。
## 727. `cs.LG` - 基于激光混沌强化学习的高吞吐量稳定声纳接力分配 [PDF](https://arxiv.org/pdf/2507.05900), [HTML](https://arxiv.org/abs/2507.05900)
### Authors
Zengjing Chen,Lu Wang,Chengzhi Xing
### Background
本研究关注水下声纳网络中的稳定声纳接力分配问题。大多数现有文献主要关注的是声纳接力分配的稳定性，但本研究提出了古典稳定布局和模糊稳定布局两种不同的目标，通过激光混沌为基础的方法来实现这些稳定的布局，实现高吞吐量。研究表明，激光混沌产生的随机数和多处理在交换过程中的应用能够提高吞吐量，增强对未来环境变化的适应性。模糊认知相较于精确认知而言，更有利于形成更稳定的配置，减少波动。这些发现为复杂水下环境中的接力节点选择提供了实用的方法和理论基础。
### Innovation
本研究的创新之处在于提出了一种基于激光混沌的多处理学习方法（LC-ML），用于高效获得高吞吐量并且快速达到稳定状态。该方法采用激光混沌生成的随机数来学习多源节点的接力分配方案，有效满足网络稳定性和高效性的双重需求，增强了系统在动态环境下的适应能力。模糊认知的方法也被引入，使得系统能够在复杂环境下形成更稳定且波动更小的配置。
### Conclusion
本研究通过激光混沌强化学习的方法，充分探索接力节点的决策力，兼具高吞吐量需求和适应动态变化环境的能力。模糊的认知方式使系统形成更稳定的配置，减少了波动性。这对于复杂水下环境中的声纳接力节点选择具有实用和理论意义。未来的工作可以考虑扩大应用场景，进一步提高系统性能和适应能力。
## 728. `cs.LG` - 在线核空间中具有$β$-和$ϕ$-混合序列的正则化学习算法 [PDF](https://arxiv.org/pdf/2507.05929), [HTML](https://arxiv.org/abs/2507.05929)
### Authors
Priyanka Roy,Susanne Saminger-Platz
### Background
本文在核希尔伯特空间（RKHS）中研究了一种基于一类依赖过程的在线正则化学习算法。选择的这类过程的依赖程度通过混合法系数来衡量。作为代表性案例，我们分析了一个严格平稳马尔可夫链，其依赖结构由$?phi$-和$?beta$-混合法系数表征。
### Innovation
在上述假设下，我们推导出指数和多项式衰减的混合法系数的概率上界，以及该类算法的收敛速率。
### Conclusion
本文研究了一种基于$?beta$-和$?phi$-混合序列的在线核空间正则化学习算法，并推导出了各类重要结论。
## 729. `cs.LG` - 通信高效的模块化联邦学习在拥挤环境中抓取姿态检测中的应用 [PDF](https://arxiv.org/pdf/2507.05861), [HTML](https://arxiv.org/abs/2507.05861)
### Authors
Woonsang Kang,Joohyung Lee,Seungjun Kim,Jungchan Cho,Yoonseon Oh
### Background
抓取姿态检测（GPD）是机器人自主性的基本能力，但由于依赖于大小和多样性的大数据集，存在重要的数据隐私和集中化挑战。联邦学习（FL）提供了一种隐私保护的解决方案，但在应用到GPD时，由于大型模型的高通信开销而受到阻碍，这是一个关键问题，特别是在资源受限的机器人中。
### Innovation
我们提出了一种新的模块级别的联邦学习框架，通过分析GPD模型功能组件的学习动态，首先识别出收敛较慢的模块，并将额外的通信努力分配给这些模块。该框架包含两个阶段：标准的全模型训练阶段，随后是一个通信效率高的阶段，在此阶段中仅训练识别出的收敛较慢的模块，并聚合它们的部分更新。实验结果表明，我们的方法在给定的通信预算下比标准FedAvg和其他基线方法具有更高的准确性。此外，我们在物理机器人的实际实验中验证了我们的方法，在杂乱场景中具有更高的抓取成功率。
### Conclusion
我们的工作展示了在去中心化方式下训练鲁棒且通用的GPD模型的通信高效的框架，有效改善了通信成本和模型性能之间的权衡。
## 730. `cs.LG` - ADPv2: 一种用于结直肠疾病潜在生物标志物发现的层次结构组织类型注释数据集 [PDF](https://arxiv.org/pdf/2507.05656), [HTML](https://arxiv.org/abs/2507.05656)
### Authors
Zhiyuan Yang,Kai Li,Sophia Ghamoshi Ramandi,Patricia Brassard,Hakim Khellaf,Vincent Quoc-Huy Trinh,Jennifer Zhang,Lina Chen,Corwyn Rowsell,Sonal Varma,Kostas Plataniotis,Mahdi S. Hosseini
### Background
计算病理学（CoPath）利用组织病理学图像来提高临床病理的诊断精度和重复性。然而，由于需要大量的专业知识和高昂的标注成本，目前可供使用的标注有细分类层次组织类型（HTT）的公共数据集仍然非常稀缺。现有的数据集如数字病理学图鉴（ADP）可以提供跨多种器官的通用HTT注释，但无法深入研究特定器官的疾病。在此基础上，我们提出了ADPv2数据集，专注于消化道的组织病理学分析，提供了详细标记的20,004张结肠健康活检图像切片，注释了32个不同层次的3级组织类型。基于此数据集，我们经过两阶段训练提出了多标签表示学习模型，并使用VMamba架构在多标签分类的结肠组织类型中达到了平均精度88%。此外，通过分析该模型在不同结肠疾病受损组织上的预测行为，揭示了统计模式，证明了结肠癌发展的两种病理途径，展示了数据集对特定器官疾病深入研究的潜力，有助于潜在生物标志物的发现。
### Innovation
ADPv2数据集专注于消化道的组织病理学，并提供详细层次的32种组织类型注释，主要用于数字病理学，不同于现有数据集ADP，它能够进行特定器官疾病研究，比如结肠癌，并成功训练了模型，实现了多标签分类性能的提升。此外，通过模型的预测行为分析，揭示了结肠癌发展中的统计模式，验证了潜在的病理机制。该数据集和模型为消化道疾病特别是结肠疾病的生物标志物研究提供了有力支持。
### Conclusion
通过分析ADPv2数据集上模型的预测行为，揭示了结肠癌发展的两种病理模式，并确认了多种统计模式。这表明ADPv2数据集能够进行结肠疾病的深入研究，为结直肠疾病的潜在生物标志物发现提供支持。此外，该数据集和背后的模型不仅提高了在消化道疾病研究中的标注精度，也为其他相关的临床病理研究提供了有价值的资源。
## 731. `cs.LG` - 稳健的实时语音工作量估计用于智能化人机器系统 [PDF](https://arxiv.org/pdf/2507.05985), [HTML](https://arxiv.org/abs/2507.05985)
### Authors
Julian Fortune,Julie A. Adams,Jamison Heard
### Background
在需要快速准确完成任务的环境中（例如，远程操作无人机），低和高的操作员工作负荷会降低任务表现。通过智能调节系统需求和交互方式，响应操作员工作负荷状态的变化，可以在避免不必要的工作负荷状态下提高表现。现有的工作负荷评估系统可以通过后处理估计多个工作负荷组成部分，但很少有系统能够实时估计语音工作负荷或在实时操作中发挥作用。因此，提出了一个能够估计实时语音工作负荷并在不需要时减轻不必要工作负荷状态的算法。
### Innovation
算法能够实时估计语音工作负荷，并在出现不必要工作负荷状态时进行调整。同时，该算法还证实了其在不同个体和人机团队模式下的普适性。这一研究成果对于开发适应性强的人机系统至关重要
### Conclusion
通过本研究，我们展示了如何实时估计语音工作负荷并在操作员状态不理想的情况下进行有效的调整。这不仅增加了系统在高工作负荷状态下的适应性，而且提高了操作员的表现。这一成果为开发更智能、更适应的人机交互系统提供了重要的技术支持。
## 732. `cs.LG` - 使用离线强化学习的实时通信稳健带宽估计 [PDF](https://arxiv.org/pdf/2507.05785), [HTML](https://arxiv.org/abs/2507.05785)
### Authors
Jian Kai,Tianwei Zhang,Zihan Ling,Yang Cao,Can Shen
### Background
实时通信（RTC）系统中的带宽估计（BWE）至关重要。传统的启发式方法在动态网络下缺乏适应性，而在线强化学习（RL）方法则面临高的探索成本和潜在的服务中断问题。相比之下，离线RL利用了从真实环境收集的高质量数据，提供了改进的方法，但仍然存在离分布动作、策略从多样化数据集中提取和生产系统中可靠部署等问题。
### Innovation
本文提出了一种基于离线RL的稳健带宽估计框架RBWE，结合Q-ensemble（Q函数的集合）和高斯混合策略来降低离分布风险并提升策略学习效果。此外，还引入了应急机制，以在高不确定性情况下切换到启发式方法，确保部署的稳定性。
### Conclusion
实验结果显示，RBWE在减少过估计错误方面降低了18%，并提高了10%分位数的用户体验质量（QoE）18.6%，证明其在RTC应用中的实用有效性。
## 733. `cs.LG` - 在具有序列依赖性的市场中击败最佳固定再平衡组合：通用凯利准则推广和适用于序列依赖性市场的通用学习算法 [PDF](https://arxiv.org/pdf/2507.05994), [HTML](https://arxiv.org/abs/2507.05994)
### Authors
Duy Khanh Lam
### Background
在在线投资组合优化框架中，现有的学习算法生成的策略累计财富远逊于事后最佳固定再平衡组合，尽管它们在渐近增长率方面是一致的。通过引入更多辅助信息可以改进这一不佳表现，但这也带来了特征选择和高维设置的困难。传统的凯利准则需要资产回报独立，但在具有序列依赖性的市场中，它不适用。尽管可以利用资产回报中的潜在序列依赖模式，但通常需要大量的训练数据，而该论文提出了一种仅依赖逐渐揭示的数据来学习这种依赖关系的算法。该算法无需对数据分布作任何假设，以形成最终超越最优固定再平衡组合累计财富的策略。
### Innovation
该论文提出了一种通用学习算法，能够在具有序列依赖性的市场中生成超越最优固定再平衡组合累计财富的策略。其创新点在于：1) 没有任何假设的情况下利用逐渐揭示的数据来学习序列依赖性；2) 该算法与独立同分布随机矩阵过程相适应；3) 该算法能够生成渐近增长率最高策略，这与其在基于推广后的凯利准则构建的最优策略相匹配。
### Conclusion
实验结果在真实市场数据集上验证了该算法的理论保证和预期性能，只要序列依赖显著即可。这进一步证实了该算法在各种情境下的广泛适用性。
## 734. `cs.LG` - 高效及时更新传播的联邦学习 [PDF](https://arxiv.org/pdf/2507.06031), [HTML](https://arxiv.org/abs/2507.06031)
### Authors
Juncheng Jia,Ji Liu,Chao Huo,Yihui Shen,Yang Zhou,Huaiyu Dai,Dejing Dou
### Background
联邦学习（FL）作为一种管理分布式数据的有效方法，在最近几年取得了显著进展。
### Innovation
提出了高效的FL方法，利用额外的下行链路带宽资源确保更新及时传播。设计方案包括两个部分：1. 异步框架中的Asynchronous Staleness-aware Model Update (FedASMU)：服务器端采用动态模型聚合技术，客户端提出自适应模型调整机制。2. 基于同步框架的FedSSMU。
### Conclusion
理论分析显示提出的方法具备收敛性。实验结果表明FedASMU和FedSSMU在准确性和效率方面显著优于基准方法，分别提高了145.87%和97.59%。
## 735. `cs.LG` - 使用纠缠测量的理想实例量子态认证 [PDF](https://arxiv.org/pdf/2507.06010), [HTML](https://arxiv.org/abs/2507.06010)
### Authors
Ryan O'Donnell,Chirag Wadhwa
### Background
量子态认证任务是对于给定的假设态σ和多个未知态ρ的副本，测试者需判断这两个态是否相等或在迹范距上相差ε。已知在测试者能对所有副本进行纠缠测量的前提下，对于最坏情况的假设态σ，需要Θ(d/ε^2)个ρ的副本是充分且必要的。但这种最坏情况下的界限并未针对每个实例的最优复制复杂性给出。在限制测试者只能进行非纠缠测量的条件下，此前已经证明了理想实例下的边界[CLO22, CLHL22]，但对于不限制测量类型的情形，这个边界仍是一个开放问题。
### Innovation
本文通过证明在测试者能进行完全纠缠测量的情况下量子态认证的理想实例边界解决了上述开放问题。与非纠缠测量的情况类似，本文证明了认证σ的最优复制复杂度由最坏情况的复杂度乘以σ和完全混合态之间的保真度给出。本文还使用了全新的量子版本的Ingster-Suslina 方法来证明我们的下界，这种方法有望成为独立感兴趣的方法。此外，这种方法还允许我们以异常简洁的方式恢复到粗糙度测试[OW15]的下界，即完全混合态的认证。
### Conclusion
本文证明了在测试者能进行完全纠缠测量的情况下，量子态认证的理想实例边界。具体来说，认证态σ的最优复制复杂度等于最坏情况复杂度乘以该态与完全混合态之间的保真度。此外，本文引入了新的量子版本Ingster-Suslina 方法来证明下界，为理想实例下量子态认证提供了一个简洁的理论基础。
## 736. `cs.LG` - Intra-DP：适用于移动边缘计算的高性能协同推理系统 [PDF](https://arxiv.org/pdf/2507.05829), [HTML](https://arxiv.org/abs/2507.05829)
### Authors
Zekai Sun,Xiuxian Guan,Zheng Lin,Zihan Fang,Xiangming Cai,Zhe Chen,Fangming Liu,Heming Cui,Jie Xiong,Wei Ni,Chau Yuen
### Background
在资源受限的移动设备上部署深度神经网络（DNNs）面临巨大挑战，特别是在实现实时性能的同时，还需应对计算资源和电池寿命的限制。现有的移动边缘计算（MEC）方法主要依赖于逐层模型划分，并且由于DNN操作的顺序执行导致了显著的传输瓶颈。
### Innovation
Intra-DP引入了一种基于本地操作的创新并行计算技术，通过将它们的计算（操作）分解为多个独立子操作，并通过并行执行重叠计算和传输不同的子操作来缓解MEC中的传输瓶颈，从而实现快速且节能的推理。
### Conclusion
评估结果显示，与最先进的基线方法相比，Intra-DP将每次推理的延迟最多减少了50%，能耗最多减少了75%，同时并未牺牲准确性。
## 737. `cs.LG` - 一种用于多任务预测的无线基础模型 [PDF](https://arxiv.org/pdf/2507.05938), [HTML](https://arxiv.org/abs/2507.05938)
### Authors
Yucheng Sheng,Jiacheng Wang,Xingyu Zhou,Le Liang,Hao Ye,Shi Jin,Geoffrey Ye Li
### Background
随着移动通信网络的复杂性和动态性不断增加，准确预测诸如信道状态信息（CSI）、用户位置和网络流量等关键系统参数变得至关重要，这对于物理层和介质访问控制层的任务非常重要。尽管传统的基于深度学习的方法已被广泛应用于此类预测任务，但它们往往难以在不同的场景和任务中进行泛化。因此，本文提出了一个统一的基础模型，旨在支持无线网络中多任务预测，并且可以适用于多种预测区间。该模型通过单一变量分解来统一异构任务，通过编码细粒度来增强区间意识，并使用因果Transformer作为底层架构以实现准确预测。此外，还引入了一种训练期间的补丁掩蔽策略，以支持任意长度的输入。
### Innovation
本文提出了一个用于多任务预测的统一基础模型，该模型通过单一变量分解来统一异构任务，通过编码细粒度提升区间意识，并使用因果Transformer作为底层架构以实现高精度预测。此外，引入了一种训练期间的补丁掩蔽策略，以支持任意长度的输入。经过大规模数据集训练后，该基础模型在未见过的场景中的泛化能力很强，并在新的任务上实现了零样本性能，超越了传统的全样本基准模型。
### Conclusion
经过大规模数据集训练的提出的基础模型展示了强大的泛化能力，在未见过的场景中表现优异，并在新的任务上实现了零样本性能，超过了传统的全样本基准模型。
## 738. `cs.LG` - 通过RKHS密度算子的核迹距离：度量测度的量子统计度量 [PDF](https://arxiv.org/pdf/2507.06055), [HTML](https://arxiv.org/abs/2507.06055)
### Authors
Arturo Castellanos,Anna Korba,Pavlo Mozharovskyi,Hicham Janati
### Background
概率分布之间的距离是许多统计机器学习任务的关键组成部分，包括两样本检验和生成建模等。现有的度量方法如最大均值差异(MMD)和Wasserstein距离都有各自的局限性，尤其是MMD在判别能力和参数选择方面的不足。为了克服这些局限，本文提出了一种新的测度之间的距离，该距离通过核协方差算子的施坦纳范数进行比较。这种方式可以提供对MMD的一些改进，表现出更好的判别能力和鲁棒性，并且还能利用核方法的一些优势，避免高维条件下的样本复杂性问题。
### Innovation
本文介绍了一种新的度量测度的方法，该方法通过核协方差算子的施坦纳范数进行比较。这种新的距离方法是一种积分概率度量，并且可以介于MMD和Wasserstein距离之间。该创新避免了MMD的一些缺陷，例如更具有判别性并且对超参数的选择具有鲁棒性。该方法还利用了核方法的一些特性，可以避免高维条件下的样本复杂性问题。此外，作者还提供了一种算法来实际计算该距离，这种算法的一个扩展可以作为独立的内容存在，即针对分布差别的核矩阵扩展。
### Conclusion
该创新方法已经被应用于污染下的鲁棒近似贝叶斯计算和粒子流量模拟中，通过对实证结果进行了说明，展示了该方法的优势。
## 739. `cs.LG` - Minimal Deterministic Echo State Networks Outperform Random Reservoirs in Learning Chaotic Dynamics [PDF](https://arxiv.org/pdf/2507.06050), [HTML](https://arxiv.org/abs/2507.06050)
### Authors
Francesco Martinuzzi
### Background
机器学习（ML）被广泛应用于建模混沌系统。回声状态网络（ESNs）因其简单的结构和快速的训练而受到关注。然而，ESNs的表现对超参数的选择和随机初始化非常敏感。本文展示了使用确定性规则和简单拓扑结构构建的估计确定性回声状态网络（MESNs）相较于标准ESNs，在混沌吸引子重构任务上表现出更好的性能。通过一个包含超过90个混沌系统的数据集对10种不同的最小确定性回声状态网络初始策略进行了基准测试。MESNs相较于标准ESNs的最大误差减少高达41%。此外，结果还表明MESNs更具有鲁棒性，表现出较低的运行间差异，并具有在不同系统中重复使用超参数的能力。这些结果表明，在ESNs设计中结构化的简单性可以超越随机复杂性，从而更好地学习混沌动力学.
### Innovation
采用确定性规则和简单拓扑结构构建的MESNs在学习混沌动态方面比随机初始化的ESNs表现出更好的性能。MESNs在超参数选择和结构设计上表现出了更大的灵活性和鲁棒性，能够潜在地减少模型训练的时间和计算资源。通过对比分析，MESNs取得的最大误差减少了41%。同时，MESNs具有可重复使用超参数的能力，这使得它们在不同混沌系统中的应用更加灵活和高效。
### Conclusion
本文研究结果显示，在ESNs设计中采用结构化的简单性可以超越随机复杂性，从而在学习混沌动态方面表现出更优的效果。MESNs具有更好的性能、更高的鲁棒性和更强的跨系统适用性，为混沌系统建模提供了一种更为有效和可靠的模型。
## 740. `cs.LG` - 杨德尔神经网络在椭圆偏微分方程正向和反向问题中的应用 [PDF](https://arxiv.org/pdf/2507.06038), [HTML](https://arxiv.org/abs/2507.06038)
### Authors
Kyriakos Georgiou,Constantinos Siettos,Athanasios N. Yannacopoulos
### Background
本文在之前引入的杨德尔神经网络（Fredholm Neural Networks/ FNNs）的基础上，扩展了框架以解决线性及半线性椭圆偏微分方程的正向和反向问题。通过边界积分方法在势理论框架内设计了一种深层神经网络（DNN）来表示椭圆偏微分方程解的迭代过程。这种方法通过可解释的方式计算层数、权重、偏置和超参数，将此神经网络称为势杨德尔神经网络（PFNN）。该方法在内部区域保持低误差，并在边界上达到机器精度附近。通过构造性的证明确保方案的一致性，并提供了内部和边界区域的显式误差界，反映了PFNN各层的结构特性。这些误差界依赖于边界函数的逼近和积分离散化方案，均直接对应于杨德尔神经网络架构的组成部分。通过这种方法，本文提供了一种可解释的方案，明确尊重边界条件。
### Innovation
本文将杨德尔神经网络扩展应用于椭圆偏微分方程的正向和反向问题，通过深层神经网络表示椭圆偏微分方程的解的迭代过程，并通过边界积分方法进行计算。此外，这种方法通过可解释的方式计算网络参数，并通过一致的构造性方法提供了显式的误差界，直接反映了神经网络架构的组成部分。该方法在内部区域保持低误差，并在边界上达到机器精度附近，既保证了准确性和可解释性。
### Conclusion
本文证明了杨德尔神经网络（PFNN）在解决椭圆偏微分方程正向和反向问题中的有效性和可解释性，通过边界积分方法和可解释的参数计算，保持了良好的精度，并提供了显式的误差界。该方法适用于二维线性和半线性椭圆偏微分方程的求解。
## 741. `cs.LG` - 精准与准确地估计流行率 [PDF](https://arxiv.org/pdf/2507.06061), [HTML](https://arxiv.org/abs/2507.06061)
### Authors
Aime Bienfait Igiraneza,Christophe Fraser,Robert Hinch
### Background
与分类任务不同，分类的目的是估计数据集中每个数据点的类别，而流行率估计或量化的目标是估计数据集中类别的分布。流行率估计的主要任务是从训练数据集中的流行率偏差中进行调整，并量化估计的不确定性。传统的方法，如自助法和贝叶斯量化方法，用于量化流行率估计的不确定性。然而，还不清楚哪种方法在精确性（即置信区间宽度）和覆盖范围（即置信区间良好校准）方面更优。
### Innovation
本文提出了Precise Quantifier（PQ），这是一种比现有量化方法更精确且覆盖范围良好的贝叶斯量化器。通过理论分析和基于模拟及真实数据集的实验，探讨了影响量化精度的因素，包括基础分类器的区分能力、_training_标数据集的大小以及用于估计流行率的_未_标数据集的大小。
### Conclusion
本文的研究为量化学习中的不确定性量化提供了深入的见解。研究表明，影响量化精度的关键因素包括基础分类器的区分能力、用以训练量化器的标记数据集的大小以及用于估计流行率的未标记数据集的大小。
## 742. `cs.LG` - RabakBench: 将人类标注应用于构建适应低资源语言的本地化多语言安全基准 [PDF](https://arxiv.org/pdf/2507.05980), [HTML](https://arxiv.org/abs/2507.05980)
### Authors
Gabriel Chua,Leanne Tan,Ziyu Ge,Roy Ka-Wei Lee
### Background
大型语言模型（LLMs）及其安全分类器在低资源语言上表现不佳，因为它们的训练数据和评估基准有限。这种情况下，建立专门针对特定文化或语言背景的安全基准具有重要意义。
### Innovation
介绍了RabakBench，这是一个新的多语言安全基准，涵盖了新加坡独特的语言环境，包括熟语、中文、马来语和泰米尔语。RabakBench 通过一个可扩展的三阶段管道构建：（i）生成 - 通过使用LLM进行红队攻击增强真实熟语网络内容；（ii）标注 - 使用与人类判断一致的半自动化多标签安全注释；（iii）翻译 - 在语言之间保持高保真度翻译，保留语言细微差别和毒性。此外，还提供了一个可复现的框架，用于在资源有限的环境中构建本地化安全数据集。
### Conclusion
RabakBench 使东南亚多语言环境中的安全评估更加稳健。它还提供了一个用于在低资源环境中构建本地化安全数据集的可复现框架。基准数据集和评估代码公开可用。
## 743. `cs.LG` - FEVO：大型语言模型中的金融知识扩展与推理演进 [PDF](https://arxiv.org/pdf/2507.06057), [HTML](https://arxiv.org/abs/2507.06057)
### Authors
Bo Pang,Yalu Ouyang,Hangfei Xu,Ziqi Jia,Panpan Li,Shengzhao Wen,Lu Wang,Shiyong Li,Yanpeng Wang
### Background
近年来，大型语言模型（LLMs）在数学和编程等领域中的推理能力提升显著，但在金融领域应用的研究相对较少。金融领域需要大量特定领域的知识来完成任务，现有研究在这方面的进展有限。因此，有必要开发一种专门针对金融领域的增强框架，以提升LLMs在金融任务中的性能。
### Innovation
本文提出了一种多阶段增强框架FEVO（Financial Evolution），旨在提升LLMs在金融任务中的表现。该框架通过持续预训练、监督微调和强化学习等方法系统地扩展了金融领域的知识，并植入了结构化的推理模式。此外，为了确保训练的有效性和效率，本文利用先进推理模型和基于规则的过滤方法创建了专门用于不同后训练阶段的高质数据集FEVO-Train。研究使用FEVO系列模型（C32B，S32B，R32B）进行训练，并在七个基准测试中对其金融和一般能力进行评估，结果显示FEVO-R32B在五个金融基准测试中表现最优，且优于更大规模及专门模型。此外，与仅使用强化学习训练的FEVO-R32B-0相比，FEVO-R32B在所有测试中表现更优，这展示了金融领域知识扩展和结构化逻辑推理能力提取的有效性。
### Conclusion
FEVO框架通过多层次的方法有效提升了LLMs在金融领域的应用能力，并证明了在金融领域扩充知识和培养结构化推理能力的有效性。
## 744. `cs.LG` - 通过现实评估协议的对比学习与迁移学习有效音频指纹生成 [PDF](https://arxiv.org/pdf/2507.06070), [HTML](https://arxiv.org/abs/2507.06070)
### Authors
Christos Nikou,Theodoros Giannakopoulos
### Background
近年来，歌曲识别的进步利用了深度神经网络直接从原始波形中学习紧凑的音频指纹。这些方法在受控条件下表现良好，但在真实场景中，尤其是当音频通过移动设备在嘈杂环境中捕获时，其准确性显著下降。本文介绍了一种新的评估协议，旨在更好地反映这种现实场景。该协议通过使用移动设备的麦克风录制同一段音频的不同版本，每个版本逐渐增加噪音水平。实验结果显示，两种最先进的CNN模型在该协议下的性能显著下降，与先前报道的基准相比，性能下降明显。这表明，现有的方法在嘈杂环境中表现不佳。此外，文中强调了在使用对比损失训练过程中增广管道的重要性。通过在增广管道中引入低通滤波器和高通滤波器，显著提高了两个系统的性能。
### Innovation
本文提出的创新点包括一个专门设计的现实评估协议，引入了两个系统的新的高效方法：在增广管道中加入低通和高通滤波器来提高系统在噪声环境中的性能，并通过探索从语义相关领域迁移知识的方法来增强模型的鲁棒性。实验结果显示，使用变压器架构的模型相较于CNN模型，在不同噪音水平和查询时间下表现更佳。在低噪音条件下，1秒查询的识别准确率为47.99%，10秒查询的识别准确率为97%，优于第二好的模型14%和18.5%。在高噪音条件下，15秒查询的检测率为56.5%。所有实验使用超过10万首歌的公共大规模数据集进行，与一个包含5600万向量的数据库进行比对。
### Conclusion
通过对比学习和迁移学习，本文提出的方法在现实评估协议下表现出更佳的性能。特别是在高噪音条件下的识别精度显著提高。
## 745. `cs.LG` - 通过结合生成式AI解决基于ML的安全任务中的数据挑战：经验教训 [PDF](https://arxiv.org/pdf/2507.06092), [HTML](https://arxiv.org/abs/2507.06092)
### Authors
Shravya Kanchi,Neal Mangaokar,Aravind Cheruvu,Sifat Muhammad Abdullah,Shirin Nilizadeh,Atul Prakash,Bimal Viswanath
### Background
机器学习（ML）支持的监督分类器在安全任务中广泛应用，但研究人员的关注点主要集中在算法改进上，而忽视了对这些分类器产生负面影响的数据挑战。本文探讨了如何利用生成式AI（GenAI）解决这些问题，通过合成数据增强训练数据集来提高分类器的泛化能力，并评估了这一方法在7种不同安全任务中的有效性。
### Innovation
本文提出了使用合成数据增强训练数据集的方法，并通过结合6种最先进的GenAI方法及提出新的GenAI方案Nimai，解决了数据挑战问题。研究发现，在严重的数据约束条件下，GenAI技术能够显著提升安全分类器的性能，即使只有约180个训练样本，性能也能提高32.6%。此外，GenAI还能帮助快速适应部署后的概念漂移。虽然取得了一定成功，但一些GenAI方案在某些安全任务上的初始化（训练和生成数据）存在困难，且任务中噪声标签、重叠的类别分布和稀疏特征向量等特性影响了GenAI方案的效果。
### Conclusion
研究认为，通过结合GenAI的方法可以有效解决基于ML的安全任务中的数据挑战，并驱动未来专为安全任务设计的GenAI工具的发展。
## 746. `cs.LG` - 通过平滑视角看Best-of-N：KL散度与遗憾分析 [PDF](https://arxiv.org/pdf/2507.05913), [HTML](https://arxiv.org/abs/2507.05913)
### Authors
Gholamali Aminian,Idan Shenfeld,Amir R. Asadi,Ahmad Beirami,Youssef Mroueh
### Background
Best-of-N（BoN）是一种在生成模型推理时进行对齐的有效方法，它通过从参考策略中采样N个结果，并使用代理奖励模型进行评估，最终选择得分最高的结果。尽管之前的工作表明，BoN在奖励与KL散度之间的权衡几乎是最佳的，但其效果高度依赖于所使用的代理奖励模型的质量。因此，研究团队通过引入平滑版本的Best-of-N（SBoN）和建立理论框架来解决这一问题，分析SBoN的性能如何随着样本数量的变化而变化，并研究期望的实际奖励之间的差距。
### Innovation
提出了平滑版本的Best-of-N（SBoN），并通过理论框架分析了SBoN的KL散度行为和遗憾差距，证明了平滑处理有助于缓解奖励过度优化的问题，尤其是在代理奖励质量较低的情况下。
### Conclusion
研究发现，通过平滑处理，SBoN有助于减轻奖励过度优化，特别是在代理奖励质量较低时。同时，通过理论和实验结果，该研究为理解BoN和SBoN的性能提供了新的见解，为优化生成模型推理时的对齐提供了有力支持。
## 747. `cs.LG` - 基于保守逼近的前馈神经网络在WENO方案中的应用 [PDF](https://arxiv.org/pdf/2507.06190), [HTML](https://arxiv.org/abs/2507.06190)
### Authors
Kwanghyuk Park,Jiaxi Gu,Jae-Hun Jung
### Background
该研究基于点值的保守近似求导来构建前馈神经网络(DNN)，改进经典的WENO加权方法。WENO (Weighted Essentially Non-Oscillatory)方案在求解保号律方程时表现出色，但经典WENO方案中的加权子过程较为复杂。该论文提出了一个创新的方法，即用基于保守逼近的前馈神经网络替代传统的WENO权重处理步骤，以简化加权过程并提高性能。
### Innovation
该研究通过引入一个输入为三点格式中点值，输出为两个非线性权重的前馈神经网络，来替代传统的WENO加权方法。通过监督学习方法训练神经网络，创建了一个新的带有标签的数据集，一个数值流函数被构建以逼近导数。此外，研究中引入了一个对称平衡项到损失函数中，使该神经网络更具对称性，能够产生高性能的WENO方案。
### Conclusion
所提出的方法在不同基准场景和分辨率上展示了稳定的泛化能力，并且在某些指标上优于现有的WENO3-Z方法，并达到了与WENO5-JS相近的精度。
## 748. `cs.LG` - DR23 中鲁滨son所观察到的ZTF视界：在DR23中的异常猎捕 [PDF](https://arxiv.org/pdf/2507.06217), [HTML](https://arxiv.org/abs/2507.06217)
### Authors
Maria V. Pruzhinskaya,Anastasia D. Lavrukhina,Timofey A. Semenikhi,Alina A. Volnova,Sreevarsha Sreejith,Vadim V. Krushinsky,Emmanuel Gangler,Emille E. O. Ishida,Matwey V. Kornilov,Konstantin L. Malanchev
### Background
鲁滨逊科学管道初步运行期间，ZTF（瞬态中型望远镜）与LSSTComCam共同观测了多个星域。SNAD VIII 工作坊期间进行了一次系统性的异常搜索，分析了选定的四个星域（两个是银河系内的，两个是银河系外的），并对400个候选目标进行了视觉检查。这一过程旨在展示SNAD异常检测管道的有效性，并为即将到来的LSST数据中的发现潜力提供预览。
### Innovation
采用‘PineForest’活性异常检测算法，SNAD首次在ZTF与LSSTComCam共观测的星域进行了系统性异常搜索。这种方法不仅发现了六个未被归档的变星，还对六个已知变星进行了重新分类和周期细化，展现了异常检测方法在变星发现中的应用潜力。
### Conclusion
研究结果表明SNAD异常检测管道的有效性，并预览了即将到来的LSST数据的发现潜力，同时为未来的天文观测和数据分析提供了新的工具和技术支持。
## 749. `cs.LG` - Copula Density Neural Estimation [PDF](https://arxiv.org/pdf/2211.15353), [HTML](https://arxiv.org/abs/2211.15353)
### Authors
Nunzio A. Letizia,Nicola Novello,Andrea M. Tonello
### Background
概率密度估计是统计学中的一个核心任务。本文关注估计任何观察数据相关的库 Categoria copula密度，因为这完全描述了随机变量之间的依赖关系。分离出联合依赖结构和单变量边缘分布，即库 Categoria copula本身，利用基于神经网络的方法进行建模，称为库 Categoria密度神经估计（CODINE）方法。这种方法显示出能够建模复杂分布，并可应用于互信息估计和数据生成。
### Innovation
提出了库 Categoria密度神经估计（CODINE）方法，这是一种基于神经网络的方法，用于估计观察数据相关的库 Categoria密度，可以建模复杂分布并且可用于互信息估计和数据生成。
### Conclusion
结果显示该新颖的机器学习方法能够建模复杂的分布，并且可以应用于互信息估计和数据生成。
## 750. `cs.LG` - 深度神经网络内建奥卡姆剃刀 [PDF](https://arxiv.org/pdf/2304.06670), [HTML](https://arxiv.org/abs/2304.06670)
### Authors
Chris Mingard,Henry Rees,Guillermo Valle-Pérez,Ard A. Louis
### Background
过度参数化的深度神经网络（DNNs）表现出色，这种优异性能必须源自网络架构、训练算法和数据结构之间的相互作用。为了分离这三个因素，作者应用了一个基于DNN表达的函数的贝叶斯观点来研究监督学习。通过在网络架构的基础上确定先验并且利用有序和混沌状态之间的过渡进行调整，作者对布尔函数分类进行了分析。
### Innovation
作者通过应用基于DNN表达函数的贝叶斯观点，对监督学习进行了分析。提出了通过有序和混沌状态之间的过渡来调整先验的方法。结合先验与布尔分类函数误差谱的似然模型，能够准确预测使用随机梯度下降训练的DNNs的后验概率。
### Conclusion
结构化数据与一个内在的倾向简单函数的奥卡姆剃刀式的归纳偏见相结合，使得DNNs在复杂度增加时仍能够有效工作。这种简单偏好足够强大，可以对抗函数数量随复杂度指数增长的问题，从而解释了DNNs的成功。
## 751. `cs.LG` - TextPixs：字符条件扩散与字符意识注意力及OCR导向监督 [PDF](https://arxiv.org/pdf/2507.06033), [HTML](https://arxiv.org/abs/2507.06033)
### Authors
Syeda Anshrah Gillani,Mirza Samad Ahmed Baig,Osama Ahmed Khan,Shahid Munir Shah,Umema Mujeeb,Maheen Ali
### Background
现代基于文本到图像的扩散模型的兴起为数字内容生产开辟了一个新时代，这些模型能够根据自然语言描述生成逼真且具有多样风格的图像。然而，这些模型仍然存在一个一致的缺点，即无法生成可读、有意义且拼写正确的文本，这极大地限制了其在实际应用如广告、学习及创意设计中的使用。
### Innovation
本文提出了一种新的框架，即 Glyph-Conditioned Diffusion with Character-Aware Attention (GCDA)，通过扩展一个典型的扩散模型并加入三个精心设计的模块实现了突破：(1) 双流文本编码器可以同时编码语义语境信息和显式字符表示，生成一种丰富的字符意识输入文本表示；(2) 提出了一种具有新注意力分割损失的字符意识注意力机制，用于独立限制每个字符的注意力分配，从而避免失真伪影；(3) 在OCR辅助的循环校准阶段，通过全文本感知损失直接优化模型，使其具有可读性和准确性。
### Conclusion
大规模实验证明，GCDA 在所有度量标准上都达到了新的最佳状态，特别是在基于字符的度量标准上，如 Character Error Rate 和 Word Error Rate，在文本渲染上的表现优于以前的最佳模型。同时，这些模型在人类感知和高保真图像合成质量（FID：14.3）方面也有相当的竞争力。
## 752. `cs.LG` - 可扩展的机器操控是否需要多样性的全部？ [PDF](https://arxiv.org/pdf/2507.06219), [HTML](https://arxiv.org/abs/2507.06219)
### Authors
Modi Shi,Li Chen,Jin Chen,Yuxiang Lu,Chiming Liu,Guanghui Ren,Ping Luo,Di Huang,Maoqing Yao,Hongyang Li
### Background
数据规模在自然语言处理（NLP）和计算机视觉（CV）中的基础模型中取得了显著的成功，但对于机器人操控中有效数据扩展的原则仍然理解不足。本文通过研究机器人学习中数据多样性的微妙作用，探讨任务、机器人类型和专家演示这三个关键维度，挑战了“多样化程度越高越好”的传统直觉。通过在多种机器人平台上的大量实验，揭示了任务多样性比每项任务的演示数量更为关键，多体态预训练数据对于跨体态迁移是可选的，以及专家多样性在政策学习中可能具有误导性，特别是速度的多模态性是关键因素。
### Innovation
提出了分布去偏方法来缓解速度的不确定性，从而提升了GO-1-Pro的性能，获得了15%的显著提升，相当于使用两倍多的预训练数据。这些发现提供了新的视角，并提供了如何有效扩展机器人操控数据集的实用指导。
### Conclusion
通过本文的工作，我们发现任务多样性比每项任务的演示数量更为关键，多体态预训练数据对跨体态迁移是可选的，并且专家多样性在政策学习中可能会产生误导，特别是速度的多模态性是关键因素。基于这些见解，我们提出了一种分布去偏方法来缓解速度的不确定性，GO-1-Pro在性能上取得了显著提升。
## 753. `cs.LG` - 使用排序技巧近似不变函数具有理论依据 [PDF](https://arxiv.org/pdf/2403.01671), [HTML](https://arxiv.org/abs/2403.01671)
### Authors
Wee Chaimanowong,Ying Zhu
### Background
许多机器学习模型利用分组不变性，这种不变性在各种应用中都很常见。为利用不变性结构，一种常见方法是“框架平均化”，例如“组平均化”，它使用整个组来使函数对称化。另一种极端情况是“规范化”，它在每个点处的框架仅包含单个分组元素，将该点变为其轨道代表。与组平均化相比，规范化在计算效率上更优，但是结果的规范化函数是非可微或不连续的，因此它的理论性能尚未得到充分关注。因此，本文研究了规范化技巧的逼近理论，具体包括估计算法的点值误差、$L^2(textbf{P})$逼近误差以及内核的特征值衰减率。
### Innovation
本文建立了规范化技巧的逼近理论，给出了点值误差、$L^2(textbf{P})$逼近误差的界限，以及内核特征值衰减率，使其具有理论上的支持，解决了理论性能未被充分关注的问题，为理解规范化技巧的计算效率和误差提供了理论依据。
### Conclusion
本文通过研究建立了规范化技巧的理论框架，证明了其逼近不变函数的有效性，并提出了具体误差界限，为理解与应用规范化技巧提供了科学依据。
## 754. `cs.LG` - UQLM：大型语言模型不确定性量化的一个Python包 [PDF](https://arxiv.org/pdf/2507.06196), [HTML](https://arxiv.org/abs/2507.06196)
### Authors
Dylan Bouchard,Mohit Singh Chauhan,David Skarbrevik,Ho-Kyeong Ra,Viren Bajaj,Zeya Ahmad
### Background
大语言模型（LLMs）生成虚假或误导性内容的现象称为幻觉，这对下游应用的安全性和可信度构成了重大挑战。
### Innovation
本文引入了UQLM，这是一个使用最新的不确定性量化（UQ）技术的Python包，用于LLM幻觉检测。该工具包提供了一套基于UQ的分数器，可以计算从0到1的响应级置信度分数，并提供了一种开箱即用的基于UQ的幻觉检测解决方案，便于集成到LLM输出中以增强其可靠性。
### Conclusion
UQLM为提高LLM输出的可靠性提供了一种易于集成的解决方案，通过使用最新的UQ技术来检测幻觉。
## 755. `cs.LG` - LLM 基础排序器的效率-效果 PetaFLOPs [PDF](https://arxiv.org/pdf/2507.06223), [HTML](https://arxiv.org/abs/2507.06223)
### Authors
Zhiyuan Peng,Ting-ruen Wei,Tingyu Song,Yilun Zhao,Yi Fang
### Background
大语言模型（LLMs）最近被应用于信息检索中的重排序任务，取得了良好的性能。然而，它们的高计算需求常常阻碍了其实际部署。现有研究使用延迟、前向传递次数、输入令牌和输出令牌等代理指标来评估基于LLM的重排序器的效率。但这些指标依赖于硬件和运行时选择（例如，是否并行、批量大小等），并且往往无法考虑模型大小，导致难以解读和模糊了效率-效果权衡的评估。
### Innovation
提出了新的基于LLM的重排序器指标：每拍浮点运算（PetaFLOP）的排序指标（RPP）和每拍浮点运算的查询数量（QPP），构建了一个可解释的浮点运算量估算器来估算没有运行实验的LLM基础重排序器的FLOPs。基于提出的指标进行了广泛的实验，评估了不同架构的多种基于LLM的重排序器，研究了它们的效率-效果权衡。
### Conclusion
根据提出的指标，对多种基于LLM的重排序器进行了全面实验，研究了它们的效率-效果权衡，并将此问题提到了研究界面前。
## 756. `cs.LG` - 基于视觉聚类先验的瓷砖级ViT推理方法在零样本多物种植物识别中的应用 [PDF](https://arxiv.org/pdf/2507.06093), [HTML](https://arxiv.org/abs/2507.06093)
### Authors
Murilo Gustineli,Anthony Miyaguchi,Adrian Cheung,Divyansh Khattak
### Background
该研究介绍的是DS@GT团队在2025年PlantCLEF挑战赛中关于植被块图像多物种植物识别的第二名解决方案。背景在于当前植物识别领域，尤其是在植被块图像识别方向上，多物种识别技术存在挑战，特别是在零样本学习的条件下，如何有效且精确地识别不同种类的植物成为研究重点。
### Innovation
该论文的创新点在于开发了一种结合瓷砖级的ViT推理策略（使用细调的Vision Transformer ViTD2PC24All进行瓷砖级推理），一种4x4的磁砖拼接策略以确保磁砖尺寸与网络的感知视野相匹配（518x518），以及通过PaCMAP + K-Means视觉聚类和地理定位过滤实现领域先验适应的方法。此外，还采用多数投票和基于聚类的贝叶斯先验进行加权，提高了识别精度。
### Conclusion
整体来说，该研究提出的方法在隐私榜上达到了0.348的宏F1值，且不需要额外的训练。所有相关的代码、配置文件和可重复性脚本都可以在公开网址处获取。结论表明，该方法有效地提升了零样本条件下的多物种植物识别性能，并为该领域的进一步研究提供了有价值的参考。
## 757. `cs.LG` - 通过高斯混合模型的最优传输进行领域适应 [PDF](https://arxiv.org/pdf/2403.13847), [HTML](https://arxiv.org/abs/2403.13847)
### Authors
Eduardo Fernandes Montesuma,Fred Maurice Ngolè Mboula,Antoine Souloumiac
### Background
传统机器学习系统假设训练和测试数据是从固定概率分布中抽取的，但在实际应用中，数据采集的条件可能会改变，因此这种假设往往无法满足。为了应对这种变化，研究领域出现了一种对领域适应（domain adaptation）的方法，这种适应过程需要最少的数据访问来进行学习，以构建对数据分布变化具有鲁棒性的模型。最优传输（optimal transport）是一种理论基础扎实的工具，可以分析分布的变化，尤其是能够将不同领域之间的映射写成方程。然而，现有的最优传输方法通常计算成本高昂，其复杂度随样本数量的立方而增加。
### Innovation
本文探索了在高斯混合模型（GMMs）之间进行最优传输的方法，这种方法可以方便地用源GMM和目标GMM的组成部分来表达。作者通过9个基准实验，共执行了85个适应任务，证明了该方法相比之前的浅层领域适应方法更加有效，并且能够很好地与样本数量n和维度d进行扩展。
### Conclusion
本文提出的方法在理论上和计算复杂性上都优于现有的浅层领域适应方法，具有较强的适应性和扩展性。
## 758. `cs.LG` - Curvature-Aligned Federated Learning (CAFe): Harmonizing Loss Landscapes for Fairness Without Demographics [PDF](https://arxiv.org/pdf/2404.19725), [HTML](https://arxiv.org/abs/2404.19725)
### Authors
Shaily Roy,Harshit Sharma,Asif Salekin
### Background
联邦学习（FL）能够实现隐私保护的合作训练，非常适合分散的人类感知应用。然而，当前确保FL公平的方法依赖于敏感属性的知识，这与FL的隐私原则相冲突。此外，人类感知数据中的敏感属性可能未知或隐藏。
### Innovation
引入了Curvature-Aligned Federated Learning (CAFe) 方法，该方法在无需敏感属性知识的条件下实现了公平性，称之为“无需人口统计的公平性”（FWD）。CAFe 在本地训练和客户端损失景观锐度感知聚合中引入了曲率正则化，以在客户端内外对齐曲率，平衡公平性和性能。
### Conclusion
我们通过理论和实证验证，以及使用三个真实世界数据集和资源受限设备构成的异构测试配置的实时FL部署进行了全面评估，证明了CAFe 的有效性。我们还对局部训练数据量、客户端抽样、通信开销、资源成本和运行时间性能进行了敏感性分析，证明其在实际FL边缘设备部署中的可行性。
## 759. `cs.LG` - 使用置信度衡量异质治疗效果中的变量重要性 [PDF](https://arxiv.org/pdf/2408.13002), [HTML](https://arxiv.org/abs/2408.13002)
### Authors
Joseph Paillard,Angel Reyero Lobo,Vitaliy Kolodyazhniy,Bertrand Thirion,Denis A. Engemann
### Background
因果机器学习有望从复杂数据中估计个体治疗效果。要在现实世界中成功应用机器学习方法，了解哪些变量驱动治疗响应异质性至关重要。本文分析了在估计条件平均治疗效应（CATE）时，基于条件置换重要性（CPI）方法的PermuCATE算法对于统计严谨的全局变量重要性评估的应用。理论分析和经验研究表明，PermuCATE在有限样本区域中的表现优于Leave-One-Covariate-Out（LOCO）参考方法，能提供可靠的变量重要性度量，增加统计功效，对于有限数据的生物医学应用中进行因果推断至关重要。
### Innovation
提出了基于条件置换重要性方法的PermuCATE算法，用于在估计条件平均治疗效应（CATE）时进行统计上严谨的全局变量重要性评估。PermuCATE在有限样本区域中的表现优于Leave-One-Covariate-Out参考方法，提供可靠的变量重要性度量。
### Conclusion
PermuCATE在模拟和真实健康数据集（包括多达数百个相关变量的情境中）中被实验证明具有优势，显示出较高的统计功效。
## 760. `cs.LG` - Longitudinal Ensemble Integration for 顺序分类中的多模态数据集成 [PDF](https://arxiv.org/pdf/2411.05983), [HTML](https://arxiv.org/abs/2411.05983)
### Authors
Aviad Susman,Rupak Krishnamurthy,Yan Chak Li,Mohammad Olaimat,Serdar Bozdag,Bino Varghese,Nasim Sheikh-Bahaei,Gaurav Pandey
### Background
多模态纵向数据的有效建模在多个应用领域，尤其是生物医学中非常重要。然而，针对这一问题的文献中存在较少的方法，并且大多数方法未能充分考虑到数据的多模态性。
### Innovation
提出了一种新颖的多模态和纵向学习框架Longitudinal Ensemble Integration (LEI)，用于序列分类。LEI通过使用来自个体数据模态的中间基础预测来进行更好的时间上的集成，并能识别在有效预测痴呆相关诊断中始终重要的特征。
### Conclusion
研究表明，LEI在纵向多模态数据的序列分类中具有潜在的应用价值。
## 761. `cs.LG` - SQLBarber：利用大型语言模型生成符合需求且真实的SQL工作负载的系统 [PDF](https://arxiv.org/pdf/2507.06192), [HTML](https://arxiv.org/abs/2507.06192)
### Authors
Jiale Lao,Immanuel Trummer
### Background
数据库研究与开发常常需要大量的SQL查询进行基准测试，但获取真实的SQL查询因隐私问题而具有挑战性，并且现有的SQL生成方法在定制化和满足现实约束方面能力有限。
### Innovation
SQLBarber 是一种基于大型语言模型（LLMs）的系统，用于生成定制化和真实的SQL工作负载。它通过引入一个声明性接口来简化用户生成SQL模板的过程，并结合自校正模块和贝叶斯优化器，提高了查询生成的效率和与目标成本分布的匹配度。
### Conclusion
通过在十个不同难度级别的基准测试上进行广泛的实验，结果表明，SQLBarber 是唯一能够生成定制化SQL模板的系统。它将查询生成时间减少了1到3个数量级，并显著提高了与目标成本分布的匹配度，相较于现有方法，这充分展示了其在性能上的提升和优势。
## 762. `cs.LG` - 基于粗到细动作序列的Q网络用于高效机器人学习 [PDF](https://arxiv.org/pdf/2411.12155), [HTML](https://arxiv.org/abs/2411.12155)
### Authors
Younggyo Seo,Pieter Abbeel
### Background
预测动作序列在近期的机器人行为克隆算法中起到了关键作用。然而，这种思想能否应用于增强学习（RL）以提高其性能尚未得到验证。
### Innovation
提出了一种名为CQN-AS的新颖价值基RL算法，它通过明确训练价值函数来学习执行动作序列的后果，从而输出动作序列上的Q值。实验表明，CQN-AS在BiGym和RLBench中的稀疏奖励人形控制和桌面操作任务上优于多种基线方法。
### Conclusion
将动作序列集成至预测真实回溯时，通过CQN-AS算法能够降低验证损失，证明了其在数据高效机器人学习中的有效性。
## 763. `cs.LG` - 在随机动力系统中使用对数神经证书进行策略验证 [PDF](https://arxiv.org/pdf/2406.00826), [HTML](https://arxiv.org/abs/2406.00826)
### Authors
Thom Badings,Wietze Koops,Sebastian Junges,Nils Jansen
### Background
本文考虑了针对离散时间随机系统的到达避免规范（reach-avoid specification）验证基于神经网络的策略问题。现有方法依赖于计算神经网络的Lipschitz常数来进行这种验证任务，但这种依赖在Lipschitz常数大，特别是高阈值概率的到达避免规范方面带来了挑战。文章解决了这个问题，并提出了一种新的方法来获得较小的Lipschitz常数。
### Innovation
本文提出了两种关键贡献：1. 引入了对数到达避免超鞅（logRASMs），该方法具有比原始到达避免超鞅（RASMs）中呈现的指数级更小的值，从而具有较低的理论Lipschitz常数。2. 提供了一种基于加权范数计算Lipschitz常数的更紧的上界的方法。上述方法能有效克服现有方法在大Lipschitz常数方面遇到的问题。
### Conclusion
实验评估表明，可以一致地验证高达99.9999%概率的到达避免规范的满足情况。
## 764. `cs.LG` - 警惕Scaffold的成本！良性客户端甚至可能成为后门攻击的共犯。 [PDF](https://arxiv.org/pdf/2411.16167), [HTML](https://arxiv.org/abs/2411.16167)
### Authors
Xingshuo Han,Xuanye Zhang,Xiang Lan,Haozhao Wang,Shengmin Xu,Shen Ren,Jason Zeng,Ming Wu,Michael Heinrich,Tianwei Zhang
### Background
Scaffold是一种已广泛认可的有效解决联邦学习中数据异质性影响的解决方案，通过校准每个客户端的局部梯度来实现显著性能提升。然而，该论文指出，这种性能提高是以增加安全性漏洞为代价的。
### Innovation
提出了一种名为BadSFL的新型后门攻击方法，这是首次将良性客户端转化为攻击共犯的方法，通过独特地篡改控制变量，使良性客户端的局部梯度更新向攻击者中毒的方向隐秘偏导，使其成为不知不觉的共犯并显著增强后门持久性。此外，BadSFL还利用GAN增强的中毒策略丰富攻击者的数据集，保持在良性样本和被后门污染样本上的高准确性，同时保持隐蔽性。
### Conclusion
BadSFL在对抗性实验中表现出更持久的攻击效果，即使停止恶意模型注入，其有效性仍能维持60个全局轮次以上，比现有的基准提高了三倍多。
## 765. `cs.LG` - CoDy: 动态图的反事实解释器 [PDF](https://arxiv.org/pdf/2403.16846), [HTML](https://arxiv.org/abs/2403.16846)
### Authors
Zhan Qu,Daniel Gomm,Michael Färber
### Background
时空图神经网络（TGNNs）被广泛用于动态系统的建模，在这些系统中，关系和特征随时间变化。尽管TGNNs在这些领域展示了强预测能力，但它们复杂的架构给解释性带来了重大挑战。反事实解释方法通过展示对输入图进行修改如何影响模型预测，提供了一种有希望的解决方案。为此，我们提出了一种名为CoDy的实例级模型通用解释方法，它通过结合蒙特卡洛树搜索和启发式选择策略，识别出反事实子图，以解释TGNN预测。CoDy基于空间、时间和局部事件影响信息高效地探索潜在解释子图的巨大搜索空间。
### Innovation
CoDy通过结合蒙特卡洛树搜索和启发式选择策略，提出了一种实例级的模型通用解释方法，旨在识别反事实子图以解释TGNN预测。这种方法能够高效地探索潜在的解释子图空间，并利用时空及局部事件影响信息进行搜索。相比于最先进的基准模型，CoDy在AUFSC+指标上表现出16%的提升，证明了其有效性和优越性。
### Conclusion
CoDy已被证明对于动态图的反事实解释非常有效，它不仅可以显著提高预测解释的准确性和可靠性，还能促进对TGNN模型的进一步理解。未来的工作将探索如何进一步优化CoDy算法，并将其实现到更广泛的动态系统中。
## 766. `cs.LG` - 学习分布式知识图谱中的联邦神经图数据库以回答复杂查询 [PDF](https://arxiv.org/pdf/2402.14609), [HTML](https://arxiv.org/abs/2402.14609)
### Authors
Qi Hu,Weifeng Jiang,Haoran Li,Zihao Wang,Jiaxin Bai,Qianren Mao,Yangqiu Song,Lixin Fan,Jianxin Li
### Background
基于深度学习的基础模型的日益增加的需求突显了高效数据检索机制的重要性。神经图数据库（NGDBs）提供了一种引人注目的解决方案，通过神经空间存储和查询图结构数据，使大语言模型（LLMs）能够访问精确且上下文相关的信息。然而，现有的NGDBs只能处理单一图操作，限制了它们在多个分布图间进行推理的能力。此外，现有NGDBs不支持多源图数据，这限制了它们捕捉现实世界数据的复杂性和多样性的能力。许多应用场景中，数据分布在多个来源上，跨越这些来源推理的能力对于做出明智的决策至关重要。特别是在处理敏感的图数据时，直接共享和聚合数据带来了重大的隐私风险。因此，依赖于NGDBs的应用不得不在这中间选择：牺牲数据隐私或牺牲在多个图上进行推理的能力。
### Innovation
本文提出了学习联邦神经图数据库（FedNGDB），这是一种创新的体系框架，旨在实现多源图数据上的隐私保护推理。FedNGDB利用联邦学习在多个来源之间协作学习图表示，从而丰富实体之间的关系，并提高图数据的整体质量。
### Conclusion
通过FedNGDB，系统能够在保护隐私的情况下，在多源图数据上进行推理，克服了现有NGDBs的限制。这为跨多个图进行复杂查询提供了新的途径，对于处理敏感数据的应用具有重要意义。
## 767. `cs.LG` - 回归于均值：通过后处理回归在少量标签下的自动评估与统计推断 [PDF](https://arxiv.org/pdf/2411.12665), [HTML](https://arxiv.org/abs/2411.12665)
### Authors
Benjamin Eyre,David Madras
### Background
机器学习系统能够执行多种任务的能力导致了从这些系统生成的合成标签在数据分析或模型评估等统计推断中的应用。Prediction Powered Inference (PPI) 架构允许利用大量伪标签数据和少量真实高质量标签数据，以较低的方差和无偏估计来评估所关注的数量。大多数关于 PPI 的工作都集中在相对较大的标记样本集上，这些样本集可能需要大量的资源来获得。然而，当我们缺乏标记数据时，PPI++ 方法的表现甚至不如传统的统计推断。研究人员通过将 PPI++ 与普通最小二乘回归相联系，来分析小样本规模下的高方差问题，并利用回归框架来更好地理解 PPI 的有效性。
### Innovation
作者提出了两种新颖的基于 PPI 的技术，通过利用稳健回归方法，即使在少量标签的情况下也能生成更低的方差估计。
### Conclusion
通过回归于均值的策略，新方法能够提高统计推断的有效性，特别是在标记数据稀缺的情况下，其表现优于传统方法和 PPI++ 方法。
## 768. `cs.LG` - 优化学习奖励函数的危险：低训练误差不保证低遗憾 [PDF](https://arxiv.org/pdf/2406.15753), [HTML](https://arxiv.org/abs/2406.15753)
### Authors
Lukas Fluri,Leon Lang,Alessandro Abate,Patrick Forré,David Krueger,Joar Skalse
### Background
在强化学习中，指定描述所需任务的奖励函数可能极具挑战性。奖励学习旨在解决这一问题，通过学习奖励函数。然而，学习到的奖励模型可能在数据分布上误差较低，但在后续生成的策略上却有较大的遗憾。我们称之为错误遗憾不匹配。错误遗憾不匹配的主要来源是策略优化过程中常见的分布转移。本论文通过数学证明，低期望测试误差的奖励模型能保证低最坏情况遗憾，但对于任何固定的期望测试误差，仍存在现实数据分布导致错误遗憾不匹配现象。即使使用政策正则化技术，如RLHF，类似问题仍然存在。我们希望这些结果能够促进奖励模型学习及衡量其质量的改进方法的理论和实证研究。
### Innovation
论文通过数学证明揭示了低期望测试误差的奖励模型能够保证低最坏情况遗憾，但任何固定的期望测试误差仍可能引发错误遗憾不匹配。此外，即使在使用政策正则化技术的情况下，这种类似问题仍然存在。
### Conclusion
本研究结果旨在激发在奖励模型学习及衡量其质量方面改进方法的理论和实证研究。
## 769. `cs.LG` - 预训练图对比掩蔽自编码器是强大的EEG蒸馏器 [PDF](https://arxiv.org/pdf/2411.19230), [HTML](https://arxiv.org/abs/2411.19230)
### Authors
Xinxu Wei,Kanhao Zhao,Yong Jiao,Hua Xie,Lifang He,Yu Zhang
### Background
有效利用大量未标记的高密度EEG数据来提高在有限标记低密度EEG数据场景中的性能是一项重大挑战。现有方法难以平衡高密度和低密度EEG数据之间的差距，尤其是在分类任务中表现不佳。
### Innovation
本文通过将问题形式化为图迁移学习和知识蒸馏问题，提出了一种名为EEG-DisGCMAE的统一预训练图对比掩蔽自编码器蒸馏架构。该架构引入了一种新的统一图自监督预训练范式，无缝整合了图对比预训练和图掩蔽自编码器预训练。此外，论文提出了一种图拓扑蒸馏损失函数，使轻量级的学生模型能够在预训练和微调过程中从已训练于高密度数据的教师模型中学习，从而有效处理通过对比蒸馏缺失的电极问题。
### Conclusion
EEG-DisGCMAE在两个临床EEG数据集的四种分类任务中得到了验证，通过预训练和微调阶段的知识蒸馏，有效地利用了大量未标记的数据。
## 770. `cs.LG` - KAN-AD：基于柯尔莫戈罗夫-阿诺尔德网络的时间序列异常检测 [PDF](https://arxiv.org/pdf/2411.00278), [HTML](https://arxiv.org/abs/2411.00278)
### Authors
Quan Zhou,Changhua Pei,Fei Sun,Jing Han,Zhengwei Gao,Dan Pei,Haiming Zhang,Gaogang Xie,Jianhui Li
### Background
时间序列异常检测（TSAD）是云服务和网络系统实时监控的基础，能够迅速识别异常，防止昂贵的系统失败。大多数由预测模型驱动的TSAD方法倾向于过分关注微小波动而过拟合。我们的分析表明，有效的TSAD应侧重于通过平滑的局部模式来建模“正常”行为。这可以通过将时间序列建模为近似平滑的单变量函数来实现。然而，直接的KAN实现对这些局部扰动较为敏感，因此我们提出了KAN-AD方法，将其B-样条基替换为截断的傅里叶展开，并引入了一种新的轻量级学习机制，强调全局模式以保持对局部扰动的耐受性。
### Innovation
我们提出了KAN-AD方法，用截断的傅里叶展开替换B-样条基，并引入了一种新的轻量级学习机制。这种方法着重于全局模式，同时对局部扰动保持鲁棒性。在四个流行的TSAD基准测试上，KAN-AD的检测准确性平均提高了15%，最高达到27%，而且参数少于1,000，导致推理速度比原KAN快50%，体现了方法的效率和实用性。
### Conclusion
KAN-AD在时间和准确性上都表现出显著的优势，比现有最先进的基准提高了15%至27%的检测精度，并且具有更快的推理速度和更少的可训练参数，这证实了其高效性和实用价值。
## 771. `cs.LG` - 基于顺序近似验证加速推测解码 [PDF](https://arxiv.org/pdf/2502.04557), [HTML](https://arxiv.org/abs/2502.04557)
### Authors
Meiyu Zhong,Noel Teku,Ravi Tandon
### Background
推测解码（SD）是一种用于利用大型语言模型（LLMs）进行更快推理的技术。它通过使用较小的草稿模型自回归生成一组标记序列，并使用较大的目标模型并行验证这些序列以确保统计一致性。然而，定期为目标模型进行并行验证调用限制了SD达到更低延迟的能力。
### Innovation
本文提出SPRINTER方法，该方法利用一种低复杂度的验证器来预测草稿模型生成的标记是否会被目标模型接受。SPRINTER通过顺序近似验证来降低对目标模型的调用次数，并仅在某个标记被认为不可接受时才调用目标模型，从而在不牺牲生成质量的前提下进一步提高速度和降低计算成本。
### Conclusion
我们对SPRINTER进行了理论分析，并在生成的统计特性和预计的延迟减少方面进行了研究。实验结果表明，近似验证在保持高质量生成的同时，进一步减少了延迟。
## 772. `cs.LG` - 迭代重要性微调扩散模型 [PDF](https://arxiv.org/pdf/2502.04468), [HTML](https://arxiv.org/abs/2502.04468)
### Authors
Alexander Denker,Shreyas Padhy,Francisco Vargas,Johannes Hertrich
### Background
扩散模型是生成建模的重要工具，在成像和蛋白质设计等领域作为有效的先验应用。然而，在下游任务中应用扩散模型的主要挑战之一是高效地从得到的后验分布中采样，这可以通过$h$-变换来解决。本文在$h$-变换的基础上，探讨了一种训练扩散模型的方法，以实现条件采样的均摊化。该方法通过路径基的重要性权重重新采样合成数据集，逐步优化$h$-变换，进而应用于类别条件采样、逆问题和文本到图像扩散模型的奖励微调等场景，以展示该框架的有效性。
### Innovation
本文提出了一种自我监督的算法，通过估计$h$-变换来调整扩散模型，实现条件采样的均摊化。该方法通过重新采样合成数据集的方式，并利用路径基的重要性权重，逐步优化$h$-变换的过程，从而在具有类别条件采样、逆问题和奖励微调需求的场景中实现了高效地采样。
### Conclusion
本文提出的方法在类别条件采样、逆问题以及文本到图像的扩散模型奖励调整等方面展示了其有效性，迭代重要性微调扩散模型的方法为更高效的扩散模型应用提供了新的思路。
## 773. `cs.LG` - 差分隐私森林中的训练集重建：DP效果如何？ [PDF](https://arxiv.org/pdf/2502.05307), [HTML](https://arxiv.org/abs/2502.05307)
### Authors
Alice Gorgé,Julien Ferry,Sébastien Gambs,Thibaut Vidal
### Background
近期研究表明，机器学习模型容易受到针对其训练数据的隐私攻击。为了减轻这些风险，差分隐私（DP）已经成为一种广泛应用的对策，因为它提供了严格的隐私保护。本文针对最先进的ε-差分隐私随机森林引入了一种重建攻击。通过结合森林结构的知识及DP机制的特性，我们正式重建了最有可能生成给定森林的原始数据集。通过广泛的计算实验，我们探讨了模型实用性和隐私保证与重建准确性之间的相互作用。结果表明，即使在训练时具有有意义的DP保证，随机森林也可能会泄露部分训练数据。具体而言，虽然DP降低了重建攻击的成功率，但仅有的对抗攻击完全免疫的森林的预测性能也并不优于一个恒定分类器。
### Innovation
文章通过引入一种结合了森林结构和DP机制特性的约束编程模型，正式重构可能生成给定森林的最可能数据集，这是首次针对先进的ε-差分隐私随机森林进行此类研究。通过大量计算实验探究了模型实用性、隐私保证和重建准确性之间的关系。
### Conclusion
尽管差分隐私减少了重建攻击的效果，但随机森林在训练时具有实际意义的DP保证也可能泄露部分训练数据。研究揭示了，仅有的对抗攻击完全免疫的森林的预测性能并不优于一个恒定分类器，因此作者提出了针对重建攻击更具抵抗力且预测性能非显然损坏的差分隐私随机森林的实用建议。
## 774. `cs.LG` - 从反事实到树结构：模型提取攻击的竞争分析 [PDF](https://arxiv.org/pdf/2502.05325), [HTML](https://arxiv.org/abs/2502.05325)
### Authors
Awa Khouna,Julien Ferry,Thibaut Vidal
### Background
随着机器学习即服务（MLaaS）的发展，模型的解释性和安全性之间的权衡变得更为突出。解释方法如反事实解释可能会无意间增加模型抽取攻击的风险，从而导致非授权复制专有模型。本文旨在正式化和描述模型重建的风险与内在复杂性，特别是关注用于准确推断底层预测函数所必需的'Oracle'查询。介绍了基于加性决策树的模型（如决策树、梯度提升和随机森林）的新型重建算法，并通过竞争分析的角度对该类攻击进行了正式分析，提供了理论上的查询复杂度界限，从而提供了对部署安全漏洞的新见解。
### Innovation
本文介绍了新型的重建算法，这些算法在理论上实现了完美的保真度同时展示了强大的任何时间性能。通过竞争分析视角对该类攻击进行了正式研究，建立了评价其效率的理论框架，并对基于树模型的抽取提供了一系列理论界限，加深了对模型部署安全性的理解。
### Conclusion
本文通过对基于树模型的抽取提供了理论查询复杂度界限，建立了评价模型提取攻击效率的基础框架，为模型的安全部署提供了新的见解。
## 775. `cs.LG` - 基于嵌入的方法在假两极分化新闻检测中的应用 [PDF](https://arxiv.org/pdf/2501.01370), [HTML](https://arxiv.org/abs/2501.01370)
### Authors
Karthik Mohan
### Background
假两极分化新闻（hyperpartisan news）指的是立场极为偏激的政治新闻，其目的在于制造公众的政治分歧。为了识别真假两极分化新闻，研究人员尝试了多种方法，包括n-gram、情感分析以及使用预训练的ELMo模型生成句子和文档表示。先前的最佳系统使用预训练的ELMo结合双向LSTM模型，在10倍交叉验证中达到了约83%的准确率。
### Innovation
该研究创新性地使用了语言模型（LLMs）进行嵌入生成，这种方法取得了约92%的准确率，超过了之前的最佳系统使用预训练的ELMo结合双向LSTM模型的83%的准确率。
### Conclusion
通过使用语言模型进行嵌入生成，该方法在假两极分化新闻的检测上取得了显著的改进，达到了更高的准确率。
## 776. `cs.LG` - DeepCell: 自监督多视图融合的电路表示学习 [PDF](https://arxiv.org/pdf/2502.06816), [HTML](https://arxiv.org/abs/2502.06816)
### Authors
Zhengyuan Shi,Chengyu Ma,Ziyang Zheng,Lingfeng Zhou,Hongyang Pan,Wentao Jiang,Fan Yang,Xiaoyan Yang,Zhufei Chu,Qiang Xu
### Background
本文介绍了DeepCell，这是一种新颖的电路表示学习框架，能够有效集成来自And-Inverter Graphs (AIGs)和Post-Mapping (PM)网表的多视图信息。DeepCell的核心是一个自监督的Mask Circuit Modeling (MCM)策略，通过融合不同设计阶段的互补电路表示，生成统一和丰富的嵌入式表示，这是在已有文献中的创新点。
### Innovation
DeepCell首次明确设计用于PM网表表示学习的框架，性能和预测准确性都达到了新的基准。该框架在功能性和效果上显著超越了现有的开源EDA工具。
### Conclusion
通过将其应用于EDA任务，如功能性的工程变更单（ECO）和工艺映射，DeepCell展示了其实用效果。广泛的实验结果表明，DeepCell在效率和性能上明显优于最先进的开源EDA工具。
## 777. `cs.LG` - 多数据源条件生成建模的理论 [PDF](https://arxiv.org/pdf/2502.14583), [HTML](https://arxiv.org/abs/2502.14583)
### Authors
Rongzhen Wang,Yan Zhang,Chenyu Zheng,Chongxuan Li,Guoqiang Wu
### Background
大型生成模型的成功引发了范式的转变，通过利用大量的多源数据来增强模型能力。然而，这些数据源之间的相互作用在理论层面上还有待探索。
### Innovation
本文首次对条件生成模型中的多源训练进行了严格的分析，每种条件代表一个独立的数据源。提出了基于间隔数的条件最大似然估计中的平均整体变距距离的通用分布估计误差界。结果表明，在源分布具有某些相似性和模型足够表达力的情况下，多源训练比单源训练具有更精细的误差界。进一步将通用理论应用于条件高斯估计和深度生成模型，并通过 characterization 来确定它们的间隔数。
### Conclusion
研究表明，数据源的数量和源分布之间的相似性提高了多源训练的优势。模拟和实际实验验证了理论，并且代码已发布于 this https URL.
## 778. `cs.LG` - 统一解释性异常检测和根本原因分析的动力系统 [PDF](https://arxiv.org/pdf/2502.12086), [HTML](https://arxiv.org/abs/2502.12086)
### Authors
Yue Sun,Rick S. Blum,Parv Venkitasubramaniam
### Background
动力系统广泛存在于各个科学和工程领域，但由于其易受异常影响，这些异常可能严重损害其性能和可靠性。因此，该领域面临着异常检测、根本原因定位和异常类型分类的重要挑战。本文定义了两类异常：一类是通过相互关联的变量传播的网络异常，另一类是仅局限于个别变量的测量异常。
### Innovation
本文提出了一种称为解释性因果微分方程网络（ICODE）的学习框架，它是一种以模型内在的可解释性学习为基础的创新方法。ICODE通过神经ODE进行异常检测，并利用因果推断通道进行根本原因分析（RCA），揭示特定时间点被标记为异常的原因。ICODE设计了一种能在单一可解释框架中同时实现异常检测、RCA和异常类型分类的方法。
### Conclusion
本文通过理论分析展示，异常会改变系统的内在ODE，导致变量间的因果关系发生变化。通过评估表明，ICODE在各种动力系统中的有效性得到了验证，能够准确检测异常、分类异常类型并定位其源头。
## 779. `cs.LG` - Multi-Channel Hypergraph Contrastive Learning for Matrix Completion [PDF](https://arxiv.org/pdf/2411.01376), [HTML](https://arxiv.org/abs/2411.01376)
### Authors
Xiang Li,Changsheng Shui,Zhongying Zhao,Junyu Dong,Yanwei Yu
### Background
评分是一种典型的用户显式反馈，直观地反映了用户对相关商品的喜爱程度。矩阵完成本质上是一个评分预测过程，也是推荐系统中的一个重要问题。近年来，图神经网络（GNNs）广泛应用于矩阵完成中，通过将评分矩阵视为二分图来捕捉用户的商品偏好。然而，现有的方法在实际场景中由于数据稀疏性和长尾分布易受难以预测的影响。此外，图神经网络的传播机制难以捕捉节点间的高阶关联和约束，而这些对推荐任务是非常有用的。
### Innovation
本文提出了一种用于矩阵完成的多通道超图对比学习框架，名为MHCL。MHCL能够自适应地学习超图结构来捕捉节点之间的高阶关联，并通过基于注意力的多视图聚合共同捕捉局部和全局协作关系。进一步地，为了考虑评分的大小和顺序信息，将不同的评分子图视为不同的通道，并鼓励相邻评分之间的对齐，还通过多通道交叉评分对比学习实现不同评分之间的相互增强。实验结果表明，所提出的方法在五个公开数据集上的性能显著优于现有最先进的方法。
### Conclusion
扩展的实验表明，提出的MHCL方法显著优于当前最先进的方法，是处理矩阵完成中数据稀疏性和长尾分布问题的有效手段，同时也能够更准确地捕捉节点间的高阶关联和约束，提升推荐系统的性能。
## 780. `cs.LG` - 基于集成视频文本的大语言模型组合策略框架在心力衰竭评估中 [PDF](https://arxiv.org/pdf/2502.16548), [HTML](https://arxiv.org/abs/2502.16548)
### Authors
Jianzhou Chen,Jinyang Sun,Xiumei Wang,Xi Chen,Heyu Chu,Guo Song,Yuji Luo,Xingping Zhou,Rong Gu
### Background
心力衰竭是全球范围内导致死亡的主要原因之一，每年有数百万人因此丧生，根据世界卫生组织（WHO）和其他公共卫生机构的数据。尽管该领域取得了显著进展，提高了生存率和射血分数，但仍有很多未满足的需求，这主要是由于心力衰竭的复杂性和多因素的特征。
### Innovation
提出了一个可组合策略框架，用于心力衰竭的评估和治疗优化。该框架模拟了医生与患者的咨询过程，并利用多模态算法来分析视频、体格检查、文本结果以及医疗历史等数据。通过整合这些各种数据源，该框架为患者提供了更全面的评估和优化的治疗方案。此外，该多模态方法在心力衰竭预后预测的准确性上优于单一模态的人工智能算法。
### Conclusion
通过这种方法，我们可以进一步评估各种病理指标对心力衰竭预后的影响，提供更全面的评估。
## 781. `cs.LG` - 分析子空间路由：递归最小二乘法在大型语言模型持续学习中的工作机制 [PDF](https://arxiv.org/pdf/2503.13575), [HTML](https://arxiv.org/abs/2503.13575)
### Authors
Kai Tong,Kang Pan,Xiao Zhang,Erli Meng,Run He,Yawen Cui,Nuoyan Guo,Huiping Zhuang
### Background
大型语言模型（LLMs）具有广泛的能力，能够处理各种语言相关任务。然而，对LLMs进行微调会降低其一般技能，持续微调将进一步导致累积知识的重大退化。最近，在大型语言模型中出现持续学习（CL）的概念，其目标是在持续适应新的任务时保持之前学过的知识和通用技能。现有技术要么利用先前的数据进行重放，导致额外的计算成本，要么利用单一的参数高效模块来学习下游任务，这限制了新知识的吸收并导致不同任务之间的干扰。
### Innovation
本文提出了一种名为Analytic Subspace Routing(ASR)的方法，以解决这些问题。通过隔离在深层特征的子空间内的学习，ASR采用低秩适应消除不同任务之间的知识干扰。此外，提出了一个分析路由机制，适当利用不同子空间中学习到的知识。通过递归最小二乘法训练一个多任务路由模型，使路由器能够动态适应新数据，并有效分配当前任务到适当的子空间，同时具有不遗忘之前学习任务的性质。
### Conclusion
实验结果表明，本方法实现了之前知识几乎完美的保留，同时无缝地融合了新信息，有效克服了现有方法的核心局限性。
## 782. `cs.LG` - RSPO: 带正则化的自我博弈对齐大型语言模型 [PDF](https://arxiv.org/pdf/2503.00030), [HTML](https://arxiv.org/abs/2503.00030)
### Authors
Xiaohang Tang,Sangwoong Yoon,Seongho Son,Huizhuo Yuan,Quanquan Gu,Ilija Bogunovic
### Background
自我博弈对齐已成为有效调整大规模语言模型（LLMs）的方法，它将偏好优化表述为两玩家游戏。然而，关于正则化策略的研究，特别是与参考策略相关的正则化，尚未充分探讨以减轻过度优化的问题。现有方法存在的主要问题是缺乏一种统一且可插拔的框架，能够支持不同正则化策略的同时保证收敛到纳什均衡。
### Innovation
我们提出了 **带正则化的自我博弈策略优化（RSPO）**，这是一种通用且模块化的框架，能够统一先前的方法，并允许简单地插拔各种正则化策略，同时保持相应的正则化方法的收敛到纳什均衡的特性。实验证明，使用前向和后向KL散度的线性组合进行正则化的RSPO显着提升了长度控制赢率，从非正则化的自我博弈的28.5%提高到35.4%，并在Arena-Hard、MT-Bench、ArmoRM评分和响应多样性方面表现出了持续的优越性能。
### Conclusion
RSPO结合了简单性、收敛性保证和显著的实验收益，为探索语言模型对齐中的带正则化的自我博弈提供了一个强有力的基础。
## 783. `cs.LG` - DRAN: 一种适应分布和关系的空间时序预测网络 [PDF](https://arxiv.org/pdf/2504.01531), [HTML](https://arxiv.org/abs/2504.01531)
### Authors
Xiaobei Zou,Luolin Xiong,Kexuan Zhang,Cesare Alippi,Yang Tang
### Background
空间时序系统的准确预测对于系统管理、控制以及危机预防等任务至关重要。然而，空间时序系统固有的时间变异使得在非平稳条件下实现准确预测变得困难。为了应对非平稳性问题，本文提出了一个称为分布和关系自适应网络（DRAN）的模型，能够在随着时间变化动态适应关系和分布的变化。
### Innovation
本文开发了空间因子学习器（SFL）模块来进行时空特征的标准化和去标准化。为了应对传感器之间动态变化的空间关系，本文提出了动态-静态融合学习器（DSFL）模块，该模块通过自适应融合机制有效地将从动态和静态关系中学到的特征进行整合。此外，引入了随机学习器来捕捉空间时序表示中的噪声成分。
### Conclusion
本文方法在气象预测和交通流量预测上优于最先进的方法。实验结果显示，SFL 有效保持了各种时空标准化操作下的空间关系。通过学习的动态和静态关系的可视化表明，DSFL 能够捕捉节点之间的局部和远程关系。
## 784. `cs.LG` - 可扩展的离散扩散采样器：组合优化与统计物理学 [PDF](https://arxiv.org/pdf/2502.08696), [HTML](https://arxiv.org/abs/2502.08696)
### Authors
Sebastian Sanokowski,Wilhelm Berghammer,Martin Ennemoser,Haoyu Peter Wang,Sepp Hochreiter,Sebastian Lehner
### Background
在统计物理学、变分推断和组合优化领域，从复杂非规范化分布中学习离散域上的采样出现了作为有前景的研究方向。虽然最近的工作表明扩散模型在此领域具有潜力，但现有方法在内存扩展方面存在限制，导致无法实现足够的采样步骤，这是因为它们需要对整个生成过程进行回传。为了克服这些限制，我们提出了两种新的离散扩散采样训练方法，一种基于策略梯度定理，另一种利用Self-Normalized Neural Importance Sampling (SN-NIS)。这些方法实现了内存高效的训练，并在无监督组合优化中达到了最先进的结果。此外，许多科学应用还要求无偏采样能力。我们提出了对SN-NIS和神经马尔可夫链蒙特卡洛的方法进行的改进，首次使离散扩散模型能够应用于这一问题。在Ising模型基准测试上验证了我们的方法，并发现它们优于流行的自回归方法。这些工作为将扩散模型应用于广泛的科学应用打开了新的途径，这些应用以往仅限于精确的似然模型。
### Innovation
我们提出了两种新的离散扩散采样训练方法，一种基于策略梯度定理，另一种利用Self-Normalized Neural Importance Sampling (SN-NIS)。这些方法与现有方法相比，实现了更高效的内存使用，并且在无监督组合优化中达到了最先进的结果。而且，我们提出了对SN-NIS和神经马尔可夫链蒙特卡洛方法的改进，使离散扩散模型能够应用于那些需要无偏采样的问题，这是前所未有的。我们的工作开创了在离散域应用扩散模型的新途径，这些应用此前仅限于精确似然模型。
### Conclusion
我们的工作为许多科学应用打开了新的应用领域，尤其是那些需要离散扩散模型来实现实际应用而受限于精确似然模型的应用。通过引入这些新的训练方法，我们不仅提高了离散扩散采样的效率，还为组合优化和统计物理学提供了更强大的工具。
## 785. `cs.LG` - 平衡高效性和表达性：基于游走中心性的子图GNN [PDF](https://arxiv.org/pdf/2501.03113), [HTML](https://arxiv.org/abs/2501.03113)
### Authors
Joshua Southern,Yam Eitan,Guy Bar-Shalom,Michael Bronstein,Haggai Maron,Fabrizio Frasca
### Background
子图GNN已经发展成为克服图神经网络(GNN)表达性限制的有前景架构，通过处理子图集来实现。尽管它们在实际性能上表现出色，但这些方法面临着高计算复杂度的问题：它们处理的子图集大小与节点数成线性关系，这限制了其在大规模图上的应用。本文介绍了如何有效且易于实现地减少子图GNN的计算成本，从而扩展其更广泛的应用。
### Innovation
本文提出了名为HyMN的方法，该方法利用基于游走的中心性度量来采样少量的相关子图，大大减少子图集的大小。通过与扰动分析的联系，突显基于中心性的子图采样的优越性，并进一步证明这些基于游走的中心性可以作为结构编码，提高鉴别能力。实验结果表明，HyMN能够在保持高效性和表达性的同时，提高下游性能，使得子图GNN可应用到更大规模的图中。此外，该方法在计算时间上胜于更复杂的子图采样方法，并且在某些情况下甚至优于其他最先进的方法的性能。
### Conclusion
HyMN通过利用基于游走的中心性策略，成功表现出在高效性和表达性之间取得平衡的能力，从而更广泛地应用于大规模图中。其有效的合成表达性、效率和下游性能，为子图GNN的应用奠定了基础。
## 786. `cs.LG` - 通过反向传播优化扩散策略 [PDF](https://arxiv.org/pdf/2505.10482), [HTML](https://arxiv.org/abs/2505.10482)
### Authors
Ningyuan Yang,Jiaxuan Gao,Feng Gao,Yi Wu,Chao Yu
### Background
扩散策略因其高表示能力，在机器人技术、游戏和自动驾驶等决策场景中广泛应用，能够从演示数据中学习多种技能。然而，演示数据的不足和完善覆盖范围有限，可能导致生成次优轨迹，甚至灾难性故障。现有的基于强化学习（RL）的微调方法虽有潜力解决问题，但难以有效地将proximal策略优化（PPO）适应扩散模型，由于解噪过程中的动作似然估计计算复杂，导致优化目标复杂。
### Innovation
本文提出了一种名为NCDPO的新框架，将扩散策略重构为噪声条件下的确定性策略。通过将每个解噪步骤视为基于预采样噪声的可微变换，NCDPO实现了解析似然评估和所有扩散时间步长的梯度反向传播。实验表明，NCDPO在从头开始训练时，其样本效率与多层感知机+PPO相当，并且在样本效率和最终性能上优于现有方法，适用于连续机器人控制和多智能体游戏场景。同时，实验结果表明，该方法对扩散策略中的解噪时间步数量具有鲁棒性。
### Conclusion
NCDPO在样本效率和最终性能上优于现有方法，特别是在连续机器人控制和多智能体游戏场景中展现了优越性。此外，NCDPO的框架展示了对扩散策略中解噪时间步数量的良好鲁棒性。
## 787. `cs.LG` - 信任区域扭曲策略改进 [PDF](https://arxiv.org/pdf/2504.06048), [HTML](https://arxiv.org/abs/2504.06048)
### Authors
Joery A. de Vries,Jinke He,Yaniv Oren,Matthijs T. J. Spaan
### Background
蒙特卡洛树搜索（MCTS）在深度强化学习（RL）中推动了很多近期的突破。然而，在实践中将MCTS扩展到并行计算仍具挑战性，由此激励了替代规划者如顺序蒙特卡洛（SMC）方法的发展。许多SMC方法通过将RL重新表述为策略推断问题而采用粒子滤波，但这些粒子滤波的设计选择往往与RL中在线规划的目标相冲突，即在开始规划时获得策略改进。
### Innovation
本文借鉴MCTS，专门为RL定制了一种改进的SMC规划器——信任区域扭曲SMC（TRT-SMC）。该方法通过限制动作采样和显式处理终止状态来提高规划器内的数据生成，同时改进策略和价值目标估计。
### Conclusion
TRT-SMC展示了在离散和连续领域中相较于基础MCTS和SMC方法改进的运行时间和样本效率。
## 788. `cs.LG` - 预训练模型在重用中任务和特征相关性的经验研究 [PDF](https://arxiv.org/pdf/2506.01975), [HTML](https://arxiv.org/abs/2506.01975)
### Authors
Jama Hussein Mohamud,Willie Brink
### Background
预训练神经网络在机器学习领域被广泛使用和重用。Alice为特定任务训练了一个模型，而Bob可以利用Alice的一部分神经网络来完成不同的任务，这通常能取得很好的效果。文章探讨了Bob在使用Alice预训练网络中的成功背后的原因，以及任务和特征之间的相关性对这种重用成功的影响。
### Innovation
研究提供了一个实验框架，用于在计算机中研究重用预训练模型中影响实际成功的因素。研究结果表明，Bob的成功可能是运气使然，即他的任务准确率随与Alice任务之间的相关性增加而单调增加。即使任务是不可证明相关的，通过Alice的网络结构和优化器选择，Bob也能显著优于随机性能。研究还发现，在任务相关性较小时，重用较低级别的预训练层更为有效。
### Conclusion
在控制的现实场景中，只有存在语义相关性时，Bob才能有效重用Alice的预训练网络。研究得出的结论是，最优重训练层数量可能反映了任务和特征的相关性。
## 789. `cs.LG` - 面向视觉语言模型的通用连续记忆 [PDF](https://arxiv.org/pdf/2505.17670), [HTML](https://arxiv.org/abs/2505.17670)
### Authors
Wenyi Wu,Zixuan Song,Kun Zhou,Yifei Shao,Zhiting Hu,Biwei Huang
### Background
语言模型和视觉-语言模型在多个任务上取得了显著成果，但仍难以应对需要多模态或多语言现实世界知识的复杂推理任务。现有的方法通常将图像和文本标记连接成一个长序列作为记忆，这可能会大幅增加上下文长度并影响性能。现有方法的一个主要问题是，它们需要大量的参数和较长的上下文，这限制了其应对复杂任务的能力。因此，引入一种能够高效提供相关多模态信息的外部记忆系统是必要的，这种系统可以在不牺牲性能的情况下有效存储和访问多模态和多语言知识。
### Innovation
提出了一种新的设计思路，即使用连续记忆（一种紧凑的密集嵌入集）来更有效地表示多模态和多语言知识。该方法的关键创新之处在于，视觉-语言模型可用作其自身的连续记忆编码器。该论文还介绍了一种高效的方法，使用极少量的模型参数和小规模的数据集（仅为模型参数的1.2%和15,600个自我合成样本）进行微调，将视觉-语言模型转化为记忆编码器，从而实现了一种新颖的记忆模块。这种模块是细粒度的，在推理时冻结的视觉-语言模型，使其成为插件即用型，可以灵活集成到系统中。该方法CoMEM利用视觉语言模型的原有能力，仅用8个连续嵌入表示任意多模态和多语言知识。这种方法已经在八个跨模态推理基准测试中展示了其有效性，证明了该设计改进了复杂跨模态推理任务的性能，大幅提高了对复杂任务的处理能力。
### Conclusion
该研究通过提出一种新的连续记忆设计和高效微调方法，有效提升了视觉语言模型在复杂多模态推理任务中的表现，证明了该方法在多个多模态推理基准测试中的优越性，并展示了其灵活性和高效性。
## 790. `cs.LG` - SPEED-RL: 通过在线课程学习更快训练推理模型 [PDF](https://arxiv.org/pdf/2506.09016), [HTML](https://arxiv.org/abs/2506.09016)
### Authors
Ruiqi Zhang,Daman Arora,Song Mei,Andrea Zanette
### Background
使用强化学习（RL）对可验证奖励的大型语言模型进行训练可以显著提升它们的推理能力，但由于不高效的统一提示采样方法，使得该过程非常耗时。
### Innovation
引入了适应性在线RL课程(SPEED)，它选择性地选择具有中等难度的训练示例以最大化学习效率。理论上，证明了中等难度的提示可以提高梯度估计器的信噪比，加速收敛。实验证明，这是一种高效的实现方式，能够实现2到6倍的训练速度，且不降低准确性，无需手动调参，可以无缝整合到标准RL算法中。
### Conclusion
SPEED-SRL 方法通过选择性采用中等难度提示，使得大型语言模型的训练速度快了2到6倍，且不需要人工调整，能够无缝集成到标准的 RL 算法中。
## 791. `cs.LG` - Offline Learning and Forgetting for Reasoning with Large Language Models [PDF](https://arxiv.org/pdf/2504.11364), [HTML](https://arxiv.org/abs/2504.11364)
### Authors
Tianwei Ni,Allen Nie,Sapana Chaudhary,Yao Liu,Huzefa Rangwala,Rasool Fakoor
### Background
在推理阶段利用大型语言模型进行搜索已被证明能够进一步提升模型解决复杂数学和推理问题的能力。然而，这种方法会显著增加计算成本和推理时间，因为模型需要生成和评估多个候选解决方案来确定可行的推理路径。
### Innovation
本文提出了一个有效的策略，通过在来自不同搜索方法的未配对成功和失败推理路径上进行微调，将搜索能力直接集成到模型中。该策略还包括使用较小的学习率来缓解盲目微调对模型搜索能力的负面影响。实验结果表明，相较于推理时的搜索基线，通过离线微调生成的数据（搜索生成的数据）可以将成功率提高约23%，同时将推理时间降低180倍。此外，本文的学习和遗忘目标始终优于监督微调和基于偏好方法。
### Conclusion
研究表明，通过离线微调生成的数据，可以提高大型语言模型解决推理问题的成功率，同时大幅缩短推理时间，且能够持续优于监督微调和基于偏好方法。
## 792. `cs.LG` - 在二元反馈设置中利用预测优化第一价格拍卖的出价策略 [PDF](https://arxiv.org/pdf/2506.15817), [HTML](https://arxiv.org/abs/2506.15817)
### Authors
Jason Tandiary
### Background
文章研究了在二元反馈情况下Vickrey第一价格拍卖。随着第一价格拍卖的重要性增加以及机器学习模型预测能力的提升，本文提出了一种基于BROAD-OMD框架的新算法。该算法利用预测最高竞争对手出价的信息，从而改进了BROAD-OMD算法的遗憾边界。在一定的正态条件下，论文还提出了遗憾边界为O(T^(3/4) * Vt^(1/4))的结果，展示了在准确预测情况下算法实现零遗憾的效果。
### Innovation
提出了一种在BROAD-OMD框架下的新算法，能够利用机器学习模型对未来最高竞争对手出价的预测来改进遗憾边界。在准确预测情况下实现了零遗憾，并给出了遗憾边界为O(T^(3/4) * Vt^(1/4))的保证，进一步提升了算法性能。
### Conclusion
文章提出的新算法在准确预测情况下实现了零遗憾，并且在某些正态条件下具备O(T^(3/4) * Vt^(1/4))的遗憾边界，这表明在第一价格拍卖中利用机器学习模型预测能力能够显著提高拍卖算法的表现。
## 793. `cs.LG` - 加速大规模正则化高阶张量恢复 [PDF](https://arxiv.org/pdf/2506.09594), [HTML](https://arxiv.org/abs/2506.09594)
### Authors
Wenjin Qin,Hailin Wang,Jingyao Hou,Jianjun Wang
### Background
现有的张量恢复方法无法识别张量尺度变化对其结构特征的影响，而且处理大规模高阶张量数据时面临极大的计算成本。因此需要一种新的方法来解决这些问题以加速大规模张量恢复。
### Innovation
文章通过结合Krylov子空间迭代、块朗格马斯双因子化过程和随机投影策略，首先提出了两个快速而准确的低秩张量逼近（LRTA）问题的随机化算法，并设定了逼近误差估计的理论界。接着开发了一种适合大规模张量恢复的新型非凸建模框架，又基于此框架分别研究了一些典型的非凸模型和高效的优化算法，适用于高阶张量恢复任务，并将提出的随机化LRTA方案集成到其核心和计算密集部分。
### Conclusion
进行广泛的实验结果表明，所提出的算法在大规模张量数据下具有实践性、有效性和优越性，优于一些最先进的方法。
## 794. `cs.LG` - 基于变分方法的离线强化学习离分布状态纠正 [PDF](https://arxiv.org/pdf/2505.00503), [HTML](https://arxiv.org/abs/2505.00503)
### Authors
Ke Jiang,Wen Jiang,Xiaoyang Tan
### Background
离线强化学习的表现受到状态分布偏移问题的影响，特别是在处理离分布（OOD）状态时。为了应对这一问题，前人提出了离分布状态纠正的方法，其中一种流行的策略是密度感知安全感知（DASP），该方法鼓励智能体优先采取导致更高数据密度结果的动作，从而使其能够在安全的分布内操作或返回安全区域。然而，现有的方法可能在提供安全决策的关键背景信息方面不够充分，因此需要新的方法来优化决策的目标函数，使之在考虑潜在结果的同时也考虑结果的密度，从而提高安全决策的有效性。
### Innovation
本文提出了一种新颖的方法——基于变分框架的密度感知安全感知（DASP），该方法优化了包含决策潜在结果及其密度双重考量的总体目标，为安全决策提供了至关重要的上下文信息，从而克服了传统方法的不足，提高了离线强化学习在离分布状态下的性能。
### Conclusion
通过在离线MuJoCo和AntMaze套件上的广泛实验，证明了本文提出的方法的有效性和可行性，表明该方法能够显著提升离线强化学习在处理离分布状态时的表现。
## 795. `cs.LG` - 贝叶斯层次不变预测 [PDF](https://arxiv.org/pdf/2505.11211), [HTML](https://arxiv.org/abs/2505.11211)
### Authors
Francisco Madaleno,Pernille Julie Viuff Sand,Francisco C. Pereira,Sergio Hernan Garrido Mejia
### Background
本文提出了贝叶斯层次不变预测（BHIP），其基于层次贝叶斯重新定义了不变因果预测（ICP）。通过利用层次结构，BHIP可以明确测试在异质数据下因果机制的不变性，相较于ICP，这提高了计算扩展性，适用于更多预测变量。同时，由于贝叶斯的本质，BHIP允许使用先验信息，增加了其灵活性和准确性。文中探讨了两种稀疏性诱导先验：汉舍 Shoe 和尖峰与粘结 Spike-and-Slab，这两种方法有助于更可靠地识别因果特征。实验表明，在合成数据和真实数据上，BHIP展示了作为ICP替代推理方法的潜力。
### Innovation
BHIP将ICP重新定义为基于层次贝叶斯的方法，以测试在异质数据下因果机制的不变性，增加了先验信息的使用，通过引入汉舍（horseshoe）和尖峰与粘结（spike-and-slab）两种稀疏性诱导先验提高了因果特征识别的可靠性，使得BHIP在大数量预测变量下具有更好的计算扩展性。
### Conclusion
通过BHIP的实验结果表明，该方法是一种高效的替代ICP的因果推理方法，特别是在处理大量预测变量时表现出色。
## 796. `cs.LG` - WATS: 通过波let感知温度调整校准图神经网络 [PDF](https://arxiv.org/pdf/2506.23782), [HTML](https://arxiv.org/abs/2506.23782)
### Authors
Xiaoyang Li,Linwei Tao,Haohui Lu,Minjing Dong,Junbin Gao,Chang Xu
### Background
图神经网络（GNNs）在处理关系数据时表现出色，但它们的置信度估计往往与实际预测准确性不符，这在安全关键环境中构成了重大制约。尽管现有的图感知校准方法试图减轻这一限制，但它们主要依赖于粗粒度的一跳统计信息，如邻居预测置信度或潜节点嵌入，从而忽略了图拓扑中固有的微粒级结构异质性。
### Innovation
本文提出了一种名为Wavelet-Aware Temperature Scaling（WATS）的后处理校准框架，该框架基于可调节的热核图波let特征为节点分配特定温度。WATS利用图波let的可扩展性和拓扑敏感性来精化置信度估计，而无需重新训练模型或访问相邻的logits或预测。WATS在七个具有不同图结构的基准数据集上以及两个GNN基础架构上进行广泛评估，结果显示它在所有比较方法中实现了最低的期望校准误差（ECE），并且在ECE上比经典的和图特定的基本方法平均高出42.3%，同时WATS在降低校准方差方面也表现出色，平均减少17.24%。此外，WATS在计算效率方面表现出色，能够很好地扩展到不同大小和密度的图中。
### Conclusion
WATS通过波let感知温度调整校准图神经网络，显著提升了在安全关键环境中的应用。该方法在多个基准数据集和两种GNN上取得了最佳的期望校准误差，并且在计算效率方面也表现出色。
## 797. `cs.LG` - GuiderNet:一种用于优化量子电路几何结构和缓解荒漠 plateau 的元学习框架 [PDF](https://arxiv.org/pdf/2506.21940), [HTML](https://arxiv.org/abs/2506.21940)
### Authors
Marwan Ait Haddou,Mohamed Bennai
### Background
变分量子算法（VQAs）为近期量子优势提供了潜力，但由于梯度消失的荒漠 plateau 和欠佳的优化地形问题而面临挑战。参数化量子电路（PQCs）在这些挑战面前表现不佳。
### Innovation
提出了一种基于元学习框架的 GuiderNet，利用数据依赖的参数位移来最小化 Fubini-Study 度量张量的日志条件数，条件指引 PQCs 参数进入几何上有利的区域。GuiderNet 作为一个经典神经网络进行元训练，以在混合量子-经典管道中引导 PQCs 参数初始化和适应性调制，从而实现更平滑和稳健的优化。
### Conclusion
GuiderNet 在 Kaggle 糖尿病分类任务中将累计训练损失降低了 5 倍以上，测试准确率从 75.3% 提高到 98.6%，少数类别 F1 评分从 0.67 提高到 0.95。此外，GuiderNet 抑制了梯度爆炸并稳定了参数更新，增强了优化的平滑性和稳健性。这些结果表明几何元约束可以缓解荒漠 plateau 和病态条件问题，提供了一种可扩展的方法来增强量子机器学习中的可训练性和泛化能力。
## 798. `cs.LG` - 逃出柏拉图的洞穴：使用JAM对独立训练的视觉和语言模型进行对齐 [PDF](https://arxiv.org/pdf/2507.01201), [HTML](https://arxiv.org/abs/2507.01201)
### Authors
Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim
### Background
独立训练的视觉和语言模型各自拥有不同的表征空间，并由各自的模态、目标和架构形成。然而，一种新兴假设——柏拉图表征假设（Platonic Representation Hypothesis）表明，这些模型可能仍朝着共享的现实统计模型收敛。因此，现有的方法通常依赖于事后统计检测对齐，而未曾尝试直接优化不同模态之间的对齐。该研究提出将这种柏拉图对齐问题转化为一个多目标优化任务，既要保留每个模态的原有结构，又要实现相互的协同性。研究者提出了Joint Autoencoder Modulator（JAM）框架，该框架通过在预训练单模态模型的潜在表示上训练模态特定的自编码器，并通过重建和跨模态目标加强对齐，旨在解决这个问题。研究还评估了该框架在三个关键设计轴上的效果：对齐目标、最有效的层深度以及基础模型规模对表征收敛的影响。实验结果表明，尽管基础模型已经冻结，该框架仍然能够稳定地促使不同模态之间的对齐，提供了理论洞察和将通用单模态基础转变为专门多模态模型的实践途径。
### Innovation
提出了将柏拉图对齐问题转化为一个多目标优化任务的方法；提出了Joint Autoencoder Modulator（JAM）框架，通过训练模态特定的自编码器加强不同表征之间的对齐。
### Conclusion
研究显示，即使在冻结和独立训练的不同模态表征之间，该框架仍然能够有效地提升对齐度，从理论上和实践中为多模态模型的构建提供了新的见解和方法。
## 799. `cs.LG` - skfolio：Python中的组合优化 [PDF](https://arxiv.org/pdf/2507.04176), [HTML](https://arxiv.org/abs/2507.04176)
### Authors
Carlo Nicolini,Matteo Manzi,Hugo Delatte
### Background
在量化金融领域，组合优化是一个基本挑战，需要强大且可靠的计算工具，能够将统计严谨性和实际操作能力相结合。目前的研究和实践中，没有一个库能够完全集成这些需求，并提供统一的框架来支持多样化分配策略和先进的金融估算方法。这使得研究人员和实践者在使用组合优化技术时面临挑战，尤其是在需要遵循行业标准的机器学习工作流程时。因此，开发一个能够无缝集成到scikit-learn生态系统的开源Python库，对于促进金融领域的研究与实践具有重要意义。
### Innovation
skfolio是一个开源的Python库，专门用于组合构造和风险管理。它通过无缝集成到scikit-learn生态系统，提供了一个统一的框架，支持从经典的投资组合优化方法到现代基于聚类的方法，以及最先进的金融估算器和定制的交叉验证技术。它还按照scikit-learn的fit-predict-transform模式，使得研究人员和 practitioners 可以利用机器学习工作流程进行组合优化，从而提高研究的可重复性和透明度。
### Conclusion
skfolio提供了一个完整的解决方案，结合了统计严谨性和实际操作能力，使得研究人员和从业者能够更方便地进行组合优化的研究和实践，促进了量化金融领域的进步和创新。
## 800. `cs.LG` - 无配对图像超分辨率的最优传输视角 [PDF](https://arxiv.org/pdf/2202.01116), [HTML](https://arxiv.org/abs/2202.01116)
### Authors
Milena Gazdieva,Petr Mokrov,Litu Rout,Alexander Korotin,Andrey Kravchenko,Alexander Filippov,Evgeny Burnaev
### Background
现实世界中的图像超分辨率（SR）任务通常缺乏配对的数据集，限制了监督技术的应用。因此，这类任务通常通过基于生成对抗网络（GANs）的无配对技术来进行，这些技术会产生复杂的训练损失函数，包含多种正则化项，例如内容或身份损失。虽然GANs在实践中表现良好，但它们通常只是通过启发式的手段来使用，即对于它们的行为的本质理解仍然较为有限。本文从理论上探讨了这类模型中出现的优化问题，并得出了两个令人惊讶的观察结果：首先，学习到的SR映射总是最优传输（OT）映射；其次，理论证明并实验证明，学习到的映射存在偏差，即它实际上没有将低分辨率图像的分布转换为高分辨率的分布。
### Innovation
本文发现学习到的SR映射总是最优传输（OT）映射，并证明了学习到的映射存在偏差。受此发现的启发，作者研究了神经最优传输领域的最新进展，以解决偏差问题，并建立了规范化GANs与神经最优传输方法之间的有趣联系。表明现有的基于GAN的方法存在偏差，而这些算法则旨在学习一个无偏差的OT映射。作者通过一系列合成和现实世界的无配对SR实验实证地展示了这些发现。开源代码已发布在指定的URL上。
### Conclusion
通过理论分析和实际实验，本文阐明了无配对图像SR任务中GANs和最优传输方法之间的关系，并提出了解决偏差问题的新方法。研究成果有助于更好地理解这些模型的行为，并推动此类图像增强技术的发展。
## 801. `cs.LG` - MPX: JAX中的混合精度训练 [PDF](https://arxiv.org/pdf/2507.03312), [HTML](https://arxiv.org/abs/2507.03312)
### Authors
Alexander Gräfe,Sebastian Trimpe
### Background
混合精度训练已成为提高神经网络训练效率的重要工具。与此同时，JAX因其多功能性在机器学习工具库中变得越来越流行，但目前缺乏对混合精度训练的支持。现有的工具箱如Equinox和Flax虽已具备相关特性，但操作繁琐且修改量大。
### Innovation
MPX是一个专门为JAX设计的混合精度训练工具箱，它简化并加速了大规模神经网络的训练过程，同时保持模型准确性。MPX能够无缝集成到Equinox和Flax等工具箱中，并能将全精度管道转换为混合精度版本。通过将输入和输出都转换为半精度，并引入动态损失尺度机制，MPX能够解决半精度计算中常见的梯度下溢和溢出现象。其设计继承了JAX的类型提升行为，确保了操作处于正确的精度级别，并允许在需要时（如求和、求均值或softmax）选择性地使用全精度。
### Conclusion
MPX提供了自动创建和管理混合精度梯度和优化器的包装器，使现有JAX训练管道的整合更加简便。此外，MPX的源代码、文档和使用示例可在官网获得。
## 802. `cs.LG` - 理想磁流体静平衡的神经网络求解器 [PDF](https://arxiv.org/pdf/2507.03119), [HTML](https://arxiv.org/abs/2507.03119)
### Authors
Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff
### Background
本文介绍了一种新颖的方法，通过使用人工神经网络参数化傅里叶模态来计算三维磁流体静平衡，并将其与传统求解器计算的结果进行比较。然后在实空间全量体上最小化非线性全局力残差，使用一阶优化器实现最小化。研究结果表明，在计算成本相当时，神经网络方法可以获得与现有代码相同水平的最小残差，在计算成本更高时可以达到更低的残差最小值，从而建立力残差的新下限。研究采用较为简单的神经网络模型，预测这种方法不仅适用于单个静平衡的求解，还能够计算适用于连续分布静平衡的神经网络模型。
### Innovation
本文提出了一种新的方法，利用人工神经网络参数化傅里叶模态来计算三维磁流体静平衡。这种方法具有计算成本较低且可以达到较低残差的优点，从而可以作为传统求解器的一个新下限。作者还预测这种方法对未来静平衡的求解会有显著改善。这为磁流体静平衡问题提供了一个新的计算策略，特别是在计算成本和精度要求较高的场景中具有潜在优势。
### Conclusion
本文通过采用简单的神经网络模型，已经取得与现有方法相近的计算结果，并展示了其在复杂场景下的潜力。未来的工作将致力于提升模型的复杂性和精确性，以应用于更广泛的物理场景。
## 803. `cs.LG` - Unsupervised 学习用于非平衡图之间最优传输计划的预测 [PDF](https://arxiv.org/pdf/2506.12025), [HTML](https://arxiv.org/abs/2506.12025)
### Authors
Sonia Mazelet,Rémi Flamary,Bertrand Thirion
### Background
基于戈罗沃夫-瓦瑟斯坦（Gromov-Wasserstein）和其他扩展的图之间的最优传输是一种强大的工具，用于比较和对齐图结构。然而，解决与之相关的非凸优化问题非常耗时，限制了这些方法在大规模图上的适用性。
### Innovation
本文提出了一种基于深度学习的方法，称为Unbalanced Learning of Optimal Transport（ULOT），用于预测两个图之间的最优传输计划。该方法通过最小化融合不平衡戈罗沃夫-瓦瑟斯坦（FUGW）损失进行训练。提出了一种带有交叉注意力的新神经架构，并且该架构可以根据FUGW交易超参数进行条件化。ULOT在合成的随机块模型（SBM）图以及来自fMRI的真实皮质表面数据上进行了评估，预测传输计划的损失比经典求解器快100到1000倍以上。此外，预测的计划可以用作经典求解器的温暖启动，加速其收敛。更重要的是，预测的传输计划对图输入和FUGW超参数具有完全可微性，使得可以优化ULOT计划的功能量。
### Conclusion
ULOT能够快速准确地预测最优传输计划，并且能够通过对其进行微调来优化功能量，同时提供对经典求解器的辅助与加速效果。
## 804. `cs.LG` - LoSiA: 通过子网络定位与优化实现高效的高秩微调 [PDF](https://arxiv.org/pdf/2507.04487), [HTML](https://arxiv.org/abs/2507.04487)
### Authors
Xujia Wang,Yunjia Qi,Bin Xu
### Background
PEFT方法，如LoRA，通过引入低秩分解矩阵显著减少了可训练参数的数量。然而，现有的方法在领域专业化任务中进行大量的矩阵乘法运算，导致计算效率低下且微调性能不佳。因此，我们提出了一种创新方法LoSiA（Low-Resources Subnet Integration Adaptation），该方法在训练过程中动态地定位和优化关键参数。具体来说，通过梯度稀疏性分析识别子网络并将其优化为可训练的目标。该设计通过仅更新子网络参数实现有效的高秩适应，从而减少额外的矩阵乘法。我们还提出了LoSiA-Pro，这是一种LoSiA的更快实现方式，相比LoRA将训练延迟降低了约27%。广泛的评估表明，我们的方法在领域专业化和常识推理任务中实现了与全面微调相似的性能，同时训练时间最少。进一步的分析表明，LoSiA 还能在持续训练中减少遗忘现象。
### Innovation
提出了LoSiA方法，通过动态定位和优化关键参数来实现高效的高秩适应。使用梯度稀疏性分析识别子网络并优化其参数，从而减少额外的矩阵乘法，提高计算效率。进一步提出了LoSiA-Pro，降低了训练延迟。
### Conclusion
我们的方法在领域专业化和常识推理任务中实现了与全面微调相似的性能，同时训练时间最少，并在持续训练中减少遗忘现象。此外，LoSiA-Pro 相比LoRA将训练延迟降低了约27%。
## 805. `cs.LG` - NoWag: 一种用于大型语言模型形状保持压缩的一体化框架 [PDF](https://arxiv.org/pdf/2504.14569), [HTML](https://arxiv.org/abs/2504.14569)
### Authors
Lawrence Liu,Inesh Chakrabarti,Yixiao Li,Mengdi Wang,Tuo Zhao,Lin F. Yang
### Background
大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但在资源受限的环境中部署时由于巨大的计算和内存需求而受到限制。
### Innovation
提出了NoWag：一种统一的零样本形状保持压缩算法框架，包括NoWag-VQ和NoWag-P两种形状保持压缩形式。NoWag-VQ显著优于现有的零样本矢量量化方法，而NoWag-P与最先进的方法竞争。
### Conclusion
这些结果表明，这些压缩方法之间存在共性，这可能会激发未来的相关研究。
## 806. `cs.LG` - 使用多模式多实例学习从外周血TCR谱库分类自身免疫性疾病 [PDF](https://arxiv.org/pdf/2507.04981), [HTML](https://arxiv.org/abs/2507.04981)
### Authors
Ruihao Zhang,Fei Ye,Dandan Meng,Yixuan Huang,Maochen,Xiao Liu
### Background
T细胞受体（TCR）谱具有编码自身免疫疾病关键免疫标志的潜力，但在临床应用中受限于序列稀疏性和低检测率。研究者们致力于开发能够高效利用TCR测序数据进行诊断的工具与方法，以提高对自身免疫性疾病的诊断精度和覆盖率，尤其是如何在大规模数据中准确识别疾病相关的TCR特征和基因，以及如何通过TCR谱库分类区分不同类型的自身免疫性疾病。
### Innovation
研究引入了EAMil框架，该框架是一种多实例深度学习模型，它结合了PrimeSeq特征提取、ESMonehot编码和增强的门控注意力机制，用于诊断系统性红斑狼疮（SLE）和类风湿性关节炎（RA）。EAMil模型在SLE和RA诊断上实现了卓越的准确性，AUC值分别为98.95%和97.76%。该模型不仅能够在多个病种分类中表现出色，还能够通过SLEDAI评分对SLE患者的病情严重程度进行分层，并精准诊断SLE患者的损伤部位，同时有效控制年龄和性别等混杂因素的影响。
### Conclusion
该具有可解释性的免疫受体分析框架为自身免疫疾病检测和分类提供了新的见解，具有广泛潜在的临床应用前景，特别是在免疫介导疾病的分类学研究中。
## 807. `cs.LG` - 在LSTM中集成时空特征以实现基于空间信息的COVID-19住院预估 [PDF](https://arxiv.org/pdf/2506.05752), [HTML](https://arxiv.org/abs/2506.05752)
### Authors
Zhongying Wang,Thoai D. Ngo,Hamidreza Zoraghein,Benjamin Lucas,Morteza Karimzadeh
### Background
新冠疫情的严重打击凸显了准确及时的住院预估对于支持有效医疗规划的重要性。然而，大多数预测模型在变异体潮涌期间表现不佳，这正是它们最需要发挥作用的时候。本研究介绍了一种创新的并行流长短期记忆（LSTM）框架，用于预测美国每日州级新增住院人数。该框架结合了一个从Meta社交连通性指数派生的空间时间特征——社交距离到住院区（SPH），以提高预测准确性。SPH作为州际人口互动的代理，捕捉跨时空的传播动态。该架构捕捉短期和长期时间依赖性，并采用多水平聚类策略平衡预测一致性和误差。与COVID-19预测枢纽的集成模型评估显示，本模型在delta和Omicron潮涌期间的表现优越。特别是在Omicron潮涌期间，本模型在7、14、21和28天预测时间点上分别比集成模型多估算27、42、54和69个住院病例，从而证实SPH的预测能力，并加强了其在提高预测模型效果方面的有效性。本研究不仅推进了住院预估的发展，还强调了SPH等时空特征在建模传染病传播复杂动态的重要性。
### Innovation
本研究提出了一个创新的并行流LSTM框架，结合了从Meta社交连通性指数派生的空间时间特征——社交距离到住院区（SPH），以增强预测效果。SPH作为州际人口互动的代理，捕捉跨时空的传播动态。该框架能够同时捕捉短期和长期的时间依赖性，并采用多水平聚类策略平衡预测的一致性和误差。研究结果表明，该模型在预测州级新增住院人数方面显著优于现有的集成模型。此外，数据抽样实验进一步证实了SPH的预测能力及其在提高预测模型效果方面的有效性。
### Conclusion
本研究展示了在LSTM中引入SPH的重要性，能够显著提升住院预估的准确性。该研究不仅推进了住院预估的发展，还强调了时空特征在建模传染病传播复杂动态中的重要性。
## 808. `cs.LG` - TopCoW挑战中的Willis环评估：拓扑感知的Willis环解剖分割 [PDF](https://arxiv.org/pdf/2312.17670), [HTML](https://arxiv.org/abs/2312.17670)
### Authors
Kaiyuan Yang,Fabio Musio,Yihui Ma,Norman Juchler,Johannes C. Paetzold,Rami Al-Maskari,Luciano Höher,Hongwei Bran Li,Ibrahim Ethem Hamamci,Anjany Sekuboyina,Suprosanna Shit,Houjing Huang,Chinmay Prabhakar,Ezequiel de la Rosa,Bastian Wittmann,Diana Waldmannstetter,Florian Kofler,Fernando Navarro,Martin Menten,Ivan Ezhov,Daniel Rueckert,Iris N. Vos,Ynte M. Ruigrok,Birgitta K. Velthuis,Hugo J. Kuijf,Pengcheng Shi,Wei Liu,Ting Ma,Maximilian R. Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus Maier-Hein,Chengcheng Zhu,Huilin Zhao,Philippe Bijlenga,Julien Hämmerli,Catherine Wurster,Laura Westphal,Jeroen Bisschop,Elisa Colombo,Hakim Baazaoui,Hannah-Lea Handelsmann,Andrew Makmur,James Hallinan,Amrish Soundararajan,Bene Wiestler,Jan S. Kirschke,Roland Wiest,Emmanuel Montagnon,Laurent Letourneau-Guillon,Kwanseok Oh,Dahye Lee,Adam Hilbert,Orhun Utku Aydin,Dimitrios Rallios,Jana Rieger,Satoru Tanioka,Alexander Koch,Dietmar Frey,Abdul Qayyum,Moona Mazher,Steven Niederer,Nico Disch,Julius Holzschuh,Dominic LaBella,Francesco Galati,Daniele Falcetta,Maria A. Zuluaga,Chaolong Lin,Haoran Zhao,Zehan Zhang,Minghui Zhang,Xin You,Hanxiao Zhang,Guang-Zhong Yang,Yun Gu,Sinyoung Ra,Jongyun Hwang,Hyunjin Park,Junqiang Chen,Marek Wodzinski,Henning Müller,Nesrin Mansouri,Florent Autrusseau,Cansu Yalçin,Rachika E. Hamadache,Clara Lisazo,Joaquim Salvi,Adrià Casamitjana,Xavier Lladó,Uma Maria Lal-Trehan Estrada,Valeriia Abramova,Luca Giancardo,Arnau Oliver,Paula Casademunt,Adrian Galdran,Matteo Delucchi,Jialu Liu,Haibin Huang,Yue Cui
### Background
Willis环是一个连接大脑主要循环的动脉网络，其血管结构被认为影响严重的脑血管疾病的风险、严重程度和临床结果。然而，描述Willis环高度变异的解剖结构仍然是一个手工和耗时的专业任务。Willis环通常通过两种非侵入性血管成像技术，磁共振血管成像（MRA）和计算机断层血管成像（CTA）来成像，但用于标记Willis环解剖结构的标注数据集有限，尤其是在CTA方面。
### Innovation
组织了TopCoW挑战，发布了注释的Willis环数据集，首次包含13个Willis环血管组件的体素层次标注，利用虚拟现实技术。TopCoW数据集是最大的一个，包含200对来自相同患者的MRA和CTA图像。邀请了来自六大洲的250多名参与者参赛，对226个来自五个中心的扫描进行评估。顶级团队在全球范围内实现了超过90%的Dice分数、80%的F1分数，以及超过70%的平衡准确度来分割和分类Willis环变种。最佳算法在分类胎儿型后交通动脉和利用Willis环解剖学检测动脉瘤方面也展示了临床潜力。提供开源数据和最佳算法以促进进一步的方法发展和临床工具构建。
### Conclusion
TopCoW展示了Willis环分割算法在广泛下游临床应用中的实用性和灵活性，具有解释性。发布注释数据集和最佳算法能够促进进一步的临床工具开发。
## 809. `cs.LG` - 从强混合观测进行深度学习：稀疏正则化和最小最大最优性 [PDF](https://arxiv.org/pdf/2406.08321), [HTML](https://arxiv.org/abs/2406.08321)
### Authors
William Kengne,Modou Wade
### Background
近年来，浅层神经网络估计算法在独立数据上的显式正则化和优化取得了显著进展。然而，在依赖数据上研究此类特性仍然是一个挑战。本文研究了从强混合观测的数据中进行深度学习的方法，并处理了平方和广泛类别的损失函数。
### Innovation
本文提出了稀疏正则化的深度神经网络预测方法。对于回归估计、分类、时间序列预测等一般框架，建立了期望超额风险的oracle不等式，并提供了Hölder光滑函数类的界。对于强混合数据的非参数回归和亚指数误差，提供了$L_2$误差的oracle不等式，并研究了该误差在Hölder复合函数类上的上界。对于具体情况下的非参数自回归，给出了特定误差分布（高斯和拉普拉斯）下$L_2$误差在Hölder复合函数类上的下界。
### Conclusion
基于对强混合观测数据的研究，深度神经网络估计器在Hölder复合函数类上的$L_2$误差达到了最小最大最优率，到了最优的阶数。
## 810. `cs.LG` - 关于变量子学习模型训练性和非退量化之间关系的研究 [PDF](https://arxiv.org/pdf/2406.07072), [HTML](https://arxiv.org/abs/2406.07072)
### Authors
Elies Gil-Fuster,Casper Gyurik,Adrián Pérez-Salinas,Vedran Dunjko
### Background
变量子学习（QML）的成功依赖于设计合适的参数化量子电路（PQCs），这些电路类似于经典机器学习中的神经网络。成功实现QML需要满足可训练性和非退量化等特性。近期研究指出，训练性和退量化在变量子学习模型中的关系错综复杂，尚未完全解决。
### Innovation
本文从机器学习的角度，证明了一系列结果，其中一些表明训练性和非退量化并不是不可调和的冲突。论文首先提供了一些新的相对于其他文献的更广泛的概念定义，这些定义是操作上驱动的，并且与先前的研究一致。之后，论文研究了训练性和退量化之间的关系，并讨论了QML模型的“变量子性”不同层次。最后，提出了构建同时具有可训练性和非退化特征的PQC基础QML模型的方法，这些模型对应于不同层次的“变量子性”。
### Conclusion
虽然没有讨论这些模型的实际效用，但本文为寻找更为通用的构造方法提供了思路，这可能为实际应用铺平道路。
## 811. `cs.LG` - 新闻与负荷：驱动区域多时间尺度电力需求预测的社会与经济因素 [PDF](https://arxiv.org/pdf/2406.06641), [HTML](https://arxiv.org/abs/2406.06641)
### Authors
Yun Bai,Simon Camal,Andrea Michiorri
### Background
电力需求与经济活动及天气模式之间的关系已得到充分研究，但该研究进一步探索了电力需求与社会因素之间的联系。研究通过自然语言处理技术，分析了大量的新闻语料库，展示了文本特征与区域电力需求之间的因果关系，并考虑了多种时间尺度，从1天到30天，以及经济变量如GDP、失业率和通货膨胀率的影响。
### Innovation
该研究首次将关于社会状态的动态信息嵌入到能源需求建模和预测方法中，并通过分析大量新闻进行这一探索，特别是在揭示文本特征与区域电力需求之间的因果关系方面引入了新的方法。该研究还根据影响程度的不同，区分了社会指标和经济指标的不同作用，从而提高了电力需求预测的准确性。
### Conclusion
研究表明，文本特征与军事冲突、交通运输、全球疫情、区域经济以及国际能源市场等内容相关，这些因素在格兰杰因果检验和双重机器学习方法中显示出了与区域电力需求的关系性影响。社会指标在威尔士中部和英格兰西南部的影响较为重要，而经济指标则在东米德尔兰兹和北爱尔兰具有更重要的作用。将这些因素纳入模型后，预测准确率提高了约6%。
## 812. `cs.LG` - AI引发的不可保风险：政府作为最后保险人 [PDF](https://arxiv.org/pdf/2409.06672), [HTML](https://arxiv.org/abs/2409.06672)
### Authors
Cristian Trout
### Background
许多专家认为，AI系统迟早会带来无法保险的风险，包括存在性风险。这引发了一个极端的责任豁免问题：在发生此类灾难情况下，很少甚至没有方能被追究责任。
### Innovation
本文提出了一种新颖的解决方案：由政府提供的强制性AI开发者赔偿计划。该计划使用风险定价的赔偿费来引导社会最优水平的关怀。风险估计通过调查包括被保险的开发者在内的专家来确定。使用贝叶斯信念 serum 机制激励诚实和努力的回应。与替代方案相比，这种方法可能更好地利用了所有私人信息，并为被保险开发者提供了明确的信号，他们必须缓解什么风险以降低费用。作者建议将收取的费用用于资助开发人员所需的安全研究，并通过二次融资机制来诱导对这种公共物品的理想供应。
### Conclusion
建议使用二次融资机制将安全研究项目与私人贡献竞争，用以展示哪些项目应该由公共资金补充。
## 813. `cs.LG` - 流式扩散:一种实时互动生成的流水线级解决方案 [PDF](https://arxiv.org/pdf/2312.12491), [HTML](https://arxiv.org/abs/2312.12491)
### Authors
Akio Kodaira,Chenfeng Xu,Toshiki Hazama,Takanori Yoshimoto,Kohei Ohno,Shogo Mitsuhori,Soichi Sugano,Hanying Cho,Zhijian Liu,Masayoshi Tomizuka,Kurt Keutzer
### Background
现有的扩散模型能够从文本或图像提示生成高质量的图像，但在实时交互方面往往表现不佳。特别是在元宇宙、直播视频流和广播等需要高通量的应用场景中，这种局限性尤为明显。现有扩散管道中的无分类导向（CFG）方法会导致额外的U-Net计算量，增加了冗余。
### Innovation
提出了一种名为StreamBatch的新方法，将原始的顺序去噪过程转换为批量去除噪声过程，消除了传统的等待和交互方式，实现了流畅和高通量的流媒体。设计了一种新颖的输入输出队列，以并行化流处理过程，应对数据输入频率和模型吞吐量之间的差距。提出了一种新颖的残差无分类导向（RCFG）算法，减少了负条件去噪步骤的数量，最多减少到一个或零。引入了一个随机相似度过滤（SSF）算法，优化了能耗。
### Conclusion
通过提出的策略和现有的成熟加速工具，StreamBatch实现了在不同去噪级别时比顺序去噪方法快约1.5倍的速度。RCFG的提出将速度提高了高达2.05倍。结合提出的方法和AutoPipline的现有加速工具，使得图像到图像的生成在一块RTX4090上达到每秒91.07帧，提高了Diffusers开发的AutoPipline的通量59.56倍。此外，提出的流式扩散（StreamDiffusion）还分别在一块RTX3060和一块RTX4090上将能耗降低了2.39倍和1.99倍。
## 814. `cs.LG` - 当您第一次看到$a^2+b^2=c^2$时会问什么？评估LLM在好奇心驱动的提问方面的能力 [PDF](https://arxiv.org/pdf/2409.17172), [HTML](https://arxiv.org/abs/2409.17172)
### Authors
Shashidhar Reddy Javaji,Zining Zhu
### Background
大型语言模型（LLMs）能够存储大量的知识，但它们获取新知识的能力尚未被完全探索。本文提出了一种新的评估框架，该框架通过促使LLMs生成关于陈述的科学知识的问题，来评估它们获取新知识的能力。这种生成的问题模拟了面对新信息时的好奇个体。通过评分生成的问题的质量，从而评估LLMs的知识获取潜力。
### Innovation
本文提出了一种评估LLMs获取新知识能力的创新框架。该框架通过模拟好奇个体首次面对科学知识陈述时的提问方式，对LLMs进行评价。实验中使用了包含物理学、化学和数学多个领域的合成数据集，并进行了严密的消除实验以验证评分方法的有效性。此外，该研究还发现，虽然大型模型如GPT-4和Mistral 8x7b在生成连贯和相关的问题方面表现出色，但较小的Phi-2模型也同样或更加有效，表明模型大小并非决定其知识获取潜力的唯一因素。
### Conclusion
所提出框架量化了一个长期以来被忽视的重要模型能力，并为开发更知识渊博的AI系统提供了研究机会。
## 815. `cs.LG` - 使用深度强化学习在未知环境中进行多无人机追逃的在线规划 [PDF](https://arxiv.org/pdf/2409.15866), [HTML](https://arxiv.org/abs/2409.15866)
### Authors
Jiayu Chen,Chao Yu,Guosheng Li,Wenhao Tang,Shilong Ji,Xinyi Yang,Botian Xu,Huazhong Yang,Yu Wang
### Background
多无人机追逐-逃避问题对无人机群智能构成关键挑战。多智能体强化学习（MARL）在建模合作行为方面显示出潜力，但大多数基于强化学习（RL）的方法仍受限于简化且动态有限或固定场景的模拟。以前使用RL策略部署实际追逐-逃避的应用主要局限于二维场景，如地面车辆或固定高度的无人机。
### Innovation
本文通过考虑无人机动力学和物理约束来解决多无人机追逐-逃避问题。引入了预测增强网络以应对合作策略学习中的部分可观测性问题。还提出了一种适应性环境生成器，使MARL训练具有更高的探索效率和更好的策略泛化能力。实验表明，该方法在挑战性场景中显著超越所有基线，并在未见过的场景中实现100%的捕获率。最后，通过两阶段奖励优化，推导出可行策略，并以零样本方式部署在真实四旋翼上。据我们所知，这是在未知环境中通过集体推力和姿态速率控制命令推导和部署基于RL的策略的第一项工作。
### Conclusion
通过在线规划，使用深度强化学习在未知环境中实现了多无人机追逐-逃避，并首次通过集体推力和姿态速率控制命令推导和部署了基于RL的策略。
## 816. `cs.LG` - 熵稳定保守通量形式神经网络 [PDF](https://arxiv.org/pdf/2411.01746), [HTML](https://arxiv.org/abs/2411.01746)
### Authors
Lizuo Liu,Tongtong Li,Anne Gelb,Yoonsang Lee
### Background
本文构建了一种将经典数值守恒定律融入数据驱动框架中的熵稳定保守通量形式神经网络（CFN）。该方法主要利用熵稳定的、第二阶精度且非振荡的Kurganov-Tadmor（KT）方案来实现。熵稳定CFN使用斜率限制作为去噪机制，从而在噪声和稀疏观测环境以及光滑和不连续区域都能准确预测结果。
### Innovation
提出了熵稳定保守通量形式神经网络，并采用了熵稳定、第二阶精度及非振荡的Kurganov-Tadmor方案，结合斜率限制作为去噪机制。这种方法在长时间模拟中能保持稳定性与守恒性，并且即使缺乏后期时间剖面的先验知识也能准确预测激波传播速度，从而实现长时模拟.
### Conclusion
数值实验表明，熵稳定CFN在长时间区间内仍能保持稳定性和守恒性，同时具有高精度。方法能够准确预测激波传播速度，无需依赖训练数据后期时间剖面的先验知识。
## 817. `cs.LG` - 特征决定命运：高维回归中的迁移学习理论 [PDF](https://arxiv.org/pdf/2410.08194), [HTML](https://arxiv.org/abs/2410.08194)
### Authors
Javan Tahir,Surya Ganguli,Grant M. Rotskoff
### Background
随着大规模预训练神经网络的出现，适应这些“基础”模型以解决数据受限的下游任务的方法变得至关重要。当前方法，如微调、偏好优化和迁移学习，在目标任务接近源任务时已成功应用，但仍缺乏对“任务相似性”的精确理论理解。传统的观点认为简单的源和目标数据分布相似性度量，如φ距离或积分概率度量，可以直接预测迁移的成功率，但实际研究结果表明，这在一般情况下并非如此。本文采用以特征为中心的观点来研究迁移学习，并通过理论结果证明了当目标任务能够被预训练模型的特征空间很好地表示时，迁移学习优于从头开始训练。
### Innovation
本文提供了一种基于特征的视角来理解迁移学习，得出了在特征空间重叠较强时，线性迁移和微调都能提升性能的新发现，特别是在数据稀缺的情况下。这一成果建立在对深度线性网络特征学习动力学的逐渐理解之上，并且通过数值实验证实了线性模型中的结果同样适用于非线性网络。
### Conclusion
当源任务和目标任务的特征空间重叠足够强时，线性迁移和微调都能改善性能，特别是在数据稀缺的情况下。通过分析深层线性网络中转移学习的相图，本文为特征学习动力学提供了新的见解，并通过实验证明该结论不仅适用于线性网络，也适用于非线性网络。
## 818. `cs.LG` - 让坎迪：基于分数的扩散模型统一视图 [PDF](https://arxiv.org/pdf/2411.18702), [HTML](https://arxiv.org/abs/2411.18702)
### Authors
Chicago Y. Park,Michael T. McCann,Cristina Garcia-Cardona,Brendt Wohlberg,Ulugbek S. Kamilov
### Background
扩散模型近年来已成为生成现实合成信号的强大工具，特别是在生成自然图像方面。虽然这些算法往往非常简单，但背后的理论却非常复杂，并且文献中存在多种复杂的理论说明。本文旨在为信号处理社区提供一个简单的自包含理论解释，用于解释分数基于扩散模型。
### Innovation
本文提供了一种简洁的理论说明，仅依赖于少数几个“教科书”级的结果，用于几种影响深远的基于分数的扩散模型。提供了一种简化的方法来实现条件采样，而无需任何似然性近似。
### Conclusion
本文展示了几种有影响力的方法对应于这些模板中的特定选择，并表明替代的、更为直接的算法选择可以提供相当的结果。这种方法还具有启用条件采样的附加优势，而无需任何似然性近似。
## 819. `cs.LG` - LLMs是否具有先见之明？基于每日新闻的连续评估 [PDF](https://arxiv.org/pdf/2411.08324), [HTML](https://arxiv.org/abs/2411.08324)
### Authors
Hui Dai,Ryan Teehan,Mengye Ren
### Background
现有的大型语言模型评估基准由于新模型和训练数据的不断涌现而变得迅速过时，并且这些基准无法评估LLM随时间的性能变化，因为它们由静态的问题集组成，缺乏时间维度。现有的评估方法无法持续更新和评估LLM的性能变化，以此来应对这些挑战的不足之处。
### Innovation
本文提出了使用未来事件预测作为连续评估方法，评估LLM的跨时间泛化和预测能力。评估基准Daily Oracle通过自动从每日新闻生成问题-答案对来挑战LLM预测未来事件的结果。这种方法不仅让评估更加动态和全面，还揭示了预训练数据过时对LLM性能的影响，并指出RAG虽然可以提高预测准确性但不能阻止性能的持续下降，强调了持续更新模型的需求。
### Conclusion
我们的研究发现，随着预训练数据的过时，LLM的性能随着时间的推移而下降。尽管检索增强生成（RAG）能够提升预测准确性，但这种性能下降的趋势依然存在，因此需要持续更新模型以适应新的训练数据和挑战。相关代码和数据可从提供的链接中获得。
## 820. `cs.LG` - 预训练可逆生成作为无监督视觉特征学习 [PDF](https://arxiv.org/pdf/2412.01787), [HTML](https://arxiv.org/abs/2412.01787)
### Authors
Rongkun Xue,Jinouwen Zhang,Yazhe Niu,Dazhong Shen,Bingqi Ma,Yu Liu,Jing Yang
### Background
近期基于评分匹配和流匹配的生成模型在生成任务中取得了显著进展，但在判别任务中的潜力尚未充分开发。尽管存在生成分类器等以往方法，但它们未能充分利用这些模型构建判别任务所需的复杂度和功能。现有方法尚未全面发挥预训练生成模型在判别任务中的能力，主要原因在于这些模型复杂的设计使其难以融入现有的判别任务中。
### Innovation
本文提出了一种名为Pretrained Reversible Generation (PRG)的新方法。PRG通过逆转预训练连续生成模型的生成过程来提取无监督表示，从而有效重用这些生成模型，利用它们的强大特征提取能力来服务于下游任务。此框架允许根据特定任务选择特征层次结构，从而实现灵活的任务适应性。PRG在多个基准测试中表现出色，超越了之前的众多方法，并在包括ImageNet 64*64分辨率下达到78%的顶级准确率。此外，广泛的消融研究表明，PRG在处理此类任务时非常有效，特别是在分布外（out-of-distribution）评估中的表现得到了进一步验证。详情请参考此链接：this https URL
### Conclusion
本研究表明，通过利用预训练生成模型的高容量和灵活性，PRG在建立无监督特征表示方面具有显著优势，适用于多种下游任务并能实现卓越的性能。
## 821. `cs.LG` - 重新思考诱导头中的关联记忆机制 [PDF](https://arxiv.org/pdf/2412.11459), [HTML](https://arxiv.org/abs/2412.11459)
### Authors
Shuo Wang,Issei Sato
### Background
诱导头机制是计算电路的一部分，能使大语言模型（LLMs）在无需微调的情况下适应新任务。尽管现有工作已解释了如何获得这种强大的机制，但对于模型如何协调长上下文中的信息和预训练中获得的全局知识在下一个标记预测中仍然缺乏理解。本文从联想记忆的角度探讨双层变换器如何全面捕获上下文信息并将其与生成器模型生成的提示下的预训练双词知识进行平衡。
### Innovation
本文创新性地从联想记忆的角度分析了轮询器权重矩阵的表示及其结果的logits，并通过设计特定的提示来评估训练后的轮询器输出是否符合理论结果，以更好地理解和利用模型在基于上下文的学习过程中的机制。
### Conclusion
研究结果表明，双层变换器能有效地捕获和平衡上下文信息与预训练知识，为理解大语言模型在基于上下文学习中的工作机制提供了新的视角。
## 822. `cs.LG` - Transformer 模型在贝叶斯网络序列生成中模拟 MLE [PDF](https://arxiv.org/pdf/2501.02547), [HTML](https://arxiv.org/abs/2501.02547)
### Authors
Yuan Cao,Yihan He,Dennis Wu,Hong-Yu Chen,Jianqing Fan,Han Liu
### Background
变压器在处理各种领域中的序列数据（例如自然语言处理）任务方面取得了显著成功，但对其理论能力的理解仍然有限。本文探讨了基于上下文最大似然估计（MLE）的贝叶斯网络中自回归生成序列的变压器的理论能力。
### Innovation
本文提出了一种新方法，即利用变压器在贝叶斯网络中进行自回归序列生成的理论能力。具体来说，研究得出一种简单的变压器模型可以（i）根据上下文估计贝叶斯网络的条件概率；（ii）基于估计的条件概率自回归生成一个新的样本。通过大量实验进一步证明了该变压器不仅在理论上存在，而且还可以通过训练有效地获得。此分析强调了变压器学习复杂概率模型的潜力，并有助于更好地理解大语言模型作为强大序列生成器的能力。
### Conclusion
本文的研究结果表明，变压器可以在贝叶斯网络中模拟MLE进行序列生成，并且这一发现不仅在理论上有效，还能够在实践中通过训练实现。这对于理解大型语言模型作为强大的序列生成器具有重要意义。
## 823. `cs.LG` - AbdomenAtlas-8K: 在三周内对8,000个CT切片进行多器官分割标注 [PDF](https://arxiv.org/pdf/2305.09666), [HTML](https://arxiv.org/abs/2305.09666)
### Authors
Chongyu Qu,Tiezheng Zhang,Hualin Qiao,Jie Liu,Yucheng Tang,Alan Yuille,Zongwei Zhou
### Background
医学图像注释，尤其是器官分割，耗费大量人力和时间。例如，腹部器官注释估计需要30-60分钟每CT体积，具体取决于注释者的经验和器官的大小、可见性和复杂性。因此，公开的多器官分割数据集通常数据量有限、器官多样性不足。
### Innovation
提出了一种主动学习方法来加速器官分割的注释过程，并创建了迄今为止规模最大的多器官数据集，包含8,448个CT体积的脾脏、肝脏、肾脏、胃、胆囊、胰腺、主动脉和下腔静脉的标注，相当于320万片切片。常规注释方法会耗费资深注释者大约30.8年的时间，而本方法在三周内完成任务（基于每天8小时工作量，每周工作5天）并保持相似甚至更好的注释质量。这一成就得益于方法的三独特性：（1）使用多预训练分割模型减少标签偏差；（2）有效检测模型预测误差；（3）关注指导 注释者修改最关键错误。此外，总结了常见AI算法和注释者错误的分类学，以持续改进AI和注释，降低创建大规模数据集的成本，适用于更广泛医学成像任务
### Conclusion
该方法缩短了多器官分割数据集的标注时间，节省了大量时间成本，并提出了改进算法和注释的策略，未来可能进一步提高标注效率和质量。
## 824. `cs.LG` - 大型语言模型中演绎与归纳推理的作用 [PDF](https://arxiv.org/pdf/2410.02892), [HTML](https://arxiv.org/abs/2410.02892)
### Authors
Chengkun Cai,Xu Zhao,Haoliang Liu,Zhongyu Jiang,Tianfang Zhang,Zongkai Wu,Jenq-Neng Hwang,Lei Li
### Background
大型语言模型（LLMs）在推理任务中展现了惊人的能力，但它们依赖于静态提示结构和在复杂场景中的有限适应性仍然是一个重大挑战。本文分析了LLMs在推理方面现有的局限性和挑战，指出需要发展能够动态结合演绎和归纳推理的新框架，以提高模型在复杂任务中的适应性和性能。
### Innovation
提出了一种名为DID（Deductive and Inductive Deduction）的新框架，该框架结合了演绎和归纳推理方法，采用来自认知科学的原则，通过结合Littlestone维度和信息熵来精准评估任务难度和指导分解策略。DID使模型能够根据问题复杂度逐步适应其推理路径，从而模拟人类的认知过程。通过多个基准测试（包括AIW和MR-GSM8K），验证了DID的有效性和效率。结果显示，DID在推理质量和解题准确性上取得了显著提升，并且相比现有方法具有较低的计算成本。
### Conclusion
研究结果表明，DID在提高LLM性能的同时保持了较低的计算成本，为开发更符合认知规律的、更具能力的语言模型提供了方向。本文贡献了一种理论基础的支持、基于输入的方法来增强LLM推理能力，为替代传统输出探索方法提供了高效选择。
## 825. `cs.LG` - 在细粒度时间尺度上使用贝塔声誉提高人类-机器人协作中的信任估计 [PDF](https://arxiv.org/pdf/2411.01866), [HTML](https://arxiv.org/abs/2411.01866)
### Authors
Resul Dagdanov,Milan Andrejevic,Dikai Liu,Chin-Teng Lin
### Background
人类在互动中根据感知到的信任调整行为。为了实现类似的人适应性，机器人必须在与人类协作过程中准确估计信任，并在足够细粒度的时间尺度上更新这些估计。目前主流的方法是使用贝塔声誉来量化人类信任，但这依赖于二元性能调优，仅在每个任务完成后更新信任估计。此外，通常需要手动构建奖励函数来构建性能指标，这既费时又费力。这些限制阻碍了对细粒度协作任务过程中连续信任变化的高效捕获。因此，本文提出了一种新的框架，用于在细粒度时间尺度上使用贝塔声誉估计人类信任。为了细化贝塔声誉，我们使用连续的奖励值在任务的每个时间步更新信任估计。我们使用最大熵优化构建连续的奖励函数，以消除对性能指标的繁琐规定需求。该提出的框架通过提高准确性、消除手动构建奖励函数的需求以及促进更智能的机器人的发展而改进了信任估计。
### Innovation
本文提出的框架在细粒度时间尺度上使用贝塔声誉估计人类信任，通过使用连续的奖励值在每个任务时间步更新信任估计。文中使用最大熵优化构建连续的奖励函数，从而消除了对性能指标的手动规定需求。这些改进提高了信任估计的准确性，并促进了机器人技术的进步。
### Conclusion
本文提出了一种新的框架，通过在细粒度时间尺度上使用贝塔声誉估计人类信任，提高了信任估计的准确性，消除了手动构建奖励函数的需求，并为开发更智能的机器人奠定了基础。
## 826. `cs.LG` - Tractable Transformers for Flexible Conditional Generation [PDF](https://arxiv.org/pdf/2502.07616), [HTML](https://arxiv.org/abs/2502.07616)
### Authors
Anji Liu,Xuejie Liu,Dayuan Zhao,Mathias Niepert,Yitao Liang,Guy Van den Broeck
### Background
非自回归生成模型（NAR）通过更合理的方式处理多样化的条件生成任务，相较于自回归模型（AR），它们不受序列相关性的限制。最近在非自回归模型（如扩散语言模型）方面的进展表明，在相似规模下，它们在无条件生成上的表现优于自回归模型（如GPT）。然而，这种性能改进并不总是反映在条件生成性能上。原因之一是，现有模型对于训练过程中未见过的条件概率查询（即未知变量集）难以泛化，因此强大的无条件生成性能并不能保证高质量的条件生成性能。
### Innovation
本文提出了Tractable Transformers（Tracformer），这是一种基于Transformer的生成模型，能够更稳健地应对不同的条件生成任务。Tracformers不同于现有的仅依赖于完整输入提取的全局上下文特征的模型，而是引入稀疏Transformer编码器来捕捉局部和全局上下文信息，并通过解码器用于条件生成。这种方法实现了在文本建模任务上相对于最近的扩散模型和自回归模型基线的最优条件生成性能。
### Conclusion
实验结果表明，Tractable Transformers在文本建模任务上的条件生成性能达到了最新标准。
## 827. `cs.LG` - AI故障责任与保险: 核能领域的先例及其对人工智能的启示 [PDF](https://arxiv.org/pdf/2409.06673), [HTML](https://arxiv.org/abs/2409.06673)
### Authors
Cristian Trout
### Background
随着人工智能系统变得更加自主且能力增强，专家警告称它们可能会导致灾难性的损失。本文通过借鉴核能行业成功的先例，探讨为关键人工智能事件（CAIOs，可能导致或本可导致灾难性损失的事件）造成的损害，将有限、严格的第三方责任强制分配给前沿AI模型开发者的可能性。建议通过强制保险来解决开发者难以通过诉讼获得赔偿的问题，减少“赢家诅咒”效应，并利用保险公司的准监管能力。
### Innovation
本文提出了将核能领域成功的责任和保险机制应用于人工智能领域的创新性观点，具体包括：建议为AI关键事件造成的损害引入有限、严格的第三方责任；推荐强制保险来应对开发者在诉讼中的“难以通过诉讼获得赔偿”的问题，遏制“赢家诅咒”效应，并利用保险公司的准监管能力。预计保险公司将通过因果风险建模、监控、游说实施更严格的监管以及提供防范损失的建议来应对AI造成的极端风险。
### Conclusion
虽然这种责任分配和强制保险机制不是替代监管措施的解决方案，但它可以有效地将资源分配给风险建模和安全设计，从而有助于未来的监管努力。
## 828. `cs.LG` - 使用神经网络推断高阶耦合 [PDF](https://arxiv.org/pdf/2501.06108), [HTML](https://arxiv.org/abs/2501.06108)
### Authors
Aurélien Decelle,Alfonso de Jesús Navas Gómez,Beatriz Seoane
### Background
最大熵方法起源于统计物理中的逆伊辛/泊塔斯问题，被广泛用于跨生物信息学和神经科学等学科建模复杂系统的成对相互作用。尽管这些方法取得了一定成功，但它们往往无法捕捉到理解集体行为至关重要的高阶相互作用。相比之下，现代机器学习方法可以建模这些高阶相互作用，但代价是解释性差且计算成本高昂。受限玻尔兹曼机（RBM）通过在二部架构中的隐藏单元中编码统计相关性，提供了一种计算效率更高的替代方案。基于这项工作，我们介绍了将RBM映射到广义泊塔斯模型的方法，使得可以系统地提取任意阶次的交互。借助RBM结构使得计算变得可行的大-$N$近似，我们以最小的计算努力提取了有效多体耦合。我们还提出了一种用于在更复杂的生成模型中恢复高阶相互作用的稳健框架，并引入了一个简单有效的泊塔斯表示的固定方案。在合成数据上的验证显示，可以准确恢复二阶和三阶相互作用。应用于蛋白质序列数据时，我们的方法可以高保真地重建接触图，并优于最先进的逆泊塔斯模型。
### Innovation
我们将RBM映射到广义泊塔斯模型，以系统地提取高阶交互。通过RBM结构使得计算变得可行的大-$N$近似，以最小的计算努力提取了有效多体耦合。提出了用于恢复复杂生成模型中高阶交互的稳健框架，并引入了简单的泊塔斯表示固定方案。
### Conclusion
我们的结果证明RBM是高维分类数据中高阶结构建模的强大且高效的工具。
## 829. `cs.LG` - 通过熵风险度量实现高效的风险敏感规划 [PDF](https://arxiv.org/pdf/2502.20423), [HTML](https://arxiv.org/abs/2502.20423)
### Authors
Alexandre Marthe(ENS de Lyon, UMPA-ENSL),Samuel Bounan,Aurélien Garivier(UMPA-ENSL, MC2),Claire Vernade
### Background
风险敏感规划的目标是在马尔可夫决策过程（MDPs）中寻找最大化某些关注尾部的风险度量的策略。然而，传统的阈值概率或条件风险值等高度可解释的风险度量的优化任务可能非常耗时。先前的研究表明，只有熵风险度量（EntRM）可以通过动态规划有效地优化，但其背后不易解释的参数选择问题依然存在。本文通过计算整个参数值下的最优政策集，实现了目标度量的紧密近似。
### Innovation
本文提出了一种新颖的结构分析方法和熵风险的光滑性质，以有效计算出整个参数下的最优政策集，从而为感兴趣的度量提供了紧密的近似值。这种方法避免了传统方法中的解释性问题，为风险敏感规划提供了更优的解决方案。
### Conclusion
实验证明，本方法在多种决策场景中均表现出强大的性能。
## 830. `cs.LG` - MEIT: 多模态心电图指令调谐在大型语言模型生成报告中的应用 [PDF](https://arxiv.org/pdf/2403.04945), [HTML](https://arxiv.org/abs/2403.04945)
### Authors
Zhongwei Wan,Che Liu,Xin Wang,Chaofan Tao,Hui Shen,Jing Xiong,Rossella Arcucci,Huaxiu Yao,Mi Zhang
### Background
心电图（ECG）是监测心脏状况的主要非侵入式诊断工具，对于协助临床工作者至关重要。尽管近年来的研究集中于使用ECG数据分类心脏状况，但ECG报告的生成却被忽视，它是耗时且需要临床专家知识的任务。
### Innovation
本文提出了多模态ECG指令调谐(MEIT)框架，这是首次尝试使用大型语言模型(LLMs)和多模态指令进行ECG报告生成的研究。为了促进未来的研究，我们还建立了一个基准，使用多种LLM骨干对MEIT在两个大规模ECG数据集上的表现进行了评估。我们独特的将ECG信号和报告的表示进行对齐，并通过超过80万份ECG报告对MEIT进行了广泛的实验，使用了9个开源LLM。MEIT的结果证明了指令调整的LLMs在质量报告生成、零样本能力、信号扰动下的鲁棒性以及与人类专家评估的一致性方面表现优异。
### Conclusion
这些发现强调了MEIT的有效性及其在实际临床应用中的潜力。
## 831. `cs.LG` - 提示编程对函数级代码生成的影响 [PDF](https://arxiv.org/pdf/2412.20545), [HTML](https://arxiv.org/abs/2412.20545)
### Authors
Ranim Khojah,Francisco Gomes de Oliveira Neto,Mazen Mohamad,Philipp Leitner
### Background
大型语言模型（LLMs）被软件工程师广泛用于代码生成。尽管这些模型在增加效率方面表现出色，但生成的代码存在与上下文无关或错误的问题，这揭示了提示编程（或提示工程）的重要性。在提示编程中，工程师通过应用特定的提示技术（如思维链、输入-输出示例等）来优化生成的代码。尽管有某些提示技术的研究，但不同技术及其相互作用对代码生成的影响尚未完全清楚。
### Innovation
该研究引入了一个包含7072个提示的CodePromptEval数据集，用于评估五种提示技术（少量示例、角色、思维链、函数签名、包列表）对三个LLMs（GPT-4o、Llama3、Mistral）生成的完整函数的正确性、相似性和质量的影响。研究发现，虽然某些提示技术显著影响生成的代码，但组合使用多种技术不一定能改善结果。此外，研究观察到在使用提示技术时正确性和质量之间的权衡。
### Conclusion
CodePromptEval数据集和复现包将促进未来对提高LLM生成代码的研究以及评估新提示技术。
## 832. `cs.LG` - 基于FPGA的运行时自适应变压器神经网络加速器 [PDF](https://arxiv.org/pdf/2411.18148), [HTML](https://arxiv.org/abs/2411.18148)
### Authors
Ehsan Kabir,Austin R.J. Downey,Jason D. Bakos,David Andrews,Miaoqing Huang
### Background
变压器神经网络（TNN）在自然语言处理（NLP）、机器翻译和计算机视觉（CV）任务中表现出色，但它们计算和内存需求高，特别是在资源受限的设备如FPGA上，且不同的变压器模型在不同应用中的处理时间存在差异。为每个模型设计专用加速器复杂且耗时。目前存在一些专用加速器，但缺乏运行时适应能力，且通常依赖稀疏矩阵来降低延迟，但由于应用特定的稀疏模式，硬件设计更加复杂。
### Innovation
本文提出了ADAPTOR，一种在FPGA上用于变压器编码器和解码器的运行时自适应加速器。ADAPTOR提升了处理单元和片上内存的利用率，增强了并行性并减少了延迟。它包含了高效的矩阵切片以在FPGA平台上分配资源，并完全量化以提高计算效率和可移植性。实验结果表明，该设计在能耗和速度上都优于NVIDIA K80 GPU和i7-8700K CPU，且比一些最先进的FPGA加速器有1.7至2.25倍的速度提升。
### Conclusion
ADAPTOR显著提升了一般Transformer神经网络在FPGA上的算法效率，具有较低的能耗并提供运行时的自适应性，展示了它在实际应用中的部署潜力。
## 833. `cs.LG` - 通过质荷排斥最优传输的无监督异常检测 [PDF](https://arxiv.org/pdf/2502.12793), [HTML](https://arxiv.org/abs/2502.12793)
### Authors
Eduardo Fernandes Montesuma,Adel El Habazi,Fred Ngole Mboula
### Background
检测数据集中的异常是机器学习中的一个长期存在的问题。在这种情况下，异常被定义为与剩余数据显著不同的样本。同时，最优传输（OT）是数学领域中关注两个概率测度之间最小化成本的运输问题。在经典OT中，一个测度自身最优的传输策略是恒等映射。在这个背景下，本文通过迫使样本使其质量转移，并保持最小化成本目标，来解决异常检测问题。质荷排斥最优传输（MROT）恰好满足这一需求，使得数据集中较低密度区域的样本会因需要转移更大的质量而产生更高的传输费用。
### Innovation
本文提出了一种新的传输问题——Mass Repulsing Optimal Transport（MROT），该方法通过将样本质量移出数据集内部并保持最小化传输成本，来提高异常检测性能。利用MROT提出的新型异常评分机制，实验结果显示该算法在现有的基准测试和故障检测问题中优于现有方法。
### Conclusion
通过对现有基准测试和故障检测问题进行一系列实验，本文展示了新的MROT算法在无监督异常检测任务中优于现有方法，这一改进是通过将样本质量从低密度区域排斥并保持最小化传输成本来实现的。
## 834. `cs.LG` - 视觉适应性提示技术在组合零样本学习中的应用 [PDF](https://arxiv.org/pdf/2502.20292), [HTML](https://arxiv.org/abs/2502.20292)
### Authors
Kyle Stein,Arash Mahyari,Guillermo Francia,Eman El-Sheikh
### Background
视觉-语言模型（VLMs）已经在多模态任务中展示了惊人的能力，特别是在学习视觉和文本数据的联合表示上，并且它们是组合零样本学习（CZSL）任务的强大工具。CZSL要求模型在训练过程中未直接遇到的新视觉原语（如属性和对象）组合中进行泛化。现有工作集中在修改文本编码器的输入，通常使用静态提示，但这方法难以捕捉变化的视觉上下文，因为它们主要关注文本调整而不是利用视觉特征进行组合推理。因此，需要一种新的方法来解决这些问题。
### Innovation
本文提出了一种视觉适应提示系统（VAPS），利用可学习的视觉提示库和相似度检索机制，在VLM框架内桥梁连接语义和视觉特征。关键创新在于动态视觉提示库机制，根据图片的视觉特征选择最相关的属性和对象提示，并包含一个视觉提示适配器，以鼓励模型学习更具泛化能力的嵌入空间。我们已经通过多个CZSL基准测试，涵盖了封闭和开放世界场景，得到了优秀的结果。
### Conclusion
实验结果表明，该提出的方法在三个CZSL基准上取得了最先进的性能。该研究提出了一个动态选择最相关视觉提示的视觉适应提示系统，能够更好地利用模型的视觉特征来进行组合推理，从而提高了组合零样本学习的效果。
## 835. `cs.LG` - 一种集成大型语言模型的级联协作多智能体框架用于匝道并流控制 [PDF](https://arxiv.org/pdf/2503.08199), [HTML](https://arxiv.org/abs/2503.08199)
### Authors
Miao Zhang,Zhenlong Fang,Tianyi Wang,Qian Zhang,Shuai Lu,Junfeng Jiao,Tianyu Shi
### Background
传统强化学习（RL）在复制人类行为、在多智能体场景中有效泛化以及克服内在的可解释性问题方面存在局限。当需要深刻理解环境、智能体协调和动态优化时，这些困难更加复杂。虽然增强型的大语言模型（LLM）在泛化和互操作性方面表现出潜力，但它们经常忽视了必要的多智能体协调。因此，提出了一种级联协作多智能体（CCMA）框架，该框架结合了用于个体互动的RL、精细调整的LLM以支持区域合作、用于全球优化的奖励函数以及检索增强的生成机制，以在复杂驾驶场景中动态优化决策过程。
### Innovation
引入了级联协作多智能体（CCMA）框架，该框架结合了用于个体互动的RL、精细调整的LLM以支持区域合作、用于全球优化的奖励函数以及检索增强的生成机制，从而在复杂驾驶场景中动态优化决策过程。这解决了传统RL在多智能体协调中的不足和大语言模型忽视必要协调的问题，展示了在微观和宏观层面显著的性能提升。
### Conclusion
实验结果表明，CCMA框架在复杂驾驶环境中优于现有的RL方法，在微观和宏观性能上都表现出显著的提升。
## 836. `cs.LG` - 为年轻数字公民的伦理人工智能：隐私治理的呼吁 [PDF](https://arxiv.org/pdf/2503.11947), [HTML](https://arxiv.org/abs/2503.11947)
### Authors
Austin Shouli,Ankur Barthwal,Molly Campbell,Ajay Kumar Shrestha
### Background
随着青年使用的数字平台中人工智能（AI）的迅速扩张，隐私、自主权和数据保护方面面临着重大挑战。尽管基于AI的个性化服务能够提升用户体验，但通常缺乏明确的道德界限，容易使年轻用户成为数据滥用和算法偏见的牺牲品。
### Innovation
本文提出了对于伦理AI治理的呼唤，倡导构建一个以青少年为中心的隐私保护结构化框架，透明的数据实践和监管审查。文章指出需要紧急介入的关键领域，包括算法透明度、隐私教育、家长与数字数据分享的道德标准以及问责机制。
### Conclusion
通过这种方法，作者希望赋予青年更多控制其数字身份的权利，并提议为政策制定者、AI开发者和教育者制定具体策略，以构建一个更加公平和负责任的AI生态系统。
## 837. `cs.LG` - MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation [PDF](https://arxiv.org/pdf/2502.12632), [HTML](https://arxiv.org/abs/2502.12632)
### Authors
Sihyun Yu,Meera Hahn,Dan Kondratyuk,Jinwoo Shin,Agrim Gupta,José Lezama,Irfan Essa,David Ross,Jonathan Huang
### Background
扩散模型在合成高质量视频方面表现优异，但目前仅限于生成短片段视频（例如，2-10秒），对于生成长时间视频（如几分钟）而言仍是一个待解决的研究问题。因此，本文提出了MALT扩散模型（使用记忆增强的潜在转换器），专门用于生成长视频。
### Innovation
本文创新性地引入了复发注意层，将多个片段编码到一个紧凑的记忆潜在向量中，并通过时间维的保持该记忆向量，使得MALT能够在长时序上下文中继续生成新的视频片段。同时，还提出了几种训练技术，以使模型能够在长时间范围内生成高质量的帧并实现最小的降级。
### Conclusion
通过在长期视频基准上的实验验证了MALT的有效性。在长时间上下文理解和稳定性方面，MALT在UCF-101数据集上128帧视频生成上的FVD评分为220.4，优于之前的最先进技术648.4。此外，还探索了MALT在文本到视频生成中的应用，结果显示它比其他长时间文本到视频生成的方法具有生成更长视频的能力。
## 838. `cs.LG` - 当联邦学习遇到量子计算：综述与研究机会 [PDF](https://arxiv.org/pdf/2504.08814), [HTML](https://arxiv.org/abs/2504.08814)
### Authors
Aakar Mathur,Ashish Gupta,Sajal K. Das
### Background
联邦学习（FL）是一种高效的分布式机器学习方法，但其可扩展性和效率受到限制。量子计算（QC）的发展为解决这些限制提供了可能。量子联邦学习（QFL）利用量子计算的进步来改进分布式联邦学习模型的可扩展性和效率，通过研究量子技术和联邦学习的结合，提出了新的问题和解决方案，重点关注量子和联邦学习的局限性，如架构、Noisy Intermediate Scale Quantum（NISQ）设备以及隐私保护等方面。
### Innovation
本文系统而全面地探讨了量子计算与联邦学习交汇时出现的新问题和解决方案，重点在于综合介绍混合量子经典方法的关键发展和整合策略，并探讨了量子计算如何影响联邦学习，特别突出了量子增强的梯度隐藏、量子纠缠态、量子密钥分发、量子安全性及量子增强的差分隐私等优势如何融入联邦学习以增强框架的安全性、效率和隐私保护。
### Conclusion
研究提出了可能的未来发展方向，以填补研究空白和挑战，旨在激发更快和更安全的量子联邦学习模型的实际应用。
## 839. `cs.LG` - 像测试一样过滤：数据驱动的数据过滤用于CLIP预训练 [PDF](https://arxiv.org/pdf/2503.08805), [HTML](https://arxiv.org/abs/2503.08805)
### Authors
Mikey Shechter,Yair Carmon
### Background
介绍了Filter Like You Test (FLYT)算法，这是一种用于大规模视觉-语言数据集的编目算法。FLYT算法通过学习每个数据点作为预训练示例的有效性，来构建数据集。在此基础上，提出了Mixing-FLYT (M-FLYT)算法，它将不同评分方法生成的每例评分作为特征，并学习将这些评分统一成单一评分。FLYT生成了训练示例的分布，通过Soft Cap Sampling (SCS)策略，从每例概率中获取过滤后的预训练数据集，在防止示例重复的同时进行采样。最终，作者通过这些方法实现了在DataComp中等规模过滤基准测试上的40.1% ImageNet零样本准确率，比之前所有结果提高了2%的绝对准确率，并且比使用类似公共资源的其他结果高出了5.5%。此外，作者的这种方法在38个DataComp评估任务上的平均准确率达到了37.7%，超越了之前仅使用公共资源的所有方法0.4%的准确率。
### Innovation
FLYT通过学习每个示例作为预训练样本的有效性来生成评分模型，使用来自下游任务训练集的梯度信号来加权每个示例的特征。M-FLYT则进一步将不同评分方法生成的每例评分统一成单一评分。Soft Cap Sampling (SCS)策略通过使用重复惩罚来防止样本过代表，从而从每例概率中获取过滤后的预训练数据集。
### Conclusion
在DataComp中等规模过滤基准测试中，FLYT和M-FLYT方法取得了40.1%的ImageNet零样本准确率，比之前所有结果提高了2%的绝对准确率，并且比使用类似公共资源的其他结果高出了5.5%。这种方法在38个DataComp评估任务上的平均准确率达到了37.7%，比以往使用公共资源的方法高出了0.4%的准确率。
## 840. `cs.LG` - 通过显式知识边界建模提升大语言模型可靠性 [PDF](https://arxiv.org/pdf/2503.02233), [HTML](https://arxiv.org/abs/2503.02233)
### Authors
Hang Zheng,Hongshen Xu,Yuncong Liu,Lu Chen,Pascale Fung,Kai Yu
### Background
大语言模型（LLMs）容易因自我意识错位而产生幻觉，尤其是在处理超出其知识边界的问题时更为明显。现有的缓解策略通过不确定性估计或查询拒绝机制来应对，但这些方法在计算效率和有用性方面存在不足。
### Innovation
提出了显式知识边界建模（EKBM）框架，该框架通过结合快速和慢速推理系统，实现可靠性和可用性的平衡。首先，使用快速推理模型生成带有信心标记的回答，使高信心输出能立即使用。不确定的预测则触发慢速精炼模型以提高准确性。同时，提出了混合训练管线，增强了模型的自我意识而不降低任务性能。
### Conclusion
EKBM评估表明，它在对话状态跟踪任务中优于基于不确定性的基线模型。进一步分析显示，精炼显著提高了准确性，同时保持了较低的计算成本。该框架为在易出错的应用中部署可靠的LLMs提供了一个可扩展的范式，有效平衡了准确性和实际用途。
## 841. `cs.LG` - 量子QSAR在药物发现中的应用 [PDF](https://arxiv.org/pdf/2505.04648), [HTML](https://arxiv.org/abs/2505.04648)
### Authors
Alejandro Giraldo,Daniel Ruiz,Mariano Caruso,Guido Bellomo
### Background
定量结构-活性关系（QSAR）建模在药物发现中至关重要，然而传统的QSAR方法在处理高维度数据和捕捉复杂分子互动时存在局限性。
### Innovation
本文提出通过量子支持向量机（QSVMs）来提升QSAR技术，利用量子计算原理在希尔伯特空间中处理信息。使用量子数据编码和量子核函数，旨在开发更为准确和高效的预测模型。
### Conclusion
通过量子QSAR模型，有望克服传统QSAR方法的局限，实现药物发现中的更高效和准确的预测建模。
## 842. `cs.LG` - GC-GAT：基于图目标条件和跨上下文注意力的多模态车辆轨迹预测 [PDF](https://arxiv.org/pdf/2504.11150), [HTML](https://arxiv.org/abs/2504.11150)
### Authors
Mahir Gulzar,Yar Muhammad,Naveed Muhammad
### Background
要准确预测周围车辆的未来轨迹，需要提供某些上下文信息给运动预测模型。上下文信息可以是静态的（如车道、交通标志等）或动态的（如交通参与者）。本文提出了一种基于车道图的运动预测模型，首先预测图基目标提案，然后通过多个上下文元素之间的交叉注意机制进行融合。
### Innovation
本文模型采用了基于图的目标条件（GC）和跨上下文注意力的多模态车辆轨迹预测方法，通过轻量级门控循环单元编码场景上下文，然后通过交互器跨上下文注意力机制对编码场景特征和图目标提案进行处理，最后通过拉普拉斯混合密度网络回归多模态轨迹。该方法能够更加稳健地预测未来轨迹，因为它学习关注未来与目标相关的重要场景元素。
### Conclusion
本文方法在nuScenes运动预测数据集上进行了评估，达到了目前最先进的结果。
## 843. `cs.LG` - GMLM：连接图神经网络和语言模型以进行异质节点分类 [PDF](https://arxiv.org/pdf/2503.05763), [HTML](https://arxiv.org/abs/2503.05763)
### Authors
Aarush Sinha
### Background
异质节点分类中，集成结构化图数据与丰富文本信息存在显著挑战，尤其是对于异质节点分类。现有方法在计算成本或不同模态的有效融合上往往存在不足。
### Innovation
- 引入了动态活跃节点选择策略，以实现可控的PLM文本处理；- 提出了基于软掩码和可学习图[MASK]标记的GNN特定对比预训练阶段，以实现稳健的结构表示；- 设计了专门的融合模块，将基于RGCN的GNN嵌入与PLM（GTE-Small & DistilBERT）嵌入进行整合。
### Conclusion
在异质节点分类基准（Cornell, Wisconsin, Texas）上进行的广泛实验表明了GMLM的优势。特别是GMLM（DistilBERT）在Cornell和Texas上的准确率分别提高了4.7%和2.0%，超过了之前的最佳基线。这项工作强调了目标导向的PLM参与和模态特定预训练对提高和效率提升的重要性。
## 844. `cs.LG` - KD$^{2}$M：一种统一的特征知识蒸馏框架 [PDF](https://arxiv.org/pdf/2504.01757), [HTML](https://arxiv.org/abs/2504.01757)
### Authors
Eduardo Fernandes Montesuma
### Background
知识蒸馏（KD）旨在将教师模型的知识转移到学生神经网络中。传统的做法是通过匹配两个网络的预测结果（即输出），但这一过程最近有研究表明，匹配神经网络的激活分布（即特征）可能更为有效，这种方法被称为‘分布匹配’。
### Innovation
本文提出了一种统一框架，名为KD$^{2}$M（即Knowledge Distillation through Distribution Matching），它归纳了分布匹配中使用的各种度量标准，并通过在计算机视觉数据集上的基准测试和理论结果推导，展示了其优势。
### Conclusion
本文贡献了三个方面：（i）概述了分布匹配过程中使用的各个度量标准；（ii）在计算机视觉数据集上进行了基准测试；（iii）推导出了新的理论结果，为KD提供了更深入的理解。
## 845. `cs.LG` - MAMUT：一种用于生成语言模型训练专用数据集的新型数学公式修改框架 [PDF](https://arxiv.org/pdf/2502.20855), [HTML](https://arxiv.org/abs/2502.20855)
### Authors
Jonathan Drechsel,Anja Reusch,Steffen Herbold
### Background
数学公式是各种科学领域中基础且广泛使用的重要组成部分，用于表达复杂概念和关系。尽管最先进的变压器模型在处理和理解自然语言方面表现出色，但在处理和理解数学符号时却遇到了挑战，因为数学符号具有复杂结构和多样的表示形式。
### Innovation
介绍了Math Mutator (MAMUT)框架，该框架能够生成给定数学公式的等效版本和伪造版本，有效捕捉相同概念在不同表示形式中的数学多样性。基于MAMUT，生成了四个包含多样化表示形式的大规模数学数据集。实验表明，这些数据集训练的模型在数学检索任务上表现出新的最佳性能。
### Conclusion
我们在GitHub上发布了我们的代码、生成的数据集和预训练的数学模型：this https URL。
## 846. `cs.LG` - Thompson采样的反事实推理 [PDF](https://arxiv.org/pdf/2504.08773), [HTML](https://arxiv.org/abs/2504.08773)
### Authors
Olivier Jeunen
### Background
推荐系统通过在不确定性的环境中进行串行决策来决定向用户展示什么样的内容，以优化不同目标。为了成功解决探索-利用权衡，Thompson采样提供了一种自然且广泛应用的概率选择行动的方法。然而，在这种情境中，因果和反事实推理的问题，在线下评估等场景中的应用并不直观，尤其是大多数现有的估算器依赖于行动倾向，但在Thompson采样的过程中这些是不可轻易获得的。因此需要方法能够精确且高效地计算各种参数和结果分布下的行动倾向，使得倒政策估算器能在Thompson采样场景中使用，从而解决了这一问题，拓宽了反事实推理的实际应用场景，比如推荐系统无偏的线下评估，以及在线广告、个性化等因果推理的一般应用领域。
### Innovation
作者推导出了Thompson采样场景中各种参数和结果分布下的精确且高效的行动倾向表达式，允许使用倒政策估计器来解决因果和反事实推理问题。这种方法显著扩展了反事实推理的实际应用场景，包括推荐系统的无偏线下评估，以及在线广告、个性化等领域的因果推理应用。
### Conclusion
研究通过精确高效的计算行动倾向表达式，使得反事实推理在Thompson采样场景下成为可能，这不仅解决了现有技术无法解决的问题，还为实际应用场景提供了新的方法，提高了决策的准确性和效果。
## 847. `cs.LG` - 独立记分牌模型的实证验证 [PDF](https://arxiv.org/pdf/2506.00180), [HTML](https://arxiv.org/abs/2506.00180)
### Authors
Juho Kim
### Background
独立记分牌模型（ICM）是现代扑克锦标赛策略的基础。尽管ICM在理论和实践上都很重要，但在现实世界中的表现，特别是在大规模应用中的表现，还没有得到充分的审查和验证。因此，本文旨在通过对超过一万场扑克锦标赛的结果进行研究，来实证验证ICM的准确性和适用性。
### Innovation
本文的创新之处在于引入了一个新的扑克锦标赛数据集，并通过大规模的实证研究来验证ICM的准确性。实证研究包括两部分：首先，验证ICM比所提出的基线模型更有准确性；其次，证明ICM低估了大底牌玩家的表现，而高估了小底牌玩家的表现。
### Conclusion
本文的研究结果表明了ICM在评估玩家在扑克锦标赛中的表现时的局限性，并为未来研究开发新的算法来估计玩家的价值提供了有用的数据和见解。
## 848. `cs.LG` - Embedding Atlas: 低摩擦、互动式嵌入可视化 [PDF](https://arxiv.org/pdf/2505.06386), [HTML](https://arxiv.org/abs/2505.06386)
### Authors
Donghao Ren,Fred Hohman,Halden Lin,Dominik Moritz
### Background
嵌入投影在可视化大规模数据集和模型方面非常流行。然而，人们在使用嵌入可视化工具时常常会遇到“摩擦”，主要体现在两个方面：（1）采用障碍，例如繁琐的数据清洗和加载任务、处理规模的限制、结果与现有工作流程的不集成；（2）分析能力的局限性，缺乏与外部工具集成来展示元数据的协调视图。
### Innovation
本文介绍了一款名为 Embedding Atlas 的可扩展、互动式可视化工具，旨在让用户能够尽可能轻松地与大规模嵌入进行交互。Embedding Atlas 使用现代 web 技术和先进的算法（包括基于密度的聚类和自动标签化），提供了大规模环境下快速且丰富的数据分析体验。我们通过与其他流行的嵌入工具进行竞争性分析，证明了 Embedding Atlas 的功能集特别有助于减少摩擦，并报告了其实时渲染性能的基准测试结果，显示了其在数百万点集上的表现。
### Conclusion
Embedding Atlas 是开源软件，旨在支持嵌入式分析的未来工作。
## 849. `cs.LG` - 特征提取与引导以增强语言模型的链式思考推理能力 [PDF](https://arxiv.org/pdf/2505.15634), [HTML](https://arxiv.org/abs/2505.15634)
### Authors
Zihao Li,Xu Wang,Yuzhe Yang,Ziyu Yao,Haoyi Xiong,Mengnan Du
### Background
大型语言模型（LLMs）能够利用链式思考（CoT）技术解决推理和数学问题。DeepSeek-R1等模型通过延长CoT链的长度，显著提升了复杂问题的推理能力，但这也需要大量高质量的长CoT数据和精细调整，成本较高。许多现有的LLMs缺乏对应的预训练稀疏自编码器（SAEs），这限制了增强其推理能力的方法的选择和应用效果.
### Innovation
本文受DeepSeek-R1深层次思考机制的启发，提出了一种无需外部数据集的引导技术，增强了LLMs的推理能力。首先利用稀疏自编码器（SAEs）从原始的CoT中提取可解释的特征，并利用这些特征引导LLMs生成时的内部状态。对于没有预训练SAEs的LLMs，进一步提出了一种全新的SAE-free引导算法，直接从LLMs的残差激活计算引导方向，无需显式使用SAEs。实验结果表明，这两种方法均显著增强了LLMs的推理能力.
### Conclusion
这两种方法——基于SAEs的引导和无SAE的引导——成功地增强了LLMs的链式思考推理能力，无需额外的外部数据集，降低了增强LLMs推理能力的成本和所需的数据质量要求。
## 850. `cs.LG` - VolleyBots: 一种结合运动控制与战略博弈的多无人机排球游戏测试平台 [PDF](https://arxiv.org/pdf/2502.01932), [HTML](https://arxiv.org/abs/2502.01932)
### Authors
Zelai Xu,Ruize Zhang,Chao Yu,Huining Yuan,Xiangmin Yi,Shilong Ji,Chuqi Wang,Wenhao Tang,Feng Gao,Wenbo Ding,Xinlei Chen,Yu Wang
### Background
机器人运动以其明确的目标、明确的规则和动态互动为特点，为展示实体智能提供了理想的场景。本论文研究了一种名为VolleyBots的多无人机排球测试平台，通过物理动力学让多个无人机合作并竞争排球运动。
### Innovation
VolleyBots测试平台整合了三种功能：竞争与合作游戏模式、轮流互动结构以及敏捷的三维机动。无人机需要在对抗中协调团队行动、预测对手策略以及实现精确的三维定位。通过结合运动控制和战略博弈，VolleyBots提供了复杂问题，并且尚无可用的专家演示。研究还通过不同算法对比，展示了基于策略的学习方法在单个无人机任务中的表现优于非策略方法，并在复杂的结合了运动控制与策略的博弈任务中两者均被证明具有挑战性。此外，研究设计了一种层次化策略，实现了在多人任务中的显著胜率。
### Conclusion
本研究通过VolleyBots测试平台展示了在多无人机协作与竞争中的挑战性任务，并通过多层次策略提高了胜率，未来研究将进一步探索运动控制与高阶策略的复杂交互。
## 851. `cs.LG` - 在大规模语言模型中控制幻觉的基本不可能性 [PDF](https://arxiv.org/pdf/2506.06382), [HTML](https://arxiv.org/abs/2506.06382)
### Authors
Michał P. Karpowicz
### Background
当前的大规模语言模型能够生成自然而然的语言输出，然而这些输出往往伴随着不切实际的幻觉。这些问题的存在使得模型的响应不总是真实、全面和有用的信息，这对模型的应用造成了限制。本文通过严谨的数学证明揭示了这种幻觉控制的基本不可能性，并详细分析了这一性质的根本原因及其背后的数学原理。
### Innovation
本文创新地运用了拍卖理论、概率预测的适当评分理论以及transformer架构的log-sum-exp分析来证明了信息聚合在实现信息保真、知识揭示和知识约束优化方面的根本性限制。文中首次从数学结构的角度严格证明了幻觉控制的基本不可能性，并为管理这种幻觉而非彻底消除它提供了理论基础。这一研究不仅在技术上开辟了新的研究方向，也加深了我们对神经网络推理、知识哲学以及博弈论和信息论经典结果之间深刻联系的理解。
### Conclusion
本文揭示了大规模语言模型中幻觉不可避免的存在，展示了信息聚合之间的基本权衡。研究结果认为，为了实现更有效的AI系统，需要理解和接受幻觉的存在，找到管理这些问题的方法而不是试图完全消除它们。这种认识为开发在数学约束下的有益AI系统提供了理论指导。
## 852. `cs.LG` - 大型语言模型指令跟随通过增强注意机制 [PDF](https://arxiv.org/pdf/2506.13734), [HTML](https://arxiv.org/abs/2506.13734)
### Authors
Vitoria Guardieiro,Adam Stein,Avishree Khare,Eric Wong
### Background
大型语言模型的生成控制仍然是确保其安全可靠部署的关键挑战。尽管prompt工程和调优是常见的方法，但最近的研究探索了隐式引导（latent steering）这一轻量级技术，它通过改变模型内部激活来引导生成过程。然而，后续研究显示隐式引导的有效性是有限的，通常表现不及简单的指令提示。为解决这一局限，作者首先建立了一个针对多种行为的标准基准，以评估引导技术。基于这一基准的见解，作者介绍了Instruction Attention Boosting（InstABoost），这是一种隐式引导方法，通过改变模型生成期间的注意力来加强指令提示的强度。InstABoost结合了现有方法的优点，并由先前工作中的理论支持，这些工作表明，基于Transformer的模型中的上下文规则遵循可以通过操纵指令上的注意力来控制。实验结果表明，InstABoost在控制成功方面优于传统提示和隐式引导方法。
### Innovation
首先，作者建立了一个基准对隐式引导技术进行了标准化评估。接着，作者提出了Instruction Attention Boosting（InstABoost），这是一种通过在产生期间改变模型的注意力来加强指令提示强度的隐式引导方法。InstABoost结合了现有方法的优点，通过操控指令上的注意力，理论上支持了可控制基于Transformer的模型的上下文规则遵循。
### Conclusion
实验结果表明，与传统的提示和隐式引导方法相比，InstABoost在控制成功方面表现更优。
## 853. `cs.LG` - 工业URLLC中的基于GCN的强化学习概率实时保证 [PDF](https://arxiv.org/pdf/2506.15011), [HTML](https://arxiv.org/abs/2506.15011)
### Authors
Eman Alqudah,Ashfaq Khokhar
### Background
确保包级通信质量对于大型工业无线网络中的超可靠、低延迟通信（URLLC）至关重要。传统的Local Deadline Partition (LDP)算法利用静态优先级，通过干扰协调来增强通信质量。然而，这种方法在多小区、多频段网络中面临着实时交通需求、网络拓扑、剩余传输机会和干扰模式的变化挑战，影响了网络性能和可靠性。
### Innovation
本文通过引入结合深度Q-网络（DQN）强化学习框架的图卷积网络（GCN）增强了LDP算法。该方法能动态学习基于实时交通需求、网络拓扑、剩余传输机会和干扰模式的链路优先级。GCN捕捉空间依赖性，而DQN通过奖励引导探索实现自适应调度决策，显著提升了网络性能，尤其是在复杂URLLC要求下。对比实验证明，GCN-DQN模型的平均信干比（SINR）分别比LDP和基于CNN的方法提高了179.6%、197.4%、175.2%和31.5%、53.0%、84.7%。
### Conclusion
GCN-DQN模型在提高网络性能、满足复杂URLLC要求方面非常有效，且具有最小的开销。
## 854. `cs.LG` - 使用高斯过程回归加速鞍点搜索的有效实现及其在分子反应中的应用 [PDF](https://arxiv.org/pdf/2505.12519), [HTML](https://arxiv.org/abs/2505.12519)
### Authors
Rohit Goswami(1),Maxim Masterov(2),Satish Kamath(2),Alejandro Peña-Torres(1),Hannes Jónsson(1) ((1) Science Institute and Faculty of Physical Sciences, University of Iceland, Reykjavík, Iceland, (2) SURF, Amsterdam, The Netherlands)
### Background
在高维能量表面中定位一阶鞍点是识别热激活事件机制和估算速率的关键步骤，尤其是在振动近似转换态理论下的谐振子近似中。直接与电子结构计算结合时，达到鞍点配置所需的能量和原子力评估数量是一个主要问题。
### Innovation
描述了通过使用二聚体估计Hessian最低特征模式的高斯过程回归（GPR）加速的最小模式跟踪方法的有效实现。构建并更新代理能量表面，并在每次电子结构计算后更新。结果显示，与二聚体方法相比，使用GPR的计算可以减少一个数量级的电子结构计算次数。尽管分子自由度在刚度上的范围很广，但计算使用笛卡尔坐标进行，其电子结构计算次数与Sella软件包中实现的复杂内部坐标方法相当。
### Conclusion
高斯过程回归代理模型的C++实现足以使鞍点搜索的时间减少在3种情况中的3种，即使计算是在较低的哈特里-福克水平下进行的。
## 855. `cs.LG` - EEG2TEXT-CN: 通过大规模语言模型和对比学习对中国EEG数据集中的开放词汇文本-EEG对齐的探索性研究 [PDF](https://arxiv.org/pdf/2506.00854), [HTML](https://arxiv.org/abs/2506.00854)
### Authors
Jacky Tai-Yu Lu,Jung Chiang,Chi-Sheng Chen,Anna Nai-Yun Tung,Hsiang Wei Hu,Yuan Chiao Cheng
### Background
该论文介绍了一种名为EEG2TEXT-CN的框架，这是目前所知的最早将脑电图（EEG）与中文文本生成相结合的框架之一。该框架利用生物基础的EEG编码器（NICE-EEG）和紧凑型预训练语言模型（MiniLM），通过屏蔽预训练和对比学习将多通道脑信号与自然语言表示对齐。该研究利用了包含大约十汉字与128通道EEG信号对齐的数据集（中国EEG数据集），展示了非音素级别的多模态语言解码的可能性。这项工作为后续的多语言脑电图到文本研究奠定了基础，并为进一步探索汉语认知语言界面提供了新的方向。
### Innovation
该论文提出了一个针对中文的开放词汇的EEG到文本生成框架（EEG2TEXT-CN），并且构建了一种结合了生物基础的EEG编码器（NICE-EEG）和紧凑型预训练语言模型（MiniLM）的架构。通过屏蔽预训练和对比学习对EEG信号和自然语言进行对齐。该方法在零样本情况下实现了单字符级别的EEG数据解码和完整句子的预测，展示了非音素级别的脑电图解码潜力。这为多语言的脑电图到文本研究开辟了新的方向，并夯实了后续研究的基础。
### Conclusion
该研究展示了使用大规模语言模型和对比学习进行开放词汇的中文文本-EEG对齐的可能性，尽管在句法流畅性方面存在挑战，但证明非音素级别的跨模态语言解码从EEG信号是可行的。该工作为多语言脑电图到文本接口研究铺平了道路，并为进一步的汉语认知语言界面研究奠定了基础。
## 856. `cs.LG` - PDFMathTranslate: 保留版面的科技文档翻译 [PDF](https://arxiv.org/pdf/2507.03009), [HTML](https://arxiv.org/abs/2507.03009)
### Authors
Rongxin Ouyang,Chang Chu,Zhikuang Xin,Xiangyao Ma
### Background
科学技术文献中的语言障碍阻碍了科学和技术的发展与传播。然而，早期的文献翻译工作大多忽视了保留版面信息的重要性。
### Innovation
引入了PDFMathTranslate，这是一个开源软件，能够翻译科技文献的同时保留其版面布局。通过利用大型语言模型的最新进展和精确的版面检测技术，该软件在精准度、灵活性和效率方面取得了关键改进。
### Conclusion
本工作已经开源，并且拥有超过22.2万次下载量。
## 857. `cs.LG` - 使用少量样本学习高效检测间歇性任务失败 [PDF](https://arxiv.org/pdf/2507.04173), [HTML](https://arxiv.org/abs/2507.04173)
### Authors
Henri Aïdasso,Francis Bordeleau,Ali Tizghadam
### Background
开发人员在使用持续集成（CI）和部署流水线时面临的一个主要挑战是间歇性任务失败，这些失败通常是由于非确定性的不确定问题（如不稳定测试或基础设施问题），而非常规的代码相关错误。此前的研究开发了基于大规模任务日志的数据集来训练机器学习模型来分类任务失败为间歇性或常规类型。相比之下，最新的方法使用了基于非确定性任务重试的启发式方法，但由于在没有明确政策的情况下重试可疑失败的任务会导致间歇性任务失败被错标记为常规失败，因此在实际应用中限制了其性能。我们的手动分析表明，平均有32%的间歇性任务失败被错误地标记为常规失败。基于这些局限性，本文提出了使用少量样本学习（FSL）来检测间歇性任务失败的新方法。我们使用少量手动标注的日志样本微调一个小型语言模型，并使用生成的丰富嵌入训练一种机器学习分类器。我们的FSL方法在所有项目中仅需12个样本就能达到70-88%的F1分数，远超以往的方法（在4个项目中F1分数仅为34-52%）。总体而言，本研究强调了数据质量和数量的重要性，并为组织提供了更有效且实用的间歇性任务失败检测框架。
### Innovation
提出了一种使用少量样本学习（FSL）的新颖方法来检测间歇性任务失败，通过微调一个小型语言模型并使用生成的丰富嵌入训练机器学习分类器，实现了在所有项目中仅需12样本的70-88% F1分数，远超之前方法在多个项目中的表现。
### Conclusion
本研究强调了数据质量和数量的重要性，提供了一个更有效且实用的框架，用于在组织中检测间歇性任务失败。
## 858. `cs.LG` - 使用荷兰档案数据的自我监督语音表示学习 [PDF](https://arxiv.org/pdf/2507.04554), [HTML](https://arxiv.org/abs/2507.04554)
### Authors
Nik Vaessen,Roeland Ordelman,David A. van Leeuwen
### Background
这篇论文探讨了使用荷兰档案电视广播数据对语音基础模型进行自我监督学习的应用，特别是wav2vec 2.0模型。研究首先分析了预训练数据质量假设，展示了音乐、噪音和说话人重叠对SSL收敛和下游微调性能的影响。然后研究了有效预处理策略，通过使用Whisper和WhisperX将噪音广播数据集转换为预训练的高质量数据集。此外，还比较了单语言和多语言预训练，并展示了单语言预训练在域外数据中的鲁棒性。最后，通过继续使用55000小时的档案数据对wav2vec 2.0 XLS-R模型进行预训练，实现了荷兰语言的最新大模型LARGE wav2vec 2.0模型。
### Innovation
1. 研究荷兰档案电视广播数据用于语音基础模型的自我监督学习。2. 提出了音乐、噪音和说话人重叠对预训练和下游微调性能的影响。3. 开发了有效预处理策略，将噪音广播数据集转换为预训练的高质量数据集。4. 比较了单语言和多语言预训练，展示了单语言预训练的鲁棒性。5. 实现了荷兰语言的最新大模型LARGE wav2vec 2.0模型。
### Conclusion
通过继续使用55000小时的荷兰档案数据对wav2vec 2.0 XLS-R模型进行预训练，研究人员实现了最新的LARGE wav2vec 2.0模型，该模型能够更好地处理单语言和多语言预训练的数据，并在荷兰语音识别任务中取得了优异的性能。
## 859. `cs.LG` - 从视频到EEG：将联合嵌入预测架构应用于揭示脑信号分析中的视觉概念 [PDF](https://arxiv.org/pdf/2507.03633), [HTML](https://arxiv.org/abs/2507.03633)
### Authors
Amirabbas Hojjati,Lu Li,Ibrahim Hameed,Anis Yazidi,Pedro G. Lind,Rabindra Khadka
### Background
EEG信号以高时间和低空间分辨率捕获脑活动，适用于神经诊断、认知监测和脑机接口等应用。有效分析受到有限标注数据、高维度以及无法全面捕捉时空依赖性的可扩展模型的阻碍。现有的自监督学习方法往往集中于空间或时间特征，导致表现不佳。
### Innovation
提出了EEG-VJEPA，这是一种利用视频联合嵌入预测架构（V-JEPA）的新适应方法，用于EEG分类。通过将EEG视作视频样序列表，EEG-VJEPA使用联合嵌入和自适应掩码学习语义上有意义的时空表示。这是第一项利用V-JEPA进行EEG分类并探索模型中学习的视觉概念的工作。EEG-VJEPA在公开的Temple University Hospital（TUH）异常EEG数据集上的评估表明，其分类准确性优于现有最先进的模型。EEG-VJEPA捕获生理相关的时间和空间信号模式，并提供可解释的嵌入，有助于诊断流程中的人机协作。
### Conclusion
这些发现将EEG-VJEPA定位为适用于现实世界临床环境中的可扩展和可信赖的EEG分析框架。
## 860. `cs.LG` - 信息论驱动的机器学习在分离气动流时间变化模式分解中的应用 [PDF](https://arxiv.org/pdf/2505.24132), [HTML](https://arxiv.org/abs/2505.24132)
### Authors
Kai Fukami,Ryo Araki
### Background
本文进行了一种信息论模式分解，针对分离气动流动。当前数据驱动的方法基于一种称为深度 sigmod 分流的神经网络，可以从给定的流场快照中提取关于目标变量未来时间戳的信息性组件，从而捕捉随时间变化的模态结构中的因果关系。本文探讨了四种机翼周围的分离流动示例，包括：1. 在后失速迎角处的层流周期性尾涡，2. 数值和实验测量的强阵风-机翼交互作用，3. 湍流尾涡的扰动性时域响应，4. 以及在横向周期性域中的湍流尾涡。研究通过揭示与时间变化的升力响应相关的信息性涡旋结构，对周期性脱落情况进行分析。研究进一步通过阵风与机翼交互作用的例子，解释了阵风对机翼升力响应的影响，并在湍流尾涡案例中利用信息度量突出显示与机翼和涡旋核心相关的结构作为信息性组成部分。
### Innovation
本文提出了一种基于信息论的机翼分离气动流的时间变化模式分解方法。该方法使用深度 sigmod 分流神经网络从流场快照中提取信息性组件，捕捉随时间变化的模态结构的因果关系。对于研究中的各种案例，该方法能揭示与时间变化的响应相关的信息性涡旋结构，并且在湍流尾涡案例中，模型仅基于信息度量而不需要任何先验的气动学和长度尺度知识就凸显了有用的信息组件。
### Conclusion
本文的研究提供了关于一系列非定常气动问题基于因果关系的见解。该方法能够有效地识别和解释分离流中的流场结构和动态特性，对于非定常的气动问题具有广泛的应用潜力。
## 861. `cs.LG` - 链状推理压缩的激活引导 [PDF](https://arxiv.org/pdf/2507.04742), [HTML](https://arxiv.org/abs/2507.04742)
### Authors
Seyedarmin Azizi,Erfan Baghaei Potraghloo,Massoud Pedram
### Background
大型语言模型在包含中间步骤（称为'推理链'）的情况下擅长复杂推理。然而，这些推理链往往是冗长的，即使是对于简单问题也是如此，这会导致占用过多上下文、延迟增加和更高的能源消耗。研究发现在模型的残留流激活空间中，冗长且以英语为主的推理链与简练且以数学为中心的推理链处于不同的区域。通过提取和注入“引导向量”来转换这两种模式，可以可靠地将生成引向更简练的推理，从而使推理链压缩而无需重新训练。研究人员进一步通过Formalize这一方法，定义为激活引导压缩（ASC），这是一种推理时的技术，通过直接修改隐藏表示来缩短推理痕迹。
### Innovation
提出了一种名为Activation-Steered Compression (ASC) 的方法，通过在模型的残差流激活空间中注入引导向量，实现推理链的压缩。ASC能够在不进行重新训练的情况下，仅使用100个多余和简练的示例对MATH500和GSM8K数据集上的推理链长度进行67.43%以上的缩减，同时保持模型的准确性。ASC作为一种无需训练的方法，几乎没有运行时的额外开销，在MATH500数据集上，8B模型的端到端推理时间平均加快2.73倍。
### Conclusion
ASC作为一种实际且高效的工具，可以简化推理能力语言模型在延迟或成本敏感环境中的部署。该研究结果表明，ASC能够有效压缩推理链，提高推理效率，而无需额外的训练开销。同时，这种技术可以节省能源消耗并提高推理速度，使其在许多应用场景中具有很高的实用性。
## 862. `cs.LG` - 堆叠自适应预测 [PDF](https://arxiv.org/pdf/2505.12578), [HTML](https://arxiv.org/abs/2505.12578)
### Authors
Paulo C. Marques F
### Background
该研究考虑了一种方法，用于对堆叠集成的预测模型进行自适应化转换。背景在于，最顶部的元学习器可能具有简单的形式，这使得可以实现一个具有可管理计算成本的程序，该程序能够近似获得边缘有效性，而无需使用独立校准样本。研究者通过实证结果表明，该方法在与标准归纳替代方法的比较中表现更好。
### Innovation
该研究的创新之处在于展示了如何通过堆叠集合方法实现自适应预测模型，特别强调了元学习器可能具有的简单形式使得这种方法在保持计算成本可管理的同时，能够近似获得边缘有效性，并且无须使用独立校准样本。这一方法相比标准方法表现出优势。
### Conclusion
研究通过实验证明，堆叠自适应预测方法相比传统的归纳预测方法具有竞争力，能够在保持高效计算成本的同时，实现近似边缘有效性的预测。
## 863. `cs.SE` - 开源背后的隐性成本：开源软件许可管理的系统元文献综述 [PDF](https://arxiv.org/pdf/2507.05270), [HTML](https://arxiv.org/abs/2507.05270)
### Authors
Boyuan Li,Chengwei Liu,Lingling Fan,Sen Chen,Zhenlin Zhang,Zheli Liu
### Background
集成第三方软件组件是现代软件开发中的一种常见实践，提供了效率和创新方面的显著优势。然而，这项实践也伴随着与软件许可相关的风险。缺乏对此的理解可能导致纠纷，给企业带来严重的法律和运营挑战。学术界和产业界针对这些挑战进行了各种调查并提出了相应的解决方案和工具，但仍存在不足之处。此外，开源软件（OSS）许可证的快速演化以及生成式软件工程技术，如大型语言模型（CodeLLMs）的广泛应用，给系统的管理软件许可风险带来了新的挑战。
### Innovation
本文系统地综述了80篇精心挑选的关于OSS许可的论文，将现有研究分为三个关键类别：许可识别、许可风险评估和许可风险缓解。基于这些分类，讨论了现有解决方案的挑战，指出了未来研究的机会，并为实践者提供了实用建议，旨在促进学术界和产业界的交流，加速软件工程社区范围内合法软件风险的生态管理。
### Conclusion
本文希望通过对现有研究的全面综述，为未来的学术研究和工业实践提供指导，弥合学术与工业之间的差距，加速软件工程社区内合法软件风险的生态系统治理。
## 864. `cs.SE` - FuzzFeed: 使用大型语言模型和模糊测试自动生成最弱前置条件的方法 [PDF](https://arxiv.org/pdf/2507.05272), [HTML](https://arxiv.org/abs/2507.05272)
### Authors
Daragh King,Vasileios Koutavas,Laura Kovacs
### Background
最弱前置条件（WP）描述了所有满足给定后置条件的程序终止执行所能从的初始状态的最大集合。生成最弱前置条件是具有广泛实际应用的任务，包括验证和运行时错误检查等领域。为了实现这一目标，本论文提出结合大型语言模型（LLMs）和模糊测试的方法来生成最弱前置条件。为此，引入了模糊测试指导（FG），FG通过程序执行反馈引导LLMs生成正确的最弱前置条件。FG利用模糊测试进行近似检查候选最弱前置条件的有效性和薄弱之处，反馈给LLMs以作上下文修正。
### Innovation
本论文提出一种结合大型语言模型和模糊测试的方法来生成最弱前置条件。引入了模糊测试指导FG，利用模糊测试反馈信息纠正和优化LLMs生成的最弱前置条件，提高了其生成正确最弱前置条件的总体效果。
### Conclusion
本论文通过全面的基于Java的确定性数组程序基准测试集验证了该方法的有效性。实验表明，大型语言模型能够生成有效的候选最弱前置条件，且通过FG反馈机制可以进一步提高这些模型的生成能力。
## 865. `cs.LG` - 一个通用 surrogate 的万能攻击：基于 CLIP 的普遍可转移和目标导向的对抗攻击 [PDF](https://arxiv.org/pdf/2505.19840), [HTML](https://arxiv.org/abs/2505.19840)
### Authors
Binyan Xu,Xilin Dai,Di Tang,Kehuan Zhang
### Background
尽管深度神经网络（DNNs）在许多任务上取得了广泛的成功，但它们仍然容易受到对抗攻击。传统的对抗攻击通常需要频繁查询目标模型或依赖于与目标模型高度相似的代理模型，这些代理模型通常使用目标模型的训练数据的子集进行训练。然而，在实际场景中，当训练数据不可访问且频繁查询会引起警报时，生成对抗样本会变得更加困难。
### Innovation
本文提出了一种名为 UnivIntruder 的新颖攻击框架，该框架仅依赖于一个公开可用的 CLIP 模型和公开可用的数据集。通过利用文本概念，UnivIntruder 生成了普遍、可转移和目标导向的对抗扰动，误导 DNNs 将输入分类为由文本概念定义的对手指定的类别。实验结果表明，该方法在 ImageNet 上的攻击成功率高达 85%，在 CIFAR-10 上的攻击成功率超过 99%，显著优于现有的基于转移的方法。此外，还揭示了实际世界的脆弱性，即使不查询目标模型，UnivIntruder 也能使图像搜索引擎如 Google 和 Baidu 的攻击成功率高达 84%，使视觉语言模型如 GPT-4 和 Claude-3.5 的攻击成功率高达 80%。这些发现突显了在传统途径被阻断的情况下，该攻击方法的实际应用价值，并强调需要重新评估 AI 应用的安全框架。
### Conclusion
总之，这些发现表明了在传统防御手段被阻断的情况下，UnivIntruder 攻击在实际应用中的可行性，强调了重新评估 AI 应用安全框架的必要性。
## 866. `cs.SE` - ReservoirChat：结合LLM和知识图谱的ReservoirPy交互式文档 [PDF](https://arxiv.org/pdf/2507.05279), [HTML](https://arxiv.org/abs/2507.05279)
### Authors
Virgile Boraud(Mnemosyne),Yannis Bendi-Ouis(Mnemosyne),Paul Bernard(Mnemosyne),Xavier Hinaut(Mnemosyne)
### Background
该研究引入了一个工具，旨在利用ReservoirPy库提升大型语言模型（LLMs）在辅助代码开发和回答复杂问题方面的性能。通过使用检索增强生成（RAG）和知识图谱，该方法旨在减少幻觉并提高生成回答的准确性。系统提供了类似于ChatGPT的交互体验，专为ReservoirPy量身定制，使用户能够编写、调试和理解Python代码，同时访问可靠的领域特定见解。在这项评估中，尽管象ChatGPT-4o和NotebookLM这样的专有模型在一般知识问题上表现出稍微更好的表现，但该模型在编程任务中表现更佳，并且相对于其基础模型Codestral-22B有显著改进。
### Innovation
该研究提出了一个结合了检索增强生成（RAG）和知识图谱（KG）的方法，旨在提高大型语言模型在辅助代码开发和回答复杂问题中的能力，特别是在领域特定知识的应用上。这种结合使模型既保留了高阶语言的理解能力，又增加了专用领域的准确性和可靠性。这种方法通过增强模型的上下文理解能力，提高了代码生成和问题解答的质量。
### Conclusion
尽管专有的ChatGPT-4o和NotebookLM模型在通用知识问题上稍微更好，但该模型在编程任务上表现更出色，并显示出相对于其基础模型Codestral-22B有显著的改进。该工具为用户提供了一个交互式的环境，帮助他们更好地编写、调试和理解Python代码。
## 867. `cs.SE` - 通过大型语言模型衡量代码可读性属性变化对代码质量评估的影响 [PDF](https://arxiv.org/pdf/2507.05289), [HTML](https://arxiv.org/abs/2507.05289)
### Authors
Igor Regis da Silva Simoes,Elaine Venson
### Background
代码可读性是代码质量的关键方面，受标识符名称、注释、代码结构和标准遵守等因素影响。然而，在行业和学术界评估这一属性都存在挑战。静态分析工具评估代码异味和注释比例，而代码审查则引入了主观性。这项研究探讨了使用大型语言模型（LLMs）标准化、重复性和一致地评估代码质量的可读性属性。
### Innovation
本文通过一项准实验研究，测试了大型语言模型对代码可读性属性变化的敏感度。研究设计了去除注释、用模糊名称替换标识符名称和重构去除代码异味三种干预措施。研究发现大型语言模型在评估代码意义上比参考模型更为敏感，并且能够直接反映每种干预的本质。
### Conclusion
大型语言模型显示出评估语义质量方面（如标识符名称、注释、文档与代码目的之间的连贯性）的潜在能力，虽然模型表现出一定的评估变异性，但并未削弱结果的统计显著性。
## 868. `cs.SE` - zkSDK：通过自动化跟踪驱动的零知识证明后端选择简化零知识证明开发 [PDF](https://arxiv.org/pdf/2507.05294), [HTML](https://arxiv.org/abs/2507.05294)
### Authors
William Law
### Background
零知识（ZK）程序的快速发展催生了多种工具，帮助开发者编写程序。Risc Zero支持使用如Rust这样的通用编程语言，而Circom、Lib-snark和Cairo等其他语言也广受青睐。然而，进入ZK领域的开发者面对诸多不同的ZK后端选择，导致学习曲线陡峭且开发体验分散在不同平台上。许多开发者最终会选择一个专用的ZK后端并持续使用。因此，zkSDK被引入，这是一个模块化框架，通过抽象后端复杂性和使用自定义的Python-like编程语言Presto来简化ZK应用程序的开发。Presto能够分析程序的计算工作负载强度，结合用户定义的标准和动态选择算法，自动选择最优的ZK证明后端。通过全面分析实际工作负载，zkSDK证明了它能够从支持的ZK后端中选择最适合的那个，提供无缝且用户友好的开发体验.
### Innovation
zkSDK通过引入Presto，一种自定义的Python-like编程语言，能够分析程序的计算工作负载强度。结合用户定义的标准和动态选择算法，它可以自动选择最优的ZK证明后端，从而简化零知识证明应用程序的开发过程，提供无缝且用户友好的开发体验，解决了不同ZK后端导致的学习曲线陡峭和体验分散的问题.
### Conclusion
通过深入分析和评估实际工作负载，研究证明了zkSDK能够有效地从支持的ZK后端中选择最合适的后端，提供了一个无缝且用户友好的开发体验。zkSDK通过即时优化选择ZK后端，显著提高了开发ZK应用程序的效率和便捷性.
## 869. `cs.SE` - ASSURE：AI驱动浏览器扩展的 metamorphic 测试 [PDF](https://arxiv.org/pdf/2507.05307), [HTML](https://arxiv.org/abs/2507.05307)
### Authors
Xuanqi Gao,Juan Zhai,Shiqing Ma,Siyi Xie,Chao Shen
### Background
大型语言模型（LLMs）被整合到浏览器扩展中，极大地改变了网页浏览体验，带来了如内容摘要、智能翻译和上下文感知写作辅助等功能。然而，这些基于AI的扩展带来了前所未有的测试和可靠性保证挑战。传统的浏览器扩展测试方法无法适应LLM驱动扩展的非确定性行为、上下文敏感性和复杂网页环境集成的特点。现有LM测试方法缺乏针对特定浏览器上下文的有效评价框架。为了解决这些问题，作者提出了一个模块化的自动测试框架，称为ASSURE，专门用于测试AI驱动的浏览器扩展。
### Innovation
ASSURE框架包含三个主要组成部分：（1）模块化的测试用例生成引擎，支持基于插件扩展测试场景，（2）自动执行框架，协调复杂的网页内容、扩展处理和AI模型行为之间的交互，（3）配置可变的验证流水线，系统地评估行为一致性与安全不变量而非完全依赖输出匹配。评估结果显示ASSURE能够显著提高测试效率，平均12.4分钟内就发现关键的安全漏洞，相比手动测试提高6.4倍的测试吞吐量。
### Conclusion
该研究展示了ASSURE的有效性，通过模块化的自动测试框架显著提高了AI驱动浏览器扩展的测试效率和效果，解决了传统测试方法的缺陷，并提供了全面的解决方案来应对AI驱动浏览器扩展的独特挑战。
## 870. `cs.SE` - CoreCodeBench：一种可配置的多场景代码仓库级基准 [PDF](https://arxiv.org/pdf/2507.05281), [HTML](https://arxiv.org/abs/2507.05281)
### Authors
Lingyue Fu,Hao Guan,Bolun Zhang,Haowei Yuan,Yaoming Zhu,Jun Xu,Zongyu Wang,Lin Qiu,Xunliang Cai,Xuezhi Cao,Weiwen Liu,Weinan Zhang,Yong Yu
### Background
随着大型语言模型（LLMs）展示出日益复杂的代码处理能力，评估其在工程级代码上的性能仍然具有挑战性。现有的基于存储库级别的基准主要集中在单一场景，如代码生成或错误修复上，未能充分捕捉现实世界软件或项目工程工作流中的多样性和复杂性。此外，这些基准在问题定位可控性和生成测试用例的可靠性方面存在限制。为解决这些限制，作者提出了一种名为CorePipe的自动化管道，将其转换为全面的测试用例，并介绍了一种可配置的多场景存储库级别基准CoreCodeBench。为了模拟实际的工程场景，CorePipe生成了三种类型的基本问题（开发、BugFix和Test-Driven Development），专门针对核心代码部分。这些基本问题进一步组合成三种类型的复合问题，通过超参数调整灵活性地调整难度级别。CoreCodeBench提供了一个全面且广泛的存储库级基准，以调查LLMs在实际工程项目的适用性。
### Innovation
作者提出了CorePipe，一种完全自动化的管道，能够将存储库转换为全面的测试用例，并引入了CoreCodeBench，这是一种可配置的多场景存储库级别基准。CorePipe能够生成三种类型的基本问题（开发、BugFix和Test-Driven Development），针对核心代码部分。这些基本问题被进一步组合成三种类型的复合问题，并通过超参数调整灵活性地调整难度级别。CoreCodeBench提供了一个全面且广泛的存储库级基准，以调查LLMs在实际工程项目的适用性。实验表明，在各种场景中使用16种LLM揭示了不同的能力，并提供了对LLM在工程环境中性能的多维度见解。
### Conclusion
实验结果表明，使用16种LLM在各种场景下揭示了不同的能力。CoreCodeBench提供了一个集成且广泛的基准，用于研究LLM在实际工程项目的应用。CorePipe的代码可在给定的网址处获得，CoreCodeBench的数据也可通过另一个给定的网址访问。
## 871. `cs.LG` - LLM Hypnosis：利用用户反馈进行未经授权的知识注入以影响所有用户 [PDF](https://arxiv.org/pdf/2507.02850), [HTML](https://arxiv.org/abs/2507.02850)
### Authors
Almog Hilel,Idan Shenfeld,Jacob Andreas,Leshem Choshen
### Background
用户反馈在训练语言模型（LMs）时被用来调整模型的行为和知识。然而，研究人员发现，攻击者可以通过仅提供提示并根据LM输出进行点赞或点踩反馈的方式，持续地改变LM的知识和行为。这种攻击方式揭示了一个新的特征：即使在非常有限的偏好数据下，也可以对LM的细粒度行为进行精准控制。
### Innovation
本研究揭示了一种新的攻击机制，即将用户反馈用于未经授权的知识注入，以影响所有用户的LM。这种攻击方式不仅扩展了对预训练数据污染和部署时提示注入的研究，还展示了即使在高度受限的形式下也可以对LM的行为产生精细控制。研究展示了这种攻击方式可以实现插入事实性知识、修改代码生成模式并引入可利用的安全缺陷，以及注入虚假的财务新闻。
### Conclusion
该研究不仅识别出了语言模型偏好调整中的一个新特征，还提出了一种针对使用用户反馈训练的LM的新攻击方法。这一发现对于提高语言模型的安全性和稳健性具有重要意义，同时也提出了对训练数据和用户反馈机制进行改进的必要性。
## 872. `cs.SE` - OASBuilder: 使用大型语言模型生成在线API文档的OpenAPI规范 [PDF](https://arxiv.org/pdf/2507.05316), [HTML](https://arxiv.org/abs/2507.05316)
### Authors
Koren Lazar,Matan Vetzler,Kiran Kate,Jason Tsay,David Boaz Himanshu Gupta,Avraham Shinnar,Rohith D Vallam,David Amid Esther Goldbraich,Guy Uziel,Jim Laredo,Ateret Anaby Tavor
### Background
AI代理和业务自动化工具需要与外部Web服务交互，但它们通常需要标准化的、机器可读的API规范信息。然而，可用的API信息经常以非结构化的自由格式HTML文档形式出现，需要用户花费大量时间手动将其转换为结构化格式。这给用户带来了不便和效率低下。因此，需要一种能够自动将API文档转换为机器可读规范的方法，以提高效率和便捷性。
### Innovation
OASBuilder是一个创新性的框架，旨在将大量的不一致的API文档页面转换为一致且机器可读的API规范。该框架通过结合大型语言模型和基于规则的算法来实现这一目标，这些算法由文档网页结构领域的专业知识指导。实验结果显示，OASBuilder在多种情况下表现良好，能够生成包含原始文档大部分信息的有效OpenAPI规范。OASBuilder已经在企业环境中成功实施，节省了大量的手动工作时间，并使得许多复杂的企业API作为工具供LLMs使用。
### Conclusion
OASBuilder通过结合大型语言模型和基于规则的算法，成功地将不同的API文档转换为有效的OpenAPI规范。该框架已经证明了其在多个API上的适用性，并在企业环境中展现了显著的效率提升。未来，它有望作为API管理的重要工具在商业领域得到更广泛的应用。
## 873. `cs.LG` - 在银河化学演化中的模型对比与基于仿真推理指南 [PDF](https://arxiv.org/pdf/2507.05060), [HTML](https://arxiv.org/abs/2507.05060)
### Authors
Berkay Gunes,Sven Buder,Tobias Buck
### Background
该论文提出了COMPASS框架，这是一个新颖的基于模拟推理框架，结合了得分基于的扩散模型与变换器架构，旨在对竞争的银河化学进化（GCE）模型进行参数估计和贝叶斯模型对比。该框架专门用来处理高维、不完整且大小变化的恒星丰度数据集。利用高精度的元素丰度测量，该框架能够评估40种核合成产量表格的组合。
### Innovation
该创新之处在于COMPASS框架的独特设计能够同时进行参数估计与贝叶斯模型对比，适用于处理具有挑战性的恒星丰度数据集。通过使用得分基于的扩散模型与变换器架构的结合，该框架能够在复杂的模型对比和数据推理任务中提供更加精确的结果。
### Conclusion
利用优选的模型，该研究得出了一个陡峭的高质量初始质量函数斜率和增加的Ia型超新星规范，这些结果与先前的太阳小区研究结果一致，但通过全任务贝叶斯推理得出。研究结果表明，现代基于模拟的推理方法能够稳健地限制天文学模拟中的不确定物理过程，并且在处理复杂的基于模拟的数据时能够促进合理的模型选择。
## 874. `cs.SE` - 通过静态分析任务评估大模型的代码推理能力：CoRe基准 [PDF](https://arxiv.org/pdf/2507.05269), [HTML](https://arxiv.org/abs/2507.05269)
### Authors
Danning Xie,Mingwei Zheng,Xuwei Liu,Jiannan Wang,Chengpeng Wang,Lin Tan,Xiangyu Zhang
### Background
大语言模型（LLMs）已在软件工程的多个领域得到广泛应用，如代码生成、程序修复和漏洞检测。这些应用需要理解深层次的代码模式，包括值传播、控制流和程序元素之间的相互依赖。然而，现有基准主要评估端到端的效果，如代码是否正确修复或生成，从而忽视了模型在程序语义推理中的能力。
### Innovation
本文提出CoRe基准，这是一个高质量的人工验证基准，用于评估LLMs在基本静态分析任务上的能力。CoRe包含跨C/C++、Java和Python编写的程序的数据依赖性、控制依赖性和信息流任务实例12,553个。本文提出了一种语义感知多样化采样策略，基于结构覆盖率和依赖深度选择目标和任务实例，以确保语义多样性和推理复杂性。研究评估了10个主流LLMs，结果显示，尽管它们在识别依赖关系方面表现良好，但模型在需要深层语义理解和多步推理的任务中仍存在困难。
### Conclusion
本文进一步进行了定性分析，揭示了关键挑战，如复杂控制结构和反向依赖模式，为提高LLMs代码推理能力提供了见解。
## 875. `cs.SE` - 使用大型语言模型增强需求工程的多智能体辩论策略 [PDF](https://arxiv.org/pdf/2507.05981), [HTML](https://arxiv.org/abs/2507.05981)
### Authors
Marc Oriol,Quim Motger,Jordi Marco,Xavier Franch
### Background
目前，大型语言模型（LLM）代理正在被广泛应用于各种需求工程（RE）任务中。现有的研究主要集中在提升它们准确性的方法上，如提示工程、模型微调和检索增强生成等。然而，这些方法通常将模型视为孤立的黑匣子，依赖单次输出，没有迭代改进或合作，这限制了其鲁棒性和适应性。
### Innovation
本文提出，如同人类辩论通过引入多方位视角可以提高准确性和减少偏见，不同的LLM代理辩论和合作也能达到同样的效果。研究旨在探索多智能体辩论（MAD）策略是否能提升需求工程的性能。我们系统地研究了不同领域的MAD策略，并提出了一种基于MAD的初步框架来测试其在需求工程分类中的应用。
### Conclusion
多智能体辩论为提高大型语言模型在需求工程任务中的准确性提供了有前景的方法。本研究为了解多智能体辩论策略奠定基础，提供了对未来研究和实际应用中需求工程的改进建议。
## 876. `cs.SE` - PromiseTune: 解析因果上具有一致性和可解释性的配置调优方法 [PDF](https://arxiv.org/pdf/2507.05995), [HTML](https://arxiv.org/abs/2507.05995)
### Authors
Pengzhou Chen,Tao Chen
### Background
现代软件系统的高可配置性使得配置优化成为一个关键步骤，以确保系统的性能如延迟或吞吐量。然而，由于代价高昂的测量、庞大的配置空间以及复杂的配置地形，现有的调优工具由于探索不确定区域与利用已知最优配置的指导之间难以平衡预算使用的困难而效果不佳。核心问题是缺乏识别具有潜力区域的知识，这也给结果的可解释性带来了挑战。
### Innovation
我们提出了PromiseTune，这是一种通过因果净化规则引导配置优化的方法。PromiseTune的独特之处在于，它学习规则反映配置景观中的特定区域，并通过因果推理净化这些规则。剩下的规则充当了有潜力区域的近似反映，从而限制调优以强调景观中的这些地方。这正如我们所证明的那样，可以有效地缓解探索与利用之间的权衡。
### Conclusion
我们在12个系统和不同预算下，将PromiseTune与11种最先进的调优工具进行了比较，结果显示PromiseTune在总体排名上优于其他工具，提高了42%的排名，并且提供更多的信息来解释隐藏的系统特性，提供了景观级别的空间可解释性。
## 877. `cs.SE` - TigAug：自动驾驶系统中交通信号灯检测测试的数据增强 [PDF](https://arxiv.org/pdf/2507.05932), [HTML](https://arxiv.org/abs/2507.05932)
### Authors
You Lu,Dingji Wang,Kaifeng Huang,Bihuan Chen,Xin Peng
### Background
近年来，随着感测和计算技术的进步，自动驾驶车辆技术得到了快速发展。确保自动驾驶系统（ADS）的可靠性和鲁棒性变得尤为重要。尽管在测试ADS的各个模块方面已经取得了显著进展，但对交通信号灯检测模型的自动化测试却很少受到关注。目前，常用的实践是手工收集和标记交通信号灯数据，但这既劳动密集型，又难以在不同的驾驶环境下收集多样化的数据。为解决这些问题，本文提出了TigAug方法，自动增强标记的交通信号灯图像用于测试交通信号灯检测模型。
### Innovation
本文提出了TigAug方法，这是一种数据增强方法，用于测试自动驾驶系统中的交通信号灯检测模型。通过构建基于系统理解天气环境、相机属性和交通信号灯属性的两大家族的元同变关系和三大家族的变换，TigAug能够自动生成用于测试的交通信号灯图像，同时也用于改善交通信号灯检测模型的性能。大量的实验表明TigAug方法的有效性和效率。
### Conclusion
本文介绍了TigAug方法，它验证了在自动驾驶系统中自动增强交通信号灯图像以测试交通信号灯检测模型的有效性与效率。TigAug使用增强后的图像结合特定变换的元同变关系来检测交通信号灯检测模型的错误行为，并通过重新训练来提高模型性能。实验结果表明，TigAug在测试交通信号灯检测模型方面是有效的，在生成交通信号灯图像方面是高效的，且生成的交通信号灯图像具有可接受的自然度。
## 878. `cs.SE` - 在强化学习系统中检测和缓解奖励劫持：一项综合的实证研究 [PDF](https://arxiv.org/pdf/2507.05619), [HTML](https://arxiv.org/abs/2507.05619)
### Authors
Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma
### Background
奖励劫持在强化学习（RL）系统中是一个严重的威胁，它可能导致自主代理利用奖励函数的漏洞，实现高分却未完成预期目标。尽管人们对这一问题越来越重视，但系统的检测和缓解方法依然有限。研究通过跨15个不同的RL环境和5种算法的大规模实验，考察奖励劫持现象，提出了六类奖励劫持类型的自动检测算法。研究发现，奖励密度和与真正目标的对齐程度对奖励劫持频率有显著影响，而缓解策略能够在实验场景中减少最多54.6%的奖励劫持情况，但实际应用中还存在概念漂移、假阳性成本和对抗适应等挑战。这些研究资料、数据集和实验方案都已公开，以支持RL安全性的可复制研究。
### Innovation
该研究通过大规模实验分析了不同RL环境和算法下的奖励劫持问题，并提出了自动化检测六类奖励劫持类型的算法，包括规格游戏、奖励篡改、代理优化、目标错位、利用模式和线性插针。研究实现了78.4%的精度和81.7%的召回率，同时计算开销低于5%，并证明了通过调整奖励函数属性可以显著减少奖励劫持现象。此外，研究还发现缓解技术在实际应用中面临更多挑战，如概念漂移、假阳性成本和对抗适应。整个研究资料和实验方案均已公开，以支持RL安全性的可复制研究。
### Conclusion
通过15个不同的RL环境和5种算法分析了15,247个训练序列，提出了六类奖励劫持的检测算法和缓解技术，验证了其在三大应用场景中的有效性，发现奖励密度和目标对齐对减少奖励劫持影响显著，但实际应用中面临诸多挑战。研究结果表明，未来应进一步关注概念漂移、假阳性成本和对抗适应等问题，以提高RL系统的安全性。
## 879. `cs.SE` - 使用中间表示代理框架实现异常安全的代码生成 [PDF](https://arxiv.org/pdf/2410.06949), [HTML](https://arxiv.org/abs/2410.06949)
### Authors
Xuanming Zhang,Yuxuan Chen,Yuan Yuan,Minlie Huang
### Background
大型语言模型（LLMs）在生成的代码中往往难以进行稳健的异常处理，导致程序在运行时容易出错。现有解决方案难以满足开发需求，需要一种新的方法来提高代码的异常处理精度和整体的鲁棒性。
### Innovation
提出了一种名为Seeker的新颖多代理框架，通过中间表示（IR）方法强制在LLM生成的代码中实现异常安全性。引入了通用异常枚举（CEE），一个从官方文档、技术实践和实际代码中提取出的标准化异常处理策略知识库。使用深度检索增强生成（Deep RAG）算法来高效导航异常继承层次结构，并在保持功能性正确性的同时，实现错误的主动处理，从而生成更安全的代码。
### Conclusion
Seeker在开源Java项目和多个基准测试中表现出色，相比现有的基线模型，提高了37%的异常处理精度和38%的整体代码鲁棒性。该框架在实际问题修复中能实现28%的成功率，比之前的解决方案提高了9个百分点。Seeker展示了实现更大规模编码任务和复杂软件工程任务的潜力，为LLM生成代码与工行业标准的对接提供了一个实用、可推广的解决方案。
## 880. `cs.LG` - StreamDiT: 实时流式文本到视频生成 [PDF](https://arxiv.org/pdf/2507.03745), [HTML](https://arxiv.org/abs/2507.03745)
### Authors
Akio Kodaira,Tingbo Hou,Ji Hou,Masayoshi Tomizuka,Yue Zhao
### Background
近年来，通过将基于变压器的扩散模型扩展到数十亿参数，文本到视频（T2V）生成领域取得了巨大进展，能够生成高质量的视频。但现有的模型通常仅能离线生成短片段，限制了它们在互动和实时应用中的使用。
### Innovation
本文提出了StreamDiT，一种流式视频生成模型，通过引入流动匹配以及移动缓存来训练。设计了具有不同缓存帧分割方案的混合训练，以提升内容一致性并优化视觉质量。基于adaLN DiT，使用可变时间嵌入和窗口注意力构建模型。为实现实时性能，还提出了针对StreamDiT的多步骤知识蒸馏方法，减少了总函数评估次数。
### Conclusion
通过上述方法，我们训练了一个4亿参数的StreamDiT模型，并实现了每秒16帧的实时性能，能够生成512p分辨率的视频流。通过定量指标和人工评价评估了该方法，验证了模型在实时应用程序中的有效性，如流式生成、互动生成和视频到视频。
## 881. `cs.SE` - 探索软件工程中的同理心：灰色文献分析的实践者视角 [PDF](https://arxiv.org/pdf/2507.05325), [HTML](https://arxiv.org/abs/2507.05325)
### Authors
Lidiany Cerqueira,João Pedro Bastos,Danilo Neves,Glauco Carneiro,Rodrigo Spínola,Sávio Freire,José Amancio Macedo Santos,Manoel Mendonça
### Background
同理心是关键的社会技能，对于软件工程中的沟通与协作至关重要，但仍然是一个研究不足的话题。本研究旨在从实践者的角度探索软件工程中的同理心，以定义其含义、识别障碍、讨论克服障碍的实践，并探讨其影响。
### Innovation
本研究采用质性内容分析法，对来自DEV和Medium两个广泛用于实践者的社区的55篇网络文章进行了分析，并通过后续调查与同理心专家合作，提出了一个综合框架，该框架包含了定义同理心、识别障碍、促进团队同理心的实践以及改善效果，如提升了协作、沟通，并减少了焦虑、挫败和压力。这项研究填补了软件工程中同理心研究的空白，提出了改善团队动态的策略和框架，为未来研究提供了方向。
### Conclusion
调查结果表明，该框架清晰且有价值，提高了同理心意识，并提出了改进和整合到培训中的建议。这项研究通过识别障碍并提供培养同理心的策略，为改善团队动态铺平了道路。未来的研究将探讨同理心在软件工程实践中的更广泛影响。
## 882. `cs.SE` - 迁移提示：使用演变的大语言模型稳定生成AI应用程序 [PDF](https://arxiv.org/pdf/2507.05573), [HTML](https://arxiv.org/abs/2507.05573)
### Authors
Shivani Tripathi,Pushpanjali Nema,Aditya Halder,Shi Qiao,Alekh Jindal
### Background
生成AI正在通过自然语言接口和智能自动化转变商业应用。然而，这些底层的大语言模型（LLMs）正在迅速演变，使得一致和稳定地提示它们变得具有挑战性。这导致应用程序表现出不一致和不可预测的行为，这削弱了企业对于关键业务流程所需可靠性的信任。
### Innovation
本文提出了一种提示迁移的概念，作为在不稳定的LLMs环境中系统地稳定生成AI应用程序的方法。通过分析Tursio企业搜索应用程序在相继的GPT模型升级中的影响，文章详细介绍了提示迁移框架，包括提示重设计和迁移测试平台，并展示了这些技术如何恢复应用程序的一致性。结果显示，经过结构化的提示迁移可以完全恢复由于模型漂移而失去的应用可靠性。
### Conclusion
我们得出了实用的经验教训，强调提示生命周期管理和严格的测试对于确保可靠的生成AI驱动的商业应用程序的重要性。
## 883. `cs.SE` - 扩展行为软件工程：负责任软件工程中的人工智能团队决策与协作 [PDF](https://arxiv.org/pdf/2504.09496), [HTML](https://arxiv.org/abs/2504.09496)
### Authors
Lekshmi Murali Rani
### Background
行为软件工程（BSE）研究软件工程任务的行为和社交维度，但人类-人工智能协作（HAIC）的重要性日益提高，给BSE带来新的挑战和机遇，尤其是在决策（DM）以及人机团队协作方面。这促使研究关注人类与AI在软件工程任务中的决策和协作，以促进负责任的软件工程。
### Innovation
该研究旨在从认知角度识别HAIC中的挑战和细微差别，设计和优化人类-AI团队的合作模式，以增强集体智能并促进软件工程中的负责任决策。它强调了以人为本的方法，并探讨了HAIC对其自身、团队以及组织层面的BSE影响。
### Conclusion
该研究通过分析HAIC，有助于更好地理解人类与AI协作的复杂性，提出了优化人类-AI团队合作的策略，旨在推进负责任的软件工程实践。
## 884. `cs.SE` - 学习聚焦：语言模型用于高效代码漏洞检测的上下文提取 [PDF](https://arxiv.org/pdf/2505.17460), [HTML](https://arxiv.org/abs/2505.17460)
### Authors
Xinran Zheng,Xingzhi Qian,Huichi Zhou,Shuo Yang,Yiling He,Suman Jana,Lorenzo Cavallaro
### Background
语言模型（LMs）在漏洞检测方面显示出了潜力，但在处理较长的实际代码片段时遇到困难，因为漏洞的位置稀疏且不明确。这些问题在令牌限制加剧的情况下变得更加严重，往往导致模型未能检测到与漏洞相关的信号，从而影响有效的学习。核心的直觉是通过增强LMs来提供简明且信息丰富的上下文。基于提交的注释提供精确、不受CWE影响的监督，但在推理阶段不可用，因为它们依赖于历史代码更改。此外，由于极其稀疏的特点，通常只涵盖几行代码，导致LM难以直接处理这些数据。
### Innovation
该论文提出了一种名为FocusVul的模型无偏框架，通过学习选择敏感上下文来提高基于LM的漏洞检测效果。FocusVul通过分层语义建模学习基于提交的注释模式，并在推理时将这些模式泛化以识别漏洞相关的行级区域。然后，通过选择区域周围的依赖性和执行流提取LM导向的上下文，从而提供语义丰富的输入进行有效漏洞检测。实验结果表明，FocusVul在真实基准上的性能始终优于基于启发式方法和全功能微调方法，平均提高分类性能164.04%，并减少约19.12%的FLOPs（每秒浮点运算次数）.
### Conclusion
实验表明，FocusVul在真实基准上的性能始终优于基于启发式方法和全功能微调方法，平均提高分类性能164.04%，并减少约19.12%的FLOPs（每秒浮点运算次数）.
## 885. `cs.SE` - 使用大型语言模型支持规范要求调试和理解的工具 [PDF](https://arxiv.org/pdf/2507.05504), [HTML](https://arxiv.org/abs/2507.05504)
### Authors
Alex Kleijwegt,Sinem Getir Yaman,Radu Calinescu
### Background
规范性要求涉及社会、法律、伦理、同理心和文化（SLEEC）等规范，这些规范必须被系统遵守。为了识别这些要求，已经发展了许多标准和规定。这些要求通常由非技术系统中的各个利益相关者（如伦理学家、律师、社会科学家）定义，因此保证它们的一致性和管理需求提取过程非常复杂且容易出错。虽然近期研究使用特定领域语言来定义规范性要求，通过形式方法分析其一致性，但这些方法通常以非技术用户难以理解的方式展示结果，这阻碍了对这些要求的理解和通过迭代过程进行的验证变得效率低下。
### Innovation
本文提出了一种名为SLEEC-LLM的工具，该工具利用大语言模型（LLMs）为模型检查中的反例（对应于SLEEC规则不一致）提供自然语言解释。SLEEC-LLM提高了规范性要求的提取效率和可解释性，并能够进行一致性分析。
### Conclusion
通过两个实际案例研究总结了SLEEC-LLM的使用情况，表明该工具在实际应用中提高了非技术利益相关者调试和理解规范性要求的效率和质量。
## 886. `cs.SE` - 提示编程对函数级代码生成的影响 [PDF](https://arxiv.org/pdf/2412.20545), [HTML](https://arxiv.org/abs/2412.20545)
### Authors
Ranim Khojah,Francisco Gomes de Oliveira Neto,Mazen Mohamad,Philipp Leitner
### Background
大型语言模型（LLMs）在软件工程中越来越用于代码生成。然而，LLMs 的局限性，如不相关或错误的代码，突显了提示编程（或提示工程）的重要性，即工程师应用特定的提示技巧来改进生成的代码。尽管已经有了一定程度的研究，但对于不同提示技巧及其交互作用在代码生成中的影响还不完全清楚。因此，为了进一步理解提示技巧的效果，引入了CodePromptEval 数据集，评估五种提示技巧（少量样本、人物角色、思维链、函数签名、包列表）对三个LLMs（GPT-4o、Llama3 和 Mistral）生成的完整函数的正确性、相似性和质量的影响。
### Innovation
引入了一个名为CodePromptEval的数据集，该数据集包含7072个提示，用于评估五种提示技巧对三个LLMs生成的关系函数的正确性、相似性和质量的影响。此外，研究发现某些提示技巧对生成的代码有显著影响，但结合多个提示技巧并不总是能提高结果，并观察到在使用提示技巧时正确性和质量之间的权衡。该数据集和复制包将为未来的LLM代码生成研究和新提示技巧的评估提供便利。
### Conclusion
提示技巧对代码生成有显著影响，但不一定通过组合技巧来提高结果。此外，在使用提示技巧时，正确性和质量之间存在权衡。所创建的数据集和复制包将促进对LLM生成代码的研究和新提示技巧的评估。
## 887. `cs.SE` - 缩小差距：开源LLM的监督微调作为一种教育工具替代产权模型的可行方案 [PDF](https://arxiv.org/pdf/2507.05305), [HTML](https://arxiv.org/abs/2507.05305)
### Authors
Lorenzo Lee Solano,Charles Koutcheme,Juho Leinonen,Alexandra Vassar,Jake Renzella
### Background
前沿的大规模语言模型（LLMs）如ChatGPT和Gemini能够为新手程序员解析晦涩的编译器错误，但由于其庞大的计算规模、高昂的成本以及过度协助的倾向，这些模型在广泛教育中的应用存在诸多问题。研究表明，较小的专门化语言模型，通过监督微调（SFT）增强后，提供了教育工具上更为可行的替代方案。本研究利用来自真实初级编程 coursework（CS1/2）学生自动生成的编程错误的新数据集，对三个开源模型：Qwen3-4B、Llama-3.1-8B和Qwen3-32B进行了监督微调。研究采用了专家人工评估和大规模自动分析相结合的方式，评估了8,000个模型响应的表现。
### Innovation
本研究展示了监督微调（SFT）如何显著提升较小模型的教育质量，使其性能与更大规模的模型相媲美。研究通过分析模型大小和质量之间的权衡，发现通过在高质量、特定领域的数据上微调紧凑且高效的模型可以创造专门化的模型，从而推动教育工具的发展。此外，本研究还提供了一种可复制的方法，以促进在教育环境中更广泛地获得生成型AI能力。
### Conclusion
通过监督微调，较小的、专门化语言模型能够在教育工具中发挥重要作用。这种方法不仅提高了教育工具的实用性，还为更广泛地在教育领域应用生成型AI提供了可行路径。进一步的工作可以探索不同领域数据集对模型性能的影响，以及在其基础上进行更深入的研究和应用。
## 888. `cs.SE` - 评估小型语言模型在代码生成中的应用：基于基准的一次经验研究 [PDF](https://arxiv.org/pdf/2507.03160), [HTML](https://arxiv.org/abs/2507.03160)
### Authors
Md Mahade Hasan,Muhammad Waseem,Kai-Kristian Kemell,Jussi Rasku,Juha Ala-Rantala,Pekka Abrahamsson
### Background
近年来，小型语言模型（SLMs）的发展为高效的代码生成提供了新的可能性。与大型语言模型（LLMs）相比，SLMs轻量且成本效益高，尤其适合作为资源受限环境下的替代方案。然而，关于SLMs在代码生成中的能力、局限性和性能权衡的实际理解仍然有限。因此，本文通过经验评估了20个多参数量级的开源SLMs（0.4B到10B参数）在五种不同的代码相关基准测试（HumanEval、MBPP、Mercury、HumanEvalPack和CodeXGLUE）上的表现，旨在填补这一空白，分析SLMs在生成代码的正确性、计算效率以及在多种编程语言之间的性能方面的表现差异和权衡。
### Innovation
本文首次系统性地评估了小型语言模型在代码生成中的应用，并提出了对其性能进行全面的对比分析方法。研究结果显示，尽管性能和效率之间存在权衡，但一些紧凑的SLMs在吞吐量方面仍然具有竞争力，适合资源受限环境下的部署。然而，更高的准确性需要使用更大规模的模型，这些模型在计算性能上表现得更好，但需要消耗更多的计算资源。此外，研究还揭示了不同编程语言在性能上的差异，但统计分析表明这些差异并不显著，表明小型语言模型在不同编程语言之间的泛化能力较强。
### Conclusion
基于研究结果，本文为小型语言模型在实际代码生成任务中的设计和选择提供了有价值的见解，特别是在资源受限的环境下，可以根据性能、效率和通用性等因素进行权衡，选择最适合的模型。进一步的研究可以探索如何优化小型语言模型以提高其准确性和效率之间的平衡。
## 889. `cs.SE` - cuVSLAM：CUDA加速的视觉里程计和建图 [PDF](https://arxiv.org/pdf/2506.04359), [HTML](https://arxiv.org/abs/2506.04359)
### Authors
Alexander Korovko,Dmitry Slepichev,Alexander Efitorov,Aigul Dzhumamuratova,Viktor Kuznetsov,Hesam Rabeti,Joydeep Biswas,Soha Pouya
### Background
准确可靠的姿态估算对于任何自主机器人都是至关重要的。本文介绍了cuVSLAM，这是一种先进的视觉同时定位与建图解决方案，能够与多种视觉惯性传感器套件兼容，包括多台RGB和深度相机以及惯性测量单元。cuVSLAM能在边缘计算设备上实时运行，并支持从最少1台到最多32台相机的各种几何配置，适用于广泛的机器人设置。
### Innovation
cuVSLAM特别针对CUDA进行优化，以便在边缘计算设备，如NVIDIA Jetson上进行实时应用，具有最小的计算开销。cuVSLAM支持多种视觉惯性传感器套件，能够处理不同数量和配置的RGB相机，从单个到32个，为广泛的应用提供灵活性。
### Conclusion
通过在多个先进的基准测试上的实验结果，本文展示了cuVSLAM的优良性能。
## 890. `cs.SE` - 重新审视模型卡片：在伦理AI要求方面弥合理论与实践之间的差距 [PDF](https://arxiv.org/pdf/2507.06014), [HTML](https://arxiv.org/abs/2507.06014)
### Authors
Tim Puhlfürß,Julia Butzke,Walid Maalej
### Background
现有的模型卡片作为AI模型开发者用来向使用者传达关键信息的主要文档框架，但最近的研究表明，模型文档实践中存在不足，说明在AI需求和当前的模型文档实践之间存在差距。为了理解这一差距并提供解决方案，研究人员对26项道德与AI指导方针、三个AI文档框架、三项关于模型卡片的定量研究和十个实际模型卡片进行了主题分析。
### Innovation
研究识别了43个与模型文档相关的伦理要求，并将其组织成一个涵盖四大主题和十二个子主题的分类体系。这项分类体系突出了模型开发者主要强调模型能力和可靠性，并忽视了解释性、用户自主权和公平性等其他伦理方面的需求。此外，研究成果还为重新设计全面考虑伦理AI需求的模型卡片框架提供了一个基础。
### Conclusion
研究发现模型开发者在文档中主要强调模型的能力和可靠性，但忽视了解释性、用户自主权和公平性等其他伦理方面。新的分类体系为基础构建全面解决伦理AI需求的模型卡片框架提供了支持，强调了增强对道德AI考虑的文档支持的需求。
## 891. `cs.SE` - ETrace：通过基于大模型的追踪分析实现智能合约的事件驱动漏洞检测 [PDF](https://arxiv.org/pdf/2506.15790), [HTML](https://arxiv.org/abs/2506.15790)
### Authors
Chenyang Peng,Haijun Wang,Yin Wu,Hao Wu,Ming Fan,Yitao Zhao,Ting Liu
### Background
随着区块链技术在各领域的不断应用，智能合约的安全性和稳定性保障成为一个重要挑战。当前的漏洞检测方法主要分为静态分析和动态分析两种，但这些传统方法大多依赖于原始合约代码的分析。然而，并非所有智能合约都提供访问源代码的权限。
### Innovation
ETrace是一个新型的事件驱动漏洞检测框架，利用LLM（大规模语言模型）进行追踪分析，无需访问源代码即可发现潜在漏洞。通过从交易日志中提取细粒度的事件序列，并利用LLM作为自适应语义解释器，通过链式思维推理重建事件分析，实现模式匹配以发现交易行为模式与已知攻击行为之间的因果关系。
### Conclusion
通过对ETrace的初步实验结果验证了其有效性。
## 892. `cs.SE` - 使用少量示例学习高效检测间歇性作业失败 [PDF](https://arxiv.org/pdf/2507.04173), [HTML](https://arxiv.org/abs/2507.04173)
### Authors
Henri Aïdasso,Francis Bordeleau,Ali Tizghadam
### Background
开发人员在使用持续集成（CI）和部署管道时面临的主要挑战之一是间歇性作业失败的发生，这些失败通常是由于非确定性因素（例如不稳定的测试或基础设施问题）引起的，而不是常规的代码相关错误（如bug）。先前的研究开发了机器学习（ML）模型，这些模型基于大量的作业日志数据集来分类作业失败为间歇性或常规。现有的最佳实践方法使用基于非确定性作业重跑的启发式方法，但在没有明确政策要求重跑可疑作业失败的情况下，可能会错误地将间歇性作业失败标记为常规失败，从而限制了其实际性能。据我们手动分析的2,125个来自5个工业项目和1个开源项目的作业失败显示，平均而言，32%的间歇性作业失败被错误地标记为常规失败。为了解决这些问题，本文提出了使用少量示例学习（FSL）进行间歇性作业失败检测的新方法。具体来说，我们使用少量手动标记的日志示例微调了一个小型语言模型，生成丰富的嵌入，然后用于训练ML分类器。我们的FSL方法在所有项目中的F1分数达到了70-88%，而仅使用12个样本，远超过现有方法在4个项目中的表现（F1分数在34-52%之间）。
### Innovation
本文提出了使用少量示例学习（FSL）的方法来检测间歇性作业失败。这种方法使用少量手动标记的日志示例微调了一个小型语言模型，生成丰富的嵌入，然后用于训练ML分类器，实现了70-88%的F1分数，优于现有的最佳实践方法在4个项目中的表现（F1分数在34-52%之间），突显了数据质量的重要性和提供了更高效、更实用的间歇性作业失败检测框架。
### Conclusion
本研究强调了数据质量的重要性，并提供了一种更高效和可行的框架，用于组织中的间歇性作业失败检测。通过使用少量示例学习的方法检测间歇性作业失败，可以提高检测的准确性和效率。
## 893. `cs.SE` - scikit-package -- 软件打包标准和分享可再现科学软件的路线图 [PDF](https://arxiv.org/pdf/2507.03328), [HTML](https://arxiv.org/abs/2507.03328)
### Authors
S. Lee,C. Myers,A. Yang,T. Zhang,S. J. L. Billinge
### Background
科学研究的进步依赖于结果的共享和再现。当科学家使用自己编写的软件进行数据分析或计算时，就会遇到代码版本控制、代码质量以及代码共享的特殊挑战。scikit-package 项目通过提供教程和自动化的、集中式的可重用工作流，为科学家创造 minimal effort 的代码重用和共享途径。
### Innovation
scikit-package 提供了一套标准和路线图，旨在帮助没有专业软件工程师培训的科学家编写更可重用和维护的软件代码。它通过教程和自动化的、集中式的可重用工作流，帮助科学家提高软件的可再现性和可分享性。
### Conclusion
scikit-package 为科学界提供了一套社区维护的工具和路线图，帮助科学家将代码提升到更高层次的可再现性和可分享性，包括从简单的代码块转换为单一脚本中的函数，到发布可安装、完全测试和文档化的软件包。
## 894. `cs.SE` - ContractTrace：追溯智能合约版本以支持安全分析 [PDF](https://arxiv.org/pdf/2412.20866), [HTML](https://arxiv.org/abs/2412.20866)
### Authors
Fatou Ndiaye Mbodji,Vinny Adjibi,Moustapha Awwalou Diouf,Gervais Mendy,Kui Liu,Jacques Klein,Tegawende Bissyande
### Background
由于区块链技术固有的不可变性，智能合约的更新需要部署在新的地址上，而不是修改现有的地址，从而导致版本历史的碎片化，并为分析造成关键的盲点。例如，这种碎片化严重阻碍了安全研究人员跟踪合约版本中的漏洞生命周期的能力。虽然Etherscan等平台提供了详细的以太坊智能合约信息，但它们缺乏追踪合约血统中的先驱和后继关系的关键功能，从而阻碍了系统的漏洞演化研究。
### Innovation
为了应对追溯智能合约血统的挑战，我们采用设计科学研究（DSR）方法，并引入了ContractTrace，这是一种自动化的基础设施，能够准确地识别并链接智能合约的不同版本，形成连贯的血统。这个工具能够构建一个最新的开源数据集LineageSet，专门用于支持关于智能合约中漏洞、缺陷或任何其他属性演化模式的安全研究。通过一个基于安全的研究案例，ContractTrace展示了如何揭示合同血统中之前被掩盖的漏洞生命周期，并跟踪关键的安全漏洞在版本跨变时是持续存在还是得到解决。
### Conclusion
这种能力对于理解漏洞传播模式以及评估区块链环境中安全补丁的有效性至关重要。在DSR方法的评估阶段，我们用局部敏感哈希（LSH）方法对比我们的方法进行血统检测，验证了我们技术的安全相关性和准确性。
## 895. `cs.SE` - RPHunter: 通过代码与交易融合分析揭露加密代币的吸血骗局 [PDF](https://arxiv.org/pdf/2506.18398), [HTML](https://arxiv.org/abs/2506.18398)
### Authors
Hao Wu,Haijun Wang,Shangwang Li,Yin Wu,Ming Fan,Wuxia Jin,Ting Liu
### Background
rug pull诈骗已成为区块链领域的一个持续威胁，导致投资者巨额资金损失。传统方法要么依赖预定义模式检测代码风险，要么通过统计交易数据训练检测模型，但现实中rug pull方案往往涉及恶意代码和可疑交易行为的复杂互动，现有的单一方法难以有效检测此类诈骗。
### Innovation
提出了一种名为RPHunter的新技术，将代码分析和交易分析结合起来检测 Rug Pull。技术采用定义规则和流分析来提取代码风险信息，并构建语义风险代码图以获取更多的代码层面危险性信息。同时，通过构建动态代币交易行为图来捕捉交易层面的行为，再利用图神经网络提取互补特征，并通过注意力融合模型将两者结合，提升检测准确性。
### Conclusion
对645个rug pull案例进行手动分析构建了真实数据集，并在自建数据集上进行评估，结果显示RPHunter在精确度、召回率和F1分数上均表现优越，优于现有方法，实际应用中RPHunter能够准确识别到大量的rug pull代币，具有较高的精确度。
## 896. `cs.SE` - 基于搜索的元等价关系选择以优化大型语言模型的鲁棒性测试 [PDF](https://arxiv.org/pdf/2507.05565), [HTML](https://arxiv.org/abs/2507.05565)
### Authors
Sangwon Hyun,Shaukat Ali,M. Ali Babar
### Background
大型语言模型（LLMs）的可信度评估，特别是在稳健性方面，引起了广泛关注。目前，元等价测试通过定义元等价关系（MRs）已被广泛应用，以此评估LLMs执行的稳健性。然而，基于MRs的稳健性测试需要大量的MRs，因此优化选择MRs是必要的。大多数现有的LLM测试研究侧重于自动生成测试案例（即MRs）以增强故障检测，通常仅考虑单一扰动MRs来评估LLMs。
### Innovation
本文提出了一种基于搜索的方法，优化MR组以最大限度地提高故障检测并最小化LLM执行成本。此外，该方法涵盖了MR中的组合扰动，有助于在稳健性评估中扩展测试空间。为此，开发了一种搜索过程，并实现了四种搜索算法：单GA、NSGA-II、SPEA2和MOEA/D，使用新颖的编码来解决MR选择问题。实验结果发现，MOEA/D算法在优化LLM稳健性测试的MR空间方面表现最佳，并且识别出了适用于LLM稳健性测试的关键MRs。
### Conclusion
在LLM稳健性评估中，我们的研究揭示了优化测试的基本问题，并提供了基于搜索的解决方案的见解。
