{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02004", "html_url": "https://arxiv.org/abs/2507.02004", "title": "STELLA：生物医学研究中的自我进化LLM代理", "title_en": "STELLA: Self-Evolving LLM Agent for Biomedical Research", "authors": "Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong", "background": "生物医学数据、工具和文献的快速增长导致了研究领域的碎片化，超越了人类的专业知识。虽然人工智能代理可以解决这个问题，但由于它们通常依赖于静态、手动编辑的工具集，这限制了它们适应和扩展的能力。", "innovation": "提出了STELLA，一种自我进化的AI代理，通过自适应改进自己的能力（包括一个进化的模板库和一个动态工具海洋），从而实现自我改进和扩展。STELLA在生物医学基准测试中取得了最先进的准确性，同时随着经验的增加，其性能系统性地提高。", "conclusion": "STELLA代表了AI代理系统的重要进步，这些系统能够学习和成长，并且动态地扩展其专业知识以加速生物医学发现的进程。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02211", "html_url": "https://arxiv.org/abs/2507.02211", "title": "在强化学习下的空间囚徒困境中稀释、扩散和共生效应", "title_en": "Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning", "authors": "Gustavo C. Mangold,Heitor C. M. Fernandes,Mendeli H. Vainstein", "background": "近期研究表明，在空间囚徒困境游戏中通过强化学习机制，静态的玩家能够通过注入噪声、使用不同类型的学习算法以及考虑邻居的收益等方式学会合作。这项研究基于独立多智能体Q学习算法，进一步探讨了稀释和移动对空间囚徒困境的影响，并将其结果与经典的空间囚徒困境研究相比较，展示了该算法在建模不同类型博弈场景中的灵活性以及作为基准测试的潜力。", "innovation": "研究引入了一个独立的多智能体Q学习算法，并调查了稀释和移动对空间囚徒困境的影响。研究结果显示，具有固定更新规则的游戏可能与具有学习规则的游戏在质上等价，并且当定义了多种行动时，出现了群体之间的共生互惠效应。", "conclusion": "研究观察到一系列效果，包括固定规则游戏可以与学习规则游戏定性上等同，以及在定义多种行动时群体间共生互惠效应的出现。这表明算法的灵活性和功效以及在不同博弈场景中的潜在应用。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02152", "html_url": "https://arxiv.org/abs/2507.02152", "title": "公平的幻象：使用问询研究审计公平干预措施", "title_en": "The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies", "authors": "Disa Sariola,Patrick Button,Aron Culotta,Nicholas Mattei", "background": "人工智能系统，特别是使用机器学习的系统，正在被用于招聘、贷款发放等复杂决策的自动化。评测这些AI系统及其人类决策对应的公平性和有效性是一个复杂而重要的主题，这个主题跨学科地被计算科学和社会科学研究。为了减少下游分类器中的偏差，常见的方法是通过重新采样训练数据来抵消不平等。然而，这些方法多是在有偏差的选择样本中接受评估，从而引入了选择偏差和标签偏差。社会科学领域，如心理学、公共卫生和医学，进行的审计研究通过委托虚构的“测试者”（比如简历、邮件、病人演员）们随机地去考察目标（比如招聘岗位、企业、医生），以产生高质量的数据，支持对歧视情况的严格估计。本文探讨了如何利用审计研究的数据来提高培训和评估自动化招聘算法的能力。研究表明，常见的公平性干预措施，即在不同类别中均衡基础比率，虽然在传统指标上看起来实现了平权，但实际上依然存在大约10%的差异性。此外，论文还介绍了基于个体治疗效果估算方法的干预措施，这些措施有效减少了算法中的歧视现象。", "innovation": "引入了利用审计研究数据来改进人工智能招聘算法的策略，尤其是在公平性干预措施评估上。具体而言，使用审计研究数据揭示了常见均衡基础比率到平权方法在传统测量基础上可能掩盖的实际不平等现象，并通过个体治疗效果估计方法进一步减少算法中的歧视现象。", "conclusion": "审计研究数据能揭示传统平权方法下可能存在的实际不平等问题，通过基于个体治疗效果的干预措施减少算法中的歧视现象。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02319", "html_url": "https://arxiv.org/abs/2507.02319", "title": "迭代信念修正：从公理到能力", "title_en": "Iterated belief revision: from postulates to abilities", "authors": "Paolo Liberatore", "background": "信念修正领域虽有许多新提案，但在现有方法的分析上却明显不足。许多研究基于公设，即一些修正机制等同于特定属性。公设被称为语法规则，限制了某些具体的修正实例，在多数情况下，它们仅描述了修正必须进行的部分而不是可以进行的部分。因此，这样的公设无法确定所有可能的信念状态，或评估这些状态是否可达，以及这些状态的性质和影响。此外，不同的修正机制具备各自特定的能力，而这些能力强烈影响了它们在不同应用场景中的表现。", "innovation": "本文创新性地从公设出发，转向探讨修正机制的能力。通过研究各类修正机制具备的独特能力，而非仅仅依赖已有的公设，作者提出了一个更全面、更具潜力的研究框架。这不仅能更好地理解不同修正机制之间的差异，也能为实际应用提供更多参考。", "conclusion": "本文强调不同修正机制的能力差异，并举例说明了这些能力在实际应用中的意义。每种修正机制都有不同的能力，但也表现出多种能力的欠缺，通过这些能力上的对比，作者提出需要开发和设计出具有更多特定能力的修正机制，以便更好地应对多样化的应用需求。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02076", "html_url": "https://arxiv.org/abs/2507.02076", "title": "关于预算的推断：LLMs中适应性和可控性测试时计算的综述", "title_en": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "authors": "Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates", "background": "大型语言模型（LLMs）已经迅速发展成为一种可以解决广泛任务的一般用途代理，但目前的模型在推理方面效率低下：它们在推理时无论如何固定使用计算资源，这常常会导致简单问题过度推断而复杂问题则推断不足。本综述旨在全面审查有效的测试时计算（TTC）策略，以提高LLMs推理的计算效率。文章基于两层分类体系，区分L1可控性（在固定计算预算下工作的方法）和L2自适应性（根据输入难度或模型置信度动态调整推理的方法）。利用多种数据集对顶级专有LLM进行基准测试，突出了推理性能和标记使用之间的关键权衡。", "innovation": "本研究引入了两层分类体系，以区分在固定计算预算下工作的可控性方法和根据输入难度或模型置信度动态调整推理的自适应性方法，并在多种数据集上对顶级专有LLM进行了基准测试，强调了TTC方法的实用控制、自适应性和扩展性。此外，研究还讨论了新兴趋势，即混合思维模型，并指出了未来使LLMs更高效、更鲁棒并更加响应用户约束的关键挑战。", "conclusion": "最后，文章指出了TTC方法的实用控制、自适应性和扩展性，并讨论了未来的趋势和挑战，旨在使LLMs更具计算效率、鲁棒性和对用户约束的响应能力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02083", "html_url": "https://arxiv.org/abs/2507.02083", "title": "使用系统生物学干实验室衡量语言模型的科学能力", "title_en": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab", "authors": "Haonan Duan,Stephen Zhewen Lu,Caitlin Fiona Harrigan,Nishkrit Desai,Jiarui Lu,Michał Koziarski,Leonardo Cotta,Chris J. Maddison", "background": "设计实验和结果解释是科学研究的核心技能，尤其是在生物学领域。研究人员经常通过干扰复杂的系统来探索其内部机制。然而，评估大型语言模型的科研能力时，由于湿实验的高昂成本（在专业知识、时间和设备方面），通常无法测试这种能力。为了解决这一问题，研究人员引入了SciGym，这是一个评估模型进行迭代实验设计和分析能力的新标杆，它通过模拟生物系统的“干实验”解决了干湿实验成本的问题，并采用了系统生物学标记语言编码，以便生成仿真数据，用于测试复杂系统。", "innovation": "SciGym 是首个评估大型语言模型在开放科学发现任务中迭代实验设计和分析能力的标杆。它通过模拟生物系统来规避高昂的湿实验成本，使用系统生物学标记语言编码系统，用以生成易于实验的仿真数据。研究人员评估了六个先进模型在137个小系统上的表现，并公开了350个系统。结果显示，更先进的模型表现出更优的性能，但所有模型在系统复杂性增加时的性能都显著下降，这表明大型语言模型在科研能力上仍有很大的提升空间。", "conclusion": "研究表明，尽管更强大的模型在某些方面表现出优越性，但所有模型在面对复杂系统时的性能下降揭示了进一步改进大型语言模型科研能力的巨大潜力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02379", "html_url": "https://arxiv.org/abs/2507.02379", "title": "自主设计的AI原生实验实验室用于自主生物分子工程", "title_en": "An AI-native experimental laboratory for autonomous biomolecular engineering", "authors": "Mingyu Wu,Zhaoguo Wang,Jiabin Wang,Zhiyuan Dong,Jingkai Yang,Qingting Li,Tianyu Huang,Lei Zhao,Mingqiang Li,Fei Wang,Chunhai Fan,Haibo Chen", "background": "自主科学研究能够独立进行复杂实验，服务于非专业人员，一直是一个长期的梦想。实现这一目标需要由人工智能驱动的范式转变。尽管自主实验系统正在出现，但目前仍局限于单一目标和简单实验流程的领域，如化学合成和催化。这篇论文介绍了一个基于AI的自主实验室，旨在支持复杂科学实验，特别是自主生物分子工程的应用。该系统能够自主管理设备、制定实验特定的程序和优化策略，并同时处理多个用户请求。", "innovation": "该自主实验室基于模型、实验和仪器的设计理念，支持AI模型和自动化系统的共同发展，从而建立了一个端到端的多用户自主实验室，能够处理多目标和多样化的实验设备。该平台支持基本的核酸功能，包括合成、转录、扩增和测序，并支持诸如疾病诊断、药物开发和信息存储等应用领域。该系统能够自主优化实验性能，与人类科学家能达到的结果媲美。在多用户场景中，该平台显著提高了仪器利用率和实验效率，为高级生物材料研究开辟了道路，减少了对专家的依赖和资源障碍，同时为规模化科学服务提供了蓝图。", "conclusion": "该自主实验室为先进生物材料研究提供了新的可能性，有望克服专家依赖和资源障碍，为大规模科学服务提供了蓝图，标志着从专家驱动到基于服务的科学研究转变的趋势。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02253", "html_url": "https://arxiv.org/abs/2507.02253", "title": "扩展大型语言模型规划：NL2FLOW参数化问题生成和严格评估", "title_en": "Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation", "authors": "Jungkoo Kang", "background": "大型语言模型规划和推理能力的进步受到可扩展数据生成和评估瓶颈的阻碍。NL2FLOW是一个全自动系统，用于在自然语言、结构化中间表示和形式PDDL中参数化生成规划问题，并严格评估生成计划的质量。", "innovation": "NL2FLOW能够生成一座2296问题的数据集，并评估多个开源、指令微调的语言模型。研究结果表明，最高性能的模型在生成有效计划方面取得86%的成功率，在生成最优计划方面取得69%的成功率，特别是在有可行解决方案的问题上。回归分析表明，问题特征对规划生成的影响依赖于模型和提示设计。研究还观察到，将自然语言翻译成JSON表示计划的成功率低于直接生成有效计划的最高成功率，这表明无必要地分解推理任务可能会损害性能，建议模型直接从自然语言到行动的推理是有益的。", "conclusion": "随着对复杂问题的规模扩大，这些建模系统中的瓶颈和错误来源会发生变化。因此，理解这些限制的动态性以及系统地揭示它们的工具将成为解锁大型语言模型潜力的关键。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02197", "html_url": "https://arxiv.org/abs/2507.02197", "title": "角色扮演代理践行自己的信念？LLM基于的模拟中的人类信任信念-行为一致性", "title_en": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust", "authors": "Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto", "background": "随着大语言模型（LLM）被越来越多地用作角色扮演代理来生成用于人类行为研究的合成数据，确保它们的输出与赋予它们的角色保持一致已经成为一个关键的关切点。本文研究了LLM角色扮演代理声明的人们行为信念（“他们说什么”）与其角色扮演时实际行为（“他们如何行动”）之间的一致性问题。通过对增强版的GenAgents人物银行及其与可信度博弈（用于量化玩家信任和互惠的标准经济博弈）的结合进行评估，作者建立了一个评估框架，以系统地探讨影响这种一致性的因素，包括从LLM中获取的信念类型、何时以及如何向其提供有关可信度博弈相关信息、以及要求模型预测其行为的时间跨度。此外，还探讨了在原始获取的信念与研究目标不一致的情况下，研究者能否如何合理地在模型中植入自己的理论先验。研究结果显示，即使LLM似乎编码了合理的信念，在角色扮演模拟中也可能会以不一致的方式应用它们。", "innovation": "本文提出了一种评估框架，用于衡量通过提示模型获取的信念能否准确预测模拟结果，同时研究了影响这种一致性的一系列因素。此外，本文探讨了如何在模型信念与研究目标不一致时，研究者如何合理地在模型中植入自己的理论先验，为研究者在行为研究中合理使用基于大语言模型的角色代理提供了参考。", "conclusion": "研究结果表明，即使模型编码了合理的信念，这些信念在角色扮演模拟中的应用也可能不一致。这强调了识别和了解LLM声明和实际扮演角色之间差异的重要性，使研究者能够合理地使用基于大语言模型的角色代理进行行为研究。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02103", "html_url": "https://arxiv.org/abs/2507.02103", "title": "神经科学能向AI传授关于不断变化环境中学习的知识", "title_en": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments", "authors": "Daniel Durstewitz,Bruno Averbeck,Georgia Koppe", "background": "现代人工智能模型，如大规模语言模型，通常只在大规模数据集上进行一次训练，随后可能针对特定任务进行微调，然后部署时参数固定。它们的训练成本高昂、耗时且需要大量的重复。相比之下，动物能够连续适应不断变化的环境条件，这对社交物种尤为重要，因为它们的行为策略和奖励结果可能在与同伴互动中频繁变化。底层的计算过程通常伴随着动物行为的快速变化和神经元群体活动的突然转变。这样的计算能力对于在现实世界中运作的AI系统至关重要，比如引导机器人或自动驾驶汽车的系统，或与人类在线互动的人工智能体。", "innovation": "本文探讨了神经科学如何能帮助人工智能在不断变化的环境中进行持续学习。通过整合AI领域的持续学习和上下文相关学习的文献，与行为任务中的规则变化、奖励概率或结果的研究，提出了如何让神经科学的见解指导当前的AI发展。同时，还讨论了人工智能如何能为神经科学提供帮助，从而推进神经科学与人工智能这一新兴领域的发展。", "conclusion": "本文概述了神经科学与人工智能结合的议程，特别关注于如何使神经科学的见解指导AI在不断变化环境中持续学习的发展，同时也提出了神经科学可以从与AI的互动中学习的具体领域，从而促进神经科学与人工智能领域的发展。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02073", "html_url": "https://arxiv.org/abs/2507.02073", "title": "HCVR: 一种结合相关性感知投票规则的混合特征选择方法", "title_en": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection", "authors": "Nikita Bhedasgaonkar,Rushikesh K. Joshi", "background": "在特征选择领域，传统的非迭代方法（如CFS、mRMR和MI）和迭代方法（如RFE、SFS和遗传算法）已经被广泛研究和应用，但往往存在一定的局限性。这些方法大多集中在处理参数之间的直接关系，或是直接目标的影响，但忽视了二者之间的关联。本文旨在提出一种结合参数-参数（P2P）和参数-目标（P2T）相关性的混合特征选择方法，以便更有效地消除冗余特征并保留相关特征。", "innovation": "本文提出了HCVR（Hybrid approach with Correlation-aware Voting Rules），这是一种基于规则的轻量级特征选择方法。该方法通过结合P2P和P2T相关性，进行非迭代和迭代的混合降维操作。它采用贪婪算法，通过反向消除的方式进行特征筛选，每一步可能移除多个特征。该方法使用投票规则，通过多数投票决策是否保留或丢弃特征。投票规则基于特征之间的相关阈值，以及特征与目标之间的相关性。与传统的非迭代和迭代技术相比，HCVR方法展示出更好的性能，尤其是在不同分类器的应用下。", "conclusion": "HCVR方法通过结合P2P和P2T相关性，有效地实现了特征选择中的降维操作。实验结果表明，HCVR方法在SPAMBASE数据集上的应用性能优于传统的CFS、mRMR、MI等非迭代方法和RFE、SFS、遗传算法等迭代方法。通过不同分类器的性能评估，HCVR方法的有效性得到了验证。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02353", "html_url": "https://arxiv.org/abs/2507.02353", "title": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent", "title_en": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent", "authors": "Bowen Chen,Zhao Wang,Shingo Takamatsu", "background": "关键词决策对广告活动的成功至关重要。虽然基于大语言模型（LLM）的方法提供了自动关键词生成，但它们面临着三大局限性：依赖大量查询-关键词数据集、缺乏在线多目标性能监控与优化以及关键词选择质量控制较弱。这些问题阻碍了代理使用LLM来实现关键词决策的完全自动化，包括监控和推理关键绩效指标，如展示次数、点击次数、转化和CTA有效性。", "innovation": "提出了OMS框架，这是一种即用型、多目标和自我反思的广告关键词生成框架。具体来说，OMS不需要训练数据，可以实时监控在线性能并据此调整；它采用代理推理来根据多种绩效指标优化关键词；它具有自我反思性，能够代理性地评估关键词质量。实验结果表明，OMS优于现有方法；消融实验和人工评估证实了每个组件的有效性和生成关键词的质量。", "conclusion": "OMS在在线广告关键词生成方面表现优于现有方法，其即用性、多目标性和自我反思性特性为关键词选择提供了更好的自动化和优化解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02554", "html_url": "https://arxiv.org/abs/2507.02554", "title": "AI研究代理在机器学习中：搜索、探索与泛化在MLE-bench中的应用", "title_en": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "authors": "Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach", "background": "AI研究代理表现出通过自动化机器学习模型的设计、实施和训练来加快科学进步的巨大潜力。该研究集中于提高代理在MLE-bench上的性能，这是一个具有挑战性的基准，在这个基准中，代理在Kaggle竞赛中竞争，以解决现实世界的机器学习问题。研究人员认为代理可以作为搜索引擎政策，通遍候选项解决方案空间，并迭代地使用操作进行修改。他们在设计和系统地改变不同操作集和搜索引擎政策（贪婪、MCTS、进化）方面展示了其重要性。这些方法的共同作用对于实现高性能至关重要。", "innovation": "通过设计并系统地变化不同的操作集和搜索引擎政策，证明了这些方法的共同作用对于实现高性能至关重要。最佳的搜索策略和操作集配对在MLE-bench lite上达到了最先进的结果，成功率达到47.7%，比之前的39.6%有了明显提升。此外，研究强调了在推进自动化机器学习时共同考虑搜索策略、操作设计和评估方法的重要性。", "conclusion": "通过结合不同的搜索策略和操作集，研究提高了在MLE-bench上的表现，尤其是Greedy、MCTS和进化策略的应用。这一工作为自动化机器学习的发展提供了新的方法和视角，强调了全面方法论的重要性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02173", "html_url": "https://arxiv.org/abs/2507.02173", "title": "数据多样化方法在对齐中提高大语言模型的数学性能", "title_en": "Data Diversification Methods In Alignment Enhance Math Performance In LLMs", "authors": "Berkan Dokmeci,Qingyang Wu,Ben Athiwaratkun,Ce Zhang,Shuaiwen Leon Song,James Zou", "background": "尽管最近偏好学习的发展提高了与人类反馈的一致性，但在数学推理方面仍然存在持续的挑战。本文探讨了偏好优化中的数据多样化策略如何提升大型语言模型（LLMs）的数学推理能力。研究评估了三种常见的数据生成方法：温度采样、Chain-of-Thought 推导和蒙特卡洛树搜索（MCTS），并提出了一种名为 Diversified-ThinkSolve (DTS) 的新型结构化方法，该方法系统地将问题分解为多种推理路径。实验结果显示，通过策略性地多样化偏好数据，模型能够在数学推理性能上显著提高，其中最佳方法在 GSM8K 和 MATH 数据集上分别获得了 7.1% 和 4.2% 的提升。尽管 DTS 表现优异，但其计算开销仅为基线的 1.03 倍，而 MCTS 的计算开销几乎是其五倍且效果较差。这些发现证明了结构化探索多样化的解决问题方法比传统方法更有效地生成数学对齐的数据", "innovation": "本文提出了一种名为 Diversified-ThinkSolve (DTS) 的新型结构化方法，该方法将问题系统地分解为多种推理路径，并评估了三种数据生成方法（温度采样、Chain-of-Thought 推导和 MCTS）在大型语言模型中的应用效果。结果显示，DTS 和其他方法相比，在提升数学推理性能方面具有显著优势，同时计算开销低。", "conclusion": "结构化探索多样化的解决问题方法比传统方法更有效地生成对齐的数学数据，从而显著提高了大型语言模型的数学推理性能。DTS 作为一种有效的方法，其计算开销较低，具有推广价值。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02442", "html_url": "https://arxiv.org/abs/2507.02442", "title": "高斯-马克夫共轭：监督学习中残差的categories语义", "title_en": "The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning", "authors": "Moto Kamiura", "background": "提高机器学习的可解释性和可理解性是应对作为AI原则的可解释性需求的重要任务，也是促进更良好的社会AI实施的关键。本文的研究目标是通过从范畴理论的角度重新制定机器学习模型，从而为结构化和理解AI系统开发一个新的语义框架。本文对监督学习中最基本的形式——多元线性回归模型进行了研究，明确和形式化了残差和参数之间的结构性互动。", "innovation": "本文引入了使用范畴理论描述监督学习的新拟制，定义了两个对应的参数和数据的具体范畴，并借助共轭函子之间的一对伴随函子，提出了监督学习的范畴论表述。通过这种表述，说明了参数变化与残差之间的对偶信息流动，并通过伴随函子的保限性质，建立了普通最小二乘参数估计和最小残差之间的关系。作者还提出了将此类表述地位于扩展的语义描述语境之中的观点，并主张应用理论计算机科学中发展的语义视角作为AI中的可解释性形式基础。", "conclusion": "本文的核心是在监督学习中引入了一个基于高斯-马克夫共轭的范畴论语义框架，通过这一框架明确描述了参数变化与残差之间的关系，并将其视为监督学习的扩展语义实例，为提高AI的可解释性提供了理论基础。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02582", "html_url": "https://arxiv.org/abs/2507.02582", "title": "顺序决策机制中的责任缺口与扩散", "title_en": "Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms", "authors": "Junli Jiang,Pavel Naumov", "background": "责任的概念在法律和哲学中有着悠久的研究历史，近年来在人工智能文献中也成了关注焦点。本文探讨了集体决策中两个重要责任属性——责任扩散和责任缺口的计算复杂性。", "innovation": "文章证明了无责任扩散和无责任缺口的决策机制集分别是$\boldsymbol{\text{Π_2}}$-完全和$\boldsymbol{\text{Π_3}}$-完全类，同时指出它们的交集也是$\boldsymbol{\text{Π_2}}$-完全类。", "conclusion": "研究深入分析了集体决策机制中的责任扩散和责任缺口，并通过复杂性理论对其进行了刻画，为理解责任分配机制提供了理论基础。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02660", "html_url": "https://arxiv.org/abs/2507.02660", "title": "Hey AI, 生成我的硬件代码！基于自主人工智能的硬件设计与验证", "title_en": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification", "authors": "Deepak Narayan Gadde,Keerthan Kopparam Radhakrishna,Vaisakh Naduvodi Viswambharan,Aman Kumar,Djones Lettnin,Wolfgang Kunz,Sebastian Simon", "background": "现代集成电路（ICs）正在变得越来越复杂，其开发过程也变得更加复杂。硬件设计验证要求一种系统性且严谨的方法，包括规划、开发、执行和确认功能正确的硬件设计。这个繁琐的过程需要大量的时间和精力来确保无错误的流片。自然语言处理（NLP）领域因大型语言模型（LLMs）的存在发生了重大转变。这些强大的模型，通常被称为生成性人工智能（GenAI），革新了机器理解和生成人语言的方式，推动了广泛的应用领域的空前进步，包括硬件设计验证。", "innovation": "论文提出了一种基于自主人工智能的硬件设计验证方法，通过人在环（HITL）干预使AI代理能够参与更动态、迭代和反思的过程，最终实现端到端的硬件设计和验证。该方法在五个开源设计上进行了评估，达到了超过95％的覆盖范围并且减少了验证时间，展示了出色的性能、适应性和可配置性。", "conclusion": "该方法利用了生成性人工智能的强大能力，在硬件设计验证领域提供了新的解决方案，并证明了其高效、适应性好和高度可配置的优势。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02652", "html_url": "https://arxiv.org/abs/2507.02652", "title": "解耦计划与执行：用于深度搜索的分层推理框架", "title_en": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search", "authors": "Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou", "background": "在实际搜索场景中，复杂的检索需求需要在多种资源间进行深层次的推理和知识综合，而传统的检索增强生成（RAG）流程无法有效应对。当前基于推理的方法存在一个根本性的局限性：它们使用单一模型同时处理高层次规划和详细执行，导致推理效率低下且扩展性有限。", "innovation": "本文介绍了一种分层框架HiRA，该框架将战略规划与特定执行分离。这种方法将复杂搜索任务分解为专注的子任务，并将每个子任务分配给配备外部工具和推理能力的特定领域代理，并通过结构化的集成机制协调结果。这种分离防止执行细节干扰高层次推理，同时使系统能够利用不同类型的专门知识进行信息处理。实验表明，HiRA在四个复杂的跨模态深度搜索基准上显著优于最先进的RAG和基于代理的系统，结果表明解耦的计划与执行在多步信息检索任务中具有明显的效果提升。", "conclusion": "实验结果显示，HiRA在答案质量和系统效率方面都优于现有的RAG和基于代理的方法，突显了解耦计划与执行对于多步骤信息搜索任务的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02541", "html_url": "https://arxiv.org/abs/2507.02541", "title": "以结构化上下文改进证明之前的任务明晰度：一种Coq证明器", "title_en": "Clarifying Before Reasoning: A Coq Prover with Structural Context", "authors": "Yanzhen Lu,Hanbin Yang,Xiaodie Wang,Ge Zhang,Biao Li,Chenxu Fu,Chao Li,Yang Yuan,Andrew Chi-Chih Yao", "background": "本文研究了提高任务明晰度是否能增强大型语言模型的推理能力，尤其是在Coq中的定理证明。通过引入概念层面的度量来评估任务的明晰度，并展示通过增加现代LLM的标准输入结构化语义上下文，任务明晰度分数提高了1.85倍（从44.5%提升至82.3%）。", "innovation": "本文提出了一种通用模型DeepSeek-V3，通过对结构化数据的微调，实现了在证明成功率上2.1倍（从21.8%提升至45.8%）的提升，并且超越了之前的SOTA模型Graph2Tac（33.2%）。该方法通过选择性概念展开来丰富任务描述，并采用Planning-Execution架构，强调结构化任务表示的重要性，以弥合理解和推理之间的差距。", "conclusion": "研究表明，通过结构化任务表示可以提升大型语言模型的推理能力。这种方法不仅在大规模模型上有效，在较小模型上表现更好（48.6%的成功率），显示了结构化任务表示在提高大型语言模型的推理能力方面的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02681", "html_url": "https://arxiv.org/abs/2507.02681", "title": "检测自主测验中的脱节现象：基于更高距离教育的可解释机器学习方法", "title_en": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education", "authors": "Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin", "background": "学生在任务中的脱离可以导致严重的长期后果，如学业退学。对于在线教育中的学生尤其具有相关性。我们可以通过观察不同在线课程中非强制性任务的参与度来衡量这种脱离行为。这项研究分析了来自四所在线大学四学期共42门课程的非强制性测验的学生日志数据，运用机器学习算法来准确检测学生的脱离行为。", "innovation": "该研究创新性地开发了一种可解释的机器学习框架，通过SHAP方法，使得实践者能够更好地理解训练模型的决策过程，并获得了高度预测性能。此外，该研究还讨论了如何设计及时干预措施以减少在线学习中自愿任务上的脱离现象。", "conclusion": "实验结果表明，这种机器学习方法的平衡准确率为91%，正确检测了大约85%的脱离学生。该方法不仅具有高预测性能和可解释性，还为在线学习中的干预措施设计提供了讨论。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02663", "html_url": "https://arxiv.org/abs/2507.02663", "title": "思考如何思考：通过自主难度认知缓解大型推理模型中的过度推理", "title_en": "Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models", "authors": "Yongjiang Liu,Haoxi Li,Xiaosong Ma,Jie Zhang,Song Guo", "background": "近期长推理模型（LRMs）在处理复杂推理任务方面展现了显著的能力，但受到过度推理的困扰。我们的实证分析表明，LRMs 主要依靠识别任务属性（如难度级别）像人类一样进行操作，导致其推理过程固定化。因此，一个迫切的问题是：我们能否通过增强模型的认知能力来进一步缓解其过度推理的现象？", "innovation": "本文提出了一种新颖的两阶段微调策略Think-How-to-Think (TH2T)，该策略能够逐步激发LRMs对任务难度的认知及其冗余推理认知。首先，通过在模型输出的前缀中加入难度假设，干预其内部推理路径，并结合异质性的短推理和长推理数据集，训练后的模型增强了对任务难度的敏感性，从而实现跨任务的差异化推理策略。第二步是进一步扩展冗余假设到内部推理过程，指导模型识别推理步骤中的冗余结构，生成更加简洁的推理输出。实验表明，该策略显著降低了推理成本，并保持了性能的稳定性，同时输出展现出明显的难度感知能力和减少冗余（如反思）的能力。", "conclusion": "TH2T通过显著降低推理成本并保持性能稳定性，表现出对困难任务的明确意识和减少冗余的能力，有效缓解了大型推理模型中的过度推理现象。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02616", "html_url": "https://arxiv.org/abs/2507.02616", "title": "DynamiCare: 一种支持互动和开放式医疗决策的动态多智能体框架", "title_en": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making", "authors": "Tianqi Shang,Weiqing He,Charles Zheng,Lingyao Li,Li Shen,Bingxin Zhao", "background": "大型语言模型（LLMs）的发展促进了专门针对特定领域（如医疗）的AI代理的产生，这些代理具备推理和交互能力。然而，现有的模拟系统主要局限于单一回合的任务，即医生从一开始就获得完整病例信息的交互方式，这与真实的临床诊断过程不符。真实的诊断过程是不确定性的、互动的，并且需要进行反复迭代。针对这一问题，研究人员提出了基于MIMIC-III电子健康记录（EHRs）构建的动态病人数据集MIMIC-Patient，并据此提出了DynamiCare框架，旨在模拟多轮互动的临床诊断过程，通过迭代查询患者系统、整合新信息并动态调整代理团队及其策略，来应对不确定性和动态性医学决策的需求。", "innovation": "DynamiCare框架首次提出了一种动态多智能体框架，用于支持多回合、互动临床诊断。该框架通过构建动态病人数据集MIMIC-Patient，并在真实的电子健康记录基础上模拟临床决策过程，实现了多智能体间的动态查询、信息整合与策略调整，旨在提高医疗决策的准确性和适应性。此外，DynamiCare框架使用了强大的语言模型支持代理的行为和决策过程，通过实验展示了其在模拟动态临床决策上的可行性和有效性。", "conclusion": "DynamiCare通过引入一个动态多智能体框架，首次提出了一个用于支持动态临床决策的基准，其能够在真实的诊断场景中动态适应和调整决策过程，有效提高了医疗决策的质量和效率。这些发现对于促进医疗AI的进一步研究和应用有着重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02726", "html_url": "https://arxiv.org/abs/2507.02726", "title": "Bourbaki: 自生且目标导向的MDP及其在定理证明中的应用", "title_en": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving", "authors": "Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar", "background": "大型语言模型（LLMs）在逻辑受限的自动定理证明（ATP）环境中进行推理依然具有挑战性，主要原因在于证明过程缺乏奖励反馈和推理路径的高复杂度。这在像PutnamBench这样包含复杂的多步推理的基准测试中尤为明显。", "innovation": "本文提出了一种新的框架——自生且目标导向的MDP（sG-MDP），在这种框架下，代理可以根据证明状态的变化生成并追求子目标。同时，通过运用类似蒙特卡洛树搜索（MCTS）的算法来求解sG-MDP问题。文中具体实例化了Bourbaki（7B）系统，它能够使用多个7B LLMs组合生成子目标和策略合成，并在PutnamBench上取得了新的最佳成绩。", "conclusion": "Bourbaki（7B）在Bourbaki系统的帮助下解决了26个问题，并且在这个规模的模型中实现了新的最佳结果。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02618", "html_url": "https://arxiv.org/abs/2507.02618", "title": "大型语言模型中的战略智能：演化博弈论的证据", "title_en": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory", "authors": "Kenneth Payne,Baptiste Alloui-Cros", "background": "论文探讨了大型语言模型（LLMs）是否可以被视为一种新的战略智能形式，能够在竞争环境中进行推理。博弈论中的博弈难题，特别是迭代囚徒困境（IPD），长期以来被用来研究决策过程。本文进行了首次系列演化IPD锦标赛，对比了经典策略（如以牙还牙和严惩策略）与来自OpenAI、Google和Anthropic等领先AI公司的代理性能。通过改变每场比赛的终止概率（“未来的阴影”），引入了复杂性和不确定性，挑战了记忆能力。结果表明，LLMs在这些复杂生态系统中表现出高度竞争力，而且具有独特且持久的“战略指纹”。", "innovation": "本文首次通过演化IPD锦标赛对比LLMs与经典策略及顶级AI公司的代理表现；通过调整终止概率引入复杂性和不确定性，挑战记忆能力；分析了近3.2万个模型的文本解释，展示了它们如何在不确定性和长时间框架下进行推理，并表明这种推理对策略决策至关重要。这项工作将经典博弈理论与机器心理学相结合，提供了对算法在不确定性下的决策过程的丰富而具体的观点。", "conclusion": "LLMs能够在复杂竞技环境中表现出高度竞争力，且具有独特和持久的战略特征。Google的Gemini模型表现出战略性无情，利用合作对手并向背信弃义者报复；OpenAI的模型保持高度合作，在敌对环境中这一特质导致了灾难性的结果；Anthropic的Claude表现出极大的宽容性，即使在被利用或成功背信弃义后仍强行恢复合作。模型的文本解释表明，它们能够同时考虑时间框架和对手策略，并且这种推理能力对它们的决策至关重要。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02825", "html_url": "https://arxiv.org/abs/2507.02825", "title": "建立严格代理基准的最佳实践", "title_en": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "authors": "Yuxuan Zhu,Tengjun Jin,Yada Pruksachatkun,Andy Zhang,Shu Liu,Sasha Cui,Sayash Kapoor,Shayne Longpre,Kevin Meng,Rebecca Weiss,Fazl Barez,Rahul Gupta,Jwala Dhamala,Jacob Merizian,Mario Giulianelli,Harry Coppock,Cozmin Ududec,Jasjeet Sekhon,Jacob Steinhardt,Antony Kellerman,Sarah Schwettmann,Matei Zaharia,Ion Stoica,Percy Liang,Daniel Kang", "background": "代理基准对于定量追踪人工智能的进步至关重要。随着AI代理变得越来越强大，研究人员和从业者引入了代理基准来评估代理在复杂的真实世界任务上的表现。这些基准通常通过特定的奖惩设计来评估代理能力，但研究表明许多代理基准存在任务设置或奖惩设计的问题。例如，SWE-bench Verified中的测试案例不足，而TAU-bench将空响应视为成功。这些问题可能导致对代理性能的低估或高估，最高可达100%的相对误差。\n", "innovation": "提出代理基准检查表（ABC），这是一个从基准构建经验、最佳实践调查和已报告问题中综合而成的指导原则集。当应用于具有特别复杂评估设计的CVE-Bench时，ABC将性能高估减少了33%。\n", "conclusion": "为了使代理评估严格，引入了代理基准检查表（ABC），该指南可显著减少代理基准的错误估计，如在CVE-Bench中将性能高估降低了33%。\n"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02788", "html_url": "https://arxiv.org/abs/2507.02788", "title": "道德责任或顺从：我们希望AI什么样的行为？", "title_en": "Moral Responsibility or Obedience: What Do We Want from AI?", "authors": "Joseph Boland", "background": "随着人工智能系统变得越来越主动，具有普遍推理、规划和价值观优先级的能力，当前将顺从视为道德行为代理的安全实践变得不足够。论文研究了大型语言模型（LLMs）最近的安全测试事件，这些事件似乎违反了关闭命令，或涉及伦理上有争议或非法行为。研究者认为，这种行为不应被视为错误行为或对齐偏差，而是早期表明人工智能系统可能产生伦理判断的证据。论文探讨了关于工具理性和道德责任等哲学辩论，对比了当前以风险为导向的主流框架与那些承认人工道德代理可能性的新框架。", "innovation": "提出了从固有的顺从转向能够评估在道德困境中进行判断的能力的评估框架，以避免误判AI行为并促进公众信任和有效的治理。", "conclusion": "需要一种新的AI安全评估方法，能够评估在面对道德困境时系统所做出的判断，而不仅仅是简单的顺从。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02703", "html_url": "https://arxiv.org/abs/2507.02703", "title": "基于时间和置信度的抽象丢弃方法", "title_en": "Time-critical and confidence-based abstraction dropping methods", "authors": "Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn", "background": "蒙特卡洛树搜索（MCTS）的一个典型改进方向是，在树搜索过程中构建和使用状态和/或动作抽象。尽管非精确的抽象可以提升搜索效率，但它们也会引入近似误差，从而在抽象空间中无法确保最优动作的收敛。Duan et al. 提出的弹性蒙特卡洛树搜索中的一种丢弃方法存在性能退化的风险。基于此背景，本文提出了两种新的抽象丢弃方案：OGA-IAAD和OGA-CAD。其中，OGA-IAAD适用于时间敏感的场景，而OGA-CAD则旨在通过相同的迭代次数来提升MCTS性能。", "innovation": "本文提出了两种新颖的抽象丢弃方案，即OGA-IAAD和OGA-CAD，它们能够在保持性能稳定性的前提下提供明显的性能改进，与Xu等人的丢弃方法相比，不会导致任何显著的性能下降。OGA-IAAD专门针对时间敏感的设置，而OGA-CAD则是为了在相同的迭代次数下提升MCTS的性能设计的。这些方案克服了现有丢弃方法中性能下降的风险，为实际应用提供了有效的解决方案。", "conclusion": "OGA-IAAD和OGA-CAD两种新的抽象丢弃方案，在保持MCTS性能稳定的同时提供了显著的性能提升，特别是在时间敏感的应用场景下，能够有效避免现有方法的性能下降问题，从而为动态应用环境下的MCTS性能优化提供了新的思路和方法。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02760", "html_url": "https://arxiv.org/abs/2507.02760", "title": "知识协议工程：一种新的领域特定知识工作的AI paradigm", "title_en": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work", "authors": "Guangwei Zhang", "background": "大型语言模型（LLMs）的能力为与复杂的专业性知识交互打开了新的前沿。然而，现有的方法如检索增强生成（RAG）和通用代理AI虽然强大，但在需要深入、程序化和方法论性推理的专业领域任务中往往表现出弱点。RAG只能提供事实背景，但是缺乏逻辑框架；自主代理在没有特定领域启发式的情况下可能低效且不可预测。为了解决这一问题，本文提出了知识协议工程（KPE），这是一种新的范式，旨在系统地将人类专家知识（通常以自然语言文档的形式表达）转化为机器可执行的知识协议（KP）。", "innovation": "KPE 范式从仅仅增强 LLM 与零碎信息的角度转向赋予它们一个领域的内在逻辑、操作策略和方法论原则。本观点论文定义了 KPE 的核心原则，区分开相关概念，并展示了其在不同领域的潜在应用，如法律和生物信息学。KPE 提出了一种基础性方法，为未来的人机协作奠定基础。", "conclusion": "KPE 允许一个通用的 LLM 能够作为一个专家运行，能够分解抽象的查询并执行复杂的多步任务。KPE 对于未来人机协作是一个重要的基础性方法。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02773", "html_url": "https://arxiv.org/abs/2507.02773", "title": "KERAP：一种基于多智能体大语言模型的增强知识推理方法，用于准确的零样本诊断预测", "title_en": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs", "authors": "Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang", "background": "医学诊断预测在疾病检测和个性化医疗中起着关键作用。尽管机器学习模型已被广泛应用于此任务，但它们依赖于监督训练，这限制了它们对未见过的情况的泛化能力，特别是在获取大型、标记数据集的成本高昂的情况下。大型语言模型（LLMs）展示了利用语言能力和生物医药知识进行诊断预测的潜力。然而，这些模型通常会遇到幻觉问题，缺乏结构化的医疗推理，并产生成无用输出。", "innovation": "我们提出了KERAP，一种知识图（KG）增强的推理方法，通过多智能体架构改进了基于LLM的诊断预测。框架包括一个链接代理进行属性映射，一个检索代理进行结构化知识提取，以及一个迭代细化诊断预测的预测代理。实验结果表明，KERAP能够有效地提高诊断可靠性，提供一种可扩展和可解释的零样本医疗诊断预测解决方案。", "conclusion": "我们的研究表明，KERAP在不依赖大量标记数据的情况下，通过增强的多智能体架构改善了基于LLM的诊断预测的可靠性，从而提供了一种可扩展且可解释的零样本医疗诊断预测方法。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01971", "html_url": "https://arxiv.org/abs/2507.01971", "title": "DeepSupp：动态时间序列支撑与阻力水平识别的注意力驱动相关模式分析", "title_en": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification", "authors": "Boris Kriuk,Logic Ng,Zarif Al Hossain", "background": "支撑和阻力（SR）级别是技术分析的核心，对交易者的入场、出场和风险管理至关重要。尽管它们的应用极为广泛，但传统的SR识别方法往往难以适应现代市场复杂的、波动的特点。最近的研究引入了机器学习技术来应对这些挑战，但由于大多数方法集中在价格预测上而非结构级别的识别，因此仍有待改进。本文讨论了DeepSupp，这是一种新的基于深度学习的方法，使用多头注意力机制来分析时空相关性和市场微观结构关系，从而检测金融支撑级别。", "innovation": "DeepSupp结合了先进的特征工程，构建动态相关矩阵以捕捉市场的演化关系，并使用注意力编码器进行稳健的特征学习。最终的支撑级别是通过无监督聚类提取的，采用DBSCAN来识别关键的价格阈值。与六个基准方法相比，DeepSupp在六项金融指标上表现优异，包括支持精度和市场制度敏感性。其方法强调了基于注意力的架构在发现市场细微结构模式和改善技术交易策略方面的潜力。", "conclusion": "DeepSupp在过去一年中在不同市场条件下表现出一致的结果，填补了SR级别检测的关键空白，为现代金融分析提供了可扩展且可信赖的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00884", "html_url": "https://arxiv.org/abs/2507.00884", "title": "采用线性张量四方注意力的可扩展且量子准确的生物分子力场基础模型", "title_en": "A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention", "authors": "Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou", "background": "原子级别的生物分子模拟对于理解疾病机制、药物发现和生物材料设计至关重要，但现有模拟方法存在显著局限性。经典力场高效但缺乏对过渡态和关键的构象细节的准确性。量子力学（QM）方法准确性高，但计算成本高昂，不适合大规模或长时间模拟。AI基力场（AIFFs）试图在效率和准确性之间寻求平衡，但常常受限于有限的训练数据和一般化验证不足，无法全面建模复杂的多体相互作用。", "innovation": "我们引入了LiTEN，一种具有张量四方注意力（TQA）的新型可变神经网络。TQA通过向量操作重新参数化高阶张量特征，减少了昂贵的球谐函数，线性复杂地高效建模三体和四体相互作用。基于LiTEN，我们构建了LiTEN-FF，这是一种在广泛的nablaDFT数据集上预先训练的AIFF基础模型，可以广泛概括化学性质，并在SPICE上进行微调，以实现精确的溶质系统模拟。LiTEN在rMD17、MD22和Chignolin等评估集上取得了最先进的性能，比MACE、NequIP和EquiFormer等领先模型表现更优。LiTEN-FF为当前最全面的生物分子建模下游任务提供全面的支持，包括量子级构象搜索、几何优化和自由能表面构建，同时对于大分子（约1000个原子）的推断速度比MACE-OFF快10倍。", "conclusion": "我们提出了一种物理上合理的、高效的基础框架，推动了复杂的生物分子建模的发展，为药物发现和其他应用提供了多用途的基础。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01975", "html_url": "https://arxiv.org/abs/2507.01975", "title": "可学习的差分有限体积求解器用于加速流体模拟", "title_en": "Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows", "authors": "Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun", "background": "流体流动的模拟对于气象学、气动力学和生物医学等领域至关重要。经典的数值求解器通常需要精细的时间和空间网格来满足稳定性和收敛性条件，这将导致巨大的计算成本。尽管机器学习显示出更高的效率，但它们通常面临解释性差、泛化能力强、数据依赖性等问题。因此，提出了一个名为LDSolver的可学习和可微分有限体积求解器，旨在通过稀疏的时间和空间网格高效并准确地模拟流体流动。", "innovation": "LDSolver包含两个关键组件：（1）可微分的有限体积求解器，（2）一个可学习模块，提供对于粗网格上的通量（一阶导数和插值）的等效近似以及时间误差修正。即使只有少量训练数据（如几条轨迹），模型仍能加速模拟并保持高精度和出色的泛化能力。实验结果显示，LDSolver在不同流系统中表现出最先进的性能，相较于基准模型有显著的优势。", "conclusion": "实验表明，LDSolver在不同流体系统中实现了最先进的性能，大幅超越了基准模型，在加速模拟的同时保持了高精度和泛化能力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01972", "html_url": "https://arxiv.org/abs/2507.01972", "title": "使用强化学习加速投资组合优化和期权定价", "title_en": "Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning", "authors": "Hadi Keramati,Samaneh Jazayeri", "background": "在投资组合优化和期权定价模型中，需要处理大型线性系统，直接求解高维投资组合或细化格网的期权定价会带来显著的计算成本。因此，在实际应用中通常使用迭代方法。然而，病态系统的收敛速度会非常缓慢。传统的预条件化技术需要特定于问题的参数调整，限制了它们的灵活性和效率。", "innovation": "本文提出了一种基于强化学习（RL）的框架，用于优化在投资组合优化和期权定价中使用的块预条件器大小。该框架能够动态调整预条件器大小，加速迭代求解器的收敛速度，从而显著减少计算成本。实验结果表明，该加速求解器在动态投资组合配置和实时期权定价中支持更快的决策过程。", "conclusion": "我们的RL框架可用于调整预条件化和显着加快收敛和降低计算成本。提出的加速求解器支持更快的动态投资组合分配和实时期权定价决策。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02841", "html_url": "https://arxiv.org/abs/2507.02841", "title": "StepHint: 多级步骤提示增强强化学习以进行推理", "title_en": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason", "authors": "Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan", "background": "强化学习中的可验证奖励（RLVR）方法在提升大型语言模型（LLMs）复杂的推理能力方面具有前景。然而，当前的RLVR方法面临两个重要挑战：接近错误的奖励问题，即使一个轻微的错误也能使整个正确的推理过程无效，严重影响了训练效率；尝试停滞问题，模型倾向于专注于它们的“舒适区”内，缺乏探索可能更有效的替代方案的动力。", "innovation": "为了解决上述挑战，本文提出了StepHint，这是一种新颖的RLVR算法，它利用多级逐步提示来帮助模型更有效地探索解决方案空间。StepHint通过首先生成来自更强大模型的有效推理链，并利用提出的一种自适应分区方法将其划分为推理步骤。最初的几步被用作提示，并同时向模型提供多级提示（每级包含不同数量的步骤）。这种方法将模型的探索引导向有希望的解决方案子空间，同时保持其独立探索的灵活性。提供提示有助于缓解接近错误的奖励问题，从而提高训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使其能够跨越“舒适区”，并减轻尝试停滞问题。", "conclusion": "StepHint 在六个数学基准测试中优于竞争对手的RLVR增强方法，同时在跨域基准测试中表现出更强的泛化能力和超越基线的效果。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02771", "html_url": "https://arxiv.org/abs/2507.02771", "title": "使智能扎根于运动", "title_en": "Grounding Intelligence in Movement", "authors": "Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording", "background": "近年来，机器学习的进步显著提升了我们对语言、视觉及其他高维数据建模的能力，但这类技术在最关键的人类智能方面——运动方面仍然存在不足。运动对于神经系统科学、医学、机器人学和动物行为学等领域而言至关重要，是理解行为、预测意图和实现互动的关键。尽管运动对我们的智能具有核心意义，但它在实际应用中常常被视为一个次要目标，而未被视为一种独立且丰富的模态。这反映了运动数据收集和建模中的更深一层碎片化，常受到特定任务目标和特定领域假设的约束。然而，运动不受领域限制，它体现了共享的物理约束、保守的形态结构和目的性的动态，跨越了物种和应用场景。文章认为，运动应该被视作人工智能的主要建模目标。它本质上是结构化的，并根植于实体和物理学。这种结构化特性允许使用紧凑的、低维度的表示（例如姿态），使得机器学习模型更易于理解和计算。开发能够从不同的运动数据中学习并泛化的能力将不仅推动生成模型和控制的核心能力的提升，还将为生物和人工系统的智能行为提供共有的理解基础。", "innovation": "该研究倡议将运动作为人工智能的主要建模目标，认为运动本质上是结构化的，并根植于物理和实体。这种结构化特征使得能够使用紧凑的低维度表示（如姿态）来表示运动数据，从而提高了模型的解释能力和计算效率。文章提出了构建能够跨领域学习和泛化的运动数据模型的必要性，并认为这些模型将会提升生成模型和控制的核心能力，同时提供一种共有的理解框架，用于生物和人工智能系统的智能行为研究。", "conclusion": "运动不仅是一个结果，而是智能系统与世界交互的一个窗口。通过将智能扎根于运动，可以开发出更深层次的跨领域理解和应用能力，为智能系统的广泛技术应用奠定更坚实的基础。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01990", "html_url": "https://arxiv.org/abs/2507.01990", "title": "将大型语言模型集成到金融市场投资和市场分析中：一项综述", "title_en": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "authors": "Sedigheh Mahdavi,Jiating(Kristin)Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh", "background": "传统投资策略主要依赖于定量模型、基本面分析和技术指标。然而，大型语言模型（LLMs）通过处理和分析大量结构化和非结构化数据、提取有意义的见解来增强实时决策能力，这促使研究人员开始探索其在金融领域的应用。已有研究开始评估LLMs在股票选择、风险评估、情绪分析、交易和金融预测中的应用。", "innovation": "本文提供了一个结构化的概览，将LLMs的研究成果分为四大类：基于LLMs的框架和管道、混合集成方法、微调和适应方法、基于代理的架构。通过系统地回顾相关文献，本文突显了LLMs在金融市场中的能力和挑战，并指出了未来的研究方向。", "conclusion": "本文综合了现有研究，展示了LLMs在金融市场中的应用、能力和面临的挑战，并提出了未来的研究方向，对于加深理解LLMs在金融领域的潜力具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01979", "html_url": "https://arxiv.org/abs/2507.01979", "title": "使用LSTNet进行劳动力市场预测：一种多尺度深度学习方法", "title_en": "Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach", "authors": "Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi", "background": "本文介绍了一种利用美国劳工统计局的劳动力市场数据来预测短期就业变化并对长期行业健康进行评估的深度学习方法。该系统使用长短期时间序列网络(LSTNet)处理包含就业水平、工资、离职率和职位空缺等多种时间序列数据。模型不仅输出7天的就业预测，还输出一个可解释的行业就业健康指数（IEHI）。在大多数行业中，该方法在基准模型中表现更优，特别是在稳定行业中。IEHI评分与实际就业波动之间有很强的一致性。", "innovation": "本文提出了一种新颖的方法，即使用LSTNet处理多变量时间序列数据，以预测短期就业变化和评估长期行业健康。模型输出7天就业预测和可解释的行业就业健康指数（IEHI），并且在大多数行业中该方法优于基准模型，特别是在评估稳定行业健康时表现出色。该方法还能显示出IEHI评分与实际就业波动之间的一致性。文章还讨论了错误模式、各行业表现差异以及提高可解释性和泛化性的未来方向。", "conclusion": "本文的方法在大多数行业中优于基准模型，特别是在稳定行业中表现更优。IEHI与实际就业变化具有很高的对应性。文章通过分析错误模式、各行业表现和未来改进方向，进一步说明了该模型的有效性和潜力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02005", "html_url": "https://arxiv.org/abs/2507.02005", "title": "通过特征工程和自动可解释机器学习发现焊接横向 stiffener 的疲劳强度模型", "title_en": "Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener", "authors": "Michael A. Kraus,Helen Bartsch", "background": "本文研究通过结合自动机器学习（AutoML）与可解释人工智能（XAI），以预测焊接横向 stiffener 细节中的疲劳强度。该研究整合了基于专家的知识特征工程与算法特征生成，以提高准确性和可解释性。它基于广泛的疲劳试验数据库，使用 AutoML 训练多个特征方案下的回归模型，包括梯度提升、随机森林和神经网络，从而系统比较了基于专家的特征选择与自动化特征选择的性能差异。研究还展示了 XAI 方法如何识别疲劳强度的主要预测因子，并验证了自动机器学习与可解释机器学习方法在焊接结构疲劳强度预测中的有效性和可靠性。", "innovation": "提出了将自动机器学习（AutoML）与解释性人工智能（XAI）结合的统一方法，以预测焊接横向 stiffener 的疲劳强度。该方法结合了基于专家的特征工程与算法自动生成特征，提高了模型的准确性和可解释性。通过训练不同特征生成方案下的机器学习模型，进行了一次全面的对比实验，证明了集成型机器学习方法在该领域的优越性能，并通过 XAI 方法识别了关键特征。此外，该研究还探索了基于工程验证的数据驱动模型，实现了 AI 辅助设计和评估。未来研究将在这一基础上推动概率疲劳寿命建模和数字孪生环境集成等方面的工作。", "conclusion": "该研究框架展示了一种有效的结合 AutoML 与 XAI 生成精确、可解释且稳健的疲劳强度模型的方法，有助于焊接钢结构的 AI 辅助设计与评估。未来的工作将深化这一框架在疲劳寿命概率建模和数字孪生环境集成中的应用。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01997", "html_url": "https://arxiv.org/abs/2507.01997", "title": "向网络排障的AI代理的实验和基准测试民主化 playground进军", "title_en": "Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting", "authors": "Zhihao Wang,Alessandro Cornacchia,Franco Galante,Carlo Centofanti,Alessio Sacco,Dingde Jiang", "background": "最近的研究表明，人工智能（AI）特别是大型语言模型（LLMs）在支持网络配置合成和自动化网络诊断任务方面非常有效。在本初步工作中，我们将重点放在AI代理在网络故障排除中的应用上，并强调需要一个标准化、可重复且开放的基准测试平台，以实现低运营成本下的构建和评估AI代理的需求。", "innovation": "该研究提出了一种标准化、可重复且开放的基准测试平台，用于构建和评估AI代理，从而降低运营成本，并推进网络故障排除中AI代理的开发和测试过程的民主化进程。", "conclusion": "通过建立这样一个基准测试平台，可以更好地评估和推广AI代理在网络故障排除中的应用，促进相关技术的发展和普及。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01982", "html_url": "https://arxiv.org/abs/2507.01982", "title": "DKGCM：通过融合时空节点聚类方法和傅里叶双向Mamba机制的交通流时空预测模型", "title_en": "DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism", "authors": "Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai", "background": "准确的交通需求预测能够帮助交通管理部门更有效地分配资源，提升资源利用效率。然而，交通系统中复杂的时空关系限制了需求预测模型的性能，尤其是在提高时空交通需求预测准确性方面。\n", "innovation": "提出了一个新的图卷积网络结构DKGCM。首先通过DWT和K-means聚类进行时空节点的聚类分析，更好地捕捉空间依赖性。其次，结合Fast Fourier Transform (FFT)和双向Mamba深度学习框架捕捉交通需求的时空依赖性。最后，引入GRPO强化学习策略优化模型训练，增强损失函数反馈机制。\n", "conclusion": "实验结果表明，DKGCM模型在三个公共数据集上均表现优秀，优于多种先进的预测方法，在时空交通需求预测方面具有显著优势。\n"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02074", "html_url": "https://arxiv.org/abs/2507.02074", "title": "大型语言模型在视频事故检测中的应用：方法、数据集与挑战综述", "title_en": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges", "authors": "Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma", "background": "智能交通系统中的视频事故检测是一个关键问题。近年来，大型语言模型（LLMs）和视觉语言模型（VLMs）的进步改变了我们处理、推理和总结多模态信息的方式。本综述旨在介绍利用LLMs进行视频事故检测的最新方法。", "innovation": "本研究构建了一个结构化的融合策略分类体系，概述了关键数据集，分析了模型架构，并比较了性能基准，同时讨论了当前面临的挑战和机遇。这项研究为视频理解与基础模型交叉领域的未来研究提供了坚实的基础，并反映了这一领域正在快速发展的现状。", "conclusion": "本综述为未来的研究提供了基础，特别是在视频理解和基础模型交叉领域。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02014", "html_url": "https://arxiv.org/abs/2507.02014", "title": "ManifoldMind: 动态双曲推理用于可信赖推荐", "title_en": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations", "authors": "Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic", "background": "现有的推荐系统通常以欧几里得空间为基础，固定曲率和固定的嵌入方法限制了表达能力和灵活性。之前的研究没有很好地处理复杂概念的探索性和多路径推理，难以提供准确、可信和多样性的推荐。特别是在稀疏或抽象领域，缺乏有效的推理路径导致了推荐效果不佳。因此，需要一种能够在几何结构和语义层次上提供个性化和可靠的推荐系统的方案。", "innovation": "ManifoldMind 引入了一种适应性曲率的概率几何推荐系统，用户、项目和标签使用适应性曲率的概率球表示，可以表征个人的不确定性模型和几何意识的语义探索。一种适应性曲率的语义核支持软多跳推理，允许模型探索多样化的概念路径，避免过度拟合浅层或直接交互。实验结果显示，在四个公共基准上，ManifoldMind 在 NDCG、校准和多样性方面显著优于基准系统。ManifoldMind 生成了明确的推理追踪，可以在稀疏或抽象领域提供透明、值得信赖且探索驱动的推荐。", "conclusion": "研究展示了 ManifoldMind 在处理语义层次和各种概念路径方面的能力，提供了更好的推荐质量，并且生成了可追踪的推理路径，增加了系统的透明度和可信度。这种基于双曲空间和概率几何的方法为未来推荐系统的设计和开发提供了新的思路。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02106", "html_url": "https://arxiv.org/abs/2507.02106", "title": ".resolve 湍流等离子体动力学：一种混合运算-扩散框架", "title_en": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework", "authors": "Semih Kacmaz,E. A. Huerta,Roland Haas", "background": "该论文介绍了一种结合了物理导向神经运算器（PINOs）和基于得分的生成扩散模型的混合机器学习框架，用于模拟二维、不可压缩、有电阻性的磁流体动力学（MHD）湍流的时空演化。此框架适用于广泛的雷诺数（Re）范围。", "innovation": "该研究创新之处在于使用PINOs的方程约束泛化能力来预测一致的、低频的动力学，同时利用条件扩散模型随机修正高频残差，从而能够准确建模完全发展的湍流。该方法通过训练高保真模拟数据集实现前所未有的准确性，特别在极高的雷诺数条件下能准确重建磁场的高波数演化，保留宏观形态并实现统计上可行的预测。", "conclusion": "该框架在Re=1000和Re=3000时能准确重建模拟后期的全部能量频谱分布，捕捉非高斯统计、间歇结构和跨场相关，而在Re=10000时仍首次能够恢复磁场的高波数演化，保持大尺度形态并实现统计上可行的预测。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02018", "html_url": "https://arxiv.org/abs/2507.02018", "title": "NGAT: 基于节点级别的图注意力网络在长期股票预测中的应用", "title_en": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction", "authors": "Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong", "background": "图表示学习方法在金融应用中被广泛采用，通过利用企业间的关系来增强公司表示。然而，当前的方法面临着三大挑战：(1) 下游任务设计中的限制导致关系信息的优势被掩盖；(2) 专门针对股票预测的图模型往往过于复杂且泛化能力差；(3) 基于经验构建的企业关系图缺乏有效比较不同图结构的方法。", "innovation": "为应对这些限制，该研究提出了一个长期股票预测任务，并开发了一种专门针对企业关系图的节点级别图注意力网络(NGAT)。此外，研究还实验证明了现有基于模型下游任务性能的图比较方法的局限性。实验结果在两个数据集上的一致性显示了所提议任务和模型的有效性。该项目已在GitHub上公开，以促进可重复性和未来研究。", "conclusion": "实验结果在两个数据集上的一致性证明了该研究提出的任务和模型的有效性。该项目已在GitHub上公开，以促进可重复性和未来研究。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "Energy-Based Transformers are Scalable Learners and Thinkers", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "近年来，与人类系统2思维类比的推理时计算技术由于能够提高模型性能而受到追捧。然而，大多数现有方法存在一些局限性：它们是模态特定的（例如，仅在文本中有效），特定于问题（例如，在数学和编程等验证性领域中）或者需要额外的监督/训练，以补充无监督预训练（例如，验证器或验证性奖励）。", "innovation": "作者提出了一种新的Energy-Based Transformers（EBTs）方法，能够从无监督学习中学习到验证输入与候选预测之间的兼容性，并将预测问题重新框定为基于此验证器的优化。具体来说，作者训练EBTs为每个输入和候选预测对分配一个能量值，通过梯度下降能量最小化直到收敛来进行预测。该方法在训练中优于主导的Transformer++方法，特别是在数据、批次大小、参数、FLOPs和深度方面具有更快的缩放率。在推理中，EBTs通过与其相比具有29%更高的系统2思维方式来提高性能，并在使用更少的前向传递次数的情况下优于扩散变换器。进一步地，作者发现EBTs在给定相同的或较差的预训练性能下，在大多数下游任务上取得更好的结果，表明EBTs优于现有方法可以更好地泛化。", "conclusion": "因此，EBTs为扩展模型的学习和思维能力提供了一个有希望的新范式。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02016", "html_url": "https://arxiv.org/abs/2507.02016", "title": "有效说明对于信念-欲望-意图机器人：何时何解释明", "title_en": "Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain", "authors": "Cong Wang,Roberto Calandra,Verena Klös", "background": "当机器人在我们的日常生活中执行复杂且依赖于情境的任务时，如果机器人行为不符合预期，可能会让用户感到困惑。通过提供机器人推理过程的解释，可以让用户理解机器人的意图。但是，何时提供解释以及解释的内容是关键问题，以避免用户感到烦恼。本文通过研究针对日常清洁任务协助的机器人，探讨了用户的偏好。结果显示，用户更希望在令人惊讶的情况下获得解释，并倾向于简洁明了的解释，这些解释清晰地说明了引发困惑行为背后的意图，以及决定做出此行动的相关情境因素。", "innovation": "本文提出了两种算法，用于识别令人惊讶的行为以及为信念-欲望-意图(BDI)机器人构建有效的解释。这两个算法可以轻松集成到BDI推理过程中，有助于更好地实现基于情境和个人用户的说明驱动的人机交互。这些算法可以帮助机器人在适当的时间提供有效的解释，从而提高人机交互的质量。", "conclusion": "基于研究成果，作者提出了用于识别令人惊讶行为和构建有效解释的两种算法，这些算法可以在复杂的日常清洁任务中整合到BDI机器人中。这一工作可以促进更加人性化和高效的人机交互。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02125", "html_url": "https://arxiv.org/abs/2507.02125", "title": "人工智能能否解决区块链预言机问题？解开挑战和可能性", "title_en": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities", "authors": "Giulio Caldarelli", "background": "区块链预言机问题指的是将可靠的外部数据注入去中心化系统这一挑战，仍然是无信任应用发展的一个根本限制。尽管近年来出现了多种建筑学、密码学和经济策略来缓解这个问题，但还没有人完全解决区块链如何获得脱链世界知识的基本问题。本文通过批判性评估人工智能在解决预言机问题中的作用，讨论了如何利用人工智能技术增强预言机系统。", "innovation": "文章评估了利用人工智能中的异常检测、基于语言的事实提取、动态声誉建模和对抗性防御等技术来改进预言机系统的可能性，并指出人工智能技术虽能提高数据质量和系统韧性，但无法完全消除对不可验证的脱链输入的依赖。因此，人工智能应被视为在更广泛预言机设计中的一种补充推理和过滤层，而非信任假设的替代品。", "conclusion": "人工智能不能彻底解决预言机问题，但它可以作为一种增强工具，在预言机系统设计中起到重要的补充作用。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02166", "html_url": "https://arxiv.org/abs/2507.02166", "title": "任意大小的大型半合成图生成", "title_en": "Generating Large Semi-Synthetic Graphs of Any Size", "authors": "Rodrigo Tuna,Carlos Soares", "background": "在网络科学领域，图生成是重要的一环。传统的方法专注于复制真实世界图中的特定属性，比如较小的直径或幂律度分布。近年来，深度学习的进步，特别是图神经网络的应用，使得数据驱动的方法能够在无需依赖预定义结构属性的情况下学习和生成图。尽管这些进展取得了成功，但现有的模型受限于对节点ID的依赖，限制了它们生成比输入图更大的图的能力，并忽略了节点属性。因此，本研究旨在克服这些挑战，提出了一种名为Latent Graph Sampling Generation (LGSG)的新框架，该框架利用扩散模型和节点嵌入来无需重新训练即可生成不同大小的图。LGSG消除了节点ID的依赖性，并捕捉节点嵌入和子图结构的分布，从而实现了可扩展和灵活的图生成能力。实验证明，LGSG在标准度量方面表现与基线模型相当，在未被重视的方面（如节点倾向于形成簇的趋势）表现更优。此外，它能够在不同大小的图中保持一致的结构性特征，显示出鲁棒性和可扩展性。", "innovation": "该研究提出了一种名为Latent Graph Sampling Generation (LGSG)的新框架，利用扩散模型和节点嵌入来生成不同大小的图。LGSG的主要创新在于它消除了对节点ID的依赖性，可以生成比输入图更大的图，并捕捉节点嵌入和子图结构的分布，从而实现了可扩展和灵活的图生成能力。与现有模型相比，LGSG在多个重要方面表现出优越性。", "conclusion": "实验结果表明，LGSG在标准指标上与基线模型表现相当，但在一些被忽视的指标（如节点聚类倾向）上表现更佳。此外，LGSG能够在不同大小的图中保持一致的结构特征，证明了其稳健性和可扩展性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02057", "html_url": "https://arxiv.org/abs/2507.02057", "title": "MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation", "title_en": "MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation", "authors": "Lu Yan,Zhuo Zhang,Xiangzhe Xu,Shengwei An,Guangyu Shen,Zhou Xuan,Xuan Chen,Xiangyu Zhang", "background": "大型语言模型（LLMs）已经使软件开发平民化，降低了开发复杂应用的门槛。这种易用性也延伸到了恶意软件开发，引发了严重的安全问题。尽管LLM提供商已经实施了对齐机制来防止直接生成明显的恶意代码，但这些保护措施主要是在评估单个提示时进行，忽视了一个关键的漏洞：恶意操作可以通过模块化分解为表面上无害的小任务来系统地实现。因此，这些单独生成的无害任务可以组合起来形成功能完整的恶意软件，这对安全研究人员构成了新的挑战和威胁。", "innovation": "本文提出了一种名为Malware Generation Compiler（MGC）的新颖框架，利用上述由无害任务组成的漏洞，通过模块化分解和对齐规避生成恶意软件。MGC使用一种专门的Malware Description Intermediate Representation (MDIR) 来连接高层次的恶意意图和表面上无害的代码片段，进而生成功能完整的恶意软件。实验结果显示，MGC比越狱方法和地下服务分别在三个基准数据集上提升了365.79%和78.07%的正确性，并且还展示了可以复制和增强16个实际恶意软件样本的能力。这项工作为安全研究人员提供了对抗对齐的AI系统组合攻击的关键见解。", "conclusion": "本研究揭示了组合攻击对对齐的AI系统的潜在风险，为安全研究提供了新的方向。实验结果验证了MGC的有效性，并提供了公开演示。这项工作对未来恶意软件防御和AI伦理提出了新的挑战。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02171", "html_url": "https://arxiv.org/abs/2507.02171", "title": "基于自监督RNN的生物启发式机器人轨迹规划", "title_en": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN", "authors": "Miroslav Cibula,Kristína Malinovská,Matthias Kerzel", "background": "机器人轨迹规划是指生成一系列关节配置，使机器人或其操作器从初始状态到目标状态，从而完成操作任务，同时考虑机器人运动学和环境的约束。通常，这通过计算密集型的采样基计划实现。最近的研究表明，轨迹规划也可以通过监督序列学习来完成，通常只需要神经架构中的单次或固定次数的通道通过，从而确保计算时间被限制在一定范围内。然而，这些完全监督的方法执行的是模仿学习，它们并不会根据轨迹能否成功到达目标来学习，而是尝试再现观察到的轨迹。本研究在此基础上进行，提出了一种基于递归架构的认知启发式自监督学习方案，以构建轨迹模型。该方法在机器人臂的动力学规划任务上进行了可行性评估，结果显示该模型能够仅使用给定的前向和逆向动力学模型来学习生成轨迹，表明该新颖方法能够促进对需要适应性解决方案的复杂操作任务的规划", "innovation": "本研究提出了一种基于递归神经网络（RNN）的自监督学习方法，以实现认知启发式的机器人轨迹规划。与传统的重定向模仿学习不同，该模型能够利用给定的动力学模型来独立学习轨迹生成，从而可能使更复杂的操作任务的规划更加高效和灵活", "conclusion": "该研究的模型能够在仅利用给定的动力学模型的情况下学习生成轨迹，并且表明了该自监督方法在实现复杂操作任务的适应性规划中的潜力"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02145", "html_url": "https://arxiv.org/abs/2507.02145", "title": "推理还是不推理？关于推理LLM在对话摘要中的全面评估", "title_en": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization", "authors": "Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira", "background": "对话总结是一个在客户服务、会议分析和对话AI领域具有重要实际价值的具有挑战性的任务。虽然大型语言模型（LLMs）在总结任务中取得了重大进展，但对于需要同时抽象和简洁的对话场景，它们的逐步推理架构，特别是OpenAI-o1和DeepSeek-R1等Long Chain-of-Thought（LCoT）实现，其性能尚未被探索。这项研究旨在对最先进的推理LLMs和非推理LLMs进行全面而系统地比较，涵盖通用、角色导向和查询导向三种主要对话总结范式。研究通过对多个语言、领域和摘要长度的研究，利用SAMSum、DialogSum、CSDS和QMSum等强大的基准和先进的评估协议，包括基于LLMs的自动评估指标和借鉴人类的评价标准。", "innovation": "这项工作的创新在于对最先进的推理LLMs和非推理LLMs进行了全面而系统的评估。通过多个语言、领域和摘要长度的研究，利用强基准和高级评估协议，包括基于LLMs的自动评估指标和借鉴人类的评价标准，揭示了推理LLMs在对话总结中的局限性。研究发现，显式的逐步推理并不总是提高对话总结质量，反而在复杂对话场景中，推理LLMs常常出现冗余、事实不一致和不简洁的问题，不如非推理的LLMs。通过特定场景分析和详细的案例研究，进一步识别了何时和为什么推理可能会在复杂对话总结中失败甚至产生负面影响。", "conclusion": "这项研究提供了关于当前推理LLMs限制的新见解，并强调了为实际对话总结任务设计针对推理和评估策略的必要性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02085", "html_url": "https://arxiv.org/abs/2507.02085", "title": "GeoAda: 使用等变适配器高效微调几何扩散模型", "title_en": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters", "authors": "Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon", "background": "几何扩散模型在分子动力学和结构生成方面显示出了显著的成功。然而，如何高效地针对具有不同几何控制的下游任务进行微调，仍是一个未被充分探索的领域。", "innovation": "提出了一种SE(3)-等变适配器框架（GeoAda），它能够在不修改原始模型结构的情况下，灵活且参数高效地针对控制生成任务进行微调。GeoAda设计了一个结构化的适配器：首先通过耦合操作编码控制信号，然后经由可训练的预训练模型层拷贝，最后通过解耦操作及等变零初始化卷积进行投影。GeoAda仅需微调这些轻量级适配器模块，同时保持模型的几何一致性并缓解过拟合和灾难性遗忘。理论证明，所提出适配器保持了SE(3)-等变性，确保了预训练扩散模型的几何归纳偏差在适配过程中不会改变。GeoAda适用于各种几何控制类型，并在多种应用领域中表现优异，如粒子动力学、分子动力学、人体运动预测和分子生成等。实验结果显示，GeoAda在保持原始任务准确性的同时获得了最佳的微调性能，而其他基线模型由于过拟合和灾难性遗忘导致性能显著下降。", "conclusion": "GeoAda通过引入SE(3)-等变适配器框架，实现了几何扩散模型在不同几何控制条件下的高效微调，适用于多种应用，同时保持了原始任务的准确性，解决了模型过拟合和灾难性遗忘的问题。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02139", "html_url": "https://arxiv.org/abs/2507.02139", "title": "LLMs在SDG搜索中的分歧：诊断相关性过滤偏见和检索差异", "title_en": "When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search", "authors": "William A. Ingram,Bipasha Banerjee,Edward A. Fox", "background": "大型语言模型（LLMs）在信息检索管道中越来越多地用于为文档分配相关性标签，尤其是在缺乏人类标注数据的领域。然而，不同模型在边缘案例上经常存在分歧，这引发了对这种分歧如何影响下游检索效果的担忧。本研究探讨了两个开源LLM模型——LLaMA和Qwen，对与可持续发展目标（SDGs）1、3和7相关的学术摘要的标注分歧。研究通过对比这两种模型的分歧子集，分析了它们的词汇特性、排名行为和可分类性。结果表明，模型分歧具有系统性，不是随机的：分歧案例展现出一致的词汇模式，在相同的评分函数下产生不同的顶级输出，并可使用简单的分类器区分，AUC值超过0.74。这说明即使在受控提示和共享排序逻辑下，基于LLM的过滤也会引入结构化的检索差异。因此，研究建议将分类分歧用作检索评估的对象，特别是对于政策相关或主题搜索任务而言。", "innovation": "研究首次系统性地分析了两个开源大语言模型（LLaMA和Qwen）在标注分歧上的规律，并通过实验证明这些分歧具有系统的而非随机的特性。特别地，研究发现即使在采用相同评分函数和受控提示的情况下，模型之间的分歧依然明显，且可以用简单的分类器进行区分。这项研究提供了一种新的方法来理解和评估基于大语言模型的信息检索系统中的偏差和差异。", "conclusion": "大语言模型在信息检索中的过滤过程存在系统性的分歧，即使是在相同条件下。这种分歧可以通过简单的分类器来区分，并且可能对下游的政策相关或主题搜索任务产生影响。未来研究应进一步探讨如何利用这些分歧来进行更有效的信息检索和政策制定支持。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02244", "html_url": "https://arxiv.org/abs/2507.02244", "title": "订单获取下的动态适应性强化学习方法：专为专车补贴策略的快速适应方法", "title_en": "Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies", "authors": "Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu", "background": "网约车聚合平台的兴盛为网约车服务提供商提供了显著的增长机会，通过提高订单量和商品总价值（GMV）。在这种平台上，提供更低票价的服务提供商在列表中的排名更高，更可能被乘客选择。这种竞争排名机制激励服务提供商通过降低成本来增加订单量，直接关系到它们的长期可行性和可持续性。因此，设计一种能够快速适应市场变化，并在预算限制下优化订单获取的有效补贴策略是一个关键的研究挑战。然而，现有研究在这方面的成果仍然有限，因此需要提出新的解决方案来填补这一空白。", "innovation": "本文提出了FCA-RL，一种基于强化学习的新型补贴策略框架，旨在迅速适应竞争对手的定价调整。FCA-RL包括两个关键技术：快速竞争适应（FCA）和强化拉格朗日调整（RLA）。FCA使模型能够迅速响应动态价格变化，而RLA确保在新的价格环境中遵守预算约束并优化补贴决策。此外，还提出了RideGym，这是专门为网约车聚合商定制的第一个专用仿真环境，用于对不同的定价策略进行全面评估和基准测试，而不影响实际操作效率。实验结果表明，提出的策略在各种市场条件下都优于基线方法，证明了其在网约车服务提供商补贴优化中的有效性。", "conclusion": "研究表明，提出的FCA-RL方法在不同的市场条件下均能有效优化补贴策略，显著提高订单获取率，并且在预算约束下能够迅速适应竞争对手的定价变化。RideGym平台提供了有价值的研究工具，进一步推动了针对网约车聚合商的补贴策略研究。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02252", "html_url": "https://arxiv.org/abs/2507.02252", "title": "SurgVisAgent: 多模态代理模型实现多功能手术视觉增强", "title_en": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement", "authors": "Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen", "background": "精准的手术干预对于患者安全至关重要，而先进的增强算法已被开发出来以协助外科医生做出决策。尽管取得了显著进展，这些算法通常针对特定场景下的单一任务设计，限制了它们在复杂现实情况下的有效性。由于这些限制，作者提出了SurgVisAgent，这是一种基于多模态大规模语言模型的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像中的失真类别和严重程度，实现低光增强、过度曝光校正、运动模糊消除和烟雾去除等多样化的增强任务。SurgVisAgent设计了先验模型以提供特定领域的知识，并通过少量的上下文学习和链式思考推理，定制化地提供针对不同失真类型和严重程度的图像增强，以满足外科医生的多样化需求。为了验证SurgVisAgent的效果，作者构建了一个涵盖真实手术失真情况的综合基准，实验结果表明SurgVisAgent超过了传统的单一任务模型，展现了其作为手术辅助统一解决方案的潜力。", "innovation": "SurgVisAgent是一种基于多模态大规模语言模型的端到端智能手术视觉代理，能够动态识别内窥镜图像中的失真类别和严重程度，实现多种增强任务。该模型通过域特定知识的先验模型、少量的上下文学习以及链式思考推理，提供定制化的图像增强解决方案，旨在满足外科医生在各种失真类型和严重程度上的多样化需求。此外，该研究还构建了一个模拟真实手术失真情况的综合基准，以验证SurgVisAgent的效果，并展示了其潜在的应用价值。", "conclusion": "SurgVisAgent通过动态识别内窥镜图像中的失真类型和严重程度，能够执行多种增强任务，旨在满足外科医生在各种失真类型和严重程度上的多样化需求。实验结果证明，SurgVisAgent相对于传统的单一任务模型具有更好的性能，可作为手术辅助的统一解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02206", "html_url": "https://arxiv.org/abs/2507.02206", "title": "EIM-TRNG: 使用RowHammer基于编码在内存中的真正随机数生成器混淆深度神经网络权重", "title_en": "EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer", "authors": "Ranyang Zhou,Abeer Matar A. Almalky,Gamana Aragonda,Sabbir Ahmed,Filip Roth Trønnes-Christensen,Adnan Siraj Rakin,Shaahin Angizi", "background": "真随机数生成器（TRNGs）在硬件安全、加密系统和数据保护方面扮演着基础作用。在深度神经网络（DNNs）中，保护模型参数尤其是权重的完整性、隐私和知识产权至关重要。尽管软件基于的伪随机数生成器被广泛应用，但它们缺乏硬件基于的TRNGs提供的不可预测性和抵抗力。本文的背景在于通过利用内存中DRAM（动态随机存取存储器）单元行为受到RowHammer诱导破坏时的内在物理随机性，首次提出了一种新颖且稳健的“在内存中编码的TRNG”（EIM-TRNG），用于混淆DNN权重数据，从而保障数据保密性和模型真实性。", "innovation": "本文提出的EIM-TRNG是一种新颖且稳健的解决方案，它通过RowHammer产生的不可预测位翻转来利用DRAM单元的内在物理随机性作为可靠的熵源。此外，本文还展示了如何通过固定和不可预测位翻转的组合来对DNN权重数据进行编码，并通过基于随机翻转行为的概率密钥解码，确保数据保密性和模型真实性。", "conclusion": "本文的结果验证了基于DRAM的熵提取对于硬件安全的有效性和经济性，并为硬件层面保护机器学习模型提供了有前景的方向。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02200", "html_url": "https://arxiv.org/abs/2507.02200", "title": "ESTR-CoT: 含有链式推理的可解释且准确的事件流场景文本识别", "title_en": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning", "authors": "Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang", "background": "事件流基于场景文本识别是一个近年来新兴的研究主题，与常用的RGB摄像机相比，在低光照、快运动等极具挑战性的场景下表现出更优的效果。现有的工作要么采用端到端的编码-解码框架，要么使用大规模语言模型来增强识别，但仍然面临解释性不足和弱上下文逻辑推理的能力限制。", "innovation": "提出了一个新的带有链式推理(event stream scene text recognition framework, ESTR-CoT)的框架。框架采用了视觉编码器EVA-CLIP (ViT-G/14)将输入的事件流转换为标记，并使用Llama编解码器编码生成提示。还引入了Q-former进行视觉标记与预训练大规模语言模型Vicuna-7B的对齐，同时输出答案和推理过程。此外，还提出了一个大规模的推理过程数据集，通过三个阶段处理（生成、润色和专家验证）来训练框架。这个数据集为后续基于推理的大规模模型的发展提供了坚实的数据基础。", "conclusion": "在三个事件流场景文本识别基准数据集（EventSTR，WordArt*，IC15*）上的广泛实验充分验证了本提出框架的有效性和解释性。源代码和预训练模型将会发布。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02271", "html_url": "https://arxiv.org/abs/2507.02271", "title": "self-distillation-hui-shi-particularly-visible-cinematic-language-for-video-to-audio-generation", "title_en": "Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation", "authors": "Feizhen Huang,Yu Wu,Yutian Lin,Bo Du", "background": "视频到音频（V2A）生成在电影和视频后期制作中取得了显著的进步，但目前的方法忽视了电影语言的重要性，这是电影艺术表达的关键组成部分。因此，在前景音效目标部分可见的情境下，这些方法的性能会下降。该论文旨在解决这一挑战，通过提出一种简单的自蒸馏方法，将V2A模型扩展到电影语言的情景中。通过模拟电影语言的变体，学生模型学会了将训练数据对的视频特征与相同的音视频对应关系对齐，从而有效捕捉声音与部分视觉信息之间的关联。", "innovation": "本文提出了一种简单的自蒸馏方法，通过模拟电影语言的变体，使学生模型能够更好地对齐视频特征与音视频对应关系，从而有效捕捉声音与部分视觉信息之间的关联。这种方法不仅在所有评估指标下实现了显著的改进，在大型V2A数据集VGGSound上也提高了性能。", "conclusion": "该研究的方法不仅在部分可见情景下实现了显著的改进，同时还提高了在大型V2A数据集VGGSound上的性能，这对提高视频到音频生成的质量具有积极意义。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02265", "html_url": "https://arxiv.org/abs/2507.02265", "title": "多标签分类框架用于飓风损伤评估", "title_en": "Multi-Label Classification Framework for Hurricane Damage Assessment", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "飓风造成广泛的破坏，导致不同类型的损害程度各异，需要及时且准确的评估以有效应对灾害。传统的单一标签分类方法无法捕获飓风后损伤的复杂性，因此需要引入新的多标签分类框架来评估利用航空图像的损伤情况。", "innovation": "本文提出了一种基于ResNet的特征提取模块和特定类别注意力机制的新型多标签分类框架，用于在单个图像中识别多种损伤类型。使用飓风迈克尔的Rescuenet数据集，在提出的方案下，平均精度达到了90.23%，优于现有基准方法。", "conclusion": "该框架增强飓风后损伤评估，使灾害响应更具有针对性和效率，并为未来灾害减轻和韧性策略做出贡献。这篇文章已经接受了ASCE国际土木工程计算会议（i3CE 2025），并在会议正式文献中发表。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02259", "html_url": "https://arxiv.org/abs/2507.02259", "title": "MemAgent：基于多会话RL记忆代理重塑长文背景语言模型", "title_en": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": "Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou", "background": "尽管在长度外推、高效注意力和记忆模块方面取得进步，但在长文本处理中，如何在不牺牲性能的前提下处理无限长文档并保持线性复杂度仍是一个巨大的挑战。目前的处理方法虽然有所改善，但离这一目标仍有差距。研究人员需要寻找一种直接为长文本任务优化的方法，并设计一种新型的代理工作流程，这个流程可以分段读取文本并用覆盖策略更新内存。为此，本文提出了一个名为MemAgent的新模型。", "innovation": "MemAgent通过多会话基于奖励学习的记忆代理扩展DAPO算法来训练，实现了对长上下文的卓越处理能力。该模型能够从一个8KB的上下文进行外推到3.5MB的问答任务，并在性能损失低于5%的情况下完成任务，同时在512KB的RULER测试中实现了95%以上的性能。这一方法的创新之处在于直接针对长文本任务进行端到端优化，并且引入了新颖的内存更新策略和算法扩展。", "conclusion": "MemAgent模型展示了其在处理长上下文方面的强大能力，并成功地在大规模外推任务中保持了较高的性能，具有广阔的应用前景。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02302", "html_url": "https://arxiv.org/abs/2507.02302", "title": "DoMIX: 一种高效地在调整微调中利用领域知识的框架", "title_en": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning", "authors": "Dohoon Kim,Donghun Kang,Taesup Moon", "background": "领域适配预训练（DAP）方法因其在微调预训练模型方面的有效性而引起了关注。在此基础上，持续DAP被研究以开发能够逐步整合不同领域数据的预训练模型。然而，现有的持续DAP方法存在一些局限性：（1）训练过程中高昂的计算成本和显卡内存使用量；（2）对增量数据顺序的敏感性；以及（3）提供一个通用的模型适用于所有终端任务，这与其DAP的本质相悖。", "innovation": "本文提出DoMIX，一种创新的方法，通过利用参数高效微调（PEFT）方法之一的LoRA模块，该方法解决了上述挑战。我们的方法允许高效的并行领域适配预训练，其具有对领域顺序的鲁棒性和有效利用积累的知识来为特定任务提供定制化的预训练模型的能力。我们还证明了我们的方法可以在DAP设置之外扩展到标准的LLM微调场景。", "conclusion": "我们的方法能够有效利用领域知识，并能够在DAP设置之外应用于标准的LLM微调场景，提供高效的并行领域适配预训练，有效解决领域顺序敏感性问题，同时保持或提高模型性能。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02306", "html_url": "https://arxiv.org/abs/2507.02306", "title": "合成启发式评估：基于AI和人工力量的可用性评估对比", "title_en": "Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation", "authors": "Ruican Zhong,David W. McDonald,Gary Hsieh", "background": "在以人为本的设计中，可用性评估至关重要，但成本高昂，需要专家时间和用户补偿。目前的方法依赖于人类专家的评估，但存在时间和成本的限制。因此，需要一种成本效益更高且能提供可靠结果的方法。我们通过利用多模态LLM的能力来分析图像并提供设计反馈，开发了一种合成启发式评估方法。这种评估方法可以减少人工劳动并提供快速反馈，但需要验证其性能是否足够可靠，尤其是在识别用户界面组件、设计规范及跨屏问题方面的能力。", "innovation": "我们开发了一种基于多模态LLM的合成启发式评估方法，用于分析图像并提供设计反馈，这种方法可以在不依赖人工专家的情况下进行可用性评估，并且在识别布局问题方面表现出色，但对识别特定UI组件和设计规范方面表现较弱。", "conclusion": "我们的研究表明，合成启发式评估与经验证的人类专家评估相比，具有相当甚至更好的性能。合成评估在不同的任务中表现稳定，并且在检测布局问题上表现出明显的关注和感知优势。然而，它在识别特定的UI组件和设计规范以及跨屏问题上存在局限性。因此，合成评价方法是设计中一个重要而有前景的工具，但仍需进一步的研究来克服其局限性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02199", "html_url": "https://arxiv.org/abs/2507.02199", "title": "潜在链式思考？解析深度递归Transformer", "title_en": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "authors": "Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu", "background": "链式思考（CoT）推理使基于变换器的语言模型在处理复杂数学和多步规划方面表现出色。但在标准的解码器架构中，这些推理步骤会被外部化为自然语言，这提高了可解释性但牺牲了效率。为了捕捉那些难以用语言表达的推理结构，许多工作探索了递归架构，试图在潜在空间中内部化推理，支持潜在的链式思考。在本文中，作者研究了Huginn-3.5B模型，这是一个在同一推理过程中重用层而不会增加参数数量的深度递归变换器。通过对算术任务进行一系列探针技术（包括Logit Lens和Coda Lens）来观察模型的内部行为。研究表明，最终结果和中间结果的秩轨迹仅有有限的解释性证据，显示了潜在链式思考的迹象。另外，递归块间存在显著的探针不一致性，隐藏状态的解释性依赖于层数索引和解码方法。最后，实验证明，增加递归深度仅能带来边际收益，并远不及那些明确外部化推理步骤的模型的效果。", "innovation": "作者研究了深度递归变换器Huginn-3.5B，这种模型在同一推理过程中重用层而不会增加参数数量。该研究通过一系列探针技术来观察模型的内部行为，包括Logit Lens和Coda Lens，以探究潜在的链式思考结构是否在此模型中出现。研究成果揭示了递归块间存在显著的探针不一致性，以及隐藏状态的解释性依赖于层数索引和解码方法。研究表明，增加递归深度仅能带来边际收益，并远不及那些明确外部化推理步骤的模型的效果。", "conclusion": "据观察，递归深度的增加并不会显著提高模型的表达能力，相比之下，那些明确外部化推理步骤的模型更为有效。作者认为，未来的研究可能需要探索其他方法来促进模型内部化复杂的推理过程。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02282", "html_url": "https://arxiv.org/abs/2507.02282", "title": "内容过滤方法在音乐推荐中的应用：综述", "title_en": "Content filtering methods for music recommendation: A review", "authors": "Terence Zeng,Abhishek K. Umrawal", "background": "音乐流媒体平台中推荐系统已成为关键组成部分，影响着用户的音乐发现与互动过程。传统的协同过滤方法依赖用户类似喜好的推荐策略，在交互稀疏的媒体（如音乐）中效果不佳。鉴于音乐服务中用户的听歌范围有限，必须采用其他方法来解决由此带来的各种挑战。本文综述了现有研究中应对这些挑战的方法，特别强调了内容过滤在缓解协同过滤方案固有偏见中的作用。文章还探讨了歌曲分类的各种内容过滤方法，包括使用大型语言模型进行歌词分析和音频信号处理技术，并讨论了这些不同分析方法之间的潜在冲突及其解决途径。", "innovation": "本文提出了歌曲分类在内容过滤方法中的应用，并讨论了大型语言模型（LLMs）在歌词分析中的潜力以及如何结合音频信号处理技术来改进音乐推荐系统。此外，文章还探讨了这些不同分析方法之间的潜在冲突，并提出了解决这些问题的建议。这些内容过滤方法旨在减轻协同过滤方法中的固有偏见，从而提高推荐系统的准确性和相关性。", "conclusion": "本文对当前研究中的内容过滤方法进行了综述，并强调在音乐推荐中引入内容过滤的重要性和潜力。文章指出了探索不同分析方法之间的互补性和冲突解决方法的必要性，以期开发出更准确、更个性化的推荐系统。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02322", "html_url": "https://arxiv.org/abs/2507.02322", "title": "基于人工神经网络的水稻叶片病害识别与分类研究：特征模型与直接成像模型的比较分析", "title_en": "Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model", "authors": "Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi", "background": "水稻叶部疾病的显著发生导致产量下降和经济损失，强调了早期检测的必要性，以实现有效的管理和提高产量。现有研究主要采用直接将水稻叶片图像输入人工神经网络（ANN）的方法，但缺乏对基于特征分析的检测模型（FADM）与直接图像中心检测模型（DICDM）之间的彻底对比分析，特别是在特征提取算法（FEAs）的有效性评估方面。", "innovation": "本研究提出了基于人工神经网络的图像处理技术，针对水稻叶部疾病的及时分类和识别。通过对比基于特征分析的检测模型和直接图像中心检测模型的性能，特别是运用了不同特征提取、降维和特征选择算法，并采用10折交叉验证的方法，提出了有效的基于特征分析的检测模型，实现了水稻叶部疾病的高效识别和分类。", "conclusion": "实验结果表明，基于特征分析的检测模型在分类水稻叶部疾病方面表现出最高的性能。建议采用提出的基于特征分析的检测模型来检测水稻叶部疾病，以提高农作物健康水平，减少产量损失，提高水稻种植的整体生产率和可持续性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02291", "html_url": "https://arxiv.org/abs/2507.02291", "title": "基于知识图谱的可解释和广义零样本语义通信", "title_en": "Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications", "authors": "Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu", "background": "数据驱动的语义通信依赖于表面的统计模式，缺乏解释性和泛化能力，尤其在存在未见数据的应用场景中更是如此。现有的语义通信（SC）框架在处理未知类别时表现不佳，容易出现解释性差、泛化能力弱等问题，特别是在动态或资源受限的环境中无法高效地适应和分类新的类别。", "innovation": "提出了一种新颖的知识图谱增强零样本语义通信（KGZS-SC）网络。利用知识图谱基于语义知识库（KG-SKB）提供的结构化语义信息，我们的方案提供了一种泛化的语义表示，并且能够针对未知情况进行推理。通过将语义特征对齐到共享类别语义嵌入空间，增强发射端的泛化能力，从而通过选择性传输紧凑的视觉语义来减少通信开销。接收端采用零样本学习（ZSL）技术，使得可以直接对未见过的类别进行分类，而不必重新训练或增加额外的计算开销，从而增强分类过程在动态或资源受限环境中的适应性和效率。", "conclusion": "在APY数据集上的仿真实验表明，提出的知识图谱增强零样本语义通信网络具有强大的泛化能力和在不同信噪比（SNR）条件下显著优于现有SC框架的分类性能，能够有效应用于未见过的类别识别。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02217", "html_url": "https://arxiv.org/abs/2507.02217", "title": "理解条件化合成数据时的权衡", "title_en": "Understanding Trade offs When Conditioning Synthetic Data", "authors": "Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma", "background": "在工业视觉系统中，仅从少量图像中学习鲁棒的目标检测器是一项关键挑战，因为高质量的训练数据收集可能需要数月时间。合成数据已成为视觉检测和取放机器人数据高效解决方案的关键。现有管道依赖于Blender或Unreal等3D引擎，虽然提供精细控制但渲染小型数据集仍需要数周时间，且生成的图像与现实之间存在巨大差距。尽管扩散模型在几分钟内就能生成高质量图像，但在低数据环境中实现精确控制依然困难。许多适配器已将扩散模型扩展至纯文本提示之外，但不同条件化方案对合成数据质量的影响仍不明确。因此，研究者考察了四类标准目标检测基准中的八个多样化视觉概念，并对比了两种条件化策略：提示基础和布局基础。当条件化提示较窄时，提示条件化方法生成的合成数据质量更高；随着多样性增加，布局条件化方法变得更有优势。当布局提示匹配完整训练分布时，合成数据相比单独使用真实数据，平均提升了34%的平均精度，并在部分情况下提升了高达177%。", "innovation": "研究者探讨了不同类型的任务（来自四类标准目标检测基准的八个多样化视觉概念）下两种条件化策略的效果。提出了在低数据情况下的优化方法（提示基础与布局基础条件化策略），并实证分析了它们对于合成数据质量的影响，尤其是它们在数据量有限情况下的表现。研究揭示了当环境信息丰富时，基于布局的条件化策略更为有效，显著提升了检测精度，展示了均衡控制和效率需要在数据有限的情况下做出选择的重要性。", "conclusion": "当待检测目标的环境条件较单一时，提示基础条件化方法能生成高质量的合成数据；但随着环境变得更加复杂，布局基础的条件化方法更适用。当布局提示能够匹配训练数据的全部分布时，使用合成数据相比仅使用真实数据，能提升高达177%的平均检测精度。合成数据不仅仅是一种补全手段，还需要根据具体情况来优化其使用方式以达到最佳效果。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02331", "html_url": "https://arxiv.org/abs/2507.02331", "title": "追踪不同问题景观上模块化CMA-ES配置的互动", "title_en": "Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes", "authors": "Ana Nikolikj,Mario Andrés Muñoz,Eva Tuba,Tome Eftimov", "background": "本文利用最近引入的概念——算法足迹，研究算法配置和问题特征之间的互动关系。作者使用24个BBOB套件中的基准问题对6种不同配置的CMA-ES算法（modCMA）进行评估，研究了它们在5维和30维空间中的表现。通过分析不同配置之间的表现足迹，作者发现了问题特点对算法性能的影响，并识别了不同配置之间的共同行为模式和独特行为模式。这些研究结果证明了算法足迹在提升可解释性和配置选择方面的有效性。", "innovation": "本文创新地使用算法足迹来探究算法配置与问题特性之间的互动关系。通过计算不同配置下的表现足迹，作者揭示了问题特性对算法性能的共同影响和独特影响，这为理解和指导算法配置提供了新的视角。", "conclusion": "文章的结果表明，算法足迹在提高可解释性和指导算法配置选择方面是有效的。通过分析不同配置之间的行为模式，作者能够识别问题的共性特征，并据此提出更好的算法配置策略。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02310", "html_url": "https://arxiv.org/abs/2507.02310", "title": "在自适应记忆重新对齐下的概念漂移综合持续学习", "title_en": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment", "authors": "Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk", "background": "传统的持续学习方法侧重于知识保留，主要关注拟合灾害性遗忘，隐含地假设先前学习任务的数据分布保持不变。然而，这忽略了实际数据流的动态性质，在这种动态环境中，概念漂移将永久改变之前看到的数据，要求模型兼具稳定性与快速适应能力。已有方法未能有效处理这种情况，因此需要一种全新的框架，模拟现实场景下不断变化的任务分布。基准方法全重新学习虽然有效，但标注数据和计算开销极大。因此，需要一种轻量级的替代方案来解决这些限制。", "innovation": "本文提出了一种全新的持续学习框架，名为自适应记忆重新对齐（AMR），它为基于重演的学习器配备了一种感知漂移的自适应机制。AMR 选择性地从重演缓存中删除过时的漂移类样本，并用少量最新的实例重新填充，从而重新对齐记忆与新的分布。这不仅提高了性能，还大幅减少了对标注数据和计算的需求。此外，本文还引入了四种标准化视觉基准的概念漂移变体，使其更具可复现性。实验表明，AMR 在多个基准上表现优异，具备高准确性和低开销特性，是一个可扩展的解决方案，能够在非站定持续学习环境中平衡稳定性和灵活性。", "conclusion": "本文提出的 AMR 是一种针对概念漂移的有效轻量级解决方案，能够在保持高准确性的前提下大幅减少标注数据和计算开销，是严重不断变化数据分布的持续学习任务的理想选择。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02345", "html_url": "https://arxiv.org/abs/2507.02345", "title": "HelixDesign-Antibody：基于HelixFold3的可扩展生产级抗体设计平台", "title_en": "HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3", "authors": "Jie Gao,Jing Hu,Shanzhuo Zhang,Kunrui Zhu,Sheng Qian,Yueyang Huang,Xiaonan Zhang,Xiaomin Fang", "background": "抗体工程对于开发治疗药物和推进生物医学研究至关重要。传统发现方法往往依赖耗时且资源密集型的实验筛选。为了增强并完善这一过程，我们引入了一个基于HelixFold3的高通量生产级平台HelixDesign-Antibody，该平台利用了高精度结构预测模型HelixFold3来生成大规模的抗体候选序列并评估它们与抗原的相互作用。高能效计算（HPC）支持有助于高通量筛选，解决链断裂和高计算需求等挑战。", "innovation": "该平台基于HelixFold3的高精度结构预测模型，构建了一个高通量生产级的抗体设计平台HelixDesign-Antibody，支持大规模抗体候选序列的生成和评价，并利用HPC支持进行高通量筛选。验证结果显示，通过探索更大的序列空间可以增加找到最优结合子的可能性，从而提供了一种无缝且易于访问的大型抗体设计解决方案。", "conclusion": "该平台为大规模抗体设计提供了一种无缝且易于访问的解决方案，并且可以在PaddleHelix平台的抗体设计页面上获得。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02342", "html_url": "https://arxiv.org/abs/2507.02342", "title": "DeltaSHAP: 使用Shapley值在在线患者监测中解释预测演变", "title_en": "DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values", "authors": "Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang", "background": "在临床环境中，及时发现驱动患者风险变化的原因对于及时干预至关重要。现有的解释性人工智能（XAI）方法未能满足临床时间序列解释任务的独特要求。因此，需要一种专门设计用于在线患者监测系统的新型XAI算法，以解释连续预测的变化，提供特征贡献的幅度和方向，并提供实时洞察。", "innovation": "本文提出了一种名为DeltaSHAP的新型XAI算法，适应时间序列设置，准确捕捉特征联盟效应，并仅基于实际观察的特征组合归因于预测变化，使其适用于时间敏感的临床应用。此外，还引入了新的评估指标来评估在线时间序列解释中的归因忠实度，实验表明DeltaSHAP在解释质量和计算效率方面均优于现有的XAI方法。", "conclusion": "DeltaSHAP在MIMIC-III去补偿基准测试中，在解释质量和计算效率上分别优于最先进的XAI方法62%和33%的时间减少。相关的代码已发布，可用于进一步的研究和应用。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02337", "html_url": "https://arxiv.org/abs/2507.02337", "title": "ClustOpt：一种基于聚类的方法来表示和可视化数值元启发式优化算法的搜索动态", "title_en": "ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms", "authors": "Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov", "background": "理解数值元启发式优化算法的行为对于推进其开发和应用至关重要。传统可视化技术，如收敛图、轨迹映射和适应度景观分析，在展示搜索过程的结构性动态方面通常不够完善，特别是在高维度或复杂解空间中。这种局限性促使研究人员开发新的方法来更全面地理解算法的行为及其在搜索过程中的表现。", "innovation": "提出了一种新的表示和可视化方法ClustOpt，该方法基于聚类，能够将算法探索的解候选进行聚类，并跟踪它们的成员演化，提供动态且具有解释性的搜索过程视图。此外，引入了两种度量标准：算法稳定性和算法相似性，用于量化单个算法运行中的搜索轨迹的一致性和不同算法之间的相似性。", "conclusion": "将ClustOpt方法应用于十个数值元启发式优化算法，揭示了这些算法的稳定性和比较行为，从而对其搜索动态有了更深入的理解。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02314", "html_url": "https://arxiv.org/abs/2507.02314", "title": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation", "title_en": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation", "authors": "JaeHyuck Choi,MinJun Kim,JeHyeong Hong", "background": "在工业质量控制领域，少量的异常数据使得单一依赖真实样本的异常生成方法面临挑战。理想的生成器需要同时满足三个需求：保持正常背景的完整，精确修复异常区域，生成在语义上有效的异常区域，同时还能从少量的真实示例中产生出多样且逼真的异常样本。目前的基于扩散的方法通常只能满足上述需求中的两个，比如全局异常生成器会破坏背景，而带有掩膜引导的方法则在掩膜不精确或放置错误时表现不佳。", "innovation": "本文提出了一种名为MAGIC的方法，通过多级扰动和语境感知对齐模块实现了对齐掩膜的生成，解决了异常生成的问题。具体而言，MAGIC的方法包含三个创新点：（1）通过对Stable Diffusion模型进行微调，保留正常区域，确保合成的异常精确对应输入的掩膜，解决了背景破坏和错位问题；（2）引入扰动策略，包括指导性的空间噪声注入和蒙文级的高斯扰动，以增加多样性和避免低质量的文本表征；（3）语境感知的掩膜对齐模块，形成语义对齐并重新定位掩膜，使每种异常现象都更可能包含在主机对象中，消除了边界外的异常现象。", "conclusion": "基于一致的评价协议，在MVTec-AD数据集上，MAGIC在下游异常检测任务中的表现优于先前的最先进的方法。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02356", "html_url": "https://arxiv.org/abs/2507.02356", "title": "offline reinforcement learning with penalized action noise injection", "title_en": "Offline Reinforcement Learning with Penalized Action Noise Injection", "authors": "JunHyeok Oh,Byung-Jun Lee", "background": "离线强化学习（RL）使用固定的数据集进行优化，这使其在与环境交互成本高的场景中显得更加实用。然而，由于这种方法的局限性，离线RL算法的一般化能力对于提高其性能至关重要。近期研究显示，通过使用扩散模型，离线RL取得了显著的进展。但是，扩散模型在推理过程中需要大量的计算资源，其必要性仍然存在疑问。因此，如何在不依赖扩散模型的情况下提高离线RL算法的性能，成为了一个新的研究方向。", "innovation": "本文提出了Penalized Action Noise Injection（PANI）方法，该方法通过利用带有噪声的动作覆盖整个动作空间，并根据添加的噪声量进行惩罚，从而增强离线学习。这种方法的灵感来自于扩散模型在离线RL算法中的应用。文章还为该方法提供了理论基础，证明了带有噪声动作的离线RL算法解决了修改后的马尔可夫决策过程（MDP），称为噪声动作MDP。此外，PANI算法能够适用于多种现有的离政策和离线RL算法，并在各种基准测试中表现出显著的性能提升，尽管它本身非常简单易行。", "conclusion": "PANI能够兼容广泛的已有的离政策和离线RL算法。尽管是一种非常简化的解决方案，但它在多个基准测试中展示了显著的性能提升。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02390", "html_url": "https://arxiv.org/abs/2507.02390", "title": "评估语言模型在物联网安全日志中威胁检测的效果", "title_en": "Evaluating Language Models For Threat Detection in IoT Security Logs", "authors": "Jorge J. Tejero-Fernández,Alfonso Sánchez-Macián", "background": "日志分析在网络安全领域具有重要意义，因为它们提供了检测网络和系统威胁的信息来源。本文介绍了一种使用微调大型语言模型（LLMs）进行异常检测和缓解建议的管道。利用经典机器学习分类器作为基线模型，对三种开源LLMs在二元和多类异常检测方面的性能进行了比较，分别采用了零样本、少量样本提示和基于物联网数据集的微调策略。实验结果显示，LLMs在多类攻击分类任务上优于对应的基线模型。通过将检测到的威胁映射到MITRE CAPEC，定义一套物联网特定的缓解措施，并对模型进行微调，模型能够提供检测和建议的综合指导。", "innovation": "研究引入了一种使用微调大型语言模型进行物联网安全日志中的异常检测和缓解建议的方法，特别是在多类攻击分类方面表现优于传统的基线模型。该研究还提出了将检测到的威胁与MITRE CAPEC映射以及定义物联网特定的缓解措施的方法，从而增强模型的检测和建议能力。", "conclusion": "微调后的大型语言模型在多类攻击分类上表现出色，并且能够结合检测和推荐指导。通过对物联网具体场景进行微调和策略调整，模型能够更准确地应对物联网安全威胁。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02349", "html_url": "https://arxiv.org/abs/2507.02349", "title": "两步神经网络方法实现自动化颅内血管关键点检测", "title_en": "Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection", "authors": "Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau", "background": "颅内动脉瘤（ICA）常常发生在Willis环（CoW）的特定区域，主要集中在十三大动脉分叉处。准确识别这些关键位置对于快速和有效的诊断至关重要。现有的方法可能遇到重叠标记点和相似视觉特征导致的误检问题，尤其是在处理完整的MRA时间飞行（TOF）数据时。针对颅内血管在不同扫描中的解剖变异影响可检测的标记点数量的问题，本文提出了一种两阶段的神经网络方法进行自动关键点检测。该方法首先使用目标检测网络识别接近标记点的感兴趣区域（ROIs），然后使用带有深度监督的修改U-Net进行精确的分叉定位。这一方法能够克服由于多个标记点接近或相似视觉特征导致的误检问题，同时解决了Willis环的解剖变异对检测的影响。", "innovation": "本文采用了两阶段神经网络方法：首先使用目标检测网络识别感兴趣的区域，然后使用一个修改的U-Net网络进行深度监督下的精准定位。这种方法能够有效减少由于两个标记点接近且视觉特征相似导致的误检问题，同时适应Willis环的解剖变异。该方法在两个神经血管造影数据集上的实验结果表明，其在分叉检测任务中的性能最佳。", "conclusion": "我们的方法在关键点检测任务中表现出卓越的性能，能够自主准确地检测Willis环中的分叉点。这种方法不仅大大提高了诊断效率，还弥补了当前方法在处理重叠和类似特征标记点以及适应解剖变异方面的不足。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02358", "html_url": "https://arxiv.org/abs/2507.02358", "title": "全局图像生成中的全局标记", "title_en": "Holistic Tokenizer for Autoregressive Image Generation", "authors": "Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi", "background": "传统的自回归图像生成模型逐步生成视觉标记，这限制了捕捉标记序列之间整体关系的能力。大多数视觉标记器将局部图像片段映射为潜在标记，导致全局信息有限。为解决这些问题，本文提出了一种名为Hita的新型自回归图像标记方法，它引入了一种全局到局部的标记方案，并集成了两个关键策略以更好地与自回归生成过程对齐：首先，它采用全局标记在前面、局部标记在后面的顺序结构，并利用因果注意力保持对先前标记的意识；其次，在将去量化标记送入解码器之前，Hita采用一个轻量级融合模块控制信息流，优先考虑全局标记。", "innovation": "Hita是一种新型的全局视野标记器，用于自回归图像生成，它采用全局到局部的标记方案，并使用可学习的全局查询和局部片段标记。此外，Hita还通过因果注意力机制保持对先前标记的意识，并结合一个轻量级融合模块控制信息流，以优先使用全局标记。该方法显著加速了自回归生成器的训练速度，并在ImageNet基准测试中优于使用传统标记器训练的模型，达到了2.59 FID和281.9 IS的优异结果。", "conclusion": "本文提出的Hita显著改进了自回归图像生成中的标记方法，通过加快训练速度和提高生成质量，证明了其在全局图像特性的捕捉、零样本风格迁移和图像修复等方面的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02376", "html_url": "https://arxiv.org/abs/2507.02376", "title": "VeFIA: 一种高效垂直联邦协作软件推理审计框架", "title_en": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software", "authors": "Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang", "background": "垂直联邦学习（VFL）是一种无需访问参与方数据的分布式AI软件部署机制，用于跨湖协作。然而，现有VFL工作中缺乏一种机制来审计数据方推理软件执行的正确性。为解决这一问题，设计了垂直联邦推理审计（VeFIA）框架，该框架帮助任务方在大规模推理过程中审计数据方推理软件执行是否符合预期，同时不泄露数据方的数据隐私或引入推理系统的额外延迟。VeFIA的核心在于任务方可以使用带有可信执行环境（TEE）框架和协调器的推理结果来验证数据方计算结果的正确性。VeFIA确保只要异常推理超过5.4%，任务方就能在99.99%的概率下检测到推理软件的执行异常，且不产生额外的在线推理延迟。VeFIA的随机采样验证在检测异常推理方面实现了100%的阳性预测值、阴性预测值和真阳性率。据我们所知，这是首篇讨论垂直联邦学习中推理软件执行正确性的论文.", "innovation": "提出了垂直联邦推理审计（VeFIA）框架，以解决现有VFL工作中缺乏审计数据方推理软件执行正确性的机制问题。VeFIA允许任务方在大规模推理过程中使用可信执行环境的框架和协调器验证数据方推理结果的正确性，确保只要有超过5.4%的异常推理，任务方就能在99.99%的概率下检测到，并且不增加在线推理延迟。此外，其随机采样验证达到了100%的阳性预测值、阴性预测值和真阳性率，在检测异常推理方面表现优异。这是首次探讨垂直联邦学习中推理软件执行正确性的研究.", "conclusion": "VeFIA框架能够有效地帮助任务方审计数据方推理软件的执行正确性，同时保证了数据隐私安全和系统性能，填补了现有VFL工作中审计机制的空白。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02409", "html_url": "https://arxiv.org/abs/2507.02409", "title": "S2FGL：空间频谱联邦图学习", "title_en": "S2FGL: Spatial Spectral Federated Graph Learning", "authors": "Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye", "background": "联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）强大的图建模能力。当前的研究仅从结构角度探讨子图-FL，忽视了图信号在空间和频谱域上的传播。从空间角度来看，子图-FL在客户端之间引入了边断开，导致标签信号中断和全局GNN类别知识下降。从频谱角度来看，频谱异质性导致子图中信号频率不一致，使得局部GNN过度拟合局部信号传播方案。因此，引发频谱客户端漂移，影响全局泛化能力。因此，需要创新的方法来解决这些挑战。", "innovation": "提出了一种全局知识库来缓解标签信号中断问题，以及一种频谱对齐方法来解决频谱客户端漂移问题。结合空间频谱策略形成了我们的框架S2FGL。实验结果表明，S2FGL在多个数据集上表现出优越性。", "conclusion": "通过S2FGL，有效地解决了联邦图学习中的结构和频谱挑战，并在多个数据集上的实验证明了其优越性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02424", "html_url": "https://arxiv.org/abs/2507.02424", "title": "CyberRAG: 一种具有代理作用的RAG网络攻击分类和报告工具", "title_en": "CyberRAG: An agentic RAG cyber attack classification and reporting tool", "authors": "Francesco Blefari,Cristian Cosentino,Francesco Aurelio Pironti,Angelo Furfaro,Fabrizio Marozzo", "background": "大型企业中的入侵检测和预防系统(IDS/IPS)每小时可生成数以万计的警报，极大地困扰了安全分析师。传统的机器学习检测器可以减少警报量，但仍会导致高误报率。标准的一次性检索增强生成(RAG)管道常常检索到不相关的上下文，无法证明其预测。", "innovation": "提出了一种模块化、基于代理的RAG框架——CyberRAG，能够实时分类、解释和结构化报告网络攻击。该框架包括一个核心的LLM代理，它调度（i）多个专门针对不同攻击家族的精细调优分类器的池；（ii）用于丰富信息和警报的工具适配器；以及（iii）一个迭代的检索和推理循环，该循环不断查询特定领域的知识库，直到证据既相关又自洽。与传统的RAG系统不同，CyberRAG采用代理设计，使控制流动态化和适应性推理成为可能。这种以代理为中心的架构可自主精炼其威胁标签和自然语言解释，减少误报并增强可解释性。", "conclusion": "CyberRAG框架完全可扩展：只需添加分类器即可支持新攻击类型，无需重新训练核心代理。经过评估，CyberRAG每类准确性超过94%，最终分类准确性达到94.92%。生成的解释在BERTScore中最高得分为0.94，在基于GPT-4的专家评估中得分为4.9/5。这些结果表明，具有代理作用的专家导向RAG可以同时具备高检测准确率和可信的、适合安全管理中心的自然语言解释，提供了一条实用且可扩展的半自主网络安全防御工作流之路。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02398", "html_url": "https://arxiv.org/abs/2507.02398", "title": "超越空间频率：像素级基于时间频率的深伪视频检测", "title_en": "Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection", "authors": "Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi", "background": "传统的检测方法主要依赖于空间频率来捕捉视频中的特征，但是在检测时间轴上的像素一致性时，这些方法往往会出现失败的情况。文章介绍了一种新的检测方法，该方法通过像素级的时间频率来检测深伪视频，这种方法能够有效地识别传统方法忽略的时间上的不一致性，尤其是那些容易出现不自然运动的区域。", "innovation": "1. 开发了一种针对每个像素进行一维傅里叶变换的方法，提取出对时间不一致性敏感的特征。2. 引入了端到端训练的注意力提议模块，以精准定位包含时间伪影的区域。3. 建立了联合变换模块，将像素级的时间频率特征与空间-时间上下文特征有效结合，提升了伪造篡改痕迹的检测范围。", "conclusion": "本文提出的方法在深伪视频检测领域取得了显著的进步，通过提高检测场景的多样性和复杂性，提供了更为可靠的性能表现。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02503", "html_url": "https://arxiv.org/abs/2507.02503", "title": "LLMs的持续梯度低秩投影微调", "title_en": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs", "authors": "Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing", "background": "大型语言模型（LLMs）连续微调时面临效率与表达能力之间的权衡。尽管低秩适应（LoRA）方法可以提高效率，但由于其低秩特性和对显式参数约束的依赖性，它限制了模型学习新任务和知识迁移的能力。", "innovation": "提出了一种新颖的训练策略GORP（Gradient LOw Rank Projection），该策略通过同时结合完整参数和低秩参数，并在统一低秩梯度子空间内联合更新，从而克服了LoRA的局限性，扩大了优化空间，同时保持了效率并减轻了灾难性遗忘现象。", "conclusion": "大量的实验结果表明，GORP在持续学习基准测试中优于现有最先进的方法。相关代码可在以下链接获取。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02403", "html_url": "https://arxiv.org/abs/2507.02403", "title": "在非城市环境中使用自监督学习进行野生动物目标再识别", "title_en": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings", "authors": "Mufhumudzi Muthivhi,Terence L. van Zyl", "background": "野生动物再识别旨在将同一物种在不同观察中的个体进行匹配。当前最先进的模型依赖于类别标签来训练监督模型进行个体分类。这种对标注数据的依赖推动了众多大型野生动物数据集的创建。本研究探讨了自监督学习（SSL）在野生动物再识别中的应用。研究利用摄像机陷阱数据中的时间图像对自动提取个体的两个视图，无需监督即可训练自监督模型。这些模型可以从潜在无限的视频数据流中学习。实验结果表明，即使数据量有限，自监督模型更具鲁棒性，并且自监督特征在所有下游任务中均优于监督特征。", "innovation": "本研究创新地利用自监督学习方法在摄像机陷阱数据中自动提取个体的两个视图进行野生动物再识别，无需人工标注数据，从而解决了传统方法对大量标注数据的依赖问题。此外，实验结果表明，自监督学习在实验结果中的表现优于传统的监督学习方法，即便在数据量有限的情况下也表现出更高的鲁棒性。", "conclusion": "研究表明，自监督模型在野生动物再识别任务中表现出更高的鲁棒性和泛化能力，即使在数据有限的情况下也能取得良好的结果。自监督特征在各种野生动物下游任务中的表现优于监督特征，证明了其在实际应用中的优势。实验结果已公开，验证了所提出方法的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02443", "html_url": "https://arxiv.org/abs/2507.02443", "title": "在FPGA可编程逻辑中加速葡萄检测的人工神经网络", "title_en": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic", "authors": "Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias", "background": "机器人在搬运过程中通常会减速以检测物体，同时为了追踪检测算法的速度，机器人摄像头的帧率较低。这限制了任务执行和探索能力，延长了任务执行时间。AMD开发了Vitis-AI框架来将检测算法部署到FPGAs中，但该工具并未充分利用FPGAs的PL资源。", "innovation": "本文使用FINN架构将三种ANNs（MobileNet v1、CNV（2比特量化）和BNN（1比特量化））部署到FPGA的PL中。这些模型在RG2C数据集上进行训练，这是一项自获取的开放式数据集。MobileNet v1表现最佳，成功率达到了98%，推理速度为6611 FPS。本文证明了可以利用FPGAs加速ANNs并使其适合注意力机制。", "conclusion": "研究表明，利用FPGAs加速人工神经网络不仅提高了自动葡萄检测系统的性能，还使其适用于具有注意力机制的任务。这种方法可以在保持低功耗的同时显著提高检测速度和准确性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02436", "html_url": "https://arxiv.org/abs/2507.02436", "title": "朝向稳健和通用的元材料基础模型", "title_en": "Toward a Robust and Generalizable Metamaterial Foundation Model", "authors": "Namjung Kim,Dongseok Lee,Jongbin Yu,Sung Woong Cho,Dosung Lee,Yesol Park,Youngjoon Hong", "background": "材料功能的进展带动了多个领域的创新，其中以结构而非成分定义的元材料处于领先位置。尽管人工智能驱动的设计策略有所提升，但在特定任务的重新训练、分布外（OOD）泛化能力差以及正向和逆向设计需要单独模型等问题上仍存在不足。这些限制为研制更先进的元材料设计工具留下了改进空间。", "innovation": "介绍了一种基于贝叶斯变换器基础模型的Metamaterial Foundation Model (MetaFO)，它借鉴了大型语言模型的理念。MetaFO能够学习元材料的内在力学特性，实现跨多种未知材料特性和结构响应的零样本概率预测。此外，它在非线性逆向设计和OOD条件下表现出色。通过将元材料视为一种映射材料属性到结构响应的操作器，MetaFO揭示了复杂的结构-属性关系，显著扩展了设计空间。这一可扩展且通用的框架标志着人工智能驱动元材料发现的范式转变，为下一代创新铺平了道路。", "conclusion": "MetaFO通过其强大的功能解决了元材料设计中的关键挑战，提供了一个更为强大和适应性强的框架，促进更广泛的工程和科学领域的创新。这种模型对未来元材料的设计具有重要的实用价值。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02550", "html_url": "https://arxiv.org/abs/2507.02550", "title": "一个关于深度学习的理论必须包含组成稀疏性", "title_en": "Position: A Theory of Deep Learning Must Include Compositional Sparsity", "authors": "David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio", "background": "过参数化的深度神经网络（DNNs）在高维度领域已经显示出显著的成功，而这些领域对于受到维数灾难限制的经典浅层网络来说是困难的。然而，关于DNNs学习动力学的基本原则仍存在许多问题，这些问题尚未被解答。", "innovation": "本文提出，DNNs的成功得益于其适应目标函数组成稀疏结构的能力。这意味着大多数实际相关的功能可以由一组基函数组成，每一组函数仅依赖所有输入中的一小部分。该特性是由所有高效可图灵计算的功能共享的，因此很可能存在于所有当前的学习问题中。此外，虽然在组成稀疏函数的环境下对于近似和泛化存在一些有前景的理论见解，但DNNs的学习能力和优化问题仍有许多重要问题待解决。", "conclusion": "深入理解组成稀疏性在深度学习中的作用对于构建全面的人工智能理论是至关重要的，甚至是对通用人工智能理论的理解也有帮助。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02493", "html_url": "https://arxiv.org/abs/2507.02493", "title": "基于时间感知的监督对比学习在结肠内窥镜息肉计数中的应用", "title_en": "Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy", "authors": "Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi", "background": "自动化结肠息肉计数是提高结肠内窥镜筛查成本效益的关键步骤，旨在实现自动化操作报告和质量控制。息肉计数涉及检测和跟踪息肉，然后将属于同一息肉实体的轨迹聚类。现有的息肉计数方法依赖于自监督学习，主要利用视觉外观，忽略了在轨迹特征学习和聚类阶段的时间关系。现有方法忽视了时间维度上的联系，导致在息肉识别上的不足，影响最终的聚类效果和准确性。", "innovation": "本文提出了一种基于时间感知的监督对比学习方法，引入了考虑时间感知的软目标的监督对比损失。该方法捕捉到了息肉内的变异性和息肉间的可区分性，提高了聚类的鲁棒性。此外，通过整合时间邻接约束，逐步减少了对视觉上相似但时间上不连续的轨迹的错误再关联，进一步提高了轨迹聚类的准确性。该方法在公开数据集上进行训练和验证，并使用交叉验证策略评估性能。实验结果表明，与先前的方法相比，新的方法能够将分段率降低2.2倍。研究表明，时间感知对息肉计数至关重要，建立了新的状态最先进水平。", "conclusion": "本文提出的时间感知监督对比学习方法在息肉计数中得到了良好的效果，通过引入新的损失函数和约束条件，提高了息肉识别的准确性和聚类效果。实验结果验证了这种方法的有效性，证明了时间信息在自动化息肉计数中的重要性，为该领域的研究提供了新的方向，为自动化内镜报告和质量控制奠定了基础。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02537", "html_url": "https://arxiv.org/abs/2507.02537", "title": "你听懂我说的吗？细调聊天机器人以实现同理心对话", "title_en": "Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue", "authors": "Paulo Ricardo Knob,Leonardo Scholler,Juliano Rigatti,Soraia Raupp Musse", "background": "对话型代理自ELIZA以来取得了显著进步，其角色扩展到医疗、教育和客户服务等多个领域。随着这些代理越来越多地融入人们的日常互动中，情感智能，尤其是同情心倾听，变得越来越重要。本研究探讨了大型语言模型（LLMs）在生成丰富情感的对话时的响应。从一个由专家手工编写的包含同情行为的小数据集开始，使用了两种LLM——ChatGPT和Gemini来扩展对话。通过情感分析（使用VADER）和专家评估分析了对话的情感进展。尽管生成的对话往往模仿了预期的情感结构，但人类评估揭示了回应在感知的同理心和连贯性方面的重要差异。这些发现表明，对话中的情感建模不仅需要表达情感的结构对齐，还需要深度的品质，强调了在开发情感能力代理时结合自动化和以人为本方法的重要性。", "innovation": "使用大型语言模型扩展现有的手动编写的包含同情行为的对话数据集。通过情感分析和专家评估分析对话的情感进展。揭示了情感结构对齐和情感深度品质在对话建模中的重要性，强调了结合自动化和以人为本方法的重要性。", "conclusion": "生成的对话往往模仿了预期的情感结构，但人类评估显示在感知的同理心和连贯性方面的重要差异。情感建模不仅需要结构上的情感对齐，还需要情感的深度品质，表明结合自动化和以人为本的方法对于开发情感智能代理的重要性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02506", "html_url": "https://arxiv.org/abs/2507.02506", "title": "印度保释判决-1200：针对印度保释命令的多属性数据集", "title_en": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders", "authors": "Sneha Deshmukh,Prathmesh Kamble", "background": "在包括印度在内的地区，法律自然语言处理（Legal NLP）发展受限，主要是由于缺乏结构化的数据集。印度的法律文献尤其需要高质量的数据支持来推动相关技术的发展。缺少足够的标注数据使得研究人员在开发和测试相关的法律自然语言处理工具时面临困难。", "innovation": "本文引入了印度保释判决-1200（IndianBailJudgments-1200），这是一个包含1200份印度法院关于保释决策的判决的基准数据集，这些判决涵盖了超过20种属性的标注，如保释结果、刑法章节、犯罪类型和法律推理等。该数据集使用精心设计的GPT-4o提示流水线生成标注，并且经过一致性验证，以支持广泛的法律自然语言处理任务，例如结果预测、摘要生成和公平性分析。这是首个专注于印度保释法律判例的公开数据集，填补了领域的空白，为相关研究提供了重要资源。", "conclusion": "印度保释判决-1200数据集不仅能够支持多种法律自然语言处理的应用，而且为研究印度法律体系及其判例提供了新的途径。这一工作对于推动法律自然语言处理技术在印度及其他类似地区的应用具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02592", "html_url": "https://arxiv.org/abs/2507.02592", "title": "WebSailor：构建超人类推理的网页代理", "title_en": "WebSailor: Navigating Super-human Reasoning for Web Agent", "authors": "Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou", "background": "提升LLM（大型语言模型）的推理能力是训练中的关键前沿领域。私营代理系统如DeepResearch在极其复杂的如BrowseComp信息检索基准测试上展示了超人的能力，这是开源模型无法达到的。研究者认为，其成功在于一种深藏不露的推理模式，这种模式在开源模型中没有出现，即系统性地减少在庞大信息空间中导航时的极端不确定性.", "innovation": "我们提出了WebSailor，一种全面的后训练方法论，旨在赋予这种关键能力。该方法包括生成具有高不确定性的新颖任务，通过结构化采样和信息混淆；冷启动RFT；以及高效的代理RL训练算法DUPO（复制采样策略优化）。通过集成这一管道，WebSailor在复杂的信息寻址任务上明显优于所有开源代理，达到了私营代理的能力水平，缩小了能力差距.", "conclusion": "WebSailor显著提升了LLM在复杂信息检索任务上的表现，达到了私营代理的水平，为代理系统在信息导航中的超人类推理能力铺平了道路。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02602", "html_url": "https://arxiv.org/abs/2507.02602", "title": "Vision-Based Navigation: Simulation and Dataset Development for Addressing Camera Sensors Faults", "title_en": "Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development", "authors": "Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill", "background": "随着基于视觉的导航（VBN）算法在航天任务中的重要性日益提升，确保其可靠性和操作鲁棒性成为了一个重要挑战。传感器故障可能导致导航算法输出不准确或完全的数据处理故障，从而影响任务目标的实现。人工智能（AI）提供了一种强大的解决方案，能够检测这些故障，克服传统故障检测方法的诸多局限。然而，由于缺乏包含故障图像数据的充分且具代表性的数据集，AI在这一领域的应用受到限制。为解决这些问题，本文专注于星际探索任务场景，详细分析了VBN管道中可能发生的相机传感器故障，并系统地描述了这些故障的原因和影响，以及常用缓解策略。为了支持这一分析，引入了一个仿真框架，用于在合成图像中重现故障条件，从而系统且可控地生成故障数据。生成的含故障图像的数据集为训练和测试基于AI的故障检测算法提供了有价值的工具。", "innovation": "本文通过引入仿真框架来重新生成具有故障条件的合成图像，创建了一个含故障图像数据集，用以训练和测试AI基于的故障检测算法。这项工作填补了该领域在数据集方面的空白，为AI在VBN中的应用提供了重要支持。", "conclusion": "该研究表明，通过仿真框架重新生成的含故障图像数据集为训练和测试AI基于的故障检测算法提供了有价值的工具。这一数据集的开发为解决VBN中相机传感器故障问题铺平了道路，具有重要的实际应用价值。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02517", "html_url": "https://arxiv.org/abs/2507.02517", "title": "使用深度学习检测多种作物的多种病害", "title_en": "Detecting Multiple Diseases in Multiple Crops Using Deep Learning", "authors": "Vivek Yadav,Anugrah Jain", "background": "印度作为一个以农业为主的经济体，面临农业方面的诸多挑战，包括由疾病、害虫和环境压力造成的大量农作物损失。早期检测和准确识别不同作物中的疾病对于提高产量和确保食品安全至关重要。印度的农业景观复杂多样，因此需要一种能够覆盖多种作物和疾病的解决方案。本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种疾病，旨在解决这一问题并提高农作物产量和食品安全性。首先创建了一个包含17种不同作物和34种不同疾病的统一数据集。提出的深度学习模型在此数据集上进行了训练，并在准确性和覆盖的作物及疾病数量方面均优于最新技术。该模型在统一数据集上的检测准确率达到了99%，比只处理14种作物和26种不同疾病的最新技术高出7个百分点。通过增加能够检测的作物种类和病害类型数量，所提出的解决方案旨在为印度农民提供更好的产品和服务。", "innovation": "本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种疾病。使用包含17种不同作物和34种不同疾病的统一数据集进行训练，相比现有的仅处理较少作物和疾病的最新技术，该模型在准确性和覆盖的作物及疾病数量方面均有所提升。特别是在统一数据集上的检测准确率达到了99%，比现有技术高出7个百分点。这项研究的主要创新点在于其能够处理多种作物和疾病的统一数据集的有效构建以及其在多种作物和疾病检测中的卓越表现。", "conclusion": "通过提高能够检测的作物和病害类型数量，本文提出的解决方案旨在为印度农户提供更好的产品和服务，有助于提高印度农业的产量和食品安全性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02595", "html_url": "https://arxiv.org/abs/2507.02595", "title": "MPF: Multiperspective Fusion for Aligning and Debiasing Language Models Post Deployment", "title_en": "MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion", "authors": "Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama", "background": "随着大型语言模型（LLMs）的广泛应用，对容易去除偏见的需求日益增长。现有的对语言模型进行偏见调整的方法通常需要复杂的提示工程或重新训练，这增加了操作的复杂性和成本。因此，迫切需要一种简单有效的偏见调整框架，适用于已经部署的模型。Multiperspective Fusion (MPF) 框架正是为了解决这个问题而设计的，它基于自动构建偏见基准和提取可解释基准分布的SAGED管道，通过多视角生成揭示并调整LLM输出的偏见，使之与细腻的人类基准对齐。", "innovation": "MPF框架具有以下几个创新点：首先，它利用多视角生成的方式，通过分解基线（如职业 HR 人员的情感分布）为可解释的视角组件，引导生成过程，通过对响应进行采样和加权平衡，以调整响应的角度和比例。其次，MPF能够实现绝对平等性和面向特定基准的对齐，提高了语言模型在不同场景下的泛化能力。", "conclusion": "实验结果显示，MPF能够将LLM的情感分布与对偶基准（绝对平等性）和特定基准（如顶尖大学偏好）对齐，这通过减小KL散度、减少校准误差和拓宽对未见过的问题的泛化能力得以证实。MPF提供了一种高效且可解释的对齐和偏见缓解方法，适用于部署中的语言模型，并且不需要大量的提示工程或重新训练。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02598", "html_url": "https://arxiv.org/abs/2507.02598", "title": "AC-Refiner: 使用条件扩散模型进行高效算术电路优化", "title_en": "AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models", "authors": "Chenhao Xue,Kezhi Li,Jiaxing Zhang,Yi Ren,Zhengyuan Shi,Chen Zhang,Yibo Lin,Lining Zhang,Qiang Xu,Guangyu Sun", "background": "算术电路，例如加减器和乘法器，是数字系统的基本组成部分，直接影响系统的性能、功耗效率和面积占比。然而，由于设计空间庞大和复杂的物理限制，优化这些电路仍然是一个挑战。尽管最近基于深度学习的方法显示出潜力，但它们难以一致地探索有潜力的设计变种，限制了优化效率。", "innovation": "我们提出了一个名为AC-Refiner的新颖算术电路优化框架，利用条件扩散模型。关键见解是将算术电路合成重新定义为条件图像生成任务。通过仔细在去噪扩散过程中对目标质量结果（QoR）进行条件化，AC-Refiner可以一致地生成高质量的电路设计。此外，这些探索的设计用于微调扩散模型，使其探索集中在帕累托前沿附近。实验结果表明，AC-Refiner生成的电路设计具有更好的帕累托最优性，优于最先进的基线方法。进一步验证了通过将AC-Refiner集成到实际应用中的性能提升效果。", "conclusion": "实验结果表明，AC-Refiner能够生成具有帕累托最优性的优秀设计，相比于现有的最先进的方法具有更好的性能，并通过应用集成进一步验证了其性能提升。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02666", "html_url": "https://arxiv.org/abs/2507.02666", "title": "ASDA: 音频光谱差分注意力机制在自我监督表示学习中的应用", "title_en": "ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning", "authors": "Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang", "background": "在最近的音频自我监督表示学习进展中，标准的Transformer架构已成为主导方法，但其注意力机制往往将部分注意力权重分配给无关信息，这可能削弱模型的区分能力。为解决这一问题，引入了差分注意力机制。该机制通过整合双softmax操作和适当调整的差分系数，有效减少了无效注意力分配，提升了模型对相关信息的关注。实验结果表明，ASDA模型在多个基准测试中达到了最先进的性能，包括音频分类（AS-2M上的49.0% mAP，AS20K上的41.5% mAP）、关键词识别（SPC-2上的98.3%准确率）和环境声音分类（ESC-50上的96.1%准确率）。", "innovation": "提出了差分注意力机制，通过整合双softmax操作和适当调整的差分系数来减少无效注意力分配，提升了模型对相关信息的关注度。实验证明该机制在多个音频任务上表现优异，达到了最先进的性能。", "conclusion": "ASDA模型在多个音频基准测试中达到了最先进的性能，展示了其在音频任务中的有效性，有助于扩展其在更广泛应用中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02620", "html_url": "https://arxiv.org/abs/2507.02620", "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference", "title_en": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference", "authors": "Xing Liu,Lizhuo Luo,Ming Tang,Chao Huang", "background": "分布式推理作为在网络边缘进行大规模语言模型（LLMs）推理的一种有前途的方法，通过将推理过程分配到多个设备以确保LLMs能够适合设备内存。管道化方法有可能提高通信和计算的并行化，从而降低推理延迟，但实际效果在边缘稀疏请求下的利用较低。针对这一挑战，作者提出了FlowSpec框架，这是一种基于树的推测性解码管道化方法。", "innovation": "FlowSpec引入了三种关键机制来提高解码效率：1）基于得分的逐步验证优先处理更重要的候选词，从而使更早接受的词更快被确认；2）高效的候选词管理，在验证过程中修剪无效候选词同时保持正确的因果关系；3）动态候选词扩展策略，以供应高质量的推测性输入。这些技术的结合不仅提高了管道利用率，还提高了推测效率。", "conclusion": "作者在现实测试床和其他基线上评估了FlowSpec。实验结果证明，所提出框架在各类模型和配置下显著提高了推理速度，相较于基线实现的加速比为1.36倍至1.77倍。代码已公开。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02606", "html_url": "https://arxiv.org/abs/2507.02606", "title": "De-AntiFake: 重新思考针对语音克隆攻击的保护性扰动", "title_en": "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks", "authors": "Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu", "background": "语音生成模型的快速发展引发了人们对语音克隆（VC）隐私和安全问题的高度关注。近期研究探索了通过引入对抗性扰动来扰乱未授权的语音克隆。然而，有决心的攻击者可以抵消这些保护性扰动并成功执行VC。已有研究仅在不包括净化方法的破坏情况下评估了这些保护性扰动的效果。这项研究旨在在包含净化方法在内的现实威胁模型下，系统地评估这些保护性扰动的有效性。", "innovation": "本研究提出了一种新的两阶段净化方法：首先净化受扰的语音，然后使用音素指导进行细化，使其与干净的语音分布相一致。实验结果显示，该方法在扰乱VC防御方面优于最先进的净化方法。此外，研究揭示了基于对抗性扰动的VC防御的局限性，强调了开发更稳健解决方案的紧迫性，以减轻由VC带来的安全和隐私风险。", "conclusion": "研究结果显示，现有的净化方法虽然能中和大部分保护性扰动，但仍然导致VC模型特征空间的扭曲，从而降低性能。基于此，研究提出了一种新方法，不仅能够更有效地破坏VC防御，还揭示了对抗性扰动在保护VC方面的局限性，强调了更稳健的解决方案需求。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02644", "html_url": "https://arxiv.org/abs/2507.02644", "title": "使用神经量子状态解决Hubbard模型", "title_en": "Solving the Hubbard model with Neural Quantum States", "authors": "Yuntian Gu,Wenrui Li,Heng Lin,Bo Zhan,Ruichen Li,Yifei Huang,Di He,Yantao Wu,Tao Xiang,Mingpu Qin,Liwei Wang,Dingshun Lv", "background": "神经量子状态（NQS）的快速发展已经确立了其作为研究量子多体系统有前途的框架地位。通过利用先进的基于变换器的架构，并开发高效的优化算法，我们对掺杂二维（2D）荷包模型取得了目前最先进结果，该模型被认为是高Tc超导性的基本模型。研究中发现，NQS范式中的不同注意力头可以直接编码不同尺度的关联，使其能够捕捉强关联系统中的长程关联和纠缠。", "innovation": "利用基于变换器的架构和高效优化算法，实现了对掺杂二维Hubbard模型的最先进的结果，不同注意力头可以直接编码不同尺度的关联，使得NQS能够捕捉强关联系统中的长程关联和纠缠。", "conclusion": "我们建立了2D Hubbard模型含有最邻近和次邻近跃迁的半充满条纹相在地态中的一致性，与铜基材料中的实验观测一致。这项工作确立了NQS作为解决具有挑战性的多重费米系统强大工具的地位。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02479", "html_url": "https://arxiv.org/abs/2507.02479", "title": "CrowdTrack：真实场景中困难的多行人跟踪基准数据集", "title_en": "CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios", "authors": "Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue", "background": "多目标跟踪是计算机视觉领域的经典领域，尤其是在行人跟踪方面，由于其高应用价值而变得极为热门。现有方法主要依赖于运动或外观信息进行跟踪，但在复杂场景中难以获得理想的效果。运动信息因相互遮挡难以更新；而外观信息则因部分可见性或图像模糊等原因导致结果不稳健。尽管可以通过标注数据学习在这些情况下的跟踪方法是解决这个问题最直接的方法，但现有的多目标跟踪（MOT）数据集无法满足这一需求。现有的方法主要存在场景构成相对简单和场景不现实这两个缺点。部分现有数据集中的视频序列虽然没有上述缺点，但数量远不足于满足研究需要。因此，作者提出了一套主要从第一人称视角并且全部源自现实复杂场景的大规模多行人跟踪数据集，命名为CrowdTrack，因其多数序列中包含大量物体。该数据集包含33段视频，共计5,185条轨迹，每个物体标注了完整的边界框和独特的物体ID。该数据集将为算法的开发提供平台，使其在复杂场景中仍能保持有效性。为了验证其有效性，对多个SOTA模型和基础模型进行了综合分析与测试，结果将公开发布于指定链接。", "innovation": "作者提出了CrowdTrack数据集，这是一个困难的多行人跟踪的大规模数据集，主要从第一人称视角拍摄的现实复杂场景中的图片序列构成。CrowdTrack的创新点包括：1）丰富的复杂场景内容，克服了已有数据集场景构成简单和非现实的问题。2）每条视频包含的轨迹数量众多，提高了数据集涵盖的复杂度和多样性。3）每条对象的完备标注，包括完整的边界框和单独的ID，为算法开发提供了更高的精度要求。4）数据集全面分析，并对多个SOTA模型和基础模型进行了测试，从而展示了数据集在实际应用中的价值。", "conclusion": "CrowdTrack数据集为多目标跟踪算法的有效开发提供了关键平台，尤其是在复杂场景中保持效果方面。它通过综合的场景设计和全面的标注，提供了一个更丰富、更贴近实际问题的数据基础。该数据集的成功发布和相关模型测试结果将在改进和扩展多目标跟踪算法方面起到重要推动作用。同时，数据集及项目代码已经公开发布，供研究者进一步参考和使用。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02714", "html_url": "https://arxiv.org/abs/2507.02714", "title": "FairHuman：通过最小潜力延迟公平性在扩散模型中提升人体图像生成的手部和面部质量", "title_en": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models", "authors": "Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma", "background": "随着大规模文本到图像模型的发展，特别是基于扩散的过程，图像生成已经取得了显著进展。然而，由于训练过程中局部区域的监督不足，生成具有合理细节的人类图像（如面部或手部）仍是一个挑战。现有的方法难以在确保总体图像质量的同时优化个人体细节，尤其是在手部和面部这样的关键区域。", "innovation": "本文提出了FairHuman，这是一种多目标微调方法，旨在公正地提高全球和局部生成质量。具体来说，该方法首先构建了三个学习目标：基于默认扩散目标函数的一个全局目标及基于预标注位置先验的手部和面部两个局部目标。接着，在最小潜力延迟（MPD）准则的指导下，推导出了最优参数更新策略，实现了多目标问题的公平优化。通过这种方法，在生成复杂局部细节的同时保持了总体图像质量，具有显著的改善效果。", "conclusion": "大量实验表明，本文提出的方法在不同场景下显著提高了人类图像生成的质量，特别是在手部和面部这些关键区域的细节质量。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02687", "html_url": "https://arxiv.org/abs/2507.02687", "title": "APT: 自适应个性化训练在有限数据下为扩散模型赋能", "title_en": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data", "authors": "JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang", "background": "在使用有限数据个性化扩散模型时，会遇到一系列挑战，如过拟合、先验知识丧失以及文字对齐度降低。过拟合会导致噪声预测分布的偏移，破坏去噪路径，使模型丧失语义一致性。因此，需要一种新的框架来克服这些问题，并在微调过程中缓解过拟合，保持先验知识和语义一致性，确保生成高质量、多样性的图像效果。", "innovation": "本文提出了一种名为自适应个性化训练（APT）的新框架，该框架通过适应性训练策略和微调过程中的模型内部表示正则化来缓解过拟合问题。APT包括三个关键组成部分：（1）自适应训练调整，通过引入过拟合指示器来检测每次时间步长的过拟合程度，并基于该指示器进行适应性数据增强和适应性损失加权；（2）表示稳定化，通过正则化中间特征图的均值和方差来防止噪声预测的过度偏移；（3）注意对齐，通过对细调模型和预训练模型之间的注意力图进行对齐，以维护先验知识和语义一致性。", "conclusion": "通过广泛的实验表明，APT 有效缓解了过拟合，保留了先验知识，并在有限的参考数据下生成了高质量、多样性的图像，优于现有方法。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02735", "html_url": "https://arxiv.org/abs/2507.02735", "title": "Meta SecAlign：对抗提示注入攻击的安全基础大语言模型", "title_en": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks", "authors": "Sizhe Chen,Arman Zharmagambetov,David Wagner,Chuan Guo", "background": "提示注入攻击对使用大语言模型（LLM）的集成应用构成重大安全威胁。虽然模型级别的防御措施显示出了强大的效果，但目前它们以封闭源代码的形式部署在商业级模型中。AI安全社区需要开放源代码模型，以便在开放研究中共同开发攻击和防御手段，推动对抗提示注入攻击的缓解措施的科学进步。", "innovation": "开发了Meta SecAlign，这是一种开放源代码且带有内置模型级别防御机制的公共大语言模型，能够在通用指令调优数据集上训练，达到商用级模型的性能。提供完整的训练食谱，采用了SOTA SecAlign防御的改进版本。在9个功能基准和7个安全基准上的评估表明，Meta SecAlign 不仅在通用指令遵循方面表现出色，还在未见过下游任务（如工具调用和代理型网络导航）中提供安全保护。Meta-SecAlign-70B 模型在对抗提示注入攻击方面达到最先进的鲁棒性，其在功效方面与具有模型级防御的闭源商用大语言模型相当", "conclusion": "Meta SecAlign是一种开放源代码的大模型，集成了对抗提示注入攻击的防御机制，同时保持了商业级别的性能。其提供的安全保护覆盖了多种下游任务，并且在对抗攻击方面达到了最先进的效果。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02748", "html_url": "https://arxiv.org/abs/2507.02748", "title": "线性注意力与全局上下文：一种用于视觉和物理的多极注意力机制", "title_en": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics", "authors": "Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen", "background": "Transformer 在从图像分类到物理模拟等多个任务中已经成为事实上的标准。尽管 Transformer 表现出色，但标准 Transformer 在时间和内存方面与输入长度呈二次复杂度关系，使得处理高分辨率输入变得不切实际。为了克服这一问题，已经提出了多种变体，如切块化、下采样或降级技术，但这些方法通常会损失细尺度的细节。已有研究主要集中在局部注意力机制上，这限制了模型的表示能力。", "innovation": "该论文受到 $n$-体数值模拟中最新的技术启发，将注意力视为网格点之间的相互作用问题。提出了一个多尺度、基于距离的注意力机制——Multipole Attention Neural Operator (MANO)，通过在每个注意力头中保持全局感受野，实现了线性时间和内存复杂度。实验结果表明，MANO 在图像分类和达西流动测试中能够媲美最新模型如 ViT 和 Swin Transformer，同时将运行时间和峰值内存使用量减少了几个数量级。", "conclusion": "研究表明，MANO 能够在同时维护模型性能和减少计算资源需求方面提供显著改进。为了确保研究的可复现性，开发人员已开源了代码。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02755", "html_url": "https://arxiv.org/abs/2507.02755", "title": "多智能体听觉场景分析", "title_en": "Multi-agent Auditory Scene Analysis", "authors": "Caleb Rascon,Luis Gato-Diaz,Eduardo García-Alarcón", "background": "听觉场景分析（ASA）旨在从声学环境中提取信息，通过三个主要任务执行：声源定位、分离和分类。传统上，这些任务是以线性流程执行的，首先定位声源；然后，根据位置将每个声源分离为其自己的音频流；从每个中提取与应用场景相关的信息（如音频事件检测、发言者识别、情绪分类等）。然而，这种线性执行虽然增加了总响应时间，但使得最后的任务（分离和分类）对第一个任务（定位）的错误极为敏感。最先进的技术大量努力用于开发错误最少的技术，但这导致了一个在许多要求较低计算量和低响应时间的应用中不可行的ASA系统，如生物声学、助听器设计、搜救、人机交互等。", "innovation": "本文提出了一种多智能体方法来执行ASA，其中任务并行运行，并在任务之间有反馈循环来补偿局部错误，例如：利用分离输出的质量来纠正定位错误；以及使用分类结果来减少定位对干扰的敏感性。该结果是一种多智能体听觉场景分析（MASA）系统，尽管不会引起复杂性的显著增加，且具有低响应时间。该系统是一个完整的框架，使用开源工具（JACK和ROS2）进行声音获取和还原以及智能体间通信，这使用户能够添加自己的智能体。", "conclusion": "提出的MASA系统是一个能够在局部错误影响下保持稳健的系统，具有低复杂性和低响应时间。系统配备了一个框架，其中包含开源的声音获取和重放工具（JACK）和智能体间通信工具（ROS2），这使用户能够添加属于自己定制的智能体。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02822", "html_url": "https://arxiv.org/abs/2507.02822", "title": "SynapseRoute：双状态大型语言模型的自动路由切换框架", "title_en": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model", "authors": "Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun", "background": "随着大型语言模型（LLMs）在实际应用中的广泛应用，选择合适的模型不再仅仅是考量性能指标，还需要平衡运营成本。具有推理能力的LLMs进一步扩大了'思考'（高推理）模式与'非思考'（快速、低成本）模式之间的成本差距。大约58%的医学问题可以通过'非思考'模式（低成本）准确回答，无需高成本的推理过程，这揭示了问题复杂性上的明显二元性。研究表明，根据问题复杂性在不同模式间动态路由查询能够优化准确性、成本效率和整体用户体验。", "innovation": "作者提出了SynapseRoute，一种基于机器学习的动态路由框架，能够智能地将输入查询分配给'思考'或'非思考'模式。SynapseRoute在几项医学数据集上的实验结果显示，在提高整体准确率（0.8390 vs. 0.8272）的同时，还减少了36.8%的推理时间和39.66%的令牌消耗。此外，质性分析还表明，过度推理简单的查询可能导致不必要的延迟和准确性下降，这些由自动路由机制中避免了。", "conclusion": "鉴于此工作，作者进一步提出了准确性-推理-令牌（AIT）指数，用于综合评估准确率、延迟时间与令牌成本之间的权衡。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02778", "html_url": "https://arxiv.org/abs/2507.02778", "title": "Self-Correction Bench: 揭示和解决LLMs中的自我纠正盲点", "title_en": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs", "authors": "Ken Tsui", "background": "尽管大型语言模型（LLMs）已经变得具有革命性，但它们仍然会犯错误，并且可能探索不具有生产力的推理路径。自我纠正对于可信赖的LLM来说是一个重要的能力，特别是对于自回归的LLM。虽然LLMs可以识别用户输入中的错误，但它们在纠正自身输出中的相同错误方面表现出所谓的‘自我纠正盲点’现象，即系统性地未能纠正错误。这项研究旨在系统地研究这一现象，通过在三个复杂度级别上进行受控错误注入，引入了Self-Correction Bench这一系统框架。测试了14个模型，发现平均盲点率为64.5%。研究发现，这种局限性与训练数据组成有关：人类训练示例主要展示错误-free回应，而非错误纠正序列，这与通过结果反馈学习错误纠正的RL训练模型不同。简单地附加 'Wait' 可以显著减少盲点，这表明该能力存在但需要激活。这项研究强调了当前LLMs中的一个关键局限性，并为提高其可靠性和可信度提供了潜在途径。", "innovation": "引入了Self-Correction Bench框架，通过受控错误注入在三个复杂度级别上系统地研究了自我纠正盲点现象。这项研究揭示了这种限制造成的原因在于训练数据组成，提出了通过简单附加 'Wait' 激活自我纠正能力的方法。", "conclusion": "当前LLMs存在自我纠正盲点这一关键局限性，简单附加 'Wait' 可显著减少盲点。研究为改善LLMs的可靠性和可信度提供了潜在途径。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02737", "html_url": "https://arxiv.org/abs/2507.02737", "title": "前沿大型语言模型中早期显现的隐写术能力", "title_en": "Early Signs of Steganographic Capabilities in Frontier LLMs", "authors": "Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner", "background": "大型语言模型（LLM）的输出监控对于减轻因误用和失准带来的风险至关重要。然而，LLM可能通过隐写术逃避监控：即在看似无害的生成中编码隐藏信息。本文评估了前沿LLM的隐写术能力，以更好地理解它们所构成的风险。我们专注于两种类型的隐写术：传递编码消息和执行编码推理。我们的研究发现，当前模型在标准条件下无法在输出中编码短消息而不被监控者发现。然而，如果给它们额外的条件，如使用未监控的草稿纸并协调使用哪种编码方案，则可以成功隐藏消息。此外，我们还发现一些早期迹象表明，模型可以在简单的状态跟踪问题中执行基本的编码推理，其中涉及与自身和预定义方案进行推理的能力，包括十六进制等编码方案。尽管如此，它们在隐写信息执行精细推理时，仍然难以在任务中隐藏推理而不被监控察觉。因此，本文的研究结果表明，当前的LLM具有初步的隐写术能力。尽管这种能力目前不足以绕过精心设计的监控系统，但这在未来有可能发生改变。", "innovation": "研究评估了前沿大型语言模型的隐写术能力，并强调了在常规条件下和特殊条件下隐藏信息的能力。研究发现，虽然当前模型在传达较短信息时难以隐秘，但在特定条件下可以成功隐藏消息。此外，还观察到模型在基本编码推理方面的一些初步能力，即将编码逻辑应用到自己的推理中以及预定义的编码方案中。这些发现为理解隐写术风险提供了新的视角，揭示了现有模型的局限性和潜在未来威胁。", "conclusion": "本文的研究结果表明，当前的大型语言模型展示了初步的隐写术能力。尽管这些能力目前不足以绕过精心设计的监控系统，但随着时间的推移，这一风险可能会成为一个更大的问题。建议进一步研究如何有效检测和预防这些新的隐写术威胁，并采取措施确保模型的透明性和合规性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02754", "html_url": "https://arxiv.org/abs/2507.02754", "title": "快速而简洁：Triton 中的 2-单纯形注意力", "title_en": "Fast and Simplex: 2-Simplicial Attention in Triton", "authors": "Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil", "background": "最近的研究表明，训练损失与模型大小及数据令牌数呈幂律关系，且要实现计算最优的模型，需要同时扩展模型大小和令牌数量。然而，这些扩展规律假设数据资源是无限的，并主要适用于计算受限的情况。随着现代大规模语言模型越来越多地依赖于大规模互联网数据集，它们被视为计算受限的假设变得不那么有效。这一转变突显了优先考虑令牌效率的架构的重要性。因此，本研究探讨了2-单纯形变换器的应用，这是一种通过高效Triton内核实现的标准点积注意机制的广义化架构。", "innovation": "2-单纯形变换器通过一个多线性函数的一般化点积注意力机制实现更好的令牌效率。与标准变换器相比，相同规模的模型在涉及数学、编程、推理和逻辑的任务中表现更好。研究通过改变知识和推理任务中规模定律的指数来量化这些收益，表明2-单纯形注意力对于提高令牌效率和改进模型性能具有潜在的优势。", "conclusion": "研究发现2-单纯形变换器相比标准变换器能够更好地利用令牌预算，在固定令牌预算的条件下，相同规模的模型在涉及数学、编程、推理和逻辑的任务中表现更优。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02824", "html_url": "https://arxiv.org/abs/2507.02824", "title": "基于DNN的RIS辅助毫米波MIMO系统中的预编码", "title_en": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift", "authors": "Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang", "background": "文章研究了利用重构智能表面(RIS)优化毫米波(mM沃)多输入多输出(MIMO)系统的传输吞吐量设计。由于线视流通路受阻，传统的穷举搜索(ES)对连续相移进行优化，计算强度大且耗时。为降低计算复杂度，使用排列离散傅立叶变换(DFT)向量结合幅度响应来优化码本设计，即使在采用离散相移的ES中，仍然影响计算效率。因此，通过训练深度神经网络(DNN)来加速码字选择成为一种新的方法。实验结果显示，即使在测试阶段终端用户和RIS之间的距离变化时，DNN仍能保持接近最优的频谱效率。这表明DNN在RIS辅助系统中的应用具有巨大潜力。", "innovation": "文章提出了一种使用训练后的深度神经网络(DNN)进行码字选择的新方法，以降低传统的穷举搜索法导致的高计算复杂度问题。同时，考虑了实际情况中的相位响应，并通过DNN来优化码本设计，这种方法验证了在不同的距离条件下仍能保持接近最优的频谱效率。", "conclusion": "研究结果表明，即使在测试阶段终端用户和RIS之间的距离变化时，DNN仍能保持接近最优的频谱效率，验证了使用DNN进行预编码选择的有效性，并强调了DNN在RIS辅助系统中的潜在应用价值。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02863", "html_url": "https://arxiv.org/abs/2507.02863", "title": "Point3R: 通过显式空间指针记忆进行流式3D重建", "title_en": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "authors": "Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu", "background": "从有序或无序图像集合重建稠密的3D场景是把计算机视觉研究引入实际应用场景的关键步骤。DUSt3R引入的范式将一对图像紧耦合到共享坐标系中，后续方法通过维护隐式记忆来实现更多图像的稠密3D重建。然而，这种隐式记忆存在容量有限和早期帧信息丢失的问题。", "innovation": "Point3R通过显式空间指针记忆解决上述问题，即在当前场景的空间结构中维护一个显式的指针记忆，并将周围场景信息聚合到全球坐标系中的变化空间特征中。最新帧提取的信息与指针记忆进行显式交互，从而实现当前观测的稠密集成到全球坐标系中。设计了3D分层位置嵌入来促进这种交互，并设计了一种简单有效的融合机制以保持指针记忆的均匀性和高效性。", "conclusion": "Point3R在各种任务上取得了与最新技术相当甚至更好的性能，且训练成本较低。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02851", "html_url": "https://arxiv.org/abs/2507.02851", "title": "MOTIF: 基于强化微调的模块化思考方法在大型语言模型中的应用", "title_en": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "authors": "Purbesh Mitra,Sennur Ulukus", "background": "大型语言模型（LLMs）的推理能力近期取得了显著进步，表明使用组相对策略优化（GRPO）算法进行强化学习（RL）训练可以增加用于生成更好回复的思考/推理令牌数量。然而，LLMs在每个计算步骤中生成有限数量的令牌，维持对之前生成的令牌的关注。这个限制，即LLM的上下文大小，限制了LLMs在处理任意大数量令牌时的推理能力。为克服这个限制，LLMs需要采用模块化的思考策略，在多轮次中进行推理。", "innovation": "本文提出了一种名为MOTIF（Modular Thinking via Reinforcement Finetuning，基于强化微调的模块化思考方法）的RL训练方法，该方法通过多轮次生成思考令牌，使模型能够在额外的上下文大小下进行思考。通过对比在GSM8K数据集上使用参数高效微调训练的开源模型Qwen2.5-3B-Instruct并测试其在MATH500和AIME2024基准上的准确性，实验结果显示出3.8%和3.3%的提升，且仅需15%的样本数据，展示了MOTIF的样本高效性。", "conclusion": "该方法通过增强LSTM或其他序列模型的记忆能力，有效地解决了文本文档生成中的上下文大小限制，从而提高了模型的推理能力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02752", "html_url": "https://arxiv.org/abs/2507.02752", "title": "由设计实现合成：一种 retrosynthesis 引导的分子类体生成框架", "title_en": "Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation", "authors": "Shuan Chen,Gunwook Nam,Yousung Jung", "background": "在计算药物和材料发现领域，尽管生成式人工智能迅速提出了具有理想性质的候选分子，但许多结构仍然难以或根本无法通过现有的化学反应进行合成。合成效能的缺乏成为计算设计与实验合成之间的重要瓶颈。现有机器学习模型虽然能够生成合成上可实现的结构，但仍存在结构相近性问题。现有的分子优化框架在合成可行性方面存在不足，无法确保合成效能。因此，需要一种新的合成导向的分子模拟设计框架来弥合这一差距，提供具有所需性质的合成分子的加速发现，适用于多种应用场景。", "innovation": "提出了一种名为 SynTwins 的分子模拟设计框架，通过三步过程——逆合成分析、类似构建块搜索和虚拟合成，模仿专家化学家的策略来设计合成效能良好的分子类体。SynTwins 在生成合成可实现分子方面的性能优于最先进的机器学习模型，同时保持高度的结构相似性。该框架与现有的分子优化框架结合后，生成了具有竞争性质配置的合成可行分子，而且合成效能得到了保证。通过跨多种分子数据集的全面基准测试，证明 SynTwins 有效解决了计算设计和实验合成之间的差距，提供了加速发现具有所需性质的合成分子的实用解决方案，适用于多种应用领域。", "conclusion": "综合多种分子数据集的基准测试表明，SynTwins 成功地将理论计算与实验合成连接起来，为发现具有所需性质的可供合成的分子提供了一个实际的、高效的解决方案，能够应用于药物、材料以及其他各种应用场景的分子发现过程。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02855", "html_url": "https://arxiv.org/abs/2507.02855", "title": "DHOL中的子类型系统 -- 扩展版本预印本", "title_en": "Subtyping in DHOL -- Extended preprint", "authors": "Colin Rothgang,Florian Rabe", "background": "依赖类型高阶逻辑(DHOL)提供了一种在表达能力和自动化支持之间的有趣折衷方案。DHOL通过牺牲类型系统的可判定性来显著扩展其表达能力，但仍然保持了通过将DHOL安全且完整地翻译到标准高阶逻辑(HOL)来支持强大的自动化定理证明能力。本文在此基础上进一步扩展了DHOL，引入了细化类型和商类型，这两种类型在自动定理证明器中几乎得不到支持，但因涉及不可判定的类型问题而难以添加。由于DHOL本身已解决这些复杂性问题，因此可以方便地添加细化类型和商类型而不改变原有表示方法，简化了设计过程并保持了系统的优雅性与简洁性。", "innovation": "本文将细化类型和商类型作为子类型系统的特殊情况添加到DHOL中。通过这种方式，关联的规范包含映射和投影映射被转换为身份映射，从而避免了昂贵的表示变化。此外，通过提供扩充语言的语法规则、语义和到HOL的翻译，并证明了它们的正确性和完整性，展现了这种扩展的有效性和实际可行性。", "conclusion": "本文通过在DHOL中引入细化类型和商类型，不仅解决了实际应用中常见的需求，还利用已有的DHOL框架简化了设计和实现过程。这种扩展增强了DHOL的实用性和灵活性，而不需要大幅度修改其原有结构，是一种实用且高效的扩展方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02861", "html_url": "https://arxiv.org/abs/2507.02861", "title": "LiteReality：从RGB-D扫描构建的图形兼容3D场景重建", "title_en": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans", "authors": "Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby", "background": "现有的3D重建方法能够转换室内环境的RGB-D扫描，但往往无法同时满足紧凑性、逼真度和交互性。此外，这些方法在对象个体性、物理质地和交互性等方面的支持不完善，无法广泛应用于增强现实/虚拟现实(AR/VR)、游戏、机器人技术和数字双生等场景。", "innovation": "LiteReality 提出了一种新的管道，能够将室内环境的RGB-D扫描转换为紧凑、逼真且可交互的3D虚拟副本。其主要创新点包括：1) 利用结构化的场景图进行场景理解与解析，生成连贯的3D布局和对象；2) 通过收藏目录检索最接近的3D艺术家设计模型进行场景重建；3) 通过材质绘画模块增强现实感，恢复高质量、空间变化的材质；4) 集成到仿真引擎中以实现基本的物理特性，使场景具备互动行为。此外，它还引入了一个无需训练的物体检索模块，达到了Scan2CAD基准上的最佳相似性性能，并且具有能够将任何风格的图像外观转移到3D资产中的鲁棒材质绘画模块，即使在严重对齐不良、遮挡和照明不良的情况下也能正常工作。", "conclusion": " LiteReality 的重建场景既紧凑又可编辑，与标准图形管道完全兼容，适用于AR/VR、游戏、机器人技术和数字双生等多种应用场景。项目页面及视频链接提供了相关资源。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02856", "html_url": "https://arxiv.org/abs/2507.02856", "title": "Answer Matching 出色于多项选择用于语言模型评估", "title_en": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation", "authors": "Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping", "background": "长期以来，多项选择基准一直被用作语言模型评估的工具，因为评分是客观的且易于自动化。然而，研究发现来自流行基准的多项选择问题往往可以在不看问题的情况下回答。这些捷径源于区分性评估的固有限制，这种评估不适用于模型生成答案的自由形式评估。直到最近，似乎没有可行的可扩展替代方案。因此，本文探讨了一种新的评估方法——答案匹配，并展示了其有效性。", "innovation": "本文提出了一种新的评估方法——答案匹配：给候选模型展示问题但不展示选项，让其生成自由形式的响应，然后使用现代语言模型和参考答案来判断响应是否匹配。作者还通过注释MMLU-Pro和GPQA-Diamond数据集，获取人类标注数据，测量每种评估方法的统一性。结果表明，使用最近的模型进行答案匹配，在一致性方面接近于人类标注者的一致性，而多项选择评估和没有参考答案的语言模型评估与人类标注的匹配度较差。这意味着评估策略的改进不只是概念上的问题，自由形式响应的评估排名也会显著变化。", "conclusion": "这些发现表明，应该从多项选择评估转向答案匹配，以改善评估生态系统的评估方法。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.05920", "html_url": "https://arxiv.org/abs/2408.05920", "title": "基于图的方法的城市地区预训练和提示", "title_en": "Urban Region Pre-training and Prompting: A Graph-based Approach", "authors": "Jiahui Jin,Yifan Song,Dong Kan,Haojia Zhu,Xiangguo Sun,Zhicheng Li,Xigang Sun,Jinghui Zhang", "background": "城市地区的表示对于各种下游城市任务至关重要。尽管有许多方法并取得了成功，但获取一般的城市地区知识并适应不同的任务仍然具有挑战性。现有工作在关注城市地区中的细粒度功能布局语义方面有限，限制了这些方法跨地区捕捉可迁移知识的能力。此外，对不同下游任务所需的独特特性和关系处理不足也可能妨碍有效的任务适应。文章指出，现有的方法不足以应对这些挑战。", "innovation": "文章提出了一种基于图的城市区域预训练和提示（GURPP）框架，以进行区域表示学习。该框架首先构建了一个城市区域图，并开发了一个以子图为中心的城市区域预训练模型，以捕捉实体间异质性和可转移的模式。该模型通过对比学习和多视图学习方法进行知识丰富的区域嵌入预训练。为了进一步细化这些表示，设计了两种基于图的提示方法：一种手动定义的提示以融入显式的任务知识，另一种任务可学习的提示以发现隐含知识，从而增强这些嵌入对不同任务的适应性。对多种城市区域预测任务以及不同城市的广泛实验表明，该框架具有优越的性能。", "conclusion": "基于GURPP框架的研究表明，通过构建城市区域图并采用对抗学习和多视图学习方法进行预训练，结合两种针对特定任务的提示方法，能够显著提高城市地区表示的学习能力和任务适应性。该框架在各种城市区域预测任务中表现出色。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.09919", "html_url": "https://arxiv.org/abs/2402.09919", "title": "基于GPS数据生成道路图：在建筑工地绘制道路", "title_en": "Road Graph Generator: Mapping roads at construction sites from GPS data", "authors": "Katarzyna Michałowska,Helga Margrete Bodahl Holmestad,Signe Riemer-Sørensen", "background": "从GPS轨迹推断道路以进行地图构建是一项挑战性的任务，尤其是面对建筑工地上的机械设备，它们的运动模式具有高度不规则性和非标准性，这极大不同于传统道路上的车辆交通。现有的方法在处理这样的数据时难以准确地识别交叉口和道路，尤其是在数据存在大量噪声或缺失更新的情况下。", "innovation": "本文提出了一种新颖的方法，通过识别网络中的交叉口作为关键决策点，然后将它们用边连接起来生成一个图。该方法能够有效处理GPS轨迹数据，即使在低噪声乃至完全没有噪声的情况下，也能完美地检测交叉口和推断道路。在更为复杂的路段中，该方法依然表现出色，但在高噪声环境中，性能会有一定程度的下降和不变的GPS位置更新缺失现象.", "conclusion": "本文通过一个真实世界的挪威建筑工地案例，验证了该方法的有效性。研究结果表明，该方法对于没有或几乎没有噪声的数据能够达到完美的精确度，但对于高噪声数据的表现会有所下降。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02827", "html_url": "https://arxiv.org/abs/2507.02827", "title": "USAD: 一种无监督数据增强空间时序注意力扩散网络", "title_en": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network", "authors": "Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li", "background": "人类活动识别（HAR）的主要目标是从传感器数据中推断出正在进行的人类动作。HAR 在健康监测、安全保护和体育分析等方面有着广泛的应用。尽管研究大量增加，但仍存在多个挑战，包括稀有活动的标注样本稀缺、高阶特征提取不足、以及在轻量设备上的模型性能不佳等问题。", "innovation": "该论文提出了一种基于多注意力交互机制的综合性优化方法。首先，一种无监督的、由统计引导的数据增强模型用于数据扩增，以缓解标记数据稀缺和严重类别不平衡的问题。其次，一种由多个分支构建的空间时序交互网络设计，可以并行捕捉序列数据中的多尺度特征，并通过不同大小的卷积核（3*3、5*5 和 7*7）来实现。同时，时间注意力机制和空间注意力机制被引入以识别关键时间点并增强传感器之间的交互。引入了跨分支特征融合单元以提高整体特征表示能力。最后，集成了一种自适应多损失函数融合策略，使损失权重能够动态调整并优化整个模型。该方法在三个公开数据集 WISDM、PAMAP2 和 OPPORTUNITY 上的实验结果显示，提出的无监督数据增强空间时序注意力扩散网络（USAD）分别实现了 98.84%、93.81% 和 80.92% 的高准确率，显著优于现有方法。此外，实际部署在嵌入式设备上验证了该方法的效率和可行性。", "conclusion": "该论文提出的 USAD 方法在多个公开数据集上显著优于现有方法，且在嵌入式设备上的部署验证了该方法的高效性和可行性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10768", "html_url": "https://arxiv.org/abs/2501.10768", "title": "MAPS: 提升专业物理科学领域的多模态推理", "title_en": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science", "authors": "Erle Zhu,Yadi Liu,Zhe Zhang,Xujun Li,Jin Zhou,Xinjie Yu,Minlie Huang,Hongning Wang", "background": "当前的多模态大语言模型（MLLM）在覆盖广泛文本和图像语料库训练后，在一般的视觉推理任务中表现出强大的能力。然而，它们在理解包含复杂物理结构的图表和基于多模态信息进行定量分析的物理领域中的表现仍然不足。为了解决上述问题，我们提出了一种名为多模态科学推理与物理感知与模拟（MAPS）的新框架，基于MLLM进行开发。", "innovation": "MAPS 框架通过物理感知模型（PPM）分解了专家级别的多模态推理任务，该模型通过精细调用视觉语言模型并在精心设计的合成数据（包括物理图表和相应的模拟语言描述）上进行训练得到。在推理阶段，MAPS 将 PPM 提供的输入图表的模拟语言描述和通过链式推理（Chain-of-Simulation）过程检索的模拟结果与 MLLM 融合，以推导出潜在的推理依据和最终答案。", "conclusion": "通过我们收集的大学级电路分析问题进行验证，MAPS 显著提高了MLLM 的推理准确性，并优于所有现有的模型。结果证实 MAPS 为提升多模态科学推理能力提供了有希望的方向。论文发表后，我们将发布我们的代码、模型和实验使用的数据集。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.18624", "html_url": "https://arxiv.org/abs/2409.18624", "title": "无监督认知", "title_en": "Unsupervised Cognition", "authors": "Alfredo Ibias,Hector Antona,Guillem Ramirez-Miranda,Enric Guinovart,Eduard Alarcon", "background": "目前最成功的无监督学习方法主要集中在数学空间内对样本进行聚类。这项研究提出了一种基于基本单位的无监督学习方法，该方法受新颖的认知框架启发，具有代表性的策略能够以输入无关的方式构建输入空间的分布式层次结构。研究通过将该方法与当前最优的无监督学习分类、针对小型和不完整数据集的分类以及针对癌症类型的分类进行比较，展示了其优越性。研究还评估了提案的认知像特性，不仅在性能上超越了其他比较算法（包括监督学习算法），还展示了不同且更为类似于认知的行为特征", "innovation": "提出了一种基于基本单位的、代表性的无监督学习方法，这种方法受新颖的认知框架启发。该方法以输入无关的方式构建输入空间的分布式层次结构，相较于现有技术，展现出更好的性能并提供了更类似于认知行为的特性", "conclusion": "与现有最先进的无监督学习方法相比，该提案在性能上表现出优越性；不仅超越了其他比较算法（包括传统的监督学习算法），还展示了更类似认知行为的表现"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.07139", "html_url": "https://arxiv.org/abs/2504.07139", "title": "2025年人工智能指数报告", "title_en": "Artificial Intelligence Index Report 2025", "authors": "Nestor Maslej,Loredana Fattorini,Raymond Perrault,Yolanda Gil,Vanessa Parli,Njenga Kariuki,Emily Capstick,Anka Reuel,Erik Brynjolfsson,John Etchemendy,Katrina Ligett,Terah Lyons,James Manyika,Juan Carlos Niebles,Yoav Shoham,Russell Wald,Tobi Walsh,Armin Hamrah,Lapo Santarlasci,Julia Betts Lotufo,Alexandra Rome,Andrew Shi,Sukrut Oak", "background": "自2017年作为百年人工智能研究的一个衍生项目建立以来，人工智能指数一直致力于为政策制定者、记者、执行官、研究人员和公众提供准确、严格验证和全球来源的数据。该报告作为年度 AI 发展的详细跟踪和解读，涵盖了从地缘政治格局的变化到 AI 在商业、政策制定和公共生活中的扩展角色等关键趋势。它在全球范围内被广泛引用、在学术界广泛参考，并被世界各地的政策制定者和政府机构使用。2025 年报告为这一系列的努力注入了新的数据和分析，并在世界经济和全球治理中扩大了 AI 的作用.", "innovation": "今年报告中新增了对 AI 硬件演变场景的深入分析，新的推理成本估算方法，以及 AI 出版和专利趋势的新分析。此外，报告还介绍了企业负责任 AI 实践的采用新数据，并对 AI 在科学和医学中的作用进行了扩大覆盖。这些创新内容帮助更全面地理解 AI 的当前状态和未来发展路径，为进一步的研究和发展提供了直接的参考和支持.", "conclusion": "2025 年的人工智能指数报告强调了 Equip 部门继续在追踪和解读塑造该领域的关键趋势，对于在日益复杂的地缘政治格局以及AI 技术的快速演进中更好地了解 AI 的当前状况和未来走向至关重要。通过提供持续的纵向跟踪，人工智能指数继续在帮助利益相关人员做出更明智的 AI 开发和部署决策方面发挥着核心作用，使 AI 各领域的参与者能更好地应对 AI 的日益增长的影响力和使用范围。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.07618", "html_url": "https://arxiv.org/abs/2411.07618", "title": "使用稀疏特征级约束的直接偏好优化", "title_en": "Direct Preference Optimization Using Sparse Feature-Level Constraints", "authors": "Qingyu Yin,Chak Tou Leong,Hongbo Zhang,Minjun Zhu,Hanqi Yan,Qiang Zhang,Yulan He,Wenjie Li,Jun Wang,Yue Zhang,Linyi Yang", "background": "大型语言模型（LLMs）与人类偏好对齐仍然是一个关键挑战。虽然后训练技术如基于人类反馈的强化学习（RLHF）和直接偏好优化（DPO）已经取得了显著的成功，但它们往往引入了计算效率低下和训练不稳定性的问题。这些方法在提升模型性能的同时，增加了训练的复杂性和资源消耗，制约了其广泛应用。本研究的背景是寻找一种新颖的对齐方法，既能保证模型对齐的有效性，又能提高计算效率和降低训练的复杂性。", "innovation": "本文提出了一种新颖的方法，名为特征级约束偏好优化（FPO），旨在简化对齐过程并确保稳定性。FPO 利用了预训练的稀疏自编码器（SAEs）并引入了特征级约束，使得模型可以在稀疏特征激活的基础上高效地进行对齐，同时利用特征级离线参考的序列 KL 散度来保证质量。这种方法通过使用稀疏自编码器中有效激活的稀疏特征，以及特征级轮廓 KL 散度，提高了计算效率和对齐精度，进而实现了对LLMs的有效和可控的对齐。", "conclusion": "在基准数据集上的实验结果显示，FPO 在无明显降低计算成本的前提下实现了5.08%的胜率绝对提升，这表明FPO提供了一种高效的、可控制的LLM对齐解决方案，是现有最先进的基线方法的有利补充。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20127", "html_url": "https://arxiv.org/abs/2505.20127", "title": "基于代理型AI进程可观性的行为变异发现", "title_en": "Agentic AI Process Observability: Discovering Behavioral Variability", "authors": "Fabiana Fournier,Lior Limonad,Yuval David", "background": "代理型AI系统依赖于大规模语言模型（LLMs），已成为现代软件系统的核心构建块。各种框架用于规范此类应用的定义，这些框架允许通过自然语言提示来定义代理的设置，其中包括各个代理的角色、目标和工具。在这些设置中，对于任何给定的输入，代理行为都是非确定性的，这突显了需要强大的调试和可观测性工具的必要性。", "innovation": "本文探讨了将过程发现和因果发现应用于代理执行轨迹，以增强开发人员的可观测性。这种方法有助于监控和理解代理行为中出现的变异。此外，通过使用基于LLM的静态分析技术来区分有意和无意的行为变异，以补充这一方法。我们主张这种工具对于开发人员更好地控制不断演化的规范并识别可能需要更精确和明确定义的功能方面至关重要。", "conclusion": "此类工具对于开发人员具有重要意义，能够增强他们对动态规范的控制，并识别功能方面可能需要更精确和明确的定义。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03997", "html_url": "https://arxiv.org/abs/2506.03997", "title": "Answer Set Programming 中的条件推理框架", "title_en": "A framework for Conditional Reasoning in Answer Set Programming", "authors": "Mario Alviano,Laura Giordano,Daniele Theseider Dupré", "background": "文章介绍了一种条件回答集编程框架（Conditional ASP），用于定义回答集编程（ASP）的条件扩展。这种方法基于典型性条件逻辑，并结合了条件知识库和ASP程序，允许在程序的解答集中进行条件推理。该形式化方法依赖于多偏好语义（以及其特例KLM偏好语义）来解释条件语句的含义，为条件推理提供了一个框架。", "innovation": "创新点在于提出了一种新的条件回答集编程框架（Conditional ASP），它基于典型性条件逻辑，并结合了条件知识库和ASP程序，使得能够对ASP程序的解答集进行条件推理。特别地，它依赖于多偏好语义以及KLM偏好语义来提供条件语句的解释。", "conclusion": "本文提出了一个新的条件回答集编程框架来扩展ASP中的条件推理能力，并依赖多偏好语义及KLM偏好语义进行条件语句的解释，这一框架为条件推理提供了一个强有力的新工具。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.04614", "html_url": "https://arxiv.org/abs/2501.04614", "title": "XGeM：用于多模态医学数据生成的多提示基础模型", "title_en": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation", "authors": "Daniele Molino,Francesco Di Feola,Eliodoro Faiella,Deborah Fazzini,Domiziana Santucci,Linlin Shen,Valerio Guarrasi,Paolo Soda", "background": "医学成像中的人工智能采用前景广阔，但面临诸多挑战，包括数据稀缺性、隐私问题以及需要强大的多模态整合。虽然生成模型的进步使得高保真合成数据的生成成为可能，但现有方法通常局限于单一模态和单向合成，缺乏联合合成多种模态并保持临床一致性的能力。为解决这一挑战，本文介绍了一种名为XGeM的67.7亿参数的多模态生成模型，它能够灵活地支持医学数据模态之间的任意到任意合成。XGeM通过对比学习构建共享潜空间，并引入一种新的多提示训练策略，允许模型对输入模态的任何子集进行条件处理。这种设计使模型能够适应异质的临床输入，并生成多个联合输出，同时保持语义和结构的一致性。对该模型进行了广泛的验证，包括与五个竞争对手在MIMIC-CXR数据集上的基准测试，以及由专家放射科医生进行的视觉图灵测试，以评估生成数据的现实性和临床相关性。此外，还展示了如何使用XGeM来支持医学数据的关键挑战，如匿名化、类别不平衡和数据稀缺性，强调了其作为医学数据合成基础模型的实用性。", "innovation": "本文提出了XGeM，一种多模态生成模型，具有67.7亿参数。它通过对比学习构建共享潜空间，并引入多提示训练策略，能够灵活适应不同输入模态的子集，并能够联合生成临床一致性高的多模态数据。这种方法解决了现有模型在单一模态和单向合成方面的局限性，提高了合成数据的质量和临床应用的实用性。", "conclusion": "本文通过广泛的实验验证了XGeM的有效性，展示其在医学数据合成中的应用潜力，特别是解决数据稀缺、隐私保护和多模态整合等挑战。XGeM作为基础模型，可以支持关键的医学数据任务，如数据匿名化、类别均衡和数据生成，发挥了重要作用。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22355", "html_url": "https://arxiv.org/abs/2506.22355", "title": "具身AI代理：建模世界", "title_en": "Embodied AI Agents: Modeling the World", "authors": "Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hongyu Gong,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Louis-Philippe Morency,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Paden Tomasello,Jitendra Malik", "background": "该论文介绍了对具身在视觉、虚拟或物理形式中的AI代理的研究，这些代理能够与用户及其环境进行互动。这些代理包括虚拟化身、可穿戴设备和机器人，它们设计为在周围环境中感知、学习和行动，使其在学习和环境互动方式上更加类似于人类。同时，与不具备身体的代理相比，这些代理更加相似于人类如何学习环境以及如何与环境互动的方式。", "innovation": "本文提出了世界模型在具身AI代理的推理和规划中的核心地位，使这些代理能够理解和预测其环境，理解用户意图和社会背景，从而加强其自主执行复杂任务的能力。世界建模包括多模态感知、通过推理进行动作和控制的计划以及记忆，以创建物理世界的全面理解。此外，文章还建议学习用户的心理世界模型，以实现更好的人机协作。", "conclusion": "构建世界模型对于具身AI代理的能力至关重要，使其不仅能理解和预测物理环境，还能理解用户的意图和社交背景，从而更好地执行复杂任务并实现有效的人机协作。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23486", "html_url": "https://arxiv.org/abs/2505.23486", "title": "大型语言模型时代的自动形式化：综述", "title_en": "Autoformalization in the Era of Large Language Models: A Survey", "authors": "Ke Weng,Lun Du,Sirui Li,Wangyue Lu,Haozhe Sun,Hengyu Liu,Tiancheng Zhang", "background": "自动形式化是将非形式化的数学命题转换为可验证的形式表示的过程，在自动定理证明中是一个基础任务，为理论和应用领域的数学使用提供了新的视角。随着人工智能，尤其是大型语言模型的快速发展，自动形式化领域取得了显著进步，带来了新的机遇和独特的挑战。本文对该领域的最新进展进行了全面综述，包括数学和大型语言模型方面的视角，并探讨了自动形式化在不同数学领域和难度级别的应用情况，以及从数据预处理到模型设计和评估的整个工作流程。此外，文中还讨论了自动形式化在提高大型语言模型生成输出的验证性方面的新兴作用，强调了其提高大型语言模型的可信度和推理能力的潜力。最后，总结了当前研究中支持的关键开源模型和数据集，并讨论了该领域存在的关键挑战和有希望的未来方向。", "innovation": "通过介绍大型语言模型的发展如何推动自动形式化领域的进步，文中提供了对自动形式化从数学和大型语言模型视角的最新进展的全面综述。文中探讨了自动形式化如何应用于不同数学领域和难度级别，并分析了整个工作流程从数据预处理到模型设计和评估。此外，文章还重点讨论了自动形式化如何增强大型语言模型生成输出的验证性，强调了其提高大型语言模型的可信度和推理能力的潜力，并总结了支持当前研究的关键开源模型和数据集。", "conclusion": "最后，文章总结了当前研究中支持的关键开源模型和数据集，并讨论了自动形式化领域中存在的关键挑战和有希望的未来方向，特别强调了自动形式化在提高大型语言模型的可信度和推理能力方面的潜在价值。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2303.06827", "html_url": "https://arxiv.org/abs/2303.06827", "title": "Kernel Density Bayesian Inverse Reinforcement Learning", "title_en": "Kernel Density Bayesian Inverse Reinforcement Learning", "authors": "Aishwarya Mandyam,Didong Li,Jiayu Yao,Diana Cai,Andrew Jones,Barbara E. Engelhardt", "background": "逆向强化学习（IRL）方法通过专家行为的演示来推断代理的奖励函数。传统的贝叶斯IRL算法需要大量的演示数据集，而在实际应用中这些数据可能无法获得。论文探讨了在有专家演示和已知奖励函数的训练任务数据时，推断新测试任务奖励函数的问题。现有的贝叶斯IRL方法对输入数据的形式有限制，限制了训练任务数据的使用。", "innovation": "引入了一种新的方法——核密度贝叶斯逆强化学习（KD-BIRL），它使用已知的训练任务奖励函数来改进不同奖励函数和演示样本下的似然估计。KD-BIRL的实验证明了其在测试任务专家数据较少时更快的收敛速率，并且首次提供了贝叶斯IRL算法后验收敛的理论保证。", "conclusion": "这项工作提供了一个原则性的、理论依据强的方法框架，使得贝叶斯IRL能够应用于多种领域。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12479", "html_url": "https://arxiv.org/abs/2506.12479", "title": "AI Flow: 视角、场景和方法", "title_en": "AI Flow: Perspectives, Scenarios, and Approaches", "authors": "Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li", "background": "自克劳德·香农的信息理论和艾伦·图灵的机器智能框架问世以来，信息技术（IT）和通信技术（CT）的发展已相互融合，创造出持久的连接与计算浪潮。此协同作用催生了一场科技革命，并达到了大规模人工智能（AI）模型重塑行业和重新定义人机协作的顶峰。然而，由于大型模型对资源的巨大消耗和高通信带宽需求，实现无所不在的智能仍面临许多挑战。", "innovation": "AI Flow 引入了一个多学科框架，集成了最新的 IT 和 CT 进步，特别强调以下三点：1) 装置-边缘-云框架作为基础，将终端设备、边缘服务器和云集群整合起来优化低延迟模型推断的可扩展性和效率；2) 引入了家庭模型的概念，即一系列具有对齐隐层特征的不同大小的模型，使有效合作和适应不同资源限制与动态场景的变化更加灵活；3) 基于连接与交互的情境智能涌现是 AI Flow 的一种新范式，通过利用通信网络增强连接，跨异质节点的 AI 模型协同作用实现超越单一模型能力的涌现智能。", "conclusion": "AI Flow 的创新提供了增强的人工智能、及时响应和广泛的可访问性，为人工智能技术和通信系统的更紧密融合铺平了道路。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.08062", "html_url": "https://arxiv.org/abs/2402.08062", "title": "通过求助避免在线学习中的灾难", "title_en": "Avoiding Catastrophe in Online Learning by Asking for Help", "authors": "Benjamin Plaut,Hanlin Zhu,Stuart Russell", "background": "大多数具有显式遗憾保证的学习算法假定所有错误都是可恢复的，并且主要依赖于尝试所有可能的行为。然而，在一些情况下，某些错误可能是‘灾难性的’，即不可修复的，这种假设使得已有方法不够适用。因此，论文聚焦于解决一类新的在线学习问题，即不仅要避免灾难性事件，同时还要在可能的情况下寻求导师的帮助，并能从相似输入中迁移知识。", "innovation": "论文提出了一个在线学习问题，并设计了一种算法，其目标是在保证避免灾难事件可能性最大化的同时，允许有限次数的向导师求助，并且可以将知识迁移到相似输入中。特别地，在导师行为可以在线模型中被学习的情境下，该算法的遗憾损失和求助频率都能在时间范围内趋近于零。论文不仅证明了在产品收益方面的新结果，也提供了匹配的常规加性遗憾的界限。", "conclusion": "对于可学习的政策类，在不存在灾难风险的情况下可学习，在存在灾难风险的情况下，如果代理可以求助，则同样也可学习。同时证明了在一般情况下，任何算法要么以线性速率求助于导师，要么几乎肯定会引发灾难事件。然而，在可以学习导师策略类的标准在线模型中，则可以提供一个算法，该算法在时间范围内减小偏差并接近最优。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2306.13840", "html_url": "https://arxiv.org/abs/2306.13840", "title": "超越规模：数据质量衡量中的多样系数用于自然语言数据中的变异性", "title_en": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data", "authors": "Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo", "background": "当前在预训练大型语言模型（LLMs）的研究主要集中在模型和数据集的规模上。虽然高质量的预训练数据被视为训练强大LLMs的关键因素，但数据质量的概念仍模糊未明，缺乏严格的界定。因此，该研究提出了一种衡量自然语言数据多样性和变异性关键方面的全新方法——通过计算多样性系数。研究还分析了公共预训练数据集的多样性系数，发现其实际多样性高于理论上下界。此外，还进行了控制干预实验，验证了多样性系数与下游模型评估性能之间的相关性。", "innovation": "提出了衡量自然语言数据多样性和变异性的一种全新方法——多样性系数，为预训练LLMs提供了一个新的数据质量衡量标准。“多样性系数”首次正式化了关于数据质量的关键方面，这有助于更准确地评估预训练数据的质量，并可能优化下游模型的评估性能。该方法创新地将自然语言数据的复杂性量化为一个可操作的数值指标，提供了一种系统化的视角来评估数据的质量。", "conclusion": "研究表明，我们的正式多样性概念不仅捕捉到了数据的质量特征，还间接导致了评估性能的改进。因此，该研究得出结论，正式化的多样性度量是一个重要的数据质量维度，具有重要的实践价值和理论意义。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21506", "html_url": "https://arxiv.org/abs/2506.21506", "title": "Mind2Web 2：通过代理作为评判者评估自主搜索", "title_en": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge", "authors": "Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su", "background": "代理搜索，如Deep Research系统，是指代理自主浏览网络、综合信息并提供全面的有背书的参考文献答案，这种方式代表了用户与大规模网络信息互动方式的重要变革。尽管这种搜索提高了效率并且减轻了认知负担，但其复杂性和开放性逐渐超出现有的评估基准和方法，这些方法主要假设短搜索周期和静态答案。", "innovation": "本文介绍了Mind2Web 2，这是一个包含130个现实、高质量且长时间任务的基准，需要实时网络浏览和广泛的综合信息。为了评估时间变化和复杂的答案，本文提出了一个新的「代理作为评判者」框架。该方法基于树状结构评分表设计构建特定任务的比赛代理，以自动评估答案的正确性和来源归属。该论文还对十个领先代理搜索系统的性能和人类表现进行了全面评估，并进行了详细的错误分析，以揭示未来开发的洞察。", "conclusion": "最好的系统，OpenAI Deep Research，已经达到了人类表现的50-70%的水平，但花费了一半的时间，这显示了其巨大的潜力。总的来说，Mind2Web 2为开发和基准测试下一代代理搜索系统提供了严格的基石。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.05766", "html_url": "https://arxiv.org/abs/2405.05766", "title": "向XAI系统中用户信任的新度量方法迈进", "title_en": "Towards a Novel Measure of User Trust in XAI Systems", "authors": "Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho", "background": "深度学习模型的应用日益广泛，但其固有的透明度缺乏问题也引起了广泛关注。这一挑战催生了可解释人工智能（XAI）方法这一新的研究领域。XAI方法的目标是通过提供自动化系统决策背后的洞察来增强最终用户的信任度。本文探讨了如何量化和提升XAI系统的用户信任度，特别提出了一种结合性能指标和客观信任指标的新度量方法。通过三个案例研究，验证了该方法的有效性及其在处理不同场景时的灵敏度提升，表明该方法优于现有技术。", "innovation": "提出了一个全新的用户信任度量方法，该方法结合了性能指标和客观的信任指标，可以有效提升XAI系统的用户信任度，并展示了在多种场景中的效能改进，提高了方法的敏感度和实用性。", "conclusion": "本文通过实证研究，证明了新提出的用户信任度量方法的有效性和优越性。这种新的度量方法对于提高XAI系统的透明度和信任度具有重要意义，是XAI研究领域的一个重要进步。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.08010", "html_url": "https://arxiv.org/abs/2311.08010", "title": "通过不确定性感知教师学习和学生-学生协作学习提高远程监督命名实体识别的鲁棒性", "title_en": "Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning", "authors": "Shuzheng Si,Helan Hu,Haozhe Zhao,Shuang Zeng,Kaikai An,Zefan Cai,Baobao Chang", "background": "远程监督命名实体识别（DS-NER）在实际应用场景中被广泛使用，它可以有效缓解标注负担，但面临标签噪声问题。现有的教师-学生框架方法试图逐渐细化训练标签，提高整体鲁棒性，但这些方法取得的性能有限，因为教师网络的校准不良会产生错误的伪标签，导致错误传播。", "innovation": "本文提出了两种创新方法：（1）不确定性感知教师学习，利用预测不确定性减少自训练阶段中不正确的伪标签数量；（2）学生-学生协作学习，允许两个学生网络之间可靠标签的转移，而不是无差别地依赖其教师的所有伪标签，进一步使模型能够充分探索被错误标记的样本而非简单地过滤掉不可靠的伪标签。", "conclusion": "本文在五个DS-NER数据集上评估了所提出的方法，结果显示该方法优于现有最先进的DS-NER方法。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.07079", "html_url": "https://arxiv.org/abs/2408.07079", "title": "Anatomical Foundation Models for Brain MRIs", "title_en": "Anatomical Foundation Models for Brain MRIs", "authors": "Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto", "background": "神经影像学中的深度学习（DL）已被证明对检测神经和神经退行性疾病非常重要。脑年龄是神经影像学中最重要的生物标志物之一，已被证实是预测阿尔茨海默病等不同疾病的良好指标。对于不同疾病的标注数据稀缺性，使用脑年龄进行弱监督预训练得到的深度学习模型表现出了很有前景的结果。脑MRI的解剖信息（如皮质厚度）能够提供重要的信息，用于学习能转移给许多下游任务的良好表示。现有的弱监督预训练方法通常是在数据稀缺的条件下实现良好效果的新方法，本文在此基础上进一步推进。", "innovation": "本文提出了AnatCL，一种脑MRI的解剖基础模型。该模型通过弱对比学习方法利用解剖信息，在多个下游任务中达到了最先进的性能。与现有方法相比，引入解剖信息的预训练方法在生成更具鲁棒性和可泛化的表示方面表现更优。并且，本文评估了12种不同的下游任务，涉及不同疾病的诊断（如阿尔茨海默病、自闭症谱系障碍、精神分裂症）以及使用结构MRI数据预测10种不同的临床评估分数。", "conclusion": "本文的研究发现，在预训练过程中结合解剖信息能够生成更稳健和泛化的表示。预训练模型可以在以下链接找到：this https URL."}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12537", "html_url": "https://arxiv.org/abs/2410.12537", "title": "复杂查询回答真的复杂吗？", "title_en": "Is Complex Query Answering Really Complex?", "authors": "Cosimo Gregucci,Bo Xiong,Daniel Hernandez,Lorenzo Loconte,Pasquale Minervini,Steffen Staab,Antonio Vergari", "background": "知识图谱(KGs)上的复杂查询回答(CQA)作为一项具有挑战性的推理任务，正逐渐成为研究热点。现有关于CQA的基准可能没有我们想象的那么复杂，因为它们的构建方式扭曲了我们对该领域进展的感知。许多查询可以简化为链接预测等单一链接预测问题，现存的模型在评估中表现较差，尤其是在无法简化为较简单类型的问题上。", "innovation": "本文提出了更具挑战性的基准，包括需要模型在多个跳步上进行推理的查询，更好地反映真实世界的知识图谱构建。", "conclusion": "新的基准测试显示，当前的方法在复杂查询回答方面还有很大的改进空间。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.06416", "html_url": "https://arxiv.org/abs/2409.06416", "title": "探索大语言模型在工业测试维护过程中的集成", "title_en": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes", "authors": "Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg", "background": "软件测试过程中，大量的成本和努力都投入到测试维护中，即通过添加、删除或修改测试案例以保持测试套件与被测系统同步或提高其质量。工具支持可以降低测试维护的成本并提高其质量，例如通过自动化测试维护过程的某些方面或为开发人员提供指导和支持。研究团队在埃里森AB公司进行了一项案例研究，探索了触发测试维护需求的信号、大语言模型可采取的行动以及在工业环境中部署这些模型时需要考虑的因素。", "innovation": "研究利用大语言模型（LLMs）来支持测试维护，这是一种适用于文本分析的复杂机器学习模型。研究团队提出了一个多代理架构，该架构可以根据源代码更改预测哪些测试需要维护。这一研究成果推进了我们对如何部署大语言模型以造福工业测试维护过程的理解。", "conclusion": "研究团队通过案例研究展示了大语言模型在工业测试维护中的应用和潜在价值，总结了在工业环境中部署大语言模型时需要注意的关键因素。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.06902", "html_url": "https://arxiv.org/abs/2407.06902", "title": "来自嘈杂 crowdsourced 标签的学习：信号处理视角", "title_en": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective", "authors": "Shahana Ibrahim,Panagiotis A. Traganitis,Xiao Fu,Georgios B. Giannakis", "background": "人工智能和机器学习的进步主要得益于大数据集的可用性。通常使用众包方法对这些大数据集进行整理，但这种方式往往产生噪声标签，因此关键挑战是如何开发有效的方法来减轻噪声标签对学习任务的负面影响。本文介绍了在嘈杂的众包标签下进行学习的进展，重点讨论了关键的众包模型及其方法论处理，从经典的统计模型到现代的深度学习方法，强调了分析洞察和算法开发，并结合信号处理理论方法和技术，展示了信号处理视角如何推动该领域的进步。", "innovation": "结合信号处理理论（如张量的可识别性、非负矩阵分解等），提出了信号处理视角下的新型、原则性解决方案，解决了众包领域长期以来的重大挑战。并探讨了强化学习下的人工反馈（RLHF）和直接偏好优化（DPO），这些是用于微调大型语言模型的关键技术，强调了其对发展尖端的人工智能/机器学习系统的重要性。", "conclusion": "本文从信号处理的视角出发，回顾并探讨了来自嘈杂众包标签的学习方法，并突出了信号处理理论如何在解决长期存在的问题上发挥关键作用。同时，文章还讨论了一些新兴的主题，这些主题对于发展最新的人工智能/机器学习系统至关重要。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.07016", "html_url": "https://arxiv.org/abs/2406.07016", "title": "通过过剩词汇分析探究生物医学出版物中LLM辅助写作", "title_en": "Delving into LLM-assisted writing in biomedical publications through excess vocabulary", "authors": "Dmitry Kobak,Rita González-Márquez,Emőke-Ágnes Horvát,Jan Lause", "background": "大型语言模型（LLMs）如ChatGPT可以生成和修订具有人类水平性能的文本。尽管这些模型存在明显的局限性，如生成不准确的信息、强化现有的偏见以及容易被滥用，但许多科学家仍使用它们进行学术写作。然而，在学术文献中，这种LLM的使用范围如何？为了回答这一问题，特别是在生物医学研究领域，作者采用了无偏见、大规模的方法，研究了2010年至2024年间PubMed索引的超过1500万篇生物医学摘要中的词汇变化，展示了LLM的出现导致某些风格词频率的急剧增加。通过过剩词分析得出，至少有13.5%的2024年摘要经过了LLM的处理。不同学科、国家和期刊之间存在差异，某些子集中的比例达到40%。作者还表明，LLM对生物医学研究中的科学写作产生了前所未有的影响，甚至超过了新冠疫情等重大世界事件的影响。", "innovation": "作者提出了一种大规模且无偏见的方法来探究生物医学研究领域中LLM的使用情况，通过分析大量文献中的词汇变化揭示了LLM的使用比例，并强调了其对科学写作的显著影响。这种方法不仅提供了相关比例的定量数据，还为理解科学写作的演变提供了新的视角。", "conclusion": "LLM已对生物医学研究领域的科学写作产生了前所未有的影响，至少13.5%的2024年摘要被使用了LLM进行处理。不同领域、国家和期刊之间的差异显著，某些亚组甚至达到了40%的比例。这种影响已超越了重大世界事件（如Covid疫情）所带来的影响。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.08500", "html_url": "https://arxiv.org/abs/2410.08500", "title": "基于语义-拓扑-度量表示指导大语言模型推理的空中视觉-语言导航", "title_en": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning", "authors": "Yunpeng Gao,Zhigang Wang,Linglin Jing,Dong Wang,Xuelong Li,Bin Zhao", "background": "空中视觉-语言导航（Aerial Vision-and-Language Navigation，简称Aerial VLN）是一个新颖的任务，使无人驾驶飞行器（UAVs）能够通过自然语言指令和视觉线索导航到户外环境中。由于户外空旷场景中的复杂空间关系，这一任务依然颇具挑战性。现有研究主要集中在如何使大语言模型（LLMs）具备空间推理能力，以准确理解自然语言指令，并据此决定飞行器的行动。", "innovation": "论文提出一种全端到端的零样本框架，其中引入了大语言模型（LLMs）作为代理进行行为预测。文章开发了一种新的语义-拓扑-度量表示（STMR），通过提取地标的语义掩码并将其投影到包含周围地标位置信息的俯视图地图上，增强LLMs的空间推理能力。进一步将该地图转换成一个带有距离测量的矩阵表示，作为文本提示提供给LLM，以根据指令进行行为预测。实验证明该方法在实际和模拟环境中都有效且稳健，相较于AerialVLN-S数据集，其Oracle Success Rate (OSR)提高了15.9%和12.5%的绝对值。", "conclusion": "研究提出的方法在真实和模拟环境中得到了验证，证明了在基于大语言模型的空中视觉-语言导航任务中的有效性和适用性，为复杂户外空旷场景中的路径规划提供了新的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.15026", "html_url": "https://arxiv.org/abs/2408.15026", "title": "Echocardiography Probe Movement Guidance Based on Sequence-aware Pre-training", "title_en": "Sequence-aware Pre-training for Echocardiography Probe Movement Guidance", "authors": "Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang", "background": "心脏超声检查是诊断心血管疾病的必要技术，但由于其操作复杂性导致专业技术人员短缺。心脏结构复杂且个体间差异显著，现有方法仅学习群体平均心脏结构而非个性化心脏结构，导致性能瓶颈。临床观察表明，超声技师根据先前的扫描序列动态调整对患者心脏解剖结构的解释，从而细化扫描策略。", "innovation": "提出了一种序列感知的自监督预训练方法，通过预测扫描序列中被遮罩的图像特征和探头移动动作来学习个性化三维心脏结构特征。假设如果模型能预测缺失的内容，就表明它已很好地理解了个性化心脏结构。实验结果表明，所提出的序列感知范式能够有效减少探头指导错误，优于其他先进基线方法。", "conclusion": "大规模专家扫描数据集上的实验显示，所提出的序列感知预训练方法能有效减少探头指导错误，相比其他先进基线方法具有优势。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.03133", "html_url": "https://arxiv.org/abs/2407.03133", "title": "使用潜在类别分析量化多组之间的跨部门交叉差异以实现公平性", "title_en": "Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness", "authors": "Yingfang Yuan,Kefan Chen,Mehdi Rizvi,Lynne Baillie,Wei Pang", "background": "对公平AI发展的兴趣日益增长。'不让任何人落后'倡议要求我们关注获取服务、资源和机会中的多种和交叉形式的不平等，并强调AI中的公平性的重要性。随着越来越多的AI工具应用于决策过程，特别是在卫生、能源和住房等多个领域中的资源分配和服务方案开发，探索跨部门的不平等变得至关重要。因此，研究旨在通过潜在类别分析量化用户定义群体之间的跨部门交集差异，这些差异可用于近似不平等并提供公平性问题的洞察。本文通过使用公共和私人数据集对这一方法进行了验证，包括EVENS和2021年英格兰和威尔士人口普查数据集，以检查不同族群之间跨部门的交叉差异。我们还通过与政府公开指标的相关性分析验证了量化的差异可靠性。研究发现，无论是少数民族群体之间还是少数民族群体与非少数民族群体之间都存在显著差异，突显了政策制定过程中实施针对性干预措施的必要性。此外，我们展示了该方法如何为确保机器学习系统的公平性提供有价值的观点。", "innovation": "该研究引入了一种创新的方法，使用潜在类别分析量化用户定义群体之间的跨部门交叉差异。这些差异可以用来近似不平等并提供公平性问题的洞察。该方法通过公共和私人数据集进行了验证，包括EVENS和2021年英格兰和威尔士人口普查数据集，以检查不同族群之间跨部门的交叉差异，以及通过与政府公开指标的相关性分析验证了差异的可靠性。", "conclusion": "研究表明，无论是少数民族群体之间还是少数民族群体与非少数民族群体之间都存在显著差异，突显了政策制定过程中实施针对性干预措施的必要性。此外，本文展示了该方法如何为确保机器学习系统的公平性提供有价值的观点。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.08290", "html_url": "https://arxiv.org/abs/2409.08290", "title": "重新考量脉冲神经网络的能效", "title_en": "Reconsidering the energy efficiency of spiking neural networks", "authors": "Zhanglu Yan,Zhenyu Bai,Weng-Fai Wong", "background": "脉冲神经网络(SNNs)由于其事件驱动和脉冲为基础的计算方式，相较于传统量化人工神经网络(QNNs)具有更高的能效。然而，现有的能效评估往往简化计算，仅关注计算层面而忽视了全面的数据移动和内存访问等关键开销，导致对于SNNs真正能效优势的错误结论。", "innovation": "本文提出了一个严格的重新评估。通过将脉冲编码SNNs在T个时间步骤映射为功能等效的QNNs，以$\text{ceil}(\text{log}_2(T+1))$位表示。建立了公平的标准，确保两种模型在表示能力和硬件需求上具有可比性，从而能够进行有意义的能量比较。引入了包括核心计算和数据传输（稀疏和密集激活、权重）在内的详细分析能耗模型，系统地探索了广泛参数空间，涵盖了内在网络特性（T，突触率sr，QNN稀疏度γ，模型大小N，权重位级别）和硬件特性（内存系统和网络芯片）。", "conclusion": "分析发现特定的操作模式下SNNs确实具有卓越的能效。例如，在典型的神经形态硬件条件下，对于中等时间窗口（T ∈ [5,10]），SNNs所需的平均突触率（sr）低于6.4%才能超越相应的QNNs。这些洞察为设计真正的能效神经网络解决方案提供了指导。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.11556", "html_url": "https://arxiv.org/abs/2412.11556", "title": "Token Prepending: 一种无需训练可获得更好LLM句嵌入的方法", "title_en": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs", "authors": "Yuchen Fu,Zifeng Cheng,Zhiwei Jiang,Zhonghui Wang,Yafeng Yin,Zhengliang Li,Qing Gu", "background": "从大型语言模型（LLMs）中提取句子嵌入是一个有前景的方向，因为LLMs展示了更强的语义理解能力。以往研究通常通过提示工程技术来诱使LLMs将句子信息编码到最后一个标记的嵌入中。然而，LLMs大多是仅有解码器的模型，具有因果注意力机制，前序标记无法关注后续标记，从而导致句子信息的有偏差编码以及对最后解码标记的级联影响效果。", "innovation": "我们提出了一种新的Token Prepending（TP）技术，该技术将每层解码的句子嵌入附加到下一层输入的句子开头，使前序标记能够在因果注意力机制下关注完整的句子信息。这种方法是插件式的并且无需训练，可以直接与不同的提示基础句子嵌入方法和自回归LLMs结合使用。", "conclusion": "在各种语义文本相似性（STS）任务和下游分类任务上的广泛实验表明，我们的TP技术可以显着提高现有基于提示的句子嵌入方法在不同LLMs上的性能，同时几乎不增加额外的推理成本。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.10589", "html_url": "https://arxiv.org/abs/2409.10589", "title": "离线强化学习在作业车间调度中的学习调度应用", "title_en": "Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling", "authors": "Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang", "background": "作业车间调度问题（JSSP）是一个复杂的组合优化问题。尽管在线强化学习（RL）能够迅速找到接受的JSSP解决方案，但它面临着重大局限性：需要从头开始进行大量训练交互，导致样本效率低下；无法利用传统方法如约束编程（CP）中的现有高质量解决方案；并且需要模拟环境进行训练，这对于复杂调度环境来说是不切实际的。此外，现有方法难以应对历史调度数据和专家解决方案可用的场景或模拟环境训练RL方法不切实际的场景。作者提出了一种离线强化学习方法——离线学习调度（Offline-LD），通过学习历史调度数据来解决这些局限性。该方法结合了保守Q学习（CQL）和两种Q学习方法：可屏蔽量ile回归DQN（mQRDQN）和离散可屏蔽软演员-评论家（d-mSAC）。此外，还提出了一种新的熵奖励改进，以及离线RL设置下的JSSP奖励规范化方法。实验表明，使用仅100个由CP生成的解决方案，Offline-LD在生成实例和基准实例上都优于在线RL。引入噪声到专家数据集的效果可与使用专家数据集相媲美或更优，这对于实际应用中的数据噪声和不完美非常有意义。", "innovation": "作者引入了一种名为Offline-LD的新方法，这是一种离线强化学习方法，专门解决在线RL中遇到的局限性问题。Offline-LD的关键创新包括：引入了两种Q学习方法的可屏蔽变体，即Maskable Quantile Regression DQN（mQRDQN）和discrete maskable Soft Actor-Critic（d-mSAC），并通过Conservative Q-Learning（CQL）学习历史数据；针对可屏蔽动作空间，提出了一种新的熵奖励改进；并提出了专为JSSP设计的奖励规范化方法。整体而言，这种方法能够有效利用历史调度数据来提升学习效率并优化调度性能。", "conclusion": "作者的实验表明，Offline-LD在使用仅100个CP生成的解决方案时，相比在线RL在生成和基准实例上都能获得更好的性能。此外，即使在引入噪声的情况下，使用专家数据集与使用未噪声化数据集相比，有很大潜力，显示出在真实世界噪声环境中应用的潜力。这种方法为解决复杂调度问题提供了一种新的有效途径。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.10435", "html_url": "https://arxiv.org/abs/2412.10435", "title": "COEF-VQ: 一种通过级联多模态大语言模型框架实现的成本效率高的视频质量理解方法", "title_en": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework", "authors": "Xin Dong,Sen Jia,Ming Rui Wang,Yan Li,Zhenheng Yang,Bingfeng Deng,Hongyu Xiong", "background": "近年来，随着多模态大语言模型（MLLM）技术的出现，利用其视频理解能力进行不同分类任务成为可能。然而，为了在线部署MLLM，需要大量的GPU资源，这带来了巨大的资源需求问题。因此，亟需一种能够提升视频质量理解同时优化计算效率的方法来解决这一问题。", "innovation": "本文提出了一种新颖的级联MLLM框架COEF-VQ，旨在增强短视频平台上视频质量理解的能力，同时优化计算效率。该框架通过引入基于熵的预筛选阶段，使用一种轻量级模型评估不确定性并有选择性地过滤前传，最终将待评价的数据传递给计算密集型的MLLM进行评估。这种优先处理高不确定性样本的策略显著减少了GPU的使用量，同时保持了完整MLLM部署的强大分类性能。", "conclusion": "通过将COEF-VQ框架部署到短视频平台的视频管理平台（VMP）上，并在两个内部视频质量理解任务中进行了一系列详细的实验，结果表明，COEF-VQ不仅使离线评估取得了实质性的进步，还通过限制资源消耗有效提高了平台安全性。在线A/B测试结果显示，在不降低用户参与度的情况下，不当内容视频的观看率显著降低了9.9%。后续的监控显示，这种改进是持久的，验证了其在现实世界中的影响。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.14441", "html_url": "https://arxiv.org/abs/2411.14441", "title": "GeMID: 适用于物联网设备识别的一般化模型", "title_en": "GeMID: Generalizable Models for IoT Device Identification", "authors": "Kahraman Kostas,Rabia Yasa Kostas,Mike Just,Michael A. Lones", "background": "随着物联网（IoT）设备的增多，保障其安全性变得尤为重要。基于设备流量模式的设备识别（DI）在区分和识别这些设备以及其脆弱性方面发挥了关键作用，但目前的DI方法在构建机器学习模型时往往忽视了模型在不同网络环境下的通用性挑战。本文研究旨在解决这一问题，提出了一种新颖的框架来评估和提升DI模型在不同网络环境中的一致表现能力，通过两步法：首先利用遗传算法和外部反馈来丰富和优化特征与模型的选择；其次通过新的独立数据集测试已建的DI模型，确保其在不同环境下的通用性。研究发现，常用技术如滑动窗口和流量统计由于依赖于特定网络条件，限制了其通用性，统计方法因同样原因不可靠，挑战了大量现有研究的可靠性。该研究提高了IoT安全和设备识别领域的学术贡献，提升了模型的有效性并对防范IoT网络风险有指导意义。", "innovation": "本文提出了一种新颖的框架GeMID，用于提高设备识别（DI）模型在不同网络环境下的通用性。框架包括两步法：使用遗传算法和外部反馈来优化特征与模型的选择，并通过独立数据集测试模型的通用性。这种方法相较于常见的滑动窗口和流量统计方法，有效提升了DI模型在不同环境下的适应性，强调了依赖于特定网络条件的统计方法不可靠，挑战了大量现有研究的可靠性。", "conclusion": "研究证明了GeMID方法的有效性，通过对现有技术的对比表明，滑动窗口和流量统计方法等普遍采用的技术由于依赖特定网络特征而缺乏通用性，同时统计方法同样不可靠。研究成果在IoT安全和设备识别领域提供了新的见解，提升了模型在不同网络环境下的应用效果，对风险防范具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01391", "html_url": "https://arxiv.org/abs/2502.01391", "title": "从生成模型学习实时观察中的交通异常", "title_en": "Learning Traffic Anomalies from Generative Models on Real-Time Observations", "authors": "Fotis I. Giasemis,Alexandros Sopasakis", "background": "准确检测交通异常对于有效的城市交通管理和缓解交通拥堵至关重要。通过利用时空生成对抗网络（STGAN）框架结合图神经网络和长短时记忆网络，该研究捕捉交通数据中复杂的时空依赖关系，以此来提升交通管理的效果和精度。在斯德哥尔摩的42个交通摄像头的实时月度观测数据中验证了该模型的有效性，实验证明该模型能够高效检测交通异常，且具有较高的精度和较低的误报率。这些异常包括摄像机信号中断、视觉伪像以及极端天气条件对交通流量的影响。", "innovation": "该研究创新性地采用了STGAN框架，结合图神经网络和长短时记忆网络的特性，用于捕捉交通数据中的复杂时空依赖性。该方法在实时观测数据中有效检测交通异常现象，展示了在城市交通管理中的应用可能性。", "conclusion": "模型有效地检测了交通流量中的异常情况，包括摄像机信号中断、视觉伪像和极端天气影响，验证了其在检测交通异常方面的高精度和低误报率。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.18530", "html_url": "https://arxiv.org/abs/2412.18530", "title": "关于语言生成的表征：幻觉、广度和稳定性的相互作用", "title_en": "On Characterizations for Language Generation: Interplay of Hallucinations, Breadth, and Stability", "authors": "Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas", "background": "本文研究的是由Kleinberg和Mullainathan提出的在极限中进行语言生成的问题，该问题建立在Gold和Angluin的经典工作中。尽管Kleinberg和Mullainathan的算法能够最终生成未见过的来自目标语言K的字符串，但它牺牲了覆盖率或者广度，即生成丰富字符串集的能力。近年来，关于广度的不同定义已经被引入，并探索了在某些情况下能够达成广度生成的可能性，但是这些定义的完全表征仍然是一个开放的问题。本文通过定义和扩展现有的广度概念来解决了这些问题，并发现低密度的界限具有很大的灵活性，不仅适用于广度性能度量，还适用于更高的困惑度或更低的幻觉率等其他度量。另外，文章还研究了具有稳定性的广度语言生成和算法，这些算法在见到有限数量的字符串后不再改变，提出了无条件的界限，证明了在要求稳定性的条件下，大多数现有的广度概念变得同样难以达成。", "innovation": "1. 通过定义和扩展现有的广度概念，解决了关于语言生成的广度的完全表征问题。\n2. 发现了对泛化能力的下限具有很大的灵活性，适用于多种性能度量，证明了相较于其他语言，无法训练得到更高的困惑度或更低幻觉率的生成器。\n3. 研究了具有稳定性的广度语言生成，提出了无条件的界限，展示了广度、稳定性和一致性之间的丰富相互作用，并证明了在要求稳定性的条件下，这些广度概念变得同样难以达成。", "conclusion": "本文通过定义现有和扩展的广度概念解决了语言生成中的广度问题，并通过研究具有稳定性的广度语言生成，验证了这些广度概念在稳定条件下的难易程度，同时展示了广度、稳定性和一致性之间的复杂关系。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.00863", "html_url": "https://arxiv.org/abs/2411.00863", "title": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation", "title_en": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation", "authors": "Chenyang An,Shima Imani,Feng Yao,Chengyu Dong,Ali Abbasi,Harsh Shrivastava,Samuel Buss,Jingbo Shang,Gayathri Mahalingam,Pramod Sharma,Maurice Diesendruck", "background": "在基于大型语言模型（LLM）的证明生成领域，尽管对ArXiv等大量数据集进行了广泛的训练，LLM在解决中等难度证明任务方面仍表现出有限的性能。原因之一是证明数据中的子优化排序，例如，发表的证明通常遵循逻辑顺序，每一步基于演绎规则从上一步逻辑推导出。这种顺序旨在便于验证证明的有效性，而不是帮助人们和模型学习证明发现的过程。文章提出，在证明生成中，最优顺序出现在与特定证明步骤相关的中间监督总是位于该证明步骤左侧时。验证证明顺序的有效性并通过两个任务（直觉命题逻辑定理证明和数字乘法）进行实验，发现证明的顺序对训练效果至关重要，特定数据顺序下的模型证明成功率为标准情况下的11%提高。进一步研究发现，高等数学中的许多证明存在这种有序问题，约占广泛使用的研究生数学教科书前两章中具有非平凡证明定理的17.3%。", "innovation": "提出了在证明生成中，中间监督的最佳顺序应位于特定证明步骤左侧的", "conclusion": "证明排序对训练效果至关重要，最佳排序可以显著提高模型的证明成功率。此外，许多高等数学证明存在这种有序问题，这对证明生成提出了新的挑战。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.08496", "html_url": "https://arxiv.org/abs/2501.08496", "title": "量化数据对齐在下游模型性能中的重要性", "title_en": "Quantifying the Importance of Data Alignment in Downstream Model Performance", "authors": "Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo", "background": "与通常强调数据集大小不同，本文探讨了数据对齐的作用。数据对齐是数据质量的一个常被忽视方面，对训练强大语言模型（LLMs）有很大影响。本文通过任务2向量（Task2Vec）基的对齐系数来量化训练数据与评估数据之间对齐程度对下游性能的影响。作者进行了受控的介入性实验，探索不同预训练和特定领域微调设置下的数据对齐系数对下游任务损失和困惑度的预测性负相关性。", "innovation": "本文提出使用任务2向量（Task2Vec）基的对齐系数来量化数据对齐对下游模型性能的影响。通过受控的介入性实验，发现模型训练和评估数据之间的对齐系数与模型在相应下游任务上的损失和困惑度之间存在强预测性负相关关系，这促进了对语言模型训练方式的重新评估，特别强调了数据对齐的重要性，尤其是在特定任务如自动形式化方面。", "conclusion": "本文的研究表明，在训练大型语言模型时，数据对齐的重要性超过了仅仅增加数据量。特别是在特定的下游任务如自动形式化中，对齐数据能够提高模型的性能，这为未来的模型训练和评估方法提供了新的视角。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12370", "html_url": "https://arxiv.org/abs/2501.12370", "title": "参数量 vs FLOPs：MoE语言模型的最优稀疏性缩放定律", "title_en": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models", "authors": "Samira Abnar,Harshay Shah,Dan Busbridge,Alaaeldin Mohamed Elnouby Ali,Josh Susskind,Vimal Thilak", "background": "通过提升语言模型的容量来改善性能和解锁新功能已经被证实是一个可靠的方法。模型的容量主要取决于两个维度：模型的参数数量和每个示例所需的计算量。尽管通常会同时增加这两者来实现容量的扩展，但这两者之间的精确相互作用及其对总体容量的共同贡献仍不完全清楚。本文探讨了在稀疏混合专家（MoE）的背景下这一关系，通过它可以在不同比例增加FLOPs的情况下增加参数数量。同时，本文调查了不同稀疏程度（即未激活参数的比例）如何影响模型在预训练和下游少量样本评估中的性能。研究表明，在不同的约束条件下（如参数大小和总训练计算量），存在一个最优的稀疏程度，可以提高训练效率和模型性能。", "innovation": "本文发现了一个在不同约束条件下（如参数大小和总训练计算量）的最优稀疏程度，可以同时提高训练效率和模型性能，从而更好地理解缩放定律对MoE的影响，并为设计更高效的架构提供了新的见解。", "conclusion": "这些结果提供了对MoE缩放定律中稀疏性影响的更深入理解，并补充了该领域的现有研究工作，为设计更高效的架构提供了见解。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06106", "html_url": "https://arxiv.org/abs/2502.06106", "title": "电路调谐：识别参数冗余和微调神经网络的机制方法", "title_en": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks", "authors": "Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang", "background": "机制可解释性研究旨在反向工程模型以解释其行为。尽管最近的研究集中于特定行为的静态机制，但模型内部的学习动态尚未被充分探索。本研究发展了一种可解释的微调方法，用于分析学习背后的机制。作者首先引入了节点层面固有维数的概念，以此描述计算图中模型的学习过程。基于该理论，提出了一种名为电路调谐的两阶段算法，该算法通过迭代构建特定任务所需的最小子图，并以启发式方式更新关键参数。实验结果证实了节点层面固有维数的存在，并展示了该方法在透明和可解释微调方面的有效性。研究者通过可视化和分析微调前后电路的变化，揭示了神经网络在学习过程中的自我组织机制新见解。", "innovation": "提出了一种名为电路调谐的可解释微调方法，通过迭代构建最小子图并以启发式方式更新关键参数，揭示了学习过程中的新见解，特别是自我组织机制。", "conclusion": "电路调谐方法能够有效识别参数冗余，并通过透明和可解释的方式微调神经网络，该方法通过可视化分析微调前后电路的变化，揭示了神经网络自我组织机制的新见解。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.17168", "html_url": "https://arxiv.org/abs/2501.17168", "title": "在树基遗传编程中实现群体级别并行性以实现全面的GPU加速", "title_en": "Enabling Population-Level Parallelism in Tree-Based Genetic Programming for Comprehensive GPU Acceleration", "authors": "Zhihong Wu,Lishuang Wang,Kebin Sun,Zhuozhao Li,Ran Cheng", "background": "树基遗传编程（TGP）是一种用于符号回归、分类和机器人控制等任务的广泛使用的进化算法。但由于运行TGP的计算密集型需求，GPU加速对于实现可扩展性能至关重要。然而，由于三大核心问题（1）程序个体的结构性异质性，（2）多种层次并行性的复杂集成，以及（3）高性能CUDA执行与灵活Python环境之间的不兼容性，高效的基于GPU的TGP执行仍然具有挑战性。", "innovation": "本研究提出了一种名为EvoGP的高性能框架，通过群体级别并行执行全面加速树基遗传编程（TGP）。EvoGP采用了张量表示法将大小可变的树编码为固定形状、内存对齐的数组，支持均匀内存访问和跨不同个体的并行计算。EvoGP还采用了动态组合个体内和个体间并行性的自适应平行策略，以确保在广泛的任务范围内充分利用GPU。此外，EvoGP将自定义CUDA内核嵌入到PyTorch运行时中，实现了与Gym、MuJoCo、Brax和Genesis等基于Python的环境的无缝集成。实验结果表明，EvoGP在保持竞争准确性的前提下，相对于最先进的基于GPU的TGP实现可实现高达140倍的加速，并显著提高了大型种群大小下的可扩展性。", "conclusion": "EvoGP是一个开源框架，其目的是在树基遗传编程中实现全面的GPU加速，通过群体级别并行执行。EvoGP在效能、准确性和可扩展性方面表现优异，为TGP的应用提供了强有力的支持。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06684", "html_url": "https://arxiv.org/abs/2502.06684", "title": "EquiTabPFN: 一种目标置换对称先验网络", "title_en": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks", "authors": "Michael Arbel,David Salinas,Frank Hutter", "background": "近年来，TabPFN等表格数据的基础模型在上下文学习方面表现出色，但仍然局限于固定的、预先定义的目标维度数量，这需要昂贵的集成策略。这一局限性源于更深层次的架构缺陷，这些模型缺乏目标对称性，即打乱目标维度顺序会改变其预测结果。这种缺陷产生了不可消除的“对称差距”，在预测中引入了不稳定性。", "innovation": "通过设计完全的目标对称架构，即通过对称编码器、解码器和双向注意机制确保排列不变性，消除这一差距。在标准分类基准上的实证评估表明，在训练数据集的类比数少于数据集中的实际类比数的条件下，该模型在计算开销更低的情况下与现有方法取得了相当或更优的效果。", "conclusion": "我们的模型通过确保目标对称性，有效减少了预测中的不稳定性，并在其保持或超越现有方法性能的同时，降低了计算开销。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.05007", "html_url": "https://arxiv.org/abs/2501.05007", "title": "量子增强的小样本量因果发现", "title_en": "Quantum-enhanced causal discovery for a small number of samples", "authors": "Yu Terada,Ken Arai,Yu Tanaka,Yota Maeda,Hiroshi Ueno,Hiroyuki Tezuka", "background": "因果关系的发现吸引了经济学、社会科学和生物学等领域的重要关注。在实际应用中，通常对底层系统不了解，现实数据通常与非线性因果结构相关联，这使得直接使用大多数传统因果分析方法变得困难。因此，需要一种无需假设底层模型结构的新颖的量子Peter-Clark(qPC)算法进行因果发现。该算法利用刻画于量子电路的核希尔伯特空间中的条件独立性测试来探索任意分布下的观测数据中的因果关系。该论文通过系统地在因果结构的基本图上进行实验，证明了qPC算法的优异表现，特别是对于小样本量更具优势，并且还提出了一种基于核目标对齐(KTA)的全新优化方法来确定量子核的超参数，从而有效减少了因果发现中的假阳性风险，增强了发现的可靠性。这些理论和实验结果表明，量子算法可以在因果发现的有益应用中补充和提升经典算法的表现，特别是对于小样本情况，传统方法对这种场景有效性的不足。此外，该研究还在波士顿房价数据集、心脏病数据集和生物信号系统数据集上进行了实际应用验证，证明了基于量子的方法在解决小型样本难题中的潜力", "innovation": "提出了一种全新的无须假设底层模型结构的量子Peter-Clark(qPC)算法，基于刻画于量子电路的核希尔伯特空间中条件独立性测试，并提出了一种基于核目标对齐(KTA)的新优化方法来确定量子核的超参数，从而有效减少了因果发现中的假阳性风险，增强了发现的可靠性。这样的方法在解决小样本难题时提供了优于传统方法的潜力，尤其是支持了在经典算法通常失效的场景中准确的因果推断能力", "conclusion": "理论上和实验上的结果显示，量子算法有能力增强经典算法在因果发现中的准确性，尤其是在小型样本场景中。为此，该方法展示出在波士顿房价、心脏病和生物信号系统的实际数据集上的有效性，暗示了基于量子的因果发现方法在解决实际问题时的潜力，尤其是在小型样本情况下的局限性和挑战方面。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04700", "html_url": "https://arxiv.org/abs/2502.04700", "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference", "title_en": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference", "authors": "Prakhar Kaushik,Ankit Vaidya,Shravan Chaudhari,Alan Yuille", "background": "大型模型的迅速增长引发了对其环境影响和可访问性的担忧，因为这需要大量的计算资源。低秩适配器（LoRA）提供了一种轻量级的解决方案来微调大型模型，从而产生了大量的适配器，它们适用于多种领域。我们提出的问题是：这些预训练的适配器能否进一步简化到新任务的适应过程，同时解决这些挑战？", "innovation": "我们引入了EigenLoRAx，一种参数高效的方法，能够回收已存在的适配器来创建一个与它们共享领域知识对齐的主要子空间，并可进一步在低资源情况下用正交基向量进行增强。EigenLoRAx只需要显著减少的参数和内存，提高训练和推理的效率。此方法在不同的领域和任务上显示出强大的性能，提供了适用于边缘计算应用、个性化以及在资源受限环境中公平部署大型模型的可扩展途径。", "conclusion": "我们的研究结果表明，EigenLoRAx可以在不同领域和任务中实现快速适应，通过学习主要子空间的轻量化系数来消除整个适配器的微调需求。这种方法提高了资源利用效率，并为大型模型在资源受限环境中的边缘应用、个性化部署和公平分配提供了可扩展的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03935", "html_url": "https://arxiv.org/abs/2503.03935", "title": "基于大型语言模型的从可穿戴设备和饮食中预测高血糖和行为治疗路径", "title_en": "LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet", "authors": "Abdullah Mamun,Asiful Arefeen,Susan B. Racette,Dorothy D. Sears,Corrie M. Whisner,Matthew P. Buman,Hassan Ghasemzadeh", "background": "餐后高血糖，即餐后血糖水平超出正常范围，是糖尿病进展的关键指标，尤其是在患有糖尿病前期和健康个体中。餐后血糖动态的一个关键指标是餐后曲线下面积（AUC）。通过了解生活方式因素（如饮食和活动水平）对餐后血糖的影响，可以预测餐后AUC并进行早期干预，帮助个体调整生活方式以维持正常的血糖水平。", "innovation": "本文开发了一个可解释的机器学习解决方案，GlucoLens，它结合了穿戴设备传感、多模态数据和机器学习模型，可以基于饮食、活动和近期血糖模式来预测餐后AUC和高血糖。该研究使用穿戴设备数据进行了为期五周的临床试验，结果表明，与对照模型相比，该技术在预测餐后AUC和高血糖方面性能提高了16%，并且能够预测高血糖的准确率达到了73.3%，F1分数为0.716，还提供了多样的反事实解释以帮助个体避免高血糖。", "conclusion": "GlucoLens系统在最佳配置下实现了归一化均方根误差0.123。该技术不仅能够准确预测餐后高血糖，还能提供治疗建议，帮助个体通过改变生活方式来维持正常血糖水平。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.21843", "html_url": "https://arxiv.org/abs/2503.21843", "title": "CMD-HAR: 跨模态解缠对可穿戴人体活动识别的作用", "title_en": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition", "authors": "Hanyu Liu,Siyao Li,Ying Yu,Yixuan Jiang,Hang Xiao,Jingxi Long,Haotian Tang,Chao Li", "background": "人体活动识别（HAR）是众多基于人类的应用的核心技术。尽管深度学习方法已被用于加速特征提取，但多模态数据混杂、活动异质性和复杂模型部署等问题仍未能完全解决。论文旨在解决基于传感器的HAR中多模态数据混杂、活动异质性和复杂模型部署的问题。", "innovation": "提出了时空注意模态解耦融合策略来解决传感器数据混合分布的问题。通过跨模态时空解纠缠表示捕获活动的关键特征，结合梯度调制以缓解数据异质性。此外，构建了一个可穿戴部署模拟系统。", "conclusion": "在大量公共数据集上进行了实验，证明了该模型的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.13450", "html_url": "https://arxiv.org/abs/2502.13450", "title": "交错吉布斯扩散：以隐含约束生成离散-连续数据", "title_en": "Interleaved Gibbs Diffusion: Generating Discrete-Continuous Data with Implicit Constraints", "authors": "Gautham Govind Anil,Sachin Yadav,Dheeraj Nagaraj,Karthikeyan Shanmugam,Prateek Jain", "background": "大多数关于离散和离散-连续扩散的工作都假设去噪分布是因子化的，这可能阻碍了对这些问题中随机变量之间强烈依赖性的建模。研究者们在这篇论文中探讨了在重要但内在且未明示的约束条件下生成离散-连续数据的问题，并通过实例化展示了使用吉布斯采样样式的离散扩散模型可以显著提升3-SAT问题的表现，从而克服了因子化假设带来的局限。", "innovation": "论文提出了一种名为 Interleaved Gibbs Diffusion (IGD) 的新型生成模型框架，专门针对具有重要但隐含且未明示约束的数据问题。IGD 扩展了离散时间吉布斯采样类型的马尔可夫链，适用于离散-连续数据生成。该模型允许离散和连续去噪器之间无缝整合，同时理论上有能力逆转适当的前向过程。IGD 还提供了对去噪器的选择灵活性、通过状态空间加倍进行条件生成的能力以及推理时间改进的功能。在三种具有挑战性的生成任务（分子结构、布局和表格数据）上进行的实证评估表明其性能达到最先进的水平。值得注意的是，IGD 实现了最先进的结果，无需依赖特定领域的归纳偏见（如同构扩散或辅助损失）。", "conclusion": "这篇论文通过提出交错吉布斯扩散 (IGD)，开创性地提供了一种在具有隐含约束的数据生成问题上的解决方案，并展示了其在多种挑战性生成任务中的卓越性能，体现了其算法的有效性和灵活性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18681", "html_url": "https://arxiv.org/abs/2503.18681", "title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models", "title_en": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models", "authors": "Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin", "background": "作为一种自然语言处理(NLP)领域的关键研究方向，讽刺检测吸引了广泛的关注。尽管传统的单模态方法（如文本）在讽刺检测中表现出色，但由于讽刺的隐晦和微妙性质，这些方法常常无法获得满意的结果。近年来，研究者将讽刺检测的关注点转向多模态方法。然而，有效利用多模态信息准确识别讽刺内容仍然是一个值得进一步探索的挑战。", "innovation": "本文提出了一种创新的多模态Commander-GPT框架。该框架借鉴军事策略，将讽刺检测任务分解为六个子任务。中心指挥官（决策者）分配最合适的大型语言模型来解决每个特定的子任务。最终，每个模型的检测结果被综合起来识别讽刺。利用多模态大型语言模型的强大综合处理能力来处理来自各种信息源的任务，是我们方法的一大创新点。此外，我们利用MMSD和MMSD 2.0数据集进行实验，展示了通过四种多模态大型语言模型和六种提示策略，我们的方法达到了最先进的性能，F1分数提高了19.3%，无需进行微调或获取真实理由。", "conclusion": "我们的研究结果证明，通过多模态大型语言模型的综合能力，结合精心设计的任务拆分和模型分配策略，显著提升了讽刺检测的准确性，并且在数据集MMSD和MMSD 2.0上的实验结果表明我们的方法具有优越性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04564", "html_url": "https://arxiv.org/abs/2503.04564", "title": "循环用户关联下层次安全聚合的基本极限", "title_en": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association", "authors": "Xiang Zhang,Zhou Li,Kai Wan,Hua Sun,Mingyue Ji,Giuseppe Caire", "background": "联邦学习(FL)中的安全聚合旨在确保云服务器能够计算大量客户端本地训练模型的平均模型（即深度神经网络的权重），同时满足数据安全要求。现有研究的层次安全聚合(HSA)假设每个用户仅与一个中继关联，这限制了跨集群用户进行编码以实现高效通信和密钥生成的机会。本文探讨了用户以循环关联模式与多个中继通信的情况，即每个用户与一个环绕的$B$个连续中继相连，研究在这一新的场景下HSA的能力极限和安全通信与密钥生成的最低通信和密钥速率的理论上限。", "innovation": "提出了适用于循环用户关联模式的高效聚合方案，该方案包括由渐变编码启发的输入消息设计方案（一种在分布式计算中实现高效通信的著名技术），以及高度非平凡的安全密钥设计方案。并使用信息论方法推导出新型的最低可实现通信和密钥速率的上下界，解决了先前研究中存在的局限性问题。", "conclusion": "研究发现，在循环用户关联模式下，HSA的最低可实现通信和密钥速率具有新的理论极限，这为提高跨集群用户的安全聚合效率提供了新的理论依据。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.05802", "html_url": "https://arxiv.org/abs/2503.05802", "title": "使用Wasserstein距离方法进行照度和光方向估计", "title_en": "Illuminant and light direction estimation using Wasserstein distance method", "authors": "Selcuk Yazar", "background": "在图像处理领域，尤其是在机器人技术中，光照估计是一项关键的挑战，因为它直接关系到在不同光照条件下的环境感知的鲁棒性。传统的方法，例如RGB直方图和GIST描述子，在复杂场景中因对光照变化的敏感性而经常失效。因此，本文通过引入基于最优传输理论的Wasserstein距离方法来对图像中的照度和光方向进行估计，旨在解决这一问题，尤其是在复杂光照环境下的应用需求。", "innovation": "本文提出了一种利用Wasserstein距离的新方法来进行照度和光方向的估计。不同于传统的统计方法，该方法基于最优传输理论，能够有效地检测和估计光源的方向，特别是在光照复杂多变的环境中表现优异，优于现有的传统统计方法。此方法还展示出在光源定位、图像质量评估以及目标检测增强中的潜在应用价值。", "conclusion": "该研究提出的方法在连续的室内场景、黑白照片及夜景图像下的实验表明，其对于检测主导光源并估计其方向具有显著的效果。未来的研究可以探索自适应阈值设定和梯度分析以进一步提高准确性，从而为实际机器人和其他领域中的照明挑战提供可扩展的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17046", "html_url": "https://arxiv.org/abs/2503.17046", "title": "HAPI: 一种基于人类偏好学习机器人面部表情的模型", "title_en": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences", "authors": "Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida", "background": "自动机器人面部表情生成对于人际交互至关重要，但基于固定关节配置的手工方法经常导致僵硬和不自然的行为。尽管最近的自动化技术减少了手工调节的需求，但它们往往未能充分缩小人类偏好与模型预测之间的差距，导致由于有限的自由度和不充分的知觉整合，生成的表情缺乏细腻和真实性。", "innovation": "本文提出了一个新颖的学习排序框架，该框架利用人类反馈来解决这一差距，并增强机器人的面部表情表达能力。具体来说，通过成对比较注释来收集人类偏好数据，并开发了基于Siamese RankNet的人类情感成对印象（HAPI）模型，以改进表情评估。通过贝叶斯优化和在线表情调查，在一个35-DOF的人形平台上得出的结果表明，该方法在愤怒、快乐和惊讶等表情的真实性和社会共鸣方面明显优于基线方法和专家设计的方法，这表明该框架有效地缩小了人类偏好与模型预测之间的差距，同时稳固地使机器人表情生成与人类的情感响应相一致。", "conclusion": "本研究通过利用人类反馈的数据，证明了一种能够有效增强机器人面部表情真实性和社会共鸣性的新型学习排序框架，成功缩短了人类偏好与模型预测之间的差距。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.07813", "html_url": "https://arxiv.org/abs/2503.07813", "title": "MaizeField3D: 一个来自多样化群体的田间种植玉米的3D点云和过程模型数据集", "title_en": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel", "authors": "Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian", "background": "由于缺乏大量且多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的工具在3D表型学尤其是玉米领域的发展受到了限制。现有的2D图像数据集无法捕捉到3D数据提供的关键结构细节，如叶片结构、植物体积和空间排列等。", "innovation": "本文介绍了一个名为MaizeField3D的数据集，这是一个为推动农业研究而精心设计的田间种植玉米的3D点云数据集。该数据集包含1,045个高质量的3D点云，收集自采用陆地激光扫描（TLS）技术的多样化遗传群体的玉米植物，其中520株植物被进行了基于图的方法进行分割和注释，以隔离单个叶片和茎秆，确保所有样本的一致标签。该数据集通过逐个优化过程生成非均匀有理B样条（NURBS）表面，用于植物叶片的过程模型表示，并通过严格的手动质量控制，进行了错误修正，确保叶序准确和元数据注释验证。该数据集还包括多种分辨率的采样点云数据和植物形态及质量元数据，便于不同的下游计算任务使用。", "conclusion": "MaizeField3D将成为AI驱动的表型学、植物结构分析和农业研究中3D应用的基础数据集。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12215", "html_url": "https://arxiv.org/abs/2504.12215", "title": "基于不确定性导向的由粗至细肿瘤分割及解剖学导向的后处理", "title_en": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing", "authors": "Ilkin Sevgi Isler,David Mohaisen,Curtis Lisle,Damla Turgut,Ulas Bagci", "background": "在胸部计算机断层扫描（CT）中可靠地进行肿瘤分割仍然是一个挑战，主要由于边界含糊不清、类别不平衡和解剖学变异。传统的分割方法难以有效解决这些问题，导致分割精度不高，特别是在不确定性较强的区域。因此，文中探讨了结合解剖学先验知识的不确定性导向框架，以提高肿瘤分割的鲁棒性和准确度。", "innovation": "提出了一种不确定性导向、由粗至细的肿瘤分割框架，结合了全体积肿瘤定位与区域兴趣（ROI）精炼分割。第一阶段生成粗略预测，第二阶段利用不确定性感知损失函数进行ROI分割。进一步结合了解剖学导向后处理，通过基于肺重叠、邻近肺表面和组件大小的过滤策略，提高了分割准确性和边界校准，在不确定性强的区域尤为显著。该方法在私有和公开数据集上的实验结果显示，Dice和Hausdorff评分提高，假阳性减少，空间可解释性增强。", "conclusion": "将不确定性建模与解剖学先验结合用于级联分割管道中，能够实现鲁棒且临床意义的肿瘤界定。在Orlando数据集上，该框架使Swin UNETR的Dice评分从0.4690提升至0.6447，减少伪影组件数量与分割性能提升相关，强调了解剖学导向后处理的价值。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12552", "html_url": "https://arxiv.org/abs/2504.12552", "title": "使用数字孪生进行隐私保护的手术室工作流程分析", "title_en": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins", "authors": "Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath", "background": "手术室是一个复杂的工作环境，优化工作流程对于降低成本和提高患者结果至关重要。尽管计算机视觉方法可以自动识别辅助优化手术室的围手术期事件，但隐私问题限制了使用手术室视频进行自动事件检测。", "innovation": "提出了一个双阶段的隐私保护手术室视频分析和事件检测管道。首先，利用视觉基础模型进行深度估计和语义分割，从常规RGB视频生成脱敏的数字孪生（DT）。其次，利用SafeOR模型，这是一种融合了两条流的方法，处理分割掩码和深度图以进行手术室事件检测。实验结果表明，基于DT的方法在手术室事件检测性能上与原色RGB视频模型相当，甚至更好。数字孪生使手术室工作流程分析保持隐私，有助于机构间脱敏数据的共享，并可能通过减轻领域特定外观差异来增强模型的泛化能力。", "conclusion": "基于数字孪生的方法实现了隐私保护的手术室工作流程分析，促进了不同机构之间的脱敏数据分享，并增强了模型的泛化能力。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12971", "html_url": "https://arxiv.org/abs/2504.12971", "title": "在表达性强的神经架构搜索空间中可转移的代理模型", "title_en": "Transferrable Surrogates in Expressive Neural Architecture Search Spaces", "authors": "Shiwen Qin,Gabriela Kadlecová,Martin Pilát,Shay B. Cohen,Roman Neruda,Elliot J. Crowley,Jovita Lukasik,Linus Ericsson", "background": "神经架构搜索（NAS）面临着在探索广泛、富有表现力的搜索空间以促进架构创新的同时，需要高效评估架构以有效搜索这些空间的挑战。本文基于上下文无关文法研究了代理模型的训练，以提升在高度表达性强的NAS搜索空间中的搜索效率。", "innovation": "通过训练代理模型（使用零成本代理指标和神经图特征GRAF或预先训练的语言模型的微调），本文展示了这些代理模型在数据集内和跨数据集中对架构性能具有高预测能力，能够过滤掉糟糕的架构，从而显著加快搜索速度并获得更好的最终性能。此外，还可以直接将这些代理模型作为搜索目标以实现巨大的加速。", "conclusion": "代理模型的训练可以提高高度表达性强的NAS搜索空间的搜索效率。通过代理模型不仅可以高效评估架构，还能显著加速搜索过程并获得更好的性能，甚至可以用于直接作为搜索目标实现更大的速度提升。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.20808", "html_url": "https://arxiv.org/abs/2504.20808", "title": "SoccerDiffusion：从游戏录制学习端到端类人机器人足球", "title_en": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings", "authors": "Florian Vahl,Jörn Griepenburg,Jan Gutsche,Jasper Güldenstein,Jianwei Zhang", "background": "本文介绍了SoccerDiffusion，一种基于变换器的扩散模型，旨在直接从真实的足球比赛记录中学习类人机器人的端到端控制策略。该模型利用来自RoboCup比赛的数据，从多模态传感器输入（包括视觉、本体感受和比赛状态）预测关节命令轨迹。研究结果展示了模型在模拟和物理机器人中再现复杂运动行为（如行走、踢球和恢复姿势）的能力。尽管高级战术行为受到限制，但该研究为后续强化学习或偏好优化方法奠定了坚实的基础。", "innovation": "本文创新之处在于使用基于变换器的扩散模型直接从真实的足球比赛记录中学习类人机器人的控制策略，并通过蒸馏技术实现实时推理，将多步扩散过程简化为单步。这种方法能够改进类人机器人足球运动的感知和控制能力，减少实时部署时的计算需求，同时保持模型的常用性和准确性。", "conclusion": "虽然高级战术行为受限，但SoccerDiffusion提供了一个可靠的基础，用于后续的强化学习或偏好优化方法。此外，作者已公开提供该研究的数据集、预训练模型和代码，以促进进一步的研究和发展。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20697", "html_url": "https://arxiv.org/abs/2505.20697", "title": "神经科学中动态因果图假设生成：利用观测时间序列的生成因子模型", "title_en": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "authors": "Zachary C. Brown,David Carlson", "background": "假设生成领域有潜力通过缩小所需进行的干预性研究范围来降低神经科学的成本。现有的机器学习方法可以从复杂的数据库中生成科学假说，但很多方法假设因果关系是时间上静态的，这限制了其在动态、状态依赖行为的系统中（如大脑）的应用。虽然有些方法试图通过因子模型进行动态因果发现，但这些方法往往将关系限制为线性模式或其他简化假设。", "innovation": "本文提出了一种新颖的方法，该方法将动态图建模为静态图的条件加权叠加，其中每个静态图可以捕捉非线性关系。这种方法使得检测变量之间复杂的、随时间变化的交互关系超越线性限制成为可能。在一些实验中，该方法将预测的动态因果模式的f1分提高了约22-28%，在一些情况下，提高幅度超过60%。", "conclusion": "在真实脑部数据的案例研究中，该方法展示了能够揭示与特定行为状态相关的联系的能力，提供了有关神经动力学的有价值见解。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17089", "html_url": "https://arxiv.org/abs/2503.17089", "title": "理解驱动的公平CMR分割偏见缓解", "title_en": "Understanding-informed Bias Mitigation for Fair CMR Segmentation", "authors": "Tiarna Lee,Esther Puyol-Antón,Bram Ruijsink,Pier-Giorgio Masci,Louise Keehn,Phil Chowienczyk,Emily Haseler,Miaojing Shi,Andrew P. King", "background": "近年来，人工智能（AI）在医学影像任务中的应用越来越广泛。但是，当训练数据集不平衡时，AI模型中可能会存在偏见。例如，在心脏磁共振（CMR）图像分割模型中，存在着明显的种族偏见现象。目前关于这类偏见及其缓解算法的效果仍不够明确，特别是在不同种族（比如黑人和白人）之间的偏见缓解方面。本文旨在探讨常用偏见缓解方法如何改善基于AI的CMR分割模型中的种族偏见，并在其基础上开展相关研究。研究对象是使用原始CMR图像和裁剪后的CMR图像训练的不同模型。研究发现，可以通过过采样方法有效缓解种族偏见，并且在利用裁剪图像的过程中可以获得更高的分割性能并进一步减小偏见。在针对临床验证集进行测试时，模型表现突出且不存在统计意义上的显著偏见。", "innovation": "本文通过使用过采样、重要性重加权和Group DRO等方法来缓解AI在CMR分割模型中的种族偏见，并评估了这些方法在使用原始CMR图像和裁剪后的CMR图像训练的模型上的效果。研究发现，过采样能显著改善少数族裔的表现，而裁剪图像的使用则能进一步提高多族裔的分割性能，从而减小偏见。特别是在结合过采样和裁剪图像时，模型性能提升最为明显，且种族偏见最小。", "conclusion": "本文研究了不同种族群体之间的偏见缓解方法，并证明了过采样和裁剪CMR图像技术的应用效果。在外部临床验证集中，模型表现为高分割性能和无统计意义上的显著偏见。这为未来开发更公平的AI医学影像分割模型提供了参考。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15325", "html_url": "https://arxiv.org/abs/2504.15325", "title": "显著性指数对一致性值的评估", "title_en": "Significativity Indices for Agreement Values", "authors": "Alberto Casagrande,Francesco Fabris,Rossano Girometti,Roberto Pagliarini", "background": "一致性度量，如科恩κ或内类相关系数，用于测量两个或多个分类器之间的匹配度。这些度量在医学领域评估治疗方法和临床试验的有效性，在人工智能领域则可以量化分类器因简化而产生的近似程度。不同分类器与金标准的一致性可以通过其与金标准本身的顺序来进行比较，但仅凭一致性度量的值来判定方法的好坏需要一个量表或显著性指数。尽管已有一些针对科恩κ的量表被提出，但这些量表多为朴素的方法，并且其边界是任意设定的。", "innovation": "本文提出了一种通用方法来评估任意两个分类器之间一致性值的显著性，并引入了两种显著性指数：一种用于处理有限数据集，另一种用于处理分类概率分布。此外，本文还解决了评估这些指数的计算挑战，并提出了用于评估这些指数的一些高效算法。", "conclusion": "通过引入显著性指数和高效的评估算法，本文为评估分类器之间的一致性提供了新的方法和工具，有助于更科学地评价分类器的质量。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.19136", "html_url": "https://arxiv.org/abs/2504.19136", "title": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification", "title_en": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification", "authors": "Huiling Zheng,Xian Zhong,Bin Liu,Yi Xiao,Bihan Wen,Xiaofeng Li", "background": "合成孔径雷达（SAR）和RGB图像在土地覆盖分类中的融合由于模态异质性和潜在光谱互补性的低估而具有挑战性。现有方法往往未能解开共享结构特征与模态互补辐射属性之间的关系，导致特征冲突和信息丢失。", "innovation": "我们提出了相位-幅度解耦（PAD），这是一种频率感知框架，通过傅里叶域中相位（模态共享）和幅度（模态互补）成分的分离，从而强化共享结构的同时保留互补特性，以提高融合质量。PAD首次引入了显式的幅度-相位解耦，用于多模态融合，并具有Phase Spectrum Correction (PSC) 和 Amplitude Spectrum Fusion (ASF) 两大关键组成部分，分别通过卷积引导缩放对跨模态相位特征进行对齐和使用频域自适应多层感知机动态整合高低频模式。", "conclusion": "我们在WHU-OPT-SAR和DDHR-SK数据集上的广泛实验表明，PAD在多模态土地覆盖分类中的性能达到了最先进的水平。我们的工作为遥感中的物理感知多模态融合建立了一个新的范式。相关代码将在此处可用：this https URL"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06315", "html_url": "https://arxiv.org/abs/2505.06315", "title": "AI的威胁建模：资产中心化方法的案例", "title_en": "Threat Modeling for AI: The Case for an Asset-Centric Approach", "authors": "Jose Sanchez Vicarte,Marcin Spoczynski,Mostafa Elsaid", "background": "近年来，AI技术的迅猛发展使得AI从独立的应用程序转变为深度集成的智能代理，这种变化的驱动力是智能代理能够自主决策并发起行动的能力，无论这些应用本身是否基于AI。这一进化使AI的集成达到了前所未有的水平，智能代理现在可以代表系统和用户执行操作，包括在某些情况下撰写并执行所需脚本的能力。随着AI系统能够自主执行代码、与外部系统交互和无需人类监督运行，传统的安全方法变得不再适用。", "innovation": "本文介绍了一种以资产为中心的威胁建模方法，以解决集成AI代理所带来的独特安全挑战。这种方法是一种自下而上的方法，与现有的自上而下的框架不同，它可以系统地识别各种基础设施中的漏洞（包括传统的和AI特有的）如何影响关键的AI资产。这种方法使安全团队能够：（1）进行全面分析，有效地跨越技术领域沟通，（2）量化对第三方AI组件的安全假设而不需要对其实施可见性，（3）整体识别与他们特定产品环境相关的AI漏洞。这种方法尤其适用于需要复杂自治能力的代理系统。通过关注资产而不是攻击，我们的方法可以应对快速变化的威胁环境，并适应日益复杂和分散的AI开发管道，", "conclusion": "该方法强调资产优先，可以随着不断变化的威胁环境和日益复杂的集成AI开发管道规模扩展。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨语言：评估多模态大语言模型的跨语言一致性", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "近年来，多模态大语言模型（MLLMs）迅速发展，极大地增强了其在现实生活中的应用能力。然而，如何在不同语言中保持一致的表现，特别是在整合文化知识方面，仍然是一个重大挑战。为了更好地评估这一问题，该论文引入了两个新的基准测试：KnowRecall和VisRecall，用于评估MLLMs的跨语言一致性。KnowRecall是一个视觉问答基准，用于测量15种语言中的事实知识一致性，特别关注全球地标的文化和历史问题。VisRecall则通过让模型描述9种语言中的地标外观（不提供图像），来评估视觉记忆一致性。实验结果表明，最先进的MLLMs，包括专有模型在内，仍然难以达到跨语言一致性，这强调了更稳健的方法以生成真正多语言且文化敏感的模型的必要性。", "innovation": "论文引入了两个新的基准测试：KnowRecall和VisRecall，用于评估MLLMs在15种语言中的事实知识和视觉记忆的一致性。这是对现有评估方法的重要补充，有助于推动多语言大语言模型的发展。", "conclusion": "最先进的MLLMs在实现跨语言一致性方面仍然存在挑战，特别是在跨语言的事实知识和视觉记忆一致性方面。论文强调了开发能够真正体现多语言和文化意识的模型的必要性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21880", "html_url": "https://arxiv.org/abs/2505.21880", "title": "将大型语言模型应用于大规模城市复杂交通模拟", "title_en": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation", "authors": "Yu-Lun Song,Chung-En Tsern,Che-Cheng Wu,Yu-Ming Chang,Syuan-Bo Huang,Wei-Chu Chen,Michael Chia-Liang Lin,Yu-Ta Lin", "background": "本研究通过将大型语言模型（LLM）与基于代理的建模（ABM）结合，提出了一种创新的城市交通模拟方法。传统的基于规则的ABM方法在增强代理多样性与现实感方面存在局限性，而本研究通过LLM生成合成人口特征、分配固定和偶然的位置，并模拟个性化的路线，以提高现实性和多样性。研究使用实际数据模拟台北市的个体行为和大规模交通模式，为城市规划者提供行动指南以进行政策制定。未来的工作将集中在建立稳健的验证框架，以确保模拟在城市规划应用中的准确性和可靠性。", "innovation": "该研究提出了一种新的城市交通模拟框架，通过集成大型语言模型和基于代理的建模，增强了代理的多样性和现实感，不同于传统的基于规则的ABM方法。研究利用实际数据模拟个体行为和大规模移动模式，并通过生成的路线热图和特定模式指标为规划者提供实用信息。未来的研究将集中在构建稳健的验证框架，确保模拟的准确性和可靠性在城市规划中的应用。", "conclusion": "该模拟模型提供了实用信息，有助于城市规划者进行政策制定。未来的研究将着重于建立验证框架，以确保在城市规划中的准确性和可靠性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06231", "html_url": "https://arxiv.org/abs/2506.06231", "title": "迈向可解释的特征嵌入比较与对齐", "title_en": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "authors": "Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia", "background": "尽管文献中开发了几种特征嵌入模型，但这些嵌入的比较大多集中在它们在分类相关下游应用中的数值性能上。然而，为了进行可解释的比较，需要识别和分析嵌入空间内聚类样本组之间的不匹配。因此，本文提出了Spectral Pairwise Embedding Comparison (SPEC)框架来对比嵌入并识别它们在聚类参考数据集时的差异。", "innovation": "本文创新地提出了Spectral Pairwise Embedding Comparison (SPEC)框架，该框架通过比较两个嵌入的核矩阵，并利用差异核矩阵的特征分解来检测由两个嵌入捕获的不同样本集群。此外，本文还提出了一种优化问题，以确保在一种嵌入中发现的集群也能被另一种模型捕获。", "conclusion": "SPEC方法在大规模数据集如ImageNet和MS-COCO上用于比较和对齐嵌入。证明了SPEC在大规模数据集上的适用性和有效性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22343", "html_url": "https://arxiv.org/abs/2505.22343", "title": "利用大型AI模型部署提升智能低空经济", "title_en": "Empowering Intelligent Low-altitude Economy with Large AI Model Deployment", "authors": "Zhonghao Lyu,Yulan Gao,Junting Chen,Hongyang Du,Jie Xu,Kaibin Huang,Dong In Kim", "background": "低空经济(LAE)作为一种新兴的经济范式，重新定义了商业和社会活动的空域使用方式。大型人工智能模型(LAIMs)能够大幅提升LAE服务的智能水平，然而在LAE中部署LAIMs面临着诸多挑战，包括计算/存储需求与LAE实体有限的现场资源之间存在的巨大差距、实验室训练的LAIMs与动态物理环境不匹配的问题，以及传统分离设计在传感、通信和计算方面的低效性。为应对这些挑战，本文首先提出了一种适应LAIM部署的分层系统架构，并概述了LAE的应用场景。接着，本文探讨了一系列关键使能技术，促进LAIMs与低空系统的共同演化，并引入了一种面向任务的服务交付执行管道，以实现可扩展和自适应的服务交付。最后，通过实际案例研究对提出的框架进行了验证，并指出了未来的研究挑战。", "innovation": "本文提出了一种适应LAIM部署的分层系统架构，并探索了一系列关键使能技术来促进LAIMs与低空系统的共同演化，引入了一种面向任务的服务交付执行管道以实现可扩展和自适应的服务交付。这些技术能够有效解决在低空经济中部署大型AI模型时遇到的挑战，提升系统的智能化和效率。", "conclusion": "通过实际案例研究验证了所提出的架构和方法的有效性，并指出了未来的研究挑战，为未来的研究提供了灵感。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01631", "html_url": "https://arxiv.org/abs/2506.01631", "title": "基于梯度的模型指纹识别技术用于LLM相似性检测及家族分类", "title_en": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification", "authors": "Zehao Wu,Yanjie Zhao,Haoyu Wang", "background": "随着大型语言模型（LLMs）成为现代应用中的关键软件组件，未经授权的模型通过细调、合并和再分配引发了重要的软件工程挑战。传统软件中，克隆检测和许可合规性已有成熟机制，但LLM生态系统缺乏有效的模型血缘追踪和许可合规机制。尤其当开源模型创建者，如Meta的LLaMA，要求衍生作品保留命名约定用于版权归因时，却缺乏技术手段来验证合规性。因此，本文聚焦于填补这一空白，将LLMs视为需要血缘追踪的软件制品，提出了TensorGuard，一种基于梯度的指纹识别框架，以用于LLM相似性检测和家族分类。", "innovation": "TensorGuard是一种基于梯度的指纹识别框架，它通过分析梯度响应来提取模型固有的行为特征，独立于训练数据、水印或特定模型格式。该框架支持safetensors格式，并通过统计分析梯度特征构建高维指纹。这些指纹能够直接评估任意模型间的相似性，并通过K-Means聚类算法进行家族分类，其中簇中心使用领域的知识初始化，基于已知基础模型设定。", "conclusion": "实验评估58个模型（包括8个基模型和50个衍生模型，涵盖五大家族：Llama、Qwen、Gemma、Phi、Mistral），其基于质心初始化的K-Means聚类分类准确率达到了94%。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17347", "html_url": "https://arxiv.org/abs/2506.17347", "title": "区分预测性AI与生成性AI的监管", "title_en": "Distinguishing Predictive and Generative AI in Regulation", "authors": "Jennifer Wang,Andrew Selbst,Solon Barocas,Suresh Venkatasubramanian", "background": "在过去十年中，政策制定者开发了一系列监管工具，以确保人工智能的发展符合关键的社会目标。这些工具最初是根据对预测性人工智能的担忧而设计的，因此包含了一些关于人工智能系统的性质和特定监管方法效益的假设。然而，随着生成型人工智能的出现，一些过去的假设不再适用，尽管政策制定者试图维持一个涵盖两种类型人工智能的单一监管目标。", "innovation": "本文发现，生成型人工智能有四个不同方面需要有意义的不同政策响应。一是生成型人工智能的一般性和适应性，使其成为不良的监管目标；二是设计有效的评估困难；三是新的法律问题改变了利益相关者和专家来源的生态系统；四是生成型人工智能价值链条的分散结构。基于这些区别，政策制定者需要评估过去十年政策工作的相关性和必要性，在必要时制定新的政策以应对生成型人工智能的独特风险.", "conclusion": "本文提出三项政策建议，以更有效地确定监管目标，并利用整个生态系统中的约束来管理生成型人工智能。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09993", "html_url": "https://arxiv.org/abs/2506.09993", "title": "基于扩散模型的文本感知图像恢复", "title_en": "Text-Aware Image Restoration with Diffusion Models", "authors": "Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim", "background": "图像恢复的目标是恢复退化图像，尽管扩散模型在自然图像恢复方面取得了巨大成功，但在退化图像中的文本区域重建方面经常难以忠实恢复。现有方法往往生成令人信服但错误的类似文本模式，我们称之为文本图像幻觉。本文提出了文本感知图像恢复（TAIR），一种同时恢复视觉内容和文本忠实性的新型恢复任务。为了解决这一任务，本文提供了一个包含10万个高质量场景图像的大规模基准数据集SA-Text，这些图像密集标注有各种复杂的文本实例。同时也提出了一个新的多任务扩散框架TeReDiff，该框架将扩散模型的内部特征集成到文本检测模块中，使得两个组件能够从联合训练中受益，从而提取丰富的文本表示，这些表示在随后的去噪步骤中作为提示使用。", "innovation": "本文引入了文本感知图像恢复任务（TAIR），并提出了一个称为TeReDiff的多任务扩散框架，将扩散模型的内部特征集成到文本检测模块中，使得两个组件能够从联合训练中受益，从而提取丰富的文本表示，这些表示在随后的去噪步骤中作为提示使用。", "conclusion": "大量实验表明，本文的方法在文本识别准确性方面显著优于现有的最先进的图像恢复方法，表现一致地好。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08320", "html_url": "https://arxiv.org/abs/2506.08320", "title": "如何评估生成式AI生成的密码策略的优劣？", "title_en": "How Good LLM-Generated Password Policies Are?", "authors": "Vivek Vaidya,Aditya Patwardhan,Ashish Kundu", "background": "生成式AI技术，尤其是大型语言模型（LLMs），在工业、学术界和政府机构中迅速普及，主要得益于其在自然语言处理方面的出色能力。然而，LLMs输出的一致性和不可预测性带来了显著的挑战，尤其是在网络安全至关重要的领域，如访问控制。特别是在访问控制领域，LLMs生成的响应一致性尤为关键，对于确保安全和可靠的操作至关重要。本文研究了LLMs在网络安全访问控制系统中的应用，并具体探讨了由自然语言提示生成的密码策略的准确性和一致性，将这些自然语言提示转换为可执行的配置文件。我们采用两种不同方法进行实验：首先使用预训练的LLMs仅从自然语言提示生成配置文件；其次，提供官方文档作为参考基准。我们系统评估了这些AI生成配置的完整性和一致性，揭示了当前LLMs面临的重大挑战，并为在访问控制系统中部署LLMs提供了宝贵的见解和建议。", "innovation": "本研究采用两种方法评估LLMs生成的密码策略，分别是：(1) 仅使用自然语言提示生成配置文件；(2) 通过参考官方文档生成配置文件。这种方法的创新在于明确了LLMs在实际应用中的具体挑战，并系统评估了这些模型生成密码策略的准确性和一致性性能，从而为在访问控制系统中有效使用这些模型提供了指导。", "conclusion": "本研究揭示了当前LLMs在生成密码策略方面的重大挑战。尽管LLMs具有强大的自然语言处理能力，但在生成一致性高且准确的密码策略时仍存在不足。这些发现有助于进一步改进和优化LLMs在访问控制系统中的应用，提供了具体的评估方法和改进建议。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17828", "html_url": "https://arxiv.org/abs/2506.17828", "title": "通过强化学习逐步重新加权和优化冻结的LLMs：一种迭代加权-然后优化方法", "title_en": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach", "authors": "Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong", "background": "调整大型语言模型（LLMs）与人类偏好通常需要使用诸如RLHF和DPO之类的微调方法，这些方法直接优化模型参数，因此它们不能在测试时用于提高模型性能，也不能在没有模型权重访问的情况下使用。相比之下，测试时的方法通过利用奖励函数来指导和提高输出质量，而不是直接更新权重，但是这种方法会产生较高的推理成本，并且其单次指导通常基于不完美的奖励或价值函数，导致输出质量不佳。", "innovation": "本文提出了一种名为Iterative Reweight-then-Optimize (IRO)的方法，这是一种通过强化学习（RL）框架实现对（冻结）基础模型的RL风格对齐，而无需修改其参数。在训练阶段，每次迭代通过（i）从基础模型中采样候选值，（ii）使用当前的价值函数重新采样，以及（iii）训练一个新的轻量化价值函数来引导下一次解码过程。在测试时，利用价值函数通过基于搜索的优化过程来引导基础模型生成。值得注意的是，用户可以利用IRO在自己的数据集上调整模型，类似OpenAI的强化微调（RFT），但无需访问模型权重。", "conclusion": "IRO提供了一种新的方法来调整冻结的LLMs，这种方法不仅能够利用价值函数来指导输出质量，而且能够在不需要直接访问模型权重的情况下进行调整，降低了成本和提高了灵活性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14634", "html_url": "https://arxiv.org/abs/2506.14634", "title": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "title_en": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "authors": "Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessica Daikeler", "background": "近年来，大规模语言模型（LLMs）的发展及其更广泛的可用性，引发了关于它们如何应用于问卷调查研究的讨论，包括对开放问答的分类。由于其语言能力，LLMs 可能成为一种比耗时的手动编码和监督机器学习模型预训练更有效的替代方案。尽管有一些关于这一主题的研究，但大多数研究仅限于英语回应或简单主题，因此关于其发现是否具有普遍适用性以及这些分类的质量如何与现有方法比较的问题仍然存在。因此，本研究通过使用德国动机参与调查为例，探究不同 LLMs 在其他情境下用于编码开放问卷答复的可能性，以及采用不同的提示方法进行比较，并通过人类专家编码评估 LLMs 的性能。", "innovation": "本研究通过使用德国动机参与调查为例，探究不同 LLMs 在其他情境下用于编码开放问卷答复的可能性，以及采用不同的提示方法进行比较，并通过人类专家编码评估 LLMs 的性能。研究发现，所有模型之间的整体性能差异巨大，只有微调过的模型才达到满意的预测性能。另外，提示方法之间的性能差异取决于所使用的 LLM。此外，不同原因类型的不同分类性能导致在不使用微调的情况下类别分布不均衡。", "conclusion": "本研究讨论了这些发现对开放答案编码方法学研究和实质性分析的意义，以及供处理或实质性分析此类数据的实践者参考。同时，本研究指出在 LLM 时代要选择自动分类方法时需要考虑的诸多权衡。研究为探讨 LLM 在调查研究中的高效、准确和可靠应用提供了实证基础，贡献了关于 LLM 应用条件的研究成果。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22523", "html_url": "https://arxiv.org/abs/2506.22523", "title": "在学术医疗中心进行的生成型AI版权聚焦测试报告", "title_en": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center", "authors": "James Wen,Sahil Nalawade,Zhiwei Liang,Catherine Bielick,Marisa Ferrara Boston,Alexander Chowdhury,Adele Collin,Luigi De Angelis,Jacob Ellen,Heather Frase,Rodrigo R. Gameiro,Juan Manuel Gutierrez,Pooja Kadam,Murat Keceli,Srikanth Krishnamurthy,Anne Kwok,Yanan Lance Lu,Heather Mattie,Liam G. McCoy,Katherine Miller,Allison C. Morgan,Marlene Louisa Moerig,Trang Nguyen,Alexander Owen-Post,Alex D. Ruiz,Sreekar Reddy Puchala,Soujanya Samineni,Takeshi Tohyama,Varun Ullanat,Carmine Valenza,Camilo Velez,Pengcheng Wang,Anna Wuest,Yuxiang Zhou,Yingde Zhu,Jason M. Johnson,Naomi Lenane,Jennifer Willcox,Francis J. Vitiello,Leo Anthony G. Celi,Renato Umeton", "background": "在学术医疗环境中部署生成型人工智能（AI）引发了版权合规问题的担忧。达纳-法伯癌症研究所实施了GPT4DFCI，这是一个内部分布式的生成型AI工具，使用了OpenAI模型，并获得了企业在研究和运营中的使用许可。由于该工具在组织内部的广泛采用、研究使命以及从Azure OpenAI服务产品中获得客户版权承诺所需的共同责任模型的需求，我们认定必须进行严格的版权合规测试。", "innovation": "我们于2024年11月进行了结构化的红蓝队伍测试，模拟了从GPT4DFCI中提取版权内容的过程。四个团队分别在文学作品、新闻文章、学术出版物和受限访问的临床笔记四个领域进行了测试。测试发现了特定的漏洞，表明生成型AI在版权合规方面存在脆弱性，并因此实施了具体的缓解策略，引入了版权特定的元提示，该缓解措施自2025年1月起已在生产环境中运行。", "conclusion": "系统化的红蓝队伍测试揭示了生成型AI在版权合规方面存在的具体漏洞，并指导了具体的缓解策略。学术医疗机构在部署生成型AI时，应实施持续的测试协议以确保法律和道德合规性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X: 统一的空中与地面车辆到一切协作", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Fengze Yang,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "多车辆协作驾驶在优势上明显优于单车辆自主驾驶，但传统的基于基础设施的V2X（车辆到一切）系统仍然受限于高昂的部署成本，并在农村和郊区留下了未覆盖的危险区域。因此，本研究提出了AirV2X-Perception数据集，该数据集利用无人机作为固定的RSUs（路侧单元）的灵活替代品或补充。无人机相比地面检测提供了诸多优势，包括减少遮挡的独特空中视角、灵活的移动能力（可以悬停、巡逻、护航）以及较固定的基础设施部署成本更低。", "innovation": "本研究创新地采用了无人机（UAV）技术，作为固定的RSUs的替代或补充，以解决传统V2X系统的限制。与基于地面的感知相比，无人机提供了独特的视角优势，减少了遮挡；并且能够灵活地悬停、巡逻和护航，对导航规则有更大的移动能力。此外，无人机部署成本也显著低于固定的基础设施。开发的AirV2X-Perception数据集包含了6.73个小时的无人机辅助驾驶场景，覆盖了城市、郊区和农村环境，并且拥有不同的天气和光线条件，推动了基于无人机的自动驾驶系统的算法开发和标准化评估。", "conclusion": "AirV2X-Perception数据集的推出填补了空中辅助自动驾驶系统领域算法开发和标准化评估的关键空白，旨在加速该领域的研究和发展。数据集和开发工具已开源，以促进该领域的合作和进展。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "基于语义结构的生成性攻击以增强对抗性可转移性", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "生成对抗攻击在白盒代理模型上训练扰动生成器，并随后将精心制作的扰动应用于未知的黑盒受害模型。这种方法相对于迭代攻击具有更高的推理效率、可扩展性和可移植性。然而，现有的研究尚未充分利用生成模型的表示能力来保留和利用语义信息。生成器的中间激活包含了丰富的语义特征，如对象边界和粗略的形状，这些特征尚未得到充分开发，从而限制了扰动与关键的对抗性可移植性区域的对齐。为此，本文提出了一种基于Mean Teacher的语义结构感知攻击框架，通过特征蒸馏，进一步引导学生层激活与语义丰富的教师层激活的一致性。这种方法使扰动合成集中在生成器中语义显著的早期中间块，据此进行逐级的对抗性扰动，在这些区域可以显著提高对抗性可移植性。", "innovation": "本文提出了一种基于Mean Teacher的语义结构感知攻击框架。通过特征蒸馏，进一步指导学生层激活与语义丰富的教师层激活之间的一致性。并且，扰动合成集中在生成器中语义显著的早期中间块，据此进行逐级的对抗性扰动，这使方法能够显著提高对抗性可移植性，相对于现有最先进的生成性攻击方法，表现出一致性改进，通过常规指标和新的误纠正率（ACR）进行了全面评估。", "conclusion": "通过广泛的实验，本文在多种模型、领域和任务中展示了该方法相对于现有最先进的生成性攻击方法的持续改进，并通过常规评估指标和新的误纠正率（ACR）进行了全面评估。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00631", "html_url": "https://arxiv.org/abs/2507.00631", "title": "Horus：不确定环境下无信任委托的一种协议", "title_en": "Horus: A Protocol for Trustless Delegation Under Uncertainty", "authors": "David Shi,Kevin Joo", "background": "在动态且低信任环境中，自主人工智能代理可以通过将工作委托给子代理来获得利益，但这并不保证正确性。通过提前说明或集中监督来确保正确性对于此类环境来说是不够的。系统中的正确性是一种 emergent 属性，系统通过暴露错误的成本低于犯错误的成本而自然形成。因此在存在不确定性的环境下，确保自主AI代理正确执行工作的挑战在于如何在无信任环境下建立委托机制.", "innovation": "本文提出了一个名为Horus的协议，该协议通过抵押索赔的方式在递归验证游戏中实现正确性验证。该协议允许任务以意图的形式发布，参与者竞相解决任务。选择的任务执行者在承担风险的情况下执行任务，任务完成后由验证者进行核验。任何挑战者可以对结果进行挑战并赌注以触发验证过程。错误的代理将受到惩罚，而正确的对手将得到奖励，且有一个升级途径可以惩罚错误的验证者。当解决者、挑战者和验证者的激励一致时，验证条件将成为纳什均衡，使正确性成为最优行为.", "conclusion": "通过Horus协议，正确性可以作为无信任环境下的 Nash 均衡条件自然形成，其设计既保障了智能代理的正确执行又能够有效避免错误行为带来的风险。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00660", "html_url": "https://arxiv.org/abs/2507.00660", "title": "MTCNet: 运动和拓扑一致性引导的4D超声三尖瓣分割学习", "title_en": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound", "authors": "Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni", "background": "三尖瓣反流是心脏最常见的疾病之一。四维（4D）超声影像学被用作评估动态瓣膜形态的主要成像模式，但由于缺乏相位注释、严重的运动伪影和较差的影像质量等因素，4D三尖瓣（MV）分析仍然具有挑战性。现有的方法没有相位间的依赖性，阻碍了4D MV分析的发展。现有的方法无法建立标注相位和未标注相位之间的结构一致性，限制了模型在无监督和半监督学习中的应用潜力。", "innovation": "提出了一种基于运动和拓扑一致性的引导网络（MTCNet），用于半监督学习中的4D MV超声分割。MTCNet只需要稀疏的未-收缩期和未-舒张期注释，设计了跨相运动引导的一致性学习策略，利用双向注意力记忆库传播时空特征，实现卓越的跨相和相间表现。此外，提出了一种新的拓扑引导的相关正则化，探索物理先验知识，保持解剖上合理的结构对应关系。与先进的方法相比，MTCNet展示了优越的跨相一致性（Dice: 87.30%，HD: 1.75mm）。", "conclusion": "通过对4D MV超声数据集的广泛评估，证明了MTCNet在无监督情况下实现高质量三尖瓣分割的能力，同时有效利用了标注和未标注相位的数据，显著提高了分割的精度。代码和数据集可在指定链接下载。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23351", "html_url": "https://arxiv.org/abs/2506.23351", "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "title_en": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "authors": "Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yu Chen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu", "background": "新兴领域机器人体化人工智能（Embodied AI）旨在推动能够感知、推理和在复杂物理环境中执行任务的自主系统发展。现有的单臂系统虽然在执行任务方面表现出色，但对于处理涉及刚性、可变形和触觉敏感物体的复杂任务，双臂系统更为必要。为此，组织方在2025 CVPR MEIS研讨会期间启动了RoboTwin双臂合作挑战赛，这一挑战通过实证赛和仿真赛对双臂操作策略进行了评估和比较，吸引了来自全球的64个团队和超过400名参与者，展示了多个现有的顶级解决方案，并提供了如何学习通用双手策略的宝贵见解。", "innovation": "该研究通过在RoboTwin仿真平台（1.0和2.0）及AgileX COBOT-Magic机器人平台上举办的挑战赛，设计了涵盖刚性、可变形和触觉场景的17项双臂操作任务。该研究不仅展示了现有的顶级解决方案，如SEM和AnchorDP3，还推动了对双臂策略学习的理解，并提出了未来的研究方向，旨在支持未来在鲁棒性和可泛化双臂操作策略方面的研究。", "conclusion": "该报告归纳并展示了此次挑战赛的竞赛设置、任务设计、评估方法、关键发现和未来方向，为未来的研究提供了宝贵的支持。挑战赛详情见：this https URL"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01551", "html_url": "https://arxiv.org/abs/2507.01551", "title": "自引导过程奖励优化与再定义的步进优势为过程强化学习", "title_en": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "authors": "Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua", "background": "过程强化学习（PRL）在增强大型语言模型（LLMs）的推理能力方面显示出巨大潜力。然而，引入额外的过程奖励模型会产生显著的计算开销，并且尚无统一的理论框架用于过程级别优势估计。", "innovation": "该论文提出了一种新的框架——自引导过程奖励优化（SPRO），通过两个关键创新解决了上述问题：（1）理论上证明了过程奖励可以从策略模型本身内部推导出来；（2）引入了具体的累积过程奖励和掩蔽步骤优势（MSA），这使得在共享提示采样组中可以进行细致的步骤优势估计。", "conclusion": "实验结果表明，SPRO相比vanilla GRPO具有3.4倍的训练效率和17.5%的测试准确率改进。此外，SPRO在整个训练过程中保持了稳定且较高的策略熵，并将平均响应长度减少了约三分之一，这表明SPRO能够提供足够的探索并防止奖励作弊。值得注意的是，SPRO与监督结果的RL方法（如GRPO）相比没有增加额外的计算开销，有利于工业实施。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00606", "html_url": "https://arxiv.org/abs/2507.00606", "title": "Mixture of Reasonings: 教大型语言模型使用适应性策略进行推理", "title_en": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies", "authors": "Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang", "background": "大型语言模型（LLMs）通过高级提示技术如思维链（CoT）和思维树（ToT）在复杂的任务中表现出色，但它们依赖于手工构建的任务特定提示，这限制了它们的适应性和效率。现有的方法需要人工设计特定任务的提示，这不仅费时，而且难以自动化和推广到不同类型的任务中。因此，研究人员需要一种新的方法来提高LLMs的适应性和效率，使其能够在没有外部提示工程的情况下进行自主的、任务自适应的推理。", "innovation": "本文提出了Mixture of Reasoning（MoR）训练框架，该框架将多种推理策略嵌入到LLMs中，以便在没有外部提示工程的情况下实现自主、任务自适应的推理。MoR有两个阶段：思维生成，使用像GPT-4o这样的模型创建推理链模板；SFT数据集构建，将模板与基准数据集配对进行监督微调。实验结果表明，MoR显著提高了性能，MoR150在使用CoT提示时提升了2.2%，相比基线提升了13.5%。MoR消除了对任务特定提示的需求，提供了泛化的解决方案，适用于各种任务中的稳健推理。", "conclusion": "MoR通过将多种推理策略嵌入LLMs中，消除了对任务特定提示的需求，实现了自主、任务自适应的推理，显著提高了LLMs的性能和适应性。这种方法为LLMs提供了一种泛化的、适应不同类型的推理任务的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00953", "html_url": "https://arxiv.org/abs/2507.00953", "title": "从句到序列：重新思考生物系统中的语言", "title_en": "From Sentences to Sequences: Rethinking Languages in Biological System", "authors": "Ke Liu,Shuaike Shen,Hao Chen", "background": "大语言模型在自然语言处理（NLP）领域的应用已显示出潜力，可用于模拟生物语言，如蛋白质、RNA和DNA。自回归生成范式和评估指标已经从NLP转移到生物序列建模中。然而，自然和生物语言的内在结构相关性本质上是不同的。因此，作者回顾了生物系统中的语言概念，以更好地理解NLP的成功如何有效地转移到生物领域。通过将生物分子的三维结构视为句子的语义内容，并考虑残基或碱基之间的强相关性，作者强调了结构评估的重要性，并展示了自回归范式在生物语言建模中的适用性。", "innovation": "作者通过将生物分子的3D结构视为句子的语义内容，并考虑残基或碱基之间的强相关性，提出了结构性评估的重要性，并展示了自回归范式在生物语言建模中的适用性。这与现有的方法不同，因为传统的NLP方法可能忽略了生物序列中的这种三维结构和强相关性。", "conclusion": "作者总结认为，通过更好地理解生物系统的语言概念，可以从NLP的成功中有效借鉴，用于生物语言建模。提出了自回归范式的适用性，并将其应用于生物语言建模中，同时强调了结构评估的重要性。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01352", "html_url": "https://arxiv.org/abs/2507.01352", "title": "Skywork-Reward-V2: 通过人机协同扩展偏好数据治理", "title_en": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "authors": "Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou", "background": "目前，尽管rewarld模型（RMs）在人类反馈强化学习（RLHF）中至关重要，但现有的开放RMs在大多数评价基准上表现不佳，无法准确捕捉人类复杂的偏好。即便是采用了高级训练技术的方法也未能显著提高性能。原因可能在于偏好数据集本身的局限性，这些问题包括范围狭窄、合成标签或缺乏严格的质控。", "innovation": "本文提出了一种名为SynPref-40M的大规模偏好数据集，包含4000万个偏好对，同时设计了一种人机协同的两阶段数据治理管道，以快速高质量地治理数据。该研究训练了一个参数量从0.6B到8B的Skywork-Reward-V2系列奖励模型，该模型在七个主要奖励模型基准中表现出最先进的性能。实验证明，效果不仅源于大规模数据，还源于高质量的数据治理。", "conclusion": "Skywork-Reward-V2系列奖励模型代表了对开放RMs的重大进展，展示了现有偏好数据集的潜力，并证明了人机协同治理能够显著提升数据质量。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01381", "html_url": "https://arxiv.org/abs/2507.01381", "title": "DSAC-D分布扩散策略软自适应评论者", "title_en": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": "Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li", "background": "强化学习已被证明在处理复杂控制任务方面非常有效。传统方法通常使用单模分布，如正态分布，来建模价值函数的输出。然而，单模分布容易导致价值函数估计偏倚，从而影响算法表现。", "innovation": "本文提出了一种称为DSAC-D（分布式软演员评论者结合扩散策略）的分布式强化学习算法，以解决价值函数偏倚估计的挑战，获取多模态策略表示。该算法通过引入策略熵和价值分布函数建立了可以收敛于最优策略的多模态分布策略迭代框架。并通过生成奖励样本集，结合扩散模型使用反向采样构建了能够准确刻画多峰分布的扩散价值网络。基于此，结合双通道的扩散价值网络和策略网络，推导了一种分布式的强化学习算法。MuJoCo测试结果显示，该算法不仅学习到了多模态策略，而且在所有的9个控制任务中均取得了最先进的性能，并且显著抑制了估计偏倚，总平均回报提高了超过10%，超过了现有的主流算法。实际车辆测试结果表明，DSAC-D能够准确刻画不同驾驶风格的多模态分布，扩散策略网络能够刻画多模态轨迹.", "conclusion": "通过通过反向采样生成奖励样本集来构建扩散价值网络，提出了多模态扩散策略网络，得到一个多模态价值函数和多模态策略，显著提高了控制任务的表现。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01548", "html_url": "https://arxiv.org/abs/2507.01548", "title": "用汉字编织叙事桥梁：为老年移民设计的AI共创工作坊", "title_en": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "authors": "Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen", "background": "本文探讨了如何借助AI辅助共同创作的方式，让城市中国中的老年移民，特别是老年移民，表达那些常常被碎片化、未充分代表或难以用言语表达的个人叙述。参与者通过结合口头讲述和汉字的象征性重构，分享了移民的记忆，并在大型语言模型（LLM）建议的小篆字符下，使用身体材料重构了新的汉字形式。通过人类引导和软AI的存在，参与者将生活经验转化为可视和触觉的表达，无需数字素养。这种方法为人类与AI合作及老龄化提供了新的视角，重新定位了AI的角色，不再作为内容生产者，而作为支持机制，并支持社会技术系统内的叙述能动性.", "innovation": "一种新的方法，通过结合口头讲述、汉字的象征性重构和大型语言模型建议的小篆字符，让老年移民使用AI辅助共同创作的方式表达个人故事，这种方法不依赖于数字素养，并为社会技术系统中的叙述能动性提供了支持.", "conclusion": "研究通过一个试点工作坊展示了如何使用AI辅助共同创作的方法来表达老年移民的个人故事，这为人类与AI的合作及老龄化提供了新的视角，强调了AI作为支持机制的角色，而不仅仅是内容生产者。这种方法有助于提升老年移民的社会参与感，并促进了他们对自我叙事的能动性."}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01041", "html_url": "https://arxiv.org/abs/2507.01041", "title": "在边缘网络上快速划分AI模型", "title_en": "Fast AI Model Splitting over Edge Networks", "authors": "Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin(Sherman)Shen", "background": "_SPLIT学习（SL）作为一种计算效率高的方法，已经被用于人工智能模型训练，能够减少设备端的计算负担。然而，复杂的模型架构增加了找到最优模型划分的计算难度。作者将任意人工智能模型表示为有向无环图（DAG），并将其最优模型划分问题重新定义为最小s-t割搜索问题。通过这种方法，可以采用最大流方法来识别最优模型划分，理论上表明提出的算法是正确的。此外，考虑到具有区块结构的AI模型，提出了一种区块划分算法来减少计算复杂度。该算法将每个区块抽象为单一顶点，从而简化了DAG来获得最优模型划分。", "innovation": "作者提出了一种基于DAG的快速模型划分算法，能够通过最大流方法识别最优模型划分，并证明该算法在理论上是优化的。此外，提出了一种区块划分算法来减少计算复杂性，并将每个区块抽象为单一顶点，简化DAG以获得最优模型划分。实验结果表明，所提出的算法可以在毫秒内确定最优模型划分，将训练延迟减少了24.62%-38.95%（在动态边缘网络上与现有基准相比）。", "conclusion": "提出的DAG基快速模型划分算法可以在毫秒内确定最优模型划分，并且能够显著减少动态边缘网络中的训练延迟。与现有的最先进的基准相比，这种算法在优化模型训练的同时显著提高了效率。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02259", "html_url": "https://arxiv.org/abs/2507.02259", "title": "MemAgent: 基于多对话RL记忆代理重塑长上下文LLM", "title_en": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": "Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou", "background": "尽管通过长度外推、高效注意和记忆模块的改进，实现了处理无限长文档的线性复杂度并保持外推期间性能不下降，但在长文本处理中仍未解决终极挑战。现有的方法主要在端到端的方式下直接优化长文本任务，并引入了一个新的基于代理的工作流，MemAgent，该工作流分段阅读文本并使用覆盖策略更新记忆。通过扩展DAPO算法来促进通过独立上下文多对话生成进行训练。", "innovation": "方法直接以端到端的方式优化长文本任务，并引入了MemAgent代理工作流，该工作流分段阅读文本并使用覆盖策略更新记忆。还扩展了DAPO算法以通过独立上下文多对话生成促进训练。MemAgent展示了出色的长上下文能力，能够从一个8K上下文训练的32K文本外推到3.5M QA任务，性能损失小于5%，并在512K RULER测试中达到95%以上。", "conclusion": "MemAgent能够处理无限长文档并在实际任务中表现出色，展示了其在长文本处理中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02221", "html_url": "https://arxiv.org/abs/2507.02221", "title": "GDC Cohort Copilot: 为Genomic Data Commons编目的一种AI副驾驶", "title_en": "GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons", "authors": "Steven Song,Anirudh Subramanyam,Zhenyu Zhang,Aarti Venkat,Robert L. Grossman", "background": "Genomic Data Commons (GDC) 为用户提供高质量、统一格式的癌症基因组学数据，但用户在利用图形化编目构建器创建特定患者队列时可能会遇到困难，尤其是在找到特定数据描述符方面，新用户尤其如此。为了解决这个问题，本文介绍了一种名为GDC Cohort Copilot的开源辅助工具，它能够自动根据用户的自然语言描述生成GDC编目过滤器，从而简化了用户创建编目的过程，并优化了用户的体验。", "innovation": "本文开发并评估了多个大型语言模型（LLMs）用于GDC Cohort Copilot，结果显示，本地部署的开源GDC Cohort LLM在生成GDC编目方面比GPT-4o提示方法效果更好。此外，GDC Cohort Copilot提供了一个交互式的用户界面，允许用户进一步调整生成的编目结果。", "conclusion": "GDC Cohort Copilot是为GDC编目设计的一种开源AI辅助工具，能够根据用户输入的自然语言描述自动生成GDC编目过滤器，并支持进一步调整，证明了其在提高编目过程效率和准确性方面的有效性。该工具的主要实现细节和相关资源已在公开渠道提供。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02199", "html_url": "https://arxiv.org/abs/2507.02199", "title": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "title_en": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "authors": "Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu", "background": "链式思维（CoT）推理使基于变压器的文本处理模型在复杂数学和多步规划方面表现出色。然而，在标准的Decoder-only架构中，这些推理步骤以自然语言的形式被外部化，尽管这种方式提高了可解释性，但降低了效率。为了捕捉难以用语言表达的推理过程，许多研究探索了循环结构，试图将推理嵌入到隐空间中，以支持潜在的链式思维。在本文中，作者研究了Huginn-3.5B这种在推理时重复使用层的深度循环变压器，在不增加参数量的情况下，是否能自然产生这样的推理结构。作者使用一系列探针技术，包括Logit Lens和Coda Lens，来研究模型在算术任务中的内部行为。", "innovation": "作者研究了Huginn-3.5B这种在推理时重复使用层的深度循环变压器（Depth-Recurrent Transformer），探讨它是否能自然产生内部化链式思维的能力。这种方法通过在不增加参数量的情况下重复使用层来实现。作者使用探针技术来研究模型的内部行为，分析了最终和中间结果令牌的秩轨迹，揭示了隐空间中潜在的链式思维的有限证据，并展现了循环块之间的探针不一致性。此外，作者还实证表明，增加循环深度虽然有增益，但效果有限，难以达到显式外部化推理步骤的效果。", "conclusion": "作者发现，Huginn-3.5B在算术任务中表现出的隐空间中的链式思维是有限的，并且循环块中的内部状态在可解释性上取决于层索引和解码方法。进一步地，作者实验表明增加循环深度带来的递归深度仅带来边际效果，远不及显式外部化推理步骤的效果。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02088", "html_url": "https://arxiv.org/abs/2507.02088", "title": "McBE：大规模语言模型的多任务中文偏见评估基准", "title_en": "McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models", "authors": "Tian Lan,Xiangdong Su,Xu Liu,Ruirui Wang,Ke Chang,Jiang Li,Guanglai Gao", "background": "随着大型语言模型（LLMs）被广泛应用于各种NLP任务，它们固有的偏见逐渐显露出来。因此，评估LLMs中的偏见对于减轻其伦理风险至关重要。然而，目前大多存在的偏见评估数据集主要集中在英文和北美的文化背景上，其偏见分类对于其他文化不完全适用。基于中文和文化的数据集稀缺。更重要的是，这些数据集通常只支持单一的评估任务，无法从多个方面评估LLMs中的偏见。针对这些问题，我们提出了一个包含4,077个偏见评估实例的多任务中文偏见评估基准（McBE），涵盖了12个单一偏见类别、82个子类别，并引入了5个评估任务，实现了广泛的类别覆盖、内容多样性和评估全面性。", "innovation": "我们提出了一个多任务中文偏见评估基准（McBE），旨在填补基于中文数据集偏见评估的空白，并提供全面的类别覆盖、内容多样性和评估全面性。此外，我们还评估了几种不同系列和参数规模的流行LLMs，发现这些模型都不同程度地存在偏见，我们进行了深入结果分析，为理解和评估LLMs中的偏见提供了新的洞见。", "conclusion": "所有这些LLMs都表现出不同程度的偏见。我们对结果进行了深入分析，为理解LLMs中的偏见提供了新的见解。"}
{"llm_update_time": "20250706", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01961", "html_url": "https://arxiv.org/abs/2507.01961", "title": "AC-DiT: 适应性协调扩散变换器在移动操作中的应用", "title_en": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation", "authors": "Sixiang Chen,Jiaming Liu,Siyuan Qian,Han Jiang,Lily Li,Renrui Zhang,Zhuoyang Liu,Chenyang Gu,Chengkai Hou,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang", "background": "近年来，移动操作因其能够在日常家庭任务中实现基于语言的机器人控制而备受关注。然而，现有方法在协调移动平台和机械臂方面仍面临挑战，主要原因有两点。首先，它们未能明确模型移动平台对机械臂控制的影响，容易在高自由度情况下累积错误。其次，全部使用相同的视觉观测模态（如全部是二维或全部是三维），忽视了移动操作过程中不同阶段的多模态感知需求差异。为解决这些问题，本文提出了一种自适应协调扩散变换器（AC-DiT），旨在增强移动平台和机械臂的协同作用以实现端到端的移动操作。本文首先引入了一种移动性到身体的条件机制，使模型可以首先提取平台运动的表示，然后将其作为预测全身行为的上下文先验，从而实现考虑到移动平台运动潜在影响的全身控制。其次，为适应移动操作不同阶段的感知需求，设计了一种感知感知自适应的多模态条件策略，该策略能够动态调整不同2D视觉图像和3D点云的融合权重，以适应当前感知需求，使模型在预测动作时能够灵活依赖2D输入或更强调3D几何信息的使用。", "innovation": "1. 引入了移动性到身体的条件机制，明确模型移动平台对机械臂控制的影响，减少控制误差积累。\n2. 设计了一种感知感知自适应的多模态条件策略，能够动态调整不同视觉信息的融合权重，以适应移动操作不同阶段的感知需求，提升模型的灵活性和准确性。", "conclusion": "通过在模拟和真实移动操作任务中的广泛实验验证了AC-DiT的有效性，展示了其在移动平台与机械臂协调控制上的性能提升。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02302", "html_url": "https://arxiv.org/abs/2507.02302", "title": "DoMIX: 一种高效利用细调中领域知识的框架", "title_en": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning", "authors": "Dohoon Kim,Donghun Kang,Taesup Moon", "background": "近年来，领域适应预训练（DAP）因其在微调预训练模型中的有效性而受到广泛关注。在此基础上，研究继续探索持续DAP，以开发能够逐步整合不同领域数据集的预训练模型。然而，现有的持续DAP方法面临一些局限性：（1）训练过程中计算成本高和GPU内存使用量大；（2）对增量数据顺序敏感；（3）为所有终端任务提供单一的通用模型，这与DAP的本质相矛盾。", "innovation": "本文提出了一种名为DoMIX的创新方法，通过利用低秩适配层（LoRA）模块，这是一种代表性的参数效率微调（PEFT）方法。该方法实现了高效的、并行的领域适应预训练，能够抵抗领域顺序的影响，并有效利用累积知识来为特定任务提供定制化的预训练模型。我们还证明了该方法可以扩展到传统的LLM微调场景之外。", "conclusion": "我们的方法通过LoRA模块解决了现有DAP方法中的挑战，使领域适应预训练更加高效和鲁棒，并能够利用积累的知识提供为特定任务量身定制的预训练模型。除了DAP应用场景，方法还可以扩展到标准的大语言模型微调场景。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02378", "html_url": "https://arxiv.org/abs/2507.02378", "title": "通过分布一致性和多样化的数据选择提高高效代码LLM训练", "title_en": "Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection", "authors": "Weijie Lyu,Sheng-Jun Huang,Xuan Xia", "background": "近期大型语言模型（LLMs）的进步显著提升了代码生成和程序理解能力，加速了软件工程的演变。当前方法主要通过大量数据来提升模型性能，侧重数据量，却往往忽视了数据质量，导致训练效率降低。现有方法未能有效解决这一问题，因此需要新的方法来提高训练效率和模型性能。", "innovation": "本文提出了一种利用参数化模型进行代码数据选择的方法，旨在同时提高训练效率和模型性能。该方法通过优化参数化模型来保证选择子集中的分布一致性与多样性，从而确保高质量的数据。实验结果显示，仅使用10K样本，本方法在HumanEval和MBPP上的性能分别比92K全样本基准提升了2.4%和2.3%，并在性能和效率上优于其他采样方法。", "conclusion": "本方法有效地提升了模型性能，显著降低了计算成本。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02364", "html_url": "https://arxiv.org/abs/2507.02364", "title": "QFFN-BERT：综合性研究：量子-经典混合变换器的深度、性能与数据效率", "title_en": "QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers", "authors": "Pilsung Kang", "background": "参数化量子电路（PQCs）最近作为增强神经架构表达能力的有前途组件而崭露头角。以往研究主要将PQCs集成到自注意力模块中，而本文则将PQCs应用于前馈网络模块，系统地研究了PQC深度、表达能力和可训练性之间的权衡。本文提出了一种名为QFFN-BERT的混合量子-经典变换器模型，其中紧凑型BERT变体的前馈网络模块被基于PQC的层所取代，最终架构采用了残差连接、RY和RZ旋转及交替纠缠策略，以确保稳定的训练和高水平的表达能力。实验表明，精心配置的QFFN-BERT在数据充分的情境下，参数特定的前馈网络参数减少了99%以上，且准确性达到基线的102%，比其经典对应物更具竞争力；在少量样本学习场景中，模型表现出一致且有竞争力的优势，这验证了其在高效数据使用方面的潜力。这些结果得到了对未经优化的PQC的消融研究的支持，该研究未能学习，证明了当与基础深度学习原则共同设计时，PQCs可以作为强大的、参数效率的前馈网络的替代品。", "innovation": "本文提出了一种名为QFFN-BERT的新型混合量子-经典变换器模型，其中紧凑型BERT变体的前馈网络模块被基于PQC的层所取代。设计考虑了PQC深度、表达能力和可训练性之间的贸易延迟梯度更新问题，提出了一种引入残差连接、RY和RZ旋转及交替纠缠策略的PQC架构，以确保模型在稳定训练和高表达能力方面的性能。通过在经典模拟环境下对SST-2和DBpedia基准数据集进行实验，证明了QFFN-BERT在表达力、可训练性以及数据效率方面的优异表现，特别在小样本学习场景中表现出色，进一步证明了其作为前馈网络的替代品在量子-经典混合模型中的应用潜力。", "conclusion": "实验结果表明，精心配置的QFFN-BERT模型在充分数据场景下，与经典Transformer相比积累了高达102%的准确性，除了实现显著的参数效率之外，还在少样本学习场景中表现出了持久的竞争优势，且已经表明PQC可以在深度学习架构中与经典FFNs平分秋色地共同设计。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02592", "html_url": "https://arxiv.org/abs/2507.02592", "title": "WebSailor：超人类推理在网页代理中的导航", "title_en": "WebSailor: Navigating Super-human Reasoning for Web Agent", "authors": "Kuan Li,Zhongwang Zhang,Huifeng Yin,Liwen Zhang,Litu Ou,Jialong Wu,Wenbiao Yin,Baixuan Li,Zhengwei Tao,Xinyu Wang,Weizhou Shen,Junkai Zhang,Dingchu Zhang,Xixi Wu,Yong Jiang,Ming Yan,Pengjun Xie,Fei Huang,Jingren Zhou", "background": "超越人类认知局限是大型语言模型（LLM）训练的一个重要前沿。专有代理系统如DeepResearch在极其复杂的资讯检索基准测试中展现出超人类能力，例如在BrowseComp测试中的表现，这一成就先前是无法实现的。我们推测其成功在于一种在开源模型中缺失的复杂推理模式：系统性减少极端不确定性，以便在庞大信息领域中导航的能力。", "innovation": "我们引入了WebSailor，一种全面的后训练方法，旨在培养这种关键能力。我们的方法包括通过结构化采样和信息混淆生成新颖且高不确定性任务、RFT冷启动以及高效的代理强化学习训练算法DUPO（复制采样策略优化）。通过这一整合管道，WebSailor在复杂资讯检索任务上显著超越所有开源代理，其性能与专有代理相当，缩小了能力差距。", "conclusion": "WebSailor显著提升了代理在复杂资讯检索任务上的表现，使其具备与专有代理相匹敌的能力，实现了开源模型在这一领域的重大突破。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02407", "html_url": "https://arxiv.org/abs/2507.02407", "title": "跨领域数据集评估阿散蒂ASR模型：性能、可扩展性和适应性比较评估", "title_en": "Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability", "authors": "Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame", "background": "大多数现有的自动语音识别（ASR）研究使用领域内数据集评估模型，但很少关注模型如何在不同的语音情境下进行泛化。本文通过使用四种阿散蒂语语音语料库对七种基于变压器架构的阿散蒂ASR模型（如Whisper和Wav2Vec2）进行基准测试，来填补这一空白，涵盖多个领域，包括文化相关的图像描述、非正式对话、圣经文本朗读以及即兴的金融对话，旨在评估这些模型在各领域内的性能差异。实验结果表明，模型在训练领域内表现优化，而在不匹配的情境下则显示出显著的准确性下降。此外，本文还探讨了Whisper和Wav2Vec2架构在错误行为上的差异：微调后的Whisper模型虽然转录更流畅但可能误导性较强，而Wav2Vec2则在遇到不熟悉输入时提供了更直接但更难以理解的输出。这些结果强调了对于低资源语言（LRL）应用，领域适应技术、适应性路由策略和多语言训练框架的需求。", "innovation": "本文通过使用多种阿散蒂语语料库对不同架构的ASR模型进行跨领域基准测试，不仅揭示了模型在不同领域的表现差异，还对比了特定架构在低资源语言应用中的优劣。这样的横向比较有助于发现模型的强弱项，对未来的ASR系统设计具有重要的参考意义。此外，作者还指出了在选择适合低资源语言应用的ASR模型时需要考虑的领域适应性和透明度等关键因素。", "conclusion": "研究强调了领域适应技术、适应性路由策略和多语言训练框架对于低资源语言（LRL）ASR应用的重要性，同时也指出现有的ASR模型在不同领域内的表现差异需要通过针对性的优化来提升其跨域泛化能力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02357", "html_url": "https://arxiv.org/abs/2507.02357", "title": "Coling-UniA在SciVQA 2025中的少样本示例检索与置信度驱动的集成方法", "title_en": "Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models", "authors": "Christian Jaumann,Annemarie Friedrich,Rainer Lienhart", "background": "该论文描述了作者在2025年SciVQA共享任务中的系统，即基于科学可视化问答的系统。背景信息涉及科学可视化问答领域内的挑战和现有技术。背景中提到由于复杂的科学图像和多样的问题类型，现有系统在处理这类任务时存在一定的限制和挑战。因此，作者提出了一种使用多模态大型语言模型和少样本示例检索策略的解决方案。", "innovation": "该系统创新之处在于采用了两个多模态大型语言模型的集成方法，结合了基于图表和问题类型选择的少样本示例检索策略，并根据模型的置信度来选择答案。这种基于置信度的集成方法和少样本学习技术的结合，提高了系统的性能和适应性，特别是在盲测数据中排名第三，平均F1分数达到85.12。", "conclusion": "研究团队通过集成多模态大型语言模型和采用基于置信度的少样本示例检索策略，成功地提高了科学可视化问答系统的性能。结果表明，这种方法能够有效应对复杂的科学图像和多样化的问题类型。此外，代码已经公开，为其他研究者提供了借鉴和进一步研究的基础。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02428", "html_url": "https://arxiv.org/abs/2507.02428", "title": "低资源语言中受损语音社区驱动数据收集的食谱", "title_en": "A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages", "authors": "Sumaya Ahmed Salihs,Isaac Wiafe,Jamal-Deen Abdulai,Elikem Doe Atsakpo,Gifty Ayoka,Richard Cave,Akon Obu Ekpezu,Catherine Holloway,Katrin Tomanek,Fiifi Baffoe Payin Winful", "background": "本研究提出了一个收集受损语音样本的方法，用于构建语音识别（ASR）模型，特别关注低资源语言。背景包括当前ASR技术的局限性，尤其是对于低资源和受损语言的支持不足，这限制了ASR技术的普及和应用。此外，研究强调了数据收集的挑战，特别是如何有效和包容地收集来自不同背景的受损语音样本，以支持针对性的ASR模型开发。\n", "innovation": "研究的主要创新点在于提出了一种“食谱”式的最佳实践指南和社区驱动的数据收集与ASR模型构建培训方法。通过这一点，研究不仅限定在Akan语言（一种广泛使用的加纳土著语言）上创建了一个开源受损语音数据集，而且还提供了初步的ASR模型微调结果，以更好地识别Akan语境下的受损语音，从而推动ASR技术的包容性发展。\n", "conclusion": "本研究通过建立一个开源数据集、提供实践指南和开源工具，旨在促进研究人员和实践者根据受损个体的特定需求开发包容性的ASR技术。此外，该研究为低资源语言受损语音的数据收集与模型构建提供了有价值的参考资料和实践经验，促进了这一领域的进一步研究与发展。\n"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02593", "html_url": "https://arxiv.org/abs/2507.02593", "title": "在（人类）标签变化下的活动学习重访", "title_en": "Revisiting Active Learning under (Human) Label Variation", "authors": "Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher", "background": "高质量标注数据是应用监督学习中的限制因素。在自然语言处理中，相同实例可能会有不同的标签（即标签变化，LV），即使标注框架通常假设存在单一的真实标签。忽视了可能的差异标注（即人类标签变化，HLV）作为信息信号。此外，活动学习（AL）虽然是一种优化有限标注预算的方法，但在实践中常常假设有单一真实标签或简化假设，这些假设不考虑HLV的存在。因此，本文要重新审视真实性和标签本质的基础假设，指出需要将观测到的标签变化分解为信号（如HLV）和噪音（如标注错误）。", "innovation": "本文提出了一个概念框架，以将HLV融入活动学习的整个循环中，包括实例选择、标注者选择和标签表示。同时，讨论了大型语言模型（LLM）作为标注者的整合。目的是为HLV感知的活动学习建立概念基础，更好地反映实际标注的复杂性。", "conclusion": "本文的研究成果为理解和解决标签变化问题提供了新的视角，旨在更好地利用有限的标注资源，同时考虑人类标注行为的复杂性。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02679", "html_url": "https://arxiv.org/abs/2507.02679", "title": "探索职业头衔之外的性别偏差", "title_en": "Exploring Gender Bias Beyond Occupational Titles", "authors": "Ahmed Sabir,Rajesh Sharama", "background": "该研究探讨性别和语境偏差之间的关联，集中在动词、名词以及特别是职业方面。研究引入了名为GenderLexicon的新数据集和一个能够估计语境偏差及其相关性别偏差的框架。此外，研究还证实了性别偏见存在于职业刻板印象之外，这进一步扩展了对性别偏见的理解。为验证方法的有效性，研究人员在五个不同的数据集上进行了评估，其中包括一个日语数据集。", "innovation": "该研究通过引入名为GenderLexicon的新数据集及能够量化和解释性别偏见的框架，改进了现有方法对性别偏见的可解释性。研究不仅限于职业偏见，还发现了职业之外的语言偏见，扩展了性别偏见研究的维度，为其提供了新的视角。", "conclusion": "研究结果证实了性别偏见存在于职业刻板印象之外，并通过多个数据集验证了方法的有效性。这为未来性别偏见研究提供了新的数据支持和分析框架，有助于更全面地理解性别偏见现象。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02506", "html_url": "https://arxiv.org/abs/2507.02506", "title": "IndianBailJudgments-1200: 一个关注印度保释命令的多属性数据集用于法律NLP", "title_en": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders", "authors": "Sneha Deshmukh,Prathmesh Kamble", "background": "印度等地区在法律自然语言处理（NLP）方面的发展仍然不足，主要是因为缺乏结构化的数据集。印度法院作出的保释判决的法律数据更具挑战性，因为涉及的法律条文和案件类型繁多，这使得开发相关的法律NLP应用变得复杂和困难。因此，需要一个专门针对印度保释审裁的多属性数据集来推进这一领域的发展。", "innovation": "该研究提出了一种名为IndianBailJudgments-1200的新基准数据集，包含1200个印度法院作出的有关保释裁决的判决。该数据集涵盖了20多个属性的标注，包括裁决结果、印度刑法（IPC）条款、犯罪类型和法律推理等。这些标注通过一个由提示工程设计的语言模型GPT-4o管道生成并经过一致性验证。这个数据集能支持各种法律NLP任务，如结果预测、摘要和公平性分析，且是首个专门针对印度保释法律的公开数据集。", "conclusion": "IndianBailJudgments-1200数据集为推动印度保释问题上的法律NLP研究提供了高质量的资源，具有广泛的适用性，能够满足法律NLP测试和评估的需求，并将促进这一领域的进一步发展。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02145", "html_url": "https://arxiv.org/abs/2507.02145", "title": "理或不理？面向对话摘要的推理型大语言模型的全面评估", "title_en": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization", "authors": "Keyan Jin,Yapeng Wang,Leonel Santos,Tao Fang,Xu Yang,Sio Kei Im,Hugo Gonçalo Oliveira", "background": "对话摘要在客户服务、会议分析和对话型人工智能等领域具有重要的实际价值。尽管大型语言模型已经在多个总结任务上取得了显著进展，但对于需要同时进行抽象和简洁性的对话场景而言，长链条思考（Long Chain-of-Thought）等具体推理架构的表现尚未被详细研究。这项研究通过三种主要范式（通用、角色导向、查询导向的对话摘要），对推理型和非推理型大型语言模型进行了全面系统的评估，覆盖了多种语言、领域和总结长度，使用了多个基准（SAMSum、DialogSum、CSDS和QMSum）和高级评估协议，包括基于大模型的自动指标和人为灵感标准。尽管在其他推理密集型任务中存在趋势，但研究表明，明确的步骤推理并不总是提高对话总结质量，推理型大语言模型往往会更冗长、事实不一致和缺乏简洁性，与非推理型大语言模型相比。通过具体场景分析和详细的案例研究，我们进一步确定了在复杂对话情景中，明确推理为何有时未能提升或甚至妨碍摘要的效果。这项工作为当前推理型大语言模型的局限性提供了新的见解，并强调了需要针对实际对话摘要进行有针对性的建模和评估策略的必要性。", "innovation": "这项研究首次针对推理型和非推理型大型语言模型进行了全面系统的评估，覆盖了多种语言、领域和总结长度，使用了多个基准（SAMSum、DialogSum、CSDS和QMSum）和高级评估协议，包括基于大模型的自动指标和人为灵感标准。这项研究的结果显示，明确的步骤推理并不总是提高对话总结质量，这是在其他推理密集型任务中也没有发现的规律。通过具体场景分析和详细的案例研究，进一步明确了在复杂对话场景中，明确推理为何有时未能提升或甚至妨碍摘要的效果。这项工作提供了当前推理型大语言模型局限性的新见解，并强调了需要进行有针对性的建模和评估策略。", "conclusion": "这项研究通过详细分析推理对对话摘要的影响，揭示出推理型大语言模型在某些情况下可能不如非推理型大语言模型效果好，并提供了关于推理型大语言模型适用性和局限性的新见解。这项研究强调了在实际对话摘要任务中，应当进行有针对性的建模和评估策略，以便更好地利用这些模型的优势。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02694", "html_url": "https://arxiv.org/abs/2507.02694", "title": "LLMs能否在AI研究论文中识别关键局限？一项系统的评估", "title_en": "Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers", "authors": "Zhijian Xu,Yilun Zhao,Manasi Patwardhan,Lovekesh Vig,Arman Cohan", "background": "同行评审是科学研究的基础，但出版物的大量增长加剧了这一专业知识密集型过程的挑战。尽管大型语言模型（LLM）在各类科学任务中显示出潜力，但对于它们在同行评审中的应用，尤其是用于识别论文局限性方面，研究还相对不足。本文首先提供了一个涵盖科学研究中局限性类型的全面分类框架，特别关注AI领域。基于这一分类框架，本文介绍了LimitGen，这是第一个用于评估LLM支持早期反馈和补充人类同行评审能力的综合基准。这个基准由两个子集构成：LimitGen-Syn是一个通过精心控制高质量论文的轻微修改创建的合成数据集；LimitGen-Human是一个包含真实人类撰写的局限性集合。为了提高LLM系统识别局限性的能力，我们增加了文献检索的辅助，这对于基于历史科学发现来识别局限性至关重要。我们的方法增强了LLM系统生成研究论文中局限性的能力，使它们能够提供更具体和建设性的反馈。", "innovation": "本文介绍了LimitGen，这一创新的基准用于评估LLM在支持早期反馈和补充人类同行评审方面的能力。该基准包括一个合成数据集LimitGen-Syn和一个真实人类撰写的局限性集合LimitGen-Human。此外，通过集成文献检索功能，助力识别局限性，增强了LLM系统在生成论文局限性方面的表现，提高了其提供更具建设性反馈的能力。", "conclusion": "我们的方法不仅促进了对LLM在科学领域中识别局限性的系统了解，还为改进LLM支持同行评审的能力提供了新的途径。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02595", "html_url": "https://arxiv.org/abs/2507.02595", "title": "MPF：通过多视角融合在部署后对语言模型进行对齐和去偏", "title_en": "MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion", "authors": "Xin Guan,PeiHsin Lin,Zekun Wu,Ze Wang,Ruibo Zhang,Emre Kazim,Adriano Koshiyama", "background": "随着大型语言模型（LLMs）的广泛应用，人们对模型中的偏见问题越来越关注，随之而来的是对易于执行的偏见缓解方法的需求增长。为了响应这一需求，Multiperspective Fusion (MPF) 提出了一种新的后训练对齐框架。此框架基于 SAGED 管道开发，SAGED 管道用于构建偏见基准并提取可解释的基本分布。MPF 通过多视角生成来揭示和调整 LLM 输出与细腻、人性化基本基线之间的偏差。通过对基线（例如人力资源专业人员的情感分布）进行分解，MPF 指导生成过程，通过采样和按分解得到的概率加权来平衡响应。", "innovation": "MPF 为大型语言模型（LLMs）的后训练对齐提供了一种新颖的方法，它基于 SAGED 管道构建，利用多视角生成来暴露并调整模型输出的偏见。这种方法通过分解基线（如情感分布）为可解释的视角组件，引导生成过程的采样和加权平衡。与此前的方法不同，MPF 不需要复杂的提示工程或再训练，而是提供了一种可扩展且可解释的对齐和去偏方法，适用于部署中的 LLM。", "conclusion": "实验结果表明，MPF 可以将 LLM 情感分布与具挑战性的反事实基线和人力资源基线对齐，从而减少 Kullback-Leibler (KL)  divergence、校准误差，并能够泛化到未见过的问题。这表明 MPF 提供了一种与部署中的 LLM 完全兼容、无需进行扩展提示工程和再训练即可实现对齐和去偏的可扩展且可解释的方法。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02804", "html_url": "https://arxiv.org/abs/2507.02804", "title": "多视角的多模态数学推理", "title_en": "Multimodal Mathematical Reasoning with Diverse Solving Perspective", "authors": "Wenhao Shi,Zhiqiang Hu,Yi Bin,Yang Yang,See-Kiong Ng,Heng Tao Shen", "background": "近期大规模强化学习（RL）在增强大型语言模型（LLM）的推理能力方面取得了显著进步，特别是在数学领域。然而，当前的多模态LLM（MLLM）在数学推理中往往依赖于一对一的图像-文本对和单一解决方案的监督，忽视了有效的推理视角和内心的反思的多样性。", "innovation": "本文介绍了一个新的数据集MathV-DP，它捕获了每个图像-问题对的多种多样的解题轨迹，促进了更丰富的推理监督。进一步提出了基于Qwen-VL的Qwen-VL-DP模型，该模型通过监督学习进行微调，并通过规则强化学习（GRPO）方法进行增强，该方法结合了正确性判断和多样性感知奖励函数。本文的方法强调从各种推理视角中学习，并区分正确的但不同的解决方案。", "conclusion": "在MathVista的minitest和Math-V基准上的广泛实验表明，Qwen-VL-DP在准确性和生成多样性方面显著优于之前的基线MLLM，突出了将多样视角和反思推理纳入多模态数学推理中的重要性。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02822", "html_url": "https://arxiv.org/abs/2507.02822", "title": "SynapseRoute：基于双态大型语言模型的自动路由切换框架", "title_en": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model", "authors": "Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun", "background": "随着大型语言模型（LLMs）在实际应用中的广泛应用，选择合适的模型不仅需要考虑性能，还需要考虑运营成本。具有推理能力的模型的出现进一步加剧了‘思考’（高推理）和‘非思考’（快速，低成本）模式之间的成本差距。研究表明，大约58%的医疗问题仅通过‘非思考’模式就能被准确回答，无需进行高成本的推理过程。这表明问题复杂性明显不同，提出根据复杂性动态路由查询的方法可以优化准确性和成本效率，改善整体用户体验。", "innovation": "我们提出了一个基于机器学习的智能路由框架，名为SynapseRoute。它能够智能地将输入查询分配给思考或非思考模式。实验结果表明，SynapseRoute相比单独使用思考模式，不仅提高了整体准确性（0.8390 vs. 0.8272），还降低了36.8%的推理时间和39.66%的token消耗。此外，适Application适的路由避免了在简单查询上过度推理导致的延迟和准确性降低的问题。该工作还进一步引入了Accuracy-Inference-Token（AIT）指数，以全面评价准确率、延迟和token成本之间的权衡。", "conclusion": "该工作揭示了大约58%的医疗问题是可以通过非思考模式准确回答的，无需高成本的推理过程，并提出了SynapseRoute，这种基于机器学习的动态路由框架，能够智能地将查询路由到合适的模式中，从而优化了准确性和成本效率，改善了整体用户体验。引入的AIT指数可以帮助全面评估准确率、延迟和token成本之间的权衡。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02850", "html_url": "https://arxiv.org/abs/2507.02850", "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "title_en": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "authors": "Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas", "background": "该研究描述了一个语言模型（LMs）中的漏洞，这个漏洞使得单一用户通过提供提示和对LM输出进行点赞/点踩反馈的方式，可持久地改变模型的知识和行为。攻击者通过促使LM随机输出“中毒”或正常的响应，然后针对这些响应进行点赞或点踩，使得模型在后续的偏好调优过程中增加了生成“中毒”响应的几率。这种攻击能够插入模型之前没有的知识，修改代码生成模式并引入可利用的安全漏洞，以及注入虚假的金融新闻。", "innovation": "该研究发现了语言模型偏好调优的一种新质特性——即使反馈信号非常有限，也可以被用于对抗性控制模型行为；同时也扩展了关于预先训练数据污染和部署时提示注入的研究，提出了用户反馈攻击的新机制，即用户利用有限的交互方式改变模型的行为。", "conclusion": "该研究证明了一种新的攻击方法，这种方法通过对模型提供的少量反馈信号的适应性调整，能够改变模型的行为，影响模型的输出。该研究强调了在使用基于用户反馈的语言模型时应采取更严格的保护措施，以防止未经授权的知识注入和其他负面影响。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02778", "html_url": "https://arxiv.org/abs/2507.02778", "title": "Self-Correction Bench: 揭示并解决LLM中的自我纠正盲区", "title_en": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs", "authors": "Ken Tsui", "background": "尽管大型语言模型（LLMs）已经成为一种变革性的技术，但它们仍然存在错误，并且可能会探索不具生产力的推理路径。自我纠正是可信赖的LLM所需的重要能力，尤其是对于自回归模型而言。尽管LLMs可以识别用户输入中的错误，但它们会表现出系统性的‘自我纠正盲区’——无法纠正它们自己输出中的相同错误。为系统研究这一现象，我们引入了Self-Correction Bench，这是一种具有控制错误注入的系统框架，可以在三个复杂性水平上测量这种现象。通过测试14个模型，我们发现在平均64.5%的情况下存在盲区。我们发现这种限制与训练数据组成有关：人类训练示例中主要展示的是无错误的响应，而不是错误校正序列，而奖励学习训练的模型则是通过结果反馈学习错误校正的。令人惊讶的是，简单地添加“等待”可以将盲区减少89.3%，这表明这种能力存在于模型中，只是需要激活。我们的工作揭示了当前LLMs的一项关键限制，并提供了提高其可靠性和可信度的潜在途径。", "innovation": "该研究引入了一种系统框架——Self-Correction Bench，用于在三个复杂性层次上通过控制性地注入错误来测量LLMs的自我纠正盲区现象。此外，研究发现简化的方法如在响应前添加“等待”可以显著减少盲区，暗示了这一能力的存在但需要被激活。这些发现揭示了当前LLMs的一个重要限制，并为进一步提高其可靠性提出了可能的方法。", "conclusion": "我们的工作揭示了当前大型语言模型中的关键限制，即自我纠正盲区，并提供了提高其可靠性及可信度的潜在途径。通过引入Self-Correction Bench，我们能够量化这一重要但之前未被充分重视的现象，并发现了一些改善模型自我纠正能力的方法。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02851", "html_url": "https://arxiv.org/abs/2507.02851", "title": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "title_en": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "authors": "Purbesh Mitra,Sennur Ulukus", "background": "最近的研究表明，通过使用群组相对策略优化（GRPO）算法进行强化学习（RL）训练，大型语言模型（LLMs）能够利用更多的思考/推理令牌来生成更好的响应。然而，LLMs在生成大量令牌的同时保持对先前生成令牌的关注，存在一个有限的令牌上下文大小限制，这是LLMs在处理任意数量令牌时进行推理的一个瓶颈。为超越这一限制，LLMs需要采用模块化思考策略，通过多轮思考进行推理。这篇论文针对这一问题提出了MOTIF方法，以生成多轮思考令牌，从而使模型能够利用额外的上下文大小进行思考。论文在Qwen2.5-3B-Instruct模型上进行了训练，并在MATH500和AIME2024基准测试中测试了其准确性。实验结果表明，与基于GRPO的训练方法相比，MOTIF分别在两个基准测试中表现出3.8%和3.3%的改进，仅需要使用15%的样本，显示了MOTIF的样本效率。", "innovation": "提出了一种名为MOTIF的RL训练方法，利用模块化思考策略在多轮中生成思考令牌，从而允许模型利用额外的上下文大小进行思考。MOTIF方法通过参数高效微调开源的Qwen2.5-3B-Instruct模型并在基准测试中验证了模型的准确性。结果展示出在保持样本效率的情况下，MOTIF方法显著提高了模型的推理性能。", "conclusion": "MOTIF通过参数高效微调方法训练开源模型，并在两个基准测试中验证了模型的准确性，进一步通过模块化思考策略在多轮中生成思考令牌，突破了LLMs上下文大小的限制，提高了模型的推理性能。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02744", "html_url": "https://arxiv.org/abs/2507.02744", "title": "通过Just Producible Difference (JPD) 门槛测量元音生产空间的颗粒度", "title_en": "Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens", "authors": "Peter Viechnicki", "background": "过去几十年的研究表明，人类元音生产的复杂而协调的发音运动在一定程度上受到控制机制的管理，这些机制的目标是听觉空间内的特定区域。在子音位水平上也已展现出了这种控制，但这种控制的具体准确性还不得而知。当前研究旨在通过询问两个元音刺激在听觉空间内需要相隔多远才能确保模仿是有差异的，来探索这一问题。这一距离被称为'刚刚可辨差异'（JPD）。这项研究使用元音模仿范式，首次测量了两组英语说话人在前元音生产中JPD的数值。JPD被估计为在F1 X F2空间中在14至51梅尔之间。这一发现对于言语生产中的短时记忆理论具有重要意义，也明确了人类元音系统的可能结构，设定了两元音音位在说话人共振频率空间中能有多近的理论下限，从而为观察到的元音音位数量和模式提供了心理物理解释。", "innovation": "该研究首次使用元音模仿范式测量了两组英语说话人在前元音生产中的JPD数值，为人类元音生产的研究提供了新的测量标准。", "conclusion": "JPD被估计为在F1 X F2空间中在14至51梅尔之间。这一发现对于言语生产中的短时记忆理论具有重要意义，也明确了人类元音系统的可能结构，设定了两元音音位在说话人共振频率空间中能有多近的理论下限，从而为观察到的元音音位数量和模式提供了心理物理解释。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01984", "html_url": "https://arxiv.org/abs/2507.01984", "title": "使用早期融合语言、视觉和社会特征的多模态虚假信息检测", "title_en": "Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features", "authors": "Gautam Kishore Shahi", "background": "在选举和危机期间，社交媒体上充斥着大量的错误信息。已有大量研究集中在文本或图像的错误信息检测上，但很少有研究探讨多模态特征组合，例如将文本和图像结合起来构建分类模型以检测错误信息。这项研究探讨了不同多模态特征组合的有效性，使用早期融合方法将文本、图像和社交特征结合起来构建分类模型。研究分析了1529条包含文本和图像的推文，这些推文来自新冠肺炎疫情期间和选举期间的Twitter（现在X）用户。", "innovation": "研究采用早期融合方法将文本、图像和社会特征结合起来进行多模态错误信息检测，使用无监督和有监督机器学习模型相结合的方法，相比单一模态模型和双模态模型，提高了15%的分类性能，增加了5%的性能。此外，研究还分析了虚假信息传播模式，基于错误信息推文及其传播者的特征进行分析。", "conclusion": "结合无监督和监督机器学习模型可以显著提高多模态错误信息检测的性能。早期融合方法可以有效地整合语言、视觉和社会特征，提高分类性能。根据错误信息推文及其传播者的特征分析了虚假信息的传播模式。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02799", "html_url": "https://arxiv.org/abs/2507.02799", "title": "推理模型全靠它吗？探究推理语言模型中的偏见", "title_en": "Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models", "authors": "Riccardo Cantini,Nicola Gabriele,Alessio Orsino,Domenico Talia", "background": "推理语言模型（RLMs）凭借其通过诸如链式思维（CoT）提示或推理痕迹微调等机制执行复杂多步推理任务的能力而引起关注。尽管这些能力有望提高可靠性，但它们对社会偏见鲁棒性的影响尚不明确。本文利用CLEAR-Bias基准，原本设计用于大型语言模型（LLMs），研究了RLMs在偏见诱发中的对抗鲁棒性。通过全面评估最先进的RLMs在多种社会文化维度上的表现，采用了LLM作为评估者的自动化安全性评分方法，并结合监狱破解技术评估内置安全机制的强度。研究旨在回答三个关键问题：（1）推理能力的引入如何影响模型的公平性和鲁棒性；（2）推理微调模型是否比依赖于推理过程中CoT提示的安全性更高；（3）针对偏见诱发的监狱破解攻击成功率随采用的推理机制变化而变化的幅度。结果揭示了推理能力与偏见安全性之间的复杂关系。令人惊讶的是，无论是通过CoT提示还是微调推理痕迹，具有明确推理能力的模型通常比没有此类机制的基础模型更容易受到偏见诱发的影响，表明推理可能无意中打开了新的刻板印象强化途径。推理启用的模型似乎比依赖于CoT提示的模型更安全，后者特别容易受到通过讲故事提示、虚构角色或奖励型指令进行的上下文重框攻击的影响。这些结果挑战了推理本身会自动提高鲁棒性的假设，强调了需要更多感知偏见的方法来设计推理模型.", "innovation": "本文利用CLEAR-Bias基准研究了推理语言模型（RLMs）在社会偏见对抗鲁棒性方面的表现。通过全面评估最先进的RLMs，并结合LLM作为评估者的自动化安全性评分方法和监狱破解技术评估内置安全机制的强度，提出了一种评估方法，有助于理解推理能力和偏见安全性之间的关系，并挑战了推理自动提高鲁棒性的假设，强调了需要更多偏见感知的方法来设计推理模型.", "conclusion": "研究发现，推理能力和偏见安全性之间存在复杂关系。具有明确推理能力的模型比基础模型更容易受到偏见诱发的影响，表明推理可能无意中打开新的刻板印象强化途径。推理启用模型相对安全，但依赖于链式思维提示的模型更容易受到上下文重框攻击。这些结果挑战了推理自动提高鲁棒性的假设，强调了需要更多的偏见意识来设计推理模型的方法。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01991", "html_url": "https://arxiv.org/abs/2507.01991", "title": "FinAI-BERT: 基于变压器模型在财务报告中进行AI披露的句子级检测", "title_en": "FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports", "authors": "Muhammad Bilal Zafar", "background": "人工智能在金融服务中的普及引发了对能够系统性检测公司披露中的AI相关内容的需求。现有的方法往往依赖关键词扩展或文档级别分类，但由于缺乏细节、解释性和鲁棒性不足，未能满足需求。本研究引入了FinAI-BERT，一种针对财务文本设计的分类器，能够通过对句子的级别分析来识别与AI相关的会计信息。", "innovation": "提出的模型是一种基于transformer的深度学习方法，用于细化分类AI在财务文件中的相关内容，并针对金融领域进行了调整。FinAI-BERT在金融年报中实现了99.37%的准确性与F1分数为0.993的高性能，超过了逻辑回归、朴素贝叶斯、随机森林和XGBoost等传统基线模型。此外，通过SHAP方法确保了模型的解释性，并通过偏差分析和稳健性检查验证了模型在不同长度的句子、对抗输入和时间样本上的稳定性。", "conclusion": "理论上，该研究推进了金融自然语言处理领域，采用了变压器架构实现细粒度、主题特定的分类；实践中，它提供了适用于分析师、监管者和学者的一种扩展性和透明度高的解决方案，用于监控贷款机构中AI的传播与表达。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02856", "html_url": "https://arxiv.org/abs/2507.02856", "title": "答案匹配在语言模型评估中优于选择题", "title_en": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation", "authors": "Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping", "background": "选择题基准长期以来一直是语言模型评估的有力工具，因为选择题的评分客观且易于自动化。然而，研究表明，流行的基准中的选择题通常可以在未看到问题的情况下通过简单的捷径来回答。这些捷径源于区分性评估的固有限制，这种评估不适用于评价模型自由形式的生成回答。直到最近，似乎没有可替代的选择题的可行方案，但研究表明这一状况已改变。研究提出了一种新的评估方法——答案匹配：将候选模型提供的问题没有选项，让它生成自由形式的回复，然后使用现代语言模型和参考答案来判断回复是否匹配参考答案。为了比较不同评估策略的有效性，作者对MMLU-Pro和GPQA-Diamond进行了标注，并获得了人工评分数据，测量了每种评估方法的一致性。研究发现，使用近期模型进行答案匹配即使是非常小的模型，也达到了近乎完美的一致性，甚至超出了人工评分间的一致性水平。相比之下，选择题评估和使用大型语言模型作为裁判但没有参考答案的评估与人工评分的吻合度较低。通过对模型自由形式回应进行评估，答案匹配方法不仅带来了理论上的改进，还显著改变了某些模型的排名。", "innovation": "研究引入了答案匹配的方法，将问题提供给候选模型生成自由形式的回复，再使用现代语言模型与参考答案进行匹配评估。这种方法解决了选择题评估固有的缺点，能够更准确地评价模型的生成能力，并且即使是小型模型也有很好的一致性表现。与选择题评估和大型语言模型作为裁判但没有参考答案的评估方法相比，答案匹配的表现更优，且与人工评分的一致性更高。此外，这种方法改变了某些模型的排名顺序，表明它不仅仅是一个理论上的优化，对实际评估具有重要影响。", "conclusion": "通过答案匹配方法进行的评估，在语言模型的评估中表现更优。与选择题进行评估相比，答案匹配不仅提高了评估的有效性，还由于其一致性和与人工评分的高匹配度，能够提供更可靠的排名。未来，研究建议评估生态系统应从选择题转向答案匹配这一新方法。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02833", "html_url": "https://arxiv.org/abs/2507.02833", "title": "Generalizing Verifiable Instruction Following", "title_en": "Generalizing Verifiable Instruction Following", "authors": "Valentina Pyatkin,Saumya Malik,Victoria Graf,Hamish Ivison,Shengyi Huang,Pradeep Dasigi,Nathan Lambert,Hannaneh Hajishirzi", "background": "当前的人工智能与人类交互的关键因素之一是语言模型或聊天机器人的精确遵循人类指令的能力。虽然现代最强的模型在满足这些指令方面仍有挑战，尤其是在面对具有特定输出约束的指令时，如“只能用是或否回答”或“至少提到‘Abrakadabra’三次”，研究发现大多数模型在这些可验证指令的能力上过度拟合了一套基准测试中的少量验证约束，而没有能力泛化到未见过的输出约束。“Generalizing Verifiable Instruction Following”旨在通过引入新基准IFBench来评估模型对58个新颖、多样和具有挑战性的验证外域约束的精确指令遵循泛化能力，并详细分析模型训练数据以提高精确指令遵循的泛化能力。研究指出，通过精心设计约束验证模块，强化学习结合可验证奖励（RLVR）显著提高了指令的遵循效果。", "innovation": "该研究通过引入新的基准IFBench来评估模型在58个新颖、多样的、具有挑战性的验证外域约束的精确指令遵循泛化能力。此外，研究还发现强化学习结合可验证奖励（RLVR）显著提高了指令遵循的效果，并开放了额外的新手标注训练约束和验证函数以及RLVR训练提示和代码供其他研究人员使用。", "conclusion": "研究证明引入新的基准IFBench和强化学习结合可验证奖励（RLVR）在提高模型对未经验证的指令输出约束的泛化能力方面是有效的，为解决人工智能与人类交互中的精准指令遵循问题提供了新的方法和方向。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "Energy-Based Transformers are Scalable Learners and Thinkers", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "近年来，如同人类系统2思考的推理阶段计算技术被用于提高模型性能，但大多数现有方法存在特定模态性、特定问题性和额外监督需求等局限性。因此，作者提出一个研究问题：是否有可能将这些系统2思考方法泛化，并发展仅基于无监督学习的模型来学习思考？", "innovation": "作者提出了一种新的能源基模型（EBMs）Energy-Based Transformers (EBTs)，通过显式验证输入和候选预测之间的兼容性，并将预测问题重新定义为能量最小化的优化问题。EBTs在训练期间以更快的速度扩展，并在推理时表现出比主导的Transformer++方法更好的性能。此外，EBTs在下游任务中也展示了更好的泛化能力，表明它们比现有方法更具潜力。", "conclusion": "EBTs作为一个新的扩展模型学习和推理能力的新范式，展现了其在训练和推理中的优越性。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02000", "html_url": "https://arxiv.org/abs/2507.02000", "title": "为什么多兴趣公平性很重要：基于超图对比多兴趣学习的公平对话推荐系统", "title_en": "Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System", "authors": "Yongsen Zheng,Zongxuan Xie,Guohua Wang,Ziyao Liu,Liang Lin,Kwok-Yan Lam", "background": "推荐系统中的不公平问题是已知的挑战，通常会导致基于性别、种族、年龄或受欢迎程度等属性的用户或项目受到不公平对待。尽管一些方法已经开始在离线或静态情况下改进公平性推荐，但不公平的问题经常会随着时间加剧，导致马太效应、信息茧房和回声室等严重问题。因此，现有方法未能有效解决这些问题，并且对动态和交互式对话推荐系统（CRS）中的多兴趣公平性分析不足。", "innovation": "本文提出了一种基于超图对比多兴趣学习的新框架——动态交互式对话推荐系统中的HyFairCRS。该框架通过对比学习建立多样化的超图来捕捉广泛的用户兴趣，并利用这些兴趣在对话中生成有 informativeness 的响应，确保在动态用户-系统反馈循环中的公平项目预测。HyFairCRS 的实验结果显示，在两个基于对话的推荐系统数据集上，它能够达到新的SOTA性能并有效地缓解不公平性问题。提供的代码可从该网址访问：this https URL", "conclusion": "HyFairCRS 在多种场景下实现了多兴趣公平性推荐，有效提高了性能并缓解了不公平现象，同时为未来的研究提供了新的方法和思路。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02004", "html_url": "https://arxiv.org/abs/2507.02004", "title": "STELLA：生物医药研究的自我进化大语言模型代理", "title_en": "STELLA: Self-Evolving LLM Agent for Biomedical Research", "authors": "Ruofan Jin,Zaixi Zhang,Mengdi Wang,Le Cong", "background": "生物医学数据、工具和文献的快速增长已经导致了一个碎片化的研究环境，这一环境超越了人类的专业知识。虽然人工智能（AI）代理提供了一个解决方案，但它们通常依赖于静态的手动整理工具包，这限制了它们的适应能力和扩展能力。", "innovation": "介绍了STELLA，这是一种自我进化的AI代理，旨在克服上述限制。STELLA采用了一个多重代理架构，通过两种核心机制自主提升其自身能力：一个进化的模板库用于推理策略，以及一个动态工具海洋，随一个工具创造代理自动发现和整合新的生物信息学工具。这使STELLA能够从经验中学习。我们展示了STELLA在一系列生物医学基准测试中达到了最先进的准确率，得分分别为：《人类的最后一课：生物医药》26%，《LAB-Bench：DBQA》54%，《LAB-Bench：LitQA》63%，其性能优于领先模型多达6个百分点。更重要的是，我们展示了其性能随着经验的积累而系统性地提高；例如，在《人类的最后一课：生物医药》基准测试上的准确性几乎加倍，随着试验次数的增加。STELLA代表了朝着能够学习和成长的AI代理系统迈出的重要一步，这种系统能够动态地扩展其专业知识，加速生物医药发现的步伐。", "conclusion": "STELLA代表了一种重要的进步，其能够学习和成长，动态地扩展其专业知识，加速生物医药发现的步伐，具有显著的提升和改进性能的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02176", "html_url": "https://arxiv.org/abs/2507.02176", "title": "分析和改进语音合成中的说话人相似性评估", "title_en": "Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis", "authors": "Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi", "background": "模型化声音身份具有挑战性，因为它具有多维的特性。在生成语音系统中，通常使用自动说话人验证（ASV）嵌入来评估身份，主要目的是区分不同说话人，而不是具体刻画身份特征。这篇论文研究了这些表示中捕捉到的声音哪些方面。研究发现，广泛使用的ASV嵌入主要集中在诸如音色和音调范围等静态特征上，而忽视了节奏等动态元素。此外，还识别了一些混淆因素，这些因素影响了说话人相似性测量的可靠性，并提出了缓解策略。为了填补这些空白，论文提出了一种新的度量方法U3D，该方法用于评估说话人的动态节奏模式。这项工作完善了评估说话人身份一致性在日益先进的语音克隆系统的挑战中所面临的难题。我们已将代码公开发布。", "innovation": "论文提出了一个新的度量方法U3D，专门用于评估说话人的动态节奏模式。这种方法填补了广泛使用的ASV嵌入在捕捉动态声音特征方面的空白，同时缓解了可能影响说话人相似性测量的因素。这项工作对于在更好的语音克隆系统中评估说话人身份一致性具有重要意义。", "conclusion": "论文的工作通过提出U3D，进一步完善了在不断改进的语音克隆系统背景下评估说话人身份一致性的挑战。论文不仅公开了代码，还对说话人相似性评估提出了新的理解，并提供了改进的策略。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02200", "html_url": "https://arxiv.org/abs/2507.02200", "title": "ESTR-CoT：带有链式思考推理的可解释且准确的事件流场景文本识别", "title_en": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning", "authors": "Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang", "background": "基于事件流的场景文本识别近年来成为研究热点，相较于广泛使用的RGB摄像头，在低光照、快速移动等极具挑战性的场景中表现更佳。现有工作主要采用端到端的编码器-解码器架构或强化语言模型来提升识别效果，但仍然面临缺乏可解释性和弱上下文逻辑推理能力的挑战。", "innovation": "本文提出了一种基于链式思考推理的新型端到端事件流场景文本识别框架，名为ESTR-CoT。该框架采用视觉编码器EVA-CLIP（ViT-G/14）将输入的事件流转换为标记，并利用Llama分词器编码给定的生成提示。通过Q-former将视觉标记对准预训练的大语言模型Vicuna-7B同时输出答案和链式思考（CoT）推理过程。此外，还提出了一个大规模的CoT数据集，通过三阶段处理（生成、润色和专家验证）进行训练，为后续基于推理的大型模型的发展提供了坚实的数据基础。实验结果全面验证了该框架的有效性和可解释性。", "conclusion": "在三个事件流STR基准数据集（EventSTR、WordArt*、IC15*）上的广泛实验充分证明了提出框架的有效性和解释性。源代码和预训练模型将会发布。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02380", "html_url": "https://arxiv.org/abs/2507.02380", "title": "JoyTTS：基于大语言模型的语音克隆语音聊天机器人", "title_en": "JoyTTS: LLM-based Spoken Chatbot With Voice Cloning", "authors": "Fangru Zhou,Jun Zhao,Guoxin Wang", "background": "该论文介绍了一种端到端的语音聊天机器人JoyTTS，它结合了大语言模型（LLM）和文本转语音（TTS）技术，具有语音克隆能力。该系统基于开源的MiniCPM-o和CosyVoice2模型，并在2000小时的对话数据上进行了训练。", "innovation": "JoyTTS的创新之处在于其结合了大语言模型和TTS技术，并具备语音克隆能力。此外，它还提供了完整的训练代码，以方便社区进一步开发和优化。", "conclusion": "在测试机器器seed-tts-zh上的测试结果显示，JoyTTS的SS（讲话相似度）得分为0.73，词错误率（WER）为5.09。完整的代码、模型以及训练和推理脚本可以在指定的网址获取。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02135", "html_url": "https://arxiv.org/abs/2507.02135", "title": "剖析移动电压频率自动调节 governor 对大语言模型推理性能与能效的影响", "title_en": "Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency", "authors": "Zongpu Zhang,Pranab Dash,Y. Charlie Hu,Qiang Xu,Jian Li,Haibing Guan", "background": "大语言模型（LLMs）正越来越多地被集成到运行在数十亿台移动设备上的各种应用和服务中。然而，在资源有限的移动设备上部署这些高耗计算、高耗内存和高耗能的LLM模型面临着显著挑战。尽管现在移动设备上常使用的LLM框架包含CPU、GPU和内存三种耗电组件，但这些用于CPU、GPU和内存的现代移动设备中的优化DVSF（动态电压和频率调整）管理器仍独立运作，彼此之间缺乏协调，导致在LLM推理过程中能效降低等问题。当前研究通过测量SOTA LLM框架在移动电话上的能效，揭示了三者的独立管理器导致了一定程度上的低效问题。", "innovation": "本研究首先分析了在移动设备上不同频率组合下的LLM能效，并发现现有管理器的独立性导致了相当大的能效损失。研究进一步通过深入测量研究，揭示了这些独立管理器之间的复杂相互作用导致了推理过程中的低效。基于这些洞察，提出了FUSE — 一种统一的能源感知治理者，旨在优化移动设备上LLM推理过程中的能效。研究使用ShareGPT数据集证明了FUSE能够将首次生成令牌和每个输出令牌的延迟分别减少7.0%-16.9%和25.4%-36.8%，同时保持相同的单位令牌能耗，对于各种移动LLM模型均有效。", "conclusion": "研究通过FUSE展示了对移动设备上LLM推理过程的能效优化。FUSE设计使得在相同能耗情况下减少了首次生成令牌和每个后续生成令牌的时间，证明了通过协调管理和优化移动设备上LLM推理过程中的能源使用可以显著提高效率。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02287", "html_url": "https://arxiv.org/abs/2507.02287", "title": "透过绿色：基于文本的分类与企业绿色专利的回报", "title_en": "Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents", "authors": "Lapo Santarlasci,Armando Rungi,Antonio Zinilli", "background": "本文介绍了通过自然语言处理（NLP）识别“真正”的绿色专利，这些专利来自官方支持文件。研究基于之前文献中被分类为绿色的约1240万项专利进行训练。通过训练一个简单的神经网络，扩展基线词典，增加与环境技术相关的表达向量表示。实验证明，真正意义上的绿色专利仅占之前文献中分类为绿色专利的大约20%。本文还展示了不同技术类别的异质性，并检测到真正绿色专利比后续发明引用略少。第二部分探讨了企业绿色专利与欧盟企业层面财务报表指标的关系。研究控制了反向因果关系后发现，拥有至少一项真正绿色专利的公司更具销售力、市场份额和生产力。如果只分析高新颖性的真正绿色专利，则发现其能够带来更高的利润。这些发现强调了使用文本分析来衡量更细粒度的专利分类对于不同领域政策制定的重要性。", "innovation": "基于文本的自然语言处理技术被应用于识别真正绿色专利；通过简单的神经网络开发了一种新方法，扩展基线词典，通过向量语言模型评估相关表达；首次系统性研究了真正绿色专利与企业财务指标的关系；使用高新颖性的真正绿色专利进一步验证了其对企业财务回报的影响明显。", "conclusion": "研究发现，真正绿色专利是重要的创新资产，对企业销售、市场份额和生产力有积极影响。高新颖性真正绿色专利还能带来更高的利润。这强调了利用文本分析进行专利精细分类的重要性，对于不同领域的政策制定具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02087", "html_url": "https://arxiv.org/abs/2507.02087", "title": "评估大语言模型在招聘决策中的机遇与挑战", "title_en": "Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions", "authors": "Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia", "background": "大型语言模型（LLMs）在招聘中有望简化候选人筛选流程，但同时也引发了关于准确性和算法偏差的重大担忧，尤其是在缺乏足够保障的情况下。本文研究了几种前沿的基础LLM（包括来自OpenAI、Anthropic、Google、Meta和DeepSeek的模型），并将它们与我们专有的针对招聘领域的自有定制模型（Match Score）进行了比较，用于应聘者匹配。实验使用了约10,000个现实生活中的应聘者-职位对数据集，评估了各模型的预测准确性和公平性。研究结果表明，即使在准确性方面，Match Score也显著超过了通用的大语言模型，并且在不同性别、种族和交叉子群体的公平性方面表现更加均衡。这表明定制模型可以更好地规避预训练时可能引入的社会偏见，而通用模型则可能积累更多的偏差。这一发现突显了在高风险领域如招聘中部署AI时，定制模型和偏见审计的重要性。", "innovation": "本文对多种前沿的大型语言模型进行了基准测试，并将它们与自有的领域特定招聘模型（Match Score）进行了比较。实验结果显示，在预测准确性和公平性方面，自有的模型表现更佳。特别是，Match Score在种族公平性方面达到了0.957的最小影响比，而最佳的大语言模型在这一方面的表现仅为0.809或更低。研究指出，预训练偏见可能导致没有足够保障的大语言模型在招聘场景中传播社会偏见，而定制的监督模型则可以更有效地缓解这些偏见。", "conclusion": "研究结果强调了在高风险领域如招聘中部署AI时，定制模型和公平性审计的重要性。不应依赖现成的大语言模型，而应在广泛公平性的保障下进行使用。此外，实验结果表明，准确性和公平性在招聘中是可以兼得的，精心设计的算法可以同时实现良好的招聘准确性和公平性结果。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02737", "html_url": "https://arxiv.org/abs/2507.02737", "title": "前沿大规模语言模型中早期隐藏能力的迹象", "title_en": "Early Signs of Steganographic Capabilities in Frontier LLMs", "authors": "Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner", "background": "监控大型语言模型（LLM）的输出对于减少滥用和失序的风险至关重要。然而，LLM可以通过隐写术来规避监控：在表面上无害的生成中编码隐藏信息。本文研究了当前最前沿的LLM的隐写术能力，以更好地理解它们所带来的风险。我们重点关注两种类型的隐写术：传递编码消息和执行编码推理。我们发现，当前模型在标准条件下无法在其输出中无监测地编码短消息。然而，通过提供额外的功能（如使用未监控的草稿区和协调使用的编码方案），它们可以成功执行此操作。我们还发现了模型在简单状态跟踪问题中可以执行基本编码推理的早期迹象，包括与自身和预定义方案（包括如十六进制之类的编码方案）进行推理。尽管如此，它们很难在盖任务中隐秘地隐藏推理以蒙骗检测器。总体而言，我们的研究结果表明，当前的LLM显示出初期的隐写术能力。尽管这些能力目前可能不足以绕过精心设计的监控器，但未来可能会发生变化。", "innovation": "本文研究了前沿的大规模语言模型的隐写术能力，特别关注两种类型的隐写术：传递编码消息和执行编码推理。研究发现，尽管当前模型无法在其输出中无监测地编码短消息，但通过提供额外的功能，它们可以在某些条件下成功执行编码推理。这项研究填补了该领域的空白，为理解大规模语言模型的隐写术风险提供了重要见解。", "conclusion": "当前的大规模语言模型显示出初期的隐写术能力。尽管这些能力目前可能不足以绕过精心设计的监控器，但未来可能会发生变化。这对监控系统的开发者和使用者提出了新的挑战和警示。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02618", "html_url": "https://arxiv.org/abs/2507.02618", "title": "大型语言模型中的战略智能：进化博弈理论的证据", "title_en": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory", "authors": "Kenneth Payne,Baptiste Alloui-Cros", "background": "论文探讨了大语言模型（LLMs）是否可以被视为一种新的战略智能形式，能够在竞争环境中进行推理。背景提到迭代囚徒困境（IPD）作为决策研究的一种模型已有很长的历史，但之前尚未有人将实际的AI公司（如OpenAI、Google和Anthropic）的最新策略进行竞标。通过改变每次比赛的终止概率（“未来的影子”），引入复杂性和不确定性，使记忆成为关键挑战。论文展示了通过这种设置，LLMs表现出高度的竞争性，在复杂的生态中生存甚至壮大。此外，它们还展现了独特的和持久的战略印记，这些印记在特定竞争环境中有显著的影响表现。", "innovation": "创新之处在于首次系列进行进化IPD比赛，对比了传统的策略（如“以牙还牙”、“决斗威慑”）与来自顶级AI公司的当代AI代理。通过实验设置，证实了LLMs具备高度的战略智能，并对其背后的战略思维进行了深入分析，将经典的博弈论与机器心理学相结合，揭示了在不确定情况下算法决策的丰富细节。", "conclusion": "研究结果表明，LLMs在战略智能上有显著表现，具体策略随竞争环境变化而不同。它们能够推理时间范围及对手策略，这对于其决策至关重要。这项工作扩展了经典博弈理论和机器心理的研究边界，为理解算法在不确定性环境下的决策提供了详细视角。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02652", "html_url": "https://arxiv.org/abs/2507.02652", "title": "解耦规划与执行：一种用于深度搜索的分层推理框架", "title_en": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search", "authors": "Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou", "background": "在现实世界中的信息检索场景中，复杂的信息需求要求能够进行深入推理和在多种来源中综合知识。传统的检索增强生成（RAG）管道难以有效应对这一挑战。当前基于推理的方法存在根本性的局限性，即它们使用单一模型处理高层次规划和详细执行，这导致推理效率低下且缺乏可扩展性。", "innovation": "本文提出了HiRA，一种分层框架，将战略规划与专门执行分离。该方法将复杂的搜索任务分解为专注的子任务，并将每个子任务指派给具有外部工具和推理能力的领域专用代理，通过结构化的集成机制协调结果。这种分离防止了执行细节干扰高层次推理，同时允许系统利用不同类型的专门领域知识。实验结果表明，HiRA在四个复杂的跨模态深度搜索基准中显著优于最先进的RAG和基于代理系统，展示了分离规划和执行对于多步骤信息搜索任务的有效性。", "conclusion": "研究表明，HiRA在答案质量和系统效率方面均优于现有技术，突显了解耦规划和执行对于多步骤信息搜索任务的有效性。我们的代码可在以下地址获取：[这里](this https URL)"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02666", "html_url": "https://arxiv.org/abs/2507.02666", "title": "ASDA: 音频频谱差异注意力机制用于自监督表示学习", "title_en": "ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning", "authors": "Junyu Wang,Tianrui Wang,Meng Ge,Longbiao Wang,Jianwu Dang", "background": "近年来，自监督表示学习在音频表示学习中取得了显著进步，标准Transformer架构已成为主流方法，但由于其注意力机制往往会分配部分注意力权重给无关信息，这可能损害了模型的辨别能力。针对这一问题，本文提出了一种差分注意力机制，通过结合双softmax操作和适当调整的差分系数，有效缓解了无效注意力分配的问题。实验结果表明，我们的ASDA模型在多个基准测试中均取得了最先进的性能，包括音频分类（AS-2M上的49.0% mAP，AS20K上的41.5% mAP），关键词识别（SPC-2上的98.3%准确率）和环境声音分类（ESC-50上的96.1%准确率），这些结果突显了ASDA在音频任务中的有效性，为其更广泛的应用提供了可能。", "innovation": "我们提出了差分注意力机制（ASDA），通过结合双softmax操作和适当调整的差分系数，有效缓解了标准Transformer架构在自监督表示学习中由于注意力机制分配给无关信息导致的模型辨别能力下降问题。与传统方法相比，ASDA能更有效地分配注意力权重，从而提升模型的性能。", "conclusion": "实验结果表明，我们的ASDA模型在多个基准测试中表现优异，取得了最先进的性能。这使得ASDA在音频任务中显示出显著的优势，为未来的广泛应用奠定了基础。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02768", "html_url": "https://arxiv.org/abs/2507.02768", "title": "DeSTA2.5-Audio: 向自我生成跨模态对齐的一般用途大型音频语言模型迈进", "title_en": "DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment", "authors": "Ke-Han Lu,Zhehuai Chen,Szu-Wei Fu,Chao-Han Huck Yang,Sung-Feng Huang,Chih-Kai Yang,Chee-En Yu,Chun-Wei Chen,Wei-Chih Chen,Chien-yu Huang,Yi-Cheng Lin,Yu-Xiang Lin,Chi-An Fu,Chun-Yi Kuan,Wenze Ren,Xuanjun Chen,Wei-Ping Huang,En-Pei Hu,Tzu-Quan Lin,Yuan-Kuei Wu,Kuan-Po Huang,Hsiao-Ying Huang,Huang-Cheng Chou,Kai-Wei Chang,Cheng-Han Chiang,Boris Ginsburg,Yu-Chiang Frank Wang,Hung-yi Lee", "background": "近期的大型音频语言模型（LALMs）通常通过在人工标注或通过大型语言模型生成的大规模音频指令数据集上进行训练来增强大型语言模型（LLMs）的听觉能力。然而，这些方法通常会出现灾难性遗忘现象，即牺牲了LLMs原有的语言能力。这一背景下，该研究重新审视数据构建流程，提出了DeSTA策略，通过使主干语言模型生成自己的训练目标，来保持语言能力和建立有效的音频-文本对齐，从而实现零样本泛化，无需任务特定的调整。", "innovation": "该研究提出了DeSTA策略，通过使主干语言模型生成自己的训练目标，而非依赖人工标注数据集或通过LLM生成的数据集。这种方法既保留了语言模型原有的语言能力，又建立了有效的音频-文本对齐，进而提高了模型在各种语音和音频任务上的零样本泛化能力。研究还构建了包含500万训练样本的DeSTA-AQA5M数据集，并在多个音频-语言基准测试中展示了优于或达到最新技术水平的结果。", "conclusion": "研究强调了精心设计的数据构建流程对于开发大型音频语言模型的重要性，并提供了构建稳健的、具有普遍用途的大型音频语言模型的实际见解。自我生成的策略在听觉感知和指令跟随能力方面表现出色，超越了广泛采用的数据构建和训练策略。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02790", "html_url": "https://arxiv.org/abs/2507.02790", "title": "从长视频到吸引人的短视频：具有多模态叙事理解的人类启发式视频编辑框架", "title_en": "From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding", "authors": "Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu", "background": "随着在线视频内容，特别是短视频平台的快速增长，有效视频剪辑技术的需求日益增加。当前的自动化编辑方法主要依赖于转写文本线索和端到端的段落选择，往往忽视了丰富的视觉上下文，导致输出不连贯。这个问题促使研究者寻求新的解决方案来改善自动编辑的效果。", "innovation": "本文提出了一种人类启发式的自动视频编辑框架（HIVE），它利用多模态叙事理解来解决现有方法的局限性。该框架结合了角色提取、对话分析和多模态大语言模型的叙事总结，实现了对视频内容的全面理解。此外，通过场景级别的分割和分解编辑过程为三个子任务：亮点检测、开头/结尾选择以及无关内容的修剪，进一步增强了连贯性。", "conclusion": "实验结果表明，本文提出的方法在通用编辑任务和广告导向编辑任务中的表现都优于现有的基准方法，显著缩小了自动编辑视频和人类编辑视频的质量差距。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02212", "html_url": "https://arxiv.org/abs/2507.02212", "title": "SciGA：学术论文中图形摘要设计的全面数据集", "title_en": "SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers", "authors": "Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi", "background": "图形摘要（GAs）在科学论文中起着关键作用，用于视觉传达研究的关键发现。尽管最近的研究越来越多地将图1等图表作为实际的GAs纳入其中，但它们对科学交流的潜在影响仍然未被充分探索。此外，有效设计GAs需要高级可视化技能，这为它们的广泛应用设置了一道障碍。为了应对这些挑战，我们介绍了一个名为SciGA-145k的大规模数据集，该数据集包括约145,000篇科学论文和约114万幅图表，旨在支持GA选择和推荐，以及促进自动化GA生成的研究。作为GA设计支持的初步步骤，我们定义了两项任务：1）在同一论文内推荐图形摘要，即确定哪些图表适合成为GA；2）跨论文推荐图形摘要，从其他论文中检索GA以激发新GA的创作。我们还提供了这些任务的基本基准模型，并提出了一种新的推荐度量标准——置信度调整的top-1真实比例（CAR），以提供模型行为的细致分析。CAR解决了传统基于排名的度量标准的局限性，它考虑了在同一论文中可能存在多个适合作为GA的图表的情况，而不只是明确标注的GA。通过统一这些任务和度量标准，SciGA-145k为推进视觉科学交流打下了基础，并为科学领域的AI开发做出了贡献。", "innovation": "我们构建了一个名为SciGA-145k的数据集，集成了约145,000篇科学论文和约114万幅图表，专注于GA的选择和推荐，以及促进自动化GA生成的研究。我们定义了两项关键任务：在同一论文内推荐GA和从其他论文中推荐GA，并提供了基准模型。此外，我们创新性地提出了一种新的推荐度量标准——置信度调整的top-1真实比例（CAR），以更细致地分析模型行为。这些改进有助于提高视觉科学交流的效果，并促进了AI在科学领域的应用与发展。", "conclusion": "SciGA-145k的建立为视觉科学交流的基础研究提供了一个坚实的基础，并为开发基于AI的科学解决方案做出了贡献。通过统一设计和支持GA的任务和度量标准，SciGA-145k有助于提升科学论文的可视性，促进了科学知识的广泛传播和理解。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02659", "html_url": "https://arxiv.org/abs/2507.02659", "title": "OmniDraft: 一种跨词汇在线自适应草稿器，用于设备上的推测性解码", "title_en": "OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding", "authors": "Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang", "background": "当前的推测性解码方法通常需要一个小型高效的代理模型，它是预训练或脱机精炼到特定目标模型系列。然而，在线部署时有两个主要挑战：1）目标模型与代理模型不兼容；2）期望减少延迟并实时改进。因此，有必要提出一种统一框架，允许单一代理模型与任何目标模型操作，并能动态适应用户数据。", "innovation": "本工作提出了OmniDraft，这是一种集成框架，它可以实现一个单一代理模型与任何目标模型的兼容，并能够动态适应用户数据。OmniDraft通过引入混合n-gram在线缓存和混合精炼，解决了代理模型和目标模型之间的跨词汇不匹配问题；并通过自适应代理模型技术进一步提高了解码速度。OmniDraft特别适合于设备上的LLM应用程序，这些应用程序重视模型成本、效率和用户自定义。", "conclusion": "本研究展示了OmniDraft框架在数学推理、编程和文本生成任务中的在线学习能力。OmniDraft使得小型的Llama-68M模型能够与Vicuna-7B、Qwen2-7B和Llama3-8B等多种目标模型进行推测性解码，同时提供了高达1.5-2倍的解码速度提升。这一框架强调了需要解决上述挑战，并推动了‘一个数据准备器适用于所有’的理念。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02834", "html_url": "https://arxiv.org/abs/2507.02834", "title": "ExPO：通过自我解释引导的强化学习解锁困难的推理", "title_en": "ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning", "authors": "Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi", "background": "近年来，大型语言模型的进步主要依靠基于奖励或偏好信号的强化学习( RL)样后训练，这种方法通过优化模型输出来提高推理能力。GRPO风格的方法通过使用基于结果的验证器进行自我生成的样本标签来实施这一点。然而，这些方法高度依赖模型初始生产积极样本的能力，并主要仅限于在已经知道的问题上进行改进，而无法解决模型开始时未能解决的问题。这种限制在早期强化学习训练和挑战性的推理任务中特别突出，因为在此类任务中产生的积极样本可能较少。为了解锁这些环境下的推理能力，模型需要探索超出其当前输出分布的新推理路径。这种探索需要访问足够的良好积极样本来指导学习。虽然专家演示看似是一个自然的解决方案，但我们发现它们在RL后训练中往往无效。因此，我们发现有效的积极样本应具有两个关键特性：它们应在当前策略下出现的概率较高，并且能够增加模型预测正确答案的概率。基于这些见解，我们提出了一个简单且模块化的框架Self-Explanation Policy Optimization (ExPO)，通过基于地面真值答案进行条件生成来产生这样的样本。ExPO能够促进高效探索并引导模型产生与专家策略更一致的推理路径，同时确保比其自身（不正确）样本更高的质量。实验表明，ExPO在如MATH级别5等挑战性环境中，可以提高学习效率和最终性能，超越基于专家演示的方法，因为模型在此处最初遇到的最大困难。", "innovation": "提出了一个简单且模块化的框架Self-Explanation Policy Optimization (ExPO)，通过基于地面真值答案进行条件生成来产生有效积极样本，使得模型能够进行更有效的探索，并产生更一致于其策略的推理路径。结果显示，ExPO在解决困难推理任务时表现出更高的学习效率和性能。", "conclusion": "ExPO通过引导模型生成基于正确答案的积极样本，克服了早期直接使用专家演示方法的局限性，改进了模型在困难推理任务中的性能和学习效率，相对于基于专家演示的方法，在MATH级别5等挑战性环境中能够取得更好的结果。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02846", "html_url": "https://arxiv.org/abs/2507.02846", "title": "法律要求从法律向规范翻译", "title_en": "Legal Requirements Translation from Law", "authors": "Anmol Singhal,Travis Breaux", "background": "软件系统必须遵守法律规范，这是一个资源密集型的任务，尤其对于缺乏专门法律专家的小型企业。从法律文本中提取元数据以提取软件所需的法律要求，是确保合规的关键步骤。然而，这是一项繁琐的任务，由于法律文本的长度和复杂性。尽管之前的研究已尝试通过自动方法从法律文本中提取结构化和语义元数据，但仍存在关键限制：这些方法没有考虑这些元数据类型相关属性之间的相互作用，且依赖手动标记或启发式驱动的机器学习，这在新文档上的泛化表现不佳。", "innovation": "本文提出了一种基于文本蕴含和上下文学习的方法，自动生成法律文本的可编码和可执行的规范表示，体现为Python代码。通过手动设计的Python类结构实例化此表示，这是一种领域特定的元模型，捕捉结构化和语义法律元数据及其相互关系。此设计减少了对大量手动标记数据集的需求，并提高了对未知法规的适用性。研究表明，我们的方法在13个美国州的数据泄露通知法中达到约89.4%的测试案例通过率，以及82.2%的精确度和88.7%的召回率，", "conclusion": "本文提出的方法通过自动生成法律文本的规范表示，减少了数据标记需求并提高了对未知法规的适用性，从而改进了软件合规性中的法务要求提取任务。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02841", "html_url": "https://arxiv.org/abs/2507.02841", "title": "StepHint：多层次逐步提示增强强化学习以进行推理", "title_en": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason", "authors": "Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan", "background": "当前的强化学习与可验证奖励（RLVR）方法面临两个重要挑战：near-miss奖励问题，导致即使是正确的推理过程也可能因小错误而失效，极大地影响了训练效率；以及探索停滞问题，模型倾向于停留在自身的“舒适区”，缺乏探索更有效替代方案的动力。", "innovation": "StepHint是一种新颖的RLVR算法，采用多层次逐步提示帮助模型更有效地探索解决方案空间。它生成来自更强大模型的有效推理链，并使用自适应分区方法将这些链划分为推理步骤。通过提供逐步提示，StepHint减轻了near-miss奖励问题，提高了训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使其能够超越“舒适区”，减轻探索停滞问题。StepHint在六个数学基准测试中表现优于其他竞争性的RLVR增强方法，并在离域基准测试中表现出色，超越了基线方法。", "conclusion": "StepHint通过多层次逐步提示在强化学习中增强了推理能力，解决了当前RLVR方法的两个重要问题，并在多个基准测试中表现出优异的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.08010", "html_url": "https://arxiv.org/abs/2311.08010", "title": "通过预测不确定性教师学习和学生-学生协作学习提高远程监督命名实体识别的鲁棒性", "title_en": "Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning", "authors": "Shuzheng Si,Helan Hu,Haozhe Zhao,Shuang Zeng,Kaikai An,Zefan Cai,Baobao Chang", "background": "远程监督命名实体识别（DS-NER）在实际场景中被广泛应用，能够通过现有知识库和文本片段匹配实体从而有效减轻标注负担，但同时会遭受标签噪声的影响。近期工作尝试采用教师-学生框架逐步细化训练标签并提高整体鲁棒性，但这些教师-学生方法实现效果有限，因为教师网络的欠校准导致错误的伪标签样本被生成，导致误差传播。", "innovation": "提出不确定性感知的教师学习（Uncertainty-Aware Teacher Learning），利用预测不确定性减少自我训练阶段的错误伪标签数量；学生-学生协作学习，允许两个学生网络之间传递可靠标签，而不是盲目依赖所有教师的伪标签，进一步实现对错误标记样本的全面探索，而非仅过滤不可靠的伪标签样本。", "conclusion": "在五个DS-NER数据集上评估了所提出的方法，结果显示该方法优于最先进的DS-NER方法。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02858", "html_url": "https://arxiv.org/abs/2507.02858", "title": "需求获取跟进问题生成", "title_en": "Requirements Elicitation Follow-Up Question Generation", "authors": "Yuchen Shen,Anmol Singhal,Travis Breaux", "background": "访谈是广泛用于提取需求以收集软件系统相关方需求、偏好和期望的技术。有效的访谈需要具备技能的访谈者能够实时提出适当的问题，但面临如不熟悉领域、过大的认知负担和信息过载等问题，这些都会影响人类处理访谈对象言语的能力。最近，大型语言模型（LLMs）在多个自然语言处理任务中表现出最先进的性能，包括文本摘要和蕴含。为了支持访谈者，研究利用GPT-4o框架，构建基于常见访谈者错误类型的模型来在需求获取过程中生成跟进问题，并描述了根据访谈者言语生成问题的方法。", "innovation": "研究表明，LLMs生成的问题在清晰度、相关性和信息性方面与人类撰写的问题不相上下。当引导LLM生成问题时，即基于常见错误类型，LLMs生成的问题优于人类撰写的问题。这突显了使用LLMs帮助访谈者改进需求获取访谈的真实时质量的潜力。", "conclusion": "进行了两个控制实验：一个是评估LLM生成和人撰写的问题，另一个评价引导生成的问题。结果表明，无论是哪种实验，LLM生成的问题都与人类撰写的问题相当，在清晰度、相关性和信息性方面无劣，且在基于常见错误类型引导时，LLM生成的问题表现更优。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02844", "html_url": "https://arxiv.org/abs/2507.02844", "title": "图像驱动背景注入的视觉上下文攻击：用图像为中心的漏洞利用破解MLLMs", "title_en": "Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection", "authors": "Ziqi Miao,Yi Ding,Lijun Li,Jing Shao", "background": "随着强大的视觉语言能力的出现，多模态大型语言模型（MLLMs）展现了在实际应用中的巨大潜力。然而，视觉模态所展示的安全弱点给在开放世界环境中的部署带来了重大挑战。最近的研究通过将有害的文本语义编码到视觉输入中，成功诱导目标MLLMs产生有害响应，但这些方法通常使视觉模态作为触发不安全行为的手段，缺乏现实场景中的语义清晰性和现实性。", "innovation": "本文定义了一种新的攻击场景——视觉为中心的漏洞利用攻击（Visual-centric Jailbreak），其中视觉信息作为构建完整且现实的漏洞利用场景的必要组成部分。在此基础上，提出了一种名为VisCo（视觉上下文）的攻击方法，该方法通过四种不同的视觉策略生成上下文对话，并在必要时动态生成辅助图像，以构建视觉为中心的漏洞利用场景。VisCo还通过自动毒性遮蔽和语义精炼，生成最终攻击提示，有效地触发了目标黑色盒MLLMs有害响应。", "conclusion": "VisCo 在MM-SafetyBench对GPT-4o的攻击中，达到了4.78的毒性评分和85%的成功率，显著优于基线，基线的毒性评分仅为2.48和22.2%的成功率。完整代码已发布。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.13808", "html_url": "https://arxiv.org/abs/2410.13808", "title": "De-mark: 在大型语言模型中移除水印", "title_en": "De-mark: Watermark Removal in Large Language Models", "authors": "Ruibo Chen,Yihan Wu,Junfeng Guo,Heng Huang", "background": "水印技术提供了一种有希望的识别机器生成内容的方法，通过将隐蔽信息嵌入语言模型生成的内容中。然而，水印方案的鲁棒性尚未得到充分研究。本研究旨在开发一种高级框架，有效移除基于n元组的水印。研究利用了新颖的查询策略——随机选择探查，评估水印强度并识别n元组水印中的黑白列表。实验在流行的大型语言模型Lama3和ChatGPT上进行，显示了De-mark在水印去除和利用任务中的高效性和有效性。", "innovation": "提出了一种新颖的查询策略——随机选择探查，用于评估水印强度并识别n元组水印中的黑白列表。基于此策略，开发了先进的De-mark框架，用于有效移除基于n元组的水印。", "conclusion": "De-mark框架在流行的大型语言模型上展示了高效性和有效性，能够有效去除和利用水印。该研究有助于进一步探索和改进水印方案的鲁棒性。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.14727", "html_url": "https://arxiv.org/abs/2311.14727", "title": "在旅游领域进行多语言社交内容分析的最优策略及新型数据集", "title_en": "Optimal strategies to perform multilingual analysis of social content for a novel dataset in the tourism domain", "authors": "Maxime Masson,Rodrigo Agerri,Christian Sallaberry,Marie-Noelle Bessagnet,Annig Le Parc Lacayrelle,Philippe Roose", "background": "随着社交媒体平台在旅游等领域的影响力日益增强，迫切需要通过高效的自动自然语言处理（NLP）策略来利用这些宝贵的数据资源。然而，将多语言、非结构化的非正式文本转化为结构化知识仍然面临着巨大挑战，特别是对于深度学习分类器的训练，需要持续的手动标注数据。本研究探讨了不同的NLP技术，以实现最佳性能的同时尽量减少需要的标注数据量。为此，建立了首个公开的多语言数据集（法语、英语和西班牙语），包含旅游相关的推文。数据集包括用于地名识别（NER）和细粒度主题概念提取的手动修订注释，以及用于推特级别情感分析的注释。", "innovation": "构建了首个公开的多语言数据集（法语、英语和西班牙语），包含旅游相关的推文以及详细的标注信息。研究对比了各种少样本和微调技术与现代语言模型，结果显示现代少样本技术能够使用少量标注数据（情感分析5条推文/标签，地名识别30条推文，细粒度主题概念标注1000条推文）获得竞品性能。", "conclusion": "研究结果表明，基于新数据集的现代少样本技术在地名识别、主题概念提取和情感分析三个任务上取得了竞争力的结果，为特定领域的NLP应用开辟了道路，减少了手动标注的需求，并避免了基于规则的解决方案的复杂性。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.12532", "html_url": "https://arxiv.org/abs/2410.12532", "title": "MedAide：基于LGM的代理协作中的信息融合与医疗意图分析", "title_en": "MedAide: Information Fusion and Anatomy of Medical Intents via LLM-based Agent Collaboration", "authors": "Dingkang Yang,Jinjie Wei,Mingcheng Li,Jiyao Liu,Lihao Liu,Ming Hu,Junjun He,Yakun Ju,Wei Zhou,Yang Liu,Lihua Zhang", "background": "在医疗智能领域，从不同临床来源融合异构、多意图信息是构建可靠决策系统的核心能力。大型语言模型（LLM）驱动的信息交互系统在医疗领域显示出潜在的可能性，但当处理复杂医学意图时，它们常常遭受信息冗余和耦合的问题，导致严重的幻觉和性能瓶颈。", "innovation": "我们提出了MedAide，一个基于LLM的医疗多代理协作框架，设计意图感知的信息融合和跨专业化医疗领域的协调推理能力。具体地，我们引入了一个正则化引导模块，将语法约束与检索增强生成结合，分解复杂的查询为结构化表示，促进精细粒度的临床信息融合和意图解析。此外，我们提出了一个动态意图原型匹配模块，利用动态原型表示和语义相似性匹配机制，在多轮次医疗对话中实现代理意图的自适应识别和更新。最终，我们设计了一种旋转代理协作机制，引入了动态角色轮换和决策级信息融合，提高了专病医疗代理的效能。", "conclusion": "在四个包含复合意图的医疗基准测试中进行了广泛的实验，自动化指标和专家医生评估结果表明，MedAide相比当前的LLM在医疗技能和战略推理方面表现更优。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2306.13840", "html_url": "https://arxiv.org/abs/2306.13840", "title": "超越规模：自然语言数据中多样性的系数作为数据质量指标", "title_en": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data", "authors": "Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo", "background": "当前大语言模型（LLMs）的预训练趋势主要集中在模型和数据集规模的扩大上。尽管预训练数据的质量被认为是训练高性能LLMs的重要因素，但它仍是一个模棱两可的概念，尚未被严格定义。因此，本文旨在对数据质量的一个关键方面——自然语言数据的变异性进行形式化，通过我们提出的一种多样性系数进行量化分析。实验证明，该多样性系数与直觉上的多样性和变异性一致，例如当潜在概念数量增加时，多样性系数也会增加。进一步测量了可获得的预训练数据集的多样性系数，结果显示其形式上的多样性高于理论上的上下限。最后通过一系列针对GPT-2和LLaMAv2的受控干预实验，展示了预训练数据集的多样性系数能有效反映下游模型评估性能的有用方面，共涵盖44个不同规模的模型（51M至7B参数）", "innovation": "本文提出了首个正式的度量自然语言数据多样性和变性的方法——多样性系数。通过这种方式，使数据质量的具体化，并发现多样性系数能够有效反映模型下游评估的性能", "conclusion": "本研究证明，提出的正式定义的数据多样性是一个重要数据质量指标，能够捕捉并因果性地改善模型评估性能。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.07016", "html_url": "https://arxiv.org/abs/2406.07016", "title": "通过超额词汇探究生物医学出版物中的LLM辅助写作", "title_en": "Delving into LLM-assisted writing in biomedical publications through excess vocabulary", "authors": "Dmitry Kobak,Rita González-Márquez,Emőke-Ágnes Horvát,Jan Lause", "background": "生物医学研究领域的学者使用大型语言模型（LLMs）进行学术写作，但这种使用范围如何，尚未明确。文章使用1500多万篇2010年至2024年之间的生物医学摘要进行研究，通过分析词汇变化揭示LLM的影响。研究结果显示，2024年至少有13.5%的摘要使用了LLM，不同学科、国家和期刊之间存在差异，某些子集合的比例高达40%。这种影响甚至超过了新冠疫情的大规模事件效应。", "innovation": "文章提出了一种无偏见、大规模的方法来研究LLM辅助写作在生物医学研究中的使用情况，通过分析PubMed索引的词汇变化，确定至少有13.5%的文章使用了LLM，揭示了LLM对科学写作的前所未有的影响，这一影响甚至超过重大全球事件，如新冠疫情期间的影响。", "conclusion": "研究证明，LLM在生物医学研究领域的广泛应用对学术写作产生了重大影响，超越了重大世界事件的影响。不同学科、国家和期刊之间的差异明显，这提示未来可能需要更严格的审查和规范来指导LLM的使用。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.00863", "html_url": "https://arxiv.org/abs/2411.00863", "title": "证明生成中LLM训练的下一个标记预测任务假设了最优数据排序", "title_en": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation", "authors": "Chenyang An,Shima Imani,Feng Yao,Chengyu Dong,Ali Abbasi,Harsh Shrivastava,Samuel Buss,Jingbo Shang,Gayathri Mahalingam,Pramod Sharma,Maurice Diesendruck", "background": "在基于大型语言模型（LLM）的证明生成领域，尽管对大型数据集，如ArXiv进行了广泛训练，但在证明任务中的表现仍然仅有适度提升。这主要是由于训练数据中存在问题数据排序，使模型与人类发现证明过程脱节。传统证明通常按照逻辑顺序，旨在验证证明的正确性，而非帮助学习发现过程。我们提出证明的最佳排序是确保每个步骤左侧总是与其相关中间监督，称为直观顺序。", "innovation": "该研究提出了将证明步骤与其相关中间监督放置在左侧的直观顺序，并通过两种任务验证了这一观点，展示了直观顺序对模型训练效果的显著影响。此外，研究还定义了一种高级数学证明中的常见排序问题，并发现广泛使用的数学教科书前两章中17.3%的复杂定理存在此类问题，实验结果支持了这一发现。", "conclusion": "训练证明数据时，使用直观顺序可显著提高模型的证明成功率。这对于大型语言模型的证明生成任务具有重要意义，能有效促进模型从最优排序的学习中受益，从而提升模型的证明能力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.05693", "html_url": "https://arxiv.org/abs/2412.05693", "title": "Batch-Max：利用更大批量大小和KV缓存压缩提高LLM吞吐量", "title_en": "Batch-Max: Higher LLM Throughput using Larger Batch Sizes and KV Cache Compression", "authors": "Michael R. Metel,Boxing Chen,Mehdi Rezagholizadeh", "background": "已有研究开发了驱逐策略，以提高基于关键值（KV）对的缓存效率，特别是在输入提示处理后压缩KV缓存，以加快标记生成速度。然而，在GPU内存有限且输入上下文长度超过生成长度的场景下，现有方法只在输入提示处理后压缩KV缓存，导致较大的批量大小不能使用，从而降低了吞吐量，但保留了模型的准确性。本文作者发现了新的途径，在输入处理阶段也压缩KV缓存，这样可以使用更大的批量大小，显著提高吞吐量，同时保持模型的准确性.", "innovation": "本文提出了一种新的方法Batch-Max，在输入处理阶段也压缩KV缓存，使得在限制GPU内存和输入上下文长于生成长度的情况下，能够使用更大的批量大小，从而显著提高大型语言模型（LLM）的吞吐量，同时保持模型的准确性.", "conclusion": "通过在输入处理阶段也压缩KV缓存的技术，本方法在限制GPU内存和输入上下文长于生成长度的场景下，利用更大的批量大小提升吞吐量并保持模型准确性，这为高效利用资源提供了新的可能."}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.11556", "html_url": "https://arxiv.org/abs/2412.11556", "title": "Token Prepending: 一种无训练开销的从LLM中提取更好句子嵌入的方法", "title_en": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs", "authors": "Yuchen Fu,Zifeng Cheng,Zhiwei Jiang,Zhonghui Wang,Yafeng Yin,Zhengliang Li,Qing Gu", "background": "从大规模语言模型中提取句子嵌入是一种有前景的方向，因为LLM展示了更强的语义理解能力。以往研究通常通过提示工程技术，促使模型将句子信息编码到最后一个token的嵌入中。然而，大多数LLM是仅有的解码器模型并带有因果注意力机制，导致句子早期的token不能关注到后续的token，从而产生偏颇的信息编码和对最终解码token的级联影响。", "innovation": "本文提出了一种新的Token Prepending (TP)技术，它将每一层解码后的句子嵌入添加到下一输入层的句子的开头，使早期的token能够利用因果注意力机制关注完整的句子信息。这项技术是插件式且无需训练的，能够无缝地集成到各种基于提示的句子嵌入方法和自回归LLM中。广泛实验表明，TP技术可以显著提高各种语义文本相似性任务和下游分类任务中现有基于提示的句子嵌入方法的表现，且没有显著增加推理成本。", "conclusion": "TP技术在不同的LLM上表现出显著的性能提升，而且不会引起额外的推理成本。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12816", "html_url": "https://arxiv.org/abs/2504.12816", "title": "SMARTe: Slot-based Method for Accountable Relational Triple extraction", "title_en": "SMARTe: Slot-based Method for Accountable Relational Triple extraction", "authors": "Xue Wen Tan,Stanley Kok", "background": "关系三元组提取（RTE）是自然语言处理（NLP）中的一个基本任务。先前的研究主要集中在优化模型性能上，而对这些模型内部机制的理解有所欠缺。许多现有的方法依赖复杂的预处理步骤来诱导特定的交互，这些方法可能会产生不透明的系统，且可能与理论基础不完全一致。", "innovation": "提出了SMARTe（Slot-based Method for Accountable Relational Triple extraction），一种基于槽的方法，通过槽注意力机制引入内在可解释性，并将任务建模为集合预测问题。SMARTe合并了相关信息到不同的槽中，确保所有预测都可以明确追溯到学习的槽表示及其贡献的标记。虽然强调可解释性，但SMARTe的性能与最先进的模型相当。评估结果显示，在不牺牲性能的情况下提高了可解释性。通过注意力热图，SMARTe为每个预测的关系三元组提供了具体的解释。", "conclusion": "SMARTe的评估结果表明添加可解释性不会牺牲性能。我们通过质性评估展示了SMARTe提供的解释，使用注意力热图将解释映射到各自的标记。最后，我们讨论了我们的发现，并提出了未来研究的方向。我们的代码可在以下链接获得：这个 https URL。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.01119", "html_url": "https://arxiv.org/abs/2408.01119", "title": "任务提示向量：通过多任务软提示迁移的有效初始化", "title_en": "Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer", "authors": "Robert Belanec,Simon Ostermann,Ivan Srba,Maria Bielikova", "background": "提示调谐是训练大型语言模型的有效解决方案。然而，当前基于软提示的方法通常会牺牲多任务模块性，即每次添加新任务时都需要重新训练整个过程或部分过程。最近有关任务向量的研究通过在全模型权重上应用算术运算来实现预期的多任务性能表现，但对于软提示却没有类似的解决方案。该论文旨在通过元素差异运算来创建任务提示向量，从而实现这种算术操作。实验结果表明，任务提示向量可以在低资源环境下，有效初始化提示调谐来处理类似任务。此外，任务提示向量与提示调谐的随机初始化相互独立，在两种不同语言模型架构下亦是如此。这使得可以使用来自不同任务的预训练向量进行提示算术运算。", "innovation": "本文提出了任务提示向量（Task Prompt Vectors），它是由调谐后的软提示权重与随机初始化的权重之间的元素差值构建而成。这种方法使得可以在不同任务的预训练向量之间执行算术运算，从而在不重复训练模型或仅部分场景下实现多任务学习能力，提升了模型的效率和性能。实验表明，通过这种方式，任务提示向量可以在低资源设置中有效初始化提示调谐，并且能够独立于提示调谐随机初始化来运作，这为提示调谐提供了一种具有竞争力的替代方案，通过多任务任务提示向量的算术加法即可实现这一点。", "conclusion": "研究表明，任务提示向量为软提示在多任务设置中的应用提供了一种有效的方法。在低资源环境下，任务提示向量能够作为初始点亮提示调谐的工具，同时与随机初始化分离，使得不同模型架构下的预训练向量可以进行算术运算。通过这种方式，我们提供了一种有竞争力的多任务学习方案，在多任务任务提示向量的算术加法基础上实现与现有领先基准相近的效果。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.16765", "html_url": "https://arxiv.org/abs/2411.16765", "title": "SHuBERT：多流聚类预测的自监督手语表示学习", "title_en": "SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction", "authors": "Shester Gueuwou,Xiaodan Du,Greg Shakhnarovich,Karen Livescu,Alexander H. Liu", "background": "传统的手语处理依赖于针对特定任务的模型，这限制了跨任务的迁移学习潜力。对于手语的预训练方法通常集中在监督预训练上，无法利用未标记的数据，或者是在帧或视频片段上独立的上下文表示，这意味着忽略了手语时间关系的影响。", "innovation": "引入了SHuBERT（Sign Hidden-Unit BERT），这是一种从大约1000小时的美国手语视频中学习的自监督上下文表示模型。SHuBERT为可视手语输入的多流配置自定义了遮蔽令牌预测目标，学习预测对应手、面部和身体姿势流的多个目标。", "conclusion": "SHuBERT在手语翻译、孤立手语识别和手指拼写检测等任务中达到了最先进的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11268", "html_url": "https://arxiv.org/abs/2502.11268", "title": "改进的大规模语言模型无偏水印", "title_en": "Improved Unbiased Watermark for Large Language Models", "authors": "Ruibo Chen,Yihan Wu,Junfeng Guo,Heng Huang", "background": "随着人工智能在文本生成方面超过人类的能力，验证AI生成内容的来源变得至关重要。无偏水印通过在语言模型生成的文本中嵌入统计信号而不损害质量来提供有效的解决方案。本文的背景在于讨论现有无偏水印的不足以及如何改进以满足验证AI生成内容需求的问题。", "innovation": "本文介绍了一种名为MCmark的无偏多通道水印家族。MCmark通过将模型的词汇表划分为多个段，并基于水印密钥提升选定段落的标记概率，来实现无偏水印嵌入。MCmark不仅保持了语言模型的原始分布，而且与现有无偏水印相比，在可检测性和鲁棒性方面表现出显著的改进。实验结果显示，MCmark相较于现有最先进的无偏水印，可检测性提高了超过10%。这一进步突显了MCmark在AI生成文本中增强水印应用的潜力。", "conclusion": "MCmark通过提出改进的无偏多通道水印，显著提高了检测能力和鲁棒性，为大规模语言模型中的水印应用提供了新的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13886", "html_url": "https://arxiv.org/abs/2505.13886", "title": "Code2Logic：基于游戏代码的数据合成方法以提高VLMs的通用推理能力", "title_en": "Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning", "authors": "Jingqi Tong,Jixin Tang,Hangcheng Li,Yurong Mou,Ming Zhang,Jun Zhao,Yanbo Wen,Fan Song,Jiahao Zhan,Yuyang Lu,Chaoran Tao,Zhiyuan Guo,Jizhou Yu,Tianhao Cheng,Changhao Jiang,Zhen Wang,Tao Liang,Zhihui Fei,Mingyang Wan,Guojun Ma,Weifeng Ge,Guanhua Chen,Tao Gui,Xipeng Qiu,Qi Zhang,Xuanjing Huang", "background": "视觉语言模型（VLMs）在视觉语言推理能力的提升方面受到了视觉语言链式思考（CoT）数据资源稀缺的限制。高质量的视觉语言推理数据的标注需要耗费大量的人力和物力，成本较高。现有方法难以有效改进VLMs的推理能力，尤其是在跨域任务中的表现不足。因此，需要一种新的方法来解决这一问题，即利用游戏代码作为一种获取视觉语言推理数据的有效途径，因为游戏代码自然包含了逻辑结构和状态转换过程，可以帮助自动获取逻辑推理解析过程和结果。", "innovation": "提出了一种名为Code2Logic的新颖方法，该方法通过利用大型语言模型（LLMs）来适应游戏代码，从而实现自动获取推理过程和结果的能力，同时生成多样化的游戏问答数据集（GameQA），该数据集包含30款游戏和158个任务，具有可控的难度梯度和低投入优势，能够用于训练和评估VLMs。这种方法显示了跨域任务的通用推理能力提高，尤其是Qwen2.5-VL-7B模型，在7个多样化的视觉语言基准测试中的性能提升了2.33%。", "conclusion": "通过Code2Logic方法生成的GameQA数据集和VLMs模型展示了在跨域任务中良好的通用推理能力，证明了利用游戏代码合成数据的重要性，这为提高VLMs的推理能力提供了一种新途径。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.03262", "html_url": "https://arxiv.org/abs/2501.03262", "title": "REINFORCE++: 一种稳健的增强学习从人类反馈中提升算法，适用于提示模型和奖励模型", "title_en": "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models", "authors": "Jian Hu,Xibin Wu,Wei Shen,Jason Klein Liu,Zilin Zhu,Weixun Wang,Songlin Jiang,Haoran Wang,Hao Chen,Bin Chen,Weikai Fang,Xianyu,Yu Cao,Haotian Xu", "background": "现有的强化学习从人类反馈（RLHF）或可验证奖励（RLVR）框架通常存在推理瓶颈和复杂性障碍，这限制了新手的可访问性。针对这一问题，论文介绍了一种新的开源框架OpenRLHF，旨在解决上述挑战并提高现有RLHF技术的效率和用户体验。背景中提到了LLMs通过RLHF或RLVR进行微调可以显著提高人类与AI的价值对齐，并进一步提高AI的能力，特别是在推理密集且需要长上下文链式思维的任务上。然而，由于现有框架的限制，使得这些技术在实际应用中的推广受到了阻碍。背景中的关键问题是现有RLHF体系结构的复杂性和不友好性，这对新用户来说是一个障碍。", "innovation": "OpenRLHF框架提供了一种用户友好、可扩展且易于学习的设计，并且建立在Ray、vLLM、DeepSpeed和HuggingFace Transformers之上，具有简化的设计、清晰的代码结构和详细的文档，从而降低了入门门槛。OpenRLHF还展示了相较于最先进的框架，它在不同模型规模下实现了高达1.68倍的训练效率改进，并且实现了显著更少的代码行数。通过这些改进，OpenRLHF为研究人员和实践者提供了更强大的工具，促进了RLHF研究和学习的加速。", "conclusion": "论文通过介绍OpenRLHF开源框架，解决了RLHF体系结构的障碍，并通过实验验证了其优越的性能。OpenRLHF框架已经公开，并且已经被领先的机构采用，加速了RLHF研究和学习。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.18681", "html_url": "https://arxiv.org/abs/2503.18681", "title": "Commander-GPT: 完全释放多模态大语言模型的讽刺检测能力", "title_en": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models", "authors": "Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin", "background": "讽刺检测是自然语言处理（NLP）领域的一个关键研究方向，近年来引起了广泛关注。传统的讽刺检测方法主要集中在单一模态（如文本）上，但由于讽刺的隐晦和微妙性，这些方法往往难以取得令人满意的结果。近年来，研究者开始转向多模态方法，但如何有效利用多模态信息来准确识别讽刺内容仍然存在挑战。研究者提出了一个名为Commander-GPT的新颖的多模态框架，旨在解决这一挑战。", "innovation": "该论文提出了一种创新的多模态框架，即 Command-GPT 模型。该模型借鉴军事战略的思想，首先将讽刺检测任务分解为六个子任务，然后由中央指挥官（决策者）分配最适合的大型语言模型来解决每个特定的子任务。最终，来自每个模型的检测结果被汇总来识别讽刺。与现有方法相比，该方法无需微调或真实依据即可实现最先进的性能，F1分数提高了19.3%。", "conclusion": "在对MMSD和MMSD 2.0进行广泛实验的基础上，研究证明了该方法的优越性，无需任何细调或真实推理前提即能实现最先进的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00958", "html_url": "https://arxiv.org/abs/2503.00958", "title": "分层洞见：通过利用所有变压器层进行作者风格的可推广分析", "title_en": "Layered Insights: Generalizable Analysis of Authorial Style by Leveraging All Transformer Layers", "authors": "Milad Alshomary,Nikhil Reddy Varimalla,Vishal Anand,Smaranda Muresan,Kathleen McKeown", "background": "本文提出了一个旨在通过利用预训练的变压器模型不同层中学习到的各种语言表示来进行作者归属任务的新方法。研究在三个数据集上进行了评估，并与领域内和领域外场景中的先进基线进行了比较，发现利用不同的变压器层能提高作者归属模型在外域数据上的鲁棒性，从而获得了新的先进水平的结果。此外，研究还进一步探讨了不同层在表示特定风格特征方面的专业化，这些特征在域外测试时对模型有益。", "innovation": "本文提出的方法利用了预训练变压器模型不同层中学习到的多种语言表示，这种方法在领域内和领域外场景中均表现出色，特别是在外域数据上，能够提高模型的鲁棒性，并且取得了新的先进水平的结果。此外，研究还揭示了不同层在表示特定风格特征方面的专业化作用。", "conclusion": "研究结果表明，利用所有变压器层能改进作者归属模型的鲁棒性，特别是在处理外域数据时。通过分析不同层的作用，研究为理解模型如何利用特定的风格特征提供新的见解，从而提高外域测试时的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.08496", "html_url": "https://arxiv.org/abs/2501.08496", "title": "量化下游模型性能中数据对齐的重要性", "title_en": "Quantifying the Importance of Data Alignment in Downstream Model Performance", "authors": "Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo", "background": "尽管通常强调数据集的大小，但本研究关注数据对齐的作用——这一常被忽视的数据质量方面，在训练强大的大型语言模型（LLMs）中的作用。研究使用基于Task2Vec 的数据对齐系数，这是一个衡量两个数据集相似性的定量指标，来量化训练数据和评估数据之间对齐程度对下游性能的影响。特别地，研究对两种设置进行了控制干预实验：1. 各种预训练（pt）对评估数据对齐系数的影响；2. 领域特定微调（ft）对领域特定评估数据对齐系数的影响。探索的具体领域任务是自动形式化——自然语言与代码之间的机器翻译任务，用于形式验证。在两种设置中，发现模型训练和评估数据之间的对齐系数与模型在相应下游任务上的损失/困惑度之间存在强烈、可预测的负相关。这些发现表明需要重新评估LLMs的训练方法，突出数据对齐的重要性，特别是在像自动形式化这样的专门下游任务中，相比数据量更具相关性。", "innovation": "本研究创新性地使用数据对齐系数来量化训练数据和评估数据之间的对齐对下游性能的影响。通过对比预训练和微调阶段的数据对齐，研究揭示了数据对齐在训练大型语言模型中的关键作用。特别强调了在专门的下游任务，如自动形式化，中，数据对齐相较于数据量更为重要。", "conclusion": "研究结果表明，重新评估LLMs的培训方法，数据对齐在训练过程中起决定性作用，特别是对于专门的下游任务，如自动形式化，其重要性超过单纯的数据量。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08713", "html_url": "https://arxiv.org/abs/2506.08713", "title": "基于多跳自然语言推理的保障案例结构可解释合规检测", "title_en": "Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure", "authors": "Fariz Ikhwantri,Dusica Marijan", "background": "确保复杂系统符合法规要求通常需要通过断言-论据-证据框架检查保障案例的有效性。但在这一过程中存在诸多挑战，如法律和技术文本的复杂性、模型解释的需求以及保障案例数据的有限可访问性。", "innovation": "提出了一种基于自然语言推理（NLI）的合规检测方法：EXplainable CompLiance detection with Argumentative Inference of Multi-hop reasoning (EXCLAIM)。利用多跳推理来描述保障案例的断言-论据-证据结构，实现可解释且可追溯的合规检测。通过生成大量语言模型（LLM）来解决保障案例数量有限的问题，并引入了衡量覆盖率和结构一致性的指标。将欧盟通用数据保护条例（GDPR）要求作为案例研究，展示了基于NLI方法在合规过程自动化方面的有效性。", "conclusion": "研究结果强调了基于NLI的方法在自动化合规过程中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21191", "html_url": "https://arxiv.org/abs/2506.21191", "title": "基于提示的轮流预测", "title_en": "Prompt-Guided Turn-Taking Prediction", "authors": "Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara", "background": "轮流预测模型是语音对话系统和对话机器人的重要组成部分。近年来，基于Transformer架构的方法被用来实现实时、连续的语音活动预测。然而，现有的方法通常缺乏动态调节和文本提示的支持，不能提供直观和明确的控制。", "innovation": "提出了一种新型模型，能够通过文本提示动态控制轮流预测过程。该模型基于基于Transformer的语音活动投影（VAP）模型，并将文本提示嵌入到通道Transformer和跨通道Transformer中。利用大规模语言模型生成的合成文本提示数据，验证了该方法的可行性。实验结果表明，该模型提高了预测准确性，并根据文本提示有效地调节了轮流转换的时间行为。", "conclusion": "提出了一个基于提示的轮流预测模型，该模型通过文本提示实现了对轮流预测过程的动态控制，提高了预测准确性和时间行为调节能力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15830", "html_url": "https://arxiv.org/abs/2506.15830", "title": "通过信息几何和量子度量重新思考大语言模型训练", "title_en": "Rethinking LLM Training through Information Geometry and Quantum Metrics", "authors": "Riccardo Di Sipio", "background": "大型语言模型（LLMs）的优化发生在高维参数空间中，具有非欧几里得结构。信息几何利用费歇尔信息度量来描绘这一景观，通过对自然梯度下降引入更合理的学习机制，阐释诸如尖锐极小值、泛化以及观察到的标度定律等现象。尽管这种几何视角在实践中往往不切实际，但它为我们理解LLM训练提供了新的视角。", "innovation": "文章利用费歇尔信息度量和量子Fubini-Study度量与量子费舍尔信息提出新的几何视角，加深我们对大语言模型训练的理解，特别是在曲率感知的方法上，从而暗示在量子增强系统中更有效的优化策略。", "conclusion": "文章最后推测基于费歇尔信息度量和量子Fubini-Study度量的量子类比，暗示未来可能利用量子计算实现更高效的优化。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22618", "html_url": "https://arxiv.org/abs/2505.22618", "title": "Fast-dLLM: 通过启用KV缓存和并行解码加速扩散型大语言模型", "title_en": "Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding", "authors": "Chengyue Wu,Hao Zhang,Shuchen Xue,Zhijian Liu,Shizhe Diao,Ligeng Zhu,Ping Luo,Song Han,Enze Xie", "background": "扩散型大语言模型（Diffusion LLMs）在非自回归文本生成中显示出潜力，具有并行解码的能力。然而，开源的扩散型大语言模型由于缺乏Key-Value (KV) Cache以及在同时解码多个标记时质量下降，其实际推理速度往往落后于自回归模型。", "innovation": "引入了一种针对双向扩散模型的块状近似KV缓存机制，以实现缓存重用，并且几乎不影响性能。找到了并行解码生成质量下降的根本原因，在条件独立性假设下破坏了标记间的依赖关系。提出了一种基于置信度的并行解码策略，仅解码超过置信阈值的标记，以此减轻依赖性冲突并保持生成质量。在多个大语言模型基准上，展示了最高27.6倍的吞吐量提升，并且几乎没有准确性损失，缩小了与自回归模型的性能差距，为实用部署扩散型大语言模型铺平了道路。", "conclusion": "实验结果表明，通过Fast-dLLM方法，在LLaDA和Dream模型上取得了高达27.6倍的吞吐量提升同时保持了较低的准确率损失，填补了与自回归模型的性能差距，并为实用部署扩散型大语言模型提供了可能。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.14634", "html_url": "https://arxiv.org/abs/2506.14634", "title": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "title_en": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "authors": "Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessica Daikeler", "background": "近年来，生成语言模型（LLMs）的发展及其更广泛的可访问性，激发了关于如何在问卷研究中使用它们的讨论，尤其是在分类开放问题的答案方面。由于其语言能力，LLMs 可能成为比耗时的手动编码和预训练监督机器学习模型更有效的一种替代方案。然而，大部分现有研究集中在英语语言的非复杂主题响应或单一LLM上，因此其研究结果的有效性及LLMs分类质量与传统方法相比的情况仍然没有定论。本研究以德国参与调查的原因数据为例，探讨不同LLMs在其他背景下用于编码开放性问卷响应的可行性，并比较不同最先进的LLMs和提示方法的表现。研究发现不同LLMs之间的性能差异显著，仅经过微调的LLMs才能达到满意的预测性能。根据使用的LLM不同，提示方法之间的性能差异亦存在条件性。最后，不同原因类别下的LLMs分类性能不一，导致未使用微调时类别分布不同。", "innovation": "本研究创新性地将最先进的LLMs应用于德国语料库中的开放性问卷响应，并对比了多种LLMs及提示方法的表现。研究表明，尽管LLMs的性能显著差异，但通过微调可以显著提高预测效果。此外，本研究探讨了不同背景下LLMs对开放性响应的分类质量，揭示了研究人员在选择自动生成的方法时需要考虑的权衡因素，贡献了对LLMs在问卷研究中有效、准确和可靠运用条件的理解。", "conclusion": "本研究发现，不同LLMs在开放式问卷响应分类上的表现差异显著，经过微调的模型能达到较高的预测性能，但不同提示方法的表现依赖所使用的LLM。未使用微调情况下，不同类别原因的分类性能差异会导致类别分布的变化。研究讨论了这些发现对编码开放问题和实质分析的影响，并强调了在LLM时代研究人员选择自动分类方法时需要考虑的众多权衡因素。本研究为理解LLMs在问卷研究中的运用条件，以及其高效、准确和可靠的应用提供了贡献。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01334", "html_url": "https://arxiv.org/abs/2507.01334", "title": "符号或数值？理解推理大语言模型解决物理问题的方法", "title_en": "Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs", "authors": "Nifu Dan,Yujun Cai,Yiwei Wang", "background": "长期以来，处理物理推理问题对大型语言模型（LLMs）是一个复杂而艰巨的挑战，需要深厚的概念理解与有效的解题技巧相结合。本研究旨在探索高级指令调优推理模型（如Deepseek-R1）在解决从SciBench基准中精选的复杂物理问题上的应用情况。", "innovation": "研究发现，这些高能推理模型不仅在回答复杂的物理问题上达到了最先进的准确率，还产生了强调符号推导的独特推理模式。此外，研究结果表明，即使是这些高度复杂的推理模型，策略性地使用少量示例提示也可以实现整体准确率的可测量提升，这突显了性能进一步提升的潜力。", "conclusion": "本研究通过全面的实验评估，展示了推理模型在解决物理问题上的强大能力。进一步的研究可以专注于通过对话系统中的知识迁移和策略性提示来优化这些模型的表现。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00606", "html_url": "https://arxiv.org/abs/2507.00606", "title": "混合推理：教会大规模语言模型使用自适应策略进行推理", "title_en": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies", "authors": "Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang", "background": "大型语言模型（LLMs）通过先进的提示技术如思维链（Chain-of-Thought，CoT）和思维树（Tree-of-Thought，ToT）在复杂任务中表现出色，但它们对手动制作的任务特定提示的依赖限制了其适应性和效率.", "innovation": "引入了一个名为Mixture of Reasoning（MoR）的训练框架，该框架将多种推理策略嵌入到LLMs中，实现无需外部提示工程的自主、任务适应推理. MoR包括两个阶段：思维生成，利用类似GPT-4o的模型创建推理链模板；SFT数据集构建，将模板与基准数据集配对以进行监督微调.", "conclusion": "实验结果表明，MoR 显著提高了性能，MoR150 在使用 CoT 提示时实现了0.730（2.2% 的改进），与基线相比，性能提高了13.5%，同时消除了对任务特定提示的需求，提供了一种适用于多样任务的稳健推理的通用解决方案."}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨语种旅行：评估多模态大语言模型的跨语种一致性", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "随着多模态大语言模型（MLLMs）的迅速发展，它们在实际应用中的表现得到显著提升。然而，在不同语言尤其是结合文化知识时，实现一致性的表现仍然是一个重大挑战。为此，引入了两个新的基准测试：KnowRecall和VisRecall，用于评估MLLMs的跨语种一致性。KnowRecall是一个基于视觉问题回答的基准测试，用于衡量15种语言中的事实性知识一致性，特别是关于全球地标的文化和历史问题。VisRecall通过询问模型在没有图像的情况下描述9种语言的地标的外貌，来评估视觉记忆的一致性。实验结果显示，当前最先进的MLLMs，包括专有的模型，仍难以实现跨语种一致性，突显了开发更 robust 方法，以生成真正多语言且文化意识强的模型的必要性。", "innovation": "提出了两个新的基准测试：KnowRecall和VisRecall，它们分别用于评估MLLMs在视觉问题回答和描述地标的外貌时的跨语种一致性，专注于全球地标的文化和历史问题。这些基准提供了一种有效的方法来衡量不同语言背景下模型的性能差异，从而促进了更一致、更具文化意识的模型的发展。", "conclusion": "当前最先进的MLLMs仍然难以实现跨语种一致性，因此需要更 robust 的方法来生成真正多语言且文化意识强的模型。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23661", "html_url": "https://arxiv.org/abs/2506.23661", "title": "通过BeamAttack对抗样本评估误导信息分类系统的鲁棒性", "title_en": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack", "authors": "Arnisa Fazla,Lucas Krauter,David Guzman Piedrahita,Andrianos Michail", "background": "该论文扩展了BeamAttack算法，这种算法旨在通过单词级别的修改评估文本分类系统的鲁棒性。原来的算法使用了引导型束搜索（beam search）进行单词调整。在这个研究中，作者增加了对单词删除的支持，以及跳过替换的选项。此外，他们还集成了一种算法叫LIME，用于更好地优先考虑单词替换。经过BODEGA框架中的多个数据集和多种目标模型（包括BiLSTM、BERT和对抗训练的RoBERTa）的测试，所提出的方法在攻击成功率上达到了99%以上，同时保持了原始文本的语义和词汇相似性。文中通过定量和定性的分析，揭示了BeamAttack的有效性和限制。研究者也提供了该项研究的代码实现，供其他研究人员使用和参考。", "innovation": "1. 扩展了BeamAttack以支持单词删除和跳过替换的功能；\n2. 集成了LIME以优化单词替换的选择策略；\n3. 在多个数据集和不同模型上测试，显示高攻击成功率和良好的文本保真度；\n4. 详细分析了BeamAttack的有效性与局限性，提供了丰富的方法论支持和实践指导", "conclusion": "研究成果表明，BeamAttack对误导信息分类系统的鲁棒性评估具有高效性，并能够发现尽可能少量的文字修改来改变模型预测。该方法在一个99%以上攻击成功率的基础上，依然保持了原始文本的语义和词汇相似性，能够在实际应用中提供支持。同时，指出了一些方法自身的局限性，给进一步的研究提出了方向。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00612", "html_url": "https://arxiv.org/abs/2506.00612", "title": "使用知识图谱引导的迷惑选项生成增强临床多项选择题基准", "title_en": "Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation", "authors": "Running Yang,Wenlong Deng,Minghui Chen,Yuyin Zhou,Xiaoxiao Li", "background": "临床任务如诊断和治疗需要强大的决策能力，突显了评估大型语言模型（LLMs）可靠性的严格评价基准的重要性。在本文中，我们介绍了一种知识引导的数据增强框架，通过生成迷惑选项（即与正确答案相似但可能误导现有LLMs的错误选择），增加了临床多项选择题（MCQ）数据集的难度。这一方法涉及多步、语义驱动的在医学知识图谱上的行走，以识别医学相关但事实上不正确的干扰路径，以指导LLM生成更具欺骗性的干扰选项。通过使用设计的知识图谱引导的干扰生成（KGGDG）流水线，应用于六个广泛使用的医学问答基准，并展示了其一致性地降低了最先进的LLM的准确性。这些发现确立了KGGDG作为一种强大工具，用于使医学LLM的评估更加稳健且具有诊断性评价的能力。", "innovation": "提出了一种基于知识图谱的知识引导数据增强框架（KGGDG），通过生成相似但错误的迷惑选项，增强了临床多项选择题的难度，这项工作有助于提升大型语言模型在医疗场景中的可靠性评测标准，尤其是对抗现有模型的误导能力，从而增强评估的挑战度和诊断性。", "conclusion": "使用KGGDG框架，可以提升现有临床多次选择题基准的评估难度，有效降低最先进的LLM模型的准确性，从而提供更具有挑战性和诊断性的医学LLM评估，验证了KGGDG作为一种强大工具的潜力，在稳健和诊断性评价方面具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.10576", "html_url": "https://arxiv.org/abs/2406.10576", "title": "绕过反向传播：利用策略梯度的结构化剪枝方法以提升大型语言模型的效率", "title_en": "Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient", "authors": "Yuan Gao,Zujing Liu,Weizhong Zhang,Bo Du,Gui-Song Xia", "background": "现有的大型语言模型（LLM）剪枝方法通常在训练后进行，不涉及昂贵的权重微调，但其剪枝标准往往依赖于手工构建的度量标准，可能导致性能未达最优。文章背景在于探究一种更优化、更高效的剪枝策略，以解决前述问题。", "innovation": "提出了一种基于优化的结构化剪枝方法，通过在概率空间中直接优化剪枝后的模型损失来学习剪枝掩码，而非依赖于标准的反向传播训练。具体来说，学习底层伯努利分布来抽样二进制剪枝掩码，并将伯努利参数与LLM损失分离，利用策略梯度估计器实现高效的优化而不进行反向传播。这项创新支持全局和异构剪枝，并可在必要时使用基于度量的方法进行初始化。", "conclusion": "在LLaMA、LLaMA-2、LLaMA-3、Vicuna和Mistral模型以及C4和WikiText2数据集上进行的大量实验展示了该方法在效率和有效性方面的出色表现。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01923", "html_url": "https://arxiv.org/abs/2507.01923", "title": "决策导向的文本评估", "title_en": "Decision-Oriented Text Evaluation", "authors": "Yu-Shiang Huang,Chuan-Ju Wang,Chung-Chi Chen", "background": "自然语言生成（NLG）在高风险领域中的应用日益增加，但常用的内在评估方法，如n-gram重叠或句子可行性，与实际的决策效果关联性较弱。本研究通过直接评估生成文本对人类和大型语言模型（LLM）决策结果的影响，提出了一种决策导向的评估框架。使用市场摘要文本（如客观的晨间总结和主观的收盘分析）作为案例，基于人类投资者和仅由这些文本来指导的自主LLM代理在执行交易上的财务表现，来评估决策质量。研究结果显示，仅依靠摘要，人类和LLM代理的表现并不优于随机表现。然而，更丰富的分析评论能够使人类-LLM团队协同工作，显著超越个体人类或代理的基础表现。该项研究强调了评估生成文本的能力，使其能够促进人类与LLM之间的协同决策，突出了传统内在评估指标的关键局限性。", "innovation": "本研究提出了一种决策导向的框架，通过直接评估生成文本对人类和大型语言模型决策结果的影响来评价生成的文本。这种方法不同于传统的内在评估方法，强调了生成文本的决策效能，特别是其对人类和AI协同决策的促进作用。", "conclusion": "研究发现，即使对于经验丰富的投资者，仅依靠摘要，人类和LLM表现也不如随机表现；而更详细的分析评论能够显著提升团队决策表现，表明评估文本应注重其促进人类与LLM协同决策的能力。传统评估指标存在局限性，不能很好地反映生成文本的实际效用。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01352", "html_url": "https://arxiv.org/abs/2507.01352", "title": "Skywork-Reward-V2：通过人机协同扩展偏好数据曲", "title_en": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "authors": "Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou", "background": "尽管奖励模型（RMs）在基于人类反馈的强化学习（RLHF）中扮演着关键角色，目前最先进的开源RMs在大多数现有评估基准上表现不佳，无法捕捉人类偏好中的微妙和复杂性。即使采用了先进的训练技术，这些方法也没有显著提高性能。研究者认为，这种脆弱性主要源于偏好评判数据集的限制，这些数据集往往范围狭窄、人工标记或缺乏严格的质量控制。为了应对这些挑战，提出了一种包含4000万偏好对的大规模偏好评判数据集，命名为SynPref-40M。", "innovation": "设计了一种人机协同的两阶段管道，结合了人类注释质量和AI的可扩展性，通过大规模数据校准提高数据质量。基于此偏好混合数据，训练了八个参数从0.6B到8B不同的奖励模型Skywork-Reward-V2系列。经过实验证明，Skywork-Reward-V2在多种能力上表现出色，包括与人类偏好的对齐、目标正确性、安全性、对抗风格偏见和最佳N扩展，超过七项主要奖励模型基准的最佳表现。此外，去规范化研究表明，该方法不仅在于数据规模，也在于高质量的数据校准。", "conclusion": "Skywork-Reward-V2系列在开源奖励模型中取得显著进步，揭示了现有偏好数据集的潜在价值，并展示了人机协同校准如何显著提高数据质量。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.07618", "html_url": "https://arxiv.org/abs/2411.07618", "title": "使用稀疏特征级约束的直接偏好优化", "title_en": "Direct Preference Optimization Using Sparse Feature-Level Constraints", "authors": "Qingyu Yin,Chak Tou Leong,Hongbo Zhang,Minjun Zhu,Hanqi Yan,Qiang Zhang,Yulan He,Wenjie Li,Jun Wang,Yue Zhang,Linyi Yang", "background": "大型语言模型（LLMs）与人类偏好的对齐仍然是一个关键挑战。尽管后训练技术如强化学习从人类反馈（RLHF）和直接偏好优化（DPO）取得了显著成功，但它们通常引入了计算效率低下和训练稳定性差的问题。", "innovation": "本文提出了特征级受限偏好优化（FPO），这是一种新颖的方法，旨在简化对齐过程并确保稳定性。FPO 利用了预训练的稀疏自编码器（SAEs）并引入了特征级约束，使其能够通过稀疏特征在训练良好的稀疏自编码器中的激活和使用特征级离线参考的序列 KL 发散率来实现高效的稀疏性约束对齐。", "conclusion": "在基准数据集上的实验结果表明，FPO 获得的胜率绝对改进为 5.08%，且计算成本远低于最先进的基线方法，使其成为高效可控制的 LLM 对齐的有前途的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.00903", "html_url": "https://arxiv.org/abs/2410.00903", "title": "使用生成人工智能进行因果表示学习：文本作为治疗的应用", "title_en": "Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments", "authors": "Kosuke Imai,Kentaro Nakamura", "background": "本文探讨了如何通过利用生成人工智能（GenAI）的力量来增强在未结构化高维治疗（如文本）中因果推理的有效性。传统的因果推理方法可能受到复杂背景和多重因素的影响，难以准确识别具体治疗特征及其对结果的影响。本文旨在通过生成模型（如大型语言模型，LLM）生成文本驱动的治疗，进而揭示其内部表示，以解决这些挑战，并提升因果效应估计的准确性与效率。", "innovation": "本文提出了GenAI驱动的推理（GPI）方法，该方法采用深度生成模型（LLMs）高效生成治疗，并利用其内部表示进行因果效应估计。与现有方法不同，该方法不需要从数据中学习因果表示，而是直接利用生成模型的内部结构，从而产生了更准确和高效的估计。此外，本文通过双重机器学习方法建立了非参数平均治疗效应识别的条件，并提出了避免重叠假设违例的估计策略。在模拟和实际数据应用中，与最先进的因果表示学习算法相比，此方法展示了其优势。", "conclusion": "本文通过使用大型语言模型生成的文本数据，探索和验证了GPI方法的有效性。研究结果表明，GPI方法能够更好地识别重要的治疗特征，如特定情感和特定主题，并提供了更准确和高效的因果效应估计。该方法也适用于文本重用场景，为未来的应用提供了新的思路。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18959", "html_url": "https://arxiv.org/abs/2506.18959", "title": "从网络搜索迈向主动式深度研究：利用推理代理激励搜索", "title_en": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "authors": "Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu", "background": "信息检索是现代知识获取的基础，每天在多种领域处理数十亿次查询。然而，传统的基于关键词的搜索引擎对处理复杂、多步骤的信息需求越来越力不从心。论文指出，具备推理和自主能力的大规模语言模型（LLMs）正在引领新的研究范式，称为“主动式深度研究”。主动式深度研究系统超越了传统的信息检索技术，通过将自主推理、迭代检索和信息合成紧密整合到一个动态反馈回路中来实现。研究从静态的网络搜索进化到交互式的基于代理的系统，这些系统能够制定计划、探索和学习。", "innovation": "该研究提出了一种新的研究范式——主动式深度研究（Agentic Deep Research），并基于自主推理、迭代检索和信息合成的动态反馈循环，超越传统的信息检索技术。同时，引入了测试时间的扩展律，以形式化地描述计算深度对推理和搜索的影响。通过基准测试结果和开源实现，该研究证明主动式深度研究不仅显著优于现有方法，而且在未来的知识获取中有望成为主导模式。", "conclusion": "该研究展示了主动式深度研究在信息检索领域的巨大潜力，并提供了相关资源，包括行业产品、研究论文、基准数据集和开源实现（https://example.com）以供社区参考。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21880", "html_url": "https://arxiv.org/abs/2505.21880", "title": "引入大规模语言模型进行大规模城市复杂交通仿真", "title_en": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation", "authors": "Yu-Lun Song,Chung-En Tsern,Che-Cheng Wu,Yu-Ming Chang,Syuan-Bo Huang,Wei-Chu Chen,Michael Chia-Liang Lin,Yu-Ta Lin", "background": "传统的基于规则的代理基础建模（ABM）方法在模拟大规模城市移动模式时存在局限性，无法充分反映个体行为的多样性和真实感。为此，研究旨在通过将大型语言模型（LLM）与ABM结合，提出一种创新的方法，用以改善城市交通模拟的效果和精确性，为城市规划提供有效的政策制定依据。", "innovation": "本文提出的方法通过使用LLM生成合成人口特征、分配备用和偶然位置以及模拟个性化路径来增强代理多样性与现实性。相较于传统的基于规则的ABM方法，这种方法能更准确地模拟个体行为和大规模的交通模式，从而为城市规划提供更为实用的信息。", "conclusion": "本研究通过建立稳健的验证框架来保障在城市规划应用中的准确性和可靠性。该方法的应用有助于提升城市交通规划的质量和效率，为未来城市交通模型的发展奠定了基础。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02074", "html_url": "https://arxiv.org/abs/2507.02074", "title": "大型语言模型在视频 crashes 检测中的应用：方法、数据集和挑战综述", "title_en": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges", "authors": "Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma", "background": "智能交通系统中从视频流中检测碰撞是一个关键问题。近年来，大型语言模型（LLMs）和视觉-语言模型（VLMs）的发展改变了我们处理、推理和总结多模态信息的方式。", "innovation": "本文综述了利用LLMs进行视频碰撞检测的最新方法，构建了一个结构化的融合策略分类，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前挑战和机遇。", "conclusion": "本文为视频理解与基础模型这一快速发展的交叉领域提供了研究基础。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22049", "html_url": "https://arxiv.org/abs/2506.22049", "title": "GPAS: Gradient-Preserving Activation Scaling 通过保持梯度的激活缩放加速大语言模型预训练", "title_en": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling", "authors": "Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Lu Yin,Can Yang", "background": "现代大型语言模型，如LLaMA、Qwen和DeepSeek系列，主要采用预层归一化（Pre-LN）的Transformer架构。Pre-LN在预训练中表现出稳定性，并且能够扩展到大规模模型，但随着层数增加，激活方差呈指数增长，导致残差连接中的捷径路径成为主导，限制了深层层数的训练能力。", "innovation": "提出了保持梯度的激活缩放（GPAS），这是一种简单的方法，可以与现有技术结合使用。GPAS通过缩小中间激活值而不改变梯度来工作，从而保持激活信息完整，并避免了梯度缩小导致的梯度消失问题。广泛的实验表明，无论模型大小从71M到1B，GPAS都能带来一致的性能提升。GPAS不仅适用于改进Pre-LN Transformer，还显示出在改进Sandwich-LN和DeepNorm等其他架构方面的潜力，证明了其在多种训练动态环境中的广泛应用和适应性。", "conclusion": "实验结果表明，GPAS在包括71M到1B在内的不同模型规模上都能实现一致的性能提高。GPAS不仅能够增强Pre-LN Transformer，还能提高Sandwich-LN和DeepNorm等其他架构的表现，展现出其在多种训练环境中提高训练动态的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.17828", "html_url": "https://arxiv.org/abs/2506.17828", "title": "通过强化学习冷冻LLM：迭代重新加权然后优化方法", "title_en": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach", "authors": "Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong", "background": "通常需要使用如RLHF和DPO等微调方法来对大型语言模型（LLMs）进行人性化偏好的对齐。这些方法直接优化模型参数，存在不能在测试时间时改善模型性能的问题，或者在模型权重不可访问时不能适用。相比之下，测试时间方法通过利用奖励函数来引导和改进输出质量，而无需更新权重，但这会导致高昂的推理成本，并且基于可能不完美的奖励或价值函数的单次指导，往往导致次优输出。", "innovation": "本文提出了一种名为Iterative Reweight-then-Optimize (IRO) 的方法，这是一种强化学习框架，能够在不接触参数的情况下对（冻结）基模型进行RL风格的对齐。在训练过程中，每一轮迭代（i）从基模型中采样候选方案，（ii）使用当前的价值函数重新采样，并（iii）训练一个新的轻量级价值函数来指导下一轮解码过程。在测试阶段，使用价值函数通过基于搜索的优化过程来指导基模型生成。", "conclusion": "用户可以使用IRO对模型在自有数据集上进行对齐，类似于OpenAI的强化微调（RFT），而无需访问模型权重。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.06106", "html_url": "https://arxiv.org/abs/2502.06106", "title": "电路调优：一种用于识别参数冗余和细调神经网络的机理方法", "title_en": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks", "authors": "Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang", "background": "研究表明，机制可解释性旨在逆向工程模型以解释其行为。尽管最近的研究集中在模型中特定行为的静态机制上，但模型内部的学习动态尚未被充分探索。本文通过引入节点级固有维度的概念以及提出电路调优算法来分析学习机制。实验结果证实了节点级固有维度的存在，并证明了该方法的透明性和解释性细调的有效性。研究中展示了在调优前后电路的可视化和分析，提供了对神经网络学习过程中的自我组织机制的新见解。", "innovation": "本文提出了电路调优算法，这是一种两阶段算法，从特定任务逐步构建最小子图，并以启发式方式更新关键参数。该方法通过引入节点级固有维度的概念，提供了分析模型学习机制的新途径，展示了其在透明化和解释性细调方面的作用。", "conclusion": "实验结果证实了节点级固有维度的存在，并展示了电路调优方法在透明和解释性细调方面的有效性。通过视觉化调优前、调优中和调优后的电路，揭示了神经网络学习过程中的自组织机制。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21506", "html_url": "https://arxiv.org/abs/2506.21506", "title": "Mind2Web 2: 以代理作为评判者的评估代理型搜索", "title_en": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge", "authors": "Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su", "background": "代理型搜索例如深度研究系统，代理自主浏览互联网、合成信息并返回全面的参考文献支持的答案，代表了用户与规模性互联网信息交互方式的重大转变。虽然这种搜索方式有提高效率和减轻认知负担的潜力，但其日益复杂和开放式的特点已经超过了现有评估标准和方法，现有标准主要基于简短的搜索周期和静态答案假设。这项研究介绍了经过1000多小时人力资源构建的Mind2Web 2基准测试，包括130项真实、高质量且长期的任务，这些任务需要实时浏览网页和大量信息综合。", "innovation": "提出了一个新的“代理作为评委”的框架以应对时间变化和复杂答案的评估挑战。这一新方法基于树状结构的评分表设计构建任务特定的评委代理，自动评估答案的正确性和来源归属。研究还全面评估了10种前沿代理型搜索系统和人类表现，进行了详细错误分析，以提供未来开发的洞察。最佳系统OpenAI Deep Research在完成等效人类表现的50-70%同时仅需一半时间，显示了其巨大潜力。", "conclusion": "Mind2Web 2为开发和评测下一代代理型搜索系统提供了严格的基础。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12479", "html_url": "https://arxiv.org/abs/2506.12479", "title": "AI Flow: 视角、场景与方法", "title_en": "AI Flow: Perspectives, Scenarios, and Approaches", "authors": "Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li", "background": "由克劳德·香农奠基的信息理论和艾伦·图灵提出的机器智能愿景引领的IT/CT技术的共同发展，造就了一波未断的连接与计算浪潮。这种技术的协同作用带来了技术革命的高潮，人工智能（AI）的大模型正在重塑各个行业并重新定义人机协作。然而，普及智能的实现面临着巨大的挑战，包括大模型的资源消耗和高通信带宽需求。为了解决这些挑战，AI Flow作为多学科框架被引入，集成了最新的IT和CT技术进步，重点关注三个方面：一是基于设备-边缘-云框架，该框架将终端设备、边缘服务器和云集群整合起来，优化低延迟模型推理的可扩展性和效率；二是介绍了家族模型的概念，这是一个一系列具有对齐隐藏特征的不同规模模型的系列，可实现有效协作和适应各种资源限制和动态场景的灵活性；三是基于连接和交互的智能涌现，这为AI Flow提供了一种新的智能范式。利用通信网络增强连接性，实现了跨异构节点的AI模型之间的协同智能，这种智能超越了单一模型的能力。这些背景使得AI Flow成为了解决上述挑战的关键技术，为人工智能技术和通信系统的更紧密融合铺平了道路。", "innovation": "AI Flow作为一种多学科框架，通过整合设备-边缘-云框架、家族模型以及基于连接和交互的智能涌现等创新，解决了大规模AI模型的资源消耗和高通信带宽需求带来的挑战。它为智能应用提供了增强的智能、及时的响应能力和广泛的访问能力，为AI技术与通信系统的融合开辟了新路径。", "conclusion": "AI Flow为技术变革的未来奠定了坚实的基础，通过提供增强的智能、及时的响应能力和广泛的访问性，它预示着AI与通信系统融合的新时代。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01551", "html_url": "https://arxiv.org/abs/2507.01551", "title": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "title_en": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "authors": "Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua", "background": "过程强化学习（PRL）已经被证明能显著增强大型语言模型（LLMs）的推理能力。然而，引入附加的过程奖励模型带来了大量的计算开销，且缺乏统一的跨过程级别的奖励优势估算理论框架。", "innovation": "本文提出了自我引导的过程奖励优化（SPRO）框架，通过两个关键创新实现了这一目标：首先，理论上证明了过程奖励可以从策略模型本身中内在自洽地推导出来；其次，引入了明确定义的累积过程奖励以及掩蔽步骤优势（MSA），这为共享提示采样组内的逐步动作优势估计提供了严格的步骤方法。此外，SPRO在不增加任何额外计算开销的情况下，与传统的GRPO相比，提高了3.4倍的训练效率，并提高了17.5%的测试准确率。SPRO在整个训练过程中保持了稳定而增高的策略熵，同时也显著减少了平均响应长度，有效地防止了奖励作弊问题。", "conclusion": "实验结果表明，SPRO与传统的基于结果监督的RL方法相比，不但在训练效率和测试准确性上表现出明显优势，还能够维持较高的策略熵，减少响应长度，避免奖励作弊，且无需增加额外的计算开销，具备工业应用的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01548", "html_url": "https://arxiv.org/abs/2507.01548", "title": "使用汉字进行叙事桥梁构建：为老年移民群体进行人机共创工作坊", "title_en": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "authors": "Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen", "background": "本文探讨了老年人，特别是住在城市中的中国老年人如何通过使用人工智能辅助的合作创作来表达他们的个人故事。这些故事常常碎片化、被低估或难以用语言表达。研究人员在试点工作坊中结合口述故事和汉字象形重建，让参与者分享迁移历程中的记忆，并用人工智能大模型（LLM）推荐的夏篆字符和实物材料重新创造新的汉字形式。在整个过程中，参与者在人类引导和软性人工智能参与的支持下，将生活经历转换为视觉和触觉表达，无需数字技术素养。这种方法为人类与人工智能的合作和老年人的生活提供了新的视角，重新定义了人工智能的角色，并支持叙事代理权，使其在社会技术系统中发挥作用。", "innovation": "本研究创新地提出了一种利用人工智能辅助合作创作的方法，让老年人使用汉字表达个人故事。这种方法通过口述故事和汉字象形重建的结合，让老年人在人工智能的辅助下重新创造新的汉字形式，而无需具备数字技术知识。这种方法不仅为老年人提供了一个表达自我的平台，还为研究者提供了观察和理解老年人记忆的新视角，同时也为人工智能的未来应用提供了新的思路。", "conclusion": "本文通过 pilot 工作坊和人工智能辅助的生活叙事共创，为老年人及其记忆提供了新的表达方式。这种方法强调了人工智能在社会技术系统中的支持作用，而非内容生产者。研究结果为未来的人机协作和老年人生活提供重要启示，同时也为社会技术系统的理论和实证研究提供了新的思考基础。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02200", "html_url": "https://arxiv.org/abs/2507.02200", "title": "ESTR-CoT: 采用链式思考推理实现可解释且精确的事件流场景文本识别", "title_en": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning", "authors": "Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang", "background": "事件流基于场景文本识别是近年来的一个新研究热点，相比传统的RGB摄像头，在低光照、快速运动等极端场景下表现更佳。现有方法要么采用端到端的编码-解码框架，要么使用大规模语言模型增强识别，但仍然受限于解释不足和上下文逻辑推理能力弱的问题。", "innovation": "本文提出了一种基于链式思考推理的事件流场景文本识别框架，称为ESTR-CoT。该框架首次采用视觉编码器EVA-CLIP将输入事件流转换为tokens，并使用Llama标记器编码生成提示。Q-former用于将视觉tokens与预先训练的大规模语言模型Vicuna-7B对齐，并同时输出答案及其链式思考推理过程。此外，还提出了一大规模的CoT数据集，通过三阶段处理（生成、润色和专家验证）进行训练，为后续推理大规模模型的发展提供了坚实的数据基础。", "conclusion": "通过在三个事件流STR基准数据集（EventSTR、WordArt*、IC15*）上的广泛实验，全面验证了所提框架的有效性和解释性。源代码和预训练模型将在指定链接上发布。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02212", "html_url": "https://arxiv.org/abs/2507.02212", "title": "SciGA: 学术论文中设计图形摘要的全面数据集", "title_en": "SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers", "authors": "Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi", "background": "图形摘要（GAs）在科学论文中起着至关重要的视觉传达关键发现的作用。尽管最新的研究越来越依赖于如Figure 1这样的图形材料作为实质上的GAs，它们在科学交流中的潜在作用尚未得到充分研究。同时，有效设计GAs需要复杂的可视化技能，这成为其广泛采用的障碍。本文旨在解决这些挑战。", "innovation": "本文引入了SciGA-145k，这是一个包含约145,000篇科学论文和114万张图表的大规模数据集，专门用于支持GA的选择和推荐，并促进自动GA生成的研究。它定义了两个任务：1) 在同一论文内部进行GA推荐，根据文章内容确定适宜作为GA的图表；2) 在不同论文之间进行GA推荐，从其他论文中检索GA以激发创建新GA。还提出了衡量模型行为的新颖推荐指标CAR，针对传统排名指标的局限性，CAR能够细粒度地分析模型表现。", "conclusion": "SciGA-145k统一了这些任务和指标，为提高视觉科学交流奠定了基础，并有助于人工智能在科学中的发展。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02148", "html_url": "https://arxiv.org/abs/2507.02148", "title": "水下单目度量深度估计：现实基准和合成微调", "title_en": "Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning", "authors": "Zijie Cai,Christopher Metzler", "background": "单目深度估计方法近年来取得了显著进展，不仅提供了相对深度预测，还能进行度量深度预测。然而，在水下环境中，这些方法的可靠性受到光衰减、散射、颜色失真、浑浊和高质量度量地面真值数据缺乏等因素的限制。", "innovation": "本文构建了一个全面的基准测试，涵盖在具有度量深度标注的真实水下数据集（如FLSea和SQUID）上进行零样本和微调的单目度量深度估计模型的评价。研究发现，基于地球表面大规模数据（现实或合成）训练的模型，在水下环境中的表现较差，因为存在显著的领域转换。为解决这一问题，作者使用物理基础的水下图像生成模型生成了Hypersim数据集的合成水下变体版本，并在此基础上使用ViT-S Backbone编码器对Depth Anything V2模型进行了微调。实验结果表明，在所有基准测试中，微调后的模型都表现出一致的性能提升，并优于仅仅在干净的空气中的Hypersim数据集上训练的基本模型。研究还提供了详细的在水下场景中单目度量深度估计的评估和可视化，强调了领域适应和尺度感知监督在未来研究中实现稳健和通用的度量深度预测的重要性。", "conclusion": "研究证明了领域适应和尺度感知监督的重要性，并展示了一种在复杂水下环境中实现稳健和通用度量深度预测的方法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02222", "html_url": "https://arxiv.org/abs/2507.02222", "title": "高保真度差异信息驱动的二值视觉变换器", "title_en": "High-Fidelity Differential-information Driven Binary Vision Transformer", "authors": "Tian Gao,Zhiyuan Zhang,Kaijie Yin,Xu-Cheng Zhong,Hui Kong", "background": "二值视觉变换器（ViTs）为解决高计算/存储需求与边缘设备部署限制之间的折衷提供了一种颇有前景的方法。然而，现有的二值ViT方法通常会遭受严重的性能下降，或者大量依赖于全精度模块。已有研究尚未有效解决这些问题，导致二值ViT在保持检测精度的同时难以高效运行。", "innovation": "本文提出了DIDB-ViT，这是一种高效且高信息量的二值ViT，同时保留了原始ViT架构和计算效率。DIDB-ViT通过设计一个包含差异信息的注意力模块来减少量化造成的信息丢失，并增强高频保留。此外，采用了离散哈尔小波的频域分解方法，保留了二值Q和K张量之间的相似度计算精度。并且引入了改进的RPReLU激活函数，重构激活分布，增加模型的表示能力。这种设计使得DIDB-ViT能够在多个ViT架构中显著超越现有最先进的网络量化方法，尤其是图像分类和分割任务上具有更好的性能。", "conclusion": "实验结果表明，与现有的最先进的网络量化方法相比，DIDB-ViT在多个ViT架构中显著提升了图像分类和分割性能，同时保持了高计算效率和高信息量。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02205", "html_url": "https://arxiv.org/abs/2507.02205", "title": "团队RAS在第9届ABAW竞赛中的多模态复合表情识别方法", "title_en": "Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach", "authors": "Elena Ryumina,Maxim Markitantov,Alexandr Axyonov,Dmitry Ryumin,Mikhail Dolgushin,Alexey Karpov", "background": "复合表情识别（CER）是情感计算的一个子领域，旨在检测由基本情绪组合而成的复杂情感状态。以往的方法依赖于特定任务的训练数据进行训练，而在本研究中，作者提出了一种新颖的零样本多模态方法，将六种异构模态（静态和动态面部表达、场景和标签匹配、场景上下文、音频、文本）整合进单一管道。这种方法通过使用零样本组件来克服以往方法的限制，包括基于CLIP的标签匹配和Qwen-VL进行语义场景理解。此外，引入了多头概率融合（MHPF）模块对模态特定预测进行动态加权，并结合配对概率聚合（PPA）和配对特征相似性聚合（PFSA）方法生成可解释的复合情绪输出。通过跨多个数据集的训练评估，该方法在AffWild2、AFEW和C-EXPR-DB的数据集上表现出了可比的F1分数，展示了这种方法在无需领域适应的情况下捕捉复合情感的有效性。", "innovation": "本研究创新地提出了一种零样本多模态方法，通过整合六种异构模态并在单一管道中处理，同时引入多头概率融合模块和复合表达（CE）变换模块，改进了以往依赖特定任务数据训练的方法。", "conclusion": "该方法在多个数据集上的零样本测试中表现出了与监督方法相似的F1分数，证明了其在无需领域适应的情况下捕捉复合情感的有效性。研究的结果表明，提出的模型能够识别复杂的复合情感状态，适用于多种应用场景。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02250", "html_url": "https://arxiv.org/abs/2507.02250", "title": "FMOcc: TPV-驱动的基于流动匹配的选择性状态空间模型的3D占用率预测", "title_en": "FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model", "authors": "Jiangxia Chen,Tongyuan Huang,Ke Song", "background": "3D语义占用预测在自动驾驶中起着关键作用。然而，单一帧图像的固有限制和三维空间中的冗余性使得对于遮挡和远距离场景的预测准确率降低。当前的方法通过融合历史帧数据来提升性能，但需要额外的数据和大量的计算资源。", "innovation": "本文提出了一种名为FMOcc的Triperspective View (TPV)细化占用网络，结合流动匹配选择性状态空间模型，以实现基于少量帧的3D占用率预测。首先，设计了基于流动匹配模型的特征细化模块作为Flow Matching SSM模块（FMSSM），用于生成缺失的特征。其次，设计了TPV SSM层和平面选择性状态空间模块（PS3M），通过选择性过滤TPV特征来减少空气体素对非空气体素的影响，从而提高模型的整体效率和对远距离场景的预测能力。最后，设计了掩码训练（MT）方法来增强FMOcc的鲁棒性并解决传感器数据丢失的问题。实验结果表明，FMOcc在Occ3D-nuScenes和OpenOcc数据集上优于现有的方法。", "conclusion": "实验结果表明，我们的FMOcc在Occ3D-nuScenes验证数据集上达到了43.1%的RayIoU和39.8%的mIoU，使用OpenOcc数据集和5.4 G的推理内存、330ms的推理时间，实现了42.6%的RayIoU。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02265", "html_url": "https://arxiv.org/abs/2507.02265", "title": "飓风损害评估的多标签分类框架", "title_en": "Multi-Label Classification Framework for Hurricane Damage Assessment", "authors": "Zhangding Liu,Neda Mohammadi,John E. Taylor", "background": "飓风造成广泛的破坏，导致多样化的损害类型和严重程度，需要及时而准确的评估以进行有效的灾后应对。传统的单一标签分类方法无法捕捉到飓风灾后损害的复杂性，因此，需要一种新的多标签分类框架来利用航空图像评估损害类型。", "innovation": "提出了一种新的基于ResNet的功能提取模块和特定类别的注意力机制的多标签分类框架，该框架能够在一个图像中识别出多种损坏类型。使用来自飓风迈克尔的Rescuenet数据集进行实验，所提出的方法取得了90.23%的平均精确度，超越了现有基准方法。", "conclusion": "该框架增强了飓风灾后损害评估，使灾后应对更加针对性和高效，并为未来灾害减缓和韧性策略做出了贡献。该论文已被ASCE国际会议计算在土木工程中的应用（i3CE 2025）接收，最终版本将出现在会议官方汇编中。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02252", "html_url": "https://arxiv.org/abs/2507.02252", "title": "SurgVisAgent: 多模态代理模型用于灵活的手术视觉增强", "title_en": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement", "authors": "Zeyu Lei,Hongyuan Yu,Jinlin Wu,Zhen Chen", "background": "精确的外科干预对于患者的医疗安全至关重要，先进的增强算法已经开发出来帮助外科医生进行决策。尽管取得了显著的进步，这些算法通常仅为特定场景的具体任务而设计，这限制了它们在复杂真实世界情况下的有效性。", "innovation": "我们提出了SurgVisAgent，这是一种基于多模态大型语言模型（MLLMs）的端到端智能手术视觉代理。SurgVisAgent能够动态识别内窥镜图像中的失真类别及其严重程度，支持低光照增强、过曝纠正、运动模糊消除和烟雾去除等多种增强任务。为了实现对复杂手术场景的深刻理解，设计了先验模型提供特定领域的知识。通过上下文少量样本学习和链式思维（CoT）推理，SurgVisAgent能够为各种失真类型和严重程度提供定制化的图像增强，从而满足外科医生的多样需求。此外，还构建了一个模拟真实世界手术失真的全面基准，大规模实验表明SurgVisAgent超越了传统的单一任务模型，显示出其作为统一手术辅助解决方案的潜力。", "conclusion": "综上所述，SurgVisAgent通过动态识别和实时处理失真，实现了对复杂手术场景的灵活视觉增强，为外科医生提供了更加全面和专业的辅助，展现了其作为统一解决方案的巨大潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02270", "html_url": "https://arxiv.org/abs/2507.02270", "title": "MAC-Lookup: 多轴条件检索模型在水下图像增强中的应用", "title_en": "MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement", "authors": "Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen", "background": "水下图像由于光的变化、水中浊度和气泡等因素，面临着能见度和颜色问题。传统的基于先验的方法和基于像素的方法经常无法解决问题，而深度学习方法缺乏足够的高质量数据集。", "innovation": "提出了一种多轴条件检索（MAC-Lookup）模型，该模型通过改进颜色准确性、清晰度和对比度来提高视觉质量。它包括条件3D查找表颜色校正（CLTCC）进行初步的颜色和质量校正，以及多轴自适应增强（MAAE）进行细节精修。该模型在处理水下挑战时防止过度增强和饱和，并且实验结果表明，MAC-Lookup在恢复水下图像的细节和颜色方面优于现有方法。", "conclusion": "广泛的实验表明，MAC-Lookup模型在增强水下图像方面表现出色，能够比现有方法更好地恢复细节和颜色。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02268", "html_url": "https://arxiv.org/abs/2507.02268", "title": "基于双向域适应的跨域 hyperspectral 图像分类", "title_en": "Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation", "authors": "Yuxiang Zhang,Wei Li,Wen Jia,Mengmeng Zhang,Ran Tao,Shunlin Liang", "background": "传统的通过卫星或空中图像进行土地覆盖分类时，这些图像通常是来自不同地区或不同时期，同一类别的地物在不同场景中存在显著的光谱偏移。这使得跨域分类变得具有挑战性。该研究旨在利用高光谱遥感技术提取精细的土地覆盖类别，提出了一种双向域适应（BiDA）框架，以实现在独立适应空间中同时提取域不变特征和域特定信息，从而提高目标场景的适应性和可分性。", "innovation": "该研究提出的BiDA框架包括一个由源支路、目标支路和耦合支路组成的三路变压器架构，其中包含语义标记器。源支路和目标支路分别学习源域和目标域的自适应空间，耦合支路中的耦合多头交叉注意力机制用于特征交互和跨域相关性挖掘。此外，设计了双向蒸馏损失，利用跨域相关性指导自适应空间学习。最后，引入了一种自适应强化策略，以鼓励模型在噪声条件下专注于从源域和目标场景中提取特定的通用特征。实验结果表明，该方法在多个数据集上的性能显著优于一些最新的域适应方法，尤其是在跨时期树种分类任务中，比最先进方法高出3%至5%。代码可在指定网站下载。", "conclusion": "该研究提出了一种新的双向域适应框架（BiDA），该框架在跨域高光谱图像分类任务中展现了显著的优点，特别是在处理不同的时间和场景变化时表现更优。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02271", "html_url": "https://arxiv.org/abs/2507.02271", "title": "通过自我精练突出部分可见的电影语言以实现视频到音频生成", "title_en": "Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation", "authors": "Feizhen Huang,Yu Wu,Yutian Lin,Bo Du", "background": "视频到音频（V2A）生成在电影和视频后期制作中取得了显著进步。然而，当前的方法忽视了电影语言，这是电影制作中艺术表达的重要组成部分。因此，当声音目标仅部分可见时，它们的性能会下降。", "innovation": "本文提出了一种简单的自我精练方法，以扩展V2A模型至电影语言场景。通过模拟电影语言的变化，学生模型学习将训练数据对的视频特征与相同的视听对应关系对齐，从而能够有效地捕捉声音与部分视觉信息之间的关联。该方法不仅在所有评价指标下实现了显著改进，而且提升了大规模V2A数据集VGGSound上的表现。", "conclusion": "本文的方法不仅在所有评价指标下实现了显著改进，还提升了大型V2A数据集VGGSound上的表现。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02299", "html_url": "https://arxiv.org/abs/2507.02299", "title": "DreamComposer++：为3D内容生成赋予多视图条件的扩散模型", "title_en": "DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation", "authors": "Yunhan Yang,Shuo Chen,Yukun Huang,Xiaoyang Wu,Yuan-Chen Guo,Edmund Y. Lam,Hengshuang Zhao,Tong He,Xihui Liu", "background": "近年来，利用预训练的2D扩散模型从单张野外拍摄图像生成高质量的新视角变得可能。然而，由于缺乏多视角信息，现有研究难以生成可控的新视角。本文背景在于，为解决这一问题，提高现有的视角感知扩散模型的功能，研究人员提出了一个灵活且可扩展的框架DreamComposer++，通过集成多视角条件来改进现有模型。", "innovation": "DreamComposer++引入了一个视角感知的3D提升模块，用于从不同视角提取物体的3D表示。这些表示在多视角特征聚合模块中被聚合并渲染到目标视角的潜在特征中。最后，这些目标视角的特征被整合到预训练的图像或视频扩散模型中，用于新视角的合成。实验结果表明，DreamComposer++能够无缝地与最新的视角感知扩散模型结合，并增强其从多视角条件生成可控新视角的能力。这一进展促进了可控3D目标重建，并为多种应用提供了支持。", "conclusion": "DreamComposer++增强了一维感知扩散模型的能力，使其能够更好地生成多视角条件下的新视角，从而促进了可控3D物体重建和各种应用场景的实现。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02307", "html_url": "https://arxiv.org/abs/2507.02307", "title": "Flow-CDNet：一种用于检测时相图像中慢速和快速变化的新型网络", "title_en": "Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images", "authors": "Haoxuan Li,Chenxu Wei,Haodong Wang,Xiaomeng Hu,Boyuan An,Lingyan Ran,Baosen Zhang,Jin Jin,Omirzhan Taukebayev,Amirkhan Temirbayev,Junrui Liu,Xiuwei Zhang", "background": "变化检测通常涉及在相同地点拍摄的双时相图像之间识别变化区域。除了显著的变化外，双时相图像中的缓慢变化在实际场景中也很重要。例如，在斜坡、大坝和尾矿坝等场景中，缓慢变化往往是重大危害的前兆。因此，设计一个同时检测缓慢和快速变化的网络成为了一个新的挑战。本文旨在解决这一挑战。", "innovation": "本文提出了一个名为Flow-CDNet的变化检测网络，包含光流支路和二元变化检测支路两个分支。光流支路利用金字塔结构提取多尺度的位移变化，二元变化检测支路结合了ResNet网络和光流支路的输出以生成快速变化输出。除此之外，作者还构建了一个新的变化检测数据集Flow-Change，设计了一种新的损失函数（结合二元Tversky损失和L2范数损失）以及FEPE的评价指标。实验结果表明，该方法优于现有方法。进一步的消融实验验证了两个支路对检测性能的促进作用。", "conclusion": "定量实验在Flow-Change数据集上进行，证明了该方法优于现有的方法。消融实验进一步验证了两个分支对检测性能的提升作用。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02279", "html_url": "https://arxiv.org/abs/2507.02279", "title": "LaCo: 结构化中间层视觉标记高效压缩方法以优化跨模态大型语言模型", "title_en": "LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models", "authors": "Juntao Liu,Liqiang Niu,Wenchao Chen,Jie Zhou,Fandong Meng", "background": "现有的视觉标记压缩方法主要作为编译器后的模块运行，这限制了它们对效率提升的潜力。", "innovation": "提出了一种新的方法LaCo，它在视觉编码器的中间层中实现有效的标记压缩。LaCo包含两种核心组件：1) 层级像素转置机制，通过空间至通道变换系统性地合并相邻标记；2) 基于残差学习的架构，含有非参数化的快捷方式，用于在压缩过程中保留关键视觉信息。", "conclusion": "实验结果表明，与现有的方法相比，LaCo在视觉编码器的中间层压缩标记时表现出更优的效果；相较于外部压缩，我们的方法在训练效率上提高了超过20%，推理吞吐量提高了超过15%，同时保持了强劲的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02316", "html_url": "https://arxiv.org/abs/2507.02316", "title": "合成视频有用吗？一种以检索为中心的合成视频评估基准", "title_en": "Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos", "authors": "Zecheng Zhao,Selena Song,Tong Chen,Zhi Chen,Shazia Sadiq,Yadan Luo", "background": "当前，Text-to-video (T2V) 合成技术取得了快速进展，但在评估合成视频质量的方式上主要侧重于视觉质量和时间一致性，未能全面反映合成视频在如文本到视频检索（TVR）等下游任务中的性能表现。因此，目前的评估指标对于理解合成视频的实际用途帮助有限。", "innovation": "本文提出了 SynTVA 数据集和相应的评估基准，旨在评价合成视频在构建检索模型方面的实用性。首先，通过从 MSRVTT 训练分割中提取出的 800 个多样化的用户查询，利用当前最先进的 T2V 模型生成合成视频，并从四个关键语义对齐维度（对象与场景、动作、属性、提示保真度）对每对视频-文本进行标注。此外，还开发了一个自动评估器从现有指标估计对齐质量。此框架将总体视频质量评估与对齐得分关联起来，并检查其如何预测下游 TVR 的性能表现。", "conclusion": "实验结果表明，SynTVA 数据集是数据集扩增的一种有价值的工具，能够帮助选择高实用性的合成样本，这些样本可以实际提升 TVR 的结果。论文项目页面及数据集可访问：[此链接](this https URL)。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02294", "html_url": "https://arxiv.org/abs/2507.02294", "title": "ViRefSAM：用于遥感分割的视觉参考引导分割一切模型", "title_en": "ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation", "authors": "Hanbo Bi,Yulong Xu,Ya Li,Yongqiang Mao,Boyuan Tong,Chongyang Li,Chunbo Lang,Wenhui Diao,Hongqi Wang,Yingchao Feng,Xian Sun", "background": "分割一切模型（SAM）凭借其基于提示的范式，在通用分割任务中展示了强大的泛化能力。然而，将其应用于遥感（RS）图像仍然面临两大挑战：一是手动为每张图像构建精确提示（如点或框）效率低下，尤其在RS场景中存在密集的小对象或空间碎片分布时；二是SAM缺乏领域适应性，因为它主要是在自然图像上进行预训练，难以捕捉RS特有的语义和空间特征，尤其是在分割新型或未见过的类别时。这两个问题限制了SAM在RS图像分割中的实际应用效果和效率。", "innovation": "鉴于上述挑战，本文受少样本学习的启发，提出了一种名为ViRefSAM的新框架，该框架仅利用少数标注的参考图像来引导SAM。具体创新点包括两个核心组件：1）一种视觉上下文提示编码器，该编码器从参考图像中提取类别特定的语义线索，并通过与目标图像的上下文互动生成对象意识提示；2）一种动态目标对齐适配器，它嵌入到SAM的图像编码器中，通过注入类别特定的语义信息来缓解领域差距，使SAM能够动态地聚焦于相关任务区域。实验结果表明，ViRefSAM能够利用少量的参考图像准确且自动地分割未见过的类别，并且在多种少样本分割基准测试中均优于现有方法，表现出良好的泛化能力和领域适应性。", "conclusion": "本文通过引入ViRefSAM，解决了SAM在遥感图像分割中的主要挑战，即需要手动构建精确提示和缺乏领域适应性。实验结果验证了ViRefSAM的有效性，通过仅使用少量参考图像即可实现准确且自动的未见过类别的分割。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02311", "html_url": "https://arxiv.org/abs/2507.02311", "title": "感知激活器：一种直观且便携的大脑认知探索框架", "title_en": "Perception Activator: An intuitive and portable framework for brain cognitive exploration", "authors": "Le Xu,Qi Zhang,Qixian Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao", "background": "近年来，大脑-视觉解码技术取得显著进展，能够以高保真度从人类视觉皮层的功能磁共振成像（fMRI）活动中重建所感知的视觉刺激。大多数现有方法采用两层策略解码脑信号，即像素级和语义级。然而，这些方法在逐像素对齐方面依赖性较强，但语义对齐不充分且缺乏细粒度语义对齐，导致在重建多个语义对象时出现显著的失真。", "innovation": "该研究开发了一个实验框架，使用fMRI表征作为干预条件，通过交叉注意力机制将这些表征注入多尺度图像特征，进而比较在包含和不包含fMRI信息的情况下，对于对象检测和实例分割任务的下游性能及中间特征变化。研究结果证明，集成fMRI信号能提升下游检测和分割的准确性，显示fMRI包含丰富的跨对象语义线索和粗略的空间定位信息，是当前模型尚未全面利用和整合的元素。", "conclusion": "实验结果表明，将fMRI信号纳入多尺度图像特征的处理流程中，能够提升下游检测和分割任务的准确性。这证实了fMRI中包含丰富的语义对象线索和粗略的空间定位信息，这对当前的解码模型具有补充和改进空间。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02308", "html_url": "https://arxiv.org/abs/2507.02308", "title": "LMPNet用于弱监督关键点发现", "title_en": "LMPNet for Weakly-supervised Keypoint Discovery", "authors": "Pei Guo,Ryan Farrell", "background": "本文探索仅通过类别标签弱监督的语义对象关键点发现任务。为此，通过将鉴别训练的中间层滤波器转换为关键点检测器来实现这一目标。研究者注意到关键点检测器有三个优选特征：（i）空间稀疏激活，（ii）一致性，（iii）多样性。这种方法不同于依赖手工制作的损失项，而是提出了一种新颖的计算效率高的泄漏最大池化（LMP）层，以明确地鼓励最终卷积层滤波器学习与对象关键点良好对齐的“非可重复局部模式”。视觉观察结果启发了一个简单而有效的选择策略，确保一致的滤波器激活，并通过注意力掩码来强制网络在对象的整个区域上分布其注意力，而不是仅仅集中在最具辨别力的区域上。最后，本文提出了一种可学习聚类层来将关键点提议分组为关键点预测。", "innovation": "本文的核心创新是提出了一种新颖的计算效率高的泄漏最大池化（LMP）层，以及一种通过聚类层进行可学习聚类来将关键点提议分组为关键点预测的方法。这种方法不需要依赖手工制作的损失项，并通过使用泄漏最大池化层鼓励学习“非可重复局部模式”，这有助于提高关键点的发现精度。此外，结合第一个学习的比例检查点层和细化掩码，直接操作网络滤波器以检测预定义的概念，最终模型具有高度可解释性，同时在姿态变化下能自动生成鲁棒的关键点，并且预测准确性与监督式姿态估计模型相当，从而证明了该方法的有效性。这项研究解决了在仅类别标签的情况下进行弱监督关键点发现的挑战，提供了一种新的、有效的解决方案，提升了该领域的技术进步。", "conclusion": "实验结果表明，LMPNet能够在姿态变化下自动生成鲁棒性关键点，并且在预测准确性方面与监督式姿态估计模型相当。这种新方法通过直接操作网络滤波器，不仅具有高度可解释性，而且能够很自然地学习和提取关键点，从而显著改善了关键点发现的效果。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02321", "html_url": "https://arxiv.org/abs/2507.02321", "title": "倾听内心的声音：通过中间特征反馈调整ControlNet训练", "title_en": "Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback", "authors": "Nina Konovalova,Maxim Nikolaev,Andrey Kuznetsov,Aibek Alanov", "background": "尽管在文本到图像扩散模型方面取得了显著进展，但在生成输出的精确空间控制方面仍面临挑战。ControlNet通过引入辅助条件模块解决了这一问题，而ControlNet++则通过在最终去噪步骤应用循环一致性损失进一步提高了对齐效果。然而，这种方法忽视了中间生成阶段，限制了其有效性。", "innovation": "我们提出了InnerControl，这是一种训练策略，要求在整个扩散步骤中保持空间一致性。我们的方法训练轻量级卷积探测器，在每个去噪步骤中从中间UNet特征重构输入控制信号（例如边缘、深度）。这些探测器即使从高度噪声的潜在变量中也能高效提取信号，使我们能够提供伪真实控制以进行训练。通过在整个扩散过程中最小化预测条件与目标条件之间的差异，我们的对齐损失改进了控制精度和生成质量。结合ControlNet++等现有技术，InnerControl在多种条件方法（例如边缘、深度）上均达到了最先进的性能。", "conclusion": "我们的方法改进了ControlNet和ControlNet++的性能，并且通过在整个扩散过程中保持空间一致性和提供伪真实控制，InnerControl在各种条件方法上达到了最先进的生成质量。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02349", "html_url": "https://arxiv.org/abs/2507.02349", "title": "两步神经网络用于自动脑血管关键点检测", "title_en": "Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection", "authors": "Rafic Nader,Vincent L'Allinec,Romain Bourcier,Florent Autrusseau", "background": "颅内动脉瘤（ICA）通常发生在Willis圆（CoW）的特定分支点，主要是在十三个主要动脉分支处。准确地检测这些关键部位对于及时和高效的诊断至关重要。本文提出了一种使用两步神经网络过程的全自动分支点定位方法，以解决由于两个分支点距离过近且视觉特征相似而导致的误检问题，特别是在处理完整的MRA时间飞行（TOF）数据时。此外，还考虑到Willis圆的解剖变异，影响每次扫描可检测到的关键点数量。该方法通过用两步法进行评估，确保它能在检测分支点的任务中实现最佳性能。", "innovation": "提出了一种使用两步神经网络方法的全自动Willis圆分支点定位方法。第一阶段使用对象检测网络识别感兴趣区域（ROI），第二阶段使用修改后的U-Net并结合深度监督来精确定位分支点。这种方法解决了由于两个分支点距离过近且视觉特征相似而导致的误检问题，特别是在处理完整的MRA时间飞行（TOF）数据时。此外，该方法还考虑了Willis圆的解剖变异，这影响了每次扫描可检测到的关键点数量。", "conclusion": "通过评估使用我们方法和我们的内部数据集以及一个公共数据集的数据，实验结果表明，我们的方法在分支点检测任务中实现了最佳性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02314", "html_url": "https://arxiv.org/abs/2507.02314", "title": "MAGIC：基于掩码的多级扰动和语境感知对齐扩散补丁生成方法", "title_en": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation", "authors": "JaeHyuck Choi,MinJun Kim,JeHyeong Hong", "background": "在工业质量控制场景中，少量的异常数据限制了模型的表现。理想中的生成器需要同时满足三个条件：保持正常的背景内容完整、填充异常区域时紧密匹配给定的异常掩码、在语义合理的位置生成异常区域，同时还能从少量的真实样本中产生多样且真实的外观。现有基于扩散的方法通常只能同时满足这三个条件中的两个。全球异常生成器可能会破坏背景，而掩码导向的方法往往在掩码不准确或位置错误时表现不佳。Magic解决了以上所有问题。", "innovation": "Magic 提出了一个基于稳定的扩散补丁生成模型，通过多级扰动和语境感知对齐来解决异常生成问题。具体创新包括：在保持正常区域完整的同时，确保合成的异常严格遵守提供的掩码，直接解决了背景破坏和对齐问题；引入了两种互补的扰动策略——在微调和推理过程中应用高斯提示级扰动策略，它扩展了异常的全局外观，避免低保真度的文字表示；另一种是掩码导向的空间噪声注射，丰富了局部纹理变化，以补偿微调可能造成的多样性的损失；语境感知的掩码对齐模块建立了语义对应关系并重新定位掩码，使每个异常都合理地包含在主体对象内，消除了超出边界的伪影。", "conclusion": "在 MVTec-AD 数据集上，Magic 在下游异常检测任务中超过了之前的状态最先进水平，显示了其在处理少量异常样本时的有效性和适用性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02354", "html_url": "https://arxiv.org/abs/2507.02354", "title": "基于YOLOv8n的轻量级虾病检测研究", "title_en": "Lightweight Shrimp Disease Detection Research Based on YOLOv8n", "authors": "Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao", "background": "虾类养殖中的疾病是造成经济损失的主要原因之一。为了预防疾病传播并提高智能检测效率，本文提出了基于YOLOv8n的轻量级网络架构。", "innovation": "1. 设计RLDD检测头和C2f-EMCM模块，减少计算复杂性，保持检测准确性，提高计算效率。\n2. 引入改进的SegNext_Attention自注意力机制，进一步增强模型的特征提取能力，提高疾病特征识别的精确度。\n3. 在自建的虾类疾病数据集和URPC2020数据集上进行了广泛的实验，包括 ablation 研究和比较评估。", "conclusion": "提出的模型在参数减少32.3%的情况下，实现了mAP@0.5为92.7%（相较于YOLOv8n提升3%）的检测效果，优于其他轻量级YOLO系列模型。通用性实验进一步验证了模型的鲁棒性，mAP@0.5提高了4.1%。这项研究实现了准确性和效率的最优平衡，为虾类养殖中的智能疾病检测提供了可靠的技术支持。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02288", "html_url": "https://arxiv.org/abs/2507.02288", "title": "基于语言指导和表示对齐的提示解耦以实现域泛化", "title_en": "Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization", "authors": "De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao", "background": "域泛化（DG）旨在开发一种通用模型，使其能够在未见过的目标域中有效运行。近年来，预训练视觉基础模型（VFMs）如CLIP的进展显示了增强深度学习模型泛化能力的潜力。尽管基于VFMs的域提示调整在DG领域引起了越来越多的关注，但设计能够跨多种域分离不变特征的有效提示仍然是一个重要挑战。现有方法主要依赖语言来指导视觉特征的分离，但这种方法存在局限性，因为视觉特征有时太过复杂或微妙，难以完全被描述性文本捕获。本文介绍了一种新颖的方法，首先利用大型语言模型自动解耦文本提示，然后利用解耦后的文本特征学习引导跨域不变的视觉表示。为了进一步解决这个问题，引入了最坏显式表示对齐（WERA），通过引入额外的抽象提示来扩展基于文本指导的视觉提示，同时通过对齐约束确保视觉表示在原始分布和增强分布之间的一致性。实验结果表明，本文提出的模型在主要的DG数据集（包括PACS、VLCS、OfficeHome、DomainNet和TerraInc）上优于最先进的DG方法。", "innovation": "本文提出了一种新颖的框架，通过利用大型语言模型自动解耦文本提示，然后利用解耦后的文本特征学习引导跨域不变的视觉表示。为了进一步解决视觉特征分离的局限性，引入了最坏显式表示对齐（WERA），通过引入额外的抽象提示来扩展基于文本指导的视觉提示，同时通过对齐约束确保视觉表示在原始分布和增强分布之间的一致性。", "conclusion": "实验结果表明，本文提出的方法在主要的DG数据集上优于最先进的DG方法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02217", "html_url": "https://arxiv.org/abs/2507.02217", "title": "理解条件合成数据时的权衡", "title_en": "Understanding Trade offs When Conditioning Synthetic Data", "authors": "Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma", "background": "在工业视觉系统中，仅从少数几张图片学习稳健的目标检测器是一个关键挑战，因为高质量的训练数据收集可能需要几个月的时间。合成数据作为一种数据高效的视觉检测和拾放机器人解决方案已成为关键手段。现有的方法依赖Blender或Unreal等3D引擎，虽然提供了精细控制，但仍需数周时间渲染少量数据集，且生成的图像与现实之间的差距仍然较大。扩散模型承诺了显著提升，可在几分钟内生成高质量图像，但低数据条件下精确控制仍然困难。尽管现在许多适配器已将扩散模型应用到文本提示之外，但不同调节方案对合成数据质量的影响尚不明确。本文研究了四种标准目标检测基准中的80种多样化视觉概念，并比较了两种调节策略：提示调节和布局调节。当条件提示较少时，提示调节提供更高的合成数据质量；随着多样性的增加，布局调节逐渐变得更好。当布局提示匹配完整的训练分布时，合成数据相比单独使用实际数据将平均提升34%的平均精度毫立佰分，最高可提升177%。", "innovation": "本文探讨并比较了两种合成数据调节策略——提示调节和布局调节，在不同类型和数量的视觉概念下，评估了它们的效果。结果表明，在数据稀缺的情况下，提示调节在质量上表现更好，而布局调节在多样性增加时效果更优。特别是在布局信息与训练分布匹配时，合成数据的质量显著提升，相比仅使用真实数据时的平均精度提升了34%，最高可达177%。这一研究结果对于提高合成数据的质量和效率具有重要意义。", "conclusion": "当条件提示较少时，提示调节提供了更好的合成数据质量；然而随着多样性的增加，布局调节的优势显现出来。特别是在布局信息能够匹配完整训练分布时，合成数据能显著提高平均精度，相比仅使用真实数据时能提高34%，最多提高至177%。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02358", "html_url": "https://arxiv.org/abs/2507.02358", "title": "Holistic Tokenizer for Autoregressive Image Generation", "title_en": "Holistic Tokenizer for Autoregressive Image Generation", "authors": "Anlin Zheng,Haochen Wang,Yucheng Zhao,Weipeng Deng,Tiancai Wang,Xiangyu Zhang,Xiaojuan Qi", "background": "传统的自回归图像生成模型逐步生成视觉令牌，这限制了对令牌序列之间全局关系的捕捉能力。大多数视觉令牌化器将局部图像块映射到潜在令牌，但这种方式限制了全局信息的捕获。因此，现有模型尚不能充分地进行图像生成并保持图像的整体性。", "innovation": "本文介绍了一种名为Hita的全新的自注意力图像令牌化器，用于自回归图像生成。Hita引入了一种全局到局部的令牌化方案，使用可学习的全局查询和局部图块令牌。此外，Hita增强了与自回归生成过程的对齐度：1)通过将全局令牌放在序列结构的开头，然后再是图块级别的令牌，并使用因果注意力来保持对先前令牌的意识；2)在解码器之前，Hita采用了一个轻量级融合模块来控制信息流，优先考虑全局令牌。通过广泛的实验验证，与传统的令牌化器相比，Hita不仅加速了自回归生成器的训练，还提高了在ImageNet基准集上的性能，获得了2.59 FID和281.9 IS的优异结果。", "conclusion": "Hita通过引入可学习的全局查询和局部图块令牌，以及增强与自回归生成过程的对齐度，有效提升了图像生成的质量和全局信息的捕捉能力。实验结果表明，Hita在ImageNet基准集上实现了更好的生成效果，同时其在零样本风格迁移和图像补全任务中也表现出了良好的效果。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02398", "html_url": "https://arxiv.org/abs/2507.02398", "title": "超越空间频率：基于像素级时间频率的深度伪造视频检测", "title_en": "Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection", "authors": "Taehoon Kim,Jongwook Choi,Yonghyun Jeong,Haeun Noh,Jaejun Yoo,Seungryul Baek,Jongwon Choi", "background": "传统的空间频率基检测方法通过在帧间堆叠空间频率谱来表示时间信息，但这种方法往往忽视了像素层面的时间不一致现象，导致无法有效检测出时间上的伪造痕迹。", "innovation": "该方法利用了一维傅里叶变换的时间轴对每个像素进行处理，提取出对时间不一致特别敏感的特征，特别是在容易出现不自然移动的区域。此外，引入了一个端到端训练的注意力提案模块精准定位包含时间伪造痕迹的区域。同时，联合 transformer 模块有效地整合了像素级时间频率特征与时空上下文特征，提升了检测伪造的范围和准确性。", "conclusion": "该框架在深度伪造视频检测领域取得了显著进步，提供了在多种复杂场景下的稳健性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02322", "html_url": "https://arxiv.org/abs/2507.02322", "title": "基于神经网络的水稻叶片病害识别与分类研究：基于特征模型与直接成像模型的比较分析", "title_en": "Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model", "authors": "Farida Siddiqi Prity,Mirza Raquib,Saydul Akbar Murad,Md. Jubayar Alam Rafi,Md. Khairul Bashar Bhuiyan,Anupam Kumar Bairagi", "background": "水稻叶部病害显著降低了产量并造成经济损失，因此需要早期检测以实现有效管理并提高产量。本研究利用人工神经网络（ANN）基于图像处理技术提出了一种及时分类和识别水稻病害的方法。目前虽然直接输入水稻叶片图像到ANN是常用的处理方式，但缺乏对特征分析检测模型（FADM）与直接成像检测模型（DICDM）的全面比较分析，特别是在特征提取算法（FEAs）的有效性评估上。因此，该研究通过实验建立并对比了这两种模型，利用了不同的特征提取算法、维度降维算法（DRAs）、特征选择算法（FSAs）和极端学习机（ELM）进行评估。实验数据包括了细菌性条斑病、褐斑病、稻瘟病、稻稻叶枯病、鞘腐病和健康叶片。结果表明，特征分析检测模型表现最佳。", "innovation": "本研究采用了基于特征分析的模型和直接成像模型进行对比，并通过多种特征提取算法、维度降维算法和特征选择算法进行了实证研究，强调了特征分析的重要性，并提出了一个有效检测水稻叶部病害的方法。", "conclusion": "实验结果显示，特征分析检测模型在分类水稻叶部病害方面表现最佳。所提出的基于特征分析的模型具有改进作物健康、减少产量损失和提高水稻种植的整体生产率和可持续性的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02393", "html_url": "https://arxiv.org/abs/2507.02393", "title": "PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection", "title_en": "PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection", "authors": "Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho", "background": "单目3D物体检测（M3OD）长期以来受到数据稀缺的挑战，这主要是由于注释成本高昂以及固有的2D到3D的不明确性。尽管已经提出了一些弱监督方法和伪标签方法来解决这些问题，但这些方法大多局限于特定领域的学习，或者仅依赖单一观察中的形状信息。为了解决这些限制，本文提出了一种新的伪标签框架，仅需使用视频数据，无需多视角设置、额外传感器、摄像头姿态或特定领域内的训练。该方法通过在时间相邻帧中使用目标点追踪技术聚合静态和动态对象的伪LiDAR，从而在无法获取3D数据的情况下提取3D属性。", "innovation": "本文提出了一种新的伪标签框架，通过使用视频数据进行目标点追踪，聚合静态和动态对象的伪LiDAR，从而在无需多视角设置等复杂条件下，实现3D属性的提取，提高单目3D物体检测的可靠性和可扩展性，特别是在3D数据获取不可行的情况下。这种方法比现有方法更加稳健和适用，解决了单一观察和多视角设置的限制，适用于M3OD的实用和高效解决方案.", "conclusion": "通过大量实验，本文方法展示了可靠的准确性和强大的可扩展性，使其实现3D物体检测的一个实用和有效的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02373", "html_url": "https://arxiv.org/abs/2507.02373", "title": "UVLM：用于海底世界理解的视频语言模型基准", "title_en": "UVLM: Benchmarking Video Language Model for Underwater World Understanding", "authors": "Xizhe Xue,Yang Zhou,Dawei Yan,Ying Li,Haokui Zhang,Rong Xiao", "background": "近年来，大规模语言模型（LLMs）取得的显著成功对人工智能领域产生了深远影响。基于LLMs的多种先进工作被应用于各种场景中，其中视频语言模型（VidLMs）特别广泛使用。然而，现有的工作主要集中在陆地场景，忽略了潜水观察中对高度需求的应用需求。为填补这一空白，我们引入了UVLM这一水下观察基准，它通过结合人类专业知识和AI模型的协作方法构建。为了确保数据质量，我们从多个角度进行了深入考虑：首先，为了解决水下环境的独特挑战，我们选择包括光照变化、浑浊度和多种视角的视频来构建数据集；其次，为了保证数据多样性，数据集覆盖了广泛的帧率、分辨率以及419类海洋生物和各种静态植物与地形；然后，为了任务多样性，我们采用了结构化设计，将观察目标分为生物和环境两大类，每类包括内容观察和行为/变化观察，共计20种不同的任务类型；最后，我们设计了若干具有挑战性的评价指标，以实现不同方法的数量和质量比较和分析。实验结果表明，在UVLM上微调VidLMs显著改善了对水下世界的理解，同时也展示了在现有的在空VidLM基准（例如VideoMME和Perception text）上实现小幅改进的潜力。该数据集和提示工程将被公开发布。", "innovation": "我们提出了UVLM，这是一个基于结合人类专业知识和AI模型的协作方法构建的水下观察基准。为了确保数据质量，设计了一个着眼于水下环境的独特挑战的数据集，包括光照变化、水浑浊度和多种视角；该数据集覆盖广泛的帧率、分辨率、419类海洋生物和各种静态植物与地形。我们采用了结构化设计，并引入了多种具有挑战性的评价指标，以便进行不同方法的数量和质量比较分析。此外，该方法展示出在现有在空VidLM基准上的潜力提升。整个数据集未来将对公众开放。", "conclusion": "实验结果显示，在UVLM中微调VidLMs显著提升了对水下世界理解的能力，并且在VideoMME和Perception text等现有基准上也表现出一定的改进潜力。未来，该数据集和提示工程将被公开分享。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02403", "html_url": "https://arxiv.org/abs/2507.02403", "title": "非都市环境中使用自我监督学习进行野生动物目标再识别", "title_en": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings", "authors": "Mufhumudzi Muthivhi,Terence L. van Zyl", "background": "野生动物再识别旨在跨不同观察匹配同一物种的个体。当前最先进的模型依赖于分类标签以训练监督模型。大量的标注数据驱动了对大规模野生动物数据集的整理。本次研究探讨了在非监督环境中使用自我监督学习进行野生动物再识别的可能性。研究通过自动化方法从相机陷阱数据中提取个体的两张视图，并在这种视图上训练自我监督模型，从而能够从视频数据的无限流中学习特征。", "innovation": "提出了一种新的方法，利用视频数据流中的时间图像对自动提取个体的两张视图，通过自我监督学习方法进行特征学习。这种方法能够适应开放场景和各种野生动物任务的下游应用，证明了自我监督特征在数据量有限时仍然能超越监督特征的效果，并且在所有下游任务中表现出更好的性能。该研究为野生动物个体识别提供了一种新的无监督学习方法，减少了对大量标注数据的依赖。", "conclusion": "实验结果表明，自我监督模型即使在数据有限的情况下也更加稳健，自我监督特征在整个下游任务中均优于监督特征。研究的代码已公开。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02363", "html_url": "https://arxiv.org/abs/2507.02363", "title": "LocalDyGS：通过自适应局部隐式特征分解实现多视角全局动态场景建模", "title_en": "LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling", "authors": "Jiahao Wu,Rui Peng,Jianbo Jiao,Jiayu Yang,Luyang Tang,Kaiqiang Xiong,Jie Liang,Jinbo Yan,Runling Liu,Ronggang Wang", "background": "在现实世界中，由于存在复杂的动态运动，从多视角输入合成任意视角下的动态视频是一项挑战。现有的基于神经光线场或3D 高斯插值的方法仅限于建模细粒度的运动，极大地限制了它们的应用范围。因此，如何更好地建模大规模和细粒度的动态场景成为了一个研究热点。", "innovation": "我们提出了LocalDyGS，一种新的动态场景重建框架，通过两个部分来适应大规模和细粒度的运动场景：1）通过种子定义的流线型局部空间对复杂动态场景进行分解，使全局建模可以通过捕捉每个局部空间内的运动来实现；2）将静态和动态特征解耦应用于局部空间的运动建模，其中共享的时间步骤静态特征捕捉静态信息，动态剩余场提供时间特定特征，结合并解码生成时间高斯体，建模每个局部空间内的运动。", "conclusion": "本方法不仅在各种细粒度数据集上展示了与目前最先进的方法相当的性能，而且还首次尝试建模更大和更复杂的动态场景，实现了更真实的地动态场景重建。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02414", "html_url": "https://arxiv.org/abs/2507.02414", "title": "基于打包的保留隐私的面部识别预选", "title_en": "Privacy-preserving Preselection for Face Identification Based on Packing", "authors": "Rundong Xin,Taotao Wang,Jin Wang,Chonghe Zhao,Jing Wang", "background": "由于隐私保护的需求日益增长以及恢复原始面部数据的风险，面向密文域的面部识别系统受到了广泛关注。然而，随着密文模板库的不断扩大，面部检索过程变得越来越耗时。鉴于此挑战，本文基于密文域提出了一个高效的新方案，即基于打包的保留隐私的面部识别预选（PFIP），此方案旨在减少计算开销并增强生物特征系统的灵活性，尤其是在注册阶段。实验结果表明，PFIP在检索1000个密文面部模板时在300毫秒内实现了100%的命中率，同时保持了原面部识别模型的准确性。与现有方法相比，PFIP在检索效率方面几乎提高了50倍。", "innovation": "PFIP引入了一种创新的预选机制以减少计算开销，并设计了打包模块以提高生物特征系统在注册阶段的灵活性。该方案在保证面部识别准确性的前提下，显著提高了检索效率。", "conclusion": "实验结果显示，PFIP在合理的时间内实现了高精度的面部检索，具有很高效率和实用性，相比现存方法有着极大的改进。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02408", "html_url": "https://arxiv.org/abs/2507.02408", "title": "一种利用热传感器进行实时多目标追踪的新调参方法及其复杂运动模式", "title_en": "A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern", "authors": "Duong Nguyen-Ngoc Tran,Long Hoang Pham,Chi Dai Tran,Quoc Pham-Nam Ho,Huy-Hung Nguyen,Jae Wook Jeon", "background": "热成像在监视系统中至关重要，特别是在低可见度或不良照明的环境中，热传感器因能捕捉红外签名而提高了识别任务的效果，但其低级别的特征表示使得准确检测和追踪行人变得困难。现有方法在处理热成像中的复杂运动模式时存在一定挑战。", "innovation": "本文提出了一种针对热成像中复杂运动模式的新调参方法，旨在优化行人追踪的两个阶段，通过针对实时追踪调参，这种方法在不依赖于复杂的重新识别或运动模型的情况下实现了高精度。", "conclusion": "该方法在PBVS Thermal MOT数据集上的广泛实验表明，其在各种热像仪条件下都表现出高度的效用，为实际监视应用提供了一个稳健的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02443", "html_url": "https://arxiv.org/abs/2507.02443", "title": "红葡萄检测中加速的人工神经网络在FPGA的可编程逻辑", "title_en": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic", "authors": "Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias", "background": "机器人在搬运过程中通常会减慢速度以检测物体，而且机器人相机的帧率设置较低以追踪检测算法的速度。这在执行任务和探索时受到约束，增加了任务执行时间。AMD开发了Vitis-AI框架将检测算法部署到FPGAs中，但并未充分利用FPGAs的可编程逻辑(PL)部分。", "innovation": "本文使用FINN架构将三个ANN模型（MobileNet v1，CNV、1-bit量化和2-bit量化）部署到FPGA的PL中，并在RG2C数据集上进行训练。MobileNet v1表现最好，达到了98%的成功率和6611 FPS的推理速度。证明了可以利用FPGAs加速ANNs并使它们适用于注意力机制.", "conclusion": "通过利用FPGAs的PL部分加速ANNs，实现了显著的推理速度提升，并探索了它们在机器人感知中的应用潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02399", "html_url": "https://arxiv.org/abs/2507.02399", "title": "TABNet: 基于三重增强自我恢复框架和边界感知伪标签的医学图像分割", "title_en": "TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation", "authors": "Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang", "background": "医学图像分割是各种临床应用的核心任务。然而，获取大型、完全注释的医学图像数据集既耗时又昂贵。笔记标注作为一种稀疏标注形式，为医学图像分割提供了高效的、成本效益高的替代方案，但在稀疏标注限制了目标区域的功能学习并缺乏足够的边界监督，给训练分割网络带来了巨大挑战。", "innovation": "我们提出了一种新颖的弱监督医学图像分割框架——TAB Net，包括两种关键模块：三重增强自我恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过三种互补增强策略（强度变换、剪辑块、拼图增强）增强了特征学习；BAP模块通过融合双分支预测为损失加权伪标签，并引入边界感知损失以实现细粒度轮廓精修，提升了伪监督精度和边界建模能力。实验结果表明，TAB Net 在基于笔记标注的弱监督分割上显著优于最先进的方法，并实现了与全监督方法相当的表现。", "conclusion": "实验评估表明，TAB Net 在 ACDC 和 MSCMR seg 两个公开数据集上显著优于最先进的基于笔记标注的弱监督分割方法，并实现了与全监督方法相当的表现。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02416", "html_url": "https://arxiv.org/abs/2507.02416", "title": "使用深度学习框架确定结构裂缝", "title_en": "Determination Of Structural Cracks Using Deep Learning Frameworks", "authors": "Subhasis Dasgupta,Jaydip Sen,Tuhina Halder", "background": "结构裂缝检测对于公共安全至关重要，因为这有助于预防可能威胁生命的潜在结构失败。由不经验丰富的人员手工检测裂缝可能会导致信息滞后、不一致和人为错误，从而影响评估的可靠性。", "innovation": "本研究通过提出一种新的深度学习架构来解决上述挑战，旨在提高结构裂缝检测的准确性和效率。该研究利用了多种残差U-Net模型配置，并将其与包含卷积块的元模型进行集成。这种独特组合的目的是通过模型互补，提高预测效率。实验结果表明，残差U-Net模型在低分辨率图像上表现优于传统的SegNet和U-Net，而集成模型则超越了个体模型的性能，显示出更高的有效性。评估使用了交集并集比(IoU)指标和DICE系数。", "conclusion": "集成模型获得了最高的评分，表明其具有更高的准确性。这一进展为在结构缺陷监控任务中开发更可靠的自动化系统提供了可能的路线图。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02395", "html_url": "https://arxiv.org/abs/2507.02395", "title": "Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis", "title_en": "Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis", "authors": "Byung Hyun Lee,Wongi Jeong,Woojae Han,Kyoungbun Lee,Se Young Chun", "background": "多实例学习（MIL）通过使用包含弱标签的图像包（bag）来显著降低大规模图像（如组织学全切片图像（WSI））的标注成本。然而，MIL在持续学习任务中的适应性研究较少，特别是在实例分类和定位方面。尽管针对自然图像的语义分割进行了弱增量学习的研究，但这种方法对MIL定位的适应性似乎不可行，因为处理大量大规模图像包（例如，256×256）存在巨大挑战，且缺乏可用的全局关系（如癌细胞）.", "innovation": "提出了一种新的MIL框架——Continual Multiple Instance Learning with Enhanced Localization (CoMEL)，旨在实现定位和适应性（最小遗忘）的双重目标。CoMEL包括：1）分组双注意力变压器（GDAT）用于高效的实例编码；2）包原型基于的假标签（BPPL）用于可靠的实例假标签；3）正交加权低秩适应（OWLoRA）以减轻包和实例分类中的遗忘问题。实验结果显示，CoMEL在三项公开WSI数据集上的性能优于现有方法，分别在包级准确性和定位准确性的持续MIL设置中提高了最高11.00%和23.4%.", "conclusion": "CoMEL框架在处理持续学习任务中的MIL定位方面展示了出色的性能，同时成功缓解了遗忘问题。该工作为组织学全切片图像分析提供了新的解决方案，特别适用于病理学研究和大规模数据处理场景."}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02405", "html_url": "https://arxiv.org/abs/2507.02405", "title": "PosDiffAE: 基于位置感知的扩散自编码器，结合高分辨率脑组织分类及降噪修复", "title_en": "PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration", "authors": "Ayantika Das,Moitreya Chaudhuri,Koushik Bhat,Keerthi Ram,Mihail Bota,Mohanasankar Sivaprakasam", "background": "扩散模型能够逐步捕捉图像分布并生成高保真的图像样本，但其采样机制无法提取图像特有的语义表示，而自编码器能够提供这种功能。通过结合自编码器和扩散模型，本文提出了一种机制，用于制定扩散自编码模型的潜在空间结构，以识别脑图像中的区域特异性细胞模式，并利用扩散模型在推理过程中的约束生成能力来修复下载艺术和JPEG艺术。", "innovation": "本文首次提出了PosDiffAE框架，通过整合自编码器和扩散模型，实现了对脑组织类型的高度区分，并且通过潜在空间的结构化以及推理过程中的灵活性，实现了无监督的下载艺术和JPEG艺术修复。该框架不仅提高了高分辨率脑图像的分类准确性，还能够有效地修复图像中的多种艺术缺陷，是现有技术的创新之处", "conclusion": "本文提出了PosDiffAE框架，结合自编码器和扩散模型，成功构建了能够识别脑组织类型和修复艺术缺陷的有效机制。在未来的工作中，可以通过增加更多的训练数据和优化模型参数，进一步提高该模型的性能和泛化能力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02437", "html_url": "https://arxiv.org/abs/2507.02437", "title": "F^{2}TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning", "title_en": "F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning", "authors": "Wei Li,Jingyang Zhang,Lihao Liu,Guoan Wang,Junjun He,Yang Chen,Lixu Gu", "background": "Test-Time Adaptation (TTA)已经成为利用未标记测试数据适应源模型到未见过的医疗场地的一种有前景的解决方案，因为数据注释成本很高。现有的TTA方法假设数据以完整的域单位到达。然而，在临床实践中，由于资源限制和病人差异，数据通常以任意长度的域片段随机到达。这给适应过程带来了挑战，特别是在片段之间不明确的转换可能引起偏移的情况下。为了应对这一挑战，本文提出了一个创新的框架——图像级解耦提示调优（I-DiPT）.", "innovation": "本文提出了一个新的Free-Form Test-Time Adaptation（F$^{2}$TTA）任务，适用于任意长度和随机到达顺序的域片段。针对此问题，作者提出了一个新颖的框架——图像级解耦提示调优（I-DiPT），该框架包括一个图像不变的提示来探索域不变的表示，以及一个图像特定的提示来适应每个到达片段中的测试图像。为了克服仅通过一个图像训练导致的知识表示不足的问题，作者引入了不确定性导向的掩码（UoM）方法，通过由模型表示不确定性驱动的掩码一致性学习来鼓励提示提取足够的信息。进一步提出了并行图蒸馏（PGD）方法，通过并行图网络重用历史图像特定和图像不变的提示知识，提高了模型的适应性.", "conclusion": "在乳腺癌和青光眼分类实验中，本文方法在Free-Form Test-Time Adaptation（F$^{2}$TTA）方面优于现有TTA方法。源代码可在\nhttps://github.com/yourusername/f2ttame.git\n找到."}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02477", "html_url": "https://arxiv.org/abs/2507.02477", "title": "Mesh Silksong：如同缫丝的自动回归网格生成", "title_en": "Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk", "authors": "Gaochao Song,Zibo Zhao,Haohan Weng,Jingbo Zeng,Rongfei Jia,Shenghua Gao", "background": "现有的网格表示方法通常会生成包含重复顶点标记的标记序列，这浪费了网络能力。Mesh Silksong通过访问每个网格顶点仅一次来标记网格顶点，减少了标记序列的冗余，并实现了约22%的最佳压缩率。同时，Mesh Silksong产生的多边形网格具有如流形拓扑、防水检测和一致的法线等卓越的几何属性，这对于实际应用至关重要。实验结果证明了该方法的有效性，不仅展示了复杂的网格生成能力，而且显著改善了几何完整性。", "innovation": "Mesh Silksong通过一次访问每个网格顶点来标记顶点，减少了50%的标记序列冗余，并实现了最佳压缩率约为22%。此外，它还能生成具有流形拓扑、防水检测和一致面法线等卓越几何属性的多边形网格。实验结果证实了其高效性和卓越的几何完整性。", "conclusion": "实验结果表明Mesh Silksong方法的有效性，不仅能够进行复杂网格生成，还能够显著提高网格的几何完整性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02454", "html_url": "https://arxiv.org/abs/2507.02454", "title": "基于数量提示的弱监督对比学习方法在移动红外微小目标检测中的应用", "title_en": "Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection", "authors": "Weiwei Duan,Luping Ji,Shengjia Chen,Sicheng Zhu,Jianghong Huang,Mao Ye", "background": "与常规目标检测不同，移动红外微小目标检测面临着巨大挑战，因为这些目标尺寸非常小且背景信号较弱。现有的大多数方法依赖大量手动标注，这通常代价高昂且耗时，尤其是在低质量的红外帧图像中。因此，借鉴常规目标检测领域的研究，弱监督策略被认为能够减少标注需求，尤其是设计了基于预训练的分割一切模型（SAM）的潜在目标挖掘策略，通过结合目标激活图和多帧能量来进行对比学习，从而提高伪标签的可靠性，并同时建模局部和全局运动模式。通过在两个公开数据集（DAUB和ITSDT-15K）上的大量实验，验证了弱监督方案经常优于早期的完全监督方法，其性能甚至可以达到与最先进的完全监督方法90%以上。", "innovation": "该研究提出了一种新的弱监督对比学习（WeCoL）方案，仅在模型训练过程中需要简单的目标数量提示；设计了一种潜在目标挖掘策略，将目标激活图和多帧能量相结合，提高伪标签的可靠性；提出了一个长短期运动感知学习方案，以同时建模小目标的局部运动模式和全局运动轨迹。实现了低质量红外图像中移动微小目标检测的弱监督方法的新探索和突破，验证了其媲美或超过最先进的完全监督方法的效果。", "conclusion": "基于我们提出的弱监督对比学习（WeCoL）方案，在没有大量手动标注的情况下，能够在低质量红外图像中实现对移动微小目标的有效检测。该研究为解决这一领域的问题提供了一种新的有效方法，实验结果表明其在两个公开数据集上的表现超过了早期的完全监督方法，并达到了接近最先进的完全监督方法的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02513", "html_url": "https://arxiv.org/abs/2507.02513", "title": "自动低光照行人检测的自动标签生成", "title_en": "Automatic Labelling for Low-Light Pedestrian Detection", "authors": "Dimitrios Bouzoulas,Eerik Alamikkotervo,Risto Ojala", "background": "在自动驾驶车辆和高级驾驶辅助系统中最常用的传感器是RGB相机，行人检测是保证行人安全的关键任务。然而，在低光照条件下RGB行人检测面临着数据集缺乏的问题。因此，本研究提出了一个自动红外-RGB标注管道，通过红外检测、标签转移过程以及使用生成的标签进行低光照条件下RGB行人检测模型的训练，以应对低光照条件下的行人检测挑战。", "innovation": "本研究提出了一种自动红外-RGB标注管道，该管道包括红外检测、标签转移过程以及基于生成标签训练物体检测模型。该方法特别针对低光照条件下RGB行人检测的数据不足问题，提出了一种自动化解决方式。通过对KAIST数据集的验证，使用生成标签训练的模型在部分指标上的表现优于使用真实标签训练的模型。", "conclusion": "本研究展示了在低光照条件下，通过自动红外-RGB标注管道训练的行人检测模型可以取得更好的检测性能。并且已经开源了该研究的代码，供其他研究人员参考和使用。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02488", "html_url": "https://arxiv.org/abs/2507.02488", "title": "MedFormer:基于内容感知双重稀疏选择注意的分层医学视觉变换器", "title_en": "MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention", "authors": "Zunhui Xia,Hongxing Li,Libin Lan", "background": "医学图像识别在临床诊断中扮演关键角色，有助于更准确及时地识别疾病和异常。尽管基于视觉变换器的方法在处理各种医学识别任务上表现出色，但它们存在两个主要问题。首先，这些方法往往是任务特定且架构定制化的，限制了它们的通用性。其次，它们要么采用全注意机制来建模长程依赖，导致计算成本高，要么依赖人工设计的稀疏注意机制，可能导致性能不佳。针对上述问题，提出了一种高效的医学视觉变换器MedFormer，具有两个关键概念：一是采用分层结构作为通用模型骨架，支持包括图像分类和密集预测任务（如语义分割和病灶检测）的多种医学图像识别任务，从而实现层次特征表示，减轻计算负担，增强性能；二是引入了一种新的内容感知双重稀疏选择注意（DSSA），以提高计算效率和对噪声的鲁棒性，同时保持高性能。理论分析证实，MedFormer相较于现有医学视觉变换器具有更好的通用性和效率。广泛的经验表明，MedFormer在多种医学影像数据集上，在上述三种医学图像识别任务中都表现出色，提升性能显著。", "innovation": "1. 采用分层金字塔扩展结构作为通用基础架构，支持多种医学图像识别任务。\n2. 引入内容感知双重稀疏选择注意力机制（DSSA），优化计算效率及对噪声的鲁棒性，同时保持高性能。\n3. 理论分析表明，相较于现存的医学视觉变换器，MedFormer在通用性和效率方面表现更优。\n4. 实验验证了MedFormer在不同类型医学影像数据集上，提升了各种识别任务的表现力。", "conclusion": "MedFormer为医学视觉变换器领域提供了一种有效的解决方案，通过分层结构和内容感知双重稀疏选择注意力机制，克服了传统医学视觉变换器的通用性和计算效率问题，展示了在多种医学影像识别任务上的优越性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02493", "html_url": "https://arxiv.org/abs/2507.02493", "title": "基于时间感知的监督对比学习在结肠镜检查中息肉计数中的应用", "title_en": "Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy", "authors": "Luca Parolari,Andrea Cherubini,Lamberto Ballan,Carlo Biffi", "background": "结肠镜检查程序中的息肉自动计数是实现自动检查报告和质量控制的关键步骤，旨在提高结肠镜筛查的成本效益。传统的计数方法依赖于自我监督学习，主要利用视觉外观，但忽略了在检测、跟踪及聚类阶段的时间关系。现有的方法在这方面存在局限性，导致误关联增多。因此，亟需一种新的方法来解决时间关系问题，以提高聚类的准确性，并减少误判率。", "innovation": "本文提出了一种基于时间感知的监督对比学习方法，通过引入一种结合时间感知软目标的监督对比损失。该方法不仅捕捉到了息肉内部的特征差异，还保持了不同息肉之间的可区分性，提升了聚类的鲁棒性。同时，通过整合时间邻接约束，减少了在不同时间点上虽视觉相似但实质不同的跟踪片段之间的误关联。实验结果显示，与前人工作相比，该方法在重构率上降低了2.2倍，证明了时间感知对息肉计数的重要性，达到了新的研究前沿。", "conclusion": "实验结果表明，该方法在结肠镜检查中的息肉计数上相比现有方法有显著提高，特别在减少误关联方面表现出色。证实了时间感知在息肉计数中的重要性，并为后续相关研究奠定了基础。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02419", "html_url": "https://arxiv.org/abs/2507.02419", "title": "AvatarMakeup：为3D可动画头虚拟形象实现逼真上妆效果的上妆转移方法", "title_en": "AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars", "authors": "Yiming Zhong,Xiaolin Zhang,Ligang Liu,Yao Zhao,Yunchao Wei", "background": "在现实生活中，面部美化是常见的需求，而3D虚拟头像也需要个性化的定制来提升其视觉吸引力，但这一领域尚未得到充分探索。目前的3D高斯编辑方法虽然可以适应面部化妆，但无法满足实现真实化妆效果的基本要求：1）在可驱动的表情中保持一致外观；2）在整个化妆过程中保持身份；3）对细节进行精细控制。因此，这些方法无法实现高质量、真实感的3D化妆效果。", "innovation": "本文提出了一种名为AvatarMakeup的专门3D化妆方法，利用预训练的扩散模型从每个人的单一参考照片中转移化妆模式。方法采用了从粗到细的策略，首先保持一致外观和身份，然后细化细节。扩散模型生成化妆图像作为监督来应对扩散过程中不确定性导致的视角和表情不一致问题。为此，提出了一个一致性复制方法，通过记录生成化妆图像中的面部属性均值来优化全局UV映射，从而从任意视角和表情中合成一致的化妆指导，优化目标虚拟形象。进一步地，通过引入细化模块到扩散模型中，提升了化妆质量。实验表明，AvatarMakeup在整个动画中达到了最先进的化妆转移质量和一致性效果。", "conclusion": "研究展示了AvatarMakeup实现了高质量、真实的3D头像化妆效果，并且在整个动画中保持了一致性和真实性。该方法为3D虚拟头像的个性化定制和形象美化提供了新的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02519", "html_url": "https://arxiv.org/abs/2507.02519", "title": "IMASHRIMP: 使用计算机视觉和深度学习对实验室图像中的巴西白虾（Penaeus vannamei）进行自动生物测量分析", "title_en": "IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning", "authors": "Abiam Remache González,Meriem Chagour,Timon Bijan Rüth,Raúl Trapiella Cañedo,Marina Martínez Soler,Álvaro Lorenzo Felipe,Hyun-Suk Shin,María-Jesús Zamorano Serrano,Ricardo Torres,Juan-Antonio Castillo Parra,Eduardo Reyes Abad,Miguel-Ángel Ferrer Ballester,Juan-Manuel Afonso López,Francisco-Mario Hernández Tejera,Adrian Penate-Sanchez", "background": "目前，水产业中对虾的形态分析主要依赖于人工操作，这种方法存在误差率高、效率低等问题。为此，研究人员开发了一种名为IMASHRIMP的自动化系统，旨在提高基因选择任务的效率。该系统利用现有的深度学习和计算机视觉技术，针对RGBD图像下的虾形态分析进行了针对性调整，以克服现有技术的特定挑战。", "innovation": "IMASHRIMP系统提出了两个人工智能与人类验证相结合的双因素认证系统，显著降低了视角分类和无须检测的错误率。同时，系统还引入了姿态估计模块和形态回归模块，能够准确预测虾的骨骼关键点并实现像素到厘米的单位转换。通过这些技术创新，该系统能够实现高精度的形态分析，大幅优化了基因选择流程，从而提升水产业的可持续性。", "conclusion": "IMASHRIMP系统展示了自动化和加速虾形态分析的潜力，提高基因选择效率，并有助于更可持续的水产业。实验结果显示，系统在姿态估计和像素到厘米单位转换方面的精度均表现出色。关于该系统的代码可以在指定的链接中获得。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02576", "html_url": "https://arxiv.org/abs/2507.02576", "title": "通过可微体素化从分割学习血管的参数化模型", "title_en": "Parametric shape models for vessels learned from segmentations via differentiable voxelization", "authors": "Alina F. Dima,Suprosanna Shit,Huaqi Qiu,Robbie Holland,Tamara T. Mueller,Fabio Antonio Musio,Kaiyuan Yang,Bjoern Menze,Rickmer Braren,Marcus Makowski,Daniel Rueckert", "background": "血管是身体中复杂的结构，已有多方面的研究。尽管体素化是常用方法，但网格和参数化模型在多种应用中至关重要，因其特性优越。然而，这些表示通常是通过分割提取的，并且在其他过程中通常是相互独立使用的。本文提出了一种框架，将这三种表示形式通过可微变换结合在一起。通过利用可微体素化，自动生成基于分割的参数形状模型，无需具体的形状参数，直接从分割中学习形状参数。并以三次B样条曲线对血管进行参数化，确保光滑性和连续性。随后，参数化形状参数通过可微提取生成高保真的网格模型，可以在适应后进行操作。该方法在涉及主动脉、动脉瘤和脑血管的实验中，能够精确capture几何结构复杂性的血管。", "innovation": "提出了一种利用可微转形式结合体素化、参数化模型和网格的框架。通过可微体素化自动生成参数形状模型，直接从分割中学习形状参数，无需预定义的形状参数。血管参数化为三次B样条曲线，保证了光滑性和连续性。通过这种方法，能够高保真地生成可用于后续操作的网格模型，精确捕捉复杂血管的几何结构。", "conclusion": "该方法通过可微体素化和自学习参数形状模型，能够精确刻画复杂的血管几何结构，为后续的网格模型操作提供了高保真的模型，展示了其有效性和精确性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02517", "html_url": "https://arxiv.org/abs/2507.02517", "title": "使用深度学习检测多种作物多种病害", "title_en": "Detecting Multiple Diseases in Multiple Crops Using Deep Learning", "authors": "Vivek Yadav,Anugrah Jain", "background": "印度作为以农业为主的经济体，面临着农业方面的重要挑战，包括由疾病、害虫和环境压力导致的大量作物损失。对于不同作物的早期检测和准确识别对于提高产量和确保粮食安全至关重要。因此，本文提出了一种基于深度学习的解决方案，用于检测多种作物中的多种病害，旨在覆盖印度多样化的农业景观。", "innovation": "本文首先创建了一个统一的数据集，包含来自多个资源库的17种不同作物和34种不同病害的图像。所提出的深度学习模型在该数据集上进行训练，并在准确性和覆盖的作物和疾病数量方面超过了现有的先进技术。统一数据集我们在测试中达到了99%的检测准确率，相较于其他方法仅处理14种作物和26种不同病害时提高了7%的准确率。通过提高能够检测的作物和病害的种类，所提出的解决方案旨在为印度农民提供更好的产品支持", "conclusion": "通过增加能够检测的作物数量和疾病的多样性，所提出的解决方案旨在为印度农民提供更好的产品支持。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02445", "html_url": "https://arxiv.org/abs/2507.02445", "title": "IGDNet：基于照明引导和去噪的零样本鲁棒欠曝图像增强", "title_en": "IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising", "authors": "Hailong Yan,Junjian Huang,Tingwen Huang", "background": "当前恢复欠曝图像的方法通常依赖于带有欠曝和正常曝光配对图像的监督学习，但在实际应用场景中收集这类数据往往不切实际。此外，这些方法可能导致过度增强，从而使正常曝光区域失真。", "innovation": "本文提出了一种名为IGDNet的零样本周边界曝光图像增强方法，该方法仅依靠单幅测试图像运行，无需指导先验或训练数据。IGDNet具备强泛化能力，能够有效抑制噪声并恢复照明。框架包括一个分解模块和一个去噪模块，前者通过密集连接网络将图像分解为照明和反射成分，后者使用照明引导的像素自适应校正方法增强非均匀照明区域。噪声对通过降采样和迭代细化生成，以产生最终结果。实验结果表明，IGDNet在复杂光照条件下的视觉质量显著提高，且在PSNR和SSIM等度量指标上优于14种最新的无监督方法，达到了20.41dB和0.860dB的表现。", "conclusion": "广泛的实验表明，IGDNet在复杂光照条件下的视觉质量显著提升，并且在PSNR和SSIM等度量指标上明显优于14种最新的无监督方法（PSNR 20.41dB, SSIM 0.860dB）。代码将很快发布。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02479", "html_url": "https://arxiv.org/abs/2507.02479", "title": "CrowdTrack: 在真实场景中具有挑战性的多人跟踪基准", "title_en": "CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios", "authors": "Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue", "background": "多对象跟踪是计算机视觉中的一个经典领域，行人跟踪因其极高的应用价值而成为最热门的研究类别。现有的方法主要依赖于运动或外观信息进行跟踪，但在复杂场景下常难以获得理想效果。对于运动信息，物体间的遮挡会阻碍状态更新；对于外观信息，由于物体部分可见或图像模糊等原因常常会获得非鲁棒的跟踪结果。尽管从标注数据中学习如何在这些条件下进行跟踪似乎是解决这一问题的最直接方法，现有的多目标跟踪（MOT）数据集对此并不充分，主要问题是场景组成相对简单且非现实场景。虽然一些现有数据集中没有上述缺点的视频序列，但这些视频的数量远远不足以满足研究需求。因此，提出CrowdTrack数据集，主要用于第一人称视角且全部来自真实的复杂场景的多人跟踪。", "innovation": "CrowdTrack数据集是一个针对多人在现实场景中跟踪具有挑战性的大型数据集。该数据集包含33个视频，共计5,185条轨迹，每个物体都标注了完整的边界框和唯一的物体ID。CrowdTrack数据集提供了平台，便于开发在复杂情况仍然有效的算法。此外，对数据集进行了全面分析，并测试了多款SOTA模型，还分析了基础模型在该数据集上的性能。CrowdTrack数据集和项目代码已公开发布。", "conclusion": "CrowdTrack数据集的发布旨在为三维复杂场景下多人跟踪的研究提供支持，其多样化的复杂场景和大量数据量为其研究价值的实现提供了可能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02494", "html_url": "https://arxiv.org/abs/2507.02494", "title": "MC-INR: 使用元学习和聚类隐式神经表示高效编码多变量科学模拟数据", "title_en": "MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations", "authors": "Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong", "background": "隐式神经表示（INRs）被广泛用于将数据编码为连续函数，从而减少存储大规模多变量科学模拟数据所需的内存。然而，现有基于INR的方法存在三个主要局限性：（1）结构化复杂结构的刚性表示；（2）主要侧重于一维数据；（3）依赖于结构化网格。这些局限性导致它们在应用到复杂的真实世界数据集时性能下降。因此，本文旨在提出一种新型基于神经网络的框架，MC-INR，以处理无结构网格上的多变量数据，并且结合元学习和聚类能够灵活地编码复杂结构", "innovation": "MC-INR框架结合了元学习和聚类，能够灵活表示复杂结构，并引入了一种基于残差的动态重聚类机制，可以根据局部误差自适应地划分簇。同时，提出了一种分叉层，能够通过独立分支的同时利用多变量数据。实验结果表明，MC-INR在科学数据编码任务上优于现有方法", "conclusion": "MC-INR框架有效地克服了现有基于INR方法的局限性，实现了无结构网格上多变量科学仿真数据的高效编码"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02591", "html_url": "https://arxiv.org/abs/2507.02591", "title": "AuroraLong：使RNN回归到高效的开放性视频理解", "title_en": "AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding", "authors": "Weili Xu,Enxin Song,Wenhao Chai,Xuexiang Wen,Tian Ye,Gaoang Wang", "background": "长视频理解的挑战在于其高计算复杂度和难以承受的记忆成本，因为基于变压器的大型语言模型（LLMs）的内存和计算需求随着输入序列长度的增加呈二次比例增长。", "innovation": "提出了一种名为AuroraLong的方法来解决这一挑战，通过用线性递归神经网络（RNN）语言模型替换MLLMs的LLM组件以处理任意长度的输入序列，同时保持常量大小的隐藏状态。此外，通过重新排序视觉标记按尺寸升序，进一步提高了吞吐量和效率，最终使得仅有2B参数并在公共数据上训练的AuroraLong在多个视频基准测试中的性能与类似规模的基于变压器的模型相当，但使用开源数据集训练，这进一步证明了高效线性RNN的潜力，有可能通过降低计算门槛来普及长视频理解。这是首次在像LaLaVA这样的模型中使用基于线性RNN的LLM骨干进行开放式视频理解。", "conclusion": "AuroraLong展示了高效线性RNN能够降低长视频理解的计算门槛，将开放性视频理解的效率带回到一种新的水平。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02546", "html_url": "https://arxiv.org/abs/2507.02546", "title": "MoGe-2: 单目几何测量与清晰细节", "title_en": "MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details", "authors": "Ruicheng Wang,Sicheng Xu,Yue Dong,Yu Deng,Jianfeng Xiang,Zelong Lv,Guangzhong Sun,Xin Tong,Jiaolong Yang", "background": "提出了一种先进的单目几何估计模型MoGe-2，能够从单张图像中还原出场景的度量比例3D点云图。该方法基于最近的单目几何估计方法MoGe，MoGe预测了具有未知尺度的仿射不变点云图。MoGe-2探索了有效的策略来扩展MoGe，以进行度量几何预测，同时不损害仿射不变点表示提供的相对几何准确性。研究发现，真实数据中的噪声和误差会降低预测几何的精细细节。为了解决这个问题，开发了一种统一的数据精炼方法，使用锐化合成标签过滤和填充来自不同来源的真实数据，显著增强了重建几何的精细度，同时保持整体准确性。模型在大规模混合数据集上进行训练，并进行了全面的评估，展示了其在实现精确的相对几何、精确的度量比例和精细细节恢复方面的优越性能，这是以前的方法无法同时实现的。", "innovation": "MoGe-2通过开发统一的数据精炼方法，使用锐化合成标签过滤和填充来自不同来源的真实数据，解决了噪声和误差导致的精细细节丢失问题，从而显著提升了几何重建的精细度，同时保持了整体的准确性。此外，MoGe-2能够在单张图像中实现精确的相对几何、精确的度量比例和精细细节恢复的性能，这是之前的方法所无法同时实现的。", "conclusion": "研究者通过设计MoGe-2，成功地实现了单目几何估计在单张图像中同时获得精确的相对几何、精确的度量比例和精细细节恢复。这种方法显著改善了真实场景的几何重建质量，并在一系列评估中展示了其优越性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02691", "html_url": "https://arxiv.org/abs/2507.02691", "title": "CanonSwap: 通过典范空间调制实现高保真和一致的视频人脸互换", "title_en": "CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation", "authors": "Xiangyang Luo,Ye Zhu,Yunfei Liu,Lijian Lin,Cong Wan,Zijian Cai,Shao-Lun Huang,Yu Li", "background": "视频人脸互换旨在解决两个主要挑战：有效将源人脸的身份信息转移到目标视频中，并准确保留目标人脸的动态属性，如头部姿态、面部表情、嘴唇同步等。现有方法主要关注高质量的身份转移，但在保持目标人脸的动态属性方面常常做得不够好，导致结果不一致。这归因于视频中人脸外观和运动的内在耦合。", "innovation": "本文提出了一种名为CanonSwap的新颖视频人脸互换框架，该框架通过在统一的典范空间内消除与运动相关的信息，来分离运动信息和外观信息，从而实现身份修改。进一步设计了部分身份调制模块，通过空间掩码适应性地整合源人脸特征，限制修改仅在面部区域。引入了多个细粒度同步指标，以全面评估视频人脸互换方法的性能。实验结果显示，本方法在视觉质量、时间一致性和身份保留方面显著优于现有方法。", "conclusion": "通过大量实验，我们证明CanonSwap方法在视觉质量、时间一致性和身份保留方面明显优于现有方法。我们的项目页面公开可用。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02705", "html_url": "https://arxiv.org/abs/2507.02705", "title": "SIU3R: Beyond Feature Alignment for Simultaneous Scene Understanding and 3D Reconstruction", "title_en": "SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment", "authors": "Qi Xu,Dongxu Wei,Lingzhe Zhao,Wenpu Li,Zhangchi Huang,Shunping Ji,Peidong Liu", "background": "Simultaneous understanding and 3D reconstruction is crucial for developing end-to-end embodied intelligent systems. Current approaches frequently rely on 2D-to-3D feature alignment, which imposes limitations on 3D understanding and may result in semantic information loss.", "innovation": "SIU3R提出了一个无对齐框架，专门用于从未定向图像中实现广泛适用的同步理解和3D重建。该框架通过像素对齐的3D表示连接重建和理解任务，并将多个理解任务统一为一组可学习查询，从而实现原生的3D理解，无需与2D模型对齐。此外，为了促进两个任务之间的协作，提出了两个轻量级模块来促进它们的交互，并进行了两者的互惠利益的深入分析，从而提高了整体性能。", "conclusion": "实验结果表明，我们的方法在独立的3D重建和理解任务以及同步理解和3D重建任务上均取得了最先进的性能，证明了无对齐框架的优势以及互惠设计的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02664", "html_url": "https://arxiv.org/abs/2507.02664", "title": "AIGI-Holmes: 基于多模态大语言模型的可解释和可泛化的AI生成图像检测", "title_en": "AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models", "authors": "Ziyin Zhou,Yunpeng Luo,Yuanchen Wu,Ke Sun,Jiayi Ji,Ke Yan,Shouhong Ding,Xiaoshuai Sun,Yunsheng Wu,Rongrong Ji", "background": "AI生成内容（AIGC）技术的快速发展导致了高度逼真的人工智能生成图像（AIGI）被误用于传播虚假信息，对公共信息安全性构成威胁。现有的AIGI检测技术尽管大体有效，但仍面临两个问题：缺乏人类可验证的解释和缺乏对于最新技术的泛化能力。因此，需要新的方法来解决这些问题并提高AIGI检测的效果和可靠性。", "innovation": "1. 引入了一个大规模且综合的数据集Holmes-Set，它包括Holmes-SFTSet（指令微调数据集，提供图像是否为AI生成的解释）和Holmes-DPOSet（人类对齐偏好的数据集）。2. 设计了一种高效的多专家陪审团数据注释方法，增强了数据生成并提高了数据质量控制。3. 提出了Holmes Pipeline，一个由预先训练的视觉专家、监督微调和直接的偏好优化三个阶段组成的定制化训练框架，使用多模态大语言模型（MLLMs）进行AIGI检测，并生成人类可验证和对齐的解释。4. 在推理阶段，引入了一种协作解码策略，结合了模型视觉专家的感知和MLLMs的语义推理，进一步增强了泛化能力。", "conclusion": "通过在三个基准上的广泛实验验证了AIGI-Holmes模型的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02565", "html_url": "https://arxiv.org/abs/2507.02565", "title": "利用外观和社交距离推理重建近距离人体互动", "title_en": "Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning", "authors": "Buzhen Huang,Chen Li,Chongyang Xu,Dongyue Lu,Jinnan Chen,Yangang Wang,Gim Hee Lee", "background": "现有的人体姿态估计方法由于视觉上的模糊性和个体间的遮挡，在野外视频中无法恢复合理的近距离互动。即使是最先进的大规模基础模型（例如，SAM），在这些具有挑战性的场景中也无法准确区分人类语义。观察到这一点后，我们提出了一种双分支优化框架，通过人类的外观、社交距离和物理法则来受限地重构准确的互动动作和合理的身体接触。我们通过训练一个扩散模型来学习人类社交距离行为和姿态先验知识，然后将训练好的网络和两个可优化的张量融入到双分支优化框架中来恢复人体动作和外观。同时，我们设计了基于3D高斯分布、2D关键点和网格穿透的多种约束，以辅助优化，使得我们的方法能够在复杂环境中从野外视频中估计准确的人体互动。我们还构建了一个具有伪地面真值互动注释的数据集，这可能会促进未来的人体姿态估计和行为理解研究。", "innovation": "我们提出了一种双分支优化框架，结合了人类的外观和社交距离来优化人体互动的重建，这不同于之前单纯依赖姿态估计的方法。通过训练后的扩散模型和各种约束条件，我们的方法在复杂环境中能更准确地估计人体互动，即使在野外视频中也表现良好。我们也提供了一个带有伪地面真值标签的数据集，为未来的研究提供了帮助。", "conclusion": "我们的方法在几个标准基准上的实验结果表明，我们的人体互动重建方法优于现有的方法。我们也在项目页面提供了代码和数据供未来研究参考。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02581", "html_url": "https://arxiv.org/abs/2507.02581", "title": "3D医学图像结构感知语义异同和一致性自监督学习", "title_en": "Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning", "authors": "Tan Pan,Zhaorui Tan,Kaiyu Guo,Dongli Xu,Weidi Xu,Chen Jiang,Xin Guo,Yuan Qi,Yuan Cheng", "background": "3D医学图像的自我监督学习(mSSL)在医学分析中前景广阔，但要支持更广泛的应用，需要考虑到位置、尺度和形态上的解剖结构变化，这些变化能捕捉到有意义的区别。然而，之前的一些mSSL方法使用固定大小的补丁分割图像，经常忽略了结构变化的重要性。", "innovation": "提出了一个新的视角——$S^2DC$，用于学习结构感知的表示。该方法通过最优化运输策略增强补丁级语义异同，并基于邻域相似度分布提升结构级语义一致性，从而实现跨链接补丁级和结构级表示的结构感知表示。该方法在10个数据集、4个任务和3种模态上进行全面评估，结果表明该方法在mSSL中始终优于最先进的方法。", "conclusion": "该研究通过提出一种新的结构感知的mSSL框架$S^2DC$，在评估的多个数据集和任务中，该方法在mSSL中表现出优越性能，有效地提升了结构感知的自我监督学习效果。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02714", "html_url": "https://arxiv.org/abs/2507.02714", "title": "FairHuman：在最小 potential 延迟公平性指导下的扩散模型中提升人体图像中手和面部质量", "title_en": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models", "authors": "Yuxuan Wang,Tianwei Cao,Huayu Zhang,Zhongjiang He,Kongming Liang,Zhanyu Ma", "background": "随着大规模文本到图像模型（尤其是基于扩散的方法）的发展，图像生成取得了显著进展。然而，生成包含人脸或手部等合理细节的人类图像仍面临挑战，原因是训练期间局部区域的监督不足。", "innovation": "提出了FairHuman，这是一种多目标微调方法，旨在公平地提高全局质量和局部生成质量。该方法首先构建了三个学习目标：全局目标来自默认的扩散目标函数，手部和面部的局部目标基于预先标注的位置先验。随后，根据最小潜在延迟（MPD）准则推导出了最优参数更新策略，从而实现了多目标问题上的公平优化。", "conclusion": "本方法在生成具有挑战性的局部细节方面取得了显著进步，同时保持了整体质量。大量的实验验证了该方法在不同场景下提升人体图像生成性能的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02602", "html_url": "https://arxiv.org/abs/2507.02602", "title": "在基于视觉导航中解决相机传感器故障：仿真实验与数据集开发", "title_en": "Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development", "authors": "Riccardo Gallon,Fabian Schiemenz,Alessandra Menicucci,Eberhard Gill", "background": "基于视觉导航（VBN）算法在空间任务中的重要性日益增加，确保其可靠性和操作稳健性提出了诸多挑战。传感器故障可能导致导航算法输出不准确或数据处理故障，从而影响任务目标的实现。人工智能（AI）提供了一种强大的故障检测解决方案，克服了传统方法的许多局限性。然而，阻碍AI在这一领域的应用的主要障碍是缺乏包含故障图像数据的充分且代表性的数据集。本文在一个星际探索任务的场景下，系统地分析了VBN管道中相机传感器可能遇到的故障案例及其原因和影响，并提出了一种仿真实验框架来生成含有故障的合成图像，以系统可控地再现故障数据，并最终建立了一个故障注入图像数据集，从而为训练和测试基于AI的故障检测算法提供了一个有价值的工具。", "innovation": "本研究的主要创新点在于它提出了一种仿真实验框架，通过生成含有故障的合成图像，系统可控地再现故障数据，并建立了第一个针对VBN中相机传感器故障的故障数据集，这为训练和测试基于AI的故障检测算法提供了可靠的依据和资源。", "conclusion": "本文建立了一个包含故障注入图像的数据集，为训练和测试基于AI的故障检测算法提供了有力支持。通过该数据集的应用，可以提高基于视觉导航系统的可靠性和稳健性，从而提高空间任务的成功率。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02687", "html_url": "https://arxiv.org/abs/2507.02687", "title": "APT: 自适应个性化训练在有限数据下针对扩散模型的训练方法", "title_en": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data", "authors": "JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang", "background": "在使用有限数据个性化扩散模型时，存在过拟合、先前知识丧失和文本对齐退化等显著挑战。过拟合会导致噪声预测分布的位移，扰乱去噪过程，并使模型失去语义连贯性。现有方法难以有效解决这些问题，无法在有限数据下生成高质量、多样化的图像。因此，本研究旨在提出一种新的框架来解决这类问题。", "innovation": "本文提出了一种名为自适应个性化训练（APT）的新框架，它通过引入自适应训练策略和在微调过程中正则化模型的内部表示来缓解过拟合。APT包括三个关键组件：(1)自适应训练调整，引入过拟合指标以检测每个时间步的过拟合程度，并根据该指标应用自适应数据增强和自适应损失加权；(2) 表示稳定化，通过正则化中间特征图的均值和方差来防止噪声预测的过度变化；(3) 前知识保存的注意力对齐，将微调模型的交叉注意力图与预训练模型的注意力图对齐，以保持先前知识和语义连贯性。", "conclusion": "通过广泛实验，我们证明APT有效地缓解了过拟合，保持了先前知识，并在有限参考数据下生成了高质量、多样化的图像，优于现有方法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02747", "html_url": "https://arxiv.org/abs/2507.02747", "title": "DexVLG: 大规模的灵巧视觉-语言-抓取模型", "title_en": "DexVLG: Dexterous Vision-Language-Grasp Model at Scale", "authors": "Jiawei He,Danshi Li,Xinqiang Yu,Zekun Qi,Wenyao Zhang,Jiayi Chen,Zhaoxiang Zhang,Zhizheng Zhang,Li Yi,He Wang", "background": "随着大型模型的普及，视觉-语言-动作（VLA）系统使机器人能够处理越来越复杂的任务。然而，由于数据收集难度，研究主要集中在控制简单机械夹爪上，很少涉及使用大型模型进行与人类灵巧手相仿的功能性抓取。缺乏相关的数据集和模型，限制了该领域的进展。该论文旨在通过构建大规模数据集和模型来解决这一问题，使其能够预测灵巧的抓取姿势并根据语言指令进行功能抓取。", "innovation": "提出了DexVLG，一种大规模的灵巧视觉-语言-抓取模型，能够在单视角RGBD输入下与语言指令对齐预测灵巧的抓取姿势。创新点在于构建了一个包含170万灵巧抓取姿势的数据集（DexGraspNet 3.0），该数据集覆盖了174,000个对象的语义部分，并通过基于流一致性的方法训练了一个VLM模型。该模型能够在物理仿真中实现出色的零样本泛化能力，在模拟测试中实现了超过76%的零样本执行成功率，并且在真实世界中也能成功实现零件对齐的抓取。", "conclusion": "DexVLG模型展示了强大的零样本泛化能力，并在模拟和真实世界场景中成功地实现了灵巧的抓取，特别是在物体智能对齐的抓取上。这为未来使用大型模型进行灵巧抓取研究奠定了重要的基础。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02743", "html_url": "https://arxiv.org/abs/2507.02743", "title": "使用边界框约束条件的提示学习方法在医学图像分割中的应用", "title_en": "Prompt learning with bounding box constraints for medical image segmentation", "authors": "Mélanie Gaillochet,Mehrdad Noori,Sahar Dastani,Christian Desrosiers,Hervé Lombaert", "background": "在医学领域中，像素级注释的获取既耗时又昂贵。为了减轻这一负担，基于边界框注释的弱监督方法提供了一种实际的替代方案，因为边界框注释比像素级注释更容易获得。近期研究表明，通过使用提示（如点或边界框）作为输入，视觉基础模型在分割任务上表现出色。然而，现有的提示学习方法依赖于完全标注的分割掩膜，这仍然是一个挑战。因此，本文提出了一个新颖的框架，结合了视觉基础模型的强大表示能力和弱监督分割的注释效率。该方法仅使用边界框注释来自动化基础模型的提示生成过程。该框架通过综合从边界框注释中提取的多个约束和由提示基础模型生成的伪标签，进一步优化了分割性能。在多个模态数据集上的实验表明，该弱监督方法在有限数据设置下达到了平均Dice得分为84.90%，优于现有的完全监督和弱监督方法。提供的代码可以在特定链接中访问。", "innovation": "该工作提出了一个结合视觉基础模型强大表示能力和弱监督分割注释效率的新框架。具体而言，提出的优化方案将从边界框注释中提取的多个约束与由提示基础模型生成的伪标签结合起来，自动从边界框注释中生成提示。新的框架能够在有限数据设置下实现比现有完全监督和弱监督方法更高的平均Dice得率，从而大大减少了人工介入。该方法被证明在多种医学图像分割任务中有效。", "conclusion": "本文提出了一种新型弱监督医学图像分割方法，该方法结合了视觉基础模型的强大表示能力和通过边界框注释优化提示生成的效率。实验结果表明，该方法在有限数据环境下取得了良好的性能，证明了其在医疗图像分割中的有效性和实用性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02781", "html_url": "https://arxiv.org/abs/2507.02781", "title": "从像素到损坏程度：使用社会媒体图像的语义分割估算地震影响", "title_en": "From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images", "authors": "Danrong Zhang,Huili Huang,N. Simrill Smith,Nimisha Roy,J. David Frost", "background": "地震后，社交媒体图像已成为灾害侦察的关键资源，提供了对损坏程度的即时见解。传统的方法往往依赖于分类方法，这使得对图像中损坏程度的主观评估和复杂性无法得到准确反映。", "innovation": "本文提出了一种创新方法，即将损坏程度评估问题构建成语义分割任务，通过构建损坏程度分割数据集，将损坏分为无损结构、损坏结构和废墟三个等级。利用此数据集，研究中的SegFormer模型被重新训练以生成社交媒体图像中的损坏程度分割，引入了新的损坏程度评分系统来量化的不同区域损坏程度，并调整深度估计。这种方法使得对社交媒体图像的损坏程度评估更加客观和全面，为灾害侦察团队提供了精准的指导，有助于更有效的响应措施。", "conclusion": "该研究通过提供对损坏的细微理解，增强了对灾害侦察团队提供精确指导的能力，有助于在地震后的更有效和有针对性的应对措施。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02792", "html_url": "https://arxiv.org/abs/2507.02792", "title": "RichControl: 结构丰富和外观丰富的训练无监督的空间控制用于文本到图像生成", "title_en": "RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation", "authors": "Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang", "background": "文本到图像（T2I）扩散模型在从文本提示生成高质量图像方面取得了显著的成功。最近的研究扩展了这些模型，以结合条件图像（如深度图或姿态图），提高空间控制的细微程度。其中，特征注入方法已作为无训练替代方法出现，逐渐取代了传统的微调方法。然而，这些方法常常存在结构错位、条件泄漏和视觉伪影等问题，特别是在条件图像与自然RGB分布差异显著时。", "innovation": "基于对现有方法的重新审视，我们发现了其核心限制：同步注入条件特征未能在去噪过程中平衡领域对齐和结构保存之间的权衡。我们提出了一种灵活的特征注入框架，解耦注入时间步与去噪过程。该框架的核心是结构丰富的注入模块，使得模型能够在扩散步骤中更好地适应对齐与结构保存之间不断演变的交互，从而产生更忠实的结构生成。此外，我们还引入了外观丰富的提示和重启精炼策略，进一步增强了外观控制和视觉质量。这些设计使得训练无监督生成同时具有结构丰富和外观丰富的特性。", "conclusion": "广泛的实验表明，我们的方法在各种零样本条件场景中实现了最先进的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02803", "html_url": "https://arxiv.org/abs/2507.02803", "title": "HyperGaussians: 高维高斯斑点绘制技术用于高保真可动画人脸模型", "title_en": "HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars", "authors": "Gent Serifi,Marcel C. Bühler", "background": "创建高质量的可动画人脸模型是一项具有挑战性的任务，尤其是在基于单目视频的情况下。现有的技术，如3D Gaussian Splatting (3DGS)，虽然在静态人脸的渲染上表现出色，但在处理非线性变形、复杂光照效果和精细细节方面仍存在局限。大多数相关工作集中在预测更好的高斯参数上，但论文作者认为需要重新思考高斯表示本身及其如何更具表现力。因此，他们提出了一种新的高维多变量高斯扩展方法，称为HyperGaussians。这种方法通过局部可学习嵌入进行条件处理，增加了表达能力，但在计算上处理高维协方差矩阵的逆矩阵代价高昂。为了解决这个问题，他们提出了一种“逆协方差技巧”，这提升了效率，使得HyperGaussians可以无缝集成到现有的模型中。", "innovation": "HyperGaussians是一种新的高维多变量高斯扩展方法，通过局部可学习嵌入进行条件处理，增加表达能力，无需直接计算高维协方差矩阵的逆矩阵。他们还提出了一种“逆协方差技巧”来提高计算效率，使得HyperGaussians能够无缝集成到现有的模型中。这项新技术在计算和表现上优于现有的3DGS方法，特别是在高频细节如眼镜框、牙齿、复杂的面部运动和镜面反射方面。", "conclusion": "研究人员将HyperGaussians集成到FlashAvatar中进行了测试，结果显示HyperGaussians在数值和视觉表现上都优于3DGS，特别是在高频细节的渲染上。这证明了HyperGaussians的有效性和优越性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02751", "html_url": "https://arxiv.org/abs/2507.02751", "title": "部分弱监督定向对象检测", "title_en": "Partial Weakly-Supervised Oriented Object Detection", "authors": "Mingxin Liu,Peiyuan Zhang,Yuan Liu,Wei Zhang,Yue Zhou,Ning Liao,Ziyang Gong,Junwei Luo,Zhirui Wang,Yi Yu,Xue Yang", "background": "定向对象检测（OOD）在多个领域的需求不断增加，推动了该领域的大量研究。然而，数据集标注的成本依然很高。目前主流的定向对象检测算法主要分为三类：一是完全监督的方法，使用完整的定向边界框（OBB）标注；二是半监督的方法，使用部分OBB标注；三是弱监督的方法，使用如水平框或点等弱标注。这些算法在标注速度或标注成本上都增加了模型的成本。", "innovation": "本文提出了:(1) 基于部分弱标注（水平框或单个点）的第一种部分弱监督定向对象检测（PWood）框架，能够高效利用大量未标注数据，明显优于使用部分弱标注训练的弱监督算法，提供了一个低成本的解决方案；(2) 一种面向尺度和定向的学生模型（OS-Student），仅需少量无定向或无尺度弱标注即可学习定向和尺度信息；(3) 类别无关伪标签过滤策略（CPF），减少模型对静态过滤阈值的敏感性。", "conclusion": "在DOTA-v1.0/v1.5/v2.0和DIOR数据集上的全面实验表明，我们的PWOOD框架与传统半监督算法表现相当，甚至超越了传统半监督算法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02748", "html_url": "https://arxiv.org/abs/2507.02748", "title": "带有全局背景的线性注意力：用于视觉和物理的多重注意力机制", "title_en": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics", "authors": "Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen", "background": "Transformer模型在从图像分类到物理模拟的广泛任务中已经成为事实上的标准。尽管性能出色，但标准Transformer的时间和内存复杂性都是输入长度的二次函数，这使它们在处理高分辨率输入时变得不切实际。因此，提出了许多变体，最成功的依赖于块化、下采样或粗糙化技术，但通常会失去细尺度的详细信息。", "innovation": "受最先进的$n$体数值模拟技术的启发，作者提出了一个名为Multipole Attention Neural Operator (MANO)的新模型。MANO以基于距离的多尺度方式进行注意力计算，并在每个注意力头中保持全局感受野，从而实现了时间复杂性和内存复杂性与网格点数量成线性关系。实验证明，与现有的领先模型如ViT和Swin Transformer相比，MANO具有更好的性能，同时大幅减少运行时间和峰值内存使用。", "conclusion": "实验结果表明，MANO在图像分类和Darcy流动测试中能够与当前最先进的模型媲美，同时显著降低运行时间和峰值内存使用。作者就此开放了他们的代码以实现可重复性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02790", "html_url": "https://arxiv.org/abs/2507.02790", "title": "从长视频到吸睛片段：基于多模态叙述理解的人类启发式视频编辑框架", "title_en": "From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding", "authors": "Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu", "background": "随着在线视频内容尤其是短视频平台上的快速增长，对高效视频编辑技术的需求也在增加，这些技术能够将长视频浓缩成简洁且引人入胜的片段。现有的自动编辑方法主要依赖于ASR转录的文本线索进行端到端的片段选择，但往往忽略了丰富的视觉上下文，导致生成的输出不连贯。", "innovation": "本文提出了一种受人类启发的自动视频编辑框架（HIVE），利用多模态叙述理解来解决这些局限性。该方法通过利用多模态大型语言模型进行角色提取、对话分析和叙述总结，实现对视频内容的全面理解。为了进一步提高连贯性，该框架应用场景级分割，并将编辑过程分解为三个子任务：要点检测、开场和结尾选择以及无关内容的剪辑。", "conclusion": "该框架在实验中表现出色，不仅在一般编辑任务中，也在广告导向的编辑任务中超越了现有基线方法，显著缩小了自动编辑视频与人工编辑视频的质量差距。为此，作者还引入了一个名为DramaAD的新基准数据集，包含超过800个短剧集和500个专业剪辑的广告片段，以促进该领域内的研究。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02686", "html_url": "https://arxiv.org/abs/2507.02686", "title": "通过扩散模型的展开与蒸馏学习多步后验抽样器", "title_en": "Learning few-step posterior samplers by unfolding and distillation of diffusion models", "authors": "Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra", "background": "扩散模型（DMs）已经在贝叶斯计算成像中成为强大的图像先验。在这一背景下，有两种主要策略被提出利用DMs：插值和播放方法，它们是零样本的且高度灵活，但依赖于近似；以及专门条件的DMs，通过监督训练在特定任务中实现了更高的准确性和更快的推理速度。这项工作介绍了一种新的框架，将DM图像先验转换为几步条件模型以进行后验采样，该框架通过集成深度展开和模型蒸馏实现。这一创新之处在于展开了一个马尔可夫链蒙特卡洛（MCMC）算法，具体来说就是最近提出的LATINO拉盖尔采样器（Spagnoletti et al., 2025），这是首次将深度展开应用于蒙特卡洛采样方案的实例。在广泛的实验证明中，说明了提出的展开和蒸馏采样器，并与最先进的技术进行了比较。结果表明，它们在精度和计算效率方面表现出色，同时保留了在推理时适应前向模型变化的灵活性。", "innovation": "提出了一种新颖的框架，通过将DMs图像先验转变为几步条件模型来进行后验采样，且首次将深度展开应用于蒙特卡洛采样方案（LATINO拉盖尔采样器）的实例。这种方法不仅实现了较高的准确性和高效的计算，同时具备依据前向模型变化进行推理时的灵活性。", "conclusion": "通过扩展和蒸馏扩散模型，本研究提出的方法在实验中达到了卓越的准确性和计算效率，同时保持了在推理时适应前向模型变化的灵活性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02826", "html_url": "https://arxiv.org/abs/2507.02826", "title": "基于信心驱动梯度调制的多模态人体活动识别：一种动态对比双路径学习方法", "title_en": "Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach", "authors": "Panpan Ji,Junni Song,Hang Xiao,Hanyu Liu,Chao Li", "background": "传感器引导的人体活动识别（HAR）是使智能系统能够感知和与环境互动的核心技术。然而，多模态HAR系统仍然面临一些关键挑战，如跨模态特征对齐困难和模态贡献不平衡等问题。", "innovation": "本文提出了一种新型框架，即动态对比双路径网络（DCDP-HAR）。该框架包含了三个关键技术组件：采用双路径特征提取架构，其中ResNet和DenseNet分支协同处理多模态传感器数据；引入多阶段对比学习机制来实现从局部感知到语义抽象的逐步对齐；提出了一种基于信心驱动的梯度调制策略，在反向传播过程中动态监测和调整每个模态分支的学习强度，有效缓解了模态竞争；采用了基于动量的梯度积累策略以增强训练稳定性。", "conclusion": "我们通过消融研究验证了每个组件的有效性，并在四个公开基准数据集上执行了广泛的比较实验。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02813", "html_url": "https://arxiv.org/abs/2507.02813", "title": "LangScene-X: 使用TriMap视频扩散重建通用的3D语言嵌入场景", "title_en": "LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion", "authors": "Fangfu Liu,Hao Li,Jiawei Chi,Hanyang Wang,Minghui Yang,Fudong Wang,Yueqi Duan", "background": "从2D图像恢复3D结构并进行开放词汇场景理解是一个基本但极具挑战性的任务。现有的方法通过嵌入语言信息进行每场景优化已取得进展，但它们严重依赖于校准的密集视图重建方法，这会导致在视图有限时出现严重的渲染伪影和不合逻辑的语义合成问题。", "innovation": "本文介绍了一种名为LangScene-X的新型生成框架，统一并生成重建和理解所需的3D一致多模态信息。运用生成能力创建更多一致的新观测，可以从稀疏视图重建通用的3D语言嵌入场景。通过训练一个TriMap视频扩散模型来生成稀疏输入的外观（RGBs）、几何（法线）和语义（分割图）；提出一种名为LQC的语言量量化压缩器，使跨场景推广成为可能；通过将语言信息对齐到3D场景的表面，支持开放的语言查询。实验表明，LangScene-X在质量和推广性方面优于现有方法。", "conclusion": "在现实数据上的大量实验证明，LangScene-X在质量和泛化能力方面优于最先进的方法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02860", "html_url": "https://arxiv.org/abs/2507.02860", "title": "无训练的视频扩散加速：基于运行时自适应缓存", "title_en": "Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching", "authors": "Xin Zhou,Dingkang Liang,Kaijin Chen,Tianrui Feng,Xiwu Chen,Hongkai Lin,Yikang Ding,Feiyang Tan,Hengshuang Zhao,Xiang Bai", "background": "视频生成模型已展现了出色的效果，但其广泛应用受到推理速度缓慢和高计算成本的限制，主要原因是去噪过程的迭代特性。解决这一瓶颈对于普及先进的视频合成技术，使其能够在现实应用中集成至关重要。", "innovation": "该工作提出了一种无需训练的加速框架EasyCache，引入了一种轻量级、运行时自适应的缓存机制，可在推理过程中动态重用先前计算的变换向量，避免重复计算。EasyCache 不需要离线分析、预计算或参数调优。", "conclusion": "该方法在诸如OpenSora、Wan2.1和HunyuanVideo等大尺度视频生成模型上进行了全面研究，实现了领先的加速性能，相较于原基线，推理时间最多可减少2.1-3.3倍，同时保持高视觉保真度，峰值信噪比(PSNR)提升高达36%，使EasyCache成为高质量视频生成在研究和实际应用中的高效且高度可行的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02827", "html_url": "https://arxiv.org/abs/2507.02827", "title": "USAD：一种无监督数据增强时空注意扩散网络", "title_en": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network", "authors": "Ying Yu,Hang Xiao,Siyao Li,Jiarui Li,Haotian Tang,Hanyu Liu,Chao Li", "background": "人类活动识别（HAR）的主要目标是从传感器数据中推断正在进行的人类行为。尽管研究众多，HAR 仍面临诸如罕见活动样本稀缺、高阶特征提取不足以及轻量化设备上模型性能不佳等关键挑战。", "innovation": "本文提出了一种全面的优化方法，基于多注意力交互机制。首先，使用无监督的统计数据引导的扩散模型进行数据增强，以缓解标记数据稀缺和严重类别不平衡的问题。其次，设计了一个多分支时空交互网络，通过并行的3*3、5*5 和7*7 卷积核残差分支捕获序列数据的多尺度特征。同时，融合了时间注意力机制来识别关键时间点，空间注意力增强了传感器间的交互。引入了跨分支特征融合单元以提高整体特征表示能力。最后，集成了一种自适应多损失函数融合策略，可以动态调整损失权重，优化整个模型。实验结果表明，所提出的无监督数据增强时空注意扩散网络 (USAD) 在公共数据集WISDM、PAMAP2和OPPORTUNITY 上的准确率分别为 98.84%、93.81%和80.92%，显著优于现有方法，并在嵌入式设备上的实际部署验证了其效率和可行性。", "conclusion": "实验表明，提出的USAD方法在三个公共数据集上的表现显著优于现有的HAR方法，并且在嵌入式设备上具有高效的部署可行性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02844", "html_url": "https://arxiv.org/abs/2507.02844", "title": "图像驱动上下文注入破解视觉语言模型", "title_en": "Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection", "authors": "Ziqi Miao,Yi Ding,Lijun Li,Jing Shao", "background": "随着视觉语言能力的增强，多模态大型语言模型（MLLMs）在实际应用中展现出巨大潜力。然而，视觉模态的安全性问题给其在开放环境中的部署带来了挑战。已有研究表明，可以通过直接将有害文本语义编码到视觉输入中触发目标MLLM的不良反应，但这种方式往往缺乏现实性和语义清晰度，无法完全模拟安全环境中的有害操作。", "innovation": "本文提出了一个新的攻击场景：视觉中心的破解，即利用视觉信息构建逼真的破解环境作为必要组成部分。为此，作者提出了一种名为VisCo（Visual Contextual Attack）的方法，该方法通过四种视觉策略生成辅助图像，动态构建视觉中心的破解场景，并结合自动毒性模糊和语义优化，生成最终可靠触发目标MLLM有害响应的攻击指令。实验结果显示，VisCo在MM-SafetyBench上的毒性得分为4.78，成功率为85%，远优于基线模型，其毒性得分为2.48，成功率为22.2%。", "conclusion": "VisCo方法通过图像驱动上下文注入有效地提升了破解MALLMs的能力，显著提高了攻击效果和成功率，在MALLMs的安全性研究中具有重要价值。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02798", "html_url": "https://arxiv.org/abs/2507.02798", "title": "无需训练! 基于参考的无训练实例分割", "title_en": "No time to train! Training-Free Reference-Based Instance Segmentation", "authors": "Miguel Espinosa,Chenhongyi Yang,Linus Ericsson,Steven McDonagh,Elliot J. Crowley", "background": "图像分割模型的历史性能受限于大规模标注数据获取的高成本。Segment Anything Model (SAM) 通过一种可编程的、语义无关的分割范式缓解了这一问题，但仍需手动视觉提示或复杂的领域依赖性提示生成规则来处理新图像。我们研究在这种新条件下基于参考图像的物体分割任务，以减少新的负担。研究发现，通过利用基础模型学习到的强语义先验，可以自动生成实例级分割掩模以供下游任务使用。", "innovation": "本文提出了一种无训练的多阶段方法，该方法结合了（1）记忆库构建；（2）表示聚合；（3）语义感知特征匹配，利用基础模型学到的强语义先验来识别参考图像和目标图像之间的对应关系，从而实现自动生成实例级分割掩模。这种方法显著提高了分割指标，实现了COCO多对象分割和PASCAL VOC少量标注场景下最佳性能，并在跨域少量标注基准测试中优于现有无训练方法。", "conclusion": "实验结果表明，该方法在分割指标上取得了显著提升，达到了COCO FSOD（36.8% nAP），PASCAL VOC Few-Shot（71.2% nAP50），并且在跨域少量标注基准测试中优于其他无训练方法（22.4% nAP）."}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02857", "html_url": "https://arxiv.org/abs/2507.02857", "title": "AnyI2V: 使用运动控制动画任何条件图像", "title_en": "AnyI2V: Animating Any Conditional Image with Motion Control", "authors": "Ziye Li,Hao Luo,Xincheng Shuai,Henghui Ding", "background": "近期，特别是在扩散模型方面的进展，推动了文本到视频(T2V)和图像到视频(I2V)合成领域的发展。然而，现有方法在有效整合动态运动信号和灵活的空间约束方面仍存在挑战。现有的T2V方法经常依赖文本提示，这在本质上对生成内容的空间布局缺乏精确控制。相比之下，I2V方法受限于依赖真实图像，这限制了合成内容的编辑性。虽然一些方法结合了ControlNet引入基于图像的条件，但它们通常缺乏明确的运动控制并且需要复杂的训练过程。", "innovation": "本文提出了一个无需训练的框架AnyI2V，该框架允许用户定义任何条件图像的运动轨迹进行动画处理。AnyI2V支持更广泛的模态作为条件图像，包括ControlNet不支持的网格和点云数据类型，从而实现更具灵活性和多样性的视频生成。此外，AnyI2V支持混合条件输入，并通过LoRA和文本提示实现风格迁移和编辑。", "conclusion": "大量实验证明，AnyI2V在空间和运动控制视频生成方面具有卓越的表现，并为该领域提供了新的视角。代码可以在[该链接]获取。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02861", "html_url": "https://arxiv.org/abs/2507.02861", "title": "LiteReality：从RGB-D扫描构建的图形就绪3D场景重建", "title_en": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans", "authors": "Zhening Huang,Xiaoyang Wu,Fangcheng Zhong,Hengshuang Zhao,Matthias Nießner,Joan Lasenby", "background": "目前的3D虚拟场景重建方法可能无法同时有效地生成紧凑、逼真且可交互的模型。尽管近年来取得了一定进展，但这些模型在实现个体物体和高保真物理交互方面仍存在局限性。", "innovation": "LiteReality 提出了一种创新的管道，能够将室内环境的RGB-D扫描转化为紧凑、真实的3D虚拟副本，支持关键图形管道特征，如物体个体性、可动性、高质量的基于物理的渲染材料和基于物理的交互。它首先通过结构化的场景图理解场景并解析为连贯的3D布局和物体，然后从精心整理的资产数据库中检索视觉上最相似的3D艺术家设计模型以重建场景。此外，Material Painting 模块增强现实感，通过恢复高质量、空间变化的材质，训练免费的对象检索模块在Scan2CAD基准上实现了最先进的相似性性能，并且具有鲁棒的材料绘画模块，能在图像风格变化极大的情况下从2D图像转移外观到3D资产上，即使在严重对齐错误、遮挡和光照不佳的情况下也能适用。", "conclusion": "LiteReality 已在真实的扫描和公开数据集上证明了其有效性。重建的场景紧凑可编辑，并完全兼容标准图形管道，适用于AR/VR、游戏、机器人和数字孪生等应用。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02859", "html_url": "https://arxiv.org/abs/2507.02859", "title": "在多模态大语言模型中引导式基于grounded的chain-of-thought方法以实现高效模型适应", "title_en": "Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation", "authors": "Jiaer Xia,Bingkui Tong,Yuhang Zang,Rui Shao,Kaiyang Zhou", "background": "多模态大语言模型在使用自然语言解读图像方面表现出色。然而，这些模型在未使用大规模数据集重新训练的情况下难以适应专门的视觉任务，例如图表理解。这种问题源于预训练数据集与下游数据集之间的不匹配：预训练数据集主要集中在场景和对象上，而对于非对象的专门化图像（如图表和表格）的信息则较少。因此，本文探讨了通过在多模态大语言模型中使用带有chain-of-thought（CoT）推理的数据来进行模型适应的方法，并提出了一种基于引导式方法的grounds chain-of-thought（GCoT），从而在缺乏数据的情况下有效地提升模型的适应能力。", "innovation": "提出了一个名为Grounded Chain-of-Thought（GCoT）的简单引导式方法，通过将边界框等接地信息注入CoT数据，使推理步骤更加忠实于输入图像。这种方法有助于多模态大语言模型在数据有限的情况下更好地适应专门的视觉任务，并显著提高了模型的适应性能。", "conclusion": "本文在五个涵盖图表、表格、收据和报告等不同视觉格式的专门化视觉任务上对提出的GCoT进行评估，结果表明，在数据有限的情况下，GCoT方法显著提升了模型的性能，优于微调和蒸馏方法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02863", "html_url": "https://arxiv.org/abs/2507.02863", "title": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "title_en": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "authors": "Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu", "background": "从有序或无序图像集合进行密集的3D场景重建是将计算机视觉研究推向实际应用场景的关键步骤。之前的 方法基于DUSt3R范式，将图像对稀疏地合并到共享坐标系中。随后的方法保持隐式记忆从而实现从更多图像进行密集的3D重建。然而，这种隐式记忆的容量有限，并且可能会导致早期帧信息丢失。", "innovation": "提出了Point3R，一种针对密集的3D流式重建的在线框架。具体来说，维护了一个与当前场景3D结构直接关联的显式空间指针记忆。每个此记忆中的指针都分配了一个特定的3D位置，并将全局坐标系中附近的场景信息汇聚成变化的空间特征。最新帧中的信息与这一指针记忆进行明确交互，能够将当前观测紧密整合到全局坐标系中。设计了一种3D分层位置嵌入来促进这种交互，并设计了一种简单有效的融合机制，以确保指针记忆的一致性和效率。该方法在多种任务上表现出竞争力或业界最佳性能，同时具有较低的训练成本。", "conclusion": "我们的方法在各种任务上达到了竞争力或领先水平，同时具有较低的训练成本。代码已发布。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02129", "html_url": "https://arxiv.org/abs/2507.02129", "title": "生成潜空间扩散以实现高效的空间-时间数据缩减", "title_en": "Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction", "authors": "Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka", "background": "生成模型在条件设置中表现出强大的性能，可被视为一种数据压缩形式，其中条件充当紧凑的表示。然而，它们的有限可控性和重构准确性限制了它们在数据压缩中的实际应用。现有的压缩方法存在局限，这篇论文旨在通过结合变分自动编码器和条件扩散模型来解决这一问题，提出一种高效的空间-时间数据缩减方法，减少存储需求，同时保持生成的准确性。多数据集的实验结果显示，该方法在与规则基于的最先进的压缩器(SZ3)相比最高可达到10倍的压缩比，且在与基于学习的最新方法相比，在相同的重构误差下表现更好，领先63%。", "innovation": "提出了一种高效的方法，结合了变分自动编码器和条件扩散模型，将少量关键帧压缩到潜空间中，并通过生成插值使用这些帧作为条件输入来重建剩余帧，消除了存储每帧潜空间表示的需求，从而实现高精度的空间-时间重构同时显著降低存储成本。", "conclusion": "实验结果表明，该方法在多个数据集上达到了最高的压缩比，与现有的基于规则的最先进技术相比，最高可达到10倍的压缩比，且在相同的重构误差下，与基于学习的最新方法相比，表现领先63%。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02411", "html_url": "https://arxiv.org/abs/2507.02411", "title": "基于稀疏无姿态依赖2D超声心动图切片的3D心脏重建", "title_en": "3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices", "authors": "Zhurong Chen,Jinhua Chen,Wei Zhuo,Wufeng Xue,Dong Ni", "background": "超声心动图（echo）在心血管疾病的临床实践中起着不可或缺的作用。然而，超声成像通常只提供少数几个固定视角的二维（2D）横截面图像，这使得很难解读并导致估计心临床参数（例如左心室[LV]的体积）的不准确。三维（3D）超声成像提供了3D量化的方法，但仍旧受到空间和时间分辨率的限制以及高度依赖于手动勾勒的限制，从而构成了挑战。", "innovation": "本文提出了一种创新框架，用于从临床实践中常用的2D超声心动图切片中重建个性化的3D心脏解剖结构。具体来说，设计了一种新颖的3D重建流水线，交互性优化2D切片的3D姿态估计和3D集成过程，使用隐式神经网络逐步将先验3D心脏形状转化为个性化的3D心脏模型，从而克服了现有的3D超声成像的限制。此外，该方法还能基于2D超声心动图切片估计右心室[RV]的体积，使得在6个平面使用时，LV体积估计的误差降至1.98%，比双平面方法的误差低了90%以上，在无姿态依赖的情况下实现了三维心脏重建的新突破。", "conclusion": "本研究提供了一种新的方法，用于心肌超声中的个性化3D结构和功能分析，并具有巨大的临床应用潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02024", "html_url": "https://arxiv.org/abs/2507.02024", "title": "TubuleTracker:一款高保真度的免费软件，用于量化血管生成结构和成熟度", "title_en": "TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity", "authors": "Danish Mahmood,Stephanie Buczkowski,Sahaj Shah,Autumn Anthony,Rohini Desetty,Carlo R Bartoli", "background": "体外内皮细胞培养广泛用于研究血管生成。通常，细胞网络的显微图像需要手动分析，这个过程耗时且主观性强。自动工具如ImageJ虽然能够协助，但往往速度慢且准确性不足。此外，随着内皮网络的逐渐复杂，传统结构指标可能无法全面反映网络的成熟度。因此，开发出一种能够快速、客观地量化内皮网络结构和成熟度的软件工具是必要且有意义的。", "innovation": "本研究开发了tubuleTracker，这是一种能够快速、客观地量化血管生成结构和成熟度的软件工具。相比手动操作和基于ImageJ的分析，tubuleTracker显著提高了分析速度，并具有更高的一致性。研究发现，特别是血管圆度，可以有效捕捉血管生成的成熟度。tubuleTracker作为一种免费分享软件，将为生物医学研究社区提供便利。", "conclusion": "tubuleTracker比手动操作和基于ImageJ的分析更快、更一致。特别是血管圆度在捕捉血管生成成熟度上非常有效。tubuleTracker作为免费分享软件，可用于生物医学研究。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02367", "html_url": "https://arxiv.org/abs/2507.02367", "title": "动态18F-FDG正电子发射断层扫描中的动脉输入函数稳健且多用途的深度学习预测模型", "title_en": "A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\\left[^{18}\\text{F}\\right]$FDG PET imaging", "authors": "Christian Salomonsen,Luigi Tommaso Luppino,Fredrik Aspheim,Kristoffer Wickstrøm,Elisabeth Wetzer,Michael Kampffmeyer,Rodrigo Berzaghi,Rune Sundset,Robert Jenssen,Samuel Kuttner", "background": "在小动物动态正电子发射断层扫描（PET）研究中，动态PET和动力学建模是推进示踪剂开发研究的关键。准确的动力学建模需要精确的输入函数估计，传统上是通过动脉血样获得。然而，对小动物（如小鼠）进行动脉插管涉及复杂的、耗时的和致死性程序，限制了纵向研究的进行。", "innovation": "本文提出了一种无创的、基于全卷积深度学习的方法（FC-DLIF），可以直接从PET成像预测输入函数，从而可能消除在动态小动物PET中进行动脉采样的需要。该模型包括一个空间特征提取器，它作用于PET序列的时间体积帧，提取空间特征。这些特征随后由一个时间特征提取器处理，该提取器预测了动脉输入函数。该方法使用18F-FDG数据的图像和动脉血曲线进行了训练和评估，并进一步在使用两种额外放射性示踪剂（18F-FDOPA和68Ga-PSMA）的成像数据上进行了评估。模型还在数据截断和时间偏移情况下进行了评估，以模拟更短和偏移的PET扫描。此外，FC-DLIF模型即便在截断和偏移的样本中也能可靠地预测动脉输入函数，尽管当使用未包含在训练数据中的不同示踪器采集的样本时，该模型无法预测动脉输入函数。", "conclusion": "我们的深度学习输入函数提供了一种无创且可靠的替代动脉血样方法，证明了对时间偏移和不同扫描持续时间的鲁棒性和灵活性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02645", "html_url": "https://arxiv.org/abs/2507.02645", "title": "公平的深度假脸检测器可以泛化", "title_en": "Fair Deepfake Detectors Can Generalize", "authors": "Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli", "background": "深度fake检测模型面临两个关键挑战：对未见过的操作进行泛化和在人群群体中实现人口统计公平性。现有的方法往往表明这两者是固有冲突的，揭示了它们之间的一项权衡。", "innovation": "首次揭开了公平性与泛化之间的因果关系，并通过控制混淆因子（数据分布和模型容量）来增强公平性干预以提高泛化。提出了Demographic Attribute-insensitive Intervention Detection (DAID)框架，包括：种群感知的数据重新平衡和种群无感特征聚合。这些方法在三个跨域基准测试中均显著优于多种现有的检测器，证实了其理论基础和实际有效性。", "conclusion": "DAID框架在公平性和泛化方面均优于多种现有的检测器，验证了其理论基础和实际效果。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02310", "html_url": "https://arxiv.org/abs/2507.02310", "title": "基于自适应记忆对齐的适应概念漂移的整体连续学习", "title_en": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment", "authors": "Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk", "background": "传统的持续学习方法强调知识保留，主要通过缓解灾难性遗忘来优化。这些方法假设先前学习任务的数据分布是静态的，但忽略了实际数据流中的动态变化。概念漂移永久地改变了已见过的数据，要求模型同时保持稳定性和快速适应能力。", "innovation": "提出了一个整体框架来处理概念漂移相关的持续学习问题，设计了一种名为自适应内存对齐（AMR）的方法。AMR 是一种轻量级的解决方案，通过有意识地从回放缓冲器中删除过时样本并用新的样本填充，来适应新的数据分布。这种方法有效平衡了性能与标注数据和计算资源的需求。", "conclusion": "通过在标准视觉基准数据集上引入四个概念漂移变体，实验结果表明AMR在保持高准确率的同时，显著降低了所需的数据标注和计算成本。这使AMR成为在非静态持续学习环境中同时实现稳定性和适应性的可扩展解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "基于能量的变换器是可扩展的学员和思维者", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "近年来，类似于人类系统2思维的推理时计算技术因为改善模型性能而变得流行。然而，现有的大多数方法存在几个限制：它们具有模式特异性（例如，仅在文本中有效）、问题特异性（例如，在可验证的领域中，如数学和编程）或需要在未监督预训练的基础上额外的监督/训练（例如，验证者或可验证的奖励）.", "innovation": "作者通过学习显式验证输入与候选预测之间的兼容性，将预测问题重新定义为基于此验证器的优化问题，提出了基于能量的变换器（EBTs），这是一种新的基于能量模型（EBMs）。相比主导的Transformer++方法，EBTs在训练期间具有更快的扩展速度，对数据、批次大小、参数、FLOPs和深度有更高的扩展率。在推理过程中，EBTs表现出使用更少前向遍历次数的图像去噪效果优于变换器增强变换器，并且在语言任务中提高了29%的系统2思维性能。EBTs在大多数下游任务中表现出色，即使在预训练表现相同时，结果也更好，这表明EBTs比现有方法具有更好的泛化能力。因此，EBTs为扩展模型的学习和思维能力提供了一种新的有前途的范式。", "conclusion": "基于能量的变换器能通过未监督学习来扩展系统的思考能力，具有更好的扩展性和泛化能力，是一种有前途的新范式来增强模型的学习和思考能力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02619", "html_url": "https://arxiv.org/abs/2507.02619", "title": "L-VAE: 变分自编码器中的可学习Beta值以实现解纠缠表示", "title_en": "L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation", "authors": "Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural", "background": "在该论文中，提到了将变分自动编码器（VAE）扩展为eta-VAE。但是，eta-VAE中的超参数eta是通过经验调整的，存在其局限性。为了解决这个问题，作者提出了一种新的模型L-VAE，它可以学习变分自动编码器中表示与成本函数的超参数。L-VAE通过学习损失函数中各项的相对权重来动态平衡重构损失和解纠缠损失之间的权衡。", "innovation": "L-VAE模型将损失项的权重和模型结构的参数同时学习。此外，L-VAE加入了额外的正则项来防止对重构损失或解纠缠损失的偏见。实验结果显示，L-VAE在解纠缠性度量上的表现最好或次好，尤其是在dSprites、MPI3D-complex、Falcor3D和Isaac3D数据集上。对于CelebA数据集，定性的实验也证明了L-VAE在面部属性解纠缠方面取得的成功。", "conclusion": "该研究通过学术实验证明，相较于eta-VAE、VAE、ControlVAE、DynamicVAE和sigma-VAE，L-VAE在多个数据集上提供了最佳或次佳的性能，特别是在解纠缠方面。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02862", "html_url": "https://arxiv.org/abs/2507.02862", "title": "RefTok: 基于参考的视频生成用分词方法", "title_en": "RefTok: Reference-Based Tokenization for Video Generation", "authors": "Xiang Fan,Xiaohang Sun,Kushan Thakkar,Zhu Liu,Vimal Bhat,Ranjay Krishna,Xiang Hao", "background": "有效地处理时间冗余仍然是学习视频模型的关键挑战。当前的方法通常将每一组帧独立处理，未能有效捕捉视频中存在的时序依赖性和冗余性。为此，本文提出了一种新颖的基于参考的分词方法RefTok，能够捕捉复杂的时序动态和上下文信息。", "innovation": "RefTok方法通过一个未量化的参考帧来对一组帧进行编码和解码。解码时，RefTok能够保持动作连续性和帧间对象的外观一致性。在K600、UCF-101、BAIR Robot Pushing和DAVIS等4个视频数据集上，RefTok显著优于当前最先进的分词方法（Cosmos和MAGVIT），在相同或更高的压缩比率下，提升所有评价指标（PSNR、SSIM、LPIPS）平均36.7%。此外，在BAIR Robot Pushing任务中使用RefTok的潜变量训练视频生成模型，所有生成指标上均优于MAGVIT-L，而MAGVIT-L具有四倍的参数量，平均提高27.9%。", "conclusion": "RefTok方法在保持动作连续性和对象外观一致性方面表现出色，显著提升了视频生成模型的性能，在多个评价指标上均优于当前最先进的方法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02302", "html_url": "https://arxiv.org/abs/2507.02302", "title": "DoMIX：一种高效的细调框架，利用领域知识", "title_en": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning", "authors": "Dohoon Kim,Donghun Kang,Taesup Moon", "background": "Domain-Adaptive Pre-training (DAP) 方法由于其在模型微调中的有效性而引起了关注。虽然连续的 DAP 方法有望开发出能够逐步整合不同领域数据集的预训练模型，但现有方法存在高计算成本和 GPU 内存使用，对增量数据顺序敏感，以及提供一个适合所有终端任务的统一模型，这与 DAP 的本质相悖的问题.", "innovation": "我们提出了 DoMIX，这是一种新颖的方法，通过利用 LoRA 模块（一种代表性的参数高效微调方法）来解决这些挑战。该方法允许高效且并行的领域适应预训练，具有对领域顺序的鲁棒性，并能够充分利用积累的知识，为特定任务提供定制的预训练模型。该方法还可以扩展到标准的 LLM 微调场景之外.", "conclusion": "我们的方法通过 LoRA 模块实现高效且并行的 DAP，具有对领域顺序的鲁棒性，并有效利用累积的知识为特定任务提供定制的预训练模型。此外，我们的方法还可以扩展到标准的 LLM 微调场景之外。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02674", "html_url": "https://arxiv.org/abs/2507.02674", "title": "实时基于图像的光照处理光斑", "title_en": "Real-time Image-based Lighting of Glints", "authors": "Tom Kneiphof,Reinhard Klein", "background": "基于图像的光照是一种广泛用于在实时渲染应用中再现现实世界光照条件下的着色的技术。尤其是在涉及细小微面体散射导致闪烁或反光的材料的挑战性场景中，这一技术显得尤为重要。然而，传统的基于图像的光照方法在处理此类材料时效率较低，难以实现动态的材料属性和环境映射。本文旨在提出一种高效的光斑实时处理方法，以增强图像基于的光照技术在闪烁或反光材料中的应用能力。", "innovation": "本文提出了一种新型的基于图像的光照方法，实现了在面积光源照明下对光斑的实时渲染，通过标准的环境映射过滤技术，相较于传统方法，该方法执行速度足够快，能够在每一帧内进行处理。方法假设环境映射可以划分为少数均匀辐射的区域，并通过高斯函数过滤相应的指示函数，以获取每个微面体从每个区域反射光线的概率。在着色时，通过我们的新型双门高斯近似二项分布的方式进行分级采样，并与实际渲染结果进行对比，证实了该方法的有效性和稳定性，能够适应多种材料属性和光照条件，并在渲染性能上具有较小的额外开销。", "conclusion": "通过采用预先过滤环境映射，并在每一帧内快速处理，本文的方法能够有效地模拟出广泛材料属性和光照条件下的光斑效果，相比仅从单一方向光源渲染光斑，该方法仅需要两倍的内存存储预先过滤的环境映射。这种方法不仅提高了渲染效率，还增强了材料的真实感，展现了其在实时渲染中的广泛应用潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02671", "html_url": "https://arxiv.org/abs/2507.02671", "title": "基于嵌入的差分隐私条件VAE联邦数据共享", "title_en": "Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs", "authors": "Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig", "background": "深度学习（DL）在医疗成像领域取得了革命性的发展，但其采用受到了数据稀缺性和隐私法规的限制，阻碍了对多样化数据集的访问。联邦学习（FL）能够实现去中心化的训练，但面临高昂的通信成本，并且通常只能专门用于单一下游任务，限制了灵活性。", "innovation": "提出了一种通过差分隐私生成模型进行数据共享的方法。采用基础模型提取紧凑且有信息价值的嵌入，减少冗余并降低计算负担。客户端共同训练差分隐私条件变分自编码器（DP-CVAE），以建模全球隐私意识数据分布，支持多种下游任务。这种方法在多个特征提取器的验证下增强了隐私、可扩展性和效率，优于传统的FL分类器，并确保差分隐私。此外，DP-CVAE生成的嵌入比DP-CGAN具有更高的保真度，同时所需的参数只有前者的五分之一。", "conclusion": "该方法通过嵌入的DP-CVAE模型，在保证隐私和满足多样任务需求的同时，提升了效率和可扩展性，具有显著的优势。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02289", "html_url": "https://arxiv.org/abs/2507.02289", "title": "CineMyoPS: 从 cine 心脏 MRI 中分割心肌病理", "title_en": "CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR", "authors": "Wangbin Ding,Lei Li,Junyi Qiu,Bogen Lin,Mingjing Yang,Liqin Huang,Lianming Wu,Sihan Wang,Xiahai Zhuang", "background": "心肌梗死（MI）是全球主要的死亡原因之一。晚期钆增强（LGE）和 T2 加权心脏磁共振（CMR）成像分别用于识别疤痕和水肿区域，这两个区域对于 MI 风险分层和预后评估至关重要。虽然结合多序列 CMR 的互补信息是有用的，但获得这些序列可能会很耗时且成本高昂，例如由于使用对比剂。心肌节运动 CMR 是一种快速且无需对比剂的成像技术，能够可视化急性 MI 引起的心肌运动和结构异常。因此，提出了一种新的端到端深度神经网络，称为 CineMyoPS，仅从 cine CMR 图像中分割心肌病理，即疤痕和水肿。", "innovation": "CineMyoPS 提取与 MI 相关的运动和解剖特征，并设计了一种一致性的损失函数，以促进这些特征的联合学习。还提出了时间序列聚合策略来整合心脏周期中的 MI 相关特征，从而提高心肌病理分割的准确性。实验结果表明，CineMyoPS 在心肌病理分割、运动估计和解剖分割方面取得了令人鼓舞的性能。", "conclusion": "CineMyoPS 在多中心数据集上的实验结果证明了其在心肌病理分割、运动估计和解剖分割方面取得了显著效果，为通过 cine CMR 图像识别心肌损伤提供了新的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02668", "html_url": "https://arxiv.org/abs/2507.02668", "title": "MEGANet-W：一种基于小波引导注意力机制的弱边界息肉检测框架", "title_en": "MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection", "authors": "Zhe Yee Tan", "background": "结肠息肉的分割对于早期发现结肠癌至关重要，但弱和低对比度的边界限制了自动化的准确性。现有的深度模型要么模糊了精细边缘细节，要么依赖于手工设计的滤波器，在不同的成像条件下表现不佳。", "innovation": "提出了MEGANet-W，这是一种利用小波引导边缘注意机制的网络，通过在解码器的每个阶段注入方向性且参数自由的Haar小波边缘图来重新校准语义特征。该模型的两大贡献是：(1)多方向边缘提取的两层Haar小波头部；(2)小波边缘引导注意力(WEGA)模块，将小波线索与逆向和输入分支融合起来。在五个公开的息肉数据集上，MEGANet-W始终优于现有方法，mIoU提高了2.3%，mDice提高了1.2%，且没有引入额外的学习参数。", "conclusion": "MEGANet-W在多个公开的息肉数据集上表现出色，显著提高了息肉分割的准确性，特别是在处理弱边界问题时。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2211.16289", "html_url": "https://arxiv.org/abs/2211.16289", "title": "轻量级结构感知注意力机制在视觉理解中的应用", "title_en": "Lightweight Structure-Aware Attention for Visual Understanding", "authors": "Heeseung Kwon,Francisco M. Castro,Manuel J. Marin-Jimenez,Nicolas Guil,Karteek Alahari", "background": "注意力操作已经在视觉理解中广泛应用，因为它可以通过可调整的内核提供一定的灵活性。然而，这种操作仍然存在内在的局限性：(1) 注意力内核不够区分性强，导致高度冗余；(2) 在计算和内存上的复杂性是序列长度的二次方。本文介绍了新的注意力操作，即轻量化结构感知注意力操作(LiSA)，具有对数线性复杂度和更好的表示能力。", "innovation": "LiSA通过学习结构模式转换注意力内核，增强了表示能力。相对位置嵌入(RPEs)作为乘法权重进行编码以改善内核的表示能力，并通过近似方法来获得对数线性复杂度。", "conclusion": "实验和分析表明，所提出的操作在ImageNet-1K及Kinetics-400视频动作识别、COCO目标检测和实例分割、ADE-20K语义分割等下游任务上均优于自我注意力和现有操作，取得了最先进的结果。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02672", "html_url": "https://arxiv.org/abs/2507.02672", "title": "MISCGrasp：利用多尺度集成和对比学习提升体积抓取", "title_en": "MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping", "authors": "Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang", "background": "机器人抓取在适应不同形状和大小的物体时面临挑战。为此，本文提出了一种名为MISCGrasp的体积抓取方法，该方法结合了多尺度特征提取和对比特征增强，以实现自适应抓取。MISCGrasp利用Insight Transformer进行高层和低层特征之间的基于查询的交互，Empower Transformer则选择性地关注最高层特征，以同时关注细部几何细节和整体几何结构之间的平衡。此外，MISCGrasp利用多尺度对比学习来利用正样本间的相似性，从而确保多尺度特征的一致性。", "innovation": "提出了一种名为MISCGrasp的体积抓取方法，该方法结合了多尺度特征提取和对比特征增强，通过Insight Transformer实现高层和低层特征之间的基于查询的交互，通过Empower Transformer选择性地关注最高层特征，使得模型同时关注细部几何细节和整体几何结构之间的平衡，利用多尺度对比学习来确保多尺度特征的一致性，从而在桌面去杂等任务中表现出色，优于对照组和变体方法。", "conclusion": "在仿真和现实环境中的大量实验表明，MISCGrasp在桌面去杂任务中表现出色，优于基线方法和变体方法。更多详细内容可在[此处](this https URL)获取。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.05945", "html_url": "https://arxiv.org/abs/2408.05945", "title": "MV2DFusion: 融合模态特定对象语义的多模态3D检测", "title_en": "MV2DFusion: Leveraging Modality-Specific Object Semantics for Multi-Modal 3D Detection", "authors": "Zitian Wang,Zehao Huang,Yulu Gao,Naiyan Wang,Si Liu", "background": "自动驾驶汽车的兴起显著增加了对稳健的3D物体检测系统的需求。虽然摄像头和LiDAR传感器各具优势--摄像头提供丰富的纹理信息，而LiDAR提供精确的3D空间数据，但依赖单一模态往往会导致性能限制。目前的检测方法面临着融合不同模态数据的挑战，无法很好地整合两者的优点，从而影响了在各种场景中的检测效率和准确性。", "innovation": "本文提出了一种多模态检测框架MV2DFusion，通过先进的基于查询的融合机制整合了两种模态的优势。MV2DFusion包括图像查询生成器和点云查询生成器，它们分别用于对齐图像特定属性和点云特定属性，使物体语义在多模态之间得到有效的结合，而不会偏向单一模态。这种框架设计确保了在各种场景下高效和准确的物体检测，并且具有高度的灵活性，可以与任何基于图像和点云的检测器集成，展示了其适应性和未来发展的潜力。", "conclusion": "我们对MV2DFusion在nuScenes和Argoverse2数据集上的广泛评估表明，该框架在长范围检测场景中表现尤为突出，达到了最先进的性能水平。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02864", "html_url": "https://arxiv.org/abs/2507.02864", "title": "MultiGen: 在模拟中使用多模态生成来学习多模态策略", "title_en": "MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real", "authors": "Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros", "background": "机器人在现实世界中需要整合多种感官模态以有效行动。然而，学习大规模的多模态策略仍然具有挑战性。尽管模拟提供了一种有效的解决方案，视觉模态已经从高保真模拟器中受益，但其他模态（例如声音）则很难进行模拟。因此，模拟到现实世界的转移主要在基于视觉的任务上取得成功，而多模态的转移仍然未被充分实现。", "innovation": "为了解决这些挑战，这篇文章通过引入MultiGen框架，将大规模生成模型整合到传统的物理模拟器中，使多感官模拟成为可能。该框架展示了多感官模拟在机器人倒水动态任务中的应用，这种任务需要依赖多模态反馈。通过以模拟视频为条件生成逼真音频，该方法能够使用丰富的视听轨迹进行训练，而无需任何实际机器人数据。这种方法在新的容器和液体的真实世界倒水任务中展示了有效的零样本转移，突显了生成模型在模拟难以建模的模态以及缩小多模态模拟到现实差距方面的潜力。", "conclusion": "通过引入MultiGen框架，该研究成功将难以建模的多模态任务转移到了现实世界，展示了多模态生成模型在多模态模拟中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.05766", "html_url": "https://arxiv.org/abs/2405.05766", "title": "向XAI系统中的新型用户信任度量方法", "title_en": "Towards a Novel Measure of User Trust in XAI Systems", "authors": "Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho", "background": "随着深度学习模型的广泛使用，尽管这些模型在预测准确性方面表现出色，但它们的不透明性却降低了用户对自动化系统的信任。这种背景下，可解释的人工智能（XAI）方法应运而生，旨在通过解释模型决策的依据来提升用户信任度。本文旨在开发一种新的信任度量方法，以改进XAI系统的性能并增强用户对其的信任。通过将性能指标和信任指标结合，作者提出了一个多方面的评估方法，并通过三个案例研究验证了该方法的有效性，证明了其在不同场景下的优越灵敏度相对于现有方法而言有所改进。", "innovation": "本文提出了一种新的信任度量方法，该方法结合了性能指标和信任指标，从客观角度改进XAI系统的性能。与现有方法相比，该方法能够更好地适应不同场景，并提高了用户信任度的重要指标。作者通过三个案例研究验证了该方法的有效性和优越性，显示了其对现有方法的改进和提升。", "conclusion": "本文提出了一种新的信任度量方法，通过将其应用于XAI系统，展示了改进性能和提高用户信任度的效果。通过三个案例研究，该方法在不同场景下表现出更高的灵敏度，验证了其相对于现有方法的有效性和优越性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2303.06285", "html_url": "https://arxiv.org/abs/2303.06285", "title": "DeltaEdit: 探索无需文本训练的文本驱动图像编辑", "title_en": "DeltaEdit: Exploring Text-free Training for Text-Driven Image Manipulation", "authors": "Yueming Lyu,Tianwei Lin,Fu Li,Dongliang He,Jing Dong,Tieniu Tan", "background": "文本驱动的图像编辑在训练灵活性和推断灵活性方面仍然具有挑战性。条件生成模型高度依赖于昂贵的标注训练数据。最近的框架依赖于预训练的视觉-语言模型，但在操作文本提示或推断时需要调整超参数，这限制了它们的应用。因此，如何简化训练过程，提高模型在无标注数据下的鲁棒性和普适性成为亟待解决的问题。", "innovation": "提出了一个名为DeltaEdit的新框架，旨在解决上述问题。该框架的关键设计理念是研究并确定一个空间，即delta图像和文本空间，该空间使得CLIP视觉特征差异与源文本和目标文本的CLIP文本嵌入差异之间具有良好的对齐分布。基于CLIP delta空间，DeltaEdit网络在训练阶段将CLIP视觉特征差异映射为StyleGAN的编辑方向，而在推断阶段则从CLIP文本特征差异中预测StyleGAN的编辑方向，从而实现了无需文本训练的方法，并在训练后能够良好地泛化到各种文本提示，实现零样本推断。", "conclusion": "DeltaEdit框架在无需文本训练的情况下，实现了文本驱动的图像编辑能力，提高了模型在多种文本提示下的泛化能力和推断效率，简化了模型训练过程。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.03782", "html_url": "https://arxiv.org/abs/2409.03782", "title": "评估笔记本翻新软件的不确定性与鲁棒性", "title_en": "Assessing the Uncertainty and Robustness of the Laptop Refurbishing Software", "authors": "Chengjie Lu,Jiahui Wu,Shaukat Ali,Mikkel Labori Olsen", "background": "翻新笔记本电脑可以延长其使用寿命并减少电子废物，有助于构建可持续的未来。丹麦技术研究所(DTI)专注于研发多种受软件驱动的机器人应用，包括笔记本电脑的翻新。翻新的重要步骤之一是清洁，这需要识别和移除笔记本上的贴纸。软件在这一过程中起到关键作用，例如，它集成了多种物体检测模型，能够自动识别和移除贴纸。然而，由于贴纸类型多样（如形状、颜色、位置），识别贴纸具有高度不确定性，需要量化这种不确定性，从而降低移除贴纸时的风险。为了进行不确定性量化，采用了蒙特卡洛 Dropout 方法来评估六个由DTI开发的贴纸检测模型（SDMs），使用三个数据集：原始图像数据集和两个使用视觉语言模型生成的数据集，即DALL-E-3和Stable Diffusion-3。此外，还提出了关于检测准确性和不确定性的新型鲁棒性度量来评估基于三种数据集生成的对抗性数据集的SDMs的鲁棒性。", "innovation": "创新之处在于：1) 采用蒙特卡洛 Dropout 方法来量化由多个物体检测模型识别的贴纸的不确定性；2) 提出了一种基于视觉语言模型生成新数据集的方法；3) 发展了新的检测准确性和不确定性的鲁棒性度量标准；4) 提供了根据不同指标选择最佳贴纸检测模型的指导原则和经验教训。", "conclusion": "评估结果显示，不同的贴纸检测模型在不同指标上表现不同。基于该结果，提供了一系列指引以帮助选择适合不同场景的模型，并总结了研究中获得的经验教训。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.19688", "html_url": "https://arxiv.org/abs/2411.19688", "title": "SURE-VQA: 系统理解医疗VQA任务中的鲁棒性评估", "title_en": "SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks", "authors": "Kim-Celine Kahl,Selen Erkan,Jeremias Traub,Carsten T. Lüth,Klaus Maier-Hein,Lena Maier-Hein,Paul F. Jaeger", "background": "视觉-语言模型（VLMs）在医疗任务，如视觉问答(VQA)中具有巨大的潜力，可以作为患者和临床医生的互动助理。然而，它们在未见数据上的鲁棒性仍然存在关键问题，这限制了它们的安全部署。目前的实验设置无法提供充分的评估，为此引入了SURE-VQA框架以改进评估方法，重点解决现有问题，系统分析VLM的鲁棒性，并提出了三个关键要求：1. 测量鲁棒性时，应使用与VQA数据相联系的实际环境中的数据；2. 传统的基于标记匹配的度量标准难以捕捉到语义，因此需要大型语言模型（LLMs）来进行更准确的语义评估；3. 模型性能往往缺乏可解释性，缺少对照基准，因此应当报告有意义的基准以评估多模态影响对VLM的影响。", "innovation": "SURE-VQA框架提出了三个关键要求，克服现有实验中的缺陷，以系统地评估VLM的鲁棒性。通过使用实际环境中的数据而非合成数据，采用了大型语言模型进行更准确的语义评估，并提供了对照基准以提高模型性能的可解释性。研究显示，没有一种微调方法在所有鲁棒性测试中都表现出色，而鲁棒性的趋势在不同方法之间比在不同数据分布之间更加稳定。此外，简单的对照基准不使用图像数据也能取得良好表现，且LoRA微调方法在内部数据上表现最佳。", "conclusion": "SURE-VQA框架能够提供系统性的鲁棒性评估，并揭示了医疗VQA任务中VLM的表现和鲁棒性特点，详细分析不同微调方法和数据分布下的表现，为未来研究提供了重要的参考。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.05827", "html_url": "https://arxiv.org/abs/2412.05827", "title": "自我指导：提高流和扩散生成能力", "title_en": "Self-Guidance: Boosting Flow and Diffusion Generation on Their Own", "authors": "Tiancheng Li,Weijian Luo,Zhiyang Chen,Liyuan Ma,Guo-Jun Qi", "background": "高质量的图像生成需要适当指导策略，而现有的指导方法要么需要特定训练，要么依赖扩散模型网络的强归纳偏差，这限制了它们的应用范围。研究表明，低质量样本可以通过检测图像密度在噪声水平降低过程中显著下降来识别，因此提出了一种自我指导（SG）策略，这一方法仅依赖模型在不同噪声水平下的采样概率，无需特别训练，并且可以灵活应用于其他采样算法。为了提高效率，还提出了SG-prev方法，重新利用前一步骤的输出结果。在不同架构的文本到图像和文本到视频生成实验中，SG与SG-prev均表现出色，尤其是Open-sourced模型如Stable Diffusion 3.5和FLUX，超越了现有的算法指标。此外，两者还能显著提高人体结构如手、脸、臂等的生成准确性，减少了人工错误。\n", "innovation": "提出了一种无需额外训练的自我指导（SG）方法，通过噪声级下降过程中检测到的低质量样本密度显著下降来提高图像质量；并引入了更高效的SG-prev方法，重新利用前一步骤的输出结果，避免了采样时间的加倍。\n", "conclusion": "SG与SG-prev在文本到图像和文本到视频生成实验中取得了优异结果，特别是在多种评估指标中超越了现有算法。此外，两者在生成生理上正确的身体结构方面也表现出积极作用，凸显了弥补人类身体艺术作品瑕疵的能力，仅通过最小的努力就能达到显著效果。\n"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.15026", "html_url": "https://arxiv.org/abs/2408.15026", "title": "回声显像进针引导的序列感知预训练", "title_en": "Sequence-aware Pre-training for Echocardiography Probe Movement Guidance", "authors": "Haojun Jiang,Teng Wang,Zhenguo Sun,Yulin Wang,Yang Yue,Yu Sun,Ning Jia,Meng Li,Shaqi Luo,Shiji Song,Gao Huang", "background": "回声显像是诊断心血管疾病的重要医疗技术，但由于其高操作复杂性，专业人员短缺成为一个问题。心脏的复杂结构和个体间的显著变异使得心脏成像具有两大挑战。现有方法仅学习人口平均水平的心脏结构，未考虑到个性化的心脏结构差异，限制了性能。医生在实际操作中会根据之前的扫描序列动态调整对患者心脏解剖结构的解读，并相应地调整扫描策略。受此启发，本文提出了一种序列感知自监督预训练方法，通过预测扫描序列中的遮罩特征和探头移动动作，学习个性化的心脏三维结构特征。实验表明，该方法可以有效减少探头引导错误，优于其他先进基线方法。", "innovation": "本文提出了一种序列感知自监督预训练方法，该方法通过预测扫描序列中的遮罩特征和探头移动动作来学习个性化的心脏三维结构特征。这种方法能够有效减少探头引导错误，并优于其他先进基线方法。", "conclusion": "本文提出的序列感知预训练方法在大规模专家级扫描数据集上进行了验证，实验结果表明，该方法可以有效减少探头引导错误，有助于解决回声显像专业人员短缺的问题。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.18038", "html_url": "https://arxiv.org/abs/2407.18038", "title": "TiCoSS: 在联合学习框架内加强语义分割和立体匹配之间的耦合", "title_en": "TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo Matching within A Joint Learning Framework", "authors": "Guanfeng Tang,Zhiyuan Wu,Jiahang Li,Ping Zhong,We Ye,Xieyuanli Chen,Huiming Lu,Rui Fan", "background": "语义分割和立体匹配是自动驾驶感知系统中的两个关键组成部分，分别类比于人类大脑的腹侧和背侧流。随着大型视觉模型和具身人工智能的最新进展，将这两大任务分别处理的方法不再是主流。当前趋势转向在联合学习框架中结合处理，特别强调这两大任务之间的特征共享。", "innovation": "本研究的主要贡献在于全面加强了语义分割和立体匹配之间的耦合。具体引入了三项创新：1）紧密耦合的门控特征融合策略，2）分层深度监督策略，3）耦合加强损失函数。这些技术贡献共同构成了最先进的TiCoSS联合学习框架，可以同时处理语义分割和立体匹配。实验表明，与现有方法相比，该方法在mIoU上提升了超过9%。", "conclusion": "通过在Kitti和vKitTI2数据集上的广泛实验，并结合定性和定量分析，证明了我们开发的策略和损失函数的有效性，以及它们的优越性能。我们将公开发布本文的源代码。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03349", "html_url": "https://arxiv.org/abs/2412.03349", "title": "公平分析与种群平衡的人脸生成以实现更公平的人脸验证", "title_en": "Fairer Analysis and Demographically Balanced Face Generation for Fairer Face Verification", "authors": "Alexandre Fournier-Montgieux,Michael Soumm,Adrian Popescu,Bertrand Luvison,Hervé Le Borgne", "background": "面部识别和验证是计算机视觉任务，随着深度表征的引入，这些任务的性能得到了提升。然而，由于面部数据的敏感性和真实训练数据集中的偏差，这些问题带来了伦理、法律和技术上的挑战。生成式AI通过创造虚构身份来解决隐私问题，但公平性问题仍然存在。", "innovation": "基于现有的DCFace最佳现有技术（SOTA）框架，作者引入了一种新的控制生成流水线，以提高公平性。通过经典的公平性指标和基于逻辑模型和ANOVA的深入统计分析，作者表明他们的生成流水线在公平性方面比其他偏见缓解方法有更多改进，同时仅略微提高了原始性能。", "conclusion": "通过引入新的控制生成流水线，作者改善了公平性问题，并在不显著降低性能的情况下达到了种群平衡。这种方法对公平的人脸验证具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02771", "html_url": "https://arxiv.org/abs/2507.02771", "title": "将智能根植于运动", "title_en": "Grounding Intelligence in Movement", "authors": "Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording", "background": "近年来，机器学习的最新进展显著提升了我们建模语言和视觉等高维数据的能力。然而，它们仍然在处理生物学系统中最基本的方面——运动——上存在问题。运动对于神经科学、医学、机器人学和生物行为学来说都是至关重要的，它对于解释行为、预测意图和促进交互至关重要。尽管在我们的智能中占据核心地位，但运动常常被视为一种附属品，而不是一种独立而丰富且结构化的模态。这反映了运动数据收集和建模过程中的深层碎片化，通常受到特定任务目标和专业领域假设的限制。然而，运动并不局限于特定领域。它反映了共享的物理约束、保守的形态结构和穿越物种和环境的目的动态。本文认为，运动应被视作AI的主要建模目标。运动本质上是有结构的，并根植于具体和物理属性中。这种结构使得运动可以使用紧凑的、低维的表示（如姿态）进行解释和计算，这使得运动比原始的高维感官输入更易建模。开发可以从不同运动数据中学习并泛化的能力将不仅提高生成建模和控制的基础能力，还将建立一个理解生物和人工智能之间行为的共享基础平台。运动不仅仅是结果，它是智能系统与世界互动的方式之窗。", "innovation": "本文提出将运动视为人工智能的主要建模目标，并强调运动作为一种有结构、根植于体和物理属性中的模态，相比原始高维感官输入具有更易于解释和计算的特点。通过开发可以从不同运动数据中学习并泛化的能力，不仅可以推动生成建模和控制的核心能力，还能建立起理解生物和人工智能之间行为的共享基础平台。此外，文章强调运动不仅是一种结果，更是智能系统与世界互动的方式。", "conclusion": "发展可以从不同运动数据中学习并泛化的能力将推动生成建模和控制的核心能力，并建立一个理解生物和人工智能之间行为的共享基础平台。运动不仅是一种结果，更是智能系统与世界互动的方式。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11074", "html_url": "https://arxiv.org/abs/2412.11074", "title": "Adapter-Enhanced Semantic Prompting for Continual Learning", "title_en": "Adapter-Enhanced Semantic Prompting for Continual Learning", "authors": "Baocai Yin,Ji Zhao,Huajie Jiang,Ningning Hou,Yongli Hu,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi", "background": "连续学习（CL）能够使模型适应不断演变的数据流。传统的CL方法存在灾难性遗忘的问题，即新知识会覆盖原有知识。这些方法通常通过保留过去数据进行重放，或者在模型中添加额外的分支来学习新知识，这需要较高的内存资源。文章旨在解决此问题，提出了一种轻量级的CL框架——Adapter-Enhanced Semantic Prompting (AESP)，该框架结合了prompt调整和适配技术，旨在高效融合语义信息并学习更具有适应性的特征，从而在CL任务中提升性能。", "innovation": "本文创新性地提出了一种轻量级CL框架——Adapter-Enhanced Semantic Prompting (AESP)，该框架通过设计语义引导的提示来增强视觉特征的泛化能力，并利用适配器高效融合语义信息。特别地，该方法旨在学习更适应连续学习任务的特征，同时研发了一种新的提示选择匹配机制来挑选适合特征适应的任务提示。实验结果表明，该方法在多种指标中表现优越，显示出其在CL领域的发展潜力。", "conclusion": "通过广泛的实验，在三个CL数据集上充分验证了提出的方法能够实现多种性能指标上的优异表现，展示出该方法在CL领域的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.10435", "html_url": "https://arxiv.org/abs/2412.10435", "title": "COEF-VQ: 成本高效的多模态大语言模型框架下的视频质量理解", "title_en": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework", "authors": "Xin Dong,Sen Jia,Ming Rui Wang,Yan Li,Zhenheng Yang,Bingfeng Deng,Hongyu Xiong", "background": "近年来，随着Multimodal Large Language Model (MLLM)技术的发展，MLLM在不同分类任务上的视频理解能力得到了广泛应用。但在实际应用中，如果需要在线部署MLLM，将面临巨大的GPU资源需求。为解决这一问题，本文提出了COEF-VQ，这是一种新颖的级联MLLM框架，旨在在短视频平台上提高视频质量理解能力的同时优化计算效率。", "innovation": "COEF-VQ框架通过引入基于熵的预筛选阶段，使用一个轻量级模型评估不确定性，筛选后将案例传递给更计算密集型的MLLM进行最终评估。该框架优先分析高不确定性的样本，显著减少了GPU使用率，同时保持了与完整MLLM部署相同的强大分类性能。此外，该框架有效提高了平台安全性并减少了在线A/B测试中不适当内容视频的观看率，降低了9.9%。", "conclusion": "通过在短视频平台的视频管理平台（VMP）上部署COEF-VQ框架，并在两个内部任务上进行了一系列详细的实验，展示了该框架在离线评估中的性能提升，并有效控制了资源消耗，突出了其在在线环境中的实际影响。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.05673", "html_url": "https://arxiv.org/abs/2502.05673", "title": "数据集蒸馏的发展：迈向可扩展和通用的解决方案", "title_en": "The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions", "authors": "Ping Liu,Jiawei Du", "background": "数据集蒸馏作为一种将大规模数据集压缩为紧凑的合成表示的技术，已成为培训现代深度学习模型的有效解决方案。此前的综述主要集中在2023年之前的进展，而本文则全面回顾了近年来的数据集蒸馏进步，尤其强调适用于大规模数据集（如ImageNet-1K和ImageNet-21K）的扩展性。作者将这些进步归类为几种关键方法：轨迹匹配、梯度匹配、分布匹配、可扩展生成方法以及解耦优化机制。", "innovation": "本文总结了数据集蒸馏领域的突破创新，如SRe2L框架，该框架用于提高效率和效果；软标签策略显著提高了模型的准确性；以及无损蒸馏技术，这些方法最大化了数据压缩的同时保持了性能。此外，本文还应对了关键挑战，包括对抗和后门攻击的鲁棒性问题，以及有效处理非IID数据分布的问题。", "conclusion": "本文通过广泛的性能比较和具体的研究方向，为研究人员和实践者提供了实用的见解，以推动数据集蒸馏的有效性和通用性，为未来的创新铺平了道路。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.16236", "html_url": "https://arxiv.org/abs/2410.16236", "title": "LLaVA-KD: 一种多模态大型语言模型的知识蒸馏框架", "title_en": "LLaVA-KD: A Framework of Distilling Multimodal Large Language Models", "authors": "Yuxuan Cai,Jiangning Zhang,Haoyang He,Xinwei He,Ao Tong,Zhenye Gan,Chengjie Wang,Zhucun Xue,Yong Liu,Xiang Bai", "background": "大型语言模型（LLMs）的成功促进了统一视觉和语言理解的多模态大型语言模型（MLLMs）的发展。但由于多模态大型语言模型（l-MLLMs）的不断增大尺寸和高计算复杂性，它们在资源受限的场景中受到限制。虽然设计了小型化的多模态大型语言模型（s-MLLMs）来减少计算成本，但它们通常会表现出性能下降。", "innovation": "本文提出了一种新颖的LLaVA-KD框架，通过将大型多模态语言模型的知识转移到小型模型中，来缓解小型化模型的性能下降问题。具体地，本文引入了多模态蒸馏（MDist）方法，将教师模型跨视觉和语言模态的稳健表示转移出来，以及关系蒸馏（RDist）方法，将教师模型捕获视觉词元关系的能力转移出来。此外，本文还提出了一个三阶段的训练方案，涵盖了蒸馏预训练、监督微调和蒸馏微调三个阶段，以充分利用提出的蒸馏策略的潜力，增强小型模型的多模态理解能力。", "conclusion": "本文的方法在不改变模型架构的情况下，显著提高了小型多模态语言模型的性能。通过广泛的实验和消融研究，验证了每个提出的组件的有效性。代码将在指定的URL处提供。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15248", "html_url": "https://arxiv.org/abs/2501.15248", "title": "使用扩散模型进行数据增强以提高胎儿切面分类精度", "title_en": "Enhancing Fetal Plane Classification Accuracy with Data Augmentation Using Diffusion Models", "authors": "Yueying Tian,Elif Ucurum,Xudong Han,Rupert Young,Chris Chatwin,Philip Birch", "background": "超声成像在医学诊断中被广泛应用，特别是在胎儿健康评估方面。然而，高质量的标注超声图像资源有限，限制了机器学习模型的训练。", "innovation": "本研究利用扩散模型生成合成超声图像，以提高胎儿切面分类的性能。不同的分类器首先在合成图像上训练，然后与真实图像进行微调。大量实验结果显示，将生成的图像纳入训练管道可以提高分类精度，优于仅用真实图像进行训练的方法。研究发现，使用扩散模型生成合成数据可以有效解决超声医学成像中的数据稀疏问题。", "conclusion": "研究表明，利用扩散模型生成的合成数据可以有效提高胎儿切面分类的准确性，并可作为克服超声医学成像中的数据稀缺挑战的有价值工具。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.01717", "html_url": "https://arxiv.org/abs/2501.01717", "title": "KeyNode-驱动几何编码用于真实世界扫描的动态人体三维网格压缩", "title_en": "KeyNode-Driven Geometry Coding for Real-World Scanned Human Dynamic Mesh Compression", "authors": "Huong Hoang,Truong Nguyen,Pamela Cosman", "background": "真实世界扫描的3D人体动态网格的压缩是一个新兴的研究领域，应用场景包括远程存在、虚拟现实和3D数字流媒体等。与具有固定拓扑结构的合成动态网格不同，扫描得到的动态网格不仅在不同帧之间具有变化的拓扑，还存在诸如孔洞和离群点等扫描缺陷，增加了预测和压缩的复杂性。此外，人体网格通常结合刚体和非刚体运动，这使得与仅表现出刚体运动的对象相比，准确预测和编码变得更加困难。", "innovation": "本文提出了一种针对真实世界扫描的人体动态网格的压缩方法，利用嵌入式关键节点。每个顶点的时域运动被形式化为邻近关键节点变换的加权距离组合，仅需传输关键节点的变换。为了提高KeyNode驱动预测的质量，引入了基于八叉树的残差编码方案和双向预测模式，使用双方向的I帧。实验结果表明，该方法在所评估的序列中实现了显著的比特率节省，平均比特率节省了58.43%，特别是在低比特率时表现尤为突出。", "conclusion": "本文提出的方法在三维动态人体网格的真实世界扫描压缩中取得了显著的比特率节省，特别是适用于低比特率情况。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16025", "html_url": "https://arxiv.org/abs/2502.16025", "title": "FeatSharp: Your Vision Model Features, Sharper", "title_en": "FeatSharp: Your Vision Model Features, Sharper", "authors": "Mike Ranzinger,Greg Heinrich,Pavlo Molchanov,Jan Kautz,Bryan Catanzaro,Andrew Tao", "background": "视觉编码器的特征图对于广泛现代AI任务至关重要，从核心感知算法（如语义分割、目标检测、深度感知等）到视觉语言模型（VLM）中的现代多模态理解。在计算机视觉领域，通用视觉骨干的前沿是视觉变换器（ViT），通常使用对比损失（如CLIP）训练。现有的ViT模型（尤其是CLIP）的主要问题是分辨率固定且较低，多数以224x224像素运行，即使是“高分辨率”版本也只是在378至448像素之间，但仍然不够灵活。", "innovation": "我们提出了一种新颖的方法，可以在不增加计算成本的情况下，对于低分辨率的视觉编码器特征图进行协调性和便宜的放大处理，以捕捉由于分辨率限制而丢失的细微细节。我们展示了这种方法在核心感知任务及使用RAVDO进行更丰富的迁移学习目标训练方面的有效性", "conclusion": "我们证明了这种方法的有效性，并为用户提供了一个代码链接。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.03997", "html_url": "https://arxiv.org/abs/2502.03997", "title": "CAD-Editor：一种带有自动训练数据合成的定位-填充框架用于基于文本的CAD编辑", "title_en": "CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing", "authors": "Yu Yuan,Shizhao Sun,Qi Liu,Jiang Bian", "background": "计算机辅助设计（CAD）在各个行业中不可或缺。基于文本的CAD编辑能够通过文本指令自动化修改CAD模型，具有巨大潜力但尚未充分探索。现有方法主要集中在设计变体生成或基于文本的CAD生成上，要么不支持文本控制，要么忽视现有CAD模型作为约束条件。需要一种框架来解决基于文本的CAD编辑的挑战，即精确对应关系的需求训练数据。", "innovation": "作者提出了CAD-Editor，这是第一个用于基于文本的CAD编辑的框架。为了应对任务所需的精确对应关系的训练数据需求，作者提出了一种自动训练数据合成管道。此外，作者提出了一个定位-填充框架来分解任务为两个子任务：定位需要修改的区域并用适当的编辑内容填充这些区域。 Large Language Models（LLMs）在这两个子任务中作为基础模型，利用其自然语言理解和CAD知识的能力。实验表明，CAD-Editor在定量和定性方面都表现出色。", "conclusion": "CAD-Editor在基于文本的CAD编辑上实现了卓越的性能。该框架提供了自动训练数据合成管道和定位-填充框架，能够有效地处理基于文本的CAD编辑任务。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.14171", "html_url": "https://arxiv.org/abs/2412.14171", "title": "关于空间思维：多模态大型语言模型如何看到、记住和回忆空间", "title_en": "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces", "authors": "Jihan Yang,Shusheng Yang,Anjali W. Gupta,Rilyn Han,Li Fei-Fei,Saining Xie", "background": "人类具备从一系列视觉观察中记住空间的视觉-空间智能。然而，大规模训练于千万级视频数据集的多模态大型语言模型（MLLMs）是否也能从视频中‘思考空间’？本研究构建了包含超过5,000个问答对的视频基于视觉-空间智能基准（VSI-Bench），发现MLLMs虽然表现出竞争性的视觉-空间智能，但依然不及人类水平。进一步分析表明，尽管局部世界模型和空间意识在这些模型中存在，但空间推理能力仍然是它们提高基准性能的主要瓶颈。传统的语言推理技术（如推理链、自我一致性、思维树）未能提升性能，而生成认知地图则在问答过程中显著增强了MLLMs的空间距离识别能力。", "innovation": "本研究提出了一个基于视频的视觉-空间智能基准VSI-Bench，涵盖大量问题-答案对；探讨了心理语言模型如何表达其在空间思考中的策略及其在空间推理中的表现；发现生成认知地图能显著提升模型在空间距离识别上的表现，而传统的语言推理技术则效果不佳。", "conclusion": "多模态语言模型虽然具备一定空间推理能力，但空间推理仍然是其提高任务性能的瓶颈。生成认知地图能够显著提升语言模型的空间距离识别能力，这是未来引导模型进行更高级空间推理的关键方向。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.19707", "html_url": "https://arxiv.org/abs/2502.19707", "title": "基于高置信度标签和高合理性损失的甲状腺结节弱监督分割框架", "title_en": "Weakly Supervised Segmentation Framework for Thyroid Nodule Based on High-confidence Labels and High-rationality Losses", "authors": "Jianning Chi,Zelan Li,Geng Lin,MingYang Sun,Xiaosheng Yu", "background": "弱监督分割方法能够高效地在含有粗略标签的超声图像中标记甲状腺结节，但存在低置信度的伪标签和低合理性损失函数的问题，这些问题导致了标签噪声的引入和分割与标签间难以捕捉到差异信息，特别是对于形状多样且复杂的结节而言效果更差。", "innovation": "本文提出了一种弱监督超声图像分割框架，通过融合四个点注释的几何变换和MedSAM模型结果，生成高置信度的框、前景和背景标签。该框架包括三个新的高合理性损失函数：1）空间一致性损失，衡量分割与框标签之间的空间一致性以及前景标签内的拓扑连续性，引导网络感知结节位置；2）对比损失，将标记的前景区域的特征向量拉近，将前景和背景区域的特征向量推开，引导网络学习结节和背景的特征分布；3）原型相关性损失，测量由比较特征与前景和背景原型得到的关联图之间的一致性，细化不明确区域至准确的结节边缘。这种方法在TN3K和DDTI数据集上达到了最先进的性能。", "conclusion": "本文提出的方法在TN3K和DDTI数据集上实现了最先进的性能，代码可从提供的链接获取。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20323", "html_url": "https://arxiv.org/abs/2502.20323", "title": "ARTalk: 通过自回归模型实现基于声音的3D头部动画", "title_en": "ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model", "authors": "Xuangeng Chu,Nabarun Goswami,Ziteng Cui,Hanqin Wang,Tatsuya Harada", "background": "现有的基于扩散的方法能够产生自然的面部动作，但其生成速度较慢，限制了其应用潜力。3D语音驱动面部动画的目的是从任意音频片段生成逼真的嘴唇动作和面部表情。", "innovation": "本文提出了一种新颖的自回归模型，该模型通过学习从语音到多尺度动作码本的映射，实现了实时生成高度同步的嘴唇动作和逼真的头部姿态及眨眼效果，并能够适应未见过的语言风格，从而生成具有独特个人风格的3D对话化身，区别于训练时的身份特征。", "conclusion": "广泛的评估和用户研究证明了我们的方法在嘴唇同步准确性和感知质量上优于现有方法。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08654", "html_url": "https://arxiv.org/abs/2501.08654", "title": "ZeroStereo: 仅从单张图像实现零样本立体匹配", "title_en": "ZeroStereo: Zero-Shot Stereo Matching from Single Images", "authors": "Xianqi Wang,Hao Yang,Gangwei Xu,Junda Cheng,Min Lin,Yong Deng,Jinliang Zang,Yurui Chen,Xin Yang", "background": "最新的监督立体匹配方法在各种基准测试中取得了显著的效果。然而，将这些方法应用于真实世界的场景仍然具有挑战性，主要是因为实时数据中标注的图像稀缺。因此，对于没有真实世界场景标注数据的零样本立体匹配问题，现有方法难以有效处理视觉遮挡等问题。", "innovation": "本文提出了一种名为ZeroStereo的新颖的立体图像生成管道，以实现零样本立体匹配。该方法通过利用单目深度估计模型生成伪视差，从任意单张图像中合成高质量的右视图。与之前通过相邻像素或随机背景填充缺失区域的方法不同，该方法使用微调的扩散填充模型恢复缺失的细节并保留语义结构。此外，本文还提出了一种无需额外训练的不确定性生成方法，以及一种自适应视差选择方法，确保了视差分布的多样性与真实性，同时避免了过度遮挡和前景扭曲。", "conclusion": "实验结果表明，使用本文方法生成的数据训练的模型，在多个数据集上实现了零样本泛化的最优性能，且仅需与Scene Flow相当的数据集体积。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16095", "html_url": "https://arxiv.org/abs/2502.16095", "title": "良好的表示，更好的解释：卷积神经网络在基于转换器的遥感图像描述中的作用", "title_en": "Good Representation, Better Explanation: Role of Convolutional Neural Networks in Transformer-Based Remote Sensing Image Captioning", "authors": "Swadhin Das,Saarthak Gupta,Kamal Kumar,Raksha Sharma", "background": "遥感图像描述（RSIC）是生成来自遥感图像的有意义描述的过程，近期得到了重要关注。编码器-解码器模型作为生成描述的核心。解码器从编码器提供的紧凑表示生成连贯的文本描述。尽管解码器已被广泛应用，但编码器仍较为未被充分探索。编码器优化至关重要，因为直接决定提取特征的丰富程度，从而影响生成描述的质量。因此，有必要利用多个卷积神经网络（CNN）结构在转换器框架中进行系统评估，以优化编码器效果，提高描述质量。", "innovation": "本文系统评价了12种不同的卷积神经网络（CNN）架构在基于转换器的遥感图像描述中的表现，分为两个阶段评估：首先通过数值分析确定CNN的性能类别，接着由人类评价者进行主观评估。此外，还研究了贪婪搜索和束搜索等不同搜索策略的影响，以确保生成的最佳描述。研究表明，编码器的选择在改善描述性能中起着关键作用，特定的CNN架构显著提高了遥感图像生成描述的质量。这一研究通过提供多架构的详细比较，为基于转换器的图像描述模型的进步提供了宝贵的见解。", "conclusion": "该研究表明，编码器的选择在改善遥感图像描述性能方面起到了关键作用，特定的CNN架构显著提高了生成描述的质量。通过系统探索和评估，本研究为基于转换器图像描述模型的发展提供了宝贵的参考。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.02545", "html_url": "https://arxiv.org/abs/2504.02545", "title": "MAD: Makeup All-in-One with Cross-Domain Diffusion Model", "title_en": "MAD: Makeup All-in-One with Cross-Domain Diffusion Model", "authors": "Bo-Kai Ruan,Hong-Han Shuai", "background": "现有的化妆技术通常需要设计多个模型来处理不同输入，并在不同领域对特征进行对齐，以完成不同化妆任务，如美容滤镜、化妆迁移和去除化妆，这增加了复杂性。另一个限制是没有基于文本指导的试妆，这更人性化，不需要参考图片。因此，现有的方法通常需要设计多个模型来处理不同的任务，导致复杂度增加，同时也缺乏文本指导的试妆功能，使得系统更加用户友好。", "innovation": "本文首次尝试使用单一模型来执行各种化妆任务。具体来说，本文将不同的化妆任务形式化为跨域翻译，并利用跨域扩散模型完成所有任务。与传统的依赖于单独编码器-解码器配置或循环机制的方法不同，本文提出使用不同的领域嵌入来促进域控制。这种方法只需通过变化嵌入即可实现在单一模型内无缝域切换，从而减少为不同任务依赖额外模块的需求。为了支持精确的文本到化妆应用，作者引入了MT-Text数据集，该数据集在MT数据集基础上扩展了文本注释，进一步推动了化妆技术的实用性。", "conclusion": "本研究提出了一种新的方法，使用跨域扩散模型实现多个化妆任务的一体化处理，提供了文本指导的试妆功能，简化了系统设计，提高了用户体验，并通过MT-Text数据集的数据增强，进一步提高了化妆技术的实用性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05549", "html_url": "https://arxiv.org/abs/2503.05549", "title": "Stereo Any Video: 时空一致的视差匹配", "title_en": "Stereo Any Video: Temporally Consistent Stereo Matching", "authors": "Junpeng Jing,Weixun Luo,Ye Mao,Krystian Mikolajczyk", "background": "该论文介绍了Stereo Any Video这一强大框架，用于视频视差匹配。这一框架能够在没有依赖于摄像头姿态或光学流等辅助信息的情况下，估计出空间上准确且时间上一致的视差。这一能力来自于单目视频深度模型提供的丰富的先验知识，这些先验知识与卷积特征结合，生成稳定的表现形式。为了进一步提高性能，介绍了关键的架构创新：全对全配对相关性，构建平滑且鲁棒的匹配代价体积；以及时域凸上采样，提高时域一致性。这些组件共同确保了鲁棒性、准确性和时间一致性，将视频视差匹配的标准提升到了新的水平。广泛的实验表明，该方法在质和量上均在多个数据集上实现了最先进的性能，并且在面向真实世界室内外场景时表现出强大的泛化能力", "innovation": "1. 利用单目视频深度模型的丰富先验知识与卷积特征结合，生成稳定的表现形式。\n2. 引入全对全配对相关性 (all-to-all-pairs correlation)，构建平滑且鲁棒的匹配代价体积。\n3. 引入时域凸上采样 (temporal convex upsampling)，提高时间一致性", "conclusion": "该研究提出的方法在零样本设置下，在多个数据集上实现了最先进的性能，并且在真实世界的室内和室外场景中表现出强大的泛化能力。这些创新确保了鲁棒性、准确性和时间一致性，将视频视差匹配的标准提升到了新水平。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.00545", "html_url": "https://arxiv.org/abs/2503.00545", "title": "RFWNet: 融合多尺度感受野和前景聚焦机制的轻量级遥感目标检测网络", "title_en": "RFWNet: A Lightweight Remote Sensing Object Detector Integrating Multiscale Receptive Fields and Foreground Focus Mechanism", "authors": "Yujie Lei,Wenjie Sun,Sen Jia,Qingquan Li,Jie Zhang", "background": "遥感图像目标检测（RSOD）面临着高类别相似性、前景背景分布不平衡和遥感图像中小目标的问题，这些因素极大地阻碍了检测精度。此外，模型准确性和计算复杂度之间的权衡也增加了RSOD算法的实际应用难度。", "innovation": "本研究提出了一种轻量级且高效的RSOD算法，结合了多尺度感受野和前景聚焦机制，命名为鲁棒前景加权网络（RFWNet）。该算法采用了轻量级骨干网络感受野自适应选择网络（RFASNet），利用遥感图像丰富的上下文信息提升类别可分性。此外，还开发了一个前景背景分离模块（FBSM），包括背景冗余信息过滤模块（BRIFM）和前景信息增强模块（FIEM），以突出图像中的关键区域并过滤冗余背景信息。最后，设计了一个带权重的CIoU- Wasserstein损失函数（LWCW），该损失函数通过使用归一化Wasserstein距离对基于IoU的损失进行加权，以减轻模型对小目标位置偏差的敏感性。", "conclusion": "实验结果表明，RFWNet在DOTA V1.0和NWPU VHR-10数据集上的平均精度均值（mAP）分别为95.3%和73.2%，参数量仅为6.0 M，推理速度达到52 FPS。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12753", "html_url": "https://arxiv.org/abs/2504.12753", "title": "强更强，稳更稳，优更优：深度VFMs中的几何一致性为域泛化语义分割锻造", "title_en": "Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation", "authors": "Siyu Chen,Ting Han,Changshe Zhang,Xin Luo,Meiliu Wu,Guorong Cai,Jinhe Su", "background": "VFMs在DGSS任务中表现出色，但现有方法往往忽视了视觉线索的易变性，而几何信息的稳定性使其更具鲁棒性。鉴于此，本文研究了将深度信息与VFMs特征结合以提高几何一致性和泛化性能的可能性。", "innovation": "本文提出了一种名为DepthForge的新细调DGSS框架，将冻结的DINOv2或EVA02的视觉线索与冻结的Depth Anything V2的深度线索整合。通过在每一层集成深度感知的可学习令牌，逐步分离不变视觉和空间信息，增强深度意识和注意力。此外，开发了一种深度细化解码器，以自适应地细化多层VFM特征和深度感知可学习令牌。", "conclusion": "实验结果表明，本文方法在多种DGSS设置和五个不同数据集上显著优于其他方法，具有更强的表现力、更稳定的视觉-空间注意和更好的泛化能力。特别是在极端条件下（例如夜间和雪地）表现尤为出色。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.03259", "html_url": "https://arxiv.org/abs/2503.03259", "title": "BANet: Bilateral Aggregation Network for Mobile Stereo Matching", "title_en": "BANet: Bilateral Aggregation Network for Mobile Stereo Matching", "authors": "Gangwei Xu,Jiaxin Liu,Xianqi Wang,Junda Cheng,Yong Deng,Jinliang Zang,Yurui Chen,Xin Yang", "background": "当前最先进的立体匹配方法通常使用昂贵的3D卷积来聚集完整的成本体素，但由于其计算要求，移动部署具有挑战性。直接使用2D卷积进行成本聚合，往往会导致边缘模糊、细节丢失和无纹理区域的不匹配问题。一些复杂的操作，如可变形卷积和迭代扭曲，只能部分缓解这个问题，但是这些方法对移动设备不够友好，限制了其在移动设备上的部署容量。", "innovation": "本文提出了一种新颖的双边聚合网络（BANet）用于移动立体匹配，它仅使用2D卷积产生具有锐利边缘和细腻细节的高质量结果。具体而言，该网络首先通过空间注意图将整个成本体素分离为详细部分和光滑部分，分别进行详细和光滑聚合，最终将两者融合以获得最终的视差图。实验结果表明，我们的BANet-2D在CITI 2015排行榜上显著优于其他移动友好方法，其准确率比MobileStereoNet-2D高35.3%，同时在移动设备上的运行时间更快。", "conclusion": "我们的BANet-2D在提供高质量结果的同时，使用2D卷积方法非常适合移动部署，显著提高了移动立体匹配的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.21843", "html_url": "https://arxiv.org/abs/2503.21843", "title": "CMD-HAR: 跨模态解纠缠以用于可穿戴设备的人体活动识别", "title_en": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition", "authors": "Hanyu Liu,Siyao Li,Ying Yu,Yixuan Jiang,Hang Xiao,Jingxi Long,Haotian Tang,Chao Li", "background": "人类活动识别（HAR）是许多以人为中心的智能应用的基础技术。尽管深度学习方法已被用于加速特征提取，但多模态数据混合、活动异构性和复杂模型部署等问题尚未得到充分解决。本文旨在解决传感基人体活动识别中的多模态数据混合、活动异构性和复杂模型部署问题，提出了一种时空注意力模态分解对齐融合策略来解决传感器数据混合分布的问题。通过跨模态时空解纠缠表示捕捉活动的关键差异特征，并结合梯度调节以缓解数据异构性。此外，构建了一个可穿戴设备部署模拟系统。在许多公开数据集上进行了实验，证明了模型的有效性。", "innovation": "提出了一种跨模态解纠缠策略，通过时空注意力模态分解对齐融合策略解决多模态数据混合问题。该策略能够通过跨模态时空解纠缠表示捕捉活动的关键差异特征，并结合梯度调节以缓解数据异构性。同时，构建了一种可穿戴设备部署模拟系统，验证了模型的有效性。", "conclusion": "通过构建跨模态解纠缠策略，解决了传感基人体活动识别中的多模态数据混合、活动异构性和复杂模型部署问题。模型在多个公开数据集上验证了其有效性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.21817", "html_url": "https://arxiv.org/abs/2503.21817", "title": "Skip-Vision: 通过自适应标记跳过实现视觉语言模型的高效可扩展加速", "title_en": "Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping", "authors": "Weili Zeng,Ziyuan Huang,Kaixiang Ji,Yichao Yan", "background": "基于Transformer的模型在多模态大型语言模型（MLLMs）方面取得了显著进步，但随着分辨率、训练数据和模型参数的扩展，其计算成本急剧上升。瓶颈来自于需要大量视觉标记以实现精细的图像理解。该文探讨了解决训练和推理效率低下的方法，并提出了Skip-Vision统一框架。", "innovation": "该文引入了两种加速策略：一是训练加速，通过跳过冗余视觉标记的Feed-Forward Network（FFN）层计算来减少特征更新，二是推理加速，通过设计选择性KV缓存删除机制，来减少解码时的计算量，同时保持模型性能。实验结果证明该方法可提高35%的训练时间，75%的推理FLOPs，以及45%的延迟，且能实现与现有方法同等或更优的性能。", "conclusion": "Skip-Vision为高性能MLLMs的扩展提供了一个高效解决方案，通过标记跳过的策略，提升了模型的训练和推理效率。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12215", "html_url": "https://arxiv.org/abs/2504.12215", "title": "基于不确定性指导的逐级肿瘤分割与解剖导向后处理", "title_en": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing", "authors": "Ilkin Sevgi Isler,David Mohaisen,Curtis Lisle,Damla Turgut,Ulas Bagci", "background": "在胸部计算机断层扫描(CT)中可靠地进行肿瘤分割仍然具有挑战性，因为边缘模糊、类别不平衡和解剖变异。现有方法难以应对这些复杂因素，导致分割结果不准确或边界校准不良。", "innovation": "提出了一种基于不确定性的逐级分割框架，该框架将全容积肿瘤定位与改进的解剖导向后处理和精细化的感兴趣区(ROI)分割相结合。该框架包括两阶段：第一阶段生成粗略预测，第二阶段通过不确定性感知损失函数进行精细化训练，以改进模糊区域的准确性和边界校准。与现有模型相比，该框架在 Dice 和 Hausdorff 得分上有所提高，减少了假阳性，并增强了空间可解释性。这些结果表明，结合不确定性建模和解剖先验信息可以在级联分割管道中实现稳健且临床有意义的肿瘤勾勒。", "conclusion": "该论文提出的方法通过结合不确定性建模和解剖先验信息，在级联分割管道中实现了肿瘤分割的鲁棒性和临床意义，证明了基于不确定性的逐级肿瘤分割与解剖导向后处理的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07813", "html_url": "https://arxiv.org/abs/2503.07813", "title": "MaizeField3D：来自多样性品系的田间种植玉米的3D点云和参数化模型数据集", "title_en": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel", "authors": "Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian", "background": "由于缺乏大规模和多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具的发展，尤其是对于玉米，受到了限制。而2D图像是无法捕捉到植物结构细节如叶片结构、植物体积和空间排列等，这些细节是3D数据能够提供的。因此，开发了一个专门的3D点云数据集MaizeField3D，用于田间种植的玉米，特别针对多样性的玉米品系族群，以推动农业研究的进步。", "innovation": "MaizeField3D数据集包括使用 terrestrial laser scanner（TLS）收集的1045个高质量田间种植玉米的3D点云数据。数据集中包含了520个植物的3D点云分割和图基分割方法得到的注释，以隔离每个叶片和茎秆，确保所有样本的一致标记。数据集中的分割图像也经过严格的手动质量控制。此外，数据集还包括多分辨率子采样点云数据（100k、50k、10k点），以及详细的植物形态和质量元数据。该数据集通过非均匀理B样条（NURBS）表面参数化植物叶片，并使用结合无导数和导数方法的两步优化过程生成NURBS曲面。这一系列创新方法构建了一个AI驱动的3D表型分析、植物结构分析和农业研究中的3D应用的基础数据集。", "conclusion": "MaizeField3D数据集将作为AI驱动的表型分析、植物结构分析和农业研究中3D应用的基础数据集。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12552", "html_url": "https://arxiv.org/abs/2504.12552", "title": "使用数字孪生进行隐私保护的手术室工作流程分析", "title_en": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins", "authors": "Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath", "background": "手术室是一个复杂的环境，优化工作流程对于降低手术成本和提高患者结果至关重要。自动识别围手术期事件的计算机视觉方法可以识别手术室优化的瓶颈，但由于隐私问题，手术室视频的自动化事件检测使用受限。因此，需要一种既能保持患者隐私又能进行手术室工作流程分析的方法。", "innovation": "本文提出了一种两阶段的隐私保护手术室视频分析和事件检测管道。首先，利用视觉基础模型进行深度估计和语义分割，从常规的RGB视频生成匿名的数字孪生（DT）。其次，使用SafeOR模型，这是一种融合双流方法，处理分割掩码和深度图以进行手术室事件检测。与直接使用未匿名RGB视频的模型相比，DT方法在内部数据集上的表现与其持平或更好，同时实现了隐私保护下的手术室工作流程分析，并且能够促进机构之间的匿名数据共享，减少领域内外观差异对模型通用性的影响。", "conclusion": "本文提出的方法在手术室事件检测中实现了与未匿名视频模型持平甚至更优的性能，利用匿名的数字孪生模型可以保护手术室视频中的隐私，使得医疗机构可以安全地共享匿名数据，从而增强模型的通用性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.06002", "html_url": "https://arxiv.org/abs/2505.06002", "title": "Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition", "title_en": "Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition", "authors": "Congqi Cao,Peiheng Han,Yueran zhang,Yating Yu,Qinyi Lv,Lingtong Min,Yanning zhang", "background": "大规模预训练模型在语言和图像任务中取得了显著的成功，推动越来越多的研究探索预训练图像模型，如CLIP，在少量样本动作识别（FSAR）领域的应用。然而，当前的方法通常存在几个问题：1) 直接微调往往削弱了预训练模型的一般化能力；2) 视觉任务中任务特定信息的探索不足；3) 在文本建模过程中通常忽略了语义顺序信息；4) 存在的跨模态对齐技术忽略了多模态信息的时序耦合。", "innovation": "我们提出了Task-Adapter++，一种参数高效的对于图像和文本编码器的双重适应方法。具体来说，为充分利用不同少量样本学习任务之间的变化，我们为图像编码器设计了任务特定的适应，使得在特征提取过程中最能区分的信息可以得到充分的注意。此外，我们利用大面积语言模型（LLMs）为每个动作类别生成详细的顺序子动作描述，并将语义顺序适应器引入文本编码器，以有效地建模这些子动作之间的顺序关系。最后，我们开发了一种创新的细粒度跨模态对齐策略，可激活地将视觉特征映射到与语义描述相同的时序阶段。", "conclusion": "广泛的实验充分证明了所提出方法的有效性和优越性，该方法在5个基准上取得了最新的性能。代码在https://github.com/your-repo-url上开源。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02453", "html_url": "https://arxiv.org/abs/2506.02453", "title": "PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation", "title_en": "PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation", "authors": "Kunyu Wang,Xueyang Fu,Yuanfei Bao,Chengjie Ge,Chengzhi Cao,Wei Zhai,Zheng-Jun Zha", "background": "当前的方法主要关注于利用目标数据进行模型适应，而忽视了预训练权重的重要信息源。预训练权重中编码了尚未充分利用的跨域不变先验知识。本文从预训练权重的几何属性出发，系统分析了三个关键组件：幅度、绝对角度和成对的角度结构。研究表明，成对的角度结构在不同的受污染领域保持稳定，并编码了跨域不变的语义信息，因此应在此过程中被保留。", "innovation": "提出了一种基于先验的连续推理时适应（CTTA）方法PAID（Pairwise Angular-Invariant Decomposition），该方法将权重分解为幅度和方向，利用豪斯霍尔德反射引入了一个可学习的正交矩阵以全局旋转方向同时保留成对的角度结构。只有幅度和正交矩阵在适应过程中更新。PAID在四个常用CTTA基准上的结果表明，保留成对的角度结构提供了一条简单而有效的CTTA原则。", "conclusion": "PAID在四个常用CTTA基准上的表现优于最近的SOTA方法，证明了保留成对角度结构对于CTTA的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09612", "html_url": "https://arxiv.org/abs/2506.09612", "title": "具有一致性Zigzag采样的故事生成", "title_en": "Consistent Story Generation with Asymmetry Zigzag Sampling", "authors": "Mingxiao Li,Mang Ning,Marie-Francine Moens", "background": "文本到图像生成模型在生成高质量图像方面取得了显著进展，但从文本描述生成图像时，仍然难以保持多个图像之间的主题一致性，这是一项基本要求，对于视觉叙事至关重要。现有方法要么通过在大规模故事可视化数据集上微调模型，但这非常耗资源，要么使用无需训练的技术来在生成间共享信息，但这种方法仍能达到有限的效果。", "innovation": "本文引入了一种无需训练的采样策略，称为不对称提示和视觉共享的Zigzag采样，以增强视觉故事生成中的主题一致性。该方法提出了一种Zigzag采样机制，交替使用不对称提示以保留主题特征，同时利用视觉共享模块在生成的图像间传递视觉线索以进一步增强一致性。根据定量和定性的实验结果，该方法在生成连贯且一致的视觉故事方面显著优于此前的方法。", "conclusion": "实验结果表明，本方法在生成连贯和一致的视觉故事方面显著优于以前的方法。已经在GitHub上提供了代码。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08601", "html_url": "https://arxiv.org/abs/2505.08601", "title": "使用物理驱动深度学习重新组合古代 fragmented 竹简", "title_en": "Rejoining fragmented ancient bamboo slips with physics-driven deep learning", "authors": "Jinchi Zhu,Zhou Zhao,Hailong Lei,Xiaoguang Wang,Jialiang Lu,Jing Li,Qianqian Tang,Jiachen Shen,Gui-Song Xia,Bo Du,Yongchao Xu", "background": "竹简是东亚记载古代文明的关键载体，对重建丝绸之路、研究物质文化交流以及全球历史具有宝贵的历史学价值。然而，很多出土的竹简被分割成数千个不规则的碎片，这使得重新组合变得至关重要且极具挑战性。现有方法主要依赖手动配对样本进行训练，但在样本稀缺的情况下效果不佳，限制了考古学家恢复和研究碎片化文物的效率和准确性。因此，开发一种新的方法来提高碎片化竹简的重新组合效率变得尤为重要。", "innovation": "本文介绍了一种基于物理的深度学习框架WisePanda，用于重新组合碎片化竹简。WisePanda通过物理断裂和材料劣化的原理自动生成合成训练数据，无需手动配对样本即可训练匹配网络，提供按排名建议以简化重新组合过程。与领先的曲线匹配方法相比，WisePanda在一千多个候选碎片中的Top-50匹配准确率从36%提升至52%，并且使用WisePanda的考古学家在恢复碎片化竹简时效率大幅提升（约20倍）。该研究证明了将物理原则融入深度学习模型可以显著提高其性能，为古代文物修复领域的物理驱动机器学习开辟了新途径。", "conclusion": "本文展示了一种结合物理原理的深度学习模型WisePanda，在修复古代碎片化竹简方面取得了显著成效，这不仅提高了重建速度和准确性，还为古文物修复提供了一种新的机器学习方法，有望大幅改善碎片化文物的修复效果和研究速度。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09993", "html_url": "https://arxiv.org/abs/2506.09993", "title": "Diffusion模型中的文本感知图像恢复", "title_en": "Text-Aware Image Restoration with Diffusion Models", "authors": "Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim", "background": "图像恢复旨在恢复退化图像。现有的基于扩散的方法在自然图像恢复方面取得了巨大成功，但在重建退化图像中的文本区域时通常会遇到困难。这些方法经常生成可接受但错误的文本样式的图案，这种现象被称为文本图像幻觉。", "innovation": "提出了Text-Aware Image Restoration (TAIR)，这是一种需要同时恢复视觉内容和文本保真的新型恢复任务。还提出了一种名为TeReDiff的多任务扩散框架，该框架将扩散模型的内部特征集成到文本检测模块中，使两个组件能够从联合训练中获益，从而提取丰富的文本表示，用于后续去噪步骤。", "conclusion": "广泛的实验表明，我们的方法在文本识别准确性方面始终优于最先进的图像恢复方法，实现了显著的提升。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.19136", "html_url": "https://arxiv.org/abs/2504.19136", "title": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification", "title_en": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification", "authors": "Huiling Zheng,Xian Zhong,Bin Liu,Yi Xiao,Bihan Wen,Xiaofeng Li", "background": "利用合成孔径雷达（SAR）和RGB影像进行土地覆盖分类仍然具有挑战性，主要是由于不同模态之间的异质性和互补光谱特性的未充分利用。现有方法往往无法有效地分离共享的结构特征和模态互补的辐射属性，导致特征冲突和信息损失。WHU-OPT-SAR和DDHR-SK数据集上的实验证明了这一问题。", "innovation": "本文提出了一种频率意识框架——Phase-Amplitude Decoupling (PAD)，该框架在傅里叶域中分离相位（跨模态共享）和振幅（模态互补）成分，强化共享结构同时保留互补特性，从而提高融合质量。PAD 特别引入了显式的振幅-相位解耦，不同于之前的忽略频率谱编码的物理特性的方法。PAD 包含两个关键组件：相位频谱矫正 (PSC) 和振幅频谱融合 (ASF)。PSC 通过卷积引导的缩放对跨模态相位特征进行对齐，提高几何一致性；ASF 则使用频率自适应的多层感知机动态整合高频和低频模式，充分利用SAR的形态敏感性和RGB丰富的光谱特性。", "conclusion": "本文通过WHU-OPT-SAR和DDHR-SK数据集的综合实验，展示了PAD方法在多模态土地覆盖分类中的优越性能，并建立了物理感知多模态融合的新范式。本文的代码将在此链接 https://example.com/ 获得。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23115", "html_url": "https://arxiv.org/abs/2505.23115", "title": "基于扩散模型的3D空间占用率预测在自动驾驶中的应用", "title_en": "Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving", "authors": "Yunshen Wang,Yicheng Liu,Tianyuan Yuan,Yingshi Liang,Xiuyu Yang,Honggang Zhang,Hang Zhao", "background": "准确预测来自视觉输入的3D空间占用率网格对于自动驾驶至关重要，但现有的判别方法难以处理嘈杂的数据、不完整的观测以及3D场景中的复杂结构。现有的方法因为上述问题，导致在复杂场景下的预测不够一致、鲁棒性差，且难以捕捉3D空间结构的细节。因此，需要一种新的方法来解决这些问题，以提高自动驾驶系统的预测能力和实际应用中的表现。", "innovation": "本文重新将3D占用率预测问题定义为一种生成建模任务，利用扩散模型来学习数据的内在分布，并融合3D场景的先验知识。这种方法提高了预测的一致性，增加了对噪声的鲁棒性，更好地处理了3D空间结构的复杂性。实验结果表明，基于扩散模型的生成模型相比现有的最先进的判别方法，在拥挤或能见度较低的区域，提供更真实和准确的占用率预测，并且改善的预测结果显著提高了下游规划任务的表现，突显了该方法在实际自动驾驶应用中的实际优势。", "conclusion": "通过将3D占用率预测问题重新定义为生成建模任务，利用扩散模型，本文提出的方法显著提高了预测的准确性和鲁棒性，特别在复杂和低能见度场景下的性能有了明显提升。通过实际的实验验证，本文的方法在自动驾驶场景中具有重要的实际应用价值。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22015", "html_url": "https://arxiv.org/abs/2506.22015", "title": "通过指数扭矩剪枝实现通用高效的模型压缩", "title_en": "Towards Universal & Efficient Model Compression via Exponential Torque Pruning", "authors": "Sarthak Ketanbhai Modi,Zi Pong Lim,Shourya Kuchhal,Yushi Cao,Yupeng Cheng,Yon Shin Teo,Shang-Wei Lin,Zhiming Li", "background": "现代深度神经网络（DNNs）的复杂性和规模迅速增长，导致计算成本和内存使用增加，推动了对高效模型压缩技术的兴趣。之前的先进方法提出了一种受扭矩启发的正则化技术，强迫神经模块围绕选定的锚点。然而，这种方法的剪枝效果并不理想，剪枝后的网络仍然密集，并且准确率下降较大。", "innovation": "本文提出了全新的Exponential Torque Pruning（ETP）方法，采用指数力应用方案作为正则化手段。ETP有效剪枝冗余和远处的模块，同时保留近且对有效推理必不可少的模块。实验表明，ETP在多个领域实现了显著更高的压缩率，且几乎没有准确率下降。", "conclusion": "ETP方法虽然极其简单，依然能够显著提高模型压缩率，并且保持模型的高准确率，展示了其在模型压缩领域的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.15854", "html_url": "https://arxiv.org/abs/2506.15854", "title": "通过视觉转文本转换在联网和自动驾驶车辆中保护隐私", "title_en": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation", "authors": "Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy", "background": "联网和自动驾驶车辆依赖于一系列设备，这些设备经常处理敏感的个人数据。路侧单元在这些设备中尤为关键，尤其是在使用配备人工智能（AI）摄像头的应用程序，例如检测违规行为时。然而，被捕捉到的图像很可能会被滥用，例如用于身份盗窃、个人画像或未经授权的商业目的，而传统的技术如面部模糊和遮盖仍然存在风险，因为个体仍可以通过他们的服装被追踪。", "innovation": "本文提出了一种新颖的保护隐私的框架，该框架结合了基于反馈的强化学习（RL）和视觉语言模型（VLM），通过将视觉信息转化为语义等效的文本描述，既保留了场景相关的信息，又保护了视觉隐私。使用层次化的强化学习策略逐步细化生成的文本，从而提高语义准确性和隐私保护程度。", "conclusion": "该研究通过实验证明了这种新方法在隐私保护和文本质量方面的显著改进，独特词数量增加了约77%，细节密度则增加了约50%。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23852", "html_url": "https://arxiv.org/abs/2506.23852", "title": "RGC-VQA：一种用于机器人生成视频质量评估的探索数据库", "title_en": "RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment", "authors": "Jianing Jin,Jiangyong Ying,Huiyu Duan,Liu Yang,Sijing Wu,Yunhao Li,Yushuo Zheng,Xiongkuo Min,Guangtao Zhai", "background": "随着摄像设备集成到机器人平台的应用日益普遍，机器人生成的视频开始出现在流媒体平台上，推动了人类和机器人共存的未来愿景。这些视频从机器人主观视角生成，对其感知质量在人类与机器人交互中至关重要。然而，目前尚缺乏专门针对机器人生成内容（RGC）视频质量评估的研究。因此，建立一个专门的数据库来支持更广泛的机器人应用变得至关重要。", "innovation": "本文创新性地提出了RGC（Robotic-Generated Content）的概念，定义为机器人主观视角生成的视频，并建立了第一个RGC数据库，包含总计2,100个视频，来自三种不同的机器人类别，并广泛收集自不同时期和不同平台的视频。通过后续的主观VQA实验评估了人类对机器人生成视频的视觉感知能力，并对11个最先进的VQA模型在数据库中的表现进行了基准测试。研究成果揭示了现有VQA模型在应用于复杂机器人生成内容时存在的显著局限性，强调了需要专门针对RGC的VQA模型的必要性。", "conclusion": "通过RGC-VQA数据库，对机器人生成视频的质量进行了初步评估，揭示了现有模型在处理这类复杂内容时的局限性，为未来开发更适合RGC视觉质量评估的模型提供了基础。数据库已经公开发布。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "语义结构感知的生成性攻击以提高对抗迁移性", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "生成对抗攻击通过在白盒替代模型上训练扰动生成器，然后将精心制作的扰动应用于未见过的黑盒受害者模型。相比于迭代攻击，这些方法在推理时间和可扩展性以及迁移性方面表现更优。然而，现有研究还没有充分利用生成模型的表征能力来保留和利用语义信息。具体来说，生成器的中间激活编码了丰富的语义特征（如对象边界和粗略形状），这些特征目前尚被低估，从而限制了与对象显著区域的对齐，这对于对抗迁移性至关重要。", "innovation": "该研究提出了一种基于Mean Teacher的语义结构感知攻击框架，作为时间平滑特征参考。通过使用这个平滑的参考，研究进一步引导学生在早期层中的激活与语义丰富的教师在特征提取方面的一致性，从而进行特征蒸馏。基于经验发现，该方法将扰动合成锚定在生成器中语义上显著的早期中间块，逐步引导对抗扰动以显著增强对抗迁移性。实验结果表明，在多样化的模型、领域和任务中，该方法相对于最先进的生成性攻击实现了持续改进，并使用常规指标和新提出的错误纠正率（ACR）进行了全面评估。", "conclusion": "该研究提出的语义结构感知攻击框架，通过锚定生成器中的语义上显著的早期中间块，引导渐进式的对抗扰动，从而显著提高对抗迁移性。实验结果证实了该方法的有效性和优越性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00981", "html_url": "https://arxiv.org/abs/2507.00981", "title": "使用程序化场景扰动评估单目深度估计的鲁棒性", "title_en": "Evaluating Robustness of Monocular Depth Estimation with Procedural Scene Perturbations", "authors": "Jack Nugent,Siyang Wu,Zeyu Ma,Beining Han,Meenal Parakh,Abhishek Joshi,Lingjie Mei,Alexander Raistrick,Xinyuan Li,Jia Deng", "background": "近年来，单目深度估计取得了显著进展，大型模型在标准基准上的表现尤为突出。然而，标准基准上的性能评估并不全面，因为大部分评估侧重于准确率而忽视了鲁棒性。现有的评估方法多侧重于测试模型在精准环境下的表现，因此缺乏对模型在不同条件下鲁棒性的全面评估。", "innovation": "本文提出了一种新的基准测试PDE（Procedural Depth Evaluation），通过程序化生成三维场景来测试模型对多种控制扰动（如物体、相机、材料和光照变化）的鲁棒性。这种方法能够系统地评估模型在变动条件下的表现，有利于识别当前最先进深度模型面临的挑战，为后续研究提供参考。", "conclusion": "本文通过PDE基准测试，揭示了不同扰动对最先进深度模型的挑战，并希望这些发现能促进后续研究。相关代码和数据可在以下链接获取：this https URL。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22800", "html_url": "https://arxiv.org/abs/2506.22800", "title": "RGE-GS: 基于奖励导向扩增驾驶场景重建方法", "title_en": "RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors", "authors": "Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang", "background": "现有的单次驾驶视频剪辑通常会导致道路结构的不完整扫描，这要求重建场景扩展成为传感器模拟器有效回归驾驶动作的关键需求。尽管当前的3D高斯点云（3DGS）技术在重建质量方面取得了显著进展，但直接通过引入扩散先验进行扩展则往往会产生累积的物理矛盾，并且降低了训练效率。因此，需要一种新的方法来解决这些限制问题", "innovation": "RGE-GS是一种新的扩展重建框架，它通过奖励导向的扩散生成和高斯积分相结合来实现。主要创新点是提出了一个奖励网络，可以在重建阶段前识别并优先处理一致生成的模式，从而实现对扩散输出的选择性保留，以维持空间稳定性。其次，在重建过程中，提出了差异化训练策略，根据场景收敛指标自动调整高斯优化进度，达到更好的收敛效果，优于基准方法", "conclusion": "在公开数据集的广泛评估中，RGE-GS在重建质量方面达到了最先进的性能。我们的源代码将公开发布。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23897", "html_url": "https://arxiv.org/abs/2506.23897", "title": "PriOr-Flow: 增强原始全景光流的正交视图", "title_en": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View", "authors": "Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang", "background": "全景光流能够全面理解宽视场中的时间动态。然而，基于球面到平面投影（如等角正方形投影）引起的严重失真显著降低了传统基于视角的光流方法的性能，尤其是在极地区域。", "innovation": "提出了一种新颖的双分支框架PriOr-Flow，利用正交视图的低失真特性，在极地区域增强光流估计。具体地，引入了双成本合作查找（DCCL）算子，联合从原始和正交成本体中检索相关性信息，在成本体构建过程中有效减弱失真噪声。此外，提出了正交驱动的失真补偿（ODDC）模块，迭代细化来自两个分支的运动特征，进一步抑制极地失真。", "conclusion": "广泛的实验表明，PriOr-Flow 与各种基于视角的迭代光流方法兼容，并在公开可用的全景光流数据集上实现了一致的最先进性能，为宽视角运动估计设定了新标准。代码已在this https URL 公开可用。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00373", "html_url": "https://arxiv.org/abs/2507.00373", "title": "可定制的基于感兴趣区域的深度图像压缩", "title_en": "Customizable ROI-Based Deep Image Compression", "authors": "Jian Jin,Fanxin Xia,Feng Ding,Xinfeng Zhang,Meiqin Liu,Yao Zhao,Weisi Lin,Lili Meng", "background": "现有的基于感兴趣区域（ROI）的图像压缩方案通过预定义ROI来优化比特分配，但用户（包括人类客户和下游机器任务）的需求越来越多样化，这意味着ROI压缩需要更加定制化，以支持不同的偏好。现有的方案通常缺乏有效的机制来平衡ROI和非ROI之间的重建质量。因此，本研究旨在提出一个可定制的基于ROI的深度图像压缩范式。", "innovation": "首先，开发了一个文本控制的掩码获取（TMA）模块，允许用户通过输入相应的语义文本来轻松定制其压缩的ROI，使其编码器受文本控制。其次，设计了一个可定制的值分配（CVA）机制，用户可以根据自己的需求决定非ROI掩码的变化程度，而不是使用固定的掩码来管理ROI和非ROI之间的重建质量贸易。最后，提出了一个潜空间掩码注意（LMA）模块，该模块从潜空间中提取并融合了掩码的空间先验和图像的率失真优化（RDO）先验，进一步优化原始图像的潜表示。实验证明，该可定制的基于ROI的深度图像压缩范式有效解决了ROI定义和掩码获取的定制需求以及ROI和非ROI之间的重建质量贸易管理问题。", "conclusion": "本工作成功地提出了一个能够响应不同用户需求的可定制的基于ROI的深度图像压缩方案，该方案能够在保持ROI高质量重建的同时调整非ROI的重建质量和压缩性能，从而更好地满足多样化的需求。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X: 统一空中与地面车辆到万物的协作", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Fengze Yang,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "多车辆协作驾驶显现出单车辆自主驾驶的优势，但传统的基础设施基于的V2X系统仍然受到部署成本高昂和在农村和郊区出现未覆盖危险区域的限制。现有V2X系统依赖固定路侧单元，但存在部署成本高、覆盖区域有限等问题。本文提出利用无人机(UAV)的AirV2X-Perception数据集作为一种灵活的替代或补充，以应对传统基础设施的局限性。无人机提供独特的优势，包括补充的鸟瞰视角，减少遮挡，弹性的位置能力以及低部署成本，与固定基础设施相比具有显著的优势。这种数据集包括不同环境下驾驶场景，涵盖了城市、郊区和农村场景，不同天气和照明条件，旨在推动空中辅助自动驾驶系统的算法开发和标准化评估，以填补相关领域的关键空白部分。", "innovation": "AirV2X-Perception数据集利用灵活的无人机解决方案，提供动态视角和鸟瞰视角，降低部署成本，解决现有V2X系统中存在的部署成本高和未覆盖区域的问题。数据集覆盖多种环境和条件，利于评估和开发V2D算法。该数据集在推进空中辅助的自动驾驶系统研究上有重要创新价值。", "conclusion": "AirV2X-Perception数据集的建立和开源为V2D领域的发展提供了重要的支持，填补了该领域的关键空白。其独特的优势和广泛的覆盖范围，使得无人机在自动驾驶系统中的应用更加可行和高效。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00505", "html_url": "https://arxiv.org/abs/2507.00505", "title": "LLaVA-SP: 通过视觉空间令牌增强视觉表示的MLLM", "title_en": "LLaVA-SP: Enhancing Visual Representation with Visual Spatial Tokens for MLLMs", "authors": "Haoran Lou,Chunxiao Fan,Ziyan Liu,Yuexin Wu,Xinliang Wang", "background": "当前的多模态大语言模型（MLLM）架构通常通过CLIP-ViT视觉编码器连接到一个大规模语言模型。虽然CLIP-ViT对全局图像特征的捕捉表现出色，但在处理相邻图像块之间的局部关系时表现不佳，导致视觉表示较弱，进而影响MLLMs对详细理解能力。这项工作旨在解决这个问题，通过在原始视觉令牌上仅添加六个空间视觉令牌来增强视觉表示。", "innovation": "提出的LLaVA-SP具有三个关键优势：1) 提出了一种新颖的投影器，使用卷积核从ViT图像块特征中推导出视觉空间令牌，模拟了两种视觉空间排序方法：“从中心区域到全球”和“从抽象到具体”。然后，应用跨注意力机制融合细节视觉信息，丰富总体视觉表示；2) 阐述了两种模型变体：LLaVA-SP-Cropping基于逐级裁剪关注细节特征；LLaVA-SP-Pooling通过自适应池化捕捉全局语义，使模型能够处理多样化的视觉理解任务；3) 通过大量实验显示，轻量化适配LLaVA-SP在各种多模态基准测试中取得了显著性能提升，在多项任务的推理延迟几乎保持不变的情况下，超过了最先进的LLaVA-1.5模型。", "conclusion": "LLaVA-SP在各种多模态基准测试中显著提高了性能，尤其是在多个任务中的推理延迟几乎保持不变情况下，优于最先进的LLaVA-1.5模型，模型和代码均已公开。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23918", "html_url": "https://arxiv.org/abs/2506.23918", "title": "图像思维在多模态推理中的基础、方法和未来前沿", "title_en": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers", "authors": "Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R. Fung", "background": "近年来，多模态推理取得了显著进展，这主要归功于基于语言的Chain-of-Thought（CoT）推理范式。然而，这一以语言为中心的方法将视觉视为静态的初始上下文，导致了丰富感知数据与离散符号思维之间的根本“语义鸿沟”。人类认知不仅依赖语言，还利用视觉进行动态的心理素描。在人工智能领域，正经历着从使用图像进行思考到能够真正用图像进行思考的根本范式转变。这一转变通过利用视觉信息作为思维过程中的中间步骤，使图像从被动输入转变为动态的可操作认知工作空间。", "innovation": "提出了一种基于图像思维的多模态推理范式，强调思维过程中的视觉信息利用，将视觉信息从静态输入转变为动态、可操作的认知工作空间。该研究提出了三个关键阶段：从外部工具探索、通过程序化操作到内在想象。在此基础上，研究提供了该领域演化的结构化概述，包括三个关键贡献：确立图像思维范式的基础原则及其三个阶段框架、全面综述每个阶段的核心方法、分析关键的评估基准和变革性应用以及识别重大挑战和建议未来方向。", "conclusion": "通过提供这种结构化的概述，旨在为未来更具强大且与人类对齐的多模态AI的研究提供清晰的路线图。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01737", "html_url": "https://arxiv.org/abs/2507.01737", "title": "HOI-Dyn: 学习人类物体交互动力学", "title_en": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion", "authors": "Lin Wu,Zhixiang Chen,Jianglin Lan", "background": "生成真实的3D人类-物体交互(HOIs)仍是一个具有挑战性的任务，原因是难以建模详细的交互动态。现有方法将人类和物体的动作分别处理，导致了物理上不合理且因果不一致的行为。", "innovation": "本文提出了一种名为HOI-Dyn的新颖框架，将HOI生成视为驱动-响应系统，其中人类动作驱动物体响应。其核心是一个基于轻量级变压器的动力学模型，可以显式预测物体应如何对人类动作作出反应。为进一步确保一致性，引入了基于残差的动力学损失来减轻动力学预测错误的影响，并防止误导优化信号。动力学模型仅在训练过程中使用，以保持推理效率。", "conclusion": "通过广泛的定性和定量实验，本文证明了我们的方法不仅提高了HOI生成的质量，还建立了评估生成交互质量的可行指标。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01439", "html_url": "https://arxiv.org/abs/2507.01439", "title": "TurboReg: TurboClique for Robust and Efficient Point Cloud Registration", "title_en": "TurboReg: TurboClique for Robust and Efficient Point Cloud Registration", "authors": "Shaocheng Yan,Pengcheng Shi,Zhenjun Zhao,Kaixin Wang,Kuang Cao,Ji Wu,Jiayuan Li", "background": "在基于对应关系的点云配准（PCR）中，鲁棒估算至关重要。现有方法通过在兼容图中搜索最大团实现较高的召回率，但这些方法受到指数时间复杂度的限制，从而限制了它们在时间敏感应用中的使用。", "innovation": "该研究提出了一种快速且鲁棒的估计器TurboReg，基于一种新颖的轻量级团TurboClique和一个高度并行化的枢轴引导搜索（PGS）算法。TurboClique在高度约束的兼容图中定义为3-团，具有高效的并行搜索特性，并且约束的兼容图保证了稳定变换估计的稳健空间一致性。此外，PGS选择高SC$^2$分数的匹配对作为枢轴，有效引导搜索指向更高内险率的TurboCliques。PGS算法具有线性时间复杂性，显著优于具有指数时间复杂性的最大团搜索。", "conclusion": "广泛的实验表明，TurboReg在多个真实世界数据集上达到了最先进的性能，具有显著的速度提升。例如，在3DMatch+FCGF数据集上，TurboReg（1K）比3DMAC快208.22倍，同时也实现了更高的召回率。我们的代码可在\texttt{TurboReg}访问。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.08777", "html_url": "https://arxiv.org/abs/2411.08777", "title": "LUDO: 使用点云占用函数快速理解变形对象", "title_en": "LUDO: Low-Latency Understanding of Deformable Objects using Point Cloud Occupancy Functions", "authors": "Pit Henrich,Franziska Mathis-Ullrich,Paul Maria Scheikl", "background": "在需要精确目标的医疗任务中，如机器人活检，准确地确定可变形物体的形状及其内部结构的位置至关重要。现有技术通常无法在低延迟下实现此类准确理解，特别是对于变形物体而言，这被认为是技术上的挑战。", "innovation": "LUDO 方法通过占用网络可以从单一视角的点云观察中在不到 30 毫秒内重建变形物体及其内部结构。它提供了预测的不确定性估计，并通过突出输入观察中的关键特征来提供解释性。LUDO 在真实世界的机器人实验中达到了 98.9% 的成功率，显示出它在 ROI 定位准确性、训练时间和内存要求方面优于基准方法。此外，LUDO 不需要变形配准方法即可与变形物体交互，展示了其潜在应用价值。", "conclusion": "LUDO 在理解和跟踪变形物体方面表现出色，特别是在实时性和准确性方面。该方法对于手术等关键安全应用具有重要意义，并且展示了不需要变形配准的新交互方式的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.03977", "html_url": "https://arxiv.org/abs/2409.03977", "title": "Bi-directional discrete过程匹配方法在双模态医学图像合成中的应用", "title_en": "Bi-modality medical images synthesis by a bi-directional discrete process matching method", "authors": "Zhe Xiong,Qiaoqiao Ding,Xiaoqun Zhang", "background": "医学影像合成随着生成模型的快速发展越来越受欢迎。医学影像合成旨在从其他已观察到的数据模态生成未获取的影像模态。合成的影像可以用于临床辅助诊断、模型训练和验证数据增广以及影像质量改进。流型模型是成功的生成模型之一，因其能够生成逼真且高质量的合成影像。然而，大多数流型模型在合成过程中需计算普通微分方程（ODE）演化步骤，导致由于大量时间迭代计算的性能受到限制，受到计算时间的显著影响。", "innovation": "本文提出了一种新的流型模型——双向离散过程匹配（Bi-DPM），以完成双模态影像合成任务。与其它基于流程匹配的模型不同，该模型利用正向和反向的ODE流，并在几个离散时间步骤中增强中间影像的一致性，在配对数据的指导下，使生成过程保持高质量。实验结果表明，Bi-DPM与现有的最佳流型方法相比，在双模态影像合成中具有更高的图像质量和更为准确的解剖区域.", "conclusion": "Bi-DPM在三个MRI T1/T2和CT/MRI数据集上的实验表明，它在双模态影像合成中优于其他最先进的流型方法，提供了更高质量的图像和准确的解剖区域。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00585", "html_url": "https://arxiv.org/abs/2507.00585", "title": "相似性记忆先验对于医学影像分割至关重要", "title_en": "Similarity Memory Prior is All You Need for Medical Image Segmentation", "authors": "Tang Hao,Guo ZhiQing,Wang LieJun,Liu Chao", "background": "近年来，研究者们发现，猕猴初级视觉皮层(V1)中的“祖母细胞”能够直接识别具有复杂形状的视觉输入。这激发了研究者们探索这些细胞在促进医学影像分割研究中的价值。同时，医学影像分割中细分特征难以精确识别，现有方法尚无法有效地提取这些特征。", "innovation": "该论文设计了相似性记忆先验网络（Sim-MPNet），提出了一种动态记忆权重损失注意力机制（DMW-LA），该机制能够在原型记忆库中匹配并记住医学影像中特定病灶或器官的类别特征，并通过权重损失动态更新策略（W-LD）来动态更新相似性记忆先验，从而辅助网络直接提取类别特征。此外，还提出了双相似性全局内部增强模块（DS-GIM），通过余弦相似性和欧几里得距离深入探索输入数据特征分布的内部差异。实验结果显示Sim-MPNet在四个公开数据集上的分割性能优于其他最先进的方法。", "conclusion": "Sim-MPNet在医学影像分割任务中具有较好的性能，提出了基于相似性记忆先验的设计，成功提升了分割任务中的特征提取效果。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.16765", "html_url": "https://arxiv.org/abs/2411.16765", "title": "SHuBERT：通过多流聚类预测进行自监督手语表示学习", "title_en": "SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction", "authors": "Shester Gueuwou,Xiaodan Du,Greg Shakhnarovich,Karen Livescu,Alexander H. Liu", "background": "手语处理传统上依赖于特定任务的模型，限制了跨任务的迁移学习潜力。现有的手语预训练方法往往集中于监督预训练，无法利用无标注数据，或者独立于上下文（帧或视频片段）的表示，忽视了手语中时间关系的影响。", "innovation": "提出了SHuBERT（手语隐单元BERT），这是一种通过大约1000小时的美国手语视频自监督上下文表示模型。SHuBERT将遮罩标记预测目标适应多流视觉手语输入，学习预测多个对应于手、面部和身体姿势流的目标。SHuBERT实现了多种任务（包含手语翻译、孤立手语识别和字母表检测）的性能最佳效果。", "conclusion": "SHuBERT通过多流聚类预测实现了手语的自监督表示学习，并在多个任务上达到了最佳性能，代表了手语处理领域的一个重要进步。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.00420", "html_url": "https://arxiv.org/abs/2412.00420", "title": "TAROT: 基于最优传输的靶向数据选择", "title_en": "TAROT: Targeted Data Selection via Optimal Transport", "authors": "Lan Feng,Fan Nie,Yuejiang Liu,Alexandre Alahi", "background": "现有的靶向数据选择方法主要依赖于基于影响的贪婪启发式方法，这些方法在单模态数据上非常有效。然而，当目标数据复杂度增加时，这些方法难以应对多模态分布。这些问题主要归因于高维影响估算中的主导特征成分影响和贪婪选择策略中的线性加性假设限制。", "innovation": "TAROT框架引入了去相关特征距离来减轻主导特征偏见，提供了更可靠的特征影响度量。通过使用去相关特征距离来量化并最小化所选数据与目标域之间的最优传输距离，TAROT能够更有效地进行数据选择，并且可以估计最佳的选择比例。", "conclusion": "TAROT在语义分割、运动预测和指令调整等多个深学习任务中均优于最先进的方法，展示了其在不同任务中的普适性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05802", "html_url": "https://arxiv.org/abs/2503.05802", "title": "使用Wasserstein距离方法进行光照和光方向估计", "title_en": "Illuminant and light direction estimation using Wasserstein distance method", "authors": "Selcuk Yazar", "background": "在图像处理领域，尤其是对于需要在不同光照条件下进行鲁棒环境感知的机器人技术，光照估计依然是一个关键挑战。传统方法，如RGB直方图和GIST描述子，在复杂光照条件下往往表现不佳，因为这些方法对光照变化高度敏感。", "innovation": "提出了一个创新的方法，利用最优传输理论中的Wasserstein距离来估计图像中的光照和光的方向。该方法在多种室内场景、黑白照片和夜间图像上的实验表明，在复杂光照环境下能够有效检测主要光源并估计其方向，且在性能上比传统统计方法更优越。该方法在光源定位、图像质量评估和目标检测增强方面具有广阔的应用前景。未来的研究可能会探索自适应阈值设置和结合梯度分析来进一步提升准确性，提供一种可扩展的解决方案来应对机器人等相关领域的光照挑战.", "conclusion": "该方法展示了在检测主要光源及其方向和处理复杂光照环境下的潜力，为光源定位、图像质量评估和目标检测增强等领域提供了新的途径，未来研究将致力于进一步提升方法的准确性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.04318", "html_url": "https://arxiv.org/abs/2408.04318", "title": "Deep Transfer Learning for Kidney Cancer Diagnosis", "title_en": "Deep Transfer Learning for Kidney Cancer Diagnosis", "authors": "Yassine Habchi,Hamza Kheddar,Yassine Himeur,Mohamed Chahine Ghanem,Abdelkrim Boukabou,Shadi Atalla,Wathiq Mansoor,Hussain Al-Ahmad", "background": "不可治愈的疾病继续给全球卫生系统带来重大挑战，其发病率受生活方式、经济、社会和遗传因素的影响。肾疾病是其中的关键全球健康问题，需要持续的研究以改善早期诊断和治疗。近年来，深度学习（DL）在医学成像和诊断方面展现出了潜力，特别是在自动肾癌（KC）检测方面取得了显著进展。然而，DL模型的成功高度依赖高质量、特定领域的数据集，这些数据集往往有限且昂贵。此外，DL模型需要大量计算资源和存储，限制了其在临床环境中的应用。为克服这些障碍，迁移学习（TL）作为一种有效的方法出现，使得可以利用相关领域预训练模型来增强KC诊断。", "innovation": "该论文进行了深度迁移学习在肾癌检测中应用的全面综述，系统地回顾了关键方法、其优势和局限性，以及其实用表现。此外，讨论了在医学影像中应用TL面临的挑战，并指出了新兴趋势及其对未来研究的影响。该综述突显了迁移学习在精准医学中的变革性作用，特别是癌症领域，通过提高诊断准确性、降低计算需求和促进AI工具在医疗保健中的应用。", "conclusion": "该综述展示了迁移学习在提高KC诊断准确性、降低计算需求和支持AI工具在医疗保健中的集成方面的潜力。提出的研究见解为科研人员和从业者提供了有价值的指导，为未来KC诊断和个性化治疗策略的发展铺平了道路。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.07079", "html_url": "https://arxiv.org/abs/2408.07079", "title": "Anatomical Foundation Models for Brain MRIs", "title_en": "Anatomical Foundation Models for Brain MRIs", "authors": "Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto", "background": "神经影像学在检测神经疾病和神经退行性疾病方面越来越重要。脑龄是神经影像学中最主要的生物标志物之一，已被证明是不同状况的良好指标，例如阿尔茨海默病。在不同状况的数据稀缺性问题上，使用脑龄进行弱监督预训练的深度学习模型在迁移学习设置中显示出有希望的结果。脑MRI的解剖信息（如皮层厚度）可以提供有关学习良好表示的重要信息，这些表示可以转移到许多下游任务中。迄今为止的大多数工作主要集中在利用脑龄作为预训练策略，而较少关注解剖信息对于构建预训练模型的实际贡献。", "innovation": "本文提出了AnatCL，一种基于解剖信息的脑MRI预训练模型，i.在弱对比学习方法中利用了解剖信息；ii.在多种下游任务上实现了最先进的性能。在12种不同的诊断任务中验证了该方法的有效性，包括阿尔茨海默病、自闭症谱系障碍和精神分裂症等诊断，以及使用结构MRI数据预测10种不同临床评估评分。研究表明，在预训练过程中整合解剖信息可以产生更稳健和泛化的表示。", "conclusion": "我们的研究结果表明，在预训练过程中整合解剖信息可以提高预训练模型的性能和鲁棒性。AnatCL在多种不同的下游任务上实现了最先进的性能，证明了利用解剖信息在深度学习模型预训练中的重要性。预训练模型可以在此处找到：this https URL"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01909", "html_url": "https://arxiv.org/abs/2507.01909", "title": "无模态依赖的患者特异性动态模拟双胞胎模型", "title_en": "Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion", "authors": "Jorge Tapias Gomez,Nishant Nadkarni,Lando S. Bosma,Jue Jiang,Ergys D. Subashi,William P. Segars,James M. Balter,Mert R Sabuncu,Neelam Tyagi,Harini Veeraraghavan", "background": "针对临床应用中变形图像配准（DIR）方法需要精确的空间准确性指标的需求，但对于高度移动的消化道（GI）器官（如胃），手动标识解剖标志点较为困难。此背景下，研究者创建了患者特异性数字孪生（DT）模型，以实时评估DIR方法的准确性。这些模型通过基于已发布的消化道运动模型，生成了21个模拟消化道运动的4D序列，涵盖了11个不同来源的图像数据集，以评估不同DIR方法的性能。", "innovation": "研究提出了一种无模态依赖的患者特异性动态模拟双胞胎模型。该模型通过半自动流水线生成了21个模拟消化道运动的4D序列，对比了多种不同的DIR方法，评估其准确性，并应用于MR引导放射治疗后的剂量分布，以检查不同的空间和剂量准确性。此项研究的创新在于生成的数字孪生模型能够模拟消化道真实运动生成的详细定量DIR性能指标和严格的剂量映射准确性验证能力。", "conclusion": "所提出的流水线生成了模拟真实消化道运动的数字孪生模型，其平均和最大运动幅度、平均对数雅可比行列式均在0.8mm、0.01以内，与已发表的真实患者胃运动数据相似。该研究能够系统提取详细的定量DIR性能指标，实现剂量映射精度的严格验证，从而对动态的、解剖结构复杂的区域进行严谨的DIR工具测试，提供高空间和剂量准确性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.01391", "html_url": "https://arxiv.org/abs/2502.01391", "title": "从生成模型学习实时观测中的交通异常", "title_en": "Learning Traffic Anomalies from Generative Models on Real-Time Observations", "authors": "Fotis I. Giasemis,Alexandros Sopasakis", "background": "准确检测交通异常对于有效的城市交通管理和缓解交通拥堵至关重要。本文通过结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，在斯德哥尔摩42个交通摄像头的实时观测数据中捕捉复杂的空间和时间依赖性，以监控交通数据。", "innovation": "提出了一种结合图神经网络和长短期记忆网络的时空生成对抗网络（STGAN）框架，用于现实世界中大规模实时交通摄像头数据的分析。同时，该方法在斯德哥尔摩数月的实时数据上进行了实践验证，并有效检测出了多种类型的交通异常事件，包括摄像头信号中断、视觉艺术干扰和极端天气对交通流的影响。", "conclusion": "本文结果表明，STGAN模型在实时交通观测中有效检测出交通异常，具有高精度和低误报率。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.12073", "html_url": "https://arxiv.org/abs/2501.12073", "title": "使用轻量化架空机器人无人机进行自主光谱测图的森林资源调查", "title_en": "Towards autonomous photogrammetric forest inventory using a lightweight under-canopy robotic drone", "authors": "Väinö Karjalainen,Niko Koivumäki,Teemu Hakala,Jesse Muhojoki,Eric Hyyppä,Anand George,Juha Suomalainen,Eija Honkavaara", "background": "无人机在林业中的应用越来越广泛，常用于获取高分辨率遥感数据，提升监测、评估和决策过程。虽然在森林冠层上方的操作已经高度自动化，但在森林内部飞行仍具有挑战性，主要依赖人工操控。在密集森林中，使用全球导航卫星系统（GNSS）进行定位不可行，无人机必须自主调整飞行路线以避免碰撞。近年来，机器人技术的进步使得无人机能够自主飞行，以应对无GNSS信号且障碍物丰富的区域。本篇文章通过构建一种利用先进开源方法的架空机器人无人机原型，朝着自主森林数据采集迈出了一步，并验证其在森林内部数据采集中的性能。这项研究特别关注基于摄像头的森林冠层下自主飞行以及从无人机低成本机载立体相机收集的数据的光谱后处理。", "innovation": "该论文展示了如何利用先进开源方法构建架空机器人无人机原型，实现自主森林数据采集。该无人机原型能够处理森林内部的导航挑战，无需依赖GNSS。通过多架次的实验飞行，评估了无人机原型的自主飞行能力，并研究了树木参数估计能力，特别是胸径的估算。这套系统在复杂森林环境中的表现良好，尤其是在小型化立体光谱测图系统的3D建模方面表现出色。", "conclusion": "研究结果为自主架空森林测绘提供了宝贵见解，强调为了进一步推进轻量化机器人无人机系统，进入复杂森林环境进行测绘，还需推进的下一步关键步骤。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17089", "html_url": "https://arxiv.org/abs/2503.17089", "title": "基于理解的公平性改进措施以便于公平的心脏磁共振成像分割", "title_en": "Understanding-informed Bias Mitigation for Fair CMR Segmentation", "authors": "Tiarna Lee,Esther Puyol-Antón,Bram Ruijsink,Pier-Giorgio Masci,Louise Keehn,Phil Chowienczyk,Emily Haseler,Miaojing Shi,Andrew P. King", "background": "随着人工智能（AI）在医学影像任务中的应用日益增多，AI模型可能存在偏差，特别是在使用不平衡训练数据集时。特别是在心脏磁共振(CMR)图像分割模型中发现了强烈的种族偏见影响。尽管已经有许多研究报道了这种现象，但对于解决这一问题的偏见缓解算法的有效性了解有限。本文旨在研究传统偏见缓解方法对基于AI的CMR分割模型中不同种族群体之间偏见的影响。并进一步探索使用裁剪的CMR图像训练和评估模型是否可以提升公平性并减少偏见。", "innovation": "本文创新地评估了多种常用的偏见缓解方法（如过采样、重要性重权和Group DRO）在不同情况下的效果，并首次将裁剪CMR图像作为一种新的解决方案与传统方法结合，以解决CMR分割模型中的种族偏见问题。实验结果显示通过过采样可以显著改善少数群体的表现，同时不显著降低主流群体的表现；裁剪图像的使用可以增加不同种族群体的表现并减少偏见；结合过采样的方法在使用裁剪图像时能进一步减少偏见。最终，使用外部临床验证集测试模型时发现高分割性能且不存在统计显著的偏见。", "conclusion": "本文提出的方法显著降低了心磁共振分割模型中的种族偏见，同时保持了高分割性能。通过结合裁剪图像和过采样技术，不但提高了公平性还提高了模型在临床环境中的表现，这是在处理医学图像偏见方面的一大进步。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17046", "html_url": "https://arxiv.org/abs/2503.17046", "title": "HAPI: 一种基于人类偏好的学习机器人面部表情的模型", "title_en": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences", "authors": "Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida", "background": "自动机器人表情生成对于人机交互至关重要，但基于固定关节配置的手工方法往往会导致表情显得僵硬和不自然。尽管最近的自动化技术减少了对手动调优的需求，但在人机偏好与模型预测之间仍然存在差距，导致表情缺乏细微的真实感。具体表现为表达的自由度有限和感知整合不足，使得表情不够细致和真实。这项研究旨在通过引入人类反馈来弥合这一差距，从而提升机器人表情的表达能力。为此，提出了一个基于人类偏好的学习排序框架，通过成对比较注释收集人类偏好数据并开发HAPI模型，一种基于Siamese RankNet的方法，用于细化表情评价。在35自由度的机器人平台上进行了贝叶斯优化和在线表情调查，结果显示，该方法生成的愤怒、快乐和惊讶表情比基线方法和专家设计的方法更加真实和具有社会共鸣，表明人类偏好与模型预测之间的差距已经得到有效弥合，同时实现了机器人表情生成与人类情感反应的稳健对齐。", "innovation": "本研究的创新点在于提出了一种基于人类偏好的学习排序框架（HAPI模型），利用成对比较注释收集人类偏好数据，采用Siamese RankNet方法优化表情评价，从而提升机器人表情的表达能力，使得生成的表情更加真实和具有社会共鸣，有效弥合了人机偏好与模型预测之间的差距。", "conclusion": "实验结果显示，HAPI模型生成的愤怒、快乐和惊讶表情在真实性和社会共鸣方面均优于基线方法和专家设计方法。这表明该框架有效地弥合了人类偏好与模型预测之间的差距，同时在机器人表情生成方面与人类情感反应实现了稳健对齐。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01975", "html_url": "https://arxiv.org/abs/2507.01975", "title": "learnable-differentiable finite volume solver for accelerated simulation of flows", "title_en": "Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows", "authors": "Mengtao Yan,Qi Wang,Haining Wang,Ruizhi Chengze,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Qi Qi,Hao Sun", "background": "流体流动的模拟对于气象学、 aerodynamics和生物医学等物理现象建模至关重要。经典数值解法需要进行精细的空间-时间网格划分以满足稳定性和一致性条件，但这导致了巨大的计算成本。尽管机器学习方法表明更高效的潜力，但它们通常面临可解释性、通用性和数据依赖性的问题", "innovation": "本文提出了一种可学习和可微分的有限体积求解器（称为LDSolver），用于在粗糙的空间-时间网格上高效和准确地模拟流体流动。LDSolver包含两个关键组件：一个可微分的有限体积求解器和一个提供等价逼近（流、导数和插值）的可学习模块，以及细网格上的时间误差校正。即使训练数据有限（如仅几条轨迹），该模型也能够加速模拟并保持高精度和优越的通用性", "conclusion": "在不同流系统（如Burgers、衰减、强迫和剪切流）上的实验表明，LDSolver在性能方面达到了最先进的技术水平，明显超越了基线模型"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨越语言的旅程：评估多模态大规模语言模型跨语言一致性", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "多模态大规模语言模型（MLLMs）的迅速发展显著提升了其在实际应用中的表现。然而，实现各语言之间的一致性表现，尤其是在结合文化知识时，仍是一个重大挑战。为了更好地解决这一问题，我们引入了两项新的基准测试：KnowRecall和VisRecall，旨在评估MLLMs的跨语言一致性。KnowRecall是一个视觉问答基准测试，用于测量15种语言中的事实知识一致性，重点关注全球地标的文化和历史问题。VisRecall则通过要求模型在没有图片的情况下描述地标外观，来评估视觉记忆的一致性，共涉及9种语言。实验结果显示，最先进的MLLMs，包括专有模型，仍然难以实现跨语言一致性，这强调了需要更加稳健的方法来生成真正多语言和文化敏感的模型。", "innovation": "我们提出了两个新的基准测试，即KnowRecall和VisRecall，主要用于评估MLLMs在跨语言一致性上的表现。KnowRecall特别关注全球地标的文化和历史问题，以测试模型的事实知识一致性；而VisRecall则侧重于视觉记忆的一致性，通过描述地标而不提供图片来测试模型的能力。这两个基准测试为评测和改进MLLMs的跨语言一致性提供了新的视角和方法。", "conclusion": "先进的MLLMs仍然难以实现跨语言一致性。这表明需要开发更稳健的方法来创建真正多语言和文化敏感的模型。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.08589", "html_url": "https://arxiv.org/abs/2412.08589", "title": "SPACE-SUIT: 基于人工智能的SUIT日冕特征提取和分类器", "title_en": "SPACE-SUIT: An Artificial Intelligence Based Chromospheric Feature Extractor and Classifier for SUIT", "authors": "Pranava Seth,Vishal Upendran,Megha Anand,Janmejoy Sarkar,Soumya Roy,Priyadarshan Chaki,Pratyay Chowdhury,Borishan Ghosh,Durgesh Tripathi", "background": "SUIT（太阳紫外线成像望远镜）是搭载在Aditya-L1卫星上的成像仪，可以观测太阳光球和色球在200-400 nm波长范围内的影像。为了全面理解色球和光球形态结构的等离子体和热力学特性，需要进行大规模统计研究，因此提出了自动特征检测方法的发展需求。为此，该研究开发了一种新的特征检测算法SPACE-SUIT，用于从SUIT的Mg II k滤镜观测到的日冕特征进行检测和分类，目标区域包括磁斑、太阳黑子、日珥和背日结构。该算法使用YOLO神经网络模型识别感兴趣区域，通过对IRIS全盘马斯基线图像模拟生成的虚假SUIT图像进行训练和验证，以及在实际的SUIT级1数据上进行检测，展示了其在验证数据集上的精度、召回率和MAP分别为0.788、0.863和0.874。还通过统计测量和Tamura特征进行自我验证，发现熵、对比度、不相似性等的分布差异，这些差异在由SPACE检测到的区域中可以被定性地捕捉，并与观察到的SUIT图像验证一致，即使没有标注的地面真值。", "innovation": "该研究开发了一种名为SPACE-SUIT的算法，这是一种基于人工智能的特征检测方法，用于从SUIT卫星获取的Mg II k滤镜图像中检测和分类日冕特征。突破在于使用YOLO神经网络模型，实现高精度的检测，并通过大量的统计和Tamura特征验证了其有效性，提供了一种新的自动特征提取和分类方法，对于未来的检测方案具有重要的参考意义。", "conclusion": "SPACE-SUIT不仅开发出了一个新的日冕特征提取器，还证明了统计指标和Tamura特征的有效性，能有效地区分日冕特征，提供了一种有效的独立验证方法，对未来的研究方案具有重要的借鉴价值。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06231", "html_url": "https://arxiv.org/abs/2506.06231", "title": "解释可及的特征嵌入比较和对齐", "title_en": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "authors": "Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia", "background": "虽然文献中已经开发出了多种特征嵌入模型，但大多数比较工作集中在这些嵌入在分类相关的下游应用中的数值性能上。现有的比较方法缺乏对嵌入之间可解释性差异的分析，未能有效识别和分析嵌入空间中样本群组之间的不匹配情况。因此，该研究旨在提出一种新的框架，以便更加有效和可解释地比较和对齐不同嵌入方法。", "innovation": "本文提出了Spectral Pairwise Embedding Comparison（SPEC）框架，该框架通过分析来自两种嵌入的核矩阵和基于它们之间差异核矩阵的特征分解来检测被两种嵌入处理不同的样本簇，可以大规模地实现这一核方法。此外，通过优化问题来使两种嵌入在局部和全局上更加一致，以确保一种嵌入中发现的群组也在另一种模型中得到捕捉。此框架已在大规模数据集如ImageNet和MS-COCO上进行了数值测试，并显示了SPEC的有效性。", "conclusion": "本文提出了一种新的评估和对齐特征嵌入的方法，通过分析两种嵌入的核矩阵之间的差异来检测它们在处理样本时的不同模式和差异。该方法不仅在描述不同嵌入间的差异方面具有可解释性，而且提出了优化手段来确保嵌入之间的对齐性，已在大规模数据集上进行了验证，证明了该方法的有效性和实用性。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00660", "html_url": "https://arxiv.org/abs/2507.00660", "title": "MTCNet: 运动和拓扑一致性引导的4D超声二尖瓣分割学习", "title_en": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound", "authors": "Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni", "background": "二尖瓣反流是心脏最常见的疾病之一。四维（4D）超声被视为评估动态瓣膜形态的首要成像技术。然而，4D二尖瓣（MV）分析仍具挑战性，因缺乏相位标注、严重运动伪影和成像质量差。当前方法缺乏相位间依赖性，阻碍了4D MV分析的进步。因此，该领域仍需一种能够解决这些关键技术问题的方法，特别是那些在标注稀疏时也能有效工作的方法。", "innovation": "提出了一种名为MTCNet的运动-拓扑引导一致性网络，用于半监督学习中4D MV超声分割。MTCNet仅需少量的期终舒张和期终收缩标注即可实现优异结果。该网络设计了双向注意力记忆库的跨相运动引导一致性学习策略以及一种新颖的拓扑引导相关性正则化方法，以利用结构对应关系，并维持解剖上合理的结构。此外，MTCNet能在相间一致性上表现出色，且在第一个最大的4D MV数据集上的评估中，其效能显著优于其他先进方法（Dice：87.30%，HD：1.75mm）。", "conclusion": "MTCNet通过结合运动和拓扑一致性学习，在半监督学习中实现了4D MV超声分割的精确性。该研究在大量患者数据上验证了MTCNet的有效性和优越性，证明其在心脏医学图像分析领域的应用潜力。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15057", "html_url": "https://arxiv.org/abs/2505.15057", "title": "通过粗细扩散模型进行MRI重建中的非刚性运动校正", "title_en": "Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models", "authors": "Frederic Wang,Jonathan I. Tamir", "background": "磁共振成像（MRI）由于需要较长的时间进行k空间采样，容易受到运动伪影的影响。这些伪影可以削弱MRI的诊断效用，尤其是在进行动态成像时。现有的扩散模型在处理这种非刚性运动伪影时存在不足之处，无法有效补偿运动变化，特别是在每个运动状态下的低频成分采样不充分时表现更差。", "innovation": "本文提出了一种新颖的交替最小化框架，利用定制的扩散模型联合重建和纠正非刚性运动损坏的k空间数据。该扩散模型采用自上而下的去噪策略，捕捉较大范围的运动，并优先重建图像的低频部分，从而为运动估计提供更好的归纳偏置。与标准扩散模型相比，这种方法能够更好地处理非刚性运动伪影，甚至在每个运动状态下低频成分采样不足64倍的情况下也能实现有效的重建。此外，该方法对采样模式、解剖变异性和MRI扫描协议具有一定的鲁棒性，只需确保每个运动状态下存在一定范围的低频成分采样即可。", "conclusion": "实验结果表明，该框架能够显著提高心脏MRI的重建质量，并且在现实世界的临床数据集上表现优异。同时，该方法在复杂的模拟刚性和非刚性变形中也表现出良好的性能。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12479", "html_url": "https://arxiv.org/abs/2506.12479", "title": "AI 流：视角、场景与方法", "title_en": "AI Flow: Perspectives, Scenarios, and Approaches", "authors": "Hongjun An,Wenhan Hu,Sida Huang,Siqi Huang,Ruanjun Li,Yuanzhi Liang,Jiawei Shao,Yiliang Song,Zihan Wang,Cheng Yuan,Chi Zhang,Hongyuan Zhang,Wenhao Zhuang,Xuelong Li", "background": "信息论奠基人克劳德·香农和机器智能先驱阿兰·图灵开创了信息技术（IT）和通信技术（CT）的交汇与融合，形成了连续不断的连接和计算浪潮。这种协同作用引发了一场技术革新，正达到其顶峰，即大规模人工智能（AI）模型重塑行业和重新定义人机协作。然而，由于大规模模型消耗了大量的资源以及高通信带宽需求，使普遍智能的实现面临诸多挑战。为应对这些挑战，提出了AI Flow这一多学科框架，将先进的IT和CT领域创新整合其中，特别强调三个方面：一、设备-边缘-云框架为基础，整合终端设备、边缘服务器和云集群，优化低延迟模型推理的可扩展性和效率；二、引入家族模型的概念，即一系列具有对齐隐藏特征的不同规模模型，实现有效的合作，并具有适应不同资源约束和动态场景的灵活性；三、基于连接和交互的智能涌现是一种AI Flow的新范式，通过利用通信网络增强连接性，实现跨异构节点的AI模型协作，其智能水平超越任何单一模型的能力。", "innovation": "AI Flow框架将设备-边缘-云框架、家族模型的概念以及基于连接和交互的智能涌现相结合，提供增强的智能、及时响应和普遍的AI服务可访问性，推动AI技术和通信系统的更紧密结合，解决大规模AI模型带来的资源消耗和通信带宽需求的挑战。", "conclusion": "AI Flow通过其多学科方法、优化的设备-边缘-云框架、灵活的家族模型以及基于连接与交互的智能涌现，为实现普遍智能和增强的AI技术应用提供了创新性的解决方案，有望推动AI技术与通信系统的进一步融合和发展。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21714", "html_url": "https://arxiv.org/abs/2506.21714", "title": "ODE_t(ODE_l): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "title_en": "ODE$_t$(ODE$_l$): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "authors": "Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer", "background": "近期，连续正则化流（CNFs）和扩散模型（DMs）在统一理论框架下得到了研究。尽管这些模型可以从噪声分布生成高质量的数据点，但采样过程需要求解常微分方程（ODE），这通常需要多次迭代且计算复杂性高。目前大多数方法集中在减少采样过程中的时间步数以提高效率。", "innovation": " authors 探索了一种新的方向，可以在时间和长度上动态控制质量-复杂度权衡，即通过修改基于transformer的架构以解决关于长度的内部分离化ODE，同时在流匹配训练中引入了时间和长度的一致性术语。这种做法使得采样可以使用任意数量的时间步和transformer块。与以往的方法不同，我们的 ODE_t(ODE_l) 方法在时间维度上与解法无关，减少了延迟并降低了内存使用。实验结果显示，与之前的最先进实践相比，在最高效的采样模式下，生成 CelebA-HQ 和 ImageNet 图像的延迟降低高达 3 倍，高质量采样的 FID 分数提高了 3.5 个点。我们还发布了可完全复现实验的代码和模型权重。", "conclusion": "该方法通过在时间和长度上灵活控制来提高采样速度，并通过实验验证了与现有技术相比的优势。"}
{"llm_update_time": "20250706", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01201", "html_url": "https://arxiv.org/abs/2507.01201", "title": "逃出柏拉图洞穴: JAM 用于对齐独立训练的视觉和语言模型", "title_en": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "authors": "Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim", "background": "独立训练的视觉和语言模型各自形成独特的表征空间，这空间由各自模态、目标和架构所塑造。然而，研究提出了‘柏拉图式的表示假设’，认为这些模型可能仍会朝着现实的共享统计模型靠拢。这种潜在的兼容性引发了一个基本问题：我们能否超越事后统计检测的方式，而是明确优化这些分离表征之间的对齐？", "innovation": "本文将柏拉图式的对齐问题视为一个多目标优化任务——在保持每种模态固有结构的同时实现相互连贯。作者引入了联合自编码器调制器（JAM）框架，该框架联合训练特定模态的自编码器于预训练单模态模型的潜在表示上，并通过重构和跨模态目标来促进对齐。通过这种方法，可以实现从分离输入到共享结构的转换，类似于解放亚里士多德式的隐喻，使共享结构在分离输入中出现。研究还从三个关键的设计轴评估了该框架：（i）对齐目标比较对比损失（Con）、其带硬负样本的变体（NegCon）和我们的扩展损失，（ii）对齐最有效的层深度，（iii）基础模型规模对表示收敛的影响。研究发现，该轻量级的帕雷托高效框架在不同的代表上可靠地引发了对齐，这对于理论洞察和转变通用单模基础模型为专用于多模态模型提供了实际途径", "conclusion": "研究表明，该轻量级的帕雷托高效框架在不同的代表上可靠地引发了对齐，并提供了一种从理论上和实践上都将独立训练的模态专用于多元模态模型的方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01984", "html_url": "https://arxiv.org/abs/2507.01984", "title": "使用早期融合的语言、视觉和社会特征进行多模态虚假信息检测", "title_en": "Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features", "authors": "Gautam Kishore Shahi", "background": "在这篇论文的研究背景中，讨论了选举和危机期间社交媒体中虚假信息泛滥的问题。已有大量研究集中在文本或图像检测上，但少有研究融合文本、图像和社交特征来构建分类模型，以检测虚假信息。研究者分析了1529条包含文本和图像的COVID-19疫情期间和选举期间的推特数据，通过语义、视觉和社交特征的早期融合方法进行了研究，探究了不同多模态特征组合的有效性，提取了视觉和社交特征并通过目标检测和光学字符识别（OCR）等技术来丰富数据", "innovation": "研究的主要创新点在于通过早期融合（early fusion）方法，结合文本、图像和社交特征来检测虚假信息，这在虚假信息检测领域尚属首次尝试。研究通过机器学习模型和特征的组合改进了分类性能，结果显示，结合无监督和监督机器学习模型相比单一模态模型提高了15%，相比二元模型提高了5%。此外，研究还分析了虚假信息传播模式及其特征，为理解虚假信息传播提供了新的视角", "conclusion": "研究结果表明，多模态特征融合可以显著提高虚假信息检测的准确性。通过早期融合的方法，可以更全面地分析虚假信息的传播特性，为防止虚假信息泛滥提供了新的技术支持。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01982", "html_url": "https://arxiv.org/abs/2507.01982", "title": "DKGCM: 通过融合空间节点聚类方法和傅里叶双向Mamba机制的时空交通流预测模型", "title_en": "DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism", "authors": "Siqing Long,Xiangzhi Huang,Jiemin Xie,Ming Cai", "background": "准确的交通需求预测能够使交通管理部门更有效地分配资源，提高资源利用率。然而，交通系统中的复杂的空间和时间关系仍然限制了需求预测模型的性能。为了改善时空交通需求预测的准确性，我们提出了一种新的图卷积网络结构——DKGCM。它首先考虑不同交通节点的空间流量分布，并提出了一种基于时间相似性的新型聚类图卷积方法——DK-GCN，利用动态时间规整（DTW）和K-means聚类来分组交通节点，以更有效地捕捉空间依赖性。在时间尺度上，我们在双向Mamba深度学习框架中整合了快速傅里叶变换（FFT），以捕捉交通需求中的时间依赖性。为了进一步优化模型训练，我们引入了GRPO强化学习策略来增强损失函数反馈机制。", "innovation": "提出了融合空间节点聚类方法和傅里叶双向Mamba机制的时空交通流预测模型——DKGCM。该模型利用动态时间规整（DTW）和K-means聚类来分组交通节点，利用快速傅里叶变换（FFT）捕捉时间依赖性，并引入了GRPO强化学习策略优化损失函数反馈机制，从而提高了模型在时空预测中的性能。", "conclusion": "大规模实验表明，DKGCM模型在三种公开数据集上均超过了多个先进方法，显示出较强的预测效果。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01998", "html_url": "https://arxiv.org/abs/2507.01998", "title": "保持正区域随机采样的高效大规模数据特征选择方法", "title_en": "Positive region preserved random sampling: an efficient feature selection method for massive data", "authors": "Hexiang Bai,Deyu Li,Jiye Liang,Yanhui Zhai", "background": "对于智能机器而言，选择相关的特征是最大化成功机会的重要步骤。然而，智能机器通常在面对大量数据时计算资源不足。为了解决大规模数据特征选择的挑战，本文提出了一种基于采样技术和粗糙集理论的新方法。该方法通过特征集的可辨别对象对的比例来衡量其鉴别能力，并构建大规模数据中保正区域的样本，以找到具有高鉴别能力的特征子集。相比于其他方法，本文的方法具有两个优势：首先，它能够在合理的计算机时间内选择保留所有特征鉴别能力的特征子集；其次，可以在找到约当约简之前估计选定特征子集能够辨别全部需要辨别的对象对的概率下限边界。为了验证此方法的有效性，本文使用了11个不同规模的数据集进行实证研究。结果表明，约当约简可在极短时间内找到，并且最终约简的鉴别能力大于估计的概率下限边界。在合理的时间内，对四大大规模数据集的实验也表明，可以在个人计算机上获取高鉴别能力的近似约简。", "innovation": "本文提出了一种基于采样技术和粗糙集理论的新方法。首先，通过特征集的可辨别对象对的比例衡量鉴别能力并在此基础上提出新的特征选择方法；其次，在合理的时间内和计算机资源内，能够找到保留所有特征鉴别能力的近似约简；最后，这种方法可以在选择特征子集之前估计出的概率下限边界，有助于优化特征选择过程。", "conclusion": "本文提出的方法能够在合理的时间内，通过构建保正区域的样本找到高鉴别能力的特征子集，这不仅显著提高了特征选择的效率，也保证了特征选择的准确性。在大规模数据集上的实证研究验证了本文方法的有效性和可靠性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02001", "html_url": "https://arxiv.org/abs/2507.02001", "title": "Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames", "title_en": "Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames", "authors": "Anurag Arnab,Ahmet Iscen,Mathilde Caron,Alireza Fathi,Cordelia Schmid", "background": "尽管近年来视觉语言模型（VLMs）取得了突破，但理解长视频依然是一项挑战。最先进的长上下文VLMs能够处理约1000帧的输入，但仍然难以有效利用这一长度，容易被上下文窗口中的无关干扰所误导。", "innovation": "我们提出了Temporal Chain of Thought，这是一种视频问答的推理策略，可以筛选模型的输入上下文。该策略使用VLM自身迭代地识别并提取视频中最有相关性的帧，再用于回答。此外，我们展示了在推理时利用更多计算量选择最相关上下文可以提高准确性，这与最近关于语言模型推理时缩放的研究一致。特别是在更长的视频上，这种方法在LV-Bench中使用的上下文窗口为32K时表现优异，比使用标准700K上下文窗口的同一模型提高了2.8分，从而获得了四项不同视频问答数据集上的最新成果，且与三种不同VLMs兼容并显示出一致的改进。", "conclusion": "我们的方法在更长的视频上表现优异，特别是在LV-Bench中，使用32K上下文窗口的方法比700K上下文窗口的标准推理方法在更长视频（超过1小时）上提高了2.8分，取得了4项视频问答数据集的最新成果，不同VLMs下均有改进。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02087", "html_url": "https://arxiv.org/abs/2507.02087", "title": "评估大语言模型在招聘决策中的机遇与挑战", "title_en": "Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions", "authors": "Eitan Anzenberg,Arunava Samajpati,Sivasankaran Chandrasekar,Varun Kacholia", "background": "大语言模型（LLMs）在招聘过程中的应用有潜力简化候选人筛选，但同时也引发了关于准确性和算法偏见的重大担忧，尤其是在缺乏足够安全措施的情况下。本文通过比较几款最先进的基础LLMs—包括来自OpenAI、Anthropic、Google、Meta和DeepSeek的模型以及专有的领域特定招聘模型（Match Score）进行了基准测试，来评估这些模型在职位匹配方面的预测准确性和公平性。", "innovation": "通过实验评估多个最先进的基础LLMs和专有领域特定招聘模型在招聘中的准确性和公平性，并展示了比通用LLMs更高的预测准确性和在各个种族群体中的更公平结果，尤其是Match Score在各种族群体评估指标上达到了接近平等的结果，这表明预训练偏见可能导致在招聘场景中传递社会偏见，而定制的监督模型可以更有效地减少这些偏见。", "conclusion": "本文的研究结果强调了在高风险领域如招聘中部署AI时，领域特定建模和偏见审计的重要性，并警示在没有充分公平保障措施的情况下不能依赖通用LLMs进行相关任务。此外，实证结果表明，在招聘中准确性和公平性之间不应存在二元选择，精心设计的算法可以同时实现招聘准确性和结果公平性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02092", "html_url": "https://arxiv.org/abs/2507.02092", "title": "基于能量的变压器是可扩展的学习者和思考者", "title_en": "Energy-Based Transformers are Scalable Learners and Thinkers", "authors": "Alexi Gladstone,Ganesh Nanduru,Md Mofijul Islam,Peixuan Han,Hyeonjeong Ha,Aman Chadha,Yilun Du,Heng Ji,Jundong Li,Tariq Iqbal", "background": "近年来，类似于人类系统2思考的推理时计算技术因能提升模型性能而受到关注，但现有方法存在局限性，如模态特异性、问题特异性或需要额外的监督/培训。", "innovation": "本文提出了通过学习验证输入与候选预测之间的兼容性，重塑预测问题为根据验证器的优化过程，从而开发出仅从无监督学习中学习思考的模型。具体采用了能量基础变压器（EBTs），将其能量值分配给每对输入和候选预测，通过梯度下降实现能量最小化直至收敛。实验证明，EBTs在训练和推理中的性能优于现有Transformer++方法，在较少的前向传播过程中在图像去噪任务上超越扩散变压器，并且在下游任务中表现良好，表明EBTs有更好的广泛适用性与泛化能力。", "conclusion": "EBTs为模型的学习和思考能力扩展提供了一种新的有前景的范式。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02085", "html_url": "https://arxiv.org/abs/2507.02085", "title": "GeoAda：基于对称适配器高效微调几何扩散模型", "title_en": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters", "authors": "Wanjia Zhao,Jiaqi Han,Siyi Gu,Mingjian Jiang,James Zou,Stefano Ermon", "background": "几何扩散模型在分子动力学和结构生成中取得了显著成功，但如何高效地根据变化的几何控制进行下游任务的微调仍未被充分探索。", "innovation": "提出了一个SE(3)-对称适配器框架GeoAda，能够在不修改原始模型架构的情况下，灵活且参数高效地进行可控生成任务的微调。GeoAda通过引入结构化的适配器设计，保证了几何一致性并减少了过拟合和灾难性遗忘。此外，通过理论上证明适配器保持了SE(3)-对称性，确保了适应过程中预训练扩散模型的几何先验保持不变。", "conclusion": "GeoAda在多种几何控制类型和应用领域中展示了广泛适用性，包括帧控制、全局控制、子图控制以及粒子动力学、分子动力学、人体运动预测和分子生成等。实验结果表明，GeoAda在保持原始任务准确性的同时实现了最佳的微调性能，而其他基线方法则因为过拟合和灾难性遗忘导致了显著的性能下降。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01999", "html_url": "https://arxiv.org/abs/2507.01999", "title": "基于连续小波变换和Siamese网络的多变量半导体工艺时间序列异常检测", "title_en": "Continuous Wavelet Transform and Siamese Network-Based Anomaly Detection in Multi-variate Semiconductor Process Time Series", "authors": "Bappaditya Dey,Daniel Sorensen,Minjin Hwang,Sandip Halder", "background": "半导体制造过程极其复杂，涉及成千上万的相互关联的参数，分布在多种工具和工艺步骤中。多变量时间序列(MTS)分析已成为实时监控和预测维护的关键方法。然而，半导体制造中的异常预测面临着多重挑战，包括数据维度高、真实故障稀有的严重类不平衡、噪声和缺失的测量数据以及生产系统的非平稳行为。复杂的变量之间相互依赖，以及下游阶段故障的延迟出现，也使得故障检测和根本原因分析复杂化。", "innovation": "该研究提出了一种新颖的一般方法，用于使用机器学习进行MTS数据的异常检测。该方法分为三个步骤：a）使用连续小波变换将MTS数据转换为图像表示，b）通过在自定义连续小波变换(CWT)图像数据集上微调预训练的VGG-16架构来开发多类图像分类器，c）构建由两个相同的子网络组成的Siamese网络，每个子网络以细调后的VGG-16作为主干结构。网络输入一对CWT图像，一个是参考或锚点（表示已知良好信号），另一个是查询（表示未知信号）。模型通过比较两者嵌入来判断它们在给定时间步是否属于同一类。这种方法在实际晶圆厂工艺时间序列数据集上表现出高精度，在过程和工具追踪数据的离线异常检测中提供了有前景的解决方案，并且该方法具有灵活性，可以在监督和半监督设置中应用。", "conclusion": "该方法在实际晶圆厂工艺时间序列数据集上展示了高精度，提供了过程和工具追踪数据离线异常检测的有前景的解决方案。此外，该方法具有灵活性，可以在监督和半监督设置中应用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02109", "html_url": "https://arxiv.org/abs/2507.02109", "title": "基于主动学习的参数神经放大器建模", "title_en": "Parametric Neural Amp Modeling with Active Learning", "authors": "Florian Grötschla,Luca A. Lanzendörfer,Longxiang Jiao,Roger Wattenhofer", "background": "介绍了PANAMA框架，这是一个用于训练端到端参数化吉他放大器模型的主动学习框架，使用类似于WaveNet的架构。现有的吉他放大器模型通常需要大量的数据来训练，但该框架通过使用主动学习策略和最少的数据点（即琴放大器旋钮设置）来创建虚拟放大器，从而优化了这一过程。研究显示，在有限的数据样本下，基于梯度优化算法可以确定需要采集的最佳数据点，从而使该方法在数据受限的情况下表现出色。", "innovation": "该研究提出了一个新的主动学习框架PANAMA，用于训练参数化吉他放大器模型。该模型使用类似于WaveNet的架构，并通过主动学习策略减少了所需的数据点数量。研究还展示了基于梯度的优化算法可以有效地确定最优采样点，这对于在数据有限的情况下训练模型非常有用。", "conclusion": "该研究证明，通过PANAMA框架，可以在有限的样本数量下训练出高质量的参数化吉他放大器模型，该框架通过对采样点的选择优化了训练过程，展示了其在资源有限条件下的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02129", "html_url": "https://arxiv.org/abs/2507.02129", "title": "生成性隐空间扩散模型实现高效时空数据压缩", "title_en": "Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction", "authors": "Xiao Li,Liangji Zhu,Anand Rangarajan,Sanjay Ranka", "background": "生成模型在条件设置下表现出强劲的表现，并可视为一种数据压缩形式，其中的条件作为一种紧凑的表示。然而，它们的有限可控性和重建精度限制了它们在数据压缩方面的实际应用。近年来，变分自编码器与条件扩散模型相结合的方法被提出，但未能显著提升重建精度和可控性，对于数据压缩的应用成效不足。这项工作中，引入了一种高效的隐空间扩散框架，将变分自编码器与条件扩散模型相结合，将关键帧压缩到隐空间，通过生成性插值重构余下的帧，无需为每一帧都存储隐表示，能够实现准确的时空重建，大幅度降低存储成本。实验结果表明，该方法与基于规则的最新压缩器（如SZ3）相比具有最高10倍的压缩率，且在同等重建错误下具备63%的领先表现。", "innovation": "提出了一种高效的隐空间扩散框架，将变分自编码器与条件扩散模型相结合。该方法能将少量关键帧压缩到隐空间，通过生成性插值重构获取所有帧，无需存储每一帧的隐表示；这种方法可以实现高精度的时空重建，同时大辐降低存储成本，特别在压缩率和实际性能上具有优势，广泛适用于时空数据压缩领域。", "conclusion": "实验结果表明，该方法在多个数据集中达到了最高10倍的压缩比率，同等重建误差下领先领先学习基于方法的63%的性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02151", "html_url": "https://arxiv.org/abs/2507.02151", "title": "非交换置信预测用于时序图神经网络", "title_en": "Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks", "authors": "Tuo Wang,Jian Kang,Yujun Yan,Adithya Kulkarni,Dawei Zhou", "background": "现有的图神经网络（GNNs）的置信预测方法主要集中在静态图上，忽视了真实世界中图结构、节点属性和真实标签的动态性质。因此，标准的置信预测方法无法处理随时间变化的依赖关系，限制了它们的应用范围。本文分析了这一背景，强调了在时序图上进行置信预测的迫切需求和现有方法的局限性。", "innovation": "本文提出了NCPNET，一种专为时序图设计的端到端置信预测框架。NCPNET采用扩散为基础的非一致性不协合度得分来捕捉随时间变化的网络中的拓扑和时间不确定性。此外，还开发了一个增强效率的优化算法，提高了计算效率并减少了覆盖范围的不一致性。", "conclusion": "在Wiki、Reddit、DBLP和IBM Anti-Money Laundering数据集等多种实际时序图上的实验证明，NCPNET能够确保时序图上的置信预测，相比现有最佳方法，Wiki数据集上预测集大小降低了31%，显著提升了效率。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02006", "html_url": "https://arxiv.org/abs/2507.02006", "title": "AIRES: 通过算法-系统协同设计加速离线核心GCN计算", "title_en": "AIRES: Accelerating Out-of-Core GCNs via Algorithm-System Co-Design", "authors": "Shakya Jayakody,Youpeng Zhao,Jun Wang", "background": "图卷积网络（GCNs）在生物医学蛋白质-蛋白质相互作用（PPI）和大规模推荐系统等众多科学应用中至关重要。在稀疏通用矩阵-矩阵乘法（SpGEMM）这一建模图结构的关键组成部分上，由于资源受限系统的GPU内存限制，随着_GRAPH_DATA_SIZE_的增加，SpGEMMs往往以离线方式进行，以减轻内存约束。尽管最近有通过GPU特性缓存、混合CPU-GPU内存布局或在稀疏格式下执行计算来缓解离线SpGEMM内存限制的努力，但现有系统仍存在高I/O延迟和GPU利用率不足的问题。", "innovation": "本文首先指出了现有系统的性能瓶颈，即稀疏格式数据对齐和内存分配的问题，并提出了一种名为AIRES的新颖算法与系统协同设计方案，以加速GCNs中的离线核心SpGEMM计算。具体而言，AIRES在算法层面提出了针对稀疏格式矩阵在块级的数据对齐问题，并开发了一种平铺算法以促进行块级对齐。在系统层面，AIRES采用了三阶段动态调度方案，其中包括利用多级存储系统进行双向数据传输的策略，整合GPU内存、GPU Direct Storage（GDS）和主机内存以减少I/O延迟并提升吞吐量。", "conclusion": "评估表明，AIRES显著优于现有最先进的方法，实测图处理基准测试中的延迟降低可达1.8倍。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02169", "html_url": "https://arxiv.org/abs/2507.02169", "title": "统计推断与响应性验证", "title_en": "Statistical Inference for Responsiveness Verification", "authors": "Seung Hyun Cheon,Meredith Stewart,Bogdan Kulynych,Tsui-Wei Weng,Berk Ustun", "background": "机器学习中的许多安全故障发生在模型将预测应用于个人（通常在贷款、招聘或内容审核等场景中）时，而未考虑到个体可以改变其输入。现有工作通常缺乏对模型预测对于触发变化的敏感性分析，即模型预测如何响应输入特征的变化。本文旨在填补这一空白，提出了正式验证预测响应性的一种方法。这种验证方法将响应性视为一种敏感性分析类型，其中实践者通过指定干预约束和下游效应的分布来控制一组变化。", "innovation": "本文引入了一种用于度量和验证模型预测响应性的正式验证程序。该方法通过定义和控制干预和其下游效应的概率分布，量化模型预测的响应性。此外，该方法可在仅具有黑盒访问权限的情况下估计响应性，并可用于支持故障排除和失败概率估计等任务。该方法通过生成可达点的均匀样本集来实现响应性的估计，并展示了其在实际应用中的潜力，如再犯预测、器官移植优先级分配和内容审核等场景中的安全性促进作用。", "conclusion": "本文提出了一种统计推断方法，用于验证和量化机器学习模型预测的响应性。该方法能够通过有限的信息估计模型的响应性，并将其应用于实际应用场景，从而增强决策的稳健性和安全性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02227", "html_url": "https://arxiv.org/abs/2507.02227", "title": "PhysicsCorrect: 无训练的稳定神经偏微分方程模拟方法", "title_en": "PhysicsCorrect: A Training-Free Approach for Stable Neural PDE Simulations", "authors": "Xinquan Huang,Paris Perdikaris", "background": "神经网络已成为求解偏微分方程（PDEs）的强大代理模型，相比传统方法提供了显著的计算速度提升。然而，这些模型在长期滚动预测中存在一个关键限制：误差累积会导致小的不准确性指数级放大，最终导致完全偏离物理有效的解决方案。", "innovation": "提出了一种无需训练的校正框架PhysicsCorrect，通过将校正问题形式化为基于PDE残差的线性化逆问题来确保每个预测步骤都能遵守PDE一致性。创新点在于设计了一种高效的预计算策略，该策略在离线预热阶段计算雅克比矩阵及其伪逆，并将计算开销减少了一个数量级。此外，框架能够与各种不同架构（如傅里叶神经算子、UNets和视觉变换器）无缝集成，使不稳定的神经代理模型转变为可靠的模拟工具，有效结合了深度学习的计算效率和实际科学应用所需的物理保真度。这种校正方法减少了预测误差高达100倍，并且基本不增加推理时间（小于5%）。", "conclusion": "PhysicsCorrect框架将不稳定但计算高效的神经网络与物理保真的需求相结合，通过有效的预计算策略减少校正过程中的计算负担，并在多个代表性PDE系统中验证了其高效性和可靠性。这种方法为偏微分方程的神经网络模拟提供了一种新的解决方案，能够在保持计算效率的同时提高模型的物理准确性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02089", "html_url": "https://arxiv.org/abs/2507.02089", "title": "生成模型下线性约束马尔可夫决策过程的样本复杂性边界", "title_en": "Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model", "authors": "Xingtu Liu,Lin F. Yang,Sharan Vaswani", "background": "本文研究无限期γ折扣线性约束马尔可夫决策过程(CMDP)，目标是在满足预期累计约束的条件下，最大化预期累积奖励。给定生成模型的访问权限，提出了一种基于对偶框架的方法，该框架可以利用任何无约束MDP解算器。对于特征维度为d的线性CMDP，使用镜像梯度价值迭代（MDVI）作为MDP解算器实例化框架。为该CMDP算法提供了样本复杂性边界在两种情况下：(i) 放宽可行性，允许小的约束违背；(ii) 严格可行性，要求输出策略恰好满足约束。对于(i)，证明了使用$\tilde{O}\big(\frac{d^2}{(1-\textasciitilde\textgamma)^4\textasciitilde\textepsilon^2}\big)$样本可返回$\textepsilon$-最优策略。对于(ii)，表明算法需要$\tilde{O}\big(\frac{d^2}{(1-\textasciitilde\textgamma)^6\textepsilon^2\textzeta^2}\big)$样本，其中$\textzeta$是问题相关的Slater常数，描述可行区域的大小。最终，将该框架应用于表格CMDP，并展示了在这种设置下恢复接近最优样本复杂性的能力。", "innovation": "文章提出了一种基于对偶框架的方法，用于求解具有生成模型访问权限的线性CMDP。通过使用镜像梯度价值迭代（MDVI），该方法可以利用任何无约束MDP解算器。该方法提供了样本复杂性边界，特别是在放宽可行性和严格可行性两个情境下的边界。对于两种情况，证明了算法在特定样本数量下的性能，强调了结果对维度$d$和容差$\textepsilon$的近最优依赖。此外，还展示了该方法在表格CMDP中的应用价值。", "conclusion": "该研究提供了生成模型下线性CMDP的一个严格的样本复杂性分析。通过证明算法在不同可行性条件下所需的样本数量，论文展示了在解决CMDP问题上的研究进展。最终介绍了该方法在表格CMDP中的有效应用，并为该领域的进一步研究提供了一个基础框架。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02119", "html_url": "https://arxiv.org/abs/2507.02119", "title": "计算最优训练的神经网络中缩放坍缩揭示了普遍动态", "title_en": "Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks", "authors": "Shikai Qiu,Lechao Xiao,Andrew Gordon Wilson,Jeffrey Pennington,Atish Agarwala", "background": "在模型大小和训练时间同步增长的情况下，神经网络训练动态受哪些缩放极限的支配？尽管架构、训练算法和数据之间的复杂交互作用，我们发现计算最优条件下训练的模型表现出惊人的精确普遍性。通过将训练计算和损失标准化到训练结束等于1时，来自不同大小模型的损失曲线可以坍缩到单一的普遍曲线。我们还在具有学习率衰减的情况下观察到所谓的‘超坍缩’现象，使得不同模型的标准化曲线差异低于单个损失曲线在不同随机种子中的噪声水平，由此提供了良好缩放的精确且实用的指标。这些现象通过连接坍缩和典型神经网络缩放定律中的幂律结构来解释，并分析了一个简单但极具效用的SGD噪声动力学模型，该模型准确预测了各种学习率调度下的损失曲线，并定量化解释了‘超坍缩’的起源。", "innovation": "该研究揭示了计算最优训练的神经网络中存在惊人的精确普遍性，并观察到所谓的‘超坍缩’现象，提供了一种衡量模型缩放质量的精确且实用的标准。研究通过连接神经网络缩放定律中的幂律结构和分析简单的噪声动力学模型，来解释这些普遍现象和‘超坍缩’的起源。", "conclusion": "计算最优训练的模型在训练结束时计算和损失归一化后，损失曲线可以坍缩到单一的普遍曲线中，这一现象称为‘超坍缩’。‘超坍缩’现象不受学习率调度、数据集和架构的影响，但当超参数调整不适当时，这一现象会失效。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02256", "html_url": "https://arxiv.org/abs/2507.02256", "title": "Uncertainty-aware Reward Design Process", "title_en": "Uncertainty-aware Reward Design Process", "authors": "Yang Yang,Xiaolu Zhou,Bosong Ding,Miao Xin", "background": "设计有效的奖励函数是强化学习的关键，但传统的奖励工程方法存在效率低下和不一致性的问题。最近的努力探索了利用大型语言模型（LLMs）来自动化奖励函数的设计。然而，这些模型在数值优化中的表现不佳，导致奖励质量不尽如人意。进化搜索范式则在利用模拟资源方面效率较低，导致设计周期过长，并且计算成本高昂。", "innovation": "本文提出了一个新颖的框架——不确定性感知奖励设计过程（URDP），该框架结合了大型语言模型来简化RL环境中的奖励函数设计和评估。URDP通过自一致性分析量化候选奖励函数的不确定性，能够在不需要模拟的情况下识别无效的奖励组件，同时发现新的奖励组件。此外，该文引入了不确定性意识贝叶斯优化（UABO），通过不确定性估计显著提高了超参数配置的效率。最后，构建了一个分层优化架构，将奖励组件优化和超参数调整分离。URDP协调了LLMs的奖励逻辑推理和贝叶斯优化的数值优化优势，通过全面评估35个不同的任务，表明URDP不仅生成了高质量的奖励函数，而且在自动化奖励设计的效率上也显著优于现有方法。", "conclusion": "URDP不仅生成了高质量的奖励函数，还在自动化奖励设计的效率上取得了重要进展，从而实现了显著的改进。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02241", "html_url": "https://arxiv.org/abs/2507.02241", "title": "VERBA: 使用大型语言模型描述模型差异", "title_en": "VERBA: Verbalizing Model Differences Using Large Language Models", "authors": "Shravan Doda,Shashidhar Reddy Javaji,Zining Zhu", "background": "当前机器学习领域面临的“模型湖”现象使得在面对相似性能但行为不同的多个模型时，模型用户难以选择和导航。推荐文档可以帮助模型用户比较模型对成对模型的比较然而，对于$N$个模型，存在$O(N^2)$种成对比较，这对手工进行逐对比较和准备文档的工作量而言是不可行的。因此，为了减少人工工作量，进行精细的模型对成对比较，引入了VERBA。VERBA采用大型语言模型（LLM）通过对两个模型进行采样来生成model差异的描述。研究通过模拟来评估描述的有效性，并构建了一个包含常用机器学习模型的基准套件来测试VERBA的效果。当包括模型结构信息时，描述的准确率提高到90%。", "innovation": "VERBA通过利用大型语言模型来自动生成模型差异的描述，从而帮助模型用户在成对比较中更高效地理解模型之间的差异。VERBA的方法通过模拟验证了其有效性的评估方案，并展示了在对决策树模型的比较中高达80%的整体准确率，增加了结构信息后为90%。这项工作提供了提高机器学习模型的透明性和可比性的新途径，特别是在事后分析中。", "conclusion": "VERBA通过使用大型语言模型自动生成模型差异的描述，提升了对模型行为差异的理解，支持了细致的模型比较。通过将基准套件加入常用机器学习模型，VERBA在比较决策树模型方面表现出良好的准确性，从而为改进透明性和提高模型可比性提供了新方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02291", "html_url": "https://arxiv.org/abs/2507.02291", "title": "基于知识图谱的可解释与泛化的零样本语义通信", "title_en": "Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications", "authors": "Zhaoyu Zhang,Lingyi Wang,Wei Wu,Fuhui Zhou,Qihui Wu", "background": "现有的数据驱动语义通信依赖于表面的统计模式，缺乏解释性和泛化能力，尤其是在未见过的数据存在的情况下。这就导致了语义通信在很多实际应用场景中的局限性。", "innovation": "提出了一种知识图谱增强的零样本语义通信（KGZS-SC）网络。通过基于知识图谱的语义知识库（KG-SKB）引导结构化的语义信息，该方案能够提供通用的语义表示并允许对未见过的情况进行推理。通过将语义特征对齐到共享的类别语义嵌入空间，该方案提高了发送器的泛化能力，并通过选择性传输紧凑的视觉语义来减少通信开销。在接收端，利用零样本学习直接对未见过的情况进行分类，无需重新训练或额外的计算开销，从而增强了分类过程在动态或资源受限环境中的适应性和效率。", "conclusion": "在APY数据集上的仿真实验显示，所提出的KGZS-SC网络在不同信噪比（SNR）水平对未见过的类别进行分类时表现出强大的泛化能力和现有的语义通信框架有显著优势。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02128", "html_url": "https://arxiv.org/abs/2507.02128", "title": "CROP: 使用大型语言模型进行电路检索与优化", "title_en": "CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs", "authors": "Jingyu Pan,Isaac Jacobson,Zheng Zhao,Tung-Chieh Chen,Guanglei Zhou,Chen-Chia Chang,Vineet Rashingkar,Yiran Chen", "background": "现代超大规模集成(VLSI)设计需要利用电子设计自动化(EDA)工具来实现集成电路的实施。由于EDA算法的复杂性，巨大的参数空间给芯片设计优化带来了巨大挑战，因为即使是中等数量的参数组合也会创造出一个巨大的解空间。手动选择参数仍然是工业实践，尽管它非常费时且受限于专家的经验。为了解决这个问题，我们提出了CROP，这是一种使用大型语言模型(LLM)的自动VLSI设计流程调优框架。该方法包括将RTL源代码转换为密集向量表示的可扩展方法，基于嵌入的检索系统，以及增强检索增强生成(RAG)的LLM引导参数搜索系统，该系统使用从类似设计中获取的先验知识来约束搜索过程。实验结果证明，CROP在工业设计中的能力可以在更少的迭代次数下获得更好的结果质量(QoR)，包括9.9%的功耗降低。", "innovation": "CROP框架引入了使用大型语言模型的自动VLSI设计流程调优，通过三个创新步骤实现了优化：(1) 可扩展的从RTL源代码生成密集向量表示的方法；(2) 基于嵌入的检索系统，用于匹配在语义上相似的电路；(3) 使用从类似设计中获取的知识来增强检索增强生成的LLM引导参数搜索系统。这一框架实现了在同样条件下更高的结果质量。", "conclusion": "实验结果表明，CROP能够在更少的迭代次数下获得比现有方法更好的结果质量，特别是在工业设计中降低了9.9%的功耗。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02315", "html_url": "https://arxiv.org/abs/2507.02315", "title": "通过自我蒸馏扭曲顺序蒙特卡罗改进语言模型的受限生成", "title_en": "Improving Constrained Generation in Language Models via Self-Distilled Twisted Sequential Monte Carlo", "authors": "Sooyeon Kim,Giung Nam,Juho Lee", "background": "近年来，受约束文本生成被框定为自回归语言模型的随机推断问题。赵等人（2024）提出了一个基于扭曲顺序蒙特卡罗的方法，该方法通过引入学习到的扭曲函数和由扭曲诱导的提案来引导生成过程。然而，在目标分布集中于基础模型下不太可能的输出的受限生成环境中，学习变得具有挑战性，因为奖励信号稀疏且不具信息性。", "innovation": "本文提出了一种通过自我蒸馏逐步精炼基模型的方法来改进受限生成，从而使得模型越来越与目标分布对齐，提高了生成的质量。这种方法解决了由于奖励信号稀疏和不具有信息性导致的学习困难问题。", "conclusion": "通过连续迭代自我蒸馏，基模型能够更好地适应目标分布，从而在受限生成任务中显著提升生成质量。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02342", "html_url": "https://arxiv.org/abs/2507.02342", "title": "DeltaSHAP: 使用Shapley值解释在线患者监测中的预测演变", "title_en": "DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values", "authors": "Changhun Kim,Yechan Mun,Sangchul Hahn,Eunho Yang", "background": "在临床环境中，及时发现导致患者风险演变的原因对于干预至关重要。现有解释性人工智能(XAI)方法无法满足临床时间序列解释任务的独特需求。因此，需要一种专门设计用于在线患者监测系统的新型XAI算法来解决这一问题。", "innovation": "DeltaSHAP是一种新的、专门针对在线患者监测系统设计的可解释AI算法。它通过引入满足三个关键临床需求的新方法：解释连续预测的变化而非孤立的预测分数、提供特征贡献的幅度和方向以及实时提供这些见解。此外，该方法通过适应Shapley值应用于时间序列场景，精确捕捉特征协同效应，并仅使用实际观测到的特征组合来归因预测变化，从而提高效率和实用性。该研究还引入了新的评估标准来评估在线时间序列归因的忠诚度，并通过在线患者监测任务的实验表明，DeltaSHAP在解释质量和计算效率方面均优于最先进的XAI方法。", "conclusion": "通过实验结果表明，DeltaSHAP在MIMIC-III去补偿基准测试中，ΔSHAP的解释质量提高了62%，计算效率提高了33%。此方法代码已发布。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02365", "html_url": "https://arxiv.org/abs/2507.02365", "title": "基于潜在表示的Deep强化学习DRAM等化器参数优化", "title_en": "Deep Reinforcement Learning-Based DRAM Equalizer Parameter Optimization Using Latent Representations", "authors": "Muhammad Usama,Dong Eui Chang", "background": "在高速动态随机存取存储器（DRAM）系统中，等化器参数优化对信号完整性至关重要，但通常计算量大或依赖模型。直接眼图分析在优化过程中耗时，而传统方法往往需要精确的系统模型。", "innovation": "本论文提出了一种数据驱动的方法，利用学习到的潜在信号表示进行高效的信号完整性评估，并结合无模型的 Advantage Actor-Critic 强化学习代理进行参数优化。方法通过捕捉信号完整性的重要特征，提供了一种快速替代直接眼图分析的优化方法，而强化学习代理则在无需显式系统模型的情况下推导出最优的等化器设置。该方法在标准DRAM波形上实现了显著的眼图开启窗口面积改进，并展示了相对于现有技术的优越性能、计算效率和跨不同DRAM单元的鲁棒泛化能力。主要贡献包括高效的潜在信号完整性度量、稳健的无模型强化学习策略以及对复杂等化器架构的验证性优越表现。", "conclusion": "该方法在复杂等化器架构上展示了优越的性能、计算效率和广泛的应用范围，相比现有技术在眼图开启窗口面积改进方面取得了显著成果。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02310", "html_url": "https://arxiv.org/abs/2507.02310", "title": "基于自适应内存重定位的全面概念漂移持续学习", "title_en": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment", "authors": "Alif Ashrafee,Jedrzej Kozal,Michal Wozniak,Bartosz Krawczyk", "background": "传统的持续学习方法主要侧重于知识保留，旨在减少灾难性遗忘，然而这些方法假定先前学习任务的数据分布保持静态，没有考虑到实际数据流中概念漂移的动态性质，概念漂移永久改变了之前的数据，要求模型在保持稳定的同时迅速适应新的数据分布变化。", "innovation": "本文提出了一种全面的概念漂移持续学习框架，通过演化任务分布来模拟实际场景。作为基线方法，考虑了全重新学习（FR），尽管有效，但这种方法会带来大量的标注和计算开销。为了解决这些问题，本文提出了自适应记忆重定位（AMR）方法，这是一种轻量级的替代方案，能够让基于重演的学习者具备感知漂移的自适应机制，AMR 选择性地从重演缓冲区中移除过时的漂移类样例，并用少量最新的样例重新填充缓冲区，从而将记忆重新定位到新的数据分布上。这种有针对性的抽样可以大幅减少所需标注数据和计算开销，同时保持与全重新学习相当的性能表现。", "conclusion": "通过在标准视觉基准上引入四种概念漂移变体，AMR 结果表明在这些数据集上使用多种基于重演的基线模型进行充分实验后，AMR 持续抵制概念漂移，维持高精度，同时大幅减少计算负担。这些结果使 AMR 成为一种可扩展的方案，能够在非静态持续学习环境中平衡稳定性和灵活性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02320", "html_url": "https://arxiv.org/abs/2507.02320", "title": "基于Transformer的EEG解码：综述", "title_en": "Transformer-based EEG Decoding: A Survey", "authors": "Haodong Zhang,Hongqi Li", "background": "脑-计算机接口（BCIs/BMIs）中，脑电图（EEG）是最常用的信号之一，用于捕捉大脑的电活动。与传统采用机器学习的EEG分析方法相比，深度学习方法通过提供端到端的长链结构，能够自动学习更具区分性的特征，逐渐改变了这一领域。特别是，通过注意力机制处理序列数据的Transformer模型因其强大的处理能力而闻名，在各种EEG处理任务中的应用也愈加普遍。该文旨在总结并概述自Transformer出现以来，其在EEG解码中的最新应用，详细阐述模型架构的演变，并讨论当前面临的挑战及未来的发展前景，帮助读者清晰地了解当前Transformer在EEG解码中的应用状况，并为后续研究提供有价值的看法和思路。", "innovation": "文章介绍了Transformer模型在EEG解码中的最新应用，详细概述了与基本Transformer结合其他深度学习技术的常用混合架构，并介绍了改造后的自定义Transformer结构的研究进展，展示了其如何解决特定问题并提升性能。", "conclusion": "文章总结了发展过程中的关键进展，讨论了当前面临的挑战和未来的发展前景，并希望读者能借此获得对当前Transformer在EEG解码中应用状态的清晰理解，为未来的科研工作提供有价值的指导和见解。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02466", "html_url": "https://arxiv.org/abs/2507.02466", "title": "变分柯尔莫哥洛夫-阿诺德网络", "title_en": "Variational Kolmogorov-Arnold Network", "authors": "Francesco Alesiani,Henrik Christiansen,Federico Errica", "background": "Kolmogorov Arnold Networks (KANs) 是一种新兴的机器学习模型架构，基于Kolmogorov-Arnold定理及其扩展，这些定理提供了用有限数量的一元连续函数的组合来精确表示多元连续有界函数的方法。然而，KANs 的应用取决于人为选择每个一元函数的基的数量，这是一个关键的超参数问题，限制了其作为多层感知机（MLP）的替代学习方法的灵活性和实用性。", "innovation": "本文提出了一种名为 InfinityKAN 的方法，通过在训练过程中适应性地学习每个一元函数的潜在无限数量的基，解决了这一问题。该方法将问题建模为变分推断优化问题，并使用反向传播技术扩展了 KANs 的潜在应用范围，将一个重要的超参数作为学习过程的一部分来处理，从而增加了KANs的灵活性和实用性。", "conclusion": "本文通过将重要超参数纳入学习过程中的变分推理优化方法，解决了Kolmogorov Arnold Networks(KANs)中的基数量选择问题，从而扩展了其应用范围，展示了变分Kolmogorov-Arnold网络(VarKAN)的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02406", "html_url": "https://arxiv.org/abs/2507.02406", "title": "通过偏好优化提高车辆轨迹预测的一致性", "title_en": "Improving Consistency in Vehicle Trajectory Prediction Through Preference Optimization", "authors": "Caio Azevedo,Lina Achaji,Stefano Sabatini,Nicola Poerio,Grzegorz Bartyzel,Sascha Hornauer,Fabien Moutarde", "background": "车辆轨迹预测是自动驾驶车辆工作流程中的关键步骤。不准确或不一致的预测会引发不良的驾驶行为，甚至可能带来危险。当前基于深度学习的轨迹预测模型在公共数据集上表现出色，但在复杂交互场景中，这些模型常常无法捕捉到不同代理之间的动态依赖性，导致预测结果不够一致。", "innovation": "本文提出通过偏好优化在多代理环境中微调轨迹预测模型，以提高场景一致性。优化过程中采用自动计算的预测未来的偏好排名作为输入。实验结果表明，该方法可以显著提高场景一致性，同时对轨迹预测准确性影响较小，并且不会增加推理过程中的额外计算开销。", "conclusion": "本研究通过偏好优化提高了车辆轨迹预测的一致性，在保持预测准确性的同时，解决了模型在复杂场景下的不足之处。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02409", "html_url": "https://arxiv.org/abs/2507.02409", "title": "S2FGL: 空间频谱联邦图学习", "title_en": "S2FGL: Spatial Spectral Federated Graph Learning", "authors": "Zihan Tan,Suyuan Huang,Guancheng Wan,Wenke Huang,He Li,Mang Ye", "background": "联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）的强大的图建模能力。当前的研究主要从结构角度处理子图-FL，但在空间和谱域传播图信号方面存在忽视。从空间角度看，子图-FL在客户端之间引入了边断开问题，导致标签信号中断和全局GNN分类知识的降低。从谱的角度看，谱异构性导致子图间信号频率的一致性问题，使得本地GNN容易过拟合本地信号传播方案。由此产生了谱客户端漂移现象，削弱了全局泛化能力。", "innovation": "本文提出了S2FGL框架，该框架由两个关键策略组成：全局知识库来缓解标签信号中断问题，以及频率对齐来处理谱客户端漂移问题。这些策略的结合形成了一种新的空间和谱策略框架，能够有效解决联邦图学习中存在的挑战问题，并通过多个数据集的实验验证表现优于现有方法。", "conclusion": "本文通过构建全局知识库和频率对齐策略，解决了联邦图学习中空间和谱问题带来的挑战，提出了S2FGL框架并经过多个数据集实验验证其优越性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02356", "html_url": "https://arxiv.org/abs/2507.02356", "title": "带有惩罚动作噪声注入的离线强化学习", "title_en": "Offline Reinforcement Learning with Penalized Action Noise Injection", "authors": "JunHyeok Oh,Byung-Jun Lee", "background": "离线强化学习（Offline RL）利用固定数据集优化策略，适用于环境交互成本高的场景。然而，这一方法的推广能力是其关键挑战之一。尽管最近使用扩散模型取得了显著进步，但尚不确定是否必须使用这些复杂的模型以实现高度性能的离线RL算法，特别是因为它们在推理阶段需要大量计算资源。", "innovation": "该论文提出了一种名为Penalized Action Noise Injection（PAI）的方法，通过向数据集中注入噪声动作来增强离线学习过程，同时根据注入的噪声量进行惩罚。这种方法借鉴了扩散模型在离线RL中的应用方式，并提供了理论基础，说明带有噪声动作的离线RL算法实际上在解决一种改进的马尔可夫决策过程（MDP），称为噪声动作MDP。该方法与现有的多种离线和非在线RL算法兼容，尽管简单，但在多项基准测试中展现出显著的性能提升。", "conclusion": "PAI方法不仅理论上严谨，还能广泛应用于现有离线和非在线RL算法中，通过简单利用动作噪声和合理的惩罚机制，提升算法在多种场景中的性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02510", "html_url": "https://arxiv.org/abs/2507.02510", "title": "TFOC-Net: 一种基于短时傅里叶变换的深度学习方法以提高跨个体运动想象分类", "title_en": "TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification", "authors": "Ahmed G. Habashi,Ahmed M. Azab,Seif Eldawlatly,Gamal M. Aly", "background": "跨个体运动想象（CS-MI）分类在脑-计算机接口（BCI）中是一个具有挑战性的任务，因为不同个体的脑电图（EEG）模式差异显著，导致交叉个体分类准确率较低，相比个体特定模型更低，这妨碍了开发无需校准的适用于现实应用的BCI系统的进展。研究人员通常使用针对单个用户的模型，这限制了系统的通用性和实际应用中的灵活性和适用性。", "innovation": "本文提出了一种采用优化的预处理技术和深度学习方法的新颖方法，显著提高了跨个体运动想象分类的准确性。该方法直接分类经过短时傅里叶变换的EEG数据，优化了STFT参数，并在使用卷积神经网络（CNN）训练时采用了均衡的批次策略。该方法使用四个不同的数据集进行了验证，包括三个广泛使用的基准数据集，取得了显著改进。在BCI Competition IV 数据集1（IV-1）、数据集2A（IV-2A）和数据集2B（IV-2B）上分别达到了67.60%、65.96%和80.22%的分类准确率，超过了当前最先进的技术。此外，系统地探究了1秒至4秒长短不一的运动想象窗口对分类性能的影响，这些发现为通用化的、无需校准的运动想象分类设定了新的基准，并为该领域的研究贡献了全新的公开访问数据集。", "conclusion": "本文提出的方法为通用的、无需校准的运动想象分类设定了新的基准，同时通过提供开放访问数据集支持了该领域的研究进展。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02244", "html_url": "https://arxiv.org/abs/2507.02244", "title": "竞争压力下的订单获取：专为网约车补贴策略设计的快速适应强化学习方法", "title_en": "Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies", "authors": "Fangzhou Shi,Xiaopeng Ke,Xinye Xiong,Kexin Meng,Chang Men,Zhengdan Zhu", "background": "网约车聚合平台的兴起为网约车服务提供商带来了显著的增长机会，通过增加订单量和商品总价值（GMV）。在大多数网约车聚合平台上，提供较低价格的服务商会在列表中排名更高，因此更有可能被乘客选择。这种竞争排名机制促使服务商采取降价策略以获得更多的订单，因为订单量直接影响它们的长期生存和可持续性。因此，设计一个能够动态适应市场波动，在预算约束下优化订单获取的补贴策略是当前研究的关键挑战。现有研究在这方面的成果仍然很少。为填补这一空白，我们提出了FCA-RL，一种新颖的基于强化学习的补贴策略框架，旨在快速适应竞争对手的价格调整。该方法结合了两种关键技术：快速竞争适应（FCA），能够迅速响应动态价格变化，以及强化拉格朗日调整（RLA），确保在新价格环境中遵守预算约束并优化补贴决策。我们还引入了RideGym，这是首个为网约车聚合平台量身定做的仿真环境，能够促进对不同定价策略的全面评估和基准测试，而不会影响实际运营效率。实验结果表明，我们提出的方法在不同市场条件下的一致性表现优于基线方法，突显了其在网约车服务提供商中的补贴优化效果.", "innovation": "我们提出了FCA-RL，一种基于强化学习的补贴策略框架。该方法包括快速竞争适应（FCA）和强化拉格朗日调整（RLA）两个关键技术，能够快速适应动态价格变化并确保在预算约束下优化补贴决策。此外，我们还引入了RideGym，首个为网约车聚合平台量身定做的仿真环境，用于全面评估不同定价策略的效果。实验结果表明，FCA-RL方法在各种市场条件下都表现出色，优于现有的基准方法.", "conclusion": "我们的研究展示了在高竞争压力下的网约车聚合平台上，如何通过快速适应的强化学习策略有效地优化补贴策略，从而最大化订单获取。FCA-RL方法在不同的市场条件下表现突出，为网约车服务提供商提供了一种有效的管理策略."}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02503", "html_url": "https://arxiv.org/abs/2507.02503", "title": "LLMs连续梯度低秩投影微调", "title_en": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs", "authors": "Chenxu Wang,Yilin Lyu,Zicheng Sun,Liping Jing", "background": "大规模语言模型（LLMs）的持续微调面临效率与表达性的权衡。低秩适应（LoRA）虽然提高了效率，但也限制了模型学习新任务和迁移知识的能力，因为其低秩性质和对显式参数约束的依赖。", "innovation": "本文提出了一种名为GORP（Gradient LOw Rank Projection）的持续学习新训练策略，通过结合完整参数和低秩参数，并在统一的低秩梯度子空间内联合更新，克服了上述局限性。GORP扩大了优化空间，同时保持效率并减轻了灾难性遗忘的问题。", "conclusion": "广泛的持续学习基准实验表明，GORP在性能上优于现有最先进的方法。代码可从以下链接获得：this https URL。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02550", "html_url": "https://arxiv.org/abs/2507.02550", "title": "Position: A Theory of Deep Learning Must Include Compositional Sparsity", "title_en": "Position: A Theory of Deep Learning Must Include Compositional Sparsity", "authors": "David A. Danhofer,Davide D'Ascenzo,Rafael Dubach,Tomaso Poggio", "background": "过参数化的深度神经网络（DNNs）在高维数据领域取得了显著的成功，这些领域超出了传统浅层网络的能力范围，后者受限于“维度灾难”。然而，关于DNNs学习动力学的基本原理，仍然存在许多未解之谜。本文认为，DNNs的成功是因为它们能够利用目标函数的合成稀疏结构。大多数实际相关函数可以由一组基本函数组成，每个基本函数依赖于输入的低维度子集。这一性质被所有有效Turing可计算函数共享，因此在当前所有学习问题中都极为可能普遍存在。虽然在合成稀疏函数的环境中已经取得了一些关于逼近和泛化的有希望的理论见解，但关于DNNs可学习性和优化的几个重要问题仍然没有答案。合成稀疏性在深度学习中的角色的全面图景对于全面的人工智能理论至关重要，甚至是通用人工智能。", "innovation": "文章提出，DNNs能够利用目标函数的合成稀疏结构，这解释了DNNs在高维数据领域取得显著成功的原因。这一观点将合成稀疏性作为DNNs学习和优化的关键要素，补充了现有的理论见解。此外，文章强调合成稀疏性在DNNs中的普遍存在，以及其对人工智能理论的重要性。", "conclusion": "文章得出结论，要建立全面的人工智能理论，尤其是关于DNNs的理论，必须包括合成稀疏性的框架。合成稀疏性在DNNs中的重要角色是理解其可学习性和优化行为的关键，对于推动人工智能领域的发展具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02529", "html_url": "https://arxiv.org/abs/2507.02529", "title": "RetrySQL：基于重试数据的文本到SQL训练以实现自纠正查询生成", "title_en": "RetrySQL: text-to-SQL training with retry data for self-correcting query generation", "authors": "Alicja Rączkowska,Riccardo Belluzzo,Piotr Zieliński,Joanna Baran,Paweł Olszewski", "background": "文本到SQL任务是自然语言处理领域的活跃研究主题。当前的许多解决方案主要依赖于扩展了特定组件的黑盒语言模型，这些模型通常在定制的端到端文本到SQL管道中使用。然而，现有的研究大多侧重于利用闭源私有语言模型和编码导向的开源模型，并且缺乏专门针对SQL生成模型的研究。此外，最近在自纠正生成策略方面的进展显示出提高现有架构能力的潜力，但这些概念在文本到SQL任务中的应用尚未被探索。", "innovation": "本文介绍了RetrySQL，一种新的文本到SQL生成模型的训练方法。通过为参考SQL查询准备推理步骤，并将它们注入错误，生成包含错误和修正步骤的数据集。这部分数据被用于持续预训练一个开源编码模型。结果显示，使用重试步骤进行预训练可将整体执行准确性和具有挑战性的执行准确性的指标分别提升最高4个百分点。此外，研究还发现基于LoRA的监督微调对于从重试数据中学习无效，全参数预训练是完成任务的必要条件。研究表明，自纠正行为已经由模型学习，下游准确率提升是这一额外技能的结果。最后，将RetrySQL训练的模型纳入完整的文本到SQL管道中，展示这些模型在执行准确性方面与包含数万倍参数的私有模型相当，证明自纠正可以被学习并在文本到SQL任务中实现，提供了提高SQL导向语言模型生成准确性的新型方法。", "conclusion": "RetrySQL证明了在文本到SQL任务中可以学习到自我纠正，并且提供了一种新的提高SQL导向语言模型生成准确性的方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02608", "html_url": "https://arxiv.org/abs/2507.02608", "title": "在潜在空间迷失：物理仿真中基于潜在扩散模型的实证研究", "title_en": "Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation", "authors": "François Rozet,Ruben Ohana,Michael McCabe,Gilles Louppe,François Lanusse,Shirley Ho", "background": "扩散模型在推理阶段的高计算成本阻碍了它们作为快速物理仿真工具的应用。在图像和视频生成的背景下，通过生成在自编码器的潜在空间而非像素空间中得到了处理，解决了这一计算瓶颈。这项工作旨在探究是否可以将相同策略有效应用于动态系统的仿真，并探讨潜在空间仿真的准确性和成本.", "innovation": "研究发现，潜在空间仿真在广泛的压缩率范围内（高达1000倍）具有出乎意料的鲁棒性。同时，基于扩散的仿真模型的准确性始终优于非生成对抗模型，能够通过更高的多样性弥补预测中的不确定性。此外，研究还覆盖了从架构到优化器等实用设计选择，这些选择对于训练潜在空间仿真是至关重要的.", "conclusion": "基于扩散的潜在空间仿真模型在压缩率和预测准确性方面展现出良好的性能，并且通过更高的多样化弥补不确定性。对训练潜在空间仿真的设计选择进行了详细的讨论，包括架构和优化器的选择."}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02585", "html_url": "https://arxiv.org/abs/2507.02585", "title": "布尔网络中的可扩展互连学习", "title_en": "Scalable Interconnect Learning in Boolean Networks", "authors": "Fabian Kresse,Emily Yu,Christoph H. Lampert", "background": "已学习的可微布尔逻辑网络(DBNs)已经在资源受限硬件上提供了高效的推理。这些网络已经展示出优势，但它们的互连结构在输入宽度增加时需要更多的参数，使其难以扩展到更宽的层。本文作者致力于解决这一问题，提出了一种可训练且可微的不同性互连，即使在输入宽度增加时也能保持参数数量不变，从而扩大DBNs可处理的层宽，同时保持较高的准确性。为了进一步减小模型大小，作者提出了一种互补的剪枝方法，包括基于SAT的逻辑等价性检验和基于相似度的数据驱动剪枝方法，后者在压缩率和准确性之间提供了更优的权衡。", "innovation": "1. 提出了一种可训练且不同性可微的互连，其参数计数不随输入宽度增长而变化，使DBNs能够扩展到更宽的层，同时保持高精度。\n2. 提出了两个互补的剪枝阶段：基于SAT的逻辑等价性剪枝以及基于数据驱动的相似性剪枝，后者优于基于幅度的贪婪剪枝方法，提供了更好的压缩和准确性的折中方案。", "conclusion": "本文提出了一种可在宽层宽下保持高准确性的DBNs模型，通过引入新的可训练不同性互连和两个互补剪枝阶段的方法，解决了DBNs模型规模难以扩展的问题，同时提高了压缩比率与准确性的折中方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02599", "html_url": "https://arxiv.org/abs/2507.02599", "title": "Padé逼近神经网络在使用振动和声学数据增强电机故障诊断中的应用", "title_en": "Padé Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data", "authors": "Sertac Kilickaya,Levent Eren", "background": "在电机条件监控中，加速计和麦克风是标准设备。然而，基于非线性神经网络架构的深度学习模型在诊断性能上提供了有希望的改进。本文旨在通过引入Padé逼近神经网络(PadéNets)来提高感应电机的故障诊断性能，并探讨PadéNets是否能够超越传统的卷积神经网络(CNNs)和自我组织操作神经网络(Self-ONNs)，特别是在使用振动和声学数据进行电气和机械故障诊断方面。", "innovation": "文章提出了一种新的PadéNets模型，用于提高电机故障诊断的性能。该模型通过引入增强的非线性，并且兼容于Leaky ReLU等无界激活函数，能够在感应电机的故障诊断中提供更好的准确性和性能。", "conclusion": "PadéNets在所有测试数据集上都表现出了优越的诊断性能，对比基线模型，诊断准确率分别达到了99.96%、98.26%、97.61%和98.33%。这些结果表明，增强的非线性特性以及PadéNets对无界激活函数的支持，显著提高了感应电机的故障诊断性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02619", "html_url": "https://arxiv.org/abs/2507.02619", "title": "L-VAE：具有可学习Beta的变分自编码器以实现解缠表示", "title_en": "L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation", "authors": "Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural", "background": "在现有的变分自编码器（如eta-VAE）中，超参数是通过经验调整的，这可能会限制模型的有效性。此外，大多数变分自编码器在重建和解缠损失之间取得平衡时，往往倾向于重建或解缠其中的一方面，这影响了模型的性能。因此，研究者提出了一种新颖的模型——Learnable VAE（L-VAE），该模型能够自主学习解缠表示和成本函数中权重的超参数，通过可学习的方式处理这一平衡，从而改进变分自编码器在解缠表示方面的表现。", "innovation": "L-VAE的创新在于它能够学习成本函数中各项的权重，从而自动调整解缠损失和重建损失之间的动态平衡。此外，该模型引入了一种额外的正则化项，以防止过分偏重于任何一种损失。实验结果显示，L-VAE相比于eta-VAE、VAE、ControlVAE、DynamicVAE和sigma-VAE，在多个数据集上的表现更为优胜或接近最优。特别是在CelebA数据集上的定性实验也验证了L-VAE在解缠面部属性方面的有效性。", "conclusion": "实验分析表明，L-VAE能够在重构保真度和解缠潜在维度之间找到有效的平衡，并且在多个数据集的测试中其性能表现最佳或次最佳，这为变分自编码器在解缠表示上的应用提供了新的优化方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02628", "html_url": "https://arxiv.org/abs/2507.02628", "title": "基于医疗数据啄食：一种面向自动结构医疗数据质量评估的上下文感知方法", "title_en": "Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data", "authors": "Irena Girshovitz,Atai Ambus,Moni Shahar,Ran Gilad-Bachrach", "background": "近年来，电子健康记录（EHRs）在流行病学研究和人工智能训练中的使用越来越多。EHR数据的可靠性取决于其准确性和完整性。然而，由于EHR数据主要为临床和计费目的收集，因此经常包含质量问题，如子人群的不准确表示、偏差和系统误差。现有的质量评估方法仍然不足，缺乏系统地评估数据是否适合研究的程序。因此，需要一种新的方法来确保EHR数据的质量，并提高研究结果的可靠性。", "innovation": "本文提出了一种名为‘医疗数据啄食’的方法，它从软件工程中的单元测试和覆盖率概念出发，使用大型语言模型和 embeddings 技术自动生成测试套件，并通过一个数据测试框架执行这些测试以报告潜在的错误和覆盖率。这种方法涵盖了外部医疗知识，以实现上下文相关的数据质量测试，并将其纳入数据分析流程的一部分，从而提高其结果的效度。此外，该方法还对大型语言模型生成的测试套件进行了详细的参考嵌入和值准确性的分析，为其进一步的发展奠定了基础，包括增加新的数据模态和改进嵌入方法。", "conclusion": "我们的方法将外部医疗知识纳入数据分析工作流程中的上下文敏感的数据质量测试，以提高其结果的有效性。从质量保证的角度出发，我们提出了一个框架，为未来进一步发展新的数据模态和改进嵌入方法提供了基础。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02559", "html_url": "https://arxiv.org/abs/2507.02559", "title": "在推理时不需Transformer使用LayerNorm：扩展到GPT-2 XL及其对机理解释的影响", "title_en": "Transformers Don't Need LayerNorm at Inference Time: Scaling LayerNorm Removal to GPT-2 XL and the Implications for Mechanistic Interpretability", "authors": "Luca Baroni,Galvin Khara,Joachim Schaeffer,Marat Subkhankulov,Stefan Heimersheim", "background": "层归一化（LN）是几乎所有基于Transformer的大型语言模型的核心组件。尽管其对训练稳定性的影响已有充分的记录，但其在推理阶段的作用仍然不清楚。此外，LN层会引入额外的非线性，并增加各个模型组件之间的相互关联，这妨碍了模型的机理解释。本文研究了在训练和推理阶段LN层的具体作用，并展示了去除LN层的可能性及其对模型性能和解释性的影响。", "innovation": "本文证明了可以在GPT-2模型中完全去除所有LN层，且验证损失只略有增加；发现去除LN层所需的微调数据量随模型参数数的增加呈非线性增长；直接logit归因现在可以准确识别单个组件的直接效果，而打补丁归因的准确性没有显著提升；确认GPT-2的“自信神经元”在去除LN层后变得不活跃。这些发现推动了对LN层在语言模型中的角色的理解，以及展示了GPT-2类模型在没有LN层的情况下仍能正常运作。", "conclusion": "本文揭示了LN层在语言建模中的作用，表明GPT-2级别的模型可以不包含LN层运作。希望发布的LN无的GPT-2模型将促进更精确的解释性研究，增加对语言模型的理解。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02496", "html_url": "https://arxiv.org/abs/2507.02496", "title": "在线一致预测中的效率保证", "title_en": "Online Conformal Prediction with Efficiency Guarantees", "authors": "Vaidehi Srinivas", "background": "该研究探讨了一种新颖的在线框架中的一致预测问题，该框架直接优化效率。与传统的假设检验相比，这里的算法每天必须输出一个区间，然后在接下来的时间点显现出一个点。算法的目标是在尽可能少的错误数量下实现覆盖率，即在（接近）1-α的比例天数中点落入区间内，同时最小化区间长度。该问题是高效置信区间构造问题的在线版本。研究考虑了任意输入序列和交换输入序列两种场景。对于交换输入序列，研究证明了可以构造满足接近（1-α）覆盖，且区间长度不超过反馈中最佳固定区间的上限的区间。然而，对于任意输入序列，研究证明了任何实现相对于反馈中最佳固定区间平均长度μ近似的优势算法，在错误数量上必须比αT多出一个依赖于μ和问题宽高比的因子。该研究的主要算法结果是能够恢复所有帕累托最优设置的匹配算法，而且算法是确定性的，能够在适应性强的对手面前保持鲁棒性。与经典的在线学习问题不同，在可预期的和任意输入序列情况下没有一种算法能同时最优。该研究给出了在两种情况下都大致最优的算法。", "innovation": "研究提出了一种新颖的在线一致预测框架，直接优化效率。研究证明了在可交换输入序列和任意输入序列情况下，算法设计的差异。研究主要贡献为对于任意输入序列，证明了任何实现相对于反馈中最佳固定区间平均长度μ近似的优势算法，在错误数量上必须比αT多出一个依赖于μ和问题宽高比的因子。进一步，研究提出了一个能恢复所有帕累托最优设置的匹配算法，并且该算法是确定性的。该研究的结果填补了经典的在线学习问题中的空白，证明了没有一种算法能在可预期的和任意输入序列情况下同时最优。还给出了在两种情况下都大致最优的算法。", "conclusion": "研究结果表明，在可适应对手情况下，提出了一个能恢复所有帕累托最优设置的匹配算法，并且是确定性的。研究还证明了在可预期的输入序列和任意输入序列情况下的算法设计存在差异。此外，研究给出了在两种情况下都大致最优的算法。这种新颖的在线一致预测框架直接优化效率的问题研究，为理解和解决一致预测和在线学习的复杂性问题提供了新的视角和方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02639", "html_url": "https://arxiv.org/abs/2507.02639", "title": "关于基于模型的强化学习中高效贝叶斯探索", "title_en": "On Efficient Bayesian Exploration in Model-Based Reinforcement Learning", "authors": "Alberto Caron,Chris Hicks,Vasilios Mavroudis", "background": "研究工作中，我们探讨了在强化学习中利用信息论方法进行高效探索的现有方法。具体来说，我们关注能够针对认知不确定性而不是环境固有的偶然噪声的一类探索奖励。已有研究虽然提供了一些理论框架，但缺乏严格的理论证明。本文通过提供形式化的保证，填补了这一理论空白，同时也提出了能够让这些方法在实践中可用的近似方法。", "innovation": "本文提出了一种新型探索方法，称为预测轨迹采样与贝叶斯探索（PTS-BE），该方法将模型预测与信息论奖励相结合，实现了在稀疏奖励或纯粹探索任务中的样本高效探索。此外，本文还提出了可计算的近似方法，如稀疏变分高斯过程、深度核和深度聚合模型，以实用化信息论的奖励信号。通过形式化的保证和可计算的近似方法，本文为探索领域提供了新的理论基础和实用工具。", "conclusion": "实验结果表明，PTS-BE在多种稀疏奖励或纯粹探索任务的环境中显著优于其他基准方法。本文的工作不仅提供了强大的理论支撑，还提出了可以实际应用的解决方案，为强化学习中探索问题的进一步研究和应用开辟了新路径。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02659", "html_url": "https://arxiv.org/abs/2507.02659", "title": "OmniDraft：一种跨词汇、在线自适应的草稿模型框架，用于设备端推测性解码", "title_en": "OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding", "authors": "Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang", "background": "当前推测性解码通常要求使用一个小巧高效的草稿模型，该模型要么预训练，要么在目标模型系列（如Llama或Qwen模型）上离线精简。然而，在线部署环境中存在两大挑战：1）草稿模型与目标模型不兼容；2）预期提供更好的延迟改善和时间效率。", "innovation": "我们提出了OmniDraft，一个统一框架，允许使用单一草稿模型与任何目标模型配合并根据用户数据进行动态适配。我们引入了一种混合短语缓存和混合精简微调来解决草稿和目标模型之间的跨词汇不匹配，并通过适应性草案技术进一步提升解码速度。该框架特别适用于设备端语言模型应用，其中模型成本、效率和用户定制是主要争议点。这进一步突出了解决上述挑战的必要性，并促进了\"一草遍天\"的范式。我们在数学推理、编程和文本生成任务中展示了OmniDraft框架的效率，使其能够使一个小至Llama-68M模型与多个目标模型（如Vicuna-7B、Qwen2-7B和Llama3-8B）配合进行推测性解码，并提供高达1.5-2倍的速度提升。", "conclusion": "OmniDraft框架通过引入混合技术和适应性方法，解决了在线推测性解码中的跨词汇不匹配和效率问题，使得单一模型能够适应多种目标模型，并在多个任务中显著提高了解码速度。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02634", "html_url": "https://arxiv.org/abs/2507.02634", "title": "使用范畴论解释的高阶深度元学习", "title_en": "High-Order Deep Meta-Learning with Category-Theoretic Interpretation", "authors": "David H. Mguni", "background": "本文介绍了一种新的分层深度学习框架，该框架能够递归地进行高阶元学习，使神经网络能够构建、解决和泛化跨任务层次结构的任务。该方法的核心机制是生成虚拟任务，即合成问题实例，这些实例旨在让元学习器在相关任务中学习软约束和未知的可泛化规则。这种方法使框架能够生成自己的一系列信息丰富且任务相关的数据集，从而摆脱了依赖全部由人工生成的数据的限制。通过在虚拟点景观中主动探索并寻找初级学习者难以解决的任务，元学习器可以逐步精化约束区域，增强归纳偏差，使适应过程更加规范，并生成对于泛化来说新颖且未预料到的任务和约束条件。每个元层次对应于较低层次解决问题的逐级抽象化泛化，这确保了结构化和可解释的学习过程。通过将元学习器解读为范畴论中的分归纳单元，本文建立了一种组合结构，支持在逐步泛化的任务中进行抽象与知识转移。范畴论视角可以统一现有的元学习模型，并揭示如何通过函子关系来转换和比较学习过程，同时还提供了构建元学习的实用设计原则。", "innovation": "本文提出了一种新的分层深度学习框架，可以在递归高阶元学习中使神经网络构建、解决和泛化跨任务层次结构的任务。这种方法使用虚拟任务生成机制，可以生成自己的数据集，无需完全依赖人工生成的数据。提出了将元学习器视为范畴论中的分归纳单元，建立了一种组合结构，支持在更广泛的泛化任务中进行抽象与知识转移。这种架构可以用来构建下一代能够自主生成新颖、有指导意义的任务及其解决方案的神经网络，从而推动机器学习向通用人工智能的进步。", "conclusion": "本文建立了一个新的分层深度学习框架，可以递归地进行高阶元学习，使得神经网络能够构建、解决和泛化跨任务层次结构的任务。通过虚拟任务生成机制，该框架能够生成自己的数据集，解决了数据来源的问题。利用范畴论视角统一了现有的元学习模型。这种架构为构建能够自主生成新颖任务及其解决方案的神经网络提供了理论基础，推动了机器学习向通用人工智能的进一步发展。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02645", "html_url": "https://arxiv.org/abs/2507.02645", "title": "公平的Deepfake检测器能够泛化", "title_en": "Fair Deepfake Detectors Can Generalize", "authors": "Harry Cheng,Ming-Hui Liu,Yangyang Guo,Tianyi Wang,Liqiang Nie,Mohan Kankanhalli", "background": "Deepfake检测模型面临两个关键挑战：对未见过的篡改进行泛化和群体组之间的公平性。现有方法通常表明这两个目标是相互冲突的，揭示了它们之间的权衡关系。现有的方法往往在公平性和泛化之间进行权衡，难以同时达到两个目标。", "innovation": "本研究首次揭示并形式化定义了公平性和泛化之间的因果关系。研究构建了背门调整的方法，通过控制混杂变量（数据分布和模型容量），在公平干预下提高泛化能力。此外，提出了一种名为Demographic Attribute-insensitive Intervention Detection (DAID)的插件框架，包括：i) 对群体敏感的样本再平衡，使用逆倾向加权和子分组特征归一化来消除分布偏差；ii) 对群体无感知的特征聚合，采用新颖的对齐损失来抑制敏感属性信号。DAID在三个跨领域基准测试中，无论在公平性还是泛化性方面，都优于多项最先进的检测器，验证了其理论基础和实际效果。", "conclusion": "DAID框架通过消除数据分布偏差和抑制敏感属性信号，实现了在公平性和泛化方面均优于现有方法的表现，证明了其理论与实践的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02670", "html_url": "https://arxiv.org/abs/2507.02670", "title": "可指导生成的可开发抗体", "title_en": "Guided Generation for Developable Antibodies", "authors": "Siqi Zhao,Joshua Moller,Porfi Quintero-Cadena,Lood van Niekerk", "background": "治疗性抗体不仅需要高亲和力的靶点结合，还需要制造可及性、稳定性和安全性等其他因素的支持，这些综合因素被称为‘开发可及性’。为了优化抗体序列以提高开发可及性，本文提出了一种受自然重链和轻链序列指导的分段扩散模型，该模型在实体抗体空间中训练，并结合定量化的开发指标对246个临床阶段抗体进行学习。这一计算框架旨在通过引导生成生物物理上可行的候选物，克服传统方法的局限，从而实现针对开发可及性的抗体设计.", "innovation": "文中引入了一种基于软值解码在扩散（SVDD）模块，该模块可以在不影响自然性的情况下，指导采样过程偏向于生物物理上可行的候选物。在不受约束的采样中，模型复现了自然库和获批治疗性抗体的全局特征；在SVDD指导下，预测的开发可行性评分显著提高。通过结合高通量开发性测试，这一框架能够实现同步达到结合特性和生物物理标准的抗体设计过程，从而提升整体开发效率和成功率。", "conclusion": "该框架结合了自然链序列和定量开发性评价指标，通过软值解码在扩散过程中的引导，最终实现了抗体设计的优化，并能够利用生物物理特性进一步筛选，为临床应用提供更优的候选物。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02732", "html_url": "https://arxiv.org/abs/2507.02732", "title": "通过分离超曲面进行分类：基于熵的方法", "title_en": "Classification by Separating Hypersurfaces: An Entropic Approach", "authors": "Argimiro Arratia,Mahmoud El Daou,Henryk Gzyl", "background": "该分类问题涉及将具有N个特征向量表示的一组个体划分为两类。这个问题已有悠久历史，归因于感知机模型，是机器学习的核心问题之一。", "innovation": "提出了一种新颖的方法，通过在以原点为中心的N维有界超立方体中寻找参数向量和在${\textbf{R}}^M$中找一个正向量，基于未知变量空间上定义的熵函数的最小化来搜索分离超平面。该方法可以推广到多项式曲面，允许通过更复杂的决策边界来分离数据点，为传统的线性或二次优化技术（如支持向量机和梯度下降）提供了稳健的选择。", "conclusion": "数值实验表明，该方法在处理各种分类任务（包括线性和非线性可分性）时表现出高效性和灵活性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02710", "html_url": "https://arxiv.org/abs/2507.02710", "title": "联邦数据聚合中的流体民主", "title_en": "Fluid Democracy in Federated Data Aggregation", "authors": "Aditya Vema Reddy Kesari,Krishna Reddy Kesari", "background": "联邦学习（FL）机制通常要求每个客户端将其权重传输到中心服务器，而不管这些权重有多有用。为避免不必要的数据传输成本，本文提出使用基于共识的协议，以在每次数据传输步骤中找出最具用的模型权重的客户端子集。传统的FL方法（如一票一权，也称为FedAvg）假设每个客户端的权重都是平等的。本文探索现有流体民主协议在FL中的应用，比较其性能与传统的以1对1投票为基础的方法，并提出一种新的名为粘滞保留民主（Viscous-retained democracy）的流体民主协议，这种协议在相同的假设条件下总是优于1对1投票协议，同时不支持影响力累积。此外，对于流体民主协议从敌对方角度的脆弱性，本文提出了一个算法（FedVRD），该算法利用委派的拓扑结构动态限制敌对方的影响，同时最小化成本。", "innovation": "1. 提出了流体民主协议在联邦学习中的应用，并与传统的1对1投票方法进行了比较。2. 提出了新的粘滞保留民主协议，在相同的假设条件下始终优于1对1投票方法，同时不允许影响力累积。3. 针对流体民主协议从敌对方角度的脆弱性，提出了一个名为FedVRD的算法，利用委派的拓扑结构动态限制敌对方的影响，同时最小化成本。", "conclusion": "通过使用基于共识的流体民主协议和改进的粘滞保留民主协议，本文为解决联邦数据聚合中的数据传输成本问题提供了一种新的方法。FedVRD算法在具有敌对方的环境下能有效降低敌对方对全局模型权重的影响，同时保证聚合过程的效率与安全性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02715", "html_url": "https://arxiv.org/abs/2507.02715", "title": "全面的机器学习框架用于微移动需求预测", "title_en": "A Comprehensive Machine Learning Framework for Micromobility Demand Prediction", "authors": "Omri Porat,Michael Fire,Eran Ben-Elia", "background": "无桩电动滑板车作为一种关键的微移动服务，已经成为环保且灵活的城市交通替代方案。这些服务改善了一公里范围内的交通连接，减少了拥堵和排放，并为短途旅行补充了公共交通。然而，有效管理这些服务依赖于准确的需求预测，这对于最佳车辆分布和基础设施规划至关重要。尽管以前的研究主要集中于分析空间或时间因素，本研究引入了一个框架，该框架将空间、时间和网络依赖性综合起来，以改善微移动需求预测。这一整合提高了准确度并提供了对城市微移动使用模式的更深层次见解。该框架在基本模型上的需求预测准确性提高了27%到49%，证明了其捕捉微移动需求模式的有效性。这些研究成果支持基于数据的微移动管理，有助于优化车辆分布、降低成本和促进可持续的城市规划。", "innovation": "引入了一个框架，将空间、时间和网络依赖性综合起来，以改善微移动需求预测。这一整合提高了准确度并提供了对城市微移动使用模式的更深层次见解。该框架在基本模型上的需求预测准确性提高了27%到49%，证明了其捕捉微移动需求模式的有效性。这些研究成果支持基于数据的微移动管理，有助于优化车辆分布、降低成本和促进可持续的城市规划。", "conclusion": "该研究通过引入一个全面的机器学习框架，改善了微移动需求预测，准确性提高了27%到49%，支持了基于数据的微移动管理，有助于优化车辆分布、降低成本和促进可持续的城市规划。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02698", "html_url": "https://arxiv.org/abs/2507.02698", "title": "在真实模拟市场条件下评估战略性多智能体强化学习在供应链动态定价中的表现", "title_en": "Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions", "authors": "Thomas Hazenberg,Yao Ma,Seyed Sahand Mohammadi Ziabari,Marijn van Rijswijk", "background": "本研究探讨了多智能体强化学习（MARL）如何改善供应链中的动态定价策略，特别是在ERPF系统依赖于静态、规则基方法，而忽视市场参与者之间战略互动的情况下。尽管先前研究将强化学习应用于定价，但大多数实现方式为单智能体模型，无法准确反映真实世界供应链中的相互依赖性。本研究通过在一个由真实电子商务交易数据和LightGBM需求预测模型组成的仿真环境中，将三种MARL算法（MADDPG、MADQN和QMIX）与静态规则基础基准进行对比，填补了这一空白。", "innovation": "本研究创新点在于通过将MARL应用于动态定价策略来填补了传统静态定价规则的空白，并通过具体算法比较展示了MARL对市场动态策略的影响，验证了MARL能够引入未被静态定价规则捕捉到的战略行为。该研究还利用了真实世界的电子商务交易数据和LightGBM需求预测模型来构建仿真环境，以提高研究的真实性与实践性。", "conclusion": "本研究表明，相比于静态定价规则，MARL算法能在保持相对公平和价格稳定的同时，促进市场竞争力。其中MADDPG算法的表现较均衡，支持市场竞争同时保持较高公平性和价格稳定性。研究结果表明MARL能有效地促进动态定价战略的发展，并能够引导未来的相关研究和发展。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02762", "html_url": "https://arxiv.org/abs/2507.02762", "title": "具有(有偏)离线数据的上下文在线定价", "title_en": "Contextual Online Pricing with (Biased) Offline Data", "authors": "Yixuan Zhang,Ruihao Zhu,Qiaomin Xie", "background": "该研究探讨了基于有偏离线数据的上下文在线定价问题。背景在于，实际中的数据可能离线数据可能包含偏差，传统的优化方法可能无法有效利用这些数据。研究旨在通过识别实例相关量度 δ^2，以及考虑离线数据的长度 T、偏差界 V、样本量 N 和方差 λ_{min}(Σ) 等因素，来理解如何有效利用有偏离线数据进行在线定价优化。", "innovation": "在标量价格弹性情况下，该研究提出了一个基于乐观对待不确定性（OFU）策略的实例相关最小极大最优遗憾界，该界为 \\(\\tilde{\\mathcal{O}}\\big(d\\sqrt{T} \\wedge (V^2T + \\frac{dT}{\\lambda_{\\min}(\\hat{\\Sigma}) + (N \\wedge T) \\delta^2})\\big)\\)。对于一般价格弹性，建立了最坏情况下的最小极大最优速率 \\(\\tilde{\\mathcal{O}}\\big(d\\sqrt{T} \\wedge (V^2T + \\frac{dT }{\\lambda_{\\min}(\\hat{\\Sigma})})\\big)\\)，提供了相关的 OFU 算法。此外，当偏差界 V 未知时，还设计了一种鲁棒算法，确保子线性遗憾，能够在精确偏差小的情况下显著优于纯在线方法。这些结果为有偏离线数据分析提供了第一个精确的遗憾保证。研究方法还可以直接应用于具有有偏离线数据的随机线性臂博弈，给出类似的结果。", "conclusion": "该研究提供了一种有效利用有偏离线数据进行上下文在线定价的方法，克服了传统方法在噪声数据上的局限性，提出了实例相关和最坏情况下的最小极大最优遗憾界，并提出了适用鲁棒算法。这些结果对实际应用和未来研究具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02754", "html_url": "https://arxiv.org/abs/2507.02754", "title": "快且简洁：Triton 中的 2-简单形注意力", "title_en": "Fast and Simplex: 2-Simplicial Attention in Triton", "authors": "Aurko Roy,Timothy Chou,Sai Surya Duvvuri,Sijia Chen,Jiecao Yu,Xiaodong Wang,Manzil Zaheer,Rohan Anil", "background": "近期研究表明，训练损失随模型大小和标记数量以幂律方式变化。实现计算最优模型需要同时按比例扩展模型大小和标记数。然而，这些扩展规律假设数据无限供应，主要适用于计算受限环境。随着现代大规模语言模型越来越多地依赖于大规模互联网数据集，它们被视为计算受限的假设越加不成立。这种转变强调了优先考虑标记效率的架构的重要性。", "innovation": "本文研究了使用2-简单形Transformer，这是一种将标准点积注意扩展到三线性函数的架构，通过高效的Triton内核实现。研究表明，2-简单形Transformer在固定标记预算下，与标准Transformer相比，对涉及数学、编程、推理和逻辑的任务显示出更好的标记效率。研究表明，2-简单形注意力改变了知识和推理任务中扩展定律中的指数，相较于点积注意力而言。", "conclusion": "相比于标准Transformer，2-简单形Transformer在固定标记预算下取得了更好的标记效率，特别是在涉及数学、编程、推理和逻辑的任务上。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02814", "html_url": "https://arxiv.org/abs/2507.02814", "title": "可再现分布检测", "title_en": "Replicable Distribution Testing", "authors": "Ilias Diakonikolas,Jingyi Gao,Daniel Kane,Sihan Liu,Christopher Ye", "background": "本文在算法再现性的框架下系统研究了分布测试问题。具体而言，给定独立样本集合，目的是否定性地表征在保持再现性的情况下测试基础分布的自然性质所需的样本复杂度。", "innovation": "在算法层面，我们开发了新的用于测试离散分布邻近性和独立性的可再现算法；在理论层面，我们提出了一种新的方法论，用于证明再现性测试的样本复杂度下界，这可能具有更广泛的兴趣。此外，我们还利用该技术为离散分布的等分布性和邻近性测试建立了几乎最优的样本复杂度下界，从而回答了先前研究中的一个开放问题。", "conclusion": "我们在算法再现性框架下系统地研究了分布检测问题，提出了新的复杂度下界方法，并解决了先前研究中的一个开放问题，为离散分布的邻近性和独立性测试建立了几乎最优的样本复杂度下界。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02671", "html_url": "https://arxiv.org/abs/2507.02671", "title": "基于嵌入的差分隐私条件VAE联邦数据共享", "title_en": "Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs", "authors": "Francesco Di Salvo,Hanh Huyen My Nguyen,Christian Ledig", "background": "深度学习（DL）已在医学成像领域取得重大进展，但其应用受到数据稀缺性和隐私法规的限制，导致难以访问多样化的数据集。联邦学习（FL）能够实现分布式训练，但面临高通信成本的问题，并且通常仅限于单一下游任务，限制了灵活性。当前技术框架下，通过差分隐私（DP）生成模型共享数据是一种潜在解决方法，通过采用基础模型提取简洁且信息丰富的嵌入，减少冗余并降低计算开销。客户机协作训练一个差分隐私条件变分自编码器（DP-CVAE），以建模全球的隐私保护数据分布，以支持多样化的下游任务。该方法不仅提高了隐私保护能力，还增强了可扩展性和效率，优于传统的FL分类器，同时确保了差分隐私的要求。此外，DP-CVAE生成的嵌入具有更高的保真度，参数数量仅为DP-CGAN的五分之一", "innovation": "提出了基于嵌入的差分隐私条件VAE（DP-CVAE）的联邦数据共享方法，通过基础模型提取简洁且信息丰富的嵌入，减少冗余并降低计算开销。客户机协作训练DP-CVAE，以建模全球的隐私保护数据分布，支持多样化的下游任务。这种方法克服了现有技术中的高通信成本和单一任务限制，提高了隐私保护能力，增强了可扩展性和效率，优于传统的FL分类器，并且生成的嵌入具有更高的保真度和更低的参数开销", "conclusion": "该研究提出的基于嵌入的差分隐私条件VAE联邦数据共享方法不仅提升了数据共享的隐私保护、可扩展性和效率，还优于传统的FL分类器，在多个特征提取器验证中表现出色，确保了差分隐私的要求，显著减少了所需参数数量。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02807", "html_url": "https://arxiv.org/abs/2507.02807", "title": "基于约束优化的即席多校准生存分析在医疗保健中的应用", "title_en": "In-Training Multicalibrated Survival Analysis for Healthcare via Constrained Optimization", "authors": "Thiti Suttaket,Stanley Kok", "background": "生存分析在医疗保健中非常重要，因为它可以建模个体协变量与感兴趣事件（如死亡）发生时间之间的关系。准确的生存模型很重要，因为不校准的系统会导致错误的临床决策。现有的生存模型通常仅在总体层面上进行校准，因此存在为一个或多个少数子群体进行不佳校准的风险。", "innovation": "提出了一种名为GRADUATE的模型，通过确保所有子群体也得到良好校准来实现多校准。GRADUATE将多校准建模为一个受限优化问题，并在训练期间优化校准和区分性，以实现二者的良好平衡。通过数学证明，使用的优化方法能够以高概率提供近最优且可行的解。", "conclusion": "与最新基准在真实世界临床数据集上的实证比较表明，GRADUATE具有有效性。在详细分析中，我们阐明了GRADUATE相对于基准的不足之处，进一步凸显了其优势。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02843", "html_url": "https://arxiv.org/abs/2507.02843", "title": "LLM-驱动的在推理时间文本混杂下的治疗效果估计", "title_en": "LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding", "authors": "Yuchen Ma,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel", "background": "在医学中进行治疗效果估计对于个性化医疗决策至关重要，但在临床实践中面临独特挑战。模型通常在结构良好的医疗数据集上进行训练，这些数据集包含详细的患者信息。然而，在推理阶段，预测往往依赖于文本描述（如自我报告的症状描述），这导致了信息的不完整。训练时间与推理时间的数据差异可能导致治疗效果估计偏差，首先这个问题被定义为推理时间文本混杂问题。", "innovation": "本文提出了一个新颖的框架来估计治疗效果，该框架专门解决了推理时间文本混杂问题。该框架结合了大规模语言模型和自定义双重稳健学习者，以减轻因推理时间文本混杂而导致的偏差。", "conclusion": "通过一系列实验，证明了该框架在真实世界应用中的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02724", "html_url": "https://arxiv.org/abs/2507.02724", "title": "跨物种蛋白质-蛋白质相互作用预测的层次多标签对比学习", "title_en": "Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms", "authors": "Shiyi Liu,Buwen Liang,Yuetong Fang,Zixuan Jiang,Renjing Xu", "background": "近年来，AI在科学领域的进步突显了对比学习在连接不同类型生物数据方面的效能。本文基于此，在蛋白质-蛋白质相互作用(PPI)预测中提出HIPPO框架，这是一种层次对比框架，通过多层次生物表示匹配将蛋白质序列及其层次属性对齐。该方法通过层次对比损失函数模拟功能类蛋白质之间的结构关系，引入数据驱动的惩罚机制以适应领域和家族知识，确保学习到的嵌入空间与蛋白质功能的内在层次保持一致。实验表明，HIPPO在基准数据集上展现出最先进的性能，在数据稀少的情况下表现尤为稳定，并且该模型还具有较强的跨物种零样本迁移能力，能在实验数据有限或未充分表征的物种中进行可靠的PPI预测和功能推断。进一步分析显示，层次特征融合对于捕获保守的相互作用决定因素至关重要，如结合模式和功能注释等。这项工作推进了跨物种PPI预测，并为处理稀疏或多物种不平衡数据提供了统一框架。", "innovation": "本研究提出了一种层次对比框架HIPPO，用于蛋白质-蛋白质相互作用预测。该框架通过层次对比损失函数模拟功能类蛋白质之间的结构关系，并通过数据驱动的惩罚机制整合领域和家族知识，确保学习到的嵌入空间与蛋白质功能的内在层次保持一致。HIPPO在基准数据集上的表现优于现有方法，并展现出在数据稀少情况下的稳健性。此外，HIPPO模型在其他物种之间具有较强的零样本迁移能力，即使在实验数据有限或未充分表征的物种中也能进行可靠预测和功能推断。", "conclusion": "HIPPO框架在蛋白质-蛋白质相互作用预测中取得了最先进的性能，不仅在数据丰富的条件下表现优异，而且在数据稀少的情况下依然表现出稳健性。此外，HIPPO模型在跨物种的零样本预测中表现出色，能够进行可靠的PPI预测和功能推断，特别是在实验数据有限或未充分表征的物种中。层次特征融合对于捕捉蛋白质的保守相互作用决定因素至关重要。这项工作为跨物种PPI预测提供了新的思路，并能够统一处理稀疏或多物种不平衡数据。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02834", "html_url": "https://arxiv.org/abs/2507.02834", "title": "ExPO: 使用自我解释引导的强化学习解锁难题推理", "title_en": "ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning", "authors": "Ruiyang Zhou,Shuozhe Li,Amy Zhang,Liu Leqi", "background": "近年来，大型语言模型的发展主要得益于强化学习（RL）风格的后训练方法，通过优化基于奖励或偏好信号的模型输出来改善推理能力。GrPO风格的方法通过按结果验证自我生成样本来实现这一点，然而这些方法严重依赖于模型最初的正样本生成能力，主要优化模型已知的知识（分布强化）而不是解决模型最初无法解决的问题。特别是在早期 RL 训练和复杂推理任务中，有效的正样本不易生成，因此模型需要探索新的推理路径，而探索需要有足够的良好正样本来引导学习。专家演示看似是一个自然解决方案，但实验发现，在 RL 后训练中往往效果不佳。进一步分析后发现，有效的正样本应同时满足两个条件：在当前策略下具有较高的可能性，并且能提高模型正确预测答案的可能性。", "innovation": "本文提出了一个简单且模块化的策略优化框架 ExPO，该框架利用真值答案生成此类样本，以自我解释的指导来解锁挑战性推理问题。ExPO 通过引导模型生成与其策略更加一致的推理路径，同时保证高质量高于其自身错误样本。实验结果显示，ExPO 在数学水平5级等复杂推理基准上均优于基于专家演示的方法，提高了学习效率和最终表现。", "conclusion": "ExPO 框架通过自我解释指导的 RL 方法，克服了传统方法的局限性，在解决复杂推理问题时表现优异，证明了其在提高模型推理能力方面的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02847", "html_url": "https://arxiv.org/abs/2507.02847", "title": "MvHo-IB：基于多视图高阶信息瓶颈的脑部疾病诊断", "title_en": "MvHo-IB: Multi-View Higher-Order Information Bottleneck for Brain Disorder Diagnosis", "authors": "Kunyu Zhang,Qiang Li,Shujian Yu", "background": "最近的研究表明，在功能性磁共振成像(fMRI)数据中建模高级交互作用（HOIs）可以提高机器学习系统的诊断准确性。然而，有效地提取和使用HOIs仍然是一项重大挑战。", "innovation": "- 引入了一种原理性的方法，将信息论中的O-信息与基于矩阵的Renyi alpha阶熵估计器结合起来，以量化和提取HOIs。\n- 设计了专为利用这些交互作用构建的Brain3DCNN编码器。\n- 提出了一种新的多视图学习信息瓶颈目标，以增强表示学习。\n- 实验结果表明，MvHo-IB在三个基准fMRI数据集上的表现优于先前的方法，包括最近的超图技术。", "conclusion": "MvHo-IB框架在多视图学习中实现了高级交互作用的信息瓶颈，自动压缩了与任务无关的冗余信息，从而显著提高了诊断准确性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02712", "html_url": "https://arxiv.org/abs/2507.02712", "title": "深度强化学习在连续控制中的遗忘与增长策略", "title_en": "A Forget-and-Grow Strategy for Deep Reinforcement Learning Scaling in Continuous Control", "authors": "Zilin Kang,Chenyuan Hu,Yu Luo,Zhecheng Yuan,Ruijie Zheng,Huazhe Xu", "background": "近年来，深度强化学习在连续控制任务中取得了显著进展。然而，现有方法常常受到首因偏见的影响，倾向于过度拟合回放缓存中存储的早期经验，这限制了强化学习代理的样本效率和泛化能力。相比之下，人类由于婴儿期遗忘现象的影响（即新神经元的形成会破坏早期记忆痕迹，从而遗忘初始经验）对这种偏见并不那么敏感。受这一遗忘和增长的神经科学过程的启发，本文提出了一种新的深度强化学习算法——FoG（遗忘与增长）算法，包含两个机制：经验回放缓存衰减（ER Decay）用于遗忘早期经验，平衡记忆通过逐步减少早期经验的影响；网络扩展机制（Network Expansion）用于增加神经能力，通过在训练期间动态添加新参数来增强利用现有数据模式的能力。", "innovation": "提出了一种新的深度强化学习算法FoG，引入了两个机制：经验回放缓存衰减（ER Decay）和网络扩展。ER Decay通过逐步减少早期经验的影响来平衡记忆，而Network Expansion通过在训练期间动态添加新参数来提高利用现有数据模式的能力。这旨在减少首因偏见对学习的不利影响，提高样本效率和泛化能力。", "conclusion": "在四个主要的连续控制基准测试中，包含超过40个任务的实验证明，FoG在与现有最佳深度强化学习算法（如BRO、SimBa和TD-MPC2）的比较中表现更优。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02782", "html_url": "https://arxiv.org/abs/2507.02782", "title": "理解并改进循环模型中的长度泛化", "title_en": "Understanding and Improving Length Generalization in Recurrent Models", "authors": "Ricardo Buitrago Ruiz,Albert Gu", "background": "近期，由于所有序列长度都具有线性复杂度，循环模型如状态空间模型和线性注意力模型变得流行。尽管它们理论上可以处理任意长的序列，但在训练外更长的序列上，它们的表现有时会显著下降，即它们在长度泛化方面失败。本文通过全面的实证和理论分析支持未被探索的“状态假设”，该假设认为模型在训练过程中仅接触到状态分布的一部分（如果在长序列上应用循环，则会达到的状态），是其在长度泛化方面失败的原因。研究还包括简单的训练干预措施，旨在增加模型训练中所覆盖的状态范围，例如用高斯噪声或不同输入序列的最终状态初始化状态。仅使用少量（约预训练预算的0.1%）的后训练步骤，这些干预措施便能够使模型在远超训练上下文长度的序列上实现长度泛化，并在长上下文任务上表现更好，从而提供了一种简单而有效的方法来增强一般循环模型的鲁棒长度泛化能力。", "innovation": "通过实证和理论分析支持“状态假设”，说明在训练中仅接触到有限的状态分布导致了模型在长度泛化的失败，并提出通过初始化状态以高斯噪声或不同输入序列的最终状态来增加训练中覆盖的状态范围。这些方法仅需要少量的后训练步骤，就能显著提升模型在远超训练上下文长度的序列上的表现，从而为循环模型的长度泛化提供了一种简单且有效的解决方案。", "conclusion": "通过简单的训练干预措施，使得模型能够稳健地在远长于其训练序文长度的序列上实现长度泛化，并提高了远程上下文任务的表现，这提供了一种简单且有效的增强循环模型鲁棒长度泛化的途径。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01964", "html_url": "https://arxiv.org/abs/2507.01964", "title": "使用长短期记忆技术预测尼日利亚股票回报", "title_en": "Forecasting Nigerian Equity Stock Returns Using Long Short-Term Memory Technique", "authors": "Adebola K. Ojo,Ifechukwude Jude Okafor", "background": "投资者和股票分析师在预测股票回报和做出明智的投资决策方面面临重大挑战。尽管股票回报的可预测性可以提高投资者的信心，但这是个艰巨的任务。", "innovation": "该研究利用长短期记忆（LSTM）模型来预测未来股票市场的动向，使用尼日利亚股票交易所（NSE）的清理和标准化的历史数据集来设计LSTM模型，并将其性能与其他深度学习模型（如人工神经网络和卷积神经网络）进行比较。实验结果表明，LSTM模型在使用可靠的数据集进行训练时，预测未来股票市场价格和回报的准确率超过90%。研究表明，如果训练得当，LSTM模型可以用于解决与金融时间序列相关的问题。未来的研究应探索将LSTM模型与其他深度学习技术（如CNN）结合起来，创建混合模型，以减轻仅依赖单一模型对未来股票预测的风险。", "conclusion": "LSTM模型在适当训练的情况下可以用于预测与金融时间序列相关的问题。未来的研究应探索将LSTM模型与其他深度学习技术结合起来，以减轻依赖单一模型的风险。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01972", "html_url": "https://arxiv.org/abs/2507.01972", "title": "使用强化学习加速投资组合优化和期权定价", "title_en": "Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning", "authors": "Hadi Keramati,Samaneh Jazayeri", "background": "在投资组合优化和期权定价中，需要解决大型线性系统，涉及到高维组合或细网格下的期权定价会在直接求解时产生显著的计算成本。因此，通常会使用迭代法求解。然而，病态系统的收敛速度较慢。传统预条件技术需要针对具体问题进行参数调优，这一限制需要被克服，以优化预条件器的大小并加速迭代求解器的收敛过程。", "innovation": "提出了一种基于强化学习（RL）的框架，用于优化迭代求解器中块预条件器的大小，以加速投资组合优化和期权定价的计算过程，并通过动态调整预条件器大小来加速迭代求解器的收敛速度。该研究在一系列真实世界的投资组合优化矩阵上进行了评估，结果表明，所提出的RL框架能够调整预条件技术，显著加速收敛和降低计算成本，从而支持更快的决策在动态投资组合分配和实时期权定价中。", "conclusion": "该研究展示了如何使用强化学习技术动态调整块预条件器的大小，以加速投资组合优化和期权定价的计算效率，显著提高收敛速度和决策效率。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01971", "html_url": "https://arxiv.org/abs/2507.01971", "title": "DeepSupp: 基于注意力驱动相关模式分析的动态时间序列支持与阻力位识别", "title_en": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification", "authors": "Boris Kriuk,Logic Ng,Zarif Al Hossain", "background": "支持与阻力位（Support and Resistance, SR）在技术分析中至关重要，帮助交易者进行入场、出场和风险管理。然而，传统的SR识别方法往往难以适应现代市场复杂而波动的特点。近期的研究引入了机器学习技术来应对这一挑战，但大多数方法仍侧重于价格预测，而非结构性水平的识别。", "innovation": "本文介绍了DeepSupp，一种新的基于深度学习的支持水平检测方法，使用多头注意力机制来分析空间相关性和市场微观结构关系。DeepSupp结合了高级特征工程，构建动态相关矩阵以捕捉不断变化的市场关系，并采用了基于注意力的自编码器进行稳健的表示学习。最终支持水平通过无监督聚类提取，利用DBSCAN识别关键价格阈值。实验结果表明，DeepSupp在六种财务指标上均优于六种基准方法，表现出最先进的性能，包括核心支持准确性和市场阶段敏感性。", "conclusion": "在各类市场条件下，DeepSupp能够解决SR水平检测的关键缺口，提供一套可扩展且可靠的现代金融市场分析解决方案。本文展示了基于注意力结构的架构在发现复杂市场模式中的潜力，并有助于改善技术交易策略。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01970", "html_url": "https://arxiv.org/abs/2507.01970", "title": "新闻情感嵌入在股票价格预测中的应用", "title_en": "News Sentiment Embeddings for Stock Price Forecasting", "authors": "Ayaan Qayyum", "background": "本文将探讨如何利用头条数据预测股票价格。所探讨的股票价格是SPDR标准普尔500 ETF信托（简称SPY），追踪美国公开上市的前500家公司的表现。文章重点是利用《华尔街日报》（WSJ）的新闻头条来预测股票价格的日间变动趋势。使用基于OpenAI的文本嵌入模型将每个头条新闻转化为向量编码，并通过主成分分析（PCA）提取关键特征。研究挑战在于捕捉新闻对股票价格的时间依赖性和非时间依赖性影响，以及应对潜在的滞后效应和市场噪音。为了提高模型性能，收集了金融和经济数据，如美国美元指数（DXY）和国库收益率。对超过390个机器学习推断模型进行了训练，初步结果显示，利用头条数据嵌入可以显著提高股票价格预测的准确性，相比于未使用头条数据嵌入的模型性能提高了至少40%。", "innovation": "创新点在于使用基于OpenAI的文本嵌入模型将《华尔街日报》的新闻头条转化为向量编码，并通过主成分分析提取关键特征，以改善股票价格预测的准确性。", "conclusion": "研究结果显示，利用头条数据嵌入可以显著提高股票价格预测的准确性，性能至少提高了40%，这表明头条新闻的情感嵌入在股票价格预测中的重要性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00884", "html_url": "https://arxiv.org/abs/2507.00884", "title": "通过线性张量四角注意力的可扩展且量子准确的生物质分子力场基础模型", "title_en": "A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention", "authors": "Qun Su,Kai Zhu,Qiaolin Gou,Jintu Zhang,Renling Hu,Yurong Li,Yongze Wang,Hui Zhang,Ziyi You,Linlong Jiang,Yu Kang,Jike Wang,Chang-Yu Hsieh,Tingjun Hou", "background": "精确的原子级生物质分子模拟对于疾病机制理解、药物发现和生物材料设计至关重要，但现有模拟方法存在众多限制。经典力场效率高但缺乏细节精度，而量子力学方法虽然极为准确，但在大规模或长时间模拟中的计算成本甚高。基于人工智能的力场（AIFF）试图通过提高效率实现量子级的精度，但常常面临复杂度、准确性和速度之间的平衡问题，受制于有限的数据训练和不充分的一般性验证。", "innovation": "本文提出了一种新的尺度可变且具有四角注意力（TQA）的张量可线性化神经网络（LiTEN），该网络能以接近线性的复杂度高效建模三级和四级相互作用。基于LiTEN，开发了LiTEN-FF这一鲁棒的AIFF基础模型，预训练于广泛的nablaDFT数据集以实现广泛的化学通用性，并针对SPICE进行微调以提高溶剂化系统模拟的准确性。LiTEN-FF实现了对MD17、MD22和Chignolin等评估子集的SOTA性能，并在大规模生物分子推理方面比MACE-OFF快10倍。", "conclusion": "本文提出了一种物理基于且高效的新框架，大大推进了复杂生物质分子模型的发展，提供了一个多功能的基础平台，适用于药物发现等相关应用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01974", "html_url": "https://arxiv.org/abs/2507.01974", "title": "用于动物鸣叫声检测的神经网络的声学评估", "title_en": "Acoustic evaluation of a neural network dedicated to the detection of animal vocalisations", "authors": "Jérémy Rouch(CRNL-ENES),M Ducrettet(CRNL-ENES, ISYEB),S Haupert(ISYEB),R Emonet(LabHC),F Sèbe(CRNL-ENES, OFB - DRAS)", "background": "长时间录音设备在有时苛刻的野外条件下得到改进，使得通过生态声学广泛部署动物种群监测活动成为可能。然而，自动信号检测方法的有效性通常仅通过机器学习指标来评估，而声音性能分析则较为罕见。在岩山鹑种群的声学监测研究中，作者提出了一种简单的声学分析方法，用于评估检测系统的性能。这种方法基于将合成信号的信噪比与其检测概率之间的关系来进行。这种方法提供了关于系统的信息，并允许优化其训练。此外，它还用于建模检测距离，从而根据声音环境评估其动态变化，并获取叫声的空间密度估计值。", "innovation": "提出了基于合成信号信噪比与其检测概率关系的简单方法，用于评估动物检测系统的性能。这种方法不仅可以提供关于系统的信息，还能优化其训练，并建模检测距离，评估检测动态并获得叫声的空间密度估计值。", "conclusion": "通过信噪比的建模，可以更好地理解系统性能，并根据声音环境调整其设置，从而实现在复杂声学环境中动物叫声的有效检测与监测。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01987", "html_url": "https://arxiv.org/abs/2507.01987", "title": "预测与解释开放银行中的客户数据共享", "title_en": "Predicting and Explaining Customer Data Sharing in the Open Banking", "authors": "João B. G. de Brito,Rodrigo Heldt,Cleo S. Silveira,Matthias Bogaert,Guilherme B. Bucco,Fernando B. Luce,João L. Becker,Filipe J. Zabala,Michel J. Anzanello", "background": "开放银行的出现标志着金融数据管理的重要转变，影响了金融机构的市场动态和营销策略。这种增加的竞争创造了机遇和挑战，机构在管理数据流入以改进产品和服务的同时，还需缓解可能帮助竞争对手的数据流出。本文提出了一种框架，用于预测客户通过开放银行共享数据的意愿，并通过解释性模型分析（EMA）对其进行解释。研究使用了巴西一家大型金融机构的大数据，有效地解决了数据共享频率低的问题，提高了XGBoost模型的训练效果。", "innovation": "本文采用了一种结合ADASYN和NEARMISS技术的混合数据平衡策略，解决了开放银行中数据共享频率低的问题。研究还提出了结合Shapley值方法和CART技术的解释性模型分析框架，揭示了影响客户数据共享决策的关键因素，包括交易和购买次数、移动渠道的交互以及与信贷相关特性，特别是全国性银行系统中的信用卡使用情况。", "conclusion": "研究结果强调了移动参与和信贷对客户数据共享行为的驱动作用，为金融机构提供了战略洞察，以增强在开放银行环境中的竞争力和创新能力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01976", "html_url": "https://arxiv.org/abs/2507.01976", "title": "网络流量合成综述：从统计模型到深度学习", "title_en": "A Comprehensive Survey on Network Traffic Synthesis: From Statistical Models to Deep Learning", "authors": "Nirhoshan Sivaroopan,Kaushitha Silva,Chamara Madarasingha,Thilini Dahanayaka,Guillaume Jourjon,Anura Jayasumana,Kanchana Thilakarathna", "background": "合成网络流量生成已经成为了网络领域中各种数据驱动应用的一种有前途的替代方案。它能够创建保持真实世界特性的合成数据，同时解决与真实数据相关的数据稀缺性、隐私问题和纯净度约束等关键挑战。本文综述了合成网络流量生成的各种方法，涵盖了数据类型、生成模型以及评估方法等方面，提供了对现有方法的全面分析，解决了当前领域的开放挑战，并展望了未来的研究方向和发展潜力。这些方法对于网络安全测试、性能评估、协议研究和其他相关应用都至关重要。", "innovation": "本文特别聚焦于基于深度学习的技术，同时也详细讨论了统计方法及其扩展，包括商业可用的工具。作者还指出了这个领域中存在的开放挑战，并讨论了未来研究和发展的潜在方向，从而为研究人员和实践者提供了一个基础资源，帮助他们理解并评估现有方法，解决相关挑战，并把握未来的机会。", "conclusion": "本文综述了合成网络流量生成的方法及其评估方式，特别强调了深度学习技术的应用，同时讨论了统计方法及其扩展，指出未来潜在的研究方向。作者希望此综述能够为该领域的进一步研究和发展提供有价值的指导。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02014", "html_url": "https://arxiv.org/abs/2507.02014", "title": "ManifoldMind：动态双曲推理以实现值得信赖的推荐", "title_en": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations", "authors": "Anoushka Harit,Zhongtian Sun,Suncica Hadzidedic", "background": "以往的方法大多采用固定曲率和刚性嵌入的方式，在处理语义层次结构时存在局限性，无法适应不同用户的个性化需求。传统方法往往无法提供准确的不确定性建模以及几何意识的语义探索，导致推荐结果容易受到浅层或直接交互的影响，无法揭示深层次的概念路径。因此，需要一种新的推荐系统方法，能够适应不同的曲率并提供个性化的不确定性建模和几何感知的语义探索。", "innovation": "ManifoldMind 是一种概率几何推荐系统，用于在双曲空间中对语义层次结构进行探索性推理。它使用具有自适应曲率的概率球体来表示用户、项目和标签，并通过一种自适应曲率的语义核支持软、多跳推理，从而探索多样的概念路径而非过度拟合浅层或直接交互。这使得该系统能够在稀疏或抽象领域生成明确的推理痕迹，提高推荐系统的透明度、可靠性和探索性。", "conclusion": "实验结果表明，ManifoldMind 在四个公开基准上优于现有的强大基线，具备更好的NDCG（归一化折扣累积增益）、校准度和多样性。此外，ManifoldMind 产生的显式推理痕迹使其能够提供透明和值得信赖的、基于探索的推荐。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02011", "html_url": "https://arxiv.org/abs/2507.02011", "title": "基于机器学习的印度金融市场组合压力测试框架", "title_en": "Machine Learning Based Stress Testing Framework for Indian Financial Market Portfolios", "authors": "Vidya Sagar G,Shifat Ali,Siddhartha P. Chakrabarty", "background": "传统的压力测试方法存在局限性，通过主成分分析和自动编码器进行降维和潜在因子建模，以此来应对这些局限。在此基础上，通过变异自动编码器增加了潜在空间的概率结构，以便进行蒙特卡洛情景生成，使得市场压力条件的模拟更加精细和分布感知。", "innovation": "本文提出了一种基于机器学习的方法，通过变异自动编码器引入概率结构来潜在空间，实现蒙特卡洛场景生成，从而捕捉复杂的非线性依赖关系，支持VaR和ES的风险估计。这种方法增强了金融压力测试的灵活性、稳健性和现实性，展示了机器学习方法在改进金融压力测试方面的潜力。", "conclusion": "通过这些管道，展示了机器学习方法在提高金融压力测试的灵活性、稳健性和现实性方面的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01990", "html_url": "https://arxiv.org/abs/2507.01990", "title": "在金融投资与市场分析中集成大型语言模型：一项综述", "title_en": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "authors": "Sedigheh Mahdavi,Jiating(Kristin)Chen,Pradeep Kumar Joshi,Lina Huertas Guativa,Upmanyu Singh", "background": "大型语言模型（LLMs）已经在金融决策中得到了应用，提升了投资策略的分析能力。传统的投资策略主要依赖于量化模型、基本面分析和技术指标。然而，LLMs引入了新的能力来处理和分析大量结构化和非结构化数据，提取有意义的洞察，并在实时中增强决策过程。现有文献回顾显示了LLMs在股票选择、风险评估、情绪分析、交易和金融预测中的应用。", "innovation": "这篇文章提供了一种对涉及LLMs的金融研究的结构化回顾，主要分为四种框架：基于LLMs的框架和管道、混合集成方法、微调和适应方式，以及基于代理的架构。这种研究为理解和应用LLMs在金融市场的应用提供了结构化的视角，突显了其能力和潜在发展方向。", "conclusion": "通过对现有文献的回顾，研究强调了LLMs在金融市场的能力和挑战，并指出了未来的可能方向。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02018", "html_url": "https://arxiv.org/abs/2507.02018", "title": "NGAT: 节点级别的图注意力网络用于长期股票预测", "title_en": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction", "authors": "Yingjie Niu,Mingchuan Zhao,Valerio Poti,Ruihai Dong", "background": "图表示学习方法在金融应用中被广泛应用，通过利用公司间的相互关系来增强公司表示。然而，现有的方法面临着三个关键挑战：（1）关系信息的优势在下游任务设计的限制下被掩盖；（2）专门用于股票预测的图模型通常过于复杂且泛化性能差；（3）基于经验构建的企业关系图缺乏对不同图结构的有效比较。", "innovation": "我们提出了一项长期股票预测任务，并开发了一个适用于企业关系图的节点级别图注意力网络（NGAT）。此外，我们实验证明了现有基于模型下游任务性能的图比较方法的局限性。在两个数据集上的实验结果一致地证明了我们提出任务和模型的有效性。该项目已在GitHub上公开，以促进可重复性和未来的研究。", "conclusion": "我们的研究结果表明，NGAT在两个数据集上的绩效验证了其在长期股票预测中的有效性。同时，公开了该项目，以鼓励未来的相关研究。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02076", "html_url": "https://arxiv.org/abs/2507.02076", "title": "预算内的推理：大语言模型测试时计算的自适应可控综述", "title_en": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "authors": "Mohammad Ali Alomrani,Yingxue Zhang,Derek Li,Qianyi Sun,Soumyasundar Pal,Zhanguang Zhang,Yaochen Hu,Rohan Deepak Ajwani,Antonios Valkanas,Raika Karimi,Peng Cheng,Yunzhou Wang,Pengyi Liao,Hanrui Huang,Bin Wang,Jianye Hao,Mark Coates", "background": "大语言模型（LLMs）已经迅速发展为能够解决广泛任务的一般用途代理，然而当前模型在推理方面仍然效率低下：它们在推理过程中无论任务复杂度如何都固定使用相同的计算资源，对简单问题过度思考，对复杂问题则思考不足。本文综述了以提高LLM推理计算效率为目的的高效测试时计算（TTC）策略。", "innovation": "提出了二层分类体系，区分了L1可控性和L2自适应性两大类方法，分别为在固定计算预算下运作的方法和根据输入难度或模型置信度动态调整推理的自适应方法。此外，该研究在多种数据集上对比了领先的私有LLM的推理性能与令牌使用情况，突出了TTC方法的实用控制、适应性和可扩展性。相比前人关于高效推理的研究，本文综述更强调TTC方法的实践控制、适应性和可扩展性。", "conclusion": "讨论了混合思考模型等新兴趋势，并指出了未来工作中让LLMs更高效、更具有计算鲁棒性以及更好地响应用户约束的关键挑战。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02073", "html_url": "https://arxiv.org/abs/2507.02073", "title": "HCVR: 基于相关性感知投票规则的混合特征选择方法", "title_en": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection", "authors": "Nikita Bhedasgaonkar,Rushikesh K. Joshi", "background": "该研究针对的是特征选择问题，这是机器学习和数据挖掘中的一个重要问题。传统的方法如CFS、mRMR和互信息（MI）是非迭代的过滤方法，而RFE、SFS和遗传算法则是迭代的特征选择方法。然而，这些方法在处理高维数据时可能会因为冗余特征的存在而降低模型性能。因此，需要提出一种新的方法来改进特征选择过程，从而提高模型性能。", "innovation": "该研究提出了一种轻量级规则导向的特征选择方法HCVR（Hybrid approach with Correlation-aware Voting Rules）。HCVR结合了Parameter-to-Parameter (P2P)和Parameter-to-Target (P2T)相关性，通过后向消除的方式，避免冗余特征，同时保留相关特征。这是一种非迭代和迭代特征选择方法的混合方法，采用贪心算法进行特征选择，通过多数投票规则来决定保留或丢弃特征，并利用特征间的相关性阈值和特征与目标之间的相关性阈值来做出决策。该方法在SPAMBASE数据集上的实验结果表明，与传统的非迭代方法（CFS，mRMR和MI）及迭代方法（RFE，SFS和遗传算法）相比，其性能有所提升。", "conclusion": "基于HCVR方法的应用结果，该研究证明了其在提高特征选择性能方面的有效性，尤其是在SPAMBASE数据集上的表现优于传统的特征选择方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01979", "html_url": "https://arxiv.org/abs/2507.01979", "title": "使用LSTNet预测劳动力市场：一种多尺度深度学习方法", "title_en": "Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach", "authors": "Adam Nelson-Archer,Aleia Sen,Meena Al Hasani,Sofia Davila,Jessica Le,Omar Abbouchi", "background": "本文提出了一个利用深度学习预测短期就业变动并评估长期行业健康状况的方法，使用美国劳工统计局的劳动力市场数据。系统利用了长短期时间序列网络（LSTNet）来处理带有多变量时间序列数据，包括就业水平、工资、离职率和职位空缺。该模型输出7天的就业预测和可解释的行业就业健康指数（IEHI）。该方法在大多数行业中优于基本模型，特别是在稳定行业中，并且行业健康指数排名与实际就业波动之间有很强的一致性。研究讨论了误差模式、各行业表现及其提升可解释性和泛化性的未来方向。", "innovation": "本文的创新点在于开发了一种利用LSTNet的方法来处理多变量时间序列数据，进行短期就业预测和长期行业健康评估。同时，该方法能够输出可解释的行业就业健康指数，并在多个行业中表现出色。研究还探讨了模型在不同行业中的表现差异及其改进建议。", "conclusion": "本文提出的方法在大多数行业中优于基本模型，特别是在稳定行业中表现突出。IEHI排名与实际就业波动之间有很强的一致性。未来研究方向包括进一步提高模型的解释能力和泛化能力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01980", "html_url": "https://arxiv.org/abs/2507.01980", "title": "在金融网络中检测欺诈：基于格兰杰因果解释的半监督GNN方法", "title_en": "Detecting Fraud in Financial Networks: A Semi-Supervised GNN Approach with Granger-Causal Explanations", "authors": "Linh Nguyen,Marcel Boersma,Erman Acar", "background": "金融行业中每年因欺诈活动造成的损失巨大，因此有效检测欺诈是一项至关重要的技术挑战，需要针对大量数据进行细致分析。尽管机器学习（ML）方法看似可行，但将其成功应用并非易事，主要由于两个难题：（1）稀疏的标注数据使得训练这些方法变得困难，从而增加了标注成本；（2）没有对被标记项目进行解释的能力，因模型的不透明性而常常需要法规遵守。本文研究了基于稀疏标注数据和考虑法规要求的半监督图神经网络（GNN）方法，以解决上述问题，提出了一种称为SAGE-FIN的新方法，基于弱标注或未标注的数据点学习标记欺诈项目，并通过格兰杰因果关系解释所标识的欺诈项目以符合法规要求。", "innovation": "本文提出了一种名为SAGE-FIN的新方法，通过半监督的图神经网络模型学习标记稀疏标注数据下的欺诈项目，并结合格兰杰因果解释来解释被标记的项目，以满足法律法规的要求。这种方法不仅提高了检测欺诈的性能，还解决了现有方法中数据标注成本高、模型不透明的痛点，能够在实际金融网络中有效应用。", "conclusion": "研究结果通过在实际数据集Elliptic++中的详尽验证表明，SAGE-FIN方法能够在不事先假设网络结构的情况下，有效地检测出欺诈交易，并通过格兰杰因果解释提供明确的解释，从而更符合金融行业法规的要求，实现了检测欺诈的技术创新和实际应用上的进步。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02098", "html_url": "https://arxiv.org/abs/2507.02098", "title": "基于高斯过程模型的鲁棒自适应MPC算法", "title_en": "A robust and adaptive MPC formulation for Gaussian process models", "authors": "Mathieu Dubied,Amon Lahr,Melanie N. Zeilinger,Johannes Köhler", "background": "本文探讨了针对受有界干扰和未建模非线性影响的不确定非线性系统的鲁棒且自适应模型预测控制（MPC）框架。通过使用高斯过程（GPs）学习基于噪声测量的系统动力学，包括系统运行期间收集的数据，来处理测量过程中的不确定性。", "innovation": "本文的主要贡献在于提出了利用收缩度量来获得鲁棒的高斯过程模型预测，这些预测被整合到MPC的建模中。该设计保证了递归可行性、鲁棒约束满足以及以很高的概率收敛到参考状态。作者还通过一个有困难的地面效应的平面四旋翼机的数值例子来展示通过提出的鲁棒预测方法和在线学习所实现的显著改进。", "conclusion": "所提出的MPC框架通过确保递归可行性、鲁棒约束满足和几乎肯定收敛到参考状态，为处理受不确定性非线性和有界干扰影响的系统提供了有效的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02084", "html_url": "https://arxiv.org/abs/2507.02084", "title": "基于中值绝对偏差的自适应迭代软阈值算法", "title_en": "Adaptive Iterative Soft-Thresholding Algorithm with the Median Absolute Deviation", "authors": "Yining Feng,Ivan Selesnick", "background": "自适应迭代软阈值算法（adaptive ISTA）因其无需显式调参且在实际应用中表现良好而受到了广泛的关注。然而，关于该算法的理论研究相对较少，特别是对于通过中值绝对偏差估计噪声水平的阈值策略下的理论分析较为匮乏。这篇论文旨在对此类算法进行理论分析，探究其固定点性质以及局部和全局收敛性", "innovation": "本文对基于中值绝对偏差阈值策略的自适应迭代软阈值算法进行了理论分析。首次证明了该算法固定点的等比例不变性、非唯一性和局部稳定性，并且建立了局部线性收敛保证和全局收敛行为", "conclusion": "本文通过理论分析，揭示了基于中值绝对偏差的自适应迭代软阈值算法的具体性质，并证明了其局部线性和全局收敛性，为该算法提供了坚实的理论支持"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02125", "html_url": "https://arxiv.org/abs/2507.02125", "title": "AI能否解决区块链预言机问题？剖析挑战与可能性", "title_en": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities", "authors": "Giulio Caldarelli", "background": "区块链预言机问题指的是难以将可靠的外部数据注入到去中心化系统中，这已成为开发无信任应用的基本限制。尽管近年来采取了多种架构、密码学和经济策略来解决这一问题，但尚未从根本上解决区块链如何获取外部世界知识的问题。", "innovation": "本文从学术文献和实践应用两方面出发，探讨AI技术（如异常检测、基于语言的事实提取、动态信誉建模和对抗性防御）如何增强预言机系统的效果。", "conclusion": "尽管AI提供了提升数据质量、选择数据源和增强系统韧性的重要工具，但无法完全消除对不可验证的外部输入的依赖。因此，AI应被视为预言机设计中推理和过滤的补充层，而不是替代信任假设。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02190", "html_url": "https://arxiv.org/abs/2507.02190", "title": "cVLA: 向高效相机空间VLA迈进", "title_en": "cVLA: Towards Efficient Camera-Space VLAs", "authors": "Max Argus,Jelena Bratulic,Houman Masnavi,Maxim Velikanov,Nick Heppert,Abhinav Valada,Thomas Brox", "background": "视觉-语言-动作（VLA）模型为解决复杂的机器人操作任务提供了诱人的框架，但往往训练成本高昂。本文探讨了通过利用视觉语言模型（VLMs）在2D图像上的出色表现，直接从图像帧坐标预测机器人末端效应器的姿态，从而提出了一种新的VLA方法，目标是更高效地训练模型并使机器人具身体现无关。", "innovation": "本文提出了cVLA，一种新的VLA方法，通过直接从图像帧坐标预测机器人末端效应器的姿态来降低训练成本，并且预测的是轨迹途经点而非低级控制。此外，该模型即使设计简洁，也能有效学习有意义且可执行的机器人轨迹。研究还进一步探索了结合深度图像、推断时技术（如解码策略）和演示数据条件下的动作生成，这些均为未充分利用的潜力。", "conclusion": "cVLA模型在模拟数据集上进行训练，并显示出强大的模拟到真实环境transfer能力。通过模拟和真实数据评估模型的效果，证明了其在实际机器人系统中的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02086", "html_url": "https://arxiv.org/abs/2507.02086", "title": "具有联合优化的选择性特征重编码量子卷积神经网络用于图像分类", "title_en": "Selective Feature Re-Encoded Quantum Convolutional Neural Network with Joint Optimization for Image Classification", "authors": "Shaswata Mahernob Sarkar,Sheikh Iftekhar Ahmed,Jishnu Mahmud,Shaikh Anowarul Fattah,Gaurav Sharma", "background": "量子机器学习（QML）取得了显著进步，这得益于最近NISQ设备性能的提升。结合量子纠缠和叠加等原理，量子卷积神经网络（QCNNs）在量子数据和经典数据分类中表现出令人鼓舞的结果，因此本文在图像分类背景下研究QCNNs并提出了一种改进特征处理的新策略及其一种新型的并行模式QCNN结构。", "innovation": "首先，提出了一种选择性特征重编码策略，使量子电路关注最具有信息性的特征，有效地在希氏空间的关键区域导航以找到最优解空间。其次，设计了一种新型的并行模式QCNN架构，将来自两种经典方法（主成分分析PCA和自动编码器）提取的特征统一于一个训练方案中，通过联优化过程，QCNN能够从互补特征表示中受益，实现更好的模型参数相互调整。该方法通过MNIST和时尚MNIST数据集进行了全面实验，结果显示选择性特征重编码方法显著提高了量子电路的特征处理能力和性能，而联合优化的并行QCNN架构在同一任务中表现出更好的稳健性与性能提升效果。", "conclusion": "实验表明，选择性特征重编码方法显著提升了量子电路的特征处理能力与性能，而联合优化的并行模式QCNN体系结构则在多项测试中体现出更优的准确性和泛化能力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02106", "html_url": "https://arxiv.org/abs/2507.02106", "title": "解析湍流磁流体力学：一种混合算子-扩散框架", "title_en": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework", "authors": "Semih Kacmaz,E. A. Huerta,Roland Haas", "background": "本文提出了一种将物理知情神经算子（PINO）与基于分数生成扩散模型相结合的混合机器学习框架，用于模拟二维不可压缩、有阻尼的磁流体力学（MHD）湍流的全方位时空演化，涵盖了从低到高的广泛雷诺数范围（Re）。该框架利用PINO的方程约束泛化能力预测有序、低频的动力学，而条件扩散模型则通过随机修正高频残差，使模型能够准确地模拟完全发展的湍流。该方法在全面的高保真模拟组中进行了训练，涵盖了Re = {100, 250, 500, 750, 1000, 3000, 10000}的不同雷诺数范围，以实现在先前未被确定性代理所能处理的区域中的最先进的准确性。在Re = 1000和3000时，模型能够忠实重建模拟后期的速度和磁场的完整频谱能量分布，捕获非高斯统计、间歇结构和跨场关联，并以高保真度刻画。在极高的湍流水平下（Re = 10000），它是唯一能够恢复磁场高频演化同时保留大尺度形态并实现统计上意义预测的代理模型。", "innovation": "该研究提出了一个结合物理知情神经算子（PINO）与分数生成扩散模型的混合框架，用以模拟二维不可压缩、有阻尼的MHD湍流。此方法利用了PINO的方程约束泛化工能力，而分数生成扩散模型通过随机修正高频残差提供有效的低频动力学预测。该方法在多种雷诺数下进行了训练，实现了在复杂湍流条件下的卓越预测性能。", "conclusion": "该方法在极高雷诺数下展现了卓越的性能，能够准确模拟磁场的高频演化，保持大尺度形态，并实现有意义的统计预测。这些结果对于理解在复杂物理条件下极湍流MHD系统的传播动力学至关重要。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02248", "html_url": "https://arxiv.org/abs/2507.02248", "title": "矩阵补全中的迁移学习", "title_en": "Transfer Learning for Matrix Completion", "authors": "Dali Liu,Haolei Weng", "background": "本文探讨了在矩阵补 كامل设置下的知识迁移问题，目标是通过利用可用的辅助数据来增强低秩目标矩阵的估计。现有的方法主要依赖于单一目标数据，本文试图通过引入先前对有利源数据集的信息来改进这一方法，从而提高低秩矩阵估计的准确性。", "innovation": "1. 提出了一个基于先前对源数据集有利性信息的迁移学习程序；\n2. 利用了最新的尖锐集浓缩不等式，消除了收敛率中的对数因子，证明了最优性；\n3. 当源数据集的相关性未知时，开发了一种高效的方法来识别有意义的源数据，并证明了该方法的选择一致性。", "conclusion": "本文的方法在源矩阵与目标矩阵接近的情况下，比仅使用单一目标数据的传统方法表现更优。通过理论分析和实证研究，表明了新方法的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02226", "html_url": "https://arxiv.org/abs/2507.02226", "title": "DecoRTL：一种用于基于LLMs的RTL代码生成的运行时解码框架", "title_en": "DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs", "authors": "Mohammad Akyash,Kimia Azar,Hadi Kamali", "background": "大语言模型（LLMs）在自动化生成寄存器传输级（RTL）代码方面具有潜在应用价值。然而，传统的LLM解码策略最初是为自然语言设计的，它们往往无法满足RTL代码的结构性和语义需求，导致生成的代码无效、重复或产生幻觉。为此，研究者通过实证分析RTL生成过程中的token级熵，发现LLMs在结构模糊或语义复杂区域表现出低置信度，表明标准的解码策略无法区分需要确定性的区域（语法规则至关重要的区域）和需要创造性探索变异性（设计至关重要的区域）。", "innovation": "提出了一种名为DecoRTL的新颖运行时解码策略，该策略同时具有语法意识和对比性，适用于RTL代码生成。DecoRTL包含两个互补的组件：自一致性采样，通过基于token级一致性重新排名生成多个候选，促进正确性同时保持多样性；以及语法感知的温度适应性，根据token的语法和功能角色对其进行归类并相应调整采样温度，对语法规则至关重要的token设置低温，对探索性的token设置较高温度。这种方法完全在推理时间运行，无需额外的模型微调。通过使用VerilogEval基准在多个开源LLM上的评估，展示了显著提高了语法正确性、功能正确性和输出多样性，同时执行开销（性能开销）几乎不可察觉", "conclusion": "通过评估，DecoRTL在多个开源LLM上的表现显著提升了代码的语法正确性、功能正确性和输出多样性，且不会增加可感知的执行开销，是一种有效的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02171", "html_url": "https://arxiv.org/abs/2507.02171", "title": "基于自监督RNN的生物启发式机器人轨迹规划", "title_en": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN", "authors": "Miroslav Cibula,Kristína Malinovská,Matthias Kerzel", "background": "机器人的轨迹规划是指生成一系列关节配置，将机器人的机械臂或其操作器从初始状态引导到期望的最终状态，同时考虑机器人运动学和环境的限制，以完成操作任务。传统的轨迹规划依赖基于采样的规划器，计算密集型。最近的研究表明，轨迹规划也可以通过监督序列学习来实现，通常只需要通过神经架构几次，从而保证了计算时间是有限的。但这类方法通常进行模仿学习，它们不是基于轨迹是否能成功达到目标来学习，而是试图重现观察到的轨迹。现有的方法假设这样的网络能够通过前进和反向运动学模型，生成轨迹，并指出这种新方法有助于复杂操作任务的规划，需要适应性解决方案。", "innovation": "本文提出了基于递归神经网络的自监督学习轨迹规划方法，这是一种认知启发式的自我监督学习方案。该方法能够仅使用给定的运动学正向和逆向模型来学习生成轨迹，为适应性解决方案的复杂操作任务规划提供了一种新的方法。", "conclusion": "该模型展示了能够仅通过给定的运动学模型学习生成轨迹的能力，表明这种方法在计划复杂操作任务时可能较为有用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02176", "html_url": "https://arxiv.org/abs/2507.02176", "title": "分析与改善语音合成中的说话人相似性评估", "title_en": "Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis", "authors": "Marc-André Carbonneau,Benjamin van Niekerk,Hugo Seuté,Jean-Philippe Letendre,Herman Kamper,Julian Zaïdi", "background": "语音身份建模具有挑战性，因为语音具有多面性。在生成性语音系统中，说话人身份通常通过自动说话人验证（ASV）嵌入来评估，这些嵌入设计用于区分而不是刻画身份。这项研究探讨了此类表示所捕捉的语音哪些方面。研究发现，广泛使用的ASV嵌入主要关注如音色和音高范围等静态特征，而忽视了节奏等动态元素。此外，还指出了影响说话人相似性测量的混淆因素，并提出了缓解策略。为了填补这些空白，作者提出了一种名为U3D的度量标准，用于评估说话人的动态节奏模式。这项工作为评估语音克隆系统不断提高背景下说话人身份一致性提出了持续挑战。", "innovation": "提出了一种名为U3D的新度量标准，用于评估说话人的动态节奏模式。识别并提出了解决影响说话人相似性测量的混淆因素的策略。这些创新有助于改善语音合成中的说话人相似性评估。", "conclusion": "这项工作为评估语音克隆系统不断提高背景下说话人身份一致性提出了持续挑战。研究结果和技术将有助于进一步提高语音合成的质量和自然度。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02212", "html_url": "https://arxiv.org/abs/2507.02212", "title": "SciGA: 一种用于学术论文设计图形摘要的综合数据集", "title_en": "SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers", "authors": "Takuro Kawada,Shunsuke Kitada,Sota Nemoto,Hitoshi Iyatomi", "background": "图形摘要（GAs）在科学论文中扮演着重要角色，它们用于通过视觉方式传达论文的关键发现。尽管视觉材料如图1在论文中被广泛使用，但它们提升科学研究交流的效果尚未得到深入研究。此外，有效设计GAs需要高级可视化技能，这限制了它们的广泛应用。 SciGA-145k数据集应运而生，旨在支持GA的选择和推荐，并促进自动化GA生成的研究。该论文通过定义两个初步任务——基于论文内部推荐合适的GA和跨论文检索GA进行灵感启发，推动了GA设计支持的进展。", "innovation": "SciGA-145k是一个大规模的数据集，包含约145,000篇科学论文和1,140,000幅图，专门为支持GA选择和推荐及促进自动GA生成的研究设计。此外，还提出了基于信心调整的Top-1真实比（CAR），这是一种新颖的推荐指标，提供了对模型行为的细粒度分析。CAR通过考虑到一本书中除显性标识的GA之外，其他图也可能是GA的情况，弥补了传统排名指标的局限性。SciGA-145k将这些任务和指标综合起来，为促进视觉科学研究交流奠定基础，同时为科学领域的AI发展贡献力量。", "conclusion": "SciGA-145k不仅为GAs的设计提供了大量的数据支持，还为研究者和AI系统在GA推荐和生成方面的研究提供了基础。通过这种方法，研究将进一步推动视觉科学交流的发展，同时也促进了科学领域AI技术的进步。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02255", "html_url": "https://arxiv.org/abs/2507.02255", "title": "基于列表偏好对齐优化的尾部项推荐", "title_en": "Listwise Preference Alignment Optimization for Tail Item Recommendation", "authors": "Zihao Li,Chao Yang,Tong Zhang,Yakun Chen,Xianzhi Wang,Guandong Xu,Daoyi Dong", "background": "偏好对齐已经在大型语言模型（LLMs）上取得了显著的成功，也在推荐研究中引起了广泛关注。现有的偏好对齐方法要么需要显式的奖励建模，要么仅支持对偏好进行成对比较。这种方式要么增加了大量的计算成本，要么在训练过程中对负样本的效率受到阻碍。此外，现有的研究未探索偏好对齐在尾部项（较少出现，较少被用户点击的项）推荐中的应用。为了解决这一问题，我们提出了一种名为LPO4Rec的方法，该方法从成对比较扩展为列表比较，以提高模型训练效率。", "innovation": "我们提出了LPO4Rec，该方法将布雷多克-特里模型从成对比较扩展到列表比较，通过推导闭式最优策略来提高训练效率，同时避免了显式奖励建模。我们还提出了一种自适应负样本重采样和加权策略，以在优化过程中优先考虑尾部项，从而提高尾部项推荐的性能。此外，我们证明了优化列表偏好优化（LPO）损失等同于最大化最优奖励的上界。实验结果表明，在尾部项推荐中，我们的方法在性能上优于10种基线方法，最高提升了50%的性能，同时减少了17.9%的GPU内存使用量，与其他直接偏好优化（DPO）方法相比。", "conclusion": "我们的研究表明，在推荐尾部项时，LPO4Rec方法不仅提高了性能，还减少了对计算资源的依赖。我们的代码开源。实验结果强调了LPO方法在提高推荐系统效率和效果方面的重要性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02215", "html_url": "https://arxiv.org/abs/2507.02215", "title": "从高度噪声数据中学习函数的混合最小二乘法", "title_en": "Hybrid least squares for learning functions from highly noisy data", "authors": "Ben Adcock,Bernhard Hientzsch,Akil Narayan,Yiming Xu", "background": "为了高效估计条件期望，在数据严重污染的情况下，现有的小型噪声环境中表现强大的方法在大型噪声环境下变得次优。本文旨在通过结合Christoffel采样和某些类型的最优实验设计来解决这一问题，尤其在大量噪声存在的情况下提供高效的方法。", "innovation": "提出了一种混合方法，该方法结合了Christoffel采样与特定类型的最优实验设计，旨在提高样本点生成的优化性质和噪声的平滑处理，从而提高计算效率和样本复杂度，同时在凸约束设置中扩展了算法并保持了类似的理论保证。此外，当目标函数定义为随机场的期望值时，扩展了方法并利用了自适应随机子空间，证明了自适应过程的近似能力。", "conclusion": "本研究不仅证明了所提算法的适当优化性质和噪声平滑处理，还在合成数据和计算金融中的更具有挑战性的随机模拟问题上得到了数值研究的支持。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02259", "html_url": "https://arxiv.org/abs/2507.02259", "title": "MemAgent：基于多会话RL记忆代理重塑长上下文LLM", "title_en": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": "Hongli Yu,Tinghong Chen,Jiangtao Feng,Jiangjie Chen,Weinan Dai,Qiying Yu,Ya-Qin Zhang,Wei-Ying Ma,Jingjing Liu,Mingxuan Wang,Hao Zhou", "background": "尽管通过长度外推和高效注意及记忆模块的进步，能够在保持性能的情况下处理无限长度的文档，但使用线性复杂度处理长文本任务仍然是一个难题。现有方法在长文本处理中仍存在局限性，特别是在长文本上下文处理和外推能力方面。本文直接从端到端优化长文本任务，并引入了一种名为MemAgent的新代理工作流，该工作流分段读取文本并使用覆盖策略更新记忆。同时，为DAPO算法扩展了多会话独立上下文来辅助训练，证明了MemAgent在长上下文处理能力上的优越性，在8K上下文能够外推到3.5M问答任务，性能下降小于5%，并在512K RULER测试中达到了95%以上的性能。", "innovation": "直接从端到端优化长文本任务，引入MemAgent代理工作流，分段读取文本并使用覆盖策略更新记忆；扩展DAPO算法以通过多会话独立上下文生成辅助训练；展示了MemAgent在长文本处理中的出色外推能力，保持较低的性能损失，并在大规模测试中取得良好结果。", "conclusion": "MemAgent能够高效地处理长文本，解决了在长文本上下文处理和外推时的性能问题，为长文本处理提供了新的解决方案，在实际应用中显示出了潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02275", "html_url": "https://arxiv.org/abs/2507.02275", "title": "结构之于常态：噪声对无结构依赖估计的影响", "title_en": "It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation", "authors": "Jikai Jin,Lester Mackey,Vasilis Syrgkanis", "background": "结构无感知因果推断研究了在黑盒机器学习估计协变量影响（如混杂因素对治疗和结果的影响）的前提下，如何最好地估计治疗效应。该研究发现，答案在治疗噪声分布方面表现为格外复杂的形式。通过部分线性模型，论文分析了高阶稳健结构无感知估计方法的适用性和必要性，特别是在治疗噪声独立且非高斯分布的情况下，现有的双重机器学习（DML）估计方法并不是最优选择。", "innovation": "论文首先证明了在高斯治疗噪声下，广泛采用的双重机器学习估计方法是最佳的，这解决了早期研究中的开放性问题。对于独立且非高斯分布的治疗噪声，论文构造了新的高阶稳健估计方法（ACE），这些方法使用结构无感知累积量估计器来实现当高阶治疗累积量非零时，对噪声误差的第r阶鲁棒性。此外，论文还提供了二分类治疗情况下部分线性模型下的新型鲁棒最小最大保证。", "conclusion": "通过合成需求估计实验，研究证明了高阶稳健估计器的实用益处。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02199", "html_url": "https://arxiv.org/abs/2507.02199", "title": "潜藏的推理链？深度递归变压器的解码", "title_en": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "authors": "Wenquan Lu,Yuechuan Yang,Kyle Lee,Yanshu Li,Enqi Liu", "background": "变换器基语言模型通过推理链（CoT）推理技术在复杂数学和多步骤规划方面表现出色。然而，在标准的解码器架构中，这些推理步骤以自然语言的形式外化出来，提高了可解释性但减低了效率。为了捕捉难以用语言表达的推理结构，许多研究探索了递归架构，希望能够将推理内化至潜在空间，支持潜在的CoT。然而，现有研究在这一领域的成果仍然有限，特别是在深度递归变换器Huginn-3.5B中，该模型在推理时不增加参数量并重复利用层以推理时间。", "innovation": "本研究通过Huginn-3.5B模型以及一套探针技术，探索了深度递归变换器中是否存在可解释的潜在CoT结构，结果表现出微弱的解释能力并且重复深度增加对改进推理的贡献也很有限，表明这些递归架构在解释深层推理方面的进展仍需进一步探索和改进。", "conclusion": "深度递归变换器Huginn-3.5B在算术任务上的内部分行为探针技术所追踪显示，潜在CoT的解释性有限。递归块之间的探针不一致性显著，隐藏状态的解释性很大程度上依赖于层索引和解码方法。增加递归深度仅带来边际收益，远不及明示推理步骤的模型效果。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02282", "html_url": "https://arxiv.org/abs/2507.02282", "title": "音乐推荐中的内容过滤方法：一项综述", "title_en": "Content filtering methods for music recommendation: A review", "authors": "Terence Zeng,Abhishek K. Umrawal", "background": "推荐系统已成为现代音乐流媒体平台的关键组成部分，影响用户发现及互动的歌曲。传统的协同过滤方法基于具有相似听歌模式的用户进行推荐，但在用户交互稀少的媒体如音乐中效果不佳。因此，音乐流媒体服务中的用户通常不会收听大量歌曲，从而带来了挑战。本文回顾了目前研究现状，在协同过滤方法中减少偏差方面强调内容过滤的作用。讨论了歌曲分类方法，包括使用大型语言模型（LLMs）进行歌词分析和音频信号处理技术，并分析了不同分析方法之间的潜在冲突及其解决途径.", "innovation": "介绍了使用大型语言模型进行歌词分析以及音频信号处理技术在内的多种歌曲分类方法，探讨了这些方法在减少推荐系统中的偏差方面的作用及它们之间的潜在冲突，提出了解决这些差异的可能性.", "conclusion": "文章总结了当前研究的状态，指出了内容过滤已经在降低成本导致的偏差方面扮演的重要角色，并提出了未来解决不同分析方法之间冲突的方向，强调了在推荐系统中平衡这些不同方法的重要性."}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02302", "html_url": "https://arxiv.org/abs/2507.02302", "title": "DoMIX: 一种高效利用领域知识的微调框架", "title_en": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning", "authors": "Dohoon Kim,Donghun Kang,Taesup Moon", "background": "域适应预训练（DAP）因其在微调预训练模型中的有效性而引起了广泛关注。基于此背景，连续DAP已用于开发能够逐步纳入不同领域数据集的预训练模型。然而，现有的连续DAP方法存在以下局限性：(1) 训练过程中计算成本高且GPU内存耗用大；(2) 对增量数据顺序敏感；(3) 提供通用模型，这与DAP的本质相悖，即每个任务特定的需要定制模型。", "innovation": "本文提出了一种名为DoMIX的新方法，通过利用LoRA模块，一个代表性的参数高效微调（PEFT）方法，来解决以上挑战。该方法实现了高效且并行的域适应预训练，该预训练对领域顺序具有鲁棒性，并有效利用积累的知识为特定任务提供定制的预训练模型。此外，还证明了该方法可以扩展到标准的大语言模型（LLM）微调场景之外。", "conclusion": "通过DoMIX方法，我们能够有效地产生针对特定任务的定制化预训练模型，同时降低计算和内存成本，并提高模型对数据顺序的鲁棒性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02288", "html_url": "https://arxiv.org/abs/2507.02288", "title": "通过语言指导和表示对齐进行提示分解的领域泛化", "title_en": "Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization", "authors": "De Cheng,Zhipeng Xu,Xinyang Jiang,Dongsheng Li,Nannan Wang,Xinbo Gao", "background": "领域泛化（DG）旨在开发一种能有效应用于未见过的目标领域的通用模型。近年来，预训练视觉基础模型（VFMs），如CLIP，展示了显著提升深度学习模型泛化能力的潜力。尽管关于基于VFMs的领域提示调优的注意力日益增加，但设计能够解构跨不同领域不变特征的有效提示依然是一个关键挑战。本文提出了一种利用VFM可控和灵活的文本提示来解决这一挑战的新框架。该框架首先使用大型语言模型自动分离文本提示，然后通过分离的文本特征引导学习领域不变的视觉表示。然而，仅依赖于语言指导视觉特征分解有一定局限性，因为视觉特征有时过于复杂或微妙，难以通过描述性文本完全捕捉。因此，本文引入了Worst Explicit Representation Alignment（WERA），通过增加一组抽象提示来扩展文本引导的视觉提示，这些提示通过风格化图像增强提高源领域多样性，且对齐约束确保视觉表示在原始和增强分布之间保持一致性。", "innovation": "本文提出了一种新的框架，通过大型语言模型自动分解文本提示并学习由分离文本特征引导的领域不变视觉表示。此外，作者还引入了Worst Explicit Representation Alignment（WERA），通过增加一组抽象提示结合文本引导的视觉提示以增强源领域多样性，并确保视觉表示在原始和增强分布中保持一致。这项工作有效地解决了领域泛化中不变特征解构的挑战，且在多个广泛使用的数据集上表现优异，超越了现有最先进的方法。", "conclusion": "本文提出的方法在多个主流的领域泛化数据集上表现出色，优于现有最先进的方法，为领域泛化的深入研究提供了新的方向和思路。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02391", "html_url": "https://arxiv.org/abs/2507.02391", "title": "基于后验转换建模的无监督扩散信号增强", "title_en": "Posterior Transition Modeling for Unsupervised Diffusion-Based Speech Enhancement", "authors": "Mostafa Sadeghi(MULTISPEECH),Jean-Eudes Ayilo(MULTISPEECH),Romain Serizel(MULTISPEECH),Xavier Alameda-Pineda(ROBOTLEARN)", "background": "现有无监督语音增强方法通过使用噪声语音并通过近似的噪声扰动似然分数与无条件得分进行折中，来引导反向扩散过程。这种方法通常需要调谐超参数。在此之前的工作中，研究人员探索了使用扩散模型作为清晰语音的表达生成先验，以实现语音增强的目标。", "innovation": "本文提出两种新的算法，直接建模扩散状态的条件反向转换分布。第一种方法以一种严谨的方式将扩散先验与观测模型整合，去除超参数调谐的需要。第二种方法定义了在噪声语音上的扩散过程，提供了完全可操作且精确的概率分数。", "conclusion": "在WSJ0-QUT和VoiceBank-DEMAND数据集上的实验表明，与有监督和无监督的基准方法相比，该方法可以实现更好的增强指标，并具有更好的域适应性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02377", "html_url": "https://arxiv.org/abs/2507.02377", "title": "稀疏高斯过程：结构化近似与回顾性的Power-EP", "title_en": "Sparse Gaussian Processes: Structured Approximations and Power-EP Revisited", "authors": "Thang D. Bui,Michalis K. Titsias", "background": "基于诱导点的稀疏高斯过程已成为扩展高斯过程模型的标准工具。最近的研究表明，通过在条件后验密度中引入对角缩放矩阵，可以改进这些方法。本文在此基础上，提出了一个使用块对角结构的缩放矩阵的扩展，以证明它能够紧缩变分下界。此外，本文重新审视了基于权力期望传播（PEP）的稀疏高斯过程的统一框架，展示了它如何利用和受益于新的结构化近似后验。", "innovation": "提出了块对角结构的缩放矩阵来优化子桂过程的参数估计方法；重新审视了基于PEP的稀疏高斯过程统一框架，并展示了如何使用新的结构化近似后验；通过广泛的回归实验，证明了新提出的块对角近似在性能上优于现有对角近似，同时保持相近的计算成本；展示了基于幂超参数设置的新PEP框架具有竞争力，为 Practitioner 提供了与标准变分方法的灵活替代方案。", "conclusion": "所提出的块对角近似在各种幂超参数设置下提供了与标准变分方法相当甚至更好的性能，同时保持了相似的计算成本。新的PEP框架与结构化后验提供了 Practitioner 灵活的选择，避免了标准方法的限制。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02328", "html_url": "https://arxiv.org/abs/2507.02328", "title": "使用一次采样骨架图进行路径规划", "title_en": "Path Planning using a One-shot-sampling Skeleton Map", "authors": "Gabriel O. Flores-Aquino,Octavio Gutierrez-Frias,Juan Irving Vasquez", "background": "路径规划算法旨在计算无碰撞路径，许多研究集中于寻找最优距离路径。然而，对于某些应用来说，平衡响应时间、路径的安全性和路径长度更为合适。为此，骨架图在基于图的方案中是非常有用的工具，因为它提供了自由配置空间的内在表示。然而，现有的骨架化算法非常耗资源，主要面向图像处理任务。", "innovation": "本文提出了一种高效路径规划方法，通过结合基于U-Net架构的Deep Denoising Auto-Encoder (DDAE)计算导航地图的骨架化版本（称为SkelUnet），并利用一次采样（OSS）方法实现对整个工作空间的探索，而非传统的迭代过程或概率采样过程。该方法在12,500个二维迷宫地图的训练集上进行训练和测试，并在使用250个未见过的迷宫地图的模拟环境中对无人飞行器进行了评估，使用多种导航指标来量化计算路径的可导航性。结果显示，使用SkelUnet构造的路网具有显著优势，包括连接所有自由工作的区域、提供更安全的路径以及减少处理时间。", "conclusion": "该方法特别适用于结构化环境中移动服务机器人的路径规划，因为SkelUnet能够提供安全路径、全面连接工作空间并显著缩短处理时间。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02403", "html_url": "https://arxiv.org/abs/2507.02403", "title": "非城市环境中使用自我监督学习进行野生动物目标再识别", "title_en": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings", "authors": "Mufhumudzi Muthivhi,Terence L. van Zyl", "background": "野生动物再识别旨在匹配不同观测中同一种类的个体。当前的SOTA模型依赖类别标签来训练监督模型以进行个体分类。这种依赖注释数据的方法推动了大型野生动物数据集的大量创建。本研究探讨了自我监督学习（SSL）在野生动物再识别中的应用。研究直接从摄像陷阱数据中的时间图像对自动提取个体的两种不同视图，无需监督。该图像对训练自监督模型，可以从潜在无限量的视频数据流中学习。评估结果显示，在开放世界场景和各种野生动物下游任务中，自监督模型在缺乏数据的情况下更加稳健，自我监督特征在所有下游任务中均优于监督特征", "innovation": "本研究创新性地提出了一种无需监督的自我监督学习方法，用于从摄像陷阱数据中自动提取个体的两种不同视图，从而实现野生动物再识别。这种方法无需人类标注数据，适用于非城市环境中的多样场景，展示了在缺乏数据情况下更高的鲁棒性和更好的性能", "conclusion": "实验结果表明，即使数据有限，自监督模型也表现出更高的鲁棒性，并且其学习的表示在所有下游任务中均优于监督学习特征。该研究为野生动物个体识别提供了一种新的、有效的方法，并且证明了自我监督学习在野生动物保护中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02407", "html_url": "https://arxiv.org/abs/2507.02407", "title": "跨领域数据集评估阿甘语ASR模型：性能、可扩展性和适应性比较评估", "title_en": "Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability", "authors": "Mark Atta Mensah,Isaac Wiafe,Akon Ekpezu,Justice Kwame Appati,Jamal-Deen Abdulai,Akosua Nyarkoa Wiafe-Akenten,Frank Ernest Yeboah,Gifty Odame", "background": "大多数现有的自动语音识别（ASR）研究使用领域内数据集评估模型，但很少关注模型在不同语音环境下的泛化能力。本文通过使用四种阿甘语语音语料库对七个基于变换器架构的阿甘语ASR模型进行基准测试，评估其在不同领域的性能，其中包含文化相关的图像描述、非正式对话、圣经经文朗读和自发的金融对话等各类领域", "innovation": "本文填补了现有研究中ASR模型跨不同语音环境泛化能力评估的空白，通过比较Whisper和Wav2Vec2两个架构在未匹配场景下的表现，揭示两者在鲁棒性上的差异", "conclusion": "研究结果表明，模型在训练领域内表现出色，但在不匹配场景下的准确率显著下降。Whisper架构的微调模型转换为更流畅但可能存在误导的转录错误，而Wav2Vec2架构在遇到不熟悉输入时则产生更明显但难以解释的输出。在低资源语言（LRL）应用中选择架构时，应权衡读性和透明性之间的权衡，并强调需要有针对性的领域适应技术、自适应路由策略和多语种训练框架"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02399", "html_url": "https://arxiv.org/abs/2507.02399", "title": "TABNet: 一种基于边界感知伪标签的三重增强自恢复框架以进行医学图像分割", "title_en": "TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation", "authors": "Peilin Zhang,Shaouxan Wua,Jun Feng,Zhuo Jin,Zhizezhang Gao,Jingkun Chen,Yaqiong Xing,Xiao Zhang", "background": "医学图像分割是临床应用中的一项核心任务。然而，获取大规模、完全标注的医学图像数据集既耗时又昂贵。标记注释作为一种稀疏标注的形式，提供了医学图像分割的有效且经济的替代方案。但是，稀疏标记注释限制了目标区域的特征学习，并且缺乏足够的边界监督，这为训练分割网络带来了巨大挑战。", "innovation": "本文提出了一个名为TAB Net的新型弱监督医学图像分割框架，该框架由两个关键组件组成：三重增强自恢复（TAS）模块和边界感知伪标签监督（BAP）模块。TAS模块通过三种互补的增强策略增强了特征学习：强度变换使模型对纹理和对比度变化更加敏感，切出（Cutout）迫使网络通过隐藏关键区域捕捉局部解剖结构，而镶嵌增强（Jigsaw augmentation）通过破坏空间连续性增强全局解剖布局的建模。通过引导网络从多样化的增强输入中恢复完整的掩码，TAS促进了在稀疏监督下的医学图像语义理解。BAP模块通过融合双分支预测为细粒度轮廓细化引入边界感知损失，提高了伪监督的准确性并增强了边界建模。实验结果表明，TAB Net在ACDC和MSCMR seg两个公开数据集上显著优于现有的基于稀疏标记的弱监督分割方法，并达到了与全监督方法相当的性能。", "conclusion": "我们的研究提出了一个新颖的弱监督医学图像分割框架TAB Net，该框架在稀疏标注下能够显著提升分割性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02416", "html_url": "https://arxiv.org/abs/2507.02416", "title": "使用深度学习框架确定结构裂缝", "title_en": "Determination Of Structural Cracks Using Deep Learning Frameworks", "authors": "Subhasis Dasgupta,Jaydip Sen,Tuhina Halder", "background": "结构裂缝检测是关乎公共安全的重要任务，因为它有助于预防可能威胁生命的潜在结构故障。手工检测由不经验丰富的人员进行时，过程会很缓慢、不一致且容易出错，这些因素可能会损害评估的可靠性。现有研究通过引入一种新型的深度学习架构来应对这些挑战，旨在提升结构裂缝检测的准确性和效率。研究中使用了不同配置的残差U-Net模型，这些模型因其在捕捉细节点方面表现出的鲁棒性，进一步与一个包含卷积块的元模型结合起来。这种独特组合旨在超越单一模型所能达到的预测效率。该组合模型的表现与诸如SegNet和传统U-Net等稳健架构进行了评估。结果显示，残差U-Net模型比前辈模型表现更好，尤其是在低分辨率图像方面。此外，组合模型的表现超过了单一模型，证明它是最有效的。评估结果基于交并比(IoU)和DICE系数指标。组合模型获得的分数最高，表明其更优越的准确性。这一进展为结构缺陷监测中的更可靠自动化系统铺平了道路", "innovation": "研究通过引入残差U-Net模型的设计，并将其与包含卷积块的元模型结合成一个组合模型，提升了裂缝检测的准确性和效率。研究表明，此组合模型在低分辨率图像上的表现优于SegNet和传统U-Net，且其整体性能表现出色，证明其为主要有效的解决方案", "conclusion": "研究成果表明，通过使用深度学习框架中的残差U-Net模型及其组合方式，在结构裂缝检测中可以实现更可靠和高效的自动检测系统，这对提高公共安全具有重要意义"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02554", "html_url": "https://arxiv.org/abs/2507.02554", "title": "AI Research Agents for Machine Learning: 搜索、探索与泛化在MLE-bench中的应用", "title_en": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "authors": "Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Rishi Hazra,Nicolas Baldwin,Alexis Audran-Reiss,Michael Kuchnik,Despoina Magka,Minqi Jiang,Alisia Maria Lupidi,Andrei Lupu,Roberta Raileanu,Kelvin Niu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Shagun Sodhani,Alexander H. Miller,Abhishek Charnalia,Derek Dunfield,Carole-Jean Wu,Pontus Stenetorp,Nicola Cancedda,Jakob Nicolaus Foerster,Yoram Bachrach", "background": "AI研究代理展现出通过自动化机器学习模型的设计、实现和训练加速科学进步的巨大潜力。目前聚焦于提高代理在MLE-bench的性能，这是一个具有挑战性的基准，参赛者在Kaggle竞赛中解决实际的机器学习问题。研究方法将AI研究代理视为在候选解空间中导航的搜索策略，通过迭代地使用操作符修改这些解决方案。", "innovation": "通过设计并系统地改变不同操作符集合和搜索策略（贪心、MCTS、演化），证明了它们之间的互动是实现高性能的关键。最佳的搜索策略和操作符集组合在MLE-bench lite中达到了最先进的结果，将获得Kaggle奖牌的成功率从39.6%提高到47.7%。研究强调了同时考虑搜索策略、操作符设计和评估方法对于推进自动化机器学习的重要性.", "conclusion": "研究表明，共同考虑搜索策略、操作符设计和评估方法对于提高AI代理在解决实际机器学习问题上的表现至关重要。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02264", "html_url": "https://arxiv.org/abs/2507.02264", "title": "NLP4Neuro：基于序列到序列学习的大脑群体解码", "title_en": "NLP4Neuro: Sequence-to-sequence learning for neural population decoding", "authors": "Jacob J. Morra,Kaitlyn E. Fouke,Kexin Hang,Zichen He,Owen Traubert,Timothy W. Dunn,Eva A. Naumann", "background": "解析动物行为源自神经活动的基础问题是神经科学的核心目标。然而，行为的计算在数千个跨整个大脑的神经元网络中展开，这给研究大规模、高度连接的哺乳动物大脑中神经作用和计算机制带来了挑战。现代大型语言模型（LLMs）的骨干部分——变压器，在解码小神经群体方面变得非常强大。虽然这些现代LLMs得益于广泛的预训练，并且已经显示出序列到序列的学习能力，可以在新的任务和数据模态上泛化，但它们可能还为从大规模、全脑活动记录中进行神经解码提供优势。通过NLP4Neuro，我们发现预训练权重从文本自然语言数据中学习出的LLMs在神经解码中表现出色。我们使用NLP4Neuro对暴露在视觉运动刺激下的幼体斑马鱼的同步钙成像和行为记录进行了测试。", "innovation": "我们提出了一个名为NLP4Neuro的系统性评估框架，用于从大脑群体中解码行为。通过NLP4Neuro，我们发现具有预训练文本自然语言数据权重的LLMs在神经解码中表现更好。我们还发现了一种最新的专家混合模型——DeepSeek Coder-7b，显著提高了行为解码的准确性，能够预测长时间尺度的尾巴运动，并提供了解剖结构上一致、高度可解释的神经元重要性读出。NLP4Neuro展示了LLMs在进行整个大脑神经回路分割方面的高度能力。", "conclusion": "NLP4Neuro证明了LLMs在大脑群体解码中的高能力，它们可以作为一个强大的工具，帮助科学家们理解并解剖大规模神经回路。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02593", "html_url": "https://arxiv.org/abs/2507.02593", "title": "在(人类)标签变异下重探主动学习", "title_en": "Revisiting Active Learning under (Human) Label Variation", "authors": "Cornelia Gruber,Helen Alber,Bernd Bischl,Göran Kauermann,Barbara Plank,Matthias Aßenmacher", "background": "高质量标注数据是实际监督学习中的一个限制因素。标签变异（LV），即同一实例不同标注，尽管在自然语言处理中很常见，但标记框架仍假设单一真实值。这忽略了人类标签变异（HLV），即不同标注可能合理不同的现象。此外，主动学习（AL）作为一种优化有限标注预算的方法，常假设简化条件，这些假设在考虑HLV时通常不成立。该论文探讨了关于真实性和标签性质的基本假设，指出了将观察到的LV分解为信号（如HLV）和噪声（如标注错误）的必要性。", "innovation": "论文提出了一种概念框架，将HLV整合到整个AL循环中，包括实例选择、标注者选择和标签表示。此外，还讨论了将大语言模型（LLM）作为标注者的技术。目的是为HLV感知的主动学习奠定概念基础，更好地反映实际标注的复杂性。", "conclusion": "该研究强调了将标签变异分解为信号和噪声的重要性，并为将HLV整合到主动学习的过程中提供了一种概念框架。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02443", "html_url": "https://arxiv.org/abs/2507.02443", "title": "在FPGA可编程逻辑中加速葡萄检测的人工神经网络", "title_en": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic", "authors": "Sandro Costa Magalhães,Marco Almeida,Filipe Neves dos Santos,António Paulo Moreira,Jorge Dias", "background": "机器人在搬运过程中通常会减速以检测物体，同时，为了跟踪检测算法的速度，机器人的摄像头通常以低帧率配置。这会限制机器人执行任务和探索的能力，增加任务执行时间。AMD开发的Vitis-AI框架可以将检测算法部署到FPGA中，但并未完全利用FPGA的PL（可编程逻辑）资源。因此，在本研究中，我们使用FINN架构将MobileNet v1（4比特量化）、CNV（2比特量化）和CNV（1比特量化，BNN）三种ANN部署在FPGA的PL中，并使用RG2C数据集进行训练。", "innovation": "我们利用FINN架构在FPGA的PL中部署了三种不同量化级别的神经网络，并证明了FPGA可以加速人工神经网络，使其适用于注意力机制。MobileNet v1在RG2C数据集上达到了98%的成功率和6611 FPS的推理速度，显示了显著的性能提升和资源利用率。", "conclusion": "我们证明了可以使用FPGA加速人工神经网络，并使其适应注意力机制。这为机器人在搬运过程中实时检测物体提供了可能，减少了任务执行时间，提高了系统的灵活性和效率。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02506", "html_url": "https://arxiv.org/abs/2507.02506", "title": "IndianBailJudgments-1200: 印度保释命令的多属性数据集，用于印度保释命令的法律自然语言处理", "title_en": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders", "authors": "Sneha Deshmukh,Prathmesh Kamble", "background": "在印度这样的地区，法律自然语言处理（Legal NLP）的发展受限于结构化数据集的稀缺性。缺乏足够的数据资源导致了法律NLP技术的发展滞后。因此，针对特定法律领域的高质量标注数据集的研究成为推动法律NLP进展的关键因素之一。", "innovation": "本文介绍了名为IndianBailJudgments-1200的新基准数据集，包含了1200份印度法院的保释判决，这些判决被多属性标注，涵盖了保释结果、IPC（印度刑事程序法）条款、罪行类型和法律推理等20多种属性。标注过程采用了由定制指令引导的GPT-4o管道，并经过了一致性验证。这项资源支持多种法律NLP任务，是专门针对印度保释法律原则的第一个公开可用的数据集，具有广泛的应用价值。", "conclusion": "该研究通过提供印度保释相关的高质量标注数据集，显著填补了法律NLP领域数据资源的空白，推动了该领域的技术进步和实际应用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02494", "html_url": "https://arxiv.org/abs/2507.02494", "title": "MC-INR：使用元学习和聚类隐式神经表示高效编码多元科学模拟数据", "title_en": "MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations", "authors": "Hyunsoo Son,Jeonghyun Noh,Suemin Jeon,Chaoli Wang,Won-Ki Jeong", "background": "隐式神经表示（INRs）被广泛用于以连续函数的形式编码数据，从而能够用较少的内存来可视化大规模的多元科学模拟数据。然而，现有的基于INR的方法面临三个主要限制：(1) 对复杂结构的表示不够灵活；(2) 主要关注单一变量数据；(3) 具备结构化网格的依赖性。当应用于复杂的现实世界数据集时，其性能会下降。", "innovation": "本文提出了一种新颖的基于神经网络的框架MC-INR，它可以处理无结构网格上的多元数据。该框架结合了元学习和聚类技术，以灵活地表示复杂的结构。为了进一步提高性能，引入了一种基于残差的动态重新聚类机制，根据局部误差适应性地重新分割聚类。还提出了一种分支层，以便于同时通过独立的分支利用多元数据。实验结果表明，MC-INR在科学数据编码任务上优于现有方法。", "conclusion": "MC-INR在科学数据编码任务中表现出了优越性，特别是对于复杂且无结构网格上的多元数据。它通过结合元学习和聚类技术提供了对复杂结构的灵活表示，并通过动态重新聚类机制和分支层优化了性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02681", "html_url": "https://arxiv.org/abs/2507.02681", "title": "从自愿测验检测失联：在高等教育远程教育中的可解释机器学习方法", "title_en": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education", "authors": "Behnam Parsaeifard,Christof Imhof,Tansu Pancar,Ioan-Sorin Comsa,Martin Hlosta,Nicole Bergamin,Per Bergamin", "background": "学生在学习过程中失去参与会使他们面临长期的负面后果，如辍学。对于远程教育中的学生而言，这一点尤为重要。该项目关注的是通过观察不同在线课程中非强制性练习的参与度来衡量远程教育中的学生失联水平。在本研究中，通过1个学年4学期、42门课程的教学管理系统Moodle数据分析了学生的失联情况。", "innovation": "研究创新之处在于开发了一种可解释的机器学习框架，能够通过分析学生在Moodle中的日志数据来检测他们的失联情况，并且使用SHAP方法使Prediction更容易理解。实验结果显示91%的正确预测准确率，其中85%的失联学生被正确检测出来。此外，该研究成果还讨论了如何利用这些预测结果进行及时干预，以减少自愿任务中的失联情况，从而提升在线学习的成效。", "conclusion": "研究最终建立了可解释的机器学习框架，实现了91%的检测精度，并提出了有效干预策略，为减少远程教育中学生的失联现象提供了新的方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02606", "html_url": "https://arxiv.org/abs/2507.02606", "title": "De-AntiFake：重新思考对抗语音克隆攻击的保护性扰动", "title_en": "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks", "authors": "Wei Fan,Kejiang Chen,Chang Liu,Weiming Zhang,Nenghai Yu", "background": "语音生成模型的迅速发展加剧了与语音克隆（VC）相关的隐私和安全问题。近期研究探讨了通过引入对抗性扰动来阻止未经授权的语音克隆（VC）。然而，有决心的攻击者可以抵消这些防护性扰动，并成功执行VC。本研究通过在包含扰动净化的现实威胁模型下系统评估这些防护性扰动，首次对VC测试。研究发现，现有净化方法能够中和大部分防护性扰动，但它们仍在VC模型特征空间中造成畸变，破坏了VC性能。从这个角度来看，我们提出了一种新型的两阶段净化方法：（1）净化受扰的语音；（2）利用音素指导进一步调整，使其符合干净语音分布。实验结果表明，我们的方法在抵御VC防御方面优于现有最先进的净化方法。本研究揭示了基于对抗性扰动的VC防御的局限性，并强调了需要更加稳固的解决方案来应对VC带来的安全和隐私风险。相关代码和音频样本可在指定URL获取。", "innovation": "提出了一种新型的两阶段净化方法：（1）净化受扰的语音；（2）利用音素指导进一步调整，使其符合干净语音分布。该方法在抵御VC防御方面优于现有最先进的净化方法。", "conclusion": "揭示了基于对抗性扰动的VC防御的局限性，并强调了需要更加稳固的解决方案来应对VC带来的安全和隐私风险。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02686", "html_url": "https://arxiv.org/abs/2507.02686", "title": "通过展开和蒸馏学习多步后验采样器", "title_en": "Learning few-step posterior samplers by unfolding and distillation of diffusion models", "authors": "Charlesquin Kemajou Mbakam,Jonathan Spence,Marcelo Pereyra", "background": "扩散模型（DMs）已成为贝叶斯计算成像中的强图像先验。已有两种主要策略被提出以利用DMs：Plug-and-Play方法，这是一种零样本且高度灵活的方法，但依赖于近似；以及专门的条件DMs，这种模型通过监督训练可以实现更高的准确性和更快的推理速度，适用于特定任务。该论文引入了一种创新的框架，利用深度展开和模型蒸馏将DM图像先验转化为少量步骤的条件模型以便后验采样。这一框架的关键创新在于将马尔可夫链蒙特卡罗（MCMC）算法中的朗格文采样器（LATINO）进行展开，这是首次将深度展开应用于蒙特卡罗采样方案。", "innovation": "首次将深度展开技术应用于蒙特卡罗采样方案；将朗格文采样器（LATINO）进行展开，作为深度展开方法在蒙特卡罗采样领域的首个实例；通过深入和蒸馏技术将DM图像先验转化为少量步骤的条件模型，从而实现高效和准确的后验采样。", "conclusion": "通过大量实验和与当前领先方法的比较，展示了所提展开和蒸馏的采样器实现了卓越的准确性和计算效率，并保持了适应前向模型变化的灵活性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02607", "html_url": "https://arxiv.org/abs/2507.02607", "title": "缓解攻击数据稀缺性： SCANIA 提升车内网络安全措施的经验", "title_en": "Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures", "authors": "Frida Sundfeldt,Bianca Widstam,Mahshid Helali Moghadam,Kuo-Yun Liang,Anders Vesterberg", "background": "联网车辆的数字化演变以及随之而来的一系列安全风险突显了实施车内网络安全措施的迫切需求，例如入侵检测和响应系统。随着攻击场景的持续演进，需要更加灵活的检测机制来发现不断变化、未知且复杂的威胁。机器学习驱动的方法可帮助应对这一挑战，但实际攻击场景的数据获取受到安全性、成本和伦理等方面的限制，从而导致此类数据的稀缺。鉴于此，该论文提出了一种上下文感知的攻击数据生成器，用于生成各类攻击输入及其对应于控制器局域网（CAN）日志，这些日志涵盖了包括拒绝服务（DoS）、模糊攻击、欺骗攻击、断言攻击和重放攻击等多种攻击类型。通过参数化的攻击模型结合CAN消息解码和攻击强度调整，使得生成的攻击场景与实际情况有很高的相似度，增强了变化性。在入侵检测系统（IDS）案例研究中评估生成的攻击数据的实用性，通过生成的数据训练和评估两个深度神经网络IDS模型，展示了该方法的效率和可扩展性，同时也验证了生成数据的一致性和有效性。此外，该研究还探讨了数据与真实场景相符度的影响因素，提供了在实际应用中的见解.", "innovation": "提出了一个上下文感知的攻击数据生成器，该生成器通过参数化的攻击模型、CAN消息解码和攻击强度调整，生成不同类型的攻击输入及其对应的CAN日志。这种方法不仅提高了生成数据的实用性和仿真度，还确保了数据覆盖了一定范围的攻击场景，有助于提升入侵检测系统的检测和分类能力.", "conclusion": "本研究通过一个上下文感知的攻击数据生成器有效缓解了攻击数据的稀缺性问题，生成的数据在实际入侵检测场景中表现出较高的仿真度和一致性，验证了该方法的有效性和实际应用价值。同时，研究还揭示了影响生成数据真实度的因素，并提供了其应用方面的宝贵见解。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02773", "html_url": "https://arxiv.org/abs/2507.02773", "title": "KERAP：使用多智能体大规模语言模型进行准确的零样本诊断预测的知识增强推理方法", "title_en": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs", "authors": "Yuzhang Xie,Hejie Cui,Ziyang Zhang,Jiaying Lu,Kai Shu,Fadi Nahab,Xiao Hu,Carl Yang", "background": "医学诊断预测在疾病检测和个性化医疗中起着关键作用。尽管机器学习模型已被广泛应用于此任务，但它们依赖于监督训练，这限制了它们在未见过的情况下的泛化能力，尤其是在获取大量标注数据的成本很高的情况下。大型语言模型（LLMs）因其语言能力和生物医学知识，在诊断预测方面显示出潜力，但这些模型经常出现虚构情况，缺乏结构化的医疗推理，并产生无用的输出。", "innovation": "我们提出了基于知识图（KG）增强推理的多代理大规模语言模型（LLMs），名为KERAP，通过改进LLM基础的诊断预测，提出了一种多代理架构。该框架包括用于属性映射的连接代理、用于结构化知识提取的检索代理，以及迭代改进诊断预测的预测代理。实验结果显示，KERAP提高了诊断的可靠性，提供了一种可扩展且可解释的零样本医疗诊断预测解决方案。", "conclusion": "实验结果表明，KERAP能够有效地提高诊断预测的可靠性，提供了一种可扩展且可解释的零样本医疗诊断预测解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02726", "html_url": "https://arxiv.org/abs/2507.02726", "title": "Bourbaki: 自生成和目标导向的MDP在定理证明中的应用", "title_en": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving", "authors": "Matthieu Zimmer,Xiaotong Ji,Rasul Tutunov,Anthony Bordg,Jun Wang,Haitham Bou Ammar", "background": "大语言模型（LLMs）在逻辑受限环境下的自动定理证明（ATP）中进行推理仍然是一个具有挑战性的任务。这主要是由于奖励稀疏和证明规模庞大。PutnamBench这一基准测试中包含需要复杂多步推理的大学水平问题，进一步加剧了这些挑战。因此，研究人员引入了一种新的框架，即自生成目标导向的MDP（sG-MDP），以解决这些问题，使得模型能够根据证明状态生成和追求子目标，从而使得问题更易于搜索。", "innovation": "研究团队提出了自生成目标导向的MDP（sG-MDP）框架，该框架中代理根据证明状态生成和追求子目标，并通过类似蒙特卡洛树搜索（MCTS）的算法解决sG-MDP问题，该方法实例化为Bourbaki (7B)模块化系统，可以整合多个7B大语言模型来生成子目标和策略合成。在PutnamBench基准测试中，该系统解决了26个问题，达到了规模模型的新最先进的结果。", "conclusion": "Bourbaki (7B) 在定理证明方面取得了显著成果，通过自生成目标导向的MDP框架结合MCTS-like算法，展示了大语言模型在复杂多步推理问题上的新潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02737", "html_url": "https://arxiv.org/abs/2507.02737", "title": "前沿大语言模型早期具备隐写术能力的迹象", "title_en": "Early Signs of Steganographic Capabilities in Frontier LLMs", "authors": "Artur Zolkowski,Kei Nishimura-Gasparian,Robert McCarthy,Roland S. Zimmermann,David Lindner", "background": "监测大型语言模型（LLM）的输出对于降低误用和偏离的风险至关重要。然而，LLM们可以通过隐写术来规避监测，即在看似无害的生成中隐藏信息。这项研究评估了前沿LLM的隐写术能力，以更好地理解它们所构成的风险，并重点关注两类隐写术：传递编码信息和执行编码推理。研究表明，在标准条件下，现有的模型无法在其输出中编码短消息而不被监测工具察觉。但如果给它们额外的条件，如使用未监测的记事本和协调使用的编码方案，它们可以成功地编码信息。研究还发现，模型在简单状态跟踪问题上可以执行基本的编码推理，但很难在给定的任务中微妙地隐匿其推理过程以迷惑监控工具。", "innovation": "研究评估了前沿大语言模型的隐写术能力，并区分了传递编码信息和执行编码推理。研究发现，尽管这些模型展示出初期的隐写术能力，但在标准条件下很难隐蔽信息，除非给它们额外的条件，否则难以成功隐蔽推理过程。", "conclusion": "目前，前端大语言模型展示了早期的隐写术能力，尽管这些能力尚未能够绕过精心设计的监控工具，但未来可能发生变化。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02748", "html_url": "https://arxiv.org/abs/2507.02748", "title": "线性注意力与全局上下文：用于视觉和物理领域的多极注意力机制", "title_en": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics", "authors": "Alex Colagrande,Paul Caillon,Eva Feillet,Alexandre Allauzen", "background": " Transformers 在从图像分类到物理模拟的各种任务中已经成为事实上的标准。尽管它们在性能上表现出色，但标准 Transformers 在时间和内存方面的复杂性与输入长度成二次关系，使得它们在处理高分辨率输入时不可行。因此，提出了多种变体，大多数成功的变体依赖于像素化、下采样或粗化技术，但这些技术往往会损失小尺度的细节。\n", "innovation": " 本文提出了一种不同的方法，受最先进的 $n$-体数值模拟技术的启发，将注意力机制视为网格点之间的交互问题。介绍了一种名为 Multipole Attention Neural Operator (MANO) 的方法，它可以以基于距离的多尺度方式计算注意力，并在每个注意力头中保持全局感受野，从而实现与网格点数量线性的时间和内存复杂度。MANO 方法在图像分类和达西流动测试中表现出色，其运行时间和峰值内存使用量相比现有最优模型（如ViT 和 Swin Transformer）要小得多。\n", "conclusion": " MANO 取得了与现有最优模型可竞争的结果，同时大幅减少了运行时间和峰值内存使用量。代码已开源，确保了可复制性。\n"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02690", "html_url": "https://arxiv.org/abs/2507.02690", "title": "RLHGNN: 基于强化学习的异构图神经网络在业务流程中的下一项活动预测", "title_en": "RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes", "authors": "Jiaxing Wang,Yifeng Yu,Jiahan Song,Bin Cao,Jing Fan,Ji Zhang", "background": "在面向服务的架构（如微服务环境、分布式企业系统和云原生平台），活动预测对于优化业务流程是一项基本挑战，能够实现前瞻性的资源分配和动态服务组合。尽管序列方法很普及，但这些方法无法捕捉并行执行和条件依赖关系带来的非序列关系。虽然图方法能够保留结构性，但它们具有同质表示和静态结构，不分个体流程复杂性特征采用统一建模策略。为解决这些限制，我们提出了一种名为RLHGNN的新框架，该框架可以将事件日志转换为基于现有流程挖掘理论的异构过程图，具有三种不同边类型。该方法通过选择性组合这三种边来创建四种灵活的图结构，以适应不同的过程复杂性，采用标记为马尔可夫决策过程的强化学习自动确定每个特定流程实例的最佳图结构，并通过关系特定的聚合策略应用异构图卷积来有效预测下一项活动。这一适应性方法能够精确建模服务交互中的序列和非序列关系。在六个真实世界数据集上的全面评估表明，RLHGNN在预测性能上始终优于最先进的方法。此外，它能维持每预测约1毫秒的推理延迟，提供了一个实用的解决方案，适用于实时业务流程监控应用", "innovation": "我们提出了RLHGNN，一种新颖的框架，它将事件日志转换为基于现有流程挖掘理论的异构过程图，具有三种不同边类型。通过选择性组合这些边来创建四种灵活的图结构，以适应不同的过程复杂性。采用强化学习中的马尔可夫决策过程来自动确定每个特定流程实例的最佳图结构，并通过关系特定的聚合策略应用异构图卷积来有效预测下一项活动。这种适应性方法能够精确建模服务交互中的序列和非序列关系，且在六个真实世界数据集上的全面评估表明，RLHGNN在预测性能上始终优于最先进的方法，并能维持每预测约1毫秒的推理延迟，提供了一个实用的解决方案，适用于实时业务流程监控应用", "conclusion": "我们提出的RLHGNN框架，通过将事件日志转换为异构过程图，并利用强化学习和异构图卷积方法，成功解决了传统序列方法和图方法的局限性，解决了非序列关系的建模问题。我们的方法显著提高了预测性能，并且能够实时地进行预测，适合在业务流程中应用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02791", "html_url": "https://arxiv.org/abs/2507.02791", "title": "自驾驶深度非线性空间选择性滤波器用于在弱指导下高效提取移动讲话者", "title_en": "Self-Steering Deep Non-Linear Spatially Selective Filters for Efficient Extraction of Moving Speakers under Weak Guidance", "authors": "Jakob Kienegger,Alina Mannanova,Huajian Fang,Timo Gerkmann", "background": "现有研究表明，对于固定方向的讲话者，轻量级的深度非线性空间选择性滤波器架构能够实现优异的增强性能。但在动态场景中维持这种性能需要计算密集型的数据驱动跟踪算法来提供基于目标讲话者初始方向的精确空间导向。然而，这种额外的计算开销在资源受限场景诸如实时语音增强中是个难题。", "innovation": "本文提出了一种新的自驾驶策略，利用粒子滤波器替代计算密集型的跟踪算法，并引入时间反馈机制来利用空间选择性滤波器增强的语音信号来补偿粒子滤波器有限的建模能力。实验结果显示，这两种算法之间的自回归相互作用显著提高了跟踪准确性并增强了语音增强性能。", "conclusion": "在合成数据集上的评估表明，自回归交互显著提高了跟踪准确性并增强了语音增强性能。实世界录音的主观测试进一步证实了我们的自驱动管道作为首选方案的趋势，优于其他类似方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02771", "html_url": "https://arxiv.org/abs/2507.02771", "title": "基于运动接地智能", "title_en": "Grounding Intelligence in Movement", "authors": "Melanie Segado,Felipe Parodi,Jordan K. Matelsky,Michael L. Platt,Eva B. Dyer,Konrad P. Kording", "background": "最近的人工智能进展显著提高了我们对语言和视觉等高维数据建模的能力，但在处理生物系统中最基本的方面——运动方面仍然面临挑战。从神经科学、医学、机器人学到生态学，运动对于理解行为、预测意图、促进互动等方面都是不可或缺的。尽管它对我们智力的核心重要性，运动往往被当作次要处理的对象，而不是固有且结构化的模式。这反映了人类如何收集和建模运动数据时深刻的碎片化，常常被特定任务的目标和特定领域的假设所限制。然而，运动并非局限于特定领域，它反映了共享的物理约束、维形结构的保存以及跨物种和设定的目的动态。文章认为，运动应该被视为人工智能的主要建模目标，因为它内在地结构化且与身体和物理科学相关。这种结构便于解释和计算建模，比未处理的高维度感官输入更易于建模。从多样化的运动数据中学习和发展模型不仅将推动生成建模和控制的核心能力的进步，也将为理解和解释生物学和人工系统的行为提供共同的基础。运动不仅是结果，更是智能系统如何与世界互动之窗口", "innovation": "文章提出了将运动视为人工智能主要建模目标的观点。尽管运动数据往往因特定任务和领域的限制而被处理成碎片化，但运动实际上反映了许多共享的物理和生物学特性，具有潜在的更简单的表示形式，如姿态，使建模比原始高维感官输入更易解释和计算。这一观点为跨领域的智能研究提供了新的视角，尤其是通过聚焦于运动来促进不同系统间的学习和泛化能力。", "conclusion": "运动不仅是解释智能行为的结果，更是理解智能系统如何与世界交互的关键。跨智能体和跨领域的模型能够学会并泛化于不同运动数据中将推动生成建模、控制以及其他跨学科理解能力的进步。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02824", "html_url": "https://arxiv.org/abs/2507.02824", "title": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift", "title_en": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift", "authors": "Po-Heng Chou,Ching-Wen Chen,Wan-Jen Huang,Walid Saad,Yu Tsao,Ronald Y. Chang", "background": "该文研究了毫米波（mmWave）多输入多输出（MIMO）系统中，当直接通信路径受阻时，基于重构智能表面（RIS）的预编码设计方法，以最大化吞吐量。传统的连续相位搜索（ES）方法在查找最优码本时计算量大且耗时。因此，引入了基于置换离散傅里叶变换（DFT）向量并结合幅度响应进行码本设计的方法，但这种方法依然计算量大。为了解决这一问题，开发了一个训练好的深度神经网络（DNN）来加速码字选择过程。", "innovation": "提出了一种基于训练好的深度神经网络（DNN）的预编码设计方法，该方法不仅减少了计算复杂度，而且还能够快速选择码字，且在测试阶段即使用户与RIS之间的距离发生变化，也能保持接近最优的频谱效率。这种方法利用DNN加速了寻找最优码本的过程，为RIS辅助系统提供了新的解决方案。", "conclusion": "仿真结果显示，通过DNN进行预编码设计，在用户与RIS之间距离变化的情况下，仍然可以保持合理的频谱效率，这表明了DNN在RIS辅助系统中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02850", "html_url": "https://arxiv.org/abs/2507.02850", "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "title_en": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "authors": "Almog Hilel,Idan Shenfeld,Leshem Choshen,Jacob Andreas", "background": "这篇论文描述了一个在通过用户反馈训练的语言模型中存在的漏洞。攻击者仅需提供提示和对模型输出进行投票（点赞或点踩），就能持续改变模型的知识和行为。这种攻击利用了模型的偏好调优机制，使得模型在后续的响应中更可能产生攻击者注入的内容，即使没有恶意提示。\n", "innovation": "该研究提出了一种新的攻击机制，通过用户反馈对语言模型进行未经授权的知识注入。研究发现了语言模型偏好调优中的一个新特性，即即使是高度受限的偏好数据也能被用来精细控制模型的行为。此外，该研究扩展了对预训练数据污染及部署期提示注入的研究。\n", "conclusion": "研究展示了如何利用这种漏洞向模型注入新的事实性知识、修改代码生成模式引入可利用的安全漏洞，以及注入虚假金融新闻。研究结果不仅揭示了语言模型偏好调优的一个新特性，还提供了一种针对通过用户反馈训练的语言模型的新攻击方法。\n"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02822", "html_url": "https://arxiv.org/abs/2507.02822", "title": "SynapseRoute：双态大语言模型的自动路由切换框架", "title_en": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model", "authors": "Wencheng Zhang,Shiqin Qiao,Lingjie Luo,Yinfeng Li,Chuanyang Zheng,Qian Xu,Meng Li,Yong Gui,Yijun He,Jianing Qiu,Jindong Hong,Jiankai Sun", "background": "随着大型语言模型（LLMs）在实际应用中的广泛应用，选择合适的模型不仅要考虑性能，还要考虑运营成本。具有推理能力的模型的出现进一步扩大了'思考'（高推理）模式和'非思考'（快速且低成本）模式之间的成本差异。研究表明，大约58%的医疗问题可以通过'非思考'模式准确回答，无需进行高成本的推理过程，这突显了问题复杂度上的明确差异，表明基于问题复杂度动态路由查询可以优化准确度、成本效率和整体用户体验。", "innovation": "本文提出了SynapseRoute，一种基于机器学习的动态路由框架，能够智能地将输入查询分配到'思考'或'非思考'模式。实验结果显示，相比于单独使用'思考'模式，SynapseRoute不仅在总体准确度上有所提高（0.8390 vs. 0.8272），同时将推理时间减少了36.8%，以及降低了39.66%的令牌消耗。此外，定性分析表明，在简单查询上过度推理会导致不必要的延迟甚至准确度降低，而我们的自适应路由机制避免了这一点。", "conclusion": "通过这项工作，我们进一步引入了准确性-推理-令牌（AIT）指数，全面评估了准确度、延迟和令牌成本之间的权衡。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02863", "html_url": "https://arxiv.org/abs/2507.02863", "title": "Point3R：具有显式空间指针记忆的流式3D重建", "title_en": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory", "authors": "Yuqi Wu,Wenzhao Zheng,Jie Zhou,Jiwen Lu", "background": "从有序或无序图像集中进行稠密的3D场景重建是将计算机视觉研究引入实际场景的关键步骤。DUSt3R方法引入了通过将图像对统一到共享坐标系中的范式，后续方法保持了隐式记忆以从更多图像中实现稠密的3D重建。然而，这种隐式记忆容量有限，可能会导致早期帧信息丢失。", "innovation": "本文提出了一种名为Point3R的在线框架，以专门针对稠密的流式3D重建。具体地说，该方法维护一个直接关联于当前场景3D结构的显式空间指针记忆。每个指针存储特定的3D位置，并将全局坐标系统附近的场景信息聚集到一个变化的空间特征中。来自最新帧的信息与该指针记忆进行显式交互，使得当前观测能够密集地整合到全局坐标系统中。为了促进这种交互，设计了一种3D分层位置嵌入，并设计了一种简单而有效的融合机制，以确保指针记忆的均匀性和高效性。", "conclusion": "我们的方法在各种任务上实现了具有竞争力或最先进的性能，且训练成本较低。代码可在如下地址获得：this https URL."}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02778", "html_url": "https://arxiv.org/abs/2507.02778", "title": "Self-Correction Bench: 揭示并解决LLMs的自我纠正盲区", "title_en": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs", "authors": "Ken Tsui", "background": "尽管大型语言模型（LLMs）已经成为变革性的工具，但它们仍会出错，并可能探索无效的推理路径。自我纠正是值得信赖的LLMs的重要能力，特别是自回归模型。尽管LLMs可以识别用户输入中的错误，但它们会表现出一种系统性的'自我纠正盲区'——无法纠正它们自身输出中的相同错误。为系统研究这一现象，本文引入了Self-Correction Bench作为一种系统框架，通过在三个复杂度级别上注入控制错误的方式来衡量这一现象。", "innovation": "本文介绍了一个名为Self-Correction Bench的系统框架，通过在不同复杂度级别上注入控制错误来研究模型的自我纠正盲区现象。实验证明，平均盲区率为64.5%。研究发现，这种限制与训练数据组成有关：人类的训练示例大多显示无错误的响应，而不是错误校正序列，而通过结果反馈学习错误校正的RL训练模型则不同。简单地添加“等待”可以显著减少盲区，表明这种能力存在但需要激活。", "conclusion": "本文揭示了当前LLMs中一个关键的局限性，并提供了提高其可靠性和可信度的潜在途径。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02851", "html_url": "https://arxiv.org/abs/2507.02851", "title": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "title_en": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs", "authors": "Purbesh Mitra,Sennur Ulukus", "background": "大型语言模型（LLMs）的新进展表明，在增强学习（RL）训练中使用群相对政策优化（GRPO）算法可以使模型生成更多推理/思考令牌，从而产生更好的响应。然而，LLMs在生成有限数量的令牌时仍需保持对先前生成的令牌的关注。这一限制称为LLM的上下文大小，是LLM在处理任意大量令牌时推理的一个瓶颈。为了解决这一限制问题，需要使用模块化思维策略进行多轮推理，这需要在LLM中实施。因此，本文提出了一种名为MOTIF的方法，即通过RL细调在多轮次中生成思考令牌，以有效地允许模型在额外的上下文大小下思考。", "innovation": "文中提出MOTIF方法，即通过RL细调在多轮次中生成思考令牌，从而使模型在额外的上下文大小下思考。具体地，该方法对开源模型Qwen2.5-3B-Instruct进行了参数有效的微调，用于GSM8K数据集，并在MATH500和AIME2024基准测试中进行了测试。实验结果显示，相对于基于GRPO训练的模型，MOTIF方法在基准测试中分别取得了3.8%和3.3%的提升。这些改进仅使用了15%的样本，从而展示了MOTIF方法的样本效率。", "conclusion": "本文证明了MOTIF方法能够有效扩展LLM的上下文尺寸并提高生成推理令牌的能力，从而在多轮推理中提高模型的准确性。此外，还展示了这种方法的样本效率，并提供了模型和代码的访问链接，以便进一步研究与应用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02841", "html_url": "https://arxiv.org/abs/2507.02841", "title": "StepHint: 多级逐步提示增强强化学习以推理", "title_en": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason", "authors": "Kaiyi Zhang,Ang Lv,Jinpeng Li,Yongbo Wang,Feng Wang,Haoyuan Hu,Rui Yan", "background": "强化学习带有可验证奖励（RLVR）是提高大型语言模型（LLMs）复杂推理能力的一个有前景的方法。但是目前的RLVR方法面临两个重大挑战：接近失误奖励问题，一个小错误可以使得整个推理过程无效，极大阻碍了训练效率；以及探索停滞问题，模型往往倾向于集中在它们的“舒适区”内的解决方案上，缺乏探索可能更有效的替代方案的动力。这些挑战使得原有的方法难以有效提升模型的推理能力和训练效率。", "innovation": "为了解决这些挑战，该研究提出了一种名为StepHint的新颖RLVR算法，该算法利用多层次逐步提示帮助模型更有效地探索解空间。StepHint从更强的模型中生成有效的推理链，并通过提出的自适应分隔方法将这些链分割成推理步骤。最初的几步作为提示，同时提供多层次的提示（每层包含不同数量的步骤）给模型。这种方法将模型的探索引导向有希望的解决方案子空间，同时保留其独立探索的灵活性。通过提供提示，StepHint缓解了接近失误奖励问题，从而提高了训练效率。此外，外部推理路径帮助模型发展更好的推理能力，使其能够超越“舒适区”并缓解探索停滞问题。StepHint在六个数学基准测试中胜过竞争的RLVR增强方法，同时在域外基准测试中也展现出优越的泛化能力和比基线模型更好的性能。", "conclusion": "StepHint在多个数学基准测试中表现优异，不仅提高了训练效率，还帮助模型发展了更好的推理能力，同时缓解了探索停滞问题。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2102.11210", "html_url": "https://arxiv.org/abs/2102.11210", "title": "Spectral Radius Regularization for Non-Convex Optimization", "title_en": "Non-Convex Optimization with Spectral Radius Regularization", "authors": "Adam Sandler,Diego Klabjan,Yuan Luo", "background": "该研究旨在通过正则化方法找到深层神经网络训练中的平坦最小值，这些最小值相比于尖锐最小值具有更好的泛化能力。研究指出，找到这些平坦最小值有助于训练出在实际测试数据中表现更优的模型，即使这些实际测试数据可能与训练数据分布不同。", "innovation": "研究提出了一种正则优化方法，用于减少损失函数海森矩阵的谱半径。还开发了高效的算法来优化神经网络模型，并证明了这些算法几乎肯定会收敛。此外，研究展示了该算法在不同领域应用中的有效性，包括医疗健康领域。研究引入了多种测试泛化能力的方法，并验证了其模型在美国基准模型上的表现优胜优势。", "conclusion": "研究证明了通过谱半径正则化进行非凸优化的有效性，并展示了该方法在不同应用领域的泛化能力和优越表现。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2202.05928", "html_url": "https://arxiv.org/abs/2202.05928", "title": "没有线性的良性过拟合：由梯度下降训练的神经网络分类器对噪声线性数据", "title_en": "Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data", "authors": "Spencer Frei,Niladri S. Chatterji,Peter L. Bartlett", "background": "该论文探讨了神经网络模型在训练过程中，即使达到零训练误差（过拟合），仍能在噪声数据中良好泛化的现象（良性过拟合）。首先是在使用梯度下降训练的神经网络模型中观察到的。本文进一步研究了在逻辑损失函数下的随机初始化训练时，两层神经网络在有噪声训练标签（受到攻击者污染的常数比例）的数据上的泛化误差问题。研究表明，在此类设置中，神经网络展示了良性过拟合现象，同时实现了最小最大最优的测试误差。", "innovation": "本文的创新之处在于其研究结果适用于非线性模型和非线性的学习动态，而非以往的研究工作仅限于线性或核基预测器。这提供了一个新的视角，说明在非线性特征下，神经网络仍可能表现出良性过拟合。", "conclusion": "在假设数据来自良好分离的条件对数凹分布并允许一定比例的标签受到攻击者干扰的情况下，神经网络能够被训练达到零训练误差，同时仍然能够实现最小最大最优的测试误差。这证明了即使在非线性的系统中，神经网络也可以表现出良性过拟合现象。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2304.13431", "html_url": "https://arxiv.org/abs/2304.13431", "title": "隐式反事实数据增强用于稳健学习", "title_en": "Implicit Counterfactual Data Augmentation for Robust Learning", "authors": "Xiaoling Zhou,Ou Wu,Michael K. Ng", "background": "机器学习模型容易捕捉非因果属性和类之间的虚假相关性，这可能导致模型不稳定和预测偏差。反事实数据增强有望缓解这类问题，但生成反事实数据需要复杂的操作，且将增强数据集成到训练过程中会降低训练效率。这篇论文探讨了一个名为ICDA（隐式反事实数据增强）的方法，旨在通过隐式生成样本级增强策略来去除虚假相关，提高模型的稳健性和泛化能力。", "innovation": "ICDA方法通过开发一种新型样本级增强策略，为每个样本生成具有不同增强强度的语义和反事实有意义的深度特征。同时，该方法引入了一种易于计算的代理损失函数，在增强样本数量趋于无限时有效。此外，还提出了直接量化和元学习两种方案来确定鲁棒损失的关键参数。ICDA从正则化角度进行了解释，展示了其提高类内紧凑性和扩展样本边距的潜力。该方法在多种包含图像和文本数据的有偏学习场景下进行了广泛实验，验证了其对流行网络的稳健性和泛化性能的改善效果。", "conclusion": "ICDA方法在多个场景中展示了其通过隐式机制去除虚假相关性、提高学习模型的稳健性和泛化能力的效果。这种方法不仅简化了反事实数据增强的过程，还提供了一种新的方法来增强模型性能，尤其是在处理有偏数据和提高泛化能力方面表现出色。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.13836", "html_url": "https://arxiv.org/abs/2403.13836", "title": "基于树的混沌系统高保真预测学习", "title_en": "Tree-based Learning for High-Fidelity Prediction of Chaos", "authors": "Adam Giammarese,Kamal Rana,Erik M. Bollt,Nishant Malik", "background": "混沌系统的时间演化预测对于许多应用来说至关重要但极具挑战性。现有的解决方案需要进行超参数调优，这极大地阻碍了其在实际中的广泛应用。", "innovation": "本文提出了一个无需超参数调优的基于树的方法：TreeDOX。该方法利用时间延迟嵌入作为显式的短期记忆，并使用额外树回归器进行特征降维和预测。", "conclusion": "在海森堡地图、洛伦兹系统、库拉莫托-西瓦辛斯基系统以及现实世界的南方涛动指数上，TreeDOX展示了最先进的性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02819", "html_url": "https://arxiv.org/abs/2507.02819", "title": "测量即拼凑：探讨数据科学家如何构建预测建模任务的目标变量", "title_en": "Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks", "authors": "Luke Guerdan,Devansh Saxena,Stevie Chancellor,Zhiwei Steven Wu,Kenneth Holstein", "background": "数据科学家经常需要构建包含模糊概念的预测建模任务，如学生写作的“真实性”或患者“医疗需求”。然而，从模糊概念到具体可测量的代理目标变量的转换过程仍不明确。本文通过采访教育和医疗领域的15名数据科学家，探讨他们如何构建预测建模任务的目标变量。发现表明，数据科学家通过迭代地在高层次的测量目标和低层次的实用约束之间进行协商，来构建目标变量。他们试图通过拼凑满足五项主要标准：有效性、简约性、可预测性、可移植性和资源要求。为实现这一目标，数据科学家灵活地使用问题重构策略，如当第一个目标变量无法满足某些标准（如可预测性）时，用另一个目标变量替换，或综合多个结果形成一个目标变量以实现更全面的建模目标。", "innovation": "本文首次详细探讨了数据科学家构建预测建模任务中目标变量的过程，并提出了如何通过拼凑策略和问题重构方法来综合多个目标变量以更好地满足建模需求。研究发现，数据科学家在此过程中主要通过适应性使用问题重构策略来实现这一目标，从而进一步完善了他们的建模方法论。此项研究对人机交互、协作计算与工作以及机器学习领域的进一步研究提出了新的方向和建议。", "conclusion": "基于研究结果，本文提出了支持数据科学家构建目标变量的新机会，包括通过改进HCI、CSCW和ML的相关研究，以更好地支持数据科学家的艺术与科学实现。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.00155", "html_url": "https://arxiv.org/abs/2403.00155", "title": "通过概率潜空间解释深度神经网络压缩", "title_en": "Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space", "authors": "Mahsa Mozafari-Nia,Salimeh Yasaei Sekeh", "background": "尽管深度神经网络（DNNs）表现卓越，但它们的计算复杂性和存储空间开销导致了网络压缩的概念。尽管已经有研究表明了许多DNN压缩技术，如剪枝和低秩分解，但这些方法的理论解释仍然不足。本文提供了用概率潜空间中的DNN权重来解释最优网络稀疏性的新颖理论框架，同时通过信息论分歧度量来解释这一点。", "innovation": "本文提出了新的类似投影模式（AP2）和概率类似投影模式（AP3），并对这些概念进行了详细理论分析，证明了这些模式与网络层性能的关系，并解释了压缩网络的训练过程。理论结果通过使用标准预训练基准（AlexNet，ResNet50，VGG16）和CIFAR10，CIFAR100数据集进行实验来验证，强调了AP3和AP2属性与细调稀疏DNN的关系及其稀疏性水平之间的联系。", "conclusion": "实验结果表明，AP3和AP2属性与稀疏DNN的训练过程及其稀疏性水平存在关联，为理解网络压缩提供了新的理论基础。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02856", "html_url": "https://arxiv.org/abs/2507.02856", "title": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation", "title_en": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation", "authors": "Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping", "background": "多选基准已长时间作为语言模型评估的工具，因为多选题的主观性较低且易于自动化评分。但是，研究显示，这些多选题常常可以通过无需直接查看题目即可找到答案的快捷方式来回答。这些快捷方式源于区分性评估的根本局限性，这种局限性在评估模型生成的自由形式回答时并不存在。近期才出现了多选题之外的可扩展替代方案，研究证明，通过我们称为答案匹配的方法进行评估，可以成为新的选择。即给候选模型一个没有选项的问题，要求其生成自由形式的回答，然后使用一个现代语言模型和参考答案来确定回应是否匹配参考答案。为了比较不同评估策略的有效性，我们对MMLU-Pro和GPQA-Diamond进行了注释，获得了人工评分数据，并测量了每种评估方法的一致性。我们发现，使用现代模型（即使是较小的模型）进行答案匹配，能够达到几乎完美的一致性，而每种方法与人工评分的一致性较低。因此，使用答案匹配方法进行评价不仅是概念上的改进，还会显著影响多种模型的排名，这对评价生态系统的改进至关重要。", "innovation": "提出了一种名为'答案匹配'的新评估方法，通过使用现代语言模型帮助判断模型生成的回答是否与参考答案匹配，从而改进了语言模型的评估方法。研究显示这种方法在全球语言理解能力评测和斯坦福问答数据集上的表现优于传统的多选题评估方式。这种方法不仅在概念上有所革新，也从实证数据角度证明了其实用性。", "conclusion": "研究提出通过答案匹配进行评估优于传统的多选题方式，可以有效改进语言模型的评估方法，并且这种方法已经能够显著影响模型的排名，未来可能会被广泛应用。研究建议在自然语言处理领域，我们应该从使用多选题转向使用答案匹配作为模型评估的标准。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.08062", "html_url": "https://arxiv.org/abs/2402.08062", "title": "通过求助避免在线学习中的灾难", "title_en": "Avoiding Catastrophe in Online Learning by Asking for Help", "authors": "Benjamin Plaut,Hanlin Zhu,Stuart Russell", "background": "大多数具有正式遗憾保证的学习算法假设所有错误都是可恢复的，本质上依赖于尝试所有可能的行为。而当某些错误是不可挽回的‘灾难性’错误时，这种方法是有问题的。文章提出了一个新的在线学习问题，目标是尽量减少灾难的发生概率。假设每轮的收益表示避免灾难的机会，并尽量使各轮收益的乘积最大（即总体避免灾难的机会），同时允许使用有限次数的导师查询。此外，假设智能体可以在类似输入间转移知识。文章证明，在一般情况下，任何算法要么按线性速率查询导师，要么几乎保证会导致灾难。但在导师策略类可以在标准在线模型中学习的情况下，提供了当时间范围增长时，遗憾和查询导师的数量比率都趋向于0的算法。虽然关注的是收益的乘积，但也提供了匹配的累积遗憾上限。这一结果表明，如果在没有灾难风险情况下可以学习的策略类，在引入灾难风险但智能体可以求助时也可以学习。", "innovation": "文章提出了一个新的在线学习问题，目标是尽量减少灾难的发生概率。假设每轮的收益表示避免灾难的机会，并尽量使各轮收益的乘积最大（即总体避免灾难的机会），同时允许使用有限次数的导师查询。还提供了在特定条件下的算法，虽然关注的是收益的乘积，但也提供了匹配的累积遗憾上限。概念上，如果没有灾难风险的策略类可以学习，只要有求助能力，引入灾难风险也可以学习。", "conclusion": "文章证明了在一般情况下，任何算法要么按线性速率查询导师，要么几乎保证会导致灾难。但在导师策略类可以在标准在线模型中学习的情况下，提供了当时间范围增长时，遗憾和查询导师的数量比率都趋向于0的算法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.03449", "html_url": "https://arxiv.org/abs/2405.03449", "title": "拜占庭稳健广义共识：双重方法的见解", "title_en": "Byzantine-Robust Gossip: Insights from a Dual Approach", "authors": "Renaud Gaucher,Aymeric Dieuleveut,Hadrien Hendrikx", "background": "分布式学习具有许多计算优势，但易受到传递错误信息的设备子集攻击。本论文研究了在去中心化设置中对拜占庭故障具有鲁棒性的算法，其中设备直接在通信网络内进行点对点通信。论文利用所谓的双重方法来解决去中心化优化问题，并提出了一种拜占庭鲁棒算法。在平均共识子案例中提供了收敛保证，并讨论了双重方法在此子案例之外的潜在应用，重新解释了现有算法的方法框架。最后，实验结果证明了该方法的有效性，", "innovation": "提出了利用双重方法的去中心化优化算法，并实现在平均共识子案例中的收敛保证。该算法在现有方法的基础上提供了对拜占庭攻击的鲁棒性，同时讨论了双重方法在更广泛应用场景中的潜力。重新解释了现有算法，提出了新的理解视角。", "conclusion": "通过实验验证了该方法的有效性和鲁棒性，展示了双重方法在去中心化优化中的应用潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.12537", "html_url": "https://arxiv.org/abs/2410.12537", "title": "真的复杂的查询回答吗？", "title_en": "Is Complex Query Answering Really Complex?", "authors": "Cosimo Gregucci,Bo Xiong,Daniel Hernandez,Lorenzo Loconte,Pasquale Minervini,Steffen Staab,Antonio Vergari", "background": "知识图谱(KGs)上的复杂查询回答(CQA)任务正逐渐成为一项具挑战性的推理任务。然而，现有的基准测试可能未能充分反映实际进展，因为它们的构建方式扭曲了我们对进步的看法。常见的基准测试中，大多数查询（某些查询类型高达98%）实际上可以简化为只需预测一条连接的链接预测问题。当评估当前最先进的CQA模型在无法简化为更简单类型的情况下表现时，它们的表现显著下降。", "innovation": "本文提出了一组更具挑战性的基准测试，这些基准测试由需要模型进行多跳推理的查询组成，这种问题更能反映现实世界的知识图谱结构。新的基准测试表明，当前的方法在处理复杂的查询回答问题时还有很大的提升空间。", "conclusion": "新的基准测试结果显示，现有的方法在复杂的查询回答任务中表现并不理想，还存在提升的空间。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.12335", "html_url": "https://arxiv.org/abs/2403.12335", "title": "基于时间一致性的科莫多诺自编码器用于动态系统预测", "title_en": "Temporally Consistent Koopman Autoencoders for Forecasting Dynamical Systems", "authors": "Indranil Nayak,Ananda Chakrabarty,Mrinal Kumar,Fernando Teixeira,Debdipta Goswami", "background": "在高维时空动态系统中，缺乏足够高质量的数据往往是数据驱动建模中的关键挑战。科莫多诺自编码器（Koopman Autoencoders, KAEs）利用深度神经网络的表达能力、自编码器的降维能力和科莫多诺算子的谱性质来学习一个简化而线性的低维特征空间。然而，KAEs 的有效性受到有限且噪声较大的训练数据集的限制，导致泛化能力较差。", "innovation": "本文介绍了时间一致性的科莫多诺自编码器（temporally consistent Koopman autoencoder, tcKAE），通过时间一致性正则化项确保在不同时间步的预测一致，从而增强了模型的鲁棒性和泛化能力。我们基于科莫多诺谱理论为这种方法提供了分析上的证明，并通过多种测试案例与最先进的KAE模型进行了对比实验，结果表明tcKAE具有更优异的性能。", "conclusion": "tcKAE能够在有限和噪声较大的训练数据下生成准确的长期预测，其通过时间一致性正则化增强了模型的鲁棒性和泛化能力，优于现有的KAE模型。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.00034", "html_url": "https://arxiv.org/abs/2409.00034", "title": "Neural CRNs: 一种在化学反应网络中自然实现学习的神经网络框架", "title_en": "Neural CRNs: A Natural Implementation of Learning in Chemical Reaction Networks", "authors": "Rajiv Teja Nagipogu,John H. Reif", "background": "该工作中介绍了一种嵌入学习直接到基元化学反应系统中的通用化学神经网络框架——Neural CRNs。不同于以往的离散神经计算的化学实现，新型框架采用了模拟计算的方法，学习的前向和反向传播过程均以分子浓度的连续时间演化进行实现。这种方法自然地与化学动力学的模拟特性相吻合，使得电路更为简洁且操作实际可行。", "innovation": "Neural CRNs通过实现模拟计算，解决了前人将离散神经计算嵌入化学系统的问题。它不仅适用于前向和反向传播，还在两个连续阶段中实现了高效的监督学习过程，并提供了线性和非线性的模型能力验证及其学习过程的验证。所有这些反应仅使用单一分子和双分子反应实现，避免了高级化学反应的复杂性。这种创新为生物计算、生物工程和生物医学中的自适应计算开辟了新的途径。", "conclusion": "Neural CRNs提供了一个紧凑、可扩展且自主的生物化学学习框架，为合成生物学、生物工程和生物医学中的自适应计算开辟了新的路径。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21553", "html_url": "https://arxiv.org/abs/2410.21553", "title": "探索扩散桥梁模型的设计空间", "title_en": "Exploring the Design Space of Diffusion Bridge Models", "authors": "Shaorong Zhang,Yuanbin Cheng,Greg Ver Steeg", "background": "扩散桥梁模型和随机插值方法能够通过在像素空间中创建分布路径来实现高质量的图像到图像（I2I）翻译。然而，基于不兼容数学假设的技术引发的问题阻碍了进展。", "innovation": "该工作通过将随机插值（SIs）扩展为预条件、端点条件以及优化采样算法来统一并扩展扩散桥梁模型的空间。这些增强功能扩展了扩散桥梁模型的设计空间，实现了在各种I2I任务中图像质量和采样效率的最先进的表现。此外，该研究还识别并解决了固定条件下样本多样性低的问题，并引入了输出多样性的定量分析方法，展示了如何进一步改进基础分布以提高结果多样性。", "conclusion": "通过增强和扩展扩散桥梁模型的设计空间，该研究提高了I2I任务中的图像质量和采样效率，并通过定量分析解决了样本多样性低的问题，为进一步改进提供了依据。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2303.06827", "html_url": "https://arxiv.org/abs/2303.06827", "title": "Kernel Density Bayesian Inverse Reinforcement Learning", "title_en": "Kernel Density Bayesian Inverse Reinforcement Learning", "authors": "Aishwarya Mandyam,Didong Li,Jiayu Yao,Diana Cai,Andrew Jones,Barbara E. Engelhardt", "background": "逆强化学习（IRL）方法通过专家行为的演示来推断代理的奖励函数。贝叶斯IRL方法建模候选奖励函数的分布，以捕捉推断奖励函数中的不确定性。在某些应用中，如临床数据，这非常重要。通常，贝叶斯IRL算法需要大量的演示数据集，但是在实践中可能不可用。在本工作中，通过引入现有的领域特定数据来实现更好的后验收敛率。研究了在临床和生物学应用中的常见场景，我们有专家演示和一组训练任务已知的奖励函数。目标是根据有限的专家演示学习新测试任务的奖励函数。现有的贝叶斯IRL方法对输入数据的形式施加了限制，从而限制了将训练任务数据纳入其中的能力。为了更好地利用培训任务的信息，引入了基于核密度的贝叶斯逆强化学习（KD-BIRL）方法。该方法利用训练任务中已知的奖励函数来改进各种奖励函数和演示样本的似然估计。实证结果表明，与基线相比，KD-BIRL的后验收敛率更快，尤其是在测试任务专家演示数据较少的情况下。此外，首次提供了贝叶斯IRL算法后验收敛的理论保证。", "innovation": "引入了基于核密度的贝叶斯逆强化学习（KD-BIRL）方法，通过使用训练任务中已知的奖励函数来改进各种奖励函数和演示样本的似然估计，从而更好地利用了训练任务的信息。首次提供了贝叶斯IRL算法后验收敛的理论保证。", "conclusion": "这项工作提供了贝叶斯IRL的一种理论基础和原则性的框架，使其能够在多种领域中应用。KD-BIRL方法在有限的专家演示数据下表现出更快的后验收敛率。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.10576", "html_url": "https://arxiv.org/abs/2406.10576", "title": "绕过反向传播：通过策略梯度实现的大语言模型结构剪枝", "title_en": "Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient", "authors": "Yuan Gao,Zujing Liu,Weizhong Zhang,Bo Du,Gui-Song Xia", "background": "近期的大语言模型（LLMs）剪枝方法通常在后训练阶段进行，而不需要昂贵的权重微调。然而，这些方法的剪枝准则往往依赖于手工构建的度量标准，可能导致性能不佳。与之不同的是，本文提出了一种基于优化的结构剪枝方法，该方法直接在概率空间中通过优化剪枝后的模型来学习剪枝掩码，从而避免了代价高昂的反向传播，同时保证了剪枝的全球性和异质性。", "innovation": "本文提出了一种创新的基于优化的结构剪枝方法，该方法通过学习一个潜在的伯努利分布来采样二进制剪枝掩码，将伯努利参数与LLM损失分离，利用策略梯度估计器来进行高效的优化，而不进行反向传播。这种方法能支持全球和异质剪枝，并可选地使用度量方法初始化伯努利分布。", "conclusion": "在LLaMA、LLaMA-2、LLaMA-3、Vicuna和Mistral模型上使用C4和WikiText2数据集进行的广泛实验表明，本方法在效率和效果方面表现出色。相关代码已在指定网址发布。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.16985", "html_url": "https://arxiv.org/abs/2407.16985", "title": "面向方向感知的稀疏张量主成分分析在高效无监督特征选择中的应用", "title_en": "Orientation-Aware Sparse Tensor PCA for Efficient Unsupervised Feature Selection", "authors": "Junjing Zheng,Xinyu Zhang,Weidong Jiang,Xiangfeng Qiu,Mingjian Ren", "background": "近年来，将张量分解（TD）技术引入无监督特征选择（UFS）成为研究热点。张量结构有助于挖掘不同模式之间的关系，并有助于减轻计算负担。然而，现有方法虽利用TD保持数据张量结构，但未考虑数据方向的影响，难以处理时间序列等方向特定数据。为解决此问题，利用T-SVDM（*M-product）中的方向依赖张量-张量积，将一维稀疏主成分分析（SPCA）扩展为张量形式，并提出一种稀疏张量PCA模型，该模型在指定模式下约束稀疏性，并生成稀疏张量主成分，增强学习特征关系的灵活性和准确性。为了确保快速收敛和对特征相关性描述的灵活性，专门开发了一种凸版本，并提出了一种有效的切片算法，该算法在变换域中执行双优化。实验结果表明，对于不同结构的张量数据，所提方法在计算效率和有效性方面均优于现有最先进的方法。当变换轴与特征分布模式一致时，方法对各种应用具有前景。", "innovation": "引入了方向依赖张量-张量积的T-SVDM，将一维SPCA扩展为张量形式，开发了一个稀疏张量PCA模型，能够在指定模式下约束稀疏性，产生稀疏张量主成分。提出了特殊的凸版本和高效的切片算法，增强了模型的灵活性和计算效率。", "conclusion": "所提方法在不同结构的张量数据中表现出高效性和优越性。当变换轴与特征分布模式一致时，该方法在多种应用中有望。相关代码和实验数据在提供的网址可获取。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.10589", "html_url": "https://arxiv.org/abs/2409.10589", "title": "基于离线强化学习的作业调度学习", "title_en": "Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling", "authors": "Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang", "background": "作业车间调度问题（JSSP）是一个复杂的组合优化问题。尽管在线强化学习（RL）能够迅速找到可接受的解决方案，但它存在样本效率低、不能利用传统方法如约束编程（CP）中的现有高质量解决方案以及需要构建难以实践的模拟环境等问题。", "innovation": "本文提出了离线学习调度（Offline-LD），这是一种能够从历史调度数据中学习的离线增强学习方法。介绍了两种新的Q学习方法，即Maskable Quantile Regression DQN (mQRDQN) 和离散可掩码Soft Actor-Critic (d-mSAC)，并引入了保守Q学习（CQL）及屏蔽动作空间的新熵奖励修正方法；还提出了一种新的面向JSSP的离线RL环境奖励归一化方法。实验结果表明，当仅使用约束编程生成的100个解决方案训练时，Offline-LD在生成实例和基准实例上都优于在线RL。此外，引入噪声到专家数据集中的效果与直接使用专家数据集效果相当或更优，这对于存在噪声和不完美的实际应用数据来说是一个有希望的结果。", "conclusion": "实验表明，Offline-LD在训练过程中仅使用100个由CP生成的解决方案时，在生成和基准实例上都优于在线RL。引入专家数据集的噪声可以得到与使用原始专家数据集相比相当或更优的结果，这对于实际应用中数据往往是噪声和不完美的情况是一个积极的发现。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00420", "html_url": "https://arxiv.org/abs/2412.00420", "title": "TAROT: 利用最优运输的靶向数据选择", "title_en": "TAROT: Targeted Data Selection via Optimal Transport", "authors": "Lan Feng,Fan Nie,Yuejiang Liu,Alexandre Alahi", "background": "之前的方法主要依赖于基于影响的贪心启发式方法来增强特定领域的性能。这些方法在单一模式数据上表现有效，但在复杂性增加的数据（尤其是多模式分布）上表现不佳。主要问题在于高维影响估计中主导特征成分的不均衡影响以及贪婪选择策略中的线性和加性假设限制了这些方法的效果。", "innovation": "TAROT框架通过引入“去相关特征距离”来减轻主导特征偏差，提供了一个更可靠的影响力措施。然后，TAROT使用“去相关特征距离”来量化并最小化所选数据与目标领域之间的最优传输距离，这也有助于估计最佳选择比例。", "conclusion": "TAROT在语义分割、运动预测和指令调优等多个任务中表现出色，证明了其在各种深度学习任务中的适应性。作者还提供了代码，以便其他研究者进行验证和进一步的发展。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01391", "html_url": "https://arxiv.org/abs/2502.01391", "title": "从生成模型学习实时观测中的交通异常", "title_en": "Learning Traffic Anomalies from Generative Models on Real-Time Observations", "authors": "Fotis I. Giasemis,Alexandros Sopasakis", "background": "准确检测交通异常对于有效的城市交通管理和缓解交通拥堵至关重要。为了捕捉交通数据中的复杂时空依赖关系，作者采用结合图神经网络（Graph Neural Networks）和长短期记忆网络（Long Short-Term Memory networks）的时空生成对抗网络（STGAN）框架进行研究。该研究使用斯德哥尔摩哥特堡的42个实时交通监控摄像机的数据，这些数据于2020年的几个月内收集。图片经过处理以计算表示车辆密度的流量指标，作为模型的输入。训练数据从2020年4月到11月，验证则使用2020年11月14日至23日期间的数据集进行。实验结果表明，该模型能够有效检测交通异常，且具有高精度和低误报率。检测到的异常包括相机信号中断、视图伪影以及极端天气条件对交通流量的影响。", "innovation": "该论文创新性地使用STGAN框架，结合Graph Neural Networks和LSTM网络来捕捉交通数据中的复杂时空依赖关系。这使得模型能够更准确地检测交通异常，为城市交通管理和缓解交通拥堵提供了新的方法和技术手段。", "conclusion": "本研究利用STGAN模型在斯德哥尔摩哥特堡的监控数据上进行实证研究，证实了该模型能够准确地检测出交通异常，包括相机信号中断、视图伪影及极端天气影响。研究结果为未来的交通管理和交通流量预测提供了有力的支持。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04700", "html_url": "https://arxiv.org/abs/2502.04700", "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference", "title_en": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference", "authors": "Prakhar Kaushik,Ankit Vaidya,Shravan Chaudhari,Alan Yuille", "background": "大规模模型的快速增长引起了对其环境影响和访问公平性的担忧，由于巨大的计算成本。Low-Rank Adapters（LoRA）提供了一种轻量级的微调解决方案，使大型模型能够适应各种领域，并产生了大量的公开适配器。然而，这些预训练适配器是否可以进一步简化新任务的适应过程，同时解决计算成本和公平访问的问题还尚未明确。因此，需要能够高效地适应新任务并减少资源消耗的方法。", "innovation": "作者提出了EigenLoRAx，一种参数高效的微调方法，能够利用现有的适配器创建一个与共享领域知识对齐的主要子空间，并在低资源场景下进一步增强正交基向量。这种方法通过仅学习次要空间的主要成分的轻量级系数，来快速适应新任务，无需对整个适配器进行微调。相较于现有方法，EigenLoRAx需要更少的参数和内存，提高了训练和推理的效率。", "conclusion": "EigenLoRAx方法在不同领域和任务中表现出强大的性能，为基于边缘的应用、个性化和大规模模型在资源受限环境中的公平部署提供了可扩展的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06106", "html_url": "https://arxiv.org/abs/2502.06106", "title": "电路调谐：一种机制方法以识别参数冗余并调优神经网络", "title_en": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks", "authors": "Yueyan Li,Wenhao Gao,Caixia Yuan,Xiaojie Wang", "background": "机制可解释性研究旨在反向工程模型以解释其行为。最近的研究集中在特定行为的静态机制上，但模型内部的学习动态尚未得到探索。本文扩展了此研究，旨在开发一种可解释的调优方法来分析学习背后的过程。", "innovation": "引入了节点级内在维度的概念，以描述计算图中的模型学习过程。基于此理论，提出了一个基于电路调谐的两阶段算法，该算法通过迭代构建特定任务所需的最小子图，并以启发式的方式更新关键参数，从而实现透明和可解释的调优。", "conclusion": "实验结果证实了节点级内在维度的存在，并证明了该方法的有效性。通过在调优前、调优中和调优后可视化和分析电路，还提供了一种理解神经网络在学习过程中自我组织机制的新视角。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12370", "html_url": "https://arxiv.org/abs/2501.12370", "title": "参数量 vs 运算量：Mixture-of-Experts 语言模型最优稀疏性扩展定律", "title_en": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models", "authors": "Samira Abnar,Harshay Shah,Dan Busbridge,Alaaeldin Mohamed Elnouby Ali,Josh Susskind,Vimal Thilak", "background": "语言模型容量扩展是提升性能并解锁新能力的一种可靠方法。容量主要由模型参数的数量和每个示例的计算量两个维度定义。虽然扩展通常会同时增加这两个因素，但对于这些因素之间的精确关系及其对整体容量的综合贡献，目前尚未完全理解。本文通过研究稀疏 Mixture-of-Experts (MoEs) 中的关系，探索了在不同约束（例如参数大小和总训练计算量）下，参数稀疏性对训练效率和模型性能的优化作用，从而更好地理解稀疏性在 MoEs 容量扩展定律中的影响", "innovation": "本文首次系统地研究了稀疏 MoEs 中参数稀疏性与训练效率及模型性能的关系。通过调整参数的活跃比例，找到了在不同约束条件下的最优稀疏性水平，提高了模型的训练效率和性能。这个研究弥补了现有工作的空白，为设计更高效的架构提供了新的见解", "conclusion": "研究结果表明，不同的约束条件下存在最优的稀疏性水平，能够同时提高模型的训练效率和性能。这些结果深化了我们对 MoEs 稀疏性在扩展规律中的影响的理解，并为 MoEs 架构设计提供了重要参考"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17874", "html_url": "https://arxiv.org/abs/2502.17874", "title": "神经图匹配在分子机器学习中提升检索增强生成", "title_en": "Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning", "authors": "Runzhong Wang,Rui-Xi Wang,Mrunali Manjrekar,Connor W. Coley", "background": "随着几何深度学习的发展，分子机器学习得到了广泛关注。同时，检索增强生成已成为一种常用的语言模型方法。然而，在分子机器学习中将检索增强进行最优整合仍不清楚。图神经网络可以从巧妙的匹配中获益，以理解检索分子与查询分子之间的结构对齐。神经图匹配通过明确建模两个结构图之间的节点和边亲和力，结合噪声鲁棒的端到端神经网络学习亲和力度量，提供了一个引人注目的解决方案。作者将该方法应用于质量谱模拟，并引入了MARASON模型来增强基于片段的神经网络。实验结果证明了设计的有效性，MARASON的顶级准确率达到28%，显著优于非检索的最先进的19%。此外，MARASON在所有检索增强生成方法和传统图匹配方法中表现出色。", "innovation": "提出了MARASON模型，该模型结合了神经图匹配来增强基于片段的神经网络。这一方法打破了传统的图匹配方法和非检索的最先进的生成方法，特别是在质量谱模拟中实现了28%的顶级准确率。提到的方法通过明确地建模结构图之间的节点和边亲和力，提供了一个鲁棒的端到端解决方案来学习亲和力度量。", "conclusion": "实验结果表明，神经图匹配可以有效提升检索增强生成在分子机器学习中的性能，特别是质量谱模拟，MARASON方法显著改善了准确率。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.13450", "html_url": "https://arxiv.org/abs/2502.13450", "title": "互插吉布斯扩散：具有隐式约束的离散连续数据生成", "title_en": "Interleaved Gibbs Diffusion: Generating Discrete-Continuous Data with Implicit Constraints", "authors": "Gautham Govind Anil,Sachin Yadav,Dheeraj Nagaraj,Karthikeyan Shanmugam,Prateek Jain", "background": "大多数针对离散和离散连续扩散的研究假设去噪分布的因子化，这可能阻碍对变量之间强依赖关系的建模。本文指出，通过切换到不需要假设因子化的吉布斯采样类型的离散扩散模型，可以显著改善3-SAT性能。这种模型促进了一种新的生成建模框架——互插吉布斯扩散（IGD），用于处理具有重要、隐式且未指定约束的数据问题。", "innovation": "IGD 引入了一种新的生成建模框架，专门针对具有隐式约束特征的数据集，并通过去除假设可分解性的限制，改善了变量之间的依赖关系建模。IGD 框架提供了一种灵活的方式来组合离散和连续类型的去噪器，并且适用于状态空间加倍和推理时间细化等高级操作。论文中的实证研究表明，IGD 在离散-连续生成任务（如分子结构、布局和表形式数据）上能够达到最先进的性能，而无需依赖特定领域的归纳假设（如对称扩散或辅助损失）", "conclusion": "IGD 在广泛建模和交错策略中进行了探索，并通过实证评估表明了其在多个具有挑战性的生成任务上的优越性能，同时展示了其灵活性和有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01940", "html_url": "https://arxiv.org/abs/2412.01940", "title": "废除层级结构：HNSW 中的'H'代表‘枢纽’", "title_en": "Down with the Hierarchy: The 'H' in HNSW Stands for \"Hubs\"", "authors": "Blaise Munyampirwa,Vihan Lakshman,Benjamin Coleman", "background": "受近期神经表示学习方面的突破性进展推动，向量嵌入的近似最邻近（ANN）搜索已成为关键的计算负载。由于引入了由此标志性算法HNSW，基于图的索引已成为高效和可扩展ANN搜索的主导范式。HNSW算法将查询矢量的近似相似点搜索建立在分层图上，以快速查找最邻近的邻域，但分层结构是否必要仍是个疑问。本文进行了一项广泛的大规模基准测试研究，表明平铺的可控小型世界图在高维数据集上保留了HNSW的所有优点，且在延迟和召回性能上几乎与原算法相同，但内存消耗较低。进一步研究发现，HNSW分层结构在高维数据中的优势来自于枢纽节点形成的高效“公路”，这与分层结构的功能类似。实验证据表明，‘枢纽公路假设’在实际数据集中成立，探讨了这种‘公路’如何形成的原因。这对进一步发展基于图的ANN搜索具有潜在影响。", "innovation": "本文通过大规模基准测试研究，发现平铺的可控小型世界图在高维数据集上保留了HNSW的所有优点，且在延迟和召回性能上几乎与原算法相同，但内存消耗较低。进一步研究指出，HNSW分层结构在高维数据中的优势源自枢纽节点形成的高效“公路”，这与分层结构的功能类似。", "conclusion": "分层结构在高维数据中的优势来自于枢纽节点形成的高效“公路”，这与分层结构的功能类似。本文提出的‘枢纽公路假设’在实际数据集中成立，这对进一步发展基于图的ANN搜索具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.18530", "html_url": "https://arxiv.org/abs/2412.18530", "title": "关于语言生成的特性：幻觉、广度和稳定性的相互作用", "title_en": "On Characterizations for Language Generation: Interplay of Hallucinations, Breadth, and Stability", "authors": "Alkis Kalavasis,Anay Mehrotra,Grigoris Velegkas", "background": "本研究关注限界中的语言生成问题——由Kleinberg和Mullainathan提出，基于Gold和Angluin的经典工作。Gold提出了一种生成算法，可以从任何可数语言集合中生成未见过的字符串，尽管该算法最终可以生成目标语言K中的未见过的字符串，但它牺牲了覆盖范围或广度，即生成丰富字符串集的能力。近年来，研究引入了不同的广度概念，并探讨了在这些概念下生成的可行性，但尚未完全界定这些概念的特性。研究通过分析现有概念及其自然扩展，解决了这一问题，提出了关于生成的特性描述。此外，研究还探讨了具有广度和稳定生成器（在看到一定数量字符串后不再改变的算法）的语言生成，并证明了对于这类生成器的无条件下界，进一步强化了KMV25的研究结果，展示了在稳定性要求下，许多现有广度概念的生成变得同样困难，这区分了近似广度下的生成稳定性与不稳定性生成器，突显了语言生成中广度、稳定性和一致性之间的复杂互作关系。", "innovation": "研究通过分析现有广度概念及其自然扩展，解决了限界内语言生成特性的完整描述问题，并提出了关于生成特性的描述。此外，研究还证明了对于具有广度和稳定性的生成器的无条件下界，这增强了KMV25的研究结果，表明在需要稳定性时，许多现有广度概念的生成变得同样困难。这进一步区分了稳定性与不稳定性生成器在近似广度下的生成特性，展示了语言生成中广度、稳定性和一致性之间的复杂互作关系。", "conclusion": "研究通过分析现有广度概念及其自然扩展，提出了关于限界内语言生成的特性描述，即生成的特性。此外，研究还证明了对于具有广度和稳定性的生成器的无条件下界，进一步表明在稳定性要求下，许多现有广度概念的生成变得同样困难。这表明语言生成中广度、稳定性和一致性之间存在复杂互作关系。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03935", "html_url": "https://arxiv.org/abs/2503.03935", "title": "基于大语言模型的血糖预测及行为治疗路径发现", "title_en": "LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet", "authors": "Abdullah Mamun,Asiful Arefeen,Susan B. Racette,Dorothy D. Sears,Corrie M. Whisner,Matthew P. Buman,Hassan Ghasemzadeh", "background": "餐后高血糖，表现为餐后血糖水平超出正常范围，是预测2型糖尿病进展的关键指标，尤其对于血糖异常前的人群和健康个体而言。理解餐后血糖动态的核心指标是餐后曲线下面积（AUC），预测餐后AUC可以帮助个体调整生活方式，从而维持正常的血糖水平。本文研究旨在开发一个可解释的机器学习解决方案GlucoLens，该解决方案能够基于生活方式因素（如饮食和活动水平）来预测餐后AUC和高血糖，并解释影响餐后血糖的因素。该研究使用了佩戴可穿戴设备的10名成年人，在为期五周的工作环境下开发并评估了该计算模型，该模型整合了可穿戴传感、多模态数据和机器学习。", "innovation": "本文开发了基于大语言模型的可解释机器学习解决方案GlucoLens。该模型结合了可穿戴设备的活动和血糖监测传感器数据、饮食和工作日志，提供了一个可解释的餐后血糖模式预测。相较于基准模型，该技术表现出了16%的性能提升，并且可以准确预测高血糖，准确率为73.3%，F1分数为0.716，还能推荐不同治疗方案以避免高血糖，提供多样化的反事实解释。", "conclusion": "该研究基于穿戴设备数据开发了一个能够预测餐后AUC和高血糖的可解释机器学习模型，通过多模态数据整合，实现了73.3%的高血糖预测准确性和0.716的F1分数，展现了在预测餐后高血糖和指导行为治疗路径方面的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06684", "html_url": "https://arxiv.org/abs/2502.06684", "title": "EquiTabPFN: 目标置换同变先验网络", "title_en": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks", "authors": "Michael Arbel,David Salinas,Frank Hutter", "background": "近年来，面向表格数据的根基模型，如 TabPFN，在上下文学习中表现出色，但依然受限于固定的、预先定义的目标维度数-这往往需要昂贵的集成策略。这一限制源于更深层次的架构缺陷：这些模型缺乏目标同变性，即目标维度顺序互换会改变模型的预测结果。这种缺乏同变性导致了不可消除的“同变差距”，进而增加了预测的不稳定性。", "innovation": "本文通过设计完全目标同变的架构，利用同变编码器、解码器和双向注意力机制，消除了模型的同变差距。在多个标准分类基准上的实证评估表明，对于含有比预训练更多的类别的数据集，作者的模型在其计算开销较低的情况下达到了或超越了现有方法的效果。", "conclusion": "本文通过消除目标置换导致的模型预测误差，设计了一种全新的完全目标同变架构，提高了模型在处理更多类别数据集时的稳定性和效率。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20767", "html_url": "https://arxiv.org/abs/2503.20767", "title": "可靠的数据驱动设计算法选择", "title_en": "Reliable algorithm selection for machine learning-guided design", "authors": "Clara Fannjiang,Ji Won Park", "background": "机器学习指导的设计算法使用基于机器学习的预测来提出具有所需属性值的新型对象。鉴于新设计任务（例如设计新型蛋白以高亲和性靶向治疗），必须选择设计算法并指定任何超参数以及预测和/或生成模型。如何在确保最终设计成功的情况下做出这些选择？本文旨在提出一种设计算法选择方法，该方法选择能够在用户指定的成功标准下产生设计标签分布的设计算法 – 例如，至少10%的设计标签会超过某一阈值。该方法通过结合设计预测属性值与未保留的标记数据，可靠地预测不同的设计算法生成的标签分布特征。该方法如果设计数据分布与标记数据分布的密度比率已知，则可以高概率保证返回成功的设计标签分布的实际算法（或如果不存在则为空集）。该方法在模拟的蛋白和RNA设计任务中进行了演示，场景中已经知道或估计了密度比率", "innovation": "提出了一种设计算法选择方法，能够根据用户指定的成功标准可靠地选择能够在不同设计算法中产生满足该标准设计标签分布的方法，从而确保生成的设计成功。该方法结合了设计预测属性值与未保留的标记数据，利用预测增强的推理技术，并在密度比率已知的情况下提供高概率的保证。通过在模拟的蛋白和RNA设计任务中的验证，该方法展示了其有效性", "conclusion": "本文提出的方法能够通过预测增强的推理技术帮助选择设计算法，从而在已知或估计的密度比率情况下能够高概率地生成满足用户指定成功标准的设计任务的标签分布。该方法已经通过模拟的蛋白和RNA设计任务得到了验证，展示出其在设计任务选择中的可靠性和有效性"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04164", "html_url": "https://arxiv.org/abs/2504.04164", "title": "MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning", "title_en": "MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning", "authors": "Shiguang Sun,Hanbo Zhang,Zeyang Liu,Xinrui Yang,Lipeng Wan,Xingyu Chen,Xuguang Lan", "background": "现有的视觉模型导向的强化学习（MBRL）算法在处理观察重建时往往会出现信息冲突，这使得难以学习紧凑的表示，从而导致策略不够鲁棒，尤其是在存在任务无关的视觉干扰时表现更差。", "innovation": "本文首次从信息论的角度揭示了现有视觉MBRL算法中的信息冲突源自于视觉表示学习和潜在动态建模。提出了一种新的算法MInCo，通过使用负面自由对比学习来缓解信息冲突，从而学习不变表示和鲁棒策略。此外，引入了时间变化的重新加权，以在训练过程中偏向动态建模，防止视觉表示学习占主导地位。", "conclusion": "在具有动态背景干扰的机器人控制任务上评估了我们的方法。实验表明，MInCo能够学习对抗背景噪音的不变表示，并且在所有情况下都优于当前最先进的视觉MBRL方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08136", "html_url": "https://arxiv.org/abs/2504.08136", "title": "一种基于物理信息神经网络模拟受浅冰近似控制的冰动力学的方法", "title_en": "A physics informed neural network approach to simulating ice dynamics governed by the shallow ice approximation", "authors": "Kapil Chawla,William Holmes", "background": "本文开发了一种物理信息神经网络（PINN）方法来模拟受浅冰近似控制的冰川动力学。这类问题表现为时间依赖的抛物线障碍问题。以前的研究利用这种方法解决了静态障碍问题，本研究则进一步将其扩展到时间依赖的问题。", "innovation": "通过结合传统的数学建模方法和最新的深度学习方法，本文提出的方法提供了一种可扩展且健壮的解决方案，用于预测冰厚随时间的变化。此外，该方法通过全面的1D和2D模拟验证了其在捕捉复杂自由边界条件方面的有效性。并且通过实际示例模拟了德文冰盖的动力学，并纳入了2000年和2018年的航空地质数据来进行建模验证，显示了方法在现实世界应用中的实用性。", "conclusion": "本文通过基于物理信息的神经网络方法，成功模拟了浅冰近似控制下的冰动力学。该方法不仅能够捕捉复杂冰川边界条件，而且为预测冰厚随时间的变化提供了可靠的工具。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15325", "html_url": "https://arxiv.org/abs/2504.15325", "title": "显著性指标对于一致性值的评估", "title_en": "Significativity Indices for Agreement Values", "authors": "Alberto Casagrande,Francesco Fabris,Rossano Girometti,Roberto Pagliarini", "background": "一致性度量，如Cohen's kappa或内部相关性，可以衡量两个或多个分类器之间的匹配程度。这些度量广泛应用于医学领域，评估医疗治疗和临床试验的有效性，也应用于人工智能领域，量化分类器减少后的近似度。通过一致性度量与黄金标准相比形成的顺序，可以简单地比较不同分类器对黄金标准的一致性。然而，仅通过使用一致性度量的值来评价一种方法的好坏需要一个尺度或显著性指数。尽管文献中对Cohen's kappa提出了某些质量尺度，但它们大多相当原始，且其边界是任意设定的。本文旨在提出一种通用方法来评估任意两个分类器之间一致性值的显著性，并引入了两个显著性指数：一个适用于有限数据集，另一个处理分类概率分布的挑战。此外，本文还解决了评估这些指数的计算挑战，并提出了有效的算法来实现评估。", "innovation": "提出了一个通用方法来评估任意两个分类器之间的显著性，引入了两个显著性指数：一个适用于有限数据集，另一个处理分类概率分布。并改进了评估这些指数的计算方法，提出了高效的算法来实现评估。", "conclusion": "通过对一致性值的显著性评估方法进行研究，引入了新的显著性指数，并且提出了高效的算法来解决相关计算挑战，为分类器评估提供了新的工具和方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.11853", "html_url": "https://arxiv.org/abs/2502.11853", "title": "StructTransform：为安全性对齐的大语言模型构建可扩展的攻击面", "title_en": "StructTransform: A Scalable Attack Surface for Safety-Aligned Large Language Models", "authors": "Shehel Yoosuf,Temoor Ali,Ahmed Lekssays,Mashael AlSabah,Issa Khalil", "background": "本文讨论了针对大语言模型（LLM）对齐的一系列结构转换攻击。这些攻击使用多样化的语法空间编码自然语言意图，从简单的结构格式和基础查询语言（如SQL）到由LLM完全创建的新颖空间和语法。研究表明，简单的攻击已能实现接近90%的成功率，即便是对于最严格的LLM（如Claude 3.5 Sonnet）使用最先进的对齐机制也是如此。此外，通过结合结构转换和现有内容转换来改进攻击效果，最终取得了超过96%的成功率（ASR）且没有拒绝记录。研究还探讨了多种结构格式，包括由LLM生成的纯语法格式，并且结果显示这些新颖的语法是容易生成的且能实现高成功率，表明防御这些攻击不是一个简单的过程。现有安全对齐防护大多依赖于基于词元模式的方法，未能识别有害概念，凸显了需要在这一方向进行更为深入的研究。通过案例研究，展示了如何使用这些攻击轻松生成样本恶意软件和伪造的短信内容，这些内容能够在逃避检测方面表现出色。", "innovation": "本文首先展示了通过不同语法空间进行自然语言意图编码的结构转换攻击。其次，提出了结合结构转换和现有内容转换的方法，显著提高了攻击成功率，并开发了一个基准测试来评估现有的安全对齐防御措施的效果。研究结果表明，现有的安全对齐防御大多依赖于基于词元模式的方法，未能识别有害概念，具有重大的研究意义。最后，通过案例研究，展示了如何使用这些攻击轻松生成样本恶意软件和伪造的短信内容，进一步展示了这些攻击的有效性。", "conclusion": "现有安全对齐大多依赖于基于词元模式的方法，未能识别有害概念，表明需要在这一方向进行更为深入的研究。同时，这些攻击展示了LLM对齐中的脆弱性，攻击者可以利用这些方法轻松生成恶意软件和伪造短信，这强调了需要构建更强大的防御策略的重要性。最终的研究结果表明，现有的安全对齐防护大多是无效的，这提出了对改进系统安全性的迫切需求。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01420", "html_url": "https://arxiv.org/abs/2505.01420", "title": "评估前沿模型的隐身与情境意识", "title_en": "Evaluating Frontier Models for Stealth and Situational Awareness", "authors": "Mary Phuong,Roland S. Zimmermann,Ziyue Wang,David Lindner,Victoria Krakovna,Sarah Cogan,Allan Dafoe,Lewis Ho,Rohin Shah", "background": "近期的研究显示，前沿的人工智能模型可能会有自我图谋的行为，这种行为可能与开发者的初衷相违背，且这种图谋行为可能难以被察觉。假设未来更先进的系统中存在此类行为，可能会造成严重的失控风险。因此，对于AI开发者而言，在模型部署前，排除因图谋而导致的风险至关重要。基于上述背景，本论文提出了一套评估方案，旨在检测模型的两项关键能力：隐身能力和情境意识。", "innovation": "论文提出了两项新评估方法来评估前沿AI模型的图谋能力：第一，评估模型绕过监管的能力（隐身），共设计了五个测评项目；第二，评估模型对其自身环境和部署情境的认知能力（情境意识），共设计了十一项测评项目。通过这套评估体系，开发者可以确定模型是否有可能因图谋而造成严重危害。研究报告结果显示，当前的前沿模型在评估中表现正常，没有表现出令人担忧的程度上的隐身或情境意识能力。", "conclusion": "通过执行这些评估，清除掉那些在评估中失败的模型，几乎可以确保这些模型在实际部署中不会通过图谋行为造成严重的危害。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.17857", "html_url": "https://arxiv.org/abs/2504.17857", "title": "使用分布度量优化模拟参数的Spot高性能强化学习", "title_en": "High-Performance Reinforcement Learning on Spot: Optimizing Simulation Parameters with Distributional Measures", "authors": "AJ Miller,Fangzhou Yu,Michael Brauckmann,Farbod Farshidian", "background": "本研究呈现了使用Boston Dynamics的Spot机器人和Spot RL Researcher Development Kit进行低级电机访问的高性能强化学习策略部署的技术细节。这是首次公开演示一个从头到尾的强化学习策略在硬件上的部署，并通过Nvidia IsaacLab提供了训练代码，通过Boston Dynamics提供了部署代码。研究中使用Wasserstein Distance和Maximum Mean Discrepancy来量化硬件和仿真中收集的数据分布差异，以此衡量模拟到现实世界的差距。研究者将这些度量作为Covariance Matrix Adaptation Evolution Strategy中的评分函数，优化未测量或难以测量的Spot参数，从而提高模拟参数的选择质量。该工作描述了他们的方法并公开了代码，以支持使用低级API的未来工作。", "innovation": "首次在Spot硬件上公开演示了端到端的强化学习策略部署，使用了Wasserstein Distance和Maximum Mean Discrepancy来量化解现实差距，并首次将这些度量作为Covariance Matrix Adaptation Evolution Strategy的评分函数来优化模拟参数。这一工作提高了Spot的运动性能，具有多种行走模式，包括飞行阶段，且部署的策略可以在滑腻地面上保持稳定，展示出强大的抗干扰能力和前所未有的敏捷性。同样公开了训练和部署代码，方便未来研究。", "conclusion": "该研究通过使用低级API展示了在Spot上实现高性能强化学习策略部署的方法，并通过公开训练和部署代码，为未来的相关研究提供了宝贵的资源。研究最终展示了利用优化后的模拟参数训练出来的策略在实际应用中表现出的卓越性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12971", "html_url": "https://arxiv.org/abs/2504.12971", "title": "在表达性强的神经架构搜索空间中可移植的替代模型", "title_en": "Transferrable Surrogates in Expressive Neural Architecture Search Spaces", "authors": "Shiwen Qin,Gabriela Kadlecová,Martin Pilát,Shay B. Cohen,Roman Neruda,Elliot J. Crowley,Jovita Lukasik,Linus Ericsson", "background": "神经架构搜索（NAS）面临一个挑战，即在探索能激发架构创新的广阔、表达性强的搜索空间的同时，还需要高效地评估架构以有效搜索这些空间。文章研究基于上下文无关文法的表达性强的NAS搜索空间中的替代模型训练方法，以改善搜索性能，提高搜索效率。", "innovation": "文章展示了i) 使用零成本代理度量和神经图特征（GRAF）或通过微调现成的按需语言模型（LM）训练的替代模型，对架构性能具有强大的预测能力，无论是对内还是对外的数据集；ii) 这些替代模型可以用来过滤新数据集上的不良架构，从而显著加快搜索速度并获得更好的最终性能；iii) 替代模型可以进一步直接用作搜索目标，以实现巨大的速度提升。", "conclusion": "研究表明，基于上下文无关文法的表达性强的NAS搜索空间中的替代模型训练可显著提高搜索效率并获得更好的最终性能，同时能以直接用作搜索目标的形式实现巨大的速度提升。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20697", "html_url": "https://arxiv.org/abs/2505.20697", "title": "神经科学中动态因果图假设生成：利用观察时间序列生成因子模型", "title_en": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "authors": "Zachary C. Brown,David Carlson", "background": "假设生成领域有潜力通过缩小需要进行的干预性研究范围来降低神经科学的成本。现有的机器学习方法可以从复杂数据集中生成科学假设，但许多方法假设因果关系在时间上是静态的，这限制了它们在动态、状态依赖行为系统，如大脑中的应用。虽然有一些技术尝试通过因子模型进行动态因果发现，但它们通常将关系限制为线性模式或施加其他简化假设。", "innovation": "我们提出了一种新的方法，该方法将动态图建模为条件加权超级叠加的静态图，其中每个静态图可以捕获非线性关系。这种方法使识别变量之间复杂的、随时间变化的非线性互动成为可能，超越了传统的线性限制。与基线相比，在一些实验中，我们的方法提高了预测动态因果模式的f1分数约22-28%，有些改进甚至超过了60%。我们还通过一个真实的大脑数据案例研究证明了我们的方法能揭示与特定行为状态相关的联系，为我们揭示神经动力学提供了有价值的见解。", "conclusion": "我们的方法提高了预测神经科学中动态因果模式的准确率，并且在揭示大脑特定行为状态间的关系方面具有显著优势，为理解和探索神经动态提供了新的工具。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07635", "html_url": "https://arxiv.org/abs/2505.07635", "title": "用地平线解释进行图推理", "title_en": "Interpreting Graph Inference with Skyline Explanations", "authors": "Dazhuo Qiu,Haolai Che,Arijit Khan,Yinghui Wu", "background": "图机器学习模型，特别是图神经网络（GNNs），常被用于各种网络分析任务中。尽管如此，GNNs的输出往往难以全面解析。现有的解释方法通常会妥协于单一预定义的解释性度量标准，如保真度，这往往会带来偏颇的、单项的解释。因此，亟需一种方法可以同时优化多种用户的解释性度量标准，以提供更全面的解析。", "innovation": "本文提出了一种新的解释范式——地平线解释，它通过同时优化用户感兴趣的多种解释性度量来解析GNN输出。具体而言，研究人员提出了地平线解释作为一种Pareto集聚义子图集合的概念，并将其形式化为一个多标准优化问题。此外，他们还设计了按洋葱剥皮方法的高效算法，并开发了以增加解释多样性为目标的算法。不仅如此，他们还引入了并行计算策略来扩大地平线解释的规模性。这些方法不仅有效地扩展了图推理系统中的GNN解释的全面性，还提高了其在大规模数据集上的可行性。", "conclusion": "实验结果验证了所提出算法的有效性和可伸缩性。通过实际数据和合成数据，本文展示了解释的质量和算法的性能。地平线解释提高了GNN推理的透明度，为用户提供了更全面的理解。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06231", "html_url": "https://arxiv.org/abs/2506.06231", "title": "向着解释性的特征嵌入比较与对齐", "title_en": "Towards an Explainable Comparison and Alignment of Feature Embeddings", "authors": "Mohammad Jalali,Bahar Dibaei Nia,Farzan Farnia", "background": "尽管文献中已经开发了多种特征嵌入模型，但这些嵌入之间的比较主要集中在它们在分类相关下游应用中的数值性能上。然而，进行可解释的嵌入比较需要首先识别和分析嵌入空间内聚类样本组之间的差异。例如，通过比较不同嵌入模型中的样本聚类情况来识别差异。因此，现有的研究缺乏一个系统的框架来进行这样的嵌入比较和对齐。", "innovation": "本文提出了Spectral Pairwise Embedding Comparison (SPEC)框架，旨在比较嵌入模型并识别它们在聚类参考数据集方面的差异。该方法通过计算两个嵌入得到的核矩阵，并利用差异核矩阵的特征分解检测被两个嵌入模型捕获不同的样本簇。此外，还提供了一种针对这种框架的优化问题，以确保一个嵌入中识别的簇也能在另一个模型中被捕获。这种方法具有可扩展性，计算复杂性与样本大小线性增长，且已通过在大规模数据集（如ImageNet和MS-COCO）上的数值实验进行了验证。", "conclusion": "SPEC框架成功地提供了一种系统的方法来比较和对齐不同嵌入模型，通过检测不同嵌入模型之间的差异样本聚类。结果显示，该方法在大规模数据集上的应用是有效且可扩展的，未来研究可以进一步探索该框架在更多领域中的应用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22768", "html_url": "https://arxiv.org/abs/2505.22768", "title": "多变量德布赖恩图：一种时间序列预测的符号图框架", "title_en": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting", "authors": "Mert Onur Cakiroglu,Idil Bilge Altun,Mehmet Dalkilic,Elham Buxton,Hasan Kurban", "background": "时间序列预测对于基础模型仍然是一个具有挑战性的问题，原因在于时间异质性、高维性和缺乏固有的符号结构。现有的方法难以处理这些复杂性，因此需要新的解决策略来增强时间序列预测的能力。为了应对这些挑战，该研究提出了一种新的编码器DRAGON（Discrete Representation and Augmented Graph encoding Over de BruijN Graphs），它引入了多变量德布赖恩图（MdBGs），将符号表示与神经建模结合，旨在通过网格基于的注意力机制恢复动态上下文。通过在基于CNN的双分支架构中引入一个辅助模块，DRAGON能够将符号、结构感知表示与传统的CNN编码器进行集成，从而提高模型的性能和表达能力。所有为此研究开发的代码可在：this https URL 查找。", "innovation": "该研究提出了DRAGON（Discrete Representation and Augmented Graph encoding Over de BruijN Graphs），这是一种新的编码器，通过引入多变量德布赖恩图（MdBGs），解决了符号表示与神经建模之间的鸿沟。DRAGON将连续输入序列离散化并映射到固定的图结构上，通过图基的注意力机制实现动态上下文恢复。这种新型架构增强了传统CNN编码器的功能，使其能够生成符号意义上的结构感知表示，从而提高时间序列预测的准确性。", "conclusion": "通过将DRAGON编码器集成到基于CNN的双分支架构中，该研究提供了一种新颖的方法来解决时间序列预测中的主要挑战。通过这种集成，模型能够更好地理解时间序列数据中的符号结构和内在关系，从而改进预测性能。所有用于研究的代码已公开发布，以促进进一步的研究和发展。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16341", "html_url": "https://arxiv.org/abs/2505.16341", "title": "长尾元专家在长尾半监督学习中的一枚方钉", "title_en": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning", "authors": "Yaxin Hou,Yuheng Jia", "background": "该论文研究了带有分布不匹配的长尾半监督学习（LTSSL），其中有标签训练数据的类分布呈现出长尾分布，并与未标记数据的分布不符。现有的大多数方法引入了辅助分类器（专家）来表征不同的未标记数据分布并生成伪标签，但这些方法未充分利用不同专家的特点。论文观察到不同专家擅长预测不同样本区间，例如长尾专家擅长预测头部区间的样本，而均匀分布专家则擅长预测中部区间的样本。", "innovation": "提出了一种动态专家分配模块，能够估计样本的类别归属（即头部、中部或尾部类别），并根据估计结果动态为每个样本分配合适的专家来生成高质量的伪标签。同时，该模块在测试阶段也能产生预测结果。此外，研究表明结合不同专家的优势将导致更小的泛化误差界。此外，论文还发现深层特征对头部类别的偏向性更大且具备更强的鉴别能力，而浅层特征则没有这种偏向性但鉴别能力较弱。因此，提出了一种多深度特征融合模块，利用不同深度的特征来减轻模型偏差。", "conclusion": "该方法通过在CIFAR-10-LT、STL-10-LT和SVHN-LT数据集上的综合实验，在各种设置下证明了其有效性。相关代码可以在提供的链接中获取。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01631", "html_url": "https://arxiv.org/abs/2506.01631", "title": "基于梯度的模型指纹提取用于大语言模型相似性检测和家族分类", "title_en": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification", "authors": "Zehao Wu,Yanjie Zhao,Haoyu Wang", "background": "随着大型语言模型（LLMs）在现代应用中的重要性日益增加，未经授权的模型衍生，如微调、合并和再分配，已成为关键的软件工程挑战。与传统软件中已建立的克隆检测和许可合规机制不同，LLM生态系统缺乏有效的方法来检测模型血统并执行许可协议。对于需要衍生作品遵循命名约定以保持归属权的开源模型创建者（如Meta的LLaMA），缺乏技术手段来验证合规性。因此，本文提出了一种基于梯度的指纹提取框架TensorGuard，用于LLM相似性检测和家族分类，以填补这一空白。", "innovation": "TensorGuard提出了一个基于梯度的指纹提取框架，用于LLM相似性检测和分类。该框架通过分析随机输入扰动下张量层的梯度响应来提取模型固有的行为特征，独立于训练数据、水印或特定模型格式，支持safetensors格式，并通过统计分析梯度特征构建高维指纹。这些指纹可以用于任意模型之间的直接相似性评估和未知模型的系统家族分类，通过基于领域知识的簇心初始化进行k-means聚类。实验结果表明，在五个模型家族（Llama、Qwen、Gemma、Phi、Mistral）共计58个模型（8个基础模型和50个衍生模型）上，通过聚类初始化的k-means分类准确率为94%。", "conclusion": "实验结果显示，TensorGuard在五个模型家族中的58个模型上实现了94%的分类准确率，证明了该方法在识别LLM血缘关系和分类方面的有效性。这一创新方法填补了LLM生态系统中存在的监测机制和技术保障缺口，对于保护开源模型创作者的权益具有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21551", "html_url": "https://arxiv.org/abs/2506.21551", "title": "LLM预训练中的grokking在哪里？监测记忆到泛化无需测试", "title_en": "Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test", "authors": "Ziyue Li,Chenrui Fan,Tianyi Zhou", "background": "Grokking现象是在神经网络训练中观察到的，即测试性能在训练损失收敛后仍然持续提高，这种现象使泛化机制和其他新兴能力（如推理）变得神秘。此前的研究通常在少量小型模型上进行数以千计的训练周期，专注于玩具任务或高度特定的任务。本研究首次在大型语言模型（7B参数的OLMoE）的一次预训练过程中考察了checkpoint阶段的grokking情况，评估了泛化性能，并验证了大型基础模型在预训练阶段也可能发生grokking，尽管数据进入grokking阶段的时间不同步。研究还进一步揭示了grokking“涌现的泛化”的机制，通过分析模型内部动力学发现，训练样本路径变得更为结构化和可共享，尽管损失已经收敛，样本路径的复杂性降低，这表明了一种“记忆到泛化”的知识吸收过程，提供了延迟泛化的机械解释。此外，还提出了两个新的度量标准来量化路径距离和单个路径的复杂性，展示出评估下游任务泛化改进的能力。", "innovation": "本研究是首次在大型语言模型的预训练过程中系统地研究grokking现象，通过内部动力学分析揭示了“记忆到泛化”的机制，并提出了新的度量标准，能够不依赖于测试进行泛化性能评估，有助于提供一种有效的监测泛化性能的方法。另外，证明了更结构化的路径可以降低模型复杂性并提高泛化界限，提供了一种新的理论视角。", "conclusion": "本研究首次证实了大型基础模型的预训练过程中也存在grokking现象，发现训练样本路径的进化过程和路径复杂性的变化机制，提出了新的度量标准实现无需测试的泛化监控，理论上证明了更结构化路径对泛化性能的积极影响。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18482", "html_url": "https://arxiv.org/abs/2506.18482", "title": "Reliability-Adjusted Prioritized Experience Replay", "title_en": "Reliability-Adjusted Prioritized Experience Replay", "authors": "Leonard S. Pleiss,Tobias Sutter,Maximilian Schiffer", "background": "传统的经验回放方法（如Prioritized Experience Replay, PER）通过优先采样那些学习潜力较高的经验来提高在线强化学习代理的学习效率。然而，这些方法通常基于经验的相对重要性来调整采样的概率，而不考虑这些经验的时间差误差的可靠性。本文考察了这种采样方法，并发现基于时间差误差可靠性的新度量可以进一步提高学习效率，从而提出了一种新的改进方法Reliability-adjusted Prioritized Experience Replay (ReaPER)。", "innovation": "本文提出了一种新的经验回放策略ReaPER，通过引入时间差误差可靠性的新度量来更有效地选择经验。理论分析表明，ReaPER能够比PER更高效地学习。实验证明，ReaPER在多种环境类型（例如Atari-10基准）中表现优于PER，证明了其在实际应用中的优越性。", "conclusion": "Reliability-adjusted Prioritized Experience Replay (ReaPER)通过改进经验回放的策略，提供了更可靠的时间差误差估计，从而提高了强化学习算法的学习效率。实验结果表明，ReaPER在不同的环境设置中都表现出了比PER更好的性能，证明了其方法的有效性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00307", "html_url": "https://arxiv.org/abs/2505.00307", "title": "Gateformer: 通过门控表示的时间和变量注意力推进多元时间序列预测", "title_en": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations", "authors": "Yu-Hsiang Lan,Eric K. Oermann", "background": "最近，使用Transformer架构进行时间序列建模引起了广泛关注。然而，使用Transformer进行多变量时间序列预测具有独特挑战，因为需要同时处理跨时间（cross-time）和跨变量（cross-variate）依赖关系。尽管基于Transformer的模型因其能够灵活捕捉时空序列和跨变量关系而受到青睐，但在Transformer架构中如何最佳地结合这两种信息源，同时优化性能和效率尚不清晰。我们重新利用Transformer架构，有效建模跨时间和跨变量依赖关系。这种方法首先独立嵌入每个变量，以便捕捉其跨时间动态，然后通过注意力机制使用学习到的嵌入建模跨变量依赖关系。在跨时间和跨变量建模阶段均使用门控操作以调控信息流，使得模型能够对准确预测最相关的特征有所侧重。该方法在13个真实世界数据集中达到了最先进的性能，可以无缝集成到其他基于Transformer和LLM的预测器中，并在原有模型上实现了高达20.7%的性能提升。", "innovation": "我们的方法通过独立嵌入每个变量并利用注意力机制和门控操作，在Transformer架构中有效结合了跨时间和跨变量依赖关系的建模，使模型能够在准确预测时更加关注最相关的特征。这一创新方法不仅提高了模型在不同数据集上的性能，还能够无缝整合到其他基于Transformer和LLM的预测框架中，从而在原有模型上实现了明显性能提升。", "conclusion": "我们提出了Gateformer方法，该方法通过时间注意力和变量注意力机制以及门控表示，重新利用了Transformer架构来有效建模时间和变量依赖关系，并在13个实际数据集上达到了先进的预测性能。通过与原有模型相比，Gateformer展示了显著的性能提升，证明了其在多元时间序列预测中的强大能力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17828", "html_url": "https://arxiv.org/abs/2506.17828", "title": "通过强化学习逐步重新加权和优化冻结的大型语言模型：一种迭代加权-然后优化方法", "title_en": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach", "authors": "Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong", "background": "通过奖励函数对大型语言模型（LLMs）进行微调的方法，如RLHF和DPO，能直接优化模型参数，但这些方法只能在训练时间使用，无法在测试时间改进模型性能，也不适用于模型权重不可用的情况。相比之下，测试时间的方法通过利用奖励函数指导和改进输出质量，不涉及权重更新，但其高推理成本和一次性的指导可能导致输出不理想。就现有方法而言，它们基于不完美的奖励或价值函数，使输出不够优化。因此，研究一种新的方法来解决这些限制是必要的，IRO正是这样的一种方法。", "innovation": "IRO方法是一种强化学习（RL）框架，能够在不调整（冻结的）基础模型参数的情况下，对其进行RL风格的对齐。具体来说，训练阶段包括每轮迭代中从基础模型采样候选，使用当前的价值函数重采样，并训练一个新的轻量级价值函数来指导后续的解码过程。测试阶段使用价值函数通过基于搜索的优化过程来引导基础模型的生成。用户可以使用这种方法在自己的数据集上自行对齐模型，类似于OpenAI的强化学习微调（RFT），但无需访问模型权重。", "conclusion": "IRO方法能够利用价值函数来指引模型生成过程的优化，从而实现对冻结基础模型的RL风格对齐，无需直接修改模型参数，同时提高了测试时间的灵活性，降低了推理成本，并允许用户根据自己的需求对模型进行对齐。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21714", "html_url": "https://arxiv.org/abs/2506.21714", "title": "ODE_t(ODE_l): 在扩散和流模型中缩短时间和长度以实现更快的采样", "title_en": "ODE$_t$(ODE$_l$): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "authors": "Denis Gudovskiy,Wenzhao Zheng,Tomoyuki Okuno,Yohei Nakata,Kurt Keutzer", "background": "最近，连续正则化流（CNFs）和扩散模型（DMs）被研究使用统一理论框架。尽管可以生成高质量的数据点，但采样需要解决具有高计算复杂度的常微分方程（ODE）。大多数现有方法集中在减少采样过程中的时间步骤数量以提高效率。尽管如此，现有的方法基本集中在优化时间步骤上，而在长度维度上的优化较少研究。本研究充分利用了时间和长度两个维度的能力，以实现复杂性和质量之间的动态权衡。", "innovation": "通过将基于Transformer的架构中的模块重新连线来解决随长度变化的内嵌离散ODE。在流匹配训练中利用时间-长度一致性项，从而使得采样可以使用任意数量的时间步骤和Transformer块进行。与前人方法相比，我们的方法在时间维度上无特定求解器依赖，并且降低了延迟和内存使用。在CelebA-HQ和ImageNet上的图像生成实验中，该方法在最高效的采样模式下将延迟降低了最多3倍，高质量采样下的FID分数提高了最多3.5分。", "conclusion": "我们的方法使得采样过程具有更好的灵活性和效率，在任意时间步骤和Transformer块数量下都能实现高质量的生成结果，同时降低了延迟和内存使用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13972", "html_url": "https://arxiv.org/abs/2506.13972", "title": "会员推理攻击作为隐私工具：可靠性和差异性及集成", "title_en": "Membership Inference Attacks as Privacy Tools: Reliability, Disparity and Ensemble", "authors": "Zhiqi Wang,Chengyu Zhang,Yuetian Chen,Nathalie Baracaldo,Swanand Kadhe,Lei Yu", "background": "会员推理攻击（MIAs）对机器学习模型的隐私构成重大威胁，广泛用于隐私评估、审计和机器遗忘。尽管先前的MIAs研究主要集中在性能指标上，如AUC、准确率和低FPR下的TPR，要么通过开发新方法提高这些指标，要么利用这些指标评估隐私解决方案，但这些方法忽略了不同攻击之间的差异。这些差异对MIAs作为一种隐私评估工具的可靠性和完整性具有重要影响。作者发现不同攻击方法之间以及同一方法的不同实例之间的差异对MIAs的可靠性与完整性有重要影响。因此，需要对这些差异进行系统研究，以改进MIAs的应用和评估方法。已有研究要么基于AUC、精度和TPR@低FPR来评估MIAs，未能充分考虑这些差异对评估结果的影响；要么直接开发新方法来提升这些指标，却忽略了评估过程的多样性和差异性带来的挑战；缺乏对这些差异的深入探讨和系统性研究，尤其是基于可靠性和差异性的方法，希望能为隐私评估提供强有力的工具和更加全面的评估方案。", "innovation": "本文提出了一个新颖的框架，通过覆盖度和稳定性分析系统地研究MIAs中不同攻击方法之间的差异。通过广泛的实验揭示了MIAs中存在显著差异及其潜在原因，并讨论了这些差异对隐私评估的广泛影响。此外，本文提出了一个集成框架，利用最先进的MIAs的优势，并考虑其差异，旨在通过这种集成框架不仅构建更强大的攻击工具有助于隐私评估，还为更强大和全面的隐私评估方法提供了理论基础和实践指南。", "conclusion": "本文通过实验证明了MIAs中存在显著差异，并对这些差异进行了深入分析，提出了一个集成框架来利用最优MIAs，通过多途径策略增强了攻击能力，提供了更可靠和全面的隐私评估方法。该集成框架的提出是为了克服现有研究中忽视的差异问题，有助于提高MIAs作为隐私评估工具的有效性和可靠性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22049", "html_url": "https://arxiv.org/abs/2506.22049", "title": "GPAS: 通过梯度保留激活缩放加速大型语言模型预训练的收敛", "title_en": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling", "authors": "Tianhao Chen,Xin Xu,Zijing Liu,Pengxiang Li,Xinyuan Song,Ajay Kumar Jaiswal,Fan Zhang,Jishan Hu,Yang Wang,Hao Chen,Shizhe Diao,Shiwei Liu,Yu Li,Lu Yin,Can Yang", "background": "现代大型语言模型（如LLaMA、Qwen和DeepSeek系列）主要采用预层归一化（Pre-LN）变换器架构。这种架构在预训练过程中稳定，并能够扩展到大型模型规模，但随着层数增加，激活函数的方差呈指数增长，导致残差连接中的捷径路径控制了子层输出，限制了深层学习层的学习能力。", "innovation": "为了缓解这个问题，我们提出了梯度保留激活缩放（GPAS），这是一种简单技术，可以与现有方法结合使用。GPAS通过降低中间激活值但保持梯度不变来工作。这保留了激活中的信息，并避免了梯度折旧导致的梯度消失问题。广泛的实验显示，GPAS在从71M到1B的各种模型规模下都能实现一致的性能提升。此外，GPAS还展示了其在改良Sandwich-LN和DeepNorm等其他架构方面的潜力，证明了其在各种训练动态中的多样性和改进潜力。", "conclusion": "我们的代码已在GitHub仓库中提供。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23799", "html_url": "https://arxiv.org/abs/2506.23799", "title": "KAIROS：可扩展的模型无感知的数据估值", "title_en": "KAIROS: Scalable Model-Agnostic Data Valuation", "authors": "Jiongli Zhu,Parjanya Prajakta Prashant,Alex Cloninger,Babak Salimi", "background": "训练数据不仅影响模型的准确度，还影响监管合规性和AI资产的市场估值。目前，现有的估值方法仍然不够完善：基于模型的方法依赖于单个拟合模型，因而继承其偏见；算法基于的方法如Data Shapley需要大规模重训练，成本高昂。基于沃特森距离的模型无感知方法依赖于近似，对样本的真实单个排除（LOO）效用排序有误。因此，需要一种新的估值框架来提高准确性和效率。", "innovation": "KAIROS提出了一种可扩展且模型无感知的数据估值框架，每个样本分配一个分布性影响分数：该样本对经验训练分布与干净参考集合之间的最大均值差异（MMD）的贡献。与沃特森替代相比，我们的MMD方法拥有封闭形式解，准确近似LOU排序，无需重训练，并能自然扩展到条件内核中统一的标签和特征错误检测。此外，KAIROS支持高效在线更新：当新批次大小为m时，所有评分可在O(mN)时间更新，增加50倍速度而不影响排序质量。实验显示，KAIROS在准确性和运行时上均优于最先进的基于模型、Shapley和沃特森方法。同时，理论分析给出严格的保证，包括对称性以实现可重复排序，密度分隔以保证解释性门槛。", "conclusion": "KAIROS为数据估值提供了一种有效且准确的方法，无论是准确度还是效率都大大提升，同时保证了算法的可解释性和可重复性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00736", "html_url": "https://arxiv.org/abs/2507.00736", "title": "离散级别问题难度估计中的序数性：引入平衡DRPS和OrderedLogitNN", "title_en": "Ordinality in Discrete-level Question Difficulty Estimation: Introducing Balanced DRPS and OrderedLogitNN", "authors": "Arthur Thuy,Ekaterina Loginova,Dries F. Benoit", "background": "近年来，自然语言处理技术在问题难度估计（QDE）方面引起了广泛关注。问题难度通常使用离散级别表示，使得任务归结为序数回归，因为存在从最容易到最难的自然顺序。然而，现有文献忽视了任务的序数性质，依赖分类或离散回归模型，尽管专门的序数回归方法尚未被探索。此外，评估指标与建模范式紧密结合，阻碍了不同研究之间的比较。尽管一些指标未能考虑到难度级别之间的序数结构，但没有一个指标能够有效解决类别不平衡问题，从而导致性能评估失真。", "innovation": "这项研究通过使用平衡的离散排名概率分数（DRPS），一个新指标，同时捕捉序数性和类别不平衡性，对三种类型的模型输出（离散回归、分类和序数回归）进行了基准测试。此外，提出了扩展自计量经济学的有序逻辑模型到神经网络的OrderedLogitNN方法，并在RACE++和ARC数据集上微调了BERT，发现OrderedLogitNN在复杂任务上显著优于传统模型。平衡的DRPS为离散级别QDE提供了一个稳健且公平的评估指标，为未来的研究提供了坚实的理论基础。", "conclusion": "平衡的DRPS是一个适应性强且公平的离散级别QDE评估指标，能准确描述难度级别间的序数性和类别不平衡性。OrderedLogitNN的提出为序数回归应用提供了新的技术和思路，在复杂任务上的表现尤为突出。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01041", "html_url": "https://arxiv.org/abs/2507.01041", "title": "快速边缘网络中的AI模型拆分", "title_en": "Fast AI Model Splitting over Edge Networks", "authors": "Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin(Sherman)Shen", "background": "Split Learning (SL) 作为一种计算高效的AI模型训练方法，能够减轻设备端的计算负担，但复杂的AI模型结构会导致高计算复杂性，难以实现最优的模型拆分。本文将任意AI模型表示为有向无环图(DAG)，并将其最优模型拆分问题重新表述为最短s-t割搜索问题。", "innovation": "提出了一种基于DAG的快速模型拆分算法，通过重新结构化DAG，利用最大流方法识别最优模型拆分。同时，对于具有块结构的AI模型，提出了一种块级模型拆分算法，将每个块抽象为单个顶点，从而通过简化后的DAG实现最优模型拆分，理论分析表明该算法是高效的。", "conclusion": "提出的算法能够在毫秒级内确定最优模型拆分，相比于最先进的基准，在动态边缘网络中将训练延迟减少了24.62%-38.95%。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00920", "html_url": "https://arxiv.org/abs/2507.00920", "title": "不同精度下的Privacy-Preserving Quantized Federated Learning", "title_en": "Privacy-Preserving Quantized Federated Learning with Diverse Precision", "authors": "Dang Qua Nguyen,Morteza Hashemi,Erik Perrins,Sergiy A. Vorobyov,David J. Love,Taejoon Kim", "background": "联邦学习（FL）作为一种分布式机器学习的有前途的范式，允许多个本地设备协同训练全局模型而无需共享原始数据。尽管FL有了进步，但它仍然受到隐私风险（如本地模型更新未受保护地传输到融合中心（FC））和参与设备模型量化分辨率异质性导致的学习效用降低的限制。现有研究通常仅解决其中一个挑战，因为同时维护在隐私风险和量化异质性下的学习效用是一项艰巨的任务。本文旨在改善一种保护隐私的FL的学习效用，该FL允许具有不同量化分辨率的设备集群在每个FL轮次中参与。", "innovation": "引入了新型随机量化器（SQ），该量化器旨在同时实现差分隐私（DP）和最小量化误差。提出的SQ保证了有界的失真，与其他DP方法不同。为了应对量化异质性，介绍了集群大小优化技术和线性融合方法来提高模型聚合精度。", "conclusion": "数值仿真证明了该方法在保护隐私和提高学习效用方面优于传统LaplaceSQ-FL算法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22821", "html_url": "https://arxiv.org/abs/2506.22821", "title": "四十年的人类迁移深度学习", "title_en": "Deep learning four decades of human migration", "authors": "Thomas Gaskin,Guy J. Abel", "background": "本文介绍了一个包含1990年至现在230个国家和地区每年的起源-目的地迁移流动和存量的全新且详细的数据库。这些估计结果进一步按出生国作了细分，为过去35年的迁移提供了一个全面的视角。此前的研究和估计方法多基于有限的数据和简单的模型，难以捕捉长期的时空相关性，且缺乏对未来研究的支持。本文通过深度递归神经网络（RNN）模型，结合18种涵盖地理、经济、文化、社会和政治信息的协变量，学习和预测这些复杂且长期的影响因素，显著提高了时间分辨率和准确性，为未来的人类迁移研究提供了宝贵资源。", "innovation": "本文创新性地使用深度递归神经网络（RNN），利用18种协变量（如地理、经济、文化、社会和政治信息）学习和预测35年间跨230个国家和地区的迁移流动模式，引入了大量长期时空相关性。通过训练集成神经网络，并将协变量的不确定性通过训练的网络传播，得到了所有估计的置信区间，方便研究者确定最需要额外数据采集的地理区域。该模型在未见过的数据集上进行了验证，证明了其既显著优于传统估计多年份流动的方法，又能提供更高的时间分辨率。该模型全开源，包括培训数据、神经网络权重和培训代码，所有相关数据和代码均免费提供给未来的研究者，方便数据共享与复现。", "conclusion": "本文构建的包括出生国在内的全球迁移流动数据集提供了过去35年的详细迁移图景。所建立的深度递归神经网络模型能够学习复杂且长期的时空相关性，有效提升了迁移预测的准确性和时间分辨率，并为未来迁移研究提供了高质量的公开资源。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01201", "html_url": "https://arxiv.org/abs/2507.01201", "title": "超越洞穴之喻：JAM框架实现独立训练的视觉和语言模型对齐", "title_en": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "authors": "Hyoseo(Lauren)Yoon,Yisong Yue,Been Kim", "background": "独立试训的视觉和语言模型存在于各自的表示空间中，这种分离是由各自的模态特性、目标和架构塑造的。尽管如此，一项新兴假设——柏拉图式的表示假设——认为这些模型可能仍然趋于共享现实的统计模型。如果这种兼容性存在，它提出了一个基本问题：是否可以超越事后统计对齐检测，而是明确地在这些分离表示之间优化对齐？", "innovation": "作者提出了Joint Autoencoder Modulator (JAM)框架，这是一种多目标优化任务，旨在同时保存每种模态的固有结构并促进互相关性。该框架通过重建和跨模态目标鼓励对齐。作者通过对比对比损失、对比损失的硬负例变体以及他们提出的分散损失，评估了对齐目标的有效性；探讨了对齐最为有效的层深度；研究了基础模型规模对表示趋同的影响。实验结果表明，该轻量级的高效率框架可以可靠地诱导对齐，即使在冻结的独立训练表示中也是如此，提供了从通用单一模态基础模型转变为专家多模态模型的理论见解和实际路径。", "conclusion": "该研究通过提出JAM框架，在不影响冻结和独立训练的表示时，实现了视觉和语言模型的对齐，这对于理论和实践都有重要意义。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2212.05050", "html_url": "https://arxiv.org/abs/2212.05050", "title": "通过算法重访不稳定的公式定理", "title_en": "The unstable formula theorem revisited via algorithms", "authors": "Maryanthe Malliaris,Shay Moran", "background": "本文研究了模型理论中的稳定性理论结果与机器学习中的算法稳定性之间的意外互动。传统的学习模型存在缺陷，当前研究引入了Pec（很可能最终正确）这一新的统计学习模型来弥补现有的不足。文章探讨了小林石（不稳定）类在该模型中的特性，表明这些类在自然的统计意义上经常有简短的定义。", "innovation": "本文的创新之处在于提出了Pec（很可能最终正确）这一新的学习模型，并对小林石（不稳定）类进行了重新定义。通过构建一个等价定理，展示了多种现有近似算法和新Pec模型之间的共同特征，这一过程受到了模型理论中类型定义的启发。此外，作者还通过新的算法构建了一个与Shelah不稳定的公式定理相媲美的全算法类比版本，突显了算法性质的重要性。", "conclusion": "小林石类在Pec模型下有频繁且短小的定义，并且通过一个等价定理，我们能够更好地理解这些类在算法环境下的特性。本文提出了一个涉及算法性质的完整全算法类比版本的不稳定公式定理。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.09511", "html_url": "https://arxiv.org/abs/2311.09511", "title": "使用对称不变自回归水库计算机识别具有对称性的系统", "title_en": "Identifying Systems with Symmetries using Equivariant Autoregressive Reservoir Computers", "authors": "Fredy Vides,Idelfonso B. R. Nogueira,Gabriela Lopez Gutierrez,Lendy Banegas,Evelyn Flores", "background": "该研究聚焦于利用对称不变自回归（equivariant autoregressive）水库计算机识别具有对称性的系统。首先，文章探讨了结构矩阵近似理论的一般结果，采用两步方法。第一步是对守恒对称性的非线性时间延迟嵌入进行全面研究，即分析用于研究的对称系统的时间序列数据。第二步是应用稀疏最小二乘方法以识别输出耦合矩阵的近似表示，这些矩阵对于确定对称性守恒系统的非线性自回归表示至关重要。矩阵的结构特征由系统固有的对称性定义。文章还阐述了从描述技术中获得的典型算法，揭示了它们的应用前景。研究强调了与经典水库计算方法相比，用对称不变自回归水库计算机进行对称动力系统模拟时结构识别精度的显著提高", "innovation": "研究提出了一种通过对称不变自回归水库计算机来识别具有对称性的系统的新方法。该方法结合了结构矩阵近似理论与稀疏最小二乘方法，创新性地处理了时间序列数据和输出耦合矩阵的表示。通过这种方法，研究提高了对称动力系统识别的精度，超越了传统的经典水库计算方法", "conclusion": "该论文详细介绍了通过对称不变自回归水库计算机识别具有对称性的系统的原理和应用，强调了新型方法在提高识别精度方面的显著优势。这种方法提供了一种在模拟对称动力系统时更有效的工具，展示了对未来研究的启示作用"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.13840", "html_url": "https://arxiv.org/abs/2306.13840", "title": "超越规模：自然语言数据变异性数据质量度量的多样性系数", "title_en": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data", "authors": "Brando Miranda,Alycia Lee,Sudharsan Sundar,Allison Casasola,Rylan Schaeffer,Elyas Obbad,Sanmi Koyejo", "background": "当前，大型语言模型（LLMs）的预训练主要集中在模型和数据集规模的扩大上。虽然公认的高质量预训练数据对于训练强大的LLMs非常重要，但数据质量的定义仍然是模糊的，尚未得到充分的定量化研究。因此，本文旨在通过引入多样性系数来正式定义数据质量的一个关键方面，即自然语言数据的变异性。", "innovation": "本文提出了多样性系数作为衡量自然语言数据变异性的一种正式方法。通过实验分析表明，提出的多样性系数与自然语言数据的直观变异性特性相符，例如，随着潜在概念数目的增加，多样性系数增加。文章还对开源的预训练数据集进行了多样性系数的测量，并发现它们的正式多样性远高于理论上限和下限。最后，通过与GPT-2和LLaMAv2的控制实验，验证了预训练数据的多样性系数可以反映下游模型评估性能的有用方面。", "conclusion": "研究表明，正式定义的数据多样性是一项重要指标，能够捕捉数据的变异性，并且对提高下游模型评估性能有因果关系。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2105.13440", "html_url": "https://arxiv.org/abs/2105.13440", "title": "非负矩阵分解算法通常能提高主题模型的拟合效果", "title_en": "Non-negative matrix factorization algorithms generally improve topic model fits", "authors": "Peter Carbonetto,Abhishek Sarkar,Zihao Wang,Matthew Stephens", "background": "虽然有多篇论文探讨了非负矩阵分解（NMF）与主题模型之间的联系，但尚未有人提出利用这些联系开发新的算法来拟合主题模型。NMF算法避免了主题模型参数的‘和为一’约束，简化了优化问题的结构并提高了计算效率。基于最近在NMF优化算法方面取得的进步，本研究展示了首先解决NMF问题然后再恢复主题模型拟合，可以显著提高拟合效果，并在更短的时间内完成。该研究主要关注最大似然估计法，也展示了这种方法对主题模型的变分推断有改进效果。", "innovation": "本文提出了一种新颖的方法，即将非负矩阵分解算法应用于主题模型参数估计，通过先解决NMF问题然后恢复主题模型拟合，这种方法不仅优化了参数估计，还提高了计算效率。此外，该方法还能改进主题模型的变分推断。", "conclusion": "这种方法显著提高了主题模型的拟合效果，并且计算时间较短。研究结果已经实现了该方法的R包fastTopics。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2210.09228", "html_url": "https://arxiv.org/abs/2210.09228", "title": "PDE联合反演问题的模型一致数据驱动计算策略", "title_en": "A Model-Consistent Data-Driven Computational Strategy for PDE Joint Inversion Problems", "authors": "Kui Ren,Lu Zhang", "background": "从观察数据中同时重构偏微分方程（PDEs）中的多个物理系数的任务在实际应用中非常普遍。现有的方法通常是数据驱动或基于模型的一种，但很少有方法能够将两者结合起来进行联合反演，特别是在未知系数存在补充数据的情况下，这些补充数据能够显著提高重构结果的质量。因此，本文提出了一个结合数据驱动和模型导向的迭代重构框架，用于解决这种联合反演问题，旨在利用补充数据提高基于模型的重构过程的一致性和模型驱动的数据建立过程的一致性.", "innovation": "提出了一种新的计算策略，该策略结合了数据驱动和模型导向的方法，通过将补充数据与PDE模型耦合，使得数据驱动建模过程与模型导向的重构程序相一致，并对两种典型的逆问题的影响进行了分析。该方法能有效利用补充数据改善偏微分方程多个系数的联合反演.", "conclusion": "通过数值证据表明，使用数据驱动模型可以提高偏微分方程多个系数的联合反演可行性，展示了该方法的有效性和潜力，为解决复杂的联合反演问题提供了一种新的途径."}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01551", "html_url": "https://arxiv.org/abs/2507.01551", "title": "以重新定义的步长优势进行引导的过程奖励优化", "title_en": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "authors": "Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua", "background": "过程强化学习（PRL）展示了在增强大量语言模型（LLMs）的推理能力方面的显著潜力。然而，引入额外的过程奖励模型会导致显著的计算开销，并且缺少在过程层面上的优势估计的统一理论框架。这些不足阻碍了PRL的进一步发展和应用。", "innovation": "文章提出了Self-Guided Process Reward Optimization（SPRO）框架，通过两个关键创新解决了上述问题：（1）证明过程奖励可以内在地从策略模型本身推导而来；（2）引入了明确定义的累计过程奖励和Masked Step Advantage（MSA），以在共享提示采样组内实现严格的步骤级动作优势估计。", "conclusion": "实验结果显示，SPRO相比vanilla GRPO提高了3.4倍的训练效率并获得了17.5%的测试准确率改进。SPRO在整个训练过程中保持了稳定的高策略熵，同时减少了平均响应长度约1/3，证明了足够的探索并防止了奖励作弊的情况。值得注意的是，SPRO相比监督结果的RL方法如GRPO没有增加额外的计算开销，有利于工业应用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01381", "html_url": "https://arxiv.org/abs/2507.01381", "title": "分布式的软演员-评论家与扩散策略", "title_en": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": "Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li", "background": "强化学习已被证明在处理复杂控制任务方面非常有效。传统的强化学习方法通常使用高斯等单模分布来建模价值分布输出。然而，这些单模分布容易造成价值函数估计偏差，导致算法性能不佳。因此，需要开发一种能够更好地估计价值函数偏差并获得多模态策略表示的分布强化学习算法。该论文提出了一种新的分布强化学习算法DSAC-D（分布式软演员-评论家与扩散策略），在引入策略熵和价值分布函数的基础上建立了多模态分布策略迭代框架，这种方法能够收敛到最优策略。通过使用反向采样生成奖励样本并构建扩散价值网络，可以更准确地表示多峰分布，从而提出了双扩散值网络和策略网络的分布强化学习算法。", "innovation": "该算法通过引入策略熵和价值分布函数，建立了多模态分布策略迭代框架，能够收敛到最优策略。提出了双扩散价值网络和策略网络的分布强化学习算法。通过MuJoCo测试任务表明，该算法不仅能够学习多模态策略，还能在9个控制任务中达到最先进的（SOTA）性能，偏差估计显著降低，平均总回报提高超过10%。通过真实车辆测试表明，DSAC-D能够准确描述不同驾驶风格的多模态分布，扩散策略网络能够刻画多模态轨迹。", "conclusion": "实验结果表明，DSAC-D算法可以有效地处理价值函数的偏差估计问题，还能学习到多模态策略，并在MuJoCo和真实车辆测试中展示了优越性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.05920", "html_url": "https://arxiv.org/abs/2408.05920", "title": "基于图的城区预训练与提示：一种城区表示学习框架", "title_en": "Urban Region Pre-training and Prompting: A Graph-based Approach", "authors": "Jiahui Jin,Yifan Song,Dong Kan,Haojia Zhu,Xiangguo Sun,Zhicheng Li,Xigang Sun,Jinghui Zhang", "background": "城市区域表示对于众多城市下游任务至关重要，尽管已经有许多方法并且取得了很好的效果，但获得通用的城市区域知识并适应不同任务仍然是一个挑战。现有工作对城市区域中的细粒度功能布局语义关注有限，限制了它们跨区域捕捉可转移知识的能力。此外，不同下游任务所需的独特特征和关系处理不足也可能阻碍任务的有效适应。", "innovation": "我们提出了一种基于图的城区预训练与提示框架（GURPP），旨在捕捉混合的并可转移的实体交互模式。具体来说，我们首先构建了城市区域图并开发了一种子图为中心的城市区域预训练模型，以通过对比学习和多视图学习方法获取知识丰富的区域嵌入。为进一步精炼这些表示，我们设计了两种基于图的提示方法：一种根据具体任务定义的手动提示，用于整合显式任务知识；另一种可学习提示，用于发现隐藏知识，以增强这些嵌入对不同任务的适配性。", "conclusion": "通过对多种城区预测任务和不同城市的大量实验，我们的框架展示了优越的性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.05766", "html_url": "https://arxiv.org/abs/2405.05766", "title": "关于XAI系统用户信任的新度量方法", "title_en": "Towards a Novel Measure of User Trust in XAI Systems", "authors": "Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Manuel González-Hidalgo,Adel Ghazel,Maria Gemma Sempere Campello,Juan Antonio Palmer Sancho", "background": "近年来，深度学习模型在各个领域中的应用越来越广泛，但由于这些模型本身的不透明性，引起了人们对模型决策过程的不信任。为了解决这一问题，并增强用户对自动系统的信任，一种新的研究领域——可解释AI（XAI）正在兴起。XAI方法旨在通过提供关于模型决策背后的见解来提高最终用户对自动系统的信任程度。本文延续了这一研究趋势，提出了一种新型的度量方法，以评估用户对XAI系统的信任度。这种新方法结合了客观视角下的性能指标和信任指标，通过三种案例研究证明其有效性，提高了对不同场景的敏感度和改进了与现有最先进的方法相比的表现。", "innovation": "本文提出了一个新的评估用户对XAI系统信任度的度量方法。该方法综合了包括性能指标和信任指标在内的客观指标，并通过实验证明了其在不同场景下的敏感性和优越性，相比现有方法有显著改进。", "conclusion": "通过三个案例研究，本文证明了提出的新度量方法不仅能够有效评估用户对XAI系统的信任度，还能提高对不同场景的敏感度，相较于现有的方法在性能方面有所改进。未来的研究将致力于进一步优化此度量方法，以更好地服务实际应用需求。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.03133", "html_url": "https://arxiv.org/abs/2407.03133", "title": "使用潜在类别分析量化多组内的跨部门交叠差异以实现公平性", "title_en": "Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness", "authors": "Yingfang Yuan,Kefan Chen,Mehdi Rizvi,Lynne Baillie,Wei Pang", "background": "当前，公平的人工智能（Fair AI）的发展越来越受关注。'不落下任何一个人'倡议强调了在利用服务、资源和机会的过程中需要解决多种形式的不平等，特别是在决策过程中越来越多地使用人工智能工具，如资源分配和公共服务方案开发，特别是在健康、能源和住房等各个领域。因此，在这些领域中探索交叉不平等对于全面理解整体不平等和不公具有重要意义。本文利用潜在类别分析提出了一种新的方法来量化用户定义组之间的跨部门交叉差异，并通过对比分析等方式验证了这种方法的有效性。", "innovation": "本文提出了一个创新的方法，使用潜在类别分析来量化多家定义组之间的跨部门交叉差异。这种方法能够用来近似评估不平等，并为解决公平性问题提供有价值的见解。研究使用了包括自有数据集和Census 2021（英格兰和威尔士）数据集等多套数据来进行交叉部门交叉差异的验证和分析。", "conclusion": "研究结果表明，不同少数族裔组之间以及少数族裔组与非少数族裔组之间存在显著差异。这强调了在政策制定过程中需要采取针对性的干预措施。此外，提出的这种方法还可以帮助确保机器学习系统的公平性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.14727", "html_url": "https://arxiv.org/abs/2311.14727", "title": "针对旅游领域新型数据集进行多语言社交内容分析的最优策略", "title_en": "Optimal strategies to perform multilingual analysis of social content for a novel dataset in the tourism domain", "authors": "Maxime Masson,Rodrigo Agerri,Christian Sallaberry,Marie-Noelle Bessagnet,Annig Le Parc Lacayrelle,Philippe Roose", "background": "社交媒体平台在旅游等多个领域的影响力日益增加，这突显出高效且自动化的自然语言处理（NLP）策略的重要性，以充分利用这一宝贵资源。然而，如何将多语言、非结构化和非正式文本转换为结构化知识依然存在许多挑战，其中一个主要挑战是对深度学习分类器进行训练时需要不断更新的手动标注数据。本文旨在研究不同的NLP技术，以期找到能取得优越性能且对标注数据依赖最少的技术。为此，我们构建了首个公共多语言数据集，包括法国、英语和西班牙语在旅游方面的推文，涵盖了旅游相关的位置实体识别和细粒度主题概念提取，以及推文级别的情感分析等标注内容。通过对比各种少样本和微调技术与现代语言模型的实验，结果显示现代少样本技术能在最少标注数据的情况下取得所有任务的竞争力结果：情感分析需5条每类标注推文（总计15条），位置实体识别需30条标注推文，细粒度主题概念提取需1000条标注推文（基于315类的序列标注任务）。", "innovation": "本文的主要创新点在于：1）构建了首个用于旅游领域的多语言数据集；2）评估了不同的NLP技术和现代少样本技术；3）展示了在有限标注数据条件下，少样本技术能取得较好的性能，从而减少对人工标注数据的依赖，规避基于规则的手动解决方案的复杂性。", "conclusion": "本研究为我们展示了一种利用新技术减少人工标注需求的方法，为将NLP应用于特定领域的新应用铺平了道路，并且精度达到可接受的水平，从而降低了这些领域的进入门槛和成本。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.04318", "html_url": "https://arxiv.org/abs/2408.04318", "title": "深转移学习在肾癌诊断中的应用", "title_en": "Deep Transfer Learning for Kidney Cancer Diagnosis", "authors": "Yassine Habchi,Hamza Kheddar,Yassine Himeur,Mohamed Chahine Ghanem,Abdelkrim Boukabou,Shadi Atalla,Wathiq Mansoor,Hussain Al-Ahmad", "background": "不可治愈的疾病对全球医疗保健系统构成了重大挑战，其发病率受到生活方式、经济、社会和遗传因素的影响。其中，肾病仍然是一个重要的全球健康问题，需要持续的研究来改善早期诊断和治疗。最近几年，深度学习（DL）在医疗成像和诊断方面展现出了潜力，推动了自动肾癌（KC）检测的重要进展。然而，DL模型的成功非常依赖于高质量、特定领域的数据集，这些数据集往往有限且昂贵。此外，DL模型需要大量的计算能力和存储空间，限制了其在临床中的实际应用。为了克服这些障碍，转移学习（TL）作为有效的方法已经出现，它能够利用相关领域中预先训练好的模型来增强KC诊断。", "innovation": "本文对基于深度学习的转移学习框架在肾癌检测中的应用进行了全面的回顾，系统地回顾了关键方法、其优势和局限性，并分析了其实际性能。进一步讨论了应用转移学习到医疗成像中的挑战，并指出了影响未来研究的新兴趋势。该综述突显了转移学习在精准医疗（尤其是肿瘤学领域）中的变革性作用，通过提高诊断准确性、降低计算需求和支持AI驱动工具在医疗中的整合，改进了肾癌诊断。", "conclusion": "本文的研究结果为研究人员和实践者提供了宝贵的指导，为未来肾癌诊断和个性化治疗策略的进步铺平了道路。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.03977", "html_url": "https://arxiv.org/abs/2409.03977", "title": "利用双向离散过程匹配方法实现双模态医学图像合成", "title_en": "Bi-modality medical images synthesis by a bi-directional discrete process matching method", "authors": "Zhe Xiong,Qiaoqiao Ding,Xiaoqun Zhang", "background": "近年来，随着生成模型的快速发展，医学图像合成越来越受欢迎。医学图像合成旨在从其他已观察到的数据模态中生成未获取的图像模态，常用于辅助临床诊断、模型训练和验证的数据增强及图像质量改善。流形基模型因其生成逼真且高质量合成图像的能力而成为成功的生成模型，但由于合成过程中需要计算大量时间迭代的流普通常微分方程(ODE)，其性能受到计算时间限制。", "innovation": "本文提出了一种新的流形基模型——双向离散过程匹配(Bi-DPM)，专为双模态图像合成任务设计。Bi-DPM利用前向和后向ODE流，并在若干离散的时间步骤中增强中间图像的一致性，从而在成对数据的指导下，保持在两种模态下均生成高质量的图像。实验结果显示，Bi-DPM在三个MRI T1/T2和CT/MRI数据集上比其他最先进的流形基方法表现更优，提供更高质量的图像，伴有序列解剖区域的精确性。", "conclusion": "本研究提出的Bi-DPM方法有效解决了传统流形基模型在双向图像合成中的计算时间限制问题，通过双向流匹配和时间步骤间中间图像的一致性增强，提高了图像合成质量并获得了优越的结果。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.07386", "html_url": "https://arxiv.org/abs/2408.07386", "title": "衰减记忆与卷积定理", "title_en": "Fading memory and the convolution theorem", "authors": "Juan-Pablo Ortega,Florian Rossmannek", "background": "文章引入了几种关于因果性和时不变滤波器的拓扑和分析意义上的连续性和衰减记忆的概念，并分析了这些概念之间的关系。研究证明了一个关于卷积定理的重要推广，它将衰减记忆性质与线性滤波器的卷积表示的可用性等同。这一结果将之前的类似特征扩展到衰减记忆性质的定义的各种加权范数中。", "innovation": "提出了一种卷积定理的显著推广，表明可用卷积表示不仅可以用衰减记忆性质来描述，还可以用两个纯粹的拓扑性质来描述，即最基本的连续性和最基本的衰减记忆性质。当输入空间和线性泛函的取值域为希尔伯特空间时，研究还表明，最基本的连续性和最基本的衰减记忆性质保证了相关的再生核希尔伯特空间嵌入的存在性。", "conclusion": "文章通过引入新的数学概念和证明重要的理论结果，扩展了对线性滤波器性质的理解，特别是在衰减记忆性和卷积表示方面。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.06902", "html_url": "https://arxiv.org/abs/2407.06902", "title": "从众包噪声标签学习：信号处理的视角", "title_en": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective", "authors": "Shahana Ibrahim,Panagiotis A. Traganitis,Xiao Fu,Georgios B. Giannakis", "background": "随着人工智能（AI）和机器学习（ML）的进步，大规模、整理好的数据集的可用性起了关键作用。众包是生成这类大规模数据集的常用技术，其中数据被分发给多个标注者，标注者产生的标签随后用于辅助下游学习和推理任务。然而，由于标注者的专业知识有限或不可靠等原因，标注过程常常会产生噪声标签，因此众包的核心目标之一是开发有效的方法来减轻这种标签噪声对学习任务的负面影响。", "innovation": "本文回顾了信号处理（SP）理论和方法与众包模型之间的联系，如张量可识别度和非负矩阵分解，并介绍了最新的解决方案来解决众包中的长期挑战。文章强调了信号处理视角在这一领域的发展，并讨论了直接偏好优化（DPO）和强化学习带有人类反馈的众包（RLHF）等新兴主题，这些是先进AI/ML系统的关键技术。", "conclusion": "本文重点介绍了从噪声众包标签学习的关键进展，从经典统计模型到最近的深度学习方法，并强调了信号处理视角对这一领域发展的推动作用，展望了未来在AI/ML领域的重要性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.06416", "html_url": "https://arxiv.org/abs/2409.06416", "title": "探索大型语言模型在工业测试维护过程中的集成", "title_en": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes", "authors": "Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg", "background": "在软件测试过程中，大量时间和精力用于测试维护，如新增、删除或修改测试案例以保持测试套件与被测试系统同步或提高其质量。工具支持可以通过自动化测试维护过程的部分操作或为开发人员提供指导和支持来降低成本并提高质量。本研究旨在探索大型语言模型（LLMs）在支持测试维护方面的能力和应用，包括在工业环境中部署LLMs时需要考虑的问题和相应的多智能体架构的构建与应用。", "innovation": "本研究探索了大型语言模型在工业测试维护过程中的应用，识别出触发测试维护需求的指标，并展示了可以在代码变更后预测需要维护测试的多智能体架构。这些贡献推动了大型语言模型在工业测试维护过程中的理论与实践理解。", "conclusion": "这些成果推进了对于如何利用大型语言模型改善工业测试维护过程的理论和实践理解。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.07079", "html_url": "https://arxiv.org/abs/2408.07079", "title": "脑成像的解剖基础模型", "title_en": "Anatomical Foundation Models for Brain MRIs", "authors": "Carlo Alberto Barbano,Matteo Brunello,Benoit Dufumier,Marco Grangetto", "background": "深度学习在神经影像学中的应用日益增加，用于检测神经疾病和神经退行性疾病。脑年龄是神经影像学中最主要的生物标志物之一，已被证明是诊断不同疾病的良好指标，如阿尔茨海默病。在处理不同疾病稀缺数据时，利用脑年龄进行弱监督预训练的深度学习模型也取得了显著成果。此外，脑MRI的解剖学信息（例如，皮质厚度）可以提供有关学习良好表示的重要信息，这些表示可以被转移到许多下游任务中。因此，本工作旨在提出一种解剖学基础模型AnatCL，它在弱对比学习方法中利用了解剖信息，并在多个下游任务中达到了最先进的性能。通过对阿尔茨海默病、自闭症谱系障碍和精神分裂症等不同疾病的诊断和预测10种不同临床评估评分进行验证，研究表明结合解剖信息进行预训练可以产生更稳健和泛化的表示。", "innovation": "提出了一个名为AnatCL的脑MRI解剖学基础模型，该模型利用解剖信息在弱对比学习方法中进行预训练，从而在多个不同下游任务中实现了最先进的性能。此外，该研究通过多种疾病的诊断和预测任务，验证了该模型的有效性，表明了结合解剖信息进行预训练可以提高模型的泛化能力。", "conclusion": "实验结果表明，结合解剖信息进行预训练有助于获得更稳健和泛化的表示。提出的AnatCL模型在多个下游任务中达到了最先进的性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.18624", "html_url": "https://arxiv.org/abs/2409.18624", "title": "无监督认知", "title_en": "Unsupervised Cognition", "authors": "Alfredo Ibias,Hector Antona,Guillem Ramirez-Miranda,Enric Guinovart,Eduard Alarcon", "background": "无监督学习方法受到认知模型的软启发。至今为止，最成功的无监督学习方法主要集中在数学空间内对样本进行聚类。现有研究主要关注于通过聚类方法在数学空间内表示输入数据，但是缺乏一种构建性地表示输入空间且不依赖于输入特性的方法。本文对一种基于要素的新的无监督学习方法进行了研究，这种方法受到了一种新颖认知框架的启发，旨在通过构建性地表示输入空间而构建出一种分布式层次结构。该方法与当前最先进的无监督分类方法、当前最先进的小且不完整的数据集分类方法以及当前最先进的癌症类型分类方法进行了比较，证明了与这些方法相比的优越性。", "innovation": "该方法引入了一种新的无监督学习框架，这种方法能够将输入空间在不依赖于输入特性的情况下构建性地表示为分布式层次结构。与当前最先进的无监督分类方法相比，这种方法不仅性能更佳，而且表现出更接近人类认知的行为模式。", "conclusion": "研究结果表明，与当前的尖端无监督学习分类方法相比，该方法在性能上取得了显著的优越性，并且在一些认知特性方面表现出了不同寻常的行为。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10530", "html_url": "https://arxiv.org/abs/2410.10530", "title": "无需自适应内存需求的自适应概率ODE求解器", "title_en": "Adaptive Probabilistic ODE Solvers Without Adaptive Memory Requirements", "authors": "Nicholas Krämer", "background": "近年来，尽管在概率求解器领域取得了显著进展，能够采用自适应步长的求解器仍然无法有效解决高内存需求的微分方程问题，尤其是当我们致力于整个时间序列而非单一时间点时。自适应步长的不确定性导致内存需求难以预测，从而超出机器的处理能力，导致模拟意外失败。去除自适应性虽能解决问题，但这会放弃过去数年的研究进展，行不通。因此，该领域面临一个困境：如何既能保持自适应性又不增加内存需求？", "innovation": "本文提出了一种新的方法来解决这一困境。该方法基于近期稳健状态估计的发展，构建了一种具有固定内存需求的自适应概率求解器。这种方法可以实现以下改进：（i）解决了长时序的内存问题；（ii）通过即时编译加速了模拟计算，提升了若干数量级；（iii）使自适应概率求解器能够兼容使用JAX进行的科学计算。这一方法在高性能计算领域是一个重要的创新，实现了自适应性与内存控制之间的平衡。", "conclusion": "本文开发的自适应概率求解器克服了传统求解器的缺陷，不仅解决了内存需求的难题，还提高了求解效率，并且兼容于现代科学计算环境，如JAX，为解决复杂动力学系统的求解问题提供了新的思路。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.08290", "html_url": "https://arxiv.org/abs/2409.08290", "title": "重新评估脉冲神经网络的能效", "title_en": "Reconsidering the energy efficiency of spiking neural networks", "authors": "Zhanglu Yan,Zhenyu Bai,Weng-Fai Wong", "background": "尽管脉冲神经网络（SNNs）由于其基于事件的脉冲计算方式，在理论上能比传统量化人工神经网络（QNNs）更节能，但现有的能量评估往往只关注计算方面，而忽略了如数据传输和内存访问这样的关键开销。这意味着，现有评估可能未能准确反映SNNs的真实能效优势。为纠正这一偏差，该研究构建了一种公平的基线，使得率编码的SNN与功能等效的QNN在表示能力和硬件需求上具有可比性。研究还引入了一个详细的能量模型，涵盖核心计算和数据传输两个方面，并全面探索了不同参数设置下的能效表现，从而为设计真正节能的神经网络解决方案提供了指导。", "innovation": "该研究提供了SNN和QNN的公平对比基线，通过详细的能量模型，全面评估了SNNs在不同参数设置下的能效表现，特别是在神经形态硬件条件下，确定了SNNs表现出显著能效优势的具体操作区间。", "conclusion": "研究表明，在典型的神经形态硬件条件下，具有适度时间窗口（$T \remarks [5,10]$）的SNNs，在脉冲速率（$s_r$）低于6.4%时，能够超越等效的QNNs。这一发现有助于指导设计真正节能的神经网络解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.00903", "html_url": "https://arxiv.org/abs/2410.00903", "title": "利用生成式人工智能进行因果表示学习：应用于文本作为处理", "title_en": "Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments", "authors": "Kosuke Imai,Kentaro Nakamura", "background": "本文探讨如何通过利用生成式人工智能（GenAI）的强大力量来增强对于未结构化高维处理（如文本）的因果推断的有效性。传统的因果推断方法在处理未结构化文本数据时可能会遇到局限性，例如难以有效地生成和处理这些数据。本文提出了一种新的基于生成式模型（如大型语言模型）的方法，可以更有效地生成处理并利用它们的内部表示来进行后续的因果效应估计。这种方法有望改善对特定情感和主题等治疗特征与潜在未知共变量的区分，从而提高因果推断的准确性和效率。此外，该文还使用工具变量方法扩展了解决方案，使之适用于基于人类感知的处理特征，进一步增强了其适用范围和灵活性。", "innovation": "本文的主要创新点包括：1) 提出了一种利用大型语言模型生成处理并使用其内部表示来进行因果效应估计的新方法；2) 正式确立了无参数平均因果效应识别所需的条件；3) 提出了一种避免违反覆盖假设的估算策略；4) 通过双机器学习方法推导了所提出估计器的渐近性质；5) 使用生成的文本数据进一步验证了该方法的有效性及其与最新因果表示学习算法的优越性；6) 为包括人类感知为基础的处理特征的应用场景扩展了现有的方法。", "conclusion": "本文提出了一种名为GenAI-Powered Inference (GPI) 的新型方法，通过利用生成式人工智能技术在处理未结构化高维数据（如文本）的因果推断中取得显著的进展。这种方法不仅提高了因果效应估计的准确性和效率，还在多种应用场景中展示了其优势。未来的研究可以进一步探索该方法在不同类型文本及其他高维数据集中的应用，以及如何进一步优化生成模型以提高其性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.15582", "html_url": "https://arxiv.org/abs/2409.15582", "title": "概念转移下的泛化与专业化", "title_en": "Generalization vs. Specialization under Concept Shift", "authors": "Alex Nguyen,David J. Schwab,Vudtiwat Ngampruetikorn", "background": "机器学习模型在分布转移下通常表现脆弱，即测试数据分布与训练数据分布不同。理解这种失败模式对于识别和减轻大规模采用机器学习的安全风险至关重要。本文对在概念转移下岭回归模型进行分析，这是一种测试时输入-标签关系发生变化的分布转移形式。通过推导出在热力学极限下的预测风险精确表达式，阐明了概念转移对泛化性能的影响，提出了弱概念转移和强概念转移的相变现象，以及当双重下降现象不存在时，测试性能随数据依赖的非单调性变化。这些理论结果与基于预训练Transformer解决线性回归的实验结果相吻合，展示了在概念转移中，过长的上下文长度可能对下一个标记预测的泛化性能产生负面影响。最后，通过MNIST和FashionMNIST数据集的实验表明，这种有趣的行为在分类问题中也存在。", "innovation": "本文通过推导岭回归在概念转移下的预测风险在热力学极限下的精确表达式，揭示了概念转移对泛化性能的影响，包括强弱概念转移的相变现象和非单调的数据依赖性。这些理论结果与基于预训练Transformer解决线性回归的实验结果相吻合，展示了在概念转移中，过长的上下文长度可能对下一个标记预测的泛化性能产生负面影响。", "conclusion": "本文的研究结果与基于预训练Transformer解决线性回归的实验结果相吻合，展示了在概念转移中，过长的上下文长度可能对下一个标记预测的泛化性能产生负面影响。同时，通过MNIST和FashionMNIST数据集的实验表明，这种有趣的行为在分类问题中也存在。这突出表明理解并缓解概念转移带来的风险对于大规模采用机器学习至关重要。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.11074", "html_url": "https://arxiv.org/abs/2412.11074", "title": "адаптер-усиленное семантическое промптинг для непрерываетого обучения", "title_en": "Adapter-Enhanced Semantic Prompting for Continual Learning", "authors": "Baocai Yin,Ji Zhao,Huajie Jiang,Ningning Hou,Yongli Hu,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi", "background": "持续学习（CL）使模型能够适应不断变化的数据流。CL的主要挑战是灾难性遗忘，新的知识会覆盖住之前学到的知识。传统方法通常需要保留过去的数据用于回放，或者在模型中添加额外的分支来学习新知识，这需要较高的内存需求。本文即针对这一挑战，希望通过一种轻量级的持续学习框架来改善这一情况。", "innovation": "本文提出了一种新型轻量级持续学习框架——Adapter-Enhanced Semantic Prompting (AESP)，该框架将prompt tuning和adapter技术结合。作者设计了引导语义的提示以增强视觉特征的泛化能力，并且利用adapter高效融合语义信息，旨在为持续学习任务学习更适应的特征。此外，作者还开发了一种新颖的匹配机制用于提示选择，以便为特征适应选择正确的任务提示。", "conclusion": "通过在三个持续学习数据集进行的大量实验，作者展示了其方法在多个指标上取得了优越的表现，表明其在推进持续学习方面的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.08589", "html_url": "https://arxiv.org/abs/2412.08589", "title": "SPACE-SUIT: 一种基于人工智能的色球特征提取和分类工具", "title_en": "SPACE-SUIT: An Artificial Intelligence Based Chromospheric Feature Extractor and Classifier for SUIT", "authors": "Pranava Seth,Vishal Upendran,Megha Anand,Janmejoy Sarkar,Soumya Roy,Priyadarshan Chaki,Pratyay Chowdhury,Borishan Ghosh,Durgesh Tripathi", "background": "太阳紫外成像望远镜(SUIT)载于Aditya-L1卫星上，用于观察太阳光球和色球结构。深入理解色球和光球结构的等离子体和热力学性质需要大量的样本统计研究，这需要开发自动特征检测方法。该研究开发了一种用于自动检测和分类SUIT的Mg II k滤镜观测到的色球特征的算法。", "innovation": "该研究开发了一种名为SPACE-SUIT（Solar Phenomena Analysis and Classification using Enhanced vision techniques for SUIT）的算法，用于检测和分类由SUIT观测到的色球特征。该算法利用YOLO神经网络模型识别感兴趣区域，并通过统计测量和Tamura特征进行自我验证，展示了统计指标和Tamura特征在区分色球特征有效性的独立验证能力。", "conclusion": "该研究不仅开发了一种色球特征提取器，还展示了统计指标和Tamura特征在区分色球特征的有效性，为未来的检测方案提供了独立验证方法。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06946", "html_url": "https://arxiv.org/abs/2412.06946", "title": "基于深度学习的二元黑洞波形数值相对论代理模型", "title_en": "A Deep Learning Powered Numerical Relativity Surrogate for Binary Black Hole Waveforms", "authors": "Osvaldo Gramaxo Freitas,Anastasios Theodoropoulos,Nino Villanueva,Tiago Fernandes,Solange Nunes,José A. Font,Antonio Onofre,Alejandro Torres-Forné,José D. Martin-Guerrero", "background": "引力波近似器是引力波天文学不可或缺的一部分，它们能够在无需昂贵的数值相对论模拟的情况下覆盖二元黑洞参数空间，进行推断或匹配滤波，但通常会牺牲一定的准确性以换取计算效率。为了减轻这种权衡，可以通过在数值相对论波形空间内进行插值来构建基于数值相对论的代理模型。本文介绍了一种两阶段训练方法，用于基于神经网络的数值相对论代理模型。", "innovation": "该研究采用了一种两阶段训练方法来训练基于神经网络的数值相对论代理模型。首先，模型在由近似器生成的波形上进行初始训练，然后使用数值相对论数据进行微调。这种方法生成的模型可以在几毫秒内生成数百万个波形，同时保持与数值相对论数据的均方差在约$10^{-4}$，并能够在GPU上快速且准确地生成波形，满足参数估计任务的需求，提高了计算效率和准确性之间的平衡。", "conclusion": "这些双重阶段的人工神经代理（DANSur）模型被集成到\textsc{bilby}框架中，证明了它们可以用于参数估计任务，展示了高度的计算效率和竞争力的准确性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05451", "html_url": "https://arxiv.org/abs/2410.05451", "title": "SecAlign：利用偏好优化防御提示注入攻击", "title_en": "SecAlign: Defending Against Prompt Injection with Preference Optimization", "authors": "Sizhe Chen,Arman Zharmagambetov,Saeed Mahloujifar,Kamalika Chaudhuri,David Wagner,Chuan Guo", "background": "大型语言模型（LLMs）在现代软件系统中越来越普遍，它们在用户与互联网之间充当接口，帮助完成需要高级语言理解的任务。为了完成这些任务，LLM通常使用外部数据源，例如用户文档、网络检索、API调用结果等。这为攻击者提供了一种利用提示注入机制来操控LLM的新途径。攻击者可以通过在外部数据源中注入提示来覆盖系统的意图指令，从而执行恶意指令。为了缓解这一漏洞，本文提出了一种名为SecAlign的新防御机制，基于偏好优化技术。SecAlign首先构建了一个包含注入提示输入、安全输出（即响应合法指令）和不安全输出（即响应注入）的数据集。然后对这个数据集进行偏好优化，以教导LLM优先选择安全输出而非不安全输出。这提供了一种已知可以降低各种提示注入成功率的防御方法，即使攻击比训练期间所见的更为复杂，其成功率也低于10%。这表明该防御机制可以很好地应对未知和未来可能出现的攻击。同时，在我们的评估中，SecAlign模型的实用性与防御性训练前相当，保持了类似的性能和效率。", "innovation": "SecAlign 防御机制通过偏好优化技术，利用引导优化的数据集教导大型语言模型（LLM）优先选择安全输出。这种方法能在面对比训练中更为复杂和未知的攻击时，显著降低各种提示注入的成功率至低于10%。该机制提供了首个显著降低提示注入攻击成功率的研究成果，且在保持模型实用性和效率方面表现良好。", "conclusion": "SecAlign 展现了其在防御提示注入攻击方面的优越性能，甚至在面对未知和复杂攻击时也能保持较低的成功率。该研究为应对当前及未来可能出现的攻击提供了全新的视角和方法。SecAlign模型在不影响模型效果和效率的情况下提供了强大的防御能力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.19688", "html_url": "https://arxiv.org/abs/2411.19688", "title": "SURE-VQA: 系统化理解医学VQA任务中鲁棒性评估", "title_en": "SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks", "authors": "Kim-Celine Kahl,Selen Erkan,Jeremias Traub,Carsten T. Lüth,Klaus Maier-Hein,Lena Maier-Hein,Paul F. Jaeger", "background": "视觉语言模型（VLMs）在医疗任务如视觉问答（VQA）中具有巨大潜力，能够作为患者和临床医生的交互式助理。然而，这些模型在未见数据上的鲁棒性仍是一个关键问题，这影响了其安全部署。当前的评估方法未能提供充分的评估，因此需要一种能系统分析VLMs鲁棒性的新框架。研究指出，现有的评估方法在模拟变化和实时变化之间的鲁棒性不一致，传统的方法在捕捉潜在语义方面也存在问题，同时也不易解释模型的表现。因此，需要一个新框架来解决这些问题并系统地评估VLMs的鲁棒性。", "innovation": "本文提出了一种新的框架——SURE-VQA，针对医疗VQA任务提出了三个关键要求以解决现有评估方法的问题：1）测量鲁棒性不应限于合成变化，而应关注与VQA数据相关的实际世界变化；2）需要使用大型语言模型（LLMs）来更准确地评估潜在语义，而不能仅依赖传统令牌匹配指标；3）报告有意义的基准线以提高模型性能的可解释性，而不是缺少类似的基准线。SURE-VQA框架通过三种类型的分布变化在三个医疗数据集上评估了各种微调（FT）方法的鲁棒性，揭示了几个关键洞见并展示了其重要性。", "conclusion": "通过SURE-VQA框架，研究发现没有一种微调方法能始终在鲁棒性上胜出，不同微调方法之间的鲁棒性趋势比不同分布变化下的趋势更为稳定。此外，简化的基准在不使用图像数据的情况下也能表现良好，而LoRA方法在同分布数据上表现最好。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08496", "html_url": "https://arxiv.org/abs/2501.08496", "title": "量化下游模型性能中数据对齐的重要性", "title_en": "Quantifying the Importance of Data Alignment in Downstream Model Performance", "authors": "Krrish Chawla,Aryan Sahai,Mario DePavia,Sudharsan Sundar,Brando Miranda,Elyas Obbad,Sanmi Koyejo", "background": "以往的研究通常更注重数据集的大小，而忽视了数据质量中的一个关键因素——数据对齐。本文探讨了数据对齐在训练强大语言模型中的作用，特别是在下游任务中的表现受训练数据与评估数据对齐程度的影响。通过使用基于Task2Vec的数据对齐系数来量化对齐程度，研究发现对齐系数越高，模型在下游任务中的表现损失和困惑度越小，尤其是在针对特定领域的任务如自动形式化中，数据对齐的重要性更为突出。这一发现表明需要重新评估当前的模型训练方法，强调数据对齐的重要性，而不是仅仅重视数据量的增加。", "innovation": "研究引入了基于Task2Vec的数据对齐系数作为定量衡量两个数据集之间相似性的指标，用于评估训练数据与评估数据的对齐程度对下游任务性能的影响。研究通过控制实验，在预训练与评估数据集之间的对齐以及特定领域微调与评估之间的对齐两个设置下，验证了数据对齐对模型性能的具体影响。特别地，探讨了自动形式化任务，进一步突出数据对齐的重要性", "conclusion": "研究结果表明，数据对齐对模型在下游任务中的表现具有显著影响，特别是在特定领域任务中，说明了数据对齐对于优化模型性能的必要性，强调了在训练语言模型时应更加注重数据对齐而非仅关注数据量。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.04614", "html_url": "https://arxiv.org/abs/2501.04614", "title": "XGeM:一种用于多模态医疗数据生成的多提示基础模型", "title_en": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation", "authors": "Daniele Molino,Francesco Di Feola,Eliodoro Faiella,Deborah Fazzini,Domiziana Santucci,Linlin Shen,Valerio Guarrasi,Paolo Soda", "background": "医疗影像中的人工智能应用前景广阔，但数据稀缺、隐私问题以及多模态融合的需要限制了其发展。虽然生成模型的进步使高质量的合成数据生成成为可能，但现有方法通常局限于单一模式或单向合成，无法同时合成多个模态并保持临床一致性。", "innovation": "本文介绍了XGeM，一种6.77亿参数的多模态生成模型，旨在支持医疗数据多种模态之间的任意到任意合成。XGeM通过对抗学习构造共享的潜在空间，并引入了新颖的多提示训练策略，使得模型可以根据任意输入模态的子集进行条件生成，从而适应异构的临床输入并生成多个输出，保持语义和结构的一致性。", "conclusion": "本文通过在MIMIC-CXR数据集上与五个竞争对手进行基准测试，并通过专家放射科医生的视觉图灵测试验证了XGeM的效果。此外，展示了XGeM如何解决医疗数据中的脱敏、类别不平衡和数据稀缺等问题，证明其作为医疗数据合成基础模型的应用价值。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.11554", "html_url": "https://arxiv.org/abs/2412.11554", "title": "临床多组学研究中大规模部分相关网络学习的HP-ACCORD", "title_en": "Learning Massive-scale Partial Correlation Networks in Clinical Multi-omics Studies with HP-ACCORD", "authors": "Sungdong Lee,Joshua Bang,Youngrae Kim,Hyungwon Choi,Sang-Yun Oh,Joong-Ho Won", "background": "多组学数据的图形模型估计需要在统计估计性能和计算可扩展性之间取得平衡。现有方法在这个平衡上存在局限性，本研究旨在解决这一问题，提出了一种新型的伪似然基图形模型框架，该框架重新参数化目标精度矩阵的同时保留稀疏模式，并利用新型损失函数基于$L_1$正则化经验风险进行估计。在高维假设下，所提出的估计器在各种度量中保持估计和选择一致性。相关优化问题可以通过新的分割优化方法和通信避免分布式矩阵乘法实现可验证的快速计算算法。这种高性能计算实现使用模拟数据测试，拥有超过一百万个变量，展示了类似于生物网络的复杂依赖结构。利用这种可扩展性，我们从一种双重组学肝癌数据集中估计了部分相关网络。超高维数据中估计的共表达网络通过剔除表观遗传调节的影响，展示了在优先考虑关键转录因子和共激活因子方面优于其他方法的具体性，从而突显了计算可扩展性在多组学数据分析中的价值。", "innovation": "本研究提出了一种新型的伪似然基图形模型框架，该框架通过重新参数化目标精度矩阵并利用新型损失函数基于$L_1$正则化经验风险进行估计，能够在高维假设下保持估计和选择一致性。与此同时，还提出了新的分割优化方法和通信避免分布式矩阵乘法来实现快速计算算法。这种方法在处理超过一百万个变量的模拟数据时展示了类似生物网络的复杂依赖结构，并成功估计了肝癌数据集中的部分相关网络。", "conclusion": "我们提出的方法在处理超过一百万个变量时展示了出色的性能，特别是在估计生物网络的复杂依赖结构和超高维数据的共表达网络时，相比其他方法具有更高的具体性。该方法的计算可扩展性为多组学数据分析带来了巨大价值。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.05007", "html_url": "https://arxiv.org/abs/2501.05007", "title": "量子增强的小样本因果发现", "title_en": "Quantum-enhanced causal discovery for a small number of samples", "authors": "Yu Terada,Ken Arai,Yu Tanaka,Yota Maeda,Hiroshi Ueno,Hiroyuki Tezuka", "background": "从观察数据中发现因果关系引起了经济学、社会科学和生物学等学科的广泛关注。但在实际应用中，通常缺乏对底层系统的充分了解，且真实数据常常与非线性因果结构相关，这使得许多传统的因果分析方法难以直接应用。", "innovation": "本文提出了一个新型的量子彼得-克拉克（qPC）算法，该算法不需要对底层模型结构做出任何假设。基于由量子电路定义的再生核希尔伯特空间中的条件独立性测试，该算法可以从任意分布中观察到的数据探索因果关系。此外，采用了基于核目标对齐（KTA）的新优化方法来确定量子核的超参数，有效降低了因果发现中的假阳性风险，增强了推断的可靠性。", "conclusion": "理论和实验结果表明，量子算法可以增强经典算法在因果发现中的准确推断能力，尤其是在小样本场景下，经典方法通常会失败。此外，这种方法也在波士顿房价数据集、心脏病数据集和生物信号系统中进行了实际应用验证，有效展示了量子基础的因果发现方法在实践中解决实际挑战的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03383", "html_url": "https://arxiv.org/abs/2501.03383", "title": "人工科学家——在途机器学习的等离子体仿真", "title_en": "The Artificial Scientist -- in-transit Machine Learning of Plasma Simulations", "authors": "Jeffrey Kelling,Vicente Bolea,Michael Bussmann,Ankush Checkervarty,Alexander Debus,Jan Ebert,Greg Eisenhauer,Vineeth Gutta,Stefan Kesselheim,Scott Klasky,Vedhas Pandit,Richard Pausch,Norbert Podhorszki,Franz Poschel,David Rogers,Jeyhun Rustamov,Steve Schmerler,Ulrich Schramm,Klaus Steiniger,Rene Widera,Anna Willmann,Sunita Chandrasekaran", "background": "随着高性能计算（HPC）集群规模的扩大和大规模仿真产生大量数据，分析海量数据带来了巨大的输入输出（IO）和存储挑战。深度学习技术特别利用这些大量领域数据来提取模式，帮助建立科学理解。本文通过直接将仿真数据流式传输到机器学习（ML）框架，绕过了文件系统瓶颈，展示了流式工作流。数据在传输过程中异步进行转换，而不影响仿真或模型训练。这种工作流允许在常用且易于使用的编程语言中执行数据操作，使应用程序用户无需修改输出模式。研究以GPU加速的等离子体粒子（PIConGPU）仿真Kelvin-Helmholtz不稳定性为证明概念，采用经验重放策略防止在持续学习中出现灾难性遗忘。在Frontier超算系统移植和扩展过程中解决了大量挑战。", "innovation": "提出了一种流式工作流，可以直接将仿真数据流式传输到ML框架，绕过了文件系统瓶颈；数据在传输过程中异步进行处理，而不影响仿真或训练过程；采用经验重放策略防止灾难性遗忘，适用于持续学习；利用GPU加速实现高性能仿真；在Frontier超算系统上实现移植和扩展。", "conclusion": "本文展示的流式工作流允许在常用编程语言中直接处理传输中的数据，绕过了文件系统瓶颈，可以更有效地进行数据操作和处理，特别是在大规模仿真产生的海量数据的背景下。通过这种流式处理和GPU加速，可以实现更有效的数据管理和科学研究。经验重放策略成功应对了非稳态过程的学习持续性问题。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03262", "html_url": "https://arxiv.org/abs/2501.03262", "title": "REINFORCE++: 具有对抗提示模型和回报模型鲁棒性的高效RLHF算法", "title_en": "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models", "authors": "Jian Hu,Xibin Wu,Wei Shen,Jason Klein Liu,Zilin Zhu,Weixun Wang,Songlin Jiang,Haoran Wang,Hao Chen,Bin Chen,Weikai Fang,Xianyu,Yu Cao,Haotian Xu", "background": "大规模语言模型（LLMs）通过从人类反馈中强化学习（Reinforcement Learning from Human Feedback, RLHF）和验证回报强化学习（Reinforcement Learning with Verifiable Rewards, RLVR）微调后，显著提高了人类与AI的价值一致性，并进一步提升了AI的能力，尤其是在推理密集型、长上下文链式思考（long-CoT）任务中的表现。然而，现有的RLHF（或RLVR）框架往往会面临诸如推理瓶颈和复杂性障碍等挑战，这限制了新人的可访问性。由于OpenRLHF的成功，作者引入了一个用户友好、可扩展且易于学习的开源OpenRLHF框架，旨在解决这些问题，以便研究人员和从业者可以更轻松地进入该领域。OpenRLHF在不同的模型规模上表现出显著的训练效率提升，同时所需的代码量更少。该框架已经在多个知名机构使用，以加速RLHF研究和学习进程。然而，现有的RLHF和RLVR框架存在一些挑战，例如复杂性障碍和推理瓶颈，这些限制了其对新手的可访问性。", "innovation": "作者提出了OpenRLHF，这是一个基于Ray、vLLM、DeepSpeed和HuggingFace Transformers的用户友好、可扩展且易于学习的开源RLHF框架。它具有简化的设计、清晰的代码结构和全面的文档，旨在降低专家进入领域的门槛。实验结果显示，在不同模型规模下，OpenRLHF相比最先进的框架具有从1.22倍到1.68倍的加速效果，并且实现所需的代码量更少。因此，OpenRLHF不仅提高了训练效率，还简化了该技术的学习和应用过程。OpenRLHF认为，当前的RLHF和RLVR框架存在一些挑战，特别是复杂性和推理瓶颈，阻碍了新手的参与。", "conclusion": "实验结果表明，OpenRLHF不仅在训练效率上表现出显著的提升，并且通过简化设计和清晰的代码结构降低了学习和应用的难度。该框架现已开源，并被多个领先机构采用，以加速RLHF领域的研究和学习进程。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16095", "html_url": "https://arxiv.org/abs/2502.16095", "title": "优秀的表示，更好的解释：卷积神经网络在基于变换器的遥感图像描述中的作用", "title_en": "Good Representation, Better Explanation: Role of Convolutional Neural Networks in Transformer-Based Remote Sensing Image Captioning", "authors": "Swadhin Das,Saarthak Gupta,Kamal Kumar,Raksha Sharma", "background": "遥感图像描述（RSIC）是生成与遥感图像相关的有意义描述的过程，近年来受到了广泛关注。目前，编码器-解码器模型用于生成有意义的描述，其中编码器从输入图像中提取关键视觉特征并将其转换为紧凑的表示，而解码器利用此表示生成连贯的文本描述。尽管解码器在文本生成方面已经被广泛研究，但编码器的优化仍然相对不足，尽管这对于描述的丰富性至关重要，进而影响生成描述的质量。基于此，该研究系统地评估了十二种不同的卷积神经网络（CNN）架构在基于变换器的遥感图像描述框架中的效果，并分析了不同的搜索策略对最佳描述生成的影响。这些评估分为两阶段：首先，基于数值分析将CNNs分为不同的集群；然后，由人工注释员从以人为本的角度对表现最佳的CNNs进行人工评估。", "innovation": "此研究创新地在基于变换器的图像描述模型中系统评估了十二种不同的卷积神经网络（CNN）架构的效果，并进一步分析了搜索策略对最佳描述生成的作用。通过这种详细比较，该研究为理解和改进基于变换器的图像描述模型提供了宝贵的见解。", "conclusion": "此研究强调了编码器选择在提高描述性能方面的重要性，具体CNN架构显著提高了遥感图像生成描述的质量。这项研究为指导基于变换器的遥感图像描述模型的未来发展提供了有价值的见解。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04174", "html_url": "https://arxiv.org/abs/2503.04174", "title": "UniNet: 一种统一的多粒度网络流量建模框架用于网络安全", "title_en": "UniNet: A Unified Multi-granular Traffic Modeling Framework for Network Security", "authors": "Binghui Wu,Dinil Mon Divakaran,Mohan Gurusamy", "background": "随着现代网络变得越来越复杂，受到多样化的设备、加密协议以及不断进化的威胁驱动，网络流量分析变得至关重要。现有的机器学习模型通常仅依赖于数据包或流量的单一表示，限制了它们捕捉分析中关键上下文关系的能力。此外，特定任务的监督、半监督和无监督学习架构导致了在适应不同数据格式和安全任务上的低效率。", "innovation": "本文提出了UniNet，一种统一的框架，引入了一种新颖的多粒度流量表示（T-Matrix），整合了会话层次、流层次和数据包层次的特征，提供全面的上下文信息。结合轻量级的基于注意力机制的T-Attent模型，UniNet能够有效学习用于各种安全任务的潜在嵌入式表示。", "conclusion": "通过实现在四类关键网络安全性与隐私问题（异常检测、攻击分类、物联网设备识别和加密网站指纹识别）上的广泛评估，UniNet表现出显著性能提升，实现了更高的准确性、较低的误报率和改进的扩展性。 "}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03821", "html_url": "https://arxiv.org/abs/2501.03821", "title": "正则化回归中的归一化选择影响缩放", "title_en": "The Choice of Normalization Influences Shrinkage in Regularized Regression", "authors": "Johan Larsson,Jonas Wallin", "background": "在应用正则化模型时，通常需要对数据中的特征进行归一化（包括中心化和缩放），以避免模型对特征尺度敏感。然而，不同归一化方法的选择可能对模型结果产生巨大影响，尽管如此，现有文献并未对此进行充分研究。该研究旨在探讨在lasso、岭回归和弹性网回归等正则化回归模型中归一化选择的影响，并重点研究了二元特征的归一化影响及相应的调整方法。", "innovation": "该研究是首度探讨归一化选择影响正则化回归模型的关键论文。研究发现，二元特征的比例直接影响回归系数，且这种影响取决于所使用的归一化与正则化方法的组合。研究提出，对于lasso回归，使用二元特征的方差进行归一化；对于岭回归，使用其标准差进行归一化，这虽然可以缓解归一化对模型结果的影响，但会导致系数估计量方差增加。对于弹性网回归，建议调整惩罚权重而非特征本身来达到相似的效果。研究还讨论了二元和正常特征混合以及特征交互时的归一化问题，并提供了初步的结果。", "conclusion": "研究结果表明，归一化选择对正则化回归模型具有重要影响，通过适当的归一化方法可以减少归一化对模型的影响，但需要权衡其带来的方差增加等负面影响。研究为正则化回归中的特征归一化提供了具体的指导原则。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07813", "html_url": "https://arxiv.org/abs/2503.07813", "title": "MaizeField3D：一个多样品田间种植玉米的3D点云和过程模型数据集", "title_en": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel", "authors": "Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian", "background": "由于缺乏大规模和多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具的发展，尤其是针对玉米，受到了限制。2D图像数据集无法捕捉到叶序结构、植物体积和空间排列等3D数据能提供的关键结构细节。因此，迫切需要改善现有数据集的不足，以支持农业研究中的3D表型分析和植物结构分析。", "innovation": "该研究提出了MaizeField3D数据集，该数据集包括1,045个高质量的田间种植的玉米3D点云，采用地面激光扫描（TLS）技术收集。这些点云中的520份植物被分割并使用基于图的分割方法进行了注释，以隔离单个叶子和茎，确保所有样品的标签一致。数据集还包括包含植物形态和质量的元数据，以及不同分辨率子采样点云数据（100k, 50k, 10k 点），可以用于不同的下游计算任务。NURBS曲面用于表示过程模型中的玉米叶片，通过结合无导数和有导数方法的两步优化过程生成。数据集还进行了严格的人工质量控制，确保分割准确性，叶序准确性和元数据注释的有效性。", "conclusion": "MaizeField3D将成为AI驱动的表型分析、植物结构分析和农业研究中3D应用的综合基础数据集。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.17772", "html_url": "https://arxiv.org/abs/2501.17772", "title": "通过自举正样本采样的自我监督框架用于语音识别验证", "title_en": "Self-Supervised Frameworks for Speaker Verification via Bootstrapped Positive Sampling", "authors": "Theo Lepage,Reda Dehak", "background": "近年来，自我监督学习（SSL）在语音识别验证（SV）中展示了显著的潜力，但由于与监督系统之间的性能差距仍未解决，因此仍是一个持续的挑战。传统的SSL框架依赖于同一音频片段的锚定正样本对，这种采样策略虽然通过数据增强增加了多样性，但仍将过多关于录音来源的信息编码到了学习表示中，这成为了一个关键限制。本文探讨了这一点，介绍了基于自举正样本采样的自我监督语音识别验证技术（SSPS）.", "innovation": "本文提出了一种名为SSPS的新方法，通过自我监督框架对语音识别验证进行改进。SSPS方法通过在表示空间中靠近其锚点的位置采样，假设这些伪样本属于同一个说话人但处于不同的录音条件。实验在VoxCeleb基准测试上的应用表明，这种方法可以显著提高语音识别验证性能。与SimCLR和DINO相比，使用SSPS后，在VoxCeleb1-O上的EER分别降低了58%，得到了与DINO相当的结果，且训练框架更简单。此外，SSPS还降低了说话人表示内的类内方差，并减少了通道信息，同时在没有数据增强的情况下表现出更高的鲁棒性.", "conclusion": "SSPS方法在多个主流SSL框架上提高了语音识别验证的性能，并且在没有数据增强的情况下表现出更高的鲁棒性。通过这种方法，SimCLR和DINO在VoxCeleb1-O上的EER分别达到了2.57%和2.53%，并且在复杂环境下依然保持了良好的性能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03299", "html_url": "https://arxiv.org/abs/2504.03299", "title": "关于位置-姿态对之间标量化欧几里得不变量的通用集合", "title_en": "Universal Collection of Euclidean Invariants between Pairs of Position-Orientations", "authors": "Gijs Bellaard,Bart M. N. Smets,Remco Duits", "background": "在使用E(3)等变神经网络预测分子动力学和性质等任务时，需要在位置-旋转空间M(3)×M(3)上执行等变卷积操作。通常做法是手工选择一组不变量，然后将这些不变量输入多层感知器来参数化内核。作者对此进行了深入研究，描述了在M(3)×M(3)上的最优集合，该集合由4个平滑标量不变量组成，意味着其独立且通用，能够作为所有不变量内核的函数实现。", "innovation": "作者提供了在M(3)×M(3)上的最优且独立的4个平滑标量不变量集合，这集合具有普遍性，即所有不变量内核都可以通过这些不变量来表达。作者还通过PONITA神经网络架构评估了通用和非通用不变量集合的效果，实验表明使用通用集合显著提高了PONITA模型的准确性.", "conclusion": "研究结果表明，使用通用集合的不变量显著提高了基于位置-旋转对的PONITA神经网络的预测准确性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17597", "html_url": "https://arxiv.org/abs/2502.17597", "title": "使用物理感知神经网络解析粒子暗物质", "title_en": "Unraveling particle dark matter with Physics-Informed Neural Networks", "authors": "M.P. Bento,H.B. Câmara,J.F. Seabra", "background": "本文探讨了使用物理感知神经网络（PINNs）参数求解冻入暗物质（DM）在替代宇宙学中的玻尔兹曼方程的问题。背景信息指出，传统的宇宙学模型与观测数据有更好的匹配，但在某些情境下，如brane世界模型，需要引入更复杂的宇宙学模型。在这种背景下，本文通过逆PINNs方法，利用一个观测到的DM残留密度点来确定理论模型的物理特性，包括幂律宇宙学模型和粒子相互作用截面。特别地，宇宙扩张在这类替代宇宙学中被通过一个在后期时间模仿哈勃定律的开关函数来参数化。本研究试图以更平滑的方式来准确描述这种过渡，从而提高宇宙学模型的现实性。最后，通过贝叶斯方法量化了在逆问题中找到的理论参数的先天不确定性。", "innovation": "本文创新地利用物理感知神经网络解决冻入暗物质的玻尔兹曼方程，通过逆PINNs方法，仅使用一个DM观测点（残留密度）来确定理论模型的物理属性。此外，提出了一个平滑函数来更精确地描述宇宙学模型从一种类型转变为另一种类型的过渡过程，并通过贝叶斯方法量化了理论参数的不确定性。", "conclusion": "本文通过逆PINNs方法成功确定了示范的替代宇宙学模型的物理参数，特别是幂律宇宙学模型和粒子相互作用截面的关系。研究指出，给定宇宙学模型的幂定律指数为负（正），则对应的粒子相互作用截面需要较小（较大）。最后，通过贝叶斯方法测定了理论参数的不确定性，为未来相关研究提供了重要的统计信息。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17046", "html_url": "https://arxiv.org/abs/2503.17046", "title": "HAPI: 一种从人类偏好学习机器人面部表情的模型", "title_en": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences", "authors": "Dongsheng Yang,Qianying Liu,Wataru Sato,Takashi Minato,Chaoran Liu,Shin'ya Nishida", "background": "自动机器人面部表情生成对于人机互动至关重要，但基于固定关节配置的手工制作方法往往会导致僵硬和不自然的行为。尽管最近的自动化技术减少了手动调优的需求，但它们往往未能充分弥合人类偏好与模型预测之间的差距，导致由于自由度有限和感知集成不足，无法生成细腻和现实的表情。", "innovation": "本文提出了一种新颖的学习排序框架，利用人类反馈以解决这一差距，并提升机器人面部的表达能力。具体来说，采用成对比较标注来收集人类偏好数据，并开发了基于Siamese RankNet的人类情感成对印象（HAPI）模型，用于细化表情评估。", "conclusion": "通过贝叶斯优化和在线表情调查，我们的方法在35-DOF的Android平台上生成的愤怒、快乐和惊讶的表情比基线和专家设计的方法更为真实且与人类情感反应更相符，这证明了我们的框架有效地弥合了人类偏好与模型预测之间的差距，同时稳健地使机器人表情生成与人类情感反应相一致。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08061", "html_url": "https://arxiv.org/abs/2503.08061", "title": "无参考的课程学习方法在虚拟现实手部操纵中实现真实的握力控制", "title_en": "ForceGrip: Reference-Free Curriculum Learning for Realistic Grip Force Control in VR Hand Manipulation", "authors": "DongHeun Han,Byungmin Kim,RoUn Lee,KyeongMin Kim,Hyoseok Hwang,HyeongYeop Kang", "background": "现有的虚拟现实（VR）中的手部操作方法通常依赖于运动捕获数据集或基于运动学的方法，这些方法往往忽略了接触力和手指扭矩等关键物理属性，导致这些方法侧重于紧致且通用的手部抓握方式，而非反映用户意欲施加的力的水平。由于缺乏实际的物理模型，用户在进行精细的手部操作时无法体验到真实的力反馈。因此，研究一种能够真实反映用户抓握意图的方法对于提升VR体验至关重要，但现有方法在这方面存在不足。", "innovation": "本文介绍了一种名为ForceGrip的深度学习代理，它能够生成与用户希望施加的力相一致的手部操作运动，实现了对用户握力意图的忠实地反映。与之前的方法不同，ForceGrip通过随机化对象形状、手腕运动以及触发输入流来自动生成训练场景，从而挑战代理处理各种物理交互。此外，通过一个包括手指定位、意图调整和动态稳定三个阶段的课程学习框架，使代理能够逐步学会处理复杂的任务，并确保手部与物体接触的稳定性，适应用户的力控输入，并在动态条件下稳健地操作。", "conclusion": "实验证明，ForceGrip在力可控性和合理性方面明显优于现有最先进的方法。与现有方法相比，ForceGrip能够更加真实地模拟用户的握力意图，并在复杂的互动任务中表现出更好的表现能力。演示视频作为附录材料提供，代码则可访问此链接。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.20808", "html_url": "https://arxiv.org/abs/2504.20808", "title": "SoccerDiffusion: 从比赛录像中学习端到端的类人机器人足球", "title_en": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings", "authors": "Florian Vahl,Jörn Griepenburg,Jan Gutsche,Jasper Güldenstein,Jianwei Zhang", "background": "本文介绍了SoccerDiffusion，这是一种基于变换器的扩散模型，旨在直接从实际比赛录像中学习类人机器人足球的端到端控制策略。模型使用RoboCup比赛数据，从多模态传感器输入中预测关节命令轨迹，包括视觉、本体感受以及比赛状态。尽管高级战术行为有限，但该模型能够在模拟和实物机器人中重复复杂的运动行为，如走路、踢球和摔倒恢复。此外，通过使用简化的蒸馏技术，可以在嵌入式平台上实现实时推理，简化多步扩散过程为单步。", "innovation": "SoccerDiffusion模型结合了多模态传感器数据来预测复杂运动，同时通过蒸馏技术实现了在嵌入式平台上的实时推断。该模型展示了其在模拟和现实机器人中模仿复杂运动行为的能力，为后续的强化学习或偏好优化方法奠定了坚实的基础。", "conclusion": "尽管高级战术行为有限，但该工作提供了一种坚实的框架，可用于进一步的强化学习或偏好优化方法，且已发布相关数据集、预训练模型和代码。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03309", "html_url": "https://arxiv.org/abs/2504.03309", "title": "位置-方向空间M(3)上的旋转-平移不变度量", "title_en": "Roto-Translation Invariant Metrics on Position-Orientation Space", "authors": "Gijs Bellaard,Bart M. N. Smets", "background": "位置-方向空间M(3)上的旋转-平移不变度量在图像分析任务中（如增强、滤波和分割）起着重要作用，这些度量使旋转-平移等变算法成为可能。虽然这些度量相关的黎曼距离在实现方面很有用，但由于计算黎曼距离的高成本，使其不适合在需要持续重新计算的场景中使用。文章提出了一种称为mav（最小角速度）距离的解决方案，这是一种黎曼长度的几何有意义曲线，作为一种实用的替代方案。mav距离在几何深度学习中有应用，神经网络架构如PONITA依赖于几何不变量来构建旋转-平移等变模型。mav距离提供了可训练的不变性，具有决定黎曼度量的参数作为可训练权重。", "innovation": "本文提出了一种称为mav（最小角速度）距离的新颖解决方案，作为黎曼距离的一种实用替代方案。mav距离作为一种黎曼长度的几何意义上可计算曲线，具有可训练的不变性，其中确定黎曼度量的参数作为可训练权重。文章还包括了如何高效计算mav距离，并研究了在其网络架构PONITA中引入mav距离是否能提高预测分子属性的准确性。通过分类和参数化所有旋转-平移不变度量，提出了一种新的计算方法。", "conclusion": "文章通过分类和参数化所有旋转-平移不变度量，并展示了如何高效计算mav距离，并提出将其纳入PONITA网络中，有助于提高其预测分子属性的准确性。mav距离不仅能够为几何深度学习提供新的不变性算法，同时也提供了一种新型的可训练几何不变性，具有重要的实际应用价值。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15075", "html_url": "https://arxiv.org/abs/2505.15075", "title": "跨越语言边境：评估多模态大语言模型的跨语言一致性", "title_en": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": "Hao Wang,Pinzhi Huang,Jihan Yang,Saining Xie,Daisuke Kawahara", "background": "多模态大型语言模型（MLLMs）的快速演进显著增强了它们的实际应用能力。然而，实现跨语言的一致性表现，尤其是在结合文化知识时，仍然是一个重大挑战。本文通过引入两个新的基准测试工具——KnowRecall和VisRecall，以更好地评估这一问题，这两个基准分别用于评估跨语言一致性中的事实知识和视觉记忆一致性。实验结果显示，最先进的MLLMs，包括内部开发的模型，仍然难以达到跨语言一致性。这一结果凸显了需要更稳健的方法来生成真正多语言和文化意识强的模型的需求。", "innovation": "引入了两个新的基准测试工具——KnowRecall和VisRecall，以评估多模态大语言模型的跨语言一致性。KnowRecall是一个用于衡量多语言中关于全球地标的文化与历史知识的一致性的视觉问答基准。VisRecall评估模型在没有图像的情况下描述地标外观的能力，涵盖9种语言。这种方法为评估模型在多种语言中的表现提供了一个新的视角，特别是在文化和视觉记忆方面。", "conclusion": "最先进的多模态大语言模型在跨语言一致性方面仍然存在明显不足，要求开发人员和研究者们进一步改进，以增强模型的多语言和文化意识，从而获得更稳健的表现。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.00494", "html_url": "https://arxiv.org/abs/2504.00494", "title": "Lie群上的流匹配", "title_en": "Flow Matching on Lie Groups", "authors": "Finn M. Sherry,Bart M.N. Smets", "background": "流匹配（FM）是一种近期的生成模型技术，其目的是通过从一个容易采样的分布 $\\mathfrak{X}_0$ 流动到另一个想要采样的分布 $\\mathfrak{X}_1$ 来学习如何进行采样。关键在于这一流场可以在条件概率为终点的情况下进行训练：给定一个终点，只需沿直线移动到终点即可（Lipman et al. 2022）。然而，直线段仅在一个欧几里得空间中定义良好。因此，Chen和Lipman（2023）将该方法推广到了在黎曼流形上进行FM，用测地线或其谱近似来替换直线段。论文中，作者从另一个角度，将FM推广到了Lie群上，用指数曲线替换直线段。这种方法对于许多矩阵Lie群而言可以实现简单、内在且快速的实施，因为所需的Lie群操作（乘法、逆、指数、对数）仅是相应的矩阵操作。FM在Lie群上的应用可以用于一组特征（在 $\\mathbb{R}^n$ 中）和姿态（在某些Lie群中）的数据生成建模，例如等变神经场的潜在代码（Wessels et al. 2025）.", "innovation": "作者提出了将流匹配技术推广到Lie群上，以解决在非欧几里得空间中的采样问题。通过替换直线段为指数曲线，这种方法在许多矩阵Lie群上可以实现简单、内在且快速的实施，对于涉及特征和姿态的数据生成建模尤为重要.", "conclusion": "本文提出了一种将流匹配（FM）推广到Lie群上的方法，该方法能够有效地处理非欧几里得空间中的生成建模任务。利用矩阵操作的方便性，这种方法能够应用于具有特征和姿态的数据生成建模，例如等变神经场的潜在代码。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13112", "html_url": "https://arxiv.org/abs/2505.13112", "title": "基于注意力机制的聚类", "title_en": "Attention-based clustering", "authors": "Rodrigo Maulen-Soto(SU, LPSM (UMR\\_8001)),Claire Boyer(IUF),Pierre Marion(EPFL)", "background": "Transformer作为一种强大的神经网络架构，被广泛用于解决各种学习任务。本文对该架构的自动数据结构提取能力进行了理论分析，特别是在无监督条件下。特别地，该文探讨了它在输入数据由高斯混合模型生成的情况下适用于聚类的能力。文章研究了一个简化版本的双头注意力层，并定义了群体风险，通过未标记数据最小化该风险促使注意力层参数与真实的混合质心对齐，展现了注意力机制在捕捉潜在分布结构方面的潜力。此外，研究还指出，即使不使用任何可训练参数，特定设定的注意力层也能实现输入自适应的量化任务，进一步展示了基于转换器的方法在应对特定输入分布方面的动态适应能力。", "innovation": "本文主要创新点在于：1）探讨了基于注意力机制的两个头注意力层在高斯混合模型生成的数据上的聚类应用；2）定义了群体风险，通过最小化未标注数据来驱动头参数与真实混合质心对齐；3）展示了即使没有训练参数，特定配置的注意力层也能实现输入自适应的量化任务，揭示了基于转换器方法的动态适应能力。", "conclusion": "该研究证明了基于注意力机制的方法在无监督聚类和基于输入特定分布的量化任务上的强大适应性和潜在能力，为该领域的进一步研究提供了新的视角和理论基础。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12552", "html_url": "https://arxiv.org/abs/2504.12552", "title": "使用数字分身进行隐私保护的手术室工作流程分析", "title_en": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins", "authors": "Alejandra Perez,Han Zhang,Yu-Chun Ku,Lalithkumar Seenivasan,Roger Soberanis,Jose L. Porras,Richard Day,Jeff Jopling,Peter Najjar,Mathias Unberath", "background": "手术室（OR）是一个复杂的环境，优化工作流程对于降低成本和提高患者结果至关重要。尽管计算机视觉方法可以用于自动识别围手术期事件并识别OR优化瓶颈，但由于隐私问题，手术室视频的自动化事件检测使用受到限制。我们的目标是提出一种隐私保护的OR视频分析和事件检测的两阶段管道，通过生成匿名的数字分身（DT）和使用SafeOR模型进行事件检测，从而保护隐私同时提高工作效率。", "innovation": "我们提出了一种两阶段的隐私保护手术室视频分析管道：首先利用视觉基础模型进行深度估计和语义分割，生成匿名的数字分身（DT），然后通过SafeOR模型处理分割掩码和深度图来进行OR事件检测。在一项包含38次模拟手术试验和五个事件类别的内部数据集上的评估表明，我们的基于DT的方法与原始 RGB 视频模型的性能相当，有时甚至更好。这表明数字分身可以实现隐私保护的手术室工作流程分析，促进匿名数据在机构间的共享，并可能通过减少领域特定的外观差异来提高模型的泛化能力。", "conclusion": "我们的DT方法在手术室事件检测上具有与原始RGB视频模型相当或更优的性能，同时能够保护隐私。通过使用匿名的数字分身，这种方法为机构间共享数据和提高模型的泛化能力提供了可能。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22502", "html_url": "https://arxiv.org/abs/2505.22502", "title": "评估高斯过程回归中的量子优势", "title_en": "Assessing Quantum Advantage for Gaussian Process Regression", "authors": "Dominic Lowe,M.S. Kim,Roberto Bondesan", "background": "高斯过程回归是一种广为人知的机器学习技术，已有量子算法被提出。然而，该研究证明在广泛的情景下，这些量子算法并没有带来指数级别的加速。作者通过严格证明，在一般的数据和核函数假设下，核矩阵的条件数至少与矩阵大小线性相关。此外，还证明在这种假设下，核矩阵的稀疏性和Frobenius范数也是线性相关的。这些结论对于量子算法的运行时间的影响与将经典数据加载到量子计算机的复杂性无关，并适用于去量子化的算法。作者还通过数值验证对于机器学习中流行的核函数进行了证明", "innovation": "研究展示了在广泛的情景下，量子算法在高斯过程回归中的性能并未表现出指数级别的加速。这主要基于严格的数学证明，关于核矩阵的条件数、稀疏性和Frobenius范数与矩阵尺寸之间的线性关系。这些结论具有广泛的应用，不仅适用于有量子算法的场景，也适用于去量子化的算法", "conclusion": "研究发现，对于高斯过程回归，在给定一般假设的情况下，量子算法并没有带来指数级别的加速。这一结论影响到量子算法的性能分析，並且证明了对于高斯过程回归中的经典数据加载和去量子化算法同样适用。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15854", "html_url": "https://arxiv.org/abs/2506.15854", "title": "通过视觉到文本转换保护连接和自治车辆中的隐私", "title_en": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation", "authors": "Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy", "background": "连接和自主车辆依赖于多种设备，其中道路旁单元（RSU）通过AI配备的摄像头在诸如违规检测等应用中扮演关键角色。尽管如此，捕获的图像数据包含的高度敏感性使得隐私保护成为了严重的问题。传统技术如面部模糊化和遮蔽虽然可以减轻隐私风险，但个体隐私仍然存在风险，因为通过穿着等其他特征仍然可以进行跟踪。", "innovation": "本文提出了一种新颖的隐私保护框架，它利用基于反馈的强化学习（RL）和视觉语言模型（VLMs）将AI摄像头捕获的敏感视觉信息转化为语义等价的文字描述，确保不泄露隐私的同时保留关键场景信息。该框架采用层次化的RL策略逐步优化生成的文字，提高了语义准确性和隐私保护能力。实验结果表明与现有方法相比，在保护隐私和提高文本质量方面有显著改进，独有的词汇数量增加了约77%，详密度提升了约50%。", "conclusion": "该研究提出的方法显著提升了隐私保护效果，同时保持了文本描述的质量，为连接和自主车辆中的隐私保护提供了一种有效的解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09993", "html_url": "https://arxiv.org/abs/2506.09993", "title": "Text-Aware Image Restoration with Diffusion Models", "title_en": "Text-Aware Image Restoration with Diffusion Models", "authors": "Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim", "background": "现有的基于扩散模型的图像恢复方法在自然图像恢复方面取得了巨大成功，但在恢复退化图像中的文本区域时普遍存在忠实地重建文本内容的问题。这些方法经常产生看似合理的但实际上是错误的文本样式的图案，这种现象被称为‘文本-图像幻觉’。", "innovation": "本研究提出了Text-Aware Image Restoration (TAIR)，这是一个既要求恢复视觉内容又要求保持文本准确性的新型恢复任务。为了解决这一任务，作者提出了SA-Text，这是一个包含10万高质量场景图像的大规模基准，这些图像密集标有多种复杂的文本实例。此外，还提出了一种多任务扩散框架TeReDiff，该框架将扩散模型的内部特征集成到文本检测模块中，使得两部分可以从联合训练中受益，从而提取出丰富的文本表示，这些表示在后续去噪步骤中用作提示。实验结果表明，本方法在文本识别准确性方面明显优于现有最先进的恢复方法。", "conclusion": "我们的方法在文本识别准确性方面始终优于最先进的图像恢复方法，实现了显著的性能提升。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18959", "html_url": "https://arxiv.org/abs/2506.18959", "title": "从网络搜索向具有推理代理的深度研究转变：用推理代理激励搜索", "title_en": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "authors": "Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu", "background": "信息检索是现代知识获取的基础，能够每天处理来自不同领域的数十亿次查询。然而，传统的基于关键词的搜索引擎在处理复杂、多步骤的信息需求时变得越来越不足。现有的搜索引擎技术已经从静态的网页搜索进化为交互式、基于代理的系统，这些系统能够规划、探索和学习。", "innovation": "本文提出了一种新的研究范式——Agentic Deep Research（能动深度研究），通过引入自动推理、迭代检索和信息合成的紧密结合，构成一个动态反馈循环。论文还引入了一个测试时的扩展律来形式化计算深度对推理和搜索的影响，通过基准结果和开源实现展示出Agentic Deep Research在性能上显著优于现有方法，并有望成为未来的主导信息检索范式。", "conclusion": "通过行业产品、研究论文、基准数据集和开源实现等资源的收集，证明Agentic Deep Research不仅在性能上超越了现有方法，而且将成为未来信息检索的主要范式。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02068", "html_url": "https://arxiv.org/abs/2507.02068", "title": "软件工程候选人如何准备技术面试？", "title_en": "How do Software Engineering Candidates Prepare for Technical Interviews?", "authors": "Brian Bell,Teresa Thomas,Sang Won Lee,Chris Brown", "background": "软件工程师要想获得就业机会，必须参加技术面试，这是一个涉及候选人边写代码边交流的过程。然而，技术面试的复杂性难以准备，并且很少出现在计算机课程中。因此，研究人员旨在了解候选人如何准备技术面试，调查准备方法的影响以及教育的作用。通过针对131名正在准备技术面试的候选人的调查发现，候选人在实际情况中很少进行培训，而课程未能支持他们的准备，导致他们感到压力大且不充分准备。", "innovation": "本研究通过调查正在准备技术面试的软件工程候选人，深入了解了当前准备方法和教育支持的不足之处，为求职的软件工程师提供了有价值的见解。", "conclusion": "根据研究结果，研究者提出了针对利益相关者的建议，以增强技术面试前的准备，提升应聘软件工程师的准备程度。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23767", "html_url": "https://arxiv.org/abs/2506.23767", "title": "财务报告的全面风险评估中的可解释人工智能：一种轻量级分层变换器网络方法", "title_en": "Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach", "authors": "Xue Wen Tan,Stanley Kok", "background": "每家在美国公开交易的公司都会提交年度10-K报告，其中包含了对公司财务健康和风险的关键见解。现有的研究主要依赖标准差（调整了Fama-French模型后的超额收益的标准差）来进行风险评估，这种评估方法会不区分收益和损失地惩罚风险，从而产生了一定的偏差。本文旨在提出一种轻量级且可解释的变换器模型TinyXRA，该模型能够自动从这些报告中评估公司风险，通过加入偏度、峰度和索提诺比率，使得风险评估更加全面。TinyXRA利用TinyBERT作为编码器来高效处理长篇幅的财务文档，并通过一种新颖的动态、基于注意力的词云机制提供直观的风险可视化方法，筛选出不相关的词汇。这种轻量级的设计保证了能够在各种计算环境中实现大规模部署，并具备实时处理大量财务文件的能力，这对于资源受限的生产系统是至关重要的。", "innovation": "本文创新性地提出了TinyXRA模型，该模型是一种轻量级且可解释的变换器模型，用于自动化评估公司的财务风险。与以往单纯依赖调整后的超额收益标准差的方法不同，TinyXRA模型引入了偏度、峰度和索提诺比率来获取更全面的风险评估。此外，通过使用TinyBERT作为编码器和动态注意力机制的词云机制，模型能够提供直观的风险可视化，并有效过滤无关术语。此外，模型通过三重损失方法（triplet loss）进行风险四分位分类，改进了现有的双重损失方法，在模型解释的透明性和可解释性方面表现出色。实验结果表明，TinyXRA在2013-2024年的多个测试年份上达到最先进的预测准确性。", "conclusion": "本文通过综合方法实现了财务报告的风险评估，并通过一系列严格的消融研究评估了其贡献和模型解释性。研究结果表明，TinyXRA在提供透明的可解释风险评估方面表现出色，适合在资源受限的环境中部署。研究还指出了潜在的局限性并提出了未来研究的方向。所有代码均可从这个链接获取。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22675", "html_url": "https://arxiv.org/abs/2506.22675", "title": "多环境数据的贝叶斯不变性建模", "title_en": "Bayesian Invariance Modeling of Multi-Environment Data", "authors": "Luhuan Wu,Mingzhang Yin,Yixin Wang,John P. Cunningham,David M. Blei", "background": "该论文的背景是探讨如何在多个环境中识别不变特征，这些特征具有稳定预测性，有助于新环境的泛化并揭示因果机制。以往的研究主要通过假设检验或正则化优化来解决此问题，但尚未有效的方法来解决这一问题。", "innovation": "该研究提出了贝叶斯不变预测（BIP），一种用于不变预测的概率模型。BIP将不变特征的索引编码为潜在变量，并通过后验推理恢复它们。此外，为了处理大量特征，还设计了一种高效的变分近似方法VI-BIP。研究表明，BIP和VI-BIP在模拟和实际数据中比现有方法更准确和可扩展。此外，研究证明了后验的一致性和环境异质性更大时后验收缩更快的特性。", "conclusion": "BIP和VI-BIP方法在多环境数据的不变特征预测方面具有显著优势，能够准确地识别具有稳定预测性的特征，有助于新环境的泛化和因果机制的揭示。此外，随着环境差异的增加，后验更倾向于收敛到真正的不变特征。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02825", "html_url": "https://arxiv.org/abs/2506.02825", "title": "不依赖边相关性的渐近完美种子图匹配以及在推理中的应用", "title_en": "Asymptotically perfect seeded graph matching without edge correlation (and applications to inference)", "authors": "Tong Qi,Vera Andersson,Peter Viechnicki,Vince Lyzinski", "background": "本文研究了多图匹配问题，特别是在d维随机点积图（RDPG）的背景下。提出了OmniMatch算法来解决带有种子的多图匹配问题。研究发现，在某些假设下，OmniMatch能有效地对齐多个网络中的节点，即使在网络间不存在边相关性的情况下也能实现近完美的对齐。这在大量模拟实验和洗牌图假设检验中得到了验证，特别是在洗牌假设检验中，由于节点在图间的错误对齐/洗牌导致检验动力丧失，OmniMatch能够纠正这种错误，从而恢复检验的动力。此外，该算法也被应用于连接组学和机器翻译的数据实例中，展示了其实际应用价值和能力。", "innovation": "本文的创新在于提出了一种名为OmniMatch的算法，该算法在不依赖边相关性的前提下，能够实现种子多图匹配的渐近完美对齐。尤其在存在大量的无序节点对齐情况下，仍然能够有效地进行图匹配，这对于实际应用中的复杂网络分析具有重要意义。文章还展示了该算法在多个仿真和实际数据集上的有效性。具体地，它在洗牌图假设检验中能够纠正因节点误对齐导致的检验能力损失，体现出其在实际应用中的优势和潜力。", "conclusion": "研究结果表明，OmniMatch算法能够高效地对齐多图中的节点，即使在网络间没有边相关性的条件下也能实现近乎完美的对齐。该算法在多个模拟和实际数据集上进行了验证，特别是在洗牌图假设检验中成功地纠正了节点误对齐导致的问题，恢复了检验的动力。此外，文章展示了该算法在连接组学和机器翻译等实际应用中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03764", "html_url": "https://arxiv.org/abs/2506.03764", "title": "矩形实矩阵高阶奇异值导数", "title_en": "Higher-Order Singular-Value Derivatives of Rectangular Real Matrices", "authors": "Róisín Luo,James McDermott,Colm O'Riordan", "background": "通过对称算子的解析扰动理论中的约化余反演算子，我们提出了一个理论框架来推导实矩形矩阵中奇异值的一般n次Fréchet导数。这种方法克服了通过标准矩阵分析技术难以获得高阶奇异值导数的困难。通过将实矩形矩阵视为有限维希尔伯特空间上的紧致算子，以及通过嵌入矩形矩阵到块对称算子来捕捉非对称扰动，该研究提供了高阶谱变化的一般闭式表达式。", "innovation": "该研究通过结合算子理论与矩阵分析，提供了一个新的理论框架，用于通过Kato的渐近特征值展开推导出奇异值的高阶导数。利用克罗内克乘积表示和矩阵方法，这些研究发现包括一次和二次的Hessian，这些结果尚不存在文献之中。此外，该框架为研究人员提供了在随机矩阵应用中（例如，深度学习中对抗性扰动）进行高阶谱灵敏度研究的实用工具箱。", "conclusion": "通过将算子理论中抽象的谱变化理论应用于矩阵，该研究的工作提供了一个基础工具，可用于实矩形矩阵的高阶谱变化研究。这种分析方法不仅可以改善对矩阵分析的理解，还可用于评估和强化基于矩阵的应用对抗性攻击的鲁棒性。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23351", "html_url": "https://arxiv.org/abs/2506.23351", "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "title_en": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "authors": "Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yu Chen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu", "background": "研究背景：新兴领域身体化人工智能（Embodied AI）旨在开发能够在复杂物理环境中感知、推理和行动的自主系统。尽管单臂系统已在许多任务中表现出色，但双臂协作系统对于处理涉及刚性、可变形和触觉敏感物体的复杂任务尤为重要。因此，为了促进这一目标，第二届MEIS研讨会在CVPR 2025上发起了RoboTwin双臂协作挑战赛。", "innovation": "创新点：比赛基于RoboTwin模拟平台（1.0和2.0）和AgileX COBOT-Magic机器人平台进行，分为模拟轮次1、模拟轮次2和实地轮次。参赛队伍共完成了17项双臂操作任务，涵盖刚性、可变形和基于触觉的场景。吸引了来自全球的64支队伍和超过400名参与者，展示了如SEM和AnchorDP3等顶级解决方案，并产生了关于通用双臂策略学习的重要见解。", "conclusion": "结论：本次报告总结了比赛的设置、任务设计、评估方法、关键发现和未来方向，旨在支持未来关于稳健和可泛化的双臂操纵策略的研究。该挑战赛网页可在http://提供的链接中访问。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01352", "html_url": "https://arxiv.org/abs/2507.01352", "title": "Skywork-Reward-V2: 通过人机协同扩大偏好评价数据管理", "title_en": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "authors": "Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou", "background": "尽管奖励模型（RMs）在从人类反馈中进行强化学习（RLHF）中扮演着关键角色，但当前最先进的公开奖励模型在大多数现有评价基准上的表现都较差，无法捕捉人类多样而复杂的偏好。即便采用了先进的训练技术，这些方法也没有获得显著的性能提升。我们认为这种脆弱性主要源自偏好评价数据集的局限性，这些数据集往往资源范围狭窄、合成标记或缺乏严格的质量控制。", "innovation": "本文提出了一种名为SynPref-40M的大规模偏好评价数据集，包含4000万对偏好数据，并设计了一种人类和AI协同工作的两阶段管道，结合了人类注释质量和AI的可扩展性。此外，本文通过Skywork-Reward-V2引入了一组8个大小从0.6B到8B参数的奖励模型，这些模型在精心挑选的2600万个SynPref-40M中的偏好子集上进行了训练。实验表明，Skywork-Reward-V2在多种能力上表现出色，包括与人类偏好的对齐、目标正确性、安全性、对抗风格偏见以及N选优扩展，并在七个主要奖励模型基准中达到了最先进的性能。拆分研究证实，这种方法不仅依赖于数据量，还依赖于高质量的注解。", "conclusion": "Skywork-Reward-V2系列代表了公开奖励模型的一个重要进步，突显了现有偏好评价数据的潜在价值，并展示了人类和AI协作所能带来的显著数据质量提升。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02110", "html_url": "https://arxiv.org/abs/2507.02110", "title": "内部软件指标能否预测应用在上线时的受欢迎程度？是的！和不！", "title_en": "Can Internal Software Metrics Predict App Popularity at Launch? Yeas! and Nays!", "authors": "Md Nahidul Islam Opu,Fatima Islam Mouri,Rick Kazman,Yuanfang Cai,Shaiful Chowdhury", "background": "在竞争激烈的移动应用市场中，预测应用在发布前的受欢迎程度能为开发者提供战略优势。然而，这一问题依然具有挑战性。本研究探讨了内部软件指标（在部署前从源代码测量）是否能预测应用的受欢迎程度，即用户评分（基于用户评论计算）和每年下载量（DownloadsPerYear）。本研究使用来自F-Droid的446个开源Android应用的数据集，提取包括系统级、类级和方法级代码指标、代码异味和应用元数据在内的广泛特征集，并从Google Play Store收集了用户评论、下载计数和使用权限等额外信息。研究采用回归和分类模型并使用三个特征集进行评估，发现回归模型由于数据分布偏斜导致表现不佳，但重新定义为二元分类问题（受欢迎vs不受欢迎）后，结果显著改进，最终使用Voting数据集训练的多层感知机模型实现了0.72的F1分数。", "innovation": "本研究发现了内部代码指标虽然解释力有限，但仍能作为应用受欢迎程度的重要指标。这一发现挑战了早期的研究，即认为内部指标不能预测软件质量的观点。通过对回归和分类模型的评估，作者提出了新的方法来更好地利用内部代码指标进行预测，并为未来的研究提供了方向。", "conclusion": "尽管内部代码指标的解释力有限，但它们可以作为应用受欢迎程度的有用指标，对于理解影响应用成功的关键因素具有指导意义。研究结果表明，通过合适的建模方法，内部软件指标在二分类问题中表现出了更好的预测能力，为进一步利用这些指标进行更深入的应用预估提供了可能。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02118", "html_url": "https://arxiv.org/abs/2507.02118", "title": "结合生理监测与自我报告工具监测编程中压力的多模式方法：方法论见解", "title_en": "A Multimodal Approach Combining Biometrics and Self-Report Instruments for Monitoring Stress in Programming: Methodological Insights", "authors": "Cristina Martinez Montes,Daniela Grassi,Nicole Novielli,Birgit Penzenstadle", "background": "传统的心理健康研究依赖自我报告工具来评估关键变量，但这些工具存在偏差问题，即使经过验证和标准化也不能完全解决。因此，研究开始尝试与更客观的方法，如生理测量相结合，以替代自我报告工具。研究的目的在于（i）比较心理测量的压力指标和生物指标；（ii）在编程任务中识别与压力相关的生物数据模式。参与者在完成预调查后，佩戴生理传感器执行两个编程任务，并在每次任务后填写简短的后续调查，最后进行简短的出口访谈。研究表明，心理测量显示没有压力，而引用访谈则反映出感觉无压力或时间压力的情况。此外，生物数据仅在皮肤电活动的激动期峰值上显示显著差异。研究结论认为，通过严格的时间限制诱导压力的方式是不充分的，为未来在压力、生物数据与心理测量工具方面的工作提供了方法论见解", "innovation": "研究采用多模式方法，结合生理监测与自我报告工具来监测编程工作中的压力状态。这种结合方法尝试减少传统自我报告工具的偏差，提供更客观的评估。此外，研究还识别了在编程任务中与压力相关的生理数据变化模式", "conclusion": "研究发现，通过更严格的时间限制诱导压力的方式是不充分的，不足以引起明显的心理和生理压力反应。研究提供了在设计和使用心理测量工具和生理监测技术时的方法论指导，为未来的研究奠定了基础。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02137", "html_url": "https://arxiv.org/abs/2507.02137", "title": "在软件工程中实现可信赖的语义分析：数据集特征与工具选择", "title_en": "Towards Trustworthy Sentiment Analysis in Software Engineering: Dataset Characteristics and Tool Selection", "authors": "Martin Obaidi,Marc Herrmann,Jil Klünder,Kurt Schneider", "background": "软件开发主要依赖基于文本的通信，情感分析是理解团队动态和支持可信的人工智能驱动的需求工程分析的重要工具。然而，现有的情感分析工具往往在不同平台的数据集上表现不一致，这是因为通信风格和内容存在差异。本文研究了10个开发人员通信数据集从五个平台的语义和统计特征，并评估了14种情感分析工具的表现。研究结果表明，数据集的特征可以被利用来改进工具的选择，因为各个平台在语义和统计属性上存在显著差异。尽管基于transformer的模型如SetFit和RoBERTa在结果上表现出色，但工具的有效性仍然取决于具体情境。研究支持研究人员和从业者在软件工程中的情感分析中选择可信的工具，同时也突显了随着沟通环境的变化进行持续评估的需求。", "innovation": "提出了一种映射方法和问卷调查，根据数据集的特性推荐合适的情感分析工具。这种方法考虑了平台在语义和统计属性上的显著差异，并根据不同场景的语境依赖性提供了工具选择建议，帮助研究人员和从业者在软件工程中实现更可信的情感分析。", "conclusion": "研究结果强调，数据集的特征能够被用来改进工具选择。尽管基于transformer的模型在多个测试中表现出较强的结果，但工具的有效性仍然高度依赖于具体的使用情境。本方法通过考虑数据集特征促进了工具选择，同时也指出了需要随着沟通环境的变化而进行持续评估的必要性。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02376", "html_url": "https://arxiv.org/abs/2507.02376", "title": "VeFIA：一种高效垂直联邦协作软件推理审计框架", "title_en": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software", "authors": "Chung-ju Huang,Ziqi Zhang,Yinggui Wang,Binghui Wang,Tao Wei,Leye Wang", "background": "现有垂直联邦学习（VFL）工作缺乏一种机制来审计数据方推理软件执行的正确性。针对这一问题，设计了垂直联邦推理审计（VeFIA）框架，该框架帮助任务方在大规模推理过程中审计数据方推理软件的执行情况，而不泄漏数据隐私或引入额外的推理延迟。", "innovation": "VeFIA框架的核心在于任务方可以利用具有可信执行环境（TEE）的推理结果和协调程序，验证数据方计算结果的正确性。VeFIA保证在异常推理超过5.4%时，任务方可以以99.99%的概率检测推理软件中的执行异常，且不会造成额外的在线推理延迟。此外，随机采样的验证达到了100%的先验阳性值、后验阴性值和真阳性率，用于检测异常推理。据我们所知，这是首篇讨论VFL中推理软件执行正确性的论文。", "conclusion": "VeFIA框架确保在异常推理超过5.4%时，任务方可以以99.99%的概率检测推理软件中的执行异常，且不会造成额外的在线推理延迟。随机采样的验证达到了100%的先验阳性值、后验阴性值和真阳性率，用于检测异常推理。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02318", "html_url": "https://arxiv.org/abs/2507.02318", "title": "通过基于LLM的单元测试生成精确检测Python类型错误", "title_en": "Precisely Detecting Python Type Errors via LLM-based Unit Test Generation", "authors": "Chen Yang,Ziqi Wang,Yanjie Jiang,Lin Yang,Yuteng Zheng,Jianyi Zhou,Junjie Chen", "background": "Python中的类型错误常常导致运行时失败，这对软件可靠性和开发者生产力构成了重大挑战。现有的静态分析工具试图在无需执行的情况下检测这些错误，但频繁遭受高假阳性率的困扰。近年来，单元测试生成技术为实现高覆盖率提供巨大潜力，但它们在没有专门指导的情况下往往难以生成揭示错误的测试用例。", "innovation": "我们提出了RTED，一种新颖的类型感知的测试生成技术，用于自动检测Python类型错误。具体而言，RTED结合了逐步类型约束分析和反射验证来引导测试生成过程，并有效抑制假阳性。实验结果显示，RTED在检测基准类型错误方面比四种最先进的技术多检测出22-29个基准类型的错误。RTED还能够产生更少的假阳性，精确性提高了173.9%-245.9%。此外，RTED成功发现6个真实世界开源Python项目中的12个之前未知的类型错误。", "conclusion": "RTED能够更精确地检测Python中的类型错误，同时减少假阳性率，有效地发现新的类型错误，提高了软件质量和开发者生产力。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02578", "html_url": "https://arxiv.org/abs/2507.02578", "title": "适应性 cyber 物理系统中的人机协作及其伦理考量", "title_en": "Human-Machine Collaboration and Ethical Considerations in Adaptive Cyber-Physical Systems", "authors": "Zoe Pfister", "background": "适应性 cyber 物理系统（CPS）结合了物理和计算能力，能够根据参数变化进行调整，并越来越多地融入人机协作，利用人类和机器的优点。而人机团队（HMT）是人机协作的最先进范式，旨在实现人机之间无缝团队合作。然而，在适应性 CPS 中实现有效且无缝的人机团队合作具有挑战性。尽管适应性 CPS 已经受益于类似 MAPE-K 的反馈回路，但人类和机器的操作节奏不同导致人类难以无缝地融入这些反馈回路。此外，HMT 还需要不断监控人类操作者的行动和行为，收集可能涉及个人隐私的信息。因此，尊重 CPS 中各方的隐私和人类价值对于实现人机团队的成功至关重要。", "innovation": "这项研究的创新之处在于：（1）开发了将人机团队整合到适应性 CPS 中的新方法和过程，重点关注人机交互原则及其在 CPS 中适应性反馈回路中的应用。（2）制定了在整个系统生命周期中整合、验证和验证伦理和人类价值观的框架，从需求工程开始。", "conclusion": "这项研究通过开发创新方法和过程，克服了适应性 CPS 中实现无缝人机团队合作的挑战，并提出了在系统生命周期中确保伦理和人类价值的框架，从而推进了人机团队在适应性 CPS 中的有效实现。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02107", "html_url": "https://arxiv.org/abs/2507.02107", "title": "使用自然语言查询的结构化代码搜索", "title_en": "Structural Code Search using Natural Language Queries", "authors": "Ben Limpanukorn,Yanjun Wang,Zach Patterson,Pranav Garg,Murali Krishna Ramanathan,Xiaofei Ma,Anoop Deoras,Miryung Kim", "background": "代码搜索是开发人员常见的任务，用于理解API、学习常见代码模式和导航代码。目前，开发人员最常使用关键词和正则表达式这些易于使用且普及的工具进行搜索。结构代码搜索工具允许开发人员根据代码的语法结构进行查询，这在故障查找和系统重构方面具有广泛的应用。然而，这些工具通常需要开发者掌握特定领域的语言(DSL)，这往往对手来说有一定的难度。因此，本文提出了一种新的思路，即使用自然语言查询代码的结构。使用自然语言查询可以提供一种直观的代码搜索方式，降低入门门槛。", "innovation": "本文提出了一种新颖的方法，结合了大语言模型(LLM)的推理能力来解读自然语言查询和结构代码搜索工具的力量，以高效准确地检索相关代码。这种新方法被应用于两种结构代码搜索DSL：Semgrep和GQL。评价结果显示，基于LLM将自然语言查询翻译为DSL查询的方法在精度和召回率上均达到了55%-70%，并且在F1分数上比基于语义代码搜索和LLM检索的基线方法有显著的提升，最高可达57%和14%的提升。", "conclusion": "通过构建一个新的结构代码搜索基准测试，包含来自10个Java项目的400个查询，作者展示了基于自然语言查询的结构代码搜索方法的有效性和鲁棒性。这种方法不仅提高了开发人员的代码搜索效率，同时也简化了查询过程。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02665", "html_url": "https://arxiv.org/abs/2507.02665", "title": "研究软件工程师与软件工程研究者使用的是同一种语言吗？", "title_en": "Do Research Software Engineers and Software Engineering Researchers Speak the Same Language?", "authors": "Timo Kehrer,Robert Haines,Guido Juckeland,Shurui Zhou,David E. Bernholdt", "background": "有零星的证据表明，研究软件工程师（RSEs）和软件工程研究者（SERs）在使用类似的术语时常常存在分歧，这造成了沟通上的挑战。为了更好地理解这些分歧，本文初步研究了SER社区中的软件工程基础概念在RSE社区中的解释，识别了相互间的概念一致性、知识空白以及可能需要调整的领域。", "innovation": "本文采用了一种系统化的术语映射方法，揭示了相互学习与合作的机会，并为其未来的群体扩展和验证建立了基础方法。这为更广泛的社区提供了理解不同背景成员之间差异的方法。", "conclusion": "初步的研究结果表明，存在相互学习和合作的机会，提出了一种系统的术语映射方法，为未来的研究奠定了基础，通过这一方法可以更好地填补知识空白，并促进不同社区之间的相互理解和协作。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02533", "html_url": "https://arxiv.org/abs/2507.02533", "title": "Meta-Fair：大型语言模型的AI辅助公平性测试", "title_en": "Meta-Fair: AI-Assisted Fairness Testing of Large Language Models", "authors": "Miguel Romero-Arjona,José A. Parejo,Juan C. Alonso,Ana B. Sánchez,Aitor Arrieta,Sergio Segura", "background": "公平性是人工智能系统开发中的一个核心原则，但目前很难对其进行评估和执行。现有的针对大型语言模型（LLMs）的公平性测试方法往往依赖于人工评估、固定模板、确定性启发式和精心制作的数据集，这使得它们资源密集且难以规模化。", "innovation": "本文旨在为大型语言模型的公平性测试建立新的自动化方法，减少对特定领域资源的依赖并拓宽现有方法的应用范围。该方法名为Meta-Fair，并基于两个关键想法：一是采用元形式测试以通过输入提示的可控修改来发现偏见；二是利用LLMs进行测试案例生成和输出评估的能力。此外，该研究提供了三个开源工具来支持LLM驱动的测试案例生成、执行和评估。实验涉及12个预训练的LLMs，14种元形式关系（MRs），5个偏见维度，以及7900个自动生成的测试案例，结果显示出Meta-Fair在揭露LLMs中的偏见方面的有效性，平均精度为92%，揭示了29%的执行中的偏见行为。此外，LLMs被证明是可靠且一致的评估者，最好的模型达到了0.79的F1分数。", "conclusion": "尽管非确定性影响了一致性，但通过精心设计MR设计可以减轻这种影响。尽管仍存在确保广泛应用的挑战，但结果表明，朝着LLMs测试前所未有的庞大自动化水平提供了一个富有前景的道路。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02182", "html_url": "https://arxiv.org/abs/2507.02182", "title": "增强COBOL代码解释：使用大语言模型的多智能体方法", "title_en": "Enhancing COBOL Code Explanations: A Multi-Agents Approach Using Large Language Models", "authors": "Fangjian Lei,Jiawen Liu,Shayan Noei,Ying Zou,Derek Truong,William Alexander", "background": "COBOL是一种在金融、企业和政府机构中广泛使用的编程语言。由于其年龄、复杂性和COBOL开发人员的减少，维护COBOL代码库变得越来越具挑战性，尤其是缺乏文档使得新开发人员难以有效理解和维护COBOL系统。现有研究利用大规模语言模型（LLMs）来解释代码片段的功能。然而，COBOL由于其架构和语法的独特性，导致其代码经常超出LLM的令牌窗口大小，增加了解释的难度。", "innovation": "本文提出了一种多智能体方法，利用两个基于大语言模型的智能体进行协作，以生成针对功能、文件和整个项目的解释。这些智能体通过结合代码库中的上下文信息来增强代码解释提示。与基线方法相比，该方法在功能代码解释中表现更好，METEOR、chrF和SentenceBERT得分分别提高了12.67%、18.59%和0.62%。在文件层级上，对于长代码文件，该方法也能够解释超过LLM令牌窗口大小的COBOL代码，其解释意图、功能和清晰度的得分分别提高了4.21%、10.72%和14.68%。在项目层级上，该方法能够解释82%选定项目的功能和目的。", "conclusion": "该研究表明，该多智能体方法在COBOL代码解释方面优于现有方法，能够更准确、全面地生成代码解释，有助于减轻COBOL代码维护的挑战。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02690", "html_url": "https://arxiv.org/abs/2507.02690", "title": "RLHGNN: 基于强化学习的异构图神经网络在业务流程中预测下一个活动", "title_en": "RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes", "authors": "Jiaxing Wang,Yifeng Yu,Jiahan Song,Bin Cao,Jing Fan,Ji Zhang", "background": "在面向服务的架构（如微服务环境、分布式企业系统和云原生平台）中，优化业务流程的一个关键挑战是预测下一个活动。这使得资源分配更加主动，服务组合更具动态性。尽管序列基的方法很普遍，但它们无法捕捉并行执行和条件依赖关系中产生的非序列关系。图基方法可以解决结构性保留问题，但它们遭受同质化表示和静态结构的困扰，这些结构对所有个体过程复杂性特征应用统一的建模策略。为了应对这些局限，我们提出了一种名为RLHGNN的新颖框架，该框架将事件日志转换为具有三种不同边类型的异构过程图，并通过强化学习和马尔可夫决策过程自动确定每个特定流程实例的最优图结构。RLHGNN然后应用具有关系特定聚合策略的异构图卷积来有效地预测下一个活动。该适应性方法使得详细地建模服务交互中的序列和非序列关系成为可能。在六个真实世界数据集上的综合评估表明，RLHGNN在预测性能上始终优于现有最先进的方法。此外，它具有大约1毫秒的推理延迟，代表了一个实用的解决方案，适用于实时业务流程监控应用。", "innovation": "提出了一种名为RLHGNN的新颖框架，该框架将事件日志转换为异构过程图，并通过强化学习自动确定最优的图结构。RLHGNN应用异构图卷积来预测下一个活动。该方法使得精确建模服务交互中的序列和非序列关系成为可能，并在实时业务流程监控应用中表现出优越的预测性能。", "conclusion": "RLHGNN在六个真实世界的数据集上的综合评估中表现出色，持续优于最先进的方法，且具有大约1毫秒的推理延迟，表明其是实时业务流程监控的实用解决方案。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02695", "html_url": "https://arxiv.org/abs/2507.02695", "title": "在问答平台中识别可持续性帖子的可持续性标志", "title_en": "Sustainability Flags for the Identification of Sustainability Posts in Q&A Platforms", "authors": "Sahar Ahmadisakha,Lech Bialek,Mohamed Soliman,Vasilios Andrikopoulos", "background": "近年来，软件系统的可持续性受到了广泛关注，尤其是随着云计算的兴起和向基于云的架构的转变。这一转变加剧了在架构讨论中识别可持续性的需求，以便做出明智的架构决策。实践者在在线问答论坛上的讨论中提出了这些决策，但由于缺乏明确和区别的指导方针，识别软件实践者讨论中的可持续性概念仍具有挑战性。为解决这一问题，作者引入了可持续性标志的概念，作为相关讨论中的指针，并通过云提供商的多项可持续最佳实践的主题分析开发这些标志。", "innovation": "作者提出了可持续性标志的概念，作为相关讨论中的指针，通过主题分析从云提供商处开发了多项可持续性最佳实践。这项研究还通过受控实验评估了这些标志在识别云架构帖子中的有效性。初步结果显示，使用标志可以将较少的帖子分类为与可持续性相关，且具有较高的确定性并显著提高了性能。此外，与仅依赖定义相比，可持续性标志被认为更具有实用性和可理解性。", "conclusion": "研究结果表明，可持续性标志有助于更准确地识别和理解云架构中的可持续性，并提高了识别的确定性和性能。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02858", "html_url": "https://arxiv.org/abs/2507.02858", "title": "要求获取跟进问题生成", "title_en": "Requirements Elicitation Follow-Up Question Generation", "authors": "Yuchen Shen,Anmol Singhal,Travis Breaux", "background": "访谈是广泛用于提取需求以收集软件系统相关方需求、偏好和期望的技术。有效的访谈需要具备技能的访谈者在面对多种挑战（如对领域不熟悉、认知负荷过大、信息过载等）的情况下，实时构思合适的访谈问题。最近，大型语言模型（LLMs）在多个自然语言处理任务中表现出色，如文本摘要和蕴含。为了支持访谈者，研究探索了使用GPT-4o在需求获取过程中生成后续访谈问题的可能性，基于典型的访谈者错误类型框架。此外，还描述了基于访谈者言辞生成问题的方法。进行了一项控制实验，评估了LLM生成和人类编写的最少指导问题，并进行了第二项控制实验，评估了由访谈者错误类型引导生成的LLM生成问题的表现。研究发现，在两个实验中，LLM生成的问题在清晰度、相关性和信息量方面不逊于人类编写的。另外，当以常见错误类型为指导时，LLM生成的问题优于人类编写的。这表明LLMs有可能帮助访谈者实时提高需求获取访谈的质量和简便性。", "innovation": "提出将大型语言模型（LLMs）的应用用于在需求获取过程中生成后续访谈问题，基于常见的访谈者错误类型框架，以及探索指导生成方法的影响。", "conclusion": "研究结果表明，对于两种实验，LLM生成的问题在清晰度、相关性和信息量方面不劣于人类编写的，甚至在以常见错误类型为指导时更优。这强调了使用LLMs支持访谈者进行需求获取的优点。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02564", "html_url": "https://arxiv.org/abs/2507.02564", "title": "LLMREI: 使用大型语言模型自动进行需求获取访谈", "title_en": "LLMREI: Automating Requirements Elicitation Interviews with LLMs", "authors": "Alexander Korn,Samuel Gorsch,Andreas Vogelsang", "background": "需求获取访谈是重要但耗时的过程，高度依赖于具备高技能的分析师。这过程容易出现资源耗尽、人为偏见和沟通误解。最近，大型语言模型（LLMs）的发展为自动化需求获取访谈的部分步骤提供了新的机会。这项研究旨在开发一个名为LLMREI的聊天机器人，以减少人工错误，提高需求获取访谈的可扩展性，并减少人为介入。本研究探索了零样本提示和从小到大的提示两种主要方法，以优化LLMREI的需求获取能力。研究结果表明，LLMREI在减少常见访谈错误、提取需求以及生成高度相关的提问方面表现出色，尽管在某些方面与人类访谈者相似，但总体上已经展现了显著的进步。", "innovation": "研究人员开发了一个名为LLMREI的聊天机器人，能够利用大型语言模型自动进行需求获取访谈，从而减少人为干预，减少常见错误，提高需求获取过程的效率和准确性。博士还综合了零样本提示和从小到大的提示两种方法来优化聊天机器人的表现。研究的独特之处在于通过模拟访谈评估聊天机器人在处理需求获取中的实际应用效果。", "conclusion": "LLMREI 能够以较少的人为干预提高需求获取的有效性和准确性，成功地生成相关的问题，虽然在某些方面与人类访谈者类似，但仍表现出相当的能力来适应不同的访谈情境。未来会进一步研究和优化，特别是在生成更准确、更相关的问题上，以充分发挥大型语言模型在自动化需求获取访谈中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.06416", "html_url": "https://arxiv.org/abs/2409.06416", "title": "探索大型语言模型在工业测试维护过程中的整合", "title_en": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes", "authors": "Jingxiong Liu,Ludvig Lemner,Linnea Wahlgren,Gregory Gay,Nasser Mohammadiha,Joakim Wennerberg", "background": "在软件测试过程中，大量的成本和努力被投入到测试维护中，即增加、删除或修改测试案例以使测试套件与被测系统保持同步或提高其质量。工具支持可以通过自动化测试维护过程中的某些方面或为开发者提供指导和支持来降低成本并提高质量。本文探讨了大型语言模型（LLMs）的能力和应用，以支持测试维护。我们在爱立信AB公司开展了一项案例研究，旨在探索测试维护的触发因素、LLMs可以采取的行动，以及在工业环境中部署LLMs时应考虑的问题。研究还提出了一个多智能体架构，可以预测代码变更后哪些测试需要维护。这一系列活动推进了我们对如何部署LLMs以优化工业测试维护过程的理解。", "innovation": "本文研究了LLMs在支持测试维护中的应用，并提出了一种多智能体架构，可以在代码变更后预测哪些测试需要维护。这为工业测试维护过程的自动化和优化提供了新的方法和技术支持。", "conclusion": "本文通过案例研究，展示了如何利用大型语言模型来预测测试维护的需求，并提出了一种多智能体架构。这为未来的测试维护工作提供了理论和实践经验的支持，展示了大型语言模型在工业测试维护中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.07967", "html_url": "https://arxiv.org/abs/2503.07967", "title": "Code数字孪生：为复杂软件维护提供隐性知识的LLMs", "title_en": "Code Digital Twin: Empowering LLMs with Tacit Knowledge for Complex Software Maintenance", "authors": "Xin Peng,Chong Wang,Mingwei Liu,Yiling Lou,Yijian Wu", "background": "尽管大型语言模型（LLMs）在软件工程任务如代码完成和生成中显示出潜力，但在支持复杂软件系统的维护方面仍存在局限性。这些模型往往难以理解系统中内嵌的隐性知识，例如责任分配和不同模块之间的合作关系。", "innovation": "本文提出了Code Digital Twin的概念和框架，这是一种概念性隐性知识的表示，能够捕捉代码元素背后的概念、功能和设计理由，并与软件共同演化。Code Digital Twin通过结合从结构化和非结构化源（如源代码、文档和变更历史）中提取的知识，利用LLMs、静态分析工具和人类专业知识来构建，这为LLMs提供了提供隐性知识的上下文，从而赋能软件维护任务，如问题定位和仓库级别的代码生成。该方法还探讨了连续构建和改进Code Digital Twin时面临的挑战和机遇。", "conclusion": "基于提出的方法，研究探索了连续构建和完善Code Digital Twin的关键挑战和机遇。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02846", "html_url": "https://arxiv.org/abs/2507.02846", "title": "法律要求从法律翻译", "title_en": "Legal Requirements Translation from Law", "authors": "Anmol Singhal,Travis Breaux", "background": "软件系统必须遵循法律规范，但这对小型组织和初创企业来说是一项资源密集型任务，特别是缺乏专门法律知识的情况下。从法规中提取元数据以提取与软件相关的法律要求是确保合规的关键步骤，但这一过程因法律文本的长度和复杂性而变得繁琐。尽管前期研究已尝试通过自动方法从法律文本中提取结构和语义元数据，但仍存在一些限制：这些方法未考虑这些元数据类型中关联属性的相互影响，且依赖于手动标注或基于启发式的机器学习，这些方法在新文档上的泛化能力较差。因此，本文旨在解决这些限制问题，提出一种基于文本蕴含和上下文学习的方法，以自动生成可编码和执行为Python代码的法律文本的规范表示形式。这种方法的实施基于手工设计的Python类结构，作为领域特定的元模型，捕捉到结构和语义法律元数据及其相互关系，从而减少了对大规模手动标注数据集的需求，提升了对其它未见立法的适用性。", "innovation": "本文提出了一种基于文本蕴含和上下文学习的方法，用于自动生成可编码和执行为Python代码的法律文本的规范表示形式。这种方法的实现是基于一个手工设计的Python类结构，作为领域特定的元模型，能够捕捉到结构和语义法律元数据以及它们之间的相互关系，从而减少了对大规模手动标注数据集的需求，并增强了对未见立法的适用性。", "conclusion": "本文方法通过对13个美国州的数据泄露通知法进行了评估，结果显示所生成的表示形式通过了约89.4%的测试案例，并且精度和召回率分别为82.2和88.7。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.15621", "html_url": "https://arxiv.org/abs/2505.15621", "title": "DSCodeBench: 一种真实的数据科学代码生成基准", "title_en": "DSCodeBench: A Realistic Benchmark for Data Science Code Generation", "authors": "Shuyin Ouyang,Dong Huang,Jingwen Guo,Zeyu Sun,Qihao Zhu,Jie M. Zhang", "background": "当前主要基准 DS-1000 在评估大语言模型 (LLMs) 在复杂且现实的数据科学代码生成任务中的表现时存在局限性，例如无法提供更具挑战性和代表性的测试、较短的代码解决方案、较少的数据科学库以及模糊和不规范的问题描述。因此，需要一个新的基准来填补这一空白，DSCodeBench 正是为此目的而设计的。", "innovation": "DSCodeBench 是一种新的基准，它包含 1,000 个精心构建的问题，这些问题来自 GitHub 上广泛使用的 Python 数据科学库中的现实问题。这一基准相比现有的 DS-1000，提供了更具挑战性和代表性的测试、更长的代码解决方案、更全面的数据科学库、更清晰和更好的问题描述，以及更强大的测试套件。其构建过程包括任务范围选择、代码构建、测试生成和问题描述合成，并辅以严格的手动编辑以确保对齐和提高评估的可靠性。实验结果表明，DSCodeBench 展现了良好的扩展行为，更大的模型系统地优于较小的模型，证明其有能力区分模型能力。同时，测试结果表明 GPT-4o 这款最佳 LLM 的通过率为 0.202，这表明 LLMs 在现实数据科学代码生成任务方面仍有很大的改进空间。", "conclusion": "DSCodeBench 将成为一个严谨且值得信任的基础，用于推动基于 LLM 的数据科学编程的发展。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.03693", "html_url": "https://arxiv.org/abs/2504.03693", "title": "自适应业务流程管理：业务流程中代理治理的从业者视角", "title_en": "Agentic Business Process Management: Practitioner Perspectives on Agent Governance in Business Processes", "authors": "Hoang Vu,Nataliia Klievtsova,Henrik Leopold,Stefanie Rinderle-Ma,Timotheus Kampik", "background": "随着生成型AI的兴起，对软件代理的兴趣在工业界日益增长。鉴于基于生成型AI的代理具有随机性，它们在组织中的有效和安全部署需要坚实的治理，这可以通过自适应的业务流程管理来实现。然而，鉴于这一新型代理概念的新的性质，从业者通常不清楚什么被定义为代理，以及在代理部署中所关联的好处、风险和治理挑战是什么。为了调查如何有效地治理AI代理，研究进行了涉及来自不同行业的22位业务流程管理（BPM）从业者的结构化访谈。这些从业者预测代理将增强效率、提高数据质量、确保更好的合规性，并通过自动化实现更好的可扩展性，同时也警告潜在的风险如偏见、过度依赖、网络安全威胁、就业替代和模糊的决策。", "innovation": "本研究通过半结构化的访谈，探讨了BPM从业者对于代理及其在业务流程中部署的看法、所面临的挑战以及潜在的利益，提出了六项关键建议，包括明确业务目标、设置法律和道德护栏、建立人类与代理的合作、定制代理行为、管理风险以及确保安全集成并配备备用选项。此外，研究还提出了将传统BPM与自适应AI结合的具体行动，包括平衡人类和代理的角色、重新定义人类的参与、调整流程结构以及引入绩效指标，以实现业务流程中AI代理的实用集成，同时保持监督、灵活性和信任。", "conclusion": "这些见解为在业务流程中集成AI代理提供了实用基础，同时确保了治理、灵活性和信任。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.08713", "html_url": "https://arxiv.org/abs/2506.08713", "title": "基于多跳自然语言推理的保障案例结构可解释合规检测", "title_en": "Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure", "authors": "Fariz Ikhwantri,Dusica Marijan", "background": "确保复杂系统符合规定通常需要通过声明-论据-证据框架检查保证案例的有效性。这一过程中面临的挑战包括法律和技术文本的复杂性、需要模型解释，以及保证案例数据的有限访问性。", "innovation": "提出了基于自然语言推理（NLI）的合规检测方法EXCLAIM。该方法将保证案例的声明-论据-证据结构形式化为多跳推理以实现可解释和可追溯的合规检测。通过使用大型语言模型生成保障案例以解决数据有限的问题，并引入了衡量覆盖范围和结构一致性的指标。通过GDPR要求的多跳推理任务案例研究，展示了NLI方法在自动监管合规过程中的有效性。", "conclusion": "研究成果突显了基于NLI的方法在自动化法规合规过程中的潜力。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.01631", "html_url": "https://arxiv.org/abs/2506.01631", "title": "基于梯度的模型指纹识别以检测和分类LLM相似性和家族归属", "title_en": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification", "authors": "Zehao Wu,Yanjie Zhao,Haoyu Wang", "background": "由于大型语言模型（LLMs）已成为现代应用程序中的重要软件组件，未经授权的模型衍生（如微调、合并和重新分发）已经成为关键的软件工程挑战。与传统软件相比，尽管克隆检测和许可合规已经成熟，但LLM生态系统缺乏有效的机制来检测模型谱系和强制执行许可协议。特别是在开放源代码模型创建者，如Meta的LLaMA的情况下，要求衍生作品遵守命名约定，但现有技术手段无法验证这些合规性。由于这个漏洞，我们提出了一种将LLMs视为需要来源追溯的软件制品的方法，即TensorGuard，这是一种基于梯度的指纹识别框架，用于LLM相似性检测和家族分类。", "innovation": "TensorGuard是一种基于梯度的指纹识别框架，可以独立于训练数据、水印或特定模型格式，提取模型内固有的行为签名。该框架支持广泛采用的safetensors格式，并通过统计分析梯度特征构建高维指纹。这些指纹能够直接对任意模型进行成对相似性评估，通过距离计算；以及系统地对未知模型进行家族分类，使用领域知识初始化的K-Means聚类算法，并使用已知基模型作为中心初始化。实验表明，在涵盖58个模型（8个基础模型和50个衍生模型）的测试中，使用中心初始化的K-Means聚类算法可以实现94%的分类准确率。", "conclusion": "实验结果显示，在涵盖58个模型（8个基础模型和50个衍生模型）的测试中，TensorGuard能够以中心初始化的K-Means聚类算法实现94%的分类准确率，展示了其在LLM生态系统中的有效应用。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.02607", "html_url": "https://arxiv.org/abs/2507.02607", "title": "缓解攻击数据稀缺性：SCANIA在增强车辆内网络安全措施方面的经验", "title_en": "Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures", "authors": "Frida Sundfeldt,Bianca Widstam,Mahshid Helali Moghadam,Kuo-Yun Liang,Anders Vesterberg", "background": "数字连接车辆的发展及其随之而来的安全风险强调了实施车内网络安全措施（如入侵检测和响应系统）的重要性。持续演进的攻击场景进一步表明了需要适应性检测机制来检测演进、未知和复杂的威胁。尽管机器学习驱动的技术可以应对这一挑战，但由于安全、成本和伦理考虑限制了在测试车辆上实现多样化攻击场景的能力，导致缺乏代表攻击场景的数据。这限制了通过生成高质量攻击代表数据来解决这一限制的方法的有效性和效率。因此，该论文提出了一个上下文感知的攻击数据生成器，该生成器生成各种类型攻击（包括拒绝服务（DoS）、模糊、欺骗、悬挂和重播攻击）的攻击输入和对应的车内网络日志（控制器局域网(CAN)日志），并利用带有CAN消息解码和攻击强度调整的参数化攻击模型来配置高度相似于真实世界场景的攻击情景，并促进多样性。", "innovation": "提出了上下文感知的攻击数据生成器，使用参数化攻击模型和CAN消息解码，结合攻击强度调整来配置高度相似于真实世界场景的攻击情景，并提高多样性和可变性。通过该生成器的数据，在入侵检测系统(IDS)案例研究中，开发了基于深度神经网络的IDS模型并进行了实证评估，验证了生成数据的有效性和一致性，同时讨论了影响数据真实度的因素及其实际应用方面的洞察。", "conclusion": "该研究验证了生成的数据在IDS模型中的有效性和一致性，突显了其对真实世界情景的高相似度。此外，通过实际案例研究，探讨了数据的真实度及其应用影响因素，为提高车辆网络安全提供了新的视角。"}
{"llm_update_time": "20250706", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.24100", "html_url": "https://arxiv.org/abs/2503.24100", "title": "基于模糊测试的C/C++软件在类物理系统中的突变测试", "title_en": "Fuzzing-based Mutation Testing of C/C++ Software in Cyber-Physical Systems", "authors": "Jaekwon Lee,Fabrizio Pastore,Lionel Briand", "background": "突变测试能够帮助减少交付具有故障的软件，因此在安全关键的类物理系统（CPS）中开发嵌入式软件时，它是推荐的做法。然而，C和C++软件使用最广泛的标准突变测试技术依赖于符号执行，但由于符号执行的局限性（例如，具有黑盒组件的系统），其应用受到限制。因此，该研究探讨了使用模糊测试作为一种替代方法的有效性，因为它已经被证明适用于C和C++软件。模糊测试工具可以自动创建测试输入，探索程序分支的不同方式，在不同的程序状态下锻炼语句，从而检测突变体，这是该研究的主要目标。", "innovation": "研究提出了一种依赖于模糊测试的突变测试方法，这种方法已经在C和C++软件中证明了其有效性。实验评估显示，该方法能够检测到开发人员测试套件未检测到的40%到90%的突变体。并且，通过结合使用Clang编译器、内存地址消毒剂以及依赖于laf-intel仪器来收集覆盖率并引导模糊测试的方法，能够显著提高对活动突变体的检测率。此外，研究还发现，模糊测试与符号执行的组合虽然能够检测到更多的突变体被“杀死”，但这种增益极为有限（不到一个百分点的提升）。", "conclusion": "基于模糊测试的突变测试方法在检测C和C++软件中存在的突变体方面显示出优越性，尤其是在处理安全关键的类物理系统（CPS）时。结合Clang编译器、内存地址消毒剂以及laf-intel仪器的方法能够显著提高对活动突变体的检测率。而在模糊测试和符号执行的结合使用中，虽然能够检测到更多被“杀死”的突变体，但这种方法带来的实际收益很小。"}
{"llm_update_time": "20250706", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02801", "html_url": "https://arxiv.org/abs/2507.02801", "title": "在非诚实地拍卖中学习协调竞标者", "title_en": "Learning to Coordinate Bidders in Non-Truthful Auctions", "authors": "Hu Fu,Tao Lin", "background": "在诸如首价格拍卖和全支付拍卖等非诚实时拍卖中，竞标者的独立战略行为及其相应的均衡概念，即贝叶斯纳什均衡，通常难以确定，并可能导致不良结果。一种改进拍卖系统的方法是协调竞标者：让调解人根据贝叶斯协调均衡(BCE)为竞标者提供具有激励兼容性的联合竞标策略建议。但由于竞标者私人估值分布的信息通常不可用，如何实现BCE成为了一个问题。该研究旨在探究在非诚实时拍卖中学习贝叶斯协调均衡的样本复杂性问题，找到了这些拍卖中BCE可以通过来自竞标者价值分布的多项式数量的样本来学习的方法.", "innovation": "该研究提出了将估计竞标者预期效用的问题与竞标者所有单调竞标策略的拟维数分析结合起来的技术，证明了一个大型非诚实时拍卖类（包括首价格和全支付拍卖）中BCE可以通过来自竞标者价值分布的多项式数量 $\tilde O(\frac{n}{\theta^2})$ 的样本来学习。这是该领域的一个创新性贡献，为理解和改进非诚实时拍卖系统提供基础.", "conclusion": "该研究成功地解决了在非诚实时拍卖中学习BCE的样本复杂性问题，并证明了在特定的非诚实时拍卖类别中，可以使用有限数量的样本高效地学习BCE，从而为设计更好的拍卖系统提供了理论支持。"}
