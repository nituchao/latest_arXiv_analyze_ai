<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-cn"><id>https://www.github.com/nituchao</id><title>The latest arXiv papers analyzed by AI</title><updated>2025-06-22T02:17:49.521960+00:00</updated><author><name>nituchao</name></author><link href="https://github.com/nituchao/latest_arXiv_analyze_ai" rel="alternate"/><link href="https://github.com/nituchao/latest_arXiv_analyze_ai/arxiv_papers_data/atom.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Arxiv papers analyzed by AI on 20250621</subtitle><entry><id>1. CALM: Contextual Analog Logic with Multimodality</id><title>1. CALM: Contextual Analog Logic with Multimodality</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[CALM（Contextual Analog Logic with Multimodality）将符号推理与神经生成相结合，使系统能够基于真实世界多模态数据做出情境敏感的决策。CALM通过将逻辑与神经感知进行整合，创建了一种可以处理多模态输入的类比逻辑。其方法是每个谓词使用领域树表示，并在实体的上下文背景确定时迭代细化其类比真值，通过神经网络捕捉多模态信息并经过符号推理模块确保满足约束条件。通过填补空白对象放置任务，CALM表现出色，优于经典逻辑和大型语言模型，也展示了符合逻辑约束和精细人类偏好的空间热图生成能力。
CALM展示了在多模态环境中既能进行逻辑推理又能与偏好对齐的潜力，为需要逻辑精度和解释性的神经系统处理多模态信息的下一代人工智能系统奠定了基础。]]></content><link href="https://arxiv.org/pdf/2506.14936"/><summary>经典二值逻辑系统无法捕捉人类决策的微妙之处，同时在多模态环境中需要人手设定，这可能会变得随意、僵化和脆弱。神经网络擅长从多模态数据中提取丰富的上下文信息，但缺乏可解释的结构来进行推理。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>2. MEAL：连续多智能体强化学习的基准</id><title>2. MEAL：连续多智能体强化学习的基准</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[MEAL是首个针对持续多智能体强化学习（CMARL）的基准。它利用JAX实现GPU加速，使得在标准台式机上能够在几小时内完成针对MEAL的100个任务序列的持续学习。作者展示了将流行的方法简单组合在简单的环境中表现良好，但在需要持续协调和适应的复杂环境中失败了。通过消融研究确定了对MEAL上CMARL至关重要的架构和算法特性。

MEAL为评估和改进持续多智能体强化学习方法提供了新的基准。这种方法能够进行高效计算和长时间的任务序列处理，通过实验证明了现有方法的局限性，并指出了关键的架构和算法特性。]]></content><link href="https://arxiv.org/pdf/2506.14990"/><summary>基准在强化学习（RL）算法的发展和分析中起着关键作用，而环境可用性对研究有重大影响。现有的较少研究的交叉点是持续学习（CL）在协同多智能体环境中的应用。现有的CL基准仅在CPU上运行环境，导致计算瓶颈并限制了任务序列的长度。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>3. 截断近端策略优化</id><title>3. 截断近端策略优化</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[提出了一种新的截断近端策略优化（T-PPO），该方法通过简化政策更新和长度受限的响应生成，改进了训练效率，解决了完全同步长生成过程中的硬件利用率低的问题。通过提出Extended Generalized Advantage Estimation（EGAE）来通过对不完整响应的优势估计确保政策学习的完整性，同时设计了一种计算优化机制，使策略和价值模型可以独立优化。这种方法减少了冗余计算，加速了训练过程，而不会牺牲收敛性能。
T-PPO 在AIME 2024中的32B基模型上展示了其有效性，实验结果表明，它将推理LLMs的训练效率提高了2.5倍，并且优于现有竞争对手。]]></content><link href="https://arxiv.org/pdf/2506.15050"/><summary>近年来，测试时放大语言模型（LLMs）通过生成长链推理（CoT），展示了在科学和专业任务中的出色推理能力。强化学习（RL）是开发这些推理模型的关键组件，Proximal Policy Optimization（PPO）及其变体通过试错学习模型。然而，PPO因其实时政策性质在长响应生成过程中容易变得耗时，进一步受到响应长度增加的影响。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>4. HeurAgenix: 利用大语言模型解决复杂组合优化挑战</id><title>4. HeurAgenix: 利用大语言模型解决复杂组合优化挑战</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[引入了HeurAgenix，这是一种利用LLM的两阶段框架，首先进化启发式算法，然后自动选择。在启发式进化阶段，HeurAgenix利用LLM比较种子启发式解决方案与更高质量的解决方案，提取可重用的进化策略。在解决问题时，它根据LLM的感知能力动态选择最有可能解决问题状态的启发式方法。此外，引入了双奖励机制对轻量级启发式选择器进行微调，该机制结合了选择偏好信号和状态感知信号，以应对NOISY标注导致的监督信号稀疏性问题。
经过广泛实验，HeurAgenix在多种经典基准测试中不仅优于现有的基于LLM的超启发式算法，还与专门的求解器相媲美或超过它们。代码可以在提供的链接中获得。]]></content><link href="https://arxiv.org/pdf/2506.15196"/><summary>启发式算法在解决组合优化（CO）问题中发挥着至关重要的作用，但传统的设计高度依赖人工专业知识，并且难以跨不同实例泛化。由于CO问题的复杂性，通常需要大量可靠的监督信号来进行有效的启发式选择，但这在实践中往往难以获得。为解决问题，本文提出了HeurAgenix，这是一种基于大语言模型（LLM）的两阶段超启发式框架。第一阶段通过LLM进化启发式方法，第二阶段自动选择最合适的启发式方法。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>5. 多智能体强化学习在自主多卫星地球观测中的应用：一个现实案例研究</id><title>5. 多智能体强化学习在自主多卫星地球观测中的应用：一个现实案例研究</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[提出了使用基于多智能体强化学习（MARL）框架的自主多卫星地球观测任务规划方法。通过模拟单卫星操作并扩展到多卫星星座来研究基于强化学习的自主EO任务规划。利用接近实时的卫星仿真环境评估了状态最领先的MARL算法（包括PPO、IPPO、MAPPO和HAPPO），证明了MARL算法在多卫星协调中的有效性和优势。为分散协调的EO任务提供了实用的指导。
研究结果表明，MARL方法能有效平衡地面对卫星的成像和资源管理需求，解决多卫星系统中存在的非平稳性和奖励相互依赖问题。这一研究为自主卫星操作提供了理论和实践基础，进一步改进了分散EO任务中政策学习的方法。]]></content><link href="https://arxiv.org/pdf/2506.15207"/><summary>低地轨道（LEO）卫星数量的指数增长改变了地球观测（EO）任务，解决了气候监测、灾害管理等方面的问题。然而，多卫星系统中的自主协调仍然是一个基本挑战。传统优化方法难以应对动态EO任务中的实时决策需求，因此需要使用强化学习（RL）和多智能体强化学习（MARL）。在本研究中，通过模拟单卫星操作并扩展到多卫星星座使用MARL框架来研究基于RL的自主EO任务规划。研究了关键挑战，包括能源和数据存储限制、卫星观测中的不确定性以及在部分可观测性下的分散协调复杂性。利用近乎实时的卫星仿真环境评估了最先进的MARL算法（如PPO、IPPO、MAPPO和HAPPO）的训练稳定性和性能。研究结果表明，MARL算法能够有效平衡成像和资源管理，并在多卫星协调中解决非平稳性和奖励相互依赖的问题。从本研究中获得的见解为自主卫星操作奠定了基础，并为分散协调的EO任务提供实用的指南。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>6. 无人船舶和无人机合作下具有不确定性的海事MEC联合计算卸载和资源分配</id><title>6. 无人船舶和无人机合作下具有不确定性的海事MEC联合计算卸载和资源分配</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[文章提出了一个基于UAVs和船舶合作的联合计算卸载和资源分配的MEC架构，并利用拉普拉斯优化来处理不可预测的任务到达和计算资源可用性变化问题。将长期约束转化为短期约束，通过不均匀的代理软演员批评算法有效解决了Markov博弈问题。
通过模拟实验验证了所提出的算法在解决计算卸载和资源分配问题上的有效性。]]></content><link href="https://arxiv.org/pdf/2506.15225"/><summary>近年来，海事物联网（MIoT）的计算需求快速增长。无人航空器（UAVs）和船舶基于多接入边缘计算（MEC）可以满足MIoT的需求。然而，不确定的海事业务任务带来了计算卸载和资源分配效率低的问题。因此，本文聚焦于通过UAVs和船舶的合作来进行不确定海事业务的计算卸载和资源分配问题，以解决效率问题。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>7. 视觉导航中的高效且泛化的环境理解</id><title>7. 视觉导航中的高效且泛化的环境理解</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[本文通过因果视角研究导航任务的特性，引入因果框架来展示传统序列方法的局限。提出了Causality-Aware Navigation (CAN)方法，其中包含因果理解模块以增强代理的环境理解能力。实验证明，本文方法在各种任务和模拟环境中均优于基线，归因于因果理解模块在强化学习和监督学习设置下有效泛化，且无额外计算开销。
我们的研究表明，我们的方法在多种任务和模拟环境中一致优于基线。归因于引入的因果理解模块，在强化学习和监督学习设置下具有有效泛化能力，且未增加额外的计算开销。]]></content><link href="https://arxiv.org/pdf/2506.15377"/><summary>视觉导航是嵌入式AI的核心任务，使代理能够导航至复杂环境中的目标。导航任务中频繁需要建模先前时间步骤累积的序列数据。尽管现有方法效果良好，它们通常会同时处理所有历史观测，忽视了数据内部关联结构，这可能限制了进一步提升任务性能的潜力。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>8. 利用基于LLM的推理与执行代理管理复杂故障分析流程</id><title>8. 利用基于LLM的推理与执行代理管理复杂故障分析流程</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[该论文探讨了一种基于大规模语言模型（LLM）的规划代理（LPA）的设计和实现，以帮助FA工程师解决他们的分析任务。该LPA将LLM与高级规划能力和外部工具利用相结合，实现复杂查询的自动处理、从外部系统检索相关数据以及生成人类可读的响应。评价结果显示，该代理在支持FA任务方面表现出高效性和可靠性。
该研究展示了一种利用基于LLM的规划代理来管理和执行复杂故障分析流程的有效方法，该方法能够自主处理复杂查询、检索相关数据并生成人可读的响应，从而提高了FA任务的支持效率和可靠性。]]></content><link href="https://arxiv.org/pdf/2506.15567"/><summary>故障分析（FA）是一个高度复杂且知识密集型的过程。将AI组件集成到FA实验室的计算基础设施中，可以实现检测图像中的不合格情况、从多种数据源检索类比案例以及从注释图像生成报告等多种任务。然而，随着部署的AI模型数量的增加，一个挑战是如何将这些组件组织成协调且高效的流程，使它们能无缝集成到FA过程中。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>9. 动态路由游戏中自然语言状态表示对LLM代理行为的影响</id><title>9. 动态路由游戏中自然语言状态表示对LLM代理行为的影响</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[本文提出了一个新的框架，通过沿三条轴描绘状态表示的方法：行动信息性（即状态表示捕捉已执行动作的程度）；奖励信息性（即状态表示描述获得奖励的力度）；和提示风格（或自然语言压缩，即全文本历史的总结），来解决这些差距。此框架在动态自私路由游戏中得到了应用，证明自然语言状态表示对LLM代理行为有关键影响。具体而言，提供了总结而非完整的历史自然语言表示、关于遗憾而非原始收益的信息以及有限的其他行动信息的表示，这些表示更接近于博弈论预测的均衡行为，并且游戏行为更稳定。相比之下，其他表示可能会表现出与均衡较大的偏差、长时间内动态游戏中行为的更大波动性，或两者皆有。
本研究发现，自然语言状态表示的这些特性对于代理行为的影响至关重要。特别是，提供了总结历史、反映遗憾信息和限制他人行动信息的表示可以导致更接近博弈论预测的行为和更稳定的动态游戏玩法。相比之下，其它表示可能导致偏离均衡表现或时间上的动态游戏行为更为不稳定，甚至兼而有之。]]></content><link href="https://arxiv.org/pdf/2506.15624"/><summary>大型语言模型（LLMs）在动态环境中的决策制定中显示出潜力，但它们无状态的性质意味着需要创建自然语言的历史表示。因此，本文探讨了一个统一的框架，用于系统地为反复的多智能体游戏中LLM代理构建自然语言“状态”表示。在此之前，对含有LLM代理的游戏研究并未系统地编码游戏历史，导致对状态表示对代理行为的影响认识模糊，并限制了研究之间的可比性。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry><entry><id>10. AI政策模块：开发计算机科学学生在AI伦理和政策方面的技能</id><title>10. AI政策模块：开发计算机科学学生在AI伦理和政策方面的技能</title><updated>2025-06-22T10:17:49+08:00</updated><content type="CDATA"><![CDATA[我们开发了一个AI政策模块，将关于AI政策的讨论引入计算机科学课程。还更新和扩展了AI政策模块，包括一个关于‘AI规制’的技术作业。这一模块和作业旨在提高学生对AI伦理和政策的理解，使他们能够将伦理原则转化为实践，并讨论AI规制的问题。
通过模块前后的问卷调查，学生对AI伦理和政策的态度发生了积极的变化。他们更加关注AI技术的伦理影响，并且表现出了更强大参与到AI规制讨论中的能力。AI政策模块及其技术作业（‘AI规制’）作为提升学生伦理知识的有效工具，对技术最专注的AI工程师的培训提供了重要的支持和培训机会。]]></content><link href="https://arxiv.org/pdf/2506.15639"/><summary>随着人工智能（AI）进一步融入个人和职业环境中，必须更加关注AI伦理问题，同时通过AI政策来治理和监管AI技术。当前的大学计算机课程尚未充分准备未来的AI从业者，能够将抽象的伦理原则和规范性政策偏好融入AI系统的设计与开发。因此，熟悉AI政策景观并通过将伦理原则转化为实践成为技术最专注的AI工程师的一项重要责任。为了应对这些新的期望，我们开发了一个AI政策模块，将关于AI政策的讨论引入计算机科学课程。这一模块在秋季试点成功后，我们对其进行了更新和扩展，包括一个关于‘AI规制’的技术作业。我们通过模块前后的问卷调查评估了学生对AI伦理和政策的态度变化。结果显示，学生对AI技术的伦理影响表示了更大的关注，同时更加自信地参与到关于AI规制的讨论中。最后，我们强调了AI规制作业作为一种有效且引人入胜的工具，用于探索AI对齐的边界，并强调‘政策’在解决伦理挑战中的作用。</summary><category term="cs.AI"/><published>2025-06-22T10:17:49+08:00</published></entry></feed>