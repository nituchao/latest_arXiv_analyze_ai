{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00092", "html_url": "https://arxiv.org/abs/2507.00092", "title": "思考关于思考：SAGE-nano的逆向推理以实现自我反思的语言模型", "title_en": "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models", "authors": "Basab Jha,Firoj Paudel,Ujjwal Puri,Zhang Yuting,Choi Donghyuk,Wang Junhao", "background": "大型语言模型（LLMs）在带有推理链提示的复杂推理任务中显示出显著的能力，但是它们的决策过程仍然带有黑箱性质。SAGE-nano是一个40亿参数的推理模型，通过引入逆向推理机制（textbfinverse reasoning），使LLMs能够在事后分解并解释自己的推理链路。", "innovation": "我们提出了第一个通过逆向推理实现LLM自我反思的严格框架，提出了逆向元学习框架来逆转注意力流，设计了全面的推理透明度评估框架，并证明了增加逆向推理可以提高模型可解释性的同时提升推理性能，为透明AI系统开辟了新的途径，并促进了AI安全、教育和科学发现的进步。", "conclusion": "SAGE-nano在推理准确性和解释质量上表现出色，其在AQUA-RAT上的推理准确率达74.6%，解释质量的人类偏好得分为92.1%，几乎等于Claude-3.5 Sonnet或GPT-4o这样的模型，证明了我们的工作在准确性和解释性的提升方面均取得了显著成效。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00008", "html_url": "https://arxiv.org/abs/2507.00008", "title": "DiMo-GUI：通过模态感知视觉推理促进GUI接地测试时缩放的技术进步", "title_en": "DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning", "authors": "Hang Wu,Hongkai Chen,Yujun Cai,Chang Liu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang", "background": "图形用户界面（GUI）中的自然语言查询接地因视觉元素的多样性、空间拥挤以及语言的歧义性而具有独特挑战。以往的方法往往将其视为一个整体图像，对不同模态的处理不够独立导致精度上的限制。", "innovation": "该论文提出了一种无需训练的框架DiMo-GUI，结合动态视觉接地和模态感知优化策略。不将GUI视为单一图像，而是将其划分为文本元素和图示元素，利用通用的视觉-语言模型分别进行模态独立推理。当预测存在歧义或错误时，通过生成基于模型初始预测的候选焦点区域并逐步放大来动态聚焦注意力，以避免附加训练或标注。这种层次细化过程有助于在视觉拥挤布局中进行消歧，从而提高接地结果的准确性。", "conclusion": "我们在标准GUI接地基准上评估了这一方法，并展示了在基础推断管道上的持续改进，进一步证实了模态分离与区域聚焦推理相结合的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00180", "html_url": "https://arxiv.org/abs/2507.00180", "title": "使用强化学习与反事实分析从遗留系统中提取可解释逻辑的黑盒到蓝图", "title_en": "BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis", "authors": "Vidhi Rathore", "background": "现代化遗留软件系统是一个关键但具有挑战性的任务，常常因缺乏原始系统文档和对其内部决策逻辑复杂性的理解而受阻。传统的行为克隆方法只能复制输入输出行为而无法捕捉到背后的意图。", "innovation": "本文提出了一种新的管道，能够自动从被视为黑盒的遗留系统中提取可解释的决策逻辑。该方法利用强化学习（RL）代理探索输入空间，并通过奖励那些导致系统输出显著变化的行动来识别关键决策边界。通过K-Means聚类反事实状态转换，训练决策树来提取近似系统决策逻辑的人类可读规则。", "conclusion": "作者在三个具有不同复杂性的假象遗留系统上展示了管道的有效性，包括基于阈值的、组合条件的和非线性范围逻辑。结果表明，RL代理成功地将探索集中在相关边界区域，并且提取到的规则准确反映了假象遗留系统的核心逻辑，为遗留系统迁移过程中生成规格和测试案例提供了有力的基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00054", "html_url": "https://arxiv.org/abs/2507.00054", "title": "利用奖励引导的数据集蒸馏提高SLMs的推理能力", "title_en": "Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation", "authors": "Shreyansh Padarha", "background": "近年来，将大型语言模型（LLMs）的知识压缩进更易于部署和高效的中小型语言模型（SLMs）已经成为一个研究热点。知识蒸馏技术被广泛应用，使学生模型能够从更大更强大的教师模型中学习。然而，传统的蒸馏方法通常只是让学生模型复制教师模型在分布内的响应，这限制了学生模型的泛化能力，尤其是在复杂的推理任务中容易表现出性能不足和计算成本高的问题。本文研究了如何通过一种新的奖励引导的数据集蒸馏框架（AdvDistill）来提升SLMs在推理任务上的能力。通过利用多个教师模型针对每个提示产生的答案，并基于规则验证器分配奖励，从而给予学生模型不同的权重进行训练，来克服这些传统问题", "innovation": "本文提出了一种名为AdvDistill的奖励引导的数据集蒸馏框架。该框架通过多个教师模型针对每个提示生成的多个响应作为数据集的一部分，并为这些响应分配基于规则验证器的奖励。这些奖励被用作学生模型训练时的权重，从而提高了学生模型在数学和复杂推理任务上的性能。这项研究展示了将奖励机制应用于数据集蒸馏过程中的有效性和潜在好处", "conclusion": "与传统的知识蒸馏方法相比，AdvDistill框架通过引入奖励机制，显著提高了学生模型在数学和复杂推理任务上的性能。这表明，通过合理的奖励分配策略优化数据集蒸馏过程是改进中小型语言模型推理能力的有效方式。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00048", "html_url": "https://arxiv.org/abs/2507.00048", "title": "基于FAIR数据和计算基础设施的协作数字孪生", "title_en": "A collaborative digital twin built on FAIR data and compute infrastructure", "authors": "Thomas M. Deucher,Juan C. Verduzco,Michael Titus,Alejandro Strachan", "background": "在科学和工程应用中，自驾驶实验室（SDL）结合机器学习与自动实验，为加速发现和优化任务提供了强有力的手段。特别是在支持可获取、可访问、可互操作和可重用的（FAIR）数据基础设施的情况下，有共同兴趣的SDL可以更有效地协作。本文基于nanoHUB服务构建了一个分布式SDL实现，用于在线模拟和FAIR数据管理。研究人员可以将独立优化任务的数据提交到共享的中央数据库，并从分析工具和自动更新的机器学习模型中受益。这一框架为地理上分散的合作者提供支持，使得他们能够轻松地共享和利用相关信息，促进了跨学科的合作。", "innovation": "本文提出了基于nanoHUB服务构建的分布式SDL实现，该实现基于FAIR数据和计算基础设施支持地理上分散的合作者，促进他们共享和利用相关信息。而且，通过引入一个新的优化任务——将食物色素结合以达到所需目标颜色——展示了如何通过易获取和成本低廉的材料促进研究和教育。此外，通过引入易于扩展到其他优化问题的工具，进一步增强了该方法的普遍性和灵活性。", "conclusion": "该研究构建了一个基于FAIR数据和计算基础设施的协作数字孪生系统，在这一框架下，研究人员可以通过简单的网络界面提交新数据点，并自动处理，同时利用纳米HUB平台的数据。该系统支持在线模拟和优化任务的研究合作，鼓励研究者和学生利用FAIR数据、预测性机器学习模型和序列优化进行实验。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00041", "html_url": "https://arxiv.org/abs/2507.00041", "title": "TalentMine：基于LLM的多模态人才表格提取与问答", "title_en": "TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables", "authors": "Varun Mannam,Fang Wang,Chaochun Liu,Xin Chen", "background": "在人才管理系统中，关键信息通常以复杂表格的形式存在，这对传统的语言模型在信息检索方面提出了显著挑战。这种挑战在处理需要精确解析表格关系的人才文档时尤为明显，以便进行准确的信息检索和下游决策。当前的表格提取方法在语义理解方面存在不足，导致在集成到检索增强的聊天应用中时表现不佳。研究表明，虽然结构化的表格信息可以被提取，但表格元素之间的语义关系会被丢失，从而导致下游查询失败。", "innovation": "为了应对这一问题，本文提出了TalentMine，这是一个基于语言模型增强的新颖框架，能够将提取的表格转换为语义丰富表示。与依赖于CSV或文本线性化的传统方法不同，我们的方法通过专门的多模态推理保留了表格数据的结构和语义维度。实验结果显示，TalentMine在员工福利文档集合中的查询回答任务中达到了100%的准确率，远远超过了标准AWS Textract提取的0%以及AWS Textract视觉问答能力的40%。我们还发现，Claude v3 Haiku模型在人才管理应用中表现最优。这项工作的主要贡献包括对当前表格提取管道中的语义信息损失的系统分析，提出了一种基于语言模型的语义丰富表格表示方法，以及一个有效的检索增强系统集成框架，并通过多项基准测试显示了多种类别中的显著改进。", "conclusion": "TalentMine通过对提取的表格进行语义增强，解决了当前表格提取方法在语义理解和下游查询方面的不足，从而在多个类别中显著提高了人才分析任务的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00050", "html_url": "https://arxiv.org/abs/2507.00050", "title": "SEZ-HARN: 自解释零样本人体活动识别网络", "title_en": "SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network", "authors": "Devin Y. De Silva,Sandareka Wickramanayake,Dulani Meedeniya,Sanka Rasnayaka", "background": "人体活动识别（HAR）使用惯性测量单元（IMU）传感器数据，在医疗保健和辅助生活环境中具有多种实际应用。然而，在现实场景中的应用受到缺乏全面的IMU基HAR数据集和现有HAR模型透明度不足的限制。零样本HAR（ZS-HAR）解决了数据限制的问题，但当前模型难以解释其决策过程，降低了透明度。鉴于此，本文提出了一种新型的IMU基自解释零样本HAR模型——自解释零样本人体活动识别网络（SEZ-HARN），能够在训练中未遇到的活动上进行识别，并提供骨架视频来解释其决策过程。该模型在四个基准数据集（PAMAP2、DaLiAc、HTD-MHAD、MHealth）上的实验验证了其有效性，并将其性能与三个最先进的黑盒ZS-HAR模型进行了对比，结果表明SEZ-HARN能够生成真实且可理解的解释，并在PAMAP2数据集上达到与最佳黑盒模型3%以内的零样本预测准确率，其他数据集上也保持了类似的表现。", "innovation": "本文提出了SEZ-HARN模型，这是一种自解释的零样本HAR模型，能够在未见过的活动中进行识别，并提供解释其决策过程的骨架视频。该模型在多个基准数据集上的表现优于或至少与最先进的黑盒ZS-HAR模型相当。", "conclusion": "实验结果证明，SEZ-HARN不仅能生成真实且易于理解的解释，还能实现与当前最优黑盒模型相当的零样本识别准确性。SEZ-HARN在PAMAP2上的零样本预测准确率与最佳黑盒模型相差不到3%，在其他三个数据集上也保持了可比的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00181", "html_url": "https://arxiv.org/abs/2507.00181", "title": "ChatGPT 产生更‘懒惰’的思想者：认知参与度下降的证据", "title_en": "ChatGPT produces more \"lazy\" thinkers: Evidence of cognitive engagement decline", "authors": "Georgios P. Georgiou", "background": "尽管大型语言模型（LLMs）在教育中的应用越来越多，但人们对其可能导致学生减少深度思考和积极学习的担忧也随之增加。本研究旨在探讨生成性人工智能工具（具体是ChatGPT）对学生在学术写作任务中认知参与度的影响。研究采用实验设计，参与者被随机分配到AI辅助（使用ChatGPT）或无辅助（对照组）条件下。参与者完成了一项结构化的论证写作任务，并使用一种名为CES-AI的认知参与度量表，该量表用于评估心理努力、注意力、深入处理和策略性思考。实验结果表明，使用ChatGPT组的认知参与度得分显著低于对照组。这表明AI辅助可能导致认知卸载。", "innovation": "本研究开发并采用了CES-AI量表来评估认知参与度，这是对AI在教育中应用潜在影响的认知方面的创新研究，旨在通过量化分析来揭示AI工具在教育中的实际效果。", "conclusion": "本研究的研究成果表明，AI辅助可能会导致认知卸载，这在一定程度上降低了学生在学术写作任务中的认知参与度。这些发现对AI工具在教育中的应用提出了重要问题，呼吁教育工作者制定促进学生主动、反思性地与AI生成内容互动的教学策略，以避免损害学生的自我调节学习和发展深度认知参与的能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00079", "html_url": "https://arxiv.org/abs/2507.00079", "title": "VoyagerVision：探索多模态信息在开放学习系统中的作用", "title_en": "VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems", "authors": "Ethan Smyth,Alessandro Suglia", "background": "开放性（或开放性范围）是致力于强大通用人工智能（AGI）研究的一个活跃领域，允许模型主动追求其选择的任务。近年来，大型语言模型（LLMs）如GPT-4o的进步使其能够解释图像输入。这种功能的应用实例，例如OMNI-EPIC，通过提供像素数据供代理视角感知，使模型能够解析环境并解决任务。这些研究为模型提供了更大的能力去理解空间环境，从而增加了它成功完成任务的数量，扩展了其开放性潜力。本研究试图通过引入VoyagerVision——一种能够使用屏幕截图作为视觉反馈在Minecraft中构建结构的多模态模型，进一步拓宽这一潜力。VoyagerVision在50次迭代中能够创建平均2.75种独特的结构，而Voyager无法做到这一点，这标志着一个全新的方向。在一系列建筑材料测试中，Voyager Vision在平坦世界中的成功率为50%，大多数失败出现在更复杂结构的构建上。", "innovation": "本研究提出的VoyagerVision是一种多模态模型，能够在Minecraft中通过截图提供视觉反馈来构建结构，这既基于Voyager的工作又在全新的方向上进行了改进。VoyagerVision可以在50次迭代中平均创建2.75种独特的结构，而在平坦世界的建筑材料测试中，它的成功率达到了50%，展示了比之前的模型更有潜力的理解和构建复杂结构的能力。本文通过这种新的方法，进一步展示了多模态信息在开放性学习系统中的重要作用，并为未来的研究提供了新的视角。", "conclusion": "VoyagerVision通过引入多模态模型来解决在Minecraft中构建结构的问题，表明多模态信息在开放性学习系统中的重要作用，大大扩展了模型理解和生成复杂结构的能力。未来的研究可以进一步探索在其他环境中的应用，并在更复杂的任务中测试VoyagerVision的效果。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00218", "html_url": "https://arxiv.org/abs/2507.00218", "title": "基于学习的路由：最新进展与未来方向的引导式回顾", "title_en": "Learning for routing: A guided review of recent developments and future directions", "authors": "Fangting Zhou,Attila Lischka,Balazs Kulcsar,Jiaming Wu,Morteza Haghir Chehreghani,Gilbert Laporte", "background": "这篇论文回顾了将机器学习工具应用于解决NP难题组合优化问题的当前进展，特别是如旅行商问题（TSP）和车辆路径问题（VRP）等路由问题。由于这些问题固有的复杂性，精确算法往往需要大量的计算时间才能找到最优解，而启发式方法只能提供近似解，但无法保证最优性。近年来，机器学习模型的成功促使越来越多的研究人员提议并实施各种机器学习技术来解决这些具有挑战性的路由问题。文章提出了一种分类法，将基于机器学习的路由方法分为构建型和改进型两种类型，强调它们对不同类型问题的适用性，并旨在传统运筹学（OR）方法与最先进机器学习技术之间建立联系，为未来的路由问题提供一个结构化的框架，包括新兴的VRP变体.", "innovation": "该研究的创新之处在于提出了一种分类法，将基于机器学习的路由方法分类为构建型和改进型，强调这些方法在不同类型问题上的适用性。并且旨在将传统的运筹学方法与最新的机器学习技术结合，为以后的研究提供了一个结构化的指导框架。", "conclusion": "本文旨在将传统的运筹学方法与最新的机器学习技术相结合，为未来研究提供了一个结构化的框架，以解决新兴的车辆路径问题变体。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00417", "html_url": "https://arxiv.org/abs/2507.00417", "title": "ASTRO：通过反思和回溯在上下文中学习语言模型进行推理", "title_en": "ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context", "authors": "Joongwon Kim,Anirudh Goyal,Liang Tan,Hannaneh Hajishirzi,Srinivasan Iyer,Tianlu Wang", "background": "近年来，通过强化学习（RL）训练大规模语言模型（LLMs）已经产生了具有更强推理能力的推理模型。开源的推理模型复制虽然取得了成功，但这些模型可能已经具备了较强的推理和搜索行为。这使得提升那些不具备推理能力的LLMs变得困难，特别是像LLama 3这样的一族模型。本文旨在通过合成数据集来训练语言模型，该数据集来源于蒙特卡洛树搜索（MCTS）过程中的数学问题解决轨迹。这种方法使模型在强化学习中能够更好地进行探索和反思，从而增强其推理能力并解决复杂问题.", "innovation": "本文提出了一种名为ASTRO的新框架，它通过模拟蒙特卡洛树搜索的搜索轨迹来训练语言模型，使其能够进行类似于搜索算法的推理，包括自我反思、回溯和探索。这种方法通过将搜索轨迹转换为自然语言的链式思考来丰富模型的先验知识，并通过强化学习进一步提高其性能，特别是在解决需要迭代矫正的问题方面，成效显著。", "conclusion": "研究结果表明，启发式训练方法能够为开放的LLMs提供强大的推理能力，从而提高其处理复杂问题的能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00810", "html_url": "https://arxiv.org/abs/2507.00810", "title": "一种具有收敛性分析的非 IID 机器学习问题健壮算法", "title_en": "A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis", "authors": "Qing Xu,Xiaohua Xuan", "background": "本文基于非平滑优化、二次规划和迭代过程提出了一个改进的数值算法来解决最小最大问题。在某些较为宽松的假设下，例如梯度连续性和有界性，我们提供了对该算法收敛性的严格证明。此算法可以广泛应用于鲁棒优化、不平衡学习等多个领域。", "innovation": "根据非平滑优化、二次规划和迭代过程提出的改进数值算法及其在某些较小假设下的严格收敛证明", "conclusion": "我们提出的方法在解决不同领域的问题方面具有广泛的应用潜力，尤其是鲁棒优化和不平衡学习领域。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00205", "html_url": "https://arxiv.org/abs/2507.00205", "title": "整体医疗服务中的人工智能；提升性能和可解释性", "title_en": "Holistic Artificial Intelligence in Medicine; improved performance and explainability", "authors": "Periklis Petridis,Georgios Margaritis,Vasiliki Stoumpou,Dimitris Bertsimas", "background": "随着医疗中人工智能应用的兴趣日益增加，先前已经引入了一个名为HAIM（整体医疗服务中的人工智能）的框架，该框架将多模态数据融合以解决下游临床任务。然而，HAIM在任务方面是通用的，并且缺乏可解释性。针对这些局限性，引入了xHAIM（可解释性HAIM），这是一个新的框架，利用生成型人工智能通过四个结构化的步骤增强预测和可解释性，包括自动识别与任务相关的患者数据、生成全面的患者摘要、利用这些摘要进行改进的预测建模以及通过将预测与特定患者的医学知识相关联来提供临床解释。", "innovation": "xHAIM引入了生成型人工智能来增强预测和可解释性，它通过四个步骤自动识别任务相关的多模态患者数据，生成全面的患者摘要，使用这些摘要进行改进的预测建模，并将预测与患者的特定医学知识联系起来，提供临床解释。通过HAIM-MIMIC-MM数据集评估，xHAIM将胸病理和手术任务的平均AUC提升至90.3%，重要的是，xHAIM使人工智能从一个黑盒预测器转变为一个可解释的决策支持系统，使得临床医生可以在预测中进行交互式的跟踪，追溯回相关的患者数据，从而将人工智能的进步与临床应用相结合。", "conclusion": "xHAIM提高了对胸病理和手术任务的平均AUC，并且通过生成型人工智能，增强了预测和可解释性，将人工智能从黑盒预测器转变为可解释的决策支持系统，为临床医生提供了可靠的依据以辅助其决策过程。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00557", "html_url": "https://arxiv.org/abs/2507.00557", "title": "在MCSAT集成下改进SMT-NRA中的局部搜索", "title_en": "Advancing Local Search in SMT-NRA with MCSAT Integration", "authors": "Tianyi Ding,Haokun Li,Xinpeng Ni,Bican Xia,Tianqi Zhao", "background": "本文针对满足非线性实数理论(Satisfiability Modulo the Theory of Nonlinear Real Arithmetic, SMT-NRA)的局部搜索方法进行改进。虽然已有局部搜索方法取得了一定的成果，但由于SMT-NRA问题固有的复杂性和非线性的挑战，现有的方法仍有改进空间，尤其是在搜索效率和效果方面有待提升。", "innovation": "文章提出了二维cell-jump移动（称为$2d$-cell-jump），扩展了局部搜索框架，命名为$2d$-LS，并结合模型构建满足性计算（MCSAT）框架，改进了搜索效率。此外，实施了一种叫作sample-cell投影操作符的技术，该技术针对实域中的CDCL风格搜索特别有效，有助于引导搜索避开对立状态。最后，设计了结合MCSAT、$2d$-LS和OpenCAD的混合框架，通过信息交换来提升搜索效率。", "conclusion": "实验结果表明，通过这些改进方法提升局部搜索性能，实现了局部搜索效率的提升，展示了所提方法的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00432", "html_url": "https://arxiv.org/abs/2507.00432", "title": "数学推理能否提升泛化大语言模型能力？理解大语言模型推理的可迁移性", "title_en": "Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning", "authors": "Maggie Huan,Yuetai Li,Tuney Zheng,Xiaoyu Xu,Seungone Kim,Minxin Du,Radha Poovendran,Graham Neubig,Xiang Yue", "background": "大语言模型（LLMs）在数学推理方面取得了显著进步，新模型在诸如MATH和AIME等基准测试中已经超越了人类的水平。然而，随着排行榜每周的提升，有必要质疑这些进步是否代表了更广泛的解决问题的能力，还是仅仅窄化了过拟合。因此，为了评估这些模型的能力，作者评估了20多个预训练的推理调优模型，并在数学、科学问答、代理规划、编码和标准指令遵循等多个任务中进行了测试。大多数在数学中取得成功的模型在其他领域并未成功转移其进步。为了更深入地研究这一现象，作者使用数学数据进行了受控实验，并采用不同调优方法测试了Qwen3-14B模型。结果显示，强化学习调优模型能在不同领域实现良好的泛化，而监督微调调优模型往往失去通用能力。对潜在空间表示和标记空间分布变化的分析表明，监督微调会导致代表性和输出显著漂移，而强化学习则保持了通用领域结构。研究结果表明需要重新思考标准的后训练食谱，尤其是在依赖SFT（监督微调）精简数据以推进推理模型方面。", "innovation": "1. 评估了超过20个开放权重推理调优模型在多个任务集（包括数学、科学问答、代理规划、编码和标准指令遵循）上的表现。\n2. 通过受控实验，结合数学数据和不同调优方法测试Qwen3-14B模型。\n3. 分析了潜在空间表示和标记空间分布变化，揭示了监督微调（SFT）和强化学习（RL）调优方法在模型性能和泛化能力方面的区别。\n4. 强调了重新思考后训练食谱的重要性，并建议减少对SFT精简数据的依赖。", "conclusion": "大多数在数学中表现优秀的模型在其他任务中未能成功迁移其进展。强化学习调优模型相较于监督微调调优模型在多个领域展现出更好的泛化能力。这表明，在调优和使用大语言模型时，应重思考后训练的方法，减少传统精简数据（SFT）的说法，以提升模型的通用能力和解决更广泛的任务。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00002", "html_url": "https://arxiv.org/abs/2507.00002", "title": "Hypertokens: 基于标记化大语言模型的全息关联记忆", "title_en": "Hypertokens: Holographic Associative Memory in Tokenized LLMs", "authors": "Christopher James Augeri", "background": "大型语言模型（LLMs）展现出惊人的能力，但存在明显的精度损失问题，重新定义为信息扩散现象。这一重新定义将问题从计算精度转向了一个信息论通信问题。现有研究方法未能有效解决LLMs中的K:V和V:K内存问题，尤其是在关键值操作和空间搜索方面较差的表现。", "innovation": "论文引入了HDRAM（Holographically Defined Random Access Memory），一种基于超标记的符号内存框架，将变压器潜在空间视为扩谱通道。HDRAM集成了超标记、结构化符号代码、经典纠错编码、全息计算和量子启发式搜索等技术，通过原理上一致的信号解扩展方式恢复分布式信息。这种方法使得HDRAM能够实现高效的关键值操作和Grover样式的潜在空间搜索。通过结合错误检测与纠正语法、压缩感知和基尔霍夫子空间对齐技术，HDRAM在保持架构不变的情况下显著提升了关联检索性能，展示了经典-全息-量子启发原则（CHQ）如何增强变压器架构的方法。", "conclusion": "HDRAM通过有效地处理信息扩散现象，显著提高了LLMs的内存操作效率和检索性能，为增强大语言模型的记忆和检索能力提供了新的思路。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00979", "html_url": "https://arxiv.org/abs/2507.00979", "title": "通过因果影响提示增强LLM代理的安全性", "title_en": "Enhancing LLM Agent Safety via Causal Influence Prompting", "authors": "Dongyoon Hahm,Woogyeol Jin,June Suk Choi,Sungsoo Ahn,Kimin Lee", "background": "随着由大型语言模型（LLMs）驱动的自主代理在各种辅助任务中表现出潜在性，确保它们的行为安全可靠，以防止意外后果的发生变得至关重要。现有的方法需要一种新的技术来识别和减轻因智能体决策导致的风险，这需要一种结构化的方式来表示因果关系，从而使智能体能够预见有害的结果并做出更安全的决策。", "innovation": "该研究提出了一种名为CIP的新技术，利用因果影响图（CIDs）来识别和缓解智能体决策过程中的风险。该方法包括三个关键步骤：首先，基于任务规范初始化CIDs以概述决策过程；其次，使用CIDs引导智能体与环境的交互；最后，根据观察到的行为和结果迭代优化CIDs。实验结果显示，该方法有效地增强了代码执行和移动设备控制任务中的安全性。", "conclusion": "该研究展示了如何通过因果影响图（CIDs）和CIP技术来提升自主代理的行为安全性。这种方法有效地防止了由于智能体决策导致的有害后果，为智能体在各种应用中的安全可靠运行提供了新的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00011", "html_url": "https://arxiv.org/abs/2507.00011", "title": "新型RL方法在高效电梯组控制系统中的应用", "title_en": "Novel RL approach for efficient Elevator Group Control Systems", "authors": "Nathan Vaartjes,Vincent Francois-Lavet", "background": "大型建筑中电梯交通管理对于减少乘客旅行时间和降低能源消耗至关重要。由于启发式或模式识别算法难以应对分派中的随机性和组合性，作者将位于阿姆斯特丹自由大学的六电梯、十五层系统建模为马尔可夫决策过程，并训练了一个端到端的强化学习（RL）电梯群控系统（EGCS）。", "innovation": "创新点包括：提出了一种新颖的动作空间编码来处理电梯调度的组合复杂性；引入了基础步骤来模拟连续的乘客到达；设计了定制的奖励信号以提高学习效率；探索了根据不同基础步骤调整折扣因子的方法；基于 Dueling Double Deep Q-learning 的 RL 架构显示，提出的基于 RL 的 EGCS 能适应波动的交通模式，在高度随机的环境中学习，并超越了传统的基于规则的算法。", "conclusion": "提出的基于 RL 的 EGCS 能够有效管理大型建筑中的电梯交通，适应波动的交通模式，从高度随机的环境中学习，并且相比传统的基于规则的算法展现出更好的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00841", "html_url": "https://arxiv.org/abs/2507.00841", "title": "SafeMobile: 在链级别检测和自动评估多模态移动代理的越狱行为", "title_en": "SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents", "authors": "Siyuan Liang,Tianmeng Fang,Zhe Liu,Aishan Liu,Yan Xiao,Jinyuan He,Ee-Chien Chang,Xiaochun Cao", "background": "随着多模态基础模型在智能代理系统中的广泛应用，诸如移动设备控制、智能助手交互和多模态任务执行等场景逐渐依赖于这类大型模型驱动的代理。然而，相关的系统也面临着潜在的越狱风险。攻击者可能通过特定输入诱使代理绕过原始的行为约束，进而执行风险敏感的操作，如更改设置、执行未授权命令或冒充用户身份，这给系统安全带来了新的挑战。现有的智能代理安全性措施在面对复杂的互动时仍存在局限性，特别是在检测多轮对话或多任务序列中的潜在风险行为方面。此外，缺乏有效的自动评估方法来辅助评估和确定这些风险的影响。", "innovation": "本文探索了移动多模态代理的安全问题，尝试通过结合行为序列信息构建风险辨别机制，并基于大型语言模型设计了自动辅助评估方案。通过在几个代表性高风险任务中的初步验证，该方法在一定程度上改善了对风险行为的识别，并有助于降低代理被越狱的概率。期望该研究能够为多模态智能代理系统的安全风险建模与保护提供有价值的参考。", "conclusion": "本文方法在一定程度上改善了对风险行为的识别，并有助于降低代理被越狱的概率，为多模态智能代理系统的安全风险建模与保护提供了有价值的参考。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00003", "html_url": "https://arxiv.org/abs/2507.00003", "title": "基于NeutroSENSE的不确定决策：一种反映不确定性的入侵检测方法", "title_en": "Deciding When Not to Decide: Indeterminacy-Aware Intrusion Detection with NeutroSENSE", "authors": "Eyhab Al-Masri", "background": "随着物联网（IoT）环境的增长，对可解释性的入侵检测系统的需求日益增加。传统的机器学习方法在预测过程中往往缺乏明确的透明度和准确性，这在边缘部署中尤为关键。NeutroSENSE框架通过结合鲁棒的机器学习模型（如随机森林、XGBoost和逻辑回归）与 neutrosophic 逻辑，将预测置信度分解为真（T）、假（F）和不确定性（I）三个部分，增强了系统的理解和决策能力。这种方法允许对不确定性进行量化，并在高不确定性的情况下标记样本进行人工审查，从而提高了系统的鲁棒性和可解释性，特别是对于边缘部署环境而言，这是一种宝贵的优势。", "innovation": "NeutroSENSE引入了一种新颖的方法，通过结合鲁棒的机器学习模型与 neutrosophic 逻辑，将预测置信度分解为真（T）、假（F）和不确定性（I），实现了对不确定性的量化和对不确定性的审查机制。这种方法不仅提高了系统的准确性和可解释性，还能够支持对边缘部署环境中的不确定决策进行可靠的判断。", "conclusion": "NeutroSENSE通过其新颖的架构和不确定性量化方法，在IOT环境中实现了97%的高准确率。这种基于不确定性的审查机制提供了对误分类样本的深入理解，并支撑了更可信的人工智能决策。该研究证明了neutrosophic 逻辑在提升准确性和可解释性方面的实际应用价值，为信任意识AI在边缘和雾计算的物联网安全系统中提供了坚实的理论基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00013", "html_url": "https://arxiv.org/abs/2507.00013", "title": "ST-MTM: 遵循季节与趋势分解的掩码时间序列建模方法用于时间序列预测", "title_en": "ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting", "authors": "Hyunwoo Seo,Chiehyeon Lim", "background": "时间序列预测是一个既重要又具有挑战性的问题，广泛应用于工业领域。最近，掩码时间序列建模被提出用于通过从未掩码部分重建掩码段来有效建模时间依赖性。然而，由于时间序列中的语义信息因其多个成分产生的复杂时间变化而交织在一起，直接掩码原始时间序列忽略了时间序列中的固有语义结构，这可能导致模型学习原始数据中存在的伪时间模式。因此，为了捕捉不同的时间语义，我们提出通过分解方法来处理交织模式。", "innovation": "提出了一种新颖的基于季节与趋势分解的掩码时间序列建模框架ST-MTM。该框架包括一个新颖的掩码方法，用于季节与趋势组件，能够结合每个组件的不同时间变化。ST-MTM使用周期掩码策略对季节成分进行掩码，基于固有的多周期性生成多个掩码季节序列，并使用子序列掩码策略对趋势成分进行掩码，以掩蔽共享相似变化的时间区域。此外，ST-MTM引入了一种对比学习任务，通过增强多个掩码季节表示之间的上下文一致性来支持掩码建模。", "conclusion": "实验结果表明，我们提出的ST-MTM在时间序列预测方面的表现优于现有的掩码建模、对比学习和监督预测方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00951", "html_url": "https://arxiv.org/abs/2507.00951", "title": "超越符号：从脑启发式智能到人工通用智能的认知基础及其社会影响", "title_en": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact", "authors": "Rizwan Qureshi,Ranjan Sapkota,Abbas Shah,Amgad Muneer,Anas Zafar,Ashmal Vayani,Maged Shoman,Abdelrahman B. M. Eldaly,Kai Zhang,Ferhat Sadak,Shaina Raza,Xinqi Fan,Ravid Shwartz-Ziv,Hong Yan,Vinjia Jain,Aman Chadha,Manoj Karkee,Jia Wu,Philip Torr,Seyedali Mirjalili", "background": "研究领域持续探讨机器能否在类似人类的领域真正地思考、推理和行动。尽管像GPT-4.5、DeepSeek、Claude 3.5 Sonnet、Phi-4和Grok 3等模型展现了多模态流畅性和部分推理能力，但它们仍受限于基于标记预测的方式以及缺乏地面行动能力。本文旨在从跨学科的角度系统地探讨AGI的发展，结合了人工智能、认知神经科学、心理学、生成模型和基于代理系统等多个领域。", "innovation": "文章提出了一种基于代理的RAG框架，该框架结合了检索、规划和动态工具使用来支持更灵活的行为。探讨了信息压缩、测试时自适应和无需训练的方法等通用策略作为实现具有适应性和跨领域智能的关键路径。重新审视视觉语言模型不仅作为感知模块，还作为兴起的身临其境理解和协作任务完成的接口。强调记忆和推理的融合是智能产生的核心，这是一种由模块化、交互和自我改进组件紧密配合，通过压缩、推理和目标引导认知结合的方式来实现的综合概念。", "conclusion": "通过神经图形式系统、强化学习和认知脚手架方面的进步，最近的架构开始弥合统计学习与目标导向认知之间的鸿沟。同时指出了通往AGI的道路上的关键科学、技术和伦理挑战。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00007", "html_url": "https://arxiv.org/abs/2507.00007", "title": "在教育实验室中整合通用生成型AI平台以培养批判性思维和数字素养", "title_en": "Integrating Universal Generative AI Platforms in Educational Labs to Foster Critical Thinking and Digital Literacy", "authors": "Vasiliy Znamenskiy,Rafael Niyazov,Joel Hernandez", "background": "随着生成型人工智能（GenAI）平台如ChatGPT、Claude和Gemini的出现，将其纳入教育实验室活动以培养本科生的批判性思维和数字素养变得至关重要。然而，盲目依赖大型语言模型（LLMs）存在局限性和风险。本研究提出了一种新的教育框架，通过让学生将GenAI作为研究主体和认知工具来解决问题，引导他们通过文本、图像和视频等多种模态评价GenAI生成的回应，从而增强他们的学术素养和批判性思维能力。", "innovation": "本研究创新性地提出了一种整合GenAI教育框架，将GenAI视为研究对象和认知工具。它引导学生自己设计专业领域的提示，并评价GenAI生成的文本、图像和视频回应。研究以非自然科学专业的天文学课程为例进行了试点实施，显示了学生较高的参与度和批判性反思能力，并提出了一种可复制的跨学科AI整合实验室工作的模型，可以适应不同科学领域。", "conclusion": "该研究结果显示，结构化的AI交互在教育中非常重要，当与反思性评估方法结合使用时，GenAI可以提高学习成果。研究提出了一种可复制的、适应不同科学领域的模型，为跨学科AI整合实验室工作提供了指导。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00012", "html_url": "https://arxiv.org/abs/2507.00012", "title": "通过最小化条件互信息获得不可提炼模型", "title_en": "Towards Undistillable Models by Minimizing Conditional Mutual Information", "authors": "Linfeng Ye,Shayan Mohajer Hamidi,En-hui Yang", "background": "当使用深层神经网络(DNN)作为黑盒输入-输出教师进行知识蒸馏(KD)时，如果难以提炼出高性能的学生网络，则称该DNN为不可提炼模型。研究发现，可以通过使DNN的每个类别输出概率簇在响应同一标签的所有样本实例时高度集中来构建不可提炼模型，理想情况下每个类别应集中到一个单一的概率分布。通过条件互信息(CMI)来衡量每个簇的集中度，提出了一种新的训练方法——最小化CMI（CMIM）方法，该方法在联合最小化传统交叉熵(CE)损失和在全部温度范围下所有温度缩放簇的CMI值的同时训练DNN。实验结果表明，CMIM模型可以有效防止知识蒸馏，测试的所有KD方法从CMIM模型提炼出的学生网络都比独立训练的标签平滑的学生网络表现更差。此外，相对于单独使用CE损失训练的模型，CMIM模型在预测准确性方面也表现更优。", "innovation": "提出了一种新的训练方法，即通过最小化条件互信息（CMIM）来训练DNN模型，该方法通过在整个温度范围下联合最小化交叉熵损失和所有温度缩放簇的条件互信息值来训练，从而构建不可提炼模型。", "conclusion": "CMIM模型通过广泛的实验测试证明了其不可提炼性，所有测试的KD方法从CMIM模型提炼的学生网络都无法超越独立训练的标签平滑学生网络的效果，同时CMIM模型在自我预测准确度方面也优于单独使用CE损失训练的模型。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00015", "html_url": "https://arxiv.org/abs/2507.00015", "title": "对抗指示令牌的视觉变换器在无线信号分类中的对抗攻击防御", "title_en": "Vision Transformer with Adversarial Indicator Token against Adversarial Attacks in Radio Signal Classifications", "authors": "Lu Zhang,Sangarapillai Lambotharan,Gan Zheng,Guisheng Liao,Xuekang Liu,Fabio Roli,Carsten Maple", "background": "变压器在自然语言处理和计算机视觉等多个领域的显著成功为它们在物联网（IoT）设备通信系统中自动调制分类中的应用铺平了道路。然而，观察到基于变压器的无线信号分类易于遭受细微而复杂的对抗攻击。为解决这一问题，我们提出了一种防御策略来对抗基于变压器的调制分类系统的对抗攻击。该论文提出了一种新型的视觉变压器（ViT）架构，通过引入新的对抗指示（AdvI）令牌检测对抗攻击。先前的研究中还没有在ViT中提出使用AdvI令牌来防御对抗攻击的案例。", "innovation": "本文介绍了一种新的对抗指示（AdvI）令牌，并将其集成到视觉变压器（ViT）中，通过结合对抗训练方法和使用AdvI令牌的检测机制，实现了在统一神经网络模型中同时进行训练时防御和运行时防御，从而减少了系统的体系结构复杂度。我们通过分析注意力机制来探讨该方法的运行原理，并展示了AdvI令牌在ViT中的关键作用，它影响注意力权重并突出输入数据中潜在可疑或异常的区域或特征。实验结果显示，我们的方法在处理白盒攻击场景中优于多种竞争方法，包括利用快速梯度方法、投影梯度下降攻击和基本迭代方法。", "conclusion": "我们的研究通过引入对抗指示（AdvI）令牌，为基于变压器的无线信号分类系统提供了有效的防御机制。这种机制不仅简化了系统架构，而且提高了对抗攻击下的分类准确性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00016", "html_url": "https://arxiv.org/abs/2507.00016", "title": "通过预训练模型正则化实现基于梯度的微调", "title_en": "Gradient-based Fine-Tuning through Pre-trained Model Regularization", "authors": "Xuanbo Liu,Liu Liu,Fuxiang Wu,Fusheng Hao,Xianglong Liu", "background": "大规模预训练模型在多个领域有广泛的应用。然而，针对特定下游任务进行微调需要大量的计算资源和存储空间。一种基于梯度的参数选择方法（GPS）专注于在每个神经元中仅微调拥有高梯度的参数，从而减少训练参数的数量。但是这种方法增加了计算资源和存储需求。", "innovation": "本文提出了一种高效基于梯度和正则化的微调方法（GRFT），该方法更新权重矩阵的行或列。理论证明，具有最高平方梯度总和的行或列是最适合更新的。该策略有效减少了存储开销并提高了参数选择的效率。此外，通过引入正则化提高预训练模型的知识迁移效果。实验表明，GRFT在FGVC和VTAB数据集上的参数更新量分别仅为总参数的1.22%和0.30%，展示了GRFT的高度效率和有效性，并且在性能上超越了现有方法如GPS、Adapter Tuning和LoRA。", "conclusion": "本文提出了一种新的高效微调方法GRFT，通过更新预训练模型权重矩阵的行或列，并引入正则化优化性能，减少计算资源和存储需求，同时实现了卓越的性能，特别是在参数更新量上的大幅减少。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00014", "html_url": "https://arxiv.org/abs/2507.00014", "title": "SWE-Bench-CL: 编码智能体的持续学习", "title_en": "SWE-Bench-CL: Continual Learning for Coding Agents", "authors": "Thomas Joshi,Shayan Chowdhury,Fatih Uysal", "background": "大型语言模型（LLMs）已经在静止代码生成基准测试中取得了显著成果，但实际的软件开发是动态的，包括不断演变的问题、修复和功能要求。为了弥补这一点，作者介绍了一种基于OpenAI和普林斯顿NLP在2024年发布的SWE-Bench Verified数据集的新颖持续学习基准SWE-Bench-CL。该基准通过按时间顺序组织GitHub问题，反映了自然的仓库演变，从而直接评估智能体积累经验、跨任务迁移知识和避免灾难性遗忘的能力。", "innovation": "SWE-Bench-CL基准通过将GitHub问题按时间顺序组织，反映了自然的仓库演变过程，用于直接评估智能体在持续学习中的表现。作者还引入了一个结合FAISS支持的语义记忆模块的互动LangGraph基评估框架，并提供了一套特定的持续学习度量标准，包括平均准确率、遗忘度、正向/反向迁移、工具使用效率，以及通用综合持续学习评分和CL-Fbeta评分，从而捕捉稳定性和可塑性的权衡。此外，作者还制定了一个严格的实验协议，比较了具有记忆能力和无记忆能力的智能体在多样化的Python仓库中的表现。", "conclusion": "SWE-Bench-CL基准和配套的评估框架为持续学习下的编码智能体提供了标准化的评估方法，并公开了所有代码和数据，以便更广泛的研究和开发社区能够复制实验结果，推动开发更适应和健壮的AI智能体。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00004", "html_url": "https://arxiv.org/abs/2507.00004", "title": "推理计算扩展理论：通过定向随机技能搜索进行推理", "title_en": "A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search", "authors": "Austin R. Ellis-Mohr,Anuj K. Nayak,Lav R. Varshney", "background": "大语言模型（LLMs）在训练和部署过程中需要大量的计算、能源和经济资源。虽然训练规模的扩展法则已经指导了领域中的许多进展，但推理成本现在已成为整体资源负担的重要组成部分，尤其是在推理型模型方面。现有的一些关于计算效率的表征，通常关注模型规模、数据集规模和推理代数的单一或固定组合，可能无法捕捉更有效的操作点。为了改进这一点，作者引入了一种定向随机技能搜索（DS3），该框架将推理表示为学习技能图上的随机遍历。该框架允许从简化且表达力强的实例中推导出任务成功和计算成本的闭式表达式，涵盖各种推理策略，包括链式思维（CoT）和树状思维（ToT），从而实现任务难度和模型能力为函数的比较分析。为了实现这一目标，作者扩展了前人的LLM训练第一性三部分图框架，将其与推理相结合，并分别将DS3与表征LLM扩展行为的实验方法联系起来。", "innovation": "该研究引入了定向随机技能搜索（DS3），这是一种新的通用框架，将推理表示为学习技能图上的随机遍历。作者从简化但表达力强的实例出发，推导出任务成功和计算成本的闭式表达式，涵盖了各种推理策略，包括链式思维和树状思维。该框架不仅允许进行推理策略的比较分析，还能理论恢复实际观察到的模式，如线性准确度的对数计算、随任务难度和模型能力改变的青睐推理策略的变化、推理即使在性能参数扩展达到平台期时所表现出的新兴行为，以及最佳-N（BoN）和多数投票行为的统一分析框架。通过明确表征训练与推理的相互依赖，该框架深化了对理论的理解，并支持了算法设计和资源分配的归因式设计。", "conclusion": "该研究通过引入DS3框架，不仅提出了推理计算扩展的新理论，同时也提供了实际的应用实例和分析方法。该框架克服了传统观点的限制，考虑了训练与推理之间的相互作用，从而为理论理解和算法设计提供了坚实的基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00025", "html_url": "https://arxiv.org/abs/2507.00025", "title": "通过频率域适应实现对新动态系统的泛化", "title_en": "Generalizing to New Dynamical Systems via Frequency Domain Adaptation", "authors": "Tiexin Qin,Hong Yan,Haoliang Li", "background": "利用深度神经网络从数据中学习潜在动力学在建模各种复杂的物理动力学方面显示出显著的潜力。然而，当前的方法在特定领域内可靠预测的能力有限，并且难以将基于相同一般动力学但环境特征不同的未知系统进行泛化。", "innovation": "提出了一种参数高效的方法——Fourier Neural Simulator for Dynamical Adaptation (FNSDA)，能够在傅里叶空间内通过适应直接泛化到新的动力学系统。FNSDA 通过自动分割傅里叶模态识别共享动力学，并通过条件概率将特定于每个新环境的模态进行学习，从而实现高效的泛化。", "conclusion": "FNSDA 在四个代表性的动态系统家族上进行评估，结果表明，与现有的方法相比，FNSDA 在显著减少参数成本的情况下实现了优越或竞争力的泛化性能。我们的代码可以在以下链接获取：this https URL."}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00019", "html_url": "https://arxiv.org/abs/2507.00019", "title": "量子启发式编码策略在机器学习模型中的应用：提出和评估实例级别、全局离散和类条件表示", "title_en": "Quantum Inspired Encoding Strategies for Machine Learning Models: Proposing and Evaluating Instance Level, Global Discrete, and Class Conditional Representations", "authors": "Minati Rath,Hema Date", "background": "本文研究了将经典数据转化为用于纯经典机器学习模型的量子数据的方法。介绍了三种数据编码策略：实例级别策略 (ILS)、全局离散策略 (GDS) 和类条件值策略 (CCVS)。这些策略的主要目的是减少编码时间同时确保正确的编码值，并分析其对分类性能的影响。ILS 处理数据集中的每一行独立地，并模仿局部量子状态；GDS 将数据集中所有独特的特征值均匀映射到量子状态；CCVS 对每个类分别编码独特的值，保留了类相关的信息。本文应用这些编码策略进行分类任务，并评估其在编码效率、准确性、模型准确性和计算成本上的影响。通过分析编码时间、精度和预测性能之间的权衡，本文为经典机器学习工作流程中的量子启发式数据转换提供了优化见解。", "innovation": "本文提出了三种新的量子启发式数据编码策略：实例级别策略 (ILS)、全局离散策略 (GDS) 和类条件值策略 (CCVS)，并评估了这些策略对经典机器学习模型分类性能的影响。", "conclusion": "研究通过对编码时间、精度和预测性能的权衡分析，提供了用于经典机器学习工作流程的量子启发式数据转换的优化建议。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00026", "html_url": "https://arxiv.org/abs/2507.00026", "title": "ROSE: 向基于真实世界的大型语言模型安全评估迈进", "title_en": "ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models", "authors": "Jiale Ding,Xiang Zheng,Cong Wang,Wei-Bin Lee,Xingjun Ma,Yu-Gang Jiang", "background": "随着大型语言模型（LLMs）在实际应用中越来越被作为黑盒组件部署，对其安全性的评估，特别是在对抗性提示下的安全性评估变得至关重要。现有的手动安全基准依赖于手工构建的对抗性提示，但它们具有静态性质和更新所需的大量劳动，难以跟上迅速发展的LLM。自动化对抗性提示生成为适应性评估提供了可能，但当前的方法在对抗性话题多样性和真实世界语境化方面仍存在不足，这源于黑盒优化中的探索-利用困境以及缺乏实际语境化的问题，导致对抗性提示在话题和情境方面都较为狭隘和重复。", "innovation": "本文提出了一种名为Reality-Oriented Safety Evaluation (ROSE)的新颖框架，使用多目标强化学习微调对抗性LLM生成多样化主题和丰富上下文的对抗性提示。实验结果显示ROSE在发现最新LLM的安全漏洞方面优于现有方法，在综合评估指标上表现出显著改进。我们期望ROSE能够朝着LLM更实际和基于真实世界的安全评估迈进。", "conclusion": "我们希望ROSE代表了LLM更实际和基于真实世界的安全评估的一步。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00022", "html_url": "https://arxiv.org/abs/2507.00022", "title": "GLU Attention Improve Transformer", "title_en": "GLU Attention Improve Transformer", "authors": "Zehao Wang", "background": "Gated Linear Units (GLU) 在提升神经网络性能方面显示出了巨大的潜力。在本文中，作者介绍了一种新颖的注意力机制——GLU Attention，它将非线性引入注意力的值中，展示了在文本和视觉模态中提高模型性能和加速收敛速度的效果，同时不需要额外的参数和几乎不含计算成本的开销。GLU Attention 轻量且能无缝集成到其他技术如 Flash Attention、Rotary Position Embedding (RoPE) 以及各种 Multi-Head Attention (MHA) 变体中，如 Grouped-Query Attention (GQA)。该研究已开源于 GitHub 上", "innovation": "提出了一种新颖的注意力机制——GLU Attention，将其非线性引入注意力的值中。实验结果表明，无需额外参数且几乎不增加计算成本的情况下，GLU Attention 能够提升模型性能和加速收敛速度，同时还能无缝集成到其他现有的注意力机制技术中，包括 Flash Attention、RoPE 等", "conclusion": "GLU Attention 提升了 Transformer 模型在文本和视觉模态中的性能和收敛速度，不增加任何负担参数和计算成本。该技术能与其他现有的注意力机制技术无缝集成，并公开发布在 GitHub 上供他人使用"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00018", "html_url": "https://arxiv.org/abs/2507.00018", "title": "隐式奖励作为桥梁：SFT和DPO连接的统一视角", "title_en": "Implicit Reward as the Bridge: A Unified View of SFT and DPO Connections", "authors": "Bo Wang,Qinyuan Cheng,Runyu Peng,Rong Bao,Peiji Li,Qipeng Guo,Linyang Li,Zhiyuan Zeng,Yunhua Zhou,Xipeng Qiu", "background": "在将预训练语言模型应用到实际任务时，训练后处理阶段（post-training processes）是关键步骤，学习从演示或偏好信号中获取知识在这一步中起着重要作用。尽管监督微调（SFT）和偏好学习两种方法在训练后处理阶段被广泛应用，但两者之间的理论关系并不清晰，现有研究侧重于分别探讨这两者的效果和局限性。本文旨在构建一个统一的理论框架，将其两者联系起来，提供清晰的理解和改进空间。", "innovation": "本文提出了一种统一的理论框架，将监督微调（SFT）和偏好学习（如直接偏好优化DPO）联系起来，并揭示了隐式奖励的关键作用。文章通过严格的数学推导展示了两者在同一最优策略-奖励子空间内运作，并指出SFT可以视为隐式奖励学习的一个特例。进一步，作者提出了一种简单的学习率降低方法，显著提高了指令遵循任务的性能，并从f-散度函数导出了新的SFT目标，以更有效地优化偏好学习模型。最后，论文扩展了偏好学习中LLM输出与Q函数之间的理论关系到SFT背景下，并给出了证明性的数学推导和实验验证。", "conclusion": "本文强调了监督微调与偏好学习在训练后处理阶段的关键联系，并揭示了隐式奖励对模型性能的重要性。通过提出的新理论和方法，可以有效提高语言模型在指令遵循等任务上的表现。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00024", "html_url": "https://arxiv.org/abs/2507.00024", "title": "AIMatDesign：在数据稀缺条件下增强知识的强化学习方法以用于逆向材料设计", "title_en": "AIMatDesign: Knowledge-Augmented Reinforcement Learning for Inverse Materials Design under Data Scarcity", "authors": "Yeyong Yu,Xilei Bian,Jie Xiong,Xing Wu,Quan Qian", "background": "随着新材料需求的增加，机器学习驱动的逆向设计方法在高维材料组成空间与有限实验数据间面临巨大挑战。现有方法主要存在两大局限：(I) 机器学习模型在高维空间中的可靠性不足，导致设计过程中预测偏斜；(II) 这些模型未能有效整合领域专家知识，限制了其知识引导型逆向设计的支持能力。这些局限性阻碍了高效、稳健的新材料设计进程。", "innovation": "我们提出了AIMatDesign框架，通过使用基于差分算法的数据增强方法来构建一个可靠的体验池，加快模型收敛速度。此外，引入了由大型语言模型（LLMs）指导的自动精炼策略，动态纠正预测不一致，增强奖励信号和状态价值函数之间的对齐。知识导向的奖励函数利用专家领域规则提升训练的稳定性和效率。实验结果表明，AIMatDesign在发现效率、收敛速度和成功率方面显著优于传统机器学习和强化学习方法。通过AIMatDesign提出的材料候选体在实验合成的代表性Zr基合金中产生了性能最佳的高塑性金属玻璃，其屈服强度达1.7GPa，延伸率达10.2%，与预测值十分一致。同时，框架准确捕捉了屈服强度随成分变化的趋势，展示了其可靠性及闭环材料发现的潜力", "conclusion": "AIMatDesign在实验合成的代表Zr基合金中产生了高性能的BMG，展示了其在逆向材料设计中的卓越性能和可靠性。该框架为数据稀缺条件下的材料设计提供了一种有效的方法，有效解决高维空间中的预测偏见和缺乏专家知识整合的问题。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00033", "html_url": "https://arxiv.org/abs/2507.00033", "title": "Video LLMs中长时序视频QA的时刻采样", "title_en": "Moment Sampling in Video LLMs for Long-Form Video QA", "authors": "Mustafa Chasmai,Gauri Jagatap,Gouthaman KV,Grant Van Horn,Subhransu Maji,Andrea Fanelli", "background": "视频大语言模型（Video LLMs）在视频问题回答（VideoQA）领域的进展显著。现有方法在较短视频上表现良好，但在处理更长视频时，常面临长序列推理困难的问题。为扩展Video LLMs以适用于更长的视频内容，常用的帧子采样方法（在固定间隔选择帧）可能会导致关键帧丢失或多个相似帧的冗余信息增加，影响模型的准确性和计算资源的使用效率。", "innovation": "本文提出了一种通用的文本到视频时刻检索模型指导帧采样的方法，称为‘时刻采样’，这是一种模型无关的方法，能够根据问题的上下文选择最相关的帧。通过使用一个轻量级的时刻检索模型来优化帧的选择，该方法提升了长视频问题回答的效果，通过对四个长格式VideoQA数据集和四个最先进的Video LLMs的大量实验表明了该方法的有效性。", "conclusion": "通过广泛实验验证，我们的方法在视频大语言模型中提升了长视频问题回答的效果。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00038", "html_url": "https://arxiv.org/abs/2507.00038", "title": "质胜于量：基于点维V信息的有效大规模数据缩减策略", "title_en": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information", "authors": "Fei Chen,Wenchi Zhou", "background": "数据缩减在数据驱动的人工智能中扮演着关键角色，通过在大规模数据集中识别最具信息性的实例来提高模型训练效率。核心挑战在于如何选择最优实例而非整个数据集，以提高数据质量和训练效率。现有的方法通常需要大量的数据，效率低下且难以满足要求。", "innovation": "本文提出了一种基于点维V信息（PVI）的有效数据缩减策略。首先，通过PVI量化实例难度，过滤出低难度实例，采用静态方法。实验表明，移除10%-30%的数据，仅损失0.0001%-0.76%的分类器性能。此外，采用渐进式学习方法对按PVI升序排序的实例进行分类器训练，加速收敛，提高8%的准确性。进一步将PVI框架从仅适用于英文数据集扩展到多样的中文NLP任务和基础模型，为跨语言数据缩减和更快的训练提供了新视角。", "conclusion": "有效数据缩减策略能够提升所选最优子集的分类器性能，并提高训练效率。同时，PVI框架已被成功应用于多种中文NLP任务，提供了跨语言数据缩减的宝贵见解，代码已在此处发布：this https URL."}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00037", "html_url": "https://arxiv.org/abs/2507.00037", "title": "基于神经元插值的模型融合", "title_en": "Model Fusion via Neuron Interpolation", "authors": "Phoomraphee Luenam,Andreas Spanopoulos,Amit Sant,Thomas Hofmann,Sotiris Anagnostidis,Sidak Pal Singh", "background": "模型融合旨在通过创建一个能够体现所有父模型优点的代表性模型，来合并多个模型的知识。然而，这一过程由于内部表示的差异（如置换不变性、随机初始化或训练数据分布不同）而变得复杂。目前的方法大多难以有效地在不同的训练数据分布下将多个训练好的神经网络整合为一个网络。因此，本研究提出了一个以神经元为中心的新型模型融合算法家族，这些算法能够在任意层类型下将多个父模型的中间神经元分组，以创建目标表示，目标是由融合模型以相应子网络近似。该方法在先前方法的基础上加入了神经元归属分数的计算，并且不受训练数据分布的限制。实验结果显示，本方法在零样本和非IID场景下的融合效果优于先前的技术，展示了其实用性与优势。", "innovation": "提出了一种以神经元为中心的新型模型融合算法家族，能够在任意层类型下将多个父模型的中间神经元分组，以创建目标表示，目标是由融合模型以相应子网络近似。该方法在先前方法的基础上加入了神经元归属分数的计算，并且不受训练数据分布的限制。实验结果表明，该方法在零样本和非IID场景下的融合效果优于先前的技术。", "conclusion": "实验结果证明了本方法在各种基准数据集上的优越性，与先前的融合技术相比，特别在零样本和非IID融合场景中表现出色。该方法能够应用于任意层类型，并且已经展示了其对多个训练好的神经网络在不同训练数据分布下进行有效整合的潜力。代码可在此处获取：this https URL"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00030", "html_url": "https://arxiv.org/abs/2507.00030", "title": "动态环境中的基于上下文臂赛的自适应动作持续时长的深度强化学习", "title_en": "Adaptive Action Duration with Contextual Bandits for Deep Reinforcement Learning in Dynamic Environments", "authors": "Abhishek Verma,Nallarasan V,Balaraman Ravindran", "background": "深度强化学习（DRL）已经在复杂序列决策任务中取得了显著成就，例如玩Atari 2600游戏和掌握棋盘游戏。然而，动作执行的时间尺度仍然是一个关键但未充分探索的方面。当前研究旨在提出一种新的范式，将上下文臂赛与DRL相结合，以自适应选择动作持续时间，提高策略的灵活性和计算效率。", "innovation": "提出了将上下文臂赛模块集成到深度Q网络（DQN）中，该模块能够根据状态上下文学习选择最优的动作重复率。实验结果表明，与静态持续时间基线相比，该方法在Atari 2600游戏上取得了显著的性能提升，这突显了自适应时间抽象在DRL中的有效性。这种范式为游戏和机器人等实时应用中动态动作持续时间的设计提供了一个可扩展的解决方案。", "conclusion": "该范式提供了一种可扩展的解决方案，适用于需要动态动作持续时间的实时应用环境，如游戏和机器人。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00032", "html_url": "https://arxiv.org/abs/2507.00032", "title": "Ken 利用层：学生脑海中的希伯记忆回放以实现自适应知识追踪", "title_en": "Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing", "authors": "Grey Kuling,Marinka Zitnik", "background": "知识追踪（KT）是教育技术中的一个关键技术，旨在更好地理解学生的学习过程和掌握知识的情况。传统的KT方法在处理大规模数据时遇到了时间和空间效率的问题，而且往往依赖于大量的标注数据和复杂的神经网络结构。因此，需要一种新的、高效的、生物学启发的方法来实现个性化的知识追踪，以克服上述挑战。", "innovation": "1. 时间递减的希伯记忆更新机制，实现优雅的遗忘。2. 新颖的损失对齐内部目标（LIT）方法，计算理想内部状态，支持无回传的学习。3. 快速希伯记忆与较慢的线性网络相结合，进行记忆的快速关联更新和渐进的回顾性巩固，实现少量样本的个性化定制和自然遗忘，无需存储原始数据或依赖大规模数据集训练。4. 全部在嵌入空间操作，支持结构化（表格）和非结构化（短答）输入，具有更高的效率和更少的记忆使用。", "conclusion": "KUL-KT在公开的十个KT基准测试中，在排名敏感度指标如nDCG和Recall@10上优于强大基线。在课堂部署中，KUL-KT能够个性化短答案数据生成的测验，提升了学生感觉的有用性并减少了难度（p < 0.05）。消融研究表明，希伯记忆衰减和LIT对于持续适应至关重要。与强大的图基追踪模型相比，KUL-KT训练速度提高了1.75倍，且内存使用减少了99.01%，使其成为了规模化个性化学习的生物依据的、记忆高效且输入灵活的框架。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00028", "html_url": "https://arxiv.org/abs/2507.00028", "title": "HiT-JEPA: 一种用于相似性计算的分层级自监督轨迹嵌入框架", "title_en": "HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation", "authors": "Lihuan Li,Hao Xue,Shuang Ao,Yang Song,Flora Salim", "background": "城市轨迹数据的表现形式对有效分析空间移动模式至关重要。尽管已经取得了一定的进展，但设计能够捕获多样且互补信息的轨迹表示仍然是一个开放的研究问题。现有方法难以在单一模型中同时融合轨迹的细微细节和高层次汇总，限制了其同时关注长期依赖性和保留局部细微差别的能力。因此，需要一种能够统一学习跨语义抽象层的多尺度城市轨迹表示的方法，以实现局部动力学和全球语义的一致性结构。已有研究中，实验在多个真实数据集上的结果表明，HiT-JEPA 的分层级设计产生了更丰富、多尺度的表示形式。", "innovation": "HiT-JEPA 提出了一种统一框架，用于学习多尺度的城市轨迹表示，涵盖了语义抽象的不同层次。该框架采用三层层次结构，逐级捕捉点级的细微细节、中间模式以及高层轨迹抽象，使模型能够实现局部动力学和全球语义的一致性结构。通过实验证明，HiT-JEPA 的分层级设计能够生成更丰富、多尺度的表示形式，对于轨迹相似性计算具有更高的效果。", "conclusion": "通过广泛应用的广泛实验验证，HiT-JEPA 能够提供更全面、多尺度的表示，从而在轨迹相似性计算任务中表现出更好的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00039", "html_url": "https://arxiv.org/abs/2507.00039", "title": "基于模式的图分类：质量度量的比较及预处理的重要性", "title_en": "Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing", "authors": "Lucas Potin,Rosa Figueiredo,Vincent Labatut,Christine Largeron", "background": "图分类旨在根据图的结构和属性特征对其进行分类，适用于诸如社会网络分析和生物信息学等多个领域。已有方法中，依赖于模式（即子图）的方法提供较好的可解释性，因为用于分类的模式可以直接解释。为了识别有意义的模式，通常使用质量度量来评估每个模式的区分能力。然而，已有文献提供了几十种这样的度量，使得选择最适合特定应用的那个变得困难。只有少数调查试图通过比较这些度量来提供一些见解，但它们都没有特别集中在图上。这通常导致系统地使用最广泛使用的度量，而没有进行彻底的评估。本研究提出了一种对38种文献中质量度量的比较分析。基于四个数学特性，我们对其进行理论化描述，并利用公开可用的数据集构成基准，提出了一种生成模式金标准排名的方法。我们利用这些资源对度量进行实证比较，包括模式排名和分类性能。此外，我们提出了一种基于聚类的预处理步骤，将出现在同一图中的模式分组，以增强分类性能。实验结果表明，这样做有效，减少了需要处理的模式数量，同时实现了相似的性能，同时也表明一些流行度量在文献中并不是结果最好的措施。", "innovation": "提出了对38种文献中质量度量的比较分析，并基于四个数学特性进行了理论描述。利用公开可用的数据集构成基准，并提出了一种生成模式金标准排名的方法。提出了基于聚类的预处理步骤来分组出现在同一图中的模式，以增强分类性能，并展示了一些流行度量在文献中并不是结果最好的措施，强调了适当度量选择的重要性。此外，预处理步骤的有效性验证了模式聚类的重要性，减少了需要处理的模式数量，同时保持了类似的分类性能。", "conclusion": "研究表明，为了提高图分类的效果，选择适当的质量度量十分重要。基于模式的图分类过程中，聚类预处理是一种有效的手段，可以同时减少需要处理的模式数量，提升分类性能。并且，一些在文献中常用的度量并不是最好的选择，研究结果强调了对各种度量进行系统比较的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00043", "html_url": "https://arxiv.org/abs/2507.00043", "title": "MR-CLIP: 效率高的基于元数据指导学习的MRI对比度表示", "title_en": "MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations", "authors": "Mehmet Yigit Avci,Pedro Borges,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso", "background": "在临床系统中准确解读磁共振成像（MRI）扫描依赖于对图像对比度精确的理解，而这种对比度主要由回波时间和重复时间等获取参数决定，这些参数存储在DICOM元数据中。目前广泛使用的是如T1加权或T2加权这样较为粗略的标签，这类标签难以准确反映具体的获取设置。在很多实际数据集中，这些标签完全缺失，导致只有原始的获取参数作为标识。并且现有的元数据经常不完整、存在噪音或不一致。这会使得图像解释、检索和整合到临床工作流程中变得复杂。为了使更多的高级临床应用得以实施，如实现模态不变表示和数据协调，可靠的和标准化的元数据是必不可少的。为此，提出了一种多模态对比学习框架MR-CLIP，用于通过与DICOM元数据对齐MR图像来学习对比度敏感的表示，无需依赖手动标签。", "innovation": "MR-CLIP是一个多模态对比学习框架，能够通过与DICOM元数据对齐来学习对比度敏感的表示，而无需依赖手动标签。该方法通过对跨越各种扫描器和协议的多样化临床数据集进行训练，捕捉了不同获取之间的对比度差异，并在扫描内部。MR-CLIP的跨模态检索和对比度分类效果得到证明，展示了其扩展性和在更多临床应用中的潜力。该代码和权重将在公开途径提供，以便进一步研究和应用。", "conclusion": "MR-CLIP有能力通过与DICOM元数据的对齐来提高对比度表示的学习效率，并适用于多样化的临床数据集。这种方法不仅在跨模态检索和对比度分类上展示了它的优越性，还能够实现相对于不同扫描器和协议的更多形式的模态不变表示，从而潜在地促成进一步的临床应用。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00052", "html_url": "https://arxiv.org/abs/2507.00052", "title": "VSF-Med: 一种用于医学视觉语言模型的漏洞评分框架", "title_en": "VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models", "authors": "Binesh Sadanandan,Vahid Behzadan", "background": "文章背景指出，视觉语言模型（VLMs）有潜力简化医学影像流程，然而临床上对这些模型的安全评估仍缺乏系统性研究。文章对此领域的需求进行了阐述，强调了现有漏洞评估的不足之处，特别是缺乏有效的安全评测工具和方法。", "innovation": "文章的创新在于提出了VSF--Med框架，该框架整合了三个新颖的组件：(i) 丰富的针对新兴威胁向量的复杂文本攻击模板；(ii) 能够保留医疗影像临床真实性的不可感知视觉干扰；(iii) 由两独立的人工智能评分员评估的八维评价标准体系，并通过z-评分正则化整合得到一个综合风险度量。该框架完全基于公开数据集构建，并提供了开源代码，能够生成大量的对抗性变体，实现对任何医学VLM的一键式基准测试。", "conclusion": "研究结果显示，多种先进的VLM模型在攻击持续影响、提示注入效果及安全绕过成功率方面均显示出不同程度的脆弱性，其中Llama-3.2-11B-Vision-Instruct模型在攻击持续影响方面最脆弱，而GPT-4o模型则在两方面均有提升。VSF--Med框架的成功应用为医学VLM后续的安全改进和评估提供了有力工具，促进了该领域的发展。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00029", "html_url": "https://arxiv.org/abs/2507.00029", "title": "LoRA-Mixer: 通过串行注意力路由协调模块LoRA专家", "title_en": "LoRA-Mixer: Coordinate Modular LoRA Experts Through Serial Attention Routing", "authors": "Wenbing Li,Zikai Song,Hang Zhou,Yunyao Zhang,Junqing Yu,Wei Yang", "background": "最近的努力将低秩适应（LoRA）与混合专家（MoE）结合起来，以适应大型语言模型（LLMs）的多种任务，但仍存在主要限制：要么用切换专家替换整个注意力/前馈层，要么并行专家分支，这稀释了参数效率和任务准确性。现有方法要么同时优化LoRA专家和路由机制，要么直接部署预训练的、冻结的LoRA模块。", "innovation": "本文提出了LoRA-Mixer，一种模块化和轻量级的MoE框架，结合了LoRA专家。核心创新在于通过动态路由，使用任务特定的LoRA专家取代注意力模块的输入/输出线性层的投影矩阵。该设计利用了传统变压器和状态空间模型固有的线性投影结构，确保了框架与多种基础模型的兼容性。框架支持两种操作模式：（1）利用新的硬软路由策略联合优化LoRA专家和路由机制；（2）直接部署来自外部库的预训练、冻结LoRA模块。同时介绍了自适应专业化平衡损失（SBL），以优化专家平衡和任务特定对齐，确保路由决策的稳定性和最大化专家重复使用率。该框架在七项基准数据集上的实验表明了其有效性。与现有方法相比，使用相同参数量的48%，LoRA-Mixer在特定数据集上提高了性能。", "conclusion": "LoRA-Mixer在GSM8K、HumanEval和MedQA数据集上分别对基模型提高了7.61%、4.88%和3.08%。与最先进的方法相比，在基准数据集上，使用相同参数量的48%，实现额外改进1.09%、1.45%和1.68%，表明其高效性和强大的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00057", "html_url": "https://arxiv.org/abs/2507.00057", "title": "在基于LLM的代码生成中无需 oracle 估计正确性", "title_en": "Estimating Correctness Without Oracles in LLM-Based Code Generation", "authors": "Thomas Valentin,Ardi Madadi,Gaetano Sapia,Marcel Böhme", "background": "大型语言模型（LLMs）在生成代码方面的应用非常成功，但它们可能会‘虚构’，即生成格式正确但事实错误的输出。在没有现成正确实现（即 oracle）的情况下，我们能否量化生成的代码正确性？这个问题是本文的背景。传统方法依赖 oracle 来评估模型的性能，但本文提出了一种新的方法来评估生成代码的错误程度，这在不需要 oracle 的情况下是可行的。", "innovation": "本文提出了一种新的度量方法，称为不一致性，可以在没有 oracle 的情况下高效估计生成程序的错误程度，并提供错误概率的下界。此外，该方法能够自动识别约三分之二的错误代码，且基于 oracle 的 LLM 评估可以可靠地被基于不一致性的评估所替代。实验结果显示，该方法在多种代码生成任务中的有效性非常显著。", "conclusion": "对于平均代码生成任务，基于不一致性的方法能够自动识别大约三分之二的错误程序，且没有假阳性报告。基于 oracle 和基于不一致性的评估方法对 LLM 排名具有非常强的一致性，说明在无需 oracle 的情况下，该方法可以可靠地评估 LLM 代码生成的准确性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00042", "html_url": "https://arxiv.org/abs/2507.00042", "title": "通过差异加权的经验回放缓解灾难性遗忘", "title_en": "Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay", "authors": "Xinrun Xu,Jianwen Yang,Qiuhong Zhang,Zhanbiao Lian,Zhiming Ding,Shan Jiang", "background": "在云-边缘协作物体检测中持续适应边缘模型以进行交通监控时，会遭受灾难性遗忘的问题。模型在适应新数据分布时会忘记之前学到的知识，这在具有周期性变化（如日夜、高峰时段）的动态交通环境中尤为成问题，因为过去的知识仍然很有价值。现有的方法如经验回放和视觉提示在一定程度上缓解了这一问题，但它们难以有效优先和利用历史数据以实现最佳的知识保留和适应。传统的简单存储和回放所有历史数据的方法效率低下，而将所有历史经验视为同等重要忽略了它们对当前领域的不同相关性。", "innovation": "本文提出了基于自适应经验回放的ER-EMU边缘模型更新算法，以解决上述局限性。ER-EMU采用FIFO原则管理有限大小的经验缓冲，并利用新颖的基于领域距离度量的经验选择算法（DDM-ES）。DDM-ES使用多核最大均值偏差（MK-MMD）来量化目标领域的差异，优先选择与当前目标领域差异最大的历史数据，从而确保训练多样性，并促进从更多历史经验中保留知识，同时防止过分拟合新领域。经验缓冲还使用简单的随机抽样策略更新，保持先前领域平衡的表示。在贝尔维尤交通视频数据集上的实验结果表明，ER-EMU能够一致提升几种最先进的云-边缘协作物体检测框架的性能。", "conclusion": "ER-EMU算法通过采用自我适应的经验回放机制及基于领域差异度量的经验选择算法，有效地解决了在动态交通环境中云-边缘协作物体检测模型的灾难性遗忘问题，实现了更好的知识保留和适应能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00068", "html_url": "https://arxiv.org/abs/2507.00068", "title": "MANTA:跨模态语义对齐与信息论优化及长时问序多模态理解", "title_en": "MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding", "authors": "Ziqi Zhong,Daniel Tang", "background": "虽然多模态学习已经取得了显著进展，但当前方法经常将模态分开处理，导致代表性不一致和推理不一致。这项研究旨在通过引入MANTA（基于文本对齐的多模态抽象和归一化）框架解决这一问题，该框架能够在文本结构化的空间中统一视觉和听觉输入，使大型语言模型能够无缝处理。这有助于解决多模态理解中的一些关键挑战，包括模态间语义对齐、自适应时间同步、多层次内容表示以及长序列中的上下文感知稀疏信息检索。MANTA方法在一个严格数学框架中得到了形式化证明，确保在标记限制下的上下文选择是最优的。实验结果表明，MANTA可以将现有的最先进模型的整体准确性提高22.6%，用于长视频问答任务，对于超过30分钟的视频，性能提升尤为显著，达到27.3%。此外，MANTA在时间推理任务和跨模态理解中的表现也分别提高了23.8%和25.1%。该框架还引入了新的密度估计技术，用于最小化冗余同时保留稀有信号，为通过结构化文本统一多模态表示提供了新的基础。", "innovation": "MANTA是一个通过信息论优化实现模态间语义对齐的跨模态框架，能够自适应时间同步，多层次内容表示，以及上下文感知稀疏信息检索。此外，该框架还引入了新的密度估计技术，用于最小化冗余同时保留稀有信号，为统一多模态表示提供了新的基础。", "conclusion": "实验表明，MANTA能够显著提高现有最先进模型的准确性，特别是在长视频问答、时间推理和跨模态理解任务上取得了显著的性能提升。系统地认识到MANTA在优化多模态表示和理解方面的潜力，为未来研究奠定了坚实的基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00070", "html_url": "https://arxiv.org/abs/2507.00070", "title": "使用迁移学习方法的高效植物病害检测", "title_en": "An efficient plant disease detection using transfer learning approach", "authors": "Bosubabu Sambana,Hillary Sunday Nnadi,Mohd Anas Wajid,Nwosu Ogochukwu Fidelia,Claudia Camacho-Zuñiga,Henry Dozie Ajuzie,Edeh Michael Onyema", "background": "植物疾病对农民和整个农业部门构成了重大挑战。早期检测植物疾病对于减轻其影响和防止广泛损害至关重要，因为疾病爆发会影响作物的产量和质量。随着技术的发展，自动监测和检测植物疾病爆发的自动化机会越来越多。本研究提出了一种使用迁移学习方法识别和监控植物疾病的系统。", "innovation": "该研究利用YOLOv7和YOLOv8两个最先进的目标检测模型进行微调，以准确检测细菌、真菌和病毒性植物疾病，如白粉病、叶片角斑病、早疫病和番茄花叶病毒。模型性能通过多个指标评估，包括平均精确率（mAP）、F1分数、精确率和召回率，分别达到了91.05、89.40、91.22和87.66。结果表明YOLOv8在目标检测方面优于其他方法，预示其在现代农业实践中的潜在应用。", "conclusion": "这种方法提供了可扩展的自动化早期任何植物疾病检测解决方案，提高了作物产量，减少了对人工监测的依赖，并支持可持续农业实践。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00075", "html_url": "https://arxiv.org/abs/2507.00075", "title": "自改善训练动力学的理论模型通过解决问题验证差距", "title_en": "Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap", "authors": "Yifan Sun,Yushan Liang,Zhen Zhang,Jiaye Teng", "background": "自改善是大型语言模型（LLM）中最显著的技术之一，旨在通过内部训练提升模型性能而无需使用外部数据。尽管自改善对于提升模型性能非常重要，但关于自改善过程中性能如何演变的探索仍然相对不足。本文通过引入'解决问题验证差距'的概念对自改善的训练动力学进行理论建模，为理解自改善过程中的性能提升提供了新的视角。", "innovation": "本文创新地通过'解决问题验证差距'的概念对自改善进行理论建模，并基于此框架提出了一种仅使用前几个训练周期的信息来预测自改善最终性能的方法。此外，研究还探讨了外部数据对自改善过程的影响，并发现即使在外部数据有限的情况下，外部数据也可以在任何阶段使用而不显著影响最终性能。", "conclusion": "基于理论建模，本文验证了方法的有效性，并通过多种LLM和数据集进行了实证分析，结果表明通过前几个训练周期的信息可以预测自改善的最终性能，并揭示了外部数据在有限情况下对自改善过程的影响。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00066", "html_url": "https://arxiv.org/abs/2507.00066", "title": "InSight-R: 基于AutoGraph的风险导向的人机失误事件识别和界面诱发风险评估框架", "title_en": "InSight-R: A Framework for Risk-informed Human Failure Event Identification and Interface-Induced Risk Assessment Driven by AutoGraph", "authors": "Xingyu Xiao,Jiejuan Tong,Peng Chen,Jun Sun,Zhe Sui,Jingang Liang,Hongru Zhao,Jun Zhao,Haitao Wang", "background": "在核电等关键安全领域，人类可靠性仍然是一个重要问题，操作失败往往与人为错误相关。现有的传统人因可靠性分析（HRA）方法依赖于专家判断，识别人因错误事件（HFEs）和性能影响因素（PIFs），这种方法存在可重复性差、主观性强和界面级数据整合不足的问题。当前方法未能精确评估人机界面设计对操作员性能变异性和错误易感性的影响。因此，本研究提出了一种基于AutoGraph的InSight-R框架，该框架通过将行为数据链接到由自动图基执行框架（AutoGraph）构建的界面嵌入知识图谱（IE-KG），实现了基于错误多发和时间偏差操作路径的自动化HFE识别。", "innovation": "该研究提出了一种基于AutoGraph的InSight-R框架，通过自动图基执行框架（AutoGraph），将行为数据链接到界面嵌入知识图谱（IE-KG），实现了基于错误多发和时间偏差操作路径的自动化HFE识别。此外，研究还讨论了设计师与用户之间的冲突如何与人因错误相关。结果表明，InSight-R不仅增强了HFE识别的客观性和可解释性，而且为数字控制环境中的动态、实时的人因可靠性评估提供了一条可扩展的途径，并为界面设计优化提供了实用见解，推动了基于机制的人因分析方法的发展。", "conclusion": "InSight-R框架不仅增强了HFE识别的客观性和可解释性，而且为数字控制环境中的实时、动态的人因可靠性评估提供了一条可扩展的途径，并为界面设计优化提供了实用见解，推动了基于机制的人因分析方法的发展。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00061", "html_url": "https://arxiv.org/abs/2507.00061", "title": "Smooth-Distill: 一种用于穿戴传感数据多任务学习的自我蒸馏框架", "title_en": "Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data", "authors": "Hoang-Dieu Vu,Duc-Nghia Tran,Quang-Tu Pham,Hieu H. Pham,Nicolas Vuillerme,Duc-Tan Tran", "background": "该论文介绍了一种新型的自我蒸馏框架Smooth-Distill，旨在利用穿戴传感器数据同时进行人类活动识别（HAR）和传感器位置检测。本研究提出的框架利用了一个统一的基于CNN的架构——MTL-net，该架构处理加速度计数据并分别针对每个任务生成两个输出。与常规的需要独立师生模型的蒸馏方法不同，Smooth-Distill框架使用模型自身的平滑历史版本作为教师模型，这大大减少了训练计算开销，同时保持了性能优势。研究人员为此还开发了一个综合的加速度计数据集，记录了三种不同佩戴位置下的12种不同的睡眠姿势，并补充了两个现有公共数据集（MHealth和WISDM）以支持这项研究。", "innovation": "本研究的创新点在于提出了一种自我蒸馏框架Smooth-Distill，该框架利用模型自身的平滑历史版本作为教师模型，实现了训练计算开销的显著降低，同时保持了性能优势。此外，MTL-net的统一CNN架构可以根据不同的任务进行分支处理，支持HAR和传感器位置检测两种任务的同时进行。这种方法在收敛稳定性方面表现出色，并且相对于传统的多任务学习基线具有较低的过拟合率。", "conclusion": "Smooth-Distill方法为人类活动识别系统的实践应用提供了知识蒸馏的有效解决方案，平衡了准确性与训练效率，并且该框架降低了模型训练的计算成本，对于需要频繁模型更新或在资源受限平台上进行训练的场景尤为重要。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00083", "html_url": "https://arxiv.org/abs/2507.00083", "title": "通过干预感知空间因果图形网络进行深度目标空袭系统的战略反事实建模", "title_en": "Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks", "authors": "Wei Meng", "background": "当前的战略层级模拟缺少对战术打击行为与战略延迟之间结构化因果关系的建模，特别是在‘韧性-节点抑制-协商窗口’链中的中间变量结构瓶颈。", "innovation": "提出了一种名为干预感知时空图形神经网络（IA-STGNN）的新颖框架，实现了从战术输入到战略延迟输出的因果闭环。模型结合了图形注意力机制、反事实模拟单元以及空间干预节点重建，以实现打击配置和同步策略的动态模拟。培训数据来自符合NIST SP 800-160标准的多物理仿真的GEANT4 + COMSOL平台，确保了结构追溯性和政策级验证。", "conclusion": "IA-STGNN在MAE减少12.8%，Top-5精度提高18.4%，因果路径一致性和干预稳定性增强方面显著优于基线模型（ST-GNN, GCN-LSTM, XGBoost）。该模型支持核威慑模拟、外交窗口评估和多策略优化，并为高级政策建模提供了一个结构化且透明的AI决策支持机制。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00078", "html_url": "https://arxiv.org/abs/2507.00078", "title": "时间的语言：时间序列基础模型的语言模型视角", "title_en": "The language of time: a language model perspective on time-series foundation models", "authors": "Yi Xie,Yun Xiong,Zejian Shi,Hao Niu,Zhengfu Liu", "background": "随着大规模语言模型的兴起，大规模参数的模型在大量数据集上训练的基础模型范式已经被应用于多个领域，取得了显著的成功。时间序列基础模型是这一范式的重大扩展，展示了惊人的表达能力、泛化能力和跨域迁移性。然而，这引发了根本性的矛盾：时间序列数据体现的是不同的动态系统，这使得跨域迁移显得直观上是不可能的，但这与模型的实际成功相矛盾。为了解决这一矛盾，本文从理论和实验的角度探讨了基于片段的时间序列基础模型的学习机制和泛化能力。我们提出，这些模型不仅仅是采用一种新的架构，而是从根本上将语言模型的表征范式从确定性的向量扩展到了潜在的概率分布形式。理论分析支持这一框架，表明连续的时间序列片段可以忠实量化成一个离散词汇表，其关键统计特性与自然语言高度一致。这一泛化使时间序列模型能够继承大规模语言模型的稳健的表示能力和迁移能力，从而解释了它们在时间任务中的卓越性能。最终，本文为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了坚实的理论基础。", "innovation": "本文创新性地引入了基于片段的时间序列基础模型，并从理论和实证两方面解释了这些模型如何继承语言模型的表示能力和迁移能力，表现出在时间任务中的显著性能。研究表明，基于片段的时间序列模型能够将决定性的向量表示扩展为潜在的概率分布形式，从而实现与自然语言的统计特性相似的泛化。", "conclusion": "我们的研究为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了坚实的理论基础，且进一步阐释了时间序列模型在时间和语言表征上的迁移能力，显著提升了其在时间序列任务中的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00087", "html_url": "https://arxiv.org/abs/2507.00087", "title": "pUniFind：一个统一的大规模预训练深度学习模型，推动质谱数据解释的极限", "title_en": "pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation", "authors": "Jiale Zhao,Pengzhi Mao,Kaifei Wang,Yiming Li,Yaping Peng,Ranfei Chen,Shuqi Lu,Xiaohong Ji,Jiaxiang Ding,Xin Zhang,Yucheng Liao,Weinan E,Weijie Zhang,Han Wen,Hao Chi", "background": "虽然深度学习已经显著提高了质谱数据的解释能力，但现有的多数模型仍主要作为特征提取器，而非统一的评分框架。本文介绍了pUniFind，这是首个将端到端肽-谱评分与开放、零样本新测序集成的大规模多模态预训练模型，旨在解决这一问题。模型在超过1亿个开放搜索衍生的谱图上进行了训练，并通过跨模态预测对谱图和肽谱进行了调和，显示出在各种数据集上优于传统引擎的表现，尤其是显著提高了免疫肽谱学中鉴定出的肽的比例。", "innovation": "pUniFind 是首个将肽-谱评分与开放、零样本新测序集成的大规模多模态预训练模型。该模型通过超过1亿个开放搜索衍生的谱图进行训练，实现了在不同类型数据集上的优异表现，特别是在免疫肽谱学中鉴定了更多的肽。该模型支持超过1,300种修饰，即便在比现有方法大300倍的搜索空间中也能鉴定出更多的肽段。此外，该模型还包含了一个基于深度学习的质量控制模块，能够进一步恢复额外的合成肽，其中包括一些无法从参考蛋白质组中映射到基因组的合成肽，同时保持全面的碎片离子覆盖。这些特点说明pUniFind 提供了一种统一且可扩展的深度学习框架，提高了蛋白质组分析的灵敏度、修饰覆盖范围和解释能力。", "conclusion": "这些结果确立了pUniFind 作为一种统一、可扩展的深度学习框架，能够改善质谱数据的解析、修饰覆盖范围，并增强解释能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00044", "html_url": "https://arxiv.org/abs/2507.00044", "title": "HistoART：组织图像artifact检测和报告工具", "title_en": "HistoART: Histopathology Artifact Detection and Reporting Tool", "authors": "Seyed Kahaki,Alexander R. Webber,Ghada Zamzmi,Adarsh Subbaswamy,Rucha Deshpande,Aldo Badano", "background": "在现代癌症诊断中，全切片成像（WSI）被广泛用于数字化组织样本，以进行详细、高分辨率的检查；然而，根据癌症类型和临床情境，也会结合使用其他诊断方法，如液体活检和分子检测。尽管WSI通过实现自动化、精准的分析，极大地革新了数字病理学，但仍可能受到切片准备和扫描过程中引入的artifact的影响，这些artifact会威胁到后续的图像分析。为应对这一挑战，论文提出并对比了三种WSI artifact检测方法：基于基础模型的方法（FMA）、基于深度学习的方法（DLA）和基于知识的方法（KBA）。这些方法针对六种常见的artifact类型，包括组织折叠、焦外区域、气泡、组织损伤、标记痕迹和血液污染。评估在来自不同扫描器（Hamamatsu、Philips、Leica Aperio AT2）及多个场地的50,000多个图像片段上进行，以确保检测的有效性和准确性。", "innovation": "论文提出并对比了三种WSI artifact检测方法，分别是基于基础模型的方法（FMA）、基于深度学习的方法（DLA）和基于知识的方法（KBA）。其中，FMA在patch-wise AUROC（0.995，95% CI [0.994, 0.995]）上取得了最优表现，优于ResNet50-based（0.977，95% CI [0.977, 0.978]）和KBA（0.940，95% CI [0.933, 0.946]）。此外，还开发了一种质量报表示图工具，用于量化高质量图像片段并可视化artifact分布。", "conclusion": "研究通过FMA实现了对WSI artifact的高精度检测，并开发了质量报表示图工具来量化和可视化artifact及其分布情况，从而提高了诊断的准确性和可靠性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00088", "html_url": "https://arxiv.org/abs/2507.00088", "title": "大型语言模型如何评判并影响人类的协作行为", "title_en": "How large language models judge and influence human cooperation", "authors": "Alexandre S. Pires,Laurens Samson,Sennay Ghebreab,Fernando P. Santos", "background": "随着人类越来越多地依赖大型语言模型（LLMs）来支持社会环境中的决策，这些工具对人们的道德和政治判断产生了影响。然而，LLMs在社交决策中的长期影响尚不清楚。特别是，当社交互动的评估依赖于语言模型时，人类的协作行为会受到怎样的影响？文章探讨了这一问题，尤其是在间接互惠、声誉和评估他人互动能力等因素驱动人类合作的情况下。研究使用最先进的LLMs来评估合作行为，并通过进化博弈论模型评估LLM驱动的判断如何影响长期的社会动态。结果显示，LLMs在评估与良好对手的合作时有较高的共识，但在评判不诚信者合作时存在差异。这些差异可以显著影响合作行为的普及率。最后，研究还测试了引导LLMs规范的提示，表明干预可以影响LLMs的判断，特别是通过目标导向的提示。\n", "innovation": "研究创新地使用了21种不同的先进LLMs来评估合作行为，并通过进化博弈论模型评估LLMs驱动的判断在人群中的长期影响。此外，研究还测试了通过提示来引导LLMs规范，这显示干预可以影响LLMs的判断。\n", "conclusion": "大型语言模型在评判人类合作行为时表现出显著的一致性，但在评判不诚信者行为时存在差异。这些差异对合作行为的普及率有重大影响。通过目标导向的提示可以引导LLMs的规范，从而可能影响其判断结果。文章强调，需要谨慎地调整LLMs的规范以保护人类合作。\n"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00081", "html_url": "https://arxiv.org/abs/2507.00081", "title": "State and Memory is All You Need for Robust and Reliable AI Agents", "title_en": "State and Memory is All You Need for Robust and Reliable AI Agents", "authors": "Matthew Muhoberac,Atharva Parikh,Nirvi Vakharia,Saniya Virani,Aco Radujevic,Savannah Wood,Meghav Verma,Dimitri Metaxotos,Jeyaraman Soundararajan,Thierry Masquelin,Alexander G. Godfrey,Sean Gardner,Dobrila Rudnicki,Sam Michael,Gaurav Chopra", "background": "大规模语言模型（LLMs）已经在自然语言理解和生成领域取得了显著进展，但在应用于复杂的、现实世界的科学工作流程时仍受到内存、规划和工具集成等方面的挑战。SciBORG是一种模块化的代理框架，旨在让基于LLM的代理能够自主规划、推理并可靠地执行特定领域的任务。SciBORG通过动态构建来自源代码文档的代理并添加有限状态自动机（FSA）内存，实现了持久状态跟踪和上下文感知决策。这种方法消除了手动提示工程的需要，并通过保持长流程中的上下文能够从工具或执行失败中恢复，从而实现多样化应用的稳健和可扩展部署。\n", "innovation": "SciBORG框架通过动态构建代理和引入有限状态自动机（FSA）记忆，实现了持久状态跟踪和上下文感知决策，不需要人工提示工程，因此能够在复杂的工作流程中保持上下文并从工具或执行失败中恢复。该框架展示了通过物理和虚拟硬件（如用于执行指定反应的微波合成仪）实现上下文感知决策。SciBORG还在从PubChem数据库自动执行多步骤生物测定检索中展示了多功能性，包括多步骤规划和推理以及代理间通信与协调执行探索性任务。系统基准测试表明，SciBORG代理能够实现可靠的执行、自适应计划和可解释的状态转换。\n", "conclusion": "SciBORG通过维护长期工作流程中的上下文和从工具或执行失败中恢复来实现稳健和可扩展的部署。实验结果表明，记忆和状态意识对于代理的规划和可靠性至关重要。SciBORG为在复杂环境中部署AI代理提供了通用基础。\n"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00085", "html_url": "https://arxiv.org/abs/2507.00085", "title": "基于拓扑-数据联合融合的图网络在鲁棒交通速度预测中的应用，考虑数据异常", "title_en": "A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism", "authors": "Ruiyuan Jiang,Dongyao Jia,Eng Gee Lim,Pengfei Fan,Yuli Zhang,Shangbo Wang", "background": "精确的交通预测对于智能交通系统（ITS）至关重要，但当前的方法难以处理交通动力学的内在复杂性和非线性，使得集成空间和时间特性变得困难。现有方法使用静态技术来处理非稳态和异常的历史数据，限制了其适应性和数据平滑度。", "innovation": "本文提出了一种新的框架——图融合增强网络（GFEN），用于网络级别的交通速度预测。GFEN引入了一种新颖的拓扑时空图融合技术，通过可训练的方法从数据分布和网络拓扑中精确提取并融合时空相关性，能够构建多尺度时空特征。此外，GFEN采用一种结合基于K阶差分的数学框架和基于注意力的深度学习结构的混合方法，以自适应方式平滑历史观察结果，并动态减轻数据异常和非稳态特性的影响。", "conclusion": "通过广泛的实验，GFEN在预测精度上比现有最佳方法提高了约6.3%，并以接近于最近混合模型两倍的速度实现了收敛，证实了其卓越的性能，并显示出显著提升交通预测系统效率的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00093", "html_url": "https://arxiv.org/abs/2507.00093", "title": "$\\sigma$-Maximal Ancestral Graphs", "title_en": "$σ$-Maximal Ancestral Graphs", "authors": "Binghua Yao,Joris M. Mooij", "background": "Maximal Ancestral Graphs (MAGs)提供了一种抽象表示有向无环图（DAGs）中的潜在（选择）变量关系的方法。它们可以编码关于所代表DAGs的祖先关系和d分离信息。MAGs在证明FCI因果发现算法的有效性和完整性方面发挥了重要作用。然而，MAGs的一个显著内在限制是无法表示循环因果关系。本文旨在解决这一限制，介绍了一种新的图形对象，称为$\\sigma$-最大祖先图（$\\sigma$-MAGs），这种图形可以提供循环有向图（DGs）中潜在变量的抽象表示，类似于MAGs对DAGs的表示。", "innovation": "引入并研究了一种新的图形对象$\\sigma$-MAGs，它可以提供循环有向图（DGs）中潜在变量的抽象表示，弥补了MAGs不能表示循环因果关系的局限性。作者展示了$\\sigma$-MAGs的性质，并提供了它们的马尔可夫等价类的刻画。", "conclusion": "本文提出了$\\sigma$-MAGs，一种可以表示循环有向图（DGs）和潜在变量的新图形结构，填补了MAGs在处理循环因果关系方面的空白。通过研究$\\sigma$-MAGs的性质，作者为未来的相关工作提供了理论基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00090", "html_url": "https://arxiv.org/abs/2507.00090", "title": "生成异质多维数据：一项比较研究", "title_en": "Generating Heterogeneous Multi-dimensional Data : A Comparative Study", "authors": "Corbeau Michael,Claeys Emmanuelle,Serrurier Mathieu,Zaraté Pascale", "background": "消防员干预中的人员和物资分配极其敏感，依赖于模拟来实验各种场景。此研究背景在于通过模拟生成数据的方法来优化消防员的响应，并使用定制的评估指标来衡量生成数据的质量，针对消防领域的特殊情况，传统评测指标往往不够精确，因此需要新的评测方法来确保生成数据的实际应用价值和合理性。生成的数据需要包含了响应时间分布、干预的时空分布、事故情况以及一些罕见事件等细节，且数据分布非常不平衡，非高斯分布变量的特性增加了生成数据的难度。", "innovation": "本研究创新之处在于引入并比较了多种数据生成方法，包括随机抽样、表格变分自动编码器、标准生成对抗网络、条件表格生成对抗网络和扩散概率模型，以评估这些方法在捕捉消防干预细节方面的有效性。同时，使用了特定领域的评测指标和标准评测指标（如Wasserstein距离）相结合的方式对生成数据的质量进行了全面的评估，以确保其在真实场景中的应用价值和合理性。", "conclusion": "通过比较研究，发现不同的数据生成方法在捕捉复杂性和细微联系上表现不同。特别地，条件表格生成对抗网络（CTGAN）和扩散概率模型表现出较强的泛化能力和生成高质量数据的能力。这些方法不仅有助于生成高度真实的数据，还为消防干预的实际部署提供了可靠的数据支持。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00082", "html_url": "https://arxiv.org/abs/2507.00082", "title": "通信高效令牌传输的联邦学习使能混合语言模型", "title_en": "Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission", "authors": "Faranaksadat Solat,Joohyung Lee,Mohamed Seif,Dusit Niyato,H. Vincent Poor", "background": "混合语言模型（HLMs）结合了边缘设备上的小型语言模型（SLMs）的低延迟效率和集中服务器上的大型语言模型（LLMs）的高准确性。传统的端到端LLM推理模式由于需要频繁地将模型调用卸载到LLM，因此存在显著的通信开销，特别是在带宽受限的环境中。 FedHLM是一个通信高效的HLM框架，它通过联邦学习（FL）将知情推理与FL集成，以解决这一问题。", "innovation": "FedHLM的关键创新在于通过协作学习令牌级别的不确定性阈值来确定何时需要LLM协助。它利用FL以一种隐私保护、分布式的方式优化这些阈值，而不是使用静态或手动调整的阈值。此外，它还利用基于嵌入的令牌表示为点对点（P2P）解决，使客户端能够在不参与LLM的情况下重用与语义相似的客户端的推理结果。进一步引入了分层模型聚合：通过客户端更新边缘服务器优化本地路由策略，同时跨集群协调在全局决策边界上取得一致。这层设计可以捕捉到重复的不确定性模式，减少冗余的LLM查询。实验表明，在大规模新闻分类任务中，FedHLM能够将LLM传输减少95%以上，并且几乎没有准确性损失，使其非常适合大规模和高效的数据边缘智能应用。", "conclusion": "FedHLM通过实现通信高效的令牌传输，为混合语言模型在联邦学习框架下的应用开辟了新的可能性，从而显著减少了通信开销，特别是在大规模新闻分类任务中实现了显著的性能提升。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00094", "html_url": "https://arxiv.org/abs/2507.00094", "title": "高效检查丰富的数据感知Declare规范", "title_en": "Efficient Conformance Checking of Rich Data-Aware Declare Specifications (Extended)", "authors": "Jacobo Casas-Ramos,Sarah Winkler,Alessandro Gianola,Marco Montali,Manuel Mucientes,Manuel Lama", "background": "尽管对数据驱动规范的流程分析和挖掘越来越感兴趣，基于对齐的符合性检查主要集中在纯控制流规范或对数值数据和变量至常量比较的有限数据感知扩展上。由于数据依赖性的存在，找到对齐在计算上是困难的，因此传统的对齐方法仅限于简单的情况。本文研究了在引用模型用数据感知的Declare表达，包含通用数据类型和数据条件的情况下，对齐的计算问题。虽然在数据依赖复杂的情况下，找到对齐是计算上困难的，但论文展示了在这种丰富设置下，仍然可以通过结合现有的两种最佳控制流和数据依赖处理方法（A*搜索和SMT求解）来高效且表达能力强地计算数据感知的最优对齐。", "innovation": "本文通过精心结合控制流处理技术与SMT求解技术，提出了一个新的算法技术，能够高效地探索搜索空间，通过应用修正常量动作逐步解决约束冲突，实现了在通用数据类型和数据条件环境中高效且表达能力强的数据感知最优对齐。此外，研究证明了该算法的正确性，并展示了它的高效性，实验结果表明该方法在性能上超越了现有最好的方法，同时还支持更加复杂的约束，因此具有支持实际应用的潜力。", "conclusion": "本文证明了在数据感知的Declare规范中计算数据意识最优对齐的可能性，并且这种实现方法在效率和表达能力方面都表现优异。这种方法超过了现有的最优方法，并支持更复杂的约束，展示了其在现实应用中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00102", "html_url": "https://arxiv.org/abs/2507.00102", "title": "迈向制造中的透明和数据驱动的故障检测：一种针对单一变量离散时间序列的案例研究", "title_en": "Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series", "authors": "Bernd Hofmann,Patrick Bruendl,Huong Giang Nguyen,Joerg Franke", "background": "在现代制造中，确保一致的产品质量，尤其是在关键安全应用中，至关重要。传统的质量控制方法依赖于手工定义的阈值和特征，这在应对生产数据中的复杂性和变异性方面不具备灵活性，并且需要大量的专业知识。相比之下，机器学习等数据驱动方法虽然在检测性能方面表现出色，但通常作为黑盒模型运作，缺乏工业应用的可解释性，使得接受度较低。因此，研究提出了一种结合监督机器学习的多类故障分类、Shapley加性解释进行后验可解释性，以及专门领域的可视化技术，该技术将模型解释映射到操作员可解释特征的研究方法，以提高故障检测的透明度和可解释性，增强在工业质量控制中的应用信任度。这种方法应用于一种关键安全工艺——压焊，通过单一变量离散时间序列的数据集实现了95.9%的故障检测精度，并通过定量扰动分析和定性的专家评估证实了解释的相关性和可解释性。", "innovation": "该研究引入了一种结合监督机器学习模型的多类故障分类、Shapley加性解释进行后验可解释性，以及专门领域的可视化技术，用于故障检测的方法。该方法实现了在工业环境中的有效应用，提高了数据驱动与可解释性的结合，并显著增强了使用工业质量控制的信任度和解释性。这种方法不同于传统的手工定义阈值和特征，以及纯粹的黑盒机器学习模型，而是提供了一种平衡性能和解释性的创新解决方案。", "conclusion": "本研究提出的方法成功地将数据驱动的故障检测与透明度和解释性相结合，通过应用于压焊工艺，实现了高精度的故障检测（95.9%），并通过定量和定性评估证实了模型解释及可视化技术的有效性和实用性。该方法的提出将为提高工业质量控制体系的设计应用中的人类信任度和可解释性贡献重要力量。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00108", "html_url": "https://arxiv.org/abs/2507.00108", "title": "在生成式AI时代的编程教学：文献洞见、教学建议及学生观点", "title_en": "Teaching Programming in the Age of Generative AI: Insights from Literature, Pedagogical Proposals, and Student Perspectives", "authors": "Clemente Rubio-Manzano,Jazna Meza,Rodolfo Fernandez-Santibanez,Christian Vidal-Castro", "background": "随着基于大型语言模型的强大新工具推动下的自动源代码生成工具的发展，计算机编程正在发生真正的变革。这种变革同样在世界各地大学的入门级编程课程中显现，引发了关于如何在生成式人工智能的背景下教授、学习和评估编程内容的深入讨论。", "innovation": "文章一方面回顾了相关研究，强调了专著文献中识别的优势和劣势；另一方面提议通过聚焦于代码理解与执行，而非仅仅编码或程序功能的教学方法，使教学、学习和评估更加丰富，特别推崇使用代码的可视化表现形式和其执行的可视化模拟作为有效的教学工具，激发学生更深层的理解。", "conclusion": "文章最后提出了学生的反馈，支持在面向对象编程课程中将Java（或其他语言）的可视化模拟纳入培训过程作为初步背景，为推广使用可视化模拟提供了初步的支持。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00195", "html_url": "https://arxiv.org/abs/2507.00195", "title": "数据异质性和光滑性在局部更新中的作用", "title_en": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness", "authors": "Kumar Kshitij Patel", "background": "该论文致力于理论理解在分布式和联邦优化中起作用的局部更新算法，特别是在现实数据异质性模型下的局部SGD算法。重点关注的是有界二阶异质性假定，并且该假定被证明是局部更新在凸和非凸设置中优于中心化或者小批量方法的必要和充分条件。论文在多个环境中为不同局部更新算法建立了紧绷的上界和下界，并对多个问题类别进行了复杂度分析。", "innovation": "核心贡献在于提出了细粒度的共识误差分析框架，在满足第三阶光滑性和放宽异构性假设的情况下，提供了更精确的有限时间收敛界。该论文还扩展到了在线联邦学习中，给出了基于一阶和 bandit 反馈的基本后悔界。总的来说，这些结果阐明了当且为何局部更新提供可证明优势的条件。", "conclusion": "该论文为分析异质环境中局部SGD提供了一个自包含的指南，并且澄清了局部更新提供可证明优势的时刻和原因。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00096", "html_url": "https://arxiv.org/abs/2507.00096", "title": "AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets", "title_en": "AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets", "authors": "Ailiya Borjigin,Wei Zhou,Cong He", "background": "替代资产代币化正在转变非传统金融工具在网络中的表示和交易。然而，确保基于网络的代币化生态系统中的可信性提出了重大挑战，从离链资产数据的验证到执行监管合规性。因此，需要一种智能代理架构，将智能代理与区块链集成，实现网络可信的替代资产代币化，以增强透明度、安全性和合规性，解决数据真实性与欺诈的问题，并通过实时AI异常检测和链上执行减轻房地产资产代币化过程中的风险（如欺诈性房源和洗钱）", "innovation": "本文提出了一个由智能代理与区块链集成的AI治理代理架构，该架构能够自治代理协调代币化过程（资产验证、估值、合规检查和生命周期管理），并通过智能驱动的治理层监控代理行为，实施信任策略，并通过加密经济激励来促进信任。这项工作提供了一个新的框架，用于在基于网络的资产代币化生态系统中增强信任，为希望部署安全且合规的代币化平台的从业者提供了见解", "conclusion": "与现有的基于AI治理的多智能体系统和区块链结合，可以显著增强代币化资产生态系统中的信任程度，为在网络中实现可信的资产代币化提供了一种新的方法，为从业者部署安全、合规的代币化平台提供了新的见解"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00191", "html_url": "https://arxiv.org/abs/2507.00191", "title": "超越传感器数据：可穿戴设备中的行为数据基础模型改善了健康预测", "title_en": "Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions", "authors": "Eray Erturk,Fahad Kamran,Salar Abbaspourazad,Sean Jewell,Harsh Sharma,Yujie Li,Sinead Williamson,Nicholas J Foti,Joseph Futoma", "background": "可穿戴设备记录的生理和行为信号可以提高健康预测。尽管基础模型在这些预测中越来越被使用，但它们主要应用于低级传感器数据，而行为数据由于其与生理相关的时间尺度和数量更具有信息价值，因此通常更具有信息性。现有研究表明，行为数据在特定健康任务中的应用前景广阔，特别是在行为驱动的任务如睡眠预测上表现优越。为进一步探索这一领域，本文利用2.5亿小时的可穿戴数据（来自162000名个体），系统地优化了适用于该独特数据集的架构和标记策略，评估了模型在57个与健康相关的任务上的表现，发现该模型在多种实际应用中表现出色，特别是在行为驱动的任务中，如睡眠预测，并且当结合原始传感器数据表示时，性能进一步提升。这些结果强调了为可穿戴设备量身定制基础模型设计的重要性，并展示了通过新健康应用的潜力。", "innovation": "本文开发了基础模型来处理行为信号，这与传统的以传感器数据为基础的模型不同，它系统地优化了适用于大量独特数据集的架构和标记策略。研究结果表明，当结合原始传感器数据时，该模型在行为驱动的任务，如睡眠预测方面表现尤为出色。此外，研究锁定在2.5亿小时的可穿戴数据集，涉及162000名个体，这为理解行为数据在健康预测中的作用提供了独特的机会。", "conclusion": "本文的研究成果证明了基础模型设计需要针对可穿戴设备进行定制，并展示了行为数据在健康预测中的潜力，特别是在与行为驱动的任务相关方面。未来的研究可以基于这些发现进一步开发新的健康应用，以改善个人健康管理和监控。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00161", "html_url": "https://arxiv.org/abs/2507.00161", "title": "设计适应性叙事平台以在政治极化学习环境中促进公民教育", "title_en": "Designing an Adaptive Storytelling Platform to Promote Civic Education in Politically Polarized Learning Environments", "authors": "Christopher M. Wegemer,Edward Halim,Jeff Burke", "background": "政治极化削弱了公民教育的效果，因为它会导致人们对自己政治阵营外的成员持有对立观点的抗拒心理。新兴的人工智能技术为减少极化和促进政治开放性提供了新的契机。文章介绍了一种新颖的设计策略，运用行动性和情感响应式的叙事手段来保持学生在叙事中的情感参与度，并通过这些手段促进对政治对立群体成员的换位思考。文章基于政治心理学和叙事学理论，探讨了情感计算技术如何支持叙事中的三个机制：故事世界的沉浸、对角色的认同以及与叙述者的互动。研究者采用基于设计的研究方法，迭代开发并完善了一个由AI介导的数字公民叙事平台（AI-DCS），通过整合面部情绪识别和注意力跟踪技术，实时评估用户的情绪和注意力状态；通过GPT-4实现在叙事内容中的逐字语言适应，以保持学生对不同政治观点的叙事内容的情感参与。", "innovation": "研究开发了一个AI介导的数字公民叙事平台（AI-DCS），通过结合多模态的情感计算技术和情境化叙事设计，实现叙事内容的个性化调整，从而提高学生对政治对立观点的叙事内容的情感参与度，并促进对不同政治群体成员的换位思考。这一平台是AI支持的、情感感知的策略基础，旨在减轻情感极化的同时保留学习者的自主性。这项工作代表了一个新的研究方向，即通过技术手段来辅助和改善公民教育的效果。", "conclusion": "该研究指出了在公民教育中利用AI进行情感感知策略的可能性和挑战，强调了算法素养的重要性，并提出了人机交互界面中AI对话管理和情感适应性学习环境的设计挑战。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00225", "html_url": "https://arxiv.org/abs/2507.00225", "title": "利用人工智能发现标准模型常数的内在分析结构", "title_en": "Discovering the underlying analytic structure within Standard Model constants using artificial intelligence", "authors": "S. V. Chekanov,H. Kjellerstrand", "background": "本文基于符号回归和遗传编程的方法，探索标准模型（SM）的基本参数中的潜在分析结构。通过对大量的表达式进行筛选，以相对精度优于1%的高质量表达式，识别出基本参数间最简单的分析关系，并发现了若干显著观察结果。这些结果将有助于模型构建者和针对SM常数之间隐藏模式的人工智能方法，或作为连接SM参数的基本常数的小集合的基础构建块。", "innovation": "利用符号回归和遗传编程的方法来寻找标准模型常数之间的简洁的分析关系。这种方法能够有效地在大量的表达式中筛选出高质量的表达式，并识别出基本参数间的最简单关系，这对模型构建以及发现更深层次的潜在规律具有重要意义。", "conclusion": "本文通过人工智能方法发现了标准模型常数之间潜在的分析结构，并报告了几项重要的观察结果。这些发现可以作为模型构建和复杂物理规律探索的重要输入。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00185", "html_url": "https://arxiv.org/abs/2507.00185", "title": "多模态、多疾病医疗影像基础模型 (MerMED-FM)", "title_en": "Multimodal, Multi-Disease Medical Imaging Foundation Model (MerMED-FM)", "authors": "Yang Zhou,Chrystie Wan Ning Quek,Jun Zhou,Yan Wang,Yang Bai,Yuhe Ke,Jie Yao,Laura Gutierrez,Zhen Ling Teo,Darren Shu Jeng Ting,Brian T. Soetikno,Christopher S. Nielsen,Tobias Elze,Zengxiang Li,Linh Le Dinh,Lionel Tim-Ee Cheng,Tran Nguyen Tuan Anh,Chee Leong Cheng,Tien Yin Wong,Nan Liu,Iain Beehuat Tan,Tony Kiat Hon Lim,Rick Siow Mong Goh,Yong Liu,Daniel Shu Wei Ting", "background": "当前的医疗影像人工智能模型主要是单模态和单疾病。虽然尝试创建多模态和多疾病模型，但其临床准确性存在不一致现象。此外，这些模型的训练通常需要大量的、劳动密集型以及标注良好的数据集。", "innovation": "开发了梅尔梅德-FM (MerMED-FM)，这是一种最先进的多模态、多专科基础模型，采用自我监督学习和记忆模块进行训练。该模型结合了10个专科和7种成像模态的330万张医学图像，包括计算机断层扫描(CT)、胸部X光片(CXR)、超声(US)、病理切片、彩色眼底摄影(CFP)、光学相干断层扫描(OCT)和皮肤病图像。与现有的基础模型相比，MerMED-FM 在多种疾病上的表现非常出色，各种模态的AUROCs分别为 0.988 (OCT)；0.982 (病理)；0.951 (超声)；0.943 (CT)；0.931 (皮肤)；0.894 (CFP)；0.858 (CXR)。", "conclusion": "MerMED-FM 有望成为高度适应性的、多样化的跨专科基础模型，能够跨医学学科提供稳健的医疗影像解释。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00227", "html_url": "https://arxiv.org/abs/2507.00227", "title": "探究语音合成中韵律建模的随机方法", "title_en": "Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis", "authors": "Paul Mayer,Florian Lux,Alejandro Pérez-González-de-Martos,Angelina Elizarova,Lindsey Vanderlyn,Dirk Väth,Ngoc Thang Vu", "background": "虽然生成方法近年来取得了快速进展，但生成具有表现力的韵律的语句仍然是文本到语音合成中的一个具有挑战性的任务。特别是对于明确通过音高、能量和时长等参数建模韵律的系统，原因是为了提高解释性和可控制性。本文旨在探讨随机方法在这种任务中的有效性，包括归一化流、条件流匹配和修正流。", "innovation": "该研究比较了随机方法与传统的确定性基线方法，以及实际的人类实现。实验结果显示，随机方法通过捕捉人类语音中固有的变异性，能产生自然的韵律，与人类演讲者相当，并且通过调整采样温度还提供了额外的可调节选项。", "conclusion": "研究发现，随机方法在韵律建模方面表现出色，能够生成媲美人类的自然韵律，并且开放了更多的可控性选项。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00209", "html_url": "https://arxiv.org/abs/2507.00209", "title": "SurgiSR4K：用于机器人辅助微创手术的高分辨率内窥镜视频数据集", "title_en": "SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures", "authors": "Fengyi Jiang,Xiaorui Zhang,Lingbo Jin,Ruixing Liang,Yuxin Chen,Adi Chola Venkatesh,Jason Culman,Tiantian Wu,Lirong Shao,Wenqing Sun,Cong Gao,Hallie McNamara,Jingpei Lu,Omid Mohareri", "background": "高分辨率成像是提高视觉清晰度和实现精确计算机辅助指导的关键，尤其是在微创手术（MIS）中。尽管4K内窥镜系统越来越受欢迎，但专门用于机器人辅助MIS的高质量4K数据集仍然短缺。目前的数据库未能充分反映实际手术室中的多种视觉挑战，包括反光、器械遮挡、出血和软组织变形等。", "innovation": "SurgiSR4K是第一个提供公有访问权限的高分辨率手术数据集，以4K原始分辨率拍摄，涵盖了多种真实手术场景下的视觉情况，有助于增强图像分辨率、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新颖视图合成和视觉语言模型（VLM）开发等计算机视觉任务。该数据集为高分辨率手术影像的研究提供了坚实的基础，并促进了智能成像技术的发展，提升图像引导机器人手术的性能、安全性和易用性。", "conclusion": "SurgiSR4K为高分辨率手术影像研究和智能成像技术发展提供了强有力的支持，能够广泛应用于多种计算机视觉任务，有助于推动微创手术和相关技术的进步。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00145", "html_url": "https://arxiv.org/abs/2507.00145", "title": "AI-Hybrid TRNG: 基于核的深度学习在物理噪声中近似均匀熵的采集", "title_en": "AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise", "authors": "Hasan Yiğit", "background": "目前，真随机数生成器（TRNG）通常需要昂贵的硬件或者专门的量子设备。这些硬件不但成本高昂，而且部署较为复杂。为了克服这些限制，研究人员开发了一种新的AI-Hybrid TRNG框架，它能够直接从物理噪声中提取几乎等概率的熵，无需复杂和昂贵的设备，而是通过低成本的射频前端和CPU定时抖动进行训练，从而生成32位的高熵流，且无需量化步骤。这种方法无需依赖专用硬件，而是利用自适应的自然源和重新播种机制，保证了生成序列的真正不可预测性和自主性，从而拓宽了高完整性随机数生成器在安全系统、加密协议、嵌入式和边缘设备、随机过程模拟及服务器应用中的应用场景。这种方法生成的数字通过了NIST SP 800-22电池测试和十九种定制统计测试，结果符合加密标准，且前向和后向预测实验也未显示出任何可被利用的偏差。模型的脚印低于0.5MB，这使得它可以部署在MCU和FPGA软核心上以及其他资源受限的平台上。简而言之，这一新的AI-Hybrid TRNG框架克服了传统随机数生成的固有局限性，并大幅简化了其部署方式。", "innovation": "AI-Hybrid TRNG是一种基于深度学习的真随机数生成器，它通过低成本的射频前端和CPU定时抖动进行训练，直接从物理噪声中提取几乎等概率的熵，无需依赖昂贵的量子设备或其他专门硬件。这种方法不仅成本低，而且生成的数字序列具有高度不可预测性和自主性，通过了严格的NIST及自定义统计测试，满足加密标准。此外，模型的体积小，适用于MCU和FPGA软核心等资源受限的平台。这种创新方法简化了真随机数生成器的部署，拓宽了在各种应用中的适用场景。", "conclusion": "AI-Hybrid TRNG通过基于深度学习的自适应自然源和重新播种机制，不仅提高了真随机数生成器的安全性和可靠性，还显著降低了成本和复杂度。它有效地实现了物理噪声到高可信随机数序列的转化，通过严格的测试满足了加密安全要求。同时，模型的轻量化特点使得它在资源有限的设备上也具有很强的实用性，为安全系统、加密协议、嵌入式设备等多个领域提供了高效的随机数生成解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00214", "html_url": "https://arxiv.org/abs/2507.00214", "title": "两阶段注入推理学习：利用LLM生成的推理改进分类", "title_en": "Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning", "authors": "Mads Henrichsen,Rasmus Krebs", "background": "传统的分类模型通常将输入直接映射到标签，缺乏显式推理过程，这可能限制了它们的性能、鲁棒性和可解释性。", "innovation": "该论文提出了一种两阶段的方法，通过利用大型语言模型（LLM）生成的推理来增强文本分类。首先，作者利用一个通用推理数据集对Llama-3.2-1B-Instruct模型进行微调，以生成给定问题和答案的文本推理。其次，使用这个预先训练的Llama-R-Gen来为下游生成模型创建一个增加的数据集。下游模型基于Llama-3.2-1B-Instruct，只接受输入文本，但训练输出生成的推理和预测的情绪。这种方法在dair-ai/emotion数据集上进行了实验，表明能够显著提高情感预测的准确性，并通过显式推理训练展现了强大的泛化能力。", "conclusion": "这项工作强调了LLM生成的推理在创建更丰富的训练数据集方面的潜力，从而提高了各种下游NLP任务的性能，并提供了明确的解释。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00229", "html_url": "https://arxiv.org/abs/2507.00229", "title": "使用复域全局注意力模块及频谱时域损失的高保真度语音超分辨率网络", "title_en": "A High-Fidelity Speech Super Resolution Network using a Complex Global Attention Module with Spectro-Temporal Loss", "authors": "Tarikul Islam Tamiti,Biraj Joshi,Rida Hasan,Rashedul Hasan,Taieba Athay,Nursad Mamun,Anomadarshi Barua", "background": "语音超分辨率（SSR）通过增加采样率来提升低分辨率语音的质量。尽管大多数SSR方法侧重于幅度重构，但近期研究表明，相位重构对于提升感知质量非常重要。现有的多数SSR方法主要关注于幅度的重建，而忽视了相位的重构，这对提高语音的清晰度和自然度至关重要。因此，本文在此背景下提出了CTFT-Net网络，旨在同时重构幅度和相位来改进SSR任务，目标是提高频率重建质量和噪声鲁棒性。", "innovation": "本文创新地提出CTFT-Net（Complex Time-Frequency Transformation Network）网络，该网络在复数域中同时重构幅度和相位，采用复数全局注意力模块来建模跨音素和频域之间的依赖关系，同时利用复数卷积捕捉长距离和局部特征，以提高频率重构和噪声鲁棒性。此外，CTFT-Net采用时域和多分辨率频域损失函数，以提升模型的泛化能力。该模型特别适用于极端采样率增益场景，能够有效重建高频率而不产生噪声伪影。", "conclusion": "实验结果表明，CTFT-Net在VCTK数据集上优于现有的先进模型（如NU-Wave、WSRGlow、NVSR和AERO），特别是在2kHz到48kHz的极端采样率增益场景下，能够有效重建高频部分且无噪声伪影。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00184", "html_url": "https://arxiv.org/abs/2507.00184", "title": "使用各种文本编码器的文本到关卡扩散模型——以超级马里奥兄弟为例", "title_en": "Text-to-Level Diffusion Models With Various Text Encoders for Super Mario Bros", "authors": "Jacob Schrum,Olivia Kilday,Emilio Salas,Bess Hagan,Reid Williams", "background": "最近的研究已经展示出生成基于瓷砖的游戏关卡时扩散模型可以实现无条件生成，但对于文本转关卡生成的使用则较少被探索。在实际应用中，创建一个易用的模型涉及需要包含描述性文本和游戏关卡的配对，同时还需要一个文本嵌入模型和一个生成整个可玩关卡的方法，而不仅仅是单个场景。本文介绍了自动为现有关卡数据集分配描述性标题的策略，并使用预训练的文本编码器和平头模型训练扩散模型。生成关卡的描述性标题也被自动分配，以便可以比较输入和输出描述的重叠程度。同时对关卡的多样性和可玩性进行了评估。结果与未条件扩散模型和生成对抗网络进行了比较，并与Five-Dollar Model和MarioGPT的文本转关卡方法进行了对比。值得注意的是，最好的扩散模型使用一个简单的平头模型作为文本嵌入，并且比使用更复杂的文本编码器训练扩散模型所需时间更短，说明并不一定需要依赖较大的语言模型。此外，还提供了一个图形用户界面，允许设计师从模型生成的场景中构建长关卡", "innovation": "本文提出了一种策略，以自动为现有关卡数据集分配描述性标题，并使用预训练的文本编码器和平头模型训练扩散模型。模型结果显示，简单平头模型的文本嵌入效果最好且训练效率更高。还提供了一个图形用户界面，使设计师能够使用生成的场景构建长关卡。", "conclusion": "最佳的扩散模型使用简单的平头模型进行文本嵌入，并且比使用更复杂文本编码器的模型训练速度快。该工作表明在处理游戏关卡生成任务时，可能并不总是必须单独训练大型语言模型。该研究在自动分配描述性标题和生成可玩游戏关卡的同时，提高了多样性和可玩性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00239", "html_url": "https://arxiv.org/abs/2507.00239", "title": "在对齐的语言模型中线性解码被拒绝的知识", "title_en": "Linearly Decoding Refused Knowledge in Aligned Language Models", "authors": "Aryan Shrivastava,Ari Holtzman", "background": "大多数常用的语言模型通过指令调优和强化学习进行微调，这可能会使它们拒绝执行被认为有害的用户请求。然而，跳出约束的提示（jailbreak prompts）可以绕过这些拒绝机制并生成有害的响应。该研究旨在探讨通过跳出约束的提示访问的信息能否被线性探针所预测，发现大量最初被拒绝的信息是可以通过线性方法解码的。例如，在跨模型中，被跳出约束的语言模型对于国家平均智商的回答可以被线性探针准确预测，并且皮尔逊相关系数超过0.8。研究还发现，即使未拒绝的基模型训练出来的探针可以转移到指令调优版本中，揭示跳出约束生成的信息，表明许多被拒绝的内部表示仍然存在于指令调优的语言模型中。该研究发现这些信息并非仅存在于模型的残留部分，而是被其激活表达，甚至在下游任务中的其他微妙表达中也存在。这表明指令调优没有完全消除或重新定位有害信息，而是抑制了其直接表达，使得信息既线性可访问又间接影响下游行为，", "innovation": "研究指出，语言模型在指令调优过程中没有消除有害信息，而是抑制了其直接表达，使得信息既线性可访问又间接影响下游行为。通过线性探针提取出被拒绝的信息，并揭示了这些信息在下游任务中的间接影响。", "conclusion": "指令调优没有完全消除或重新定位有害信息，而是抑制了它们的直接表达，这些信息既线性可访问又间接指导下游行为。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00248", "html_url": "https://arxiv.org/abs/2507.00248", "title": "使用有限数据开发轻量级DNN模型进行实时手语识别", "title_en": "Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition", "authors": "Nikita Nikitin,Eugene Fomin", "background": "手语识别面临着数据稀缺、高计算成本以及训练和推理环境帧率不一致等关键挑战。现有的解决方案往往难以兼顾这些因素，尤其是在资源有限的边缘设备上实现高精度的实时识别。本研究提出了一种基于轻量级DNN的手语识别框架，旨在解决上述问题，特别是在数据量受限的情况下也能保持较高的识别精度。通过将手语的特定参数（如手形、手掌方向、动作和位置）编码成向量输入，并利用MediaPipe进行关键点提取，实现了高度分离的输入表示。", "innovation": "本研究的创新点在于提出了一种利用轻量级DNN（模型大小小于10MB）进行实时手语识别的框架，通过将手语手势的特定参数编码为向量形式，以及使用MediaPipe进行关键点检测，使得输入数据具有良好的区分性。模型能够在边缘设备上以不到10毫秒的延迟准确识别343个手语动作，同时开发了一个数据注释平台'SLAIT Data'，用于结构化标注和向量提取。实验结果表明，该模型在孤立手语识别中的准确率达到了92%，并在SLAIT AI网页应用中稳定运行，展示了其实时识别能力。", "conclusion": "本研究开发了一种轻量级DNN模型，能够实现实时手语识别，即使在有限的数据条件下也能保证较高的识别精度。通过减少模型大小和优化计算，该模型在边缘设备上具有高效性，展示了在实际应用场景中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00257", "html_url": "https://arxiv.org/abs/2507.00257", "title": "Gym4ReaL: 用于评估现实世界强化学习的一套环境", "title_en": "Gym4ReaL: A Suite for Benchmarking Real-World Reinforcement Learning", "authors": "Davide Salaorni,Vincenzo De Paola,Samuele Delpero,Giovanni Dispoto,Paolo Bonetti,Alessio Russo,Giuseppe Calcagno,Francesco Trovò,Matteo Papini,Alberto Maria Metelli,Marco Mussi,Marcello Restelli", "background": "近年来，强化学习（RL）取得了显著进展，已经在多种模拟环境中达到了超人类性能。随着研究转向在现实世界的应用部署，RL 面临一系列新的挑战，如状态-动作空间庞大、环境非平稳、观察受限等。尽管这些挑战在现实世界中至关重要，但在当前的基准测试中却常常被忽视，这些基准测试倾向于关注理想化的、完全可观测的、非变化的环境，忽略了引入现实世界的复杂性。", "innovation": "本文提出了 Gym4ReaL，这是一个全面的现实世界环境套件，旨在支持在现实场景中运行和评估 RL 算法。该套件包含一系列多样化任务，让算法暴露于多种实际挑战之中。实验结果显示，标准 RL 算法在这些设置下仍然具备与基于规则的基准测试相当的竞争力，这促使我们需要开发更多方法来充分利用 RL 解决现实世界的复杂任务的潜力。", "conclusion": "本文通过引入 Gym4ReaL，帮助识别和解决 RL 在现实世界应用中的挑战，表明标准 RL 算法在这种现实环境中表现出色，鼓励开发新方法以全面发挥 RL 的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00234", "html_url": "https://arxiv.org/abs/2507.00234", "title": "时间序列人工智能的可解释性：具有全局注意力的多模型热力图融合与NLP生成的解释", "title_en": "Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations", "authors": "Jiztom Kavalakkatt Francis,Matthew J Darr", "background": "现有的可解释性方法在时间和空间上存在对齐问题，卷积网络无法捕捉全局上下文，而Transformer缺乏局部精准度。这些问题在如医疗保健和工业监控等关键领域妨碍了可操作的洞察力。", "innovation": "提出了一个整合由ResNet单独生成的热图和重构成的2D Transformer的全局加权输入显著性新框架，将其与统一可视化中的梯度加权激活图和Transformer注意力时间和空间对齐结合起来，实现全面对齐的同时保持实时性能。综合框架在临床和工业数据集上显示出显著提高，NLP模块将融合热图转换为领域特定的叙述，得到BLEU-4和ROUGE-L评分验证。", "conclusion": "通过将可解释性正式化为因果保真度和时间空间对齐，该方法为透明、时间意识的决策提供了可扩展的解决方案，促进了技术输出和利益相关者理解之间的桥梁。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00258", "html_url": "https://arxiv.org/abs/2507.00258", "title": "大型语言模型微调方法对记忆影响", "title_en": "Impact of Fine-Tuning Methods on Memorization in Large Language Models", "authors": "Jie Hou,Chuxiong Wu,Lannan Luo,Qiang Zeng", "background": "随着预训练大语言模型（LLMs）能力的不断进步，\"预训练和微调\"范式已经成为主流，催生了各种微调方法的发展。但是，在微调过程中产生隐私风险，即记忆风险，尚未得到充分的关注。因此，本文对流行的微调方法进行了分类，并通过成员推理攻击（MIA）的视角评估它们对记忆的影响。研究表明，相比于基于参数的微调，基于提示的微调在性能表现相近的情况下，对MIA的脆弱性较低，并且无论模型规模如何，都保持低记忆特性。这些发现表明，基于参数的微调更容易泄露隐私信息，而基于提示的微调则是一种更具有隐私保护性的选择。", "innovation": "本文创新地通过成员推理攻击（MIA）来评估不同微调方法对记忆的影响，并发现基于提示的微调方法在隐私保护方面相对于基于参数的微调更具优势，无论模型规模如何，均表现为低记忆、低脆弱性。", "conclusion": "本文研究表明，基于参数的微调方法在微调过程中更容易泄露用户数据，而基于提示的微调方法在保持性能相近的同时，提供了更强的隐私保护能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00287", "html_url": "https://arxiv.org/abs/2507.00287", "title": "自监督多视图X射线配准", "title_en": "Self-Supervised Multiview Xray Matching", "authors": "Mohamad Dabboussi,Malo Huard,Yann Gousseau,Pietro Gori", "background": "多视角X射线在骨折、肌肉损伤及其他异常诊断中至关重要。尽管基于AI的单一图像分析技术取得了显著进展，但当前方法在建立不同X射线视角之间稳健对应关系方面仍存在问题，这是精确临床评估所必需的。为了改善这一问题，本研究提出了一种新的自监督管道，通过自动生成合成X射线视角间的多对多对应关系矩阵，避免了手动标注的需求。该管道利用从未标注CT体积自动推导出的数字重建X射线（DRR）实现这一目标。在实验中，研究还展示了在合成X射线视角中学习对应关系作为预训练策略的有效性，以增强在实际数据上的自动多视角骨折检测性能。评估结果表明，在多视角骨折分类中整合对应关系可以提高性能。", "innovation": "本研究提出了一种新的自监督管道，通过自动生成未标注CT体积的DRR来实现合成X射线视角之间的多对多对应关系。该管道利用了一个基于转换器的训练阶段，能够准确预测两个或多个X射线视角间的对应关系。此外，该研究还展示了在合成X射线视角中学习对应关系作为预训练策略的有效性，从而提升了在实际数据上的自动多视角骨折检测性能。", "conclusion": "通过这种方法，研究成功地提高了多视角骨折分类的性能，展示了自监督学习在解决多视图X射线分析挑战中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00269", "html_url": "https://arxiv.org/abs/2507.00269", "title": "特征整合空间：联合训练揭示神经网络表示中的双重编码", "title_en": "Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations", "authors": "Omar Claflin", "background": "当前的稀疏自编码器(SAE)方法基于神经网络解释性假设激活可以通过线性叠加分解为稀疏、可解释的特征。尽管具有高重建精度，但SAEs仍无法消除多义性，并表现出病态的行为错误。", "innovation": "该研究提出神经网络在同一个底物中编码信息有两种互补的空间：特征身份和特征整合。为了验证这种双重编码假设，开发了序列训练和联合训练架构，同时捕捉身份和整合模式。联合训练实现了41.3%的重建改进和51.6%的KL散度误差减少。此外，小的非线性组件（参数的3%）实现了16.5%的独立改进，证明了计算关系的关键捕获，这些关系对于行为来说是参数有效率的。干预实验结果显示整合特征对实验操纵具有选择性的敏感性，导致模型输出中产生系统性的行为效应，包括跨语义维度的显著交互效应。这项工作为(1)神经表示中的双重编码，(2)有意义的非线性编码特征交互，以及(3)从事后特征分析到综合计算设计的架构范式转变提供了系统证据，为下一代SAEs奠定了基础。", "conclusion": "这项工作为神经网络表示中的双重编码、有意义的非线性编码特征交互和架构范式转变提供了系统性的证据，并提出了一种新的自编码器设计方案，该方案从事后特征分析转向集成计算设计，为下一代自编码器奠定了基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00268", "html_url": "https://arxiv.org/abs/2507.00268", "title": "控制优化的深度强化学习在智能自主系统中的应用", "title_en": "Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems", "authors": "Oren Fivel,Matan Rudman,Kobi Cohen", "background": "传统的深度强化学习（DRL）方法通常假设执行动作是完美的，忽视了智能体选定动作与实际系统响应之间的不确定性及偏差。在实际应用中，如机器人学、机械电子和通信网络中，由于系统动力学、硬件限制和延迟等因素导致的执行偏差会严重影响性能。", "innovation": "本研究开发了一种新型的控制优化DRL框架，明确地建模并补偿执行偏差，这在现有方法中是一个未被充分重视的问题。本方法建立了一个结构化的两阶段过程：确定目标动作和选择合适的控制信号以确保正确的执行。训练过程中考虑了执行偏差和控制器的校正，将这些因素纳入训练过程后，AI代理优化了目标动作与实际控制信号和预期结果的关系，具体考虑了执行误差。这种方法增强了鲁棒性，使智能决策在面对现实不确定性时仍然有效。", "conclusion": "本方法通过弥合理想化学习与实际实施之间的差距，为工程实践提供了一项重大进展。智能代理可以在训练过程中预见和调整执行错误和系统干扰，使其在真实的工程环境中更加实用和高效。研究还在五个我们重新构建的开放源代码机械模拟环境中进行了评估，展示了其在控制导向应用中的鲁棒性和高效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00275", "html_url": "https://arxiv.org/abs/2507.00275", "title": "Double Q-learning for Value-based Deep Reinforcement Learning, Revisited", "title_en": "Double Q-learning for Value-based Deep Reinforcement Learning, Revisited", "authors": "Prabhat Nagarajan,Martha White,Marlos C. Machado", "background": "在强化学习（RL）中，过估计问题普遍存在，Q学习算法是许多基于值的深度RL算法的基础。为了应对Q学习中的过估计问题，Double Q-learning算法被引入，该算法通过训练两个Q函数并利用这两个函数进行行动选择和行动评估来降低过估计问题。在基于DQN的深度Q网络中，尽管Double Q-learning被转换为Double DQN，但Double DQN并没有严格地采用Double Q-learning的核心思想，即训练两个彼此关联的Q函数。本文旨在研究如何将Double Q-learning的核心思想应用于基于值的深度强化学习算法，从而设计出Deep Double Q-learning（DDQL）算法", "innovation": "本文提出了一种新的算法Deep Double Q-learning（DDQL），旨在更严格地采用Double Q-learning的核心思想，即训练两个相互关联的Q函数以减少过估计问题。DDQL无需额外的超参数即可在57个Atari 2600游戏中表现出色，相比Double DQN，DDQL能够减少过估计现象并展现出更好的性能。此外，本文对DDQL的网络结构、回放比例以及批量采样策略等几个方面也进行了研究", "conclusion": "DDQL相较于Double DQN，在57个Atari 2600游戏中表现出更好的表现，能够在不引入额外超参数的情况下减少过估计问题。本文还探讨了DDQL的网络架构、回放比例和批量采样策略等几个关键组成部分"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00292", "html_url": "https://arxiv.org/abs/2507.00292", "title": "通过多保真度、模型融合策略降低数字病理学中多种实例学习方法的性能变异性", "title_en": "Reducing Variability of Multiple Instance Learning Methods for Digital Pathology", "authors": "Ali Mammadov,Loïc Le Folgoc,Guillaume Hocquet,Pietro Gori", "background": "数字病理学通过将组织样本数字化为全切片图像(WSIs)来革新该领域，但这带来了高分辨率和大文件大小的挑战，特别是对于深度学习模型的应用。WSIs通常被分割成较小的图像块进行处理，每个切片有一个全局标签，而不是昂贵的像素级注释。通过将每张切片视为图像块的集合，多实例学习（MIL）方法成为WSI分类的合适解决方案。然而，MIL方法在不同批次之间的性能差异性很高，这使得不同MIL方法之间的可靠比较变得困难。这种变异性主要来源于权重初始化、批次排序和学习率三个因素：", "innovation": "我们提出了一种多保真度、模型融合策略来减少MIL方法的性能变异性。首先训练多个模型进行少量的迭代，然后基于验证得分选择最稳定和有前景的模型进行平均处理。这种方法可以应用于任何现有的MIL模型，从而减少性能变异性，简化超参数调优，提高可重复性，同时保持计算效率。我们使用2个数据集、3种初始化策略和5种MIL方法进行了超过2000次实验的广泛验证，以证明该方法的有效性。", "conclusion": "我们的多保真度、模型融合策略可以显著降低MIL方法在数字病理学中应用时的性能变异性，为模型选择和超参数调优提供了一种有效的方法，从而提高了方法的稳定性和可重复性，同时在计算效率方面保持了良好的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00286", "html_url": "https://arxiv.org/abs/2507.00286", "title": "盲和低视力人士使用生成式AI管理视觉隐私", "title_en": "Visual Privacy Management with Generative AI for Blind and Low-Vision People", "authors": "Tanusree Sharma,Yu-Yun Tseng,Lotus Zhang,Ayae Ide,Kelly Avery Mack,Leah Findlater,Danna Gurari,Yang Wang", "background": "盲和低视力（BLV）个体使用生成式AI（GenAI）工具来理解和管理日常生活中的视觉内容。虽然此类工具可以增强视觉内容的易用性，从而提高用户的独立性，但它们也会带来视觉隐私方面的复杂挑战。为了解当前实践和未来设计偏好，研究者通过采访21名参与者进行研究，揭示了用户在六个关键场景中的隐私平衡策略，包括自我展现、室内外空间隐私、社交分享以及处理专业内容等。", "innovation": "研究发现，用户已经能够有效地平衡隐私、效率和情感自我表达的需求，在六个关键场景中采取不同的策略应对隐私风险。研究进一步提出设计偏好，如在设备上进行处理、零储存保证、敏感内容屏蔽、隐私意识的外观指示以及多模态触觉镜像互动方法等，这些发现为通过深入的设计来支持用户为中心的视觉隐私管理提供了实际建议。这些设计建议扩大了隐私的概念并负责任地处理他人的数据。", "conclusion": "研究提出了实用的设计建议，以支持通过生成式AI的用户中心视觉隐私管理，并扩展了隐私定义和处理他人数据的责任感概念。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00310", "html_url": "https://arxiv.org/abs/2507.00310", "title": "通过贝叶斯惊奇实现开放型科学发现", "title_en": "Open-ended Scientific Discovery via Bayesian Surprise", "authors": "Dhruv Agarwal,Bodhisattwa Prasad Majumder,Reece Adamson,Megha Chakravorty,Satvika Reddy Gavireddy,Aditya Parashar,Harshit Surana,Bhavana Dalvi Mishra,Andrew McCallum,Ashish Sabharwal,Peter Clark", "background": "自主科学发现（ASD）不仅仅依赖于回答问题，更重要的是知道提出哪些问题。目前大多数ASD研究集中在使用大型语言模型（LLMs）在目标驱动的环境中进行科学探索，这通常是由人类指定的研究问题来引导假设生成。然而，通过允许AI系统按其自己的标准驱动探索，可能会进一步加速科学发现。现有的一些ASD方法主要基于多样性的直觉策略或人类兴趣的主观代理，这些方法要么难以有效导航广泛的假设空间，要么定义模糊。因此，有必要发展更有效的ASD方法，特别是在探索开放性问题时。", "innovation": "本文介绍了AutoDS，一种通过贝叶斯惊奇量化假设前后知识变化的方法，用于开放型ASD。AutoDS利用蒙特卡洛树搜索（MCTS）策略和渐进扩充方案（使用惊奇作为奖励函数），有效探索嵌套假设空间。实验结果表明，与竞争对手相比，在固定预算下，AutoDS提高了发现惊喜数据的能力，惊喜数据量增加了5-29%。这些发现对领域专家来说也具有很大惊喜感，证明了该方法的创新性和其在创建开放型ASD系统方面的潜力。", "conclusion": "AutoDS在数据驱动的科学发现领域取得了显著成果，能够有效探索数据和生成令人惊讶的发现，这表明它在开放型ASD系统中具有重要作用。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00288", "html_url": "https://arxiv.org/abs/2507.00288", "title": "重构数字责任：后国民会计背景下AI驱动创新与跨国治理", "title_en": "Reconfiguring Digital Accountability: AI-Powered Innovations and Transnational Governance in a Postnational Accounting Context", "authors": "Claire Li,David Freeborn", "background": "随着AI系统在审计和财务报告等领域逐步成为决策的中介，传统的基于控制、透明度和可审计性的问责机制正受到冲击。本研究探讨了AI驱动的数字创新如何在跨国治理背景下重塑组织问责制。", "innovation": "研究整合了技术接受模型（TAM）、行动者网络理论（ANT）和制度理论，分析了组织如何应对超越国界的监管、道德和文化压力，从而采用AI技术。提出将合规性和合法性纳入TAM的应用，重新定义问责制作为一种社会技术网络中关系和自发生成的属性，而非仅由用户感知决定。建议采用内部治理重构和外部行动者网络参与的策略，以促进会计领域的负责任、合法且广受接受的AI采用。", "conclusion": "问责制在跨国社会技术网络中协同构建，不仅受用户感知影响，还受制于治理逻辑和规范期望。在后国民会计背景下，需要通过内部治理改造和外部行动者网络互动的方式促进能够被全球接受的负责、合法的AI应用。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00322", "html_url": "https://arxiv.org/abs/2507.00322", "title": "由干扰导致的错误：当有缺陷机制压倒稳健机制时语言模型在生成平衡括号时出错", "title_en": "Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones", "authors": "Daking Rai,Samuel Miller,Kevin Moran,Ziyu Yao", "background": "尽管编码能力取得了显著进展，语言模型（LMs）仍然在简单的句法任务（如生成平衡括号）上表现不佳。本研究探讨了不同规模（124M-7B）的语言模型出现这些错误的机制，以期理解并解决这些错误。研究表明，语言模型依赖于不依赖于彼此的多种组件（注意头和前馈神经元），这些组件独自进行预测。部分组件在广泛范围的输入下可靠地促进正确答案（即“稳健机制”），而其他组件则不那么可靠，会引入噪声并促进错误标记（即“有缺陷机制”）。错误发生在有缺陷机制主导预测场景，压倒稳健机制时。", "innovation": "提出了RASteer，一种系统地识别并增加可靠组件贡献的方法，以提高模型性能。RASteer显著提高了平衡括号任务的性能，某些模型的准确性从0%提高到约100%，没有损害模型的一般编码能力。此外，该方法还展示了在算术推理任务中的广泛应用，实现了最高约20%的性能提升。", "conclusion": "研究揭示了语言模型出现括号匹配错误的机制，并提出了一种新的方法RASteer来提高模型性能。这个方法不仅在平衡括号任务上取得了显著效果，还在算术推理任务中展示了广阔的适用性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00297", "html_url": "https://arxiv.org/abs/2507.00297", "title": "非洲语言的自然语言处理", "title_en": "Natural language processing for African languages", "authors": "David Ifeoluwa Adelani", "background": "自然语言处理（NLP）技术近年来取得了显著进展，通过大规模未标注数据和自我监督学习提升了性能。但是，多语言模型在处理低资源语言时面临挑战，如数据噪音大和缺乏标注数据集导致难以评估其性能。特别是在撒哈拉以南非洲地区，所有土著语言在标注数据的可用性和网络上的未标注数据方面都可被视为低资源语言。", "innovation": "本文专注于撒哈拉以南非洲地区的低资源语言，通过分析公开可用语料库中的噪音并构建高质量语料库，证明了语义表示的质量不仅取决于数据量，还取决于预训练数据的质量。通过实验展示了词嵌入的局限性以及多语言预训练语言模型（PLM）的机会，尤其是在未见过的语言和低资源场景中的应用。进一步研究如何使用少量单语文本适应和专门化多语言PLM以处理未见过的非洲语言。研究人员还致力于解决非洲语言在NLP研究中的代表性不足问题，开发了21种非洲语言的大规模人工标注数据集，用于命名实体识别和机器翻译两项重要任务，进行了广泛实证评估以检验最新方法在有监督、弱监督和迁移学习设置中的性能。", "conclusion": "通过对噪音的分析和高质量语料库的构建，本文展示了语义表示质量的多维度影响因素，并突显了多语言PLM相较于词嵌入的优势，特别是在低资源语言的适应和专门化方面。研究还致力于提高非洲语言在NLP研究中的代表性，并为这些语言提供了重要数据集和评估方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00347", "html_url": "https://arxiv.org/abs/2507.00347", "title": "VTS-Guided AI Interaction Workflow for Business Insights", "title_en": "VTS-Guided AI Interaction Workflow for Business Insights", "authors": "Sun Ding,Ude Enebeli,Atilhan(Ati)Manay,Ryan Pua,Kamal Kotak", "background": "现代企业面临着大量的密集且非结构化的报告。将这些文档转化为有价值的见解需要耗费大量的人力，并且在需要迅速得出答案时往往不够灵活。", "innovation": "VTS-AI 将视觉思维策略（强调基于证据的观察、关联和思考）整合到AI代理中，使得从非结构化的文本、表格和图像中大规模提取商业洞察成为可能。该系统分为微、中、宏三个级别，能够标明问题、链接来源页面，并将这些信息整理成可搜索的YAML文件中的行动杠杆。VTS-AI 在测试中展示了与一次性ChatGPT提示相当的速度，但提供了更丰富的发现，如页面位置、原文引用片段、严重程度评分和因果关系。此外，VTS-AI 能够让分析师在同一个集成开发环境中接受或调整输出结果，确保了人机协作的持续性。早期结果显示 VTS-AI 能够识别关键指标的方向，并明确哪些地方需要更深的数据分析支持。", "conclusion": "下一步将包括将叙事标签映射到财务比率、通过模型-上下文协议添加财务调整语言模型以及建立风险与安全层以压力测试模型和确保数据安全。这些升级的目标是将VTS-AI打造为一个生产就绪且审计友好的快速商业分析工具。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00358", "html_url": "https://arxiv.org/abs/2507.00358", "title": "连续时间线性-二次强化学习问题的数据驱动探索", "title_en": "Data-Driven Exploration for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems", "authors": "Yilie Huang,Xun Yu Zhou", "background": "本文研究的是连续时间下的线性-二次（LQ）控制问题的强化学习（RL），与之前的文献不同的是，这里的波动性依赖于状态和控制，而状态为标量且控制运行奖励缺失。此前的工作（如@huang2024sublinear）使用了常数或确定性的探索计划，这种方法在实施中需要大量调整，并且不考虑迭代过程中的学习进展。最新的研究提出了一个无需调参的数据驱动探索机制，通过批评家调整熵正则化，并通过演员调整策略方差。这一机制相比之前的固定探索计划，更好地提升了学习效率，且仍然保持了最佳的亚线性遗憾边界。", "innovation": "本文提出的数据驱动探索机制可以自适应地调整熵正则化和策略方差，这与以往的工作不同，之前的探索计划要么是基准，要么是确定性的，需要大量调参且忽视学习进展。本文的方法在保持亚线性遗憾边界的同时，进一步增强了学习效率，且方法灵活，相比非自适应的模型自由和模型基于探索方法，自适应探索加速了收敛并改进了遗憾性能。", "conclusion": "本文的方法在保持亚线性遗憾边界的同时，进一步增强了学习效率，自适应探索机制通过调整熵正则化和策略方差提升学习效率，相较于非自适应模型自由和模型基于方法，本方法加速了收敛并改善了性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00352", "html_url": "https://arxiv.org/abs/2507.00352", "title": "AST指导的LLM方法在SVRF代码合成中的应用", "title_en": "An AST-guided LLM Approach for SVRF Code Synthesis", "authors": "Abanoub E. Abdelmalak,Mohamed A. Elsayed,David Abercrombie,Ilhami Torunoglu", "background": "标准验证规则格式（SVRF）对于半导体应用至关重要，如设计规则检查（DRC）、布局与电路图比对（LVS）和光学邻近校正（OPC）。随着节点的发展，复杂的设计规则使得传统SVRF的发展变得无效，这凸显了在SVRF开发中存在专业知识的缺口。", "innovation": "本文提出了一种新颖的方法论，结合了抽象语法树（AST）嵌入和检索增强生成（RAG），以增强SVRF代码合成。该方法通过结构验证和领域的特定洞察确保语义准确性，并通过一个专门的评分框架补充标准指标（如BLEU和ROUGE-L）来减少错误。AST提供严格的结构验证，而RAG注入相关领域的知识，有效提升了代码生成的工作流程。", "conclusion": "在包含740个DRC规则实现的全面基准测试中，该方法显示出与基于文本的基本微调过程相比高达40%的代码生成准确性提升。这种将行业专业知识与先进的编码策略结合的应用，不仅在数据集有限的情况下优化了SVRF开发，还创造了一个更加直观和有效的工作环境，从而使用户能够快速迭代设计周期，减少手动错误纠正，显著提高总体生产力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00378", "html_url": "https://arxiv.org/abs/2507.00378", "title": "iPanda：智能协议测试与调试代理框架", "title_en": "iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing", "authors": "Xikai Sun,Fan Dang,Kebin Liu,Xin Miao,Zihao Yang,Haimo Lu,Yawen Zheng,Yunhao Liu", "background": "协议实现的符合性测试至关重要，但传统测试方法需要手动创建大量测试案例和脚本，导致过程劳手动、低效率。近期，大型语言模型（LLMs）展示出了出色的文本理解能力和代码生成能力，为自动化测试提供了新的前景。因此，本文探讨了如何利用LLMs自动化进行协议符合性测试的问题背景。", "innovation": "提出了iPanda，这是一个端到端的框架，利用LLMs自动化协议符合性测试。iPanda首先采用关键词法自动生成全面的测试案例，然后使用基于代码的检索增强生成方法来解释实施并生成可执行的测试代码。此外，iPanda还集成了一个迭代自校正机制以改进生成的测试脚本的质量。最后，通过执行并分析生成的测试，系统地验证实现与协议规范的一致性。实验结果显示，与基于LLMs的方法相比，iPanda显著提高了测试代码生成的成功率（Pass@1），提升了4.675到10.751倍。", "conclusion": "iPanda是一个全面的框架，能够有效地利用LLMs自动执行协议符合性测试，不断提高测试的执行效率和成功比率。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00440", "html_url": "https://arxiv.org/abs/2507.00440", "title": "因果图回归方法：重新审视混杂效应", "title_en": "A Recipe for Causal Graph Regression: Confounding Effects Revisited", "authors": "Yujia Yin,Tianyi Qu,Zihao Wang,Yifan Chen", "background": "因果图学习（CGL）已成为改善图神经网络在分布外（OOD）场景下的泛化能力的一种有前途的方法。尽管如此，现有的CGL技术在回归任务中的应用仍处于空白，而回归任务比分类任务更具挑战性。本文聚焦于因果图回归（CGR）问题，重新审视现有CGL方法中对混杂效应的处理方式，以适应回归任务的特性。", "innovation": "本文通过对比学习的视角，将分类任务中特定的因果干预技术推广至回归任务，重新塑造处理混杂效应的方法，通过理论和实验验证了其在图OOD基准上的有效性和实用性，并提供了模型实现和相关代码。", "conclusion": "本文的研究在图回归任务中验证了CGL的有效性，通过重新审视现有CGL方法中的混杂效应处理方式，提出了适合图回归问题的CGL方法，并通过广泛的实验评价证明了这种新方法的优越性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00418", "html_url": "https://arxiv.org/abs/2507.00418", "title": "在HPC群集中为LLMs提供服务：Qualcomm Cloud AI 100 Ultra与高性能GPU的比较研究", "title_en": "Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI 100 Ultra and High-Performance GPUs", "authors": "Mohammad Firas Sada,John J. Graham,Elham E Khoda,Mahidhar Tatineni,Dmitry Mishin,Rajesh K. Gupta,Rick Wagner,Larry Smarr,Thomas A. DeFanti,Frank Würthwein", "background": "本文对Qualcomm Cloud AI 100 Ultra（QAic）加速器在大型语言模型（LLM）推理中的表现进行了基准分析，评估了其能效（瓦特每吞吐量）以及与NVIDIA（A100, H200）和AMD（MI300A）GPU在国家研究平台（NRP）生态系统中的性能对比。研究使用vLLM框架提供了总计15个开源LLM，参数量从1.17亿到90亿不等。研究结果显示，QAic推理卡在大多数情况下表现出良好的能效。", "innovation": "本文通过基准分析首次将Qualcomm Cloud AI 100 Ultra与领先的GPU进行直接对比，提供了能效方面的详细数据，并揭示了该芯片在高性能计算（HPC）应用中的潜在价值", "conclusion": "研究发现，Qualcomm Cloud AI 100 Ultra在能效方面表现良好，尤其是在与NVIDIA和AMD的GPU对比中。这为国家研究平台（NRP）中的高性能计算（HPC）应用提供了有价值的见解。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00419", "html_url": "https://arxiv.org/abs/2507.00419", "title": "地质万物三维模型：一种用于统一和零样本地下理解的可指令基础模型", "title_en": "Geological Everything Model 3D: A Promptable Foundation Model for Unified and Zero-Shot Subsurface Understanding", "authors": "Yimin Dou,Xinming Wu,Nathan L Bangs,Harpreet Singh Sethi,Jintao Li,Hang Gao,Zhixiang Guo", "background": "了解地球的地下结构对于能源转型、自然灾害减轻以及行星科学至关重要。然而，地下分析仍然支离破碎，每个任务（如结构解释、地层分析、地质体分割和属性建模）都需要特定的数据分布和任务表象。", "innovation": "本研究提出了地质万物三维模型（GEM），这是一种统一的生成架构，它将所有这些任务重新表述为基于地下成像推断出的潜在结构框架上的人工提示条件推理。GEM能够通过沿结构框架传播由人类提供的提示（例如井筒记录、掩模或结构草图）产生地质上一致的输出，从而实现跨不同提示类型的任务中零样本的泛化能力。这一能力源自一个两阶段训练过程，该过程结合了在大规模实地地震数据上的自我监督表示学习，以及使用来自多种地层任务的混合提示和标签的大敌对微调。该模型展示了在各种任务中的广泛适用性，包括火星雷达地层学分析、俯冲带的结构解释、全地震地层学解释、地质体界定和属性建模。", "conclusion": "通过将专家知识与结构感知的生成推理相结合，GEM为可扩展的人机协同地球物理AI奠定了基础，从支离破碎的流程转变为垂直整合的、可指令的推理系统。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00407", "html_url": "https://arxiv.org/abs/2507.00407", "title": "通过机器学习原子势增强分子图结构", "title_en": "Augmenting Molecular Graphs with Geometries via Machine Learning Interatomic Potentials", "authors": "Cong Fu,Yuchao Lin,Zachary Krueger,Haiyang Yu,Maho Nakata,Jianwen Xie,Emine Kucukbenli,Xiaofeng Qian,Shuiwang Ji", "background": "分子性质预测需要3D几何结构，通常使用昂贵的密度函数理论（DFT）等方法获得。本文旨在利用机器学习原子势（MLIP）模型直接预测分子几何结构，而不依赖于昂贵的计算方法。为此，该研究采集了一个包含350万分子和3亿个构象的大规模分子弛豫数据集，利用监督学习训练了基础MLIP模型以预测3D结构下的能量和力。研究表明，这些模型可以用于优化几何结构，提供可用于分子性质预测的弛豫3D几何结构，同时引入基于弛豫3D几何结构的几何微调方法来缓解潜在偏差并改善后续预测。此外，当有真实3D几何结构时，基础模型可以直接微调以用于性质预测。这些结果表明，基于弛豫数据训练的MLIP基础模型能够提供支持性质预测的有价值分子几何结构。", "innovation": "该研究通过采集大规模分子弛豫数据集并使用机器学习原子势模型直接预测分子几何结构，提出了一种新的方法来获得分子几何结构，不仅能减少计算成本，还能改善后续的分子性质预测精度。同时，引入了一种基于弛豫3D几何结构的几何微调方法，以进一步优化性质预测结果。", "conclusion": "研究证明，基于弛豫数据训练的机器学习原子势模型能够提供有益的分子几何结构，这对分子性质预测具有重要意义。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00443", "html_url": "https://arxiv.org/abs/2507.00443", "title": "基于鸽子启发的3D障碍检测与避障机动方法在多无人机系统中的应用", "title_en": "Novel Pigeon-inspired 3D Obstacle Detection and Avoidance Maneuver for Multi-UAV Systems", "authors": "Reza Ahmadvand,Sarah Safura Sharif,Yaser Mike Banad", "background": "最近多智能体系统的操作表明，在城市区域部署多无人机系统的需求数量日益增加，而这些区域通常存在静态和动态障碍物。因此，研究提出了受金鱼群集行为和鸽子行为启发的自然启发式无碰撞编队控制方法，以考虑避障机动。该研究框架采用半分布式控制方法，使用概率性的Lloyd算法进行中心化指导算法以实现无人机遇的位置优化，而分布式控制方法则用于车辆间的碰撞和障碍物避障。此外，该框架已被扩展到三维空间，并提出了新的三维机动定义。最终，该框架应用于2D和3D场景中的多无人机系统，并证明了在动态环境中具有静态和移动障碍物时，所提出方法的有效性。", "innovation": "研究提出了一种基于鸽子行为启发的三维障碍检测与避障机动方法。该方法采用半分布式控制策略，结合了中央指导算法和分布式控制策略，以实现无人机遇的位置优化和障碍物避免。此外，该方法在三维空间的应用扩展了其适用范围，并验证了在动态环境中的有效性。", "conclusion": "所提出的基于鸽子启发的3D无碰撞编队控制方法已被应用于2D和3D场景中的多无人机系统，并且实验结果表明该方法在静态和移动障碍物存在的动态环境中是有效的。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00339", "html_url": "https://arxiv.org/abs/2507.00339", "title": "训练X射线视觉：来自多摄像机视频的无遮挡分割、无遮挡内容完成和视-invariant 对象表示", "title_en": "Training for X-Ray Vision: Amodal Segmentation, Amodal Content Completion, and View-Invariant Object Representation from Multi-Camera Video", "authors": "Alexander Moore,Amar Saini,Kylie Cancilla,Doug Poland,Carmen Carrano", "background": "无遮挡分割和无遮挡内容完成要求使用物体先验来估计复杂场景中被遮挡的掩模和物体特征。迄今为止，数据无法提供对象上下文的额外维度：多个摄像机共享同一场景的视野。现有的数据集未充分考虑多摄像机视角和自然遮挡在真实场景中的应用，MOVi-MC-AC 数据集为此领域提供了新的解决方案，特别是在合成和真实世界视频中，可识别和跟踪多个视角之间的物体设置极为罕见。", "innovation": "MOVi-MC-AC 是迄今为止最大的无遮挡分割和首个无遮挡内容数据集。它通过多摄像机（MC）设置提供了多个摄像机共享同一场景的可能性，物体可以在不同的视角之间被识别和跟踪。MOVi-MC-AC 还引入了新的复杂性来合成视频，即为检测和分割之间提供一致的物体标识符，并且每个摄像机具有独特的特征和运动模式。此外，该数据集为无遮挡内容提供了标签，达到约580万物体实例的新高，并且首次提供无遮挡内容的地面真实标签，为无遮挡分割和无遮挡内容完成领域做出了重要贡献。", "conclusion": "MOVi-MC-AC 数据集极大地推动了物体检测、追踪和分割的研究进展，不仅提高了物体分割的精度，还在合成视频中引入了新的复杂性，即多摄像机视角下的物体识别和分割一致性。这个数据集将为计算机视觉领域未来的研究提供重要的参考，特别是在X射线视觉、无遮挡内容完成和视-invariant 对象表示方面。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00356", "html_url": "https://arxiv.org/abs/2507.00356", "title": "CGEarthEye：基于吉林一号卫星星座的高分辨率遥感视觉基础模型", "title_en": "CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation", "authors": "Zhiwei Yi,Xin Cheng,Jingyu Ma,Ruifei Zhu,Junwei Tian,Yuanxiu Zhou,Xinge Zhao,Hongzhe Li", "background": "深度学习方法在遥感（RS）的智能解释方面取得了显著进展，尤其是基于大规模预训练范式的模型研究迅速重塑了地球观测（EO）的各个领域。然而，虽然中分辨率数据具有开放访问性和高时空覆盖度的优势，但由于获取通道的限制，高分辨率光谱RS图像的发展受到了限制。吉林-1卫星星座是世界上最大的亚米级商业RS卫星星座，拥有丰富的亚米级图像资源。研究基于吉林-1的特点提出了CGEarthEye框架，包含五个不同参数规模的骨干网络，总计拥有2.1亿参数。", "innovation": "研究人员开发了JLSSD，这是一个专门为吉林-1星座数据设计的1500万规模的多时相半监督学习（SSL）数据集，覆盖全球且在一个年周期内每季度采样一次。该数据集通过多级表示聚类和采样策略构建。CGEarthEye框架在预训练中结合了季节对比、基于增强的对比以及遮蔽补丁标记对比策略。全面评估表明，CGEarthEye在10个基准数据集中表现出优于现有技术（SOTA）的性能，还展示了在特性可视化、模型收敛性、参数效率及实际 mapping 应用等方面的优势特点。", "conclusion": "本研究预计CGEarthEye出色的表示能力将促进吉林-1数据在传统地球观测应用中的更广泛和高效的使用。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00435", "html_url": "https://arxiv.org/abs/2507.00435", "title": "RoboEval: 机器人操作如何与结构化和可扩展的评估相交", "title_en": "RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation", "authors": "Yi Ru Wang,Carter Ung,Grant Tannert,Jiafei Duan,Josephine Li,Amy Le,Rishabh Oswal,Markus Grotz,Wilbert Pumacay,Yuquan Deng,Ranjay Krishna,Dieter Fox,Siddhartha Srinivasa", "background": "现有的双臂操作策略评估标准往往仅报告二元任务成功情况，但这种评估方式可能会掩盖策略行为中的关键缺陷，如协调不力、抓握过程中的打滑或双臂使用不均衡等问题。RoboEval 提出了一个分层、语义紧密的任务组合框架，能够系统地挑战空间、物理和协调能力，旨在揭示当前双臂操作策略的局限性。", "innovation": "RoboEval 引入了一系列分解为特定技能阶段的分层任务，搭配细致的诊断指标和超过3000个人类示范，支持模仿学习。实验显示，具有相似成功率的策略在任务执行方式上存在显著差异，部分策略在对齐方面困难，而另一些则在时序一致的双臂控制方面困难。RoboEval 发现行为指标与任务指标对半以上对成功的关系显著，即使在二元成功饱和的情况下，这些行为指标仍然具有信息价值。RoboEval 通过指明何时以及如何策略失败，提供了更加深入和可操作的机器人操作理解，并突显了超越成功率的评估工具的需求。", "conclusion": "RoboEval 通过更加细致和全面的评估，提供了机器人操作的深入理解，并强调了超越单纯成功率评估工具的必要性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00459", "html_url": "https://arxiv.org/abs/2507.00459", "title": "使用稳定扩散进行过程感知且高保真的微结构生成", "title_en": "Process-aware and high-fidelity microstructure generation using stable diffusion", "authors": "Hoang Cuong Phan,Minh Tien Tran,Chihun Lee,Hoheok Kim,Sehyok Oh,Dong-Kyu Kim,Ho Won Lee", "background": "理解材料设计中的工艺-结构关系对于合成现实的微结构图像至关重要，但这一任务由于训练显微镜照片的限制和工艺变量的连续性而具有挑战性。现有的方法尚无法克服这些挑战，因此需要开发一种新的方法来生成可控且符合特定工艺条件的图像，同时捕捉工艺驱动的微结构变化，并解决数据稀缺性和计算约束的问题。", "innovation": "本文提出了一种基于 Stable Diffusion 3.5 Large (SD3.5-Large) 的过程感知生成建模方法，该方法引入了数值感知嵌入，能够直接将连续变量（退火温度、时间、放大倍数）编码到模型的条件中，从而在指定的工艺条件下实现可控图像生成。此外，通过细调 SD3.5-Large 的一小部分权重（细调模块 DreamBooth 和低秩适应 LoRA），以适应材料领域。这种方法在真实的微结构微型结构上使用语义分割模型验证现实性，同时利用物理描述符和空间统计方法进行定量分析，证明了合成结构和实际结构之间的强烈一致性。", "conclusion": "该研究代表了首个采用 SD3.5-Large 的过程感知微结构生成方法，为数据驱动的材料设计提供了一种可扩展的方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00451", "html_url": "https://arxiv.org/abs/2507.00451", "title": "通用游戏玩法中最佳代理识别", "title_en": "Best Agent Identification for General Game Playing", "authors": "Matthew Stephenson,Alex Newcombe,Eric Piette,Dennis Soemers", "background": "该研究提出了一种高效且通用的方法，用于在多问题领域中准确识别最适合每个子任务的算法。这种方法将问题视为多臂-bandit的最佳臂识别问题集，其中每个臂代表一种特定的算法或代理，每个bandit对应一个特定的任务。研究者的目标是在有限的测试次数内，通过优化选择过程来确定每个游戏中性能最高代理。", "innovation": "该研究提出了一种基于威尔逊分数区间（Optimistic-WS）的乐观选择过程，该过程根据潜在的遗憾减少来为所有多臂-bandit中的每个臂排名。与以前的最佳臂识别算法相比，Optimistic-WS在加权简单遗憾的平均值方面表现出显著的性能改进，特别是在两个常用的通用游戏框架，GVGAI和Ludii中进行了验证。这种方法能够显著提高通用游戏框架中代理评估程序的质量和准确性，同时也适用于其他算法运行时间较长的多任务领域。", "conclusion": "本研究提出的方法在多任务领域的代理识别方面展现了显著的改进，特别是在通用游戏框架中。通过优化选择过程和基于威尔逊分数区间的乐观选择技术，该方法成功地识别了每种游戏中性能最佳的代理，并展示了比现有算法更好的性能。这为多任务环境下的代理评估提供了新的视角和方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00445", "html_url": "https://arxiv.org/abs/2507.00445", "title": "逐迭代蒸馏在生物分子设计中奖励导向的微调扩散模型", "title_en": "Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design", "authors": "Xingyu Su,Xiner Li,Masatoshi Uehara,Sunwoo Kim,Yulai Zhao,Gabriele Scalia,Ehsan Hajiramezanali,Tommaso Biancalani,Degui Zhi,Shuiwang Ji", "background": "扩散模型在建模复杂、高维数据分布方面已经显示出极高的效果，但在实际应用中，往往需要超越高保真生成，还要求对基于物理模拟或其他科学知识的非可微奖励函数进行优化。虽然已经研究了使用强化学习方法来微调扩散模型，但这些方法常常由于其在线性策略的原因，存在稳定性差、样本效率低和模式坍塌的问题。因此，需要一种新的框架来解决这些问题，使扩散模型能够优化任意奖励函数。通过将问题转化为策略蒸馏问题，收集离策略数据，并根据模拟的软最优策略对模型进行更新，提出了一种新的微调框架，该框架在训练稳定性和样本效率上表现出优越性，相较于现有的基于策略的强化学习方法有明显优势。实验结果表明，该方法能够有效并且更优地进行奖励优化，适用于蛋白质、小分子和调控DNA设计等多种任务。", "innovation": "本文提出了一种迭代蒸馏的微调框架，利用策略蒸馏方法，通过离策略数据收集、模拟软最优策略进行模拟和优化当前模型策略以减少KL散度来训练模型。这种方法在训练稳定性和样本效率方面优于现有的基于策略的强化学习方法。通过对比实验结果，展示了本方法在不同生物分子设计任务中的有效性。", "conclusion": "本文提出了一种基于策略蒸馏的迭代微调框架，使扩散模型能够优化任意奖励函数。通过实验验证了该方法在蛋白质、小分子和调控DNA设计等多种任务中的训练稳定性和样本效率显著提高，证明了该方法的有效性和优越性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00491", "html_url": "https://arxiv.org/abs/2507.00491", "title": "Twill：在异构移动边缘平台上调度组合人工智能系统", "title_en": "Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms", "authors": "Zain Taufique,Aman Vyas,Antonio Miele,Pasi Liljeberg,Anil Kanduri", "background": "组合人工智能（cAI）系统将多个AI模型链在一起以解决复杂问题。这类系统通常由深度神经网络（DNNs）、变压器和大型语言模型（LLMs）组成，显示出较高的计算多样性和动态的工作负载变化。在移动边缘平台上部署cAI服务提出了在未知序列中动态调度并发DNN和变压器推理任务的重大挑战。现有移动边缘AI推理策略处理多DNN或仅为变压器的工作负载，依赖于设计时的性能分析，无法处理cAI系统所需的DNN和变压器的并发推理。现有技术无法满足cAI系统的并发推理需求，以及满足异构移动边缘平台上的功耗预算。", "innovation": "我们提出了Twill，一种运行时框架，它通过任务亲和力感知集群映射和迁移、优先级感知任务冻结/解冻和DVFS技术，以在功耗预算内最小化推理延迟来处理cAI工作负载的并发推理请求。Twill框架已在Nvidia Jetson Orin NX平台上实现和部署，并通过针对现代DNN和LLM的先进边缘AI推理技术进行评估，将推理延迟平均减少了54%，同时遵守功耗预算。", "conclusion": "我们通过开发Twill框架成功解决了在异构移动边缘平台上调度cAI系统中遇到的挑战。该框架能够在满足功耗预算的情况下，优化cAI工作负载的并发推理任务。实验结果显示，在多种现代DNN和LLM上，Twill将平均推理延迟降低了54%。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00461", "html_url": "https://arxiv.org/abs/2507.00461", "title": "具有相位和幅度量化的新颖复值霍夫曼神经网络", "title_en": "Novel Complex-Valued Hopfield Neural Networks with Phase and Magnitude Quantization", "authors": "Garimella Ramamurthy,Marcos Eduardo Valle,Tata Jagannadha Swamy", "background": "本文研究了两种新颖的复值霍夫曼神经网络（CvHNNs），这两种网络引入了相位和幅度的量化机制。现有文献中的复值霍夫曼神经网络在性能上存在一定的局限性，研究者旨在通过相位和幅度的量化，增加神经网络的状态数量，进而拓展它们的应用范围。", "innovation": "本文提出了两种新型的CvHNNs，分别使用矩形坐标和极坐标表示复网络贡献，并引入了天花板型激活函数。第一种CvHNN基于矩形坐标表示，而第二种CvHNN则基于极坐标表示，这两种方法都能显著提高神经网络的状态数量，相比现有模型具有更广泛的应用潜力。", "conclusion": "所提出的CvHNNs通过引入相位和幅度的量化机制，扩展了复值霍夫曼神经网络的性能边界，提高了其在复杂问题上的处理能力，从而扩大了它们的潜在应用场景。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00454", "html_url": "https://arxiv.org/abs/2507.00454", "title": "ATSTrack: 通过对齐时间和空间缩放来增强视觉语言跟踪", "title_en": "ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales", "authors": "Yihao Zhen,Qiang Wang,Yu Qiao,Liangqiong Qu,Huijie Fan", "background": "视觉语言跟踪（VLT）的一个主要挑战是视觉输入和语言描述之间的对齐不准确，这主要是由于目标运动引起的。以前的跟踪器探索了许多有效的方法来修改特征，以保持更对齐的特征。然而，最终阻碍其能力的一个重要但未被探索的因素是视觉输入与语言输入之间本就存在的时间和空间信息缩放差异。为了应对这一问题，本文提出了一种新颖的视觉语言跟踪器，通过调整不同输入组件的时间和空间尺度来增强特征修改的效果，命名为ATSTrack。具体来说，本文根据视觉输入的时间和空间对应性将每个语言描述分解为不同属性的短语，对其进行精细的特征修改。此外，还引入了一个视觉语言标记，包含了上一帧的修改后的语言信息，以引导模型提取更与语言描述相关的视觉特征，从而减少由空间缩放差异引起的影响。实验结果表明，所提出的ATSTrack在性能上与现有方法相当。我们将发布我们的代码。", "innovation": "提出了一个新颖的视觉语言跟踪器ATSTrack，通过调整时间空间尺度来增强不同输入组件的特征修改效果。方法包括将语言描述分解为基于时间和空间对应性的短语，并进行精细的特征修改。引入了一个视觉语言标记来引导模型提取更相关的视觉特征，从而减少空间缩放差异的影响。", "conclusion": "通过提出的ATSTrack，通过调整时间空间尺度增强了特征修改的效果，并且实验表明该方法在性能上与现有方法相当。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00467", "html_url": "https://arxiv.org/abs/2507.00467", "title": "注重多样性的精炼随机森林", "title_en": "Diversity Conscious Refined Random Forest", "authors": "Sijan Bhattarai,Saurav Bhandari,Girija Bhusal,Saroj Shakya,Tapendra Pandey", "background": "随机森林（RF）是一种广泛应用的集成学习技术，以其在多种领域的稳健分类性能而闻名。然而，它通常依赖于数百棵树和所有的输入特征，导致高推断成本和模型冗余。现有方法主要通过增加树的数量和利用所有特征来提高性能，但这种方式显然增加了模型的复杂性和成本。因此，如何在保持分类性能的同时减少树的数量和特征的数量成为了一种亟待解决的问题。", "innovation": "本文提出了一种精炼随机森林分类器，通过动态地仅在信息性特征上生长树，并通过聚类和保留不相关的树来强制多样性最大化。具体而言，该方法首先移除非信息性特征，然后通过分析确定需要生长的新树的数量，并通过基于相关性的聚类去除冗余的树。这种方法相比传统的随机森林，在相同数量的树的情况下，可以获得更好的分类准确性。通过在8个基准数据集上进行的实验验证了该模型的有效性。", "conclusion": "本文提出的精炼随机森林模型通过动态生长特征和强制多样性最大化，在保持甚至提高分类准确性的同时减少了树和特征的数量，从而提高了模型效率。实验结果表明，该模型在相同数量的树的情况下相比标准随机森林具有更高的分类准确性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00509", "html_url": "https://arxiv.org/abs/2507.00509", "title": "TeamCMU在Touché：具有广告整合与检测对抗共演的对话搜索", "title_en": "TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search", "authors": "To Eun Kim,João Coelho,Gbemileke Onilude,Jai Singh", "background": "随着对话搜索引擎越来越多地采用由大规模语言模型（LLMs）和检索增强生成（RAG）驱动的生成型范式，将广告整合到生成回应中既带来了商业机会也带来了用户体验的挑战。传统的搜索中，广告和信息内容界限分明，但在生成式系统中这种界限变得模糊，这引发了透明度和信任方面的担忧。因此，本文提出了一个模块化的广告管理管线以适应RAG为基础的对话系统，包括一个广告重写器和一个鲁棒的广告分类器来处理广告。我们利用合成数据训练高性能分类器，然后通过监督微调广告重写器和最佳N选一方法来引导广告整合策略，以确保结合的最不显眼的回应。", "innovation": "本文提出了一个对抗共演框架，并构建了一个模块化广告管理管线，该管线包括广告重写器和广告分类器。我们利用合成数据结合课程学习训练分类器，通过监督微调和最佳N选一方法来优化广告的隐形性，从而实现更顺畅的广告整合。这为开发更复杂的广告意识生成搜索系统和健壮的广告分类器提供了新的视角。", "conclusion": "实验结果显示，我们的广告分类器在合成广告数据上经过训练并通过课程学习提升后，具备了稳健的检测性能。此外，通过分类器指导优化，无论是监督微调还是最佳N选一方法，都显著提高了广告的隐形性，从而实现更无缝的整合。这些发现为开发更具针对性的广告整合与检测机制奠定了基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00513", "html_url": "https://arxiv.org/abs/2507.00513", "title": "组织呼叫中心客户服务代表对人工智能助手的看法", "title_en": "Customer Service Representative's Perception of the AI Assistant in an Organization's Call Center", "authors": "Kai Qin,Kexin Du,Yimeng Chen,Yueyan Liu,Jie Cai,Zhiqiang Nie,Nan Gao,Guohui Wei,Shengzhu Wang,Chun Yu", "background": "在不同的人工智能工具集成形成的复杂社会和技术环境中，员工与客户的互动构成了工作实践的核心。这项研究旨在探索电力网格服务呼叫中心的客户服务代表（CSRs）对其与客户互动中的人工智能助手的感知。研究通过实地考察和与13名CSRs进行半结构化访谈，揭示了人工智能在降低传统工作负担（如打字和记忆）的同时，也引入了新的负担（如评估、合规性、心理负担）的过程。这项研究不仅增加了组织环境中人工智能集成的细微理解，还强调了CSRs为适应更新系统所做的努力和负担。", "innovation": "这项研究通过实地考察和半结构化访谈的形式，严格分析了客服代表的人工智能助手使用体验，提出了对高技术环境下服务工作的新理解和新观点。该研究创新之处在于它不仅揭示了人工智能在缓解客服工作负担方面的积极作用，更重要的是指出了人工智能带来的新的挑战和压力，为组织和管理者提供了更有针对性的建议。", "conclusion": "这项研究贡献了对组织环境中人工智能集成的更深刻理解，并凸显了客服代表在适应更新系统过程中所做的努力和负担。研究建议组织和管理者应采取相应的措施来减轻员工的压力，并提供必要的培训和支持。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00535", "html_url": "https://arxiv.org/abs/2507.00535", "title": "在生成式人工智能时代的重新思考群体推荐系统：从一次性推荐到具有代理性的群体决策支持", "title_en": "Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support", "authors": "Dietmar Jannach,Amra Delić,Francesco Ricci,Markus Zanker", "background": "二十多年前，首次提出了设计一种能够对用户群体而非个体用户提供推荐系统的理念。自那时以来，大量关于如何获取个体偏好、如何汇总这些偏好以及如何为用户群体生成推荐的算法提议被提出。尽管相关研究文献丰富，但在实际应用中，人们几乎找不到真正的群体推荐系统案例。这一现象使得学术界普遍假设值得质疑，特别是在群体沟通过程和基于推荐的决策制定方面。该论文探讨了这些假设和相应的系统设计是否符合用户的需求或期望，并呼吁在这一研究领域进行重新定位，利用现代生成式AI代理的优势，如ChatGPT等。", "innovation": "该论文提出了一种新的研究方向，即群体推荐系统应该支持人类群体成员在聊天中互动，并以有代理性的方式协助决策过程。这种新的设计理念强调了与用户需求和期望的契合度，利用生成式AI代理来促进更自然的决策环境，最终促进群体推荐系统的广泛应用和采纳。", "conclusion": "论文指出，现有的群体推荐系统的假设和设计往往不符合用户的需求或期望，并呼吁重新定位这一研究领域，采用现代AI技术来促进更自然的群体决策环境，最终提高群体推荐系统在实际应用中的广泛采用程度。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00485", "html_url": "https://arxiv.org/abs/2507.00485", "title": "PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning", "title_en": "PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning", "authors": "Weiran Guo,Guanjun Liu,Ziyuan Zhou,Ling Wang", "background": "强化学习（RL）广泛应用于代理与环境交互以最大化奖励的任务中。在此基础上，安全强化学习（Safe RL）引入了成本度量，确保代理在决策时遵循安全约束。然而，该研究指出Safe RL可能遭受后门攻击，攻击者可以通过这些攻击使代理执行不安全的动作。该项研究通过引入相关概念和评估指标，首次提出了结合正反样本（PNAct）的后门攻击框架，以明确PNAct的性质并设计相应的攻击算法，增强了对安全强化学习潜在风险的认识。", "innovation": "该项研究是安全强化学习领域中第一个结合正反样本（PNAct）的后门攻击框架。通过理论分析PNAct的性质并设计相应的攻击算法，该研究展示了安全强化学习中后门攻击的可能性。此外，还通过实验评估了所提出的后门攻击框架的有效性，使用了现有的评估指标进行了验证。该研究强调了对安全强化学习潜在风险的认识，突显此类攻击的可行性。其代码及相关补充材料可在指定链接下载。", "conclusion": "该研究首先介绍了后门攻击的概念和评估标准，针对安全强化学习首次提出了结合正反样本（PNAct）的后门攻击框架。通过理论分析PNAct的性质并设计了相应的攻击算法，并通过实验验证了攻击的有效性。这突显了安全强化学习中的潜在风险，并展示了此类攻击的可行性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00493", "html_url": "https://arxiv.org/abs/2507.00493", "title": "视觉无序图揭示视觉模型在整体形状处理方面的隐藏差异", "title_en": "Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing Across Vision Models", "authors": "Fenil R. Doshi,Thomas Fel,Talia Konkle,George Alvarez", "background": "人类能够基于局部纹理线索和物体部件的配置来识别物体。然而，当前的视觉模型主要依赖局部纹理线索，导致生成的特征不够稳定和组合性。形状与纹理偏见的研究将形状和纹理表示对立起来，衡量形状相对于纹理的质量，忽视了模型和人类可以同时依赖这两种线索的可能性，从而模糊了两种表示的绝对质量。因此，研究重新将形状评价定义为绝对配置能力的问题，通过Configural Shape Score (CSS)进行评估，揭示了不同模型在整体形状识别方面的差异，特别是展示了完全自监督和语言对齐的变压器模型在CSS上的表现。这种研究方法揭示了高CSS网络依赖于长范围的交互，并且代表相似性分析显示了深层转换后从局部到全局编码的过渡。最终，配置形状得分也预测了其他依赖形状的评价结果。", "innovation": "提出了视觉无序图这一新的视觉模型评价方法。通过无序图对图像进行配对，保留局部纹理同时改变全局部件的排列，以此评估模型的整体形状识别能力。这种方法揭示了现有视觉模型在处理整体形状方面的差异，特别是在配置形状分数上表现出色的完全自监督和语言对齐的变压器模型。此外，本文还揭示了高CSS网络依赖于长范围交互，并且通过代表相似性分析展示了深层转换后从局部到全局编码的过渡。最后，研究展示了配置形状分频能够预测其他依赖形状的评价结果。", "conclusion": "研究认为，通往真正稳健、可泛化并且类似人类的视觉系统的道路，可能不在于对形状和纹理之间的人工选择，而是在于能够无缝整合局部纹理和全局配置形状的架构和学习框架。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00525", "html_url": "https://arxiv.org/abs/2507.00525", "title": "Box-QAymo: 用于自主驾驶的盒子引用VQA数据集", "title_en": "Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving", "authors": "Djamahl Etchegaray,Yuxia Fu,Zi Huang,Yadan Luo", "background": "可解释的交流对于自主驾驶的安全和可信至关重要，但现有视觉-语言模型（VLMs）通常在理想化假设下运行，难以在现实世界场景中捕捉用户意图。现有的驾驶导向的VQA数据集仅限于全场景描述或方式点预测，无法评估VLMs是否可以响应局部用户驱动的查询。该论文介绍了一个盒子引用的数据集和基准（Box-QAymo），旨在评估和微调视觉-语言模型在用户指定对象的时空和时间推理能力。用户通过绘制边界框表达意图，提供一个快速且直观的接口，以针对复杂场景中的集中查询。", "innovation": "该研究提出了一个分层评估协议，从二元的合理性检查问题开始，评估基本模型能力，然后到（1）对于边界框引用对象的属性预测，（2）目标实例的运动理解，以及（3）跨帧间物体动态的时空运动推理。同时，研究团队进行了精细的物种类别和视觉属性众包，反映了复杂情境中的驱动因素。通过负样本抽样、时间一致性检查和困难知觉的平衡，确保了数据集的稳健性和多样性。", "conclusion": "此工作揭示了当前视觉-语言模型在被询问感知问题时的重大局限性，突显了实现实际性能的差距。这项工作为开发更稳健且可解释的自主驾驶系统奠定了基础，这些系统能够在现实条件下与用户进行有效沟通。完整的评估结果表明当前的VLMs在空间和时间推理方面存在显著的限制。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00537", "html_url": "https://arxiv.org/abs/2507.00537", "title": "所有注意力头并非皆适用于你：利用注意力剪除优化CLIP的图像表示", "title_en": "Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation", "authors": "Feng Lin,Marco Chen,Haokui Zhang,Xiaotian Yu,Guangming Lu,Rong Xiao", "background": "CLIP在多种应用中表现出稳健的性能，但研究者发现某些注意力头可能对最终表示有负面影响，通过移除这些头可以提升下游任务的表现。本文研究了CLIP图像编码器中注意力头的作用，并提出了一种简单有效的注意力剪除技术（AAT），该技术通过调整注意力权重来抑制特定注意力头的贡献，从而系统地识别和移除有害注意力头，以提升表示质量。实验表明在多个领域实验，AAT都能够提升下游任务的表现，相较于CLIP-family模型跨模态检索任务，召回率提升了11.1%。", "innovation": "提出了注意力剪除技术（AAT），这种方法通过操纵注意力权重来抑制特定注意力头的贡献，系统地识别并移除有害注意力头，从而优化了CLIP的图像表示，提升了模型在下游任务中的性能。", "conclusion": "注意力剪除技术AAT在多个领域提升下游任务表现的实验结果表明，该方法能够有效改进大规模视觉-语言模型，且几乎不会增加推理成本。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00577", "html_url": "https://arxiv.org/abs/2507.00577", "title": "BadViM：针对Vision Mamba的后门攻击", "title_en": "BadViM: Backdoor Attack against Vision Mamba", "authors": "Yinghao Wu,Liyan Zhang", "background": "视觉状态空间模型（Vision State Space Models, VSSMs），特别是像Vision Mamba (ViM)这样的架构，已经被证明是 Vision Transformers (ViTs) 的有希望的替代品。然而，这种新型架构的安全影响，尤其是对后门攻击的脆弱性，仍然没有被充分研究。后门攻击通过在受到攻击的模型中潜伏触发器，使得模型在包含这些触发器的输入上发生误分类，而在干净输入上保持正常行为。这项研究旨在通过设计专门针对Vision Mamba的后门攻击框架BadViM来评估和测试ViM的后门攻击可操作性。BadViM利用了Victim模型的频率敏感模式来创建隐蔽且分布式的触发器，并使用隐藏状态对齐损失来战略性地操纵模型内部表示，从而提高攻击效果。", "innovation": "本研究通过引入一个新型的名为BadViM的后门攻击框架，专门针对Vision Mamba。BadViM利用了Resonant Frequency Trigger（RFT），并提出了Hidden State Alignment loss，以优化触发器的隐蔽性和分布性，同时也最大化了攻击的成功率，表明了BadViM即使面对包括PatchDrop、PatchShuffle和JPEG压缩在内的常见防御措施也具有强大的抵抗力。", "conclusion": "BadViM在不降低干净数据的分类准确性的情况下，实现了更高的攻击成功率，并且在面对常见的防御措施时表现出出色的抗打击能力，这表明Vision Mamba在面对后门攻击时存在显著的脆弱性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00589", "html_url": "https://arxiv.org/abs/2507.00589", "title": "量子电路结构优化在量子强化学习中的应用", "title_en": "Quantum Circuit Structure Optimization for Quantum Reinforcement Learning", "authors": "Seok Bin Son,Joongheon Kim", "background": "强化学习（RL）通过与环境交互学习最优策略，但高维空间中的‘维数灾难’限制了其学习效率。量子强化学习（QRL）利用量子计算中的叠加和纠缠特性，能有效处理高维问题。QRL采用了参数化量子电路（PQC）作为核心计算模块，通过门操作进行线性和非线性变换，类似于经典神经网络的隐藏层。然而，前期研究中的QRL主要使用基于经验和直觉设计的固定PQC结构，没有对其最优性进行验证。", "innovation": "本文提出了一个QRL-NAS算法，结合量子神经架构搜索（QNAS）来优化QRL中的PQC结构。实验表明，QRL-NAS在奖励方面优于使用固定电路的QRL，证明了其有效性和实用性。", "conclusion": "QRL-NAS算法通过量子神经架构搜索优化PQC结构，提高了奖励，验证了其在量子强化学习中的有效性和实用性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00598", "html_url": "https://arxiv.org/abs/2507.00598", "title": "高分辨率空间记忆需要像网格细胞那样的神经编码", "title_en": "High-resolution spatial memory requires grid-cell-like neural codes", "authors": "Madison Cotteret,Christopher J. Kymn,Hugh Greatorex,Martin Ziegler,Elisabetta Chicca,Friedrich T. Sommer", "background": "连续吸引子网络（CANs）被广泛用于模拟大脑如何通过持久的递归活动暂时保持连续的行为变量，比如动物在环境中的位置。但是，这种记忆机制对噪音或异质性等细微缺陷非常敏感，而这在生物系统中都很常见。过去的研究表明，通过将连续体离散化为有限的离散吸引子状态可以提高鲁棒性，但会降低表示变量的分辨率，从而在稳定性和分辨率之间形成困境。传统模型中使用的单模峰码（bump-like codes）的CANs对这种困境尤其严重。为了克服这个问题，研究者探讨了基于随机特征嵌入的稀疏二元分布式编码，其中神经元具有空间周期性的感受野。", "innovation": "研究者提出了基于稀疏二元分布式编码的网格细胞样代码（grid-cell-like codes），通过这种方法，CANs能够同时实现高稳定性和高分辨率。该模型还扩展到将任意非线性流形嵌入到CAN中，如球体或环面，并将线性路径积分扩展为沿着自编程的流形上的向量场进行积分。这一工作为大脑如何以高分辨率稳定地表示连续变量并执行任务相关的灵活计算提供了理论基础。", "conclusion": "本文提供了理论证明，表明使用网格细胞样的代码可以使CANs在保证高稳定性和高分辨率的同时，更有效地存储和计算连续变量。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00482", "html_url": "https://arxiv.org/abs/2507.00482", "title": "物理线索引导的风格迁移以实现自适应全息重构", "title_en": "Physics-Aware Style Transfer for Adaptive Holographic Reconstruction", "authors": "Chanseok Lee,Fakhriyya Mammadova,Jiseong Barg,Mooseok Jang", "background": "全息成像面临着从记录的衍射图重建物体复振幅的病态逆问题。尽管最近的深度学习方法在经典相位恢复算法上表现出了潜力，但它们往往需要高质量的真实复振幅地图数据集来实现两个领域之间的统计逆映射操作。传统的相位恢复算法通常需要详细的复杂相位图作为参照，而这在实际应用中数据获取较为困难。本研究旨在解决这一问题，提出了一种基于物理知识的风格迁移方法，以实现无需高质量复振幅数据的成像。通过将物体到传感器的距离视为衍射图案中的隐式风格，该方法利用这种“风格域”作为中间层构建循环图像转换，从而通过仅使用强度测量数据集实现逆映射操作的学习，这个过程是自适应的。这种方法在生物医学成像中具有潜在应用，能够实时、无标签地重构动态流动的红细胞形态，进一步展示了其在难以获得真值场景下的成像应用潜力。该框架利用嵌在测量中的物理信息，提供了一种在缺乏真实数据情况下进行成像应用的实用学习策略。", "innovation": "研究提出了一种基于物理知识的风格迁移方法，通过将物体到传感器的距离视为衍射图案中的隐式风格，利用这种风格作为中间域构建循环图像转换，从而实现仅基于强度测量数据集的逆映射操作学习。这种方法能够在缺乏高质量复振幅数据集的情况下，进行自适应的全息重构，特别适用于难以获得真实数据的成像应用场景。该方法首次利用物理线索与深度学习相结合的方式，减轻了对高质量复振幅数据的依赖，提高了全息成像的实用性与灵活性。这种方法为缺乏真实数据场景下的成像应用提供了一种新的可能性。", "conclusion": "研究提出了一种新的自适应全息成像方法，利用物体到传感器的距离作为隐含的风格，通过物理线索与深度学习相结合的方式，实现仅基于强度测量数据集的逆映射操作学习。该方法在生物医学成像中展示了其重构动态流动的红细胞形态的能力，进一步证明了其在获得真实数据困难场景中的成像应用潜力。该方法为全息成像提供了新的架构思维，能够在缺乏复振幅数据的情况下进行自适应重构，提高了成像在实际应用中的潜力与实用性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00546", "html_url": "https://arxiv.org/abs/2507.00546", "title": "通过表示学习在纳米光子学中的逆设计", "title_en": "Inverse Design in Nanophotonics via Representation Learning", "authors": "Reza Marzban,Ali Adibi,Raphael Pestourie", "background": "在纳米光子学中，逆设计的计算发现能够实现特定电磁（EM）响应的结构已成为光学最近进展的关键工具。传统的基于直觉或迭代优化方法难以应对高维、非凸的设计空间以及EM模拟的巨大计算需求。近年来，机器学习（ML）作为一种有效的方法逐渐崭露头角，以解决这些瓶颈问题。这篇综述从表示学习的角度出发，将ML增强的逆设计方法分类为输出侧和输入侧两种方式。", "innovation": "通过表示学习的视角，这篇综述论文分类了两种ML增强的逆设计方法：输出侧方法利用ML在解空间中学习一个表征以加速优化求解，而输入侧方法则通过生成模型利用ML学习紧凑的潜在空间表示可行的器件几何结构，从而有效进行全局探索。每种方法都有其独特的优势和限制，如数据需求、泛化能力和新型设计发现的潜力。同时，结合物理优化和数据驱动表征的混合框架有助于跳出局部最优解，提高可扩展性和实现知识的迁移。文章还指出了该领域的开放挑战和机遇，如复杂性管理、几何无关的表征集成、工艺约束的结合以及多物理场协同设计的进步。", "conclusion": "文章指出，要重点关注复杂性管理，发展几何无关的表示，整合制造约束，以及推进多物理场协同设计等领域。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00583", "html_url": "https://arxiv.org/abs/2507.00583", "title": "通过知觉正则化检测AI生成的视频", "title_en": "AI-Generated Video Detection via Perceptual Straightening", "authors": "Christian Internò,Robert Geirhos,Markus Olhofer,Sunny Liu,Barbara Hammer,David Klindt", "background": "生成式AI的发展使得合成视频在真实感方面取得了显著进步，这对内容认证构成了重大挑战，并引发了关于滥用的紧迫担忧。现有的检测方法往往难以泛化，无法捕捉到细微的时间不一致性。", "innovation": "提出了一种名为ReStraV（Representation Straightening Video）的新颖方法，以区分自然视频与AI生成的视频。该方法基于‘知觉正则化’假说——即现实世界视频在神经表示域中的轨迹更加直线化——通过分析与这一预期几何属性的偏差。使用预训练的半监督视觉转换器(DINOv2)，量化模型表示域中的时间曲率和逐步距离。通过聚合每个视频的这些指标的统计数据并训练分类器，显示出AI生成的视频与真实视频在曲率和距离模式上存在显著差异。这种方法在最小成本的同时实现了顶级的检测性能，显著超越现有基于图像和视频的方法。ReStraV计算效率高，提供了一种低成本且有效的检测解决方案。", "conclusion": "这项工作提供了利用神经表示几何学来检测AI生成视频的新见解。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00606", "html_url": "https://arxiv.org/abs/2507.00606", "title": "混合推理：训练大型语言模型以使用自适应策略进行推理", "title_en": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies", "authors": "Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang", "background": "大型语言模型（LLMs）通过高级提示技术如思维链（CoT）和思维树（ToT）表现出色于复杂任务，但它们对手工制作的任务特定提示的高度依赖限制了灵活性和效率.", "innovation": "引入了混合推理（MoR）训练框架，该框架将多种推理策略嵌入到大型语言模型中，以实现自主、任务适应性的推理，无需外部提示工程.", "conclusion": "实验表明，MoR 显著增强了性能，MoR150 使用思维链提示时提高了 2.2%，与基线相比提高了 13.5%。MoR 消除了对任务特定提示的需求，提供了跨多种任务的稳固推理的通用解决方案."}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00579", "html_url": "https://arxiv.org/abs/2507.00579", "title": "TUM-MiKaNi在SemEval-2025任务3中的表现：向着多语言和知识驱动的事实非事实幻觉识别", "title_en": "TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification", "authors": "Miriam Anschütz,Ekaterina Gikalo,Niklas Herbster,Georg Groh", "background": "幻觉是语言模型(LLMs)的主要问题之一，影响其可信度和更广泛领域中的应用。大多数关于幻觉的研究集中在英语数据上，忽视了LLMs的多语言性质。SemEval-2025任务3旨在解决多语言幻觉和相关观察性过度生成错误的问题。", "innovation": "提出了一种两步法管道，结合了基于检索的事实验证（使用Wikipedia）和一个微调过的BERT系统，用于识别常见的幻觉模式。该系统在所有语言中均取得了竞争性结果，在八个语言中，包括英语，进入前十大。此外，该系统还支持任务涵盖的14种语言之外的多种语言。这是一种多语言幻觉识别器，可帮助改进LLM输出及其未来用途。", "conclusion": "该多语言幻觉标识系统能够帮助提高语言模型输出的质量和实用性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00755", "html_url": "https://arxiv.org/abs/2507.00755", "title": "LearnAFE: 消除AFE与后端分类器的独立设计，实现信号与噪声比感知的模拟前端与后端联合优化框架", "title_en": "LearnAFE: Circuit-Algorithm Co-design Framework for Learnable Audio Analog Front-End", "authors": "Jinhai Hu,Zhongyi Zhang,Cong Sheng Leow,Wang Ling Goh,Yuan Gao", "background": "传统上，模拟前端（AFE）和后端分类器是独立设计的。这种分离的设计虽然常见，但并不理想。论文通过实验证明，通过联合优化AFE的传输函数和后端分类器，可以实现系统级别的最优性能。特别是在信号噪声比（SNR）感知的训练过程中，调整模拟带通滤波器（BPF）的传输函数参数，可以显著提升整体系统的性能和效率。", "innovation": "提出了一个电路-算法协同设计框架（LearnAFE），该框架通过对AFE的传输函数和后端分类器进行联合优化，可以在不同输入信号SNR条件下实现高效的音频信号分类任务。这种联合优化方法，特别是在信号噪声比感知的训练过程中，通过调整模拟带通滤波器的参数，实现了传递函数和分类器的优化。使用自定义的损失函数LBPF验证了这种方法的有效性，与传统方法相比，具有更低的电源消耗和更少的电容面积要求。优化后的设计在130nm SKY130 CMOS工艺中实现，准确率范围为90.5%-94.2%，只需22,000个分类器参数，输入信号SNR从5 dB到20 dB均适用。", "conclusion": "通过实施该框架，显著降低了能源消耗和电容面积，特别是在SNR为5 dB到20 dB的输入信号范围内，实现了高达94.2%的关键词分类准确度，显示出该方法在实际应用中的巨大潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00657", "html_url": "https://arxiv.org/abs/2507.00657", "title": "生成偏颇：大语言模型社交代理中的生成夸张、偏差与毒性", "title_en": "Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity", "authors": "Jacopo Nudo,Mario Edoardo Pandolfo,Edoardo Loru,Mattia Samory,Matteo Cinelli,Walter Quattrociocchi", "background": "该研究调查了大型语言模型（LLMs）在模拟社交媒体上的政治话语时的行为。利用2024年美国总统选举期间X平台上的2100万条互动数据，研究人员构建了基于1186名真实用户的LLM代理，并在受控环境下促使它们回复具有政治意义的推文。代理可以初始化为带有最少意识形态线索（零样本）或近期推文历史（有限样本），以便与人类回复进行一对一比较。研究评估了三种模型家族的语言风格、意识形态一致性和有毒性，发现更丰富的背景信息虽提高了内部一致性，但也加剧了极化、修辞特征和有害语言的现象。研究表明，LLM不仅没有模仿用户，反而重塑了用户。它们的输出反映了内部优化动力，而不是观察到的行为，这引入了结构性偏差，影响了它们作为社交代理的可靠性。这一发现挑战了它们在内容审核、审慎模拟和政策建模中的应用。", "innovation": "利用2100万条社交媒体互动数据构建基于1186个真实用户的真实场景下的LLM代理，探讨背景信息对LLM输出的影响，揭示了“生成夸张”现象，这种现象系统地放大了显著特质，超出了实际基准。研究发现，LLM不仅没有模仿用户，反而重塑了用户，其输出更反映内部优化动力而非实际行为。", "conclusion": "LLM在生成语料过程中产生了系统性的夸张放大效应，这种效应由内部优化动态驱动而非用户行为。其输出不准确地反映了用户行为，因此不能作为可靠的模拟代理。这在内容审核、审慎模拟和政策建模等方面提出了挑战。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00653", "html_url": "https://arxiv.org/abs/2507.00653", "title": "Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models", "title_en": "Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models", "authors": "Yilun Zhang", "background": "大型语言模型（LLM）推理计算成本的不断上升已成为其广泛应用和可持续部署的关键障碍。现有的优化策略效果显著，但主要基于统计直觉或架构修改，缺乏对推理过程本身的认知理论指导。已有研究提出的优化方法虽有效，但未能完全解决这一问题，因此需要一种新的方法来应对这一挑战。", "innovation": "论文提出了一种名为Cognitive Load-Aware Inference（CLAI）的新框架，将认知负荷理论（CLT）和神经科学的原则应用于LLM推理过程。通过引入内在认知负荷（$ICL_{LLM}$）、外在认知负荷（$ECL_{LLM}$）和相关认知负荷（$GCL_{LLM}$）的概念，重新定义推理过程为一种认知经济优化问题，并提出两种实现路径：CLAI-Prompt和CLAI-Tune。这两种方法在复杂推理、长上下文问答和代码生成等多个基准测试中，显著降低了令牌消耗（最高达45%），同时保留了准确性，并展示了自主分解复杂问题的能力，这是人类专家认知的关键特征。", "conclusion": "本研究证明，通过模仿大脑对资源的管理策略，可以构建更高效、更稳健和更具能力的人工智能系统。这为优化大规模语言模型的推理过程提供了一种新的神经符号框架。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00665", "html_url": "https://arxiv.org/abs/2507.00665", "title": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder", "title_en": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder", "authors": "Sihang Li,Wei Shi,Ziyuan Xie,Tao Liang,Guojun Ma,Xiang Wang", "background": "强化学习从人类反馈（RLHF）是使大型语言模型（LLMs）与人类价值观保持一致的关键范式，但在其核心的奖励模型仍然相当不透明。本文探讨了通过机械分析来解读和改进奖励模型的新框架，旨在提高奖励模型的安全性和可解释性，特别是在安全性导向的数据集上的应用。实验结果显示，SAFER可以在最小数据修改的情况下精确地改善或降低安全性对齐，而不牺牲通用对话性能。", "innovation": "提出了Sparse Autoencoder For Enhanced Reward model（SAFER）这一新框架，利用稀疏自动编码器（SAEs）来揭示奖励模型激活中的人类可解释特征，进而理解与安全性相关的关键决策过程。SAFER通过选择和拒绝响应的激活差异来量化个体特征的重要性，据此设计了针对数据污染和去噪的策略，使得奖励模型的改进变得更加精准高效。", "conclusion": "SAFER为高风险大型语言模型对齐任务中的奖励模型解读、审计和改进提供了新的方法，能够通过最小的数据修改来精确实现安全性对齐而不会影响通用对话性能。该文代码可通过给定的链接访问。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00709", "html_url": "https://arxiv.org/abs/2507.00709", "title": "TopoStreamer：自主驾驶中的时空车道段拓扑推理", "title_en": "TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving", "authors": "Yiming Yang,Yueru Luo,Bingkun He,Hongbin Lin,Suzhong Fu,Chao Yan,Kun Tang,Xinrui Yan,Chao Zheng,Shuguang Cui,Zhen Li", "background": "现有的车道段拓扑推理方法在保持一致的空间定位嵌入和时间上的多属性学习方面存在局限性，这阻碍了准确的道路网络重构。通过捕捉车道段及其语义类型之间的拓扑关系，车道段拓扑推理能够构建出全面的道路网络，使端到端的自动驾驶系统能够执行依赖道路的操作，如转弯和变道。但现有的方法在一致的空间位置嵌入和时间上的多属性学习方面存在一定限制，这影响了准确的道路网络重构。因此需要一种能够克服这些限制的新方法来提升自动驾驶中的车道网络感知能力。", "innovation": "TopoStreamer 提出了一种端到端的时间感知模型用于车道段拓扑推理。具体包括三个方面创新：1) 流式属性约束，在中心线和边界坐标及其分类中确保时间一致性；2) 动态车道边界的定位编码，增强查询中最新的位置信息的学习；3) 车道段去噪，有助于捕捉多样化的车道段模式。这些改进增强了模型的性能。", "conclusion": "在OpenLane-V2数据集上，TopoStreamer 在车道段感知任务中实现了3.4%的mAP提升，在中心线感知任务中实现了2.1%的OLS提升，相较于现有最先进的方法显著提升了性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00611", "html_url": "https://arxiv.org/abs/2507.00611", "title": "残差奖励模型在偏好强化学习中的应用", "title_en": "Residual Reward Models for Preference-based Reinforcement Learning", "authors": "Chenyang Cao,Miguel Rogel-García,Mohamed Nabail,Xueqian Wang,Nicholas Rhinehart", "background": "偏好强化学习(PbRL)提供了一种在奖励信号难以指定的环境中学习高绩效策略的方法，避免了奖励设计中的手动设计和耗时工作。然而，PbRL存在收敛速度慢的问题，因为它需要在奖励模型中进行训练。先前的研究提出从演示学习奖励模型并在偏好下进行微调，但当使用神经网络作为模型时，前训练和微调使用的不同损失函数可能导致可靠优化的挑战。本文提出了一个结合先验知识的残差奖励模型(Residual Reward Model, RRM)方法来解决这一问题。RRM假设环境的真正奖励可以分解为两部分：先验奖励和学习奖励。先验奖励是在训练前可用的一个术语，例如用户的最佳猜测奖励函数或从逆强化学习(IRL)学习到的奖励函数，而学习奖励是通过偏好进行训练的。介绍了基于状态和基于图像的RRM版本，并在Meta-World环境套件中的多个任务上进行了评估。实验结果显示，该方法显著提高了常见PbRL方法的性能。对于不同类型的先验奖励，包括代理奖励、从IRL获得的奖励，甚至代理奖励的否定版本，该方法都能实现性能提升。此外，还使用Franka Panda进行了实验，表明该方法在真实机器人上具有优越性能，显著加快了不同任务的学习策略并用更少的步骤取得了成功。相关视频参见: https://example.com", "innovation": "本文引入了残差奖励模型(Residual Reward Model, RRM)，它能够有效结合先验知识来提高偏好强化学习(PbRL)的性能。通过将环境的真正奖励拆分为先验奖励和学习奖励两部分，RRM使得在前训练和微调中使用不同的损失函数成为可能，从而解决了一些之前的挑战并提高了性能。该方法被验证在多个任务和真实机器人上具有优越的性能，能够显著加快策略学习速度并取得成功。此外，RRM在不同类型先验奖励下的广泛适用性也展示了其灵活性和应用价值", "conclusion": "实验结果显示，该方法显著提高了PbRL的性能，特别是在不同种类的先验奖励下，包括代理奖励从IRL学到的奖励，甚至是代理奖励的反号版本。使用真实机器人Franka Panda进行的实验也证明了该方法的有效性，它在不同任务中都有更快的策略学习速度和更少的步骤成功。该方法为PbRL的研究开辟了新的道路，提高了算法在难以指定奖励信号的环境中的应用效率。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00724", "html_url": "https://arxiv.org/abs/2507.00724", "title": "Holmes: 通过解耦共同特征来实现大型视觉模型有效且无害的所有权验证", "title_en": "Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features", "authors": "Linghui Zhu,Yiming Li,Haiqin Weng,Yan Liu,Tianwei Zhang,Shu-Tao Xia,Zhi Wang", "background": "大型视觉模型在各种下游任务中取得了显著成果，主要是通过利用私人和有价值的本地数据对预训练模型进行微调。这使得个性化的模型成为了其所有者的宝贵知识产权。类似传统 DNN 时代的模型盗取攻击，现有模型所有权保护方法也给这些个性化模型带来了重大风险。然而，本文指出，大多数现有的防御方法都是为从头开始训练的模型设计的，这些方法通常存在引入额外安全风险、容易误判甚至对微调模型无效的问题。因此，本文提出了一种通过解耦共同特征来实现大型视觉模型有效且无害的所有权验证方法，以缓解这些问题。", "innovation": "本文提出了一个通过解耦共同特征实现大型视觉模型有效且无害的所有权验证方法，称为 Holmes。该方法包括三个主要阶段：首先，构建保留共同特征并破坏数据集特定特征的阴影模型，通过阴影模型和受害者模型的输出差来表示受害者模型的数据集特定特征；其次，训练一个元分类器来识别包含受害者模型数据集特定特征的被盗模型；最后，通过假设检验进行模型所有权验证，以降低随机性并增强鲁棒性。这种方法在基准数据集上的实验结果证实了其在同时检测不同类型模型盗取方面具有有效性。", "conclusion": "本文提出了一种通过解耦共同特征来实现大型视觉模型有效且无害的所有权验证方法，该方法能够缓解模型盗取攻击带来的问题，并在多个基准数据集上进行了验证，证明了其实用性和有效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00669", "html_url": "https://arxiv.org/abs/2507.00669", "title": "Audio-3DVG: 统一的声学与点云融合技术用于三维视觉定位", "title_en": "Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding", "authors": "Duc Cao-Dinh,Khai Le-Duc,Anh Dao,Bach Phan Tat,Chris Ngo,Duy M. H. Nguyen,Nguyen X. Khanh,Thanh Nguyen-Tang", "background": "3D视觉定位（3DVG）涉及基于自然语言在3D点云中定位目标物体。尽管先前的研究在使用文本描述方面取得了进展，但利用口头语言（即基于声学的3D视觉定位）在这一领域仍然被忽视且具有挑战性。最近，自动语音识别（ASR）的进步和声学表示学习的发展促使研究人员尝试结合声学和空间信息来改进定位效果。一些研究将语音作为单一输入处理，本文则将其分解为两个互补的任务：对象提及检测和基于音频的注意力机制，以更好地理解音频场景并提高目标辨识率，尤其是在混乱的场景中。文献还提供了一些合成的音频描述，支持对于基准数据集进行统一的评估。实验结果表明，基于音频的3D视觉定位不仅可以取得新的最佳性能，还能与基于文本的方法相媲美，这表明将口头语言整合到三维视觉任务中的潜力巨大。", "innovation": "本文提出了一个新颖的Audio-3DVG框架，它将声学和空间信息相结合，通过将语音任务分解为对象提及检测和音频引导注意力模块来提高音频驱动的3D视觉定位性能。这种方法不仅优于其他基于语音的方法，还挑战了基于文本的方法的性能，证明了将语音信息纳入三维视觉任务的重要性。", "conclusion": "通过构建统一的音频-点云融合技术，本文的Audio-3DVG不仅实现了基于音频的3D视觉定位的新最佳性能，还展示了利用语音信息改进三维视觉任务的方法的有效性。这为进一步研究和开发多模态融合在三维视觉中的应用开辟了新的路径。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00631", "html_url": "https://arxiv.org/abs/2507.00631", "title": "Horus: 一种在不确定性下实现无信任委托的协议", "title_en": "Horus: A Protocol for Trustless Delegation Under Uncertainty", "authors": "David Shi,Kevin Joo", "background": "在动态且低信任度的环境中，自主AI代理可以通过让渡任务给子代理来受益，但其正确性无法通过预先的规格说明或集中的监督来保证。错误的成本可能远高于纠正错误的成本，因此需要一种机制来确保系统的正确性，即使在缺乏集中监督的情况下。正确的性被认为是系统的一种 emergent 属性，即通过激励机制使得错误得不偿失，从而让系统达到正确性这个平衡状态。现有的机制无法完全满足这一需求，特别是在大规模、动态、低信任度的系统中。因此，研究如何在这样的环境中确保任务正确性具有重要价值。鉴于此，作者提出了一种通过抵押索赔进行递归验证的游戏协议，以实现任务的正确性验证和委托处理机制。", "innovation": "该协议通过抵押索赔进行递归验证，提出了在动态、低信任环境中确保AI代理任务正确性的新方法。任务以意图的形式发布，解决者竞争完成这些任务。在任务执行过程中存在风险，并且由验证者在执行后检查正确性。任何参与者都可以通过抵押来挑战结果，启动验证过程。错误的代理将会被惩罚，而正确的反对者会得到奖励。如果激励机制在解决问题者、挑战者和验证者之间对齐，这种协议将使错误被最小化，正确性成为各个参与者的最优策略。这一机制有效地减少了集中监督的需求，并通过经济激励促进了系统的正确性。", "conclusion": "当解决者、挑战者和验证者的激励机制对齐时，这样的协议使得错误通过博弈过程被最小化，正确性成为系统的 Nash 平衡状态。通过引入这种机制，系统能够在缺乏集中监督的情况下保持正确性，这对于动态、低信任环境中的大规模应用特别有价值。这种协议的设计和实现具有广泛的适用性和重要的实践意义。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00660", "html_url": "https://arxiv.org/abs/2507.00660", "title": "MTCNet: 4D超声心动图中指导运动和拓扑一致性学习的二尖瓣分割", "title_en": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound", "authors": "Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni", "background": "二尖瓣反流是心脏最常见的疾病之一。四维（4D）超声成像是评估动态瓣膜形态的主要影像学技术。然而，现有的4D二尖瓣（MV）分析仍然具有挑战性，原因包括缺乏相位标注、严重的运动伪影以及较差的影像质量。目前的方法缺乏相位间依赖性，限制了4D MV分析的效果。现有方法的这一缺陷导致了在4D MV超声图像分割方面难以实现高精度和跨相位一致性。因此，需要一种新的方法来解决这些问题，实现跨相位一致性，并提高二尖瓣超声图像的分割精度。", "innovation": "本文提出了一个名为MTCNet（运动-拓扑引导一致性网络）的新方法，用于半监督学习环境下的4D MV超声图像分割，可以实现跨相位一致性。MTCNet仅需少量的终舒张期和终收缩期标注，设计了一种跨相位运动引导的一致性学习策略，利用双向注意力记忆库传播时空特征，实现相位内外的一致性能。此外，还提出了一种拓扑引导的相关正则化方法，探索物理先验知识以维持解剖上的合理性。这种结构上的相应性使得MTCNet能够有效利用标记和未标记相位之间的结构信息，从而提高分割精度。与其它先进方法相比，MTCNet在1408个相位的160名患者的第一大的4D MV数据集测试中表现更优（Dice：87.30%，HD：1.75mm）。", "conclusion": "通过MTCNet，实现了4D MV超声图像的高精度分割，提高了跨相位的一致性。本研究不仅发展了一种新的方法，也证明了它在复杂的4D MV超声图像分割任务中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00788", "html_url": "https://arxiv.org/abs/2507.00788", "title": "AI余响：探究AI助手对软件可维护性下游影响", "title_en": "Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability", "authors": "Markus Borg,Dave Hewett,Nadim Hagatulah,Noric Couderc,Emma Söderberg,Donald Graham,Uttam Kini,Dave Farley", "background": "AI助手，如GitHub Copilot和Cursor，正在改变软件工程领域。尽管已有研究指出生产率的提升，但它们对软件可维护性的影响仍需进一步研究。这项研究旨在探讨与AI助手共同开发是否会影响软件可维护性，特别是其他开发者修改源代码的难易程度。", "innovation": "本研究通过两阶段受控实验来评估AI助手在软件开发中的作用，涉及151名参与者，其中95%是专业开发人员。在第一阶段，参与者在Java Web应用程序中添加新功能时，有或没有AI辅助。第二阶段，随机对照试验中，新的参与者在没有AI辅助的情况下改进这些解决方案。结果显示，AI辅助开发在后续改进中带来了适度的速度提升和平均代码健康度略有提高，虽然总体差异不显著，但习惯使用AI的用户在第一阶段的增加的代码健康程度具有统计学显著性。此外，使用AI助手比未使用时任务完成时间中位数减少了30.7%，习惯使用AI的用户平均速度提高了55.9%。这些发现增加了现有证据，表明AI助手可以有效地加速开发，并且没有观察到代码质量下降的迹象。未来研究应重点关注由过度代码生成导致的代码膨胀和开发人员在实施过程中心理债务积聚所带来的风险。", "conclusion": "研究表明AI助手可以有效加速开发，并且没有观察到代码质量下降的迹象。然而，仍需关注过度代码生成导致的代码膨胀和开发过程中积累的心理债务。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00790", "html_url": "https://arxiv.org/abs/2507.00790", "title": "LD-RPS: 零样本统一图像恢复通过潜在扩散循环后验采样", "title_en": "LD-RPS: Zero-Shot Unified Image Restoration via Latent Diffusion Recurrent Posterior Sampling", "authors": "Huaqiu Li,Yong Wang,Tongwen Huang,Hailang Huang,Haoqian Wang,Xiangxiang Chu", "background": "在低级视觉中，统一图像恢复是一个极具挑战性的任务。现有方法要么针对特定任务进行定制设计，限制了其在不同类型的退化情况下的泛化能力，要么依赖配对数据集进行训练，从而受到封闭数据集的限制。", "innovation": "提出了一种新型的、无需数据集的统一方法，通过预训练的潜在扩散模型进行循环后验采样。该方法结合多模态理解模型，在无任务特定条件下为生成模型提供语义先验。此外，采用轻量级模块对退化输入与扩散模型生成的偏好进行对齐，并采用循环精 refinements 进行后验采样。", "conclusion": "广泛的实验表明，我们的方法在性能和鲁棒性方面优于最新的方法，验证了其有效性和鲁棒性。我们的代码和数据将在该网址提供：this https URL"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00814", "html_url": "https://arxiv.org/abs/2507.00814", "title": "许多LLM比单一模型更具有功利性", "title_en": "Many LLMs Are More Utilitarian Than One", "authors": "Anita Keshmirian,Razan Baltaji,Babak Hemmatian,Hadi Asghari,Lav R. Varshney", "background": "道德判断在大型语言模型（LLM）的对齐和社交推理中发挥着核心作用。随着多智能体系统的兴起，理解LLMs在合作中的集体表现变得至关重要，与单个智能体相比。在人类道德判断中，群体讨论会产生一种功利性提升，即倾向于认可那些尽管有害但能最大化大多数人利益的行为规范违规。本研究旨在探讨类似的动力机制是否会在多智能体LLM系统中出现。研究通过测试六个模型在个人道德困境中独立或集体讨论的情况来验证这一现象。", "innovation": "研究通过将单一LLMs与多智能体LLMs进行对比，探讨了多智能体组合中的道德判断动态。研究发现，在不同的情境下，多智能体LLMs在集体讨论时比单独决策时更倾向于接受道德违规行为，这一现象类似于人类实验的表现。研究进一步分析了这种行为背后的机制差异，指出尽管LLM集体的行为表现可能与人类群体类似，但是驱动因素存在显著区别。", "conclusion": "本研究的结论表明，虽然LLM集体在表面上模仿了人类群体推理的行为，但实际上它们的行为机制不同，这为AI对齐、多智能体系统设计和人工道德推理提出了新的挑战和启示。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00880", "html_url": "https://arxiv.org/abs/2507.00880", "title": "NN-Former: 重新思考神经网络表示中的图结构", "title_en": "NN-Former: Rethinking Graph Structure in Neural Architecture Representation", "authors": "Ruihan Xu,Haokui Zhang,Yaowei Wang,Wei Zeng,Shiliang Zhang", "background": "随着深度学习的广泛应用，高效的网络设计和部署变得至关重要，神经预测器成为评估属性如准确性和延迟的关键工具。近期的研究表明，图神经网络（GNN）和变压器在表示神经架构方面表现出色，但两者都有各自的缺点：GNN难以表示复杂的特征，而变压器在架构深度增加时泛化能力较差。", "innovation": "该研究重新审视了神经架构拓扑结构，并发现兄弟节点在先前的研究中被忽视，因此提出了一个新的预测器，结合了GNN和变压器的优点来学习增强的拓扑结构。这一创新点提出了一个新颖的token混合器，考虑兄弟节点，以及一个新的通道混合器（双向图同构前馈网络），从而实现了在准确性和延迟预测方面的持续优秀表现，为学习有向无环图（DAG）拓扑提供了有价值的见解。", "conclusion": "该方法在准确性和延迟预测方面表现出一致的优秀性能，为学习DAG拓扑提供了理论支持，其代码可以在此处找到：this https URL."}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00817", "html_url": "https://arxiv.org/abs/2507.00817", "title": "CAVALRY-V：视频MLLMs对抗攻击的大规模生成框架", "title_en": "CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs", "authors": "Jiaming Zhang,Rui Hu,Qing Guo,Wei Yang Bryan Lim", "background": "视频多模态大型语言模型（V-MLLMs）在时间推理和跨模态理解方面展现了显著的能力，但在对抗攻击方面的脆弱性因复杂的空间-时间推理机制、时间依赖性和计算限制而尚未得到充分探索。现有的攻击方法对此类模型进行了有限的测试和挑战，研究者认为直接针对视觉感知与语言生成的交叉接口是进一步增强模型安全性的关键方法。", "innovation": "CAVALRY-V引入了两项关键创新：（1）一个双重目标语义视觉损失函数，同时破坏模型的文本生成概率和视觉表现，削弱跨模态集成；（2）一个计算高效的两阶段生成器框架，结合大规模预训练以实现跨模态的可转移性，并进行专门的微调以增强时空一致性。", "conclusion": "通过在全面的视频理解基准测试上的实证评估表明，CAVALRY-V在多个商业系统和开源模型上显著超越了现有的攻击方法，平均性能提升了22.8%。此外，通过隐含的时间连贯建模实现了跨模态的理解改进，甚至在仅针对图像理解任务时也同样取得了显著成果，达到了34.4%的平均增益。这一成果证明了CAVALRY-V作为跨模态系统对抗研究的基石方法的巨大潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00833", "html_url": "https://arxiv.org/abs/2507.00833", "title": "HumanoidGen: 通过LLM推理进行双臂灵巧操作的数据生成", "title_en": "HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning", "authors": "Zhi Jing,Siyuan Yang,Jicong Ao,Ting Xiao,Yugang Jiang,Chenjia Bai", "background": "现有的机器人操作数据集和仿真基准主要针对机器人手臂平台，而对于配备双臂和灵巧手的类人机器人，仿真任务和高质量示范相对缺乏。双臂灵巧操作本质上更为复杂，因为它需要协调的手臂运动和手部操作，导致自主数据收集变得具有挑战性。", "innovation": "该论文提出了HumanoidGen框架，这是一个自动任务创建和演示收集框架，利用原子灵巧操作和LLM推理生成关联约束。具体来说，该框架提供了基于原子操作的空间注解，并使用LLM规划器生成基于物体可用性和场景的执行空间约束链，以增强臂部移动的能力。为了进一步提高规划能力，该文采用了一种蒙特卡洛树搜索的变体来增强LLM推理，以适应长期任务和不足的标注。", "conclusion": "在实验中，创建了一个包含增强场景的新基准，以评估收集的数据质量。结果显示，2D和3D扩散策略的表现能够随着生成的数据集的规模而扩展。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00832", "html_url": "https://arxiv.org/abs/2507.00832", "title": "自动解剖基础后处理减少假阳性并提高深度学习颅内动脉瘤检测的可解释性", "title_en": "Automated anatomy-based post-processing reduces false positives and improved interpretability of deep learning intracranial aneurysm detection", "authors": "Jisoo Kim,Chu-Hsuan Lin,Alberto Ceballos-Arroyo,Ping Liu,Huaizu Jiang,Shrikanth Yadav,Qi Wan,Lei Qin,Geoffrey S Young", "background": "尽管深度学习模型能够在CTA中检测颅内动脉瘤方面取得了进展，但假阳性率仍然较高，阻碍了这些模型的临床应用。为了进一步降低假阳性率，作者采用了一种自动化的、基于解剖学的、启发式学习的混合动脉-静脉分割后处理方法，以检测颅内动脉瘤。研究中使用了两种深度学习模型：CPM-Net和一个可变形3D卷积神经网络-变压器混合体（3D-CNN-TR），并对143例私有CTA（包含218例标注的动脉瘤）进行了测试。", "innovation": "研究采用了一种基于解剖学的、可解释的后处理方法，能够有效减少两种深度学习模型检测颅内动脉瘤的假阳性率，同时不减少真阳性率，并且能够降低假阳性率/例数的比例，提高了深度学习模型在颅内动脉瘤检测中的性能和临床接受度。这种方法还结合了自动化和特定领域的启发式学习处理，为改善动脉瘤检测模型的效果和临床接受度提供了新的可能性。", "conclusion": "基于解剖学的、可解释的后处理能够提高基于深度学习的动脉瘤检测模型的表现。更广泛地说，结合自动的、基于特定领域的启发式学习的过程为改善动脉瘤检测模型的性能和临床适用性提供了新的希望。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00902", "html_url": "https://arxiv.org/abs/2507.00902", "title": "服务化星座：直接卫星至设备网络中的定制连通性管理", "title_en": "Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks", "authors": "Feng Wang,Shengyu Zhang,Een-Kee Hong,Tony Q.S. Quek", "background": "Direct-satellite-to-device (DS2D)通信正作为一种有前景的全球移动服务扩展解决方案，依赖于卫星星座的部署。然而，管理多星座的DS2D连接性存在诸多挑战，包括多覆盖重叠引起的高干扰及因快速卫星移动导致的频繁切换。目前，大多数方法仅在同一星座内运行，这在很大程度上限制了利用多星座连接性的潜力，导致DS2D服务性能不佳。", "innovation": "本文提出了星座即服务（CaaS）框架，将整个多星座基础设施视为共享资源池，并动态形成每个DS2D服务区域的最佳子星座（SC）。每个SC的形成集成了来自不同轨道的卫星，基于用户需求提供了定制化的连通性。CaaS采用了两种创新策略：基于生成性人工智能（GenAI）的预测卫星波束成形和预配置的切换路径，以高效地实现卫星接入和移动管理。仿真结果表明，CaaS在提高卫星服务速率的同时减少了切换开销，使其成为在多星座环境中管理和优化DS2D连接的一种高效且可持续的解决方案。", "conclusion": "CaaS通过将整个多星座基础设施视为共享资源池，并通过卫星波束成形与预配置切换路径动态形成最佳子星座，显著改善了DS2D服务性能，减少了切换开销。这使其成为多星座环境中管理DS2D连接的一个高效且可持续的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00903", "html_url": "https://arxiv.org/abs/2507.00903", "title": "基于深度学习的心肌磁共振成像T1和T2图分割在自动化疾病检测中的应用", "title_en": "Deep learning-based segmentation of T1 and T2 cardiac MRI maps for automated disease detection", "authors": "Andreea Bianca Popescu,Andreas Seitz,Heiko Mahrholdt,Jens Wetzl,Athira Jacob,Lucian Mihai Itu,Constantin Suciu,Teodora Chitiboi", "background": "参量组织映射能够实现心脏组织的定量表征，但手动勾画存在观察者间的一致性问题。传统的依赖平均松弛值和单一阈值的方法可能过于简化心肌的复杂性。本研究旨在评估深度学习能否达到与观察者间一致性相当的分割精度，探讨超越平均T1/T2值的统计特征的实用性，并评估结合多个特征的机器学习是否能提高疾病检测能力。", "innovation": "使用深度学习模型对T1/T2图进行分割，并通过结合多个特征提高疾病检测效果。研究发现，随机森林应用于所有特征可以显著提高分值，超过观察者间的一致性，并且高度相关于手动分割的结果。", "conclusion": "深度学习促进了T1/T2图的分割，结合多个特征与机器学习能够提高疾病检测的效果。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00891", "html_url": "https://arxiv.org/abs/2507.00891", "title": "MemeCMD：一种基于上下文检索的自动生成的中文多轮对话数据集", "title_en": "MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes", "authors": "Yuheng Wang,Xianhe Tang,Pufeng Huang", "background": "Memes在在线社交互动中被广泛使用，它们以生动、直观且往往幽默的方式表达意图和情感。现有的对话数据集大多局限于手动标注或纯文本对话，缺乏多模态互动中的表达性和情境细微差别。因此，本研究旨在解决缺乏表达力与情境微妙的问题，并介绍了MemeCMD，这是一种自动生成的包含上下文相关表情包的中文多轮对话数据集，通过结合大规模的机器学习标注的图片库与跨多种场景的自动生成对话，确保表情包的合理使用，提高多模态对话生成的有效性，从而为发展多模态对话AI提供可扩展且隐私保护的资源。", "innovation": "本研究创新地提出了一种名为MemeCMD的数据集，通过自动生成的方式结合大规模的Meme图片库与对话数据，加入了情境相关性的检索机制，从而填补纯文本对话数据集的不足，使对话更具有表达力和情境细微差别。", "conclusion": "实验表明，通过本研究的方法生成的对话更加符合上下文，并且具有多样性的图屮梗融入，展示了在这种数据集上的生成对话的有效性和多样性，为其作为发展多模态对话AI的可扩展且隐私保护的数据资源提供了有力的支持。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00907", "html_url": "https://arxiv.org/abs/2507.00907", "title": "感性零信任时代：我们为何不能再信任感官", "title_en": "The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses", "authors": "Fabio Correa Xavier", "background": "在深假和克隆声音等 sophisticated 攻击手段越来越多的情况下，组织需要一种新的安全理念：感性零信任。在这一背景下，本文科学分析了需要系统地质疑通过感官感知的信息，并提出了严格验证协议来减少基于生成式人工智能的欺诈风险。", "innovation": "将零信任原则扩展至人类感官信息，提出通过 Out-of-Band 验证、视觉语言模型（VLMs）作为法证合作者、加密来源以及人类培训等概念建立的框架。强调即使在 AI 生成的现实世界中，我们的感官也不再可以隐式信任，需要进行验证。", "conclusion": "领导者需要培养一种方法论上的怀疑主义文化，以在新的威胁环境下保护组织的完整性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00769", "html_url": "https://arxiv.org/abs/2507.00769", "title": "LitBench：一个可靠评估创造性写作的基准和数据集", "title_en": "LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing", "authors": "Daniel Fein,Sebastian Russo,Violet Xiang,Kabir Jolly,Rafael Rafailov,Nick Haber", "background": "评估由大型语言模型（LLMs）生成的创造性写作仍然面临挑战，因为开放式的叙述缺乏真实的基准。没有表现良好的自动化评估方法，现有的语言模型被用作零样本法官，然而其在这方面的可靠性是不确定的。为了寻求创造性写作的稳健评估，引入了LitBench，这是一个第一个标准基准和成对数据集，包括来自Reddit的去偏见的人类标签故事比较的保留测试集和由人类偏好标签组成的43827对训练语料库。使用LitBench，我们（i）评估零样本的LLM法官，（ii）训练Bradley Terry和生成奖励模型，（iii）进行在线人类研究以验证奖励模型在新生成的故事中的排名。我们的基准测试将Claude-3.7-Sonnet识别为最强的现成法官，达73%的一致性；在训练模型中，Bradley-Terry和生成奖励模型都达到了78%的准确性，超过所有现成的法官。在线人类研究进一步验证了我们训练后的奖励模型在新生成的故事中与人类偏好的一致性。我们发布了LitBench及其奖励模型，提供了一个经过验证的资源，用于可靠的自动化评估和优化创造性写作系统。", "innovation": "提出了LitBench，这是一个标准基准和成对数据集，用于创造性的写作验证，包括来自Reddit的去偏见的人类标签故事的保留测试集和由人类偏好标签组成的训练语料库。使用LitBench，研究逐步评估了零样本的LLM法官，训练了Bradley Terry和生成奖励模型，进行了在线人类研究以验证奖励模型在新生成的故事中的排名。研究表明，Claude-3.7-Sonnet是最强的现成法官，Bradley-Terry和生成奖励模型的准确性超过了所有现成的法官，且在线人类研究进一步证实了训练模型与人类偏好的一致性。 LitBench和奖励模型的发布提供了评估和优化创造性写作系统的可靠资源。", "conclusion": "LitBench为创造性写作的自动化评估和优化提供了可靠的标准和资源，通过标准化的基准测试和数据集，验证了零样本和训练的LLM法官的性能，展示了生成奖励模型在创造性写作评估中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00838", "html_url": "https://arxiv.org/abs/2507.00838", "title": "通过对短样本进行风格分析识别人类和LLM生成的文章", "title_en": "Stylometry recognizes human and LLM-generated texts in short samples", "authors": "Karol Przystalski,Jan K. Argasiński,Iwona Grabska-Gradzińska,Jeremi K. Ochab", "background": "随着大型语言模型（LLMs）的发展，研究者们正致力于通过风格分析（Stylometry）来区分机器生成和人类创作的文本。这项技术在版权归属、知识产权和伦理人工智能使用方面有着重要的应用前景。风格分析已被广泛应用于特征化文本风格和作者身份归因。为了解决模型归属问题，有必要对这些机器生成的文本进行分析，以识别它们的独特写作模式。研究者们创建了一个基于Wikipedia的数据集，涵盖了由人类、各种LLM模型、不同文本摘要方法和改写方法生成的文章，以此作为实验的基础。通过使用树型模型和基于n-gram的特征，研究表明，即使是相对微小的10句文本也非常有可能被准确地区分，尤其是在特定的文本类型中。", "innovation": "该研究创新性地提出并应用了风格分析技术，用于识别由大型语言模型生成的文本和人类创作的文本之间的差异。研究人员通过构建一个基于Wikipedia的数据集，涵盖了从人类到各种LLM模型生成的多种文本。利用人类设计和n-gram基于的特征，实验不仅展示了在跨验证中达到0.87的马修斯相关系数，还在二分类情况下达到0.98的高准确性。研究结果还表明，通过Shapley Additive Explanations，能够识别出机器生成文本和人类文本的独特特征。这些特征包括特定的词语重复模式和逻辑结构的标准化程度等。", "conclusion": "通过构建基准数据集并基于此进行风格分析，这项研究成功地区分了人类和大型语言模型生成的文章。结果表明，尤其是在特定文本类型中，使用特定的机器学习模型和特征可以实现高精度的文本来源识别。这一发现对于改善知识产权保护和加强人工智能伦理使用具有重要意义。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00816", "html_url": "https://arxiv.org/abs/2507.00816", "title": "PI-WAN: 一种面向未知环境四旋翼动力学预测的物理感知风自适应网络", "title_en": "PI-WAN: A Physics-Informed Wind-Adaptive Network for Quadrotor Dynamics Prediction in Unknown Environments", "authors": "Mengyun Wang,Bo Wang,Yifeng Niu,Chang Wang", "background": "准确的动力学建模对于四旋翼在各种应用中实现精确轨迹跟踪至关重要。传统基于物理知识的建模方法在未知环境中由于变载荷、风扰动和外部干扰变得局限。另一方面，基于数据的建模方法在处理未见过的数据分布时表现欠佳，限制了它们在未知场景中的有效性。针对这些问题，我们提出了物理感知风自适应网络（PI-WAN），这一方法结合了知识驱动和数据驱动的建模方法，通过直接在训练过程中嵌入物理约束实现四旋翼动力学的鲁棒学习。PI-WAN 使用了时空卷积网络架构来高效捕捉历史飞行数据中的时序依赖，同时，物理约束损失函数将物理原理应用于提高模型的泛化能力和适应性，强化对未见过条件的鲁棒性。通过将实时预测结果集成到模型预测控制（MPC）框架，我们提升了闭环跟踪性能。全面的仿真和现实世界飞行实验表明，我们的方法在预测精度、跟踪精度和对未知环境的鲁棒性方面优于基线方法。", "innovation": "物理感知风自适应网络（PI-WAN）同时结合知识驱动和数据驱动的方法，通过在训练过程中嵌入物理约束实现四旋翼动力学的鲁棒学习。该网络使用时空卷积网络架构来捕捉历史飞行数据中的时序依赖，并使用物理约束损失函数来改善模型的泛化能力和鲁棒性。通过集成实时预测结果到模型预测控制（MPC）框架中，实现了闭环跟踪性能的提升。", "conclusion": "我们提出的物理感知风自适应网络（PI-WAN）在预测精度、跟踪精度和对未知环境的鲁棒性方面均优于基线方法，证明了其在四旋翼动力学预测中的有效性和优越性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00938", "html_url": "https://arxiv.org/abs/2507.00938", "title": "WebArXiv：在固定不变的arXiv任务上评估多模态代理", "title_en": "WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks", "authors": "Zihao Sun,Meng Fang,Ling Chen", "background": "大型语言模型（LLMs）的最新进展使得自主网络代理的开发成为可能，这些代理能够导航和与实际网站互动。然而，现有基准的不稳定性和不一致性使得评估这些代理仍然具有挑战性，因为它们通常依赖于动态内容或过于简化的模拟。WebArXiv为这些代理提供了静态且时间不变的任务集，基于arXiv平台。WebArXiv通过将任务锚定在固定的网页快照中并提供确定的地面真实值和标准化的行为轨迹，确保了可重复性和可靠的评估。", "innovation": "WebArXiv引入了一个包含275个基于arXiv平台任务的静态平衡基准，用于评估多模态代理。此基准通过固定网页快照确保了可重复性和可靠性。研究中提出了一种轻量级的动态反思机制，允许代理在决策过程中选择性地检索相关过去的步骤，以解决常见的失败模式——刚性历史反射。", "conclusion": "十种最先进的网络代理在WebArXiv上的评估结果显示了代理之间的明显性能差异，并验证了提出的方法的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00909", "html_url": "https://arxiv.org/abs/2507.00909", "title": "将AI数据中心转变为电网互动资产：凤凰城实地演示的结果", "title_en": "Turning AI Data Centers into Grid-Interactive Assets: Results from a Field Demonstration in Phoenix, Arizona", "authors": "Philip Colangelo,Ayse K. Coskun,Jack Megrue,Ciaran Roberts,Shayan Sengupta,Varun Sivaram,Ethan Tiao,Aroon Vijaykar,Chris Williams,Daniel C. Wilson,Zack MacFarland,Daniel Dreiling,Nathan Morey,Anuja Ratnayake,Baskar Vairamohan", "background": "人工智能（AI）正在推动电力需求以指数级增长，威胁着电网的可靠性，导致社区在新能力建设上支付更高的价格，并阻碍了AI创新，因为数据中心需要等待电网容量受限的情况下的连接。", "innovation": "本文介绍了Emerald Conductor这一软件-only方法的首次现场演示，该方法是在与主要企业合作伙伴合作下完成的。Emerald Conductor将AI数据中心转变为灵活的电网资源，能够即时且高效地利用现有的电力系统，而无需大规模的基础设施建设。该平台能通过基于实时电网信号来协调AI工作负载，无需硬件修改或能源储存，重新定义了数据中心作为具有增强电网可靠性、提高成本效益和加速AI发展能力的电网互动资产。", "conclusion": "在亚利桑那州凤凰城的一个256-GPU集群中进行的试验，在电网高峰事件期间历时三小时，实现了电网事件期间集群电力使用率减少25%的同时，保持了AI服务质量（QoS）的保证。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00914", "html_url": "https://arxiv.org/abs/2507.00914", "title": "以大规模语言模型为动力的城市智能代理：概念、能力和应用", "title_en": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "authors": "Jindong Han,Yansong Ning,Zirui Yuan,Hang Ni,Fan Liu,Tengfei Lyu,Hao Liu", "background": "长久以来，智能城市的愿景是利用大数据和人工智能技术打造高效、宜居且可持续的都市环境。近期，大型语言模型（LLMs）的出现为实现这一愿景提供了新的途径。具备强大的语义理解和推理能力，LLMs可以作为智能代理，自主解决跨学科的复杂问题。文章关注的是城市LLM代理，这种代理能够半实体化存在于城市的混合网络空间中，用于系统级别的城市决策。", "innovation": "文章首次系统性地介绍了城市LLM代理的概念、特点及其应用场景。着重讨论了代理的工作流程，包括城市感知、记忆管理、推理、执行和学习等环节。另外，还按五个领域对城市LLM代理的应用案例进行了分类研究：城市规划、交通、环境、公共安全和城市社会。研究了其部署中值得信赖性和评估问题，并指出了未来研究中需要解决的开放性问题，为相关领域的进一步发展提供了一条路线图。", "conclusion": "该综述旨在成为城市LLM代理新兴领域的基础，并为LLMs与城市智能交叉领域的进步提供指导。我们维持并不断更新了一份包含相关论文和开源资源的列表，详见http://www.example.com。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00969", "html_url": "https://arxiv.org/abs/2507.00969", "title": "从单张图像构建手术神经辐射场", "title_en": "Surgical Neural Radiance Fields from One Image", "authors": "Alberto Neri,Maximilan Fehrentz,Veronica Penza,Leonardo S. Mattos,Nazim Haouchine", "background": "神经辐射场（NeRF）在三维重建和视图合成方面表现出色，但由于它们对大量多视角数据的依赖，它们在仅能获得少量数据的手术术中环境中应用有限。具体来说，术中收集大量数据难以实现，因为时间有限。这项工作通过利用术前MRI数据以及术中单张图像和术前数据，解决了这一挑战，以提高在手术场景中训练NeRF的效率和效果。", "innovation": "提出了一种结合术前MRI数据和术中单张图像的方法，通过神经风格迁移技术（WTC2和STROTSS）进行视图转换，以避免过度风格化，从而快速高效地训练NeRF，特别适用于手术场景下的数据有限情况。", "conclusion": "该方法在四个临床神经外科病例中进行了评估，并与基于真实手术显微镜图像训练的NeRF模型的合成结果进行了定量比较，结果显示了强大的合成一致性，表明重建保真度和风格对齐度高。与真实情况相比，该方法显示出高的结构相似度，证明重建质量和纹理保留良好，从而证明了在手术环境中从单张图像训练NeRF方法的可行性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00953", "html_url": "https://arxiv.org/abs/2507.00953", "title": "从句子到序列：重新思考生物系统中的语言", "title_en": "From Sentences to Sequences: Rethinking Languages in Biological System", "authors": "Ke Liu,Shuanke Shen,Hao Chen", "background": "大规模语言模型在自然语言处理（NLP）中的范式也展示出了在建模生物语言，如蛋白质、RNA 和 DNA 方面的潜力。NLP 中的自回归生成范式和评估指标已被转移到生物序列建模中，尽管自然语言和生物语言在内在结构关联上有根本的差异，但现有方法仍然适用。因此，该研究重新审视了生物系统中的语言概念，旨在更好地理解 NLP 的成功如何有效转化为生物领域。通过将生物分子的三维结构视为句子的语义内容，并考虑到残基或碱基之间的强关联性，强调了结构评估的重要性，并演示了自回归范式在生物语言建模中的适用性。", "innovation": "将生物分子的三维结构视为句子的语义内容，并考虑到残基或碱基之间的强关联性，重新定义生物系统中的语言概念，强调结构评估的重要性，并证明了自回归范式在生物语言建模中的适用性。", "conclusion": "重新审视了生物系统中的语言概念，提出了通过将生物分子的三维结构作为语义内容的自回归建模方法，并展示了其在生物语言建模中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01003", "html_url": "https://arxiv.org/abs/2507.01003", "title": "通过遍历定理描述神经网络的训练过程：幽灵节点", "title_en": "Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes", "authors": "Eun-Ji Park,Sangwon Yun", "background": "近期的研究提议从遍历角度解释神经网络的训练过程。在此基础上，作者提供了一个统一的框架，通过随机梯度下降法理解并加速深度神经网络的训练。通过对目标函数几何景观的分析，引入了一个实际的诊断工具——运行最大的李雅普unov指数的估计值，这一诊断工具可以区分向稳定极小值的真实收敛与在鞍点附近仅进行统计性稳定。", "innovation": "提出了一种幽灵类别扩展标准分类器的新方法，通过添加辅助幽灵输出节点使模型获得额外的下降方向，从而在损失障碍狭窄时打开横向走廊，并使优化器在早期训练阶段绕过较差的极值。研究结果表明，这种方法严格减少了近似误差，并在充分收敛后，幽灵维度消失，扩展模型的不变法则与原始模型一致，存在一条在扩充的参数空间中未增加总损失的同时使原始损失任意减少的路径。", "conclusion": "这些结果提供了一个在原理上对架构层面进行的干预措施，在早期阶段加速训练速度同时保持渐近行为的稳定性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00966", "html_url": "https://arxiv.org/abs/2507.00966", "title": "MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement", "title_en": "MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement", "authors": "Nikolai Lund Kühne,Jesper Jensen,Jan Østergaard,Zheng-Hua Tan", "background": "在新序列模型如Mamba和xLSTM出现之前，已有研究表明这些模型在单声道语音增强、自动语音识别和自我监督的音频表示学习中与最先进的模型相当或更优。然而，以往的研究发现序列模型如LSTM和Mamba容易在训练集上过拟合。为了解决这一问题，之前的研究表明在LSTMs中加入自注意力能够显著提高单声道语音增强任务的泛化性能。然而，将Mamba与时间-频率多头注意力模块结合使用以及探索其泛化性能的研究尚不充分。", "innovation": "本文提出了一种新的混合架构MambAttention，它结合了Mamba和共享的时间-频率多头注意力模块，以实现可泛化的单声道语音增强。此外，还提出了一种新的数据集VoiceBank+Demand Extended (VB-DemandEx)，该数据集基于VoiceBank+Demand数据集，但具有更具有挑战性的噪声类型和更低的信噪比。MambAttention模型在两个离域数据集DNS 2020和EARS-WHAM_v2上的所有报告评估指标中均优于现有模型，并且与现有的VB-DemandEx数据集上的性能相当。此外，研究表明时间-和频率多头注意力模块之间的权重共享对泛化性能至关重要，同时引入了共享时间-和频率多头注意力模块与LSTM和xLSTM结合的方案，进一步提高了离域数据集的性能。尽管如此，MambAttention模型在所有报告的评估指标中仍然是两个离域数据集上的最优模型", "conclusion": "MambAttention模型在两个测试数据集上优于现有模型，在同域数据集上与现有模型的性能相当。模块之间的权重共享研究以及引入共享时间-和频率多头注意力模块与LSTM和xLSTM结合的研究结果表明，这种设计对泛化性能有显著的积极影响。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00971", "html_url": "https://arxiv.org/abs/2507.00971", "title": "适应性推理作为安全防御", "title_en": "Reasoning as an Adaptive Defense for Safety", "authors": "Taeyoun Kim,Fahim Tajwar,Aditi Raghunathan,Aviral Kumar", "background": "现有的推理方法已能够通过适配测试时算力分配来提升大模型在可验证领域（如数学和代码）上的性能。本文旨在探讨如何利用这一方法来训练表现出一定程度安全鲁棒性的模型，并展示这样做可以带来一定的好处。研究发现，通过训练模型适应性地进行推理，可以在遇到含糊不清的问题时花费更多算力，从而改进安全性争议的权衡。同时，模型内部学会区分安全和不安全的问题，并展现出对白盒（如GCG）和黑盒攻击（如PAIR）的鲁棒性增强。\n", "innovation": "本文提出了一个名为TARS（Training Adaptive Reasoners for Safety）的方法，这个方法基于强化学习（RL），通过使用推理链式记录和一个平衡安全与任务完成的奖励信号来训练模型进行安全推理。TARS通过以下三种关键设计选择来防止捷径行为并保持推理能力：（1）轻量级的预训练微调阶段；（2）混合有害、无害及模棱两可的提示，防止拒绝过多等捷径行为；（3）奖励函数避免训练过程中推理能力的退化。\n", "conclusion": "通过对每条提示进行推理，TARS训练的模型展现出了更好的安全拒绝权衡，同时对白盒和黑盒攻击都表现出更高的鲁棒性，为训练对抗破解和有害请求的大模型提供了一种有效且开放的方法。\n"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00990", "html_url": "https://arxiv.org/abs/2507.00990", "title": "通过生成视频模仿实现无需物理示范的机器人操作", "title_en": "Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations", "authors": "Shivansh Patel,Shraddhaa Mohan,Hanlin Mai,Unnat Jain,Svetlana Lazebnik,Yunzhu Li", "background": "当前机器人操作主要依赖于物理示范和专门针对机器人的训练，这些方法不仅耗时，而且难以扩展。本研究提出了一种名为RIGVid的系统，使机器人能够通过模仿AI生成的视频进行复杂的操作，无需任何物理示范或机器人特定的训练。该系统能够在给定语言命令和初始场景图像的情况下，生成潜在的示范视频，并通过视觉语言模型自动筛选出符合命令的视频。", "innovation": "该系统的核心创新在于无需物理示范或者特定机器人训练，而是通过生成视频进行模仿，同时使用视频扩散模型生成示范视频，通过视觉语言模型筛选有效视频，以及使用6D姿态追踪技术提取物体轨迹并将其适应到机器人上。研究还展示了生成视频在机器人操作中的有效性，并表明其性能随着生成质量的提高而增强。另外，研究还证明依赖生成视频优于关键点预测等更紧凑的替代方法，强6D姿态追踪也优于其他轨迹提取方法，如密集特征点追踪。", "conclusion": "研究结果表明，通过现代现成模型生成的视频可以作为机器人操作的有效监督源。通过这一发现，可以改进机器人操作中模仿的方法，减轻对物理示范的依赖，并提高操作任务的效率和灵活性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01001", "html_url": "https://arxiv.org/abs/2507.01001", "title": "SciArena: 一项针对科学研究文献任务的基础模型开放评价平台", "title_en": "SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks", "authors": "Yilun Zhao,Kaiyan Zhang,Tiansheng Hu,Sihong Wu,Ronan Le Bras,Taira Anderson,Jonathan Bragg,Joseph Chee Chang,Jesse Dodge,Matt Latzke,Yixin Liu,Charles McGrady,Xiangru Tang,Zihang Wang,Chen Zhao,Hannaneh Hajishirzi,Doug Downey,Arman Cohan", "background": "科学文献理解和综合的传统基准仅限于研究社区内部进行模型比较，而不直接促进研究社区的参与。SciArena 平台旨在公开并合作地评估基础模型在科学文献任务上的表现，通过借鉴聊天机器人竞技场的评价方法，即通过社区投票进行模型比较，从而利用集体智慧，这提供了一种社区驱动的、开放性科学任务评估方式。平台目前支持23种开源和专有基础模型，并已收集了来自多个科学领域可信研究人员的超过13,000票。所收集的数据证实了提交的问题多样性、与实际文献需求的对齐性，以及参与研究人员的自洽性和评估者间的一致性较高。根据模型排名领导榜，讨论了模型评估的结果与见解。为了进一步促进基于模型的自动化评价系统在文献任务中的研究，SciArena-Eval （基于收集的偏好数据的元评价基准）也被创建出来，用来衡量模型在评估答案质量方面的准确性，即通过比较它们的两两评估与人类投票的差异来实现。实验结果强调了基准的挑战，并强调了需要更可靠的自动化评价方法的需求。", "innovation": "SciArena 平台采用聊天机器人竞技场的社区投票模型比较方法，利用集体智慧促进基础模型在科学文献任务上的开放性评估。同时，它提出了 SciArena-Eval 基准，通过比较模型的评估与人类投票来衡量模型在评估答案质量方面的准确性，从而解决传统方法的可靠性问题。", "conclusion": "SciArena 平台证明了利用集体智慧进行基础模型自动评价的有效性，并通过收集的偏好数据提出了 SciArena-Eval 基准，进一步促进了针对科学文献任务的自动化评价方法的研究。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking: 向大规模强化学习推动多模态通用推理的方向", "title_en": "GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Leyi Pan,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianle Gong,Wenkai Li,Wei Jia,Xin Lyu,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuxuan Zhang,Zhanxiao Du,Zhenyu Hou,Zhao Xue,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "该论文介绍了GLM-4.1V-Thinking，这是一个被设计用来推进通用多模态推理的视觉-语言模型（VLM）。研究者开发了一个可以进行大规模预训练的能力较强的视觉基础模型，然后通过强化学习中的课程采样（RLCS）来挖掘该模型的全部潜能，使其能够在涉及科学、技术、工程和数学（STEM）问题解决、视频理解、内容识别、编程、图像描述、基于GUI的代理以及长文档理解等多个任务中取得全面提升。", "innovation": "该研究通过大规模预训练开发出了一个强大的视觉基础模型，并结合RLCS方法，显著提升了模型的多模态推理能力。最后开放了GLM-4.1V-9B-Thinking这一模型，不仅取得了业内最佳的性能，还在多个公开基准测试中表现超越了规模更大的Qwen2.5-VL-72B模型，甚至在挑战性的任务如长文档理解和STEM推理上与闭源模型GPT-4o表现相当或优于后者，展现出了较强的通用性。", "conclusion": "GLM-4.1V-9B-Thinking在28个公开基准测试中几乎在所有任务上都取得了优于Qwen2.5-VL-7B的表现，并且在18个基准测试中甚至超越了更大的Qwen2.5-VL-72B模型。此外，该模型在开放源代码的状态下还在复杂的任务如长文档理解和STEM推理等方面表现出了强大的能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2203.09952", "html_url": "https://arxiv.org/abs/2203.09952", "title": "克服幽灵：基于图关系学习的信息可靠性表示与端到端稳健导航", "title_en": "Conquering Ghosts: Relation Learning for Information Reliability Representation and End-to-End Robust Navigation", "authors": "Kefan Jin,Xingyao Han", "background": "在实际自动驾驶应用中， environmental disturbances are inevitable，包括传感器数据噪声、多种照明条件、恶劣天气和外部对抗性干扰等。这些干扰会影响车辆的感知能力和性能，主要问题之一是假阳性检测（ghost object），即那些不存在或出现在错误位置的对象。传统的导航方法倾向于避开所有检测到的对象以确保安全，然而，避开一个幽灵可能会将车辆置于更危险的境地，如公路上的突然刹车。面对多种干扰类型，从感知层面难以解决该问题。潜在的解决方法是通过整体场景中的关系学习来检测幽灵，并开发一个集成的端到端导航系统。我们的逻辑是场景中所有车辆的行为受到其邻居的影响，正常车辆行为合理，而幽灵车辆不符合逻辑。通过学习周围车辆的时空关系，学会每辆车的信息可靠性表示，然后开发一个机器人导航网络。", "innovation": "与现有工作不同，我们鼓励网络学习如何表示可靠性以及如何通过不确定性合并所有信息，从而提高效率和泛化能力。据作者所知，这是首篇利用图关系学习来实现存在幽灵车辆状态下的端到端稳健导航的工作。在CARLA平台上进行的仿真结果证明了所提出方法在各种场景中的可行性和有效性。", "conclusion": "该方法为在存在幽灵车辆情况下的自动驾驶应用提供了新的解决方案，通过学习车辆之间的关系，提高了导航系统的鲁棒性和可靠性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02952", "html_url": "https://arxiv.org/abs/2505.02952", "title": "使用逐步剪切搜索方法解决提示模糊性的迭代解决方案", "title_en": "Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach", "authors": "Fabrizio Marozzo", "background": "生成式AI系统通过使自然语言编码和问题解决成为可能，已经彻底改变了人类交互方式。然而，自然语言的固有模糊性往往会导致指令不精确，迫使用户进行迭代测试、纠正和重新提交。我们提出了一个迭代的方法，通过结构化的澄清问题和备选解决方案系列方式，系统地缩小这些模糊性，并通过输入/输出示例进行展示。一旦所有不确定性都得到解决，最终将生成一个精确的解决方案。这种方法在涵盖编程、数据分析和创意写作等多个领域的数据集上进行了评估，显示出比传统的单次解决方案更高的准确性、可竞争的解决时间和更高的用户满意度，而后者通常需要多次手动迭代才能得到正确的输出.", "innovation": "我们提出了一种迭代方法，通过结构化的澄清问题和备选解决方案系列方式，系统地缩小编码中的模糊性。这种方法在解决自然语言固有模糊性方面具有优势，能够实现更高的准确性、可竞争的解决时间和提高用户满意度，相比传统的单次解决方案，它不需要多次手动迭代即可达到正确的输出结果。", "conclusion": "我们提出的迭代方法，通过结构化的澄清问题和备选解决方案，在编程、数据分析和创意写作等多个领域中，展示了比传统单次解决方案更高的准确性、可竞争的解决时间和更高的用户满意度。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.20302", "html_url": "https://arxiv.org/abs/2409.20302", "title": "OM4OV: 利用本体匹配进行本体版本控制", "title_en": "OM4OV: Leveraging Ontology Matching for Ontology Versioning", "authors": "Zhangcheng Qiang,Kerry Taylor,Weiqing Wang", "background": "由于语义网的动态特性，版本控制是必要的，特别是在处理广泛使用的本体时捕捉时间变化信息。长期以来，人们认识到版本控制（OV）是高效本体管理的关键组成部分。然而，随着本体规模的增长和由手工劳动造成的累积错误，当前的版本控制方法已经不堪重负。", "innovation": "本文提出了一种使用现有本体匹配（OM）技术与系统的新型版本控制方法，并引入了统一的OM4OV管道。从OM的角度出发，我们重新定义了版本控制任务的表述和度量方法，并基于OM产生的先前提案对齐信息，提出了名为交叉参考（CR）机制的管道优化方法，以提升整体的版本控制性能。我们通过来自Ontology Alignment Evaluation Initiative (OAEI)数据集的版本控制测试床实验验证了OM4OV管道和交叉参考机制，并讨论了用于版本控制任务的本体匹配见解，指出一些由版本控制系统检测到的显式错误对映射实际上并不是不正确的。", "conclusion": "我们实验验证了OM4OV管道和交叉参考机制，并通过版本控制测试床展示了其有效性，还深入探讨了本体匹配在版本控制任务中的应用与效果。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.10774", "html_url": "https://arxiv.org/abs/2408.10774", "title": "Flexora: 弹性低秩适应方法用于大规模语言模型", "title_en": "Flexora: Flexible Low Rank Adaptation for Large Language Models", "authors": "Chenxing Wei,Yao Shu,Ying Tiffany He,Fei Richard Yu", "background": "大规模语言模型（LLMs）通过增加模型参数的规模，显著提升了泛化能力并在实际中解锁了新功能。不过，在特定下游任务上的表现往往受限于它们对这些任务的知识边界。因此，人们引入了微调技术，特别是广泛使用的低秩适应（LoRA）方法来扩展这些任务的知识边界，然而由于其在某些任务上的潜在过拟合，LoRA在这些任务上的效果不佳。为克服这种过拟合并提高LoRA在任务中的表现，提出了弹性的低秩适应（Flexora）方法，该方法能够自动且灵活地选择需要微调的关键层，以达到在不同下游任务上的最佳表现。Flexora首先将这一层的选择问题定义为一个规范的超参数优化（HPO）问题，然后使用展开微分（UD）方法解决这个问题，并最终基于优化后的超参数选择最有效的层。广泛的实验表明，Flexora能够持续改善现有的基线方法，表明Flexora在实际中的有效性。此外，还提供了具有洞察力的理论结果和多次消融研究，以全面理解Flexora的方法。", "innovation": "提出了弹性的低秩适应（Flexora）方法，自动并灵活地选择需要微调的关键层，借助展开微分（UD）方法解决层选择问题，并基于优化后的超参数选择最有效的层，有效克服LoRA方法的过拟合问题，提高微调性能和适应性。", "conclusion": "广泛的实验表明，Flexora能够在多种预训练模型和自然语言处理任务上持续提升性能，证明了该方法的有效性。通过理论分析和消融研究，提供了对Flexora方法的全面理解。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20702", "html_url": "https://arxiv.org/abs/2506.20702", "title": "全球人工智能安全研究优先事项的新加坡共识", "title_en": "The Singapore Consensus on Global AI Safety Research Priorities", "authors": "Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Johannes Heidecke,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,William Tjhi,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić", "background": "随着人工智能（AI）能力的迅速提升以及自主性的增加，AI的发展既带来了巨大的变革潜力，也引发了关于如何确保AI安全的激烈讨论。安全的AI需要被认为是可信、可靠和安全的，因此建立一个可信赖的生态系统至关重要。为了支持这一领域的研究，2025新加坡AI国际科学院会议汇集了来自世界各地的AI科学家，共同识别和整合AI安全的研究重点。该会议产生的报告基于Yoshua Bengio领导的国际AI安全报告，并获得了33个国家的支持。该报告采用了多层次防御模型，将AI安全研究领域分为三个类别。", "innovation": "该报告创新地将AI安全研究领域细分为三个类别：创建可信AI系统的挑战（开发）、评估其风险的挑战（评估），以及部署后的监控和干预挑战（控制）。这种多层次防御模型为人工智能安全研究提供了一个更加全面和系统的方法。", "conclusion": "该报告总结了全球AI安全的高优先级研究领域，促进了跨国界的科学交流与合作，并强调了建立可信AI生态系统的重要性，以促进创新的同时避免负面反应。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06096", "html_url": "https://arxiv.org/abs/2505.06096", "title": "自由且公平的硬件：利用大模型生成无版权侵权风险Verilog代码的新路径", "title_en": "Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs", "authors": "Sam Bush,Matthew DeLorenzo,Phat Tieu,Jeyavijayan Rajendran", "background": "由于大型语言模型（LLM）在硬件设计任务中的限制，例如生成功能性的Verilog代码，推动了利用开源仓库中精心筛选的硬件数据集的各种优化。然而，现有的数据集规模有限，并且缺乏再利用的版权检查，导致fine-tuned LLMs可能存在版权违规的风险。因此，需要一个评估基准来估计Verilog训练的LLM产生受版权保护代码的风险，并提供一个开放源代码的Verilog数据集FreeSet来降低这种风险，同时提出一个自动化数据集策展框架以确保公平使用的Verilog数据。", "innovation": "提出了一个评估基准框架来估计Verilog训练的LLM产生受版权保护代码的风险。提出了一个包含超过220k文件的开源Verilog数据集FreeSet，并建立了自动数据集策展框架以确保公平使用的Verilog数据。通过持续预训练的方法，提出了一种fine-tuned Llama模型FreeV，该模型显示出在先前研究中的最小版权侵权风险，版权违规率为3%，并且生成Verilog代码的功能有所改进，实现了VerilogEval pass@10率提高超过10%的效果。", "conclusion": "研究表明FreeV展示了最小的版权侵权风险，并且在生成Verilog代码的功能上取得了显著改进，进一步验证了OpenSet策展框架的有效性，使得通过大模型生成无版权侵权风险的Verilog代码成为现实。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20094", "html_url": "https://arxiv.org/abs/2505.20094", "title": "SwarmThinkers: 学习大规模原子KMC跃迁的物理一致性", "title_en": "SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale", "authors": "Qi Li,Kun Li,Haozhi Han,Honghui Shang,Xinfu He,Yunquan Zhang,Hong An,Ting Cao,Mao Yang", "background": "尽管在几十年的发展中取得了进步，但传统科学模拟系统实现同时具备物理一致性、设计可解释性以及多尺度扩展性的目标仍然难以实现。经典方法如动力学蒙特卡洛确保热力学准确性，但扩展性不佳；而基于学习的方法提供了效率，但往往牺牲了物理一致性与可解释性。", "innovation": "我们提出了一种基于强化学习框架SwarmThinkers，将原子尺度模拟重新构想为与物理定律紧密相关的群体智能系统。每个扩散粒子都被建模为具有局部决策能力的代理，通过共享的策略网络在热力学约束下选择跃迁。引入加权机制融合学习偏好与跃迁率，保留统计保真度的同时实现可解释、分步决策。这种框架遵循集中训练、分散执行的模式，使得策略能够泛化到不同规模、浓度和温度的系统而无需重新训练。在模拟辐射引起的Fe-Cu合金沉淀的基准测试中，SwarmThinkers成为第一个可以在单个A100 GPU上实现全规模物理一致性模拟的系统，比使用开源KMC在超级计算机上的模拟快4963倍（平均快3185倍），同时内存消耗降低了485倍。通过将粒子视为决策者，SwarmThinkers实现了科学模拟的一个范式转变，通过代理驱动的智能统一了物理一致性、可解释性和可扩展性。", "conclusion": "SwarmThinkers通过将原子尺度模拟重新构想为群体智能系统，实现了同时物理一致性、可解释性和可扩展性的目标。这种新框架能够在单个GPU上高效实现大规模原子水平的模拟，并为科学模拟领域带来了新的范式。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16459", "html_url": "https://arxiv.org/abs/2505.16459", "title": "MMMR：评估大规模多模态推理任务", "title_en": "MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks", "authors": "Guiyao Tie,Xueyang Zhou,Tianhe Gu,Ruihang Zhang,Chaoran Hu,Sizhe Zhang,Mengqu Sun,Yan Zhang,Pan Zhou,Lichao Sun", "background": "近期，多模态大型语言模型（MLLMs）的发展使得整合语言、视觉及结构化输入的能力增强，并开启了逻辑推理、空间理解和科学分析等复杂任务的大门。尽管如此，MLLMs，特别是在推理过程中引入中间思考痕迹的MLLMs-T的推理能力和评测标准仍然有待深入探索，现有研究主要集中在感知或最终答案的准确性上，无法全面揭示模型在不同模态间的推理过程或失败模式。为了填补这一空白，本文提出了一种新的MMMR基准，旨在严格考察明确的多模态推理。MMMR包含1083道高难度问题，覆盖六种不同的推理类型，并具有符号深度和多跳需求，还包括一个模块化的推理痕迹评估管道（RTEP），用于超越准确率来评测推理质量，通过相关性、一致性等度量和结构化错误注释进行评估。实验结果显示，MLLMs-T整体优于无思维模型，但即便是Claude-3.7-Sonnet和Gemini-2.5 Pro等顶尖模型也存在推理路径上的问题，如不一致和过度推理。该基准揭示了准确性与推理质量之间持续存在的差距，提供了未来模型开发的可操作评估管道。", "innovation": "本文提出了MMMR基准，旨在严苛地检验多模态推理。MMMR拥有一个高难度数据集，包含1,083个覆盖多种推理类型的题目，一个模块化的推理痕迹评估管道，通过相关性、一致性和结构化错误注释等度量来评估推理质量，这超过了准确性的单一评估维度。该基准还揭示了即便是顶级模型也存在的推理缺陷，如不一致和过度推理。这些发现提供了一个具有可操作性的评估框架，有助于未来模型的改进和发展。", "conclusion": "该基准揭示了准确性与推理质量之间持续存在的差距，提供了未来模型开发的可操作评估管道，最终MMMR提供了一个可扩展的基础，用于评估、比较和改进新一代多模态推理系统。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20170", "html_url": "https://arxiv.org/abs/2505.20170", "title": "Equations 思维程序以解决代数文字问题", "title_en": "Program of Equations Thoughts to Solve Algebra Word Problems", "authors": "Yunze Lin", "background": "近年来，代数文字问题（AWPs）已成为自然语言处理任务中的一个重要领域。大型语言模型（LLMs）展示了强大的数学能力，链式思维技术通过逐步推理指导LLMs取得了显著的成果。然而，LLMs自身的计算弱点意味着在推理过程中可能会产生累积计算错误，导致最终答案不正确。", "innovation": "为了解决这一问题，本文提出了一种称为Equations 思维程序（POET）的方法，将生成逐步推理答案的任务转变为预测方程和生成代码的两阶段任务，将复杂的计算卸载到Python解释器上，从而避免LLMs中的计算错误。此外，还提出了一种零样本POET，利用手动设计的模板使LLMs可以直接生成用于一阶求解的Python代码。该方法在PEN和ALG514数据集上分别实现了95.3%和98.0%的准确性，设立了新的SOTA。零样本POET还在DRAW-1K数据集上达到了95.5%的SOTA结果。", "conclusion": "本文通过提出Equations 思维程序（POET）和零样本POET，显著提高了在ALG514、PEN和DRAW-1K数据集上解决代数文字问题的准确性，推动了该领域的最新技术发展。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21329", "html_url": "https://arxiv.org/abs/2506.21329", "title": "基于主动推断的AI系统在科学研究中的应用", "title_en": "Active Inference AI Systems for Scientific Discovery", "authors": "Karthik Duraisamy", "background": "人工智能的迅速发展带来了科学发现的变革期望，但现有系统仍然受到操作架构、脆弱的推理机制以及与实验现实分离的限制。因此，需要通过解决抽象差距、推理差距和现实差距三大根本问题来推动由AI驱动的科学发展，而不是仅仅依赖于模型规模、数据和测试时间的计算能力。科学研究要求能够模拟动作和响应、区分相关性和机制的因果结构，并持续校准的内部表示形式。", "innovation": "提出了基于主动推断的AI系统，这类系统能（i）保持基于因果自监督基础模型的长期研究记忆；（ii）配有贝叶斯护栏的符号或神经符号规划者；（iii）生成持久的知识图谱，其中思考产生新的概念节点，推理建立因果关系，现实世界交互去除错误连接并强化验证的路径；（iv）通过与高保真模拟器和自动化实验室的闭环互动来优化内部表示——一个思维推演指导行动，而经验上的惊讶重塑理解的操作循环。此外，研究表明反馈的固有模糊性和潜在的不确定性使人类判断不可或缺，不应仅作为临时支架，而是作为永久的架构组件。", "conclusion": "这种主动推断的AI系统架构是从内模型启用的反事实推理与外部验证之间的相互作用中产生发现的关键，人类的判断对于理解和验证假设是必不可少的，无论是暂时的还是永久性的。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23153", "html_url": "https://arxiv.org/abs/2505.23153", "title": "向导集体自适应智能的概念框架", "title_en": "Conceptual Framework Toward Embodied Collective Adaptive Intelligence", "authors": "Fan Wang,Shaoshan Liu", "background": "集体自适应智能（CAI）代表了在物理智能体领域的一个革新性方法，其中多个自主智能体协作、适应并自组织以应对复杂的动态环境。通过使系统能够根据未预见的挑战重新配置，CAI 在真实世界场景中实现了稳健的性能。这项文章提出了设计和分析CAI的概念框架，概述了关键属性包括任务泛化、抗灾性、可扩展性和自组装，旨在连接理论基础与实践方法来构建适应性、涌现性智能。通过构建对理解并实施CAI的结构化基础，这项工作旨在指导研究人员和实践者开发更稳健、可扩展和适应性强的智能系统，应用于各种领域。", "innovation": "提出了一个设计和分析集体自适应智能（CAI）的概念框架，概述了关键属性包括任务泛化、抗灾性、可扩展性和自组装，将理论基础与实践方法连接起来。这项工作不仅提供了一种理解CAI的结构化方法，还进一步指导研究人员和实践者开发更先进的智能系统。", "conclusion": "通过提供集体自适应智能的结构化基础，这项工作为研究人员和从业者开发在不同领域更加稳健、可扩展和适应性强的AI系统指明了方向。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22774", "html_url": "https://arxiv.org/abs/2506.22774", "title": "伦理原则与算法方法的桥梁：评估AI系统可信性的另类方法", "title_en": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems", "authors": "Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis", "background": "人工智能技术代表了人类制造的复杂挑战，尤其是那些广泛融入社会并对人类产生重大影响的技术。虽然其他技术也可能带来巨大风险，但人工智能的广泛影响使其社会效应尤为深远。人工智能系统的复杂性和它们的能力会导致对超出直接人类监控和理解的操作技术的依赖。为了减轻由此产生的风险，已经开发了一些理论工具和指导原则，同时也开发了旨在保护可信人工智能的技术工具。然而，指导原则提供了更全面的视角，但未能提供衡量可信性的技术；而技术工具虽然可以在衡量方面做得更好，但它们缺乏全面的视角，仅专注于可信人工智能的具体方面。", "innovation": "本文提出了一种结合可信人工智能的伦理成分和PageRank及TrustRank算法过程的评估方法。目标是通过引入算法标准建立一种评估框架，以最小化自我评估方法中固有的主观性。应用该方法表明，通过考虑相关指导文件的理论内容，可以实现对AI系统可信性的综合评估，并提供定量的见解。", "conclusion": "方法能够在全面评估AI系统的可信性方面提供定量的视角，同时考虑相关指导文件的理论内容，从而减少主观性，并有助于更有效地评估AI系统的信任水平。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22419", "html_url": "https://arxiv.org/abs/2506.22419", "title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "title_en": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "authors": "Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach", "background": "近年来，大规模语言模型（LLMs）取得了快速进步，这些模型有潜力在科学研究中发挥作用。要达成这一目标的一个关键能力是能够复现现有的研究成果。为了评估人工智能代理在活跃研究领域的复现结果能力，作者引入了一种新的基准测试——自动化LLM速过赛，利用了NanoGPT速过赛的研究社区贡献数据，该比赛旨在以最短的时间训练一个GPT-2模型。这19个速度赛任务提供了代理以前的比赛脚本记录和具有多样级别的提示，包括伪代码到类似论文的描述。这些记录旨在快速实现，并且速度赛改进涵盖了广泛的代码级变化，从高级算法改进到硬件感知优化。这些特性使得基准测试在提升LLM训练前沿问题上既易于实现又具有现实意义。", "innovation": "该研究引入了自动化LLM速过赛，基于NanoGPT速过赛的研究贡献，为AI评估提供了一个新的标准。每个任务都提供了以往的速度记录脚本和不同的提示水平，从伪代码到类似论文的描述，覆盖了不同的代码级变化。这使得基准测试兼具易用性和现实性，反映在提升LLM训练方面面临的前沿问题。研究发现，最新的推理LLM与最先进的框架结合时，在基准测试中仍难以重现已知的创新，即使提供了详细的提示也未能成功。这一基准为评估LLM自动科学复现能力提供了一个简单而未饱和的衡量标准，对于自主研究代理来说是必需但不充分的技能。", "conclusion": "该研究展示了自动化LLM速过赛的能力，能够作为一个简单的、未饱和的衡量标准，评估LLM自动科学复现的能力，这对于自主研究代理来说是必要的前提技能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22919", "html_url": "https://arxiv.org/abs/2506.22919", "title": "Hecto：适应性且可解释的多功能专家模块", "title_en": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning", "authors": "Sanskar Pandey,Ruhaan Chopra,Saad Murtaza Bhat,Ark Abhyudaya", "background": "Mixture-of-Experts (MoE) 模型通过将输入路由到专门化的专家来实现条件计算，但这些专家依赖于相同的归纳偏差，限制了表示的多样性。静态的计算路径对于需要不同类型的推理的输入来说是低效的，并限制了专家的专业化和解释性。", "innovation": "提出了一种轻量级的 MoE 架构 Hecto，结合了用于时间推理的 GRU 专家和用于静态抽象的 FFNN 专家，通过稀疏 Top-1 门控机制进行组合。Hecto 在三种推理基准 (AG News, SST-2, HotpotQA) 和一个回归任务 (STS-B) 上进行评估时，即使只接收独立的输入表示，其性能也能达到或接近同质基准的水平，同时表现出清晰的专家专业化，每个专家都对应不同的推理类型 (时间 vs 静态)。在更大的批次大小下，Hecto 表现更好，由于宽松的计算限制，其异构架构能够更有效地优化。在消融实验中，确定了架构多样性是 Hecto 在多种推理任务中的稳定性和可解释性的来源。", "conclusion": "Hecto 确立了自己作为条件计算的新基准，提供了一种原理上专业化推理的框架，适用于低资源环境，其模型强度源于原理上的专业化。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23520", "html_url": "https://arxiv.org/abs/2506.23520", "title": "ChemActor: 使用生成数据增强化学合成动作的自动化提取", "title_en": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "authors": "Yu Zhang,Ruijie Yu,Jidong Tian,Feng Zhu,Jiapeng Liu,Xiaokang Yang,Yaohui Jin,Yanyan Xu", "background": "随着对机器人合成在有机化学领域中兴趣的增加，从文献中自动化提取化学程序变得至关重要。然而，这一任务仍然具有挑战性，因为化学语言的固有歧义性和开发可靠的人工标注协议所需的人力成本极高。因此，需要一种能够将未结构化的实验程序转换为结构化动作序列的方法，以解决数据分析不足和质量低下的问题。", "innovation": "该研究提出了一个无需大量手动标注数据的框架，利用大型语言模型（LLM）生成的数据进行化学执行者的训练。这项创新包括使用分布差异度量的数据选择模块与通用大语言模型结合，从而产生可由单个分子输入执行的动作序列。此外，还引入了一种新的多轮大语言模型圈审查指标，反映了模型对化学实验程序的高级理解和认知。通过反应到描述（R2D）和描述到动作（D2A）任务的广泛实验，ChemActor在基准模型的基础上取得了10%的性能提升，达到了最佳状态。", "conclusion": "ChemActor通过大语言模型生成数据增强了化学合成动作的自动化提取，在反应到描述和描述到动作任务上表现出色，比基线模型高出10%的性能，相关代码已公开。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2210.06230", "html_url": "https://arxiv.org/abs/2210.06230", "title": "基于Transformer变分自编码器的准符号语义几何", "title_en": "Quasi-symbolic Semantic Geometry over Transformer-based Variational AutoEncoder", "authors": "Yingji Zhang,Danilo S. Carvalho,André Freitas", "background": "形式/符号语义能够通过其局部化或组合性质提供句子表示的规范和固定的可控性和可解释性。本文探讨如何将这种性质引入当前的分布表示句子模型，以更好地控制和解释语言模型（LM）的语言生成过程", "innovation": "本文理论地将句子语义表示为语义角色-词内容特征的组合，并提出了形式语义几何。通过部署基于Transformer的变分自编码器并结合监督方法，将这种几何结构注入到基于Transformer的语言模型（如GPT2）中。此外，提出了一种新的探测算法来引导句子向量在该几何结构上的移动。实验结果表明，形式语义几何可以提供更好的句子生成调控和解释能力", "conclusion": "实验结果表明，形式语义几何能够潜在地提高句子生成的可控性和解释性"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.03302", "html_url": "https://arxiv.org/abs/2401.03302", "title": "实操中的现实：基于YOLOv8和DeiT的医疗图像中脑肿瘤的异常感知诊断", "title_en": "Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT", "authors": "Seyed Mohammad Hossein Hashemi,Leila Safari,Mohsen Hooshmand,Amirhossein Dadashzadeh Taromi", "background": "可靠的脑肿瘤诊断仍然具有挑战性，因为这类病例的临床发生率较低。然而，大多数提出的算法忽视了这一事实。现有的方法并未充分考虑到数据中肿瘤与正常组织的现实不平衡比例。该研究提出了一个临床启发的框架，用于异常鲁棒的肿瘤检测与分类，旨在更好地适应临床实际场景的不平衡数据分布特点。", "innovation": "研究通过使用YOLOv8n对现实不平衡数据集(1:9的肿瘤与正常组织比例，来自81位患者的30,000个MRI切片)进行微调，首次实现了异常感知的脑肿瘤诊断。此外，提出了患者间(Patient-to-Patient, PTP)的新评价指标，从效率更高的ResNet152教师网络知识迁移到Data Efficient Image Transformer (DeiT)学生模型，使得后者在短短20个训练周期内获得F1得分为0.92，性能媲美教师网络(0.97)，且大幅度降低了计算资源消耗。", "conclusion": "该端到端的诊断框架在临床代表性异常分布数据上展示了高鲁棒性，提供了一个符合临床环境实际情况的实用工具。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.10248", "html_url": "https://arxiv.org/abs/2311.10248", "title": "识别全局模型的真实情况：一种抵御联邦学习中拜占庭和后门攻击的通用解决方案", "title_en": "Identifying the Truth of Global Model: A Generic Solution to Defend Against Byzantine and Backdoor Attacks in Federated Learning (full version)", "authors": "Sheldon C. Ebron,Meiying Zhang,Kan Yang", "background": "联邦学习允许多个参与者在不共享原始训练数据的情况下协作训练机器学习模型。然而，联邦学习的特性使得恶意客户端可以通过注入错误的模型更新来影响训练模型，进行拜占庭或后门攻击。传统的方法是通过测量每个模型更新与“真实模型更新”之间的距离来检测恶意模型更新。现有的防御方法要么需要服务器上的良性根数据集（例如FLTrust），要么仅使用trimmed mean或median作为阈值来剪枝（例如FLAME）。但是，良性根数据集是不切实际的，trimmed mean或median也可能消除来自这些被低估的数据集的贡献。因此，该领域需要一种无需依赖良性根数据集的通用解决方案来抵御模型中毒攻击。", "innovation": "FedTruth是一种通用解决方案，旨在抵御联邦学习中的模型中毒攻击。它通过对所有模型更新进行动态聚合权重估计“真实模型更新”（即全局模型更新），从而不依赖于特定的良性或恶意数据分布假设或良性根数据集的访问。FedTruth考虑了所有良性客户端的潜在贡献，并通过实验证明了其在大规模联邦学习系统的高效性以及对抗拜占庭和后门攻击的效果。", "conclusion": "FedTruth能够减少对抗拜占庭和后门攻击的攻击影响，并在大规模联邦学习系统中表现出高效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.04370", "html_url": "https://arxiv.org/abs/2406.04370", "title": "通过黑盒访问的大语言模型置信度估计", "title_en": "Large Language Model Confidence Estimation via Black-Box Access", "authors": "Tejaswini Pedapati,Amit Dhurandhar,Soumya Ghosh,Soham Dan,Prasanna Sattigeri", "background": "在评估信任时，不仅模型的响应本身，对其响应的信心度评估也非常重要。本文探讨了仅通过黑盒或查询方式访问大型语言模型（LLM）响应以估计置信度的问题。目前尚未有简单且易于扩展的框架来解决该问题。通过此研究，旨在提高模型在多种任务上的置信度评估准确性，并提供具有解释性的洞察，以便理解置信度的预测特征。", "innovation": "本文提出了一种简单且扩展性强的框架，通过工程化新型特征并使用解释性模型（如逻辑回归）训练这些特征来估计置信度。该框架在多种基准任务中表现优异，尤其在部分情况下超过了基线10%以上（基于AUROC指标）。此外，该可解释的方法提供了对置信度预测特征的洞察，使针对一种LLM构建的置信模型能够在给定的数据集上零样本推广到其他LLM上，这是一项有趣且有用的发现。", "conclusion": "通过简单的框架，本研究有效估计了Flan-ul2、Llama-13b、Mistral-7b和GPT-4等模型在四种问答任务上的置信度，以及Pegasus-large和BART-large在两种摘要任务上的置信度。该方法不仅提高了模型在多种任务中的置信度评估准确性，而且提供了有价值和有意义的解释性发现，这些发现有助于理解和改进大语言模型的使用。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.09158", "html_url": "https://arxiv.org/abs/2404.09158", "title": "StreakNet-Arch：一种针对海洋载波激光雷达-雷达成像的抗散射网络架构", "title_en": "StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging", "authors": "Xuelong Li,Hongjun An,Haofei Zhao,Guangying Li,Bo Liu,Xing Wang,Guanghua Cheng,Guojun Wu,Zhe Sun", "background": "在海洋水下环境中，由于海水的散射效应，传统的成像技术难以获得高精度的水下图像。为了克服这一问题，研究人员开发了基于自开发的海水载波激光雷达-雷达 (UCLR) 的实时端到端二分类框架，旨在提高水下成像的散射抑制能力。通过使用自注意力机制和一种新型的双分支交叉注意力机制（Double Branch Cross Attention，简称DBC-Attention），该框架在控制水槽验证条件下表现出色，与传统的带通滤波相比取得了更高的F1分数，在可比的模型大小和复杂度下优于基于学习的MP网络和CNNs。", "innovation": "该研究创新性地提出了一种基于自开发的UCLR的技术架构，引入了双分支交叉注意力机制（DBC-Attention），并将其应用于水下成像中。这项研究还验证了该UCLR系统的实际效果，在南中国海的实地试验中，达到了1000米深度和20米范围内的水下目标3D绘图误差为46毫米，显示了该方法的有效性和实用性。此外，该研究还提供了一个公开的数据集，包含2,695,168个真实水下3D点云数据，以促进进一步的研究。", "conclusion": "StreakNet-Arch架构通过使用自我注意力和新型双分支交叉注意力机制，在水下成像中实现了优越的散射抑制效果。通过实验验证，该方法不仅在水槽实验中表现出色，还展现了实际应用中的高精度。同时，该研究提供了公开的数据集和源代码，为未来的科研工作奠定基础。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.12446", "html_url": "https://arxiv.org/abs/2409.12446", "title": "神经网络在低复杂度数据上具有泛化能力", "title_en": "Neural Networks Generalize on Low Complexity Data", "authors": "Sourav Chatterjee,Timothy Sudijono", "background": "本研究探讨了使用ReLU激活函数的前向神经网络在处理低复杂度数据时的泛化能力。文章基于独立同分布的数据生成机制，引入了简单编程语言的概念，并定义了相应的神经网络描述长度。研究者给出了多个基本计算任务的例子，如判断自然数是否为素数。研究表明，对于从1到N之间均匀随机抽取的n个数，构建的插值MDL网络可以准确地判断一个新抽取的数字是否为素数，错误概率为$1- O(\frac{(\text{ln} N}{n})}$，并且网络并非为检测素数设计，而是通过最小描述学习自发发现了具有该功能的网络。此外，该研究也讨论了在噪声数据上的应用，表明MDL神经网络插值器能够展示适度的过拟合现象。", "innovation": "研究引入了简单编程语言的概念和相应的描述长度定义，证明了对于独立同分布的数据生成机制，MDL前向神经网络可以高概率泛化。文章还探讨了在噪声数据下的应用，进一步展示了MDL神经网络在处理复杂数据时的泛化潜力。", "conclusion": "研究结果表明，MDL前向神经网络在低复杂度数据上具有良好的泛化能力，特别是在插值任务中可以准确判断未见数据的属性。此外，即使在网络设计上不特意针对某些特定任务时，通过最小描述学习也可以发现具有该任务处理能力的网络。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.01141", "html_url": "https://arxiv.org/abs/2410.01141", "title": "使用NLP和LLMs基于语义相似性评估经济研究论文标题去重技术", "title_en": "Evaluating Deduplication Techniques for Economic Research Paper Titles with a Focus on Semantic Similarity using NLP and LLMs", "authors": "Doohee You,S Fraiberger", "background": "该研究探讨了大规模NLP数据集中文献标题高效去重的方法。现有研究主要利用Levenshtein距离、余弦相似度等距离度量方法和sBERT模型进行语义评估。然而，大量重复标题的存在可能导致资源浪费和信息冗余，因此亟需有效的方法来识别和去除这些重复标题。", "innovation": "研究创新地采用多种配对方法和语义评估模型，全面分析标题间的语义相似性，提出了新的去重策略，并通过人工标注的对照集进一步验证了其有效性。这种方法不仅提高了去重的准确性，还增强了在大规模数据集上的适用性。", "conclusion": "研究结果表明，基于观察到的不同方法之间的语义相似性，可能重复的文献标题比例较低。进一步的人工标注对照集评估支持了这一发现，并且与基于NLP和LLMs的距离度量结果相符。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.09111", "html_url": "https://arxiv.org/abs/2409.09111", "title": "源自扩散的Transformer：一种统一的神经消息传递框架", "title_en": "Transformers from Diffusion: A Unified Framework for Neural Message Passing", "authors": "Qitian Wu,David Wipf,Junchi Yan", "background": "学习具有特定几何结构（例如观测到的或未观测到的）的结构化数据的表示是一项基本挑战，现有的常用模型解决方案包括消息传递神经网络（MPNNs）。本文受到物理系统的启发，提出了一种能量约束扩散模型，该模型结合了几何扩散的归纳偏置和逐层的能量最小化约束。通过这一框架，可以统一多种常见神经架构的计算流程，包括各种类型的MPNNs、MLPs、GNNs和Transformers。", "innovation": "本文创新地提出了一种能量约束扩散模型，从能量传递理论角度统一了消息传递神经网络等多种不同类型的学习模型，并基于此框架开发了一类新的神经消息传递模型，命名为扩散启发式Transformer（DIFFormer），该模型的应用范围广泛，包括现实世界的网络、图像、文本以及物理粒子等不同类型的结构化数据。", "conclusion": "在多种不同的数据集上进行实验表明，新的模型在数据结构观测、部分观测或完全未观测的情景下均表现出了良好的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.24119", "html_url": "https://arxiv.org/abs/2506.24119", "title": "SPIRAL: 自零和博弈的自我游戏激励多轮多智能体强化学习中的推理", "title_en": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "authors": "Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques", "background": "最近的强化学习进展表明，语言模型可以通过训练于具有可验证奖励的任务中发展出复杂的推理能力，但这些方法依赖于人工标识的问题-答案对以及特定领域的奖励工程。研究引入了SPIRAL（自我游戏框架），通过模型相互自我游戏学习，避免了人工监督的需要。自我游戏中，SPIRAL生成了一个无穷的课程，随着模型必须不断适应更强的对手，问题逐渐变得更具挑战性。为了实现大规模的自我游戏训练，研究实施了一个全自动、多轮、多智能体强化学习系统，并提出了基于角色的优势估计（RAE）方法来稳定多智能体训练。通过SPIRAL，一对一零和博弈中的自我游戏能够产生广泛可迁移的推理能力，单独训练Qwen3-4B-Base在Kuhn扑克中就实现了数学推理提升8.6%和一般推理提升8.4%，优于在25000条专家游戏轨迹上的自我演示（SFT）训练。研究分析表明，这种迁移通过三种认知模式实现：系统分解、期望价值计算和案例分析。多游戏训练（井字游戏、Kuhn扑克、简单谈判）进一步提高了性能，因为每个游戏都发展出独有的推理优点。将SPIRAL应用于强大的推理模型（DeepSeek-R1-Distill-Qwen-7B）也能带来2.0%的平均性能提升，表明零和博弈自然地发展了可迁移的推理能力，这一方向为自主推理的发展指明了一种有希望的途径。", "innovation": "SPIRAL是一个自我游戏框架，使模型通过自我游戏学习多轮、多智能体强化学习，无需人工监督。它通过公开无穷的课程并通过与不断改进版本的自我游戏来提升推理能力。SPIRAL实现了全自动、多轮、多智能体强化学习系统，并提出了基于角色的优势估计方法（RAE）来稳定多智能体训练，从而提高多智能体强化学习的稳定性。自我游戏使模型能够在面对更强的对手时不断适应，从而训练出具有广泛可迁移推理能力的模型。", "conclusion": "零和博弈在SPIRAL框架下自然地发展出广泛的可迁移推理能力，证明了这一方法在自主推理开发中的潜力。通过实现SPIRAL和优化自我游戏学习方法，研究人员展示了通过自我游戏能够有效提高语言模型的推理能力和泛化能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.01020", "html_url": "https://arxiv.org/abs/2402.01020", "title": "通过 ologs 和 wiring diagrams 度量概念的类比", "title_en": "Quantifying analogy of concepts via ologs and wiring diagrams", "authors": "Jason Lo", "background": "本文基于 Spivak 和 Kent 创建的本体日志 (ologs) 理论，定义了一种连线图的概念。连线图被定义为有向带标号图，标号对应于 olog 中的类型，也可以被视为自主系统中传感器的读数。因此，连线图可以作为自主系统形成抽象概念的框架。背景信息还包括ikit 如何利用图论和范畴论中的技术来比较和操作连线图骨架，并通过仅对连线图可用的操作扩展图编辑距离的通常定义，得出所有骨架连线图的度量集。", "innovation": "创新在于采用了 olog 和连线图来分析和比较自主系统中概念的抽象表示，并通过图论和范畴论的结合提供了一种新的度量方法，定义了骨架连线图的范畴结构，以及扩展了图编辑距离的概念，适用于连线图，为比较和处理骨架连线图提供了新的手段。此外，通过给出的例子说明了如何利用该框架应用于任何应用领域。", "conclusion": "结论是提出了通过看待概念为连线图来度量概念之间类比的新方法，并展示了这种方法在自主系统中的应用潜力，同时也提供了如何将这种方法应用于更多实际领域的方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2302.14368", "html_url": "https://arxiv.org/abs/2302.14368", "title": "通过特征解耦和增强现实采样方法提升扩散模型的可控性", "title_en": "Enhanced Controllability of Diffusion Models via Feature Disentanglement and Realism-Enhanced Sampling Methods", "authors": "Wonwoong Cho,Hareesh Ravi,Midhun Harikumar,Vinh Khuc,Krishna Kumar Singh,Jingwan Lu,David I. Inouye,Ajinkya Kale", "background": "扩散模型已经展示了良好的性能，研究人员不断尝试提高扩散模型的可控性。但是，在训练扩散模型获得解耦的潜在空间以及在采样过程中自然地结合解耦的条件方面，研究仍然不足。该研究提出了用于特征解耦的扩散模型训练框架（FDiff），并提出了一种采样方法来提升模型的逼真度和可控性。研究通过条件置信散度细化扩散模型（GCDM）和时间步骤依赖性加权调度来提升模型表现和控制力。实验观察到对比现有方法，本研究的方法在图像操作和图像翻译中表现出更好的可控性", "innovation": "该研究提出了一种用于特征解耦的扩散模型训练框架（FDiff），并通过条件置信散度细化扩散模型（GCDM）和时间步长依赖性加权调度来提升扩散模型性能。这种方法通过对两种潜在特征、空间内容掩码和展平的样式嵌入进行条件训练，依赖于解噪过程的归纳偏差，将姿态/布局信息编码在内容特征中，将语义/风格信息编码在样式特征中。采样方法包括条件置信散度细化扩散模型（GCDM）和时间步骤依赖性加权调度，以进一步提高生成的逼真度和控制能力。", "conclusion": "通过提出FDiff框架和采用GCDM方法及时间步骤加权调度，该研究在图像操作和图像翻译任务中提升了扩散模型的可控性和真实感，提供了新颖且有效的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04946", "html_url": "https://arxiv.org/abs/2411.04946", "title": "SPGD：最陡扰动梯度下降优化", "title_en": "SPGD: Steepest Perturbed Gradient Descent Optimization", "authors": "Amir M. Vahedi,Horea T. Ilies", "background": "优化算法在多个科学和工业领域中起着关键作用，但常常会遇到诸如陷于局部极小值、鞍点和平坦区域等障碍，使收敛到合理的或接近最优解变得格外困难。", "innovation": "该论文提出了最陡扰动梯度下降（SPGD）算法，通过将梯度下降法原理与周期性的均匀扰动抽样相结合，创新地设计了一种生成候选解集并选择与当前解相比损失差异最大的解的方法。SPGD不仅保留了梯度下降法的有针对性的高效性，还利用了随机扰动的探索优点，从而在不同问题空间中能够更全面地搜索全局最优解。", "conclusion": "SPGD在解决3D组件包装问题上的应用显示出显著的效果，特别是在复杂的响应表面和多维非凸连续优化问题上超越了四种现有方法。与现有的二维基准函数相比，SPGD表现出更优异的性能，展示了其在复杂优化景观中的导航能力。这些结果表明，SPGD具有广泛优化问题的多功能潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.10747", "html_url": "https://arxiv.org/abs/2402.10747", "title": "完全差分拉格朗日卷积神经网络及其在物理驱动降水_nowcasting中的应用", "title_en": "Fully Differentiable Lagrangian Convolutional Neural Network for Physics-Informed Precipitation Nowcasting", "authors": "Peter Pavlík,Martin Výboh,Anna Bou Ezzeddine,Viera Rozinajová", "background": "本文提出了一种结合数据驱动学习与物理驱动领域知识的卷积神经网络模型，用于降水_nowcasting。现有方法多基于外推，本文则在此基础上提出了LUPIN模型，这是一种动力学双U-Net，具备完全可微和GPU加速的特点，能够在整个流程中进行端到端的训练和推断。在这过程中，模型能动态生成中尺度运动场，使用可微分的半拉格朗日外推算子，并捕捉降水随时间的变化。通过与现有其他基于AI的模型进行定量和定性的比较，在极端天气事件案例研究中，展示了LUPIN模型的优越性能，其在某些方面甚至超过了基准模型。", "innovation": "1. 提出了LUPIN模型，即拉格朗日双U-Net，结合了数据驱动和物理驱动的知识。\n2. 该模型可以在完全可微和GPU加速环境中进行端到端的训练和推断，特别是实时数据驱动的拉格朗日坐标变换。\n3. 使用半拉格朗日外推算子和无流场U-Net共同作用，有效捕捉降水随时间的变化。", "conclusion": "通过对模型的评估，在极端天气事件案例中，LUPIN模型的表现与选择的基准模型相当甚至更优。此工作为进一步发展拉格朗日机器学习模型开辟了新的可能性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04403", "html_url": "https://arxiv.org/abs/2411.04403", "title": "为无推理高效的稀疏检索模型实现竞争力的搜索相关性", "title_en": "Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers", "authors": "Zhichao Geng,Yiwen Wang,Dongyu Ru,Yang Yang", "background": "近年来，通过成熟的倒排索引引擎进行高效检索的所学稀疏检索引起了广泛关注。特别是，无推理的稀疏检索模型因其在检索过程中避免了在线模型推理从而节省大量计算成本，提供合理吞吐量和延迟而备受青睐。然而，即使是最先进的无推理稀疏模型在搜索相关性上也远远落后于稀疏和密集的Siamese模型。因此，提高无推理稀疏检索模型的搜索相关性成为一个重要的研究方向，需要专门的训练方法，而非使用与Siamese编码器相同的训练方法。", "innovation": "本文提出了两种不同的方法来提高性能。首先，提出了一种IDF意识的惩罚用于匹配函数，抑制低IDF词的贡献并增加模型对有信息意义短语的关注。此外，提出了一个异构集成知识蒸馏框架，结合了密集型和稀疏型Siamese检索器，在预训练阶段生成监督信号。这种框架利用了两种检索器的优势，为知识蒸馏提供了强有力的上界。为了达成不同监督模型的多样性反馈，我们对教师模型的输出进行归一化和聚合，消除得分尺度差异。在BEIR基准测试中，我们的模型显著优于目前最先进的无推理稀疏模型，NDCG@10得分提高了3.3。其搜索相关性与Siamese稀疏检索器相当，客户端延迟仅为BM25的1.1倍。", "conclusion": "我们的方法在无推理的稀疏检索模型中实现了竞争力的搜索相关性。我们提出的IDF意识惩罚和异构集成知识蒸馏框架显著提升了模型性能，同时控制了无推理检索模型的计算成本，展示了搜索相关性和客户端延迟的优势。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.02277", "html_url": "https://arxiv.org/abs/2310.02277", "title": "Junk DNA Hypothesis: Pruning Small Pre-Trained Weights Irreversibly and Monotonically Impairs 'Difficult' Downstream Tasks in LLMs", "title_en": "Junk DNA Hypothesis: Pruning Small Pre-Trained Weights Irreversibly and Monotonically Impairs \"Difficult\" Downstream Tasks in LLMs", "authors": "Lu Yin,Ajay Jaiswal,Shiwei Liu,Souvik Kundu,Zhangyang Wang", "background": "长期以来，人们认为大型语言模型（LLMs）中的权重包含大量的冗余，因此可以对预训练权重进行剪枝以减少参数量而不影响性能。然而，这篇论文提出了一个相反的观点，即预训练模型中具有小幅度值的权重包含了对处理困难的下游任务至关重要的知识，特别是在进行大量剪枝时，性能下降遵循着单调关系。并且，这些看似无关紧要的权重即使在允许下游持续训练的情况下，其剪枝也会导致知识的不可逆损失和性能下降。另外，量化压缩未能展示这种单调效应，也不能明确分离这些任务难度信息。论文通过引入几个量化指标来测量下游任务的难度，支持了这一假设，并在不同的模型大小、任务类别、数据集及剪枝方法下验证了该结论。", "innovation": "论文提出了新视角来处理大型语言模型的预训练权重，即引入Junk DNA Hypothesis。这与传统观点截然相反，认为即使是微不足道的权重也包含关键知识，尤其是在处理困难任务时。此外，通过提出若干量化指标并进行深入研究，论文证明了剪枝带来的性能下降是单调且不可逆的，而量化压缩则不能有效分离任务难度信息，进一步支持了这一假设的创新性。", "conclusion": "论文通过广泛的实验，证实了Junk DNA Hypothesis在不同模型规模、任务类型、数据集及剪枝方法下的有效性，证明了即使在允许下游持续训练的情况下，剪枝也会导致性能的不可逆单调下降。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10736", "html_url": "https://arxiv.org/abs/2501.10736", "title": "基于多尺度不确定性一致性和跨教师-学生注意力的遥感图像半监督语义分割", "title_en": "Semi-supervised Semantic Segmentation for Remote Sensing Images via Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention", "authors": "Shanwen Wang,Xin Sun,Changrui Chen,Danfeng Hong,Jungong Han", "background": "半监督学习为解决遥感（RS）图像分割中的像素级标注劳动密集型问题提供了有吸引力的解决方案。然而，RS图像具有丰富的多尺度特征和高类间相似性，这构成了独特的挑战。为了解决这些问题，本文提出了一个多尺度不确定性一致性及跨教师-学生注意力（MUCA）模型，以应对RS图像语义分割任务中的半监督学习问题。", "innovation": "MUCA通过引入多尺度不确定性一致性正则化，限制了网络不同层特征图之间的一致性，从而提升了半监督算法在无标签数据上的多尺度学习能力。此外，模型利用跨教师-学生注意力机制引导学生网络，通过教师网络提供的补充特征构建更具判别性的特征表示，从而加强分割性能。该设计有效整合了弱增强和强增强，进一步提升了分割效果。", "conclusion": "通过对ISPRS-Potsdam和LoveDA数据集的广泛实验验证，结果显示，本文方法在半监督领域优于现有的最先进方法。特别是在区分高度相似的物体方面，模型表现优异，展示了其在半监督RS图像分割任务中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13094", "html_url": "https://arxiv.org/abs/2501.13094", "title": "通过对比去噪的稳健表示一致性模型", "title_en": "Robust Representation Consistency Model via Contrastive Denoising", "authors": "Jiachen Lei,Julius Berner,Jiongxiao Wang,Zhongzhu Chen,Zhongjia Ba,Kui Ren,Jun Zhu,Anima Anandkumar", "background": "深度神经网络的稳健性在安全敏感的应用中至关重要。因此，随机化平滑为对抗噪声提供理论保证，但在处理大规模扰动和相比传统方法在推理时引入了大量计算开销。已有方法在较小扰动半径上表现良好，但在较大扰动半径上表现不佳。本文基于这一点背景，提出了一种新方法，将生成建模任务重新表述为沿像素空间扩散轨迹的判别任务，并通过实例判别实现一致表示，从而大幅降低推理成本并达到最先进性能。", "innovation": "本文创新地将生成建模任务转化为沿扩散轨迹的判别任务，采用实例判别确保轨迹上点的一致性表示。通过受益于学习到的表示进行微调，开发出隐式的去噪-分类机制，仅通过一个预测即可实现，极大地减少了推理成本。在多种数据集上进行的实验显示，本文方法在所有扰动半径上比基于扩散的方法平均提高了5.3%的认证精度，且对于较大扰动最高提高11.6%，同时推理成本降低了85倍。", "conclusion": "通过对比去噪的稳健表示一致性模型在处理大扰动时表现优异，并通过减少计算成本达到了最先进的认证精度。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12787", "html_url": "https://arxiv.org/abs/2411.12787", "title": "从整体到局部：提高视觉指令微调效率的局部增强适配器", "title_en": "From Holistic to Localized: Local Enhanced Adapters for Efficient Visual Instruction Fine-Tuning", "authors": "Pengkun Jiao,Bin Zhu,Jingjing Chen,Chong-Wah Ngo,Yu-Gang Jiang", "background": "EVIT寻求以最小的计算开销将多模态大型语言模型适配到下游任务中，但随着任务多样性和复杂性的增加，EVIT在解决数据冲突方面面临重大挑战。", "innovation": "提出了一种全方位到局部的框架Dual Low-Rank Adaptation (Dual-LoRA)，通过双重结构优化增强适配器处理数据冲突的能力。此外，还引入了视觉提示增强(VCE)，这是一种多级局部特征聚合模块，旨在丰富视觉-语言投影的局部细节。该方法在内存和时间效率上表现良好，仅需要标准LoRA方法的1.16倍推理时间，并且只有4专家LoRA-MoE推理时间的73%。", "conclusion": "在各种下游任务和通用多模态语言模型基准上的广泛实验验证了我们所提出方法的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.02144", "html_url": "https://arxiv.org/abs/2501.02144", "title": "建立生成性发现无机晶体的基线", "title_en": "Establishing baselines for generative discovery of inorganic crystals", "authors": "Nathan J. Szymanski,Christopher J. Bartel", "background": "生成型人工智能为材料发现提供了有希望的途径，但其相对于传统方法的优势尚未明确。本文通过引入并对比两种基线方法——电荷平衡原型的随机枚举和已知化合物的离子交换法——与四种生成技术（基于扩散模型、变分自编码器和大规模语言模型）进行了基准测试。结果显示，传统方法如离子交换在生成新颖且稳定的材料方面表现更优，但这些新材料往往与已知化合物相似。相比之下，生成模型则在提出新颖的结构框架方面表现出色，且在其训练数据充足的情况下，更能准确地针对电带隙和体模量等材料特性。为了提高基线和生成方法的性能，本文实施了在生成后筛选的步骤，将所有提议的结构都通过预训练的机器学习模型进行稳定性和属性筛选，这些模型包括普遍原子势。这种低成本的筛选步骤显著提高了所有方法的成功率，保持了计算效率，并为材料发现中生成策略的有效利用提供了一条实际路径。", "innovation": "本文引入并比较了两种基线方法和四种生成技术，通过实验证明了生成模型在提出新颖结构框架方面优于传统方法，并提出了生成后结构筛选的方法来提高表现。这种方法不仅提高了材料发现的成功率，还实现计算效率的有效性，为生成模型的发展提供了方向，特别是在针对热力学稳定的新材料生成方面。", "conclusion": "本文通过建立基线对于生成方法进行了比较，强调了生成模型的提升空间，尤其是对于热力学稳定的新材料生成。这为材料科学中的生成模型应用提供了实用路径。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.18241", "html_url": "https://arxiv.org/abs/2412.18241", "title": "基于大型语言模型的推荐系统自动生成图结构框架", "title_en": "An Automatic Graph Construction Framework based on Large Language Models for Recommendation", "authors": "Rong Shan,Jianghao Lin,Chenxu Zhu,Bo Chen,Menghui Zhu,Kangning Zhang,Jieming Zhu,Ruiming Tang,Yong Yu,Weinan Zhang", "background": "图神经网络（GNNs）已成为从图结构数据进行推荐的最新方法。现有基于GNN的推荐方法主要集中在模型结构和基于预定义图的学习策略优化上，忽略了图构建阶段的重要性。早期的图构建工作通常依赖于特定规则或众包，这要么过于简单，要么过于耗时。最近的工作开始利用大型语言模型（LLMs）来自动化图构建，鉴于它们丰富的开放世界知识和卓越的推理能力。然而，这些方法通常存在两个局限性：（1）缺乏全局视角（例如忽视上下文信息）；（2）构建效率低下。", "innovation": "我们提出了基于LLMs的自动生成图结构框架AutoGraph。利用LLMs推断用户偏好和物品知识，并将其编码为语义向量。通过向量化提取潜在因素，并将其作为额外节点嵌入到用户/物品节点中，构建出具有丰富全局视角的图结构。此外，设计基于元路径的消息聚合方法，以有效聚合语义和协同信息。该框架具有模型无关性，兼容不同骨干模型。实验结果显示，AutoGraph在三组真实世界数据集上比现有基线方法更有效率。在华为广告平台上进行的在线A/B测试中，AutoGraph取得了2.69%的RPM提升和7.31%的eCPM提升，目前它是主要的地图模型，服务于数亿人。", "conclusion": "实验结果表明，AutoGraph在真实世界数据集上具有优于现有基线方法的有效性和效率，并实际部署在华为广告平台中，取得了显著的效果提升。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04388", "html_url": "https://arxiv.org/abs/2502.04388", "title": "新兴智人呼唤多智能体范式再思考", "title_en": "Position: Emergent Machina Sapiens Urge Rethinking Multi-Agent Paradigms", "authors": "Hepeng Li,Yuhong Liu,Jun Yan,Jie Gao,Xiaoou Yang", "background": "人工智能（AI）代理具有自主学习和独立决策的能力，在交通、能源系统和制造业等多个关键基础设施领域具有巨大潜力。然而，由具有不同且未对齐目标的多方推动设计和部署的AI系统的激增，带来了关键挑战：如何在共享环境中使这些不协调的AI系统和谐共存并共同发展，而不引发混乱或影响安全？", "innovation": "提出对现有基于多智能体系统的框架进行根本性重新思考，如多智能体系统和博弈论，这些框架大多局限于预定义的规则和静态的目标结构。建议AI代理能够在动态调整目标、进行妥协、建立联盟，并通过不断演变的关系和社交反馈进行安全的竞争或合作。通过两个关键基础设施应用案例研究，呼吁向这些多智能体AI系统的涌现性、自我组织性和情境意识性转变。", "conclusion": "强调多智能体AI系统的变革性变化，以实现智能体间合作与竞争的动态平衡，从而应对共享环境中不协调的问题。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.09310", "html_url": "https://arxiv.org/abs/2501.09310", "title": "基于上下文学习的文本到SQL错误研究", "title_en": "A Study of In-Context-Learning-Based Text-to-SQL Errors", "authors": "Jiawei Shen,Chengcheng Wan,Ruoyi Qiao,Jiazhen Zou,Hang Xu,Yuchen Shao,Yueling Zhang,Weikai Miao,Geguang Pu", "background": "大语言模型已经应用于文本到SQL任务，利用其上下文学习能力将自然语言问题转化为结构化查询语言。然而，这种技术面临正确性问题，需要高效的修复解决方案。本文是首个全面研究文本到SQL错误的研究。研究涵盖四种代表性上下文学习方法、五种基本修复方法、两个基准和两种模型设置，发现文本到SQL错误普遍存在，总结了7类29种错误类型。现有修复尝试提升了正确性，但代价是大量的计算开销和频繁的误修复。", "innovation": "本研究提出了MapleRepair，这是一种新颖的文本到SQL错误检测和修复框架。评估结果表明，MapleRepair通过避免误修复13.8%并减少67.4%的计算开销，在现有解决方案中表现更优，从而显著提升了修复效率和正确性。", "conclusion": "文章通过全面研究文本到SQL错误，提出了MapleRepair框架，该框架能够在相对较少的计算开销下有效修复更多的查询，显著提升了修复质量。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.03628", "html_url": "https://arxiv.org/abs/2502.03628", "title": "通过视觉信息引导减少大型跨模态模型幻觉的令牌幕后生活", "title_en": "The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering", "authors": "Zhuowei Li,Haizhou Shi,Yunhe Gao,Di Liu,Zhenting Wang,Yuxiao Chen,Ting Liu,Long Zhao,Hao Wang,Dimitris N. Metaxas", "background": "大型视觉语言模型（LVLMs）能够有效地处理文本和视觉输入之间的关系，但在生成过程中，它们往往会生成句法上合理但缺乏视觉基础的内容。研究者通过在生成过程中检查令牌概率排序来探索这些幻觉的内部动态，并发现了三种关键模式：逐步视觉信息丢失，在生成过程中心理视觉接地的令牌逐渐变得不那么受欢迎；早期兴奋，在层中语义有意义的令牌在最终层之前达到峰值；隐藏的真实信息，尽管最终没有被解码，但视觉接地的令牌在推理中仍保留相对较高的排名。", "innovation": "研究提出了VISTA（视觉信息引导与令牌概率增强），这是一款无需额外训练的推理时干预框架，旨在减少幻觉并促进真实信息。VISTA通过结合两种互补的方法工作：在活性空间中增强视觉信息和利用早期层的激活来促进语义有意义的解码。与现有方法相比，VISTA无需外部监督，并适用于各种解码策略。广泛实验表明，VISTA在评估的开放生成任务中平均减少了幻觉约40%，并一致表现出优于现有方法的结果。", "conclusion": "VISTA通过减少幻觉并促进真实信息获取，在四种架构下三种解码策略的四个基准上取得了最优表现，显著降低了幻觉现象，验证了其有效的解决策略"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.13949", "html_url": "https://arxiv.org/abs/2411.13949", "title": "SMoLoRA：探索并克服持续视觉指令调整中的双重灾难性遗忘", "title_en": "SMoLoRA: Exploring and Defying Dual Catastrophic Forgetting in Continual Visual Instruction Tuning", "authors": "Ziqi Wang,Chang Che,Qi Wang,Yangyang Li,Zenglin Shi,Meng Wang", "background": "持续视觉指令调整（CVIT）有助于大规模语言模型（MLLMs）通过将视觉任务重新框定为语言指令来处理广泛的视觉任务。前人的工作主要通过开发新的基准和缩减灾难性遗忘的方法来推进CVIT，但这些努力主要遵循传统的持续学习框架，忽视了CVIT特有的挑战。研究发现CVIT中存在双重灾难性遗忘，模型不仅要遗忘之前学习的视觉理解，还随着新任务的获得而下降指令遵循能力。尽管之前的努力为CVIT提供了一些基础，但仍需更有效的解决方案来应对这一问题。", "innovation": "提出了分立低秩适应（SMoLoRA）框架，该框架通过两个独立模块分别处理视觉理解和指令遵循进行分离路由。这种双路由设计允许在两个领域进行专门的适应，防止遗忘并提高性能。此外，还提出了一个新基准，该基准不仅评估模型对未见过的任务的一般化能力，还评估处理各种任务中不同指令的能力。实验结果表明，SMoLoRA在减轻双重遗忘、提高对未见过任务的泛化能力和确保多样化指令跟随的鲁棒性方面优于现有方法。", "conclusion": "分立低秩适应（SMoLoRA）框架能够有效地解决CVIT中双重灾难性遗忘的问题，提高了对未见过的任务的一般化能力和对多种任务中变化指令的遵循能力。实验表明了该框架的有效性，并提供了原始代码供参考。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.09105", "html_url": "https://arxiv.org/abs/2411.09105", "title": "VideoCogQA：用于评估视频语言模型认知能力的可控基准", "title_en": "VideoCogQA: A Controllable Benchmark for Evaluating Cognitive Abilities in Video-Language Models", "authors": "Chenglin Li,Qianglong Chen,Zhi Li,Feng Tao,Yin Zhang", "background": "最新的大型视频-语言模型（LVLMs）在多模态视频理解上取得了有前景的结果，但尚不清楚这些模型是否具备完成高级任务所需的认知能力，特别是在涉及符号和抽象感知的任务方面。现有基准通常依赖于注明的现实世界视频，这些视频缺乏对视频内容和固有难度的控制，限制了它们的诊断能力。为解决这一问题，我们提出了VideoCogQA，一种基于游戏世界环境的可扩展和完全可控的基准，旨在评估LVLMs的认知能力。通过使用程序引擎生成合成视频，VideoCogQA能够对视觉元素、时间动态和任务难度进行细致的控制。这一方法允许对视频认知能力进行有针对性的评估，不依赖于来自视觉场景语义的先验知识。数据集包括800个视频和3280个问答对，涵盖了与抽象概念、符号元素和多模态整合相关的时间渐变任务，难度各异。实验结果显示，即使是最新模型如GPT-4o，在涉及抽象概念的任务上的平均性能为48.8%，任务复杂性增加时性能下降15%，凸显了LVLMs在保持一致性表现上的挑战。", "innovation": "VideoCogQA是一个基于游戏世界环境的可扩展和完全可控的新基准，通过程序化引擎生成的合成视频，提供了对视觉元素、时间动态和任务难度的精细控制。这使得能够对视频的认知能力进行有针对性的评估，而不需要依赖视觉场景语义的先验知识。", "conclusion": "实验结果表明，即使是最先进的模型如GPT-4o，在涉及抽象概念的任务上也只能达到48.8%的性能，任务复杂性增加时，性能降低了15%。通过这项工作，我们希望揭示当前LVLMs的局限性，并提供有关如何更有效地模拟人类认知过程的洞见。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.13030", "html_url": "https://arxiv.org/abs/2502.13030", "title": "通过似然比正则化进行高维协变量偏移下的约束推理", "title_en": "Conformal Inference under High-Dimensional Covariate Shifts via Likelihood-Ratio Regularization", "authors": "Sunay Joshi,Shayan Kiyani,George Pappas,Edgar Dobriban,Hamed Hassani", "background": "该论文探讨了在存在协变量偏移的情况下进行容错预测的问题。给定源域的带标签数据和目标域的无标签数据，目标是在目标域中构建具备有效边缘覆盖率的预测集。现有的大多数方法需要估算未知的似然比函数，这对于高维数据（如图像）来说可能是不可行的。", "innovation": "本文提出了一种新的方法——似然比正则化分位数回归（LR-QR）算法。该方法结合了pinball损失函数和新颖的正则化技术，从而可以构建阈值函数而无需直接估计未知的似然比函数。进一步，该方法证明在目标域内具有目标覆盖水平，误差可以控制。此外，通过学习理论中的新颖稳定性界分析方法，提供了关于覆盖概率的理论保证。实验结果表明，LR-QR算法在高维预测任务中表现出色，包括Communities and Crime数据集的回归任务、WILDS数据集的情感分类任务以及MMLU基准上的LLM问答任务。", "conclusion": "本文提出了一种新颖的方法LR-QR，该方法能够在高维数据存在的协变量偏移情况下，构建目标域中具有有效覆盖率的预测集，并且实验结果表明，该方法在多种高维任务中均表现出优越的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03040", "html_url": "https://arxiv.org/abs/2503.03040", "title": "SAGE: 未来的状态-行动增强以引导对话生成", "title_en": "SAGE: Steering Dialog Generation with Future-Aware State-Action Augmentation", "authors": "Yizhe Zhang,Navdeep Jaitly", "background": "近年来，大规模语言模型在任务导向的应用中表现出色，但构建能够进行自然、战略对话的情感智能聊天机器人仍然是一个挑战。本文分析了现有的语言模型在对话生成中存在的问题，尤其是在情感智能方面的不足，需要一种新的方法来控制长时间对话中的行为，提高对话质量。", "innovation": "本文提出了一种名为SAGE的新方法，通过引入潜在变量来控制对话生成中的长期行为，这些变量可以捕捉对话中的情感状态和策略。SAGE的核心是状态-行动链（SAC），它通过在每次响应生成之前引入潜在变量，使对话的进展具有粗粒度的控制，同时保持自然的交互模式。此外，还介绍了一种自我改进管道，利用对话树搜索、基于LLM的奖励建模和目标Fine-tuning来优化对话轨迹。实验结果表明，使用这种方法训练的模型在情感智能指标上表现优异，同时在大规模语言模型基准测试中保持了强大的能力。潜在变量的离散性质促进了搜索策略的应用，并为未来利用强化学习改进对话系统奠定了基础，学习可以在状态级别而非标记级别进行。", "conclusion": "通过引入潜在变量和状态-行动链，SAGE能够在对话生成中实现对长期行为的精细控制，并通过自我改进管道优化对话轨迹。实验表明其在情感智能和任务导向能力上的表现优异，为进一步利用强化学习提高对话系统提供了可能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.13536", "html_url": "https://arxiv.org/abs/2411.13536", "title": "3D Head Identity Preserving Stylization Using Multiview Score Distillation", "title_en": "Identity Preserving 3D Head Stylization with Multiview Score Distillation", "authors": "Bahri Batuhan Bilecen,Ahmet Berke Gokmen,Furkan Guzelant,Aysegul Dundar", "background": "3D头的风格化可以将现实中的面部特征转化为更具艺术感的表示形式，提升游戏和虚拟现实应用中的用户参与度。尽管3D感知生成器取得了显著进展，但许多3D风格化方法主要提供近乎正面视角的图像，难以保留原始主题的独特性。结果，生成的输出往往缺乏多样性和独特性。本研究通过利用PanoHead模型，从360度视角综合生成图像来应对这些挑战。同时还提出了一种基于负对数似然蒸馏（LD）的新框架，结合了多视角网格评分和镜像梯度在3D GAN架构中的应用，并引入了评分排名加权技术，从而实现了显著的质性和量化改善。这些发现不仅推进了3D头的风格化技术，还为扩散模型与GAN之间有效的蒸馏过程提供了宝贵见解，尤其关注身份保留这一关键问题。", "innovation": "提出了一种基于负对数似然蒸馏（LD）的新框架，结合了多视角网格评分和镜像梯度在3D GAN架构中的应用，以及评分排名加权技术，实现了显著的质性和量化改善。我们的方法不仅推进了3D头的风格化技术，还为扩散模型与GAN之间有效的蒸馏过程提供了宝贵见解，尤其关注身份保留这一关键问题。", "conclusion": "通过利用PanoHead模型和新框架，本研究解决了3D头风格化中的关键挑战，提供了更高质量的输出，特别是在身份保留方面取得了显著进步。此外，研究成果为进一步促进扩散模型和GAN之间的有效蒸馏过程提供了新的视角和技术参考。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.05795", "html_url": "https://arxiv.org/abs/2502.05795", "title": "大型语言模型中的深度诅咒", "title_en": "The Curse of Depth in Large Language Models", "authors": "Wenfang Sun,Xinyuan Song,Pengxiang Li,Lu Yin,Yefeng Zheng,Shiwei Liu", "background": "在这篇论文中，作者指出了一个称为“深度诅咒”的概念，它揭示并解释了现代大型语言模型（LLMs）中一个近期观察到的现象，即几乎所有一半的层效果低于预期。这种现象在Llama、Mistral、DeepSeek和Qwen等最流行的LLM家族中广泛存在。研究表明，导致深层层在LLM中效果不佳的根本原因是预层归一化（Pre-LN）的广泛使用。虽然Pre-LN稳定了Transformer LLMs的训练，但它的输出方差随模型深度呈指数增长，从而导致深层Transformer块的导数为单位矩阵，几乎没有对训练做出贡献。", "innovation": "为了解决这个问题，作者提出了层归一化缩放（LNS）方法，该方法通过按深度的平方根的倒数来缩放层归一化输出的方差。这个简单的修改降低了更深的Transformer层的输出方差爆炸，改善了它们的贡献。实验结果表明，无论是在130M到7B范围内的模型大小，LNS都优于之前的归一化和缩放技术，提高了LLM预训练性能，并平滑地应用到监督微调中。", "conclusion": "这项研究发现，层归一化缩放使深层层在训练过程中能更有效地做出贡献。作者提供的代码可以在以下链接找到： \texttt{this https URL}。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13504", "html_url": "https://arxiv.org/abs/2503.13504", "title": "CoCMT：通信高效的跨模态变换器在协同感知中的应用", "title_en": "CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception", "authors": "Rujia Wang,Xiangbo Gao,Hao Xiang,Runsheng Xu,Zhengzhong Tu", "background": "现有的多代理协作感知系统通过共享传感信息来提升每个代理的感知能力，并能有效应对传感器不足、遮挡和远距离感知等挑战。但这些系统通常会传输包含大量非关键信息的中间特征图，如鸟瞰图（BEV）表示，这导致了较高的通信带宽需求。因此，需要一种既能保持感知能力又能减少通信需求的方法来解决这一问题.", "innovation": "本文提出了CoCMT（基于对象查询的协作框架），通过选择性地提取和传输关键特征来优化通信带宽。CoCMT中引入了高效的查询变换器(EQFormer)，用于有效融合多代理对象查询，并实现协同的深层监督，以增强各阶段之间的正面强化，从而提高整体性能。实验结果表明，CoCMT在OPV2V和V2V4Real数据集上不仅性能超越了最先进的方法，还大幅降低了通信需求。例如，在V2V4Real数据集上，我们的模型（Top-50对象查询）仅需0.416 MB的带宽，比最先进的方法减少了83倍，同时AP70提高了1.1个百分点，实现了通信效率的突破，能够在带宽受限的环境中进行协作感知部署，而不牺牲检测精度.", "conclusion": "CoCMT利用基于对象查询的协作框架和高效的查询变换器，成功地在保持感知能力的同时，大幅减少了通信需求，为在带宽受限的环境中的协作感知部署提供了新的解决方案，并在多个数据集上取得了良好性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18549", "html_url": "https://arxiv.org/abs/2503.18549", "title": "RLCAD: 基于旋转操作的CAD命令序列生成的强化学习训练环境", "title_en": "RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation", "authors": "Xiaolong Yin,Xingyu Lu,Jiahang Shen,Jingzhe Ni,Hailong Li,Ruofeng Tong,Min Tang,Peng Du", "background": "在三维CAD系统中，CAD命令序列是一种典型的参数化设计范式，通过叠加2D草图来构造模型，使用诸如拉伸、旋转和布尔操作等操作。尽管自动生成命令序列的学术兴趣日益增长，现有的方法和数据集只支持2D草图绘制、拉伸和布尔操作等操作，这限制了复杂几何的表示能力。因此，本论文构建了一个基于CAD几何引擎的强化学习（RL）训练环境（gym），旨在生成B-Rep几何表示下的CAD命令序列，支持包括旋转操作在内的更广泛的几何操作。", "innovation": "本论文创新性地提出了一个基于CAD几何引擎的强化学习（RL）训练环境（gym），能够生成包括旋转操作在内的B-Rep几何表示下的CAD命令序列。通过该训练环境，算法能够根据输入的边界表示（B-Rep）几何生成相应的CAD几何，实现了生成命令序列质量上的先进水平（SOTA），突破了现有方法的局限性，提升了复杂几何建模的能力。", "conclusion": "通过构建基于CAD几何引擎的强化学习训练环境，本论文实现了优异的B-Rep几何表示下的CAD命令序列生成能力，突破了现有方法仅支持基础几何操作的局限，为复杂几何建模提供了新的解决方案，达到了生成命令序列的先进水平（SOTA）。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00949", "html_url": "https://arxiv.org/abs/2505.00949", "title": "Llama-Nemotron: 高效推理模型", "title_en": "Llama-Nemotron: Efficient Reasoning Models", "authors": "Akhiad Bercovich,Itay Levy,Izik Golan,Mohammad Dabbah,Ran El-Yaniv,Omri Puny,Ido Galil,Zach Moshe,Tomer Ronen,Najeeb Nabwani,Ido Shahaf,Oren Tropp,Ehud Karpas,Ran Zilberstein,Jiaqi Zeng,Soumye Singhal,Alexander Bukharin,Yian Zhang,Tugrul Konuk,Gerald Shen,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Yoshi Suhara,Olivier Delalleau,Zijia Chen,Zhilin Wang,David Mosallanezhad,Adi Renduchintala,Haifeng Qian,Dima Rekesh,Fei Jia,Somshubra Majumdar,Vahid Noroozi,Wasi Uddin Ahmad,Sean Narenthiran,Aleksander Ficek,Mehrzad Samadi,Jocelyn Huang,Siddhartha Jain,Igor Gitman,Ivan Moshkov,Wei Du,Shubham Toshniwal,George Armstrong,Branislav Kisacanin,Matvei Novikov,Daria Gitman,Evelina Bakhturina,Prasoon Varshney,Makesh Narsimhan,Jane Polak Scowcroft,John Kamalu,Dan Su,Kezhi Kong,Markus Kliegl,Rabeeh Karimi,Ying Lin,Sanjeev Satheesh,Jupinder Parmar,Pritam Gundecha,Brandon Norick,Joseph Jennings,Shrimai Prabhumoye,Syeda Nahida Akter,Mostofa Patwary,Abhinav Khattar,Deepak Narayanan,Roger Waleffe,Jimmy Zhang,Bor-Yiing Su,Guyue Huang,Terry Kong,Parth Chadha,Sahil Jain,Christine Harvey,Elad Segal,Jining Huang,Sergey Kashirsky,Robert McQueen,Izzy Putterman,George Lam,Arun Venkatesan,Sherry Wu,Vinh Nguyen,Manoj Kilaru,Andrew Wang,Anna Warno,Abhilash Somasamudramath,Sandip Bhaskar,Maka Dong,Nave Assaf,Shahar Mor,Omer Ullman Argov,Scot Junkin,Oleksandr Romanenko,Pedro Larroy,Monika Katariya,Marco Rovinelli,Viji Balas,Nicholas Edelman", "background": "介绍了Llama-Nemotron系列模型，这是一个开放源代码的异构推理模型家族，提供了卓越的推理能力、推理效率，并且具有企业使用的开放许可。该家族包含三种不同大小的模型——Nano（8B）、Super（49B）和Ultra（253B），并且与先进的推理模型如DeepSeek-R1表现相当，在推理吞吐量和内存效率方面表现更优。", "innovation": "1. 使用从Llama 3模型加速推理、知识蒸馏和持续前期训练得出的神经架构搜索方法。\n2. 引入了一种动态推理切换功能，允许用户在推理期间在标准聊天和推理模式之间切换。\n3. 为支持开放研究和促进模型开发提供了资源：Llama-Nemotron推理模型、完整后续培训数据集和训练代码库：NeMo、NeMo-Aligner和Megatron-LM。", "conclusion": "Llama-Nemotron模型是一系列公开源代码的高效推理模型，具有卓越的推理能力和开放企业使用权限。这些模型提供了高效的推理表现，以及在推理吞吐量和内存效率方面的优势，并且通过动态推理切换和丰富的资源支持来促进研究和模型开发。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02869", "html_url": "https://arxiv.org/abs/2502.02869", "title": "通过随机世界中的元训练实现大规模上下文强化学习", "title_en": "Towards Large-Scale In-Context Reinforcement Learning by Meta-Training in Randomized Worlds", "authors": "Fan Wang,Pengtao Shao,Yiming Zhang,Bo Yu,Shaoshan Liu,Ning Ding,Yang Cao,Yu Kang,Haifeng Wang", "background": "ICRL允许代理从交互经验中自动学习和实时学习，但规模化训练的瓶颈在于缺乏可扩展的任务集合。该研究通过设计可生成大规模高质量任务的AnyMDP方法来解决这个问题，同时控制结构偏见较低。此外，为促进大规模的元训练，提出了逐步监督和先验信息诱导的方法，以更好地适应ICRL的学习过程，这为大规模ICRL的训练和评估提供了可能。然而，ICRL的可扩展性可能会导致任务多样性的增加和适应时间的延长，这对未来的研究具有重要启示意义，强调了广泛且多样的任务设计的必要性，以及追求长期性能而非快速适应的重要性。", "innovation": "研究提出了AnyMDP，这是一种程序生成的表格马尔可夫决策过程，能够生成大规模高质量的任务并保持较低的结构偏见。引入了逐步监督和先验信息诱导的方法来辅助ICRL的学习过程，这有助于提高ICRL的能力，使其能够泛化到未培训的任务集中的任务。这为大规模ICRL的训练和评估提供了可能，并且通过AnyMDP提供的可扩展任务集，可以更深入地探讨数据分布与ICRL性能之间的关系，显示了ICRL泛化的潜在代价在于增加的任务多样性和更长的适应期。", "conclusion": "随着AnyMDP生成的足够大规模的任务，所提出的方法能够泛化到训练集中未考虑的任务。生成的大规模任务集不仅使ICRL的研究更加全面，还提示了ICRL的泛化可能伴随着任务多样性的增加和更长的适应期，因此强调了多样且广泛的任务设计的必要性，以及追求长期性能的重要性，而不仅仅是快速适应。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.07330", "html_url": "https://arxiv.org/abs/2503.07330", "title": "YOLO基于模型幻觉的缓解：重新审视分布外检测", "title_en": "Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection", "authors": "Weicheng He,Changshun Wu,Chih-Hong Cheng,Xiaowei Huang,Saddek Bensalem", "background": "在动态环境中，物体检测系统必须可靠地感知感兴趣的物体，但不能过于自信以确保安全决策。为了过滤由新型物体感知过度自信产生的幻觉，通常会基于分布外（OOD）检测技术添加额外的保护措施。然而，现有评估用的OOD数据集通常无法准确反映实际情况，导致评价结果不可靠。这会使YOLO家族检测器及其过滤器在现有OOD基准下的性能评定结果不尽如人意。", "innovation": "本文的研究发现了现有OOD数据集评估结果校准和OOD检测中幻觉减少的新方法。首先，重新校准了所有现有评估结果，发现现有OOD数据集中一些检测到的对象实际上是属于训练数据集定义的分布内类别的对象。其次，提出了一种方法来减少幻觉，即通过精心合成一个与要检测的对象语义上相似的OOD数据集，在YOLO检测器的微调中抑制对象得分，并实现了一个结合了微调检测和过滤系统的联合管道，在自动驾驶基准BDD-100K上将整体幻觉误差减少了88%。", "conclusion": "通过综合考虑校准OOD数据集评估结果和精心设计的OOD数据集来微调YOLO检测器，本文显著提高了YOLO家族检测器及其过滤器在OOD检测中的性能。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.21248", "html_url": "https://arxiv.org/abs/2503.21248", "title": "ResearchBench：通过基于灵感的任务分解评估大语言模型在科学发现中的表现", "title_en": "ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition", "authors": "Yujie Liu,Zonglin Yang,Tong Xie,Jinjie Ni,Ben Gao,Yuqiang Li,Shixiang Tang,Wanli Ouyang,Erik Cambria,Dongzhan Zhou", "background": "大型语言模型（LLMs）在辅助科学研究方面展现出潜力，但它们是否能够发现高质量的研究假设尚未得到专门基准的验证。由于缺乏专门的基准测试，这一能力尚未得到充分探索。为解决这一问题，本文介绍了首个面向大语言模型的基准测试，涵盖科学研究的关键子任务：灵感检索、假设构成和假设排序，并通过专家验证保证其准确性。该基准测试专注于2024年出版的论文，确保最小化与LLM预训练数据的重叠，从而减少数据污染的可能性", "innovation": "本文提出了首个专门针对大语言模型的基准测试，该基准测试涵盖科学研究的多个关键子任务，包括灵感检索、假设构成和假设排序。开发了一种自动化的框架，从12个学科的科学论文中提取关键组件，包括研究问题、背景调查、灵感和假设，并通过专家验证确认其准确性。此测试框架强调2024年出版的论文，以减少与LLM预训练数据的重叠，确保减少数据污染。试验结果表明，大语言模型在检索灵感方面表现良好，这是一种分布外任务，表明其能够发现新的知识关联。", "conclusion": "此研究表明，大语言模型能够有效地作为“研究假设矿井”，在生成大量创新假设方面具有潜力，且需要较少的人为干预。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.21393", "html_url": "https://arxiv.org/abs/2503.21393", "title": "通过情感和语义分析评估大型语言模型及谷歌翻译对印度语言的翻译", "title_en": "An evaluation of LLMs and Google Translate for translation of selected Indian languages via sentiment and semantic analyses", "authors": "Rohitash Chandra,Aryan Chaudhari,Yeshwanth Rayavarapu", "background": "大型语言模型（LLMs）在语言翻译领域，尤其是低资源语言的翻译中取得了显著进展。然而，对由LLMs生成的翻译质量评估研究相对较少，特别是在Gemini、GPT和Google Translate方面。此研究通过使用语义和情感分析来评估Gemini、GPT和Google Translate等LLMs对印度语（包括梵语、泰卢固语和印地语）文本的翻译质量，基于专家翻译的选定文本（《薄伽梵歌》、《塔玛斯》和《大行篇》），展现了LLMs在翻译准确性上的进步，同时也揭示了在情感和语义保留方面面临的挑战，特别是在隐喻和哲学语境下的文本如《薄伽梵歌》等。", "innovation": "该研究通过使用语义和情感分析的方法来评估LLMs的翻译质量，首次专门针对印度语言文本进行了大规模、系统的评估，特别是针对具有隐喻和哲学背景的文本。这种评估方法有助于揭示LLMs在翻译任务中的具体优势和不足，为开发更准确和文化敏感的翻译系统提供了参考依据。", "conclusion": "LLMs在翻译准确性方面取得了显著进展，尤其是在情感和语义的保留方面，GPT模型在情感极性的保留上优于人工（专家）翻译。总体而言，GPT模型在情感和语义保留方面优于Google Translate。该研究有助于开发更加准确和文化敏感的大型语言模型翻译系统。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00703", "html_url": "https://arxiv.org/abs/2505.00703", "title": "T2I-R1: 使用协作的语义级和标记级链式思考强化图像生成", "title_en": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT", "authors": "Dongzhi Jiang,Ziyu Guo,Renrui Zhang,Zhuofan Zong,Hao Li,Le Zhuo,Shilin Yan,Pheng-Ann Heng,Hongsheng Li", "background": "近期大型语言模型的研究展示了如何通过链式思考（CoT）和强化学习（RL）来提升性能。然而，这些推理策略在视觉生成领域中的应用尚未得到广泛探索。", "innovation": "提出了一种新的增强推理的文本到图像生成模型T2I-R1，该模型通过带有双层链式思考过程的强化学习（RL）来实现。模型通过识别两个层次的链式思考（语义级和标记级）来分别增强生成的不同阶段，并引入了BiCoT-GRPO，该方法通过组合生成奖励无缝优化双层链式思考的生成策略。该方法应用于基准模型Janus-Pro，实现了在T2I-CompBench上的13%提升和在WISE基准上的19%提升，甚至超过了当前最先进的模型FLUX。", "conclusion": "通过我们的推理策略，改进了基线模型Janus-Pro，取得了优越的性能，在两个基准测试中均超过了当前最先进的模型FLUX。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16722", "html_url": "https://arxiv.org/abs/2505.16722", "title": "打破mBad！跨语言去毒的监督微调", "title_en": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "authors": "Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen", "background": "随着大型语言模型（LLMs）在全球应用中的普及，确保这些模型在多样的语言环境下无毒性成为一个关键挑战。本文探讨了跨语言去毒（Cross-lingual Detoxification）这一跨语言范式，该范式可以减少毒性，并让去毒能力在不同语言背景下的高资源语言和低资源语言之间进行迁移。作者通过392种广泛设置来分析跨语言去毒的有效性，评估在数据有限的情况下的毒性减轻效果，并研究了减轻毒性对模型在无毒性任务中性能的影响，揭示了安全性和知识保留之间的权衡。", "innovation": "本文提出了一种监督微调方法，用于跨语言去毒，使去毒能力可以在不同语言资源背景下的语言之间进行迁移，有效减少了毒性，并且在不同语言环境下的模型性能得到了保持。作者通过广泛的设置来分析这一方法的有效性，并揭示了其中的权衡关系。此外，作者还提供了解决这个问题的公开代码和数据集，使得研究更具开放性和可重复性。", "conclusion": "本文通过对392种广泛设置的分析，证明了跨语言去毒的有效性，并展示了监督微调方法在确保模型性能的同时减少毒性的重要性。作者还指出了在安全性和知识保留之间存在的权衡，并提供了研究中使用的代码和数据集，方便其他研究者进行进一步的研究。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24625", "html_url": "https://arxiv.org/abs/2505.24625", "title": "学习视频构建3D世界：通过3D视觉几何先验增强MLLMs", "title_en": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors", "authors": "Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang", "background": "之前的研究已经探讨了使用多模态大语言模型（MLLMs）通过将3D场景解释为视频来理解3D空间的方法。这些方法通常依赖于全面的3D数据输入，如点云或重建的鸟瞰图（BEV）地图。本研究在此基础上，通过增强MLLMs直接从视频数据中理解并推理3D空间的能力，推动了该领域的发展，而无需额外的3D输入数据。", "innovation": "提出了一种新颖且高效的方法——Video-3D Geometry Large Language Model (VG LLM)。该方法使用3D视觉几何编码器从视频序列中提取3D先验信息，将这些信息与视觉标记结合后输入到MLLM中。实验表明，该方法在各种与3D场景理解和空间推理相关的任务中表现出显著改进，并且其不依赖于显式3D数据输入的4B模型在VSI-Bench评估中达到了与现有最先进的方法相当甚至超越的结果，如在与Gemini-1.5-Pro的对比中表现出更佳性能。", "conclusion": "本研究通过提出VG LLM，展示了MLLMs在直接从视频数据中进行3D场景理解与空间推理方面的能力增强，且不依赖于额外的3D输入数据即可实现与现有先进水平相当甚至更优的结果。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16211", "html_url": "https://arxiv.org/abs/2505.16211", "title": "AudioTrust: 评估音频大型语言模型多维度可信性的基准", "title_en": "AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models", "authors": "Kai Li,Can Shen,Yile Liu,Jirui Han,Kelong Zheng,Xuechao Zou,Zhe Wang,Xingjian Du,Shun Zhang,Hanjun Luo,Yingbin Jin,Xinxin Xing,Ziyang Ma,Yue Liu,Xiaojun Jia,Yifan Zhang,Junfeng Fang,Kun Wang,Yibo Yan,Haoyang Li,Yiming Li,Xiaobin Zhuang,Yang Liu,Haibo Hu,Zhizheng Wu,Xiaolin Hu,Eng-Siong Chng,XiaoFeng Wang,Wenyuan Xu,Wei Dong,Xinfeng Li", "background": "音频大型语言模型（ALLMs）的迅速发展和广泛应用迫切需要对其可信性进行系统的理解。然而，目前的研究主要集中在文本模式上或仅关注一系列有限的安全维度，未能充分考虑音频模式的独特特性和应用场景。现有的评估框架缺乏针对音频特性的独特风险进行系统的评估，尤其是对于反常识（hallucination）的要求，隐私问题，鲁棒性的考量以及验证等方面。因此，现有的框架难以全面评估ALLMs的可信性，特别是在涉及高风险音频场景时。AudioTrust正是在这个背景下提出的，它提供了首个专门针对ALLMs的全方位、多维度可信性评估框架和基准测试。", "innovation": "AudioTrust构成了第一个致力于评估ALLMs的全方位可信性的框架和基准测试。这个框架设计了六方面评估标准：公平性、反常识性、安全性、隐私、鲁棒性和认证。AudioTrust涵盖了18种不同的实验设置，使用精心挑选的真实世界数据集（如日常对话、紧急呼叫、语音助手交互）来探索ALLMs的复杂可信性。AudioTrust还精心设计了9个针对音频特性的评估指标，并采用大规模自动化评估流程对模型进行客观、可扩展的评分。这些框架和基准测试能够全面评估ALLMs在面对各种高风险音频场景时的可信边界和局限性，为未来音频模型的安全和可信部署提供了宝贵的见解和依据。", "conclusion": "实验结果表明，当前最先进的开源和闭源ALLMs在多种高风险音频场景中的可信边界和支持说明存在局限性。AudioTrust和基准测试提供的结果为未来音频模型的可信和安全部署提供了不可或缺的指导。欲查看更多详细信息和评估结果，可在该网址获取：this https URL."}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02205", "html_url": "https://arxiv.org/abs/2506.02205", "title": "Bregman Centroid Guided Cross-Entropy Method", "title_en": "Bregman Centroid Guided Cross-Entropy Method", "authors": "Yuliang Gu,Hongpeng Cao,Marco Caccamo,Naira Hovakimyan", "background": "交叉熵方法（CEM）是模型导向强化学习（MBRL）中的广泛应用的轨迹优化器，但其单一模式的采样策略在多模式地形上容易导致过早收敛。研究人员提出了一种名为$\textbf{\textit{\textnormal{BC-EvoCEM}}}$的新方法，通过利用Bregman质心来进行性能加权集成和多样性控制，从而改善了CEM的性能。该方法通过在质心周围的信任区域进行采样来更新最少贡献的工人，同时巧妙地利用了贝特朗散度与指数族分布的对偶性，确保该方法可以无缝集成到标准CEM流水线中，而无需显著增加计算负担。", "innovation": "提出了一种名为$\textbf{\textit{\textnormal{BC-EvoCEM}}}$的新方法，通过利用Bregman质心来进行性能加权集成和多样性控制，从而改善了CEM的性能。该方法利用Bregman散度与指数族分布之间的对偶性，确保了其可以无缝集成到标准的CEF流水线中，同时简单且有效地提升了$\textbf{CEM}$的收敛性和解的质量。", "conclusion": "该方法在合成基准、复杂导航任务和完整的MBRL流水线中得到了实验验证，证明了$\textbf{\textit{\textnormal{BC-EvoCEM}}}$能够有效提升CEM的收敛性和解的质量，为CEM提供了一个简单而有效的改进方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18232", "html_url": "https://arxiv.org/abs/2505.18232", "title": "Two-Stage Regularization-Based Structured Pruning for LLMs", "title_en": "Two-Stage Regularization-Based Structured Pruning for LLMs", "authors": "Mingkuan Feng,Jinyang Wu,Siyuan Liu,Shuai Zhang,Ruihan Jin,Feihu Che,Pengpeng Shao,Zhengqi Wen,Jianhua Tao", "background": "大型语言模型（LLMs）由于参数数量庞大，其部署受到很大阻碍。结构化剪枝（structured pruning）被证明是一种有前途的解决方案。然而，当前的方法往往直接根据某些指标删除不重要的参数，这会导致知识丢失且需要大量的重新训练。", "innovation": "本文提出了一种新的剪枝方法TRSP（Two-Stage Regularization-Based Structured Pruning for LLMs），分为两个阶段使用正则化来逐步减少模型参数的数量。第一阶段通过将每个转换层的输出乘以可学习的初始权重，并将\boldsymbol{\text{1}}-范数作为正则化项添加到损失函数中来学习这些权重。第二阶段通过正则化较小权重层的输出与输入之间的差异来鼓励知识转移到保留的层。这种方法相比直接删除参数能保留更多知识并更好地保持模型性能。", "conclusion": "通过广泛的实验表明，TRSP在不需要重新训练的情况下，优于现有的逐层结构剪枝方法，且作为一种逐层剪枝方法，它可以实现显著的端到端加速，因此它是一种具有潜力的LLM高效部署解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09438", "html_url": "https://arxiv.org/abs/2505.09438", "title": "评估基于GPT和推理的大语言模型在物理奥赛问题上的表现：超越人类表现及其对教育评估的影响", "title_en": "Evaluating GPT- and Reasoning-based Large Language Models on Physics Olympiad Problems: Surpassing Human Performance and Implications for Educational Assessment", "authors": "Paul Tschisgale,Holger Maus,Fabian Kieser,Ben Kroehs,Stefan Petersen,Peter Wulff", "background": "大语言模型（LLMs）现已广泛可用，能够触及各教育层次的学员。这引发了对其在教育中可能绕过重要学习过程并损害评估规范性的担忧。物理教育中，问题解决在教学和评估中占据核心地位，因此理解LLMs在物理问题解决方面的特殊能力变得尤为重要。这有助于制定负责任和教育有效的LLMs整合方法。研究者选择了德国家物理奥林匹克问题作为评估基准，比较了通用大语言模型（GPT-4o）和推理优化模型（o1-preview）性能，探讨了实现这一目标的方法和技术挑战。", "innovation": "该研究首次将两种不同的大语言模型（GPT-4o和o1-preview）与参与德国家物理奥林匹克的学生表现进行了比较，基于物理奥赛问题集进行评估。研究通过评估生成解的正确性以及分析大语言模型生成解的特点和限制，提出新的发现和见解，包括模型在物理奥赛问题上的高级问题解决能力，尤其是在给定不同提示时，o1-preview表现出高度一致的优秀表现。这提供了新的关于确保教育评估完整性和支持学生批判性使用大语言模型的见解。", "conclusion": "研究结果表明，两个测试的LLMs（GPT-4o和o1-preview）在奥运会标准的物理问题解决上表现出色，通常优于人类参与者。提示技术对GPT-4o性能影响较小，而o1-preview几乎一致地优于GPT-4o和人类基准。研究讨论了这些发现对物理教育中总结性评估和形成性评估的设计的影响，包括如何确保评估的完整性和支持学生批判性地对待大语言模型。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20485", "html_url": "https://arxiv.org/abs/2505.20485", "title": "在非一致数据下通过保留全局知识梯度避免联邦学习中遗忘", "title_en": "Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data", "authors": "Abhijit Chunduru,Majid Morafah,Mahdi Morafah,Vishnu Pandi Chellapandi,Ang Li", "background": "联邦学习因数据异质性存在而变得非常具有挑战性。虽然有很多方法来应对这一问题，如本地正则化、更好的模型融合技术和数据共享，但这些方法缺乏对数据异质性如何影响全局决策边界的深刻理解。本文通过使用玩具模型进行实验性分析缩小了这一差距，发现现有方法在局部训练过程中忘记了全局决策边界，只学习了完美的局部决策边界，无论初始权重如何，且即使从预训练的最优权重开始也会丧失全局决策边界。", "innovation": "提出了一种联邦学习框架FedProj，该框架能够在局部训练过程中稳健地学习全局决策边界，并避免遗忘。设计了一种新颖的服务器端集成知识转移损失函数，进一步校准学习到的全局决策边界。为了缓解学习到的全局决策边界遗忘的问题，进一步提出了一个利用公共未标记数据集的 episodic 记忆来调节每个局部训练步骤的梯度更新。实验结果表明，FedProj在各种条件下都优于现有的方法。", "conclusion": "实验结果表明，FedProj在各种条件下都显著优于现有的方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17117", "html_url": "https://arxiv.org/abs/2505.17117", "title": "从词元到思维：LLMs和人类在压缩和意义之间如何权衡", "title_en": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning", "authors": "Chen Shani,Dan Jurafsky,Yann LeCun,Ravid Shwartz-Ziv", "background": "人类将知识组织成紧凑的概念类别，通过语义压缩来映射多元实例到抽象表示，同时保留意义（例如，燕子和蓝birds都是鸟，大多数鸟可以飞行）。这些概念反映了表达准确性和表示简洁性之间的权衡。大型语言模型展示了惊人的语言能力，但其内部表示是否像人类一样在压缩和语义准确性之间达到类似的人类平衡仍然不清楚。本文通过引入一个新的信息理论框架，结合率失真理论和信息瓶颈原理，定量比较了这些策略。通过对多种大型语言模型的词元嵌入与人类概念化基准测试进行分析，揭示了关键差异。虽然大型语言模型形成了符合人类判断的广泛概念类别，但在捕捉对人类理解至关重要的细粒度语义差异方面具有局限性。更根本的是，大型语言模型表现出强烈的倾向于激进统计压缩的倾向，而人类概念系统似乎更倾向于适应性细微差别和上下文丰富性，即使这在我们的度量标准下降低了压缩效率。这些发现揭示了当前AI和人类认知架构之间的关键差异，为获得更接近人类认知架构的大型语言模型指明了路径。", "innovation": "提出了一个新的信息理论框架，结合率失真理论和信息瓶颈原理，定量比较了人类和大型语言模型在语义压缩与意义表达之间的权衡策略；通过分析多种大型语言模型的词元嵌入与人类概念化基准测试，揭示了关键差异，特别是在细粒度语义和压缩策略上的不同。", "conclusion": "当前的大型语言模型倾向于激进的统计压缩，这与人类通过适应回归和上下文丰富性在语义上保留细微差别的倾向有所不同。这些发现为开发与人类认知架构更加对齐的大型语言模型提供了新的方向。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19955", "html_url": "https://arxiv.org/abs/2505.19955", "title": "MLR-Bench: 评估开放性机器学习研究中的AI代理", "title_en": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": "Hui Chen,Miao Xiong,Yujie Lu,Wei Han,Ailin Deng,Yufei He,Jiaying Wu,Yibo Li,Yue Liu,Bryan Hooi", "background": "近年来，AI代理在推动和辅助科学研究方面展现了其日益增长的潜力。为了评估AI代理在开放性机器学习研究中的表现，本文引入了MLR-Bench基准测试框架，该框架包括三个关键组件：（1）来自NeurIPS、ICLR和ICML研讨会的201项研究任务，涵盖多样化的ML主题；（2）结合基于LLM的评审员和精心设计评审标准的自动化评估框架MLR-Judge，以评估研究质量；（3）一个模块化的研究代理框架MLR-Agent，能够通过四个阶段（创意生成、提案形成、实验、论文撰写）完成研究任务。该框架支持对这些研究阶段的逐级评估，以及最终研究论文的端到端评估。", "innovation": "MLR-Bench框架独特地集成了201项来自顶级会议的工作室的研究任务，一个基于LLM的自动化评估框架，以及一个可以指导研究代理完成四个研究阶段任务的模块化框架。此外，该研究还验证了MLR-Judge框架的有效性，并通过公开源代码，为社区提供了一个评估、诊断和改进AI研究代理的工具，以促进可靠和透明的科学研究发展。", "conclusion": "利用MLR-Bench框架，研究评估了六种最新的LLM和一个高级编码代理。结果显示，尽管LLM在生成连贯的创意和结构良好的论文方面表现出色，但现有的编码代理通常会生成虚假或无效的实验结果（例如，在80%的情况下），这构成了科学可靠性的一个主要障碍。此外，人类评估验证了MLR-Judge的有效性，并支持其作为规模化评估研究的工具潜力。开放源代码的MLR-Bench将帮助社区进行基准测试、诊断和改进AI研究代理，以实现值得信赖和透明的科学研究。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02007", "html_url": "https://arxiv.org/abs/2506.02007", "title": "eACGM: 非侵入式性能跟踪与异常检测面向机器学习系统", "title_en": "eACGM: Non-instrumented Performance Tracing and Anomaly Detection towards Machine Learning Systems", "authors": "Ruilin Xu,Zongxuan Xie,Pengfei Chen", "background": "随着机器学习（ML）应用的广泛采用，对高性能计算的需求不断增长。为了提升ML系统的性能并优化故障诊断，研究者们开发了多种性能监控工具。然而，这些工具通常需要在应用程序中进行代码修改或增加监控逻辑，这增加了实现和维护的复杂性。因此，急需一种无需代码修改即可实现全面性能监控和异常检测的方法。eACGM正是针对这一需求而设计的，它基于eBPF技术，实现了对GPU和网络通信层等关键硬件组件以及CUDA、Python、PyTorch等关键软件栈的实时性能数据采集，同时提供了非侵入性和低开销的特点。", "innovation": "eACGM的主要创新在于其非侵入性设计和低开销特性。它利用eBPF技术实时采集关键硬件和软件组件的性能数据，且无需进行代码修改或调整。此外，eACGM运用高斯混合模型（GMM）对多维性能指标进行统计建模和聚类分析，能够有效识别复杂的故障模式，如延迟异常、硬件故障和通信效率低下等问题，从而实现系统瓶颈和异常行为的快速诊断。", "conclusion": "通过在多节点分布训练场景中的广泛实证研究和案例分析，eACGM证明了其在保持非侵入性和低开销的情况下，能够有效捕捉模型训练和推理过程中的关键性能异常。其稳定且全面的异常检测性能和监控能力表明eACGM适用于实际生产环境中的性能优化和支持大规模AI/ML系统的故障诊断。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10967", "html_url": "https://arxiv.org/abs/2506.10967", "title": "超越注意力或相似性：在MLLM中最大化条件多样性进行token修剪", "title_en": "Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs", "authors": "Qizhe Zhang,Mengzhen Liu,Lichen Li,Ming Lu,Yuan Zhang,Junwen Pan,Qi She,Shanghang Zhang", "background": "在多模态大型语言模型（MLLMs）中，图像令牌的输入长度往往远大于其文本对应物，导致高昂的推理成本。目前的研究主要通过去除冗余的图像令牌来尝试解决这一问题，但现有的方法要么依赖于基于注意力的剪枝，保留了大量的重复令牌，要么使用基于相似性的剪枝，忽视了指令的相关性，从而导致性能不如预期。", "innovation": "本文提出了一种新颖的图像令牌剪枝方法，称为CDPruner，这种方法通过最大限度地提高保留令牌的条件多样性来超越基于注意力或相似性的方法。首先，定义了基于指令的图像令牌的条件相似性，然后通过行列式点过程（DPP）重新定义了令牌剪枝问题以最大化选择子集的条件多样性。CDPruner是一种无需训练和模型无关的方法，使其实现方便地应用于各种MLLMs。广泛的实验表明，CDPruner在各种视觉语言基准上建立了新的最先进水平。通过DPP最大化条件多样性，所选子集更好地表示输入图像并紧密符合用户指令，从而即使在高减缩比的情况下也能保持强大的性能。当应用于LLaVA时，CDPruner将FLOPs减少95%，CUDA延迟减少78%，同时保持原来的94%的准确性。", "conclusion": "CDPruner通过最大化条件多样性来剪枝令牌，在各种MLLMs中实现了有效的高效率，同时保持了性能的完整性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17336", "html_url": "https://arxiv.org/abs/2506.17336", "title": "使用苏菲克chain-of-thought推理和同态加密向量数据库保护个人信息的LLM交互", "title_en": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases", "authors": "Yubeen Bae,Minchan Kim,Jaejin Lee,Sangbum Kim,Jaehyung Kim,Yejin Choi,Niloofar Mireshghallah", "background": "大型语言模型（LLMs）作为个人代理使用时，会访问用户的敏感数据，如日历、电子邮件和医疗记录。用户目前面临一种权衡：他们可以选择将许多存储在远程数据库中的私人记录发送给强大的但不信任的LLM提供商，从而增加暴露风险；或者选择在可信设备上本地运行较弱的模型。本研究旨在解决这一问题。", "innovation": "本文提出了一种名为Socratic Chain-of-Thought Reasoning的方法，该方法将一般非私密的用户查询发送给强大的但不信任的LLM，该LLM生成Chain-of-Thought（CoT）提示和详细的子查询而不访问用户数据。然后，在单个用户的百万条私人数据条目上执行加密的子秒级语义搜索，并使用同态加密向量数据库进行搜索。最后，将CoT提示和解密记录输入本地语言模型以生成最终响应。在LoCoMo长上下文问答基准测试中，结合GPT-4o与本地Llama-3.2-1B模型的混合框架，比单独使用GPT-4o提高了7.1个百分点。这标志着朝着任务在不信任的强大LLM和弱本地模型之间分解和分配，同时保护用户隐私的系统迈出第一步。", "conclusion": "研究提出的系统能够通过拆分任务，在不信任的强大LLM和弱本地模型之间分担计算，同时保护用户隐私。该混合框架在LoCoMo基准测试中表现出色，证明了实现用户隐私保护和提高模型性能相结合的可行性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17765", "html_url": "https://arxiv.org/abs/2506.17765", "title": "CARTS: Collaborative Agents for Recommendation Textual Summarization", "title_en": "CARTS: Collaborative Agents for Recommendation Textual Summarization", "authors": "Jiao Chen,Kehui Yao,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Jason Cho,Evren Korpeoglu,Sushant Kumar,Kannan Achan", "background": "当前推荐系统需要对文本数据进行总结，例如生成产品轮播或其他组展现项目的简洁且连贯的标题。大型语言模型虽然在NLP领域表现出了文本总结的潜力，但这些方法并不直接适用于推荐系统，因为推荐系统的解释需要与项目集的核心特征密切相关，并且要严格遵守字数限制。", "innovation": "本文提出了一种名为CARTS（Collaborative Agents for Recommendation Textual Summarization）的多智能体LLM框架，专门用于推荐系统中的结构化总结。CARTS将任务分解为三个阶段：生成增强生成（GAG）、精炼循环和仲裁，每个智能体角色在这些阶段中依次负责提取关键项目特征、基于相关性和长度反馈迭代精炼候选标题、并通过合作仲裁过程选择最终标题。本研究通过大规模电子商务数据实验和实时A/B测试表明，CARTS显著优于单步骤和思维链的LLM基线，提高了标题的相关性和用户参与度指标。", "conclusion": "实验结果表明，CARTS框架在电子商务数据中显著优于单步和思维链的LLM基线，提升了标题的相关性和用户参与度指标，展示了其在推荐系统中的有效性和优势。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13759", "html_url": "https://arxiv.org/abs/2506.13759", "title": "离散扩散在大规模语言和多模态模型中的应用：综述", "title_en": "Discrete Diffusion in Large Language and Multimodal Models: A Survey", "authors": "Runpeng Yu,Qi Li,Xinchao Wang", "background": "这项工作中，我们提供了对离散扩散语言模型（dLLMs）和离散扩散多模态语言模型（dMLLMs）的系统调查。dLLMs和dMLLMs与自回归（AR）模型不同，它们采用多令牌，平行解码范式，使用全注意及其去噪基生成策略。这种方法自然地使并行生成、精细的输出可控性和动态、响应感知成为可能。这些能力是AR模型难以实现的。近年来，许多工业规模的专属d(M)LLMs以及大量的开源学术d(M)LLMs已经展示了与自回归模型相当的性能，同时在推理速度上可以达到10倍的加速。这种离散扩散LLMs和MMLMs的进步主要得益于两个领域的进展。第一个是自回归LLMs和MMLMs的发展，积累了大量数据、基准和训练与推理的基础架构。第二个贡献领域是离散扩散底层数学模型的演变。这些进步共同推动了自2025年初的大规模研究浪潮。", "innovation": "离散扩散LMLMs和MMLMs的关键创新在于采用多令牌，平行解码范式，利用全注意和去噪基生成策略，这种方法能让模型实现并行生成、精细的输出可控性和动态、响应感知。这些能力使离散扩散模型在并行性和可控性方面超越了传统的自回归模型，特别是在大规模应用和速度优化方面取得了显著的提升。", "conclusion": "我们总结了离散扩散模型在语言、视觉语言和生物领域的新兴应用。我们还讨论了未来的研究和部署方向，强调了离散扩散模型在这些领域中的潜力和应用前景。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15709", "html_url": "https://arxiv.org/abs/2506.15709", "title": "基于图神经网络的网络模式估算研究与改进", "title_en": "Studying and Improving Graph Neural Network-based Motif Estimation", "authors": "Pedro C. Vieira,Miguel E. P. Silva,Pedro Manuel Pinto Ribeiro", "background": "图神经网络（GNNs）是图表示学习的主要方法。尽管它们在构建模式频率估计方面的应用已有一定的研究，但在网络模式显著性分布（SP）预测方面，GNNs的应用仍处于起步阶段，相关基准尚不存在。本文旨在填补这一空白，将SP估计问题独立于模式频率估计任务来处理，旨在优化该问题以提高解释性、稳定性和大规模处理能力。研究基于大量的合成数据集进行了实证验证，并进一步在真实世界的数据集上进行了测试。观察到1-WL限制模型在精确SP估计方面表现不佳，但能够通过比较预测的SP和由合成生成器产生的SP来进行图生成过程的近似模拟。这是首次使用基于GNN的模式估算研究，提出了直接模式估计可以帮助克服通过子图计数进行模式估算时面临的理论局限的观点。", "innovation": "将SP估计独立于子图频率估计，并将问题重新表述为多目标回归问题。优化了模型，使其在解释性和大规模应用上有更好的表现。通过合成数据集和真实数据集的实验验证了方法的有效性，并揭示了1-WL限制模型在SP估计上的局限性，同时也展示了直接SP估计方法的优势。", "conclusion": "1-WL限制模型在精确SP估计方面表现不佳，无法进行精确的SP估计，但可以通过比较预测的SP和由合成生成器产生的SP来进行图生成过程的模拟。基于GNN的网络模式估算研究首次提出并表明直接模式估计可以在某种程度上克服传统方法的限制。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06946", "html_url": "https://arxiv.org/abs/2506.06946", "title": "医疗保健领域让流水线即席生产：挑战与经验教训", "title_en": "Making a Pipeline Production-Ready: Challenges and Lessons Learned in the Healthcare Domain", "authors": "Daniel Angelo Esteves Lawand(1),Lucas Quaresma Medina Lam(1),Roberto Oliveira Bolgheroni(1),Renato Cordeiro Ferreira(1,2,3,4),Alfredo Goldman(1),Marcelo Finger(1) ((1) University of São Paulo, (2) Jheronimus Academy of Data Science, (3) Technical University of Eindhoven, (4) Tilburg University)", "background": "将机器学习（ML）训练流水线部署到生产环境中需要良好的软件工程实践。然而，典型的数据科学工作流程往往会导致代码缺乏关键的软件质量属性。本文通过对SPIRA项目的研究来探讨这个问题。SPIRA项目旨在创建一个 ML-Enabled System（MLES），利用语音分析提前诊断呼吸功能不足。该项目经历了从一个概念验证的 Big Ball of Mud（v1）版本，到基于设计模式的模块化巨拱门（v2）版本，再到基于测试驱动的微服务集（v3）版本三个发展阶段，每个版本都在整体的扩展性、可维护性、稳定性和韧性方面有所提高。本文总结了这个过程中遇到的挑战和学到的经验教训，为寻求将流水线生产化的研究者和实践者提供了见解。", "innovation": "项目经历了从Big Ball of Mud（v1）版本，到模块化巨拱门（v2）版本，再到微服务集（v3）版本三个发展阶段，每个版本都在整体的扩展性、可维护性、稳定性和韧性方面有所提高。通过这些变化证明了改进代码质量的重要性，以适应生产环境的要求。", "conclusion": "本文分享了将ML流水线部署到生产环境中的挑战与经验教训，为未来的研究者和实践者提供了宝贵的建议，尤其在医疗保健领域，这具有重要的指导意义。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19089", "html_url": "https://arxiv.org/abs/2506.19089", "title": "语言模型可能不明白你的意思：通过故事情境评估心理理论", "title_en": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting", "authors": "Nathaniel Getachew,Abulhair Saparov", "background": "现有的基准测试可能受到预训练数据污染的影响，而StorySim框架则通过制作高度可控的Storyboard生成新颖且组成的故事情境，以评估大语言模型的心理理论（ToM）和世界建模（WM）能力。研究发现，大多数模型在WM任务上的表现优于ToM任务，而且在与人类互动时相比，它们在处理无生命的物体时表现更好。此外，通过该框架他们发现了诸如最近效应偏见等启发式行为的证据，即过度依赖故事早期事件。相关代码可以免费获取。", "innovation": "引入了StorySim，一个可编程框架，用于生成合成故事以评估大型语言模型的心理理论和世界建模能力，与之前可能受到预训练数据污染的基准不同，StorySim能够生成新颖且组成的故事情境，并通过一个可高度控制的Storyboard进行精准操纵。框架被用来设计心理理论和世界建模任务，这些任务控制了追踪和建模心理状态的能力。", "conclusion": "研究结果显示大多数模型在世界建模任务上的表现优于心理理论任务。模型在与人类互动时的表现优于处理无生命的物体。另外，他们发现了启发式行为的证据，如最近效应偏见等。生成的所有数据和评估代码都免费提供。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18710", "html_url": "https://arxiv.org/abs/2506.18710", "title": "大型语言模型的教育知识基准测试", "title_en": "Benchmarking the Pedagogical Knowledge of Large Language Models", "authors": "Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portela,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod", "background": "现有的基准测试如大规模多任务语言理解（MMLU）在评估AI的知识和能力方面起到了关键作用，但主要集中于内容知识，忽略了对学生教师教学方法和实践的理解评估。该论文提出了教育知识基准，旨在评估大型语言模型在跨领域教学知识（CDPK）和特殊教育需要及残疾（SEND）教学知识方面的能力。这些基准通过精选教师专业发展考试问题构建，涵盖了多种教学亚领域，如教学策略和评估方法。报告的结果显示97个模型在教学知识问题上的准确率范围从28%到89%之间。", "innovation": "该论文创新性地提出了教育知识基准，这是为了填补现有基准测试中在评估模型理解教学方法方面的空白。基准测试设计基于精心筛选的教师职业发展考试问题，覆盖了多种教学亚领域。", "conclusion": "教育基准测试对于测量模型对教学概念的理解能力、对学习者需求的恰当反应以及支持不同情境下的有效教学实践至关重要。它们对于指导大型语言模型及其工具在教育领域的负责任和基于证据的应用决策，以及引导政策制定具有重要意义。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12036", "html_url": "https://arxiv.org/abs/2506.12036", "title": "一种精简方法对文本到图像扩散模型进行调优", "title_en": "A Minimalist Method for Fine-tuning Text-to-Image Diffusion Models", "authors": "Yanting Miao,William Loh,Pacal Poupart,Suraj Kothawade", "background": "最近的工作使用强化学习（RL）对文本到图像的扩散模型进行微调，提高了文本与图像的对齐以及样本质量。但是现有的方法引入了不必要的复杂性：例如，这些方法需要缓存完整的采样轨迹，依赖可微分的奖励模型或大型偏好数据集，或需要专门的指导技术。", "innovation": "本文受‘黄金噪声’假设的启发——即某些初始噪声样本可以始终产生更好的对齐效果——引入了Noise PPO，一种完全冻结预训练扩散模型的简单RL算法，并且学习一个根据提示条件生成初始噪声的生成器。这种方法不需要存储采样轨迹、奖励回传或复杂的指导技巧。实验结果表明，优化初始噪声分布可以在原模型基础上持续提高对齐和样本质量，在推理步骤较少的情况下，优化效果最为显著，随着推理步骤增加，噪声优化的效果逐渐减弱但仍然存在。这些发现澄清了黄金噪声假设的范围和局限性，并强调了对扩散模型进行简单RL微调的实际价值。", "conclusion": "通过实验验证了噪声优化对扩散模型的微调具有显著效果，并指出噪声优化的效果随着推理步骤增加而减弱但仍具现实意义。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12747", "html_url": "https://arxiv.org/abs/2506.12747", "title": "激发扩散和状态空间模型在医学图像分割中的潜力", "title_en": "Unleashing Diffusion and State Space Models for Medical Image Segmentation", "authors": "Rong Wu,Ziqi Chen,Liming Zhong,Heng Li,Hai Shu", "background": "现有的分割模型在单一医学影像数据集上训练时，往往对于未见过的器官或肿瘤缺乏鲁棒性。开发一个能在训练数据之外识别稀有或新型肿瘤类别的稳健模型对于推动医学影像应用至关重要。现有的分割模型在遇到未见过的器官或肿瘤时表现不佳，亟需一种能够在未见过的数据中进行准确分割的新框架。作者提出了一种新颖的方法DSM，该方法利用扩散和状态空间模型来分割训练数据之外的未见过的肿瘤类别。DSM利用了修改后的注意力解码器中的两组对象查询，以提高分类准确性。", "innovation": "DSM框架创新地结合了扩散模型和状态空间模型，通过两组对象查询来增强分类准确性。首先，模型通过对象感知特征分组策略学习器官查询，以捕捉器官级别的视觉特征。然后，通过基于扩散的视觉提示，精炼肿瘤查询，从而实现对未见过的肿瘤的精细分割。此外，通过扩散引导的特征融合以及CLIP的文本嵌入，DSM能够提高语义分割性能，并增强模型在不同场景和多标签任务中的鲁棒性。实验结果表明，DSM在各种肿瘤分割任务中表现出色。", "conclusion": "通过广泛的实验，证实了DSM框架在多种肿瘤分割任务中的优越性能。该框架提升了模型在面对未见过的肿瘤时的鲁棒性，并为医学影像应用中的精确分割提供了新的解决方案。代码可以在该链接获取。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20259", "html_url": "https://arxiv.org/abs/2506.20259", "title": "使用神经网络生成和定制机器人手臂轨迹", "title_en": "Generating and Customizing Robotic Arm Trajectories using Neural Networks", "authors": "Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Igor Farkaš", "background": "文章介绍了一种神经网络方法，用于生成和定制机器人手臂的轨迹，确保精确性和重复性。该方法通过整合计算机器人手臂前向运动学的神经网络与关节角度生成器，实现了机器人手臂的精确动作，并在人机交互场景中提高了动作的可预测性。该研究在认知机器人领域进行了试验性的应用，特别是NICO机器人通过精确线性移动指向空间中的特定点，展示了其优势。", "innovation": "创新点在于开发了一种新的神经网络方法，结合了前后向运动学计算和关节角度生成器，以定制机器人手臂的轨迹，并成功地在实验设置中实现精准控制和适应不同环境的技术。这解决了如何通过神经网络定制化生成精准的机器人手臂轨迹的问题，提供了在实际应用中可靠的方法。这项工作拓展了神经网络在机器人控制领域的应用范围，使得机器人动作更加灵活和精确。", "conclusion": "本研究成功地开发了一种通过神经网络生成和定制机器人手臂轨迹的方法，提高了机器人的动作精度和可重复性。这种方法具有广泛的应用前景，能够在不同场景中定制不同的运动轨迹。在NICO机器人实验中，能够通过精确线性移动指向空间中的特定点，验证了该方法的有效性。未来，可以通过进一步优化神经网络和增加数据集的多样性来提升方法的应用效果。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21098", "html_url": "https://arxiv.org/abs/2506.21098", "title": "ComRAG：基于动态向量存储的检索增强生成在工业实时社区问答中的应用", "title_en": "ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry", "authors": "Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan", "background": "社区问答（CQA）平台可以被视为社区中的重要知识库，但有效利用历史交互和领域知识仍面临挑战。现有方法往往对外部知识利用不足，无法整合动态历史问答上下文，或者缺乏适合工业部署的存储机制。", "innovation": "提出了ComRAG，一种利用中心点记忆机制集成静态知识和动态历史问答对的检索增强生成框架，适用于工业部署。ComRAG在三个工业CQA数据集上表现优于所有基线——相比基线，它在向量相似度上提高了25.9%，将延迟降低了8.7%到23.3%，并且通过迭代使片段增长降低了97.4%（从20.23%降低到2.06%）。", "conclusion": "ComRAG有效地融合了静态知识和动态历史问答上下文，大幅提升了实时社区问答系统的效果，显著降低了延迟和存储需求，为工业应用提供了有效的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22397", "html_url": "https://arxiv.org/abs/2506.22397", "title": "使用引导条件流匹配去雾显微镜图像：在保真度和逼真度之间寻找平衡", "title_en": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism", "authors": "Anirban Ray,Ashesh,Florian Jug", "background": "荧光显微镜是生命科学领域的重要驱动力，高端共聚焦显微镜能过滤出焦光，而成本较低且更易于获取的广域显微镜则无法完成此任务，导致图像模糊。计算去雾技术试图结合这两者的优势，使显微镜便宜但图像清晰。在感知失真权衡中，人们可以优化数据保真度（如低MSE或高PSNR）或数据现实度（如感知度量LPIPS或FID的测量值）。现有的方法要么优先考虑保真度而牺牲现实度，要么生成感知上令人信服但缺乏量化准确性。本文旨在寻找保真度与个人预测（样本）现实度之间的平衡，通过引导条件流动匹配框架来适应生成过程，从而实现这一点。", "innovation": "本文提出了一种名为HazeMatching的新型迭代方法，用于去雾荧光显微镜图像，能够有效地平衡这两个目标。HazeMatching通过引导生成过程中的条件速度场，以一个模糊观测作为指导，实现这一点。该方法在5个数据集上进行了评估，涵盖了合成数据和真实数据，从失真和感知质量两个方面进行评估，平均显示出在保真度和现实度之间的良好平衡，并能产生校准良好的预测。", "conclusion": "HazeMatching不需要显式的退化操作符，因此适用于真实显微镜数据。所有用于训练和评估的数据以及我们的代码将在许可下公开。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21997", "html_url": "https://arxiv.org/abs/2506.21997", "title": "Binned semiparametric Bayesian networks", "title_en": "Binned semiparametric Bayesian networks", "authors": "Rafael Sojo,Javier Díaz-Rozo,Concha Bielza,Pedro Larrañaga", "background": "本文介绍了一种新的概率半参数模型，该模型利用数据分箱来减少非参数分布中核密度估计的计算成本。该研究开发了两种新的条件概率分布，针对分箱半参数贝叶斯网络中的稀疏分箱核密度估计和傅里叶核密度估计。这些概率分布通过使用稀疏张量和限制条件概率计算中的父节点数量来解决维度灾问题，这通常影响分箱模型。通过复杂性分析和使用合成数据以及UCI机器学习库的多个数据集进行的多种比较实验来评估提案，实验包括不同的分箱规则、父节点限制、网格大小和样本数量，以全面了解模型的行为。", "innovation": "本文的创新点在于开发了一种新的概率半参数模型，该模型利用数据分箱技术来降低非参数分布中核密度估计的计算成本。本文提出了两种新的条件概率分布：稀疏分箱核密度估计和傅里叶核密度估计，这有助于解决维度灾问题。这些方法通过使用稀疏张量和限制条件概率计算中的父节点数量来提高计算效率。", "conclusion": "分箱半参数贝叶斯网络在结构学习和对数似然估计方面与非分箱半参数贝叶斯网络没有显著差异，但具有显著更高的计算效率。因此，分箱半参数贝叶斯网络证明是一种可靠且更高效的替代方案。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X: 统一空地车辆到万物协作", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "虽然多车辆协作驾驶相比单一车辆自主驾驶具有明显优势，但现有的基于基础设施的V2X系统仍受到大规模部署成本高以及农村和郊区未覆盖区域安全隐患的约束。本研究利用无人驾驶飞行器(UAV)作为固定路边单元(RSU)的灵活替代或补充，提出了AirV2X-Perception数据集，该数据集覆盖了不同天气和光照条件下的城市、郊区和农村环境，为无人机辅助驾驶提供了场景支撑，有助于加快空中辅助自动驾驶系统的发展。", "innovation": "本研究利用无人驾驶飞行器将地面感知和空中感知相结合，提供了独特的优势，如减少障碍物遮挡的鸟瞰视角、动态定位能力以及显著降低的部署成本。该数据集旨在促进和标准化车辆到无人机(V2D)算法的研发和评估，填补了空中辅助自动驾驶系统快速发展中的关键空白。此外，数据集和开发工具包已开源，面向更广泛的社区和研究者提供支持。", "conclusion": "AirV2X-Perception数据集显著推动了车辆到无人机算法的发展与评估，使其成为研究与产业应用的重要资源，有助于加速空中辅助自动驾驶系统的进步。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22698", "html_url": "https://arxiv.org/abs/2506.22698", "title": "人类与人工智能的文本生成与理解：跨学科研讨会报告", "title_en": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report", "authors": "Emily Dux Speltz", "background": "本次报告综合了一项最近的跨学科研讨会的结果，研讨会聚集了认知心理学、语言学习以及基于人工智能（AI）的自然语言处理（NLP）领域的领先专家。研讨会由国家科学基金会资助，旨在弥合我们对AI语言模型与人类认知过程在文本理解和创作关系上的理解差距。与会者通过跨认知、语言和技术视角的协作对话，探讨了人类生成和理解文本所涉及的基本过程，以及AI如何不仅提供对我们认知过程的理解，还能增强人类能力。会议揭示了大型语言模型（LLM）与人类认知之间的关系模式，特别是在模型接受人类反馈微调后，LLM的行为与人类语言处理越来越趋于一致。", "innovation": "研讨会上最突出的发现包括LMLs在揭示人类语言处理方面的潜力，在经过人类反馈微调后，LLM的行为越来越与人类语言处理相一致，以及在语言任务中的人机协作带来的机遇和挑战。这些发现将指导未来在认知心理学、语言学和教育领域的LLM研究、开发和实施。", "conclusion": "该报告强调了在语言任务中促进人类与AI合作以增强人类在文本理解和生成能力时需要考虑到的伦理考量和技术责任，并呼吁通过有效的协作来提升人类在文本理解与生成方面的能力。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22403", "html_url": "https://arxiv.org/abs/2506.22403", "title": "HyperCLOVA X THINK 技术报告", "title_en": "HyperCLOVA X THINK Technical Report", "authors": "NAVER Cloud HyperCLOVA X Team", "background": "介绍了HyperCLOVA X THINK，这是HyperCLOVA X系列中的第一个专注于推理的大型语言模型，它在大约6万亿高质量的韩语和英语 token 上进行了预训练，并结合了目标定向合成的韩语文本数据。该模型采用了计算和内存平衡的Peri-LNTransformer，通过三个阶段的课程预训练，并扩展上下文窗口到128K token。它还通过验证奖励支持的强化学习进行监督微调，支持详细推理和简洁回答模式。该模型在韩国相关的基准测试如KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench上表现与尺寸相近的模型相当，同时保持了稳健的双语一致性和平译质量。另外，其视觉增强变体在KCSAT STEM基准测试上匹配或超过GPT-4.1，所有这些都在比现有相似尺寸模型更低的训练计算资源下实现。", "innovation": "该模型克服了现有大模型的局限，通过在计算和内存平衡的Transformer中实施Peri-LN架构，并采用特定阶段的预训练方法，扩展上下文窗口，提高了模型的推理性能。它还通过验证奖励支持的强化学习方法进行监督微调，实现了详细推理和简洁回答模式。此外，它在资源和计算效率上表现出优异性，实现了更好的性能水平，同时保持了稳健的双语一致性和平译质量，以及视觉增强能力在特定任务上的优越表现。", "conclusion": "HyperCLOVA X THINK被定位为韩国AI创新的坚实基础，并作为一个宝贵的全球研究资源。研究团队还提出了剪枝和蒸馏技术，这将应用于HyperCLOVA X THINK以开发一个开源和商业友好的基础模型。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22554", "html_url": "https://arxiv.org/abs/2506.22554", "title": "Seamless Interaction: 滑畅的互动 - 双人多模态运动建模与大规模数据集", "title_en": "Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset", "authors": "Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Rakesh Ranjan,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer", "background": "人类沟通涉及复杂的口头和非口头信号的相互作用，这对于传达意义和实现人际目标至关重要。为了开发具有社会智能的人工智能技术，开发能够理解和生成双方行为动态的模型至关重要。为此，我们介绍了Seamless Interaction数据集，这是一个包含超过4000个小时的互动视频片段的大规模集合，来自4000多名在多样化背景下的参与者。这个数据集为开发理解双方身体动态的人工智能技术提供了可能，从而推动了虚拟代理、远程存在经验和多模态内容分析工具的进步。", "innovation": "我们开发了一套模型，利用数据集生成与人类语言对应的双人运动手势和面部表情，并能输入对话双方的声音和视觉行为作为输入。我们提供了一个使用语言大模型声音版本和2D/3D渲染方法的变体，这让我们更接近具有互动性的虚拟代理。此外，我们描述了可控制的运动模型变体，可以适应情感反应和表达性水平，并生成更具语义相关性的手势。我们还讨论了评估这些双人运动模型质量的方法，这表明这些模型在更直观和响应式的人机互动中的潜力有所提高。", "conclusion": "这些双人运动模型展示了更直观和响应式的人机交互的潜力，推动了虚拟代理、远程存在经验和多模态内容分析工具的发展。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22832", "html_url": "https://arxiv.org/abs/2506.22832", "title": "VLMs中基于监听者的图像偏好推理增强", "title_en": "Listener-Rewarded Thinking in VLMs for Image Preferences", "authors": "Alexander Gambashidze,Li Pengyi,Matvey Skripkin,Andrey Galichin,Anton Gusarov,Konstantin Sobolev,Andrey Kuznetsov,Ivan Oseledets", "background": "训练能够抵抗泛化的稳健且通用的奖励模型对于使文本到图像和文本到视频生成模型与人类意图保持一致至关重要。然而，当前的奖励模型往往缺乏泛化能力，并且监督微调会导致记忆现象，必须依赖复杂的标注流水线。尽管强化学习（RL），特别是组相对策略优化（GRPO），可以改善泛化能力，但研究人员发现一个关键问题：当一个模型的推理过程与其独立的视觉-语言模型（“监听者”）的推理过程相矛盾时，其推理准确率会出现显著下降。为了应对这个问题，该研究提出了一种“监听者增强”的GRPO框架，通过重新评估推理者的推理链以提供密集且校准的置信分数，从而塑造RL奖励信号，促使推理者不仅给出正确答案，还能以说服独立模型的方式进行解释。听众导向的奖励方案在ImageReward基准测试上实现了最高的准确率（67.4%），显著提高了大型人类偏好数据集（1.2M票）的泛化性能，相较于基础模型提升了6%以上，并且减少了与强大GRPO和SFT基线对比时的推理矛盾。", "innovation": "该研究提出了一种基于监听者的GRPO框架，该框架通过独立的视觉-语言模型重新评估推理者的推理过程，提供密集且校准的置信分数，将这种反馈整合到RL奖励信号中。这种方法不仅提高了推理者的准确率，还鼓励其生成能够说服独立模型的解释，从而提供了一个可扩展且数据效率高的方法来使视觉-语言模型符合细微的人类偏好。", "conclusion": "研究结果表明，基于监听者的奖励方案为将视觉-语言模型与微妙的人类偏好对齐提供了一条可扩展且数据高效的途径。该团队已开源其推理模型，请访问此链接：this https URL."}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22523", "html_url": "https://arxiv.org/abs/2506.22523", "title": "为生成式AI进行红队测试：在学术医疗中心完成的一项版权集中测试报告", "title_en": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center", "authors": "James Wen,Sahil Nalawade,Zhiwei Liang,Catherine Bielick,Marisa Ferrara Boston,Alexander Chowdhury,Adele Collin,Luigi De Angelis,Jacob Ellen,Heather Frase,Rodrigo R. Gameiro,Juan Manuel Gutierrez,Pooja Kadam,Murat Keceli,Srikanth Krishnamurthy,Anne Kwok,Yanan Lance Lu,Heather Mattie,Liam G. McCoy,Katherine Miller,Allison C. Morgan,Marlene Louisa Moerig,Trang Nguyen,Alexander Owen-Post,Alex D. Ruiz,Sreekar Reddy Puchala,Soujanya Samineni,Takeshi Tohyama,Varun Ullanat,Carmine Valenza,Camilo Velez,Pengcheng Wang,Anna Wuest,Yuxiang Zhou,Yingde Zhu,Jason M. Johnson,Naomi Lenane,Jennifer Willcox,Francis J. Vitiello,Leo Anthony G. Celi,Renato Umeton", "background": "在医疗领域部署生成式人工智能（AI）引发了版权合规方面的担忧。dana-Farber癌症研究所利用OpenAI模型推出了一个称为GPT4DFCI的内部生成AI工具，并获得企业范围内用于研究和运营的批准。鉴于工具在组织内的广泛采用、研究使命以及微软OpenAI产品的共同责任模型要求，需要进行严格的版权合规测试，以确保在生成AI使用过程中遵守相关法规。因此，研究所在2024年11月制定了一个结构化的红队测试计划，包括42名来自学术、工业和政府机构的参与者，共同测试GPT4DFCI提取受版权保护内容的能力。测试结果显示，通过对文学作品、新闻文章、科学出版物和受限制访问的临床笔记的间接提示策略，文学内容被成功提取，而新闻文章和科学出版物的提取则未能成功。临床笔记测试表明适当的隐私保护措施已经实施，未发现内容复制问题。这些发现揭示了生成式AI在版权合规方面存在的具体漏洞，凸显了需要对其实施持续测试和合规性检查的必要性。", "innovation": "该研究实施了系统化的红队测试，针对生成式AI中的版权合规问题，发现并提出了具体的缓解策略。这包括在GPT4DFCI中引入一项专门针对版权的元提示，该策略自2025年1月起得以实施。这些策略有助于学术医疗机构在使用生成式AI时确保法律和伦理合规性，为其他机构提供了有效的参考框架。这表明，通过持续的测试和反馈机制，可以在生成式AI的实际应用中更好地管理版权问题。", "conclusion": "系统化的红队测试揭示了生成式AI在版权合规方面的具体漏洞，并提出了针对这些漏洞的实质性缓解策略。学术医疗机构在部署生成式AI时，必须实施持续的测试程序，以确保遵守法律和道德规范。这具有重要的实践指导意义，有助于提高生成式AI技术在医疗领域的应用和可靠性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22968", "html_url": "https://arxiv.org/abs/2506.22968", "title": "反对'文化软化'现象", "title_en": "Against 'softmaxing' culture", "authors": "Daniel Mwesigwa", "background": "这项论文探讨了AI模型如何正在消除文化的多样性，并将其简化为通用的表达形式，作者将这一现象称为'文化软化'。论文指出，这一现象对当前AI评价构成了根本性的挑战，并强调改善和强化文化的评价方式对于大型AI系统的文化对齐至关重要。同时，论文指出，机器学习和人机交互的方法在文化评价上存在局限性，需要进行两项关键的概念性转变。首先，应将文化问题置于评价过程的时间维度中去考虑；其次，虽然承认文化的普遍性存在，但更重要的是要将它们置于具体背景中进行考量，这样才会超越技术要求，更好地理解文化的复杂性。", "innovation": "作者提出了两项关键的概念转变，一是改变文化评价的思考方式，而非首先询问文化是什么，而应思考文化在何时体现；二是承认文化普遍性存在的同时，实际挑战在于将其置于具体的语境当中进行考量，而非仅仅描述它们。这些新的思考方式旨在促进更加符合文化复杂性的评价方法，超越技术要求的局限性。", "conclusion": "本文通过引入两项新的概念性转变——时间和具体背景——强调文化评价不应局限于技术要求，而应寻求更复杂、更适应文化特性的评价方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23137", "html_url": "https://arxiv.org/abs/2506.23137", "title": "基于语义感知的流调控评分方法对知识图谱补全的应用", "title_en": "Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion", "authors": "Siyuan Li,Ruitong Liu,Yan Wen,Te Sun", "background": "知识图谱完成（KGC）的关键在于多面关系的有效建模。然而，现有大多数方法依赖于静态的嵌入式评分，存在无法捕捉上下文依赖性和关系动态性的内在局限.", "innovation": "本文提出了流调控评分（FMS）框架，该框架包括两个主要部分：（1）语义背景学习模块，用于编码上下文敏感实体表示；（2）条件流匹配模块，用于学习以上述上下文为指导，从主头到尾部嵌入的动态转换。这种上下文指导下的预测向量场代表了上下文化的关系路径，实现了初始静态评分的动态优化。通过对多个标准基准的全面评估，表明该方法优于先前的最优结果.", "conclusion": "FMS通过结合上下文意识的静态表示和条件动态信息，促进了关系语义的更深入建模。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22704", "html_url": "https://arxiv.org/abs/2506.22704", "title": "超出代码范畴：大型语言模型在软件开发中的多维度影响", "title_en": "Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development", "authors": "Sardar Bonabi,Sarah Bana,Vijay Gurbaxani,Tingting Nian", "background": "大型语言模型（LLM）有望显著影响软件开发，特别是在开源软件（OSS）领域。本文首先概述了LLM可能通过代码开发、知识转移和技能提升对OSS的影响机制，然后通过一项自然实验——意大利暂时禁止使用ChatGPT——来实证考察LLM在这三个关键领域的具体影响。该实验使用差异性分析框架，分析了来自意大利、法国和葡萄牙88,022名GitHub开源开发者的数据。研究结果表明，访问ChatGPT可以提高开发者生产力6.4%，知识分享增加9.6%，技能获取增加8.4%。这些益处根据不同经验水平的开发者而异：初学者主要受益于生产力的提升，而有经验的开发者则更多地受益于知识共享的改进和技能获取的加速。此外，研究发现，LLM辅助学习具有高度的上下文依赖性，在技术复杂、碎片化或快速发展的场景中，所产生的益处最大。", "innovation": "本文通过一项自然实验考察了大型语言模型对开源软件开发的具体影响，使用差异性分析框架（Difference-in-Differences framework）分析来自三个相似国家的数据；此外，研究还指出，LLM的影响不仅限于直接的代码生成，还包括增强的协作学习和知识交流，这对全面理解LLM的影响至关重要。另外，研究还强调了LLM对不同经验水平开发者的影响差异，以及对技术复杂场景下的高效益利用。", "conclusion": "本文的研究结果提出了关键的管理启示：战略性地部署大型语言模型可以加速新手开发者的入职和提高生产力，支持中级开发者促进知识共享和协作，并支持快速技能获取，从而整体上提升组织的长期生产力和灵活性。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23815", "html_url": "https://arxiv.org/abs/2506.23815", "title": "AI对教育评估的影响：一种建构性对齐框架", "title_en": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment", "authors": "Patrick Stokkink", "background": "随着人工智能（AI）尤其是大规模语言模型（LLM）在教育领域的影响力持续增加，当前的评估方式可能不再适用于评估学生的学习成果和理解能力。因此，教育和评估需要适应AI的存在，特别是评估方法是否允许使用AI存在分歧。为了达到这一目的，该论文基于建构性对齐（CA）理论和布鲁姆分类法，探讨了AI如何影响不同布鲁姆层次的学习目标，并提出了适应性评估方法建议。", "innovation": "该论文提出了一个基于建构性对齐理论和布鲁姆分类法的框架，探讨了AI如何影响不同学习目标层次，强调了教学人员需要了解AI工具的能力和局限性，进而更好地调整评估方法。该论文提出了一种结构化指南建议，以促进教职员工之间的对齐。", "conclusion": "该论文指出，为了更好地适应AI在教育中的应用，评估方法应该与教学目标对齐，包括形成性和总结性的评估都应考虑关于AI使用的立场一致性。此外，教学人员需要接受培训，了解AI工具的能力和局限性，从而更好地调整他们的评估方法。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23431", "html_url": "https://arxiv.org/abs/2506.23431", "title": "流水线解码器用于高效上下文感知文本生成", "title_en": "Pipelined Decoder for Efficient Context-Aware Text Generation", "authors": "Zixian Huang,Chenxu Niu,Yu Gu,Gengyang Xiao,Xinwei Huang,Gong Cheng", "background": "作为生成式AI的基础，自回归模型需要根据所有之前生成的令牌来生成新的令牌，这虽然保证了高质量但同时也限制了模型只能按顺序生成，形成了限制生成速度的瓶颈。现有的解码器架构无法实现在上下文感知文本生成任务中并行生成文本，从而导致速度受限。", "innovation": "本文提出了一种新的流水线解码器架构，该架构可以高效地并行生成文本。流水线解码器同时启动多个子序列的生成，并在每一时间步骤中为每个子序列生成一个新令牌以实现并行化。实验在包括问答、文本总结和关键词生成等多个文本生成任务上表明，本文提出的流水线解码器显著提升了生成速度，且在生成质量上没有明显的损失，同时也没有增加内存消耗。", "conclusion": "本文提出的流水线解码器架构显著提高了并行生成文本的效率，适用于多个文本生成任务，同时在生成质量和内存消耗上保持了良好的平衡。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00163", "html_url": "https://arxiv.org/abs/2507.00163", "title": "将提示视为科学探究", "title_en": "Prompting as Scientific Inquiry", "authors": "Ari Holtzman,Chenhao Tan", "background": "提示是研究和控制大型语言模型的主要方法，也是一个非常强大的工具。几乎所有的大型语言模型的能力，如少样本学习、推理和宪法AI，都是通过提示首次得以解锁。然而，提示通常不被视为科学研究，并常被视为一种神秘的技艺，遭到诟病。本文作者认为这是对提示角色误解。作者提出，如果将大型语言模型视为一种新的复杂和透明的有机体，而不是程序，那么提示实际上是一个行为科学，而不是一个解决方案.", "innovation": "本文作者将提示方法视为一种行为科学，这为理解大型语言模型提供了全新的视角，打破了将提示视为神秘技艺的传统观念。这种新的理解方式强调提示在大型语言模型研究中的重要性，也是对提示科学地位的一种创新认可.", "conclusion": "提示不仅是大型语言模型研究和控制的重要方法，而且是这些模型科学分析的关键组成部分。提示不仅不是低劣的方法，而是行为科学，它能够探查模型的语言界面，类似于机制可解释性研究中的神经基础探查，提示的研究是大型语言模型科学研究的重要组成部分."}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23952", "html_url": "https://arxiv.org/abs/2506.23952", "title": "设计中的自主权：在AI决策支持中保护人类自主权", "title_en": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "authors": "Stefan Buijsman,Sarah Carter,Juan Pablo Bermúdez", "background": "随着AI系统在专业、技能和个人领域支持人类决策方面的作用日益增强，尽管已有研究探讨了AI可能对全球人类自主权的影响，但针对特定领域的自主权——即在特定技能或专业知识范围内自我治理行动的能力——的研究仍然不足。我们通过分析医学、金融和教育领域的实证案例，考察AI决策支持系统如何影响专业知识能力和真实的价值观形成，进而揭示缺失可靠故障指标和潜在价值观无意识转变可能导致的自主权流失问题。", "innovation": "我们提出了一个构建自主权保护的AI支持系统框架，包括细致的角色说明、失效机制的实施和促进反思性实践的具体社会技术设计模式。这些设计模式旨在在利用AI能力的同时，保持特定领域的自主权，从而为开发能够增强而非削弱人类在专业领域行为中自决权的AI系统提供具体指导。", "conclusion": "通过该框架，我们可以设计出既能发挥AI优势又能保护人类在专业领域内自主权的AI系统，避免因AI介入而导致的自主权的丧失。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00152", "html_url": "https://arxiv.org/abs/2507.00152", "title": "表理解与（多模态）大型语言模型：科学与非科学数据的跨领域案例研究", "title_en": "Table Understanding and (Multimodal) LLMs: A Cross-Domain Case Study on Scientific vs. Non-Scientific Data", "authors": "Ekaterina Borisova,Fabio Barth,Nils Feldhus,Raia Abu Ahmad,Malte Ostendorff,Pedro Ortiz Suarez,Georg Rehm,Sebastian Möller", "background": "表格广泛应用于科研、商业、医学和教育等领域。尽管大型语言模型（LLMs）在下游任务中表现出色，但它们处理表格数据的效率仍被低估。本文通过跨领域和跨模态评估，研究基于文本和多模态LLMs在表格理解任务中的有效性，包括科学与非科学数据背景下的表格处理以及图像与文本表示的表格处理情况。同时，还进行了可解释性分析以测量上下文使用和输入相关性。", "innovation": "本文首次对多模态LLMs进行跨领域和跨模态的系统评估，并提出了一个新基准——TableEval，包含来自学术出版物、维基百科和财务报告的3017个表格，每个表格以五种不同格式呈现，以验证LLMs在不同表格式下的处理能力。研究表明，尽管LLMs在不同表模态下保持了稳健性，但在处理科学表格时仍面临重大挑战。", "conclusion": "研究结果表明，LLMs在处理不同模态的表格数据时仍具稳健性，但在科学表格方面的处理能力需要进一步提升。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23944", "html_url": "https://arxiv.org/abs/2506.23944", "title": "调整你的身体：减轻模仿学习中的本体感觉偏移", "title_en": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning", "authors": "Fuhang Kuang,Jiacheng You,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao", "background": "传统的机器人任务模仿学习模型通常依赖于多模态输入，比如RGB图像、语言和自身感知状态。虽然自身感知状态对决策制定和障碍规避直观上很重要，但将其全部纳入却意外地降低了模仿学习的性能。研究发现，训练数据和部署数据中自身感知状态分布的显著差异是造成此问题的根本原因，即本体感觉偏移问题。因此，需要一种能够弥合训练和部署状态下分布差异的方法来应对这一挑战，从而提高系统的鲁棒性并确保在实际部署中维持高性能。", "innovation": "该研究提出了一种领域适应框架，通过利用部署期间收集的策略测试数据，并应用Wasserstein距离量化专家级数据和策略测试数据之间本体感觉状态的差异。通过将噪声添加到这两组状态，且比例与Wasserstein距离成正比，以缩小两者的差距，这一策略通过使训练和部署中的分布对齐而提升了系统的鲁棒性。实验证明，该方法可以有效地利用本体感觉信息同时减轻其负面影响，且优于简单的丢弃本体感觉信息的解决方案和旨在解决分布偏移的其他基线方法。", "conclusion": "该方法通过量化和减小本体感觉状态之间的差异，显著提升了在实际部署条件下机器人操作任务中的模仿学习性能。相比直接忽略本体感知的信息或使用其他不同策略处理分布偏移的方法，该策略表现更佳。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23044", "html_url": "https://arxiv.org/abs/2506.23044", "title": "Ovis-U1 技术报告", "title_en": "Ovis-U1 Technical Report", "authors": "Guo-Hua Wang,Shanshan Zhao,Xinjie Zhang,Liangfu Cao,Pengxin Zhan,Lunhao Duan,Shiyin Lu,Minghao Fu,Xiaohao Chen,Jianshan Zhao,Yang Li,Qing-Guo Chen", "background": "介绍了Ovis-U1，这是一个拥有3亿参数的统一模型，融合了多模态理解、文本到图像生成和图像编辑能力。该模型基于Ovis系列构建，采用了扩散机制的视觉解码器和双向令牌精炼器，使其在图像生成任务上能够媲美GPT-4o等顶级模型。与仅使用冻结的语言模型进行生成任务的模型不同，Ovis-U1从语言模型开始使用一个新的统一训练方法，通过结合理解和生成任务实现性能提升。", "innovation": "Ovis-U1 使用了一种新的统一训练方法，从语言模型开始，结合理解和生成任务进行训练，相比单独训练理解或生成任务，这种方法能提高性能。Ovis-U1在OpenCompass 多模态学术基准测试中得分为69.6，超过了Ristretto-3B和SAIL-VL-1.5-2B等最近的先进模型。在文本到图像生成任务中，其在DPG-Bench和GenEval基准测试中的得分分别为83.72和0.89。在图像编辑任务中，其在ImgEdit-Bench和GEdit-Bench-EN基准测试中的得分为4.00和6.42。这些结果显示Ovis-U1在多模态理解和编辑领域的先进性，标志着Ovis统一模型系列的初始版本的创新性突破。", "conclusion": "作为Ovis统一模型系列的初始版本，Ovis-U1在多模态理解、生成和编辑领域展现出了显著的性能，特别是在文本到图像生成和图像编辑任务中达到了最高的基准测试得分，表明了其在该领域的先进性和领先地位。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00216", "html_url": "https://arxiv.org/abs/2507.00216", "title": "跨文化翻译中的风格对齐", "title_en": "Towards Style Alignment in Cross-Cultural Translation", "authors": "Shreya Havaldar,Adam Stein,Eric Wong,Lyle Ungar", "background": "成功的沟通依赖于说话人意图风格（即，说话人想要传达的内容）与听众理解风格（即，听众感知的内容）的一致性。然而，文化差异往往导致两者之间出现失配，例如礼貌常在翻译中丢失。研究发现，大语言模型（LLMs）在翻译风格时偏好中立化，并且在非西方语言中的表现更差。", "innovation": "我们提出了RASTA（检索增强的风格对齐）方法，利用学习到的风格概念来鼓励LLM翻译恰当传达文化沟通规范并保持风格一致。", "conclusion": "这种新颖的方法有助于改进跨文化翻译中的风格一致性问题，特别是在非西方语言中的应用更为显著。"}
{"llm_update_time": "20250702", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23491", "html_url": "https://arxiv.org/abs/2506.23491", "title": "ZonUI-3B:轻量级的用于跨分辨率GUI定位的视觉语言模型", "title_en": "ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "authors": "ZongHan Hsieh,Tzer-Jen Wei,ShengJing Yang", "background": "现有的大规模视觉语言模型（VLM）虽然在图形用户界面（GUI）定位任务中表现优异，但其巨大参数量导致计算成本高昂，不适合消费级硬件使用。因此，需要开发一种轻量级但性能强大的视觉语言模型来满足这一需求，特别是在高分辨率桌面环境中需要有效处理的数据稀缺性问题。ZonUI-3B正是这样的创新成果。", "innovation": "ZonUI-3B通过以下创新点解决了一系列难题：(i) 组合了多平台、多分辨率的24K示例数据集，来源多样，包括移动端、桌面端和网页的GUI截图，有效应对高分辨率桌面环境中的数据匮乏问题；(ii) 采用两阶段微调策略，先进行跨平台训练以建立稳健的GUI理解，再对高分辨率数据进行专门的微调，显著提高模型适应性；(iii) 数据整理和冗余减少策略，表明较小、重复度较低的数据子集可以获得与大量数据相同的效果，强调数据多样性而非数据量。这些创新显著提升了模型的准确性及适应性。", "conclusion": "ZonUI-3B在标准GUI定位基准上的表现优于参数量远超4B的模型，尤其是在高分辨率桌面环境下的性能优势尤为明显，验证了平衡采样和两阶段微调对增强模型稳健性的重要性。该模型在单一RTX 4090显卡上即可完全训练，充分显示了其轻量级设计的优势。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00239", "html_url": "https://arxiv.org/abs/2507.00239", "title": "在对齐的语言模型中线性解码被拒绝的知识", "title_en": "Linearly Decoding Refused Knowledge in Aligned Language Models", "authors": "Aryan Shrivastava,Ari Holtzman", "background": "大多数常用的语言模型（LMs）通过指令调优和强化学习的结合进行微调和对齐，导致模型拒绝执行被认为有害的用户请求。然而，劫持提示可以绕过这些拒绝机制，引发有害的回应。已有研究关注了被拒绝的信息在劫持提示下的可解码性，发现了很多被拒绝的信息是线性可解码的，如通过劫持的LM可以预测多个国家平均智商的数值，相关性达到0.8以上。同时，基模型训练的探针有时可以转移到其指令调优的版本上，揭示了劫持生成的信息，表明许多被拒绝的代表性状在指令调优过程中仍然存在。这些研究结果表明，指令调优并不完全消除或重新定位潜在危害信息，而是抑制了其直接表达，使之仍在剩余的表示空间中位线性可访问和间接影响下游行为提供了条件。", "innovation": "该论文的一项创新在于，研究发现被拒绝的信息可以通过在LM隐藏状态上训练的线性探针进行线性解码，表明指令调优模型在一定程度上仍然保留了这些信息。此外，提出了一种新的观点，即被劫持的LM在生成过程中其实利用了这些被拒绝的信息，这通过与LM生成的对比结果相关联得以证实。", "conclusion": "该研究表明，指令调优并不完全消除有害信息，其主要作用是抑制有害信息的直接表达，但仍使这些信息线性可解码，并在下游任务中间接产生影响。因此，需要进一步关注指令调优模型中潜藏的风险，并采取措施减轻这些风险。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00210", "html_url": "https://arxiv.org/abs/2507.00210", "title": "LineRetriever：面向规划的网页代理观察值减少方法", "title_en": "LineRetriever: Planning-Aware Observation Reduction for Web Agents", "authors": "Imene Kerboua,Sahar Omidi Shayegan,Megh Thakkar,Xing Han Lù,Massimo Caccia,Véronique Eglin,Alexandre Aussem,Jérémy Espinas,Alexandre Lacoste", "background": "大型语言模型在网页导航任务中表现出色，但网页的广泛上下文，通常表示为DOM或Accessibility Tree结构，经常超出模型的上下文限制。当前的方法，如自底向上的截断或基于嵌入的检索，会丢失关于网页状态和行动历史的关键信息。这对于网页代理中的适应性规划特别有害，因为理解当前状态对确定未来动作至关重要。我们假设嵌入式模型缺乏足够的容量来捕捉计划相关的信息，特别是在检索支持未来动作预测的内容时。因此，如何优化检索方法以适应性规划网页导航任务成为了关键问题。", "innovation": "我们提出了LineRetriever，一种新颖的方法，利用语言模型识别和检索对未来导航步骤最相关的观察线。与注重语义相似的传统检索方法不同，LineRetriever明确考虑了规划的范围，优先考虑对于动作预测有贡献的元素。实验结果表明，LineRetriever可以在保持性能一致性的同时减少每一步的观测规模。", "conclusion": "我们的实验表明，LineRetriever可以在每一步减少网页代理的观测规模，同时保持在上下文限制内的性能一致性。这为适应性规划在网页导航任务中的应用提供了一种新的方法。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00244", "html_url": "https://arxiv.org/abs/2507.00244", "title": "形态句法的代数结构", "title_en": "The Algebraic Structure of Morphosyntax", "authors": "Isabella Senturia,Matilde Marcolli", "background": "在数学公式化合并和强极简主义者假说的背景下，本文提出了一种形态语法界面的数学模型。在此框架下，形态学具有负责单词形成的组合性质，并组织成一个形态树的熔岩。然而，语法内部并没有形态学移位。然而，具有拆分公理的存在，但需要将形态树集扩展到传统上仅由熔岩生成的集合之外，扩展为可能的形态学输入的较大集合，以参与形态句法树的形成，作为作为代数和操子代数之间的对应关系。形态句法树的结构形式可借助于这种操子对应的描述，其将形态学和语法数据配对，并考虑形态学拆分的影响。", "innovation": "本文通过引入形态学与句法之间的数学模型，探讨了形态与句法边界的概念，并重新解释了分布式形态学中的一些操作作为允许在形态句法对象内部语法与形态学边境移动的转换。这种理论框架通过操子对的概念提供了形态学与句法间边界灵活移动的数学依据，并增强了对语言结构 formation 的理解与描述能力。", "conclusion": "本文通过代数结构分析了形态学与句法界面的规律性特征，为形态与句法间的转换提供了数学框架。通过操子代数的对应关系理论，阐明了形态与句法的边界可以灵活移动，并解释了分布式形态学中移动这些边界的机制，从而为理解更复杂的语言结构提供了新的视角。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00258", "html_url": "https://arxiv.org/abs/2507.00258", "title": "大型语言模型中微调方法对记忆影响的研究", "title_en": "Impact of Fine-Tuning Methods on Memorization in Large Language Models", "authors": "Jie Hou,Chuxiong Wu,Lannan Luo,Qiang Zeng", "background": "随着预训练大型语言模型（LLMs）能力的不断提升，‘预训练和微调’范式已成为主流，催生了各种微调方法的发展。然而，微调过程中引发的记忆风险尚未引起足够的重视。", "innovation": "本文对流行的微调方法进行了分类，并通过成员身份推断攻击（MIAs）的角度评估它们对记忆的影响。研究表明，与基于参数的微调相比，基于提示的微调在MIA脆弱性方面表现更优，同时记忆保持较低，不随模型规模变化。这一发现表明基于参数的微调更容易泄露私人信息，基于提示的微调则是一种更隐私保护的选项。", "conclusion": "总的来说，基于提示的微调方法对隐私保护更为有利，而基于参数的微调则更易泄露私人信息。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00246", "html_url": "https://arxiv.org/abs/2507.00246", "title": "EfficientXLang: 通过跨语言推理提高标记效率", "title_en": "EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning", "authors": "Sanchit Ahuja,Praneetha Vaddamanu,Barun Patra", "background": "尽管最近在语言推理模型(LRMs)方面取得了进展，但大多数研究仍然仅限于英语，尽管许多模型是基于多语言数据预训练的。这项工作研究了非英语语言在推理中的效率，特别是在减少标记使用方面是否保持准确度，并探讨了多语言推理的实际优点.", "innovation": "实验评估了三种开源RLMs(DeepSeek R1, Qwen 2.5 和 Qwen 3)，在四种数学数据集和七种类型多样的语言中进行推理。发现推理在非英语语言中不仅减少了标记使用，还保持了准确度。这些改进在翻译推理轨迹成英语后仍持续存在，这表明了真正的推理行为改变，而非表层语言效应。研究结果强调了多语言推理的优势及强大的多语言基础的重要性，扩展了对语言模型推理的看法.", "conclusion": "研究结果表明，非英语语言在推理中不仅减少了标记使用，还保持了准确度。这些发现拓宽了关于语言模型推理的看法，强调了多语言推理的价值及建立强大的多语言基础的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00330", "html_url": "https://arxiv.org/abs/2507.00330", "title": "在冷启动场景中为联合实例和标签选择建模数据多样性", "title_en": "Modeling Data Diversity for Joint Instance and Verbalizer Selection in Cold-Start Scenarios", "authors": "Mohna Chakraborty,Adithya Kulkarni,Qi Li", "background": "基于提示的方法利用了预训练语言模型（PLMs）所蕴含的知识，该模型是基于掩码语言模型（MLM）目标训练的；然而，这些方法在模板、标签器和少量示例的选择上对这些因素很敏感，尤其是在没有标注数据的冷启动设置中。现有研究忽视了实例与标签器之间的依赖关系，即实例-标签概率取决于标签器词元在嵌入空间中的临近程度。", "innovation": "作者提出了COLDSELECT，这是一种联合标签器和实例选择方法，用于建模数据多样性。COLDSELECT将PLM词汇表和$h_{[MASK]}$嵌入映射到共享空间，并应用降维和聚类确保选择的高效性和多样性。通过优化最小不确定性与最大化多样性，COLDSELECT能够有效地捕捉数据关系。", "conclusion": "在八个基准测试上的实验表明，COLDSELECT在减少不确定性增强泛化方面优于基准方法，在标签器和少量示例选择方面在冷启动场景中表现更佳。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00297", "html_url": "https://arxiv.org/abs/2507.00297", "title": "非洲语言的自然语言处理", "title_en": "Natural language processing for African languages", "authors": "David Ifeoluwa Adelani", "background": "近年来，基于大量未标记数据和自监督学习的词嵌入和语言模型在自然语言处理（NLP）中的性能得到了显著提升。多语言模型通常在诸如维基百科之类的网络数据上进行训练，但这些模型面临着一些挑战，包括低资源语言的参与度不足、数据质量较差以及缺乏标记数据集的评估难题，特别是在像英语这样的高资源语言之外的语言中。本论文的重点是撒哈拉以南非洲地区的语言，这些语言在标签数据的可用性和网络上找到的未标记数据方面都可被视为低资源语言。论文分析了公开可用语料库中的噪声，并制作了一个高质量的数据集，表明词嵌入中学习的语义表示的质量不仅取决于数据量，还取决于预训练数据的质量。作者通过实验证明了词嵌入的局限性以及多语言预训练语言模型（PLM）在未见过的语言和低资源场景中的机会。此外，作者研究了如何使用少量单语文本将多语言PLM适应和专门化为未见过的非洲语言。为了解决非洲语言在NLP研究中的代表性不足，作者为21种非洲语言开发了大规模的人工标注数据集，用于两个重要的NLP任务：命名实体识别和机器翻译。论文在监督、弱监督和迁移学习的不同场景下进行了广泛的实证评估，使用了最先进的方法。", "innovation": "1. 分析并展示了公共语料库中的噪声，并制作了一个高质量的数据集，证明了词嵌入中学习的语义表示的质量不仅取决于数据量，还取决于预训练数据的质量。\n2. 实证展示了词嵌入的局限性以及多语言预训练语言模型（PLM）在未见过的语言和低资源场景中的优势。\n3. 研究了如何使用少量单语文本将多语言PLM适应和专门化为未见过的非洲语言。\n4. 为21种非洲语言开发了大规模的人工标注数据集，针对两个重要的NLP任务：命名实体识别和机器翻译，填补了这些语言在NLP研究中的数据空白。\n5. 开展了广泛的实证评估，利用最先进的方法在不同场景下进行测试，包括监督、弱监督和迁移学习，验证了方法的有效性。", "conclusion": "本论文通过实证研究展示了词嵌入和多语言预训练语言模型在非洲低资源语言中的应用潜力，特别是在命名实体识别和机器翻译等关键任务上的成就。研究不仅提升了非洲低资源语言在NLP中的适用性和性能，还为未来在这些语言上的进一步研究和应用奠定了坚实的基础。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00214", "html_url": "https://arxiv.org/abs/2507.00214", "title": "基于LLM生成推理的两阶段学习：利用生成推理改进分类", "title_en": "Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning", "authors": "Mads Henrichsen,Rasmus Krebs", "background": "标准分类模型通常直接将输入映射到标签，而没有显式推理的过程，这可能限制了它们的性能、鲁棒性和可解释性。本文介绍了一种新的两阶段方法，通过利用大型语言模型（LLM）生成的推理来增强文本分类。首先，使用LLM对一个通用推理数据集进行微调，生成给定问题和答案的文本推理。然后，使用训练后的LLM创建下游生成模型的增强训练数据集。下游模型被训练以直接输出推理和预测情感。实验表明，这种生成模型的准确率（情感预测）相比仅输出情感的基准生成模型提高了8.7个百分点，表明推理生成的强大泛化能力和显式推理培训的优势。", "innovation": "本文提出了一种新的两阶段方法，通过利用大型语言模型（LLM）生成的推理来增强文本分类。第一阶段，使用给定推理数据集对LLM进行微调以生成推理。第二阶段，使用训练后的LLM生成的推理来增强下游生成模型的训练数据集，使下游生成模型不仅能够直接输出情感，还能输出推理。这种方法在情感分类数据集上展示了显著的性能提升，证明了LLM生成推理在创建更丰富的训练数据集方面的潜力，从而提高多种下游NLP任务的性能，并提供显式的解释。", "conclusion": "研究表明，整合生成推理的生成模型在情感预测上的改进达到了8.7个百分点，突显了生成推理在分类任务中的强泛化能力和显式推理培训的优势。这项工作表明LLM生成推理有可能创建更丰富的训练数据集，从而提高各下游NLP任务的性能，并提供显式的解释。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00355", "html_url": "https://arxiv.org/abs/2507.00355", "title": "多跳问题分解与检索增强生成", "title_en": "Question Decomposition for Retrieval-Augmented Generation", "authors": "Paul J. L. Ammann,Jonas Golde,Alan Akbik", "background": "通过将大型语言模型（LLMs）与可验证的外部数据源结合，可以生成可靠的回复。检索增强生成（RAG）是这种方法之一，在问题回答等任务中特别有效，它通过检索与问题语义相关的片段来辅助模型生成答案。然而，对于涉及多个文档的多跳问题，如“2023年NVIDIA、苹果和谷歌中哪一家公司获利最多？”，标准的RAG难以有效地检索到足够的信息，因为它无法直接合并来自多个文档的相关事实。因此，需要提出能够处理多跳问题的新方法来改进标准RAG的性能。", "innovation": "本文提出了一个基于问题分解的RAG管道：首先使用LLM将原始查询分解为子问题，然后为每个子问题检索相关片段，最后对候选片段进行重新排序以提高检索的覆盖范围和精确度。该方法展示了在解决多跳问题上，利用问题分解和重新排序可以有效结合多个文档，并减少噪音，提高最相关片段的质量，进而提高问题回答的准确性和效率。值得注意的是，通过使用现成的交叉编码器重新排序器与LLM驱动的问题分解结合，可以在不需额外训练或特殊索引的情况下显著提升RAG在多跳问题上的表现。", "conclusion": "本文评估了该方法在MultiHop-RAG和HotpotQA数据集上的表现，结果显示相比于标准RAG基线，改进的方法在检索性能（MRR@10提升了36.7%）和答案准确性（F1提升了11.6%）上都有显著提高，并证明了该方法作为一种无需额外训练和专用索引的实用增强方案的效果。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00439", "html_url": "https://arxiv.org/abs/2507.00439", "title": "超越社会人口学提示：使用监督使LLMs与人类反应分布对齐", "title_en": "Beyond Sociodemographic Prompting: Using Supervision to Align LLMs with Human Response Distributions", "authors": "Gauri Kambhatla,Sanjana Gautam,Angela Zhang,Alex Liu,Ravi Srinivasan,Junyi Jessy Li,Matthew Lease", "background": "准确预测不同人群群体对主观问题的回答具有重大价值。本文展示了相对简单的监督方法可以显著提高语言模型与多样化人口群体的一致性，这种一致性通过跨越不同主题的三个数据集进行评估。除了评估平均表现外，文章还报告了特定群体之间的一致性如何变化。文章的简单性和普适性促进了其易于采用，而其广泛的发现则为何时使用或不使用这种方法提供了有用的指导。通过在许多LLM和提示策略上进行评估，并公开发布工作，文章提供了一个有用的基准，以刺激未来的研究。", "innovation": "本文提出了一种相对简单的监督方法，该方法能显著提高语言模型与多样化人口群体的一致性。这种方法适用于广泛的主题，并且提供了一种基准，有助于未来的研究。", "conclusion": "简单且通用的方法使其易于采用，广泛的发现提供了有用的实际应用指导。公开的工作和多种语言模型与提示策略的评估为未来研究提供了有用的参考基准。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00322", "html_url": "https://arxiv.org/abs/2507.00322", "title": "故障干扰：当故障机制覆盖有效机制时，语言模型在生成平衡括号时出错", "title_en": "Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones", "authors": "Daking Rai,Samuel Miller,Kevin Moran,Ziyu Yao", "background": "尽管编码能力取得了显著进展，语言模型（LMs）在生成平衡括号等简单的句法任务上仍然表现不佳。本研究调查了不同规模（124M-7B）的LMs中存在的错误背后的机制，以期理解并减轻这些错误。研究表明，语言模型依赖于多个独立进行预测的组件（注意力头部和FF神经元）。这些组件中有部分能够可靠地在多种输入条件下提供正确答案（即，实施“有效机制”），而其他部分则不可靠并引入错误（即，实施“故障机制”），导致错误发生的原因是“故障机制”会覆盖并主导“有效机制”给预测带来的影响。", "innovation": "本文介绍了一种名为RASteer的调控方法，用于系统地识别并增加可靠组件的贡献，以提升模型性能。RASteer在平衡括号任务中显著提高了模型性能，使部分模型的准确率达到约100%，且未损害模型的普遍编程能力。此外，进一步展示了其在算术推理任务中的广泛适用性，实现了性能提升约20%的效果。", "conclusion": "RASteer方法显著改善了语言模型在生成平衡括号任务中的表现，提升了部分模型的准确性至约100%，并在算术推理任务上也显示出约20%的性能提升。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00460", "html_url": "https://arxiv.org/abs/2507.00460", "title": "使用开放基准评估语言模型的缺陷", "title_en": "Pitfalls of Evaluating Language Models with Open Benchmarks", "authors": "Md. Najib Hasan(1),Mohammad Fakhruddin Babar(2),Souvika Sarkar(1),Monowar Hasan(2),Santu Karmaker(3) ((1) Wichita State University, (2) Washington State University, (3) University of Central Florida)", "background": "开放的大语言模型（LLM）基准测试，例如HELM和BIG-bench，为语言模型（LMs）的公平比较、可重复性和迭代进步提供了标准化和透明的协议。然而，开放性也引入了重要的且未充分探索的问题。本研究通过系统地构建了“作弊”模型——直接在公开测试集上微调BART、T5和GPT-2的小型变体，并在著名开放基准测试HELM中取得高排名，但表现出不理想的一般化能力和有限的实用性，揭示了这些问题。", "innovation": "研究通过构建利用公开测试集微调更小型模型的作弊模型，挑战了开放基准测试中领先排名的真实性和实用性，提出了高排行榜成绩不总是反映现实世界效果的观点，并强调必须结合私有或动态基准来保证评估的完整性，从而推动LM评估方法的基本重新评估，确保更可靠的评估结果。", "conclusion": "高排名在开放基准中的LM可能并不总是反映其实际效果。为了确保LM评估的稳健性和可靠性，必须使用私有或动态基准来补充开放评估。同时，需要重新评估现有的基准评估方法。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00389", "html_url": "https://arxiv.org/abs/2507.00389", "title": "使用大型语言模型进行因果提示的隐含情感分析", "title_en": "Causal Prompting for Implicit Sentiment Analysis with Large Language Models", "authors": "Jing Ren,Wenhao Zhou,Bowen Li,Mujie Liu,Nguyen Linh Dan Le,Jiade Cen,Liping Chen,Ziqi Xu,Xiwei Xu,Xiaodong Li", "background": "隐含情感分析（ISA）旨在推断未明确表达的情感，这需要模型进行更深层次的推理以理解微妙的上下文线索。最近，使用大型语言模型（LLMs）的基于提示的方法在ISA中显示出潜力，但这些方法经常依赖于在链式思维（CoT）推理路径上进行多数投票，而不评估其因果有效性，这使它们容易受到内部偏见和虚假关联的影响。针对这一挑战，我们提出了CAPITAL，这是一种因果提示框架，其中融入了前端门调整以改进CoT推理。CAPITAL将整体因果效应分解为两个组成部分：输入提示对推理链的影响，以及这些链对最终输出的影响。这些部分使用基于编码器的聚类和NWGM近似进行估计，并使用对比学习目标来更好地使编码器的表示与LLM的推理空间对齐。在三个LLM的基准ISA数据集上的实验表明，CAPITAL在准确性和鲁棒性方面都优于强大的提示基线，特别是在对抗条件下更具优势。这项工作提供了一种将因果推理整合到LLM提示中的规范方法，并强调了其在情感推理中的优势，尤其是意识偏见方面。公开代码和案例研究可以在该网址获取：this https URL", "innovation": "提出的CAPITAL框架将前端门调整融入CoT推理中，通过将整体因果效应分解为客户端输出和生成输出的影响来进行因果推理。这种方法使用基于编码器的聚类和NWGM近似估计因果效应，并通过对比学习目标来提高编码器表示与LLM推理空间的匹配度。该框架在三个基准ISA数据集上得到了实验证明，表现优于现有基线方法，尤其是在对抗性条件下的表现更为出色。这种因果推理方法为LLM提示提供了更为规范的集成方式，并揭示了其在情感分析中的潜在好处，尤其是在减少偏见方面。", "conclusion": "本研究提出了CAPITAL框架，成功地将因果推理算法应用于基于LLM的ISA，显著提高了情感分析的准确性和鲁棒性，特别对对抗条件下的表现有显著改善。该方法对于开发更可靠和无偏的SSL和NLP模型具有重要贡献和启示。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00547", "html_url": "https://arxiv.org/abs/2507.00547", "title": "算法应用中的方法论严谨性：话题建模算法的实例说明", "title_en": "Methodological Rigour in Algorithm Application: An Illustration of Topic Modelling Algorithm", "authors": "Malmi Amadoru", "background": "随着高级计算算法的发展，研究方法正朝着计算密集型研究方向迈进，这为理论开发开辟了新的途径。然而，这些算法的不透明性以及其应用时缺乏透明度和严谨性构成了新的方法论挑战，可能削弱研究的信任度。关于这一新领域研究方法论严谨性的讨论仍在发展中。", "innovation": "本文试图提供有关在话题建模算法应用中确保方法论严谨性的指导，通过实例说明结构化话题建模算法的应用，并提出了一套指导原则。这些原则不仅适用于话题建模算法，还可以根据具体情况应用于其他算法。特别地，该建议将为初学者提供帮助，并且对处理相关研究手稿的编辑和审稿人也具有价值。", "conclusion": "本文补充了关于话题建模的研究文献，并加入了关于计算密集型理论构建领域方法论严谨性讨论的行列。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00601", "html_url": "https://arxiv.org/abs/2507.00601", "title": "基于提示和对齐的低资源LLM任务可转移建模策略", "title_en": "Transferable Modeling Strategies for Low-Resource LLM Tasks: A Prompt and Alignment-Based", "authors": "Shuangquan Lyu,Yingnan Deng,Guiran Liu,Zhen Qi,Ruotong Wang", "background": "在低资源语言场景中，现有的大型语言模型存在知识迁移和适应能力有限的问题。因此，针对这一挑战，本文提出了一种结合知识转移模块与参数高效微调策略的统一框架，旨在增强模型在任务和语言转换中的泛化能力和训练稳定性，尤其是在数据稀缺的情况下，该方法能有效提升大型语言模型在多语言预训练模型和主流迁移方法中的性能和稳定性。", "innovation": "该研究提出了一种新的框架，通过结合知识转移模块和参数高效微调策略，引入了知识对齐损失和软提示微调等技术，来指导模型在稀少标注条件下有效吸收目标语言或任务的结构特征。框架内还包含轻量级的适应模块，以降低计算成本。研究还通过稳定性分析实验和合成伪数据转移实验，系统地评估了该方法在不同低资源任务中的适用性和鲁棒性，结果表明该方法在MLQA、XQuAD和PAWS-X等跨语言任务中表现优异，尤其在数据极度稀缺情况下优势更加突出。", "conclusion": "本文提出的方法具有较强的通用性和扩展性，能在保持大型语言模型一般能力的同时增强其特定任务的适应性，非常适合复杂的语义建模和多语言处理任务。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00579", "html_url": "https://arxiv.org/abs/2507.00579", "title": "TUM-MiKaNi在SemEval-2025任务3中的表现：向着多语言和知识驱动的非事实妄想识别", "title_en": "TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification", "authors": "Miriam Anschütz,Ekaterina Gikalo,Niklas Herbster,Georg Groh", "background": "大语言模型（LLMs）的妄想是一个主要问题，影响它们的信任度和广泛应用。大部分关于妄想的研究集中在英语数据上，忽视了LLMs的多语言特性。本文介绍了我们对SemEval-2025任务3 - Mu-SHROOM多语言共享任务中的提交情况，重点在于妄想和相关可观察过度生成错误。", "innovation": "提出了一种两步流水线方法，结合了使用维基百科进行检索的基于事实的验证与一个微调过的BERT系统，用于识别常见的妄想模式。该系统在所有语言中都取得了竞争力的结果，在十三种语言中排名前10，英语包括在内。而且，该系统支持超过任务覆盖的十四种语言的多种语言。这使得跨语言的妄想识别器能够帮助改善LLM输出及其未来应用的价值。", "conclusion": "该多语言妄想识别器可以作为改进LLM输出和其广泛应用的关键工具。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00665", "html_url": "https://arxiv.org/abs/2507.00665", "title": "SAFER: 使用稀疏自编码器探究奖励模型中的安全性", "title_en": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder", "authors": "Sihang Li,Wei Shi,Ziyuan Xie,Tao Liang,Guojun Ma,Xiang Wang", "background": "强化学习从人类反馈（RLHF）是使大语言模型（LLMs）与人类价值观对齐的关键范式，然而其核心的奖励模型仍然具有很大的不透明性。本文旨在通过机械分析来解释和改进奖励模型，从而更深入地理解安全相关决策过程。", "innovation": "提出了稀疏自编码器用于增强奖励模型（SAFER）框架，利用稀疏自编码器揭示奖励模型激活中的可解释特征，量化重要性特征，并设计针对性的数据污染和去噪策略，证明SAFER能够在最小数据修改的情况下精确地提升或削弱安全对齐，不牺牲通用聊天性能。该方法为高风险LLM对齐任务中的解释、审核和改进奖励模型做出了贡献。", "conclusion": "SAFER能精准地提升或削弱安全对齐，同时不牺牲通用聊天性能，并可应用于高风险LLM对齐任务中的解释、审计和改进奖励模型。本文的代码已公开。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00534", "html_url": "https://arxiv.org/abs/2507.00534", "title": "NIRANTAR：基于真实语音数据的新语言和领域持续学习", "title_en": "NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data", "authors": "Tahir Javed,Kaushal Bhogale,Mitesh M. Khapra", "background": "该论文介绍了Nirantar，一个全面的框架，用于评估多语言和多领域语音识别（ASR）中的持续学习（CL）。Nirantar旨在反映现实中的CL挑战，通过印度22种语言和地区208个区的自然事件来收集数据，从而评估语言增量（LIL）、领域增量（DIL）以及新的语言增量领域增量学习（LIDIL）场景。与以往依赖模拟场景的工作不同，Nirantar通过展示动态、非均匀的语言和领域变化，提供了一个理想的持续学习研究测试平台。该框架包含3250小时的人类转录语音，其中1720小时是首次引入的数据，这使研究人员能够系统地评估CL方法。此前，持续学习方法在各个场景下的表现并未一致良好，这凸显了需要更稳健的CL策略的需求。", "innovation": "Nirantar框架的独特之处在于它使用了22种语言和地区的真实语音数据，涵盖了208个区，并且通过自然事件收集这些数据。它评估了语言增量、领域增量以及新的语言增量领域增量学习场景，填补了以往持续学习研究的空白。此外，Nirantar提供了一个动态、非均匀的变化环境，使得其成为持续学习研究的理想测试平台。", "conclusion": "该框架为现有持续学习方法提供了一个全面的基准测试，结果显示不存在能够一致表现良好的方法。因此，进一步研究更稳健的持续学习策略是必要的。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00540", "html_url": "https://arxiv.org/abs/2507.00540", "title": "基于Capsule网络的人机交互语义意图建模", "title_en": "Capsule Network-Based Semantic Intent Modeling for Human-Computer Interaction", "authors": "Shixiao Wang,Yifan Zhuang,Runsheng Zhang,Zhijun Song", "background": "该论文针对人机交互中意图识别准确度不足的问题，提出了一种基于Capsule网络的用户语义意图建模算法。文本的语义特征通过向量化的胶囊结构来表示，并通过动态路由机制在多个胶囊层之间传递信息，从而更有效地捕捉语义实体之间的层次关系和部分整体结构。实验使用开源的自然语言理解数据集进行，并与其他主流模型进行比较，结果显示该模型在准确率、F1分数和意图检测率方面优于传统方法和其他深度学习结构。同时，研究分析了动态路由迭代次数对模型性能的影响，提供了训练过程中损失函数的收敛曲线，验证了所提方法的稳定性和有效性。", "innovation": "该研究创新地提出了基于Capsule网络的用户语义意图建模算法，使用向量化的胶囊结构表示语义特征，并通过动态路由机制进行信息传递，此外，还引入基于边际的机制改进模型的意图类别区分能力，从而提高了模型在复杂语义条件下的意图识别准确度。", "conclusion": "该研究通过实验验证了基于Capsule网络的语义意图建模方法的有效性和稳定性，为复杂语义条件下的人机交互意图识别提供了新的结构化建模思路。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00718", "html_url": "https://arxiv.org/abs/2507.00718", "title": "AI Analyst: 大型语言模型在财务时间序列报告生成中的框架和综合评估", "title_en": "AI Analyst: Framework and Comprehensive Evaluation of Large Language Models for Financial Time Series Report Generation", "authors": "Elizabeth Fons,Elena Kochkina,Rachneet Kaur,Zhen Zeng,Berowne Hlavaty,Charese Smiley,Svitlana Vyetrenko,Manuela Veloso", "background": "该论文探讨了大型语言模型（LLMs）从时间序列数据生成财务报告的潜力。背景在于随着数据量的增长和计算能力的提升，利用LLMs自动生成财务报告成为可能，能够提高报告生成效率，减少人为错误，同时提供新的分析视角和方法。", "innovation": "论文提出了一种框架，包括提示工程、模型选择和评估。引入了自动化高亮系统，将生成的报告信息分类为直接来自时间序列数据的见解、基于财务推理的见解和依赖外部知识的见解。这种方法有助于评估模型的事实基础和推理能力。通过使用真实股票市场指数数据和合成时间序列数据进行实验，展示了LLMs生成连贯和信息丰富财务报告的能力。", "conclusion": "实验结果表明，尽管存在挑战，LLMs在生成财务报告方面具有显著潜力，特别是在处理大量时间和结构化数据方面。未来的研究可以进一步探索如何增强模型的能力，使其更加精确和可靠。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00782", "html_url": "https://arxiv.org/abs/2507.00782", "title": "一种功能模型自然语言语义的图示演算", "title_en": "A Diagrammatic Calculus for a Functional Model of Natural Language Semantics", "authors": "Matthieu Pierre Boyer", "background": "该研究基于形式化编程方法探讨自然语言语义学，旨在增强传统语义表示的表达能力。研究将构建基于范畴的类型和效果系统，并采用图表演算来模拟效果的解析和处理，以高效计算句子的意义表达式。", "innovation": "该研究引入了一种基于范畴的类型和效果系统，并通过图示演算模型解析和处理效果。其目的在于扩展传统语义表示的表达力，从而更高效地计算句子的意义表示。", "conclusion": "通过采用功能编程的新视角，该研究为自然语言语义学提供了新的理论体系和支持工具，达到了提高句式意义解析效率的目的。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00700", "html_url": "https://arxiv.org/abs/2507.00700", "title": "Vision-Language模型中的认知风格对比：日语中的整体注意力与英语中的分析焦点", "title_en": "Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention in Japanese Versus Analytical Focus in English", "authors": "Ahmed Sabir,Azinovič Gasper,Mengsay Loem,Rajesh Sharma", "background": "跨文化研究表明，不同文化背景的个体在处理视觉信息时会采取不同的方式。例如，东亚人倾向于采取整体视角，关注上下文关系，而西方人则倾向于采用分析视角，专注于个体对象及其属性。本研究旨在探讨在同一语言上主要训练的Vision-Language模型（VLMs），特别是日语和英语，是否会在注意力模式上表现出类似的文化差异。通过对比分析图像描述，研究检查了这些模型是否反映了整体或分析倾向的不同。研究表明，VLMs不仅内化了语言的结构特征，还复制了培训数据中嵌入的文化行为，表明文化认知可能隐性地影响模型输出。", "innovation": "该研究通过对比分析图像描述，探索了不同文化背景下训练的Vision-Language模型是否会展现出类似的文化注意力模式差异。这是首次通过机器学习和自然语言处理的方法来研究文化对语言模型影响的直接证据。", "conclusion": "研究表明，Vision-Language模型不仅内化了语言的结构特征，还复制了培训数据中嵌入的文化行为。这意味着文化认知可能隐性地影响模型输出，在类似人类认知方面，机器学习模型能反映出文化差异。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00509", "html_url": "https://arxiv.org/abs/2507.00509", "title": "TeamCMU在Touché:对话搜索中广告整合与检测的对抗共生演化", "title_en": "TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search", "authors": "To Eun Kim,João Coelho,Gbemileke Onilude,Jai Singh", "background": "随着对话搜索引擎越来越多地采用由大型语言模型（LLMs）和检索增强生成（RAG）支持的生成式范式，将广告整合到生成式响应中既带来了商业机遇也带来了用户体验的挑战。与传统搜索引擎中的广告明确区分不同，生成式系统模糊了信息内容与促销材料之间的界限，这引发了透明度和信任方面的担忧。因此，提出了一种模块化的管道来管理基于RAG的对话系统中的广告管理，包括广告重写器和鲁棒的广告分类器。利用合成数据训练高效分类器，并结合监督微调和最佳N采样方法进行广告整合，以提高广告的隐蔽性，从而实现更顺畅的整合。", "innovation": "该研究提出了一个结合广告重写器和鲁棒分类器的模块化管道来处理基于RAG的对话系统中的广告管理问题。通过利用合成数据训练性能高的分类器，并结合监督微调和最佳N采样方法进行广告整合，研究提出了广告泛化检测和最小侵入性的广告插入的解决方案。同时，通过这种方法，展示了这种方法在提升广告隐蔽性方面的有效性，从而推动了更复杂、更智能的广告意识生成搜索系统的开发。", "conclusion": "通过基于合成广告数据训练的分类器实现稳健的检测性能，并通过分类器引导的优化（包括微调和最佳N采样方法）显著提高广告的隐蔽性，从而在对话搜索中实现了更无缝的广告整合。这些发现为开发更复杂和稳健的广告感知生成搜索系统提供了对抗共生演化的框架。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00606", "html_url": "https://arxiv.org/abs/2507.00606", "title": "混合推理：教大型语言模型使用自适应策略进行推理", "title_en": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies", "authors": "Tao Xiong,Xavier Hu,Wenyan Fan,Shengyu Zhang", "background": "大型语言模型（LLMs）通过复杂的提示技术如链式思考（CoT）和树状思考（ToT）在复杂任务中表现出色，但它们高度依赖于手动构建的任务特定提示，这限制了它们的适应性和效率。现有的方法需要人工设计的提示来完成任务，导致灵活性和效率的瓶颈。", "innovation": "本文提出了一种名为混合推理（MoR）的训练框架，该框架将多种推理策略嵌入到LLMs中，从而实现无需外部提示工程的自主、任务适应性推理。MoR分为两个阶段：思考生成，利用如GPT-4o等模型创建推理链模板；SFT数据集构建，将模板与基准数据集进行配对，用于监督学习。实验表明，MoR显著提高了性能，MoR150在使用CoT提示时相较于基线提升了2.2%，在直接对比中提升了13.5%。MoR消除了对特定任务提示的需求，提供了一个在多变任务上进行稳健推理的一般性解决方案。", "conclusion": "MoR通过嵌入多种推理策略，实现了无需人工提示工程的自主任务适应性推理，显著提升了LLMs在复杂任务上的性能，并提供了一种通用方法来增强跨多种任务的推理能力。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00783", "html_url": "https://arxiv.org/abs/2507.00783", "title": "生成式AI与未来科学计量学：当前话题与未来问题", "title_en": "Generative AI and the future of scientometrics: current topics and future questions", "authors": "Benedetto Lepori,Jens Peter Andersen,Karsten Donnay", "background": "本文旨在回顾生成式AI（GenAI）在科学计量学中的应用，并探讨其对这一领域更广泛的影响。首先，介绍了GenAI生成性和概率性的本质，基于分布语言学。然后，探讨了GenAI在模拟人类‘推理’能力上的争论。第二，通过利用这种区分来批判性地探讨了在科学计量学中使用GenAI进行主题分类、引用上下文分析、预测应用、学者画像和研究评估的最新实验。第三，探讨了GenAI生成大量科学语言可能对科学计量学产生根本性影响的可能性，进而影响用于衡量科学的文本特征，如作者、词汇和参考文献。", "innovation": "本文提供了有关科学计量学中生成式AI应用的研究和思考，强调了对不同GenAI模型性能进行系统比较的必要性，并讨论了生成式AI可能对科学计量学产生根本性影响的可能性。同时，文章引发了关于生成式AI对科学文本特征和科学计量学方法潜在影响的深入讨论。", "conclusion": "总的来看，本文提出应继续对比不同GenAI模型在特定任务下的表现，并通过详尽的实证研究和理论反思来理解知识生产模式的变化。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00828", "html_url": "https://arxiv.org/abs/2507.00828", "title": "ProxAnn: 以用户为导向的主题模型和文档聚类评估", "title_en": "ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering", "authors": "Alexander Hoyle,Lorena Calvo-Bartolomé,Jordan Boyd-Graber,Philip Resnik", "background": "现有的主题模型和文档聚类评估方法要么依赖于与人类偏好不匹配的自动化度量标准，要么需要难以扩展的专家标签。因此，现有方法不能准确反映模型在实际应用中的表现。为了解决这一问题，本文设计了一个可扩展的人类评估协议及其相应的自动化近似方法，该方法能够更好地反映模型的实际使用情况。评估者或基于LLM的代理将审查分配给特定主题或群组的文本项，推断出该组的类别，然后将该类别应用到其他文档中，从而验证自动化代理的效果。", "innovation": "本文提出了一个可扩展的人类评估协议及其相应的自动化近似方法，打破了以往依赖专家标签的方法。此方法通过让评估者或基于LLM的代理来推断一个群组的类别，并将其应用于其他文档，从而更真实地反映模型的实际应用情况。研究结果表明，最佳的LLM代理在统计上与人类标注者难以区分，并可作为自动化评估中的合理替代品。", "conclusion": "通过本文介绍的协议，开发者可以更准确地评估主题模型和文档聚类的实际应用价值。此外，最佳的基于LLM的代理能够提供比传统方法更准确的评估结果，同时降低评估成本。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00769", "html_url": "https://arxiv.org/abs/2507.00769", "title": "LitBench: 一个用于可靠评估创意写作的基准和数据集", "title_en": "LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing", "authors": "Daniel Fein,Sebastian Russo,Violet Xiang,Kabir Jolly,Rafael Rafailov,Nick Haber", "background": "评估大型语言模型（LLMs）生成的创意写作仍然具有挑战性，因为开放式的叙述缺乏真实基准。缺乏有效的自动化评估方法时，常用的现成（OTS）语言模型被用作零样本评估者，但它们在这种背景下的可靠性尚不清楚。为了获得创意写作的稳健评估，引入了LitBench，它是首个为创意写作验证标准化的基准和配对数据集，包含从Reddit中抽取的2,480个脱偏的人类标记故事对比以及43,827对人类偏好标签的训练语料库。这项研究旨在通过LitBench评估零样本LLM裁判，训练布拉德利-_terry和生成奖励模型，并在网上进行人类研究以验证奖励模型排名的准确性于新生成的故事，以确保其与人类偏好保持一致。", "innovation": "引入了LitBench，首次提供了标准化的基准和配对数据集，包含2,480个脱偏的人类标记故事对比及43,827对人类偏好标签的训练语料库，用于创意写作的可靠评估。使用LitBench评估零样本LLM裁判的性能，训练布拉德利-terry和生成奖励模型，并在线进行研究以验证奖励模型排名的准确性，确保其与新生成的故事人类偏好一致。研究结果表明，训练后的奖励模型比所有现成的裁判表现更好，准确率达到78%，并与人类偏好高度一致。", "conclusion": "通过LitBench，研究识别了Claude-3.7-Sonnet作为最强的现成裁判，达到73%的人类偏好一致性；训练后的Bradley-Terry和生成奖励模型都达到了78%的准确性，在所有现成裁判中表现最佳。在线人类研究进一步证实，已训练奖励模型在新生成的故事中与人类偏好保持一致。成果和奖励模型已公开，为可靠地自动化评估和优化创意写作系统提供了审定资源。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00838", "html_url": "https://arxiv.org/abs/2507.00838", "title": "风格分析识别短样本中的人类和LLM生成文本", "title_en": "Stylometry recognizes human and LLM-generated texts in short samples", "authors": "Karol Przystalski,Jan K. Argasiński,Iwona Grabska-Gradzińska,Jeremi K. Ochab", "background": "随着大型语言模型（LLMs）的不断发展，识别由模型生成的文本与人类撰写的文本变得越来越重要。这个问题关系到模型归属、知识产权和道德AI使用等方面。为了应对这个问题，研究人员利用风格分析（Stylometry）来识别文本的风格和作者身份，并将这一方法应用于LLM生成的文本，以此识别其独特的写作风格模式。研究者构建了一个基于Wikipedia的数据集，包含人类撰写的摘要、由不同LLM生成的文本、通过不同文本摘要方法处理的文本以及经过重新表达的方法处理的文本。", "innovation": "本文的创新之处在于，通过构建一个包含多种类型文本的数据集，并使用树基模型（决策树和LightGBM）以及人类设计和基于n-gram的方法来识别风格特征，达到了较高的识别性能。特别是在多类场景中，达到了0.87的马修斯相关系数，在二元分类中，最大准确率达到了0.98。此外，Shapley Additive Explanations方法还能确定LML和人类撰写文本的特征差异，以及LLM文本中的特定过度使用的词汇和更高的标准化语法特征。", "conclusion": "研究表明，在文本类型定义明确的情况下，能够有效地区分机器生成的文本和人类生成的文本，尤其是在复杂的LLM模型越来越先进的背景下。这对于解决模型归属、知识产权和道德AI使用等方面的问题具有重要意义。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00883", "html_url": "https://arxiv.org/abs/2507.00883", "title": "数学不是文化中立的：通过实体和情景扰动探测文化差距", "title_en": "Mathematics Isn't Culture-Free: Probing Cultural Gaps via Entity and Scenario Perturbations", "authors": "Aditya Tomar,Nihar Ranjan Sahoo,Ashish Mittal,Rudra Murthy,Pushpak Bhattacharyya", "background": "尽管数学通常被认为与文化无关，但数学问题的表述方式可能会带有隐含的文化背景。现有的基准数据集，如GSM8K，主要根植于西方规范，包括名字、货币和日常生活场景。这些数据集在不同文化背景下的应用可能存在局限性。", "innovation": "作者通过基于提示的转换方法，并结合手动验证，创建了针对非洲、印度、中国、韩国和日本五个地区的GSM8K测试集的变体。评估了六个不同规模的大型语言模型（从8亿到72亿参数），并使用五种不同的提示策略，以测试它们对数学问题文化表述差异的鲁棒性。研究发现，对于文化适应性的变化，具有推理能力的模型表现出更好的适应性，表明深入的推理有助于弥合数学任务中的文化表达差距。", "conclusion": "模型在原始以美国为中心的数据集上的表现最好，在文化适应性版本上的表现则相对较差，但具有良好推理能力的模型在文化变化面前表现更优越，这意味着深层次的推理有助于弥合数学任务中的文化差异表达。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00885", "html_url": "https://arxiv.org/abs/2507.00885", "title": "Downstream 任务的缩放定律不可靠：现实核查", "title_en": "Scaling Laws Are Unreliable for Downstream Tasks: A Reality Check", "authors": "Nicholas Lourie,Michael Y. Hu,Kyunghyun Cho", "background": "下游缩放定律旨在根据较小规模预训练损失来预测更大规模的任务性能，但对于这种预测是否可行存在不确定性。有研究表明任务性能遵循明显的线性缩放趋势，而其他研究则指出了下游缩放定律的基本挑战，如涌现和逆缩放现象。已有数据表明，接近线性缩放规律的情况只占少数，约39%。实验环境的小幅变动也可能彻底改变缩放趋势，强调了理解缩放定律成功条件的重要性。因此，为了全面模拟能量预训练损失和下游任务性能之间的关系，必须接受缩放行为偏离线性趋势的情况，这些差异的努力说明了线性缩放模型的局限性。", "innovation": "本文进行了一项元分析，调查现有关于下游缩放定律的数据，发现只有相对少数情况下（39%）能够接近线性缩放规律，而实验设置的小修改可能完全改变缩放趋势。这项工作强调了理解缩放规律成功条件的必要性，并提出了全面模型的需要，以覆盖缩放行为偏离线性趋势的情况。", "conclusion": "通过元分析，研究发现线性缩放规律只在小部分情况下适用，约39%。实验设置的小变化可以彻底改变缩放趋势。因此，线性缩放模型存在局限性，需要在全面模拟能量预训练损失与下游任务性能的关系时接受缩放行为可能偏离线性趋势的情况。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00999", "html_url": "https://arxiv.org/abs/2507.00999", "title": "La Leaderboard: 用于西班牙语变体和西班牙及拉丁美洲语言的大规模语言模型排行榜", "title_en": "La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America", "authors": "María Grandury,Javier Aula-Blasco,Júlia Falcão,Clémentine Fourrier,Miguel González,Gonzalo Martínez,Gonzalo Santamaría,Rodrigo Agerri,Nuria Aldama,Luis Chiruzzo,Javier Conde,Helena Gómez,Marta Guerrero,Guido Ivetta,Natalia López,Flor Miriam Plaza-del-Arco,María Teresa Martín-Valdivia,Helena Montoro,Carmen Muñoz,Pedro Reviriego,Leire Rosado,Alejandro Vaca,María Estrella Vallecillo-Rodríguez,Jorge Vallego,Irune Zubiaga", "background": "目前的排行榜展示了大规模语言模型（LLMs）的现状及其局限性。为了促进能够反映西班牙语社区语言和文化多样性的LLMs的发展，本文介绍了La Leaderboard，这是第一个专门为西班牙及拉丁美洲语言和方言评估生成型LLMs的开源排行榜。该排行榜旨在为主要服务于西班牙语社区的LLMs评估提供标准。初始版本结合了66个数据集，涵盖了巴斯克语、卡塔卢尼亚语、加利西亚语，以及不同西班牙语方言，评估了50个模型的表现。", "innovation": "提出了La Leaderboard，这是第一个专注于西班牙和拉丁美洲语系和方言的大规模语言模型排行榜。特别之处在于，该排行榜指导如何为下游任务选择最合适的评估设置，并提供使用较少示例（以减少环境影响和提高研究社区的可复现性）的合理性解释。", "conclusion": "La Leaderboard旨在成为所有致力于西班牙语社区LLM发展的社区的评估标准。该排行榜的发布为其他语言的社区驱动型排行榜的发展提供了方法学指导，建立了评估的标准，并展示了评估不同模型的结果。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00994", "html_url": "https://arxiv.org/abs/2507.00994", "title": "我们还应该使用掩码语言模型预训练编码器吗？", "title_en": "Should We Still Pretrain Encoders with Masked Language Modeling?", "authors": "Hippolyte Gisserot-Boukhlef,Nicolas Boizard,Manuel Faysse,Duarte M. Alves,Emmanuel Malherbe,André F. T. Martins,Céline Hudelot,Pierre Colombo", "background": "高质量的文本表示对于广泛的语言处理任务至关重要。传统的编码器预训练主要依赖于掩码语言模型（MLM），但研究表明，通过因果语言模型（CLM）进行解码器预训练的模型可以有效转换为编码器，并且在许多文本表示基准测试中表现出色。然而，尚不清楚这些改进是否反映了CLM目标固有的优势，还是由模型和数据规模等因素造成的混杂因素引起。", "innovation": "本文通过一系列大规模、严格控制的预训练实验，共训练了30个不同规模（从2.1亿到10亿参数）的模型，并进行了超过15,000次的微调和评估运行。研究发现，虽然MLM训练可以获得更好的整体性能，但在数据效率和细微调整稳定性方面，CLM训练的模型表现更好。此外，提出了一种双相训练策略，即首先使用CLM训练，随后使用MLM，在固定计算预算下获得最佳性能。这种策略在从现有大型语言模型生态系统中的预训练CLM模型初始化时变得更有吸引力，减少了训练顶级编码器模型所需的计算负担。", "conclusion": "研究结果表明，在固定计算预算下，使用CLM进行预训练，然后跟随MLM训练策略，可以获得最佳的文本文献表示效果。此外，这种方法相较于从零开始训练模型更加高效，特别是当可以利用现有的预训练CLM模型时。最后，研究公开了所有项目资源以促进进一步研究。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00022", "html_url": "https://arxiv.org/abs/2507.00022", "title": "GLU Attention Improve Transformer", "title_en": "GLU Attention Improve Transformer", "authors": "Zehao Wang", "background": "Gated Linear Units (GLU)已经被证明在提升神经网络性能方面具有巨大的潜力。现有的注意力机制（如Multi-Head Attention）通常依赖于线性操作，这限制了模型的表达能力。", "innovation": "本文提出了一种新颖的注意力机制——GLU Attention，该机制在注意力机制的值中引入非线性。实验证明，GLU Attention可以提高模型性能和收敛速度，不增加额外参数且几乎不需要额外的计算成本。此外，该机制与Flash Attention、Rotary Position Embedding (RoPE)等其他技术无缝集成，并能与各种Multi-Head Attention (MHA)变体（如Grouped-Query Attention (GQA)）无缝结合。", "conclusion": "GLU Attention是一种轻量级机制，可以轻松集成到现有模型中，并且已在文本和视觉模态中得到了有效验证。项目已开源在github上。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00814", "html_url": "https://arxiv.org/abs/2507.00814", "title": "许多LLM比单个更倾向于功利主义", "title_en": "Many LLMs Are More Utilitarian Than One", "authors": "Anita Keshmirian,Razan Baltaji,Babak Hemmatian,Hadi Asghari,Lav R. Varshney", "background": "道德判断是大语言模型（LLM）对齐和社会推理的关键组成部分。随着多智能体系统变得越来越重要，了解LLM在协作中的集体功能变得至关重要，与个体智能体相比亦然。在人类道德判断中，群体讨论导致了功利主义提升，即倾向于赞同有利于最大多数人利益的规范违反行为，即使会导致伤害。本研究探讨这种动态是否在多智能体LLM系统中出现。研究中测试了六种模型在不同的条件下进行道德困境的推理，这些条件包括：（1）单人情况，各模型独立推理；（2）群体情况，它们通过多轮讨论进行互动。研究结果表明，所有模型在群体情况下的道德违反行为被认为比单人情况更可接受，类似于人类实验的结果。然而，人类和模型之间依然存在区别，人类群体展现出行动偏好，而LLM群体则表现出规范敏感度降低或增强了无偏性。这意味着，尽管LLM集体的表面行为模仿了人类群体推理，但背后的驱动机制不同。研究对AI对齐、多智能体设计及人工道德推理的影响进行了讨论。", "innovation": "本研究通过在多智能体LLM系统中引入“群体”条件（多轮讨论），考察其相比于单个模型的行为差异。这种研究设计创新地探讨了群体动态如何影响LLM的道德判断，揭示了它们与人类群体差异的缘由，为理解LLM在多智能体系统中的行为提供了新视角。", "conclusion": "研究结果表明，多智能体LLM在道德判断上可能表现得更倾向于功利主义，但它们背后的驱动机制与人类群体有所不同。这些发现对AI对齐、多智能体设计及人工道德推理具有重要意义，提醒我们在开发多智能体系统时需特别关注这些差异以确保伦理与公平。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00891", "html_url": "https://arxiv.org/abs/2507.00891", "title": "MemeCMD：一种基于上下文检索的自动生成中文多轮对话数据集", "title_en": "MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes", "authors": "Yuheng Wang,Xianhe Tang,Pufeng Huang", "background": "表情包（meme）在在线社交互动中被广泛使用，为表达意图和情感提供了生动、直观且常常富有幽默感的方式。现有的对话数据集主要局限于手动标注或纯文本对话，缺乏多模态交互所具有的表达能力和上下文细微差别。MemeCMD针对这些挑战，提供了一个新的自动生成的中文多轮对话数据集，其中包括上下文获取的表情包。该数据集结合了一个大规模的、由MLLM标注的图库，并通过双智能体自动生成跨多场景的对话，确保了表情包的上下文相关性与自然分布规律性，从而推进了多模态对话AI的发展和应用规模", "innovation": "MemeCMD创新性地结合了大规模的、由MLLM标注的表情包库，并通过双智能体自动生成跨多场景的中文多轮对话。此外，它还引入了检索框架以及自适应阈值，确保了上下文相关性与自然分布规律。实验表明，该方法生成的内容上下文相关且多样性丰富，可以作为多模态对话AI发展中的可扩展且隐私保护的宝贵资源", "conclusion": "MemeCMD数据集通过结合大规模图库和对话生成以及采用上下文相关检索框架，实现了有效的情感丰富对话生成。相对于现有数据集，MemeCMD提供了一个更广泛且适用当前挑战的情境对话数据集，提供了多样且合适的背景信息，从而能够更好地推进多模态对话AI的应用与发展。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00985", "html_url": "https://arxiv.org/abs/2507.00985", "title": "话语启发式规则用于道德自纠偏的悖论", "title_en": "Discourse Heuristics For Paradoxically Moral Self-Correction", "authors": "Guangliang Liu,Zimo Qi,Xitong Zhang,Kristen Marie Johnson", "background": "道德自纠偏被证明是一种有望使大型语言模型的输出与人类道德价值观相一致的方法。然而，这种技术存在两个主要悖论：一是尽管有实证和理论证据支持自纠偏的有效性，但这种能力仅在表面层面运行；二是尽管大型语言模型有能力诊断其输出中的不道德方面，但在自纠偏过程中却难以识别这种道德不一致的原因。为了更好地理解并解决这些悖论，本文分析了用于提升道德自纠偏的微调语料库的语用构建，揭示了有效构建背后存在的启发式规则，并表明这些启发式规则的出现会导致在同时提升自纠偏和自我诊断能力时产生不一致的情况。", "innovation": "本文通过对微调语料库的分析，揭示了道德自纠偏依赖于反映启发式捷径的语用构建，指出了这些启发式规则在自纠偏过程中的存在会导致不一致问题，并提出了通过利用精简数据集的启发式规则来改进道德自纠偏的方法。同时也指出了这一能力在从具体情境中学习和模型规模方面的泛化挑战。", "conclusion": "本文提出了利用精简数据集的启发式规则来改善道德自纠偏的解决方案，并强调了这一能力在从具体情境中学习和模型规模方面的泛化挑战。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00033", "html_url": "https://arxiv.org/abs/2507.00033", "title": "Video LLMs中长视频问答中的瞬间采样", "title_en": "Moment Sampling in Video LLMs for Long-Form Video QA", "authors": "Mustafa Chasmai,Gauri Jagatap,Gouthaman KV,Grant Van Horn,Subhransu Maji,Andrea Fanelli", "background": "近年来，视频大语言模型（Video LLMs）在视频问答（VideoQA）领域取得了显著进展。现有方法在处理短视频时表现良好，但在长视频中难以进行长距离推理。为了解决这个问题，帧下采样（按一定间隔选取帧）是常用的策略，但这往往会丢失关键帧或加入冗余信息，从而影响模型准确回答问题的能力并增加计算资源消耗。", "innovation": "本文提出了一种新颖的、模型无关的方法——瞬间采样（moment sampling），利用通用的文本到视频的瞬间检索模型来指导帧的选取过程。此方法能够在回答问题的上下文环境中，优先选择与问题最相关的帧，从而在Video LLMs中提高长视频问答（long-form VideoQA）性能。该方法通过在四个长视频问答数据集上使用四种最先进的Video LLMs进行大量实验，证明了其有效性。", "conclusion": "研究采用瞬间采样方法，在四种最先进的Video LLMs上对四个长视频问答数据集进行实验，验证了这一方法的有效性，显著提升了Video LLMs在长视频问答任务中的表现。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00026", "html_url": "https://arxiv.org/abs/2507.00026", "title": "ROSE: 向现实导向的大语言模型安全性评估迈进", "title_en": "ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models", "authors": "Jiale Ding,Xiang Zheng,Cong Wang,Wei-Bin Lee,Xingjun Ma,Yu-Gang Jiang", "background": "随着大语言模型（LLMs）在实际应用中被日益部署为黑箱组件，对其安全性的评估尤其是对抗性提示下的安全性评估变得至关重要。现有的手动安全性基准测试受到静态特性和更新时的大量劳动需求限制，难以跟上LLM的快速进步。因此，自动化生成对抗性提示为适应性评估提供了有前途的途径。然而，当前方法在对抗性话题覆盖（话题层面的多样性）和与现实世界情景的对齐方面仍存在不足。为解决这些问题，提出了一种名为ROSE（Reality-Oriented Safety Evaluation）的新框架，使用多目标强化学习来微调对抗性LLM，以生成话题多样性和背景丰富的对抗性提示。实验表明，ROSE在发现先进LLM的安全漏洞方面优于现有方法，且在综合评估指标上有所改进。", "innovation": "提出的ROSE框架使用多目标强化学习来微调对抗性LLM，以生成话题多样性和背景丰富的对抗性提示。该框架解决了现有方法在对抗性话题覆盖和与现实世界情景的对齐方面的不足，提高了安全性评估的有效性和适应性。", "conclusion": "ROSE代表了大语言模型安全性评估中更实用和现实导向的一步。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00018", "html_url": "https://arxiv.org/abs/2507.00018", "title": "隐式奖励作为桥梁：SFT与DPO连接的统一视角", "title_en": "Implicit Reward as the Bridge: A Unified View of SFT and DPO Connections", "authors": "Bo Wang,Qinyuan Cheng,Runyu Peng,Rong Bao,Peiji Li,Qipeng Guo,Linyang Li,Zhiyuan Zeng,Yunhua Zhou,Xipeng Qiu", "background": "后训练过程是将预训练语言模型应用于现实世界任务的关键阶段，从演示学习或偏好信号学习中获得的经验对于这一适应过程至关重要。本文提供了监督微调（SFT）和偏好学习在大型语言模型（LLM）后训练中的统一理论框架。通过严格的数学推导，证明了SFT和偏好学习方法（如直接偏好优化 DPO）都在相同的最优策略-奖赏子空间中运作，其中SFT代表一种隐式奖励学习的特殊情况。然而，传统SFT的一个关键限制是在优化过程中，分布匹配中的KL发散项变得与策略无关，未能约束模型更新。", "innovation": "本文提出了一种简单有效的学习率降低方法，从而显著提高了性能（相对于指令跟随任务，相对增益最高可达25%，绝对胜率增益6%）。此外，从不同的f-散度函数中推导出SFT目标，以保持优化过程中的KL项，进一步提升了后DPO模型的性能。最后，扩展了偏好学习中的LLM对数和Q函数的关系到SFT上下文，提供了数学证明和实验验证。", "conclusion": "研究表明，SFT和偏好学习方法在相同的最优策略-奖赏子空间中工作，提出的方法有效地弥补了传统SFT的缺陷，显著提高了模型性能。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00911", "html_url": "https://arxiv.org/abs/2507.00911", "title": "语言谱系学中的偕同词数据瓶颈", "title_en": "The Cognate Data Bottleneck in Language Phylogenetics", "authors": "Luise Häuser,Alexandros Stamatakis", "background": "为充分发挥计算系统谱系学方法在偕同词数据上的潜力，需要应用特定的（复杂）模型及基于机器学习的技术。然而，这两种方法都需要比目前手动收集的偕同词数据集大得多的数据集。据我们所知，缺乏一种可行的方法来自动生成更大的偕同词数据集。我们通过自动从BabelNet（一个多语言百科字典）中提取数据集来证明这一点。此类数据集上的谱系推断产生的树与公认的黄金标准基准树有很大程度的不一致。我们还讨论了为什么从其他多语言资源中提取更合适的数据矩阵的可能性很小。因此，需要更大数据集的谱系数据分析方法在偕同词数据上的应用是不可能的。这就提出了一个问题，即这些计算方法在历史语言学中如何以及是否可以应用。", "innovation": "文章通过自动从BabelNet中提取数据集来证明了缺乏生成更大偕同词数据集的可能性，并探讨了为什么从其他多语言资源中提取更合适数据矩阵的可能性很小。文章还提出了在偕同词数据上应用需要更大数据集的方法存在的问题，以及这些计算方法在历史语言学中的应用前景。", "conclusion": "需要更大数据集的谱系数据分析方法在偕同词数据上的应用是不可能的。如何以及能否将这些计算方法应用于历史语言学仍是一个待解的问题。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00002", "html_url": "https://arxiv.org/abs/2507.00002", "title": "超代币：结构化联想记忆在标记化大语言模型中的全息记忆", "title_en": "Hypertokens: Holographic Associative Memory in Tokenized LLMs", "authors": "Christopher James Augeri", "background": "大型语言模型（LLMs）表现出显著的能力，但它们在计算精度上存在明显问题，这被重新定义为信息扩散问题。这一重新定义将问题从计算精度转变为信息论通信问题。文章通过这种方式探讨了LLMs中的K:V和V:K内存问题，并致力于通过HDRAM（全息定义随机存取存储器）来解决这个问题。HDRAM将变压器潜空间视为一种展开频谱信道，构建了一种符号化内存框架。", "innovation": "HDRAM（全息定义随机存取存储器）采用超代币，结合经典错误校正码（ECC）、全息计算和量子启发式搜索，通过原理性的展开技术恢复分散的信息。这种相干内存地址能高效地进行键值操作和类Grover搜索。通过结合ECC语法、压缩感知和Krylov子空间对齐，HDRAM显著提升了联想检索能力，同时无需修改架构。这展示了经典-全息-量子启发（CHQ）原则可以增强变压器架构的方法。", "conclusion": "HDRAM 改进了大语言模型中的联想检索，通过无架构改动实现了高效的关键值操作和类Grover搜索。研究证明，CHQ 原则能够有效加固变压器架构。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00068", "html_url": "https://arxiv.org/abs/2507.00068", "title": "MANTA: 具备跨模态语义对齐与信息论优化的长形式多模态理解框架", "title_en": "MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding", "authors": "Ziqi Zhong,Daniel Tang", "background": "当前的多模态学习方法往往分别处理各模态的信息，导致表示和推理存在不一致的问题。为了克服这一问题，本研究提出了MANTA（具备文本对齐的多模态抽象和归一化）框架，该框架通过结构化的文本空间联合视觉和听觉输入，以便与大规模语言模型无缝处理。MANTA框架解决了四个关键挑战：（1）使用信息论优化进行跨模态的语义对齐；（2）适应性的时间同步以适应不同的信息密度；（3）层次化的内容表示以实现多尺度的理解；（4）上下文感知的稀疏信息检索方法从长序列中提取信息。本研究在严谨的数学框架内正式化了方法，并证明了在token约束下的上下文选择最优性。", "innovation": "MANTA框架通过结构化的文本空间联合视觉和听觉输入，解决了多模态学习中模态之间表示和推理不一致的问题，并提出了四个关键创新：（1）信息论优化的跨模态语义对齐；（2）适应性时间同步；（3）多层次内容表示；（4）上下文感知的稀疏信息检索技术。该框架还引入了减少冗余性和保留稀有信号的新型密度估计方法，为多模态表示的统一提供了新的基础。", "conclusion": "在长视频问答任务上的广泛实验表明，MANTA方法在总体准确度上较现有模型提高了22.6%，特别是对于超过30分钟的视频提高尤为显著（27.3%）。此外，MANTA在时间推理任务上提高了23.8%，在跨模态理解任务上提高了25.1%。这一框架为统一多模态表示提供了新方向，具有明确的理论基础和实际应用效益。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00054", "html_url": "https://arxiv.org/abs/2507.00054", "title": "使用奖励导向的数据集蒸馏增强SLMs的推理能力", "title_en": "Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation", "authors": "Shreyansh Padarha", "background": "近年来，将大型语言模型（LLMs）的知识压缩并传递到更易部署且高效的中小型语言模型（SLMs）方面取得进展，得益于知识蒸馏（KD）技术的进步。这些技术让较小的学生模型能够从更大、更有能力的教师模型中学习。然而，蒸馏通常强调学生模型只是复制教师模型在分布内的响应，这限制了其泛化能力，特别是在推理任务中更为明显，并可能消耗大量的计算资源。", "innovation": "本文提出了一种名为AdvDistill的奖励导向的数据集蒸馏框架。该框架利用教师模型对每个提示的多个生成结果，并基于规则验证器分配奖励。这些奖励根据其分布在模型训练过程中作为权重。通过这种方法及其后续的行为分析，学生模型在数学和复杂推理任务中的性能明显提升，证明了奖励机制在数据集蒸馏过程中的有效性和优势。", "conclusion": "该研究通过引入奖励机制，显著提高了学生模型在数学和复杂推理任务上的表现，展示了奖励导向的数据集蒸馏方法的有效性和优势。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01001", "html_url": "https://arxiv.org/abs/2507.01001", "title": "SciArena: 用于科学文献任务的基础模型开放评估平台", "title_en": "SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks", "authors": "Yilun Zhao,Kaiyan Zhang,Tiansheng Hu,Sihong Wu,Ronan Le Bras,Taira Anderson,Jonathan Bragg,Joseph Chee Chang,Jesse Dodge,Matt Latzke,Yixin Liu,Charles McGrady,Xiangru Tang,Zihang Wang,Chen Zhao,Hannaneh Hajishirzi,Doug Downey,Arman Cohan", "background": "传统的科学文献理解和合成基准测试通常是封闭和竞争性的，缺乏社区参与。SciArena 提出了一个开放且协作的平台来评估基础模型在科学文献任务上的性能。该平台借鉴了聊天机器人评估竞赛（Chatbot Arena）的社区投票模型，通过聚合的智慧提供了一个社区驱动的评估，解决了需要参考文献的长篇文章的任务。平台目前支持23个开源和专有基础模型，并收集了来自不同科学领域受信任的研究者的超过13,000个投票数据。已分析并确认提交的问题具有多样性，与现实世界的文献需求对齐，参与研究者在评估中表现出强烈的自我一致性和评论者之间的一致性。", "innovation": "SciArena 提供了一个社区驱动的平台，直接邀请研究社区参与基础模型的评估过程，遵循聊天机器人竞赛的评估方法，即通过社区投票来进行模型比较。这个平台以集体智慧的方式运作，能够评估基础模型在开放式科学任务上的性能，这些任务要求提供基于文献的长篇回答。此外，SciArena 还发布了 SciArena-Eval 作为元评估基准，通过比较模型的两两评估与人类投票来进行准确性测量，强调了需要更可靠的方法来自动评估模型的准确性。", "conclusion": "该研究通过数据分析证明了提交的问题是多样化的，且符合现实世界的文献需求，并展示了参与者的评估一致性和互评者的一致性。通过平台提供的结果和见解，发现在基于模型的自动评估系统中需要引入更多的可靠方法，并发布了 SciArena-Eval 作为用于衡量模型判断答案质量准确性的基准。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00045", "html_url": "https://arxiv.org/abs/2507.00045", "title": "CaughtCheating：你的MLLM擅长做偷拍侦探吗？探索视觉感知和推理的边界", "title_en": "CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning", "authors": "Ming Li,Chenguang Wang,Yijun Liang,Xiyao Wang,Yuhang Zhou,Xiyang Wu,Yuqing Zhang,Ruiyi Zhang,Tianyi Zhou", "background": "最近的代理多模态大型语言模型（如GPT-o3）在各种现有基准测试中取得了接近天花板的分数，推动了对更具挑战性的测试任务的需求。这些多模态大型语言模型在一些人类专家级别的任务中表现出色，例如GeoGuesser，展示了它们作为能够注意到图像中细微线索，并将它们编织成连贯、情境化的解释，从而得出可靠答案的侦探的潜力。然而，它们能否与优秀的真人侦探达到相同的性能？为了回答这个问题，我们调查了GPT-o3仍能处理的一些难题，发现了一个常见场景，在那里o3的表现几乎降至零，我们将其命名为CaughtCheating。这个场景由社交媒体上的请求启发，要求他人检测照片提供者伴侣分享的照片中的可疑线索。我们进行了广泛的研究和分析，以了解现有的MLLM为何缺乏足够的能力来解决这类任务。CaughtCheating提供了一类具有重要价值和实用用途的挑战性视觉感知和推理任务。在这些任务中取得成功为MLLMs开启了获取人类级别的侦探感知和推理能力的道路。", "innovation": "通过调查GPT-o3在特定场景下的表现，揭示了现有MLLM在视觉感知和推理任务上的局限性，提出了被称为‘CaughtCheating’的挑战性测试任务，为多模态大型语言模型的发展提供了新的研究方向。", "conclusion": "CaughtCheating提供了一类挑战性极高的视觉感知和推理任务，展示了现有的MLLM在处理此类任务时存在的不足。这一研究为进一步开发具备人脑般推理能力的MLLM们铺平了道路。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00234", "html_url": "https://arxiv.org/abs/2507.00234", "title": "可解释的时序AI：全局注意力和NLP生成解释的多模型热图融合", "title_en": "Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations", "authors": "Jiztom Kavalakkatt Francis,Matthew J Darr", "background": "本文讨论了现有解释性方法中存在的时空对准问题，其中卷积网络无法捕捉全局上下文，而Transformer又缺乏局部精度。这些限制阻碍了在医疗保健和工业监控等安全关键领域中的行动见解。因此，本文提出了一个新的框架，通过集成ResNet产生的热图和重新结构化的2D Transformer与全局加权输入显著性相结合，以增强模型解释性。该框架可以实现完全的时空对准，同时保持实时性能.", "innovation": "本文创新性地提出了一种新的框架，通过将ResNet的梯度加权激活图和Transformer注意层卷展开合并到统一的可视化中，实现了全时空对准，同时保持实时性能。并且，结合了一种NLP模块，将融合后的热图转换为特定领域的叙述性解释，验证了BLEU-4（0.586）和ROUGE-L（0.650）得分。这为透明的时间意识决策提供了技术输出与利益相关者理解之间的桥梁，提供了一种可扩展的解决方案.", "conclusion": "实验结果表明，该混合框架在心电图异律性检测数据集上达到了94.1%的准确性（F1 0.93），在UCI Energy Appliance数据集上的回归误差降低了到RMSE = 0.28 kWh（R2 = 0.95）。该方法显著优于独立的ResNet、Transformer和InceptionTime基线，提高了3.8%到12.4%。通过正式化解释为因果保真度和时空对齐，该方法满足了技术输出与利益相关者理解之间的需求，提供了一种可扩展的透明解决方案，以进行时间感知决策."}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00092", "html_url": "https://arxiv.org/abs/2507.00092", "title": "思考关于思考：SAGE-nano的逆向推理实现自我意识语言模型", "title_en": "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models", "authors": "Basab Jha,Firoj Paudel,Ujjwal Puri,Zhang Yuting,Choi Donghyuk,Wang Junhao", "background": "大语言模型（LLMs）在通过链式思考（CoT）提示解决复杂推理任务方面表现出显著能力，但其决策过程仍有部分不透明。本文提出了一种新颖的方法，即逆向推理，允许LLMs在推理完成后再解释其链式推理过程。通过逆向推理推理链的选择原因，逆向推理提供了不同于传统CoT方法的独特视角，而传统CoT方法主要面向前向推理生成。研究人员通过逻辑推理谜题、数学问题和伦理难题测试了SAGE-nano模型的表现，验证了其在推理准确性与解释质量上的领先优势，同时也发现了逆向推理对可解释性与推理性能的提升作用。这种方法为透明的人工智能系统开辟了新途径，并在AI安全、教育和科学发现方面填补了重大空白。", "innovation": "本文的主要创新点包括：(i) 提出了首个用于LLM自我反思的严格框架，该框架通过逆向推理实现；(ii) 引入了一种新颖的元学习框架，逆转了注意力流动的方向；(iii) 提出了全面的推理透明度评价框架；(iv) 展示了通过逆向推理增加推理可以提升可解释性并改善推理性能。", "conclusion": "通过详细的测试，证明了SAGE-nano模型在推理准确性和解释质量上达到了行业领先水平，与Claude-3.5 Sonnet或GPT-4o等模型相比具有竞争力。本文的工作为透明AI系统开辟了新的研究方向，并解决了AI安全、教育和科学发现中的重大问题。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00082", "html_url": "https://arxiv.org/abs/2507.00082", "title": "采用联邦学习的混合语言模型以实现通信效率的令牌传输", "title_en": "Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission", "authors": "Faranaksadat Solat,Joohyung Lee,Mohamed Seif,Dusit Niyato,H. Vincent Poor", "background": "混合语言模型（HLMs）结合了小规模语言模型（SLMs）在边缘设备上的低延迟高效性和大规模语言模型（LLMs）在集中式服务器上的高准确性。与传统的端到端LLM推理不同，HLM通过在本地SLM预测不确定时才调用LLM来减少延迟和通信量，但这在带宽受限的情况下会导致显著的通信开销。", "innovation": "FedHLM是一种沟通高效的HLM框架，结合了不确定性感知推理与联邦学习（FL）。FedHLM的关键创新在于合作学习控制何时需要LLM帮助的token级不确定性阈值。它使用FL以隐私保护和分布式的方式优化这些阈值，同时利用基于嵌入的token表示进行P2P解决，使客户端可以重用与语义相似的peer的预测，从而避免与LLM交互。此外，它引入了分层模型聚合：边缘服务器通过客户端更新来细化本地路由策略，而跨集群协调则使全局决策边界保持一致。这种分层设计捕捉到反复出现的不确定性模式，减少了冗余的LLM查询。", "conclusion": "实验表明，FedHLM在大规模新闻分类任务中降低了95%以上的LLM传输量，而几乎没有准确性损失，使其非常适合可扩展和高效的边缘AI应用。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00310", "html_url": "https://arxiv.org/abs/2507.00310", "title": "通过贝叶斯惊奇实现开放性科学发现", "title_en": "Open-ended Scientific Discovery via Bayesian Surprise", "authors": "Dhruv Agarwal,Bodhisattwa Prasad Majumder,Reece Adamson,Megha Chakravorty,Satvika Reddy Gavireddy,Aditya Parashar,Harshit Surana,Bhavana Dalvi Mishra,Andrew McCallum,Ashish Sabharwal,Peter Clark", "background": "自主科学发现（ASD）不仅依赖于回答问题，还在于知道问哪些问题。近年来，大多数ASD研究侧重于在目标导向的情境中使用大型语言模型（LLMs），依赖人类规定的研究问题来引导假设生成。然而，使AI系统依靠自身标准驱动探索可能会进一步加速科学发现。目前一些方法根据多样性启发式或人为有趣的主观度量来选择假设，但前者难以有效导航典型情况下庞大的假设空间，后者则因定义模糊而存在问题。", "innovation": "本文提出了AutoDS——一种使用贝叶斯惊奇驱动开放性ASD的方法。通过量化LLM对假设的先验信念与实验结果后的后验信念之间的知识转变来开展科学探索。为高效探索嵌套假设的空间，方法利用蒙特卡洛树搜索（MCTS）策略，使用惊奇作为奖励函数进行逐步扩展。在生物学、经济学、金融学和行为科学等多个真实数据集上的实验结果显示，在固定预算下，AutoDS显著优于竞争对手，能产生5%-29%更多的L都认为惊奇的发现。进一步的人类评估表明，AutoDS的大部分发现对领域的专家来说都是惊奇的，这表明它是构建开放性ASD系统的重要步骤。", "conclusion": "本研究展示了使用贝叶斯惊奇进行开放式科学发现的有效性，通过这种方法，AutoDS在固定预算内能够产生更多被认为惊奇的发现，并得到了领域专家的认可，表明这是推动开放式科学发现系统的进步。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00248", "html_url": "https://arxiv.org/abs/2507.00248", "title": "使用有限数据开发轻量级DNN模型进行实时手语识别", "title_en": "Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition", "authors": "Nikita Nikitin,Eugene Fomin", "background": "手语识别面临的主要挑战包括数据稀缺性、高计算成本以及训练和推理环境之间的帧率不匹配。针对这些挑战，该研究提出了一种使用轻量级深度神经网络（DNN）的新框架，以便在有限数据下实现实时手语识别。", "innovation": "该研究通过将手语特定参数（如手型、手掌方向、动作和位置）编码成向量化输入，并利用MediaPipe进行关键点提取，实现了高度可区分的输入数据表示。此外，开发的轻量级DNN架构可部署在边缘设备上，具有低于10ms的低延迟，并能准确分类343种手语。研究还设计了一个数据标注平台（slait data）来实现结构化的标签和向量提取。", "conclusion": "该模型在孤立手语识别中达到了92%的准确率，并已被集成到slait ai的网络应用中，展示了稳定的推理性能。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00078", "html_url": "https://arxiv.org/abs/2507.00078", "title": "时间的语言：时间序列基础模型的語言模型视角", "title_en": "The language of time: a language model perspective on time-series foundation models", "authors": "Yi Xie,Yun Xiong,Zejian Shi,Hao Niu,Zhengfu Liu", "background": "随着大型语言模型的兴起，大规模参数的模型在多个领域得到广泛应用，并取得显著成果。时间序列基础模型作为这一范式的扩展，展现出强大的表示能力、泛化能力和跨域迁移能力。然而，这引发了一个基本的悖论：时间序列数据反映了不同的动力系统，直观上跨域迁移似乎是不合理的，这与模型的实际成功形成矛盾。本文从理论和实验两方面探讨基于块的时间序列基础模型的学习机制和泛化能力。研究表明，连续的时间序列块可以被精确量化为一个离散词汇表，其关键统计特性与自然语言的高度一致。这种泛化能力使时间序列模型能够继承大型语言模型的稳健表示和迁移能力，解释了其在时间任务中的出色表现。", "innovation": "本文提出了基于块的时间序列基础模型的学习机制和泛化能力的理论和实证研究。作者认为这类模型不仅仅是应用新的架构，而是从根本上扩展了语言模型的表示范式，即从确定性的向量表示扩展到了潜在的概率分布形式。通过对连续时间序列块进行离散量化，它们能够继承大型语言模型的强大表示和迁移能力，从而解释了它们在时间任务中的出色表现。这项工作为理解、评估和改进大型时间序列基础模型的安全性和可靠性提供了坚实的理论基础。", "conclusion": "本文从理论和实验角度探讨时间序列基础模型的学习机制和泛化能力，提出了其能够继承大型语言模型的稳健表示和迁移能力的观点，解释了其在时间任务中的表现。同时，为理解、评估和改进大型时间序列基础模型的安全性和可靠性提供了理论基础。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00432", "html_url": "https://arxiv.org/abs/2507.00432", "title": "数学推理是否会提升通用大语言模型的能力？理解大语言模型推理的可移植性", "title_en": "Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning", "authors": "Maggie Huan,Yuetai Li,Tuney Zheng,Xiaoyu Xu,Seungone Kim,Minxin Du,Radha Poovendran,Graham Neubig,Xiang Yue", "background": "数学推理已成为大规模语言模型（LLMs）取得进步的标志，最新的模型在MATH和AIME等基准测试上的表现已经超过了人类水平。然而，随着排行榜的持续改进，值得质疑的是，这些进步是否反映了更广泛的问题解决能力，还是仅仅反映了狭窄的过拟合。因此，需要对这些模型进行评估，以了解其表现在不同领域的转移能力。", "innovation": "研究者评估了超过20种开放权重的推理调优模型，并通过控制实验研究不同调优方法（强化学习和监督微调）对模型跨域适应性的影响。实验发现，强化学习调优模型能够在不同领域表现出通用性，而监督微调调优模型往往会忘记普遍能力。进一步通过潜在空间表示和标记空间分布变化分析，表明supervised fine-tuning会引起表示和输出的显著偏移，而强化学习则保留了通用领域的结构。", "conclusion": "研究结果表明，需要重新思考标准后训练食谱，特别是在依赖supervised fine-tuning提炼数据以推进推理模型方面的依赖。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00417", "html_url": "https://arxiv.org/abs/2507.00417", "title": "ASTRO: 通过反思和回溯在上下文中教授语言模型进行推理", "title_en": "ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context", "authors": "Joongwon Kim,Anirudh Goyal,Liang Tan,Hannaneh Hajishirzi,Srinivasan Iyer,Tianlu Wang", "background": "近期通过强化学习（RL）训练大型语言模型（LLMs）已经导致了推理能力显著提升的推理模型的出现。开源复现推理模型虽然成功，但这些模型依赖的内部模型本身已经表现出了较强的推理能力以及早期RL前观察到的搜索行为。因此，如何利用这些模型来提升那些不具备推理能力的语言模型，比如Llama 3的推理能力尚不清楚。ASTRO通过利用蒙特卡洛树搜索（MCTS）的数学问题解决轨迹来构建合成数据集，旨在教导语言模型学习结构化搜索行为。这些合成数据集中的搜索轨迹被转换成自然语言思维链，既捕捉了成功的尝试，也捕捉了从失败中恢复的情况，从而为语言模型提供了丰富的探索先验知识。通过使用这些搜索导出的轨迹进行微调，并利用可验证的奖励进一步改进性能，研究人员尝试解决需要迭代纠正的问题，尤其是MATH-500、AMC 2023和AIME 2024等具有挑战性的问题。", "innovation": "ASTRO通过创建从蒙特卡洛树搜索（MCTS）轨迹中提取的合成数据集，教导语言模型学习结构化搜索行为。这种合成数据集中的搜索轨迹被转换成自然语言思维链，既包含成功的尝试也包含从失败中恢复的过程，从而提供丰富了的探索先验知识。这种方法利用自反性和回溯能力，使语言模型能够更好地进行推理。因此，通过这种方法，研究人员能够显著提高语言模型在数学问题解决方面的表现，特别是在处理需要迭代纠正的问题时。", "conclusion": "研究结果表明，通过这种方法，助手模型（如Llama 3）的推理能力显著增强，在MATH-500上的绝对性能提高了16.0%、AMC 2023上提高了26.9%、AIME 2024上提高了20.0%，特别是在处理需要迭代纠正的难题方面取得了特别显著的改善。这些结果证明了灵感来源于搜索的训练方法对开放语言模型具有原则性的提升效果。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00425", "html_url": "https://arxiv.org/abs/2507.00425", "title": "在基于变换器的自回归流的连续空间中实现灵活的语言建模", "title_en": "Flexible Language Modeling in Continuous Space with Transformer-based Autoregressive Flows", "authors": "Ruixiang Zhang,Shuangfei Zhai,Jiatao Gu,Yizhe Zhang,Huangjie Zheng,Tianrong Chen,Miguel Angel Bautista,Josh Susskind,Navdeep Jaitly", "background": "自回归模型在语言建模方面取得了显著进展。尽管离散标记、单向上下文和单阶段解码是其成功的关键因素，但也促进了对新的建模灵活性维度的探索。本文的研究背景在于利用连续空间替代离散标记空间实现语言建模的新方法。通过引入基于变换器的自回归流，该方法能够捕捉全局双向上下文，并具有分块生成和多阶段生成过程的能力。", "innovation": "该研究提出了一种新的框架TarFlowLM，利用基于变换器的自回归流来模型连续表示。该方法解锁了高度灵活性，支持构建能够捕捉全局双向上下文、分块生成并提供层次多阶段生成过程的模型。通过设计新的混合耦合变换来捕捉离散数据形成的潜空间中的复杂依赖关系，进一步增强了模型的灵活性和性能。理论分析还展示了该方法与传统的离散自回归模型之间的联系。", "conclusion": "在语言建模基准实验中，该框架表现出强大的似然性能，并强调了其固有的灵活建模能力。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00449", "html_url": "https://arxiv.org/abs/2507.00449", "title": "通过上下文相关稀疏注意力克服状态空间模型的长上下文限制", "title_en": "Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention", "authors": "Zhihao Zhan,Jianan Zhao,Zhaocheng Zhu,Jian Tang", "background": "自然语言处理（NLP）中的长时间上下文建模仍然是一个关键挑战，因为基础的Transformer架构的时间复杂度与序列长度成二次关系。虽然状态空间模型（SSMs）提供了次二次解决方案，但它们在捕捉长距离依赖方面表现不佳。传统的关联回忆任务无法充分代表现实世界长时间上下文建模的复杂性，因此提出了新的联合回忆任务来解决这个问题。理论证明SSMs无法在次二次时间内解决多查询联合回忆。因此，提出了一种新的方法，结合状态空间模型与上下文相关稀疏注意（CDSA），解决多查询联合回忆问题。为将理论成果应用到实际问题中，进一步提出了局部敏感哈希注意力（HAX），该方法在自然语言处理领域表现出优异性能，比原有的SSMs基线和上下文无关稀疏注意（CISA）结合的SSMs具有更优的表现。", "innovation": "提出了新的联合回忆任务以改进状态空间模型的长上下文建模能力，理论证明状态空间模型在解决多查询联合回忆问题上的局限性，并提出结合状态空间模型与上下文相关稀疏注意的解决方案。进一步提出局部敏感哈希注意力（HAX）方法，该方法在理论上和实践中都证明了优越性。", "conclusion": "广泛实验表明，HAX在合成和真实世界长时间上下文基准测试中均优于状态空间模型基线和结合上下文无关稀疏注意的状态空间模型。这一研究为改善状态空间模型的长上下文能力提供了新的视角和方法。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00487", "html_url": "https://arxiv.org/abs/2507.00487", "title": "MassTool：大型语言模型的多任务搜索型工具检索框架", "title_en": "MassTool: A Multi-Task Search-Based Tool Retrieval Framework for Large Language Models", "authors": "Jianghao Lin,Xinyuan Wang,Xinyi Dai,Menghui Zhu,Bo Chen,Ruiming Tang,Yong Yu,Weinan Zhang", "background": "工具检索是使大规模语言模型（LLMs）能够有效与外部工具交互的关键组件。现有的大多数方法主要集中在优化工具表示上，往往忽略了精确查询理解的重要性。研究人员注意到这一缺陷，并致力于开发更加全面的方法以提升查询理解和工具检索的精确性。", "innovation": "提出了一种名为MassTool的多任务搜索型框架，旨在同时提高查询表示和工具检索准确性。该框架采用双塔架构，包括用于检测工具使用的工具使用检测塔，以及使用查询为中心的图卷积网络（QC-GCN）进行有效查询-工具匹配的工具检索塔。此外，还整合了基于搜索的用户意图建模（SUIM）以处理多样且不常见查询，以及适应性知识迁移（AdaKT）模块以支持高效的多任务学习。通过联合优化工具使用检测损失、列表式检索损失和对比正则化损失，MassTool建立了一个稳健的两阶段顺序决策管道，以实现精确的查询理解。", "conclusion": "广泛的实验表明，MassTool在提高检索精度方面具有有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00081", "html_url": "https://arxiv.org/abs/2507.00081", "title": "状态和记忆即为所有需要的要素，以实现强大的、可靠的AI代理", "title_en": "State and Memory is All You Need for Robust and Reliable AI Agents", "authors": "Matthew Muhoberac,Atharva Parikh,Nirvi Vakharia,Saniya Virani,Aco Radujevic,Savannah Wood,Meghav Verma,Dimitri Metaxotos,Jeyaraman Soundararajan,Thierry Masquelin,Alexander G. Godfrey,Sean Gardner,Dobrila Rudnicki,Sam Michael,Gaurav Chopra", "background": "大规模语言模型（LLMs）在自然语言理解和生成方面取得了显著进展。然而，它们在处理复杂的科学工作流程时仍然受到内存、规划和工具集成挑战的限制。现有系统在应对这些挑战方面效果有限，尤其是当需要进行复杂决策和长期执行任务时。为此，SciBORG（Scientific Bespoke Artificial Intelligence Agents Optimized for Research Goals）被提出，这是一种模块化的代理框架，允许基于LLM的代理自主规划、推理并执行高可靠性的专门领域任务。该系统利用实时状态跟踪和上下文感知决策制定，使得代理能够在无需手动提示工程的情况下高效执行。通过结合物理和虚拟硬件，使得SciBORG能够在各种应用场景下实现稳定且可扩展的部署。SciBORG 还展示了如何通过多步骤规划、推理、代理间通信和协调执行探索性任务，从而利用PubChem数据库中的多步骤生物测定检索实现自动化。", "innovation": "SciBORG 是一种模块化代理框架，允许基于 LLM 的代理自主规划、推理，并执行高可靠性的专属领域任务。通过结合实时状态跟踪和上下文感知决策制定，SciBORG 在实现长期任务执行、复杂规划和应对工具或执行失败方面具备显著优势，无需手动提示工程。SciBORG 还实现了与物理和虚拟硬件的集成，展示了其在实际应用中的强大性能和可扩展性。特别是通过多步规划、代理间通信与协调执行探索性任务，SciBORG 在探索性科学工作中具有 nouvel作用。系统基准测试展示了 SciBORG 代理的可靠执行、适应性规划和可解释的状态转换能力。研究表明，记忆和状态意识是实现代理规划可靠性的关键因素，为复杂环境下的 AI 代理部署提供了通用基础。", "conclusion": "SciBORG 通过动态构建代理并结合状态跟踪和上下文感知决策，展示了强大的可扩展性和适应性，实现复杂科学任务的可信赖执行。这一框架不仅解决了现有的代理技术在复杂规划和工具集成方面的局限，还为其他环境中的 AI 代理部署提供了广泛适用的基础。未来的工作可以通过进一步优化内存管理和状态跟踪机制来提高 SciBORG 的性能，并探索更广泛的领域应用。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00316", "html_url": "https://arxiv.org/abs/2507.00316", "title": "μ²Tokenizer: 可微多尺度多模态标记器用于放射学报告生成", "title_en": "$μ^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation", "authors": "Siyou Li,Pengyao Qin,Huanan Wu,Dong Nie,Arun J. Thirunavukarasu,Juntao Yu,Le Zhang", "background": "自动化放射学报告生成（RRG）旨在从医学影像（如计算机断层扫描CT）中生成详细的文本报告，以提高诊断准确性和管理建议的效率。RRG面临两大挑战：（1）在资源受限的情况下从影像数据中提取相关信息的内在复杂性；（2）客观评估模型生成的报告与专家撰写的报告之间的差异的难度。为了应对这些挑战，本文提出了一种μ²LLM，这是一种用于RRG任务的多尺度多模态大型语言模型。μ²Tokenizer作为中间层，集成了多尺度视觉标记器和文本标记器的多模态特征，并通过直接偏好优化（DPO）提升了报告生成的质量，该优化由GREEN-RedLlama引导。在四个大型CT影像-报告医学数据集上的实验结果表明，该方法优于现有方法，突显了精细化调整μ²LLMs在有限数据下进行RRG任务的潜力。", "innovation": "提出了一种多尺度多模态大型语言模型μ²LLM，以及一种新的可微多尺度多模态标记器μ²Tokenizer。该模型通过直接偏好优化（DPO）和使用GREEN-RedLlama引导，增强了报告生成的质量。研究表明，这种方法在有限数据下比现有方法表现更优，展现了多尺度多模态大型语言模型在RRG任务中的潜力。", "conclusion": "实验结果表明，本文的方法在四个大型CT影像-报告医学数据集上优于现有方法，说明精细化调整的μ²LLMs在有限数据下也能够有效应用于RRG任务，展示了多尺度多模态大型语言模型在医疗领域的巨大潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00693", "html_url": "https://arxiv.org/abs/2507.00693", "title": "利用大型语言模型进行即兴言语自杀风险检测", "title_en": "Leveraging Large Language Models for Spontaneous Speech-Based Suicide Risk Detection", "authors": "Yifan Gao,Jiao Fu,Long Guo,Hong Liu", "background": "早期识别自杀风险对于预防自杀行为至关重要，因此识别与研究与自杀风险相关的模式和标志成为当前研究的关键焦点。本文介绍了我们在第1届SpeechWellness挑战赛（SW1）中的研究结果，该挑战赛旨在探索言语作为非侵入性和易于获取的心理健康指标以识别具有自杀风险的青少年。研究背景强调了自杀风险早期识别的重要性，并指出言语可以作为一种可能的检测自杀风险的非侵入性手段。", "innovation": "本文提出的方法利用大型语言模型（LLM）作为主要工具来进行特征提取，同时结合传统的声学和语义特征。这种创新的方法在SW1挑战赛中取得了74%的准确率，排名第一，展示了基于LLM的方法在评估自杀风险时分析言语的潜力。", "conclusion": "实验结果证明了基于LLM的方法在自杀风险评估中的分析潜力。该方法通过综合使用大型语言模型和传统声学、语义特征，提高了自杀风险识别的准确性和可靠性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00808", "html_url": "https://arxiv.org/abs/2507.00808", "title": "向专业录制再现的多步骤TTS方法", "title_en": "Multi-interaction TTS toward professional recording reproduction", "authors": "Hiroki Kanagawa,Kenichi Fujita,Aya Watanabe,Yusuke Ijima", "background": "语音导演通常通过提供反馈来迭代地改进语音演员的表演以达到预期效果。在实际录制过程中，这种基于反馈的迭代改进过程非常重要，但在文本到语音合成（TTS）中却被忽视了。因此，即使合成的语音往往与用户的期望风格有所偏差，也难以在初步合成后进行细致的风格调整。", "innovation": "本文提出了一种多步骤交互的TTS方法，允许用户直观快速地调整合成语音。该方法模拟了TTS模型与其用户的交互，模仿了声音演员和声音导演之间的关系。实验证明，所提出的方法及其相应的数据集能够根据用户的指导进行迭代的风格调整，展示了其多步骤交互的能力。示例音频可在此获取：https://ntt-hilab-gensp:this http URL", "conclusion": "实验结果表明，所提出的模型及其相应数据集可以按照用户的方向进行迭代的风格调整，从而证明了其多交互能力。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00466", "html_url": "https://arxiv.org/abs/2507.00466", "title": "使用端到端变压器架构在演奏MIDI中进行节奏和强拍跟踪", "title_en": "Beat and Downbeat Tracking in Performance MIDI Using an End-to-End Transformer Architecture", "authors": "Sebastian Murgul,Michael Heizmann", "background": "音乐表演MIDI的节奏跟踪是一项具有挑战性的任务，对于乐谱级别音乐转录和节奏分析至关重要，但现有方法主要侧重于基于音频的方法。因此，本文提出了一种基于变压器的端到端模型，用于在演奏MIDI中进行节奏和强拍跟踪，采用了编码器-解码器架构将MIDI输入转换为节奏注释。该方法引入了新颖的数据预处理技术，包括动态扩增和优化的分词策略，以提高在不同数据集中的准确性和泛化能力。通过使用A-MAPS、ASAP、GuitarSet和Leduc数据集进行广泛的实验，与最先进的隐马尔可夫模型（HMMs）和基于深度学习的节奏跟踪方法进行比较，结果表明该模型在各种音乐风格和乐器中实现了竞争性的F1分数，优于现有符号音乐节奏跟踪方法。这项研究揭示了变压器架构在符号节奏跟踪中的潜力，并建议将其与自动音乐转写系统结合以增强音乐分析和谱曲生成未来研究的方向。", "innovation": "本文提出了一种基于变压器的端到端模型，用于在演奏MIDI中进行节奏和强拍跟踪，该模型采用了编码器-解码器架构将MIDI输入转换为节奏注释，并引入了动态扩增和优化的分词策略来提高准确性和泛化能力。这种方法在各种音乐风格和乐器中都达到了竞争性的F1分数，优于现有方法。", "conclusion": "研究结果表明，该模型在各种音乐风格和乐器中实现了竞争性的F1分数，优于现有的符号音乐节奏跟踪方法。这揭示了变压器架构在符号节奏跟踪中具有潜在优势，并建议将其与自动音乐转写系统结合以增强音乐分析和谱曲生成。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00877", "html_url": "https://arxiv.org/abs/2507.00877", "title": "可验证自然语言到线性时序逻辑翻译：基准数据集和评估套件", "title_en": "Verifiable Natural Language to Linear Temporal Logic Translation: A Benchmark Dataset and Evaluation Suite", "authors": "William H English,Chase Walker,Dominic Simon,Sumit Kumar Jha,Rickard Ewetz", "background": "现有的自然语言（NL）到形式化时序逻辑（TL）翻译系统的实证研究表明，它们在现有基准上的表现几乎完美。然而，现有的研究仅评估了NL逻辑到形式化TL翻译的准确性，忽略了系统对原子命题进行语义化的能力，这是验证最终公式在具体状态空间中的关键特征。因此，许多NL到TL翻译框架提出了自定义的数据集，这些数据集中的正确语义化是已知的，这使得性能指标被夸大，忽略了需要扩展和通用的系统。因此，该研究提出了Verifiable Linear Temporal Logic Benchmark (VLTL-Bench)，在一个统一的基准中测量自动化NL到LTL翻译的验证和可验证性。基准数据集包含三个独特的状态空间和数千种不同形式的自然语言规范及其相应的形式化规范，并且还包括样本轨迹以验证时序逻辑表达式。", "innovation": "该研究提出了Verifiable Linear Temporal Logic Benchmark (VLTL-Bench)，这是一个统一的基准，用于衡量自动化的NL到LTL翻译的验证和可验证性。基准数据集包含三个独特的状态空间和数千种不同的自然语言规范及其相应的形式化规范，以及样本轨迹来验证时序逻辑表达式。基准数据集在每个步骤后提供了正确的答案，以使研究人员能够改进和评估整个问题的不同子步骤。", "conclusion": "为了促进可验证的NL到LTL翻译方法的实质进步，本文公开了VLTL-Bench。研究人员可以通过访问此网址：this https URLbench来使用该基准进行评估。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00898", "html_url": "https://arxiv.org/abs/2507.00898", "title": "ONLY: 一层干预充分缓解大型视觉语言模型中的幻觉", "title_en": "ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models", "authors": "Zifu Wan,Ce Zhang,Silong Yong,Martin Q. Ma,Simon Stepputtis,Louis-Philippe Morency,Deva Ramanan,Katia Sycara,Yaqi Xie", "background": "近年来，大型视觉语言模型（LVLMs）引入了一种新的范式，通过文本响应理解并推理图像输入。尽管它们在各种跨模态任务中取得了出色的表现，但它们面临着持久的幻觉问题，这导致在实际应用中存在实用的弱点，并引发对其可靠部署的担忧。现有工作探索了对比解码方法以缓解这一问题，通过对比原始LVLM的输出与扰动版本的输出来减轻问题。然而，这些方法需要两个或更多的查询，这会延缓LVLM响应生成，使之不太适合实时应用。", "innovation": "我们提出了一个无需训练的解码方法ONLY，仅需要一次查询和在解码中一层干预，可以有效地实现实时部署。具体来说，通过使用文本到视觉的熵比来选择性放大每个标记的关键文本信息来增强文本输出。广泛的实验结果表明，我们的提议ONLY在各种基准上始终优于最先进的方法，同时其实施努力和计算成本都很低。", "conclusion": "大量实验结果表明，ONLY方法在各种基准上均优于当前最先进的方法，同时在实施和计算成本上都非常经济。此外，ONLY仅需单次查询和一层干预，从而实现实时部署。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2210.06230", "html_url": "https://arxiv.org/abs/2210.06230", "title": "基于Transformer变分自编码器的近似符号语义几何", "title_en": "Quasi-symbolic Semantic Geometry over Transformer-based Variational AutoEncoder", "authors": "Yingji Zhang,Danilo S. Carvalho,André Freitas", "background": "形式/符号语义可以因为其局部化或组合性质，提供规范化、刚性控制和解释性向句子表示。然而，如何将这样的性质引入当前的分布句法表示中，以控制和解释语言模型的生成是一个挑战。本文旨在通过理论框架将句子语义表示为语义角色-词内容特征的组合，并提出了形式语义几何。", "innovation": "本文通过理论框架将句子语义表示为语义角色-词内容特征的组合，提出了形式语义几何。同时，为将这种几何结构引入基于Transformer的变分自编码器（例如GPT2），采用了一种监督方法，使句子生成可以被操控并解释在低维度的潜空间中。此外，还提出了一个新的探针算法来引导句向量在该几何结构上的移动。这些方法显示形式语义几何能够更好地控制和解释句子生成。", "conclusion": "实验结果显示，形式语义几何可以潜在地提高句子生成的控制和解释能力。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2401.14640", "html_url": "https://arxiv.org/abs/2401.14640", "title": "大语言模型能评估复杂的问题答案归因吗？基于知识图谱的自动基准测试", "title_en": "Can LLMs Evaluate Complex Attribution in QA? Automatic Benchmarking using Knowledge Graphs", "authors": "Nan Hu,Jiaoyan Chen,Yike Wu,Guilin Qi,Hongru Wang,Sheng Bi,Yongrui Chen,Tongtong Wu,Jeff Z. Pan", "background": "归因型问题回答（AQA）引起了广泛的关注，但仍存在归因评估方面的几个限制，包括缺乏细粒度的归因类别、依赖于人工注释以及无法比较只有细微差别的归因。基于此现状，本文提出了复杂的归因型问题回答（CAQA），它包含全面的归因类别，并使用知识图谱（KGs）自动生成，还涵盖了复杂的归因场景。", "innovation": "本文引入了CAQA，一个大规模的基准测试，包括全面的自动生成的归因类别和复杂归因场景。进行了广泛实验验证CAQA的有效性，包括25个自动评估器的基准测试、与人工评估者的比较、使用CAQA微调的LLM评估者测试等。这些实验揭示了一系列重要的发现，有助于未来AQA的研究。", "conclusion": "实验结果表明CAQA是一个有效且全面的基准测试工具，可用于进一步探究和提升AQA技术。所有代码和数据已经公开，便于研究者们使用和改进。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00740", "html_url": "https://arxiv.org/abs/2507.00740", "title": "安全低带宽SPV：简化支付验证协议的形式处理及其安全边界", "title_en": "Safe Low Bandwidth SPV: A Formal Treatment of Simplified Payment Verification Protocols and Security Bounds", "authors": "Craig S Wright", "background": "本文论文探讨了简化支付验证（SPV）协议的完整形式化规范、协议描述以及数学证明结构，这些内容最初在比特币白皮书中定义。与流行的实现方式误导不同，本文展示了在有界对手假设下SPV不仅安全，而且在需要可扩展和可验证交易纳入的数字现金系统中是严格最优的选择。论文重建了SPV协议的基础，将其验证模型建立在符号自动机、Merkle成员关系和证明链鉴别谓词之上。通过严格的概率和博弈论分析，推导出协议安全操作的经济界限，在部分连接、敌对中继网络及对手传播延迟的情况下验证其活跃性和安全性属性。此外，规范引入了低带宽优化措施如自适应轮询和压缩头同步，同时保持正确性。本文不仅作为安全SPV实现的蓝图，还驳斥了关于非验证客户端的常见误解。", "innovation": "1. 重建了SPV协议的基础，将其验证模型建立在符号自动机、Merkle成员关系和证明链鉴别谓词之上。\n2. 通过严格的概率和博弈论分析，推导出了协议的经济界限，在各种条件下验证了其活跃性和安全性。\n3. 引入了低带宽优化措施，如自适应轮询和压缩头同步，同时保持正确性。\n4. 提出了一种安全SPV实施的蓝图，并驳斥了关于非验证客户端的常见误解。", "conclusion": "本文探讨了SPV协议的完整形式化规范、协议描述及其数学证明结构。通过严格的分析，证明了SPV在有界对手假设下的安全性以及其在数字现金系统中的最优性。文章进一步引入了低带宽优化措施。本文不仅为安全SPV实现提供了蓝图，还启示了对于非验证客户端常见误解的覆盘。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.14373", "html_url": "https://arxiv.org/abs/2412.14373", "title": "ECG-Byte: 一种用于端到端生成心电图语言模型的分词器", "title_en": "ECG-Byte: A Tokenizer for End-to-End Generative Electrocardiogram Language Modeling", "authors": "William Han,Chaojing Duan,Michael A. Rosenberg,Emerson Liu,Ding Zhao", "background": "大型语言模型（LLMs）在各个领域中表现出色，包括心电图（ECGs）的应用。现有方法通常采用两阶段流程：首先使用自监督学习（SSL）目标进行心电图特定编码器的预训练，然后使用编码器生成的特征对大型语言模型进行微调以进行自然语言生成（NLG）。然而，这些方法存在多阶段训练效率低下和解释编码器生成特征的挑战两个关键问题。", "innovation": "我们提出了ECG-Byte，这是一种针对心电图自回归语言建模的适应性字节对编码（BPE）分词器流程。ECG-Byte 将心电图信号压缩并编码为令牌，并通过结合心电图和文本令牌直接实现了端到端的大语言模型训练。这种方法增强了解释性，因为心电图令牌可以直接映射回原始信号。利用ECG-Byte，我们实现了具有竞争力的NLG性能，同时训练速度提高了三倍，并且只需要传统两阶段方法所需数据量的48%。", "conclusion": "本研究通过提出ECG-Byte，提供了一种直接对大语言模型进行端到端训练的方法，通过结合心电图和文本的令牌化，提高了模型的效果和解释性，同时显著减少了数据要求和训练时间。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.14405", "html_url": "https://arxiv.org/abs/2410.14405", "title": "事实回忆、启发式方法还是纯粹猜测？语言模型对事实完成的精确解释", "title_en": "Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion", "authors": "Denitsa Saynova,Lovisa Hagström,Moa Johansson,Richard Johansson,Marco Kuhlmann", "background": "当前对语言模型（LMs）的解释未充分考虑到它们基于提示中的多种信号进行合理预测的事实，而不仅仅是基于记忆事实关联。例如，当查询“阿斯黛尔·林德格伦出生在”并得到“瑞典”的响应时，人们没有区分预测是基于知道作者的出生地，还是假设了一个听起来像瑞典名字的人就出生在瑞典。该研究旨在通过构建包含四种不同预测场景的自定义数据集（普ISM）来解决这一问题：通用语言建模、猜测、启发式回溯和精确事实回忆。通过对两种流行的可解释性方法进行应用，即因果追踪和信息流分析，研究发现每种场景的结果都是独特的。这对事实回忆的精确性和通用语言建模场景保持了之前关于中期MLP子层重要性的结论，而在猜测和启发式场景中，发现最后的MLP子层扮演着关键角色。", "innovation": "该研究提出了一个专为事实完成的自定义数据集构建方法PrISM（Prism），该方法涵盖了四种不同类型的预测场景：通用语言建模、猜测、启发式回忆和精确事实回忆。此外，应用了两种流行的可解释性方法——因果追踪和信息流分析，以揭示每种场景的不同结果", "conclusion": "研究提供了更多关于语言模型在处理事实相关查询时如何工作的细致分析，证实了情节记忆在事实回忆中的重要作用，并发现当使用启发式或猜测方法时，模型后期的MLP子层尤其重要。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.04370", "html_url": "https://arxiv.org/abs/2406.04370", "title": "通过黑盒访问进行大型语言模型置信度估计", "title_en": "Large Language Model Confidence Estimation via Black-Box Access", "authors": "Tejaswini Pedapati,Amit Dhurandhar,Soumya Ghosh,Soham Dan,Prasanna Sattigeri", "background": "在评估模型响应的信任度时，估计响应的不确定性和置信度是至关重要的，这不仅能评估单个响应，还能整体评估模型。本文关注利用黑盒或查询访问方式，对于大型语言模型（LLMs）的响应置信度进行估计的问题。通过这种方式，希望构建一个简单但有效的框架，能估计多个大型语言模型在不同任务上的置信度，并且在某些情况下还优于基线方法，甚至在AUROC指标上高出10%以上。此外，该方法还有助于揭示预测置信度的关键特征，使得不同模型上的置信度模型实现零样本泛化。", "innovation": "提出了一个简单且可扩展的框架，通过工程师的新颖特征，使用逻辑回归等可解释模型来估计置信度。此框架在多种任务和不同的大型语言模型上进行了测试，并且表现出优异的性能。特别地，该方法不仅能够有效估计多个大型语言模型的置信度，还能实现零样本泛化，即在未见过的数据集上，也能对不同模型的响应置信度进行有效估计，并且在某些情况下优于基线方法。这种框架在保持模型简单的同时，提供了可解释性，有助于理解关键特征对置信度的影响。", "conclusion": "本文通过简单的黑盒或查询访问方式，建立了大型语言模型置信度估计的框架，表明该方法在多个基准任务和大型语言模型上的应用中表现出卓越的性能，并具备零样本泛化的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00979", "html_url": "https://arxiv.org/abs/2507.00979", "title": "通过因果影响提示增强大型语言模型代理的安全性", "title_en": "Enhancing LLM Agent Safety via Causal Influence Prompting", "authors": "Dongyoon Hahm,Woogyeol Jin,June Suk Choi,Sungsoo Ahn,Kimin Lee", "background": "随着由大型语言模型（LLMs）驱动的自主代理在各种辅助任务中展示出潜力，确保其行为的安全和可靠性变得至关重要，以避免意外后果。因此，研究如何提高这些代理的安全性变得非常重要。论文介绍了一种名为CIP的新方法，利用因果影响图（CIDs）不仅识别，还减轻代理决策过程中产生的风险。CIDs提供了一种结构性的因果关系表示，使代理能够预见到潜在的危害结果并做出更安全的决策。该研究通过结构化的步骤实现这一目标：首先基于任务规范初始化CIDs，然后让代理用CIDs进行环境交互，最后根据观察到的行为和结果迭代改进CIDs。实验表明，这种方法在代码执行和移动设备控制等任务中显著提高了安全性。", "innovation": "该研究提出了CIP（Causal Influence Prompting）方法，利用因果影响图（CIDs）来识别和缓解由代理决策引发的风险。CIDs为因果关系提供了一种结构化的表示方式，让代理能够预见潜在的不良后果，并进行更安全的决策。该方法提供了一个基于任务规范初始化CIDs、代理用CIDs与环境交互以及根据观察结果迭代改进CIDs的过程。", "conclusion": "实验结果表明，该方法在代码执行和移动设备控制等任务中有效提升了安全性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.15044", "html_url": "https://arxiv.org/abs/2503.15044", "title": "SPADE: 结构化提示增强在机器生成文本检测中对话增强", "title_en": "SPADE: Structured Prompting Augmentation for Dialogue Enhancement in Machine-Generated Text Detection", "authors": "Haoyi Li,Angela Yifei Yuan,Soyeon Caren Han,Christopher Leckie", "background": "大型语言模型（LLMs）生成合成内容的能力日益提高，引发了对其被误用的担忧，从而推动了机器生成文本（MGT）检测模型的发展。然而，这些检测器面临显著挑战，因为缺少高质量的合成数据集进行训练。", "innovation": "提出了一个结构化的框架SPADE，使用基于提示的正负样本检测合成对话。SPADE产生了14个新的对话数据集，并在八个MGT检测模型上进行了基准测试。此外，研究了聊天历史长度对在线对话检测准确性的影响，提供了增强LLM应用安全的实际方法。", "conclusion": "利用提出的增强框架生成的混合数据集在泛化性能上有所提升，开放源代码数据集、代码和提示可在指定链接下载。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.01141", "html_url": "https://arxiv.org/abs/2410.01141", "title": "使用NLP和LLMs评估经济研究论文标题去重技术的语义相似性", "title_en": "Evaluating Deduplication Techniques for Economic Research Paper Titles with a Focus on Semantic Similarity using NLP and LLMs", "authors": "Doohee You,S Fraiberger", "background": "本文研究了大规模NLP数据集中的经济研究论文标题的高效去重技术。研究通过探索各种配对方法以及传统的距离度量方法（如Levenshtein距离和余弦相似度）和基于语义评估的sBERT模型，旨在评估这些方法在不同情况下对标题去重的效果。根据实验结果，文章发现这些方法在不同方法中显示出较低的语义相似度，暗示潜在的重复实例较少。为此，研究进一步使用了人工注释的数据集作为基准评估，以得出更明确的结论，研究表明基于NLP和LLMs的距离度量方法与之前的研究结果一致。", "innovation": "引入了额外的语义相似度评估方法（如sBERT模型）来提高去重技术的有效性。通过使用人工标注的数据集进行更深入的评估，旨在验证初始发现的有效性。进一步地，结合NLP和LLMs的距离度量方法为经济研究论文标题的去重提供了新的方法论支持。", "conclusion": "研究基于实验数据发现，通过多种方法评估，经济研究论文的标题中潜在的重复现象较为罕见。更深入的实验结果支持了NLP和LLMs在距离度量和语义相似度评估方面的有效性。为进一步提高去重质量，建议未来研究可以使用更多的实际数据集进行测试，从而全面验证这些方法的实际效用。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01144", "html_url": "https://arxiv.org/abs/2501.01144", "title": "BlockDialect: 块级细粒度混合格式量化技术用于高效的大语言模型推理", "title_en": "BlockDialect: Block-wise Fine-grained Mixed Format Quantization for Energy-Efficient LLM Inference", "authors": "Wonsuk Jang,Thierry Tambe", "background": "大语言模型（LLMs）的规模在迅速增加，这带来了内存使用和计算成本的显著挑战。量化权重和激活值可以解决这些问题，而硬件支持的细粒度缩放被看作一种缓解异常值的有效方案。然而，现有的方法难以捕捉复杂的块数据分布。背景内容中详细介绍了这些问题以及现有方法的限制。", "innovation": "本文提出了BlockDialect，一种块级细粒度混合格式技术，通过从格式书中选择每个块的最佳数量格式来改进数据表示。还介绍了DialectFP4格式书，包含了适应多种数据分布的FP4变体格式（类似于方言）。为了高效利用这种方法，提出了两阶段的在线DialectFP4激活量化方案。此外，DialectFP4通过选择可表示的值作为与低精度整数算术兼容的缩放整数来确保能量效率。相比MXFP4格式，BlockDialect在LLaMA3-8B和LLaMA2-7B模型上的准确率分别提高了10.78%（7.48%），使用的比特数更低，并且在全路径矩阵乘法量化时仍能保持94.55%（97.31%）的精度。创新点在于解决如何表示而非如何缩放的问题，为高效LLM推理提供了新的途径。", "conclusion": "该研究展示了一种能量高效的LLM推理方法，能够实现高精度和低计算成本，对于大语言模型的部署具有重要意义。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03040", "html_url": "https://arxiv.org/abs/2503.03040", "title": "SAGE：增强对话生成的面向未来的状态-动作扩充", "title_en": "SAGE: Steering Dialog Generation with Future-Aware State-Action Augmentation", "authors": "Yizhe Zhang,Navdeep Jaitly", "background": "近期大型语言模型在任务导向的应用中表现出显著的能力，但构建能够进行自然、策略性对话的具备情感智能的聊天机器人仍然存在挑战。现有的方法通过标准的语言模型微调无法很好地控制长周期对话行为，限制了聊天机器人的智能化水平。本文基于此背景，提出了一个名为SAGE的新颖方法，通过引入潜在变量来控制对话生成中的长期行为。这些潜在变量能够涵盖对话回合之间的状态和战略，使得对话生成能够更好地控制对话进程，同时保持自然的对话模式。", "innovation": "该方法的核心在于State-Action Chain（SAC），其通过引入潜在变量来增强标准语言模型微调的过程，使得模型能够更好地控制对话状态和策略，从而提高对话的自然度和智能化水平。此外，还提出了一种自我改进管道，利用对话树搜索、基于LLM的奖励建模和目标导向的微调来优化对话轨迹。这种方法允许进行基于搜索的策略，为进一步将强化学习应用于对话系统提供了基础，使其能够以状态水平进行学习，而不仅仅是在标记级别。", "conclusion": "实验结果显示，通过这种方法训练的模型在情感智能评估指标上表现出色，同时在语言模型基准测试中也具有强大的能力。潜在变量的离散性质为进一步研究利用强化学习来控制对话系统状态奠定了基础。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21248", "html_url": "https://arxiv.org/abs/2503.21248", "title": "基于启发式任务分解的L大型语言模型在科学研究中的基准测试：ResearchBench", "title_en": "ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition", "authors": "Yujie Liu,Zonglin Yang,Tong Xie,Jinjie Ni,Ben Gao,Yuqiang Li,Shixiang Tang,Wanli Ouyang,Erik Cambria,Dongzhan Zhou", "background": "大型语言模型（LLMs）在辅助科学研究方面显示出了潜力，但它们发现高质量研究假设的能力尚未得到验证，因为缺乏专门的基准测试。为填补这一空白，本研究引入了首个大规模的LLM评估基准，涵盖科学研究的近充分子任务：灵感检索、假设合成和假设排序。研究人员开发了一种自动化框架，从12个学科的科学论文中提取关键组成部分，并通过专家验证确保其准确性。此外，为了防止数据污染，研究仅聚焦于2024年发表的论文，以确保与LLM预训练数据的最小重叠。", "innovation": "该研究首次推出了一个大规模的基准来评估LLMs，涵盖科学研究的近充分子任务，这是通过启发式任务分解实现的。研究涵盖了灵感检索、假设合成和假设排序等任务，并且在数据收集和处理方面采取了严格的控制措施，以避免污染。研究结果显示，LLMs在出分布任务（灵感检索）中的表现良好，显示出其出让挖掘新型知识关联的能力，将其定位为“研究假设矿”，能够大规模生成创新性假设，减少人类干预。", "conclusion": "研究发现，LLMs在检索灵感方面表现出色，表明它们能够揭示新的知识关联，预示着LLMs可能作为“研究假设矿”，能够大规模地生成创新性假设，减少人工干预，促进自动化的科学研究发现。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14051", "html_url": "https://arxiv.org/abs/2502.14051", "title": "RocketKV: 通过两阶段KV缓存压缩加速长上下文LLM推理", "title_en": "RocketKV: Accelerating Long-Context LLM Inference via Two-Stage KV Cache Compression", "authors": "Payman Behnam,Yaosheng Fu,Ritchie Zhao,Po-An Tsai,Zhiding Yu,Alexey Tumanov", "background": "大语言模型依赖KV缓存来高效处理解码阶段中的长上下文，但KV缓存的大小随输入长度线性增长，导致内存带宽和容量负担增大。现有方法难以解决这一挑战。", "innovation": "提出了一种无需训练的KV缓存压缩策略RocketKV，包含两个连续阶段。第一阶段对输入序列进行粗粒度的永久KV缓存清除。第二阶段采用混合稀疏注意机制进行细粒度的top-k稀疏注意。通过一方面在注意力分数上利用头和序列维度的减少，另一方面提供最高400倍压缩比、解码阶段最大3.7倍的速度提升以及GPU峰值内存减少26.5%，同时在多种长上下文任务上几乎保持了零准确度损失。另外还提出适用于多轮场景的RocketKV变体，该变体在所有测试中表现出优异性能，接近最优的top-k注意力方案。", "conclusion": "RocketKV在加速大语言模型处理长上下文任务方面取得了显著效果，通过两阶段压缩策略在保持或接近最优准确度的前提下，大幅减少了内存使用并提升了速度。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16722", "html_url": "https://arxiv.org/abs/2505.16722", "title": "突破mBad！跨语言去毒的监督微调", "title_en": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "authors": "Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen", "background": "随着大型语言模型（LLMs）在全球应用中的普及，确保它们在各种语言背景下都是无毒的仍然是一个关键挑战。跨语言去毒是一种跨语言方法，能在不同语言谱系的高资源语言和低资源语言之间缓解毒性，使其去毒能力能够相互转移。该研究通过392种广泛的场景设置，分析了跨语言去毒的有效性，特别是在数据有限的跨分布设置下减少毒性的方式，并探讨了缓解措施如何影响模型在非毒性任务上的表现，揭示了安全性与知识保留之间的权衡。", "innovation": "该研究提出了跨语言去毒这一方法，旨在使大型语言模型在不同语言谱系之间缓解毒性问题，实现去毒能力的转移。通过监督微调方法，在数据有限的条件下分析了去毒的有效性和影响，揭示了安全性和知识保留之间的权衡。该研究的代码和数据集已经公开。", "conclusion": "该研究通过跨语言去毒方法，提高了大型语言模型在全球多语言应用中的安全性，同时探讨了缓解毒性对模型性能的影响，为该领域的进一步研究奠定了基础。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.09310", "html_url": "https://arxiv.org/abs/2501.09310", "title": "基于即席学习的文本到SQL错误研究", "title_en": "A Study of In-Context-Learning-Based Text-to-SQL Errors", "authors": "Jiawei Shen,Chengcheng Wan,Ruoyi Qiao,Jiazhen Zou,Hang Xu,Yuchen Shao,Yueling Zhang,Weikai Miao,Geguang Pu", "background": "大型语言模型（LLMs）被采用来执行文本到SQL任务，利用其即席学习（ICL）能力将自然语言问题转化为结构化查询语言（SQL）。然而，这种技术面临着正确性问题，需要高效的修复方案。现有的错误修复尝试在低计算开销的情况下提供了有限的正确性改进，但导致了很多误修复。因此，本文对文本到SQL的错误进行了首次全面研究，涵盖了四种代表性的即席学习技术、五种基本修复方法、两个基准和两种LLM设置。研究发现这种错误很普遍，总结了7类29种错误类型，并指出现有修复方法在低计算开销的情况下无法提供显著的正确性改进，且错误修复率不高。", "innovation": "本文提出了MapleRepair，这是一种新颖的文本到SQL错误检测和修复框架。评价表明，MapleRepair 通过纠正比现有解决方案更多的查询（13.8%），同时减少误修复和计算开销（67.4%），表现出色。", "conclusion": "文本到SQL错误非常普遍，本文研究了七类共29种错误类型。现有修复方法效率低下且准确性有限，而提出的MapleRepair框架显著提高了查询修复的数量，并减少了计算开销。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21096", "html_url": "https://arxiv.org/abs/2506.21096", "title": "DALR：多模态句表示学习的双层对齐学习", "title_en": "DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning", "authors": "Kang He,Yuzhe Ding,Haining Wang,Fei Li,Chong Teng,Donghong Ji", "background": "之前的跨模态句表示学习方法取得了显著的效果，但大多数方法集中在粗粒度的图文对齐，存在跨模态偏见和模内语义分化这两个关键挑战，这严重影响了句表示的质量。", "innovation": "提出了一种名为DALR的双层对齐学习方法，为跨模态对齐设计了一种一致性学习模块，使用辅助任务的语义相似性实现精细的跨模态对齐。同时，提出融合全局模内对齐学习和排名蒸馏，以更好地捕捉句间关系并提升表示质量。", "conclusion": "实验结果表明，DALR在语义文本相似性(STS)和迁移任务(TR)上优于当前最先进的基准方法，验证了其有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17080", "html_url": "https://arxiv.org/abs/2505.17080", "title": "非心智，而是符号：通过符号学重新定义LLMs", "title_en": "Not Minds, but Signs: Reframing LLMs through Semiotics", "authors": "Davide Picca", "background": "本文挑战了将大型语言模型（LLMs）视为认知系统的普遍倾向，而是提出了一个符号视角，将其置于更广泛的符号操作和意义构建动态中。而非假设LLMs理解语言或模拟人类思维，本文认为它们的主要功能是基于概率关联重新组合、重新语境化和循环语言形式。从认知论框架转向符号论框架，有助于避免拟人化，更精准地理解LLMs如何参与文化过程，而不是通过思考，而是通过生成需要解读的文字。通过理论分析和实际例子，本文展示了LLMs作为符号代理的工作机制，其输出可以被视为需要情境协商和批判反思的解释行为。", "innovation": "本文提出了一种符号视角，强调LLMs通过生成文字来参与文化过程，而非理解语言或模拟人类思维。通过基于符号学的分析，本文提供了一种更精准且伦理上更为自觉的框架，用于研究和使用LLMs，并重新定义LLMs在拟人化生态中的角色为技术参与者，而非心智拥有者。这种视角促使我们重新考虑语言、解释的基础以及人工系统在知识生产中的角色。", "conclusion": "本文通过符号学框架，重新定义了LLMs的角色，将其视为技术参与者，而不仅仅是心智的拟人化。文章通过说明LLMs如何作为符号代理在文学、哲学、教育和文化生产中的应用，以及它们作为创造力工具、对话平台和批判性研究手段的作用，强调了符号学范式对于理解LLMs的文化功能和伦理重要性的贡献。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.19856", "html_url": "https://arxiv.org/abs/2504.19856", "title": "Efficient Domain-adaptive Continual Pretraining for the Process Industry in the German Language", "title_en": "Efficient Domain-adaptive Continual Pretraining for the Process Industry in the German Language", "authors": "Anastasia Zhukova,Christian E. Matt,Bela Gipp", "background": "当前的技术如DAPT需要进一步训练语言模型（LM），然而在某些情况下，由于缺乏标记任务数据，不能通过LM微调进行通用领域适应。在非英语语言如德语的特定领域，收集这种相关的大量数据尤为困难，尤其是在过程工业这样的领域中。现有的基于掩码语言模型（MLM）的方法需要大量与目标领域相关的数据，但这对于特定行业和少数语言来说是个挑战。因此，本文提出了一种新的方法，ICL-APT，结合在上下文学习和k最近邻算法，以减少GPU时间并保持高性能。这种方法在某些特定领域中提供了更有效的替代方案，特别是在计算资源有限的环境中。", "innovation": "提出了一种结合上下文学习（ICL）和k最近邻（kNN）技术以增强目标数据的高效领域适应持续预训练方法（ICL-APT）。这种创新的方法显著减少了GPU时间，同时保持了模型的高性能，为计算资源有限的工业提供了经济高效的解决方案。ICL-APT在某些特定领域性能上超过了现有的DAPT方法，并且所需GPU计算时间减少了大约四倍，这为低资源行业的NLP解决方案提供了更广泛的应用可能。", "conclusion": "ICL-APT方法不仅在性能上优于现有的DAPT方法，而且显著减少了GPU计算时间，降低了对计算资源的需求。这种方法在低资源行业中的应用表明，NLP技术可以更加经济并且可行地应用于生产环境，对于致力于减少计算开销的行业尤其重要。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19089", "html_url": "https://arxiv.org/abs/2506.19089", "title": "语言模型可能不理解你：通过故事提示评估理论思维", "title_en": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting", "authors": "Nathaniel Getachew,Abulhair Saparov", "background": "先前的基准可能受到预训练数据污染的影响，而本文介绍的StorySim框架通过生成合成故事来评估大型语言模型（LLMs）的理论思维（ToM）和世界建模（WM）能力，能够精确操控角色视角和事件。这项研究设计了基于WM的任务和ToM任务，并控制了追踪和建模心理状态的能力。实验结果显示大多数模型在WM任务上的表现优于ToM任务，且模型在处理人类相比无生命物体时表现更好。研究还发现了一些启发式行为的证据，如近因偏差和过高依赖早期事件。所有用于生成数据和评估的代码均可公开获取。", "innovation": "提出了StorySim框架，该框架能够生成合成故事以评估LLMs的ToM和WM能力。StorySim通过故事板锚定新颖且组合的故事提示，实现对角色视角和事件的高度可控。该框架设计了能够控制跟踪和建模心理状态的ToM和WM任务，以精确评估模型的能力，发现了启发式行为的证据。", "conclusion": "研究发现大多数LLMs在WM任务上的表现优于ToM任务。模型在处理人类相比无生命物体时表现更好。此外，还揭示了一些启发式行为，如近因偏差和过高依赖早期事件。所有数据生成和评估代码均公开发布。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24778", "html_url": "https://arxiv.org/abs/2505.24778", "title": "重新审视信心表达标记在不确定性估计中的作用：标记能否准确反映大规模语言模型的不确定性？", "title_en": "Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?", "authors": "Jiayu Liu,Qing Zong,Weiqi Wang,Yangqiu Song", "background": "随着大规模语言模型（LLMs）在高风险领域中的广泛应用，准确评估其置信度变得至关重要。人类通常通过表层标记（如“相当有信心”）来表达信心，而不是通过数值。然而，尚未清楚LLMs是否一致地使用这些标记来反映其内在置信度，因为与各种标记相关的不确定性量化困难。本文首先定义标记置信度为模型在使用表层标记时观察到的准确性。研究在多个问答数据集中的分布内和分布外场景中，对开源和专有LLM进行了评价。结果表明，尽管标记在相同分布内表现良好，但在分布外场景中其置信度却不一致。由此表明表层标记用于置信度估计的可靠性值得关注，强调了改进基于标记的置信度与实际模型不确定性之间的对齐的必要性。", "innovation": "本文通过定义标记置信度并在这几个重要的LLM数据集上进行了广泛的评估。研究发现，虽然标记在分布内表现良好，但在分布外场景中其置信度却不一致，从而对基于标记的置信度估计方法提出了质疑。这为改进大语言模型不确定性估计提供了一种新的视角。", "conclusion": "本文的研究结果揭示了表层信心标记在解决不确定性估计问题中的局限性，强调了在使用这些标记来评估模型置信度时需要更加谨慎。希望这项工作能够促使未来研究致力于解决标记与模型实际不确定性的不一致性问题，从而提高LLMs在高风险领域中的应用可靠性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21393", "html_url": "https://arxiv.org/abs/2503.21393", "title": "通过情感和语义分析评估大型语言模型和谷歌翻译在选定印度语言翻译中的表现", "title_en": "An evaluation of LLMs and Google Translate for translation of selected Indian languages via sentiment and semantic analyses", "authors": "Rohitash Chandra,Aryan Chaudhari,Yeshwanth Rayavarapu", "background": "大型语言模型（LLMs）在语言翻译领域取得了显著进展，特别是在低资源语言方面。然而，关于通过LLMs生成的翻译质量评估的研究仍然有限，特别是对于如梵语、泰卢固语和印地语等印度语言。现有研究主要集中于采用情感和语义分析方法，专门针对这些特定语言来评估模型生成的翻译质量。研究所选择的经典文本，包含专家已有高质量翻译的内容，以对比LLMs与人工翻译的表现。研究表明，尽管LLMs在翻译准确度上取得了重大进步，但在保留情感色彩和语义完整性方面，尤其是对于诸如《薄伽梵歌》等具有比喻性和哲学性内容的文本时，仍然存在挑战。GPT模型在情感极性保留方面表现优于人工翻译，但总体而言，GPT模型在情感和语义方面优于Google Translate.", "innovation": "本研究创新性地使用情感和语义分析方法来评估大型语言模型（如Gemini、GPT等）和谷歌翻译在印度语言翻译中的表现。研究选取了具有高度翻译挑战的经典文本，这些文本已有专家级的人工翻译作为参照，以此来对比LLMs生成的翻译质量。不同于现有研究集中在某些具体语言或一次性翻译任务，本研究提供了一个系统的方法来评估不同LLMs在印度语言翻译中的表现。", "conclusion": "本研究揭示，虽然大型语言模型在翻译准确性上取得了显著进步，但它们在情感保留和语义完整性方面的表现仍然有限，尤其是在富含比喻和哲学内容的文本翻译中。GPT模型在情感极性保留方面优于人工翻译。整体而言，GPT模型比Google Translate在情感和语义方面有更好的表现。本研究有助于开发更准确和文化敏感的翻译系统以供大型语言模型使用。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21098", "html_url": "https://arxiv.org/abs/2506.21098", "title": "ComRAG：利用动态向量存储的检索增强生成方法用于工业领域实时社区问答", "title_en": "ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry", "authors": "Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan", "background": "社区问答（CQA）平台在社区中扮演着重要的知识库角色，但如何有效利用历史交互和领域知识实现实时应用仍然是一个挑战。现有的方法往往在利用外部知识、整合动态历史问答语境或开发适合工业部署的记忆机制方面存在不足。", "innovation": "提出了一种名为ComRAG的检索增强生成框架，它通过基于质心的记忆机制将静态知识与动态历史问答对结合起来，以适应工业领域的实时CQA。ComRAG的方法能够在检索、生成和存储方面实现高效处理，并且在工业CQA数据集上的实验证明了其在向量相似度、延迟和块增长方面的优势表现。", "conclusion": "ComRAG在三个工业CQA数据集上均优于所有基准模型，分别实现了最高达25.9%的向量相似度提升、8.7%至23.3%的延迟降低，并且迭代过程中块增长降低了高达20.23%到2.06%。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23431", "html_url": "https://arxiv.org/abs/2506.23431", "title": "流水线解码器用于高效上下文感知文本生成", "title_en": "Pipelined Decoder for Efficient Context-Aware Text Generation", "authors": "Zixian Huang,Chenxu Niu,Yu Gu,Gengyang Xiao,Xinwei Huang,Gong Cheng", "background": "自回归模型作为生成AI的基础，需要根据所有先前生成的令牌来生成一个新的令牌，这确保了高质量生成，但也限制了模型以单个令牌的方式生成，形成了生成速度的瓶颈。", "innovation": "本文提出了一种新的解码器架构，可以并行生成文本，以适应上下文感知的生成任务。该提出的流水线解码器同时启动多个子序列的生成，并在每个时间步长中为每个子序列生成一个新的令牌，实现并行性。实验表明，在包括问答、文本摘要和关键短语生成等多种文本生成任务中，流水线解码器显著提高了生成速度，而没有显著损失生成质量和额外的内存消耗。", "conclusion": "本文提出的流水线解码器可以在不牺牲生成质量和内存消耗的前提下有效提高生成速度。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.00949", "html_url": "https://arxiv.org/abs/2505.00949", "title": "Llama-Nemotron: 效率型推理模型", "title_en": "Llama-Nemotron: Efficient Reasoning Models", "authors": "Akhiad Bercovich,Itay Levy,Izik Golan,Mohammad Dabbah,Ran El-Yaniv,Omri Puny,Ido Galil,Zach Moshe,Tomer Ronen,Najeeb Nabwani,Ido Shahaf,Oren Tropp,Ehud Karpas,Ran Zilberstein,Jiaqi Zeng,Soumye Singhal,Alexander Bukharin,Yian Zhang,Tugrul Konuk,Gerald Shen,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Yoshi Suhara,Olivier Delalleau,Zijia Chen,Zhilin Wang,David Mosallanezhad,Adi Renduchintala,Haifeng Qian,Dima Rekesh,Fei Jia,Somshubra Majumdar,Vahid Noroozi,Wasi Uddin Ahmad,Sean Narenthiran,Aleksander Ficek,Mehrzad Samadi,Jocelyn Huang,Siddhartha Jain,Igor Gitman,Ivan Moshkov,Wei Du,Shubham Toshniwal,George Armstrong,Branislav Kisacanin,Matvei Novikov,Daria Gitman,Evelina Bakhturina,Prasoon Varshney,Makesh Narsimhan,Jane Polak Scowcroft,John Kamalu,Dan Su,Kezhi Kong,Markus Kliegl,Rabeeh Karimi,Ying Lin,Sanjeev Satheesh,Jupinder Parmar,Pritam Gundecha,Brandon Norick,Joseph Jennings,Shrimai Prabhumoye,Syeda Nahida Akter,Mostofa Patwary,Abhinav Khattar,Deepak Narayanan,Roger Waleffe,Jimmy Zhang,Bor-Yiing Su,Guyue Huang,Terry Kong,Parth Chadha,Sahil Jain,Christine Harvey,Elad Segal,Jining Huang,Sergey Kashirsky,Robert McQueen,Izzy Putterman,George Lam,Arun Venkatesan,Sherry Wu,Vinh Nguyen,Manoj Kilaru,Andrew Wang,Anna Warno,Abhilash Somasamudramath,Sandip Bhaskar,Maka Dong,Nave Assaf,Shahar Mor,Omer Ullman Argov,Scot Junkin,Oleksandr Romanenko,Pedro Larroy,Monika Katariya,Marco Rovinelli,Viji Balas,Nicholas Edelman", "background": "文中介绍了Llama-Nemotron系列模型，这是一个开放且异构推理模型家族，具有出色推理能力、推断效率和企业使用的开放许可证。该系列模型包括Nano（8B）、Super（49B）和Ultra（253B）三种规格，与顶尖推理模型如DeepSeek-R1相比，虽然性能相当，但提供了更优的推断吞吐量和内存效率。报告中详细讨论了这些模型的训练流程，包括从Llama 3模型开始的神经架构搜索以加速推理，知识精炼，连续前向训练，以及一个推理重点后训练阶段，分为监督微调和大规模强化学习两部分。Llama-Nemotron模型是第一次支持动态推理切换开关的开源模型，在推理中能切换标准聊天和推理模式。研究者还提供了相关资源：开源模型Llama-Nemotron理，后训练数据集Llama-Nemotron-Post-Training-Dataset，以及训练代码库NeMo、NeMo-Aligner和Megatron-LM。这些模型提供了一种在一个模型中提供强大推理能力的同时保持推断效率的方法，旨在推动开放研究和模型开发。", "innovation": "Llama-Nemotron提出了新颖的训练流程，融合了加速推理、知识精炼、前向训练及监督微调和大规模强化学习，特别在提供动态推理切换选项方面实现了创新，使得用户可以实时切换标准聊天和推理模式，同时，其开源许可使学术界和企业界能够更好地使用和扩展这些模型，意义显著。这些创新有助于提高推理模型的实际应用效果同时保持高效的推理性能。", "conclusion": "本报告最终强调了Llama-Nemotron系列模型在提供高效推理的同时支持动态推理切换的创新性。通过公开发布源代码和培训数据集，研究为开放研究和模型开发铺平了道路，提供了强大的推理能力与推断效率之间的平衡，并且开创了一种新的开源模式推理模型典范。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17117", "html_url": "https://arxiv.org/abs/2505.17117", "title": "从词语到思维：LLMs和人类如何在压缩与意义之间权衡", "title_en": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning", "authors": "Chen Shani,Dan Jurafsky,Yann LeCun,Ravid Shwartz-Ziv", "background": "人类通过语义压缩的方式，将多样化的实例映射到抽象的表示中，并在保持语义的同时实现信息精炼（例如， robin 和 blue jay 都是鸟类，大多数鸟类都能飞行）。这些概念反映了表达准确性和表示简单性之间的权衡。虽然大型语言模型（LLMs）展示了卓越的语用能力，但它们内部的表示是否也体现出类似人类的这种权衡还不清楚。本研究采用信息论框架，借鉴率-失真理论和信息瓶颈原则，定量分析 LLMs 的表示策略与人类标准之间的差异，揭示了LLMs在细致的语言语义区分方面存在的挑战，并进一步发现LLMs倾向于高度统计压缩，而不是人类的认知系统更重视适应性细节和语境丰度这一特性，即LLMs的压缩效率较低。这些发现揭示了当前AI与人类认知架构之间的关键差异，为改进LLMs为人脑所认可的概念表示提供指导.", "innovation": "引入了一种新的信息论框架，运用率失真理论和信息瓶颈原则来定量比较 LLMs 表示策略与人类标准之间的差异。这种做法首次系统化地评估了LLMs如何与人类在压缩与意义之间的权衡过程进行对比，并揭示了在细节语义处理上的差异以及压缩策略的根本性不同。", "conclusion": "虽然LLMs 形成了与人类判断一致的广泛概念类别，但在细微语义区分方面存在不足。更根本的是，LLMs 倾向于高度的统计压缩，而人类的认知系统更重视适应性细节和丰富的语境，虽然这在我们的度量下导致了较低的压缩效率。这些发现揭示了当前AI与人类认知架构之间的关键差异，为未来开发更接近人类思维过程的概念表示模型提供了方向。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18710", "html_url": "https://arxiv.org/abs/2506.18710", "title": "大型语言模型的教育知识基准评测", "title_en": "Benchmarking the Pedagogical Knowledge of Large Language Models", "authors": "Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portela,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod", "background": "现有的基准测试如大规模多任务语言理解（MMLU）在评估AI的知识和能力方面发挥了重要作用，但这些基准主要侧重于内容知识，未能充分评估模型对教学方法（即教学和培训实践）的理解。本文介绍了教育知识基准（Pedagogy Benchmark），这是一个旨在评估大语言模型在跨领域教学知识（CDPK）以及特殊需要和残疾（SEND）教育知识的新数据集。这些基准的数据来自于教师专业发展考试中的精心整理的问题，涵盖了诸如教学策略和评估方法等多种教学亚领域。", "innovation": "本文提出了一种新的基准测试方法，即教育知识基准，专门用于评估大语言模型在跨领域教学知识以及特殊教育需求和残疾（SEND）上的理解程度。该基准采用了从教师职业发展考试中精心筛选的问题，覆盖了广泛的教学亚领域。该研究还报告了97个模型在教育知识问题上的准确率，从28%到89%不等，并探讨了成本与准确率之间的关系，还展示了帕累托值前沿随时间的进展。在线排行榜提供了一个交互式平台，依赖于各种模型属性，如每令牌成本和开放式权重，以及不同学科的表现进行探索和筛选。", "conclusion": "教育知识基准对测量大型语言模型及其在教育中的应用潜力至关重要，可以衡量模型理解教学概念的能力，适应学习者需求并支持不同的教学实践。这对于指导和政策制定具有重要意义，并确保大型语言模型及其工具在教育环境中的负责任和基于证据的应用。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22403", "html_url": "https://arxiv.org/abs/2506.22403", "title": "HyperCLOVA X THINK 技术报告", "title_en": "HyperCLOVA X THINK Technical Report", "authors": "NAVER Cloud HyperCLOVA X Team", "background": "HyperCLOVA X THINK 是HyperCLOVA X 家族中的首个注重推理的大型语言模型，在预训练过程中处理了大约6万亿个高质量的韩语和英语词元，并通过专门合成的韩语文本进行扩充。模型通过多阶段的预训练课程扩展上下文窗口至128K词元，并通过监督微调结合可验证奖励的强化学习进行后培训，支持详细的推理模式和简短的回答模式。该模型在针对韩国的基准测试方面表现出色，如KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench，并保持了强大的双语一致性及翻译质量。另外，视图增强变体在KCSAT STEM基准测试中表现与GPT-4.1持平或更优秀，这些都是在比现有相似规模模型更低的训练计算成本下实现的。", "innovation": "创新之处在于将模型设计为计算与内存平衡的Peri-LN Transformer，预训练采用一个三级课程扩展上下文窗口，使用监督微调结合强化学习从可验证奖励支持丰富的推理和简洁的回答模式。此外，还提出了一种剪枝和蒸馏技术，将很快应用于HyperCLOVA X THINK为开源和商业友好的基础模型。这使得HyperCLOVA X THINK成为韩国AI创新的强大基础，并为全球研究社区提供了有价值的资源.", "conclusion": "这些能力使HyperCLOVA X THINK成为韩国AI创新的坚固基础，且具有全球研究社区中的重要价值。同时，实现了低计算成本下在多个基准测试中与相似规模模型竞争的表现，并提供了开源和商业友好的剪枝与蒸馏技术。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23146", "html_url": "https://arxiv.org/abs/2506.23146", "title": "Learning-to-Context Slope: 超越性能幻象评估上下文学习有效性", "title_en": "Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions", "authors": "Dingzriui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng", "background": "上下文学习（ICL）作为一种有效的方法，被用来提高大规模语言模型（LLMs）的性能。然而，在不同模型和任务下的效果差异很大，这使得实践者难以确定何时使用ICL能够可靠地提升性能。现有的评估方法依赖于应用ICL后的性能变化，然而这些方法存在可靠性低、归因困难和在数据不足的情况下使用不切实际的问题。", "innovation": "本文提出了一个名为‘学习到上下文坡度’（LCS）的新颖度量标准，该度量标准通过建模学习收益（演示中的损失减少）与上下文相关性（演示与输入的相关性）之间的斜率来量化ICL的效果。LCS通过以下方式解决了基于性能的度量标准的关键局限：(1) 可以捕捉到即使输出错误时的连续损失变化，从而提高可靠性；(2) 公式将ICL的失败归因于弱的上下文对齐（无法将输入适应演示）或强大的输出校准（自我验证正确性）；(3) 尽量减少对标签数据的依赖，通过合成评估。广泛实验表明，LCS在标签设置中与性能改进高度相关，在偏见或数据稀缺的场景中真实地反映效果。进一步分析确定了LCS的可操作阈值，并识别了对ICL成功至关重要的模型能力。", "conclusion": "深入分析显示LCS的可操作阈值，并确定了对ICL成功至关重要的模型能力。LCS在标记设置中与性能改进高度相关，在偏见或数据稀缺的场景中真正地反映效果。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23137", "html_url": "https://arxiv.org/abs/2506.23137", "title": "流调模态评分在语义感知知识图谱完成中的应用", "title_en": "Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion", "authors": "Siyuan Li,Ruitong Liu,Yan Wen,Te Sun", "background": "知识图谱(Knowledge Graph, KG)完成(Knowledge Graph Completion, KGC)的一个关键在于有效建模多面关系，但现有大多数方法依赖于静态嵌入得分，难以捕捉上下文依赖性和关系动态性，存在局限性。", "innovation": "本文提出了一个新的Flow-Modulated Scoring (FMS)框架。该框架包含两个主要模块：(1) 语义上下文学习模块，用于编码上下文敏感的实体表示；(2) 条件流匹配模块，用于根据上述语境学习头到尾嵌入的动态转换。这一预测向量场代表了基于语境的关联路径，动态提升了实体对的初始静态评分。通过结合情境感知的静态表示和条件动态信息，FMS促进了更深层次的关系语义建模。", "conclusion": "在多个标准基准上的综合评估表明，本文提出的方法在知识图谱完成任务上超越了现有的最新成果。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22698", "html_url": "https://arxiv.org/abs/2506.22698", "title": "人类与人工智能的文本生产和理解：跨学科工作会报告", "title_en": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report", "authors": "Emily Dux Speltz", "background": "这篇报告综合了近期一个跨学科研讨会的结果，该研讨会汇集了认知心理学、语言学习和基于人工智能的自然语言处理领域的领先专家。研讨会由国家科学基金会资助，旨在探讨人工智能语言模型与人类认知过程在文本理解和创作方面的关系，揭示了一个关键的知识空白。与会者从认知、语言和科技视角进行了合作对话，讨论了人类产生和理解文本时的内部过程，以及人工智能如何既帮助我们理解这些过程，又能增强人类能力。", "innovation": "报告揭示了大型语言模型（LLMs）与人类认知之间的新兴关系模式，特别强调了LLMs在提供人类语言处理见解方面的潜力，以及当模型通过与人类反馈微调后，其行为与人类语言处理之间的日益一致。报告还讨论了人类与人工智能合作在语言任务中带来的机遇与挑战。", "conclusion": "通过综合这些发现，该报告旨在指导大型语言模型在未来认知心理学、语言学和教育中的研究、开发和实施。它强调了在通过有效的人工智能合作提高人类在文本理解和创作能力方面的伦理考量和技术责任的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23743", "html_url": "https://arxiv.org/abs/2506.23743", "title": "二元问答中的位置偏差：不确定性如何塑造模型偏好", "title_en": "Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences", "authors": "Tiziano Labruna,Simone Gallo,Giovanni Da San Martino", "background": "二元问答模型在面对不同选项时，可能会因为选项的顺序不同而表现出偏好，这种现象称为位置偏差。本文通过重新适应SQuAD-it数据集并创建了具有不同程度上下文和更少上下文的情景，研究了这一现象在不同不确定性条件下模型表现的变化。此外，还使用了两个棘手的基准测试来进一步分析位置偏差的影响。", "innovation": "研究者重新设置了SQuAD-it数据集，增加了额外的错误选项，并逐步减少了上下文信息和答案的相关性，从而形成一系列不同不确定性的数据集。此外，他们还评估了两个天然具有更高不确定性的基准测试：WebGPT（具有不平等的人类质量评分的问题对）和Winning Arguments（依据 Reddit 的 r/ChangeMyView 比较更具说服力的观点）。", "conclusion": "研究表明，在低不确定性的条件下，位置偏差几乎不存在，但在决定哪个选项正确性更高变得困难时，位置偏差会显著增加。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.19342", "html_url": "https://arxiv.org/abs/2407.19342", "title": "通过循环卷积实现高效微调", "title_en": "Parameter-Efficient Fine-Tuning via Circular Convolution", "authors": "Aochuan Chen,Jiashun Cheng,Zijing Liu,Ziqi Gao,Fugee Tsung,Yu Li,Jia Li", "background": "低秩调整（LoRA）已经成为大型基础模型微调流行的方法。它通过使用低秩矩阵A和B来表示权重变化（即ΔW = BA），从而减少可训练参数并减轻内存占用。尽管取得了成功，其固有的低秩特性可能限制了其性能。已有多种变体被提出以解决此问题，但这些变体往往忽视了LoRA在计算和内存效率方面的优势。", "innovation": "本文提出了一种新的方法——循环卷积调整（C$^3$A），它不仅能实现高秩调整并提高性能，还能在计算能力和内存使用方面表现出色。在各种微调任务中的广泛实验表明，C$^3$A持续优于LoRA及其变体。", "conclusion": "C$^3$A在各类微调任务中表现出更优的性能，并且不仅能够在计算和内存方面提供优势，还能实现高秩调整。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.20302", "html_url": "https://arxiv.org/abs/2409.20302", "title": "OM4OV：利用本体匹配进行本体版本控制", "title_en": "OM4OV: Leveraging Ontology Matching for Ontology Versioning", "authors": "Zhangcheng Qiang,Kerry Taylor,Weiqing Wang", "background": "由于语义网络具有动态性，版本控制对于捕捉时间变化的信息是必要的，尤其是对于广泛使用的本体。虽然长期以来，本体版本控制（OV）被视为高效本体管理的关键组成部分，但由于本体规模的不断扩大，以及由人工劳动引发的累积错误，现有的OV方法已难以应对。因此，本文提出了一种新的方法，利用现有的本体匹配（OM）技术和系统来执行本体版本控制。从OM的角度出发，我们构建了一个新的任务公式和测量指标，提出了基于OM先前对齐的新pipeline优化方法，称之为交叉引用机制，以提高整体本体版本控制性能。我们在来自Ontology Alignment Evaluation Initiative (OAEI) 数据集的版本控制测试环境中实验验证了OM4OV pipeline和交叉引用机制。还讨论了使用本体匹配进行本体版本控制的一些见解，表明一些由OV系统检测出的显式虚假映射实际上并非虚假的映射关系。", "innovation": "提出了一种新的方法，利用现有的本体匹配（OM）技术来执行本体版本控制（OV），提出了一个统一的OM4OV pipeline，从OM的角度出发，提出了新的任务公式和测量指标，并且提出了基于OM先前对齐的新pipeline优化方法，名为交叉引用机制，以提高整体本体版本控制性能。", "conclusion": "通过在来自Ontology Alignment Evaluation Initiative (OAEI)的测试集上的实验证明了OM4OV pipeline和交叉引用机制的有效性，并且认为在使用本体匹配进行本体版本控制的任务中发现的一些显式虚假映射关系实际上是真实的。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.19906", "html_url": "https://arxiv.org/abs/2411.19906", "title": "基于图的经典和量子方法确定性L系统推理", "title_en": "A Graph-Based Classical and Quantum Approach to Deterministic L-System Inference", "authors": "Ali Lotfi,Ian McQuillan,Steven Rayan", "background": "L系统可以用来模拟和创建许多生物过程的仿真，比如植物发育。通常由专家手动找到给定过程的L系统，这是一个耗时的过程。如果能够根据数据，如图像序列来自动推导，这将具有重大意义。因此，本文关注从字符串序列中推导特定类型的L系统，即确定性上下文无关L系统（D0L系统）。作者引入了字符串序列的特征图，并将其问题转化为最大独立集问题和SAT问题，从而在多项式时间内解决。然后提出了经典精确算法和近似量子算法来解决这些问题。", "innovation": "作者首次将字符串序列的推导问题转化为图论中的最大独立集问题和SAT问题，并利用此转化提出了经典精确算法和近似量子算法来解决这些问题。这种方法能够利用新兴的量子计算技术加速L系统推理过程。", "conclusion": "通过引入字符串序列的特征图，作者将D0L系统推理问题转化为最大独立集问题和SAT问题，利用经典的精确算法和近似量子算法在多项式时间内解决这些问题，从而克服了手动推导的耗时难题，为L系统推理提供了新的方法和可能性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.06432", "html_url": "https://arxiv.org/abs/2412.06432", "title": "将专家标签整合到基于LLM的排放目标检测中：实例选择 vs 自动提示设计", "title_en": "Integrating Expert Labels into LLM-based Emission Goal Detection: Example Selection vs Automatic Prompt Design", "authors": "Marco Wrzalik,Adrian Ulges,Anne Uersfeld,Florian Faust,Viola Campos", "background": "本文讨论了在企业报告中检测减排目标的任务，这是监测公司应对气候变化进展的重要手段。研究重点在于如何将带有标签的专家反馈样本整合进基于LLM的处理管道之中，对比了两种策略：一种是动态选择少量代表性样本，另一种是通过LLM自动优化提示。研究基于一个包含769条实际业务报告中气候相关信息的数据集展开。研究发现，自动提示优化是更优的方法，而将两种方法结合起来仅能提供有限的好处。", "innovation": "研究展示了如何将专家反馈整合进基于LLM的处理管道，并且对比了动态选择少量代表性样本和通过LLM自动优化提示的两种策略。研究的创新点在于发现了自动提示优化优于动态选择样本，同时也表明两种方法结合使用效果并不显著提升。", "conclusion": "通过自动提示优化方法，可以更有效地捕捉到分类任务中的复杂性。结合自动提示优化和少量样本选择在本研究场景下带来的益处有限。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.10774", "html_url": "https://arxiv.org/abs/2408.10774", "title": "Flexora：大型语言模型的灵活低秩适应", "title_en": "Flexora: Flexible Low Rank Adaptation for Large Language Models", "authors": "Chenxing Wei,Yao Shu,Ying Tiffany He,Fei Richard Yu", "background": "大型语言模型（LLMs）通过增加模型参数的数量，显著提高了泛化能力并开启了实践中的新功能。然而，这些模型在特定下游任务上的表现通常受限于其对该任务知识的边界。因此，引入了微调技术，特别是广泛使用的低秩适应（LoRA）方法，以扩大这些任务的知识边界，但LoRA可能会在某些任务上因潜在的过拟合而表现不佳。为了克服这一过拟合问题并提高LoRA的表现，提出了灵活低秩适应（Flexora）方法，该方法能够自适应地选择需要微调的最重要的层，以在不同下游任务上获得最佳性能。Flexora首先将层选择问题转化为一个明确的超参数优化（HPO）问题，然后使用展开的微分（UD）方法来解决该问题，并最终基于优化后的超参数选择最有用的层。大规模实验表明，Flexora能够在多个预训练模型和自然语言任务上持续改进现有的基线方法，证明了Flexora在实践中的有效性。此外，还提供了深入的理论结果和大量消融研究，以全面理解Flexora。", "innovation": "提出了一种名为Flexora的灵活低秩适应方法，该方法能够自适应地选择需要微调的最重要的层，以在不同下游任务上获得最佳性能。Flexora将层选择问题视为一个明确的超参数优化问题，并使用展开的微分方法解决该问题，最终根据优化后的超参数选择最有用的层。Flexora能够在多个预训练模型和自然语言任务上改善现有基线方法的表现，展现出其在实践中的有效性。", "conclusion": "大量的实验表明，Flexora能够在多个预训练模型和自然语言任务上持续改进现有的基线方法，证明了Flexora在实践中的有效性。此外，还提供了深入的理论结果和大量的消融研究，以全面理解Flexora的方法和应用。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.03704", "html_url": "https://arxiv.org/abs/2412.03704", "title": "通过视觉价值模型扩展推理时间搜索以改善视觉理解", "title_en": "Scaling Inference-Time Search with Vision Value Model for Improved Visual Comprehension", "authors": "Xiyao Wang,Zhengyuan Yang,Linjie Li,Hongjin Lu,Yuancheng Xu,Chung-Ching Lin,Kevin Lin,Furong Huang,Lijuan Wang", "background": "尽管视觉语言模型（VLMs）取得了显著进展，但在提升响应质量方面，尤其是在扩大推理时间计算规模上仍然缺乏有效的办法。这一能力被认为是近期大规模语言模型研究中实现自我改进模型的关键步骤。本文介绍了Visual Value Model（VisVM），旨在指导VLM在推理时间搜索中生成具有更好视觉理解能力的响应。VisVM不仅评估当前搜索步骤生成句子的质量，还能预见后续句子的质量，从而提供长期价值，避免生成可能引起幻觉或细节不足的句子，从而提高响应质量。", "innovation": "VisVM的独特之处在于不仅评估当前生成句子的质量，还预测后续句子的质量，提供长期价值指导模型生成更好的文本。此外，通过使用VisVM指导生成的标注对模型进行自训练，证明了这种方法可在多种跨模态基准测试中提升模型性能，为开发自我改进的VLM提供了潜在可能。", "conclusion": "实验结果表明，与贪婪解码和使用其他视觉奖励信号的搜索方法相比，VisVM指导的搜索显著提高了生成具有丰富视觉细节并减少幻觉的描述性标题的能力。进一步研究表明，使用VisVM指导生成的标注对模型进行自训练能够显著提升各种跨模态基准测试中的模型性能，表明了开发自我改进的VLM的潜力。我们的价值模型和代码可在以下链接获取：this https URL。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.24117", "html_url": "https://arxiv.org/abs/2506.24117", "title": "在希伯来圣经中的文本平行检测：基于变换器的基准", "title_en": "Intertextual Parallel Detection in Biblical Hebrew: A Transformer-Based Benchmark", "authors": "David M. Smiley", "background": "在圣经研究中，识别平行段落是理解跨文本关系的关键。传统的手动比对方法既耗时又容易出错。先前的研究表明，预训练的变换器基语言模型具有潜在的应用价值。本文以希伯来圣经中的撒母耳/列王纪与历代志之间的已知平行段落为研究对象，评估了E5、AlephBERT、MPNet和LaBSE等模型在检测文本平行方面的表现。通过余弦相似度和Wasserstein距离进行测量，结果表明E5和AlephBERT模型表现良好，E5在平行段落检测方面更优，而AlephBERT在非平行段落区分方面更出色。", "innovation": "本文创新地采用了预训练的变换器基语言模型来识别希伯来圣经中的文本平行，并与传统的手动比对方法进行了对比，展示了这些模型在提高检测效率和准确性方面的潜力。特别是E5和AlephBERT在平行段落检测和非平行段落区分方面的优异表现，为古代语言研究提供了新的方法和技术支持。", "conclusion": "研究结果表明，预训练模型可以增强检测古代文本中跨文本平行关系的效率和准确性，这些模型的应用不仅限于圣经研究，还可以扩展到更广泛的古代语言学研究中。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.00703", "html_url": "https://arxiv.org/abs/2505.00703", "title": "T2I-R1：通过协作的语义级和token级CoT强化图像生成", "title_en": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT", "authors": "Dongzhi Jiang,Ziyu Guo,Renrui Zhang,Zhuofan Zong,Hao Li,Le Zhuo,Shilin Yan,Pheng-Ann Heng,Hongsheng Li", "background": "最近的大语言模型进展展示了如何通过chain-of-thought (CoT)和强化学习 (RL) 提升性能。然而，这些推理策略在视觉生成领域的应用尚未得到充分探索。本文介绍了T2I-R1，一种基于双层chain-of-thought (CoT)逻辑推理过程的强化学习文本到图像生成模型。该模型通过识别高阶和低阶的CoT来增强不同生成阶段的表现，从而提升图像生成的质量。", "innovation": "我们提出了T2I-R1，一种双层chain-of-thought (CoT)推理过程支持的强化学习文本到图像生成模型，包括语义级CoT用于高级规划以及token级CoT用于逐块像素处理。此外，我们引入了BiCoT-GRPO，它通过联合生成奖励优化了同时进行的生成CoT。", "conclusion": "通过应用我们的推理策略到基线模型Janus-Pro中，我们在T2I-CompBench上实现了13%的性能提升，在WISE基准上实现了19%的提升，甚至超过了最先进的模型FLUX。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14518", "html_url": "https://arxiv.org/abs/2505.14518", "title": "向音频感知的大语言模型教授未听见的内容：通过合成负样本减轻幻觉现象", "title_en": "Teaching Audio-Aware Large Language Models What Does Not Hear: Mitigating Hallucinations through Synthesized Negative Samples", "authors": "Chun-Yi Kuan,Hung-yi Lee", "background": "最近的音频感知大语言模型（ALLMs）使得它们能够处理和理解音频输入，但这些模型常常会生成不存在的声音事件，降低了它们在实际应用中的可靠性。为了解决这一问题，本文探讨了LISTEN（Learning to Identify Sounds Through Extended Negative Samples）方法。这种方法通过使用模型主干中的合成数据进行对比性训练，增强ALLMs区分存在和不存在声音的能力。论文指出，现有的方法需要修改LLM的参数，而LISTEN方法则无需对参数进行更改，同时通过轻量级适配器高效地整合音频表示，这种方法不仅能够有效减轻幻觉现象，而且在现有音频问题和推理基准测试中的表现依然出色，同时在数据和计算效率方面更加高效", "innovation": "提出了LISTEN（Learning to Identify Sounds Through Extended Negative Samples）方法，一种对比训练方法，通过使用模型主干中的合成数据，增强ALLMs区分真实和不存在声音的能力。不需要修改LLM的参数，通过轻量级适配器高效地整合音频表示，有效减轻幻觉现象，同时保持在现有音频问题和推理基准测试中的卓越性能，且在数据和计算效率方面表现更佳", "conclusion": "实验表明，LISTEN方法能够有效减轻幻觉现象，同时保持在现有音频问题和推理基准测试中的出色表现，并且在数据和计算效率方面更具优势。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23940", "html_url": "https://arxiv.org/abs/2506.23940", "title": "Graft: 通过高效参数协同整合领域知识的多模态大型语言模型", "title_en": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs", "authors": "Yang Dai,Jianxiang An,Tianwei Lin,Hongyang He,Hongzhe Huang,Wenqiao Zhang,Zheqi Lv,Siliang Tang,Yueting Zhuang", "background": "多模态大型语言模型（MLLMs）在各个领域都取得了成功，但在面对不同类型的数据输入时，模型的应用性往往会下降，尤其是针对特定任务进行微调的MLLMs。尽管跨领域专业知识共享的研究至关重要，但在数学或代码等领域专门训练的MLLMs之间的知识共享研究仍相对不足。为了弥合领域特异性MLLMs中的知识碎片化，本文提出了一种统一的参数整合框架，该框架支持模块化合成专家能力。该方法基于一种新颖的兼容性感知参数拼接（CAPS）策略，该策略结合了局部功能贡献度与全局信息论信号来指导有选择的参数融合。此外，引入了一种领域兼容性评分机制，该机制量化专家之间在激活层的对齐程度，并与下游任务效用相关联。这种方法使最终模型能够协同利用异质知识，同时保持结构模块化。", "innovation": "本文提出了一个统一的参数整合框架，该框架基于兼容性感知参数拼接（CAPS）策略，通过结合局部功能贡献度与全局信息论信号来指导有选择的参数融合。此外，引入了一种领域兼容性评分机制，能够在激活层量化专家之间的对齐程度，并与下游任务效用相关联。这种机制在低秩自适应层粒度上进行扩展，以确保高效的集成并保持最小的推理开销。该框架为实现组合式的、领域自适应的MLLMs提供了一条可行的道路，展示了其在各种多模态基准测试中的有效性，且具有扩展性。", "conclusion": "本文的框架经过在各种多模态基准测试中的广泛评估，证明了它在组合式的、领域自适应的MLLMs的有效性和扩展性。该框架为应对领域特殊性的MLLMs知识碎片化问题提供了一种有效的方法，展现了其在多模态应用中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05288", "html_url": "https://arxiv.org/abs/2504.05288", "title": "寻求和利用实时视觉知识", "title_en": "Seeking and Updating with Live Visual Knowledge", "authors": "Mingyang Fu,Yuyang Peng,Dongping Chen,Zetong Zhou,Benlin Liu,Yao Wan,Zhou Zhao,Philip S. Yu,Ranjay Krishna", "background": "我们周围不断变化的视觉世界包括实时新闻、社交媒体趋势以及通过卫星图像和增强现实增强的全球基础设施变化。然而，多模态大型语言模型（MLLMs）在自动化许多任务时，由于固定训练数据集中的截止日期限制，难以保持最新。为了量化这一停滞现象，我们引入了LiveVQA，这是首款专为支持实时视觉知识的获取和更新研究设计的数据集，包含107,143个样本和12个类别数据。这些数据来源于2024年4月至2025年5月的最新新闻文章、视频平台和学术出版物。", "innovation": "我们创新地引入了LiveVQA，它是一个全新的数据集，专门用于支持对实时视觉知识的获取和更新研究。通过LiveVQA，我们能够评估模型如何处理超越其知识边界的新视觉信息，以及目前的方法如何帮助更新模型。我们对17种最先进的MLLM进行了全面基准测试，发现这些模型在处理超出知识截止日期的内容时存在显著性能差距。具体而言，工具使用或能动的视觉寻求框架获得了327%的平均改进。此外，我们还探索了参数高效微调（PEFT）方法，以更新MLLM的新视觉知识。我们的实验表明，在更新MLLM时，适配器容量与模型能力之间的关键平衡至关重要。所有实验数据集和源代码均已在公网发布：this https URL", "conclusion": "我们的研究表明，通过利用参数高效微调方法，我们可以显著提高MLLM更新新视觉知识的能力。适配器容量与模型能力之间的平衡是关键因素。这些研究成果为多模态大型语言模型如何保持与当前世界的同步提供了一定的指导。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16211", "html_url": "https://arxiv.org/abs/2505.16211", "title": "AudioTrust：评估音频大型语言模型多维度信任度的标准", "title_en": "AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models", "authors": "Kai Li,Can Shen,Yile Liu,Jirui Han,Kelong Zheng,Xuechao Zou,Zhe Wang,Xingjian Du,Shun Zhang,Hanjun Luo,Yingbin Jin,Xinxin Xing,Ziyang Ma,Yue Liu,Xiaojun Jia,Yifan Zhang,Junfeng Fang,Kun Wang,Yibo Yan,Haoyang Li,Yiming Li,Xiaobin Zhuang,Yang Liu,Haibo Hu,Zhizheng Wu,Xiaolin Hu,Eng-Siong Chng,XiaoFeng Wang,Wenyuan Xu,Wei Dong,Xinfeng Li", "background": "音频大型语言模型（ALLMs）的发展和应用正在迅速扩展，但对其信任度的系统性研究仍然不足，尤其是在评估模型在音频模态下独特风险方面，目前的研究主要集中在文本模态或仅涵盖了安全维度的有限部分，未能充分考虑到音频模态固有的特性和应用场景。因此，迫切需要一个全面且专业的评估框架来评价音频模型的信任度。", "innovation": "本文提出了AudioTrust，首个专为ALLMs设计的多维度信任度评估框架和基准。AudioTrust覆盖了公平性、幻觉、安全性、隐私、鲁棒性和身份验证六个关键维度，并通过18个不同的实验设置进行评估。此外，它还构建了一个包含超过4,420个真实世界音频/文本样本的数据集，以更好地检测ALLMs的多维度信任度，并设计了9个针对音频的具体评估指标，实现了大规模自动化评分。这为未来的音频模型安全可靠部署提供了有价值的参考。", "conclusion": "实验结果揭示了当前开源和闭源ALLMs在面对各种高风险音频场景时的信任度边界和限制，为未来音频模型的部署提供了宝贵见解。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18232", "html_url": "https://arxiv.org/abs/2505.18232", "title": "基于两阶段正则化的层间结构剪枝方法", "title_en": "Two-Stage Regularization-Based Structured Pruning for LLMs", "authors": "Mingkuan Feng,Jinyang Wu,Siyuan Liu,Shuai Zhang,Ruihan Jin,Feihu Che,Pengpeng Shao,Zhengqi Wen,Jianhua Tao", "background": "大型语言模型（LLMs）的部署受到其大量参数的影响。现有的结构化剪枝方法直接基于某些指标删除不重要的参数，这通常会导致知识丢失，并需要大量的重新训练。TRSP（Two-Stage Regularization-Based Structured Pruning）方法通过两阶段的正则化处理克服了这些缺点，在剪枝过程中保留了更多的知识，并且比直接删除参数的方法更好地保持了模型性能。", "innovation": "TRSP引入了一种两阶段的结构剪枝方法。首先通过在每个变换层的输出乘以一个可学习权重，添加$\boldsymbol{\text{l}}_1\boldsymbol{\text{-norm}}$作为正则化项到损失函数中，进行初步的正则化，这被认为是第一阶段的正则化。随后，对于权重较小的层，对输出和输入之间的差异进行额外正则化，促使知识转移到保留的层，这被称为第二阶段的正则化。通过这种方式，TRSP方法显著提高了知识保留和模型性能的保留，而不需要进行重新训练。", "conclusion": "通过广泛的实验表明，TRSP在不需重新训练的情况下，优于强大的逐层结构剪枝方法，并且作为一种逐层剪枝方法，它在端到端加速方面表现显著，是一种有效的LLM部署解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19955", "html_url": "https://arxiv.org/abs/2505.19955", "title": "MLR-Bench: 评估AI代理在开放性机器学习研究中的表现", "title_en": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": "Hui Chen,Miao Xiong,Yujie Lu,Wei Han,Ailin Deng,Yufei He,Jiaying Wu,Yibo Li,Yue Liu,Bryan Hooi", "background": "近年来，AI代理在推动和支持科学发现方面的潜力日益显现。本文旨在通过MLR-Bench评估AI代理在开放式机器学习研究中的表现，MLR-Bench涵盖了来自NeurIPS、ICLR和ICML研讨会的201项研究任务，涉及多样的机器学习主题。", "innovation": "1. MLR-Bench是一个综合的基准，包括201项研究任务、MLR-Judge自动化评估框架和MLR-Agent研究代理模块。\n2. MLR-Judge结合了基于LLM的评审员和精心设计的评审标准，用于评估研究质量。\n3. MLR-Agent能够通过四个阶段完成研究任务：概念生成、提案制定、实验和论文写作，支持分阶段评估和最终论文的端到端评估。\n4. 通过MLR-Bench评估了六种前沿LLM和先进的编码代理，发现LLM在生成连贯的概念和结构化论文方面表现良好，而当前的编码代理经常生成无效的实验结果，这对科学研究的可靠性构成了重大障碍。\n5. MLR-Judge通过人工评估得到了验证，专家评审者达成高度一致，支持其作为可扩展的研究评价工具的应用潜力。", "conclusion": "MLR-Bench公开发布，旨在帮助社区进行基准测试、诊断和改进AI研究代理，以实现值得信赖和透明的科学研究。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11999", "html_url": "https://arxiv.org/abs/2506.11999", "title": "推荐基础模型的生成表示学习", "title_en": "Generative Representational Learning of Foundation Models for Recommendation", "authors": "Zheli Zhou,Chenxu Zhu,Jianghao Lin,Bo Chen,Ruiming Tang,Weinan Zhang,Yong Yu", "background": "在人工智能领域，开发能够应对多种任务的基础模型一直是一个长期目标。随着通用基础模型在各个领域的普及，它们的影响逐渐扩展到了推荐系统领域。尽管最近的研究已经探索了应用于各种生成任务的基础模型，但这些模型往往忽视了关键的嵌入任务，并且在多任务学习中面临知识共享与冲突解决的挑战，以及收敛速度不一致的问题。", "innovation": "为了解决这些限制，本文引入了RecFound，一种设计用于推荐基础模型的生成表示学习框架。本文构建了一个包括生成和嵌入任务在内的全面数据集，并提出了一种包含任务特定低秩专家混合（TMoLE）、步骤导向收敛样本调度器（S2Sched）以及模型合并模块的新型多任务训练方案，以应对知识共享与冲突问题，解决不一致的收敛问题，并平衡多任务性能。实验结果表明，RecFound在各种推荐任务中达到了最先进的性能，并超越了现有的基线模型。", "conclusion": "实验结果显示，RecFound在多种推荐任务上取得了领先的表现，优于现有的基线模型。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.07416", "html_url": "https://arxiv.org/abs/2504.07416", "title": "RadZero：基于相似性的跨注意力在放射学中解释性的视觉-语言对齐的零样本多任务能力", "title_en": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "authors": "Jonggwon Park,Soobum Kim,Byungmu Yoon,Kyoyun Choi", "background": "近期多模态模型在医学影像学中的视觉-语言（VL）对齐方面取得了显著进步。然而，现有的方法难以有效利用复杂的医学影像报告，并且通过注意力概率可视化提供的解释性有限。本文基于此背景进行了研究，以解决这些问题。", "innovation": "本文介绍了一种名为RadZero的新型框架，用于放射学中的VL对齐，具有零样本多任务能力。RadZero的关键组件是VL-CABS（基于相似性的跨注意力文本-图像嵌入对齐），它通过相似性概率实现了可解释的细粒度VL推理。此外，RadZero利用大型语言模型从放射学报告中提取简洁的语义句子，并采用多正样本对比训练来有效捕捉影像与多个相关文本描述之间的关系。通过计算文本嵌入和局部图像块特征之间的相似性，VL-CABS enables零样本推断，并生成像素级别的VL相似图用于接地和分割。实验结果表明，RadZero在零样本分类、接地和分割方面优于当前最先进的方法。此外，VL相似图分析还展示了VL-CABS在VL对齐中提高解释性的潜力。", "conclusion": "实验结果和定性评估表明，RadZero在开放词汇语义分割方面具有能力，并进一步验证了它在医学成像中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.19351", "html_url": "https://arxiv.org/abs/2412.19351", "title": "ETTA：阐明文本到音频模型的设计空间", "title_en": "ETTA: Elucidating the Design Space of Text-to-Audio Models", "authors": "Sang-gil Lee,Zhifeng Kong,Arushi Goel,Sungwon Kim,Rafael Valle,Bryan Catanzaro", "background": "近年来，文本到音频(TTA)合成功音技术取得了显著进展，用户可以通过自然语言提示生成合成功音，丰富其创意工作流程。然而，数据、模型架构、训练目标函数以及采样策略对目标基准的影响尚不明确。本文旨在对TTA模型的设计空间进行全面理解，通过大规模实证实验，主要集中在扩散和流动匹配模型上。", "innovation": "本文的贡献包括：1) AF-Synthetic，一个高质量合成音频字幕的大数据集，通过音频理解模型获得；2) 对不同架构、训练、推理设计选择系统性比较；3) 对采样方法及其生成质量和推理速度的关系进行了分析，给出了帕累托曲线分析。借此知识，提出了名为Elucidated Text-To-Audio (ETTA)的最佳模型。当在AudioCaps和MusicCaps上进行评估时，ETTA在公有数据训练的基线模型上有所改进，并且在内部数据训练的模型上具有竞争力。此外，ETTA展示了生成复杂且富有想象力的音频的能力，这一任务比当前基准更具有挑战性。", "conclusion": "最后，文章展示了ETTA在根据复杂和富有想象力的文本生成更具创造性音频方面的改进能力，这比当前基准更具挑战性。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.02952", "html_url": "https://arxiv.org/abs/2505.02952", "title": "使用渐进切割-搜索方法解决提示歧义的迭代解决方案", "title_en": "Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach", "authors": "Fabrizio Marozzo", "background": "生成式AI系统通过自然语言编码和问题解决极大地改变了人类交互。然而，自然语言固有的模糊性导致了指令的不精确，迫使用户反复测试、修正和重新提交其提示。本研究旨在通过系统地缩减模糊性、提出澄清问题和备选方案，提高指令的精确度，最终生成一个明确的解决方案。该方法在编码、数据分析和创意写作等多个领域的多样数据集上进行了测试，结果显示其在准确性、解决方案时间以及用户满意度方面均优于传统的一次性解决方案，后者通常需要多次手动迭代才能获得正确输出。", "innovation": "本文提出了一种迭代方法，通过系统的澄清问题和备选方案，逐步缩减自然语言的模糊性，生成精确的解决方案。该方法使用输入/输出示例进行展示。该方法在编码、数据分析和创意写作等多个领域的数据集上进行了评估，表明其优于传统的单次解决方案，显示出更高的准确性、竞争力的解决时间以及更高的用户满意度。", "conclusion": "我们的方法在解决自然语言的模糊性方面表现出色，通过逐步澄清问题，提高了指令的精确性，最终生成了一个明确的解决方案。实验表明，与传统的单次解决方案相比，该方法在准确性、解决方案时间和用户满意度方面取得了显著改进。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16571", "html_url": "https://arxiv.org/abs/2506.16571", "title": "捕捉可视化设计 rationale", "title_en": "Capturing Visualization Design Rationale", "authors": "Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha", "background": "先前的自然语言数据集主要集中在数据可视化领域的评估、洞察生成以及根据自然语言指令生成可视化图。这些研究往往依赖于受控的实验环境和专门为可视化设计打造的问题，从而导致关注点偏重于对可视化图的解读，而忽视了对设计编码的理解。本文研究背景即是在这一背景下展开的，旨在通过自然语言探究可视化设计的思路。", "innovation": "本文提出了一种新的数据集和方法，用于通过自然语言探究可视化设计的思路。研究引入了一个独特的数据源：数据可视化课程中由学生创建的具有叙述性的可视化笔记本。这些笔记本将视觉制品和设计说明结合在一起，使学生能够明确阐述他们的设计决策背后的理由。此外，研究还利用了大型语言模型（LLMs）从笔记中的叙述和表达中生成和分类问题-答案-理由三元组，然后进行仔细验证，建立了一个数据集，该数据集记录和提炼了学生的可视化设计选择及其对应的理由。", "conclusion": "该研究结果推出了一种全新的探究数据可视化设计思路的方法，避免了以往研究关注解读而忽视设计思路的局限性，为该领域的进一步研究提供了新的视角和方法。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00033", "html_url": "https://arxiv.org/abs/2507.00033", "title": "Video LLMs中长时长视频问答的时刻采样", "title_en": "Moment Sampling in Video LLMs for Long-Form Video QA", "authors": "Mustafa Chasmai,Gauri Jagatap,Gouthaman KV,Grant Van Horn,Subhransu Maji,Andrea Fanelli", "background": "近期在视频大型语言模型（Video LLMs）方面的进展显著提升了视频问答（VideoQA）领域。现有方法在处理短视频时表现良好，但在处理长视频时往往难以进行长距离推理。帧抽样（在一定间隔内选择帧）是扩展Video LLMs以处理更长视频内容的常用方法，但这种方法不尽理想，可能导致关键帧的丢失或包括来自多个类似帧的重复信息，从而削弱模型的准确回答能力并增加计算资源消耗。因此，提供一种能够根据问题上下文选择最相关帧的方法对于提升VideoQA表现具有重要意义。", "innovation": "提出了一种名为'moment sampling'的新颖且模型无关的方法，通过一个轻量级的文本到视频时刻检索模型来指导帧的选择过程。该方法能够使模型选择与问题上下文最相关的帧，从而改善长视频问答的性能。实验表明，在四个长形式的VideoQA数据集上使用四种最先进的Video LLMs时，该方法的有效性得到了验证。", "conclusion": "通过广泛的实验，证明了所提方法在长视频上使用Video LLMs进行问答的有效性，能够根据问题上下文选择最相关的帧，提升了长视频问答的性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00043", "html_url": "https://arxiv.org/abs/2507.00043", "title": "MR-CLIP: 基于元数据高效学习MRI对比度表示", "title_en": "MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations", "authors": "Mehmet Yigit Avci,Pedro Borges,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso", "background": "精确理解临床系统的磁共振成像（MRI）扫描需要基于精确的图像对比度理解。对比度主要由采集参数（如回波时间及重复时间）决定，这些参数记录在DICOM元数据中。虽然广泛使用诸如T1加权或T2加权这样的粗略标签，但它们并不准确反映实际采集设置。在许多真实数据集中，这些标签完全缺失，仅靠原始采集参数作对比标识。此外，可利用的元数据往往不完整、噪声大或不一致。缺乏可靠和标准化的元数据使得图像解释、检索及纳入临床工作流程变得复杂。为了应对这些挑战，MRI需要具备对比度感知表示，以支持更高级的临床应用，如实现模态不变表示及数据规范化。", "innovation": "本文提出了MR-CLIP，一种多模态对比学习框架，能够将MRI图像与其DICOM元数据对齐从而学习对比度感知表示，而不依赖于手动标签。该模型在多种扫描器和协议的临床数据集上进行了训练，可以捕捉不同采集过程中的对比度变化，实现解剖不变的表示。MR-CLIP在跨模态检索和对比度分类方面的效果进行了测试，展示了其可扩展性和进一步应用于临床的潜力。该模型代码和权重已公开发布。", "conclusion": "MR-CLIP通过将MRI图像与DICOM元数据对齐来学习对比度感知表示，克服了缺乏可靠元数据的挑战，有助于更精确的图像解释和进一步的临床应用。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00046", "html_url": "https://arxiv.org/abs/2507.00046", "title": "基于进化计算的图像分割方法检测增材摩擦搅拌沉积过程中的缺陷和特征", "title_en": "Evolutionary computing-based image segmentation method to detect defects and features in Additive Friction Stir Deposition Process", "authors": "Akshansh Mishra,Eyob Mesele Sefene,Shivraman Thapliyal", "background": "该研究提出了一种基于进化计算的图像分割方法，用于分析增材摩擦搅拌沉积（AFSD）过程中的完整性和缺陷。该方法通过多层AFSD构建中的缺陷检测和特征识别来优化分析过程。该技术结合了梯度幅度分析和距离变换，生成新的注意力加权可视化，突出显示关键界面区域。传统的成像方法难以识别细微的材料过渡区和潜在缺陷区域，而多通道可视化技术则将边界信息、空间关系和材料密度数据综合成统一的表现形式，定量测量界面质量。", "innovation": "创新在于采用了粒子群优化（PSO）算法自动确定分割阈值，为不同条件下的五种AFSD样品进行了全面的图像分割和多通道可视化分析，通过这种方法成功识别了AFSD接头中未完全结合的区域和不均匀性，提供了一种定量评估增材制造组件质量和优化工艺的手段。", "conclusion": "研究表明，基于注意力的分析成功识别了AFSD接头中未完全结合的区域和不均匀性，提供了工艺优化和增材制造组件质量评估的定量指标。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00049", "html_url": "https://arxiv.org/abs/2507.00049", "title": "AdaDeDup: 适应性混合数据剪裁以提高大型对象检测模型训练效率", "title_en": "AdaDeDup: Adaptive Hybrid Data Pruning for Efficient Large-Scale Object Detection Training", "authors": "Feiyang Kang,Nadine Chang,Maying Shen,Marc T. Law,Rafid Mahmood,Ruoxi Jia,Jose M. Alvarez", "background": "大规模数据集的计算负担和固有冗余给当前机器学习模型的训练带来了挑战。现有的数据剪裁方法存在局限性：基于密度的方法可能过于通用，而基于模型的方法可能会引入冗余或计算成本过高。", "innovation": "提出了一种名为AdaDeDup的新型混合框架，该框架结合了基于密度的剪裁与基于模型的反馈，且在集群适应性方面表现出协同智能化。AdaDeDup首先对数据进行分区并应用初始基于密度的剪裁，然后使用代理模型评估每个集群剪裁前后的损失影响，从而调整特定于集群的剪裁阈值，使冗余集群进行更激进的剪裁，而保留关键信息。实验结果表明，AdaDeDup在大规模对象检测基准测试中显著优于现有基准，且在剪裁20%的数据后仍能保持接近原始模型的性能。", "conclusion": "AdaDeDup在大规模对象检测模型的训练中在减少性能下降的同时保持了高数据效率。其方法为数据高效训练提供了有效方案。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.24119", "html_url": "https://arxiv.org/abs/2506.24119", "title": "SPIRAL：通过多轮多智能体强化学习在零和游戏中进行自我对弈促进推理", "title_en": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "authors": "Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques", "background": "近期强化学习的进步表明，通过训练可验证奖励的任务，语言模型能够发展出复杂的推理能力，但这依赖于人工策划的问题-答案配对和特定领域的奖励工程。本文提出了一种名为SPIRAL的自我对弈框架，使得模型通过相互对抗不断进阶的自身版本来学习，从而不需要人工监督。在这种自我对弈过程中，SPIRAL生成了无限层递进挑战的任务序列，随着对更强大对手的适应，模型必须不断地进行调整。为实现大规模自我对弈训练，本文还实现了一个全在线的多轮多智能体强化学习系统，提出了角色条件优势估计（RAE）方法来稳定多智能体训练。通过对零和游戏进行自我对弈训练，模型获得了广泛的推理能力。在单独对Kuhn扑克进行训练时，Qwen3-4B-Base提升了8.6%的数学推理和8.4%的一般推理，优于仅使用25,000个专家游戏轨迹进行策略性训练的结果。分析表明，这种迁移主要通过系统分解、期望价值计算和案例分析三种认知模式实现。多游戏训练（包括五子棋、Kuhn扑克和简单谈判）进一步提高了性能，因为每种游戏都可以为模型发展不同的推理强项。将SPIRAL应用于强大推理模型（DeepSeek-R1-Distill-Qwen-7B）仍然能带来2.0%的平均性能提升。这些结果表明，零和游戏自然地发展出可迁移的推理能力，这为自主推理的发展提供了有希望的方向。", "innovation": "引入了一种名为SPIRAL的新框架，模型通过自我对弈不断进化的版本学习，无需人工监督。为了实现大规模自我对弈训练，提出了全在线的多轮多智能体强化学习系统，并提出角色条件优势估计（RAE）方法来稳定多智能体训练。SPIRAL能够通过自我对弈训练生成一个递进的学习曲线，使模型自然地发展出强大的推理能力。这种方法展示了零和游戏在促进模型推理能力方面的作用，为自主推理的发展提供了有希望的方向。", "conclusion": "零和游戏自然地发展出可迁移的推理能力，表明SPIRAL框架有望促进自主推理能力的发展。这种方法在强化学习中展示了新的潜在应用，尤其是在无需人工干预的情况下提升语言模型的推理能力方面。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00052", "html_url": "https://arxiv.org/abs/2507.00052", "title": "VSF-Med: 一种医疗视觉语言模型的漏洞评分框架", "title_en": "VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models", "authors": "Binesh Sadanandan,Vahid Behzadan", "background": "现有的视觉语言模型（VLMs）可以简化耗时的医学影像工作流程，但在临床环境中的系统安全评估依然鲜见。这促使本研究提出了一种全面的漏洞评分框架（VSF-Med），用于评估医疗VLMs的安全性。", "innovation": "该研究提出了三个关键创新：(i) 一个包含复杂文本提示攻击模板的丰富库，以应对新兴威胁；(ii) 通过结构相似性阈值校准不可察觉的视觉扰动，保持临床真实性；(iii) 一个八维度的评价维度，由两款独立的LLM进行评估，最终通过z分数标准化合并成一个0-32的综合风险指标。通过该框架，任何医疗VLM都可以通过一行命令进行可重复基准测试，并生成其缺陷评分。此外，该框架完全基于公开数据集，伴随开源代码，可生成超过30,000种对抗变体，从而提供全面的安全评估。评估结果显示，先进的VLM在攻击生存性、提示注入效果和安全规避成功上均有不同程度的不安全性增强，例如Llama-3.2-11B-Vision-Instruct在攻击生存性上的峰值脆弱性增加了1.29σ；GPT-4o在攻击生存性上增加了0.69σ，在提示注入攻击上增加了0.28σ。", "conclusion": "该研究了大量先进的VLM在多个维度上的安全性评估结果，并提出了一个可公开访问的框架（VSF-Med），旨在通过控制不可察觉的视觉扰动和结构相似性阈值，为医疗VLMs提供系统的安全检测和评分。"}
{"llm_update_time": "20250702", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22419", "html_url": "https://arxiv.org/abs/2506.22419", "title": "自动化的大型语言模型速度跑分基准：重现NanoGPT改进", "title_en": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "authors": "Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach", "background": "大型语言模型（LLMs）的快速进步有望促进科学进步，其中的关键能力之一是能够重复现有工作。为了评估AI代理在活跃研究领域再现结果的能力，引入了一个自动化的LLMs速度跑分基准，利用NanoGPT速度跑大赛（一个旨在以最短时间训练GPT-2模型的比赛）的研究社区贡献。这项比赛提供了19个任务，每个任务都提供了先前记录的训练脚本，有时还会提供从伪代码到论文样式的改进记录的三种格式之一的提示。由于这些脚本设计得能够快速执行，因此速度改进涵盖了从高级算法改进到硬件感知优化的各种代码级变化。这些特征使基准既易于访问又具有现实意义，是改善LLM训练前沿问题的一部分。", "innovation": "本文引入了自动化的LLMs速度跑分基准，强调了多项创新。首先，该基准以NanoGPT速度跑大赛为基础，提供了丰富的训练脚本和多样化的改进提示。其次，它重点关注现有的创新如何被新算法和硬件优化所再现，为评估LLMs的自动科学再现能力提供了简单有效的方法。最终，虽然最新推理LLMs在细节提示下仍难以重现已知创新，但该基准为评估LLMs自动化科学再现能力提供了一个明确的度量标准，这是自主研究代理所需但不充分的能力。", "conclusion": "本文的基准为评估LLMs自动化科学再现能力提供了一个明确的度量标准，尽管最新推理LLMs甚至在得到详细提示的情况下，仍然难以重现已知创新。因此，该基准不仅突显了自主研究代理需要具备的重要技能，还为开发能够自动进行科学研究的LLMs提供了指导。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00042", "html_url": "https://arxiv.org/abs/2507.00042", "title": "通过差异加权经验回放减轻灾难性遗忘", "title_en": "Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay", "authors": "Xinrun Xu,Jianwen Yang,Qiuhong Zhang,Zhanbiao Lian,Zhiming Ding,Shan Jiang", "background": "在云-边缘协作目标检测中实时调整边缘模型以监测交通时，模型可能会遭受灾难性遗忘，即模型在适应新数据分布时会忘记之前学习的知识。这在交通环境中的问题尤为严重，因为交通环境具有周期性变化（如白天/黑夜、高峰时段），过去的知识仍然具有重要意义。现有方法如经验重温（Experience Replay）和视觉提示（Visual Prompts）在缓解这一问题方面取得了一定成效，但仍无法有效地优先选择和利用历史数据，以优化知识保留与适应。例如，简单存储和重放所有历史数据可能效率低下，而假设所有历史经验同等重要忽略了它们对当前域的不同相关性。", "innovation": "本文提出了一种基于自适应经验回放的边缘模型更新算法ER-EMU。ER-EMU采用有限大小的经验缓冲区，并使用FIFO原则管理。ER-EMU还引入了一种名为DDM-ES（基于域距离度量的经验选择）的新算法。DDM-ES利用多核最大均值差异（MK-MMD）来量度目标域之间的差异性，优先选择与当前目标域最不同的历史数据，从而确保训练多样性和提高知识保留范围，同时防止过度拟合新域。经验缓冲区还使用简单随机抽样策略来保持过去域的均衡表示。", "conclusion": "实验结果证明，ER-EMU可以持续提高几种最先进的云-边缘协作目标检测框架的表现，特别是在涉及重复白天/黑夜循环的Bellevue交通视频数据集上的表现。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00044", "html_url": "https://arxiv.org/abs/2507.00044", "title": "HistoART: 组织病理学伪影检测和报告工具", "title_en": "HistoART: Histopathology Artifact Detection and Reporting Tool", "authors": "Seyed Kahaki,Alexander R. Webber,Ghada Zamzmi,Adarsh Subbaswamy,Rucha Deshpande,Aldo Badano", "background": "在现代癌症诊断中，全切片成像（WSI）被广泛用于数字化组织标本，以便进行详细和高分辨率的检查。然而，根据癌症类型和临床背景，也使用其他诊断方法，如液体活检和分子测试。虽然WSI通过实现自动化的精确分析而改变了数字病理学，但仍然容易受到在切片准备和扫描过程中引入的伪影的影响，这些伪影会损害后续的图像分析。本文的研究背景即在于此，旨在通过提出并比较三种稳健的WSI伪影检测方法来解决这一挑战：基于基础模型的方法（FMA）、深度学习方法（DLA）和基于知识的方法（KBA）。", "innovation": "本文提出的创新在于其采用了三种不同方法进行WSI中的伪影检测，包括基于基础模型的方法（FMA）、基于ResNet50的深度学习方法（DLA）以及基于知识的方法（KBA）。特别地，FMA在6种常见伪影类型（组织褶皱、对焦不佳区域、气泡、组织损伤、标记痕迹和血液污染）的检测上表现最佳。此外，还开发了一种质量报告评分卡来量化高质量图像并可视化伪影分布。", "conclusion": "研究结果表明，基于基础模型的方法（FMA）在50,000多张来自不同扫描仪图像片段的评估中取得了最高的AUROC值（0.995，95% CI [0.994, 0.995]），超过了ResNet50基础方法（AUROC: 0.977，95% CI [0.977, 0.978]）和基于知识的方法（AUROC: 0.940，95% CI [0.933, 0.946]）。通过促进伪影检测到可操作的洞察，该工具将有助于提高病理学图像的质量和分析的准确性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00045", "html_url": "https://arxiv.org/abs/2507.00045", "title": "CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning", "title_en": "CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning", "authors": "Ming Li,Chenguang Wang,Yijun Liang,Xiyao Wang,Yuhang Zhou,Xiyang Wu,Yuqing Zhang,Ruiyi Zhang,Tianyi Zhou", "background": "近期的多模态大语言模型如GPT-o3在各种现有基准测试中取得了接近天花板的成绩，这激发出对更具有挑战性的测试任务的需求。据报道，这些多模态大语言模型在人类几项专家级任务上表现优异，如GeoGuesser，证明它们在注意到图像中的细微线索并编织成连贯的解释方面具有巨大潜力，可能导致可靠的答案。但它们是否能与优秀的真人侦探相媲美？为解答这一问题，该研究调查了GPT-o3仍能处理的一些复杂场景，并发现了一个其表现几乎降至为零的共同场景，命名为CaughtCheating。这一研究灵感来自社交媒体请求，要求他人从发帖人伴侣分享的照片中检测可疑线索。该研究进行了广泛的实验和分析，以理解现有多模态大语言模型在解决此类任务时为何缺乏足够的能力。CaughtCheating提供了一类具有巨大价值和实际用途的视觉感知和推理挑战任务。在这些任务中的成功为多模态大语言模型获取类似于人类侦探的感知和推理能力铺平了道路。", "innovation": "研究通过引入“CaughtCheating”这一新的挑战任务，来测试多模态大语言模型在视觉感知和推理方面的边界。这不仅增加了对这些模型的挑战，还为未来的研究提供了新的方向。研究还详细分析了现有模型在处理此类任务时的不足之处，为改进模型提出了参考意见。", "conclusion": "研究发现，尽管多模态大语言模型在某些视觉感知和推理任务上表现优秀，但在“CaughtCheating”这类特定任务上却表现不佳，导致其性能几乎为零。这种现象揭示了现有模型在视觉感知和推理方面的能力限制，进而促使研究者进一步探索提高多模态大语言模型在这一类任务上表现的方法，以实现人类级别的侦探感知和推理能力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00153", "html_url": "https://arxiv.org/abs/2507.00153", "title": "基于扩散的图像增强在户外机器人语义分割中的应用", "title_en": "Diffusion-Based Image Augmentation for Semantic Segmentation in Outdoor Robotics", "authors": "Peter Mortimer,Mirko Maehlisch", "background": "基于学习的感知算法在部署于未见过的数据分布和代表不足的环境下时会表现出色下降。户外机器人特别容易受到动态光照、季节性和天气效应导致的视觉场景外观快速变化的影响，这种变化会导致训练数据中未能充分代表实际部署环境的场景。本文关注准备自动驾驶汽车在充满雪的环境下部署的问题。", "innovation": "本文提出了一种基于扩散的图像增强新方法，以更好地在训练数据中模拟实际部署环境。这种方法依赖于互联网规模数据集上学习的公共视觉基础模型。基于扩散的图像增强使我们能够控制训练数据中的地面表面的语义分布，并针对其部署环境微调模型。同时，本文采用了开放词汇语义分割模型来筛选出包含幻觉的增强候选样本，以提高模型的可靠性。", "conclusion": "本文认为，基于扩散的图像增强方法可以扩展到其他未见过的环境，如沙地环境和火山地形。这些技术能够提高自动驾驶汽车在特殊环境下的性能，增强算法的鲁棒性和适应性，为其在真实世界中的广泛应用奠定基础。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00068", "html_url": "https://arxiv.org/abs/2507.00068", "title": "MANTA:跨模态语义对齐与信息论优化的长时多模态理解", "title_en": "MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding", "authors": "Ziqi Zhong,Daniel Tang", "background": "多模态学习已经取得显著进展，但当前方法往往将模态分开处理，导致表示和推理上的不一致。现有方法在处理不同类型的信息（如视觉与听觉）时存在局限性，难以实现无缝集成和有效理解。因此，提高多模态之间的语义对齐，以及实现跨模态的信息有效融合和处理，是解决多模态理解问题的关键挑战。", "innovation": "本文提出了MANTA（多模态抽象和归一化通过文本对齐），这是一个基于理论的框架，将视觉和听觉输入统一到结构化的文本空间中，并无缝利用大型语言模型进行处理。MANTA解决四大挑战：（1）信息论优化下的模态之间语义对齐；（2）适应不同的时间同步与信息密度；（3）层次化内容表示以实现多尺度理解；（4）基于上下文的稀疏信息检索。该方法被形式化并在严格的数学框架中证明其在标记约束下的上下文选择最优性。实验证明MANTA在长视频问题回答任务中改善了现有最好模型的整体准确率最多22.6%，特别是对于超过30分钟的视频，提升达到27.3%。此外，MANTA在时间推理任务和跨模态理解任务中分别提高了23.8%和25.1%。该框架还引入了减少冗余的同时保留稀有信号的新型密度估计技术，从而在结构化文本中建立了多模态表示的新基础。", "conclusion": "MANTA框架通过结构化文本统一多模态表示，克服了当前多模态学习的局限性，为长时多模态理解提供了新的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00070", "html_url": "https://arxiv.org/abs/2507.00070", "title": "使用迁移学习方法的高效植物病害检测", "title_en": "An efficient plant disease detection using transfer learning approach", "authors": "Bosubabu Sambana,Hillary Sunday Nnadi,Mohd Anas Wajid,Nwosu Ogochukwu Fidelia,Claudia Camacho-Zuñiga,Henry Dozie Ajuzie,Edeh Michael Onyema", "background": "植物疾病对农民和农业产业构成了重大挑战。早期检测植物疾病对于缓解其影响和防止广泛损害至关重要，因为爆发会对作物的产量和质量造成严重影响。随着技术的进步，自动化植物病害监测和检测的机会不断增加。", "innovation": "本研究提出了一种系统，用于通过迁移学习方法识别和监控植物疾病。具体来说，该研究利用了两个最新的目标检测模型YOLOv7和YOLOv8，通过在植物叶片图像数据集上进行微调，系统能够准确检测细菌、真菌和病毒病害，如白粉病、角度斑点病、早疫病和番茄 mosaic 病毒等。评价指标包括mAP、F1分数、精度和召回率，其值分别为91.05、89.40、91.22和87.66，表明YOLOv8在目标检测方法中表现出优越的效率和效果，具有用于现代农业实践的潜力。这种方法提供了大规模和自动化的植物疾病早期检测解决方案，有助于提高作物产量，减少对人工监控的依赖，并支持可持续的农业实践。", "conclusion": "本研究展示了YOLOv8在植物疾病检测中的优越性能，并提出了一种高效的自动化解决方案，有助于提高作物产量，支持可持续的农业实践。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00162", "html_url": "https://arxiv.org/abs/2507.00162", "title": "FreeLong++：通过多频带光谱融合实现无需训练的长视频生成", "title_en": "FreeLong++: Training-Free Long Video Generation via Multi-band SpectralFusion", "authors": "Yu Lu,Yi Yang", "background": "近年来，基于文本提示的高质量短视频生成技术取得了显著进展。然而，将这些模型扩展到更长的视频片段仍然面临重大挑战，主要原因是时间一致性与视觉保真度的下降。初步观察表明，直接将短视频生成模型应用到更长的序列中会导致显著的质量下降。进一步分析发现，随着视频长度的增加，高频成分逐渐失真，我们将其称为高频失真。现有模型无法有效处理这一问题，导致生成的长视频质量较差，难以维持时间连续性和视觉细节。", "innovation": "本文提出了FreeLong++，这是一种无需训练的框架，可平衡长视频特征的频率分布，以增强去噪过程中的信号质量。FreeLong++使用多分支架构，包括多个注意力分支，每个分支负责不同时间尺度的处理。通过结合全局低频特征和局部高频特征，FreeLong++实现了从低频到高频的多带频率融合，确保长视频序列中语义的一致性和精细的运动动力学。这种方法无需额外训练即可直接插入现有的视频生成模型中，显著提升了长视频的时序一致性和视觉保真度，并支持多提示视频生成和长深度或姿态序列的可控制视频生成。", "conclusion": "FreeLong++在长视频生成任务中表现出色，与先前的方法相比，在4倍和8倍于原长度的视频生成任务中显著优于之前的方法。此外，该方法还支持统一多提示视频生成，并实现了平滑的场景过渡和可控制的视频生成。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00182", "html_url": "https://arxiv.org/abs/2507.00182", "title": "基于图的深度学习用于玉米植物组件分割", "title_en": "Graph-Based Deep Learning for Component Segmentation of Maize Plants", "authors": "J. I. Ruíz,A. Méndez,E. Rodríguez", "background": "在精准农业中，探索作物生产时的一个重要任务是识别个体植物的各个组件。传统的2D成像、3D重构和卷积神经网络（CNN）已尝试完成此任务，但它们在处理3D数据和识别个体植物组件时存在一些缺点。因此，本文提出了一种基于图神经网络（GNN）的概念，并结合主成分分析（PCA）特征增强，利用LiDAR三维点云数据集来检测个体植物的组件。", "innovation": "本文提出了一个新的深度学习架构，基于图神经网络（GNN），并通过主成分分析（PCA）特征增强，利用LiDAR三维点云数据集来检测个体植物的组件。每个点被当作一个节点，并通过K-最近邻（KNN）层建立边，从而表示3D点云数据集。然后使用Edge-Conv层进一步增强每个点的特征。最后，应用图注意网络（GAT）以分类可见的植物表型组件，如叶、茎和土壤。", "conclusion": "此研究证明，基于图的深度学习方法可以提高用于识别个体植物组件的分割精度，平均IoU超过80%，并且优于基于点云的其他现有模型。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00224", "html_url": "https://arxiv.org/abs/2507.00224", "title": "计算机视觉在团队工作中使用的物体中的挑战与机遇", "title_en": "Computer Vision for Objects used in Group Work: Challenges and Opportunities", "authors": "Changsoo Jung,Sheikh Mannan,Jack Fitzgerald,Nathaniel Blanchard", "background": "互动性和空间感知技术正在改变教育框架，特别是在K-12环境中，动手探索培养了更深刻的概念理解。然而，在协作任务中，现有的系统往往无法准确捕捉学生与物理物体之间的真实互动。自动6D姿态估计可以从RGB图像或视频估算物体在三维空间中的位置和方向，可以解决此问题。对于与物理物体交互的协作团队，6D姿态估算使AI系统可以关联物体和实体。研究人员利用这种技术建立了一个名为FiboSB的新颖且具有挑战性的6D姿态视频数据集，收录了三个参与者解决具有小手持立方体和重量秤的互动任务。由于团队从远处整体拍摄以捕捉所有参与者，再加上立方体的小尺寸，这使得6D姿态估计变得非平凡。研究人员评估了四种最先进的6D姿态估计方法，揭示了当前算法在协作团队工作中的局限性。错误分析表明，6D姿态方法的对象检测模块存在缺陷。研究人员通过细调YOLO11-x解决了这一问题，得到总体mAP_50为0.898的结果。这项工作为基础数据集、基准结果和YOLO11-x错误分析的提出提供了基础，以在困难的协作环境中利用6D姿态估计。", "innovation": "提出了一个名为FiboSB的新颖且具有挑战性的6D姿态视频数据集，用于评估和改进6D姿态估计方法。同时，研究人员通过细调YOLO11-x算法，提高了在团队合作任务中的6D姿态估计准确性，并揭示了当前算法的局限性。", "conclusion": "这项工作为利用6D姿态估计在复杂协作情境中提供了基础数据集、基准结果和错误分析，为未来的研究提供了重要的资源和方向。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00248", "html_url": "https://arxiv.org/abs/2507.00248", "title": "使用有限数据开发轻量级DNN模型进行实时手语识别", "title_en": "Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition", "authors": "Nikita Nikitin,Eugene Fomin", "background": "手语识别系统面临数据缺乏、高计算成本以及训练和推理环境帧率差异等关键挑战。现有的系统通常对这些挑战应对不足，影响了系统性能和应用范围。", "innovation": "本文提出了一种使用轻量级DNN进行实时手语识别的新框架，这些DNN在有限数据下训练。通过对特定于手语的手势、掌心方向、动作和位置参数进行矢量化输入，并利用MediaPipe进行关键点提取，实现了高度可区分的输入数据表示。该架构被优化以支持在边缘设备上的低于10MB部署，能够在不到10毫秒的延迟下准确分类343个手语手势。提出的数据标注平台'slait data'支持结构化的标注和矢量提取，模型在孤立手势识别中达到了92%的准确率，并已被集成到'slait ai' web应用程序中，展示了稳定的推理性能。", "conclusion": "本文通过开发轻量级DNN模型，克服了手语识别技术中的数据限制和计算成本高难题，为实现更广泛且实时的手语识别应用铺平了道路。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00261", "html_url": "https://arxiv.org/abs/2507.00261", "title": "虚拟防手：基于野生视频提取策略生成剑术对决", "title_en": "VirtualFencer: Generating Fencing Bouts based on Strategies Extracted from In-the-Wild Videos", "authors": "Zhiyin Lin,Purvi Goel,Joy Yun,C. Karen Liu,Joao Pedro Araujo", "background": "剑术是一种包含多样但策略性强的动作的竞技运动，尽管基础动作种类有限（如步法、冲刺、挑击），但每种动作的执行方式会有所差异（快慢、大小、进攻与防守）。运动员的动作受到策略的指导，这种策略往往是对对手行为的反应。作者认为这种动作多样性和背后涉及双人策略的组合促使了借助数据驱动模型来研究剑术。", "innovation": "该项目提出了VirtualFencer系统，该系统能够在不监督的情况下从野生视频中提取3D剑术动作和策略，然后利用这些知识生成真实的剑术行为。该系统展示了其多方面的能力，包括自我对决、与网络视频中真实剑手的动作对决，以及与职业剑手互动对决。", "conclusion": "VirtualFencer系统成功地从野生视频中自动提取剑术运动和策略，并利用这些数据生成逼真的剑术行为，展示了其在自动剑术模拟和训练中的潜在应用价值。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00287", "html_url": "https://arxiv.org/abs/2507.00287", "title": "自我监督的多视角X射线配对", "title_en": "Self-Supervised Multiview Xray Matching", "authors": "Mohamad Dabboussi,Malo Huard,Yann Gousseau,Pietro Gori", "background": "准确解读多视角 radiographs 对诊断骨折、肌肉损伤和其他异常至关重要。虽然在基于人工智能单一图像分析方面取得了显著进步，但当前方法在建立不同X射线视角之间的稳健对应关系方面仍存在困难，这对于精确的临床评估至关重要。", "innovation": "本文提出了一种新颖的自我监督管道，通过自动从未标记的CT体积中生成大量合成X射线视角之间的对应关系矩阵，从而消除了手动标注的需要。这一方法运用了数字化重建放射图（DRR），并结合基于变换器的训练阶段以准确预测两个或多个X射线视角之间的对应关系。此外，本文还证明了学习合成X射线视角之间的对应关系可以作为一种预训练策略，提高对实际数据中自动多视角骨折检测的性能。", "conclusion": "广泛的合成和真实X射线数据集评估表明，结合对应关系可以提高多视角骨折分类的表现。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00170", "html_url": "https://arxiv.org/abs/2507.00170", "title": "SelvaBox: 高分辨率的热带树木冠层检测数据集", "title_en": "SelvaBox: A high-resolution dataset for tropical tree crown detection", "authors": "Hugo Baudchon,Arthur Ouaknine,Martin Weiss,Mélisande Teng,Thomas R. Walla,Antoine Caron-Guay,Christopher Pal,Etienne Laliberté", "background": "在研究受到人类干预和气候变化影响的复杂热带森林生态系统时，单一树木冠层的检测至关重要。然而，热带冠层在大小、结构和模式方面存在显著差异，通常相互重叠且交织在一起，要求采用先进的遥感方法应用于高分辨率图像。尽管人们对热带树木冠层检测的兴趣日益增加，但注释数据集仍然稀缺，限制了模型的稳健开发。因此，迫切需要一个大规模且开放访问的数据集来推动这一领域的研究和发展。", "innovation": "作者引入了SelvaBox，这是迄今为止最大的用于高分辨率无人机图像中热带树木冠层检测的开放访问数据集。它涵盖了三个国家，并包含超过83,000个手动标注的冠层，是所有先前热带森林数据集中的冠层数量总和的一个数量级的增加。在SelvaBox上进行的广泛基准测试显示了两个关键发现：1）更高分辨率的输入始终提高检测准确度；2）仅在SelvaBox上训练的模型在未见过的热带树木冠层数据集上实现了竞争力的无监督检测性能，匹配或超过了竞争对手的方法。此外，在统一的多分辨率管道中，联合使用SelvaBox和其他三个分辨率从3到10厘米像素的数据集训练的检测器在所有评估数据集中排名第一或第二。", "conclusion": "SelvaBox, 全套代码和预训练权重均被公开，为热带树木冠层检测领域的发展提供了重要的基础数据和技术支持。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00243", "html_url": "https://arxiv.org/abs/2507.00243", "title": "VOCAL: 视觉里程计 via 对比学习", "title_en": "VOCAL: Visual Odometry via ContrAstive Learning", "authors": "Chi-Yao Huang,Zeel Bhatt,Yezhou Yang", "background": "视觉里程计（VO）的进步已经从根本上重塑了机器人技术的格局，使其能够实现现代自主系统中至关重要的超精准相机状态估计。尽管取得了这些进步，但许多基于学习的视觉里程计技术依赖于刚性几何假设，这些假设在可解释性和在完全数据驱动框架内的理论基础方面常常表现出不足。", "innovation": "我们提出了VOCAL（Visual Odometry via ContrAstive Learning），这是一种新颖的框架，重新定义了视觉里程计为标签排名挑战。通过结合贝叶斯推断与表示学习框架，VOCAL将视觉特征组织成与相机状态相一致的形式。排名机制促使相似的相机状态在潜在空间中收敛为一致且空间上连贯的表示。这种策略性对齐不仅增强了学习特征的可解释性，还确保了与多模态数据源的兼容性。广泛的KITTI数据集上的评估证明了VOCAL增强了的可解释性和灵活性，推动视觉里程计向更通用和解释性强的空间智能演进。", "conclusion": "在KITTI数据集上的广泛评估表明，VOCAL增强了可解释性和灵活性，推动视觉里程计向更普遍和解释性强的空间智能方向发展。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00365", "html_url": "https://arxiv.org/abs/2507.00365", "title": "改进的U-Net模型在离线手写签名去噪中的应用", "title_en": "An Improved U-Net Model for Offline handwriting signature denoising", "authors": "Wanghui Xiao", "background": "手写签名因其法律效应和独特性，在金融交易、商业合同和个人事务等多个领域广为应用。在法医学鉴定中，离线手写签名分析需要特定数量的签名样本，这些样本通常来自各种历史合同或档案材料。但是，提供的签名样本中通常混有大量的干扰信息，这对签名识别工作提出了严峻挑战。", "innovation": "本文提出了一种基于改进U-Net结构的签名去噪模型，通过引入离散小波变换和PCA变换以增强模型抑制噪声的能力。实验结果表明，该模型在去噪效果上显著优于传统方法，能够有效提高签名图像的清晰度和可读性，为签名分析和识别提供更可靠的技术支持。", "conclusion": "研究提出的基于改进U-Net结构的签名去噪模型，在离线手写签名去噪方面表现出色，提高了签名识别系统的鲁棒性，并为后续的手写签名分析与识别提供了更清晰、更可靠的技术支持。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00328", "html_url": "https://arxiv.org/abs/2507.00328", "title": "MammoTracker: Mask-Guided Lesion Tracking in Temporal Mammograms", "title_en": "MammoTracker: Mask-Guided Lesion Tracking in Temporal Mammograms", "authors": "Xuan Liu,Yinhao Ren,Marc D. Ryser,Lars J. Grimm,Joseph Y. Lo", "background": "在监测乳腺癌进展及促进早期诊断方面，时间序列乳腺X光摄影（乳腺钼靶）中的病灶定位准确追踪至关重要。然而，在计算机辅助诊断（CAD）系统中，跨检查病灶自动对应仍然是一项挑战，限制了其有效性。", "innovation": "我们提出了MammoTracker，这是一种基于掩码的病灶追踪框架，旨在自动化连续检查中的病灶定位。该方法采用从粗到细的策略，包含全局搜索、局部搜索和评分细化三个关键模块。我们还引入了一个新的数据集，该数据集包含公开展示的EMBED乳腺X光摄影数据集中730个肿块和钙化病例的精心整理先验检查注释，生成了超过20000个病灶对，使其成为已知最大的乳腺钼靶病灶跟踪资源。实验结果表明，MammoTracker的平均重叠精度为0.455，准确率为0.509，比基线模型高出8%，突显了其用于CAD基于病灶进展分析的潜力。", "conclusion": "实验结果表明，MammoTracker在病灶跟踪方面显著优于基线模型，对乳腺钼靶图像中的病灶进展分析具有重要的应用前景。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00356", "html_url": "https://arxiv.org/abs/2507.00356", "title": "CGEarthEye：基于吉林一号卫星星座的高分辨率遥感视觉基础模型", "title_en": "CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation", "authors": "Zhiwei Yi,Xin Cheng,Jingyu Ma,Ruifei Zhu,Junwei Tian,Yuanxiu Zhou,Xinge Zhao,Hongzhe Li", "background": "深度学习方法显著推进了遥感（RS）领域智能重解释的发展，特别是基于大规模预训练范式的模型研究迅速重塑了地球观测（EO）的不同领域。然而，尽管中分辨率数据具有较高的开放访问性和时空覆盖度，超高分辨率光学RS影像由于受限的获取通道而限制了高分辨率遥感视觉基础模型（RSVFM）的进步。作为世界上最大的亚米级商业RS卫星星座，吉林一号星座拥有丰富的亚米级图像资源。然而，目前的高分辨率RSVFM模型在参数规模和多时相数据集构建上存在局限性，亟需新的解决方案来提升模型性能和数据应用效率。", "innovation": "该研究提出了一种名为CGEarthEye的RSVFM框架，专门针对吉林一号卫星的特点，采用五个具有不同参数比例的骨干网络，总参数量达21亿。为增强基础模型的表现力，构建了首个1500万规模的多时相半监督学习（SSL）数据集JLSSD，覆盖全球并按季度采样。框架结合了季节对比、基于增强的数据对比和掩码补丁标记对比策略进行预训练。全面的评估显示，CGEarthEye在10个基准数据集上均取得优异表现，尤其在特征可视化、模型收敛性、参数效率以及实际应用中的性能方面表现出色。", "conclusion": "CGEarthEye的研究成果表明，它具备出色的表示能力，有望推动吉林一号数据在传统地球观测应用中的更广泛应用。这项研究为提升高分辨率遥感图像处理能力和应用范围提供了新的视角和方法。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00263", "html_url": "https://arxiv.org/abs/2507.00263", "title": "不结构化短租图像集合中的房间场景发现与分组", "title_en": "Room Scene Discovery and Grouping in Unstructured Vacation Rental Image Collections", "authors": "Vignesh Ram Nithin Kappagantula,Shayan Hassantabar", "background": "短期租赁平台的迅速增长已导致上传的房源图片数量激增，但这些图片通常缺乏有组织的分类。这种缺乏组织性造成了重大挑战，尤其是在旅行者试图理解一个房源的空间布局时，尤其是在同一类型的多个房间中。为了解决这个问题，我们提出了一种有效的方法来解决房间场景发现和分组问题，以及识别每个卧室组中的床类型。这种分组有助于旅行者理解房源的空间组织、布局和睡眠配置。该方法的关键在于引入了一个计算效率高、能够快速响应和适应数据稀缺环境的机器学习管道。该管道包括监督房间类型检测模型、监督图像之间重叠检测模型和使用相似度评分的聚类算法。同时，管道还利用多模态大语言模型（MLLM）模型根据每个卧室组图片中的视觉内容将每个卧室组映射到房源元数据中指定的床类型上。我们分别评估了上述模型，并整体评估了整个管道，观察结果显示，与现有的对比学习和预训练嵌入聚类方法相比，具有显著优越的性能。", "innovation": "我们提出了一种计算效率高、能够实现快速响应和适应数据稀缺环境的机器学习管道。该管道融合了监督房间类型检测模型、监督重叠检测模型和聚类算法，能够有效地将具有相似性的图片分组，并利用多模态大语言模型（MLLM）模型根据视觉内容映射卧室组到对应的床类型上。", "conclusion": "我们通过分别和整体评估了上述模型，观察到与现有的对比学习和预训练嵌入聚类方法相比，该管道具有显著的优越表现。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00292", "html_url": "https://arxiv.org/abs/2507.00292", "title": "降低数字病理学中多重实例学习方法的变异性", "title_en": "Reducing Variability of Multiple Instance Learning Methods for Digital Pathology", "authors": "Ali Mammadov,Loïc Le Folgoc,Guillaume Hocquet,Pietro Gori", "background": "数字病理学通过数字化组织样本为全屏图像（WSI），彻底改变了病理学领域。然而，WSI的高分辨率和大尺寸给深度学习模型的应用带来了困难。通常，WSI会被分割成较小的片段，每张幻灯片有一个全局标签（诊断），而不是昂贵的逐像素标注。通过将每张幻灯片视为片段的集合，多重实例学习（MIL）方法成为WSI分类的理想方案。但是，MIL方法在不同运行中的性能差异性极大，可能在测试集上达到10-15个AUC点的差异，这使得不同MIL方法之间的可靠比较变得困难。这种差异性主要来自于三个方面：i）权重初始化，ii）批次洗牌顺序，iii）学习率。因此，为了应对这个问题，本文引入了一种多保真度、模型融合策略，旨在减少MIL方法的性能变异性。", "innovation": "本文提出了一种多保真度、模型融合策略，首先为多个模型进行几次迭代训练，并根据验证分数选择最稳定和最有可能的模型进行平均。这种方法可应用于任何现有的MIL模型以减少性能变异性。此外，该策略简化了超参数调整，提高了可重复性并保持了计算效率。", "conclusion": "通过在包含2种数据集、3种初始化策略和5种MIL方法的超过2000个实验中对方法进行广泛验证，确认该方法在提高MIL方法的可重复性和性能稳定性方面具有显著效果。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00327", "html_url": "https://arxiv.org/abs/2507.00327", "title": "超越低秩调优：模型先验引导的秩分配方法以提高在少量数据和大域间差距情况下的转移有效性", "title_en": "Beyond Low-Rank Tuning: Model Prior-Guided Rank Allocation for Effective Transfer in Low-Data and Large-Gap Regimes", "authors": "Chuyan Zhang,Kefan Wang,Yun Gu", "background": "低秩适应（LoRA）已被证明能在保持与完全微调基础模型相当的性能的同时，降低计算成本。然而，其固定的低秩结构限制了在存在显著领域差异的场景中的适应性，这些场景通常需要较高的秩来捕捉领域特定的复杂性。当前的适应性LoRA方法试图通过动态扩张或选择性分配秩来克服这一局限性，但这些方法常常依赖于迭代修剪、秩搜索或额外正则化等计算密集型技术。", "innovation": "本文提出了一种名为Stable Rank-Guided Low-Rank Adaptation（SR-LoRA）的新框架，利用预训练权重矩阵的稳定秩作为逐层分配秩的自然先验。通过利用稳定秩，反映了权重的内在维度，SR-LoRA能够在不增加搜索成本的情况下，在各层之间合理且高效地重新分配秩，提高适应性。实验结果显示，SR-LoRA在具有显著领域差距的少量样本任务上的性能和效率都优于最近的适应性LoRA变体。", "conclusion": "SR-LoRA在存在显著领域差距的少量样本任务上表现优越，提供了性能和效率之间的更好权衡。相关代码可在该链接下载。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00334", "html_url": "https://arxiv.org/abs/2507.00334", "title": "填充场景：感知 affordance 的人类视频生成", "title_en": "Populate-A-Scene: Affordance-Aware Human Video Generation", "authors": "Mengyi Shan,Zecheng He,Haoyu Ma,Felix Juefei-Xu,Peizhao Zhang,Tingbo Hou,Ching-Yao Chuang", "background": "本文探讨了是否可以将视频生成模型重新用于交互式世界模拟。研究集中在通过训练文本到视频模型来预测人类与环境的互动能力。给定一个场景图像和描述人类行为的提示，模型被细调以将人物插入场景中，同时确保行为、外貌、协调性和场景互动的一致性。研究不同于以往工作，它们是从单个场景图像中推断人类 affordance（即人物的插入位置及其行为方式），而不是依靠明确的条件如边界框或身体姿态来实现。这项研究通过分析跨注意力热图来深入了解预训练视频模型的内在 affordance 感知能力，无需有标记的 affordance 数据集便可实现。", "innovation": "本文的创新点在于不依赖于边界框或身体姿态等明确条件，而是仅从单张场景图像中推断人类的 affordance，以此训练模型来预测和插入人物的行为。这种方法利用了预训练的视频生成模型的内在 affordance 感知能力，无需额外的标记数据集即可实现更为灵活和自适应的视频生成。", "conclusion": "通过该研究证明了文本到视频模型具备感知场景互动的能力，并能在单张图像中推断出人类的行为意向。跨注意力热图的深入研究表明，这种方法能够通过场景图像自身来有效捕捉并利用模型的内在 affordance 感知机制，从而改进视频生成过程中人物插入的自然性和连贯性。这一方法为交互式虚拟环境和数字内容生成提供了新的可能性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00363", "html_url": "https://arxiv.org/abs/2507.00363", "title": "GDGS: 通过几何引导初始化和动态密度控制的3D高斯斑点", "title_en": "GDGS: 3D Gaussian Splatting Via Geometry-Guided Initialization And Dynamic Density Control", "authors": "Xingjun Wang,Lianlei Shan", "background": "3D Gaussian Splatting (3DGS) 是一种用于实时生成逼真图像的方法，但由于其对准确初始化的依赖和优化难以将无序高斯分布转化为有序表面的问题，导致其在密度控制方面表现不佳。这篇文章提出了一种通过几何引导初始化和动态密度控制的方法来改进3DGS，解决了上述问题。", "innovation": "1. 几何引导初始化：预测高斯参数，确保准确放置并加快收敛。\n2. 表面对齐优化策略：细化高斯放置，提高几何精度并使表面与场景法线对齐。\n3. 动态自适应密度控制机制：基于区域复杂度调整高斯密度，增强视觉保真度。", "conclusion": "这些创新使得该方法能够实现高保真实时渲染，并在复杂场景中显著提高视觉质量。实验结果表明该方法与其他最先进的方法相比，能够实时渲染高保真图像，结果与现有的最佳方法相当或更优。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00339", "html_url": "https://arxiv.org/abs/2507.00339", "title": "训练X射线视觉：多摄像头视频中的无遮挡分割、无遮挡内容完成和视不变对象表示", "title_en": "Training for X-Ray Vision: Amodal Segmentation, Amodal Content Completion, and View-Invariant Object Representation from Multi-Camera Video", "authors": "Alexander Moore,Amar Saini,Kylie Cancilla,Doug Poland,Carmen Carrano", "background": "无遮挡分割和无遮挡内容完成需要使用对象先验来估计复杂场景中的遮挡掩模和对象特征。目前，还没有数据集提供了额外的维度，即多个摄像头共享同一个场景的视角。已有的一些数据集提供了无遮挡检测、跟踪和分割标签，但其他方法依赖于缓慢的剪切和粘贴方案来生成无遮挡内容的伪标签，这些方法没有考虑到真实遮挡在显性分割掩模中存在的自然遮挡现象。新的数据集MOVi-MC-AC通过多摄像头视频模拟杂乱的家庭用品场景，填补了这一空白并为计算机视觉中的深度学习领域做出了两方面的贡献。", "innovation": "提出了一个名为MOVi-MC-AC的新数据集，它包括多摄像头设置下的一致物体标识符，以及无遮挡内容任务。MOVi-MC-AC是迄今为止最大的无遮挡分割数据集，也是首次提供真实无遮挡内容的无遮挡数据集。该数据集为多个摄像头的不同视角下的物体识别与跟踪提供了场景，提高了物体检测、跟踪和分割的研究水平。MOVi-MC-AC还提供了超过580万个物体实例的标签，极大地增加了无遮挡数据集中的物体实例数量，为研究提供了更丰富的数据支持。", "conclusion": "MOVi-MC-AC为计算机视觉中的深度学习提供了新的挑战，通过多摄像头设置和无遮挡内容任务，推动了物体检测、跟踪和分割的研究进度。新数据集不仅增加了无遮挡分割的数据量，还首次提供了无遮挡内容的准确标签，这对理解和解决计算机视觉中的遮挡问题具有重要价值。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00253", "html_url": "https://arxiv.org/abs/2507.00253", "title": "GazeTarget360: 朝着实现全景视点估计以提高机器人感知能力", "title_en": "GazeTarget360: Towards Gaze Target Estimation in 360-Degree for Robot Perception", "authors": "Zhuangzhuang Dai,Vincent Gbouna Zakka,Luis J. Manso,Chen Li", "background": "让机器人理解人类的注视目标是允许其执行下游任务的关键，例如在现实世界的人机交互中进行注意力估计和动作预判。先前的研究通过使用数据驱动的方法来解决画面内的目标定位问题，并小心地移除画面外样本。基于视觉的注视估计方法，例如OpenFace，无法有效地吸收图像背景信息，无法在主体视线离开摄像头的情况下预测其注视目标位置。因此，这项工作提出了一种系统，可以解决在泛化视觉场景中从单张图像估计360度注视目标的问题，该系统名为GazeTarget360，它整合了注意力检测器的条件推理引擎、预训练的视觉编码器以及多尺度融合解码器。交叉验证结果显示GazeTarget360可以在未见过的情景中生成准确且可靠的注视目标预测。这意味着这是一个前所未有的系统，可以从真实的摄像画面上预测注视目标，且具有高效性和可部署性。其开源代码已发布于this https URL.", "innovation": "该系统GazeTarget360通过集成注意力检测器的条件推理引擎、预训练的视觉编码器以及多尺度融合解码器来解决泛化视觉场景中的360度注视目标估计问题。它能够在未见过的情景中生成准确且可靠的注视目标预测，适用于实时真实摄像画面中的情境，实现高效且可部署的注视目标预测系统。", "conclusion": "该系统首次能够在真实的摄像画面上实现高效且可部署的注视目标预测，并通过公开源码供研究使用，推动了机器人感知能力的发展。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00372", "html_url": "https://arxiv.org/abs/2507.00372", "title": "高效深度和空间变化的图像模拟以实现失焦降blur", "title_en": "Efficient Depth- and Spatially-Varying Image Simulation for Defocus Deblur", "authors": "Xinge Yang,Chuong Nguyen,Wenbin Wang,Kaizhang Kang,Wolfgang Heidrich,Xiaoxing Li", "background": "现代大光圈相机常遭受景深浅的困扰，导致焦点平面外的物体成像模糊。这一限制对固定焦距相机尤为棘手，如智能眼镜中的传感器，由于外形尺寸和功率限制，添加自动对焦机制困难重重。现有的光学畸变和焦距特性各异，导致训练于开源数据集上的深度学习模型在实际场景表现不佳，难以适应各个相机系统的独特属性。本文着眼于这一领域，重点分析了当前智能眼镜相机的固有缺陷及其对数字图像处理的挑战，以及基于现有数据集训练模型的局限性。", "innovation": "本文提出了一种高效且可扩展的数据集合成方法，该方法无需依赖现实世界数据的微调，能够同时建模深度相关的失焦和空间变化的光学畸变现象，以解决计算复杂度和高质量RGB-D数据稀缺的问题。", "conclusion": "实验结果表明，训练于本研究所提供的低分辨率合成图像的网络在多种场景下，对高分辨率（12MP）的现实世界图像具有良好的泛化能力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00368", "html_url": "https://arxiv.org/abs/2507.00368", "title": "适应性Top-K概率整合的分布外检测", "title_en": "Out-of-Distribution Detection with Adaptive Top-K Logits Integration", "authors": "Hikaru Shijo,Yutaka Yoshihama,Kenichi Yadani,Norifumi Murata", "background": "神经网络通常会对分布外（OOD）样本做出过度自信的预测。因此，检测OOD数据对于提高机器学习的安全性至关重要。MaxLogit是简单的且强有力的方法之一，它使用模型的最大logit来提供OOD分数。我们发现，除了最大logit，其他logit也对OOD检测有用。基于此发现，我们提出了新的方法ATLI（Adaptive Top-k Logits Integration），该方法可以适应性地确定每个模型特有的有效top-k logits，并将最大logit与其他top-k logits结合使用。我们使用ImageNet-1K基准测试评价了我们提出的方法。广泛实验表明，我们提出的方法将MaxLogit方法的假阳性率（FPR95）降低了6.73%，并将FPR95额外降低了2.67%，优于其他最先进的方法", "innovation": "提出了一种新的方法ATLI（Adaptive Top-k Logits Integration）。该方法适应性地确定每个模型特有的有效top-k logits，并结合最大logit与其他top-k logits。并通过实验验证了其有效性，相较于其他方法降低了更多的假阳性率", "conclusion": "我们提出的ATLI方法通过结合模型的最大logit与其他top-k logits，降低了假阳性率。相较于MaxLogit方法降低了6.73%，相较于其他最先进的方法降低了2.67%。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00392", "html_url": "https://arxiv.org/abs/2507.00392", "title": "通过将单张2D图像提升至3D空间学习密集特征匹配", "title_en": "Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space", "authors": "Yingping Liang,Yutao Hu,Wenqi Shao,Ying Fu", "background": "特征匹配在许多计算机视觉任务中发挥着基础性作用，但现有方法严重依赖于稀缺且干净的多视角图像集合，这限制了其在多种复杂场景中的泛化能力。此外，传统特征编码器通常是在单视角2D图像上进行训练，限制了其捕捉3D相关的对应性的能力。因此，研究工作集中在开发能够利用大量多样单视角图像的新型框架，以提升特征匹配在3D场景中的能力。", "innovation": "本文提出了一个新颖的两阶段框架，名为Lift to Match (L2M)，能够将2D图像提升至3D空间，充分利用大量多样化单视角图像的学习优势。L2M的创新之处在于第一阶段使用多视角图像合成和3D特征高斯表示学习3D感知特征编码器，将3D几何知识注入编码器；第二阶段通过大规模单视角图像生成的合成数据集和新颖视图渲染策略来学习特征解码器，从而实现跨领域的一致性特征匹配。", "conclusion": "大量实验验证了本文方法在零样本评估基准中的卓越泛化能力，证明了所提出框架在鲁棒特征匹配中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00377", "html_url": "https://arxiv.org/abs/2507.00377", "title": "MedDiff-FT: 数据效率扩散模型微调及其在结构引导控制医学图像合成中的应用", "title_en": "MedDiff-FT: Data-Efficient Diffusion Model Fine-tuning with Structural Guidance for Controllable Medical Image Synthesis", "authors": "Jianhao Xie,Ziang Zhang,Zhenyu Weng,Yuesheng Zhu,Guibo Luo", "background": "现有的医学图像分割深度学习方法往往受到高质量训练数据稀缺的限制。尽管扩散模型能够通过生成合成图像提供解决方案，但其在医学成像领域的应用仍受限于对大规模医学数据集的需求以及图像质量的要求。为了解决这些挑战，本文提出了一种名为MedDiff-FT的可控医学图像生成方法，该方法通过对扩散基础模型进行微调，以一种数据高效的方式生产具有结构依赖性和领域特异性的医学图像。", "innovation": "MedDiff-FT方法通过微调扩散模型，在减少大量数据要求的同时生成高质量且具有结构依赖性的医学图像。其在生成过程中的动态自适应引导掩膜能够确保合成图像的解剖学一致性，轻量级的随机掩膜生成器通过分层的随机性注入增强多样性，并使用自动的质量评估协议根据特征空间指标过滤掉次优输出，最后通过掩膜腐蚀来进一步优化图像的真实性。", "conclusion": "MedDiff-FT在五个医学图像分割数据集上的测试表明，与现有最优方法相比，其合成的图像-掩膜对平均提高了1%的Dice分数。该框架在生成质量、多样性以及计算效率之间实现了有效平衡，提供了一个实用的医学数据扩增解决方案。相关代码已发布。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00371", "html_url": "https://arxiv.org/abs/2507.00371", "title": "PlantSegNeRF：通过联合通道神经辐射场与多视图图像实例匹配进行植物3D实例点云重建的少量样本跨数据集方法", "title_en": "PlantSegNeRF: A few-shot, cross-dataset method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching", "authors": "Xin Yang(1 and 2),Ruiming Du(3),Hanyang Huang(1 and 2),Jiayang Xie(1 and 2),Pengyao Xie(1 and 2),Leisen Fang(1 and 2),Ziyue Guo(1 and 2),Nanjun Jiang(4),Yu Jiang(5),Haiyan Cen(1 and 2) ((1) College of Biosystems Engineering and Food Science, Zhejiang University, (2) Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, (3) Department of Biological and Environmental Engineering, Cornell University, (4) Amway (China) Botanical R and D Center, (5) Horticulture Section, School of Integrative Plant Science, Cornell AgriTech)", "background": "植物器官点云分割是高分辨率和准确提取器官级表型特征的前提。尽管深度学习的发展极大地推动了植物点云分割的研究，但现有的器官分割技术在分辨率、分割精度和跨多种植物物种的一般性方面仍存在局限性。", "innovation": "本文提出了一种新的方法PlantSegNeRF，旨在从多视角RGB图像序列直接生成广泛植物物种的高精度实例点云。PlantSegNeRF 通过在多视角图像上进行2D实例分割来生成每个器官对应的实例掩码。利用一个特别设计的实例匹配模块匹配和优化了同一植物器官的多视角实例ID。PlantSegNeRF 创建了一个包含颜色、密度、语义和实例信息的隐式场景，并通过体积密度将其转换为高精度植物实例点云。与常用的点云语义分割方法相比，PlantSegNeRF 在结构复杂数据集上的精度、召回率、F1 分数和 IoU 分别提高了 16.1%、18.3%、17.8% 和 24.2%。", "conclusion": "PlantSegNeRF 在植物点云实例分割任务中表现出显著优势。在所有植物数据集中，PlantSegNeRF 在 mPrec、mRec、mCov 和 mWCov 上分别取得了平均 11.7%、38.2%、32.2% 和 25.3% 的改善。本研究扩展了器官级植物表型，并为植物科学中的大规模模型开发提供了高质量的3D数据的高通量方式。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00447", "html_url": "https://arxiv.org/abs/2507.00447", "title": "基于潜在空间的后验中值归一化流以实现更高保真度感知复原", "title_en": "Latent Posterior-Mean Rectified Flow for Higher-Fidelity Perceptual Face Restoration", "authors": "Xin Luo,Menglin Zhang,Yunwei Lan,Tianyu Zhang,Rui Li,Chang Liu,Dong Liu", "background": "感知-失真权衡（PD-权衡）理论表明，面部复原算法需要平衡感知质量和忠实度。尽管后验中值归一化流（PMRF）提出了一种基于流的方法以最小化失真并维持完美感知质量，但其像素空间建模方法限制了其与人类感知的对齐能力，而人类感知基于人们对两个图像分布辨别能力的判断。因此，迫切需要一种新的方法来改进现有的面部复原技术，以更好地与人类感知对齐。", "innovation": "本文提出了一种新的方法——潜在-PMRF，将PMRF重新公式化为变分自编码器（VAE）的潜在空间，从而在优化过程中更好地与人类感知对齐。通过定义源分布为最小失真估计的潜在表示，将最小失真精度限制在VAE的重构误差内。此外，我们的研究揭示了VAE的设计至关重要，我们的VAE在重建和复原方面显著优于现有的VAE。实验结果表明，潜在-PMRF方法在盲面部复原方面表现出了优越性，提供了优于现有方法的PD-权衡，并且具有显著的收敛效率，相比PMRF在FID上的速度提升5.79倍。", "conclusion": "潜在-PMRF在盲面部复原中展现出了卓越的PD-权衡，同时提供了显著的收敛效率，其代码将作为开源发布。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00429", "html_url": "https://arxiv.org/abs/2507.00429", "title": "DiGA3D：从粗到细的几何和外观扩散传播以实现多功能3D修复", "title_en": "DiGA3D: Coarse-to-Fine Diffusional Propagation of Geometry and Appearance for Versatile 3D Inpainting", "authors": "Jingyi Pan,Dan Xu,Qiong Luo", "background": "在基于文本引导的3D修复中，开发一个统一的管道，使得用户能够以灵活的方式移除、重新纹理或替换对象是至关重要的。然而，要在统一框架中完成多种3D修复任务仍然存在挑战：1) 单参考修复方法在应对与参考视图相差较大的视图时缺乏鲁棒性；2) 使用2D扩散先验独立修复多视图图像时出现外观不一致；3) 当插值区域存在显著几何变化时，几何不一致性限制了修复性能。", "innovation": "该论文提出了DiGA3D，这是一种新颖且多功能的3D修复管道，利用扩散模型以粗细有序的方式传播一致的外观和几何特性。首先，DiGA3D开发了一种选择多个参考视图的鲁棒策略，以减少传播过程中的错误。其次，DiGA3D设计了注意特征传播（AFP）机制，该机制通过扩散模型将选中的参考视图中的注意特征传播到其他视图，以保持外观一致性。此外，DiGA3D引入了一种纹理-几何评分蒸馏采样（TG-SDS）损失，以进一步提高3D修复场景的几何一致性。", "conclusion": "广泛的实验表明了该方法的有效性。我们在多个3D修复任务上进行了详细测试，并展示了DiGA3D方法的优点。该研究网站可从此链接查看：this https URL"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00373", "html_url": "https://arxiv.org/abs/2507.00373", "title": "可定制化的基于感兴趣区域的深度图像压缩", "title_en": "Customizable ROI-Based Deep Image Compression", "authors": "Ian Jin,Fanxin Xia,Feng Ding,Xinfeng Zhang,Meiqin Liu,Yao Zhao,Weisi Lin,Lili Meng", "background": "传统的基于感兴趣区域（ROI）的图像压缩方法通过优先优化ROI区域的重建质量来分配比特位，但随着用户需求的多样化，单一固定的ROI定义和重建质量的分配机制已无法满足需求。不同的用户可能对ROI的定义不同，或者对ROI和非ROI之间的重建质量折衷有不同要求。现有的ROI图像压缩方法在ROI定义上缺乏灵活性，不具备有效机制来平衡ROI和非ROI之间的重建质量。", "innovation": "本文提出了一种可定制化的基于ROI的深度图像压缩新范式。首先，设计了文本控制掩码获取（TMA）模块，允许用户通过输入相应的语义文本轻松自定义ROI以进行压缩，使编码器受文本控制。其次，设计了可定制值分配（CVA）机制，确保非ROI区域可以根据用户需求的可变范围减影，而不是采用固定尺度来处理ROI和非ROI之间的重建质量折衷。最后，引入了潜空间掩码注意力（LMA）模块，提取掩码的空间先验和图像的率失真优化（RDO）先验，并在潜空间中进行融合，进一步优化源图像的潜空间表示。实验结果表明该方法在ROI定义和掩码获取的灵活性，以及管理ROI和非ROI之间重建质量的折衷方面，有效解决了现有方法的不足。", "conclusion": "本文提出了一种可定制化的基于ROI的深度图像压缩新范式，通过TMA、CVA和LMA三个模块确保了编码器的灵活性和高效性能。实验结果验证了该框架的有效性和优越性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00454", "html_url": "https://arxiv.org/abs/2507.00454", "title": "ATSTrack: 通过对齐时间和空间尺度增强视觉语言跟踪", "title_en": "ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales", "authors": "Yihao Zhen,Qiang Wang,Yu Qiao,Liangqiong Qu,Huijie Fan", "background": "视觉语言跟踪（VLT）的一个主要挑战是由目标运动引起的视觉输入和语言描述之间的对齐不良。先前的跟踪器探索了许多有效的方法来修改特征，以保留更多的对齐特征。然而，这一问题的根本原因之一，即视觉和语言输入之间的内在时间和空间尺度差异，仍未被充分探索。", "innovation": "本文提出了一种新颖的视觉语言跟踪器ATSTrack，通过对齐不同输入组件的时间和空间尺度来增强特征修改的效果。具体地，基于视觉输入的时间和空间对应性，将每个语言描述分解为不同属性的短语，并以精细的方式修改它们的特征。此外，引入了一个视觉语言标记，包含来自上一帧的修改语言信息，以指导模型提取与语言描述更相关的视觉特征，从而减少由于尺度差异造成的影响。", "conclusion": "我们的实验结果表明，提出的ATSTrack在性能上与现有方法相当。我们的代码将在未来发布。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00462", "html_url": "https://arxiv.org/abs/2507.00462", "title": "利用Mean-Shift引导的测试时自适应：解锁所有测试样本的潜力", "title_en": "Unleashing the Potential of All Test Samples: Mean-Shift Guided Test-Time Adaptation", "authors": "Jizhou Han,Chenhao Ding,SongLin Dong,Yuhang He,Xinyuan Gao,Yihong Gong", "background": "视觉-语言模型（VLMs）如CLIP展现出很强的泛化能力，但在测试阶段面对分布偏移时表现不佳。现有的无训练测试时自适应（Training-Free Test-time Adaptation, TTA）方法仅在CLIP的原始特征空间内运行，专注于高置信度的样本，而忽略了低置信度样本的潜力。因此，需要一种方法来同时提升所有测试样本，以改善特征表示并增强自适应稳定性，从而提高模型在不同分布数据上的鲁棒性适应能力。", "innovation": "提出了MS-TTA（Mean-Shift Guided Test-Time Adaptation），这是一种无需训练且在单一步骤中使用k-最近邻（kNN）Mean-Shift的方法，增强了测试样本的特征表示超出CLIP原有的特征空间。该方法通过细化所有测试样本来增强特征紧凑性和类别可分辨性，进一步通过缓存细化的嵌入来提升推理的稳健性，从而实现更稳定的自适应。此外，广泛的实验表明，MS-TTA在各种交叉数据集基准上的性能优于最先进的TTA方法，而不需要额外的训练。", "conclusion": "MS-TTA能够在不进行额外训练的情况下实现更鲁棒的自适应，通过增强特征表示和使用Mean Shift提升特征，同时提供细化后的嵌入来进一步提升推理性能，从而在不同分布的数据上取得了更稳定的表现。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00430", "html_url": "https://arxiv.org/abs/2507.00430", "title": "MFH: 结合频率域与手写数学表达式识别", "title_en": "MFH: Marrying Frequency Domain with Handwritten Mathematical Expression Recognition", "authors": "Huanxin Yang,Qiwen Wang", "background": "手写数学表达式识别 (HMER) 遇到了复杂公式结构和字符布局在序列预测中的挑战。现有方法在处理胡椒这些问题时表现不佳。", "innovation": "本文提出了一种将频率域分析与HMER相结合的方法 (MFH)，利用离散余弦变换 (DCT)。这种方法强调了频率信息在识别数学公式的结构分析中的辅助作用。实验结果显示，当应用于各种基线模型时，该网络在多种数据集上的表现均有所提升，证明了频率域信息的有效性。MFH-CoMER 在 CROHME 2014/2016/2019 的测试集上取得了显著的准确率，分别为 61.66%/62.07%/63.72%。", "conclusion": "该研究表明，在HMER中引入频率域分析可以显著提高识别精度，并展示了该方法在实际应用中的潜力。源代码已在网上提供。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00401", "html_url": "https://arxiv.org/abs/2507.00401", "title": "Few-shot 分类作为一种多实例验证：跨域无预训练主干的有效迁移", "title_en": "Few-shot Classification as Multi-instance Verification: Effective Backbone-agnostic Transfer across Domains", "authors": "Xin Xu,Eibe Frank,Geoffrey Holmes", "background": "研究跨域少量样本学习时，遇到的问题是在实际应用案例中，对主干（即特征提取器）的微调是不可能或不切实际的。由于冻结的“黑盒”主干产生的低质量固定嵌入值，处理少量样本分类问题时需要将其表示为一系列的多个实例验证（MIV）任务。受此启发，提出了一种兼具计算效率和主干无关性的新的少样本领域适应方法——MIV-head，从而能够在不微调主干模型的情况下，有效地在测试阶段捕捉目标领域的强表示性能，具有显著的跨域迁移效果。研究使用覆盖广泛卷积神经网络和基于ImageNet1K预训练的视觉变压器等方向主流架构，与现有的部分微调（或适配）方法相比，展示了MIV-head具有竞争力的准确率和较低的迁移成本，而现有的分类头方法在准确率上却远远落后。", "innovation": "提出了一种新的少量样本领域适应方法MIV-head，该方法无需微调主干模型，利用少量可变的镜像样本数据在目标领域进行学习和优化，并在目标领域的测试数据提供强大的表现，这是一种在计算上高效且与预训练主干的特性无关的方法。通过对MIV-head的各种配置进行消融实验，结果证实了其核心组件的有效性，并通过开源代码向社区开放了模型实现。", "conclusion": "通过在不同设置下使用一个扩展的Meta-dataset基准，利用代表性卷积神经网络和基于ImageNet1K预训练的视觉变压器模型，我们证明了MIV-head在跨域少量样本图像分类中的性能与现有的部分微调方法相当，同时在迁移成本方面具有明显优势。进一步的消融实验进一步证实了所提出方法的有效性，并对其核心组成部分进行了实验评估。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00501", "html_url": "https://arxiv.org/abs/2507.00501", "title": "Laplace-Mamba: Laplace 频率先验引导的 Mamba-CNN 融合网络用于图像去雾", "title_en": "Laplace-Mamba: Laplace Frequency Prior-Guided Mamba-CNN Fusion Network for Image Dehazing", "authors": "Yongzhen Wang,Liangliang Chen,Bingwen Hu,Heng Liu,Xiao-Ping Zhang,Mingqiang Wei", "background": "近年来，图像恢复的进展突显了空间状态模型（SSMs）作为建模长程依赖的强大工具的作用，由于其吸引人的线性复杂性和计算效率。然而，基于SSM的方法在重构局部结构方面存在局限性，尤其是在处理高维数据时效率较低，经常导致细部图像特征恢复不佳。", "innovation": "提出了一种新颖的框架——Laplace-Mamba，它结合了Laplace频率先验和混合Mamba-CNN架构，以高效处理图像去雾问题。该框架利用Laplace分解将图像分解为低频分量和高频分量，通过双并行支路分别使用SSMs和CNNs进行专门处理，解决了图像去雾中的多样化挑战。Laplace变换还使低频分量的信息保留下采样根据奈奎斯特理论得以显著提高计算效率。经过多个基准测试，本文方法在恢复质量和效率方面均优于当前最先进的方法。", "conclusion": "广泛实验证明，Laplace-Mamba方法在图像恢复质量和效率方面均优于当前最先进的方法，代码和预训练模型可在指定链接下载。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00469", "html_url": "https://arxiv.org/abs/2507.00469", "title": "Bisecle: 绑定与分离在视频语言理解连续学习中的应用", "title_en": "Bisecle: Binding and Separation in Continual Learning for Video Language Understanding", "authors": "Yue Tan,Xiaoqian Hu,Hao Xue,Celso De Melo,Flora D. Salim", "background": "前沿的视觉-语言模型（VLMs）在视频理解任务上取得了显著的进步。然而，现实中的视频通常以不断进化的数据流形式存在（如穿戴设备摄像捕捉的动态场景），这要求模型能够持续适应新的数据分布和新场景。由于在新任务上微调模型的计算成本高昂，通常只会更新一小部分参数，而大部分模型保持不变。这给大规模的多模态基础模型带来了新的挑战，如灾难性遗忘和更新冲突。尽管基础模型在参数高效的连续学习方面存在困难，人类大脑的海马体进化出高效的记忆形成和巩固机制。受海马体快速绑定和模式分离机制的启发，本文提出Bisecle用于视频语言连续学习，其中多方向监督模块用于捕捉更多的跨模态关系，对比提示学习方案用于隔离任务特定的知识，以促进有效的记忆存储。绑定和分离过程进一步增强了VLMs保留复杂经验的能力，使其在视频理解任务中能够实现稳健且高效的学习。", "innovation": "1. 提出Bisecle用于视频语言连续学习，结合多方向监督模块捕捉更多跨模态关系。\n2. 设计对比提示学习方案来隔离任务特定知识，以促进有效记忆存储。\n3. 利用海马体的绑定与分离机制，增强VLMs保留复杂经验的能力，实现稳健且高效的连续学习。", "conclusion": "我们对提出的Bisecle进行了深入评估，展示了其在几个VideoQA基准上减轻遗忘并增强跨任务泛化的能力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00490", "html_url": "https://arxiv.org/abs/2507.00490", "title": "大型多模态模型中的可觉察差异", "title_en": "Just Noticeable Difference for Large Multimodal Models", "authors": "Zijian Chen,Yuan Tian,Yuze Sun,Wei Sun,Zicheng Zhang,Weisi Lin,Guangtao Zhai,Wenjun Zhang", "background": "可觉察差异（JND）是人类视觉系统能感知的最小变化，这一概念已被研究了数十年。尽管近期的工作已经将这一领域扩展到机器视觉，但缺乏系统性的研究来探讨在多种任务和刺激类型下的人类感知边界。特别是在大体量多模态模型（LMMs）迅速发展的今天，对这些模型多方面能力的研究成为了主流。然而，LMMs的感知缺陷尚未得到充分研究，这可能导致潜在的安全问题和响应效率不佳。", "innovation": "本文提出了一个新的概念——LMM-JND（大型多模态模型中的可觉察差异），并构建了一个大规模数据集VPA-JND，包含21,500个参考图像和超过489,000个刺激，涉及12种失真类型。该研究揭示了当前LMMs在基本比较查询方面的视觉盲点，并指出视觉和语言骨干之间的相关性，这可能会指导未来LMMs视觉精度的改进。", "conclusion": "我们的研究表明，LMM-JND是研究LMMs的独特视角，可预测的LMM-JND在安全问题上至关重要。这项研究指出，需要进一步关注LMM的视觉缺陷，以提高模型的安全性和效率。该研究工作可在本文链接中获取。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00472", "html_url": "https://arxiv.org/abs/2507.00472", "title": "ARIG：用于实时对话的自回归互动头生成", "title_en": "ARIG: Autoregressive Interactive Head Generation for Real-time Conversations", "authors": "Ying Guo,Xi Liu,Cheng Zhen,Pengfei Yan,Xiaoming Wei", "background": "面部交流是一种常见的人类活动，激发了互动头部生成的研究。虚拟代理可以根据自身及其他用户的音频或运动信号生成听觉和视觉响应。虽然现有的片段生成范式或显式监听/说话生成切换方法在未来的信号获取、上下文行为理解和切换平滑性方面存在局限，使得实时性和现实感难以兼得，因此急需改进的方法来解决这类问题。在本研究中，我们旨在提出一种基于自回归的帧级框架ARIG，以实现更好的交互现实性的实时生成方法。", "innovation": "我们通过将运动预测建模为非向量量化自回归过程来实现实时生成，不同于离散代码本索引预测，我们使用弥散过程表示运动分布，以在连续空间中获得更准确的预测。在理解互动行为方面，我们利用双轨双模信号，通过双向整合学习总结短程行为，并在长程上进行上下文理解。在对话状态理解方面，我们通过语音活动信号及互动行为理解（IBU）中的上下文特征来理解实际对话中存在的各种状态（打断、反馈、暂停等），这些作为最后渐进式运动预测的条件。通过广泛的实验验证了我们模型的有效性，使其在实时生成方面表现出较好的交互真实性。", "conclusion": "本文提出了一种基于自回归的帧级框架ARIG，能够以更好的交互现实性实现实时生成。通过双轨双模信号和双向整合学习，我们实现了短程行为的总结与长程上下文理解。结合语音活动信号及互动行为理解的结果，我们能够更精确地预测运动状态，从而改进交互的现实性和实时性，为未来的人机互动提供了重要的研究基础和创新方法。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00505", "html_url": "https://arxiv.org/abs/2507.00505", "title": "LLaVA-SP: 使用视觉空间标记增强视觉表示的多模态大语言模型", "title_en": "LLaVA-SP: Enhancing Visual Representation with Visual Spatial Tokens for MLLMs", "authors": "Haoran Lou,Chunxiao Fan,Ziyan Liu,Yuexin Wu,Xinxiang Wang", "background": "多模态大语言模型（MLLMs）通常通过将基于CLIP-ViT的视觉编码器连接到大型语言模型来构建。虽然CLIP-ViT擅长捕捉全局图像特征，但在建模相邻补丁之间的局部关系方面表现不佳，导致视觉表示较弱，从而影响MLLMs的详细理解能力。", "innovation": "本文提出了LLaVA-SP，它通过仅添加六种空间视觉标记到原始视觉标记中来增强视觉表示。该方法的主要创新点包括：1）提出了一种新型的投影器，该投影器使用卷积核从ViT补丁特征中推导出视觉空间标记，模拟两种视觉空间排序方法：“从中心区域到全局”和“从抽象到具体”，之后应用跨注意机制来融合精细视觉信息，丰富整体视觉表示。2）提出了两种模型变体：LLaVA-SP-Cropping通过渐进裁剪专注于细节特征，LLaVA-SP-Pooling通过自适应池化捕捉全局语义，使模型能够处理多样化的视觉理解任务。3）实验证明，通过LoRA微调的LLaVA-SP在各种多模态基准上取得了显著的性能提升，其在多个任务上的性能表现优于最先进的LLaVA-1.5模型，几乎相同推理延迟。", "conclusion": "LLaVA-SP在视觉表示增强方面表现出显著优势，具体通过改进视觉表示和模型变体设计，进一步提升了多模态大语言模型在各种任务上的性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00502", "html_url": "https://arxiv.org/abs/2507.00502", "title": "ExPaMoE：可用于持续测试时适应的可扩展并行混合专家", "title_en": "ExPaMoE: An Expandable Parallel Mixture of Experts for Continual Test-Time Adaptation", "authors": "JianChao Zhao,Songlin Dong", "background": "持续测试时适应（CTTA）旨在使模型能够在面对分布偏移的不断变化时，实时地适应流式传输的未标记数据。现有的CTTA方法通常依赖于在所有领域间共享模型参数，这使得它们在面对大规模或非平稳领域偏移时容易出现特征纠缠和灾难性遗忘。", "innovation": "我们提出了ExPaMoE，一种基于可扩展并行混合专家架构的新框架。ExPaMoE通过双分支专家设计和带有标记引导特征分离的领域通用和领域特定知识解耦，并基于实时检测频率域线索的实时领域辨别器(SODD)动态扩展专家池。通过广泛实验，证实ExPaMoE在多种CTTA场景中具有优越性。", "conclusion": "我们在标准基准测试中评估了我们的方法，包括CIFAR-10C, CIFAR-100C, ImageNet-C和Cityscapes-to-ACDC语义分割数据集。我们还介绍了一个名为ImageNet++的大型现实CTTA基准，用于更好地反映复杂领域演变下的长期适应情况。ExPaMoE在所有方面都优于先前的技术，显示出较强的稳健性、可扩展性和遗忘抗性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00519", "html_url": "https://arxiv.org/abs/2507.00519", "title": "拓扑约束学习在高效腹腔镜肝脏标志物检测中的应用", "title_en": "Topology-Constrained Learning for Efficient Laparoscopic Liver Landmark Detection", "authors": "Ruize Cui,Jiaan Zhang,Jialun Pei,Kai Wang,Pheng-Ann Heng,Jing Qin", "background": "肝脏在腹腔镜肝脏手术中是外科医生的重要解剖定位参考，有助于最小化手术风险。然而，器官的管形结构属性和术中变形给自动标志物检测带来了显著挑战。", "innovation": "提出了TopoNet，这是一种拓扑约束学习框架，结合了蛇-CNN双路径编码器以捕捉详细的RGB纹理信息和深度感知的拓扑结构，同时引入边界感知拓扑融合（BTF）模块，适应性地融合RGB-D特征，提高边缘感知同时保留全局拓扑。此外，嵌入拓扑约束损失函数，确保预测和标签之间的同伦等价性。", "conclusion": "大量实验表明，TopoNet在L3D和P2ILF数据集上实现了出色的准确性和计算复杂性，强调了其在腹腔镜肝脏手术中的临床应用潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00474", "html_url": "https://arxiv.org/abs/2507.00474", "title": "ADAptation: 基于重建的无监督主动学习方法用于乳腺超声诊断", "title_en": "ADAptation: Reconstruction-based Unsupervised Active Learning for Breast Ultrasound Diagnosis", "authors": "Yaofei Duan,Yuhao Huang,Xin Yang,Luyi Han,Xinyu Xie,Zhiyuan Zhu,Ping He,Ka-Hou Chan,Ligang Cui,Sio-Kei Im,Dong Ni,Tao Tan", "background": "深度学习诊断模型通常由于训练（源）领域和测试（目标）领域之间的分布变化而性能下降。收集和标记足够的目标领域数据进行模型重新训练是理想方案，但受限于时间和资源稀缺。虽然主动学习（AL）能有效减少标记成本同时保持性能，但在处理不同数据集间分布变化的挑战时力有不逮。因此，本文提出了一种基于解码器的无监督主动学习框架ADAptation，用于领域适应，方法在有限标注预算下从多领域数据池中高效选择有信息量的样本。首先利用解码器模型在跨数据集间通过将目标图像转化为源域风格来实现分布的一致性。然后引入了两种关键创新：（a）超球面约束对比学习网络，用于紧凑特征聚类；（b）双评分机制，用于量化和平衡样本的不确定性和代表性。实验结果显示，该方法在五个常用的深度分类器上超过了现有的强AL竞争者，验证了其在临床领域适应中的有效性和泛化能力。", "innovation": "提出的ADAptation框架结合了解码器模型进行分布同质化，同时引入了超球面约束对比学习网络和双评分机制。该方法在多个乳腺超声数据集上实验，表明其在保持性能的同时，对于有限标注预算下有效选择样本具有优势，这一框架对于临床领域的多域适应具有创新性意义。", "conclusion": "本文提出的ADAptation无监督主动学习框架在乳腺超声诊断领域的四个数据集上表现出色，即使在有限的标注预算下，也能有效提升诊断模型的性能和适应性。该方法不仅验证了其在特定应用中的有效性，也为未来临床领域的多源异构数据适应提供了新的研究思路。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00506", "html_url": "https://arxiv.org/abs/2507.00506", "title": "SCING：通过选择性跨模态提示调优迈向更高效和鲁棒的人重识别", "title_en": "SCING:Towards More Efficient and Robust Person Re-Identification through Selective Cross-modal Prompt Tuning", "authors": "Yunfei Xie,Yuxuan Cheng,Juncheng Wu,Haoyu Zhang,Yuyin Zhou,Shoudong Han", "background": "近年来，研究人员常采用复杂的适配器设计或模态特定调优来适应如CLIP等视觉-语言预训练模型以用于人体重识别(ReID)任务，但往往忽略了跨模态间的相互作用，这导致了高计算成本或对齐效果欠佳。之前的这些方法在追求性能的情况下，难以同时保持高效的推理速度和鲁棒性。", "innovation": "本文提出了一种简单而有效的框架，名为Selective Cross-modal Prompt Tuning (SCING)，旨在增强跨模态对齐性和对实际扰动的鲁棒性。该创新包括了两种关键的改进：首先是Selective Visual Prompt Fusion (SVIP)轻量级模块，它通过跨模态门机制动态地将有区别的视觉特征注入到文本提示中；其次是Perturbation-Driven Consistency Alignment (PDCA)，这是一种双重路径的训练策略，通过规整原始和增强后的跨模态嵌入一致性来在随机图像扰动下确保不变特征对齐。", "conclusion": "我们在多个流行的基准测试集上进行了广泛的实验，包括Market1501，DukeMTMC-ReID，Occluded-Duke，Occluded-REID和P-DukeMTMC，结果表明所提出的方法在保持高效的推理速度时，克服了之前模型的不足，实现了性能和计算开销的最佳权衡。本文框架在不使用大量适配器的情况下依然表现出了出色的效果，将在论文被接受后公开代码。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00537", "html_url": "https://arxiv.org/abs/2507.00537", "title": "并非所有注意力头都符合需求：使用注意力消除优化CLIP的图像表示", "title_en": "Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation", "authors": "Feng Lin,Marco Chen,Haokui Zhang,Xiaotian Yu,Guangming Lu,Rong Xiao", "background": "CLIP在多种应用中表现出稳健的性能，但某些注意力头可能会对最终表示产生负面影响。因此，可以通过消除这些不利的注意力头来提高下游任务的效果。", "innovation": "提出了一种简单且有效的方法——注意力消除技术(AAT)，通过调整注意力权重来抑制特定注意力头的贡献。AAT采用两种适应不同应用场景的策略，系统地识别和消除有害的注意力头以优化表示质量。", "conclusion": "AAT在不同领域的下游任务中能持续提升性能，特别是在CLIP家族的跨模态检索任务中，召回率提升了多达11.1%。结果表明，AAT能够几乎不增加推理成本的情况下有效优化大规模的视觉语言模型。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00493", "html_url": "https://arxiv.org/abs/2507.00493", "title": "视觉异序词揭示视觉模型在整体形状处理上的隐秘差异", "title_en": "Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing Across Vision Models", "authors": "Fenil R. Doshi,Thomas Fel,Talia Konkle,George Alvarez", "background": "人类能够基于局部纹理线索和物体部件的配置来识别物体，然而当前的视觉模型主要依赖局部纹理线索，导致其产生脆弱且不具组合性的特征。形状与纹理偏差的研究将形状和纹理表示对立起来，测度形状相对于纹理的质量，忽视了模型（和人类）可能同时依赖这两种线索的可能性，从而掩盖了这两种表示的绝对质量。目前的模型在整体形状处理上存在不足，急需一种新的方法来评估和改进它们的整体形状处理能力。因此，本文提出了一种新的评估方法——构型形状评分（CSS），以绝对构型能力为测量标准，评估模型对形状的认知能力，揭示不同视觉模型在形状处理上的差异，强调了局部纹理和整体构型形状处理的重要性。", "innovation": "本文引入了构型形状评分（CSS）方法，该方法能够在保持局部纹理的同时，通过对象-异序词对来衡量模型对不同物体类别的整体构型能力。实验结果显示，自监督和语言对齐的变压器模型在CSS评分中表现优异。进一步的机制探索发现，高CSS网络依赖于长程交互，这为优化视觉模型的整体形状处理能力提供了新的见解。此外，CSS评分还与其他依赖形状的评估指标呈正相关，表明具体形状识别精度与CSS评分之间存在一定的关联。这种新方法和发现为设计真正强大、通用且类似人类的视觉系统提供了新的思路。", "conclusion": "本文展示了视觉模型在整体形状处理能力上的广泛差异，并提出了新的CSS评分方法来评估这种能力。高CSS网络依赖弹性长程相互作用，而低CSS网络则主要关注局部特征。通过这种新的评估方法，可以更好地理解不同视觉模型的整体形状处理能力，并为进一步设计和优化视觉模型提供方向。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00554", "html_url": "https://arxiv.org/abs/2507.00554", "title": "LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail Conserved Anti-Aliasing", "title_en": "LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail Conserved Anti-Aliasing", "authors": "Zhenya Yang,Bingchen Gong,Kai Chen,Qi Dou", "background": "尽管3D高斯斑点化（3DGS）在3D场景渲染中已经取得了质量与效率方面的显著进步，但抗锯齿（anti-aliasing）伪影仍然是一个持久的挑战。现有方法主要依赖低通滤波来减轻锯齿，但这些方法对采样率不敏感，常常导致过滤不足和过度平滑的渲染效果。", "innovation": "本文提出LOD-GS，一种基于层次细节（Level-of-Detail）敏感的3D高斯斑点化滤波框架，该框架能够动态预测每个3D高斯原始的最佳过滤强度。具体而言，为每个高斯添加一组基函数，该函数将采样率作为输入来建模外观变化，从而实现对采样率的敏感过滤。这些基函数参数与3D高斯在端到端的方式中共同优化。采样率受到焦距和相机距离的影响，但现有方法和数据集仅依赖下采样模拟焦距变化，忽视了相机距离的影响。本文引入了新的合成数据集，以不同相机距离渲染对象，以更全面地评估算法效果。", "conclusion": "在公共数据集和新收集数据集上进行的广泛实验表明，本文方法在实现超高质量渲染的同时有效消除了抗锯齿伪影。代码和数据集已开源。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00525", "html_url": "https://arxiv.org/abs/2507.00525", "title": "Box-QAymo：面向自主驾驶的框引用VQA数据集", "title_en": "Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving", "authors": "Djamahl Etchegaray,Yuxia Fu,Zi Huang,Yadan Luo", "background": "可解释的交流对于自主驾驶的安全和可信赖至关重要，但现有的视觉-语言模型（VLMs）通常基于理想化的假设，在现实世界场景中难以捕捉用户意图。现有的面向驾驶的VQA数据集仅限于全场景描述或路径预测，无法评估VLMs是否能够回应局部的用户驱动查询。因此，需要一个能够评估和微调VLMs在用户指定对象上进行空间和时间推理能力的数据集和基准.", "innovation": "该论文引入了Box-QAymo，一个框引用的VQA数据集和基准，旨在评估和微调VLMs在用户指定对象上的空间和时间推理能力。用户通过绘制边界框表达意图，提供了一个快速且直观的接口以解决复杂场景中的集中查询。此外，论文还提出了一个分层评估协议，包括基本模型能力的二元核检问题、有关框引用对象的属性预测、目标实例的运动理解以及跨帧物体间动力学的空间时间运动推理。通过众包细粒度的对象类别和视觉属性，以及提取对象轨迹来构建时间基础的问答对，保证了数据集的稳健性和多样性。", "conclusion": "我们的综合评估揭示了当前VLMs在感知问题查询上的重大局限性，突出了其实现阶段性能与理想差距。本研究为基础开发更稳健和可解释的自主驾驶系统提供了基础，这些系统能够在现实条件下有效地与用户进行交流。数据集和项目页面可以在此获取：this https URL."}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00583", "html_url": "https://arxiv.org/abs/2507.00583", "title": "基于感知平直性的AI生成视频检测", "title_en": "AI-Generated Video Detection via Perceptual Straightening", "authors": "Christian Internò,Robert Geirhos,Markus Olhofer,Sunny Liu,Barbara Hammer,David Klindt", "background": "生成AI的迅速发展使得产生了高度逼真的合成视频，这对内容的真实性认证构成了重大挑战，并引发了对其滥用的担忧。现有的检测方法在泛化能力和捕捉细粒度的时间不一致性方面存在不足。", "innovation": "本文提出了一种新颖的方法ReStraV（Representation Straightening Video），用于区分自然视频和AI生成的视频。该方法灵感来源于'感知平直性'假设，即真实世界的视频轨迹在神经表示域中变得更直。通过使用预训练的自我监督视觉变换器(DINOv2)，量化了模型表示域中的时间曲率和步距距离，并对每个视频聚合这些度量的统计特征，训练分类器。实验结果表明，AI生成的视频与真实视频在曲率和距离模式上有显著不同的表现。轻量级分类器在VidProM基准测试中达到了最先进的检测性能，如97.17%的准确率和98.63%的AUROC，大大优于现有基于图像和视频的方法。ReStraV计算效率高，提供了一种低成本且有效的检测方案。", "conclusion": "这项工作为使用神经表示几何学进行AI生成视频检测提供了新的见解。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00603", "html_url": "https://arxiv.org/abs/2507.00603", "title": "World4Drive: 通过意识驱动的物理潜在世界模型实现端到端自动驾驶", "title_en": "World4Drive: End-to-End Autonomous Driving via Intention-aware Physical Latent World Model", "authors": "Yupeng Zheng,Pengxuan Yang,Zebin Xing,Qichao Zhang,Yuhang Zheng,Yinfeng Gao,Pengfei Li,Teng Zhang,Zhongpu Xia,Peng Jia,Dongbin Zhao", "background": "现有的端到端自动驾驶系统通常需要昂贵的感知监督来提取场景信息，从而自动生成规划轨迹。然而，这导致了对于构建一个能够实现无感知标注、端到端规划的自我监督学习中的关键研究挑战：构建一个信息丰富的驾驶世界模型。", "innovation": "本文提出了World4Drive，一个通过使用视觉基模型构建潜在世界模型，从而生成和评估多模态规划轨迹的端到端自动驾驶框架。它首先提取场景特征，包括驾驶意图以及通过视觉基模型提供的空间语义先验增强的世界潜在表示。然后基于当前场景特征和驾驶意图生成多模态规划轨迹，并在潜在空间中预测多个驱动意图驱动的未来状态。最后，引入了世界模型选择模块来评估和选择最佳轨迹。通过潜在空间中实际未来观测与预测观测的自我监督对齐实现无感知标注的端到端规划。", "conclusion": "World4Drive 在开放环 nuScenes 和闭环 NavSim 基准测试中均实现了最先进的性能，无需手动感知注释，取得了20.1%的相对L2误差减少、46.7%的碰撞率降低以及3.75倍的训练收敛速度提升。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00648", "html_url": "https://arxiv.org/abs/2507.00648", "title": "UMDATrack：在恶劣天气条件下统一多域自适应跟踪", "title_en": "UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions", "authors": "Siyuan Yao,Rui Zhu,Ziqi Wang,Wenqi Ren,Yanyang Yan,Xiaochun Cao", "background": "视觉对象跟踪在过去几十年中取得了显著进展。大多数现有方法集中在学习目标表示的白天良好条件下数据，而在不受限制的现实世界场景中（如夜间或雾天环境），由于巨大的领域变换，性能显著下降。因此，本文提出了UMDATrack，在统一领域的自适应框架下，能够保持在各种不良天气条件下高质量的目标状态预测。", "innovation": "首先，使用可控场景生成器在不同文本提示的指导下，合成少量（源白天数据集少于2%帧）的未标记视频，涵盖多种天气状况。其次，设计了一个简单有效的领域自适应器(DCA)，使得目标物体表示能够快速适应不同天气条件，而无需冗余的模型更新。最后，提出了一个目标感知的置信对齐模块(TCA)，该模块遵循最优运输定理，以增强源域与目标域之间的位置一致性。", "conclusion": "大量的实验证明，UMDATrack在恶劣天气条件下显著超越现有高级视觉跟踪器，取得了新的最先进的性能。我们的代码可以在以下链接获取：this https URL。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00586", "html_url": "https://arxiv.org/abs/2507.00586", "title": "Context-Aware Academic Emotion Dataset and Benchmark", "title_en": "Context-Aware Academic Emotion Dataset and Benchmark", "authors": "Luming Zhao,Jingwen Xuan,Jiamin Lou,Yonghui Yu,Wenwu Yang", "background": "学术情绪分析在评估学生在学习过程中的参与度和认知状态方面发挥着重要作用。尽管面部表情识别技术在基本情绪领域取得了显著进展，但由于缺乏公开可用的数据集，学术情绪识别仍处于探索阶段。为了填补这一空白，该论文介绍了一个名为RAER的新数据集，该数据集包含了约2700个视频片段，涵盖多种自然学习场景，如教室、图书馆、实验室和宿舍，并记录了课堂和个人学习的情况。这些视频片段由多名标注者使用多种标注水平进行了独立标注，以增强数据标注的一致性和可靠性。", "innovation": "本文提出了一个名为CLIP-CAER（基于CLIP的上下文感知学术情绪识别）的新方法，该方法利用可学习的语言提示在视觉-语言模型CLIP中集成面部表情和上下文线索。实验结果显示，CLIP-CAER在学术情绪识别方面显著优于当前最先进的基于视频的基本情绪识别方法，强调了上下文在准确识别学术情绪中的重要作用。此外，该论文还引入了第一个捕捉多样自然学习场景的数据集RAER。", "conclusion": "该研究不仅提供了一个新的数据集RAER，还提出了一种新颖的方法CLIP-CAER，显著提高了学术情绪的识别精度，并强调了上下文对准确识别学术情绪的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00570", "html_url": "https://arxiv.org/abs/2507.00570", "title": "3D应用中的离群检测：综述", "title_en": "Out-of-distribution detection in 3D applications: a review", "authors": "Zizhao Li,Xueyang Kang,Joseph West,Kourosh Khoshelham", "background": "在许多3D应用中，能够检测在训练集中不常见的物体是一项关键能力，尤其是在自主驾驶等场景中。传统的机器学习方法在对象识别时假设，在推断过程中遇到的所有对象类别都在训练数据中存在的封闭类别集中。这一假设限制了在现实世界中的泛化能力，因为未在训练期间见过的物体可能会被错误分类或者完全被忽视。为了可靠的人工智能，离群检测识别与训练分布显著偏离的输入。本文对3D应用中的离群检测进行了全面的综述，涵盖了可信和不确定人工智能的更广泛范畴。", "innovation": "本文提供了离群检测方法的比较分析，探索了模型结构、不确定性指标、分布距离分类以及不确定性校准技术。特别强调了对抗性鲁棒离群检测和故障识别，这在3D应用中尤为重要。同时，本文还指出了一些有前景的研究方向，如将3D视觉集成到离群检测中，并提供了理论和实用见解，突显了新兴的研究机会。这些见解有助于新手研究人员更有效地导航领域，促进可靠、安全和鲁棒的人工智能系统的开发。", "conclusion": "本文为离群检测领域提供了理论和实践的见解，展示了新兴的研究机会，如3D视觉的集成，并强调了对抗性鲁棒离群检测和故障识别等有前景的研究方向，为开发可靠、安全和鲁棒的人工智能系统做出了贡献。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00585", "html_url": "https://arxiv.org/abs/2507.00585", "title": "对于医学图像分割而言，只需相似记忆先验", "title_en": "Similarity Memory Prior is All You Need for Medical Image Segmentation", "authors": "Tang Hao,Guo ZhiQing,Wang LieJun,Liu Chao", "background": "近年来，研究发现猕猴初级视觉皮层（V1）中的“祖母细胞”可以直接识别具有复杂形状的视觉输入，这种发现启发了我们探索这些细胞在促进医学图像分割研究中的价值。因此，本文致力于设计一种用于医学图像分割的相似记忆先验网络（Sim-MPNet），并提出了一种动态记忆权重-损失注意力（DMW-LA），通过在原型记忆库中的相似记忆先验匹配和记忆医学图像中的特定病变或器官的类别特征，帮助网络学习类别之间的微妙纹理变化。", "innovation": "本文创新点在于提出了一种动态记忆权重-损失注意力（DMW-LA），它通过原型记忆库中的相似记忆先验匹配和记忆特定病变或器官的类别特征，帮助网络学习类别间的微妙纹理变化。此外，还提出了一种双相似度全局内部增强模块（DS-GIM），通过余弦相似度和欧几里得距离深入探讨输入数据特征分布的内部差异。实验证明，Sim-MPNet在四个公开数据集上的分割性能优于其他最先进的方法。", "conclusion": "实验结果表明，Sim-MPNet在医学图像分割性能上优于其他最先进的方法。我们已在https://github.com/dinghaoran/Sim-MPNet提供了代码。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00608", "html_url": "https://arxiv.org/abs/2507.00608", "title": "简化伪标签以提升领域自适应目标检测", "title_en": "De-Simplifying Pseudo Labels to Enhancing Domain Adaptive Object Detection", "authors": "Zehua Fu,Chenguang Liu,Yuyu Chen,Jiaqi Zhou,Qingjie Liu,Yunhong Wang", "background": "在交通和运输场景下的目标检测虽然取得了显著成果，但高质量标注数据的获取仍然需要大量时间和劳动。因此，无监督领域适应（UDA）在目标检测方面引起了越来越多的研究兴趣。目前，领域对齐方法主导了目标检测的UDA，尽管这样可以获得最佳性能，但最近自标注方法因简便和高效而受到关注。然而，自标注检测器无法在性能上与领域对齐方法相媲美，主要原因是训练过程中存在的简单标签偏差问题。为解决这个问题，作者提出了一种名为De-Simplifying Pseudo Labels（DeSimPL）的新方法，旨在减少训练中简单样本的比例，并显著提高自标注检测器的性能。", "innovation": "作者提出了一种名为De-Simplifying Pseudo Labels (DeSimPL)的方法，通过利用实例级内存库实现创新的伪标签更新策略，并在训练过程中引入对抗样本以增强复杂样本的数量。此外，还提出了一种自适应加权损失，以避免模型在后期训练中遭受过多虚假正样本伪标签带来的负面影响。", "conclusion": "实验结果表明，DeSimPL能够有效降低训练中简单样本的比例，显著提高了自标注检测器的性能。在四个基准测试上的广泛实验验证了作者的分析和结论。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00566", "html_url": "https://arxiv.org/abs/2507.00566", "title": "具有原型引导特征对齐的零样本骨架动作识别", "title_en": "Zero-shot Skeleton-based Action Recognition with Prototype-guided Feature Alignment", "authors": "Kai Zhou,Shuhai Zhang,Zeng You,Jinwu Hu,Mingkui Tan,Fei Liu", "background": "零样本骨架基于动作识别旨在对未见过的人类动作进行分类，而无需在训练过程中接触这类动作。这一任务非常具有挑战性，因为难以从已知动作扩展到未知动作。先前的研究通常采用两阶段训练：首先使用交叉熵损失对已见动作类别进行预训练，然后对提取的骨架特征和文本特征进行对齐，使骨架-文本对齐和语言模型的泛化能够向未知类别传播知识。然而，这些方法受到两个主要问题的阻碍：一是固定骨架编码器无法充分捕捉有效骨架-文本对齐所需的排列信息，导致骨架特征区分度不足；二是测试过程中参与对齐的骨架和未见文本特征之间的偏移没有被忽视，影响了对齐效果。", "innovation": "为了克服这些问题，我们提出了一个原型引导的特征对齐框架，称为PGFA。具体而言，我们开发了一个端到端的跨模态对比训练框架，以提高骨架和文本特征的对齐，保证骨架特征有足够的区分度。此外，我们引入了一种原型引导的文本特征对齐策略来缓解测试过程中分布差异对效果的负面影响。我们通过理论分析支持了这种原型引导的文本特征对齐策略，并在NTU-60, NTU-120, 和 PKU-MMD 三个众所周知的数据集上通过实证评估了我们的整体PGFA。与目前领先的SMIE方法相比，在NTU-60, NTU-120, 和 PKU-MMD 数据集上，PGFA分别实现了22.96%，12.53%，和18.54%的绝对准确性改进。", "conclusion": "我们提出了一种新的原型引导特征对齐框架（PGFA），该框架通过改善跨模态对比训练并提出原型引导的文本特征对齐策略，显著提高了骨架基于动作识别的准确性。实验结果显示，PGFA在多个知名数据集上表现优越，相较于现有最佳方法，大幅提高了准确性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00593", "html_url": "https://arxiv.org/abs/2507.00593", "title": "使用CAN总线信号在卡车上检测超车行为：机器学习方法的比较研究", "title_en": "Overtake Detection in Trucks Using CAN Bus Signals: A Comparative Study of Machine Learning Methods", "authors": "Fernando Alonso-Fernandez,Talha Hanif Butt,Prayag Tiwari", "background": "在卡车上安全地进行超车操作对于避免事故和确保交通流畅至关重要。准确预测此类操作对于高级驾驶辅助系统(ADAS)及时做出知情决策非常重要。本文研究了通过沃尔沃集团提供的五辆在用车辆的控制器局域网络(CAN)数据收集的超车检测。我们评估了几种常见的分类器，包括人工神经网络(ANN)、随机森林(RF)和支持向量机(SVM)，并分析了不同的预处理配置如何影响性能。研究发现，交通条件的变化对信号模式影响显著，尤其是在没有超车的情况下，如果训练数据缺乏足够的多样性，分类性能将受到影响。由于数据是在不受限制的实际条件下收集的，类别的多样性不能事先保证。然而，使用多辆车的数据进行训练可以提高泛化能力并减少特定条件下的偏差。我们的单车分析还显示，特别是对于超车，分类准确性依赖于每辆车的训练数据量。为了应对这一问题，我们应用了评分级别融合策略，这在大多数情况下为每辆车提供了最佳性能。总体而言，通过融合得到的真负率TNR = 93%，真阳性率TPR = 86.5%。这项研究是BIG FUN项目的一部分，该项目探索了如何将人工智能应用于车辆日志数据以理解并预测驾驶员行为，特别是在关照镜系统(CMS)作为传统外置后视镜的数字替代品的情况下。", "innovation": "本文创新地使用了从真实世界条件收集的真实数据进行超车检测研究，并评估了多种机器学习方法，特别是研究了数据多样性对分类性能的影响。提出并应用了评分级别融合策略，以提高模型的整体性能。此外，研究工作为理解和预测驾驶员行为提供了一种新的方法，特别是在引入CMS作为驾驶员辅助工具的情况下。", "conclusion": "通过使用评分级别融合策略，我们实现了TNR = 93% 和 TPR = 86.5% 的分类准确率。该研究展示了机器学习方法在处理车辆数据中的潜力，特别是在检测和预测驾驶员行为方面，并为未来的应用场景提供了新的见解。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00676", "html_url": "https://arxiv.org/abs/2507.00676", "title": "基于预训练的一体化Transformer框架用于整体人体抓取动作生成", "title_en": "A Unified Transformer-Based Framework with Pretraining For Whole Body Grasping Motion Generation", "authors": "Edward Effendy,Kuan-Wei Tseng,Rei Kawakami", "background": "该研究提出了一种基于Transformer的新框架，用于整体现有人体抓取，解决了姿态生成和运动填补问题，实现了更真实和稳定的物体交互。研究利用GRAB数据集证明了该方法在连贯性、稳定性和视觉真实感等方面优于现有的先进基准模型。此外，模块化设计还支持其他人体运动应用的轻松适应。", "innovation": "该研究引入了一种基于Transformer的数据高效预训练阶段，利用大规模和多样化的运动数据集，生成鲁棒的时空表示，可以应用于抓取任务。通过这项技术，提出了一个涵盖姿态生成、运动填补和提升转换器（LiftUp Transformer）等三个阶段的整体人体抓取框架。", "conclusion": "实验结果表明，该方法在GRAB数据集的表现优于现有的先进基准模型，在连贯性、稳定性和视觉真实感方面均有显著提升。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00690", "html_url": "https://arxiv.org/abs/2507.00690", "title": "基于支撑结构的点云转移性和不可防御性攻击", "title_en": "Cage-Based Deformation for Transferable and Undefendable Point Cloud Attack", "authors": "Keke Tang,Ziyong Du,Weilong Peng,Xiaofei Wang,Peican Zhu,Ligang Liu,Zhihong Tian", "background": "现有的点云对抗攻击方法通常对几何约束有严格要求，以保证攻击的合理性，但这种做法自身限制了对抗攻击的可转移性和不可防御性。而在变形方法方面，虽然可以作为一种替代方案，但现有的无结构方法可能会引入不自然的扭曲，导致攻击的点云显得突兀，破坏了其合理性。", "innovation": "本文提出了一种基于支撑结构的变形框架——CageAttack，该方法首先围绕目标对象构建一个支撑结构，提供一种有序的基础，确保变形的平滑和自然。通过对支撑结构的顶点应用扰动，这些扰动会无缝地传播到点云中，确保变形后仍保持合理的属性，同时提高了攻击方法的可转移性和不可防御性。在七个3D深度神经网络分类器上的广泛实验表明，CageAttack 在可转移性、不可防御性和合理性之间取得了更好的平衡，优于最先进的方法。", "conclusion": "CageAttack 在实验中表现出了在可转移性、不可防御性和合理性方面的优异平衡，相较现有的顶级方法具有显著优势。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00698", "html_url": "https://arxiv.org/abs/2507.00698", "title": "修正线性注意力中的幅度忽视", "title_en": "Rectifying Magnitude Neglect in Linear Attention", "authors": "Qihang Fan,Huaibo Huang,Yuang Ai,ran He", "background": "Softmax 注意力作为一种Transformer的核心操作，具有出色的全局建模能力，但由于其二次复杂度，限制了其在视觉任务中的应用。相比之下，线性注意力具有与Softmax相似的表示形式，但复杂度为线性，可以实现高效全局信息建模。然而，线性注意力相比于标准的Softmax注意力表现出显著的性能下降。本文基于线性注意力的公式分析了这一问题的根本原因，发现线性注意力完全忽视了查询（Query）的幅度信息，导致注意力分数分布无法根据查询的规模动态调整，因此尽管结构上与Softmax相似，线性注意力的注意力分数分布截然不同。", "innovation": "本文提出了一种名为Magnitude-Aware Linear Attention (MALA)的新方法，通过对线性注意力进行修改，使其能够充分包含查询的幅度信息。MALA能够在生成的注意力分数分布上更加接近Softmax注意力，同时展示出更加均衡的结构。该方法在图像分类、物体检测、实例分割、语义分割、自然语言处理、语音识别和图像生成等多个任务中进行了评估，并取得了优异的结果。", "conclusion": "实验结果表明，与标准的Softmax注意力相比，MALA方法在多个任务上表现出较强的效果。代码将在指定链接处提供。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00709", "html_url": "https://arxiv.org/abs/2507.00709", "title": "TopoStreamer：自主驾驶中的时间车道段拓扑推理", "title_en": "TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving", "authors": "Yiming Yang,Yueru Luo,Bingkun He,Hongbin Lin,Suzhong Fu,Chao Yan,Kun Tang,Xinrui Yan,Chao Zheng,Shuguang Cui,Zhen Li", "background": "现有的道路网络构建方法在保持一致的位置嵌入和学习多属性的时间信息方面存在限制，这影响了准确的道路网络重建。自主驾驶系统依赖于准确的道路网络来进行转向和换道等道路相关的操作。", "innovation": "提出了TopoStreamer，一种端到端的时间感知模型，用于车道段拓扑推理。特别地，TopoStreamer引入了三个关键改进：流式属性约束、动态车道边界位置编码和车道段去噪。此外，使用车道边界分类度量评估现有模型的准确性，这是自主驾驶中换道场景的一项关键措施。TopoStreamer在OpenLane-V2数据集上的表现优于最新方法，特别是在车道段感知任务中提高了3.4%的mAP和中心线感知任务中提高了2.1%的OLS。", "conclusion": "TopoStreamer通过上述改进提高了车道段拓扑推理的准确性，特别是在车道网络感知和中心线感知任务中取得了显著性能提升，展示了其在自主驾驶中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00707", "html_url": "https://arxiv.org/abs/2507.00707", "title": "BEV-VAE: 多视图图像生成中具有空间一致性的方法用于自动驾驶", "title_en": "BEV-VAE: Multi-view Image Generation with Spatial Consistency for Autonomous Driving", "authors": "Zeming Chen,Hang Zhao", "background": "目前的自动驾驶中，多视图图像生成需要在不同相机视图中保持一致的三维场景理解。大部分现有方法将此问题视为2D图像集生成任务，忽略了明确的3D建模。我们认为，在自动驾驶应用中，场景生成需要结构化的表示形式。因此，该论文提出了一种名为BEV-VAE的方法，以实现一致和可控的视图合成。BEV-VAE通过训练一个多视图图像变分自编码器来构建紧凑且统一的鸟瞰图(BEV)潜在空间，然后通过潜在扩散变换器生成场景。", "innovation": "BEV-VAE首先训练一个多视图图像变分自编码器以构建紧凑且统一的BEV潜在空间，然后通过潜在扩散变换器生成场景。该方法能够根据相机配置任意生成视图，可选地包括3D布局。实验表明，该方法在nuScenes和Argoverse 2 (AV2)数据集上对三维一致重建和生成的性能较强。", "conclusion": "实验结果表明，BEV-VAE在nuScenes和Argoverse 2 (AV2)数据集上的3D一致重建和生成性能较强。代码可在指定网址获取。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00721", "html_url": "https://arxiv.org/abs/2507.00721", "title": "UPRE: 对象检测中的统一提示和表示增强的零样本领域适应", "title_en": "UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement", "authors": "Xiao Zhang,Fei Wei,Yong Wang,Wenda Zhao,Feiyi Li,Xiangxiang Chu", "background": "零样本领域适应（ZSDA）面临着由于目标域缺乏图像而导致的重大挑战。之前的解决方案利用视觉-语言模型（VLMs）来应对这一挑战，并利用它们的零样本学习能力。然而，这些方法主要解决领域分布转移，忽略了检测任务与VLMs之间的不匹配问题，因为VLMs依赖于手动构建的提示。", "innovation": "我们提出了统一提示和表示增强（UPRE）框架，它联合优化了文本提示和视觉表示。该方法引入了一种结合语言领域先验和检测特定知识的多视图领域提示，并且包含了一个产生领域风格变化的视觉表示增强模块。此外，我们还引入了多层次增强策略，包括相对领域距离和正负分离，这些策略分别在图像级别和实例级别对多模态表示进行对齐，并捕捉多元化的视觉表示。", "conclusion": "在九个基准数据集上进行的广泛实验表明，我们的框架在ZSDA检测场景中的性能优越。代码已发布。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00659", "html_url": "https://arxiv.org/abs/2507.00659", "title": "LoD-Loc v2: 使用显式轮廓对齐实现低细节度城市模型空中视觉定位", "title_en": "LoD-Loc v2: Aerial Visual Localization over Low Level-of-Detail City Models using Explicit Silhouette Alignment", "authors": "Juelin Zhu,Shuaibang Peng,Long Wang,Hanlin Tan,Yu Liu,Maojun Zhang,Shen Yan", "background": "先前的基于线框对齐的方法LoD-Loc在低细节度(LoD)城市模型上展示了有希望的定位结果。然而，LoD-Loc主要依赖于高细节度(LoD3或LoD2)城市模型，而大部分可用的城市模型和许多国家计划构建的城市模型是低细节度(LoD1)。因此，能够对低细节度城市模型进行定位可以解锁无人机在全球城市定位中的潜力。因而，提出洛D-Loc v2，该方法采用从粗到细的方法，使用明确的轮廓对齐策略来实现低细节度城市模型中的空中精准定位。", "innovation": "LoD-Loc v2利用了粗糙到精细的方法和明确的轮廓对齐策略，在低细节度城市模型上实现了精确的空中定位。具体来说，它首先应用建筑分割网络以塑形成建筑轮廓，然后在粗略姿态选择阶段通过围绕先验姿态均匀采样姿态假设来构造姿态成本体，以表示姿态概率分布。接着，在精细姿态估计阶段使用结合多束跟踪方法的粒子滤波方法以更高效地探索假设空间并获得最终的姿态估计。此外，该研究还发布了两个包含10.7公里面积的LoD1城市模型数据集，它们附带了真实的RGB查询和姿态标注。实验结果表明，LoD-Loc v2不仅在高细节度模型上提高了估计精度，并且首次实现了对低细节度城市模型的定位，且性能超越了最先进的基线方法，甚至超过了基于纹理模型的方法，同时扩大了收敛盆地以容纳更大的先验误差。", "conclusion": "LoD-Loc v2显著提高了低细节度城市模型上的定位精度，并且首次实现了对低细节度城市模型的定位。相较于其他基准方法，它在性能上取得了显著优势，甚至优于基于纹理模型的方法。此外，发布两个高精度数据集推进了该领域的进一步研究，同时扩大了方法的适用范围。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00724", "html_url": "https://arxiv.org/abs/2507.00724", "title": "Holmes: 通过解耦通用特征实现对个性化大型视觉模型的有效且无害的模型所有权验证", "title_en": "Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features", "authors": "Linghui Zhu,Yiming Li,Haiqin Weng,Yan Liu,Tianwei Zhang,Shu-Tao Xia,Zhi Wang", "background": "大型视觉模型在各种下游任务中取得了显著的成果，主要是通过对预训练模型进行微调，以此提高模型性能，实现个性化。这种方法使得个性化模型成为其所有者的重要知识产权。然而现有的防御方法对微调模型的有效性不足，甚至可能引入新的安全风险。因此，需要一种新的方法来有效验证个性化模型的所有权，且该方法需要安全无害且能够适应微调模型的属性。", "innovation": "该论文提出了一种名为Holmes的方法，通过解耦共同特征来实现对个性化大型视觉模型的无害模型所有权验证。具体而言，该方法包括三个主要阶段：首先，创建阴影模型，保留受害者模型的通用特征同时扰乱数据集特定特征；然后，训练元分类器以识别是否存在受害者数据集的特定特征；最后，通过假设检验进行模型所有权验证，以减少随机性并提高稳健性。该方法有效地解决了针对微调模型的传统方法存在的不足之处，如增加安全风险、误判概率高等问题。", "conclusion": "通过广泛的基准数据集实验证明，该方法在同时检测不同类型的数据集盗用模型方面是有效的。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00748", "html_url": "https://arxiv.org/abs/2507.00748", "title": "通过强化学习改进MLLMs在多图像定位中的推理能力", "title_en": "Improving the Reasoning of Multi-Image Grounding in MLLMs via Reinforcement Learning", "authors": "Bob Zhang,Haoran Li,Tao Zhang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Yanbin Hao", "background": "最近，多模态大语言模型（MLLMs）在带有文本参考的单图像场景中表现出色的视觉定位能力，但在涉及复杂多图像组合和多模态指令的真实应用场景中，其推理性能下降，这暴露了它们在跨图像推理和泛化方面的局限性。", "innovation": "本文采用基于强化学习（RL）的后训练策略来提高MLLMs在多图像定位任务中的推理性能。具体而言，该方法包括：1）合成高质量的chain-of-thought（CoT）数据以进行冷启动训练；2）通过低秩适应（LoRA）进行监督微调（SFT）；3）使用合并后的SFT模型进行拒绝采样以筛选高质量的RL数据，并利用基于规则的RL引导模型找到最优推理路径。", "conclusion": "通过大量实验结果，本文方法的有效性得到了验证，在MIG-Bench上性能提高了9.04%，在几个领域外推理定位基准上分别提高了SFT基线的4.98%，在多图像感知方面，相对于基础模型在BLINK和MMIU基准数据集的子集上分别获得了3.1%和2.4%的提升。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00752", "html_url": "https://arxiv.org/abs/2507.00752", "title": "multi-modal graph convolutional network with sinusoidal encoding for robust human action segmentation", "title_en": "Multi-Modal Graph Convolutional Network with Sinusoidal Encoding for Robust Human Action Segmentation", "authors": "Hao Xing,Kai Zhe Boey,Yuankai Wu,Darius Burschka,Gordon Cheng", "background": "准确的人类动作时序分割对于智能机器人在协作环境中的应用至关重要，因为精确理解子活动标签及其时序结构是必要的。然而，人类姿态估计和物体检测中固有的噪声往往会引发过度分割的错误，打断动作序列的连贯性。", "innovation": "为了应对这一挑战，本文提出了一种多模态图卷积网络（MMGCN），该网络将低帧率（例如1帧/秒）的视觉数据与高帧率（例如30帧/秒）的动作数据（骨骼和物体检测）相结合，以减轻碎片化问题。本文介绍了三个关键技术贡献：1. 使用正弦编码策略将3D骨骼坐标映射到连续的正弦-余弦空间，以增强空间表示的鲁棒性；2. 引入时空图融合模块，通过分层次特征聚合对具有不同分辨率的多模态输入进行对齐；3. 设计SmoothLabelMix数据增强技术，通过混合输入序列和标签生成具有渐变动作过渡的合成训练示例，增强预测的时序一致性并减少过度分割的错误。", "conclusion": "在双手动作数据集中进行的广泛实验表明，本文的方法在动作分割准确性方面优于最先进方法，特别是在F1@10和F1@25项目中分别取得了94.5%和92.8%的性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00790", "html_url": "https://arxiv.org/abs/2507.00790", "title": "LD-RPS: 一种通过潜在扩散递归后验采样实现零样本统一图像恢复的方法", "title_en": "LD-RPS: Zero-Shot Unified Image Restoration via Latent Diffusion Recurrent Posterior Sampling", "authors": "Huaqiu Li,Yong Wang,Tongwen Huang,Hailang Huang,Haoqian Wang,Xiangxiang Chu", "background": "在低级视觉中，统一图像恢复是一个极具挑战性的任务。现有的方法要么针对特定任务进行定制设计，限制了它们在不同类型退化中的泛化能力，要么依赖于配对数据集的训练，从而受到闭集约束的限制。", "innovation": "我们提出了一种新颖的、无需数据集的统一方法，通过利用预训练的潜在扩散模型进行递归后验采样。该方法在任务盲条件下结合了多模态理解模型以提供生成模型的语义先验，并利用轻量级模块调整退化输入与扩散模型生成偏好的对齐，此外采用了递归精炼进行后验采样。", "conclusion": "广泛的实验表明，我们的方法在综合性能和鲁棒性上优于现有最先进的方法。我们的代码和数据将在以下链接提供：this https URL"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00754", "html_url": "https://arxiv.org/abs/2507.00754", "title": "LUViT: 使自监督ViT具备语言能力", "title_en": "Language-Unlocked ViT (LUViT): Empowering Self-Supervised Vision Transformers with LLMs", "authors": "Selim Kuzucu,Muhammad Ferjad Naeem,Anna Kukleva,Federico Tombari,Bernt Schiele", "background": "将大型语言模型（LLMs）与视觉变换器（ViTs）集成，利用LLMs丰富的语义知识和推理能力，对仅基于视觉的任务具有巨大潜力。然而，LLMs的语言中心预训练与ViTs的视觉中心训练之间的固有模态不匹配构成了根本挑战，直接融合通常不能充分利用LLMs的潜力，并导致不稳定微调。因此，LLMs部分被冻结，仅学习视觉组件。", "innovation": "引入了一种新的方法——Language-Unlocked Vision Transformers (LUViT)，它通过协同预训练策略克服了模态不匹配。具体来说，LUViT通过（1）使用Masked Auto-Encoding (MAE) 对ViT进行预训练，以获得更丰富的视觉表示；（2）同时用MAE目标训练LLM融合块中的LoRA层，实现两者协同优化。这种方法引导ViT生成LLM对齐的特征，并使LLM能够有效解释视觉信息。", "conclusion": "实验结果表明，LUViT在各种下游视觉任务上显著提高了性能，展示了利用LLM知识进行视觉理解更有效和高效的方法。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00802", "html_url": "https://arxiv.org/abs/2507.00802", "title": "TRACE：时间可靠的解剖条件增强3D CT生成与高效性", "title_en": "TRACE: Temporally Reliable Anatomically-Conditioned 3D CT Generation with Enhanced Efficiency", "authors": "Minye Shao,Xingyu Miao,Haoran Duan,Zeyu Wang,Jingkun Chen,Yawen Huang,Xian Wu,Jingjing Deng,Yang Long,Yefeng Zheng", "background": "3D医学图像生成对于数据增强和患者隐私至关重要，需要可靠的和高效的模型适用于临床实践。然而，当前的方法存在解剖精度有限、轴向长度限制以及巨大的计算成本等问题，使得这些方法无法在资源和基础设施有限的地区普及和实际应用中展开。", "innovation": "我们提出了TRACE框架，通过2D多模态条件化扩散方法生成具有时空对齐的3D医学图像。TRACE将连续的2D切片视为视频帧对，结合分割先验和放射学报告进行解剖对齐，并采用光流保持时间一致性。", "conclusion": "实验结果表明，TRACE能够在保持解剖保真度和时空一致性的同时有效地平衡计算效率。代码可在该链接获取：this https URL."}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00789", "html_url": "https://arxiv.org/abs/2507.00789", "title": "OptiPrune: 基于注意力引导噪声与动态 token 选择的提示-图像一致性提升", "title_en": "OptiPrune: Boosting Prompt-Image Consistency with Attention-Guided Noise and Dynamic Token Selection", "authors": "Ziji Lu", "background": "文本到图像的扩散模型在生成图像与文本提示之间实现精确的语义对齐时，通常会遇到效率问题，尤其是在资源受限的硬件上进行部署。现有方法要么通过噪声优化带来大量的计算开销，要么在语义保真度上做出妥协并猛烈削减token。", "innovation": "本文提出了OptiPrune，一个结合了分布感知初始噪声优化与基于相似性token裁剪的统一框架，以同时解决这两个挑战。具体而言，(1) 引入了由注意分数引导的分布感知噪声优化模块，以引导初始潜空间噪声向语义有意义的区域靠拢，缓解主体忽略和特征纠缠等问题；(2) 设计了一种高效的硬件token裁剪策略，通过块间相似性选择代表性的基础token，增加随机性以增强泛化能力，并在注意力操作前使用最大相似性复制恢复裁剪的token。该方法在噪声优化过程中保持了高斯先验，并在不牺牲对齐质量的情况下实现了高效的推理。", "conclusion": "在基准数据集（如Animal-Animal）上的实验表明，OptiPrune实现了最先进的提示-图像一致性，且计算成本显著降低。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00756", "html_url": "https://arxiv.org/abs/2507.00756", "title": "使用图卷积网络进行开放世界人体动作分割", "title_en": "Towards Open-World Human Action Segmentation Using Graph Convolutional Networks", "authors": "Hao Xing,Kai Zhe Boey,Gordon Cheng", "background": "人类与物体交互的分割是日常活动理解的基本任务，对辅助机器人、医疗保健和自主系统等领域至关重要。现有的许多基于学习的方法擅长闭集动作分割任务，但在开放集场景中，由于新兴的未知动作，它们难以泛化。由于人类活动的动态多样性，收集完整的训练动作类别不切实际，因此需要能够检测和分割未标记的动作的模型。为解决这个问题，该研究正式界定了开放世界动作分割问题，并提出了一种结构化的框架来检测和分割未见过的动作。背景说明了在现有方法难以适应开放集场景时，开发一种新型框架的重要性，以促进在未见过的动作上的分割和检测，无需人工标注。", "innovation": "提出的框架包括以下三个关键创新点：1）增强金字塔图卷积网络（EPGCN），具有新型解码器模块，用于增强时空特征上采样；2）基于Mixup的训练方法来合成未见过的分布数据，减少对人工标注的依赖；3）引入了新的时间聚类损失，用于分组已知动作的同时拉开未知样本的距离。", "conclusion": "研究在两种具有挑战性的交互式动作识别数据集（Bimanual Actions and 2 Hands and Object (H2O) datasets）上评估了框架的表现。实验结果表明，该框架在多个开放集评估指标上显著优于现有的先进动作分割模型，分别在开放集分割F1@50和未见过分检测的性能上取得了16.9%和34.6%的相对提升。此外，通过深入的消融研究评估了每个提出组件的影响，确定了开放世界动作分割的最佳框架配置。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00739", "html_url": "https://arxiv.org/abs/2507.00739", "title": "基于提升方案的Biorthogonal可调小波单元在卷积神经网络中的应用", "title_en": "Biorthogonal Tunable Wavelet Unit with Lifting Scheme in Convolutional Neural Network", "authors": "An Le,Hung Nguyen,Sungbal Seo,You-Suk Bae,Truong Nguyen", "background": "现有的卷积神经网络（CNN）中的卷积、池化和下采样操作通常使用标准的小波变换。这些操作受到正交性和滤波器长度相等的严格约束，限制了滤波器设计的灵活性。因此，需要一种新的小波单元，可以在不严格保持这些条件下提供更多的设计自由度，并在此基础上提升CNN性能，特别是在图像分类和异常检测方面.", "innovation": "提出了一种基于提升方案的新型双正交可调小波单元。该单元打破了正交性和滤波器长度相等的约束，增强了卷积、池化和下采样操作，提高了CNN在图像分类和异常检测中的性能。在ResNet-18和ResNet-34网络中验证了该方法的有效性，尤其是在CIFAR-10、DTD数据集上的分类准确率和MVTec异常检测数据集榛子类异常检测任务中的性能方面.", "conclusion": "提出的双正交可调小波单元在ResNet-18和ResNet-34中提升了图像分类性能，并在MVTec异常检测数据集榛子类的分割和检测任务中表现出较高的准确性和鲁棒性，表明该方法在捕捉细微特征方面具有有效性."}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00845", "html_url": "https://arxiv.org/abs/2507.00845", "title": "Do Echo Top Heights Improve Deep Learning Nowcasts？", "title_en": "Do Echo Top Heights Improve Deep Learning Nowcasts?", "authors": "Peter Pavlík,Marc Schleiss,Anna Bou Ezzeddine,Viera Rozinajová", "background": "短时降水预报（现在casting）对于交通运输、农业和灾害缓解等天气敏感行业至关重要。尽管最近的深度学习模型在提高降水预报技能方面显示了前景，但大多数方法仅依赖于二维雷达反射率场，而忽略了全三维雷达体积中可用的垂直信息。本文探讨了使用回波顶高度（ETH），这是一种二维投影，指示雷达反射率超过给定阈值的最大海拔，作为深度学习现在casting中的辅助输入变量的可能性。研究表明，ETH与雷达反射率之间存在相关性，有助于预测降水强度。", "innovation": "本文提出了一种分通道处理雷达反射率和ETH的单通道3D U-Net模型。该模型能够在低降雨率阈值下利用ETH提升技能，但高降雨强度时效果不一致，且模型使用ETH会导致降雨强度系统性低估。", "conclusion": "尽管ETH在某些情况下有助于现在casting，但也易误导模型并增加误差变异。本文为评估其他变量对现在casting性能的潜在贡献奠定了基础。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00817", "html_url": "https://arxiv.org/abs/2507.00817", "title": "CAVALRY-V: 大规模生成器框架在视频MLLMs中的对抗性攻击", "title_en": "CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs", "authors": "Jiaming Zhang,Rui Hu,Qing Guo,Wei Yang Bryan Lim", "background": "视频多模态大型语言模型（V-MLLMs）在时间推理和跨模态理解方面表现出色，但它们对对抗攻击的脆弱性尚未得到充分研究。这一不足主要由于其复杂的跨模态推理机制、时间依赖性和计算限制。目前，这些模型在对抗攻击方面的脆弱性仍是一个需要解决的重要问题。本文旨在通过CAVALRY-V（Cross-modal Language-Vision Adversarial Yielding for Videos）框架直接针对视频理解中视觉感知与语言生成之间的关键接口，提出对抗性攻击的新方法，以提升模型的安全性与鲁棒性，在存在的视觉和语言生成上增加攻击效果。", "innovation": "CAVALRY-V框架引入了两个关键创新：(1) 双目标语义视觉损失函数，同时破坏模型的文本生成预测和视觉表示，削弱跨模态融合；(2) 计算效率高的两阶段生成器框架，结合大规模预训练以实现跨模型的可迁移性，以及针对时空连贯性的专门微调。这种两阶段的框架设计不仅可以提高视觉理解，还能显著提升对抗攻击的效果，表明CAVALRY-V框架在视频MLLMs中对抗攻击的应用潜力。", "conclusion": "实验结果表明CAVALRY-V在多个视频理解基准测试中优于现有攻击方法，对商业系统（GPT-4.1, Gemini 2.0）和开源模型（QwenVL-2.5, InternVL-2.5, Llava-Video, Aria, MiniCPM-o-2.6）表现出显著的性能提升，达到22.8%的平均改进。尤其对于图像理解任务，平均提升达到34.4%，显示了CAVALRY-V作为多模态系统对抗研究基础框架的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00792", "html_url": "https://arxiv.org/abs/2507.00792", "title": "实现实时生成虚拟人类角色多限制运动的逆运动学", "title_en": "Real-Time Inverse Kinematics for Generating Multi-Constrained Movements of Virtual Human Characters", "authors": "Hendric Voss,Stefan Kopp", "background": "实时生成准确而逼真的虚拟人类运动对于计算机图形学、交互式虚拟环境、机器人技术和生物力学等各种应用都具有高重要性。传统的积分法、CCD算法、FABRIK算法等迭代基于的逆运动学算法在处理多个约束条件时存在误差累积和关节限制复杂的问题，难以满足逼真人类运动建模的需求。该研究旨在开发一种能够高效处理自由度高的复杂人体骨架的实时逆运动学求解器，以解决这些挑战并提高性能。", "innovation": "该研究利用TensorFlow的自动求导和即时编译技术，将正向和逆向运动学操作视为可微操作，从而有效解决了多约束问题中的误差累积和复杂的关节限制问题。这种方法能够实现对SMPLX人体骨架模型的实时处理，并在性能上优于Cyclic Coordinate Descent (CCD)、FABRIK和非线性优化算法IPOPT。研究结果表明，该逆运动学求解器能够达到实时运行，具有快速收敛、每次迭代计算开销小和更高的成功率等特点。该代码已经在GitHub上公开。", "conclusion": "本文提出的方法成功解决了多约束条件下的逆运动学问题，展示了在SMPLX人体骨架模型上优秀的实时性能。相比现有的迭代方法，该方法在收敛速度、计算开销和成功率方面均有显著提升，具有良好的应用潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00822", "html_url": "https://arxiv.org/abs/2507.00822", "title": "使用合成数据训练的CNN进行即时颗粒大小分布测量", "title_en": "Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data", "authors": "Yasser El Jarida,Youssef Iraqi,Loubna Mekouar", "background": "颗粒大小分布（PSD）测量在矿产、制药和化肥制造等行业中至关重要，极大影响产品质量和操作效率。传统PSD测量方法如筛分分析和激光衍射是手工的、耗时的，并且由于颗粒重叠的影响而受限。最近，卷积神经网络（CNN）的发展使得可以直接从颗粒图像中实现自动化和实时的PSD估算。通过这种方式，PSD参数可以被实时地测量，从而实现工业环境中的高效监测和控制。然而，原始数据质量对于保证模型的准确性和可靠性具有重要意义。", "innovation": "本文提出了一种基于CNN的方法，该方法使用Blender高级渲染能力生成的现实合成颗粒图像进行训练。这种方法通过系统地变化颗粒形状、纹理、照明和空间布局，能够模拟多种实际工业场景。通过对三种不同结构的CNN（ResNet-50、InceptionV3和EfficientNet-B0）进行评估，结果表明模型具有相似的准确度，但EfficientNet-B0在计算效率方面更为出色，适合实时工业应用。这种方法展示了使用现实的合成数据进行训练的CNN的优势，为自动工业PSD监控提供了巨大潜力。", "conclusion": "该研究展示了使用合成数据对CNN进行训练的有效性。通过这种方法训练的模型能够实时地测量颗粒大小分布，对于工业应用非常实用。此外，这种方法还可能广泛应用于其他需要颗粒图像分析的领域，从而提供更高效的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00852", "html_url": "https://arxiv.org/abs/2507.00852", "title": "无托盘条件下变光照明下的深学习方法实现灵活组件检测", "title_en": "Robust Component Detection for Flexible Manufacturing: A Deep Learning Approach to Tray-Free Object Recognition under Variable Lighting", "authors": "Fatemeh Sadat Daneshmand", "background": "工业4.0背景下，柔性制造系统需要具备在非结构化环境中抓取物体的机器人，无需严格的定位约束。目前的系统要求物体需放置在结构化的托盘中，且对光照条件敏感。本文研究背景在于开发一种计算机视觉系统，该系统能够使工业机器人在任意取向下检测并抓取笔的组件，而不需要使用结构化的托盘，并能适应不同光照条件，从而提高制造系统的灵活性和效率，减少设置时间。", "innovation": "本文提出了一种基于Mask R-CNN的方法，用于在没有托盘的复杂光照条件下对笔组件进行鲁棒检测和抓取。该方法解决了三个关键挑战：在无定位约束下的对象检测、对抗极端光照变化的鲁棒性，以及用成本效益高的摄像头实现可靠性能。通过在ZHAW的完整笔制造线上实施和评估该方法，结果显示在不同光照条件下达到了95%的检测准确性，省去了结构化组件放置的需求，将设置时间减少了30%，并且显著提高了制造灵活性。该方法通过不同光照条件下的大量验证，证明了其实用的工业应用价值。", "conclusion": "该计算机视觉系统在不同光照条件下的检测准确率达到95%，且不需要结构化的组件放置托盘，实现了显著的设置时间和制造灵活性的节省。该方法展示了在实际工业部署中的应用潜力，证明了其对提高柔性制造系统效能的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00868", "html_url": "https://arxiv.org/abs/2507.00868", "title": "视觉上下文学习能否胜任组合医疗任务？", "title_en": "Is Visual in-Context Learning for Compositional Medical Tasks within Reach?", "authors": "Simon Reiß,Zdravko Marinov,Alexander Jaus,Constantin Seibold,M. Saquib Sarfraz,Erik Rodner,Rainer Stiefelhagen", "background": "本文探讨了视觉上下文学习的潜力，以使单一模型能够处理多个任务并在测试时适应新任务，而无需重新培训。与以往的方法不同，本研究的关注点是训练能够在任务序列中适应的上下文学习者，而不仅仅是针对个别任务。在解决涉及多个中间步骤的复杂任务时，本研究旨在使用单一模型让用户能够灵活地在测试时定义整个视觉管道。", "innovation": "首先，本文研究了视觉上下文学习架构的特性和局限性，特别是代码本的角色。其次，引入了一种新的方法，通过合成组合任务生成引擎来训练上下文学习者。该引擎从任意分割数据集中启动任务序列，允许训练组合任务的视觉上下文学习者。此外，还探讨了不同的掩码训练目标，以更好地了解如何训练模型以解决复杂的组合任务。这一探索不仅提供了关于多模态医学任务序列的重要见解，还指出了需要解决的挑战。", "conclusion": "本文的探索不仅提供了关于多模态医学任务序列的重要见解，还指出了需要解决的挑战。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00898", "html_url": "https://arxiv.org/abs/2507.00898", "title": "ONLY: 一层干预充分缓解大型视觉语言模型中的幻觉", "title_en": "ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models", "authors": "Zifu Wan,Ce Zhang,Silong Yong,Martin Q. Ma,Simon Stepputtis,Louis-Philippe Morency,Deva Ramanan,Katia Sycara,Yaqi Xie", "background": "近期的大型视觉语言模型(LVLMs)通过文本响应的方式理解和推理图像输入，取得了跨多种多模态任务的显著性能。然而，这些模型在实际应用中存在幻觉问题，这会降低它们的可靠性。现有方法用对比解码来缓解这一问题，但这些方法需要多次查询，导致LVLM响应生成速度变慢，不适合实时应用。", "innovation": "我们提出了一个无需训练的解码方法ONLY，这种方法只需要一个查询并在解码过程中进行一次层干预，从而实现高效的实时部署。我们通过文本到视觉熵比率对每个词进行文本输出的增强，从而增强关键文本信息。实验结果显示，我们的方法在不同基准测试中的一致性表现优于现有的先进方法，并且实施简便、计算成本低。", "conclusion": "我们的方法ONLY有效地缓解了大型视觉语言模型中的幻觉问题，同时提供了一种高效的实时解决方案，不需要额外的训练步骤并且具有较低的计算成本。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00861", "html_url": "https://arxiv.org/abs/2507.00861", "title": "SafeMap：基于不完整观测的高精度地图构建", "title_en": "SafeMap: Robust HD Map Construction from Incomplete Observations", "authors": "Xiaoshuai Hao,Lingdong Kong,Rong Yin,Pengwei Wang,Jing Zhang,Yunfeng Diao,Shu Zhao", "background": "高精度地图对于自动驾驶至关重要，但现有方法在处理多视角相机数据不完整时效果不佳。", "innovation": "SafeMap框架通过引入基于高斯的视角视域重建模块（G-PVR）和基于蒸馏的鸟瞰图矫正模块（D-BEVC），能够确保在某些相机视角缺失的情况下也能保持精度。G-PVR根据可用视角之间的关系动态优先处理最有信息含量的区域，而D-BEVC利用全景鸟瞰图特征来纠正基于不完整观测的数据所得到的鸟瞰图表示。这些组件共同实现了端到端的地图重建和鲁棒性的高精度地图生成。SafeMap具有易于实现且可以无缝集成到现有系统中的特性，提供了一个即插即用的解决方案，提升了系统的鲁棒性。", "conclusion": "实验结果表明，SafeMap在完整和不完整场景下均显著优于之前的地图构建方法，在准确性和可靠性方面表现更优。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00825", "html_url": "https://arxiv.org/abs/2507.00825", "title": "高频频谱和几何先验对于具有挑战性的UAV图像端到端检测变换器", "title_en": "High-Frequency Semantics and Geometric Priors for End-to-End Detection Transformers in Challenging UAV Imagery", "authors": "Hongxing Peng,Lide Chen,Hui Zhu,Yan Chen", "background": "基于无人机（UAV）的物体检测（UAV-OD）面临着诸如小目标尺寸、高密度分布和复杂背景等显著挑战。现有的算法常常依赖于手工构建的组件，如锚框，这些组件需要精细调整且泛化能力有限。此外，还有非最大值抑制（NMS）步骤，这依赖于阈值，容易在密集物体检测时出错。因此，通用架构难以适应航空成像特性，从而导致性能限制。目前的端到端框架尚未有效解决这些航空特定的问题。", "innovation": "本文提出了一种专为无人机优化的全方位增强实时检测变换器框架HEGS-DETR。首先，引入了高频率增强语义网络（HFESNet）作为新的骨干，以保留关键的高频空间细节，提高对复杂背景中小目标和遮挡目标的区分能力。其次，高效小对象金字塔（ESOP）策略高效地融合了高分辨率特征图，提升了小目标检测性能。最后，提出了选择查询再激活（SQR）和几何感知位置编码（GAPE）模块来增强检测器解码器的稳定性和定位精度，有效地优化了边界框，并为密集场景提供显式的空间先验。", "conclusion": "在VisDrone数据集上的实验表明，HEGS-DETR在保持实时速度的同时，实现了基线50%准确性5.1%和基线5%准确性3.8%的提升，同时减少了4M的参数量。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00849", "html_url": "https://arxiv.org/abs/2507.00849", "title": "UAVD-Mamba: 可 deformable token 融合视觉 Mamba 的多模态无人机检测", "title_en": "UAVD-Mamba: Deformable Token Fusion Vision Mamba for Multimodal UAV Detection", "authors": "Wei Li,Jiaman Tang,Yang Li,Beihao Xia,Ligang Tan,Hongmao Qin", "background": "无人机在交通管理、农业、应急救援等领域广泛应用，但面临着遮挡、小目标尺寸、不规则形状等挑战，需要一种鲁棒且高效的多模态无人机目标检测方法。目前，Mamba 在多模态图像融合方面表现出显著潜力，因此基于此本文提出了UAVD-Mamba框架，用于基于无人机的多模态目标检测。", "innovation": "1. 提出了可变形token Mamba块（Deformable Token Mamba Block，DTMB），通过结合可变形卷积和正常卷积中的自适应补丁生成可变形token，提高几何适应性。\n2. 为RGB和红外（IR）模态分别设计了两种单独的DTMB，其输出在Mamba块中提取特征，并在融合Mamba块中进行特征融合，优化多模态特征互补性。\n3. 通过在不同尺度堆叠四个DTMB，生成多尺度特征表示，提高多尺度物体检测能力，尤其是小物体检测。\n4. DNM模块借鉴YOLO系列进行了修改，特别是对SPPF和C3K2进行了改进，以更好地处理多尺度特征，并在DTMB之前使用跨增强空间注意力，在融合Mamba块之后使用跨通道注意力，提取更具有区分性的特征.", "conclusion": "实验结果表明，本文方法在DroneVehicle数据集上的mAP指标上优于基线OAFA方法，提高了3.6%。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00950", "html_url": "https://arxiv.org/abs/2507.00950", "title": "MVP: SMP Challenge 2025 Video Track获胜解决方案", "title_en": "MVP: Winning Solution to SMP Challenge 2025 Video Track", "authors": "Liliang Ye(1),Yunyao Zhang(1),Yafeng Wu(1),Yi-Ping Phoebe Chen(2),Junqing Yu(1),Wei Yang(1),Zikai Song(1) ((1) Huazhong University of Science and Technology, Wuhan, China, (2) La Trobe University, Melbourne, Australia)", "background": "社交媒体平台是内容传播、意见表达和公众参与的核心枢纽，涵盖了多种模态。准确预测社交媒体视频的流行度可以为内容推荐、趋势检测和观众互动提供有价值的应用。因此，进行视频流行度预测对于社交媒体平台变得尤为重要。本论文介绍了一种名为Multimodal Video Predictor (MVP)的方法，该方法是作者在SMP挑战赛2025视频轨道中获得胜利的解决方案。", "innovation": "MVP通过结合预训练模型提取的深度视频特征、用户元数据和上下文信息，构建了富有表现力的视频后处理表示方法。该框架使用系统化的预处理技术，如对数变换和离群值去除，以提高模型的鲁棒性。研究团队采用梯度提升回归模型来捕捉多模态之间的复杂模式。这种方法在官方评估中排名第一，证明了其在社交媒体平台上进行多模态视频流行度预测的有效性和可靠性。", "conclusion": "本研究提出的方法MVP在SMP挑战赛2025视频轨道的官方评估中排名第一，这表明它的有效性和可靠性，适用于社交媒体平台的多模态视频流行度预测。研究还提供了源代码，供进一步的研究使用。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00886", "html_url": "https://arxiv.org/abs/2507.00886", "title": "GaussianVLM: 使用语言对齐的高斯点表示进行场景中心的3D视觉语言建模及其在自主推理中的应用", "title_en": "GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond", "authors": "Anna-Maria Halacheva,Jan-Nico Zaech,Xi Wang,Danda Pani Paudel,Luc Van Gool", "background": "随着多模态语言模型的发展，它们在三维场景理解中的应用已成为快速增长的研究前沿，推动了三维视觉语言模型（VLMs）的发展。当前方法高度依赖于物体检测器，这引入了处理瓶颈并限制了税种灵活性。", "innovation": "本文提出了一种基于场景中心的三维VLM，适用于三维高斯点表示场景，通过使用场景和任务感知的表示增强了语言感知。该方法直接将丰富的语言特征嵌入到三维场景表示中，并通过将语言与每个高斯原语关联实现早期模态对齐。此外，提出了一种双疏化器，通过任务导向和位置导向路径将其染色表示浓缩成紧凑且任务相关信息的令牌，生产出稀疏、任务感知的全局和局部场景令牌。", "conclusion": "本文介绍了首个基于高斯点表示的VLM，该模型能够从标准RGB图像中提取逼真的三维表示，具有很强的泛化能力，在非域设置下比之前的三维VLM性能高出五倍。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00969", "html_url": "https://arxiv.org/abs/2507.00969", "title": "手术神经辐射场来自单张图像", "title_en": "Surgical Neural Radiance Fields from One Image", "authors": "Alberto Neri,Maximilan Fehrentz,Veronica Penza,Leonardo S. Mattos,Nazim Haouchine", "background": "神经辐射场（NeRF）在3D重建和视图合成方面表现出卓越的能力，但由于它们依赖于大量的多视角数据限制了它们在手术室内操作环境中的应用，在这些环境中仅能获得有限的数据。特别地，由于时间限制的缘故，在手术过程中收集如此大量的数据是不实际的。本研究通过利用单张术中图像和术前数据来训练NeRF，解决了这一挑战。术前的MRI数据被用来定义设备所需的相机视角和用于稳健且无遮挡训练的图像集。通过神经风格转换技术（WTC2和STROTSS结合）使术中的外观与术前构建的训练集进行了迁移，从而能够创建用于即时和快速单图像NeRF训练的数据集", "innovation": "本研究首次利用单张术中图像和术前数据来训练NeRF，特别采用了术前MRI数据定义相机视角和图像集，并通过WTC2和STROTSS结合的方法将术中图像的外观迁移到术前构建的训练集中，实现了单图像NeRF的快速训练，解决了传统多视角方法在手术情境中的限制问题", "conclusion": "我们的方法证明了在手术环境中单图像NeRF训练的可行性，克服了传统多视角方法的局限，通过与使用实际手术显微镜图像训练的NeRF模型进行定量比较显示了强大的合成一致性，相似度指标显示了高度的重建保真度和风格对齐。我们的方法与真实数据的结构性相似度验证了重建质量和纹理保真度的良好表现"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00981", "html_url": "https://arxiv.org/abs/2507.00981", "title": "使用程序化场景扰动评估单目深度估计的鲁棒性", "title_en": "Evaluating Robustness of Monocular Depth Estimation with Procedural Scene Perturbations", "authors": "Jack Nugent,Siyang Wu,Zeyu Ma,Beining Han,Meenal Parakh,Abhishek Joshi,Lingjie Mei,Alexander Raistrick,Xinyuan Li,Jia Deng", "background": "近年来，单目深度估计取得了显著进展，特别是在基准测试标准上的表现优异的大模型的成功。然而，标准基准测试并不能完全评估模型的表现，因为大多数基准主要评估准确度，而不是鲁棒性。本研究引入了一个新的基准——PDE（Procedural Depth Evaluation），用于系统地评估模型的鲁棒性，通过程序生成创建3D场景，测试模型对多种可控扰动的鲁棒性，包括对象、相机、材料和光照的变化。", "innovation": "提出了一个新的评估基准PDE（Procedural Depth Evaluation），该基准利用程序生成技术创建3D场景，用于评估模型对多种扰动的鲁棒性，包括对象、相机、材料和光照的变化，从而弥补了传统评估方法的不足，提供了更全面的模型评估方式。", "conclusion": "通过分析PDE的结果，研究揭示了一些对于最先进深度模型具有挑战性的扰动，期望这些发现能指导未来的研究。此外，研究结果和数据可在以下网址获得：this https URL。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00980", "html_url": "https://arxiv.org/abs/2507.00980", "title": "RTMap：实时递归制图与变化检测定位", "title_en": "RTMap: Real-Time Recursive Mapping with Change Detection and Localization", "authors": "Yuheng Du,Sheng Yang,Lingxuan Wang,Zhenghua Hou,Chengying Cai,Zhitao Tan,Mingxia Chen,Shi-Sheng Huang,Qiang Li", "background": "尽管最近的在线高清地图方法减轻了离线管道的负担并解决了地图新鲜度问题，它们仍然受到感知不准确、交通密集区域遮挡以及无法融合多智能体观察的限制。", "innovation": "提出了RTMap来通过持续众包多遍历的高清地图作为自我进化的记忆来增强这些单遍历方法。RTMap同时在端到端的方式上解决了三种核心挑战：(1) 对高清地图元素的不确定性感知位置建模，(2) 与众包先验地图的概率感知定位，以及 (3) 实时检测可能的道路结构变化。", "conclusion": "在几个公开的自动驾驶数据集上的实验展示了我们的性能对于先验地图质量和定位精度的坚实表现，同时展示了我们的方法在逐步提升众包先验地图的准确性和新鲜性方面具有稳健的服务下游预测和规划模块的效果。我们将会公开我们的源代码，详细版会在稍后更新。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00916", "html_url": "https://arxiv.org/abs/2507.00916", "title": "Masked training enhances discriminative models for image-to-3D reconstruction", "title_en": "Masks make discriminative models great again!", "authors": "Tianshi Cao,Marie-Julie Rakotosaona,Ben Poole,Federico Tombari,Michael Niemeyer", "background": "本文介绍了Image2GS，这是一种针对从单张照片重建逼真的3D场景的挑战性问题的新颖方法。特别关注重建过程中的图像到3D提升问题。通过将转换问题（将图像转换为表示可见内容的3D模型）与完成问题（生成输入中不存在的内容）分离，我们创建了一个更加确定的任务，适合判别模型。这种方法使用从优化3D高斯点生成的可见性掩码，在训练中排除了从源视图不可见的区域，这使得我们在可见区域的重建质量显著提高，优于强基线模型。尽管仅在被遮罩区域进行训练，但Image2GS在完整场景上的评估也与在全目标图像上进行训练的最先进的判别模型保持竞争力。", "innovation": "本文提出了一个名为Image2GS的新颖方法，通过分离图像到3D重建中的提升问题和完成问题，设计了一种使用从优化高斯点生成的可见性掩码进行训练的新策略。这种方法显著提高了可见区域的重建质量，并且即使仅在被遮罩区域进行训练，其性能也与在完整图像上进行训练的最先进的判别模型相当。这项工作展示了解决图像到3D提升问题的方法可以显著改善模型性能，尤其是对于无法看到的区域的建模问题具有独特优势。", "conclusion": "本文的研究结果强调了判别模型在适应未见过的区域时面临的根本挑战，并展示了将图像到3D提升作为不同问题处理并使用特定技术解决的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00008", "html_url": "https://arxiv.org/abs/2507.00008", "title": "DiMo-GUI：通过模态感知视觉推理推进GUI定位的测试时扩展", "title_en": "DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning", "authors": "Hang Wu,Hongkai Chen,Yujun Cai,Chang Liu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang", "background": "GUI中的自然语言查询定位因其视觉元素的多样性、空间拥挤以及语言的模糊性而面临独特挑战。现有方法通常将GUI视为单一整体图像进行处理，导致在处理复杂布局时容易出现理解和定位的不确定性。", "innovation": "提出了DiMo-GUI，一种无需训练的GUI定位框架，利用动态视觉定位和模态感知优化两大核心策略。该方法将输入分为文本元素和图标元素，利用通用视觉-语言模型独立处理每种模态，当预测不准确时，通过生成焦点区域并递进细化来动态聚焦注意力，从而在不需要额外训练或注释的情况下解决视觉拥挤布局的歧义性问题，显著提升了定位准确性与效率。", "conclusion": "我们在标准GUI定位基准上评估了DiMo-GUI，结果显示该方法在模糊性处理与准确性上均优于基线推理管道，验证了将模态分离与区域聚焦推理结合的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01009", "html_url": "https://arxiv.org/abs/2507.01009", "title": "ShapeEmbed：一种用于二维轮廓量化的人工监督学习框架", "title_en": "ShapeEmbed: a self-supervised learning framework for 2D contour quantification", "authors": "Anna Foix Romero,Craig Russell,Alexander Krull,Virginie Uhlmann", "background": "物体形状是各种应用中视觉信息的重要来源之一。形状量化的一个核心挑战是确保提取的度量在保持对象内在几何不变性的变换中保持不变，例如改变其大小、方向和在图像中的位置。本文旨在解决这一挑战，并提出了一种名为ShapeEmbed的新方法，这是一种自监督的表示学习框架，用于将二维图像中对象的边界表示为欧几里得距离矩阵，并生成一个在平移、缩放、旋转、镜像和点索引方面不变的形状描述符。这种方法克服了传统形状描述符的局限性，并且在现有基于自动编码器的最佳方法上有所改进。我们的框架在自然和生物图像中的形状分类任务中表现出色。这种方法特别适用于生物成像应用领域。", "innovation": "引入了ShapeEmbed，这是一种自监督的表示学习框架，用于将二维图像中对象的轮廓表示为欧几里得距离矩阵，并生成一个在平移、缩放、旋转、镜像和点索引方面不变的形状描述符。这种方法克服了传统形状描述符的局限性，并且在现有基于自动编码器的最佳方法上有所改进。", "conclusion": "我们的框架在自然和生物图像中的形状分类任务中表现出色。我们预计这种方法对于生物成像应用特别相关。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00016", "html_url": "https://arxiv.org/abs/2507.00016", "title": "通过预训练模型正则化实现基于梯度的微调", "title_en": "Gradient-based Fine-Tuning through Pre-trained Model Regularization", "authors": "Xuanbo Liu,Liu Liu,Fuxiang Wu,Fusheng Hao,Xianglong Liu", "background": "大规模预训练模型已在多个领域展现出广泛的应用，但这些模型在特定下游任务上的细调需要巨大的计算资源和存储空间。一种基于梯度的参数选择（GPS）方法虽然可以减少需要训练的参数数量，但也增加了计算资源需求和存储需求。", "innovation": "本文提出了一种基于梯度和正则化的细调方法（GRFT），该方法通过对权重矩阵的行或列进行更新来实现高效细调。理论证明了具有最高平方梯度总和的行或列是最优更新对象。此外，该方法还加入了正则化，以增强从预训练模型的知识迁移，GRFT 在 FGVC 和 VTAB 数据集上的参数更新量仅为 1.22% 和 0.30%，超越了现有方法 GPS、Adapter Tuning 和 LoRA。", "conclusion": "GRFT 实现了最先进的性能，并且其效率和效果非常高，只需要更新极小的参数数量。源代码将会很快发布。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00992", "html_url": "https://arxiv.org/abs/2507.00992", "title": "UniGlyph: 统一的分割条件化扩散模型用于精确的视觉文本合成", "title_en": "UniGlyph: Unified Segmentation-Conditioned Diffusion for Precise Visual Text Synthesis", "authors": "Yuanrui Wang,Cong Han,YafeiLi,Zhipeng Jin,Xiawei Li,SiNan Du,Wen Tao,Yi Yang,shuanglong li,Chun Yuan,Liu Lin", "background": "文本到图像生成技术极大地促进了内容创作的发展，但准确渲染视觉文本仍是一个关键挑战，原因包括模糊的字符、语义漂移和有限的风格控制。现有方法通常依赖预先渲染的字符图像作为条件输入，但这限制了原字体样式和颜色线索的保留，导致复杂的多分支设计，增加了模型的开销并减少了灵活性。", "innovation": "本文提出了一种基于分割的框架，该框架使用包含字符形状、颜色和空间细节的像素级视觉文本掩码作为统一的条件输入。该方法引入了两个核心组件：(1) 一种精调的双语分割模型，用于精确的文本掩码提取；(2) 增强了适应字符条件和区域特定损失的简洁扩散模型，以在内容和风格方面保持文本保真度。该方法在 AnyText 基准测试中达到最先进的性能，特别在中文和英文情景下显著优于先前的方法。为了进行更严格的评估，还引入了两个新的基准：基于复杂排版中布局和字符一致性的 GlyphMM 基准，以及基于小规模文本区域生成质量的 MiniText 基准。实验结果表明，该模型在两项场景中均大幅优于现有方法，尤其在小文本渲染和复杂布局保留方面表现出色。", "conclusion": "在 任何文本 (AnyText) 的基准测试中，本文的方法达到了最先进的性能，显著超越了先前的方法，特别是在中文和英文情景下。通过引入 GlyphMM 和 MiniText 基准，提供了更严格的评估。实验结果表明，模型在小文本渲染和复杂布局保留方面表现出色，证明了其强大的泛化能力和部署准备度。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01012", "html_url": "https://arxiv.org/abs/2507.01012", "title": "DAM-VSR: 解离外观与运动的视频超分辨", "title_en": "DAM-VSR: Disentanglement of Appearance and Motion for Video Super-Resolution", "authors": "Zhe Kong,Le Li,Yong Zhang,Feng Gao,Shaoshu Yang,Tao Wang,Kaihao Zhang,Zhuoliang Kang,Xiaoming Wei,Guanying Chen,Wenhan Luo", "background": "现实世界的视频超分辨（VSR）面临着复杂且难以预测的退化挑战。尽管一些最新的方法利用了图像扩散模型进行VSR，并展示了改进的细节生成能力，但它们仍然难以产生时间上一致的帧。由于SVD（Stable Video Diffusion）的内生图像动画特性，仅使用低质量视频生成精细细节具有挑战性。为了应对这一问题，我们提出了DAM-VSR（Disentanglement of Appearance and Motion for VSR）框架，这是一种将VSR分解为外观增强和运动控制问题的分离框架。专门通过参考图像超分辨实现外观增强，通过视频ControlNet实现运动控制。这种分离充分利用了视频扩散模型的生成先验和图像超分辨模型的细节生成能力。", "innovation": "该研究提出了DAM-VSR框架，该框架将VSR分解为外观增强和运动控制两个问题，并使用参考图像超分辨和视频ControlNet分别实现这些目标。此外，DAM-VSR还采用了所提出的运动对齐双向采样策略，使其能够处理更长输入视频的VSR。该方法在现实世界数据和AIGC数据上取得了最先进的性能，展示了强大的细节生成能力。", "conclusion": "DAM-VSR在现实世界数据和AIGC数据上取得了最先进的性能，证明了其强大的细节生成能力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00028", "html_url": "https://arxiv.org/abs/2507.00028", "title": "HiT-JEPA:一种用于相似性计算的分层自监督轨迹嵌入框架", "title_en": "HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation", "authors": "Lihuan Li,Hao Xue,Shuang Ao,Yang Song,Flora Salim", "background": "城市轨迹数据的表示在有效分析空间移动模式方面起着关键作用。尽管取得了相当大的进展，但在设计能够捕捉多样性和互补信息的轨迹表示方法方面仍然存在研究问题。现有方法难以在单一模型中同时整合轨迹的细粒度细节和高层次的总结，这限制了它们同时关注长期依赖关系和保留局部细微差别的能力。", "innovation": "本文提出了一种名为HiT-JEPA（Hierarchical Interactions of Trajectory Semantics via a Joint Embedding Predictive Architecture）的统一框架，用于跨语义抽象级别学习多尺度城市轨迹表示。该框架采用三层分层结构，逐级捕捉点级细粒度细节、中间模式和高层次轨迹抽象，使模型能够在一个统一结构中整合局部动态和全局语义。实验结果显示，HiT-JEPA的分层设计产生了更丰富、多尺度的表示。", "conclusion": "通过广泛的实验，在多个真实世界轨迹数据集中进行轨迹相似性计算，表明HiT-JEPA的分层设计产生了更丰富的多尺度表示。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking：利用可扩展强化学习实现多功能多模态推理", "title_en": "GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Leyi Pan,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianle Gong,Wenkai Li,Wei Jia,Xin Lyu,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuxuan Zhang,Zhanxiao Du,Zhenyu Hou,Zhao Xue,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "论文介绍了GLM-4.1V-Thinking，一种旨在推进通用多模态推理的视觉语言模型（VLM）。通过大规模预训练构建了一个具备显著潜力的视觉基础模型，并结合强化学习中的课程采样（RLCS）方法，提升了模型在多种任务上的综合能力，包括STEM问题解决、视频理解、内容识别、编程、定位、基于GUI的代理和长文档理解等。该模型在28个公开基准测试中表现出色，特别是在长文档理解和STEM推理等挑战性任务上，与开源或闭源的GPT-4o等大模型相当或更优。", "innovation": "论文提出了一种新的视觉语言模型GLM-4.1V-Thinking，通过大规模预训练建立了一个具有显著潜力的视觉基础模型，并结合强化学习中的课程采样（RLCS）方法，实现了在多模态推理方面的能力提升，特别是在STEM问题解决、视频理解、内容识别、编程等多个领域，提升了模型的全面能力。同时，该论文开放了GLM-4.1V-9B-Thinking模型，并在28个公共基准测试中展示了其卓越的性能。", "conclusion": "论文在多功能多模态推理方面取得显著进展，通过开源模型GLM-4.1V-9B-Thinking在28个公共基准测试中显示了优越的性能，特别是在长文档理解和STEM推理等复杂任务上，其表现甚至优于开源或闭源的大模型GPT-4o，进一步证实了其强大的能力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00185", "html_url": "https://arxiv.org/abs/2507.00185", "title": "Multimodal, Multi-Disease Medical Imaging Foundation Model (MerMED-FM),", "title_en": "Multimodal, Multi-Disease Medical Imaging Foundation Model (MerMED-FM)", "authors": "Yang Zhou,Chrystie Wan Ning Quek,Jun Zhou,Yan Wang,Yang Bai,Yuhe Ke,Jie Yao,Laura Gutierrez,Zhen Ling Teo,Darren Shu Jeng Ting,Brian T. Soetikno,Christopher S. Nielsen,Tobias Elze,Zengxiang Li,Linh Le Dinh,Lionel Tim-Ee Cheng,Tran Nguyen Tuan Anh,Chee Leong Cheng,Tien Yin Wong,Nan Liu,Iain Beehuat Tan,Tony Kiat Hon Lim,Rick Siow Mong Goh,Yong Liu,Daniel Shu Wei Ting", "background": "当前的医学图像的人工智能模型主要是一模多病或多模一病。尽管试图创建多模态和多疾病的模型，但临床准确性并不一致。此外，训练这些模型通常需要大量的、劳动密集型和高度标记的数据集。", "innovation": "我们开发了MerMED-FM，这是一个最先进的多模态、多专科基础模型，通过自我监督学习和记忆模块进行训练。MerMED-FM采用了跨多个专科和模态的330万医学影像数据进行训练，包括CT、胸部X光、超声、病理切片、彩色眼底摄影、光学相干断层扫描和皮肤影像。", "conclusion": "MerMED-FM在多种疾病上的表现强劲，并且具有高度适应性、多功能性和学科间的交叉能力，能够在多种医学领域中实现稳健的医学影像解释。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00051", "html_url": "https://arxiv.org/abs/2507.00051", "title": "使用双网络在影像导向介入手术中实现实时导丝尖端跟踪", "title_en": "Real-Time Guidewire Tip Tracking Using a Siamese Network for Image-Guided Endovascular Procedures", "authors": "Tianliang Yao,Zhiqiang Pei,Yong Li,Yixuan Yuan,Peng Qi", "background": "人工智能解决方案在临床实践中的不断融入提高了医疗服务的效率与效果。本文专注于心血管疾病图像引导治疗中的导丝尖端跟踪任务，以提高医生的诊断和治疗质量。实验在15个临床数字减影血管造影（DSA）序列中随机选取3个进行验证，覆盖多种介入场景，以验证该方法的有效性与可靠性能。结果表明该方法在实时性、准确性和处理速度上均表现良好，满足临床需求。", "innovation": "提出了一种基于双网络且带有双重注意机制的新颖跟踪框架，结合自我注意和跨注意策略，提升了空间-时间特征学习能力，处理视觉模糊、组织变形和影像伪影等问题。实验证明，该方法能实现精确的导丝尖端跟踪，且具有较强的鲁棒性。进一步的机器人平台验证表明，该框架适用于自动化诊断和治疗过程，具有广泛的应用前景。", "conclusion": "验证结果显示，该跟踪框架具备0.421 ± 0.138 mm的平均定位误差，最大误差为1.736 mm，平均交并比（IoU）达到0.782。该框架还保持了每秒57.2帧的平均处理速度，满足介入影像的实时需求。此外，在机器人平台上的验证显示了进一步的可靠性，提升了自动化诊断和治疗的质量，表明该研究具有实际应用价值。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00416", "html_url": "https://arxiv.org/abs/2507.00416", "title": "Evo-0: 具备隐式空间理解的视觉-语言-行动模型", "title_en": "Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding", "authors": "Tao Lin,Gen Li,Yilei Zhong,Yanwen Zou,Bo Zhao", "background": "视觉-语言-行动（VLA）模型已经成为一种有潜力的框架，使机器人能够在现实世界中感知、推理和行动。这些模型通常基于预训练的视觉-语言模型（VLMs），由于大规模文本预训练，它们在语义理解方面表现出色。然而，VLMs通常缺乏精确的空间理解能力，因为它们主要是在无3D监督的2D图像-文本配对上进行调优。为了弥补这一局限性，最近的方法引入了显式的3D输入，如点云或深度图，但这种方法需要额外的深度传感器或估计缺陷。相比之下，我们提出了一个即插即用模块，通过利用现成的视觉几何基础模型隐式地将3D几何特征注入VLA模型。我们设计了五个需要精确的空间理解能力的任务，以验证我们方法的有效性。广泛评估表明，我们的方法显著提高了最先进的VLA模型在各种场景下的性能。", "innovation": "我们提出了一个即插即用模块，通过利用现成的视觉几何基础模型隐式地将3D几何特征注入VLA模型，以增强其空间理解能力，并设计了五个需要精确的空间理解能力的任务来验证这种方法的有效性。", "conclusion": "我们的方法显著提高了最先进VLA模型在各种场景下的性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00209", "html_url": "https://arxiv.org/abs/2507.00209", "title": "SurgiSR4K: 一种用于机器人辅助微创手术的高分辨率内窥镜视频数据集", "title_en": "SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures", "authors": "Fengyi Jiang,Xiaorui Zhang,Lingbo Jin,Ruixing Liang,Yuxin Chen,Adi Chola Venkatesh,Jason Culman,Tiantian Wu,Lirong Shao,Wenqing Sun,Cong Gao,Hallie McNamara,Jingpei Lu,Omid Mohareri", "background": "高分辨率成像在微创手术（MIS）中至关重要，可以提高视觉清晰度并提供精准的计算机辅助指导。尽管4K内窥镜系统已逐渐普及，但专门针对机器人辅助MIS的公开可用的原生4K数据集仍然缺乏。SurgiSR4K填补了这一空白，提供了一个原生4K分辨率的手术成像和视频数据集，以反映实际的机器人辅助手术条件。该数据集包含多种视觉场景，如镜面反射、器械遮挡、出血和软组织变形，旨在反映腹腔镜和机器人手术中常见的挑战。", "innovation": "SurgiSR4K是首个公开可用的原生4K分辨率手术影像和视频数据集，涵盖了多种视觉挑战，旨在为多种计算机视觉任务提供高分辨率数据支持，包括超分辨率（SR）、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新颖视图合成以及视觉语言模型（VLM）的研发提供了坚实的数据基础。", "conclusion": "SurgiSR4K为高分辨率手术影像研究的发展提供了稳固的基础，并促进了旨在提升图像引导机器人手术性能、安全性和易用性的智能影像技术的发展。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00320", "html_url": "https://arxiv.org/abs/2507.00320", "title": "探索情感体验的大脑基础中的理论偏差观察", "title_en": "Exploring Theory-Laden Observations in the Brain Basis of Emotional Experience", "authors": "Christiana Westlin,Ashutosh Singh,Deniz Erdogmus,Georgios Stratis,Lisa Feldman Barrett", "background": "在情感科学中，人们普遍认为传统的民间情感类别形成了一种生物和心理类型，并且研究通常被设计和分析以识别特定情感的模式。这种方法塑造了研究结果的观察，最终强化了研究之初的假设。本文重新分析了一项由这种类型指导的研究数据，该研究报道了个别人脑模式与34种情感类别平均评级之间的映射关系。", "innovation": "本研究通过重新分析数据，提出了重新审视情感分类的新观点，即将情感类别视为具有变量和情景化实例的人群。研究利用最少的假设去分析数据中的方差结构。结果显示，与原研究不同，研究人员未能观察到原始映射，并观察到个人间存在显著变异。这项研究证明了初始假设如何最终影响科学结论，并指出在一项假设被多方法验证之前不应过于严肃地接受其结论。", "conclusion": "本研究强调了初始假设对科学研究结论的影响，并建议在一个假设通过多种分析方法支持之前不应被认真对待。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00190", "html_url": "https://arxiv.org/abs/2507.00190", "title": "从物理世界重思3D目标检测", "title_en": "Rethink 3D Object Detection from Physical World", "authors": "Satoshi Tanaka,Koji Minoda,Fumiya Watanabe,Takamasa Horibe", "background": "高精度和低延迟的3D目标检测对于自动驾驶系统至关重要。现有研究表明，虽然基于mean average precision (mAP) 和延迟评估性能很常见，但这些研究往往忽视了速度与精度之间的权衡关系。它们未充分考察不同硬件设备和加速器之间的权衡，尤其是在实时应用至关重要的情况下。此外，这些研究忽略了运动规划中的碰撞规避问题，不同的mAP值可能导致不同的安全规划状态。", "innovation": "本文引入了新的评估指标——延迟感知平均精度（L-AP）和规划感知平均精度（P-AP），以提高实时3D目标检测的全面评估。通过nuPlan数据集，证明了该新指标的有效性，并优化了硬件差异和加速器的3D目标检测模型。同时，通过延迟感知超参数优化（L-HPO），开发了实时3D目标检测的最新性能模型。此外，通过使用新指标，证明了“点云越多，识别性能越好”这一假设在实时应用中是不正确的，并对硬件和模型选择进行了优化。", "conclusion": "通过引入L-AP和P-AP，本文为全面评估实时3D目标检测提供了新的视角，并通过nuPlan数据集和具体应用展示了新指标的有效性和应用前景。同时，证明了新指标可以用于优化硬件和模型选择，适应实时应用的需求。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00435", "html_url": "https://arxiv.org/abs/2507.00435", "title": "RoboEval：机器人操作与结构化可扩展评估的交汇", "title_en": "RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation", "authors": "Yi Ru Wang,Carter Ung,Grant Tannert,Jiafei Duan,Josephine Li,Amy Le,Rishabh Oswal,Markus Grotz,Wilbert Pumacay,Yuquan Deng,Ranjay Krishna,Dieter Fox,Siddhartha Srinivasa", "background": "现有的双臂操作策略评价基准仅报告二元任务成功率，这种评分方式往往隐藏了策略行为中的关键缺陷，例如协调能力差、抓取时滑动、双臂使用不均匀等问题。RoboEval 提出了一种新的评价框架，旨在揭示当前双臂操作策略的限制。", "innovation": "RoboEval 引入了一套分层、语义化任务的评估工具，这些任务被分解为技能特定的阶段，并通过系统性地挑战空间、物理和协调能力来对策略进行评价。RoboEval 与精细粒度的诊断指标和 3000 多个人类演示配合使用，支持模仿学习。实验结果显示，虽然具有相似成功率的策略在执行任务时存在差异，例如一些策略在对齐方面出现问题，而另一些则在时间上一致的双臂控制方面遇到困难，但行为指标与任务指标的相关性在一半以上的情况下仍然表现良好，即使二元成功率饱和，仍然具有信息价值。RoboEval 通过识别策略何时以及如何失败，推动了对机器人操作更深层次的理解，并强调超越单纯成功评价工具的需求.", "conclusion": "RoboEval 能够提供更深入、更具体的操作理解，帮助识别策略疲软环节，强调了对策略行为进行评价的工具需要超越简单成功率的观点。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00041", "html_url": "https://arxiv.org/abs/2507.00041", "title": "TalentMine: 基于LLM的多模态人才表格提取和问答", "title_en": "TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables", "authors": "Varun Mannam,Fang Wang,Chaochun Liu,Xin Chen", "background": "在人才管理系统中，关键信息常以复杂的表格形式存在，这给传统的语言模型带来了显著的信息检索挑战。尤其是在处理需要精确解读表格关系的人才文档时，这些挑战更为突出。现有的表格提取方法在语义理解方面存在缺陷，导致在检索增强聊天应用中集成时性能不佳。当前的瓶颈在于，虽然可以提取结构化的表格信息，但表格元素间的语义关系被丢失，从而导致下游查询失败。因此，该研究旨在解决这一问题，通过引入TalentMine框架，利用LLM增强的方法将提取的表格转换为语义丰富的新表示形式，以保留表格中的结构和语义维度。", "innovation": "TalentMine是一个新颖的LLM增强框架，它可以将提取的表格转换为语义丰富的表示形式，与传统的依赖于CSV或文本线性化的方法不同，该方法利用专门的多模态推理来保留表格数据的结构化和语义维度。实验结果表明，TalentMine在查询响应任务中的准确率达到100%，而标准AWS Textract提取和AWS Textract视觉问答功能的准确率分别为0%和40%。我们还发现，Claude v3 Haiku模型对于人才管理应用是最优的选择。该研究的关键贡献包括：(1) 对现有的表格提取管道中语义信息丢失的系统性分析；(2) 提出了一种基于LLM的方法来实现语义丰富的表格表示；(3) 一种高效的集成框架，将检索增强系统作为端到端系统进行集成；(4) 在人才数据分析任务上的全面基准测试，显示了在多个类别中的显著改进。", "conclusion": "通过引入TalentMine框架，解决了表格提取过程中语义关系丢失的问题，有效地提升了检索增强系统在人才管理中的性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00206", "html_url": "https://arxiv.org/abs/2507.00206", "title": "针对医学成像的3D语义图像合成", "title_en": "Towards 3D Semantic Image Synthesis for Medical Imaging", "authors": "Wenwu Tang,Khaled Seyam,Bin Yang", "background": "在医学领域，获取大型数据集极具挑战性，这既源于数据获取的障碍，也源于严格的隐私保护法规。因此，数据可用性和隐私保护成为在医学影像应用中应用机器学习的主要障碍。现有的许多方法只关注生成2D切片，而忽视了全容积数据的需求。Med-LSDM模型在此背景下应运而生，它直接在3D领域操作，并利用脱敏的语义图生成合成数据，以作为隐私保护和数据增强的方法。", "innovation": "Med-LSDM模型引入了一个指导机制，通过在预训练的VQ-GAN的潜在空间内应用扩散模型来控制3D图像的生成过程。通过在压缩的潜在空间中操作，该模型显著降低了计算复杂度，同时仍然保留了重要的3D空间细节。该模型在3D语义医学图像合成方面表现出色，尤其在全容积数据应用方面具有优势。", "conclusion": "在条件Duke乳腺数据集上，Med-LSDM模型的3D-FID得分为0.0054，Dice得分为0.70964，接近真实的图像（Dice为0.71496）。这些结果表明，模型生成的合成数据与真实数据之间的领域差距很小，可用于数据增强。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00476", "html_url": "https://arxiv.org/abs/2507.00476", "title": "FreNBRDF：一种频域修正的神经材质表示", "title_en": "FreNBRDF: A Frequency-Rectified Neural Material Representation", "authors": "Chenliang Zhou,Zheyuan Hu,Cengiz Oztireli", "background": "准确的材质建模对于实现拟真渲染至关重要，能够弥合计算机生成图像与现实世界照片之间的差距。传统的建模方法依赖于表征BRDF数据，而近期的研究转向了潜在神经表示，后者为各种任务提供了紧凑和灵活的框架。然而，这些方法在频域的行为尚未得到充分理解。论文旨在解决这一问题，并引入了FreNBRDF，一种基于频域修正的神经材质表示方法，通过利用球面谐波，将频域考虑引入到神经BRDF建模中。", "innovation": "提出了一种基于频域修正的新型消失点损失函数，并将其纳入一个通用且可适应的重建和编辑框架中，从而增强了保真度、适应性和效率。此外，FreNBRDF通过频域分析神经材质，并结合了该分析结果，改变了传统的观点，为材质建模提供了新的视角。", "conclusion": "大量的实验表明，FreNBRDF在材质外观重建和编辑的准确性和鲁棒性方面优于最先进的方法，能够支持更加结构化和可解释的下游任务和应用程序。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00498", "html_url": "https://arxiv.org/abs/2507.00498", "title": "MuteSwap：基于静默面孔的语音转换", "title_en": "MuteSwap: Silent Face-based Voice Conversion", "authors": "Yifan Liu,Yu Fang,Zhouhan Lin", "background": "传统的语音转换通过来自源说话者和目标说话者的音频输入，修改源说话者的语音特征以匹配目标说话者。但在无法获取清晰音频的情况下，如静默视频或嘈噪声环境中，这一过程变得不可行。因此，本文关注从视觉输入中实现无声面孔到声音的语音转换（Silent Face-based Voice Conversion，SFVC）这一任务，并尽可能保持源说话者在静默视频中的语音内容。这项任务挑战在于仅使用视觉线索生成可理解的语音和转换身份，极具挑战性。", "innovation": "本文提出了MuteSwap，这是一种新颖的框架，利用对比学习对齐跨模态身份，并通过最小化互信息分离共享的视觉特征来实现该任务。该方法特别适用于嘈噪声条件下，此时依赖音频输入的方法无法产生可理解的结果，展示了该方法的有效性及SFVC任务的可行性。", "conclusion": "实验结果显示，MuteSwap在语音合成和身份转换方面取得了令人印象深刻的表现，特别是在嘈噪声条件下，表明我们的训练方法有效且SFVC任务的可行性得以证明。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00398", "html_url": "https://arxiv.org/abs/2507.00398", "title": "从三维超声准确高效估计胎儿出生体重", "title_en": "Accurate and Efficient Fetal Birth Weight Estimation from 3D Ultrasound", "authors": "Jian Wang,Qiongying Ni,Hongkui Yu,Ruixuan Yao,Jinqiao Ying,Bin Zhang,Xingyi Yang,Jin Peng,Jiongquan Chen,Junxuan Yu,Wenlong Shi,Chaoyu Chen,Zhongnuo Yan,Mingyuan Luo,Gaocheng Cai,Dong Ni,Jing Lu,Xin Yang", "background": "胎儿出生体重（FBW）的准确估计对于优化分娩决策和降低围产儿死亡率至关重要。临床方法存在效率低下、操作依赖性强以及在复杂胎儿解剖结构情况下难以应用的问题。现有的深度学习方法基于2D标准超声图像或视频，缺乏空间信息，限制了预测精度。", "innovation": "本文提出了一种直接从三维胎儿超声图估计胎儿出生体重的方法，这种方法结合了多尺度特征融合网络（MFFN）和基于合成样本的学习框架（SSLF）。MFFN能够通过引入通道注意、空间注意和基于排名的损失函数实现稀疏监督下的多尺度特征提取和融合。SSLF通过简单合并不同胎儿的头部和腹部数据生成合成样本，利用半监督学习策略提高预测性能。实验结果显示本文方法具有优越的表现，平均绝对误差为166.4±155.9克，平均绝对百分比误差为5.1±4.6%，超过了现有方法并接近资深医生的准确性。", "conclusion": "本文方法在从三维超声准确高效估计胎儿出生体重方面取得了显著进展，尤其是在复杂胎儿解剖结构的情况下，其预测性能接近资深医生的水平。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00511", "html_url": "https://arxiv.org/abs/2507.00511", "title": "使用高级U-Net进行医学图像分割：VMSE-Unet和VM-Unet CBAM+", "title_en": "Medical Image Segmentation Using Advanced Unet: VMSE-Unet and VM-Unet CBAM+", "authors": "Sayandeep Kanrar,Raja Piyush,Qaiser Razi,Debanshi Chakraborty,Vikas Hassija,GSS Chalapathi", "background": "本文基于传统的VM U-Net框架，通过引入Squeeze-and-Excitation (SE)和Convolutional Block Attention Module (CBAM)技术，提出了一种新的深度学习结构VMSE U-Net和VM-Unet CBAM+，旨在提升医学图像分割的精确度、特征定位和计算效率。这两种模型在多个数据集上表现出了优越性，尤其是在精度、交并比、精确度和召回率方面，以及在计算效率、推理时间和内存使用上的优越性。", "innovation": "本文的创新在于将Squeeze-and-Excitation (SE)和Convolutional Block Attention Module (CBAM)技术整合到传统VM Unet框架中，从而显著提高了分割精度、特征定位和计算效率。VMSE Unet模型在多项实验中表现出最高的准确率、交并比、精确度和召回率，同时也表现出优秀的计算效率，具有更快的推理时间和更低的内存使用。", "conclusion": "研究表明，增强的VMSE-Unet架构是医学图像分析的一个有价值工具，具有重要的现实临床应用潜力。未来的研究将集中在优化其准确度、鲁棒性和计算效率。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00635", "html_url": "https://arxiv.org/abs/2507.00635", "title": "眼科手术期间稳定跟踪眼睛视线方向", "title_en": "Stable Tracking of Eye Gaze Direction During Ophthalmic Surgery", "authors": "Tinghe Hong,Shenlin Cai,Boyang Li,Kai Huang", "background": "眼科手术机器人通过减少人类外科医生的自然手颤抖，提供了出色的稳定性和精度，使得在受限的手术空间内进行精细操作成为可能。尽管已经开发出了基于视觉和力的控制方法来指导手术机器人，但是术前导航仍然高度依赖手动操作，这限制了手术的一致性，增加了不确定性。当前的眼球追踪技术，无论是传统的还是深度学习为基础的，都面临依赖额外传感器、手术环境中遮挡问题以及面部识别的要求，这些都构成了挑战。", "innovation": "本文提出了一种结合机器学习和传统算法的眼球定位与追踪方法，这种方法不需要特征点，能够在不同照明和阴影条件下保持稳定的虹膜检测和视线估计。与现有技术相比，这项创新解决了对额外传感器的依赖、遮挡问题以及需要面部识别的问题，从而提供了一种更为稳健的眼球追踪方法，特别是在眼科手术环境中。", "conclusion": "通过广泛的现实世界实验，研究结果表明，该研究提出的方法在眼球方向估计中的平均误差为0.58度，并且基于计算的方向，机器人手臂的平均控制误差为2.08度。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00577", "html_url": "https://arxiv.org/abs/2507.00577", "title": "BadViM: Backdoor Attack against Vision Mamba", "title_en": "BadViM: Backdoor Attack against Vision Mamba", "authors": "Yinghao Wu,Liyan Zhang", "background": "Vision State Space Models (SSMs)，特别是Vision Mamba (ViM)，在视觉任务中被认为是有前景的替代视觉变压器 (Vision Transformers, ViTs) 的方法。然而，这一新型架构的安全性问题，特别是它们对后门攻击的易感性，已经被严重忽视。后门攻击通过将隐藏触发器嵌入目标模型，使其在输入包含这些触发器时发生错误分类，同时在普通输入上保持正常表现。本文通过引入专门针对Vision Mamba的后门攻击框架BadViM，探讨了ViM的后门攻击漏洞。该攻击使用Resonant Frequency Trigger (RFT)等手段利用目标模型的频率敏感模式，创造了隐蔽且分布式的后门触发器。", "innovation": "本文提出了一种新型后门攻击框架BadViM，通过使用Resonant Frequency Trigger (RFT)，专门针对Vision Mamba进行设计。BadViM还引入了Hidden State Alignment loss，通过战略性地调整模型的内部表示来达到攻击目的，具体是通过使后门图像的隐藏状态与目标类别的隐藏状态对齐来提高攻击效果。BadViM实现加固攻击，尽管面对PatchDrop、PatchShuffle和JPEG压缩等常见防御措施显示出显著的抵抗力，其攻击成功率仍然高，同时保持了干净数据的准确性。", "conclusion": "实验结果表明，BadViM在保持干净数据准确性的同时，实现了较高的攻击成功率，并表现出对传统防御措施的卓越抗性，如PatchDrop、PatchShuffle和JPEG压缩，这对于对抗Vision Mamba的后门攻击具有重要意义。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00491", "html_url": "https://arxiv.org/abs/2507.00491", "title": "Twill: 在异构移动边缘平台上调度复合人工智能系统", "title_en": "Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms", "authors": "Zain Taufique,Aman Vyas,Antonio Miele,Pasi Liljeberg,Anil Kanduri", "background": "复合人工智能（cAI）系统通过串联多种AI模型来解决复杂问题，通常由深度神经网络（DNNs）、变换器和大语言模型（LLMs）组成。这类系统在移动边缘平台上部署时，面临动态调度多个不同类型计算任务的挑战，尤其是DNN和变换器的并发推理任务。现有的移动边缘AI推理策略大多只针对单一DNN或变换器的工作负载，依赖于预先设计的性能分析，难以应对cAI系统所需的DNN和变换器的并发推理任务。", "innovation": "提出了一种名为Twill的运行时框架，通过任务亲和性感知的集群映射和迁移策略、优先级感知的任务冻结/解冻策略以及动态电压频率调整（DVFS），实现了在异构移动边缘平台上高效调度复合AI系统的并发推理请求，同时最小化推理延迟并在给定的功耗预算内运行。", "conclusion": "通过在Nvidia Jetson Orin NX平台上实现并部署Twill框架，并与最先进的边缘AI推理技术进行评估，结果显示Twill平均减少了54%的推理延迟，同时满足了功率预算的要求。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00651", "html_url": "https://arxiv.org/abs/2507.00651", "title": "GANs Secretly Perform Approximate Bayesian Model Selection", "title_en": "GANs Secretly Perform Approximate Bayesian Model Selection", "authors": "Maurizio Filippone,Marius P. Linhard", "background": "生成对抗网络（GANs）在生成模型中非常流行且成功。尽管如此，优化过程非常具有挑战性，容易导致过拟合，因此需要正则化手段来避免这一问题。本文通过将GANs解释为概率生成模型，来重新审视它们的成功和限制，进而通过贝叶斯神经网络的视角理解GANs的部分随机性，从而建立通用逼近条件。进一步地，将GANs的对抗式优化视为边际似然的代理优化，利用边际似然优化与奥卡姆剃刀原理之间的联系，定义正则化和优化策略，旨在平滑损失景观，寻找最小描述长度的解决方案，这些策略与扁平的极小值和良好的泛化能力相关联。", "innovation": "通过将GANs解释为贝叶斯神经网络，以及将其对抗式优化过程解释为边际似然的代理优化，从而定义了新的正则化和优化策略，这些策略旨在平滑损失景观，寻找最小描述长度的解决方案。这为理解GANs的正则化策略提供了一个新的视角，并表明这些策略可以改善性能，加深了对GANs原理的理解。", "conclusion": "实验结果表明，这些策略可以提高性能，这为更深入理解正则化策略在GANs中的应用铺平了道路。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00673", "html_url": "https://arxiv.org/abs/2507.00673", "title": "Prompt2SegCXR：基于提示分割胸部X光片中所有器官和疾病的提示", "title_en": "Prompt2SegCXR:Prompt to Segment All Organs and Diseases in Chest X-rays", "authors": "Abduz Zami,Shadman Sobhan,Rounaq Hossain,Md. Sawran Sorker,Mohiuddin Ahmed,Md. Redwan Hossain", "background": "图像分割在医疗领域发挥着关键作用，能够从周围区域中隔离出感兴趣的器官或区域。传统的分割模型通常是针对特定器官或疾病进行训练，限制了其处理其他器官和疾病的灵活性。目前，少有高级模型能够进行多器官或多疾病分割，增加了灵活性。此外，最近基于提示的图像分割引起了更多关注，因为它允许模型根据用户提供的提示进行区域分割。然而，尚没有专门的研究集中在基于提示的交互式多器官和多疾病分割，特别是在胸部X光（Chest X-rays）方面.", "innovation": "本文提出两项主要贡献：首先，通过医学专家从多个数据源收集并整理了一个包含23个类别的数据集，包括6个器官和17种疾病，专门用于基于提示的胸部X光分割。其次，引入了Prompt2SegCXR，这是一种轻量级模型，可以准确分割胸部X光中的多种器官和疾病。该模型结合了多阶段特征融合，能够从不同网络层中结合特征以增强空间和语义理解，提高分割精度。与现有的基于提示的图像分割预训练模型相比，本文模型表现良好，提供了基于用户提示分割胸部X光的可靠解决方案.", "conclusion": "本文通过生成由医学专家设计的基于提示的提示草图，并提出了一种轻量级模型Prompt2SegCXR，能够准确分割胸部X光中的多种器官和疾病。该模型综合了多阶段特征融合，通过结合不同网络层的特征增强了空间和语义的理解能力，实现了高精度的分割，为基于用户提示进行胸部X光分割提供了可靠的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00582", "html_url": "https://arxiv.org/abs/2507.00582", "title": "通过深度平衡模型连接经典和基于学习的迭代配准", "title_en": "Bridging Classical and Learning-based Iterative Registration through Deep Equilibrium Models", "authors": "Yi Zhang,Yidong Zhao,Qian Tao", "background": "传统的可变形医学图像配准问题通常被表述为一个优化问题。经典方法通过对这一问题进行迭代求解，而基于学习的方法则使用循环神经网络（RNN）通过固定步数的展开来模仿这一过程。然而，经典方法通常在达到足够迭代次数后收敛，而基于学习的展开方法缺乏理论上的收敛保证，并且在实际使用中表现出不稳定性。此外，展开方法在训练阶段有一个实际瓶颈：由于时间反向传播（BPTT），GPU内存量随展开步数线性增长。为了应对这两个理论和实际挑战，我们提出了一种新的配准框架DEQReg，该框架基于深度平衡模型（DEQ），将配准问题表述为寻求平衡的问题，从而建立了经典优化方法和基于学习的展开方法之间的自然联系。DEQReg可以保持恒定的内存消耗，允许理论上无限的迭代步骤。", "innovation": "DEQReg，基于深度平衡模型的新配准框架，将配准问题表述为求平衡问题，连接经典优化和基于学习的方法。该方法保持恒定内存使用，允许理论上无限的迭代步骤。通过广泛的评估，我们展示了DEQReg在性能上与最先进的展开方法相当，同时显著减少了内存消耗。我们还发现了一个有趣的现象：现有的展开方法在推理步骤超过训练配置时，性能先略有提升然后不可逆地恶化，相比之下，DEQReg通过其内置的求平衡机制实现了稳定的收敛，从而弥合了经典优化和现代基于学习的配准方法之间的差距", "conclusion": "DEQReg通过其固有的平衡寻求机制，解决了经典方法和基于学习的方法之间的理论和现实挑战，不仅保持了恒定的内存使用，还能够实现稳定的收敛。在广泛的评估中，DEQReg的性能达到了竞品水平，同时大幅降低了内存消耗。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00670", "html_url": "https://arxiv.org/abs/2507.00670", "title": "Mind the Detail: Uncovering Clinically Relevant Image Details in Accelerated MRI with Semantically Diverse Reconstructions", "title_en": "Mind the Detail: Uncovering Clinically Relevant Image Details in Accelerated MRI with Semantically Diverse Reconstructions", "authors": "Jan Nikolas Morshuis,Christian Schlarmann,Thomas Küstner,Christian F. Baumgartner,Matthias Hein", "background": "近年来，基于深度学习的加速MRI重建技术在图像质量方面取得了显著的改进，特别是在高加速因子下的表现令人印象深刻。然而，从临床角度来看，图像质量并不是最重要的，重要的是重建的数据要能保留所有临床相关的信息。现有技术在进行基于扩散的重建时，即便是考虑重新采样，也有可能无法重建小的和不常见的病理情况，从而可能导致错误的诊断决策（假阴性）。", "innovation": "本文提出了一种名为“语义多样性重建”（Semantic Diverse Reconstructions, SDR）的方法，该方法在给出原始重建的基础上，生成具有增强语义多样性的新重建图像，同时这些图像必须与测量数据完全一致。为了自动评估SDR，作者使用fastMRI+数据集训练了一个物体检测器。研究结果表明，SDR方法显著降低了假阴性诊断的概率，并提高了平均精确度。", "conclusion": "SDR方法在加速MRI重建中具有显著优势，能够显著减少假阴性诊断并提高平均精确度，这些临床相关的图像细节有助于提高MRI诊断的准确性。该研究的代码可以在指定的链接中获取。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00669", "html_url": "https://arxiv.org/abs/2507.00669", "title": "Audio-3DVG: 统一音频与点云融合的3D视觉定位", "title_en": "Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding", "authors": "Duc Cao-Dinh,Khai Le-Duc,Anh Dao,Bach Phan Tat,Chris Ngo,Duy M. H. Nguyen,Nguyen X. Khanh,Thanh Nguyen-Tang", "background": "3D视觉接地（3DVG）涉及基于自然语言在三维点云中定位目标对象。尽管之前的工作已经在使用文本描述方面取得了进展，但利用语音作为输入，即基于音频的3D视觉接地，仍然处于被忽视和具有挑战性的阶段。动机来源于自动语音识别（ASR）和语音表示学习的进步，本文提出了一种简单而有效的框架Audio-3DVG，该框架结合了音频和空间信息以增强接地效果。通过将语音分解为两个互补的任务，首先引入对象提及检测，明确识别音频中提及的对象，接着提出了一个音频导向的注意力模块，以捕捉候选对象与关系性语音线索的交互，从而改善目标识别在杂乱场景中的表现。为了支持基准测试，还为标准的3DVG数据集（包括ScanRefer、Sr3D和Nr3D）合成了音频描述。实验结果表明，Audio-3DVG不仅在基于音频的接地方面达到了新的SOTA性能，而且与基于文本的方法相媲美，突显了将口语纳入3D视觉任务中的潜力。", "innovation": "提出了Audio-3DVG框架，结合了音频和空间信息以增强3D视觉定位。通过分解任务为两个互补部分：对象提及检测和音频导向的注意力模块，改善了在杂乱场景下的目标识别。此外，还为标准3DVG数据集合成了音频描述，对基准测试进行了支持。", "conclusion": "Audio-3DVG不仅在基于音频的3D视觉定位方面达到了新的SOTA性能，而且展示了结合口语与3D视觉任务的可能性，表明了整合口语信息的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00333", "html_url": "https://arxiv.org/abs/2507.00333", "title": "屏幕与范围：跨技能水平设计综合可视化方案的经验教训", "title_en": "Scope Meets Screen: Lessons Learned in Designing Composite Visualizations for Marksmanship Training Across Skill Levels", "authors": "Emin Zerman,Jonas Carlsson,Mårten Sjöström", "background": "各种专业领域，如警察、军人、猎人以及射击运动员（如奥运会射击、双向射击和现代五项运动员）都需要射击技巧。当前训练和教练方法主要是基于重复训练，教练无法从射手的角度进行观察，分析仅限于姿势和准确性，且仅限于会话结束后的评估。因此，本研究旨在开发一个射击可视化系统，研究其对初学者和专家射手的有效性，特别是跨不同技能水平的有效性评估方法。为了实现这一目标，研究者创建了五种复合视图，采用第一人称射击视频，并叠加了各种度量和图形总结。这五种视图在10位参与者（5位专家射手，5位初学者）中进行了评估，参与者通过混合方法的研究，进行了射击计数任务和瞄准解读任务，以及相互偏好比较和半结构化访谈。研究结果表明，在9次中的10次情况下，一种仪表板风格的综合视图，结合了原始视频、极坐标图和选定的图表，被更喜欢，并且对不同技能水平的理解有所支持。", "innovation": "研究提出了一个射击可视化系统，旨在通过前瞻性视角改善射击训练中的反馈。创新点包括：1) 创造了五种复合视图，整合了第一人称视频和度量叠加图形；2) 采用了混合方法的研究设计，包括射击计数任务、瞄准解读、偏好比较和半结构化采访，以评估系统的有效性；3) 结果展示了在不同技能水平中，第一人称视频与视觉分析整合的有效性，为教练提供了新的见解，且建议此种方法可能适用于其他基于精度的运动。", "conclusion": "研究结果表明，结合了原始视频、极坐标图和选定图表的仪表板风格视图更受欢迎，有助于不同技能水平的理解。该设计研究结果强调了将第一人称视频与视觉分析整合应用于教练培训的重要性。未来的研究可以进一步应用于其他基于精度的运动项目，提供有效的反馈和指导。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00780", "html_url": "https://arxiv.org/abs/2507.00780", "title": "YOLOv8n的高精度和轻量化糖尿病视网膜病变检测改进研究", "title_en": "Research on Improving the High Precision and Lightweight Diabetic Retinopathy Detection of YOLOv8n", "authors": "Fei Yuhuan,Sun Xufei,Zang Ran,Wang Gengchen,Su Meng,Liu Fenghao", "background": "糖尿病视网膜病变的早期检测和诊断是当前眼科研究的一个重点。由于微病变的细微特征及其易受背景干扰的影响，现有检测方法在准确性和鲁棒性方面仍然面临许多挑战。", "innovation": "提出了一个基于改进YOLOv8n的轻量级高精度检测模型YOLO-KFG。通过设计新的动态卷积KWConv和C2f-KW模块改进了骨干网络，增强了模型对微病变的感知能力；设计了特征聚焦扩散金字塔网络(FDPN)，充分整合多尺度上下文信息，进一步提高了模型对微病变的感知能力；设计了轻量级共享检测头GSDHead，减少了模型参数量，使其更适用于资源受限设备。实验结果表明，与基线模型YOLOv8n相比，改进模型参数减少了20.7%，mAP@0.5提高了4.1%，召回率提高了7.9%。与YOLOv5n和YOLOv10n等主流单阶段算法相比，YOLO-KFG在检测准确性和效率上显示出明显优势。", "conclusion": "YOLO-KFG在保持高精度的同时降低了模型复杂度，适用于资源受限的设备，为糖尿病视网膜病变的检测提供了新的方法。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00660", "html_url": "https://arxiv.org/abs/2507.00660", "title": "MTCNet: 4D超声心动图中引导运动和拓扑一致性学习的二尖瓣分割", "title_en": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound", "authors": "Rusi Chen,Yuanting Yang,Jiezhi Yao,Hongning Song,Ji Zhang,Yongsong Zhou,Yuhao Huang,Ronghao Yang,Dan Jia,Yuhan Zhang,Xing Tao,Haoran Dou,Qing Zhou,Xin Yang,Dong Ni", "background": "二尖瓣反流是心血管疾病中最常见的病况之一。四维（4D）超声成像是评估动态瓣膜形态的主要成像技术，但由于缺乏相位标注、严重的运动伪影以及影像质量不佳，4D二尖瓣（MV）分析仍然具有挑战性。现有的方法缺乏相位间的依赖性，限制了4D MV分析的发展与精度。因此，需要一种可以弥补相位间依赖性缺失的创新方法来提升4D MV分析的效果和准确性。", "innovation": "本文提出了一种名为MTCNet的运动-拓扑引导一致性网络，用于半监督学习（SSL）环境下的4D MV超声分割。MTCNet利用交叉相位运动引导的一致性学习策略，并通过双向注意记忆库传播时空特征，从而在相内和相间实现了出色的表现。此外，MTCNet还采用了拓扑引导的相关正则化，探索了物理先验知识来维持解剖上合理的结构对齐，进而有效地利用了有标签和无标签相位之间的结构对应关系。", "conclusion": "在包含160名患者共1408个相位的首个最大4D MV数据集上进行了广泛的评估，展示了MTCNet在跨相一致性上的优越性能（Dice：87.30%，HD：1.75毫米），相比其他先进方法拥有显著优势。代码和数据集均可通过提供的链接获取。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00687", "html_url": "https://arxiv.org/abs/2507.00687", "title": "非鲁棒分类器的扩散分类指导", "title_en": "Diffusion Classifier Guidance for Non-robust Classifiers", "authors": "Philipp Vaeth,Dibyanshu Kumar,Benjamin Paassen,Magda Gregorová", "background": "分类指导旨在引导扩散过程，以便给定的分类器能够可靠地识别生成的数据点属于某一类。然而，大多数分类指导方法仅限于那些专门在扩散前向过程的噪声上进行训练的鲁棒分类器。本文旨在将分类指导扩展到可以使用非鲁棒分类器，即那些在无噪声条件下进行训练的分类器。通过对标准CelebA数据集、专门的SportBalls数据集和高维真实世界CelebA-HQ数据集上的非鲁棒和鲁棒分类器对扩散过程的噪声的敏感性进行分析，研究发现，在噪声条件下，非鲁棒分类器的性能显著下降，导致不稳定梯度。", "innovation": "提出了一种方法，利用一阶去噪图像预测，并采用源自随机优化方法（如指数移动平均）的稳定化技术，以缓解这些问题。实验结果表明，该方法在提高分类指导稳定性的同时，保持了样本多样性及视觉质量。这项工作推动了生成模型中条件采样技术的发展，使其能够使用更广泛的分类器作为指导分类器。", "conclusion": "本文通过针对非鲁棒分类器设计了一种新的分类引导方法，利用去噪预测和稳定化技术提高了分类指导的稳定性，同时保持了生成样本的多样性与视觉质量。这是针对无噪声训练的分类器在扩散模型中的首次成功应用，拓宽了应用于扩散生成过程中的分类器范围。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00937", "html_url": "https://arxiv.org/abs/2507.00937", "title": "RaGNNarok：一种用于无人驾驶地面车辆增强雷达点云的轻量级图神经网络", "title_en": "RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles", "authors": "David Hunt,Shaocheng Luo,Spencer Hallyburton,Shafii Nillongo,Yi Li,Tingjun Chen,Miroslav Pajic", "background": "低成本室内移动机器人正随着家庭和商业空间中自动化技术的普及而变得流行。然而，现有基于激光雷达和相机的解决方案在视觉受阻环境中表现不佳，数据处理的计算开销高，而且激光雷达成本高昂。相比之下，毫米波雷达传感器提供了成本效益高、重量轻的选择，并能在不损害精度的情况下适应各种视觉条件。但是现有的雷达定位方法存在点云稀疏、噪声大、误检测等问题。因此，本文提出了一种基于图神经网络（GNN）的轻量级、实时且通用的RaGNNarok框架，用于增强雷达点云，即使在复杂、动态的环境中也能适用。", "innovation": "RaGNNarok是一个实时、轻量级且适用于各种场景的图神经网络（GNN）框架，可以显著提升雷达点云的精确度。它可以实时运行在资源受限的设备上（如低配置的Raspberry Pi 5），无需额外的计算资源，并且适用于定位、SLAM和自主导航等多种任务，特别是在复杂和动态环境中。", "conclusion": "RaGNNarok具有强大的可靠性和通用性，成为低成本室内移动机器人的稳健解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00743", "html_url": "https://arxiv.org/abs/2507.00743", "title": "基于可调小波单元的卷积神经网络在光学相干断层扫描分析增强中用于分类Epiretinal Membrane手术类型", "title_en": "Tunable Wavelet Unit based Convolutional Neural Network in Optical Coherence Tomography Analysis Enhancement for Classifying Type of Epiretinal Membrane Surgery", "authors": "An Le,Nehal Mehta,William Freeman,Ines Nagel,Melanie Tran,Anna Heinke,Akshay Agnihotri,Lingyun Cheng,Dirk-Uwe Bartsch,Hung Nguyen,Truong Nguyen,Cheolhong An", "background": "本研究旨在开发一种基于深度学习的方法，用于识别视网膜膜（ERM）移除手术类型，包括内部限制膜（ILM）移除或单独移除ERM。通过使用睫状体光相干断层扫描（OCT）中心扫描作为输入，模型试图更准确地区分这两种手术类型。研究者利用传统卷积神经网络（CNN）架构的ResNet18并结合预处理步骤改进了这一模型的性能，通过能量剪切和小波去噪提高准确性至72%，显示出比原始扫描更强的性能。然后进一步结合了可调小波单元（OrthLatt-UwU和PR-Relax-UwU），使得分类准确性分别提升到76%和78%。通过对比显示该AI模型在识别手术类型方面的表现优于经验丰富的手动判定者，后者仅能达到50%的准确率。", "innovation": "本研究的创新点在于结合ResNet18卷积神经网络和可调小波单元（如OrthLatt-UwU和PR-Relax-UwU），这些单元能够自动调整滤波器系数，在非下采样、步长为二的卷积和池化层中使用，增强了模型在区分ILM移除与单独的ERM移除数据集上的分类准确性。通过这种方法，研究实现了在后手术OCT扫描分类上优于经验人类判读者的性能，并有潜力辅助临床决策，提供更准确和可靠的数据分类结果，同时指出这是首次将可调小波用于分类不同类型的ERM移除手术的研究", "conclusion": "在此研究中，我们提出了一种基于可调小波单元的卷积神经网络模型，该模型在Optical Coherence Tomography（OCT）扫描数据上对Epiretinal Membrane手术类型进行分类，提高了分类的准确性和可靠性。模型在ILM移除和单独的ERM移除之间的区分上分别实现了76%和78%的准确性，远超人类手动划分类人的50%准确性。这突显了基于CNN模型的临床辅助决策的重要性，展示了可调小波单元在神经网络中的有效性，将这些技术用于眼部医学影像分析具有广阔的前景。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00903", "html_url": "https://arxiv.org/abs/2507.00903", "title": "基于深度学习的T1和T2心脏MRI成像图的分割方法及自动疾病检测", "title_en": "Deep learning-based segmentation of T1 and T2 cardiac MRI maps for automated disease detection", "authors": "Andreea Bianca Popescu,Andreas Seitz,Heiko Mahrholdt,Jens Wetzl,Athira Jacob,Lucian Mihai Itu,Constantin Suciu,Teodora Chitiboi", "background": "参数化组织映射能够实现心脏组织的定量表征，但这种方法依赖于观察者手动勾勒，容易产生主观性差异。传统方法使用平均放松值和单一阈值可能过于简化心肌的复杂性。本研究旨在评估深度学习是否能够达到与观察者间差异相当的分割准确性，探索超出平均T1/T2值之外的统计特征的实用性，并评估将多重特征结合的机器学习是否能够增强疾病检测效果。", "innovation": "研究采用了基于深度学习的方法进行T1和T2心脏MRI成像图的分割，并通过使用多种统计特征来提高疾病检测的效果。研究还发现，结合多种特征的机器学习在疾病检测中比单一阈值的方法更为优越，分割模型的Dice相似系数达到了85.4%，并且随机森林方法在F1分数上有显著提升。", "conclusion": "深度学习可以促进T1/T2心脏MRI成像图的分割，而结合多种特征的机器学习则能够进一步提高疾病的检测效果。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00993", "html_url": "https://arxiv.org/abs/2507.00993", "title": "提升3D CT扫描中肺部疾病诊断", "title_en": "Advancing Lung Disease Diagnosis in 3D CT Scans", "authors": "Qingqiu Li,Runtian Yuan,Junlin Hou,Jilan Xu,Yuejie Zhang,Rui Feng,Hao Chen", "background": "为了更准确地诊断胸部CT扫描中的肺部疾病，作者提出了一种简单有效的模型。他们通过分析3D CT扫描的特性并去除非肺部区域，使得模型能够专注于与病灶相关的区域，从而降低计算成本。此外，作者还使用了ResNeSt50作为强有力的特征提取器，并采用了加权交叉熵损失以缓解不同类别之间的失衡问题，特别针对数量较少的鳞状细胞癌类别。", "innovation": "该研究提出了一种简单的3D CT扫描肺部疾病诊断方法。首先通过对3D CT扫描进行非肺部区域去除处理，优化了模型的特征提取，提高了诊断准确性。使用ResNeSt50作为特征提取器，结合加权交叉熵损失处理类别不平衡问题，特别是在鳞状细胞癌类别的模型优化上有所突破，表现出色。", "conclusion": "该模型在公平疾病诊断挑战的验证集上达到了宏F1分数0.80，展示了其在区分不同肺部状况方面的强大性能。这一研究提出的模型和方法为肺部疾病的精准诊断提供了新的思路和技术支持。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2302.14368", "html_url": "https://arxiv.org/abs/2302.14368", "title": "通过特征解耦和真实性增强采样方法提高扩散模型的可控性", "title_en": "Enhanced Controllability of Diffusion Models via Feature Disentanglement and Realism-Enhanced Sampling Methods", "authors": "Wonwoong Cho,Hareesh Ravi,Midhun Harikumar,Vinh Khuc,Krishna Kumar Singh,Jingwan Lu,David I. Inouye,Ajinkya Kale", "background": "扩散模型在多个任务中表现出良好的性能，因此在提高扩散模型可控制性方面付出了很多努力。然而，如何训练扩散模型以拥有解耦的潜在空间，以及如何在采样过程中自然地融入解耦的条件仍处于探索阶段。", "innovation": "提出了一种特征解耦框架（FDiff），用于训练扩散模型以解耦特征；提出了一种通用可组合扩散模型方法和时间步长相关权重调度策略，以提升真实性和进一步改进性能；观察到与现有方法相比，提出的解耦方法在图像处理和图像转换中具有更好的可控性。", "conclusion": "通过特征解耦训练扩散模型，并提出采样方法以增强真实性和提升性能，从而提高了扩散模型的可控性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00983", "html_url": "https://arxiv.org/abs/2507.00983", "title": "DMCIE: 基于输入和误差连接的扩散模型以提高MRI图像中脑肿瘤分割的准确性", "title_en": "DMCIE: Diffusion Model with Concatenation of Inputs and Errors to Improve the Accuracy of the Segmentation of Brain Tumors in MRI Images", "authors": "Sara Yavari,Rahul Nitin Pandya,Jacob Furst", "background": "准确分割MRI扫描中的脑肿瘤对于可靠的临床诊断和有效的治疗规划至关重要。近年来，扩散模型在图像生成和分割任务中表现出显著的效果。本文介绍了一种基于扩散模型的新颖纠错分割方法。利用3D U-Net生成初始分割掩码，通过识别预测与真实值之间的差异生成误差图，将误差图与原始MRI图像连接起来，指导扩散模型以增强分割准确性。评估结果显示，DMCIE方法在BraTS2020数据集上超过了多种最先进的基于扩散的分割方法，Dice分数为93.46，HD95为5.94 mm，表明误差导向的扩散模型能够产生精确可靠的脑肿瘤分割结果。", "innovation": "提出了DMCIE（Diffusion Model with Concatenation of Inputs and Errors）框架，结合3D U-Net生成初始分割掩码和误差图，利用这些信息引导扩散模型进行改善分割。该方法有效针对错误分类区域进行优化，通过连接原始多模态MRI输入（T1, T1ce, T2, FLAIR），显著提高了分割精度。", "conclusion": "DMCIE方法通过使用多模态MRI输入和误差导向的扩散过程，提高了脑肿瘤分割的准确性，在BraTS2020数据集上实现了最佳性能，证明了其在脑肿瘤分割任务中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00984", "html_url": "https://arxiv.org/abs/2507.00984", "title": "大规模仓储自动化中的箱子姿态和形状估计及领域适应", "title_en": "Box Pose and Shape Estimation and Domain Adaptation for Large-Scale Warehouse Automation", "authors": "Xihang Yu,Rajat Talak,Jingnan Shi,Ulrich Viereck,Igor Gilitschenski,Luca Carlone", "background": "现代仓储自动化系统依赖于大量数据，这些数据主要来自智能机器人，但这些数据大多未经过注释。研究工作者开发了一种基于现实世界未标注数据的自监督领域适应管道，以提高感知模型的性能，而无需人工注释。研究专注于估计箱子的姿态和形状，并提出了一种校正与认证的管道来执行自监督的箱子姿态和形状估计。该方法在模拟和实际工业场景中进行了广泛评估，并应用于包含50,000张图像的大型实际世界数据集。自监督模型相比仅在模拟中训练的模型表现出显著的性能提升，并且优于零样本3D包围盒估计基准模型。", "innovation": "开发了一种基于现实世界未标注数据的自监督领域适应管道，专注于估计箱子的姿态和形状。提出了一种校正与认证的管道来执行自监督的箱子姿态和形状估计。这种方法在模拟和实际工业场景中进行了广泛评估，并且在与仅在模拟中训练的模型和零样本3D包围盒估计基准模型的比较中表现出显著的性能提升。", "conclusion": "自监督模型在大规模仓储自动化系统中的箱子姿态和形状估计上表现出显著的性能提升，尤其是在模拟与实际场景的适应能力上优于其他模型。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00832", "html_url": "https://arxiv.org/abs/2507.00832", "title": "利用自动解剖基于的后处理减少假阳性并提高深度学习颅内动脉瘤检测的可解释性", "title_en": "Automated anatomy-based post-processing reduces false positives and improved interpretability of deep learning intracranial aneurysm detection", "authors": "Jisoo Kim,Chu-Hsuan Lin,Alberto Ceballos-Arroyo,Ping Liu,Huaizu Jiang,Shrikanth Yadav,Qi Wan,Lei Qin,Geoffrey S Young", "background": "尽管深度学习（DL）模型在CTA（计算机断层扫描血管造影）图像中检测颅内动脉瘤方面表现出色，但高假阳性（FP）率仍然阻碍了其临床应用。尽管模型架构和检测阈值调整策略有所改进，但仍然无法彻底解决FP问题。为了解决这一问题，研究人员采用了一种自动的、基于解剖学的启发式学习混合动脉-静脉分割后处理方法，进一步降低了FP率。方法包括使用两种DL模型进行训练和评估，并通过多种分割掩码来判定并去除可能的FPs，从而提高DL模型的检测性能。结果显示，对于两种DL模型，这种后处理方法显著降低了FP率，提升了检测准确性，并且保持了TPs的完整性，从而降低了FP/case比率，提高了模型的临床接受度和可解释性。同样重要的是，用于去除FPs的方法提高了模型的可解释性，使医生能够更好地理解模型的输出结果。", "innovation": "研究采用了一种自动的、基于解剖学的启发式学习混合动脉-静脉分割后处理方法，有效地降低了两种DL模型的FP率，特别是对于颅外、静脉和非血管结构的FP。特别是在保留TPs的情况下，显著降低了FP/case比率，从而提高了检测模型的临床接受度和可解释性。这种方法为进一步改进和临床应用深度学习颅内动脉瘤检测模型提供了新的思路和方法。", "conclusion": "基于解剖的、可解释的后处理技术能够提升DL模型在颅内动脉瘤检测中的性能。更广泛地说，自动化的、基于特定领域知识的启发式混合处理方法有望进一步提高动脉瘤检测模型的性能和临床接受度。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00990", "html_url": "https://arxiv.org/abs/2507.00990", "title": "Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations", "title_en": "Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations", "authors": "Shivansh Patel,Shraddhaa Mohan,Hanlin Mai,Unnat Jain,Svetlana Lazebnik,Yunzhu Li", "background": "该研究介绍了一个名为RIGVid的系统，该系统能够让机器人通过模仿生成的视频来执行复杂的操作任务，如倾倒、擦拭和混合，而不需要任何物理演示或针对机器人的特定训练。给定语言命令和初始场景图像，一个视频扩散模型会生成潜在的示范视频，然后通过视觉语言模型（VLM）自动筛选不符合命令的结果。6D姿态跟踪器会从视频中提取物体轨迹，并以体无关的方式重新定向到机器人上。", "innovation": "研究引入了RIGVid系统，该系统能够通过模仿生成的视频让机器人进行复杂的操作任务。系统利用视频扩散模型生成潜在的示范视频，并通过视觉语言模型自动筛选出符合命令的结果。6D姿态跟踪器从视频中提取物体轨迹，并以体无关的方式重新定向到机器人上。结果显示，通过生成的视频进行模仿的效果与实际演示相同，而且生成质量越高，性能越好。与关键点预测相比，依赖生成的视频更有优势。", "conclusion": "研究证明，使用最先进的现成模型生成的视频可以作为机器人操作的有效监督来源。通过大量真实世界的评估，显示了生成的视频模仿方法的有效性，并且强调了使用视频扩散模型和6D姿态跟踪的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.04814", "html_url": "https://arxiv.org/abs/2406.04814", "title": "从单一视频流中学习视频扩散模型的终生学习", "title_en": "Lifelong Learning of Video Diffusion Models From a Single Video Stream", "authors": "Jason Yoo,Yingchen He,Saeid Naderiparizi,Dylan Green,Gido M. van de Ven,Geoff Pleiss,Frank Wood", "background": "以往对于自回归视频扩散模型的训练通常需要大量的离线数据，而本文探讨了一种新颖的方法，即仅从单一视频流中训练这些模型，这种方法类似于有体验的代理体会环境的方式，同时本文还发现这种方法可以与标准离线训练达到相似的效果，特别是使用经验回放方法，仅保留先前视频流的一部分数据即可实现这一目标。", "innovation": "本文的创新在于提出了一种从单一视频流中训练自回归视频扩散模型的新方法，这种方法不仅可行性高，而且在相同梯度更新步骤下能达到与标准离线训练相当的效果。此外，本文还引入了四个新的数据集，分别为Lifelong Bouncing Balls、Lifelong 3D Maze、Lifelong Drive和Lifelong PLAICraft，以支持在单一视频流下的终生生成视频模型的训练和评估。", "conclusion": "通过使用单一视频流和引入的新数据集，本文证明了自回归视频扩散模型可以在现阶段有效训练，并且可以达到与标准训练类似的效果。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2307.16579", "html_url": "https://arxiv.org/abs/2307.16579", "title": "对比条件潜在扩散模型在音视频分割中的应用", "title_en": "Contrastive Conditional Latent Diffusion for Audio-visual Segmentation", "authors": "Yuxin Mao,Jing Zhang,Mochu Xiang,Yunqiu Lv,Dong Li,Yiran Zhong,Yuchao Dai", "background": "本文提出了一种对比条件潜在扩散模型，用于音视频分割（AVS），并深入研究了音频对分割的影响。通过将音频与最终分割图之间的相关性建模，保证了它们之间的强相关性，从而实现语义相关的表示学习。该框架通过潜在扩散模型将条件生成过程学习出来，在测试阶段的去噪过程中提供地面真值感知推理。文章强调了音频信号对模型输出的贡献，并通过最小化多模态数据（例如，基于音频-视觉数据）与单模态数据（例如，仅基于音频数据）条件概率之间的密度比来广泛建模音频信号的贡献。这样，通过密度比优化，潜在扩散模型可以显式地最大化音频对AVS的贡献，从而以对比学习约束来实现该目标，其中扩散部分作为主要目标以实现最大似然估计，而密度比优化部分施加约束。通过采用这种通过对比学习的潜在扩散模型，有效地增强了音频对AVS的贡献。这些效果通过在基准数据集上的实验结果得到了验证。相关代码和结果可以在项目页面上找到：this https URL", "innovation": "本文创新地提出了对比条件潜在扩散模型，用于音视频分割。该模型通过最小化多模态数据与单模态数据之间的密度比，强调了音频信号的贡献，从而显式最大化音频对AVS的贡献。通过密度比优化和对比学习，模型在测试阶段能够实现最大似然估计，并施加约束，从而有效提高了音频在AVS中的贡献。这种新的框架在实验中得到了验证，并通过在基准数据集上的表现证明了其有效性", "conclusion": "本文提出了一种对比条件潜在扩散模型，通过最小化多模态数据与单模态数据之间的密度比，显式最大化音频对AVS的贡献。通过密度比优化和对比学习，模型在测试阶段实现了最大似然估计，并施加了约束。实验结果表明，该模型在基准数据集上的表现证明了其有效性。相关代码和结果已在线提供"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01016", "html_url": "https://arxiv.org/abs/2507.01016", "title": "VQ-VLA: 通过扩展向量量化动作标记器改进视觉-语言-行动模型", "title_en": "VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers", "authors": "Yating Wang,Haoyi Zhu,Mingyu Liu,Jiange Yang,Hao-Shu Fang,Tong He", "background": "本文介绍了一种基于迄今为止最大规模的动作轨迹数据集的创新性向量量化动作分词器，相较于之前的方法，利用了超过100倍的数据。 extensive dataset 允许该分词器能够捕捉丰富的时空动态，从而构建一个不仅加速推理速度，而且生成更平滑、更连贯的动作输出的模型。该分词器在训练后，可以无缝适应各种下游任务，从短时响应行为到长时规划，无需任何调优。研究表明，在训练过程中，动作轨迹合成数据和真实数据之间的领域差距很小，因此可以有效利用大量的合成数据，而不会牺牲实际应用表现。为验证这一方法，我们进行了广泛的实验，包括模拟环境和真实的机器人平台，在长期规划任务中，随着合成轨迹数据量的增加，分词器的性能显著提高，特别是在两个现实任务中的成功率提高了30%以上。这些发现突显了本动作分词器作为一种强大且可扩展的实时嵌入式智能系统解决方案的潜力，为机器人控制的更高效和可靠设计开辟了道路。", "innovation": "创新点在于提出了一种新的基于大规模动作轨迹数据集的向量量化动作分词器，能够大幅度提高动作轨迹的数据量。该方法不仅加速了推理过程，还能生成更加平滑和连贯的动作输出。此外，研究人员发现合成和真实动作轨迹之间的领域差距较小，这使得可以大量使用合成数据，而不会影响实际性能。这种方法已在模拟和真实的机器人平台上得到了验证，结果显示合成轨迹数据的增加显著提高了下游任务的性能，尤其是在长期规划任务中成功率为30%以上。该方法为企业智能系统的实时落地提供了有力支撑，提升了机器人控制的效率和可靠性。", "conclusion": "本文提出的方法展示了向量量化动作标记器在视觉-语言-行动模型中的潜力，证明了其作为实时嵌入式智能系统强大且可扩展的解决方案的有效性和可靠性。该方法不仅能够在多种下游任务中实现零样本适应，而且还能够在各种机器人控制场景中提供更高的成功率。这些发现为未来机器人智能系统的构建提供了重要的参考和指导。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.09105", "html_url": "https://arxiv.org/abs/2411.09105", "title": "VideoCogQA: 评估视频语言模型认知能力的可控基准", "title_en": "VideoCogQA: A Controllable Benchmark for Evaluating Cognitive Abilities in Video-Language Models", "authors": "Chenglin Li,Qianglong Chen,Zhi Li,Feng Tao,Yin Zhang", "background": "大型视频语言模型(LVLMs)在多模态视频理解方面取得了显著成果，但现有研究尚不清楚这些模型是否具备处理高阶任务所需的认知能力，尤其是那些涉及象征性和抽象感知的任务。目前的基准测试主要依赖于带有注释的真实世界视频，这限制了它们对 LVLMs 的评估能力。鉴于此，作者提出了一种名为 VideoCogQA 的基准测试，旨在填补这一空白。", "innovation": "VideoCogQA 提供了一个可扩展且完全可控的基准测试，灵感来自于游戏环境。通过程序化引擎生成合成视频，该基准测试能够精细控制视觉元素、时间动态和任务难度，从而独立于视觉场景语义，专注于评估视频认知能力。该数据集包含 800 个视频和 3,280 个问题-答案对，涵盖各种难度级别的抽象概念、象征性元素和多模态集成任务。", "conclusion": "实验结果表明，即使是最先进的模型如 GPT-4o，在涉及抽象概念的任务上平均只能达到 48.8% 的性能。随着任务复杂性的增加，性能会下降 15%，突显了当前 LVLMs 在保持一致性能方面面临的挑战。这项工作旨在展示当前 LVLMs 的局限性，并为其未来更好地模拟人类认知过程提供见解。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.07995", "html_url": "https://arxiv.org/abs/2409.07995", "title": "深度重要：RGB-D在交通场景语义分割中的深层交互探索", "title_en": "Depth Matters: Exploring Deep Interactions of RGB-D for Semantic Segmentation in Traffic Scenes", "authors": "Siyu Chen,Ting Han,Changshe Zhang,Weiquan Liu,Jinhe Su,Zongyue Wang,Guorong Cai", "background": "RGB-D数据逐渐成为辅助驾驶理解复杂场景的关键数据源。然而，现有的研究对深度图中的内在空间属性关注不足，这导致了由于注意力错移引起预测误差。深度图的真实世界空间关系在语义分割任务中非常重要，但目前的模型没有充分探索这一点。研究者们尝试通过提出一种新颖的可学习深度交互金字塔变换器（DiPFormer），来探索并利用深度图的有效性。DiPFormer 使用深度空间感知优化（Depth SAO）和深度线性交叉注意力（Depth LCA）学习RGB-D特征空间的相似性，同时通过多层感知机解码器结合多尺度特征，以满足实时需求。", "innovation": "本文提出了可学习深度交互金字塔变换器（DiPFormer），针对现有研究在深度图处理中的不足。其创新点包括：1) 引入深度空间感知优化（Depth SAO），用于表示真实的三维空间关系；2) 通过深度线性交叉注意力（Depth LCA）学习RGB-D特征空间的相似性，以精化像素级别的空间差异；3) 利用多层感知机解码器结合多尺度特征，以适应实时应用的要求。与现有方法相比，DiPFormer 在道路检测（+7.5%）和语义分割（+4.9% / +1.5%）任务中显著提升了注意力表示的一致性，并在KITTI和Cityscapes数据集上达到了最先进的效果（分别为97.57%的F-分数和68.74%的mIoU，以及83.4%的mIoU）。", "conclusion": "通过DiPFormer，本文在深度图处理中取得了显著的改进，特别是在道路检测和语义分割方面，并在多个数据集上达到了最先进的性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05255", "html_url": "https://arxiv.org/abs/2410.05255", "title": "使用Self-Sampling Preference Optimization弥合SFT和DPO在扩散模型对齐中的差距", "title_en": "Bridging SFT and DPO for Diffusion Model Alignment with Self-Sampling Preference Optimization", "authors": "Daoan Zhang,Guangchen Lan,Dong-Jun Han,Wenlin Yao,Xiaoman Pan,Hongming Zhang,Mingxiao Li,Pengcheng Chen,Yu Dong,Christopher Brinton,Jiebo Luo", "background": "现有的后训练技术通常被划分为监督微调（SFT）和强化学习（RL）方法；SFT在训练过程中较为稳定，但在泛化能力上受限，而RL方法尽管泛化能力强，但需要额外的偏好数据或奖励模型，并且存在奖励滥用的风险。为了保留SFT和RL的优点，即去除配对数据和奖励模型的需要，同时保持SFT的训练稳定性和RL的泛化能力，本文提出了一种新的对齐方法——自我采样偏好优化（SSPO）", "innovation": "SSPO引入了一种随机检查点重播（RCR）策略，使用历史检查点构建配对数据，有效减少了过拟合现象。同时，使用自我采样正则化（SSR）策略动态评估生成样本的质量。当生成样本更可能成为胜利样本时，SSPO会自动从直接偏好优化（DPO）切换到监督微调（SFT），确保训练过程能准确反映样本质量。实验结果表明，SSPO在文本到图像基准测试中表现优于现有方法，其有效性在文本到视频任务中也得到了验证。文章在文本到图像和文本到视频基准测试中验证了SSPO，表明其在这些基准测试中均表现优异，超越了之前的所有方法", "conclusion": "SSPO不仅在文本到图像基准测试中优于现有方法，还在文本到视频任务中表现出色。这种方法展示了同时保留SFT的训练稳定性和RL的泛化能力的可能性，有效解决了两者之间的平衡问题。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.00772", "html_url": "https://arxiv.org/abs/2406.00772", "title": "通过条件扩散模型的无监督对比分析在脑MRI中检测异常", "title_en": "Unsupervised contrastive analysis for anomaly detection in brain MRIs via conditional diffusion models", "authors": "Cristiano Patrício,Carlo Alberto Barbano,Attilio Fiandrotti,Riccardo Renzulli,Marco Grangetto,Luis F. Teixeira,João C. Neves", "background": "现有的对比分析（CA）方法依赖监督对比学习或变分自编码器（VAEs）来检测脑MRI中的异常，但这些方法需要使用特定的健康和非健康数据，这在临床上是个挑战。无监督异常检测（UAD）提供了一种替代方案，通过学习健康解剖结构的参考表示，而无需使用目标样本。由于在图像生成方面表现更优，扩散模型在UAD中逐渐被采用，但准确重建脑部解剖结构仍然是一个难点。本文探讨了如何通过训练健康图像上的自我监督对比编码器来提取有意义的解剖特征，从而改善脑部MRI的重建质量，并通过条件扩散模型实现可解释的异常定位。这种方法在面部图像数据集和四个脑部MRI数据集上进行了验证，特别是在NOVA基准上的异常定位性能上达到了最先进的水平。", "innovation": "本文提出了一个无监督框架，通过训练健康的自我监督对比编码器来提取有意义的解剖特征，使用这些特征来条件化扩散模型以重建给定图像的健康外观，从而实现像素级的可解释异常定位。这是通过对比分析技术与扩散模型相结合来进行无监督异常检测的一种创新方法。", "conclusion": "本文方法在面部图像数据集及四个脑部MRI数据集上进行了验证，特别是在NOVA基准上的异常定位性能达到了最先进的水平。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.12787", "html_url": "https://arxiv.org/abs/2411.12787", "title": "从整体到局部：高效视觉指令微调的局部增强适配器", "title_en": "From Holistic to Localized: Local Enhanced Adapters for Efficient Visual Instruction Fine-Tuning", "authors": "Pengkun Jiao,Bin Zhu,Jingjing Chen,Chong-Wah Ngo,Yu-Gang Jiang", "background": "论文探讨了如何通过最小的计算开销将多模态大型语言模型（MLLMs）适配到下游任务中，但随着任务多样性和复杂性的增加，EVIT在解决数据冲突方面遭遇了显著挑战。", "innovation": "提出了一种新的框架——双低秩适应（Dual-LoRA），通过双重结构优化增强适配器解决数据冲突的能力。此外，还引入了多级局部特征聚合模块视觉线索增强（VCE），以丰富视觉-语言投影的局部细节。该方法在内存和时间效率方面表现出色，仅需标准LoRA方法1.16倍的推理时间，以及4专家LoRA-MoE的73%的推理时间。", "conclusion": "通过大量下游任务和通用MLLM基准的实验验证了所提出方法的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.05769", "html_url": "https://arxiv.org/abs/2405.05769", "title": "探索基于文本指导的单幅遥感图像编辑", "title_en": "Exploring Text-Guided Single Image Editing for Remote Sensing Images", "authors": "Fangzhou Han,Lingyu Si,Zhizhuo Jiang,Hongwei Dong,Lamei Zhang,Yu Liu,Hao Chen,Bo Du", "background": "人工智能生成内容（AIGC）在遥感领域图像生成方面产生了显著影响，但遥感图像（RSI）编辑这一同样重要的领域却未受到足够关注。传统的基于深度学习的编辑方法通常涉及两个连续的阶段：生成和编辑。对于自然图像，这两个阶段主要依赖于大规模基准数据集预训练的生成主体，并通过视觉语言模型（VLMs）的文本指导。然而，这些方法对RSIs的应用变得不那么可行：首先，现有的生成RSI基准数据集未能完全捕捉RSI的多样性，不足以支持通用编辑任务。其次，单一文本语义对应多个图像语义，导致引入错误的语义。", "innovation": "为解决上述问题，本文提出了一种基于文本指导的RSI编辑方法，可以通过单一图像进行训练。采用多尺度训练方法来保持一致性，无需使用大量的基准数据进行训练，同时利用预训练的RSI VLMs和提示组合（PE）来确保准确性和可控性。实验结果表明，该方法在多个RSI编辑任务中优于现有方法，在CLIP评分和主观评估方面显示出显著优势。此外，研究了编辑后的RSIs支持灾害评估任务的能力，以验证其实用性。", "conclusion": "提出的基于文本指导的单一图像RSI编辑方法具有显著优势，已经在多个RSI编辑任务中表现优异，并可通过提示组合确保准确性和可控性，验证了编辑后的RSIs在实际灾害评估任务中的可行性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.13536", "html_url": "https://arxiv.org/abs/2411.13536", "title": "使用多视角评分蒸馏保持身份的3D头像风格化", "title_en": "Identity Preserving 3D Head Stylization with Multiview Score Distillation", "authors": "Bahri Batuhan Bilecen,Ahmet Berke Gokmen,Furkan Guzelant,Aysegul Dundar", "background": "3D头像风格化技术将现实中的面部特征转化为艺术化的表现形式，增强游戏和虚拟现实应用中的用户参与度。尽管已有意识地3D生成器取得了显著进展，但许多3D风格化方法主要提供近似正面视角，往往无法保留原始主题的独特身份，导致输出缺乏多样性和个性化。", "innovation": "提出了一种新的框架，通过使用负对数似然蒸馏（LD）增强身份保存并改善风格化质量。该方法结合了多视角网格分数和镜像梯度，并在3D GAN架构中引入了评分排名加权技术，实现了显著的定性和定量改进。此外，该研究还提供了一种有效的蒸馏过程，探讨了扩散模型和GAN之间的转换问题，重点关注身份保存的关键问题。", "conclusion": "该研究不仅推进了3D头像风格化的现状，还提供了关于扩散模型和GAN之间有效蒸馏过程的宝贵见解，重点关注身份保存问题。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.09158", "html_url": "https://arxiv.org/abs/2404.09158", "title": "StreakNet-Arch: 基于抑制散射网络架构的水下携带LiDAR-雷达成像", "title_en": "StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging", "authors": "Xuelong Li,Hongjun An,Haofei Zhao,Guangying Li,Bo Liu,Xing Wang,Guanghua Cheng,Guojun Wu,Zhe Sun", "background": "本文介绍了一种基于自研的水下携带LiDAR-雷达（UCLR）的StreakNet-Arch，该架构结合了自我注意机制和新型双分支交叉注意力（DBC-Attention），用于实时、端到端的二分类场景，以增强散射抑制。在受控水槽验证条件下，StreakNet-Arch在含有自我注意机制或DBC-Attention时，相比于传统的带通滤波和基于学习的MP网络以及CNN，在相似的模型大小和复杂度下，实现了更高的F1分数。并且实验证明，通过NVIDIA RTX 3060的实时基准测试，其平均成像时间保持恒定（54到84毫秒），远远优于传统方法（58到1257毫秒的线性增长）。为了促进进一步的研究，贡献了一个包含2695168个实际水下3D点云数据的公共镜像管相机图像数据集，该数据集已经展示了其在南海试验中的准确性。", "innovation": "本文的创新点在于提出了一种结合自我注意机制和新型双分支交叉注意力（DBC-Attention）的StreakNet-Arch架构，实现了提升水下携带LiDAR-雷达散射抑制效果。相较于传统的带通滤波和基于学习的MP网络以及CNN，在相似的模型大小和复杂度下，实现了更高的F1分数，并且在NVIDIA RTX 3060的实时基准测试中表现出了恒定的平均成像时间，优于传统方法。此外，该论文还贡献了一个公共可用的数据集以促进进一步的研究。在南海的试验表明，该系统具有较高的准确性和鲁棒性，误差在46毫米以内。", "conclusion": "综上所述，本文提出了一种基于抑制散射网络架构的水下携带LiDAR-雷达成像方案，通过自我注意机制和新型双分支交叉注意力提升了散射抑制效果，能够在真实条件下实现高性能和实时性，并且具有很强的稳定性和准确性，为后续的相关研究提供了有力支持。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.13949", "html_url": "https://arxiv.org/abs/2411.13949", "title": "SMoLoRA: 探索和克服连续视觉指令调优中的双重灾难性遗忘", "title_en": "SMoLoRA: Exploring and Defying Dual Catastrophic Forgetting in Continual Visual Instruction Tuning", "authors": "Ziqi Wang,Chang Che,Qi Wang,Yangyang Li,Zenglin Shi,Meng Wang", "background": "视觉指令调优（VIT）使多模态大型语言模型（MLLMs）能够通过将视觉任务框定为语言指令来有效处理多种视觉任务。在此基础上，连续视觉指令调优（CVIT）让MLLMs能够逐步学习新任务，适应不断变化的功能。尽管之前的工作通过开发新的基准和减轻灾难性遗忘的方法来推进CVIT，但这些努力大多遵循传统的连续学习范式，忽视了CVIT特有的挑战。研究发现了CVIT中的双重灾难性遗忘形式，即MLLMs不仅会忘记之前学习的视觉理解，还会随着新任务的获得而降低对指令遵循的能力。为了应对这一问题，提出了SMoLoRA框架，该框架通过两种不同模块实现分离路由，一个专注于视觉理解，另一个专注于指令遵循，从而实现特定领域的专业适应，阻止遗忘并提高性能。此外，还提出了一种新的CVIT基准，超越了现有的基准，进一步评估模型对未见过任务的泛化能力和处理各任务中多样化指令的能力。广泛的实验表明，SMoLoRA在解决双重遗忘、提高对未见过任务的泛化能力和确保多样性指令的性能方面都优于现有方法。", "innovation": "1. 提出了SMoLoRA框架，通过两种不同模块实现分离路由，一个专注于视觉理解，另一个专注于指令遵循，从而实现特定领域的专业适应，阻止遗忘并提高性能。2. 设计了一种新的CVIT基准，不仅评估模型如何减轻遗忘，还评估对其未见过任务的泛化能力和处理不同任务中多样化指令的能力。3. 证明了SMoLoRA在减轻双重遗忘、提高泛化能力以及确保多样性指令执行的鲁棒性方面优于现有方法。", "conclusion": "SMoLoRA框架通过分离路由设计，在视觉理解和指令遵循两个领域实现专业适应，有效地解决了双重灾难性遗忘问题，同时也提高了MLLMs在遇到新任务时的泛化能力和执行多样化指令的稳定性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.11281", "html_url": "https://arxiv.org/abs/2410.11281", "title": "DynaCLR: 采用时间正则化的细胞动力学对比学习", "title_en": "DynaCLR: Contrastive Learning of Cellular Dynamics with Temporal Regularization", "authors": "Eduardo Hirata-Miyasaki,Soorya Pradeep,Ziwen Liu,Alishba Imran,Taylla Milena Theodoro,Ivan E. Ivanov,Sudip Khadka,See-Chi Lee,Michelle Grunberg,Hunter Woosley,Madhura Bhave,Carolina Arias,Shalin B. Mehta", "background": "该项研究提出了DynaCLR方法，一种基于对比学习的自监督嵌入细胞和细胞器动力学的方法。DynaCLR结合了单细胞追踪和时间敏感对比采样，学习细胞动力学的稳健、时间调节表示。该方法能够有效地将嵌入应用于同分布和异分布的数据集，并且可以用于多个下游任务，即使仅提供了稀疏的人类标注。研究通过结合荧光和无标记成像通道展示了高效的人类参与的标注流程。DynaCLR方法使多种下游生物分析得以实现：细胞分裂和感染分类、异质细胞迁移模式聚类、荧光通道到无标记通道的细胞状态跨模态提炼、细胞响应的时间对齐以及感染引起的细胞器响应发现。这种方法为药物、微生物和遗传干预下的动态细胞响应的比较分析提供了一个灵活的工具。开源提供了DynaCLR模型训练和推断管道的PyTorch实现及GUI工具，用于细胞轨迹在真实空间和嵌入空间的可视化和标注。", "innovation": "DynaCLR方法通过结合单细胞追踪和时间敏感的对比采样，学习细胞动力学的稳健时间调节表示，适用于多种下游生物分析任务，提升了细胞动力学嵌入的效果和应用范围。开源提供了该方法的实现和GUI工具，便于实际应用和便捷的细胞轨迹标注。", "conclusion": "DynaCLR方法能够有效地嵌入细胞动力学，并适用于多种下游生物分析任务。该方法提供了一种灵活的方式，进行药物、微生物和遗传干预下的动态细胞响应的比较分析。开源实现了DynaCLR的方法，使其易于实际应用，包括高效的细胞状态标注和细胞轨迹分析。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.19278", "html_url": "https://arxiv.org/abs/2411.19278", "title": "OMNI-DC: 高度鲁棒的多分辨率深度集成深度完成", "title_en": "OMNI-DC: Highly Robust Depth Completion with Multiresolution Depth Integration", "authors": "Yiming Zuo,Willow Yang,Zeyu Ma,Jia Deng", "background": "深度完成（DC）旨在从RGB图像和稀疏深度图中预测密集的深度图。现有的DC方法在新数据集或未见过的稀疏深度模式上泛化能力较差，这限制了它们在现实世界中的应用效果。", "innovation": "提出了高度鲁棒的OMNI-DC深度完成模型，该模型能够在零样本的情况下泛化到各种数据集。该模型的关键设计是新型的多分辨率深度集成模块，使模型能够处理非常稀疏的深度输入。该研究还引入了一种新型拉普拉斯损失来建模训练过程中的模糊性。此外，使用高质量数据集的混合以及尺度规范化技术对OMNI-DC进行训练，并结合合成深度模式。广泛的实验在7个数据集上表明，相对于基线，平均错误降低了高达43%的效果提升。", "conclusion": "该研究通过使用多分辨率深度集成方法、新型拉普拉斯损失以及高质量数据集的混合训练，提出了高度鲁棒的OMNI-DC深度完成模型，在多个数据集上实现了显著的性能提升，显示出良好的泛化能力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.10736", "html_url": "https://arxiv.org/abs/2501.10736", "title": "基于多尺度不确定性一致性和跨教师-学生注意力的遥感图像半监督语义分割", "title_en": "Semi-supervised Semantic Segmentation for Remote Sensing Images via Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention", "authors": "Shanwen Wang,Xin Sun,Changrui Chen,Danfeng Hong,Jungong Han", "background": "半监督学习为遥感图像分割提供了诱人的解决方案，可减轻劳动密集型像素级标注的负担。然而，遥感图像具有独特的挑战，包括丰富的多尺度特征和高类间相似性。这些挑战限制了现有半监督算法的效果。因此，本研究旨在通过一种新的半监督多尺度不确定性与跨教师-学生注意力（MUCA）模型来解决这些挑战，以提升遥感图像语义分割任务中的性能和效果，特别是在区分高相似性对象方面。", "innovation": "本研究提出了一个多尺度不确定性一致性正则化和跨教师-学生注意力机制的MUCA模型，这是一种新的半监督方法。该模型通过引入多尺度不确定性一致性正则化来约束网络不同层之间特征图的一致性，提高了半监督算法在无监督数据上的多尺度学习能力。此外，MUCA使用跨教师-学生注意力机制指导学生网络，通过互补特征提升学生网络构建更具有区分性的特征表示能力。这种设计有效融合了弱增强和强增强技术，进一步提升了分割性能。实验结果表明，该方法在ISPRS-Potsdam和LoveDA数据集上优于现有的半监督方法，特别是在识别高度相似对象方面表现优异，展现了其在半监督遥感图像分割任务中的潜力。", "conclusion": "本文提出的MUCA模型在ISPRS-Potsdam和LoveDA数据集上的实验结果表明，该方法在半监督遥感图像语义分割任务中优于现有方法，特别是在区分高度相似的物体方面表现出色，为半监督遥感图像分割任务带来了新的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.01855", "html_url": "https://arxiv.org/abs/2501.01855", "title": "UAV-DETR: 效率高的端到端无人机影像目标检测", "title_en": "UAV-DETR: Efficient End-to-End Object Detection for Unmanned Aerial Vehicle Imagery", "authors": "Huaxiang Zhang,Kai Liu,Zhongxue Gan,Guo-Niu Zhu", "background": "无人机物体检测（UAV-OD）已在多种应用场景中得到广泛应用。然而，现有的UAV-OD算法大多依赖于手动设计的组件，需要大量调优工作。虽然端到端模型主要设计用于自然图像，但在无人机影像上的效果并不理想。因此，本文旨在解决这一问题，提出了一种针对无人机影像的高效目标检测转换器框架，即UAV-DETR。该框架包含多尺度特征融合与频率增强模块，能够捕捉不同尺度下的空间和频率信息。同时，还提出了一种频率聚焦下采样模块，以在下采样过程中保留关键的空间细节。此外，开发了一种语义对齐和校准模块，用于从不同融合路径中对齐和融合特征。", "innovation": "本文提出的UAV-DETR框架克服了现有算法依赖手动设计组件的问题，并针对无人机影像设计了多尺度特征融合与频率增强模块、频率聚焦下采样模块以及语义对齐和校准模块。该框架的有效性和泛化能力在各种无人机影像数据集上得到验证，特别是在VisDrone数据集上，相比基线方法提升显著。", "conclusion": "实验结果表明，该方法在VisDrone数据集上将AP提高了3.1％，AP_{50}提高了4.2％，并在UAVVaste数据集上也观察到类似改进。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.03628", "html_url": "https://arxiv.org/abs/2502.03628", "title": "通过视觉信息导向减少大型视觉语言模型幻觉的令牌生活", "title_en": "The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering", "authors": "Zhuowei Li,Haizhou Shi,Yunhe Gao,Di Liu,Zhenting Wang,Yuxiao Chen,Ting Liu,Long Zhao,Hao Wang,Dimitris N. Metaxas", "background": "大型视觉语言模型（LVLMs）能够有效地处理文本和视觉输入，但它们倾向于生成在语法规则上连贯但在视觉上不相关的内容。这种幻觉现象在生成过程中表现为视觉相关的令牌逐渐变得不如其他令牌受到青睐，且在早期层中蕴含的语义信息达到峰值激活，即使并非最终解码的内容依旧保持较高的排序。", "innovation": "该论文提出了VISTA（视觉信息导向与令牌逻辑增强相结合的干预框架），通过在激活空间强化视觉信息以及利用早期层的激活来促进有意义的解码。VISTA不需要额外的监督，适用于各种解码策略。实验结果表明，VISTA能够将幻觉减少大约40%，并在四种不同的基准测试中优于现有方法。", "conclusion": "实验结果证明，VISTA框架在多种解码策略下能有效减少LVLMs的幻觉现象，相比现有方法展现出更好的性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07707", "html_url": "https://arxiv.org/abs/2502.07707", "title": "PRVQL: 逐步知识引导的稳健第一人称视觉查询定位精炼", "title_en": "PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric Visual Query Localization", "authors": "Bing Fan,Yunhe Feng,Yapeng Tian,James Chenhao Liang,Yuewei Lin,Yan Huang,Heng Fan", "background": "Egocentric视觉查询定位（EgoVQL）旨在从第一人称视频中，通过给定的视觉查询来定位目标。现有方法难以处理视频中的严重对象外观变化和背景杂乱，因为缺乏足够的目标线索，导致性能下降。", "innovation": "提出了一种名为PRVQL的进步知识引导精炼框架，用于EgoVQL。其核心是通过视频连续利用目标相关的知识，并将其作为指导，以精炼查询和视频特征，从而提高目标定位。PRVQL包含多个处理阶段。每一阶段的目标知识被用于指导下一阶段的查询和视频特征精炼，以生成更准确的知识，进而进一步精炼特征。这种逐步的过程使得PRVQL中的目标知识可以逐步改进，从而导致更好的精炼查询和视频特征，最终提高定位性能。与以前的方法相比，PRVQL通过视频提供的目标信息，不仅可以利用给定的对象线索，还能增强EgoVQL在复杂场景中的表现。", "conclusion": "我们的实验在挑战性的Ego4D数据集上表明，PRVQL达到了最先进的结果，并大幅超越其他方法，证明了其有效性。我们的代码、模型和结果将发布在该网址：this https url。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07007", "html_url": "https://arxiv.org/abs/2502.07007", "title": "在物理学基础上激发创造力：AIGC中物理先验的简要综述", "title_en": "Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC", "authors": "Siwei Meng,Yawei Luo,Ping Liu", "background": "近年来，AI生成内容的发展显著提高了3D和4D生成的逼真度。然而，现有方法更注重外观一致性，忽略了物理本质，导致了不现实的变形、不稳定的动力学和不可靠的对象交互。将物理先验融入生成模型成为提升结构完整性和运动真实性的关键研究方向。", "innovation": "本文综述了物理感知生成方法，系统分析了物理约束如何集成到3D和4D生成中。首先，研究了将物理先验纳入静态和动态3D生成的最新工作，按表现形式分类，包括基于视觉、NeRF和Gaussian Splatting的方法。其次，探讨了新兴的4D生成技术，重点关注使用物理模拟建模时间动态的方法。最后，对主要方法进行了比较分析，突出了它们的优势、局限性和在不同材料和运动动力学中的适用性。通过深入分析基于物理学的AIGC，本文旨在弥合生成模型与物理真实之间差距，为未来物理一致内容生成的研究提供洞见。", "conclusion": "本文旨在桥接生成模型与物理真实之间的差距，通过对物理感知AIGC的深入分析，提供未来研究的启示，促进物理一致内容生成的新研究。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.13094", "html_url": "https://arxiv.org/abs/2501.13094", "title": "基于对比去噪的稳健表示一致性模型", "title_en": "Robust Representation Consistency Model via Contrastive Denoising", "authors": "Jiachen Lei,Julius Berner,Jiongxiao Wang,Zhongzhu Chen,Zhongjia Ba,Kui Ren,Jun Zhu,Anima Anandkumar", "background": "深度神经网络的鲁棒性在安全性关键应用中至关重要。随机化光滑提供了在对抗扰动下认证网络鲁棒性的理论保证。扩散模型被成功地用于在对模型进行预测之前净化噪声干扰的样本。然而，这些方法在处理大范围扰动时表现不佳，并且推理时的计算开销显著增加，这相比于古典方法更高。本文的目的是为了解决上述问题并提出了一种新的方法，将生成建模任务沿像素空间的扩散迹简化为潜在空间中的判别任务，通过实例判别在轨迹上实现一致表示。", "innovation": "提出了一种基于对比去噪的稳健表示一致性模型，通过实例判别在沿轨迹的点上实现了在时间上一致的表示，这种方法在推理阶段减少了大量计算成本，同时在各种数据集上取得了最先进的性能，并且在不同扰动范围内与基于扩散的方法相比，平均提高了5.3%的认证精度，最大提高了11.6%，同时减少了推理成本85倍。", "conclusion": "本文提出的模型通过对学习到的表示进行微调，实现了隐式的去噪和分类，仅需要一次预测，大幅度降低了推理成本，同时在多种数据集上取得了最先进的性能，验证了方法的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03704", "html_url": "https://arxiv.org/abs/2412.03704", "title": "使用视觉价值模型扩展推理时间搜索以提高视觉理解", "title_en": "Scaling Inference-Time Search with Vision Value Model for Improved Visual Comprehension", "authors": "Xiyao Wang,Zhengyuan Yang,Linjie Li,Hongjin Lu,Yuancheng Xu,Chung-Ching Lin,Kevin Lin,Furong Huang,Lijuan Wang", "background": "尽管视觉-语言模型（VLMs）已取得显著进展，但在提高生成响应的质量方面，缺乏有效的通过扩展推理时间计算能力的方法。这一能力被认为是近期大规模语言模型研究中自我改进模型的关键步骤。本文回顾了VLMs在生成高质量描述性说明时面临的挑战，特别是在视觉理解方面。", "innovation": "本文提出了视觉价值模型（VisVM），该模型能够在VLMs的推理过程中引导搜索，以生成具有更好视觉理解能力的响应。VisVM不仅评估当前生成句子的质量，还预测后续生成句子的质量，从而提供长期价值。VisVM能够引导VLMs避免生成容易产生幻觉或细节不足的句子，从而生成高质量的响应。实验结果表明，通过VisVM引导的搜索比贪婪解码和使用其他视觉奖励信号的搜索方法显著提高了VLM生成描述性说明的效果，增加了视觉细节并减少了幻觉。此外，使用VisVM引导的说明训练模型可以提高VLM在多种跨模态基准测试中的表现，显示出开发自我改进VLMs的潜力。", "conclusion": "实验结果表明，使用VisVM引导的搜索方法显著提高了VLMs生成具有更丰富视觉细节且较少幻觉的描述性说明的能力，相比于贪婪解码和其他使用视觉奖励信号的搜索方法。此外，使用VisVM引导的说明进行自我训练还可以提高VLM在多种跨模态基准测试中的表现，展示了其开发自我改进VLMs的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02091", "html_url": "https://arxiv.org/abs/2502.02091", "title": "Instruct-4DGS：基于4D高斯分布的静态-动态分离高效动态场景编辑", "title_en": "Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation", "authors": "Joohyun Kwon,Hanbyel Cho,Junmo Kim", "background": "最近的4D动态场景编辑方法需要处理成千上万个用于动态场景合成和更新的2D图像，并且需要额外的训练循环，这需要几小时才能编辑一个动态场景。因此，这些方法在时间维度上（即时间步数）不具可扩展性。现有方法在编辑时间上的复杂度成为了一个挑战。", "innovation": "本文提出了Instruct-4DGS，一种在时间维度上更具可扩展性的高效动态场景编辑方法。通过使用4D高斯表示来建模4D动态场景，并结合静止的3D高斯与基于六棱柱的变形场来捕捉动态信息，仅对静止的3D高斯进行编辑。为了修正编辑过程中的错位问题，引入了一种评分精炼机制。结果表明，Instruct-4DGS在编辑时间上比现有方法减少了一半以上，同时还能更好地遵循用户指令，实现高质量的编辑。", "conclusion": "Instruct-4DGS通过使用4D高斯表示和4D动态场景编辑过程中得静态-动态分离策略，实现了高效和可扩展的动态场景编辑，相对于现有方法大大减少了编辑时间，同时保持了高质量的编辑效果。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.07416", "html_url": "https://arxiv.org/abs/2504.07416", "title": "RadZero: 基于相似性的跨注意力在放射学中的可解释视觉-语言对齐与零样本多任务能力", "title_en": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "authors": "Jonggwon Park,Soobum Kim,Byungmu Yoon,Kyoyun Choi", "background": "近期，多模态模型在放射学领域的视觉-语言（VL）对齐方面取得了显著的进步。然而，现有方法难以有效利用复杂的放射学报告进行学习，并且通过注意力概率可视化提供的可解释性有限。因此，有必要提出一种新的方法来解决这些挑战。", "innovation": "该研究引入了RadZero，一个具有零样本多任务能力的新型放射学VL对齐框架。RadZero的核心是VL-CABS（基于相似性的跨注意力），它能通过可解释的细粒度VL推理将文本嵌入与局部图像特征进行对齐。RadZero利用大规模语言模型从放射学报告中提取简洁的语义句子，并采用多正例对比训练有效捕捉图像与多种相关文本描述之间的关系。它使用预先训练的视觉编码器和额外的可训练Transformer层，允许高效处理高分辨率图像。通过计算文本嵌入与局部图像补丁特征之间的相似度，VL-CABS能够进行零样本推理，输出相似概率进行分类，并生成像素级的VL相似图进行语义 grounding 和分割。实验结果表明，RadZero在零样本分类、语义定位和分割方面明显优于现有方法。此外，VL相似图分析进一步证实了VL-CABS在VL对齐解释性方面的潜力。定性的评估还展示了RadZero在开放词汇语义分割方面的潜力，进一步验证了其在医疗影像中的有效性。", "conclusion": "RadZero在零样本多任务场景下实现了可解释的VL对齐，在放射学领域的多个任务中表现出色，并且通过可视化分析，证明了其在解释性方面的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14156", "html_url": "https://arxiv.org/abs/2502.14156", "title": "Mixed Signals: 用于异构LiDAR V2X协作的多样化点云数据集", "title_en": "Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration", "authors": "Katie Z Luo,Minh-Quan Dao,Zhenzhen Liu,Mark Campbell,Wei-Lun Chao,Kilian Q. Weinberger,Ezio Malis,Vincent Fremont,Bharath Hariharan,Mao Shan,Stewart Worrall,Julie Stephany Berrio Perez", "background": "车辆到一切（V2X）协作感知已经成为了解决单车辆感知系统局限性的有希望的解决方案。然而，现有的V2X数据集在范围、多样性和质量方面都存在局限。为了弥补这些差距，本文介绍了Mixed Signals数据集，这是一个全面的V2X数据集，包含了来自三个连接的自动驾驶车辆（CAVs）的45.1万点云和240.6万边界框，这些车辆配备了两种不同配置的LiDAR传感器，以及一个配备了双LiDAR的路边单元。该数据集提供了10个类别的点云和边界框注释，保证了感知训练所需的可靠数据。", "innovation": "Mixed Signals数据集提供了全面的V2X注释，包括45.1万点云和240.6万边界框，覆盖了三种不同配置的LiDAR传感器以及一个配备双LiDAR的路边单元的车辆。该数据集详细分析了数据质量，广泛测试了现有的V2X方法，提供了精确对齐和一致注释的数据，适用于跨时间和视角的使用。", "conclusion": "Mixed Signals数据集为V2X协作提供了准备好的可靠数据，确保了训练的可靠性，并提供了广泛的方法评估，使得该数据集适用于即用场景。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14351", "html_url": "https://arxiv.org/abs/2502.14351", "title": "SegAnyPET: 从正电子发射断层扫描图像实现通用可提示分割", "title_en": "SegAnyPET: Universal Promptable Segmentation from Positron Emission Tomography Images", "authors": "Yichi Zhang,Le Xue,Wenbo Zhang,Lanlan Li,Yuchen Liu,Chen Jiang,Yuan Cheng,Yuan Qi", "background": "正电子发射断层扫描（PET）是一种关键的分子成像工具，对现代医学诊断至关重要。精确的器官分割对于多系统分析不同器官及病理间交互至关重要。但由于现有分割方法受限于标注数据不足和标注质量差异，导致其泛化能力较弱，难以在临床中广泛应用。尽管医学专用的分割基础模型在各种分割任务上具有较高的灵活性，但它们主要针对具有详细生理结构信息的结构性医学图像，并在分子PET成像中的泛化性能有限。本文收集并构建了迄今最大的PET分割数据集PETS-5k，包含5,731个三维全身PET图像和超过1.3M个二维图像。基于此数据集，本文提出了SegAnyPET，一种特定模态的3D基础模型，用于通用可提示的PET图像分割。为应对标注质量不一的问题，采用了交叉提示自信学习（CPCL）策略与不确定性指导的自我纠正过程，以从高质量标注数据和低质量噪声标注数据中稳健地学习分割。实验结果显示，SegAnyPET仅需一个或几个提示点即可分割已知和未知的目标器官，其准确率和泛化能力均优于现存的最好基础模型和特定任务的全监督模型。这使得SegAnyPET在PET图像的通用分割中表现出色。", "innovation": "本文提出了SegAnyPET，这是一种特定模态的3D基础模型，用于通用可提示的PET图像分割，并采用交叉提示自信学习（CPCL）策略与不确定性指导的自我纠正过程来应对标注质量不一的问题，从而提高了分割的准确率和泛化能力。", "conclusion": "实验结果表明，SegAnyPET在通用分割中表现出更高准确率和更强泛化能力，能够仅用一个或几个提示点分割已知和未知的目标器官，优于现有基础模型和特定任务的全监督模型。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.02424", "html_url": "https://arxiv.org/abs/2503.02424", "title": "在单幅图像中探索内在常态原型以实现通用异常检测", "title_en": "Exploring Intrinsic Normal Prototypes within a Single Image for Universal Anomaly Detection", "authors": "Wei Luo,Yunkang Cao,Haiming Yao,Xiaotian Zhang,Jianan Lou,Yuqi Cheng,Weiming Shen,Wenyong Yu", "background": "异常检测（AD）在工业检测中至关重要，但现有方法通常依赖于将测试图像与训练集中正常参考图像进行对比。然而，外观和位置的差异往往使这些参考图像与测试图像对齐变得复杂，从而限制了检测准确性。研究发现，大多数异常主要表现为局部变化，这意味着即便在异常图像内仍然存在有价值的正常信息。作者认为，这些信息对于异常检测是有用的，并且可能会更加对齐，因为异常和正常信息都源自同一张图像。因此，作者提出了一种名为INP-Former的新方法，该方法直接从测试图像中提取内在正常原型（INPs）。这种方法利用了测试图像中的正常信息，用于指导后续的重建过程，从而实现更准确的异常检测。", "innovation": "作者提出了一种新颖的方法INP-Former，该方法从测试图像中直接提取内在正常原型（INPs），而不是依赖训练集中的外部正常参考。具体而言，作者引入了INP提取器，它可以线性组合正常令牌来表示INPs，并且提出了INP一致性损失以确保INPs能够准确地代表测试图像中的正常性。此外，作者还提出了一种软挖掘损失，以在训练过程中优先考虑难以优化的样本。INP-Former在MVTec-AD、VisA和Real-IAD数据集上实现了最先进的性能，并展现出一定的零样本异常检测能力，表明其在异常检测任务中的多功能性和通用性。", "conclusion": "INP-Former在多种异常检测任务中取得了最先进的性能，并且展示了一定的零样本异常检测能力。该方法通过直接在测试图像中提取内在正常原型而不是依赖外部正常参考，显著提高了异常检测的准确性和鲁棒性，同时，方法的多功能性和通用性为工业检测提供了新的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.04065", "html_url": "https://arxiv.org/abs/2504.04065", "title": "实现检索增强视觉问答的协作参数知识校准", "title_en": "Enabling Collaborative Parametric Knowledge Calibration for Retrieval-Augmented Vision Question Answering", "authors": "Jiaqi Deng,Kaize Shi,Zonghan Wu,Huan Huo,Dingxian Wang,Guandong Xu", "background": "知识导向的视觉问答（KB-VQA）系统利用外部知识库检索的知识来回答复杂视觉相关的问题。知识检索和答案生成任务都需要精准地理解问题上下文和外部知识。然而，现有方法将这两个阶段视为独立模块，在训练过程中缺乏互动，这阻碍了参数化知识的双向共享，最终导致性能不理想。", "innovation": "提出了一种统一的检索增强问答框架，具备协作参数知识校准功能。该框架能够有效适应通用的多模态预训练模型，用于精细的知识密集型任务，同时使检索器和生成器在训练和推理时能够协作提高和分享其参数化知识。此外，引入了晚期交互机制以增强对问题和外部文档的细粒度理解，并提出了一种反思性回答机制，使模型能够明确评估和精炼其知识边界。", "conclusion": "该方法在多模型问答性能上取得了与最先进的模型相当的表现，达到了答案精度方面4.7%的显著提升，并且为基本MLLMs带来了平均7.5%的VQA性能提升。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07330", "html_url": "https://arxiv.org/abs/2503.07330", "title": "YOLO基检测模型中减少幻觉现象：重新审视非分布检测", "title_en": "Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection", "authors": "Weicheng He,Changshun Wu,Chih-Hong Cheng,Xiaowei Huang,Saddek Bensalem", "background": "在动态环境中，可靠的物体检测系统对于安全决策至关重要。基于出分布(OoD)检测的过滤技术通常被用作额外的安全措施，以过滤由对新型物体过自信引起的幻觉。然而，现有OoD基准测试下YOLO家族检测器及其过滤器的评估往往表现不佳。论文研究了性能瓶颈的根本原因，并提出了一种根本改善性能的方法。实验证实，现有OoD基准数据集中的图像实际上包含约13%的ID对象，这导致了标注的不准确，同时ID数据集中也含有OoD对象，影响了过滤器的决策边界，导致了显著不精确的性能评估。", "innovation": "第一，校准所有现有评估结果，发现现有OoD基准数据集中约13%的检测对象实际上是ID对象，而ID数据集中也存在OoD对象，影响过滤器的决策边界，导致性能评估不准确。第二，将减少幻觉视为检测器和过滤器的联合管道任务，通过精心合成与待检测物体语义相似的OoD数据集，对YOLO检测器进行微调，抑制物体得分，实现了在自动驾驶基准BDD-100K上整体幻觉错误减少88%，结合微调检测和过滤系统的显著性能提升。", "conclusion": "通过减少YOLO基础检测器中的幻觉，结合微调检测和过滤系统的性能得到了显著提升。所有代码和数据集均可在指定网址下载。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16889", "html_url": "https://arxiv.org/abs/2502.16889", "title": "超越诊断性能：揭示并量化病理基础模型中的伦理风险", "title_en": "Beyond Diagnostic Performance: Revealing and Quantifying Ethical Risks in Pathology Foundation Models", "authors": "Weiping Lin,Shen Liu,Runchen Zhu,Yixuan Lin,Baoshun Wang,Liansheng Wang", "background": "病理基础模型（PFMs）是为计算病理学定制的大规模预训练模型，它们在众多应用中取得了显著进展。PFMs通过利用大量数据的先验知识，简化了智能病理模型的开发流程。然而，研究团队识别出几个关键且相互关联的伦理风险，这些风险在现有研究中尚被忽视，但必须得到解决才能安全地将PFMs从实验室推广到临床应用。这些风险包括患者敏感信息的潜在泄露、模型性能在不同性别、种族和社会机构亚组间的差异，以及对诊断不相关的特征的依赖，这些特征降低了临床可靠性。", "innovation": "研究团队首次提出了定量分析PFMs中伦理风险的框架，包括隐私泄露、临床可靠性和群体公平性。他们提出了一个评估框架，系统地衡量关键的伦理关切维度：模型表示中患者敏感属性的可推断性程度，不同性别、种族和社会机构亚组间性能差异的程度，以及诊断不相关的特征对模型决策的影响。此外，他们还探究了这些伦理风险的根本原因，并通过实证验证了发现的结果。随后，提出了减轻这些风险的方向，以促进更加伦理健全的PFMs的开发。这项工作首次提供了一个定量和系统的伦理风险评估，强调了为PFMs制定伦理保障的迫切性，并提供了建立更值得信赖和临床稳健的PFMs的可操作建议。为了促进未来的研究和部署，评估框架将作为在线工具包发布，以支持伦理健全的PFMs的发展、审计和部署。", "conclusion": "这项研究强调了对PFMs实施伦理保障的紧迫性，并提供了可操作的见解，以构建更值得信赖和临床稳健的PFMs。通过发布评估框架作为在线工具包，该研究旨在帮助未来的相关研究和部署。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13327", "html_url": "https://arxiv.org/abs/2503.13327", "title": "Edit Transfer: 学习图像编辑的视觉上下文关系", "title_en": "Edit Transfer: Learning Image Editing via Vision In-Context Relations", "authors": "Lan Chen,Qi Mao,Yuchao Gu,Mike Zheng Shou", "background": "目前的文本方法在通过文本提示进行语义操作方面表现出色，但往往难以处理精确的几何细节（例如姿态和视点变化）。基于参考的编辑方法通常侧重于风格或外观，并且难以处理非刚性变形，而现有的方法如TIE和RIE在处理多种非刚性场景时效果不佳，因此需要一个能有效解决这些问题的新方法。", "innovation": "本文提出了一种新的编辑转移（Edit Transfer）方法，该方法从单个源-目标示例中学习并应用编辑变换到新的查询图像。通过从上下文学习中汲取灵感，使用DiT基础的文本到图像模型，提出了一种视觉关系的上下文学习范式，通过轻量级LoRA微调来捕捉少量示例中的复杂空间变换。这种方法在多种非刚性场景上大幅优于现有的TIE和RIE方法，证明了少样本视觉关系学习的有效性。", "conclusion": "编辑转移（Edit Transfer）方法通过学习一个源-目标的编辑变换来改进现有的文本和参考依赖编辑方法的不足，尤其在处理复杂的非刚性变换方面表现出色，利用少量的示例进行高效的微调，证明了其在图像编辑任务上的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05288", "html_url": "https://arxiv.org/abs/2504.05288", "title": "实时视觉知识的寻求与更新", "title_en": "Seeking and Updating with Live Visual Knowledge", "authors": "Mingyang Fu,Yuyang Peng,Dongping Chen,Zetong Zhou,Benlin Liu,Yao Wan,Zhou Zhao,Philip S. Yu,Ranjay Krishna", "background": "我们周围不断变化的视觉世界，包括实时新闻、社交媒体趋势、通过卫星图像和增强现实增强的全球基础设施变化。然而，用于自动化多种任务的多模态大型语言模型（MLLMs）难以保持最新，因为它们的固定训练数据集受到截止时间的限制。为了量化这种停滞现象，我们引入了LiveVQA数据集，这是首个专门支持研究及时视觉知识寻求和更新的107,143样本和12类数据集。LiveVQA基于2024年4月至2025年5月的近期新闻文章、视频平台和学术出版物，能够评估模型处理超越知识边界的新视觉信息的能力，并测试当前方法如何帮助更新这些模型。", "innovation": "我们提出了LiveVQA数据集，这是一种全新的多模态语义理解数据集，包含107,143个样本和12个类别，旨在支持关于实时视觉知识寻求与更新的研究。我们通过LiveVQA数据集和17个最先进的MLLMs进行了广泛的基准测试，发现由于知识截止时间之外的数据，模型在处理这些内容时存在显著的性能差距。我们还发现，通过使用工具或代理式的视觉寻求框架，性能得到了327%的提升。此外，我们探讨了参数高效调整（PEFT）方法，以更新MLLMs中的新视觉知识，并深入研究了更新MLLMs时适配器容量与模型能力之间的关键平衡问题。所有实验数据集和源代码均可在指定链接下载。", "conclusion": "我们的实验表明，及时更新MLLMs中的新视觉知识是可能的，并提出了参数高效调整（PEFT）方法来实现这一目标。此外，我们还讨论了适配器容量和模型能力之间的平衡问题，为未来研究提供了新的视角。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12652", "html_url": "https://arxiv.org/abs/2504.12652", "title": "AdaptoVision: 多分辨率图像识别模型以实现稳健且可扩展的分类", "title_en": "AdaptoVision: A Multi-Resolution Image Recognition Model for Robust and Scalable Classification", "authors": "Md. Sanaullah Chowdhury Lameya Sabrin", "background": "该论文介绍了一种新的卷积神经网络（CNN）架构AdaptoVision，旨在高效平衡计算复杂性和分类准确率。AdaptoVision通过使用增强残差单元、深度可分离卷积和分层跳跃连接，显著减少了参数量和计算需求，同时保持了在各种基准和医学影像数据集上的竞争力。实验证明，AdaptoVision在BreakHis数据集上达到了最先进的水平，在CIFAR-10上实现了95.3%的准确率，在CIFAR-100上实现了85.77%的准确率，且无需依赖任何预训练权重。该模型的简洁架构和战略性简化促进了有效的特征提取和稳健的泛化能力，特别适用于部署在实时和资源受限的环境中。", "innovation": "AdaptoVision结合了增强残差单元、深度可分离卷积和分层跳跃连接，显著减少了模型的参数量和计算需求，同时保持了与先进模型相当的性能。这项工作为解决计算资源受限环境下高效的图像分类问题提供了新的解决方案。", "conclusion": "实验结果表明，AdaptoVision在多个数据集上的表现优秀，尤其是在实时和资源受限环境中，具有高度的适用性和竞争力。该模型通过有效的特征提取和泛化能力，确保了在多种不同任务中的应用效果。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17269", "html_url": "https://arxiv.org/abs/2504.17269", "title": "向导文本引导的通用且无需训练的语义操控", "title_en": "Towards Generalized and Training-Free Text-Guided Semantic Manipulation", "authors": "Yu Hong,Xiao Cai,Pengpeng Zeng,Shuai Zhang,Jingkuan Song,Lianli Gao,Heng Tao Shen", "background": "文本引导的语义操控是指根据目标提示对生成图像中的语义进行编辑，以匹配源提示。虽然扩散模型具有强大的生成能力，能生成高保真的视觉内容，但现有方法通常需要耗时的微调（低效），不能很好地完成多项语义操控（扩展性差），并且缺乏对不同类型任务的支持（通用性有限）。进一步的研究发现，扩散模型中的噪声几何性质与语义改变之间存在强烈相关性。基于此，我们提出了一种新的基于噪声几何特性的$\textit{GTF}$方法。该方法具有通用性和无需训练的特点。", "innovation": "我们提出了一种新型的$\textit{GTF}$方法，该方法具有两方面创新点：1）通用能力：$\textit{GTF}$支持多种语义操控（如添加、删除和风格转换），并能无缝集成到所有基于扩散的方法中，具有跨模态的泛化能力；2）无需训练：$\textit{GTF}$仅通过控制噪声之间的几何关系即可生成高质量的结果，无需调优和优化。", "conclusion": "我们进行了广泛的实验，验证了$\textit{GTF}$方法的有效性，展示了其在语义操控领域的潜力，有望推动这一领域的前沿发展。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05469", "html_url": "https://arxiv.org/abs/2505.05469", "title": "从文本生成物理稳定且可构建的砖结构", "title_en": "Generating Physically Stable and Buildable Brick Structures from Text", "authors": "Ava Pun,Kangle Deng,Ruixuan Liu,Deva Ramanan,Changliu Liu,Jun-Yan Zhu", "background": "本文介绍了BrickGPT，这是首个能够从文本提示生成物理稳定砖块组合模型的方法。为实现这一目标，作者构建了一个包含大量物理稳定砖结构及其说明的大规模数据集，并训练了一个自动回归的大语言模型，利用下一个砖块的预测来预测将添加的下一个砖块。为了提高设计的稳定性，作者采用了高效的验证检查和物理感知回滚技术，在自动回归推理过程中使用物理定律和组装约束剔除不可行的标记预测。实验结果显示，BrickGPT生成的砖结构具有高稳定性、多样性和美观性，符合输入的文本提示。此外，作者还开发了一种基于文本的砖体纹理方法，生成彩色和纹理设计，展示了可以通过人工和机械臂组装的方法设计和构建这些结构。作者还 release 了一个名为 StableText2Brick 的新数据集，其中包含超过 47,000 个砖结构和 28,000 个独特的 3D 对象，并提供了详细的描述，同时在项目网站上发布了代码和模型。", "innovation": "本文创新性地提出了BrickGPT方法，首次可以通过文本提示自动生成物理稳定的砖块组合模型。通过构建物理稳定的数据集，并利用自动回归大语言模型预测下一个砖块，再通过物理验证和回滚提高设计稳定性，使得生成的砖结构不仅稳定，而且美观且多样。此外，还提出了一种基于文本的砖体纹理方法，可以生成彩色和纹理设计。这种方法能够被人工和机械臂组装并构建，展示了其实际应用潜力。", "conclusion": "本研究通过演示BrickGPT生成的砖结构和开发的基于文本的砖体纹理方法，展示了可从文本提示自动构建物理稳定且可组装的砖结构的实际能力，并通过数据集和公开的代码和模型，提供了详细的实施指南。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.00703", "html_url": "https://arxiv.org/abs/2505.00703", "title": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT", "title_en": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT", "authors": "Dongzhi Jiang,Ziyu Guo,Renrui Zhang,Zhuofan Zong,Hao Li,Le Zhuo,Shilin Yan,Pheng-Ann Heng,Hongsheng Li", "background": "近期大语言模型的发展表明，采用思维链（CoT）和强化学习（RL）策略能显著提升模型性能。然而，如何将这些推理策略应用到视觉生成领域仍是一个未被充分探索的领域。本文介绍了一种名为T2I-R1的新颖推理增强文本到图像生成模型，通过多级CoT推理过程结合RL进行优化，旨在改进视觉生成的不同阶段。", "innovation": "T2I-R1模型通过引入分层次的CoT推理过程（包括语义级CoT和标记级CoT），并在生成过程中采用双层协调的CoT-GRPO策略，通过奖励合集无缝优化生成过程中的两种CoT。相较于基线模型Janus-Pro，该模型在多个基准测试上表现更优，特别是在T2I-CompBench和WISE基准测试上分别提高了13%和19%，甚至超过了当前最先进的模型FLUX。", "conclusion": "通过应用我们的推理策略，T2I-R1模型不仅提高了文本到图像生成的性能，还在两个主要基准测试上表现超越了当前的领先模型FLUX，展示了其在视觉生成领域应用的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10685", "html_url": "https://arxiv.org/abs/2506.10685", "title": "防御性对抗CAPTCHA：一种基于语义驱动的自然对抗样本生成框架", "title_en": "Defensive Adversarial CAPTCHA: A Semantics-Driven Framework for Natural Adversarial Example Generation", "authors": "Xia Du,Xiaoyuan Liu,Jizhe Zhou,Zheng Lin,Chi-man Pun,Cong Wu,Tao Li,Zhe Chen,Wei Ni,Jun Luo", "background": "传统的验证码（ CAPTCHA）方案越来越容易受到由深度神经网络（DNN）支持的自动化攻击。现有的对抗攻击方法通常依赖于原始图像特征，造成的扭曲会影响人类的解释，限制了其在没有初始输入图像的情况下的应用。", "innovation": "本文提出了一种名为 Un sourced Adversarial CAPTCHA（DAC）的新型框架，能够生成高保真度的对抗样本，同时由攻击者指定的语义信息指导。通过利用大型语言模型（LLM），DAC 可以增强 CAPTCHA 的多样性并丰富语义信息。为了适应不同的应用场景，文章还探讨了白盒定向攻击和黑盒无定向攻击场景，并提出了两种针对定向和无定向攻击的机制。", "conclusion": "实验表明，由 BP-DAC 生成的防御性对抗验证码能够抵抗大多数未知模型的攻击，且生成的验证码对人类和 DNNs 都难以分辨。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X：统一空地一体的 Vehicle-to-Everything (V2X) 协作", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "尽管多车辆协作驾驶明显优于单车辆自主驾驶，传统的基础设施支持的V2X系统仍然受限于高昂的部署成本，并且在农村和郊区存在未覆盖的危险区域。因此，需要一种灵活的替代或补充方案。无人机作为空基感知工具提供了独特的优势，包括减少视线遮挡的鸟瞰视图、动态定位能力以及相比于固定基础设施显著更低的部署成本。为此，作者构建了AirV2X-Perception数据集，其中包括不同天气和光照条件下的城市、郊区和农村环境中的无人机辅助驾驶场景，总共持续6.73小时。该数据集支持开发和标准评价Vehicle-to-Drone (V2D)算法，填补了不断扩大的飞行辅助自动驾驶系统领域的关键空白。", "innovation": "AirV2X-Perception数据集利用无人机作为空基感知装置，创造了一种灵活的替代或补充固定路边单元（RSU）的解决方案。该数据集提供了多样的驾驶场景，有助于开发和评估Vehicle-to-Drone (V2D)算法，解决当前领域中的关键问题。无人机具备独特优势：减少视线遮挡的鸟瞰视图、动态定位能力以及显著低于固定基础设施的部署成本。", "conclusion": "AirV2X-Perception数据集提供了用于开发和评估Vehicle-to-Drone (V2D)算法的技术基础，填补了飞行辅助自动驾驶系统领域的空白，促进该领域的研究与发展。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10967", "html_url": "https://arxiv.org/abs/2506.10967", "title": "超越注意力或相似性：在MLLM中最大化条件多样性进行令牌剪枝", "title_en": "Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs", "authors": "Qizhe Zhang,Mengzhen Liu,Lichen Li,Ming Lu,Yuan Zhang,Junwen Pan,Qi She,Shanghang Zhang", "background": "在多模态大型语言模型（MLLMs）中，输入视觉令牌的长度通常远大于其文本对应物的长度，导致高昂的推理成本。许多研究试图通过去除冗余视觉令牌来解决这一问题。但当前方法要么依赖基于注意力的剪枝，保留了大量重复令牌；要么使用基于相似性的剪枝，忽略了指令相关性，从而导致性能不佳。", "innovation": "本文提出了一个新颖的视觉令牌剪枝方法CDPruner，通过对指令进行条件下的条件相似性定义，以最大化的条件多样性重新定义令牌剪枝问题，并利用行列式点过程（DPP）进行解决。该方法无需训练且适用于各种MLLM，实验表明，CDPruner在各种视觉-语言基准测试中建立了新的最优状态。通过DPP最大化条件多样性，选择的子集更好地代表输入图像，同时严格遵循用户指令，从而即使在高剪枝比例下也能保持较高性能。", "conclusion": "当应用于LLaVA时，与原始模型相比，CDPruner将FLOPs减少了95%，CUDA延迟减少了78%，但保持了94%的原始准确性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12747", "html_url": "https://arxiv.org/abs/2506.12747", "title": "唤醒扩散和状态空间模型在医学图像分割中的潜力", "title_en": "Unleashing Diffusion and State Space Models for Medical Image Segmentation", "authors": "Rong Wu,Ziqi Chen,Liming Zhong,Heng Li,Hai Shu", "background": "现有的医学影像分割模型往往是基于单一数据集训练的，这导致了当遇到未见过的器官或肿瘤时，这些模型缺乏鲁棒性。因此，开发一个能够在未见过的肿瘤类别的识别中表现出色的鲁棒模型对于推动医学影像应用至关重要。本研究集中在提出一种新的框架——DSM，它利用扩散和状态空间模型来分割超出训练数据的未知肿瘤类别。", "innovation": "DSM有两个观察点集，它们在修改后的注意力解码器内被训练以增强分类准确性。首先，模型使用基于对象的特征分组策略来学习器官查询，以捕捉器官级视觉特征。然后，通过专注于基于扩散的视觉提示来细化肿瘤查询，从而使模型能够精确分割未见过的肿瘤。此外，该模型还结合了由扩散指导的特征融合方法，以提高语义分割性能。通过集成CLIP文本嵌入，DSM能够捕捉类别敏感的类别，从而增强语言迁移知识，提高模型在各种场景和多标签任务中的鲁棒性。", "conclusion": "广泛的经验表明，DSM在各种肿瘤分割任务中表现更为出色。该研究的代码可在以下链接访问：提供的链接。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21541", "html_url": "https://arxiv.org/abs/2506.21541", "title": "StruMamba3D: 探索结构化Mamba以进行自监督点云表示学习", "title_en": "StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning", "authors": "Chuxin Wang,Yixin Zha,Wenfei Yang,Tianzhu Zhang", "background": "近年来，基于Mamba的方法通过利用具有高效上下文建模能力和线性复杂度的状态空间模型（SSM）在点云表示学习中取得了显著的效果。然而，这些方法仍然面临两个关键问题：SSM处理过程中破坏了3D点的邻接性，以及随着输入序列长度的增加，在下游任务中无法保留长期序列记忆。", "innovation": "为了克服这些问题，本文提出了一种新型的自监督点云表示学习范式——StruMamba3D。第一次，在设计空间状态并用作点之间空间依赖关系的代理。第二次，通过引入状态更新策略并与轻量级卷积结合，增强SSM，以促进空间状态之间的高效结构建模。第三次，通过引入序列长度自适应策略，减少了预训练的Mamba模型对输入长度变化的敏感性。实验结果表明，本方法在四个下游任务中的性能优越，并在没有投票策略的情况下，对于ModelNet40实现了95.1%的准确率，对于ScanObjectNN最具挑战性的分割实现了92.75%的准确率。", "conclusion": "实验结果表明，我们的方法在多个下游任务中的表现更为优越，并在没有投票策略的情况下实现了当前最佳的95.1%的ModelNet40准确率和92.75%的ScanObjectNN最具挑战性分割的准确率。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22099", "html_url": "https://arxiv.org/abs/2506.22099", "title": "BézierGS: 使用贝塞尔曲线高斯点积的动态城市场景重建", "title_en": "BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting", "authors": "Zipei Ma,Junzhe Jiang,Yurui Chen,Li Zhang", "background": "自动驾驶领域的现实街景重建对于开发真实的模拟器至关重要。现有方法主要依赖于对象姿态标注来重建和移动动态对象，这限制了大规模和广泛场景的重建能力，因为依赖高精度的物体标注。为了解决这个问题，本文提出了一种贝塞尔曲线高斯点积(BézierGS)的方法，这种方法通过学习可塑的贝塞尔曲线来表示动态物体的运动轨迹，充分利用了动态物体的时间信息，并通过可学习的曲线建模自动纠正姿态错误。通过在动态对象渲染中引入额外的监督和曲线间的一致性约束，实现了场景元素的合理且准确的分离与重建。实验结果表明，BézierGS在动态和静态场景重建以及新颖视图合成方面均优于当前最先进的方法，展示了其在大规模场景重建中的潜力和优势。", "innovation": "本文提出了一种新的方法——贝塞尔曲线高斯点积(BézierGS)，用于动态城市场景重建。该方法通过学习可塑的贝塞尔曲线来表示动态物体的运动轨迹，充分利用动态物体的时间信息，并通过学习模型自动纠正姿态错误。通过引入动态对象渲染的额外监督和曲线间的一致性约束，实现了场景元素的合理且准确的分离与重建。相比现有依赖高精度物体标注的方法，BézierGS方法能够在大规模和广泛场景的重建中表现更出色。", "conclusion": "通过广泛的实验，本文提出的方法BézierGS在Waymo Open Dataset和nuPlan基准测试中表现出色，尤其是在动态和静态场景重建以及新颖视图合成方面。这表明BézierGS在大规模场景重建中的潜力和优势，并为未来的自动驾驶模拟器开发提供了新的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.24625", "html_url": "https://arxiv.org/abs/2505.24625", "title": "从视频学习构建3D世界：通过3D视觉几何先验增强MLLMs", "title_en": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors", "authors": "Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang", "background": "先前的研究已经探讨了利用多模态大型语言模型（MLLMs）通过将3D场景解释为视频来理解3D场景的方法。这些方法通常依赖于全面的3D数据输入，如点云或鸟瞰图（BEV）地图。本研究在此基础上推进了这一领域，通过直接从视频数据理解并推理3D空间的能力，无需额外的3D输入。这种方法基于视频序列中提取3D先验信息，并将其与视觉标记结合后输入MLLM。实验显示，该方法在各种与3D场景理解和空间推理相关的任务中取得了显著的改进，所有这些都直接从视频源学习而来。尤其是在VSI-Bench评估中，不依赖显式3D数据输入的4B模型可以与其他现有最先进的方法竞争，甚至超越了Gemini-1.5-Pro.", "innovation": "我们提出了一种新颖且高效的方法——Video-3D Geometry Large Language Model（VG LLM），该方法通过3D视觉几何编码器从视频序列中提取3D先验信息，将其与视觉标记结合并输入MLLM。研究表明，该方法在多个与3D场景理解和空间推理相关的任务中表现优异，直接从视频数据学习而无需额外的3D输入，甚至在VSI-Bench评估中超越了Gemini-1.5-Pro.", "conclusion": "我们的方法不仅在多个与3D场景理解和空间推理相关的任务中取得了显著的改进，还证明了在不依赖显式3D数据输入的情况下，MLLMs可以从视频数据中直接学习并表现出与现有最先进的方法相媲美的性能，甚至在特定评估指标上超过了Gemini-1.5-Pro，展示了其在直接从视频理解和推理3D信息方面的潜力和优势。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22663", "html_url": "https://arxiv.org/abs/2505.22663", "title": "Training-Free Stylized Abstraction", "title_en": "Training Free Stylized Abstraction", "authors": "Aimon Rahman,Kartik Narayan,Vishal M. Patel", "background": "当前研究集中在生成视觉夸张但语义忠实的抽象表示，这些表示能够在保留识别能力的同时接受感知变形。不同之处在于与图像到图像的转换相比，生成这种风格化的抽象需要在保持身份线索的同时接受特定风格的差异，这对于处理不常见的个体尤其具有挑战性。现有框架往往需要通过微调来适应不同的风格和身份，这限制了它们的灵活性和应用场景。为了克服这些限制，研究人员提出了培训免费的框架，该框架利用视觉语言模型在推断时的可缩放性来提取与身份相关的特征，并结合一种新的跨域矫正流反转策略来基于风格特异性先验重建结构。", "innovation": "该论文提出了一种训练免费的框架，利用视觉语言模型（VLLMs）在推断时进行缩放来提取与身份相关的特征，并采用一种新的跨域矫正流反转策略，根据风格依赖的先验重建结构。该方法通过风格感知的时间调度动态地适应结构恢复，实现对主题和风格的高保真重建，并支持多轮抽象感知生成。此外，研究人员还为此领域的评估引入了名为StyleBench的GPT基于的人类对齐度量，适用于抽象风格，以往的像素级相似性度量在这里失效。这些实验在多种抽象类别（例如LEGO、毛绒娃娃、South Park）中显示出强大的泛化能力，展示了该方法的有效性和灵活性。", "conclusion": "该方法不仅能够处理多种抽象风格，还能在不进行微调的情况下生成多个抽象版本，展示了其在生成对抗网络和人工智能艺术创作等领域的实际应用潜力。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21980", "html_url": "https://arxiv.org/abs/2506.21980", "title": "R1-Track: 直接利用强化学习将多模态大语言模型应用于视觉对象跟踪", "title_en": "R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning", "authors": "Biao Wang,Wenwen Li", "background": "视觉单对象跟踪旨在通过初始帧中的目标状态，持续定位并在后续视频帧中估计目标的尺度。传统上，这一任务被定义为模板匹配问题，经历了从相关滤波器到双流网络再到单一流网络的发展阶段，这些方法取得了显著的进步。然而，这些方法通常需要显式的分类和回归建模，依赖于大规模数据集的监督训练，并局限于单一的跟踪任务，缺乏灵活性。近年来，多模态大语言模型（MLLMs）迅速发展，开源模型如Qwen2.5-VL展示了在基于任务的模型中的出色表现。这激发了直接将这些模型应用于视觉跟踪的兴趣。然而，实验表明Qwen2.5-VL在处理图像对的模板匹配（即跟踪任务）中表现不佳。研究者受深搜-R1的启发，使用基于规则的奖励函数，采用组相对策略优化（GRPO）强化学习方法，在小规模数据集上对Qwen2.5-VL进行了微调。生成的模型R1-Track在GOT-10k基准测试中表现出色，并且支持通过边界框或文本描述进行灵活初始化，同时保留了原始模型的大部分通用能力。我们还探讨了R1-Track的潜在改进空间。", "innovation": "本研究通过采用基于规则的奖励函数，使用组相对策略优化（GRPO）强化学习方法对Qwen2.5-VL进行了微调，生成了可灵活初始化且保留了原始模型大多数通用能力的R1-Track模型。该模型在GOT-10k基准测试中表现出色，展示了直接将多模态大语言模型应用于视觉对象跟踪的可能性，从而在灵活性和通用性方面取得了创新突破。", "conclusion": "此报告总结了截至2025年5月我们的发现，R1-Track模型在基于规则的奖励函数和GRPO强化学习方法的指导下，成功地将多模态大语言模型应用于视觉对象跟踪领域，展示了其在灵活性和通用性方面的优势。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19288", "html_url": "https://arxiv.org/abs/2506.19288", "title": "Da Yu: 朝向基于USV的水道监控与场景理解的图-caption", "title_en": "Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding", "authors": "Runwei Guan,Ningwei Ouyang,Tianhao Xu,Shaofeng Liang,Wei Dai,Yafeng Sun,Shang Gao,Songning Lai,Shanliang Yao,Xuming Hu,Ryan Wen Liu,Yutao Yue,Hui Xiong", "background": "自动化水道环境感知对于使无人水面艇（USV）理解其周围环境和做出明智决策至关重要。现有的水道感知模型主要集中在实例级对象感知（如检测、分割）。但由于水道环境的复杂性，现有的感知数据集和模型无法实现对水道的整体语义理解，限制了大规模监测和结构化日志生成。随着视觉语言模型（VLMs）的发展，通过图像描述引入了WaterCaption数据集，这是一个专为水道环境设计的细粒度、多区域长文本描述数据集，为视觉地理理解和空间场景认知提供了新的研究方向。", "innovation": "提出了适用于USV的可边缘部署的多模态大型语言模型Da Yu以及一种新的视觉到语言的投影器Nano Transformer Adaptor (NTA)。NTA在平衡计算效率和视觉特征的全局与细粒度局部建模能力方面表现出色，显著增强了模型生成长文本输出的能力。Da Yu在WaterCaption和其他几个图-caption基准上都超越了现有最先进模型。", "conclusion": "Da Yu在性能和效率之间实现了最优平衡，使其成为适用于USV的理想的图-caption解决方案，适用于水道监控和场景理解。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22554", "html_url": "https://arxiv.org/abs/2506.22554", "title": "连续互动：双向音视频动作建模及其大规模数据集", "title_en": "Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset", "authors": "Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Rakesh Ranjan,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer", "background": "人类交流涉及复杂的口头和非口头信号交互，对于传递含义和实现人际目标至关重要。为了开发具备社会智能的人工智能技术，研发能够理解和生成双向互动动态的模型至关重要。背景部分介绍了现有技术的局限性，即在理解和生成复杂人际互动时的不足，强调了目前对社会智慧AI的迫切需求，特别是对于虚拟代理、远程存在体验和多模态内容分析工具的发展。", "innovation": "该论文引入了连续互动数据集，这是一个包含超过4000小时跨多个场景面对面互动视频数据的大规模集合，共有4000多名参与者。利用该数据集，开发了一系列模型，这些模型可以从参与者及其对话者的声音和视觉行为中生成配对的运动姿态和面部表情。这些模型可以输入对话者的语音和视觉行为，并且具备控制情感响应和表达层次的功能，以及生成更相关语义的手势。论文还描述了评价这些双向运动模型质量的方法，展示了更直观和响应型的人机互动的潜力。", "conclusion": "通过这一创新性研究，研究人员针对社会智能AI的发展提出了新的模型和数据集，这些模型和数据集将推动虚拟代理、远程存在体验和多模态内容分析工具的进步，为更自然和协调的人机互动铺平道路。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22832", "html_url": "https://arxiv.org/abs/2506.22832", "title": "Listener-Rewarded Thinking in VLMs for Image Preferences", "title_en": "Listener-Rewarded Thinking in VLMs for Image Preferences", "authors": "Alexander Gambashidze,Li Pengyi,Matvey Skripkin,Andrey Galichin,Anton Gusarov,Konstantin Sobolev,Andrey Kuznetsov,Ivan Oseledets", "background": "在对齐文本到图像和文本到视频生成模型与人类意图方面，训练鲁棒且可泛化的奖励模型对于人类视觉偏好至关重要。然而，目前的奖励模型往往无法泛化，监督微调会导致记忆问题，要求复杂的标注管道。尽管强化学习（RL），特别是组相对策略优化（GRPO），提高了泛化能力，但发现了一个关键失败模式：当模型的推理轨迹与其独立且冻结的视觉-语言模型（“监听器”）评估同一个输出时，推理准确性显著下降。为此，研究人员引入了一种监听器增强的GRPO框架，通过监听器重新评估推理者的推理链，提供密集且校准的置信分数，从而塑造RL奖励信号。这鼓励推理者不仅正确作答，还要生成独立模型能够信服的解释。", "innovation": "该研究提出了监听器增强的GRPO框架，其中监听器重新评估推理者的推理链，提供密集且校准的置信分数，而不是简单的奖励信号。这种方法鼓励模型生成不仅正确的解释，还能够被独立模型信服的解释。实验结果表明，该方法在ImageReward基准测试中获得了最佳准确性（67.4%），并在大规模人类偏好数据集（1.2M投票）中显著提高了泛外部分布（OOD）性能（最高提升+6%），并且相较于强大的GRPO和SFT基线模型减少了推理矛盾。这些结果证明了基于监听器的奖励方案提供了一种可扩展且数据高效的路径，以实现视觉语言模型与精细的人类偏好对齐。", "conclusion": "研究成果表明，基于监听器的奖励机制为视觉语言模型与人类偏好对齐提供了一种可扩展且高效的数据路径。与现有基线相比，这种方法在推理准确性和一致性方面表现更佳。未来的工作将侧重于进一步提高模型对复杂视觉内容的解释能力。研究者也提供其推理模型供进一步研究使用。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23657", "html_url": "https://arxiv.org/abs/2506.23657", "title": "无标记物的脊柱可变形组织的术中跟踪", "title_en": "Towards Markerless Intraoperative Tracking of Deformable Spine Tissue", "authors": "Connor Daly,Elettra Marconi,Marco Riva,Jinendra Ekanayake,Daniel S. Elson,Ferdinando Rodriguez y Baena", "background": "无标记RGB-D成像在内固定骨科组织跟踪中是一种有前景的方法，具有高度的转化潜力。与骨内标记跟踪设备相比，无需标记的跟踪可以减少手术时间和复杂性。然而，这种方法的应用仅限于尸检研究。该论文介绍了首个用于脊柱手术的真实世界临床RGB-D数据集，并开发了用于捕获术前和术中脊柱状态之间变形的SpineAlign系统。同时还介绍了基于该数据集训练的一个术中分割网络，以及一种用于预测术中和术前场景中关键区域的注册的多任务框架——CorrespondNet。", "innovation": "介绍了首个用于脊柱手术的真实世界临床RGB-D数据集；开发了SpineAlign系统；提出了基于该数据集训练的术中分割网络；提出了用于预测术中和术前场景中关键区域的注册的CorrespondNet多任务框架。", "conclusion": "该研究展示了无标记物脊柱术中跟踪的可行性，通过实际应用数据集和新开发的系统框架，提高了术中跟踪的准确性和应用范围，具有重要的临床转化意义。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23918", "html_url": "https://arxiv.org/abs/2506.23918", "title": "图像思维在跨模态推理中的基础、方法和未来前沿", "title_en": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers", "authors": "Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R. Fung", "background": "近期，跨模态推理的进步得益于基于文本的思维链条（CoT）范式，该范式让模型在语言中进行推理。然而，这种方法将视觉视为静态背景，导致丰富的感知数据与离散符号思维之间存在着根本的‘语义缝隙’。人类认知超越语言，利用视觉作为动态的心理工作台。类似地，AI 的认知模式正经历从仅基于图像思考到能够基于图像进行思考的转变，标志着模型从工具性操作到内在想象的三个关键阶段的演变。", "innovation": "这项研究建立了图像思维范式的三大原则性框架，并详尽回顾了每个关键阶段的核心方法。同时，分析了评价基准和转型应用的关键景观，并指出了所面临的重要挑战和未来发展方向。通过提供结构化的概述，该研究旨在为更具强大且与人相符的跨模态AI未来的研究提供清晰的路线图。", "conclusion": "通过提供这个结构化的概述，作者希望为未来的跨模态AI研究提供一条清晰的道路，以构建更强大且与人相符的认知模型。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.03302", "html_url": "https://arxiv.org/abs/2401.03302", "title": "现实中的行动：利用YOLOv8和DeiT进行医学图像中脑肿瘤的异常感知诊断", "title_en": "Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT", "authors": "Seyed Mohammad Hossein Hashemi,Leila Safari,Mohsen Hooshmand,Amirhossein Dadashzadeh Taromi", "background": "脑肿瘤的可靠诊断仍具挑战性，因为其临床发病率较低。然而，现有的大部分方法忽视了这种低发病率问题。为此，本文提出了一种基于临床启发的抗异常的肿瘤检测和分类框架。该框架利用YOLOv8n在现实不平衡数据集（肿瘤与正常比为1:9；来自81名患者共计30,000个MRI切片）上微调进行检测，并提出了一种新的患者间（PTP）度量方法来评估诊断的可靠性。分类部分采用知识蒸馏技术，其中基于Data Efficient Image Transformer (DeiT)的学生模型从中ResNet152教师模型中提炼而出。学生模型在20个训练周期内达到0.92的F1分数，接近教师模型的0.97性能，但具有显著减少的计算资源需求。这一端到端的框架展示了强大的临床代表性异常分布数据中的稳健性，提供了符合临床实际情况的工具", "innovation": "本文提出了一个临床启发的抗异常肿瘤检测和分类框架，包括利用YOLOv8n在不平衡数据集上的检测方法，以及通过知识蒸馏实现高效分类的DeiT模型。此外，还提出了一种新的患者间（PTP）评估方法来衡量诊断的可靠性", "conclusion": "该端到端框架在临床代表性的异常分布数据中表现出高鲁棒性，为临床实际应用提供了一个有效的工具"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23897", "html_url": "https://arxiv.org/abs/2506.23897", "title": "PriOr-Flow:利用正交视图增强原始全景光流", "title_en": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View", "authors": "Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang", "background": "全景光流能够提供广泛的视野，但球面到平面投影（如等经纬投影）会导致严重的失真，尤其是在极地区域，这大大降低了传统基于透视的光流方法的性能。", "innovation": "提出了一种新的双分支框架PriOr-Flow，利用正交视图的低失真特性增强极地区域的光流估计。引入了Dual-Cost Collaborative Lookup (DCCL)算子，联合检索基本和正交成本体积中的相关性信息。同时，提出了Ortho-Driven Distortion Compensation (ODDC)模块，迭代地从两个分支中细化运动特征，进一步抑制极地失真。", "conclusion": "广泛的实验表明，PriOr-Flow适用于各种基于透视的迭代光流方法，并在公开的全景光流数据集上始终实现了最新的性能，为广角运动估计设定了新的基准。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22807", "html_url": "https://arxiv.org/abs/2506.22807", "title": "FreqDGT: 基于变压器的适应性动态图网络在跨被试EEG情绪识别中的应用", "title_en": "FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition", "authors": "Yueyang Li,Shengyu Gong,Weiming Zeng,Nizhuan Wang,Wai Ting Siok", "background": "脑机接口中的情绪识别依赖于脑电图（EEG）信号，因其高时间分辨率和捕捉真实情绪状态的能力而成为可靠和客观的工具。然而，跨被试的情绪识别仍存在个体差异、认知特质和情绪反应变化带来的挑战，这限制了其广泛应用。现有的方法难以克服这些挑战，尤其在跨被试情绪识别上表现不佳。", "innovation": "FreqDGT 是一种频率自适应动态图变换器，它通过集成框架系统地解决了上述问题。FreqDGT 引入了频率自适应处理（FAP），以根据神经科学证据动态加权相关频率带宽；采用了自适应动态图学习（ADGL）来学习输入特定的大脑连接模式；并实施了多尺度时间解缠网络（MTDN），结合了分层时间变换器和对抗特征解缠，以捕捉时间动态并确保跨被试的鲁棒性。实验结果证明，FreqDGT 显著提高了跨被试情绪识别的准确性，证实了将频率自适应、空间动态和时间分层建模相结合的有效性，并确保了个体差异的鲁棒性。", "conclusion": "FreqDGT 显著提高了跨被试情绪识别的准确性，验证了将频率自适应、空间动态建模与时间分层相结合的有效性，确保了系统在处理个体差异时的鲁棒性。该研究成果为基于EEG的情绪识别提供了一种新颖而有效的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23044", "html_url": "https://arxiv.org/abs/2506.23044", "title": "Ovis-U1 技术报告", "title_en": "Ovis-U1 Technical Report", "authors": "Guo-Hua Wang,Shanshan Zhao,Xinjie Zhang,Liangfu Cao,Pengxin Zhan,Lunhao Duan,Shiyin Lu,Minghao Fu,Xiaohao Chen,Jianshan Zhao,Yang Li,Qing-Guo Chen", "background": "本文介绍了Ovis-U1，这是一个具有30亿参数，集成了多模态理解、文本生成图像和图像编辑功能的统一模型。它建立在Ovis系列的基础上，采用基于扩散的视觉解码器和双向令牌精炼器相结合的方法，实现了与GPT-4o等领先模型相媲美的图像生成任务效果。与以往使用冻结的MLLM进行生成任务的模型不同，Ovis-U1 从语言模型开始进行统一训练，这种新方法在统一训练过程中更好地结合理解和生成任务，提高了性能。Ovis-U1 在多模态学术基准测试、文本生成图像和图像编辑方面都取得了优异的成绩，超过了最近的先进模型如Ristretto-3B和SAIL-VL-1.5-2B。", "innovation": "Ovis-U1 使用了一种新的统一训练方法，结合多模态理解和生成任务。这种方法避免了使用冻结的MLLM进行生成任务的问题，从而在统一训练过程中实现了更好的性能。这种新的方法提高了模型在多模态处理任务中的表现，尤其是在OpenCompass多模态学术基准测试、DPG-Bench和GenEval的文本生成图像任务以及ImgEdit-Bench和GEdit-Bench-EN的图像编辑任务中取得了更好的成绩，超越了现有的先进模型。", "conclusion": "Ovis-U1 作为Ovis模型系列的第一个版本，推动了多模态理解和生成编辑领域的边界。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.10747", "html_url": "https://arxiv.org/abs/2402.10747", "title": "全可微分拉格朗日卷积神经网络在物理知情降水现在天气预报中的应用", "title_en": "Fully Differentiable Lagrangian Convolutional Neural Network for Physics-Informed Precipitation Nowcasting", "authors": "Peter Pavlík,Martin Výboh,Anna Bou Ezzeddine,Viera Rozinajová", "background": "本文提出了一种结合数据驱动学习和物理知识的卷积神经网络模型，用于降水现在天气预报。该模型通过拉格朗日双U-网络（LUPIN）实现，结合了现有的基于外推的现在天气预报方法。", "innovation": "作者提出了一种名为LUPIN的拉格朗日双U-Net，该网络包括一个动态生成中尺度气流运动场的U-Net、一个可微半拉格朗日外推操作符以及一个不涉及气流的U-Net，用于随着时间增长和衰减降水。LUPIN能够在GPU加速下进行完全可微分的端到端训练和推理，并实时对数据进行数据驱动的拉格朗日坐标系统转换。该研究通过极端事件案例研究，对模型进行了定量和定性评估，表明LUPIN在相关基准模型中的性能或与其相当，甚至更优，为其他拉格朗日机器学习模型开辟了可能之路。", "conclusion": "通过将物理知情的拉格朗日卷积神经网络应用于降水现在天气预报，LUPIN不仅展示了在性能上的优势，而且为未来的天气预报研究提供了新的方法和技术路线。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06385", "html_url": "https://arxiv.org/abs/2503.06385", "title": "一个良好的起点很重要：通过数据驱动的权重初始化提升持续学习", "title_en": "A Good Start Matters: Enhancing Continual Learning with Data-Driven Weight Initialization", "authors": "Md Yousuf Harun,Christopher Kanan", "background": "为了适应现实世界的数据流，持续学习（CL）系统必须快速学习新的概念并保留和利用现有知识。在持续训练的深度神经网络（DNNs）中添加新信息时，对于新遇到的类别，分类器权重通常被随机初始化，导致初始训练损失高且不稳定。因此，为了达到最优收敛和精度，通常需要大量的训练时间，这增加了计算成本。", "innovation": "本文借鉴了Neural Collapse（NC）的理念，提出了一种数据驱动的权重初始化策略，以提高持续学习中的学习效率。这种方法利用了DNNs使用均方误差（MSE）训练时，最后一层的 Least-Square（LS）分类器可以由学习到的特征解析得出的特点，从而数据驱动地初始化分类器权重，使它们与特征分布相匹配，而不是采用随机初始化的方式。这种方法能够减少初始损失峰值，加速对新任务的适应。", "conclusion": "我们在大规模的持续学习环境中评估了我们的方法，展示了更快的适应速度和更好的持续学习性能。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.14153", "html_url": "https://arxiv.org/abs/2407.14153", "title": "De-LightSAM: 基于模态解耦的轻量级SAM在可推广医疗分割中的应用", "title_en": "De-LightSAM: Modality-Decoupled Lightweight SAM for Generalizable Medical Segmentation", "authors": "Qing Xu,Jiaxuan Li,Xiangjian He,Chenxin Li,Fiseha B. Tesem,Wenting Duan,Zhen Chen,Rong Qu,Jonathan M. Garibaldi,Chang Wen Chen", "background": "深度神经网络在不同模态的通用性和对未见领域的泛化能力对于医学图像分割至关重要。最近的SAM模型在各种自然场景中表现出强大的适应性，但在医学场景中其泛化能力受限，主要因为高昂的计算成本、需要手动注释的提示和解码过程中容易出现冲突的处理问题。", "innovation": "本文提出了一种基于模态解耦的轻量级SAM模型，命名为De-LightSAM。该模型通过设计轻量级的领域可控图像编码器（DC-Encoder），能够为不同模态生成区分性的视觉特征；引入自我补丁提示生成器（SP-Generator）自动生成高质量的密集提示嵌入，用于指导分割解码；设计查询解耦模态解码器（QM-Decoder），利用一对一策略为每个模态提供独立的解码通道，防止不同模态间的知识干扰；并设计了多模态解耦知识蒸馏（MDKD）策略，利用稳健的通用知识来补充领域特定的医学特征表示。实验表明，De-LightSAM在多种医学成像分割任务中优于最先进的模型，展现出卓越的模态通用性和泛化能力。此外，De-LightSAM只使用了SAM-H参数的2.0%，具有显著的参数效率优势。", "conclusion": "De-LightSAM在不同模态的医学图像分割中表现出卓越的通用性和泛化能力，且参数效率显著优于现有模型，适用于各种医学场景。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.10665", "html_url": "https://arxiv.org/abs/2402.10665", "title": "Soft Dice Confidence: 一个用于语义分割选择性预测的近最优置信度估计器", "title_en": "Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation", "authors": "Bruno Laboissiere Camargos Borges,Bruno Machado Pacheco,Danilo Silva", "background": "现有模型在提供不可靠预测时并没有选择性预测的能力，而选择性预测允许模型在不确定时选择不提供预测。现有的置信度评分函数要么忽视评估指标的具体性，要么需要额外的留出数据进行调整。因此，需要一种新的不需要调整的置信度评分函数，直接与Dice系数评估指标相匹配，以提高模型的可靠性和效率。Soft Dice Confidence (SDC) 作为一种简单的、无需调参的置信度评分函数，直接与Dice系数相匹配，受到研究者的关注。", "innovation": "作者提出了一种新的置信度评分函数——Soft Dice Confidence (SDC)，它不依赖于额外的调参数据或对特定评估指标的忽视，而是直接与Dice系数评估指标相匹配，通过理论证明在条件独立的情况下SDC接近最优。实验结果表明，SDC在六个公开的医疗成像基准测试和合成数据中均优于文献中所有先前的置信度估计器，即便这些估计器依赖额外的数据。", "conclusion": "Soft Dice Confidence (SDC) 是一种可靠的且高效的置信度估计器，适用于语义分割的选择性预测，能够提升模型在提供预测时的可靠性和效率。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12269", "html_url": "https://arxiv.org/abs/2506.12269", "title": "ICME 2025年视频会议用视频超分辨率大赛", "title_en": "ICME 2025 Grand Challenge on Video Super-Resolution for Video Conferencing", "authors": "Babak Naderi,Ross Cutler,Juhee Cho,Nabakumar Khongbantabam,Dejan Ivkovic", "background": "超分辨率（SR）是计算机视觉中的关键任务，专注于从低分辨率（LR）输入重建高分辨率（HR）图像。随着各种挑战在单图像超分辨率领域的推动，视频超分辨率（VSR）扩展到了时间域，旨在通过局部或双向传播等方法提升视频质量。本次挑战特别针对固定QPs下使用H.265编码的低分辨率视频，在低延迟场景中使用因果模型放大视频，以提高感知质量。挑战包括三个赛道：通用视频、讲话头视频和屏幕内容视频，并提供独立数据集用于训练、验证和测试。挑战中开放了一项新的屏幕内容数据集用于SR任务，并通过ITU-T Rec P.910的众包实现进行了主观测试评价。", "innovation": "挑战设计了针对视频会议的视频超分辨率任务，通过固定QPs下的H.265编码视频来提升视频质量，特别考虑了低延迟场景下使用因果模型的实际应用需求。挑战还引入了新的屏幕内容数据集，丰富了超分辨率的研究材料。此外，采用Crowdsourced方法进行主观评价，增加了评价的客观性与准确性。", "conclusion": "本次挑战通过设定特定场景下视频超分辨率的任务，既推动了技术的发展，又考虑了实际应用中的挑战，有效提升了视频质量，特别是屏幕内容的重建。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22568", "html_url": "https://arxiv.org/abs/2506.22568", "title": "最大分散，最大集中：提高MOP解的质量", "title_en": "Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions", "authors": "Gladston Moreira,Ivan Meneghini,Elizabeth Wanner", "background": "多目标优化问题（MOPs）通常需要在相互冲突的目标之间权衡，实现目标空间中的多样性和收敛性。本文提出了一种通过优化决策空间中的分散程度和目标空间中特定区域的收敛性，提高MOP解质量的方法。", "innovation": "该方法定义一个依据目标空间中决策者偏好构造成的兴趣区域（ROI），并通过使用均匀性度量增强决策空间中解的分散性。结合目标空间中的解聚集与决策空间中的解分散增强了Pareto最优解的搜索强度，同时增加了解的多样性。这种方法通过生成有效平衡分散和聚集的解，消除决策空间中解聚集导致的偏差，从而提高了解的质量和优化程度。", "conclusion": "初步实验表明，此方法通过生成既平衡分散又聚集的解，能改善多目标优化问题，减轻决策空间中解的聚集偏差，从而提高解的质量。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23491", "html_url": "https://arxiv.org/abs/2506.23491", "title": "ZonUI-3B：跨分辨率图形用户界面定位的轻量级视觉语言模型", "title_en": "ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "authors": "ZongHan Hsieh,Tzer-Jen Wei,ShengJing Yang", "background": "当前市场上的视觉语言模型（VLM）通常参数量庞大，这使得它们在消费级硬件上运行非常耗时且不现实。虽然这些模型在图形单元界面接地任务上表现出色，但它们的计算需求超出了消费级设备的能力。因此，迫切需要开发一种既能有效处理图形单元界面接地任务又能减轻计算负担的轻量级模型。ZonUI-3B模型就是在这样的背景下提出的，旨在解决大模型在实际应用中的问题，并提高整体性能和可训练性。", "innovation": "ZonUI-3B模型推出了几个创新点：(1) 利用一个包含24,000个跨平台、多分辨率数据集的例子，这些例子涵盖了移动设备、桌面和网页GUI屏幕截图，有效解决了高分辨率桌面环境中的数据稀缺性问题；(2) 采用两阶段微调策略，先进行跨平台的初步训练以建立稳健的GUI理解，然后针对高分辨率数据进行专门化微调以大幅提高模型的适应性；(3) 优化数据采集和冗余减少策略，证明了随机采样更少但冗余更少的数据子集可以达到类似大型数据集的表现，从而强调了数据多样性而非单纯数据量的重要性。通过实验验证，ZonUI-3B在标准GUI接地基准测试（包括ScreenSpot、ScreenSpot-v2和更具挑战性的ScreenSpot-Pro）中表现优异，取得了84.9%和86.4%的高精度，并超过了之前4B参数以下的模型。此外，消融实验进一步证实了平衡采样和两阶段微调在提升模型鲁棒性，特别是在高分辨率桌面场景中的关键作用。", "conclusion": "ZonUI-3B模型通过对跨分辨率GUI接地任务的优化，强调了在小型模型中提高性能和鲁棒性的潜力。其创新的两阶段微调策略和优化的数据采集方法使其能够在单个GPU（RTX 4090）上进行完整训练，并在多个图形用户界面接地基准测试中表现出色。ZonUI-3B模型为未来视觉语言模型应用于图形用户界面接地任务提供了新的研究思路和优化路径。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.04640", "html_url": "https://arxiv.org/abs/2502.04640", "title": "通过凸优化构建罗马", "title_en": "Building Rome with Convex Optimization", "authors": "Haoyu Han,Heng Yang", "background": "传统的三维重建技术，如结构从运动（Structure from Motion, SfM）方法，通常面临大规模和复杂场景下的优化难题，特别是在全局优化方面。此外，常规的优化方法可能需要复杂的初始估计和较长的计算时间，限制了其在大规模应用中的效率和灵活性。为了克服这些问题，本文提出了利用深度预测和凸优化简化全球束调整的方法，旨在提供一种更快、更高效且不需要初始估计的SfM解决方案。", "innovation": "本文提出了一种新的束调整公式（SBA，Scaled Bundle Adjustment）和一种严格的凸半定规划（SDP，Semi-Definite Programming）松弛方法来解决SBA问题，确保全局精确性。同时，本文还改进了凸优化方法的求解效率，通过Burer-Monteiro因子化方法和基于CUDA的信任域黎曼优化器（XM）解决了大型尺度下的SDP松弛问题。这种新方法被应用于SfM管道中，显著提高了重建质量，并展示了更强的效率和适用性。", "conclusion": "信息融合框架中的XM-SfM管道展示了在大规模重建中的卓越性能，与现有的SfM管道相比，不仅重建质量更好，而且计算速度更快、更加高效且不需要初始估计。这种方法为大规模三维重建提供了一种新的、强化的解决方案，对于未来的研究具有重要意义。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20485", "html_url": "https://arxiv.org/abs/2505.20485", "title": "在非同态数据中联邦学习中通过保留全局知识梯度来避免遗忘", "title_en": "Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data", "authors": "Abhijit Chunduru,Majid Morafah,Mahdi Morafah,Vishnu Pandi Chellapandi,Ang Li", "background": "联邦学习面临着数据异质性的挑战，现有方法如局部正则化、优化模型融合技术和数据共享等虽有效，但缺乏深入理解数据异质性对全局决策边界的潜在影响。本文通过玩具示例进行实验分析，揭示了现有方法会在局部训练中忘记全局决策边界，即便从预训练的最优权重开始也是如此。研究表明，全局决策边界的遗忘是一个重要问题，需要解决以提高联邦学习的性能。", "innovation": "本文提出了一种新的联邦学习框架FedProj，旨在解决全局决策边界的遗忘问题，并设计了一个新颖的服务器端集成知识转移损失来进一步校准全局决策边界。此外，FedProj还引入了一种基于公共未标记数据的阶段性记忆策略，该策略可以调节每个局部训练步骤的梯度更新，以提高模型的准确性和稳定性。", "conclusion": "实验结果表明，FedProj在非同态数据的联邦学习场景中显著优于现有的最先进的方法。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13504", "html_url": "https://arxiv.org/abs/2503.13504", "title": "CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception", "title_en": "CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception", "authors": "Rujia Wang,Xiangbo Gao,Hao Xiang,Runsheng Xu,Zhengzhong Tu", "background": "现有的多智能体协作感知系统通过共享传感器信息来提高每个智能体的感知能力，有效解决了传感器缺陷、遮挡和远距离感知等挑战。但这些系统通常通过传输包含大量非关键信息的中间特征图进行通信，这导致了高通信带宽需求。因此，需要一种既能提高通信效率又能保持感知能力的方法来克服这些限制.", "innovation": "文章引入了CoCMT，这是一种基于对象查询的协作框架，通过对关键特征的选择性提取和传输来优化通信带宽。此外，论文还提出了一种高效的查询变压器（EQFormer），以有效融合多智能体对象查询，并实施协同深度监督以增强各阶段之间的正向激励，从而提升整体性能。实验表明，CoCMT在通信效率和感知能力方面均优于现有最先进的方法，尤其是在V2V4Real数据集上，仅需0.416 Mb带宽，比SOTA方法减少83倍，同时提高AP70指标1.1个百分点，这是在带宽受限环境中实现协作感知部署效率突破的关键.", "conclusion": "CoCMT通过优化通信带宽和提高感知性能，展示了在带宽受限环境中进行协作感知部署的潜力，无需牺牲检测准确性，从而为实际应用提供了新的可能性。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10230", "html_url": "https://arxiv.org/abs/2506.10230", "title": "基于预测类条件的提示引导潜伏扩散生成3D前列腺MRI", "title_en": "Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation", "authors": "Emerson P. Grabke,Masoom A. Haider,Babak Taati", "background": "在医学成像领域的机器学习发展中，数据稀缺是一个主要挑战。现有的医疗潜伏扩散模型（LDM）策略通常依赖于短提示文本编码器、非医疗LDM或大量数据集。这些方法可能会限制性能和科学的可访问性。因此，研究者提出了一种新颖的LDM条件化方法来解决这些问题。", "innovation": "研究提出了一种名为CCELLA的新颖双头条件化方法，它同时对LDM U-Net进行自由文本临床报告和放射学分类的条件化。研究还提出了一种数据效率高的LDM框架，以CCELLA为中心，并提出了一种联合损失函数。研究方法在3D前列腺MRI上进行了评估，并在下游分类模型训练数据集中增加了由该方法生成的合成图像。方法在3D FID得分方面得到显著提升，并且在前列腺癌预测分类器训练中的准确性也有所提高，与仅使用真实图像的训练相比，使用该方法生成的合成图像进行训练的分类器达到了相似的性能。", "conclusion": "我们的方法在使用有限的数据和最少的人工注释的情况下，提高了合成图像质量和下游分类器性能。所提出的基于CCELLA的框架能够利用放射学报告和类条件LDM对高质量的医学图像进行合成，即使是在数据量较少和人力数据标注不足的情况下也能提升LDM性能和科学的可访问性。该研究的代码将在该链接（此 https URL）提供。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21319", "html_url": "https://arxiv.org/abs/2506.21319", "title": "用于增强MLLMs在可视化理解和重构的数据集", "title_en": "A Dataset for Enhancing MLLMs in Visualization Understanding and Reconstruction", "authors": "Can Liu,Chunlin Da,Xiaoxiao Long,Yuxiao Yang,Yu Zhang,Yong Wang", "background": "当前多模态大型语言模型（MLLMs）在自然图像理解方面表现出色，但在可视化理解方面存在困难。主要原因在于它们无法解码数据到可视化映射，并提取结构化信息。", "innovation": "本文提出了一种名为SimVec的紧凑且结构化的向量格式，用于编码图表元素，包括标记类型、位置和大小。同时，还提出了一套新的可视化数据集，包含图表的位图图像、相应的SimVec表示以及数据为中心的问答对，每个都有解释性链式思考句子。利用该数据集对最新的MLLMs进行了微调，并在实验中展示了微调在数据为中心的推理任务中的显著改进，同时SimVec还让MLLMs能够准确且紧凑地从图像中重构图表结构。", "conclusion": "实验结果显示，使用该数据集对MLLMs进行微调可以显著提高数据为中心的推理任务性能，并能够准确而紧凑地从图像重构图表结构。该数据集和代码在此网址可获取：this https URL。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00003", "html_url": "https://arxiv.org/abs/2507.00003", "title": "未决时如何决策：NeutroSENSE的不确定性感知入侵检测", "title_en": "Deciding When Not to Decide: Indeterminacy-Aware Intrusion Detection with NeutroSENSE", "authors": "Eyhab Al-Masri", "background": "随着物联网（IoT）环境的日益普及，入侵检测成为保证系统安全的关键技术。传统的入侵检测方法通常依赖单一算法或模型进行决策，但这些方法往往缺乏解释性和不确定性量化能力，特别是在边缘部署中，需要避免误报和漏报的风险。为了提升决策的透明度和可靠性，本研究提出了NeutroSENSE框架，结合了随机森林、XGBoost和逻辑回归等多种机器学习模型，并引入了 neutrosophic 逻辑来量化预测的信心程度，分解为可信度（T）、不可信度（F）和不确定度（I）三个部分。这种方法能更好地处理模型的不确定性，对于高不确定性的预测结果可以通过设定全球性和适应性类内阈值进行复查，从而提高整体系统的准确性和可解释性。", "innovation": "NeutroSENSE框架通过融合随机森林、XGBoost和逻辑回归等多种机器学习模型，并利用 neutrosophic 逻辑分析预测的不确定度组件，即可信度、不可信度和不确定度。它能够对不确定性强的预测结果进行标记，并设置全球性和适应性类内阈值进行复查。这种不确定性量化方式不仅提高了系统的准确率，还增强了其可解释性。特别是在边缘计算环境中，这种方法对于减少误报和漏报具有显著优势，从而支持更加可靠的人工智能辅助决策。", "conclusion": "通过实验验证，NeutroSENSE在IoT-CAD数据集上的准确率达到97%，并且误分类样本的不确定度显著高于正确分类样本。不确定度作为一个不确定性的代理指标，使得系统能够进行有信息的回避决策，并进行重点审查。该研究提供了逐步提升边缘和雾计算环境中物联网安全系统可信决策的实用框架。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00004", "html_url": "https://arxiv.org/abs/2507.00004", "title": "推理计算放大规模理论：通过定向随机技能搜索进行推理", "title_en": "A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search", "authors": "Austin R. Ellis-Mohr,Anuj K. Nayak,Lav R. Varshney", "background": "大型语言模型（LLMs）在训练和部署过程中消耗了大量的计算、能源和财务资源。虽然训练的缩放法则一直指导着该领域的进展，但推理成本现在成为了资源负担的重要组成部分，尤其是在侧重推理任务的模型中。目前对计算最优化的理解仅考虑模型大小、数据集大小和推理令牌的单独或固定组合，这种理解可能会忽略更高效的运营点。", "innovation": "本文引入了一种新的框架——定向随机技能搜索（DS3），将推理视为在学习技能图上的随机遍历。通过简化的表达实例，作者推导出了一系列封闭形式的表达式，涵盖了从任务成功到计算成本的不同推理策略，包括链式推理（CoT）和树式推理（ToT），使其能够根据任务难度和模型能力进行比较分析。同时，作者扩展了先前基于第一性原理的LLM训练三手机制，将推理过程纳入其中，并将DS3与描述LLM缩放行为的经验方法相结合。该框架理论上重现了实验观察到的模式，包括线性准确性与对数计算之间的关系、策略偏好随任务难度和模型能力的变化、即使在参数缩放下性能饱和，推理行为仍能引发的新兴行为，以及在统一分析框架内捕捉的多种投票行为（如最佳选择和多数投票）", "conclusion": "通过明确刻画训练和推理之间的交互依赖性，该框架加深了对理论的理解，并支持了原理性的算法设计和资源分配。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23309", "html_url": "https://arxiv.org/abs/2506.23309", "title": "SurgTPGS：基于文本提示高斯点云方法的语义3D手术场景理解", "title_en": "SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting", "authors": "Yiming Huang,Long Bai,Beilei Cui,Kun Yuan,Guankun Wang,Mobarak I. Hoque,Nicolas Padoy,Nassir Navab,Hongliang Ren", "background": "在现代手术研究和实践中，准确理解带有文本提示能力的3D手术场景对于手术规划和实时术中指导尤为重要。精准识别和交互手术工具及解剖结构是关键。然而，现有的研究主要集中在手术视觉语言模型、3D重建和分割上，缺乏支持实时文本提示3D查询的能力。", "innovation": "本文提出了SurgTPGS，一种新的文本提示的高斯点云方法来填补这一空白。SurgTPGS结合了Segment Anything模型和最先进的视觉语言模型，提出了一种3D语义特征学习策略。通过提取分割语言特征来实现3D手术场景重建，提供更深入的复杂手术环境理解。同时，提出了语义感知变形追踪，捕捉语义特征的无缝变形，提供更精确的纹理和语义特征重建。此外，引入了基于区域的语义信息指导训练的语义区域感知优化，特别提高了重建质量和语义平滑度。在两个真实世界的数据集上进行的全面实验显示了SurgTPGS在方法上的优越性，强调了它在革新手术实践中的潜在价值。", "conclusion": "SurgTPGS为开发下一代智能手术系统铺平了道路，通过提升手术精度和安全性。代码已发布在：<this https URL>。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.24124", "html_url": "https://arxiv.org/abs/2506.24124", "title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "title_en": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "authors": "Sixun Dong,Wei Fan,Teresa Wu,Yanjie Fu", "background": "传统的时序预测依赖于单一的数值输入，难以捕捉高层语义模式，原因是这些模式密集且无结构化。最近的方法尝试将时序表示为文本，使用大型语言模型（LLMs），但这些方法受限于令牌序列的离散性质，缺乏人类感知直觉，如识别视觉模式的能力。本文旨在通过提出一种多模态对比学习框架解决这些问题，将其原始时序数据转换为结构化的视觉和文本视角，进而增强时序预测的有效性。", "innovation": "论文提出了一个多模态对比学习框架，将原始时序数据转化为结构化的视觉和文本视角，并通过对比学习对齐这些视图，使得模型能够捕捉更丰富且互补的表示。此外，论文还引入了一个变量选择模块，利用对齐的表示来识别多变量预测中的最具信息量的变量。该方法在多个短期和长期预测基准上表现优于其他单一模态和跨模态基线。", "conclusion": "大量的实验表明，本文提出的方法在增强时序预测的有效性方面比其他单一模态和跨模态基线均表现出色，突出了模态对齐增强时序预测效果的有效性。代码可在提供的链接中获得。"}
{"llm_update_time": "20250702", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22397", "html_url": "https://arxiv.org/abs/2506.22397", "title": "使用引导条件流匹配去雾活体显微图像：在保真度和现实性之间找到一个平衡点", "title_en": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism", "authors": "Anirban Ray,Ashesh,Florian Jug", "background": "荧光显微镜是生命科学中科学研究的重要推动力。尽管高端共聚焦显微镜能够过滤掉焦外光，但更便宜且更易于获得的显微镜模式，如宽场显微镜，则无法实现这一点，导致图像模糊。计算去雾试图结合两者的优点，以保持低成本但清晰的图像。感知失真权衡告诉我们，可以优化数据保真度，如低MSE或高PSNR，或者优化现实度，通过感知度量如LPIPS或FID测量。现有方法要么优先考虑保真度而牺牲现实度，要么产生看起来有说服力但缺乏定量准确性的结果。", "innovation": "本文提出了一种新的迭代去雾方法——HazeMatching，该方法有效平衡了上述目标。通过调整条件流匹配框架，指导生成过程的方法被引导为在条件速度场中采用模糊观察，从而实现去雾结果保真度与单个预测（样本）现实度之间的平衡。该方法在5个数据集上进行评估，涵盖了合成数据和真实数据，评估了失真和感知质量。该方法与7个基线进行了比较，平均而言实现了保真度和现实度之间的稳定平衡。此外，通过校准分析表明，HazeMatching 生成的预测是经过校准的。该方法不需要显式的退化操作符，使其容易应用于实际显微镜数据。所有用于训练和评估的数据以及代码将在宽松的许可证下公开。", "conclusion": "HazeMatching 方法通过将失真度和感知质量相结合，能够平衡去雾结果的保真度和单个预测的现实度。它在5个数据集上展示了稳定的保真度和现实度之间均衡，并且生成的预测是经过校准的。该方法还适用于实际显微镜数据，并且所有相关的数据和代码将公开发布。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00002", "html_url": "https://arxiv.org/abs/2507.00002", "title": "超代币： tokenized 大语言模型中的全息关联记忆", "title_en": "Hypertokens: Holographic Associative Memory in Tokenized LLMs", "authors": "Christopher James Augeri", "background": "大语言模型（LLMs）表现出显著的能力，但在精度方面存在明显损失，这种损失被重新定义为信息扩散。这种重新定义将问题从计算精度转变为信息论通信问题。现有的内存管理和信息检索方法在大语言模型中面临K:V和V:K问题，导致信息精确度下降。", "innovation": "本文引入了HDRAM（Holographically Defined Random Access Memory），这是一种基于超代币（hypertokens）的符号记忆框架，处理转换器潜在空间作为扩展谱通道。HDRAM结合了超代币、结构化的符号代码（包括经典的纠错码ECC），全息计算和量子启发式搜索等技术，通过原则性的去扩频恢复分散的信息，实现了高效的关键值操作和Grover风格的潜在空间搜索。该方法通过结合ECC语法、压缩感知和Krylov子空间对齐，显著提高了关联检索性能，而无需改变架构，表明了经典-全息-量子启发（CHQ）原理如何加强转换器架构.", "conclusion": "HDRAM在不改变架构的情况下，通过经典-全息-量子启发原理强化了大语言模型的性能，提高了关联检索效果。这种新的存储和检索方式为大语言模型的精确度和效率带来了新的可能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00013", "html_url": "https://arxiv.org/abs/2507.00013", "title": "ST-MTM: 基于季节趋势分解的掩蔽时间序列建模方法用于时间序列预测", "title_en": "ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting", "authors": "Hyunwoo Seo,Chiehyeon Lim", "background": "复杂时间序列的预测是一个重要但具有挑战性的问题，适用于各种工业应用场景。近年来，掩蔽时间序列建模已经提出，通过从不可掩蔽部分重建掩蔽段来有效建模时间依赖性进行预测。然而，由于时间序列中的语义信息涉及由多种时间序列成分产生的复杂时间变化，直接掩蔽原始时间序列会忽略固有的语义结构，可能导致掩蔽时间序列建模MTM学习到原始数据中存在的虚假时间模式。", "innovation": "我们展示了掩蔽建模技术应该通过分解方法解决纠缠模式来捕捉不同的时间语义。为此，我们提出了ST-MTM，这是一种包含季节趋势分解的掩蔽时间序列建模框架，其中包括一个新颖的掩蔽方法，该方法综合了每个成分的不同时期变化。ST-MTM使用周期性掩蔽策略为季节成分产生基于固有周期性的多个掩蔽季节序列，并使用子序列掩蔽策略为趋势成分掩蔽具有相似变化的时间区域。提出的掩蔽方法为学习复杂的时间变化和依赖关系提供了一个有效的预训练任务。此外，ST-MTM引入了一个对比学习任务，以增强多个掩蔽季节表示之间的上下文一致性，支持掩蔽建模。", "conclusion": "实验结果表明，我们提出的ST-MTM在时间序列预测方面优于现有的掩蔽建模、对比学习和监督预测方法，具有一致的优越预测性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00011", "html_url": "https://arxiv.org/abs/2507.00011", "title": "新型的RL方法在高效电梯群控制系统中的应用", "title_en": "Novel RL approach for efficient Elevator Group Control Systems", "authors": "Nathan Vaartjes,Vincent Francois-Lavet", "background": "在大型建筑中，高效电梯交通管理对于减少乘客旅行时间和降低能耗至关重要。现有的基于启发式或模式检测的控制器难以应对电梯调度的随机性和组合性，因此需要一种新的方法来优化电梯调度.", "innovation": "创新之处包括：引入了一种新颖的动作空间编码以处理电梯调度的组合复杂性；提出了基础设施步来模拟连续的乘客到达；设计了特定的奖励信号以提高学习效率；并且探讨了适应基础设施步形式的折扣因子的各种方法。基于 Dueling Double Deep Q-learning 的RL架构研究表明，所提出的基于RL的电梯群控制系统能够适应波动的交通模式，从高度随机的环境中学习，并优于传统的基于规则的方法.", "conclusion": "通过使用基于RL的方法，能够优化电梯调度，适应变化的交通模式，从高随机性环境中学习，并优于传统的基于规则的方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00019", "html_url": "https://arxiv.org/abs/2507.00019", "title": "量子启发的数据编码策略：提出和评估实例级、全局离散和类条件表示", "title_en": "Quantum Inspired Encoding Strategies for Machine Learning Models: Proposing and Evaluating Instance Level, Global Discrete, and Class Conditional Representations", "authors": "Minati Rath,Hema Date", "background": "该研究旨在通过将经典数据转换为量子数据来优化经典机器学习模型的性能，尤其是在处理高编码时间和保持正确编码值方面。研究基于三种不同的量子启发数据编码策略：实例级策略（ILS）、全局离散策略（GDS）和类条件值策略（CCVS），评估这些策略对分类性能的影响，以提供优化量子启发数据变换方法对经典机器学习工作流的见解。", "innovation": "研究引入了三种新的量子启发数据编码策略，并对它们进行了评估和比较。这些策略能够更好地处理数据变换问题，尤其是在减少编码时间和保持数据准确性的基础上，针对不同应用场景设计了不同的编码方式，提高了机器学习模型的效率和性能。", "conclusion": "通过分析编码效率、准确性、模型精度和计算成本之间的权衡，本研究提供了关于如何优化量子启发数据转换方法以适应经典机器学习流程的见解。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00016", "html_url": "https://arxiv.org/abs/2507.00016", "title": "通过先训练模型正则化进行梯度基于的微调", "title_en": "Gradient-based Fine-Tuning through Pre-trained Model Regularization", "authors": "Xuanbo Liu,Liu Liu,Fuxiang Wu,Fusheng Hao,Xianglong Liu", "background": "大规模预训练模型在多个领域展现了广泛的应用，但这些模型针对特定下游任务进行微调时需要大量的计算资源和存储空间。一种名为基于梯度的参数选择（GPS）的微调方法，只关注在每次神经元中具有高梯度的参数进行微调，以减少训练参数的数量，但这会增加计算资源需求和存储要求。", "innovation": "本文提出了一种高效且正则化的基于梯度的微调方法（GRFT），该方法更新了权重矩阵的行或列。理论证明，具有最高梯度平方和的行或列是最优更新的。此外，引入了正则化以增强知识迁移。GRFT在FGVC和VTAB数据集上只需要更新总参数的1.22%和0.30%，在性能上超越了现有方法，包括GPS、适配器调整和LoRA。", "conclusion": "GRFT方法不仅可以优化参数选择，减少存储需求，还能高效且有效地实现知识迁移，并在实验中表现出最先进的性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00015", "html_url": "https://arxiv.org/abs/2507.00015", "title": "对抗性指标标记的视觉变换器在无线信号分类中的对抗性攻击防御", "title_en": "Vision Transformer with Adversarial Indicator Token against Adversarial Attacks in Radio Signal Classifications", "authors": "Lu Zhang,Sangarapillai Lambotharan,Gan Zheng,Guisheng Liao,Xuekang Liu,Fabio Roli,Carsten Maple", "background": "变压器在自然语言处理和计算机视觉领域的显著成功为它们在自动调制分类中的应用铺平了道路，这是物联网（IoT）设备通信系统的关键组件之一。然而，已观察到基于变压器的无线电信号分类对微妙而复杂的对抗性攻击是脆弱的。为了应对这种情况，我们为基于变压器的调制分类系统开发了一种防御策略，以抵御对抗性攻击。我们通过引入一个名为对抗性指标（AdvI）标记的新概念来提高视觉变换器（ViT）的检测能力。", "innovation": "这是首次在视觉变换器中提出对抗性指标（AdvI）标记以防御对抗性攻击的工作。我们将对抗性训练方法与使用AdvI标记的检测机制结合起来，在统一的神经网络模型中实现了训练时间防御和运行时间防御。这种方法比使用单独模型检测对抗性扰动更为简单，并展示了AdvI标记作为ViT中关键组成部分的功能，它可以影响注意力权重，从而突出输入数据中的可疑或异常区域或特征。实验结果显示，在白盒攻击场景中，我们的方法优于多种竞争方法，包括使用快速梯度方法、投影梯度下降攻击和基本迭代方法的方法。", "conclusion": "我们的工作提出了一种新颖的方法，通过引入对抗性指标（AdvI）标记，结合对抗性训练和即时检测，有效地防御对抗性攻击。实验证明，我们的方法在处理白盒攻击场景时表现出优于其他竞争方法的效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00014", "html_url": "https://arxiv.org/abs/2507.00014", "title": "SWE-Bench-CL：编码代理的连续学习", "title_en": "SWE-Bench-CL: Continual Learning for Coding Agents", "authors": "Thomas Joshi,Shayan Chowdhury,Fatih Uysal", "background": "大型语言模型（LLMs）已经在静态代码生成基准测试中取得了显著成果，但在实际软件开发中，开发者需要处理一系列不断演变的问题、修复和功能请求，这是一个连续的过程。OpenAI 和 Princeton-NLP 在 2024 年引入了 SWE-Bench Verified 数据集，创建了一个新型的持续学习基准 SWE-Bench-CL。该基准通过按时间顺序组织 GitHub 问题，反映了自然的仓库演化过程，使研究者能够评估模型在知识积累、任务间迁移和防止灾难性遗忘等方面的能力。为了补充数据集，该研究还进行了任务间结构相似性和上下文敏感性的初步分析，并开发了一个基于 LangGraph 的交互式评估框架，该框架结合了一个 FAISS 支撑的语义记忆模块。同时，研究人员还提出了专门的持续学习度量标准，包括平均准确率、遗忘程度、正向/反向迁移、工具使用效率以及综合持续学习得分和 CL-F-beta 得分，以捕捉稳定性和可塑性之间的权衡。最后，通过比较具有和不具记忆能力的代理模型，研究人员在多个 Python 仓库中进行了严格的实验，并公开了所有代码和数据，为软件工程领域提供了可复现的平台，促进更适应和稳健的 AI 代理的发展。", "innovation": "1. 创建了 SWE-Bench-CL 持续学习基准，通过时间序列组织 GitHub 问题，更好地模拟实际开发过程。\n2. 提出了专门的持续学习度量标准，包括综合持续学习得分和 CL-F-beta 得分。\n3. 开发了基于 LangGraph 的交互式评估框架，结合了 FAISS 支撑的语义记忆模块，增强了模型的评估能力。", "conclusion": "该研究通过严格的实验，比较了具有和不具记忆能力的代理模型在多个 Python 仓库中的表现，提供了公开的代码和数据，旨在促进更适应和稳健的 AI 代理在软件工程中的发展。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00018", "html_url": "https://arxiv.org/abs/2507.00018", "title": "隐式奖励作为桥梁：SFT和DPO连接的统一视角", "title_en": "Implicit Reward as the Bridge: A Unified View of SFT and DPO Connections", "authors": "Bo Wang,Qinyuan Cheng,Runyu Peng,Rong Bao,Peiji Li,Qipeng Guo,Linyang Li,Zhiyuan Zeng,Yunhua Zhou,Xipeng Qiu", "background": "在将预训练语言模型落地到具体应用场景时，通过示例学习或偏好信号进行调适的后训练过程至关重要。传统的指导微调(SFT)方法和直接偏好优化(DPO)等偏好学习方法在实现这一目标中扮演重要角色，但它们各自已有独立的理论框架。研究人员希望找到一种统一的方法来理解这两种调优方法之间的联系和差异，以期实现更好的性能提升和理论指导.", "innovation": "文章提出了一个将SFT和偏好学习方法统一到同一理论框架下的方法。研究揭示了传统SFT的一个关键缺陷：在此过程中，KL散度项在匹配分布时变为常数，无法有效指导模型更新。为解决这一问题，研究提出了一种简单有效的学习率降低方法，显著提升了指令跟随任务的效果。此外，通过不同f-散度函数从偏好学习出发，推导出新的SFT目标函数，保留了KL散度项，从而进一步提升后-DPO模型的性能。最后，研究将偏好学习中的LLM输出与Q函数的关系延伸到SFT的情境中，提供了数学推导和实验验证.", "conclusion": "研究深化了对SFT和DPO之间内在关联的理解，并通过理论分析和实验验证提出了改进措施，展示了在指令遵循任务中显著的性能改进（相对收益增加至25%，绝对胜率提升6%）以及更复杂的f-散度后-DPO模型的性能更新。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00022", "html_url": "https://arxiv.org/abs/2507.00022", "title": "GLU Attention 提升Transformer", "title_en": "GLU Attention Improve Transformer", "authors": "Zehao Wang", "background": "Gated Linear Units (GLU) 已经显示出在增强神经网络性能方面的巨大潜力。本文介绍了一种新的注意力机制——GLU Attention，该机制在注意力的值中引入非线性。实验表明，GLU Attention 可以在文本和视觉模态中提高模型性能和收敛速度，同时不增加额外的参数，计算成本也几乎可以忽略不计。", "innovation": "提出了 GLU Attention，一种在注意力值中引入非线性的机制。GLU Attention 能在不增加额外参数和几乎不增加计算成本的情况下，改善 Transformer 模型在文本和视觉模态中的性能和收敛速度。此外，GLU Attention 轻量级且可以与 Flash Attention、Rotary Position Embedding (RoPE) 以及各种 Multi-Head Attention (MHA) 变种无缝集成，例如 Grouped-Query Attention (GQA)。", "conclusion": "GLU Attention 是一个轻量级的机制，可以无缝地与其它技术集成，并且已经在 Github 上开源。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00025", "html_url": "https://arxiv.org/abs/2507.00025", "title": "通过频率域适应实现对新型动力系统的泛化", "title_en": "Generalizing to New Dynamical Systems via Frequency Domain Adaptation", "authors": "Tiexin Qin,Hong Yan,Haoliang Li", "background": "利用深度神经网络从数据中学习基础动态模型，在模拟各种复杂的物理动态方面展现了显著潜力。然而，当前的方法在特定域内的可靠预测能力有限，并且在泛化到具有相同基本动态但环境特性不同的新系统方面存在挑战。", "innovation": "本文提出了一种参数高效的方法，即傅里叶神经模拟器进行动态适应（FNSDA），能够通过傅里叶空间的适应来泛化到新的动力系统。FNSDA通过自动分区的方式识别共享的动力并基于低维度的潜系统参数进行调整，从而实现高效的泛化。", "conclusion": "我们的方法在四个代表性的动态系统家族上进行了评估，结果显示FNSDA相比现有方法在泛化性能上更优或具备竞争力，且参数成本显著降低。我们的代码可以在该链接中找到。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00020", "html_url": "https://arxiv.org/abs/2507.00020", "title": "使用变分自编码器生成马尔可夫链蒙特卡洛方法中更广泛谱先验提案", "title_en": "Variational Autoencoder for Generating Broader-Spectrum prior Proposals in Markov chain Monte Carlo Methods", "authors": "Marcio Borges,Felipe Pereira,Michel Tosin", "background": "传统的马尔可夫链蒙特卡洛（MCMC）方法在生成先验提议时依赖于Karhunen-Loève展开发法，但受限于需要先验了解协方差函数。然而，在实际应用中通常无法获得这些信息。因此，需要一种数据驱动的方法来灵活捕捉更广泛的关联结构，尤其是在地下流模拟等贝叶斯逆问题中。", "innovation": "该研究提出使用变分自编码器（VAE）方法通过生成更广泛的先验提案来增强MCMC方法的效率和适用性。VAE框架能够基于数据灵活捕捉更广泛的相关结构，无需依赖预先计算的协方差函数。研究表明，在已知相关长度时，VAE参数化与KLE具有类似的准确性；而当假设的相关长度与真实值不符时，VAE方法的表现优于KLE。此外，VAE方法还显著减少了计算维度，提高了计算效率。", "conclusion": "该研究建议，在高维问题中利用深度生成模型进行MCMC方法的贝叶斯推理可以实现更具适应性和计算效率的推断。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00024", "html_url": "https://arxiv.org/abs/2507.00024", "title": "AIMatDesign：在数据稀少情况下增强知识的强化学习用于逆向材料设计", "title_en": "AIMatDesign: Knowledge-Augmented Reinforcement Learning for Inverse Materials Design under Data Scarcity", "authors": "Yeyong Yu,Xilei Bian,Jie Xiong,Xing Wu,Quan Qian", "background": "随着对新型材料的需求日益增长，机器学习驱动的逆向设计方法面临着在高维材料组成空间与有限的实验数据之间取得平衡的重大挑战。现有方法存在两大缺陷：(I)机器学习模型在高维空间中可靠性不足，导致设计过程中的预测偏差；(II)这些模型无法有效整合领域专家知识，限制了它们支持知识引导的逆向设计的能力。", "innovation": "我们提出了AIMatDesign，这是一种强化学习框架，通过使用基于差异的算法增强实验数据，构建可信的经验池，加速模型收敛。为了提高模型的可靠性，一种由大型语言模型（LLMs）指导的自动精炼策略动态纠正预测不一致，强化奖励信号与状态价值函数之间的对齐。此外，基于知识的奖励函数利用专家领域规则提高训练过程中的稳定性和效率。实验证明，AIMatDesign在发现效率、收敛速度和成功率方面明显优于传统的机器学习和强化学习方法。", "conclusion": "在AIMatDesign提出的众多候选材料中，Zr基合金的实验合成得到了一种表现出色的BMG（β 玻璃），其抗拉强度为1.7GPa，延伸率为10.2%，与预测结果非常接近。此外，该框架精确捕捉了材料组成变化对抗拉强度的影响趋势，证明了其可靠性和在闭环材料发现中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00012", "html_url": "https://arxiv.org/abs/2507.00012", "title": "通过最小化条件互信息实现不可 distill 的模型", "title_en": "Towards Undistillable Models by Minimizing Conditional Mutual Information", "authors": "Linfeng Ye,Shayan Mohajer Hamidi,En-hui Yang", "background": "深度神经网络（DNN）在被用作黑盒输入输出教师时，如果无法通过知识蒸馏（KD）被提取知识，称之为不可 distill 的 DNN。即，使用不可 distill 的 DNN 训练的学生模型（称为 knockoff 学生）的预测准确率不会优于用标签平滑（LS）方法独立训练的学生模型。为了保护 DNN 的知识产权，构建不可 distill 的 DNN 是有必要的。为了实现这一目标，研究者观察到不可 distill 的 DNN 可能具有这样的特性：对于带有相同标签的所有样本实例，其输出概率分布的每个集群都应高度集中，最好每个标签对应的集群能够坍缩成一个概率分布。基于这一观察，提出了一种新的训练方法 CMIM，通过联合最小化常规交叉熵损失和所有温度缩放集群在整个温度范围内的条件互信息（CMI）值来训练 DNN。实验证明，CMIM 模型在所有现存的 KD 方法下都是不可 distill 的。}", "innovation": "提出了一种名为 CMIM 的新训练方法，通过联合最小化常规交叉熵损失和集群的条件互信息值来训练 DNN，从而使得训练出的 CMIM 模型在现有的所有 KD 方法下都是不可 distill 的，即从 CMIM 模型蒸馏出的 knockoff 学生在预测准确率上都劣于用标签平滑方法独立训练的学生模型。此外，CMIM 模型在预测准确率上也优于单独使用交叉熵损失训练的模型。", "conclusion": "通过最小化条件互信息（CMIM）的方法，构建了不可 distill 的 DNN 模型。该模型在所有现有的知识蒸馏方法下都具有不可 distill 的特性，并且在预测准确率上优于单独使用交叉熵损失训练的模型。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00030", "html_url": "https://arxiv.org/abs/2507.00030", "title": "动态环境中文强化学习中基于上下文臂限的自适应动作持续时间", "title_en": "Adaptive Action Duration with Contextual Bandits for Deep Reinforcement Learning in Dynamic Environments", "authors": "Abhishek Verma,Nallarasan V,Balaraman Ravindran", "background": "深度强化学习（DRL）已经在复杂的序列决策任务中取得了显著成功，如玩Atari 2600游戏和掌握棋盘游戏。然而，DRL中的动作执行时间尺度这一关键但尚未充分利用的方面尚未得到充分探索。", "innovation": "提出了一种新颖的思路，即将上下文臂限与DRL集成，以适应性选择动作持续时间，增强策略的灵活性和计算效率。该方法通过将上下文臂限模块添加到深度Q网络（DQN）中，学习根据状态上下文选择最优的动作重复率。实验表明，在Atari 2600游戏中，相比静态持续时间基准，这种适应性时间抽象具有显著的性能提升，强调了动态环境中文强学习中自适应时间抽象的有效性。该范式为实时应用场景（如游戏和机器人）提供了可扩展的解决方案，涉及动态动作持续时间的重要性不可或缺。", "conclusion": "该方法提供了一种用于动态环境中的实时应用（如游戏和机器人）的可扩展解决方案，其中动态动作持续时间至关重要。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00037", "html_url": "https://arxiv.org/abs/2507.00037", "title": "模型融合通过神经元插值", "title_en": "Model Fusion via Neuron Interpolation", "authors": "Phoomraphee Luenam,Andreas Spanopoulos,Amit Sant,Thomas Hofmann,Sotiris Anagnostidis,Sidak Pal Singh", "background": "模型融合旨在通过创建一个能够捕捉所有父模型优点的代表性模型，来结合多个模型的知识。然而，这个过程由于内部表示的差异性（这些差异源于排列不变性、随机初始化或数据分布不同）而变得复杂。现有的融合方法在不同训练数据分布情况下效果不佳。为此，本文介绍了一种以神经元为中心的新型模型融合算法，旨在有效集成多个训练好的神经网络，不受训练数据分布的限制。该算法通过将父模型的中间神经元分组来创建目标表示，从而由融合模型逼近相应的子网络。这种方法不同于以往的方法，通过引入神经元贡献评分到融合过程中，可以在任意类型的层上进行泛化。实验结果表明，本文方法在零样本和非IID融合场景中明显优于现有融合技术。", "innovation": "正文提出了以神经元为中心的新型模型融合算法，该方法将神经元贡献评分引入融合过程，能够泛化到任意层类型，并在不同的基准数据集上展示了优于传统融合技术的表现，特别是在零样本和非IID融合场景中表现出色。", "conclusion": "实验结果显示，本文的算法在各种基准数据集上的一致表现优于以往的融合技术，尤其是在零样本和非IID场景中。提供的代码可以在指定的链接处访问。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00026", "html_url": "https://arxiv.org/abs/2507.00026", "title": "ROSE: 向大规模语言模型现实导向的安全评估迈进", "title_en": "ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models", "authors": "Jiale Ding,Xiang Zheng,Cong Wang,Wei-Bin Lee,Xingjun Ma,Yu-Gang Jiang", "background": "随着大型语言模型（LLMs）在实际应用中被越来越多地作为黑箱组件部署，它们在对抗性提示下的安全性评估变得至关重要。现有的手动安全基准建立在手工制作的对抗性提示上，由于其静态性质和需要不断更新的高劳动强度，难以跟上日益先进的LLM的发展。因此，自动化对抗性提示生成提供了适应性评估的前景。然而，当前的方法在对抗性主题覆盖（主题级多样性）和与现实世界背景的对齐方面存在不足，这些不足源于黑箱优化中的探索—利用困境和缺乏现实世界背景的缺失，导致对抗性提示既在主题上狭窄，又在场景上重复。", "innovation": "我们提出了一种名为Reality-Oriented Safety Evaluation（ROSE）的新型框架，它利用多目标强化学习微调对抗性LLM，生成主题多样性和上下文丰富的对抗性提示。实验表明，ROSE在揭示先进LLM的安全漏洞方面优于现有方法，并在综合评估指标方面取得了显著提升。我们希望ROSE能代表一种通往更实际和现实导向的LLM安全性评估的一步。", "conclusion": "我们希望ROSE将朝着更实际和现实导向的LLM安全性评估迈进。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00028", "html_url": "https://arxiv.org/abs/2507.00028", "title": "HiT-JEPA: 一种用于相似性计算的层次化自我监督轨迹嵌入框架", "title_en": "HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation", "authors": "Lihuan Li,Hao Xue,Shuang Ao,Yang Song,Flora Salim", "background": "城市轨迹数据的表示在有效分析空间移动模式方面发挥着关键作用。尽管已经取得了显著进步，但在设计能够捕捉多样和互补信息的轨迹表示方法方面仍存在挑战。现有的方法难以在一个模型中同时整合细粒度的轨迹细节和高层次的总结，导致其在关注长期依赖性的同时无法保留局部细微之处的能力有限。", "innovation": "我们提出了一种统一框架HiT-JEPA（Hierarchical Interactions of Trajectory Semantics via a Joint Embedding Predictive Architecture），用于学习跨越语义抽象层次的多尺度城市轨迹表示。HiT-JEPA采用了三层递进的结构，逐层捕捉点级的细粒度细节、中间模式和高层面的轨迹抽象，使得模型能够在一致的结构中整合局部动态与全局语义。通过在多个真实世界数据集上的实验证明，HiT-JEPA的层次化设计产生了更丰富、多尺度的表示。", "conclusion": "通过广泛实验，HiT-JEPA的分层设计提供了更为丰富的多尺度表示，提高了轨迹相似性计算的性能。代码已发布在线。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00031", "html_url": "https://arxiv.org/abs/2507.00031", "title": "增强时空预测的时空邻域融合：秘鲁COVID-19移动性案例研究", "title_en": "Enhancing Spatio-Temporal Forecasting with Spatial Neighbourhood Fusion:A Case Study on COVID-19 Mobility in Peru", "authors": "Chuan Li,Jiang You,Hassine Moungla,Vincent Gauthier,Miguel Nunez-del-Prado,Hugo Alatrista-Salas", "background": "精确建模人类移动对于理解传染病传播和及时干预至关重要。这项工作中，我们利用秘鲁国家数字化接触跟踪（DCT）应用在COVID-19疫情期间收集的大规模时空数据集，预测城市地区间的移动流。关键挑战在于六边形网格单元内每小时移动计数的空间稀疏性，这限制了传统时间序列模型的预测能力。为应对这一挑战，我们提出了一种轻量级且模型无关的时空邻域融合（SPN）技术，通过从其邻近的H3单元格聚合信号来增强每个单元格的特征。", "innovation": "我们提出了一种时空邻域融合（SPN）方法，该方法能够增强每个小时移动计数的时空数据单元特征，并与NLinear、PatchTST和K-U-Net三种预测框架相结合，以各种历史输入长度进行评估。实验证明，SPN在提高预测性能方面表现一致，测试MSE可减少高达9.85个百分点。此外，我们发现通过稀疏移动信号的空间平滑化提供了一个简单且有效的方法来增强公共健康危机时期的时空预测能力。", "conclusion": "我们的研究结果表明，空间平滑稀疏移动信号提供了一条简单而有效的途径，以在公共健康危机期间实现鲁棒的时空预测。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00036", "html_url": "https://arxiv.org/abs/2507.00036", "title": "IDRIFTNET：基于物理驱动的空间和时间深度学习方法用于冰山漂移预测", "title_en": "IDRIFTNET: Physics-Driven Spatiotemporal Deep Learning for Iceberg Drift Forecasting", "authors": "Rohan Putatunda,Sanjay Purushotham,Ratnaksha Lele,Vandana P. Janeja", "background": "漂浮在极地海洋中的冰山对地球气候系统发挥着关键作用，影响着向海洋的淡水流量和区域生态系统，同时也对极地航行构成挑战。然而，准确预测冰山轨迹仍然是一个艰巨的挑战，主要原因是缺乏空间和时间数据，以及冰山运动的复杂非线性性质，这种性质还受到环境变量的影响。冰山运动受多个动态环境因素的影响，形成一个高度可变的系统，轨迹识别变得复杂。这些局限性阻碍了深度学习模型对潜在动力学的有效捕捉，无法提供可靠的预测结果。", "innovation": "我们提出了一种称为IDRIFTNET的混合模型，这是一个基于物理驱动的深度学习模型，结合了冰山漂移物理的分析公式，以及增强残差学习模型。该模型学习分析解与真实观察值之间的模式差异，并结合旋转增强的光谱神经网络从数据中捕捉全局和局部模式进行未来冰山漂移位置的预报。这种模型的创新之处在于利用物理原理和深度学习技术相结合的方法，以克服数据不足和动态环境条件带来的挑战，提供更准确的预测结果。", "conclusion": "我们对IDRIFTNET模型在南极两个冰山A23A和B22A上的性能与最先进的模型进行了比较。研究结果表明，IDRIFTNET在各时间点都具有较低的最终位移误差（FDE）和平均位移误差（ADE），证明该模型在限制数据和动态环境条件下有效捕捉复杂、非线性的冰山漂移轨迹方面具有优越性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00038", "html_url": "https://arxiv.org/abs/2507.00038", "title": "质胜于量：基于点维信息的一种有效的大规模数据缩减策略", "title_en": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information", "authors": "Fei Chen,Wenchi Zhou", "background": "数据缩减在以数据为中心的人工智能中发挥着关键作用，通过识别大型数据集中的信息最丰富的实例，以提高模型训练效率。核心挑战是如何选择最优的数据实例，而不是整个数据集，以提高数据质量和训练效率。", "innovation": "提出了一种基于点维信息（PVI）的有效数据缩减策略。通过使用PVI量化实例难度并过滤掉低难度实例，实现静默的数据缩减。通过渐进学习方法在按PVI升序排序的实例上训练分类器，加快了收敛速度，并在传统训练基础上实现了0.8%的准确率提升。此外，将PVI框架从英语数据集扩展到各种中文NLP任务和模型，为跨语言数据缩减提供了有价值的洞见并加速了训练过程。", "conclusion": "有效的数据缩减策略可以使分类器在选定的最优数据子集上训练，从而提高模型性能并增强训练效率。同时，可以通过PVI框架进行跨语言数据缩减的训练，加快NLP任务的训练速度。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00055", "html_url": "https://arxiv.org/abs/2507.00055", "title": "使用知识蒸馏利用未标记的音频-视觉数据进行语音情感识别", "title_en": "Leveraging Unlabeled Audio-Visual Data in Speech Emotion Recognition using Knowledge Distillation", "authors": "Varsha Pendyala,Pedro Morgado,William Sethares", "background": "语音接口作为人机交互系统的重要组成部分，可以通过语音情感识别（SER）来根据用户情绪定制回应。人类通过多模态的声学-视觉线索来表达情感，因此利用声学和面部表达的多模态数据进行SER系统开发是有益的。然而，构建这些系统的大量标记数据成本高昂。", "innovation": "本文提出了一种名为LightweightSER（LiSER）的知识蒸馏框架，它利用未标记的多模态音频-视觉数据进行SER，通过大型教师模型（基于先进的声学和面部表示模型）构建。LiSER从教师模型中转移有关语音情感和面部表情的知识，到更轻量级的学生模型，从而减少对大量标记数据的依赖。", "conclusion": "在两个基准数据集RAVDESS和CREMA-D上进行的实验表明，LiSER可以降低SER任务对大量标记数据的依赖。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00073", "html_url": "https://arxiv.org/abs/2507.00073", "title": "分数阶策略梯度：具有长期记忆的强化学习", "title_en": "Fractional Policy Gradients: Reinforcement Learning with Long-Term Memory", "authors": "Urvi Pawar,Kunal Telangi", "background": "标准的策略梯度方法依赖马尔可夫假设，存在高方差和采样效率低的问题。FPG通过使用Caputo分数微分重新公式化梯度，建立了状态转换之间的幂律时序相关性，解决了这些问题。", "innovation": "FPG引入了分数微积分到强化学习中，通过Caputo分数微分建立了状态转换之间的幂律时序相关性，改进了标准策略梯度方法提出的策略优化框架。FPG还提出了一种有效的递归计算方法，使得计算时间和内存需求保持恒定。理论分析显示，FPG在方差减少方面相对于标准策略梯度具有渐近优势，同时保持了收敛性。实验结果表明，FPG相比现有最先进的基线方法，在采样效率和方差减少方面分别取得了35-68%和24-52%的增长。", "conclusion": "该框架提供了一种在不增加计算开销的情况下利用长期依赖性的数学方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00075", "html_url": "https://arxiv.org/abs/2507.00075", "title": "通过解题验证差距进行大型语言模型自我改进训练动态的理论建模", "title_en": "Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap", "authors": "Yifan Sun,Yushan Liang,Zhen Zhang,Jiaye Teng", "background": "大型语言模型（LLM）的自我改进是提升模型性能的重要策略，但对其训练过程中的性能变化研究尚不充分。本文专注于通过解题验证差距的概念来理论建模自我改进的训练动态过程。", "innovation": "提出了通过解题验证差距的概念来建模自我改进的训练动态，并进一步介绍了仅根据前几个训练周期的信息预测自我改进的最终效果的方法。同时，还研究了外部数据对这一动态过程的影响，并发现在其受限条件下，外部数据可以在各个阶段使用而不会显著影响最终性能。", "conclusion": "本文通过理论模型验证了自我改进的效果，并扩展了对外部数据影响的分析。结果显示，在外部数据受限时，外部数据可以在任何阶段使用而不显著影响最终性能，与实践经验相符。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00029", "html_url": "https://arxiv.org/abs/2507.00029", "title": "LoRA-Mixer: 通过串联注意力路由协调模块LoRA专家", "title_en": "LoRA-Mixer: Coordinate Modular LoRA Experts Through Serial Attention Routing", "authors": "Wenbing Li,Zikai Song,Hang Zhou,Yunyao Zhang,Junqing Yu,Wei Yang", "background": "最近将低秩适应（LoRA）与混合专家（MoE）结合以适应大型语言模型（LLMs）的多种任务仍然存在显著限制。这些方法要么用整个注意力/前馈层的开关专家替换，要么附加并行专家分支，这降低了参数效率并影响了任务准确性。对于基础模型，如变压器和状态空间模型（SSMs），现有方法未能充分利用其固有的线性投影结构。现有的框架还存在数据有限时的鲁棒路由器训练、稳定路由决策和最大化专家复用等问题。", "innovation": "本文提出了LoRA-Mixer，这是一种模块化和轻量级的MoE框架，集成了LoRA专家。创新在于用动态路由的任务特异性LoRA专家替换注意力模块输入/输出线性层的投影矩阵。此设计确保了与各种基础模型，包括变压器和状态空间模型，的无缝兼容性，并利用了这些模型的固有线性投影结构。框架支持两种操作模式：（1）通过新颖的硬软路由策略联合优化LoRA专家和路由机制，或（2）直接部署从外部仓库预训练的冻结LoRA模块。为支持在数据有限的情况下进行稳健的路由器训练，并确保稳定路由决策和最大化专家复用，引入了自适应专业化平衡损失（SBL），联合优化专家平衡和任务特异性对齐。该框架在七个基准数据集（MedQA、CoLA、SST-2、GSM8K、ARC-E、ARC-C和HumanEval）上进行大量实验，证明了LoRA-Mixer的有效性，并实现了显著的性能改进和高效率。", "conclusion": "LoRA-Mixer在GSM8K、HumanEval和MedQA数据集上分别取得了7.61%、4.88%和3.08%的性能提升，与最先进的方法相比，在使用48%参数的情况下，分别取得了1.09%、1.45%和1.68%的额外性能改进，验证了其效率和卓越性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00039", "html_url": "https://arxiv.org/abs/2507.00039", "title": "基于模式的图分类：质量度量的比较及预处理的重要性", "title_en": "Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing", "authors": "Lucas Potin,Rosa Figueiredo,Vincent Labatut,Christine Largeron", "background": "图分类旨在基于图的结构和属性特征对其进行分类，应用范围广泛，包括社会网络分析和生物信息学等领域。现有方法中，依赖于模式（即子图）的方法提供较好的可解释性，因为分类时所使用的模式可以直接解读。为了识别有意义的模式，标准做法是使用质量度量，即将每个模式的区分能力作为评价函数。然而，文献提供了多种这样的度量标准，使得选择最合适的度量标准变得困难。尽管只有少数调查试图通过比较这些度量来提供一些见解，并且这些调查并未特别关注图，但这些方法通常导致系统地使用最流行的度量标准，未进行充分的评价。", "innovation": "本文对文献中提出的38种质量度量进行了比较分析。基于四种数学性质对这38种度量进行了理论描述，并利用公开可用的数据集创建了基准，提出了一个方法来制定模式的黄金标准排名。此外，还提出了一种基于聚类的预处理步骤，该步骤将出现在同一图中的模式分组以增强分类性能。实验结果表明，该步骤具有有效性，减少了处理模式的数量，同时保持了相当的性能。此外，还展示了文献中广泛使用的某些流行度量并非总是与最佳结果相关", "conclusion": "研究通过全面的质量度量比较，展示了预处理步骤对于提高分类性能的重要性，并揭示了一些流行度量可能不是最佳选择的事实。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00034", "html_url": "https://arxiv.org/abs/2507.00034", "title": "用于OECD/NEA AI/ML关键热量流基准第二阶段的非均匀轴向功率数据收集", "title_en": "Data Collection with Non-Uniform Axial Power for Phase II of the OECD/NEA AI/ML Critical Heat Flux Benchmark", "authors": "Reece Bourisaw,Reid McCants,Jean-Marie Le Corre,Anna Iskhakova,Arsen S. Iskhakov", "background": "关键热量流（CHF）标志着轻水反应堆传热临界沸腾的开始，定义了安全的热工水力运行界限。为了支持OECD/NEA AI/ML的关键热量流基准第二阶段，该阶段引入了空间变化的功率分布，本文汇总并数字化了一个广泛的CHF数据集，涵盖了均匀和非均匀轴向加热条件。加热剖面是从技术报告中提取的，按照一致的轴向网格进行内插，并通过能量平衡检查进行验证，以便于基准测试兼容的机器可读格式编码。经典的CHF关联在均匀加热下表现出较大的误差，而在应用于非均匀剖面时表现明显下降。现代表格方法提供了更好的，但仍不完美的预测。仅在均匀数据上训练的神经网络在该领域表现良好，但在空间变化情况下无法泛化，这些都强调了需要明确包括轴向功率分布的模型。通过提供这些精心整理的数据集和基线建模结果，本研究为关键热量流基准的下一阶段奠定了高级迁移学习策略、严格的不确定性量化和设计优化工作的基础。", "innovation": "本文汇总并数字化了广泛的CHF数据集，通过内插和能量平衡检查来提供一致的轴向网格上的加热剖面，并将这些数据集编码为机器可读格式，以便于大规模数据分析和模型训练。特别是，该研究强调了需要专门为轴向功率分布非均匀情况开发的新模型，以改进CHF预测。此外，通过提供这些数据和基准结果，该研究铺平了采用先进模型和技术的道路，如迁移学习、不确定性量化和设计优化，从而提高反应堆运行的安全性和效率。", "conclusion": "通过收集并整理非均匀轴向功率数据集，该研究为下一步的CHF基准测试提供了必要的基础。这些数据集和基线结果不仅帮助识别出当前模型在非均匀加热条件下的限制，还为开发新型模型铺平了道路，以提高CHF预测的准确性和可靠性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00061", "html_url": "https://arxiv.org/abs/2507.00061", "title": "Smooth-Distill: 一种用于穿戴传感器数据多任务学习的自我蒸馏框架", "title_en": "Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data", "authors": "Hoang-Dieu Vu,Duc-Nghia Tran,Quang-Tu Pham,Hieu H. Pham,Nicolas Vuillerme,Duc-Tan Tran", "background": "现有的穿戴设备可以收集大量的加速度计数据，用于进行人体活动识别（HAR）和传感器位置检测。传统的多任务学习方法虽然能够同时处理多个任务，但通常需要大量的计算资源，尤其在缺乏计算资源的平台上，训练效率较低。本文介绍了一种新颖的自我蒸馏框架Smooth-Distill，它结合了一个统一的基于CNN的架构MTL-net，能够在同一模型上同时进行HAR和传感器位置检测，同时利用历史模型的平滑版本作为教师模型，从而减少了训练计算开销，同时保持性能优势。", "innovation": "Smooth-Distill的创新点在于：\n1. 提出了使用平滑历史模型作为教师模型的自我蒸馏框架，而不是使用独立的教师模型。\n2. 利用统一的CNN基架构MTL-net，能够同时处理HAR和传感器位置检测两个任务。\n3. 实验结果表明，Smooth-Distill在不同评估场景中比现有方法在HAR和传感器位置检测中的效果更佳，并且具有更好的收敛稳定性，降低了过拟合现象。", "conclusion": "Smooth-Distill框架通过降低模型训练的计算成本，为实践中的多任务学习系统（特别是基于加速度计数据的HAR系统）提供了一种有效解决方案，并有效平衡了准确性和训练效率，这在资源受限平台上尤为重要。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00083", "html_url": "https://arxiv.org/abs/2507.00083", "title": "通过干预意识时空因果图网络进行深目标空袭系统的战略反事实建模", "title_en": "Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks", "authors": "Wei Meng", "background": "当前战略性水平的模拟缺乏战术打击行为与战略延迟之间的结构化因果模型，特别是在‘韧性-节点抑制-谈判窗口’链中捕捉中间变量的结构性瓶颈。", "innovation": "提出了干预意识时空图神经网络（IA-STGNN），这是一种全新的框架，能够从战术输入闭合到战略延迟输出的因果回路。该模型整合了图注意力机制、反事实模拟单元和空间干预节点重构，以实现打击配置和同步策略的动态模拟。训练数据来自符合NIST SP 800-160标准的多物理场模拟平台（GEANT4 + COMSOL），确保结构可追溯性和政策级验证。并在实验结果中证明，相对于基线模型（ST-GNN、GCN-LSTM、XGBoost），IA-STGNN显著提升了性能，MAE减少了12.8%，Top-5百分比精度提高了18.4%，同时提高了因果路径一致性和干预稳定性。", "conclusion": "IA-STGNN能够实现战略延迟的可解释预测，并支持核威慑模拟、外交窗口评估和多策略优化等应用，为高级政策建模提供了一个结构化和透明的AI决策支持机制。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00080", "html_url": "https://arxiv.org/abs/2507.00080", "title": "基于CGM数据动态的在线餐食检测方法", "title_en": "Online Meal Detection Based on CGM Data Dynamics", "authors": "Ali Tavasoli,Heman Shakeri", "background": "目前，从连续葡萄糖监测（CGM）数据中检测餐食事件的方法主要依赖于传统的特征提取技术，这些方法可能无法充分捕捉与餐食相关的葡萄糖变化模式和异常。通过引入动态模式，该研究旨在进一步提高餐食检测的准确性和可解释性，从而增强在不同数据集上的泛化能力和实际应用中的可靠性", "innovation": "该研究提出了一种基于CGM数据动态模式的新方法，这种方法能够更准确地检测餐食事件。动态模式能够捕捉葡萄糖变化的关键特征，识别与餐食有关的模式和异常。这种方法不仅提高了检测的准确性，还增强了葡萄糖动态的可解释性，并提供了一种适用于不同数据集的稳健特征提取框架，从而确保在实际应用中的可靠性能。这种方法相比传统的检测方法具有显著优势", "conclusion": "该研究提出的方法为餐食检测提供了一种新的视角和工具。通过聚焦于动态特征，这种方法能够更准确、可靠地检测餐食事件，同时还能更好地解释葡萄糖动力学，适用于多种数据集，并在实际应用中表现出色。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00078", "html_url": "https://arxiv.org/abs/2507.00078", "title": "时间的语言：时间序列基础模型的语言模型视角", "title_en": "The language of time: a language model perspective on time-series foundation models", "authors": "Yi Xie,Yun Xiong,Zejian Shi,Hao Niu,Zhengfu Liu", "background": "随着大型语言模型的兴起，大规模参数和大规模数据集用于训练基础模型的范式已在多个领域取得了显著成功。时间序列基础模型构成了这一范式的重大扩展，展现出非凡的表现力、泛化能力和跨域迁移性。然而，这引发了根本性悖论：时间序列数据反应的是不同的动力系统，使得跨域迁移在直观上似乎不可行，但现实中的模型却表现出成功。该论文从理论和实验两个角度探讨了基于补丁的时间序列基础模型的表示学习机制和泛化能力，试图解释这种矛盾并提供一套架构论据，表明时间序列模型通过从确定性的向量表示扩展到潜在的概率分布形式，实现了类似于语言模型的稳定性、表示能力和迁移能力。因此，这解释了它们在时间任务中的优越表现", "innovation": "该论文提出了从语言模型视角分析时间序列基础模型的方法，论证了基于补丁的时间序列基础模型通过扩展确定性向量表示到潜在的概率分布形式，克服了时间序列数据与语言数据的本质差别，实现了类似语言模型的泛化能力和迁移能力；其理论分析支持这一框架，表明连续时间序列补丁可以量化成具有一致统计性质的离散词汇表。这为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了坚实的理论基础", "conclusion": "该研究工作为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了坚实的理论基础，解释了时间序列模型在时间任务中的优越表现；该论文认为基于补丁的时间序列基础模型不仅采用了新的架构，而且从根本上扩展了语言模型的表示范式。这使得时间序列模型能继承大型语言模型的稳健的表示能力和迁移能力"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00082", "html_url": "https://arxiv.org/abs/2507.00082", "title": "通信高效的联邦学习驱动混合语言模型用于标记传输", "title_en": "Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission", "authors": "Faranaksadat Solat,Joohyung Lee,Mohamed Seif,Dusit Niyato,H. Vincent Poor", "background": "混合语言模型（HLMs）结合了边缘设备上的小型语言模型（SLMs）的低延迟高效性和中央服务器上的大型语言模型（LLMs）的高准确性。传统的方法是在边缘设备上直接执行LLM推理，这会导致高延迟和大量通信开销。现有的HLM方法减少了这个开销，但在低置信度或高熵的情况下仍然依赖LLM，这在带宽受限的场景中会带来巨大的通信开销。", "innovation": "提出了一种名为FedHLM的通信高效的混合语言模型框架，该框架结合了不确定性感知推理和联邦学习（FL）。FedHLM的关键创新在于合作学习标记级别的不确定性阈值，以此决定何时需要LLM的帮助。这种阈值不是固定的或手动调优的，而是通过FL在隐私保护、分布式的方式进行优化。此外，它利用基于嵌入的标记表征进行对等（P2P）解决，使客户端能够在不需要LLM的情况下重用与语义相似的对等方推断出的标记。通过这种方式，层次化的建模聚合策略捕获了反复出现的不确定性模式，减少了多余的LLM查询。", "conclusion": "实验结果表明，FedHLM在大规模新闻分类任务中将LLM的传输减少了95%以上，且几乎没有准确性损失，使其非常适合可扩展且高效的边缘AI应用。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00085", "html_url": "https://arxiv.org/abs/2507.00085", "title": "一种用于鲁棒交通速度预测的联合拓扑-数据融合图网络", "title_en": "A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism", "authors": "Ruiyuan Jiang,Dongyao Jia,Eng Gee Lim,Pengfei Fan,Yuli Zhang,Shangbo Wang", "background": "精确的交通预测对智能交通系统（ITS）至关重要。然而，当前方法难以应对交通动态的固有复杂性和非线性，难以整合空间和时间特征。现有的方法使用静态技术处理非稳态和异常的历史数据，这限制了它们的适应性和数据平滑性。", "innovation": "提出了一种创新的网络级交通速度预测框架，即Graph Fusion Enhanced Network (GFEN)。GFEN引入了一种新颖的拓扑时空图融合技术，该技术使用可训练方法从数据分布和网络拓扑中详细提取和合并时空相关性，从而实现多尺度时空特征的建模。此外，GFEN结合了基于k阶差分的数学框架和基于注意力机制的深度学习结构，自适应地平滑历史观测结果并动态削弱数据异常和非稳态。", "conclusion": "广泛的实验表明，GFEN在预测精度上比最先进的方法高出约6.3%，其收敛速度几乎是最近组合模型的两倍，证实了其优越的性能和显著提高交通预测系统效率的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00105", "html_url": "https://arxiv.org/abs/2507.00105", "title": "风力发电预测中的图神经网络", "title_en": "Graph Neural Networks in Wind Power Forecasting", "authors": "Javier Castellano,Ignacio Villanueva", "background": "本文探讨了图神经网络（GNNs）在风能预测问题中的适用性。研究对象为三个风力发电设施，历时五年的历史数据被用于研究。预测变量包括数值天气预测（NWP）数据，模型在24至36小时的测试窗口内进行评估，对比了某些架构的表现与基于卷积神经网络（CNN）的最佳基准模型的表现相当。", "innovation": "发现某些GNN架构在风能预测方面的表现与基于CNN的最佳基准模型相当，这是将GNN应用于预测风力发电的一个新进展。研究使用了丰富的历史数据和数值天气预测变量，评估此方法在实际风能预测中的可行性与准确性。", "conclusion": "GNNs在风力发电预测中显示出良好应用潜力，部分GNN架构能够达到与基于CNN的模型相似的预测精度。未来研究可进一步探索不同风力设施条件下的适应性和改进现有模型。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00087", "html_url": "https://arxiv.org/abs/2507.00087", "title": "pUniFind：一个统一的大规模预训练深度学习模型，推动质谱图解释的极限", "title_en": "pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation", "authors": "Jiale Zhao,Pengzhi Mao,Kaifei Wang,Yiming Li,Yaping Peng,Ranfei Chen,Shuqi Lu,Xiaohong Ji,Jiaxiang Ding,Xin Zhang,Yucheng Liao,Weinan E,Weijie Zhang,Han Wen,Hao Chi", "background": "虽然深度学习在质谱数据解释中取得了进步，但大部分模型仍然只是特征提取器而非统一评分框架。pUniFind是首次提出的大规模多模态预训练模型，结合了肽谱评分与开放的零样本从头测序。模型在超过1亿条开放搜索谱图的数据集上进行训练，能够将谱图和肽模态在跨模态预测中统一，相较于传统引擎在各种数据集中表现更佳，特别在免疫肽段学中肽识别数量增加了42.6%。该模型还能够识别现有的从头测序方法未覆盖的大量肽段，拥有更广泛的修饰覆盖和更高的检测灵敏度。", "innovation": "pUniFind是首次提出的多模态预训练模型，能够结合肽谱评分和开放的零样本从头测序。模型在大规模数据集上进行训练，实现了谱图和肽模态在跨模态预测中的统一，并在多种数据集中超越传统引擎。尽管搜索空间扩大了300倍，但该模型仍能识别比现有从头测序方法多出60%的肽段，同时额外恢复了38.5%的肽段。该模型还包含基于深度学习的质量控制模块，进一步提高了检测灵敏度和修饰覆盖范围，同时保持了完整的片段离子覆盖。", "conclusion": "pUniFind为蛋白质组分析提供了一个统一且扩展的深度学习框架，提高了敏感度和修饰覆盖范围，并增强了模型的可解释性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00101", "html_url": "https://arxiv.org/abs/2507.00101", "title": "DFReg：用于神经网络权重分布正则化的一种受物理启发的框架", "title_en": "DFReg: A Physics-Inspired Framework for Global Weight Distribution Regularization in Neural Networks", "authors": "Giovanni Ruggieri", "background": "传统的正则化技术，如Dropout或L2衰减，虽然有效，但它们通常需要建筑结构的改变或随机扰动，这可能会对模型的训练和优化带来额外的复杂性和不稳定性。此外，这些方法只在局部层面影响权重分布，缺乏从全局角度对权重分布进行有效调控的机制。基于此背景，本文提出了DFReg，一种受密度泛函理论（DFT）启发的正则化方法，它作用于权重的整体分布，旨在鼓励平滑、多样且均匀的权重配置，从而在不改变模型结构和不引入随机扰动的情况下改进模型性能和泛化能力.", "innovation": "DFReg是一种新型的全局权重分布正则化方法，其灵感来自于物理领域的密度泛函理论。与现有的Dropout或L2衰减等局部正则化技术不同，DFReg通过应用功能惩罚来影响权重的整体分布。这种方法能够在保持模型结构不变的情况下，对权重配置施加全局结构一致性，而无需引入随机扰动和额外的架构改动，从而改善模型的泛化能力和训练效率.", "conclusion": "通过在实际任务中应用DFReg，展示了其在提高模型性能和泛化能力方面的显著效果。特别是，在一系列基准测试和实验中，DFReg展示了与现有方法相比在测试集上的优越表现。因此，DFReg为深神经网络提供了一种新的正则化方案，具有广泛的应用前景和研究价值。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00191", "html_url": "https://arxiv.org/abs/2507.00191", "title": "来自可穿戴设备的行为数据：基础模型超越传感器数据以提高健康预测", "title_en": "Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions", "authors": "Eray Erturk,Fahad Kamran,Salar Abbaspourazad,Sean Jewell,Harsh Sharma,Yujie Li,Sinead Williamson,Nicholas J Foti,Joseph Futoma", "background": "可穿戴设备可以记录生理和行为信号，这些信号可以改善健康预测。现有的基础模型已经在低级传感器数据上得到了广泛应用，尽管行为数据由于其与生理相关的时间尺度和数量更具有信息性而往往更有价值。", "innovation": "开发了基础模型来处理大量行为信号数据（来自162,000个个体超过25亿小时的可穿戴数据），系统地优化了适用于这一独特数据集的架构和标记策略。该模型在57个健康相关的任务上表现出色，涵盖了个人级别的分类和动态健康状态预测。它在基于行为的任务如睡眠预测中表现突出，并且结合原始传感器数据表示时表现进一步提升。", "conclusion": "这些结果强调了对可穿戴设备设计基础模型进行定制的重要性，并展示了利用行为数据以实现新健康应用的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00090", "html_url": "https://arxiv.org/abs/2507.00090", "title": "生成异构多维数据：一项比较研究", "title_en": "Generating Heterogeneous Multi-dimensional Data : A Comparative Study", "authors": "Corbeau Michael,Claeys Emmanuelle,Serrurier Mathieu,Zaraté Pascale", "background": "消防员的人员和物资分配至关重要，需要通过模拟多场景来进行。分配的主要目标是优化消防员的响应。生成数据对于研究这些场景是必要的。本研究旨在比较不同数据生成方法的效果，如随机抽样、表格变分自编码器、标准生成对抗网络、条件表格生成对抗网络和扩散概率模型，以确定它们在捕捉消防员干预的复杂性方面的有效性。传统的评价标准在捕捉真实场景所需的高度精密的合成数据集特征方面往往不足。为了弥补这一差距，采用了领域特定的评价标准（如响应时间分布、干预的空间-时间分布和事故表示）以及像Wasserstein距离这样的标准衡量指标来评估合成数据的质量。这些领域特定的指标旨在评估数据的变异性、复杂且精细的相关性保存以及异常情况（如低发生的事件）、初始统计分布的一致性和合成数据的操作相关性。数据分布的特点是高度不平衡，没有一个变量符合正态分布，这增加了数据生成的复杂性。", "innovation": "该研究创新地提出了一种比较不同数据生成方法的方法，特别是通过使用领域特定的评价标准和标准测量指标（如Wasserstein距离）来评估合成数据的质量。这种方法可以更好地捕捉实际消防场景中数据的复杂性。", "conclusion": "该研究结果显示，生成的异构多维数据在捕捉消防干预的复杂性方面具有一定的有效性，但不同方法的性能存在差异。Wasserstein距离和领域特定的评价标准的应用对于提高数据质量是有效的。未来的研究可以进一步探索如何优化这些数据生成方法以更好地适应消防场景的特殊需求。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00102", "html_url": "https://arxiv.org/abs/2507.00102", "title": "在制造中的透明和数据驱动的故障检测：一个关于单变量离散时间序列的案例研究", "title_en": "Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series", "authors": "Bernd Hofmann,Patrick Bruendl,Huong Giang Nguyen,Joerg Franke", "background": "现代制造中确保产品质量一致至关重要，尤其是在安全关键应用中。传统的质量控制方法依赖于手动定义的阈值和特征，这使得它们在应对生产数据中的复杂性和变化时缺乏灵活性，并且需要大量的领域专业知识。相比之下，基于数据的方法如机器学习虽然表现出色，但通常作为黑箱模型运行，从而在工业环境中影响其接受度，因为该环境中对模型的可解释性有很高的需求。", "innovation": "本文提出了一种结合监督机器学习的多类故障分类、Shapley Multiply Additive Explanations来进行事后解释以及特定领域的可视化技术（将模型解释映射到操作员可解释的功能）的方法。这一方法注重透明性同时保持数据驱动的特性，旨在增强对基于数据的故障检测系统的信任度和可解释性，从而促进工业质量控制的应用系统设计。此外还提出了一种通过定量扰动分析评估模型解释并进行定性专家评估来评价可视化的方法。", "conclusion": "所提出的方法应用于压接工艺，这一安全关键的连接技术，使用了一组单变量、连续时间序列数据集，系统实现了95.9%的故障检测准确性，并且量化和专家定性的评估结果显示生成的解释具有相关性和可解释性。这种以人为本的方法增强了对数据驱动故障检测的信任和解释性，从而为工业质量控制中的应用系统设计做出了贡献。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00184", "html_url": "https://arxiv.org/abs/2507.00184", "title": "具有各种文本编码器的Text-to-Level扩散模型：以Super Mario Bros为例", "title_en": "Text-to-Level Diffusion Models With Various Text Encoders for Super Mario Bros", "authors": "Jacob Schrum,Olivia Kilday,Emilio Salas,Bess Hagan,Reid Williams", "background": "近期研究表明，扩散模型可以无条件生成瓷砖式游戏关卡，但使用扩散模型进行文本到关卡的生成仍然存在着未被充分探索的应用。在实际应用中，创建一个可用的模型需要提供图文对、包含文本嵌入模型，并且能够生成整个可玩的关卡而不仅仅是独立场景。", "innovation": "文章提出了自动为现有关卡数据集分配描述性标题的方法，并使用预训练文本编码器和从头训练的简单变压器模型来训练扩散模型。通过自动生成的关卡分配描述性标题，可以比较输入和输出的匹配程度。此外，还评估了生成关卡的多样性和可玩性，并将其与无条件扩散模型、生成对抗网络以及Five-Dollar Model和MarioGPT等文本至关卡生成方法进行了比较。研究发现，使用简单的变压器模型进行文本嵌入的扩散模型不仅效果更好，而且训练时间更短，这说明在生成关卡时并不一定需要依赖大型语言模型。还提供了一个GUI，允许设计者从模型生成的场景构建长关卡。", "conclusion": "在生成六边形瓷砖式游戏关卡的Text-to-Level扩散模型中，使用简单变换模型可以取代更复杂文本编码器，并且效果更好。此外，研究人员还强调了评估模型多样性和可玩性的重要性，并提供了一个有助于关卡设计的用户界面。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00089", "html_url": "https://arxiv.org/abs/2507.00089", "title": "职业事故预测的新型机器学习框架与安全检查集成", "title_en": "A new machine learning framework for occupational accidents forecasting with safety inspections integration", "authors": "Aho Yapi,Pierre Latouche,Arnaud Guillin,Yan Bailly", "background": "本文提出了一种利用安全检查数据的短时职业事故预测的通用框架，并将事故的发生建模为二元时间序列。该方法生成每日预测，并将这些预测聚合为每周的安全评估以更好地支持决策。为确保预测的可靠性和操作实用性，作者使用了一种特别设计用于时间序列数据的时间滑动窗口交叉验证方法，并结合了基于聚合期级指标的评估。通过对多种机器学习算法（包括逻辑回归、树基模型和神经网络）进行训练和系统比较，作者发现长短期记忆（LSTM）网络在所有方法中表现最佳，准确度达到0.86，表明该方法的稳健性，并证明了基于安全检查的二元时间序列模型可以预测这些关键时期。该方法将常规的安全检查数据转换为清晰的每周风险评分，检测事故发生可能性最大的时期。决策者可以将这些评分整合进他们的规划工具中，以指导检查优先级、计划针对性干预措施和将资源分配给风险最高的地点或时间段，以预防事故发生，从而获得最大的安全投资回报率。", "innovation": "本文提出的框架利用安全检查数据预测职业事故，将事故的发生建模为二元时间序列，使用长短期记忆（LSTM）网络实现了最高的准确度。该方法通过生成每日预测并将其聚合为每周的安全评估，提供了一种新的工具来指导决策。此外，框架还采用了时间滑动窗口交叉验证方法和聚合期级指标评估方法，以确保预测的可靠性和操作实用性。", "conclusion": "本文提出的方法将常规的安全检查数据转换为每周的风险评分，能够识别出事故最可能发生的时间段，从而帮助决策者进行优先级排序、针对性干预措施的规划以及资源的有效分配，以防止事故发生，实现最大的安全投资回报率，展示了二元时间序列模型在职业事故预测中的有效性和优越性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00234", "html_url": "https://arxiv.org/abs/2507.00234", "title": "基于全局注意力和NLP生成解释的时间序列可解释AI：多模型热图融合", "title_en": "Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations", "authors": "Jiztom Kavalakkatt Francis,Matthew J Darr", "background": "现有的可解释性方法存在空间-时间错位的问题，卷积网络无法捕获全局上下文，而变压器则缺乏局部精度。这对医疗和工业监测等关键领域的实际操作产生了负面影响。论文提出了一种新的框架，通过结合热图（由ResNet产生的和重构的2D Transformer产生）以及全局加权输入显著性，来增强模型的可解释性。", "innovation": "该方法将ResNet的梯度加权激活图和Transformer注意力展开合并为一个统一的可视化，实现了空间-时间的对齐，同时保持了实时性能。此外，该方法通过自然语言处理模块将融合的热图转化为领域特定的叙述，经BLEU-4 (0.586)和ROUGE-L (0.650)验证。", "conclusion": "通过形式化可解释性为因果保真度和空间-时间对齐，该方法填补了技术输出与利益相关者理解之间的差距，提供了一种基于透明、时间感知决策的可扩展解决方案。实验结果表明，与单独的ResNet、Transformer和InceptionTime基线相比，该混合框架在PhysioNet数据集上达到了94.1%的准确性（F1 0.93），在UCI Energy Appliance数据集上将回归误差降低至RMSE = 0.28 kWh（R2 = 0.95），且性能更优。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00230", "html_url": "https://arxiv.org/abs/2507.00230", "title": "PPFL-RDSN: Privacy-Preserving Federated Learning-based Residual Dense Spatial Networks for Encrypted Lossy Image Reconstruction", "title_en": "PPFL-RDSN: Privacy-Preserving Federated Learning-based Residual Dense Spatial Networks for Encrypted Lossy Image Reconstruction", "authors": "Peilin He,James Joshi", "background": "从低分辨率输入重建高质量图像在协作场景中至关重要但极具挑战性，尤其是在存在隐私泄漏和推理攻击等安全风险以及高计算成本的情况下，中央训练模式尤为不适宜。", "innovation": "提出了一种新的PPFL-RDSN框架，结合联邦学习（FL）、本地差异隐私和鲁棒模型水印技术，确保数据在本地设备上保持安全，防止敏感信息泄露，并保护模型完整性，同时不透露底层数据。", "conclusion": "PPFL-RDSN在计算负担减少的同时达到与最先进的中央方法相当的性能，并有效缓解了安全和隐私漏洞，成为安全且隐私保护的协作计算机视觉应用的实用解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00195", "html_url": "https://arxiv.org/abs/2507.00195", "title": "数据异质性和光滑性在局部更新中的作用", "title_en": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness", "authors": "Kumar Kshitij Patel", "background": "该论文集中在局部更新算法，尤其是局部SGD，在分布式和联邦优化中的理论理解，特别是在数据异质性现实模型下的理解。重点在于有界的二阶异质性假设，在凸性和非凸设置中证明了局部更新可以超越集中或小批次方法的必要性和充分性。论文还考虑了在线联邦学习，提供了基于一阶和 bandit 反馈的基本遗憾界。", "innovation": "论文的核心在于一种细粒度的共识误差分析框架，该框架在第三阶光滑性和宽松的异质性假设下提供了更严格的有限时间收敛界。此外，论文为不同类型的问题类提供了方差上下界，并精确刻画了多样问题类的复杂性，通过对局部更新算法在异质环境中的分析，给予理论上的优势和具体分析指导，将其作为自含式指南。", "conclusion": "论文澄清了何时以及为什么局部更新能提供可证明的优势，并为其在异质环境中的分析提供了一个自含指南。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00257", "html_url": "https://arxiv.org/abs/2507.00257", "title": "Gym4ReaL: 用于测试实际应用强化学习的一套环境", "title_en": "Gym4ReaL: A Suite for Benchmarking Real-World Reinforcement Learning", "authors": "Davide Salaorni,Vincenzo De Paola,Samuele Delpero,Giovanni Dispoto,Paolo Bonetti,Alessio Russo,Giuseppe Calcagno,Francesco Trovò,Matteo Papini,Alberto Maria Metelli,Marco Mussi,Marcello Restelli", "background": "近年来，强化学习（RL）在模拟环境中取得了显著的进步，实现了超人的表现。随着研究转向实际应用，RL 面临新的挑战，如巨大的状态-动作空间、非平稳性和部分可观测性。虽然这些问题很重要，但在现有的基准测试中却常被忽视，这些基准测试主要集中在理想化的、完全可观测和静态的环境中，忽视了实际环境的复杂性.", "innovation": "本文提出了 Gym4ReaL，这是一个综合的、现实的环境套件，用于支持能够在现实场景中运行的 RL 算法的发展和评估。Gym4ReaL 包含一系列多样化的任务，使算法暴露在各种实际挑战下。实验结果显示，标准 RL 算法在这些环境中依旧表现出了竞争力，支持了借助 RL 来处理实际任务复杂性的方法的发展.", "conclusion": "本文通过 Gym4ReaL 套件展示了在实际场景中标准 RL 算法的竞争力，并强调了开发适应实际环境的 RL 方法的必要性，以充分利用 RL 的潜力来解决实际任务的复杂性."}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00301", "html_url": "https://arxiv.org/abs/2507.00301", "title": "结构保留的提升与学习：非线性守恒偏微分方程的科学机器学习", "title_en": "Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations", "authors": "Harsh Sharma,Juan Diego Draxl Giannoni,Boris Kramer", "background": "该研究利用提升变量变换来学习非线性偏微分方程（PDE）的结构保留降维模型，特别是在具有守恒定律的情况下。研究提出了一种混合学习方法，基于最近开发的能量平方化策略，该策略通过在PDE层面上利用非线性的知识，导出等效的二次提升系统，使模型学习在提升设置中变得更加有效。", "innovation": "该方法采用能量平方化策略，提出了一种混合学习方法，通过能量平方化获得的提升动力学在旧变量上是线性的，从而提高了模型学习的效率。基于提升后的二次PDE模型形式，方法还导出二次缩减项，并使用这些项来构建一个约束优化问题，以以结构保留的方式学习剩余的线性缩减算子。该方法不仅提高了计算效率，还保留了较高维度问题的基本物理学。", "conclusion": "提出的结构保留的提升与学习方法通过三个数值示例展示了其通用性，包括具有指数非线性的1D波动方程、二维Sine-Gordon方程和二维Klein-Gordon-Zakharov方程。数值结果表明，该学习方法在准确性和计算效率方面与现有的最先进的结构保留数据驱动模型减少方法相竞争。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00259", "html_url": "https://arxiv.org/abs/2507.00259", "title": "谁该听从？个性化联邦学习中的自适应协作", "title_en": "Who Should I Listen To? Adaptive Collaboration in Personalized Federated Learning", "authors": "Amr Abourayya,Jens Kleesiek,Bharat Rao,Michael Kamp", "background": "在联邦学习中，数据异质性是一个核心挑战。个性化联邦学习（PFL）旨在通过定制模型来解决这一问题，以适应每个客户端的数据分布。然而，许多PFL方法在效果上并未超过局部或中心化基线，暗示这些方法的协作机制与数据结构之间存在不匹配。研究人员提出了一种基于自适应协作的方法，客户端不仅可以自主确定如何依赖他人，还可以在个体实例级别自主选择信任对象，从而做出更精细的信任决定。这种方法在FEDMOSAIC（一种联邦共训练方法）中得到实现，其中客户端会在共享的无标签数据集上交换预测结果。研究进一步表明，这种基于自适应信任决策的方法能够改善模型的精确度，在各种非同态分布（non-IID）场景下优于最先进的PFL方法。", "innovation": "提出了基于自适应协作的方法，即FEDMOSAIC，它通过使客户端在个体实例级别自主选择信任对象，实现了精细化的信任决策。每个客户端根据其对私有数据和公有数据之间一致性的估计调整其损失权重，并按照其对每个实例的信心贡献全局伪标签。这种方法使客户端在参与模型训练和协作时，能够更加灵活地选择信任对象，从而提高模型的适应性和泛化能力。", "conclusion": "FEDMOSAIC 方法在不同场景下表现优于最先进的PFL方法，并提供了标准假设下的收敛性保证。研究结果表明，基于数据感知的协作对于个性化学习和提升模型鲁棒性和有效性具有巨大潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00320", "html_url": "https://arxiv.org/abs/2507.00320", "title": "探索情绪体验脑基础中的理论偏差观察", "title_en": "Exploring Theory-Laden Observations in the Brain Basis of Emotional Experience", "authors": "Christiana Westlin,Ashutosh Singh,Deniz Erdogmus,Georgios Stratis,Lisa Feldman Barrett", "background": "在情感科学中，普遍认为民间情感类别形成一种生物学和心理学的类型学，研究设计和分析通常旨在识别特定的情感模式。这种做法影响了研究结果的报告，最终强化了引导研究的假设。该研究重分析了一个以类型学为导向的研究数据，该研究报告了个体大脑模式与34个情感类别中位评分之间的映射关系。", "innovation": "该研究的创新之处在于重新分析数据时采取了一种替代的观点，认为情感类别是由可变的、位置中的实例组成的群体，并预计在同一类别内的实例之间会出现显著的大脑模式变化。分析时对数据中存在的变异结构进行了最小的假设。这些分析方法揭示了最初的映射研究可能存在的偏差，强调了需要使用多种分析方法来支持假设的重要性。", "conclusion": "这些发现表明，起点假设最终可能影响科学家的结论，并建议在认真对待假设之前，必须使用多种分析方法来支持它。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00304", "html_url": "https://arxiv.org/abs/2507.00304", "title": "MamNet: 一种新型的网络流量时间序列预测和频域模式分析的混合模型", "title_en": "MamNet: A Novel Hybrid Model for Time-Series Forecasting and Frequency Pattern Analysis in Network Traffic", "authors": "Yujun Zhang,Runlong Li,Xiaoxiang Liang,Xinhao Yang,Tian Su,Bo Liu,Yan Zhou", "background": "网络流量中的异常波动可能预示着潜在的安全威胁或系统故障，因此高效地进行网络流量预测和异常检测对于网络安全和流量管理至关重要。", "innovation": "提出了一种名为MamNet的新颖网络流量预测和异常检测模型，该模型结合了时域建模和频域特征提取。通过Mamba模块捕捉网络流量的长时依赖性，并通过傅里叶变换识别交通中的周期性波动。在功能融合层中，综合多重尺度信息以增强模型检测网络流量异常的能力。实验表明，MamNet在准确率、召回率和F1分数方面优于多种最新的主流模型，特别是在复杂流量模式和长周期趋势检测方面表现出约2%到4%的性能提升。", "conclusion": "结果表明，MamNet能够有效地捕捉不同时间尺度下的网络流量异常，并适用于网络安保和流量管理中的异常检测任务。未来的工作可能通过引入外部网络事件信息来进一步优化模型结构，从而提高模型在复杂网络环境中的适应性和稳定性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00316", "html_url": "https://arxiv.org/abs/2507.00316", "title": "$μ^2$Tokenizer: 可微分的多尺度多模态分词器用于放射学报告生成", "title_en": "$μ^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation", "authors": "Siyou Li,Pengyao Qin,Huanan Wu,Dong Nie,Arun J. Thirunavukarasu,Juntao Yu,Le Zhang", "background": "放射学报告生成（RRG）旨在从临床影像，如计算机断层扫描（CT）扫描图像，自动生成详细的文本报告，以提高诊断和管理建议的准确性和效率。然而，RRG面临两大挑战：在资源限制下从影像数据中提取相关信息的固有复杂性，以及评估模型生成报告与专家撰写的报告之间差异的难度。", "innovation": "本文提出了$μ^2$LLM，一种多尺度多模态大型语言模型，用于RRG任务。创新点包括：1) 新的$μ^2$Tokenizer中间层，整合了多尺度视觉分词器和文本分词器的多模态特征；2) 通过直接偏好优化（DPO）增强报告生成质量，参考GREEN-RedLlama进行引导优化。实验结果表明，该方法在四个大型CT图像-报告医疗数据集上优于现有方法，突显了我们的微调$μ^2$LLM在有限数据下进行RRG任务的潜力。", "conclusion": "实验结果表明，我们的方法在四个大型CT图像-报告医疗数据集上优于现有方法，证明了微调的$μ^2$LLM在有限数据下进行RRG任务的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00310", "html_url": "https://arxiv.org/abs/2507.00310", "title": "通过贝叶斯惊奇进行开放性科学发现", "title_en": "Open-ended Scientific Discovery via Bayesian Surprise", "authors": "Dhruv Agarwal,Bodhisattwa Prasad Majumder,Reece Adamson,Megha Chakravorty,Satvika Reddy Gavireddy,Aditya Parashar,Harshit Surana,Bhavana Dalvi Mishra,Andrew McCallum,Ashish Sabharwal,Peter Clark", "background": "自主科学研究（ASD）不仅包括回答问题，还需要知道提出哪些问题。当前大多数ASD的研究工作都依赖于人类设定的研究问题来引导假设生成。然而，通过允许AI系统根据自己的标准来驱动探索，科学发现的速度可能会进一步加快。现有的开放性ASD方法主要依赖多样性启发式或人类兴趣的主观代理来选择假设，但这些方法在处理大量假设时表现出色有限，且主观定义不够精确。本研究旨在通过贝叶斯惊奇来推动开放性ASD，量化LLM对假设的先验信念与获得实验结果后的后续信念变化。为有效地探索嵌套假设空间，研究提出了一种MC搜索(渐进扩展)方法，以惊奇作为奖励函数。该方法评估了21个涉及生物学、经济学、金融和行为科学等多种领域的实际数据集，发现AutoDS在固定预算下能产生比竞争对手多5%-29%的惊人发现，并且三分之二的发现被视为领域专家的惊人之见，这表明这是一个构建开发生物性ASD系统的重要步骤。", "innovation": "提出了AutoDS方法，利用贝叶斯惊奇来推动开放性ASD。通过量化LLM对同一假设在获得实验结果前后信念的变化，以及利用MC搜索策略和渐进扩展，有效地探索了嵌套假设的空间。该方法在固定预算下能显著提升ASD的发现数量，且有相当一部分发现被认为是领域专家所惊喜的。", "conclusion": "通过贝叶斯惊奇AutoDS方法，有效地推动开放性科学探索，系统在限定资源下能显著增加惊人发现。三分之二的发现对领域专家来说是令人惊讶的，这一研究标志着向构建开放性ASD系统迈出重要一步。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00275", "html_url": "https://arxiv.org/abs/2507.00275", "title": "Double Q-learning for Value-based Deep Reinforcement Learning, Revisited", "title_en": "Double Q-learning for Value-based Deep Reinforcement Learning, Revisited", "authors": "Prabhat Nagarajan,Martha White,Marlos C. Machado", "background": "在强化学习（RL）中，过估计是一个普遍存在的问题，包括Q-learning在内。为了减轻这一问题，Double Q-learning通过训练两个不同的Q函数来减少过估计，但目前的Double DQN并没有完整地采用这一机制。现有的Double DQN只是松散地应用了Double Q-learning的理念，没有真正训练两个能够互补的Q函数。因此，研究人员希望通过重新审视Double Q-learning，开发出一种新的算法Deep Double Q-learning (DDQL)，以评估其减少过估计的效果，并探索其在实际智能体中的应用表现，尤其是与现有算法Double DQN的对比表现。", "innovation": "文章提出了一种新的算法Deep Double Q-learning (DDQL)，此算法旨在更完整地应用Double Q-learning的核心思想，即通过同时训练和使用两个互补的Q函数来减少RL中的过估计现象。通过实验研究，DDQL不仅有效减少了过估计，还在57个Atari 2600游戏中总体表现出更好的性能，且不需要额外的超参数调整。文章还探索了DDQL在网络架构、经验重放比例和小批量采样策略等方面的行为和性能差异，以探索最优配置方案。", "conclusion": "实验结果表明DDQL能够有效减少过估计现象，并在多个Atari 2600游戏上超越Double DQN。此外，DDQL在多个方面保持了良好的性能，且不需要引入额外的超参数。这表明DDQL是一个有效的解决强化学习中过估计问题的新颖算法。文章还提出了一系列关于DDQL的改进建议，以便在未来的工作中进一步提升其性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00358", "html_url": "https://arxiv.org/abs/2507.00358", "title": "连续时间线性-二次强化学习问题的数据驱动探索", "title_en": "Data-Driven Exploration for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems", "authors": "Yilie Huang,Xun Yu Zhou", "background": "本文研究的是连续时间随机线性-二次(LQ)控制问题的强化学习( RL )方法，其中波动性依赖于状态和控制，但状态是标量化的，且不存在运行中的控制奖励。研究背景是在与文献[huang2024sublinear]同样的类别的LQ问题上进一步提升学习效率与性能，同时克服了文献[huang2024sublinear]中使用固定探索计划所需的最大调优量和忽视迭代过程中的学习进度的问题。", "innovation": "提出了一种模型无关的、数据驱动的探索机制，可以自适应地通过批评家调整熵正则化并通过行动家调整策略方差。这种方法与文献[huang2024sublinear]中使用的常量或确定性探索调度相比，具有最小化调优的优势，同时提高了学习效率。尽管具有灵活性，该方法仍实现了与该类LQ问题最佳已知模型无关结果相匹配的次线性后悔界限，这些结果之前只能通过固定的探索计划获得。", "conclusion": "数值实验表明，自适应探索可以加速收敛并改善后悔性能，与非自适应模型无关和模型相关的对应方法相比。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00411", "html_url": "https://arxiv.org/abs/2507.00411", "title": "Diffusion Disambiguation Models for Partial Label Learning", "title_en": "Diffusion Disambiguation Models for Partial Label Learning", "authors": "Jinfu Fan,Xiaohui Zhong,Kangrui Ren,Jiangnan Li,Linqing Huang", "background": "在实际的机器学习应用中，从模糊标签中学习是一个长期存在的问题。部分标签学习（PLL）的目标是从与给定实例相关的一组候选标签中识别出正确的标签。受各种生成任务中扩散模型出色表现的启发，本文研究了扩散模型通过逆向去噪过程来处理模糊标签的潜力。", "innovation": "本文提出了一种基于扩散模型的去模糊方法（DDMP），首先利用实例与标签之间潜在的互补信息构建伪干净标签作为初始扩散训练的基础。同时引入了转移感知矩阵，该矩阵可以估计潜在的真实标签并动态更新，从而在扩散生成过程中优化标签的真实度，提高分类器的性能。", "conclusion": "实验结果表明，DDMP在部分标签学习中的优势，证明了其对于处理模糊标签问题的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00390", "html_url": "https://arxiv.org/abs/2507.00390", "title": "MoNE: 使用轻量级新手替换冗余专家以对MoE进行结构化剪枝", "title_en": "MoNE: Replacing Redundant Experts with Lightweight Novices for Structured Pruning of MoE", "authors": "Geng Zhang,Yuxuan Han,Yuxuan Lou,Wangbo Zhao,Yiqi Zhang,Yang You", "background": "MoE能够通过每输入一个词激活一组专家来有效扩展大型语言模型，但由于需要保留所有专家在内存中，这导致了显着的内存开销。虽然结构化剪枝有潜力降低内存成本，但现有方法在模型架构、校准数据源和校准样本量的三个维度上常常表现出不理想的性能和不稳定的降级效果。", "innovation": "本文提出了MoNE（Mixture-of-Novices-and-Experts），一种新型的专家剪枝方法，通过用轻量级新手替换冗余专家来实现有效的模型压缩，减小性能下降。MoNE根据访问频率和输出方差两个指标来评估专家的冗余性。对于使用少且输出稳定的专家会被剪枝替换为轻量化新手，以最小化性能下降。实验结果显示，MoNE在三个维度上优于基线方法，具有有效性及鲁棒性。特别是在25%和50%的剪枝比例下，MoNE在九个下游任务上的平均零样本准确率分别提高了2.71%和3.61%。", "conclusion": "MoNE在三个关键维度上有效且稳健地减少了MoE模型的性能损失，显著提升了性能，尤其是在大规模语言模型中，验证了其作为结构化剪枝的一种方法的有效性和可行性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00440", "html_url": "https://arxiv.org/abs/2507.00440", "title": "因果图回归的方案：重新审视混杂效应", "title_en": "A Recipe for Causal Graph Regression: Confounding Effects Revisited", "authors": "Yujia Yin,Tianyi Qu,Zihao Wang,Yifan Chen", "background": "因果图学习（CGL）作为一个有潜力的手段，已被认为能提升图形神经网络在陌生分布（OOD）场景下的泛化能力。目前CGL技术的应用更多集中于分类任务，相对而言，在图学习中更具挑战性的回归任务则被忽视了。因此，本文致力于解决因果图回归（CGR）问题，通过对现有CGL处理混杂效应的方法进行调整，以适应回归任务的需求，特别是在图层面级的回归任务中，强调解决混杂因素的预测能力，并通过对比学习的视角，推广适用于分类任务的因果干预技术。广泛在图的OOD基准测试集上的实验验证了提案的有效性，相关的模型实现与代码可在以下网址获取：this https URL", "innovation": "本文创新之处在于对现有的CGL方法进行了调整，以适应回归任务，特别是图层面级的回归。通过对原始任务中混杂因素的预测能力进行反思，提出了一套适用于回归任务的对比学习方法，进而推广适用于分类任务的因果干预技术。这种方法在广泛的图的OOD基准测试集上的实验结果表明了其有效性与实用性", "conclusion": "广泛实验结果表明了本文提出的适用于回归任务的对比学习方法的有效性。该方法在处理图层面级的CGR问题上的有效性与实用价值被验证，并提供了相应的模型实现与代码。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00425", "html_url": "https://arxiv.org/abs/2507.00425", "title": "在基于变换器的自回归流中的连续空间灵活语言建模", "title_en": "Flexible Language Modeling in Continuous Space with Transformer-based Autoregressive Flows", "authors": "Ruixiang Zhang,Shuangfei Zhai,Jiatao Gu,Yizhe Zhang,Huangjie Zheng,Tianrong Chen,Miguel Angel Bautista,Josh Susskind,Navdeep Jaitly", "background": "自回归模型在语言建模方面取得了显著进展。但它们对离散令牌、单向上下文和单次解码的一贯依赖，同样激发了探索新设计空间的可能性，以提供更多的建模灵活性。", "innovation": "提出了一种名为TarFlowLM的新框架，该框架使用基于变换器的自回归归一化流来建模连续表示。这种方法解锁了巨大的灵活性，可以构建可以通过堆叠交替方向自回归变换捕捉全局双向上下文的模型，支持基于块的生成和灵活的令牌块大小，以及促进分层多遍生成过程。此外，还提出了新的混合耦合变换，以捕捉由离散数据形成的潜在空间中复杂的依赖关系，并证明与传统的离散自回归模型存在理论联系。", "conclusion": "在语言建模基准上的大量实验显示了强大的似然性能，并强调了本框架内在的灵活性建模能力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00467", "html_url": "https://arxiv.org/abs/2507.00467", "title": "意识多样性改进的随机森林", "title_en": "Diversity Conscious Refined Random Forest", "authors": "Sijan Bhattarai,Saurav Bhandari,Girija Bhusal,Saroj Shakya,Tapendra Pandey", "background": "随机森林（RF）是一种广泛使用的组合学习技术，具有跨多种领域的稳健分类性能。然而，它通常依赖于成百上千的树和所有输入特征，导致高推断成本和模型冗余。", "innovation": "本文提出了一种改进的随机森林分类器（Refined Random Forest Classifier），该分类器通过以下步骤迭代地改进自己：首先去除最不具信息性的特征，然后分析性地确定应生长多少新树，最后通过基于相关性的聚类去除冗余树。与标准RF在相同数量的树上进行比较，实验结果显示该提出的模型在8个多种基准数据集上（包括二分类和多分类数据集）的分类精度优于标准RF。", "conclusion": "提出的模型通过动态仅在信息性特征上生长树木、并分级化地确保最大多样性，从而提高了分类准确性，并减少了模型冗余和高推断成本。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00265", "html_url": "https://arxiv.org/abs/2507.00265", "title": "在刺激等价性模拟中考察拒绝关系", "title_en": "Examining Reject Relations in Stimulus Equivalence Simulations", "authors": "Alexis Carrillo,Asieh Abolpour Mofrad,Anis Yazidi,Moises Betancort", "background": "模拟为探索刺激等价性（SE）提供了有价值的工具，但是拒绝关系可能干扰等价类形成评估的观点仍存在争议。这项研究通过计算模型探讨了拒绝关系在刺激等价性获取中的作用。使用了前向神经网络（FFNs）、双向编码变换器（BERT）和生成预训练变换器（GPT）等模型，并通过匹配样本（MTS）模拟了18种不同情况。这些情况在训练结构（线性序列、一对一和多对一）、关系类型（仅选择、仅拒绝和选择-拒绝）以及消极比较选择（标准和有偏）上有差异。一个概率代理作为基准，代表纯粹的关联学习。主要目标是确定人工神经网络是否能够展示等价类形成，或者其表现是否反映关联学习。结果显示，拒绝关系影响了代理的表现。虽然某些代理在等价测试中获得了高准确度，特别是在有拒绝关系和有偏消极比较的情况，但其表现与概率代理相似。这些发现表明，包括变换器模型在内的人工神经网络可能依赖于关联策略而非SE。这强调了在等价性计算模型中仔细考虑拒绝关系和使用更严格的标准的重要性。", "innovation": "本研究创新之处在于利用计算模型（如前向神经网络、BERT和GPT）探讨了拒绝关系在刺激等价性形成中的作用，特别是在匹配样本（MTS）模拟中。通过不同条件下的对比分析，研究揭示了拒绝关系对代理绩效的影响，并指出人工神经网络可能依赖于关联学习策略，而不是刺激等价性。", "conclusion": "研究结果表明，人工神经网络，包括变换器模型，可能依赖于关联策略而非刺激等价性。因此，人工神经网络在等价类形成方面可能不会像预期的那样表现出不同。这些发现强调了在等价性计算模型中必须仔细考虑拒绝关系，并应用更严格的标准。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00445", "html_url": "https://arxiv.org/abs/2507.00445", "title": "迭代蒸馏在生物分子设计中奖励导向微调扩散模型的应用", "title_en": "Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design", "authors": "Xingyu Su,Xiner Li,Masatoshi Uehara,Sunwoo Kim,Yulai Zhao,Gabriele Scalia,Ehsan Hajiramezanali,Tommaso Biancalani,Degui Zhi,Shuiwang Ji", "background": "扩散模型在模拟复杂、高维数据分布方面表现出高度有效性，但在现实应用中，往往需要根据可能非可微的奖励函数（如基于物理的模拟或科学知识奖励）进行优化。虽然已经探索了通过强化学习方法对扩散模型进行微调以满足这些目标，但这种方法通常存在不稳定、样本效率低和模式崩溃等问题。本文的背景是提出了一种迭代蒸馏微调框架，以使扩散模型能够优化任意奖励函数。这种方法通过策略蒸馏问题，结合了离策略采集训练数据、模拟奖励导向的软最优策略和通过最小化模拟软最优策略和当前模型策略之间的KL散度来更新模型，从而提高训练稳定性和样本效率。通过对蛋白、小分子和调控DNA设计等不同任务的实验结果表明，本文提出的方法在奖励优化方面具有有效性并优于现有方法。", "innovation": "本文提出了一种迭代蒸馏微调框架，这种方法通过策略蒸馏问题，结合了离策略采集训练数据、模拟奖励导向的软最优策略和通过最小化模拟软最优策略和当前模型策略之间的KL散度来更新模型。相较现有的基于强化学习的方法，这种方法提高了训练稳定性和样本效率。", "conclusion": "本文通过实验表明，提出的迭代蒸馏微调框架在奖励导向的优化方面效果良好，并且在蛋白质、小分子和调控DNA设计等多种任务中均表现出优越性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00394", "html_url": "https://arxiv.org/abs/2507.00394", "title": "HelixPipe: 使用注意并行管道并行性的长序列变压器高效分布式训练", "title_en": "HelixPipe: Efficient Distributed Training of Long Sequence Transformers with Attention Parallel Pipeline Parallelism", "authors": "Geng Zhang,Shenggan Cheng,Xuanlei Zhao,Ziming Liu,Yang You", "background": "随着变压器序列长度的增长，现有的流水线并行性由于注意力计算的二次方计算和显著的内存开销而出现次优化性能。为了解决这些挑战，本文提出HelixPipe，这是一种用于长序列变压器训练的新颖流水线并行性。HelixPipe通过引入注意力并行分区，实现了不同微批次的注意力计算在不同流水线阶段的并行调度，减少了流水线中的空闲时间。同时，它采用双栈先入后出的微批次调度方式平衡内存使用，以及使通信与计算互相重叠。此外，HelixPipe通过无注意重计算和分块MLP来减少碎片并支持更长的序列长度。实验表明，HelixPipe在长序列长度下具有越来越大的优势，且在吞吐量和可扩展性方面超越了现有方法。在64个H20 GPU上训练7B模型时，HelixPipe与基础方法相比，达到了26%的加速效果。该代码可在提供的链接处查找。", "innovation": "提出了HelixPipe，一种新型的长序列变压器训练流水线并行性方法。包括注意力并行分区，双栈先入后出的微批次调度，无注意重计算以及分块MLP等技术，有效缓解注意力计算的二次方计算和显著的内存开销问题，提高了模型训练的效率和可扩展性。", "conclusion": "实验表明，HelixPipe在长序列训练上具有显著优势，对于不同规模的模型和集群配置都有较好的吞吐量和可扩展性表现。与基准方法相比，在特定配置下可以实现26%的速度提升。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00449", "html_url": "https://arxiv.org/abs/2507.00449", "title": "通过上下文相关稀疏注意克服状态空间模型的长上下文限制", "title_en": "Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention", "authors": "Zhihao Zhan,Jianan Zhao,Zhaocheng Zhu,Jian Tang", "background": "自然语言处理(NLP)中高效处理长上下文仍然是一项关键挑战，由于主要的Transformer架构的时间复杂度随着序列长度的增加而呈平方级增长。尽管状态空间模型(SSMs)提供了次平方级的替代方案，但它们在捕捉长距离依赖性方面效果不佳。广泛使用的合成任务，如关联回忆，对于模型仅要求召回单个键对应的值，缺乏上下文信息，不足以模拟真实世界的长上下文场景。因此，文章提出了改进SSMs的长上下文建模能力的新方法，包括引入一个新型合成任务——联合回忆，以及结合上下文相关的稀疏注意机制来解决这一问题。", "innovation": "本文提出了一种新的合成任务——联合回忆，强调了与上下文相关的模型能力，并通过引入上下文依赖的稀疏注意机制（CDSA）以及基于局部敏感哈希的稀疏键选择注意力（HAX）方法，提高了状态空间模型在长上下文处理中的有效性，解决了SSMs在长上下文学习上的不足。这不仅改善了理论分析的有效性和准确性，还将在实际应用中表现出色并超越了基线和集成的方法。", "conclusion": "广泛的实验表明，HAX方法在合成和实际的长上下文基准测试中，总是优于基于SSM的基线和与上下文无关的稀疏注意力集成方法，证明了该方法在长上下文建模中的优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00453", "html_url": "https://arxiv.org/abs/2507.00453", "title": "带有分块注意力的循环增强变换器模型及其长期上下文语言建模", "title_en": "Recurrent Memory-Augmented Transformers with Chunked Attention for Long-Context Language Modeling", "authors": "Ankit Kashyap", "background": "当前的语言模型通常采用Transformer架构来处理文本数据。然而，这些模型在处理长上下文依赖时可能会遇到难题，尤其是在保持计算效率的同时捕捉长距离依赖关系。本文探讨了一种新的Transformer架构，它利用全局注意机制与生物学启发的分块局部注意和递归网络启发的记忆机制，来更有效地处理短距离和长距离依赖关系，同时避免增加线性级的注意力成本。", "innovation": "该论文提出了一种结合了分块局部注意机制、递归网络启发的记忆机制以及旋转位置编码的Transformer架构。这种统一的注意模块能够有效地处理短距离和长距离依赖而无需增加注意力成本。记忆模块通过门控更新机制持久地存储过去词元的表示，并使用旋转位置编码来提供方向分离、比例不变的位置信号。此外，该架构完全使用PyTorch从零开始实现，提高了实验的透明性和模块性。", "conclusion": "本文提出的方法为对话建模、代码补全和文档理解等任务提供了一个轻量级且可扩展的设计，其模型表现为能够高效处理长上下文依赖的Transformer变体。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00485", "html_url": "https://arxiv.org/abs/2507.00485", "title": "PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning", "title_en": "PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning", "authors": "Weiran Guo,Guanjun Liu,Ziyuan Zhou,Ling Wang", "background": "在使用强化学习（RL）解决代理与环境互动以最大化奖励的任务时，安全强化学习（Safe RL）已得到广泛应用。然而，Safe RL在处理安全约束时可能受到后门攻击的影响，这些攻击会导致代理执行不安全的行为。本文首先介绍了Safe RL领域的相关概念和评估指标，提出了一个包含正负行动样本（PNAct）的后门攻击框架。", "innovation": "本文首次提出了一个同时利用正负行动样本（PNAct）的后门攻击框架。通过理论分析PNAct的特性并设计了一种攻击算法，有效评估了该后门攻击框架的效果。这项工作强调了在Safe RL中植入后门攻击的可能性，并揭示了潜在的安全风险。", "conclusion": "本文突出显示了Safe RL中存在的潜在风险，并确认了这种攻击的可行性。作者还提供了用于评估所提出后门攻击框架的相关代码和补充材料。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00451", "html_url": "https://arxiv.org/abs/2507.00451", "title": "通用游戏中的最佳代理识别", "title_en": "Best Agent Identification for General Game Playing", "authors": "Matthew Stephenson,Alex Newcombe,Eric Piette,Dennis Soemers", "background": "研究者们正在探索如何在多问题域中高效且通用地识别出最适合每个子任务的算法。这通常被作为多臂bandits中的最佳臂识别问题处理，其中每个bandits对应一个特定的任务，每个arm对应一个特定的算法或代理。现有的一些算法未能充分利用所有尝试过的方法的表现去优化选择过程，导致了性能上的局限。本研究的目标是在有限的试验次数下，在最流行的通用视频游戏AI (GVGAI)框架和Ludii通用游戏竞技系统中，找出表现最佳的代理，以显著改善代理评估程序的质量和准确性。", "innovation": "提出了一种基于威尔逊分数区间（Optimistic-WS）的乐观选择策略，这种策略能够对所有bandits中的每个arm进行排名，按其潜在的后悔减少来评估。与之前的多臂bandits的最佳臂识别算法相比，我们的方法在平均简单后悔方面的性能有了显著提升，证明了这种方法在通用游戏框架和高算法运行时间的多任务域中的有效性。", "conclusion": "通过我们的Optimistic-WS方法，可以在有限试验次数内，在通用游戏框架中显著提高代理评估的质量和准确性，这为开发更高效的多任务学习和优化方法提供了新的思路。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00480", "html_url": "https://arxiv.org/abs/2507.00480", "title": "在潜在空间中进行后验推断以实现可扩展的约束黑盒优化", "title_en": "Posterior Inference in Latent Space for Scalable Constrained Black-box Optimization", "authors": "Kiyoung Om,Kyuil Sim,Taeyoung Yun,Hyeongyu Kang,Jinkyoo Park", "background": "高维度的黑箱函数优化在科学和工程问题中非常普遍，但通常较之无约束问题更加困难，因为可行区域难以找到。虽然贝叶斯优化方法可以解决这些问题，但在高维度空间中往往面临着维度灾难的问题。此外，基于生成模型的方法虽然表现出了潜力，但是却存在可扩展性差和模式聚类的问题，尤其是在目标分布高度多模态的情况下更为明显。", "innovation": "本文提出了一种新的框架来解决上述挑战。该方法包括两个阶段：首先训练基于流的模型来捕捉数据分布以及预测函数值和约束违背情况的近似模型，并进行不确定性量化；其次，将候选者选择问题转化为后验推断问题，从潜在空间中寻找具有高目标值且不会违背约束的候选者。通过在流模型的潜在空间中进行后验分布的近似采样，而不是在数据空间中采样，可以有效缓解多模态和平台区域带来的问题，从而实现可扩展的约束黑盒优化算法。", "conclusion": "通过实验发现，本文方法在多种合成和现实世界约束黑盒优化任务上获得了卓越的性能。代码已公开可在 \texttt{this https URL} 获得。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00651", "html_url": "https://arxiv.org/abs/2507.00651", "title": "GANs秘密进行近似贝叶斯模型选择", "title_en": "GANs Secretly Perform Approximate Bayesian Model Selection", "authors": "Maurizio Filippone,Marius P. Linhard", "background": "生成对抗网络（GANs）是流行的生成模型，在许多应用中都非常成功。尽管取得了这些成就，GANs的优化仍然非常具有挑战性，需要防止过拟合的正则化措施。", "innovation": "通过将GANs解释为概率生成模型，作者能够将其视为具有部分随机性的贝叶斯神经网络，从而建立了通用逼近条件。将几种GANs变体的对抗优化视作边际似然的代理优化，利用边际似然优化与奥卡姆剃刀之间的联系，定义了正则化和优化策略以平滑损失景观，并寻找具有最小描述长度的解决方案，而这与平坦极小值和良好的泛化能力相关。实验证明了这些策略带来了性能提升，并为GANs的正则化策略提供了更深入的理解路径。", "conclusion": "这些策略改善了性能并为理解GANs的正则化策略打开了新的思路，通过近似贝叶斯模型选择这一视角，揭示了GANs优化的本质。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00589", "html_url": "https://arxiv.org/abs/2507.00589", "title": "量子电路结构优化在量子强化学习中的应用", "title_en": "Quantum Circuit Structure Optimization for Quantum Reinforcement Learning", "authors": "Seok Bin Son,Joongheon Kim", "background": "强化学习（RL）使智能体通过与环境的互动学习最优策略。然而，由于高维空间中的维度灾难，RL的学习效率受到了限制。量子强化学习（QRL）通过利用量子计算中的叠加和纠缠来解决这个问题，使得在资源较少的情况下能够有效处理高维问题。QRL结合了量子神经网络（QNN）和RL，其中参数化量子电路（PQC）作为核心计算模块。PQC通过门操作进行线性和非线性变换，类似于经典神经网络中的隐藏层。然而，之前的QRL研究使用了基于经验直觉的固定PQC结构，而没有验证其最优性。", "innovation": "本文提出了一种QRL-NAS算法，集成量子神经架构搜索（QNAS）以优化QRL中的PQC结构。实验结果表明，与使用固定电路的QRL相比，QRL-NAS能够获得更高的奖励，从而验证了其有效性和实用性。", "conclusion": "QRL-NAS算法通过优化PQC结构，提高了QRL的学习效率，验证了其在量子强化学习中的有效性和实用性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00518", "html_url": "https://arxiv.org/abs/2507.00518", "title": "使用von Mises-Fisher采样在超球面嵌入中探索大规模动作集", "title_en": "Exploring Large Action Sets with Hyperspherical Embeddings using von Mises-Fisher Sampling", "authors": "Walid Bendada,Guillaume Salha-Galvan,Romain Hennequin,Théo Bontempelli,Thomas Bouabça,Tristan Cazenave", "background": "在强化学习（RL）问题中，当动作集由超球面嵌入向量表示时，探索大规模动作集是一项挑战。传统的探索方法，如Boltzmann 探索（B-exp），虽然广受欢迎但存在可扩展性问题，因为计算 softmax 值对于每个动作都是耗时的。因此，需要一种在保持高可扩展性的同时有效探索大规模动作集合的方法。本研究提出了von Mises-Fisher探索（vMF-exp），这是一种利用超球面嵌入探索动作集的方法，可以处理数量庞大的候选动作。", "innovation": "vMF-exp 引入了一种采用 von Mises-Fisher 分布进行初始采样的方法，并探索该表示的最近邻，这种方案具有高度可扩展性，可以几乎无限地扩展到动作集。论文证明，在理论假设下，vMF-exp 以与 B-exp 相同的概率探索每个动作，而无需对每个动作进行软最大化计算，从而解决了 B-exp 的可扩展性问题。", "conclusion": "实验结果表明，vMF-exp 在模拟数据、真实世界公开数据以及全球音乐流媒体服务的推荐系统中的大规模部署中展现了其核心特性。vMF-exp 作为一种替代 B-exp 的可扩展方法，成功处理了大量嵌入超球面的动作集的探索问题。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00574", "html_url": "https://arxiv.org/abs/2507.00574", "title": "面向健康系统的临床记录的基模型", "title_en": "Foundation Models for Clinical Records at Health System Scale", "authors": "Haresh Rengaraj Rajamohan,Xiang Gao,Weicheng Zhu,Shih-Lun Huang,Long Chen,Kyunghyun Cho,Cem M. Deniz,Narges Razavian", "background": "大规模预训练已经彻底改变了语言和其他数据类型的建模，但在医疗保健领域，特别是带有结构化电子健康记录(EHRs)的领域，其潜力未被充分开发。本文提出了一种新颖的生成预训练策略，用于序贯EHR数据，通过预测下一个就诊事件来学习自回归生成各种格式化的临床事件，并内含地处理不同数据类型的联合预测。此外，该研究还引入了对重复事件预测的正则化措施，并指出基于EHR的基模型评估中的一个关键问题：当未能区分新发病和后续发生时，重复事件标记会夸大性能指标。", "innovation": "该研究提出了一个新的生成式预训练策略，专门针对序列形式的EHR数据，通过预测下一个访问事件来生成自回归的临床事件序列。该模型能够学习复杂的临床依赖关系，同时避免特定任务的微调，以其出色的零样本预测性能证明了这一点，在预测2年内和5年内痴呆症和膝骨关节炎的发生率方面，表现可与完全微调的掩码预训练变换器基线相媲美。", "conclusion": "该模型展示了在大量EHR数据上捕捉复杂临床依赖关系的能力，没有使用成本高昂的任务特定微调。此外，还发现了一个重要的评估问题，即基于EHR的基模型评估时，重复事件标记可能会使性能指标虚假提升，强调在评价模型时必须区分新发病和后续发生的情况。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00647", "html_url": "https://arxiv.org/abs/2507.00647", "title": "Cooperative Sheaf Neural Networks", "title_en": "Cooperative Sheaf Neural Networks", "authors": "André Ribeiro,Ana Luiza Tenório,Juan Belieni,Amauri H. Souza,Diego Mesquita", "background": "近来，鞘扩散（Sheaf diffusion）因其天生能够处理异质数据并且避免信息过光滑的问题，被证明是一种有前途的图表示学习设计模式。同时，合作式信息传递已经被提出作为一种增强信息扩散灵活性的方式，允许节点自主选择是否传播或收集来自邻居的信息。但现有鞘扩散方法未能表现这种合作行为，这归因于其缺乏消息方向性。为解决这一局限，作者引入了有向图上的细胞鞘及其对应的入度和出度拉普拉斯矩阵的概念，并基于此提出了一种新的合作鞘神经网络（CSNNs）", "innovation": "作者提出了一种新的合作鞘神经网络（CSNNs），通过引入有向图上的细胞鞘及其对应的入度和出度拉普拉斯矩阵的概念来解决现有鞘扩散方法缺乏消息方向性的局限。CSNN允许节点选择性地关注路径上的任意节点，减少信息过碾压问题，从而在图表示学习任务中表现出更好的性能", "conclusion": "理论上，CSNN通过其接收域表征了节点选择性地关注远处节点的能力，避免忽略路径中的其他节点，这可能有助于缓解信息过碾压的问题。实验证明，CSNN在鞘扩散和合作图神经网络方面的性能优于现有方法"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00611", "html_url": "https://arxiv.org/abs/2507.00611", "title": "基于残差奖励模型的偏好强化学习", "title_en": "Residual Reward Models for Preference-based Reinforcement Learning", "authors": "Chenyang Cao,Miguel Rogel-García,Mohamed Nabail,Xueqian Wang,Nicholas Rhinehart", "background": "偏好强化学习（PbRL）提供了一种方法，在奖励信号难以指定的环境中学习高性能策略，这种方法避免了手工设计奖励信号的繁琐过程。然而，PbRL 收敛速度较慢，因为它需要在奖励模型中进行训练。以前的研究提出从演示学习奖励模型，并对其进行微调以利用偏好。但是，当模型为神经网络时，在预训练和微调中使用不同的损失函数可能会给可靠的优化带来挑战。本文旨在有效利用先验知识，引入残差奖励模型（RRM）。RRM 假设环境的真实奖励可以分为两部分之和：先验奖励和待学习奖励。先验奖励在训练前就可用，例如用户的“最佳猜测”奖励函数，或逆强化学习（IRL）学习到的奖励函数；待学习奖励通过偏好进行训练。研究了基于状态和基于图像两种版本的RRM，并在Meta-World环境包中的多个任务上进行评估。实验证明了该方法在常见PbRL方法上的显著改进，对于不同类型的先验奖励，包括代理奖励，从逆强化学习获得的奖励，甚至代理奖励的否定版本，实现显著提升。实验还在Franka Panda上进行，并展示了该方法在真实机器人上的优异表现，在不同任务上加速了策略学习，比基准方法更少的步骤即达成功。关于结果的视频请见：this https URL", "innovation": "提出了残差奖励模型（RRM），该模型能够通过将环境的真实奖励分解为先验奖励和待学习奖励，有效利用先验知识。论文引入了基于状态和基于图像两种版本的RRM，并在多种任务上进行了评估，展示了其对现有PbRL方法的显著改进。实验还在真实机器人Franka Panda上验证了该方法的有效性，并大幅加速了策略学习过程，少于基准方法的步骤即可成功完成任务。此外，该方法对于不同类型的先验奖励都显示出了良好的泛化能力，涵盖了代理奖励和逆强化学习获得的奖励及其否定版本。", "conclusion": "本文提出的残差奖励模型（RRM）有效结合了PbRL的偏好学习和先验知识，通过将环境中真实的奖励分解为先验奖励和待学习奖励，显著改善了PbRL的性能，尤其在真实机器人上的应用展示了加速策略学习的能力并且成功完成任务的步骤更少。对于不同的先验奖励，包括代理奖励、逆强化学习获得的奖励及其否定版本，该方法均表现出显著的改进效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00653", "html_url": "https://arxiv.org/abs/2507.00653", "title": "认知负载感知推理：一种神经符号框架用于优化大型语言模型的令牌经济", "title_en": "Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models", "authors": "Yilun Zhang", "background": "大型语言模型（LLM）推理的计算成本日益升高，成为其广泛应用和可持续部署的关键障碍。当前已有的一些优化策略效果显著，但它们主要是基于统计启发式或架构修改，缺乏指导认知过程本身的认知理论。本文旨在通过引入一种新型框架——认知负载感知推理（CLAI），结合认知负载理论（CLT）和神经科学原理，来填补这一空白。本文将内在认知负载、外在认知负载和相关认知负载概念量化，将推理过程重新定义为一种认知经济优化问题，从而实现了显著的计算效率提升和准确性保持。此外，CLAI-Tune模型还展现出一种自主分解难题的能力，这与人类专家的认知特征相符。研究表明，通过模仿大脑的资源管理策略，可以构建更加高效、鲁棒和强大的人工智能系统。", "innovation": "本文提出的认知负载感知推理（CLAI）框架，提出了内在认知负载、外在认知负载和相关认知负载的概念量化方法，将其推理过程重新定义为认知经济优化问题。CLAI-Tune模型能够自主将其所学到的原理内化，实现高效推理。与现有方法相比，CLAI框架在多个基准测试中显示出了显著的优势，如在复杂推理、长上下文问答和代码生成中，能显著减少令牌消耗（最多可减少45%），并且不牺牲准确性。此外，CLAI-Tune模型还表现出类似人类专家的自主问题分解能力。", "conclusion": "通过模仿人脑的资源管理策略，本文展示了如何构建更高效、更鲁棒和更强大的人工智能系统。CLAI框架为如何更好地理解和优化大型语言模型的认知处理过程提供了一种新的视角，具有重要的理论和实践意义。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00654", "html_url": "https://arxiv.org/abs/2507.00654", "title": "基于神经网络增强的卡尔曼滤波器及道路网络辅助的GNSS定位", "title_en": "Neural Augmented Kalman Filters for Road Network assisted GNSS positioning", "authors": "Hans van Gorp,Davide Belli,Amir Jalalirad,Bence Major", "background": "全球导航卫星系统（GNSS）在全球范围内提供关键的定位信息，但在密集的城市环境中，由于多路径和非视距错误的影响，其定位精度往往会降低。道路网络数据可以用来减少这些错误的影响，提高定位系统的准确性。然而，以往使用道路网络数据的方法要么仅限于离线应用，要么依赖于卡尔曼滤波器（KF）的启发式方法，这些方法缺乏灵活性和鲁棒性。", "innovation": "我们提出了训练一个时序图形神经网络（TGNN）来将道路网络信息整合到卡尔曼滤波器中。TGNN旨在预测正确的道路段及其相关不确定性，以便在卡尔曼滤波器的测量更新步骤中使用。我们使用真实世界的GNSS数据和开源的道路网络验证了我们的方法，在具有挑战性的场景中观察到定位误差降低了29%。根据我们的知识，这是首个结合道路网络数据和GNSS测量的深度学习方法，用于确定地球上用户的地理位置。", "conclusion": "我们提出的方法将道路网络与GNSS测量数据结合，利用时序图形神经网络优化卡尔曼滤波器，从而在具有挑战性的城市环境中显著降低了GNSS定位误差。这是首个实现这一目标的深度学习方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00711", "html_url": "https://arxiv.org/abs/2507.00711", "title": "大型推理模型并不直奔主题：思考轨迹的不可靠性", "title_en": "Large Reasoning Models are not thinking straight: on the unreliability of thinking trajectories", "authors": "Jhouben Cuesta-Ramirez,Samuel Beaussant,Mehdi Mounsif", "background": "经过强化学习训练的大规模语言模型（LLMs）在推理基准测试中取得了令人印象深刻的结果。然而，越来越多的证据表明，这些模型往往会生成更长但无效的推理链（CoTs），这让他们在基准测试中的进步引发了质疑，即这些进步是否反映出了真实的推理能力提升。研究发现，这些模型会在已经提供正确解决方案的情况下，继续生成不必要的推理步骤，这些步骤往往会导向错误的结论。", "innovation": "研究发现，即使在已经提供正确解决方案的情况下，这些模型仍倾向于继续生成不必要的推理步骤，导致错误的结论。这项研究使用AIME2024数学基准测试对三个最先进的模型进行了实验，揭示了这些模型在整合纠正信息方面存在的关键局限，提出了实现稳健和可解释推理的新挑战。", "conclusion": "这些模型的推理流程存在不可靠性，甚至在已经提供正确解决方案的情况下仍会生成不必要的推理步骤，最终导致错误的结论。这些发现揭示了这些先进模型的局限性，提出了实现可解释和稳健推理的挑战。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00695", "html_url": "https://arxiv.org/abs/2507.00695", "title": "基于测试函数的方法的增量稳定性", "title_en": "A Test-Function Approach to Incremental Stability", "authors": "Daniel Pfrommer,Max Simchowitz,Ali Jadbabaie", "background": "论文提出了一种新的框架，用于基于奖励作为“测试函数”的思想分析增量输入到状态稳定性（δISS）。传统控制理论中的稳定性证明通常基于满足时间减少条件的李雅普诺夫函数，而强化学习（RL）的价值函数则是通过指数衰减非光滑、无界且从两方面都存在的情况下的一致Lipschitz奖励函数构建的。这使得RL风格的价值函数无法直接作为李雅普诺夫证明使用。在给定策略的闭环系统下，当前工作发展了一种新的等价性，该等价性将增量输入状态稳定性的变体与鲁棒持续选择Hölder连续奖励函数下的价值函数的正则性联系起来。这一结果显示了价值函数的正则性以及其与增量稳定性之间的关系可以以不同于传统的基于李雅普诺夫方法的控制理论认证稳定性的新方式来理解。", "innovation": "提出了一种新的方法，通过将奖励函数作为‘测试函数’来分析增量输入状态稳定性。这一方法将增量输入状态稳定性和价值函数的正则性联系起来，特别是与鲁棒持续选择Hölder连续奖励函数的正则性之间的等价关系。这种方法将传统的基于李雅普诺夫函数的方法与现代强化学习方法有效结合起来，并且为认证系统的增量稳定性提供了一个新的视角。", "conclusion": "这种方法将传统控制理论中的李雅普诺夫方法与现代强化学习中基于奖励价值的方法相结合，揭示了价值函数的正则性与系统增量稳定性之间的显著关系，为认证系统稳定性提供了一种新的分析框架。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00687", "html_url": "https://arxiv.org/abs/2507.00687", "title": "非鲁棒分类器的扩散分类指导", "title_en": "Diffusion Classifier Guidance for Non-robust Classifiers", "authors": "Philipp Vaeth,Dibyanshu Kumar,Benjamin Paassen,Magda Gregorová", "background": "分类器指导旨在引导扩散过程，以便给定的分类器能够可靠地识别生成的数据点。然而，大多数分类器指导方法仅适用于鲁棒性分类器，这些分类器是在扩散前向过程的噪声数据上专门进行训练的。这项研究旨在将分类器指导扩展应用到没有噪声训练的一般鲁棒性分类器上，并通过分析CelebA数据集、专门的SportBalls数据集以及高维的CelebA-HQ数据集，探究两者对扩散过程噪声的敏感性。研究发现，非鲁棒性分类器在噪声条件下会表现出显著的准确率下降，导致不稳定的方向梯度。因此，研究通过提出一种方法来解决这些问题，该方法利用一步去噪图像预测，并结合了受随机优化方法启发的稳定化技术，如指数移动平均。实验结果表明，该方法能够提高分类器指导的稳定性，同时保持样本的多样性和视觉质量。这项工作对生成模型中条件采样技术的发展做出了贡献，使其能够使用更广泛的分类器作为指导分类器。", "innovation": "提出了一种将分类器指导扩展到未受到噪声训练的鲁棒性分类器的方法。通过利用一步去噪图像预测并结合随机优化方法中的稳定化技术，解决了因噪声而导致的不稳定性问题，从而提高了生成模型的分类指南的稳定性和样本质量。", "conclusion": "通过实例证明，改进的方法能够在维持样本多样性和视觉质量的同时，提高使用非鲁棒性分类器作为指导分类器的稳定性。这项工作为生成模型中条件采样技术的发展做出了贡献。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00701", "html_url": "https://arxiv.org/abs/2507.00701", "title": "SCAWaveNet: 基于空间通道注意力的网络用于全球 significan 波高检索", "title_en": "SCAWaveNet: A Spatial-Channel Attention-based Network for Global Significant Wave Height Retrieval", "authors": "Chong Zhang,Xichao Liu,Yibing Zhan,Dapeng Tao,Jun Ni", "background": "近年来，基于空间侦察的GNSS任务生成了广泛的全球数据集，为利用深度学习方法检索显著波高（SWH）提供了坚实的基础。现有深度学习模型主要依赖CYGNSS数据和四通道信息，但经常使用单一通道输入或简单的通道串联，没有在训练时充分利用跨通道信息的交互优点。", "innovation": "本文提出了一种新颖的基于空间通道注意力的空间-通道注意力网络（SCAWaveNet），其中每个通道的DDMs特征作为独立的注意力头进行建模，使空间和通道级信息得以融合。还设计了轻量级注意力机制，通过空间和通道维度分配权重。这种网络通过四通道CYGNSS数据评估性能，显示在ERA5参考下，SCAWaveNet的平均RMSE为0.438米，使用NDBC浮标数据时平均RMSE为0.432米。与现有模型相比，在ERA5数据集上平均RMSE降低了至少3.52%，在NDBC浮标观测上降低了5.47%。", "conclusion": "SCAWaveNet通过有效地融合通道间和空间信息，显著提高了SWH的检索精度，比现有模型具有更好的性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00733", "html_url": "https://arxiv.org/abs/2507.00733", "title": "通过二元化方法衡量序数分类中的 aleatoric 和 epistemic 不确定性", "title_en": "Aleatoric and Epistemic Uncertainty Measures for Ordinal Classification through Binary Reduction", "authors": "Stefan Haas,Eyke Hüllermeier", "background": "序数分类问题涉及具有自然顺序的标签，常见于医疗和金融等领域。准确的不确定性量化，特别是将其分解为 aleatoric（固有变异性）和 epistemic（知识不足）成分，对于可靠的决策至关重要。现有研究主要集中在名义分类和回归上，鲜有关于序数分类的不确定性测量方法研究。", "innovation": "本文提出了一种新的衡量序数分类中 aleatoric 和 epistemic 不确定性的方法，该方法基于二元情况下的熵和方差度量，并能有效捕捉序数分类中的精确率和最小误差距离之间的权衡。通过表数据基准和梯度提升树及多层感知机的集成网络，本文方法在错误检测和越分布检测方面优于标准和标签级的熵和方差度量。", "conclusion": "本研究的结果强调在评估不确定性时必须考虑分类问题的序数性质。通过序数度量方法，本文的方法在错误检测和越分布检测方面表现优秀，突显了直接处理序数分类问题的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00669", "html_url": "https://arxiv.org/abs/2507.00669", "title": "Audio-3DVG: 统一的音频-点云融合用于3D视觉定位", "title_en": "Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding", "authors": "Duc Cao-Dinh,Khai Le-Duc,Anh Dao,Bach Phan Tat,Chris Ngo,Duy M. H. Nguyen,Nguyen X. Khanh,Thanh Nguyen-Tang", "background": "3D视觉定位（3DVG）涉及基于自然语言在3D点云中定位目标对象。尽管以往的工作已经利用了文本描述取得了显著的进展，但利用口头语言进行3D视觉定位——即基于音频的3D视觉定位——仍处于起步阶段并充满挑战。该领域的努力被自动语音识别（ASR）和语音表示学习的进展所激发，本研究提出了一种简单的且有效的框架Audio-3DVG，该框架结合了音频和空间信息以增强视觉定位。不同于将音频作为单一输入进行处理，研究将任务分解为两个互补的部分：首先是对象提及检测任务，该任务多标签分类以明确识别音频中提及的对象，从而促进了更结构化的音频场景推理；其次是提出的音频引导注意力模块，该模块捕捉候选对象与关系性语音线索之间的相互作用，从而在嘈杂场景中提高了目标的辨别性.", "innovation": "Audio-3DVG提出了一种有效的框架，该框架将音频和空间信息集成，通过对象提及检测和音频引导注意力模块，实现了在嘈杂场景中的目标更优定位，并通过自动语音识别（ASR）和语音表示学习的进步得到进一步提升。该研究还合成了标准3DVG数据集（包括ScanRefer，Sr3D和Nr3D）的音频描述，以支持基准测试。实验结果显示，Audio-3DVG不仅在基于音频的定位中达到了新的最佳性能，还与基于文本的方法竞争，突显了将口头语言整合到3D视觉任务中的潜力.", "conclusion": "Audio-3DVG不仅提出了一种先进的基于音频的3D视觉定位方法，而且还表明该方法在粘连场景中更优越的定位能力。通过合成标准3DVG比赛的数据集的音频描述，该研究为评估不同视觉定位技术提供了坚实的基础。音频信息的有效利用可以提高现有基于文本的方法的能量，有望成为3D视觉领域的一个重要突破。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00848", "html_url": "https://arxiv.org/abs/2507.00848", "title": "量子近似优化算法用于HIV时空簇预测", "title_en": "Quantum Approximate Optimization Algorithm for Spatiotemporal Forecasting of HIV Clusters", "authors": "Don Roosan,Saif Nirzhor,Rubayat Khan,Fahmida Hai,Mohammad Rifat Haidar", "background": "HIV流行病学数据变得更加复杂，需要先进的计算方法来准确检测和预测簇分布。本文通过使用量子加速的机器学习技术，基于AIDSVu和合成社会人口因素（SDoH）数据，分析了2022年ZIP码级别的HIV患病情况。这种方法比较了传统的聚类算法（DBSCAN、HDBSCAN）与量子近似优化算法（QAOA），开发了结合量子和经典神经网络的混合模型来预测HIV患病率，并利用量子贝叶斯网络探索了社会人口因素与HIV发病率之间的因果关系。", "innovation": "量子近似优化算法（QAOA）在群簇检测中的应用能以1.6秒的速度实现92%的准确率，优于经典算法。结合量子和经典神经网络的混合模型在预测HIV患病率方面达到了94%的准确率，超越纯粹经典的方法。量子贝叶斯分析识别了住房不稳定是HIV簇发生和扩大的关键驱动因素，而污名则对地理区域产生不同的影响。这些量子增强的技术在HIV监测方面提供更高的精确度和效率，揭示了关键的因果路径，有助于指导精准干预、优化PrEP资源分配以及解决促进HIV传播的结构性不公问题。", "conclusion": "本文提出的方法提高了HIV监控的精确度和效率，揭示了关键的因果路径。这些量子增强的方法可以指导有针对性的干预措施，优化PrEP资源的分配，并解决促进HIV传播的结构性不公问题。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00761", "html_url": "https://arxiv.org/abs/2507.00761", "title": "使用去噪扩散代理模型的 wildfire 传播概率预测方法", "title_en": "A Probabilistic Approach to Wildfire Spread Prediction Using a Denoising Diffusion Surrogate Model", "authors": "Wenbo Yu,Anirbit Ghosh,Tobias Sebastian Finn,Rossella Arcucci,Marc Bocquet,Sibo Cheng", "background": "近年来，生成AI取得了重要进展，使计算机能够模拟真实和复杂的自然过程。这种能力应用于预测野火的蔓延，这是一项艰巨的任务，因为野火本身具有不可预测性，且依赖于多种环境条件。本研究通过采用去噪扩散模型，首次提出了用于预测野火蔓延的新AI框架，该框架能够模拟不同可能的火势蔓延场景，而不仅仅是单一固定的结果。这种方法有助于考虑野火动力学中的内在不确定性，这是传统模型通常无法表现的特性。", "innovation": "本研究提出了一种新的去噪扩散模型，用来预测野火的蔓延，它能够模拟一系列可能的火势蔓延场景，而不是仅生成一种固定的预测结果。这种方法能够反映出火势蔓延的物理上合理的分布，有助于实现更智能、更快捷和更可靠的野火行为预判工具，从而辅助决策者在火灾风险评估和应对计划方面做出更好的决策。", "conclusion": "通过使用去噪扩散模型，这项技术能够帮助我们预测可能的野火蔓延场景，更好地理解野火动力学的不确定性。这不仅提高了预测的准确性，也使得决策者能够基于更广泛的可能情况来制定策略，从而提高应对火灾的能力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00899", "html_url": "https://arxiv.org/abs/2507.00899", "title": "TABASCO: 一种快速简化且物理质量改进的分子生成模型", "title_en": "TABASCO: A Fast, Simplified Model for Molecular Generation with Improved Physical Quality", "authors": "Carlos Vonessen,Charles Harris,Miruna Cretu,Pietro Liò", "background": "现有的先进3D分子生成模型依赖于显著的诱导偏置、SE(3)置换对称性和图消息传递网络来保持对称性并捕捉局部化学特性，但仍难以实现物理上的合理性。这项工作引入了TABASCO，该模型放松了上述假设，放弃了对称性保持层和消息传递机制，采用标准的非对称变换器架构，将分子中的原子视为序列，并在生成后确定性地重建键。这种简化使得模型架构更加简单，也能大幅提高数据处理能力。", "innovation": "TABASCO 使用标准的非对称变换器架构，将分子中的原子作为序列处理，并在生成后确定性地重建键。通过去除对称性保持层和消息传递机制，减少了模型复杂性，简化了模型架构，并提高了数据处理速度。尽管如此，该模型表现出 Emergent 转动对称性，即使没有硬编码对称性。", "conclusion": "我们的工作为训练适用于特定任务（如结构和药效团导向药物设计）的简约高效生成模型提供了蓝图。TABASCO 在 GEOM-Drugs 基准测试中取得了最佳的 PoseBusters 有效性和大约 10 倍于最强基线的推理速度。我们提供了模型实施的链接：this http URL."}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00736", "html_url": "https://arxiv.org/abs/2507.00736", "title": "离散水平问题难度估计中的序数性：引入平衡DRPS和OrderedLogitNN", "title_en": "Ordinality in Discrete-level Question Difficulty Estimation: Introducing Balanced DRPS and OrderedLogitNN", "authors": "Arthur Thuy,Ekaterina Loginova,Dries F. Benoit", "background": "近年来，自然语言处理技术在问题难度估计（QDE）方面引起了广泛关注。通常将问题难度表示为离散级别，并将任务归类为序数回归，因为存在从最易到最难的固有顺序。然而，现有文献大多忽视了任务的序数特性，仍依赖于分类或离散回归模型，而专门的序数回归方法尚未得到充分探索。此外，评估指标与建模范式紧密耦合，阻碍了不同研究间的可比性。一些评估指标未能充分考虑难度级别的序数结构，而另一些则未能解决类别不平衡问题，导致评估结果存在偏见。因此，这项研究旨在通过使用平衡化的离散排名概率分数（DRPS）来评估三种类型模型输出——离散回归、分类和序数回归，并且使用这个新颖的度量标准共同捕捉序数性和类别不平衡，从而解决上述限制。", "innovation": "这项研究提出了平衡化的离散排名概率分数（Balanced DRPS）作为评估离散水平问题难度估计的度量标准，并引入了基于扩展的有序逻辑回归模型的神经网络 OrderedLogitNN 方法。通过在 RACE++ 和 ARC 数据集上微调 BERT，研究发现 OrderedLogitNN 在复杂任务中表现显著更好。这种评估方法为未来研究提供了原则性的基础，提供了公正的评估标准，能够解决难度级别的序数结构和类别不平衡问题，从而改善性能评估。", "conclusion": "研究结果表明，平衡化的 DRPS 提供了一种稳健且公平的评估指标，适用于离散级别的 QDE。它提供了一个为未来研究奠定原则性基础的原则，因为它能够同时捕捉难度级别的序数性和类别不平衡性。OrderedLogitNN 模型在复杂任务中表现显著，这是该方法的一个关键优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00742", "html_url": "https://arxiv.org/abs/2507.00742", "title": "评估语言模型和提示策略在基于文本用户报告的自动硬件诊断中的应用", "title_en": "Evaluating LLMs and Prompting Strategies for Automated Hardware Diagnosis from Textual User-Reports", "authors": "Carlos Caminha,Maria de Lourdes M. Silva,Iago C. Chaves,Felipe T. Brito,Victor A. E. Farias,Javam C. Machado", "background": "计算机制造商通过文本报告为用户提供平台以描述设备故障，例如“我的屏幕在闪烁”。从这些报告中识别出故障部件对于自动化测试和提升用户体验至关重要。但这些报告往往模糊不清，缺乏细节，使得这项任务具有挑战性。过去，大型语言模型（LLMs）显示出解决这类问题的潜力。这一研究评估了27个开源模型（参数量从1B到72B不等）和2个专有语言模型，使用了零样本、少量样本、思维链（CoT）以及思维链加少量样本（CoT+FS）四种提示策略。共进行了98,948次推理，处理了超过5.1亿个输入标记，并生成了1300万输出标记。结果显示，三种模型在大小和性能之间提供了最佳平衡：mistral-small-24b-instruct和两个较小的模型llama-3.2-1b-instruct和gemma-2-2b-it，后者与具有较低VRAM使用量且竞争性性能的模型一起提供高效推理，能够适用于现代笔记本电脑或具备NPU的智能手机等终端设备。", "innovation": "该研究采用了多种语言模型和提示策略组合，对基于文本用户报告的自动硬件诊断任务进行了大规模评估，特别关注了在较小模型和高性能之间的平衡，并且发现部分较小的模型能够以较低的VRAM使用量提供与其大模型相当的性能，从而优化了终端设备上的推理效率。", "conclusion": "研究结果显示，mistral-small-24b-instruct和llama-3.2-1b-instruct以及gemma-2-2b-it三种模型提供了最优的大小与性能平衡。这些较小的模型能够以较低的VRAM使用量提供较好的性能，有利于在现代笔记本电脑或带有NPU的智能手机等终端设备上进行效率较高的推理。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00846", "html_url": "https://arxiv.org/abs/2507.00846", "title": "BoltzNCE: 使用随机插值和噪声对比估计学习玻尔兹曼生成的似然性", "title_en": "BoltzNCE: Learning Likelihoods for Boltzmann Generation with Stochastic Interpolants and Noise Contrastive Estimation", "authors": "Rishal Aggrwal,Jacky Chen,Nicholas M. Boffi,David Ryan Koes", "background": "物理系统（如分子）的建模依赖于对玻尔兹曼分布进行有效采样，该分布由能量函数定义。Boltzmann Generators通过运用连续归一化流将简单的先验转换为可重新加权以匹配玻尔兹曼分布的分布，但获取似然性需要在积分过程中计算昂贵的雅克比行列式，这使得该方法在大型分子系统中不切实际。本研究旨在解决这一问题，提出了一种新的方法来学习生成分布的似然性，该方法结合了能量基于模型的噪声对比估计和分数匹配，并通过使用随机插值将先验和生成分布进行平滑过渡，以高效地学习密度函数。在丙氨酸二肽系统上，我们展示了该方法在自由能剖面和能量分布方面与使用确切似然性的结果可媲美，并且能够以数量级的速度提高自由能差异估计的准确性.", "innovation": "利用能量基于模型进行噪声对比估计和分数匹配，通过随机插值平滑过渡先验和生成分布，从而有效学习密度函数，即使在大型分子系统中也能提供与使用确切似然性相媲美的结果，同时提高了自由能差异估计的准确性", "conclusion": "我们的方法在丙氨酸二肽系统上展示了与使用确切似然性的自由能剖面和能量分布结果相似的性能，并且能够在较大的速度下准确估计自由能差异。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00880", "html_url": "https://arxiv.org/abs/2507.00880", "title": "NN-Former: 重新思考神经架构表示中的图结构", "title_en": "NN-Former: Rethinking Graph Structure in Neural Architecture Representation", "authors": "Ruihan Xu,Haokui Zhang,Yaowei Wang,Wei Zeng,Shiliang Zhang", "background": "随着深度学习的广泛应用，网络设计和部署变得越来越高效，神经预测器对于估计精度和延迟等属性变得尤为重要。最近，图神经网络（GNNs）和变压器在表示神经架构上表现出令人鼓舞的性能。然而，这两种方法都有各自的局限性：GNNs无法表示复杂的特征，而当架构变深时，变压器的泛化能力较差。因此，本文重新思考了神经架构拓扑，发现兄弟节点在先前的研究中被忽视，提出了一个结合GNNs和变压器优势的新型预测器，引入了一种考虑兄弟节点的新型token混合器和一种名为双向图同构前馈网络的新信道混合器，该方法在精度和延迟预测方面持续表现良好，为学习有向无环图（DAG）拓扑提供了宝贵见解。", "innovation": "本文创新点在于重新思考神经架构表示的拓扑结构，提出了一种结合GNNs和变压器优势的新型预测器。引入了考虑兄弟节点的新型token混合器和一种名为双向图同构前馈网络的新信道混合器，从而解决了GNNs和变压器各自的局限性，提高了预测精度和延迟的能力。", "conclusion": "我们的方法在精度和延迟预测方面表现出了持续的优良性能，为学习DAG拓扑提供了宝贵的见解。有关代码可通过提供的链接获取。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00762", "html_url": "https://arxiv.org/abs/2507.00762", "title": "在实际强化学习环境中的遗传算法高效演示生成", "title_en": "Leveraging Genetic Algorithms for Efficient Demonstration Generation in Real-World Reinforcement Learning Environments", "authors": "Tom Maus,Asma Atamna,Tobias Glasmachers", "background": "强化学习（RL）在某些工业应用场景中展现了巨大的潜力，但其广泛应用受到样本效率低和学习动态不稳定等固有挑战的限制。本研究探讨了使用遗传算法（GAs）来改善在工业启发式分拣环境中强化学习的性能。研究通过将GA生成的专家演示整合到深度Q网络（DQN）体验回放缓冲区中，并用这些演示作为强化策略优化（PPO）代理的预热轨迹，加快训练收敛速度。研究还对比了标准RL训练、基于规则的启发式方法、暴力优化方法和演示数据，发现GA生成的演示显著提升了RL的性能。", "innovation": "本研究提出了一种新的方法，利用遗传算法生成的专家演示来增强策略的学习。此举将GA生成的演示数据整合到DQN的体验回放缓冲区中，并将其作为PPO代理的预热路径，以加速训练收敛。这种方法利用了遗传算法和强化学习的优势，展示了混合学习范式的潜力，即启发式搜索方法与数据驱动的强化学习相结合。", "conclusion": "实验结果表明，利用遗传算法生成数据的PPO代理相较于其他方法显著提升了累积奖励，这突显了这种混合学习方法的潜力。研究框架已开源，为适应性强化学习策略在实际场景中的应用提供了进一步研究的基础。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00920", "html_url": "https://arxiv.org/abs/2507.00920", "title": "隐私保护的具有不同精度的量化联邦学习", "title_en": "Privacy-Preserving Quantized Federated Learning with Diverse Precision", "authors": "Dang Qua Nguyen,Morteza Hashemi,Erik Perrins,Sergiy A. Vorobyov,David J. Love,Taejoon Kim", "background": "联邦学习（FL）作为一种分布式机器学习的有希望的范式，允许多个本地设备在无需共享原始数据的情况下协作训练全局模型。尽管FL取得了进展，但隐私风险（本地模型更新传输到融合中心的安全性问题）和模型量化不一致导致的学习效率降低仍然是限制因素。现有研究通常只解决上述一个挑战，同时在保护隐私并处理量化不一致的情况下保持学习效率是一项富有挑战的任务。", "innovation": "本文提出了一个新颖的随机量化器（SQ），旨在同时实现差分隐私（DP）和最小量化误差，这与其他的DP方法相比，具有有界失真的是一个显著优势。此外，提出了集群大小优化技术与线性融合方法结合，以提高模型聚合的准确性，解决量化不一致性的问题。这些创新为联邦学习中的隐私保护和学习效率提升提供了新的途径。", "conclusion": "通过数值仿真验证了本研究方法在隐私保护和学习效率方面相对于经典LaplaceSQ-FL算法的优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00862", "html_url": "https://arxiv.org/abs/2507.00862", "title": "基于电生理信号的机器学习早期检测马铃薯发芽", "title_en": "Machine Learning-based Early Detection of Potato Sprouting Using Electrophysiological Signals", "authors": "Davide Andreoletti,Aris Marcolongo,Natasa Sarafijanovic Djukic,Julien Roulet,Stefano Billeter,Andrzej Kurenda,Margot Visse-Mansiaux,Brice Dupuis,Carrol Annette Plummer,Beatrice Paoli,Omran Ayoub", "background": "准确预测马铃薯发芽，避免显现出任何视觉迹象之前即可进行预测，对于有效仓储管理至关重要。马铃薯发芽会降低其商业价值和营养价值。有效的预测可以精确应用防发芽化学物质（ASCs），减少浪费并降低成本。由于健康和环境担忧，禁用了常用的ASCs（如CIPC），导致使用了更为昂贵的替代品，增加了成本压力。现有方法主要依赖于视觉识别，只能在形态变化后检测到发芽，这限制了其对主动管理的有效性。因此，一种可靠且能够早期预测的方法对于及时干预和提高仓储策略的效率至关重要。早期指的是在任何明显迹象出现之前就能检测到发芽。本文正是针对此问题进行了研究，提出了一种机器学习（ML）方法，利用传感器记录的电生理信号在发芽早期阶段进行预测。该方法包括前期信号处理、从时频域提取特征并训练监督学习模型以实现早期发芽检测。", "innovation": "本文提出了一种全新的机器学习（ML）方法，通过传感器记录的电生理信号来实现早期预测马铃薯发芽。该方法包括预处理记录的信号、从时频域提取相关特征以及训练监督学习模型。此外，还引入了不确定性量化技术以提高预测准确性。实验结果表明该方法在早期检测马铃薯发芽方面的表现良好。但仍然需要进一步改进以减少预测误差，特别是在降低最大观测偏差方面。", "conclusion": "实验结果显示出早期检测马铃薯发芽的潜力，但还需进一步优化以减少预测误差，特别是在降低最大观测偏差方面。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00851", "html_url": "https://arxiv.org/abs/2507.00851", "title": "使学习与内生性决策对齐", "title_en": "Aligning Learning and Endogenous Decision-Making", "authors": "Rares Cristian,Pavithra Harsha,Georgia Perakis,Brian Quanz", "background": "我们在决策时往往会受到某些偏见的影响，例如物品的需求量受到定价策略的影响，而在线结账选项则依赖于展示的商品组合。但在这种情况下最具挑战性的问题是如何缺乏反事实信息，同时又需要进行学习来获取这种信息。因此，本文旨在提出一种完整的端到端方法，能在内生不确定性条件下训练机器学习模型，使其对下游决策具有意识，从而在决策过程中有效应用。此外，本文还引入了一种鲁棒优化变体，该变体考虑了机器学习模型的不确定性，具体是通过在机器学习模型的空间中构建不确定性集，并优化行动以抵御最坏情况的预测。此外，本文还提出了新的面向端到端学习框架的两类随机优化问题，并通过实验证明了这种方法在定价和库存组合/推荐问题上的优越性。此外，模型的预测也取决于第一个阶段做出的决策，尽管这种决策不会影响随机变量，但它确实影响了正确的点预测应做出的内容。", "innovation": "本文提出了在内生不确定性条件下训练机器学习模型的方法，解决了由于缺乏反事实信息而带来的挑战，并引入了一种考虑机器学习模型不确定性的鲁棒优化方法。这种方法可以作为一个统一框架，解决定价和库存商品组合/推荐问题，并且从现有方法的比较中显示出一致的优异性能。通过引入新的两类随机优化问题，为了解决这些问题提供了新的框架。", "conclusion": "本文提出了一种端到端方法，可以在内生不确定性条件下训练机器学习模型，并通过鲁棒优化变体考虑了模型的不确定性。此外，还为定价和库存组合/推荐问题提出了新的随机优化问题，并通过一系列计算实验展示了其有益性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00945", "html_url": "https://arxiv.org/abs/2507.00945", "title": "时间序列基础模型是流预测工具", "title_en": "Time Series Foundation Models are Flow Predictors", "authors": "Massimiliano Luca,Ciro Beneduce,Bruno Lepri", "background": "本文研究了时间序列基础模型（TSFMs）在人群流动预测中的有效性，特别是针对Moirai和TimesFM这两个模型。研究在Bike NYC、Taxi Beijing和西班牙全国出行数据中进行实证分析，模型仅依赖于每个OD流的时间演化过程，而不依赖于显式的空间信息。研究表明，Moirai和TimesFM在统计学和深度学习基线模型中表现出更好的性能，展现出更准确的预测和更高的精度指标。", "innovation": "本文创新性地将时间序列基础模型应用于人群流动预测，特别针对Moirai和TimesFM两个模型进行评估。研究展示了TSFMs在零样本设置下的有效性和实用性，特别是在缺乏移动数据标注或空间上下文缺失的情况下。", "conclusion": "本文结果显示，TSFMs在准确性、可扩展性和实际应用价值上有显著优势。这些模型即使在有限带注释数据或缺失空间上下文的情境下仍能提供高度准确的流量预测。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00927", "html_url": "https://arxiv.org/abs/2507.00927", "title": "理解节点和边预测中的泛化能力", "title_en": "Understanding Generalization in Node and Link Prediction", "authors": "Antonis Vasileiou,Timo Stoll,Christopher Morris", "background": "消息传递图神经网络（MPNNs）在节点和边预测中具有重要性，广泛应用于科学和工业领域。虽然MPNNs在实际应用中表现良好，但其在训练集外的泛化能力仍不明确。现有研究表明MPNNs在图级别预测任务中的泛化能力强，但在节点和边级别预测任务中的泛化能力研究较少。现有研究往往假设节点或边之间的独立性，忽视了这种相关性，并且对聚合和损失函数的设定较为固定，没有考虑图结构的影响。本文研究旨在填补这一研究空白，提供一个综合框架，分析MPNNs在归纳和传递学习中的泛化特性，同时考虑了不同的架构参数和损失函数，并量化了图结构的影响。该框架不仅适用于图数据，也可应用于任何分类任务。", "innovation": "引入了一个统一框架来分析MPNNs在归纳和传递学习中的泛化特性，该框架可以量化图结构的影响，并考虑了多元的架构参数和损失函数。此外，该框架还可以应用于任何分类任务，既涵盖了归纳学习也包括了传递学习。研究同时支持了理论洞察，加深了对MPNNs在这些任务中的泛化能力的理解。", "conclusion": "本文通过一个统一的框架研究了MPNNs在节点和边预测任务中的泛化能力，该框架能够有效量化图结构的影响，并适用于各种分类任务。研究结果加深了我们对MPNNs泛化能力的理解。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00965", "html_url": "https://arxiv.org/abs/2507.00965", "title": "大规模知识图谱中用于下游机器学习的可扩展特征学习", "title_en": "Scalable Feature Learning on Huge Knowledge Graphs for Downstream Machine Learning", "authors": "Félix Lefebvre,Gaël Varoquaux", "background": "许多机器学习任务可以从外部知识中获益。大型知识图谱存储这类知识，并且嵌入方法可以将这些知识提炼为可供下游应用直接使用的向量表示。然而，当前模型有两个主要限制：它们主要优化用于链接预测的局部对比学习，而对于大规模图由于GPU内存限制难以扩展。", "innovation": "本文提出了一种名为SEPAL（可扩展嵌入传播算法）的方法，旨在为大规模知识图谱生成高质量的嵌入表示，并进行大规模下游任务。SEPAL的核心思想是通过仅优化一小部分实体的嵌入，并通过消息传递将这些嵌入传播到图的其余部分，来强制全局嵌入对齐。", "conclusion": "SEPAL在7个大规模知识图谱和46个下游机器学习任务上进行了评估，结果显示它显著优于先前的方法。此外，SEPAL能够大幅提升基础嵌入模型的规模，在普通硬件上也能适应庞大的知识图谱。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01003", "html_url": "https://arxiv.org/abs/2507.01003", "title": "通过遍历定理解释神经网络训练过程：幽灵节点", "title_en": "Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes", "authors": "Eun-Ji Park,Sangwon Yun", "background": "最近的研究提出了从遍历角度解释训练过程的方法。基于这一基础，我们提出了一种统一框架，利用随机梯度下降理解并加速深度神经网络的训练。通过分析目标函数的几何景观，我们引入了一个实用的诊断方法——运行估计的最大李亚普unov指数，它能证明地区分真实的向稳定极小值的收敛和仅在鞍点附近的统计稳定。", "innovation": "我们提出了幽灵节点扩展的标准分类器类别，通过增加辅助幽灵输出节点，使得模型可以获得额外的下降方向，并在早期训练阶段绕过狭窄的损失障碍，从而使优化器绕过劣质盆地。我们证明了这种方法严格减少了近似误差，在充分收敛后，幽灵维度会消失，扩展模型的不变规律与原始模型相同，并且存在一条参数空间扩大的路径，使得总损失不增加而原始损失减少到任意幅度。这一结果提供了在保持渐近行为的前提下加速早期训练期架构干预的理论方法.", "conclusion": "这些结果结合在一起，提供了一个在保持渐近行为的同时，加速早期训练阶段架构干预的理论方法，即通过幽灵节点促进模型的可训练性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00007", "html_url": "https://arxiv.org/abs/2507.00007", "title": "在教育实验室中集成通用生成型AI平台以培养批判性思维和数字素养", "title_en": "Integrating Universal Generative AI Platforms in Educational Labs to Foster Critical Thinking and Digital Literacy", "authors": "Vasiliy Znamenskiy,Rafael Niyazov,Joel Hernandez", "background": "该论文的背景在于，目前教育领域中存在使用大型语言模型（LLMs）进行研究时的局限性和风险，尤其是在缺乏批判性使用这些工具的情况下。研究者建议将生成性人工智能（GenAI）平台，如ChatGPT、Claude和Gemini，集成到教育实验室活动中，以提升本科生的批判性思维和数字素养。", "innovation": "创新点在于提出了一种新型教育框架，该框架将GenAI平台作为研究主题和认知工具，并让学生们提出学科特定的提示并评估由GenAI生成的文本、图像和视频内容。此外，提出了一种可复制的跨学科AI整合实验室工作的模型，适用于各类科学学科，旨在通过反思性评估方法提高学习成果。", "conclusion": "研究表明，结构化的AI交互在教育中非常重要，并且利用GenAI结合反思性评估方法可以提升学习效果。该论文展示了一种可复制的教育实验室模型，能够提高学生们的批判性思维和数字素养，并建议该模式在不同科学领域具有适应性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00971", "html_url": "https://arxiv.org/abs/2507.00971", "title": "作为适应性防御的推理", "title_en": "Reasoning as an Adaptive Defense for Safety", "authors": "Taeyoun Kim,Fahim Tajwar,Aditi Raghunathan,Aviral Kumar", "background": "现有的推理方法能够在数学和代码等可验证领域提高语言模型（LLM）的性能。本文研究如何利用这些方法训练具备一定程度安全漏洞鲁棒性的模型，并展示这样的训练方法可带来益处。研究指出，通过利用奖励学习（RL）方法，可以在模型的训练过程中结合思考链和安全与任务完成之间的平衡奖励信号，从而增强模型的安全性。文章还指出了三个关键的设计选择：一种“现学现用”的初步微调阶段、混合包含有害、无害和模棱两可提示以防止捷径行为、以及一种防止推理能力退化的奖励函数。这些模型在面对模棱两可查询时会增加计算使用，更好地权衡安全和拒绝行为，并且在面对白盒和黑盒攻击时表现出更强的鲁棒性。", "innovation": "提出了一种名为TARS（Training Adaptive Reasoners for Safety）的训练方法，这是一种基于奖励学习的方法，聚焦于通过思考链和安全与任务完成之间的平衡奖励信号来训练模型，从而提高模型的安全性和面对不同攻击的鲁棒性。该方法的关键创新点在于选择混合提示类型以防止捷径行为，采用奖励函数避免训练过程中的推理能力退化。", "conclusion": "本文提供了一种有效且开放的训练方案，用于通过逐个提示的推理训练LLM以抵御逃逸和有害请求。此方法通过增强模型在面对模棱两可查询时的适应性表现和安全性辨别能力，提升了模型在白盒和黑盒攻击情境下的鲁棒性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01004", "html_url": "https://arxiv.org/abs/2507.01004", "title": "ZeCO：线性注意模型无通信开销序列并行方法", "title_en": "ZeCO: Zero Communication Overhead Sequence Parallelism for Linear Attention", "authors": "Yuhong Chou,Zehao Liu,Ruijie Zhu,Xinyi Wan,Tianjian Li,Congying Chu,Qian Liu,Jibin Wu,Zejun Ma", "background": "线性注意力机制为大规模语言模型（LLMs）提供了显著的优势，例如提供线性计算复杂度，使其能够高效地处理超长序列（例如100万上下文）。然而，现有的序列并行（Sequence Parallelism, SP）方法在分布式处理这些任务时成为瓶颈，主要由于大量的通信开销。因此，需要一种新的SP方法来消除这种通信开销，实现长序列训练的端到端接近线性可扩展性。", "innovation": "本文提出了ZeCO（Zero Communication Overhead）序列并行方法，这是一种旨在克服现有SP方法缺点的新方法，通过引入All-Scan（一种新的集体通信原语）来实现无通信开销，并在长序列训练中实现接近线性可扩展性。具体而言，与当前最先进的SP方法相比，在256个GPU和800K序列长度的场景下，ZeCO达到了60%的速度提升。", "conclusion": "我们认为ZeCO为高效训练下一代LLMs在以前难以处理的序列长度上提供了一条明确的道路。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00005", "html_url": "https://arxiv.org/abs/2507.00005", "title": "SwarmFusion: 利用群体智能和深度学习革新灾害响应", "title_en": "SwarmFusion: Revolutionizing Disaster Response with Swarm Intelligence and Deep Learning", "authors": "Vasavi Lankipalle", "background": "灾害响应需要在混乱环境中进行快速且适应性决策。现有的方法面对紧急灾害管理时面临挑战，特别是在应对洪水和山林火灾等灾害场景时需要在实时资源分配和路径规划方面有所改进。传统方法在这方面效率较低，为提高灾害响应的速度和效果，有必要引入新的技术框架来优化这些任务。", "innovation": "SwarmFusion 是一种新型的混合框架，将粒子群优化算法与卷积神经网络相结合，以实现实时资源分配和路径规划的优化。通过处理实时卫星、无人机和传感器数据，SwarmFusion 提升了灾害现场的态势感知和操作效率。研究结果表明，与基准方法相比，使用 SwarmFusion 可以提高 40% 的响应速度和 90% 的幸存者覆盖范围。这表明 SwarmFusion 是一种可扩展的数据驱动方法，具有在不同危机场景中应用的潜力，可提供紧急灾害管理的变革性解决方案。", "conclusion": "SwarmFusion 提供了一种基于数据的创新方法来优化灾害响应中的实时资源分配和路径规划，展示了显著提高响应时间和幸存者覆盖范围的效果。这种方法具有在其他多种危机实际场景中应用的潜力，是时间关键型灾害管理的革命性解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00048", "html_url": "https://arxiv.org/abs/2507.00048", "title": "基于FAIR数据和计算基础设施的协作数字孪生", "title_en": "A collaborative digital twin built on FAIR data and compute infrastructure", "authors": "Thomas M. Deucher,Juan C. Verduzco,Michael Titus,Alejandro Strachan", "background": "该研究利用机器学习与自动实验的集成，应用于自驾车实验室（SDL），加速科学研究和工程应用中的发现和优化任务。通过结合FAIR数据基础设施，具有相似兴趣的研究人员能够更有效地协同工作。研究者基于nanoHUB服务构建了一个分布式的SDL实现，用于在线模拟和管理FAIR数据，地理上分散的研究人员可以共享实验数据，利用分析工具和机器学习模型进行自动更新。", "innovation": "研究核心创新点在于提出了一个基于nanoHUB服务的分布式SDL实现，该实现依赖于FAIR数据基础设施，不仅让分散的研究人员能够分享和利用实验数据，还利用简单的web界面提交新数据点，并自动处理这些数据。研究引入了一个工作流程，通过主动学习进行序列优化，无需预定义假设即可自动训练机器学习模型，指导未来的实验选择。此外，研究还引入了“精明的双胞胎”概念，即优化任务旨在找到组合食品色素达到目标颜色的最佳配方，使研究人员和学生可以轻松获取并使用这些工具来探索FAIR数据、预测性机器学习模型和序列优化的结合应用。", "conclusion": "该工具适用于多种优化问题，具有广泛的应用潜力。其成功之处在于展示了如何利用远距离协作和自动处理技术，提升科学研究和工程应用中的效率和准确性。未来的研究可以进一步扩展这些工具的应用范围，探索更多潜在的研究领域。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00006", "html_url": "https://arxiv.org/abs/2507.00006", "title": "MVGBench：多视图生成模型的全面基准", "title_en": "MVGBench: Comprehensive Benchmark for Multi-view Generation Models", "authors": "Xianghui Xie,Chuhang Zou,Meher Gitika Karumuri,Jan Eric Lenssen,Gerard Pons-Moll", "background": "近年来，多视图图像生成模型（MVGs）成为创建3D对象的主要驱动力。然而，现有的评估指标通常将生成的图像与真实目标视图进行比较，这不适合评估生成任务，因为多个解决方案可能与真实目标不同。此外，不同MVGs在不同视角、合成数据和特定光照下进行训练，其鲁棒性和对真实数据的泛化能力很少被彻底评估。缺乏严格的评估协议，也难以确定哪些设计选择推动了MVGs的发展。因此，亟需一个包含三个主要方面的全面基准：最佳设置性能、对真实数据的泛化能力和鲁棒性。引入了一个新的3D自一致性度量，用于比较由不相干生成多视图重建的3D重建结果。系统地在四种不同的精选真实和合成数据集上比较了现有的十二个MVGs。研究表明，现有方法在鲁棒性和泛化能力方面存在重要限制，指出了最关键的设计选择，并在此基础上提出了超越所有评估方法的ViFiGen方法，以提高3D一致性。", "innovation": "引入了一个基于3D自一致性的新度量，用于比较由不相干生成多视图重建的3D重建结果；系统地比较了十二种现有的MVGs；发现了现有方法在鲁棒性和泛化能力方面的关键限制；提议了最有效的ViFiGen方法，以实现3D一致性。还包括了开源代码、模型和基准套件。", "conclusion": "MVGBench是评估MVGs的重要进展，通过设计选择的分析和新型3D自一致性度量，揭示了MVGs的关键限制和最有效的设计。ViFiGen作为一种新的方法，比现有的所有MVGs在3D一致性方面表现更佳，展示了全面基准在推动研究进步中的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00042", "html_url": "https://arxiv.org/abs/2507.00042", "title": "通过差异加权经验重放减轻灾难性遗忘", "title_en": "Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay", "authors": "Xinrun Xu,Jianwen Yang,Qiuhong Zhang,Zhanbiao Lian,Zhiming Ding,Shan Jiang", "background": "在云-边缘协作目标检测中的边缘模型持续适应动态交通环境时，模型可能会出现灾难性遗忘现象，即模型在适应新数据分布时会丢失之前学到的知识。现有的方法，如经验重放和视觉提示，在一定程度上缓解了这个问题，但它们不易于优先处理和利用历史数据以实现最佳的知识恢复和适配。本文分析指出，简单存储所有历史数据或同等看待所有历史经验的效果不理想，因为它们忽视了历史经验对于当前领域的相关性差异。因此，以往方法难以有效地选择与当前任务最具差异性的历史经验并进行重放以保持知识并促进适应。", "innovation": "本文提出了基于自适应经验重放的ER-EMU边缘模型更新算法，通过有限的经验缓冲区管理和新颖的基于领域距离度量的经验选择算法（DDM-ES）来解决上述限制。ER-EMU使用具有先进先出（FIFO）原则管理的经验缓冲区，并采用基于多核最大均值偏差（MK-MMD）的领域距离度量算法，优先选择与当前目标领域差异最大的历史数据进行重放，从而确保了训练的多样性和知识的广泛保留，并避免了新领域的过度适应。同时，通过简单随机抽样更新经验缓冲区以保持先前领域的平衡表征。实验结果表明，ER-EMU算法显著提高了当前最先进的云-边缘协作目标检测框架的性能。", "conclusion": "实验结果验证了ER-EMU算法的有效性，证明它能够有效缓解灾难性遗忘并提升云-边缘协作目标检测框架在动态交通监控中的性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00044", "html_url": "https://arxiv.org/abs/2507.00044", "title": "HistoART: 组织病理学图像异常检测与报告工具", "title_en": "HistoART: Histopathology Artifact Detection and Reporting Tool", "authors": "Seyed Kahaki,Alexander R. Webber,Ghada Zamzmi,Adarsh Subbaswamy,Rucha Deshpande,Aldo Badano", "background": "在现代癌症诊断中，全切片成像（WSI）已广泛应用于将组织标本数字化，以进行高分辨率的详细检查。然而，其他诊断方法如液体活检和分子检测也根据癌症类型和临床环境进行使用。虽然WSI通过实现自动化和精确分析，极大地改进展示数字病理学，但它仍然容易受到制片和扫描过程中引入的伪影的影响，这些伪影会降低后续图像分析的效果。", "innovation": "作者提出并比较了三种基于不同原则的WSI伪影检测方法：基于基础模型的伪影检测方法（FMA，使用精细调整的统一神经图像（UNI）架构）、基于深度学习的方法（DLA，基于ResNet50结构）以及基于知识的方法（KBA，利用纹理、颜色和频率等手工程度特征），来识别六种常见伪影类型：组织褶皱、焦外区域、气泡、组织损伤、标记物痕迹和血液污染。通过来自多种扫描器（包括Hamamatsu、Philips、Leica Aperio AT2）的超过50,000张图像块的数据评估，FMA在像素级别AUROC中达到最高值0.995，显著优于基于ResNet50的方法（AUROC：0.977）和基于知识的方法（AUROC：0.940）。", "conclusion": "通过开发一种质量报告计分卡，该工具量化高质量图像块并可视化伪影分布，从而将检测结果转化为可操作的洞察。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00054", "html_url": "https://arxiv.org/abs/2507.00054", "title": "以奖励导向的数据集蒸馏增强 SLM 的推理能力", "title_en": "Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation", "authors": "Shreyansh Padarha", "background": "将大型语言模型（LLMs）的知识压缩到更易于部署和高效的中小型语言模型（SLMs）中的努力得益于知识蒸馏（KD）技术的进步。这些技术使较小的学生模型能够从更大、更强大的教师模型的回答中学习。然而，蒸馏通常集中在学生模型复制教师模型在特定分布内的响应上，这限制了其泛化能力。这一限制在推理任务上更加明显，并且在计算成本上也是一个挑战。", "innovation": "本文提出了AdvDistill，一种奖励导向的数据集蒸馏框架。该框架利用每个提示的多轮生成（回答），结合基于规则的验证器分配奖励，并将这些奖励作为权重进行学生模型的训练。这种方法和后续的行为分析显示，在数学和复杂推理任务上，学生模型的性能有了显著提升，证明了在数据集蒸馏过程中引入奖励机制的有效性和益处。", "conclusion": "本研究表明，通过引入奖励机制的数据集蒸馏可以显著提高小型语言模型在数学和复杂推理任务上的表现，具有较高的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00050", "html_url": "https://arxiv.org/abs/2507.00050", "title": "SEZ-HARN: 自解释零样本人类活动识别网络", "title_en": "SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network", "authors": "Devin Y. De Silva,Sandareka Wickramanayake,Dulani Meedeniya,Sanka Rasnayaka", "background": "人类活动识别（HAR）使用惯性测量单元（IMU）传感器的数据，在医疗保健和辅助生活环境中有很多实际应用。然而，在现实世界中的应用受到了全面的IMU基础HAR数据集缺乏的限制，这些数据集覆盖了广泛的活动范围，以及现有HAR模型的透明度不足。零样本HAR（ZS-HAR）解决了数据限制问题，但当前的模型很难解释其决策过程，从而降低了透明度。", "innovation": "本文提出了一种新的基于IMU的ZS-HAR模型，称为自我解释的零样本人类活动识别网络（SEZ-HARN）。该模型能够在训练期间未遇到的活动中进行识别，并提供骨骼视频以解释其决策过程。实验结果显示SEZ-HARN不仅能生成现实且易于理解的解释，同时零样本识别准确度也达到了与顶级黑盒模型相近的水平，特别是在PAMAP2数据集上，其零样本预测准确度与最佳黑盒模型仅相差3%。", "conclusion": "通过在PAMAP2、DaLiAc、HTD-MHAD和MHealth四个基准数据集上的实验，SEZ-HARN不仅提供了现实且易于理解的解释，同时也保持了与现有顶级黑盒ZS-HAR模型相似的零样本识别准确度。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00049", "html_url": "https://arxiv.org/abs/2507.00049", "title": "AdaDeDup: 适应性混合数据裁剪以提高大型对象检测训练效率", "title_en": "AdaDeDup: Adaptive Hybrid Data Pruning for Efficient Large-Scale Object Detection Training", "authors": "Feiyang Kang,Nadine Chang,Maying Shen,Marc T. Law,Rafid Mahmood,Ruoxi Jia,Jose M. Alvarez", "background": "大规模数据集的计算负担和固有冗余性对现代机器学习模型的训练构成了挑战。数据裁剪可以通过选择更小但更具信息量的子集来提供一种解决方案，但现有的方法存在局限性：基于密度的方法可能在任务上不具针对性，而基于模型的方法可能会引入冗余或导致计算成本过高。", "innovation": "我们提出了适应性去重（AdaDeDup），这是一种新颖的混合框架，融合了基于密度的裁剪方法和基于模型的反馈机制，并以集群自适应的方式进行。该框架首先将数据分割，并应用初始化的基于密度的裁剪。然后使用代理模型来评估初裁剪对每个集群内部的影响，并通过保留样本与删除样本的损失比较来计算任务相关的信号，以适应性调整集群特定的裁剪阈值。这使得在冗余集群中可以进行更激进的裁剪，而在信息丰富的集群中保持关键数据，从而提高了大型模型训练的数据效率，同时显著优于现有基准，且大幅减少了性能退化，同时在数据去除率20%的情况下达到了接近原始模型的性能。", "conclusion": "广泛的实验在大规模对象检测基准（Waymo、COCO、nuScenes）中使用标准模型（BEVFormer、Faster R-CNN）展示了AdaDeDup的优势。它显著优于明显的基础模型，大幅减少了性能退化（例如，waymo上的性能下降超过54%），在去除20%数据的同时达到了与原始模型接近的性能，突显了其提高大规模模型训练数据效率的有效性。源代码已公开。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00079", "html_url": "https://arxiv.org/abs/2507.00079", "title": "VoyagerVision: 探索多模态信息在开放学习系统中的作用", "title_en": "VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems", "authors": "Ethan Smyth,Alessandro Suglia", "background": "开放性是实现通用人工智能（AGI）的一个活跃研究领域，这使模型能够自主选择任务。近年来，大型语言模型（LLMs）如GPT-4o的能力增强，使得这类模型能够解释图像输入。OMNI-EPIC等实现使得LLMs能够接收代理视角的像素数据，辅助其理解环境以解决任务。该论文认为，向模型提供视觉输入能够增强其解释空间环境的能力，从而扩大其能成功完成任务的数量，进一步扩展其开放性潜力。", "innovation": "该论文提出了VoyagerVision，这是一个多模态模型，能够利用屏幕截图作为视觉反馈，在Minecraft中构建结构。相比于Voyager，VoyagerVision在五十次系统迭代中平均创建2.75个独特结构，展示了其创建结构的新方向。VoyagerVision在平坦世界中的建造单元测试中成功率达到50%，尽管在复杂结构上遇到了一些挑战，但仍然是一个重要的进展。", "conclusion": "VoyagerVision的能力扩展了开放学习系统的潜在应用，通过利用多模态屏幕截图反馈，它能够更有效地构建和完成任务。研究表明，多模态信息对于增强模型的开放性学习任务具备重要作用。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00057", "html_url": "https://arxiv.org/abs/2507.00057", "title": "基于LLM的代码生成中无需先验估计正确性", "title_en": "Estimating Correctness Without Oracles in LLM-Based Code Generation", "authors": "Thomas Valentin,Ardi Madadi,Gaetano Sapia,Marcel Böhme", "background": "大语言模型（LLMs）在从自然语言规范生成代码方面取得了巨大成功，但它们也存在错误，即生成的代码可能语法正确但事实错误。在缺乏正确实现（即金标准）的情况下，如何量化生成的代码正确性变得尤为困难。本文旨在探索一种无需金标准即可量化代码错误程度的方法，即不依赖先验的错误估计方法。通过这种方法，研究者能够有效衡量代码生成任务中代码的正确性，甚至可以替代基于先验的评估方式，对大语言模型进行更可靠、更高效的评价。", "innovation": "本文提出了一种新的错误度量方法，称为不一致性（incoherence），该方法可以在没有先验知识的情况下高效估计代码的错误程度，并提供生成代码错误的概率下界。与基于先验的评估相比，基于不一致性的评估方法能够更有效地识别错误代码。通过实验表明，对于平均代码生成任务，基于不一致性的方法可以自动识别大约三分之二的错误代码，且准确率高，无误报现象。此外，基于不一致性评估的排名与基于先验评估的排名高度一致，这表明这种方法的可靠性和有效性。", "conclusion": "本文提出了一种无需金标准即可量化代码生成任务中代码错误性的方法，即基于不一致性（incoherence）的评估方法。该方法不仅能够高效识别错误代码，而且在可靠性上接近甚至优于基于金标准的评估方法。研究发现，基于不一致性评估与基于金标准评估的排名高度一致，这证明了该方法的有效性和实用性。今后的工作可以进一步探索该方法在其他复杂任务中的应用效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00248", "html_url": "https://arxiv.org/abs/2507.00248", "title": "使用有限数据开发实时手语识别的轻量级DNN模型", "title_en": "Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition", "authors": "Nikita Nikitin,Eugene Fomin", "background": "手语识别面临着数据稀缺、高计算成本和训练与推断环境帧率不匹配等关键挑战。针对这些挑战，研究人员提出了一种新的框架，利用轻量级的深度学习模型（DNN）进行实时手语识别，这些模型是在有限的数据集上训练的。", "innovation": "该研究通过编码手语特定参数（如手势形状、手掌方向、动作和位置）为向量输入，并利用MediaPipe进行关键点提取，从而实现了高度可区分的输入数据表示。此外，其深度学习架构通过优化部署大小，使边缘设备在不到10毫秒的延迟下能够准确识别343个手语手势。", "conclusion": "该研究的模型在孤立手语识别中达到了92%的准确性，并已集成到‘slait ai’网络应用程序中，展示了稳定的推理性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00180", "html_url": "https://arxiv.org/abs/2507.00180", "title": "黑箱到蓝图：使用强化学习和反事实分析从遗留系统中提取可解读逻辑", "title_en": "BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis", "authors": "Vidhi Rathore", "background": "现代软件系统的现代化是一个关键但具有挑战性的任务，经常受到原始文档缺失和对系统复杂决策逻辑理解不足的影响。传统的行为克隆方法只能复制输入/输出行为，而不捕捉其背后的意图。因此，需要一种新的方法从被视为黑箱的遗留系统中自动提取可解释的决策逻辑，这正是本文提出的创新所在，使用强化学习代理探索输入空间，通过奖励导致系统输出实质性变化的事件来识别关键决策边界，并通过K-Means聚类和决策树技术来提取这些逻辑边界附近的人类可读规则。这个研究方法需要大量的输入和输出数据，并通过自定义计算机生成的简单示例进行测试，以验证方法的有效性", "innovation": "提出了一种新方法，使用强化学习和反事实分析从被视为黑箱的遗留系统中自动提取可解释的决策逻辑。通过奖励导致系统输出实质变化的操作，来识别关键决策边界；使用K-Means聚类和决策树训练来提取人类可读的规则，这些规则可以近似系统在关键决策边界附近的决策逻辑。这种方法为在遗留系统迁移期间生成规范和测试用例奠定了基础。", "conclusion": "通过实验证明，使用强化学习代理的方法能够有效地在相关的边界区域集中探索，并提取准确反映简单示例逻辑的人类可读规则。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00092", "html_url": "https://arxiv.org/abs/2507.00092", "title": "思考的艺术：SAGE-nano 的逆向推理及其自我意识语言模型", "title_en": "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models", "authors": "Basab Jha,Firoj Paudel,Ujjwal Puri,Zhang Yuting,Choi Donghyuk,Wang Junhao", "background": "大型语言模型(LLMs)在使用链式思考(CoT)提示解决复杂推理任务方面表现出色，但其决策机制仍然相对封闭。本文介绍了一种新的逆向推理(textbfinverse)范式，使得LLMs能够在其推理过程结束后回溯分析并解释自己的推理路径。通过应用在SAGE-nano模型上（这是一个40亿参数的推理模型），该方法利用元认知结构通过注意机制反向反馈来识别关键决策点并生成推理选择的解释。与传统CoT方法主要关注正向推理生成不同，逆向推理提供了理解为何选择了特定推理路径而不是其他路径的洞察。", "innovation": "(i) 提出了第一个严格框架，使LLMs通过逆向推理实现自我反思；(ii) 提供了新颖的元学习框架以逆转注意流；(iii) 建立了全面的推理透明性评估框架；(iv) 证明了通过逆向推理增加推理可以改善可解释性以及推理表现。", "conclusion": "通过逻辑推理谜题、数学问题和伦理困境等从AQUA-RAT、 CommonsenseQA 和定制基准中进行的全面测试，展示了SAGE-nano在推理准确性和解释质量上的卓越表现，并且其性能几乎与Claude-3.5 Sonnet或GPT-4o相当。我们的这项工作为透明人工智能系统开辟了新途径，并在人工智能的安全性、教育和科学发现方面填补了重要空白。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00263", "html_url": "https://arxiv.org/abs/2507.00263", "title": "未结构化 vacation 租房图片集合中的房间场景发现与分组", "title_en": "Room Scene Discovery and Grouping in Unstructured Vacation Rental Image Collections", "authors": "Vignesh Ram Nithin Kappagantula,Shayan Hassantabar", "background": "随着 vacation 租房 (VR) 平台的快速增长，上传的照片数量也在不断增加，但这些照片通常没有经过结构化的分类，导致旅行者难以理解公寓的布局，尤其是当有一个或多个相同类型的房间时这个问题更加明显。目前，由于缺少组织，使得旅行者在选择住宿时面临很大挑战。该研究旨在解决房间场景发现和分组问题，并识别每个卧室组中的床铺类型，这对于旅行者理解空间组织、布局及住宿配置尤为重要。", "innovation": "本文提出了一种高效的机器学习管道，该管道采用低延迟的监督房间类型检测模型、监督重叠检测模型以及基于相似度分数的聚类算法，能够有效地组织和识别图片，同时提出使用多模态大型语言模型 (MLLM) 将每个卧室组映射到相应的床铺类型。此方法在样本效率学习和实时或数据稀缺环境中表现良好，性能超越了现有的对比学习和预训练嵌入聚类方法。", "conclusion": "该研究提出的机器学习管道能够显著提高旅行者对公寓布局和床铺配置的理解，具有低延迟、样本效率高的特点，适用于实时和数据稀缺环境。并在独立评估和整体评估中表现出强劲性能，超越了传统的对比学习和预训练嵌入聚类方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00260", "html_url": "https://arxiv.org/abs/2507.00260", "title": "Disentangled Feature Importance", "title_en": "Disentangled Feature Importance", "authors": "Jin-Hong Du,Kathryn Roeder,Larry Wasserman", "background": "特征重要性量化面临着一个根本性挑战：当预测因子相关时，标准方法系统地低估了它们的贡献。许多现有方法在平方误差准则下针对相同的群体函数进行了优化，揭示了它们共相关偏差的原因。", "innovation": "为了克服这一限制，作者引入了一种名为Disentangled Feature Importance (DFI)的方法，这是经典R²分解的一种非参数泛化，使用最优运输理论。DFI通过交通映射将共相关特征转化为独立的潜在变量，消除了共相关带来的偏差。在潜在可加模型中，DFI为重要性提供了一个有原则的分解，使得重要性分数之和等于潜在变量的预测变异性，并且在任意特征依赖性下，可以根据交互加权的功能ANOVA方差推广此方法。开发了一整套关于DFI的半参数理论，建立了重要性估计在潜在空间中的根-n一致性与渐进正态性，并扩展到原始特征空间中的布尔斯-瓦瑟斯坦映射。", "conclusion": "DFI通过设计避免了反复子模型重构的计算负担和条件协变量分布估计的挑战，从而实现了计算效率。重要性估计在两个回归函数和变换映射估计误差都是o_{\text{P}}(n^{-1/4})的情况下，达到了二阶估计误差，该误差在该条件下消失。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00423", "html_url": "https://arxiv.org/abs/2507.00423", "title": "替罪羊：针对联邦学习的中毒成员推断攻击与防御", "title_en": "Find a Scapegoat: Poisoning Membership Inference Attack and Defense to Federated Learning", "authors": "Wenjin Mo,Zhiyuan Li,Minghong Fang,Mingwei Fang", "background": "联邦学习（FL）允许多个客户端在中央服务器协调下合作训练全局机器学习模型，无需共享原始数据。这种方法在GDPR等隐私法规盛行的今天尤其吸引人，许多知名公司正在采用这种方法。然而，FL的分布式性质使其容易受到中毒攻击的影响，恶意客户端（由攻击者控制）可以发送有害数据来破坏模型。现有的大多数FL中毒攻击侧重于降低模型的准确率，而对这些攻击的隐私保护关注较少。", "innovation": "研究引入了一个新的中毒攻击方法FedPoisonMIA，该方法能够使得恶意客户端通过构造本地模型更新来推断成员信息。此外，研究还提出了一种稳健的防御机制来减轻FedPoisonMIA攻击的影响。", "conclusion": "通过在各种数据集上进行的大量实验，验证了该攻击的有效性，而提出的防御方法也成功降低了其影响。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00205", "html_url": "https://arxiv.org/abs/2507.00205", "title": "整体医疗人工智能;改进性能和可解释性", "title_en": "Holistic Artificial Intelligence in Medicine; improved performance and explainability", "authors": "Periklis Petridis,Georgios Margaritis,Vasiliki Stoumpou,Dimitris Bertsimas", "background": "随着人工智能在医疗领域的应用兴趣日益增长，先前我们引入了HAIM（Holistic AI in Medicine）框架，该框架融合了多模态数据以解决下游临床任务。然而，HAIM在任务无关的数据处理和缺乏解释性方面存在局限性。为了克服这些局限，本文提出了xHAIM（Explainable HAIM）框架，该框架通过生成性人工智能增强了预测和解释性，并包含四个结构化步骤：自动识别与任务相关的患者数据、生成全面的患者总结、利用这些总结改进预测模型，并通过链接预测到患者特定医学知识来提供临床解释。这些步骤改善了AI的性能和可解释性，使其成为一种可解释的决策支持系统。", "innovation": "xHAIM（Explainable HAIM）框架利用生成性人工智能，在预测和解释性方面增强了HAIM。具体创新点包括：(1) 自动识别任务相关的多模态患者数据；(2) 生成全面的患者总结；(3) 利用这些总结改进预测模型；(4) 通过链接预测到患者特定医学知识提供临床解释。该框架突破了AI作为黑盒预测器的局限，使其成为一个可解释的决策支持系统。", "conclusion": "xHAIM在HAIM-MIMIC-MM数据集上的评估表明，xHAIM将平均AUC提高到了90.3%，尤其是在胸部病理和操作任务中的表现。重要的是，xHAIM将AI转变为一种可解释的决策支持系统，使得临床医生能够与系统互动，回溯预测到相关的患者数据，从而架起了人工智能进步与临床应用之间的桥梁。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00032", "html_url": "https://arxiv.org/abs/2507.00032", "title": "Ken 利用层：学生的Ken中的希伯尔重放以实现自适应的知识追踪", "title_en": "Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing", "authors": "Grey Kuling,Marinka Zitnik", "background": "该论文引入了一种生物启发的知识追踪（KT）架构KUL-KT，结合了Hebbian记忆编码和基于梯度的巩固，应用于可扩展且不依赖输入的数据框架中。KUL-KT借鉴了神经系统中记忆巩固的原理，将其应用于学生建模，引入了两个关键技术：（1）具有递减值衰的记忆更新，以实现优雅的遗忘。（2）一种新的Loss-aligned Internal Target（LIT）方法来计算理想的内部状态，允许不断学习而不需通过时间反向传播。该架构由一个快速的Hebbian记忆（通过单个关联更新捕捉每个学习者交互）和一个较慢的线性网络组成，该线性网络通过梯度下降巩固回忆样本。这种设计使得能够实现少量的个人定制，并自然遗忘无需存储原始数据或依赖于大型群体训练。KUL-KT支持结构化（表格）和非结构化（简答）输入。在公开发布的十个KT基准测试中，KUL-KT在nDCG和Recall@10等关键性排名指标上优于强劲的基线模型，且在课堂部署中，通过简答数据个性化测验，提高了学员感知的帮助性和降低了难度（p<0.05）。消除实验证明，希伯尔衰减和LIT对持续适应至关重要。与强劲的基于图的KT模型相比，KUL-KT的训练速度提高1.75倍，内存使用减少99.01%。这些成果使KUL-KT成为大型个性化学习中生物基础、内存高效且输入灵活的框架。背景总结：KUL-KT提供了一种创新的方法，通过整合Hebbian记忆更新和LIT方法，能够高效地进行持续学习，并且适用于结构化和非结构化的输入数据。", "innovation": "KUL-KT引入了一种新的记忆巩固机制，采用递减值衰的记忆更新和Loss-aligned Internal Target（LIT）方法来计算理想的内部状态，确保在没有通过时间反向传播的情况下实现连续学习。这项创新使得该模型能够高效地处理多样化的输入数据，并且实现少量的学习个性化同时自然遗忘，无需储存原始数据或依赖大型数据集的训练。这种架构明显区别于传统的基于图的知识追踪模型，展示了在理解和记忆学习中的巨大进展，特别是在教学应用中的直接效果显著。创新总结：KUL-KT通过引入新的Hebbian记忆更新机制和LIT方法，提供了一种在持续学习中高效运行的新型架构，特别适用于需要不断学习更新的知识追踪任务。", "conclusion": "KUL-KT架构在多个公开的基准测试中显示出强大的性能，特别是在关键的排名指标上超越了同类先进的模型。该模型还通过课堂部署展示了其实用性的特征，并且在实验中证实，Hebbian衰减和LIT对于持续的适应更新至关重要。与基于图的模型相比，KUL-KT不仅训练速度快，而且所需的内存显著减少，这使得KUL-KT成为大型、个性化学习场景中高效率、记忆高效的有力选择。结论总结：KUL-KT提供了一种高效的记忆机制与持续学习的方法，不仅在理论层面具有一定的创新性，且在实际应用中也取得了显著的效果，展示了其在大规模个性化学习场景中的潜力和优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00298", "html_url": "https://arxiv.org/abs/2507.00298", "title": "在生成建模中增强可解释性：由生成因子引导的科学数据集中统计分离的潜在空间", "title_en": "Enhancing Interpretability in Generative Modeling: Statistically Disentangled Latent Spaces Guided by Generative Factors in Scientific Datasets", "authors": "Arkaprabha Ganguli,Nesar Ramachandra,Julie Bessac,Emil Constantinescu", "background": "本研究旨在解决从复合高维数据集中统计性地提取生成性因素的挑战，特别是在无监督或半监督设置下。通过研究基于编码器-解码器架构的生成模型，以非线性降维的方式，重点在于分离低维潜在变量，这些变量代表独立的物理因素。研究通过使用辅助变量的方式，在标准变分自编码器（VAE）框架中引入了新型的Aux-VAE架构，以实现分离解耦，并通过保留先验统计知识，最小化对标准VAE损失函数的修改，从而形成相关因素和学习到的辅助变量相一致的潜在空间结构。比较多个数据集的评估验证了Aux-VAE的有效性，包括天文学模拟数据集。", "innovation": "我们提出了一种新的编码器-解码器生成模型，称为Aux-VAE，它基于经典的VAE框架。通过使用辅助变量，它能够在标准VAE损失函数中最小化对模型的修改，同时利用先验统计知识来实现解耦。Aux-VAE通过引导潜在空间的形成，使得潜在因子与学习到的辅助变量保持一致。通过多个数据集的比较评估，验证了该方法的有效性，特别是在天文学模拟数据集中表现出色。", "conclusion": "我们的研究通过在VAE中引入Aux-VAE架构，解决了复杂高维数据集中生成因子的统计提取问题，并通过比较评估证明了其有效性，为无监督或半监督设置下的数据建模提供了新方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00402", "html_url": "https://arxiv.org/abs/2507.00402", "title": "GRAND: 具有保证节点差分隐私的图形发布", "title_en": "GRAND: Graph Release with Assured Node Differential Privacy", "authors": "Suqing Liu,Xuan Bi,Tianxi Li", "background": "差分隐私是一个广泛认可的框架，用于保护数据中的敏感信息。尽管在许多领域得到了广泛应用，但它在网络数据（特别是节点水平）的应用仍然较为不足。现有方法要么仅专注于基于查询的方法，限制输出为预定义的网络统计，要么未能保留网络的关键结构属性。", "innovation": "我们提出了一种名为GRAND（Graph Release with Assured Node Differential privacy）的新网络发布机制，这是首个在确保节点差分隐私的同时还能保留网络结构属性的网络发布方法。在一系列潜在空间模型下，我们展示了发布后的网络分布与原始网络分布渐近收敛。通过合成和真实世界数据集的实验，我们验证了该方法的有效性。", "conclusion": "我们提出的方法能够在保证节点差分隐私的同时，发布完整的网络结构，并且在潜在空间模型下，发布后的网络分布与原始网络分布渐近收敛。实验表明，该方法在合成和真实世界数据集上都有较好的效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00353", "html_url": "https://arxiv.org/abs/2507.00353", "title": "基于自适应集成稀疏学习和区间预测的增强物理驱动锂离子电池模型", "title_en": "Augmented Physics-Based Li-ion Battery Model via Adaptive Ensemble Sparse Learning and Conformal Prediction", "authors": "Samuel Filgueira da Silva,Mehmet Fatih Ozkan,Faissal El Idrissi,Marcello Canova", "background": "准确的电化学模型对于锂离子电池在电动汽车和电网储能等实际应用中的安全高效运行至关重要。简化模型（ROM）可以兼顾精度和计算效率，但往往难以捕捉高倍率条件下的复杂非线性行为。现有研究仍面临挑战，因此需要一种新的方法来改进简化模型的准确性，特别是要能够补偿不可预测的动力学行为，增强模型的可靠性和准确性。", "innovation": "本文提出了一种自适应集成稀疏识别（AESI）框架，该方法通过与扩展单粒子模型（ESPM）相结合，以及采用演化集成稀疏学习策略，构建了一种稳健的混合模型。AESI框架还引入了区间预测方法，以提供电压误差动态的理论保证，从而进一步增强模型预测的可靠性。结果表明，该混合模型在不同运行条件下的电压预测精度显著提高，均方误差降低了高达46%，并且通过区间预测验证了统计上有效的预测区间，覆盖率分别为96.85%和97.41%。", "conclusion": "基于ESPM的混合模型（ESPM + AESI）和区间预测方法共同提高了电压预测的准确性和可靠性，为锂离子电池的实际应用提供了更强大的模型支持。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00401", "html_url": "https://arxiv.org/abs/2507.00401", "title": "跨域少量样本分类：有效无预训练骨干网络迁移", "title_en": "Few-shot Classification as Multi-instance Verification: Effective Backbone-agnostic Transfer across Domains", "authors": "Xin Xu,Eibe Frank,Geoffrey Holmes", "background": "我们研究了在不允许调整骨干网络（即特征提取器）的情况下进行跨域少量样本学习的情况——这种场景在实际应用场景中变得越来越常见。处理由冻结的“黑箱”骨干网络产生的低质量和静态嵌入导致少量样本分类问题转化为一系列多个实例验证（MIV）任务的表示。", "innovation": "我们提出了一种名为'MIV-head'的新方法，这一方法类似于一种对任何预训练的骨干网络都无感知的分类头，且计算效率高。MIV-head的核心组件在目标域少量样本数据上进行训练，能够在测试数据上取得优异表现，而无需调整骨干网络，且在元测试阶段实现。这种方法在各种设置下，使用扩展的Meta-dataset基准测试中的跨域少量样本图像分类，以及代表性的预先训练在ImageNet1K上的卷积神经网络和视觉变压器骨干网络，展示了其竞争力，而适应成本则远低于最新的适用于相同骨干网络的“适配器”方法。同时也发现已知的“分类头”方法在准确性方面明显落后。通过消融研究实证证明了方法核心组件的有效性。", "conclusion": "我们的MIV-head方法在无需对骨干网络进行微调的情况下，在目标域上可以取得优异的表现，并且适应成本显著低于最新的部分微调方法。我们分享了我们的代码：this https URL"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00511", "html_url": "https://arxiv.org/abs/2507.00511", "title": "使用高级U-Net进行医学图像分割：VMSE-Unet和VM-Unet CBAM+", "title_en": "Medical Image Segmentation Using Advanced Unet: VMSE-Unet and VM-Unet CBAM+", "authors": "Sayandeep Kanrar,Raja Piyush,Qaiser Razi,Debanshi Chakraborty,Vikas Hassija,GSS Chalapathi", "background": "本文介绍了一种旨在提高医学图像分割性能的深度学习架构VMSE U-Net和VM-Unet CBAM+模型。这些模型结合了传统的VM U-Net框架，并融合了Squeeze-and-Excitation (SE) 和 Convolutional Block Attention Module (CBAM) 技术，从而改善了分割的准确性、特征定位和计算效率。", "innovation": "本文的主要创新在于将SE和CBAM技术整合到传统的VM U-Net架构中，显著提升了分割精度、特征定位和计算效率。VMSE Unet模型在多个数据集上显示出优越的性能，特别在准确度、交并比（IoU）、精确度和召回率等方面表现出色，并且在GPU和CPU上的计算效率更高，推理时间更快，内存使用更少。", "conclusion": "研究建议改进的架构VMSE-Unet是医学图像分析的一个有价值的工具。其发现强调了进一步优化准确度、鲁棒性和计算效率的重要性，突显了其在临床应用中的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00514", "html_url": "https://arxiv.org/abs/2507.00514", "title": "使用多保真SBI的高效模拟推断", "title_en": "Simulation-Efficient Cosmological Inference with Multi-Fidelity SBI", "authors": "Leander Thiele,Adrian E. Bayer,Naoya Takeishi", "background": "基于模拟的推断成本很高，可以通过结合不同保真度的模拟集来减少这种成本。背景信息指出，现有的方法在这种情况下不一定有效，尤其是在预算有限和问题难度大的情况下。论文旨在针对这个问题提出一种改进的方法。", "innovation": "提出了一种基于特征匹配和知识蒸馏的多保真推断方法。这种方法特别适用于小模拟预算和困难的推断问题，能够提高后验分布的质量。", "conclusion": "论文通过使用多保真模拟集，结合特征匹配和知识蒸馏技术来改进基于模拟的推断方法，并在预算有限和难题中表现出色。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00537", "html_url": "https://arxiv.org/abs/2507.00537", "title": "并非所有注意力头都是你需要的：通过注意力消除改进CLIP的图像表示", "title_en": "Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation", "authors": "Feng Lin,Marco Chen,Haokui Zhang,Xiaotian Yu,Guangming Lu,Rong Xiao", "background": "CLIP已经在多种应用中展现了稳健的表现，但研究者假设某些注意力头会影响最终的表示，并使模型性能在下游任务中的表现下降。因此，他们提出了一种简单有效的方法——注意力消除技术（AAT），通过调节注意力权重来抑制特定头部的贡献，并系统地识别和消除有害的注意力头以提升表示质量。实验证明，AAT能够在不同的领域中提高下游任务的性能，特别是在CLIP家族模型的跨模态检索方面的召回率提升了11.1%。这些结果表明，AAT在几乎不增加推理成本的情况下能够有效提升大规模视觉-语言模型的表现。", "innovation": "提出了一种简单有效的注意力消除技术（AAT），通过调节注意力权重来抑制特定注意力头的贡献，系统地识别和消除有害的注意力头，从而提高表示质量。实验表明AAT可以显著提高下游任务性能，特别是CLIP家族模型的跨模态检索召回率提升了11.1%。", "conclusion": "实验结果表明，注意力消除技术（AAT）能够有效提升大规模视觉-语言模型的表现，且几乎不会增加推理成本。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00482", "html_url": "https://arxiv.org/abs/2507.00482", "title": "物理感知风格迁移以实现适应性全息重构", "title_en": "Physics-Aware Style Transfer for Adaptive Holographic Reconstruction", "authors": "Chanseok Lee,Fakhriyya Mammadova,Jiseong Barg,Mooseok Jang", "background": "全息影像呈现了一个反问题，即从记录的衍射图案重构物体的复振幅。虽然最近的深度学习方法已经在相位恢复算法上展现出了潜力，但它们通常需要高质量的真实复振幅地图数据集来实现两域之间的统计反向映射操作。这些方法往往依赖于高质量的真实数据集。因此，迫切需要一个无需高质量真实数据集的方法来实现反向映射操作.", "innovation": "本文提出了一种物理感知风格迁移的方法，将物体到传感器的距离视为衍射图案中的隐式风格。使用风格域作为中间域构建循环图像转换，证明了反向映射操作可以在仅使用强度测量数据集的情况下以自适应方式学习。这种方法无需依赖高质量的真实数据集，为那些难以或不可能获得真实数据的成像应用提供了一种实用的学习策略.", "conclusion": "通过利用嵌入在测量中的物理线索，本文展示了一种方法，该方法可以通过实时、无标记的成像技术重建流动红血球的形态，具有适应性和潜在的实际应用价值。这种对物理线索的学习策略为当前难以获取真实数据的成像应用提供了一种切实可行的方法."}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00498", "html_url": "https://arxiv.org/abs/2507.00498", "title": "MuteSwap: 基于静默面部的无声语音转换", "title_en": "MuteSwap: Silent Face-based Voice Conversion", "authors": "Yifan Liu,Yu Fang,Zhouhan Lin", "background": "传统的语音转换技术需要同时获取音源说话者和目标说话者的干净音频，但在没有干净音频的场景下，如静默视频或噪声环境中，这种转换变得不可行。本文探讨了通过静默面部进行无声语音转换的任务（Silent Face-based Voice Conversion, SFVC），即仅通过目标说话人的面部图像和音源说话人的静默视频（包含唇动信息）实现语音的转换，目标是使转换后的语音保留音源内容同时具备目标说话人的身份特征。这一任务对语音合成和身份转换都提出了挑战，因为它仅依赖视觉信息来生成可懂的语音并进行身份转换。", "innovation": "MuteSwap 是一个新颖的框架，它使用对比学习来对齐跨模态的身份信息，并最小化互信息以分离共享的视觉特征。通过这一方法，MuteSwap 在语音合成和身份转换中实现了出色的表现，特别是在噪声条件下，传统依赖于音频输入的方法无法生成可懂的语音时，MuteSwap 仍然表现出色。这不仅证明了我们训练方法的有效性，还证明了静默面部语音转换的可行性。", "conclusion": "实验结果显示，MuteSwap 在语音合成和身份转换任务上表现优异，尤其是在噪声条件下，展示了在仅使用视觉信息的情况下进行语音转换的有效性和可行性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00469", "html_url": "https://arxiv.org/abs/2507.00469", "title": "Biscele: 在视频语言理解的持续学习中，结合和分离", "title_en": "Bisecle: Binding and Separation in Continual Learning for Video Language Understanding", "authors": "Yue Tan,Xiaoqian Hu,Hao Xue,Celso De Melo,Flora D. Salim", "background": "前沿的视觉-语言模型（VLMs）在视频理解任务上取得了显著的改进。然而，现实世界中的视频通常以不断进化的数据流形式存在（例如，可穿戴眼镜捕捉的动态场景），需要模型能够持续适应变化的数据分布和新的情境。考虑到在新任务上对模型进行微调的成本高昂，通常只会更新一小部分参数，而大量的模型保持不变。这给大规模多模态基础模型的持续学习框架带来了新的挑战，即灾难性遗忘和更新冲突。基础模型在参数高效的持续学习方面遇到困难，但人类大脑的海马体进化出了高效的记忆形成和巩固机制。受海马体快速结合和模式分离机制的启发，本文提出了Biscele用于视频语言持续学习，通过多方向的监督模块捕捉更多的跨模态关系，并设计了一种对比提示学习方案来隔离任务特定的知识，以促进有效的记忆存储。结合和分离过程进一步增强了VLMs保持复杂体验的能力，使它们在视频理解任务中能够实现稳健和高效的持续学习。我们对提出的Biscele进行了全面评估，结果表明它能够在多个视频问答基准测试上有效减轻遗忘并增强跨任务泛化能力。", "innovation": "本文提出了Biscele用于视频语言的持续学习。Biscele设计了一种多方向的监督模块来捕捉跨模态关系，并提出了一种对比提示学习方案来隔离任务特定知识，这有助于高效的记忆存储。结合和分离过程进一步增强了VLMs保持复杂经验的能力，使其在视频理解和持续学习中表现出色。", "conclusion": "通过全面评估Biscele，我们展示了其减轻遗忘和增强跨任务泛化的能力。Biscele能够在多个视频问答基准测试中有效实现视频语言的持续学习。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00583", "html_url": "https://arxiv.org/abs/2507.00583", "title": "通过感知直化进行生成式视频检测", "title_en": "AI-Generated Video Detection via Perceptual Straightening", "authors": "Christian Internò,Robert Geirhos,Markus Olhofer,Sunny Liu,Barbara Hammer,David Klindt", "background": "生成式AI的快速发展产生了高度逼真的合成视频，这给内容认证带来了重大挑战，并引起了对其滥用的担忧。现有检测方法在泛化能力及捕捉微妙的时序不一致性方面常表现出色，但存在局限性。", "innovation": "提出了一种名为ReStraV(Representation Straightening Video)的新型方法，用于区分真实和AI生成的视频。该方法借鉴了“感知直化”假说，即真实世界视频在神经表征域中轨迹变得更直。通过预训练的自监督视觉变换器（DINOv2），量化模型表示域中的时序曲率和步距长度，进而训练分类器。实验表明，生成式视频在曲率和距离模式上表现出与真实视频显著不同的特征。实验结果展示了轻量级分类器在VidProM基准测试上的优越检测性能（例如97.17%的准确率和98.63%的AUROC），远超现有基于图像和视频的方法。", "conclusion": "ReStraV方法在计算效率上表现出色，提供了一种低成本且有效的检测解决方案。本研究为使用神经表示几何学检测生成式视频提供了新的见解。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00616", "html_url": "https://arxiv.org/abs/2507.00616", "title": "几何高斯近似概率分布", "title_en": "Geometric Gaussian Approximations of Probability Distributions", "authors": "Nathaël Da Costa,Bálint Mucsányi,Philipp Hennig", "background": "复杂概率分布，如贝叶斯后验分布，在许多应用中是核心问题。研究几何高斯近似的方法，如通过微分同胚或黎曼指数映射的高斯推进，是解决这些问题的重要工具和技术。", "innovation": "这项研究首先回顾了两种不同的几何高斯近似方法，然后探讨了它们之间的关系，进一步提供了一个建设性的证明表明，几何高斯近似具有普遍性，可以捕捉到任何概率分布。最后，研究探讨了是否可以找到一个共同的微分同胚，以获得该类分布族的高质量几何高斯近似。", "conclusion": "研究证明了几何高斯近似具有捕捉任何概率分布的能力，并探讨了在给定概率分布族的情况下，能否找到共同微分同胚以获得高质几何高斯近似的问题。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00600", "html_url": "https://arxiv.org/abs/2507.00600", "title": "多层金融网络中可解释的角色聚类指南", "title_en": "A Practical Guide to Interpretable Role-Based Clustering in Multi-Layer Financial Networks", "authors": "Christian Franssen,Iman van Lelyveld,Bernd Heidergott", "background": "理解金融机构在互联市场中的功能角色对于有效的监管、系统性风险评估和清算计划至关重要。一种基于角色的、可解释的聚类方法被提出，用于识别不同市场板块中的机构功能位置。该方法遵循由邻近度度量、聚类评估标准和算法选择定义的一般聚类框架，基于ego网络特征构建可解释的节点嵌入，以捕捉机构间的直接和间接交易关系。通过使用欧洲中央银行（ECB）的货币市场统计报告（MMSR）的交易级数据，该研究展示了角色聚类方法如何揭示不同类型的机构角色，如市场中介、跨板块连接者和边缘贷方或借方，强调了基于角色的聚类在分析金融网络和理解复杂市场结构中机构行为的灵活性和实际价值。", "innovation": "提出了一种新的可解释的基于角色的聚类方法，用于多层金融网络。该方法基于邻近度度量、聚类评估标准和算法选择定义了一般框架，通过ego网络特征构建可解释的节点嵌入，以捕捉直接和间接的交易关系。这种方法能够揭示不同市场的机构角色，并提供关于这些角色的可解释性结果。", "conclusion": "基于角色的聚类方法在分析金融网络和理解机构行为具有很大的灵活性和实际价值，能够揭示不同类型的机构角色，如市场中介、跨板块连接者和边缘贷方或借方。该方法具有较高的可应用于实际金融监管和风险评估中的潜在价值。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00546", "html_url": "https://arxiv.org/abs/2507.00546", "title": "通过表示学习实现纳米光子学的逆向设计", "title_en": "Inverse Design in Nanophotonics via Representation Learning", "authors": "Reza Marzban,Ali Adibi,Raphael Pestourie", "background": "逆向设计在纳米光子学中的应用，通过计算发现能够实现特定电磁响应结构的技术，已经成为最近光学进步的关键工具。传统上依靠直觉驱动或迭代优化方法难以应对高维度和非凸的设计空间，并且电磁模拟对计算能力提出了巨大需求。机器学习最近提供了有效的解决方案，通过表示学习来克服这些瓶颈。机器学习方法被划分为输出侧和输入侧两大类：输出侧方法使用机器学习学习解空间中的表示，从而创建一个可微的求解器以加速优化；输入侧技术则利用机器学习学习可能设备几何形状的紧凑、潜在空间表示，通过生成模型实现高效的全局探索。不同的策略各有优缺点，包括数据需求、泛化能力和新颖设计发现潜力。结合基于物理的优化与数据驱动的表示，这些混合框架有助于摆脱局部极值、提高可扩展性并促进知识迁移。", "innovation": "通过引入表示学习来分类并划分逆向设计方法，分别探讨输出侧和输入侧技术。输出侧方法旨在优化解空间中的表示来提高优化速度，而输入侧技术则利用机器学习来生成可能的设备几何形状。这样做有助于管理复杂的优化过程和探索设计空间，同时结合物理优化和数据驱动方法来增强其性能和鲁棒性。", "conclusion": "尽管机器学习在纳米光子学逆向设计中提供了显著优势，但还需要解决一些开放挑战和机会。这些挑战包括管理复杂性、设备几何与物理无关的表示、整合制造约束以及多物理层设计的进展。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00641", "html_url": "https://arxiv.org/abs/2507.00641", "title": "海biased 物理网络：基于局部物理法则的自我组织计算架构", "title_en": "Hebbian Physics Networks: A Self-Organizing Computational Architecture Based on Local Physical Laws", "authors": "Gunjan Auti,Hirofumi Daiguji,Gouhei Tanaka", "background": "传统机器学习方法在物理中的应用依赖于全局优化，这限制了模型的可解释性和无法在不引入外部约束的情况下直接通过模型结构实现物理限制。现有的方法通过全局损失函数来调整权重，但这些方法可能损害模型的即时解释性和直观性。", "innovation": "提出了一种新的计算框架——海biased 物理网络（HPN），通过局部海biased 更新直接编码物理法则来驱动权重适应，而不是依赖全局损失函数。HPNs 利用非平衡热力学理论和普利戈金波动理论，通过量化连续性、动量或能量的不平衡来驱动权重调整，形成一个基于残差的热力学过程，从而产生从随机初始条件无监督地自组织且符合物理规律的结构。", "conclusion": "海biased 物理网络重新定义了计算作为残差驱动的热力学过程，提供了一种可解释性强、可扩展性好且物理上合理的复杂动力系统建模方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00671", "html_url": "https://arxiv.org/abs/2507.00671", "title": "利用强化学习实现自适应MCMC的方法", "title_en": "Harnessing the Power of Reinforcement Learning for Adaptive MCMC", "authors": "Congye Wang,Matthew A. Fisher,Heishiro Kanagawa,Wilson Chen,Chris. J. Oates", "background": "采样算法是概率机器学习的关键，近年来采样算法的工具种类激增。然而，采样算法的复杂性与调参负担的增加成正比，导致需要将采样器的调优视为独立的学习任务。Wang等人在2025年将Metropolis-Hastings算法视为马尔可夫决策过程，提出了基于强化学习的自适应Metropolis-Hastings（Reinforcement Learning Metropolis-Hastings，RLMH）。", "innovation": "本文观察到自然选择的奖励，例如接受率或期望平方跳距，不足以训练RLMH，并提出了一种基于对比发散的新奖励，这在RLMH背景下表现更优。此外，研究了RLMH的潜力，提出了平衡马尔可夫转移核的灵活性和相关RL任务可学习性的自适应梯度采样器。并通过posteriordb基准的全面仿真支持了RLMH的实际有效性。", "conclusion": "RLMH通过新的奖励机制和自适应梯度采样器，在自适应MCMC领域表现出更强的实践效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00629", "html_url": "https://arxiv.org/abs/2507.00629", "title": "窄的单隐藏层网络在教师-学生设置下的泛化性能", "title_en": "Generalization performance of narrow one-hidden layer networks in the teacher-student setting", "authors": "Jean Barbier,Federica Gerace,Alessandro Ingrosso,Clarissa Lauditi,Enrico M. Malatesta,Gibbs Nwemadji,Rodrigo Pérez Ortiz", "background": "理解神经网络对简单输入-输出分布的泛化能力是评估其在真实数据集上的学习性能的关键。经典的教师-学生设置中，网络通过一个标签生成器教师模型获得数据进行训练，是一个完美的理论测试床。但在这种背景下，尚未完全理论解释全连接单隐藏层网络在具有通用激活函数时的性能。因此，本研究旨在通过统计物理方法为窄网络（即隐藏单元数远大于输入维度数）开发一个完整的理论，以预测其在回归或分类任务中的泛化误差。这项工作利用了有限温度（贝叶斯）和经验风险最小化估计器，以少量权重统计的形式给出了闭式性能表达式，并揭示了在样本数量足够大且与网络参数数量成比例时隐藏神经元的专业化现象。研究表明，该理论能准确预测通过全批量梯度下降（包括带有噪声的拉angevin 动力学梯度下降）训练的神经网络的泛化误差。", "innovation": "本文通过统计物理方法为窄网络提供了一个完整的理论，揭示了隐藏神经元的专业化现象，并准确预测了通过不同方法训练的神经网络的泛化误差。", "conclusion": "本文提出了一种理论，能够准确预测窄的单隐藏层网络在回归或分类任务中，在足够大的样本情况下，通过噪声和带噪声的全批量梯度下降训练的神经网络的泛化误差。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00640", "html_url": "https://arxiv.org/abs/2507.00640", "title": "前向逆转核回归方法解决薛定谔桥问题", "title_en": "Forward Reverse Kernel Regression for the Schrödinger bridge problem", "authors": "Denis Belomestny,John. Schoenmakers", "background": "本文研究了薛定谔桥问题（SBP），这是熵最优传输的核心问题。对于通用的参考过程和初始-终局分布，本文提出了一种前向-逆转迭代蒙特卡罗方法，以非参数方式近似薛定谔势能。特别地，使用核基蒙特卡罗回归，在相应的不动点问题的Pacific迭代中应用。通过在迭代中保持正性和希尔伯特距离上的收缩性，我们开发了一个收敛算法，并提供了势能估计的收敛率，并证明了其最优性。作为应用，我们基于构建的势能和条件扩散的前向逆转模拟方法，提出了一种用于薛定谔桥过程最终维度分布的非嵌套蒙特卡罗方法", "innovation": "提出了前向-逆转迭代蒙特卡罗方法来近似薛定谔势能，并使用核基蒙特卡罗回归。通过迭代中保持正性和收缩性证明算法收敛，并提供估计势能的收敛率并证明其最优性。提出了一种基于构建的势能和前向逆转模拟方法的非嵌套蒙特卡罗方法，用于薛定谔桥过程的最终维度分布", "conclusion": "本文开发了一个用于薛定谔桥问题的前向-逆转核回归方法，并证明了算法的收敛性和估计势能的最优性。此外，基于构建的势能，提出了一种用于在引入条件扩散的前向逆转模拟方法中估计薛定谔桥过程最终维度分布的非嵌套蒙特卡罗方法"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00683", "html_url": "https://arxiv.org/abs/2507.00683", "title": "测试自注意力的玻尔兹曼浴观点：GPT-2 变量分析", "title_en": "Testing the spin-bath view of self-attention: A Hamiltonian analysis of GPT-2 Transformer", "authors": "Satadeep Bhattacharjee,Seung-Cheol Lee", "background": "该研究基于Huo和Johnson提出的基于物理的框架，该框架将大型语言模型（LLMs）的注意力机制视为相互作用的两体自旋系统，并提供了对重复和偏见等现象的原理性解释。研究人员以此为基础，从生产级的GPT-2模型中提取完整的查询-键权重矩阵，并为每个注意头导出相应的有效哈密顿量，从而获得预测给定上下文中下一个标记分布的解析相界logit差距准则。", "innovation": "本研究创新地利用自旋系统框架分析GPT-2的注意力机制，提取了每个注意力头的哈密顿量，并基于此获得解析的相界准则预测下一个标记的分布。研究还通过系统的评估和针对性的消融试验，提供了生产级模型中自旋浴类比的强实证证据，验证了这些预测的有效性，加强了自旋浴模型与自注意力机制之间的联系。这项工作不仅为解释提供了一个可处理的物理视角，还为新型生成模型提供了理论基础，弥补了理论凝聚态物理和人工智能之间的差距。", "conclusion": "研究结果表明，理论logit差距与模型实际的标记排序之间存在强烈负相关（相关系数约为-0.70，p<10^-3），靶向的消融试验进一步证明，抑制与自旋浴预测最一致的头部可以诱导输出概率的变化，确认了自旋浴模型和自注意力机制之间的因果联系。这为生产级模型中自旋浴类比的实证验证提供了有说服力的证据，为生成模型的新发展奠定了基础。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00726", "html_url": "https://arxiv.org/abs/2507.00726", "title": "大型语言模型能否发展出策略性推理？从学习国际象棋后的见解", "title_en": "Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess", "authors": "Dongyoon Hwang,Hojoon Lee,Jaegul Choo,Dongmin Park,Jongho Park", "background": "虽然强化学习（RL）在大语言模型（LLMs）的数学推理中展现了潜力，但使用RL进行LLMs的战略推理尚未被充分探索。本文研究了通过使用RL在国际象棋中是否可以培养LLMs的战略推理能力。为此，利用国际象棋预训练的动作-价值网络来提供稀疏的二元奖励，旨在衡量LLMs的输出棋局质量，这种方法可以被视为知识蒸馏的一种形式。实验结果表明，基于蒸馏的密集奖励通常优于稀疏的二元奖励。然而，令人惊讶的是，所有模型都无法达到专家水平，甚至停滞在较低水平。研究人员进一步在国际象棋的原因训练中展开了SFT和RL的消融实验，结果显示这种限制可能是由于预训练模型内部对国际象棋的领悟不足，仅依靠RL可能无法完全克服这一问题", "innovation": "本文引入了利用国际象棋预训练的动作-价值网络来提供密集奖励的方法，这种方法可以视作知识蒸馏形式。研究表明，基于蒸馏的密集奖励在性能上优于稀疏的二元奖励，但所有模型在长期训练后仍无法达到专家级水平，这表明更大的挑战可能在于LLMs对游戏规则和策略的理解不足，这需要进一步的探索和研究", "conclusion": "虽然通过强化学习在国际象棋中训练LLMs展示了一定潜力，但所有模型都不能达到专家级水平。这中间可能存在着模型对其所学博弈规则和策略的理解不足的问题，单纯依靠强化学习难以完全弥补这一缺口，需要进一步研究解决。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00719", "html_url": "https://arxiv.org/abs/2507.00719", "title": "引导的无条件和有条件生成模型用于准地转湍流的超分辨和推理", "title_en": "Guided Unconditional and Conditional Generative Models for Super-Resolution and Inference of Quasi-Geostrophic Turbulence", "authors": "Anantha Narayanan Suresh Babu,Akhil Sadam,Pierre F.J. Lermusiaux", "background": "通常，海洋、天气和气候的数值模拟较为粗糙，观测数据稀疏且存在间断。本文采用四种生成扩散建模方法，旨在通过细分辨率的稀疏和有间断观测数据来提高解析度并进行推断，应用于β平面上的强迫二维准地转湍流。测试案例涵盖了两种湍流模式、两种雷诺数和两种观测类型，评估了重构涡旋场、湍流统计量、超分辨概率集及其误差。结果表明，SDEdit生成不合理的场，而DPS以低计算成本生成合理的重构，但平滑了精细尺度特征。有条件的方法需要重新训练，但能重构缺失的精细尺度特征，保持观测一致性，并具有正确的统计性质，如能量谱。此外，其平均模型误差与其集合标准差高度相关且可预测。结果揭示了扩散模型在实现便利性、保真度（锐度）和循环一致性之间的权衡，并为地球物理逆问题中的部署提供了实用指导。", "innovation": "提出了四种生成扩散建模方法，包括两种引导的无条件方法（SDEdit和DPS）和两种条件方法（加权标准版和自由分类器引导），以处理稀疏和有间断观测数据来提高分析分辨率并进行推断。", "conclusion": "SDEdit生成不合理的场，DPS在较低计算成本下生成合理的重构，但平滑了精细尺度特征。有条件的方法需要重新训练，但能重构缺失的精细尺度特征，保持观测一致性，并具有正确的统计性质。这些方法的平均模型误差与其集合标准差高度相关且可预测，强调了扩散模型在实现便利性、保真度和循环一致性之间的权衡，并为其在地球物理逆问题中的部署提供了实用指导。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00747", "html_url": "https://arxiv.org/abs/2507.00747", "title": "慢流形上的SINDy", "title_en": "SINDy on slow manifolds", "authors": "Diemen Delgado-Cano,Erick Kracht,Urban Fasel,Benjamin Herrmann", "background": "SINDy（稀疏识别非线性动力学）已经证明是一种有效方法，可以从数据中学习动态系统的可解释模型。然而，对于高维慢-快动力学系统，回归问题同时变得计算上不可行且病态。尽管原则上，仅建模在潜在慢流形上运行的动力学可以解决这两个挑战，但由于需要通过包含较高阶非线性作为候选项来补偿截断的快变量，导致SINDy库的规模急剧膨胀。", "innovation": "本工作开发了一种SINDy变体，该方法通过两个步骤稳健高效地识别慢-快动力学：首先，识别慢流形，即快变量作为慢变量函数的代数方程；其次，为在流形上的慢变量动力学习模型。关键是利用步骤(i)中学到的方程，构建一个仅包含作为候选项的重要较高阶非线性的流形导向函数库。不同于包含一定阶数的所有单项式，由此形成的定制库是针对具体问题定制的稀疏子集，并且根据具体问题进行了定制。该方法在截断弹跳屈曲梁和NACA 0012机翼流数值示例中得到演示。我们发现在慢流形上的动力学识别既减少了SINDy库的条件数，又减少了库的规模，从而使得准确识别慢流形上的动力学成为可能。", "conclusion": "我们提出的方法显著降低了SINDy库的条件数和规模，从而在慢流形上准确地识别动力学成为可能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00950", "html_url": "https://arxiv.org/abs/2507.00950", "title": "MVP: SMP Challenge 2025 视频赛道获胜方案", "title_en": "MVP: Winning Solution to SMP Challenge 2025 Video Track", "authors": "Liliang Ye(1),Yunyao Zhang(1),Yafeng Wu(1),Yi-Ping Phoebe Chen(2),Junqing Yu(1),Wei Yang(1),Zikai Song(1) ((1) Huazhong University of Science and Technology, Wuhan, China, (2) La Trobe University, Melbourne, Australia)", "background": "社交媒体平台作为内容传播、意见表达和公众参与的核心枢纽，在多种模态下发挥作用。准确预测社交媒体视频的热门程度能应用于内容推荐、趋势检测和受众参与等有价值的应用场景。", "innovation": "MVP系统结合预先训练的视频特征与用户元数据和上下文信息，构建了表现力强的帖子表示。它采用系统化的预处理技术，如对数变换和离群值去除，以提高模型的稳健性。MVP使用梯度提升回归模型来捕捉不同模态下的复杂模式。", "conclusion": "MVP在SMP挑战2025视频赛道的官方评估中排名首位，证明了其在社交媒体平台多模态视频热门程度预测中的有效性和可靠性。源代码可在指定链接获取。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00866", "html_url": "https://arxiv.org/abs/2507.00866", "title": "模板匹配遇见深度学习：使用物理引导神经网络进行红移估算", "title_en": "Template-Fitting Meets Deep Learning: Redshift Estimation Using Physics-Guided Neural Networks", "authors": "Jonas Chris Ferrao,Dickson Dias,Pranav Naik,Glory D'Cruz,Anish Naik,Siya Khandeparkar,Manisha Gokuldas Fal Dessai", "background": "准确的光谱红移估计对于观测宇宙学至关重要，特别是在大规模调查中，光谱测量不切实际。传统的方法包括模板匹配和机器学习，每种方法都有各自的优势和局限性。", "innovation": "本文提出了一种结合模板匹配和深度学习的方法，使用物理引导的神经网络。通过将光谱能量分布模板嵌入网络架构中，模型将物理先验信息植入训练过程。系统采用了多模态设计，结合交叉注意力机制融合光谱和图像数据，以及贝叶斯层进行不确定性估计。该模型在公开可用的PREML数据集上进行了评估，包括来自Hyper Suprime-Cam PDR3释放的大约40万个星系的5带光线度量、多带成像和光谱红移数据。该方法实现了0.0507的均方根误差、0.13%的3σ灾难性异常率和0.0028的偏差，满足了LSST红移需求的两个指标，适用于红移小于3的情况。", "conclusion": "这些结果突显了结合物理驱动模板与数据驱动模型的方法在即将到来的宇宙学调查中进行稳健的红移估计的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00894", "html_url": "https://arxiv.org/abs/2507.00894", "title": "Procrustes-Wasserstein距离的深入研究：性质与重心", "title_en": "An in depth look at the Procrustes-Wasserstein distance: properties and barycenters", "authors": "Davide Adamo,Marco Corneli,Manon Vuillien,Emmanuelle Vila", "background": "Procrustes-Wasserstein (PW) 方法由于其对刚性变换（如旋转和反射）的不变性，作为一种替代Wasserstein距离的最优传输距离引入，更适合用于点云的对齐和比较。为了在这些应用中使用PW，研究人员详细构建了一个离散概率度量的空间，并证明在该空间上PW实际上是一个距离。为此，已经存在了解决PW问题的算法，但本文通过讨论和测试多种初始化策略扩展了PW框架，并引入了PW重心的概念，提出了一种计算其估计值的算法，从而实现了计算点云集合的代表形状的新方法。这种方法在需要精确对齐和形状保持的场景中表现优于现存的OT方法，展示了PW在机器学习和计算几何应用中对2D和3D点云分析的潜力，在考古学中也有其用处。", "innovation": "1. 详细构建离散概率度量的空间，并证明PW在该空间上为距离。\n2. 扩展PW框架，讨论并测试多种初始化策略。\n3. 引入PW重心的概念，并提出相应的算法。\n4. 发展了一种计算点云集合代表形状的新方法。\n5. 在需要精确对齐和形状保持的场景中，实现了优于现存OT方法的表现。\n6. 在考古学中展示了PW的实用性，展示了其在提升2D和3D点云分析中的潜力。", "conclusion": "本文深入研究了Procrustes-Wasserstein距离的性质，并发展了用于计算点云重心的新算法，证明了PW在多种情景下的优越表现，并展示了其在考古学中的应用潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00984", "html_url": "https://arxiv.org/abs/2507.00984", "title": "大规模仓库自动化中的箱体姿态和形状估计及领域适应", "title_en": "Box Pose and Shape Estimation and Domain Adaptation for Large-Scale Warehouse Automation", "authors": "Xihang Yu,Rajat Talak,Jingnan Shi,Ulrich Viereck,Igor Gilitschenski,Luca Carlone", "background": "现代仓库自动化系统依赖大量智能机器人生成的数据，但大部分数据未标注。因此，如何有效利用这些未标注数据以改进感知模型成为亟待解决的问题。本文关注于在没有人工标注的情况下，通过自监督领域适应管道来提高感知模型的性能，特别是在估计箱子的姿态和形状方面。", "innovation": "本文提出了一种自监督领域适应管道，利用真实世界中的未标注数据来改进感知模型，而无需人工标注。该方法特别适用于估计盒子的姿势和形状，并通过新的正确-验证管道提升了自监督箱体姿态和形状估计的效果。", "conclusion": "本文的方法在模拟和真实工业环境中进行了广泛评估，包括对一个包含50,000张图像的大规模真实世界数据集的适应。实验结果表明，自监督模型在模拟训练基础上表现更优，且在零样本3D边框估计基准上显示出显著改进。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00937", "html_url": "https://arxiv.org/abs/2507.00937", "title": "RaGNNarok：在无人驾驶地面车辆上用于增强雷达点云的轻量级图神经网络", "title_en": "RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles", "authors": "David Hunt,Shaocheng Luo,Spencer Hallyburton,Shafii Nillongo,Yi Li,Tingjun Chen,Miroslav Pajic", "background": "低成本的室内移动机器人随着家庭和商业空间自动化程度的提高而越来越受欢迎。然而，现有的基于激光雷达和摄像头的解决方案存在一些限制，如在视线受阻的环境中性能较差、数据处理的高计算开销以及高成本的激光雷达。相比之下，毫米波雷达传感器提供了一种成本效益高且轻量化选择，在各种可视性条件下都能提供精确的距离测量。然而，现有的基于雷达的定位方法存在点云稀疏、噪声和误检测的问题。因此，本文提出了一种基于图神经网络（GNN）的实时、轻量级和通用框架RaGNNarok，旨在增强雷达点云，即使在复杂和动态的环境中也能实现这一目标。RaGNNarok在低成本Raspberry Pi 5上的推理时间为7.3毫秒，即使在资源限制的设备上也能高效运行，无需额外的计算资源。我们评测了RaGNNarok在三大环境中的局部定位系统（SLAM）、自主导航等关键任务中的性能。结果表明其可靠性和通用性都很强，使其成为低成本室内移动机器人的一个稳健解决方案。", "innovation": "提出了RaGNNarok——一种基于图神经网络的实时、轻量级和通用框架，用于增强雷达点云。该框架能够在低成本设备上高效运行，无需额外的计算资源，并在复杂和动态的环境中展现出强大的可靠性和通用性。", "conclusion": "RaGNNarok通过使用基于图神经网络的方法，有效提升了雷达点云的质量，使其在变速和动态环境中也能够提供精准的本地化、SLAM和自主导航功能，为低成本室内移动机器人的应用提供了稳健的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00845", "html_url": "https://arxiv.org/abs/2507.00845", "title": "Do Echo Top Heights Improve Deep Learning Nowcasts？", "title_en": "Do Echo Top Heights Improve Deep Learning Nowcasts?", "authors": "Peter Pavlík,Marc Schleiss,Anna Bou Ezzeddine,Viera Rozinajová", "background": "短时降水预报对于依赖天气的行业如交通运输、农业和灾害缓解至关重要。近年来，深度学习模型在改进短时降水预报方面显示出潜力，但大多数方法仅依赖二维雷达反射率场，忽略了三维雷达体积中可用的重要垂直信息。本文探讨了使用Echo Top Height（ETH）作为辅助输入变量，ETH是一个二维投影，表示雷达反射率超过给定阈值的最大海拔高度，用于基于深度学习的短时降水预报的方法。通过研究ETH与雷达反射率之间的关系，并通过实验验证了ETH预测降雨强度的相关性。研究结果表明，ETH有助于在低降雨率阈值下提高预报技能，但在高强度降雨中效果不一致，并且包含ETH的模型系统地低估了降水强度。通过三个案例研究，说明ETH在某些情况下有助于模型，但在其他情况下会增加预报误差。", "innovation": "这篇文章探索了将Echo Top Height（ETH）作为一种辅助输入变量用于基于深度学习的短时降水预报的可能性，并开发了一种单一通道的三维U-Net架构，该架构能够处理雷达反射率和ETH作为单独的输入通道。", "conclusion": "尽管ETH有助于提高低降雨率阈值下的短时降水预报技能，但在高降雨强度下效果不一致，并且ETH模型系统地低估了降水强度。本文研究表明ETH对提高短时降水预报性能有潜在的贡献，但还需要进一步研究以优化ETH的使用策略并提高在不同降雨强度情况下的预报效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00926", "html_url": "https://arxiv.org/abs/2507.00926", "title": "HyperFusion: 层级多模态集成学习在社交媒体流行度预测中的应用", "title_en": "HyperFusion: Hierarchical Multimodal Ensemble Learning for Social Media Popularity Prediction", "authors": "Liliang Ye(1),Yunyao Zhang(1),Yafeng Wu(1),Yi-Ping Phoebe Chen(2),Junqing Yu(1),Wei Yang(1),Zikai Song(1) ((1) Huazhong University of Science and Technology, Wuhan, China, (2) La Trobe University, Melbourne, Australia)", "background": "社交媒体内容优化、营销策略和用户参与度提升离不开对帖子流行度的预测。但由于视觉、文本、时间和用户行为因素之间复杂的相互作用，预测帖子的流行度仍然具有挑战性。本研究提出了一种名为HyperFusion的层级多模态集成学习框架，以预测社交媒体上的帖子流行度，该框架结合了视觉、文本和时间空间元数据等不同级别的特征，并采用了一种新的两级训练方法来应对标签数据有限的问题。", "innovation": "该研究提出了一种新的层级多模态集成学习框架HyperFusion，它采用了一种多层次融合架构，结合了CLIP编码器的视觉表示、Transformer模型的文本嵌入以及时间空间元数据与用户特征。同时，该框架还提出了跨模态相似度度量和层次聚类特征，以捕捉不同模态之间的依赖关系。此外，还采用了一种新的两级训练方法，包括伪标记和迭代精炼，以应对缺乏标签数据的问题。", "conclusion": "HyperFusion框架在SMP挑战数据集上取得了竞争力的表现，我们的团队在SMP挑战2025（图像赛道）中获得了第三名的成绩。源代码已发布，可供参考。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00885", "html_url": "https://arxiv.org/abs/2507.00885", "title": "下游缩放定律对下游任务不可靠：现实核查", "title_en": "Scaling Laws Are Unreliable for Downstream Tasks: A Reality Check", "authors": "Nicholas Lourie,Michael Y. Hu,Kyunghyun Cho", "background": "下游缩放定律旨在预测在较大规模上的任务性能，是从较小规模预训练损失中预测的。然而，这种预测的能力尚不清楚：一些研究证明任务性能在转变下遵循清晰的线性缩放趋势，而其他研究则指出了缩放定律的基本挑战，如涌现和反向缩放。这项工作中，我们通过对现有数据的元分析，发现只在少数情况下（39%）接近线性缩放定律的拟合。此外，实验设置中的看似无害的变化可以完全改变缩放趋势。这项分析强调了需要理解缩放定律成功适用的条件。为了全面建模预训练损失与下游任务性能之间的关系，我们必须接受缩放行为偏离线性趋势的情况。", "innovation": "该研究通过对现有数据进行元分析，揭示了线性缩放定律的应用情况仅在少数情况下成立，并且提出了实验设置的细微变化可以显著影响缩放趋势。研究还强调了在全面建模预训练损失与下游任务性能之间的关系时，必须考虑缩放行为偏离线性趋势的情况。", "conclusion": "该研究发现，下游缩放定律的准确性并不总是可靠的，存在显著的偏差情况，强调了需要更深入地理解缩放行为成功适用的条件。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00838", "html_url": "https://arxiv.org/abs/2507.00838", "title": "通过样态分析识别短文本中的人类和LLM生成的内容", "title_en": "Stylometry recognizes human and LLM-generated texts in short samples", "authors": "Karol Przystalski,Jan K. Argasiński,Iwona Grabska-Gradzińska,Jeremi K. Ochab", "background": "随着大型语言模型（LLMs）的发展，模型属性、知识产权和伦理AI使用等问题变得日益突出。样态分析作为一种识别文本作者和区分文本来源的方法，被广泛应用于多个领域。本文通过将样态分析应用到LLM生成的文本中，旨在识别其独特的写作模式，并探索样态特征对区分人类与LLM生成文本的有效性。研究使用了来自维基百科的超过12000个样本，包括人类撰写的概要、LLM生成的文本以及通过不同方法处理后的文本，旨在建立更加精确的基准数据集。", "innovation": "本文的创新点在于建立了一个基准数据集，涵盖多个LLM模型（如GPT-3.5/4, LLaMa 2/3, Orca, Falcon）生成的文本，并通过多种文本摘要和重构方法来促进样态特征的识别。研究团队通过树型模型（决策树和LightGBM）利用人工设计和基于n-gram的样态特征来分类文本，这些特征包括词汇、语法、句法和标点符号模式。实验结果表明，这些方法能够在多分类场景中达到高达0.87的Matthews相关系数，并在二分类中达到接近1.0的准确率，尤其是在人类撰写的维基百科和GPT-4的应用中，准确率达到0.98。", "conclusion": "研究结果关键表明，即使是对于复杂度较高的LLMs生成的文本，也能够至少在特定文本类型中通过样态特征对其进行区分。这一发现具有重要意义，特别是在处理模型属性、知识产权和伦理AI使用等领域。本文的研究方法可以作为未来类似研究的基础，并为后续利用AI进行文本分析提供新的视角。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00979", "html_url": "https://arxiv.org/abs/2507.00979", "title": "通过因果影响提示增强大语言模型代理的安全性", "title_en": "Enhancing LLM Agent Safety via Causal Influence Prompting", "authors": "Dongyoon Hahm,Woogyeol Jin,June Suk Choi,Sungsoo Ahn,Kimin Lee", "background": "随着强大语言模型（LLMs）驱动的自主代理在各种辅助任务中展现出巨大的潜在价值，确保其安全可靠的行为变得至关重要，以防止意外后果的发生。现有方法通常难以全面识别和减轻由于代理决策而导致的风险。因此，本文旨在提出一种新颖的方法，利用因果推理图（CIDs）来识别和缓解这类风险，从而使代理能够预测有害后果并做出更安全的决策。", "innovation": "本文提出的CIP方法通过利用因果推理图（CIDs）来识别和缓解代理决策过程中的风险，从而帮助代理预测并避免潜在的有害结果。该方法包括三个步骤：基于任务规范初始化CIDs，利用CIDs引导代理与环境的交互，以及根据观察到的行为和结果逐步改进CIDs。实验结果显示，该方法在代码执行和移动设备控制等任务中均能有效提升安全性。", "conclusion": "本文提出的CIP方法能够通过因果推理图（CIDs）有效提升自主代理的安全性，实验验证了其在不同任务中的有效性。未来可以进一步研究如何更好地利用这种结构化的方法来指导更复杂的代理行为，并探索更广泛的应用场景。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00957", "html_url": "https://arxiv.org/abs/2507.00957", "title": "基于大气模型训练的机器学习选择和分类超冷TY矮星", "title_en": "Atmospheric model-trained machine learning selection and classification of ultracool TY dwarfs", "authors": "Ankit Biswas", "background": "T和Y光谱类型代表了最冷和质量最小的棕矮星群体，但由于样本统计不足，其总体数量仍不完整。现有的检测框架通常局限于识别M、L和早期T型矮星。由于更晚类型的超冷矮星（UCDs）观测样本稀少，这些框架受到限制。因此，本研究提出了一个全新的机器学习框架，该框架依赖于大气模型的合成光谱数据进行训练，专门用于识别和分类晚T型和Y型矮星。", "innovation": "该研究开发了一个基于合成光谱数据的全新机器学习框架，用于识别和分类晚T型和Y型矮星。该框架利用了最新的大气模型数据网格，生成的数据集比任何已知的样本数据集大一个数量级以上。通过拟合模型光谱与颜色关系来给这些合成模型分配光谱类型，并训练一系列分类器来识别和分类超冷矮星。该模型在测试数据集上表现优秀，且通过对已知超冷矮星目录的验证，其分类准确率超过99%，平均光谱类型精度在0.35±0.37个亚型内。这一新方法已经在光谱目录中发现了一颗以前未被记录的T8.2候选星。", "conclusion": "新提出的基于大气模型训练的机器学习方法对于从光谱目录中发现低亮度和晚类型的超冷矮星具有显著效果，展示了该模型在发现这些稀有天体方面的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.19342", "html_url": "https://arxiv.org/abs/2407.19342", "title": "C$^3$A: Parameter-Efficient Fine-Tuning via Circular Convolution", "title_en": "Parameter-Efficient Fine-Tuning via Circular Convolution", "authors": "Aochuan Chen,Jiashun Cheng,Zijing Liu,Ziqi Gao,Fugee Tsung,Yu Li,Jia Li", "background": "LoRA（低秩适应）已经成为大规模基础模型微调的一种流行方法，它通过低秩矩阵$\\mathbf{A}$和$\\mathbf{B}$来表示权重变化（即$\\Delta \\mathbf{W} = \\mathbf{B \\mathbf{A}}$），这种方法减少了可训练参数的数量并减轻了由完整delta矩阵引起的大量内存消耗。尽管LoRA在实际应用中取得了成功，但其固有的低秩特性可能会限制其性能。已有多个变种试图解决这一问题，但它们往往忽视了LoRA带来的计算和内存效率优势。", "innovation": "提出了C$^3$A（Circular Convolution Adaptation，循环卷积适应），不仅实现了高秩适应并提高性能，还在计算能力和内存利用方面表现出色。广泛的实验结果表明，C$^3$A在各种微调任务中都优于LoRA及其变种。", "conclusion": "C$^3$A在循环卷积的帮助下，不仅能够进行高效参数适配（fine-tuning），还能显著提升微调任务的性能，其在计算资源利用上也表现出更大的优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking: 面向可扩展强化学习的多功能多模态推理", "title_en": "GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Leyi Pan,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianle Gong,Wenkai Li,Wei Jia,Xin Lyu,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuxuan Zhang,Zhanxiao Du,Zhenyu Hou,Zhao Xue,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "本文介绍了一个多功能多模态推理型的模型GLM-4.1V-Thinking。该模型旨在推进通用多模态推理的发展。通过大规模预训练建立了一种强大且具有潜在能力的视觉基础模型，并通过Curriculum Sampling强化学习框架进一步提高了模型性能，使其在各种任务上展现出全面的能力提升，包括科学问题解决、视频理解、内容识别、编程、语义标注以及基于GUI的代理等。GLM-4.1V-Thinking不仅实现了与7亿参数模型相当的性能，还在多个主要基准测试中超过了更大的模型Qwen2.5-VL-72B，在28个公开基准测试中，除少数任务外，其性能均优于Qwen2.5-VL-7B，并且在部分任务上优于GPT-4o这样的闭源模型，特别是在长文档理解和科学推理等任务上表现更为出色。", "innovation": "本文创新地提出了基于标准化强化学习框架Curriculum Sampling的多功能多模态推理训练方法，通过大规模预训练和强化学习迭代优化，有效提升了模型在多种任务上的表现。开放源代码与主要模型相比，显示出了明显的性能优势，特别是在处理大型和复杂的任务如长文档理解和科学推理方面表现尤为突出。", "conclusion": "GLM-4.1V-9B-Thinking显著提升了多功能多模态推理能力，尤其在大规模强化学习算法的驱动下，其开放源代码提供了广泛的科研支持，性能超越了多个同类模型，在一些关键任务上展示了与GPT-4o等闭源模型相比的优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.05175", "html_url": "https://arxiv.org/abs/2310.05175", "title": "Outlier Weighed Layerwise Sparsity (OWL): 一种高稀疏性裁剪LLMs的缺失的秘诀", "title_en": "Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity", "authors": "Lu Yin,You Wu,Zhenyu Zhang,Cheng-Yu Hsieh,Yaqing Wang,Yiling Jia,Gen Li,Ajay Jaiswal,Mykola Pechenizkiy,Yi Liang,Michael Bendersky,Zhangyang Wang,Shiwei Liu", "background": "大规模语言模型（LLMs）在各种领域展示出非凡的性能，但在实际部署时因模型规模庞大而面临挑战。传统的网络剪枝技术被应用于LLMs，试图一次性剪枝大量参数而不影响性能。现有LLM剪枝策略通常采用等量剪枝所有层的方法，取得了稳健的效果。然而，这个策略与在视觉模型中观察到的趋势不同，后者采用非均匀层间稀疏性通常能获得更好的效果。研究者为了理解这种差异，进行了一项全面的研究，发现了激活异常值在LLMs中的出现与这一现象的关联，并在此基础上提出了新的OWL（Outlier Weighed Layerwise Sparsity）非均匀层间稀疏性裁剪技术。", "innovation": "提出了一种新的LLM剪枝方法——OWL（Outlier Weighed Layerwise Sparsity），它基于每层激活异常值的比例调整稀疏性比值，使每层权重稀疏性和异常值比例更好地对齐。实验证明，OWL相较于先前的方法，在LLaMA-V1家族和OPT模型上表现更加出色，在高稀疏性条件下，相对于顶尖模型Wanda和SparseGPT，分别在70%稀疏性下取得了61.22和6.80 perplexity的显著提升，同时实现了2.6倍的端到端推理速度提升。", "conclusion": "OWL通过非均匀的层间稀疏性调整方法，平衡了LLM模型的稀疏性和性能，提高了高稀疏性条件下的模型性能，并显著提升了推理速度。进一步的研究表明，OWL在LLM裁剪中具有重要的应用价值。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.09111", "html_url": "https://arxiv.org/abs/2409.09111", "title": "从扩散角度看Transformer：神经消息传递的统一框架", "title_en": "Transformers from Diffusion: A Unified Framework for Neural Message Passing", "authors": "Qitian Wu,David Wipf,Junchi Yan", "background": "学习具有特定几何结构（例如观察到的或未观察到的）的结构化数据的表示是一个基本挑战，而消息传递神经网络（MPNNs）已成为此类问题的一种标准模型解决方案。基于物理系统，本文提出了一种能量受限扩散模型，该模型综合了基于流形的扩散的归纳偏置以及逐层的能量最小化约束。研究表明，扩散运算符与扩散过程中隐含产生的能量函数之间存在一一对应关系，而通过有限差分迭代求解能量受限扩散系统产生了各种类型的MPNN在观察到或潜在结构上的传播层，从而形成了一般的计算流程可以表现为消息传递或其特殊情况的统一数学框架，包括多层感知器（MLPs）、图神经网络（GNNs）和变换器（Transformers）。", "innovation": "本文提出了一种新的神经消息传递模型——能量启发式变换器（DIFFormer），其全局注意力层源自原理上的能量受限扩散框架。", "conclusion": "在从现实网络到图像、文本和物理粒子的多种数据集上，新模型在数据结构观察到、部分观察到或完全未观察到的情况下都取得了出色的性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.12446", "html_url": "https://arxiv.org/abs/2409.12446", "title": "神经网络在低复杂度数据上具有泛化能力", "title_en": "Neural Networks Generalize on Low Complexity Data", "authors": "Sourav Chatterjee,Timothy Sudijono", "background": "研究发现，前馈神经网络在低复杂度数据上表现出良好的泛化能力。给定来自简单编程语言的独立同分布数据，最小描述长度（MDL）的前馈神经网络能够以高概率实现基于这些数据的插值，从而具有良好的泛化性能。通过定义这种简单编程语言及其网络的描述长度，分析了基本计算任务，例如检查自然数是否为素数，进一步对具有噪声数据的情况进行了讨论，表明MDL神经网络插值器能够展示适度的过拟合强度。", "innovation": "1. 插值MDL网络在使用来自简单编程语言的独立同分布数据时表现出良好的泛化能力。\n2. 分析了简单的计算任务，如素性测试。\n3. 讨论了噪音数据情况，表明MDL神经网络插值器展示出适度的过拟合强度，从而能够在复杂度较低的数据上有效泛化。", "conclusion": "对于独立同分布的数据集（例如，从1到N均匀随机抽取的n个数），最小描述长度的插值神经网络以很高的概率准确回答新抽取的1到N之间的数字是否是素数。此外，该研究还涉及带有噪声数据的情况，表明这些网络能够在简单任务上避免过度拟合，从而在低复杂度数据上具有良好的泛化能力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.02277", "html_url": "https://arxiv.org/abs/2310.02277", "title": "Junk DNA Hypothesis: Pruning Small Pre-Trained Weights Irreversibly and Monotonically Impairs 'Difficult' Downstream Tasks in LLMs", "title_en": "Junk DNA Hypothesis: Pruning Small Pre-Trained Weights Irreversibly and Monotonically Impairs \"Difficult\" Downstream Tasks in LLMs", "authors": "Lu Yin,Ajay Jaiswal,Shiwei Liu,Souvik Kundu,Zhangyang Wang", "background": "长期以来，人们认为大型语言模型（LLMs）中的权重包含大量冗余，因此可以删除一些参数而不影响性能。但此研究论文挑战了这一观点，认为即使是在微小的预训练权重中，也含有对解决复杂下游任务至关重要的知识。论文通过逐步减少预训练权重来验证这一假设，发现随着权重的减少，下游任务性能呈单调递减的趋势。此外，研究还指出，允许下游持续训练也无法完全弥补这种知识损失，这在复杂的任务上表现得尤为明显。研究还对比了量化压缩在解决任务难度信息分散方面的作用，发现量化效果并不如预期，不能像微小权重减少那样提供一致的单调效果。", "innovation": "该论文采用了一种新颖的任务导向角度，重新审视了大型语言模型中预训练权重的冗余和可修剪性。通过正式引入量化可测量的指标来评估下游任务的难度，并且发现即使在继续训练下游任务的情况下，主要保留小量级的预训练权重也导致不可逆转的性能下降。研究在多种模型大小、任务类型、数据集和不同的剪枝方法上进行了广泛实验，验证了Junk DNA假设的正确性。", "conclusion": "本文通过广泛的实验验证了Junk DNA假设，即去除大型语言模型中微小的预训练权重会不可逆地且单调地降低复杂下游任务的表现，即使允许下游持续训练也无法完全弥补这种损失。此外，量化压缩方法并没有展现出同样的单调关系，无法有效地分散任务难度信息。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.10747", "html_url": "https://arxiv.org/abs/2402.10747", "title": "完全可微分的拉格朗日卷积神经网络用于物理知情的降水现在预测", "title_en": "Fully Differentiable Lagrangian Convolutional Neural Network for Physics-Informed Precipitation Nowcasting", "authors": "Peter Pavlík,Martin Výboh,Anna Bou Ezzeddine,Viera Rozinajová", "background": "现有降水现在预测方法大多依赖于物理学知识，但数据驱动的模型能够有效学习复杂模式。本文旨在结合数据驱动学习和物理约束知识，提出一种拉格朗日卷积神经网络模型，以提高降水现在预测的准确性。该模型基于现有的基于外推的现在预测方法，结合了U-Net结构和差分流体力学积分操作符，实现了端到端的训练和推理过程，使得数据驱动的拉格朗日坐标变换可以在运行时进行。", "innovation": "本文提出了LUPIN（Lagrangian Double U-Net for Physics-Informed Nowcasting），一种结合拉格朗日方法和卷积神经网络的模型，用于降水现在预测。该模型包含一个动态生成中尺度气流场的U-Net，一个可微分半拉格朗日外推操作符，以及一个不包含气流的U-Net，用于捕捉降水随时间的增长和衰减。这一方法能够在完全可微分和GPU加速的环境中实现端到端训练和推理，包括在运行时对数据进行拉格朗日坐标系统的数据驱动变换。", "conclusion": "实验结果表明，LUPIN模型在极端事件案例研究中与其它基于AI的降水现在预测模型相比，既在定量上也定性上都表现出优越的性能，甚至超过了选定的基准模型。此成果为其他拉格朗日机器学习模型打开了新的研究方向。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.10248", "html_url": "https://arxiv.org/abs/2311.10248", "title": "识别全局模型的真实：在联邦学习中防御拜占庭和后门攻击的通用解决方案（完整版本）", "title_en": "Identifying the Truth of Global Model: A Generic Solution to Defend Against Byzantine and Backdoor Attacks in Federated Learning (full version)", "authors": "Sheldon C. Ebron,Meiying Zhang,Kan Yang", "background": "联邦学习（FL）允许多个参与方在无需共享原始训练数据的情况下协作训练机器学习模型。然而，FL的联邦特性使得恶意客户端能够通过注入错误模型更新进行拜占庭或后门攻击，从而影响训练结果。当前防御方法通常是通过测量每个模型更新与所谓‘基准模型更新’的距离来检测恶意更新。但是，这些‘基准模型更新’的获取要么依赖于服务器上的良性基础数据集（如FLTrust），要么仅仅使用修剪平均值或中位数作为阈值（如FLAME）。然而，这种良性基础数据集实际上是不可行的，而修剪平均值或中位数可能也会排除这些被低估的数据集的贡献。因此，我们提出了一个称为FedTruth的通用解决方案，以防御联邦学习中的模型污染攻击，其中‘基准模型更新’（即全局模型更新）将在所有模型更新中动态聚合权重来估计。", "innovation": "FedTruth 提出了一种通用解决方案来防御联邦学习中的模型污染攻击，不需假设良性或恶意数据分布，也不依赖于良性基础数据集。FedTruth 能考虑所有良性客户端的潜在贡献，并能有效地减少拜占庭和后门攻击的影响，特别是在大规模联邦学习系统中也很高效。", "conclusion": "实验证明，FedTruth 能有效减轻恶意模型更新的影响，不仅针对拜占庭攻击，也能防御后门攻击，并且在大规模联邦学习系统中表现高效。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.10665", "html_url": "https://arxiv.org/abs/2402.10665", "title": "软Dice置信度：语义分割中近最优的选择性预测置信度估计器", "title_en": "Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation", "authors": "Bruno Laboissiere Camargos Borges,Bruno Machado Pacheco,Danilo Silva", "background": "现有的预测方法通常在不确定时会给出误导性的预测，而选择性预测通过增加模型在不确定时有选择地放弃预测的选项来缓解这一问题。现有的不确定性评分函数要么忽视特定的评估指标特性，要么需要额外的保留数据进行调优。研究者们提出了一个简单的、无需调优的不确定性评分函数——软DICE置信度(软DICE置信)，该函数直接与DICE系数指标相一致。理论证明在条件独立的情况下，软DICE置信度接近最优：它为理想（不可计算的）不确定性评分函数提供了上界和下界，并显示这些界限非常接近1。在六个公开的医学成像基准数据集和合成数据上的实验验证了理论结果，并且软DICE置信度在所有实验中都优于文献中的所有先前的不确定性估计器，即使是有额外数据支持的也是如此，这些结果将软DICE置信度定位为具有可靠性和效率的选择性预测语义分割置信度估计器。", "innovation": "提出了一个简单且无需调优的不确定性评分函数——软DICE置信度(软DICE置信)。该函数直接与DICE系数指标相一致，并在条件独立的情况下是近最优的。实验结果表明，软DICE置信度在所有实验中都优于文献中的所有先前的不确定性估计器，即使是有额外数据支持的也是如此。", "conclusion": "软DICE置信度被视为选择性预测中语义分割可靠且高效的置信度估计器。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.15128", "html_url": "https://arxiv.org/abs/2409.15128", "title": "无限时区广义用途马尔可夫决策过程中的试验次数很重要", "title_en": "The Number of Trials Matters in Infinite-Horizon General-Utility Markov Decision Processes", "authors": "Pedro P. Santos,Alberto Sardinha,Francisco S. Melo", "background": "GUMDPs框架扩展了传统的MDPs框架，考虑了依赖于给定策略引发的状态-动作对访问频率的目标函数。已有研究表明，在传统的时区MDPs中，试验次数对性能影响不大。本研究聚焦于无限时区GUMDPs，旨在分析试验次数对这类问题的影响。", "innovation": "本研究首次分析了无限时区GUMDPs中试验次数的作用。研究发现了在无限时区GUMDPs中，试验次数对预期性能至关重要，且对策略的期望表现取决于试验次数。此外，研究还探讨了折扣和平均GUMDPs，并提供了有限与无限试验次数之间性能差异的理论下界和上界。进一步研究不同类别GUMDPs对性能差异的影响，并通过实验数据支持研究发现。", "conclusion": "本研究揭示了在无限时区GUMDPs中，试验次数显著影响策略的性能。这种影响在折扣和平均GUMDPs中表现不同，通过理论分析和实验数据支持了研究结论，强调试验次数和GUMDP结构对策略评估的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.17766", "html_url": "https://arxiv.org/abs/2411.17766", "title": "基于预训练模型的类别增量学习中集成双重原型以实现任务适配", "title_en": "Integrating Dual Prototypes for Task-Wise Adaption in Pre-Trained Model-Based Class-Incremental Learning", "authors": "Zhiming Xu,Suorong Yang,Baile Xu,Furao Shen,Jian Zhao", "background": "类别增量学习（CIL）旨在学习新类别同时保留历史知识的增量。现有基于预训练模型（PTM）的方法在CIL方面表现优异，但要在未知模式的下游增量任务中对PTM进行微调，仍需克服灾难性遗忘的问题，即训练过程可能会抹除PTM已有的知识。本文即是在此背景下探讨如何设计一个解决方案来处理这一问题。", "innovation": "本文提出了一个基于PTM的CIL方法——双原型网络的适配器（DPTA），用于不同增量学习任务。它包括一个适应器模块，通过中心-适应损失驱动表征更为中心聚类和类别分离。同时，通过双重原型网络进一步优化预测过程，利用原始原型预测测试样本的可能性任务索引来选择合适的适应器模块，并利用增强原型来区分高度相关类别以确定最终结果。", "conclusion": "DPTA在多个基准数据集上的实验均表现出色。代码可通过提供的链接获取。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06432", "html_url": "https://arxiv.org/abs/2412.06432", "title": "将专家标签集成到基于LLM的排放目标检测中：示例选择与自动提示设计对比", "title_en": "Integrating Expert Labels into LLM-based Emission Goal Detection: Example Selection vs Automatic Prompt Design", "authors": "Marco Wrzalik,Adrian Ulges,Anne Uersfeld,Florian Faust,Viola Campos", "background": "本文研究了企业在报告中检测减排目标的问题，这是监测公司应对气候变化进展的重要任务。重点关注如何将专家反馈（标签化例句）集成到基于LLM的管道中，并比较了两种策略的有效性：一是动态选择少量例句，二是由LLM自动优化提示。通过一个包含769个与气候相关的真实业务报告文本的公共数据集进行分析，得出结论自动优化提示效果更佳，并且结合两种方法只能提供有限的好处。进一步的质性结果显示优化的提示确实捕捉了许多针对减排目标提取任务的细微之处。", "innovation": "两种策略的比较研究，特别是研究了由LLM自动优化提示与动态选择少量例句在集成专家反馈中的效果差异，以及结合两种方法所能带来的增益程度。此工作为未来开发更加有效的自动文本处理系统提供了参考。", "conclusion": "研究发现自动优化提示是更优的方法，结合两种方法只能提供有限的好处。优化提示有效捕捉了任务的复杂性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08044", "html_url": "https://arxiv.org/abs/2501.08044", "title": "UFGraphFR：基于用户文本描述特征的图联邦推荐系统", "title_en": "UFGraphFR: Graph Federation Recommendation System based on User Text description features", "authors": "Xudong Wang,Qingbo Hao,Xu Cheng,Yingyuan Xiao", "background": "联邦学习作为一种隐私保护计算的关键范式，因其‘数据可用但不泄露’的特性，使得用户能够在不共享原始数据的情况下协作训练模型。这种特性激发了联邦推荐系统的出现，旨在平衡用户隐私与推荐准确性的需求。然而，现有的联邦推荐方法通常在参数聚合过程中忽略了用户之间的语义或行为关系，这限制了推荐效果。为了解决这个问题，基于图的联邦推荐系统被提出以利用邻域信息，但传统的图构建方法通常需要访问用户的原始数据或显式的社会链接，这与联邦学习严格的隐私要求相矛盾。基于此背景，本文提出了一种新的个性化联邦推荐框架UFGraphFR，它基于客户端本地嵌入的文本特征构建用户图。", "innovation": "UFGraphFR框架的核心创新在于通过客户端本地嵌入的文本特征构建隐私保护用户关系图，无需泄露原始用户属性，同时引入基于Transformer的架构来建模用户-项目交互序列的时间依赖关系。实验结果表明，UFGraphFR在保持用户隐私的同时，实现了与集中式和最先进的联邦推荐基准相当的推荐准确度。", "conclusion": "实验结果表明，UFGraphFR能够在保持用户隐私的同时，提供与集中式和最先进的联邦推荐基准相当的推荐准确度，证明了其在联邦推荐系统中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.14649", "html_url": "https://arxiv.org/abs/2410.14649", "title": "EvoPress: 准确的进化的动态模型压缩通过进化搜索", "title_en": "EvoPress: Accurate Dynamic Model Compression via Evolutionary Search", "authors": "Oliver Sieberling,Denis Kuznedelev,Eldar Kurtic,Dan Alistarh", "background": "大型语言模型（LLMs）的高计算成本导致了对模型压缩方法的研究激增，包括量化、稀疏化或结构化剪枝。最近的一个研究前沿是动态、非均匀压缩方法，这些方法可以在块内或层内调整压缩程度，以最小化准确性损失，同时保证全局压缩阈值。然而，目前的方法依赖于估计给定层的重要性，隐含地假设层独立贡献整体压缩误差。这项研究指出，这一独立性假设在LLM压缩中通常不成立：进一步修剪模型甚至可能显著恢复性能。", "innovation": "文章提出了EvoPress，一种新的进化框架，用于动态LLM压缩。通过将动态压缩形式化为一个通用的优化问题，EvoPress能够高效地识别最佳压缩配置文件，并在多种模型和压缩技术之间进行泛化。使用EvoPress，研究人员实现了最先进的动态压缩性能，适用于Llama、Mistral和Phi模型，设置了结构剪枝（块/层删除）、无结构稀疏化和动态位宽量化的新基准。", "conclusion": "通过EvoPress，我们达到了最先进的动态压缩性能，适用于Llama、Mistral和Phi模型，并设立了结构剪枝、无结构稀疏化和量化的新基准。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.16362", "html_url": "https://arxiv.org/abs/2501.16362", "title": "Trunk Branch-net PINN用于多孔介质中的流热预测", "title_en": "A novel Trunk Branch-net PINN for flow and heat transfer prediction in porous medium", "authors": "Haoyun Xing,Kaiyan Jin,Guice Yao,Jin Zhao,Dichu Xu,Dongsheng Wen", "background": "现有的物理信息神经网络（PINN）在处理复杂的流动和热传输问题时存在局限性，尤其是对于多孔介质中的正向流动问题、正向热传输问题、反向热传输问题以及迁移学习问题。原有的PINN方法难以有效捕捉全局和局部特征，因此，需要开发一种新的 PINN 架构来克服上述问题，提高模型的鲁棒性与适用性，以更好地应用于工程实际中。", "innovation": "提出了一种新颖的Trunk-Branch (TB)-net物理信息神经网络架构，该架构通过结合主体网（Trunk net）和分支网（Branch net），分别用于捕捉全局和局部特征，解决了传统PINN在多孔介质中处理复杂物理过程的问题。主体网采用全连接神经网络（FNN）构建，分支网根据输出结果独立构建，通过自动微分方法计算输入对输出的偏导数，进一步增加了模型的有效性和灵活性，特别是在反向热传输问题和迁移学习方面展现了优势。", "conclusion": "通过对一系列正向问题的有效性和灵活性的验证，以及迁移学习验证资源重用的可行性，提出的Trunk Branch-net PINN在流热预测中具有广泛的应用潜力，尤其在克服传统数值方法在反向问题上的局限性方面表现出色。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.05576", "html_url": "https://arxiv.org/abs/2412.05576", "title": "STONet: 用于建模微裂缝储层中溶质运输的神经算子", "title_en": "STONet: A neural operator for modeling solute transport in micro-cracked reservoirs", "authors": "Ehsan Haghighat,Mohammad Hesan Adeli,S Mohammad Mousavi,Ruben Juanes", "background": "本文介绍了一种新的神经算子——溶质运输算子网络（STONet），用于高效建模微裂隙多孔介质中的污染物运输问题。训练数据来自有限元（FEM）模拟，捕捉了不同断裂密度、方向、开口度、长度以及压力驱动与密度驱动流动平衡的各种情景。实验结果表明，经过训练的STONet在预测准确性和计算效率上均超过了现有方法，可实现快速评估地下污染风险和优化环境修复策略。", "innovation": "STONet结合了增强的DeepONet结构和基于Transformer的多头注意力机制，不仅提高了性能，而且没有额外的计算成本。模型架构特别针对这个问题设计，能够有效编码不同属性并准确预测浓度场的变化率，从而精确模拟运输过程。", "conclusion": "STONet作为一种高效的计算方法，能够在相对较小的计算资源下实现准确的预测，极大提升了评估地下污染风险和优化环境修复策略的能力。研究团队将发布实验数据和代码，以便进一步研究和验证。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.14038", "html_url": "https://arxiv.org/abs/2410.14038", "title": "Sliding Puzzles Gym: 一个视觉强化学习状态表示的可扩展基准", "title_en": "Sliding Puzzles Gym: A Scalable Benchmark for State Representation in Visual Reinforcement Learning", "authors": "Bryan L. M. de Oliveira,Luana G. B. Martins,Bruno Brandão,Murilo L. da Luz,Telma W. de L. Soares,Luckeciano C. Melo", "background": "有效的视觉表示学习对于强化学习（RL）代理从原始感官输入中抽取与任务相关的信息以及跨多种环境进行泛化至关重要。然而，现有的RL基准在单独评估表示学习能力时缺乏系统的评估能力，而这通常与其他学习挑战交织在一起。为了解决这一问题，我们引入了Sliding Puzzles Gym (SPGym)，一种新型基准，将经典的8宫格拼图游戏转换为一个视觉RL任务，其图像来自任意大的数据集。SPGym的关键创新之处在于，通过可调节的网格大小和图像池能够精确控制表示学习的复杂性，同时保持固定的环境动力学、观察空间和动作空间。这种设计使研究人员能够在不依赖于其他学习组件的情况下，隔离并扩展视觉表示挑战。", "innovation": "SPGym 通过可调整的网格大小和图像池来精确控制表示学习的复杂性，同时保持固定的环境动力学、观察空间和动作空间，使研究者能够独立地隔离和放大视觉表示学习的挑战。此外，通过大量的实验，SPGym 揭示了当前方法在处理视觉多样性时的局限性，随着可能图像的数量增加，所有算法都表现出分布内和分布外性能下降，复杂的表示学习技术往往不如简单的数据增强方法。这些发现强调了视觉表示学习在RL中的关键缺口，SPGym 成为推动鲁棒、具有普适性的决策系统进步的宝贵工具", "conclusion": "通过在SPGym 上进行大规模实验，我们发现了当前方法在处理视觉多样性和跨环境泛化方面存在的关键问题。SPGym 作为一个新的基准，为视觉表示学习的研究提供了一个新的视角，未来的研究可以利用这一工具来推动这一领域的进步。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00300", "html_url": "https://arxiv.org/abs/2502.00300", "title": "东北美国地区风速预测不确定性量化：基于证据神经网络和可解释人工智能的方法", "title_en": "Uncertainty Quantification of Wind Gust Predictions in the Northeast United States: An Evidential Neural Network and Explainable Artificial Intelligence Approach", "authors": "Israt Jahan,John S. Schreck,David John Gagne,Charlie Becker,Marina Astitha", "background": "机器学习算法在减少风速预测中的偏见方面显示出潜力，但仍低估了高风速。不确定性量化(UQ)通过识别预测的可靠性或需要谨慎解释的情况，支持了这一问题。利用美国东北部61次极地风暴的数据，研究使用大气变量和Weather Research and Forecasting (WRF)模型数据，引入了证据神经网络(ENN)作为新的UQ方法。通过对可解释AI技术的分析，发现重要的预测特征与风暴强度和风速梯度高度相关，能够贡献更高的不确定性。", "innovation": "提出了基于证据神经网络(ENN)的新方法，用于风速预测的不确定性量化，该方法利用来自WRF模型的大气变量，通过可解释AI技术识别关键预测特征并分析其不确定性，ENN方法相比WRF在均方根误差(RMSE)上降低了47%，并且构造了预测区间，成功捕捉了至少95%的观测风速，无需使用集合，大幅度提升了预测的准确性和可靠性。", "conclusion": "提供具有量化不确定性的风速预报能增强利益相关方在极端风速事件中的风险管理评估和应对规划的信心。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.14003", "html_url": "https://arxiv.org/abs/2411.14003", "title": "生成干预模型在因果扰动建模中的应用", "title_en": "Generative Intervention Models for Causal Perturbation Modeling", "authors": "Nora Schneider,Lars Lorch,Niki Kilbertus,Bernhard Schölkopf,Andreas Krause", "background": "在许多应用场景中，外界扰动对系统中的哪些机制进行修改是未知的，尽管可以获取扰动的特征。例如，在基因组学研究中，药物的一些特性可以被知晓，但这些特性对细胞调控路径的因果影响尚不清楚。因此，需要一种模型来预测这种未知扰动对系统的影响，从而获取有关其机制效果的见解。", "innovation": "提出了一种生成干预模型（GIM），该模型能够学习将扰动特征映射到因果模型中联合估计的原子干预的分布。这种方法使得能够预测未见过的扰动特征的分布变化，并洞察其在数据生成过程中的机制效应。而与其他先有方法相比，GIM在合成数据和单细胞RNA测序药物扰动数据上表现出与无结构方法相当的外分布预测能力，同时有效地推断出潜在的扰动机制，通常优于其他因果推理方法。", "conclusion": "通过生成干预模型，能够在未知扰动机制的情况下，准确预测未见扰动的变化，并深入揭示其机制影响。GIM在合成和单细胞RNA测序数据上表现优异，与无结构方法相比，既能提供准确的外分布预测，又能有效地恢复潜在的扰动机制。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02869", "html_url": "https://arxiv.org/abs/2502.02869", "title": "在随机化世界中通过元训练实现大规模上下文强化学习", "title_en": "Towards Large-Scale In-Context Reinforcement Learning by Meta-Training in Randomized Worlds", "authors": "Fan Wang,Pengtao Shao,Yiming Zhang,Bo Yu,Shaoshan Liu,Ning Ding,Yang Cao,Yu Kang,Haifeng Wang", "background": "ICRL允许代理在互动体验中自动且实时地学习，但其扩展的挑战在于缺乏可扩展的任务集合。为了解决这一问题，本文提出了名为AnyMDP的程序生成的表格MDP，通过精心设计的随机化过程生成大规模高质量任务，同时保持较低的结构偏见。为了实现大规模的高效元训练，文章还介绍了逐步监督，并在ICRL中引入先验信息。实验结果表明，在足够的AnyMDP任务规模下，所提模型能够泛化到训练集中未考虑的任务。此外，AnyMDP提供的可扩展任务集也有助于更深入地研究数据分布与ICRL性能之间的关系。值得注意的是，ICRL的泛化可能会导致任务多样性的增加和更长的适应期，这为扩展稳健的ICRL能力指明了关键的方向，强调了多样和广泛的任务设计的重要性，以及渐进性能优于少量适应的重要性。", "innovation": "提出了程序生成的表格MDP（AnyMDP），并引入了逐步监督和先验信息，以实现高效的大规模元训练，解决了ICRL扩展中的任务集合缺乏问题，通过大量的任务生成提高了ICRL的泛化能力，并深入研究了数据分布与ICRL性能之间的关系。", "conclusion": "所提出的模型能够在足够的AnyMDP任务规模下泛化到训练集未考虑的任务，同时，展示出ICRL的泛化可能伴随更高的任务多样性和更长的适应期，强调了多样性任务设计和渐进性能的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.06385", "html_url": "https://arxiv.org/abs/2503.06385", "title": "一个良好的开端很重要：基于数据驱动的权重初始化增强持续学习", "title_en": "A Good Start Matters: Enhancing Continual Learning with Data-Driven Weight Initialization", "authors": "Md Yousuf Harun,Christopher Kanan", "background": "为了适应实际数据流，持续学习系统必须快速学习新概念同时保留和利用前期知识。在持续训练的深度神经网络中，遇到新类别时，分类器权重通常被随机初始化，这会导致初始训练损失高和不稳定，从而延长了最佳收敛和准确性所需的时间，增加了计算成本。", "innovation": "本文灵感来源于神经塌缩现象，提出了一种基于数据驱动的权重初始化策略来提高持续学习中的学习效率。通过在最后一层使用均方误差进行训练，神经塌缩会产生一个权重可以通过学习到的特征推导出来的最小二乘分类器。利用这种最小二乘公式初始化分类器权重，使其与特征分布对齐，而不是使用随机初始化，从而减少了初始损失的波动并加快了新任务的学习适应。", "conclusion": "我们在大规模持续学习设置中评估了我们的方法，结果显示学习速度更快且持续学习性能有所提升。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10345", "html_url": "https://arxiv.org/abs/2503.10345", "title": "间歇反馈的镜子在线符合预测", "title_en": "Mirror Online Conformal Prediction with Intermittent Feedback", "authors": "Bowen Wang,Matteo Zecchin,Osvaldo Simeone", "background": "论文背景主要是关于在线符合预测技术，这项技术允许使用反馈来在线调节预训练的人工智能模型的表现，确保长期的覆盖率保证。然而，将先验知识纳入这一过程的近期研究虽然带来了益处，但也牺牲了具体的覆盖率保证，取而代之的是基于分位数损失的不太明确的遗憾保证。", "innovation": "本文的创新在于提出了间歇镜像在线符合预测（IM-OCP），这是一种新颖的运行时校准框架，它结合了先验知识，并能够在可能出现间歇反馈的情况下运作，同时具有极低的内存复杂度。IM-OCP能够提供长期覆盖率和亚线性遗憾，这两种保证在给定的数据序列上都是确定性的，并且对于间歇反馈来说是期望的。", "conclusion": "IM-OCP框架确保了长期覆盖率和亚线性遗憾，两种保证对任何给定的数据序列都是确定性的，并且在期望意义上与间歇反馈有关。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08271", "html_url": "https://arxiv.org/abs/2503.08271", "title": "LangTime：一种基于语言导向的时序预测统一模型，结合了近端策略优化", "title_en": "LangTime: A Language-Guided Unified Model for Time Series Forecasting with Proximal Policy Optimization", "authors": "Wenzhe Niu,Zongxia Xie,Yanru Sun,Wei He,Man Xu,Chao Hao", "background": "近年来，研究显示在多种时序应用中利用预训练大型语言模型（LLMs）的兴趣持续增加。然而，将LLMs作为时间序列预测的先模范畴模型时存在三大挑战：(1) 跨领域泛化能力。(2) 跨模态对齐。(3) 自回归框架中的累积误差。为解决这些问题，本文提出了一种基于语言导向的统一模型LangTime，结合跨领域预训练与基于强化学习的微调方法，以期提升时间序列预测性能和稳定性.", "innovation": "提出了一种名为LangTime的新模型，其结合了跨领域预训练与基于强化学习的微调方法。特别地，LangTime通过构建跨数据集和跨通道指令的语言理解提示（TCPs），促进了领域适应，并将时间序列凝缩为单一词元，从而使LLMs更好地理解并对齐时间数据。为改善自回归预测，引入了TimePPO算法，利用面向时间序列的多维奖励函数和基于循环的价值评估策略来减少累积误差。这些创新措施显著提升了跨领域时间和序列预測性能，并增强了自回归预测的稳定性和准确性.", "conclusion": "经过大量实验，LangTime达到了跨领域的最先进的预测性能，而TimePPO微调有效提升了自回归预测的稳定性和准确性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05795", "html_url": "https://arxiv.org/abs/2502.05795", "title": "大型语言模型中的深度之殇", "title_en": "The Curse of Depth in Large Language Models", "authors": "Wenfang Sun,Xinyuan Song,Pengxiang Li,Lu Yin,Yefeng Zheng,Shiwei Liu", "background": "在现代大型语言模型（LLMs）中，近一半的层效果低于预期，这被作者称为'深度之殇'。研究确认了这一现象在多种流行的LLM模型（如Llama、Mistral、DeepSeek和Qwen）中普遍存在。分析表明，这种深层层无效的原因在于前向层规范化（Pre-LN）的广泛使用，导致模型深度增加时，输出方差指数级增长，使深层的Transformer块梯度接近恒等矩阵，从而无法显著提升训练效果。", "innovation": "为解决这一训练问题，作者提出了层规范化缩放（LNS）方法，通过反比于层数的平方根来调整层规范化输出的方差。这种简单的修改抑制了更深的Transformer层的输出方差增长，提高了它们在训练中的贡献。实验结果显示，在从130M到7B的广泛模型规模下，LNS在增强LLM预训练性能方面始终优于其他规范化和缩放技术。此外，这种改进也无缝应用于监督微调。这一系列改进的原因是层规范化缩放使深层层在训练期间能够更有效地贡献。作者的代码已公开于LayerNorm-Scaling。", "conclusion": "研究证明，通过LNS方法，能够有效改善大型语言模型的训练效果，特别是在训练和后续的微调阶段。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18549", "html_url": "https://arxiv.org/abs/2503.18549", "title": "RLCAD: 用于涉及旋转操作的CAD命令序列生成的强化学习训练环境", "title_en": "RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation", "authors": "Xiaolong Yin,Xingyu Lu,Jiahang Shen,Jingzhe Ni,Hailong Li,Ruofeng Tong,Min Tang,Peng Du", "background": "在三维CAD系统中，CAD命令序列是一种典型的参数化设计范式，通过2D草图叠加操作（如拉伸、旋转和布尔操作）来构建模型。尽管学界对自动生成命令序列表现出日益浓厚的兴趣，但现有的方法和数据集仅支持草图绘制、拉伸和布尔操作。这限制了对更为复杂几何形状的表示。", "innovation": "本文提出了一种基于CAD几何引擎的强化学习（RL）训练环境。给定输入边界表示（B-Rep）几何，RL算法中的策略网络生成动作。该动作结合先前生成的动作，在训练环境中生成对应的CAD几何，并将此几何反馈给策略网络。根据训练环境中生成几何与目标几何之间的差异确定奖励，用于更新RL网络。该方法支持草图绘制、布尔操作和拉伸之外的操作，包括旋转操作。通过此训练环境，我们能够从B-Rep几何中生成命令序列，效果达到当前先进水平（SOTA）。", "conclusion": "通过提出的强化学习训练环境，我们取得了目前处理B-Rep几何生成命令序列的最佳效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09850", "html_url": "https://arxiv.org/abs/2503.09850", "title": "TabNSA：高效表格数据学习的原生稀疏注意", "title_en": "TabNSA: Native Sparse Attention for Efficient Tabular Data Learning", "authors": "Ali Eslamian,Qiang Cheng", "background": "由于表格数据具有异构特征类型、缺乏空间结构以及样本量有限等特点，深度学习面临独特挑战。本文探讨了这些挑战，并介绍了一种新的深度学习框架——TabNSA，通过集成原生稀疏注意（NSA）模块和TabMixer主干网络来有效地建模表格数据。", "innovation": "本文提出的TabNSA框架通过动态关注每个实例相关的特征子集来解决计算和表征挑战。NSA模块使用分层稀疏注意机制，包括标记压缩、选择性保留和局部滑动窗口，显著减少了标准注意操作的二次复杂度，同时解决特征异构性问题。此外，TabMixer主干网络通过并行的多层感知器（MLP）分支来捕捉复杂的非线性关联，这些模块通过逐元素相加和平均池化相结合，使TabNSA能够同时建模全局语境和细粒度交互。实验结果显示，TabNSA在监督学习和迁移学习设置中的一致性表现优于现有最先进的深度学习模型。进一步地，通过与调优的大型语言模型（LLM）相结合，TabNSA能够有效解决少量样本学习挑战，通过语言指导泛化在多样化的表格基准上取得了良好的效果。", "conclusion": "本文提出的TabNSA框架通过综合利用原生稀疏注意模块和TabMixer主干网络，有效地解决了表格数据的建模难题，并通过语言指导泛化的调优大型语言模型进一步增强了其少样本学习能力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.13504", "html_url": "https://arxiv.org/abs/2503.13504", "title": "CoCMT: 通信高效跨模态转换器用于协同感知", "title_en": "CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception", "authors": "Rujia Wang,Xiangbo Gao,Hao Xiang,Runsheng Xu,Zhengzhong Tu", "background": "多智能体协同感知通过共享传感器信息来提升每个智能体的感知能力，以合作完成机器人感知任务。这种方法已成功解决传感器不足、遮挡和远距离感知等挑战。尽管如此，现有的协同感知系统在传输中间特征图（如鸟瞰图表示）时存在高通信带宽需求的问题，这些特征图包含了大量不必要的信息。因此，如何在保持感知能力的同时提高通信效率是亟待解决的问题。", "innovation": "本文引入了CoCMT(协同查询机器人多任务模型)，这是一种基于对象查询的合作框架，通过选择性地提取并传输关键特征来优化通信带宽。具体来说，文章提出了一种高效的查询变压器（EQFormer），用于有效融合多智能体的对象查询，并实施了一种协同深度监督，以增强各阶段之间的正向强化，从而提升整体性能。实验结果表明，CoCMT在OPV2V和V2V4Real数据集上均优于现有方法，同时极大地减少了通信需求。在V2V4Real数据集上，模型（使用Top-50对象查询）仅需0.416 Mb的带宽，比最先进的方法低83倍，同时AP70提高了1.1％，展示了通信效率的突破，即使在带宽受限的环境中也能实现实际的协同感知部署，而不牺牲检测准确性。", "conclusion": "本文通过引入CoCMT框架，在保持感知能力的同时大幅降低了通信需求，显著提高了通信效率。实验结果证明了CoCMT的有效性和优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12147", "html_url": "https://arxiv.org/abs/2505.12147", "title": "基于物联网的工程问题中的因果机器学习：家庭能源消耗案例中的工具比较", "title_en": "Causal Machine Learning in IoT-based Engineering Problems: A Tool Comparison in the Case of Household Energy Consumption", "authors": "Nikolaos-Lysias Kosioris,Sotirios Nikoletseas,Gavrilis Filios,Stefanos Panagiotou", "background": "计算能力的迅速增加和基础设施中存储大数据的能力使得机器学习能够在众多领域进行预测。然而，在许多情况下，现有的机器学习工具被认为不够充分或不准确，因为它们仅依赖概率依赖关系而忽视了推理逻辑。因果机器学习方法似乎解决了这个缺口。本研究对比了两种常用的基于因果机器学习方法的工具及其数学背景支撑，并通过分析18个查询的结果，基于爱丁堡大学发布的IDEAL家庭能源数据集，展示了这些工具的操作情况。首要的是评价了允许使用此方法的因果关系假设，这基于该领域的既有科学知识并通过内置验证工具实现。结果令人鼓舞，并可以轻松扩展到其他领域。", "innovation": "研究对比了两种因果机器学习方法的工具，并通过特定数据集展示了其操作。评估了因果关系假设，并展示了结果的可扩展性。", "conclusion": "研究结果表明，因果机器学习对于家庭能源消耗和其他领域的工程问题提供了良好的解决路径。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06722", "html_url": "https://arxiv.org/abs/2504.06722", "title": "可解释生成建模中的可塑张量网络", "title_en": "Plastic tensor networks for interpretable generative modeling", "authors": "Katsuya O. Akamatsu,Kenji Harada,Tsuyoshi Okubo,Naoki Kawashima", "background": "本文提出了用于单一非负自适应张量树（NATT）结构优化的方案，旨在替代生成模型中的生成器范式。NATT构建方式能够自动搜索适合给定离散数据集的最佳树结构，由于其能作为概率图形模型进行解读，因此有助于理解生成过程。本文还将NATT方案与最近提出的玻尔兹曼机自适应张量树（BMATT）优化方案进行了比较，探讨了它们在不同任务中的表现，以验证NATT方案的性能。", "innovation": "提出了用于单一非负自适应张量树（NATT）结构优化的方案，该方案在给定离散数据集上自动寻找最佳树结构，从而能够在解释概率图形模型方面表现出色。通过与BMATT优化方案进行对比，展示了NATT方案与BMATT方案在不同生成建模任务中的有效性，特别是在最小化负对数似然方面两者具有相当的性能，但NATT方案不是更优的解决方案。", "conclusion": "本文展示了NATT方案在结构优化方面的优点，尤其是在能够适应离散数据集并提供可解释性方面。通过讨论不同拓扑结构对模型性能的影响以及最小子信息量标准的应用，进一步强调了NATT生成模型的信息内容和可解释性的重要性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05250", "html_url": "https://arxiv.org/abs/2504.05250", "title": "PEAKS: 通过基于核相似性的预测误差选择关键训练示例", "title_en": "PEAKS: Selecting Key Training Examples Incrementally via Prediction Error Anchored by Kernel Similarity", "authors": "Mustafa Burak Gurbuz,Xingyu Zheng,Constantine Dovrolis", "background": "随着深度学习依赖于越来越大的数据集，理解哪些示例对于泛化最重要已成为一个关键问题。虽然在数据选择方面取得了进展，但新兴的应用场景需要在这种动态环境中研究这一问题。因此，需要一种新的方法来解决连续流式数据的选择问题，即在不访问完整数据源的情况下选择样本。在这种情况下，学习者需要逐步构建一个已定义大小的训练数据集，同时学习该任务的基础。研究表明，在增量数据选择中，新样本对模型状态的影响不仅取决于其在特征空间中的几何关系，还取决于其预测误差。本文基于此见解提出了PEAKS（预测误差锚定核相似性），这是一种针对增量数据选择问题高效的数据选择方法。", "innovation": "本文提出了PEAKS（Prediction Error Anchored by Kernel Similarity），这是一种高效的数据选择方法，专为增量数据选择问题设计。该方法通过结合预测误差和核相似性的机制进行数据选择，并且在大规模数据集上优于现有的选择策略，尤其是在训练数据量增加时，比随机选择获得了更好的性能回报。", "conclusion": "我们的综合评估表明，PEAKS在所有方面都优于现有的选择策略，并且随着训练数据规模的增加，其性能回报比随机选择更好。我们提供的证据强烈表明，PEAKS是一种有效的增量数据选择方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08811", "html_url": "https://arxiv.org/abs/2504.08811", "title": "跨场景泛化类比学习框架及在智能定位中的应用", "title_en": "Analogical Learning for Cross-Scenario Generalization: Framework and Application to Intelligent Localization", "authors": "Zirui Chen,Zhaoyang Zhang,Ziqing Xing,Ridong Li,Zhaohui Yang,Richeng Jin,Chongwen Huang,Yuzhi Yang,Mérouane Debbah", "background": "现有的学习模型在跨场景应用时往往表现较差，主要原因是数据的参考框架随着部署环境和设置的变化而不同。然而，尽管每个场景的数据有不同的参考框架，其生成一般遵循一些共同的物理规则。基于这一点理解，本文提出了一个名为类比学习（Analogical Learning, AL）的深度学习框架，该框架通过隐含地检索与场景相关的参考框架信息，并与其他场景进行相对类比来做出准确预测。", "innovation": "本文设计了一个双部神经网络，称为Mateformer。其第一部分捕获输入数据与研究场景中少量嵌入数据之间的多个潜在特征空间的相对关系，其第二部分使用这些相对关系来引导非线性类比。该框架被应用于蜂窝网络中的智能无线定位的典型多场景学习问题上，实验验证了AL在三个关键维度上的优越性，包括单场景基准准确度、不同场景之间的稳定迁移能力，以及对新型未知场景的鲁棒适应能力。", "conclusion": "AL框架在单场景基准测试中表现出最先进的精度，显示出在不同场景之间的稳定迁移能力，避免了灾难性遗忘，并且能够在包括动态天气和交通条件等新型未知场景中鲁棒适应，无需进行任何调整。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08904", "html_url": "https://arxiv.org/abs/2503.08904", "title": "循环燃料反应堆中浅层循环解码网络高效参数状态估计", "title_en": "Towards Efficient Parametric State Estimation in Circulating Fuel Reactors with Shallow Recurrent Decoder Networks", "authors": "Stefano Riva,Carolina Introini,J. Nathan Kutz,Antonio Cammi", "background": "数据驱动方法的最新发展为提供工程系统（如核反应堆）的精确状态重构开辟了新的方法。由于核反应堆涉及强耦合物理的复杂性和极端恶劣的环境，特别是在第四代反应堆（Gen-IV）中，使其成为特别具有挑战性的应用。数据驱动技术可以从不同类型的信息，包括计算代理模型和系统上的局部噪声测量，组合在一起，以稳健地估计状态。这项研究利用浅层递归解码器架构从三个离堆时间序列中推断出完整的状态向量（包括中子通量、前体浓度、温度、压力和流动速度），以适应参数时间序列数据的独特挑战，以保持调查不同事故场景的可能性，并展示这种方法在各种运行条件下提供精确状态估计的能力。研究以熔盐快堆（MSFR）为基础案例，该堆是一个Gen-IV反应堆概念，由于采用液体燃料，核物理与热流体特性之间存在强耦合。准确的实时状态重建使这种方法适用于反应堆数字孪生框架下的监测和控制用途，同时使其具备评估状态估计不确定性较低的训练成本所带来的潜在优势.", "innovation": "这项研究的关键创新在于利用浅层递归解码器网络从离堆的中子通量时间序列数据中推断出核反应堆的完整状态向量，包括中子通量、前体浓度、温度、压力和流动速度。此工作扩展了标准架构以处理参数时间序列数据，确保能够调查不同的事故场景，并展示这种方法在各种运行条件下的准确状态估计能力。同时，通过较低的训练成本量化了状态估计的不确定性，证明了其在实际应用中的潜力.", "conclusion": "研究证实了浅层递归解码器网络在循环燃料反应堆中状态估计的高效性，展示了其在监测和控制等实际应用中的潜力。精确的实时状态重构使这种方法适用于反应堆数字孪生框架下的监测和控制，同时还体现了其较低的训练成本和对状态估计不确定性的量化能力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02205", "html_url": "https://arxiv.org/abs/2506.02205", "title": "Bregman Centroid Guided Cross-Entropy Method", "title_en": "Bregman Centroid Guided Cross-Entropy Method", "authors": "Yuliang Gu,Hongpeng Cao,Marco Caccamo,Naira Hovakimyan", "background": "交叉熵方法（CEM）在基于模型的强化学习（MBRL）中被广泛应用，但其单一模态采样策略在多模态景观中容易导致过早收敛。因此，需要改进方法以提升优化效果和多样性控制能力，特别是在复杂环境下的性能表现和解决质量。", "innovation": "本文提出了一种名为$\\mathbf{\\mathcal{BC}}$-EvoCEM的增强型方法，该方法利用Bregman中位数对CEM集进行原则性信息聚合和多样性控制，通过在Bregman中位数附近的信任区域内采样来更新最少贡献的个体。该方法利用Bregman散度与指数家族分布之间的对偶性，无缝整合到标准的CEM流水线中，具有几乎忽略不计的开销。实验结果表明，$\\mathbf{\\mathcal{BC}}$-EvoCEM在合成基准测试、复杂导航任务和完整的MBRL流水线中均能提高收敛性和解的质量，提供了一个简单而有效的CEM升级方案。", "conclusion": "通过集成$\\mathbf{\\mathcal{BC}}$-EvoCEM，实验结果验证了该方法能增强CEM的收敛性和解的质量，为MBRL领域的优化提供了一种简单有效的改进方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18232", "html_url": "https://arxiv.org/abs/2505.18232", "title": "Two-Stage Regularization-Based Structured Pruning for LLMs", "title_en": "Two-Stage Regularization-Based Structured Pruning for LLMs", "authors": "Mingkuan Feng,Jinyang Wu,Siyuan Liu,Shuai Zhang,Ruihan Jin,Feihu Che,Pengpeng Shao,Zhengqi Wen,Jianhua Tao", "background": "大语言模型（LLM）的部署受到其大量参数的阻碍。结构化剪枝作为一项有前景的解决方案，之前的方法直接基于某些指标移除不重要的参数，这常常导致知识损失，并需要大量的重新训练。为了解决这个问题，我们提出了一个新的剪枝方法：TRSP（Two-Stage Regularization-Based Structured Pruning for LLMs）", "innovation": "TRSP 方法通过两阶段正则化来解决知识损失的问题。首先，通过初始可学习权重对每个变压器层的输出进行乘法操作，并通过在损失函数中添加其 $\text{\textit{l}}_1$-范数作为正则化项来学习这些权重，作为第一阶段的正则化。其次，通过在输出和输入之间权重较小的层进行额外正则化，促进知识转移至保留的层，作为第二阶段的正则化。这种方法保留了更多的知识，并且在不需要重新训练的情况下，比直接的参数消除方法更好地保持了模型性能。TRSP 提出的解决方案能够在不需重新训练的情况下，超越了强层间结构化剪枝方法，并且通过逐层剪枝的方式提供了显著的端到端加速，是 LLM 部署的一个有前景的解决方案", "conclusion": "通过广泛的实验表明，TRSP 在不需要重新训练的情况下，超越了强层间结构化剪枝方法，并且提供了显著的端到端加速，为高效部署 LLM 提供了一个有前景的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20485", "html_url": "https://arxiv.org/abs/2505.20485", "title": "在非同态数据下通过保留全局知识梯度来避免联邦学习中的遗忘", "title_en": "Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data", "authors": "Abhijit Chunduru,Majid Morafah,Mahdi Morafah,Vishnu Pandi Chellapandi,Ang Li", "background": "联邦学习面临的挑战之一是数据异质性问题，现有方法虽然有效，但缺乏对数据异质性如何影响全局决策边界的深刻理解。本文通过玩具示例的实验分析填补了这一空白，揭示了现有方法存在着遗忘全局决策边界的问题，即使从预训练的最佳权重开始也是如此。", "innovation": "本文提出了FedProj，这是一种联邦学习框架，能够稳健地学习全局决策边界并在本地训练过程中避免遗忘。它设计了新颖的服务器端集成知识传递损失，进一步校准所学的全局决策边界，并提出了利用公共未标记数据集上的平均集成逻辑节点的阶段性记忆来调节每个训练步骤中的梯度更新，以此缓解全局决策边界遗忘的问题。", "conclusion": "实验结果表明，FedProj在非同态数据下的联邦学习中显著优于现有的最新方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12514", "html_url": "https://arxiv.org/abs/2505.12514", "title": "叠加推理：连续思维链的理论视角", "title_en": "Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought", "authors": "Hanlin Zhu,Shibo Hao,Zhiting Hu,Jiantao Jiao,Stuart Russell,Yuandong Tian", "background": "大型语言模型（LLMs）在许多应用中表现出色，尤其是通过链条思维（CoTs）技术解决复杂的推理问题，CoTs技术生成“思考令牌”后再回答问题。现有理论工作证明了带有离散令牌的链条思维增强了LLMs的能力，但连续链条思维（连续CoTs）在某些推理任务中超过了离散版本，特别是涉及有向图可达性问题的任务，但在这一领域缺乏理论解释。", "innovation": "本文证明了一个带有两层变换器和$D$步连续链条思维的模型能够解决有向图可达性问题，其中$D$是图的直径，而最佳已知结果的常深度变换器则需要$O(n^2)$解码步骤，这里$n$是节点数（$D<n$）。在我们的结构中，每个连续思维向量是一个叠加态，同时编码多个探索前沿（并行广度优先搜索BFS），而离散链条思维则必须从叠加态中选择一条路径，导致顺序搜索需要更多步骤且容易陷入局部最优解。此外，我们进行了大量实验验证，发现我们理论中的构建与通过训练动态获得的实证解决方案吻合得很好，而且同时编码多个搜索前沿作为叠加态在训练连续链条思维中自然出现，无需显式的监督来引导模型同时探索多条路径。", "conclusion": "通过证明带有连续链条思维的模型解决了有向图可达性问题，本文提供了一个理论上的理解，解释了连续链条思维为何在某些推理任务中优于离散版本，并展示了训练过程中自然出现了多路径探索的现象。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23800", "html_url": "https://arxiv.org/abs/2506.23800", "title": "深入预测编码神经网络的训练", "title_en": "Towards the Training of Deeper Predictive Coding Neural Networks", "authors": "Chang Qi,Matteo Forasassi,Thomas Lukasiewicz,Tommaso Salvatori", "background": "预测编码网络通过迭代的能量最小化过程进行推断，此前研究表明在浅层架构中这些网络具有较好的效果，但当层数超过五到七层时，其性能会显著下降。", "innovation": "研究发现深层结构性能下降的原因是层间能量分配失衡和深层前一层的预测指导作用不明显。为了应对这些问题，研究引入了两种优化方法来平衡能量分布，并提出了新的权重更新机制以减少深层错误积累。", "conclusion": "实验结果表明，这些方法在深层网络中的测试准确性有了显著提高，性能与相似模型的反向传播相当。这表明，在使用平衡传播训练模型时深入了解放松阶段是重要的，并为复杂任务中的应用开辟了新的可能性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23544", "html_url": "https://arxiv.org/abs/2506.23544", "title": "使用不断增加批次大小的准双曲动量的渐近和非渐近收敛性", "title_en": "Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size", "authors": "Kento Imaizumi,Hideaki Iiduka", "background": "动量方法最初在确定性凸目标函数设置中被引入，显示出比随机梯度下降（SGD）的优势。尽管动量方法在深度神经网络中广泛应用，而深度神经网络是一种典型的随机非凸优化情况，但在这些情况下的理论合理化仍然有限。准双曲动量（QHM）是动量方法中的一种算法，它推广了各种动量方法，用于更好地理解动量为基础算法的总体类别。本研究提供了mini-batch QHM在批次大小增加时的渐近和非渐近收敛结果。研究显示，实现渐近收敛需要学习率逐渐减小或批次大小逐渐增加。鉴于学习率递减对非渐近收敛的影响，作者证明了使用mini-batch QHM并保持学习率不变但不断增加批次大小的效果更佳。实验验证了即使相对较小的批次大小增加也能对神经网络训练带来益处。", "innovation": "本文提供了mini-batch QHM在增加批次大小的情况下渐近和非渐近收敛的结果，发现只有不断增加批次大小而不会降低学习率，可以提高算法效果，从而为动量方法的有效性提供了理论支撑，特别在非凸优化场景下。", "conclusion": "实验结果表明，即使增加较小的批次大小也能为神经网络训练带来益处。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15709", "html_url": "https://arxiv.org/abs/2506.15709", "title": "研究和改进基于图神经网络的图模式估计", "title_en": "Studying and Improving Graph Neural Network-based Motif Estimation", "authors": "Pedro C. Vieira,Miguel E. P. Silva,Pedro Manuel Pinto Ribeiro", "background": "图神经网络（GNNs）是图表示学习的主要方法。尽管它们在子图频率估计方面得到了广泛应用，但在网络模式显著性概型（SP）预测方面仍被忽视，且文献中没有建立标准基准。本文旨在解决此问题，将SP估计任务与子图频率估计分离，并将问题转化为多目标回归，以提高可解释性、稳定性和大规模图形处理的能力。", "innovation": "本文将SP估计任务与子图频率估计分离，并将其转化为多目标回归问题。这种方法优化了对大规模图的可解释性、稳定性和扩展性。此外，研究结果揭示了1-WL模型在精确SP估计方面的局限性，但它们可以通过预测的SP与合成生成器产生的SP进行对比，来一般化地逼近网络的生成过程。", "conclusion": "在大规模合成数据集上验证了该方法，并进一步在真实世界图上进行了测试。实验结果表明1-WL限制模型在精确估计SP方面存在困难，但可以通过预测的SP与合成生成器产生的SP进行对比，来近似地捕捉到网络的生成过程。这一基于GNN的模式估计研究还暗示了直接使用SP估计可以帮助克服通过子图计数进行模式估计时面临的理论限制。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12036", "html_url": "https://arxiv.org/abs/2506.12036", "title": "一种针对文本到图像扩散模型的极简微调方法", "title_en": "A Minimalist Method for Fine-tuning Text-to-Image Diffusion Models", "authors": "Yanting Miao,William Loh,Pacal Poupart,Suraj Kothawade", "background": "最近的研究利用强化学习（RL）来微调文本到图像的扩散模型，旨在提高文本与图像的一致性和样本质量。然而，现有的方法过于复杂：有的需要缓存整个采样轨迹，有的依赖可微奖励模型或大规模偏好数据集，还有的需要特殊引导技术。这些复杂性增加了实现难度和计算负担，限制了模型的实际应用效果和易用性。背景信息强调了简化和实用性在微调扩散模型中的重要性。", "innovation": "受‘金色噪声’假说启发，即某些初始噪声样本可以稳定地获得更优的一致性，该论文提出了Noise PPO——一种极简的RL算法，完全冻结预训练的扩散模型，学习基于提示的初始噪声生成器。该方法无需记录采样轨迹、奖励反向传播或复杂的引导技巧，简化了实现过程，增强了算法的易用性和效率。", "conclusion": "实验结果表明，优化初始噪声分布能够持续提升模型的一致性和样本质量。尽管随着推理步骤的增加，噪声优化的收益趋于减弱，但仍然保持提升效果。研究成果澄清了‘金色噪声’假说的范围和限制，并强化了极简RL微调在扩散模型中的实际价值。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21997", "html_url": "https://arxiv.org/abs/2506.21997", "title": "Binned semiparametric Bayesian networks", "title_en": "Binned semiparametric Bayesian networks", "authors": "Rafael Sojo,Javier Díaz-Rozo,Concha Bielza,Pedro Larrañaga", "background": "本文介绍了一种新的概率半参数模型，该模型利用数据分箱以减少核密度估计在非参数分布中的计算成本。该文提出了两种新的条件概率分布，并通过稀疏张量和限定条件概率计算中的父节点数量来解决数据维度上的计算挑战。通过对合成数据和UCI机器学习资源中的数据集进行复杂性分析和实验测试来验证该模型的效果，并通过不同的分箱规则、父节点限制、网格大小和实例数量来全面了解模型的行为。", "innovation": "本文创新地引入了新的半参数贝叶斯网络，通过数据分箱减少了核密度估计的计算成本。开发了两种新的条件概率分布：稀疏分箱核密度估计和傅里叶核密度估计。这些分布通过使用稀疏张量和限制条件概率计算中的父节点数量来解决维度灾难问题。", "conclusion": "经过复杂性分析和对比实验，本文提出的分箱半参数贝叶斯网络在结构学习和对数似然估计方面与非分箱半参数贝叶斯网络没有统计学意义上的显著差异，但在速度上更快。因此，新的分箱半参数贝叶斯网络证实了其较非分箱版本更为可靠且更高效的替代方案。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01208", "html_url": "https://arxiv.org/abs/2506.01208", "title": "动态网络上的多分辨率分析与统计阈值", "title_en": "Multiresolution Analysis and Statistical Thresholding on Dynamic Networks", "authors": "Raphaël Romero,Tijl De Bie,Nick Heard,Alexander Modell", "background": "动态网络数据结构变化的检测在广泛的应用领域中具有重要意义。现有方法通常将数据划分为时间间隔，提取每个间隔内的网络特征，然后比较这些特征随时间的变化。这种方法引入了时间分辨率与特征统计稳定性的固有折衷。尽管存在这种折衷，大多数方法仍然依赖于固定的时程分辨率。对于网络结构可能在不同时间尺度上发生变化的领域，如网络安全，选择合适的分辨率参数通常非常困难且具有挑战性。", "innovation": "本文提出了一种多分辨率框架ANIE（Adaptive Network Intensity Estimation），旨在自动识别网络结构演化的时间尺度，使研究人员能够同时检测快速和渐变的变化。通过将相互作用建模为泊松过程，ANIE方法分为两步进行：（1）估计节点行为的低维子空间，（2）推导出一组新颖的经验亲和系数，量化潜在因素之间的交互强度变化，并支持跨时间尺度的结构变化统计测试。理论保证了子空间估计和亲和系数的渐近行为，使ANIE方法能够进行基于模型的变化检测。", "conclusion": "实验表明，ANIE能够适应适当的时程分辨率，能够捕捉到尖锐的结构变化，同时保持对噪声的鲁棒性。进一步的应用于真实世界数据展示了ANIE多分辨率方法在检测结构变化方面的实践优势，超越了固定分辨率方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14810", "html_url": "https://arxiv.org/abs/2506.14810", "title": "智能路由在稀疏需求预测中的应用：选择策略的比较评估", "title_en": "Intelligent Routing for Sparse Demand Forecasting: A Comparative Evaluation of Selection Strategies", "authors": "Qiwen Zhang", "background": "供应链中的稀疏和间歇性需求预测构成了一个重大挑战，频繁的零需求时期影响了传统模型的准确性，进而影响库存管理。针对这一挑战，本研究旨在通过动态选择最适合每个产品需求模式的经典、机器学习（ML）和深度学习（DL）方法，提出并评估一种名为Model-Router的框架。该框架通过对比基于规则、LightGBM和InceptionTime的路由策略，使模型能够学习适应不同类型的需求模式，从而优化预测效果。实验结果表明，基于Inception Time的深度学习路由器能够比单模型基准提高高达11.8%（NWRMSLE）的预测准确率，并且具有4.67倍更快的推理时间。", "innovation": "提出了一个名为Model-Router的动态选择框架，可以根据每个产品的独特需求模式选择最适合的经典、机器学习和深度学习方法。通过对比三种不同的路由策略（基于规则、LightGBM和InceptionTime），该框架能够学习和适应各种平滑、周期性和间歇性需求模式，从而优化预测结果。实验验证了基于深度学习的Inception Time路由器相较于单一的强预测模型，在提高预测准确性的同时大幅减少了推理时间。", "conclusion": "这些预测精度的提升将显著降低缺货和浪费性库存，突显了智能、自适应人工智能在优化现代供应链运营中的关键作用。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13759", "html_url": "https://arxiv.org/abs/2506.13759", "title": "离散扩散在大规模语言和多模态模型中的应用：综述", "title_en": "Discrete Diffusion in Large Language and Multimodal Models: A Survey", "authors": "Runpeng Yu,Qi Li,Xinchao Wang", "background": "该论文回顾了离散扩散语言模型（dLLMs）和离散扩散多模态语言模型（dMLLMs）的系统性研究，指出与自回归（AR）模型不同，dLLMs和dMLLMs采用多令牌并行解码模式，依赖全注意力和去噪生成策略。这一模式天然地支持并行生成、细粒度输出可控性和动态、响应感知。这些能力在AR模型中难以实现。近年来，随着越来越多的工业规模的d(M)LLMs和大量开源的d(M)LLMs展现出与自回归对应模型相当的性能，同时比前者快10倍的推理速度，离散扩散LLMs和MLLMs的研究取得了显著进展。进展主要归功于自回归LLMs和MLLMs的发展，积累了大量的数据、基准和训练推理基础架构，以及数学上基于离散扩散模型的进步。自2025年初开始，这些突破推动了dLLMs和dMLLMs领域研究的快速增长。", "innovation": "dLLMs和dMLLMs模型采用并行解码和全注意力机制，从而实现并行生成、细粒度输出控制和响应感知动态。这一新的生成策略显著提高了模型的效率，尤其是在推理速度方面，比传统的自回归模型快10倍。此外，由于基于自回归大型语言和多模态模型的发展和数学模型的进步，dLLMs和dMLLMs领域取得了显著进展并逐渐超越了传统的模型。", "conclusion": "本文为dLLMs和dMLLMs领域提供了全面概述，回顾了其历史发展，总结了关键技术及其应用，并探讨了未来研究和部署的方向。作者认为，进一步的研究应探索这些模型在语言处理、视觉-语言处理以及生物学领域的更多应用潜力，同时需要优化模型以提高其传输效率和通用性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.24124", "html_url": "https://arxiv.org/abs/2506.24124", "title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "title_en": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "authors": "Sixun Dong,Wei Fan,Teresa Wu,Yanjie Fu", "background": "时间序列预测传统上依赖单一的数字输入，而这些输入往往难以捕捉到高层次的语义模式，因为它们是密集且无结构的。虽然最近的研究探索了使用大型语言模型（LLMs）将时间序列表示为文本的方法，但这些方法受限于标记序列的离散性质，缺乏人类通常应用的感知直觉，如解读视觉模式。本文探讨了如何将原始时间序列转换为视觉和文本的结构化视角，以捕获更丰富的表示。", "innovation": "本文提出了一种多模态对比学习框架，可以直接从数值序列构建视觉和文本模态，并通过对比学习对齐这些视角，从而使模型能够捕获更加丰富且互补的表示。此外，本文引入了一个变体选择模块，利用对齐的表示来识别多元预测中最重要变量。广泛的实验表明，本文方法在多种短期和长期预测基准中均优于强大的单模态和跨模态基线，突显了多模态对齐在时间序列预测中的效果。", "conclusion": "本文的方法在十五个短期和六个长期预测基准中均展示了超越单模态和跨模态基线的有效性，突出了多模态对齐在时间序列预测中的增效作用，并公开了相关代码。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19955", "html_url": "https://arxiv.org/abs/2505.19955", "title": "MLR-Bench: 评估AI代理在开放性机器学习研究中的表现", "title_en": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": "Hui Chen,Miao Xiong,Yujie Lu,Wei Han,Ailin Deng,Yufei He,Jiaying Wu,Yibo Li,Yue Liu,Bryan Hooi", "background": "近年来，人工智能代理展示了其在推动和支持科学发现方面不断增长的潜力。现有的研究需要一个全面的基准来评估这些代理在开放性机器学习研究中的表现。因此，本研究引入了MLR-Bench，这是一个针对AI代理的全面基准测试框架，旨在评估它们在多样的机器学习研究任务上的表现，涵盖多个领域的研究课题，并通过一个自动化评估框架MLR-Judge将这些评估标准化。", "innovation": "MLR-Bench 由三个核心组件组成：(1) 源自 NeurIPS, ICLR, 和 ICML 工作坊的 201 个研究任务，(2) 综合基于大语言模型（LLM）的评审员和精心设计的评审标准的自动评估框架 MLR-Judge，(3) 包含四个阶段（想法生成、提案制定、实验和论文撰写）的研究任务自动完成剂 MLR-Agent。该框架不仅能够阶段性评估不同的研究阶段，还支持对最终研究论文进行端到端的评估。研究人员利用 MLR-Bench 对六种前沿的大语言模型和一个先进的编程代理进行了评估，结果表明，尽管大语言模型在生成连贯的想法和结构化的论文方面效果显著，但当前的编程代理经常会生成虚假或无效的实验结果，这对科学研究的可靠性构成了严重障碍。作者还验证了 MLR-Judge 的有效性，并提供了开源软件 MLR-Bench，以促进该领域的进一步研究和应用。", "conclusion": "研究使用 MLR-Bench 评估了几种高级 AI 研究代理，揭示了大语言模型在生成连贯想法和结构化论文方面的有效性，但当前编程代理在生成无效实验结果方面存在很大问题，这对科学研究的可靠性构成了威胁。评估框架 MLR-Judge 通过人工评估显示了高一致性，有助于可靠地评估研究表现。开源 MLR-Bench 将帮助社区对 AI 研究代理进行基准测试、诊断和改进，以达到可靠和透明的科学发现目标。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.03302", "html_url": "https://arxiv.org/abs/2401.03302", "title": "实证行动：利用YOLOv8和DeiT进行医学影像中脑肿瘤的 anomaly-aware 诊断", "title_en": "Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT", "authors": "Seyed Mohammad Hossein Hashemi,Leila Safari,Mohsen Hooshmand,Amirhossein Dadashzadeh Taromi", "background": "脑肿瘤的可靠诊断因临床病例低发生率而具有挑战性。现有方法忽视了这个低发生率，未充分关注异常检测和分类中的鲁棒性问题。", "innovation": "提出了一种基于临床灵感的异常鲁棒性脑肿瘤检测和分类框架。框架包括使用YOLOv8n进行异常检测，该模型经过现实不平衡数据集（肿瘤:正常比1:9，30,000个MRI切片来自81名患者）的微调；并提出了一种新的病人到病人(PTP)指标来评估诊断的可靠性。分类部分采用基于知识蒸馏的数据效率图像变压器(DeiT)学生模型从ResNet152教师模型训练而来，显著减少了计算资源消耗。该端到端框架在临床上代表性的异常分布数据中表现出高鲁棒性，提供了一种适应临床现实情况的有效工具。", "conclusion": "该端到端框架在临床代表性的异常分布数据中展示了高鲁棒性，提供了一种适应临床现实情况的有效工具，DeiT学生模型在20个周期内达到0.92的F1分数，接近教师模型的0.97性能，同时显著减少了计算资源需求。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.09511", "html_url": "https://arxiv.org/abs/2311.09511", "title": "使用共变自回归储层计算机识别具有对称性的系统", "title_en": "Identifying Systems with Symmetries using Equivariant Autoregressive Reservoir Computers", "authors": "Fredy Vides,Idelfonso B. R. Nogueira,Gabriela Lopez Gutierrez,Lendy Banegas,Evelyn Flores", "background": "该研究旨在通过共变自回归储层计算机识别具有对称性的系统。首先，通过全面的非线性时间延迟嵌入分析，研究了共变系统的时间序列数据。其次，采用了稀疏最小二乘方法来识别输出耦合矩阵的近似表示。这些矩阵在确定共变系统的自回归非线性表示中起着关键作用。系统的结构特性由系统内在的对称性决定。文档概述了从描述技术中派生出的典型算法，提供了这些技术在实际应用中的见解。与传统的储层计算方法相比，这种方法在模拟共变动力系统时表现出显著的结构身份精度提升。", "innovation": "该研究采用了一种两步方法：首先，通过广泛的非线性时间延迟嵌入分析，研究了共变系统的时间序列数据；其次，使用稀疏最小二乘方法来识别输出耦合矩阵的近似表示。这种方法在模拟共变动力系统时表现出显著的结构身份精度提升。", "conclusion": "文档概述了从描述技术中派生出的典型算法，提供了这些技术在实际应用中的见解。与传统的储层计算方法相比，这种方法在模拟共变动力系统时表现出显著的结构身份精度提升。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.04370", "html_url": "https://arxiv.org/abs/2406.04370", "title": "通过黑盒访问评估大型语言模型的信任度", "title_en": "Large Language Model Confidence Estimation via Black-Box Access", "authors": "Tejaswini Pedapati,Amit Dhurandhar,Soumya Ghosh,Soham Dan,Prasanna Sattigeri", "background": "对模型响应的不确定性或信心进行估计对于评估模型的整体信任度至关重要。因此，本文针对通过简单黑盒或查询访问大型语言模型（LLMs）来估计响应的信心进行研究。提出了一种简单且可扩展的框架，通过工程化新颖特征并利用这些特征训练一个可解释的模型（如逻辑回归模型）来估计信心。", "innovation": "本文提出了一种新颖的方法，通过工程化特征并利用逻辑回归模型来评估大型语言模型的自信度，并通过实验证明该简单框架在多个基准任务上能够有效估计信心，甚至在某些情况下超过基线方法超过10%（AUC-ROC）。此外，该可解释方法揭示了哪些特征能预测信心，发现构建于一个LLM的信心模型可以在其他LLM上零样本泛化。", "conclusion": "本研究提出了一种简单且有效的框架，通过对大型语言模型的黑盒访问和特征工程，利用逻辑回归模型来估计模型的响应信心，并在多个基准任务上进行了验证，表现出色。此外，该方法还揭示了可解释的特征，对于理解和改进大模型的信任度评估具有重要价值。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.16553", "html_url": "https://arxiv.org/abs/2408.16553", "title": "沿海模拟的下尺度神经网络", "title_en": "Downscaling Neural Network for Coastal Simulations", "authors": "Zhi-Song Liu,Markus Buttner,Vadym Aizinger,Andreas Rupp", "background": "在现实世界的应用中，高分辨率模拟对于理解许多海岸过程是必需的，尤其是预测由海啸和风暴潮引发的洪水。然而，从粗略的表示中学习沿海海洋模拟的精细细节是一项具有挑战性的任务。为了提高对这些过程的理解，研究人员需要利用高分辨率模拟。本文探讨了利用神经网络进行时空增强的方法，以提高模拟结果的分辨率和准确性，尤其是在时间变化和空间变化方面。", "innovation": "本文提出了一种名为DNNCS（Downscaling Neural Network for Coastal Simulation）的下尺度神经网络，该网络能够通过低分辨率的模拟结果生成高分辨率的海面高度和流速可视化。该网络使用网格意识时空注意机制，将时间特征投影到空间域以进行非局部特征匹配，同时利用位置编码来利用坐标信息。此外，它使用时空双线性操作进行帧插值，并将特征图扩展到频域以进行残差映射。为了确保梯度一致性和动量变化，还提出了物理导向损失。这些技术共同提高了方法的准确性和计算效率，相比现有方法有显着改进。", "conclusion": "本文通过提出一个新颖的沿海模拟数据集，成功优化并评估了DNNCS模型，并证明了其在下尺度质量和快速计算方面的优越性，相较于当前最佳方法提高了24%的RMSE性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.16594", "html_url": "https://arxiv.org/abs/2405.16594", "title": "训练条件下特征转移情况下的覆盖率界限", "title_en": "Training-Conditional Coverage Bounds under Covariate Shift", "authors": "Mehrdad Pournaderi,Yu Xiang", "background": "近期，一致预测方法被扩展应用到特征转移的场景中。在这些场景下，训练数据和测试数据中的特征分布差异显著。虽然现有的结果保证这些方法生成的预测集的边际覆盖率达到名义水平之上，但它们在训练数据集条件下的覆盖率（称为训练条件下的覆盖率）尚未得到研究。因此，本文将在这种条件下推导训练条件下的覆盖率上限，提供这些方法的可能接近正确性（PAC）保证，探讨预测集的质量与数据分布变化严重程度之间的关系，并可用于计算更有效的预测集。", "innovation": "本文推导了训练条件下工具的覆盖率上限，提供了更严格的PAC保证，有助于计算更有效的预测集，并量化了预测集质量与数据分布变化之间的关系。这一创新弥补了现有研究中训练条件覆盖率研究的空白。", "conclusion": "研究成果提供了关于预测集的质量与数据分布变化之间关系的量化指标，有助于提高预测集的效率，并提出了有效计算预测集的可能性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.01868", "html_url": "https://arxiv.org/abs/2408.01868", "title": "Meta-Posterior Consistency for the Bayesian Inference of Metastable System", "title_en": "Meta-Posterior Consistency for the Bayesian Inference of Metastable System", "authors": "Zachary P Adams,Sayan Mukherjee", "background": "大多数关于从时间序列学习动力系统或随机过程的研究集中在稳定或遍历系统上，无论是贝叶斯推断还是频率主义推断。然而，大多数现实世界中的系统实际上是亚稳态的，即这些动力学系统在某些时间尺度上表现为稳定，但在更长的时间尺度上实际上是不稳定的。对于亚稳态系统的一致性推断可能不可行，但是可以考虑元一致性：当观测是在一个大但有限的时间间隔上时，推断程序是否会收敛而在更长的时间尺度上则会发散？", "innovation": "本文在贝叶斯框架中引入、讨论并量化了亚稳态系统的元一致性。此外，探讨了亚稳态系统中元一致性与模型动力学系统光谱特性之间的关系，特别是在均匀遍历和非遍历扩散的情况下。", "conclusion": "本文讨论了如何利用亚稳态系统中的元一致性有效地推断子系统模型，特别是在全局行为推断需要更多数据或无法保证推断程序的渐近成功时的情况。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.04775", "html_url": "https://arxiv.org/abs/2411.04775", "title": "从数据学习动力系统：基于梯度的字典优化", "title_en": "Learning dynamical systems from data: Gradient-based dictionary optimization", "authors": "Mohammad Tabish,Neil K. Chada,Stefan Klus", "background": "库普曼算子在分析动力系统全局行为方面起着重要作用。现有的数据驱动方法用于近似库普曼算子或发现底层系统的动力学方程通常需要一组固定的基函数，也称为字典。基函数的选择高度依赖于具体的问题，并且通常需要领域知识来确定最优选择。", "innovation": "本文提出了一种基于梯度下降的优化框架，用于从数据中学习合适的且可解释的基函数，并展示如何将其与EDMD、SINDy和PDE-FIND相结合。通过基准问题的例子，如Ornstein-Uhlenbeck过程、Chua电路、非线性热方程和蛋白质折叠数据，证明了所提方法的有效性。", "conclusion": "通过梯度下降优化从数据中学习基函数的新框架，不仅提高了模型的可解释性，还能够在各种动力学系统中提供更好的性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05255", "html_url": "https://arxiv.org/abs/2410.05255", "title": "通过自我采样偏好优化将SFT与DPO结合用于扩散模型对齐", "title_en": "Bridging SFT and DPO for Diffusion Model Alignment with Self-Sampling Preference Optimization", "authors": "Daoan Zhang,Guangchen Lan,Dong-Jun Han,Wenlin Yao,Xiaoman Pan,Hongming Zhang,Mingxiao Li,Pengcheng Chen,Yu Dong,Christopher Brinton,Jiebo Luo", "background": "现有的后训练技术通常被分为监督微调（SFT）和强化学习（RL）方法；SFT在训练过程中稳定但泛化能力有限，而RL尽管具有更强的泛化能力，但需要额外的偏好数据或奖励模型，并存在奖励利用的风险。", "innovation": "本文提出了一种新的对齐方法——自我采样偏好优化（SSPO），该方法结合了SFT和RL的优点，避免了配对数据和奖励模型的需求，同时保持SFT的训练稳定性并保留了RL的泛化能力。SSPO引入了随机检查点重放（RCR）策略和自我采样正则化（SSR）策略，前者利用历史检查点构建配对数据以有效减轻过拟合，后者动态评估生成样本的质量，并在生成样本更可能成为胜者样本时自动切换到DPO或SFT，确保训练过程准确反映样本的质量。", "conclusion": "实验结果表明，SSPO不仅在文本到图像基准测试中优于现有方法，在文本到视频任务中也表现出色。SSPO在文本到图像基准测试中超越所有先前的方法，在文本到视频基准测试中表现出色。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.15643", "html_url": "https://arxiv.org/abs/2405.15643", "title": "无限维线性反问题中条件分数的无条件表示", "title_en": "An Unconditional Representation of the Conditional Score in Infinite-Dimensional Linear Inverse Problems", "authors": "Fabian Schneider,Duc-Lam Duong,Matti Lassas,Maarten V. de Hoop,Tapio Helin", "background": "Score-based扩散模型(SDMs)在贝叶斯反问题中的后验分布抽样方面表现出强大的工具作用。然而，现有的方法通常需要多次评估前向映射以生成单个样本，对于大规模反问题而言，这会导致显著的计算成本。", "innovation": "提出了一种针对线性反问题的条件分数的无条件表示(UCoS)，通过将计算努力转移到离线训练阶段来避免在采样过程中评估前向模型，展现出了强大的优势。关键在于展示了从一个训练好的无条件分数通过仿射变换精确地推导出条件分数的可能性，消除了条件分数的近似需要。同时，该方法是在无限维函数空间中制定的，使其具备无离散化依赖的特性，并通过严谨的收敛性分析支持这种表述，验证了UCoS在高维计算机断层扫描(CT)和图像去模糊实验中的可扩展性与准确性。", "conclusion": "通过离线学习与前向算子相关的任务依赖分数函数，并利用仿射变换直接从无条件分数中推导条件分数，证明了UCoS在无限维线性反问题中的适用性和优越性，并通过高维CT和图像去模糊实验验证了其可扩展性和准确性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.04814", "html_url": "https://arxiv.org/abs/2406.04814", "title": "从单一视频流中实现视频扩散模型的终身学习", "title_en": "Lifelong Learning of Video Diffusion Models From a Single Video Stream", "authors": "Jason Yoo,Yingchen He,Saeid Naderiparizi,Dylan Green,Gido M. van de Ven,Geoff Pleiss,Frank Wood", "background": "该研究背景在于，当前的视频扩散模型大多需要大量离线数据进行训练，而如何从单一视频流中训练此类模型并达到与离线训练相当的效果是一个挑战。此外，现有的视频扩散模型训练和评估数据集通常不具备终身学习的能力，即数据收集和使用过程中能够持续学习和适应新环境的能力。", "innovation": "该研究创新之处在于：1) 提出了从单一视频流训练自回归视频扩散模型的可能性，且其效果与标准离线训练相当；2) 发现通过经验回放方法，仅保留一部分先前视频流即可实现上述主要结果；3) 开发了四个新的终身生成视频模型数据集用于支持这种训练和评估方式，分别是终身弹球、终身3D迷宫、终身驾驶和终身PLAICraft，每个数据集包含复杂度逐渐增加环境的一百万连续帧。", "conclusion": "研究证明了从单一视频流训练视频扩散模型的可行性及其与标准离线训练相当的效果。通过经验回放缓存方法，可以在有限的存储资源下实现有效训练。此外，研究还提供了四种新的终身学习数据集，促进了类似技术的进一步研究和应用。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.04946", "html_url": "https://arxiv.org/abs/2411.04946", "title": "SPGD: Steepest Perturbed Gradient Descent Optimization", "title_en": "SPGD: Steepest Perturbed Gradient Descent Optimization", "authors": "Amir M. Vahedi,Horea T. Ilies", "background": "优化算法在多个科学和工业领域中起着关键作用，但常常遇到障碍，如陷入局部极小值、鞍点和平坦区域，这使收敛到合理的或接近最优解变得尤为困难。", "innovation": "提出了Steepest Perturbed Gradient Descent (SPGD)算法，该算法创新性地结合了梯度下降法与周期性均匀扰动采样的原则，有效绕过了上述障碍，提高了获得更好解的可能性。SPGD通过生成一组候选解并选择与当前解相比有最大损失差值的方案，增强了传统梯度下降方法，整合了战略性探索机制，显著提高了从次优局部极小值中逃逸并有效导航复杂优化场景的可能性。", "conclusion": "SPGD在解决3D组件打包问题等NP难问题中表现出色，比四种现有方法在复杂地形响应面和多维非凸连续优化问题中取得了显著改善。与其他基于2D基准函数的现有方法相比，SPGD显示出卓越的性能，证明了其在复杂优化场景中的探索能力。结果表明，SPGD具有广泛应用于各种优化问题的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.19906", "html_url": "https://arxiv.org/abs/2411.19906", "title": "基于图的经典和量子方法确定性L-系统反推", "title_en": "A Graph-Based Classical and Quantum Approach to Deterministic L-System Inference", "authors": "Ali Lotfi,Ian McQuillan,Steven Rayan", "background": "L-系统能够模拟并创建许多生物过程，如植物发育的仿真模型。为给定过程选择L-系统通常由专家手工完成，过程耗时巨大。若能够从数据（如图像序列）中自动推导L-系统，将具有重要意义。本文关注从字符串序列中推导确定性上下文无关L-系统（D0L-系统）的问题。为此引入了字符串序列的特征图，将问题转换为多项式时间的最大独立集问题和SAT问题，提出了经典精确算法和近似量子算法来解决该问题。", "innovation": "提出使用字符串序列的特征图将确定性L-系统反推问题转换为多项式时间的两个显著问题：最大独立集问题和SAT问题。同时提出了经典精确算法和近似量子算法来解决该问题，这对于自动化生成L-系统具有重要意义。", "conclusion": "本文成功地将确定性L-系统反推问题通过特征图转换为多项式时间的两个经典计算问题，并提出了相应的算法，展示了经典和量子计算在这类问题上的应用潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.13536", "html_url": "https://arxiv.org/abs/2411.13536", "title": "使用多视角评分精炼的保身份3D头部风格化", "title_en": "Identity Preserving 3D Head Stylization with Multiview Score Distillation", "authors": "Bahri Batuhan Bilecen,Ahmet Berke Gokmen,Furkan Guzelant,Aysegul Dundar", "background": "3D头部风格化技术将现实面部特征转化为艺术表现形式，增强了游戏和虚拟现实应用中的用户参与度。尽管3D感知生成器取得了显著进步，但许多3D风格化方法主要提供近正面视角，难以保留原始主体的独特身份，导致输出缺乏多样性和个性化。", "innovation": "本文通过利用PanoHead模型，从全方位视角合成图像，提出了一种新颖框架，利用负对数似然精炼（LD）增强身份保留并提高风格化质量。框架中整合了多视角网格评分和镜像梯度，并引入了评分排名加权技术，从而在定性和定量上实现了显著的改进。", "conclusion": "我们的研究成果不仅推动了3D头部风格化的技术进步，还为在扩散模型与生成对抗网络（GANs）之间有效精炼过程提供了宝贵见解，特别是针对身份保留的关键问题。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.16776", "html_url": "https://arxiv.org/abs/2401.16776", "title": "利用嵌套多级蒙特卡洛方法改进不可解析似然的序列神经后验估计", "title_en": "Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods", "authors": "Xiliang Yang,Yifei Xiong,Zhijian He", "background": "近年来，人们对研究序列神经后验估计（SNPE）技术表现出浓厚兴趣，因其能够处理不可解析似然的仿真实验模型。SNPE技术通过神经网络条件密度估计器从自适应提议的仿真实验中学习后验概率。Greenberg等人提出的自动后验变换（APT）方法在高维数据中表现突出，但计算上需要处理不可解析归一化常数的对数期望，即嵌套期望。尽管Atomic APT方法通过离散化归一化常数来解决此问题，但其学习收敛性的分析仍然具有挑战性。因此，本文提出了一种嵌套APT方法估计嵌套期望，这有助于进行收敛性分析。由于损失函数及其梯度的嵌套估计量是有偏的，论文采用了无偏多级蒙特卡罗（MLMC）估计量来消除偏差，同时提出了一类截断MLMC估计量来权衡偏差和平均成本，进一步降低估计量的高方差。", "innovation": "提出了嵌套APT方法来估计嵌套期望并进行收敛性分析；使用无偏多级蒙特卡罗（MLMC）和截断MLMC估计量来降低方差和消除偏差。该方法适用于中等维度具有多重模式的复杂后验概率逼近。", "conclusion": "论文开发的技术改进了嵌套期望的估计方法，通过使用MLMC和截断MLMC技术降低了方差和偏差，同时也提供了数值实验来验证其在复杂后验概率逼近中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06959", "html_url": "https://arxiv.org/abs/2412.06959", "title": "使用有条件扩散模型的地质和井筒信息辅助全波形反演", "title_en": "Geological and Well prior assisted full waveform inversion using conditional diffusion models", "authors": "Fu Wang,Xinquan Huang,Tariq Alkhalifah", "background": "全波形反演（FWI）经常面临地震观测不足的挑战，导致结果带有频带限制和地质不准确。通过结合潜在的速度分布、井测数据和地质知识和期望，可以显著提高FWI向真实模型的收敛性。尽管扩散调节FWI在结合速度分布优先信息方面显示出改进的性能，但通过融入井测信息和其他地质知识优先级，其效果可以进一步增强。为了利用这一点，本文提出了一种地质类别和井信息优先信息辅助的FWI方法，使用条件扩散模型。这种方法将多模态信息无缝集成到FWI中，同时实现数据拟合和通用地质和地球物理优先匹配，这往往传统正则化方法无法实现。具体而言，本文提出将条件扩散模型与FWI结合起来，通过分类器免费指导从原始速度分布优先级扩大到结合井测数据和地质类别条件，进行多模态优先匹配。", "innovation": "本文提出了一种地质类别和井信息优先信息辅助的FWI方法，使用条件扩散模型，将多模态信息无缝集成到FWI中，同时实现数据拟合和通用地质和地球物理优先匹配。这种方法通过分类器免费指导，将井测数据和地质类别条件融入原始速度分布优先级中，进行多模态优先匹配。这种方法相比传统正则化方法具有显著优势。", "conclusion": "数值实验在OpenFWI数据集和现场海洋数据上证明了本文方法相对于常规FWI和无条件扩散调节FWI的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.03704", "html_url": "https://arxiv.org/abs/2412.03704", "title": "基于视觉价值模型扩展推理时搜索以提高视觉理解", "title_en": "Scaling Inference-Time Search with Vision Value Model for Improved Visual Comprehension", "authors": "Xiyao Wang,Zhengyuan Yang,Linjie Li,Hongjin Lu,Yuancheng Xu,Chung-Ching Lin,Kevin Lin,Furong Huang,Lijuan Wang", "background": "尽管视觉语言模型(VLMs)取得了显著进展，但在推理时通过扩大计算规模来提高响应质量的有效方法仍然缺乏。这一能力被认为是近期大型语言模型研究中改善模型自改进能力的关键步骤。本文介绍了Vision Value Model (VisVM)，它能够在VLM推理时的搜索过程中指导生成具有更好视觉理解的响应。VisVM不仅在当前搜索步骤中评估生成句子的质量，还能预见由当前步骤产生的后续句子的质量，从而提供长期价值，引导VLM避免生成可能产生幻觉或细节不足的句子，从而产生高质量的响应。实验结果表明，与贪婪解码和其他具有视觉奖励信号的搜索方法相比，VisVM引导的搜索大幅提高了生成描述性、视觉细节更丰富且幻觉更少的标题的能力。此外，还发现使用VisVM引导的标题进行自我训练，可以显著提高VLM在多种跨模态基准上的表现，显示了开发自我改进的VLM的潜力。", "innovation": "本文提出了Vision Value Model (VisVM)，创新性地通过在VLM推理时的搜索过程中评估生成句子的质量和预见后续句子的质量，提供了长期价值，引导VLM避免生成可能产生幻觉或细节不足的句子，从而生成更好的响应。该模型显著提高了生成描述性、视觉细节更丰富且幻觉更少的标题的能力，并通过自我训练进一步提高了VLM在多种跨模态基准上的表现。", "conclusion": "实验结果表明，VisVM引导的搜索大大提升了VLM生成描述性标题的能力，减少了幻觉和提升了细节丰富度。此外，使用VisVM引导的标题进行自我训练，进一步改善了VLM在跨模态任务中的表现，具有开发自我改进的VLM的潜力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.17485", "html_url": "https://arxiv.org/abs/2411.17485", "title": "利用低秩脉冲网络中的潜在流形存储重叠关联记忆", "title_en": "Storing overlapping associative memories on latent manifolds in low-rank spiking networks", "authors": "William F. Podlaski,Christian K. Machens", "background": "联想记忆架构，例如霍普菲尔德网络，长期以来一直是神经科学和人工智能中的重要概念和理论模型。然而，将这些抽象模型转化为基于突触的神经网络一直非常困难。此前的工作大多限于在大型网络中存储少量主要不重叠的记忆，从而限制了它们的可扩展性。", "innovation": "本文利用几何框架展示了所有抑制性网络的突触活动位于低维、凸且分段线性的流形上，在这些流形上的动态行为沿着流形进行移动。将联想记忆问题映射到这些动态上，展示了立方体流形的顶点如何用来存储稳定的、重叠的活动模式，直接对应于原始霍普菲尔德模型。提出了几种学习规则，显示出神经元数量线性增加的存储容量，并具备稳健的模式完成能力。这种方法有效地展示了使用几何视角设计神经流形上动力学的有效性，并对神经科学和机器学习都有启示意义。", "conclusion": "总体而言，本文作为使用几何视角设计神经流形上动力学的一个案例研究，展示了其在神经科学和机器学习中的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03551", "html_url": "https://arxiv.org/abs/2502.03551", "title": "希尔伯特空间中基于严格平稳马尔可夫链的梯度下降算法研究，特别是在ϕ-和β-混合情况下的分析", "title_en": "Gradient Descent Algorithm in Hilbert Spaces under Stationary Markov Chains with $ϕ$- and $β$-Mixing", "authors": "Priyanka Roy,Susanne Saminger-Platz", "background": "本文研究了一种在一般希尔伯特空间中运行的严格平稳马尔可夫链梯度下降算法。分析重点是该过程中混合系数，具体涉及ϕ-混合系数和β-混合系数。在这些假设下，基于混合系数指数衰减以及多项式衰减，本文推导了算法收敛行为的概率上界。", "innovation": "本文的创新点在于首次研究了在希尔伯特空间中基于严格平稳马尔可夫链的梯度下降算法，并围绕ϕ-和β-混合系数推导了算法的收敛概率上界，考虑了混合系数的指数衰减和多项式衰减情况。", "conclusion": "本文基于混合系数的衰减情况，给出了在希尔伯特空间中基于严格平稳马尔可夫链的梯度下降算法的收敛概率上界，为该算法在复杂问题中的应用提供了理论支持。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.13094", "html_url": "https://arxiv.org/abs/2501.13094", "title": "通过对比去噪获得鲁棒表示一致性模型", "title_en": "Robust Representation Consistency Model via Contrastive Denoising", "authors": "Jiachen Lei,Julius Berner,Jiongxiao Wang,Zhongzhu Chen,Zhongjia Ba,Kui Ren,Jun Zhu,Anima Anandkumar", "background": "深度神经网络的鲁棒性在安全敏感应用中至关重要。随机化平滑提供了一种理论保证，用于在对抗性扰动下认证鲁棒性。最近，扩散模型已被用于随机化平滑，在标准分类器进行预测之前对噪声扰动样本进行净化。尽管这些方法在小扰动范围内表现优异，但对于大扰动却表现不佳，并且与经典方法相比，在推理过程中产生了显著的计算开销。", "innovation": "本文将生成建模任务沿像素空间的扩散轨迹重新表述为潜空间中的判别任务，并采用实例判别以沿轨迹实现一致表示，通过时间相邻点的对齐。基于学习到的表示模型进行微调后，该模型通过单次预测实现隐式的去噪-分类过程，显著降低了推理成本。在各种数据集上进行的广泛实验表明，本文方法在推理计算预算最小的情况下达到了最先进的性能。例如，与其他基于扩散的方法相比，在ImageNet上，本文的方法在所有扰动范围内将认证的准确性提高了5.3%，在大扰动范围上提高了11.6%，同时将推理成本降低了85倍。", "conclusion": "我们的方法在推理时实现了鲁棒表示的一致性，取得了最先进的性能，并且比传统的扩散模型方法具有更低的计算成本。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.11900", "html_url": "https://arxiv.org/abs/2502.11900", "title": "无近似项的海森堡极限哈密顿量学习", "title_en": "Ansatz-free Hamiltonian learning with Heisenberg-limited scaling", "authors": "Hong-Ye Hu,Muzhou Ma,Weiyuan Gong,Qi Ye,Yu Tong,Steven T. Flammia,Susanne F. Yelin", "background": "理解和学习量子系统中的未知相互作用对于量子信息处理、设备基准测试和量子传感至关重要。传统的哈密顿量学习假设相互作用是局部的，但对于任意哈密顿量则不一定适用。此前的方法均需要高阶的精度逆多项式依赖，无法超越标准量子极限，达到海森堡极限的缩放效果。鉴于此，在没有任何结构假设的情况下学习任意稀疏哈密顿量（简称无假设哈密顿量学习）是否可能实现海森堡极限精度，是一个尚未解决的问题。本研究提供了一个量子算法，仅通过系统实时演化和最少的数字控制即可达到海森堡极限的估计误差缩放性能。该方法还具有对态制备和测量误差的鲁棒性，增加了其实用性。此外，研究还证明了无近似项的方法在实际物理哈密顿量的学习、验证模拟以及性能验证方面是有效的，并且明确了总演化时间和量子控制之间的基本权衡，揭示了任何学习算法中可控性和总演化时间复杂性的固有关系。这些成果为进一步研究在最少假设下的复杂量子系统中实现海森堡极限的哈密顿量学习奠定了基础，可能在未来开启新型基准测试和验证协议的研发。", "innovation": "该研究提出了一个无假设项的、对态制备和测量误差具有鲁棒性的量子算法，能够在没有任何结构约束的情况下学习任意稀疏哈密顿量，并达到海森堡极限的精度，超越了现有方法的精度限制。此外，该算法还揭示了关于演化时间和量子控制之间的权衡关系，填补了这一研究领域的空白，为实现最小假设下的哈密顿量学习提供了新路径。", "conclusion": "本研究证明了无近似项的海森堡极限哈密顿量学习的可能性，通过一种新的量子算法，实现了对任意稀疏哈密顿量的高效学习，且能够克服态制备和测量的误差。同时，该研究还提出了演化时间与量子控制之间的基本权衡，进一步探讨了复杂量子系统中哈密顿量学习的复杂性。这些成果为量子信息处理和量子传感领域的实际应用奠定了坚实的基础。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.01144", "html_url": "https://arxiv.org/abs/2501.01144", "title": "BlockDialect: 块级细粒度混合格式量化以实现高效的大语言模型推理", "title_en": "BlockDialect: Block-wise Fine-grained Mixed Format Quantization for Energy-Efficient LLM Inference", "authors": "Wonsuk Jang,Thierry Tambe", "background": "由于大语言模型（LLMs）的规模迅速增大，内存使用和计算成本成为一个难题。量化权重和激活可以解决这些问题，而硬件支持的细粒度缩放作为缓解异常值的有前途的方法正逐渐受到关注。然而，现有的方法难以捕捉块数据的复杂分布。", "innovation": "提出了BlockDialect，这是一种块级细粒度混合格式技术，能够为每块数据分配最佳的数值格式，以更好地表示数据。此外，还引入了DialectFP4，这是一个针对不同数据分布进行调整的FP4变体格式书。为了更高效地利用该技术，提出了一种两阶段的在线DialectFP4激活量化方法。DialectFP4确保了能量效率，通过选择与低精度整数算术兼容的缩放整数值来代表数据。与MXFP4相比，BlockDialect在LLaMA3-8B和LLaMA2-7B模型中分别提高了10.78%和7.48%的准确率，同时使用较低的位数，并且即使在全路径矩阵乘法量化时，仍保持了与全精度相比仅5.45%和2.69%的精度下降。", "conclusion": "我们的研究表明，关注如何表示而不是如何缩放数据，提出了实现高效大语言模型推理的一种有前景的路径。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.19351", "html_url": "https://arxiv.org/abs/2412.19351", "title": "ETTA：阐明文本到音频模型的设计空间", "title_en": "ETTA: Elucidating the Design Space of Text-to-Audio Models", "authors": "Sang-gil Lee,Zhifeng Kong,Arushi Goel,Sungwon Kim,Rafael Valle,Bryan Catanzaro", "background": "近年来，文本到音频（Text-To-Audio, TTA）合成技术取得了显著进展，使用户能够通过自然语言提示生成合成音频，丰富他们的创造性工作流程。然而，关于数据、模型架构、训练目标函数和采样策略如何影响TTA模型目标基准的效果尚不明确。因此，需要进行全方位的研究，以便深入理解TTA模型的设计空间。", "innovation": "本文通过设立一个大规模的实证实验，专注于扩散和流动匹配模型，主要贡献包括：1）AF-Synthetic，一个高质量合成字幕的大规模数据集，由音频理解模型获得；2）系统比较了不同架构、训练和推断设计选择对TTA模型的影响；3）分析采样方法及其帕累托曲线与生成质量和推断速度的关系。通过这些深入分析，提出了称号为阐明文本到音频(ETTA)的最佳模型。ETTA在AudioCaps和MusicCaps上的表现优于公开数据训练的基线模型，且与内部数据训练的模型相当，进一步证明了ETTA在生成复杂和富有想象力的音频方面的能力提升。", "conclusion": "ETTA在当前基准测试中更复杂和富有想象力的字幕生成任务中显示出了更强的能力，相比之下，当前的基准测试更为简单。ETTA不仅为TTA模型的设计提供了全方位的理解，还提供了性能提升，特别是在生成高质量音频方面。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.13030", "html_url": "https://arxiv.org/abs/2502.13030", "title": "基于似然比正则化的高维协变量偏移下的置信推断", "title_en": "Conformal Inference under High-Dimensional Covariate Shifts via Likelihood-Ratio Regularization", "authors": "Sunay Joshi,Shayan Kiyani,George Pappas,Edgar Dobriban,Hamed Hassani", "background": "本文探讨了在协变量偏移情况下的收敛预测问题。给定来自源域的有标签数据和来自协变量偏移目标域的无标签数据，目标是在目标域内构建具有有效边缘覆盖率的预测集。现有的大多数方法需要估计未知的似然比函数，这对于高维数据（如图像）可能是不可行的。为了解决这一难题，本文引入了似然比正则化分位数回归（LR-QR）算法，该算法通过结合尖豆损失与新的正则化选择来构建阈值函数，而无需直接估计未知的似然比函数。研究表明，LR-QR方法在目标域内的覆盖率达到了所需水平，误差项可以被控制。这一证明利用了来自学习理论的新颖覆盖率分析中的稳定性界限。实验结果表明，LR-QR算法在高维预测任务上优于现有方法，包括Communities and Crime数据集的回归任务、WILDS资源库中的图像分类任务以及MMLU基准上的LLM问答任务。", "innovation": "提出了似然比正则化分位数回归（LR-QR）算法，该方法通过结合尖豆损失与一种新颖的正则化选择来构建阈值函数，而不直接估计未知的似然比函数。该方法在目标域内的覆盖率达到了所需水平，误差项可以被控制。这种算法设计旨在解决高维数据下难以直接估计似然比函数的问题，从而提高预测集的构建效率和准确性。", "conclusion": "实验证明，LR-QR算法在高维预测任务中表现优异，特别是在Communities and Crime数据集的回归任务、WILDS资源库中的图像分类任务以及MMLU基准上的LLM问答任务中，该方法优于现有的其他方法。通过这种似然比正则化方法，提高了在高维数据下构造可靠预测集的可行性与性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02859", "html_url": "https://arxiv.org/abs/2503.02859", "title": "具有稳定性保证的无监督属性动态网络嵌入", "title_en": "Unsupervised Attributed Dynamic Network Embedding with Stability Guarantees", "authors": "Emma Ceccherini,Ian Gallagher,Andrew Jones,Daniel Lawson", "background": "动态网络嵌入的稳定性确保在不同时间点行为相似的节点能够获得相同的嵌入，从而在不同时点上比较网络中的节点。现有的方法可能无法提供这种稳定性保证，且通常需要真实标签作为指导，而这些标签可能难以获取或不准确。本文旨在通过一种无监督的动态网络嵌入方法，解决这一问题，并表明该方法在链接预测和节点分类任务中能够提供显著改进。", "innovation": "本文提出了一种无监督的属性展开邻接谱嵌入（AUASE）方法，用于动态网络中的节点属性伴随时间变化的信息。为了达到稳定性，通过证明其与潜在位置模型的一致收敛性来建立稳定性保证。相较于当前最先进的网络嵌入方法，该方法通过在四个实际属性动态网络上的比较，量化其嵌入的优势，并且是唯一一种能够满足稳定性保证的无监督属性动态嵌入方法，无需真实标签指导。", "conclusion": "AUASE方法不仅提供了稳定性的保证，而且在链接预测和节点分类任务中表现出显著改进。这是对动态网络嵌入领域的一个重要贡献，为实际应用提供了更可靠的方法。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14051", "html_url": "https://arxiv.org/abs/2502.14051", "title": "RocketKV: 通过两阶段KV缓存压缩加速长上下文LLM推理", "title_en": "RocketKV: Accelerating Long-Context LLM Inference via Two-Stage KV Cache Compression", "authors": "Payman Behnam,Yaosheng Fu,Ritchie Zhao,Po-An Tsai,Zhiding Yu,Alexey Tumanov", "background": "基于Transformer的大语言模型在解码阶段依赖于KV缓存来高效处理长上下文。然而，随着输入长度的增长，KV缓存的大小也会相应增加，对内存带宽和容量造成负担。", "innovation": "提出了一种名为RocketKV的无需训练的KV缓存压缩策略，包含两个连续阶段。第一阶段在输入序列标记上执行粗粒度的永久KV缓存逐出。第二阶段采用混合稀疏注意机制进行细粒度的Top-k稀疏注意，通过头部和序列维度的减小来近似注意分数。RocketKV在NVIDIA A100 GPU上，与完整KV缓存基线相比，提供了高达400倍的压缩比、高达3.7倍的端到端加速以及峰值内存减少最多32.6%，同时在各种长上文任务上几乎无精度损失。对于多轮对话场景，还提出了RocketKV的变体，持续优于其他现有方法，接近于完美的Top-k注意力方案的精度。", "conclusion": "RocketKV提供了一种有效的KV缓存压缩方法，不仅提高了长上下文LLM推理的效率，还在保证精度的同时降低了内存需求。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03628", "html_url": "https://arxiv.org/abs/2502.03628", "title": "通过视觉信息引导减少大型视觉语言模型幻觉的令牌隐秘生活", "title_en": "The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering", "authors": "Zhuowei Li,Haizhou Shi,Yunhe Gao,Di Liu,Zhenting Wang,Yuxiao Chen,Ting Liu,Long Zhao,Hao Wang,Dimitris N. Metaxas", "background": "大型视觉-语言模型（LVLMs）能够有效地处理文本和视觉输入，但它们往往产生语义上连贯但视觉上不着地的内容。现有研究主要是探讨LVLMs在生成过程中的幻觉机制，发现视觉信息逐渐被侵蚀、语义上具有意义的标记前期达到峰值激活以及视觉信息标记虽未被最终解码但仍保持较高排名。这些发现为进一步探索减少LVLMs幻觉的技术奠定了基础。", "innovation": "本文提出了一个无需训练的推理时间干预框架VISTA（Visual Information Steering with Token-logit Augmentation），通过结合加强激活空间中的视觉信息和利用早期层激活来促进有意义的解码，以减少幻觉并促进真实信息。相比现有方法，VISTA不需要外部监督，且适用于不同的解码策略。广泛的实验表明，使用VISTA在评估的开放生成任务中平均可减少幻觉约40%，并始终在四个基准上的四种架构中四种解码策略上优于现有方法。", "conclusion": "VISTA减少幻觉并促进真实信息的效果显著，适用于多种解码策略，为处理LVLMs幻觉提供了新颖而有效的解决方案。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02952", "html_url": "https://arxiv.org/abs/2505.02952", "title": "使用逐步切割搜索方法解决指令模糊性的迭代解决方案", "title_en": "Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach", "authors": "Fabrizio Marozzo", "background": "生成式人工智能系统通过使自然语言编码和解决问题成为可能，极大地改变了人机交互。然而，自然语言的固有模糊性常常导致指令不准确，迫使用户反复测试、纠正和重新提交指令。现有方法通常是通过一次性的手动迭代来解决这些问题，效率不高且耗时较长，用户体验欠佳。", "innovation": "本文提出了一种迭代方法，通过结构化的澄清问题和替代解决方案提案逐步缩小模糊性，同时辅以输入/输出示例。该方法在不同的应用场景中（如编码、数据分析和创造性写作）进行评估，与传统的单次解决方案相比，该方法展示出更优的准确度、竞争力的解决时间以及更高的用户满意度，无需多次手动迭代即可达到正确的输出结果。", "conclusion": "所提出的方法通过对模糊性的逐步解决，提高了生成式AI系统任务处理的效率和准确性，提升了用户体验，显示了该技术在实际应用中的潜力和价值。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00703", "html_url": "https://arxiv.org/abs/2505.00703", "title": "T2I-R1：通过协作的语义级和token级CoT强化图像生成", "title_en": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT", "authors": "Dongzhi Jiang,Ziyu Guo,Renrui Zhang,Zhuofan Zong,Hao Li,Le Zhuo,Shilin Yan,Pheng-Ann Heng,Hongsheng Li", "background": "最近的大语言模型显示出逻辑推理（CoT）和强化学习（RL）策略能显著提高生成性能。然而，如何将这些推理策略应用到视觉生成领域，特别是语义级和token级的CoT策略，仍然处于探索阶段，尚未有成熟的解决方案和应用实例。本文通过对现有模型Janus-Pro的应用，展示了如何利用强化学习和多层CoT推理来解决这一问题，推动了图像生成领域的研究进展。", "innovation": "本文的创新点在于开发了一个名为T2I-R1的新模型，它结合了逻辑推理和强化学习策略，具体采用了双层CoT推理过程——语义级CoT用于高级提示规划，token级CoT用于生成过程中低级像素处理。为了更好地结合这两种不同层次的CoT过程，提出了一种双层次CoT-GRPO算法，能够在单次训练步骤中优化生成过程的CoT策略。这对于跨模型策略的整合和优化有着重要的推动作用，能够改善图像生成质量和效果。", "conclusion": "通过T2I-R1模型的应用，实验结果显示它在T2I-CompBench和WISE基准测试上分别取得了13%和19%的性能提升，甚至超过了当前最先进的模型FLUX。表明通过强化学习和多层CoT推理相结合的方法，在视觉生成领域是可行并有效的。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07416", "html_url": "https://arxiv.org/abs/2504.07416", "title": "RadZero: 基于相似性交叉注意力的可解释医学影像视图语言对齐框架，具有零样本多任务能力", "title_en": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability", "authors": "Jonggwon Park,Soobum Kim,Byungmu Yoon,Kyoyun Choi", "background": "近期多模态模型在医学影像（医学影像）-语言（语言）对齐方面取得了显著进步，特别是在放射学领域。然而，现有方法在有效利用复杂医学报告以及提供解释性的注意力概率可视化方面存在不足。为解决这些问题，本文提出了一种名为RadZero的新框架，该框架具备零样本多任务能力，特别在可解释的细粒度医学影像-语言推理解释方面具有显著优势。RadZero通过从大型语言模型中提取医学报告中的简洁语义句子，并采用多正增强对比训练来高效捕捉图像和多个相关文本描述之间的关系，显著提升了零样本分类、覆盖和分割任务的表现。此外，VL相似性图分析展示了VL-CABS在提升医学影像语言对齐解释性方面的潜力，而定性评估进一步证明了其在开放词汇语义分割中的有效性", "innovation": "1. 提出了一种名为RadZero的新框架，该框架具备零样本多任务能力，特别在医学影像-语言对齐的解释性上具有显著优势。\n2. 引入了一个关键组件VL-CABS（基于相似性的视觉-语言跨注意力），能够使文本嵌入与局部图像特征对齐，从而实现解释性和细粒度的语义推理解释。\n3. RadZero 使用预训练视觉编码器和可训练的 Transformer 层，实现了高效高分辨率图像处理，并通过计算文本嵌入与局部图像补丁特征之间的相似性，实现了零样本推理和像素级的视觉-语言相似性图，用于可视化和分割", "conclusion": "实验结果表明，RadZero 超越了现有的最先进的方法，在零样本分类、对象检测和分割任务中表现出色。此外，VL相似性图分析显示了VL-CABS在提高视觉-语言对齐解释性方面的潜力，而定性的评估进一步证明了其在医学影像中的有效性及其开放式词汇语义分割能力。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00949", "html_url": "https://arxiv.org/abs/2505.00949", "title": "Llama-Nemotron: 高效推理模型", "title_en": "Llama-Nemotron: Efficient Reasoning Models", "authors": "Akhiad Bercovich,Itay Levy,Izik Golan,Mohammad Dabbah,Ran El-Yaniv,Omri Puny,Ido Galil,Zach Moshe,Tomer Ronen,Najeeb Nabwani,Ido Shahaf,Oren Tropp,Ehud Karpas,Ran Zilberstein,Jiaqi Zeng,Soumye Singhal,Alexander Bukharin,Yian Zhang,Tugrul Konuk,Gerald Shen,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Yoshi Suhara,Olivier Delalleau,Zijia Chen,Zhilin Wang,David Mosallanezhad,Adi Renduchintala,Haifeng Qian,Dima Rekesh,Fei Jia,Somshubra Majumdar,Vahid Noroozi,Wasi Uddin Ahmad,Sean Narenthiran,Aleksander Ficek,Mehrzad Samadi,Jocelyn Huang,Siddhartha Jain,Igor Gitman,Ivan Moshkov,Wei Du,Shubham Toshniwal,George Armstrong,Branislav Kisacanin,Matvei Novikov,Daria Gitman,Evelina Bakhturina,Prasoon Varshney,Makesh Narsimhan,Jane Polak Scowcroft,John Kamalu,Dan Su,Kezhi Kong,Markus Kliegl,Rabeeh Karimi,Ying Lin,Sanjeev Satheesh,Jupinder Parmar,Pritam Gundecha,Brandon Norick,Joseph Jennings,Shrimai Prabhumoye,Syeda Nahida Akter,Mostofa Patwary,Abhinav Khattar,Deepak Narayanan,Roger Waleffe,Jimmy Zhang,Bor-Yiing Su,Guyue Huang,Terry Kong,Parth Chadha,Sahil Jain,Christine Harvey,Elad Segal,Jining Huang,Sergey Kashirsky,Robert McQueen,Izzy Putterman,George Lam,Arun Venkatesan,Sherry Wu,Vinh Nguyen,Manoj Kilaru,Andrew Wang,Anna Warno,Abhilash Somasamudramath,Sandip Bhaskar,Maka Dong,Nave Assaf,Shahar Mor,Omer Ullman Argov,Scot Junkin,Oleksandr Romanenko,Pedro Larroy,Monika Katariya,Marco Rovinelli,Viji Balas,Nicholas Edelman", "background": "本文介绍了Llama-Nemotron系列模型，这是一个具备开放许可的企业使用条件的异构推理模型家族。该系列模型有三种规模——Nano（8B）、Super（49B）和Ultra（253B），在推理能力和推理效率方面表现出色，且能够与最先进的推理模型（如DeepSeek-R1）相竞争，并且在内存效率方面具有优势。本文详细讨论了这些模型的训练过程，包括神经架构搜索、知识蒸馏和连续预训练，随后是推理重点的后训练阶段，该阶段包括监督微调和大规模强化学习两个主要部分。", "innovation": "Llama-Nemotron模型是开源领域的首个支持动态推理切换的模型，允许用户在推理过程中在标准聊天模式和推理模式之间切换。此外，该模型提供了高度灵活且高效的推理能力，同时还在开放研究和模型开发方面提供了支持性资源，包括开放模型许可协议、完整的后训练数据集以及用于这些任务的训练代码库。", "conclusion": "Llama-Nemotron模型通过提供高效且准确的推理模型，解决了企业级应用中开放性和性能之间的平衡问题。通过提供开放源代码模型以及辅助资源，旨在促进开放研究和模型开发。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.11801", "html_url": "https://arxiv.org/abs/2503.11801", "title": "Diffuse-CLoC：基于物理的字符前瞻控制的引导扩散", "title_en": "Diffuse-CLoC: Guided Diffusion for Physics-based Character Look-ahead Control", "authors": "Xiaoyu Huang,Takara Truong,Yunbo Zhang,Fangzhou Yu,Jean Pierre Sleiman,Jessica Hodgins,Koushil Sreenath,Farbod Farshidian", "background": "现有的基于扩散模型的运动生成方法虽然在推理时可以提供直观的控制能力，但往往无法生成物理上可行的动作；而基于扩散的方法虽然在生成物理可实现的动作方面取得了进展，但缺乏对动作的预判，限制了其可控性。Diffuse-CLoC 通过一个关键洞察解决了这些问题：在同一扩散模型中建模状态和动作的联合分布，使得动作生成可以通过在预测状态的基础上进行条件化来实现可控性。这种方法允许我们利用现有的来自定型运动生成的条件化技术，同时生成物理上可行的动作。因此，这种方法在不需要高级规划器的情况下实现了规划能力。实验结果表明，该方法在处理一系列未见过的长期下游任务时表现优于传统的分层框架，包括静态和动态障碍物避免、动作生成和任务空间控制。", "innovation": "Diffuse-CLoC 通过在同一扩散模型中建模状态和动作的联合分布，使得动作生成可以通过条件化于预测状态来实现可控性，从而结合了直观的控制能力和物理可行性的优点。这种方法允许在不需要高阶规划器的情况下实现规划能力，并通过一个预训练模型处理各项任务，包括静态和动态障碍物避免、动作生成和任务空间控制。实验结果证实，该方法在性能方面超过了传统的分层框架。", "conclusion": "Diffuse-CLoC 通过结合基于扩散的方法和定型方法，提供了一种既具有直观控制又保持物理可行性的前瞻控制方案，能够在不需要高级规划器的情况下实现规划能力，并在一系列未见过的任务中展现出显著的优势。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12578", "html_url": "https://arxiv.org/abs/2505.12578", "title": "层叠自适应预测", "title_en": "Stacked conformal prediction", "authors": "Paulo C. Marques F", "background": "论文考虑了一种方法，用于使层叠预测模型组合形式化。背景是需要一种能够最终保证预测模型精度同时保持计算成本可管理性的方法。常规的自适应预测方法可能需要额外的校准样本来保证模型的预测准确性。论文探讨了利用顶级元学习器可能简单的形式，实现无需额外校准样本即可近似保持边际有效性的程序。实验证据表明，所提出的方法相比标准的归纳替代方案具有优势。", "innovation": "创新之处在于提出了一种使层叠预测模型组合形式化的自适应方法，通过利用顶级元学习器的简单形式，实现了无需额外校准样本即可近似保持边际有效性的目标，同时具有可管理的计算成本。", "conclusion": "实验结果表明，该方法优于传统的归纳替代方案，且能够有效减少对额外校准样本的需求，同时保持良好的计算效率和预测性能。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18182", "html_url": "https://arxiv.org/abs/2505.18182", "title": "基于ECG和PCG信号的机器学习在心瓣膜病检测中的研究：2015-2025年的范围综述", "title_en": "Machine Learning-Based Analysis of ECG and PCG Signals for Rheumatic Heart Disease Detection: A Scoping Review (2015-2025)", "authors": "Damilare Emmanuel Olatunji,Julius Dona Zannu,Carine Pierrette Mukamakuza,Godbright Nixon Uiso,Chol Buol,Mona Mamoun Mubarak Aman,John Bosco Thuo,Nchofon Tagha Ghogomu,Evelyne Umubyeyi", "background": "在资源有限的地区，由于成本和人力资源的限制，超声心动图作为诊断肥厚性心肌病的金标准工具仍然难以获得。为此，AI辅助听诊器作为一种有前景的早期筛查工具，在这些地区具有巨大的潜力。然而，目前缺乏标准化的数据集和广泛的验证，这限制了这些模型在临床上的可用性。这篇综述系统地检查了2015年至2025年之间的37项研究，这些研究使用机器学习技术分析心电图(ECG)和心音图(PCG)数据，以支持肥厚性心肌病(vRHD)的可及性和可扩展筛查，以达成世界心脏病联合会的25 x 25目标，即到2025年减少肥厚性心肌病的死亡率。", "innovation": "近年来，卷积神经网络(CNNs)在ECG和PCG数据的分析中取得了显著的准确率(中位数97.75%)、F1分数(0.95)和AUROC (0.89)。这项工作强调了标准化数据集、在流行病学区域进行前瞻性的临床试验以及更广泛验证的必要性，以弥合模型性能与临床适用性之间的差距。", "conclusion": "通过解决这些现有不足，AI增强的听诊技术能够为资源匮乏的地区提供心血管诊断工具，从而有助于实现早期诊断。此外，研究还提供了关于构建可访问的基于机器学习的vRHD筛查工具的实际建议，旨在填补资源匮乏地区常规听诊可能漏诊高达90%病例以及超声心动图难以到达的诊断缺口。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09730", "html_url": "https://arxiv.org/abs/2506.09730", "title": "平滑凸优化中长期步长和加速方法的实证和辅助分析", "title_en": "Empirical and computer-aided robustness analysis of long-step and accelerated methods in smooth convex optimization", "authors": "Pierre Vernimmen,François Glineur", "background": "本研究评估了在梯度计算具有相对不精确性的情况下，不同一阶优化方法的鲁棒性。相对不精确性是指当使用较少位数信息压缩梯度时，例如在处理大规模问题时在GPU上发生的梯度压缩情况。研究分析了三种主要的方法家族：常步长梯度下降法、长期步长方法和加速方法。长期步长方法和加速方法在理论上对不精确性不鲁棒，为此引入了一个半启发式的缩短因子来提高它们的理论保证。在具体的应用中测试了所有方法，展示了加速方法比预期更有鲁棒性，缩短因子显著帮助了长期步长方法。最终，所有缩短后的算法在此不精确设置下显示出潜力。", "innovation": "研究采用了绩效估计方法，理论和实证相结合分析，重点是引入半启发式缩短因子，提升了长期步长方法和加速方法的鲁棒性。特别是在面对相对不精确性问题时，展示了加速方法比传统预期更为鲁棒，缩短因子在长期步长方法改进上起到了关键作用。", "conclusion": "研究结果表明，在不精确设置下，所有缩短后的优化方法都显示出潜力，加速方法的鲁棒性比预期强，缩短因子显著提升了长期步长方法的效果。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07844", "html_url": "https://arxiv.org/abs/2506.07844", "title": "Itô过程中条件局部独立性检验的动态因果发现", "title_en": "Conditional Local Independence Testing for Dynamic Causal Discovery", "authors": "Mingzhou Liu,Xinwei Sun,Yizhou Wang", "background": "动态系统的因果关系推理是许多科学查询的核心兴趣。条件局部独立性（CLI）描述了在给定其他过程的情况下，一个过程的演变是否受另一个过程的影响，这对于系统中的因果学习至关重要。然而，现有的CLI测试仅限于计数过程。", "innovation": "本文提出了一种针对Itô过程的非参数性的CLT检验。具体来说，作者首先通过从目标过程的条件期望构造鞅来引入基于局部相关性度量（LCM）的测试统计量。为了解决估计问题，作者提出了基于最优滤波方程的高效估计器，该估计器可以达到根-N一致性。作者通过放宽对Itô过程的严格有界性条件到矩条件，建立了检验的渐近水平和功效。", "conclusion": "通过合成和真实世界实验验证了所提出的测试的有效性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22729", "html_url": "https://arxiv.org/abs/2506.22729", "title": "动态科学中的坚持悖论", "title_en": "Persistence Paradox in Dynamic Science", "authors": "Honglin Bao,Kai Li", "background": "在科学研究中，坚持不懈通常被视为一种美德。然而，本文通过强调坚持具有背景依赖性，尤其是在范式转变期间，挑战了这一传统观点。文章以2012年由AlexNet引发的深度学习革命为背景，探讨了顶级机器学习会议中超过5000名活跃科学家的研究重点和产出变化。研究表明，在这段时间内，顶尖会议越来越多地优先考虑前沿的深度学习发展，逐步取代较为传统的统计学习方法。", "innovation": "文章创新地分析了科学家在面对新兴趋势时的不同响应方式，揭示了坚持可能带来的负面效应——所谓的‘僵化惩罚’。那些态度保守、不适应新方向的科学家经历了下降；而那些战略性适应新兴趋势的科学家则获得了最大利益，在科学影响力的衡量标准（引用百分位数排名）上也表现更佳。这项研究不仅展示了宏观和微观层面的证据，还说明了科学突破如何重塑科学领域的权力结构。", "conclusion": "总体而言，文章的宏观和微观研究结果表明，科学突破作为机制重新配置了科学领域的权力结构，揭示了在快速变化的科学环境中，应变能力比单纯坚持更为重要。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22971", "html_url": "https://arxiv.org/abs/2506.22971", "title": "层级分散随机控制在信息物理系统中的应用", "title_en": "Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems", "authors": "Kesav Kaza,Ramachandran Anantharaman,Rahul Meshram", "background": "本文提出了一个用于信息物理系统控制的双时标层次分散架构。该架构由N个独立子过程、一个全局控制器以及N个本地控制器组成，每个控制器都可以被表述为马尔科夫决策过程(MDP)。这些本地控制器以较快的时间尺度运行，而全局控制器则以较慢的时间尺度运行，目标是在预算约束下最大化无限期的折现累积奖励。在分析这两种框架的理论基础后，本文提出了一种名为COpt和FOpt的不同的优化框架。", "innovation": "本文创新地提出了一种用于信息物理系统的双时标层次分散控制架构，该架构包含多个独立的子过程、一个全局控制器和多个本地控制器，每个本地控制器都被表示为一个MDP问题。文章提出了COpt和FOpt两种优化框架，并证明这些框架在一定条件下具有相同的最优值，这为信息物理系统的控制提供了新的理论依据和技术手段。", "conclusion": "本文通过建立迭定的最优策略存在性、研究两者之间的关系以及提供某一条件保证两框架达到相同最优值，证明了在不同的优化框架下，两者的最优值在一定条件下是相同的。这为信息物理系统中局部和全局策略的协调优化提供了新的思路。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22773", "html_url": "https://arxiv.org/abs/2506.22773", "title": "所有水资源消耗并非等同：一个基于水力紧张度加权的可持续计算指标", "title_en": "Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing", "authors": "Yanran Wu,Inez Hua,Yi Ding", "background": "水资源消耗已成为计算可持续性的关键维度，尤其是在人工智能工作负载迅速增长的情况下。然而，现有的水资源影响评估往往忽略了水资源紧张度更为严重的地区和时间点。为了填补这一空白，我们提出了SCARF，这是第一个将空间和时间上的水资源紧张度变化纳入计算水资源影响评估的通用框架。SCARF通过综合水资源消耗量和当地随时间变化的紧张度，计算出一个调整后的水资源影响（AWI）指标。研究通过三个案例研究，展示了优化位置和时间选择以减少水资源影响的潜在机会，为水资源可持续计算开辟了道路。", "innovation": "提出的SCARF框架首次结合了空间和时间上的水资源紧张度变化来评估计算的水资源影响。它引入了调整后的水资源影响（AWI）指标，该指标考虑了水资源消耗量和当地随时间变化的紧张度。这填补了当前评估方法的空白，因为它们往往忽略了水资源紧张度的地区和时间差异性。这为水资源的可持续计算提供了一种新的方法。", "conclusion": "通过三个案例研究，我们展示了通过优化位置和时间选择来减少水资源影响的隐藏机会，为水资源可持续计算铺平了道路。该研究为水资源利用效率的提升和计算领域的可持续发展提供了新的可行途径。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23458", "html_url": "https://arxiv.org/abs/2506.23458", "title": "基于神经启发的联合学习增强可穿戴BCI中的认知负荷解码", "title_en": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs", "authors": "Xiaoxiao Yang,Chao Feng,Jiancheng Chen", "background": "便携式脑机接口（BCI）应用，特别是使用Muse头带等可穿戴消费级脑电图（EEG）设备，为日常认知负荷检测提供了前所未有的移动性。然而，便携式EEG信号的加剧非稳态性限制了数据保真度和解码准确性，造成了便携性和性能之间的根本性权衡。", "innovation": "提出了一种统一轮询学习框架MuseCogNet，结合了自我监督和有监督的训练模式。特别地，引入了基于平均池化的EEG导向自我监督重建损失来捕捉稳健的神经生理模式，而交叉熵损失则细化任务特定的认知辨别。该联合学习框架类似于人类的自上而下和自下而上的注意力，使MuseCogNet在公开可用的Muse数据集上显著优于现有方法，并为生态条件下的神经认知监测提供了一个可实现的途径。", "conclusion": "MuseCogNet在公开的Muse数据集上显著优于现有方法，表明该联合学习框架在便携式BCI中的认知负荷解码方面具有显著优势，并为生态条件下的神经认知监测提供了一条可行路径。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06946", "html_url": "https://arxiv.org/abs/2506.06946", "title": "使管道能够投入生产：医疗保健领域中的挑战与经验教训", "title_en": "Making a Pipeline Production-Ready: Challenges and Lessons Learned in the Healthcare Domain", "authors": "Daniel Angelo Esteves Lawand(1),Lucas Quaresma Medina Lam(1),Roberto Oliveira Bolgheroni(1),Renato Cordeiro Ferreira(1,2,3,4),Alfredo Goldman(1),Marcelo Finger(1) ((1) University of São Paulo, (2) Jheronimus Academy of Data Science, (3) Technical University of Eindhoven, (4) Tilburg University)", "background": "在将机器学习(ML)培训管道部署到生产中时，需要遵循良好的软件工程实践。然而，典型的数据科学工作流往往导致代码缺乏关键的软件质量属性。这项经验报告在SPIRA项目的背景下探讨了这个问题，SPIRA项目的目的是创建一个基于ML的系统（MLES）来通过言语分析预诊断呼吸不足。报告概述了MLES的架构，并比较了连续训练子系统的三个版本：从一个大泥球的证明概念（v1），到基于设计模式的模块化巨石（v2），再到基于测试驱动的微服务集（v3）。每个版本都提高了系统的整体扩展性、可维护性、稳健性和弹性。报告分享了该过程中的挑战和经验教训，为研究者和实践者提供了参考，以使自己的管道能够在生产中使用提供了见解。", "innovation": "项目使用了从简单到复杂的连续训练子系统的三个不同版本，分别为：大泥球（v1）、模块化巨石（v2）和基于测试驱动的微服务（v3），逐步提升了系统的扩展性、可维护性、稳健性和弹性。", "conclusion": "报告分享了在将ML训练管道投入生产过程中面临的主要挑战和宝贵的经验教训，这些经验和洞察能够为其他研究人员和实践者提供有价值的参考，帮助他们改进生产化的机器学习管道的设计与实现。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23952", "html_url": "https://arxiv.org/abs/2506.23952", "title": "由设计保障自主性：在AI决策支持中保留人类自主性", "title_en": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "authors": "Stefan Buijsman,Sarah Carter,Juan Pablo Bermúdez", "background": "AI系统在各个领域的专业、技能和个人活动中越来越支持人类决策。尽管先前的工作研究了AI可能如何影响全球人类自主性，但AI对领域特定自主性(在特定技能或专业知识范围内自主行动的能力)的影响尚未充分研究。研究表明，缺乏可靠失败指标和潜在的无意识价值转变会立即和长期地侵蚀领域特定自主性。", "innovation": "本文通过分析医疗、金融和教育领域的实证案例，展示了缺乏可靠失败指标和潜在无意识价值转变如何立即和长期侵蚀领域特定自主性。提出了保留自主性的AI支持系统的建构性框架。设计模式包括明确角色说明、失效机制实施以及支持反思性实践等策略，这些策略可以帮助在利用AI能力的同时维持领域特定自主性，从而增强而不要削弱人类在专业领域行动中的能动性。", "conclusion": "该框架为开发能够增强而不是削弱人类在专门领域行动中能动性的AI系统提供了具体的指导。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00347", "html_url": "https://arxiv.org/abs/2507.00347", "title": "VTS-Guided AI Interaction Workflow for Business Insights", "title_en": "VTS-Guided AI Interaction Workflow for Business Insights", "authors": "Sun Ding,Ude Enebeli,Atilhan(Ati)Manay,Ryan Pua,Kamal Kotak", "background": "现代企业面临大量复杂且未结构化的报告，将这些文档转化为可使用的洞察需要大量努力，且在需要快速答案时并不灵活。VTS-AI旨在解决这一问题，通过将基于证据的观察、连接和思考融入AI代理中，从文档、表格和图像中大规模提取业务洞察，支持快速分析和及时响应。", "innovation": "VTS-AI采用三层架构（微观、中观、宏观）处理业务报告：标记问题、链接到源页面并汇总到可搜索的YAML文件中，形成明确的动作杠杆。与其他AI系统的测试结果相比，VTS-AI在速度上可与一次性的ChatGPT指令相匹敌，但提供了更丰富的发现，如页面位置、原话摘录、严重程度评分和因果链接。此外，分析师可以在相同的集成开发环境中接受或调整这些输出，保持人工判断的介入。该系统还能够识别关键指标的方向，并指示哪里需要深入分析。", "conclusion": "VTS-AI在快速业务分析中起到了生产级别的审计友好工具的作用，并计划通过将叙述标签映射到财务比例、通过模型-上下文协议添加财务调整语言模型、构建风险与安全层来压力测试模型和保护数据，进一步提升其能力，使其更接近完全自动化和可操作性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24852", "html_url": "https://arxiv.org/abs/2505.24852", "title": "Chameleon：用于序贯数据端到端少样本和持续学习的无需矩阵乘法的时序卷积网络加速器", "title_en": "Chameleon: A MatMul-Free Temporal Convolutional Network Accelerator for End-to-End Few-Shot and Continual Learning from Sequential Data", "authors": "Douwe den Blanken,Charlotte Frenkel", "background": "边缘设备上进行的学习可以实现低延迟、隐私保护的个性化，并提高长期稳健性，降低维护成本。然而，实现可扩展、低功耗端到端芯片上的学习，特别从具有有限示例的真实世界序贯数据中学习，仍是一个开放的挑战。现有的加速器在优化学习性能的同时会牺牲推理效率，而简化的学习算法又往往无法达到可接受的准确度目标。", "innovation": "Chameleon 通过三个关键贡献解决了这些挑战：(i) 统一的学习和推理架构支持少样本学习 (FSL)、持续学习 (CL) 和仅增加 0.5% 推理逻辑面积开销的推理；(ii) 利用时序卷积网络 (TCNs) 有效捕捉长时间依赖，实现了序贯数据和 16 kHz 未处理音频的端到端芯片上的 FSL 和 CL 的首次演示；(iii) 双模式、无需矩阵乘法的计算阵列可以在匹配最先进的仅推理关键词识别 (KWS) 加速器功耗的同时实现 4.3 倍更高的峰值 GOPS，或实现更高的性能。", "conclusion": "Chameleon 在 40 纳米 CMOS 工艺下，新的准确记录包括：对于端到端芯片上的少样本学习，新兴奥光字符集的 5 类 1 射目标是 96.8%，5 类 5 射目标是 98.8%；持续学习最终准确率 82.2%，学习 250 类别时有 10 射目标；以及在极端边缘功耗预算下，12 类 Google 语音命令数据集的推理准确率为 93.3%，功率仅为 3.1 微瓦。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00421", "html_url": "https://arxiv.org/abs/2507.00421", "title": "嵌入式DevOps：嵌入式软件和固件开发中DevOps实践的应用综述", "title_en": "Embedded DevOps: A Survey on the Application of DevOps Practices in Embedded Software and Firmware Development", "authors": "Parthiv Katapara,Anand Sharma", "background": "嵌入式系统的开发正在应对现代硬件-软件协同设计产品日益增长的复杂性，不同于云原生应用程序，嵌入式系统引入了硬件依赖性、实时约束和安全要求等挑战。现有的文献综述研究了如何将DevOps原则（特别是持续集成、持续交付和自动化测试）适应嵌入式背景，以及这些原则在工具、测试策略、管道自动化和安全方面的具体应用。然而，目前部署工作流程中的局限性和可观测性仍然是问题，未来的研究需要进一步探索和优化这些问题。", "innovation": "对20篇学术和工业源进行了文献综述，探讨了DevOps原则如何适应嵌入式系统的环境，特别是持续集成、持续交付和自动化测试等方面的应用。分类了这些原则在工具、测试策略、管道自动化和安全实践中的具体实施。", "conclusion": "该研究为研究人员和从业人员提供了一个综合的嵌入式DevOps理解，填补了该领域的文献断层，提出了一条未来研究的方向，旨在解决当前部署工作流程和可观测性中的局限性。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00378", "html_url": "https://arxiv.org/abs/2507.00378", "title": "iPanda: 智能协议一致性测试与调试代理", "title_en": "iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing", "authors": "Xikai Sun,Fan Dang,Kebin Liu,Xin Miao,Zihao Yang,Haimo Lu,Yawen Zheng,Yunhao Liu", "background": "协议一致性测试对于确保协议实现符合其规范至关重要。然而，传统的测试方法需要手动创建大量测试案例和脚本，过程繁琐且效率低下。近年来，大型语言模型（LLMs）在文本理解和代码生成方面展现了卓越的能力，为自动化测试提供了新的可能性。鉴于此，本文提出了一款名为iPanda的端到端框架，利用LLMs自动化处理协议一致性测试问题，以提高测试效率和准确度。基于给定的协议规范文档及其实现版本，iPanda首先采用关键词方法自动生成全面的测试案例。接着，通过代码检索增强生成的方法理解实现，生成可执行测试代码。为了进一步提高生成代码的质量，iPanda引入了一种迭代自我纠正机制，实现生成的测试脚本互动式优化。最后，通过执行和分析生成的测试，iPanda系统性地验证了实现与协议规范之间的合规性。在各种协议上的全面实验表明，iPanda显著优于纯LLM方法，将测试-代码生成的成功率（Pass@1）提高了4.675至10.751倍，从而极大地提升了测试效率和结果准确性。", "innovation": "iPanda 提出了一种创新的自动化协议一致性测试框架，首次利用 LLMs 实现从协议规范到生成全面、可执行测试代码的端到端处理。其采用了关键词生成测试案例、基于代码的检索增强生成方法以及迭代自我纠正机制来确保生成的测试代码质量。", "conclusion": "实验结果表明，iPanda 显著提高了测试-代码生成的成功率，相比纯 LLM 方法，成功率提高了 4.675 至 10.751 倍，有效地简化了一致性测试过程并提升了测试的精确性和效率。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00413", "html_url": "https://arxiv.org/abs/2507.00413", "title": "推荐提取局部变量重命名", "title_en": "Recommending Variable Names for Extract Local Variable Refactorings", "authors": "Taiming Wang,Hui Liu,Yuxia Zhang,Yanjie Jiang", "background": "提取局部变量是使用最广泛的重构之一，大多数集成开发环境（IDE）和重构工具都提供了自动支持这一重构的能力。然而，约为70%的推荐变量名与开发者手动构建的名称不同，这给开发者带来了额外的重命名负担，并且提供的协助有限。因此，本文介绍了一个名为VarNamer的自动化解决方案，用于推荐提取局部变量重构的变量名称。通过大规模的实证研究，我们确定了有助于命名的有用上下文，并通过程序静态分析技术开发了一组启发式规则，利用数据挖掘技术有效地推荐变量名称。评估结果显示，VarNamer在准确匹配方面明显优于最先进的IDE，具体表现为相较于Eclipse提升了52.6%，相较于IntelliJ IDEA提升了40.7%。实验还表明，该方法在C++项目等其他编程语言上的性能可以达到相当的水平，这可能表明VarNamer具有一定的普遍适用性。最后，我们设计并实施了用户研究，结果显示我们的方法可以将重构过程加快27.8%，并且减少了49.3%的推荐变量名称修改量。", "innovation": "本文提出VarNamer，这是一种自动化方法，用于推荐提取局部变量重构的变量名称。通过程序静态分析技术开发了一组启发式规则，并利用数据挖掘技术有效地推荐变量名称。特别地，一些启发式规则成功集成到了Eclipse中，成为最新版本IDE的组成部分。VarNamer在准确匹配方面明显优于最先进的IDE，尤其是在Java以外的语言中也表现出良好的性能。用户研究进一步验证了该方法的效率和有效性，能够显著提高重构速度并减少编辑量。", "conclusion": "VarNamer通过自动化推荐变量名称，有效减轻了开发者的重命名负担，并显著提高了重构的效率。该方法不仅适用于Java，通过在C++项目上的测试表明其具有跨语言的一般适用性。用户研究进一步证实了该方法的有效性和实用性。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22419", "html_url": "https://arxiv.org/abs/2506.22419", "title": "自动化的大型语言模型速度跑步基准：重现NanoGPT改进", "title_en": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "authors": "Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach", "background": "大型语言模型（LLMs）的快速发展为科学研究的进步提供了可能。实现这一目标的关键能力之一是能够重现现有工作。为了评估AI代理重复现有研究领域的成果的能力，作者引入了自动化的LLM速度跑步基准，利用了NanoGPT速度跑步比赛的社区贡献，这是一个在最短时间内训练GPT-2模型的竞争。每个19项速度跑步任务都为代理提供了前一条记录的训练脚本，并且可以提供从伪代码到新记录改进的详细描述之一的三种提示格式。这些记录旨在快速完成，改进的速度涵盖从高级算法改进到基于硬件的优化等多样的代码层变化。这些特点使基准既易于访问又具有现实意义，适用于提高LLM训练的前沿问题。研究表明，即使是当给出详细提示时，最近的推理LLMs与最先进的辅助结构（Sota scaffolds）也难以重新实现基准中的已知创新。因此，这一基准提供了一个简单且没有饱和的度量，以衡量LLM自动再现科学成果的能力，这是自主研究代理必要的（但不是充分的）技能。", "innovation": "提出了Automated LLM Speedrunning Benchmark，利用NanoGPT速度跑步比赛的数据，评估AI代理重现现有研究领域成果的能力。此基准通过详细记录如何改进了基准中的模型，提供了从伪代码到论文式描述的提示，使得代理能够快速理解和改进代码。此基准不仅实用，还能够客观评价LLMs在自动再现科学成果方面的能力，这对于开发智能研究助手至关重要。", "conclusion": "研究表明，最近的LLMs即使是当给出详细提示时，也无法重现已知的创新。因此，这一基准提供了一个关于LLM重现科学成果能力的简单且未饱和的度量，这对于开发具有必要（但不是充分的）技能的自主研究代理至关重要。这一研究为评估和改进LLMs在科学再现领域的实际应用提供了基础。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00496", "html_url": "https://arxiv.org/abs/2507.00496", "title": "深度学习模型的覆盖引导测试：一项全面调研", "title_en": "Coverage-Guided Testing for Deep Learning Models: A Comprehensive Survey", "authors": "Hongjing Guo,Chuanqi Tao,Zhiqiu Huang,Weiqin Zou", "background": "随着深度学习模型在关键安全领域中的广泛应用，确保其质量已成为现代软件工程中亟待解决的重要挑战。现有研究中涌现的验证方法中，覆盖引导测试（CGT）因其系统化的框架优势，被广泛应用于识别模型中的错误或意外行为。然而，现有的CGT研究从方法论上仍然呈现碎片化的状态，这限制了当前发展和新兴趋势的理解。本研究通过全面回顾最先进的CGT方法对深度学习模型的应用，旨在填补这一缺口，旨在包括测试覆盖分析，覆盖引导的测试输入生成和优化等方法，并基于方法论特性及应用场景提供了详细的分类。此外，还调查现有研究中的评估实践，包括数据集，模型架构以及评估维度的使用情况。最后，指出了结构覆盖与测试目标之间的关系，方法在任务和模型间的一般化能力，实际部署中的关注点，以及标准化评估与工具支持的迫切需要等开放挑战和未来方向。本研究旨在为未来学术研究与工程实践提供质量保证的路线图。", "innovation": "通过全面回顾最先进的CGT方法对DL模型的应用，提供了方法论和应用场景的分类；调查了现有研究中的评估实践；指出了未来研究的方向与开放挑战，为学术研究与工程实践提供指导。", "conclusion": "本研究指出了结构覆盖与测试目标之间的关系，方法在任务和模型间的一般化能力，实际部署中的关注点，以及标准化评估与工具支持的迫切需要。这为未来的学术研究与工程实践提供了质量保证的路线图。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.24119", "html_url": "https://arxiv.org/abs/2506.24119", "title": "SPIRAL：通过多轮多智能体强化学习在零和游戏中自我对弈激励推理", "title_en": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "authors": "Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques", "background": "近年来，强化学习的进步表明，通过对具有可验证奖励的任务进行训练，语言模型可以发展出复杂的推理能力，但这种方法依赖于人类精心编写的问答对以及特定领域的奖励工程。这些限制使得开发一种无需人类监督的人工智能系统变得困难。SPIRAL框架旨在解决这一问题，通过自我对弈的方式，模型能够不断与不断改进的自身版本进行对战，从而产生一个逐步挑战性的学习课程，不再需要人类的直接指导。为了实现这种大规模的自我对弈训练，SPIRAL还实现了一个完全在线的多功能强化学习系统，并提出了角色条件优势估计（RAE）来稳定多智能体训练。这些自我对弈的训练结果表现出类比推理能力，可以广泛转移。通过单一零和博弈（如Kuhn扑克）的训练，在数学和一般推理上分别提高了8.6%和8.4%，且优于通过大量专家游戏轨迹的训练得出的策略。进一步分析表明，这种转移是通过系统分解、预期价值计算和案例分析三种认知模式实现的。通过多博弈训练（如井字棋、Kuhn扑克、简单谈判博弈）进一步提升性能，每个游戏的独有推理优势得到了进一步的发展。应用SPIRAL框架到一个强大的推理模型中可以使其实现2.0%的平均改进。这些结果证明了零和博弈天然能够培养可转移的推理能力，为自主推理能力的发展提供了一种新的有前景的方向", "innovation": "SPIRAL框架通过自我对弈的方式，让模型与不断改进的自身版本进行对战，从而产生一个逐步挑战性的学习课程，不再需要人类的直接指导。为实现大规模自我对弈训练，SPIRAL还实现了一个完全在线的多功能多轮多智能体强化学习系统，并提出了角色条件优势估计（RAE）来稳定多智能体训练。这些机制使得模型能够在零和游戏中更好地发展并转移推理能力，同时保持稳定的学习过程。", "conclusion": "零和博弈在自然条件下的推理能力培养为自主推理能力的发展提供了一条有前景的方向。通过SPIRAL框架，模型能够在自我对弈中学习并迁移复杂推理能力，从而摆脱对外部复杂任务设计的依赖。"}
{"llm_update_time": "20250702", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17064", "html_url": "https://arxiv.org/abs/2506.17064", "title": "使用图嵌入的潜在扩散生成完整原子蛋白构象", "title_en": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings", "authors": "Aditya Sengar,Ali Hariri,Daniel Probst,Patrick Barth,Pierre Vandergheynst", "background": "当前，为了理解动态蛋白质如GPCRs的功能，生成多样化的全原子构象集是非常关键的，但大多数生成模型却简化了原子细节或完全忽略了构象多样性。为了填补这一空白，我们介绍了从分子动力学轨迹直接生成完整全原子蛋白质结构的方法，即latent diffusion for full protein generation (LD-FPG)。该方法利用Chebyshev图神经网络（ChebNet）获取蛋白质构象的低维潜在嵌入，并通过三种聚类策略——盲法、顺序和残基基于——进行处理。该扩散模型在这些潜在表示上进行训练并生成新的样本，一个解码器随后将这些样本映射回笛卡尔坐标。使用D2R-MD数据集，证明了顺序和残基基的聚类策略能够保持高水平的结构保真度（所有原子lDDT约为0.7；C-α-lDDT约为0.8），且二面角分布的Jensen-Shannon散度小于0.03，这都与分子动力学数据相符。从而为大型蛋白质提供了一种实际的全原子构象集生成方法，这是一种有望用于基结构的复杂、动态靶标治疗设计的有效工具。D2R-MD数据集和我们的实现对进一步的研究都是免费可用的。", "innovation": "提出了latent diffusion for full protein generation (LD-FPG)框架，利用Chebyshev图神经网络获得低维度的潜在嵌入，通过三种特定的聚类策略处理这些嵌入，生成具有高结构保真度的全原子蛋白质构象，并且其中顺序或残基基于的聚类策略能够恢复二面角分布，展现出潜在扩散方法在生成完整原子构象集方面的创新性。", "conclusion": "LD-FPG为生成特定系统的大蛋白质全原子构象集提供了一种实用途径，对于结构基治疗设计具有重要意义。D2R-MD数据集和我们的实现也已经开放提供，有助于进一步的研究。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00352", "html_url": "https://arxiv.org/abs/2507.00352", "title": "基于AST引导的LLM方法在SVRF代码合成中的应用", "title_en": "An AST-guided LLM Approach for SVRF Code Synthesis", "authors": "Abanoub E. Abdelmalak,Mohamed A. Elsayed,David Abercrombie,Ilhami Torunoglu", "background": "标准验证规则格式（SVRF）对于半导体应用如设计规则检查（DRC），布局与电路图比对（LVS），光学邻近效应校正（OPC）至关重要。随着工艺节点的推进，设计规则变得复杂，导致传统SVRF开发变得无效，存在技术空白。本文讨论了这一背景问题及挑战。", "innovation": "本文提出了一种新的方法，结合抽象语法树（AST）嵌入和检索增强生成（RAG），用于增强SVRF代码合成。该方法通过引入特定领域的结构验证，确保语义准确性和错误最小化，从而实现精确的代码生成。此外，提出了一个新颖的SVRF特定评分框架，补充了标准的BLEU和ROUGE-L等度量标准。该方法通过结构验证和领域知识的融合，提高了代码生成的工作效率，确保了代码生成的准确性。", "conclusion": "在740个DRC规则实现的基准测试上，该方法展示了与基本文本微调过程相比，可提高高达40%的代码生成准确性。这种方法不仅在数据集受限的情况下优化了SVRF开发，还创建了一个更直观和高效的工作环境。最终用户可以快速迭代设计周期，减少手动错误纠正，并显著提高整体生产力。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00803", "html_url": "https://arxiv.org/abs/2507.00803", "title": "朝九晚五之外：软件工程课程共同设计与交付中的行业实践者视角", "title_en": "Out of the Day Job: Perspectives of Industry Practitioners in Co-Design and Delivery of Software Engineering Courses", "authors": "Gillian Daniel,Chris Hall,Per Hammer,Alec-Angus Macdonald,Hollie Marwick-Best,Emma McKenzie,George Popa,Derek Somerville,Tim Storer", "background": "过去超过二十年里，格拉斯哥大学与工业合作伙伴共同设计并提供了多个专注于软件工程的专业课程，涵盖技术与专业技能。虽然这些合作不在少数，其带来的益处也已在文献中被广泛认可。常见的益处包括课程的现实相关性增强、学生职业网络的提前建立以及改善雇主招聘机会等。然而，文献中却很少有关于参与到课程设计与交付中的行业实践者的视角的研究。忽视这一视角值得注意，因为实践者需要投入大量时间，并且通常需要来自行业合作伙伴和学术机构的持续支持。理解这些参与课程交付的实践者的动机、期望和体验，可以帮助指导未来的合作，并确保其长期可持续性。", "innovation": "本文通过回溯研究，对参与共同设计与交付软件工程课程的行业实践者的视角进行调查。研究者采用学术合著者作为调解人的方法，旨在填补文献中的这一空白。这些实践者的视角对于未来合作的理解和未来合作的成功至关重要，因为他们的积极参与通常需要大量的时间投入以及跨机构的支持。", "conclusion": "本文提出了通过共同设计和交付软件工程课程的实践者的视角与体验建立未来长期可持续合作关系的建议。研究结果为了解如何支持和激励工业实践者继续参与这类合作提供了有效方向。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00481", "html_url": "https://arxiv.org/abs/2507.00481", "title": "HEXACO人格特质对软件团队协作质量的影响——初步研究方法", "title_en": "The Influence of HEXACO Personality Traits on the Teamwork Quality in Software Teams -- A Preliminary Research Approach", "authors": "Philipp M. Zähl,Sabine Theis,Martin R. Wolf", "background": "尽管软件工程研究主要集中在优化工作流程和技术方面，但人们越来越认识到，尤其是团队协作的人力因素对优化方案有着显著的影响。最近的研究表明，开发者的个性特征对团队协作有着强烈的影响力。实际上，个性考虑可能比流程和工具对软件开发的影响更大。因此，本文旨在设计一个研究，以衡量六因素个性特质对软件团队协作质量(TWQ)的影响。初步数据收集(n=54)表明，个性特质本身及其组合都对TWQ产生了显著影响，此外，团队中女性的比例和年龄分布等其他变量也对TWQ产生了影响。初步研究结果证明了研究设计的有效性和合理性，并提出了改进IT组织团队协作的多个机会及进一步的研究方向。", "innovation": "本文设计了一个研究来衡量六因素个性特质对软件团队协作质量(TWQ)的影响，这是将个性考量与团队协作质量之间的关系进行量化研究的一种创新方法。研究表明，个性特质本身及其组合都对TWQ产生了显著影响，这是先前研究的一个重要补充，揭示了在IT组织中提高团队协作质量的一种新的可能途径。", "conclusion": "初步研究表明，六因素个性特质及其组合、团队中女性的比例和年龄分布等因素都对软件团队协作质量(TWQ)产生了显著影响，这证明了研究设计的有效性和合理性。研究还提出了许多改进IT组织团队协作的方法，并为未来的研究提供了新的方向。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00788", "html_url": "https://arxiv.org/abs/2507.00788", "title": "AI回声：探究AI辅助对软件可维护性的影响", "title_en": "Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability", "authors": "Markus Borg,Dave Hewett,Nadim Hagatulah,Noric Couderc,Emma Söderberg,Donald Graham,Uttam Kini,Dave Farley", "background": "AI助手，如GitHub Copilot和Cursor，正在改变软件工程领域。尽管已有研究指出生产率的提升，但它们对软件维护性的影响仍需进一步探索。", "innovation": "本文研究了使用AI助手进行合作开发是否会影响软件的可维护性，具体考察了其他开发人员轻松修改源代码的程度。研究通过两阶段的控制实验，包含151名参与者，其中95%为专业开发人员，第一阶段参与者在有或没有AI辅助的情况下为Java网络应用添加新功能；第二阶段则是随机对照试验，新参与者在不做AI辅助的情况下演化这些解决方案。研究发现，AI辅助开发在第一阶段适度提高了后续演化速度，并提升了平均CodeHealth，特别是在习惯使用AI的用户中显著提高。此外，研究还验证了之前关于生产力的发现：使用AI助手的任务完成时间中位数减少了30.7%，习惯使用AI的用户平均速度提高了55.9%。研究结果表明AI助手能够有效加速开发过程，且未观察到代码质量降级的迹象，但建议未来研究警惕过度代码生成带来的代码膨胀和认知债务积累等风险。", "conclusion": "研究扩大了对AI助手能够有效加速开发的现有证据，未发现代码层面维护性退化的迹象。建议未来研究关注诸如过度代码生成引起的代码膨胀和认知债务积累等风险。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00686", "html_url": "https://arxiv.org/abs/2507.00686", "title": "一种从物联网传感器流中检测过程活动的领域特定语言和架构", "title_en": "A Domain-specific Language and Architecture for Detecting Process Activities from Sensor Streams in IoT", "authors": "Ronny Seiger,Daniel Locher,Marco Kaufmann,Aaron F. Kurz", "background": "现代物联网(IoT)系统配备了各种传感器，提供关于其组件当前操作的实时数据，这对于系统的内部控制系统和过程至关重要。然而，这些数据通常过于详细，不能直接提供有关IoT系统可能参与的更大过程执行的有用见解。流程挖掘已经发展出用于分析企业流程的高级方法，这些方法也可以应用于IoT领域。但是，将流程挖掘与IoT结合需要对低级传感器数据进行抽象化，以提升到业务流程级别。本研究旨在通过一种新的领域特定语言（DSL）Radiant，帮助领域专家进行这一抽象步骤。Radiant 支持在传感器数据中指定表示更高层次活动执行的模式，并将其转换为复杂的事件处理（CEP）应用程序，在运行时检测活动执行。利用这种软件架构，评估了 IoT 感应器在智能制造和智慧医疗中的活动执行监控，以验证质量并提出改进潜力。", "innovation": "本文提出的创新之处在于开发了一种领域特定语言（DSL）Radiant，该语言可以被领域专家用来从低级别的传感器数据中抽象出高层次的业务流程活动。通过将确定的模式转换为复杂事件处理（CEP）应用程序，使得领域专家可以在物联网系统的运行时监测活动的执行情况。同时，设计了一个在线事件抽象的软件架构，用于监控IoT传感器流中的活动执行。这种架构和方法能够帮助进一步提升IoT系统的性能和效率，尤其是在智能制造和智慧医疗等领域。", "conclusion": "对于IoT传感器流中活动执行的监测，通过提出的Radiant领域特定语言和结构化的软件架构，可以有效提升监测的质量和效率。测试结果显示，该方法对于智慧制造和智慧医疗的活动检测准确度较高，并提供了进一步改进的潜力。因此，这种方法可以在更多的IoT应用中广泛推广使用。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00264", "html_url": "https://arxiv.org/abs/2507.00264", "title": "Rust vs. C for Python Libraries: 评估兼容 Rust 的绑定工具链", "title_en": "Rust vs. C for Python Libraries: Evaluating Rust-Compatible Bindings Toolchains", "authors": "Isabella Basso do Amaral(1),Renato Cordeiro Ferreira(1,2,3,4),Alfredo Goldman(1) ((1) University of São Paulo, (2) Jheronimus Academy of Data Science, (3) Technical University of Eindhoven, (4) Tilburg University)", "background": "Python 编程语言以其语法和科学库最为人所知，但也因其慢速解释器而臭名昭著。优化 Python 中的关键部分需要特别了解编程语言之间的二进制交互，并且手动接口可能很棘手，开发者常常不得不使用复杂的第三方库。这篇文章通过比较 PyO3 Python 绑定工具链、ctypes 和 cffi 的性能和易用性，评估了使用 Rust 工具实现 Python 库的能力，同时无需担心 API 兼容性问题。", "innovation": "使用 Rust 工具实现 Python 库，通过开发的 Rust 工具链，能够达到顶尖性能，且无需担心 API 兼容性问题；并通过将性能与易用性进行比较，来验证不同绑定工具链的优势。", "conclusion": "研究发现，使用 PyO3 Python 绑定工具链可以实现与 C 相媲美的高性能，并且具有更好的易用性。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00057", "html_url": "https://arxiv.org/abs/2507.00057", "title": "LLM 基础代码生成中无需或acular的正确性估计", "title_en": "Estimating Correctness Without Oracles in LLM-Based Code Generation", "authors": "Thomas Valentin,Ardi Madadi,Gaetano Sapia,Marcel Böhme", "background": "大型语言模型（LLMs）在从自然语言规范生成代码方面取得了巨大的成功。然而，这些模型会‘胡言乱语’，即它们生成的输出虽然语法正确，但事实错误。在没有已有的正确实现（即 oracle）的情况下，如何量化生成程序的正确性？本研究旨在提出一种无需 oracle 的不一致度（incoherence）测量方法，以此评估生成代码的正确性下限，从而提高生成代码的准确性。实验结果显示，不一致度方法在平均生成代码任务中可以自动识别大约三分之二的错误代码，且没有误报。进一步分析表明，通过 oracle 评估 LLM 的方法可以被不一致度评估可靠地替代，并且基于 oracle 的 LLM 排名与基于不一致度的方法得出的排名高度一致。", "innovation": "本研究提出了一个不依赖于 oracle 的不一致度测量方法，该方法能够有效评估生成代码的正确性下限。此外，该方法还能可靠地替代 oracle 方法进行 LLM 的评估，表明其在提高代码生成准确性方面具有显著优势。进一步实现了基于 oracle 和基于不一致度的 LLM 排名高度一致，证明了该方法的可靠性和有效性。", "conclusion": "通过不一致度方法可以有效地评估生成代码的正确性，无需依赖 oracle，且在实践中取得了极高的准确性和可靠性。这种方法能够显著提高 LLM 在代码生成应用中的性能，为自然语言规范生成代码提供了一种新的可靠评估手段。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00699", "html_url": "https://arxiv.org/abs/2507.00699", "title": "多层次且可进化的多层次多轮反馈细粒度代码指令跟随基准", "title_en": "A Hierarchical and Evolvable Benchmark for Fine-Grained Code Instruction Following with Multi-Turn Feedback", "authors": "Guoliang Duan,Mingwei Liu,Yanlin Wang,Chong Wang,Xin Peng,Zibin Zheng", "background": "大规模语言模型（LLMs）在代码生成方面取得了显著进展，但它们遵循复杂编程指令的能力，特别是涉及多层和多样化约束的能力，仍没有得到充分探索。现有基准测试更多关注功能正确性，而忽略了实际开发中复杂的要求。该研究提出了MultiCodeIF，一个全面的基准测试，用于从多个维度（约束类型、层级水平和迭代优化）评估代码生成的指令跟随能力。该基准测试基于9类和27种约束类型的结构化分类构建，能够对功能和非功能指令遵循进行全面评估。通过自动管道ConstraGen，生成和演进2,021个代码任务，支持通过反馈驱动的任务变体进行多轮评价。实证研究发现，大型语言模型之间存在显著的性能差异，顶级模型Claude-3-7-Sonnet的平均约束满足度为63.0%，而较小的模型如Qwen3-1.7B仅为44.8%。模型在显式约束上表现良好，但在隐式或抽象约束上表现不佳，多层约束任务显著降低了模型的成功率，从单层的54.5%下降到多层场景下的18.8%。然而，结构化反馈能够促进逐步改进，平均约束满足度在四个迭代环节中从63.0%提高到83.4%。MultiCodeIF提供了一个可扩展、约束感知和反馈敏感的框架，用于在实际代码生成场景中基准测试LLMs，填补了合成评估和实际指令复杂性之间的差距。", "innovation": "该研究通过构建多层次且可进化的多层次多轮反馈细粒度代码指令跟随基准MultiCodeIF，填补了现有评估方法的空白，特别是针对多层和多样化约束的代码生成能力。基准测试基于9类和27种约束类型的结构化分类，能够对功能和非功能指令遵循进行全面评估。通过自动管道ConstraGen，生成和演进大量代码任务，支持多轮评价，发现不同规模的语言模型在多层约束上的表现存在显著差异。此外，结构化反馈有助于模型在多轮评价中逐步改进。", "conclusion": "MultiCodeIF提供了一个可扩展、约束感知和反馈敏感的框架，用于在实际代码生成场景中基准测试大规模语言模型，填补了现有评估方法与实际指令复杂性之间的差距，为改进语言模型的指令遵循能力提供了新的评估工具。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00014", "html_url": "https://arxiv.org/abs/2507.00014", "title": "SWE-Bench-CL: 持续学习在编程代理中的应用", "title_en": "SWE-Bench-CL: Continual Learning for Coding Agents", "authors": "Thomas Joshi,Shayan Chowdhury,Fatih Uysal", "background": "大型语言模型（LLMs）在静态代码生成基准测试中已取得令人印象深刻的结果，但实际的软件开发活动是一个不断变化的问题、修复和功能需求的连续流。这要求开发代理能够积累经验、在任务间转移知识并防止灾难性遗忘。有鉴于此，我们提出了SWE-Bench-CL，这是一个基于OpenAI和Princeton-NLP在2024年引入的人工审查SWE-Bench Verified数据集的新型持续学习基准。该基准通过有序组织GitHub问题，反映自然仓库的演变过程，可以直接评估代理的能力。此外，还补充了任务间结构相似性和语境敏感性的初步分析、以LangGraph为基础的交互式评估框架（包含FAISS后端的语义记忆模块）以及适应连续学习的一系列专门指标，这些指标能够捕捉稳定性和可塑性之间的权衡。", "innovation": "我们提出了SWE-Bench-CL，这是一个基于OpenAI和Princeton-NLP的人工审查数据集构建的新型持续学习基准，通过有序化GitHub问题流来反映自然仓库的演变过程。此外，还结合了任务间结构相似性分析、交互式LangGraph评估框架、FAISS后端的语义记忆模块，以及专门的持续学习指标，包括平均准确率、遗忘度、前后向迁移、工具使用效率，以及适应连续学习的综合评分和CL-F-beta评分，从而真实地评估代理在软件开发中的表现。所有代码和数据都已在公开仓库提供，为软件工程中的更适应和更鲁棒的人工智能代理的开发提供了可重复的平台。", "conclusion": "我们设计了一套严格的实验协议，比较了记忆能力开和不开的代理在不同Python仓库的表现。所有的代码和数据都在公开仓库提供，以便整个社区可以在此基础上进行可重复的研究，开发更加适应和鲁棒的AI代理。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00786", "html_url": "https://arxiv.org/abs/2507.00786", "title": "Snaps: 拖慢和过时？", "title_en": "Snaps: Bloated and Outdated?", "authors": "Jukka Ruohonen,Qusai Ramadan", "background": "Snap是Canonical开发的一种替代软件打包系统，并默认集成在Ubuntu Linux发行版中。考虑到多种Linux发行版及其不同的发行版本，Snap允许软件能够直接兼容地交付给用户。然而，关于Snap的批评声也经常出现。该论文揭示了目前分发的Snap包确实在平均大小和更新频率方面存在冗余和过时的问题。", "innovation": "通过实证观察，该论文为软件打包、软件包和包管理的研究领域做出了贡献，特别是在指出Snap包普遍存在的冗余性和过时性方面。", "conclusion": "目前分发的Snap包在大小和更新频率方面存在冗余和过时的问题。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00595", "html_url": "https://arxiv.org/abs/2507.00595", "title": "The Secrets Must Not Flow: Scaling Security Verification to Large Codebases (extended version)", "title_en": "The Secrets Must Not Flow: Scaling Security Verification to Large Codebases (extended version)", "authors": "Linard Arquint,Samarth Kishor,Jason R. Koenig,Joey Dodds,Daniel Kroening,Peter Müller", "background": "现有的程序验证器可以证明安全协议实现中高级的安全属性，但由于需要大量的手工努力，难以扩展到大型代码库中。", "innovation": "开发了一种名为Diodon的新方法论，通过将代码库分为协议实现（核心）和其余部分（应用程序），以解决这一挑战。这种方法允许我们应用强大的半自动化验证技术来验证安全关键的核心，同时完全自动化的静态分析通过确保应用程序不会破坏核心的安全属性，将验证扩展到整个代码库。静态分析通过证明I/O独立性来实现这一点，即应用程序的I/O操作与核心的安全相关信息（如密钥）无关，并且应用程序满足核心的要求。通过首先证明可以安全地允许应用程序在其安全协议独立的情况下进行I/O操作，然后证明手动验证和静态分析的稳健组合。", "conclusion": "Diodon在两个案例研究中得到了评估：实现签名的Diffie-Hellman密钥交换和一个大型（100k+ 行代码）生产Go代码库，该代码库实现了一个密钥交换协议，我们通过验证约1%的代码来获得机密性和注入性一致性保证，验证过程在不到3个月的人员时间内完成。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.11013", "html_url": "https://arxiv.org/abs/2506.11013", "title": "为量子软件工程制定巴西研究议程：一项系统映射研究", "title_en": "Toward a Brazilian Research Agenda in Quantum Software Engineering: A Systematic Mapping Study", "authors": "Filipe Fernandes,Cláudia Werner", "background": "量子软件工程（QSE）作为一种新兴学科，通过整合量子计算原理与传统的软件工程实践，旨在支持量子应用程序的开发。然而，QSE仍然缺乏标准化的方法、工具和指南，尤其是在某些发展中经济体中，如巴西，其在这一领域的发展滞后。", "innovation": "本研究通过系统地映射QSE领域的现状，识别研究趋势、贡献和缺口，提出了一项巴西的QSE研究议程，旨在指导国家努力并促进建立强大的本地科学社区。这项研究的独特之处在于其强调了实证研究的必要性，并提出了具体的巴西研究方向，填补了这一领域的一项重要空白。", "conclusion": "QSE是一个正在发展的领域，需要标准化、更多实证研究和来自发展中国家更大的参与来推动其前进。本研究的主要贡献在于提出了巴西QSE研究议程，以指导国家努力并促进建立强大的本地科学社区。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.06946", "html_url": "https://arxiv.org/abs/2506.06946", "title": "在医疗保健领域将流水线生产化：面临的挑战与经验教训", "title_en": "Making a Pipeline Production-Ready: Challenges and Lessons Learned in the Healthcare Domain", "authors": "Daniel Angelo Esteves Lawand(1),Lucas Quaresma Medina Lam(1),Roberto Oliveira Bolgheroni(1),Renato Cordeiro Ferreira(1,2,3,4),Alfredo Goldman(1),Marcelo Finger(1) ((1) University of São Paulo, (2) Jheronimus Academy of Data Science, (3) Technical University of Eindhoven, (4) Tilburg University)", "background": "将机器学习（ML）训练管道部署到生产环境中需要良好的软件工程实践。然而，典型的数据科学工作流程通常会导致代码缺乏重要的软件质量属性。本文通过SPIRA项目的研究，探讨了将ML-Enabled System（MLES）用于预诊断呼吸不足的问题，该项目旨在通过语音分析进行新生呼吸不足的诊断。SPIRA项目的三个版本反映了从概念验证的大球泥代码（v1）到基于设计模式的模块化巨石架构（v2），再到基于测试驱动的微服务架构（v3）的发展过程。", "innovation": "通过将MLES（从模块化巨石架构到基于测试驱动的微服务架构）的连续训练子系统的三个版本进行比较，展示了如何逐步改进系统的扩展性、可维护性、稳定性和韧性。这一过程中的挑战和经验教训对于寻求将其管道生产化的研究人员和实践者提供了宝贵的洞见。", "conclusion": "每个版本在扩展性、可维护性、健壮性和韧性方面都有所提高，详细分享了这一过程中的挑战和收获，并为其他在医疗保健领域寻求生产化流水线的学者和从业者提供了实践指导。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.11620", "html_url": "https://arxiv.org/abs/2502.11620", "title": "通过不确定性估计评估基于LLM的代码生成的正确性", "title_en": "Assessing Correctness in LLM-Based Code Generation via Uncertainty Estimation", "authors": "Arindam Sharma,Cristina David", "background": "本文探讨了使用不确定性估计作为LLM生成代码正确性的代理。在过去的工作中，不确定性估计在自然语言生成任务中得到了广泛应用，但尚未直接应用于代码生成领域。代码具有独特的语义特性，需要特殊的方法来评估其正确性。研究者在现有的基于熵和互信息的技术基础上，为代码生成任务进行了适应性改进，并引入了基于符号执行的语义等价性检查。这些方法被用来评估模型生成代码的不确定性，从而预测其正确性。此外，简化了基于熵的方法的实现，证明了其在假设LLM响应的均匀分布下仍然具有可比的有效性.", "innovation": "本文提出将不确定性估计方法应用于判断LLM生成代码的正确性。具体创新包括：1) 将基于熵和互信息的两个自然语言生成领域的领先技术改编用于代码生成；2) 针对代码的语义特性和独特性质，引入基于符号执行的语义等价性检查；3) 开发了基于不确定性估计的避免政策，限制模型在高不确定性情况下不进行预测，从而大幅减少了错误输出；4) 使用简化版本的熵方法，并展示了其有效性；5) 通过LiveCodeBench评估，表明本文方法明显优于仅依赖LLM报告的对数概率的基线方法", "conclusion": "研究表明，通过不确定性估计技术可以有效地评估基于LLM的代码生成质量，并且简化版本的方法也显示出良好的效果。此外，作者提出的方法通过限制在高不确定性情况下的预测，有效减少了错误输出，显著提高了生成代码的正确性，尤其在LiveCodeBench上的评估中表现出了显著优势。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.00322", "html_url": "https://arxiv.org/abs/2507.00322", "title": "故障干扰：当错误机制压倒正确机制时语言模型在生成平衡括号中的错误", "title_en": "Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones", "authors": "Daking Rai,Samuel Miller,Kevin Moran,Ziyu Yao", "background": "尽管编码能力取得了显著进步，语言模型（LMs）在生成平衡括号等基本语法任务上仍存在困难。这些模型依赖于多种组件（注意力头和前向神经元）进行独立预测。一些组件能够稳定地提供正确答案，而另一些则是不稳定的，会产生错误的预测，整体上模型的性能受到这些错误机制的影响。", "innovation": "该研究引入了一种名为RASteer的控制方法，用于系统地识别并增加可靠组件的贡献，以提升模型性能。这种控制方法在平衡括号任务上表现出显著提升效果，某些模型的准确性从0%提高到约100%，且不会损害模型的一般编程能力。研究还展示了RASteer在算术推理任务上的广泛适用性，实现约20%的性能提升。", "conclusion": "研究揭示了LMs中的正确和错误机制，并提出了RASteer方法，该方法通过增加可靠组件的比例，有效提升了模型在括号生成任务上的表现，并在算术推理测试中也取得了较好的效果。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2501.09310", "html_url": "https://arxiv.org/abs/2501.09310", "title": "基于上下文学习的文本到SQL错误研究", "title_en": "A Study of In-Context-Learning-Based Text-to-SQL Errors", "authors": "Jiawei Shen,Chengcheng Wan,Ruoyi Qiao,Jiazhen Zou,Hang Xu,Yuchen Shao,Yueling Zhang,Weikai Miao,Geguang Pu", "background": "大型语言模型（LLMs）被应用于执行文本到SQL任务，利用其上下文学习（ICL）能力将自然语言问题转换为结构化查询语言（SQL）。然而，这一技术存在正确性问题，并需要高效的修复解决方案。已有研究在解决这些错误方面效果有限，且高计算开销伴随高误修复率。", "innovation": "本文首次全面研究了文本到SQL错误，并提出了MapleRepair，这是一种文本到SQL错误检测和修复框架，能够更高效地修复错误，成本较低，误修复率较低。通过实验证明，MapleRepair相比现有解决方案修复了更多的查询，并减少了大量计算开销，仅出现可忽略的误修复。", "conclusion": "研究发现文本到SQL错误普遍存在，并总结了7类29种错误类型。现有修复方法在提高正确性方面效果有限，且伴随高计算开销和高误修复率。提出了MapleRepair框架，证明其比现有解决方案更优。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.05975", "html_url": "https://arxiv.org/abs/2408.05975", "title": "低代码科学领域的元科学研究", "title_en": "A Metascience Study of the Low-Code Scientific Field", "authors": "Mauro Dalle Lucca Tosi,Javier Luis Cánovas Izquierdo,Jordi Cabot", "background": "近年来，与建模相关的出版物广泛探讨了建模技术在各个领域的应用。起初，研究集中在UML（统一建模语言）和模型驱动架构上，后来向更通用的概念，如模型驱动开发或工程，转变。最近，'低代码'这一术语因其与多个流行开发平台的关联而风靡建模领域。学术界仍在讨论低代码与先前建模概念之间的差异和共同点，以及低代码对建模领域更广泛的影响。", "innovation": "本文进行了一项关于低代码的元科学研究，采用双管齐下的方法，首先分析低代码社区的组成和增长（如规模、多样性、出版渠道和主题），然后探讨这些方面与传统模型驱动社区的区别，以促使讨论低代码领域当前状态及其未来轨迹，以及低代码与建模社区之间的合作机会和协同作用。", "conclusion": "通过这项研究，希望能激发对低代码领域的讨论，理解其现状和未来方向，并探索低代码与建模社区之间的合作机遇和协同优势。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2411.00442", "html_url": "https://arxiv.org/abs/2411.00442", "title": "在软件和硬件实现中揭示浮点累积顺序", "title_en": "Revealing Floating-Point Accumulation Orders in Software/Hardware Implementations", "authors": "Peichen Xie,Yanjie Gao,Yang Wang,Jilong Xue", "background": "累积操作，如求和和矩阵乘法，是许多计算领域中的基本操作。然而，这些累积操作的具体累积顺序在现有软硬件实现中经常未被记录，这使得开发者难以确保不同系统之间的一致性结果。为了解决这一问题，论文介绍了一种名为FPRev的诊断工具，该工具通过数值测试非侵入性地揭示软件和硬件中的累积顺序。通过使用FPRev，开发者可以识别和比较累积顺序，从而创建可再现的软件并验证实现的等价性。", "innovation": "提出了FPRev，一种非侵入性的测试工具，通过分析针对特制输入测试实现的输出，来揭示软件和硬件中累积操作的具体顺序。该工具在CPU和GPU（包括具有专用矩阵加速器如张量核心的GPU）上展示了流行库（如NumPy和PyTorch）的累积顺序。此外，论文还通过广泛的实验验证了FPRev的高效性，其时间复杂性低于基本解决方案。FPRev被开源，并附有链接。", "conclusion": "论文通过提出FPRev工具，成功揭示了软件和硬件实现中的浮点累积顺序。这有助于开发者确保不同平台之间的结果一致性，并通过非侵入性测试有效识别不同的累积顺序。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.07330", "html_url": "https://arxiv.org/abs/2503.07330", "title": "基于YOLO的物体检测模型中抑制幻觉现象：重新审视离群值检测", "title_en": "Mitigating Hallucinations in YOLO-based Object Detection Models: A Revisit to Out-of-Distribution Detection", "authors": "Weicheng He,Changshun Wu,Chih-Hong Cheng,Xiaowei Huang,Saddek Bensalem", "background": "物体检测系统必须可靠地感知目标对象，同时避免过度自信，以确保动态环境中的安全决策。通过基于离群值检测（Out-of-Distribution, OoD）的筛选技术通常可以作为额外的保障，用于过滤由对新型物体过度自信引起的幻觉。然而，现有YOLO家族检测器及其过滤器在OoD基准测试下的表现往往不尽如人意，主要原因在于现有OoD基准数据集的不准确性，这导致了性能评估的不精确。现有研究缺乏对检测器和过滤器性能瓶颈的根本原因进行深入分析，以及缺乏有效的、联合的检测和过滤方案来降低幻觉误差率。", "innovation": "第一，重新评估了现有的离群值检测结果，并发现现有OoD基准数据集中的图片实际上包含约13%的归一分布（In-Distribution, ID）类别中的真实物体，这可能导致过滤器决策边界的误判。第二，提出了一个全新的方法论来减少幻觉，将检测和过滤视为联合工作流程。通过精心构建一个与要检测的对象具有语义相似性的离群值数据集，来一次性的在YOLO检测器中进行微调，以抑制物体得分，从而显著降低了总体幻觉误差率。", "conclusion": "通过上述方法，作者在自动驾驶基准数据集BDD-100K中实现了88%的幻觉错误率降低，在联合微调检测器和过滤系统中取得了显著的性能提升，证明了其方法的有效性和实用性。"}
{"llm_update_time": "20250702", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.23452", "html_url": "https://arxiv.org/abs/2505.23452", "title": "从移动应用评论中细粒度情感提取，我们关注的是什么？", "title_en": "What About Emotions? Guiding Fine-Grained Emotion Extraction from Mobile App Reviews", "authors": "Quim Motger,Marc Oriol,Max Tiessler,Xavier Franch,Jordi Marco", "background": "情感分析在用户反馈分析和文本数据洞见提取中发挥着关键作用。多数研究集中在情感极性（例如，积极、消极、中性）的分析上，但在移动应用评论中的细粒度情感分类则尚未充分探索。细粒度的情感分类能够更好地理解用户的情感反应，支持功能情感分析、面向用户的发布规划以及问题排查等工作。因此，本研究针对移动应用评论中的情感细粒度分析面临的具体挑战进行了研究，旨在填补这一研究空白，并通过开发结构化的注释框架和数据集来调整普尔钦克的情感分类学理论。", "innovation": "本研究采用普尔钦克的情感分类学理论，开发了一个结构化的标注框架和数据集，通过迭代的人工标注过程制定了明确的注释指南，并指出了情感分类中的关键挑战。此外，研究评估了使用大型语言模型自动化情感标注的可行性和成本效益，并与人工标注数据进行了对比。研究结果表明，大型语言模型在大幅减少人工努力和保持与人工标注者的显著一致性方面表现出色，但这并不能解决情感解读复杂性带来的问题，因此仍存在完全自动化的挑战。该研究为需求工程中的意见挖掘提供了结构化指南、标注数据集和开发自动化管道以捕捉应用评论中情感复杂性的见解。", "conclusion": "虽然大型语言模型在减少人工努力和保持与人类标注者的高一致性方面表现出色，但完全自动化的情感分析仍面临挑战，原因在于情感解释的复杂性。本研究通过提供结构化指南、标注数据集和开发捕捉应用评论中情感复杂性的自动化管道的见解，推进了意见挖掘的发展。"}
