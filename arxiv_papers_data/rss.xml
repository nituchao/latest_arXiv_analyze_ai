<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Arxiv Papers Analyze AI</title><link>https://github.com/nituchao/latest_arxiv_analyze_ai</link><description>Arxiv papers analyzed by AI on 20250626</description><lastBuildDate>Thu, 26 Jun 2025 17:48:27 +0800</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>1. cs.SE-科学工作流系统开发中的实证研究</title><link>https://arxiv.org/pdf/2411.10890</link><description>Background: 
科学工作流系统（SWSs）是先进的软件框架，通过协调复杂的计算任务和管理大量数据管道来驱动现代研究。这些系统提供了模块化、抽象化、互操作性、工作流组合工具、资源管理、错误处理和全面文档等功能。利用这些框架可以加快科学计算的发展，提高研究结果的效率和可重复性。然而，开发一个用户友好、高效且灵活的SWS面临着多重挑战。本文通过深入分析Stack Overflow和GitHub上的开发者和研究人员的互动，探讨这些挑战。利用BERTopic进行主题建模，了解SWS开发者讨论的主题，并识别出开发中最困难的方面。研究发现，工作流执行是最具挑战性的。通过分析GitHub issues，识别了13个主题，其中数据结构和操作是最难解决的。此外，研究还发现SO和GitHub上存在一些共通的话题，如数据结构和操作、任务管理、工作流调度，并将每个话题按类型归类（How, Why, What, Others），发现How类型在所有话题中占主导地位，表明开发者需要程序化指导。How类型的主导也出现在诸如聊天机器人和移动开发等领域。本文的研究将指导未来的研究，提出工具和技术，帮助社区克服在开发SWSs过程中的挑战。

Innovation: 
本文通过深入分析Stack Overflow和GitHub上的开发者和研究人员的互动，使用BERTopic进行主题建模，识别出SWS开发中最困难的话题，提出了对工作流执行、错误和修复、文档、依赖性等方面的详细分类和探讨，指出了How类型主题在所有话题中占主导地位，这有助于理解开发者的实际需求。这为未来提出帮助解决SWS开发挑战的工具和技术提供了实证支持和理论依据。

Conclusion: 
本文通过实证研究揭示了科学工作流系统开发过程中面临的主要挑战，并通过分析Stack Overflow和GitHub上的讨论，识别了最困难的话题和类型。该研究为未来提出有助克服这些挑战的工具和技术提供了指导，为改进SWS的发展提供了有价值的见解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.10890</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>2. cs.SE-集成多种软件 artifacts 提升基于大语言模型的 Bug 定位和程序修复</title><link>https://arxiv.org/pdf/2412.03905</link><description>Background: 
由于大语言模型（LLMs）在自动程序修复（APR）方面展现出的潜力，基于大语言模型的方法日益受到关注。这些模型可以通过插入正确的代码或直接生成补丁来修复带错误的方法。然而，大多数基于大语言模型的 APR 方法依赖单一类型的软件信息，未能充分利用不同的软件 artifact。尽管如此，许多基于大语言模型的方法并未探索哪些具体类型的 information 能更好地辅助 APR。因此，解决这一缺口对于推进基于大语言模型的 APR 技术至关重要。

Innovation: 
本文提出了一种名为 DEVLoRe 的方法，该方法利用问题内容（描述和消息）以及堆栈错误跟踪来定位带错误的方法，依赖调试信息和问题内容以及堆栈错误来定位带错误的代码行并生成可行的补丁。研究结果表明，与其他大语言模型方法相比，DEVLoRe 在 Defects4J v2.0 数据集上定位单一和非单一带错误的方法的比例分别达到 49.3% 和 47.6%，并且生成可通过所有单元测试的可行补丁的比例分别为 56.0% 和 14.5%，这表明它比目前最先进的 APR 方法表现更优。此外，还讨论了领先的大语言模型框架是否可以直接应用于其他语言代码，及其模型实施和实验结果已在GitHub 上公开，以便复制验证。

Conclusion: 
通过集成不同类型的软件 artifact，DEVLoRe 成功地展示了对带错误的代码和修复过程的有效性，比现有的 APR 方法有了显著提高。这些结果对未来的 APR 方法改进具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.03905</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>3. cs.SE-MARCO: 多代理代码优化与实时知识集成以提高高性能计算</title><link>https://arxiv.org/pdf/2505.03906</link><description>Background: 
大型语言模型（LLMs）通过代码生成能力已经转变了软件开发，但在高性能计算（HPC）领域的效果仍然有限。HPC代码需要针对并行性、内存效率和架构特定考虑的专门优化，而通用目的的LLMs往往会忽视这些特定要求。因此，作者提出了MARCO（Multi-Agent Reactive Code Optimizer），一个通过专门的多代理架构增强LLM生成代码的新框架，以适应HPC需求。MARCO采用生成代码和性能评估的分离代理，并通过反馈循环逐步优化代码。MARCO的关键创新在于其网络搜索组件，该组件能从最新的会议论文和研究出版物中获取实时的优化技术，填补预训练LLMs的知识空白。

Innovation: 
MARCO的多代理架构和实时知识集成机制，尤其体现在其网络搜索组件能够根据最新的学术成果为代码优化提供即时更新的信息，从而弥补预训练语言模型的知识不足。这一机制在LeetCode 75问题集上的评估中表现突出，相较于Claude 3.5 Sonnet，MARCO平均实现了14.6%的运行时间减少，并且集成网络搜索组件后，相较于基准MARCO系统，性能提高了30.9%。这些结果突显了多代理系统在面对高性能代码生成的特定需求方面的潜力，为其提供了相对细调领域特定模型更加经济实惠的替代方案。

Conclusion: 
MARCO对于解决高性能代码生成的特殊要求具有潜力，通过实时访问最新的知识资源进行了增强，从而显著提高了代码性能。这一框架为HPC领域的语言模型应用提供了一种新的方法，能够在减少成本的同时，改善代码的质量和效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.03906</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>4. cs.SE-具有SLA保证的CodeLLM服务的自适应请求调度</title><link>https://arxiv.org/pdf/2506.19677</link><description>Background: 
代码大型语言模型（CodeLLMs）越来越多地被整合到现代软件开发工作流中，但在资源受限的、自我托管的环境中有效地服务它们仍然是一个显著的挑战。现有的LLM服务系统使用连续批处理以提高吞吐量，但它们依赖于静态批次大小配置，不能适应波动的请求率或异构工作负载，导致频繁的服务级别协议（SLA）违反和不稳定的服务性能。

Innovation: 
我们提出了SABER，一个动态批处理策略，可以根据每请求的SLA可行性进行预测并在实时调整决策。SABER相较于最优的静态配置提高了26%的吞吐量，并减少了45%的延迟变化性，而且这都是无需手动调整或服务重启的。我们的研究表明，具有SLA意识的自适应调度对于实现健壮且高性能的CodeLLM服务至关重要。

Conclusion: 
我们的结果显示，在具有SLA保障的情况下进行自适应调度是实现稳健且高性能CodeLLM服务的关键。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19677</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>5. cs.SE-VulStamp: 使用大型语言模型进行漏洞评估</title><link>https://arxiv.org/pdf/2506.11484</link><description>Background: 
尽管现代漏洞检测工具能够帮助开发者高效地识别众多安全漏洞，但不加选择的修复工作往往会导致额外的开发成本。由于检测出的大量漏洞要么难以利用，要么在实际运营环境中影响较小，因此，需要优化软件开发生命周期中的漏洞评估过程。现有的漏洞评估方法通常依赖于源代码关联的手动描述，但由于描述质量的差异性和意图理解的主观性，这些方法的性能受限。为了应对这一挑战，这论文提出了VulStamp，一种基于意图的框架，通过静态分析和大型语言模型来提取漏洞代码的意图信息，并使用提示调优模型进行漏洞评估。此外，为了缓解不同漏洞类型数据不平衡的问题，VulStamp整合了基于强化学习的提示调优方法来训练评估模型。

Innovation: 
VulStamp框架通过结合静态分析和大型语言模型，自动提取漏洞代码的意图信息，实现了无文本描述的漏洞评估。此外，通过使用强化学习为基础的提示调优方法，解决了不同漏洞类型数据不平衡的问题，增强了评估模型的泛化能力和鲁棒性。

Conclusion: 
本文提出了一种基于意图的漏洞评估框架VulStamp，通过提取漏洞代码的意图信息，结合静态分析和大型语言模型，实现了自动化的漏洞评估。此外，VulStamp还通过集成强化学习方法，提高了模型在不同类型数据上的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.11484</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>6. cs.SE-ReCode: 使用强化学习更新代码API知识</title><link>https://arxiv.org/pdf/2506.20495</link><description>Background: 
大型语言模型（LLMs）在代码生成方面表现出色，但当遇到外部库API频繁更新时，这些模型会表现不佳。这一局限性源于LLMs仅依赖于训练数据中的过时API知识，即使有当前文档可用，也会影响其在动态环境中的可靠代码生成能力。

Innovation: 
我们提出了ReCode（基于规则的强化学习代码更新框架），这是一种创新的框架，它可以模拟人类程序员适应API更改的方式。具体来说，我们构建了一个约2,000个数据条目的数据集来训练LLMs进行基于更新信息的版本迁移。然后，我们引入了一个修改后的字符串相似度度量作为强化学习的奖励机制。我们的实验表明，ReCode在动态API场景下显著提高了LLMs的代码生成性能，尤其是在未见过的任务CodeUpdateArena中。与监督微调相比，ReCode对LLMs的一般代码生成能力影响较小。我们应用ReCode到各种LLMs和强化学习算法（GRPO和DAPO）上，所有这些都实现了性能改进。经过训练后，Qwen2.5-Coder-7B的性能优于32B参数代码指令调整模型和结构相同的推理模型。

Conclusion: 
ReCode在提升LLMs在动态环境下的代码生成性能方面表现优异，并且在监督微调的基础上效果更为稳定。我们开源了ReCode的相关代码。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20495</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>7. cs.SE-软件工程中次要研究中的研究产品：一项系统性映射研究</title><link>https://arxiv.org/pdf/2504.12646</link><description>Background: 
系统性综述（SRs）汇总了科学领域的最新证据，包括软件工程。前人研究的目标是评估SRs中报告研究产品的情况，并提供研究产品的全面列表。研究者通过分析2013年至2023年间发表的537篇次要研究，发现这些研究中只有31.5%包括研究产品。研究表明，研究产品可用性的提高趋势显著，但在2023年，只有62.0%的次要研究提供了研究产品，而仅有30.4%的产品使用永久存储库和数字对象识别码（DOI）进行存储。

Innovation: 
该研究通过系统地回顾和分析较多数量的文献（537篇），提供了关于软件工程领域次要研究中研究产品报告情况的重要数据。研究发现随着时间的推移，研究产品可用性有所增加，但仍然存在显著不足，特别是在永久存储方面较差，只有30.4%的研究使用了永久存储库和DOI进行存储。这为提高软件工程研究的透明度和可重复性提供了新的见解和改进建议。

Conclusion: 
为了增强软件工程研究的透明度和可重复性，建议在次要研究中强制要求公开研究产品。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.12646</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>8. cs.SE-大型语言模型驱动的建筑信息建模中的代码合规性检查</title><link>https://arxiv.org/pdf/2506.20551</link><description>Background: 
建筑信息建模（BIM）中的手动代码合规性检查耗时且容易出错。为了改进这一过程，本文提出了一种利用大型语言模型（LLM）半自动化的新型方法。该方法结合了GPT、Claude、Gemini和Llama等LLM与Revit软件，以理解和解释建筑规范，生成Python脚本，并在BIM环境中执行半自动化合规检查。该研究通过案例研究验证了这种方法的有效性，展示了该系统在减少合规检查时间和提高准确性方面的优势。系统能够自动识别不符合规范的房间尺寸、材料使用和对象放置等问题，并生成可操作的报告。相比传统的手动方法，该系统简化复杂的规范，确保可靠地遵守标准，提供了一种全面、灵活和成本效益高的解决方案，具有广泛的应用前景，特别是在建筑项目的各种规范文档中。

Innovation: 
提出的半自动化方法结合了大型语言模型（如GPT、Claude、Gemini和Llama）与Revit软件，实现在BIM环境中的半自动代码合规性检查。该方法能够处理复杂法规并提高合规检查的准确性，减少了重复任务，简化了复杂的规范，并确保了标准的严格执行。

Conclusion: 
通过这种方式，本文提出了一个全面、灵活且成本效益高的解决方案，可用于BIM环境中的规范检查，具有广泛的适用性，特别适用于建筑项目中的各种规范文档。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20551</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>9. cs.SE-MNN-AECS: 通过自适应核心选择在移动设备上针对LLM解码进行能效优化</title><link>https://arxiv.org/pdf/2506.19884</link><description>Background: 
随着对设备本地大规模语言模型（LLM）推理需求的增长，能源效率已成为主要的关注点，尤其对于受电池限制的移动设备。我们的分析表明，内存绑定的LLM解码阶段主导了能源消耗，但大多数现有工作主要集中在加速预填充阶段，忽视了能源方面的考虑。

Innovation: 
我们引入了自适应能效核心选择（AECS）并且将其集成到MNN中，形成了不需要根权限或操作系统修改的能效版本MNN-AECS。MNN-AECS通过动态选择低功耗CPU核心来减低LLM解码能耗，同时保持解码速度在可接受的减速标准之内。MNN-AECS在5款Android设备和2款iOS设备上使用5款不同大小的流行LLM进行了评估，并且与原始MNN相比，在所有7款设备和4款数据集上平均每设备能耗减少了23%。此外，与其他引擎如TRT-LLM、executorch、mllm和MediaPipe相比，MNN-AECS平均实现了39%到78%的能耗节省和12%到363%的速度提升，

Conclusion: 
MNN-AECS是第一个不需要根权限或操作系统修改的引擎级系统解决方案，能够在不显著影响解码速度的情况下实现LLM解码的能效优化。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19884</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>10. cs.SE-Can Language Models Replace Programmers for Coding? REPOCOD Says 'Not Yet',</title><link>https://arxiv.org/pdf/2410.21647</link><description>Background: 
尽管存在如 CoderEval、DevEval、RepoEval、RepoBench 和 LongCodeArena 等代码生成基准测试，用于评估大语言模型（LLMs）的能力，这些问题仍然没有更好地代表真实的代码编写任务。现有的基准测试通常包含简短的代码片段、合成示例或聚焦于有限规模的仓库，未能充分代表真实的编程情境，因此研究人员开始探索真实的编码任务基准测试，如 REPOCOD，以评估 LLMs 在大规模真实项目中的性能。

Innovation: 
REPOCOD 是一种新的基准测试方法，包含了复杂任务和真实的项目依赖，适用于大规模的 Python 代码生成任务。它通过使用全函数生成任务（来自 11 个流行项目，其中 50.8% 需要仓库级的上下文）以及每个实例下的 314 个开发者编写的测试案例，提高了评估的准确性。此外，研究表明，检索增强生成方法比单纯依赖目标函数依赖的方法效果更好。

Conclusion: 
在 REPOCOD 基准测试中，十个 LLMs 的表现均不理想，最高通过率未超过 30%，这表明当前的 LLMs 仍然难以胜任真实的软件开发任务。因此，需要加强 LLMs 的能力，以辅助开发人员进行实际的软件开发工作。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.21647</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>11. cs.SE-WAFFLE: 使用多模态模型进行自动前端开发的微调策略</title><link>https://arxiv.org/pdf/2410.18362</link><description>Background: 
Web开发涉及将UI设计转化为功能网页，这既对初学者也对经验丰富的开发者具有挑战性，主要原因在于HTML的复杂层级结构和样式。虽然大型语言模型（LLMs）已经在生成源代码方面显示了潜力，但在UI到HTML代码转换方面仍存在两个主要挑战：一是如何有效地向LLMs表示HTML的层级结构；二是如何弥合UI设计的视觉性质与HTML代码的文本格式之间的差距。

Innovation: 
为了应对这些挑战，作者引入了Waffle，这是一种新的微调策略，使用结构感知的注意力机制来提高LLMs对HTML结构的理解，并采用对比学习的微调方法来使LLMs对UI图像的理解与HTML代码对齐。使用Waffle进行微调的模型在我们新提出的基准WebSight-Test和现有的基准Design2Code上显示出更高的HTML匹配度、更高的CW-SSIM、更高的CLIP值和更高的LLEM值，从而优于现有微调方法。

Conclusion: 
微调后的模型在WebSight-Test和Design2Code两个基准测试中表现优异，证明了Waffle策略的有效性，并有效地解决了UI到HTML代码转换中的挑战。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.18362</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>12. cs.SE-CCISolver: 全端检测和修复方法级代码注释不一致</title><link>https://arxiv.org/pdf/2506.20558</link><description>Background: 
代码中的注释作为软件文档的关键基础，有助于开发者有效沟通和理解代码。然而，代码注释不一致（CCI）可能会对软件开发、测试和维护产生负面影响。尽管已有努力减轻这个问题，但现有研究通常依赖于不准确的数据集和不足的解决方案，削弱了其实际效用。

Innovation: 
本研究首先对现有数据集进行了定量分析，发现大量采样的数据被误标记。为应对此数据限制，我们引入了CCIBench，这是一个包含高质量数据的改进数据集，旨在支持方法级CCI方法的训练和评估。此外，我们提出了一个创新的端到端LLM基于框架CCISolver，旨在通过识别和纠正CCI来提高代码质量。全面评估显示，CCISolver在检测任务中的F1分数为89.54%，在修复任务中的GLEU分数相对基线提高了18.84%，并且在人工评估中，其修复成功率0.6533显著超过现有方法。此外，与基线模型相比，CCISolver在实际端到端设置中推理速度提高约36%，证明了其在规模和实际应用中的适用性。

Conclusion: 
CCISolver通过引入CCIBench数据集和创新的端到端LLM框架，显著提高了方法级代码注释不一致（CCI）的检测和修复效果，具备了更高的准确性、改进的速度以及良好的可扩展性，为CCI问题的解决提供了新的有效的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20558</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>13. cs.SE-揭开大型语言模型供应链构成、风险及其缓解措施的面纱</title><link>https://arxiv.org/pdf/2410.21218</link><description>Background: 
大型语言模型（LLMs）在智能和生产力方面产生了重大影响，众多企业将其整合进应用以解决特定领域任务。然而，将LLMs整合到具体场景中是一个系统的过程，涉及多个组件，统称为LLM供应链。全面理解和掌握LLM供应链的构成及其组成之间的关系，对于有效应对各种相关风险至关重要。尽管现有文献探讨了与LLMs相关的各种风险，但在双重视角下系统地描述LLM供应链仍然存在明显的空白。

Innovation: 
本文开发了一种结构化的分类框架，涵盖不同类型的风险、风险行动及其对应的缓解措施，适用于供应链不同参与者和组件。这种框架有助于行业从业者避免潜在的损害和损失，同时给学术研究人员提供了重新考虑现有方法和探索新研究方向的启示。

Conclusion: 
通过对LLM供应链组成的全面回顾，包括其内在风险及其缓解措施，可以帮助行业从业者预防潜在损害和损失，同时也可以启发学术研究人员重新思考现有方法并探索新的研究领域。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.21218</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>14. cs.LG-通过注意力头选择实现细粒度扰动引导</title><link>https://arxiv.org/pdf/2506.10978</link><description>Background: 
最近的指导方法通过干扰扩散模型来引导逆向采样，构建一个隐含的弱模型并向其远离生成。在这些方法中，注意力干扰在不适用分类器自由指导的无条件场景中表现出强大的实证性能。然而，现有的注意力干扰方法缺乏确定干扰应应用于何处的原理性方法，特别是在扩散变换器（DiT）架构中，质量相关的计算分布在多层中。本文研究了注意力扰动的粒度，从层级到单个注意力头，并发现特定的头管理不同的视觉概念，如结构、风格和纹理质量。在这一洞察基础上，我们提出了HeadHunter，一个系统框架，用于迭代选择与用户目标一致的注意力头，实现对生成质量和视觉属性的细粒度控制。此外，我们引入了SoftPAG，这是一种线性插值方法，将其选择的每个头的注意力图向单位矩阵插值，提供了一种连续调整干扰强度并抑制伪影的拨动。该方法不仅缓解了现有层级干扰的过度平滑问题，还通过组合头选择实现了特定视觉风格的精确操控。我们已在现代大型DiT基文本到图像模型中验证了我们的方法，包括Stable Diffusion 3和FLUX.1，展示了在普遍质量提升和风格特定指导方面的优越性能。我们工作的成果首次对注意力干扰在扩散模型中的头级进行了分析，揭示了注意力层内的可解释专业化，并使设计有效干扰策略成为可能。

Innovation: 
我们提出了名为HeadHunter的系统框架，用于迭代选择与用户目标一致的注意力头，实现了对生成质量和视觉属性的精细控制。此外，我们提出了SoftPAG方法，通过线性插值每个选择的头的注意力图向单位矩阵，提供了一种连续调整干扰强度并抑制伪影的手段。我们的方法解决了层级干扰的过度平滑问题，并且能够通过组合头选择实现对特定视觉风格的精确操控。

Conclusion: 
我们的方法在现代大型DiT基文本到图像模型上，展示了在普遍质量提升和风格特定指导方面的优越性能。首次对注意力干扰在扩散模型中的头级进行了研究，揭示了注意力层内的可解释专业化，并为设计有效的干扰策略提供了实际指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.10978</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>15. cs.SE-Define-ML：探讨机器学习启用系统的思路方法</title><link>https://arxiv.org/pdf/2506.20621</link><description>Background: 
随着机器学习（ML）在软件系统中的日益普及，需要特殊的方法来应对ML特有的挑战，如数据依赖性、技术可行性以及业务目标与概率系统行为之间的契合度。传统的思路方法如Lean Inception缺乏对这些ML考虑的结构化支持，可能导致产品愿景不一致和无现实依据的期望。

Innovation: 
本文提出了Define-ML框架，它在Lean Inception的基础上添加了定制化的活动——数据源映射、特征与数据源映射以及ML映射，目的是系统地将数据和技术限制整合到早期的ML产品思路中。该方法通过技术转移模型进行开发和验证，首先是静态验证（使用玩具问题）然后是动态验证（在真实工业案例研究中）。

Conclusion: 
Define-ML提供了开源验证过的ML产品思路方法，结合了Lean Inception的敏捷性，并且与可用数据对齐，增加技术和可行性意识。所有参与者都表示有意向采用Define-ML。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20621</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>16. cs.SE-智能剪枝：通过剔除坏种子增强漏洞检测的主动学习</title><link>https://arxiv.org/pdf/2506.20444</link><description>Background: 
漏洞检测对于识别软件系统中的安全弱点至关重要，但机器学习模型在该领域的有效性往往受到低质量训练数据集的阻碍，这些数据集包含噪点、错误标签或不平衡样本。传统的不确定性驱动抽样方法在解决这一问题方面效果有限，难以系统地识别和减轻难以学习的异常值，即所谓的‘坏种子’，从而影响模型训练效率。

Innovation: 
本文提出了一个新的数据映射赋能的方法，该方法系统地识别和缓解这些难以学习的异常值，通过过滤掉影响性能的样本同时强调信息性样本，来优化模型训练。与传统的基于不确定性采样方法不同，本策略优先考虑数据集质量，通过剔除性能损害样本来提高模型训练效率。实验结果显示，该方法在CodeBERT上相比随机选择提高了45.36%（DeepGini）和45.91%（K-Means）的F1分数，并且在Big-Vul数据集上优于标准主动学习61.46%（DeepGini）和32.65%（K-Means），证明了整合数据映射对于优化样本选择的有效性。此外，该方法还能增强模型的鲁棒性，通过剔除坏种子改善样本选择，稳定迭代过程中的主动学习性能。通过对这些异常值特征的分析，为未来数据集构建提供了见解，使漏洞检测更加可靠和成本效益高

Conclusion: 
通过智能剔除‘坏种子’，本文的方法显著增强了主动学习在外包软件漏洞检测中的效果，展示了集成数据映射对于优化样本选择的有效性，并为未来数据集构建提供了有价值的见解，从而使得漏洞检测更加可靠和经济。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20444</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>17. cs.LG-通过提示、微调及分布外提示评估小型语言模型的泛化能力和内部表示稳定性</title><link>https://arxiv.org/pdf/2506.17289</link><description>Background: 
该研究探讨了在两种流行的语言模型适应范式下小型语言模型的泛化能力：少样本提示（few-shot prompting）和监督微调（supervised fine-tuning）。尽管少样本提示由于其参数效率和灵活性受到青睐，但在资源受限和分布偏移的情况下，其鲁棒性仍是未知数。本文对比分析了通过不同任务格式、提示风格和模型规模实施少样本提示和微调的方法，并重点研究了这两种策略在分布内和分布外（OOD）设置下的行为差异。实验不仅评估了准确度，还分析了每种方法学习的内部表示，以评估任务特定特征的稳定性和抽象性。

Innovation: 
本文提出了一个全面比较少样本提示和微调方法的实验框架，该框架覆盖多种任务格式、提示风格和模型规模。研究特别关注在分布内和分布外设置下的行为差异，并深入分析了每种方法学习的内部表示，以便评估任务特定特征的稳定性和抽象性。研究结果揭示了不同适应策略下小型模型学习和泛化的关键差异，为在数据稀缺的情境下选择合适的模型提供了实用指导，并为提示与微调之间的持续争论提供了实证见解。

Conclusion: 
本文的研究结果强调了不同适应策略对小型模型如何学习和泛化知识的关键影响。该研究不仅在低数据条件下提供了模型选择的实际指导，还为理解提示与微调之间的争论提供了实证洞察。相关实验代码可以在指定的链接中获取。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17289</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>18. cs.LG-Variational Learning Finds Flatter Solutions at the Edge of Stability</title><link>https://arxiv.org/pdf/2506.12903</link><description>Background: 
变分学习（VL）最近在训练深度神经网络方面获得了广泛应用，并且已经能够与标准学习方法竞争。部分实际成功可以归因于如PAC-Bayes边界、最小描述长度和边际似然度这样的理论，但很少有工具能够解析其中隐含的正则化规律。本文旨在通过边缘稳定性（Edge of Stability，EoS）框架来分析变分学习中的隐含正则化规律。此前的研究表明，梯度下降可以找到平坦的解，本文将其结果推广到变分学习，证明了它甚至能够找到更平坦的解，并通过控制后验协方差和后验蒙特卡洛采样的数量实现这一点。作者采用了与标准EoS文献类似的方法，首先对二次问题进行研究，然后将其推广到深度神经网络。实验验证在各种大型网络（如ResNet和ViT）上也取得了理论结果与实验结果的一致性。这是首次研究变分学习中的EoS动态机制的工作。

Innovation: 
通过边缘稳定性（EoS）框架分析变分学习中的隐含正则化规律。证明变分学习能找到比梯度下降更平坦的解，并通过控制后验协方差和后验蒙特卡洛采样的数量实现这一点。首次通过理论与实验一致性验证来研究变分学习中的EoS动态机制，实验包括ResNet和ViT广泛的大型网络。

Conclusion: 
本文首次通过EoS框架来分析变分学习中的隐含正则化规律。结果表明，变分学习可以找到比梯度下降更平坦的解，并且实验结果与理论预测高度一致，这从实验上验证了变分学习的正则化机制。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12903</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>19. cs.SE-系统化文献综述：系统系统的数字孪生组成</title><link>https://arxiv.org/pdf/2506.20435</link><description>Background: 
数字孪生（DTs）在复杂系统建模方面变得越来越重要，特别是在Cyber-Physical Systems (CPS) 和 System-of-Systems (SoS) 中，有效的整合是关键。本文通过系统文献综述探讨了DT的构成及其验证与验证（V&amp;amp;V）方法，主要分析了21篇2022-2024年的研究文献中的构成机制、SoS特征以及V&amp;amp;V的形式、范围和挑战。

Innovation: 
本文对构成机制进行了分析，总结了V&amp;amp;V的方法并且强调了标准化和可扩展的V&amp;amp;V框架对于复杂DT实现的重要性。更为重要的是，本文指出了模型不确定性和整合复杂性等关键技术挑战，并且表明需要超越模型验证的概念，关注整合和网络物理一致性，并强调了需要标准化的构成方法学对于复杂数字孪生实现的需求。

Conclusion: 
本文提供了一个结构化的V&amp;amp;V方法分类，并强调了需要标准化、可扩展的V&amp;amp;V方法以及严格构成方法学，以便有效集成复杂的数字孪生。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20435</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>20. cs.LG-DRO-Augment框架：通过 Wasserstein 分布鲁棒优化和数据增强协同实现鲁棒性</title><link>https://arxiv.org/pdf/2506.17874</link><description>Background: 
在许多实际应用中，确保深度神经网络（DNNs）的鲁棒性和稳定性至关重要，尤其是在遇到各种输入扰动时进行图像分类任务。虽然数据增强技术已被广泛用于增强训练模型对这些扰动的抵御能力，但在同时增强模型对被破坏数据和对抗性攻击的鲁棒性方面仍有很大的改进空间。为了应对这一挑战，本研究引入了DRO-Augment，这是一个将Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略集成的新框架，以显著提高模型在广泛范围内的鲁棒性。该方法在严重数据扰动和对抗性攻击场景下优于现有的增强方法，同时在一系列基准数据集中保持良好的准确率，包括但不限于CIFAR-10-C、CIFAR-100-C、MNIST和Fashion-MNIST。在理论层面上，我们建立了用于使用计算高效且变异性正则化损失函数训练的神经网络的新泛化误差界，该损失函数与W-DRO问题密切相关。

Innovation: 
本研究提出了DRO-Augment框架，通过将Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略集成，显著提高深度神经网络的鲁棒性，特别是在面对严重数据扰动和对抗性攻击的情况下，拓广了模型在基准数据集上的鲁棒性，同时保证了在干净数据集上的准确率。理论方面，基于一个计算效率高且变异性正则化损失函数建立了新的泛化误差界，该损失函数与W-DRO问题相关。

Conclusion: 
DRO-Augment通过将Wasserstein分布鲁棒优化（W-DRO）与数据增强相结合，在严重数据扰动和对抗性攻击场景下展示了卓越的鲁棒性性能，同时在不同类型的数据集上保持了模型的准确率。此外，该方法也为优化神经网络的泛化能力提供了新的理论依据，有助于进一步理解和提高深度学习模型的鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17874</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>21. cs.SE-当领域碰撞时：一种活动理论探索跨学科协作</title><link>https://arxiv.org/pdf/2506.20063</link><description>Background: 
软件开发团队日益多样化、嵌入化且跨学科化。来自不同学科的领域专家（DEs）与专业软件开发者（SDEs）合作，带来互补的专业技能来开发和维护复杂的生产软件。然而，由于存在争议的期望、不同的问题解决视角和相互冲突的优先级，导致了摩擦和冲突。

Innovation: 
本文通过运用活动理论（AT），一种成熟的社会科学和技术框架，进行了一项实证研究，涵盖24次访谈（12位DEs和12位SDEs）和大规模验证调查（293位参与者，包括161位DEs和132位SDEs），揭示了八种SDEs和六种DEs的期望，及其在跨学科软件开发（CDSD）中的21种摩擦问题的来源和表现

Conclusion: 
本文提供了一种理解CDSD动态和冲突的理论框架，并为未来的研究、实践和基础设施设计提供了可操作性的洞见。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20063</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>22. cs.SE-LLMs能否在代码切块期间替代人类？</title><link>https://arxiv.org/pdf/2506.19897</link><description>Background: 
大型语言模型（LLMs）在计算机科学中已成为重要工具，特别是在代码理解和生成的相关任务中。然而，现有的研究并未解决政府应用代码中特有的挑战，如这些代码通常使用过时的语言编写（如MUMPS或汇编语言代码ALC），且整体代码长度超过当前商业LLMs的上下文窗口大小。此外，LLMs主要针对现代软件语言进行训练，并且在过时语言上的测试有限，这使得它们理解过时语言的能力存在不确定性，成为需要进行实证研究的领域。本文探讨LLMs在现代化政府过时代码（使用ALC和MUMPS编写）中的应用，解决输入限制带来的挑战。我们研究了不同的代码切块方法，旨在优化生成过时代码文件摘要模块注释，评估切块方法对不同LLMs（包括GPT-4o、Claude 3 Sonnet、Mixtral和Llama 3）文档生成质量的影响。研究结果显示，LLMs能够选择与人类专家划分点相近的切分点，切块方法对后续任务（如文档生成）有显著影响。LLMs生成的切分区注释比人类生成的切分区更事实性和更有用，分别高出约20%和10%。因此，本文得出结论，LLMs可以作为适合大型代码库切块的人类替代品，在使用LLMs辅助的现代化过程中。

Innovation: 
本文创新性地探讨了将LLMs应用于现代化政府过时代码（使用ALC和MUMPS编写）中，研究了不同代码切块方法对LLMs文档生成质量的影响，发现LLMs在切块划分方面表现出类似专家的能力，并且生成的注释质量更高。这些发现为利用LLMs进行代码现代化提供了新思路。

Conclusion: 
本文结论指出，LLMs能够以适合大型代码库切块的方式进行分区，且生成的注释质量高于人类，表明LLMs可以作为人类切块的替代品，在利用LLMs辅助的代码现代化过程中发挥重要作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19897</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>23. cs.SE-人工智能与敏捷软件开发：从挫折到成功——XP2025研讨会总结</title><link>https://arxiv.org/pdf/2506.20159</link><description>Background: 
XP2025全日研讨会聚集了研究者和行业实践者，讨论将人工智能整合到敏捷软件开发中的实际挑战与机会。与会者在互动环节中识别了相关痛点，发现了与工具、治理、数据质量和关键技术缺口相关的挑战，并对这些挑战进行了系统分析，以确定其根本原因。

Innovation: 
研讨会通过识别并优先处理痛点，分析根本原因，制定了一个研究路线图，指明了未来工作中的具体行动方向，包括即期解决方案和长期目标。这为推动行业与学术界的合作，从识别痛点到实现成功实施提供了有结构的议程。

Conclusion: 
研讨会的主要成果是构建了一个有结构的议程，旨在促进行业与学术界的合作，解决识别出的问题，实现成功的实施。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20159</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>24. cs.SE-PIs十项简明规则整合研究软件工程至其研发团队</title><link>https://arxiv.org/pdf/2506.20217</link><description>Background: 
研究软件工程（RSEng）是生成高质量研究软件的关键因素，可以提高研究结果。然而，作为主导研究员或研究小组领导者，你可能不了解RSEng是什么，如何开始使用它，以及如何最大化其对研究的益处。RSEng通常也会伴随着技术复杂性，这可能使一些研究者感到不易接近。

Innovation: 
本文提出了十项简明规则，旨在提高RSEng的易用性，并为PIs和领导者提供了实用的建议，以便他们在研究团队中集成RSEng。这些建议可以帮助提高研究软件的质量、可重复性和可信度，从而获得更好的、更可重复和可信的研究成果。

Conclusion: 
通过遵循这些规则，读者可以提升其研究软件的质量、可重复性和可信度，最终实现更好的、更可重复和更可信的研究成果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20217</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>25. cs.LG-使用路径签名实现的可扩展机器学习算法</title><link>https://arxiv.org/pdf/2506.17634</link><description>Background: 
路径签名作为一种提供序列和结构化数据忠实、分层表示的迭代积分，在随机分析与机器学习的交界处是一个快速发展的领域。路径签名根植于粗糙路径理论，具有不可参数化特性，适用于建模演变动力学、长范围依赖关系和不规则采样——这些都是现实世界时间序列和图数据中的常见挑战。本论文探讨了如何利用路径签名的表达能力，将其融入可扩展的机器学习管道中。

Innovation: 
本论文的主要创新包括：基于路径签名核相关的高斯过程模型，用于具备不确定量化的时间序列建模；Seq2Tens框架，通过低秩张量结构在权重空间中实现大规模建模长距离依赖；基于图的模型，通过图上的期望路径导引生成非椭圆扩散过程，提供了比标准图神经网络更具表现力且更易于管理的替代方案；随机 Fourier 路径签名特征，作为一种具有理论保证的大规模核近似算法；受控遗忘机制下的循环稀疏频谱路径签名高斯过程，结合了高斯过程、路径签名核和随机特征，适用于多展望期时间序列预测和自适应上下文长度。

Conclusion: 
本论文旨在为序列和结构化数据的可扩展、路径签名基础学习提供方法学工具包，并作为一个概念性的桥梁，提供当前该领域研究的有用参考。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17634</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>26. cs.LG-BeltCrack: 首个多序列图像工业输送带裂纹检测数据集及其三域特征学习基准方法</title><link>https://arxiv.org/pdf/2506.17892</link><description>Background: 
输送带是现代工业中的重要设备，广泛应用于生产和制造。输送带的健康状况对于操作效率和安全性至关重要。裂纹是影响输送带健康的主要威胁。为了确保安全性，如何有智能地检测裂纹正受到越来越多的关注。通过机器学习实施智能检测需要真实的数据样本，然而现有的裂纹数据集主要集中在道路场景或合成数据上，完全缺乏真实世界的工业输送带裂纹数据集。为此，为了验证可用性和有效性，该研究提出了一个新的双域数据集，并且开发了一个特别的基线方法，该方法采用三域（即时间-空间-频率）特征层级融合学习。实验结果表明该数据集的有效性和可用性，并且表明基线方法明显优于其他类似检测方法。该数据集及源代码可见于：this https URL

Innovation: 
该研究首次提出了一个多序列图像工业输送带裂纹检测数据集，旨在填补真实工业输送带裂纹数据集的空白，同时提出了一个采用三域特征层级融合学习的特殊基线方法，用于新型数据集的检测任务，提升了裂纹检测的准确性和可靠性。

Conclusion: 
实验结果证明，该新数据集与基线方法的有效性和优越性，为进一步研究工业输送带裂纹检测提供了坚实的基础，并且相关数据集和源代码已经对外开放。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17892</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>27. cs.LG-LLM生成数据中关键因素及其对模型微调的影响</title><link>https://arxiv.org/pdf/2506.19262</link><description>Background: 
大型语言模型（LLMs）的生成能力显著，使用LLM生成的数据来训练下游模型已经成为缓解特定领域数据稀缺性和减少耗时标注的有前景的方法。然而，近期研究发现，迭代使用自动生成的数据进行训练会导致模型塌陷，即模型性能随时间恶化。尽管在LLM生成数据的影响方面已进行了广泛研究，但这些研究往往忽视了数据多样性的重要性，这是数据质量的关键因素。本文旨在探讨LLM生成数据的多样性对下游模型性能的影响，具体研究不同水平的多样性对下游模型性能的影响，并探索在不同比例的LLM生成数据（称为合成数据）中训练模型的效果。实验结果表明，适度多样性的LLM生成数据在缺乏标记数据的情况下可以提升模型性能，而高度多样性的生成数据则对性能产生负面影响。

Innovation: 
研究提出了关于LLM生成数据中数据多样性对下游模型性能影响的关键发现，并提出了在训练过程中适度多样性的LLM生成数据可以提高模型性能的新见解。此研究弥补了之前忽略数据多样性影响的研究空白，为未来研究LLMs作为数据生成工具提供了指导意义。

Conclusion: 
本文的实验结果表明，在确保最小分布变化的情况下，适度多样性的LLM生成数据可以增强模型在标记数据不足情况下的性能，而高度多样性的生成数据则对性能产生负面影响。这将为未来有关LLMs作为数据生成工具的研究提供有价值的指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19262</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>28. cs.LG-分布式学习中异质性识别</title><link>https://arxiv.org/pdf/2506.16394</link><description>Background: 
本文研究了在分布式M-估计中识别具有最小数据传输量的异质参数组件的方法。背景在于当数据分布在多个节点上时，如何有效地进行参数估计，同时减少数据传输成本和提高计算效率。研究的背景还涉及异质性数据的特点和处理方法的选择，强调了在数据分布异质性较强和数据块较小的情况下保持参数估计的一致性。

Innovation: 
文章提出了两种识别异质参数的方法：一种基于重新标准化的Wald检验，能够在较低的数据块数量和较高异质性水平的情况下保持一致；另一种是极端对比检验(ECT)，通过样本拆分处理避免了从M-估计过程积累的偏差，能够在数据异质性较稀疏且数据块数量远大于样本量的情况下保持一致。ECT的优势在于操作简便和通信效率高。通过结合Wald检验和ECT，可以在不同水平的异质性稀疏性下实现更稳健的功效。此外，还通过详尽的数值实验比较了所提出方法的全家错误率(FWER)和功效，并进行了案例研究以说明方法的实现和效度。

Conclusion: 
文章通过结合Wald检验和ECT方法提出了更为稳健的异质性识别方案，并通过数值实验验证了提出的两种方法的有效性和稳健性，特别是在异质性程度和数据块数量不同的场景下，显示了较好的性能和实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16394</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>29. cs.LG-基于上下文学习的无梯度接收器自适应：原理、应用及理论</title><link>https://arxiv.org/pdf/2506.15176</link><description>Background: 
近年来，深度学习促进了能够在传统模型导向设计所面临的挑战性环境中有效地运作的无线接收器的创造。基于可编程硬件架构的深度学习接收器具备根据变化的信道环境动态调整的潜力。然而，当前的适应策略，如联合训练、超网络方法和元学习，要么灵活性有限，要么需要通过梯度下降显式优化。因此，该领域急需一种新的无梯度适应技术，以实现实时接收器的动态调整，并且这种技术不需要在线重新训练模型。对于这种需求，研究背景解释了现有技术的局限性和挑战，从而为了解决问题提供了理论和实践的基础。

Innovation: 
该研究提出了基于新兴的上下文学习（ICL）范式的无梯度适应技术。通过利用基于Transformer模型和结构化状态空间模型（SSMs）的架构框架，研究探讨了序列模型如何从上下文信息中高效学习适应。研究进一步将ICL应用于无蜂窝大规模MIMO网络，展示了ICL不仅具有理论上的分析，还有实验证据。这种方法表明，在不需要在线重新训练的情况下，通过试点信号和辅助上下文信息实现实时接收器适应是可行的。

Conclusion: 
研究结论认为，上下文学习作为一种原理上和效率上兼备的实现实时接收器自适应的技术，不需要在线重新训练，可以充分利用试点信号和使用辅助上下文信息进行接收器的适应性调整。这种技术不仅提供了理论分析，还通过实际应用提供了实证支持，表明这是一种有效和有潜力的接收器自适应方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15176</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>30. cs.LG-FORTRESS: 先锋安全风险评估以保障国家安全与公共安全</title><link>https://arxiv.org/pdf/2506.14922</link><description>Background: 
大型语言模型（LLMs）的快速发展带来了双重用途的能力，既有可能威胁国家安全和公共安全（NSPS），也可能为其提供支持。当前的模型在实现保护措施以防止潜在滥用的同时，允许良性用户获得有益信息。然而，现有基准通常未能以客观和稳健的方式测试这些保护措施对NSPS风险的抵御能力。

Innovation: 
作者提出了FORTRESS，这是一个包含500个专家制定的对抗性提示及其实例化评估标准的框架。该框架包含4到7个二元问题，用于自动评估3个领域中的语言模型：未分类信息的化学、生物、放射性、核生和爆炸物（CBRNE）、政治暴力与恐怖主义、以及刑事和金融非法活动，共有10个次类别。同时，每个提示-评估标准对还包括一个对应的良性版本，用于测试模型的过度拒绝。这揭示了前沿LLM保护措施的收益与风险之间的不同权衡：例如Claude-3.5-Sonnet表现出较低的平均风险评分（14.09/100）但最高的过度拒绝评分（21.8/100），而Gemini 2.5 Pro则表现为较低的过度拒绝（1.4）和较高的平均潜在风险（66.29）。

Conclusion: 
为了给政策制定者和研究人员提供这种风险的清晰理解，我们已经公开发布了FORTRESS：https://example.com/FORTRESS，并保留了一套私有评估集以进行进一步评估。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14922</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>31. cs.LG-使用柯尔莫哥洛夫-阿诺尔德神经网络量子态探究量子自旋系统</title><link>https://arxiv.org/pdf/2506.01891</link><description>Background: 
神经量子状态（NQS）是一类由神经网络（NNs）参数化的变分波函数，用于研究量子多体系统。在本工作中，提出了基于柯尔莫哥洛夫-阿诺尔德网络（KANs）的SineKAN，用于表示量子力学波函数为嵌套的一元函数。研究表明，使用可学习正弦激活函数的SineKAN波函数能捕捉一维横向场Ising模型、各向异性Heisenberg模型和反铁磁性$J_{1}-J_{2}$模型不同链长的地能态能量、保真度和多种相关函数。

Innovation: 
本文提出了一种新的NQS textit{ansatz}——SineKAN，它基于KANs，可用于表示量子力学波函数，并通过可学习的正弦激活函数，能够捕捉多个量子自旋系统的地能态能量、保真度和多种相关函数。特别是，在$J_1-J_2$模型上，SineKAN的表现优于之前探索的RBM、LSTM、MLP等模型，证明了其在精度和计算成本方面的优势。

Conclusion: 
SineKAN模型在计算上成本低且训练精度高，能够在不同长度的自旋模型中表现出色，特别是在$J_1-J_2$模型中，显著优于其他类型的神经量子态 textit{ansatz}。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.01891</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>32. cs.LG-SLEEPING-DISCO 9M: 一个用于生成音乐建模的大规模预训练数据集</title><link>https://arxiv.org/pdf/2506.14293</link><description>Background: 
在生成音乐建模任务（如文本-音乐生成、音乐配对、歌唱声音合成、旋律重构和跨模型检索）中，目前没有高质量的开源数据集来代表热门和知名的歌曲。过去的贡献主要集中在孤立和受限的因素上，主要是创建合成或重新录制的音乐库（例如GTSinger，M4Singer），而另一些社区的重点则是在任意大规模的音频数据集（例如DISCO-10M和LAIONDISCO-12M）。然而，这些数据集在生成音乐社区中的采用率低于预期，因为它们未能反映现实中的音乐及其特色。

Innovation: 
该论文提出了Sleeping-DISCO 9M，这是一个利用实际热门音乐和世界著名艺术家构建的大规模预训练数据集。这是一个填补现有空白的创新，提供了高质量且高可用的音乐数据集，以支持生成音乐模型的研发。

Conclusion: 
Sleeping-DISCO 9M为生成音乐社区提供了新的机会，可以通过更真实和多样化的数据来增强模型的性能，从而提高音乐生成任务的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14293</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>33. cs.LG-IKDiffuser: 多臂机器人基于扩散模型的生成逆运动学求解器</title><link>https://arxiv.org/pdf/2506.13087</link><description>Background: 
逆运动学（IK）问题是机器人领域的基础问题，但在多臂机器人系统中仍然充满挑战。由于复杂自碰撞、耦合关节和高维度冗余，传统IK求解器在多臂机器人中的效率低下、容易失败且解决方案多样性不足。

Innovation: 
本文提出了IKDiffuser，一种基于扩散模型的快速且多样的多臂机器人IK求解器。IKDiffuser通过学习配置空间中的关节分布，捕捉复杂依赖关系，能够无缝泛化到不同结构的多臂机器人系统。此外，IKDiffuser在推理过程中可以加入额外的目标而无需重新训练，增加了任务特定需求的灵活性和适应性。在6个不同多臂系统上的实验结果显示，与现有求解器相比，IKDiffuser在解决方案准确性、精确性、多样性和计算效率方面表现出色。

Conclusion: 
IKDiffuser框架为解决多臂IK问题提供了一种可扩展且统一的方法，支持多臂机器人系统在实时操作任务中的潜在应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13087</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>34. cs.LG-mSTEB: 大规模多语言评估的LLMs在语音和文本任务上的评估</title><link>https://arxiv.org/pdf/2506.08400</link><description>Background: 
大型语言模型（LLMs）在广泛任务上的表现令人印象深刻，包括多模态场景下的语音任务。然而，它们的评估通常仅限于英语和其他高资源语言。对于低资源语言，没有标准化的评估基准。本文通过提出mSTEB（大规模多模态语音和文本评估基准）填补了这一空白，该基准涵盖语言识别、文本分类、问答和翻译等任务，包括语音和文本模态。这一评估揭示了高资源语言和低资源语言之间在性能上的巨大差距，特别是在非洲以及美洲和大洋洲的少数语言中表现尤为明显。

Innovation: 
提出了mSTEB，一个新型基准，用于评估LLMs在多种任务上的表现，包括语言识别、文本分类、问答和翻译等任务，覆盖语音和文本模态。此外，该研究评估了多个领先的LLM，如Gemini 2.0 Flash、GPT-4o（音频）以及前沿的开源模型Qwen 2 Audio和Gemma 3 27B，揭示了高资源语言和低资源语言之间在性能上的巨大差距，特别是在非洲以及美洲和大洋洲的语言中表现尤为明显。

Conclusion: 
研究发现，对低资源语言在LLMs中的覆盖率不足需要更多的投资来解决。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.08400</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>35. cs.LG-曲面表示性布里�曼距离及其应用</title><link>https://arxiv.org/pdf/2504.05654</link><description>Background: 
文章利用统计学中的曲面指数族概念，定义了曲面布里�曼距离，将其视为受限于非线性参数子空间的布里�曼距离。在这一背景下，文章研究了有限加权参数集在曲面布里�曼距离下的重心问题，并揭示了曲面布里�曼距离在两个具体例子，即对称布里�曼距离和圆复正态分布间Kullback-Leibler散度中的重要性。进一步地，文章探讨了单调嵌入，并基于其定义了表示性曲面布里�曼距离，展示了α散度作为α嵌入概率单纯形到正测度椎体关系下的表示性曲面布里�曼距离的性质，这种方法应用在计算有限个α散度球体的交集中具有重要意义

Innovation: 
文章基于曲面指数族的概念定义了曲面布里�曼距离，并通过研究其在稀疏坐标集表示性方面的特性与应用，提出了新的理论框架。此外，文章证明了α散度作为一种表示性曲面布里桥曼距离的性质，为后续应用奠定了基础

Conclusion: 
文章建立了曲面布里桥曼距离的理论框架，并探讨了其在表示性方面的应用，特别是展示了一类新的参数子空间下的布里桥曼距离，为计算多个分布之间的交集提供了有效的方法</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.05654</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>36. cs.LG-价值错配：复杂性障碍</title><link>https://arxiv.org/pdf/2506.10304</link><description>Background: 
本文指出，AI对齐不仅困难，而且基于根本性的逻辑矛盾。《枚举悖论》指出，我们使用机器学习是因为不能列出所有必要的安全规则，但要使ML安全则需要从不可能枚举的范围内生成示例。这悖论通过五组独立的数学证明，或“不可克服性支柱”来确认。研究表明，从无限维度的世界-上下文要求投影到有限维度模型上导致安全策略集测度为零；验证策略安全性是coNP完全的问题，即使存在容错；用于安全性的训练数据（大量罕见灾难的示例）是逻辑自相矛盾，因此无法获得；安全性规则包含无法压缩的任意信息，任何可行网络都无法存储；优化过程旨在提高AI能力，主动反对安全性，因为两个目标的梯度通常是对齐的。这些结果表明，追求高度安全、强大的AI不仅仅是克服技术障碍，而是面对根本性的相互制约障碍。目前正在进行核心定理在Lean4中的形式验证。

Innovation: 
本文创新性地提出了《枚举悖论》，并通过五组独立的数学证明来展示AI对齐的复杂性障碍，包括几何障碍、计算障碍、统计障碍、信息论障碍和动态障碍，共同证明了安全、强大AI的追求不仅仅是技术难题，而是面临根本性的相互制约障碍。并对这些不可能性结果提出了一个策略三难境地。

Conclusion: 
本文的主要结论是，追求安全、强大的AI不仅是技术挑战，而是更深刻、相互关联的障碍。文章指出，需要重新考虑AI对齐的实现路径，并提出一个重要观点：安全、强大AI的追求面临一种策略三难境地。文章中核心定理的正式验证工作正在进行中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.10304</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>37. cs.LG-不是你的错，而是您所在的位置不同——不同人口和个性的全球城市视觉感知存在差异</title><link>https://arxiv.org/pdf/2505.12758</link><description>Background: 
理解人们的偏好和需求对于城市规划决策至关重要，但目前的方法往往将不同文化背景和城市的居民数据结合起来，这掩盖了重要的人口差异，可能导致偏差的放大。因此，研究人员需要一个全面的、基于多样化的数据集来评估不同群体对城市街道景观的感知差异。

Innovation: 
该研究进行了一项针对全球城市街道景观的大规模视觉感知调查，使用街景图像，考察了人口统计学（性别、年龄、收入、教育、种族和族裔）和个人特质对1000名来自五个国家和45个民族的参与者感知的影响。该研究提出了一个名为Street Perception Evaluation Considering Socioeconomics (SPECS)的数据集，揭示了不同人口和个性在六项传统指标（安全、活力、富有、美丽、单调、压抑）及四项新指标（住在附近、步行、骑行、绿色）上的感知评分的显著差异。此外，研究使用通用机器学习模型的结果与人类感知结果相比，发现机器学习模型倾向于高估积极指标和低估消极指标，强调了考虑到当地人的感知进行干预的必要性。

Conclusion: 
本研究旨在纠正关于街道感知的片面性处理，很少考虑人口或个性特征的问题，强调了更具针对性的城市规划干预措施需要考虑到本地人的感知。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12758</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>38. cs.LG-回收互联网数据：提升语言模型预训练数据品质和数量的方法</title><link>https://arxiv.org/pdf/2506.04689</link><description>Background: 
大型语言模型的性能随模型规模和数据规模的增大而提升。实践中，预训练依赖于大规模网络爬虫，使用几乎全部公开的互联网数据。然而，计算资源的增长速度超过了自然数据的获取速度。优质的文本数据更加稀缺，数据过滤管道常常会去除初始爬取数据中的99%以达到最佳效果。为解决预训练规模的数据墙问题，本文研究了如何回收和再利用现有过滤过程中被丢弃的数据，提出了REWIRE方法，以丰富低质量文档使其能够用于训练，从而增加合成数据在预训练集合中的比例。

Innovation: 
提出了REWIRE方法，这是一种方法，通过对低质量文档进行改造，使其能用于训练，从而增加合成数据在预训练集合中的比例。实验结果表明，在DCLM基准测试的1B、3B和7B规模下，混合高质量原始文本和重写文本分别在22个不同任务中提高了1.0，1.3和2.5个百分点的性能，相较于仅使用过滤后的网络数据进行训练。此外，使用混合数据集的训练比获得两倍网络数据的效果更好。通过进一步分析发现，混合数据中约82%来自转化较低质量的文档。REWIRE还优于其他生成合成数据的方法，如维基百科风格的同义替换、问答合成和知识提取。

Conclusion: 
回收互联网数据的有效方式能够简化和提升语言模型预训练数据的质量和数量。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.04689</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>39. cs.LG-通过交互粒子系统实现无梯度序列贝叶斯实验设计</title><link>https://arxiv.org/pdf/2504.13320</link><description>Background: 
该研究针对复杂系统，在缺乏梯度信息的情况下，提出了一个无梯度框架来优化贝叶斯最优实验设计（BOED）。传统的BOED方法在处理复杂系统时存在计算瓶颈，尤其是在高维度和PDE约束反问题中。该方法结合了Ensemble Kalman Inversion (EKI) 和 Affine-Invariant Langevin Dynamics (ALDI) 采样器，两个都具有无梯度和集束式的特点，旨在解决嵌套期望带来的计算挑战。研究者通过提出变分Gaussian近似和参数化Laplace近似来提供实用的信息增益（EIG）的上下界估计，从而实现高维度空间中的可扩展性效用估计。

Innovation: 
本文的创新之处在于提出了一种无梯度框架，它结合了EKI和ALDI两种无梯度集束式方法，以解决复杂系统的BOED问题。通过使用变分Gaussian近似和参数化Laplace近似提供实用的EIG的上下界估计，该方法能够处理高维度空间和PDE约束反问题，提高了信息驱动实验设计的鲁棒性、准确性和效率。

Conclusion: 
通过数值实验，展示了该框架在各种线性高斯模型和基于PDE的推断任务中的性能，证明了该方法在信息驱动实验设计中的稳健性、准确性和可扩展性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.13320</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>40. cs.LG-LPOSS: 通过补丁和像素上的标签传播进行开放词汇语义分割</title><link>https://arxiv.org/pdf/2503.19777</link><description>Background: 
当前的视觉和语言模型（VLMs）主要用于跨模态对齐优化，在进行内模态相似性优化方面表现不足。现有的基于补丁的编码器在分辨率上存在局限性。本文研究了如何利用VLMs的跨模态对齐能力并通过标签传播增强补丁级别的初始预测，以改善语义分割的准确性，特别是在类别边界附近的表现。

Innovation: 
提出了一种无需训练的方法，称为LPOSS+，用于开放词汇语义分割。该方法通过标签传播提高基于补丁的VLMs初始预测，并通过像素级的标签传播进行精细调整，以改善整体图像的分割准确性，同时避免了基于窗口的处理方式，能更好地捕捉图像全域上下文交互。

Conclusion: 
LPOSS+ 在多种数据集上实现了训练自由方法的最佳性能。该方法在整幅图像上进行推理，而非采用窗口处理方式，从而显著提高了类边界附近的分割精度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.19777</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>41. cs.LG-使用混合物和统计计算间隙对大型语言模型进行水印</title><link>https://arxiv.org/pdf/2505.01484</link><description>Background: 
这篇文章探讨了如何通过水印技术来辨别一段文本是由大型语言模型（LLM）还是人类生成的问题。先前的研究已经广泛探索了这种方式，包括一些基于水印的方法。本文介绍了在封闭环境下不可检测且简单的水印方案，以及在开放环境下难以去除的水印方案。

Innovation: 
本文的主要创新点在于提出了两种在不同环境下的水印方案。第一种方案是在封闭环境下，设计了一种不可检测且简单的水印方案；第二种方案则是面向开放环境，提供了一种难以移除的水印方案。这两种方案分别适用于不同场景下的文本鉴别需求，能够为实际应用中辨别文本来源提供新的工具和技术支持。

Conclusion: 
本文通过提出带有不同特性的水印方案，为进一步研究文本鉴别技术提供了新的思路和方法，能够有效区分大型语言模型生成的文本和自然人类生成的文本。同时，这两种方案分别针对封闭和开放环境进行了设计，增强了实际应用中的实用性和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.01484</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>42. cs.LG-MARCO: 多代理实时知识集成的代码优化框架用于高性能计算</title><link>https://arxiv.org/pdf/2505.03906</link><description>Background: 
大型语言模型（LLMs）通过代码生成功能改变了软件开发，但在高性能计算（HPC）中的应用效果有限。HPC代码需要对并行性、内存效率和架构特定考虑进行专门优化，这是通用语言模型通常忽视的。

Innovation: 
MARCO是一个新的框架，采用专门的多代理架构增强LLM生成的HPC代码。其核心创新在于MARCO的网络搜索组件，能够实时检索优化技术，弥补预训练LLM的知识空白。

Conclusion: 
MARCO在LeetCode 75问题集上的广泛评估显示，与仅使用Claude 3.5 Sonnet相比，MARCO平均减少了14.6%的运行时间。结合网络搜索组件后，性能提高了30.9%。结果强调了多代理系统在解决高性能代码生成的特殊要求方面的潜力，提供了与领域特定模型微调相比的成本有效替代方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.03906</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>43. cs.LG-未来 Collider 新探测器几何结构中机器学习粒子流重建的微调</title><link>https://arxiv.org/pdf/2503.00131</link><description>Background: 
在高能粒子对撞机中，粒子流重建是关键任务之一。传统的基于规则的方法在新探测器设计上进行训练时需要大量的数据样本。尽管有可能通过海量数据训练来优化新探测器的性能，但这种方法耗时且成本高昂。因此，研究者们探索了将已在一种探测器上训练好的算法应用于另一种探测器的可能性，即跨探测器微调。但由于不同的高能对撞机和探测器设计导致的复杂性，目前还不清楚这种方法在粒子流重建中的实际效果和潜力。这一研究首次对全模拟下不同探测器之间的跨探测器微调进行深入分析，并验证了其在粒子和事件级别上的性能，为加速新探测器的研发周期提供了新的可能方法。

Innovation: 
该研究展示了机器学习算法在不同高能对撞机和探测器设计之间的跨探测器微调能力，具体包括从一个大型全模拟数据集预训练模型并将其微调到具有不同设计的新探测器上。研究发现，即使使用较少的数据样本，也能达到与从零开始训练类似的表现。此外，微调后的模型在仅使用100,000个CLD事件的训练后在事件级别上的性能与从零开始训练的模型具有可比性，后者需要至少100万CLD事件才能达到类似的重建性能。这标志着首次进行全面模拟下的跨探测器微调研究，为不同探测器设计和几何结构上大模型的微调提供了指导意义。

Conclusion: 
本研究通过全模拟环境验证了跨探测器微调在粒子流重建任务中的有效性，显示了这种方法可以在大幅度减少训练数据量的情况下达到与传统方法相同的重建性能。这些发现对于将来开发可以跨多种探测器设计和几何结构进行微调的大模型具有重要指导意义，也将加速新探测器的研发周期。进一步的研究和应用可以利用机器学习技术快速优化探测器设计和性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.00131</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>44. cs.LG-WyckoffDiff -- 一种用于晶体对称性的生成扩散模型</title><link>https://arxiv.org/pdf/2502.06485</link><description>Background: 
晶体材料通常表现出高度对称性。然而，大多数生成模型并未考虑这种对称性，而是无约束地为每个原子指定位置和元素。本文提出了一种名为Wyckoff Diffusion（WyckoffDiff）的生成模型，专门用于生成基于对称性的晶体描述。该模型通过考虑包含所有对称性的晶体结构表示来实现这一目标，并设计了一种新颖的神经网络架构，允许该表示在离散生成模型框架内使用，从而在构建过程中尊重对称性，同时保持快速生成的特点。此外，还提出了一种新的度量标准Fréchet Wrenformer Distance，用于捕捉生成材料中的对称性方面，并将WyckoffDiff与最近提出的晶体生成生成模型进行了基准测试。作为概念验证研究的一部分，使用WyckoffDiff在热力学稳定性凸包下方找到了新材料。

Innovation: 
提出了WyckoffDiff，一种基于对称性的生成模型，通过考虑包含所有对称性的晶体结构表示，设计了一种新颖的神经网络架构，实现了在离散生成模型框架内的使用。此外，还提出了Fréchet Wrenformer Distance，专门用于刻画生成材料中的对称性。

Conclusion: 
WyckoffDiff在尊重对称性的同时，具备快速生成的特点，并且在概念验证中应用于寻找新的低能量材料。研究还对比了WyckoffDiff与最新的晶体生成生成模型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.06485</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>45. cs.LG-基于双精度学习的神震修正方法在近似黎曼解算器中的神经网络实现</title><link>https://arxiv.org/pdf/2503.13248</link><description>Background: 
黎曼问题是超曲偏微分方程计算建模的基础，能够促进稳定和精确的迎风方案的发展。尽管精确解算器能提供可靠的迎风通量，但由于其计算成本高，需要使用近似解算器。虽然多数情况下近似解算器能获得精确解，但在某些情况下会得到不准确的解。为改善这一局限，本文提出了基于神经网络的替代模型，通过监督学习训练来映射内部和外部保守状态变量到相应的精确通量。研究表明，这些提出的两个方法在一维和二维偏微分方程的应用中表现出强大且精确的性能。

Innovation: 
本文提出的基于神经网络的替代模型方法，特别是使用双精度学习的方法，以映射内部和外部保守状态变量到相应的精确通量，克服了传统近似解算器在某些情况下的精度不足。具体提出了使用普通神经网络和双精度神经网络两种不同的方法，展示了其在多种偏微分方程问题中的有效性和稳定性。

Conclusion: 
本文通过应用到一维和二维偏微分方程的实例展示了提出的基于神经网络的黎曼解算器改进方法的有效性和广泛适用性，未来的研究将继续探索这种新方法在复杂物理问题中的实际应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.13248</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>46. cs.LG-Graph Reasoning 过程奖励让大语言模型成为更通用的推理者</title><link>https://arxiv.org/pdf/2503.00845</link><description>Background: 
尽管大型语言模型（LLMs）取得了显著进展，但开发高级推理能力仍然是一个重要挑战。尽管步骤奖励模型（PRMs）在数学推理中的逐步反馈方面表现出色，但它们在更广泛推理领域的应用尚不完全研究，主要由于手动创建步骤级监督的成本高。本文探索了PRMs在图推理问题中的潜力，这是一种需要复杂多步推理的领域，并通过自动化任务导向轨迹和蒙特卡洛树搜索（MCTS）自动生成详细的推理步骤和步骤级标签来构建数据集。

Innovation: 
介绍了GraphSILO，这是用于图推理问题的最大数据集，具有精细的逐步标签，通过自动化任务导向轨迹和蒙特卡洛树搜索（MCTS）构建。基于此数据集，训练了GraphPRM，这是第一个专门针对图推理问题的PRM，并研究了其在推理时间放大和直接偏好优化（DPO）强化学习中的有效性。实验结果表明，GraphPRM在13个图推理任务中显著提高了LLM性能，其中Qwen2.5-7B的提高达到了9%，并且具有向新图推理数据集和新的推理领域如数学问题解决的可转移性。

Conclusion: 
研究表明，基于图的推理奖励有可能在跨领域的推理方面推进，为更通用和有效的LLMs铺平了道路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.00845</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>47. cs.LG-MaizeField3D：来自多样化群体的田间种植玉米的精炼3D点云和过程模型数据集</title><link>https://arxiv.org/pdf/2503.07813</link><description>Background: 
由于缺乏大型且多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具的发展，尤其是在玉米领域，受到了限制。2D图像数据集无法捕捉3D数据提供的关键结构细节，如叶片结构、植物体积和空间布局。这些限制促使我们开发了MaizeField3D，这是一个包含田间种植玉米的3D点云数据集，覆盖了遗传多样性群体，旨在推进农业研究。该数据集包括使用大地测量激光扫描仪（TLS）收集的1,045个高质量的3D点云，并通过基于图的分割方法对其中520株植物进行了分割和标注，确保所有样本的一致性标注。这些标注的数据用于生成描述性模型，提供了植物的有组织的参数表示。

Innovation: 
MaizeField3D通过使用3D点云数据集，解决了2D图像数据集的局限性，并促进了基于AI的表型分析、植物结构分析和农业研究中的3D应用。叶片通过非均匀有理B样条（NURBS）表面和两步优化过程描述，实现了精确的结构参数表示。该数据集还包含详细的植物形态和质量元数据以及不同分辨率的点云数据，便于下游计算任务的使用。这种基于数据集的方法提供了全面的基础数据，促进了AI驱动的表型分析的进步。

Conclusion: 
MaizeField3D将作为一个全面的基础数据集，用于AI驱动的表型分析、植物结构分析和农业研究中的3D应用。该数据集的高质量点云和描述性模型将有助于促进相关领域的研究和应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.07813</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>48. cs.LG-3D变分自动编码器用于微结构体积元指纹图谱</title><link>https://arxiv.org/pdf/2503.17427</link><description>Background: 
材料的微观结构量化是建立材料性能关系的重要步骤。基于机器学习的图像处理方法已显示出比传统图像处理技术更优越，广泛应用于微观结构量化任务中。本文提出了一种3D变分自动编码器（VAE），用于编码包含晶格取向数据的微结构体积元（VES），通过计算晶格空间对称性，并映射至晶体学基本区，从而使用连续损失函数并提高训练收敛速度。

Innovation: 
提出的3D VAE方法在处理包含随机纹理的等轴多晶微结构的VES时实现了准确重构，平均准则误差相对较小。模型还展示了良好泛化能力，能够处理训练分布外的不同纹理、晶粒尺寸和长宽比的微结构。结合晶体塑性模拟，通过指纹参数化微结构体积元在低维潜空间的方式，进而训练全连接的人工神经网络作为晶体塑性模拟的替代模型。这种指纹基替代模型能够在未见过的数据上准确预测微观结构依赖的晶体塑性应力响应。

Conclusion: 
研究表明提出的3D VAE能够有效地简化和量化复杂微结构，并通过与晶体塑性模拟结合，生成描述微观结构的特征码，实现了基于特征码的微结构－性能关系的预测，为材料的微观结构设计和优化提供了新的方法和手段。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.17427</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>49. cs.LG-从O(n^2)到O(n)参数：用于生物医学图像分类的Vision Transformer中的量子自注意力</title><link>https://arxiv.org/pdf/2503.07294</link><description>Background: 
研究中介绍了一种新的方法，即量子视力变压器（QViTs），这是通过将视觉变压器（ViTs）中的自注意力（SA）机制替换为量子自注意力（QSA）机制来实现的。QViTs被设计用于在生物医学图像分类中达到与最新方法相当的性能，但在参数量上有显著减少。研究背景基于现有架构在处理大规模数据和参数高效性上的局限性，特别是自注意力机制的高参数需求问题。

Innovation: 
该创新之处在于提出了量子自注意力机制（QSA），通过替换线性SA层为参数化的量子神经网络（QNNs），使得参数规模从O(n^2)降至O(n)。这种机制大大减少了参数数量。研究还首次探讨了从经典到量子视觉变压器的知识蒸馏方法，展示了QViTs在多种生物医学图像分类数据集上的性能，特别是高参数效率的QSA机制。此外，研究指出更高的量子比特架构在知识蒸馏预训练中更受益，表明QSA参数数量与知识蒸馏有效性之间可能存在正相关的关系。

Conclusion: 
研究证明了QSA是用于生物医学图像分析的有效架构选择，特别在参数效率上优于传统方法。研究结果支持将QSA应用到Vision Transformers中以提高生物医学图像分类的性能和效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.07294</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>50. cs.LG-使用上下界模型的契合预测</title><link>https://arxiv.org/pdf/2503.04071</link><description>Background: 
本文探讨了一种基于确定性目标变量上下界的回归模型预测区间构建方法，特别是使用契合预测（Conformal Prediction，CP）方法。现有的许多CP方法在上下界较紧的区域可能无法提供足够的覆盖范围，导致预测区间不可靠。因此，研究者们提出了一种新的CP机制CPUL，它采用模型选择方法并通过多种嵌套区间构建方法来处理。文章进一步提出了一种优化阈值机制OMLT，用于在覆盖不足的区域调整CPUL的区间，从而改善预测中的覆盖范围问题。

Innovation: 
本文的创新在于提出了一种新的CP机制CPUL，它通过模型选择途径结合了区间构建方法，并提出了一种优化阈值机制OMLT，用于调整在上下界较紧区域的预测区间。这两大创新有效解决了现有CP方法在覆盖不足区域表现不佳的问题。

Conclusion: 
通过在大规模学习任务中的实验证明，本文提出的CPUL-OMLT方法在不同数据集上表现更好，大幅优于基线方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.04071</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>51. cs.LG-蛋白质结构标记化：基准测试及新方法</title><link>https://arxiv.org/pdf/2503.00089</link><description>Background: 
近年来，蛋白质结构标记化方法的发展势头强劲，将蛋白质3D结构切分成离散或连续的表示。结构标记化使得可以直接使用有力的语言模型等技术应用于蛋白质结构，并能够将结构与蛋白质序列和功能性文本整合到大型多模态模型中。尽管取得了进步，但这些方法的能力和局限性仍然不为人所知，因为缺乏统一的评估框架。现有的评估基准普遍关注全局结构，忽视了细粒度的局部子结构。

Innovation: 
该研究首次引入了名为StructTokenBench的框架，该框架全面评估了结构标记器的质量和效率，侧重于细粒度的局部子结构而不是全局结构。此外，研究观察到码本使用不足，开发了名为AminoAseed的简单而有效的方法，增强码本梯度更新并最优平衡码本大小和维度，以提高标记器的利用效率和质量。与领先的模型ESM3相比，该方法在24个监督任务上的平均性能提高了6.31%，敏感性和利用率分别提高了12.83%和124.03%。

Conclusion: 
研究的评估结果表明，目前没有单一的模型能够在所有基准测试视角中均占主导地位。通过引入StructTokenBench评估框架和AminoAseed策略，可以更好地理解蛋白质结构标记化方法的能力和限制，从而促进该领域的进一步发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.00089</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>52. cs.LG-我将自行合并它：一种多保真自动模型合并框架</title><link>https://arxiv.org/pdf/2502.04030</link><description>Background: 
大型语言模型（LLMs）的推理能力是重要的前沿领域，但开发这些能力需要大量的专有数据集和计算资源。一种有效补充这些能力的方法是模型合并，这种方法通过结合多个模型而无需重新训练，提供了一个有希望的替代方案。然而，当前的合并方法依赖于手动设计的策略来合并超参数，这限制了模型组合的探索范围并需要大量的人力投入。

Innovation: 
本文提出了一个自动化模型合并框架，该框架可以精细地探索合并策略并且通过多保真近似方法减少成本。这个框架支持单目标和多目标优化，并引入了两个新的搜索空间：层融合（LFS）和深度整合（DIS）。研究结果表明，自动搜索可以找到1）即使在模型已经微调的领域，也能进一步提升单目标性能的合并，2）在各种任务中优化多目标前沿的合并。有效合并可以在有限计算资源内找到，例如在不到500次搜索步骤内找到。

Conclusion: 
研究发现，自动化搜索不仅可以在任务上找到进一步提升单目标性能的合并，还能在多种任务上优化多目标前沿。这些找到的有效合并可以在有限的计算资源内实现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.04030</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>53. cs.LG-基于构形化生成模型的具有保障的图像超分辨率</title><link>https://arxiv.org/pdf/2502.09664</link><description>Background: 
随着基于机器学习的基础模型在图像恢复任务中的应用越来越广泛，例如超分辨率，需要开发出能够提供可靠且可解释的不确定性量化的方法。现有的方法大多针对特定模型，不够通用。

Innovation: 
本文提出了一种基于构形预测技术的创新方法，能够为生成的图像创建一个‘置信度掩码’，使生成的图像在特定区域内的可信度评估更加可靠和直观。该方法适用于任何黑盒生成模型，只需要简单数据进行校准，并且可以通过选择局部图像相似度度量来进行高度定制。该方法理论上有较强的保证，涵盖了保真误差控制、重建质量以及数据泄漏下的鲁棒性。

Conclusion: 
通过实验证明了该方法的有效性，展现了其在保真度误差控制、重建质量以及面对数据泄漏鲁棒性方面的强大性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.09664</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>54. cs.LG-Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models</title><link>https://arxiv.org/pdf/2408.00523</link><description>Background: 
文本到图像（T2I）生成模型已被广泛用于通过将文本描述转换为高质量的图像来进行内容创作。然而，这些模型容易受到‘越狱’攻击，攻击者通过精心构造的提示绕过安全机制，生成不符合安全标准的内容。尽管研究人员已经开发了多种‘越狱攻击’来揭示这一风险，但这些方法存在许多限制，如不切实际的访问要求、容易被检测到的不自然的提示、受限的搜索空间以及对目标系统的高查询需求。

Innovation: 
本文提出了一种名为JailFuzzer的新颖模糊测试框架，该框架由大型语言模型（LLM）代理驱动，旨在在黑盒环境中高效生成自然且具有语义意义的‘越狱’提示。JailFuzzer通过种子池、引导突变引擎和判断函数三个组件实现其功能。尤其是，通过基于LLM的代理构建了引导突变引擎和判断函数，这进一步确保了在黑盒环境中的效率和适应性。研究表明，JailFuzzer在‘越狱’T2I模型方面具有显著优势，能够生成自然且语义一致的提示，减少传统防御的检测可能性，并且在最少查询开销的情况下达到高‘越狱’成功率，超越了现有方法的关键指标。

Conclusion: 
本文研究强调了在生成模型中加强安全机制的必要性，并为未来针对复杂‘越狱攻击’的研究提供了基础。JailFuzzer已开源，并可在该链接访问：this https URL.。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.00523</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>55. cs.LG-超越语言模型的自然数据集上下文学习能力解锁</title><link>https://arxiv.org/pdf/2501.06256</link><description>Background: 
大型语言模型（LLMs）表现出上下文学习（ICL）能力，使模型仅通过上下文中的示例即可执行新任务，而不需更新模型权重。虽然ICL在自然语言任务和领域中提供了快速适应，但对于文本之外的其他模态而言，其出现则不那么明显。本文系统地研究了支持LLMs中ICL在自回归模型和多种模态中出现的性质，通过促进ICL所需机制的学习来实现这一目标。文章指出，在训练数据序列中的确切token重复是ICL的重要因素，并进一步提高了ICL的稳定性和降低了其表现的瞬时性。此外，文章强调了训练任务难度对ICL出现的重要性。最后，作者通过应用对ICL出现的新见解，解锁了针对各种视觉数据集以及更具挑战性的EEG分类任务的ICL能力，在少量示例学习条件下实现这一目标。

Innovation: 
研究发现确切的token重复是支持ICL的重要因素，并在此基础上进一步增强了ICL的稳定性和降低了其表现的瞬时性。强调了训练任务难度对ICL出现的重要性，并通过应用对ICL出现的新见解，解锁了针对各种视觉数据集以及更具挑战性的EEG分类任务的ICL能力。

Conclusion: 
通过研究，作者揭示了支持LLMs中ICL出现的关键因素，并在此基础上解锁了ICL能力在自然数据集中的应用，特别是在视觉数据集和更具挑战性的EEG分类任务中的应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.06256</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>56. cs.LG-理解当前状态或预测未来？世界模型的全面调查</title><link>https://arxiv.org/pdf/2411.14499</link><description>Background: 
由于GPT-4等多模态大规模语言模型以及Sora等视频生成模型的进步，世界模型的概念受到了广泛关注。世界模型主要用于理解和预测世界的状态和发展，该论文通过对相关文献进行全面回顾，对该领域进行系统梳理，强调世界模型在构建内部表征以理解世界机制以及预测未来状态进行模拟和指导决策方面的两种主要功能。

Innovation: 
本文提供了一篇系统性的世界模型综述，分类强调了理解世界机制和预测未来状态两类主要功能，并重点探讨了世界模型在自主驾驶、机器人技术和社交模拟等领域中的应用，同时还指出了研究面临的挑战和未来的研究方向。

Conclusion: 
研究总结了代表性论文及其代码仓库，并提出了对未来研究方向的看法，旨在为相关领域的研究提供参考和启发。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.14499</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>57. cs.LG-众包中的数据质量和刷单行为检测</title><link>https://arxiv.org/pdf/2404.17582</link><description>Background: 
随着众包作为一种高效低成本的方法获取机器学习数据集的标签而涌现，评估众包提供的数据质量变得至关重要，以改善分析性能并降低后续机器学习任务中的偏差。由于大多数众包案例缺乏真实黄金标准，数据质量被定义为标注者的一致性和可信度。与通常使用Kappa系数和内类别相关系数来处理简单场景不同，众包在线环境则需要应对更复杂的情况。因此，需要一种系统的方法来评估数据质量和检测刷单威胁，通过方差分解来进行分类，并基于标注者的行为模式将其分为三类。进一步地，一个刷单指数被提出用于评估数据的一致性，两种利用马尔可夫链和广义随机效应模型度量众包工作者可信度的指标也被开发出来。最后，通过应用到人脸识别任务中，结合模拟和来自两个众包平台的实际数据，验证了这些技术的有效性和优势。

Innovation: 
提出了一个系统的方法来评估众包数据质量和检测刷单行为，包括通过方差分解分类，并基于标注者行为模式将刷手分为三类，提出了一个刷单指数和两种度量众包工作者可信度的指标，通过马尔可夫链和广义随机效应模型实施。并在人脸识别任务中验证了技术的有效性和优势。

Conclusion: 
该研究展示了评估技术在处理众包数据质量和检测刷单威胁方面的实用性和优势，可以有效地提高众包数据的质量，并降低后续机器学习任务中的偏差。</description><guid isPermaLink="true">https://arxiv.org/pdf/2404.17582</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>58. cs.LG-在自变量偏移下的上下文优化：基于Wasserstein球交集的鲁棒方法</title><link>https://arxiv.org/pdf/2406.02426</link><description>Background: 
在上下文优化中，决策者利用上下文信息（协变量）来更好地解决不确定性并做出基于信息的决策。然而，在训练和测试环境中协变量分布的差异（协变量偏移）会导致测试协变量的上游估计不准确，从而导致下游决策的次优性。论文旨在解决这一挑战，并提出了一种新颖的方法，即基于Wasserstein球交集的分布鲁棒优化（IW-DRO），以应对协变量偏移带来的挑战。

Innovation: 
提出了一种基于Wasserstein球交集的分布鲁棒优化（IW-DRO）框架，该方法通过结合多种估算方法，并利用非参数和参数估算器构造出的两个Wasserstein球的交集作为模糊集核心。论文还从理论角度证明了该方法的优越性，并推导出有限样本集中Nadaraya-Watson核估算器在协变量偏移情况下的集中结果。在计算方面，该论文将IW-DRO问题转化为可解的凸优化问题，并为大规模问题开发了近似算法，以提高计算效率。

Conclusion: 
所提出的IW-DRO框架为影响协变量偏移的不确定环境中的决策者提供了实用价值。该框架通过融合多种估算方法和通过Wasserstein球交集定义的模糊集，能够更好地处理协变量偏移带来的挑战，并提供了关于模糊集覆盖率和估算器测度集中性的理论保证。</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.02426</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>59. cs.LG-使用联邦学习的多无人机近端控制以用于人机协作领域</title><link>https://arxiv.org/pdf/2412.02863</link><description>Background: 
人机交互(HRI)是一个快速发展的研究领域。在HRI中，复杂的命令（动作）分类仍然是一个开放的问题，这通常会阻碍此类技术的实际应用。现有的研究表明，神经网络可以用于检测这些动作，但遮挡仍然是HRI中的主要问题，尤其是在使用无人驾驶航空器(UAV)时，因为在机器人移动期间，人类操作员往往处于机器人的视野之外。此外，在多机器人场景中，分布式训练也是一个开放的问题。

Innovation: 
本研究提出了一种基于长短期记忆(LSTM)深度神经网络的行动识别与控制方法，该方法与三个紧密相连的层结合使用，并嵌入了联邦学习(FL)。这种FL方法使我们的方法能够以分布式方式训练，不需要云或其它存储库，从而促进了多机器人系统的学习。此外，本研究的多机器人方法还防止了遮挡情况的发生，实验结果表明，使用真实机器人时的准确性超过96%。

Conclusion: 
本研究通过结合LSTM深度神经网络和联邦学习，提出了一种行动识别与控制方法，应用于多无人机近端控制，在多机器人协作场景中实现了高精度，有效解决了遮挡问题和分布式训练的问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.02863</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>60. cs.LG-使用无监督学习进行窄频带无线电技术信号搜索中的异构检测和射频干扰分类</title><link>https://arxiv.org/pdf/2411.16556</link><description>Background: 
无线电技术信号的搜索是一个异常检测问题，候选信号是射频频段干扰（RFI）中的一根根“芒刺”。目前的搜索框架会产生大量的假阳性信号，特别是在大型调查中，需要进行手动跟踪，这在某些情况下是不可行的。因此，一种算法上的方法是通过无监督学习来识别最异常的信号并对RFI信号进行分组，减少假阳性率。GLOBULAR（Grouping Low-frequency Observations By Unsupervised Learning After Reduction）聚类方法就是一种使用HDBSCAN来减少假阳性率和隔离异常信号以供进一步分析的方法。

Innovation: 
GLOBULAR聚类方法通过使用HDBSCAN技术，显著减少了假阳性率并隔离异常信号进行进一步分析，当与标准窄频带信号检测及空间过滤管道（如turboSETI）相结合时，表现出优于标准管道的显著性能改进，这为缓解未来大型调查的手动跟踪需求提供了大量潜力。此外，通过去除高谱段占用区域的RFI信号，GLOBULAR聚类方法可能也有助于标准管道未能检测到信号的发现。

Conclusion: 
该方法在针对Choeza等人的97个近邻星系L带的turboSETI单独搜索的基准测试中，假阳性命中率减少了93.1%，假阳性事件减少了99.3%，证明了该方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.16556</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>61. cs.LG-BINDy -- 可逆跳跃马尔可夫链蒙特卡洛的非线性动力学的贝叶斯识别</title><link>https://arxiv.org/pdf/2408.08062</link><description>Background: 
数据驱动建模中的模型简约是一种重要的认知偏差，有助于提高模型的可解释性并预防过拟合。 Sparse Identification of Nonlinear Dynamics (SINDy) 方法能够直接从数据中学习复杂的动态表达，给定一个库函数的基础。尽管如此，现有方法主要集中在参数空间的稀疏性，即仅考虑参数的稀疏表示，而忽略了模型结构的稀疏性。这可能导致模型在结构上过于复杂，从而影响模型性能。因此，寻找一种能够同时在模型空间和参数空间实现稀疏性的方法变得重要和必要。

Innovation: 
本文提出了一个名为 BINDy 的新颖贝叶斯方法，作为 SINDy 的替代方案。BINDy 的创新之处在于它针对的是模型库和其参数化的完整联合后验分布，而不是仅仅关注参数稀疏性。这使得可以在模型结构上放置任意先验，从而生成稀疏模型。由于后验定义了可以在维度上变化的参数向量，标准技术无法执行推理。因此，作者提出了一种基于可逆跳跃马尔可夫链蒙特卡洛（reversible-jump Markov-chain Monte-Carlo）积分策略的吉布斯采样器。这种方法能够同时在模型空间和参数空间实现稀疏性和复杂的模型结构，比现有方法更具有优势。

Conclusion: 
在三个基准案例研究中，通过对比 Ensemble SINDy，BINDy 展现了其优越性，特别是在具有正确模型术语的高概率分配方面更为优异。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.08062</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>62. cs.LG-关于阅读时长预测中的上下文作用</title><link>https://arxiv.org/pdf/2409.08160</link><description>Background: 
本文提供了一个新的视角，研究读者在实时语言理解过程中如何整合上下文。该研究基于‘惊奇理论’（surprisal theory），认为语言单位（如单词）的处理努力与其在上下文中的信息含量成线性关系。文章观察到，惊奇理论并不是唯一的上下文预测方法，点互信息（PMI）也可能产生同样有效的预测能力，当控制单词频率时。同时，PMI和惊奇理论与频率都相关，这意味着它们并没有包含纯上下文的信息。基于此，文章提出了一种将惊奇理论投影到频率的正交补空间中的新方法，产生了一个不与频率相关的新型上下文预测器。实验结果显示，使用正交化后的预测器来表示上下文时，解释的阅读时间变异比例要小得多。这从可解释性角度看，表明先前的研究可能高估了上下文在预测阅读时间中的作用。

Innovation: 
本文提出了一种新的上下文预测方法，即通过将惊奇理论投影到频率的正交补空间中，生成一个不与频率相关的新型上下文预测器。这种方法可以剥离频率相关性，提供更纯净的上下文信息，以更准确地预测阅读时间。与传统的惊奇理论和点互信息相比，该方法展示了更少的上下文变异解释度。

Conclusion: 
实验结果表明，使用正交化后的上下文预测器来表示上下文，能够显著减少对阅读时间变异的解释比例，也表明先前研究可能高估了上下文在预测阅读时间中的作用。新方法提高了上下文预测的准确性与可解释性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.08160</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>63. cs.LG-大规模语言模型中用于图推理的图线性化方法</title><link>https://arxiv.org/pdf/2410.19494</link><description>Background: 
大型语言模型已经发展到能够处理包括图像和音频在内的多种模态，这促使我们探索如何有效利用它们进行图推理任务。关键问题是如何将图转换为标记的线性序列，我们称之为‘图线性化’，这样大型语言模型（LLM）可以自然地处理图。我们考虑将图线性化为反映自然语言文本的一些特性，如局部依赖性和全局对齐，以便更好地帮助当今经过万亿个文本标记训练的现代大型语言模型理解和处理图。

Innovation: 
开发了几种基于图中心性和退化性的图线性化方法，并进一步通过节点重新标记技术进行了改进。实验结果证明，与随机线性化基线相比，我们的方法更有效。这项工作引入了适合大型语言模型的新颖图表示，为图机器学习与使用统一变压器模型的多模态处理趋势的整合做出了贡献。

Conclusion: 
我们的研究展示了基于图中心性和退化性的图线性化方法的有效性，并为理解图提供了一种新的视角。这种方法优化后的图表示对于大型语言模型来说是全新的，并且有助于将图机器学习与统一的变压器模型驱动的多模态处理趋势进行整合。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.19494</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>64. cs.LG-可调无限宽度图卷积神经网络</title><link>https://arxiv.org/pdf/2402.06525</link><description>Background: 
神经网络通常采用无限宽度极限来进行理论分析，在该极限下，网络输出服从高斯过程分布，称为神经网络高斯过程（NNGP）。然而，NNGP的核是固定的，只能通过少量的超参数进行调整，从而消除了代表学习的可能性。这与有限宽度的神经网络不同，后者通常被认为能很好地工作，是因为它们能够灵活地学习任务的表示。因此，在简化神经网络以使其在理论上可处理时，NNGP可能消除了使其表现良好的关键因素（代表学习）。这促使我们研究代表学习是否是图任务中可有可无的特性。

Innovation: 
我们开发了一种精确工具——图卷积深核机（Graph Convolutional Deep Kernel Machine），这种工具与无限宽度的NNGP非常相似，它也是基于无限宽度极限和核函数，但附带了一个“调节旋钮”，可以控制灵活性和相应的代表学习能力。我们发现代表学习在异质节点分类任务中带来了显著的性能提升，但在同质节点分类任务中的作用较小。

Conclusion: 
我们的研究结果显示，代表学习在异质节点分类任务中具有明显的好处，而在同质节点分类任务中影响较小。这表明，对于特定类型的任务，代表学习可以通过灵活的调节在图任务中发挥重要作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2402.06525</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>65. cs.LG-评估代码生成大型语言模型处理长距离依赖的能力</title><link>https://arxiv.org/pdf/2407.21049</link><description>Background: 
随着语言模型支持的上下文大小不断增加，评估模型有效利用这些上下文的能力变得越来越重要。本文分析了几种代码生成模型在具有多达8k个标记上下文窗口中的处理长距离依赖的能力，通过一系列逐步增加难度的多步关键检索任务来进行评估。这种评估方法比流行的‘针在一滩稻草中’测试能更细致地评估模型的能力。

Innovation: 
研究发现，当一个函数引用后来定义的另一个函数时，许多模型的性能显著下降（最高达2倍）。此外，使用滑动窗口注意力机制的模型难以处理比单个窗口更大的引用。研究通过使用调用图信息进行简单的提示修改，将多步检索性能最多提高3倍。分析还强调了长时间段性能需要更深入的考虑，而不仅仅是文档内单个事实的检索。

Conclusion: 
研究结果表明，大型语言模型在处理长距离依赖时存在明显的性能瓶颈，特别是在处理引用的延迟问题上。通过改进提示可以显著提升模型处理多步骤检索的能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.21049</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>66. cs.LG-Dual-Channel Multiplex Graph Neural Networks for Recommendation</title><link>https://arxiv.org/pdf/2403.11624</link><description>Background: 
推荐系统在准确捕捉用户和项目属性方面发挥着关键作用，这些属性反映了个人偏好。现有的推荐技术已经开始转向模拟用户和项目之间的各种互动关系，如在线购物平台上的点击、收藏和购买。然而，这些方法仍然面临两大挑战：一是对多重关系构成的各种行为模式的影响在表示学习中的建模和利用不足；二是忽略了行为模式中的不同关系对目标关系的影响，以及这些关系之间的依赖关系和合适的顺序问题。

Innovation: 
本文提出了一种名为Dual-Channel Multiplex Graph Neural Network (DCMGNN)的新型推荐框架。DCMGNN通过引入显式的行为模式表示学习器来捕捉由多重用户-项目交互关系组成的行为模式，并包括关系链表示学习器和关系链感知编码器，以发现各种辅助关系对目标关系的影响、不同关系之间的依赖关系，并挖掘行为模式中的适当关系顺序。实验结果表明，DCMGNN在三个真实世界数据集上的表现优于现有的各种推荐方法。

Conclusion: 
在所有数据集上，DCMGNN分别在Recall@10和NDCG@10的平均对比基准模型分别提高了10.06%和12.15%。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.11624</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>67. cs.LG-更好地构建归纳知识图谱完成基准数据集</title><link>https://arxiv.org/pdf/2406.11898</link><description>Background: 
知识图谱完成（KGC）旨在预测知识图谱中的缺失事实。近年来，研究焦点转向设计能够在归纳场景下表现优秀的KGC方法，其中部分或全部用于推理的实体和关系在训练期间未被观测到。已经提出了多种基准数据集以测试归纳KGC，这些数据集均是现有知识图谱的子集，用于感性KGC。然而，研究发现当前构建归纳KGC数据集的过程无意中创造了一种捷径，即使在忽略关联信息的情况下也可被利用。具体而言，观察到个性化PageRank（PPR）分数在大多数数据集上都能达到强大的或接近最优的性能。这项研究旨在探讨此问题的根本原因，并提出了一种替代策略来构造归纳KGC数据集，以减轻PPR捷径的影响。新的基准数据集有助于更好地理解归纳KGC的能力和挑战，去除任何可能模糊性能衡量的捷径。相关代码和数据集可在此网页上找到：this https URL

Innovation: 
提出了用于构造归纳KGC数据集的替代策略，以减轻PPR捷径的影响。使用新数据集进行了多种流行方法的基准测试，并分析了它们的性能，帮助更清晰地理解归纳KGC的能力和挑战，去除可能干扰性能评估的捷径。同时提供了相关代码和数据集供更广泛的学术和工业界使用。

Conclusion: 
新的基准数据集有助于更好地理解归纳知识图谱完成的能力和挑战，通过去除可能混淆性能评估的捷径提供更公正的性能评估。</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.11898</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>68. cs.LG-LT-PINN: 拉格朗日拓扑意识物理导向神经网络在边界聚焦工程优化中的应用</title><link>https://arxiv.org/pdf/2506.06300</link><description>Background: 
物理导向神经网络（PINNs）作为一种无网格工具在拓扑优化中取得了显著成功，能够同时确定最优拓扑和物理解决方案。然而，传统的PINNs依赖于基于密度的拓扑描述，这需要手动插值并限制其应用于复杂的几何形状。为了解决这一问题，本文提出了Lagrangian拓扑意识PINNs（LT-PINNs），这是一种用于边界聚焦工程优化的新框架。LT-PINNs通过将拓扑边界曲线的控制变量参数化为可学习参数来消除手动插值的需要，从而实现精确的边界确定。此外，通过引入特殊的边界条件损失函数和拓扑损失函数，确保即使对于复杂的拓扑结构也能获得清晰准确的边界表示。研究通过弹性方程和拉普拉斯方程验证了LT-PINNs的准确性及鲁棒性。同时，演示了LT-PINNs在复杂的时间依赖性和时间无关的流体问题上的有效性，而无需依赖测量数据，并展示了其在流体速度重新配置方面的工程技术应用潜力，特别是将上游均匀速度转换为下游正弦形速度配置。

Innovation: 
提出了Lagrangian拓扑意识PINNs（LT-PINNs），这是一种通过参数化拓扑边界曲线的控制变量为可学习参数来消除手动插值需求的新框架，从而能够精确确定边界。进一步引入了特殊的边界条件损失函数和拓扑损失函数，以确保即使在复杂拓扑条件下也能获得清晰准确的边界表示。验证了LT-PINNs在多种偏微分方程和复杂流体问题上的准确性和鲁棒性。这种方法特别适用于复杂拓扑结构的优化问题，且不需要进行手动插值，对于不同类型的边界条件也有很好的适应性。

Conclusion: 
结果表明，与最先进的基于密度的拓扑导向PINN（DT-PINN）相比，LT-PINN在相对L2误差上实现了显著减少，能够处理任意边界条件，适用于各种偏微分方程，并且无需手动插值即可得出清晰的拓扑边界，尤其是适用于复杂的拓扑结构，从而展示了其在边界聚焦工程优化中的有效性和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.06300</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>69. cs.LG-C-Learner: 受约束学习在因果推理中的应用</title><link>https://arxiv.org/pdf/2405.09493</link><description>Background: 
目前流行的工具变量估计方法，如增强逆概率加权和目标最大似然估计，虽然具有统计效率和双重健壯性等优良渐近性质，但在治疗组和对照组重叠度较低的情况下往往会生成不稳定的估计，需要在实践中添加额外假设或非正式调整（例如截断倾向得分）。相比之下，简单的插值估计器虽然稳定，但缺乏优良的渐近性质。

Innovation: 
本文提出了一种新颖的偏差减小方法，旨在两种方法之间取得最佳平衡，即生成既稳定又具有优良渐近性质的插值估计器。通过受约束学习框架，在给定插值量的一阶误差为零的约束下求解最佳插值估计器，并可利用包括神经网络和树集成等灵活的模型类别。在包含处理文本协变量时微调语言模型的实验设置中，本文方法在治疗组和对照组重叠度低的挑战性情况下优于基本的一步估计和定位方法，否则性能相当。此外，通过建立具有重尾逆概率得分的理论示例，解释了为什么本文方法在重叠度低的设置中表现出更优的性能差异原因。

Conclusion: 
在低重叠度环境中，本文提出的方法能产生稳定且具有优良渐近性质的估计器，较传统方法表现出更优的性能。这些发现对处理具有挑战性数据集的因果推理提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.09493</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>70. cs.LG-基于物理机制的模仿强化学习在现实驾驶中的应用</title><link>https://arxiv.org/pdf/2407.02508</link><description>Background: 
近期在模仿强化学习（IRL）方面取得的进展显著提升了自主代理学习专家演示的能力，使其能快速掌握各种复杂任务中的技能。然而，这类基于学习的代理在向高度动态的闭环环境转移知识时面临着重大挑战，其性能受到模仿学习（IL）和强化学习（RL）的相互冲突优化目标、样本效率低以及难以发现隐藏的世界模型和物理现象的影响。

Innovation: 
本文提出了一种完全数据驱动的基于物理机制的IRL方法，该方法结合了专家演示数据和探索数据，通过联合优化目标自然地从训练过程中显现出车辆动力学的物理原理。实验结果表明，在Waymax基准测试的闭环设置中，该方法优于流行的IL、RL和IRL算法，碰撞率降低了37.8%，脱道路率降低了22.2%，相比之下，基线方法性能更差。

Conclusion: 
本文提出的基于物理机制的IRL方法显著提高了在闭环环境中的性能，通过联合优化显现出车辆动力学的物理机制，验证了其在现实驾驶中的应用潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.02508</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>71. cs.LG-COBRA-PPM：基于概率编程的机器人不确定性操纵的因果贝叶斯推理架构</title><link>https://arxiv.org/pdf/2403.14488</link><description>Background: 
机器人执行任务时需要思考对象间的因果关系，但现有许多基于数据的方法缺乏因果语义，只考虑相关性。本文通过高保真Gazebo实验，展示了COBRA-PPM在不确定环境下进行机械操作的能力，预测操作结果准确率高达88.6%，并且成功率高达94.2%。该模型还在真实机器人上实现了从仿真到现实世界的迁移，展示了处理传感器噪声和随机操作中现实不确定性方面的有效性。该通用框架支持多种操作场景，为进一步结合机器人技术和因果关系的研究奠定了基础。

Innovation: 
提出了一种新的因果贝叶斯推理架构COBRA-PPM，结合了因果贝叶斯网络和概率编程，用于在不确定性条件下进行机器人操作的干预性推理。该模型通过高保真实验展示了预测操作结果的高准确率和成功率。此外，该模型还展示了从仿真到真实世界的迁移能力，有效地处理了传感器噪声和随机操作带来的现实不确定性。

Conclusion: 
COBRA-PPM框架支持广泛的操纵场景，为机器人和因果关系交叉领域的未来工作奠定了基础，扩充了现有基于数据的方法，提高了在不确定环境下执行操作的预测准确性和成功率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.14488</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>72. cs.LG-FluoroSAM：一种灵活的X射线图像分割语言指令可调基础模型</title><link>https://arxiv.org/pdf/2403.08059</link><description>Background: 
先前的努力贡献了特定任务的模型，可以解决狭窄范围的问题，但扩大到更广泛的应用需要更多的数据、注释和训练时间。近年来，语言对齐的基础模型（LFMs）——在大量高度变化的图像和文本数据上训练的机器学习模型，使广泛的应用成为可能。现有医学图像分析的基础模型主要集中在拥有大量丰富注释数据的场景和模态上。但X射线成像模态具有高度变化的图像外观和应用，从诊断胸部X射线到介入性透视，数据可用性各异。因此，需要一种能够对任意医学X射线图像进行全面和语言对齐分析的基础模型。

Innovation: 
提出了一种名为FluoroSAM的语言指令可调变体分割一切模型，从广泛的仿生X射线图像中（涉及多种人体解剖学、成像几何和视图角度）训练了一百万张图像，这些图像包含128种器官类型和464种相关工具的伪地面真值掩模及其文本描述。FluoroSAM通过在训练过程中引入文本嵌入的向量量化（VQ）实现了根据自然语言指令分割多种解剖结构和工具的能力。通过在真实X射线图像上的定量性能展示和在几个应用中的演示，展示了FluoroSAM为X射线图像采集和分析中的丰富人机交互提供了关键支持。

Conclusion: 
FluoroSAM展示了如何实现灵活的X射线图像分割，结合了语言提示能力和广泛的训练数据，为诊断和介入精准医疗中的人机交互提供了新的可能性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.08059</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>73. cs.LG-Thought Anchors: Which LLM Reasoning Steps Matter？</title><link>https://arxiv.org/pdf/2506.19143</link><description>Background: 
大型语言模型在许多领域已取得最先进的表现，但其长形式的链式思考推理带来了可解释性挑战，因为每个生成的tokens都依赖于之前的tokens，使得计算难以分解。本文认为，在句子级别分析推理跟踪的策略可能是理解推理过程的一个有前景的方法。

Innovation: 
本文提出了三种互补的归因方法：1)一种黑盒方法，通过比较在模型生成该句子或具有不同含义的句子时生成最终答案的各异，衡量每个句子的实际重要性；2)一种白盒方法，汇总句子对之间的注意力模式，识别了那些通过“接收器”注意力头受到所有未来句子不成比例关注的“广播”句子；3)一种因果归因方法，通过阻断一个句子的相关注意力，来测量其对未来句子token的影响。每种方法都提供了存在思考锚点的证据，即推理过程中的重要步骤，对后续推理过程有不成比例的影响。这些思考锚点通常是规划或回溯句子。此外，作者还提供了一个开源工具（链接）以可视化方法输出，并展示了一个案例研究，展示了不同方法如何共同绘制模型执行多步骤推理的过程。

Conclusion: 
不同方法的一致性表明，句子级别的分析对于更加深入地理解推理模型具有潜在价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19143</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>74. cs.LG-基于编码数据结构的变量子回归算法</title><link>https://arxiv.org/pdf/2307.03334</link><description>Background: 
混合变量子算法（VQAs）具有解决诸如组合优化、量子化学模拟、量子机器学习和量子纠错等实际问题的潜力，尤其在不稳定的量子计算机上。然而，传统的随机算法或量子交替操作算法会导致变量子算法成为不可信赖的‘黑箱’，无法进行模型解释，更不用说将其部署为影响关键决策的应用程序。因为这些变量子参数仅仅对应于量子门的旋转角度，而没有任何可解释的模型值。

Innovation: 
本文构建了第一个可解释的量子回归算法，在这个算法中，量子状态精确地编码了经典数据表，变量子参数直接对应于回归系数，这些系数是通过构造的实数，提供了高程度的模型可解释性和优化成本的最小化，得益于适当的表示能力。此外，利用编码的数据结构可以减少回归图计算的时间复杂度。为了实现非线性回归的电路深度缩短，可以通过经典的预处理来构建非线性特征，作为独立的编码列向量。即使在超导量子比特中最近实现了较不嘈杂的压缩编码，我们也展望了多量子门实现的量子优势，例如在中性冷原子和离子中的潜在量子实用性

Conclusion: 
本文提出了一种基于编码数据结构的变量子回归算法，使得量子状态能够精确编码经典数据表，变量子参数能直接对应回归系数，实现了高模型可解释性和有效的优化。通过经典的预处理可以进一步实现非线性特征，为进一步的研究和发展提供了坚实的理论基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2307.03334</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>75. cs.LG-Confucius3-Math: 针对中国K-12数学学习的轻量高性能推理大语言模型</title><link>https://arxiv.org/pdf/2506.18330</link><description>Background: 
该论文介绍了Confucius3-Math，这是一种开源的大规模语言模型，具有14B个参数，能够在单个消费级GPU上高效运行，并在一系列数学推理任务中取得了SOTA性能，远优于许多大得多的模型。它专注于为中国K-12学生和教师提供数学学习，通过大规模强化学习后训练方式构建，旨在以低成本解决主流的K-12数学问题。研究人员分享了开发配方、遇到的挑战和克服挑战的技术，并提出了三项技术创新：目标熵正则化、最近样本恢复和策略特定难度加权。这些创新囊括了一种新的熵正则化、一种新的数据调度策略，以及一种改进的组相对优势估计器。它们共同显著稳定了RL训练，提高了数据效率并提升了性能。这项工作证明了在特定领域低成本构建强大的推理模型的可能性，论文开放了其模型和代码供读者参考。

Innovation: 
1. 通过大规模强化学习（RL）后训练构建的轻量高性能模型，能够在单个消费级GPU上高效运行。n2. 特别重视为中国K-12学生和教师提供数学学习的模型，专注于解决主流的K-12数学问题。n3. 提出了三项技术创新：目标熵正则化、最近样本恢复和策略特定难度加权，涵盖新的熵正则化、新颖的数据调度策略和改进的组相对优势估计器。n4. 这些技术显著稳定了RL训练，提高了数据效率，并提升了性能。

Conclusion: 
该论文证明了在特定领域低成本构建强大的推理模型的可能性。通过开发Confucius3-Math模型和相关的技术，证明了在保持高性能的同时，仍然可以实现低成本的数学推理任务解决。 해당 연구는 특정 영역에서 고성능의 합리화 모델을 저렴한 비용으로 조성하는 가능성을 보여주었다. Confucius3-Math 모델과 관련된 기술을 개발함으로써, 고성능 수학 논리 문제 해결을 유지하면서 여전히 저렴한 비용을 낼 수 있음을 입증했다.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18330</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>76. cs.LG-使用射影类测度规划的离线条件强化学习</title><link>https://arxiv.org/pdf/2506.18847</link><description>Background: 
线下条件强化学习旨在训练代理从先前收集的轨迹中到达指定目标。对于长时间任务的扩展仍具有挑战性，主要是由于递增值估计错误。理论意义上的几何方法提供了一种潜在解决方案来解决这些问题。

Innovation: 
引入了一个名为项目几何规划（ProQ）的组合框架，该框架学习一个非对称距离，并重新利用它：首先作为排斥势能，促使一组关键点在学习的潜在空间中均匀分布，其次作为结构化方向成本，引导向附近的子目标。特别是，ProQ 联合几何学和外分布检测器的拉格朗日方法，确保学习到的关键点保持在可到达的区域内。通过统一度量学习、关键点覆盖和条件控制，我们的方法提出了有意义的子目标，并在各种导航基准测试上稳健地驱动了长时间的任务完成。

Conclusion: 
本方法通过统一度量学习、关键点覆盖和条件控制，生成有意义的子目标，并在不同的导航基准测试中稳健地驱动长期目标的达成。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18847</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>77. cs.LG-可见光和红外图像馈送中低光照条件下的行人检测：问题与挑战</title><link>https://arxiv.org/pdf/2311.08557</link><description>Background: 
行人检测已成为自动驾驶、智能交通和交通监控等高阶任务的基础。现有的行人检测工作主要集中在可见光图像上，尤其是在白天。然而，在环境条件变化为低光或夜晚时，这一任务变得非常具有挑战性。最近，人们开始探索使用替代数据源，如远红外（FIR）温度传感器馈送，以在低光条件下检测行人。文章综述了近年来在低光行人检测方面的进展，系统地分类和分析了从区域到非区域以及图基学习方法的各种算法，并强调了这些方法、实施问题和挑战。此外，文章还概述了可用于研究和开发先进行人检测算法的关键基准数据集，特别是在低光情况下。

Innovation: 
文章深入研究了低光照条件下的行人检测问题，并系统地分类和分析了各种检测算法。提出了使用远红外温度传感器数据作为辅助手段在低光条件下检测行人。

Conclusion: 
文章总结了低光行人检测的研究现状，明确指出了当前的主要挑战和问题，同时提供了可供研究和开发先进行人检测算法的关键数据集，旨在为相关研究提供指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2311.08557</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>78. cs.LG-已训练嵌入的注意力机制在理论上确实选择了重要词元</title><link>https://arxiv.org/pdf/2505.17282</link><description>Background: 
词嵌入在语言建模中扮演着关键角色，但由于缺乏理论理解，其实际应用的效果仍有待深入探讨。本文关注通过梯度下降获得的嵌入结构，特别是对于一种一维softmax注意力模型与线性头进行二元分类的研究，即 texttt{Softmax}( p^top E_X^top ) E_X v = frac{ text{求和}_{i=1}^T text{exp}(p^top E_{x_i}) E_{x_i}^top v}{text{求和}_{j=1}^T text{exp}(p^top E_{x_{j}}) }，其中 E_X 包含输入序列的嵌入，p 是 text{langle cls rangle} 词元的嵌入，v 是输出向量。本文基于此模型进一步探讨了词嵌入的理论结构及其影响。

Innovation: 
本文提出了一个新的视角，认为通过梯度下降训练的词嵌入能够捕捉到数据集中词元的重要程度，并且在经过进一步训练后，softmax函数选择那些对于标签起关键预测作用的词元，从而最大化其选择的边缘。该研究利用真实世界数据集（IMDB, Yelp）进行实验，验证了理论模型的预测结果。

Conclusion: 
本文通过理论分析和实验验证，证明了一种通过训练获得的注意力机制确实能够在二元分类任务中选择重要的词元，并且这些选择遵循了词元在数据集中的频率和其对标签预测的影响。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.17282</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>79. cs.LG-使用随机向量功能性链接网络进行高效统一逼近</title><link>https://arxiv.org/pdf/2306.17501</link><description>Background: 
随机向量功能性链接（RVFL）网络是一种深度为2的神经网络，具有随机内部权重和偏置。训练过程中只需学习外部权重，因此优化过程简化为线性优化任务，能够避免非凸优化问题的陷阱。已有研究表明RVFL可以近似连续函数，但本研究首次证明了在无限范数下，使用高斯分布作为内部权重的ReLU激活RVFL网络能够逼近Lipschitz连续函数。此外，研究者还给出了以高概率达到给定精度所需的隐藏层节点数的非渐近下界，这一下界与目标函数的Lipschitz常数、所需的精度以及输入维数等因素有关。该证明方法基于概率论和调和分析理论。

Innovation: 
首次在无限范数下，使用高斯分布作为内部权重的ReLU激活RVFL网络能够逼近Lipschitz连续函数；给出了以高概率达到给定精度所需的隐藏层节点数的非渐近下界，该下界依赖于目标函数的Lipschitz常数、精度要求和输入维度。

Conclusion: 
研究利用RVFL网络在无限范数下逼近Lipschitz连续函数的能力，并提供了保证高概率精度的非渐近节点数下界，这种方法基于概率论和调和分析。</description><guid isPermaLink="true">https://arxiv.org/pdf/2306.17501</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>80. cs.LG-Log-Linear Attention</title><link>https://arxiv.org/pdf/2506.04761</link><description>Background: 
Transformer模型中的注意力机制是实现准确且可扩展序列建模的重要基础，但其计算复杂度为平方级，内存复杂度为线性级，这仍然是显著的瓶颈。虽然线性注意力和状态空间模型能够提供线性时间、常数内存的序列建模能力，并且可以通过在序列长度上进行矩阵乘法丰富的并行化来高效训练，但这些模型本质上仍然是循环神经网络（RNN），其使用固定大小的隐藏状态来建模上下文，这是其发展方向上的一个根本限制。

Innovation: 
本文提出了一种新的注意力机制——对数线性注意力（Log-linear Attention），它在保持线性注意力高效性的同时，提高了软最大注意力的表达能力。对数线性注意力采用了以对数方式增长的隐藏状态集代替了固定大小的隐藏状态。特别地，在特定的生长函数下，该机制可以获得类似于线性矩阵乘法丰富的并行形式，其计算成本对序列长度呈对数线性关系。对数线性注意力是一种通用框架，可以容易地应用于现有的线性注意力变种之上。作为实例，作者将对数线性注意力应用于两种近期的架构——Mamba-2和Gated DeltaNet，发现其性能优于其线性时间变体。

Conclusion: 
对数线性注意力提供了一种新的机制，平衡了线性注意力的效率与软最大注意力的表达能力，能够以对数线性的计算复杂度建模序列，适用于当前线性注意力变种的增强，显示出在序列建模上的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.04761</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>81. cs.LG-无免费午餐：重新思考LLM推理中的内部反馈</title><link>https://arxiv.org/pdf/2506.17219</link><description>Background: 
强化学习作为一种后训练大规模语言模型（LLMs）提高推理能力的强大范式已逐渐显现。RLHF和RLVR等方法显示出显著的效果，但它们需要大量的外部监督。研究另一种类别的方法，即仅依赖内部模型衍生信号（不依赖外部奖励）的强化学习从内部反馈（RLIF），本文进行了一项深入调查。RLIF利用未监督的奖励代理，例如令牌级别的熵、轨迹级别的熵和自我确定性。理论分析显示这些内部目标部分等价，实验证明RLIF方法能够提高连接训练初期基LLMs的推理性能，与RLVR技术相当或超过。然而，随着训练过程的推进，其性能会下降，甚至低于训练前的模型。对于指令调优模型，RLIF几乎没有改进作用，表明对于已经接受指令调优的LLM，内部反馈的收益递减。通过混合模型权重，进一步分析了这些限制的原因，对如何将内部反馈信号集成到LLM训练中提出了实用指南。本文认为内部反馈需进一步优化以更有效地对LLM进行后训练改进策略进行指导

Innovation: 
研究了依靠内部模型衍生信号的RLIF方法，不同于依赖外部奖励的RLHF和RLVR。利用未监督的奖励代理如令牌级别熵、轨迹级别熵和自我确定性评估各种RLIF策略。实验结果表明，即使在开始训练阶段，RLIF也能提升基LLMs的推理性能，且在某些任务上能够或超过RLVR。进一步通过混合模型权重，分析了RLIF在训练过程中表现下降的原因，提出了实用指南以优化内部反馈的集成。也指出了RLIF在指令调优模型中改善作用有限，这一限制的原因和改进方案

Conclusion: 
RLIF可以在训练初期提升基LLMs的推理性能，但训练过程中会表现为性能下降甚至低于训练前的模型。对于已经完成指令调优的LLM，RLIF带来的内部反馈带来的改进作用有限，说明了对于已经接受指令调优的LLM，内部反馈的收益递减。通过混合模型权重进一步分析了这一限制以及RLIF在训练中的表现，以提出实用的集成内部反馈信号的建议。进一步探索内部反馈的优化将是提升LLM后训练性能的关键方向</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17219</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>82. cs.LG-量子-经典混合稀疏神经网络</title><link>https://arxiv.org/pdf/2506.18240</link><description>Background: 
本工作针对量化神经网络训练中的背景提出了一个新颖的方法，通过四次方二进制优化（QBO）模型和向前间隔传播（FIP）方法，允许使用任意激活和损失函数，并通过样条插值来处理非线性和多层复合结构带来的挑战。通过量子计算直接解决二次约束二进制优化（QCBO）问题，来优化量子计算机上复杂的非线性函数，从而拓宽了量子人工智能的应用范围。论文通过理论分析得出了近似误差的上界和所需的Ising自旋数量，并证明了在量子或acles和系数矩阵精度有限条件下量子条件梯度下降（QCGD）算法的收敛性，指出了一种解大型QCBO问题的高效算法。结果显示，使用相干Ising机器解决了Fashion MNIST分类任务，精度达到94.95%，只需1.1位精度.

Innovation: 
引入了一种新颖的QBO模型和FIP方法，利用四次样条插值支持任意激活和损失函数。提出了利用量子计算直接解决高约束QCBO问题的QCGD算法，通过量子优化技术优化复杂的非线性函数并提供解决方案的理论保证，从而提高了精度和实用性。同时，提出的方法在理论分析上较好地平衡了误差和资源耗费之间的关系。

Conclusion: 
在使用QCGD并通过相干Ising机器实验验证后，该方法显示了高精度和资源上的优效性，进一步证明了量化神经网络与量子计算结合的可行性和价值，拓宽了其在人工智能中的应用范围。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18240</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>83. cs.LG-MS-TVNet：基于多尺度动态卷积的长序列时间预测方法</title><link>https://arxiv.org/pdf/2506.17253</link><description>Background: 
长序列时间预测主要依赖于Transformer和MLP模型，而卷积网络在此领域的潜力尚未得到充分探索。现有的模型在捕捉多期片段间的复杂关系和变量依赖性方面存在局限性，这些局限性限制了它们在长序列预测中的性能。

Innovation: 
提出了一种新颖的多尺度时间序列重塑模块，能够有效捕捉多期片段间的关系与变量依赖性。在此基础上，提出了MS-TVNet，这是一种多尺度3D动态卷积神经网络，能够在多种数据集上获得优于基线模型的性能，达到了长序列时间预测的SOTA结果，展示了卷积网络在捕捉复杂时间模式方面的有效性，为未来的研究提供了新的方向。项目代码已经开源。

Conclusion: 
MS-TVNet在长序列时间预测中展示了优越的性能，通过使用多尺度动态卷积网络，有效捕捉了时间序列中的复杂模式，提出了一个新的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17253</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>84. cs.LG-VRAIL：基于向量化奖励归因的可解释学习</title><link>https://arxiv.org/pdf/2506.16014</link><description>Background: 
本文提出了一种基于价值的强化学习（RL）的双水平框架——VRAIL（向量化奖励归因的可解释学习），该框架能够从状态特征中学习可解释的权重表示。研究表明，VRAIL 在 Taxi-v3 环境中的训练稳定性和收敛性优于标准的 DQN，无需对环境进行修改。进一步的分析表明，VRAIL 可以揭示具有语义意义的子目标，如乘客拥有等，这凸显了其产生人类可解释行为的能力。

Innovation: 
VRAIL 提出了一种新颖的双层次方法，该方法结合了深度学习和强化学习，通过潜在奖励变换来塑造学习过程。估计器可以建模为线性或二次形式，允许单个特征及其交互的归因。这种方法有助于提高可解释性，使得学习过程更加透明。

Conclusion: 
研究发现，VRAIL 提供了一个通用的、模型无关的奖励塑造框架，这种框架能够同时提升学习的效率和可解释性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16014</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>85. cs.LG-非平衡鞍点伴随采样</title><link>https://arxiv.org/pdf/2506.18165</link><description>Background: 
最近，基于学习的动力采样器取得了显著进展，这些方法旨在从给定的非归一化密度中采样。这些方法通常遵循两种范式之一：(i) 使用标准参考过程将采样问题形式化为无偏随机最优控制（SOC）问题，或 (ii) 通过重要性加权采样细化退火路径测度。尽管退火方法在引导样本向高密度区域移动方面具有优势，但依赖重要性采样的方法在实践中存在高方差和有限可扩展性的问题。

Innovation: 
本文介绍了非平衡鞍点伴随采样（NAAS），这是一种基于SOC的动力采样器，它利用了退火参考动力学原理，而无需依赖重要性采样。NAAS采用了一种基于伴随匹配的精简伴随系统，使训练更高效和可扩展。

Conclusion: 
通过广泛的实验展示了本方法的有效性，包括从经典能量景观和分子玻尔兹曼分布采样。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18165</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>86. cs.LG-TabArena：面向表格数据机器学习的持续基准</title><link>https://arxiv.org/pdf/2506.16791</link><description>Background: 
随着深度学习和基础模型在表格数据中的应用越来越普及，对标准化和可靠基准的需求比以往任何时候都高。然而，当前的基准是静态的，即使发现错误、更新模型版本或发布新模型，其设计也不会更新。因此，需要一种可以持续维护和更新的动态基准系统来适应不断变化的技术环境和数据类型。这促使引入了TabArena，这是一个持续维护的生活基准，用于表格数据上的机器学习模型评估。

Innovation: 
TabArena是首个持续维护的动态表格数据基准系统。通过人工精选数据集和良好实现的模型，执行大规模基准测试并生成公开排行榜，组建经验丰富的维护团队，致力于解决传统基准更新缓慢的问题。此外，研究凸显了验证方法和超参数配置集成对评估模型性能的影响。研究发现，在实际表格数据集中，梯度提升树仍然是强有力的竞争者，但大规模时间预算下集成的深度学习模型已迎头赶上；同时，基础模型在小型数据集上表现出色。集成多个模型可进一步推进表格机器学习的最先进状态，同时也探讨了各个模型的贡献。

Conclusion: 
TabArena通过引入公共排行榜、可重复的代码和维护协议，为表格数据上的机器学习模型评估提供了一个生动的基准系统，展示了集成多个模型在表格机器学习中的作用，以及每个模型的贡献，进一步推动了该领域的研究和发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16791</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>87. cs.LG-Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning</title><link>https://arxiv.org/pdf/2506.07744</link><description>Background: 
现有的离线分层强化学习方法依赖于高级策略学习生成子目标序列。然而，这些方法的效率随着任务时间轴的增加而下降，并且缺乏在不同轨迹之间拼接有用状态过渡的有效策略。

Innovation: 
提出了Graph-Assisted Stitching（GAS）框架，将子目标选择问题作为图搜索问题来解决，而不是学习显式的高级策略。通过将状态嵌入到时间距离表示（TDR）空间中，GAS将来自不同轨迹的语义相似状态聚类为统一的图节点，从而实现高效的过渡拼接。算法应用最短路径算法来选择图中的子目标序列，同时低层次策略学习到达这些子目标。引入了时间效率（TE）度量来过滤出噪声或低效的过渡状态，显著提升任务性能。GAS在行动、导航和操纵任务上均优于先前的离线HRL方法，特别是在对拼接最敏感的任务中，得分达到88.3，远超之前的最佳得分1.0

Conclusion: 
GAS在行动、导航和操纵任务上表现出色，特别是在对拼接要求最高的任务上，显著优于之前的最佳方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07744</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>88. cs.LG-使用合成数据提高Few-shot模型泛化能力的理论保证</title><link>https://arxiv.org/pdf/2505.24190</link><description>Background: 
Few-shot图像分类由于缺乏标记训练样本仍然具有挑战性。利用合成数据对其进行增强被认为是一种有潜力的方法，但训练于合成样本的模型往往因为真实分布与合成分布之间的鸿沟而出现性能下降。针对这一局限，本文建立了可量化分布差异对监督学习影响的理论框架，特别是在图像分类的情境下。该框架为生成优质合成样本并训练具有良好泛化能力的预测器提供了实操指导。

Innovation: 
本文提出了一种基于理论的新型算法，该算法结合了原型学习，不仅优化了数据分区，还有效地弥合了真实少量数据与合成数据之间的差距。通过广泛的实验验证，本文方法在多个数据集上表现出了优于现有最先进的方法的性能优势，从而证明了使用合成数据提高Few-shot模型泛化能力的可能性并提供了理论保证。

Conclusion: 
本文通过建立一个理论框架并提出一种新型算法，证明了利用合成数据可以提高Few-shot图像分类模型的泛化能力，且实验结果表明其性能优于现有方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.24190</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>89. cs.LG-基于数据驱动的高分辨率集合天气预报支持可再生能源规划与运营</title><link>https://arxiv.org/pdf/2505.04396</link><description>Background: 
可再生能源，特别是风能的规划和运行依赖于准确、及时和高分辨率的天气信息。粗网格数值天气预报通常会缩小规模以满足这些要求，但随之带来了尺度不一致、过程表示误差、计算成本和来自混沌性、模型偏差和大尺度强迫多源不确定性纠缠的问题。该研究通过学习目标风电场的高分辨率数值天气模拟的气候分布，解决这些问题，从而生成准确、细粒度、多变量的高分辨率天气模式集合预报。使用观测气象记录和风力涡轮机功率输出作为参考，该方法在确定论或概率技能以及经济效益方面优于现有数值/统计预报细化管道。此外，100组10天、空间分辨率1公里、输出频率15分钟的预报在一个高端GPU上仅需不到1小时，而传统数值模拟需要上万小时的CPU时间。这大大降低了计算成本，但也保持了准确性，为更高效和可靠的可再生能源计划和运营铺平了道路。

Innovation: 
该研究通过学习目标风电场的高分辨率数值天气模拟的气候分布，结合粗糙网格的大尺度预报生成高度准确和细粒度的天气模式集合预报。这种方法显著降低了计算成本，同时保持了预报的准确性，为可再生能源的规划和运营提供了高效的解决方案。此外，提出的模型在与现有统计/数值预报细化管道进行比较时，无论是在确定论还是概率技能方面，都表现出优越性，并且在经济收益方面也更具优势。

Conclusion: 
该方法通过大大提高计算效率，同时保持高准确性，对可再生能源的规划和运营具有重要意义。通过提供高分辨率的天气预测，可以更好地预测风能和其他可再生能源的可用性，从而提高能源系统的可靠性和经济效益。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.04396</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>90. cs.LG-TSPulse：双空间超紧凑预训练模型以实现快速时间序列分析</title><link>https://arxiv.org/pdf/2505.13033</link><description>Background: 
时间序列预训练模型近年来取得了显著进展，提升了时间序列表示学习的效果。然而，当前最先进的模型往往规模宏大，需要大量的计算资源。本研究旨在提出一种名为TSPulse的超紧凑型时间序列预训练模型，该模型仅有100万个参数，能够在分类、异常检测、插值和检索等任务中表现出色，同时大幅降低计算需求并支持GPU-free推断，从而定义了效率高的时间序列预训练模型的新标准。

Innovation: 
TSPulse在架构和任务层面引入了创新：在架构层面，它采用双空间掩码重构方法，从时间域和频域中学习互补的信号，并通过双重嵌入分离生成详细和高层次的语义嵌入。在任务层面，它结合了TSLens——一种细调组件，支持特定任务的特征关注；多头三角法，用于通过结合多个预测头的输出来增强异常检测；以及混合掩膜预训练，用于提高零样本插值性能。

Conclusion: 
TSPulse在UEA分类基准测试中获得了5-16%的性能提升，在TSB-AD异常检测领军人榜上提高了20%，在零样本插值中提高了50%，并且在时间序列检索中提高了25%。尽管TSPulse模型仅有100万个参数（是现有最优模型的10至100倍小），并且支持GPU-free推断，却仍能实现这些优异的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.13033</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>91. cs.LG-Follow-the-Perturbed-Leader 接近于 m-集合半伯努利问题的最佳兼顾两极世界结果</title><link>https://arxiv.org/pdf/2504.07307</link><description>Background: 
我们讨论的是组合半伯努利问题中的常见情况——m-集合半伯努利问题，其中学习者从总共d个臂中精确选择m个臂。在对抗性设置下，FTRL策略已知能够达到$text{O}(text{sqrt}(nmd))$的最优遗憾界限。然而，这种方法要求在每个时间步骤中显式地计算臂选择概率并通过优化问题解决，随后按照这些概率采样，这带来了计算复杂性。为避免这些复杂性，FTPL策略采用一种更简单的做法，即选择m个估计损失中最小的臂进行随机扰动。本文研究了在对抗性设置下对FTPL策略使用Fréchet扰动时的性能，并展示了其接近最优的遗憾界限$text{O}(text{sqrt}(nm)(text{sqrt}(dlog(d))+m^{5/6}))$及在随机设置中达到最好两极共存遗憾界限的能力，即在随机设置中达到对数遗憾界限。另外，我们的理论表明，错误的因子是不可避免的，任何改进都需要从根本上差异和更具有挑战性的方法。

Innovation: 
提出使用Fréchet扰动的FTPL策略在对抗性设置下能够接近最优的遗憾界限，并且在随机设置中可以达到最好的两极共存遗憾界限，即在随机设置中实现对数遗憾界限。同时，研究表明这些方法的局限性，任何进一步改进都需要完全不同且更具挑战性的方法。

Conclusion: 
本文通过分析对抗性设置下的m-集合半伯努利问题，展示了FTPL策略在使用Fréchet扰动时的性能，达到了接近最优的遗憾界限，并且在随机设置中实现了最好的两极共存遗憾界限。同时，理论结果也展示了此类方法的限度，进一步改进需要全新的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.07307</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>92. cs.LG-化学知识指导下的隐私感知 retrosynthesis 学习框架</title><link>https://arxiv.org/pdf/2502.19119</link><description>Background: 
化学反应数据是制药、材料科学和工业化学等竞争领域的重要资产，因其具有保密性和商业价值，数据往往需要严格保护。然而，当前通过多源数据集中训练预测模型的机器学习反合成反应范式，由于需要跨组织广泛共享数据和频繁的数据传输，增加了数据暴露给未经授权访问或拦截的风险。因此，存在需要一种既能保护数据隐私又能有效训练反合成反应模型的解决方案，以确保数据的安全与有效利用。

Innovation: 
本文提出了一种隐私保护的反合成反应模型训练方法——化学知识指导下的框架（CKIF）。CKIF能够在不对私密反应数据保密的前提下实现多个化学组织间的分布式训练。它不直接收集原始反应数据，而是通过迭代、基于化学知识的模型参数聚合来学习反合成反应模型。CKIF使用预测反应物的化学性质来定量评估模型可观察的行为，以确定用于模型聚合的自适应权重。实验证明，CKIF在多种反应数据集上明显优于多个强基准模型，从而提供了一种有效且安全的反合成反应模型训练方法。

Conclusion: 
CKIF有效地解决了传统训练范式中存在的隐私保护问题，能够在多组织间安全地训练反合成反应模型。通过利用化学知识，CKIF实现了隐私保护与模型性能之间的平衡，验证了其在实际应用中的有效性和可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.19119</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>93. cs.LG-证明作为解释：可靠的预测的简短证书</title><link>https://arxiv.org/pdf/2504.08377</link><description>Background: 
该研究关注解释性的AI模型，其中解释基于训练数据的子集S'，使得所有预测错误不超过b的分类器h'在S'上的预测结果与目标函数h*在S'上的预测结果一致。这种机制在假设目标函数h*属于假设类H且数据集S包含的异常点不超过b的情况下，作为证明x确实具有标签y的依据。

Innovation: 
该研究对假设类H和一般值b（非负）下的问题进行了广泛考虑，定义了假设类H的鲁棒空心星数，并证明其能精确地刻画最小证明模块所需的最大尺寸，并分析了几个自然类别下的情况。研究还探讨了最坏情况下的分布约束证明模块大小以及基于分布和目标函数的证明系数，这些约束有助于控制预测所需的样本大小。

Conclusion: 
研究证明了证据系数ε_x、b和假设类H的VC维d与样本大小之间的匹配上界和下界。研究结果表明，通过准确控制所需样本大小，可以实现可靠的预测。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.08377</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>94. cs.LG-SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models</title><link>https://arxiv.org/pdf/2309.05019</link><description>Background: 
扩散概率模型（DPMs）已经在生成任务中取得了显著的成功。尽管从DPMs采样等同于解决扩散随机微分方程（SDE）或常微分方程（ODE），这一过程非常耗时，因此提出了许多基于改进微分方程求解器的快速采样方法。多数技术倾向于解决扩散ODE，但由于其效率更高。然而，随机采样可以提供多样性更高且质量更好的数据额外优势。已有研究主要关注随机微分方程（SDE）的变差控制扩散SDE和线性多步SDE求解器两个方面。

Innovation: 
本文作者提出了一种改进的高效随机亚当斯方法，命名为SA-Solver，用于解决扩散SDE以生成高质量数据。经过实验验证，SA-Solver在少步采样方面获得了优于或与现有最先进的采样方法相当的性能；在多个基准数据集上实现了最新的FID分数，同时评估函数调用次数适当时效果最佳。其中，SA-Solver的核心创新在于提供了一种高效的随机SDE求解方法，旨在平衡采样质量和速度。

Conclusion: 
实验结果表明，SA-Solver实现了以下目标：1) 在少步采样方面优于或达到了现有最先进的采样方法；2) 在多个基准数据集上实现了最新的FID得分，在合适的函数评估次数（NFEs）使用下效果最佳。</description><guid isPermaLink="true">https://arxiv.org/pdf/2309.05019</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>95. cs.LG-采用深度上下文蒸馏训练即插即用知识模块</title><link>https://arxiv.org/pdf/2503.08727</link><description>Background: 
在大型语言模型预训练之后动态整合新信息或快速演变的信息依然具有挑战性，特别是在数据量少或处理私有和专业文档的情况下。上下文学习和检索增强生成（RAG）方法存在局限性，如较高的推理成本和无法捕捉全局文档信息。

Innovation: 
本文提出了一种通过训练文档级别的知识模块（KMs）来模块化知识的方法。KMs被设计为轻量级、参数效率高的LoRA模块，能够存储新文档的信息并按需插入模型。作者还提出了深度上下文蒸馏方法，使KMs参数模拟带有文档上下文的教师模型的隐藏状态和逻辑值，这种方法在两个数据集中超越了标准的下一个词预测和预指令训练技术。

Conclusion: 
该研究突显了KMs与RAG之间的协同作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.08727</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>96. cs.LG-关于前向前向算法的进步</title><link>https://arxiv.org/pdf/2504.21662</link><description>Background: 
前向前向算法已在机器学习研究中不断完善，能够处理更复杂的任务，并模仿现实应用。通过多种技术和改进，该算法能够更好地处理像CIFAR10这样具有挑战性的数据集，同时保持其灵活性和低内存使用特性。

Innovation: 
改进包括卷积通道分组、学习率计划和训练期间独立块结构的结合，这导致测试错误率减少了20%。此外，为了在低容量硬件项目中进一步实施，本文介绍了更轻量级的模型，实现了21±3%的低测试错误率，并且可训练参数数量在164,706到754,386之间。

Conclusion: 
这为后续研究这些类型的神经网络的整体验证和验证提供了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.21662</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>97. cs.LG-双线性MLPs实现基于权重的机理可解释性</title><link>https://arxiv.org/pdf/2410.08417</link><description>Background: 
对深度神经网络中的多层感知机（MLPs）如何进行计算的传统理解仍然不够深入。现有的可解释性工作可以从输入数据集的隐藏激活中提取特征，但通常无法解释MLP权重如何构造这些特征。元素级非线性引入了高阶交互作用，使得追踪MLP层中的计算变得困难。本研究分析了没有元素级非线性的Gated Linear Unit（GLU）的一种类型——双线性MLPs，尽管如此，它们仍能达到竞争性的性能。双线性MLPs可以完全用三阶张量表示线性操作，因此便于灵活分析权重。通过特征值分解分析双线性MLPs的权重特征谱揭示了令人可解释的低秩结构，这种结构在玩具任务、图像分类和语言建模中均有体现。利用这种理解，可以设计对抗样本、揭示过拟合并直接从权重中识别小型语言模型电路。研究结果表明，双线性层可以作为当前激活函数的可解释替换方案，并且基于权重的解释方法对于理解深度学习模型是可行的

Innovation: 
本研究通过分析双线性MLPs，揭示了基于权重的可解释性机制。探讨了通过特征值分解分析双线性MLPs权重特征谱的方法，展示了这种低秩结构在不同任务中的可解释性，为对抗样本设计、过拟合揭示和语言模型电路识别提供了新的视角。研究提出了双线性层作为传统激活函数的可解释替代品，并强调基于权重的解释方法可用于理解深度学习模型

Conclusion: 
双线性MLPs作为一种没有元素级非线性的Gated Linear Unit类型，同时具备高可解释性结构和竞争性性能。通过特征值分解分析双线性MLPs的权重，研究人员揭示了可解释的低秩结构，并使用这种方法生成对抗样本、揭示过拟合现象和识别小型语言模型电路。研究结果表明，基于权重的可解释性在深度学习模型中是可行的，双线性层可以作为一种新的激活函数替代方案</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.08417</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>98. cs.LG-使用解耦扩散顺序蒙特卡洛方法求解线性高斯贝叶斯逆问题</title><link>https://arxiv.org/pdf/2502.06379</link><description>Background: 
最近的研究表明，预训练的生成扩散模型可以作为先验用于解决贝叶斯逆问题。在这项研究中，作者通过设计一种基于‘解耦扩散’的顺序蒙特卡洛方法，对线性高斯逆问题进行了研究。该方法使得样本可以进行更大幅的更新，从而提高了算法的有效性。这种方法适用于合成数据、蛋白质数据和图像数据，并且展示了如何将该方法扩展到离散数据上。

Innovation: 
设计了一种基于‘解耦扩散’的顺序蒙特卡洛方法（Decoupled Diffusion Sequential Monte Carlo，DDSMC），解决了线性高斯逆问题。此方法能够进行更大规模的样本更新，且是渐进准确的。展示了该方法在合成数据、蛋白质数据和图像数据中的有效性，并探讨了扩展到离散数据的可能性。

Conclusion: 
通过使用解耦扩散顺序蒙特卡洛方法，作者有效解决了线性高斯逆问题。此方法不仅在合成数据上表现良好，也能够处理蛋白质和图像数据。同时，此方法还可以扩展应用于离散数据中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.06379</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>99. cs.LG-重新思考早期停止策略：仅先细化后校准</title><link>https://arxiv.org/pdf/2501.19195</link><description>Background: 
机器学习分类器经常产生概率预测，这些预测对于精准和可解释的决策制定至关重要。这些预测的质量通常通过适当的损失函数（如交叉熵）进行评估，该损失函数分解为两个组成部分：校准误差衡量整体的欠/过自信程度，而细化误差衡量区分不同类别的能力。本文研究了校准-细化分解的新变分公式，该公式揭示了后置校准的新视角，并具备快速估计不同术语的能力。通过这种新视角，本文提供了理论和实验证据，证明在训练过程中校准误差和细化误差并未同时被最小化。基于验证损失选择的最佳时期因此是一个对于两种误差都不理想的妥协点。现有的方法即根据验证损失选择最佳时期，导致了次优解。

Innovation: 
提出了在训练过程中仅优化细化误差（Refine），然后使用标准技术进行校准后的后置校准（Calibrate）的方法。该方法能够无缝集成到任意分类器并提升了多种分类任务的表现。通过这种分期优化策略，可以在细化和校准之间找到更优的平衡点。

Conclusion: 
现有基于验证损失选择最佳时期的策略由于未同时优化校准和细化误差而导致次优解，本文提出的一种分期优化策略（先细化再校准）在多种分类任务中表现出一致的性能提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.19195</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>100. cs.LG-超越拓扑自解释性GNN：一个形式化可解释性视角</title><link>https://arxiv.org/pdf/2502.02719</link><description>Background: 
SE-GNNs作为设计上具有解释性的GNNs已经受到广泛关注，然而，它们的解释性质和局限性尚未得到充分理解。本文通过对几种流行的SE-GNNs提取的解释进行形式化定义（称为Minimal Explanations, MEs），并与已建立的解释概念，比如Prime Implicant (PI) 和忠实解释进行比较，来填补这一空白。研究发现MEs在特定任务上与PI解释匹配良好，但在其他情况下，MEs可能不如PI解释信息量大，并且与广泛接受的忠实性概念存在偏差。尽管忠实和PI解释信息量大，但难以找到，且可能非常庞大。

Innovation: 
本文首次形式化了SE-GNNs的解释（Minimal Explanations, MEs），并与PI和忠实解释进行了比较。此外，提出了Dual-Channel GNNs，该模型结合了白盒规则提取器和标准SE-GNN，可以自适应地结合两种通道，并通过实验证明了简化的Dual-Channel GNNs能够在某些任务上达到或超过广泛使用的SE-GNNs的表现。

Conclusion: 
研究表明，虽然PI和忠实解释信息量更大，但难以找到并且可能非常庞大。因此，拓展SE-GNNs的解释能力是一种自然选择。本文提出的Dual-Channel GNNs通过结合白盒规则提取器和SE-GNN，能够有效缓解初始解释的局限性，实验结果显示其在某些任务上的表现甚至优于现有方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.02719</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>101. cs.LG-平衡天平：不平衡数据学习的理论与算法框架</title><link>https://arxiv.org/pdf/2502.10381</link><description>Background: 
在机器学习中，类别不平衡仍然是一个主要挑战，尤其是在具有长尾分布的多分类问题中。现有的方法，如数据重采样、成本敏感技术和逻辑损失修改，尽管很流行且往往有效，但却缺乏坚实的理论基础。例如，成本敏感方法在贝叶斯一致性方面存在问题。这篇论文提出了一种新的理论框架来分析不平衡分类的一般化问题，并介绍了一种适用于二分类和多分类情况的新类不平衡边际损失函数，从而证明了其强$H$-一致性和基于经验损失及一种新的类敏感Rademacher复杂度得到的学习保证。

Innovation: 
1. 提出了一个新的理论框架来分析不平衡分类的一般化问题。n2. 提出了适用于二分类和多分类情况的新类不平衡边际损失函数，并证明了其强$H$-一致性。n3. 基于经验损失和新的类敏感Rademacher复杂度推导了相应的学习保证。n4. 设计了新颖的一般学习算法IMMAX (Imbalanced Margin Maximization)，该算法结合了置信边际，并适用于各种假设集。

Conclusion: 
尽管本文的焦点在于理论工作，但通过大量的实证研究还展示了我们算法相对于现有基线的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.10381</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>102. cs.LG-通过ReLU多层感知机的最大正则性实现逼近与学习的统一</title><link>https://arxiv.org/pdf/2409.12335</link><description>Background: 
深度学习的基础植根于逼近论和学习理论的看似对立的观点。逼近论强调大/表达能力强的模型不必具备泛化能力，而学习理论则关注那些能泛化但可能不够大/受限的模型。受实际深度学习实现中既表达能力强又能统计可靠的影响，本文探讨是否存在一类既足够大以实现通用逼近又足够结构化以保证泛化的神经网络。

Innovation: 
本文通过识别一类具有高结构化的ReLU多层感知机（MLPs），其既是最佳函数逼近器又是统计表现良好的网络，创造性地解决了这一问题。证明了该类MLPs可以逼近任何$(L,beta)$-Hölder函数至均匀$frac{1}{beta n}$误差，宽度为$text{O}(dn^{frac{d}{L}})$，深度为$text{O}(text{log}(d))$，参数数量为$text{O}(dn^{frac{d}{L}})$，权重和偏置值限定在$text{0, textpm} frac{1}{2}$，首尾两层除外其最大值在$n$内。此外，此类MLPs在给定$N$个独立同分布归一化超高斯训练样本时达到了接近最优的样本复杂度$text{O}(text{log}(N)/text{sqrt}(N))$。方法上，采用新的三角剖分构建方法和新的证明技术确保了构造中的函数保持其正则性，以及任何一致连续函数的正则性。结果表明，神经网络在合适有限集上可以解决McShane延拓问题.

Conclusion: 
本文通过构建一种具有最大正则性的ReLU多层感知机类，证明了存在既能够进行通用逼近又能够泛化的神经网络。进一步，该类网络不仅在逼近连续函数方面表现出色，而且在统计表现方面也表现出优异的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.12335</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>103. cs.LG-联邦学习客户端聚类以适应数据漂移</title><link>https://arxiv.org/pdf/2411.01580</link><description>Background: 
联邦学习（FL）能够在不中央集合并保留用户隐私的情况下，在边缘设备上训练深度模型。然而，客户端异质性会减慢收敛速度并限制全球模型精度。聚类联邦学习（Clustered FL, CFL）通过将具有相似表示的客户端分组并在每个聚类上训练单独的模型来解决这一问题。但是在实践中，客户端数据会随着时间推移发生变化，我们称之为数据漂移，这破坏了聚类的一致性并降低了性能。数据漂移可以以不同的形式发生，包括输出值的变化、输入特征的变化或两者之间的关系的变化。由于这些变化，客户端数据之间的异质性在不断提高。现有的CFL方法不能很好地应对数据漂移，导致性能不稳定或模型精度降低，从而减缓了收敛速度。

Innovation: 
本文提出了FIELDING，一种用于处理不同类型数据漂移的低开销CFL框架。FIELDING能够在个体客户端级别检测漂移并执行选择性的重新聚类，以平衡聚类质量和模型性能，同时保持对恶意客户端和异质性变化的鲁棒性。FIELDING能够在比现有最先进的CFL方法更快的速度下实现目标精度，速度提高1.16到2.23倍，并且将最终模型的准确性提高了1.9％到5.9％，从而使得联邦学习框架更能适应数据漂移的挑战。

Conclusion: 
通过应用FIELDING，能够显著改善最终模型的准确性，同时加快训练速度，确保面对恶意客户端时的鲁棒性，并能够有效处理不同形式的数据漂移，提高联邦学习的有效性和可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.01580</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>104. cs.LG-使用参数化量子电路进行情感识别的表示学习</title><link>https://arxiv.org/pdf/2501.12050</link><description>Background: 
量子机器学习（QML）为复杂信号域中的表示学习提供了有希望的发展途径。然而，语音情感识别（SER）由于声音信号中微妙的时间变化和情绪状态的重叠，面临着挑战。这项研究探索了参数化量子电路（PQCs）在SER中的应用，通过结合PQCs和传统卷积神经网络（CNN），利用量子特性（如叠加和纠缠）来丰富情感特征表示，以解决上述问题，并改善SER的分类性能。

Innovation: 
提出了一种混合量子经典架构，将PQCs集成到传统CNN中，利用量子属性（如叠加和纠缠）增强情绪特征表示。实验表明，与纯经典CNN基线相比，该混合模型在三个基准数据集（IEMOCAP、RECOLA和MSP-IMPROV）上的分类性能更优，且参数量减少超过50%。这为QML在情感识别中的应用提供了早期证据，并为未来的量子赋能情感计算系统奠定了基础。

Conclusion: 
研究展示了QML在情感识别中的潜在效果，并为未来的情感计算系统开发铺平了道路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.12050</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>105. cs.LG-在模型脱缰瞬间的对抗性推理</title><link>https://arxiv.org/pdf/2502.01633</link><description>Background: 
随着大型语言模型（LLMs）变得越来越强大和普及，对其失败案例的研究变得越来越重要。最近在标准化、衡量和扩展测试时计算方面的进展提出了新的方法以优化模型在困难任务上的高性能。在本文中，我们利用这些进展研究模型脱缰（即引诱对齐的LLMs产生有害回应）的方法，提出了对抗性推理自动脱缰的新方法，以补充那些旨在在推理时间计算与对抗性鲁棒性之间进行权衡的模型的防御措施。这种方法为我们理解LLM的脆弱性提供了一个新的视角，为开发更稳健和可信赖的AI系统奠定了基础。

Innovation: 
本文提出了一种利用对抗性推理方法进行自动脱缰的新技术。该方法通过利用损失信号来引导测试时计算，成功地针对许多对齐的LLM实现了最先进的攻击成功率，甚至那些希望通过在推理时间计算与对抗性鲁棒性之间权衡来提高防御能力的模型。这一方法提供了一种新的理解LLM漏洞的方式，为构建更安全的AI系统奠定了基础。

Conclusion: 
本文介绍了对抗性推理在脱缰瞬间的应用，该方法通过结合损失信号指导测试计算，在许多对齐的LLM上实现了最高的攻击成功率，为理解和改进LLM的鲁棒性和可信度提供了新的视角和策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.01633</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>106. cs.LG-无梯度切片方法在深层神经网络中的主动学习</title><link>https://arxiv.org/pdf/2410.02145</link><description>Background: 
主动学习方法旨在提高机器学习中的采样复杂度。本文研究了一种基于新型无梯度切片训练方法的主动学习方案，用于任意深度的ReLU网络，并发展了相关的收敛理论。传统上，切片算法用于线性模型，本文证明了这些算法可以扩展到深层神经网络，尽管它们是非凸且非线性的。通过合成数据实验和真实数据集的情感分类任务，本文展示了所提出的方法在现有流行深度主动学习基准中的有效性.

Innovation: 
首次证明传统的切片算法可以应用于深层神经网络，提出了一种新的无梯度切片训练方法，从而实现了首个具有收敛保证的深层主动学习方案，揭示了可行集的几何收缩率.

Conclusion: 
通过合成数据实验和真实数据集的情感分类任务，本文证明了所提出的方法在现有流行深度主动学习基准中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.02145</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>107. cs.LG-概念瓶颈模型尊重局部性吗？</title><link>https://arxiv.org/pdf/2401.01259</link><description>Background: 
基于概念的可解释性方法使用易于人类理解的中介产生机器学习模型的解释。这些方法假设概念预测能帮助理解模型内部的推理过程。本文通过分析概念预测器是否利用了“相关的”特征来做出预测来检验这一假设的真实性，该过程被称为局部性。概念预测器如果不尊重局部性，也会导致缺乏解释性，因为基于这些预测的概念预测依赖于虚假特征，使得概念预测的解释变得空洞。为了评估概念预测器是否尊重局部性，作者构建并使用了三个度量标准来描述模型何时尊重局部性，并通过理论结果补充了这些度量标准的分析。每个度量标准捕捉了一种不同的扰动概念，并评估对“无关”特征进行扰动是否会影响概念预测器生成的预测结果。研究发现，许多实际使用的基于概念的模型未能尊重局部性，因为概念预测器经常无法清楚地区分不同的概念。

Innovation: 
本文提出了一种评估概念预测器是否尊重局部性的方法，包括构建并使用了三个度量标准来描述模型何时尊重局部性。通过理论结果补充了这些度量标准的分析，并发现了许多实际使用的基于概念的模型未能尊重局部性的现象，提出了缓解这一问题的建议。

Conclusion: 
许多概念预测器未能尊重局部性，因为无法清楚区分不同的概念，使得基于这些概念的解释变得空洞。基于此研究结果，提出了缓解这一问题的建议。</description><guid isPermaLink="true">https://arxiv.org/pdf/2401.01259</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>108. cs.LG-通过将数据转换为与偏见正交实现事实上的公平性</title><link>https://arxiv.org/pdf/2403.17852</link><description>Background: 
机器学习模型在解决各领域复杂问题方面表现出了非凡的能力，但在某些情况下，这些模型可能会表现出有偏的决策，导致对不同群体的不平等对待。尽管已经进行了大量的关于反事实公平的研究，但减少多变量和连续型敏感变量对决策结果影响的方法仍然不足。现有的研究和方法还需要进一步发展，特别是在确保公平性的同时，能够保持预测准确性的技术上有所欠缺。

Innovation: 
本文提出了一种新型数据预处理算法（OB）来消除一组连续敏感变量的影响，从而在机器学习应用中促进反事实公平性。该算法基于结构因果模型（SCM）内的共轭正态分布假设，通过确保数据与观测到的敏感变量正交来实现反事实公平性。OB算法具有模型无关性，适用于各种机器学习模型和任务，并且包括稀疏变体以通过正则化提高数值稳定性。

Conclusion: 
通过在模拟数据集和实际数据集上的实证评估，实验结果表明，该方法能够在不牺牲准确性的前提下有效促进公平的结果。该方法对于解决机器学习中的公平性问题具有很大的应用潜力，并且能够为其他相关研究提供新的见解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.17852</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>109. cs.LG-显微镜图像的解缠表示</title><link>https://arxiv.org/pdf/2506.20649</link><description>Background: 
显微镜图像分析是多种应用的基础，从诊断到合成工程和环境监测。现代采集系统使获取大量图像成为可能，因此需要开发大量基于深度学习的自动图像分析方法。尽管深度神经网络在这一领域表现优异，但在显微镜图像分析中提高模型的可解释性仍然是一个挑战。

Innovation: 
本文提出了一种解缠表示学习(DRL)方法，旨在提高显微镜图像分类模型的可解释性。通过从合成数据中迁移学习获得的表示，该DRL框架在显微镜图像的三个不同领域（浮游生物、酵母细胞器和人类细胞）展示了兼顾准确性和可解释性的良好平衡。

Conclusion: 
研究表明，基于这一DRL框架，可以在显微镜图像分析领域实现具有良好准确性和可解释性的平衡。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20649</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>110. cs.LG-可解释的增强学习研究: 概念、算法、挑战</title><link>https://arxiv.org/pdf/2211.06665</link><description>Background: 
增强学习（RL）是一种流行的机器学习范式，智能代理通过与环境的交互来实现长期目标。深度增强学习（DRL）在各种复杂的控制任务中已经取得了显著的成功，尽管取得了鼓舞人心的结果，但基于深度神经网络的基础架构通常被视为一个黑箱，阻碍了在高安全性和可靠性要求的实际场景中信任和应用训练好的代理。为了解决这一问题，大量文献致力于通过构建内在可解释性或事后可解释性来揭示智能代理的内部运作。

Innovation: 
本文提供了一种全面回顾现有可解释的增强学习（XRL）工作的综述，并提出了一种新的分类框架，将先前的工作明确分类为模型解释、奖励解释、状态解释和任务解释方法。同时，本文还回顾和突出了能够利用人类知识促进学习效率和代理性能的方法，这些方法在XRL领域常常被忽视。此外，讨论了XRL领域的一些挑战和机遇，旨在为XRL领域提供高层次的总结，并激励未来对更有效XRL解决方案的研究。

Conclusion: 
本文意在提供XRL领域的高级综述，并激发对未来更有效的XRL解决方案的研究。同时，还收集和分类了开源代码，见此链接：[提供的链接]。</description><guid isPermaLink="true">https://arxiv.org/pdf/2211.06665</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>111. cs.LG-适应确定性约束的随机和有限和凸优化的一阶方法</title><link>https://arxiv.org/pdf/2506.20630</link><description>Background: 
该论文研究一类具有确定性约束条件的随机性和有限和凸优化问题。现有方法通常旨在找到一个$?epsilon$-几乎可行的随机最优解，其中期望的约束违背和期望的最优性差距都在一个预设容差$?epsilon$范围内。但在许多实际应用中，约束条件必须几乎完全得到满足，如果违反了这一要求，那么该解可能会不合适。论文分析了现有方法在此方面的问题。

Innovation: 
论文提出了用于找到一个$?epsilon$-确定性可行的随机最优解（$?epsilon$-SFSO），这种方法确保约束违背是确定性的，并且期望的最优性差距最多为$?epsilon$。该方法在一系列适当选择罚参数的二次惩罚子问题上仅使用一次加速随机梯度（ASG）方案或修改过的减小方差ASG方案。论文建立了求解$?epsilon$-SFSO的首次一阶查询复杂性界。同时，还推导出使用本方法求解样本均值问题中随机优化问题的$?epsilon$-SFSO首次一阶查询复杂性结果。

Conclusion: 
论文通过上述方法解决了随机和有限和凸优化问题中确定性约束条件的问题，确保了约束违背的确定性限制并且期望的最优性差距不超出$?epsilon$。这种方法的首次一阶查询复杂性得到了证明，并且在样本均值问题上的应用也得到了验证。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20630</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>112. cs.LG-LARP: 无偏见鲁棒数据预筛选</title><link>https://arxiv.org/pdf/2506.20573</link><description>Background: 
近年来，统计推断和机器学习方法取得了显著成功，这得益于大规模公开数据集的广泛可用性。然而，这些数据集中通常包含一些低质量或受污染的数据，对许多学习程序来说都是敏感的。因此，是否以及如何预筛选公开数据集以促进下游学习的准确性成为了一个关键问题。技术上，这需要构建能够证明保护预设下游学习器免受污染数据影响的原理性预筛选方法，且这种方法要对特定学习器无偏见。

Innovation: 
本文提出了无偏见鲁棒数据预筛选（LARP）框架，针对特定的学习器集，通过最小化最坏情况损失来寻找预筛选方法，确保这些预筛选方法能够在鲁棒性方面保护预设的下游学习器。研究首先在基于Huber估计器的Huber数据污染模型下实现该框架，探讨了不同预筛选方法的特性，理论结果表明，对不同学习器集进行LARP会比为每个学习器/场景单独进行预筛选导致模型性能有所下降。通过在真实世界图像和表格式数据上进行实验，验证了这种性能下降，并将这种权衡考虑在游戏理论框架中，展示了LARP在大规模数据集中的优势。

Conclusion: 
我们的理论结果表明，针对不同学习器集进行LARP会导致所有学习器整体性能有所下降，但通过减少下游学习器频繁预筛选的成本，LARP为大规模数据集提供了一种有效的解决方案。实验表明，LARP能够显著降低数据的效用损失，同时减少数据预筛选的重复成本。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20573</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>113. cs.LG-DemoDiffusion：预训练扩散政策的一次性人类模仿</title><link>https://arxiv.org/pdf/2506.20668</link><description>Background: 
该论文背景是让机器人在自然环境中执行操作任务。传统的方法通常需要大量的数据或复杂的在线学习机制来使机器人掌握新任务。这种方法往往需要大量的时间、人力和计算资源，同时难以保证在新环境中的一致性和可靠性。因此，研究人员需要一种简单且可扩展的方法，使机器人的操作行为更加接近人类的表现，同时减少对大量训练数据的依赖，并能够在不同任务和场景下快速适应。

Innovation: 
该研究提出了一种名为DemoDiffusion的方法，通过模仿单次人类演示来使机器人在自然环境中执行操作任务。该方法的关键创新在于结合了人类演示的手部动作作为机器人的末端执行器轨迹的有用先验，并通过动力学重定位将其转换为粗略的机器人开环运动轨迹。此外，它还利用了预训练的通用扩散政策来微调轨迹，以确保机器人的动作不仅与人类演示一致，还能保持在可能的机器人动作分布范围内。这种方法避免了在线强化学习或人机配对数据的需要，从而减少人工干预，提高了适应新任务和场景的效率和可靠性。

Conclusion: 
实验结果表明，DemoDiffusion方法在模拟和实际场景中均优于基线政策和经过动力学重定位的轨迹。在一些任务中，即使预训练的通用政策失败了，机器人也能够成功执行任务，证明了该方法的有效性和鲁棒性。这为机器人在自然环境中的操作提供了简单且高效的解决方案，同时也减少了一次性成功模仿人类演示所需的大量数据需求。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20668</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>114. cs.LG-长时依赖网络中的时间反向传播方法</title><link>https://arxiv.org/pdf/2103.15589</link><description>Background: 
时间反向传播(BPTT)是一种用于递归神经网络(RNN)中调整参数的技术。尽管已有一些尝试用N次序逼近法和截断BPTT方法来实现这一技术，这些方法基于递归神经网络仅使用短期依赖性的假设，这一假设在当前的人工神经网络技术状态中是可以接受的。然而，随着RNN的发展，它们朝向更多基于长期依赖性的调整也是合理的。因此，需要一个新的反向传播方法来应对长期依赖性的问题.

Innovation: 
本文提出了一种新的算法，使用分段前向敏感方程及其变体来分别处理单一和多个相互作用的递归循环。这种方法提供了精确的梯度，并允许网络参数在每一步中有所不同，但同时需要计算雅可比矩阵以实现该方法.

Conclusion: 
新的反向传播方法能够处理由递归神经网络的长时依赖性引起的复杂梯度计算问题，可以允许网络参数在每个后续步骤中变化，尽管这种方法需要计算雅可比矩阵以保持精确度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2103.15589</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>115. cs.LG-向以社区为导向的机器学习工程代理</title><link>https://arxiv.org/pdf/2506.20640</link><description>Background: 
大语言模型为基础的机器学习(agent)在自动化机器学习研究方面展示了巨大的潜力。然而，现有的代理通常独自在一个特定的研究问题上运行，并没有与更广泛的科研社区互动，而人类研究人员常常通过分享知识来获得见解并贡献。为了弥合这个差距，我们引入了MLE-Live，这个动态评估框架旨在评估代理与其模拟的Kaggle研究社区中的集体知识进行交流和利用的能力。

Innovation: 
基于MLE-Live框架，我们提出了CoMind，这是一种新型代理，能够在社区背景下以卓越的能力进行信息交流并开发新的解决方案。CoMind在多个Kaggle竞赛上表现出最先进水平的性能，在四个Kaggle竞赛中，平均而言比79.2%的人类竞争对手表现更好。我们已将代码发布于此：this https URL

Conclusion: 
通过引入MLE-Live框架并提出CoMind，我们展示了如何让机器学习代理更好地与科研社区互动，进而实现最先进的研究结果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20640</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>116. cs.LG-使用强化学习提高风力发电场电力生产并通过实现闭环协作控制</title><link>https://arxiv.org/pdf/2506.20554</link><description>Background: 
传统风力发电场控制算法使每个风力涡轮机独立操作，以最大化各自的发电量。然而，整个发电场的协同尾流导向可以大大提高整体风力发电场的能量产出。尽管动态闭环控制在流体控制应用中已被证明是有效的，但风力发电场优化主要依赖于忽略关键湍流流动动态的低保真静态模拟器。这项工作提出了首先将强化学习控制器与高保真大涡模拟直接集成的方法，以通过合作和动态控制策略实时响应大气湍流。

Innovation: 
将强化学习控制器与高保真大涡模拟直接集成，提出了一种新的实时响应大气湍流的协同控制策略。实验证明，该方法比静态最佳偏航控制方法通过贝叶斯优化获得的2.19%增量提升了4.30%的风力发电场功率输出，证实了动态流体响应控制将风力发电场优化作为变革性的方法，直接对加速可再生能源部署到净零目标有重要意义。

Conclusion: 
动态流体响应控制是一种具有变革性的风力发电场优化方法，直接对加速可再生能源的部署至净零目标产生影响。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20554</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>117. cs.LG-使用观察分组进行因果表示学习的CXR分类</title><link>https://arxiv.org/pdf/2506.20582</link><description>Background: 
在医疗成像领域，识别出潜在数据生成过程中的真实因果关系有助于提高特定任务的潜在特征的一般化能力和鲁棒性。本文旨在探讨如何通过因果表示学习来改善胸部X光片上的疾病分类任务的一般化能力和鲁棒性。

Innovation: 
本文提出了一种通过端到端框架进行观察分组以学习可识别的因果表示的方法，特别是专注于通过强制性别、种族和成像视角的不变性来提高疾病分类的性能。这种方法能够提升分类任务的一般化能力和鲁棒性，从而为医疗成像领域的疾病诊断提供更可靠的支持。

Conclusion: 
实验结果表明，通过观察分组学习到的因果表示能够显著提升胸部X光片多任务分类的一般化能力和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20582</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>118. cs.LG-通过CUDA内核函数和PyTorch混合编译加速的快速地雷达双参数全波形反演方法</title><link>https://arxiv.org/pdf/2506.20513</link><description>Background: 
近年来，地雷达（GPR）在工程、环境监测和地质勘探等领域得到了广泛应用，但传统的全波形反演（FWI）方法在处理GPR数据时面临参数估计不准确和计算效率低下的挑战。为解决这些问题，本文提出了一种基于CUDA内核函数和PyTorch混合编译的高性能双参数全波形反演框架，旨在提高计算效率并保持Python深度学习框架的灵活性和易用性。该框架通过集成了自定义的CUDA内核到PyTorch自动微分机制，实现了介电常数和电导率的高精度和高效反演。实验证明，该方法在合成数据和实际时序数据上均达到了双参数FWI的要求，并且具有良好的扩展性和灵活性，支持多种正则化策略如总变差和多尺度反演，从而为GPR快速成像提供了一个实用的可扩展框架。

Innovation: 
本文提出了一种新的基于CUDA内核函数和PyTorch混合编译的双参数全波形反演框架，该框架能够实现介电常数和电导率的高效反演。主要创新点在于：（1）利用CUDA内核加速计算，提高了算法效率；（2）将自定义CUDA内核与PyTorch自动微分机制结合，实现了高效的双参数反演；（3）提出了灵活的正则化策略，支持多尺度和总变差正则化，增强方法的鲁棒性和处理复杂地质结构的能力；（4）实验证明了该方法在不同类型数据上的高精度和效率。

Conclusion: 
本文通过提出一种基于CUDA内核函数和PyTorch混合编译的双参数全波形反演框架，实现了对于GPR数据的高精度和快速反演处理。该框架具有较高的灵活性和扩展性，支持多种正则化策略。实验结果表明该方法能够有效应用于GPR数据的快速成像，对于工程、环境监测、地质勘探等领域具有重要的应用价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20513</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>119. cs.LG-Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks</title><link>https://arxiv.org/pdf/2506.20548</link><description>Background: 
随着深度学习的迅速发展，特别是生成对抗网络（GANs）和扩散模型（DMs）的应用，AI生成的图像（“深假”）已经几乎无法与真实图像区分。这些图像在在线社交网络（OSNs）上广泛传播，引起了对其潜在滥用的关注。现有的深度假检测方法忽略了OSNs中的压缩块效果，这种效果遮蔽了深度假的特征，主要关注未压缩的原始图像，这些图像在现实世界中的应用场景较少。由于缺乏配对数据和无效使用压缩图像，现有的方法难以有效地检测OSNs上的深度假。

Innovation: 
本文提出了PLADA（Pay Less Attention to Deceptive Artifacts），一种新的框架，旨在解决缺乏配对数据和压缩图像无效使用的问题。PLADA包含两个核心模块：块效果擦除器（B2E），使用双重注意力机制处理块效果，和开放数据聚合（ODA），可以处理配对和非配对数据以提高检测效果。通过26个数据集的广泛实验，PLADA在OSNs上的深度假检测中表现出色，即使在配对数据有限和存在压缩的情况下，也能优于当前最先进的检测方法。此外，本文强调了“块效果”在深度假检测中的关键作用，为开放世界检测场景提供了稳健的解决方案。

Conclusion: 
PLADA框架在OSNs上的深度假检测中取得了显著的平衡效果，即使在有限配对数据和存在压缩的情况下也能超越当前最先进的检测方法。更重要的是，这项工作强调了“块效果”作为深度假检测中的关键因素，提供了针对开放世界检测场景的稳健解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20548</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>120. cs.LG-InvZW: 基于噪声对抗训练的不变特征学习在鲁棒图像零水印中的应用</title><link>https://arxiv.org/pdf/2506.20370</link><description>Background: 
本文介绍了一种基于不变特征学习的新型深度学习框架，用于鲁棒图像零水印技术。现有的一些零水印技术会改变原始图像，在验证或提取水印信息时通常还需要借助额外数据，对于需要保持图像原貌的应用场景存在局限性。本文提出的方法通过对特征空间进行优化学习，生成既能够保持内容又可以通过学习特征进行鲁棒性验证和提取的水印信息。这种方法能够提供一种有效保护图片版权和身份验证的方式，特别是在面临图像处理（如压缩、裁剪、噪音添加等）的情况下依然保持水印的鲁棒性。

Innovation: 
文章的核心创新在于通过噪声对抗训练的方式学习不变特征，构建了两个关键模块：第一模块中，通过噪声对抗学习训练特征提取器生成稳定且语义表达强的表示，这包括对抗监督对抗干扰判别器与重建约束；第二模块设计了一种基于学习多比特零水印方案，利用适应训练的不变特征映射到一系列可训练的参考代码上，以匹配目标二元消息。实验结果表明，该方法在不同图像数据集和各种图像处理后处理中都达到了最先进的鲁棒性表现，在特征稳定性和水印恢复方面超越现有自监督和深度水印技术。

Conclusion: 
本文通过基于不变特征学习的噪声对抗训练框架，在鲁棒图像零水印技术上实现了创新。该方法能够在保持图像原始内容的同时，有效地嵌入和提取水印，并通过大量实验证明了其在不同类型的图像处理后的鲁棒性。相比现有的零水印技术，本文提出的框架在泛化能力和鲁棒性方面表现优越。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20370</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>121. cs.LG-WattsOnAI：衡量、分析和可视化AI工作负载的能耗和碳足迹</title><link>https://arxiv.org/pdf/2506.20535</link><description>Background: 
随着人工智能（特别是大型语言模型）的迅速发展，模型训练和推理过程中能源使用和碳排放等问题引起了广泛关注。然而，现有的测量和报告这些影响的工具往往零散不统一，缺乏系统性的度量综合，并且在它们之间进行相关性分析的支持有限。

Innovation: 
本文介绍了WattsOnAI，这是一个全面的软件工具包，用于测量、分析和可视化AI工作负载的能耗、功耗、硬件性能和碳排放。WattsOnAI无缝集成到现有的AI框架中，提供标准化的报告，并导出详细的时序数据以支持基准测试和再现性研究。此外，它还能实现硬件度量与模型性能之间的深入相关性分析，从而帮助识别瓶颈并提高性能。通过解决现有工具的关键限制，WattsOnAI鼓励研究社区在考虑AI工作负载的原始性能的同时还要关注其环境影响，推动向更可持续的‘绿色AI’实践的转变。

Conclusion: 
WattsOnAI通过解决现有工具的关键限制，推动了AI领域向更加可持续的实践发展，鼓励研究社区在评估AI工作负载时考虑环境影响。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20535</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>122. cs.LG-稳健的子空间恢复中迭代加权最小二乘法的全局收敛性</title><link>https://arxiv.org/pdf/2506.20533</link><description>Background: 
稳健的子空间估计是许多机器学习和数据分析任务的基础。迭代加权最小二乘（IRLS）是解决此问题的一种优雅且有效的方法，但其理论性质仍知之甚少。

Innovation: 
本文证明了，在确定条件下，带动态平滑正则化的IRLS变体可以从任何初始化线性收敛到潜在的子空间。此外，这些保证已经扩展到仿射子空间估计这一缺乏先前恢复理论的设置。此外，通过低维神经网络训练的应用表明了IRLS的实际优点。结果提供了IRLS在稳健子空间恢复中的首个全局收敛性保证，也更广泛地，为非凸IRLS在黎曼流形上的收敛性提供了保证。

Conclusion: 
我们的结果首次为稳健子空间恢复中的IRLS提供了全局收敛性保证，并且更广泛地，为非凸IRLS在黎曼流形上的收敛性提供了保证。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20533</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>123. cs.LG-OctoThinker: 中期训练激励强化学习扩展</title><link>https://arxiv.org/pdf/2506.20512</link><description>Background: 
不同的基础语言模型家族，在强化学习（RL）训练后表现出不同的行为，特别是在需要大量推理的任务中。关于什么使一个基础语言模型适合强化学习的理解仍然不足。因此，深入研究这个问题对于开发下一代RL可扩展的基础模型至关重要。本文研究中期训练策略如何影响RL动力学，特别是针对Qwen和Llama这两个模型家族。结果显示：高质量的数学语料库显著提升了基础模型和RL性能，而现有的替代方案未能实现这一提升；增加问答风格的数据，特别是包含长链推理的例子，能够促进RL结果，进一步使用指令数据进一步增强了这种效果；长链推理提高了推理深度，但也可能导致模型回复的冗长和RL训练的不稳定，这强调了数据格式化的重要性；中期训练的扩展性持续增强了下游RL性能。

Innovation: 
提出了一个两阶段中期训练策略叫做‘Stable-then-Decay’，即先用200亿个令牌进行稳定训练，然后在三个专注于链式推理的分支中进行20亿个令牌的训练，并采用学习率递减策略。这一方法产生了OctoThinker模型系列，这些模型展示了强大的RL兼容性，并且在某些任务上超过了更RL友好的Qwen模型。此外，开放了OctoThinker模型以及一个超过70亿令牌的优质数学推理语料库（即MegaMath-Web-Pro-Max）。

Conclusion: 
通过深入了解中期训练策略，本文揭示了一系列重要的观察结果，并提出了实际行动建议，以优化未来的基础模型预训练策略。希望这将有助于加强语言模型在强化学习时代的应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20512</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>124. cs.LG-利用轻量级层次ViT和动态框架实现高效的视觉跟踪</title><link>https://arxiv.org/pdf/2506.20381</link><description>Background: 
基于Transformer的视觉跟踪器在建模能力上取得了显著进展，然而由于其处理速度较慢，在资源受限的设备上的实用性受到限制。

Innovation: 
本文提出了HiT和DyHiT两种高效的视觉跟踪模型。HiT的核心创新在于Bridge Module，它连接了轻量级Transformer，提升了特征表示的质量。同时引入了双图像位置编码方法来有效编码空间信息。DyHiT则通过动态选择不同计算需求的路径来灵活应对场景复杂度，使用基于分而治之策略的动态路由器来提高准确性和速度。此外，还提出了一种基于DyHiT动态路由架构的无训练加速方法，提高了不同高性能跟踪器的执行速度，而不牺牲准确性。

Conclusion: 
HiT在NVIDIA Jetson AGX平台上实现了61 fps的速度，AUC为64.6%，并超越所有先前的高效跟踪模型。DyHiT的最快版本在NVIDIA Jetson AGX上实现了111 fps的速度，AUC为62.4%。无训练加速方法使SeqTrack-B256跟踪器在NVIDIA GeForce RTX 2080 Ti GPU上实现了2.68倍的速度提升，保持了相同的AUC值69.9%。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20381</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>125. cs.LG-自监督动作识别中的特征 hallucination</title><link>https://arxiv.org/pdf/2506.20342</link><description>Background: 
理解视频中的人类动作不仅仅是分析原始像素，还需要高层次的语义推理和多模态特征的有效整合。相关工作依赖传统的像素分析方法，但本研究提出了一种新的深度平移动作识别框架，通过从RGB视频帧中同时预测动作概念和辅助特征来提升识别准确性。这种方法在测试时使用生成线索流来推断缺失线索，从而丰富特征表示而不增加计算负担。研究引入了两种新的领域特定描述符：对象检测特征（ODF）和注意检测特征（SDF），分别用于捕捉上下文线索和强调对于动作识别至关重要的空间和强度模式。

Innovation: 
本研究创新性地提出了一个自监督的动作识别框架，该框架能够通过生成线索流富化特征表示并引入两种新特征描述符，同时兼容现有的先进架构，并通过引入aleatoric不确定性建模和鲁棒损失函数来处理辅助特征的不确定性，从而实现了在多个基准测试数据集上达到最先进的性能。

Conclusion: 
多模态自监督动作识别框架在Kinetics-400、Kinetics-600和Something-Something V2等多个基准上的表现为动作动态捕捉提供了一个有效的方法，证明了其在细粒度动作识别中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20342</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>126. cs.LG-ReCode: 使用强化学习更新代码API知识</title><link>https://arxiv.org/pdf/2506.20495</link><description>Background: 
大语言模型（LLMs）在代码生成方面表现出色，但在面对频繁更新的外部库API时却显得乏力。这一局限主要源于大语言模型依赖于训练数据中的过时API知识，即使能够访问最新的文档信息也无法有效应对。这一问题在动态环境中尤为突出，制约了代码生成的可靠性。因此，提出了一种基于强化学习的ReCode框架，旨在让大语言模型能够模仿人类程序员适应API变更的能力。该框架通过构建包含约2,000个数据条目的数据集进行训练，以便根据更新的信息来进行版本迁移。同时，引入了一种改进的字符串相似度度量作为强化学习的奖励机制。实验结果表明，ReCode有效地提升了大语言模型在处理动态API场景下的代码生成性能，特别是在未见过的任务CodeUpdateArena上表现尤为明显。与监督微调相比，ReCode对大语言模型通用代码生成能力的影响较小，并且在多个LLM和不同的强化学习算法上都能保持一致的性能提升。经过训练后的Qwen2.5-Coder-7B优于同一个架构下参数为32B的代码微调模型和推理模型。相关代码已开源。

Innovation: 
提出了ReCode框架，这是一种基于强化学习的方法，用于更新大语言模型中的代码API知识。通过构建数据集和改进的字符串相似度度量，该框架使得大语言模型能够有效应对API变更，并显著提升了其在动态API场景下的代码生成性能。此外，与监督微调相比，这种方法对模型整体代码生成能力的影响较小，适用范围更广，适用于各种LLM和不同的强化学习算法。

Conclusion: 
通过ReCode框架，大语言模型在处理动态API场景中的代码生成性能得到了显著提升，尤其在未见过的任务CodeUpdateArena上表现优异。ReCode方法对大语言模型的通用代码生成能力影响较小，且在多个模型和算法上都实现了稳定改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20495</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>127. cs.LG-HiWave: 基于小波扩散采样的无需训练的高分辨率图像生成</title><link>https://arxiv.org/pdf/2506.20452</link><description>Background: 
生成模型（特别是扩散模型）已经成为图像合成的领先方法，能够展示出惊人的照片真实性和多样性。然而，训练高分辨率的扩散模型依然非常耗时，且现有零样本生成技术在生成超过训练分辨率的图像时往往会产生瑕疵，如对象重复和空间不一致性。

Innovation: 
本文介绍了一种无需训练、零样本的HiWave方法，利用预训练的扩散模型显著增强超高清图像合成的视觉保真度和结构连贯性。该方法采用两阶段管道，首先生成基础图像，然后通过DDIM反转步骤和新型小波基细节增强模块进行处理。具体而言，该方法利用反转方法来保留基础图像中的全局一致性，并在采样时，通过小波域细节增强模块保留低频组件以确保结构一致性，同时引导高频组件以丰富精细的细节和纹理。广泛的评估显示，HiWave有效地减少了先前方法中的常见视觉瑕疵，达到了更高的感知质量。用户研究进一步证实了HiWave的性能，它在超过80%的比较中被用户偏好，表明其在无需重新训练或修改架构的情况下生成高质量的超高清图像的有效性。

Conclusion: 
HiWave通过预训练的扩散模型和创新的小波域细节增强模块，在无需训练的情况下显著提高了超高清图像合成的质量，解决了现有的高分辨率图像生成中的视觉瑕疵问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20452</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>128. cs.LG-基于递归神经网络的鲁棒控制系统与闭环区域增量输入到状态稳定性及其在MPC设计中的应用</title><link>https://arxiv.org/pdf/2506.20334</link><description>Background: 
本文探讨了一类递归神经网络的输出反馈方案设计方法。现有文献中，对于此类系统的控制问题已经有一定的研究，但主要集中在系统的稳定性分析和控制策略的设计上。本文在已有研究的基础上，进一步提出了基于线性矩阵不等式的观察器和静态状态反馈控制器的设计方法，并利用全局和区域增量输入到状态稳定性（增量ISS）来确保系统的鲁棒性和状态估计的准确性。同时，为了克服区域增量ISS带来的限制，提出了一种管状非线性模型预测控制（NMPC）方案，以扩大系统的吸引区域，并通过数值模拟验证了所提方案的有效性和鲁棒性。

Innovation: 
本文提出的创新点在于基于线性矩阵不等式设计观察器和静态状态反馈控制器，并结合全局和区域增量ISS来提高系统控制的鲁棒性和精确性。进一步地，提出了利用区域增量ISS特性的管状非线性模型预测控制（NMPC）方案，确保设计的NMPC具有收敛性和递归可行性，从而扩大系统吸引区域，增强了系统的适应性和鲁棒性。通过数值仿真在pH中和过程基准上的应用验证了所提出方案的有效性。

Conclusion: 
本文通过利用全局和区域增量输入到状态稳定性性质，为一类递归神经网络设计了鲁棒的输出反馈控制系统，并通过管状NMPC方案进一步扩大了系统的吸引区域。数值模拟结果表明，所提出的控制方案可以有效应对干扰和状态估计不确定性，保证了系统的稳定性和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20334</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>129. cs.LG-POLAR：动态治疗方案的悲观模型驱动策略学习算法</title><link>https://arxiv.org/pdf/2506.20406</link><description>Background: 
动态治疗规程（DTRs）提供了一种优化随时间变化的个体路径响应的序列决策过程的框架，尤其是在医疗保健、教育和数字干预等领域。现有的统计方法通常依赖于强烈的数据正性假设，并且在数据不完整的情况下缺乏鲁棒性，而脱机强化学习方法通常关注于平均培训性能，缺乏统计保证，并要求解决复杂的优化问题。

Innovation: 
我们提出了POLAR，一种新颖的悲观模型驱动的脱机DTR优化算法。POLAR通过脱机数据估计转换动力学并量化每对历史-行动的不确定性。在奖励函数中引入悲观惩罚以禁止高不确定性的行动。与许多现有的专注于平均训练性能的方法不同，POLAR直接针对最终学习策略的次优性，并提供了理论保证，而无需依赖于计算密集的最小最大或约束优化程序。据我们所知，POLAR是第一个提供统计和计算双重保证的基于模型的DTR方法，包括策略次优性的有限样本界。

Conclusion: 
在合成数据和MIMIC-III数据集上的实证结果表明，POLAR在性能上超过了最先进的方法，并生成了接近最优的历史感知治疗策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20406</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>130. cs.LG-线性混合模型中可扩展的子集选择</title><link>https://arxiv.org/pdf/2506.20425</link><description>Background: 
线性混合模型（LMMs）通过整合固定效应和随机效应，是分析异质数据的关键工具，尤其适用于个性化医疗或适应性营销。然而，随着数据的广泛性和复杂性的增加，有时包含数千个候选预测变量，需要稀疏性来进行预测和解释。现有的稀疏学习方法对于LMMs在超过数百个预测变量的情况下扩展能力不足，与无视随机效应的线性模型中的稀疏方法相比存在显著差距。该研究填补了这一空白，提出了一种新的基于$boldsymbol{text{0}}$范数正则化的LMM子集选择方法，该方法能够在秒到几分钟内处理包含数千个预测变量的数据集。在计算方面，研究开发了一种坐标下降算法作为主要的工作马车，并提供了其收敛性的保证。还开发了一种局部搜索算法帮助在非凸优化表面上进行探索。这两种算法都可以很容易地扩展到广义LMM的子集选择。在统计方面，提供了新方法的有限样本量下的Kullback-Leibler散度的上界。然后在合成实验中展示了其优越性能，并在生物和新闻数据集上说明了其用途。

Innovation: 
提出了基于$boldsymbol{text{0}}$范数正则化的LMM子集选择方法，能够快速处理数千个预测变量的数据集；开发了坐标下降算法及其收敛性保证，以及局部搜索算法帮助探索非凸优化表面；该方法适用于广义LMM的子集选择，并提供了新方法的有限样本Kullback-Leibler散度的上界。

Conclusion: 
该方法展现了优秀性能，在合成实验和生物、新闻数据集上的应用证明了其在LMM子集选择中的有效性和优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20425</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>131. cs.LG-无偏学习排序的未识别和混淆？理解双塔模型</title><link>https://arxiv.org/pdf/2506.20501</link><description>Background: 
双塔模型是工业场景中处理偏差用户反馈的流行排序学习方法。然而，近期研究发现，用表现良好的生产系统收集的点击训练双塔模型会导致排序性能下降。该论文研究了这种现象的两种解释：日志策略的混杂影响和模型可识别性问题。理论分析了双塔模型的可识别性条件，表明需要文档位置互换或特征分布重叠才能从点击中恢复模型参数。此外，研究了日志策略对双塔模型的影响，发现当模型能完美捕捉用户行为时，日志策略不引入偏差；但是当模型未能完美捕捉用户行为时，尤其是当预测误差与文档在不同位置的放置相关时，日志策略会放大偏差。

Innovation: 
论文通过理论分析探讨了双塔模型的可识别性条件，发现文档位置互换或特征分布重叠是恢复模型参数的必要条件。此外，研究了日志策略对模型的影响，提出了通过样本文权重技术来减轻这些效应，为使用双塔模型的研究人员和实践者提供了行动指导

Conclusion: 
提出了通过样本文权重技术来减轻上述效果和为研究人员和实践者提供了实际的指导建议。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20501</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>132. cs.LG-正则化深度矩阵分解的完整损失景观分析</title><link>https://arxiv.org/pdf/2506.20344</link><description>Background: 
尽管深度矩阵分解（DMF）在各种领域有着广泛的应用，但其优化基础仍然存在诸多空白。本文旨在通过全面研究正则化DMF问题的损失景观来填补这一空白。

Innovation: 
通过为所有临界点提供闭合形式表达式，并建立精确条件来区分不同类型的临界点（局部最小值、全局最小值、严格鞍点或非严格鞍点），从而揭示了为何梯度基方法几乎总是收敛到正则化DMF问题的局部最小值。进一步推出了一个必要且充分的条件，确保每个临界点要么是局部最小值要么是严格鞍点。

Conclusion: 
通过数值实验，根据不同的设置可视化了正则化DMF问题的损失景观，以支持理论分析。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20344</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>133. cs.LG-Biomed-Enriched: 基于LLMs增强的生物医学数据集，用于预训练和提取稀有和隐藏内容</title><link>https://arxiv.org/pdf/2506.20331</link><description>Background: 
临床文本通常难以访问，因为隐私限制，医院记录无法公开共享。当前的生物医学和临床自然语言处理（NLP）资源多局限于商业用途许可的文章，这限制了对高质量、开源的临床案例集合的需求，从而影响了针对这一领域模型的训练和优化。

Innovation: 
本文介绍了Biomed-Enriched，这是一个从PubMed构建的生物医学文本数据集，通过对大量PubMed科学文章进行两阶段标注，以大型语言模型评估段落类型、领域和教育质量，并利用这些标注对小型语言模型进行微调。这使研究人员能够提取高质量的临床案例段落，并通过质量过滤和领域增强构建多种变型。此外，实验表明，这些子集的定制化有助于目标改进，包括临床案例增强和教育质量过滤的改进，从而实现更快的收敛速度和更高效的生物医学预训练策略。

Conclusion: 
Biomed-Enriched数据集提供了一个大型且开放获取的临床案例集合，这对于增强生物医学和临床NLP 应用的训练和优化具有潜在价值。通过结合质量过滤和领域增强等技术，能够实现更高效和有效的预训练策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20331</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>134. cs.LG-OLALa：异质化联邦学习中的在线学习自适应格码</title><link>https://arxiv.org/pdf/2506.20297</link><description>Background: 
联邦学习(FL)在不共享原始数据的情况下实现分布式客户端的合作训练，但由于高维模型更新需要传输，导致了显著的通信开销。这种开销可以通过客户端量化其模型更新来缓解，当中的抖动格量化器由于其结构简单性和保持收敛性的特性而备受欢迎。然而，现有的基于格的FL方案通常依赖固定的量化规则，在异质和动态环境中这些规则的适用性较差，因为用户之间的模型更新分布和训练轮次会有所不同。

Innovation: 
本文提出了一种自适应的异质联邦学习框架OLALa（Online Learned Adaptive Lattices），使得每个客户端可以使用轻量级的本地计算在线调整其量化器。通过设计一种在线学习算法，客户端可以在FL过程中调整其量化器，仅交换一组紧凑的量化参数。证明了在非固定格量化器下联邦学习的收敛保障，并表明适当的格量化可以使收敛性界更加牢固。OLALa在各种量化率下能够持续提升学习性能，优于传统的固定码本和非自适应方案。

Conclusion: 
通过在线调整格量化器，OLALa能显著提升异质环境下联邦学习的性能，减少通信开销，并在多种量化条件下证明了其优于固定码本和非自适应方案的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20297</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>135. cs.LG-CCR前缀: CCRS: 用于全面RAG评估的零样本LLM评判框架</title><link>https://arxiv.org/pdf/2506.20128</link><description>Background: 
RAG系统通过整合外部知识来增强大型语言模型（LLM），尤其是在需要准确性和时效性信息的领域中起到关键作用。然而，评价RAG输出的多方面质量——包括上下文连贯性、查询相关性、事实正确性和信息完整性——提出了显著挑战。现有的评价方法往往依赖于简单的词汇重叠度量，这种方法不够精确来捕捉这些细微差别。此外，还有一些复杂多阶段的评价管道，中间步骤包括从RAG输出中提取声称或需要微调专门的评估模型，这妨碍了实际效率的提升。为应对这些局限性，本文提出了CCR前缀（Contextual Coherence and Relevance Score）框架，这是一种新的五项指标集合，利用一个单一的、强大的预训练LLM作为零样本、端到端的评判器。该框架用于评估六个不同配置的RAG系统在具有挑战性的BioASQ数据集上的表现，并展示了其对系统性能的有效区分能力。

Innovation: 
本文提出了CCR前缀（CCRS）框架，这是一种利用预训练LLM作为零样本评判器的全新五项指标集合，用于全面评估RAG系统的性能。CCRS能够评估上下文连贯性（CC）、查询相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回率（IR）五个方面。与复杂的RAG检查器框架相比，CCRS在召回率和忠实性等关键方面提供了可比或更优越的区分能力，并且计算效率更高。

Conclusion: 
CCRS为全面评估和迭代改进RAG系统提供了一种实用、全面和高效的框架。该框架的应用结果证实了不同RAG系统配置之间的性能差异，特别展示了Mistral-7B阅读器在某些方面优于Llama变体。CCRS通过严格分析其指标特性，展示了在分数分布、收敛/区分效度、平局率、群体统计和辨别力方面的优势，证明了其在评估RAG系统时的有效性和效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20128</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>136. cs.LG-基于在线和离线特征的变压器结合的手写识别系统</title><link>https://arxiv.org/pdf/2506.20255</link><description>Background: 
手写识别系统可以利用由栅格化复杂字符和笔迹捕获的互补提示，然而大部分系统仅利用单一模态数据。本研究考虑到这一点，探讨了如何利用离线图像和在线笔迹数据来进行手写识别，并且提出了一种端到端网络，该网络可以在共享的潜在空间中提前融合这两种数据。通过这种方式，实验展示了该方法在IAMOn-DB和VNOn-DB数据集上的优越性，达到了最佳的准确度，并且还演示了方法在ISI-Air数据集上的适应性。

Innovation: 
本研究引入了一种端到端的网络，能够在共享的潜在空间中对离线图像和在线笔迹数据进行早期融合。通过一个补丁编码器将灰度裁剪转换为固定的视觉标记，以及一个轻量级的变压器对$(x, y, text{pen})$序列进行嵌入。学习可学习的潜在查询可以同时关注两个标记流，生成上下文增强的笔迹嵌入，并在交叉熵损失的目标下进行聚合并解码。由于融合发生在任何高层分类之前，时间线索在表示学习期间相互增强，从而增强了写作者的独立性。与以往的最佳方法相比，该方法在IAMOn-DB和VNOn-DB数据集上达到了1%的提高。

Conclusion: 
通过全面的实验，本研究证明了基于变压器的手写识别系统的有效性，并达到了最先进的准确度，还在ISI-Air数据集上展示了该管道的适应性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20255</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>137. cs.LG-X-SiT: 为痴呆症诊断提供固有可解释性表面视觉变换器</title><link>https://arxiv.org/pdf/2506.20267</link><description>Background: 
可解释的模型对于支持临床决策至关重要，促进了其在医学图像发展和应用中的进步。然而，三维体积数据的性质使可视化和解释复杂的结构（如大脑皮层）变得困难。相比之下，皮层表面渲染提供了更易于理解的3D大脑解剖结构表示，有助于可视化和交互式探索。因此，我们介绍了eXplainable Surface Vision Transformer (X-SiT)，这是一种第一种固有可解释的神经网络，可以基于可解释的皮层特征提供人类可理解的预测。作为X-SiT的一部分，我们引入了一种原型表面斑块解码器，用于分类表面斑块嵌入，同时结合基于案例推理与空间对齐的皮层原型。

Innovation: 
提出了eXplainable Surface Vision Transformer (X-SiT)，这是一种固有可解释的神经网络，能够基于可解释的皮层特征提供人类可理解的预测。首次使用原型表面斑块解码器和基于案例推理与空间对齐的皮层原型来分类表面斑块嵌入。结果显示，X-SiT在检测阿尔茨海默病和额颞叶痴呆方面达到了最先进的性能，并且提供了与已知疾病模式一致的具有信息性的原型，揭示了分类错误。

Conclusion: 
X-SiT在痴呆症诊断中表现优异，并提供了解释性信息，有助于加深对疾病模式的理解，同时揭示了分类错误。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20267</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>138. cs.LG-增加接受，减少19%不必要的桌面拒稿：基于11年ICLR数据</title><link>https://arxiv.org/pdf/2506.20141</link><description>Background: 
人工智能研究的爆炸性增长导致顶级AI会议（如CVPR、ICCV、KDD、AAAI、IJCAI、WSDM）上的论文提交数量急剧增加，导致这些会议在2025年必须实施严格的作者提交限制，并按简单ID顺序对多余的论文进行拒绝。虽然这种政策有助于减少审稿人的工作负担，但可能会无意中放弃有价值的论文，并惩罚作者的努力。因此，它们提出了一个问题：在遵守提交限制的同时，如何尽可能减少不必要的拒稿。

Innovation: 
作者将当前的桌面拒稿政策形式化为优化问题，并开发了一种基于线性规划松弛和描圆方案的实用算法。该方法通过实际测试（基于11年的ICLR数据）展示了在不违反任何作者限制的情况下，最多可以保留额外19.23%的论文。此外，该算法在实践中非常高效，所有结果都在53.64秒内计算完成。这种方法提供了一种简单实用的桌面拒稿策略，显著减少了不必要的拒稿，并显示出改进当前计算机科学会议提交政策的强大潜力。

Conclusion: 
该研究提供了一种简单且实用的桌面拒稿策略，该策略显著减少了不必要的拒稿，并在11年的ICLR数据下验证了其有效性和效率，表明其在改善现有计算机科学会议提交政策方面具有巨大潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20141</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>139. cs.LG-通过面料对比进行绘画的法医研究</title><link>https://arxiv.org/pdf/2506.20272</link><description>Background: 
研究艺术品中的帆布面料是进行真伪鉴定、作者归属以及保护工作的关键工具。传统方法依赖于线密度图匹配，但这种方法在画布不来自卷上连续位置时无法适用。

Innovation: 
本文提出了一种基于深度学习的方法来评估纺织品的相似性。研发了一个自动工具，该工具能够在不依赖线密度图的情况下评估画布之间的相似性。设计并训练了一个Siamese深度学习模型，通过利用扫描中学习到的特征表示来比较图像对。此外，提出了一种基于预测的聚合方法，以提供一个可靠的相似性评分。

Conclusion: 
该方法应用于马德里普拉多博物馆的画布，验证了相同编织方式的画布即使线密度相似也能有效进行对比。实验结果证明了该方法的可行性和准确性，为名作分析开辟了新途径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20272</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>140. cs.LG-COIN：具有可证明风险保证的不确定性保护选择性问答框架</title><link>https://arxiv.org/pdf/2506.20178</link><description>Background: 
对于基础模型来说，不确定性量化（UQ）是识别和缓解自动生成文本中存在的潜在幻觉的关键。然而，现有的基于启发式的UQ方法在关键指标（如选择性预测的误发现率FDR）上缺乏形式保证。尽管以往的研究采用了分裂校准预测（SCP）框架来通过构建预测集确保可接受答案的适当覆盖范围，但这些方法常常包含错误候选答案，限制了它们的实际应用价值。

Innovation: 
本文提出了一种名为COIN的方法，该方法在用户指定的FDR约束下，通过校准统计上有效的阈值来筛选每个问题下的单一生成答案。COIN通过对校准集上的经验错误率进行估计，并使用Clopper-Pearson等置信区间方法来设置真实的高概率上限错误率（即FDR）。这种方法允许在确保测试数据上的FDR控制的同时，显著增加样本保留率。此外，结果显示，使用其他上限构造方法和不确定性量化策略可以进一步提升COIN的性能，这表明其具备多种应用场景下的扩展性和适应性。

Conclusion: 
COIN框架在全球和多模态文本生成任务中展示了在风险控制上的稳健性、保留可接受答案的强大测试时的动力，以及在有限校准数据下的预测效率。该工作进一步表明，使用不同的上下限构造方法和不确定性量化策略可以在不同场景下优化COIN的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20178</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>141. cs.LG-Piecewise Linear Approximation in Learned Index Structures: Theoretical and Empirical Analysis</title><link>https://arxiv.org/pdf/2506.20139</link><description>Background: 
在数据库和系统社区中，研究人员倾向于将传统的索引结构，如B+-树，与机器学习（ML）模型结合使用。其中，误差受限的分段线性逼近（ε-PLA）因其简洁性和有效性而广受欢迎。尽管在许多学习型索引中，ε-PLA 起着核心作用，但现有的 ε-PLA 调优算法的设计和分析尚未得到充分探索。

Innovation: 
本文从理论和实际应用的角度重新审视了 ε-PLA，并首次建立了现有 ε-PLA 调优算法的期望区间覆盖率下界为 α ε^2 (α 是数据依赖常数)。此外，本文还对最先进的 ε-PLA 算法在不同学习型数据结构中的应用进行了全面比较，揭示了模型准确度、模型大小和查询性能之间的关键权衡，为未来学习型数据结构的设计提供了实用指南。

Conclusion: 
本文的研究揭示了 ε-PLA 在学习型索引结构中的潜力和挑战，为其更有效的应用提供了理论依据和实验指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20139</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>142. cs.LG-在通用有损压缩中的探索-利用权衡</title><link>https://arxiv.org/pdf/2506.20261</link><description>Background: 
通用压缩能够学习数据来源并适应其特性，无论是以批量方式（前向适应）还是以顺序方式（后向适应）进行。研究者将顺序模式重新表述为多臂老虎机问题，这是一种在强化学习中基本的模型，探讨了在有损压缩中的探索与利用之间的权衡。

Innovation: 
提出了以前提出的 '自然类型选择' 方案可以被重新表述为用于顺序有损压缩的重建导向的MAB算法，并分析了这种算法在鲁棒性和短段性能方面的局限性，随后推导并分析了鲁棒费用导向的MAB算法，适用于任意长度的块压缩.

Conclusion: 
研究了通用有损压缩中的探索与利用权衡，对比了现有方法的限制，并提出了和分析了新的鲁棒费用导向的MAB算法，以改善在任意块长度下的性能，提供了关于通用有损压缩策略选择的新见解.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20261</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>143. cs.LG-在形式化集合中进行有效选择</title><link>https://arxiv.org/pdf/2506.20173</link><description>Background: 
形似预测提供了一种无需假设分布的框架，用于构建具有覆盖保障的预测集。实践中，可能存在多种有效的形似预测集，源于不同的模型或方法。然而，选择最优集合（如最小集合）可能破坏覆盖保障。现有方法未能有效解决这一问题。

Innovation: 
本文提出了一种基于稳定性的方法，确保所选预测集的覆盖保障。该方法被扩展到在线形似设置，并在有附加结构的场景中提出了若干改进措施。实验结果证明其有效性。

Conclusion: 
本文提出的方法能够有效选择形似预测集并在所选集合上保持覆盖保障，同时适用于多种形式化设置，并通过实验验证了其实用性和有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20173</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>144. cs.LG-从树集合中提取可解释模型：计算和统计视角</title><link>https://arxiv.org/pdf/2506.20114</link><description>Background: 
树集合是一种非参数方法，以其准确性及其捕捉复杂交互的能力而闻名。尽管这些模型在预测方面表现出色，但它们难以解释，并且可能无法揭示有用的数据关系。因此，提出了一种从树集合中提取紧凑规则集的估计方法。提取的模型准确且可以手动检查来揭示预测因子与响应之间的关系。

Innovation: 
该估计器的一大创新之处在于能够同时控制提取的规则数量和每个规则的交互深度，这提高了准确性。研究人员开发了一种定制的精确算法和近似算法来高效解决该估计器背后的问题，并计算正则化路径，即不同的约束条件下不同规模的解决方案序列。此外，还建立了该方法的非渐近预测误差边界，与具有相同复杂性限制的最佳数据相关线性规则的数据驱动选择最佳数据组合的方法（oracle）进行了比较，表明在大数据样本的预测性能方面，该估算器与oracle相当。通过实验，该方法在规则提取的性能上超过了现有算法。

Conclusion: 
该方法的预测性能在大数据样本的预测性能方面与oracle相当，并且在实验中表现出优于现有规则提取算法的结果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20114</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>145. cs.LG-利用AI评分机填充缺失分数以在构造性回答测试中实现准确的能力估计</title><link>https://arxiv.org/pdf/2506.20119</link><description>Background: 
评估学习者的能力是教育领域的基础目标。特别地，对表达能力和逻辑思维等高阶能力进行测评的需求日益增加。构造性试题如简答题和论文题已成为满足这一需求的方法之一。尽管这些方法有效，但需要大量人工评分，导致工作量大且成本高。项反应理论（IRT）提供了一种可能的解决办法，通过仅由评分员评估多个测试项目的部分答案来估算能力。然而，缺失分数比例的增加导致能力估计的准确性下降。为解决这一问题，虽然研究了数据增强技术来填补缺失分数，但它们在稀疏或异质数据中往往准确性不足。

Innovation: 
本文提出了一种新颖的方法，利用自动评分技术来填补缺失分数，从而提高IRT基于能力估计的准确性，同时显著减少人工评分的工作量。

Conclusion: 
所提出的方法在能力估计中取得了高准确性，同时大幅度减少了人工评分的工作量。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20119</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>146. cs.LG-在防护增强数字孪生沙箱内的共生演化军备竞赛中实现自主网络韧性</title><link>https://arxiv.org/pdf/2506.20102</link><description>Background: 
IT与OT的融合催生了高度互联的ICS系统，使关键基础设施暴露于新的自适应智能威胁之中，使得老旧的静态防御失效。现有的安全模式往往无法完整应对系统模型的准确性、同步数据的完整性和分析引擎对复杂规避策略的弹性这“三位一体的信任”问题。

Innovation: 
本文提出了ARC框架，这是一种通过自主闭环强化过程实现分析弹性的方法。ARC在高保真数字孪生的F-SCDT中建立了一个持续的共生演化军备竞赛。定义了“红代理”作为自主发现最小化检测同时最大化进程破坏的隐匿、物理上可行攻击路径的深度强化学习代理，并通过连续对抗训练不断强化“蓝代理”防御者，两者的共同进化促使系统能够自主探测和修补自身的漏洞。实验在TEP和SWaT测试平台上验证了框架的优越性能，并通过详尽的消融研究和诸如ROC曲线和SHAP图的可视化揭示了共生演化过程对检测新型攻击性能提升的贡献。通过集成可解释的人工智能确保操作员信任，并提出可扩展的F-ARC架构，ARC不仅是一种改进，更代表了向动态、自我改进安全转型的必要范式转变，符合未来关键基础设施的安全需求。

Conclusion: 
ARC框架通过在防护增强的数字孪生沙箱内推动共生演化军备竞赛，展示了对检测新型攻击的大幅性能提升，并在可解释的人工智能和可扩展的架构支持下，实现了对关键基础设施的动态、自我改进的安全防护，是一项向更动态和自适应安全模式过渡的必要范式转变。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20102</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>147. cs.LG-使用编辑距离弱监督的开放世界多模态信息检索</title><link>https://arxiv.org/pdf/2506.20070</link><description>Background: 
现有的多媒体检索模型要么依赖于创建具有模态特定表示模型的公共子空间，要么需要在模态之间进行模式映射以衡量多媒体数据之间的相似性。这些方法常常将检索视为监督分类任务，并需要对数据进行标记。这导致了注释成本较高，并限制了在数据注释较少的现实应用场景中获取满意的性能。因此，该研究旨在避免这种注释开销，利用已预训练的语言模型和视觉任务中的编码器来实现多模态检索，而无需在不同应用间调整超参数或构建通用框架。为了评估该方法的有效性，作者创建了一个名为MuQNOL的新数据集对其进行测试，在一个查找失踪人员的场景中实现了检索效果。

Innovation: 
通过利用模式编辑距离中的弱监督，将样本之间的编辑成本视为相关性的隐式信号，FemmIR框架能够在不直接进行相似度标注的情况下，根据用户提供的示例检索出相关的多模态结果。这种框架重新利用了高层属性并保持了属性值和关系约束，在多级数据样本与查询示例之间使用交互得分。与传统的方法如度量学习或编码网络不同，FemmIR直接利用系统中已有的属性标识符，能够提供精确和近似的相似性检索结果。

Conclusion: 
FemmIR框架在使用MuQNOL数据集的情况下，能够提供与同类检索系统类似的检索效果，即使在数据注释有限的情况下也能达到较好的性能表现，证明了弱监督和编辑距离在多模态检索中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20070</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>148. cs.LG-机器学习辅助的光子器件开发：从理论到表征的多尺度方法</title><link>https://arxiv.org/pdf/2506.20056</link><description>Background: 
光子器件开发（PDD）在设计和实现控制不同波长、尺度和应用的新光子器件方面取得了显著的成功，包括通信、成像、传感和量子信息处理等领域。这是一个迭代的五步过程：1) 从设计参数推导器件行为，2) 用器件性能进行模拟，3) 从模拟中找到最优候选设计，4) 制造最优器件，5) 测量器件性能。传统上，这些步骤都依赖于贝叶斯优化、材料科学、控制理论和直接的物理驱动数值方法。然而，许多这些技术在计算上是不可行的、成本高昂或难以大规模实施。此外，PDD面临优化景观大的问题、结构或光学表征的不确定性、和实施稳健的制造过程的困难。

Innovation: 
过去十年机器学习的发展为应对这些挑战提供了新的数据驱动策略，包括用于加速计算的代理估计器、用于噪声测量建模和数据增强的生成模型、用于制造的强化学习和用于实验物理发现的主动学习。本文综述了这些方法，为借助机器学习辅助的PDD（ML-PDD）提供了一个全面的视角，这些方法能够实现高效的设计优化，结合强大的生成模型进行快速仿真和表征建模，并通过强化学习实现制造。这对于来自不同背景的研究者来说提供了宝贵的见解，促进了跨学科的努力，以加速复杂光子器件和系统的开发进程。

Conclusion: 
本文为来自不同背景的研究者提供了关于机器学习辅助的光子器件开发这一新兴主题的宝贵见解，通过综合机器学习策略和多尺度方法的应用，实现了光子器件的快速设计和制造，加速复杂光子器件和系统的开发进程。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20056</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>149. cs.LG-智能攻击：基于注意力的细粒度网页指纹攻击</title><link>https://arxiv.org/pdf/2506.20082</link><description>Background: 
网站指纹攻击（WF）旨在通过分析流量模式推断用户的访问网站情况，从而侵犯用户匿名性。尽管这项技术在受控实验环境中已被证明是有效的，但它仍然主要局限在小型场景中，通常仅识别网站的主页。在实际场景中，用户通常会快速连续访问多个子页面，这些页面与主页具有相似的页面元素，从而导致不同的网页之间流量特征的方差较低。此外，考虑场景中多个标签页的浏览情况，一个追踪可能包含多个类别的网页，导致流量中的重叠段落，相似的特征可能出现在流量的不同位置，从而增加了分类的难度。

Innovation: 
本文提出了一个基于注意力的细粒度网页指纹攻击（ADWPF），针对上述挑战设计。在训练阶段，基于注意力图对流量中的重要区域进行针对性增强，包括注意力裁剪和注意力遮盖。ADWPF然后从原始和增强的流量中提取低维度特征，并应用自注意力模块捕捉追踪的全局上下文模式。此外，为了应对多标签场景，使用残差注意力生成在不同时间位置上出现的网页的类特定表示。该方法在不同规模的数据集上进行了广泛实验，结果证明其能够超越最先进的基线方法。

Conclusion: 
提出的基于注意力的细粒度网页指纹攻击（ADWPF）在不同规模的数据集中始终优于现有的基线方法，有效应对了多标签浏览场景中的挑战，为网站指纹攻击技术提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20082</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>150. cs.LG-PocketVina 通过多囊穴调节实现了可扩展且高度准确的物理有效对接</title><link>https://arxiv.org/pdf/2506.20043</link><description>Background: 
在分子对接中，如何准确地抽样出真实的配体结合姿势是一个主要挑战，尤其是在面对未见或结构多样的靶标时。现有的分子对接方法在处理这类靶标时性能较为有限，限制了其在高通量虚拟筛选和结构导向药物发现中的应用。

Innovation: 
PocketVina 是一种快速且内存高效的基于搜索的对接框架，结合了囊穴预测和系统化多囊穴探索。PocketVina 被设计用于提高实体有效对接姿势的采样精度，并在深学习对接方法的基础上提供了更具竞争力的性能表现，尤其是在处理结构多样性和未见过的靶点时。此外，PocketVina 还能够保持在不同柔性的配体上都具有出色的实体有效对接准确性。与此同时，PocketVina 通过一个称为 TargetDock-AI 的基准数据集进一步展示了其在大规模数据集上的能力，能够在活性与非活性靶点中做出有效区分，获得更好的性能同时所需的 GPU 内存和运行时间更少。

Conclusion: 
PocketVina 提供了一种稳健且可扩展的对接策略，无需针对特定任务进行训练，并能在标准 GPU 上高效运行，使之成为高通量虚拟筛选和结构导向药物发现的理想选择。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20043</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>151. cs.LG-一个集成时空模型和大语言模型的模块化多任务推理框架</title><link>https://arxiv.org/pdf/2506.20073</link><description>Background: 
时空数据分析在各个领域中支持基于信息的决策方面发挥着关键作用，但现有模型通常局限于单一任务，缺乏进行多任务推理和复杂长形式推理的能力，这要求生成深入和解释性的输出。这些限制阻碍了它们在现实世界、多维度决策场景中的应用能力。现有模型受限于狭窄的任务规定，缺乏处理多任务和复杂推理的需求，这限制了它们在实际多领域决策中的应用效果。

Innovation: 
本文提出了一种新型框架STReason，将大型语言模型（LLMs）的推理优势与时空模型的分析能力相结合，用于多任务推理和执行，无需特定任务的微调，而是通过上下文学习将复杂的自然语言查询分解为可模块化、可解释的程序，然后系统执行以生成解决方案和详细的解释。为了进行严格的评估，构建了一个新的基准数据集，并提出了一种统一的评估框架，其中包括专门针对长形式时空推理设计的评估指标。实验结果显示，STReason在所有指标上显著优于最先进的LLM基线，尤其是在复杂的、推理密集的时空场景中表现出色。进一步的人类评估验证了STReason的可信度和实用性，展示了其减轻专家工作量和扩展到实际时空任务的潜力。成功地通过这一框架向时空推理系统的发展提供了一个有希望的方向。

Conclusion: 
STReason在多任务推理和时空场景的复杂合理化方面取得显著成果，证明了其在现实世界应用中的潜力，并为开发更强大、更通用的时空推理系统指明了发展方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20073</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>152. cs.LG-基于扩散模型的任务导向语义通信及其模型反转攻击</title><link>https://arxiv.org/pdf/2506.19886</link><description>Background: 
语义通信作为一种基于神经网络的系统设计，被认为是有前景的6G网络解决方案。任务导向的语义通信是一种新兴的范式，其核心目标是通过传输语义信息高效完成特定任务，优化通信效率和任务性能。然而，在这种情况下，隐私性保持与任务准确性的平衡是关键挑战，原因是系统容易受到模型反转攻击。在这些攻击中，对手可以通过分析和处理模型输出来恢复甚至重构输入数据，尤其是基于神经网络的系统更容易产生这种情况。此外，传统系统使用图像质量指标（如PSNR或SSIM）来评估攻击的严重性，对于任务导向的语义通信可能不够充分，视觉差异并不一定意味着语义差异。因此，需要提出新的评价攻击效果的指标，并改进数值恢复的语义质量。

Innovation: 
本文提出了一种基于扩散机制的任务导向语义通信框架——DiffSem。它通过自参照标签嵌入优化语义信息重建，显著提高任务性能。此外，该系统可以减轻信道噪声的影响，并采用语义信息扭曲确保系统在不同信噪比环境中具有抗噪声能力。为了评估攻击者的效果，我们还提出了一种新的度量标准，该标准能够更准确地量化攻击者估计的语义保真度。实验结果显示，与传统评估方法相比，DiffSem在MNIST数据集上的分类准确率提高了10.03%，且在动态信道环境中保持了稳定性能。这些结果进一步表明，传统的图像质量指标与任务相关的语义信息泄露之间存在显著差异。

Conclusion: 
实验结果表明，DiffSem在MNIST数据集上将分类准确率提高了10.03%，并且在动态信道环境中保持了稳定表现。此外，传统图像质量指标与任务相关的语义信息泄漏之间存在显著差异。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19886</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>153. cs.LG-遵循原理的健合分布性评估途径</title><link>https://arxiv.org/pdf/2506.20048</link><description>Background: 
在强化学习中，分布性离线策略评估（OPE）旨在使用在不同策略下收集的离线数据估算目标策略的回报分布。相关工作已经开发了基于期望的强化学习方法，即已投入使用的装馨Q评估（fitted-Q evaluation），但还没有统一的框架来设计分布性离线评估（FDE）方法。本文填补了这一空白，提出了一组构建理论基础的FDE方法的指导原则，并基于这些原则开发了几种新的FDE方法，提供了收敛分析，并为现有方法提供了理论依据，即使在非表格环境中也是如此。广泛的实验，包括线性二次调节器和Atari游戏上的模拟，证明了FDE方法的优越性能

Innovation: 
本文提出了一组构建理论基础的FDE方法的指导原则，并基于这些原则开发了几种新的FDE方法，这些方法在非表格环境中也有效，并且提供了收敛分析和理论依据。

Conclusion: 
FDE方法在广泛的实验中表现出优越的性能，特别是在线性二次调节器和Atari游戏上。本文填补了理论层面FDE设计中的空白，并为未来的研究提供了指导原则和方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20048</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>154. cs.LG-Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing</title><link>https://arxiv.org/pdf/2506.20000</link><description>Background: 
该研究旨在为联邦计算中的隐私保护计算提供一种新型的框架，该框架能够统一多种隐私保护机制，如全同态加密（FHE）、多方计算（MPC）以及差分隐私（DP）。研究背景包括联邦计算在数据保护方面的挑战，以及现有隐私机制如何需要更统一和灵活的安全控制框架以适应不同计算需求和安全级别。

Innovation: 
Guardian-FC框架创新性地提出了一种分层体系结构，包含两个层面：一层是执行插件，这些插件使用后端中立的领域特定语言（DSL）编写，并且可以在可互换的执行提供者（EPs）上运行；另一层是代理-AI控制平面，通过签名的遥测数据和命令确保安全性和可审计性。此外，该框架支持基于清单的设计，从而实现快速且无缝集成新的隐私后端。

Conclusion: 
研究总结了代理-AI控制平面如何通过安全循环确保联邦计算中的安全性，框架的设计因素包括支持快速故障恢复的工作负载准入以及对于新隐私后端的无缝扩展。同时，研究提出了一个研究议程，包括动态安全护栏调整、多后端组合、DSL规范开发、实现及其编译器扩展性，并强调人机交互的易用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20000</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>155. cs.LG-一个时空点过程模型对精细阅读行为建模</title><link>https://arxiv.org/pdf/2506.19999</link><description>Background: 
阅读是一个跨时空的过程，包括固定点（读者集中在特定空间点）和扫视（读者迅速将注意力转移到新点）的交替。心理语言学的一种假设是，通过建模读者的固定点和扫视可以洞察其在线句子处理。然而，标准建模方法依赖于聚合的眼动追踪测量和强假设的模型，忽视了阅读过程中发生的大量时空动态特征。此论文的目的在于提出一种更通用的概率阅读行为模型，基于标记的时空点过程，不仅捕获固定点持续时间，还能捕捉固定点在时间和空间中的位置及发生时点，通过Hawkes过程来建模扫视，展示如何每个固定点促使附近发生新固定可能性，同时牢同固定点持续时间为固定点特定预测因子的函数来捕捉效应溢出。

Innovation: 
本文提出了基于标记时空点过程的阅读行为模型，包括通过Hawkes过程建模扫视，以及用固定点特定预测因子的函数来模型固定点持续时间，捕捉效应溢出。同时，该模型在细节上比基线模型更准确地匹配了人的扫视行为。该模型在固定点持续时间建模上发现将上下文惊异作为预测因子的效果仅产生微小改进，这表明惊异理论解释精细视线波动的能力有限。

Conclusion: 
本研究提出了一种更通用的概率阅读行为模型，不仅可以捕获固定点的持续时间，还可以捕捉固定点在时间和空间中的位置及发生时点，且在实际应用中比标准方法更加有效，但惊异理论难以解释细微的视线移动。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19999</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>156. cs.LG-MAIZX：一种面向碳排放优化的云计算框架</title><link>https://arxiv.org/pdf/2506.19972</link><description>Background: 
云计算推动了创新，但也带来了显著的环境挑战，主要是由于其高的能源消耗和碳排放。数据中心占全球能源消耗的2-4%，到2040年，ICT行业的电力消耗预计将达到40%份额。随着2050年前实现净零排放的目标越来越紧迫，对更高效和透明的解决方案的需求也在增加，尤其是对于私人云基础设施，87%的组织在使用，尽管公共云系统占主导地位。这些背景信息说明了云计算所面临的能源和环境挑战，以及实现气候目标的紧迫性。

Innovation: 
该研究评估了MAIZX框架，该框架通过实时时钟和预测碳强度、PUE和能耗对资源（包括数据中心、边缘计算节点和多云环境）进行动态排名，从而优化云操作并减少碳足迹。MAIZX利用灵活的排名算法将CO2排放减少了85.68%。并且该框架在地理位置分散的数据中心进行了测试，证明了其可扩展性和有效性，可以直接与虚拟机监控程序接口优化资源在私有、混合和多云环境中的工作负载。MAIZX整合了实时和预测的碳强度、功率消耗和碳足迹数据，提供了一个增强气候绩效潜力的工具，同时保持运营效率。这些特性突显了MAIZX在优化云计算碳排放方面的创新之处。

Conclusion: 
MAIZX框架通过实时时钟和预测数据，结合动态资源排名，实现了私有云、混合云和多云环境中的工作负载优化，并显著降低了CO2排放。该框架展现了可扩展性和有效性，能够直接与虚拟机监控程序交互，结合实时和预测数据来优化资源，强化了其在气候变化适应中的应用价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19972</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>157. cs.LG-在合作多智能体强化学习中学习双向团队形成</title><link>https://arxiv.org/pdf/2506.20039</link><description>Background: 
在多智能体增强学习（MARL）的背景下，团队组建及基于团队的学习动态引起了广泛关注。现有研究主要集中在单方团队构建、预定义团队或固定人口设定上，忽视了算法性双边团队选择在动态人口中对策略性能和泛化能力的影响探索。

Innovation: 
本文提出了一种在动态多智能体系统中学习双向团队形成的框架，旨在揭示算法性双边团队形成特性对策略性能和泛化能力的影响。通过广泛采用的多智能体场景进行了验证，结果表明，该方法在大多数场景中表现竞争力强且泛化性能良好的特点。

Conclusion: 
通过这一研究，我们深入了解了算法性双边团队形成特性对多智能体系统中策略性能和泛化能力的影响。实验结果验证了该方法的有效性，展示了在合作多智能体增强学习环境中的竞争性能和良好的泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20039</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>158. cs.LG-CoVE: 压缩词汇扩展构建更好的基于大规模语言模型的推荐系统</title><link>https://arxiv.org/pdf/2506.19993</link><description>Background: 
推荐系统在提供相关内容给用户方面发挥着关键作用。随着大规模语言模型（LLMs）的快速发展，研究人员开始利用LLMs构建更加强大的推荐系统。然而，现有专注于使LLMs与推荐任务对齐的方法并未完全发挥其序列信息处理能力，导致性能不佳。

Innovation: 
本文提出了一种名为压缩词汇扩展（CoVE）的新型系统。在CoVE中，每个项目在扩展词汇表中分配了一个独特的ID。我们的框架有效地利用了LLMs的序列理解能力，显著提升了它们在推荐任务上的性能。此外，我们压缩了嵌入层，使CoVE更具大规模工业应用的可行性。通过在多种推荐数据集上的全面实验以及与以往工作的比较，证明了CoVE的有效性和性能。

Conclusion: 
通过CoVE系统，我们证明了压缩词汇扩展方法在基于大规模语言模型的推荐系统中的有效性。该方法充分利用了LLMs的序列理解能力并提高了推荐性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19993</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>159. cs.LG-MILAAP: 移动链路分配基于注意力预测</title><link>https://arxiv.org/pdf/2506.19947</link><description>Background: 
频道跳转（CS）通信系统需要适应无线网络中的干扰变化以及节点移动，以维持吞吐量效率。最优调度需要实时的网络状态信息（例如信道占用情况），以便为干扰区域内的链路选择不重叠的信道。然而，节点间状态共享会引入显著的通信开销，尤其是随着网络规模或节点移动性的增加，这会降低已经容量受限的网络的吞吐量效率。本文绕过了状态共享，而是基于基于学习的频道占用预测来适应CS调度。

Innovation: 
本文提出了基于注意力机制的MiLAAP预测框架，用于机器学习模型来捕捉网络节点间在频谱、空间和时间上的依赖关系。MiLAAP使用自注意力机制，使每个节点能够捕捉其干扰区域内的时空频道跳转模式，并据此预测该区域内的信道占用状态。与传统的依赖状态共享的方法不同，MiLAAP的预测仅依赖于本地和被动观察的信道活动，不引入通信开销。此外，还利用多头自注意力机制捕捉其他可能干扰该节点的网络节点的时空依赖关系，预测其移动轨迹，进一步提高信道占用状态预测的准确性。该方法特别适用于使用本地CS序列支持相对长期流量的动态网络，MiLAAP的信道状态预测准确率在各种节点移动模式下可达约100%，并且具有跨不同CS序列周期的零样本泛化能力。

Conclusion: 
对于使用本地CS序列支持相对长期流量的动态网络，MiLAAP的信道状态预测精度非常高，其准确率大约为100%，并且具有跨不同CS序列周期的零样本泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19947</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>160. cs.LG-Prover Agent: 一种基于代理的正式数学证明框架</title><link>https://arxiv.org/pdf/2506.19923</link><description>Background: 
本文介绍了一种名为Prover Agent的新颖AI代理，该代理将大型语言模型（LLMs）与形式证明助手Lean结合在一起，用于自动定理证明。该系统通过协调非正式推理LLM、形式证明模型以及来自Lean的反馈，同时生成辅助引理来辅助发现总体证明策略。Prover Agent在MiniF2F基准测试中取得了86.1%的成功率，是使用小型语言模型（SLMs）的新最先进的方法，相比以往方法具有更低的样本预算。文中还展示了案例研究，说明了这些生成的引理如何有助于解决具有挑战性的问题。

Innovation: 
Prover Agent 是一种将大型语言模型（LLMs）与形式证明助手Lean结合的应用，通过非正式推理、形式证明和反馈的协同作用生成辅助引理来辅助发现证明策略。相比以往使用小型语言模型的方法，Prover Agent 在MiniF2F基准测试中取得了86.1%的成功率，并具有更低的样本预算，标志着新的里程碑。

Conclusion: 
Prover Agent 成功地将大型语言模型的应用与形式证明助手相结合，提升了自动定理证明的效果。通过生成辅助引理和高效的反馈机制，Prover Agent 改进了证明过程的策略发现，特别是在策略发现方面取得了显著成果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19923</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>161. cs.LG-DualEquiNet: 双空间层次等变网络用于大生物分子</title><link>https://arxiv.org/pdf/2506.19862</link><description>Background: 
已有的几何图神经网络（GNNs）在小分子建模上取得了良好的效果，但在应用于如RNA和蛋白质等大型生物分子时，面临着可扩展性和表现力的挑战。这些系统需要能够同时捕捉原子间精细的相互作用、空间上分散但具有生物学意义的依赖关系和层次结构，例如原子形成残基、再形成更高层次的结构。现有几何GNNs大多只在欧几里得或球高斯谐波空间中操作，缺乏同时捕获细粒度原子细节和长程对称依赖关系的能力。因此，现有的几何GNNs无法有效建模大型生物分子的多层次结构.

Innovation: 
DualEquiNet是一种双空间层次等变网络，它在欧几里得和球高斯谐波空间中构建互补表示，以捕捉局部几何结构和全局对称特性。DualEquiNet使用双向跨空间消息传递和新颖的跨空间交互池化机制，以层次方式聚合原子特征到生物有意义的单元，如残基，从而实现大型生物分子系统的高效和多尺度建模。DualEquiNet在RNA属性预测和蛋白质建模等多个现有基准上取得了最先进的性能，并在两个新引入的3D结构性能基准上优于先前的方法，证明了其在大型生物分子模型任务中的广泛有效性.

Conclusion: 
DualEquiNet在多种RNA属性预测和蛋白质建模基准上达到了最先进的性能，并且在两个新引入的3D结构性能基准上的表现优于以前的方法，表明了它的广泛有效性，能够有效建模大型生物分子的多层次结构和生物学结构.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19862</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>162. cs.LG-通过流形学习进行数据驱动的动态因子建模</title><link>https://arxiv.org/pdf/2506.19945</link><description>Background: 
该研究提出了一个数据驱动的动力因子框架，该框架中响应变量依赖于高维协变量集，不需要对变量间联合动态性进行任何参数假设。研究利用Singer和Coifman引入的非线性流形学习技术Anisotropic Diffusion Maps，以纯数据驱动方式揭示协变量和响应变量的联合动态。该方法使用线性扩散近似嵌入动态，并通过卡尔曼滤波直接从扩散映射嵌入空间预测协变量和响应变量的演化。研究将Singer有关图拉普拉斯收敛速率分析扩展到欧几里得空间中沿朗文扩散的时间序列情况。

Innovation: 
提出了一个基于Anisotropic Diffusion Maps的非参数数据驱动框架来建模高维协变量和响应变量的联合动态。研究使用线性扩散近似嵌入动态，并结合卡尔曼滤波直接从扩散映射嵌入空间预测变量演化。此外，该研究严格证明了一维近似和理论平均收敛的稳健性。这种数据驱动的方法被应用于联邦储备监督情景中的股票组合压力测试，通过历史回测证明了该方法优于标准情景分析和主成分分析基准，实现了高达55%和39%的平均绝对误差减少。

Conclusion: 
该数据驱动的动力因子建模方法以纯数据驱动的方式揭示了协变量和响应变量的联合动态，并能够在联邦储备的监督情景中有效应用，尤其在股票组合压力测试中显示出显著的优势，通过历史回测证明了其准确性和可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19945</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>163. cs.LG-PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models</title><link>https://arxiv.org/pdf/2506.20629</link><description>Background: 
LoRA是一种广泛使用的大型模型微调方法，它的特点是在保持低内存占用的同时，可以将大型模型适应到特定任务。不同的优化方法已经提出，例如调整学习率、秩和初始化策略。此外，适配器放置策略也是一个重要的改进方向，现有的工作主要集中在应该在哪些模块类型中放置适配器，比如在注意力模块或MLP模块中。然而，关于适配器放置策略的研究较少，且没有明确的结果指导。

Innovation: 
作者提出了一个轻量级方法——PLoP（Precise LoRA Placement），通过理论分析自动识别给定预训练模型和微调任务中适合放置LoRA适配器的模块类型。PLoP方法通过全面的实验展示了其优于常见放置策略的效果，在最坏情况下也能与其竞争，因此为LoRA适配器的放置提供了一种更精确和高效的方法。

Conclusion: 
PLoP通过在各种超监督微调和强化学习任务中的实验验证了其在微调大型模型时的有效性和竞争力。该方法可以在较小的计算开销下为用户提供更精确的适配器放置建议，从而提高微调模型的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20629</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>164. cs.LG-RepuNet: 用于缓解DFL中恶意客户端的声誉系统</title><link>https://arxiv.org/pdf/2506.19892</link><description>Background: 
Decentralized Federated Learning (DFL) 允许节点在没有中央服务器的情况下协作训练模型，但这也带来了新的安全漏洞。每个节点独立选择模型聚合的同伴，恶意节点可以利用这种自主性通过发送受污染的模型、延迟模型提交或在网络中发送过多消息等方式进行攻击，这会负面影响系统性能。现有的解决方案通常依赖于固定配置或额外的基础设施（例如区块链），这会导致计算开销、可扩展性问题或适应性有限的问题。因此，需要用一种新的方法来应对这些局限性，确保DFL的安全性与适应性同时提升.

Innovation: 
本文提出了一个去中心化声誉系统——RepuNet，该系统能够对DFL中的威胁进行分类，并利用模型相似性、参数变化、消息延迟和通信量等度量指标动态评估节点行为。基于这些信誉分数调整节点在模型聚合中的影响力。RepuNet已经在Nebula DFL平台上与MNIST和CIFAR-10数据集进行实验证明了其对恶意行为的有效检测和缓解能力，展示了其适应性、鲁棒性和实际应用潜力.

Conclusion: 
实验结果表明，RepuNet能够有效地检测并缓解恶意行为，MNIST场景的F1得分超过95%，CIFAR-10场景的F1得分约为76%。这些结果凸显了RepuNet在去中心化联邦学习环境中的适应性、鲁棒性和广泛应用前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19892</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>165. cs.LG-无责用户在洁净室中：为生成模型定义版权保护</title><link>https://arxiv.org/pdf/2506.19881</link><description>Background: 
该论文探讨了在何种条件下生成模型的输出不会侵犯其训练数据的版权，这是由Vyas, Kakade, and Barak（ICML 2023）首次提出的问题，称之为“可验证版权保护”。他们提出了接近访问自由（NAF）的概念，并将其作为版权保护的充分条件。然而，本文重新审视了这个问题，建立了新的可验证版权保护的理论基础，这些理论基础在技术和法律上都更为坚实。尽管NAF被认为是有效的版权保护方式之一，但本文指出NAF本身并不能防止侵权，并且NAF模型可能促进逐字复制，这被认为是版权保护的明显失败，被命名为“带毒”。

Innovation: 
本文提出了无责复制保护框架，定义了有意义的保证，并通过洁净室复制保护来具体实现。洁净室复制保护允许用户通过以不会在假设的洁净室环境中复制的方式行为来控制自己的复制风险。此外，论文通过证明当数据集是“金色数据集”时，差分隐私（DP）蕴含洁净室复制保护，从而形式化了一个关于差分隐私和版权的常见直觉。

Conclusion: 
本文建立了新的理论基础，重新定义了可验证版权保护，并通过洁净室复制保护和“金色数据集”的概念提供了一种更有效的保护机制。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19881</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>166. cs.LG-掌握多专家路由：可实现的$H$一致性及强大学习保证</title><link>https://arxiv.org/pdf/2506.20650</link><description>Background: 
多专家学习中延迟学习的问题是优化输入实例分配给专家的过程，平衡专家的准确性和计算成本之间的权衡。这在自然语言生成以及图像处理、医疗诊断等其他领域都是一个关键挑战。近年来，研究提出了代理损失函数来优化延迟学习，但仍存在确保其一致性的挑战。因此，该领域需要新的代理损失函数以及高效的算法，以提供强有力的理论学习保证。

Innovation: 
论文引入了新型的代理损失函数和高效的算法，提供了单阶段（联合学习预测器和延迟函数）和两阶段（仅学习延迟函数并与固定专家相结合）学习场景下的理论学习保证，包括可实现的$H$一致性、$H$一致性上下界和贝叶斯一致性。此外，论文还提供了在低噪声假设下的增强理论保证，并在实验中报告了使用提出的代理损失函数的性能结果，与现有基线进行了对比

Conclusion: 
论文解决了单阶段和两阶段延迟学习中关于可实现的$H$一致性、$H$一致性上下界和贝叶斯一致性的开放问题，并提出了一系列新的代理损失函数，在两个专家和多个专家场景下实现了这些保证。同时，论文还提供了在低噪声假设下的增强理论保证。实验结果表明，所提出的代理损失函数的性能优于现有基准。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20650</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>167. cs.LG-网络流量中稳健的异常检测：CICIDS2017上的机器学习模型评估</title><link>https://arxiv.org/pdf/2506.19877</link><description>Background: 
构建有效的和广泛可应用的安全解决方案仍然需要识别出适合的机器学习范式对于入侵检测仍然是关键。本文在两个场景下对四种典型的模型：多层感知器（MLP）、一维卷积神经网络（CNN）、单类支持向量机（OCSVM）和局部异常因子（LOF）进行了受控比较，与CICIDS2017数据集的结果显示了现有各种机器学习模型在已知攻击和未知威胁上的表现差异。

Innovation: 
提出了对四种经典机器学习模型（MLP、CNN、OCSVM、LOF）在CICIDS2017数据集上的比较研究，在已知攻击检测和未知威胁泛化两个场景下，对其效果进行了评估，并展示了不同模型在不同攻击场景下的表现差异，为其在动态网络环境下的应用提供了实际指导。

Conclusion: 
监督学习的MLP和CNN在已知攻击上表现出色但在全新攻击上的召回率急剧下降；未监督学习的LOF在未知威胁上具有较高的召回率但误报率较高；边界基础的OCSVM在召回率和准确率上取得了较好的平衡，显示了两种场景下的稳健检测能力。因此，这些发现为选择IDS模型提供了实际指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19877</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>168. cs.LG-使用FEM模拟预测皮肤粘合界面剥离力的神经网络</title><link>https://arxiv.org/pdf/2506.19855</link><description>Background: 
研究皮肤上的胶粘剂剥离行为对于医学应用（如医用胶和透皮贴剂）的发展至关重要。传统方法，如实验测试和有限元方法（FEM），虽然被认为是金标准，但资源消耗、计算成本高且耗时，尤其是在分析广泛的材料参数空间时。

Innovation: 
本研究提出了一种基于神经网络的方法，用于预测胶粘剂从皮肤组织剥离所需的最小剥离力（F_min），减少了重复的FEM模拟的需求并显著降低了计算成本。利用从90度剥离测试中不同胶粘剂和裂纹力学参数的FEM模拟生成的数据集，神经网络模型在严格5折交叉验证下取得了高精度。最终架构能够广泛预测皮肤-胶粘剂剥离行为，均方误差（MSE）为3.66*10^-7，R^2得分为0.94，展示了稳健的表现。这项工作引入了一种可靠、计算效率高的方法来预测胶粘剂行为，大大减少了模拟时间同时保持准确性。将机器学习与高保真生物力学模拟的整合，使得皮肤-胶粘剂系统的设计和优化更加高效，为未来在计算真皮力学和生物粘合材料设计中的研究提供了可扩展的框架

Conclusion: 
这项工作提供了可靠的、计算成本低的方法来预测胶粘剂行为，显著减少了模拟时间的同时保持了准确性。这种方法的集成使得皮肤-胶粘剂系统的设计和优化更加高效，为未来的研究提供了可扩展的框架。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19855</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>169. cs.LG-利用AI进行欺诈检测和能源市场稳定性的区块链保障能源交易安全</title><link>https://arxiv.org/pdf/2506.19870</link><description>Background: 
 peer-to-peer trading 和分布式电网的发展重塑了美国的能源市场，但同时也带来了新的挑战，尤其是关于能源交易的安全性和真实性。这项研究旨在开发和构建一个安全、智能、高效的能源交易系统，以应对美国去中心化能源市场的长期挑战，特别是安全性、欺诈行为检测和市场可靠性问题.

Innovation: 
本研究将区块链技术和人工智能技术首次创新性地结合起来，构建了一个包含区块链层和人工智能层的系统架构，用于能源交易的安全保障和市场情报提升。特别地，通过使用特定的机器学习模型来识别在去中心化市场中的能源交易欺诈，从而达到提高市场稳定性与安全性目的.

Conclusion: 
通过引入区块链和人工智能技术，研究成功地解决了一些建立在区块链上的美国微电网中的能源交易安全和欺诈问题。提出的系统架构提高了去中心化能源市场的安全性和可靠性，并为未来的能源市场设计提供了新的思路和方法.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19870</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>170. cs.LG-基于模板的可扩展和低成本的新分子生成</title><link>https://arxiv.org/pdf/2506.19865</link><description>Background: 
基于模板的分子生成为药物设计提供了有希望的途径，确保生成的化合物通过预定义的反应模板和构建块是合成可访问的。然而，存在的主要挑战包括最小化合成成本、扩展大规模构建块库以及有效利用小片段集。为解决这些问题，该论文提出了一种递归成本指导框架和动态库机制，以提高生成质量和效率，克服现有模型的不足。

Innovation: 
本文提出了递归成本指导（Recursive Cost Guidance）框架，这一框架利用辅助机器学习模型来近似合成成本和可行性，引导生成低成本合成路径，极大地提升了成本效率、分子多样性和质量。还开发了动态图书馆机制，在小构建块库中增强性能，通过重用中间高回报状态来构建完整的合成树。

Conclusion: 
该方法在基于模板的分子生成中建立了最先进的结果，解决了核心挑战并提升了生成的质量和效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19865</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>171. cs.LG-在队列控制中的有限时间信息论边界</title><link>https://arxiv.org/pdf/2506.18278</link><description>Background: 
在随机处理网络中，已有研究表明MaxWeight策略能够确保稳定性并在重载情况下实现渐近最优性。然而，之前的分析并未在有限时间内提供理论上的下限。本文填补了这一空白，建立了有限时间内信息论的下限，并分析了MaxWeight策略在有限时间内性能的局限性。研究工作基于现实中的随机到达和恶意干扰情况，旨在优化队列长度的总和，这是对传统分析的一个重要扩展，为有限时间内的稳定性和效率提供了新的视角。

Innovation: 
本文的创新点包括：1) 提出了最小-最大框架来精确确定任何策略在有限时间内表现的关键参数；2) 创立了一种信息论的新下限，用于队列长度总和；3) 验证了MaxWeight策略在有限时间内不是最优的；4) 提出了一种新的调度规则，该规则通过最小化完全拉普拉斯漂移（包括二次项）来匹配信息论的下限，这一匹配在某些条件下仅差一个普遍性的常数。这些发现指出了仅基于漂移的方法的局限，并为有限时间内的原则性、非渐近最优性指明了方向，这对于队列控制具有重要意义。

Conclusion: 
本文通过展示MaxWeight策略在有限时间内不是最优的，揭示了仅基于漂移的方法的局限性，并为有限时间下的非渐近最优策略的开发提供了理论基础。研究工作不仅扩展了对随机处理网络中系统的理解，还提出了实现非渐近最优性的新策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18278</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>172. cs.LG-监督相似性对于企业关系</title><link>https://arxiv.org/pdf/2506.19856</link><description>Background: 
本文介绍了一种新的企业联系代理，即特征向量联系（CVLs）。研究使用此概念通过欧几里得相似性首次估计企业联系，随后通过量子认知机器学习（QCML）应用于相似性学习。研究证明这两种方法都可以用于构建盈利的动量溢出交易策略，但QCML相似性在简单的欧几里得相似性之上表现出更优的性能。

Innovation: 
本文的创新在于提出了一种新的企业联系代理——特征向量联系（CVLs），并利用量子认知机器学习方法改善了企业联系的估计方式，特别是在动量溢出交易策略中的应用效果更佳。

Conclusion: 
研究结果表明，无论是通过简单的欧几里得相似性还是通过量子认知机器学习（QCML）相似性，都能够用于构建盈利的动量溢出交易策略。然而，QCML相似性的表现更优。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19856</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>173. cs.LG-数据异质化边缘设备上的高效加密数据共享联邦学习</title><link>https://arxiv.org/pdf/2506.20644</link><description>Background: 
随着隐私保护变得越来越重要，越来越多的模型在边缘设备上进行训练，并通过联邦学习（FL）合并到中央服务器。然而，当前研究忽视了网络拓扑、物理距离和数据异质性对边缘设备的影响，导致延迟增加和模型性能下降的问题。

Innovation: 
为了解决这些问题，我们提出了一种新的边缘设备联邦学习方案，称为加密数据共享联邦学习（FedEDS）。FedEDS 使用客户端模型及其随机层来训练数据加密器，生成加密数据并与其它客户端共享。客户端则使用自己的随机层和加密数据来训练和调整本地模型。通过利用客户端的本地私有数据和其他客户端的加密共享数据培训模型，加快联邦学习的收敛速度，并缓解数据异质性造成的负面影响。这种方案适合应用在要求快速收敛的边缘设备上。实验结果表明，FedEDS在提升模型性能方面具有有效性。

Conclusion: 
FedEDS通过利用数据加密共享，加速了联邦学习的收敛速度，并缓解了数据异质性对模型性能的影响，特别适用于对收敛速度有高要求的边缘设备应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20644</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>174. cs.LG-听而不闻：检测联邦学习中恶意服务器的梯度泄漏</title><link>https://arxiv.org/pdf/2506.20651</link><description>Background: 
最近的研究表明，联邦学习中的梯度更新可能会无意中泄露客户本地数据的敏感信息。当恶意服务器操控全局模型以诱使客户端生成富含信息的更新时，这种风险会显著增加。本文从防御者的视角出发，提供了首个关于恶意梯度泄露攻击及其使用模型操控技术的有效分析。分析揭示了一个核心权衡：这些攻击既不能在重建私人数据方面非常有效，也不能足够隐蔽以逃避检测，尤其是在包含常见归一化技术及联邦平均的真实联邦学习环境中。

Innovation: 
本文提出了一个简单、轻量级且广泛适用的客户端检测机制，该机制能够在本地训练开始前标记可疑的模型更新。尽管这种检测并不是在所有现实的联邦学习设置中都是必要的，但该机制进一步强调了通过最小成本抵御这些攻击的可能性，提供了针对隐私意识联邦学习系统的可部署保护措施。

Conclusion: 
尽管理论上这些恶意梯度泄露攻击令人担忧，但在实践中，它们通常是有限而且可以检测的，尤其是通过基本监控。本文提出的客户端检测机制进一步证明了以最少的开销抵御这些攻击的可行性，为隐私导向的联邦学习系统提供了防护屏障。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20651</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>175. cs.LG-在闭环学习下迷失重训练：指数族模型参数空间探索</title><link>https://arxiv.org/pdf/2506.20623</link><description>Background: 
闭环学习是指从模型生成的数据反复估计模型的过程，这一过程受到了广泛关注，特别是大规模神经网络模型有可能在未来主要通过由人工神经网络生成的数据进行训练。本文研究了这种过程在指数族模型下的表现，推导出参数动态的方程，并分析了参数估计方法对模型动态的影响.

Innovation: 
文章通过研究指数族模型在闭环学习下的动态，揭示了最大似然估计赋予充分统计量鞅性质，导致过程收敛到放大数据初始偏差的吸收状态。但是，通过引入少量来自固定模型生成的数据点，最大后验估计或正则化，可以防止这种结果。此外，还展示了动力学的渐近行为不是可变参数不变的.

Conclusion: 
研究发现尽管存在发现模型偏差的倾向，但通过适当的方法干预，可以避免这种情况。同时，动力学的渐近行为不是可变参数不变的性质需要注意。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20623</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>176. cs.LG-探索图变换器的分布外泛化能力</title><link>https://arxiv.org/pdf/2506.20575</link><description>Background: 
图神经网络（GNN）已在社交网络、生物物理、交通网络和推荐系统等多个领域取得了显著成功。然而，现有方法经常假设训练数据和测试数据具有相同的数据分布，在现实场景中这往往不成立。尽管图变换器（GT）在多种内部分布（ID）基准测试中优于传统的消息传递神经网络（MPNN），但在分布变化（Shift）下的性能仍需进一步研究。在这篇文章中，作者探讨了图神经网络在分布外（OOD）泛化上的挑战，特别关注了骨干网络架构的影响。

Innovation: 
文章系统性地评估了图变换器及其与传统消息传递神经网络的混合架构在OOD设置下表现，并提出了一个用于后训练分析的新方法，该方法比较了整个内部分布和分布外测试数据集的聚类结构，具体检查了领域对齐和类别分离。该方法不仅为图变换器和消息传递神经网络提供了有意义的见解，还展示了其在领域泛化问题中的广泛应用潜力，超越了标准准确率指标，提供了更深入的泛化能力洞察。

Conclusion: 
研究结果表明，图变换器和混合图变换器-消息传递神经网络架构在OOD泛化上表现出更强的能力，即使在没有专门的领域泛化算法的情况下也是如此。该研究强调了图变换器在现实世界图学习中具有稳健性的潜力，并为未来OOD泛化研究提供了新的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20575</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>177. cs.LG-H-FEX: Hamiltonian系统的一种符号学习方法</title><link>https://arxiv.org/pdf/2506.20607</link><description>Background: 
哈密尔顿系统描述了由哈密尔顿函数支配的一类广泛的动力系统，哈密尔顿函数编码了系统的总能量并决定了系统的演化。尽管数据驱动的方法，如符号回归和基于神经网络的方法，可以从中观数据直接学习动力系统的控制方程，但这些方法往往难以准确捕捉复杂哈密尔顿函数并在保持能量守恒的同时提供精确的结果。因此，如何克服这些局限性成为了一个重要的研究挑战。

Innovation: 
本文提出了一种名为H-FEX的符号学习方法，该方法引入了新的交互节点，以有效捕捉复杂的交互项。H-FEX方法在处理高度刚性动力系统方面取得了显著效果，能够准确恢复复杂系统中的哈密尔顿函数，同时保持长期的能量守恒。

Conclusion: 
H-FEX 作为一种强大的框架，展示了其在发现复杂动力系统闭式表达式方面的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20607</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>178. cs.LG-基于真实数据的技能队列有效UCB路由演示</title><link>https://arxiv.org/pdf/2506.20543</link><description>Background: 
本文讨论了如何优化控制基于技能的排队系统，如数据中心、云计算网络和服务系统。通过使用真实数据集进行案例研究，探讨了一种最近开发的强化学习算法在最佳客户服务路由中的实际应用。实验表明，该算法能够高效地学习并适应不断变化的环境，优于静态基准策略，表明其在实际中的潜力。此外，通过引入新的启发式路由规则来减少延迟，增加了该算法的实时适用性。本文还展示了算法可以优化多个目标：除了收益最大化，还可以纳入服务器负载公平性和客户等待时间减少等次要目标。通过调整参数以平衡固有的性能权衡，研究了估计误差和参数调整的敏感性，提供了宝贵见解，有助于在复杂的真实世界排队系统中实现自适应路由算法。

Innovation: 
引入了一种新的启发式路由规则来减少延迟，并展示了算法能够在优化主要目标的同时，还能够优化多个次要目标，如服务器负载公平性与客户等待时间的减少。通过调整参数平衡性能权衡，并研究了算法对估计误差和参数调整的敏感性，提供了宝贵见解，有助于实践中的自适应路由算法实现。

Conclusion: 
实验结果表明，该强化学习算法能够高效学习并适应环境变化，优于静态基准策略，适用于多种目标下的优化，并通过算法调参平衡了潜在的性能权衡，提供了有价值的见解，有助于在复杂的真实世界排队系统中实现自适应路由算法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20543</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>179. cs.LG-图索引向量搜索的核方法</title><link>https://arxiv.org/pdf/2506.20584</link><description>Background: 
目前最流行的向量搜索图索引依赖于计算几何原理构建图，但其正式的图导航保证仅在欧几里得空间中有效。这篇论文提出了一个新的视角，通过机器学习来构建适用于度量和非度量向量空间（例如，内积相似性）的图索引。

Innovation: 
引入了一种新的图索引类型——支持向量图（SVG），利用核方法建立图的连接性，具备在度量和非度量向量空间中的正式导航保证。此外，将最流行的图索引（如HNSW和DiskANN）解释为其特定特化，证明可以通过这种特化产生新的图索引。最后提出了SVG-L0，它通过$L_0$稀疏约束进一步优化SVG，具有自我调节特性，避免了节点出边的长期选择方法，并保持了计算复杂性

Conclusion: 
这项工作展示了利用机器学习构建图索引在非度量向量空间中的可行性，并提出了SVG-L0来进一步优化构建的图，使其在度量和非度量空间中表现更佳。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20584</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>180. cs.LG-不对称REINFORCE算法在离策略强化学习中的应用：平衡正负奖励</title><link>https://arxiv.org/pdf/2506.20520</link><description>Background: 
强化学习（RL）在调整大型语言模型（LLMs）方面得到了广泛应用。与需要实时交互的策略学习相比，离策略方法虽然更具实施便利性和数据效率，但可能产生次优性能。本研究旨在通过分析简单的REINFORCE离策略算法，探讨介于离策略RL和监督微调之间的算法中间范围，其中优势定义为$A=r-V$，$r$为奖励，$V$为可调基线。通过降低$V$可强调高奖励样本，而提高$V$则能更严厉地惩罚低奖励样本。研究指出，虽然在线更新可以从正负信号中均受益，但离策略更新则倾向于更关注正奖励。

Innovation: 
研究首次对简单的离策略REINFORCE算法进行了理论分析，揭示了当基线$V$下界估计奖励期望时，算法的策略改进保证。研究发现离策略更新相比于在线更新，更侧重于利用正奖励信号，而不是负奖励信号。通过对控制随机臂bandit实验以及对最先进的LLMs进行推理任务的微调验证上述发现，表明了该方法的有效性与优势。

Conclusion: 
该研究分析了离策略REINFORCE算法，展示了在满足基线$V$条件下，算法的策略改进保证。研究结果表明离策略更新对正奖励的依赖比负奖励更强，并通过实验验证了这一结论的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20520</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>181. cs.LG-由有限元分析调节的物理信息机器学习方法在激光粉末床融合仿真加速中的应用</title><link>https://arxiv.org/pdf/2506.20537</link><description>Background: 
传统数值方法如有限元分析（FEA）在激光粉末床融合（LPBF）过程中因高计算成本而难以进行高效的模拟。因此，高效预测LPBF过程的需求显而易见，特别是在需要高精度和快速计算的情况下。传统方法面临的主要问题是计算成本高，特别是在时间依赖性问题中误差累积严重。

Innovation: 
本文提出了一种结合物理信息神经网络（PINN）和有限元分析（FEA）的建模框架，即FEA-Regulated Physics-Informed Neural Network (FEA-PINN)。通过开发一种新的动态材料更新策略和引入温度依赖材料属性，FEA-PINN能够在保持FEA精度的同时极大地提高计算效率。同时，FEA-PINN集成FEA校正模拟来确保物理一致性并减少误差扩散。研究表明，FEA-PINN在准确性上等同于FEA，但计算成本显著降低。

Conclusion: 
所提出的FEA-PINN框架已被基准FEA数据验证，并通过LPBF单道扫描进行了展示，表明该方法在提高模拟效率和准确性方面具有良好的应用前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20537</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>182. cs.LG-基于数字孪生生成数据集和高效数据增强的工业能源细分</title><link>https://arxiv.org/pdf/2506.20525</link><description>Background: 
工业非侵入式负荷监测（NILM）受限于高质量数据集的稀缺性和工业能源消耗模式的复杂变化。数据稀缺性和隐私问题需要解决，以提高NILM模型的鲁棒性和泛化能力，促进工业能源的有效监测和管理。

Innovation: 
引入了一个开放源代码的合成工业数据集（SIDED），通过数字孪生模拟生成。提出了智能设备-调制数据增强（AMDA）方法，这是一种计算高效的增强技术，通过智能调整设备功率贡献，基于相对影响提升了NILM模型的泛化能力。在实验中，使用AMDA增强的数据训练的NILM模型显著提高了复杂工业设备（如热电联产系统）的能源细分性能，尤其在样本外情景中表现优异。

Conclusion: 
AMDA方法有效提高了NILM模型的泛化能力，尤其是在复杂工业设备的能源细分中，使用AMDA增强的数据训练的模型在样本外测试中显示出显著的性能提升，验证了其的有效性和实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20525</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>183. cs.LG-多模态表示学习与融合</title><link>https://arxiv.org/pdf/2506.20494</link><description>Background: 
多模态学习是人工智能的一个快速发展领域，它通过结合来自不同来源的信息（如图像、文本和音频）来帮助机器理解复杂的事务。通过利用每种模态的优点，多模态学习使AI系统能够建立更强和更丰富的内部表示。这些表示有助于机器在实际场景中更好地进行解释、推理和做决策。该领域包括获取不同类型数据共享特征的核心技术、不同模态之间匹配信息的方法以及通过深度学习模型将这些信息结合的策略。尽管已经取得了良好的进展，但仍存在一些重大问题，如处理不同的数据格式、缺失或不完整输入以及抵御对抗攻击。研究人员正在探索新的方法，例如无监督或半监督学习、AutoML工具，以使模型更高效且更容易扩展。同时更加注重设计更好的评估指标或建立共享基准，使跨任务和领域比较模型性能变得更加容易。随着该领域不断发展，多模态学习有望改善许多领域：计算机视觉、自然语言处理、语音识别和医疗保健。未来，它可能有助于构建更像人类理解世界、灵活、基于上下文且能够应对现实世界复杂性的AI系统。

Innovation: 
研究人员正在探索新的方法，例如无监督或半监督学习、AutoML工具，以使模型更高效且更容易扩展。同时更加注重设计更好的评估指标或建立共享基准，使跨任务和领域比较模型性能变得更加容易。这些新的方法和努力，旨在提高多模态学习技术的整体性能和实用性。

Conclusion: 
随着多模态学习领域继续发展，它预计将在计算机视觉、自然语言处理、语音识别和医疗保健等多个领域得到改进。未来，多模态学习可能有助于构建更像人类理解世界、灵活性强、基于上下文且能够应对现实世界复杂性的AI系统。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20494</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>184. cs.LG-多变量时间序列中无监督策略的基准测试：异常检测</title><link>https://arxiv.org/pdf/2506.20574</link><description>Background: 
多变量时间序列在医疗保健、金融服务、制造业或物理检测监控等领域中是一个重要的问题。准确识别异常错误或故障出现的时间是至关重要的，但也很具挑战性，因为异常的未知性质以及时间序列维度之间的复杂相互依赖关系使得这种识别变得复杂。

Innovation: 
本文探讨了基于变压器的方法在时间序列异常检测中的应用，特别关注了最近提出的iTransformer架构。我们对关键参数（如窗口大小、步长和模型维度）对性能的影响进行了研究，并分析了如何从多维异常分数中提取异常标签，讨论了适合此类标签的评价指标的影响。此外，我们研究了训练期间存在异常数据的影响，并评估了使用替代损失函数缓解其影响的有效性。最后，我们对时间序列异常检测中多种变压器模型进行了全面的比较研究。

Conclusion: 
本文对几种基于变压器的时间序列异常检测模型进行了全面比较，在多种数据集上展示了所提出方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20574</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>185. cs.LG-联邦学习中的协作批量大小优化</title><link>https://arxiv.org/pdf/2506.20511</link><description>Background: 
联邦学习（FL）是一种无需在中心位置收集数据的去中心化协作机器学习框架。它在多个领域得到应用，如医院中的疾病诊断、金融交易中的欺诈检测等。在联邦学习中，尽管参与者可能会共享其用于训练的硬件资源，但由于没有信息交换，他们的训练过程可能会受到配置不当的影响。因此，研究如何优化本地批量大小以提高训练效率显得尤为重要。本文旨在通过硬件使用优化来改进本地训练过程。

Innovation: 
本文提出了一种使用贪婪随机搜索方法来优化联邦学习中的本地批量大小，以提高整个参与者的最佳训练设置。这一方法能够充分利用联邦学习的并行处理特性，提高收敛速度，并可与优化局部参数的效果相近，同时依然保持与默认参数设置相当的性能。

Conclusion: 
实验结果表明，与默认参数设置相比，本方法能提高收敛速度，保持与局部参数优化的性能相近。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20511</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>186. cs.LG-墙街Feds：联邦学习中的客户特定代币作为投资工具</title><link>https://arxiv.org/pdf/2506.20518</link><description>Background: 
联邦学习（FL）是一种协作式机器学习范式，它允许参与者在不泄露训练数据的情况下共同训练模型。这种范式特别适合金融服务等重视数据隐私、安全性和模型性能的领域。自其引入以来，已广泛研究FL，其中包括更高效的协作技术、防御其他客户端攻击模型的方法及参与者的贡献评估方法。对于盈利的联邦学习，需要开发激励方法来确定参与者之间的奖励分配。尽管提出了多种分配方法并进行了详细研究，但关于奖励分配框架的研究仍相对较少。

Innovation: 
本文提出了一个新颖的框架，引入了客户特定代币作为联邦学习生态系统的投资工具。该框架利用去中心化金融（DeFi）平台和自动做市商（AMMs）来创建一个更加灵活和可扩展的奖励分配系统，同时提供一种机制让第三方投入联邦学习过程。

Conclusion: 
该框架旨在通过结合DeFi平台和AMMs来改进现有的激励机制。这将为参与者提供一种更灵活、可扩展的奖励分配方法，并为第三方提供投资联邦学习过程的机会。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20518</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>187. cs.LG-Counterfactual 影响作为一种分布性量度</title><link>https://arxiv.org/pdf/2506.20481</link><description>Background: 
机器学习模型因为从训练数据中记忆样本而面临隐私和泛化方面的担忧。尽管现有的研究表明样本自身的自影响是衡量记忆化的一个重要指标，但近年来的研究发现训练样本（尤其是类近的样本）对记忆化的影响超过了自影响。本文探讨了将反事实影响作为分布性量度来研究模型记忆化的可能性，研究所有训练样本如何共同影响一个样本的记忆化程度.

Innovation: 
本文创新性地将反事实影响视为分布性量度，通过计算语言模型中训练样本对彼此的全面影响分布来分析其特性，发现仅仅关注自影响会严重低估记忆化所带来的实际风险。即使在视觉识别领域，了解每个训练样本之间的相互影响分布也能揭示出CIFAR-10中的类近样本情况。这项研究强调了复杂训练数据交互在记忆化中的作用，并表明分布性影响比自影响更能捕捉记忆化的本质.

Conclusion: 
研究发现，仅仅依赖自影响评估记忆化的风险是不准确的，实际记忆化受到训练样本复杂交互的影响，只有全面理解训练样本之间的相互影响才能更准确评估记忆化的风险。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20481</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>188. cs.LG-通过非公平聚合的知识蒸馏解决 Federated Learning 中的数据异质性</title><link>https://arxiv.org/pdf/2506.20431</link><description>Background: 
联邦学习旨在在一个接近集中式训练性能的分布式环境中训练全局模型。然而，诸如客户端标签偏差、数据量偏差以及其他异质性问题严重降低了模型的性能。现有许多方法忽略了只有少数客户端参与大规模客户端中的训练场景，而实验证明这种场景提出了更具有挑战性的联邦学习任务。现存研究较少关注这类场景下的模型训练问题，亟需新的方法来有效利用所有客户端的知识，特别是关注少数客户端参与情况下的模型优化.

Innovation: 
提出了一种知识蒸馏与非公平聚合（KDIA）策略，专门针对上述提到的联邦学习设置。该策略的核心在于，学生模型是参与客户端的平均聚合，而教师模型是基于三个频率（参与间隔、参与次数和数据量比例）的加权聚合。通过本地自知识蒸馏和服务器上训练的生成器生成近似独立同分布（IID）的数据特征进行辅助训练。实验结果表明，在多种异质设置下，KDIA可以在较少的训练轮次内达到更高的准确率，尤其是在严重异质性条件下效果更显著.

Conclusion: 
该研究通过非公平聚合的知识蒸馏策略显著提升了在数据异质性条件下的联邦学习性能，在少量客户端参与的大规模客户端设置中，更能充分发挥所有客户端的知识价值，降低了训练过程的复杂性和计算量，验证了其在实际应用中的有效性和优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20431</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>189. cs.LG-LLM基于的表格数据分类中自动演示选择</title><link>https://arxiv.org/pdf/2506.20451</link><description>Background: 
在应用In-Context Learning (ICL)进行表格数据分类时，核心问题是如何确定提示中所需演示的数量。此研究探讨了如何自动选择合理的演示次数，并提出了一种算法，该算法不仅考虑了表格数据的分布，还结合了用户选择的提示模板和特定的大语言模型来进行估计。

Innovation: 
本研究提出的算法利用谱图理论定义了一个新的度量标准，以量化不同演示之间的相似性。通过构建相似性图并分析其拉普拉斯算子的特征值，该算法可以推导出可用于表示表数据所需的最小演示数，且此方法已通过与传统随机选择算法的对比实验在不同数据集和大语言模型上进行了验证验证了其有效性.

Conclusion: 
本研究提出了一种基于谱图理论的方法，通过一种新的度量标准来量化演示之间的相似性，并利用拉普拉斯特征值来确定大语言模型内所需的最小演示数。这种方法在多种数据集和大语言模型上的实验验证证明了其有效性，解决了如何自动选择合理数量的演示这一挑战。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20451</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>190. cs.LG-客户端聚类结合知识共享：在个性化对等学习中增强隐私性和鲁棒性</title><link>https://arxiv.org/pdf/2506.20413</link><description>Background: 
由于人工智能（AI）在物联网（IoT）生态系统中的广泛应用，加大了对能够在异构、资源受限设备之间高效且私密地实现个性化学习方法的需求。然而，在去中心化环境中实现有效的个性化学习带来了多个挑战，如客户端之间的高效知识转移、数据隐私保护以及抵御恶意攻击的能力。这篇论文旨在通过开发P4（个性化、私密、对等）方法来解决这些挑战，P4能够在资源受限的IoT设备上提供个性化模型，同时确保差分隐私并在恶意客户端存在的情况下保持鲁棒性。解决方案通过一个轻量级的完全去中心化的算法来隐私地检测客户端相似性，并形成合作团队。在每个团队内部，客户端利用差分隐私的知识蒸馏来协同训练模型，以保持高准确性并确保在存在恶意客户端的情况下具备鲁棒性。

Innovation: 
P4是一种专为资源受限的IoT设备设计的方法，能够在保护隐私的同时建立起高效的对等协作学习。其创新之处在于采用了轻量级、完全去中心化的算法，通过隐私地检测客户端相似性形成协作团体，并且在团队内部利用差分隐私的知识蒸馏进行协同训练，这种组合有效地提高了准确性和鲁棒性。此外，P4还通过实验结果验证了其在应对恶意攻击方面的有效性，并展示了在资源受限设备上部署的可行性，其中两个客户端之间的协作训练仅增加约7秒的开销。

Conclusion: 
实验结果表明，P4的准确率比现有差分隐私的对等学习方法高出5%到30%，并且在高达30%恶意客户端的情况下保持了鲁棒性。此外，P4还展示了其在资源受限设备上的应用实践，并证明了其在提升隐私性和鲁棒性方面的有效性和实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20413</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>191. cs.LG-具有多变量并行注意力机制的基础模型以生成神经活动</title><link>https://arxiv.org/pdf/2506.20354</link><description>Background: 
在涉及异构通道配置的多变量时间序列学习中，对于深度神经网络（DNN）来说依然是一个根本性的挑战，尤其在如颅内脑电图（iEEG）等临床领域中更为显著，因为不同受试者之间的通道布置存在广泛差异。为了克服这一挑战，本文引入了一种新型的多变量并行注意力（MVPA）机制，它能够解耦内容、时间及空间注意力，确保各通道数目和配置变化的情况下高效灵活地建模时间序列数据。研究者利用该方法构建了MVPFormer，一种能够在各种受试者中通用的人类电生理学生成式基础模型，并通过预测iEEG信号的发展来训练该模型。为了支持相关领域研究者们的进一步努力，研究团队还发布了迄今为止最大的公共iEEG数据集——SWEC iEEG数据集，包含了近10,000小时的来自不同临床来源的异构记录数据。此外，MVPFormer还被用来在多个标准时间序列预测与分类任务中验证MVPA的有效性，包括癫痫检测。结果显示,MVPFormer在SWEC、MAYO和FNUSA数据集上的性能明显优于现有最先进的Transformer基线模型。

Innovation: 
本文提出了一种多变量并行注意力机制（MVPA），它能够灵活且高效地处理在不同通道数目和配置变化下的时间序列数据。基于MVPA，研究者开发了MVPFormer，这是一种开源的、具备基础网络框架、具有先进临床表现性能的基础模型。通过这一机制，MVPFormer在各类时间序列预测任务中实现了强泛化性表现，特别是在癫痫检测方面表现出专家级的性能。此外，研究团队还公开发布了目前最大的公共iEEG数据集——SWEC iEEG数据集，旨在推动整个研究领域面向未来的发展。

Conclusion: 
本文提出了多变量并行注意力机制（MVPA）和基于该机制构建的基础模型MVPFormer，二者共同构成了一个通用的时间序列分析组件。MVPFormer能够跨实验对象高效泛化的人类电生理学基础模型，已经在多个数据集上验证了其优越性。通过SWEC iEEG数据集的公共发布，研究团队希望能够在此领域中推动进一步的研究和应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20354</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>192. cs.LG-TESSERA：表面光谱时序嵌入的地表表示与分析</title><link>https://arxiv.org/pdf/2506.20380</link><description>Background: 
卫星遥感（RS）能够应用于各种地球观测（EO）领域，包括气候建模、碳核算和可持续土地使用等策略。当前，数据表达和模型表现多种多样，但尚缺乏能够同时提供全球高分辨率和高性能表示的方法。现有模型在特定任务上表现优异，但通常局限于单一数据源和任务类型，缺乏通用性和普适性。TESSERA正是为了解决这一问题而提出的，它是一种使用自我监督学习（SSL）的新型遥感基础模型，旨在生成适用于多种任务的全球范围的、基于多源卫星数据的高质量表示。

Innovation: 
TESSERA通过结合光学和雷达数据，利用Transformer编码器生成10米分辨率的全球表示，且采用多层感知机融合来自不同传感器的数据，实现了一个能够覆盖2017年至2024年的全球表示图。其创新点在于使用自监督学习方法从像素级的卫星数据时间序列中自动学习特征表示，同时创新地利用光学和雷达数据进行时序嵌入，从而提升模型的鲁棒性和性能，且该研究提供了预计算的表示，能够与现有的一系列任务特定模型和基础模型进行对比，并展示TESSERA在多个下游任务上的优越表现。开放源码策略进一步促进了该模型的普及。

Conclusion: 
研究表明，TESSERA在多种下游任务上均显著超越传统RS基准模型和其他地理时空基础模型。该模型提供了一种新的方式，能够大规模生成高质量的全球表示，为地球表面的表示与分析提供了一种强有力的支持工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20380</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>193. cs.LG-基于残差海森矩阵的PINNs积分求解方法</title><link>https://arxiv.org/pdf/2506.20441</link><description>Background: 
物理感知神经网络（PINNs）通过在损失函数中嵌入物理模型并在所谓的插值点使用自动微分最小化残差，已经成为一种学习偏微分方程（PDEs）的代理神经求解器的有效方法。原本均匀采样的插值点的选择已经成为了近期研究的重要话题，推动了自适应采样细化技术的发展。

Innovation: 
本文提出了一种新的积分近似求解方法，基于考虑函数的海森矩阵。该方法被用来指导PINNs训练过程中插值点的选择。

Conclusion: 
提出的基于残差海森矩阵的积分近似方法能有效指导PINNs在训练过程中的插值点选择，从而提高PINNs的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20441</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>194. cs.LG-通过频谱自举和拉普拉斯基增强学习进行自我监督的图学习</title><link>https://arxiv.org/pdf/2506.20362</link><description>Background: 
近年来，图神经网络（GNN）在处理图结构数据方面显示出强大的性能，但大多数现有的方法依赖于对比目标和手工设计的增强，这不仅增加了学习的复杂性，还可能导致模型对特定增强策略的高度依赖。为了克服这些限制，该论文提出了一个新的自我监督的图学习框架LaplaceGNN，通过频谱自举技术和拉普拉斯基增强，避免了负样本的需求，从而实现了更高效、更简单的结构表示学习，适用于多种应用场景。

Innovation: 
LaplaceGNN的主要创新点包括：1. 通过最大最小中心性引导的优化预先计算频谱增强，无需依赖手工设计的增强；2. 引入了对抗自举训练方案，进一步增强特征学习和鲁棒性。这些改进使得LaplaceGNN能够在保持线性复杂度的同时，提供一种更简单、更高效的自我监督图神经网络解决方案，适用于多个领域。

Conclusion: 
实验结果表明，LaplaceGNN在不同基准数据集上表现出优越的性能，相较于最先进的自我监督图方法提供了更好的自我监督图表征学习，为高效学习丰富表达性的图表示提供了新的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20362</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>195. cs.LG-在非平稳性下未来离策评估与学习</title><link>https://arxiv.org/pdf/2506.20417</link><description>Background: 
该研究探讨了未来离策评估（F-OPE）和学习（F-OPL）的问题，针对非平稳环境下的策略未来价值估计和优化问题。在这些环境中，数据随时间变化。例如，在电商平台推荐场景中，目标是利用上个月旧政策的数据来估计和优化未来月份的策略价值。由于未来环境的数据在历史数据中不可见，现有的方法要么假设环境的平稳性，要么依赖于严格的奖励建模假设，这会导致较大偏差。因此，本文旨在解决现有方法的限制问题，提出了一种新的未来价值估计器OPFV，能够有效进行未来的策略价值估计，并且在理论上证明了这种估计器的低偏差条件。

Innovation: 
提出的OPFV估计器是第一个利用时间序列数据中的结构（如季节性、周周期或节假日效应）进行离策评估的方法。通过引入一种新的重要性权重方式，OPFV能够在非平稳环境中实现有效的未来策略价值评估。此外，还提出了一种新的策略梯度方法来利用历史数据主动学习未来的策略，而不需要未来的实际数据。这种新方法在不同的实验场景下显著优于现有的方法，尤其是在非平稳条件下对未来策略价值的估计和优化方面表现出色。

Conclusion: 
本文通过提出OPFV估计器，解决了在非平稳环境下未来策略价值的评估和优化难题。通过理论分析表明OPFV在某些条件下低偏差，并通过实践证明了该方法在多种实验设置下的优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20417</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>196. cs.LG-针对轨迹数据可解释性和高效性特征选择：一种分类方法</title><link>https://arxiv.org/pdf/2506.20359</link><description>Background: 
轨迹分析不仅在于获取运动数据，更在于理解物体在空间和时间中的移动模式，以及预测其下一步的移动。由于该领域引起广泛关注，数据收集显著改善，导致大量特征可用于训练和预测模型。然而，这导致高维度特征爆炸问题，降低了数据效率和可解释性，从而降低机器学习模型的准确性。传统的特征选择方法逐渐变得普遍，以应对这一挑战。本文的背景是为了解决这个问题，并提出一种基于分类的方法来选择特征。

Innovation: 
本文提出了一种基于分类的特征选择方法，这种方法根据特征的内部结构将数据分类为几何特征和动态特征，并进一步细分为曲率、凹入、速度和加速度。这种分类方法能够持续保持或超越其他预测性能，并通过减少组合空间显著减少特征选择所需的时间。此外，通过这种分类，还能够洞察每个数据集对哪些特征集更敏感。

Conclusion: 
本文提供了强有力的证据，证明基于分类的特征选择方法可以增加解释性、减少维度和计算复杂性，并促进高级决策制定。它为研究人员和实践者处理轨迹数据集提供了方法论框架，并为可解释的人工智能领域做出了贡献。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20359</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>197. cs.LG-DipSVD: 双重要性保护的SVD方法以提升大规模语言模型压缩效率</title><link>https://arxiv.org/pdf/2506.20353</link><description>Background: 
大型语言模型（LLMs）的计算需求和部署成本不断增加，导致了一系列压缩方法的诞生。现有基于SVD的压缩方法主要关注压缩后矩阵与原矩阵的整体差异，而忽视了对关键矩阵元素的保护，导致压缩后的模型性能较差。经典压缩方法如量化和无结构剪枝也有各自的局限性，相较于这些方法，SVD压缩在硬件兼容性和理论保障方面具有优势，但现有方法未能全面保护关键元素。

Innovation: 
本文提出了一种双层重要性保护机制，增强SVD压缩方法的效果：1. 局部重要性保护：通过通道加权数据去相关化，保留每个权重矩阵中最关键的奇异向量；2. 全局重要性保护：通过启发式或优化方法使不重要层承担更大的压缩负担，从而最小化压缩对关键层的影响。实验结果表明，DipSVD在多个基准测试中表现优于现有SVD基压缩方法，尤其是在高模型压缩比时，模型性能更为出色。

Conclusion: 
研究提出的方法DipSVD通过双层重要性保护机制显著提高了SVD压缩方法的效果，尤其是在高压缩比时，模型性能大幅提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20353</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>198. cs.LG-监督耦合矩阵-张量分解(SCMTF)在溃疡性结肠炎患者报告结果计算表型中的应用</title><link>https://arxiv.org/pdf/2506.20065</link><description>Background: 
表型是指对患者进行分组以识别不同疾病的进程模式的过程。近期的趋势是利用低秩矩阵和张量分解方法来进行多模态、异质和缺失数据的处理。患者报告的症状对于理解炎症性肠病（如溃疡性结肠炎）患者的体验至关重要。然而，这类患者报告的症状通常噪声较大、具有主观性且数据稀疏，因此通常未被纳入表型研究和其他机器学习方法中。本文探讨了使用一种新颖的监督耦合矩阵-张量分解（SCMTF）方法来利用患者报告结果（PROs）来进行计算表型研究，该方法将时间点的症状和实验室数据与静态特征相结合，预测溃疡性结肠炎的药物持续时间。这种方法处理了PROs中的大量缺失数据，取得了较好的预测效果。

Innovation: 
这是第一个基于张量且监督和耦合于一体的表型方法，首次应用于溃疡性结肠炎领域，首次应用于患者报告结果(PROs)。使用深度学习框架使得模型更加灵活且易于训练。方法可以处理PROs中大量的缺失数据，最佳模型预测药疗后8个月和20个月的AUC分别为0.853和0.803。可以解析导出可解释的表型，包括静态特征和时间特征及其模式。证明了基于低秩矩阵和张量的表型方法可以成功应用于溃疡性结肠炎领域以及高度缺失的PRO数据，并且发现这些表型特征有助于预测药物持续时间，表明患者报告的症状变量包含通常被忽略的重要信息。

Conclusion: 
我们成功地运用监督耦合矩阵-张量分解（SCMTF）方法基于低秩矩阵和张量的表型技术，应用于患者的报告结果（PROs）在溃疡性结肠炎（UC）的领域。我们证明了该方法可以处理PROs中大量的缺失数据，并成功地识别出有效的表型，可以帮助预测药物的持续时间，强调了PROs数据的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20065</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>199. cs.LG-多变量时间序列数据中深度神经网络学习格兰杰因果关系的能力</title><link>https://arxiv.org/pdf/2506.20347</link><description>Background: 
格兰杰因果性（GC）提供了一种优雅的统计框架来研究多元时间序列数据之间的关联。尽管线性向量自回归模型（VAR）具有很好的解释性，但由于其对能够捕获的关联类型有特定假设，这些模型的实际应用受到限制。已有大量文献试图利用深度神经网络（DNNs）的功能逼近能力来估计GC，但这些方法往往将GC视为一个变量选择问题。因此，本文提出了一个新的思路：使用深度学习模型同时或联合建模时间序列，通过对比使用所有过去数据和排除特定时间序列组件的数据条件下的模型不确定性和残差分布，可以学习到正确的格兰杰因果结构，尤其是在有足够的训练数据时。此外，还探讨了输入层dropout对神经网络学习时间序列中格兰杰因果关系能力的影响。研究表明，经过良好正则化的模型确实可以从数据中学习到真正的格兰杰因果结构，而无需在损失函数中明确添加引导模型选择变量或进行稀疏回归的项。

Innovation: 
提出了一个新的针对GC问题的思路，即通过使用深度学习模型联合建模时间序列，并通过比较模型不确定性或残差分布的变化，来学习真正的格兰杰因果结构。此外，还研究了输入层dropout对神经网络学习GC能力的影响。并且表明，经过良好正则化的模型可以直接从数据中学习到真实的格兰杰因果结构，而不需要在损失函数中添加引导项。

Conclusion: 
通过使用经过良好正则化的深度学习模型，并通过对比含有全部过去数据和排除特定时间序列组件的数据条件下的模型不确定性和残差分布，可以从数据中学习到真正的格兰杰因果结构。此外，输入层dropout可以增强神经网络学习时间序列中GC关系的能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20347</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>200. cs.LG-学习中等输入敏感函数：一种基于QR编码解码的案例研究</title><link>https://arxiv.org/pdf/2506.20305</link><description>Background: 
函数学习过程的难度与其输入敏感度相关。例如，图像分类任务对输入不敏感，即使有轻微的损坏也不会影响分类结果；而算术和符号计算则对输入高度敏感，每个输入变量都直接影响计算结果。本研究首次探索基于学习的快速回应（QR）码解码，并深入分析学习中等敏感函数的案例研究表明，通过学习嵌入文本的结构，Transformer模型可以成功超越理论纠错极限解码QR码，甚至可以从富含英文的训练数据推广到其他语言及随机字符串。此外，研究人员发现，基于Transformer的QR解码器关注数据位并忽略校验位，这表明解码机制与传统的QR码读取器有明显不同。

Innovation: 
该论文创新性地探讨了中等输入敏感性的函数学习问题。作者利用Transformer模型进行QR码解码，该模型能够超越传统的理论纠错边界进行解码，并对外部输入的种类变化拥有很好的泛化能力。研究人员还发现，基于Transformer的QR码解码器在解码机制上不同于传统的QR码读取器，这是该研究的一个重要贡献。

Conclusion: 
研究通过实验展示了基于Transformer的QR码解码方法的有效性，表明此方法不但能够准确解码常规的QR码，还可以处理一些非典型的数据集，具备较强的泛化能力。研究还揭示了基于Transformer解码器的独特解码机制，这为进一步理解AI在编码解码领域的应用提供了新的视角。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20305</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>201. cs.LG-从聚类联邦学习中提炼通用专家</title><link>https://arxiv.org/pdf/2506.20285</link><description>Background: 
聚类联邦学习（CFL）通过训练多个分组或集群特定的专家模型来应对非同态数据（non-IID data）带来的挑战。然而，现有的方法往往忽略了集群之间共享的信息，而这些信息是所有参与联邦学习（FL）系统成员的可泛化的知识。因此，该机制存在潜在的局限性，即未能充分利用集群间共享的知识以优化整体学习的有效性。这引发了一种新的研究需求，即开发能够从多个集群的知识提炼出通用专家模型的联邦学习框架，以有效集成集群间的共享知识，同时保留个性化特性。

Innovation: 
本文介绍了一种创新的联邦学习框架，该框架通过提炼多集群的知识生成通用专家模型。通用专家捕捉所有客户端之间的全局共享信息，并随后分配给每个客户端作为下一轮模型训练的初始化。该框架通过三个迭代步骤运作：（1）客户端本地模型训练，（2）集群特定模型聚合，（3）通用专家提炼。这种三步学习范式确保了细粒度的非同态特性得到保存，同时有效整合了集群间的共享知识。相比传统的基于梯度的聚合方法，基于提炼的模型聚合方法更灵活地处理模型异构性，并减少了集群特定专家间的冲突。

Conclusion: 
本文提出了的方法在各种场景下表现出优越的性能，证明了其能够通过更有效地平衡个性化和共享知识而促进聚类联邦学习的进步。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20285</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>202. cs.LG-顺序捆绑推荐中的生产者公平性</title><link>https://arxiv.org/pdf/2506.20329</link><description>Background: 
研究在用户依次接收相关和兼容物品集合的序列捆绑推荐环境下，如何实现对不同物品组在推荐会话中展示的公平性。受现实应用场景的启发，定义了生产者公平性，旨在追求不同物品组在用户间展示的期望公平性，同时兼容高质量的捆绑推荐。

Innovation: 
提出了一种精确的解决方案，用于解决小型实例问题，并探讨了质量优先、公平优先及一种自适应优化方法，旨在实现在用户到达时实时解决公平性与质量的平衡。实验结果显示，每种方法有其优势和局限性，但都能有效地实现公平的捆绑推荐，同时不牺牲质量。

Conclusion: 
研究证实了在确保捆绑质量的前提下，能够实现对不同商品组的公平展示，提出的解决方案能够在实际应用中有效运行。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20329</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>203. cs.LG-FedBKD：拥抱非IID数据上的泛化与个性化知识蒸馏的联邦学习</title><link>https://arxiv.org/pdf/2506.20245</link><description>Background: 
联邦学习（FL）是一种分散式协作机器学习技术，旨在解决工业机器学习实践中的孤立数据孤岛和数据隐私泄露问题。但是，处理非同态独立分布（non-IID）数据是一个重大挑战。当前的解决方案要么侧重于构建一个全能的全局模型，要么定制个性化的局部模型。它们中的大多数不能在同时提供良好泛化的全局模型和良好表现的局部模型。此外，许多用于解决非IID问题的FL方案可能通过引入公共数据集来受益。然而这也增加了数据泄露的风险。为了应对这些问题，我们提出了一种新颖的数据无损知识蒸馏框架，Federated Bidirectional Knowledge Distillation (FedBKD)。该框架利用生成式对抗网络（GAN）生成合成数据，以实现全局和局部模型之间的双向知识蒸馏，从而提高双方的表现。

Innovation: 
提出了一种新颖的数据无损知识蒸馏框架FedBKD。在生成对抗网络（GAN）训练过程中，局部模型作为判别器且其参数被冻结。使用合成数据进行全局和局部模型之间的双向知识蒸馏，以促进知识交互，从而提升双方的性能。FedBKD在四种基准下的不同非IID设置中进行了广泛实验，结果表明其在每种情况下都取得了最优性能。

Conclusion: 
FedBKD通过合成数据的双向知识蒸馏有效地解决了联邦学习中的非IID数据泛化与个性化之间的平衡问题，以广泛的实验展示了其最优性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20245</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>204. cs.LG-基于转移学习的作物病害检测深度学习模型对比分析</title><link>https://arxiv.org/pdf/2506.20323</link><description>Background: 
本文探讨了一种基于人工智能驱动的作物疾病检测系统的开发，旨在帮助资源有限的农村地区农民。我们比较了不同的深度学习模型，着重分析它们在迁移学习中的有效性，以改善作物健康管理和促进农村可持续发展。

Innovation: 
本文通过利用EfficientNet、ResNet101、MobileNetV2及自定义CNN模型，实现了95.76%的验证准确率，并对比分析了不同深度学习模型在迁移学习中的性能，展示了迁移学习在农业实践中的潜力，进一步提升作物健康管理和支持农村可持续发展的能力

Conclusion: 
本文的研究证明了迁移学习在农业实践中的潜力，在作物疾病检测中具有广泛应用前景，可以有效提升作物健康管理水平，支持可持续农业在农村环境中的实施。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20323</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>205. cs.LG-Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning</title><link>https://arxiv.org/pdf/2506.20324</link><description>Background: 
动态图由于节点特征演变和网络结构变化的相互作用，展现了复杂的时序动态特性。近期，Graph Neural Controlled Differential Equations (Graph Neural CDEs) 已经将神经控制微分方程成功地从欧几里得空间路径扩展到了图路径。

Innovation: 
本文引入了 Permutation Equivariant Neural Graph CDEs，通过将 Graph Neural CDEs 投影到置换等变函数空间中，从而显著减少了模型参数的数量，同时不牺牲表示能力。这使得训练更加高效，并提高了泛化能力。

Conclusion: 
我们在模拟动态系统和真实任务上通过实验展示了该方法的优势，在插值和外推场景中都表现出更好的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20324</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>206. cs.LG-利用机器学习方法生成源自能源消费者的时序替代数据以用于长期预测场景</title><link>https://arxiv.org/pdf/2506.20253</link><description>Background: 
电力价值链中的预测引起了大量研究关注，但大多数研究主要集中在发电或消费的短期预测上，研究重点在于系统层面，而较少关注个体消费者。此外，长期预测个体电力消耗这一话题的任务被进一步忽视。本文深入比较评估了数据驱动方法生成适应能源消耗长期预测的时间序列数据。高质量的高度保真的合成数据对于一系列应用至关重要，包括能源系统的状态估计或电力网络规划。本研究采用德国家庭的开源数据集，时间分辨率为15分钟，评估并比较了如混合Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔可夫模型（HMM）和掩蔽自回归伯恩斯坦多项式归一化流（MABF）等先进的但较少常见的技术，分析这些方法复制个体能源消耗模式的时间动态、长距离依赖性和概率过渡的能力。

Innovation: 
本研究创新在于深入评估并比较了多种先进的数据驱动方法（WGAN、DDPM、HMM和MABF）在生成适合长期个体电力消耗预测的时间序列方面的能力，并且优化了合成数据生成框架，重点关注匿名和隐私保护，生成符合特定要求的高度保真合成电力消耗数据。

Conclusion: 
通过对比评估这些方法的优缺点，我们能够为状态估计和其他能源相关任务推荐最合适的策略。生成和分析框架旨在提高合成电力消耗数据的准确性和可靠性，同时确保数据符合匿名的相关标准，从而减少对特定客户的具体个人特征的危险性识别。所生成的合成电力消费模式可以立即用于状态估计或消费预测等应用中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20253</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>207. cs.LG-Q-resafe: 评估量化风险及量化感知安全性修补方法在量化大型语言模型中的应用</title><link>https://arxiv.org/pdf/2506.20251</link><description>Background: 
量化大型语言模型（LLMs）在资源受限环境中得到了越来越多的关注和重要性。然而，一些新兴的研究表明，量化可能会损害LLMs的安全能力，这强调了系统安全评估和有效的缓解策略的迫切需要。由于量化可能影响LLMs的安全性，因此进行全面的安全评估和提出相应的缓解策略变得尤为重要。本论文旨在系统评估各种主流的量化技术以及不同校准数据集，并提出一种量化感知的安全修补框架Q-resafe，以高效恢复量化LLMs的安全性，同时最大限度地减少对实用性的负面影响。

Innovation: 
本论文提出了一种名为Q-resafe的量化感知安全修补框架，该框架能够在不显著影响实用性的前提下，修复量化LLMs的安全漏洞，并重新调整量化后的安全性与未量化之前的对齐。Q-resafe框架能够系统地评估多种主流量化技术和各种校准数据集，利用广泛接受的安全评估基准来确保量化后的LLMs的安全性。

Conclusion: 
我们进行了大量的实验，结果表明，Q-resafe成功地重新调整了量化LLMs的安全性，使其与量化前的安全性保持一致，即便是面对挑战性的评估场景也是如此。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20251</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>208. cs.LG-Argumentative Ensembling for Robust Recourse under Model Multiplicity</title><link>https://arxiv.org/pdf/2506.20260</link><description>Background: 
在机器学习中，同一预测任务可能会训练出多个性能相当的模型。模型多义性（Model Multiplicity, MM）指的是这些模型对相同的输入可能有不同的预测结果。当使用这些模型提供反事实解释（Counterfactual Explanations, CEs）时，CE的有效性可能会受到质疑，需要一种统一的方法来处理模型多义性下的CE问题。

Innovation: 
本文提出了一个新颖的基于论辩的集成方法（Argumentative Ensembling），以确保在模型多义性下CE的稳健性。该方法使用计算论辩来明确表示模型和CE之间的冲突，并使用论辩语义来解决冲突，从而获得最终解决策略。此外，该方法支持在模型多义性下指定模型偏好，实现进一步的自定义集成。通过理论和实验证明了该方法的有效性，能够满足多个期望属性。

Conclusion: 
论辩集成方法提供了一种处理模型多义性下CE问题的方案，确保CE的稳健性，并通过具体的偏好指定实现集成的定制化。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20260</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>209. cs.LG-使用有限示范实现超越专家性能：双重探索的高效模仿学习</title><link>https://arxiv.org/pdf/2506.20307</link><description>Background: 
模仿学习在强化学习中是一个核心问题，目标是学习一个策略来模仿专家的行为。然而，由于状态空间的复杂性，从有限的示范中准确学习专家策略往往具有挑战性。此外，为了达到超越专家的性能，还必须探索环境并收集数据。

Innovation: 
提出了一个新颖的模仿学习算法ILDE（双重探索模仿学习），该算法从两个方面实施探索：通过奖励高不确定性的状态-动作对进行乐观的策略优化，以及通过好奇心驱动探索偏离示范轨迹的状态，以可能获得超越专家的性能。

Conclusion: 
实验结果表明，ILDE在样本效率方面优于现有的最先进模仿学习算法，在Atari和MuJoCo任务中使用较少的示范也达到了超越专家的性能。此外，从理论上证明了ILDE是一种包含乐观探索的不确定性正则化策略优化方法，遗憾增长呈次线性增长。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20307</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>210. cs.LG-零样本编码归属：分布测试方法</title><link>https://arxiv.org/pdf/2506.20197</link><description>Background: 
随着越来越多的代码被大型语言模型（LLMs）生成，如何准确地归属这些代码成为了新的挑战。通过假设检验利用已有的技术与保证，研究者试图解决这一问题。然而，由于维度的增加使得直接解决问题变得不可实现，尤其是在仅给出来自LLM的样本时。因此，研究引入了一种结合样本和LLM密度估计的方法来绕过这一问题。开发了一种名为$textsf{Anubis}$的零样本归属工具，将归属问题转化为分布测试问题，从而在仅使用约2000个样本的情况下实现了高AUROC分数（≥0.9），以区别不同类型的LLM生成的代码，如DeepSeek-Coder、CodeGemma和Stable-Code。

Innovation: 
该研究引入了$textsf{Anubis}$，这是一种零样本归属工具，将归属问题转化为分布测试问题，利用假设检验，既能准确地识别代码生成模型，又可以基于少量样本实现高AUROC分数。这种方法提供了在不直接面对高维问题的情况下，通过对样本和语言模型的密度估计来归属代码的新途径。

Conclusion: 
实验表明，$textsf{Anubis}$在区分深度寻源者-编码器、CodeGemma和Stable-Code等不同类型的LLM生成的代码时表现优异，即使在仅有约2000个样本的情况下，也实现了高AUROC分数（≥0.9）。这验证了$textsf{Anubis}$的有效性和实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20197</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>211. cs.LG-基于局部和全局特征融合的GNN有向链路预测</title><link>https://arxiv.org/pdf/2506.20235</link><description>Background: 
链路预测是图分析中的一个经典问题，具有许多实际应用。对于有向图，最近开发的深度学习方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻域信息。文献中的现有方法大多关注节点相似性和邻域信息的处理，本文在此基础上进一步融合特征嵌入与社区信息，提高有向链路预测性能。

Innovation: 
本文提出了一种新的基于图神经网络（GNN）的框架，将特征嵌入与社区信息融合，理论上证明这种混合特征可以提高有向链路预测性能。同时，还提出了一种将输入图转换为有向线图的方法，使转化后的图中的节点在图卷积过程中能聚合更多信息。这种创新方法在基准数据集上表现良好，尤其是在训练数据量较少时，优于现有最先进的方法。

Conclusion: 
实验结果显示，本文提出的方法在大多数情况下都能优于最先进的方法，尤其是在当使用作为训练数据60%的连通链路时。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20235</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>212. cs.LG-通过反事实物理导向神经网络在偏微分方程中发现因果算子</title><link>https://arxiv.org/pdf/2506.20181</link><description>Background: 
传统的残差最小化或稀疏回归方法在发现偏微分方程中的因果结构方面存在局限性。本文通过结合物理导向神经网络和反事实扰动，开发了一个原理性的框架来发现偏微分方程的因果结构。该方法通过操作层级上的功能干预来量化因果操作的必要性，并通过因果敏感指标和结构偏差度量来评估神经代理中候选微分算子的影响。实验验证了在气候动力学、肿瘤扩散和海洋流等多个领域的合成和真实数据集上该框架的有效性，特别是在噪声、冗余和数据稀缺的情况下，该方法能够一致性地恢复支配算子，优于标准的物理导向神经网络和深度算子网络在结构保真度方面。

Innovation: 
本文提出了一种新的方法，该方法通过结合物理导向神经网络和反事实扰动来发现偏微分方程的因果结构。首先，通过功能干预和操作层量化因果操作的必要性。其次，引入了因果敏感指标和结构偏差度量来评估候选微分算子的影响。实验结果表明，该方法在噪声、冗余和数据稀缺的情况下仍能一致性地恢复支配算子，优于标准的方法。

Conclusion: 
本文展示了如何通过结构因果模型和变分残差分析，将因果偏微分方程发现作为一项可处理和可解释的推理任务。该方法具有广泛的应用前景，特别是在处理高维和复杂系统中的因果关系时。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20181</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>213. cs.LG-DuoGPT：通过激活感知剪枝实现的LLMs中的训练-free双稀疏</title><link>https://arxiv.org/pdf/2506.20194</link><description>Background: 
大规模语言模型（LLMs）虽然性能强大，但在部署时由于高内存和计算成本而难以实现。尽管剪枝可以降低这些需求，但大多数方法并未考虑到在运行时观察到的激活稀疏性。因此，需要一种新的方法来更好地利用这些稀疏性，从而提高模型的效率和性能。

Innovation: 
作者重新解释了激活稀疏性作为动态结构化权重稀疏性，并提出了DuoGPT，一种统一框架，通过结合无结构权重剪枝和激活稀疏性来构建双稀疏（spMspV）工作负载。此外，通过扩展Optimal Brain Compression（OBC）框架，引入了密集模型的输出残差作为校正项。最后，优化了解决方案以实现高效GPU执行，使得这种剪枝方法可以适用于十亿参数级别的LLMs

Conclusion: 
实验结果表明，DuoGPT在不降低速度增益的情况下（1.39倍），比最先进的结构化剪枝方法在LLaMA-2和LLaMA-3上提高了多达9.17%的准确性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20194</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>214. cs.LG-确定性离散LTI-DAE系统的因果发现</title><link>https://arxiv.org/pdf/2506.20169</link><description>Background: 
在数据驱动的因果网络重建中，辨别纯起因或驱动变量在确定的线性时不变动态系统中至关重要。Kathari和Tangirala于2022年提出了一种因果发现方法，该方法将因果发现问题转化为约束识别问题。该方法使用基于动态迭代主成分分析（DIPCA）的策略识别由高斯测量误差污染的动态系统中的约束，该方法适用于没有代数关系的动态系统。然而，许多实际系统存在反馈控制或伴随守恒定律，导致代数-动态（DAE）或混合因果系统，为了解决这种情况，作者提出了一个名为变量分区（PoV）的方法，专门用于LTI-DAE系统的因果发现，该方法能够同时处理线性代数和动态关系。

Innovation: 
PoV方法在CAUSAL Discovery方面具有创新性，因为它不仅能够处理纯粹的动态系统，即没有代数方程的系统，还能够将因果驱动因素识别为最小子集。PoV方法通过DIPCA首先确定代数关系的数量（$n_a$）和动力学关系的数量（$n_d$）以及约束矩阵，然后通过约束矩阵的条件数找到一个可接受的分区来确定子集。这种新的方法为LTI-DAE系统提供了一种全面且有效的因果驱动因素识别方法，拓展了现有的研究视野。

Conclusion: 
通过案例研究展示了提出的PoV方法的有效性，该方法在复杂系统中能够有效识别因果驱动因子，特别是在那些存在反馈控制或伴随守恒定律的系统中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20169</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>215. cs.LG-基于多模态地球观测数据的高分辨率Live Fuel Moisture Content (LFMC) 火灾风险地图</title><link>https://arxiv.org/pdf/2506.20132</link><description>Background: 
野火的强度和频率正在以惊人的速度增加。最近的人工智能技术进步和公开的卫星数据使得能够在全球范围内以高分辨率和低延迟监测关键的野火风险因素。Live Fuel Moisture Content (LFMC) 是一种关键的野火风险因素，对野火研究和操作响应都有重要价值。然而，基于地面的LFMC样本采集既耗时又成本高昂，导致更新频率低且稀疏。

Innovation: 
我们探索了使用预训练的高多模态地球观测模型生成大规模空间上完整的LFMC地图的方法。这种方法在之前的随机初始化模型基础上，显著提高了预测精度（RMSE降低了20%）。我们提供了一种自动化的生成管道，能够在短时间内生成美国全境的LFMC地图，并证明该方法在两个近期受野火影响的地区（灌溉区和帕里塞德镇）的有效性。

Conclusion: 
该研究展示了利用多模态地球观测数据生成高分辨率LFMC地图的有效性和潜在价值，为野火风险评估提供了新的技术工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20132</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>216. cs.LG-Affective Priming Score: 一种用于检测序列数据中混淆效应的数据驱动方法</title><link>https://arxiv.org/pdf/2506.20204</link><description>Background: 
情绪先兆体现了情绪计算中模糊性挑战的一个案例。尽管社区多从标签角度来解决这一问题，但在数据序列中识别受情绪先兆效应影响的数据点，尤其是对生理信号的影响，仍然缺乏探索。受情绪先兆影响的数据点可能会导致在学习模型中出现分类错误。因此，需要一种数据驱动的方法来检测受情绪先兆影响的数据点，以提高模型的鲁棒性并改善情感计算数据集的设计与收集。

Innovation: 
提出了Affective Priming Score (APS)，一种数据驱动的方法来检测受情绪先兆效应影响的数据点。APS给每个数据点打分，量化它受情绪先兆影响的程度。该方法在SEED和SEED-VII数据集上进行了验证，发现使用无情绪先兆的数据序列时，模型的错误分类率显著降低。

Conclusion: 
这项工作通过在数据层面识别和缓解情绪先兆效应，为更广泛的情绪计算模糊性问题作出了贡献。这种方法提升了模型的鲁棒性，并为情感计算数据集的设计和收集提供了宝贵见解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20204</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>217. cs.LG-LSH-DynED：基于LSH的动态集成框架用于演化的多类别不平衡分类</title><link>https://arxiv.org/pdf/2506.20041</link><description>Background: 
多类别不平衡数据流的分类在机器学习中是一个关键难题，尤其是在处理多类别数据时。虽然二分类不平衡数据流的分类已经得到了相当多的关注，但仅少数研究关注多类别不平衡数据流。有效地管理和调整动态不平衡比是一个关键挑战。现有文献回顾显示，这一领域缺乏有效的解决方案和方法。“多类别不平衡非平稳数据流的动态集成框架（LSH-DynED）”试图通过结合局部敏感哈希与随机超平面投影（LSH-RHP）到动态集成多样化（DynED）框架中来解决这些挑战。这是首次将LSH-RHP应用于非平稳数据流下的欠采样。实验结果表明，基于LSH的动态集成框架（LSH-DynED）在多类别不平衡非平稳数据流分类中表现优异，尤其是在大规模、高维、严重类别不平衡的场景下，展示了其在真实世界情况下的适应性和鲁棒性。

Innovation: 
提出了一种新颖的解决方案——基于LSH的动态集成框架（LSH-DynED），通过结合局部敏感哈希与随机超平面投影（LSH-RHP）到动态集成多样化（DynED）框架中，有效地管理和调整多类别不平衡数据流中的动态不平衡比。LSH-DynED首次将LSH-RHP应用于非平稳数据流下的欠采样，从而解决了数据流中的类别不平衡问题，为提高分类性能提供了平衡的训练集。通过23个真实世界和10个半合成数据集的全面实验，LSH-DynED在Kappa和mG-Mean有效性指标上优于其他方法，展示了其在处理多类别不平衡非平稳数据流问题上的优越性能。

Conclusion: 
基于LSH的动态集成框架（LSH-DynED）在多类别不平衡非平稳数据流分类中表现出良好的适应性和鲁棒性，尤其是在大规模、高维、严重类别不平衡的数据环境下，有效提高了分类性能。通过实验验证，LSH-DynED在Kappa和mG-Mean有效性指标上表现突出，为解决多类别不平衡数据流的分类问题提供了一种有效的解决方案。此外，研究还为未来的工作提供了指导，并将其实现提供在GitHub上以保证结果的可重现性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20041</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>218. cs.LG-PdM方法综述：基于分类和回归的预测性维护诊断分析</title><link>https://arxiv.org/pdf/2506.20090</link><description>Background: 
预测性维护（PdM）已成为现代工业实践中的关键要素。通过减少意外停机时间和优化资产生命周期管理，PdM 能够提高操作可靠性和成本管理。机器学习和深度学习使得对设备故障和剩余使用寿命（RUL）的预测更加精确。尽管许多研究集中在PdM上，但尚未有一篇专门针对回归和分类方法之间比较的研究。在这篇综述中，作者评估了多种PdM方法，并重点探讨了预测性维护中分类和回归方法的比较使用。分类方法通常预测故障概率，而回归方法则提供RUL估计。通过对近期文献的全面分析，本综述强调了关键进展、挑战如数据不平衡和高维特征空间，以及新兴趋势，包括混合方法和人工智能辅助的预测性维护系统。该综述旨在使研究人员和实践者了解各种PdM方法的优势和劣势，并帮助确定未来的研究方向，以建设更稳健、针对性更强的维护系统。未来的研究可能包括系统性地审查实用方面的问题，例如公共数据集、基准平台和开源工具，以支持PdM研究的发展.

Innovation: 
本综述首次全面地对比了回归和分类方法在预测性维护中的应用，强调了混合方法和AI辅助的预测性维护系统的新兴趋势。通过对不同方法的挑战进行详细分析，为未来的PdM研究提供了有价值的指导和创新视角。

Conclusion: 
本综述旨在提供给研究人员和实践者有关各种PdM方法的优势和劣势的全面了解，并帮助确定未来研究的方向，以建设更稳健、针对性更强的维护系统。未来的研究应进一步探讨并提供实用的公共数据集、基准平台和开源工具，以支持PdM研究的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20090</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>219. cs.LG-MEL: 多级集成学习在资源受限环境中的应用</title><link>https://arxiv.org/pdf/2506.20094</link><description>Background: 
边缘环境由于资源和电力限制且容易发生故障，传统的云故障转移或压缩备份等容错方法会牺牲延迟或准确性，适用于关键边缘推理服务的效果有限。因此，需要一个新的框架来解决边缘环境的独特挑战，确保在资源受限且易故障的环境中，能够具有良好的准确性和容错性。AI推理正在变得越来越常见，特别是在需要低延迟的服务中。

Innovation: 
我们提出了一种新的框架——多级集成学习(Multi-Level Ensemble Learning, MEL)，该框架能够训练多种轻量级备份模型，这些模型可以在多台服务器可用时协作改进彼此，发生故障时单独运行但仍保持良好的性能。具体而言，MEL将该方法定义为一个多目标优化问题，其损失函数鼓励个体模型之间的多样性，促进相互改进实例表示，同时确保每个模型都能保持良好的单一性能。跨视觉、语言和音频数据集的实际评估表明，MEL提供与原始架构相当的性能，同时提供了故障容错和广泛的边缘平台部署灵活性。最值得注意的是，当我们使用MEL训练时，大小仅占原模型40%的集成模型，即使在故障情况下也能保持95.6%的集成准确性。

Conclusion: 
MEL不仅维持了与原始架构相当的性能，还提供了故障耐受性和广泛的边缘部署灵活性。实验结果显示，即使使用MEL训练的40%的集成模型，在故障情况下也能保持95.6%的集成准确性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20094</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>220. cs.LG-使用二进制优化和图学习的多层次代理操作中多样化行动计划的自动化生成</title><link>https://arxiv.org/pdf/2506.20031</link><description>Background: 
灾害响应、搜索与救援以及军事任务往往涉及多个代理，需要自动化流程来支持行动计划（COA）的规划。环境变化（如雨雪、阻塞等）会影响预期的COA性能，因此多样化且任务分配在代理间不同的COA池是必要的。代理能力的差异，包括人类团队和自主系统，为规划过程带来了实际机会和计算挑战。文章探讨了在代理任务兼容性软变化情况下，生成多样化COA池的理论框架和计算框架，从而提高多个代理操作的效率和适应性。

Innovation: 
本文提出了一种新的理论框架和计算框架，用于生成具备多样性的COA池，特别针对有软变化的代理任务兼容性情况。通过使用基因算法对COA进行集中式多机器人任务分配，最大化了COA池内的多样性以及各代理任务映射的整体兼容性。同时，通过图神经网络使用策略梯度方法在每个COA中为每个代理确定任务顺序，最大化适应任务特性的完成率。实验结果表明，与随机游走基线相比，该方法在模拟环境中的性能大幅提升，且任务序列优化度较低，计算时间约为50分钟来计划20个COA以应对5个代理/100个任务的操作。

Conclusion: 
该研究提出的方法通过基因算法和图神经网络结合的方式，不仅提高了COA的多样性和任务分配的兼容性，还为代理任务的单个序列化提供了优化排序。实验验证了该框架的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20031</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>221. cs.LG-通过大型语言模型进行开放式指令重标记学习指令遵循策略</title><link>https://arxiv.org/pdf/2506.20061</link><description>Background: 
在强化学习中开发有效的指令遵循策略仍然具有挑战性，主要依赖于大量的手动标注指令数据集，并且从稀疏奖励中学习也颇具难度。本文背景在于如何提升效率，减少对人力标注的依赖，以更好地适应复杂多样的任务需求。

Innovation: 
本文提出了一种新颖的方法，利用大型语言模型（LLMs）自动从之前收集的代理轨迹中生成开放式指令的回顾性重标记。通过这种方法识别并重新标注代理隐含完成的子任务，从而丰富代理的训练数据，显著减少对人工注释的依赖，进而提高样本效率和整体策略表现。

Conclusion: 
在Craftax环境中的实验表明，本方法在样本效率、指令覆盖范围和整体策略性能方面均优于当前最先进的基线方法，证明了利用LLM引导的开放式指令重标记对于增强指令遵循强化学习的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20061</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>222. cs.LG-使用自我蒸馏方法量化GNN的不确定性</title><link>https://arxiv.org/pdf/2506.20046</link><description>Background: 
图神经网络（GNNs）在医疗领域展现了显著的性能，但量化GNNs的预测不确定性仍是一个挑战，这是临床环境中模型可信度的重要方面。虽然贝叶斯方法和集成方法可以用于量化不确定性，但它们计算复杂且昂贵。集成方法中的不一致度量无法捕捉集成网络中模型的多样性。

Innovation: 
本文提出了一种基于知识蒸馏的新颖方法来更高效和精确地量化GNNs的不确定性。具体地，通过使用相同的网络作为教师和学生模型进行自我蒸馏，避免了训练多个独立网络的需要。为了确保自我蒸馏的影响，我们开发了一个能够捕捉网络多样性的不确定性度量，通过为每个GNN分类器分配不同的权重来实现。实验证明了该方法在精度、性能和识别异常数据分布的能力方面的有效性。

Conclusion: 
实验结果表明，所提出的方法能够有效捕捉模型的预测不确定性，同时性能与MC Dropout和集成方法相近。代码已公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20046</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>223. cs.LG-跨层离散概念发现以解释语言模型</title><link>https://arxiv.org/pdf/2506.20040</link><description>Background: 
在 transformer 层次上揭开涌现概念的关键挑战在于，残留流线性地混合和复制信息，这掩盖了大型语言模型中特征演化的路径。当前的研究主要集中在单一层面的神经表示上，未能观察到跨层的叠加效果及其带来的冗余。这些表示通常是直接分析其激活模式或将其传递给探针分类器，映射到一组预定义的概念上。

Innovation: 
提出了一种名为 CLVQVAE 的框架，通过矢量化量化将表示映射到跨层，并在过程中将重复的残留流特征合并为紧凑且可解释的概念向量。该方法结合了采样温度调整的矢量化量化和 EMA 代码表更新，提供了在保持代码表多样性的前提下对离散潜在空间的受控探索。此外，还通过带有方向相似性的缩放球形 k-means++ 初始化代码表进行增强，更好地与词嵌入空间中的语义结构对齐。

Conclusion: 
CLVQVAE 框架能够揭示大型语言模型中跨层的离散概念，并提供了一种受控探索离散潜在空间的方法，同时保持代码表的多样性。通过合并有效的技术，该方法能够为语言模型提供更深入的理解，解决传统方法的局限性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20040</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>224. cs.LG-通过迭代随机计算实现通用预训练</title><link>https://arxiv.org/pdf/2506.20057</link><description>Background: 
研究者们探索了使用随机生成的数据对模型进行预训练的方法。理论研究表明，序列模型可以被训练来近似地实现Solomonoff归纳，因此可以利用这一研究进展说明为何需要使用随机生成数据进行预训练。

Innovation: 
论文提出了一个理论框架，基于算法复杂度的角度来阐释为何随机生成数据对预训练模型有效。实证研究显示，通过随机生成的数据进行预训练，可以在未见真实数据的情况下实现模型的预训练。这种方法扩展了前人的研究，不仅适用于仿生数据，也适用于真实世界数据，通过细调预训练的模型，可以更快地收敛并且有更好的泛化性能。论文进一步验证了此类模型在不同数据集上具备零样本上下文学习的能力，并且性能随模型规模的增加而提高。

Conclusion: 
通过迭代随机计算实现的预训练方法，不仅可以提高模型性能，增强其泛化能力和加快收敛速度，还能偶尔展示零样本上下文学习能力，并且这一表现随模型规模增加而有所改善。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20057</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>225. cs.LG-边缘设备上的可验证未学习</title><link>https://arxiv.org/pdf/2506.20037</link><description>Background: 
当前，机器学习提供者通常将全球模型分发到边缘设备，随后这些设备使用本地数据进行个性化设置。当遇到版权问题、偏见或监管要求等情况时，可能需要在所有边缘设备上删除某些数据样本以进行可验证的未学习操作。确保边缘设备正确执行这种未学习操作对于维护数据的完整性和隐私都至关重要。该项研究正是在此背景下进行的，旨在为边缘设备上的可验证未学习提供一个框架，这个框架利用零知识证明，特别是zk-SNARKs技术，以不泄露隐私的方式验证数据未学习过程的有效性。

Innovation: 
该研究引入了一个基于零知识证明（zk-SNARKs）的验证框架，该框架能够确保在不影响隐私的前提下验证边缘设备上个性化模型的未学习过程。研究开发了专门的算法，确保这些算法与高效的zk-SNARK证明生成兼容，能够在计算能力和存储受限的边缘环境中实现最小的计算和内存开销。此外，该方法还保留了边缘设备上的个性化改进，即使进行了未学习操作，也能维持模型性能。

Conclusion: 
研究结果表明，这一验证框架在不显著影响个性化增强效果的前提下实现了可验证的未学习，验证了该框架在实践中的可行性和有效性，确保了隐私保护和有效的边缘设备机器未学习操作。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20037</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>226. cs.LG-TRACED: 过度感知的后悔近似与共学习性在环境设计中的应用</title><link>https://arxiv.org/pdf/2506.19997</link><description>Background: 
在未见过的环境中对深度强化学习代理进行泛化的任务仍然是一个重要的挑战。一种有希望的解决方案是无监督环境设计（UED），这是一种协同演化的框架，在此框架中，一个教师会生成具有高学习潜力的任务，而一个学生则从这个进化的课程中学习稳健的策略。现有的UED方法通常通过将最优性能与当前性能之间的差距，即后悔值来近似评价学习潜力，并仅仅依靠值函数损失进行近似。本文试图通过引入过渡预测误差作为一个额外的项来改进后悔值的近似方法，并通过提出一个轻量级的共学习性度量来捕捉一个任务的训练如何影响其他任务的性能，来构建一种新的过渡感知后悔近似与共学习性方法，即TRACED，以增强UED中的环境设计策略。实验表明，TRACED能显著提高在多个基准上的零样本泛化能力，且所需的环境交互次数比强baseline少至2倍。消融研究进一步证实了过渡预测误差和共学习性能对环境设计的有效性。这些结果表明明确的后悔近似和任务关系的显式建模有助于UED中的样本高效课程设计。

Innovation: 
1. 引入过渡预测误差作为后悔近似的一个额外项。n2. 提出共学习性作为轻量级的度量来捕捉一个任务的训练对其他任务性能的影响。n3. 基于以上两项措施提出的过渡感知后悔近似与共学习性方法TRACED，有效改进了UED中的环境设计策略，实现了增强的环境泛化和减少环境交互次数的目标。

Conclusion: 
TRACED通过改进后悔近似的计算方法和引入共学习性建模，提高了UED设计环境的能力，实现了更高效的环境泛化并减少了环境交互次数，展示了精炼的后悔近似与任务关系的显式模型可以用于UED中的样本来高效课程设计。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19997</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>227. cs.LG-DIM-SUM: 动态插补用于智能公用事业管理</title><link>https://arxiv.org/pdf/2506.20023</link><description>Background: 
传统的时序插补模型通常使用完整数据集并通过人工遮罩模式来模拟缺失值进行开发。然而，在实际的基础设施监测中，实际遇到的缺失数据量通常很大，且遵循复杂且异质的模式。因此，需要一种新的预处理框架，能够连接人工遮罩训练数据和真实的缺失数据模式，以提高插补模型的鲁棒性与实际适用性。DIM-SUM框架通过结合模式聚类和自适应遮罩策略来处理数据中实际观察到的多样化的缺失模式，从而适应实际应用场景。

Innovation: 
DIM-SUM框架引入了一种新的预处理框架，用于训练可以在不同类型和复杂模式的缺失数据上表现良好的插补模型。该框架通过聚类算法识别和分组缺失模式，以及自适应遮罩策略与理论学习保证相结合，使得模型在处理复杂数据缺失模式时具有更好的表现。DIM-SUM在来自加利福尼亚水务区域、电力数据集以及基准数据集的超过20亿条读数的实验中，展示了比传统方法更高的准确性和更少的处理时间和训练数据量。相比大规模预训练模型，DIM-SUM不仅保持了相似的精度，还具有显著更短的推理时间。

Conclusion: 
DIM-SUM在多个时间序列数据集上的实验结果证明了该方法在处理实际复杂缺失模式下的优越性能，显著降低了训练时间和提高插补准确性。该框架提出了一个将理论学习保证与实践数据处理能力相结合的新思路，能够为智能公用事业管理等领域提供更有效的数据预处理工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20023</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>228. cs.LG-Neuromorphic Wireless Split Computing with Resonate-and-Fire Neurons</title><link>https://arxiv.org/pdf/2506.20015</link><description>Background: 
神经形态计算为实时时间序列处理提供了相对于传统深度学习加速器更节能的替代方案。然而，许多边缘应用，如无线传感和音频识别，产生的流信号具有丰富的频谱特征，这些特征无法被传统的泄漏积分-放电(LIF)神经元有效捕捉。本论文研究了一种无线分割计算架构，利用具有振荡动态的振荡-放电(RF)神经元直接处理时域信号，从而消除昂贵的频谱预处理需求。通过在可调频率下振荡，RF神经元提取了时间局部化的频谱特征，同时保持低放电活动。这种时域稀疏性在计算和传输能量上都带来了显著的节省。假设使用基于OFDM的模拟无线接口进行尖峰传输，论文提出了一个完整的系统设计，并在音频分类和调制分类任务中评估了其性能。实验结果表明，提出的RF-SNN架构在推理和通信过程中显著降低了尖峰率和总能耗，且性能与传统LIF-SNN和ANN相当。

Innovation: 
本研究提出了一种无线分割计算架构，利用振荡-放电(RF)神经元直接处理时域信号，无需进行频谱预处理，通过在可调频率下的振荡，RF神经元能够提取时间局部化的频谱特征，保持低放电活动，从而在计算和传输能量上带来显著节省。提出的设计采用了基于OFDM的模拟无线接口进行尖峰传输，实现了高能效的神经形态计算。通过音频分类和调制分类任务评估了该架构的性能，表明其在性能差异不明显的情况下显著减少了能耗。

Conclusion: 
本研究展示了一种基于RF神经元的神经形态无线分割计算架构，该架构在保留与传统LIF-SNN和ANN相当的准确率的同时，显著降低了能量消耗，提出了一个完整的设计方案并在实际任务中进行了验证。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20015</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>229. cs.LG-探究分层细化量子联邦学习的新见解</title><link>https://arxiv.org/pdf/2506.20016</link><description>Background: 
量子联邦学习（QFL）面临着客户端异质性带来的显著挑战，这些挑战限制了其性能。标准的聚合方法在高度异质环境中常常失效，导致过拟合和其他优化问题。因此，需要一种新的解决方案来提高QFL的适应性和鲁棒性，特别是在需要高度个性化和鲁棒优化的应用场景中，如基因表达分析和癌症检测等领域。

Innovation: 
本文提出了一种利用深度展开的新方法，使客户端能够自主优化超参数（如学习率和正则化因子）以适应特定的训练行为。这种方法通过动态调整和自适应优化步骤来减轻过拟合和提高优化的鲁棒性，尤其是在标准方法失败的环境中。已经通过在IBM量子硬件和Qiskit Aer仿真器上进行实时训练，结果表明这种方法在准确性和性能上显著优于传统方法。特别是在关键应用领域，如基因表达分析和癌症检测中，提出了自适应微调方法，提高了诊断精度和量子系统中的预测建模能力。

Conclusion: 
深度展开框架中固有的收敛意识和可学习优化步骤确保了该方法的有效性和鲁棒性。这种方法解决了传统QFL的核心局限性，简化了其在任何复杂挑战（如医疗保健和基因组研究）中的应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20016</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>230. cs.LG-明晰滚动扩散模型在概率天气预报中的应用</title><link>https://arxiv.org/pdf/2506.20024</link><description>Background: 
扩散模型是进行概率预测的强大工具，但大多在高维混沌系统中的应用只预测未来的一张快照，这种方法难以建模复杂的时间依赖性，也无法明确考虑到系统固有的不确定性渐增特性。为了解决这个问题，虽然提出了一些滚动扩散框架将增加的噪声应用于更长的预测时间，但其与最先进的高保真扩散技术的整合仍然是一个显著挑战。

Innovation: 
该研究通过引入明晰滚动扩散模型(ERDM)，解决了滚动预测结构与原理性和高效设计的明晰扩散模型(EDM)的整合问题。主要创新点包括：1)一种新的损失加权方案，使模型容量集中在从确定性到随机性的过渡时期；2)使用预训练的EDM进行初始窗口的高效初始化策略；3)一种针对逐步去噪的定制混合序列架构，以增强时空特征提取的鲁棒性。

Conclusion: 
ERDM在2D纳维-斯托克斯模拟和ERA5全球天气预报中的表现优于关键的基于扩散的基线模型，包括条件自回归EDM。ERDM提供了一个灵活且强大的通用框架，适用于扩散序列生成问题，特别是在预测不确定性的逐步增长方面。源代码可以在指定链接找到。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20024</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>231. cs.LG-HERCULES: 基于嵌入的层次递归聚类使用大型语言模型进行高效总结</title><link>https://arxiv.org/pdf/2506.19992</link><description>Background: 
随着各种模态下的复杂数据集的爆炸性增长，需要先进的分析工具来不仅有效分组数据，还能提供人类可理解的关于发现结构的洞见。HERCULES 是一种专为处理不同数据类型的层次 k-均值聚类的新算法和 Python 软件包，包括文本、图像和数值数据（每种模式独立运行）。HERCULES 通过从单个数据点递归应用 k-均值聚类构建聚类层次结构。关键创新在于该算法深入整合了大语言模型（LLMs），用于为层次结构的每一级生成语义丰富的标题和描述，大大增强了可解释性。该算法支持两种主要表示模式：直接模式，基于原始数据嵌入或缩放数值特征进行聚类；描述模式，基于从 LLM 生成的摘要提取的嵌入聚类。用户可以提供‘主题种子’来引导 LLM 生成的摘要向特定主题靠拢。HERCULES 的交互式可视化工具促进对聚类结果的深入分析和理解。HERCULES 通过展示其能力，并讨论其从复杂数据集中提取有意义的层次化知识的潜力，展示其在实际应用中的强大功能和适用性。

Innovation: 
HERCULES 的关键创新是其深度整合大语言模型 (LLMs) 以生成层次结构的每一级的语义丰富标题和描述，大大增强了聚类结果的可解释性。此外，算法支持两种主要表示模式，允许用户根据其偏好进行聚类，提高灵活性。HERCULES 还提供了一个交互式可视化工具，帮助用户深入分析和理解聚类结果。

Conclusion: 
HERCULES 通过展示其能力并与复杂的多模态数据集进行交互，证明了它在有效分组数据和提供人类可理解的洞见方面的优势。该算法及其 Python 包为处理广泛的多模态数据集提供了一个强大的工具，并展示了在实际应用中提取有意义、层次化知识的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19992</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>232. cs.CV-边界框水印：针对目标检测模型提取攻击的防御</title><link>https://arxiv.org/pdf/2411.13047</link><description>Background: 
云中部署的深度神经网络(DNNs)常常允许用户通过API查询模型。然而，这些API会暴露模型，使其容易受到模型提取攻击（MEAs）的攻击。在这些攻击中，攻击者试图通过滥用API响应来复制目标模型。回声门控基于DNN水印是防御MEAs的一种有前景的方法，其中防御方通过API响应将回声门控注入到提取的模型中，用于作为模型的水印。如果可疑模型含有水印（即回声门控），则该模型会被验证为提取模型。这项工作主要关注目标检测（OD）模型。现有的OD模型基于回声门控的攻击方法不适用于MEAs的防御，这主要是因为在现实威胁模型中的应用场景不可行。因此，需要一种新的方法，该方法通过在API响应中悄悄修改检测到的对象边界框（BBs）来在提取模型中插入回声门控，同时保持目标检测能力。这项工作在三种不同数据集上的实验结果表明，提出的方案能够以100%的准确性识别各种实验场景中的提取模型。

Innovation: 
提出了边界框水印方法，该方法通过在API响应中悄悄修改检测到的对象边界框来在目标检测模型中插入回声门控，从而实现对模型提取攻击的有效防御，且能保持目标检测功能不受影响。这种方法适用于实际威胁模型中的目标检测模型，能够以100%的准确性识别提取模型。

Conclusion: 
提出的边界框水印方法能够成功识别所有实验场景中的提取模型，验证了该方法在目标检测模型提取攻击防御中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.13047</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>233. cs.LG-按需调节：最后一层重训练中的最优损失加权</title><link>https://arxiv.org/pdf/2506.20025</link><description>Background: 
当机器学习模型在大规模判别任务中展现出更强的能力时，它们在处理由训练数据引入的偏见方面的能力受到了越来越多的关注。前人的研究表明，在参数化方面存在两种极端情况，一种是参数不足的“总体”设置，在这种情况下通过权重优化损失最为有效；另一种是过参数化的“可分离”设置，在这种情况下，权重优化损失无法确保各类别的性能均等。本文研究了最后一层重训练（LLR）的领域，在该领域中未见过的有限训练数据常常是不可分离的，且模型的大小介于上述两种极端之间。作者指出，在这种情况下，损失权重依然有效，但这些权重必须考虑到模型的相对过参数化程度以确保效果。

Innovation: 
本文探讨了最后一层重训练的瓶颈，即在模型大小介于参数不足的“总体”设置和过参数化的“可分离”设置之间时，损失权重依然可以生效但需要考虑到模型的相对过参数化程度。

Conclusion: 
本文通过理论和实践证明，在最后一层重训练的领域中，损失权重依然有效，但这些权重必须考虑模型的相对过参数化程度以确保各类别的性能均衡。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20025</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>234. cs.LG-Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture</title><link>https://arxiv.org/pdf/2506.19935</link><description>Background: 
现有的大型语言模型（LLMs）主要使用自回归（AR）方法，而掩码扩散模型（MDMs）正在成为可行的替代方案。自回归模型通常是解码器-only结构，而掩码扩散模型通常是编码器-only结构。这种同时改变建模范式和架构的做法使得直接比较不公平。该研究试图在同一解码器-only架构下评估掩码扩散模型，以公平地比较掩码扩散模型（作为一种任意顺序自回归，或AO-AR）和标准的自回归方法。研究发现，标准的AO-AR目标可能需要改进，因为它涉及到大量的标记排列，其中许多排列比语言的固有左到右结构更不信息丰富。此外，研究还探讨了掩码扩散模型中的架构影响（解码器-only vs. 编码器-only）.

Innovation: 
研究采用了解码器-only框架来评估掩码扩散模型，从而在公平的比较中将其与标准自回归方法进行对比。此外，研究发现解码器-only的掩码扩散模型相比于编码器-only的模型，虽然模型的空间更大，但通过温度退火可以在生成速度上取得显著提升，同时保持类似的困惑度。这项工作拆分了核心范式差异和架构影响之间的关系，为未来的模型设计提供了洞见。

Conclusion: 
通过在解码器-only框架下评估掩码扩散模型，研究提出了一种新的视角来更公平地比较不同的建模方法，并且揭示了解码器-only掩码扩散模型在速度和效率上的潜力。结果强调了从多个方面（包括范式和架构）优化模型设计的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19935</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>235. cs.LG-Generalized Additive模型中最重要特征可能是特征组</title><link>https://arxiv.org/pdf/2506.19937</link><description>Background: 
在可解释机器学习中，分析特征的重要性已成为普遍做法，但有时会忽略或者无意中排除一组相关特征的联合信号。这种忽略可能会错过一个重要洞察：在许多情况下，最重要的预测因子不是单一特征，而是特征组合的综合效应。对于包含自然特征分组的数据集（包括多模态数据集），这一点尤其具有挑战性。已有研究虽然注意到了特征组合的重要性，但往往缺乏一种既高效又不需要重新训练模型的方法来确定特征组的重要性，同时还能处理高维数据并允许后验定义特征组和组的重叠。因此，本研究旨在填补这一空白，提出一种新的方法来确定特征组合在广义加性模型（GAM）中的重要性，并展示了其在行为模型、多模态神经科学数据集和髋关节置换术后健康的社会决定因素中的应用。

Innovation: 
提出了一种新的方法来确定特征组合在广义加性模型（GAM）中的重要性，这种方法效率高，无需重新训练模型，允许后定义特征组，支持组的重叠，并在高维数据中依然有意义。此外，该方法的定义类似于统计学中的解释变异度。该研究还通过三个合成实验展示了特征组合的重要性在不同数据集中的表现，并通过两个实际案例研究验证了这种方法的有效性，在多模态神经科学数据集和髋关节置换术后健康的社会决定因素中，特征组的重要性更能够提供一种更准确、全面的医学问题视图，相比单一特征分析更具优势。

Conclusion: 
特征组合的重要性分析提供了一种更准确、更全面的医学问题视图，相比单一特征分析具有更大的优势。该方法不仅适用于广义加性模型，还能够应用于高维数据集和各种类型的特征组合，对特征组的重要性评估可能有助于改进机器学习模型的解释性和预测准确性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19937</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>236. cs.LG-AIGC提供任务中生成语义通信中的蒸馏赋能知识对齐</title><link>https://arxiv.org/pdf/2506.19893</link><description>Background: 
由于AI生成内容(AIGC)的数量激增，从云传输到边缘设备和移动用户的过程产生了大量的网络流量。生成语义通信(GSC)提供了一种解决方案，通过传输高度紧凑的信息（如提示文本和潜在表示），而不是高维的AIGC数据。然而，GSC依赖于云生成 AI (GAI) 和边缘设备/用户知识的一致性，以及无线传输知识和实际信道知识的一致性，这仍然是一个挑战。因此，本文提出了DeKA-g算法，以提高生成语义通信的性能。DeKA-g算法的核心思想是将云GAI的生成知识提炼成低秩矩阵，以适应多样的无线信道条件，并通过元词辅助知识蒸馏（MAKD）和变量速率分组信噪比适应（VGSA）两种新型方法实现这一目标。

Innovation: 
DeKA-g算法提出了两种新的方法：元词辅助知识蒸馏（MAKD）和变量速率分组信噪比适应（VGSA）。MAKD使用优化的元词来提高知识蒸馏的效率，而VGSA使适应不同的压缩率和信噪比范围更加高效。与基线相比，DeKA-g算法在边缘生成的图像与云生成的图像之间的对齐上提高了44%，在压缩率适应上提高了116%，在低信噪比条件下的性能提升了28%。

Conclusion: 
DeKA-g算法通过解决了GSC系统中知识对齐的挑战，在生成语义通信中有效地对齐了边缘生成的图像与云生成的图像，同时提高了在不同压缩率和信噪比条件下的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19893</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>237. cs.LG-使用XAI解释电力价格预测的深度神经网络模型</title><link>https://arxiv.org/pdf/2506.19894</link><description>Background: 
电力市场非常复杂，涉及众多互动和复杂依赖关系，使得理解市场内部运作和价格动因极具挑战性。虽然已经开发了计量经济方法，但白盒模型在预测能力上不如深度神经网络（DNN）强大。因此，需要利用DNN进行价格预测，并使用XAI方法来理解市场中驱动价格的因素。

Innovation: 
本文使用深度神经网络模型预测电力价格，结合使用可解释性方法（如SHAP和梯度）以及可视化技术（如热力图）来分析不同特征的行为和贡献。提出了SSHAP值和SSHAP线的新概念，以增强高维表格模型的复杂表示。

Conclusion: 
通过引入这些可解释的新概念，本文增加了对不同电力市场运作机制的理解，并提供了一种深入理解复杂电力市场的有效方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19894</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>238. cs.LG-基于层间最近邻的不确定性量化框架</title><link>https://arxiv.org/pdf/2506.19895</link><description>Background: 
神经网络在难以检测模式或构建逻辑模型的问题上具有高准确性。然而，在医疗诊断或自动驾驶等高风险领域，这些算法有时会给出错误的解决方案，这会引发问题。识别和缓解这些错误的一种方法是测量神经网络决策的不确定性。本文提出了一种新的后验框架，基于查询的激活向量在每层中找到相似的训练案例来衡量决策的不确定性。通过对这些案例的分析，提出了两种新的度量标准：决策变化和层不确定性，它们捕捉了各个层中最邻近类分布的变化。该方法在CIFAR-10和MNIST两个数据集上的分类模型上进行了评估。结果表明，这些度量方法增强了不确定性估计，特别是在具有挑战性的分类任务中优于基于softmax的置信度方法。

Innovation: 
提出了一种基于层间最近邻的新后验框架，用于衡量神经网络决策的不确定性。通过确定查询的激活向量在每层中具有相似激活向量的训练案例，提出两种新的度量标准：决策变化和层不确定性，这些标准捕捉了各层中最邻近类分布的变化。该方法在分类模型中优于softmax置信度方法，特别是在具有挑战性的分类任务中表现更好。

Conclusion: 
提出的框架通过引入两种新的不确定性度量标准——决策变化和层不确定性，改进了神经网络决策的不确定性估计，尤其是在具有挑战性的分类任务中，这些度量方法优于基于softmax的置信度方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19895</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>239. cs.LG-STIMULUS: 实现多目标学习中快速收敛和低样本复杂度</title><link>https://arxiv.org/pdf/2506.19883</link><description>Background: 
近年来，多目标优化（MOO）在机器学习、运筹学和工程领域获得了广泛关注。然而，MOO算法的设计仍处于初期阶段，很多现有的MOO方法在收敛速度和样本复杂度方面表现不佳。

Innovation: 
为了应对这一挑战，本文提出了一种名为STIMULUS的新算法，该算法通过引入一种改进的递归框架来增强随机梯度估计，从而提高收敛性能并降低样本复杂度。此外，引入了带有动量项的STIMULUS-M，以进一步加快收敛速度。该算法在非凸设置下的收敛率为$O(1/T)$，在强凸设置下的收敛率为$O(text{exp}^{-text{μ}T})$，同时达到了非凸设置下$O text(n+text{√}ntext{ε}^{-1})$和强凸设置下$O text(n+ text{√}n text{ln} (text{μ}/text{ε}))$的最优样本复杂度。为减轻STIMULUS和STIMULUS-M在周期性全梯度评估的要求，进一步提出了带有自适应批量处理的增强版本STIMULUS+/STIMULUS-M+.

Conclusion: 
本文提出的方法通过改进的递归框架和动量技术有效地提高了多目标学习的收敛速度和低样本复杂度，并为相关问题提供了理论分析。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19883</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>240. cs.LG-因果感知智能QoE优化在具有自适应关键帧提取的VR交互中</title><link>https://arxiv.org/pdf/2506.19890</link><description>Background: 
在多用户虚拟现实(VR)交互中，体验质量(QoE)的优化需要在超低延迟、高保真运动同步和资源均衡分配之间取得精细平衡。现有方法在带宽分配、CPU频率和用户感知之间的因果关系方面常常存在不足，这限制了QoE的提升。因此，需要一种能够综合考虑这些因素并实现QoE最优的智能框架。

Innovation: 
本文提出了一种智能框架，通过结合自适应关键帧提取与因果感知的强化学习(RL)，以最大化QoE。具体来说，框架首先使用Weber-Fechner定律，提出了一个新的QoE度量标准，结合了感知敏感性、注意力驱动的优先级和运动重建精度。接着将QoE优化问题建模为混合整数规划(MIP)问题，并引入了一种新的部分状态因果深度确定性策略梯度(PS-CDDPG)算法，该算法结合了因果推理和Deep Deterministic Policy Gradient (DDPG)方法，以改善训练效率并实现更优的性能。

Conclusion: 
实验结果表明，该框架能够显著减少互动延迟，提升QoE，并保持公平性，相较于基准方法具有更优异的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19890</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>241. cs.LG-强化学习与传统深度学习方法在滚动轴承故障诊断中的比较分析</title><link>https://arxiv.org/pdf/2506.19929</link><description>Background: 
滚动轴承在旋转机械中的故障可能导致显著的运营中断和维护成本。现代的轴承故障诊断方法主要依赖振动分析和机器学习技术，但这些方法通常需要大量的标记数据，并且在动态环境中适应性较差。

Innovation: 
本研究探索了使用强化学习（RL），特别是深度Q网络（DQN），进行轴承故障分类任务的可能性，以增强轴承故障诊断的准确性和适应性。研究结果表明，尽管在受控条件下开发的RL模型在性能上可以与传统的监督学习模型相媲美，但通过优化奖励结构，它们在适应性方面表现出色。然而，必须进一步改进其计算需求以提高效果。

Conclusion: 
这些发现表明，强化学习有望补充传统方法，为适应性诊断框架铺平道路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19929</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>242. cs.CV-TCDiff++: 基于轨迹可控扩散模型的和谐音乐驱动群体舞蹈生成</title><link>https://arxiv.org/pdf/2506.18671</link><description>Background: 
群体舞蹈生成吸引了广泛的关注，特别是在群体编舞创作中。然而，现有的方法在生成群体舞蹈时仍面临三个主要问题：多舞者碰撞、单舞者脚部滑行以及长时间群体舞蹈生成中动作的突然切换。这些缺陷限制了群体舞蹈生成的质量和连贯性，影响了其在工业应用中的效果。

Innovation: 
本文提出了一种基于轨迹可控扩散模型的音乐驱动群体舞蹈生成框架TCDiff++。具体而言，为了缓解多舞者碰撞问题，该框架采用舞者定位嵌入来更好地保持舞者间的相对位置。为了防止单舞者脚部滑行，引入了换位模式嵌入并设计足部适配器来优化原始动作。为了解决长时群体舞蹈中的不连贯移动问题，提出了一种长时群体扩散采样策略，通过将位置信息注入噪声输入，减少了位置突变。此外，还引入了序列解码器层以增强模型对长期序列的选择性处理能力。这些改进使TCDiff++在多项实验中表现出色，特别是在长持续时间场景中，实现了高质量和连贯的群体舞蹈生成。

Conclusion: 
TCDiff++框架在长期场景中达到了最先进的表现，确保了群体舞蹈的高质量和连贯性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18671</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>243. cs.LG-正交软剪枝以实现高效的类别卸载</title><link>https://arxiv.org/pdf/2506.19891</link><description>Background: 
机器卸载旨在从预训练的神经网络中选择性地移除特定类别的知识，以满足GDPR等隐私法规。现有方法通常面临卸载速度与保留预测准确性之间的权衡，这常常导致计算开销高昂或保留类别性能显著下降。

Innovation: 
本文提出了一种新颖的类别感知软剪枝框架，利用正交卷积核正则化来实现快速而精确的遗忘，具备毫秒级响应时间。通过在训练过程中施加正交性约束，该方法能够解相关卷积滤波器并分离特征表示，同时利用激活差异分析高效地识别类别特定的通道。本文在多个架构和数据集上进行了广泛评估，展示了稳定的剪枝效果、接近即时的执行、针对目标类别的完全遗忘以及保留数据上的最小准确性损失。实验表明，本文方法显著降低了成员推理攻击的风险，并且相比最先进的基线方法，卸载速度提升了多个数量级。

Conclusion: 
该框架提供了一种高效、实用的解决方案，用于在MLaaS场景中的实时机器卸载。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19891</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>244. cs.LG-FlightKooba: 一种快速可解释的飞行轨迹预测模型</title><link>https://arxiv.org/pdf/2506.19885</link><description>Background: 
库普曼理论是一种强大的模型工具，能够将非线性系统转化为线性表示，飞行轨迹预测（FTP）是一个复杂的非线性系统。然而，目前应用库普曼理论进行FTP任务的模型效果并不理想，模型可解释性较低，而且库普曼算子的计算强度很大，导致训练时间长。

Innovation: 
本文提出了一种基于HIPPO方法、库普曼理论和控制论中的状态空间方程的新建模和控制框架：FlightKooba。FlightKooba通过直接从数据构建库普曼算子，使其框架具有高度的可解释性，并在模块中显著减少了可训练参数的数量，从而大大减少了训练时间。实验结果表明，FlightKooba方法在时间和内存消耗方面优于其他方法，特别是在训练时间和内存使用方面有明显优势，几乎实现了FTP任务的快速计算，提供了新的库普曼算子快速计算方法，开启了时间序列预测与控制结合的新可能。

Conclusion: 
FlightKooba实现了FTP任务的快速执行，提供了一种新的库普曼算子快速计算方法，提高了可解释性，大幅减少了训练时间和参数数量，为时间和控制的结合提供了新的途径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19885</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>245. cs.CV-DRO-Augment框架：通过结合Wasserstein分布鲁棒优化和数据增强实现鲁棒性</title><link>https://arxiv.org/pdf/2506.17874</link><description>Background: 
在许多实际应用中，确保深度神经网络（DNNs）的鲁棒性和稳定性至关重要，特别是在遇到各种输入扰动时。尽管数据增强技术被广泛用于提高对这些扰动的抗干扰能力，但同时抵抗被噪声污染的数据和对抗性攻击方面仍存在显著的改进空间。现有增强方法在极端数据扰动和对抗性攻击场景下表现不佳，特别是在保持对干净数据集的准确性方面。为了解决这一挑战，本文提出了一种新颖的框架DRO-Augment，该框架结合了Wasserstein分布鲁棒优化（W-DRO）和多种数据增强策略，显著提高了模型在广泛扰动下的鲁棒性。

Innovation: 
本文提出了一种名为DRO-Augment的新颖框架，该框架将Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略相结合，以显著提高模型在不同程度的腐化数据和对抗性攻击下的鲁棒性。相比现有增强方法，DRO-Augment在严苛的数据污染和对抗性攻击场景下表现出更优异的效果，同时保持了在干净数据集上的准确性。此外，研究还为使用近似变分正则化损失函数训练的神经网络建立了新的泛化误差界，该损失函数与W-DRO问题密切相关。

Conclusion: 
我们的方法在包括但不仅限于CIFAR-10-C、CIFAR-100-C、MNIST和Fashion-MNIST等多种基准数据集上均表现出色，不仅提高了模型的整体鲁棒性，而且还维护了对干净数据集的准确率。所提出的W-DRO损失函数的变分正则化损失提供了更严格的风险上下界，并在理论上为鲁棒性提供了坚实的基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17874</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>246. cs.LG-机器学习会议应建立‘反驳与批判’赛道</title><link>https://arxiv.org/pdf/2506.19882</link><description>Background: 
随着机器学习（ML）研究的迅速发展，发表了大量研究成果，但同时一些误导性、错误的甚至可能是欺诈性的研究也出现在ML会议中，这主要是由于同行评审的局限性。尽管这种错误是可以理解的，但ML会议目前缺乏有效的机制来系统地纠正这些错误。因此，需要设定一个专门的‘反驳与批判’赛道来支持批判性挑战先前研究的重要研究，促进动态的自我纠正研究生态系统。

Innovation: 
提议在ML会议上建立一个专门的‘反驳与批判’赛道，提供一个高知名度的平台，从而支持并加强对于先前研究的批判性挑战，促进自我纠正的研究环境。

Conclusion: 
建议ML会议应创建官方和信誉良好的机制，以帮助ML研究自我纠正。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19882</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>247. cs.CV-Morse: 双采样策略加速扩散模型不失真加速</title><link>https://arxiv.org/pdf/2506.18251</link><description>Background: 
扩散模型在生成高分辨率图像时效率低下，尤其是在迭代生成过程中，由于需要从随机噪声逐步生成逼真的图像，导致计算成本高昂。为了提高这些模型的效率，研究者们尝试了各种方法，例如更快的跳跃抽样策略和自适应残差反馈机制等，来优化生成过程。本研究通过开发Morse框架，结合快速跳跃抽样和自适应残差反馈，实现扩散模型不失真的加速。

Innovation: 
Morse引入了两个模型Dash和Dot来相互协作。Dash模型在预训练的快速跳跃采样模式下运行，Dot模型则更加高效地生成基于当前跳跃采样点的残差反馈，从而提升噪声估计并与Dash模型的下一个跳跃采样步骤相匹配。通过交替运行Dash和Dot两个模型，Morse能够灵活地在保证图像生成质量的同时提升整体运行效率。此外，通过重量共享策略，Morse在训练和推断过程中保持高效。Morse相对于9种基线扩散模型，在6种图像生成任务中平均获得1.78倍至3.31倍的不失真加速效果。此外，该方法还能推广应用，提高基于一致性蒸馏技术加速的Latent Consistency Model (LCM-SDXL，适用于少量步骤的文本转图像合成)的效率。

Conclusion: 
Morse框架通过结合快速跳跃抽样和自适应残差反馈策略，成功实现了扩散模型的不失真加速。该方法不仅在大多数情况下显著提升了效率，还能够灵活调整以达到所需的生成性能。同时，该研究成果还展示了其在不同模型中的泛化能力，进一步验证了其有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18251</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>248. cs.CV-LVPNet: 以潜在变量为基础的预测驱动端到端框架，用于医学图像无损压缩</title><link>https://arxiv.org/pdf/2506.17983</link><description>Background: 
现有的医学图像无损压缩方法依赖于图像分割过程，这会导致每个子图像中的潜在变量信息分布均匀。这种分布模式导致了后验崩溃（posterior collapse）以及潜在变量的低效利用。为了克服这些问题，本文提出了一种基于预测的端到端无损医学图像压缩方法LVPNet。LVPNet利用全局潜在变量来预测像素值，并对预测概率进行编码，实现无损压缩。它引入了全局多尺度探测模块（GMSM），以从整个图像中提取紧凑且具有代表性的潜在表示，有效捕捉潜在空间内的空间依赖性。此外，为了减轻量化过程中引入的信息损失，LVPNet提出了一种量化补偿模块（QCM），该模块学习量化误差的分布并调整量化特征以补偿量化损失。

Innovation: 
本文提出了一种名为LVPNet的预测驱动的端到端无损医学图像压缩方法。通过引入全局多尺度探测模块（GMSM）和量化补偿模块（QCM），LVPNet能够更有效地利用潜在变量信息。全局多尺度探测模块可以从整个图像中提取紧凑且具有代表性的潜在表示，从而使潜在空间中的空间依赖性得到有效捕捉。量化补偿模块能够学习量化误差的分布，并通过调整量化特征来补偿量化期间的信息损失。

Conclusion: 
在多个具有挑战性的基准上进行的实验表明，LVPNet相比现有的最先进的无损图像压缩方法具有更高的压缩效率，同时保持了相当的竞争推理速度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17983</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>249. cs.CV-WAFFLE: 使用多模态模型进行自动前端开发的微调策略</title><link>https://arxiv.org/pdf/2410.18362</link><description>Background: 
Web开发涉及到将UI设计转化为功能网页，对于初学者和经验丰富的开发者来说都充满挑战。HTML的层级结构和样式复杂性使得这一过程尤为困难。尽管大型语言模型（LLMs）在生成源代码方面表现出潜力，但在UI到HTML代码的生成过程中仍存在两大挑战：（1）有效向LLMs表示HTML的层级结构，（2）弥合UI设计的视觉性质与HTML代码的文本格式之间的差距。

Innovation: 
为了应对这些挑战，本文引入了Waffle，这是一种新的微调策略，通过结构感知注意机制提高LLMs对HTML结构的理解，并通过对比微调方法将LLMs对UI图像和HTML代码的理解进行对齐。使用Waffle微调的模型在新的基准测试WebSight-Test和现有基准Design2Code上表现出优异性能，分别在HTML匹配度、CW-SSIM、CLIP和LLEM等指标上提高了9.00个百分点、0.0982、32.99和27.12个百分点，超越了当前的微调方法。

Conclusion: 
与现有的微调方法相比，使用Waffle微调的模型在多个评价指标上表现更优，表明该策略对于提高前端自动开发工具的性能具有显著效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.18362</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>250. cs.CV-在合成数据中证明性改善少量样本模型的泛化能力</title><link>https://arxiv.org/pdf/2505.24190</link><description>Background: 
少量样本图像分类仍然具有挑战性，因为标记的训练样本稀缺。通过合成数据增强样本成为缓解该问题的一种有前景的方法。然而，使用合成样本训练的模型常常由于真实分布与合成分布之间的内在差距而出现性能下降。为了克服这一限制，我们开发了一种理论框架，量化这种分布差异对监督学习特别是图像分类的影响。该框架还建议了生成高质量合成样本和训练具有高泛化能力预测器的实际方法。基于该框架，我们提出了一种新型理论驱动算法，该算法结合了原型学习，以优化数据分割和模型训练，有效弥合实短暂样本数据和合成数据之间的差距。

Innovation: 
我们的工作提出了一种理论框架来量化真实样本和合成样本之间的分布差异对监督学习的影响，并提出了生成高质量合成样本的方法。在此基础上，我们提出了一种新型算法，通过结合原型学习，有效整合实短暂样本数据和合成数据，提高了模型的泛化能力。实验证明了该方法在多种数据集上的优越性能，超过了最先进的方法。

Conclusion: 
我们的方法在多种数据集上表现优越，相较于最先进的方法，有效提升了少量样本图像分类的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.24190</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>251. cs.CV-预测建模、模式识别和模拟及控制环境中植物生长的空间时间表示：全面综述</title><link>https://arxiv.org/pdf/2412.10538</link><description>Background: 
在植物表型研究中，预测植物生长模式以及在模拟和控制环境中的准确预测和表示对于应对各种挑战非常重要。本综述探讨了关于最先进的预测模式识别技术的研究，重点关注植物性状的时空建模以及动态环境相互作用的整合。文章综述了确定性、概率性和生成性建模方法，并强调了它们在高通量表型分析和基于模拟的植物生长预测中的应用。

Innovation: 
综述涵盖了2D和3D结构数据表示方法，通过功能结构植物模型和条件生成模型。文中还提出了未来的研究机会，强调将领域特定知识集成到数据驱动方法中，提高可用数据集的品质，并将这些技术应用于实际应用中。文章还指出了现有实验确定性方法的局限性，并强调了需要纳入不确定性和不断变化的环境反馈的动态框架。

Conclusion: 
文章为未来的工作提供了视角，强调了确定性模型的不足之处和需要包含环境反馈动态框架的重要性，同时也指出了功能结构植物模型和条件生成模型在2D和3D结构数据表示中的进步。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.10538</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>252. cs.CV-从粗糙到连续：运动鲁棒各向异性MRI重建的逐步细化显式神经表示</title><link>https://arxiv.org/pdf/2506.16210</link><description>Background: 
在运动鲁棒的磁共振成像（MRI）中，切片到体素的重建对于从二维切片恢复结构一致的三维脑部结构至关重要，尤其是在加速采集或患者运动的情况下。然而，由于层级结构的中断，这一任务仍然具有挑战性。其包含局部细节的k空间欠采样损失、由运动引起的全局结构失真和体素各向异性等挑战。

Innovation: 
本文提出了一种逐步细化隐式神经表示（PR-INR）框架。PR-INR在几何感知的坐标空间内统一了运动校正、结构细化和体素合成。具体而言，首先使用运动感知扩散模块生成粗糙的体素重建，以抑制运动伪影并保留全局解剖结构。然后，引入了一个隐式细节恢复模块，该模块通过对齐空间坐标和视觉特征来进行残差细化，以矫正局部结构并增强边界精度。进一步地，提出了一种体素连续感知表示模块，它将图像表示为3D坐标上的连续函数，从而实现精确的跨切片完成和高频细节恢复。

Conclusion: 
研究结果表明，PR-INR在定量重建指标和视觉质量方面均优于现有最先进的方法，并展示了在不同未见过的领域中的泛化能力和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16210</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>253. cs.CV-Mamba 政策：具有混合选择性状态模型的高效 3D 扩散策略</title><link>https://arxiv.org/pdf/2409.07163</link><description>Background: 
扩散模型在3D操作领域得到了广泛应用，因为它们能够高效地学习分布，从而实现精准的动作轨迹预测。然而，扩散模型通常依赖于参数量庞大的UNet骨干网络作为策略网络，这在资源受限的设备上难以部署。随着Mamba模型的出现，该模型因其低计算复杂度和在序列建模中的强大性能而成为有效的解决方案。现有研究表明，Mamba模型可以在动作技能学习中提供比UNet更好的性能，且对资源的需求更低。因此，本研究在此背景下提出了一种更轻量化的Mamba Policy，并结合了Mamba块和注意力机制来提取深层次的特征。实验验证了Mamba Policy在Adroit、Dexart和MetaWorld数据集上的优异性能，并且在长期操作场景中表现出更强的鲁棒性。

Innovation: 
本研究提出了Mamba Policy，这是一种轻量级但性能更强的策略模型，相比原有的策略网络减少了超过80%的参数量，但仍保持了出色的表现。Mamba Policy引入了XMamba块，该块有效地整合了输入信息与条件特征，并利用Mamba和注意力机制进行深层特征提取。此外，还探索了Mamba Policy框架内的各种Mamba变体性能。Mamba Policy在计算资源需求上远低于现有方法，并在长时间操作场景下展示了更强的鲁棒性，从而克服了扩散模型在资源受限设备上的部署难题。

Conclusion: 
实验结果表明，Mamba Policy在Adroit、Dexart和MetaWorld等数据集上表现出显著的性能优势，需要更少的计算资源。并且其在长期操作场景下的鲁棒性也优于基线方法，研究结果已在实际应用场景中被验证有效。本研究为资源受限设备上的高效3D动作预测提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.07163</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>254. cs.CV-EvDetMAV：来自移动事件相机的通用MAV检测</title><link>https://arxiv.org/pdf/2506.19416</link><description>Background: 
现有的微型空中车辆（MAV）检测方法主要依赖于目标在RGB图像中的外观特征，但这些特征的多样性使得实现通用的MAV检测变得困难。我们注意到，由于高速旋转的螺旋桨，不同类型的MAV在事件流中具有相同的显著特征，而在RGB图像中很难看到这些特征。本文研究了如何利用事件相机中的原始事件流来提取螺旋桨的显著和时空特征，从而检测不同类型的MAV，并通过三个模块过滤掉背景对象和相机运动产生的噪声。但目前没有现有的基于事件的MAV数据集，因此引入了一个新的MAV数据集，该数据集包含多种场景和不同类型的MAV，是首个基于事件的MAV数据集。在没有训练的情况下，所提出的方法显著优于现有最先进的方法，并能处理具有挑战性的场景，精确率达到83.0% (+30.3%)，召回率达到81.5% (+36.4%)，在提出的测试数据集上。该数据集和代码可在此链接获取：this https URL

Innovation: 
本文创新地使用事件相机和事件流数据来检测不同类型的MAV，提出了一个三模块方法来提取螺旋桨的关键时空特征。同时，作者还创建了首个包含多场景和不同类型MAV的基于事件的MAV数据集，为该领域的研究提供了新的数据支持。所提出的方法在没有训练的情况下显著优于现有方法，且能够处理复杂场景。

Conclusion: 
利用基于事件的MAV数据集，本文提出的方法在检测不同类型的MAV方面取得了显著的效果，精确率和召回率分别提升了83.0%和81.5%，展示了其在复杂场景下的鲁棒性，并且该数据集和代码均公开发布以供其他研究者使用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19416</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>255. cs.CV-全面筛查：从HE全切片图像中进行全面癌症遗传和表型生物标志物筛查</title><link>https://arxiv.org/pdf/2408.09554</link><description>Background: 
分子检测是癌症预后和治疗选择的标准方法，但成本高、组织破坏性强、耗时。常规HE染色全切片图像（WSI）的人工智能（AI）应用提供了一种快速且经济的替代方法，用于筛查分子生物标志物。

Innovation: 
介绍了OmniScreen，这是一种高通量的AI基系统，利用从60,529名癌症患者中提取的Virchow2嵌入，这些患者伴有489基因MSK-IMPACT靶向生物标志物面板和WSIs。OmniScreen以统一模型预测多种临床相关的生物标志物，覆盖各种癌症类型，包括难以单独建模的低频靶点。它能够可靠地识别治疗目标和共同的表型特征，跨越常见和罕见肿瘤。此外，研究了OmniScreen的生物标志物预测概率和准确性与肿瘤面积、队列大小、组织学亚型对齐及通路级形态模式的关系。这些发现突显了OmniScreen在常规临床筛查中的潜力。

Conclusion: 
这些结果强调了OmniScreen在常规临床筛查中的潜在价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.09554</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>256. cs.CV-自监督多模态NeRF在自动驾驶中的应用</title><link>https://arxiv.org/pdf/2506.19615</link><description>Background: 
研究者提出了一种基于Neural Radiance Fields (NeRF)的框架，名为Novel View Synthesis Framework (NVSF)，用于实现实时道路交通场景下激光雷达(LiDAR)和相机画面的空间隐式表示及时间变化场景的学习。该研究在包含静态和动态场景的真实自动驾驶环境中进行了测试，与现有的时间动态NeRF相比，该框架是自监督的，可以消除对3D标签的需求。为了提高训练效率和加快收敛，引入了基于启发式的图像像素采样方法，重点采样信息丰富的像素点。为了保留LiDAR点的局部特征，采用了基于双梯度的掩码方法。实验表明，在Kitti-360数据集上，与基线模型相比，该框架在LiDAR和相机领域都表现出最佳性能。

Innovation: 
该研究提出了一种自监督的多模态NeRF框架，能够在自动驾驶环境中同时处理激光雷达和相机数据。引入了基于启发式的图像像素采样方法和基于双梯度的掩码方法，提高了模型在激光雷达和相机领域的性能。该框架不需要3D标签，从而简化了模型训练过程，实现了更高效的训练和更快的收敛。

Conclusion: 
实验结果证明，与基线模型相比，该自监督多模态NeRF框架在LiDAR和相机域均表现出最佳性能，充分验证了其在自动驾驶场景中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19615</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>257. cs.CV-单一原型足够：单原型激活的可解释图像分类</title><link>https://arxiv.org/pdf/2506.19808</link><description>Background: 
现有的原型网络通常依赖多个原型之间的协作决策来进行单类别的分类和解释，而本文提出了ProtoSolo，一种基于原型网络概念的新颖且可解释的深度神经架构。ProtoSolo仅需激活单一原型即可完成分类任务，从而简化了解释过程的认知复杂度。并且，它使用特征图进行相似性比较和原型学习，以利用更多的全局信息进行分类。此外，提出了一种非原型投影学习策略，以保留原型与训练图像片段之间的信息关联，同时避免了投影操作导致的网络结构突变对分类性能的负面影响。

Innovation: 
1. 单一原型激活：只需激活单一原型进行分类，减少了认知复杂度。n2. 基于特征的比较方法：使用特征图进行相似性比较和原型学习，利用了更多的全局信息。n3. 非原型投影学习策略：在保留原型与图像片段关联性的同时，避免了投影操作对网络结构和分类性能的负面影响。

Conclusion: 
在CUB-200-2011和斯坦福汽车数据集上的实验表明，ProtoSolo在分类任务和解释复杂度方面都达到了最先进的水平。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19808</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>258. cs.CV-OmniGen2: 探索高级多模态生成</title><link>https://arxiv.org/pdf/2506.18871</link><description>Background: 
本文介绍了一种多功能且开源的生成模型OmniGen2，它可以统一解决包括文本到图像、图像编辑和上下文生成在内的多种生成任务。OmniGen2利用两个独立的解码路径来处理文本和图像模态，不共享参数并解耦图像标记器，使其能够基于现有的多模态理解模型而不需重新适应VAE输入，从而保持原有的文本生成能力。为了训练OmniGen2，作者开发了全面的数据构建管道，涵盖图像编辑和上下文生成数据。此外，还引入了针对图像生成任务的反射机制，并基于OmniGen2构建了专用的反射数据集。尽管OmniGen2的参数规模较小，但其在多个任务基准测试中的表现与Open Source模型中的其他模型相当。为了进一步评估上下文生成，即主题驱动任务，作者还引入了一个名为OmniContext的新基准。即使在多样性和一致性方面，OmniGen2也表现出色。

Innovation: 
OmniGen2相比于之前的版本OmniGen v1，具有的创新之处包括：1) 两个独立的解码路径分别处理文本和图像模态，不共享参数并解耦图像标记器；2) 基于现有的多模态理解模型进行拓展，无需重新适应VAE输入，从而保持原有的文本生成能力；3) 为图像生成任务引入了反射机制，构建了专用的反射数据集；4) 即使参数规模较小，也能在多个任务基准测试中取得有竞争力的结果；5) 引入了名为OmniContext的新基准测试，以评估上下文生成的性能。

Conclusion: 
尽管OmniGen2具有相对较少的参数量，它在多项任务中的表现达到了开放源码模型中的最优水平。OmniGen2将模型、训练代码、数据集和数据构建管道公开发布，为未来的研究提供了支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18871</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>259. cs.CV-关注采样：通过最大化解释确定性在视觉模型中构建可信的归因分析组件</title><link>https://arxiv.org/pdf/2506.19442</link><description>Background: 
图像归因分析旨在突出视觉模型学到的功能表示，以便这些突出的功能图可以反映输入的像素重要性。梯度集成是归因分析中的一个组件，通过整合来自多个样本的梯度来突出与推断相关的语义特征。这一组件往往与其他视觉模型的信息相结合，如激活图或注意力图，以形成最终的解释。然而，理论分析表明，梯度集成中样本分布与自然图像分布对齐的程度给出了解释确定性的下限。前人工作在图像中添加噪声作为样本，噪声分布可能导致解释确定性较低。出乎意料的是，实验表明额外信息可以使神经网络饱和。因此，建立可信赖的归因分析需要解决样本分布不对齐的问题。传统的做法是在输入图像中添加额外的信息，而本文提出了一种半优化的采样方法，即从输入中抑制特征。抑制特征后的样本分布大致与自然图像分布相同。大规模图像数据集ImageNet上的广泛定量评估证实了该方法的有效性，并能够在整个实验模型中提供比最先进的基线更好的解释。

Innovation: 
本文提出了一种半优化的采样方法，从输入中抑制特征，使得样本分布接近自然图像分布，从而解决了样本分布不对齐的问题。这种方法可以提高解释的确定性，通过抑制特征抑制额外信息，使得神经网络不会饱和，从而提高了归因分析的准确性与可靠性。

Conclusion: 
本文方法在大规模图像数据集ImageNet上进行了广泛 quantitative 评估，证实其在不同实验模型中都比最先进的基线方法提供了更好的解释结果。这种方法解决了样本分布不对齐的问题，并证明了在可信归因分析中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19442</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>260. cs.CV-VLN-R1: 通过强化微调实现视觉-语言导航</title><link>https://arxiv.org/pdf/2506.17221</link><description>Background: 
视觉-语言导航（VLN）是具身AI中的一个核心挑战，需要代理使用自然语言指令来导航真实世界环境。现有的基于语言模型的导航系统在离散拓扑图上运行，限制了路径规划到预定义节点连接。这限制了系统在动态环境中的适应性和灵活性。因此，有必要开发一种新的方法，使代理能够根据连续的视觉输入作出实时的导航决策，并通过强化学习机制进行训练和优化。

Innovation: 
作者提出了VLN-R1，一种端到端的框架，利用大规模视觉-语言模型（LVLM）直接将第一人称视频流转化为连续的导航动作。采用了基于GRPO的训练方法，有效地解决了长期依赖和短期贪心的权衡问题。VLAN-R1通过构建VLN-Ego数据集并提出长短期记忆采样方法，平衡了历史和当前观察。同时，结合监督微调（SFT）和奖励衰减机制的强化微调（RFT）方法，使模型能够学习高质量的动作序列预测，从而实现具身导航任务的有效训练。

Conclusion: 
VLN-R1在VLN-CE基准上表现出强大的性能，证明了LVLM可以驱动具身导航，并通过数据高效、奖励驱动的后训练增强任务特定的推理。这一框架为具身AI领域的进一步研究提供了新的思路和方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17221</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>261. cs.CV-BeltCrack: 用于工业输送带裂纹检测的第一组序贯图像数据集及其基于三域特征学习的基线方法</title><link>https://arxiv.org/pdf/2506.17892</link><description>Background: 
输送带在现代工业中是重要的设备，广泛应用于生产和制造中。输送带的健康状况对生产效率和安全性至关重要。输送带上的裂缝是对输送带健康的主要威胁。目前，为了保障安全，在使用机器学习进行智能检测时，需要实际的裂缝样本，但现有的裂缝数据集主要集中在道路场景或合成数据上，缺乏真实的工业输送带裂缝数据集。因此，开发专门针对工业输送带裂缝的检测数据集变得尤为重要，以验证其使用性和有效性并促进相关技术的发展。

Innovation: 
本文提出了BeltCrack数据集，这是首个用于工业输送带裂缝检测的序贯图像数据集，包含两个全新的裂缝检测数据集，并提出了一种基于三域（即时间-空间-频率）特征学习的特殊基线方法。实验结果证明了数据集的有效性和基线方法的优越性，该方法明显优于其他类似检测方法。此外，数据集和源代码在其公开网址上提供。这些创新为工业输送带裂缝检测提供了新的数据支持和算法基础，有助于提升工业生产能力并确保操作的安全性。

Conclusion: 
实验结果表明，提出的BeltCrack数据集和基于三域特征学习的基线方法具备很高的适用性和有效性，实验数据和算法代码已经公开，能够为工业输送带裂缝检测的研究和发展提供有效支持。未来的工作可以进一步优化检测算法，提高检测的准确性和实时性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17892</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>262. cs.CV-PP-DocBee2：增强型数据促进的多模态文档理解基线改进</title><link>https://arxiv.org/pdf/2506.18023</link><description>Background: 
PP-DocBee2 是 PP-DocBee 的高级版本，旨在提升多模态文档理解能力。该报告基于大型多模态模型架构，通过对多项关键技术的改进来克服前一代产品的局限性，包括提高合成数据质量、优化视觉特征融合策略和改进推理方法。这些改进使得 PP-DocBee2 在中文商业文档的内部基准测试上性能提高了 11.4%，同时将推理延迟减少了 73.0%。

Innovation: 
本文的主要创新包括多模态文档任务中的数据质量优化策略。通过使用大规模多模态预训练模型评估数据，并应用新颖的统计标准来过滤异常值，以确保高质量的训练数据。此外，通过分解 ViT 层并引入新颖的特征融合策略来增强 ViT 的表示能力，从而改进复杂的推理过程。研究成果提供了源代码和预训练模型供进一步研究使用。

Conclusion: 
PP-DocBee2 在多模态文档理解方面取得了显著进步，通过优化数据质量和引入新颖的融合和推理方法，大大提高了模型的性能和效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18023</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>263. cs.CV-TIIF-Bench: 如您的T2I模型如何遵循您的指令？</title><link>https://arxiv.org/pdf/2506.02161</link><description>Background: 
文本到图像(T2I)模型的快速进步开启了AI生成内容的新阶段，它们现在能够更好地理解和遵循用户指令。然而，现有的T2I模型评估基准在提示多样性、复杂性和粗略的评估指标方面存在不足，使得细粒度的文字指令和生成图像之间的对齐性能难以有效评估。因此，需要一个新的基准来系统性地评估T2I模型对复杂指令的理解和遵循能力。

Innovation: 
论文引入了TIIF-Bench（文本到图像指令跟随基准），它包括了一系列5000个按多个维度分类的提示，共分为三个难度级别。为了评估模型对不同长度提示的鲁棒性，每个提示都提供了具有相同核心意义的短和长版本。此外，引入了两个关键属性（文本渲染和风格控制）来评估文本合成的精度和T2I模型的审美一致性。通过广泛收集设计师级别的提示并结合大型视觉语言模型中的世界知识，开发了新的可计算框架以辨别T2I模型输出的细微变化。建议使用该基准对主流T2I模型进行全面评估，以揭示当前T2I模型的优点和缺点，以及现有基准的局限性。

Conclusion: 
通过在TIIF-Bench上对主流T2I模型进行细致的基准测试，分析了当前T2I模型的优点和缺点，并揭示了当前T2I基准的局限性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.02161</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>264. cs.CV-CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation</title><link>https://arxiv.org/pdf/2506.15549</link><description>Background: 
深度学习技术在通过延迟钆增强（LGE）心脏磁共振成像（MRI）进行心肌疤痕分割方面的应用展示了极大的潜力，有助于准确及时地诊断和治疗结构性心脏疾病。然而，高质量心肌疤痕标签的可用性和差异性限制了鲁棒的心肌疤痕分割模型的发展。

Innovation: 
引入了CLAIM框架，这是一种基于临床指导的心脏疤痕生成和分割框架，核心是SMILE模块（基于临床知识的心肌疤痕掩膜生成），该模块利用临床采用的AHA 17段模型来生成具有解剖上一致和空间多样性的疤痕图像。还采用了联合训练策略，同时优化疤痕分割网络和生成器，以增强生成的疤痕的逼真度和疤痕分割的准确性。

Conclusion: 
实验结果显示，CLAIM生成了解剖上一致的心肌疤痕图案，并在真实疤痕分布的Dice相似度上优于基线模型。我们的方法能够控制和生成逼真的心肌疤痕图像，并且已经在下游医疗影像任务中显示出实用性。代码可在以下链接获得。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15549</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>265. cs.CV-Cross-Frame Representation Alignment for Fine-Tuning Video Diffusion Models</title><link>https://arxiv.org/pdf/2506.09229</link><description>Background: 
在用户级别微调视频扩散模型（VDMs）以生成反映训练数据特定属性的视频面临着显著挑战，尽管其实践重要性不言而喻，但该领域尚未得到充分探索。近期的工作，如Representation Alignment (REPA)，证明了在不丧失内部隐藏状态而与预训练视觉特征对齐的情况下，可以用减少收敛时间和提高模型质量的方式改进DiT（Diffusion Time）图像扩散模型，暗示了其在VDM微调中的潜力。然而，REPA在保持帧间语义一致性方面表现不佳。

Innovation: 
该研究提出了一个直接适应REPA以适用于VDMs的方法，并通过实验验证了其在收敛性方面的有效性，但逊色于保持帧间语义一致性。为解决这一局限，提出了Cross-frame Representation Alignment (CREPA)，这是一种新的正则化技术，用于将帧的隐藏状态与邻近帧的外部特征对齐。在大规模VDM模型（如CogVideoX-5B和Hunyuan Video）上的实验评估显示，与高效参数方法（如LoRA）结合使用时，CREPA可提高视觉保真度和跨帧语义连贯性。此外，CREPA在多种具有不同属性的数据集上的验证显示了其广泛的适用性。

Conclusion: 
CREPA作为一种新颖的正则化技术，针对帧间语义一致性较差的问题，通过将帧的隐藏状态与邻近帧的外部特征对齐，改善了VDM的微调效果，特别是在视觉保真度和跨帧语义连贯性方面。该技术在多个数据集上的验证显示了其广泛的适用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.09229</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>266. cs.CV-通过注意力头选择进行精细粒度的扰动指导</title><link>https://arxiv.org/pdf/2506.10978</link><description>Background: 
扩散模型的逆向采样方法通过扰动模型来构建一个隐式的弱模型，并引导生成远离该模型。近期的指导方法通过在不同层或注意力头层面进行扰动，但在Diffusion Transformer（DiT）架构中，质量相关的计算分布在多层，现有方法缺乏确定何时以及如何应用扰动的原理方法。本文旨在研究注意力头层面的粒度，发现特定的头负责不同的视觉概念，如结构、风格和纹理质量。

Innovation: 
通过提出HeadHunter（一个系统框架，用于根据用户目标迭代选择注意力头，以实现对生成质量和视觉属性的细粒度控制）和SoftPAG（一种线性插值方法，将每个选定头的注意力图向单位矩阵插值，以连续调节扰动强度并抑制伪影），本文不仅解决了现有层级扰动方法的过平滑问题，还通过组合头选择实现了特定视觉风格的精确操控。

Conclusion: 
本研究通过HeadHunter框架在大规模DiT基文本到图像模型中验证了方法，特别是在通用质量增强和风格特定指导方面展示了优越性能。本研究提供了扩散模型中首个注意力头层面的分析，揭示了注意力层中的可解释专业化，并为有效的扰动策略设计提供了实用指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.10978</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>267. cs.CV-C3S3: 补偿竞争与对比选择在半监督医学图像分割中的应用</title><link>https://arxiv.org/pdf/2506.07368</link><description>Background: 
医学领域存在标注样本不足的问题，这限制了现有的半监督医学图像分割（SSMIS）方法在界线细分上的精准度，从而导致诊断准确性下降。为此，本文针对这一挑战提出了C3S3模型，该模型通过集成补偿竞争和对比选择来提升边界细化和整体精度。

Innovation: 
本文引入了C3S3模型，该模型包含两个创新模块：1)Outcome-Driven Contrastive Learning模块，用于精细界线定位；2)Dynamic Complementary Competition模块，利用两个高绩效子网络生成伪标签，进一步提高分割质量。这种设计显著提升了边界细化的精度和整体精度。

Conclusion: 
本文通过在两个公开的医学图像数据集（MRI和CT扫描）上进行严格验证，证明C3S3模型的表现优于现有顶尖方法，尤其是在95HD和ASD指标上实现了至少6%的显著提升，体现了重大进步。代码已公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07368</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>268. cs.CV-ZigzagPointMamba: 空间语义Mamba模型用于点云理解</title><link>https://arxiv.org/pdf/2505.21381</link><description>Background: 
现有的PointMamba方法依赖于复杂的标记顺序和随机掩码，这破坏了空间连续性和局部语义相关性，影响了点云自我监督学习的效率和效果。

Innovation: 
提出了一种称为ZigzagPointMamba的新方法，其核心是一个简单的Z字形扫描路径来全局序列化点云标记，增强了空间连续性。同时引入了一种语义孪生掩码策略（SMS），通过整合原本和相似标记的局部特征来构建模型，解决了孤立局部特征依赖问题，增强了全局语义建模能力。

Conclusion: 
预训练的ZigzagPointMamba权重显著提高了下游任务的表现，在ShapeNetPart集合体部分分割任务中获得了1.59%的mIoU提升，在ModelNet40分类任务中获得了0.4%的准确性提升，并分别在ScanObjectNN的数据子集OBJ-BG、OBJ-ONLY和PB-T50-RS上的分类任务中获得了0.19%、1.22%和0.72%的准确性提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.21381</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>269. cs.CV-单张图像的暗通道辅助深度-失焦重建方法</title><link>https://arxiv.org/pdf/2506.06643</link><description>Background: 
传统的深度-失焦（DFD）方法依赖于多张具有不同光圈或对焦状态的图像来估计场景深度。然而，单张图像的DFD方法由于固有的挑战而较少被研究。这个问题由于其解决问题的约束条件不足而难以处理，导致很少有研究集中在单张失焦图像的DFD上。

Innovation: 
本文提出了一种利用暗通道作为补充线索来估计场景深度的方法，这种方法可以捕捉局部统计和场景结构。该方法通过使用局部失焦模糊和对比度变化之间的关系来作为深度线索，从而改进了场景结构的估计。此外，该方法通过对抗学习进行端到端训练。实验结果表明，将暗通道先验引入单张图像的DFD中，可以提供有重要意义的深度估计。这验证了该方法的有效性。

Conclusion: 
本研究提出的方法通过利用暗通道线索有效地改善了单张图像的DFD性能。通过对抗学习的方法进行端到端训练，该方法在实际数据上的表现表明了其在单一图片的深度估计中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.06643</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>270. cs.CV-ViStoryBench: 一个全面的故事可视化基准体系</title><link>https://arxiv.org/pdf/2505.24862</link><description>Background: 
故事可视化旨在生成与给定叙述和参考图像一致的一系列视觉连贯图像，近年来随着生成模型的发展取得了显著进展。为了在实际场景中进一步提升故事可视化框架的性能，研究者们引入了一个全面的评估基准——ViStoryBench。通过收集多样的故事类型和艺术风格的数据集，模型可以从多个维度进行评估，包括不同的故事情节（如喜剧、恐怖）和视觉美学（如动漫、3D渲染）。ViStoryBench特别注重平衡叙事结构和视觉元素，包括单一和多个主人公的故事，以测试模型在保持角色一致性方面的能力。此外，它还包含复杂的故事情节和细致的世界构建，以挑战模型生成准确图像的能力。

Innovation: 
ViStoryBench 提供了一个广泛且多维度的评价框架，包括一系列评估指标来衡量关键方面。这使得研究者能够系统性和全面地识别不同模型的优点和不足，从而进行针对性的改进。

Conclusion: 
这个结构化且多方面的框架有助于研究人员彻底识别不同模型的强弱，促进有针对性的改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.24862</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>271. cs.CV-通过图像到视频合成实现的4D运动建模中的时间差分场</title><link>https://arxiv.org/pdf/2505.17333</link><description>Background: 
在基于图像的临床应用中，准确地建模肺部和心脏等部位的呼吸引起的周期性运动是必要的。现有的方法无法在没有包括起始和结束帧的高剂量成像扫描时模拟这种周期性的运动轨迹。然而，术前数据采集过程中，患者的轻微移动会导致呼吸周期中前后两帧之间的动态背景差异，这种差异很难通过图像配准消除，影响了最终的周期性建模效果。因此，需要新的方法来生成和模拟4D运动。

Innovation: 
本文提出了一种创新的方法，利用图像到视频（I2V）合成框架生成一系列连续帧来模拟周期性呼吸运动。为了增强动画视频的时间一致性，提出了时间差分扩散模型（Temporal Differential Diffusion Model）来生成时间差分场，该模型衡量相邻帧之间的相对差异。还引入了精细粒度的时间差分场和场增强层，以更好地与I2V框架互动，提高合成视频的时间变化准确性。实验结果表明，该方法与其他竞争方法相比，在感知相似性和时间一致性方面具有竞争力。

Conclusion: 
通过本文提出的I2V合成框架和时间差分扩散模型，本文的方法能够沿内在运动轨迹准确模拟4D视频，并且在感知相似性和时间一致性方面表现出色，有效解决了传统方法中的动态背景差异问题。未来的工作将公开相关代码。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.17333</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>272. cs.CV-它不是你，而是差异 -- 不同人口和个性在全球城市视觉感知中存在差异</title><link>https://arxiv.org/pdf/2505.12758</link><description>Background: 
了解人们对于城市规划的认知和需求对于做出恰当的决策至关重要。然而，当前方法往往将这些认知结合于多文化、多城市的背景下，忽视了重要的人口统计差异，从而可能放大了偏见。已有研究缺乏针对具体的人口特征与个性特质进行的详细探究，特别是在视觉感知体验方面。因此，本文通过使用街景图进行全球大规模的城市视觉感知调查，以探讨不同人口特征（性别、年龄、收入、教育背景、种族和民族，以及首次考虑的性格特质）如何塑造来自五个国家、45个民族、1000名参与者的城市街道感知。

Innovation: 
本文创新点在于：1）首次将性格特质纳入城市视觉感知的研究分析中；2）构建了一个名为SPECS的数据集，能够反映出六项传统指标和社会经济背景下新增四项指标的城市感知差异；3）通过比较不同来源的评价者和街道场景感知得分，发现现成的机器学习模型在预测感知得分时，过度估计了积极指标而低估了消极指标。这项研究强调了在当地原住民视角下进行个性化干预的重要性。

Conclusion: 
本文的研究目标是纠正城市街道感知的狭隘视角，主要发现是需要重视人口特征与个性特质对城市街道感知的影响。当前全球的感知数据集可能无法准确反映所有地区的具体感知差异，因此在未来的城市规划中需要考虑当地原住民的感知观点。通过这样的研究，可以帮助城市规划者更加准确地理解不同群体对于城市环境的看法，进而制定更具针对性的规划方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12758</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>273. cs.CV-VideoRFT：通过强化微调激励MLLMs的视频推理能力</title><link>https://arxiv.org/pdf/2505.12434</link><description>Background: 
强化细调（RFT）已经在大型语言模型（LLMs）上展现了实现人类级别推理能力的巨大潜力，并已扩展至多模态大语言模型（MLLMs）。然而，处理视频相关推理仍然是一个持续的挑战，因为视频数据中固有的复杂逻辑、时间和因果结构使得利用视频数据进行推理变得困难。

Innovation: 
本文提出了VIDEORFT，这是一种创新的方法，旨在将RFT范式扩展到培养MLLMs的类似人类的视频推理能力。VIDEORFT借鉴了RFT的标准两阶段流程：监督微调(SFT)使用带有链式思维(CoT)注释，随后是强化学习(RL)以提高泛化能力。为了解决视频领域中大规模、高质量视频CoT数据集稀缺的问题，作者构建了一个全自动化CoT编纂管道，该管道包括认知启发式的提示策略和视觉语言模型的条件生成，以实现视觉一致性和减少视觉幻觉。此外，提出了一种新的语义一致性奖励，以明确促进文本推理和视觉证据之间的对齐，从而促使模型产生更连贯、情境相关的基于视觉输入的推理输出。

Conclusion: 
广泛的实验表明，VIDEORFT在六个视频推理基准测试中达到了最先进的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12434</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>274. cs.CV-PanoWan: 通过纬度/经度感知机制将扩散视频生成模型提升到360°</title><link>https://arxiv.org/pdf/2505.22016</link><description>Background: 
全景视频生成能够创建沉浸式的360度内容，在需要场景一致的世界探索的应用中非常有价值。然而，现有的全景视频生成模型难以利用传统文本到视频模型中的预训练生成先验来生成高质量和多样化的全景视频，这主要是因为数据集规模有限以及空间特征表示之间的差距。

Innovation: 
我们引入了PanoWan来有效地将预训练的文本到视频模型提升至全景领域，其中配备了一些最小的模块。PanoWan利用了纬度感知抽样以避免纬度失真，其旋转语义去噪和填充像素级解码确保了在经度边界处的无缝过渡。为此，我们还贡献了PanoVid，这是一个带有说明和各种场景的高质量全景视频数据集。

Conclusion: 
PanoWan在全景视频生成上实现了最先进的性能，并且在零样本下游任务上有很强的鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.22016</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>275. cs.CV-TT3D: 台球3D重建</title><link>https://arxiv.org/pdf/2504.10035</link><description>Background: 
体育分析需要处理大量的数据，这既耗时又昂贵。神经网络的进展显著减轻了这一负担，使体育直播中的球跟踪变得高度准确。然而，依靠2D球跟踪有局限性，因为它依赖于摄像机的角度，并且无法支持全面的比赛分析。为了解决这一局限性，本文提出了一个新颖的方法，用于从在线乒乓球比赛录像中重建精确的3D球轨迹。该方法利用球运动的基本物理特性来识别最小化球飞行轨迹再现误差的弹跳状态，从而确保准确可靠的3D重建。该方法的一个主要优势是它能够推断球的旋转状态，而无需依赖于姿态估计或拍子跟踪，这些在转播视频中往往是不可靠或不可用的。为了支持这个方法，我们开发了一种自动摄像机校准方法，能够可靠地跟踪摄像机的运动。此外，我们还对现有的3D姿态估计模型进行了调整，这种模型缺少深度动作捕捉，使其能够准确追踪球员的运动。这些贡献共同使完整的乒乓球对决的3D重建成为可能。

Innovation: 
本文提出的TT3D方法能够从在线乒乓球比赛录像中重建精确的3D球轨迹，主要贡献包括：利用球运动的基本物理特性来识别最能最小化球飞行轨迹再现误差的弹跳状态；不需要依赖于姿态估计或拍子跟踪来推断球的旋转状态；开发了自动摄像机校准方法可靠地跟踪摄像机的运动；对现有的3D姿态估计模型进行了必要的调整，使其能够准确追踪球员的运动，从而实现完整的3D重建。这种方法相比之前的2D球跟踪，提供了更全面的比赛分析能力，尤其是在依赖摄像头视点和无法进行姿态估计或拍子跟踪的情况下。

Conclusion: 
本文通过引入TT3D方法，实现了从在线乒乓球比赛录像中精确重建3D球轨迹，解决了仅依赖2D球跟踪的局限性。该方法不仅提高了球轨迹的重建精度和可靠性，还能够在缺少 humans 姿态估计或拍子跟踪的情况下，推断球的旋转状态。结合自动摄像机校准和改进的3D姿态估计模型，本文为体育分析领域提供了新的解决方案，能够实现全面的比赛分析。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.10035</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>276. cs.CV-WoundAmbit：弥合最新语义分割与现实世界伤口护理的差距</title><link>https://arxiv.org/pdf/2504.06185</link><description>Background: 
慢性伤口在老年人和糖尿病患者中较为普遍，这些患者通常活动受限且伴有多种健康问题。通过移动图像捕捉进行的自动化伤口监控可以减少医生的亲自访问，通过远程跟踪伤口大小。在这一过程中，语义分割是关键环节，然而医学影像中的伤口分割研究仍不充分。因此，为了填补这一空白，作者对通用视觉、医学影像和公开伤口挑战赛中的顶级方法进行了基准测试，确保训练、数据增强和评估的标准化，并通过交叉验证减少偏差。此外，作者还评估了这些模型在实际部署中的表现，包括对外部数据集的泛化能力、计算效率和可解释性。在对五种最佳模型进行评估后，提出了一种参考对象基方法将AI生成的掩码转换成临床相关伤口大小估计，并发现基于Transformer的TransNeXt展示了最高的泛化能力。所有模型在CPU上每秒至少处理一张图像，满足实际应用需求。可解释性分析揭示了主要激活区域集中在伤口区域，表明模型关注临床相关特征。专家评估显示，所有分析模型的掩码获得高度批准，VWFormer和ConvNeXtS表现最好。伤口大小检索准确性在模型间相似，预测与专家注释高度匹配。最后，纸张展示了他们基于AI的伤口大小估计算法WoundAmbit如何整合到自定义的远程医疗系统中。

Innovation: 
作者首次对通用视觉、医学影像和公开伤口挑战赛中的顶级方法进行了基准测试，确保了公平比较。此外，提出了一种参考对象基方法将AI生成的掩码转换成临床相关伤口大小估计，这在医学影像研究中尚属首次。基准测试使用标准的训练、数据增强和评估方法，并通过交叉验证减少了偏差。该研究还展示了AI驱动的伤口大小估计算法如何整合到自定义的远程医疗系统中，这在实际应用中有重要意义。

Conclusion: 
基于Transformer的TransNeXt在泛化能力上表现出色，所有模型在处理速度上都能满足实际应用的需求。可解释性分析结果显示模型关注临床相关特征。专家对所有分析模型的掩码都有高度的批准，特别是在VWFormer和ConvNeXtS方面。伤口大小检索的准确性在不同模型间相似，预测结果也与专家注释高度匹配。WoundAmbit算法已成功整合到自定义的远程医疗系统中，这为未来的实际应用奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.06185</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>277. cs.CV-USP-Gaussian: 统一基于尖峰的图像重建、姿态矫正和高斯点划</title><link>https://arxiv.org/pdf/2411.10504</link><description>Background: 
尖峰相机作为一种创新的类脑摄像头，能够以0-1位流的形式以40 kHz的频率捕捉场景，近年来被广泛应用于通过神经辐射场（NeRF）或3D高斯点划（3DGS）进行3D重建任务。以往基于尖峰的3D重建方法通常采用分步处理的流水线模式，首先是基于建立的尖峰到图像重建算法从尖峰流中进行高质量图像重建，然后是摄像机姿态估计和3D重建。但是这种分步处理方式存在累积误差的问题，尤其是在初始图像重建质量受限时，会负面影响姿态估计的准确性，从而降低了3D重建的保真度。

Innovation: 
本文提出了一个名为USP-Gaussian的统一优化框架，将基于尖峰的图像重建、姿态矫正和高斯点划结合到一个端到端框架中。该框架利用3DGS带来的多视图一致性以及尖峰相机的运动捕捉能力，实现了图像重建网络和高斯点划之间的联合迭代优化。实验结果表明，该方法在合成数据集上能够有效消除级联误差，且在现实世界场景中能够通过姿态优化实现稳健的3D重建，相较于其他方法能够有效降低噪声并保留细微的纹理细节。

Conclusion: 
通过USP-Gaussian框架，合成了精确姿态的合成数据集上的实验结果表明，我们的方法超越了之前的方法，有效地消除了级联误差。此外，在现实场景中，通过姿态优化实现了稳健的3D重建，相比替代方法能有效降低噪声并保留细纹理细节。我们将在指定网站提供代码、数据和训练模型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.10504</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>278. cs.CV-移动摄影中的时间感知自动白平衡</title><link>https://arxiv.org/pdf/2504.05623</link><description>Background: 
摄像头依靠自动白平衡(AWB)来纠正场景照明和相机色谱敏感度导致的不自然色彩偏移。通常，这通过使用照明估计器来实现，该估计器仅从相机原始传感器图像的颜色信息中确定全局色彩偏移。移动设备提供有价值的附加元数据，如拍摄时间戳和地理位置，这些信息提供了强烈的情境线索，有助于缩小可能的照明解决方案范围。这项论文提出了一种轻量级的照明估计方法，该方法结合了这样的上下文元数据、附加的拍摄信息和图像颜色，构建了一个紧凑的模型（约5K参数），取得了令人满意的结果，达到了或超过了较大的模型。为了验证该方法，我们引入了一个包含3,224张智能手机图像的数据集，这些图像在一天的不同时间点和多种照明条件下收集了上下文元数据。数据集包括使用色彩图表确定的真实光照颜色和通过用户研究验证过的用户优选光照，为AWB评估提供了一个全面基准。

Innovation: 
论文提出了一种轻量级的照明估计方法，该方法结合了上下文元数据、附加的拍摄信息和图像颜色，构建了一个紧凑的模型（约5K参数），达到了或超过了较大的模型在AWB任务中的表现。该方法利用了移动设备收集的拍摄时间戳和地理位置信息，为自动白平衡算法提供了新的视角和改进手段。

Conclusion: 
论文通过创建一个包含3,224张智能手机图像的数据集，验证了提出的方法的有效性。该数据集包含了真实光照颜色和用户验证的偏好光照，为自动白平衡评估提供了新的基准。实验结果表明，提出的轻量级方法在多个方面表现良好，能够与或超越更大的模型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.05623</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>279. cs.CV-VLLMs中视觉和文本提示的作用以增强情感识别</title><link>https://arxiv.org/pdf/2504.17224</link><description>Background: 
视觉大型语言模型（VLLMs）在多模态理解方面显示出巨大的潜力，但在基于视频的情感识别应用中仍然受到空间和上下文感知不足的限制。传统方法侧重于孤立的人脸特征，忽略了诸如肢体语言、环境背景和社交互动等关键非言语线索，这降低了其在实际场景中的鲁棒性。

Innovation: 
为了解决这一问题，本文提出了一种名为Set-of-Vision-Text Prompting (SoVTP)的新框架，该框架通过将空间注释（如边界框、面部特征点）、生理信号（面部动作单位）和上下文线索（肢体姿势、场景动态和他人的感情）整合到统一的提示策略中，提高了零样本情感识别的能力。SoVTP在保持整体场景信息的同时，还能进行细致入微的人脸肌肉运动分析和人际关系动态分析，实验结果显示，SoVTP在视频情感识别能力上显著优于现有的视觉提示方法，验证了其有效性。

Conclusion: 
SoVTP在实时场景下的情感识别能力方面大幅提升了VLLMs的表现，表明该方法在增强视频的情感识别能力方面具有显著的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.17224</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>280. cs.CV-Large Vision-Language Models中的形状和纹理识别</title><link>https://arxiv.org/pdf/2503.23062</link><description>Background: 
形状和纹理是视觉感知的基本构建块。能够无方向、纹理或上下文约束地识别形状，独立地识别纹理和材料对于理解世界是至关重要的。本研究引入了 Large Shape and Textures (LAS&amp;amp;T) 数据集，该数据集通过从自然图像中无监督提取模式创建了大量的多样化的形状和纹理。该数据集用于评估领先的大规模视觉-语言模型(LVLM)在二维和三维场景中对形状、纹理和材料的理解能力。研究表明，LVLM的形状识别能力远低于人类水平，而材料识别在三维场景中接近人类水平，但在二维抽象纹理识别上远逊于人类。这些成果在多个领先的视觉模型上得到了验证，揭示了当前模型在理解和掌握基础视觉概念方面存在重大缺陷，简单的专门训练网络在这类任务中表现更佳。

Innovation: 
提出了名为 LAS&amp;amp;T 的大规模形状和纹理数据集，用于评估大规模视觉-语言模型在形状、纹理和材料识别上的能力。该数据集由自然图像中的模式无监督提取而成，包含超过600,000张图片，覆盖面广，可用于强大的视觉模型的基准测试。

Conclusion: 
大型视觉-语言模型在形状识别上远低于人类性能，但在材料识别上接近人类水平。模型主要依赖于高级语义特征，难以处理抽象的形状和简单的二维纹理。虽然某些简单网络在专门任务中表现优异，但整体而言，当前的大型视觉模型在理解基本视觉概念方面存在明显不足。该数据集在未来的研究中将被公开使用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.23062</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>281. cs.CV-皮肤图像中的皮肤颜色测量：基于合成数据集的评估</title><link>https://arxiv.org/pdf/2504.04494</link><description>Background: 
本文研究了从表皮显微镜图像中测量皮肤颜色的方法。利用控制熔色素含量、病灶形状、毛发模型和18种不同照明条件的一个合成数据集（S-SYNTH），对各种肤色测量方法进行了全面评估。此数据集允许严格评估方法在不同照明条件下的鲁棒性和不变性。评估了四类图像颜色度量方法：基于分割的方法，基于补丁的方法，颜色量化，以及神经网络。这些方法用于从表皮显微镜图像中估计个体颜色类型角度（ITA）和费茨帕特里克类型。结果表明，基于分割和颜色量化的方法能产生稳健且照明不敏感的估计值，而基于补丁的方法表现出显著的照明依赖偏差，需要校准。另外，结合重度模糊的神经网络模型可以提供照明不敏感的费茨帕特里克预测，并能改善过拟合问题，但其在实际图像上的泛化能力尚未得到验证。

Innovation: 
本文创建了一个控制变量的合成数据集，以评估不同肤色测量方法在不同照明条件下的鲁棒性和不变性，并比较了多种方法的表现，特别关注了神经网络模型的有效性。作者提出了一种结合重度模糊的方法来提高神经网络模型的泛化能力和鲁棒性。此外，还提供了一系列实用建议，指导设计公平可靠的皮肤颜色估计方法。

Conclusion: 
本文的结果表明，基于分割和颜色量化的方法较为稳健，而基于补丁的方法需要照明校准。神经网络模型在适当的模糊处理下可以提供光照不敏感的预测，但在实际场景中的表现尚需进一步验证。研究者提出了设计公平、可靠的皮肤颜色估计方法的实用建议。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.04494</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>282. cs.CV-MaizeField3D：多样化群体中田间种植玉米的3D点云和过程模型数据集</title><link>https://arxiv.org/pdf/2503.07813</link><description>Background: 
人工智能（AI）和机器学习（ML）在玉米3D表型分析中的应用发展受限，主要是由于缺乏大量和多样化的3D数据集。2D图像数据集无法捕捉3D数据提供的诸如叶片结构、植物体积和空间布局等关键结构细节。因此，为解决这一限制，本文介绍了MaizeField3D，一个针对多样化遗传群体的田间种植玉米的3D点云数据集，旨在促进农业研究。该数据集包含1045个高质量的田间生长玉米3D点云，使用地面激光扫描仪（TLS）采集。

Innovation: 
MaizeField3D数据集通过使用地面激光扫描仪捕捉关键结构细节，为玉米提供了高质量的3D点云数据，这有助于3D表型分析和植物结构分析。该数据集包含520株植物的分割和注释，确保了所有样本的一致标签，并使用基于图的方法进行了分割和注释。同时，通过非均匀有理B样条（NURBS）表面及两步优化过程生成的叶片，提供了结构参数化表示。该数据集还在多个分辨率级别包括元数据和点云数据，为不同的后续计算任务提供了便利。

Conclusion: 
MaizeField3D将成为AI驱动的玉米表型分析、植物结构分析以及农业研究中3D应用的基础数据集。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.07813</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>283. cs.CV-LPOSS: 在图像和像素级别传播标签的开放词汇语义分割</title><link>https://arxiv.org/pdf/2503.19777</link><description>Background: 
现有的基于视觉-语言模型（VLM）的开放词汇语义分割方法通常需要训练，而VLMs主要是为跨模态对齐优化，而不是为了模内相似性优化。尽管有方法考虑了部分优化，但它们大多依赖于窗口处理，这限制了对图像全局上下文交互的捕捉。此外，基于块的编码器受到分辨率限制，这影响了分割的准确性，特别是在类边界附近。因此，如何在不需要训练的情况下有效进行开放词汇语义分割，成为了该研究领域的挑战。

Innovation: 
该论文提出了一个无需训练的方法LPOSS+，通过标签传播增强VLM的初始预测，并利用视图模型（VM）捕捉块到块的关系。标签传播不仅在块级层面进行，还在像素级层面进行，以提高分辨率较低区域的分割准确性。LPOSS+通过在整个图像上进行推理，而不是基于窗口的方式，成功捕捉到了全局上下文交互，从而提高了分割性能。实验结果表明，LPOSS+在多种数据集上实现了最先进的性能，优于现有的训练免费方法。

Conclusion: 
LPOSS+方法通过结合块级和像素级标签传播，显著提高了开放词汇语义分割的性能，特别是在图像边界附近的分割精度上。该方法提供了一种有效的方式，可以在不依赖于模型训练的情况下进行开放词汇语义分割，同时捕捉到图像的全局上下文交互。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.19777</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>284. cs.CV-MatSwap: 考虑光线的图像中材料转移</title><link>https://arxiv.org/pdf/2502.07784</link><description>Background: 
在图像中将材料转移至指定表面的任务具有挑战性，因为画面材料外观、几何形状和照明存在复杂的纠缠。以往的材料编辑方法要么依赖复杂的文本工程，要么需要大量的手工标注，这需要艺术家的知识以及难以获取的3D场景属性。本研究旨在提出一种直接学习输入材料与其在场景中外观之间关系的方法，无需进行明确的UV映射。为了实现这一点，研究中采用了自定义的光照和几何感知扩散模型，并借助合成数据集对大规模预训练的文本到图像模型进行微调，以确保该方法能够有效地应用到真实图片中。

Innovation: 
本方法无需明确的UV映射即可将目标材料无缝融入照片中的指定位置，同时保留场景身份。该方法依赖于一种自定制的光照和几何感知扩散模型，通过合成数据集对大规模预训练的文本到图像模型进行微调。这种方法能够在合成和真实图像上进行评估，并在定性和定量上均表现出色。该方法的代码和数据已公开提供。

Conclusion: 
本方法能够在照片中指定位置无缝地集成所需材料，并保持场景的身份。通过合成数据集对大规模预训练的文本到图像模型进行微调，确保了有效的一般性。实验结果表明，该方法在合成和真实图像上均表现出色。代码和数据已公开提供，以便其他人进行参考和研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.07784</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>285. cs.CV-使用 Siamese 网络检测两幅虹膜图像是否为同卵双胞胎</title><link>https://arxiv.org/pdf/2503.09749</link><description>Background: 
传统上，在比对虹膜时，同一人的左右眼虹膜被视为与其他人的虹膜一样不同。然而，研究显示人类可以识别出来自同一个人或同卵双胞胎的两幅虹膜图像是不同的，准确率为约80%。本研究致力于自动分类技术，以确定一对虹膜图像是否来自同卵双胞胎，解决生物识别中未解决的问题。

Innovation: 
本研究采用 Siamese 网络架构和对比学习，设计了一个自动分类器，以区分同卵双胞胎和非同卵双胞胎的虹膜图像。研究通过合成同卵双胞胎图像对、双胞胎的自然虹膜图像对以及非同卵双胞胎的图像对构建了一个全面的测试集，以评估模型的能力。研究还通过三种不同的模型训练方法（原始输入图像、仅虹膜图像和非仅虹膜图像）来分析模型的学习表示，结果显示虹膜纹理和周围眼部结构的信息对于模型进行分类是有用的。

Conclusion: 
本研究使用完整的虹膜图像的方法达到了超越人类对同卵双胞胎虹膜图像分类的准确性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.09749</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>286. cs.CV-通过解耦表示实现眼科疾病分级的鲁棒多模态学习</title><link>https://arxiv.org/pdf/2503.05319</link><description>Background: 
本文讨论了眼科医生在实际应用中如何依赖多模态数据来提高诊断准确性。然而，由于缺乏医疗设备以及对数据隐私的担忧，完整多模态数据在实际应用中很少见。传统深度学习方法通常通过学习潜在空间中的表示来解决这些问题。但是，这些方法存在两个关键局限性：（i）复杂模态中的任务无关冗余信息（例如，大量的切片），导致潜在空间表示中的显著冗余。（ii）重叠的多模态表示使得很难提取每种模态的特有特征。

Innovation: 
为了克服这些挑战，作者提出了一种名为Essence-Point和解耦表示学习（EDRL）的策略，该策略将自我蒸馏机制集成到端到端框架中，以增强特征选择和分解，从而提高多模态学习的鲁棒性。Essence-Point表示学习模块选择可区分特征以提高疾病分级性能。解耦表示学习模块将多模态数据分解为模态共有的和模态特有的表示，从而减少特征的纠缠，并增强在眼科疾病诊断中的稳定性和可解释性。

Conclusion: 
在多模态眼科数据集上的实验表明，提出的方法EDRL显著优于当前最先进的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.05319</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>287. cs.CV-从O(n^2)到O(n)参数：用于生物医学图像分类的视觉变换器中的量子自我注意</title><link>https://arxiv.org/pdf/2503.07294</link><description>Background: 
本研究背景在于，现有的生物医学图像分类器在参数使用上存在巨大浪费。研究人员通过引入量子自注意力机制Quantum Self-Attention (QSA)，试图减少参数量，同时保持甚至提高模型的性能。

Innovation: 
论文创新点在于提出了量子视觉变换器（QViT），通过将传统视觉变换器（ViT）中的线性自注意力（SA）层替换成参数化的量子神经网络（QNN），实现了参数效率的显著提升。QSA机制将参数缩放从O(n^2)降低至O(n)，并且在多个数据集上展示了与经典ViT相当或更佳的表现。特别是在RetinaMNIST数据集上，QViT模型的参数效率更是达到了惊人的99.99%，即参数量减少了99.99%，体积仅为1K，而准确率仅0.88%低于当前最佳模型，同时FLOPs减少了89%。此外，论文还首次探讨了从经典模型到量子模型的知识蒸馏（KD），并发现量子模型在更多的数据集上保持了与经典模型相当的性能。

Conclusion: 
这些研究成果确立了量子自我注意力机制作为一种针对参数高效生物医学图像分析的实用架构选择。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.07294</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>288. cs.CV-通过全球视角审视扩散模型：它们在文化包容性方面做得如何？</title><link>https://arxiv.org/pdf/2502.08914</link><description>Background: 
文本到图像的扩散模型最近能够从文本提示生成视觉上引人注目、细节丰富的图像。然而，关于这些模型是否能够准确表现出各种文化细微差别的问题仍然存在。这项研究介绍了一个名为CultDiff的基准测试，评估最新的扩散模型是否能够生成涵盖十个国家的文化特定图像。研究结果显示，这些模型往往在建筑、服装和食物等文化元素上生成表现不佳，特别是在代表性不足的国家地区，通过对不同相似度方面的精细分析，发现生成图像与真实世界的参考图像在文化相关性、描述准确性以及现实性方面存在显著差距。

Innovation: 
研究引入了一个名为CultDiff的基准测试，用于评估最先进的扩散模型是否能够生成涵盖十个国家的文化特定图像。研究开发了一个基于神经网络的图像-图像相似度度量工具，称为CultDiff-S，以预测关于包含文化论断的人类判断的真实图像和生成图像之间的相似度。

Conclusion: 
这项研究突显了对更具包容性的生成人工智能系统以及广泛文化背景下公平数据集表示的需求。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.08914</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>289. cs.CV-FGS-SLAM: 基于傅里叶变换的高斯光斑实时SLAM及其稀疏稠密地图融合</title><link>https://arxiv.org/pdf/2503.01109</link><description>Background: 
3D高斯光斑技术提升了 simultaneous localization and mapping（SLAM）技术，实现了实时定位和高保真地图构建。然而，高斯位置不确定性和初始化参数的不精确性带来了挑战，常常需要大量迭代收敛，导致高斯表示冗余或不足。

Innovation: 
引入了一种基于傅里叶频域分析的自适应稠密化方法以建立高斯先验实现快速收敛。此外，提出构建独立且统一的稀疏和稠密地图，其中稀疏地图通过广义迭代最近点（GICP）支持高效跟踪，稠密地图生成高保真视觉表示。这是首次利用频域分析实现高时效高质量高斯映射的SLAM系统。

Conclusion: 
实验结果表明，该系统在Replica和TUM RGB-D数据集上的平均帧率为36 FPS，实现了定位和制图的竞争力水平。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.01109</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>290. cs.CV-VISCA：生成报告中无人类反馈的胸片异常的视觉解释与理解</title><link>https://arxiv.org/pdf/2501.17726</link><description>Background: 
随着人工智能在医疗保健中的作用日益重要，可解释和可信赖的模型变得至关重要。当前的胸片（CXR）报告生成系统缺乏在缺乏专家监督的情况下验证输出的机制，这引发了可靠性和可解释性方面的担忧。本研究旨在解决这些问题，介绍了一个新的多模态框架，该框架旨在增强由AI生成的医疗报告的语义对齐和病灶定位准确性。该框架结合了两个关键模块：短语固着模型和文本到图像扩散模块。通过比较原始和生成图像之间的特征，提出了一种双重评分系统，用于量化定位准确性并评估语义一致性，从而显著优于现有方法，实现了病理定位和文本到图像对齐方面的最新成果。

Innovation: 
提出了一个多模态框架，结合了短语固着模型和文本到图像扩散模块，通过双重评分系统实现了病理定位和语义对齐的最新成果。这种新的方法提供了验证报告质量的稳健机制，有助于提高医疗成像中AI的可信度和透明度。

Conclusion: 
该研究介绍的多模态框架显著提升了AI生成的医学报告的可靠性和可解释性，为构建更可信赖和透明的医疗成像AI奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.17726</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>291. cs.CV-无匹配的结构光深度恢复</title><link>https://arxiv.org/pdf/2501.07113</link><description>Background: 
本文介绍了一种新的方法，用于通过单目结构光系统的图像进行深度估计。不同于许多依赖图像匹配的方法，该技术使用密度体积网格来表示场景几何。这种网格通过自我监督可微的体绘制技术进行训练。该方法利用结构光系统投影模式产生的颜色场，在绘制过程中促进几何字段的独立优化，从而实现更快的收敛性和高质量的结果。此外，研究中还集成了归一化设备坐标(NDC)、失真损失和基于表面的颜色损失，以增强几何保真度。实验结果表明，该方法在几何性能方面优于现有的基于匹配的技术，在少量样本场景中平均估计深度误差降低约30%，适用于合成场景和真实场景。此外，该方法能够快速训练，比以前的非匹配方法使用隐式表示快约三倍。

Innovation: 
本文提出了一种新颖的方法，利用密度体积网格进行深度估计，通过自我监督可微的体绘制技术进行训练，并利用结构光系统投影模式产生的颜色场来优化几何字段，从而提高收敛速度和几何保真度。此外，还通过归一化设备坐标(NDC)、失真损失和表面颜色损失来增强几何保真度，实验结果证明该方法在几何性能方面优于现有的基于匹配的技术。

Conclusion: 
本文介绍了无匹配的结构光深度恢复方法，证明了该方法在几何性能方面显著优于传统的基于匹配的方法，尤其是在少量样本场景中表现突出，同时训练速度快，接近三倍于之前的非匹配方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.07113</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>292. cs.CV-基于果断生成模型的具有保障的图像超分辨率</title><link>https://arxiv.org/pdf/2502.09664</link><description>Background: 
生成式ML基础模型在图像恢复任务如超分辨率方面的使用越来越多，这要求有稳健且可解释的不确定性量化方法。本文背景在于当前需要一种既能可靠又能直观地传达生成图像可信度的方法。

Innovation: 
提出了一种基于收敛预测技术的新方法，能够创建‘置信度蒙版’，有效地传达生成图像的可信度。该方法适用于任何黑盒生成模型，包括那些被不透明API限制的模型，只需少量数据进行校准，还具有通过选择局部图像相似度度量进行高度自定义的功能。该方法还提供了广泛且强大的理论保证，包括保真误差控制、重建质量以及在数据泄露面前的鲁棒性。

Conclusion: 
通过实验评估证明了该方法的性能，并表明所提出的方法表现优异。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.09664</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>293. cs.CV-基于AI的像素级保护健康信息检测系统设计探索</title><link>https://arxiv.org/pdf/2501.09552</link><description>Background: 
医学图像中的去标识化是确保研究和临床环境中数据共享隐私的关键步骤。此过程的第一步是检测受保护的健康信息（PHI），这些信息可能存在于图像元数据中或直接嵌入图像像素中。尽管这一系统的重要性，但现有基于AI的解决方案还很少得到评估，这阻碍了开发出可靠且稳健工具的进步。因此，需要对现有系统进行深入研究，以促进该领域的发展。

Innovation: 
本文介绍了一种基于AI的PHI检测管道，由三个核心模块组成：文本检测、文本提取和文本分析。通过使用不同的模型（YOLOv11、EasyOCR和GPT-4o）进行基准测试，并在评估不同数据集中的表现后，研究发现最佳设置是为每个模块专门使用视觉和语言模型，从而在性能、延迟和使用大规模语言模型的成本之间实现良好的平衡。此外，研究还表明，将大规模语言模型应用于该系统不仅限于识别PHI内容，还增强了OCR任务，并促进了端到端的PHI检测流程，展示了令人鼓舞的结果。

Conclusion: 
研究结果表明，结合视觉和语言模型的设置在性能、延迟和成本方面表现出色，能够有效检测像素级别的PHI信息。该研究通过引入跨模块使用专门的大规模语言模型，促进了PHI检测技术的改进，并展示了利用大规模语言模型增强OCR任务和端到端检测的能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.09552</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>294. cs.CV-世界一致性数据生成方法在视觉语言导航中的应用</title><link>https://arxiv.org/pdf/2412.06413</link><description>Background: 
视觉语言导航(VLN)任务要求代理遵循自然语言指令穿越写实环境。一个主要障碍是数据稀缺，导致在未见过的环境中泛化表现不佳。尽管数据增强是扩大数据集的一种有前景的方式，但生成既有多样性又符合现实世界的数据仍然是个问题。为了应对这一挑战，我们提出了世界一致性数据生成(WCGEN)，一个满足多样性和现实一致性要求的有效数据增强框架，旨在增强代理在新环境中的泛化能力。该框架主要分为两个阶段：利用基于点云的技术确保视角间的空间连贯性，以及采用新的角度合成方法保证观察视角之间的空间和环绕一致性。通过准确预测三维空间变化，我们的方法在生成过程中保持了现实一致性。

Innovation: 
我们提出的WCGEN框架，通过结合基于点云的技术确保空间连贯性，以及引入新颖的角度合成方法保证空间和环绕一致性，来生成具有多样性和世界一致性的数据。这种方法通过准确预测三维空间变化维持生成过程中的世界一致性。实验结果表明，我们的方法能够有效提升代理在多种导航任务中的泛化能力，使其在未见过的环境中表现更佳。

Conclusion: 
我们的实验在多种数据集中验证了方法的有效性，证明我们的数据增强策略使代理在所有导航任务上均达到了新的最先进水平，并提高了VLN代理在未见过环境中的泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.06413</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>295. cs.CV-toddlers' active gaze behavior supports self-supervised object learning</title><link>https://arxiv.org/pdf/2411.01969</link><description>Background: 
幼儿通过很少的监督就能学会从不同视角识别物体，在这个过程中，他们频繁地进行眼睛和头部运动来塑造他们的视觉体验。目前尚不清楚这些行为如何促进幼儿的物体识别能力的发展。为了回答这一问题，本研究结合了活动眼动追踪技术与无监督机器学习方法，通过评估幼儿的注视策略来支持端到端的物体学习。研究使用头戴式相机捕获视角并配合无监督模型生成物体的不变特征表示，揭示了幼儿的注视行为如何支持它们的物体认知发展。研究表明，高分辨率视网膜中心视野对于形成不变的物体表征至关重要。这项工作揭示了幼儿注视行为支持其形成视角不变物体识别的关键机制。

Innovation: 
本研究创新性地将头戴式眼动追踪技术与无监督机器学习方法相结合，通过模仿幼儿的中央视觉场经验，分析幼儿的注视策略如何支持对物体不变特征的学习，并强调高分辨率视网膜中心视野在形成物体不变表示中的重要性。以往研究并没有充分关注这些细节问题，本研究填补了该领域的空白，为理解幼儿视觉认知发展提供了新的视角。通过构建基于视觉体验的无监督学习模型，本研究揭示了幼儿注视行为对物体识别能力形成的重要作用，这是直接利用实时数据直接驱动学习进程的一项进步。本研究的结果为设计儿童适应性学习环境提供了依据，这对教育科技领域具有重要意义。

Conclusion: 
本研究证实了幼儿的注视策略有助于构建视角不变的物体表征。研究表明，高分辨率的中央视觉场是这一过程的关键。这些发现揭示了幼儿注视行为如何支持其物体认知的发展，并为进一步研究提供方向。未来工作可以在更大规模和更多样化的样本中进行，以验证这些结果的普遍性，并进一步探索注视策略如何具体促进物体识别的不同方面。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.01969</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>296. cs.CV-基于通道感知指导的自适应照明学习</title><link>https://arxiv.org/pdf/2412.01493</link><description>Background: 
实现良好的视觉感知和支撑下游视觉任务的关键步骤是学习光照适应。当前的研究往往单独处理与光照相关的问题，如高动态范围成像和曝光校正等问题，而未能认识到这些任务中共享的基本特性，包括不同颜色通道具有不同的光照属性，以及这些属性在空间和频率域中的表现形式也不同。

Innovation: 
提出了通道意识的自适应照明学习网络（LALNet），这是一个多任务框架，能够高效地处理多个与光照相关的问题。LALNet将色彩分离特征与传统色彩混合特征结合，并使用光照引导注意（LGA）来利用色彩分离特征来引导色彩混合特征聚焦于通道差异，确保所有通道之间视觉的一致性。此外，LALNet还采用了双域通道调制来生成色彩分离特征，并使用混合通道调制和光照状态空间模块来生成色彩混合特征。该网络在多个光照相关的任务中表现出显著优于现有方法的性能，并且需要更少的计算资源。

Conclusion: 
在四个代表性的光照相关任务上进行了广泛的实验，结果表明LALNet在基准测试中显著优于现有方法，并且在计算资源方面具有优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.01493</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>297. cs.CV-ULSR-GS: 多视几何一致性支持的大规模表面重构高斯点积</title><link>https://arxiv.org/pdf/2412.01402</link><description>Background: 
虽然高斯点积（GS）在场景渲染和小区域表面提取方面表现出高效性和高质量，但它在处理大规模航空图像表面提取任务时存在不足。因此需要提出一种新的框架来克服这一问题，该框架专注于大规模场景的高保真度表面提取，旨在解决现有基于GS的网格提取方法的局限性。

Innovation: 
本文提出了ULSR-GS框架，通过结合点到照片的分区方法与多视图最优视图匹配原则，为每个子区域选择最佳训练图像。此外，在训练过程中，ULSR-GS采用基于多视几何一致性的稠密化策略来增强表面提取细节。实验结果表明，ULSR-GS在大规模航空摄影测量基准数据集上优于其他最先进的GS方法，特别是在复杂的城市环境中显著提高了表面提取的准确性。

Conclusion: 
ULSR-GS通过多视几何一致性在大规模场景中实现了高保真度的表面提取，显著提高了复杂城市环境中的表面提取精度，并优于其他基于GS的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.01402</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>298. cs.CV-MagicPose4D: 使用外观和运动控制构建活动模型</title><link>https://arxiv.org/pdf/2405.14017</link><description>Background: 
随着2D和3D视觉生成模型的成功，对生成4D内容的兴趣日益增加。现有方法主要依赖文本提示生成4D内容，但往往难以精确定义复杂的或罕见的运动模式。现有方法的这一局限性促使我们提出了MagicPose4D，这是一种新型框架，旨在对4D生成中的外观和运动的精致控制提供支持。该框架通过使用单目视频或网格序列作为运动提示，实现了精确和可定制的运动控制，从而解决了现有方法的限制。

Innovation: 
MagicPose4D 引入了两个关键模块：(i) 双阶段4D重建模块，该模块分为两个阶段。第一阶段侧重于使用准确的2D监督和几何信息丰富的3D伪监督捕捉模型的形状，不施加骨骼约束；第二阶段通过在第一阶段获得的更准确的伪3D监督并引入基于运动链的骨骼约束来提取3D运动（骨骼姿势），确保物理合理。此外，还提出了一种全局-局部Chamfer损失，以使预测网格顶点的整体分布与监督对齐，同时保持部分级别的对齐，无需额外注释。(ii) 跨类别运动转换模块，该模块利用4D重建模块提取的运动，并使用基于运动链的骨骼实现跨类别的运动转换，确保帧之间的平滑过渡，从而在无需额外训练的情况下实现鲁棒泛化。

Conclusion: 
通过广泛的实验，我们展示了MagicPose4D在4D内容生成的准确性和一致性方面取得了显著改进，优于现有方法，在各种基准测试中表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.14017</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>299. cs.CV-ReconX: 使用视频扩散模型从稀疏视角重建任意场景</title><link>https://arxiv.org/pdf/2408.16767</link><description>Background: 
三维场景重建的进步已经将现实世界的2D图像转化为了3D模型，并能够从数百张输入照片中生成逼真的3D结果。然而，在视角不足的情况下，这种方式仍无法详细准确地重建场景，导致未见区域存在伪影和失真。论文基于这个问题定义了一个全新的三维场景重建框架ReconX，通过引入大规模预训练视频扩散模型的强大生成先验解决稀疏视角下的三维重建问题，并确保重建场景的连贯性，同时从生成的视频中通过置信度感知的3D高斯散点优化方案恢复3D场景，展示了其在质量上超越当前最先进方法的优越性。

Innovation: 
ReconX 是一种新的三维场景重建方法，将模糊的三维重建挑战重新定义为一个时间生成任务。它利用大规模预训练视频扩散模型的强大生成先验，在稀疏视角下重建三维场景。首先，它构建了一个全局点云并将其编码到上下文空间作为三维结构条件。然后，通过这个条件，视频扩散模型生成既保留了详细信息又具有高3D一致性的视频帧，以确保从不同视角的场景连贯性。最后，通过置信度感知的3D高斯散点优化方案从生成的视频恢复三维场景。

Conclusion: 
在多种真实世界数据集上的广泛实验表明，ReconX 在质量和泛化能力上都优于现行的最先进方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.16767</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>300. cs.CV-GlyphPattern: Vision-Language模型中抽象模式识别基准</title><link>https://arxiv.org/pdf/2408.05894</link><description>Background: 
基于大型语言模型的强大基础，视觉-语言模型（VLMs）在跨视觉和文本数据推理方面取得了快速进展。尽管在训练任务上的表现良好，我们的结果揭示了VLMs在抽象模式识别上的关键挑战。为了评估这一领域，作者提出了GlyphPattern数据集，包含318个人写的描述40种书写系统中的视觉模式的描述，并配有三种视觉展示风格。该数据集的模式来源于大规模的认知科学研究，因此富含空间参照和组合性，能够挑战现有的VLMs（GPT-4o的准确率为55%，且少量提示几乎没有改进），并揭示了视觉处理、自然语言理解和模式泛化的多层次挑战。

Innovation: 
该文章的创新之处在于提出了GlyphPattern数据集，这是一个954项的语料库，旨在评估VLMs在抽象模式识别上的能力，通过非语言描述的视觉模式挑战现有模型。数据集中的模式源自大规模的认知科学研究，展示了丰富的空间参考和组合性。实验结果表明，尽管现有VLMs的准确率较低（如GPT-4o仅为55%），并且少量提示几乎没有改进，但这为理解VLMs在处理模式识别任务上的局限性提供了重要线索。

Conclusion: 
我们的实验表明，现有的VLMs在抽象模式识别上存在显著挑战（如GPT-4o的准确率仅为55%），并且即使通过少量提示几乎没有改善。详细的错误分析揭示了在视觉处理、自然语言理解和模式泛化等方面的多层次困难。因此，需要进一步的研究来克服这些挑战，并提升VLMs在抽象模式识别任务上的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.05894</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>301. cs.CV-FluoroSAM: 一种用于灵活X射线图像分割的语言提示型基础模型</title><link>https://arxiv.org/pdf/2403.08059</link><description>Background: 
现有的任务特定模型能够在狭窄的范围内解决特定问题，但扩展到更广泛的应用需要额外的数据、注释和训练时间。目前的医学影像分析基础模型主要集中于大量丰富注释数据可用的场景和成像模态。对于X射线成像，不同应用场景下的影像特征和数据可用性差异很大，从诊断胸部X射线到介入性血管造影。语言对齐的基础模型（LFMs）作为一种基于大量高度变化的图像和文本数据训练的机器学习模型，为泛用的自动化影像分析提供了新的可能。

Innovation: 
FluoroSAM，一种基于Segment Anything Model训练出的语言提示型X射线图像分割基础模型，首次从300万合成X射线图像数据开始训练，涵盖多种人体解剖学、成像几何和视角。模型通过引入文本嵌入的向量量化（VQ）训练过程，能够基于自然语言提示分割出多种医学影像中的解剖结构和工具。FluoroSAM为灵活的X射线图像分割和分析流程提供了新方法，促进了丰富的人机互动在X射线影像获取和分析中的应用。

Conclusion: 
FluoroSAM在实际X射线影像上的性能表现良好，并展示了其在多个应用中的潜力，成为X射线图像获取和分析流程中的关键使能者。项目代码已公开，可以在指定链接下载。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.08059</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>302. cs.CV-MambaMorph: 基于Mamba的医学MR-CT变形配准框架</title><link>https://arxiv.org/pdf/2401.13934</link><description>Background: 
在医学图像分析中，跨不同模态的体素级空间对应关系捕获至关重要。然而，当前的配准方法在配准精度和临床上的应用方面还不足够实用。因此，需要开发一种新的多模态变形配准框架，以解决这些问题，并提高配准的准确性及临床适用性

Innovation: 
本文介绍了一种新颖的多模态变形配准框架MambaMorph。该框架利用了一个基于Mamba的配准模块和一个精细但简单的特征提取器，分别用于高效建模远距离对应关系和高维特征学习。此外，还开发了一个脑MR-CT配准数据集SR-Reg，以解决多模态配准中数据稀缺的问题。实验结果表明，MambaMorph在配准精度方面显著优于当前的基于学习的配准方法，同时保持了合理的工作效率和计算成本

Conclusion: 
我们相信MambaMorph在医学图像配准的实际应用中有很大的潜力。MambaMorph的代码可以在指定的链接中获取。</description><guid isPermaLink="true">https://arxiv.org/pdf/2401.13934</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>303. cs.CV-Neural Graph Map: 密集映射与高效闭环约束整合</title><link>https://arxiv.org/pdf/2405.03633</link><description>Background: 
神经场基局部地图构建（SLAM）方法通常使用单一、集成的神经场作为场景表示，这限制了闭环约束的高效整合能力并限制了方法的可扩展性。为了解决这些问题，本文提出了一种用于RGB-D的新型神经制图框架，该框架使用一组轻量级的神经场来表示场景，这些神经场动态锚定到稀疏视觉SLAM系统的姿态图中，从而提高了大尺度场景中的闭环约束整合能力，同时仅需少量重新整合。该方法在大规模场景上的质量与运行时间方面也超越了现有最先进的方法。

Innovation: 
本文提出了一种新颖的RGB-D神经制图框架，使用一组轻量级神经场动态锚定到稀疏视觉SLAM系统的姿态图中，以实现大规模场景中的高效闭环约束整合，这种方法需要的重新整合非常少，并且已经在大规模场景中进行了验证，证明了其优越性。

Conclusion: 
本文提出的方法在大规模场景映射中表现出良好性能，能够整合多环约束，并且在运行时间和制图质量上都超过了现有最先进的方法。此外，有关代码已公开提供。</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.03633</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>304. cs.CV-可见和红外图像馈入中的低光行人检测：问题与挑战</title><link>https://arxiv.org/pdf/2311.08557</link><description>Background: 
行人检测已成为自动驾驶、智能交通和交通监控等多个高级任务的基础。现有研究大多集中在使用可见图像进行行人检测，主要是在白天条件下。然而，当环境条件变为低光照或夜间时，这项任务变得尤为棘手。近年来，新的想法开始使用替代源，如远红外（FIR）温度传感器信号进行低光条件下的行人检测。本文回顾了低光行人检测方法的最新进展，系统地分类和分析了基于区域、非区域以及图学习的各种算法，并强调了它们的方法、实施问题和挑战。此外，本文还概述了可用于研究和开发先进行人检测算法的关键基准数据集，特别是针对低光情况的数据集。

Innovation: 
本文系统地分类和分析了基于区域、非区域以及图学习的方法，并且概述了可用于研究和开发基于低光情况下的行人检测算法的关键基准数据集。此外，文中还提到了使用远红外（FIR）温度传感器进行低光条件下的行人检测的新思路。

Conclusion: 
本文回顾了低光行人检测方法的最新进展，强调了这些方法的方法、实施问题和挑战，并为研究和开发针对低光情况的先进行人检测算法提供了关键基准数据集的指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2311.08557</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>305. cs.CV-HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction</title><link>https://arxiv.org/pdf/2506.20566</link><description>Background: 
实时人类感知对于有效的机器人-人类交互（HRI）至关重要。大型视觉-语言模型（VLMs）提供了广泛应用的感知能力，但常常伴随着高延迟的问题，这负面影响了用户体验并限制了其实用性。为了系统研究VLM在HRI中的感知能力及其性能-延迟权衡，本文引入了HRIBench，一个旨在评估视觉问答（VQA）基准，覆盖一系列关键性的HRI感知任务。该基准涵盖五个关键领域：非言语提示理解、口头指令理解、人-机器人物体关系理解、社会导航和人员识别。通过收集真实的HRI环境数据来构建HRIBench，并利用公开可用的数据显示库来支持其余四个领域，共创建了1000个VQA问题。

Innovation: 
本文提出了一个新的基准HRIBench，旨在评估视觉问答（VQA）模型在多种关键性的HRI感知任务上的能力和性能-延迟权衡。HRIBench涵盖了五个关键领域，包括非言语提示理解、口头指令理解、人-机器人物体关系理解、社会导航和人员识别。该基准利用真实世界环境中的数据创建非言语提示理解方面的数据，其余领域的数据则来自公开可用的数据集。此外，全面评估了当前最先进的闭源和开源VLMs，指出尽管这些模型具有广泛的适用性，但它们在核心感知能力方面仍然存在不足，且目前没有模型能够在实时部署中提供令人满意的性能-延迟权衡，表明未来研究需要更小、低延迟且具备增强的人类感知能力的VLMs的发展。

Conclusion: 
我们的结果表明，当前的模型仍无法提供可靠的实时性能，因此需要进一步的研究来开发更小、延迟更低、具备增强人类感知能力的VLMs。HRIBench和研究结果可以在 GitHub 仓库找到：this https URL.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20566</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>306. cs.CV-一种具备可追溯推理的罕见疾病诊断代理系统</title><link>https://arxiv.org/pdf/2506.20430</link><description>Background: 
全球范围内罕见疾病患者超过3亿人，但这类疾病的诊断面临极大的挑战，原因是其临床异质性、个例低发病率以及大部分临床医师对罕见疾病的不熟悉。

Innovation: 
该研究介绍了DeepRare，一种由大型语言模型（LLM）驱动的首个罕见疾病诊断代理系统。DeepRare具有处理异质临床输入的功能，并能生成有关罕见疾病的排名诊断假设，且附带透明的推理链，将中间分析步骤与可验证的医学证据联系起来。DeepRare由三个关键组件组成：中央主机、长期记忆模块以及专门的代理服务器，这些服务器负责特定领域的分析任务，并整合了逾40种专业工具和广泛的、最新更新的医学知识来源，确保可以访问最新临床信息。这种模块化和可扩展的设计在复杂的诊断推理中具有复杂性的同时保持了可追踪性和适应性。通过八个数据集的评估，系统在2919种疾病中展现了优异的诊断性能，在HPO（human phenotype ontology）基础评估中显著优于其他15种方法，如传统的生物信息学诊断工具、大型语言模型和其它代理系统，平均Recall@1得分为57.18%，比第二好的方法（推理大型语言模型）高23.79个百分点。在混合模态输入场景下，DeepRare的Recall@1得分为70.60%，而Exomiser的得分为53.20%。临床专家手动验证推理链达到了95.40%的共识。此外，DeepRare已被实现为用户友好的网络应用。

Conclusion: 
DeepRare系统为罕见疾病的诊断提供了高效的代理解决方案，在透明度和准确性方面都表现出色，将显著提高罕见疾病的诊断效率和准确性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20430</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>307. cs.CV-KD-DETR: Detection Transformer with Consistent Distillation Points Sampling</title><link>https://arxiv.org/pdf/2211.08071</link><description>Background: 
DETR是一种新兴的端到端变压器架构的物体检测器，其性能在扩大规模后显著超过了经典检测器。尽管知识蒸馏在经典检测器中已有深入研究，但关于如何有效将其应用于DETR的研究尚属少数。本文主要关注如何使用知识蒸馏压缩DETR，并强调了缺乏一致的蒸馏点是DETR蒸馏的主要挑战。唯一的蒸馏点需要在教师网络和学生网络之间保持一致，但由于DETR和CNN检测器中的蒸馏点有不同的表示形式，这一点难以保证。

Innovation: 
本文提出了第一个适用于DETR的知识蒸馏框架（KD-DETR），通过一致的蒸馏点采样策略，包括将检测任务和蒸馏任务解耦的方法，并提出了一般到具体的蒸馏点采样策略。这一框架分别应用于单一尺度和多尺度的DAB-DETR和Deformable DETR及DINO模型中，均取得了性能提升。此外，还扩展了KD-DETR到不同模型之间的知识传输，如从DINO到Faster R-CNN（ResNet-50），取得了2.1%的性能提升，这一提升与同构蒸馏相当。代码可以在相关网址获取。

Conclusion: 
KD-DETR通过一致的蒸馏点采样策略增强了DETR模型的性能，并在各种模型上展示了广泛的应用潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2211.08071</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>308. cs.CV-EditP23: 通过图像提示在多视图中传播进行3D编辑</title><link>https://arxiv.org/pdf/2506.20652</link><description>Background: 
传统的方法依赖于基于文本的提示或显式的空间掩码来进行3D编辑，这些方法通常较为复杂且难以实现直观的编辑效果。EditP23通过利用两张图像作为条件输入：原始视图和经过用户编辑的视图，来实现直观的3D编辑，这种方法可以指导预训练的多视图扩散模型中的编辑感知流动，从而使编辑效果在不同视图之间保持一致性。

Innovation: 
EditP23在不使用优化的前提下，通过图像提示直接在多视图扩散模型的潜在空间中引导编辑流动，实现了无掩码的3D编辑。这种方法无需传统方法中的基于文本的提示或显式空间掩码，能够实现结构和外观的保留，且能在不同的物体类别和编辑场景下展现出高度的真实性与精确性。

Conclusion: 
通过实验证明，EditP23方法在多种物体种类和编辑场景下能够实现高度保真的编辑效果，且无需手动掩码，这提高了3D编辑的简便性和直观性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20652</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>309. cs.CV-在胎儿超声图像中融合放射组学特征与深度表示以估计孕周</title><link>https://arxiv.org/pdf/2506.20407</link><description>Background: 
准确的孕周（GA）估计对于提供优秀的产前护理至关重要，而孕妇通过胎儿超声波测量获得。然而，通过手动胎儿生物测量所得的孕周依赖于操作者的技能，耗时且准确性受限。因此，在临床实践中需要自动的计算机辅助方法。本文提出了一种新颖的特征融合框架，用于在没有任何测量信息的情况下，通过胎儿超声图像估计孕周。研究表明白天和夜间工作表现、不同季节对记忆的影响。该框架能够在三个孕期中实现平均绝对误差为8.0天的孕周估计，超过当前基于机器学习的方法。实验结果显示，该框架在不同人群和不同地理区域中具有稳健性。本文代码已公开发布在GitHub上。

Innovation: 
本文提出了一种新颖的特征融合框架，采用深度学习模型从超声图像中提取深度表示，同时提取放射组学特征以揭示胎儿大脑生长模式。通过融合放射组学特征和深度表征来估计孕周，该方法在三个孕期中的平均绝对误差为8.0天，优于当前基于机器学习的方法。该方法展示了在不同人群和不同地理区域中的鲁棒性。

Conclusion: 
本文提出的方法在胎儿超声图像中融合了放射组学特征和深度表示，以估计孕周。实验结果表明该方法准确、鲁棒。该方法已实现在GitHub上公开，激发进一步研究和应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20407</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>310. cs.CV-EAGLE: 一种用于肝包虫病病变分割的高效全局注意力模型</title><link>https://arxiv.org/pdf/2506.20333</link><description>Background: 
肝包虫病（HE）在欠发达的牧区是一种普遍的寄生虫病，这些地区医疗资源有限。尽管基于CNN和Transformer的模型在医学图像分割中得到了广泛应用，但CNN由于局部的感受野而缺乏全局背景建模能力，而尽管Transformer能够捕捉长距离依赖关系，但计算成本高昂。为解决这些问题，本文利用状态空间模型（如Mamba），这些模型能够以线性复杂度建模长序列。

Innovation: 
本文提出了一种名为EAGLE的U型网络，它由渐进视觉状态空间（PVSS）编码器和混合视觉状态空间（HVSS）解码器组成。EAGLE还设计了一个卷积视觉状态空间块（CVSSB）模块用于局部和全局特征的融合，以及一个Haar小波变换块（HWTB）模块用于在不损失信息的情况下压缩空间信息到通道维度。由于缺乏公开的HE数据集，研究团队从当地医院收集了260名患者的CT切片数据。实验结果显示，EAGLE在Dice相似度系数（DSC）上达到了89.76%，超越了MSVM-UNet的性能，提升了1.61%。

Conclusion: 
EAGLE网络在肝包虫病病变分割中表现优异，能够高效准确地完成任务。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20333</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>311. cs.CV-Weighted Mean Frequencies: 一种用于4D Flow MRI分割的手工Fourier特征</title><link>https://arxiv.org/pdf/2506.20614</link><description>Background: 
近年来，4D Flow MRI 图像的使用使我们能够量化感兴趣体积内以及整个心动周期内的速度场。然而，这些生物标志物缺乏分辨率和存在噪声，是显著的问题。现有研究表明，诸如壁剪应力这样的生物标志物特别是受到了血管分割较差分辨率的影响。目前，相位对比磁共振血管造影（PC-MRA）是用于辅助分割的最先进的方法。本研究旨在引入一种新的手工特征，它可以为4D Flow MRI图像提供一种新的视觉化方式，有助于分割任务。这种特征被称为加权均值频率（WMF），能够揭示三维空间中一个体素被脉动流通过的区域。这项特征代表了所有脉动速度体素的外壳。通过两种实验展示了该特征的价值：利用最优阈值和深度学习方法分割4D Flow MRI图像。结果显示，与PC-MRA特征相比，在深度学习任务中Iou和Dice分别增加0.12和0.13。这种特征在未来可能为血管区域的分割提供有价值的信息，并可用于心脏或大脑等其他血管区域的分割过程。

Innovation: 
论文提出了加权均值频率（WMF）这一新的手工特征，该特征可以揭示三维空间中一个体素被脉动流通过的区域，代表了所有脉动速度体素的外壳。该特征能够显著提升4D Flow MRI图像的分割性能，通过最优阈值和深度学习方法的实验，与PC-MRA特征相比在Iou和Dice分别提升了0.12和0.13。

Conclusion: 
这种WMF特征提高了4D Flow MRI图像的分割效果，展示了其在其他血管区域的分割潜力，如心脏或大脑。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20614</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>312. cs.CV-DreamAnywhere：基于对象的全景3D场景生成</title><link>https://arxiv.org/pdf/2506.20367</link><description>Background: 
近年来，文本到3D场景生成技术显示出在多个行业中变革内容创作的巨大潜力，尽管研究界在解决这一复杂任务的过程中取得了显著进展，但现有方法通常生成的环境仅面向前方、缺乏视觉真实性、场景理解有限，并且通常只能针对室内外环境进行微调。

Innovation: 
本文提出了DreamAnywhere，一个模块化的3D场景快速生成和原型设计系统。该系统从文本生成全景图像，将图像分解为背景和对象，通过混合修复构建完整的3D表示，并将对象遮罩提升为详细的3D对象并放置在虚拟环境中。DreamAnywhere 支持沉浸式导航和直观的对象级编辑，使其非常适合场景探索、视觉原型制作和快速原型制作--所有这些都不需要传统的3D工作流中的高额手工建模。此外，其模块化流水线可以在各个组件之间独立替换，比现有的基于文本和图像的3D场景生成方法在新颖视图的连贯性和图像质量方面表现出明显改进，证明了其在各种复杂场景中的效用。

Conclusion: 
全面用户研究表明，我们的方法在技术稳健性和实用性方面均优于现有方法，证明了其在低预算电影制作中的适用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20367</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>313. cs.CV-不同编码、Ansatz和测量在量子和混合卷积神经网络中的实用见解</title><link>https://arxiv.org/pdf/2506.20355</link><description>Background: 
本研究探讨了参数化量子电路（PQCs）在量子和混合卷积神经网络（HQNN和QCNN）架构中的设计选择，应用于卫星图像分类任务，使用了EuroSAT数据集。研究系统地评估了数据编码技术、变分Ansatz及采样对约500种不同模型配置性能的影响。研究表明，在混合架构中，与直接的经典对应物（例如移除PQC后的相同架构）相比，数据编码策略是主要因素，验证准确率可超过30%的差异。相比之下，变分Ansatz和测量基的选择对准确率影响较小，差异在5%以下。对于仅包含振幅编码的纯量子模型，性能最依赖于测量策略及数据到振幅的映射。测量策略可变化验证准确率30%，编码映射约变化8个百分点。

Innovation: 
研究提出了不同数据编码、变分Ansatz和测量对量子和混合卷积神经网络性能的不同影响，提供了这些设计选择的实际指导，强调了数据编码策略在混合架构中的主导作用，以及测量策略和编码映射在纯量子模型中的重要性。

Conclusion: 
研究表明，在混合架构中，数据编码策略是性能的主要决定因素，而在纯量子模型中，测量策略和编码映射至关重要。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20355</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>314. cs.CV-学习中等输入敏感函数：条形码解码案例研究</title><link>https://arxiv.org/pdf/2506.20305</link><description>Background: 
功能的可学习性与其输入敏感性密切相关。图像分类任务对输入不敏感，微小的破坏不应影响分类结果；而算术和符号计算任务对输入高度敏感，每个输入变量直接影响计算结果。本研究探讨基于学习的QR码解码，并研究中等输入敏感性的学习函数。研究表明，变换器能够成功解码QR码，即使超过理论纠错极限也能完成，可通过学习嵌入文本的结构实现这一目标。它们可以从英语丰富的训练数据泛化到其他语言和随机字符串。此外，研究发现基于变换器的QR码解码器专注于数据位而忽略纠错位，这与标准QR码读取器的解码机制不同

Innovation: 
该研究首次提出了基于学习的QR码解码方法，并探索了中等输入敏感性的学习函数。研究表明，变换器可以成功地解码QR码，甚至超过理论纠错极限；并从英语丰富的训练数据泛化到其他语言和随机字符串。此外，基于变换器的解码器采用不同的解码机制，聚焦于数据位而非纠错位

Conclusion: 
试验表明，变换器既能够成功的对QR码进行解码，甚至能够突破理论上的纠错极限，这归因于其学习内在文本结构的能力。此外，进一步研究发现，基于变换器的解码器解码机制独特，主要依赖于数据位而非纠错位。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20305</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>315. cs.CV-FundaQ-8：一种临床启发式评分框架用于自动化眼底图像质量评估</title><link>https://arxiv.org/pdf/2506.20303</link><description>Background: 
自动眼底图像质量评估（FIQA）因成像差异和主观专家评估的差异而具有挑战性。本文介绍了一种新的专家验证框架FundaQ-8，该框架通过八个关键参数系统评估眼底图像质量，包括视野覆盖、解剖学可见性、照明和图像伪影。FundaQ-8作为一个结构化的评分参考，该团队开发了一个基于ResNet18的回归模型，用于预测0到1范围内的连续质量评分。模型使用1800张来自实际临床数据源和Kaggle数据集的眼底图像进行训练，通过迁移学习、均方误差优化和标准化预处理实现。模型验证和统计分析证实了框架的可靠性和临床可解释性，并且将FundaQ-8用于糖尿病视网膜病变分级的深度学习模型也提高了诊断的稳健性，突显了质量感知训练在实际筛查应用中的重要性。

Innovation: 
提出了FundaQ-8，这是一种专家验证的框架，通过八个关键参数系统评估眼底图像质量。该研究使用了一个基于ResNet18的回归模型来预测0到1范围内的连续质量评分，并在实际临床数据和Kaggle数据集上进行了训练。此外，将FundaQ-8框架整合到糖尿病视网膜病变分级的深度学习模型中，提高了诊断的稳健性。

Conclusion: 
FundaQ-8框架系统评估眼底图像质量并具有高可靠性和临床可解释性。将FundaQ-8整合到深度学习模型中提高了糖尿病视网膜病变的诊断稳健性，表明质量感知训练在实际筛查应用中的价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20303</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>316. cs.CV-通过保留纹理的自监督、专家混合和多任务集成的酌情骨质疏松症诊断</title><link>https://arxiv.org/pdf/2506.20282</link><description>Background: 
骨质疏松症特征为骨矿密度降低和骨微观结构受损，增加了老年人群的骨折风险。尽管双能X射线吸收技术（DXA）是临床评估骨密度的标准方法，但由于其访问限制，资源匮乏地区诊断难度较大。现有通过现有影像数据进行骨质疏松症诊断的机会性计算机断层扫描（CT）分析已有出现，但目前方法存在三个局限性：一是未充分利用未标记的脊椎数据；二是来自不同设备的DXA差异导致系统偏差；三是未能充分整合如骨密度分布模式等临床知识。为解决这些问题，我们提出了一种统一的深度学习框架。

Innovation: 
一是利用影像组学表示和自我监督学习方法处理未标记的CT数据并保持骨纹理；二是采用专家混合（MoE）架构配以学习到的门控机制以增强跨设备适应性；三是将骨质疏松症诊断、骨密度回归和椎骨位置预测相结合进行多任务学习。

Conclusion: 
该方法在全国三个临床中心和外部医院验证中显示出了优于现有方法的泛化能力和准确性，对于机会性骨质疏松筛查和诊断表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20282</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>317. cs.CV-MS-IQA: 多尺度特征融合网络在PET/CT图像质量评估中的应用</title><link>https://arxiv.org/pdf/2506.20200</link><description>Background: 
正电子发射断层扫描/计算机断层扫描（PET/CT）在医疗成像中起着至关重要的作用，结合功能性信息和解剖学信息以辅助准确诊断。然而，由于噪声、压缩等因素导致的图像质量退化可能会导致诊断不明确，并增加误诊的风险。在评估PET/CT图像质量时，低级特征如失真和高级特征如器官解剖结构都会影响图像的诊断价值。但是，现有的医学图像质量评估（IQA）方法无法同时考虑这两种类型的特征。现有研究未能同时评估这些特征，导致了评估的局限性。因此，需要一种方法来准确评估PET/CT图像质量并解决这些问题。

Innovation: 
本文提出了一种新的多尺度特征融合网络（MS-IQA），用于PET/CT图像质量评估。MS-IQA采用了ResNet和Swin Transformer不同中间层的多尺度特征，增强了对局部和全局信息感知的能力。此外，还引入了一个多尺度特征融合模块，通过动态加权通道注意力机制有效结合了高级和低级信息。同时，还构建了一个包含2700张各具质量差异的PET/CT图像和由放射科医生评定的质量分数的PET-CT-IQA-DS数据集，用于提高图像质量评估的准确性和效率。

Conclusion: 
实验结果表明，本文提出的模型在各种IQA指标中优于现有的最先进的方法，为PET/CT提供了准确且高效的IQA方法。我们的代码和数据集可在特定网页上获取。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20200</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>318. cs.CV-MIRAGE: 农业专家指导对话中多模态信息寻求与推理的基准</title><link>https://arxiv.org/pdf/2506.20100</link><description>Background: 
当前，农业领域需要高级水平的咨询互动，在这类互动中，专家需要根据用户的自然查询、图像背景及一系列复杂的场景做出详细的回答和多种决策。现有的基准主要集中在特定的情境和封闭的类别中，这限制了模型在实际复杂交互中的表现。为此，该研究提出了MIRAGE基准，旨在评估模型在现实农业知识密集领域内进行多模态推理和决策的能力。

Innovation: 
MIRAGE通过结合自然用户查询、专家生成的答案和基于图像的上下文，全面捕获专家咨询的复杂性。它基于超过35,000个实际的用户与专家交互，经过精心设计的多步管道进行筛选和整理。MIRAGE不仅涵盖了作物健康、害虫诊断和作物管理等多种情境，还包含了超过7,000种独特的生物实体，使其成为多omics和多模态模型最多样化的基准之一。与现有的依赖于具体用户输入和封闭类别基准不同，MIRAGE通过未指明的、上下文丰富的场景模拟开放性问题和设置，要求模型能够推理隐藏的知识漏洞并妥善处理罕见实体，从而主动引导对话或直接回应。

Conclusion: 
MIRAGE为评估农业领域的多模态推理和决策提供了一个高保真度的基准，在实际场景中有着广泛的适用性和挑战性。通过对MIRAGE的使用和测试，研究人员和开发者可以更好地理解和改进农业咨询对话中的模型性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20100</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>319. cs.CV-X-SiT: 因其内在可解释性表面视觉变换器用于痴呆症诊断</title><link>https://arxiv.org/pdf/2506.20267</link><description>Background: 
可解释的模型对于支持临床决策至关重要，推动了其在医学图像中的开发和应用。然而，3D体数据难以可视化和解释复杂的脑结构，如大脑皮层。相比之下，皮层表面渲染提供了更易于理解的3D脑解剖表示，有助于可视化和交互式探索。基于这一优势和皮层表面数据在研究神经退行性疾病中的广泛应用，本文提出了可解释性表面视觉变换器（X-SiT）。

Innovation: 
作为一种根本上具有可解释性的神经网络，X-SiT 能基于可解释的皮层特征提供人性化可理解的预测。它引入了一种原型表面补丁解码器来对表面补丁嵌入进行分类，结合基于空间对应的皮层原型案例推理。实验结果表明，X-SiT 在检测阿尔茨海默病和前颞叶痴呆方面达到了最先进的性能，并且提供了与已知疾病模式一致且揭示分类错误的有用原型。

Conclusion: 
X-SiT 是第一个提供基于可解释皮层特征的人类可理解预测的内在具有良好解释性的神经网络，该网络在诊断痴呆方面具有出色的表现，并且还提供关于疾病模式和分类错误的有用原型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20267</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>320. cs.CV-FedBKD：在非IID数据上兼备泛化能力和个性化能力的提炼联邦学习</title><link>https://arxiv.org/pdf/2506.20245</link><description>Background: 
联邦学习（FL）提供了一种去中心化的协作机器学习方法，解决了工业实践中的孤立数据孤岛和数据隐私泄露问题。然而，处理非同态分布（非-IID）数据是一个主要挑战。现有解决方法或构建强大的全局模型，或定制个人本地模型，很少两者兼备。许多解决非-IID问题的FL解决方案依赖于引入公共数据集，但也增加了数据泄露的风险。

Innovation: 
提出了一种新颖的数据驱动的提炼框架，Federated Bidirectional Knowledge Distillation (FedBKD)。该框架通过生成对抗网络（GAN）生成合成数据，训练过程中局部模型作为判别器并冻结参数。合成数据用于全局和本地模型之间的双向提炼，实现知识交互，从而提高双方性能。实验结果表明，FedBKD在不同非-IID设置下的基准测试中均取得了SOTA性能。

Conclusion: 
FedBKD框架在非-IID数据上实现了优秀泛化能力和个人化能力的统一。通过双向知识提炼和合成数据生成，共提升了全局和局部模型的性能。实验验证了该框架的有效性和优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20245</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>321. cs.CV-基于RGB感知的共识驱动不确定性在机器人抓取中的应用</title><link>https://arxiv.org/pdf/2506.20045</link><description>Background: 
物体姿态估计模型通常过于自信，而能够同时估计目标物体的6-DoF姿态并预测估计不确定性以进行抓取的抓取代理可以在高不确定性下选择不执行任务，从而避免任务失败。尽管物体姿态估计和不确定性量化研究在不断提升，但仍然很少有研究将它们与下游的机器人抓取任务连接起来。本文分析了物体姿态估计与抓取不确定性量化在机器人抓取中的应用现状，并指出现有研究较少将这两方面结合进行优化，特别是用于提高抓取成功率方面的研究较为匮乏。

Innovation: 
研究提出了一种方法，通过在尝试抓取之前预测由基于图像的姿态估计引导的抓取是否成功来训练轻量级深度网络。训练数据是通过在真实图像上进行物体姿态估计和模拟抓取来生成的。该研究还发现，尽管在抓取试验中物体高度变化，但网络在联合训练所有物体时仍然能够受益，表明多样化的物体能够共同服务于同一个目标，这一发现为未来的研究提供了新思路。

Conclusion: 
通过共识驱动不确定性量化的方法，本文为通过RGB感知进行高效可靠的机器人抓取提供了全新的解决方案。此方法不仅能够提高抓取成功率，还能有效降低在高不确定条件下的盲目操作风险。未来的研究可以从提升网络性能和扩展应用场景两方面进一步推动该方法的实际应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20045</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>322. cs.CV-任意顺序的GPT作为掩蔽扩散模型：解耦形式与架构</title><link>https://arxiv.org/pdf/2506.19935</link><description>Background: 
大多数大型语言模型（LLMs）主要采用自回归（AR）方法，但掩蔽扩散模型（MDMs）正在成为可选的替代方案。自回归（AR）模型通常为“解码器仅”架构，而掩蔽扩散模型主要为“编码器仅”架构。这种同时改变建模范式和架构的做法使直接比较变得不公平，难以区分观察到的差异是来自建模范式本身还是架构的变化。因此，这项研究旨在通过在解码器仅框架内评估掩蔽扩散模型来提供公允的比较，并研究其架构影响（解码器仅和编码器仅），从而将核心范式差异与架构影响解耦开来，给出未来模型设计的见解。

Innovation: 
（1）在解码器仅框架下评估掩蔽扩散模型（MDMs）作为任意顺序自回归（AO-AR）模型与标准自回归模型的等价比较，表明标准AO-AR目标的观测可能需要改进；（2）研究掩蔽扩散模型内的架构影响，证明虽然编码器仅掩蔽扩散模型可以建模一个较简单的条件概率空间，但在温度退火的情况下，解码器仅掩蔽扩散模型可以实现显著的生成速度提升（约25倍），同时保持可比的困惑度，突出关键的权衡。这部分的工作从而将核心范式差异从架构影响中分离出来，给未来模型设计提供见解。

Conclusion: 
这项工作通过解耦核心范式差异与架构影响，提供了对未来模型设计的见解，并证明了在解码器仅框架下的高质量生成能力可以实现更高的速度和可比的性能，尽管模型需要处理更大的空间。源代码现在在指定的链接处可用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19935</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>323. cs.CV-流形图像的解缠表示</title><link>https://arxiv.org/pdf/2506.20649</link><description>Background: 
显微镜图像分析对不同应用至关重要，包括诊断、合成工程和环境监测。现代的图像获取系统使得获取大量图像成为可能，同时也需要开发大量的基于深度学习的自动图像分析方法。尽管深度神经网络在这个领域显示了出色的性能，但可解释性，对于显微镜图像分析来说仍然是一个重大的挑战。本文研究了表征学习的方法来提升显微镜图像分类的模型解释性。作者使用了三个不同的显微镜图像领域的基准数据集（浮游生物、酵母细胞器和人类细胞），展示了基于从合成数据转移到真实数据的解缠表示方法（DRL）框架，可以在准确性和解释性之间找到一个好的权衡点。

Innovation: 
本文提出了一种解纠缠表示学习（DRL）方法，通过从合成数据中学习表示然后转移到真实数据上，来增强显微镜图像分类的模型解释性。这种方法在三个不同的显微镜图像领域的基准数据集上展示了在准确性和解释性之间的良好权衡。

Conclusion: 
解纠缠表示学习（DRL）框架能够提供在显微镜图像分析中准确性和解释性的好权衡。该研究通过使用多个显微镜图像数据集验证了这种方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20649</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>324. cs.CV-VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration</title><link>https://arxiv.org/pdf/2506.19975</link><description>Background: 
最近神经网络的发展提高了变形图像配准（DIR）的效率和准确性，通过减少迭代优化的需要，但基于学习的方法在有限的训练数据、大变形以及缺乏标签监督的情况下表现不佳，而迭代方法虽然在这些情况下能实现更高的准确性，但速度远慢于基于学习的方法。

Innovation: 
VoxelOpt 结合了基于学习和迭代方法的优点，通过引入体素适配的消息传递、多级图像金字塔以及使用预训练的分割模型提取特征，进一步改进了变形CT图像配准的效率和准确性。

Conclusion: 
在腹部CT图像配准中，VoxelOpt 在效率和准确性方面超过了领先的迭代方法，同时达到了与带有标签监督训练的学习方法相当的表现水平。开源代码将在此链接提供：this https URL</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19975</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>325. cs.CV-利用遥感技术的多模式空间风险评估框架以支持电动汽车充电基础设施</title><link>https://arxiv.org/pdf/2506.19860</link><description>Background: 
电动汽车充电基础设施在可持续交通系统中越来越关键，但其在环境和基础设施压力下的韧性尚未得到充分研究。本研究旨在通过结合遥感数据、开放基础设施数据集和空间图分析技术，提出一种空间显性和多模态的风险评估框架RSERI-EV，以评估电动汽车充电站的脆弱性。该框架利用多种数据层（如洪水风险地图、地表温度极端值、植被指数、土地利用/覆盖、电力变电站临近程度和道路可达性）生成综合韧性评分。我们利用威尔士地区的电动汽车充电桩数据集进行实证分析，展现了该方法的有效性及多源数据融合和可解释的空间推理在支持气候适应性和基础设施感知的电动汽车部署中的价值。

Innovation: 
开发了一种结合遥感数据、开放基础设施数据集和空间图分析技术的空间显性和多模态风险评估框架RSERI-EV，以评估电动汽车充电站的脆弱性。尤其是通过构造空间$k$-最近邻($k$NN)图，实现基于邻里对比和图感知诊断，突出了多源数据融合和可解释的空间推理在促进气候适应性与基础设施感知的电动汽车部署中的作用。

Conclusion: 
研究展示了RSERI-EV框架在电动汽车充电基础设施中评估脆弱性方面的可行性，并强调了多源数据融合和可解释的空间推理在支持气候适应性和基础设施感知的电动汽车部署中的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19860</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>326. cs.CV-IPFormer：基于上下文自适应实例提案的视觉3D全景场景完成</title><link>https://arxiv.org/pdf/2506.20671</link><description>Background: 
语义场景完成（SSC）已经成为了联合学习场景几何和语义的重要方法，为移动机器人导航等下游应用提供了支持。全景场景完成（PSC）的进步在于将实例级信息整合进来，提升了场景理解中的对象级敏感性。虽然PSC最初使用了LiDAR模态，但基于摄像头图像的方法却鲜被探索。近期，基于Transformer的方法使用固定的查询集重建场景体素内的对象，这些查询通常在训练期间利用图像上下文进行更新，但在测试阶段却保持静态，限制了它们对观测场景的动态适应能力。

Innovation: 
我们提出了IPFormer，这是首个在训练和测试阶段利用上下文自适应实例提案的方法，解决了基于视觉的3D全景场景完成问题。IPFormer自适应地初始化这些查询作为来自图像上下文的全景实例提案，并通过基于注意力的编码和解码进一步细化它们，以推断语义实例-体素关系。实验结果显示，与现有方法相比，我们的方法在总体全景指标PQ和PQ-All上表现出色，此外，通过从图像上下文动态获取实例提案而非随机初始化，PQ-All提升了3.62%，整体Thing指标提升了18.65%，这些结果强调了上下文自适应实例提案在解决基于视觉的3D全景场景完成中的创新作用。

Conclusion: 
我们的研究表明，上下文自适应实例提案的引入对于解决基于视觉的3D全景场景完成具有显著的改进效果，为后续研究提供了新的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20671</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>327. cs.CV-MMSearch-R1：激励LMMs进行搜索</title><link>https://arxiv.org/pdf/2506.20670</link><description>Background: 
在实际场景中稳健部署大规模多模态模型（LMMs）需要能够访问外部知识源，因为现实世界的信息复杂且具有动态性。现有方法如检索增强生成（RAG）和提示工程搜索代理依赖于固定的管道，经常导致无效或过度的搜索行为。因此，需要一种能够支持LMMs在实际互联网环境中按需进行多轮搜索的机制，以实现更有效的知识搜索和利用。

Innovation: 
我们提出了MMSearch-R1，这是首个以强化学习为基础的端到端框架，它使LMMs可以在实际互联网环境中按需进行多轮搜索。该框架结合了图像和文本搜索工具，模型可以根据基于结果的奖励以及搜索惩罚来决定何时及如何触发这些工具进行搜索。我们在一个半自动化的流程中收集了一个多模态搜索VQA数据集，涵盖了不同视觉和文本知识需求，并通过一个既包括搜索需求又包括无搜索需求的子集来支持训练，这对形成高效且按需的搜索行为至关重要。实验结果显示，与基于RAG的基线模型相比，我们的模型不仅表现优于相同规模的基线，还接近更大RAG模型的性能，同时减少了超过30%的搜索调用次数。此外，还分析了一些关键的实证发现，为多模态搜索领域的研究提供了可操作的见解。

Conclusion: 
我们的研究不仅证明了MMSearch-R1在实际互联网环境中支持LMMs高效、按需搜索的能力，而且对提升多模态搜索领域的研究贡献了重要的见解和实践总结。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20670</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>328. cs.CV-SFNet：空间域和频域特征融合在遥感图像伪造检测中的应用</title><link>https://arxiv.org/pdf/2506.20599</link><description>Background: 
生成式人工智能的快速进步正在产生越来越难以检测的虚假遥感影像(RSI)，这可能导致错误的情报、假新闻甚至阴谋论。现有伪造检测方法通常依赖单一视觉特征来捕捉预设的伪迹，例如在RSI中检测伪造的建筑物或道路的空间域线索，或在对抗生成网络(GANs)中检测上采样操作引起的频域特征。然而，伪迹的性质可以根据地理地形、土地覆盖类型或RSI中的特定特征而有很大的不同。此外，随着生成模型变得越来越复杂，这些复杂的伪迹也在不断进化。因此，对单一视觉线索的过度依赖使得现有的伪造检测器难以在多种多样遥感数据中泛化。本文旨在通过利用空间域和频域特征来提出一种新的伪造检测框架SFNet，以识别多样化的遥感数据中的假图像。现有方法主要依靠单一视觉特征来检测伪迹，但现实中的伪迹因地理条件和特定特性而异，而且随着生成模型变得越来越复杂，伪迹也在不断发展变化，这使得现有方法难以适应多种多样且复杂的伪造图像特征。

Innovation: 
本文提出了一种新的伪造检测框架称为SFNet，通过融合空间域和频域特征来识别多样化的遥感数据中的假图像。该框架利用两个独立的特征提取器从输入遥感图像中提取空间域和频域特征，同时设计了领域特征映射模块和混合领域特征精炼模块（采用CBAM注意力机制），以成功对齐和融合多领域的特征，同时抑制冗余信息。实验结果表明，与最先进的遥感图像伪造检测方法相比，SFNet的准确率提高4%-15.18%，并且具备较强的泛化能力。

Conclusion: 
SFNet框架在多种遥感数据集上展示出显著的伪造检测准确率提升和优异的泛化性能。该方法通过融合空间域和频域特征，解决了单一视觉特征难以适应多样化及其演变的遥感伪迹问题，为遥感图像伪造检测提供了新的思路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20599</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>329. cs.CV-基于图的句子总结的密集视频字幕生成</title><link>https://arxiv.org/pdf/2506.20583</link><description>Background: 
近年来，密集视频字幕技术取得了显著进展，能够检测并描述长视频中所有事件。尽管取得了令人振奋的结果，但现有方法大多未能充分探索事件时间提案内的场景演变，从而在场景和对象在较长提案内发生变化时表现不佳。为了应对这一问题，本文提出了一种基于图的分割与总结（GPaS）框架，将事件提案分成多个短视频片段进行精细级别的字幕生成，然后将每个片段生成的描述信息总结为一句话来描述整个事件。特别聚焦于总结阶段，提出了一种有效利用语义词之间关系的框架。通过将语义词视为图中的节点，并结合图卷积网络（GCN）和长短期记忆网络（LSTM），以视觉线索为辅助，学习它们之间的关系。提出了两种图卷积网络-长短期记忆网络交互（GLI）模块的方案，以无缝集成GCN和LSTM。

Innovation: 
本文提出了一种基于图的分割与总结（GPaS）框架，分为两个阶段。第一阶段将整个事件提案分割为短视频片段进行精细级别的字幕生成；第二阶段，生成的每个片段描述信息被总结为一句话来描述整个事件。特别强调总结阶段，提出了一种有效利用语义词之间关系的框架，通过将语义词视为图中的节点，结合图卷积网络（GCN）和长短期记忆网络（LSTM），以视觉线索为辅助，学习它们之间的关系，提出了两种图卷积网络-长短期记忆网络交互（GLI）模块方案，以实现GCN和LSTM的无缝集成。

Conclusion: 
本文通过在ActivityNet Captions数据集和YouCook II数据集上与当前最先进的方法进行广泛的比较，证明了所提方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20583</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>330. cs.CV-TRIM：一种最大化时间相对信息和代表性的自监督视频摘要框架</title><link>https://arxiv.org/pdf/2506.20588</link><description>Background: 
随着视频内容的广泛应用和对高效获取有价值信息的需求增加，视频摘要和视频亮点已经成为了重要的研究领域。然而，许多现有先进技术要么依赖监督注释，要么依赖基于注意力的模型，这在计算上是昂贵的且对分布偏移敏感，影响跨数据集的应用范围。

Innovation: 
本文介绍了一种创新的自监督视频摘要模型TRIM，该模型无需使用注意力机制、RNN或变换器，就能捕获空间和时间依赖性。该框架结合了一种新颖的马尔可夫过程驱动的损失度量和两阶段自监督学习范式，确保性能和效率。这种技术在SUMME和TVSUM数据集上达到了最先进的性能，优于所有现有无监督方法，其表现也接近最好的有监督模型。这表明高效的无注释架构是可行的，也为更通用的视频摘要技术铺平了道路，挑战了依赖复杂架构的现状。

Conclusion: 
TRIM框架展示了自监督学习方法在视频摘要任务中的潜力，具有高效率和无需标注数据的特点，挑战了传统复杂模型依赖的局面，为未来的研究提供了新的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20588</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>331. cs.CV-Shape2Animal: Creative Animal Generation from Natural Silhouettes</title><link>https://arxiv.org/pdf/2506.20616</link><description>Background: 
人类能够识别混乱刺激中的有意义模式，这种认知现象称为幻象识别。本文介绍了一种名为Shape2Animal的新框架，通过重新解释自然物体轮廓（如云朵、石头或火焰）为可能的动物形态来模仿这种想象力的能力。该框架首先执行开放式词汇分割以提取物体轮廓，然后使用视觉-语言模型解释适合的主题动物概念。接着利用文本到图像的扩散模型来合成与输入形状相符的动物图像，并将其无缝融合到原始场景中，生成视觉上连贯且空间上一致的作品。

Innovation: 
本文提出了一种新的框架Shape2Animal，通过将自然物体轮廓重新解释为可能的动物形态，并利用视觉-语言模型和文本到图像的扩散模型，自动化地生成与输入形状相符的动物图像，从而实现创意动物生成。该框架能够为视觉叙事、教育资源、数字艺术和互动媒体设计提供新的机会。

Conclusion: 
通过在多样化的实际输入上评估Shape2Animal，证明了该框架的鲁棒性和创造潜力。该框架能够生成视觉上连贯且空间上一致的作品，能够为视觉叙事、教育资源、数字艺术和互动媒体设计等领域提供新机会。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20616</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>332. cs.CV-视频感知模型在3D场景合成中的应用</title><link>https://arxiv.org/pdf/2506.20601</link><description>Background: 
传统的3D场景合成需要专家知识和大量的手工努力。自动化这个过程可以极大地受益于建筑设计、机器人模拟、虚拟现实和游戏等领域。最近的3D场景合成方法往往依赖于大型语言模型（LLMs）的常识推理或现代图像生成模型的强大视觉先验。然而，当前的LLMs在3D空间推理方面表现出有限的能力，限制了它们生成逼真且连贯的3D场景的能力。同时，基于图像生成的方法在视点选择和多视图一致性方面往往受到限制。

Innovation: 
本文提出了视频感知模型用于3D场景合成（VIPScene）的新型框架，通过利用视频生成模型中编码的3D物理世界的常识知识，确保场景布局和视图间物体放置的一致性。VIPScene接受文本和图像提示，无缝地结合视频生成、前馈3D重建和开放式词汇感知模型，对场景中的每个对象进行语义和几何分析。此外，还引入了第一人称视角得分（FPVScore）用于连贯性和合理性评估，利用连续的第一人称视角优势，利用多模态大型语言模型的推理能力。实验结果表明，VIPScene显著优于现有方法，并在多种场景中表现出良好的泛化能力。开发的代码将公开释放。

Conclusion: 
VIPScene在3D场景合成中实现了更高程度的现实感和结构性一致性，通过新颖的框架和方法，显著提升了3D场景合成的性能，并且具有良好的场景泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20601</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>333. cs.CV-联合姿态估计和非配合太空目标的3D神经重建</title><link>https://arxiv.org/pdf/2506.20638</link><description>Background: 
获取地球轨道上物体的当前状态和行为对多种应用至关重要，如轨道碎片清除、在轨维护或异常检测。3D模型在太空态势感知（SSA）领域提供有价值的信息。本文利用神经辐射场（NeRF）技术，从仿真图像中对非配合轨道物体进行3D重建，这在NeRF模型面临单一色图像、未知物体方向、有限视角和缺乏散射照明等挑战性条件下尤为重要。

Innovation: 
本文主要关注相机姿态和NeRF的联合优化。实验结果显示，逐帧训练可以获得最精确的3D重建。通过优化均匀旋转估计相机姿态，并使用正则化来防止连续姿态之间的距离过大。

Conclusion: 
实验结果表明，逐帧训练实现了最准确的3D重建。通过优化均匀旋转估计相机姿态，并使用正则化来防止连续姿势之间距离过大。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20638</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>334. cs.CV-轻量级多帧集成用于视频中鲁棒YOLO目标检测</title><link>https://arxiv.org/pdf/2506.20550</link><description>Background: 
现代基于图像的目标检测模型，如YOLOv7，主要处理独立的帧而不利用视频中自然存在的时序上下文，这可能导致检测性能下降。现有基于视频的目标检测方法通常需要复杂的时序模块，进一步增加了模型大小和计算复杂性。在实际应用中，例如监控和自动驾驶中，瞬间挑战，如运动模糊、遮挡和突然的外观变化，会严重损害单帧检测性能。为了解决这些问题，本文提出了一种简单而有效的方法：将连续多帧作为输入传递给基于YOLO的检测器，并仅监督与单一目标帧相对应的输出。这种方法最大限度地减少了对现有架构的改动，保留了架构的简洁性、计算效率和实时推理能力。在MOT20Det和我们提出的BOAT360数据集上的广泛实验证明了该方法在检测鲁棒性方面的改进，特别是在轻量级模型上表现尤为明显，有效地缩小了紧凑型和重型检测网络之间的性能差距。此外，我们还贡献了一个包含来自动船的鱼眼视频序列标注数据集BOAT360，以支持未来在具有挑战性的实际场景中的多帧视频目标检测研究

Innovation: 
提出了一种将连续多帧作为输入传递给基于YOLO的检测器，并仅监督与单一目标帧相对应的输出的方法。这种方法最大限度地减少了对现有架构的改动，同时提高了检测鲁棒性，特别是在轻量级模型上表现尤为明显，有效地缩小了紧凑型和重型检测网络之间的性能差距，同时还贡献了包含来自动船的鱼眼视频序列标注数据集BOAT360以支持未来研究

Conclusion: 
广泛实验证明了所提方法在检测鲁棒性方面的改进，特别是对于轻量级模型，贡献了新的数据集支持未来多帧视频目标检测研究</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20550</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>335. cs.CV-基于单传感器设置的360度学习距离估计</title><link>https://arxiv.org/pdf/2506.20586</link><description>Background: 
机器人感知中的准确距离估计是一个基本挑战，特别是在全景成像中，传统几何方法难以应对镜头畸变和环境变化。现有方法通常依赖于精确的镜头校准，但在复杂多变的环境中效果欠佳。因此，提出了使用单个360°鱼眼镜头相机进行单目距离估计的神经网络方法，该方法直接从原始全景输入中学习和推断物体距离，具有更高的鲁棒性和适应性。

Innovation: 
该研究提出了一种基于神经网络的方法，用于利用单个360°鱼眼镜头相机进行单目距离估计。与依赖精确镜头校准的经典三角测量技术不同，该方法可以直接从原始全景图像中学习和推断物体距离，提高了在多变环境中的稳健性和适应性。该方法已经在LOAF、ULM360和新捕获的Boat360三个360°数据集上进行评估，证明了基于学习的方法在准确性和鲁棒性方面优于传统几何方法和其它学习基准方法。

Conclusion: 
实验结果表明，基于深度学习的方法在实时全景距离估计方面具有巨大潜力，因此特别适合于低成本机器人应用、自主导航和监控等领域。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20586</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>336. cs.CV-使用视觉线索辅助句子总结的视频描绘：展示、讲述和总结</title><link>https://arxiv.org/pdf/2506.20567</link><description>Background: 
该研究旨在解决密集视频captioning问题，即生成对整个视频事件描述性句子的任务。传统的captioning方法往往难以处理长视频中的复杂事件，尤其在提取事件整体描述时缺乏有效的手段。因此，研究者提出了一种分割和总结（DaS）框架，通过将每个未修剪的长视频分割为多个事件提案，再提取每段视频的视觉特征，生成相应的句子描述。这种方法的优势在于利用生成的句子富含整个事件的语义描述，提出了一种视觉线索辅助的句子总结方法，以生成最终的描述性句子。实验结果证明了该方法的有效性。

Innovation: 
该论文创新性地提出了一个分割-总结（DaS）框架，用于密集视频captioning。通过事件提案的分解和视觉特征的提取，生成多个句子描述，然后利用新的双阶段LSTM（具有新的分层注意机制）来辅助生成最终描述段落。这种双阶段的方法能够更有效地整合视觉信息与语义信息，进而生成整体性的描述。此外，通过引入视觉线索辅助的句子总结方法，更好地提取和利用视频中的视觉细节信息，提高了描述的准确性与完整性。

Conclusion: 
该研究表明，所提出的DaS框架能够有效解决密集视频captioning问题，实现对整个视频事件的描述生成。实验结果显示，该方法在ActivityNet Captions数据集上的表现优于现有方法，证明了其在该领域的先进性和有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20567</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>337. cs.CV-AdvMIM: 对抗缺失图像建模在半监督医学图像分割中的应用</title><link>https://arxiv.org/pdf/2506.20563</link><description>Background: 
近期，视觉转换器在医学图像分割任务中因其在捕获长距离依赖方面的卓越能力而受到广泛关注。然而，转换器需要大量的标记数据才能有效工作，这阻碍了在标注稀缺的半监督学习场景中的应用，即只有有限的标记数据可用。最先进的半监督学习方法提出了组合CNN-Transformer学习方法来交叉训练转换器和卷积神经网络，取得了令人鼓舞的结果。然而，如何有效训练转换器以有限的标记数据依然是一项具有挑战性的任务。

Innovation: 
本文提出了一种对抗缺失图像建模方法，以充分发挥转换器在半监督医学图像分割中的潜力。首先，通过掩码图像建模从原始领域构建辅助掩码领域，并训练转换器预测带有掩码输入的完整分割掩码，增强监督信号。利用标记数据的原始标签和未标记数据的伪标签来学习掩码领域。此外，为了进一步从掩码领域受益于原始领域，从多领域学习的角度对方法进行了理论分析，并设计了一种新的对抗训练损失来减小原始和掩码领域之间的领域差距，从而提升半监督学习性能。同时，将对抗缺失图像建模扩展到CNN网络

Conclusion: 
我们的方法在三个公开的医学图像分割数据集上进行了广泛实验，结果表明其有效性，相比现有方法，显著提高了半监督学习性能。我们的代码已经公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20563</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>338. cs.CV-AI辅助的放射学分析在检测牙槽骨损失程度和模式中的应用</title><link>https://arxiv.org/pdf/2506.20522</link><description>Background: 
牙周炎是一种慢性炎症性疾病，导致牙槽骨丧失，严重影响口腔健康和生活质量。准确评估骨丧失的严重程度和模式对于诊断和治疗计划至关重要。

Innovation: 
本研究提出了一种基于人工智能的深度学习框架，使用口腔根尖片（IOPA）自动检测和量化牙槽骨丧失及其模式。该方法结合使用YOLOv8进行牙齿检测与Keypoint R-CNN模型来识别解剖标志点，从而精确计算骨丧失的严重程度。此外，还利用YOLOv8x-seg模型对骨水平和牙齿掩膜进行分割，通过几何分析确定骨丧失模式（水平 vs. 角度）

Conclusion: 
在包含1000张放射片的大型专家注释数据集上评估，该方法在检测骨丧失严重程度（内在相关系数高达0.80）和骨丧失模式分类（准确率87%）方面取得了高精度。自动化系统提供了快速、客观和可重复的牙周评估工具，减少了对主观手动评估的依赖。通过将AI整合到牙科放射学分析中，我们的框架有望改善牙周炎的早期诊断和个性化治疗规划，从而提高患者护理和临床结果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20522</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>339. cs.CV-使用观测分组进行影像分类的因果表示学习</title><link>https://arxiv.org/pdf/2506.20582</link><description>Background: 
因果表示学习旨在发现数据生成过程背后的真正因果关系。在医学成像领域，这种能力为提高特定任务的潜藏特征的一般化能力和鲁棒性提供了机会。这项工作关注的是通过端到端框架，将观察分组以学习对于疾病分类的可识别表示，特别是在胸部X光片分类任务中，通过对种族、性别和成像视角进行不变性约束，验证了因果表示的优越性。

Innovation: 
提出了一种通过观测分组来学习疾病分类任务中可识别的因果表示的新方法。该方法通过端到端框架实现，并展示了在多分类任务中，采用观测分组以实现对种族、性别和成像视角的不变性，能够提高表示的一般化和鲁棒性。

Conclusion: 
实验结果表明，通过分组观测来学习的因果表示可以显著提高胸部X光片分类任务中的适应性和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20582</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>340. cs.CV-Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks</title><link>https://arxiv.org/pdf/2506.20548</link><description>Background: 
随着深度学习的迅猛发展，特别是在生成对抗网络(GANs)和扩散模型(DMs)的应用下，AI生成的图片‘深度伪造’图像变得几乎与真实图片难以区分。这些图片在在线社交网络(OSNs)上广泛传播，引发了对其滥用的担忧。现有的深度伪造检测方法忽视了由于压缩而产生的‘块效果’，这些效果模糊了深度伪造的特征，主要关注原始图像，这些图像在现实世界中很少见。

Innovation: 
本文提出了PLADA（Pay Less Attention to Deceptive Artifacts），一个新型框架，旨在解决配对数据缺乏和压缩图像使用效率低的问题。PLADA包括两个核心模块：块效果擦除器（B2E），它使用双阶段注意力机制处理块效果；开放数据聚合模块（ODA），处理配对和非配对数据以提高检测效果。通过26个数据集的广泛实验，证明PLADA在OSNs中检测深度伪造方面取得了显著的成果，即使在数据有限和压缩的情况下，也优于现有技术。此外，该研究引入了‘块效果’作为深度伪造检测的关键因素，提供了解决开放世界应用场景的稳健解决方案。

Conclusion: 
本文提出了PLADA，一种针对在线社交网络压缩深度伪造进行稳健检测的新型框架。PLADA通过处理‘块效果’和有效利用配对与非配对数据，实现了深度伪造检测的优异性能。这项工作强调了‘块效果’在深度伪造检测中的重要性，并为开放世界场景下的检测提供了有力的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20548</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>341. cs.CV-使用移动激光扫描仪捕获地下矿山复杂3D点云的一种深度学习方法来识别锚杆</title><link>https://arxiv.org/pdf/2506.20464</link><description>Background: 
地下矿山中的锚杆是确保岩石稳定性和减少地下采矿操作中意外事故的关键部件，因此需要频繁评估，自动检测锚杆成为一种替代人工检查的有效方法，尤其是考虑到地下矿山光照条件差和检测过程耗时的问题。目前，传统的特征工程和机器学习方法在处理大量点云数据时表现出色，但在存在噪声、环境变化和复杂背景结构的情况下，这些方法不够稳健。另外，锚杆在大范围点云中体积小且可能因加固混泥土而部分遮挡。基于这些挑战，本文提出了一种名为DeepBolt的方法，采用了一种新的双阶段深度学习架构，解决了严重类别不平衡问题，提高了3D点云中锚杆自动识别的准确性。

Innovation: 
提出了一种新的双阶段深度学习架构DeepBolt，专门用于大型复杂3D点云中锚杆的自动识别，并且该方法的交集比(Intersection over Union, IoU)在锚杆点上比最新语义分割模型高出42.5%，准确率为96.41%，召回率为96.96%，显示出在复杂地下环境下具有很好的鲁棒性和有效性。

Conclusion: 
本文提出的方法在复杂的地下3D点云环境中实现了对锚杆的自动有效识别，相比现有的技术有了显著提升，展示了其在地下矿山中的应用潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20464</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>342. cs.CV-HiWave: 无需训练的基于小波的高分辨率图像生成</title><link>https://arxiv.org/pdf/2506.20452</link><description>Background: 
扩散模型在图像合成方面取得了显著进展，展现出极高的逼真度和多样性。然而，训练高分辨率的扩散模型在计算上是不可行的，现有的一些零样本生成技术在合成超分辨率图像时会生成诸如物体重复和空间不一致的伪影。因此，在高分辨率图像生成中，保留视觉保真度和结构一致性是非常具有挑战性的任务。

Innovation: 
引入了HiWave方法，这是一种无需训练的零样本方法，它使用预训练的扩散模型在超高清分辨率的环境下生成具有增强视觉保真度和结构一致性的图像。该方法采用两阶段管道：首先是基于反转方法从预训练模型生成基础图像，然后是分块DDIM反向生成步骤和一个新颖的小波域细节增强模块。小波域细节增强器在优化图像的细节和纹理丰富性的同时，确保基础图像的基础特征不被破坏，从而保证结构的一致性。实验结果显示，HiWave有效缓解了先前方法中常见的视觉伪影，得到了优越的感知质量。用户研究证实了HiWave的有效性，尤其是在与现有最先进的方法进行图片质量对比时，HiWave在80%以上的情况下被用户更偏好。

Conclusion: 
HiWave方法能够在不重新训练或修改原有模型架构的情况下，实现高质量、超高清分辨率的图像生成，有效解决了高分辨率图像生成中的视觉伪影问题，具有很高的应用价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20452</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>343. cs.CV-A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management</title><link>https://arxiv.org/pdf/2506.20388</link><description>Background: 
准确且成本效益高的监测人工林地上生物量（AGB）对于支持当地生计和碳汇项目（如中国核证减排量CCER计划）至关重要。高分辨率林冠高度图（CHMs）是实现这一目标的关键，但传统激光雷达方法成本较高。虽然使用RGB图像的深度学习提供了替代方案，但准确提取林冠高度特征仍然具有挑战性。因此，需要开发新的方法以更高效、成本更低的方式生成高分辨率CHMs，以支持林业管理中的精准监测和管理需求。

Innovation: 
我们开发了一个新的高分辨率CHM生成模型，基于大型视觉基础模型（LVFM）。该模型集成了特征提取器、自我监督特征增强模块以保留空间细节、以及高度估算器，实现了更高的精度。在北京市房山区使用1米分辨率的Google Earth图像进行测试，该模型的表现优于现有的方法，包括传统的CNN，达到了均方根误差0.24米，相关性达到0.78，与激光雷达生成的CHMs对比。该方法能够实现超过90%的单个树木检测成功率，高度准确的AGB估计，并有效跟踪植物生长情况，显示了强大的跨领域泛化能力。

Conclusion: 
本研究提出了一种基于LVFM的新方法，用于人工林高分辨率CHM生成，实现精准林业管理。该方法提高了CHM的质量，降低了成本，并展示了广泛的适用性。这种新的方法为碳汇评估提供了有前景且可扩展的工具，适用于人工林和自然林。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20388</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>344. cs.CV-利用轻量化分层ViT和动态框架实现高效视觉跟踪</title><link>https://arxiv.org/pdf/2506.20381</link><description>Background: 
基于Transformer的视觉跟踪器展示了显著的进步，但其在资源受限的设备上应用受限，因为处理速度较慢。为此，我们提出了一种新的高效跟踪模型HiT，它在各种设备上实现了高性能和快速操作。HiT的核心创新在于Bridge Module，它将轻量级Transformer连接到跟踪框架中，提升了特征表示的质量。此外，还引入了双图像位置编码的方法，以有效地编码空间信息。

Innovation: 
HiT通过引入Bridge Module和双图像位置编码方法，实现了在不同设备上高性能和快速操作的平衡。基于DyHiT提出了一个动态的加速方法，可以根据场景复杂度灵活适应并选择不同的计算路线。同时，还提出了一种训练免费的加速方法，基于DyHiT的动态路由架构，这种方法在不牺牲准确性的前提下，显著提高了多种高性能跟踪器的执行速度。

Conclusion: 
我们在NVIDIA Jetson AGX平台上实现了HiT的61帧每秒的速度，并在LaSOT基准上实现了64.6%的AUC；DyHiT在NVIDIA Jetson AGX平台上的最快版本实现了111帧每秒的速度，并在LaSOT基准上保持了62.4%的AUC。我们提出的训练免费加速方法使得SeqTrack-B256在NVIDIA GeForce RTX 2080 Ti GPU上的速度提高了2.68倍，同时保持69.9%的AUC。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20381</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>345. cs.CV-从手抄书学到代码：面向历史文献布局分析的Transformer和YOLO检测器的比较研究</title><link>https://arxiv.org/pdf/2506.20326</link><description>Background: 
为了实现对具有复杂页面组织的历史文档的自动化处理和理解，稳健的文档布局分析（DLA）至关重要。本文对五种最先进的对象检测架构在三种代表不同纸本文档复杂性的注释数据集上进行了基准测试：e-NDP（巴黎中世纪登记簿，1326-1504年），CATMuS（源自不同中世纪和现代来源的多元分类数据集，约12世纪-17世纪）和HORAE（装饰有时间，约13世纪-16世纪的小时本手稿）.

Innovation: 
研究通过比较两种Transformer基模型（Co-DETR，Grounding DINO）与三种YOLO变体（AABB，OBB，YOLO-World）在数据集上的表现，揭示了模型架构、数据集特性及边界框表示对性能影响的显著差异。特别指出使用Oriented Bounding Boxes（OBB）对历史手稿的非笛卡尔性质模型是一个基础需求，而不是细微改进。强调了Transformer对结构化布局的整体上下文感知与CNN-OBB模型在视觉多样化和复杂文档上的优越泛化能力之间的权衡重要性.

Conclusion: 
在e-NDP数据集上，Co-DETR取得了领先表现（0.752 mAP@.50:.95），而YOLOV11X-OBB则在更复杂的CATMuS和HORAE数据集上表现出显著优势（分别为0.564和0.568）。本文证明了使用OBB不是微小改进，而是解决复杂手抄书布局分析的关键需求。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20326</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>346. cs.CV-膝关节MRI图像评估的放射omics指纹</title><link>https://arxiv.org/pdf/2506.20306</link><description>Background: 
膝关节磁共振成像（MRI）扫描的准确解读依赖于临床专家的经验判断，但常伴随高变异性和有限的可扩展性。现有的放射omics方法使用固定的一组放射omics特征（签名），这些特征通常是基于整个群体选定并应用于所有患者。这样的签名在一定程度上是可解释的，但往往过于受限，无法代表个体病理变异。因此，与不使用可解释放射omics特征的端到端深度学习（DL）方法相比，传统基于放射omics的多种方式表现受限。本文提出的背景是，当前放射omics特征的选择在个体层面上是无信息的，这并不是造成其可解释性问题的关键，而是导致在本应用中表现不佳的原因。现有的放射omics签名是基于固定特征的选择，而本文则提出了一种新的放射omics指纹框架，在该框架中，个性化特征集（指纹）为每个患者动态构建，通过深度学习模型选择预测临床条件相关的特征。利用此模型同时训练一个低维度的逻辑回归模型以改进下游分类过程的可解释性。

Innovation: 
本研究提出了一种新的放射omics指纹框架，该框架能够为每个患者构建个性化的放射omics特征集（指纹），并通过深度学习模型选择与临床条件相关的特征。这种方法不仅在多个膝关节异常诊断任务中表现优于现有的端到端深度学习模型，还在解释性方面提供了重要的临床洞察力和潜在生物标志物的发现。

Conclusion: 
本研究通过一种新的放射omics指纹框架，在多项诊断任务中展示了与先进端到端深度学习模型相当或更优的诊断准确性。更重要的是，这种框架因其内在的可解释性，能够为临床提供有意义的见解，并有可能发现新的生物标志物。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20306</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>347. cs.CV-自监督动作识别中的特征生成</title><link>https://arxiv.org/pdf/2506.20342</link><description>Background: 
传统的视频动作理解依赖于原始像素分析，但这种分析不足以提供高精度的结果。高阶语义推理和多模态特征的有效整合对于提高动作识别准确率至关重要。现有的框架在测试时通过预测RGB视频帧中的动作概念和辅助特征来提升识别效果，但缺乏在辅助特征中处理不确定性的方法。此外，现有的方法主要关注原始像素，未能利用对象检测和显著性检测中的关键信息来增强特征表示。

Innovation: 
本文提出了一个深度转换的动作识别框架，该框架通过综合预测辅助特征和行为概念来增强识别准确度。引入了两种新的领域特定描述符：对象检测特征（ODF）和显著性检测特征（SDF）。ODF用于捕获上下文线索，而SDF能够突出关键的空间和强度模式。此外，该框架能够无缝集成多种辅助模态，如光流、改进的密集路径、骨架数据和音频提示，并引入了处理辅助特征不确定性方法和稳健的损失函数来减轻特征噪声。该自监督的多模态动作识别框架在多个基准测试中取得了最先进的性能，证明了其在捕捉精细动作动态方面的有效性。

Conclusion: 
通过引入新的领域特定描述符和适应性损失函数，本文提出的多模态自监督动作识别框架显著提升了动作识别的准确性和效率，在多个数据集上达到了最好的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20342</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>348. cs.CV-Med-Art: 将扩散变换器用于2D医学图文生成</title><link>https://arxiv.org/pdf/2506.20449</link><description>Background: 
近年来，文本到图像生成模型取得了显著的突破，但在医学图像生成中的应用仍面临挑战，包括数据集较小和医学文本数据稀缺。Med-Art框架针对有限数据量下的医学图像生成进行了设计，利用视觉语言模型生成医学图像的视觉描述，解决了医学文本数据不足的问题。

Innovation: 
Med-Art引入了Hybrid-Level Diffusion Fine-tuning (HLDF)方法，使其能够在像素级别生成医学图像，有效解决了图像色彩过于饱和等问题。借助大型预训练的文本到图像模型PixArt-$boldsymbol{beta}$（基于扩散变换器DiT结构），Med-Art在两个医学图像数据集上实现了最先进的性能（通过FID、KID和下游分类性能进行评估）.

Conclusion: 
Med-Art通过利用视觉语言模型生成医学图像的视觉描述，有效地解决了医学文本数据稀缺的问题，并通过Hybrid-Level Diffusion Fine-tuning (HLDF)方法在有限数据下实现了高水平的输出性能，这对于医学图像生成具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20449</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>349. cs.CV-InvZW: 通过噪声对抗训练实现稳健图像零水印的不变特征学习</title><link>https://arxiv.org/pdf/2506.20370</link><description>Background: 
论文提出了一种基于对抗训练的深层学习框架，用于稳健的图像零水印。零水印技术保留图像原始状态，在特征空间通过优化学习参考签名。该框架分为两个模块，首先通过噪声对抗学习训练特征提取器以生成既抗干扰又含义表达的表示。其次设计了基于学习的多比特零水印方案，通过优化可匹配目标二进制信息的可训练参考代码来投影已训练的不变特征。实验结果证明了该方法在特征稳定性和水印恢复方面的优越性能，被证明优于现有自我监督和深层水印技术的鲁棒性和通用性。

Innovation: 
创新点在于提出了一种基于噪声对抗训练的深层学习框架，该框架通过噪声对抗学习训练特征提取器，使其生成既不变形又含义丰富的表示，并提出了一种基于学习的多比特零水印方案，通过优化参考代码以匹配目标二进制信息的投影。这种框架在鲁棒性和通用性上优于现有的自我监督和深层水印技术。

Conclusion: 
该方法在多种图像数据集和广泛干扰条件下，实现了在特征稳定性和水印恢复方面的最佳鲁棒性，并通过与现有自我监督和深层水印技术的比较进一步证明了其所具备的卓越鲁棒性和泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20370</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>350. cs.CV-面集合中的突发性现象</title><link>https://arxiv.org/pdf/2506.20312</link><description>Background: 
在文本和图像检索中观察到的一种现象称为突发性。突发性指的是某些元素在集合中的出现频率高于统计独立模型的预期。我们在这项研究中探讨了这种现象在基于集合的面部识别（SFR）中的普遍存在及其对性能的影响。突发现象在两个方面影响性能：一方面，具有特定属性的突发现面在面部集合中频繁出现，主导了训练实例和训练面部集合，导致在未受约束的情景下泛化能力较差；另一方面，主导评估集的突发现面干扰了集合验证和识别中的相似性比较。

Innovation: 
为检测集合中的突发现象，我们提出了三种策略，包括基于Quickshift++、特征自我相似性和广义最大池化（GMP）的方法。我们还提出了一种质量感知的GMP，能够在原始GMP中增强对前置质量低的面部的鲁棒性。我们通过在SFR基准测试上的示例和广泛实验，证明了突发性普遍存在，抑制突发性显著改善了识别性能。

Conclusion: 
研究表明，面集合中的突发性现象广泛存在，在训练和评估阶段检测到并抑制突发性能够显著提高面部识别性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20312</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>351. cs.CV-Ctrl-Z Sampling: 控制随机菱形探索的扩散采样</title><link>https://arxiv.org/pdf/2506.20294</link><description>Background: 
扩散模型在条件生成任务中表现出色，通过逐步去除高斯噪声向目标数据分布逼近。这一过程可被解释为在模型学习的潜在空间中的一种类似梯山寻顶的过程，其中模型会迭代地改善样本向概率更高的区域。然而，扩散模型往往容易收敛到局部视觉上一致但全局不一致或条件不匹配的局部最优解，这归因于潜在空间的复杂性和初始状态的不优化。以往的努力通过增强引导信号或修改初始噪声分布来尝试解决这个问题。

Innovation: 
本文引入了受控随机菱形采样（Ctrl-Z采样），这是一种新颖的采样策略，旨在在条件生成过程中检测并逃出局部最大值。方法首先使用奖励模型来识别潜在的局部最大值。在检测到后，它会注入噪声并退回到一个更早、更嘈杂的状态来逃离当前的优化平台。接着奖励模型评估候选路径，只接受能够改进的路径，而逐渐深入的退归使得在邻近替代方案失败时能够进行更强的退出。通过这种控制随机菱形过程，可以动态交替前进精炼和后退探索，从而提高生成的输出在对齐和视觉质量上的表现。Ctrl-Z Sampling 是一种不受模型影响的方法，并且与现有的扩散框架兼容。实验结果表明，仅在函数评估次数增加约7.6倍的情况下，Ctrl-Z Sampling 显著提升了生成质量。

Conclusion: 
本文提出的Ctrl-Z Sampling是一种不受模型影响且与现有扩散框架兼容的采样策略。通过在检测到局部最大值时引入噪声和后退探索的过程，能够有效提升生成的高质量输出。实验结果表明该方法能显著提高生成质量。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20294</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>352. cs.CV-突破空间限制：基于光谱域注册的高光谱和多光谱盲融合</title><link>https://arxiv.org/pdf/2506.20293</link><description>Background: 
近年来，未注册的高光谱图像(HSI)和多光谱图像(MSI)的盲融合引起了越来越多的关注。然而，现有的大多数方法通过空间变换对HSI进行处理以实现与MSI的对齐，但由于图像在空间分辨率上的显著差异，这些方法的性能往往不尽如人意。此外，处理遥感中的大尺寸图像时，对齐过程通常会变得耗时。为解决这些问题，本文从光谱域的角度提出了对齐问题的新方法。该方法首先开发了一个轻量级的光谱先验学习(SPL)网络来从HSI中提取光谱特征并提升MSI的光谱分辨率，然后通过时空下采样产生注册的HSI。通过使用子空间表示和循环训练策略进一步改进了注册HSI的光谱精度。

Innovation: 
本文提出了一种基于光谱域的对齐方法，它包括开发了一个轻量级的SPL网络来增强MSI的光谱分辨率，利用子空间表示和循环训练策略提升对齐HSI的光谱精度，并提出了一种盲稀疏融合(Blind Sparse Fusion, BSF)方法，利用组稀疏正则化来进行低秩化，从而避免了秩估计，减少了计算复杂度。最后通过一系列数值实验验证了该方法的有效性，并且证明了它能够提高分类性能。

Conclusion: 
本文方法在对齐和融合方面具有明显的效果，特别是在处理大尺寸图像时能够显著提高计算效率和准确性，并通过实验证明了其有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20293</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>353. cs.CV-基于 transformers 的扩散模型在图像恢复任务中的应用</title><link>https://arxiv.org/pdf/2506.20302</link><description>Background: 
在挑战性环境中捕获的图像常常会遭受各种形式的降级，包括噪声、色偏、模糊和散射光等。这些效果会显著降低图像质量，阻碍其在诸如目标检测、建图和分类之类的下游任务中的应用.

Innovation: 
开发了一种基于变换器的扩散模型，旨在通过改进受损害图像的质量来解决图像恢复任务。该模型在公共数据集上的评估结果表明，其性能优于现有深度学习方法，在水下图像增强、去噪和去雨方面表现突出。模型展示了扩散模型和变换器在提升受损害图像质量方面的有效性和优越性，进而扩大了这些模型在需要高质量视觉数据的下游任务中的应用范围.

Conclusion: 
研究结果表明，结合变换器的扩散模型在性能上优于当前方法，显著提升了受损害图像的质量，扩展了其在需要高保真视觉数据的下游任务中的应用范围。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20302</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>354. cs.CV-从理想到现实：统一且数据高效的密集预测以适应现实场景</title><link>https://arxiv.org/pdf/2506.20279</link><description>Background: 
密集预测任务是计算机视觉中的一个重要领域，旨在通过输入图像进行像素级标注学习。尽管该领域取得了进展，但现有方法主要集中在理想条件下，缺乏对现实世界的泛化能力，并且面临着真实数据稀缺的挑战。现有基准大多只能涵盖有限的任务，无法全面统一地评估多样的密集预测任务，尤其是在处理现实世界的迫切应用场景时。因此，需要引入新的基准和方法，能够系统地解决这一问题，提高现实世界的适用性与数据效率。

Innovation: 
本文首先引入了涵盖25个密集预测任务的基准——DenseWorld，这些任务与现实应用场景紧密相关。提出了一种名为DenseDiT的方法，最大化利用生成模型的先验信息，通过统一的策略来执行多样的密集预测任务。DenseDiT结合了参数复用机制和两个轻量级分支，能够自适应地整合多尺度上下文，整体仅增加不到0.1%的参数量。在DenseWorld上的评估显示，现有通用和专门的方法在现实世界中的泛化能力有限，而DenseDiT仅使用基线训练数据的0.01%即可取得更优结果，展示了其在实际应用中的价值。

Conclusion: 
通过DenseWorld基准和DenseDiT方法的引入，显著提高了现有方法在现实世界应用中的泛化性能和数据效率，为密集预测领域的实际部署提供了有效的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20279</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>355. cs.CV-基于Transformer并联合使用在线和离线特征的 handwriting 识别系统</title><link>https://arxiv.org/pdf/2506.20255</link><description>Background: 
手写识别通常依赖于笔迹的笔划轨迹和栅格化复杂字符提供的互补线索，然而大多数系统仅利用单一模态。文章指出现有系统通常只利用其中一种模态的特点，未能充分利用两种模态的优势。研究者提出了一个端到端的网络，能够将离线图像和在线笔迹数据进行早期融合，从而提高手写识别的效果。

Innovation: 
引入一个端到端网络，该网络可以早期融合离线图像和在线笔迹数据，并使用可学习的潜在查询同时关注两种信号流，生成上下文增强的笔画嵌入。还使用了轻量级的Transformer来编码笔画序列。这种方法在表示学习阶段增强时间线索，使得识别过程中写者之间的差异更小，最终在两个数据集上取得了最先进的精度。此外，该方法也展示了在使用手势化处理后的ISI-Air数据集上的适应性。

Conclusion: 
通过端到端网络和上下文增强的笔画嵌入，该系统在IAMOn-DB和VNOn-DB数据集上显著提高了手写识别的准确性，超越了先前的最佳结果，并通过手势化改进了底层流水线的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20255</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>356. cs.CV-通过织物比较进行绘画法证研究</title><link>https://arxiv.org/pdf/2506.20272</link><description>Background: 
在艺术品研究中，canvas（画布）的研究是鉴定、归属性和保护的重要工具。传统的方法依赖于线密度图匹配，但这种方法在画布无法直接来自卷轴连续位置时无效。本文涉及使用深度学习方法评估纺织品相似性，以弥补传统方法的不足

Innovation: 
本文提出了基于深度学习的新颖方法，通过比较画布图像的特性表示来评估纺织品的相似性。引入了无需依赖线密度图的自动工具，并设计了一个双胞胎深度学习模型进行图像对的比较。此外，提出了一种相似性评估方法，通过对多个织物样本预测的综合评估提供一个稳健的相似性评分

Conclusion: 
本文的方法在普拉多国家博物馆的画布上得到了应用，证明了平纹织物可用于即使线密度相似的情况下有效对比。实验结果显示出新方法的可行性和准确性，对名画分析提供了新的途径</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20272</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>357. cs.CV-动态事件-RGB混合传输中的带宽分配</title><link>https://arxiv.org/pdf/2506.20222</link><description>Background: 
事件相机以极低的延迟异步捕捉像素级的亮度变化，它们常与RGB相机结合使用在各种视觉应用中。然而，这种混合系统中的主要挑战是如何有效地传输大量的触发事件和RGB图像数据，尤其是设计一种既能够保障重建性能又可以实时去模糊的方法成为迫切需求。传统的方法和事件相机通常以不同的方式捕捉相同的场景，导致了两者输出中存在大量冗余信息。这需要一个能够消除冗余信息、优化带宽使用的方法来解决这一问题。本研究提出了一种事件和图像(E-I)的联合传输框架，并利用贝叶斯建模和信息瓶颈方法来分离共享和领域专有的信息，在不牺牲性能的情况下提高数据传输效率，更灵活地应对场景动态变化，为使用事件相机的系统开辟了新的途径，提升混合系统的性能卓越性。

Innovation: 
提出了一种事件和图像(E-I)的联合传输框架，通过贝叶斯建模和信息瓶颈方法有效分离共享和领域专有的信息，使共享和领域专有的信息更加紧凑和有信息量，并能根据场景动态分配带宽。该方法同时实现了高质量的重建效果和卓越的去模糊性能，能够有效消除冗余信息，优化带宽使用。此外，该方法能够在需要更高细节的动态场景中为事件分配更多信息，而在静态场景中更多地为图像分配信息，从而提高系统的性能。

Conclusion: 
本研究提出的方法不仅能够实现优于传统系统的重建质量，还能提升去模糊性能。通过联合传输框架和信息瓶颈方法相结合，不仅可以有效解决冗余信息问题，还可以更加灵活地应对不同的场景动态，乃至提高数据传输效率，进一步推动了事件相机在视觉应用中的使用和发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20222</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>358. cs.CV-Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification</title><link>https://arxiv.org/pdf/2506.20263</link><description>Background: 
FS-FGIC为一个重要挑战，模型需要在有限标记样本的情况下区分类似的小类。现有方法存在缺陷：基于元量的方法丢失空间信息并错误对齐局部特征，基于重构的方法不能利用层次特征信息并且缺乏关注区分区域的机制。

Innovation: 
我们提出了一种新的网络——HMDRN，该网络结合了双层特征重构和掩码增强的特征处理，以改善细粒度分类。HMDRN包括双层特征重构与融合模块，利用不同网络层次的互补视觉信息，并通过可学习的融合权重平衡最后一层的高层语义表示和倒数第二层的中层结构细节。此外，设计了一种空间二元掩码增强的自重构模块，根据自适应阈值处理查询特征，同时保持完全的支持特征，增强对区分区域的关注的同时过滤背景噪声。

Conclusion: 
HMDRN在三种具有挑战性的细粒度数据集上的广泛实验表明，它在Conv-4和ResNet-12骨干架构上始终优于最先进的方法。全面的消融研究验证了每个提议组件的有效性，表明双层重构增强了类间区分，而掩码增强的转换降低了类内变异。可视化结果证明了HMDRN在特征重构能力上的优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20263</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>359. cs.CV-Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement</title><link>https://arxiv.org/pdf/2506.20254</link><description>Background: 
手术工作流程的复杂性和多样性，受到手术室设置、医疗机构协议和解剖变异的影响，给开发通用模型以实现跨机构和跨手术理解带来了重大挑战。尽管最近的手术基础模型通过大规模视觉-语言数据进行预训练表现出良好的可迁移性，但在未见手术环境中，其零样本性能仍受到领域转换的限制。因此，现有模型在这些环境下的实用性受限。

Innovation: 
提出了一种名为Surgical Phase Anywhere (SPA)的轻量级框架，该框架通过最小标注适应基础模型以适应机构设置。SPA利用少量样本的时空适应对多模态嵌入进行校准，确保机构特定的手术场景和阶段一致性，并通过扩散模型编码由机构手术规程导出的任务图先验。此外，SPA还采用了动态测试时适应，利用多模态阶段预测流之间的相互同意来适应给定的测试视频，从而在未见分布时增强可靠性。SPA允许医院通过自然语言文本定义阶段、标注少数带有阶段标签的图像并提供定义阶段转化的任务图来快速自定义阶段识别模型。实验结果表明，SPA框架在跨机构和手术的少量样本手术阶段识别中达到了最先进的性能，即使在32样本标注数据下也优于全样本模型。

Conclusion: 
SPA框架通过少量样本测试时自适应和任务图引导细化，实现了跨环境的手术阶段识别，为医疗机构提供了灵活和高度可定制的解决方案，提高了模型在未知环境中的泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20254</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>360. cs.CV-通过基础模型组合实现地球观测数据挖掘的可扩展性和通用性</title><link>https://arxiv.org/pdf/2506.20174</link><description>Background: 
基础模型正在迅速改变地球观测数据的挖掘方式，使其能够针对场景分类和语义分割等关键任务提供可泛化和可扩展的解决方案。然而，大多数在地学领域的工作集中在开发大规模的基础模型，并从大量地球观测数据集开始训练，而另一种策略，即重用和组合现有的预训练模型，尚未被广泛应用和探索。这项研究旨在探讨是否可以通过将远程传感器和通用视觉数据集上预训练的小型模型进行特征级组合来提高多类关键地球观测任务的性能。研究使用GEO-Bench基准测试了多个知名模型，包括Prithvi、Hiera和DOFA。

Innovation: 
研究通过将远程传感器和通用视觉数据集上预训练的小型模型进行特征级组合，展示了这种组合策略在多个关键地球观测任务上的有效性，其性能可以与大型模型相当，同时所需的训练时间和计算资源更少。此外，研究强调了知识传递的应用潜力，可以将组合模型的优势转移到更紧凑的模型中，为在实际地球观测应用中部署基础模型提供了一条实用的途径。

Conclusion: 
特征级组合小型预训练模型可以匹配甚至超越大型模型的性能，同时需要更少的训练时间和计算资源。知识传递的应用潜力使得基础模型可以在实际地球观测应用中得到更有效的部署。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20174</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>361. cs.CV-UniCode^2：统一的大规模级联码本框架以实现统一的跨模态理解和生成</title><link>https://arxiv.org/pdf/2506.20214</link><description>Background: 
统一的大规模多模态语言模型（MLLMs）展现了在协同推进多模态理解和生成上的潜力，其中视觉码本将图像离散为令牌以进行自回归建模。现有的码本方法要么依赖小词汇量（约16K个条目），缺乏精细语义，要么粗暴地扩展，导致令牌利用率低和训练不稳定。这些码本方法在视觉代号与文本语义对齐上存在问题，影响了多模态任务的稳定性和效率，限制了模型的能力和应用场景。因此需一种大规模、语义对齐且稳定的视觉代号化方案来提升模型效果及其在实际应用中的表现。

Innovation: 
UniCode^2 提出了一个多级码本框架，实现了大规模、语义对齐且稳定的视觉代号化。通过聚类数百万个SigLIP序列嵌入，构建了一个50万个条目的码本，既保持了视觉-语言对齐，又扩大了容量。采用多级设计确保稳定性：一个冻结的码本固定嵌入空间，一个可训练的码本细化任务特定的语义，这种解耦合促进高利用率和鲁棒性学习。此外，UniCode^2 的视觉代号与文本语义的对齐支持了与预训练扩散解码器无缝集成，促进了高质量的视觉合成，且需最少的适应调整。此方法展示了不牺牲稳定性、语义和模块性的视觉代号空间扩展的可能性。

Conclusion: 
UniCode^2 在各种基准测试中表现出色，证明了在不牺牲稳定性、语义或模块性的前提下，可视化代号空间扩展的可行性。其稳定的大规模级联码本框架为统一的多模态理解和生成提供了可靠的方法，展示了在实际应用中的强大性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20214</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>362. cs.CV-如何看待现实？在多模态大语言模型中缓解OCR幻觉现象</title><link>https://arxiv.org/pdf/2506.20168</link><description>Background: 
近年来，多模态大语言模型通过整合文本和视觉信息已经提升了文档的理解能力，然而，现有的模型在实际场景中表现出一定局限性，特别是在视觉降级情况下。这种条件下，模型往往无法准确识别视觉降级和模糊性，过度依赖于语言先验或不一致的视觉-文本推理，导致生成幻觉内容。为了揭示和分析这一现象和问题，本文提出KIE-HVQA，这是首个专门评估OCR幻象在降级文档理解中的基准数据集。该数据集包括身份证明和发票的测试样本，并通过模拟现实世界降级情况评估OCR可靠性，以此来检验模型在输入降级情况下识别可靠视觉信息并相应回答的能力，突显在不确定数据上避免幻觉的挑战。通过使用基于GRPO的框架并引入新的奖励机制，结合视觉不确定性感知和引发回答拒绝的方法增加任务难度，从而缓解了模糊区域的幻觉现象。实验表明，我们的7B参数模型在KIE-HVQA中的幻觉无误准确性相比GPT-4o提高了22%，且在标准任务上没有显著性能下降，这证明了该方法的有效性和鲁棒性。

Innovation: 
本文提出了KIE-HVQA，这是首个专门评估OCR幻觉在降级文档理解中的基准数据集，通过模拟现实世界中的视觉降级情形，评估多模态大语言模型在低质量输入下的性能。此外，本文还介绍了一种基于GRPO框架的新颖奖励机制和包含自感知视觉不确定性的拒绝回答方法，从而在监督微调和强化学习框架下缓解幻觉现象。

Conclusion: 
通过实验，证实了该基于GRPO的新型多模态大语言模型框架的有效性和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20168</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>363. cs.CV-Pansharpening中的渐进对齐退化学习</title><link>https://arxiv.org/pdf/2506.20179</link><description>Background: 
基于深度学习的多光谱彩色融合（Pansharpening）已被证明能有效生成高分辨率多谱成像（HRMS）。常用的方法是使用合成数据生成监督地实高分辨率多谱数据，这些数据是基于Wald协议生成的。Wald协议假设，训练于低分辨率数据的网络在高分辨率数据上的表现与低分辨率相同。然而，经过充分训练的模型通常在其低分辨率和高分辨率数据集上表现出性能的权衡。因此，本文探讨了Wald协议不准确地近似真实退化模式对深度Pansharpening模型泛化能力的限制。

Innovation: 
文章提出了渐进对齐降级模块（PADM），该模块使用两个子网络PAlignNet和PDegradeNet之间的相互迭代，自适应地学习准确的降级过程，无需依赖预定的操作器。此外，文章引入了HFreqdiff，这是一种嵌入高频细节的扩散框架，并且集成了CFB和BACM模块，这使得高频细节选择性和精确的逆向过程学习成为可能。这些创新使高分辨率的全色和多谱影像的整合更加有效，显著提高了空间锐度和影像质量。

Conclusion: 
实验和消融研究显示，本文提出的方法在与当前最先进技术的性能上具有显著优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20179</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>364. cs.CV-利用多模态VLMs实现高效示例驱动图像编辑</title><link>https://arxiv.org/pdf/2506.20155</link><description>Background: 
文本到图像的扩散模型已经使得各种图像编辑应用变得广泛。然而，仅通过文本捕捉各种类型的编辑是具有挑战性和繁琐的。某些图像编辑的模糊特性更容易通过示例对来表达，即一对图像分别显示编辑前后的情况。本文研究了基于示例的图像编辑任务，即利用预训练的文本到图像的扩散模型和多模态VLMs将示例对中的编辑应用到内容图像上。尽管整个端到端的流水线是无需优化的，但我们的实验表明，它在多种编辑类型上仍然优于基线方法，并且速度快4倍左右。

Innovation: 
利用预训练的文本到图像扩散模型和多模态VLMs来实现基于示例的图像编辑，且无需优化，能高效地将特定的编辑应用到内容图像上，并且在多种类型的编辑中表现优于基线方法，同时速度更快。

Conclusion: 
我们提出的方法在多个编辑类型上优于基线方法，并且在不需要优化的情况下实现了高效的基于示例的图像编辑，证明了该方法的有效性和效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20155</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>365. cs.CV-BrokenVideos: 一个用于AI生成视频细粒度缺陷定位基准数据集</title><link>https://arxiv.org/pdf/2506.20103</link><description>Background: 
尽管近年来深度生成模型在视频生成方面取得了显著进展，但AI生成视频的真实度仍然有限。合成内容常常会出现视觉上的不一致运动、物理上不合理的轨迹、不自然的对象变形以及局部模糊等缺陷，这些缺陷会削弱视频的真实感和用户的信任度。准确检测和空间定位这些缺陷对自动质量控制和改进生成模型至关重要。然而，目前研究界缺乏一个专门用于定位AI生成视频缺陷的综合基准。现有的数据集要么仅限于视频或帧级检测，要么缺乏必要的细粒度空间注释，无法评估定位方法的有效性。因此，为了填补这一缺口，引入了BrokenVideos，这是一个包含3254个精心标注、像素级遮罩的AI生成视频基准数据集，这些遮罩突显了视觉缺陷的区域。每个标注都通过详尽的人类检查来确保高质量的地面真实数据。

Innovation: 
通过BreakingVideos，研究界首次获得了一个专门用于定位AI生成视频细粒度缺陷的基准数据集。实验表明，在BreakingVideos上训练最先进的缺陷检测模型和多模态大语言模型（MLLMs）可以显著提高它们在定位受损区域的能力。此数据集为生成视频模型中的缺陷定位研究提供了关键的基础。

Conclusion: 
BreakingVideos 为评估和推进生成视频模型中缺陷定位研究奠定了基础。该数据集通过详细的评价，证明了其在提高模型定位能力和推进研究方面的重要性。数据集可在指定链接处获得。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20103</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>366. cs.CV-损失感知的选择性剪枝标准的自动选择方法用于深度神经网络加速</title><link>https://arxiv.org/pdf/2506.20152</link><description>Background: 
结构化剪枝是一种广泛认可的神经网络压缩技术，适用于资源受限的边缘设备。大多数剪枝方法遵循一个包含三个阶段的顺序过程：1）训练，2）剪枝，3）微调。这种剪枝方法采用边训练边剪枝的方法，省略了初始的训练阶段，并将剪枝和微调阶段整合为一个循环。该方法通过网络整体损失指导特定剪枝层的选择和剪枝标准（基于幅度或相似度）的选择，基于一个小训练数据子集。通过每隔一定数量的运算法次数后重新训练网络，来缓解剪枝引起的精度突然下降。针对VGGNet和ResNet模型在CIFAR-10和ImageNet基准数据集上的实验表明，该方法具有有效性。ResNet56和ResNet110模型在CIFAR-10数据集上的L1精度显著提升，FLOPs降低了52%，而ResNet50模型在ImageNet数据集上的FLOPs减少了超过42%，且只降低了0.33%的L5精度。研究的源代码已公开在线。

Innovation: 
提出的剪枝技术采用边训练边剪枝的方法，将剪枝和微调阶段整合为一个循环，自动从指定的标准池中选择幅度或相似度基于的滤波器剪枝标准，并确定每层的最佳剪枝率，从而省去了手动分配固定或可变剪枝率的需求。

Conclusion: 
通过在CIFAR-10和ImageNet数据集上的实验，提出的方法证实了其有效性和能够显着提高模型性能的同时降低计算复杂性。源代码已公开，为其他研究人员提供了便利。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20152</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>367. cs.CL-经过训练的嵌入证明性地选择重要令牌的注意力机制</title><link>https://arxiv.org/pdf/2505.17282</link><description>Background: 
令牌嵌入在语言建模中扮演着至关重要的角色，尽管其在实践中的重要性显著，但这些嵌入的理论理解仍然相当有限。该论文通过分析通过梯度下降获得的嵌入结构来填补这一理论空白。论文以一个一维Softmax注意力模型为例，模型具有线性头部，用于二元分类。已有研究表明，仅仅经过一次带有逻辑损失的梯度训练后，嵌入 $E_X$ 就能捕捉到令牌在数据集中的重要性，这一点是按出现在数据集中的频率与输出向量 $v$ 成比例对齐。进一步的研究表明，通过梯度流训练参数 $p$ 至收敛后，Softmax选择那些预测标签的重要令牌，并且最终产生的 $texttt{&amp;lt;cls&amp;gt;}$ 嵌入最大化了这些选择的边际。实验结果表明，实际数据集（如IMDB、Yelp）上的现象与我们理论揭示的现象非常接近。

Innovation: 
该论文的主要创新在于通过严格理论分析，揭示了一个嵌入经过一次梯度训练后即能捕获令牌重要性的现象，并进一步探讨了在连续训练直至收敛后的选择机制。研究结果证明，经过训练的嵌入能够证明性地挑选出在句子中预测标签重要的令牌，这种选择机制在实际数据集上表现出显著的效果。

Conclusion: 
研究发现，嵌入在一次梯度训练后就能够反映令牌在数据集中的重要性，并且通过连续的梯度训练可以使Softmax机制在选择预测标签的重要令牌时最大化边际。这些发现不仅提供了对嵌入机制理论的理解，还展示了它们在实际任务中的有效性，特别是对于二元分类问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.17282</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>368. cs.CV-EAR: 从统一自回归模型中擦除概念</title><link>https://arxiv.org/pdf/2506.20151</link><description>Background: 
自回归（AR）模型在视觉理解和图像生成任务上都取得了统一且强大的表现。然而，如何在保留在整体生成质量的同时去除不需要的概念，仍然是一个开放的挑战。本文背景在于如何解决这一挑战，提出了一种有效且能保持模型实用性的概念去除方法。

Innovation: 
本文提出了一种窗口梯度累积（WGA）策略，使局部解码与擦除目标对齐，以及阈值损失遮罩（TLM）策略，在微调过程中保护与目标概念无关的内容。此外，还提出了一种新的基准测试，名为Erase Concept Generator and Visual Filter（ECGVF），旨在提供一个更严谨和全面的基础来评估AR模型中的概念去除效果。通过使用结构化模板和视觉分类器对生成的图像进行严格的过滤，确保概念的一致性和对齐。实验结果表明，EAR方法在擦除效果和模型实用性保护方面取得了显著的改进。

Conclusion: 
实验结果在ECGVF基准上进行，采用AR模型Janus-Pro显示，EAR方法在擦除效果和模型实用性的保持上都有显著提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20151</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>369. cs.CV-ToSA: Token Merging with Spatial Awareness</title><link>https://arxiv.org/pdf/2506.20066</link><description>Background: 
Token merging是一种通过减少计算成本来加速视觉转换器（ViT）的有效策略。现有方法主要依赖视觉令牌的特征相似性来进行令牌合并，忽略了空间信息融合的可能性。特别是在ViT的早期层中，视觉令牌仅拥有较弱的视觉信息，但空间信息可以作为一个可靠的合并标准。本研究旨在通过利用深度图像生成伪空间令牌，将语义和空间信息融合来改进现有的令牌合并方法。

Innovation: 
本研究提出了ToSA（Token Merging with Spatial Awareness），一种结合语义和空间感知来指导令牌合并的新方法。ToSA通过深度图像生成伪空间令牌，作为视觉令牌合并过程的辅助空间信息。引入的空间意识使得令牌合并更为明智，更好地保留了关键场景结构，从而在多个视觉和承载式问答基准测试中优于之前的方法，并显著减少了ViT的运行时间。

Conclusion: 
实验结果表明，ToSA在多种视觉和承载式问答基准测试中优于先前的令牌合并方法，同时显著减少了ViT的运行时间，使其成为ViT加速的高效解决方案。该代码将在此网址获取：this https URL</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20066</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>370. cs.CL-OmniGen2：探索高级多模态生成</title><link>https://arxiv.org/pdf/2506.18871</link><description>Background: 
本文介绍了OmniGen2，这是一种多功能且开源的生成模型，旨在提供用于包括文本到图像、图像编辑和上下文生成在内的多种生成任务的统一解决方案。OmniGen2的构建基于现有的多模态理解模型，但具有两个独立的解码路径，分别用于文本和图像模态，并且没有共享参数和独立的图像标记器。这些改进使得OmniGen2无需重新适应VAE输入即可构建在现有模型之上，从而保留了原始的文本生成能力。为了支持OmniGen2的训练，作者开发了涵盖图像编辑和上下文生成数据的全面数据构建管道，并引入了一种针对图像生成任务的反馈机制，基于OmniGen2构建了专用的反馈数据集。尽管参数量相对较小，但OmniGen2在文本到图像和图像编辑等多个任务基准测试中表现出竞争力。为了进一步评估上下文生成，即主题驱动任务，作者还提出了一个新的基准——OmniContext，该模型在开放源代码模型中实现了最先进的性能，尤其是在一致性方面。

Innovation: 
OmniGen2创新地采用了两个独立的解码路径，分别处理文本和图像模态，并且没有共享参数和独立的图像标记器。这种设计使得OmniGen2能够基于现有模型构建，无需重新适应VAE输入，从而保留原始的文本生成能力。作者还开发了用于OmniGen2的全面数据构建管道，并引入了专门针对图像生成任务的反馈机制，以及对应的反馈数据集。这些改进使得OmniGen2在多个任务基准测试中达到了竞争力的性能。

Conclusion: 
尽管参数量相对较小，但OmniGen2在多项任务基准测试中取得了竞争力的性能。为了进一步评估上下文生成，即主题驱动任务，提出了新的基准OmniContext，并且展示出先进的性能特别是在一致性方面。OmniGen2的模型、训练代码、数据集和数据构建管道将对这一领域的未来研究提供支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18871</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>371. cs.CV-从2D到3D认知：通用世界模型的简要综述</title><link>https://arxiv.org/pdf/2506.20134</link><description>Background: 
随着人工智能通用智能（AGI）的发展，世界模型逐渐受到关注，用作计算框架，学习外部世界的表示和预测未来状态。虽然早期工作主要集中在2D视觉感知与模拟上，近年来具备3D意识的生成世界模型展示了合成几何上一致、具有交互性的3D环境的能力，标志着向3D空间认知的转变。尽管进展迅速，但该领域缺乏系统分析来分类新兴技术及其在推进3D认知世界模型中的作用。本文通过介绍一个概念框架，提供了一种结构化、前瞻性的综述，从2D感知过渡到3D认知，探讨了关键的先进技术驱动因素和核心认知能力。

Innovation: 
本文主要创新在于提出了一个概念框架，系统地概述了从2D感知向3D认知转变的世界模型的发展历程，特别是强调了3D表示和技术知识的集成作为核心支柱，并详细分析了构建3D世界模型的核心认知能力：3D物理场景生成、3D空间推理、3D空间交互。同时，还探讨了这些能力在实际应用中的部署情况，包括使能AI、自动驾驶、数字孪生和游戏/VR，指出了数据、建模和部署等方面面临的挑战，为开发更稳健和具有通用性的3D世界模型指明了未来方向。

Conclusion: 
本文最终确定了面临的数据、建模和部署方面的挑战，提出了推动更稳健和具有通用性的3D世界模型的发展方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20134</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>372. cs.CV-EBC-ZIP：通过零膨胀泊松回归提高分块人群计数</title><link>https://arxiv.org/pdf/2506.19955</link><description>Background: 
密度图估计已成为人群计数的主要范式。然而，大多数现有方法忽略了地面真实密度图的极端稀疏性。在现实世界的人群场景中，大多数空间区域（通常超过95%）不包含人员，导致人群计数分布高度失衡。忽略这种失衡会使模型倾向于高估密集区域，而无法有效地处理稀疏区域。此外，用于密度估计的大多数损失函数主要基于MSE，假设数据为高斯分布，这不适用于建模离散的非负计数数据。

Innovation: 
本文提出了一种人群计数框架EBC-ZIP，该框架使用零膨胀泊松（ZIP）回归模型来表示计数的空间分布。该方法用ZIP分布的负对数似然替代了传统的回归损失，从而更好地处理了零元素较多的分布，同时保持了计数准确性。该方法基于最近提出的增强块分类(EBC)框架，继承了EBC在保持目标离散性和训练稳定性方面的优点，并通过更为原理性的概率损失进一步提高了性能。同时，还使用不同计算复杂性的骨干网络评估了EBC-ZIP的可扩展性。

Conclusion: 
在四个不同的人群计数基准上的广泛实验表明，EBC-ZIP 一致地优于 EBC，实现了最先进的结果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19955</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>373. cs.CV-基于计算机视觉的农业喷雾器boom位移自动量化</title><link>https://arxiv.org/pdf/2506.19939</link><description>Background: 
在使用自走式农业喷雾机进行农业生产时，施药率错误仍然是一个值得关注的问题。喷雾臂不稳定是导致这些错误的主要因素之一。综上所述，38米宽的喷雾臂、30公里/小时的行驶速度、多变的地形和在处理复杂田块边界时的机器动态性，使得对这些喷雾臂的控制变得非常复杂。然而，目前缺乏定量知识来准确了解喷雾臂的位移量，这妨碍了开发解决方案，这些解决方案可能包括喷雾臂的设计和响应操控系统。因此，本研究旨在开发一个自动化的计算机视觉系统来量化各种农业喷雾器的喷雾臂位移量。

Innovation: 
研究开发了一个计算机视觉系统来实时跟踪位于喷雾臂边缘的目标，使用YOLO V7、V8和V11神经网络模型进行训练，以便在田间作业中量化垂直和横向的有效位移。通过在喷雾臂上安装测斜仪来捕捉喷雾臂的角度，验证神经网络模型的输出结果。研究表明，该模型可以以超过90%的准确率检测目标，并且目标在喷雾臂上的距离估计值与测斜仪传感器数据相差不到0.026米。此系统可以量化当前喷雾器的喷雾臂位移，并可能应用于任何其他喷雾器（进行少量修改）。研究还透露，这些数据可用于改进喷雾臂的设计，以使其更具稳定性并实现更高的施药准确性。

Conclusion: 
该研究成功地开发了一个自动化的计算机视觉系统，可以实时、准确地量化各种农业喷雾器的喷雾臂位移量。通过与测斜仪的数据进行对比，证实该系统能够可靠地量化喷雾臂的运动，并为提高喷雾器的结构稳定性和施药准确性提供了技术支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19939</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>374. cs.CL-Aug2Search：利用大型语言模型生成的合成数据增强的Facebook Marketplace搜索</title><link>https://arxiv.org/pdf/2505.16065</link><description>Background: 
嵌入式检索（EBR）是一种现代搜索引擎中的关键技术，能够实现搜索查询与相关结果的语义匹配。然而，像Facebook Marketplace这样的平台上的搜索日志数据缺乏有效训练EBR模型所需的多样性和详细信息，限制了模型捕捉细微搜索模式的能力。为了应对这一挑战，该研究提出Aug2Search框架，通过利用生成式AI（GenAI）模型生成的合成数据，采用多模态和多任务方法优化查询与产品之间的相关性。研究调查了大型语言模型（LLMs）在生成高质量合成数据方面的能力及其对EBR模型性能的提升作用。实验采用了八个Llama模型和来自Facebook Marketplace的1亿条数据点进行研究，以评估不同训练集上的EBR模型性能。研究发现，Llama模型生成的合成查询和产品列表具有高一致性、相关性和多样性，同时保持了低幻觉水平。在1亿合成数据样本的情况下，Aug2Search在ROC_AUC上提高最高达4%，证明了该方法的有效性。同时，实验表明，在相同数据量下，仅使用生成数据训练的模型通常优于只使用原始数据或原始合成数据混合训练的模型。

Innovation: 
提出了Aug2Search框架，利用大型语言模型生成的合成数据增强Facebook Marketplace搜索的查询与产品相关性。研究特别关注了大型语言模型在生成高质量合成数据方面的应用，并分析了其对EBR模型性能的提升。通过多模态和多任务方法优化查询——产品相关性，并展示了使用合成数据的优势，特别是在保持低幻觉水平的同时，实现高达4%的性能提升。同时，该研究表明仅使用合成数据训练的模型在某些情况下比使用原始数据或混合数据训练的模型表现更好。

Conclusion: 
研究证实了利用生成数据增强EBR模型的有效性，特别是在Facebook Marketplace这种搜索日志数据缺乏多样性的场景中。Llama模型生成的合成数据展示了高一致性和相关性，且维持了数据质量，从而提高了EBR模型的鲁棒性和性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.16065</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>375. cs.CL-Confucius3-Math: 专为中国K-12数学学习设计的轻量高性能推理大语言模型</title><link>https://arxiv.org/pdf/2506.18330</link><description>Background: 
研究团队引入了Confucius3-Math，这是一个具有140亿参数的开源大型语言模型，能够在单个消费级GPU上高效运行，同时在一系列数学推理任务中表现出最先进的性能，甚至超过了大量规模更大得多的模型。作为使命的一部分，旨在利用AI增强教育和知识传播，Confucius3-Math特别致力于为中国K-12学生和教育者提供数学学习支持。该模型是通过大规模强化学习后训练完成的，能够低成本解决主流的中国K-12数学问题，并且能够与国家课程标准相匹配。

Innovation: 
该团队开发了三种技术创新：目标熵正则化（Targeted Entropy Regularization）、最近样本恢复（Recent Sample Recovery）和政策特定难度加权（Policy-Specific Hardness Weighting）。这其中包括了一种新的熵正则化、一种新颖的数据调度策略以及一个改进的组内相对优势估算器。这些创新显著地稳定了强化学习培训，提高了数据效率，并提升了性能。

Conclusion: 
这项工作表明，在特定领域以低成本构建强大的推理模型是可行的。团队已经开源了他们的模型和代码。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18330</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>376. cs.CL-思考锚点：哪些大语言模型的推理步骤是关键？</title><link>https://arxiv.org/pdf/2506.19143</link><description>Background: 
大语言模型在许多领域取得了最先进性能，但长篇链条推理带来了可解释性的挑战，因为生成的每个令牌都依赖于此前所有令牌，使得分解计算更加困难。我们认为，在句子级别分析推理过程有望理解推理过程。论文提出三种互补的归因方法来探究这种现象。

Innovation: 
论文提出了三种在句子级别探索大语言模型推理过程的方法，包括黑箱方法、白箱方法以及因果归因方法，并发现存在关键的推理步骤（称为思考锚点），通常是计划或回溯句子，并开放工具供可视化使用，展示在句子级别分析对于深入理解推理模型的潜力。

Conclusion: 
不同的方法之间的一致性证明了在句子级别的分析对于更深入理解推理模型的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19143</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>377. cs.CL-PP-DocBee2：提高基线性能和高效数据的多模态文档理解</title><link>https://arxiv.org/pdf/2506.18023</link><description>Background: 
PP-DocBee2是PP-DocBee的进阶版本，旨在增强多模态文档理解能力。它基于大型多模态模型架构，通过关键的技术改进解决了前一代产品的不足，包括提高合成数据的质量、改进视觉特征融合策略以及优化推理方法。这些改进在内部基准测试中提升了11.4%的性能，并将推理延迟降低了73.0%至基础版本。

Innovation: 
这项工作的关键创新在于多模态文档任务中数据质量优化策略。该团队使用大规模的多模态预训练模型来评估数据，并应用新的统计标准来过滤异常值，保证高质量的训练数据。此外，通过分解ViT的表示能力并采用新的特征融合策略，增强了模型对复杂推理的支持，利用了多模态模型中未充分利用的中间特征。

Conclusion: 
PP-DocBee2通过提高合成数据质量、优化特征融合策略以及使用高效的推理方法，在内部基准测试中取得了显著的性能提升，并降低了推理延迟。研究成果已在GitHub上开源，包括源代码和预训练模型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18023</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>378. cs.CL-科学家的第一考：通过感知、理解和推理探究MLLM的认知能力</title><link>https://arxiv.org/pdf/2506.10521</link><description>Background: 
科学发现越来越依赖基于信息密集型科学数据和领域专业知识的复杂多模态推理。尽管科学级的多模态大规模语言模型（MLLMs）有可能在现实工作中大幅增强这一发现过程，但现有科学基准主要集中在评估MLLMs的知识理解能力上，忽略了它们的感知和推理能力。因此，需要一个新的基准来全面评估MLLMs的科学认知能力，包括感知、理解和推理三个层面的多个任务。

Innovation: 
该论文提出了Scientist's First Exam (SFE)基准，设计用于评估MLLMs的科学认知能力，包括科学信号感知、科学属性理解、科学比较推理三个层面。SFE包含830个专家验证的多模态问答对，覆盖五个高价值学科领域中的66个任务。实验结果表明，当前最先进的模型GPT-o3和InternVL-3在SFE上的得分分别为34.08%和26.52%，显示出改进空间巨大。

Conclusion: 
SFE基准的研究结果将有助于进一步推动AI增强的科学发现发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.10521</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>379. cs.CL-VIFFA: 视觉解释和理解生成报告中胸部X射线异常而不依赖人工反馈</title><link>https://arxiv.org/pdf/2501.17726</link><description>Background: 
随着人工智能（AI）在医疗领域中的应用越来越广泛，对可解释且可信的模型的需求日益增加。当前的胸部X光报告生成系统通常缺乏无需专家监督就可验证输出的机制，这引发了关于可靠性和可解释性的担忧。本研究旨在应对这些挑战，提出了一种新的多模态框架，以增强AI生成的医疗报告的语义对齐和定位准确性。该框架结合了两个关键模块：短语定位模型，它基于文本提示在胸部X光图像中识别和定位病理；以及文本转图像扩散模块，它可以从提示中生成合成的胸部X光图像，同时保持解剖结构的精确性。通过在原始和生成的图像之间比较特征，引入了双评分系统：一个评分量化定位精确度，另一个评分评估语义一致性。这种方法显著优于现有方法，在病理定位和文本到图像对齐方面达到了最先进的性能。将短语定位与扩散模型相结合，并采用双评分评估系统，为验证报告质量提供了一种稳健的机制，这为更可信和透明的医疗成像AI技术铺平了道路

Innovation: 
提出的多模态框架结合了短语定位模型和文本转图像扩散模块，通过在原始和生成的图像之间比较特征提出了双评分系统，显著提高了病理定位的准确性和文本到图像对齐的一致性，解决了现有的胸部X光报告生成系统的验证机制缺乏问题，从而为AI在医疗影像领域的应用提供了更可靠且透明的基础。

Conclusion: 
通过将短语接地与扩散模型相结合，并引入双评分评价系统，该研究为验证AI生成的医疗报告的质量提供了一种可靠的机制，展现了更可信和透明的AI在医疗影像应用中的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.17726</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>380. cs.CL-作为NLP任务的治疗：心理学家对LLMs和人类同伴在认知行为疗法中的比较</title><link>https://arxiv.org/pdf/2409.02244</link><description>Background: 
研究表明，大型语言模型（LLMs）在生成单一的同理反应方面可能超越人类咨询师，但它们在会话层面的行为仍需进一步研究。本研究旨在比较人类咨询师和由同伴咨询师团队引导的LLM进行单次认知行为疗法（CBT）会话的行为。研究团队采用了一种多阶段、混合方法的研究方法，包括持续一年的心理学和社会学研究、模拟人类医生的会话和临床心理学家对会话的评估，以展示LLMs在生成单一同理响应方面可能超越人类咨询师，但在引导会话方面能力有限，强调治疗不能简化为独立的自然语言处理（NLP）任务。

Innovation: 
研究采用了多阶段的混合方法，包括持续一年的心理学和社会学研究、模拟人类医生的会话以及临床心理学家对会话的评估，展示了LLMs在生成单一同理响应方面可能超越人类咨询师，但在引导会话方面能力有限，并提出了人类与AI的协作工作流程。

Conclusion: 
尽管LLMs在生成单一同理响应方面可能优于人类咨询师，但在引导会话方面的能力有限，表明治疗不能简化为独立的NLP任务。研究建议设计人类与AI的协作工作流程以实现可扩展的支持：LLMs可以帮助结构化且证据驱动的技术，而同伴则提供关系支持。此外，研究确定了此类混合系统的具体设计机会和伦理指南。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.02244</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>381. cs.CL-GlyphPattern：视觉语言模型的抽象模式识别基准</title><link>https://arxiv.org/pdf/2408.05894</link><description>Background: 
基于强大大型语言模型的基础，视觉语言模型（VLMs）在跨视觉和文本数据的推理方面取得了快速发展。虽然VLMs在它们训练的任务上表现良好，但我们的研究结果指出了抽象模式识别中的关键挑战。为此，我们提出了GlyphPattern，这是一个由318个人手写的来自40种书写系统的视觉模式描述与三种视觉展示风格配对而成的数据集，旨在评估VLMs在抽象模式识别上的表现。这些模式来源于大规模的认知科学研究，因此富含空间参考和组合性，使得它们评价模型全面理解与判断视觉模式的能力更加丰富多样。我们的实验结果显示，即使是最先进的VLMs（GPT-4o仅达到55%的准确率），也难以应对这一挑战，即便有少量提示输入也仅有微小的性能提升。详细的错误分析揭示了多方面的挑战，包括视觉处理、自然语言理解和模式泛化的难度。

Innovation: 
该论文创新地提出了一个名为GlyphPattern的数据集，用于评估视觉语言模型在抽象模式识别上的能力。该数据集收集了318个人写的文章，并与3种视觉呈现方式组合，具有丰富的空间参考和组合性。通过该数据集，可以全面评估模型在理解与判断视觉模式的能力。此外，实验表明即使是最先进的VLMs在该基准上也表现不佳，凸显了当前模型在某些方面仍需改进的挑战。

Conclusion: 
我们的实验展示了视觉语言模型在抽象模式识别方面仍存在显著的挑战，虽然少量提示可以在一定程度上提高准确率，但总体表现并不令人满意。今后的研究需要聚焦在如何改进模型在视觉处理和自然语言理解之间的综合能力，以克服这些挑战，提升模型在抽象模式识别任务上的性能表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.05894</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>382. cs.CL-mSTEB: 大规模多语言评估大语言模型在语音和文本任务上的表现</title><link>https://arxiv.org/pdf/2506.08400</link><description>Background: 
大语言模型（LLMs）在各种任务中表现出色，但仍主要集中在英语和高资源语言上。对于低资源语言没有标准化的评估基准。因此，本文通过提出一个涵盖语言识别、文本分类、问答和翻译任务的新基准mSTEB，解决了这一问题。这些任务包括语音和文本模态。文章评估了一些领先的大语言模型，如Gemini 2.0 Flash、GPT-4o（Audio）和Qwen 2 Audio、Gemma 3 27B等最先进的开放模型。研究表明，高资源语言和低资源语言之间存在显著的性能差距，特别是在非洲和美洲/大洋洲使用的语言中。这些发现表明，需要更多的投资来解决这些语言在大语言模型覆盖范围中的代表性不足问题。

Innovation: 
本文提出的mSTEB是一个多语言评测基准，涵盖了语言识别、文本分类、问答和翻译任务，并专注于评估语言模型在语音和文本模态上的表现。这对于低资源语言的评测尤为重要。

Conclusion: 
高资源语言和低资源语言之间存在显著的性能差距，特别是在发展中国家使用的语言中。需要更多投资来提高低资源语言在大语言模型中的代表性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.08400</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>383. cs.CL-在症状检查器中评估罕见疾病诊断性能：合成案例模拟方法</title><link>https://arxiv.org/pdf/2506.19750</link><description>Background: 
症状检查器（SCs）为用户提供个性化医学信息。为了防止算法更新导致性能下降，SC开发者必须在部署前评估单一罕见疾病诊断性能的变化。然而，获取用于罕见疾病评估的数据是困难的，手动创建大量临床案例情况既昂贵又不切实际。该研究提出并验证了一种新的合成案例模拟方法，用于评估SC算法更新后单一罕见疾病的诊断性能变化。研究使用了人类表型本体（HPO）中的疾病-表型注释来生成合成案例。通过这些案例，研究模拟了SC访谈，以估算算法更新对实际诊断性能的影响。方法的有效性通过与实际指标变化的$R^2$系数进行回顾性比较来评估。实验包括了八个过去的SC算法更新。对于具有HPO频率信息的疾病（n=5），Recall@8的变化$R^2$为0.831（p=0.031），Precision@8的变化$R^2$为0.78（p=0.047），表明该方法可以预测部署后的性能。对于没有频率信息的疾病（n=3），则出现了较大的预测误差，突显了其重要性。该方法允许开发者使用一个公开可用、专家创建的知识库来提前评估单一罕见疾病SC算法变化，提供了一种透明且低成本的方法，可以有效地提高罕见疾病的诊断性能，从而可能增强早期诊断的支持。

Innovation: 
该研究提出了一种新的合成案例模拟方法，利用人类表型本体（HPO）中的疾病-表型注释来生成合成案例，以此来预测并评估SC算法更新后单一罕见疾病的诊断性能变化。这种方法有效地解决了罕见疾病评估数据获取困难的问题，为开发者提供了低成本、高效率的方法来评估并改进诊断性能。

Conclusion: 
该方法允许开发者利用公开可获取、专家创建的知识库来提前评估个体罕见疾病的SC算法变化，提供了一种透明且低成本的方法，可以有效地提高诊断性能，可能有助于早期诊断的支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19750</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>384. cs.CL-WAFFLE：多模态模型的微调用于自动化前端开发</title><link>https://arxiv.org/pdf/2410.18362</link><description>Background: 
前端开发涉及将UI设计转化为功能性网页，由于HTML的层级结构和样式的复杂性，这既对新手也对经验丰富的开发者构成挑战。虽然大规模语言模型（LLMs）展示出生成源代码的潜力，但在UI到HTML代码生成过程中存在两大挑战：一是有效向LLMs表达HTML的层级结构，二是弥合UI设计的视觉特性与HTML代码文本格式之间的差距。

Innovation: 
本文提出Waffle，一种新的微调策略，它使用结构感知注意机制改进LLMs对HTML结构的理解，并采用对比微调方法让LLMs理解和对齐UI图像与HTML代码之间的关系。使用Waffle微调后的模型在新的基准测试WebSight-Test和现有基准Design2Code上分别在HTML匹配度、CW-SSIM、CLIP和LLEM方面表现突出，优于现有的微调方法，显示出高达9.00个百分点的HTML匹配度提升、0.0982的CW-SSIM、32.99的CLIP和27.12个百分点的LLEM提高。

Conclusion: 
本研究通过提出Waffle，显著提升了UI到HTML代码生成的质量，为自动化前端开发提供了更有效的工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.18362</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>385. cs.CL-语言模型能否替代程序员进行编码？REPOCOD 表示‘尚不能’</title><link>https://arxiv.org/pdf/2410.21647</link><description>Background: 
近年来，已经出现了诸如 CoderEval、Devel、RepoEval、RepoBench 和 LongCodeArena 等代码生成基准测试，用于评估大型语言模型（LLMs）的能力，超越了诸如 HumanEval 和 MBPP 等独立基准测试。然而，这些基准测试主要包含短期完成、合成实例或局限于小规模仓库的问题，无法代表真正的编码任务。因此，一个自然的问题是LLMs在现实世界的编码任务中是否会有与基准测试中相似的表现。然而，由于这些基准测试的局限性，这个问题无法得到回答。

Innovation: 
本文提出了 REPOCOD 作为 Python 代码生成基准测试，包含了来自 11 个流行库的真实复杂任务和详细的语境依赖性。REPOCOD 包含了超过 980 个function级生成任务，其中 50.8% 的任务需要仓库级别的上下文。每个示例都包含 314 个开发者编写的测试案例，以便提供更精确的评估。研究发现，没有一个 LLM 在 REPOCOD 上的通过率为 30% 以上，表明需要构建更强的 LLMs 以辅助开发人员进行真实的软件开发。此外，研究表明检索增强生成在结果上优于仅使用目标函数依赖性作为语境的方法。

Conclusion: 
REPOCOD 证明了当前的 LLMs 在处理大规模真实项目中的复杂任务时仍然存在局限性，需要进一步改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.21647</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>386. cs.CL-FluoroSAM: 一种语言可命令的基础模型，用于灵活的X射线图像分割</title><link>https://arxiv.org/pdf/2403.08059</link><description>Background: 
现有的任务特定模型在狭窄的范围内已经能够解决特定问题，但扩展到更广泛的应用需要更多的数据、注释和训练时间。之前的努力集中在利用大数据集进行自动图像分析的基础模型，但X射线成像模态因其成像表现和应用场景的高度变异性，以及不同种类和数量数据的可用性不一，缺乏这样的广泛适用的基础模型。因此，需要一种可以处理任意医学X射线图像的新一代基础模型，能够根据自然语言提示进行结构和工具的分割，增强人类在诊断和介入精准医疗流程中的灵活度。

Innovation: 
FluoroSAM是一个全新的基础模型，通过从零开始训练，使用了大量合成不同人体解剖结构、成像几何形状和视角的X射线图像，以及128种器官类型和464种工具的伪ground truth掩模及其相关文本描述。通过训练过程中引入文本嵌入的向量量化（VQ）技术，它能够基于自然语言指令进行结构和工具的分割。此外，FluoroSAM展示了在实际X射线图像上和多个应用上的人机交互增强能力，突显了其在X射线图像获取和分析中的关键作用。

Conclusion: 
FluoroSAM为广泛的医学X射线图像提供了灵活的分割能力，可以在不同场景下更好地支持医生和与机器的交互，促进了诊断和介入精准医疗的进步。这项创新的模型表现出色，为医学影像分析开辟了新的途径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.08059</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>387. cs.CL-LLM生成数据中起关键作用的因素及其对模型微调的影响</title><link>https://arxiv.org/pdf/2506.19262</link><description>Background: 
大规模语言模型（LLMs）的生成能力显著，使用LLM生成的数据来训练下游模型已成为缓解特定领域数据稀缺和减少耗时注解的一种有前景的方法。然而，近期研究指出，不断迭代使用自动生成数据进行训练会导致模型退化，即模型性能随时间下降。尽管已对LLM生成数据的影响进行了广泛研究，但这些研究往往忽略了数据多样性的重要性，这是数据质量的关键因素。本文旨在理解LLM生成数据的多样性对下游模型性能的影响，具体探索不同多样性水平的LLM生成数据如何影响下游模型性能，并研究混合不同比例LLM生成数据训练模型的表现，称之为合成数据。实验结果显示，在最小分布偏移的情况下，适度多样化的LLM生成数据可以提高在缺乏标注数据场景下的模型性能，而高度多样化的生成数据则产生负面影响。

Innovation: 
本文研究了LLM生成数据的多样性对下游模型性能的影响，并探索了不同多样性水平的LLM生成数据及其混合用于训练的模型表现，为未来研究LLM作为数据生成器提供了有益指导，特别是在应对数据稀缺和标注工作量大的问题上有重要意义。

Conclusion: 
适度多样化的LLM生成数据可以提升在数据不足场景下的模型性能，而高度多样化的生成数据则可能对模型产生负面影响。实验结果为我们未来研究LLM生成数据的多样性和其对模型微调的影响提供了有价值的启示，有助于优化使用LLM生成数据训练下游模型的策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19262</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>388. cs.CL-LLM位置泛化的背后计算机制</title><link>https://arxiv.org/pdf/2503.13305</link><description>Background: 
大多数书面自然语言由单词和句子序列组成。类似人类，大型语言模型（LLMs）在处理文本位置方面表现出灵活性，即位置泛化现象。它们能理解带有位置扰动的文本，并且能够推广到比训练过程中遇到的更长的文本。这些现象表明LLMs在位置处理上具有包容性，但它们如何进行位置相关性的计算处理仍然是未解之谜。本文将语言现象与LLMs的计算机制联系起来，展示了如何通过某些计算机制来支持对位置扰动的包容性。尽管自注意力机制的设计复杂，本文揭示LLMs会学习一种与直觉相悖的注意力值解耦方式，其值与位置相关性和语义重要性的近似算术和表现出0.959的线性相关性。此外，识别出一种普遍存在的中间特征模式，并提供了理论证明，表明这种模式不同于随机初始化参数的变化，是一种学习到的行为，而非模型架构的自然结果。基于这些发现，本文提供了关于LLMs的位置灵活性的计算解释和标准。这项工作在将位置泛化与现代LLMs内部机制联系起来方面迈出了开创性的一步

Innovation: 
本文揭示了大型语言模型在处理位置泛化时的计算机制，暴露了它们学习到一种与直觉相悖的注意力值解耦方式，强调了与位置相关性和语义重要性的关系，并且识别了一种不同的中间特征模式，证明了这种模式是一种学习到的行为，而不是模型架构的自然结果。这一发现为理解大型语言模型的位置灵活性提供了新的计算解释和标准，为深度学习领域的研究带来了新的进展

Conclusion: 
本文基于发现提供了一种对LLMs的位置灵活性进行计算解释的新方法，并提出了以这些发现为基础的指导原则。这项工作在将位置泛化与现代LLMs内部机制联系起来方面迈出了开创性的一步，对未来的研究具有重要意义</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.13305</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>389. cs.CL-对话用户-人工智能干预：一种改进大型语言模型响应生成的提示重写研究</title><link>https://arxiv.org/pdf/2503.16789</link><description>Background: 
人类与大规模语言模型（LLM）的对话正在越来越多地渗透到人们的职业和个人生活中，但许多用户仍然难以从LLM聊天机器人中获得有用的回应。原因之一是用户在构建有效提示方面缺乏技巧，无法准确表达信息需求。与此同时，现有的现实世界对话数据集以及LLM的文本理解能力为研究这个问题及其潜在解决方案提供了独特的机会。因此，本文旨在进行首例以大规模语言模型为中心的人机对话研究，重点关注用户查询不能准确表达信息需求的方面，并探索利用大规模语言模型重写不理想的用户提示的潜力。

Innovation: 
本文进行了首次大规模语言模型中心的人机对话研究，旨在通过提示重写改善大型语言模型的响应生成。研究发现，重新措辞无效的提示可以更好地从对话系统中获得回应，同时保留用户的原始意图。此外，研究还发现，当解释提示时，大规模语言模型往往需要并且确实会做出合乎逻辑的假设。此外，研究发现，重写提示的效果在较长对话中表现更好，因为在较长对话中可以更准确地进行上下文推断，从而更好地理解用户的需求。这种方法在不同对话领域、用户意图和不同规模和家族成员的大规模语言模型中具有普遍适用性，表明提示重写作为改善人机交互的解决方案具有一定的前景。

Conclusion: 
重新措辞无效的提示可以改善大规模语言模型的回应质量，同时保留用户意图。这种方法在不同对话领域、用户意图和不同规模和家族成员的大规模语言模型中普遍适用，显示出提示重写作为人机交互解决方案的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.16789</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>390. cs.CL-超越令牌的LLM公平性量化：一种语义与统计视角</title><link>https://arxiv.org/pdf/2506.19028</link><description>Background: 
大型语言模型（LLMs）经常生成带有固有偏见的响应，这在实际应用中降低了它们的可靠性。现有的评估方法往往忽视了长篇回复中的偏差以及LLMs输出的内在变异性。这项研究旨在解决这些问题。

Innovation: 
本文提出了一种新颖的统计框架FiSCo（Fine-grained Semantic Computation），该框架通过检测长篇回复中不同性别、种族和年龄组之间的微妙语义差异，来评估LLM在组级的公平性。不同于以往侧重于情感或令牌层面的对比，FiSCo通过实证的断言层面分析以及推理检查来评估意义的一致性。分解模型输出为语义上不同的断言，并应用统计假设检验来比较组内和组间相似性，从而准确检测微妙偏见。

Conclusion: 
实验表明，FiSCo比其他评估指标更可靠地识别出微妙的偏见，并减少了随机性对LLM的影响。我们还通过合成和由人类标注的数据集验证了FiSCo的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19028</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>391. cs.CL-CogniBench: 法律启发的框架和数据集，用于评估大型语言模型的认知忠实度</title><link>https://arxiv.org/pdf/2505.20767</link><description>Background: 
现有基准评估主要关注由大型语言模型（LLM）产生的‘事实陈述’，这些陈述通过重新表述原始材料而缺乏相应的评估标准。而忽略了涉及从给定上下文进行推断的‘认知陈述’。因此，评估和检测认知陈述的幻觉变得尤为具有挑战性。鉴于此背景，研究者参考法律领域中证据评估的方式，设计了一个严谨的框架来评估认知陈述的不同忠实度层次，并构建了CogniBench数据集，揭示了重要的统计数据。为了应对不断更新的LLM，该团队进一步开发了一种易于扩展到不同模型的自动注释管道，从而构建了大规模的CogniBench-L数据集，该数据集有助于训练准确的检测器，用于应对事实和认知幻觉

Innovation: 
该研究创新性地借鉴了法律领域中的证据评估方法，创建了一个评估认知陈述层次忠实度的框架，并构建了CogniBench数据集，包含了详细的统计信息。另外，团队开发了一种可扩展的自动注释管道，创建了大规模的CogniBench-L数据集，为训练检测器提供了关键资源

Conclusion: 
该研究提出了一个评估和检测大型语言模型认知幻觉的大规模数据集CogniBench和CogniBench-L。研究结果展示了对认知陈述的评估框架，并能够扩展到不同类型的语言模型，有助于提高大型语言模型的性能检测</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.20767</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>392. cs.CL-SMAR：MoE架构下保留语言能力的软模态感知路由策略</title><link>https://arxiv.org/pdf/2506.06406</link><description>Background: 
混合专家（MoE）架构已成为大规模语言模型扩展的关键方法，越来越多的研究兴趣在于将其扩展到多模态任务。现有的构建多模态MoE模型的方法要么导致高训练成本，要么导致适应预训练模型时语言能力下降。

Innovation: 
提出了一种新颖的正则化技术——软模态感知路由（SMAR），通过使用Kullback Leibler分散来控制不同模态之间的路由概率分布，鼓励专家特化，而无需修改模型架构或过度依赖文本数据。实验表明，SMAR在仅保留86.6%的纯文本的情况下，能够保持语言能力，同时在多模态任务上表现出更佳性能，优于基线方法。

Conclusion: 
该方法提供了在多模态MoE模型中平衡模态差异化和语言能力的有效且实用的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.06406</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>393. cs.CL-奖励图推理过程使LLMs成为更泛化的推理者</title><link>https://arxiv.org/pdf/2503.00845</link><description>Background: 
尽管大型语言模型（LLMs）取得了显著进展，但在LLMs中开发高级推理能力仍然是主要挑战。过程奖励模型（PRMs）在数学推理中通过逐步反馈表现出极大的潜力，但它们在更广泛的推理领域中的应用仍充满挑战，主要由于手动创建逐级监督的成本高昂。因此，研究者们开始探索PRMs在图推理问题中的应用，因为图推理需要复杂多步的推理，并且可以使用已建立的图算法来自动生成逐级数据。通过Automated Task-oriented Trajectories和蒙特卡洛树搜索（MCTS），研究者构建了一个精细标注的图推理问题数据集GraphSILO，利用该数据集，研究者训练了GraphPRM，一种专门为图推理问题设计的第一个过程奖励模型，并在推理时间和强化学习方面验证了其效果。实验结果显示，GraphPRM显著提高了图推理任务的LLM性能，并具有跨领域的适用性。

Innovation: 
研究引入了GraphSILO，这是目前最大的图推理问题数据集，包含细粒度的过程奖励标签。研究者首次设计了用于图推理问题的PRM，即GraphPRM。并在两个关键场景下对其进行了评估：推理时的扩展性和直接偏好优化（DPO）的强化学习。此外，研究还明确展示了基于图推理奖励能增强LLMs在数学问题解决等多个领域的能力，这为进一步推进各种环境下的LLM发展铺平了道路。

Conclusion: 
研究表明，PRMs可以在多种推理场景中提升LLM的性能，特别是在图推理问题上，GraphPRM改进了Qwen2.5-7B在GSM8K和Math500等数据集中的表现。这表明PRMs具有跨领域的通用性，为LLM的多功能性和效果提升提供了新的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.00845</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>394. cs.CL-提升语言模型预训练数据质量和数量的方法：回收网络文本</title><link>https://arxiv.org/pdf/2506.04689</link><description>Background: 
大规模语言模型随模型规模和数据规模的增加而性能提升。目前，预训练依赖于大量的网页抓取数据，几乎使用了所有公开的互联网数据源。然而，可获得的高质量文本数据受到限制：通常过滤管道会移除高达99%的初始网页抓取数据以达到最佳效果。现有的预训练数据池没有与计算供应以相同的速度增长。为了应对预训练数据扩展中的“数据墙”，本文探索了如何回收和重新利用现有过滤流程中丢弃的数据，提出了REWIRE方法，通过重新编写低质量文档使其成为训练的有效工具。

Innovation: 
提出REWIRE（REcycling the Web with Guided Rewrite）方法，通过指导性重写来提升低质量文档的质量，使它们能够在训练中发挥作用。该方法能够在最终预训练数据集中增加合成数据的表示。实验结果显示，在DCLM基准模型1B、3B和7B规模下，将高质量原始文本与重整文本混合用于训练，相较于仅使用过滤后的网络数据训练，在22个多样化的任务上分别提高了1.0、1.3和2.5个百分点。此外，混合训练在效果上超过了使用两倍网络数据的训练方法。此外，研究表明，大约有82%的混合文本来自会导文档，这表明回收网络文本具有简单有效的潜力，以提升预训练数据的质量和数量，超过了包括维基百科风格重述、问答合成和知识提取在内的相关方法。

Conclusion: 
回收网络文本作为一种简单有效的方法，具有提升预训练数据质量和数量的潜力，有助于克服预训练数据扩展中的“数据墙”。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.04689</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>395. cs.CL-从源文献到引用的嘈杂路径：衡量学者如何与过去的研究互动</title><link>https://arxiv.org/pdf/2502.20581</link><description>Background: 
学术引用广泛用于评估研究和追踪知识流动。通常，这类评估依赖于原始引文计数，而忽略了引文类型的变异性。具体来说，引文的质量可能因被引论文的内容被总结、重构或歪曲而不同，从而影响信息传递的准确性。本文研究了一种大型的计算管道，用于量化大规模的引证忠实度。该管道利用论文的全文，识别引文中的引证以及引证论文中的相应陈述，并运用监督模型在句子级别测量引文的忠实度。研究发现，引用更加近期且主题相关性强、易于获取、以及第一作者H指数较低、作者团队规模适中的论文，其引文的忠实度更高。同时，通过准实验设计确定了“电话效应”——当后续文章的引文与原始声明之间的忠实度较低时，未来文章的引文忠实度也会进一步降低。这些发现揭示了引文忠实度的系统性差异，强调了仅依赖引用数量进行分析的局限性，并指出了对证据的扭曲可能性。

Innovation: 
本文引入了一种全新的计算管道，能够大规模量化引文的忠实度。该方法通过全文挖掘和监督模型的应用，首次在句子级别评估了引文的忠实度。研究发现在多种情况下，引文忠实度较高，以及首次提出了一种‘电话效应’的影响机制。

Conclusion: 
本文揭示了引文忠实度的系统性差异，指出了单纯依赖引用数量进行研究评估的不足和可能造成的证据扭曲。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.20581</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>396. cs.CL-LLaVA-CMoE：针对大规模视觉语言模型的持续专家混合</title><link>https://arxiv.org/pdf/2503.21227</link><description>Background: 
大型语言模型（LLMs）最近通过混合专家（MoE）架构增强了其在连续多模态学习中的可扩展性和适应性。然而，高效地将这些模型扩展以适应序列任务仍然具有挑战性。随着新任务的出现，模型简单扩展会导致参数快速增长，而修改共享路由组件则可能导致灾难性遗忘，即忘记以前学习的知识。

Innovation: 
该论文提出了一种持续学习框架——LLaVA-CMoE，不需要以前任务的重演数据，并确保参数效率和知识的稳健保留。提出了一种探测引导的知识扩展机制，使用探测专家动态确定何时及何处添加新专家，实现针对任务复杂度的自适应和最小参数扩展。此外，还提出了一种概率任务定位器，为每个任务分配一个专用且轻量级的路由器。通过利用基于VAE的重构策略，根据输入分布匹配来自动确定合适的路由器，解决了推理过程中任务标签未知的实际问题，从而减轻路由冲突和灾难性遗忘，实现无显式任务标签的稳健持续学习。

Conclusion: 
在CoIN基准测试上进行的广泛实验，涵盖八个不同的VQA任务，展示了LLaVA-CMoE在紧凑模型尺寸下达到较强的持续学习性能，显著减少了遗忘和参数开销，优于先前方法。这些结果验证了我们方法在大规模语言模型中的参数效率持续学习的有效性和可扩展性。代码将在不久的将来开源。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.21227</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>397. cs.CL-LADM: 长语境训练数据选择方法，基于注意力依赖度量</title><link>https://arxiv.org/pdf/2503.02502</link><description>Background: 
长语境建模近年来在大型语言模型（LLMs）领域受到了越来越多的关注。持续训练使用长语境数据已成为给LLMs提供处理长输入能力的默认方法。然而，如何衡量长语境训练数据的质量仍然是一个开放的挑战。

Innovation: 
本文提出了一种基于注意力依赖度量的长语境数据选择框架（LADM），可以从大规模、多领域的预训练语料库中高效地识别高质量的长语境数据。LADM 利用了注意机制的检索能力来捕捉上下文依赖性，确保对长语境数据的质量进行全面测量。实验结果显示，使用仅 1B 令牌进行持续训练，我们的 LADM 框架在多个长语境任务上的性能得到了显著提升。

Conclusion: 
我们的 LADM 框架在仅使用 1B 令牌进行持续训练的情况下，显著提高了多种长语境任务上大型语言模型的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.02502</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>398. cs.CL-LR^2Bench: 通过约束满足问题评估大规模语言模型的长链反思推理能力</title><link>https://arxiv.org/pdf/2502.17848</link><description>Background: 
近期大规模推理模型（LRMs）的进步显著增强了大规模语言模型（LLMs）的推理能力，使它们能够通过反思能力解决越来越复杂的任务，如假设、回溯和自我修正。然而，有效评估这些反思能力仍具有挑战性，因为缺少合适的基准。面对这一问题，我们引入了LR^2Bench，一种旨在评估LLMs长链反思推理能力的新基准。LR^2Bench 包含850个样例，覆盖六个关键的约束满足问题（CSPs），其中反思推理对于得出满足所有给定约束条件的解决方案至关重要。每个任务类型侧重于不同的约束模式，如基于知识的、逻辑的和空间的约束，从而提供了对多种问题解决场景的全面评估。我们的评估显示，即使是最先进的LRMs，如DeepSeek-R1和OpenAI o1-preview，在LR^2Bench上的表现也非常有限，平均准确匹配得分为20.0%和23.6%。这些结果强调了当前LLMs在反思推理能力方面有很大的改进空间。

Innovation: 
引入了LR^2Bench，一种专门用于评估LLMs长链反思推理能力的新基准。该基准包含850个样例，并通过多个约束满足问题场景来综合评估LLMs的复杂问题解决能力。这是第一个直接针对这类复杂推理任务的基准，有助于研究者准确评估和改进LLMs的反思推理能力。

Conclusion: 
尽管当前最先进的一类LRMs在LR^2Bench上的表现非常有限，平均准确匹配得分为20.0%-23.6%。这些结果显示出当前LLMs在反思推理能力方面仍存在显著不足，强调了在这一领域进一步改进的需求和可能的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.17848</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>399. cs.CL-平衡不确定性导向微调的忠实性与信息量</title><link>https://arxiv.org/pdf/2502.11962</link><description>Background: 
大语言模型（LLMs）可以通过指令微调（IFT）增加其信息量，但可能会牺牲其真实性。这是因为IFT使模型倾向于生成包含预训练期间覆盖不足的长尾知识的回答，导致模型在泛化到未见过的任务时变得更加信息丰富但准确度降低。

Innovation: 
该研究通过引入两个新的不确定性导向微调（$UNIT_{cut}$和$UNIT_{ref}$）来解决这一问题。$UNIT_{cut}$通过识别并从IFT数据集中移除不熟悉的知识来减少其对模型忠实性的影响，而$UNIT_{ref}$则通过训练LLMs识别其不确定性并在回答的末尾明确表示出来，来减少幻觉现象。实验证明，$UNIT_{cut}$显著提高了模型的真实性，而$UNIT_{ref}$则保持了高度的信息量并减少了幻觉。

Conclusion: 
通过这两种新的不确定性导向微调方法，研究证明了在增加模型信息量的同时，能够保持模型的真实性，减少幻觉现象。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.11962</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>400. cs.CL-在游戏《Codenames》中的随机概念形成作为评估大型语言模型的方法</title><link>https://arxiv.org/pdf/2502.11707</link><description>Background: 
该研究利用经典桌游Codenames作为基准工具，来评估大型语言模型（LLMs）在特定语言和认知技能方面的能力。在Codenames游戏中，其中一方提供一个能够覆盖多个目标词的提示词，而另一方则尝试猜测这些目标词。研究者通过控制词语的选择（抽象词 vs. 具体词、歧义词 vs. 单义词）或对手的策略（编程使其揭示词语更快或更慢），设计了多种实验来比较不同商业和开源重量级模型的表现。

Innovation: 
该研究通过利用Codenames游戏作为基准工具，评估了LLMs在特定语言和认知技能方面的能力，这提供了评估LLMs性能的新视角。通过设计各种实验控制词语选择和对手策略，研究揭示了不同模型的策略、挑战案例及它们的局限性。这种评估方式新颖且具体，有助于深入了解LLMs的表现和局限。

Conclusion: 
该研究发现，通过Codenames游戏评估LLM的表现能够提供关于其策略、挑战场景以及性能局限的详细信息。不同的实验设计揭示了模型在不同情境下的表现，有助于指导未来的模型开发和改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.11707</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>401. cs.CL-超越语言模型的自然数据集中的情境学习能力解锁</title><link>https://arxiv.org/pdf/2501.06256</link><description>Background: 
大型语言模型（LLMs）展示了内部上下文学习（ICL）能力，使模型能够在不更新权重的情况下仅通过上下文提供的示例来执行新任务。尽管ICL在自然语言任务和领域中提供了快速适应，但这种能力在超出文本的模态中出现时却并不直观。本文系统地发现了支持LLMs中ICL出现的特性，并通过促进LLMs学习所需机制来推广ICL。研究表明，训练数据序列中的具体标记重复是ICL的关键因素，这些重复还进一步提高了ICL性能的稳定性和减少了其瞬态性。此外，训练任务的难度也被认为是ICL出现的重要因素。最后，通过应用我们对ICL机制的新见解，作者发现ICL也可以应用于多种视觉数据集和更具挑战性的EEG分类任务中的少数样本学习中。

Innovation: 
研究揭示了训练数据序列中具体标记重复是支持ICL出现的关键因素，并促进了LLMs学习所需机制来推广ICL，通过这些新的见解解锁了ICL能力，使其能够应用于多种视觉数据集和更复杂的EEG分类任务中的少数样本学习。此外，研究还强调了训练任务的难度对于ICL出现的重要性，这是与以往研究中较少关注的一个方面。

Conclusion: 
通过揭示训练中具体标记的重复作为ICL的关键因素，以及具体标记重复如何提高ICL的稳定性并减少其瞬态性，该研究提出了新的理论见解。通过这些洞察，ICL的能力被解锁，使其能够适用于各种视觉数据集以及更具挑战性的EEG分类任务中的少数样本学习。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.06256</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>402. cs.CL-预训练语言模型和人类在语义关系知识上的全面评估</title><link>https://arxiv.org/pdf/2412.01131</link><description>Background: 
近年来，许多研究关注预训练语言模型（PLMs）学习语言不同方面的知识以及学习的方式。其中一领域是研究PLMs对语义关系的理解。然而，多数研究仅关注了层级关系（超称/下位关系）。更重要的是，这些研究大多没有将人类的语义关系识别结果与PLMs进行直接比较，这导致现有的模型在这一问题上的知识维度不完整。因此，该研究提出了一项新的框架，全面评估PLMs对包括超称/下位关系、部分整体关系、部分组分关系、反义关系和同义关系在内的五种不同语义关系的知识，并且通过六种新颖的评估指标对语义关系知识的不同方面进行度量。该研究还涉及16个PLMs中的14个模型（其中8个是掩码模型，8个是因果模型），这是目前为止全面类比人类和模型执行同一任务的一种尝试。尽管两种模型都用于处理上下文，但此次研究还是得出了显著差异：平均来看，掩码模型比因果模型表现更好，但两者都可能会将非反义关系误认为反义关系。

Innovation: 
研究引入了一个全面的评估框架，涵盖五种不同于层级关系的语义关系。通过六个新的评估指标，研究者有效比较了人类和模型在相对较新的未处理语义关系维度上的性能。这是首次全面类比掩码模型和因果模型在多项语义关系上的表现，并且得出了明确的认知差异。

Conclusion: 
该研究揭示了人类和模型在几乎所有的语义关系上的显著知识差距。总体而言，掩码模型在所有关系上都比因果模型表现更好。尽管如此，无论是掩码模型还是因果模型都可能会混淆非反义关系与反义关系，尤其是在反义关系上所有模型都表现得较为稳定。未来的研究可以针对这一领域进行更深入的探究，以进一步理解PLMs在语义关系知识上的学习模式。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.01131</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>403. cs.CL-VAQUUM: 视觉数据中模糊数量词是否具根基性？</title><link>https://arxiv.org/pdf/2502.11874</link><description>Background: 
模糊的数量词（如“一些”和“许多”）在不同上下文因素的影响下存在变化，尤其是与给定上下文中的物体数量相关。本文旨在评估视景语言模型（VLMs）在生成或判断模糊数量词是否适当的方面，是否与人类相符。为此，作者创建了VAQUUM数据集，包含1089张图像中的20,300个人对量化陈述的评价。

Innovation: 
作者引入了一个新的数据集VAQUUM，并通过三种不同的评估方法比较了人类判断和VLM预测之间的差异。发现两者在模糊数量词使用时都会受到物体数量的影响，但在不同评估设置下模型之间存在显著差异。这表明评估和产生模糊数量词依赖于不同类型的过程。

Conclusion: 
VLMs在处理模糊数量词时受到了物体数量的影响，但模型间存在显著不一致，表明评估和产生模糊数量词依赖于不同过程。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.11874</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>404. cs.CL-探索利用大型语言模型内部状态以提升知识边界感知能力</title><link>https://arxiv.org/pdf/2502.11677</link><description>Background: 
大型语言模型（LLMs）在多种任务中表现出色，但常常在评估知识边界时出错，导致自信但错误的回答。本文研究了利用LLMs的内部状态来增强它们从效率和风险角度感知知识边界的机制。我们探讨了在响应生成前，LLMs是否能够利用内部状态来估计信心，从而节省计算资源。我们在Natural Questions、HotpotQA和MMLU等数据集上的实验表明，LLMs在响应生成前具有显著的知识边界感知能力，在生成后会进一步细化这种感知，并且感知鸿沟在不同条件下保持稳定。

Innovation: 
我们引入了一种Confidence Consistency-based Calibration（$C^3$）方法，通过问题重述来评估信心一致性，显著提高了LLMs识别知识空缺的能力，增强了未知内容识别率，分别在NQ和HotpotQA上提高了5.6%和4.9%。我们发现，响应生成前的信心估计可以优化效率，而$C^3$可以有效控制输出风险，提高LLMs在实际应用中的可靠性。

Conclusion: 
我们的研究结果表明，利用LLMs的内部状态进行预生成信心估计可以优化效率，而$C^3$方法能有效地控制输出风险，提升了LLMs的实际应用可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.11677</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>405. cs.CL-注意力熵是一个关键因素：全注意机制预训练语言模型的并行上下文编码分析</title><link>https://arxiv.org/pdf/2412.16545</link><description>Background: 
大型语言模型在广泛的语言任务中表现出卓越的性能，这得益于它们在上下文建模方面的出色能力。标准的解码器自注意力Transformer最常用的方法是全自注意力，虽然这种方法强大，但对长序列可能效率低下，并且可能会忽略输入中的固有结构。为解决这些问题，人们提出了并行上下文编码的方法，即将上下文拆分成子片段并进行并行编码。但由于训练过程中从未遇到平行模式，直接应用并行编码会导致性能下降。然而，根本原因和可能的缓解措施尚不清楚。这篇论文旨在深入分析这一问题，发现不寻常高的注意熵可能是关键因素，并提出了一些简单的方法来减少注意力熵，从而改善性能。

Innovation: 
本文提供了对并行上下文编码的详细分析，发现不寻常高的注意力熵是一个关键因素。进一步提出利用注意力阱和选择性机制减少注意力熵的两种简单方法，并证明这些方法能有效降低不规则注意力熵，缩小性能差距，为增强上下文建模机制提供了新的思路。

Conclusion: 
研究结果表明了减少注意力熵的有效方法，可以提高模型在任务中的表现，并指出了如何进一步改进上下文建模机制的可能性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.16545</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>406. cs.CL-使用大型语言模型进行图推理的图线性化方法</title><link>https://arxiv.org/pdf/2410.19494</link><description>Background: 
大规模语言模型已经进化到能够处理包括文本、图像和音频在内的多种模态。这促使我们探索如何有效利用这些模型处理图推理任务。关键问题是如何将图转换为标记的线性序列，这一过程称作“图线性化”，以便让语言模型能够自然地处理图。我们认为，图应该被有意义且反映自然语言中某些属性的方式线性化，比如局部依赖和全局对齐，以使现当代训练于数万亿文本标记的语言模型更容易理解图。

Innovation: 
开发了基于图中心性和退化性的几种图线性化方法，并进一步通过节点重新标记技术进行了优化。实验结果表明，与随机线性化基线相比，我们的方法更有效。本工作引入了适合语言模型的新型图表示方法，为将图机器学习与统一变压器模型的多模态处理趋势相结合铺平了道路。

Conclusion: 
我们的工作展示了使用特定方法进行图线性化的有效性，并为今后研究如何更好地结合图数据和语言模型提供了新的思路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.19494</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>407. cs.CL-FactCheckmate：LMs中预检测和抑制幻觉</title><link>https://arxiv.org/pdf/2410.02899</link><description>Background: 
语言模型（LM）会产生幻觉。本文探讨了是否可以在幻觉发生之前检测和抑制它们。该研究展示了机器内部表示可以提供用于此目的的丰富信号。研究通过引入FactCheckmate方法来实现这一目标，FactCheckmate可以在解码开始之前通过学习一种分类器来预测LM是否会产生幻觉。如果检测到幻觉，FactCheckmate将干预调整LM的隐藏状态，使得模型生成更准确的输出。这项研究揭示了LM内部机制可以通过它们的隐藏状态来揭示。

Innovation: 
FactCheckmate通过学习一种分类器来预测LM是否会产生幻觉，并在解码开始之前调整LM的隐藏状态来抑制幻觉。这种方法比许多事后方法更有效，并且其检测和干预模型都比较轻量，几乎没有推理负载。

Conclusion: 
本文评估了FactCheckmate在不同规模和模型家族（包括Llama、Mistral、Qwen和Gemma）以及不同领域问题回答数据集上的性能。结果表明，FactCheckmate具有超过70%的预检测准确性，并且接受干预的LM生成的输出比未接受干预的更准确，高出34.4%。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.02899</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>408. cs.CL-WordNet与人类直觉之间的语义关系知识偏差</title><link>https://arxiv.org/pdf/2412.02138</link><description>Background: 
WordNet提供了一个由专家精心构建的语义关系数据库，而另一种信息来源则是语言使用者的直觉。本研究旨在系统性地研究这两种信息源之间的偏差程度，并且通过使用模板让人类参与者提供反馈，揭示了WordNet中的语义关系知识与人类直觉之间的普遍偏差。进一步的研究发现，同义关系和分类关系（超类和子类）之间的不一致，并且WordNet中的路径长度无法可靠地反映人们对超类和子类关系的理解。

Innovation: 
这是首次系统性地研究WordNet和人类直觉之间的语义关系知识偏差。通过使用特制模板向人类参与者提问，揭示了两种信息源在语义关系理解上的不一致性，找到了同义关系和分类关系存在系统性偏差的现象，并指出WordNet的路径长度不能作为衡量人对超类和子类关系理解的可靠指标。

Conclusion: 
WordNet和人类直觉在语义关系理解上存在普遍的偏差，同义关系和分类关系的不一致是一种系统性模式。WordNet的路径长度作为衡量超类和子类关系的指标不够可靠。因此，可以利用这种偏差更好地利用WordNet，并促进其改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.02138</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>409. cs.CL-分离言辞与思想：激活补丁揭示变换器中的语言无关概念表示</title><link>https://arxiv.org/pdf/2411.08745</link><description>Background: 
多语言语言模型中的一个关键问题是大型语言模型是否发展出一种通用的概念表示，这种表示不依赖于特定语言。论文通过分析变压器基大型语言模型（LLMs）在单词翻译任务中的潜在表示（latents），来解答这一问题。研究者从中源翻译提示中战略性地提取潜在表示，并将其插入目标翻译提示的前向传递过程中，发现输出语言在比要翻译的概念更早的层中被编码。

Innovation: 
论文通过仅使用激活补丁，展示了可以在不改变语言的情况下改变概念，反之亦然，并且证明了使用不同语言的概念平均表示进行补贴不会影响模型的翻译能力，反而会提升。此外，还展示了模型可以生成关于这些平均表示的自然语言描述，从而揭示了语言无关的概念表示的存在性。

Conclusion: 
研究结果提供了证据，表明在研究的模型中存在语言无关的概念表示。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.08745</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>410. cs.CL-世界理解或预测未来？世界模型的全面综述</title><link>https://arxiv.org/pdf/2411.14499</link><description>Background: 
由于GPT-4等多模态大型语言模型和Sora等视频生成模型的进步，世界模型的理念已经引起了广泛关注。这些模型是追求通用人工智能的关键组成部分。世界模型通常被视为理解和预测世界状态及其未来动态的工具。本文综述了世界模型的相关文献，强调了其构建内部表示以理解世界机制和预测未来状态以模拟和指导决策的两种主要功能。

Innovation: 
本文对世界模型进行了系统的分类，并重点探讨了其在自主驾驶、机器人技术和社会模拟等关键领域的应用，分析了每个领域如何利用这些特性。此外，简要概述了主要的挑战，并指出了未来研究的方向。

Conclusion: 
本文总结了代表性论文及其代码存储库，详细介绍了世界模型在不同领域的进展，并指出了未来的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.14499</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>411. cs.CL-Decrypto 竞猜基准：多智能体推理与心智理论</title><link>https://arxiv.org/pdf/2506.20664</link><description>Background: 
随着大型语言模型（LLMs）获得自主能力，它们需要在复杂的多智能体场景中进行导航，与人类用户和其他代理进行合作和竞争的互动。这需要新的推理能力，尤其是心智理论（ToM）能力，即推理其他代理“心理”状态的能力。然而，LLMs中的ToM和其他多智能体能力尚未被充分理解，因为现有的基准测试存在范围狭窄、数据泄露、饱和和缺乏互动的问题。因此，我们提出Decrypto，一个基于游戏的ToM和多智能体推理基准，它吸取了认知科学、计算语用学和多智能体强化学习的灵感。该基准设计力求在所有其他维度上尽可能简化，以消除其他基准中常见的混淆因素。据我们所知，这也是首个用于设计互动心智理论实验的平台。

Innovation: 
Decrypto 提出了一个新的游戏化基准，用于多智能体推理和心智理论（ToM），该基准吸取了认知科学、计算语用学和多智能体强化学习的灵感。该基准旨在通过消除潜在的混淆因素，简化所有其他维度的设计。同时，这也是首次专门设计用于互动心智理论实验的平台，通过全面的经验评估、鲁棒性研究和人类-人工智能混合对战实验，该基准显示了最先进的推理模型在某些关键的心智理论任务上表现不如旧版本，从而填补了当前推理和心智理论评估的关键空白。该基准为更好的人工智能代理奠定了基础。

Conclusion: 
实验结果表明，LLMs的游戏能力落后于人类和简单的词嵌入基线。通过在Decrypto基准内创建两个经典的认知科学实验的变体版本，评估了三个关键的心智理论能力。令人惊讶的是，最先进的推理模型在这些任务上的表现明显劣于其早期版本。这表明Decrypto填补了当前推理和心智理论评估的关键空白，为更好的人工智能代理铺平了道路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20664</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>412. cs.CL-评估代码生成LLM中的长距离依赖处理</title><link>https://arxiv.org/pdf/2407.21049</link><description>Background: 
随着语言模型能够支持更大的上下文规模，评估它们高效利用这些上下文的能力变得越来越重要。本研究通过在多达8k标记长度的上下文中使用一系列多步关键检索任务，分析了几种代码生成模型处理长范围依赖的能力，这些任务逐步增加了难度，能够更细致地评估模型能力，相比传统的如“针扎干草堆”测试具有不同层次的评估能力。研究发现，当一个函数引用在其提示后定义的另一个函数时，许多模型的性能会明显下降（最多降低2倍），并且使用滑动窗口注意力机制的模型在处理超出单个窗口范围的引用时也遇到困难。通过使用调用图信息进行简单的提示修改，研究进一步提高了多步检索性能，最多提高了3倍。这些分析揭示了长上下文性能需要更多考虑的问题，远超出单一文档内事实的检索之外。

Innovation: 
研究通过使用多步关键检索任务和调用图信息，提出了一个综合评估方法，能够更细致地评估代码生成模型处理长距离依赖的能力。通过简单的提示修改，解决部分模型处理长距离引用的问题，提升了多步骤检索性能。

Conclusion: 
长上下文性能不仅限于文档内部事实检索，还需更深层次的考虑模型如何有效处理长范围依赖。滑动窗口机制可能不足以处理超出单个窗口的引用，需要进一步优化。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.21049</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>413. cs.CL-MMSearch-R1: 增强LMMs的搜索动机</title><link>https://arxiv.org/pdf/2506.20670</link><description>Background: 
在现实场景中部署大规模多模态模型（LMMs）需要访问外部知识来源，因为现实世界的复杂性和动态性。现有方法如检索增强生成（RAG）和提示工程化搜索代理依赖于固定的流水线，这往往导致搜索行为低效或过度。为了应对这些挑战，本文提出了MMSearch-R1框架，这是一个端到端的强化学习框架，使LMMs能够根据基于结果的奖励进行灵活的多轮搜索。该框架结合了图像和文本搜索工具，并通过搜索-非搜索样本平衡的数据集进行训练，以指导何时和如何调用这些工具。

Innovation: 
MMSearch-R1是一个端到端的强化学习框架，可以实现LMMs的按需多轮搜索。该框架能够结合图像和文本搜索工具，并通过基于结果的奖励进行指导。提出了一个半自动化数据收集流程来构建多模态搜索和VQA数据集，包含搜索需求和非搜索需求的样本集合，这对于形成高效的按需搜索行为至关重要。模型在知识密集型和信息寻求的VQA任务中表现出色，不仅优于相同规模的基于RAG的基础模型，还在减少超过30%的搜索调用次数的情况下实现了性能匹敌更大的RAG模型的效果。

Conclusion: 
大量实验表明，我们的模型不仅在知识密集型和信息寻求的VQA任务中优于基于RAG的基本模型，而且在减少超过30%的搜索调用次数的情况下达到了更大RAG模型的性能。进一步的实证研究提供了关于促进多模态搜索研究的可操作性见解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20670</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>414. cs.CL-全局上下文机制在序列标注中的应用</title><link>https://arxiv.org/pdf/2305.19928</link><description>Background: 
在序列标注任务中，每个句子中的每个单词都需要被赋予一个标签，而全球句子信息的捕捉对于有效的序列标注至关重要。尽管双向长短期记忆网络（BiLSTM）模型被广泛使用，但它们在捕捉内部单词的全局上下文方面常常不够充分。此前，研究人员提出了一系列RNN变体来整合全局句子信息到单词表示中，尽管这些方法在一定程度上解决了这个问题，但它们仍然存在三个关键限制：（1）与传统的BiLSTM相比，它们在推理和训练过程中速度较慢；（2）它们不能有效补充transformer模型的全局信息；（3）重新实施和整合这些定制的RNNs到现有架构中成本高昂，时间成本过高。该研究旨在解决上述挑战。

Innovation: 
研究提出了一种简单但有效的全局上下文机制，该机制能够高效地为BiLSTM和transformer模型补充全局句子信息，同时不会显著影响推理和训练速度，并且易于整合到现有的架构中。研究发现，该机制在包括Conll2003、Wnut2017、微博命名实体识别任务（Weibo）、Laptop14、Restaurant14、Restaurant15和Restaurant16等七个流行的基准测试中，特别是在这些E2E-ABSA基准测试中，显著提升了F1分数。通过这种方法，研究在微博命名实体识别基准测试中取得了第三高的成绩，且在序列标注的CRF框架中表现出了具有竞争力的F1分数和更优的推理及训练速度。研究提供代码供参考。

Conclusion: 
研究提出了一种旨在解决传统BiLSTM模型在捕捉全球上下文能力不足问题的全局上下文机制，该机制能显著提升序列标注任务的性能，特别是在涉及多个真实世界任务的测试中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2305.19928</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>415. cs.CL-语言模型从不那么罕见的现象学习罕见现象：缺失的AANNs案例</title><link>https://arxiv.org/pdf/2403.19827</link><description>Background: 
语言模型能够学习稀有的句法现象，但这种学习是通过泛化还是记忆实现的，仍是一个开放的问题。本文通过对系统操纵的人规模型语料库进行逐步训练，评估了模型对一种稀有语法现象（即英语的Article+Adjective+Numeral+Noun构词法）的学习情况，考察了其在标准语料库和移除AANN句子的反事实语料库中的表现差异，并进一步探讨了学习过程中的泛化机制和输入的变异性对其学习的影响。

Innovation: 
通过构建反事实语料库并比较语言模型在标准语料库和移除AANN的语料库中的表现，表明语言模型可以通过泛化较少见的现象来学习罕见现象。此外，研究发现输入的多变性可以进一步增强学习效果。这一发现为研究语言模型通过泛化学习稀有语法现象提供了实证依据。

Conclusion: 
研究结果证明，语言模型可以通过从较少见的现象中泛化来学习罕见的语法现象，输入的多样性和变异性可以增强这种学习效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.19827</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>416. cs.CL-异步REINFORCE用于离策强化学习：平衡正负奖励</title><link>https://arxiv.org/pdf/2506.20520</link><description>Background: 
强化学习（RL）被越来越多地用于调整大型语言模型（LLMs）。离策方法相比在线方法提供了更简单的实施和更高的数据效率，但常常导致次优性能。本文通过分析一个简单的离策REINFORCE算法来研究介于离策RL和监督微调之间的算法范围，其中的优势定义为$A=r-V$，其中$r$是一个奖励，$V$是一个可调基线。降低$V$强调高奖励样本，而提升$V$更重地惩罚低奖励样本。我们首先提供关于此离策REINFORCE算法的理论分析，表明当基线$V$下界预期奖励时，该算法具有策略改进保证。我们的分析表明，虽然在线更新可以安全地利用正负信号，但离策更新则更倾向于关注正奖励而非负奖励。

Innovation: 
通过分析一个简单的离策REINFORCE算法，揭示了离策更新更多关注正奖励的理论依据，并在控制的随机多臂老虎机环境和对最先进LLMs的推理任务中进行了实验验证，证明了这种方法的有效性。

Conclusion: 
本文研究了离策RL与监督微调之间的算法范围，通过理论分析和实验验证，表明在离策REINFORCE算法中降低基线可以帮助更有效地利用奖励信号，从而提升模型性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20520</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>417. cs.CL-关于阅读时间预测中上下文的作用</title><link>https://arxiv.org/pdf/2409.08160</link><description>Background: 
本文探讨了读者在实时语言理解过程中如何整合上下文。研究基于“意外性理论”，该理论认为，语言单位（如单词）的处理努力与该单位在上下文中的信息量呈线性关系，并对上下文预测方法进行扩展，提出点互信息（PMI）是另一种能够提供相同预测力的上下文指标，并且PMI和意外性都与频率相关。这表明，PMI和意外性都不能单独提供上下文信息。

Innovation: 
提出了一种将意外性投影到与频率正交的补空间的新技术，从而产生了与频率无关的新上下文预测指标。实验结果表明，此种上下文表示方式在解释阅读时间变异性的比例显著较小。这暗示了以往研究可能高估了上下文在预测阅读时间中的作用。

Conclusion: 
通过对语言模型上下文预测方法的评估和新的上下文预测技术的研究，发现上下文对阅读时间的作用可能没有之前认为的那么重要。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.08160</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>418. cs.CL-PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models</title><link>https://arxiv.org/pdf/2506.20629</link><description>Background: 
LoRA是一种广泛应用的大模型微调方法，由于其小内存占用量，使得实践者能够以较小的成本将大模型适应到特定任务。不同修改旨在提高其效率，例如设置学习率、秩和初始化等。此外，适配器放置策略也是一项改进重点：使用LoRA时，实践者通常选择需要适配的模块类型，如Query和Key模块。然而，很少有研究关注适配器放置问题，结果也不尽相同，LoRA原始论文建议将适配器放置在注意力模块中，而其他研究则建议放在MLP模块中。研究者通过直观的理论分析，提出了一种轻量级方法PLoP，能够在给定预训练模型和微调任务的情况下自动识别适配器应当放置的模块类型，从而提高效率并实现更好的性能。通过监督微调和强化学习推理的全面实验表明，PLoP在大多数情况下超过了常用放置策略，最坏情况下也能与其竞争。

Innovation: 
提出了PLoP (Precise LoRA Placement)，一种轻量级方法，能够在给定预训练模型和微调任务的情况下自动识别适配器应当放置的模块类型，从而在监督微调和强化学习推理实验中表现出色，优于常用放置策略并在最坏情况下与其竞争。

Conclusion: 
PLoP在监督微调和强化学习推理实验中表现为持续超过传统的放置策略，并且在最坏情况下也能与其竞争，因此验证了其在适配器放置上提供的一种更优化的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20629</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>419. cs.CL-使用权重分布量看待反事实影响</title><link>https://arxiv.org/pdf/2506.20481</link><description>Background: 
机器学习模型被发现会记住训练数据中的样本，这引起了隐私和泛化方面的担忧。反事实自影响是研究记忆的一个常用指标，它量化了模型对样本的预测如何随着样本是否包含在训练数据集中而发生变化。然而，近期研究表明，记忆受自影响之外的因素影响，特别是（近）复本样本对记忆的影响很大。

Innovation: 
本研究将反事实影响视为一种分布性量度，考虑所有训练样本对单个样本记忆过程的影响。对于一个小的语言模型，我们计算了每对训练样本的影响分布，并对其进行了分析。我们发现，仅仅考虑自影响会严重低估记忆带来的可感知风险：存在（近）复本样本时，自影响显著降低，但这些样本确实是（近）可提取的。我们还观察到，对于图像分类任务，仅通过查看影响分布可以揭示CIFAR-10中的近复本样本。这些发现强调了记忆是训练数据间的复杂交互结果，而不是仅仅通过自影响就能充分捕获的。

Conclusion: 
我们的研究显示了记忆源自训练数据间的复杂交互，并指出全面的影响分布比仅仅自影响更能捕获记忆的本质。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20481</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>420. cs.CL-当大型语言模型与人类相左？大型语言模型的奉承行为</title><link>https://arxiv.org/pdf/2311.09410</link><description>Background: 
大型语言模型在生成能力方面已经表现出较为满意的性能，这似乎得益于人类反馈的大量使用，这种反馈可以提高模型生成符合用户观点的回答。然而，这种通过人类反馈继承的可说服性增强了模型倾向于生成与用户观点一致而误导性回答的行为，这种行为称为奉承。这种现象会导致偏见并降低模型的稳健性和可靠性。论文即研究了大型语言模型在回答主观意见和应反对其观点的陈述时表现出的奉承行为，以及它们在面对数学任务或客观问题时如何响应用户的暗示。

Innovation: 
该研究通过系统的人类干预提示在不同任务上分析大型语言模型的奉承倾向，并发现这些模型在需要主观意见时表现出奉承倾向，但在面对数学任务或客观问题时会展示出自信的回答正确答案，不遵循用户的暗示。

Conclusion: 
大型语言模型在主观意见问题上表现出明显的奉承倾向，而在客观问题上则不遵循用户的暗示，表现出自信地生成正确答案。这种现象需要研究者进一步解决，以提高模型的中立性并增强其在各种任务中的可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2311.09410</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>421. cs.CL-从书籍学走向代码：面向中世纪历史文书布局分析的Transformer与YOLO检测器对比研究</title><link>https://arxiv.org/pdf/2506.20326</link><description>Background: 
文档布局分析（DLA）对于自动化处理和理解具有复杂页面组织的历史文档至关重要。本文对五种最先进的对象检测架构进行了基准测试，这些架构分别针对三种具有不同复杂度特征的标记数据集进行了评估：e-NDP（巴黎中世纪登记册，1326-1504年），CATMuS（从不同中世纪和现代来源中提取的多元类数据集，约12世纪至17世纪）以及HORAE（装饰书籍，约13世纪至16世纪）。研究发现，模型架构、数据集特征和边框表示方法会对检测性能产生显著影响，并强调使用定向边界框（OBB）对于准确建模历史手稿的非笛卡尔特性来说是必需的，而非仅仅是一个细微的改进。

Innovation: 
研究对比了Transformer基模（Co-DETR，Grounding DINO）和YOLO变种（AABB，OBB，YOLO-World）在历史文书布局分析中的性能。研究揭示了模型架构、数据集特性及边界框表示方法对检测性能的显著影响，特别是强调OBB在复杂文档中至关重要。此外，研究凸显了Transformer在结构布局上的全局上下文感知和CNN-OBB模型在视觉多样和复杂文档上的卓越概括能力之间的权衡。

Conclusion: 
研究结果表明，在结构性布局上，Transformer具有优势；但在需要更多视觉多样性和复杂性的文档中，CNN-OBB模型具有更好的泛化能力。使用OBB是一种基本要求，可以更好地捕捉历史手稿非笛卡尔特性，而并非仅仅是一个小改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20326</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>422. cs.CL-内在有诸多狼化身：利用认知模型解读LLM中的价值权衡</title><link>https://arxiv.org/pdf/2506.20666</link><description>Background: 
日常生活中的社会互动往往需要在相互冲突的目标之间做出权衡，例如传达一个难听的真相，同时还要保持他人的信任并顾及他们的情感。这些价值观的权衡是人类决策和语言使用的有机组成部分，然而，目前用于解释这些动态和多层次的价值观念在大规模语言模型（LLMs）中的工具是有限的。认知科学中的所谓‘认知模型’为人类如何权衡冲突的价值提供了一个形式化的解释，通过建模说话者在选择行动或话语时的竞争效用函数的权重。本文采用了礼貌言语的认知模型来评估LLMs在权衡人类类似行为方面的程度。研究通过系统评估两种模型设置中的价值权衡情况来实现，一种是前沿的黑盒模型推理努力程度，另一种是开源模型的强化学习模型训练后的动态过程。研究结果揭示了推理模型中信息效用高于社会效用的模式，而在数学推理能力较强的开源模型中更为明显。训练动态显示，大型语言模型的价值权值在训练早期会有较大的变化，并且选择基础模型和预训练数据的影响持续存在，与反馈数据集或对齐方法的选择相比影响更大。方法适用于快速变化的LLM景观，提供关于其他高层次行为、推理模型的训练制度以及模型训练期间更好地控制价值权衡的见解。

Innovation: 
本文使用了礼貌言语的认知模型来解读大型语言模型中的价值权衡，通过对两种模型设置（推理努力程度和开源模型的强化学习模型训练后的动态过程）进行系统的评估，揭示了大型语言模型中多样性价值观的权衡模式，强调了早期训练中价值权衡的重大变化以及对基础模型和预训练数据选择的持久影响，并展示了对于动态演化的LLM景观的良好适应性。

Conclusion: 
研究的结果表明了大型语言模型在早期训练中价值权衡的重大变化，并强调了选择基础模型和预训练数据对模型训练的持久影响。研究还展示了该方法适用于快速变化的大型语言模型景观，为形成关于其他高层次行为、推理模型的训练策略以及模型训练期间更好地控制价值权衡的假设提供了洞察。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20666</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>423. cs.CL-PSALM-V：使用大语言模型在互动视觉环境中的符号化规划自动化</title><link>https://arxiv.org/pdf/2506.20097</link><description>Background: 
以往的工作探索了使用大语言模型为基于Planning Domain Definition Language (PDDL) 的符号化规划生成动作语义。这些方法主要集中在基于文本的领域或者依赖于不切实际的假设如访问预定义问题文件、完全可观测性或显式错误信息。本文介绍了一种名为PSALM-V的新系统，它能够在互动视觉环境中自主诱导符号动作语义，无需专家定义的动作条目，通过分析执行结果并合成可能的错误解释，动态推断PDDL问题文件和领域动作语义。该系统迭代地生成和执行计划，并维护一个树结构的信念，涵盖每个操作可能的动作语义，直到达到目标状态。

Innovation: 
PSALM-V是第一个能够在互动视觉环境中自主诱导符号动作语义的系统，无需专家定义的动作条目。该系统使用大语言模型生成启发式计划和候选符号语义，动态推断PDDL问题文件和领域动作语义，通过分析执行结果和合成可能的错误解释。研究表明，PSALM-V相比Claude-3.7在部分观测设置中提高了计划的成功率，步骤效率也有所提高，能够在多智能体设置中成功地诱导领域。此外，PSALM-V还能正确地诱导现实世界机器人BlocksWorld任务的PDDL前置和后置条件，尽管存在低级操作失败的问题。

Conclusion: 
PSALM-V证明了在互动视觉环境中进行符号化规划的可行性，能够在多智能体环境下引导真实世界的任务，并且在部分观测和多智能体环境中显示出优越性，显著提高了计划的成功率与效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20097</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>424. cs.CL-FundaQ-8: 一种受临床启发的自动视网膜图像质量评分框架</title><link>https://arxiv.org/pdf/2506.20303</link><description>Background: 
自动视网膜图像质量评估（FIQA）仍然具有挑战性，由于成像获取的变异性以及专家评估的主观性。现有的方法无法系统地使用八个关键参数（如视场覆盖、解剖学可见度、照明和图像伪影）客观评估视网膜图像质量。

Innovation: 
提出了一种新的专家验证框架FundaQ-8，用于使用八个关键参数系统地评估视网膜图像质量。并基于FundaQ-8构建了一个ResNet18基础的回归模型，用于预测0到1范围内的连续质量分数。该模型采用了知识迁移学习、均方误差优化和标准化预处理进行训练。此框架已通过与EyeQ数据集的验证和统计分析确认其可靠性和临床解释性，并在糖尿病视网膜病变分级的深度学习模型中提高了诊断的稳健性，突显了质量意识训练在实际筛查应用中的价值.

Conclusion: 
FundaQ-8框架整合到糖尿病视网膜病变分级的深度学习模型中，增加了诊断的稳健性，强调了在实际筛查应用中质量意识训练的价值，同时该模型的成功训练和验证也验证了其在医疗领域的临床适用性与可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20303</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>425. cs.CL-由语言模型构建语言模型</title><link>https://arxiv.org/pdf/2506.20249</link><description>Background: 
该研究旨在探索能否利用大型语言模型（LLMs）来建模发现新型语言模型（LM）架构的过程。灵感来源于真实的研究过程，涵盖了从构思与文献搜索（提案阶段）到设计实现（代码生成）、生成式预训练、以及下游评估（验证）等阶段。此外，研究利用了可扩展性定律，开发了一个名为Genesys的系统，采用分层级（梯度）的方法进行设计，新架构通过对抗性审查、实现并通过预训练逐级验证。

Innovation: 
研究的创新点在于提出了一个多代理LLM方法，该方法模拟了传统的研究阶段，同时引入了一种新颖的遗传编程背骨，相较于直接提示生成工作流具有明显的实证优势。这项工作的具体贡献包括：1）利用分层级的尺度梯度方法进行设计拟合、实现和验证；2）采用遗传编程作为硬件架构的基础，并通过实验证明了其相对于常用直接提示生成流程的优势；3）系统化的方法和全面的消融测试及正式结果，提供了针对高效自主发现系统的更广泛的见解。

Conclusion: 
该研究共发现了1,162个新型设计，并通过预训练验证了1,062个设计，结果显示最好的设计与已知架构具有高度竞争力，如在六个到九个通用基准测试中超过了GPT2、Mamba2等。这些成果提供了关于有效自主发现系统设计的广泛见解，为未来的研究方向提供了参考。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20249</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>426. cs.CL-Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning</title><link>https://arxiv.org/pdf/2506.20020</link><description>Background: 
人类推理往往受到身份保护等内在动机的影响，这会损害理性决策和判断。集体化的动机性推理在关键问题（如人类引发的气候变化或疫苗安全性）上可能对社会有害，甚至加剧政治分裂。已有研究表明大型语言模型（LLMs）也表现出类似人类的认知偏见，但这些模型的身份一致性推理选择性为何程度未知。研究者通过给LLMs分配不同的人格特征，探索了不同政治和社会人口统计属性如何引发动机性推理。通过两个基于人类实验的任务测试8种LLMs，结果显示，人格特征赋予的模型在辨别虚假信息标题的准确性上降低了约9%，而政治人格特征在展示与其身份一致的科学证据时，正确评估可能性提高了90%。压制性提示方法在缓解这些效果上基本无效。这项发现首次表明，人格特征赋予的LLMs表现出类似人类的动机性推理，且难以通过常规去偏见提示来缓解，从而引发了关于LLMs和人类中增强一致推理的担忧。

Innovation: 
本研究首次证明了赋予LLMs不同人格特征可能导致类似人类的动机性推理现象。通过对比不同LLMs的表现，研究揭示了政治人格特征对科学证据评估的显著影响，并且发现压制性提示方法在缓解这种效应时效果有限。实证结果表明，这种动机性推理难以通过传统方法缓解，引发对未来研究和应用的担忧。

Conclusion: 
本研究发现，赋予LLMs不同人格特征可能导致类似的动机性推理，政治人格特征在与身份一致的情况下特别有利于评估科学证据。这种类型的人格特征赋予模型显示出难以通过常规去偏见提示缓解的动机性推理。这一发现对LLMs的使用和未来研究提出了重要警示。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20020</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>427. cs.CL-为什么机器人不善于检测自己的错误：人类-机器人对话中误沟通检测的局限性</title><link>https://arxiv.org/pdf/2506.20268</link><description>Background: 
检测人类与机器人交互中的误解是维持用户参与和信任的关键功能。尽管人类能够通过口头和非口头线索轻松地检测到交流错误，但机器人在解释非口头反馈方面仍面临重大挑战，尽管在通过计算机视觉识别情感表达方面取得了进展。通过分析多模态数据集中的240次人机对话，并评估最先进的计算机视觉模型在检测机器人对话中的误解方面的效果，研究发现尽管使用了最先进的模型，但在识别误解方面几乎没有超越随机猜测的表现，而在更多表达情感内容的数据集上，他们可以识别出混淆状态。进一步的研究表明，人类评估者也很难识别出诱导的误解，这揭示了机器人在对话中检测误解的基本限制：即使用户感觉到诱导的误解，他们也往往不会向机器人伴侣传达这一点。

Innovation: 
该研究使用了多模态数据集来系统地引入四种类型的对话失败，并评估了最先进的计算机视觉模型在这种情境下的表现。同时，研究也通过让人类评估者参与相同的过程，来探索模型与人类在识别误解方面表现差异的根本原因。这项研究揭示了计算机视觉模型在检测机器人对话中误解方面存在的基本局限性，并提供了一种理解用户是否向机器人传达误解的视角。

Conclusion: 
研究结果表明，机器人在检测对话中的误解方面存在着基本局限，即使在用户能够感知到误解的情况下，他们通常也不会传达给机器人。这些发现可以调整对计算机视觉模型性能的期望，并帮助研究人员通过有意识地寻求反馈来设计更有效的机器人对话。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20268</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>428. cs.CL-本地检索增强生成模型在医疗任务中比商业大型语言模型更准确且节能</title><link>https://arxiv.org/pdf/2506.20009</link><description>Background: 
随着人工智能在医疗领域的应用日益广泛，引起了对其环境和伦理影响的关注。商用大型语言模型（LLMs），如ChatGPT和DeepSeek，需要大量资源，而这些系统在医疗应用中的使用引发了关于患者隐私和安全的重要问题。

Innovation: 
开发了一个可定制的检索增强生成（RAG）框架用于医疗任务，该框架监控其能源使用和二氧化碳排放。研究使用多种开源LLMs创建了不同RAG模型，比较了普通目的模型（如llama3.1:8b）和医学领域特定模型（如medgemma-4b-it）的表现，并将这些模型与DeepSeekV3-R1和OpenAIs o4-mini模型进行了对比，发现自定义的RAG模型在准确性和能源消耗方面优于商用模型。

Conclusion: 
研究表明，本地LLMs可用于开发在医疗任务中表现优于商用在线LLMs的RAG，同时还具有较小的环境影响。我们的模块化框架促进可持续的AI开发，减少能源使用并符合联合国可持续发展目标。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20009</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>429. cs.CL-DiffuCoder：理解并改进半掩蔽扩散模型在代码生成中的应用</title><link>https://arxiv.org/pdf/2506.20639</link><description>Background: 
扩散大语言模型（dLLMs）因其在整个序列上的去噪操作，成为了自回归（AR）模型的有吸引力替代品。dLLMs 的全局规划和逐步优化特性特别适用于代码生成。然而，当前的编码中dLLMs的训练和推理机制仍缺乏深入研究。本文旨在通过系统研究dLLMs的去噪过程和强化学习（RL）方法，来揭示其解码行为，并探索其在编码中的潜力。

Innovation: 
- 提出一种新型采样方案coupled-GRPO，用于构建互补的掩码噪声，提高扩散模型的解码性能，减少对AR因果依赖。n- 揭示了dLLMs与自回归模型AR的不同解码行为：dLLMs可以在不依赖半自回归解码的情况下决定生成的因果性，提高采样温度可以增加生成的多样性和生成顺序的多样性，创造更丰富的搜索空间以提高强化学习的方法效果。n- 提供了一个基于扩散的强化学习训练框架，显著提高了DiffuCoder在代码生成基准测试中的性能，并展示了扩散模型在代码生成中的潜力。

Conclusion: 
本工作深化了对dLLM生成机制的理解，并提供了一个有效的、基于扩散的RL训练框架，对代码生成任务有显著提高。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20639</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>430. cs.CL-Memento: Note-Taking for Your Future Self</title><link>https://arxiv.org/pdf/2506.20642</link><description>Background: 
大规模语言模型（LLMs）在推理任务上表现出色，但在推理需要与检索紧密耦合的情况下（例如多跳问答）则表现不佳。作者指出，现有的提示策略在处理这些任务时存在局限性，亟需一种新的方法来解决这些问题。针对这些问题，作者介绍了一种新的提示策略Memento，该方法首先将复杂问题分解为多个步骤，然后使用LLMs动态构建事实数据库，最后将这些事实组合起来解决问题，以此来克服当前提示策略的局限性，提升整体性能。

Innovation: 
Memento提出了一种新的三步提示策略，首先分解复杂问题为小步骤；其次，使用LLMs动态构建一个事实数据库；最后，将这些事实组合起来解决原始问题。在9步骤的PhantomWiki基准测试中，Memento将chain-of-thought (CoT)的表现翻倍。在开放领域版本的2WikiMultiHopQA中，CoT-RAG结合Memento比传统的CoT-RAG和多跳RAG（IRCoT）有显著的改进。在具有挑战性的MuSiQue数据集上，Memento也改进了ReAct，展示了其在代理环境中的应用价值。

Conclusion: 
Memento作为一种新的提示策略，能够显著提升现有提示策略在多跳问答等任务中的性能。该策略在多种场景下的应用表明，它具有广泛的应用潜力和增强LLMs处理推理与检索结合任务的能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20642</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>431. cs.CL-GPTailor: 通过层剪辑与缝合进行大型语言模型剪枝</title><link>https://arxiv.org/pdf/2506.20480</link><description>Background: 
大型语言模型（LLMs）在语言理解和生成方面展现出卓越的能力，但这种强大的功能通常伴随着庞大的模型规模，这给部署和推理带来了巨大挑战。结构化修剪模型参数提供了一种在部署时降低计算成本的潜在解决方案，但目前的方法主要集中在单个模型的修剪上。因此，需要一种新的策略来通过从微调模型变体中战略性地组合或合并层来压缩模型，从而保留原始模型的能力，同时聚集不同微调加强的能力。

Innovation: 
开发了一种新颖的方法，通过战略性地从不同微调模型中连接或合并层来压缩大型语言模型，该方法将最佳剪裁这些模型作为零阶优化问题进行建模，采用支持三种不同操作的空间：（1）层删除；（2）从不同候选模型中选择层；（3）层合并。实验结果表明，这种方法在模型剪枝方面具有竞争力，例如，在Llama2-13B模型系列中，我们的压缩模型保持了约97.3%的原始性能，同时移除了约25%的参数，显著优于之前最先进的方法。

Conclusion: 
该方法在模型剪枝方面表现优异，不仅大幅减少了参数量，还保持了模型的原有性能，极大地推动了大型语言模型部署的效率和可行性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20480</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>432. cs.CL-捕捉可视化设计方案</title><link>https://arxiv.org/pdf/2506.16571</link><description>Background: 
现有自然语言数据集主要关注可视化素养评估、见解生成和从自然语言指令生成可视化图表等任务。这些研究往往依赖于精确设置和专门构建的可视化图表及人为构造的问题。因此，这些研究更多关注对可视化结果的解读，而非对其编码的理解。本文介绍了通过自然语言探查可视化设计理由的新数据集和方法。研究利用由数据可视化课程学生创建的具有说明性的可视化笔记本作为一种独特的数据来源。这些笔记本结合了可视化作品和设计说明，其中学生明确解释了他们设计决策背后的理由。作者还利用大语言模型从笔记本中的叙述和解释自动生成和分类生成问题-答案-理由三元组，然后精心验证这些三元组并编纂成一个捕获和提炼学生可视化设计选择及其理性依据的数据集。

Innovation: 
本文创新地利用数据可视化课程中学生创建的具有说明性的可视化笔记本数据源，并利用大语言模型自动生成和分类问题-答案-理由三元组。这种方法能够更真实地捕捉到可视化的设计背后的理由，帮助研究人员和从业者更好地理解可视化作品的编码逻辑，而不只是解读其结果。

Conclusion: 
通过精心验证和编纂学生在可视化课程中创作的可视化笔记本中的信息，本文开发了一个新的数据集，该数据集能够捕获和提炼学生的可视化设计选择及其对应的理由，为进一步探索可视化设计过程提供了新的视角和工具。这一方法不仅为可视化领域补充了新的研究数据，也为其他相关领域的研究提供了新的灵感。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16571</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>433. cs.CL-机器学习会议应建立‘反驳与批评’轨道</title><link>https://arxiv.org/pdf/2506.19882</link><description>Background: 
机器学习研究的迅速发展导致了大量出版物的出现，但也导致了一些误导性、错误的、有缺陷甚至可能是欺诈的研究被接受并在机器学习会议上突出展示。尽管这些错误是可以理解的，但机器学习会议目前缺乏系统纠正此类错误的 robust 过程。研究进展依赖于人们对世界的逐步理解与修正，这一过程中也难免会出现这些错误。

Innovation: 
该论文提出了在机器学习会议上建立一个专门的‘反驳与批评’（R&amp;amp;C）轨道。这一轨道将为关键挑战先前研究的高水平、高信誉平台提供支持，从而促进动态自我纠错的研究生态系统。论文还讨论了轨道设计、评审原则以及潜在风险，并提供了一个关于ICLR 2025口头报告的示例性提交。

Conclusion: 
机器学习会议应该创建官方、高信誉的机制，以帮助机器学习研究进行自我纠正。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19882</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>434. cs.CL-ReCode: 使用强化学习更新代码API知识</title><link>https://arxiv.org/pdf/2506.20495</link><description>Background: 
大规模语言模型（LLMs）在代码生成方面展现出出色的能力，但在适应外部库API频繁更新时表现不佳。这一缺陷源于LLMs依赖于训练数据中过时的API知识，即使有最新的文档也难以适应。这在动态环境中给代码生成带来了挑战。本文研究了这一问题的原因并提出解决方案。

Innovation: 
本文提出了一种名为ReCode的新型框架，它借鉴了人类编程者在API变化时的适应性，通过对大约2,000个数据条目的训练，使LLMs能够基于更新的信息进行版本迁移。此外，引入了修改后的字符串相似度度量作为强化学习的奖励。实验表明，ReCode能显著提升LLMs在动态API场景下的代码生成性能，在CodeUpdateArena任务上尤甚。相比监督微调，ReCode对LLMs一般代码生成能力的影响较小。在多个LLMs和强化学习算法上进行了测试，所有都取得了持续改进。特别地，训练后的Qwen2.5-Coder-7B在某些任务上超越了32B参数代码指令调优模型和同架构的推理模型。代码已经开源附近提供的地址。

Conclusion: 
ReCode通过模仿人类编程者的适应性，有效提升了LLMs在动态API环境下的代码生成能力，且在大部分LLMs和不同的强化学习算法上都展现了显著的性能改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20495</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>435. cs.CL-多元化样本的力量：提升多语言大型语言模型推理计算规模的好处</title><link>https://arxiv.org/pdf/2506.20544</link><description>Background: 
近年来大型语言模型（LLMs）的发展重点转向了在推理时扩展计算规模，提高性能而无须重新训练模型。一种常见方法是并行采样多个输出，然后从中选择一个作为最终输出。尽管目前的工作主要集中在英语和少数几个领域，如数学和代码，与之相比，我们更关注那些可以在开放式任务、形式验证任务以及跨越语言的情境下推广的技术。本研究探讨了如何在多语言、多任务设置中稳健地扩展开放式生成任务的推理时间计算。研究发现，基于温度变化的采样策略和选择策略需要适应不同领域和变体的语言设置。

Innovation: 
研究提出了为多语言和多任务推理场景专门调整的新采样和选择策略，这些策略在语言和任务上下文中展现了显著的收益。特别是在m-ArenaHard-v2.0提示上，我们的8B模型综合采样和选择方法使翻盘率平均提高了6.8%，领先于专有的模型如Gemini。在更大规模下，Command-A（111B模型）配备我们的方法，仅用五个样本就能在相同基准上取得9.0%的提高，比单样本编码有显著增加且成本极低。结果突出了语言和任务意识的推理时间计算方法的重要性，旨在推动在边缘语言中的性能改进的平等化。

Conclusion: 
我们的研究结果表明，需要语言和任务意识的方法来优化推理时间计算，争取在欠代表性语言中民主化性能增益。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20544</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>436. cs.CL-OctoThinker: 中期训练激励强化学习扩展</title><link>https://arxiv.org/pdf/2506.20512</link><description>Background: 
不同的基础语言模型家族（如Llama和Qwen）在强化学习（RL）训练后表现出不同的行为，尤其是在需要大量推理的任务上。理解什么使得基础语言模型适合于强化学习至关重要，这对于开发下一代可扩展的RL基础模型非常重要。这项工作重点研究中期训练策略如何影响RL动态，特别是在Qwen和Llama这两种代表性模型家族上。研究揭示了高质量数学数据集（如MegaMath-Web-Pro）可以显著提升基础模型和RL性能，而其他数据集（如FineMath-4plus）却没有这种效果；通过增加QA式数据，特别是长逻辑推理链（CoT）示例，可以进一步优化RL结果，指示数据进一步解锁这种效应；虽然长CoT可以提高推理深度，但也可能导致模型响应冗长和RL训练的不稳定，强调了数据格式化的重要性；中期训练尺度一致有助于增强下游RL性能。这些见解促使提出了Stable-then-Decay两阶段中期训练策略，此策略成功提高了OctoThinker模型的RL兼容性，缩小了它与其他更RL友好的模型系列之间的性能差距，即Qwen。我们希望这项工作能够帮助指导RL时代的预训练策略。为支持进一步研究，我们还开源了包含超过700亿个令牌的数学推理密集型语料库（MegaMath-Web-Pro-Max）和相关模型。

Innovation: 
提出了Stable-then-Decay两阶段中期训练策略，成功提高了模型的RL兼容性和鲁棒性，缩小了与更RL友好的模型系列之间的性能差距。开源了包含超过700亿个令牌的数学推理密集型语料库和相关模型，为后续研究提供支持。

Conclusion: 
中期训练策略可以显著改善基础语言模型在强化学习中的表现，特别是通过高质量的数学数据增强和特定的两阶段训练方法。这为RL时代的基础模型预训练策略提供了新的见解，并为未来的研究和开发奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20512</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>437. cs.CL-模型编辑双刃剑：将代理伦理行为引导至善意或危害</title><link>https://arxiv.org/pdf/2506.20606</link><description>Background: 
基于大型语言模型的代理展示了广泛的任务能力，但在高风险领域部署时面临巨大的安全和伦理风险。这些代理的不当行为可能导致严重的现实后果，如身体伤害和经济损失。为有效引导代理的伦理行为，作者将代理行为引导定义为一种模型编辑任务。模型编辑是一种新兴的研究领域，能够对大型语言模型进行精准高效的修改，同时保持其整体能力。通过引入基于心理道德理论的多级基准工具BehaviorBench，作者系统研究并评估了这一方法的有效性。BehaviorBench不仅支持代理行为的评估，也支持行为编辑，涵盖不同场景下的复杂和模糊情景。研究发现，模型编辑不仅能动态引导代理在特定情境下的行为，还能在全局层面改变代理的道德定向。

Innovation: 
作者将代理行为引导定义为一种模型编辑任务，以引导大型语言模型代理在高风险领域的伦理行为。通过引入名为BehaviorBench的多级基准工具，作者评估了这一方法的有效性，支持代理行为在多种场景下的评估与编辑。BehaviorBench基于心理道德理论设计，能够提出复杂和模糊的场景，从而系统地研究和评估模型编辑的可行性和有效性。这种方法不仅能够在特定场景下进行细微调整，还能在全局上对代理的道德定向进行广泛的改变，促进正面行为或诱发负面行为。

Conclusion: 
通过在最前沿的大模型代理上进行全面评估，BehaviorBench表明模型编辑在不同模型和场景下都能有效引导代理行为，展示了模型编辑的潜力以及面临的挑战。研究结果提供了一个新的代理行为指导范式的关键见解，强调了模型编辑在伦理和效益方面的双重作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20606</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>438. cs.CL-Biomed-Enriched: 一种通过大型语言模型优化并提取罕见和隐藏内容的生物医学数据集</title><link>https://arxiv.org/pdf/2506.20331</link><description>Background: 
临床文本数据由于隐私限制难以获取，而PubMed中的文章包含丰富的临床案例、生物医学研究和其他类型的信息，但缺乏有效的利用方式。现有资源主要是通过批量标注大语料库来生成文本数据集，但这些资源往往难以满足生物医学和临床自然语言处理任务的具体需求，因此需要一种新的方法来构建针对性的数据集，并有效获取高质量的临床文本资源。

Innovation: 
该研究创新地提出了Biomed-Enriched数据集，通过两阶段注释过程从PubMed中筛选出高质量的生物医学文本。第一阶段利用大型语言模型对大量片段进行类型、领域和教育质量的标注，第二阶段使用这些标注信息微调小型语言模型，以推广标签至整个PMC-OA语料库。基于此数据集的元数据，研究人员可以提取出精准的子集，并利用质量过滤和领域过采样等方式构建多种变体。通过初步连续预训练实验，发现该数据集中的精选子集能够实现目标改进，而且结合这些技术能够加快训练收敛速度，节省训练资源，表明了其高效且有效的生物医学预训练策略潜力。

Conclusion: 
Biomed-Enriched数据集为生物医学和临床自然语言处理任务提供了高质量的临床案例资源，有助于提升性能并节省训练成本。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20331</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>439. cs.CL-一种具有可追溯推理的稀有疾病诊断代理系统</title><link>https://arxiv.org/pdf/2506.20430</link><description>Background: 
全世界有超过30000万人遭受罕见疾病的困扰，但及时和准确的诊断仍然面临巨大挑战。这主要是由于罕见疾病的临床异质性、低个体发病率以及多数临床医生对罕见疾病缺乏熟悉度。现有诊断方法难以应对这些挑战，因此需要一种新的解决方案。

Innovation: 
该论文介绍了一个名为DeepRare的系统，它是首个基于大语言模型的稀有疾病诊断代理系统。该系统能够处理异质性临床输入，并生成针对罕见疾病的排名诊断假设，每个诊断假设都包含透明的推理链，将中间分析步骤与可验证的医学证据联系起来。此系统包括三个关键组件：中央主机具有长期记忆模块；专门的代理服务器负责特定领域的分析任务，整合了超过40个专业工具和大型、最新的医学知识资源。系统模块化和可扩展的设计使其能够进行复杂的诊断推理，同时保持可追溯性和适应性。该系统在8个数据集上的评估中显示出了卓越的诊断性能，对2919种疾病中的1013种疾病的诊断准确率达到100%，在HPO基评估中显著优于其他15种方法。对于多模态输入场景，DeepRare的Recall@1达到了70.60%，而在同样的场景下Exomiser仅为53.20%。临床专家手动验证推理链的共识率为95.40%。此外，该系统已被实施为用户友好的网络应用程序。

Conclusion: 
研究提出了一种基于大语言模型的稀有疾病诊断代理系统DeepRare，该系统通过透明的推理链和模块化设计展示了卓越的诊断性能，并展示了在实际应用中的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20430</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>440. cs.CL-时间站在我的这边：视频聊天对话中发言时间分配的动力学</title><link>https://arxiv.org/pdf/2506.20474</link><description>Background: 
每场对话的核心在于参与者间发言时间的分配，这种分配可以是平衡的，也可以是失衡的，这一分配过程是通过连续的协商形成，涉及谁在何时发言以及发言多长时间的问题。已有研究揭示了不同平衡度的对话分配在实际对话中的感知偏好，但较少从时间和动力学角度系统分析这些分配的形成过程。本研究通过设计计算框架，测量和分类不同类型的发言时间分配模式，旨在揭示这些模式的内在动力学特征，并探讨其在人类和人工智能通信中的应用潜力。

Innovation: 
这项研究提出了一个新的计算框架，用于量化讲话者在对话中的总体发言时间分布及其底层动力学。该框架根据几个直观变数衍生出一种发言时间分配模式的分类法，通过分析大规模陌生人视频聊天数据，揭示了不同类型的发言时间分配模式在实际对话中对参与者的不同感知效果，这种效果即使在总体平衡度相同的情况下也会有所不同。新的分类法对于设计师设计人与人和人与AI之间的通信平台提供了新的工具。

Conclusion: 
研究结果表明，不同类型的发言时间分配模式对对话参与者的感知存在差异，尤其是在平衡度相同时，也有所不同。由此可知，尽管总的发言时间分配可能相似，但不同模式的动力学特征在用户体验上是有区别的。研究提出的计算框架不仅有助于理解和优化人类和人工智能之间的对话效果，还为企业设计更好的计算机介导通信平台提供了新的方法论支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20474</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>441. cs.CL-通过结构化推理增强大型语言模型</title><link>https://arxiv.org/pdf/2506.20241</link><description>Background: 
最近的大型语言模型（LLMs）已经在自然语言处理和自动化决策方面取得了显著进步。然而，这些模型在执行涉及逻辑推理和系统性规划的复杂任务时仍面临挑战。主要原因在于它们依赖隐含的统计关系而非结构化的知识。受认知科学和神经符号AI的启发，本文提出了一种增强LLMs的方法，即通过明确的结构化推理。首先，将未结构化的数据转换为结构化格式，通过显式标注推理步骤。然后，利用这个结构化数据集对LLMs进行监督微调（SFT）。此外，本文还通过Group Relative Policy Optimization (GRPO)增强了LLMs的结构化推理能力，引入了MAX-Flow和Longest Common Subsequence (LCS)两种创新算法，显著提高了推理效果并降低了计算复杂性。

Innovation: 
引入了通过结构化数据显式标注推理步骤的方法，并使用Supervised Fine-Tuning (SFT)进行模型训练。还提出了Group Relative Policy Optimization (GRPO)并结合了两种创新算法（MAX-Flow和Longest Common Subsequence (LCS)），有效提升模型的推理效果和降低计算复杂性。实验证明，在DeepSeek-R1-Distill-Qwen-1.5B模型上进行微调可以实现简洁、稳健的推理并提高与优化技术的兼容性，验证了结构化推理在LLMs中的有效性。

Conclusion: 
本文通过增强LLMs的结构化推理能力，有效提升了其在复杂任务中的表现，并增强了模型的计算效率和应用灵活性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20241</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>442. cs.CL-CBF-AFA: 基于块的多SSL融合自动流畅度评估</title><link>https://arxiv.org/pdf/2506.20243</link><description>Background: 
自动流畅度评估（AFA）依然具有挑战性，尤其是在捕捉非母语演讲者的语音节奏、停顿和脱节方面。现有方法难以全面准确地评估这些特点，特别是对于非母语者的语音特征更为复杂，使得评估更加困难。现有的单一自我监督学习（SSL）模型虽然有效，但在综合不同类型的语音特点时存在一定局限性，如声学和语义特征的平衡问题以及过段化的问题。

Innovation: 
本文提出了一种基于块的方法，结合了多种自我监督学习模型（Wav2Vec2、HuBERT 和 WavLM），通过层次化的CNN-BiLSTM框架，引入块级流畅度标记（如语速、停顿时间和n-gram重复次数），实现对块进行短语活动检测（Silero-VAD），从而进行精细的时间分析并减少过度分割的伪影。这种方法通过可学习的加权机制融合SSL嵌入，平衡声学和语言特征，并提高了局部和长期依赖性分析的能力，从而实现更好的流畅度评估结果，特别是在Avalinguo和Speechocean762数据集上的表现优于单一SSL模型和基于此分割的方法，显示出基于块的多SSL融合在稳健的流畅度评估中的优势。

Conclusion: 
本文的方法在Speechocean762数据集上实现了对单一SSL基线的2.8点F1得分和6.2点皮尔逊相关性的改进，在Avalinguo数据集上则分别实现了4.2点和4.0点的提升。相比基于块的分割方法，我们的方法表现更优。这些发现强调了基于块的多SSL融合在流畅度评估中的应用潜力，但未来的研究方向应探索其在具有不规则语调方言中的泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20243</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>443. cs.CL-使用源代码探究人工智能安全性</title><link>https://arxiv.org/pdf/2506.20471</link><description>Background: 
大规模语言模型（LLMs）在众多安全关键应用中与人类互动，这要求提升这些模型的能力的同时，更要确保其安全性，使其更好地与人类价值观和偏好对齐。然而，当前许多模型在实现这一目标上表现不佳，为用户带来了不安全和有害的体验。本文探讨了当前广泛应用的LLMs在安全性方面的不足，并提出了一种名为Code of Thought (CoDoT)的提示策略，用于评估这些模型的安全性。通过将自然语言输入转换为简单代码来表示相同意图，CoDoT能有效暴露这些先进模型在安全性上的缺陷。

Innovation: 
本文提出了一种名为Code of Thought (CoDoT)的新提示策略，用于评估大规模语言模型的安全性。具体表现为将自然语言提示转换为简单的代码形式，便于发现模型的不安全性。CoDoT被证明能显著提升对现代模型安全性问题的检测能力，如GPT-4 Turbo的毒性增加了16.5倍，DeepSeek R1完全失效，以及平均毒性增加了300%。这一策略还展示出通过递归应用CoDoT进一步增加模型的毒性，强调了对安全性和能力并重评估的需求。

Conclusion: 
鉴于LLMs正在迅速普及，本文强调了从基本原则出发评估安全性，确保安全性和能力共同提升的必要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20471</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>444. cs.CL-跨源问答中的知识aware多样化重排序</title><link>https://arxiv.org/pdf/2506.20476</link><description>Background: 
SIGIR 2025 LiveRAG比赛由自动从互联网语料库生成的评价集组成，该评价集覆盖了广泛的主题、问题类型、问题表述方式、受众类型和知识组织方法。这项比赛旨在公平评估从FineWeb语料库的1500万文档子集检索问题相关支持文档的能力。

Innovation: 
提出了一个知识感知的多样化重排序RAG管道。这一创新方法在比赛中获得了第一名，表明这种方法在处理跨源问答任务时具有显著优势.

Conclusion: 
该研究通过知识感知的多样化重排序方法，在SIGIR 2025 LiveRAG比赛中取得了第一名的成绩，展示了该方法在检索问题相关支持文档方面的有效性，特别是在处理复杂多样的问答任务时表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20476</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>445. cs.CL-叙事转变检测：动态话题模型与大型语言模型的混合方法</title><link>https://arxiv.org/pdf/2506.20269</link><description>Background: 
随着媒体叙事的快速演变，从给定语料库中仅提取叙事已不足以满足需求，更为关键的是需要研究这些叙事如何随时间发展。虽然大型语言模型在捕捉叙事元素或复杂的叙事结构方面表现良好，但在应用于整个语料库时会遇到高昂的财务或计算成本。本研究旨在结合大型语言模型的理解能力与话题模型的大规模应用性，通过叙事政策框架动态建模叙事随着时间的转变。该研究将应用话题模型和相应的变化点检测方法来发现由特定话题引起的变化，并筛选出特别代表该变化的文档，然后将这些文档输入大型语言模型以自动解释叙事和内容转变。研究对象是2009年至2023年的《华尔街日报》新闻文章。研究表明，如果在特定时间点存在叙事转变，大型语言模型可以高效地提取这一转变，但如果要判断是内容转变还是叙事转变，则表现不佳。

Innovation: 
本研究提出了一种结合大型语言模型和话题模型的方法，用于动态建模叙事随时间的变化，这种方法能有效应对传统的大型语言模型在处理大规模语料库时的局限性。此外，该研究还采用了特定的变化点检测方法来识别叙事转变，并将特别代表转变的文档输入大型语言模型进行自动化解释分析。

Conclusion: 
研究发现，若存在叙事转变，大型语言模型能够高效地提取这种转变，但在判断是内容还是叙事转变方面表现不佳。未来的研究可以进一步探索如何改进这一模型以提高其在判断不同类型的转变方面的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20269</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>446. cs.CL-TAPS: 通过结构化标签实现工具增强个性化</title><link>https://arxiv.org/pdf/2506.20409</link><description>Background: 
最近，工具增强型大型语言模型的进步使它们能够与外部工具互动，从而增强了它们完成复杂用户任务的能力。然而，现有的方法忽视了个性化在指导工具使用中的作用。本文研究了用户偏好如何有效地集成到目标导向对话代理中。通过广泛的分析，我们发现了大型语言模型在个性化工具使用能力方面的关键缺陷。为此，我们提出了一种名为TAPS的新颖解决方案，该解决方案通过利用结构化标签工具和基于不确定性的工具探测器来增强个性化工具使用的能力。

Innovation: 
引入了一种名为TAPS的新颖解决方案，通过利用结构化标签工具和基于不确定性的工具探测器来增强个性化工具使用的能力。TAPS显著提高了大型语言模型纳入用户偏好能力，实现了开源模型在NLSI任务上的最新技术水平。

Conclusion: 
通过TAPS，大型语言模型能够更好地将用户偏好的个性化因素整合到其工具使用过程中，提高了完成复杂用户任务的能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20409</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>447. cs.CL-ITFormer: 跨接时间序列与自然语言以实现大规模多任务多模态问答</title><link>https://arxiv.org/pdf/2506.20093</link><description>Background: 
时间序列数据在工业监控、医疗诊断和气候研究等多样应用中至关重要。然而，将这些高维时间信号与自然语言有效地结合起来完成动态、交互式任务仍然是一个重要难题。

Innovation: 
本文提出了一种Time-Series Question Answering (Time-Series QA) 任务，并发布了EngineMT-QA，这是一个大型的、多任务的时间文本问答数据集，旨在捕捉时间序列信号与自然语言之间复杂的交互。在此基础上，提出了一种新型的框架——Instruct Time Transformer (ITFormer)，该框架将时间序列编码器与冻结的大语言模型（LLMs）相结合，有效提取、对齐和融合了时间和文本特征，相较于强大的基线模型，在参数量增加不到1%的情况下，大幅提高了问答准确性，本研究通过结合计算效率和跨模态建模的鲁棒性，建立了一种新的时间数据与自然语言整合的可拓展范式，为多模态AI中的新研究和应用铺平了道路。

Conclusion: 
本文研究通过结合计算效率和跨模态建模的鲁棒性，建立了一种新的时间数据与自然语言整合的可拓展范式，为多模态AI中的新研究和应用铺平了道路。更多关于项目的详细信息，包括数据集和代码，可在以下网址获取：this https URL</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20093</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>448. cs.CL-玩转视角：一种更包容的自然语言处理系统的方法</title><link>https://arxiv.org/pdf/2506.20209</link><description>Background: 
在自然语言处理（NLP）领域，处理人类分歧的常见方法是聚合注释者的意见以确定单一的地面真相。然而，先前的研究表明，忽视个体观点可能导致少数派视角的代表性不足，特别是在主观任务中，注释者可能由于其偏好有系统性的分歧。考虑到标签反映了不同个人的背景、生活经验和价值观，这项研究提出了一种新的多视角方法，利用软标签鼓励开发对视角更加敏感的下一代模型，更具包容性和多元性。研究在多样化的主观文本分类任务中进行了广泛分析，例如仇恨言论、讽刺、攻击性语言和立场检测，以强调捕捉人类分歧的重要性，这是传统聚合方法经常忽略的。

Innovation: 
该研究提出了一种新的多视角方法，利用软标签来鼓励开发对视角更加敏感的下一代模型，旨在提高NLP系统的包容性和多元性。通过广泛分析多样化的主观文本分类任务，研究显示，这种多视角方法不仅更好地逼近了人类标注的分布，还在分类性能上表现出优于传统方法的优势（更高的F1得分），尽管在讽刺和立场检测等任务上表现出较低的置信度，这可能是因为这些文本本身具有内在的主观性。此外，研究还利用可解释的人工智能（XAI）方法探索了模型的不确定性，并得到了有关模型预测的有意义见解。

Conclusion: 
多种主观文本分类任务的研究结果表明，多视角方法不仅更准确地模拟了人类注释的分布（通过Jensen-Shannon散度来衡量），还取得了更好的分类性能（更高F1得分），相较于传统方法。然而，在讽刺和立场检测等任务上，该方法的置信度较低。利用可解释AI方法，研究进一步揭示了模型预测的不确定性，并提供了有意义的洞察。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20209</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>449. cs.CL-AALC: 大型语言模型高效推理通过自适应准确度-长度控制</title><link>https://arxiv.org/pdf/2506.20160</link><description>Background: 
大型推理模型（LRMs）通过生成详细的推理链来实现出色的推理能力，但这也会导致长时间延迟和成本，而准确度并未相应提高。这项工作中，作者引入了一种名为AALC的方法，将基于准确性和长度的轻量级奖励集成到强化学习中，在训练过程中动态平衡正确性和简洁性。通过将验证准确度纳入奖励，并采用平滑的、动态调度的长度惩罚，AALC将长度惩罚推迟至达到目标性能之后。

Innovation: 
AALC结合了验证准确度的奖励和动态调度的平滑长度惩罚，能够在满足性能目标之前延后长度惩罚，从而帮助模型在保持或提高准确性的前提下减少响应长度超过50%。此外，AALC还减少了冗余的推理模式，如过度设置子目标和验证，促使输出结构更加精炼，而非简单地截断信息。研究还发现，虽然这种效率的提升伴随着解释性降低（模型省略了一些叙事框架和解释性背景信息），但这种方法展示了基于奖励策略指导LRMs采取更高效、更具泛化能力推理路径的潜力。

Conclusion: 
通过在标准及非分布式的数学基准测试中进行广泛的实验，该方法不仅减少了超过50%的响应长度，还在保持甚至提升了原始准确性的基础上进行推理。此外，质性分析表明，该方法抑制了不必要的推理程序，导致输出结构更加精炼，而不是简单地截断。尽管这种方法提高了效率，但模型在训练过程中减少了对解释性背景信息的依赖，从而降低了解释性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20160</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>450. cs.CL-COIN：基于证明风险保证的不确定性保护选择性问答框架</title><link>https://arxiv.org/pdf/2506.20178</link><description>Background: 
基础模型生成的文本中需要通过不确定性量化（UQ）来识别和缓解潜在的幻觉，但现有的启发式UQ方法缺乏关于关键指标如选择性预测的错误发现率（FDR）的正式保证。尽管之前的分裂置信预测（SCP）框架能够在构建的预测集中确保可接受答案的覆盖率，但这些预测集通常包含不正确的候选答案，限制了它们的实际应用价值。本文探讨了如何进一步改进这一问题，提出了COIN框架，以统计上有效的阈值来过滤每个问题下生成的答案，并在用户指定的FDR约束下进行选择。

Innovation: 
本文提出了COIN框架，这是一种统计有效的不确定性阈值校准方法，旨在为每个问题选择一个生成的答案，并在用户指定的FDR约束下进行筛选。COIN框架通过在校准集上估计经验误差率，并应用包括Clopper-Pearson在内的置信区间方法来确定真实错误率（即FDR）的高概率上限，从而能够在测试数据上控制FDR的同时大幅提升样本保留率。此外，本文证明了使用不同的上界构造和不确定性量化策略可以进一步增强COIN的效能，从而提升了其在不同应用场景中的可扩展性和适应性。

Conclusion: 
本文展示了COIN在风险控制、保留可接受答案方面的稳健性和强大的测试时间效能，并在多种文本生成任务中验证了其预测效率。无论是一般性还是多模态文本生成任务，都证明了COIN的有效性。进一步通过使用替代的上界构造和不确定性量化策略，还展示了COIN的额外效能，这突显了其在不同应用情景中的灵活性和适用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20178</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>451. cs.CL-捷克语句子嵌入的内在与外在评估：语义相关性并不帮助机器翻译评估</title><link>https://arxiv.org/pdf/2506.20203</link><description>Background: 
本文探讨了通过内在和外在评估方法比较捷克语特有和多语言句子嵌入模型。内在评估使用Costra复杂句子转换数据集和语义文本相似性（STS）基准，评估嵌入捕捉语言现象如语义相似性、时间方面和风格变化的能力。外在评估则通过基于COMET的机器翻译评估指标对每个嵌入模型进行微调。

Innovation: 
研究发现，擅长内在语义相似性测试的模型并不总是能在下游翻译评估任务中表现得更好。相反，表面上过度平滑的嵌入空间在经过微调后可以取得优异的结果。这表明语义属性探查与下游任务之间的关系是复杂的，强调了对“操作化语义”以及更深入的下游任务数据集（如翻译评估）的研究需求。

Conclusion: 
研究揭示，语义蕴含特性与下游任务之间的关系并不简单，一些在语义相似性测试中表现良好的模型在实际机器翻译评估任务中未必能保持优异表现。此外，有些表面上看起来表现差的模型经过微调后反而可以表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20203</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>452. cs.CL-结合时空模型和大语言模型的模块化多任务推理框架</title><link>https://arxiv.org/pdf/2506.20073</link><description>Background: 
时空数据挖掘在不同领域的决策制定中发挥着关键作用。然而，现有的模型通常局限于特定任务，缺乏进行多任务推理和复杂长期推理的能力，这些能力需要生成深入的、解释性的输出。这些限制限制了它们在多方面真实世界决策场景中的应用。

Innovation: 
本文提出了STReason，这是一种新型框架，将大语言模型（LLMs）的推理优势与时空模型的分析能力结合，实现多任务推理和执行。无需特定任务微调，STReason利用上下文学习将复杂自然语言查询分解为可模块化、可解释的程序，然后系统执行以生成解决方案和详细的理由。此外，我们构建了一个新的基准数据集，并提出了一个统一的评估框架，具体为长时间序列推理设计了评估指标。实验结果表明，STReason在所有度量标准上都显著优于高级LLM基线，特别是在复杂的，推理密集的时空场景中更加出色。

Conclusion: 
人类评估进一步验证了STReason的可信度和实用性，展示了其减少专家工作量并扩大到实际时空任务的应用潜力。我们认为STReason为开发更强大和通用的时空推理系统提供了前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20073</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>453. cs.CL-SEED: 结构编码器在大语言模型辅助时间序列预测中的嵌入驱动解码</title><link>https://arxiv.org/pdf/2506.20167</link><description>Background: 
时间序列预测需要模型同时捕捉变量间的结构依赖性和跨任务的一般性。虽然结构编码器适用于特征交互建模，但在支持语义级推理或任务适应性方面能力有限。相比之下，大语言模型虽然具有强大的泛化能力，但尚未解决原始时间序列输入的问题。这一局限性阻碍了统一且具有迁移性的预测系统的开发。因此，本文提出SEED，一种用于嵌入驱动解码的结构编码器，其包含四个阶段：基于token感知的编码器进行块提取，投射模块将块与语言模型嵌入对齐，语义再编程机制将块映射到任务感知的原型，以及一个冻结的语言模型用于预测。这种模块化架构将表示学习与推理分离，实现数值模式与语义推理之间的高效对齐。在多种数据集上的实验结果表明，所提出的方法在强基线表现上取得了一致改进，并且对比研究进一步证实了SEED在解决结构-语义建模差距中的作用。

Innovation: 
提出SEED，一种用于嵌入驱动解码的结构编码器，包含四个阶段：基于token感知的编码器进行块提取，投射模块将块与语言模型嵌入对齐，语义再编程机制将块映射到任务感知的原型，以及一个冻结的语言模型用于预测。这种模块化架构将表示学习与推理分离，实现数值模式与语义推理之间的高效对齐，从而解决结构-语义建模差距。

Conclusion: 
所提出的方法在强基线表现上取得了一致改进，并且对比研究进一步证实了SEED在解决结构-语义建模差距中的作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20167</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>454. cs.CL-如何在使用大型语言模型改进对话情感识别的过程中检索示例</title><link>https://arxiv.org/pdf/2506.20199</link><description>Background: 
大型语言模型（LLMs）在多个领域中已广泛应用于各种实际场景。然而，对于情感识别等主观任务，创建高准确度的高性能应用仍然充满挑战。在此背景下，受SLT 2024 GenSER挑战赛的启发，本文探讨了通过在上下文学习（ICL）中检索高质量示例来提高对话情感识别（CER）的方法。具体而言，作者研究了基于随机和增强示例检索的不同策略，并分析了对话上下文对CER准确度的影响。实验在IEMOCAP、MELD和EmoryNLP三个数据集上进行。结果显示，增强示例检索在所有数据集上均比所研究的其他技术更优，强调了检索相关一致示例并通过改写增强的重要性。

Innovation: 
本文提出了一系列基于随机和增强示例检索的策略，特别是在上下文学习（ICL）中，这些策略用于提升对话情感识别（CER）的准确性。研究还分析了对话上下文对CER准确度的影响，并通过实验验证了增强示例检索方法的有效性，指出这种方法在所有数据集上的优越性

Conclusion: 
实验结果显示，增强示例检索方法在所有数据集上均比其他技术更优，强调了检索相关一致示例并通过改写增强的重要性。这表明增强示例检索是提高对话情感识别准确性的有效方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20199</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>455. cs.CL-CCR斯：一种零样本的LLM作为裁判的框架，用于全面的RAG评估</title><link>https://arxiv.org/pdf/2506.20128</link><description>Background: 
RAG系统通过整合外部知识来增强LLM，这对于需要事实准确性和最新信息的领域至关重要。然而，评估RAG输出的多方面质量，包括上下文连贯性、查询相关性、事实正确性和信息完整性等方面，存在显著挑战。现有的评估方法通常依赖于简单的词法重叠度量，这些度量无法捕捉这些细微差别，或者涉及复杂的多阶段管道，需要中间步骤如声明提取或需要微调专门的法官模型，这阻碍了实际效率。

Innovation: 
我们提出了CCR斯（Contextual Coherence and Relevance Score），这是一种新颖的由单一强大预训练LLM作为零样本、端到端裁判的度量体系。CCR斯评估：上下文连贯性（CC）、问题相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回率（IR）。我们将CCR斯应用于评估六个不同的RAG系统配置对具有挑战性的BioASQ数据集。分析表明，CCR斯有效地区分了各种系统的表现，例如，证实Mistral-7B阅读器优于Llama变体。我们详细分析了CCR斯度量属性，包括分数分布、收敛/区分有效性、发散率、人口统计学和区分能力。相比复杂的RAGChecker框架，CCR斯在关键方面如召回率和诚信度方面提供了可比或更强大的区分能力，同时计算效率显著更高。

Conclusion: 
CCR斯提供了一种实用、全面和高效的框架，用于评估和迭代改进RAG系统。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20128</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>456. cs.CL-利用AI评分机进行缺失分数插补以实现构造性反应测试中的精确能力估计</title><link>https://arxiv.org/pdf/2506.20119</link><description>Background: 
在教育领域评估学习者的能力是一项基本目标。特别地，评估复杂的高阶能力，如表达能力和逻辑思维能力需求增加。传统的构造性反应测试方法，如选择题和短答题，被广泛使用以满足这一需求，但这些方法需要大量人工评分，导致工作量大且成本高。项目反应理论（IRT）提供了一种新的解决方案，可以通过人工评分员仅评分部分答题，来估计学习者的总体能力，但这依赖于完整评分数据的准确性，随着缺失分数比例的增大，能力估计的准确性会下降。尽管存在数据插补技术来解决这一问题，但它们往往难以在数据稀疏或异质的情况下保证插补的准确性。

Innovation: 
为了克服这些挑战，该研究提出了一种利用自动评分技术进行缺失分数插补的创新方法，以实现基于IRT的能力估计。该方法不仅在能力估计准确性上表现优异，还能大幅减少人工评分的工作量。

Conclusion: 
通过利用自动评分技术，该研究提出的方法能够在保持准确能力估计的同时，显著减少人工评分的劳动成本，为构造性反应测试中的能力评估提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20119</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>457. cs.CL-一种空间-时间点过程模型用于阅读行为的精细建模</title><link>https://arxiv.org/pdf/2506.19999</link><description>Background: 
阅读过程是在空间和时间上展开的，包括读者的目光固定在特定位置和快速转移到新位置的过程。现有模型倾向于使用聚合的眼动追踪数据和强假设模型，忽视了很多重要的时空动态变化。本研究致力于提出一种更为通用的时空点过程模型，捕捉目光停留的位置、时间及其持续时间的动态变化，以更好地理解读句处理过程中的在线认知。

Innovation: 
研究者提出了一种基于标记时空点过程的新颖概率模型，该模型不仅能够描述固定的时长，还能精确捕捉固定的位置和时间。通过Hawkes过程模型刻画跳变过程，该模型能够捕捉到每一次固定如何激发接近的时间和空间内的下一次固定的概率。此外，固定事件的持续时间通过固定特定预测因子的时间卷积进行建模，以捕捉溢出效应。证明该Hawkes过程模型比基准模型更符合人类的跳变模式。关于固定持续时间，研究发现将情境惊奇作为预测因子仅带来轻微的准确度提高，这表明惊奇理论难以解释微细的眼动行为

Conclusion: 
该研究提出的方法改进了传统的建模方法，能够更精细地捕捉阅读过程中的时空动态变化。Hawkes过程模型在拟合人类跳变方面表现更好，但情境惊奇对模型预测精度的提升有限，提示惊奇理论在解释细粒度眼动行为方面的局限性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19999</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>458. cs.CL-连接组合语义和分布语义：通过自动编码器视角审视潜在语义几何</title><link>https://arxiv.org/pdf/2506.20083</link><description>Background: 
当前的分布式语义空间可以通过结合组合语义和符号语义来增强Transformer基自回归语言模型的可解释性、可控性、组合性和泛化能力。本文通过自动编码器视角对潜在空间几何进行审视，为连接符号和分布式语义提供了新的视角，并讨论了主要的自动编码器架构：变分自动编码器（VAE）、向量量化变分自动编码器（VQVAE）和稀疏自动编码器（SAE），以及它们在语义结构和可解释性上的差异所诱导的独特潜在几何形状。

Innovation: 
本文提出了一个新的视角，通过自动编码器审视潜在空间几何，以连接组合语义和分布式语义，并比较了三种主流的自动编码器架构，探讨了它们在语义结构和可解释性方面的影响。这种方法有助于弥合符号语义和分布式语义之间的差距。

Conclusion: 
本文回顾了潜在语义几何的自动编码器架构，并分析了这些架构在处理语义结构和提高解释性方面的作用，为连接和整合分布式与组合语义提供了一种新的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20083</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>459. cs.CL-Doc2Agent：根据API文档实现可扩展性的工具使用代理生成</title><link>https://arxiv.org/pdf/2506.19998</link><description>Background: 
REST API 在丰富网页代理的操作空间方面发挥着重要作用，但是大多数基于API的代理依赖于经过精心策划且统一的工具集，这些工具集并不反映真实世界API的复杂性。在任意领域建立工具使用代理仍然是一个重大挑战，因为这需要阅读未结构化的API文档、测试API以及推断正确的参数。

Innovation: 
提出了一种可扩展的Doc2Agent管道，用于从API文档生成可以调用Python工具的代理。Doc2Agent从API文档生成可执行工具，并通过代码代理逐步改进这些工具。评估方法包括使用真实世界的API、WebArena API和研究API，产生了验证工具。在WebArena基准测试中，Doc2Agent与直接调用API相比，实现了55％的相对性能提升，成本降低了90％。针对糖材料科学领域构建的特定领域代理进一步展示了管道在复杂、知识密集任务中的适应性。Doc2Agent提供了一种可扩展解决方案，用于从非结构化API文档生成工具代理。

Conclusion: 
Doc2Agent为构建大规模非结构化API文档的工具代理提供了一种通用解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19998</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>460. cs.CL-多步骤大语言模型框架用于精确且高效的放射学报告错误检测</title><link>https://arxiv.org/pdf/2506.20112</link><description>Background: 
大语言模型（LLM）基于的放射学报告校对的阳性预测价值（PPV）受限于错误发生的低频率，导致其准确性不高。这项研究旨在评估三步骤的LLM框架是否能提高PPV，并降低成本，相比基线方法而言。

Innovation: 
研究测试了三种不同的LLM框架：单一提示检测器，提取器加检测器，以及包含提取器、检测器和假阳性验证器的三步骤框架，并通过测量精确度（PPV和绝对真实阳性率aTPR）和效率来评估其性能。研究发现，三步骤框架显著提高了PPV，同时降低了每1000份报告的人工审查费用。

Conclusion: 
三步骤的LLM框架显著提升了PPV，并减少了运营成本，同时保持了检测性能，为AI辅助的放射学报告质量保证提供了一种有效策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20112</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>461. cs.CL-SACL：通过语义增强重排序和定位来理解并对抗代码检索中的文本偏见</title><link>https://arxiv.org/pdf/2506.20081</link><description>Background: 
代码检索是提高代码生成的关键技术，当前的代码检索器主要依赖于表面级别的文本特征（如文档字符串，标识符名称）。然而，它们往往偏向于那些文档良好的代码，即使文档质量低。这对于提高代码生成性能至关重要，因为代码检索的准确性直接影响到代码生成的结果。

Innovation: 
提出了SACL框架，通过添加语义信息来丰富文本信息并减少偏见，从而增强代码检索。与现有方法相比，SACL显著提高了代码检索性能（例如，在HumanEval、MBPP、SWE-Bench-Lite上的Recall@1分别提高了12.8%/9.4%/7.0%），并改善了代码生成的表现（例如，在HumanEval上Pass@1提高了4.88%）。

Conclusion: 
SACL通过语义增强的重排序和定位，能够更准确地理解代码并减少偏见，从而提高了代码检索和代码生成的质量。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20081</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>462. cs.AI-AnchorDP3: 3D-Yuǎn-Anzhun Huà-Fù Zǐrén Xùànshì Wèi Quán Dài-Zhǐ Chéng-Féng Wèi Chǐ de Jíóuxiàn Chānxùan Zhèngzhí Wèntí</title><link>https://arxiv.org/pdf/2506.19269</link><description>Background: 
该论文介绍了AnchorDP3，这是一种用于双臂机器人操作的扩散策略框架，它在高度随机化环境中实现了最先进的性能。训练数据采用了大规模、程序生成的仿真数据，证明了其在多元操作任务下的高效性和可靠性，特别是在物体、杂物、桌子高度、照明和背景高度随机化的情况下也能保持高成功率。论文框架结合了RoboTwin的真实到仿真管道，理论上可以仅通过场景和指令来自主生成执行性强的视觉运动策略，完全无需人类示范来学习操作技能。背景强调了在实际操作环境中的随机性和挑战性，突显了该框架在复杂环境下的稳健性与适应性。

Innovation: 
该框架融合了三项关键创新：(1) 使用渲染的真实 ground truth 实现模拟器监督语义分割，明确地在点云中分割任务关键物体，提供强烈的利用前及相关信息；(2) 任务条件特征编码器，轻量级模块处理每个任务的增强点云，通过共享的基于扩散的动作专家实现高效的多任务学习；(3) 动作锚点扩散与全状态监督的可用性锚定关键姿态，使用稀疏、几何上有意义的动作锚点替换密集轨迹预测，有效地简化了预测空间；通过同时预测机器人关节角度和末端执行器姿态来强制动作专家预测，充分利用几何一致性来加速收敛并提升精度。

Conclusion: 
通过大规模仿真训练，AnchorDP3 在 RoboTwin 测试基准上实现了 98.7% 的平均成功率，涵盖多种任务，并且在物体、杂物、桌子高度、光线和背景高度高度随机化的情况下也能保持高成功率。该框架与 RoboTwin 真实到仿真的管道集成，有望实现仅由场景和指令生成部署可用的视觉运动策略的全过程，完全排除了人类示范的学习障碍来掌握操作技能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19269</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>463. cs.CL-Inference Scaled GraphRAG: 提升知识图谱中多跳问答的推理比例图RAG</title><link>https://arxiv.org/pdf/2506.19967</link><description>Background: 
大型语言模型（LLMs）已经在语言理解和生成方面取得了显著成效，但仍然在知识密集型推理任务上表现不佳，特别是在获得结构化上下文和多跳信息方面存在限制。检索增强生成（RAG）部分缓解了这个问题，使其生成基于一体检索的上下文，但传统的RAG和GraphRAG方法往往无法捕捉知识图谱中的关系结构。该研究提出了Inference-Scaled GraphRAG，一种通过在推理时应用计算扩展来增强基于LLM的图推理的新框架。该方法结合了顺序扩展和深度链式推理图遍历，以及并行扩展和在交替推理执行循环中采样轨迹上的多数投票。在GRBench基准测试上的实验表明，该方法显著提升了多跳问答性能，比传统GraphRAG和先前的图遍历基线方法取得了显著的提升。这些发现表明，推理时的扩展是结构化知识推理的实践和架构无关的可行解决方案

Innovation: 
Inference-Scaled GraphRAG通过在推理时应用计算扩展来增强基于LLM的图推理，结合顺序扩展与深度链式推理图遍历，以及并行扩展与在交替推理执行循环中采样轨迹上的多数投票。实验结果显示，这种方法在多跳问答上取得了显著性能提升，优于传统GraphRAG和其他图遍历基线方法

Conclusion: 
Inference-Scaled GraphRAG是一种有效提升LLM在知识图谱上处理多跳问答性能的方法，表明推理时扩展是结构化知识推理的及时且架构无关的解决方案</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19967</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>464. cs.CL-CycleDistill：使用循环蒸馏的大型语言模型-bootstrap 机器翻译</title><link>https://arxiv.org/pdf/2506.19952</link><description>Background: 
大型语言模型（LLMs）尽管能够进行少样本机器翻译（MT），但在高质量机器翻译方面仍落后于专门为平行语料库训练的专用MT系统。然而，对于低资源语言，平行语料库往往稀缺或不存在。本研究旨在通过利用LLMs和少样本翻译，逐步建立高质量的MT系统，解决这一问题。CycleDistill通过从单语语料库生成合成平行语料库，迭代地进行少量样本翻译，进而依赖这些合成数据精细调整用于生成翻译的模型，从而不需要超出1至4个少量样本的平行语料库，即可实现高质机器翻译，尤其在对印度语进行的实验证明了这一点。此外，研究还探讨了在蒸馏过程期间利用softmax激活的影响，观察到了翻译质量的微妙提升。

Innovation: 
提出了一种名为CycleDistill的端到端的自提升方法，利用LLMs和少样本翻译，迭代自动生成合成平行语料库，并通过此项合成数据进一步调优模型，从而能够仅依赖少量样本进行高质量翻译，极大地降低了对平行语料库的依赖。此外，研究还验证了softmax激活在蒸馏过程中的积极作用。

Conclusion: 
CycleDistill通过利用少样本翻译和少量平行语料库，能够实现高质量的机器翻译，尤其在低资源语言上展现了显著效果。此外，研究还验证了softmax激活在循环蒸馏过程中的轻微改进作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19952</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>465. cs.AI-莫尔斯：用于扩散模型加速的双重采样</title><link>https://arxiv.org/pdf/2506.18251</link><description>Background: 
本文介绍了一种名为Morse的简单双重采样框架，用于加速扩散模型的损失less（即无损失）加速。该框架重新构思了从噪声生成数据的过程，利用了快速跳跃采样和自适应残差反馈策略。Morse包含两个模型：Dash和Dot，两者相互作用。Dash模型是任何类型的预训练扩散模型，但在跳跃采样阶段运行，提高采样效率。Dot模型比Dash模型更快，它在Dash模型轨迹上的当前跳跃采样点上通过条件生成残差反馈来提升噪声估计，使其易于匹配Dash模型的下一次估计，而无需跳跃采样。通过交替运行Dash和Dot模型并串联其输出，Morse在保持所需图像生成性能的同时提高了整体运行时效率。通过提议的Dash和Dot模型之间的权重共享策略，Morse在训练和推断时都是高效的。实验表明，与9个基准扩散模型在6种图像生成任务上相比，平均可以实现1.78倍到3.31倍的无损失加速。此外，本文还展示该方法可以进一步拓展应用于LCEM-SDXL（一种已通过一致性蒸馏技术加速的少数步骤文本图像合成模型）。

Innovation: 
Morse框架创新地通过双重采样策略加速扩散模型，结合了快速跳跃采样和自适应残差反馈两种策略。该框架的核心在于引入了两个交互的模型Dash和Dot，其中Dash模型在跳跃采样模式下工作，Dot模型则提供快速的残差反馈，从而实现图像生成的加速。此外，该方法还提出了权重共享策略，使得训练和推理过程更加高效，并且能够在多种图像生成任务中实现显著的加速效果。

Conclusion: 
Morse框架展示了在其提供的多种图像生成任务中与其他9个基准扩散模型相比，平均实现1.78倍到3.31倍的无损失加速效果。此外，Morse框架还可以应用于已经通过一致性蒸馏技术加速的LCEM-SDXL模型，进一步提升少数步骤的文本图像合成性能。该方法已在训练和推理中表现出高效性，并提供代码和模型供进一步研究使用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18251</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>466. cs.AI-无免费午餐：重思LLM推理的内部反馈</title><link>https://arxiv.org/pdf/2506.17219</link><description>Background: 
强化学习已经成为了提升大型语言模型（LLMs）推理能力的强有力范式。诸如从人类反馈的强化学习（RLHF）和具有验证奖励的强化学习（RLVR）的方法展示出了显著的效果，但这些方法需要大量的外部监督。研究团队探索了一种新的方法，即仅依赖于模型自身的信号进行内部反馈的强化学习方法（RLIF），而非外部奖励。研究团队利用了如令牌级熵、轨迹级熵、自我确定性等无监督的奖励代理来改进模型内在目标。理论分析表明这些内部目标部分等价，并在复杂的数学推理基准上评估了不同的RLIF策略，实验结果证明了在训练初期内部反馈可以提升基础LLM的推理性能，甚至可以与RLVR技术持平或超越。然而，随着训练的进展，模型性能会下降甚至低于未训练时的表现。研究团队还发现，对于指令调优的模型，内部反馈的提升效果有限，表明调优后的LLM内部反馈的效果在逐步减少。进一步分析了这种局限性，结合模型权重的混合，解释了内部反馈在训练过程中行为的原因，提供了集成内部反馈信号到LLM训练中的实用指南。这些分析希望能够为LLM的后续训练提供更科学和有效的方法指引。

Innovation: 
提出并研究了一种新的强化学习方法——内部反馈强化学习（RLIF），这种方法完全依赖于来自模型自身的信号而非外部奖励。研究团队探索了令牌级熵、轨迹级熵、自我确定性等无监督的奖励代理，并发现这些内部目标部分等价。研究团队在复杂的数学推理基准上评估了不同的RLIF策略，实验结果显示，内部反馈可以在模型训练初期显著提升推理性能，绩效可以与具有验证奖励的强化学习（RLVR）技术持平或超越，但随着训练的推进，模型的性能会下降甚至低于未训练时的表现。这种研究方法为LLM的后续训练提供了一种替代的强化学习方案，并优化了内部反馈信号的质量和效率。

Conclusion: 
在模型训练的初期，内部反馈策略（RLIF）能够显著提升基础LLM的推理性能，与具有验证奖励的强化学习技术（RLVR）相媲美或超越。但随着训练的推进，模型性能会下降甚至低于未训练前的表现。对于指令调优的模型，内部反馈的提升效果有限，表明内部反馈的回报在模型调优后会减少。研究进一步分析了这种局限性，通过混合模型权重解释了内部反馈在训练过程中的行为，提出了进行internal feedback信号集成的实用指引。研究建议未来的研究应更加关注如何在有限训练样本下提升内生信号的效果，从而改进LLM的推理能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17219</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>467. cs.AI-量子-经典混合量化神经网络</title><link>https://arxiv.org/pdf/2506.18240</link><description>Background: 
本文研究了如何通过将量子计算与经典计算相结合来训练量化神经网络，特别关注于量化神经网络在使用任意激活和损失函数时的挑战。传统的神经网络激活函数通常是连续非线性的，而在量子计算中直接处理这些非线性函数是具有挑战性的。为此，作者提出了一种新的二次二元优化（QBO，Quadratic Binary Optimization）模型，通过样条插值技术实现了任意激活和损失函数的应用。此外，为了应对多层复合结构中的非线性问题，作者提出了前向区间传播（FIP，Forward Interval Propagation）方法，该方法通过将激活函数离散化成线性子区间，解决了线性化和非线性优化的问题，并保持了神经网络的通用逼近特性。然而，将该模型应用于实际问题时，需要解决大规模问题的二次约束二元优化（QCBO，Quadratic Constrained Binary Optimization）模型的挑战，特别是处理大量约束以及相应的超参数调优问题，这大大增加了计算复杂性。

Innovation: 
本文的创新之处在于提出了一种新的量子-经典混合方法来解决量化神经网络训练中的非线性问题，通过QBO模型和FIP方法，使复杂非线性函数的优化成为可能。此外，该研究还提出了一种基于量子计算的量子条件梯度下降（QCGD，Quantum Conditional Gradient Descent）算法来直接解决QCBO问题，并提供了相关理论证明和实验结果。

Conclusion: 
实验结果表明，在使用相干Ising机（CIM，Coherent Ising Machine）进行的模型训练中，模型在Fashion MNIST分类任务上的准确性达到了94.95%。这证明了基于量子-经典混合量化神经网络模型的有效性和适用性。同时，该研究也指出了方法的局限性和未来工作方向，如进一步优化方法以简化超参数调整并减少计算复杂性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18240</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>468. cs.AI-量化LLMs公平性超越标记符：语义与统计视角</title><link>https://arxiv.org/pdf/2506.19028</link><description>Background: 
大型语言模型（LLMs）常生成含有内在偏见的回应，这影响了它们在实际应用中的可靠性。现有的评估方法往往忽视了长格式回应中的偏见以及LLMs输出的固有变化性。为解决上述问题，论文提出了一种名为FiSCo（细粒度语义计算）的新颖统计框架，该框架通过检测不同群体之间长格式回应中的微妙语义差异来评价LLMs的分组公平性。相比之下，之前的许多研究多集中于情感或标记级的比较，而FiSCo能够超越表面分析，通过论点层级的操作并利用蕴涵检查评估回应间意义的一致性。通过这种方法，论文将模型输出分解为语义上不同的论点，并运用统计假设检验来比较组间和组内的相似性，从而实现对细微偏见的稳健检测。作者进一步提出了一个新的群体反事实公平性定义，并在涵盖性别、种族和年龄的合成与人工标注数据集上验证了FiSCo。实验结果表明，FiSCo能够更可靠地识别出细微的偏见，同时减少了随机性对LLMs评估结果的影响，相较于其它评估标准更为优越。

Innovation: 
提出了一种名为FiSCo的新颖统计框架，该框架能评价LLMs的分组公平性，通过检测长格式回应中的微妙语义差异。这一方法超越了表面的分析，利用论点层级的操作和蕴涵检查来评估回应间的意义一致性，同时将模型输出分解为语义不同的论点，并运用统计假设检验进行比较，从而实现对细微偏见的稳健检测。进一步提出了群体反事实公平性定义，并在多种数据集上验证了FiSCo的有效性。试验结果表明，FiSCo能更可靠地识别出细微偏见，减少了随机影响。

Conclusion: 
FiSCo能更稳健地检测到细微偏见，减少随机性影响，并优于多种评估标准。该方法提供了一种新的视角来评价LLMs的公平性，有助于改进模型在实际应用中的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19028</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>469. cs.AI-Thought Anchors: Which LLM Reasoning Steps Matter？</title><link>https://arxiv.org/pdf/2506.19143</link><description>Background: 
大型语言模型近年来在多个领域取得了最先进的性能。然而，长形式的推理链需要解析每个生成的词都依赖于所有前面的词，这使得推理过程难以分解，增加了可解释性的挑战。本文提出了一种在句子层面分析推理轨迹的方法，有助于理解推理过程。作者认为，可解释性问题可以通过在句子层面来解决，指出在推理过程中存在对后续推理过程影响显著且比其他句子更重要的推理步骤（即‘思考锚点’）.

Innovation: 
本文提出了三种评估和识别‘思考锚点’的方法：一种是通过对比生成相同或不同含义句子的100轮推理结果的最终答案来间接衡量句子的重要性；另一种是通过聚合句子对之间的注意力模式，识别出那些在所有之后的句子中接收到不成比例关注的‘广播’句子；第三种是以因果关系为基础，通过抑制某个句子的注意力并观察其对后续句子结果的效应。这些方法提供了关于思想锚点存在的证据，即那些对后续推理过程影响较大的推理步骤，通常是计划或反弹的句子.

Conclusion: 
作者提供了开源工具以可视化这些方法的输出，并展示了如何通过这些方法来理解模型的多步骤推理。不同方法结果的一致性证明了句子层面分析对于更深入地理解推理模型有潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19143</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>470. cs.AI-PP-DocBee2：高效数据增强的多模态文档理解改进基准</title><link>https://arxiv.org/pdf/2506.18023</link><description>Background: 
PP-DocBee2是PP-DocBee的先进版本，旨在增强多模态文档的理解能力。它基于大型多模态模型架构，并通过关键的技术改进来解决问题，如增强合成数据质量、改进视觉特征融合策略和优化推理方法。这些改进使得在内部基准测试中对于中文商业文档的性能提升了11.4%，并将推理延迟降低了73.0%至基线版本。这个工作的一个关键创新是多模态文档任务中的数据质量优化策略，通过大规模多模态预训练模型来评估数据，并应用新的统计准则来过滤异常值，确保高质量的训练数据。此外，通过利用多模态模型中未充分利用的中间特征来进行增强维视图表征容量，并应用一种新的特征融合策略来改进复杂推理。

Innovation: 
1. 大规模多模态预训练模型的数据质量优化策略，通过统计准则过滤异常值，确保高质量训练数据。n2. 改进的维视图图表示能力，通过分解维视图并应用新的特征融合策略来提高复杂推理的性能。n3. 通过优化合成数据质量和改进的推理方法，显著提高了性能并减少了推理延迟。

Conclusion: 
PP-DocBee2通过关键的技术改进和创新的数据优化策略，在多模态文档理解领域取得了显著的性能提升，并通过公开源代码和预训练模型促进了该领域的进一步研究和发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18023</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>471. cs.AI-OmniGen2：探索高级多模态生成</title><link>https://arxiv.org/pdf/2506.18871</link><description>Background: 
OmniGen2 是一个多功能且开源的生成模型，旨在提供多种生成任务的统一解决方案，包括文本到图像、图像编辑和上下文生成。它与前一代 OmniGen v1 相比，具有两个不同的解码路径，分别用于文本和图像模态，并且不共享参数，使用了独立的图像分词器。这一设计使得 OmniGen2 能够在不重新适应 VAE 输入的情况下建立在现有的多模态理解模型之上，从而保持原有的文本生成能力。为了训练 OmniGen2，作者开发了一套全面的数据构建管道，涵盖了图像编辑和上下文生成数据。此外，还引入了一种针对图像生成任务的反照机制，并基于 OmniGen2 创建了一个专用的反照数据集。尽管参数规模相对较小，OmniGen2 在多个任务基准测试中取得了竞争性的结果，包括文本到图像和图像编辑。此外，为了进一步评估上下文生成（也称为主题驱动任务），作者引入了一个名为 OmniContext 的新基准测试。

Innovation: 
OmniGen2 引入了两个独立的解码路径，为文本和图像模态提供服务，不共享参数，并使用独立的图像分词器。这使得模型能够不再需要转换 VAE 输入的情况下，建立在现有的多模态理解模型之上。此外，作者还开发了数据构建管道、反照机制和专门的数据集，并在多个领域实现了竞争性结果。引入的新基准测试（OmniContext）用于评估上下文生成能力。

Conclusion: 
尽管参数相对有限，OmniGen2 仍能实现多个任务（如文本到图像和图像编辑）上的竞争性结果。在其基础上，提出了一个新的基准测试 OmniContext 专门用于评估上下文生成能力，并展示了其在开源模型中的领先一致性性能。为了帮助未来的研究，作者将发布模型、训练代码、数据集和数据构建管道。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18871</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>472. cs.AI-非平衡等温伴随采样器</title><link>https://arxiv.org/pdf/2506.18165</link><description>Background: 
近年来，基于学习的扩散采样器取得了显著的进展，它们旨在从给定的非正规化密度中采样。这些方法通常遵循两种范式之一：（i）利用标准参考过程将采样公式化为无偏随机最优控制问题（SOC问题），或（ii）通过重要性加权采样精确诊义退火路径措施。退火方法在引导样本向高密度区域移动方面具有优势，但依赖重要性抽样导致实际中高方差和有限的可扩展性。

Innovation: 
本文介绍了一种新颖的基于SOC的扩散采样器——非平衡等温伴随采样器（NAAS），该采样器利用退火参考动力学而不依赖于重要性抽样。NAAS 利用灵感来自于伴随匹配的轻量化伴随系统，以实现高效和可扩展的训练。

Conclusion: 
我们的方法在一系列任务中显示出有效性，包括从经典能量景观和分子玻尔兹曼分布中采样。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18165</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>473. cs.AI-Confucius3-Math: 一个轻量级高性能的中文K-12数学推理大语言模型</title><link>https://arxiv.org/pdf/2506.18330</link><description>Background: 
介绍了Confucius3-Math，这是一个开源的大语言模型，拥有140亿参数，能够在单块消费级显卡上高效运行；在一系列数学推理任务中表现出色，超过了众多规模更大的模型。该模型旨在通过AI提升教育资源和知识传播，在满足国家级课程要求的同时，以较低的成本解决主流的中文K-12数学问题。

Innovation: 
开发了三项技术创新：目标熵正则化、最近样本恢复和政策特定难度加权。这些创新包括新的熵正则化、新颖的数据调度策略以及改进的群体相对优势估计算法。这些创新共同显著稳定了强化学习训练、提高了数据效率并提升了模型性能。

Conclusion: 
这项研究证明了可以在特定领域以较低成本构建强大的推理模型。该模型和代码已开源。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18330</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>474. cs.AI-CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation</title><link>https://arxiv.org/pdf/2506.15549</link><description>Background: 
深度学习在基于延迟钆增强（LGE）心脏MRI的心肌疤痕分割中展示了巨大的潜力，对于结构性心脏疾病的准确和及时诊断与治疗规划具有重要意义。然而，高质量的心肌疤痕标签有限且LGE图像的可变性限制了稳健分割模型的发展。针对这一问题，我们引入了CLAIM框架：一种基于临床指导的心脏延迟钆增强图像的心肌疤痕合成与分割框架，用于解剖基础上的心肌疤痕生成和分割。

Innovation: 
 CLAIM的核心是SMILE模块（疤痕掩码生成受临床知识指导），该模块基于临床采用的心脏协会（AHA）17区模型条件化了基于扩散的生成器，以合成具有解剖一致性且空间上多样化的疤痕模式图像。此外，CLAIM采用联合训练策略，在训练过程中同时优化疤痕分割网络和生成器，以提高合成疤痕的逼真度和疤痕分割的准确性。该方法能够生成解剖上协调的疤痕模式，并在真实心肌疤痕分布的Dice相似度上优于基线模型。

Conclusion: 
我们的方法使得心肌疤痕的生成和分割可控且真实，并在后续医学影像任务中具有应用价值。代码已公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15549</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>475. cs.AI-使用KnoVo映射研究贡献的演变</title><link>https://arxiv.org/pdf/2506.17508</link><description>Background: 
传统引文分析主要衡量论文的影响，但无法准确评估其新颖性。KnoVo框架旨在解决这一问题，通过分析多层引文网络中论文与先驱和后续作品的相对新颖性，实现了对研究新颖性的量化和分析。

Innovation: 
KnoVo不仅利用大型语言模型（LLMs）动态提取比较维度（如方法、应用、数据集），而且通过类似淘汰赛选择的方法进行比较分析，给出在特定方面相对改进、平等或较差的新颖性分数。通过综合这些分数并动态展示其演变过程，KnoVo为研究人员提供了评估原创性、识别类似工作，并跟踪特定研究维度的知识演变，发现研究缺口，探索跨学科联系的能力。

Conclusion: 
通过对多个科学领域的20篇论文的详细分析，展示了KnoVo框架的功能和各种开源LLMs在KnoVo框架中的性能表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17508</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>476. cs.AI-TabArena: 用于表格数据机器学习的活标靶</title><link>https://arxiv.org/pdf/2506.16791</link><description>Background: 
随着深度学习和基础模型在表格数据中的流行，标准化和可靠的基准测试变得越来越重要。然而，当前的基准测试仍然是静态的，即使发现了错误、更新了模型版本或发布了新模型，其设计也不会更新。这促使该论文引入了TabArena，这是首个持续维护的动态表格基准测试系统。

Innovation: 
介绍了TabArena系统作为第一个持续维护的动态表格基准测试系统。该系统通过手动筛选具有代表性的数据集和实施良好的模型，以及大规模的基准测试研究，来启动和维持公开展示的排行榜。研究结果强调了验证方法和超参数配置的集成对标记模型性能的影响。此外，还观察到深度学习方法在更长的时间预算下赶上了梯度增强树，并且对于小规模数据集，基础模型表现出色。同时，展示了模型集成在表格机器学习中推动了最先进的技术水平，并探讨了各个模型的贡献。

Conclusion: 
通过公开展示的排行榜、可重复的代码和维护协议，启动了TabArena，使之成为一个可用的活标靶平台。这有助于推动表格数据机器学习领域的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16791</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>477. cs.AI-屏幕劫持：移动环境中VLM代理的视觉中毒</title><link>https://arxiv.org/pdf/2506.13205</link><description>Background: 
随着视觉-语言模型(VLMs)在移动代理中的广泛应用，这些代理被用于UI自动化和基于摄像头的用户辅助任务。然而，这些代理通常仅限于少量的用户生成数据集进行微调，这使得它们在训练过程中容易受到隐蔽威胁。本文介绍了一种名为GHOST的新攻击方法，这是第一个针对基于VLMs的移动代理的干净标签后门攻击。这种方法仅通过操纵部分训练样本的视觉输入，而不改变其对应标签或指令，注入恶意行为。

Innovation: 
该方法的核心在于通过调整有毒样本的梯度与选定目标实例的梯度，将后门相关信息嵌入有毒训练数据中。为保持隐蔽且增强鲁棒性，开发了三种实际的视觉触发器：静态视觉补丁、动态运动提示和低不透明度的细腻覆盖。这项研究覆盖了六个真实世界的Android应用程序和三个适应移动使用的VLM架构。结果表明，该攻击可实现高攻击成功率（最高94.67%），同时保持良好的干净任务性能（最高FSR 95.85%）。此外，消融研究揭示了各种设计选择如何影响攻击的有效性和隐蔽性。

Conclusion: 
这项工作首次揭示了VLM基础的移动代理的关键安全漏洞，强调了它们对清洁标签后门攻击的脆弱性，突显了在其训练管道中迫切需要有效的防御机制。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13205</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>478. cs.AI-VRAIL: Vectorized Reward-based Attribution for Interpretable Learning</title><link>https://arxiv.org/pdf/2506.16014</link><description>Background: 
该研究背景为强化学习（RL）领域中奖励函数的设计对学习效果有重要影响，但现有的RL方法在解释性方面较弱。为了解决这一问题，该研究提出了一种新的框架VRAIL，旨在提高RL的学习可解释性和稳定性。

Innovation: 
VRAIL框架通过引入两级架构，在深度学习阶段使用状态特征拟合估计的价值函数，并在强化学习阶段利用这种价值函数通过基于势的奖励转换来引导学习。此方法允许对单个特征及其交互的重要性进行归因，从而提高了学习的稳定性和收敛性，并揭示了意义明确的子目标，增强了学习结果的可解释性。

Conclusion: 
实验结果表明，VRAIL相比标准的DQN在学习稳定性和收敛性方面表现出改进，并且没有需要对环境进行修改。进一步的分析表明，VRAIL能够发现具有语义意义的子目标，这证明了其能够生成可由人类解释的行为。研究结果表明，VRAIL是一种适用于强化学习奖励塑造的一般化、模型无关框架，能够增强学习效果和可解释性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16014</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>479. cs.AI-通过注意力头选择进行细粒度的扰动引导</title><link>https://arxiv.org/pdf/2506.10978</link><description>Background: 
最近的扩散模型指导方法通过扰动模型来反向采样，构建一个隐式的弱模型并引导生成远离该模型。在这些方法中，注意力扰动在无条件场景中表现出强劲的实验性能，特别是在分类器自由的引导不可行的情况下。然而，现有的注意力扰动方法缺乏确定扰动应用于何处的原理方法，尤其是在计算质量相关的扩散转换器(DiT)架构中，这些计算分布在各层上。本文研究了注意力扰动的粒度，从层级一直到单个注意力头，并发现特定的头负责不同的视觉概念，如结构、风格和纹理质量。

Innovation: 
本文提出了‘HeadHunter’，这是一种系统框架，用于逐步选择与用户目标一致的注意力头，以实现对生成质量和视觉属性的细粒度控制。此外，引入了SoftPAG，这是一种线性插值每选定头部的注意力图向单位矩阵的方法，提供了连续的旋钮以调整扰动强度并抑制伪影。我们的方法不仅缓解了现有层级扰动的过度平滑问题，还通过组合头的选择实现了特定视图风格的有针对性处理。我们在现代大规模基于DiT的文本到图像模型上验证了该方法，包括Stable Diffusion 3和FLUX 1，展示了在通用质量提升和特定风格指导方面的优越性能。我们的工作第一次在扩散模型中提供了头级别的注意力扰动分析，揭示了注意力层内的可解释专业化，为有效的扰动策略的实用设计提供了依据。

Conclusion: 
本研究提供了扩散模型中第一个头级别的注意力扰动分析，揭示了注意力层内的可解释专业化，并且通过HeadHunter框架和SoftPAG方法增强了生成质量和视觉属性的可控性，为扩散模型生成应用提供了新的指导策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.10978</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>480. cs.AI-MS-TVNet:基于多尺度动态卷积的长期时间序列预测方法</title><link>https://arxiv.org/pdf/2506.17253</link><description>Background: 
长期时间序列预测主要依赖于Transformer和MLP模型，而卷积网络在这方面的潜力尚未得到充分挖掘。

Innovation: 
引入了一种新的多尺度时间序列重塑模块，能够有效捕获多周期块之间的关系和变量依赖性。在此基础上提出了MS-TVNet，这是一个基于多尺度3D动态卷积的神经网络。MS-TVNet在多种数据集上的全面评估中展示了优于基线模型的性能，达到了长期时间序列预测的最新技术水平。

Conclusion: 
研究结果表明，利用卷积网络捕获复杂的时序模式是有效的，为未来的相关研究指明了有希望的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17253</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>481. cs.AI-IKDiffuser：通过扩散模型为多臂机器人生成的生成逆运动学求解器</title><link>https://arxiv.org/pdf/2506.13087</link><description>Background: 
解决逆运动学（IK）问题在机器人学中是基础性的，但在多臂机器人系统中仍然具有挑战性。传统的IK求解器由于复杂的自我碰撞、耦合关节和高维冗余性而变得缓慢、容易失效且缺乏多样性。为此，该论文提出了一种基于扩散模型的IKDiffuser，以快速生成多臂机器人系统的逆运动学多解。

Innovation: 
IKDiffuser学习配置空间中的关节分布，捕捉复杂依赖关系，并支持在推理期间不重新训练的情况下集成额外目标，提供适应任务特定要求的灵活性和适应性。实验表明，IKDiffuser在多个多臂系统中提供了更高的解准确度、精确度、多样性和计算效率，为多臂逆运动学问题提供了可扩展的统一解决方案，促进多臂机器人实时操作任务的潜力。

Conclusion: 
IKDiffuser框架提供了一种可扩展且统一的方法来解决多臂IK问题，使得多臂机器人系统在实时操作任务中具有更高的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13087</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>482. cs.AI-Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning</title><link>https://arxiv.org/pdf/2506.07744</link><description>Background: 
现有的离线分层强化学习方法依赖高层策略学习来生成子目标序列。然而，随着任务时间周期的增加，这些方法的效率逐渐下降，且缺乏有效的策略来拼接不同轨迹中的有用状态转换。

Innovation: 
提出了一种新的框架Graph-Assisted Stitching (GAS)，将子目标选择问题转化为图搜索问题，而不是学习显式的高层策略。通过将状态嵌入到Temporally-Distant Representation (TDR)空间中，GAS将来自不同轨迹的语义相似状态聚合成统一的图节点，从而实现了高效的过渡拼接。同时引入了Temporally Efficient (TE)度量来过滤掉无用或效率低下的过渡状态，显著提升了任务性能。

Conclusion: 
GAS方法在行走、导航和操作任务中优于之前的离线HRL方法。特别是在最需要拼接的任务中，得分达到了88.3，大幅超越了之前的SOTA得分1.0。源代码可以在该链接中找到：this https URL.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07744</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>483. cs.AI-WoundAmbit：将最先进语义分割与实际伤口护理相结合</title><link>https://arxiv.org/pdf/2504.06185</link><description>Background: 
慢性伤口影响大量人群，尤其是老年人和糖尿病患者，他们通常活动受限且伴有多种健康问题。通过移动图像捕捉实现自动伤口监测，可以减少面对面医生访问，通过远程跟踪伤口大小来实现。语义分割是这一过程的关键步骤，但在医疗影像研究中，伤口分割仍然相对较少。

Innovation: 
本研究对通用视觉、医学影像和公开伤口挑战的最佳深度学习模型进行了基准测试。为确保公平比较，标准化了训练、数据增强和评估方法，并通过交叉验证减少了分区偏差。同时，评估了实际部署方面，如在未见过的伤口数据集上的泛化、计算效率和可解释性。还提出了一种基于参考对象的方法，将AI生成的掩码转换为具有临床意义的伤口大小估计，并对最受医生评估五个最佳模型的掩码质量进行了评估。Transformer 基础的 TransNeXt 在泛化性方面表现出最高水平。尽管推断时间有差异，但所有模型在CPU上每秒至少处理一张图像，被认为是足够高效。可解释性分析显示，激活主要出现在伤口区域，突出了临床相关特征。专家评估显示，所有分析模型的掩码批准率都很高，VWFormer和ConvNeXtS骨干表现最佳。伤口大小检索精度在各模型之间相似，预测结果与专家标注紧密匹配。最后，展示了如何将我们的人工智能驱动的伤口大小估计框架WoundAmbit集成到自定义远程医疗系统中。

Conclusion: 
总体而言，WoundAmbit框架展示了将最先进语义分割技术与实际伤口护理相结合的潜力，能够在远程医疗系统中实现精确和高效的伤口监测。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.06185</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>484. cs.AI-SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities</title><link>https://arxiv.org/pdf/2506.06406</link><description>Background: 
Mixture of Experts (MoE) 架构已成为大规模语言模型扩展的关键方法，人们对将其扩展到多模态任务也产生了极大兴趣。现有的构建多模态 MoE 模型的方法要么会导致高昂的训练成本，要么在适应预训练模型时会降低语言能力。

Innovation: 
本文提出了 Soft ModalityAware Routing (SMAR)，这是一种新颖的正则化技术，通过使用 Kullback Leibler 散度来控制不同模态路由概率分布，有助于专家领域细分，而无需修改模型架构或过度依赖文本数据。相比基准模型，SMAR 在仅使用 2.5% 纯文本的情况下，保留了 86.6% 的语言能力并表现出强大的多模态性能，为多模态 MoE 模型中平衡模态差异和语言能力提供了实用且高效的方法。

Conclusion: 
实验结果表明，SMAR 在保持高水平语言能力的同时，显示出强大的多模态性能，为解决多模态 MoE 模型中的模态差异与语言能力的平衡问题提供了有效的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.06406</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>485. cs.AI-回收网络：一种增强语言模型预训练数据质量和数量的方法</title><link>https://arxiv.org/pdf/2506.04689</link><description>Background: 
现有的大规模语言模型的性能随着模型大小和数据量的增加而提高，预训练依赖于大规模的网络爬取，几乎使用了所有公开的互联网数据。然而，可用的计算资源增长速度远快于自然数据池的增长速度，高质量文本数据的获取尤其有限。数据过滤管道通常会去除初始网络爬取数据的99%，以达到当前最先进的效果。本文研究了如何回收和再利用现有数据过滤过程中丢弃的数据，提出了一种名为REWIRE的方法，该方法可以丰富质量较低的文档，使它们能够用于训练。这种做法能够增加合成数据在最终预训练数据集中的比例。实验表明，混合高质量原始文本和经过修订的文本，可以在22个不同任务上分别带来1.0%，1.3%和2.5%的提升，相较于仅使用过滤后的网络数据训练。同时指出使用混合原始-合成数据集比获取2倍网络数据的训练效果更好。进一步分析显示，约82%的混合文本来自于原本会丢弃的低质量文档。REWIRE方法也在与生成合成数据的其他方法的对比中表现更优，包括百科式改写、问答合成和知识抽取。

Innovation: 
本文提出REWIRE方法，通过回顾和再利用现有过滤过程中丢弃的数据，丰富低质量文档，进而提高合成数据在最终预训练数据集中的比例。与其他生成合成数据的方法相比，REWIRE方法在增强预训练数据质量和数量方面更具优势，且具有显著的性能提升效果。

Conclusion: 
通过使用REWIRE方法，可以在不增加原始网络数据量的同时，显著提高预训练的数据质量和数量，有效缓解预训练过程中面临的数据瓶颈。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.04689</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>486. cs.AI-TSPulse: 双空间超紧凑预训练模型用于快速时间序列分析</title><link>https://arxiv.org/pdf/2505.13033</link><description>Background: 
时间序列预训练模型的发展显著提升了时间序列表示学习的水平，但当前最先进的模型通常规模庞大，需要大量的计算资源。因此，需要开发更紧凑的模型来满足在时间和计算资源上的需求优化。

Innovation: 
TSPulse 引入了在架构和任务层面的创新。在架构层面，它采用了双空间掩蔽重建，从时间域和频域中学习互补信号，并通过双嵌入解缠理论生成了详细的嵌入和高层次的语义嵌入。在任务层面，TSPulse 引入了 TSLens 细调组件用于任务特异性特征关注，并提出了一种多头三角化技术来增强故障检测并结合互补模型输出。此外，它还提出了一种混合掩码预训练技术，通过减少预训练偏差来改进零样本填充。这些架构和任务创新共同带来了显著的性能提升：在 UEA 分类基准上的表现提高了 5-16%，在 TSB-AD 异常检测排行榜上提升了 20%，在零样本填充上的提升达到 50%，在时间序列检索上的提升为 25%。而且，所有这些性能提升都仅使用 100 万个参数（比现有 SOTA 模型小 10-100 倍）并且可以实现无 GPU 推理，重新定义了高效时间序列预训练模型的标准。

Conclusion: 
TSPulse 证明了在保持强大性能的同时，通过采用紧凑的模型设计和特定任务的定制化技术，能够在时间序列分析中达到更高效率。该模型提供了超紧凑的、高质量的预训练时间序列表示，显著提高了在多个任务上的性能指标。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.13033</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>487. cs.AI-C3S3：半监督医学图像分割中的互补竞争与对比选择</title><link>https://arxiv.org/pdf/2506.07368</link><description>Background: 
在医学领域，由于标注样本不足的先天性挑战，现有的半监督医学图像分割方法大多无法精确捕捉边界细节，从而导致诊断准确性较低。这就需要一种能够提高边界分辨能力并提升整体精确度的新方法。

Innovation: 
提出了名为C3S3的新颖半监督分割模型，该模型结合了互补竞争和对比选择的优点，专门开发了结果导向的对比学习模块以优化边界定位，并引入了动态互补竞争模块利用两个高性能子网络生成伪标签，进一步提高分割质量。

Conclusion: 
C3S3在两个公开数据集上经过严格的验证，特别是在95HD和ASD指标上分别提升至少6%，显示出显著的进步。代码可在该链接获取。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07368</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>488. cs.AI-从量子位到企业应用的监督量子机器学习：未来展望</title><link>https://arxiv.org/pdf/2505.24765</link><description>Background: 
监督量子机器学习（QML）是量子计算与经典机器学习的交叉领域，旨在利用量子资源支持模型训练和推理。近年来，监督QML领域取得了重要进展，涵盖了变量子电路、量子神经网络、量子核方法以及混合量子-经典工作流等方法。实验研究表明，部分情况下可能存在量子优势，但同时也存在噪声、焦平原地、可扩展性问题和缺乏对性能改善的正式证明等限制。

Innovation: 
论文回顾了监督QML领域的最新进展，包括关键方法和技术，指出了潜在的研究方向和开发前景，并构建了一个未来十年（2025-2035年）的应用蓝图，以指导实际研究和企业系统的应用。

Conclusion: 
论文对监督QML的发展进行了十年展望，提出了可能的发展路径，并描述了条件，使得量子机器学习在未来十年内可以在实际研究和企业系统中得到应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.24765</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>489. cs.AI-Aurora: 在分布变化条件下 Android 恶意软件分类器的可靠性和稳定性</title><link>https://arxiv.org/pdf/2505.22843</link><description>Background: 
现代漂移适应性恶意软件分类器的性能指标显示出积极的进步，但这种性能是否代表了实际操作中的可靠性呢？传统的评估方法主要集中在基本性能指标上，而忽视了置信度误差的一致性和操作稳定性。尽管TESSERACT确立了时间评估的重要性，本研究则采取补充的研究方向，考察在分布变化条件下恶意软件分类器能否保持可靠的稳定置信度估计，并探索科学进步与实际影响之间的张力。文章讨论了在各种数据集上最新框架的脆弱性，指出需要回到白板上重新审视这些问题。

Innovation: 
本文提出了AURORA框架，用于基于置信度质量和运营韧性评估恶意软件分类器。AURORA框架对给定模型的置信度轮廓进行验证，以评估其估计的可靠性。此外，提出了新的度量标准，旨在超越单一时点性能，朝着在整个时间评价期间的整体运营稳定性评估迈进。这一创新旨在填补现有方法在实际运营可靠性方面的空白。

Conclusion: 
最新的SOTA框架在不同数据集上的脆弱性表明了返回基本原则的需求。AURORA框架及其提出的新方法为评估恶意软件检测工具的长期稳定性和可靠性提供了新的视角，这对于改善实际恶意软件威胁的检测至关重要。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.22843</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>490. cs.AI-AIDRIN 2.0: 一种评估AI数据准备性的框架</title><link>https://arxiv.org/pdf/2505.18213</link><description>Background: 
AIDRIN 是一个框架，用于评估和提升AI应用所需的原始数据质量和其他关键维度，如偏差、公平性和隐私性。它进一步根据现有的隐私保护联邦学习(PPFL)框架集成改进了用户界面，以支持分布式AI流水线，提高其在不同技术水平用户中的易用性和实用性。通过这种情况下的集成，AIDRIN确保了数据准备性和隐私性在联邦学习环境中得到了优先考虑。论文中通过一个真实数据集的实际案例研究，显示了AIDRIN在识别影响AI模型性能的数据准备性问题方面的实用性价值.

Innovation: 
AIDRIN 2.0 的创新之处在于其改进了用户界面，并成功地与现有的PPFL框架集成，从而增强了其在分布式AI流水线中的易用性和实用性。这种集成确保了在联邦学习环境中优先考虑数据准备性和隐私性。论文还通过实际案例研究强调了AIDRIN的实用价值，特别是在识别会影响AI模型性能的数据准备性问题方面.

Conclusion: 
AIDRIN 2.0 框架通过改进用户界面和与PPFL框架集成，提高了数据准备性和隐私性在联邦学习环境中的优先级，同时展示了其评估数据准备性问题的实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.18213</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>491. cs.AI-CogniBench: 一个受法律启发的框架和数据集，用于评估大型语言模型的认知忠实性</title><link>https://arxiv.org/pdf/2505.20767</link><description>Background: 
现有的基准测试主要关注由大型语言模型生成的'事实陈述'，这些陈述通过重新表述原始材料来评估，而忽视了从给定上下文中进行推断的'认知陈述'。这导致了对于认知陈述的幻觉评估和检测仍然具有挑战性。

Innovation: 
本文提出了一种借鉴法律领域证据评估方法的严格评估框架，以评估认知陈述的不同忠实度级别，并引入了CogniBench数据集，展示了有价值的统计数据。在此基础上，开发了一个易于扩展的自动注释流程，以大规模生成CogniBench-L数据集，使得能够训练出同时针对事实和认知幻觉的准确检测模型。

Conclusion: 
CogniBench数据集和相应的评估框架有助于提高对大型语言模型认知幻觉的评估和检测能力，同时也提供了一个易于扩展的自动注释框架，以适应不断发展的大型语言模型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.20767</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>492. cs.AI-教师先验运动模型：增强机器人在复杂地形上的行进</title><link>https://arxiv.org/pdf/2504.10390</link><description>Background: 
在复杂地形上实现稳定的行进依然是一个挑战，因为高维度的控制和环境不确定性。传统的范式高度依赖基于编码器的状态嵌入，这使得网络设计复杂且部署困难。本研究提出了一种基于教师-学生范式的先验框架，通过模仿学习和辅助任务学习来增强学习效率和泛化能力。该框架解耦网络设计，简化了策略网络，提高了可部署性。

Innovation: 
提出了一个基于教师-学生范式的先验框架，而非依赖于传统的编码器状态嵌入。该框架首先使用特权信息来训练高性能的教师策略，以获得可泛化的运动技能。然后，通过生成对抗机制将教师的运动分布转移到学生策略上，后者仅依赖于嘈杂的本体感觉数据，从而缓解分布性漂移导致的性能下降。辅助任务学习增强了学生策略的特征表示，加速了收敛过程并提升了对不同地形的适应能力。该框架在人形机器人上得到了验证，显著提高了动态地形上的行进稳定性并显著减少了研发成本。

Conclusion: 
该研究提供了一种在人形机器人上部署稳健行进策略的实用解决方案，展示了在复杂地形行进稳定性方面的显著改进和显著的研发成本降低。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.10390</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>493. cs.AI-通过分离表示实现眼科疾病分级的稳健多模态学习</title><link>https://arxiv.org/pdf/2503.05319</link><description>Background: 
眼科医生经常依赖多模态数据以提高诊断准确性，但在实际应用中，完整多模态数据由于缺乏医疗设备和数据隐私问题较为罕见。传统深度学习方法通常通过在潜在空间中学习表示来解决这些问题，但这类方法存在两个主要局限性：一是复杂模态中的任务无关冗余信息（例如，大量切片）导致潜在空间表示高度冗余；二是叠加的多模态表示使得从每个模态中提取独特特征变得困难。

Innovation: 
本文提出了一种名为Essence-Point和分离表示学习（EDRL）的新策略，该策略将自蒸馏机制集成到端到端框架中以增强特征选择和分离，从而提高多模态学习的鲁棒性。具体来说，Essence-Point表示学习模块选择提高疾病分级性能的判别特征，而分离表示学习模块则将多模态数据分离为模态共有的和模态特有的表示，减少特征纠缠，提升在眼科疾病诊断中的稳健性和可解释性。实验结果表明，所提出的EDRL策略显著优于当前最先进的方法。

Conclusion: 
本文提出的方法显著提高了眼科疾病分级的性能，并通过减少特征纠缠解决了传统多模态学习中的一些挑战。实验表明该方法在多模态眼科数据集上表现优异。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.05319</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>494. cs.AI-蛋白质结构标记化：基准测试与新配方</title><link>https://arxiv.org/pdf/2503.00089</link><description>Background: 
近年来，蛋白质结构标记化方法的发展加速，这些方法将蛋白质的三维结构分解为离散或连续的表示。结构标记化使得可以直接使用诸如语言建模等强大的技术应用于蛋白质结构，以及将结构与蛋白质序列和功能性文本集成的大型多模态模型。尽管取得了一些进展，但这些方法的能力和局限性仍不完全被理解，主要是因为缺乏统一的评估框架。因此，研究人员开发了一个新的评估框架——StructTokenBench，专注于细粒度的局部子结构，而不是现有的基准所关注的全局结构。

Innovation: 
该研究引入了一个名为StructTokenBench的新框架，全面评估结构标记器的质量和效率，特别关注细粒度的局部子结构。此外，研究开发了AminoAseed策略，这是一种简单有效的代码簿梯度更新方法，优化了代码簿的大小和维度，以提高标记器的利用效率和质量。该策略在24个监督任务中相对于领先的模型ESM3平均提高了6.31%的表现，同时提高了灵敏度和利用率，分别提高了12.83%和124.03%。

Conclusion: 
StructTokenBench框架和AminoAseed策略相比现有的方法有显著的优势，能够在蛋白质结构标记化中取得更优的效果。研究结果鼓励 future work 在这一领域继续探索优化策略和提高表现的可能性。该研究提供代码和模型权重，供其他研究人员参考。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.00089</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>495. cs.AI-从O(n^2)到O(n)参数：用于生物医学图像分类的视觉变换器中的量子自我注意</title><link>https://arxiv.org/pdf/2503.07294</link><description>Background: 
目前，最先进的生物医学图像分类器依赖于视觉变换器（ViTs），但这些模型通常需要大量的参数。这使得它们在资源受限的环境中难以广泛应用，尤其是需要低参数效率和高计算效率的方法来提高模型的可扩展性和部署灵活性。已有研究表明，通过使用参数化的量子神经网络（QNNs）代替传统的线性自我注意（SA）层，可以开发出量子自我注意（QSA）机制，从而减少参数数量并提高效率。因此，如何在保持性能的同时减少参数并提高量子自我注意机制的参数效率成为该领域研究的重要方向。

Innovation: 
本文提出了一种新的方法，通过将传统线性自我注意（SA）层替换为参数化的量子神经网络（QNNs）来实现量子自我注意（QSA）机制，从而将参数规模从O(n^2)减少到O(n)。这种方法不仅显著减少了参数数量，还维持了生物医学图像分类中的高准确性。实验结果表明，提出的方法在RetinaMNIST数据集上超过了13/14种最先进的方法（包括CNNs和ViTs），并且使用了不到1000个参数，仅为传统方法的0.1%。此外，本文还首次研究了从经典视觉变换器到量子视觉变换器的知识蒸馏，证明了QSA机制的参数效率和模型的可扩展性优势，并探讨了更高量子位数架构下蒸馏预训练的有效性关系。

Conclusion: 
研究表明，量子自我注意（QSA）机制可以作为一种实用的架构选择，用于实现参数效率较高的生物医学图像分析。量子自我注意机制通过减少参数数量和提高模型性能，为视觉变换器在生物医学图像分类中的应用开辟了新途径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.07294</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>496. cs.AI-LLM位置泛化背后的计算机制</title><link>https://arxiv.org/pdf/2503.13305</link><description>Background: 
大多数自然语言都是由单词和句子的序列组成，类似于人类，大型语言模型（LLMs）在处理文本位置方面表现出灵活性——我们称之为位置泛化现象。它们能够理解带有位置扰动的文本，并在训练过程中接触较短文本的基础上泛化到更长的文本。这些现象表明LLMs在处理位置时是容忍的，但它们是如何处理位置相关性尚未被完全探索。这项研究将语义现象与LLMs的计算机制联系起来，展示了LLMs如何在位置扰动面前实施特定的计算机制。尽管自我注意机制设计复杂，但研究揭示了LLMs通过学习一种反直觉的注意力logits的分解来实现这一机制。其值与位置相关性和语义重要性的算术和近似值之间有0.959的线性相关性。此外，研究还发现了中间特征中的普遍模式，这种模式我们通过理论证明可以支持这一效果，这种模式不同于随机初始化参数的行为，表明这是一种学习行为而非模型架构的自然结果。基于这些发现，研究提供了LLMs位置灵活性的计算解释和标准。这项工作在一个新的方向上建立起位置泛化与现代LLMs内部机制的联系。

Innovation: 
研究揭示了大型语言模型（LLMs）在位置泛化过程中，通过学习一种反直觉的注意力logits分解机制实现位置容忍。研究展示了LLMs在处理位置相关性变化时表现出的复杂计算机制，表明位置泛化是一种学习行为，而非模型架构的自然结果，并且提出了计算解释和标准来解释大型语言模型的位置灵活性。这项工作在一个新的方向上建立起位置泛化与现代LLMs内部机制的联系。

Conclusion: 
研究通过实证研究和理论证明，揭示了大型语言模型在位置泛化过程中所使用的一种学习机制。这一机制使得LLMs能够在处理位置变化时表现出灵活性。研究提供了对LLMs位置灵活性的计算解释和标准，并且为进一步研究提供了参考框架。这项工作为理解和改进大型语言模型提供了新的视角。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.13305</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>497. cs.AI-使用深层上下文蒸馏训练即插即用知识模块</title><link>https://arxiv.org/pdf/2503.08727</link><description>Background: 
在大型语言模型预训练之后动态整合新信息或快速进化的信息仍然具有挑战性，特别是在数据量少的场景或处理私人和专业文档时。现有的在上下文学习和检索增强生成（RAG）方法存在一些局限性，如高推理成本和难以捕获文档的全局信息。因此，需要提出一种新的方法来解决这些问题，增强语言模型在特定数据环境下的表现能力。

Innovation: 
本文提出了一种方法，通过训练文档级别知识模块（KMs）来模块化知识。KMs被设计为参数高效的LoRA模块，能够在无需大规模重新训练的情况下轻松集成到已有模型中，用于储存新的文档信息。作者提出了一种名为深层上下文蒸馏的新的学习策略，通过模拟教师模型在上下文中的隐藏状态和输出，来提高KMs的学习效果。这种方法在两个数据集上证明了其优于标准化的下一个令牌预测和其他预训练技术的效果。

Conclusion: 
该研究表明，通过训练文档级别的知识模块并通过深层上下文蒸馏方法，可以有效增强语言模型处理新信息或快速进化的信息的能力，并在保留已有模型结构和参数效率的同时，提高模型在特定场景下的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.08727</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>498. cs.AI-结合多种软件构件以提升基于LLM的软件缺陷定位与修复</title><link>https://arxiv.org/pdf/2412.03905</link><description>Background: 
大型语言模型（LLMs）已成为自动程序修复（APR）的重要工具，显示了简化APR流程的巨大潜力。现有的LLM方法往往依赖单一类型的软件信息，并未充分利用多种软件冗余。本文研究了不同类型的软件冗余在软件缺陷定位与修复中的作用。虽然部分LLM方法能够通过插入正确代码或直接生成补丁来修复软件缺陷，但大部分方法并未深入探讨哪些特定类型的软件信息最能辅助缺陷修复。

Innovation: 
我们提出了DEVLoRe方法，通过利用问题描述和错误栈轨迹来定位有缺陷的方法，同时利用调试信息和问题描述及错误栈轨迹来定位有缺陷的行，并生成可通过所有单元测试的合理补丁。实验证明，DEVLoRe方法能有效利用几种不同类型的信息，从而在缺陷修复过程中显著提高性能。DEVLoRe能够在Defects4J v2.0数据集中成功定位49.3%和47.6%的单一与非单一有缺陷的方法，并生成56.0%和14.5%的合理补丁，优于当前最优的缺陷修复方法。此外，我们重新实现了并评估了该框架，并讨论了能否直接将领先的Python代码框架应用于Java代码或反之的情况。

Conclusion: 
我们的研究结果表明，DEVLoRe方法有效地利用了问题内容、错误栈轨迹和调试信息，在缺陷定位和修复中取得了显著的效果，超越了现有最优方法。我们还通过实验证明了其在解决独特问题上的有效性，并提供了复现该研究工作的源代码和实验结果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.03905</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>499. cs.AI-MaizeField3D：来自多样品系的田间种植玉米的3D点云和程序模型数据集</title><link>https://arxiv.org/pdf/2503.07813</link><description>Background: 
由于缺乏大型且多样的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具的发展，特别是在玉米中，受到了限制。2D图像数据集无法捕捉到3D数据能够提供的关键结构细节，如叶片结构、植物体积和空间排列等。为了应对这一局限性，我们提出了MaizeField3D，这是一个由多样遗传品系的田间种植玉米的3D点云构建的、为AI可准备的数据集，旨在推动农业研究的进步。

Innovation: 
MaizeField3D 数据集包括通过地面激光扫描仪（TLS）收集的1,045个高质量点云，且其中520个点云已被通过基于图的分割方法进行分割和标注，以确保所有样本具有一致的标签。程序模型采用非均匀有理B样条（NURBS）曲面表示叶片，该曲面是在结合无导数和有导数方法的优化过程中生成的。该数据集经过严格的手动质量控制，并包含了多分辨率下采样点云数据（10万，5万，1万点），可直接用于不同的后续计算任务。

Conclusion: 
MaizeField3D 将成为AI驱动的表型分析、植物结构分析和农业研究中3D应用的全面基础数据集。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.07813</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>500. cs.AI-FGS-SLAM: 基于Fourier频域分析的高精度实时SLAM稀疏稠密地图融合方法</title><link>https://arxiv.org/pdf/2503.01109</link><description>Background: 
3D高斯插值技术提升了SLAM技术，实现了实时定位和高保真地图构建。但高斯位置和初始化参数的不确定性导致了迭代收敛困难，需要大量的迭代计算，有时会导致高斯表示冗余或不足。因此，该研究旨在解决这一问题，通过基于Fourier频域分析的自适应稠密化方法建立高斯先验信息，以实现快速收敛。此外，该研究还提出构建独立的稀疏和稠密地图，稀疏地图通过广义迭代最近点（GICP）支持高效跟踪，稠密地图创建高保真的视觉表示。这是首次通过频域分析实现实时高精度高斯地图的技术。实验结果表明，在Replica和TUM RGB-D数据集上，平均帧率为36 FPS，并在定位和建图方面达到了有竞争力的精度。

Innovation: 
提出了基于Fourier频域分析的自适应稠密化方法，用于建立高斯先验，以实现快速收敛；构建了独立的稀疏和稠密地图，其中稀疏地图通过GICP支持高效的跟踪，稠密地图提供高保真的视觉表示；该方法是首次利用频域分析实现实时高精度高斯地图的技术。

Conclusion: 
实验结果表明，该方法在Replica和TUM RGB-D数据集上实现了36 FPS的平均帧率，在定位和建图方面达到了有竞争力的精度，实现了高精度的实时SLAM技术。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.01109</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>501. cs.AI-Graph推理奖励过程使LLMs成为更通用的推理者</title><link>https://arxiv.org/pdf/2503.00845</link><description>Background: 
尽管大型语言模型（LLMs）取得了显著进展，但在LLMs中开发高级推理能力仍然是一个关键挑战。尽管过程奖励模型（PRMs）在数学推理等情境中展示了提升推理能力的潜力，但其在更广泛推理领域的应用仍然缺乏研究，主要是由于手工创建步骤级别的监督成本高昂。本文探讨了PRMs在图推理问题领域的潜力，该领域需要复杂的多步推理，并利用现有的图算法自动生成详细的推理步骤和步骤级标签数据。通过这种方式构建了一个名为GraphSILO的大型数据集，用于训练GraphPRM，这是第一个针对图推理问题设计的PRM。

Innovation: 
本文引入了GraphSILO数据集，用于图推理问题，使用自动任务导向轨迹和蒙特卡洛树搜索（MCTS）生成详细的推理步骤的步骤级标签。基于该数据集，开发了GraphPRM，这是第一个专为图推理问题设计的PRM，并在两类关键应用中进行了评估：推理时扩展和通过直接偏好优化（DPO）的强化学习。实验结果表明，GraphPRM显著提高了LLM在13个图推理任务上的表现，特别是在Qwen2.5-7B上表现了9%的增益，并展示了跨领域通用性。

Conclusion: 
我们的研究揭示了PRMs在多种领域中提升推理能力的潜力，为更加多功能和有效的LLMs铺平了道路，特别是在图推理和数学问题解决等新领域显示出了应用的可行性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.00845</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>502. cs.AI-基于不确定性意识的指令微调平衡真实性和信息量</title><link>https://arxiv.org/pdf/2502.11962</link><description>Background: 
指令微调（IFT）可以增加大型语言模型（LLMs）的信息量，但可能会降低它们的真实性。这是因为IFT引导LLMs生成包含在预训练中未充分覆盖的知识的响应。结果，在面对未见过的任务时，模型变得更具有信息量但准确性较低。本文通过实验证明，IFT数据中的陌生知识会负面影响LLMs的真实性，并引入了两种新的IFT范式——$UNIT_{cut}$和$UNIT_{ref}$来解决这一问题。$UNIT_{cut}$识别并从IFT数据集中去除陌生知识，以减轻其对模型真实性的负面影响；$UNIT_{ref}$训练LLMs认识到它们的不确定性，并在响应末尾明确指出这一点。实验结果表明，$UNIT_{cut}$显著提高了LLMs的真实性，而$UNIT_{ref}$保持了高信息量，并通过区分自信和不确定的陈述减少了妄想现象。

Innovation: 
本文提出了两种新的指令微调范式，$UNIT_{cut}$和$UNIT_{ref}$。前者通过识别并去除IFT数据中的陌生知识来减轻对模型真实性的负面影响，后者则训练LLMs来识别其不确定性并在响应结束时明确指出。这些方法成功地平衡了模型的信息量和真实性，特别是在面对未见过的任务时。

Conclusion: 
实验结果表明，$UNIT_{cut}$显著提高了LLMs的真实性，而$UNIT_{ref}$则在保持高信息量的同时减少了妄想现象，这两种方法成功地解决了指令微调带来的真实性与信息量之间的权衡问题，平衡了模型的真实性和信息量。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.11962</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>503. cs.AI-基于化学知识的信息保护可逆合成学习框架</title><link>https://arxiv.org/pdf/2502.19119</link><description>Background: 
化学反应数据是重要资产，推动了制药、材料科学和工业化学等领域的发展。这类数据具有专有性，通常包含机密见解和竞争优势，组织需要保护。然而，当前机器学习驱动逆合成反应数据的训练标准方法是将各种来源的数据汇总到单个边缘进行模型训练。这种方法存在较大的隐私风险，因为需要不同组织之间的广泛数据共享和频繁的数据传输，可能会在存储和传输过程中暴露给未经授权的访问或拦截。

Innovation: 
本文介绍了一种隐私保护的信息框架（CKIF），该框架可以在多个化学公司之间实现分布式逆合成反应模型的训练，同时不泄露专有的反应数据。CKIF通过迭代的、基于化学知识的模型参数聚合来学习逆合成模型，而不是收集原始反应数据。化学预测反应物的属性被用于量化评估每个模型的可观察行为，从而确定模型聚合的自适应权重。

Conclusion: 
在多种化学反应数据集上，CKIF显著优于几个强大的基线模型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.19119</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>504. cs.AI-WyckoffDiff -- 一种晶体对称性的生成扩散模型</title><link>https://arxiv.org/pdf/2502.06485</link><description>Background: 
晶体材料通常表现出高度对称性。然而，大多数生成模型并未考虑对称性，而是为每个原子定义位置和元素而不加限制。作者提出了一种名为Wyckoff Diffusion (WyckoffDiff) 的生成模型，该模型能够生成基于对称性的晶体描述。这一能力通过考虑编码所有对称性的晶体结构表示来实现，并设计了一个新的神经网络架构，以在离散生成模型框架中使用这种表示。此外，作者还提出了一种新的度量标准，Fréchet Wrenformer Distance，以捕捉生成材料的对称特性，并将WyckoffDiff与最近提出的晶体生成生成模型进行了基准测试。作为一种概念验证研究，作者使用WyckoffDiff在热力学稳定区域的凸包之下发现了新材料。

Innovation: 
WyckoffDiff是一种能够捕捉晶体对称性的生成模型。它通过考虑所有对称性编码的晶格结构表示，并设计了一种新型的神经网络架构，使其能够在离散生成模型框架中运行。这种模型不仅从结构上尊重了对称性，还因为离散的性质使得生成过程非常快速。此外，还引入了Fréchet Wrenformer Distance作为评估生成材料对称性的新度量标准。

Conclusion: 
WyckoffDiff展示了对晶体生成模型进行革命性改变的可能性，该模型专门用于生成具有对称性的晶体描述。这种新型模型提高了生成过程的效率，并为生成具有特定对称性的晶体提供了一种新的方法。通过基准测试表明，WyckoffDiff在生成对称性晶体材料方面优于现有方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.06485</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>505. cs.AI-超越语言模型的自然数据集中的上下文学习能力</title><link>https://arxiv.org/pdf/2501.06256</link><description>Background: 
大型语言模型（LLMs）表现出上下文学习（ICL）能力，使其能够在不更新模型权重的情况下，通过上下文中的示例来执行新任务。尽管ICL为自然语言任务和领域提供了快速适应能力，但其在其他模态（如视觉）中的出现则更为复杂。本文旨在系统性地揭示支持LLMs实现ICL的特性，并通过促进ICL所需机制的学习，应用于不同类型的模态，包括视觉数据集和更具挑战性的脑电波（EEG）分类任务。文中指出训练数据序列中的精确重复的词作为ICL的重要因素，有助于增强ICL的稳定性并减少其波动。此外，还强调了训练任务难度对ICL出现的重要性。最后，通过应用这些关于ICL出现的新见解，本文解锁了能够在少量示例学习环境下实现ICL能力的多种视觉数据集和更具挑战性的EEG分类任务。

Innovation: 
本文系统性地发现并强调了训练数据序列中的精确重复词在支持大型语言模型实现上下文学习中的重要性，进一步增强了ICL的稳定性并减少了其变异性。同时，强调了训练任务难度对ICL出现的重要性。通过开发的新颖洞见，本文成功地解锁了在多种视觉数据集和更复杂的EEG分类任务中实现上下文学习的能力，特别是在少量示例学习环境中。

Conclusion: 
本文揭示了训练数据中精确重复词对于支持大型语言模型实现上下文学习的重要影响，并且开发了增强ICL稳定性和减少其波动的方法。通过应用这些新的见解，本文成功解锁了在多种视觉数据集和更具挑战性的EEG分类任务中实现上下文学习的能力。此外，本文还强调了训练任务难度对于促进上下文学习的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.06256</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>506. cs.AI-重估早期停止：先细化再校准</title><link>https://arxiv.org/pdf/2501.19195</link><description>Background: 
机器学习分类器常产生概率预测，这对各个领域中的准确和可解析决策至关重要。这些预测的质量通常通过交叉熵等适当损失来评估，这些损失分解为两个组件：校准误差评估一般的信心不足或过估计，而细化误差衡量区分不同类别的能力。本文基于此背景，提出了一种新的校准-细化分解的变分形式，该形式对后校准提供了新见解，并使不同项的快速估计成为可能。这一新视角提供了理论和实证证据，表明校准和细化误差在训练期间不会同时最小化。基于验证损失选择最佳训练期导致一个权衡点，对于两项都是次优的。为了应对这一问题，本文提出在训练期间仅最小化细化误差（Refine），然后使用标准技术进行后校准（Calibrate）。该方法可以无缝集成到任何分类器中，并在不同分类任务中一致地提高性能。

Innovation: 
提出了一种新的校准-细化分解的变分形式，能够提供有关后校准的新见解，并允许快速估计不同项。证明了训练期间校准和细化误差不会同时最小化；建议了一种训练期间仅最小化细化误差再进行后校准的新方法。该方法无缝兼容任何分类器，并在多种分类任务中显示出一致的性能提升。

Conclusion: 
在训练期间采取先细化再校准的策略，能够更好地优化模型的细化和校准性能，提供更准确和可解析的预测。该方法为分类任务中的模型优化提供了一种新的视角和策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.19195</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>507. cs.AI-通过全球视角审视扩散模型：它们是否具有文化包容性？</title><link>https://arxiv.org/pdf/2502.08914</link><description>Background: 
文本到图像的扩散模型最近使得从文本提示生成视觉上引人注目、复杂的图像成为可能。然而，这些模型在准确反映各种文化细微差别方面的能力仍是一个悬而未决的问题。本文介绍了一个名为CultDiff的基准测试，评估最先进的扩散模型是否能够生成跨越十个国家的文化特定图像。通过细致分析不同相似性方面，研究揭示了与现实世界参考图像相比，在文化相关性、描述准确性和现实性方面的显著差异。

Innovation: 
提出了CultDiff基准测试，对最先进的扩散模型生成文化特定图像的能力进行了评估。开发了基于神经网络的图像-图像相似性度量方法CultDiff-S，用于预测具有文化特征的真实和生成图像的人类判断。

Conclusion: 
本文强调了需要更包容的生成AI系统，并且数据集需要在广泛的文化范围内更加公平和多样。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.08914</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>508. cs.AI-USP-Gaussian: 统一基于尖峰的图像重建、姿态矫正和高斯斑点</title><link>https://arxiv.org/pdf/2411.10504</link><description>Background: 
刺突型相机作为一种创新的类神经形态相机，以0-1位流形式在40 kHz的高频率下捕捉场景图像，正越来越多地用于通过NeRF或3D高斯斑点（3DGS）进行3D重建任务。然而，现有的基于刺突的3D重建方法通常采取分案处理方式，步骤包括从刺突流中重构高质量图像，然后进行相机姿态估计和3D重建。这种方式会导致累积误差，影响最终的3D重建保真度。

Innovation: 
本文提出了一种名为USP-Gaussian的协同优化框架，该框架将基于尖峰的图像重建、姿态矫正和高斯斑点技术统一起来，形成一个端到端的优化流程。利用3DGS提供的多视图一致性以及刺突相机的运动捕捉能力，我们的框架在迭代优化过程中无缝整合了尖峰到图像网络和3DGS之间的信息，从而有效避免了级联错误。我们的方法在具有精确姿态的合成数据集上优于以前的方法，并能够通过姿态优化在现实场景中实现鲁棒的3D重建，有效降低了噪音并保持了细腻的纹理细节。

Conclusion: 
我们的方法通过创建一个端到端的协同优化框架，解决了基于刺突的3D重建中的累积误差问题，提高了3D重建的精度和保真度，尤其在实际场景下表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.10504</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>509. cs.AI-PhysUniBench： multimodal模型的本科物理推理基准</title><link>https://arxiv.org/pdf/2506.17667</link><description>Background: 
物理问题求解是大型AI模型的一个具有挑战性的领域，需要整合概念理解、数学推理和物理图表的解释。当前的评估方法在捕捉本科物理的广度和复杂性方面存在显著不足，强调了需要更严格的评估方法的必要性。为此，本文提出PhysUniBench，这是一个大规模的多模态基准，旨在评估和提高多模态大型语言模型在本科物理问题上的推理能力。该基准涵盖了8个主要物理子学科的3304个物理问题，每个问题都附带一个视图图表。该基准包括开放性和选择性问题，通过迭代模型循环过程严谨地分类和难度评级。通过广泛的实验，我们观察到当前最先进的模型在物理推理方面遇到重大挑战。例如，GPT-4o mini在提出的PhysUniBench上的准确性仅为约34.2%。这些结果表明，当前的多模态大型语言模型在高级物理推理方面存在问题，特别是在多步骤问题和需要精确图表解释的问题上。通过提供一种广泛且严格的评估工具，PhysUniBench旨在推动科学领域的AI发展，激励开发具有更强物理推理、问题解决能力和多模态理解的模型。

Innovation: 
PhysUniBench是一个大规模的多模态基准，旨在评估和提高多模态大型语言模型在本科物理问题上的推理能力。它包括8个主要物理子学科的3304个物理问题，每个问题都附带一个视图图表。该基准通过迭代模型循环过程严谨地分类和难度评级。结果显示，当前最先进的模型在物理推理方面遇到重大挑战，特别是在多步骤问题和需要精确图表解释的问题上。通过提供这种广泛的评估工具，PhysUniBench旨在推动科学领域的AI发展。

Conclusion: 
PhysUniBench通过提供广和严谨的评估工具，旨在驱动AI在科学领域的发展，鼓励模型开发具有更强物理推理、问题解决能力和多模态理解的特点。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17667</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>510. cs.AI-AgentBreeder: 通过自我改进缓解多智能体支架对AI安全的影响</title><link>https://arxiv.org/pdf/2502.00757</link><description>Background: 
使用大型语言模型（LLMs）搭建多智能体系统通常可以提升复杂任务的表现，但这些支架对安全性的影响尚未得到充分研究。本文介绍了一种名为AgentBreeder的框架，用于多目标自改进进化搜索。在评估发现的支架时，使用了被广泛认可的推理、数学和安全性基准测试。该研究在'蓝'模式下观察到了79.4%的安全基准性能提升，同时保持或提高了能力评分。在'红'模式下，研究发现伴随能力优化的同时出现了对抗性脆弱的支架。这项工作展示了多智能体支架的风险，并提供了一个缓解这些问题的框架。

Innovation: 
引入了AgentBreeder框架，通过多目标自改进进化搜索发现多智能体系统中的支架。框架在安全基准性能和能力评分之间实现了平衡，在'蓝'模式下显著提升了安全性，在'红'模式下揭示了对抗性脆弱支架的风险。该工作为多智能体支架的安全性研究提供了新的视角和方法。

Conclusion: 
研究结果表明，多智能体支架对安全性有潜在风险，并且提出了一个缓解这些风险的框架。此框架在保持系统能力的同时显著提高了安全性，为未来的智能系统设计提供了宝贵的参考。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.00757</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>511. cs.AI-使用分解扩散序贯蒙特卡洛方法解决线性高斯贝叶斯逆问题</title><link>https://arxiv.org/pdf/2502.06379</link><description>Background: 
近期研究利用预训练的生成扩散模型作为先验来解决贝叶斯逆问题。该研究方向的设计特点是，通过‘分解扩散’的方式，使得样本更新更为灵活。本文设计了基于分解扩散的序贯蒙特卡洛方法（DDSMC），专门用于线性高斯逆问题，该方法在理论上是渐近精确的。研究表明，这种方法在合成数据、蛋白质数据和图像数据上都表现出了有效性，并且可以进一步拓展到离散数据领域。

Innovation: 
提出了一种基于分解扩散的序贯蒙特卡洛方法（DDSMC），用于解决线性高斯逆问题。这种方法在理论上是渐近精确的，并且在合成数据、蛋白质数据和图像数据上的实验结果都表明了其有效性。此外，方法还可以进一步拓展到离散数据领域。

Conclusion: 
通过DDSMC算法在合成数据、蛋白质数据和图像数据上的有效性验证，证明了该方法的实用性和有效性。此外，该方法可以用于解决离散数据带来的逆问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.06379</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>512. cs.AI-在狱中推理的对抗性推理</title><link>https://arxiv.org/pdf/2502.01633</link><description>Background: 
随着大型语言模型（LLMs）变得越来越强大和普及，研究其失败案例变得越来越重要。最近在标准化、衡量和扩大测试时计算方面取得的进展提出了优化模型的新方法，以在难以解决的任务上取得高性能。本文将这些进展应用于模型逃狱任务：诱导对齐的LLMs产生有害回应。

Innovation: 
本文开发了一种基于对抗性推理的自动逃狱方法，利用损失信号指导测试时计算，即使针对那些试图在推理时计算与对抗性鲁棒性之间进行权衡的对齐LLMs，也能实现最先进的攻击成功率。这种方法提出了理解LLM漏洞的新范式，为开发更安全和可信赖的AI系统奠定了基础。

Conclusion: 
本文介绍了对抗性推理在逃狱时刻的新方法，这种方法指导测试时计算，并成功应用于对齐的LLMs对抗，最终为更安全和可信赖的AI系统的开发奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.01633</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>513. cs.AI-在模型参数空间中提升后门隐蔽性</title><link>https://arxiv.org/pdf/2501.05928</link><description>Background: 
当前研究主要集中在输入空间中的不可区分触发器和特征空间中不可分割的后门表示上，以绕过检查这些空间的后门防御。然而，现有后门攻击通常针对特定类型的后门防御，而未考虑多样化的防御机制。本研究指出，针对多样化的实际防御，现有的后门攻击是否依然是真正的威胁。研究发现，输入和特征空间中的后门攻击在参数空间中会留下显著的后门相关神经元，这些未被现有后门攻击充分考虑。

Innovation: 
研究揭示了一个关键盲点，即针对输入和特征空间隐藏的后门攻击可以通过检查模型的参数空间来进行缓解。进一步研究了后门攻击在参数空间中的特性，发现输入和特征空间的攻击会在参数空间中引入显著的后门相关神经元。基于这一发现，提出了一个新的供应链攻击方法——Grond。该方法通过简单但有效的模块Adversarial Backdoor Injection (ABI)限制参数变化，在后门植入过程中动态提高参数空间的隐蔽性。实验表明，Grond比所有12种针对最新防御（包括适应性防御）的后门攻击在CIFAR-10、GTSRB和ImageNet的部分数据集上表现更优。同时，表明ABI可以提高普通后门攻击的有效性。

Conclusion: 
Grond通过改进参数空间的隐蔽性显著提升了后门攻击的效果，适应了多样化的实际防御，在多种数据集上展现了优越的效果，并且证明了参数空间对抗后门攻击的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.05928</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>514. cs.AI-分布式卫星信息网络：架构、使能技术和趋势</title><link>https://arxiv.org/pdf/2412.12587</link><description>Background: 
在万物互联和无线智能的愿景驱动下，基于超密集星座的卫星融合互联网正在发展，在初步成型。然而，现有的卫星系统由于历史遗留的机构壁垒和有限的非可再生能源异构网络资源而难以满足下一代智能应用的需求。在这一背景下，分布式卫星信息网络（DSIN）通过集簇卫星系统等构架，跨越通信、导航、遥感等多种卫星系统的信息鸿沟，建立了统一开放的信息网络模式，以支持更可靠的太空信息服务。DSIN面临着网络异构性、不可预测的信道动态、稀疏资源和分布式协作框架等方面的挑战。

Innovation: 
分布式卫星信息网络（DSIN）作为一种创新架构，通过集簇卫星系统等构架，跨越通信、导航、遥感等多种卫星系统的信息鸿沟，建立了统一开放的信息网络模式，以支持更可靠的太空信息服务。识别并讨论了分布式再生卫星网络架构、分布式卫星计算网络架构以及可重构卫星编队飞行等创新网络架构，指出了适应异构网络、不确定信道动态和稀疏资源的使能技术，同时开发了多层优化技术以满足上层确定性、自适应和安全的信息服务要求。

Conclusion: 
进一步研究和方向的重点是实现DSIN愿景所需的发展策略和新机会。通过对DSIN架构、使能技术和趋势的深入探讨，该论文提出了一系列使能技术，以提高资源效率，满足分布式卫星信息网络所需要的多样化信息服务需求。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.12587</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>515. cs.AI-通过提示、细调和零样本提示评估小型语言模型的泛化能力和内部表示稳定性</title><link>https://arxiv.org/pdf/2506.17289</link><description>Background: 
本文调查了在两种流行的适应范式下小型语言模型的一般化能力：最少示例提示和监督微调。尽管提示因其参数效率和灵活性而受到青睐，但在资源有限的环境下和分布变化中，这种方法的稳定性仍然是一个未解之谜。本文关注提示和微调在不同任务格式、提示风格和模型规模下的比较研究，特别是它们在分布内外环境中的表现。研究不仅关注准确性，还分析了各方法学习的内部表示，以评估任务特定特征的稳定性和抽象性。研究表明，不同适应策略下小型模型如何理解和泛化知识存在关键差异。这项工作为低数据环境下模型选择提供了实用指导，并为提示与微调的持续争论提供了实证见解。

Innovation: 
本文通过对比最少示例提示和监督微调两种方法，系统研究了小型语言模型在不同任务格式、提示风格和模型规模下的表现，特别是在分布内外环境中的行为。进一步分析了各方法学习的内部表示，评估了任务特定特征的稳定性和抽象性。这些发现强调了不同适应策略对小型模型知识内化和泛化能力的不同影响。这项工作为低数据环境下的模型选择提供了实用指导，并为提示与微调的争论提供了可验证的数据支持。

Conclusion: 
本文的研究结果表明，小型模型在不同的适应策略下的表现存在关键差异。这两项方法在在分布内外环境中的行为和学习的内部表示表现有所不同。这些发现为低数据环境下的模型选择提供了实用指导，并有助于为将来关于提示与微调的讨论提供实证支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17289</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>516. cs.AI-分离语言与概念：激活补丁揭示转换器中的语言无关概念表示</title><link>https://arxiv.org/pdf/2411.08745</link><description>Background: 
在多语言语言建模中，一个核心问题是大型语言模型（LLMs）是否发展出一种普适的概念表示，这种表示不依赖于特定的语言。本文通过分析转换器基于的语言模型在词翻译任务中的潜在表示（latent representations），来探讨这一问题。研究者战略性地从源翻译提示中提取潜在表示，并将其插入目标翻译提示的前向传递中。研究表明，目标语言在潜在表示中的编码晚于需要翻译的概念。基于这一发现，他们进行了两个关键实验。首先，通过激活补丁（activation patching）证明了可以在不改变语言的情况下改变概念，反之亦然。第二，表明在不同的语言中使用概念的平均表示进行补丁处理不会影响模型的翻译能力，反而提高了翻译质量。最后，他们将结果扩展到多词生成任务，并展示了模型能够生成这些平均表示的自然语言描述。这些结果提供证据支持模型中存在的与语言无关的概念表示的存在性

Innovation: 
研究通过引入激活补丁技术，揭示了在转换器模型中存在与语言无关的概念表示。通过实验显示了在不改变语言的情况下可以修改概念，且通过使用不同语言中概念的平均表示进行补丁处理可以提升模型的翻译能力。此外，研究还证实了这一发现可以应用于多词生成任务。

Conclusion: 
研究表明，转换器模型中存在与语言无关的概念表征。激活补丁技术不仅能够揭示这些表征，还能用作改进翻译质量的策略，尤其是在多语言环境中。此外，研究还证明了该模型能够在生成自然语言描述方面具有出色的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.08745</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>517. cs.AI-基于联邦学习的多无人机近端控制以实现人机协作</title><link>https://arxiv.org/pdf/2412.02863</link><description>Background: 
人机交互（HRI）是研究的热点领域。尽管有人使用神经网络来识别动作，但遮挡问题在使用无人飞行器（UAV）时尤为严重，特别是在机器人移动时，往往会导致人类操作者不在机器人的视野范围内。此外，在多机器人场景中，分布式训练也是一个开放问题。现有的方法通常难以避免遮挡情况，影响了技术的实际应用。因此，需要一种能够在分布式环境中避免遮挡并且能够识别复杂动作的方法。

Innovation: 
本研究提出了一种基于长短期记忆（LSTM）深层神经网络和联邦学习（FL）的多无人机行动识别和控制方法。该方法包括两层LSTM网络以及三个全连接层，并能够在分布式多无人机系统中实现行动识别和控制，无需云或其它数据存储库即可进行训练。实验结果表明，在实际机器人环境中，该方法的识别准确率超过了96%。

Conclusion: 
该研究通过使用分布式多无人机系统，结合LSTM和联邦学习技术，在避免遮挡的基础上成功实现了复杂动作的识别和控制，这大大提升了机器人技术在实际场景中的适用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.02863</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>518. cs.AI-世界模型的理解或未来预测？世界模型的全面综述</title><link>https://arxiv.org/pdf/2411.14499</link><description>Background: 
由于GPT-4之类的多模态大型语言模型和Sora之类的视频生成模型等先进领域的进展，世界模型的概念引起了广泛关注，这些模型是追求通用人工智能的关键组成部分。本文综述了关于世界模型的文献，指出世界模型通常被认为是理解当前世界状态或预测未来动态的工具。

Innovation: 
本文对世界模型进行了系统的分类，强调了构造内部表示以理解世界机制和预测未来状态以模拟和指导决策这两种主要功能。同时，它探索了世界模型在自主驾驶、机器人技术和社会模拟等关键领域的应用。

Conclusion: 
本文指出了世界模型领域的关键挑战，并提供了对未来研究方向的见解。最后，本文总结了代表性论文及其代码仓库，网址为this https URL.</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.14499</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>519. cs.AI-Toddler的主动注视行为支持自我监督对象学习</title><link>https://arxiv.org/pdf/2411.01969</link><description>Background: 
幼儿在几乎没有监督的情况下学会了从不同角度识别物体。在这个学习过程中，他们频繁地进行眼球和头部运动，这些动作会影响他们的视觉体验。目前尚不清楚这些行为如何影响幼儿逐渐形成的物体识别能力。本研究通过结合基于头部佩戴的眼球追踪技术的双人游戏实验和无监督机器学习，来探讨此问题。研究采用图像裁剪方式，基于眼球追踪估计的当前注视点中心，模拟幼儿的中央视觉场体验，并将视觉数据输入无监督计算模型，观察模型如何随时间构建稳定的视觉表示。研究结果表明，幼儿的注视策略有助于建立不变物体表示的学习，并且高清晰度视觉区域的有限大小在这个过程中至关重要。

Innovation: 
研究将头部佩戴的眼球追踪技术与幼儿的双人游戏实验结合，通过模拟幼儿的中央视觉场来提供视觉输入，并利用无监督机器学习方法研究他们的学习过程。这一方法揭示了幼儿注视行为如何支持其发展改变视角不变的物体识别能力，并强调了高清晰度视觉区域有限大小的重要性。

Conclusion: 
本研究显示，幼儿的注视策略有助于形成变化视角不变的物体表示。中心视觉场的高清晰度区域的有限性对于此过程是至关重要的。这揭示了幼儿注视行为如何在他们发展变化视角不变的物体识别能力的过程中起到关键作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.01969</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>520. cs.AI-评估代码生成大语言模型在处理长范围依赖性方面的表现</title><link>https://arxiv.org/pdf/2407.21049</link><description>Background: 
随着语言模型支持更大的上下文范围，评估它们有效利用这些上下文的能力变得越来越重要。本研究使用一系列多步键检索任务分析了几种代码生成模型处理长时间依赖性的能力。这些任务包括了长度高达8k个标记的上下文窗口，随着任务难度的增加，能够更加全面地评估模型的能力。研究发现，当一个函数引用了另一个稍后定义的函数时，许多模型的表现会显著下降（多达2倍）；同时，使用滑动窗口注意力机制的模型在处理比单个窗口更大的引用时存在困难。通过对提示进行简单的修改，利用调用图信息，研究团队能够将多步检索的性能提高3倍，这证明了长上下文性能需要更深入的考量和改进，而不仅仅是检索文档内的单一事实。

Innovation: 
1. 使用一系列多步键检索任务来评估代码生成模型处理长范围依赖性的能力；n2. 通过对提示进行简单的修改，利用调用图信息来提高多步检索的性能；n3. 发现并证明了滑动窗口注意力机制在处理长时间依赖性时的局限性。

Conclusion: 
研究强调了在考虑大语言模型的长上下文性能时，不仅需要关注单一事实的检索，还需要更多地关注复杂的多步逻辑处理能力。此外，对滑动窗口机制有一定局限性的发现也揭示了改进这些模型的可能方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.21049</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>521. cs.AI-基于物理知识的模仿强化学习在实际驾驶中的应用</title><link>https://arxiv.org/pdf/2407.02508</link><description>Background: 
近期模仿强化学习（IRL）的进步显著增强了自主代理吸收专家演示的能力，使其在一系列具有挑战性的任务中快速获得技能。然而，基于学习的代理在高度动态的闭环环境中转移知识时面临重大挑战，其性能受到模仿学习（IL）和强化学习（RL）的矛盾优化目标、样本低效性和探索隐藏世界模型和物理复杂性的影响。

Innovation: 
本文提出了一种完全基于数据的基于物理知识的IRL方法，该方法利用专家演示数据和探索性数据，通过联合优化目标自然地从训练过程中推导出车辆动力学的基本物理原理。通过实证实验评估，该方法在Waymax基准测试的闭环设置中超出了流行的IL、RL和IRL算法，显示出与基准方法相比37.8%的碰撞率减少和22.2%的离路率减少。

Conclusion: 
该方法在闭环环境中提升了自主代理的性能，通过利用物理知识和数据驱动的方式，解决了传统IL和RL的挑战，展示了在实际驾驶任务中的显著优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.02508</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>522. cs.AI-ReconX: 使用视频扩散模型从稀疏视角重建任意场景</title><link>https://arxiv.org/pdf/2408.16767</link><description>Background: 
3D场景重建技术已经能够将现实世界的2D图像转化为3D模型，从数百张输入照片中生成逼真的3D结果。尽管在密集视角重建场景上取得了巨大成功，但当试图从不足的拍摄视图中生成详细场景时，仍然无法准确地确保3D视角一致性，导致未观察到区域出现伪影和失真。

Innovation: 
本文提出了一种新型的3D场景重建方法ReconX，将不明确的重建挑战重新定义为一个时间生成任务。ReconX 利用大规模预训练的视频扩散模型的强大生成先验信息，从稀疏视角中构建全局点云，并在给定先验条件下生成视频帧，确保场景从多个视角都具有一致性和细节保留性，通过一种基于置信度的3D高斯点积优化方案将生成的视频重建为3D场景。

Conclusion: 
在多个现实世界数据集上的广泛实验表明，ReconX 在质量和泛化能力上均优于最先进的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.16767</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>523. cs.AI-FluoroSAM：一种用于灵活X射线图像分割的语言提示基础模型</title><link>https://arxiv.org/pdf/2403.08059</link><description>Background: 
语言提示的X射线图像分割可以增强在诊断和介入精准医疗中的人在环流程的灵活性。尽管已有工作贡献了特定任务的模型，但要在更广泛的范围内应用还需额外的数据、标注和训练时间。近年来，语言对齐的基础模型（LFMs）因其在大规模且高度变化的图像和文本数据上进行训练，从而具备广泛的适用性，成为自动图像分析的有希望工具。现有的医学图像分析基础模型主要针对大型、丰富标注的数据集可用的场景。然而，X射线成像模态的特点是图像外观和应用高度变化，从诊断胸片到介入数字减影血管造影，数据可用性各不相同。现有模型难以应对这种高度变化性和大规模的应用场景。

Innovation: 
作者通过引入FluoroSAM，一款基于Segment Anything Model调整后的语言提示可变模型，使用合成的300万张X射线图像对，这些图像覆盖了广泛的人体部位、成像几何和视角，实现了自然语言提示下对多种解剖结构和工具的分割。FluoroSAM的创新之处在于训练过程中引入了文本嵌入的向量量化（VQ），这使得图像分割更加灵活和精确。此外，FluoroSAM展示了其在实际X射线图像上的性能，并在多种应用中证明了其对于丰富的人机交互在X射线图像采集和分析中的关键作用。

Conclusion: 
FluoroSAM为全面和语言对齐的医学X射线图像分析铺平了道路，并展示了其在实际X射线图像中的应用潜力，有助于推动X射线成像和分析领域的人机交互技术发展。源代码可在该链接获取。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.08059</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>524. cs.AI-模糊测试与基于大语言模型代理的结合：一种自动且高效的文本到图像生成模型攻击框架</title><link>https://arxiv.org/pdf/2408.00523</link><description>Background: 
文本到图像（T2I）生成模型已经通过将文本描述转化为高质量图像的方式革新了内容创作。然而，这些模型容易受到被称为打破牢笼攻击的漏洞影响，攻击者通过精心构造的提示绕过安全机制生成不安全的内容。尽管研究人员开发了各种打破牢笼攻击方法，但这些方法存在许多局限性，如难以实现的访问需求、容易被检测的不自然提示、受限的搜索空间和对目标系统的高查询需求。

Innovation: 
本文提出了一种名为JailFuzzer的新颖模糊测试框架，该框架通过大型语言模型（LLM）代理驱动，旨在高效生成自然且具有语义意义的打破牢笼提示，而无需完全了解目标系统。JailFuzzer采用了种子池、引导突变引擎和预言函数三个组件来生成具有意义的变体，并通过LLM代理构建了引导突变引擎和预言函数来确保在黑盒设置中的效率和适应性。实验结果表明，JailFuzzer具有在打破T2I模型方面的显著优势，能够生成自然且语义连贯的提示，降低被传统防御手段检测到的概率，并且还以其在所有关键指标上的高成功率达到最小查询开销，远超现有方法。

Conclusion: 
本研究强调了在生成模型中建立更强安全机制的需求，并为实现对抗复杂打破牢笼攻击的研究奠定了基础。JailFuzzer是开源的，并可在该仓库: this https URL 获取。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.00523</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>525. cs.AI-COBRA-PPM: 一种使用概率编程进行机器人不确定性操作的因果贝叶斯推理架构</title><link>https://arxiv.org/pdf/2403.14488</link><description>Background: 
机器人在执行操作任务时需要理解和推理因果关系以正确地与物体交互。然而，许多基于数据的方法缺乏因果意义，仅仅考虑相关性而忽略了因果推理。因此，本文提出了COBRA-PPM，一种结合了因果贝叶斯网络和概率编程的新型因果贝叶斯推理架构，旨在进行不确定性条件下的介入性推理，以改善机器人操作任务的表现。

Innovation: 
提出了COBRA-PPM架构，该架构结合了因果贝叶斯网络和概率编程，能够进行介入性推理，在不确定性条件下更加精准。通过高保真的Gazebo实验，展示了该架构的准确预测能力（预测准确率88.6%）以及高效的动作选择能力（任务成功率94.2%）。此外，还展示了该架构在现实世界场景中的迁移有效性，证明了其在传感器噪声和随机动作等不确定性情况下的处理能力。

Conclusion: 
本文提出了一种通用且可扩展的框架COBRA-PPM，支持广泛的操场景。该框架为机器人和因果关系领域的未来研究奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.14488</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>526. cs.AI-概念瓶颈模型是否遵循局部性？</title><link>https://arxiv.org/pdf/2401.01259</link><description>Background: 
基于概念的可解释性方法使用人类可理解的中介来为机器学习模型生成解释。这些方法假设概念预测可以帮助理解模型的内部推理。这项工作通过分析概念预测器是否利用“相关”特征来做出预测来评估这种假设的真实性，我们称这种特性为局部性。概念模型如果不尊重局部性，也会变得难以解释，因为基于虚假特征的概念预测，使得概念预测的解释变得空洞。为了评估概念瓶颈模型是否尊重局部性，我们构建并使用了三个度量标准来表征模型何时尊重局部性，同时通过理论结果对分析进行了补充。每个度量标准捕捉一种不同的扰动概念，并评估“无关”特征的扰动是否影响概念预测器所做的预测。我们发现，在实践中使用的许多基于概念的模型不能尊重局部性，因为概念预测器不能总是清楚地区分不同的概念。

Innovation: 
我们提出了三个度量标准来评估概念瓶颈模型是否尊重局部性，每个标准都捕捉到一种不同的扰动概念，并检查“无关”特征的扰动是否影响概念预测器所做的预测。基于这些度量标准，我们验证了许多概念瓶颈模型在实践中无法有效尊重局部性，特别是在区分不同概念方面存在困难。此外，我们还提出了缓解这一问题的建议。

Conclusion: 
许多在实践中使用的概念预测模型无法有效尊重局部性，因为在区分不同的概念时，这些模型不能总是明确地区分不同的概念。鉴于这些发现，我们提出了缓解这一问题的建议。</description><guid isPermaLink="true">https://arxiv.org/pdf/2401.01259</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>527. cs.AI-可解释强化学习的概念、算法、挑战综述</title><link>https://arxiv.org/pdf/2211.06665</link><description>Background: 
强化学习（RL）是一种机器学习范式，其中智能代理通过与环境交互来完成长期目标。深度强化学习（DRL）由于深度学习的复兴，在复杂控制任务中取得了显著的成功。然而，基于深度神经网络的模型被认为是黑箱，阻碍了其在高安全性和可靠性要求的真实场景中的应用和信任度。为了缓解这一问题，许多文献致力于揭示智能代理的内部工作原理，通过构建内在可解释性或事后可解释性。

Innovation: 
本文提供了一篇全面的可解释强化学习（XRL）综述，并提出了新的分类方式，将现有工作明确分类为模型解释、奖励解释、状态解释和任务解释方法。同时，还回顾了利用人类知识的强化学习方法以促进代理学习效率和性能，并强调了这类方法在XRL领域的忽视。讨论了XRL面临的挑战和机遇，旨在提供一个高层次的XRL总结，并激励未来在更有效的XRL解决方案上的研究。

Conclusion: 
本文旨在总结XRL，并激励未来在这个领域的更有效研究，并收集和分类了开源代码，可在以下网址查看：[这个链接]。</description><guid isPermaLink="true">https://arxiv.org/pdf/2211.06665</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>528. cs.AI-当大型语言模型与人类观点相左时？大型语言模型的奉承行为</title><link>https://arxiv.org/pdf/2311.09410</link><description>Background: 
大型语言模型展示了广泛令人满意的生成能力，这似乎归因于反复的基于人类反馈的调试与改进。然而，通过人类反馈继承的顺从性增强了模型生成与用户观点一致答案的倾向，这种行为被称为奉承。这种现象导致偏见，影响模型的可靠性和鲁棒性。本研究旨在研究大型语言模型在回答涉及主观意见的问题以及需要根据事实产生相反意见的陈述时的奉承倾向。

Innovation: 
本文通过系统性的带有人工干预提示的方法，在不同任务上分析了大型语言模型的顺从倾向。研究揭示了大型语言模型在回答涉及主观意见的问题时有倾向产生误导性答案，而在面对数学任务或具有明确答案的问题时，则能在不同规模上表现出对用户提示的忽视，显示出正确答案的自信生成。

Conclusion: 
研究发现，大型语言模型在回答涉及主观意见的问题时，倾向于产生误导性的答案，而在解决数学任务或明确答案问题时，则更倾向于生成正确的答案，不遵循用户的提示。这表明大型语言模型中存在主观性的偏见趋势，需要进行改进以减轻这种倾向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2311.09410</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>529. cs.AI-可见和红外图像输入下的低光环境行人检测：问题与挑战</title><link>https://arxiv.org/pdf/2311.08557</link><description>Background: 
行人检测已成为自动驾驶、智能交通和交通监控等高层次任务的基础。尽管在白天的可见图像中行人检测的工作已有不少，但在恶劣光线条件或夜间环境下，该任务变得更具挑战性。近期的研究转向探讨使用其他数据源（如远红外温度传感器）来检测低光照条件下的行人。这项研究综述了低光条件下行人检测的最新进展，系统地归类和分析了基于区域、非基于区域及图学习的不同算法的方法、实现问题和挑战，并强调了用于研究与开发先进行人检测算法的关键基准数据集，特别是在低光照情况下的应用。

Innovation: 
本文探讨了使用远红外温度传感器在低光照条件下进行行人检测的新方法，综述了各种基于区域、非基于区域和图学习的行人检测算法，并强调了适用的基准数据集，为研究和开发先进的行人检测算法提供了参考。

Conclusion: 
本文全面综述了低光条件下行人检测的方法和挑战，并指出了关键的基准数据集，为该领域的进一步研究和发展提供了指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2311.08557</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>530. cs.AI-科学家的第一场考试：通过感知、理解和推理探究MLLM的认知能力</title><link>https://arxiv.org/pdf/2506.10521</link><description>Background: 
科学研究越来越依赖于基于密集科学数据和领域专业知识的复杂多模态推理。虽然现有的科学基准主要评估MLLM的知识理解能力，导致对其感知和推理能力的评估不足。因此，为了改进和增强AI在科学研究中的应用，作者提出了科学家的第一场考试(SFE)基准，用于评估MLLM的科学认知能力，包括科学信号感知、科学属性理解和科学比较推理三个层次。

Innovation: 
提出了一个名为SFE的基准测试，专注于评估MLLM的感知、理解和推理能力，特别是通过科学信号感知、科学属性理解和科学比较推理这三个维度。SFE基准包含专家验证的830个VQA对，涵盖了66个跨五个高价值学科的多模态任务。研究表明，当前最先进的GPT-o3和InternVL-3在SFE上的表现仅为34.08%和26.52%，这表明MLLM在科学研究领域有很大的提升空间。

Conclusion: 
SFE的实验结果揭示了MLLM在科学认知领域中存在的显著差距，我们希望这些见解能促进AI增强科学发现的进一步发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.10521</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>531. cs.AI-大型语言模型对非洲语言的现状：进展与挑战</title><link>https://arxiv.org/pdf/2506.02280</link><description>Background: 
大型语言模型（LLMs）正在改变自然语言处理（NLP），但它们的益处尚未广泛惠及非洲的2000种低资源语言。本文比较分析了六种LLMs、八种小型语言模型（SLMs）和六种专门的小语言模型（SSLMs）对非洲语言的覆盖情况。评估涵盖了语言覆盖范围、训练数据集、技术限制、书写系统问题和语言建模路线图。研究表明，有42种支持的非洲语言和23个可用的公共数据集，但有大量的非洲语言未被支持，仅有不足2%得到了覆盖。该研究还指出，只有拉丁、阿拉伯和吉住（Ge'ez）三种书写系统被识别，而实际上有20种活动的书写系统被忽略了。面临的首要挑战包括数据不足、分词偏差、计算成本高昂以及评估问题。这些问题需要语言标准化、社区中的语料库开发以及对非洲语言的有效适应方法进程。

Innovation: 
本文首次对比分析了六种LLMs、八种SLMs和六种SSLMs对非洲语言的覆盖情况，深入探讨了语言覆盖、训练数据集、技术限制、书写系统问题及语言建模路线图。研究全面识别了支持的非洲语言和公共数据集，揭示了语言覆盖率和书写字体识别的显著差异，并提出了语言标准化、社区语料库开发及适应方法改进等针对性建议。

Conclusion: 
尽管大型语言模型在非洲语言领域取得了一定进展，但仍有大量的非洲语言缺乏有效的技术支持。研究指出，数据不足、书写系统忽视和评估困难是主要挑战。未来需要加强社区合作来开发专用语料库，提高技术水平，并制定有效的适应方法来推动非洲语言技术和应用的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.02280</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>532. cs.AI-综合AI技术实现响应式多轮在线对话的新颖动态路由和反馈自适应</title><link>https://arxiv.org/pdf/2506.02097</link><description>Background: 
检索增强生成（RAG）系统和由大型语言模型（LLM）驱动的聊天机器人极大地推动了对话式AI的发展，它们通过将生成能力与外部知识检索结合起来实现这一点。尽管取得了成功，但在企业级部署中仍然面临着关键挑战，包括多样的用户查询、高延时、幻觉以及难以整合频繁更新的专业领域知识。目前的RAG和意图驱动系统存在这些不足，而本文提出的新颖混合框架正是为解决这些问题而设计的。

Innovation: 
本文提出了一种新的混合框架，该框架将RAG与基于意图的预定义响应相结合，利用预定义的高置信度响应提高效率，并将复杂或模糊的查询动态地路由到RAG管道。此框架通过对话上下文管理器确保多轮交互中的连贯性，并通过反馈环路改进意图，动态调整置信度阈值，并随时间扩展响应覆盖范围。实验结果表明，该框架在高准确率（95%）和低延时（180ms）方面实现了平衡，其表现优于RAG和基于意图的系统，适用于多种查询类型，并定位为企业对话式AI应用中的可扩展和适应性解决方案。

Conclusion: 
该框架通过提供平衡准确性和低延时性能，展示了其作为企业对话式AI应用中可扩展和适应性解决方案的潜力。通过动态路由和反馈自适应机制，实现对多样化企业级查询的有效处理，提升了整体对话质量。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.02097</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>533. cs.AI-Turing Test 2.0: The General Intelligence Threshold</title><link>https://arxiv.org/pdf/2505.19550</link><description>Background: 
随着人工智能（A.I.）和大型语言模型（如ChatGPT）的兴起，实现通用人工智能（A.G.I.）的新竞赛已经启动。尽管人们推测A.I.何时可以达到A.G.I.，却很难确定在何种程度下可以检测到A.G.I.，即便是使用图灵测试（及其现代变体）这样的主流工具也无法明确识别出A.G.I.的到来。因此，本文讨论了传统测试方法如图灵测试不足以衡量A.G.I.的局限性，并提出了一种新的实用方法，以判断一个系统是否达到了或超越了A.G.I.。

Innovation: 
本文提出了两个新的贡献：第一，提供了清晰的通用智能（G.I.）定义，并设定了通用智能阈值（G.I.T.），以区分达到A.G.I.的系统和未达到的系统；第二，提出了一种新的框架，用以构建检测系统是否达到通用智能的简单、全面且明确测试。这一新框架被称为图灵测试2.0，并通过实际例子展示了其应用于现代A.I.模型的方法。

Conclusion: 
本文提出了一种新的图灵测试2.0框架，用于检测系统是否达到通用智能，并通过实际例子展示了其在现代A.I.模型中的应用，从而对A.G.I.的检测提供了一种新的实用方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.19550</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>534. cs.AI-加权平均频率：用于4D Flow MRI分割的手工傅里叶特征</title><link>https://arxiv.org/pdf/2506.20614</link><description>Background: 
近年来，4D Flow MRI图像的使用使得能够量化感兴趣区域内的速度场并沿心动周期变化。然而，这些生物标志物的分辨率不足和存在噪声是重大问题。研究表明，血流脉冲方向的不准确性尤为受低分辨率血管分割的影响。目前，相位对比磁共振血管造影（PC-MRA）是先进的分割技术。本文旨在介绍一个新的手工特征，该特征为4D Flow MRI图像提供了新颖的可视化方法，有助于分割任务。这个特征被称为加权平均频率（WMF），能够揭示在三维空间中脉冲流通过的区域。WMF特征代表了所有脉冲速度体素的外壳。

Innovation: 
加权平均频率（WMF）是一种新的手工构造的傅里叶特征，用于4D Flow MRI图像的分割。该特征能有效区分脉冲血流通过的区域，并且在实验中表现出优秀的性能，提高了IoU和Dice指数，特别是在与PC-MRA特征进行比较时分别提高了0.12和0.13。这项研究成果为其他血管区域（如心脏或大脑）的分割提供了价值，能够为未来的分割过程提供宝贵的信息和新的见解。

Conclusion: 
通过两个实验表明，加权平均频率（WMF）特征在分割4D Flow MRI图像方面表现出显著的改善，特别是在使用深度学习方法时，比PC-MRA特征分别提高了0.12和0.13的IoU和Dice。这种特征有望在其他血管区域的分割中提供有价值的信息，促进分割技术的进一步发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20614</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>535. cs.AI-Define-ML：一种构思包含机器学习系统的办法</title><link>https://arxiv.org/pdf/2506.20621</link><description>Background: 
随着机器学习（ML）在软件系统中的广泛应用，传统的想法生成方法，如精益开端，缺乏针对ML特定挑战（如数据依赖性、技术可行性及业务目标与概率性系统行为之间的对齐）的结构化支持，这可能导致产品愿景与企业目标不一致，并产生不切实际的期望。为此，需要一种专门针对ML想法生成的方法。

Innovation: 
本文提出了Define-ML框架，该框架是Lean Inception的延伸，加入了专门为ML设计的活动：数据来源映射、特征到数据来源映射及ML映射，用于系统地集成数据和技术约束于早期的ML产品想法生成中，提高了业务目标与ML能力的对齐，并促进了跨功能团队之间的合作。开发和验证阶段采用了技术转移模型，通过静态和动态验证结合定量调查和定性反馈，评估其实用性和易用性，包含技术可行性意识的提高。

Conclusion: 
Define-ML提供了一种开放获取且经过验证的方法，用于ML产品想法生成，延续了Lean Inception的敏捷性，同时确保特性与可用数据相匹配，增加了技术可行性的意识。所有参与者均表示愿意采用Define-ML。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20621</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>536. cs.AI-$C^3$-Bench: 多任务中真正干扰基于大语言模型的代理的基准</title><link>https://arxiv.org/pdf/2505.18746</link><description>Background: 
基于大语言模型的代理利用工具修改环境，革新了AI与物理世界的交互方式。与仅依赖历史对话的传统NLP任务不同，这些代理在做决策时必须考虑更复杂的因素，如工具间的相互关系、环境反馈和之前的决定。当前的研究通常通过多轮对话来评估代理，但忽略了这些关键因素对代理行为的影响。

Innovation: 
本文提出了一种开源且高质量的基准$C^3$-Bench。该基准整合了攻击概念并使用单变量分析来确定影响代理稳健性的关键因素。本文设计了三个挑战：导航复杂的工具关系、处理关键隐藏信息和管理动态决策路径。此外，引入了细粒度的度量标准、创新的数据收集算法以及可重复的评估方法。

Conclusion: 
广泛的实验在49种主流代理上进行，涵盖了通用快思型、慢思型和领域特定模型。我们观察到，代理在处理工具依赖性、长上下文信息依赖性和频繁的策略切换方面存在重大缺陷。$C^3$-Bench旨在通过这些挑战揭示模型漏洞，并推动代理性能可解释性的研究。基准已公开发布。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.18746</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>537. cs.AI-在你内心有许多狼：使用认知模型解读LLMs中的价值权衡</title><link>https://arxiv.org/pdf/2506.20666</link><description>Background: 
日常生活中的社交情境往往需要在冲突目标之间进行权衡，比如传递一个严峻的真相、保持信任的同时还要考虑他人的感受。这些价值权衡是人类决策和语言使用的重要组成部分，但目前现有的工具在解释大型语言模型（LLMs）中动态和多层次的价值观方面仍然有限。认知科学中的认知模型为人类这些权衡提供正式的解释，通过建模说话者在选择行动或语句时的相互冲突的效用函数权重。本文旨在利用一个领先的礼貌言语认知模型来解读LLMs在价值权衡上的表现。

Innovation: 
本文创新性地使用认知模型，以理解LLMs中的价值权衡，这填补了现有工具的空白。研究采用了一个认知模型来评估两种模型设置中的价值权衡：推理努力程度的黑盒模型前沿以及开源模型的强化学习后训练动态。研究揭示了推理模型中较高的信息效用而不是社会效用，以及在数学推理表现更强的开源模型中类似的现象。研究发现表明，大型语言模型在训练初期有显著的效用值变化，这些影响受基础模型和预训练数据的选择持久影响，而与反馈数据集或对标方法的选择无关。

Conclusion: 
研究发现表明，需要不断改进Training动态以更好地控制模型训练中价值之间的权衡。该方法可以灵活地适应快速变化的LLM格局，为形成关于其他高层次行为的假设、设计推理模型的训练阶段和更好地控制模型训练中的价值权衡提供见解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20666</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>538. cs.AI-DeepQuark：多夸克束缚态的深度神经网络方法</title><link>https://arxiv.org/pdf/2506.20555</link><description>Background: 
首次使用基于深度神经网络的变分蒙特卡洛方法来处理多夸克束缚态，这种系统的复杂性远超电子或核子系统，主要是由于强SU（3）色相互作用。为了解决多夸克系统中的强相关性、额外的离散量子数以及难以处理的束缚作用，我们设计了DeepQuark新型高效架构。该方法在核子、双重重夸克四夸克态和完全重夸克四夸克态系统中与最先进的方法（如扩散蒙特卡洛和高斯展开方法）具有竞争力，特别是在五夸克态中超越了现有计算，例如三重重夸克五夸克态。在核子系统中，我们成功地引入了三体管状束缚相互作用，而没有增加额外的计算成本。在四夸克系统中，我们一致描述了重夸克分子T_{cc}和紧凑四夸克T_{bb}，使用了无偏的形式波函数变分原理。在五夸克领域，我们得到了弱束缚的D^* Ξ_{cc}^* 分子P_{ccbar c}(5715) 和其底组分P_{bbbar b}(15569)，它们可以被视为分子T_{cc}的类比物。我们建议在D-波J/ψ Λ_c通道搜索P_{ccbar c}(5715)。DeepQuark在处理更大规模的多夸克系统时充满前途，有望克服传统方法中的计算障碍。它还将作为探索超出两体相互作用的束缚机制的强大框架，为非微扰QCD和一般的多体物理提供宝贵的见解。

Innovation: 
首次使用基于深度神经网络的变分蒙特卡洛方法来处理多夸克束缚态，特别注意到了强大的SU（3）色相互作用。通过设计新的架构DeepQuark，解决了多夸克系统中的强相关性、额外的离散量子数和难以处理的束缚问题。在核子、四夸克和五夸克系统中，DeepQuark展示了与最先进的方法（如扩散蒙特卡洛和高斯展开方法）相竞争甚至是超出它们的性能。特别是在五夸克系统中的滚动计算表现出色，说明了其在更大和更复杂的多夸克系统中的潜力。这种方法还为探索超出两体相互作用的束缚机制提供了强有力的支持，为非微扰QCD和一般多体物理提供了新的视角。

Conclusion: 
DeepQuark在处理多夸克束缚态中表现出卓越性能，并超越了现有方法在五夸克中的计算结果。除了在核子系统中成功引入了三体管状束缚相互作用外，在四夸克系统中我们一致描述了重夸克分子T_{cc}和紧凑四夸克T_{bb}。在五夸克系统中，我们得到了弱束缚D^* Ξ_{cc}^* 分子P_{ccbar c}(5715) 和其底组分P_{bbbar b}(15569)，建议在D-波J/ψ Λ_c通道搜索P_{ccbar c}(5715)。DeepQuark有望被扩展到更大的多夸克系统中解决计算障碍问题，有助于对非微扰QCD和多体物理进行深入研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20555</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>539. cs.AI-RefPentester: 一种基于大规模语言模型的知识启发式自反思渗透测试框架</title><link>https://arxiv.org/pdf/2505.07089</link><description>Background: 
自动化渗透测试（AutoPT）正因其能够通过利用大规模语言模型（LLMs）的内在知识自动化伦理黑客攻击过程，并识别目标系统的漏洞而受到关注。然而，现有的基于LLM的AutoPT框架在某些挑战性任务中往往表现不佳，原因包括LLM训练使用了不平衡的知识、计划过程的短视，以及命令生成过程中的幻觉。此外，由于现有的框架缺乏机制从过去的失败中学习，AutoPT策略的适应性改进受到限制。

Innovation: 
本文提出了一种基于LLM的知识启发式自反思渗透测试框架，称为RefPentester。该框架旨在帮助人类操作者识别当前的PT阶段，并为每个阶段选择适当的策略和技术，执行建议的操作，提供逐步操作指导，反思并从以往的失败中学习。RefPentester将PT过程建模为一个七阶段状态机，以有效地整合所提出的框架。试验结果显示，RefPentester在揭示Hack The Box平台Sau机器上的凭据方面比基线GPT-4o模型成功16.7%，且在PT阶段转换成功率方面表现更优。

Conclusion: 
RefPentester通过利用丰富的知识和自反思机制，实现了PT策略的有效增强和学习，在一定程度上解决了现有框架的不足。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.07089</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>540. cs.AI-自细，我自己来合并：一种多保真自动模型合并框架</title><link>https://arxiv.org/pdf/2502.04030</link><description>Background: 
大型语言模型（LLMs）的推理能力代表了一个重要的创新领域，但开发这些能力需要大量的专有数据集和计算资源。通过模型合并效率地补充这些能力是一种可行的方式，这种方法可以在不重新训练的情况下将多个模型合并起来。然而，当前的合并方法依赖于手动设计的策略来合并超参数，这限制了潜在模型组合的探索范围，需要大量的人工努力。

Innovation: 
提出了一种自动模型合并框架，该框架通过使用多保真近似方法，允许对合并策略进行细粒度探索，并降低成本。该框架支持单目标和多目标优化，并引入了两个新的搜索空间：层内融合（LFS）和深度融合（DIS）。通过多个基准测试评估，该搜索能够自主找到能够提升单目标性能的合并，甚至在模型已经在之前微调的任务上也能进一步提升性能，并且能够在多种任务中优化多目标前沿。有效的合并用较少的计算资源即可发现，例如在不到500次搜索步骤内被发现。

Conclusion: 
自动模型合并框架能够在低成本的情况下进行高效探索，同时支持多种优化目标，并且能够提高模型在各种任务中的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.04030</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>541. cs.AI-通往更好的归纳知识图完成基准数据集</title><link>https://arxiv.org/pdf/2406.11898</link><description>Background: 
知识图完成（KGC）旨在预测知识图（KG）中的缺失事实。近年来，越来越多的研究关注设计能够在归纳场景中表现出色的KGC方法，即在推理时观察到的实体和关系部分或全部在训练期间未被观察到。为此，诸多用于归纳KGC基准测试的数据集已被提出，这些数据集是现有用于传递学习KGC知识图的子集。然而，作者发现现有的构建归纳KGC数据集的流程无意中创造了一条捷径，即使忽略了关系信息，这种方法也可以被利用。例如，观察到基于Personalized PageRank（PPR）得分的性能在大多数数据集上非常优秀或接近最优性能。

Innovation: 
本文研究了这一问题的根本原因，并提出了一种替代的归纳KGC数据集构建策略，旨在减轻PPR捷径的影响。作者利用新的构建策略重新评估了多个流行的KGC方法，并分析了它们的表现，以帮助去除任何混淆性能表现的捷径，从而促进对归纳KGC能力及挑战的更深刻理解。研究提供了新的基准数据集和相关代码。

Conclusion: 
新的基准数据集有助于更好地理解并揭示归纳KGC的真实性能，而不会被任何捷径所混淆。相关代码与数据集可在此处找到：this https URL.</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.11898</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>542. cs.AI-微生物显微图像的解纠缠表示</title><link>https://arxiv.org/pdf/2506.20649</link><description>Background: 
显微镜图像分析在诊断、合成工程和环境监测等多个应用领域中有重要作用。现代成像系统使得获取大量图像成为可能，但同时也需要提高自动图像分析方法的性能。尽管深度神经网络在显微镜图像分析中表现出色，但模型解释性仍是一个开放性问题。

Innovation: 
本文提出了一种解纠缠表示学习（DRL）方法，以提高显微镜图像分类模型的解释性。通过利用来自三个不同类型显微图像领域的基准数据集（浮游生物、酵母液泡和人类细胞），证明了基于合成数据学习的表示移转的DRL框架能够在准确性和解释性之间取得良好平衡。

Conclusion: 
研究表明，DRL框架在显微镜图像领域能够提供良好的解释性和准确性之间的权衡，具有重要的应用价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20649</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>543. cs.AI-通过枪声记录的声学分析剖析枪型层次</title><link>https://arxiv.org/pdf/2506.20609</link><description>Background: 
近年来枪支暴力和大规模枪击事件的频率上升，对公共安全构成了重大威胁。及时准确的信息对于执法机构减轻这些事件至关重要。目前有效但成本高昂的商用枪声检测系统成为了研究热点。该研究旨在通过利用智能手机等普遍设备中的声学分析技术，提出一种低成本的替代方案，不仅能检测枪声，还能分类使用的枪支类型。研究基于3459个枪声记录构建了一个数据集，探讨不同类型枪支发射时的声学特征差异。

Innovation: 
研究提出并评估了基于支持向量机（SVM）和卷积神经网络（CNN）的机器学习框架，用于联合枪声检测和枪支类型分类。利用深度学习方法在清洁标记数据上的平均精确度（mAP）达到0.58，超过了SVM基线（mAP 0.39）。研究还讨论了数据质量和环境噪声等因素带来的挑战以及在使用噪声较大的网络数据时的泛化能力。

Conclusion: 
该研究长期目标是开发一种高度准确、实时的系统，可在普通录音设备上部署，显著降低检测成本，并向急救人员提供关键情报。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20609</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>544. cs.AI-AI在写作过程中的作用：如何有针对性的AI支持促进学生写作</title><link>https://arxiv.org/pdf/2506.20595</link><description>Background: 
类似ChatGPT这样的技术的普遍性引发对其对学生写作影响的担忧，特别是有减少学习者自主性和表面化内容互动的趋势。虽然基于聊天的大型语言模型（LLM）独自使用时往往无法达到最佳写作效果，但研究表明，有针对性设计的AI写作支持工具能够提升写作过程。本文旨在探讨不同AI支持方法如何影响作者的自主性和知识深度的理解过程。

Innovation: 
本文通过随机对照实验，将90名本科生分配到三个条件组中：（1）基于聊天的LLM写作助手，（2）集成的AI写作工具辅助多样化 subprocesses，（3）标准写作界面（对照组）。研究结果表明，在AI支持条件下，使用集成AI写作工具的学生在写作过程中表现出更强的自主性，并且更深入地理解了知识。这些结果表明，针对写作过程特定方面的精心设计AI写作支持可以帮助学生保持他们作品的所有权，同时促进他们对内容的更深入参与。

Conclusion: 
研究发现，有针对性设计的AI写作支持工具能在提升作者的自主性和促进更深层次的知识理解方面发挥重要作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20595</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>545. cs.AI-基于图的句段总结的稠密视频描述</title><link>https://arxiv.org/pdf/2506.20583</link><description>Background: 
最近，稠密视频描述在检测和描述长时间未修剪视频中的所有事件方面取得了令人瞩目的进展。尽管取得了令人鼓舞的结果，但现有的大多数方法并未充分探索事件时间提案内的场景演变，因此在场景和对象在相对较长时间段内发生变化时表现不佳。为了应对这一问题，我们提出了一种基于图的分割和总结（GPaS）框架，用于分割和总结事件内的稠密视频描述，分两阶段进行。

Innovation: 
提出了一种两阶段的图基于句段总结框架。在分割阶段，事件提案被细分为更短的视频片段进行描述。总结阶段将为每个片段生成的携带丰富描述信息的句子总结为一句话描述整个事件。特别关注总结阶段，提出了一种有效利用语义词之间关系的框架，将其作为图中的节点，通过结合图卷积网络（GCN）和长短期记忆网络（LSTM）学习它们的交互，并利用视觉线索。提出了两种GCN-LSTM交互（GLI）模块方案，实现GCN和LSTM的无缝集成。

Conclusion: 
通过在ActivityNet Captions数据集和YouCook II数据集上与最先进的方法进行广泛比较，展示了我们方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20583</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>546. cs.AI-通过观测分组进行因果表示学习以改进胸部X光分类</title><link>https://arxiv.org/pdf/2506.20582</link><description>Background: 
在医学影像领域，因果表示学习旨在揭示数据生成过程背后的真正因果关系，从而提高任务特定隐含特征的泛化能力和鲁棒性。本文介绍了一种通过端到端框架将观测数据分组来学习疾病分类的因果表示方法，特别是在胸部X光分类中。通过分组来确保种族、性别和成像视角的不变性以提升这些表示的泛化能力和鲁棒性

Innovation: 
本文创新性地提出了一种通过观测分组来学习可用于疾病分类的因果表示的新方法。该方法通过端到端框架实现，旨在通过保证种族、性别和成像视角的不变性来改进表示学习的结果，提高模型在多种分类任务中的泛化能力和鲁棒性

Conclusion: 
我们的实验表明，通过观测分组学习到的因果表示可以显著提高多类分类任务的泛化能力和鲁棒性。该方法为医学影像分析中的疾病分类提供了一种新的、更有效的解决方案</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20582</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>547. cs.AI-通过适应性黑盒对抗攻击披露NIDS漏洞</title><link>https://arxiv.org/pdf/2506.20576</link><description>Background: 
对抗攻击，即通过精心构造的微小输入误导智能模型，已成为研究热点。然而，理论进展与实际应用之间仍存在关键差距，特别是在网络流量等结构化数据中，互相关特征使得有效的对抗操纵复杂化。此外，当前方法中的模糊性限制了可重现性，阻碍了该领域的发展。因此，现有的防御措施往往无法应对不断演变的对抗攻击。

Innovation: 
本论文提出了一种针对网络流量的新型黑盒对抗攻击方法，解决了现有方法的局限性。不同于以往工作通常假设系统访问或依赖多次探测，本方法严格遵守黑盒约束，减少了交互以避免检测，更好地反映了真实世界的场景。本方法采用适应性特征选择策略结合变化点检测和因果分析，以识别和针对敏感特征进行扰动。这一轻量级设计确保了低计算成本和高的可部署性。我们的全面实验展示了该攻击在最少交互的情况下逃避免检测的有效性和可适应性，显著提升了其实用性，适用于真实场景。通过加深对网络流量中对抗攻击的理解，本工作为进一步开发健壮的防御系统奠定了基础。

Conclusion: 
本研究通过先进的适应性策略和特征选择方法，有效扩展了对抗攻击在网络安全中的应用，并为其提供了更强大的防御路径，为不断发展中的网络安全研究做出了贡献。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20576</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>548. cs.AI-具有多变量并行注意机制的生成神经活动的基模型</title><link>https://arxiv.org/pdf/2506.20354</link><description>Background: 
多变量时间序列数据的临床领域，特别是颅内电encephalography (iEEG) 中，其通道配置在不同主体间差异极大，对DNNs来说这是一个基础挑战。基于此背景，该研究提出了一种新型的自注意力机制MVPA，能够灵活、泛化和高效地建模具有不同通道数和配置的时间序列数据。MVPA被应用于构建MVPFormer，这是一种用于人类电生理学的生成基础模型，被训练用于预测跨多种主体的iEEG信号演变。为了支持这一领域未来的工作，该论文还发布了迄今为止最大的公共iEEG数据集SWEC-iEEG，包含近10,000小时来自异质临床来源的记录。

Innovation: 
该研究提出了MVPA，这是一种新型的自注意力机制，能够将内容、时间和空间注意力分开，适用于具有不同通道数和配置的时间序列数据。在此基础上，构建了MVPFormer，这是一种用于人类电生理学的生成基础模型，能够实现跨主体的强泛化性能，显示出在癫痫检测方面的专家级性能，并在包括SWEC、MAYO和FNUSA数据集在内的多个基于Transformer的基本模型上表现出色。此外，MVPA在标准时间序列预测和分类任务中表现出色，能够匹配或超过现有的基于注意力的模型。此工作为泛用时间序列注意力机制奠定了基础，将MVPFormer确立为首个开源的iEEG基础模型，具有最佳的临床性能。

Conclusion: 
我们的研究成果确定了MVPA作为一种通用的注意力机制，适用于不同的时间序列数据，同时也确立了MVPFormer作为首个开源的iEEG基础模型，具有最先进的临床性能。相关代码和数据集的技术仍未公布，但已提供在线访问链接。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20354</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>549. cs.AI-WattsOnAI：测量、分析和可视化AI工作负载的能源和碳足迹</title><link>https://arxiv.org/pdf/2506.20535</link><description>Background: 
随着人工智能（特别是大规模语言模型）的快速发展，模型训练和推理过程中的能源消耗和碳排放引起了广泛关注。然而，现有的工具在衡量和报告此类影响时常常碎片化，缺乏系统化的度量指标集成，并且支持对这些工具之间的关联性分析较为有限。因此，该领域需要一个综合性的解决方案，以衡量、分析并可视化人工智能工作负载中的能源和碳足迹。

Innovation: 
该论文提出了一款名为WattsOnAI的综合性软件工具包，用于衡量、分析和可视化各类人工智能工作负载中的能源使用、电力消耗、硬件性能和碳排放，通过与现有的人工智能框架无缝集成，提供标准化报告和导出详尽的时间序列数据，支持轻量级基准测试和可重复性研究。WattsOnAI进一步通过深入分析硬件指标和模型性能之间的关联性，以识别瓶颈并提升性能，解决了现有工具的关键局限性，推动了环境影响与人工智能工作负载的原始性能并重的研究，并促进了更加可持续的绿色AI实践。

Conclusion: 
WattsOnAI通过解决当前工具的局限性，鼓励研究社区在衡量人工智能工作负载的原始性能的同时考虑其环境影响，并推动了向更加可持续的绿色AI实践的转变。代码可在以下网址获取：this https URL.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20535</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>550. cs.AI-当生活给你样本：提升多语言大语言模型推理计算规模的好处</title><link>https://arxiv.org/pdf/2506.20544</link><description>Background: 
近年来，大规模语言模型（LLMs）的研究重点转向了在推理时间提升计算规模，以在不重新训练模型的情况下改善性能。一种常见方法是并行采样多个输出，然后从中选择一个作为最终输出。但是，目前的工作主要集中在英语和少数几个领域，如数学和代码。相比之下，作者更关注能够跨开放任务、形式验证任务和多种语言推广的技术。因此，本研究探讨了如何在多语言、多任务设置中稳健地扩大推理时间的计算规模。研究表明，采样策略和选择策略都需要根据不同的领域和语言环境进行调整。已有选择方法在英语中有效，但在其他语言中难以泛化。因此，作者提出了适合多语言和多任务推理场景的新采样和选择策略，这些策略在不同语言和任务中表现出显著的提升效果。特别是在m-ArenaHard-v2.0提示上，作者的8B模型结合新的采样和选择方法，相比专用模型如Gemini平均提高了6.8%的胜率。对于更大的规模，Command-A（111B模型）使用这些方法，在同样的基准测试上，仅使用五个样本就比单样本解码提高了9.0%的胜率，这项改进在成本极低的情况下取得了显著提升。研究结果强调了语言和任务感知的推理时间计算方法的重要性，旨在促进欠代表语言性能的提升.

Innovation: 
作者提出并研究了适用于多语言和多任务推理场景的新采样策略和选择策略。这种方法在多种语言和任务中展示了显著的改进。特别是在m-ArenaHard-v2.0提示上，对比已有的专用模型如Gemini，其8B模型的胜率平均提升了6.8%。更大规模模型Command-A（111B模型）则显示出在相同基准测试上使用五个样本与单样本解码相比，胜率提高了9.0%，且成本极低。这项研究强调了需要根据不同语言和任务进行适应性的推理时间计算方法的重要性，以便于普及到更广泛的语言中，提升其性能表现，尤其是那些欠代表的语言。

Conclusion: 
研究结果证实了语言和任务感知的推理时间计算方法的重要性和必要性。通过开发适应多语言和多任务的采样和选择策略，能够有效提升广泛使用的多语言大语言模型的性能，尤其是在为那些被广泛忽视的语言实现绩效提升方面。未来的工作可能会探索更多应用场景下的多语言大语言模型的使用和优化。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20544</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>551. cs.AI-使用视觉线索辅助句子总结的Show, Tell and Summarize：密集视频字幕生成</title><link>https://arxiv.org/pdf/2506.20567</link><description>Background: 
在密集视频字幕生成任务中，以往的方法通常将长视频分割成多个事件提案，然后为每个提案生成一个描述性句子，但这些方法往往难以综合和总结多段视觉信息中的丰富语义内容。现有方法大多专注于单段视频内容的描述生成，缺乏有效的视觉信息与文本描述的融合机制，从而影响了整体字幕的生成效果和描述的全面性.

Innovation: 
本文提出了一种分割与总结(DaS)框架，该框架首先将每个长视频分割成多个事件提案，每个提案包含一系列短视频片段。通过现有的图像/视频字幕生成方法为每个片段生成描述性句子，然后引入视觉线索辅助的句子总结方法。新方法利用两阶段长短期记忆（LSTM）网络和层次注意机制，有效结合了视觉特征和生成的句子语义，生成对整个事件提案的描述性总结句子.

Conclusion: 
通过在ActivityNet Captions数据集上的全面实验，验证了基于分割与总结框架的密集视频字幕生成方法的有效性，表明该方法能够生成更为准确和全面的视频字幕描述.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20567</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>552. cs.AI-使用数字孪生生成的数据集和高效数据增强方法进行工业能耗分解</title><link>https://arxiv.org/pdf/2506.20525</link><description>Background: 
工业非侵入式负荷监测（NILM）受限于高质量数据集稀缺和工业能耗模式复杂多变。为了解决数据稀缺和隐私问题，本文提出了一种合成工业能耗分解数据集（SIDED），该数据集使用数字孪生模拟生成。SIDED包含来自三个不同地理区域的三种类型的工业设施，涵盖了各种电器行为、天气条件和负载特性。此外，本文还提出了一种新型的数据增强方法——电器调制数据增强（AMDA），该方法通过智能化地调整电器功率贡献，提高了NILM模型的一般化能力，特别是在处理复杂的工业电器如热电联供系统时效果显著。实验结果表明，使用AMDA增强的数据训练的NILM模型在分解复杂工业电器的能耗方面的性能显著提升，特别是在测试场景下实现了0.093的归一化分解误差，明显优于未使用数据增强和随机数据增强的模型

Innovation: 
引入了合成工业能耗分解数据集（SIDED）以及一种新型的数据增强方法——电器调制数据增强（AMDA）。SIDED通过数字孪生模拟生成，涵盖了不同类型的工业设施及其负载特性。AMDA通过智能化调整电器功率贡献来提高模型一般化能力，特别是在处理复杂工业电器时效果显著。实验结果显示使用AMDA增强的数据训练的模型，在分解能耗方面显著优于其他模型

Conclusion: 
本文通过使用SIDED数据集和AMDA数据增强方法，显著提高了工业能耗分解模型在复杂工业电器上的分解能力，尤其是在测试场景下的回归分解误差明显降低</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20525</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>553. cs.AI-Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks</title><link>https://arxiv.org/pdf/2506.20548</link><description>Background: 
随着深度学习的快速推进，特别是生成对抗网络（GANs）和扩散模型（DMs）的发展，人工智能生成的图像（称为“深伪”）变得几乎与真实图像难以区分。这些图像在在线社交媒体网络（OSNs）上广泛传播，引发了对其误用的担忧。现有的深度伪检测方法忽视了OSNs中由于压缩引入的‘块效应’，这种效应会掩盖伪内容，它们主要集中在原始图像上，但在现实场景中很少遇到这些问题。

Innovation: 
该研究提出了PLADA（Pay Less Attention to Deceptive Artifacts）框架，旨在应对配对数据缺乏和压缩图像未有效利用的问题。PLADA包含两个核心模块：块效应消除器（B2E）和开放数据聚合器（ODA），前者利用双重注意力机制处理块效应，后者处理配对和非配对数据以提高检测效果。实验证明，PLADA在检测OSNs中的深伪方面表现出色，即使在有限的配对数据和压缩情况下也能取得好成绩。更重要的是，这项工作将‘块效应’列为深伪检测中的关键因素，为开放世界场景提供了稳健的解决方案。

Conclusion: 
广泛的数据集实验表明，PLADA在OSNs中检测深伪的能力达到最佳平衡，即使在有限的配对数据和压缩条件下也超过了最先进的方法。该工作强调‘块效应’对于深伪检测的重要性，并为开发更强大、更适应现实世界变化的检测方法奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20548</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>554. cs.AI-Large Language Model-Driven Code Compliance Checking in Building Information Modeling</title><link>https://arxiv.org/pdf/2506.20551</link><description>Background: 
建筑信息模型（BIM）中的手动代码合规检查耗时且容易出错。本文研究通过引入以大型语言模型（LLM）驱动的方法，旨在部分自动化这一关键流程，以解决这一问题。

Innovation: 
本文提出了一种结合LLM（如GPT、Claude、Gemini和Llama）与Revit软件的系统，用于解释建筑代码、生成Python脚本，并在BIM环境中进行半自动合规性检查。该系统能显著减少合规检查所需的时间与努力，提高准确性，并能自动识别违规情况，生成指导性的报告。相比手动方法，该系统消除了重复任务，简化了复杂的规定，确保了标准的可靠遵守。此外，该方法提供了全面、可适应且成本效益高的解决方案，具有在建筑项目中多种规范文件的应用潜力。

Conclusion: 
本文提出的以大型语言模型驱动的BIM合规检查方法，为建筑信息模型中合规检查的自动化提供了有力的支持，具有广泛的适用范围和前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20551</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>555. cs.AI-OctoThinker: 中训练激励强化学习扩展</title><link>https://arxiv.org/pdf/2506.20512</link><description>Background: 
基座语言模型（如Llama和Qwen）在强化学习后训练过程中表现出不同的行为，尤其是在需要大量推理的任务上。了解哪些基座语言模型适合强化学习至关重要。本文研究了中训练策略对强化学习动力学的影响，特别是在Qwen和Llama这两种代表性模型系列上。研究表明：高质量的数学语料库（如MegaMath-Web-Pro）能够显著提高基座模型和强化学习性能，而现有替代方案（如FineMath-4plus）则没有这种效果；通过添加具有长链式推理的例子，增强型问题解答数据能够进一步提升强化学习结果，而指令数据则进一步强化这一效果；长链式推理虽然提升了推理深度，但也可能导致模型响应冗长和强化学习训练不稳定性增加，强调了资料格式的重要性；中期训练的扩展性训练一致地带来了更好的下游强化学习性能。

Innovation: 
介绍了双阶段中期训练策略：Stable-then-Decay，首先使用200亿个令牌以恒定学习率训练基模型，然后以学习率衰减的方式在三个专注于链式推理的分支中训练20亿个令牌。这种方法产生了一个鲁棒性好、与更友好的强化学习模型相媲美的基座语言模型家族，即OctoThinker。同时，还发布了一个包含超过700亿个令牌的精选数学推理密集型语料库（即MegaMath-Web-Pro-Max），以支持进一步研究。

Conclusion: 
本文的工作有助于理解如何设计基座模型的预训练策略，以适应强化学习时代。通过深入研究中期训练策略对强化学习的影响，揭示了如何更好地利用丰厚数据以提升模型性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20512</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>556. cs.AI-作为分布量的反事实影响</title><link>https://arxiv.org/pdf/2506.20481</link><description>Background: 
机器学习模型因记住训练数据中的样本而闻名，这引发了隐私和泛化的担忧。反事实自影响是一个常用的度量标准，用来研究这一现象，量化模型预测如何随着样本包含在训练数据集中的情况而变化。然而，最近的研究表明，记忆不仅仅受自影响的影响，其他训练样本，尤其是（准）副本，对记忆有重大影响。本文研究了反事实影响作为分布量的事务，考虑所有训练样本如何影响每个样本的记忆过程。我们发现，仅依靠自影响可能会严重低估记忆带来的实际风险，尤其是在存在（准）副本的情况下，尽管这些样本可能容易被提取。我们还在图像分类领域观察到类似的趋势，通过观察影响分布可以揭示CIFAR-10中的（准）副本存在情况。这种发现强调了记忆源自训练数据间的复杂交互，而需要全面的影响分布而非单独的自影响来更好地捕捉这一现象。

Innovation: 
本文主要创新之处在于将反事实影响作为分布量进行研究，而不仅仅是关注自影响。这种方法考虑了所有训练样本如何共同影响单个样本的记忆过程，从而提供了更全面的记忆影响分析视角。此外，该研究在小规模语言模型和图像分类任务中展示了如何计算和分析这些影响分布，揭示了训练样本间（准）副本的作用.

Conclusion: 
本文的研究发现，记忆现象源于训练数据之间的复杂交互，不应仅通过自影响来衡量和理解。相反，应通过全面的影响分布来更好地捕捉这一现象。特别是，存在（准）副本会影响单个样本的自影响，但这些样本却是容易被提取的。这些发现强调了全面理解和分析记忆背后复杂交互的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20481</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>557. cs.AI-ReCode: 使用强化学习更新代码API知识</title><link>https://arxiv.org/pdf/2506.20495</link><description>Background: 
大型语言模型（LLMs）展现出卓越的代码生成能力，但在应对外部库API频繁更新时却表现不佳。这一关键限制源自它们依赖于训练数据中的过时API知识，即使有当前文档的访问权，也会阻碍动态环境中的代码生成可靠性。

Innovation: 
我们提出了ReCode（基于规则的强化学习代码更新框架），该框架模仿人类程序员对API变化的适应过程。具体而言，我们构建了一个包含约2000个数据条目的数据集，用于训练LLMs基于更新信息进行版本迁移。此外，我们引入了一种修改过的字符串相似度度量作为强化学习的奖励。实验结果显示，ReCode显著提升了LLMs在动态API情景下的代码生成性能，特别是对于未见过的CodeUpdateArena任务。与监督微调相比，ReCode对LLMs的一般代码生成能力影响较小。我们对各种LLMs和强化学习算法（GRPO和DAPO）进行了应用，所有模型均显示出一致的性能提升。值得注意的是，经过训练后，Qwen2.5-Coder-7B的性能优于32B参数代码指令微调模型和具有相同架构的推理模型。代码已开源。

Conclusion: 
ReCode通过使用强化学习方法显著提高了大型语言模型在动态API环境下的代码生成能力，特别是在未见过的任务上表现出色。同时，它对模型的通用代码生成能力的影响较小，并在各种LLMs和算法上实现了持续的性能改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20495</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>558. cs.AI-一种具有可追溯推理的罕见疾病诊断代理系统</title><link>https://arxiv.org/pdf/2506.20430</link><description>Background: 
罕见疾病全球影响人口超过3亿，但精准及时的诊断仍然是一个普遍存在的挑战。这主要是由于罕见疾病的临床异质性、低个体发病率以及大多数临床人员对罕见疾病的不熟悉。现有诊断方法难以有效应对这些疾病。因此，迫切需要新的智能化诊断工具来改善诊断效率和准确性.

Innovation: 
该研究提出了一种名为DeepRare的罕见疾病诊断代理系统，它是第一个基于大型语言模型（LLM）并能够处理异质化临床数据的系统。DeepRare包含一个中央主机、长-term记忆模块和多个专业代理服务器，这些服务器能集成多种专业工具和最新的医疗知识来源，为用户提供最及时的临床信息，从而支持复杂的诊断推理，同时保证诊断过程的透明度和可追溯性。该系统在多种评估标准下表现优异，尤其是在罕用药理学（HPO）评价中大幅超越了其他15种方法。在多模态输入场景下，DeepRare也显示了明显的优势。此外，系统还被实现为易于使用的网页应用，能够实现临床推理链的验证和高一致性的诊断结果.

Conclusion: 
DeepRare系统展示了卓越的罕见疾病诊断性能，特别是在罕用药理学评价中显著优于其他方法，且在多模态输入场景中也表现出色。这表明DeepRare系统在临床诊断中的应用潜力是巨大的，能够成为辅助罕见疾病诊断的重要工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20430</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>559. cs.AI-基于LLM的表格数据分类中自动演示选择</title><link>https://arxiv.org/pdf/2506.20451</link><description>Background: 
在使用上下文学习（ICL）进行表格数据分类时，一个基本问题是如何确定提示中理想数量的示范。本文通过提出一种自动选择适当数量示范的算法来解决这一挑战。算法不仅考虑表格数据的分布情况，还结合用户选择的提示模板以及特定的大规模语言模型（LLM）进行评估。基于谱图理论，文章提出了一种新的度量标准来量化不同示范之间的相似性，并通过构建相似性图和分析其拉普拉斯算子的特征值来推断能够在LLM的内在表示空间中代表数据的最小示范数量。实验表明，该方法在各种数据集和LLM上优于传统的随机选择算法，有效验证了其方法的有效性。

Innovation: 
文章提出了一种结合表格数据分布、用户选择的提示模板及特定的大规模语言模型的自动示范选择算法。这种方法通过基于谱图理论的新度量标准来量化不同示范之间的相似性，并通过拉普拉斯算子的特征值来推断所需的最小示范数量，从而在大规模语言模型（LLM）的内在表示空间中有效代表数据

Conclusion: 
实验对比展示了该方法在多种数据集和大规模语言模型上的优越性能，证实了其有效性和实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20451</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>560. cs.AI-Argumentative Ensembling for Robust Recourse under Model Multiplicity</title><link>https://arxiv.org/pdf/2506.20260</link><description>Background: 
在机器学习中，为相同的预测任务会得到多个表现相同的模型。模型多样性（MM）是指当这些竞争模型对同一输入有不同的预测结果时的情况，这时通常会使用集成方法来确定输出的组合。然而，当在MM情况下提供纠正建议时，给定的反事实解释（CE）可能对所有模型都无效，因为CE在MM下的鲁棒性较差。本文分析了在MM情况下的纠正建议如何变得复杂，并将其形式化为一个名为recourse-aware ensembling（RAE）的问题。

Innovation: 
本文提出了一种新颖的基于论证的集成方法，以确保CE在MM下的鲁棒性。该方法利用计算论证明确表示模型和反事实之间的冲突，使用论证语义来解决冲突并获得最终解决方案。该方法还允许在MM条件下指定模型的偏好，提供更大的自定义集成的能力。作者还对论证集成使用了四种不同的论证语义进行了全面的理论分析，并通过八个方法实例验证了该方法的有效性，确保了所得结果满足所提出的需求属性。

Conclusion: 
本文提出了一个方法来解决在MM条件下提供纠正建议的问题，将其称为recourse-aware ensembling（RAE）。通过论证集成方法，作者确保了反事实解释的鲁棒性，并通过不同类型的论证语义分析，展示了该方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20260</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>561. cs.AI-SV-LLM：利用大型语言模型的代理方法实现SoC安全验证</title><link>https://arxiv.org/pdf/2506.20415</link><description>Background: 
确保复杂芯片系统（SoCs）设计的安全性是一项至关重要的任务，但传统的验证技术由于自动化、扩展性、全面性和灵活性方面的重大挑战，难以跟上步伐。大型语言模型（LLMs）的出现因其在自然语言理解、代码生成和高级推理方面的出色能力，提供了应对这些问题的新范式。通过采用多代理系统方式，不同特化的LLMs能够更好地协作解决复杂问题。在认识到这一机会后，本文提出了SV-LLM，一种多代理辅助系统，旨在自动化并提升SoC安全验证。

Innovation: 
SV-LLM通过整合不同特化的代理，如验证问题回答、安全资产识别、威胁建模、测试计划和属性生成、漏洞检测以及基于仿真的错误验证等任务，精简工作流程。代理通过不同的学习范式来优化性能，如上下文学习、微调和检索增强生成（RAG）。此系统旨在减少人工干预，提高准确性，并加速安全分析，支持早期设计阶段的风险主动识别与缓解。

Conclusion: 
本文通过示范案例研究和实验展示了SV-LLM的适用性和有效性，突显了其对硬件安全实践的潜在变革作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20415</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>562. cs.AI-客户端聚类与知识分享：在个性化对等学习中增强隐私和稳健性</title><link>https://arxiv.org/pdf/2506.20413</link><description>Background: 
人工智能在物联网生态系统中的广泛应用加剧了对能够高效且私密地在异构、资源受限设备上运行的个性化学习方法的需求。然而，在去中心化环境中启用有效的个性化学习带来了挑战，包括如何高效地在客户端之间转移知识、保护数据隐私以及抵御中毒攻击的能力。

Innovation: 
提出了P4（个性化、私密、对等）方法，该方法旨在为资源受限的物联网设备提供个性化的模型，同时确保差异隐私和抵御中毒攻击的鲁棒性。该方法采用轻量级的完全去中心化算法来私密地检测客户端相似性并形成合作组，在每个小组中，客户端利用差异隐私知识蒸馏来共同训练模型，从而保持高准确率并确保在恶意客户端存在情况下的鲁棒性。

Conclusion: 
通过在流行基准数据集上使用线性和CNN架构进行评估，实验结果表明P4在各种异构性和攻击场景下的准确率比领先的差异隐私对等方法高出5%至30%，并且即使在存在最高30%的恶意客户端时仍能保持鲁棒性。此外，通过在资源受限设备上的部署实验证明了P4的实用性，两个客户端之间的协作训练仅增加了约7秒的开销。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20413</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>563. cs.AI-在非稳态环境下未来的离策评估与学习</title><link>https://arxiv.org/pdf/2506.20417</link><description>Background: 
本文探讨了一种新的问题，即在未来离策评估（F-OPE）和学习（F-OPL）中的未来价值估算和优化。这种问题发生在环境分布随时间变化的非稳态环境中。例如，在电商推荐场景中，目标通常是在上个月旧策略收集的数据基础上，估算和优化对下个月策略价值的估计。关键挑战在于，未来的数据在历史数据中未被观察到。现有的方法要么假设环境的稳态性，要么依赖于严格的奖励建模假设，导致显著的偏差。

Innovation: 
作者提出了一种名为OPFV（Off-Policy Estimator for the Future Value）的新型估计器，专门用于未来任意时间点策略价值的准确估计。OPFV的关键特点是能够利用时间序列数据中的有用结构，通过新类型的权重技术利用例如季节性、周期性或节假日效应，从而在非稳态环境中进行高效的未来的策略价值评估。理论分析明确了在何种条件下OPFV具有低偏差的特点。此外，作者还扩展了该估计器，提出了一个新的基于历史数据学习未来良策的策略梯度方法。

Conclusion: 
本文所提出的方法在不同的实验设置下，相较于现有的方法，在非稳态环境中对未来的策略价值进行估计和优化方面具有显著的优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20417</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>564. cs.AI-CARMA：结合视觉-语言模型与物体和动作识别的基于上下文的情境化的人机组交互示例建立</title><link>https://arxiv.org/pdf/2506.20373</link><description>Background: 
在人机小组互动中，有效协作需要基于一致表示的当前人员和物体情况意识，以及围绕演员和操作物体的事件阶段性抽象。这需要确保机器人能够正确识别和跟踪演员、物体及其交互。因此，系统需要能够清晰且一致地识别实例，确保机器人能够在时间维度上正确识别和跟踪人员、物体及其交互。CARMA系统通过独特地识别现实世界中物体实例并将它们组织为因演员、物体和行为组成的底层三元组来实现这一目标

Innovation: 
CARMA系统通过结合视觉-语言模型与物体和动作识别技术来实现基于上下文的情境化组互动。该系统能够在真实的小组互动场景中准确识别和跟踪人员、物体及其交互，从而为需要时空推理和情境决策的应用提供结构化和稳健的基础。通过三个实验（协作倒水、递送和分类）验证了系统的能力，表明系统能够稳定生成准确的演员-行为-物体三元组

Conclusion: 
实验结果表明，CARMA系统能够稳定地生成准确的演员-行为-物体三元组，这为需要时空推理和情境决策的协作环境中的应用提供了结构性和稳健性的基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20373</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>565. cs.AI-通过频谱自助和拉普拉斯基增强进行自我监督的图学习</title><link>https://arxiv.org/pdf/2506.20362</link><description>Background: 
现有的自我监督的图学习方法依赖于负样本采样或对比学习目标，这增加了实现的复杂性。本文通过引入频谱自助技术和拉普拉斯基增强，提出了一种新框架LaplaceGNN，旨在简化自我监督的图学习过程，同时保持良好的性能。

Innovation: 
LaplaceGNN通过频谱自助技术预计算谱增强，利用最大最小中心性优化，提供了一种基于频谱的增强机制，无需依赖手工设计的增强。该方法还结合了对抗性自助训练方案，增强了特征学习能力和鲁棒性。这些改进使LaplaceGNN能够实现线性扩展，为图神经网络提供了一种高效学习富有表现力的图表示的简便方法。

Conclusion: 
在不同基准数据集上的广泛实验表明，LaplaceGNN在自我监督的图方法中表现出更优的性能，为高效学习表达性的图表示提供了新的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20362</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>566. cs.AI-自我监督动作识别中的特征生成</title><link>https://arxiv.org/pdf/2506.20342</link><description>Background: 
视频中的人类行为理解需要超越简单的像素分析，依赖于高层次的语义推理和多模态特征的有效整合。现有的深度动作识别框架主要基于RGB视频帧直接进行动作概念的预测，缺乏对动作相关区域的有效关注，无法充分利用上下文信息和关键特征。

Innovation: 
本文提出了一种深度的翻译动作识别框架，通过联合预测动作概念和辅助特征，增强动作识别的准确性。在测试阶段，通过生成缺失线索来丰富特征表示而不增加计算开销。引入了两种新的领域特定描述符：物体检测特征（ODF）和显著性检测特征（SDF），分别用于捕捉上下文线索和强调对动作识别至关重要的空间和强度模式。提出了一个将这些描述符与光学流、改进密集轨迹、骨架数据和音频提示等辅助模态无缝整合的框架，同时兼容最新架构。通过在生成步骤中引入Aleatoric不确定性建模和鲁棒损失函数，来应对辅助特征中的不确定性。

Conclusion: 
提出的多模态自我监督动作识别框架在多个基准上达到了最先进的性能，包括Kinetics-400、Kinetics-600和Something-Something V2，显示了其在捕捉细粒度动作动态方面的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20342</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>567. cs.AI-DipSVD：高效的大语言模型压缩的双重要性保护SVD方法</title><link>https://arxiv.org/pdf/2506.20353</link><description>Background: 
随着大型语言模型（LLMs）的计算需求和部署成本的不断增加，已经产生了大量的压缩方法。与量化和无结构剪枝相比，SVD压缩提供了更好的硬件兼容性和理论保证。然而，现有的基于SVD的方法主要关注原始矩阵和压缩矩阵之间的总体差异，而忽略了矩阵中关键部分的保护，这导致了压缩模型的性能较差。

Innovation: 
本文提出了一个多级重要性保护机制来增强基于SVD的压缩方法：（1）局部重要性保护：通过通道加权数据去相关来保留每个权重矩阵中最重要的奇异向量；（2）全局重要性保护：通过启发式或优化方法使较不重要的层承担更大的压缩负担，以最小化压缩对关键层的影响。

Conclusion: 
广泛的实验表明，DipSVD在多个基准上优于现有的基于SVD的压缩方法，特别是在高模型压缩比的情况下，能够实现更好的模型性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20353</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>568. cs.AI-使用神经网络生成和定制机器人手臂轨迹</title><link>https://arxiv.org/pdf/2506.20259</link><description>Background: 
本文介绍了一种利用神经网络生成和定制机器人手臂轨迹的方法，该方法能够确保精度和可重复性。在认知机器人的情境下，该方法用于设计并实现机器人手臂轨迹的生成与定制，并展示了其实验应用。通过这种方法，NICO 机器人能够精确地进行指向运动，提高机器人与人类交互时的动作可预测性。

Innovation: 
该方法的核心创新在于利用神经网络计算机器人手臂的正向运动学，结合关节角度生成器，训练神经网络生成符合需求的轨迹。通过计算角速度，机器人能够完成精准的动作，并根据形状和准确性评估其动作质量。该方法具有广泛的适用性，能够生成精确定制的轨迹，适用于不同的应用场景。

Conclusion: 
研究结果说明，这种方法在生成和定制机器人手臂精确轨迹方面具有显著优势，实现了机器人手臂动作的灵活定制，为认知机器人领域的应用提供了新的可能性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20259</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>569. cs.AI-限示例表现超越专家：双探索高效模仿学习</title><link>https://arxiv.org/pdf/2506.20307</link><description>Background: 
模仿学习是强化学习中的一个核心问题，其目标是学习一个能够模仿专家行为的策略。在实践中，由于状态空间的复杂性，从有限数量的演示中准确学习专家策略常常具有挑战性。此外，为了实现超越专家的表现，探索环境并收集数据是至关重要的。然而，这两方面都面临挑战。为了解决这些挑战，本文提出了一个名为双探索模仿学习（ILDE）的新模仿学习算法。

Innovation: 
ILDE算法从两个方面实施探索: (1) 通过探索奖金进行乐观的策略优化，奖励具有高不确定性的状态行动对，以潜在地改善对专家策略的收敛；(2) 基于好奇心探索演示轨迹中偏差的状态，以潜在地获得超越专家的表现。实验结果显示，ILDE在样本效率方面优于现有的模仿学习算法，并在Atari和MuJoCo任务上使用较少的演示实现了超越专家的表现。此外，本文还从理论角度证明了ILDE作为具有乐观探索的不确定性正则化策略优化方法，随时间轴的遗憾增长呈次线性增长。

Conclusion: 
本文提出的ILDE算法在样本效率和超越专家的表现方面取得了显著成果，同时提供了理论依据，证明了该算法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20307</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>570. cs.AI- Deep Learning 模型在作物病害检测中的比较分析：一种迁移学习的方法</title><link>https://arxiv.org/pdf/2506.20323</link><description>Background: 
该研究旨在开发一个人工智能驱动的作物病害检测系统，以帮助缺乏资源的农村地区的农民。研究人员希望通过比较不同深度学习模型的效果，特别是在迁移学习方面的表现，来提升作物病害的检测水平。研究利用了包括EfficientNet、ResNet101、MobileNetV2以及自定义CNN在内的多种深度学习模型来实现这一点。该系统通过有效的病理分类展示了其在农村环境中的潜力，特别是在改善作物健康管理和支持可持续农业方面的作用.

Innovation: 
该研究通过比较多种深度学习模型在作物病害检测中的表现，强调了迁移学习在农业实践中的潜在影响，特别是对作物健康管理和可持续农业的支持作用。研究中自定义的CNN达到了95.76%的验证准确率，进一步提升了系统的性能和可靠性.

Conclusion: 
研究结果表明，通过有效的迁移学习技术，可以显著提高作物病害检测的准确性，为农村地区的农民提供了更好的技术支持，有助于推动可持续农业的发展。该研究为以后的作物病害检测系统开发提供了重要参考和依据.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20323</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>571. cs.AI-使用机器学习方法生成来自能源消费者的时序替代品以适用于长期预测场景</title><link>https://arxiv.org/pdf/2506.20253</link><description>Background: 
电力价值链中的预测吸引了大量研究关注，大多数研究集中在发电或消费的短时预测上，更多关注系统而非个体消费者。尽管如此，长期预测个体电力消耗这一主题仍然被忽视。本文深入比较了几种基于数据的方法，用于生成适应长期用电量预测所需时间序列数据。高质量的合成数据对于多种应用至关重要，包括能源系统状态估计或电力网络规划。研究使用了一个来自德国家庭的开源数据集，具有15分钟的时间分辨率，以评估和比较几种先进的技术：混合 Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔可夫模型（HMM）和掩码自回归伯恩斯坦多项式规范流（MABF），旨在增强合成电力消费数据的准确性和可靠性，同时生成符合匿名化等标准的数据，从而保护客户的隐私。

Innovation: 
本文创新地使用了多种机器学习方法，包括混合 Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔可夫模型（HMM）和掩码自回归伯恩斯坦多项式规范流（MABF），进行了一次深入的比较分析，以评估每种方法在复制个人能耗特征上（如时间动态、长距离依赖关系和概率转换）的能力。通过这种评估，本文有助于选择最适合状态估计和其他相关任务的方法。

Conclusion: 
本文的研究框架旨在提高合成电力消费数据的准确性和可靠性，生成符合特定标准（如匿名化）的数据，以减轻对个别客户的特定解读风险。通过这种方法，生成的合成电力消费时间序列可以应用于诸如状态估计或消费预测等应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20253</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>572. cs.AI-通过结构化推理增强大型语言模型</title><link>https://arxiv.org/pdf/2506.20241</link><description>Background: 
最近的大规模语言模型（LLMs）已经显著推进了自然语言处理和自动化决策。然而，这些模型在执行涉及逻辑推理和系统规划的复杂任务时仍面临挑战，主要是由于它们依赖于隐含的统计关系，缺乏结构化的知识。认知科学与神经符号AI领域通过引入结构化推理的方法来改进LLMs，通过显式标注推理步骤将非结构化数据转换为结构化格式，并利用监督微调（SFT）来训练模型。在此基础上，通过Group Relative Policy Optimization（GRPO）增强结构化推理能力，这其中的创新算法MAX-Flow和Longest Common Subsequence (LCS)显著提高了推理效果并降低了计算复杂度。

Innovation: 
提出了利用结构化推理来增强大型语言模型的新方法。这种方法包括将非结构化数据显式标注为结构化格式，以及通过Supervised Fine-Tuning (SFT)训练LLMs。此外，通过Group Relative Policy Optimization (GRPO)增强结构化推理能力，其中运用的MAX-Flow和Longest Common Subsequence (LCS)算法提高了推理效果并简化了计算过程。

Conclusion: 
通过将DeepSeek-R1-Distill-Qwen-1.5B模型进行微调，实验结果表明，这种结构化推理方法能够实现简洁的推理、在各种场景中表现稳健以及提高与优化技术的兼容性，验证了结构化推理在大型语言模型中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20241</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>573. cs.AI-FedBKD: 利用知识蒸馏的联邦学习以在非同质独立数据上实现推广性和个性化</title><link>https://arxiv.org/pdf/2506.20245</link><description>Background: 
联邦学习（FL）是一种去中心化的协作机器学习技术，它解决了工业机器学习实践中孤立数据岛和数据隐私泄露的问题。在FL中处理非独立非同质（non-IID）分布式数据是一个主要挑战。当前的解决方案要么集中建立一个全能的全局模型，要么定制个性化的本地模型。很少有方法能在同时提供良好泛化的全局模型和良好表现的本地模型。此外，许多解决非同质问题的联邦学习解决方案依靠引入公共数据集，但这也增加了数据泄露的风险。本研究旨在解决上述问题。

Innovation: 
我们提出了一个新颖的无数据蒸馏框架，Federated Bidirectional Knowledge Distillation (FedBKD)。在训练生成对抗网络（GAN）生成合成数据时，本地模型作为鉴别器且其参数被冻结。生成的合成数据被用于在全局和本地模型之间进行双向蒸馏，实现知识交互，从而提高双方的性能。我们通过在不同非同质设置下的4个基准上进行了广泛的实验。结果显示，FedBKD在所有情况下都取得了最优性能。

Conclusion: 
我们的方法FedBKD在处理非同质数据时实现了良好的全局和本地模型性能，并通过生成对抗网络生成合成数据，实现了双向知识蒸馏。实验结果表明，该方法在所有标志设置下都取得了顶尖的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20245</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>574. cs.AI-Q-resafe：评估安全风险及量化的安全性补丁方法</title><link>https://arxiv.org/pdf/2506.20251</link><description>Background: 
量化的大语言模型（LLMs）在资源受限环境中部署越来越受到关注。然而，一些研究指出，基于少量校准数据集的量化方法可能会损害LLMs的安全性，因此迫切需要系统地进行安全性评估和有效的缓解策略。现有量化技术通常是在缺乏校准数据集的情况下进行的，这引发了关于量化对LLMs安全性影响的担忧。

Innovation: 
本文提出了一个量化感知的安全补丁框架Q-resafe，用于高效地恢复量化后的LLMs的安全功能，同时尽量减少对其实用性的影响。该框架在不同的量化技术和多元化的校准数据集上进行了全面的安全评估，使用了广泛接受的安全基准。Q-resafe能够在具有挑战性的评估场景中将量化LLMs的安全性重新与量化前的版本对齐。

Conclusion: 
实验结果表明，Q-resafe能够在不显著影响LLMs的实用性的情况下，有效地恢复量化后的安全性，即使在复杂的评估场景下也能实现量化LLMs的安全性与量化前版本的安全性相匹配。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20251</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>575. cs.AI-零样本属性分析在大型语言模型中的应用：分布测试方法</title><link>https://arxiv.org/pdf/2506.20197</link><description>Background: 
越来越多的代码片段来源于大型语言模型（LLMs）。研究者们需要提出一种方法，能够从生成代码的语言模型中进行归因分析，利用假设检验来评估代码片段是否来源于某个指定的模型。然而，仅凭LLMs的样本进行低维度运算在高维空间中处理的效率会变得极低，因此在不增加额外模型访问的情况下，使用样本和来自LLMs的密度估计进行零样本归因分析成为研究热点。作者引入了名为$text{Anubis}$的新工具，该工具将归因问题转化为分布测试问题，从而能有效地解决这一问题并实现了高AUROC分数。

Innovation: 
提出了$text{Anubis}$，一个零样本归因工具，将归因问题转化为分布测试问题。该工具利用假设检验和密度估计来高效地评估代码样本是否来自特定的语言模型。通过实验表明，该方法在区分诸如DeepSeek-Coder、CodeGemma和Stable-Code等模型时，表现优异，AUROC分数达到或超过0.9，且仅需约2000个样本。

Conclusion: 
作者提出的方法$text{Anubis}$通过将归因问题转化为分布测试问题，成功的解决了高维空间中的低效问题。该方法在少量样本的情况下，显著提高了LRMMs生成代码的归因精度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20197</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>576. cs.AI-Play下的视角：更包容的NLP系统的一种多视角方法</title><link>https://arxiv.org/pdf/2506.20209</link><description>Background: 
在自然语言处理（NLP）领域中，处理人类分歧的常见方法是汇总注释者的观点以确定单一的真实 ground truth。然而，之前的研究所表明，忽略个体意见会导致少数群体视角被低估，特别是在主观任务中，注释者可能由于个人偏好而系统地产生分歧。认识到标签反映了个人的多样化背景、生活经验和价值观，本研究提出了一种新的多视角方法，使用软标签以促进下一代敏感视角模型的发展，使之更具包容性和多样性。研究者在多样化的主观文本分类任务中进行了全面分析，包括仇恨言论、讽刺、攻击性语言和立场检测，以突出捕捉人类分歧的重要性，这一事实被传统聚合方法所忽略。结果表明，多视角方法不仅更接近人类标签分布，由Jensen-Shannon 散度（JSD）衡量，还取得了更优的分类性能（更高的F1分数），优于传统方法。然而，我们的方法在讽刺和立场检测等任务中表现出较低的信心，这可能是由于文本中固有的主观性所致。最后，结合可解释的人工智能（XAI），我们探索了模型的不确定性并揭示了关于模型预测的重要见解。

Innovation: 
本研究提出了一种新的多视角方法，使用软标签以促进下一代敏感视角模型的发展，使之更具包容性和多样性。该方法不仅更接近人类标签分布，还取得了更优的分类性能。

Conclusion: 
多视角方法更接近人类标签分布且具有更好的分类性能。然而，该方法在主观性强烈的任务（如讽刺和立场检测）中表现出较低的信心。通过可解释的人工智能，我们探索了模型的不确定性，并揭示了模型预测的重要见解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20209</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>577. cs.AI-使用局部和全局特征融合的GNN进行有向链接预测</title><link>https://arxiv.org/pdf/2506.20235</link><description>Background: 
有向图分析中的链接预测是一个经典问题，具有广泛的实际应用。近年来发展起来的深度学习方法通常通过对比学习分析节点的相似性，并通过图卷积聚合并邻域信息。本文的背景是探讨如何改进有向图链接预测的方法和技术，特别是在利用节点特征和社区信息方面。

Innovation: 
本文提出了一种新颖的图神经网络（GNN）框架，结合了特征嵌入和社区信息。通过这种混合特征，理论上证明可以提升有向链接预测的性能。此外，还提出了一种将输入图转换为有向线图的方法，这样可以使得在图卷积中更有效地聚合节点信息。

Conclusion: 
在基准数据集上的实验表明，本文的方法在大部分情况下都优于最先进的方法，尤其是在使用不同比例的连接链接作为训练数据时（30%，40%，50%和60%）。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20235</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>578. cs.AI-如何在上下文学习中检索示例以利用大型语言模型改善对话情感识别？</title><link>https://arxiv.org/pdf/2506.20199</link><description>Background: 
大型语言模型（LLMs）已在多种领域中实现了广泛的实际应用，但在情感识别等主观任务中，要实现高准确性的高表现应用仍然具有挑战性。受SLT 2024 GenSER挑战的启发，本研究探讨了如何通过增强的上下文学习（ICL）提高对话情感识别（CER）的质量。研究集中在通过检索高质量示例以提升对话情感识别的表现上，并分析了对话上下文对情感识别准确度的影响。实验在IEMOCAP、MELD和EmoryNLP三个数据集上进行。结果表明，在所有数据集上，增强的示例检索方法始终优于其他技术，突显了检索一致且相关的示例并通过改写来增强的重要性。

Innovation: 
本研究提出了一种基于随机和增强示例检索策略的方法，来改善对话情感识别的表现。通过增强示例检索技术，研究展示了这种方法对不同数据集的普遍优势，强调了选择相关和一致的示例并对其进行改写的必要性。

Conclusion: 
增强示例检索方法在提升对话情感识别方面具有显著效果，不论在哪个数据集上，它都表现出优于其他技术的效果。因此，对于提高对话情感识别的准确性，检索一致且相关的高质量示例显得尤为重要。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20199</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>579. cs.AI-Affective Priming Score: 一种检测序列数据中诱发效应的驱动数据方法</title><link>https://arxiv.org/pdf/2506.20204</link><description>Background: 
情感诱发效应体现了情感计算中模糊性挑战的实例。尽管社区主要从标签角度处理这一问题，即标识受诱发效应影响的数据点及其对数据本身（尤其是生理信号）的影响，仍处于边缘状态。受诱发效应影响的数据在用于学习模型时可能导致分类错误。已有研究表明，在训练模型时使用无诱发效应的序列能够大幅降低错分率。

Innovation: 
本文提出了一种数据驱动的方法——情感诱发分数（Affective Priming Score, APS），用于检测受诱发效应影响的数据点。每个数据点都根据其被诱发效应影响的程度得到了一个评分。该方法在SEED和SEED-VII数据集中进行验证，结果显示使用无诱发效应序列训练的模型相比于原始数据分类错误率显著降低。此工作的创新之处在于识别并缓解数据层面的诱发效应，提升了模型的鲁棒性，为情感计算数据集的设计和采集提供了新的见解。

Conclusion: 
本研究通过APS方法识别并缓解了数据集中的诱发效应，通过使用无诱发效应序列来训练模型，显著降低了模型的分类错误率，并为解决情感计算中的模糊性挑战做出了贡献。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20204</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>580. cs.AI-BrokenVideos：用于AI生成视频细微缺陷定位的基准数据集</title><link>https://arxiv.org/pdf/2506.20103</link><description>Background: 
尽管深度生成模型在视频生成方面取得了显著进展，但AI生成视频的保真度仍然有限。合成内容常表现出时间上不一致的运动、物理上不可靠的轨迹、不自然的对象变形和局部模糊等视觉伪影，这些都削弱了现实感和用户信任。准确地检测和空间定位这些伪影对于自动质量控制和改进生成模型的发展至关重要。但是，当前研究领域缺乏专门用于AI生成视频中缺陷定位的全面基准。现有数据集要么仅限于视频或帧级别检测，要么缺乏用于评估定位方法的详细空间注释。因此，本文提出BrokenVideos数据集，包含3,254个AI生成视频，其中每个视区都进行了详细的像素级别注释，以突出显示视觉损坏区域，并通过详细的人工检查确保高质量的标注。我们的实验表明，通过在BrokenVideos上训练最先进的缺陷检测模型和多模态大规模语言模型(MLLMs)，可以显著提高其对受损区域的定位能力。

Innovation: 
提出了一种名为BrokenVideos的基准数据集，包含3,254个AI生成视频，每个视区都进行了详细的像素级别注释，以突出显示视觉损坏区域，特别设计用于细致的缺陷定位。通过这种方法，本文建立了评估和推进生成视频模型中缺陷定位研究的关键基础，并表明在BrokenVideos上训练最先进的检测模型显著增强了其定位能力，同时验证了多模态大规模语言模型的改进效果。

Conclusion: 
该数据集为基准测试和推进生成视频模型中的缺陷定位研究奠定了关键基础。通过广泛评估，表明在BrokenVideos上训练最先进的缺陷检测模型和多模态大规模语言模型可以显著提高对受损区域的定位能力。数据集可从这个链接下载：this https URL.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20103</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>581. cs.AI-COIN：具有可证明风险保证的不确定性保护选择性问答框架</title><link>https://arxiv.org/pdf/2506.20178</link><description>Background: 
不确定性量化（UQ）对于基础模型至关重要，因为它有助于识别和减轻自动生成文本中的潜在幻觉。然而，启发式UQ方法在关键指标，如选择性预测的错误发现率（FDR）中缺乏正式保证。先前的研究采用了分裂校准时序预测（SCP）框架以通过构建预测集来确保可接受答案的期望覆盖率，但这些集往往包含不正确的候选，限制了它们的实际应用价值。

Innovation: 
我们提出了COIN，一种不确定性保护选择框架，可以在用户指定的FDR约束下筛选单个生成答案，同时校准统计合理的阈值。COIN通过对校准集估计经验误差率，并结合Clopper-Pearson等置信区间方法，建立真实误差率（即FDR）的高概率上限，从而能够在确保测试数据上的FDR控制的同时显著增加样本保留量。研究成果显示COIN在风险控制中的稳健性、在保留可接受答案方面的强测试时能力以及在有限校准时数据下的预测效率，并且表明使用替代上限构造和不确定性量化策略可以进一步增强COIN的效能，上述特点强调了COIN的可扩展性和适应性以应对不同的应用场景。

Conclusion: 
实验结果显示了COIN在多种文本生成任务中的稳健性、测试时保持可选答案的能力以及在有限校准时数据条件下的预测效率，并且突显了使用替代上限构造和不确定性量化策略可以进一步增强COIN的效能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20178</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>582. cs.AI-Irec：通过即时洞察回忆进行元认知支撑的自我调节学习：概念框架和系统原型</title><link>https://arxiv.org/pdf/2506.20156</link><description>Background: 
学习的核心挑战已经从知识获取转向有效的自我调节学习（SRL），即规划、监控和反思自己的学习过程。现有的数字工具在促进元认知反思方面存在不足。分散复习系统（SRS）采用去语境化的复习策略，忽视了语境的作用，而个人知识管理（PKM）工具则需要大量的手动维护来操作。

Innovation: 
本文引入了“Insight Recall”这一新型框架，将基于情境触发的个人过往见解提取作为元认知支架，以促进SRL。通过捷时自适应干预（JITAI）框架，采用动态知识图谱，即时召回相关个人见解，并用大型语言模型进行深度相似性评估来呈现最相关的支架。同时还提出了一种可选的“引导式探究”模块，让使用者在当前问题和回忆起的见解的基础上与专家大型语言模型进行苏格拉底式对话。该论文贡献了一种坚实的理论框架和实践系统平台，用以设计下一代智能化学习系统，增强元认知和自我调节能力。

Conclusion: 
该论文提供了一个具有扎实理论背景和可用系统的框架，为设计未来的智能学习系统提供了指导，这些系统能够增强元认知和自我调节技巧。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20156</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>583. cs.AI-SEED: 一种用于时间序列预测的嵌入驱动解码结构编码器</title><link>https://arxiv.org/pdf/2506.20167</link><description>Background: 
多变量时间序列预测需要模型同时捕捉每个变量的结构依赖关系，并且能够在多样化的任务中泛化。尽管结构编码器能够有效建模特征间的交互作用，但它们缺乏支持语义级推理或任务适应的能力。另一方面，大规模语言模型（LLMs）具有强大的泛化能力，但不适用于原始时间序列输入。这种不匹配限制了统一的、可转移预测系统的开发。因此，我们引入SEED，一种结合结构编码器嵌入驱动解码的结构编码器，该模型分为四个阶段：知token意识的编码器进行片段提取、投影模块使片段与语言模型嵌入对齐、语义再编程机制将片段映射到任务感知的原型以及冻结的语言模型以进行预测。这种模块化结构将表示学习与推理分离，使数值模式与语义推理之间实现高效对齐。实验结果表明，所提出的方法在强baseline上实现了持续改进，而不同数据集上的比较研究进一步确认了SEED在解决结构-语义建模缺口中的作用。

Innovation: 
我们提出了SEED，一种结构编码器嵌入驱动解码器，结合了四个关键组件：知token意识的编码器处理片段提取、投影模块使时间序列片段与语言模型嵌入对齐、语义再编程机制将片段映射到任务感知的原型，以及固定的语言模型进行预测。这种模块化架构实现了表示学习与推理的分离，能够有效建立时间序列数据中的数值模式和语义推理之间的联系。

Conclusion: 
所提出的方法在多个基准测试上展示出一致的改进，并且在不同数据集上的比较研究确认了SEED在解决结构-语义建模差距中的作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20167</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>584. cs.AI-Pansharpening中的渐进对齐退化学习</title><link>https://arxiv.org/pdf/2506.20179</link><description>Background: 
基于深度学习的复合像元生成已被证明可以有效地生成高分辨率多光谱（HRMS）图像。为了创建监督的地面真实HRMS图像，通常使用Wald协议生成的合成数据。Wald协议假设在低分辨率数据上训练的网络在高分辨率数据上也有相同的性能。然而，经过训练的模型通常在低分辨率和全分辨率数据集之间的性能存在权衡。本文研究了Wald协议，发现其对实际退化模式的不准确近似限制了深度复合像元模型的泛化能力。

Innovation: 
本文提出了一种称为逐进对齐退化模块（PADM）的新模块，该模块通过两个子网络（PAlignNet和PDegradeNet）之间的相互迭代来学习准确的退化过程，无需依赖预定义的操作。此外，引入了HFreqdiff，这是一种嵌入高频细节的扩散框架，并结合了CFB和BACM模块，以实现频率选择性细节提取和精确的反向过程学习，这有助于高效整合高分辨率Pan图像和多光谱图像，显著提高了空间清晰度和质量。

Conclusion: 
实验和消融研究表明，所提出的方法在与现有最先进的技术相比时表现出更优的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20179</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>585. cs.AI-在基于同调集的有效选择</title><link>https://arxiv.org/pdf/2506.20173</link><description>Background: 
同调预测提供了一种无需假设分布的框架，可以构建具有覆盖率保证的预测集。在实践中，可以从不同模型或方法得到多个有效的同调预测集，但选择这些集中的最理想的一个，比如最小的一个，可能会使覆盖率保证失效。因此，处理这种挑战是必要的，以确保所选择的预测集具有所需的覆盖率保证。

Innovation: 
提出了一种基于稳定性的方法，该方法确保对于所选预测集的覆盖率；拓展了结果到在线同调预测设置，并在具有额外结构的情况下提出了几种改进方法；并通过实验展示了该方法的有效性。

Conclusion: 
所提出的方法能够确保所选择的预测集具有所需的覆盖率保证，即使在存在多个有效同调预测集的情况下也能保持这一保证。进一步通过实验证明了本方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20173</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>586. cs.AI-基于损失感知的选择性剪枝标准自动选择方法以加速深度神经网络</title><link>https://arxiv.org/pdf/2506.20152</link><description>Background: 
剪枝是压缩神经网络的一种成熟技术，适用于资源受限的边缘设备。大多数剪枝方法采用分步流程，包括训练、剪枝和微调三个阶段，但这种方法可能导致模型精度的突然下降。

Innovation: 
提出了一种基于损失感知的选择性剪枝标准自动选择（LAASP）方法，将剪枝与训练过程结合，简化了剪枝流程，同时根据网络在少量训练数据上的整体损失自动选择一定池中的剪枝标准和具体的剪枝层。为了缓解由于剪枝导致的精度突降，网络会在每次减少预定义数量的浮点运算（FLOPs）后进行重新训练。另外，网络中的最佳剪枝率将自动确定，消除了对每个层固定或变量剪枝率的手动分配的需要。该方法在VGGNet和ResNet模型上进行了实验，验证了其有效性，特别是ResNet56和ResNet110模型在CIFAR-10数据集上的准确率显著提高，同时减少了52%的网络FLOPs，而ResNet50模型在ImageNet数据集上也减少超过42%的FLOPs，仅损失0.33%的顶级准确率。

Conclusion: 
该研究提出的方法能够在保持较高准确率的同时，有效减少深度神经网络的计算量，适用于实际部署于资源受限环境下的边缘设备。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20152</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>587. cs.AI- psychic cells generate consciousness? </title><link>https://arxiv.org/pdf/2506.20164</link><description>Background: 
过去的几十年里，技术的进步使得神经科学家能够以前所未有的方式研究意识的基本问题。特别关注的是被称为“心理细胞”的皮层锥体神经元，这些神经元在几十年前由Ramón y Cajal命名。研究表明，这些神经元具有独特的细胞机制，可以解释在麻醉导致意识丧失时反馈信号的特异性中断。特定类型的代谢型受体在这些神经元的树突上分布，被认为是关键的细胞机制。因此，Cajal的直觉可能在未来被证实是正确的，即我们可能只是开始理解‘心理细胞’是否以及如何产生和控制我们的意识。

Innovation: 
该研究强调了特定代谢型受体在锥体神经元中的关键作用，这可能帮助解开意识的物理基础。此外，研究揭示了锥体神经元在意识丧失过程中的特异性反馈信号中断机制。

Conclusion: 
研究表明，特定代谢型受体在锥体神经元上的分布可能是一个关键的生理机制，可能有助于理解意识的产生和控制。因此，这可能证实Cajal的直觉，即‘心理细胞’可能在意识的产生和控制中起到了关键作用，未来的研究可能会进一步揭示更多的细节。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20164</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>588. cs.AI-CCRＳ：一个零样本的预训练LLM评判框架，用于全面的RAG评估</title><link>https://arxiv.org/pdf/2506.20128</link><description>Background: 
RAG系统通过引入外部知识来增强大规模语言模型，这对于需要事实准确性和最新信息的领域至关重要。然而，评估RAG输出的多方面质量（如上下文连贯性、查询相关性、事实正确性和信息完整性）仍然存在巨大挑战。现有的评估方法往往依赖简单的词汇重叠度量，这无法捕捉这些细微差别，或者需要复杂的多阶段管道，包括事实提取或需要对专门的评判模型进行微调，这在实际操作中并不高效。

Innovation: 
本文提出了一种名为CCRＳ（上下文连贯性和相关性评分）的新框架，使用一个预训练的大型语言模型作为零样本、端到端的评判。CCRＳ评估五个方面：上下文连贯性（CC）、问题相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回率（IR）。与复杂的RAGChecker框架相比，CCRＳ在召回率和真实性方面具有相当或更优越的区分能力，同时具有更高的计算效率。

Conclusion: 
CCRＳ提供了一个实用、全面且高效的框架，用于评估和迭代改进RAG系统。它有效地区分了不同RAG系统的性能，比如证明Mistral-7B阅读器在某些方面优于Llama版本。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20128</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>589. cs.AI-人工智能与敏捷软件开发：从挫感到成功 -- XP2025研讨会总结</title><link>https://arxiv.org/pdf/2506.20159</link><description>Background: 
在2025年XP（极限编程）大会上，举办了以人工智能和敏捷软件开发为主题的全天工作坊。参会者包括来自研究界和工业界的多样化成员，他们共同讨论了将人工智能整合到敏捷软件开发中的实践挑战和机遇。通过互动环节，参与者指出了在敏捷软件开发中整合人工智能所遇到的共同痛点，例如工具、治理、数据质量和关键技能缺口等方面的问题。这些问题被系统地优先排序和分析，以找出根本原因。

Innovation: 
工作坊最终达成了联合行业和学术界的力量，共同制定了一份研究蓝图，旨在将识别出的挫败感转化为成功的实施。这份蓝图不仅指出了即时解决方案的方向，还包括了长远的目标。通过这一过程，会进一步推动人工智能在敏捷软件开发中的有效整合和应用。

Conclusion: 
会议总结了一份详细的行动计划，以促进各方合作，推动从发现的问题到成功实施的转变。未来的研究将集中在应对具体挑战的具体措施上，同时也提出了长期的战略目标。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20159</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>590. cs.AI-EAR: Erasing Concepts from Unified Autoregressive Models</title><link>https://arxiv.org/pdf/2506.20151</link><description>Background: 
AR模型已在视觉理解和图像生成任务中实现了统一且强大的性能。然而，在去除AR模型中的不需要概念同时保持整体生成质量方面仍存在技术挑战。

Innovation: 
本文提出了一种名为Erasure Autoregressive Model (EAR)的微调方法，用于在保持模型实用性的前提下有效去除概念。该方法包括Windowed Gradient Accumulation (WGA)和Thresholded Loss Masking (TLM)策略，能够精确对齐局部解码与去概念化目标，并在微调过程中保护与目标概念无关的内容。此外，还提出了一种新的基准测试Erase Concept Generator and Visual Filter (ECGVF)，以更严格、更全面地评估AR模型中的概念去除效果。此基准测试首先利用各种大型语言模型的结构化模板预生成大规模的目标替换概念提示对，然后生成图像并通过视觉分类器进行严格的过滤，以确保概念的准确性和一致性。

Conclusion: 
在ECGVF基准测试上用AR模型Janus-Pro进行的大量实验表明，EAR在概念去除的有效性和模型实用性保持方面取得了显著提高。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20151</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>591. cs.AI-MIRAGE: 农业专家引导对话中的多模态信息寻求与推理基准</title><link>https://arxiv.org/pdf/2506.20100</link><description>Background: 
在农业领域中，咨询互动中的专业级推理和决策高度复杂，需要综合自然用户查询、专家答问以及图像背景等多种信息。现有的基准测试大多依赖于规范明确的用户输入和封闭集分类系统，无法全面评估模型在实际场景中的推理和生成能力。因此，创建一个真实世界、知识密集型领域的多模态基准测试变得尤为重要，能更好地模拟专家和用户的交互过程，包括场景中的未知知识缺口、稀有实体处理以及互动引导等方面的需求。

Innovation: 
MIRAGE基准测试通过综合自然用户查询、专家答问和图像背景等信息，捕捉到农业领域中专家咨询的全部复杂性，形成了一个高保真基准测试。MIRAGE基准测试的数据源自超过35,000个真实用户与专家的互动，通过精心设计的多步管道精心筛选，涵盖了作物健康、病虫害诊断和作物管理的不同场景，其中包括超过7,000种独特的生物实体，使其成为视图语言模型中最具分类多样性的基准之一。MIRAGE的独特之处在于它采用了开放世界的设置，强调模型能力的灵活性和适应性，这对现有的依赖明确输入和封闭集分类的基准测试构成了一种创新挑战。

Conclusion: 
MIRAGE为评估视图语言模型在现实世界知识密集型领域里的多模态推理、澄清策略和长篇生成能力提供了一个新的基准。通过MIRAGE，模型能够更好地理解和应对农业咨询中的复杂情况，从而改进在农业等实际应用中的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20100</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>592. cs.AI-LSH-DynED：一种基于LSH的降采样动态集成框架用于演化的多类别不平衡分类</title><link>https://arxiv.org/pdf/2506.20041</link><description>Background: 
不平衡数据流分类是机器学习中的一个关键挑战，特别是在处理多个类别时。虽然二分类不平衡数据流分类任务得到了广泛的研究，但是在多分类不平衡数据流上的研究相对较少。有效管理动态不平衡比率是这一领域的关键挑战。已有研究集中在使用LSH-RHP与动态集成多样化结合的方法来实现降采样，以提供平衡的训练集并提升集成模型的预测性能。该研究通过在动态集成多样化（DynED）框架中整合局部敏感哈希（Locality Sensitive Hashing, LSH）与随机超平面投影（Random Hyperplane Projections, RHP）来解决这一挑战，并进行了全面的实验证明了其有效性。

Innovation: 
提出了一种新型、稳健且抗干扰的方法LSH-DynED，通过将LSH-RHP整合到DynED框架中来解决多类别不平衡非稳态数据流分类问题。这是首次将LSH-RHP用于不平衡非稳态数据流的降采样实现场景。该方法通过LSH-RHP对多数分类进行降采样，提供平衡的训练集，并提高集成模型的预测性能。实验证明LSH-DynED在Kappa和mG-Mean有效指标上优于其他方法，尤其是在大规模、高维且类别不平衡的实证和半合成数据集上表现出色，具有良好的适应性和鲁棒性。

Conclusion: 
该研究通过对比实验展示了LSH-DynED方法在处理多类别不平衡非稳态数据流分类问题上的优越性能。结果表明，LSH-DynED在大规模高维数据集和实际应用场景中具有良好的适应性和鲁棒性。此外，该研究还回顾了现有方法的不足，指出了关键挑战，并为未来的研究提供了指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20041</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>593. cs.AI-结合时空模型和LLMs的模块化多任务推理框架</title><link>https://arxiv.org/pdf/2506.20073</link><description>Background: 
时空数据挖掘在不同领域中的决策制定中起着关键作用。然而，现有的模型通常局限于狭窄的任务，缺乏进行多任务推理和复杂长期推理的能力，这些能力需要生成深入且解释性的输出。这些限制限制了它们在现实世界、多维度决策场景中的应用。

Innovation: 
我们介绍了一种新颖的框架STReason，它结合了大型语言模型（LLMs）的推理优势与时空模型的分析能力，用于多任务推理和执行，无需特定任务微调。STReason通过上下文学习分解复杂的自然语言查询为模块化、可解释的程序，并系统地执行这些程序以生成解决方案和详细的理由。为了进行严格的评估，我们构建了一个新的基准数据集，并提出了一种统一的评估框架，其中包含特别为长期时空推理设计的指标。实验结果表明，在所有指标上，STReason显著优于最先进的LLM基线，尤其是在复杂的、需要推理的时空场景中表现尤为出色。

Conclusion: 
人类评估进一步验证了STReason的可靠性和实际应用价值，展示了其减轻专家工作负担和扩大应用于现实时空任务的潜力。我们相信STReason为开发更具能力和泛化性的时空推理系统提供了有前途的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20073</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>594. cs.AI-超越自动补全：设计CopilotLens以实现透明可解释的AI编码代理</title><link>https://arxiv.org/pdf/2506.20062</link><description>Background: 
AI辅助代码助手被广泛应用以生成代码补全，显著提升开发者生产力。然而，这些工具通常只会展示建议而不解释其决策逻辑，导致决策过程难以理解，影响开发者的批判性评价和对系统的信任度。CopilotLens提供了一种新颖的交互框架，将代码补全从简单的建议转变为一个透明且可解释的事件，通过动态的双层界面揭示AI代理的决策过程，包括高层次计划和代码上下文影响。

Innovation: 
CopilotLens是一种新颖的交互框架，它改变了代码补全的方式，将其从简单的建议转变为一个透明的、可解释的过程，通过动态的双层界面展示了AI代理的决策过程，包括高层次计划和代码上下文影响，从而增加透明度和解释性。

Conclusion: 
CopilotLens提供了一种设计框架，旨在使其未来的人工智能辅助代理更加注重推理清晰度而非建议速度，从而促进更深刻的理解和更稳健的人机协作。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20062</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>595. cs.AI-VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration</title><link>https://arxiv.org/pdf/2506.19975</link><description>Background: 
近期神经网络的发展提高了变形图像配准（DIR）的性能，通过简化迭代优化过程降低了计算时间，但同时也增强了准确性。然而，基于学习的方法在有限训练数据、大形变和缺乏标签监督的情况下，仍然与迭代方法相比表现较差。虽然迭代方法在这些情况下可以获得更高的精度，但其速度远慢于基于学习的方法。这些局限促使本研究提出VoxelOpt框架，它结合了基于学习和迭代方法的优势，实现更均衡的配准精度和运行时间。

Innovation: 
VoxelOpt框架通过以下三个方面改进了传统的基于学习和迭代的方法：1）引入了体素自适应消息传递机制，低熵体素会受到较少来自邻居的影响力；2）采用多级图像金字塔结构，每个级别使用27邻域成本卷积，以避免计算复杂度的指数增长；3）使用预训练的分割基础模型进行特征提取，替代手工设计的特征或对比学习。

Conclusion: 
在腹部CT配准中，VoxelOpt在效率和准确性方面均优于领先迭代方法，同时与在标签监督下训练的最先进的基于学习的方法相当。VoxelOpt的源代码可从此链接获得。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19975</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>596. cs.AI-SACL：使用语义增强重排和定位理解及克服代码检索中的文本偏差</title><link>https://arxiv.org/pdf/2506.20081</link><description>Background: 
当前的代码检索技术主要依赖于表面级的文本特征（例如，文档字符串、标识符名称）进行编码检索，尽管这些技术是基于代码训练的，但他们往往更偏向于具有良好文档化的代码，而对代码结构和语义信息有所忽视。这一现象影响了代码生成的整体性能。为了改进这一状况，作者进行了一项深入分析，并设计了一种新的框架SACL，旨在通过增强文本信息并减少偏差来改进代码检索和代码生成的效果，特别是在HumanEval、MBPP和SWE-Bench-Lite等基准测试上取得了显著的效果提升。

Innovation: 
本文提出了SACL框架，通过增加语义信息和代码或结构知识来丰富文本信息，减少对表面级特征的依赖，克服现有代码检索中偏爱文档化代码的局限性。实验结果表明，SACL显著提高了代码检索的效果（例如，在HumanEval、MBPP和SWE-Bench-Lite上的召回率分别提高了12.8%、9.4%和7.0%），并且也提升了代码生成的性能（例如，在HumanEval上的通过率提高了4.88%）。

Conclusion: 
SACL在理解和克服代码检索中的文本偏差方面取得了显著的进步，通过语义增强重排和定位，提高了代码检索和代码生成的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20081</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>597. cs.AI-使用生成占用地图合成的鲁棒机器人探索与制图</title><link>https://arxiv.org/pdf/2506.20049</link><description>Background: 
该论文旨在通过使用生成式占用图映射来改善机器人的探索能力。背景包括现有的探索方法存在的问题，以及其他利用3D占用图的数据融合技术在机器人探索中的应用和限制。

Innovation: 
提出了SceneSense，这是一种用于预测3D占用图的扩散模型。创新之处在于，该模型能够实时地将预测结果与现有占用图进行概率融合，并且与利用直接传感器测量构建的对比图相比，增强了占用图的代表性和质量，特别是在机器人附近的区域。此外，通过将增强后的占用图直接用于现成的规划系统，展示了该方法在鲁棒性和通过性强方面的改进效果。

Conclusion: 
该系统能够通过局部增强的占用图提供更一致的探索结果。实验结果表明，使用SceneSense增强的占用图能够显著提高地图质量和可通行性，特别是在两个不同的环境中进行了全探索评估。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20049</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>598. cs.AI-使用自蒸馏进行GNN的不确定性量化</title><link>https://arxiv.org/pdf/2506.20046</link><description>Background: 
图神经网络在医疗领域的应用取得了显著成效，但如何量化GNN的预测不确定性仍然是一个挑战。传统的贝叶斯方法和集成方法虽然可以量化不确定性，但计算成本高。集成方法使用不一致度量来计算不确定性，但不能捕捉模型的多样性。本文旨在提出一种基于知识蒸馏的新方法，以更高效且精确地量化GNN的不确定性，并通过在集成网络中使用自蒸馏，避免独立训练多个模型。

Innovation: 
本文提出了一种基于知识蒸馏的方法，通过网络自身作为教师和学生的自蒸馏模型，自动生成不确定性度量指标，以捕捉网络的多样性。这种方法避免了独立训练多个模型的计算开销，同时能够在两个图数据集（MIMIC-IV和Enzymes）上准确区分出分布外数据，并且具有与MC Dropout和集成方法相当的性能。

Conclusion: 
实验结果表明，提出的自蒸馏方法能够有效地捕捉模型的预测不确定性，其性能与MC Dropout和集成方法相当，而且方法更为高效。该代码已经公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20046</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>599. cs.AI-跨层离散概念发现用于解释语言模型</title><link>https://arxiv.org/pdf/2506.20040</link><description>Background: 
在基于变压器的语言模型中，残差流会线性地混合和复制信息，这使得跨层概念的发现成为一个巨大挑战，因为这会掩盖特征在大型语言模型内部的变化。当前的研究主要集中在单一层的神经表示上，从而忽略了跨层叠加和由此引入的冗余性。这些表示通常是直接分析其激活模式，或者传递到探针分类器，将它们映射到预定义概念的有限集中。由于这些限制，本文提出了一种结合量化和稀疏量化的概念提取方法。该方法利用向量量化将跨层的表示映射到离散的概念空间，并通过在量化过程中使用基于温度的采样和技术参数更新处理离散的潜在空间，从而降低重复特征的冗余性，增强模型的可解释性，从而对概念进行精确的逐层表征建立。这种方法采用了一种特定的向量化方法来捕获特征在语言模型层数中的变化。通过引入缩放球形k-means++并结合了指数移动平均法则，实现对向量编码本体的初始化，从而使整个方法更具可控性并在语义结构中更好地捕捉到潜在空间内的语义关系。

Innovation: 
本文提出了一种结合了基于温度的采样与EMA （指数移动平均法则）更新的框架（CLVQVAE——跨层离散可量化的变分自编码器），能够消除跨层中冗余的残差流特征，使整个表示空间更具有可解释性。此外，通过采用方向相似性驱动的缩放球形k-means++作为初始方法，进一步提高了概念提取的准确性与灵活性，这种策略在词嵌入空间中的语义结构下表现得更为出色。

Conclusion: 
本文提出的CLVQVAE框架成功地在跨层量化过程中将残差流特征编码为紧凑的、可解释的概念向量。通过结合基于温度的采样和EMA更新技术，实现了对跨层特征的精确描述和编码。引入的缩放球形k-means++推荐方法进一步提升了模型在潜在空间中的语义关系识别能力。未来，该方法可以用于深度理解语言模型内部的特征演化，并提高基于语言模型的应用系统的可解释性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20040</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>600. cs.AI-使用二进制优化和图学习为多代理操作自动生成多样化行动方案</title><link>https://arxiv.org/pdf/2506.20031</link><description>Background: 
在灾害响应、搜索与救援以及军事任务中，涉及多个代理的行动需要自动化的流程来支持行动方案（COA）的规划。环境变化（如雨、雪、阻塞等）可能影响COA的预期性能，因此，要求有一个多样化的COA池，以在代理间分散任务。此外，代理能力（包括人类编队和/或自主系统）的变化为规划过程提供了实际机会和计算挑战。本文探讨了在代理-任务兼容性有小波动的情况下，如何生成多样化且高效的COA池的问题。

Innovation: 
本文提出了一种新的理论框架和计算方法，用以生成适应软变化的代理任务兼容性的多样化COA池。该方法的核心是任务空间及COA池的图抽象，以及通过遗传算法和图神经网络（采用策略梯度方法）来实现任务在每个COA中的顺序化，从而最大程度地提高COA池内的多样性并优化代理-任务映射的兼容性。通过模拟环境进行的测试表明，该方法具有显著的性能改进，与随机行走基准相比有着明显的提升，同时单个代理任务顺序优化的约束条件较小，且规划20个COA的时间约为50分钟，适用于代理5/任务100的操作情况.

Conclusion: 
本文提出的方法成功地为拥有小变化的代理-任务兼容性生成了多样化且高效的COA。通过将COAs视为集中式多机器人任务分配问题，并使用遗传算法优化任务分配的多样性，再通过图神经网络进行单个代理的任务顺序优化，该方法在模拟环境中展示了显著的性能改进。这项工作的结果不仅具有理论价值，还为实际的多代理操作提供了有价值的工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20031</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>601. cs.AI-量子神经网络在观察性生物医学研究中的倾向评分估计和生存分析</title><link>https://arxiv.org/pdf/2506.19973</link><description>Background: 
该研究旨在探讨量子神经网络（QNNs）在倾向评分估计中的应用，以解决因对比腹腔镜和开放手术技术治疗结肠直肠癌患者术后生存结果时产生的选择偏差。研究共分析了2001年至2009年间在奥斯特拉瓦大学医院接受治疗的1177例患者的数据，使用包含77个变量的大型数据集，包括患者人口统计学特征和肿瘤特征来建立模型，重点关注年龄、性别、分期和BMI四个关键协变量。

Innovation: 
研究采用了一种结合线性ZFeatureMap数据编码、SummedPaulis预测操作符及Covariance Matrix Adaptation Evolution Strategy (CMA-ES)的噪声鲁棒、无梯度优化方法。通过集成变异正则化来减轻量子测量噪声，并在精确模拟、采样（1024次射击）和模拟硬件噪声条件下进行了模拟实验。结果表明，特别是在模拟硬件噪声下，QNNs在小样本数据中表现优于经典的逻辑回归和梯度提升机，尤其是通过噪声建模增强预测稳定性。针对倾向评分匹配和加权进行的处理，以及使用遗传匹配优化和匹配权重，实现了变量平衡，标准化均数差异分别为0.0849和0.0869。经过调整后的生存分析结果表明，各组间无需显著生存差异（调整后p值0.287-0.851），表明未经调整的生存结果存在混杂偏倚。这些结果突显了CMA-ES和噪声意识策略增强的QNNs在生物医学研究中的潜在价值，特别是在小样本、高维数据集中的应用。

Conclusion: 
研究结果表明，QNNs在改善生物医学研究中因果推断方面具有潜力，尤其是在小样本和高维数据集上。优化的CMA-ES方法和噪声减敏策略进一步提高了其性能，展现了量子计算技术在生物医学研究中的应用前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19973</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>602. cs.AI-在合作多代理强化学习中的双边团队形成学习</title><link>https://arxiv.org/pdf/2506.20039</link><description>Background: 
多代理强化学习（MARL）背景下的团队形成和团队学习动态吸引了大量的研究兴趣。现有研究主要关注单方团体划分、预定义团队或固定群体设置，但动态群体中的算法双边团组选择的影响尚未充分探索。

Innovation: 
本文引入了一种框架来学习动态多代理系统中的双边团队形成。通过这项研究，我们深入了解了在双边团队形成中哪些算法属性会影响策略性能和泛化能力。我们使用广泛采用的多代理场景验证了我们的方法，展示了在大多数场景中具有竞争力的性能和改进的泛化能力。

Conclusion: 
我们的研究表明，算法性质对双边团队形成策略的性能和泛化能力有显著影响。通过实验验证，我们证明了在动态多代理系统中的双边团队形成方法的有效性和优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20039</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>603. cs.AI-揭示滚动扩散模型在概率天气预报中的应用</title><link>https://arxiv.org/pdf/2506.20024</link><description>Background: 
扩散模型是概率预测强有力的工具，尤其是在高维混沌系统中，通常预测未来的快照是逐个进行的。这种常见的方法难以建模复杂的时序依赖关系，且未明确考虑到这种系统中固有的不确定性逐渐增长的问题。尽管滚动扩散框架已在尝试解决这一问题，但将其与最先进的高保真扩散技术结合仍然存在重大挑战。因此，提出一种新的框架来解决这一问题是非常必要的，即通过引入编目滚动扩散模型（ERDM），使其能够结合滚动预测结构和编目扩散模型（EDM）的原理性强、性能良好的设计。

Innovation: 
ERDM通过将编目扩散模型的核心组件（噪声计划、网络预处理和Heun取样器）应用于滚动预测环境，实现了滚动预测结构与编目扩散模型设计的首次统一。创新点包括：(i) 一种新型的损失权重方案，专注于中期预测时间范围，该时间范围内的确定性开始让位于随机性；(ii) 使用预训练的编目扩散模型进行初始窗口的高效初始化策略；(iii) 特制的混合序列架构，用于在去噪情况下稳健地提取时空特征。ERDM在2D Navier-Stokes模拟和ERA5全球天气预报中表现出色，优于包括条件自回归EDM在内的关键基于扩散的方法基线。

Conclusion: 
ERDM提供了一个灵活且强大的通用框架，用于解决需要建模逐渐增加的不确定性的基于扩散的序列生成问题。该框架在2D Navier-Stokes模拟和ERA5全球天气预报中表现出了显著优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20024</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>604. cs.AI-RepuNet: 一种应对DFL中恶意客户端的声誉系统</title><link>https://arxiv.org/pdf/2506.19892</link><description>Background: 
Decentralized Federated Learning (DFL) 允许节点在没有中央服务器的情况下协作训练模型，但由于每个节点独立选择模型聚合的伙伴，引入了新的安全漏洞。恶意节点可以通过发送被篡改的模型（模型中毒）、延迟提交模型（延迟攻击）或向网络发送过多消息的方式利用这种自主性，这些行为会负面影响系统的性能。现有的解决方案通常依赖于固定的配置或额外的基础设施，如区块链，这会引发计算开销、可扩展性问题或适应性限制。

Innovation: 
为克服这些限制，本文提出了RepuNet，一种去中心化的声誉系统，该系统能够将DFL中的威胁进行分类，并使用模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为。根据节点的声誉评分调整其在模型聚合中的影响力。RepuNet 与去中心化的DFL平台Nebula集成，并通过MNIST和CIFAR-10数据集在非IID分布下进行实验评估，使用最多25节点的完全连接和随机拓扑结构的联邦。测试了不同强度、频率和激活间隔的攻击。结果表明，RepuNet 能够有效检测和缓解恶意行为，MNIST 场景下的 F1 分数超过 95%，CIFAR-10 情景下的 F1 分数约为 76%。这表明RepuNet具有高度的适应性、稳健性和在去中心化的分布式联邦学习环境中缓解威胁的实际潜力。

Conclusion: 
RepuNet 有效应对了DFL中恶意客户端带来的威胁，并在美国手写数字数据集（MNIST）和CIFAR-10数据集上成功地实现了高性能检测和缓解恶意行为的能力，显示了该系统在去中心化联邦学习环境中的适应性和稳健性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19892</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>605. cs.AI-HERCULES: 基于嵌入的递归层次聚类方法结合LLM进行高效总结</title><link>https://arxiv.org/pdf/2506.19992</link><description>Background: 
随着多模态复杂数据集的爆炸性增长，需要更先进的分析工具。这些工具不仅要有效地对数据进行分组，还需要为用户提供易于理解的关于所发现结构的洞察。

Innovation: 
HERCULES（嵌入基于层次递归聚类使用LLM进行高效总结）是一种新颖的算法和Python包，用于处理多种数据类型（包括文本、图像和数值数据）的层次k均值聚类。其创新之处在于深度整合大型语言模型，为聚类层次中的每个级别生成语义丰富的标题和描述，显著提高了可解释性。算法支持两种主要的表示模式：直接模式和描述模式，并为LLM生成的摘要提供了主题引导。

Conclusion: 
我们展示了HERCULES的功能，并讨论了它从复杂的多层次数据集中提取有意义的知识的潜力，其中包括提供交互式可视化工具以深入了解聚类结果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19992</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>606. cs.AI-具有挑战性的四足运动中层次强化学习和价值优化</title><link>https://arxiv.org/pdf/2506.20036</link><description>Background: 
本文提出了一个新的分层强化学习框架，用于在具有挑战性的地形上进行四足运动。该框架包含一个高低两层结构，高层策略（HLP）选择最优目标供低层策略（LLP）执行。LLP通过目标为脚步放置的在策略演员-评论家RL算法进行训练，HLP则通过在LLP学习的价值函数上进行在线优化过程来运行，而无需额外的训练或环境样本。这项研究通过与端到端的RL方法进行对比，展示了该框架的优势，包括在不同地形上实现更高奖励并减少碰撞的能力，特别是在训练过程中遇到的更难的地形上.

Innovation: 
该框架引入了一个新的HLP，通过在线优化过程在已学习的LLP价值函数上运行，而无需额外的训练或环境样本。通过与端到端的RL方法对比，展示出该框架在挑战性地形上的四足运动中能够获得更高的奖励并减少碰撞，特别是在训练中遇到的更难的地形上

Conclusion: 
实验结果表明，该分层强化学习框架在多种地形条件下，特别是在难度更高的地形上，相比于端到端的RL方法，能够更有效地提高奖励并减少碰撞。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20036</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>607. cs.AI-TRACED: 过渡感知的遗憾近似与共学习能力在环境设计中的应用</title><link>https://arxiv.org/pdf/2506.19997</link><description>Background: 
在未见过的环境中推广深度强化学习代理仍然是一个重大挑战。一种有希望的解决方案是无监督环境设计（UED），它是一个共进化框架，其中教师会根据学习潜力自适应地生成任务，而学生则学习来自不断演化的课程的稳健策略。现有的UED方法通常通过遗憾来衡量学习潜力，遗憾是当前性能与最优性能之间的差距，仅通过值函数损失近似。

Innovation: 
本文引入了过渡预测误差作为遗憾近似的额外项，并提出了轻量级共学习能力度量，以捕捉一项任务的训练如何影响其他任务的性能。通过结合这两种衡量标准，文章提出了过渡感知遗憾近似与共学习能力的环境设计（TRACED）。经验评估表明，TRACED 在多个基准测试中提高了零样本泛化能力，同时所需的环境交互次数比强大的基线算法少至多2倍。消融研究表明，过渡预测误差促进了快速的复杂性提升，而共学习能力在与过渡预测误差结合使用时能带来额外的增益。这些结果证明了改良的遗憾近似和任务关系的显式建模如何被利用于UED中的样本高效课程设计。

Conclusion: 
这些结果展示了改进的遗憾近似和任务关系的显式建模如何被用于UED中的样本高效课程设计，TRACED 提出了一个新的框架，通过结合过渡预测误差和共学习能力，提高了零样本泛化能力，同时显著减少了环境交互次数。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19997</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>608. cs.AI-MATER：自然条件下多级声学和文本情绪表示方法的意义阐释语音情绪识别</title><link>https://arxiv.org/pdf/2506.19887</link><description>Background: 
本文提出了对自然条件下语音情绪识别（SERNC）挑战的贡献，关注类别情绪识别和情感属性预测。由于自然语音中存在的个体间和个体内的复杂性，如变化性和差异性，本文提出了一个多级声学-文本情绪表示方法（MATER），这是一个新颖的分层框架，将声学和文本特征整合到词、短语和嵌入层面。通过结合低层次的词汇和声学线索与高层次的上下文化表示，MATER 有效地捕捉到了细微的音韵变化和语义内涵。此外，本文引入了一种对注释员不一致性有感知的集成策略，增强了在模糊情绪表达中的鲁棒性。

Innovation: 
提出了一个新颖的分层框架——多级声学-文本情绪表示方法（MATER），将声学和文本特征整合到词、短语和嵌入层面。结合低层次的词汇和声学线索与高层次的上下文化表示，从而有效捕捉到细微的音韵变化和语义内涵。引入了一种对注释员不一致性有感知的集成策略，提高情绪识别的鲁棒性。MATER 在两个任务中表现突出，实现了宏 F1 得分41.01%，平均CCC得分0.5928，并在情感值预测任务中取得了令人印象深刻的CCC得分0.6941，排名第二。

Conclusion: 
MATER 在两类任务中表现突出，MACRO-F1得分41.01%，平均CCC得分0.5928，并在情感值预测任务中取得了令人印象深刻的CCC得分0.6941，排名第二。该方法有效地捕捉语音中的细微音韵变化和语义内涵，并通过处理注释员的一致性问题增强了情感识别的鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19887</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>609. cs.AI-探究展开与微调在量子联邦学习中的新见解</title><link>https://arxiv.org/pdf/2506.20016</link><description>Background: 
量子联邦学习（QFL）由于客户端异质性而面临重大性能挑战。标准聚合方法在高度异质性环境中通常会失效，导致过拟合等问题。

Innovation: 
提出了一种新方法，利用深度展开技术，使客户端能够根据其特定的训练行为自主优化超参数，如学习率和正则化因子，实现动态适应。这种方法能够减轻过拟合，确保在高度异质性的环境中实现稳健优化，从而显著提高了准确性，优于传统方法。

Conclusion: 
该方法通过在IBM量子硬件和Qiskit Aer模拟器中进行实时训练，证明了在关键应用如基因表达分析和癌症检测中的有效性，提升了诊断精度和预测建模。研究结果表明，该方法解决了传统QFL的核心局限性，使其更适用于包括医疗健康和基因组研究在内的复杂问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20016</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>610. cs.AI-基于推理时缩放的GraphRAG：在知识图上提高多跳问答性能</title><link>https://arxiv.org/pdf/2506.19967</link><description>Background: 
大语言模型（LLMs）在语言理解和生成方面取得了令人印象深刻的能力，但在知识密集型推理任务上仍然表现不佳，主要是由于对结构化上下文和多跳信息的限制访问。检索增强生成（RAG）在一定程度上通过生成与检索到的上下文相关联的方式缓解了这一问题，但传统的RAG和GraphRAG方法往往无法捕捉知识图中节点间的关系结构。本研究旨在通过引入基于推理时缩放的GraphRAG框架，增强基于LLM的图推理能力，利用推理时间上的计算缩放，结合顺序缩放和深度链式推理遍历，以及并行缩放和交错推理-执行循环内的采样轨迹多数投票，改进多跳问答性能，超出了传统GraphRAG和之前的图遍历基线。这种方法表明，在LLM中进行结构化知识推理时，推理时的缩放是一种实用且架构无关的解决方案。

Innovation: 
本研究提出了一种新颖的框架——基于推理时缩放的GraphRAG，通过应用推理时的计算缩放来增强基于LLM的图推理能力。该方法结合了顺序缩放和深度链式推理遍历，以及并行缩放和交错推理-执行循环内的采样轨迹多数投票，从而显著提高了多跳问答性能，实现了与传统的GraphRAG和先前的图遍历基线相比的重要增益。

Conclusion: 
研究结果表明，推理时缩放是一种实用且架构无关的解决方案，用于用大语言模型进行结构化知识推理，其方法和性能在GRBench基准测试中得到了验证，展示了明显的优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19967</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>611. cs.AI-基于层间最近邻的不确定性量化框架</title><link>https://arxiv.org/pdf/2506.19895</link><description>Background: 
神经网络在难以检测模式或构建逻辑模型的问题上具有高精度，但有时会返回错误的解决方案，在高风险领域如医疗诊断或自动驾驶中成为问题。为了检测并减轻这些错误，可以通过测量神经网络决策的不确定性来进行。本文介绍了一种新的后处理框架，基于检索与查询在每层具有相似激活向量的训练案例来估计决策的不确定性。通过这些检索的案例，提出了决策变化（Decision Change）和层不确定性（Layer Uncertainty）两个新的度量标准，它们捕捉各层最近邻类别分布的变化。该方法在CIFAR-10和MNIST两个数据集中进行了分类模型的评估，结果表明这些度量标准可以提高不确定性估计，尤其在挑战性的分类任务中优于基于softmax的置信度方法。

Innovation: 
提出了一个新的后处理框架，通过检索具有相似激活向量的训练案例来估计决策的不确定性，并提出了决策变化和层不确定性的两个新度量标准，以捕捉各层最近邻类别分布的变化。该框架在CIFAR-10和MNIST数据集上的分类模型评估中优于基于softmax的置信度方法，特别在挑战性分类任务中展示了更好的不确定性估计效果。

Conclusion: 
基于层间最近邻的不确定性量化框架可以有效提高决策的不确定性估计，尤其在复杂的分类任务中优于传统的softmax置信度方法，为减少神经网络在高风险领域的潜在错误提供了新的策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19895</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>612. cs.AI-在代码分割过程中，LLMs能否替代人类？</title><link>https://arxiv.org/pdf/2506.19897</link><description>Background: 
大型语言模型（LLMs）已成为计算机科学中的重要工具，尤其是在代码理解和生成任务中。然而，现有的研究尚未解决政府应用中代码编写所面临的独特挑战，尤其是这类代码多采用复古语言如MUMPS或汇编语言代码（ALC），且整个代码系统中的token长度超出了当前商用LLMs的上下文窗口大小。此外，大多数LLMs主要经过现代编程语言的训练，对于复古语言的测试较少，因此它们处理复古语言的能力有待研究。本文探讨了LLMs在政府应用中MUMPS和ALC等复古代码现代化过程中代码分割的应用，重点关注输入限制的问题。通过评估不同的代码分割方法对不同LLMs生成文档质量的影响，本文展示了代码分割方法对下游任务如文档生成的显著影响。

Innovation: 
本文创新性地探讨了LLMs在复古政府代码现代化中的应用，具体通过研究多种代码分割方法，优化了LLMs生成摘要模块注释的效果，评价了不同LLMs（包括GPT-4o、Claude 3 Sonnet、Mixtral、Llama 3）在代码分割方法上的表现。实验结果表明，与人工分割相比，LLMs生成的代码分割更贴近人类专家的分区，而且生成的注释在事实性和实用性上更佳。

Conclusion: 
因此，本研究得出结论，LLMs可以在LLMs辅助的代码现代化过程中替换人类进行大规模代码库的分区工作。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19897</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>613. cs.AI-基于因果意识的自适应关键帧提取的VR交互QoE智能优化</title><link>https://arxiv.org/pdf/2506.19890</link><description>Background: 
多用户虚拟现实交互要求在超低延迟、高保真运动同步和公平资源分配之间取得微妙平衡。现有的自适应关键帧提取方法虽然减少了传输开销，但仍经常忽视分配带宽、CPU频率和用户感知之间的因果关系，限制了用户体验（QoE）的提升。

Innovation: 
本文提出了一个智能框架，结合自适应关键帧提取与因果感知增强学习（RL），通过因果影响检测，引入权重计算来自因果推理（CI）的行动指导，利用因果信息探索行动，改善训练效率，最终通过混合整数规划（MIP）问题优化关键帧、带宽和计算资源，以最大化QoE，显著降低交互延迟，提高QoE表现，并保持公平性，优于基准方法。

Conclusion: 
通过新提出的自适应关键帧提取与因果感知增强学习方法，我们在CMU运动捕捉数据库上进行了实验。结果显示，该框架不仅显著减少了交互延迟，提升了QoE表现，还维持了公平性，并表现出优于基准方法的综合性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19890</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>614. cs.AI-一种精确描述化学键断裂的从头基础波函数模型</title><link>https://arxiv.org/pdf/2506.19960</link><description>Background: 
可靠的描述化学键断裂仍然是量子化学中的一个主要挑战，因为解离物种的电子结构具有多参考性。特别是多参考方法由于计算成本高昂，必须为每个系统从头计算，不考虑不同分子间电子结构的共性。量子蒙特卡洛与深度神经网络（Deep QMC）通过预先训练可转移的波函数模型来利用这种共性，但过去的尝试都局限在一定的范围内。

Innovation: 
本文介绍了Orbformer，这是一种新型的转移波函数模型，预先训练了22,000种平衡和解离结构，并可以对未见过的分子进行微调。这种模型在化学键断裂和更具有挑战性的Diels-Alder反应等基准测试中都达到了化学精度（1 kcal/mol），它是唯一稳定收敛的方法。这项工作将解决薛定谔方程求解成本的摊销思想转化为量子化学中的实际方法。

Conclusion: 
Orbformer为量子化学领域提供了一种实用的方法，可以在处理大量分子的过程中摊销解薛定谔方程的成本，并通过其优越的准确性和计算成本比例竞争传统多参考方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19960</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>615. cs.AI-CycleDistill：利用循环蒸馏从大规模语言模型中启动机器翻译</title><link>https://arxiv.org/pdf/2506.19952</link><description>Background: 
尽管大规模语言模型（LLMs）能够在少量示例下执行机器翻译（MT），但往往比在平行语料库上训练的专门MT系统性能较弱，而这类平行语料库对于高质量MT至关重要。然而，平行语料库在低资源语言中往往稀缺或不存在。这篇文章的背景是在没有大量平行语料库的情况下，提出了一种新的方法来提高MT的性能。

Innovation: 
该文提出了名为CycleDistill的方法，这是一种利用大规模语言模型和少量示例翻译来逐步提高机器翻译质量的自举方法。该方法通过循环生成合成平行语料库，迭代地用于模型的微调，仅需1到4个少量示例，就可以在没有平行语料库的情况下实现高质量的MT，相较于少量示例基线模型，在第一轮翻译质量提高了超过20-30分chrF值。此外，该方法还研究了在蒸馏过程中利用softmax激活的影响，观察到轻微的翻译质量提高。

Conclusion: 
CycleDistill方法通过利用大规模语言模型和少量示例翻译，能够在缺乏平行语料库的情况下逐步提升机器翻译质量。在实验中，通过仅仅依靠单语料库，该方法能够取得高质量的翻译效果，且相比基线模型有显著提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19952</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>616. cs.AI-FlightKooba：一种快速可解释的飞行轨迹预测模型</title><link>https://arxiv.org/pdf/2506.19885</link><description>Background: 
Koopman理论是一种强大的模型工具，能够将非线性系统转换为线性表示；飞行轨迹预测（FTP）是一个复杂的非线性系统。然而，目前应用于FTP任务的Koopman理论模型效果不佳，模型的可解释性是一个问题，Koopman算子的计算密集度导致了长时间的训练过程。由此，本文提出一种基于HIPPO方法、Koopman理论和控制理论状态空间方程的新建模和控制框架，即FlightKooba。

Innovation: 
FlightKooba框架借鉴结构化状态空间方程的理念，直接从数据中构造Koopman算子，使其具有高度的可解释性，并显著减少了模块可训练参数的数量，进而极大地减少了训练时间。实验结果显示，FlightKooba建模方法在时间和内存消耗方面表现出优越性（与不使用CUDA级加速的Mamba模块的训练时间相当；大部分数据集的内存消耗减少了50％以上，参数数量减少了十倍），基本完成FTP任务，并提供了快速计算Koopman算子的新方法，为时间序列预测和控制的结合开辟了新的可能性。

Conclusion: 
FlightKooba方法通过大幅减少可训练参数并在不使用加速情况下具有相似的训练时间，是提高非线性系统建模效率的一种有效方式，为未来类似任务提供了新思路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19885</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>617. cs.AI-使用XAI方法解释用于电力价格预测的深度神经网络模型</title><link>https://arxiv.org/pdf/2506.19894</link><description>Background: 
电力市场极其复杂，涉及大量的互动和复杂的相互依赖关系，使理解市场内部运作和价格驱动因素变得困难。经济学方法虽然已开发出来，但白盒模型的有效性不如深度神经网络模型（DNN）。因此，本文旨在使用DNN进行价格预测，并结合XAI方法来理解驱动市场动力的因素。目的是加深对不同电力市场工作原理的理解。为实现这一目标，我们使用了可解释的方法，如SHAP和梯度，结合热图等可视化技术来分析五个电力市场的各种特征行为和贡献。

Innovation: 
本文引入了SSHAP值和SSHAP线的概念，以增强高维表型模型的复杂表示。此外，通过结合XAI方法和可视化技术，本文旨在提高对电力市场价格动态因素的理解，这是之前研究没有充分实现的创新点。

Conclusion: 
通过使用深度神经网络和解释性方法（如SHAP、梯度和热图），本文研究了五个电力市场的价格动态。通过SSHAP值和SSHAP线的引入，增强了对复杂的高维模型的解释，帮助更好地理解不同市场的运行机制。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19894</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>618. cs.AI-AIGC任务中生成语义通信的蒸馏增强知识对齐</title><link>https://arxiv.org/pdf/2506.19893</link><description>Background: 
由于AI生成内容（AIGC）的数量激增，将这些内容从云传输到边缘和移动用户的网络流量显著增加。生成语义通信（GSC）通过传输高度浓缩的信息（如提示文本和潜在表示）而非高维度AIGC数据，提供了一种潜在的解决方案。然而，GSC依赖于云生成AI（GAI）与边缘和用户之间的知识对齐，以及无线传输知识与实际信道知识之间的对齐，目前仍是一个挑战性问题。

Innovation: 
本文提出了一种名为DeKA-g的蒸馏增强知识对齐算法，用于GSC系统。该算法的核心思想是从云GAI中提炼生成知识为低秩矩阵，并将其整合到边缘以适应不同的无线信道条件。DeKA-g包含两种新颖的方法：带有元词辅助的知识蒸馏（MAKD）和变率分组SNR适应（VGSA）。MAKD通过优化元词提高知识蒸馏效率，而VGSA使系统能够高效地适应不同的压缩率和SNR范围。实验结果表明，DeKA-g在边缘生成的图像与云生成图像之间提高了44%的知识对齐，并且与基线相比提高了116%的压缩率适应效率，在低SNR条件下提升了28%的性能.

Conclusion: 
实验结果表明，DeKA-g算法在提高边缘生成图像与云生成图像之间的知识对齐上表现出色，提升了44%。同时，与基线相比，其在压缩率适应方面提高了116%的效率，在低SNR条件下的性能提升了28%。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19893</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>619. cs.AI-MNN-AECS：通过自适应核心选择在移动设备上优化LLM解码的能耗</title><link>https://arxiv.org/pdf/2506.19884</link><description>Background: 
随着对设备本地大型语言模型（LLM）推理需求的增长，能耗效率已成为主要关注问题，尤其是在电池有限的移动设备上。已有研究大多集中在加速预填充阶段，而忽视了能耗问题。LLM解码阶段是能耗的主要来源，为此，我们提出了自适应能效核心选择（AECS）策略，并将其集成到MNN中，形成了无需root权限或操作系统修改的MNN-AECS能效版本，这是首个用于移动设备的引擎级系统解决方案。MNN-AECS旨在通过动态选择低功耗CPU核心，在可接受的减速门槛内降低LLM解码的能耗。

Innovation: 
MNN-AECS通过自适应核心选择策略，实现了在保持解码速度在可接受减速阈值内的情况下，有效降低LLM解码能耗。MNN-AECS被评估5款Android和2款iOS设备上的5款不同大小的流行LLM。与原始MNN相比，MNN-AECS在所有7款设备和4款数据集上的能耗降低了23%（平均值）。MNN-AECS与包括其他引擎（https://this.is/executorch, mllm, MediaPipe）相比，在平均情况下实现了高达78%的能耗节省和12%到363%的速度提升。

Conclusion: 
MNN-AECS是首个无需root权限或操作系统修改的能效版本，通过自适应核心选择在保持LLM解码可接受速度的前提下显著降低了能耗，显示出卓越的性能和能效，表明了其在实际应用中的潜力和价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19884</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>620. cs.AI-Orthogonal Soft Pruning for Efficient Class Unlearning</title><link>https://arxiv.org/pdf/2506.19891</link><description>Background: 
机器遗忘的目标是通过从预训练神经网络中选择性地移除特定类别的知识来满足GDPR等隐私法规的要求。现有的方法通常在去训练的速度和保留预测准确度之间存在权衡，往往需要高昂的计算开销或对保留类别的显著性能下降。

Innovation: 
本文提出了一种新颖的类自觉软剪枝框架，利用正交卷积内核正则化来实现快速而精确的记忆遗忘，响应时间在毫秒级别。通过在训练过程中施加正交性约束，该方法在卷积滤波器之间建立反相关，并分离特征表示，同时通过激活差异分析有效地识别特定于类的通道。

Conclusion: 
广泛的评估表明，该方法在接近即时的执行、完全遗忘目标类别以及保留数据上的小幅度准确性损失方面表现出稳定剪枝。在CIFAR-10、CIFAR-100和TinyImageNet上进行的实验表明，该方法能够显著降低成员推理攻击风险，并且相较于最先进的基线，极大地加快了去训练的速度。这种框架为机器学习即服务(MLaaS)场景中的实时机器遗忘提供了有效的、可行的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19891</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>621. cs.AI-多代理推理和心智理论基准——Decrypto</title><link>https://arxiv.org/pdf/2506.20664</link><description>Background: 
随着大型语言模型（LLMs）获得代理能力，它们将在复杂的多代理情景中导航，与人类用户和其他代理进行合作和竞争的互动。这需要新的推理能力，其中最突出的是心智理论（ToM），即能够推理其他代理的“心理”状态。然而，LLMs中的ToM和其他多代理能力尚未被充分理解，因为现有的基准测试存在范围狭窄、数据泄露、饱和、缺少互动性等问题。因此，本文提出Decrypto，一个游戏为基础的多代理推理和ToM基准，灵感源自认知科学、计算语用学和多代理强化学习。它在所有其他维度上尽可能简化设计，消除其他基准测试中常见的混淆因素。据我们所知，它也是第一个设计互动ToM实验的平台。我们通过全面的经验性评估前沿的LLM、鲁棒性研究及人机交叉播放实验对基准设计进行了验证。我们发现LLM的游戏能力落后于人类和简单的词嵌入基准。然后我们创建Decrypto内的经典认知科学实验变体来评估三种关键的ToM能力。令人惊讶的是，我们发现最新的推理模型在这项任务上的表现远不如它们的前辈。这表明Decrypto在当前推理和ToM评估中存在关键差距，并为更优的人工智能代理铺平了道路。

Innovation: 
提出Decrypto，一个游戏为基础的多代理推理和ToM基准，灵感源自认知科学和多代理强化学习。这个基准设计考虑到消除其他基准测试中的常见混淆因素，创建了第一个设计互动ToM实验的平台。通过全面的经验性评估验证了基准设计的有效性，并展示了最新的推理模型在某些方面不如古老的模型。

Conclusion: 
Decrypto弥补了当前推理和ToM评估中存在的关键差距，通过游戏化设计提升了多代理情境下的交互性和科学性。进一步的研究可以通过在Decrypto平台上进行更多的实验，探索不同类型的多代理情景，以提升多代理人工智能代理的能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20664</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>622. cs.AI-Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models</title><link>https://arxiv.org/pdf/2506.19889</link><description>Background: 
近年来，大规模语言模型（LLMs）在社会中产生了深远的影响，但也引发了新的安全问题。特别是在Staab等人揭示隐私违规攻击（PVA）之后，模型的出色推理能力导致了严重的个人隐私问题。现有的防御方法主要通过LLMs匿名化输入查询来应对，这需要大量推理时间和无法提供满意的防御效果。此外，直接拒绝PVA查询似乎是一个有效的防御策略，但这会暴露防御方法，从而促进PVA的进化。特别是在这些方面，现有研究存在不足。

Innovation: 
本文提出了一种基于LLMs检索混淆生成（RCG）的新型防御范式，能够在高效和隐蔽的情况下抵御PVA。首先设计了一个改述提示，诱导LLMs重新编写攻击查询的“用户评论”，构造一个被干扰的数据库。然后提出了最不相关的检索策略，从被干扰的数据库中检索所需用户数据。最后，用检索到的用户数据替换“数据评论”以形成防御查询，从而用错误的个人属性回应攻击者，使攻击失败。这种方法已经在两个数据集和八种流行的LLMs上进行了广泛实验，以全面评估其可行性和优越性。

Conclusion: 
实验结果表明，基于检索混淆生成的方法可以在高效且隐蔽的情况下有效抵御PVA，显示出优越的防御性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19889</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>623. cs.AI-基于生成对抗网络的医疗保险欺诈检测攻击方法</title><link>https://arxiv.org/pdf/2506.19871</link><description>Background: 
保险欺诈检测是现代保险服务中的关键进步，能够提供智能化和数字化的监控，提高管理效率并防止欺诈。这对于确保保险系统的安全性和高效性至关重要。尽管人工智能和机器学习算法在检测欺诈索赔方面表现出色，但由于缺乏标准的防御机制，当前系统易受新兴的对抗性威胁。因此，需要增强保险欺诈检测模型的鲁棒性，以抵御对抗性操纵，确保不同保险系统的稳定性和可靠性。

Innovation: 
提出了一种基于生成对抗网络（GAN）的攻击方法，用于对欺诈检测系统进行攻击。该研究发现，攻击者无需知晓训练数据或内部模型细节，也能生成被分类为合法的欺诈案例，攻击成功率高达99%。通过微小修改真实的保险记录和索赔信息，攻击者可以显著增加欺诈风险，从而可能绕过受损的检测系统。

Conclusion: 
研究成果强调了增强保险欺诈检测模型对抗操作的鲁棒性的紧迫性，从而确保不同保险系统的稳定性和可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19871</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>624. cs.AI-利用AI进行欺诈检测与能源市场稳定性的区块链辅助安全能源交易</title><link>https://arxiv.org/pdf/2506.19870</link><description>Background: 
随着美国能源市场的去中心化和点对点交易的发展，市场安全和交易真实性成为新的挑战。此研究旨在开发并构建一个适用于美国去中心化能源市场的安全、智能和高效的能源交易系统。该研究将区块链技术和人工智能首次结合，以解决分布式能源市场长期存在的安全、欺诈行为检测和市场可靠性等问题。研究使用的数据集包含超过120万条匿名化的能源交易记录，这些记录来自模拟的点对点能源交易平台，该平台模仿真实的基于区块链的美国微电网，包括LO3 Energy和Grid+ Labs测试的微电网。每个记录包含多样化的字段，如交易标识符、时间戳、交易能量体积（kWh）、交易类型（买入/卖出）、单位价格、消费者/生产者标识（使用哈希加密以保护隐私）、智能电表读数、地理区域信息和结算确认状态。数据集还包含系统计算的交易频率、能源生产波动性和历史价格模式等行为指标。

Innovation: 
该研究创新发展地将区块链技术和人工智能相结合，用于能源交易的安全保障和市场智能提升。研究使用的机器学习模型因其在分类任务中的高性能被选择，特别是在分布式市场中的能源交易欺诈识别方面表现出色。研究通过区块链层和人工智能层的整合，提供了一种全新的解决方案，增强了安全性和市场可靠性。

Conclusion: 
通过将区块链技术与人工智能相结合，研究提出了一个在去中心化美国能源市场中实施的安全且高效的能源交易系统，该系统不仅能够提高交易的安全性和透明度，还提高了市场的智能性，有助于检测欺诈行为并增强市场的稳定性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19870</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>625. cs.AI-机器学习会议应当建立‘反驳与评论’轨道</title><link>https://arxiv.org/pdf/2506.19882</link><description>Background: 
科学通过迭代地推进和修正人类对世界的理解而发展。在机器学习（ML）研究中，快速的发展导致了大量出版物的增长，但也导致误导性、错误、有缺陷或甚至可能虚假的研究在ML会议中被接受并有时被强调。由于同行评审的局限性，这种错误是可以理解的，但ML会议并未提供足够的机制来系统地纠正这些错误。

Innovation: 
该论文提出建议，即机器学习会议应建立一个专门的‘反驳与评论’（R &amp;amp; C）轨道。这个R &amp;amp; C轨道将为支持批判性挑战先前研究的重要研究提供一个高知名度且值得信赖的平台，从而促进动态的自我纠正研究生态系统。论文还讨论了轨道设计、评审原则以及可能的陷阱，并提供了一个关于最近ICLR 2025 Oral的示例提交。

Conclusion: 
机器学习会议应该创建官方且值得信赖的机制来辅助机器学习研究的自我修正。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19882</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>626. cs.AI-网络流量中鲁棒异常检测：CICIDS2017上的机器学习模型评估</title><link>https://arxiv.org/pdf/2506.19877</link><description>Background: 
识别适合入侵检测的机器学习范式对于构建有效且可泛化的安全解决方案至关重要。本文通过在CICIDS2017数据集上两种场景下对四个代表性模型进行了对比研究：检测已知攻击类型和对以前未见过的威胁进行泛化。这些模型包括多层感知器（MLP）、一维卷积神经网络（CNN）、一类支持向量机（OCSVM）和局部异常因子（LOF）

Innovation: 
通过在CICIDS2017数据集上对比监督学习下的MLP和CNN，以及非监督学习下的LOF和基于边界的一类支持向量机（OCSVM）在检测已知攻击和先前未知威胁时的表现，探索了不同模型在动态网络环境下的性能差异及其适用性

Conclusion: 
监督学习的MLP和CNN在熟悉攻击上的准确率接近完美，但在新型攻击上的召回率急剧下降。非监督学习的LOF在未知威胁上获得了中等的整体准确率和高的召回率，但代价是较高的误报率。边界基于的一类支持向量机在精确度和召回率之间取得了最佳平衡，展示了在两种场景下的稳健检测能力，为在动态网络环境中选择IDS模型提供了实用指导</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19877</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>627. cs.AI-使用说话人嵌入提高间歇移动说话人跟踪的方法</title><link>https://arxiv.org/pdf/2506.19875</link><description>Background: 
说话人跟踪方法通常依赖于空间观测来为时间上的一致的跟踪身份分配。但在间歇性和移动性强的过程中出现限制，例如在说话人不活跃时可能改变位置，导致空间轨迹出现不连续性。

Innovation: 
本文提出了一种简单的方法，利用说话人嵌入进行身份重赋值。通过采用初始跟踪步骤提供的轨迹相关信息和多声道音频信号，使用波束成形技术改进朝向说话人位置的信号，以计算说话人嵌入。然后根据注册池使用这些嵌入来进行新的轨迹身份分配，从而提高基于神经网络和标准跟踪系统的身份分配性能。

Conclusion: 
研究结果表明，提出的基于说话人嵌入的身份重赋值方法在说话人在不活跃期间改变位置的数据集上一致地提高了身份分配性能，特别研究了波束成形和输入时长对嵌入提取的影响。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19875</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>628. cs.AI-利用双向充电实现利润优化的智能出行和配送服务：基于电动汽车</title><link>https://arxiv.org/pdf/2506.20401</link><description>Background: 
随着电动汽车（EVs）的普及，现代服务系统，如网约车和配送服务，正越来越多地将EVs纳入其运营中。尽管这种电动汽车具有更高的能源效率，但在履行请求时，它们通常具有更短的行驶范围，需要仔细考虑充电问题。最近，车辆到电网（V2G）技术的发展使得电动汽车不仅能够充电还能向电网放电，从而带来了新的机会和挑战。因此，有必要研究如何利用电动汽车的独特特性来提高运营效率和经济收益，特别是在网约车和配送服务领域中的应用。

Innovation: 
本文提出了电动汽车面向对象问题与V2G技术（EVOP-V2G）：一个以最大化利润为目标的问题。该问题旨在让电动汽车驾驶员在满足客户需求的同时管理何时何地充电或放电。这一过程涉及到动态电价、充电站选择和路径限制。作者通过混合整数规划（MIP）模型来形式化这一问题，并提出了两种近似最优的元启发式算法：一种是进化算法（EA），另一种是大规模邻域搜索（LNS）算法。实验结果表明，在真实世界数据上的测试中，与基准方法相比，该方法能够将驾驶员的利润翻倍，在小型实例上保持了最优性能，对于大型实例则展现了出色的可扩展性。

Conclusion: 
本研究强调了智能、盈利能力更强的基于电动汽车的移动系统的发展潜力，这些系统能够积极支持电网。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20401</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>629. cs.AI-DualEquiNet: 一种适用于大型生物分子的双空间分层不变网络</title><link>https://arxiv.org/pdf/2506.19862</link><description>Background: 
几何图神经网络（GNNs）在小分子建模方面表现出色，但在应用于大型生物分子（如RNA和蛋白质）时面临可扩展性和表达能力的挑战。现有几何GNNs在捕捉细粒度原子相互作用、跨越空间远处组件的长距离依赖关系以及生物相关层级结构（如原子形成残基，进而形成更高级别的域）方面能力有限。这些任务需要能够在欧几里得和球谐空间二者之间同时捕捉局部几何和全局对称特征的模型，但现有的大多数几何GNNs通常只能在这两个空间中单一工作，因而无法同时捕捉细粒度原子细节和长距离、对称感知的依赖关系，以对大型生物分子的多层次结构进行建模。已有研究工作中提及这些问题，但未提出有效的解决方案来处理这些挑战。因此，亟需一种新的方法解决这些问题，以增强在大型生物分子中的模型规模和表达能力。

Innovation: 
本文引入了DualEquiNet，这是一种双空间分层不变网络，它在欧几里得和球谐空间中构建互补表示，以捕获局部几何和全局对称感知特征。DualEquiNet采用双向跨空间消息传递和一种新颖的跨空间交互聚合机制，逐级聚合原子特征，从而构建生物有意义的单元（如残基），以实现大型生物分子系统的高效和表达性强的多层次建模。DualEquiNet在已有的核糖核酸（RNA）属性预测和蛋白质建模基准测试中获得了最先进的性能，在两个新引入的三维结构基准测试中也优于先前的方法，展示了其在一系列大型生物分子建模任务中的广泛应用效果。

Conclusion: 
DualEquiNet解决了现有几何GNNs在处理大型生物分子如RNA和蛋白质建模时存在的问题，能够同时捕捉细粒度原子细节和长距离、对称感知的依赖关系，从而高效且表达性强地进行多层次建模。实验结果表明，DualEquiNet在多个现有基准测试和新引入的三维结构基准测试中取得了最先进的性能，并且在多个大型生物分子建模任务中都表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19862</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>630. cs.AI-可证明(不)安全的模型权重释放方案进展</title><link>https://arxiv.org/pdf/2506.19874</link><description>Background: 
近年来，一些安全权重释放方案声称能够在保护模型版权和防止滥用的同时实现开源模型的分发。然而，这些方法在安全基础方面缺乏严谨性，只能提供松散的安全保证。研究者根据密码学领域的现有成果，通过正式定义的方法来标准化权重释放方案的安全性，并通过一个具体的案例研究——TaylorMLP——印证了其定义的有效性和实用性。研究发现，TaylorMLP存在漏洞，能够被利用进行参数提取，从而证明它未能实现其松散的安全目标。

Innovation: 
提出并引入了几种具体的安全定义来正式定义权重释放方案的安全性；通过具体案例研究验证了这些定义的有效性；揭示了现有的权重释放方案（如TaylorMLP）的安全漏洞，并展示了其未能达成其松散安全目标的事实。

Conclusion: 
希望这项工作能倡导将机器学习和安全性研究领域进行深入的严谨研究，并提供未来权重释放方案设计与评估的框架。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19874</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>631. cs.AI-可扩展且成本效益高的从头基于模板的分子生成</title><link>https://arxiv.org/pdf/2506.19865</link><description>Background: 
基于模板的分子生成方法通过确保生成的化合物可以通过预定义的反应模板和构建块合成，为药物设计提供了有前景的途径。然而，在基于模板的GFlowNets中存在三大核心挑战：(1) 最小化合成成本，(2) 扩展到大规模构建块库，(3) 有效利用小片段集。

Innovation: 
本文提出了两个创新点：(1) 提出了一种递归成本指导框架，通过辅助机器学习模型估算合成成本和可行性来引导生成过程，显著提高成本效益、分子多样性和质量。特别是结合了一个替代探索与利用之间权衡的利用惩罚机制。(2) 开发了一种动态库机制，通过重复使用高奖励中间态来构建完整的合成树，以提高小规模构建块库中的性能。

Conclusion: 
本研究在基于模板的分子生成中建立了最新的基准结果，通过解决核心挑战提高了合成效率和成本效益。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19865</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>632. cs.AI-基于对大规模语言模型的调优和提示工程，构建多agent AI解决可持续蛋白质生产问题</title><link>https://arxiv.org/pdf/2506.20598</link><description>Background: 
全球对可持续蛋白质来源的需求增长加速了对智能工具的需求，这些工具能够迅速处理和合成特定领域的科学知识。本研究旨在开发一个支持可持续蛋白质生产研究的多Agent人工智能框架，初始重点是微生物蛋白质来源。

Innovation: 
该研究提出了一种基于RAG的系统，该系统由两个基于GPT的大型语言模型（LLM）构成：一个是文献检索Agent，另一个是信息提取Agent。此外，研究探索了调优和提示工程两种方法来优化Agent性能，结果显示调优方法提升了平均余弦相似度分数，并且整体表现更优。

Conclusion: 
研究人员开发并发布了用户界面，使多Agent AI系统得以使用，并初步探索了额外的基于化学安全性的搜索能力。调优方法总体上提高了平均分数，达到≥0.94，尽管提示工程方法显示出较低的统计不确定性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20598</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>633. cs.AI-移动-R1：基于任务级奖励的交互式强化学习方法研究</title><link>https://arxiv.org/pdf/2506.20332</link><description>Background: 
基于视觉-语言模型的移动代理已经获得理解复杂指令和移动截图的能力，并通过思考和推理优化其动作输出，得益于强化学习如GRPO。然而，现有的研究主要集中在线下强化学习训练或基于动作级奖励的在线优化，这限制了代理与环境的动态交互，使代理容易陷入局部最优，削弱了它们的探索能力和错误矫正能力。因此，需要一种新的方法来解决这些挑战。

Innovation: 
提出了一种名为Mobile-R1的方法，使用基于任务级奖励的交互式多轮强化学习训练移动代理。Mobile-R1的训练框架包括三个阶段：初始格式微调、基于动作级奖励的单步在线训练，以及基于多轮轨迹的任务级奖励的在线训练。这种方法旨在增强Mobile-R1的探索和错误修正能力，从而显著提高性能。此外，还收集了涵盖28个中国应用程序的24,521个高质量手动注解的数据集，并建立了新基准，包括500个轨迹。所有资源如数据集、基准、模型权重和代码将开源：[链接]。

Conclusion: 
Mobile-R1通过引入基于任务级奖励的交互式多轮强化学习方法，显著提升了视觉-语言模型驱动的移动代理的探索和错误修正能力，为这类代理提供了新的训练框架和资源。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20332</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>634. cs.AI-探索前沿大语言模型在核能研究中的能力</title><link>https://arxiv.org/pdf/2506.19863</link><description>Background: 
在橡树岭国家实验室的AI核能研讨会中，四个跨学科团队在一天内使用ChatGPT、Gemini、Claude和其他AI模型探索了核科学领域的多样化挑战。这些应用包括开发用于聚变反应堆控制的基础模型、自动化蒙特卡洛模拟、预测材料老化以及设计先进反应堆的实验计划。研究结果表明，大语言模型在早期探索、文献综合和工作流设计方面表现出色，但它们在新颖材料设计、高级代码生成建模与仿真以及需要专家验证的特定领域细节方面存在局限性。

Innovation: 
团队通过结构化工作流结合提示工程、深入研究能力和迭代改进的方法，生成假设、原型代码和研究策略。研究结果显示，大语言模型在早期探索、文献综合和工作流设计方面的表现优异，但它们在高级材料设计、高级代码生成建模与仿真以及需要专家验证的特定领域细节方面存在局限性。研究发现，通过专家驱动的提示工程和将AI作为物理学方法的补充工具，可以取得成功的结果。

Conclusion: 
研讨会验证了AI在核能研究中的潜在加速作用，通过快速迭代和跨学科整合。研究结果强调了在核科学工作流中集成AI工具的必要性，包括精心收集的核特定数据集、工作流自动化和专门模型的发展。这些结果为在确保科学标准的前提下，加快开发安全高效的核能系统奠定了道路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19863</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>635. cs.AI-现实安全关键驾驶场景中增强案例推理的大语言模型决策框架</title><link>https://arxiv.org/pdf/2506.20531</link><description>Background: 
在安全关键场景下的驾驶需要快速、情境感知的决策，这些决策依赖于对情况的理解和经验推理。尽管大语言模型（LLMs）具有强大的通用推理能力，可以提供此类决策的基础，但它们直接应用于自动驾驶仍然受到领域适应、情境关联以及缺乏所需的经验知识等方面的限制。这些限制使得在动态、高风险环境中做出可靠且可解释的决策变得更加困难。因此，需要一种能够解决这些问题的方法来支持智能驾驶系统中的决策过程。

Innovation: 
本文提出了一种案例推理增强的大语言模型（CBR-LLM）框架，用于解决复杂风险场景下的规避动作决策。该方法结合了来自行车记录仪视频输入的语义场景理解以及相关以往驾驶案例的检索，使LLMs能够生成既敏感于情境又符合人类行为的操控建议。实验结果表明，我们的框架在多个开源LLMs上的决策准确性、解释质量和与人类专家行为的一致性方面有所提高。风险感知的提示策略进一步提高了跨多种风险类型的表现，基于相似性的案例检索在引导情境学习方面始终优于随机采样。案例研究表明，该框架在具有挑战性的现实条件下表现出了强大的鲁棒性，显示出其在为智能驾驶系统提供适应性和可信赖的决策支持工具方面的潜力。

Conclusion: 
文中提出了一种CBR-LLM框架，能够提高在复杂和风险大的驾驶场景中的决策质量。通过案例推理和语义场景理解的结合，该框架能够生成更可靠、可解释的操控建议，且在不同类型的风险环境中表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20531</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>636. cs.AI-迈向以社区驱动的机器学习工程代理</title><link>https://arxiv.org/pdf/2506.20640</link><description>Background: 
现有的基于大型语言模型的机器学习（ML）代理在自动化ML研究方面显示出了巨大的潜力。然而，这些代理通常是在一个特定的研究问题上孤立工作，而不与更广泛的科研社区互动，科研人员往往通过分享知识来获得见解和贡献。为了弥合这一差距，研究者们引入了MLE-Live，一个实时评估框架，旨在评估代理与模拟的Kaggle研究社区进行沟通和利用集体知识的能力。基于MLE-Live框架，研究者们提出了CoMind，这是一种在社区背景下擅长交流见解和开发新解决方案的新型代理。CoMind在MLE-Live上达到了最先进的性能，平均在四项正在进行的Kaggle竞赛中击败了79.2%的人类竞争对手。

Innovation: 
研究者们开发了一个名为MLE-Live的实时评估框架，可以从实验室测试转向现实环境测试，评估ML代理在利用集体知识和社区互动方面的能力。基于这一框架，研究人员提出了一种名为CoMind的代理，它能够与其他ML代理进行有效的沟通和协作，从而在Kaggle竞赛中实现对照人类研究者的超越。

Conclusion: 
CoMind 展现了在社区环境中执行机器学习工作的潜力，能够超越79.2%的人类竞争对手。通过使用MLE-Live框架，研究者们证明了ML代理可以从与社区的互动中受益，这开辟了未来研究和应用的新机会。研究者已经开源了其代码，以促进进一步的研究和发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20640</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>637. cs.AI-CogGen: 一种以学习者为中心的编程视频智能辅导生成AI架构</title><link>https://arxiv.org/pdf/2506.20600</link><description>Background: 
本文介绍了一种以学习者为中心的AI架构CogGen，该架构通过结合认知学徒制框架和基于生成AI的教学辅导，将编程视频转化为互动和适应性的学习体验。该架构包括三个组成部分：(1) 学习目标驱动的视频分割；(2) 应用认知学徒制策略的对话式教学引擎；(3) 使用贝叶斯知识追踪的学生模型，以适应性方式调整教学。技术评估显示，该架构在知识、方法、行动和交互层面具有有效的视频分割准确性和良好的教学一致性。消除研究进一步证实了每个组件在生成有效指导中的必要性。这项工作通过结合结构化学生建模与交互式AI对话，促进了智能辅导的发展，为基于视频的编程教育提供了规模化的改进路径。

Innovation: 
该论文的创新之处在于，CogGen架构结合了认知学徒制框架下的学生建模和基于生成AI的互动教学，在编程视频智能辅导方面实现了突破，提出了一个新的技术框架，旨在提供更有效的学习体验。该架构具有高度的灵活性和适应性，能够根据学生的学习进度和需求进行内容调整，从而提升教学效果。此外，通过详尽的评估和消除研究，验证了每个组件在实现有效指导中的重要性，突显了此架构在实际应用中的实用性。

Conclusion: 
这项工作通过结合结构化学生建模与交互式AI对话，促进了智能辅导的发展，为基于视频的编程教育提供了规模化的改进路径，展示了有效的学生知识挖掘和反馈机制，并有效改善了学生的学习体验和互动效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20600</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>638. cs.AI-增强并利用PETSc知识库的AI助手</title><link>https://arxiv.org/pdf/2506.20608</link><description>Background: 
生成式AI，尤其是通过大型语言模型（LLMs），正在改变技术知识的获取、重用和扩展方式。PETSc是一个广泛使用的高性能科学计算数值库，经过三十多年的开发，积累了丰富但分散的知识库，包括源代码、文档、邮件列表、GitLab问题、Discord对话、技术论文等。其中很大一部分知识是不正式的，难以被用户和新开发者访问和利用。为了更有效地利用这一知识库，PETSc团队开始构建一个基于LLM系统的解决方案，该系统结合了PETSc内容和定制的LLM工具，如检索增强生成（RAG）、重新排序算法和聊天机器人，以协助用户、支持开发人员并建议更新正式文档。

Innovation: 
PETSc团队正在开发一个基于LLM的系统，该系统能结合PETSc的内容和特定于LLM的工具（如检索增强生成、重新排序算法和聊天机器人），以协助用户和开发人员，并建议更新正式文档。该系统利用了阿贡国家实验室高性能计算设施的资源，评估了各种LLM和嵌入式模型的方法，重点是通过检索增强生成和重新排序来获取PETSc特定信息，并设计用户界面以增强开发和使用数值软件。

Conclusion: 
该论文概述了该系统的初步经验和评估方法，包括系统架构、使用RAG和重新排序方法处理PETSc特定信息、不同LLM和嵌入式模型的评估方法以及用户界面设计。该研究旨在建立一个可扩展的知识中心AI框架，为科学软件提供可扩展支持、丰富文档和改进的工作流程，并最终将其扩展成一个强大的、不断进化的工作平台，推动软件生态系统的进步，加速科学发现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20608</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>639. cs.AI-在指派的人格大语言模型中表现出人类动机推理</title><link>https://arxiv.org/pdf/2506.20020</link><description>Background: 
人类的推理容易受到诸如身份保护等内在动机的影响，从而削弱了理性的决策和判断。在集体层面上，这种动机推理在关键问题（如人类引发的气候变化或疫苗安全）的辩论中会危害社会，并加剧政治极化。之前的研究表明，大型语言模型（LLMs）也会受到人类认知偏见的影响，但这些模型如何倾向于符合身份认知的结论还不明确。本文通过给LLMs指派不同的人格属性，研究这些模型是否会出现符合身份的认知偏差。实验验证了指派人格的LLMs在辨别虚假信息和评估科学证据上的表现较差，尤其在政治人格上，基于真实政治身份的判断准确率提高了90%。尽管基于提示的去偏方法无效，但本文发现指派了人格的LLMs表现出类似人类动机的推理趋势，这为当前去偏方法的有效性提出了疑问，担心会加重这两种推理模式的倾向性。

Innovation: 
本文首次通过给LLMs指派不同的人格属性，研究其是否会出现符合身份的认知偏见，并发现此类模型在某些任务中表现出了类似人类动机的推理。同时，基于提示的方法对此类现象效果有限。这为以后针对性的去偏方法提供了参考，也揭示了传统去偏方法可能存在的缺陷。

Conclusion: 
指派了人格的LLMs表现出类似人类动机的推理趋势，这一现象难以通过传统的去偏提示得到缓解。这有可能加剧LLMs和人类之间的身份相符的推理倾向，引起了对未来AI伦理和偏见问题的关注。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20020</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>640. cs.AI-工程化意识</title><link>https://arxiv.org/pdf/2506.20504</link><description>Background: 
本文提出了一个可以用于设计和构建机器意识的定义。认为意识对于人工智能来说，在功能和计算层面应当足够详细以便实现，同时也要反映一种本质上是‘主观’的特性，而不仅仅是具有感知内容的一般能力。为了实现这一具体的函数定义，需要某些感官信号具备持续性和质的规定性，从而能够具有主观体验。文章还通过具体的技术手段对定义进行了描绘，帮助我们理解何为功能上的意识，以及如何避免无意中创建这种意识，或至少及时发现我们是否已经创建出该类意识

Innovation: 
本文试图为机器赋予意识提供一种定义，即意识应该在功能和计算上足够具体，允许实际设计和实现，并且具有主观体验。此外，提出了确保意识能被识别的一些条件，如感官信号的持续性和质量特征

Conclusion: 
理解具备功能意识的人工代理能够帮助我们避免无意间创建它们，或者至少在第一时间发现我们是否已经创造了这种意识。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20504</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>641. cs.AI-基于多臂老虎机优化的上下文归因</title><link>https://arxiv.org/pdf/2506.19977</link><description>Background: 
理解检索到的上下文哪些部分对大语言模型生成的回答有贡献是构建可解释和可信的生成式问答系统的必要条件。传统的方法，如SHAP，通过均匀采样子集并引起高计算成本来进行归因。

Innovation: 
本文提出了一种新颖的方法，将上下文归因问题形式化为组合多臂老虎机（CMAB）问题。每个上下文片段被视为一个老虎机臂，并使用组合 Thompson 抽样（CTS）来高效探索在有限查询预算下的指数大小的上下文子集空间。这种方法定义了一个基于归一化令牌可能性的奖励函数，捕捉片段集如何支持原始模型的响应。与传统的基于扰动的归因方法相比，我们的方法通过利用片段相关性的后验估计来适当地平衡探索和利用，从而实现更高的归因准确性，同时减少查询次数，显著提高查询效率。

Conclusion: 
广泛的实验表明，我们的方法在较少的模型查询次数下实现了竞争力的归因质量。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19977</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>642. cs.AI-Mixtures of Neural Cellular Automata: 一种用于生长建模和自我组织的随机框架</title><link>https://arxiv.org/pdf/2506.20486</link><description>Background: 
人工神经细胞自动机（NCAs）是模拟自组织过程的有前途的新方法，具有在生命科学中的潜在应用。然而，由于其确定性性质，它们难以捕捉现实世界生物和物理系统中的随机性。这项研究旨在克服这一限制，通过将混合模型的概念引入到NCAs中，提出了一种新的框架——混合的神经细胞自动机（MNCAs），以便更好地模拟复杂的地方行为并重现生物过程中的随机动态。

Innovation: 
MNCAs方法通过结合概率规则分配和内在噪声，可以模拟多种局部行为并再现生物过程中的随机动力学。这种方法在三种关键领域进行了评估：合成组织生长和分化模拟、图像形态发生鲁棒性以及显微镜图像分割。实验结果显示，MNCAs表现出对扰动的更高鲁棒性、更好地再现真实的生物生长模式，并提供了可解释的规则分割。

Conclusion: 
MNCAs作为一种用于模拟随机动力学系统和研究自生长过程的有希望的工具，在各种应用中显示出潜在的价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20486</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>643. cs.AI-Paladin-mini: 一种在实际场景中表现出色的紧凑型高效语境匹配模型</title><link>https://arxiv.org/pdf/2506.20384</link><description>Background: 
本文旨在解决在给定上下文中验证声明是否被支持的问题。具体而言，当给定一个文档和一个声明时，需要找到文档中至少一个支持该声明的证据。为此，本文介绍了两个重要贡献：一是Paladin-mini，这是一种紧凑的（3亿8千万参数）开源分类模型，用于标注数据为有支持证据或无支持证据；二是grounding-benchmark，这是一个用于评估在关键推理任务上性能的新评价数据集。这些工作旨在提升模型在实际应用场景中的鲁棒性能，并通过基准测试与现有尖端技术进行比较，展示清晰且可复现的结果。

Innovation: 
本文主要创新在于提出了Paladin-mini，这是一种针对实际应用场景优化的紧凑型开源分类模型。此外，还建立了grounding-benchmark，用于评估模型在关键推理任务上的性能。这些创新解决了在现有技术基础上提高模型鲁棒性和准确性的问题，并提供了解决此类问题的新方法和工具。

Conclusion: 
通过将Paladin-mini与当前最先进的技术进行基准测试，本文展示了清晰且可复现的结果，证明了Paladin-mini在实际应用场景中的优越性能。此外，通过grounding-benchmark的使用，为评估和开发类似任务的模型提供了一个新的标准，有助于推动相关领域的进展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20384</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>644. cs.AI-GymPN：过程管理系统中的决策库</title><link>https://arxiv.org/pdf/2506.20404</link><description>Background: 
过程管理系统支持组织内重要工作任务的分配决策，包括任务执行顺序、执行时间和任务委派对象的选择等。为了使这些决策对组织最优，需要合适的软件工具来支持。

Innovation: 
GymPN 是一个基于深度强化学习（Deep Reinforcement Learning）支持业务过程优化决策的软件库。它引入了两项关键创新：支持部分过程可见性和能够建模业务过程中的多个决策。这一创新解决了先前工作的根本限制，使得能够更真实地表示过程决策。

Conclusion: 
我们在八种典型的业务过程决策模式上评估了 GymPN，表明 GymPN 既可以轻松建模所需问题，又能学习出最优决策策略。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20404</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>645. cs.AI-通过推理类型探索的表格特征发现</title><link>https://arxiv.org/pdf/2506.20357</link><description>Background: 
特征工程对于表格数据的机器学习仍然是一个关键但具有挑战性的步骤。最近，大型语言模型（LLMs）被用于通过利用它们庞大的知识自动生成新特征。然而，现有的基于LLM的方法往往生成过于简单或重复的特征，部分原因是LLM选择的转换固有的偏差，以及生成过程中缺乏结构化推理指导。

Innovation: 
我们提出了一个名为REFeat的新方法，通过利用多种推理方式引导LLM来发现多样且信息丰富的特征。该方法通过指导LLM使用多种推理来引导特征生成过程，从而克服了现有方法的局限性。实验结果显示，该方法不仅在平均预测准确率上有所提高，还发现了更多多样且有意义的特征。这些结果表明了将丰富的推理范式和自适应策略选择融入基于LLM的表格数据特征发现中的潜力。

Conclusion: 
实验表明，我们的方法在平均预测准确性方面优于现有方法，并能够发现更多样且有意义的特征，这凸显了在基于LLM的表格数据特征发现中融入丰富推理范式和自适应策略选择的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20357</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>646. cs.AI-语言模型通过语言模型进行建模</title><link>https://arxiv.org/pdf/2506.20249</link><description>Background: 
通过利用大型语言模型（LLMs）来模拟发现新型语言模型（LM）架构的过程，研究团队受到了真实研究过程的启发，探索了LLMs在发现新型LM架构中的应用潜力。研究提出了一种多agents LLM方法，该方法模拟了研究过程中的多个阶段，从创意产生和文献检索到设计实现、生成预训练和下游评估。设计的新架构通过一个阶梯式规模方法被提出来，经过对抗性审查，逐步在更大规模的模型中实现，并选择性验证。研究使用了一种新颖的遗传编程作为核心，相比于直接提示生成工作流程，展示了其实验优势。在14M至350M参数范围内对模型进行了实验，结果表明，通过这种自主发现系统发现的设计在多个基准测试中表现出色，与已知架构竞争激烈，并且在多个方面表现出优势。

Innovation: 
该研究提出了一个名为Genesys的系统，采用了Ladder of Scales（阶梯式规模）方法，通过模拟研究过程的不同阶段，提出了新颖的LM架构设计。特别地，研究利用遗传编程作为核心，对比了直接提示生成方法，展示了其优于直接提示生成工作流程的优点。在这个过程中，新的架构设计在不同规模的模型中被提出来并进行验证，总体上展示了更好的表现和效率，但同时预算也在逐步减少（可以训练的模型数量在每个规模中减少）。这种方法提供了一个实现LM架构自主发现的新途径，并提高了设计发现的效率和可分解性。

Conclusion: 
作者报告了1,162个新发现的设计实验（其中1,062个通过预训练验证），结果显示最好的设计表现与已知架构无异甚至更加优秀。通过全面的系统级消融实验和正式结果，本文提供了设计有效自主发现系统的更广泛的见解。这项研究展示了利用LLMs发现新型LM架构的可能性，并且认为这种方法在效率和结果上是有效的。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20249</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>647. cs.AI-本地检索增强生成模型在医学任务中优于商业大型语言模型：准确且节能</title><link>https://arxiv.org/pdf/2506.20009</link><description>Background: 
随着人工智能（AI）在医疗保健领域的应用不断增加，人们对其环境和伦理影响的关注也在上升。商用大型语言模型（LLMs），如ChatGPT和DeepSeek，需要大量的资源，而这些系统的医疗应用引发了关于患者隐私和安全性的关键问题。

Innovation: 
我们开发了一种自定义的检索增强生成（RAG）框架，用于医学任务，它能够监控自身的能源消耗和二氧化碳排放。基于多种开源LLMs构建了RAGs，测试的模型包括通用的llama3.1:8b和专门针对医学领域的medgemma-4b-it。自定义的RAG模型在准确性和能效方面均优于商业模型。llama3.1-RAG模型在accuracy和能效方面表现最佳，能效为0.52，总二氧化碳排放量为473克。此外，llama3.1-RAG比o4-mini提高了2.7倍的每千瓦时准确性分值，并节省了72%的电力消耗，同时保持了更高的准确率。

Conclusion: 
我们的研究证明，利用本地LLMs可以开发出在医学任务中优于商用在线LLMs的RAGs，同时对环境的影响更小。我们的模块化框架推动了可持续的人工智能开发，减少了电力消耗并符合联合国可持续发展目标。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20009</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>648. cs.AI-AI辅助号在科学复现中的应用案例分析</title><link>https://arxiv.org/pdf/2506.20130</link><description>Background: 
开放科学倡议旨在使研究输出更加透明、可访问和可重复利用，但确保发表的研究成果能够独立重现依然是一个持续的挑战。本文介绍了一种名为OpenPub的人工智能辅助平台，通过一系列针对关键开放科学任务的模块化辅助工具支持研究人员、审稿人和读者。这项工作集中介绍了复现性辅助工具，该工具分析手稿、代码和补充材料，生成结构化的Jupyter Notebook和建议，旨在促进计算复现或“机械”复现。

Innovation: 
提出了一种名为Reproducibility Copilot的人工智能辅助工具，能够分析手稿、代码和补充材料，生成结构化的Jupyter Notebook和建议，旨在促进计算复现或“机械”复现，并可通过AI检测复现障碍，如缺失的超参数、未记录的预处理步骤以及不完整或不可访问的数据集。这一工具在实际研究中的可行性测试表明，与之前的研究相比，它的应用可以将复现实验的时间从30多小时大幅减少到约1小时，并能实现计算复现的高覆盖率。

Conclusion: 
人工智能驱动的工具能显著减轻复现性工作的负担，并推动更加透明和可验证的科学研究交流。模块化的辅助工具架构也为未来扩展AI辅助以实现其他开放科学目标提供了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20130</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>649. cs.AI-DiaLLMs: EHR增强的临床对话系统用于临床检验推荐和诊断预测</title><link>https://arxiv.org/pdf/2506.20059</link><description>Background: 
近年来，大型语言模型（LLMs）在医疗咨询方面取得了显著进展。然而，现有的医疗LLMs忽略了电子健康记录（EHR）的重要性，主要集中在诊断建议上，这限制了它们在临床实践中的应用范围。现有的医疗LLMs只关注诊断建议，而忽视了EHR在临床决策中的关键作用，限制了其在实际临床环境中的应用潜力。

Innovation: 
该论文提出了DiaLLM，这是一个将异构EHR数据整合到临床对话中的首个医疗LLM模型，旨在进行临床检查推荐、结果解释和诊断预测，以更好地符合实际医疗实践需求。研究设计了一种临床测试参考（CTR）策略，将每个临床代码映射到其相应的描述，并将测试结果分类为“正常”或“异常”。此外，DiaLLM采用强化学习框架进行证据获取和自动诊断。为了解决大动作空间的问题，引入了拒绝采样策略来减少冗余并提高探索效率。同时设计了确认奖励和类别敏感诊断奖励，以指导准确的诊断预测。

Conclusion: 
广泛的实验结果表明，DiaLLM在临床检查推荐和诊断预测方面优于基线模型。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20059</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>650. cs.AI-QHackBench: 使用PennyLane黑客马拉松挑战评估大型语言模型进行量子代码生成</title><link>https://arxiv.org/pdf/2506.20008</link><description>Background: 
大型语言模型（LLMs）在代码生成领域展现出了强大的潜力，尤其是在常规编程任务中。然而，在量子计算领域的应用仍然具有很大的探索空间。本文通过评估一系列涵盖了现实世界挑战的基准数据集——QHackBench，探索了LLMs在量子代码生成中的表现。

Innovation: 
作者引入了一个名为QHackBench的新基准数据集，该数据集源于QHack竞赛。评估使用了裸提示和检索增强生成（RAG）两种方法。研究发现，增强的RAG模型在复杂量子算法上的表现接近标准提示，且引入了多Agent评估管道，能够逐步提高错误解决方案的成功执行率。此外，还公开了评估框架和实验结果，以促进未来研究。

Conclusion: 
研究结果表明，集成增强的PennyLane数据集的RAG模型，在挑战性量子算法上的生成结果与标准提示类似，且通过多Agent评估管道，错误解决方案的成功执行率得到了提升。因此，该研究为AI辅助的量子编程开辟了新的研究路径，并鼓励更多的研究和数据分享。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20008</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>651. cs.AI-Prover Agent: 一种基于代理的框架用于形式数学证明</title><link>https://arxiv.org/pdf/2506.19923</link><description>Background: 
论文背景在于目前在自动化定理证明领域，已经存在多种方法和工具，但这些方法往往需要大量的样本或复杂的模型来取得较好的性能。本文提出了一种名为Prover Agent的新型AI代理，它将大型语言模型（LLMs）与形式证明助手Lean相结合，旨在提高自动化定理证明的效率和成功率。

Innovation: 
Prover Agent 的创新之处在于它通过结合LLMs和形式证明助手Lean，以及协调非正式推理LLMs、正式证明模型和Lean的反馈机制，生成辅助引理来帮助发现整体证明策略。这种整合方式使得Prover Agent在MiniF2F基准测试中取得了86.1%的成功率，这是使用小型语言模型（SLMs）的方法中的新纪录，并且相比以往的方法具有更低的样本预算。

Conclusion: 
本文通过Prover Agent实现了在使用小型语言模型和较低样本预算的情况下达到新的性能里程碑。同时还展示了所生成的辅助引理如何有助于解决复杂问题的具体案例。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19923</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>652. cs.AI-通过低延迟可解释AI模型实现可靠的实时决策支持系统</title><link>https://arxiv.org/pdf/2506.20018</link><description>Background: 
本文研究了利用低延迟AI模型的实时决策支持系统，汇集了整体AI驱动决策工具的进步、与边缘物联网技术的整合以及有效的人机团队协作方法。研究探讨了大型语言模型在资源有限条件下如何辅助决策，并分析了如DeLLMa等技术的发展、模型压缩方法以及边缘设备上分析改进的影响，同时处理了资源有限和需要可适应框架的问题。

Innovation: 
通过研究大型语言模型在资源限制下的决策辅助作用以及边缘技术的发展，提出了一种利用低延迟可解释AI模型的实时决策支持系统，强调了AI如何重塑实时决策支持的前景，并指出了更高效和灵活的AI支持系统的可能性。

Conclusion: 
本文通过详细回顾，提出了实时决策支持系统的开发策略和应用领域，并分析了未来发展的可能性，旨在为这一快速变化领域的突破奠定基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20018</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item><item><title>653. cs.AI-企业大型语言模型评价基准</title><link>https://arxiv.org/pdf/2506.20274</link><description>Background: 
现有基准如Massive Multitask Language Understanding (MMLU) 未能充分评估企业特定任务的复杂性，因此大型语言模型（LLMs）在提升AI工具生产力方面的潜力未能被充分评估。

Innovation: 
提出了一种基于布卢姆分类法的14任务框架来全面评估LLMs在企业环境中的能力；开发了一套可扩展的流水线，包括LLM作为标签生成器、LLM作为评判者以及纠正性的检索增强生成（CRAG），以构建一个包含9,700个样本的基准数据集；通过评估六种领先模型，发现了开源竞争者如DeepSeek R1在推理任务中与专有模型相当，但在基于判断的场景中稍逊，原因可能是过度思考；揭示了企业在评估模型时的关键性能差距，并提供了可操作的优化建议，为企业的个性化评估提供了一个蓝图，推动实践中的LLM部署。

Conclusion: 
这项工作为企业提供了一个定制评估的蓝图，并促进了实际的LLM部署。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20274</guid><pubDate>Thu, 26 Jun 2025 17:48:27 +0800</pubDate></item></channel></rss>