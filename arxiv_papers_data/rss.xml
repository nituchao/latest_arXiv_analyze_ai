<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Arxiv Papers Analyze AI</title><link>https://github.com/nituchao/latest_arxiv_analyze_ai</link><description>Arxiv papers analyzed by AI on 20250624</description><lastBuildDate>Tue, 24 Jun 2025 15:06:14 +0800</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>1. cs.AI-段一切为卫片影像：区域数据集及自动农田边界划定的坚实基线</title><link>https://arxiv.org/pdf/2506.16318</link><description>Background: 
准确的农田边界测绘对于农业高效运营至关重要。通过计算机视觉技术并结合高分辨率卫星影像的自动提取方法，可以避免昂贵的地面调查。本文基于段一切换模型(SAM)提出了一种农田边界划分流程，并采用微调策略来适应此任务，同时介绍了一种获取覆盖现有数据源之外区域的补充区域性数据集的方法。广泛的实验评估了分割准确性并测试了泛化能力。

Innovation: 
提出了基于段一切换模型(SAM)的农田边界划分流程，包括一种适应策略；开发了一种补充区域性数据集ERAS，涵盖了现有的数据源之外的区域；评估了分割准确性和泛化能力，提供了自动农田边界划分的坚实基线。

Conclusion: 
本文提出了一个基于段一切换模型的农田边界划分流程，并采用了一种新的区域性数据集ERAS，这一方法为自动农田边界划分提供了一个稳健的基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16318</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>2. cs.AI-VRAIL: Vectorized Reward-based Attribution for Interpretable Learning</title><link>https://arxiv.org/pdf/2506.16014</link><description>Background: 
本文探讨了一种基于价值的强化学习方法，特别关注于从状态特征中学习具有解释性的权重表示。VRAIL框架包括两阶段的过程：首先是深度学习阶段，使用状态特征拟合估计的价值函数；其次，利用这个价值函数通过潜力基奖励变换来指导学习。通过线性或二次形式建模估计器，允许对个体特征及其相互作用的重要性进行归因。实验结果表明，与标准DQN算法相比，VRAIL提高了训练稳定性和收敛性，且无需对环境进行任何修改。进一步的分析还揭示了VRAIL可以发现具有语义意义的次要目标，如乘客持有的目标，这突显了VRAIL产生可解释行为的能力。

Innovation: 
VRAIL是一种创新的框架，适用于价值导向的强化学习，能够从状态特征中学习具有解释性的权重表示，通过线性或二次形式的估计器建模，实现对个体特征及其相互作用重要性的归因。VRAIL通过深度学习阶段拟合价值函数，并通过潜在奖励变换引导学习过程。实验结果表明该方法在不改变环境的前提下，提高了训练稳定性和收敛性，且揭示了具有语义意义的次要目标，有助于生成有意义的且可解释的行为。

Conclusion: 
VRAIL提供了一种通用的、无模型偏好的奖励塑形框架，能够增强学习效果和解释性。通过这两阶段的过程，VRAIL展示了其在保持学习效率的同时，生成符合人类理解的可解释行为的能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16014</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>3. cs.AI-LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs</title><link>https://arxiv.org/pdf/2506.15690</link><description>Background: 
使用公共互联网合成数据提高了大规模语言模型（LLM）训练的数据使用效率，但模型崩溃的潜在威胁尚未充分探讨。现有研究主要关注单一模型中的模型崩溃问题，或者仅依赖统计代理。

Innovation: 
引入LLM Web Dynamics（LWD）框架，在网络层面研究模型崩溃。通过使用检索增强生成（RAG）数据库模拟互联网，分析模型输出的收敛模式，并通过与交互式高斯混合模型类比提供理论保证.

Conclusion: 
LWD框架通过模拟互联网并分析模型输出的收敛模式，为在大规模语言模型网络中研究模型崩溃提供了新的方法，并通过理论保证支持这种收敛性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15690</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>4. cs.AI-采用深度学习实现精确且可扩展的交换相关性</title><link>https://arxiv.org/pdf/2506.14665</link><description>Background: 
密度泛函理论（DFT）是最常用的预测分子和材料性质的电子结构方法。尽管DFT理论上是对薛定谔方程的一种精确重新表述，但在实际应用中依赖于对未知交换关联（XC）泛函的近似。目前大多数存在的XC泛函是通过一系列复杂的手工设计特征构建的，这些特征能提升准确度但会牺牲计算效率。然而，任何当前的近似都未能在化学精度（通常定义为误差低于1 kcal/mol）下实现预测实验室实验的能力。本文旨在通过一种基于深度学习的现代XC泛函方法---Skala来解决这一问题。Skala能够直接从数据中学习表示，从而绕过了昂贵的手工设计特征，实现了对于小分子的原子化能量的化学准确度，同时保留了类局域DFT的计算效率。训练数据包括以前所未有的大量具备高准确性的参考数据，这些数据是通过计算密集型的波函数方法生成的。

Innovation: 
Skala通过深度学习方法直接从数据中学习交换关联泛函（XC），从而简化了传统手工设计特征的方法，实现了对于小分子的原子化能量的化学准确度。通过使用大量的高质量参考数据——这些数据通过计算密集型的波函数方法生成，Skala不仅在计算效率上能够媲美类局域DFT，还能在化学准确度上取得突破，而且能够随着更多数据的训练而系统地改进。

Conclusion: 
Skala利用深度学习技术创造性地解决了现有的XC泛函与DFT方法在精度和效率间的权衡。这种泛函既可以在数据量继续扩大时增强第一原理模拟的预测能力，又能在覆盖更广泛的化学领域时与最佳混合泛函竞争，证明了在保持计算效率的同时实现化学准确度的可行性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14665</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>5. cs.AI-Working Document -- 使用大型语言模型形式化软件需求</title><link>https://arxiv.org/pdf/2506.14627</link><description>Background: 
该论文概述了94篇相关论文，并增加了关于软件需求跟踪、形式化方法及其工具、编程统一理论（UTP）和机构理论的相关部分。相比之前的类似作品AACS 2025 [7] 和 SAIV 2025 [8]，本文提供了一个更详细的总结，并对先前版本进行了改进，增加了背景文献和总结表，同时经过了更严格的评审过程。

Innovation: 
本文通过使用大型语言模型形式化软件需求，增加了对软件需求跟踪、形式化方法及工具、以及编程统一理论（UTP）和机构理论的介绍，从而详细总结了相关领域的最新研究进展。相比之前的版本，本文经过了更为严谨的评审，并对先前的提交建议进行了改进和调整，提升了论文质量。

Conclusion: 
本文为软件需求形式化领域的研究提供了一个全面的概述。相比于AACS 2025[7]和SAIV 2025[8]，本文不仅增补了多个理论领域的参考资料，还经过了更为严密的审查，并基于审稿人的反馈进行了改进，为后续研究提供了参考。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14627</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>6. cs.AI-AlphaDecay：LLMs中基于模块的重尾平衡的权重衰减</title><link>https://arxiv.org/pdf/2506.14562</link><description>Background: 
权重衰减是一种常见的训练大规模语言模型（LLMs）的正则化技术。然而，通常为每层分配统一的衰减率忽略了LLMs的结构多样性和不同模块的光谱特性差异。

Innovation: 
提出了一种简单而有效的方法——AlphaDecay，该方法根据重尾自正则化（HT-SR）理论，为LLM的每个模块适配性地分配不同的权重衰减强度。AlphaDecay通过对比模块的光谱特性差异来平衡模块之间的性能差异，从而提升模型性能。

Conclusion: 
通过对从60M到1B不等规模的预训练任务进行广泛实验，AlphaDecay在困惑度和泛化能力方面优于传统的均匀权重衰减和其他自适应权重衰减基线。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14562</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>7. cs.AI-Bures-Wasserstein Flow Matching for Graph Generation</title><link>https://arxiv.org/pdf/2506.14020</link><description>Background: 
图生成已成为从分子设计到药物发现等多个领域的重要任务。现代方法，尤其是在扩散和流模型方面，通过在参考分布和数据分布之间构建概率路径来取得坚实的图生成性能。然而，这些方法通常独立建模节点和边的演变，并假设数据位于欧几里得空间中，这通常是线性的插值。研究表明，这种线性假设在依赖非欧几里得结构和相互关联图模式的情况下不够优化，这可能导致采样收敛风险。

Innovation: 
该研究通过将图表示为由马尔科夫随机场（MRF）参数化的连接系统来建模节点和边的联合演变。采用MRF对象之间的最优传输位移来设计图生成的概率路径，从而构建更加合适的流匹配框架——BWFlow。BWFlow框架适用于连续和离散流匹配算法，提供符合图几何学的概率路径中的平滑速度。

Conclusion: 
实验结果在单纯的图生成和2D/3D分子生成中验证了BWFlow在图生成的有效性，其性能、稳定的训练效果和确保采样收敛都表现出竞争力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14020</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>8. cs.AI-分布性训练数据归因</title><link>https://arxiv.org/pdf/2506.12965</link><description>Background: 
传统训练数据归因算法忽视了由于初始值和批处理中的随机性，使用相同的训练数据集可能会训练出不同的模型这一事实，导致这些算法在处理时未能严谨地将随机性因素考虑进去。因此，引入分布性训练数据归因（d-TDA），旨在预测模型输出分布（经过多次训练运行）如何依赖于数据集。

Innovation: 
通过引入分布性训练数据归因（d-TDA），论文提供了一种预测模型输出分布依赖于数据集的方法。特别地，研究发现影响函数（IFs）作为分布框架的自然极限，可以在没有严格凸性假设的情况下自然地从分布性框架中涌现出来，为IFs在深度学习中的有效性和局限性提供新的数学动机。

Conclusion: 
研究表明分布性训练数据归因具有实际应用价值，能够识别对某些目标测量分布有显著影响但未必改变平均值的训练样本。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12965</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>9. cs.AI-AFBS: Buffer Gradient Selection in Semi-asynchronous Federated Learning</title><link>https://arxiv.org/pdf/2506.12754</link><description>Background: 
异步联邦学习(AFL)通过消除等待慢节点的需要来加速训练，但其异步特性引入了梯度陈旧的问题，即过时的梯度会降低性能。现有的解决方案通过梯度缓存形成了一个半异步框架，但这种方法在缓存累积大量过时的梯度时会遇到困难，因为盲目地聚合所有梯度可能会损害训练。

Innovation: 
提出了AFBS（异步分缓冲选择），这是第一个在缓存中执行梯度选择并同时确保隐私保护的算法。客户端在训练前发送随机投影加密标签分布矩阵，服务器基于其进行客户端聚类。在训练中，服务器根据信息价值对每个聚类中的梯度进行打分并选择，丢弃低价值梯度以增强半异步联邦学习。

Conclusion: 
广泛的实验在高度异质的系统和数据环境中证明了AFBS在性能上优于最新方法。特别地，CIFAR-100上，AFBS相较于之前最佳算法准确度提高了4.8%，并将达到目标准确度所需时间缩短了75%。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12754</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>10. cs.AI-Robust LLM Unlearning with MUDMAN: Meta-Unlearning with Disruption Masking And Normalization</title><link>https://arxiv.org/pdf/2506.12484</link><description>Background: 
语言模型即使经过大量安全调优，也可能保留潜在危险的知识和技能，这带来了滥用和不对齐的风险。虽然专门的遗忘方法可以被逆转，但现有研究发现这些方法仍然不够稳健。因此，需要系统评估并识别出能够实现不可逆遗忘的关键组件。

Innovation: 
本文引入了Disruption Masking技术，确保更新权重时，遗忘梯度和保留梯度的符号相同，使得所有更新均为非破坏性。同时，确认了梯度归一化和元学习的效用，并将这些洞察整合成MUDMAN（元遗忘与破坏性掩蔽及归一化相结合的方法）。MUDMAN显著优于先前的TAR方法，设定新的稳健遗忘状态标准。

Conclusion: 
MUDMAN在防止危险能力恢复方面表现出色，比先前的最佳方法TAR提升了40%，设定新的最佳标准。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12484</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>11. cs.AI-探索大型语言模型的次要风险</title><link>https://arxiv.org/pdf/2506.12382</link><description>Background: 
随着大型语言模型（LLM）在关键应用和社会功能中的逐步集成，确保其安全性和一致性成为一个重要挑战。尽管先前的研究主要关注于 Jailbreak 攻击，但非对抗性失败在良性互动中悄然出现却未得到足够关注。这些非对抗性风险表现为在良性提示中出现有害或误导性行为，不同于对抗性攻击，这种风险源自不完美的泛化，常会躲避标准的安全机制。为了实现系统的评估，该研究引入了两种风险基本要素：冗长的响应和推测性的建议，以捕捉核心的失败模式。在此基础上，提出了 SecLens，这是一种黑箱、多目标搜索框架，通过优化任务相关性、风险激活和语言的合理性来高效地激发次要风险行为。

Innovation: 
该研究引入了两种新的风险基本要素，分别是冗长的响应和推测性的建议，以捕捉大型语言模型次要风险的核心模式。进一步地，提出了 SecLens，一种黑箱、多目标搜索框架，能够有效地揭示这些风险行为。此外，还发布了 SecRiskBench，一个包含650个提示的基准数据集，覆盖八个不同的现实世界风险类别。实验结果表明，次要风险是普遍存在的，能够在不同模型间转移，并且不受模态限制，这强调了增强安全机制的迫切需要来应对良性但有害的语言模型行为

Conclusion: 
实验结果表明，次要风险在不同模型中普遍存在且不受模态限制，必须加强对良性却潜在有害的 LLM 行为的管理，以提高实际部署的安全性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12382</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>12. cs.AI- Supernova Event Dataset: 通过关键事件分析解读大型语言模型的性格 </title><link>https://arxiv.org/pdf/2506.12189</link><description>Background: 
随着大型语言模型（LLMs）在日常生活中的应用日益增多，理解它们的决策过程和个性特征变得尤为重要。本文利用我们提出的 Supernova Event Dataset，该数据集包含多元化的文章，涵盖传记、历史事件、新闻和科学发现，旨在评估 LLMs 在从文本中提取和排序关键事件方面的表现，这是一项要求多步推理和建模因果链的主观复杂挑战。

Innovation: 
本文创新性地提出 Supernova Event Dataset，用于评估 LLMs 在提取和排序文本中的关键事件的能力。通过让另一款 LLM 作为评判者，基于模型对事件的选择和分类推断每个模型的个性。研究表明，不同模型展示出不同的个性特征：例如，Orca 2 强调情绪推理，聚焦于人际动态；而 Qwen 2.5 则表现出更为策略和分析的风格。此外，不同类型的事件（如科学发现）也被细分为多个类别，进一步揭示模型的不同特质。这项工作提高了模型的可解释性，使它们更加用户友好，适用于各种多样的应用环境。

Conclusion: 
通过 Supernova Event Dataset，本文展示了多种 LLMs 在处理不同类别的事件方面的不同个性特征。这种分析方法不仅改进了模型的可解释性，而且为广泛的应用提供了更高的用户友好性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12189</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>13. cs.AI-Agent-RLVR：通过引导与环境奖励训练软件工程代理</title><link>https://arxiv.org/pdf/2506.11425</link><description>Background: 
RLVR（可验证奖励的强化学习）已被广泛用于提升大语言模型的推理能力，并在数学和编程竞赛任务等可验证领域取得了显著成果。然而，当应用于需要多步骤、复杂问题解决的代理环境中时，RLVR的有效性会显著下降，因为这些环境中可用的奖励过少，难以通过传统的RLVR方法进行有效的模型训练。

Innovation: 
本文引入了Agent-RLVR框架，该框架能够在复杂的代理环境中使RLVR发挥作用，特别关注于软件工程任务。Agent-RLVR框架借鉴了人类教学的原则，通过引入代理引导机制来积极引导代理向成功路径迈进。通过利用从战略规划到动态反馈的各种信息线索，Agent-RLVR框架能够让代理导航复杂的解决方案空间并促进主动自我改进，进一步通过额外的环境探索。在Agent-RLVR的训练循环中，代理首先尝试解决任务以生成初始轨迹，这些轨迹随后通过单元测试进行验证，并补充以代理引导。通过这些引导过的轨迹来更新代理政策，并基于奖励进行RLVR训练。

Conclusion: 
在Agent-RLVR的支撑下，Qwen-2.5-72B-Instruct在SWE-Bench Verified上的pass@1性能从9.4%提升到了22.4%。我们的引导增强的RLVR数据也适合用于测试时的奖励模型训练，进一步将pass@1提升到了27.8%。Agent-RLVR为在传统RL方法难以应对的复杂现实环境中训练代理奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.11425</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>14. cs.AI-C-SEO Bench: Does Conversational SEO Work？</title><link>https://arxiv.org/pdf/2506.11097</link><description>Background: 
大型语言模型（LLMs）正将搜索引擎转变为对话型搜索引擎（CSE），这使得搜索引擎优化（SEO）转向成为对话型搜索引擎优化（C-SEO）。目前已有方法优化网页文档，以提高其在CSE响应中的可见性，但这些方法在多个领域中的有效性尚未完全被理解。此外，现有评估主要是在单个玩家场景中进行的，即只有一个网页文档采用了C-SEO方法，而现实中多个玩家可能会竞争性地采用最新的C-SEO技术，类似于我们在SEO中看到的现象。

Innovation: 
本文提出C-SEO Bench，这是首个旨在评估C-SEO方法的应用范围、实验问题数量和参与者数量的基准测试工具。通过两个搜索任务（问答和产品推荐）和三个领域来正式化新的评估协议，包括不同参与者采用率的变动，结果显示当前大多数C-SEO方法的效果并不如预期，传统以提高LLM环境下的来源排名的SEO策略更有效。随着C-SEO采用者的增多，整体收益逐渐减少，表明这是一个拥挤的零和问题。

Conclusion: 
我们的实验结果显示，大多数C-SEO方法并不如文献中报道的那样有效，传统的SEO策略（旨在提高LLM环境下的来源排名）更有效。随着C-SEO采用者的增加，总会收益逐渐减少，表现出拥挤和零和的特性。已经提供的代码和数据可在相应链接找到。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.11097</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>15. cs.AI-xInv: 可解释的逆问题优化</title><link>https://arxiv.org/pdf/2506.11056</link><description>Background: 
逆问题在多个领域中至关重要，包括医疗保健、气候科学和农业。这些问题涉及通过迭代优化已知的前向模型来估算输入，以便能够达到期望的结果。尽管前向模型的可解释性和可理解性方面已经有了显著的发展，但逆问题的迭代优化对领域专家而言仍然相当神秘。本文旨在提出一种方法，通过对优化器产生的痕迹进行解释，生成可由人类在领域抽象层理解的解释。

Innovation: 
本文提出的方法在于将可微模拟器进行仪器化，使其在前向和后向传递过程中发出自然语言事件。随后，通过语言模型从事件列表中生成解释。通过一个示例优化问题和神经网络训练的例子来证明该方法的有效性。

Conclusion: 
本文通过可解释的逆问题优化方法，为专家提供了通过领域抽象理解逆问题优化过程的途径，从而提高了该领域的透明度和可理解性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.11056</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>16. cs.AI-有效的针对政策合规代理的有效红队测试</title><link>https://arxiv.org/pdf/2506.09600</link><description>Background: 
在具有严格政策的领域（如退款资格或取消规则）中，越来越多地使用任务导向的基于大语言模型的代理。面临的挑战是如何确保代理始终遵循这些规则和政策，适当地拒绝任何违反政策的请求，同时保持帮助性和自然的交互。这需要开发专门的设计和评估方法，以确保代理能够抵御恶意用户行为的攻击。

Innovation: 
提出了一种新的威胁模型，重点是那些试图利用政策合规代理为自己谋利益的敌对用户。介绍了一个多代理红队系统CRAFT，该系统利用政策感知的说服策略来动摇政策合规代理在客户服务场景中的表现，优于传统的监狱突破方法，如DAN提示、情感操纵和胁迫。基于现有的tau-bench基准测试，引入了tau-break测试，旨在严格评估代理在应对操纵性用户行为时的鲁棒性。进一步评估了几种简单而有效的防御策略。虽然这些措施提供了一些保护，但它们并不充分，突显了需要更强的基于研究的保障措施来保护政策合规代理免受敌对攻击的必要性。

Conclusion: 
现有的防御措施虽然提供了一些保护，但并不充分，今后需要更强有力的研究驱动的保障措施来保护政策合规的代理免受敌对攻击。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.09600</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>17. cs.AI-SLED：用于高效边缘服务的推测性LLM解码框架</title><link>https://arxiv.org/pdf/2506.09397</link><description>Background: 
尽管设备能力有所提升，但在边缘设备上高效推理先进的大型语言模型（LLMs）仍然是一个挑战，主要受限于有限的设备内存和功率限制。现有的策略如激进量化、剪枝或远程推理，要么牺牲准确性，要么导致显著的成本负担。现有研究主要集中在通过量化、剪枝或远程推理等方法来优化模型，但这些方法在效率和成本上仍然存在权衡问题。

Innovation: 
本文提出了一种新的推测性解码框架SLED，它利用推测性解码作为加速LLM自回归生成的技术，通过协调不同类型的边缘设备的计算任务，特别适应边缘计算需求。这种方法允许轻量级边缘设备本地生成多个候选标识符，而共享的边缘服务器则利用更精确的目标模型进行批量验证。SLED方法支持设备异构性，减少了服务器端的内存使用，避免了需要部署多个目标模型。实验结果表明，SLED显著提高了系统的吞吐量、容量和成本效率，同时保持了模型的准确性。

Conclusion: 
本文提出了一种新的推测性解码框架SLED，采用分布式推理机制优化了边缘计算环境下LLM的性能。实验结果表明，该方法在不牺牲模型准确性的情况下，能在轻量级边缘设备和边缘服务器之间实现高效的多任务协同，从而显著提升系统性能和成本效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.09397</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>18. cs.AI-PlantDeBERTa: 开源语言模型用于植物科学</title><link>https://arxiv.org/pdf/2506.08897</link><description>Background: 
基于变压器的语言模型的迅猛发展促进了医学和临床自然语言处理领域的突破，但植物科学领域却没有得到充分的服务。因此，该研究旨在开发PlantDeBERTa，一种针对植物胁迫响应文献中结构化知识提取的高度性能开源模型，特别针对鹰嘴豆（Lens culinaris）的各种非生物和生物胁迫反应进行了训练，使用经过专家注释和精心策划的语料库。这种方法结合了基于变换器的模型和增强的规则后语言处理与本体论导向的实体规范化，使PlantDeBERTa能够在生物上精确地捕捉有意义的关系并保持语义忠实性。

Innovation: 
PlantDeBERTa 采用了 DeBERTa 架构，该架构以其区分注意力和强大的上下文编码而闻名。该模型结合了基于变换器的建模方法与规则增强的语言后处理和本体论导向的实体规范化方法，能够在生物上精确地捕捉有意义的关系并保持语义忠实性。通过对植物胁迫响应文献中高度复杂信息的有效提取，PlantDeBERTa 提高了领域适应能力，并提供了高度解耦和可扩展的空间。

Conclusion: 
通过使用分层框架与作物本体进行集成，PlantDeBERTa 提升了在植物适应性层面提取分子、生理、生化和农艺信息的能力。PlantDeBERTa 对实体类型表现出强大的泛化能力，证明了在资源有限的科学领域实现稳健领域适应的可能性，提供了可扩展和可重复的框架以提高植物相关实体识别的精确度。PlantDeBERTa 的发布促进了计算植物科学的透明度，并推动跨学科创新。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.08897</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>19. cs.AI-测试时的强化学习教师</title><link>https://arxiv.org/pdf/2506.08388</link><description>Background: 
目前，训练语言模型（LMs）使用强化学习（RL）进行一热正确性训练，依赖于模型在初始化时有探索和解决其任务的机会。另外，强化学习推理模型的一个主要用途是作为教师角色来训练新的学生模型，并为未来的RL迭代提供冷启动，而不是直接部署。考虑到这一点，本文介绍了一种避免RL探索挑战的新框架，通过训练一种称为强化学习教师（RLTs）的新类模型，专注于产生最有效的下游蒸馏效果。

Innovation: 
本文提出了一种新型的强化学习教师（RLTs）框架，通过向模型提供问题和解决方案，然后让模型进行详细解释来提供指导。模型通过向学生提供解释并测试学生对问题解决的理解来获得密集奖励进行训练。具体而言，基于一个7B参数的RLTs，其在竞赛和研究生级任务上的最终性能优于现有的收集并处理大得多的语言模型推理痕迹的蒸馏和冷启动管道。同时，当训练大规模模型并用于处理分布外任务时，RLTs仍然保持其有效性，这为RL推理框架的效率和可重用性开辟了新途径。

Conclusion: 
本文提出的RLTs框架通过避免RL的探索挑战，为强化学习推理模型提供了一种新的有效方式，特别是用于问题解决的下游蒸馏和冷启动。这种方法不仅提高了模型在特定任务上的性能，还增强了模型在处理大规模和未知场景下的适应性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.08388</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>20. cs.AI-DriveSuprim：端到端规划中精确轨迹选择的方法</title><link>https://arxiv.org/pdf/2506.06659</link><description>Background: 
在复杂的驾驶环境中，自动驾驶车辆必须安全导航。传统的回归方法通常依赖单条预测路径，而不对预测轨迹的安全性进行评估。选择性方法通过生成并评分多个轨迹候选并预测每个轨迹的安全分数来解决这一问题，但在从成千个可能性中精确选择最佳选项以及区分细微但关键的安全差异时面临优化挑战，尤其是在罕见或较少出现的场景中。

Innovation: 
DriveSuprim 通过粗到细的逐步候选过滤范式，基于旋转的增强方法提高分布外场景的鲁棒性，以及自蒸馏框架稳定训练，来克服这些挑战并推进选择性范式。DriveSuprim 达到了在 NAVSIM v1 中 93.5% 和 NAVSIM v2 中 87.1% 的 PDMS/EPDMS 性能，并在各种驾驶场景中保持了高质量的轨迹，同时展示了优越的安全关键能力，包括碰撞避免和遵守规则。

Conclusion: 
DriveSuprim 实现了最先进的性能，展示了在不使用额外数据的情况下优越的安全关键能力，并且在各种驾驶场景中保持了高质量的轨迹。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.06659</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>21. cs.AI-优化感受器神经元：用于排列不变神经网络加速收敛的非线性注意力机制在强化学习中的应用</title><link>https://arxiv.org/pdf/2506.00691</link><description>Background: 
训练强化学习（RL）代理通常需要大量计算资源和长时间的训练。为了解决这一挑战，本文基于先前引入排列不变感官处理的神经架构的工作，提出了一种修改后的注意力机制，通过对关键向量（K）进行非线性变换，产生通过自定义映射函数生成的丰富表示（K'）。这种非线性注意力机制（NLA）增强了注意力层的表示能力，使代理能够学习更丰富的特征交互。因此，该模型实现了更快的收敛速度和改进的训练效率，同时保持与基线相当的性能。这些结果突显了非线性注意力机制有望加速强化学习而不牺牲效果的潜力。

Innovation: 
本文提出了一种新的注意力机制——非线性注意力机制（NLA），通过对关键向量进行非线性变换，产生丰富表示，增强了代理的学习能力和表达能力，从而实现了更快的收敛速度和改进的训练效率。

Conclusion: 
非线性注意力机制能够加速强化学习过程，同时保持与基线相当的性能，展示了排列不变神经网络在强化学习中的广泛应用潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.00691</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>22. cs.AI-文本生成中噪声在上下文学习中的双重去偏</title><link>https://arxiv.org/pdf/2506.00418</link><description>Background: 
当前的上下文学习（ICL）高度依赖高质量的演示，这些演示来自于大规模标注的语料库。现有方法通过计算局部困惑度来检测噪声标注，假设噪声样本的困惑度会高于干净样本。然而，当噪声比例很高时，这种方法会失效，因为许多演示都存在缺陷。研究人员重新审视了在噪声标注下基于困惑度的文本生成范式，指出困惑度存在两种偏见来源：注释本身和大型语言模型（LLMs）固有的领域知识。这些偏见会导致方法失效。

Innovation: 
提出了一个双重去偏框架，该框架利用合成邻居明确纠正困惑度估计，从而生成一个稳健的样本清洁度评分。这个评分能够揭示单个样本的清洁度，不受整体语料库噪声水平的影响。实验证明，该方法具有优越的噪声检测能力，并且最终的ICL性能与全清洁演示语料库相当。即使噪声比率极高，该方法也保持稳健。

Conclusion: 
通过双重去偏框架，研究提出了一个能够识别噪声，并且在极高噪声比率下仍能保持ICL性能的方法，为噪声标注下的文本生成提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.00418</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>23. cs.AI-Pollux: 评估俄语大型语言模型的审判之眼</title><link>https://arxiv.org/pdf/2505.24616</link><description>Background: 
目前存在用于评估大型语言模型（LLMs）生成能力的专业基准，但这些基准往往集中在英语领域。对于俄语大型语言模型的评估，缺乏相应的全面且开放的基准工具，尤其是在增强评估的可解释性方面。POLLUX旨在填补这一空白，提供了一个用于评价俄语大型语言模型综合生成能力的开放基准。

Innovation: 
POLLUX引入了创新的评估方法，以改善LLM评估的解释性。对于每种任务类型，POLLUX定义了一组详细的评估标准，并开发了一个评分协议，其中模型评估响应并提供其评分的理由。这种方法使得评估过程更加透明和标准驱动，而不仅仅是依靠耗费资源的、一对一的人类对比。此外，POLLUX还提供了一组具备精细分类任务类型的LLM评估者（7B和32B），用于细致评估生成输出。这为模型开发提供了可扩展、可解释的评估和注释工具，有效地替代了昂贵且不太精确的人类判断。

Conclusion: 
POLLUX通过提供一个详细的、精细分类的任务类型集，涵盖了多种生成领域（如代码生成、创意写作和实用助理用例），总计2100个手动制作且专业写作的提示。该基准包括一个包含35种任务类型的详细分类学，每种任务都按难度分类（简单/中等/困难），并通过专家从头开始构建数据集。POLLUX为开阔语言模型评估基准并提供一种有效、可解释的方法做出了重要贡献。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.24616</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>24. cs.AI-仅通过最大化信心提高推理能力</title><link>https://arxiv.org/pdf/2505.22660</link><description>Background: 
强化学习（RL）已经在许多领域实现了机器学习模型的重大进步。最近，RL已经使得前沿语言模型能够解决数学、科学和编程难题。然而，任何RL算法的核心都是奖励函数，而奖励工程在任何领域都是一个极其困难的问题。本文旨在介绍一种全新的RL方法——RENT：通过熵最小化实现的强化学习，该方法完全无需外部奖励或已知答案，而是利用模型生成答案时内部分布的熵作为内在奖励。研究发现，通过强化那些导致模型对生成答案有高信心的思想链过程，可以提高模型的推理能力，并在广泛使用的推理基准测试上展现出显著的性能提升。测试了来自Qwen和Mistral家族的不同规模的模型。我们的无监督学习方法具有广泛的适用性，特别是在无法获得外部监督的领域中。

Innovation: 
RENT是一种全新的完全无监督的RL方法，不需要外部奖励或已知答案，而是利用模型内部分布的熵作为奖励。这种方法能够通过强化生成高信心答案的思想链过程，提高模型的推理能力。这种方法在多种基准测试中取得了良好的效果，适用于多种规模的模型。

Conclusion: 
本文提出的方法是一种无监督学习方法，能够通过最大化模型输出答案的信心来提高模型的推理能力，这种能力的提升在广泛的推理基准测试中得到了验证。这种方法的通用性使其能够广泛应用于无法得到外部监督的领域。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.22660</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>25. cs.AI-在语音语障检测中合成数据生成的分析与评估</title><link>https://arxiv.org/pdf/2505.22029</link><description>Background: 
语音语障检测对临床诊断和语言评估至关重要，但现有方法受限于高质量标注数据的稀缺性。尽管近期在文本转语音（TTS）模型方面的进展使得合成语音语障生成成为可能，但现有的合成数据集在语调自然性和上下文多样性方面存在局限性。

Innovation: 
提出LLM-Dys，这是最全面的包含LLM增强语障模拟的语音语障数据集，涵盖了11类语言和音素层面的语障。在此基础上，改进了一种端到端的语音语障检测框架，并通过实验验证了其领先表现。所有数据、模型和代码已开源。

Conclusion: 
实验验证表明该模型达到了最先进的性能。所有数据、模型和代码均在[this https URL]开源。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.22029</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>26. cs.AI-位置即权力：系统提示在大型语言模型（LLMs）中的偏见机制</title><link>https://arxiv.org/pdf/2505.21091</link><description>Background: 
在大型语言模型（LLMs）中，系统提示是一些预先定义的指令，这些指令优先于用户输入以指导模型的行为。模型部署者通常使用这些提示来确保在不同上下文中的一致响应。虽然模型提供者设置了系统提示的基础设置，部署者和第三方开发者可以添加额外的提示，但这所有改动都是默默进行，用户毫不知情。随着系统提示变得更加复杂，它们可能会直接或间接地引入未被记录的副作用。这种缺乏透明性引发了关于不同的指令如何影响信息位置的问题。因此，本文探讨了信息位置如何影响模型行为。本研究在六个商业可用的LLMs和50个不同的人口统计学群体上比较了系统提示与用户提示中的面向处理方式，揭示出重大的偏见问题，表现为用户表现和决策情景上的差异。这些差异源自无法访问且不透明的系统级配置，这可能带来代表性的、分配性的以及其他潜在偏见和下游危害，远远超出了用户的检测和纠正能力。这些发现突出了需要审慎处理的一些关键问题，这些问题是如果不加以审视，可能会持续带来危害。同时，我们也表明系统提示分析应该被纳入AI审查流程，特别是在商业AI部署中可定制的系统提示变得更为普遍时。

Innovation: 
本研究在多个商业可用的大型语言模型上比较了系统提示与用户提示在处理人口统计学信息时的差异，揭示了重大的偏见问题。研究强调了由于系统级别配置的不可访问性所带来的不确定性和偏见，这些问题可能威胁到用户的公平和公正性。这项研究的目的在于提醒研究人员和开发者们，系统提示背后的潜在偏见可能需要更深层次的审查和分析。

Conclusion: 
本研究揭示了系统提示如何因不可访问的系统级配置而引入未被发现的偏见，这些偏见可能在用户无察觉的情况下进一步扩散和危害。因此，研究建议加强对系统提示的审查，并将其纳入AI审查流程，特别是随着可定制系统提示的广泛使用时。这不仅有助于减少AI的潜在偏见，还促进更公平和公正的人工智能应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.21091</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>27. cs.AI-从左脑到右脑：适应性文本梦想家在视觉-语言导航中的应用</title><link>https://arxiv.org/pdf/2505.20897</link><description>Background: 
VLN需要代理在部分可观察性条件下遵循自然指令进行导航，这使得感知与语言难以对齐。近期方法通过设想未来场景来克服这个问题，但依赖于基于视觉的合成，导致高计算成本和冗余细节。

Innovation: 
本文提出了一种新的适应性文本梦想家（ATD），这是一种双分支自我指导的想象策略，基于大型语言模型（LLM）。ATD具有类人左右脑的架构，左脑负责逻辑集成，右脑负责对未来场景的想象预测。通过仅微调LLM中的Q-former，ATD可以动态更新逻辑推理和想象，同时引入交叉交互机制以正规化想象输出并注入导航专家模块，使ATD能够结合LLM的推理能力及导航模型的专业知识。

Conclusion: 
在R2R基准上进行了广泛的实验，ATD以较少的参数取得了最先进的性能。相关代码详见链接。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.20897</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>28. cs.AI-在连续空间中预训练语言模型进行斟酌</title><link>https://arxiv.org/pdf/2505.20674</link><description>Background: 
人类在表达复杂句子元素之前会进行思考，这种思考过程有助于更深入的认知处理。本文通过在单个标记生成步骤中重复调用前向过程将这种斟酌过程融入语言模型。现有的研究表明，语言模型可以通过这种方式进行自我监督学习，而无需任何人工注释。该研究通过在三个广泛使用的开源架构（GPT-2、Pythia、LLaMA）和广泛下游任务评估中进行实验，展示了该方法的有效性和通用性。

Innovation: 
通过自我监督学习的方法，使语言模型在单个标记生成步骤中反复调用前向过程，模拟人类的斟酌过程，而不依赖于人工注释。这一创新使得模型能够在处理复杂语句时实现更深入的认知处理，并且在语言建模任务上的效果相当于参数量翻倍的模型。增强了Pythia模型在9个下游基准测试中的性能，特别地，PonderingPythia-2.8B超越了Pythia-6.9B，而PonderingPythia-1B与接受10倍数据训练的TinyLlama-1.1B相当。

Conclusion: 
对于语言建模任务，斟酌语言模型的性能与二次数量级参数的简单模型相当。增强过的Pythia模型在9个下游基准测试中显著优于官方模型。通过这种方法，模型不仅可以获得与原模型相似的性能，而且在参数量小得多的情况下也能获得接近甚至超过原模型的性能，表明这种方法具有广阔的前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.20674</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>29. cs.AI-SIPDO：通过合成数据反馈的闭环提示优化</title><link>https://arxiv.org/pdf/2505.19514</link><description>Background: 
大型语言模型的表现与其提示的质量密切相关，因此促成了对提示优化的一系列研究。现有大多数方法是在固定的数据集上进行优化，假设输入分布是静态的，并且提供的迭代改进支持有限。为了克服这些局限性，需要一种新的框架来系统地提升提示性能。

Innovation: 
文章提出了SIPDO（Self-Improving Prompts through Data-Augmented Optimization，通过数据增强优化自我改进提示），它是一种闭环框架，将合成数据生成整合到优化过程中。该框架结合了合成数据生成器和提示优化器，生成新例子以暴露当前提示的弱点，优化器则逐步调整提示。这一反馈驱动的循环不依赖于外部监督或新任务就能系统性地改进提示性能。实验结果表明，SIPDO在问答和推理基准测试中优于标准提示调优方法，证明了将数据合成集成到提示学习工作流程中的重要性。

Conclusion: 
SIPDO通过应用合成数据生成和优化，提供了一种无需外部监督或新任务的迭代提示优化方法。实验结果证明了这种方法的有效性，展示了数据合成在提示学习中的重要价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.19514</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>30. cs.AI-Learning to Insert for Constructive Neural Vehicle Routing Solver</title><link>https://arxiv.org/pdf/2505.13904</link><description>Background: 
现有的基于神经网络的车辆路线问题(NCO)求解方法通常遵循一种逐步添加未访问节点的构建性范式，这种方法虽然有潜力，但由于其固有的局限性往往导致次优结果。为了解决这一问题，作者探索了插入式方法，并提出了一种新的基于学习的方法——学习以插入为基础的范式(L2C-Insert)来构建解决方案。

Innovation: 
L2C-Insert在现有的逐步添加范式基础上，通过在当前部分解的任何有效位置战略地插入未访问的节点，增加了灵活性并提升了解决方案的质量。模型框架包括三个关键组件：精确插入位置预测的新型模型架构，高效的训练方案以优化模型，以及充分利用插入范式灵活性的高级推理技术。实验结果表明，L2C-Insert在不同规模的问题上表现出优越性能。

Conclusion: 
L2C-Insert 在 Travelling Salesman Problem (TSP) 和 Capacitated Vehicle Routing Problem (CVRP) 的合成和实际实例上进行了测试，结果显示 L2C-Insert 能够在各种问题规模下稳健地提供更优的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.13904</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>31. cs.AI-LightRetriever: 基于大语言模型的高速查询推理混合检索架构</title><link>https://arxiv.org/pdf/2505.12260</link><description>Background: 
基于大语言模型（LLMs）的混合检索利用LLMs将查询和文档编码为低维密集向量或高维稀疏向量，通过向量相似性检索相关文档。文档在离线时预先编码，而查询则在实时到达，需要高效的在线查询编码器。尽管LLMs显著提升了检索能力，但运行全尺寸的LLM会降低查询推理吞吐量并增加在线部署资源的需求。背景信息说明了当前解决检索效率问题的挑战和背景。

Innovation: 
本文提出了LightRetriever，一种具有极其轻量级查询编码器的新型基于LLMs的混合检索器。与在H800 GPU上运行全尺寸LLM相比，该方法通过GPU加速实现了查询推理超过1000倍的加速，甚至在没有GPU的情况下也实现了20倍的加速。实验表明，该方法在大规模检索基准测试中能很好地泛化，保持了全尺寸LLM性能的95%左右。创新点在于通过轻量级的查询编码器实现了高效快速的查询推理，同时保障了检索的性能。

Conclusion: 
该方法不仅在速度上实现了显著提升，还能保持与全尺寸LLM相当的性能，特别是在大规模检索任务中表现出色，适合在实际中进行高效部署。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12260</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>32. cs.AI-MIRAGE: 多模态空间感知、推理和智能基准</title><link>https://arxiv.org/pdf/2505.10604</link><description>Background: 
空间感知和推理是人类认知的核心组成部分，包括物体识别、空间关系理解和动态推理。尽管计算机视觉取得了进展，现有的基准仍然揭示出模型在准确识别物体属性和推理空间关系方面存在显著差距，这二者对于动态推理至关重要。由于这些局限性，我们提出了MIRAGE，一个多模态基准，用于评估模型在计数（物体属性识别）、关系（空间关系推理）以及计数与关系方面的能力。通过多样且复杂的场景需要细致的识别和推理，MIRAGE突显了最先进的模型的关键局限性，强调了改进表示和推理框架的需求。

Innovation: 
MIRAGE是一个多模态基准，旨在评估模型在物体属性识别、空间关系推理以及计数与关系方面的能力。通过多样且复杂的场景，MIRAGE展示了最先进的模型的局限性，强调了改进表示和推理框架的需求，为未来研究提供了空间时空推理的方向。

Conclusion: 
MIRAGE通过多样化和复杂的场景，揭示了当前最先进的模型在空间感知和推理方面的局限性，强调了改进表示和推理框架的重要性，为未来的研究提供了一个方向，旨在推动时空推理的研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.10604</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>33. cs.AI-介绍语音音色属性检测</title><link>https://arxiv.org/pdf/2505.09661</link><description>Background: 
该论文关注语音信号中传达的音色及其感知，提出了语音音色属性检测（vTAD）任务。在该任务中，通过一组描述人类感知的感官属性来解释语音音色。通过处理语音片段并对它们在指定音色描述符中的强度进行比较，研究者使用提取自语音片段的说话者嵌入构建了一个框架。研究在VCTK-RVA数据集上进行，实验结果表明，在训练集中包括测试说话人的场景（seen scenario）下ECAPA-TDNN说话者编码器表现更优；而在测试说话人不在训练集中的场景（unseen scenario）下FACodec说话者编码器表现出更优的泛化能力。

Innovation: 
提出了语音音色属性检测（vTAD）任务，通过一组描述人类感知的感官属性解释语音音色，使用ECAPA-TDNN和FACodec说话者编码器在不同场景下进行实验，展示了不同的编码器在已见和未见场景中的表现差异，表明提高了模型的泛化能力。

Conclusion: 
提出了语音音色属性检测任务，验证了ECAPA-TDNN和FACodec在不同场景下的适用性，进一步证明了FACodec在未见场景中的优越的泛化能力，并提供了VCTK-RVA数据集及开源代码。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.09661</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>34. cs.AI-2025年语音音色属性检测挑战评估计划</title><link>https://arxiv.org/pdf/2505.09382</link><description>Background: 
语音音色是指人耳感知到的区分一个人声音的独特质量或特征。Voice Timbre Attribute Detection (VtaD) 2025挑战旨在以比较的方式解释语音音色属性。在该挑战中，人类对语音音色的印象被用一组感官描述词进行描述，包括明亮、粗糙、温柔、磁性等。音色是在特定描述词维度内两个声音强度的比较中进行解释的。VtaD 2025挑战从5月开始，并于2025年10月在中国镇江举行的NCMMSC2025会议上达到高潮，展示特别提案。

Innovation: 
该挑战通过使用一组感官描述词来量化和解释人类感知的语音音色差异，提供了一种新的方法来理解和评估语音音色。此外，通过在NCMMSC2025会议上展示特别提案，该挑战还促进了相关领域的学术交流和技术进步。

Conclusion: 
VtaD 2025挑战为语音音色属性的客观评估提供了一个评估计划，旨在通过具体的感官描述词和声音强度比较，描述和解释人类感知的音色差异。该挑战最终体现了一种创新的方法来理解和评估语音音色，并将在学术和技术领域产生积极影响。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.09382</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>35. cs.AI-基于图增强的大规模语言模型TrumorGPT用于事实核查</title><link>https://arxiv.org/pdf/2505.07891</link><description>Background: 
在社交媒体时代，错误信息和谣言的快速传播导致了信息疫情的出现，虚假信息对社会构成了严重威胁。为了应对这一问题，我们提出了TrumorGPT，一种新型生成式人工智能解决方案，旨在健康领域进行事实核查。TrumorGPT旨在区分'谣言'，即那些最终被证实为真实的健康谣言，为鉴别纯属猜测与验证事实提供了一个关键工具。该框架利用大规模语言模型（LLM）结合少样本学习，构建语义健康知识图谱并进行语义推理。

Innovation: 
TrumorGPT引入了基于图检索增强生成（GraphRAG）的方法来解决大规模语言模型常见的幻觉问题以及静态训练数据的局限性。GraphRAG利用定期更新的语义健康知识图谱中的最新医疗新闻和健康信息，确保TrumorGPT的事实核查基于最新数据。通过对广泛医疗数据集的评估，TrumorGPT在公共健康声明的事实核查方面表现出优异性能。

Conclusion: 
TrumorGPT在多种平台上有效开展事实核查的能力标志着对抗与健康相关错误信息的关键进展，提升了数字信息时代对信任和准确性的增强。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.07891</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>36. cs.AI-AI数值天气模型的民主化：一个使用FourCastNetv2的大学研究实验室全球预报案例</title><link>https://arxiv.org/pdf/2504.17028</link><description>Background: 
本文展示了如何通过利用图形处理单元（GPUs）和可自由获取的人工智能模型（如NVIDIA的FourCastNetv2），在大学研究组中民主化人工智能驱动的全球天气预报模型的可行性。尽管NVIDIA的模型在时间和成本上相比传统的数值天气预报（NWP）有很大的优势，但由于资源有限，尤其是GPU资源有限，资源受限的大学研究小组在重现已出版的预报结果时仍面临持续的挑战。该论文展示了如何利用FourCastNetv2进行预测并通过指定的应用编程接口（API），以及如何利用NVIDIA硬件重新训练原始的FourCastNet模型。此外，论文探讨了数据管理、训练效率和模型验证，强调了在资源有限的高性能计算条件下使用高性能计算资源的优势和挑战。

Innovation: 
本文的一个创新点在于展示了如何在资源限制条件下重现人工加速驱动的全球天气预报模型的预测结果，尤其是在GPU资源有限的情况下。研究使用了NVIDIA的FourCastNetv2模型和A100 GPU，具体展示了如何利用这些资源构建预测系统，并探讨了其在大学研究中的实际应用。通过详细的实验和资源管理策略分享，为其他大学研究组提供了宝贵的参考信息，从而有助于实现人工智能驱动的数值天气预测在数字经济中的普及。

Conclusion: 
本文及其相应的GitHub材料可作为其他大学研究组和与机器学习、气候科学和数据科学相关的课程在人工智能天气预报方面开展研究和教育项目的初步指南，有助于推动人工智能驱动的数值天气预测技术的普及，促进数字经济发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.17028</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>37. cs.AI-在离策指导下的推理学习</title><link>https://arxiv.org/pdf/2504.14945</link><description>Background: 
最近的大推理模型（LRMs）研究表明，通过具验证奖励的强化学习（RLVR），复杂的多步推理和自我反省等行为可以自发生成。不过，现有的RLVR方法本质上是'在策'的，这限制了学习仅限于模型自身的输出，并且未能获得超越初始能力的推理能力。

Innovation: 
本文提出了LUFFY框架，这是一种结合了离策演示和在策采样以增强RLVR的工具。LUFFY在混合策训练中动态平衡模仿和探索。此外，LUFFY结合了具有理论保证收敛率的混合策GRPO框架，并利用正则化重要性采样进行策略塑造，以避免混合策训练中的浅层和僵硬模仿。相比之前的RLVR方法，LUFFY在六个数学基准测试中获得平均超过6.4的性能改进，在分布外任务中则超过6.2点的优势。最重要的是，LUFFY成功训练了在策略RLVR中完全失败的弱模型。这些结果证明了LUFFY超过了基于RLVR的基本限制，并展示了使用离策指导的潜在价值。

Conclusion: 
研究结果表明LUFFY超越了基于RLVR的基本限制，并展示了利用离策指导在RLVR中具有很大的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.14945</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>38. cs.AI-保护您的声音：基于时间感知的稳健水印</title><link>https://arxiv.org/pdf/2504.14832</link><description>Background: 
生成模型的快速发展导致了合成声音的真假难以区分。为了消除这种不确定性，将水印嵌入到合成声音的频域特征中已成为一种常见做法。然而，这种方法虽然提高了水印的鲁棒性，但也导致了对细粒度声音特征的损失，从而降低了声音的保真度。n

Innovation: 
为了在保持鲁棒性的同时提高保真度，本文提出了一种基于时间感知的稳健水印方法（True），这种方法结合内容驱动的编码器进行水印波形重建，并设计了时间感知门控卷积网络在位级别上恢复水印。实验结果表明，该方法具有较高的保真度和强大的鲁棒性，平均PESQ得分为4.63。n

Conclusion: 
通过提出的基于时间感知的稳健水印方法（True），作者展示了在保持声音和歌唱声音的鲁棒性的同时，提高了保真度。n</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.14832</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>39. cs.AI-基于多粒度候选感知的个性化新闻推荐</title><link>https://arxiv.org/pdf/2504.14130</link><description>Background: 
个性化新闻推荐的核心在于将候选新闻与用户的兴趣进行匹配。现有的大多数方法仅通过用户点击过的新闻来构建单一的兴趣概况，这可能无法全面捕捉用户的兴趣多样性。虽然有些方法考虑了候选新闻或主题信息，但这些方法忽略了许多粒度层次上候选新闻与用户兴趣之间的关系，因此仍不够全面。

Innovation: 
本研究提出了一个多粒度的候选感知用户建模框架，该框架能够整合用户兴趣特征，跨越不同的粒度级别。模型包含两个主要组件：候选新闻编码和用户建模。通过新闻文本信息提取器和知识增强实体信息提取器可以捕捉候选新闻特征，而基于词、实体和新闻级别的多粒度候选感知机制能提供全面的用户兴趣表示。实验结果表明，所提出的模型优于基线模型，具有显著的优势。

Conclusion: 
研究通过一个多粒度的候选感知用户建模框架，有效地提升了个性化新闻推荐的效果，克服了单一兴趣概况及忽略粒度层次关系的局限性，为未来的研究提供了新思路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.14130</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>40. cs.AI-从参考答案学习：无需二元人类偏好数据的通用语言模型对齐</title><link>https://arxiv.org/pdf/2504.09895</link><description>Background: 
大型语言模型（LLMs）被期望具备帮助性、无害性和诚实性。在安全、信心和一般偏好对齐等对齐场景中，二分类偏好数据收集和奖励建模对于转移人类的偏好是必要的，但这些过程耗时且资源密集。通过利用采样生成与高质量参考答案之间的相似性，该研究探索了一种替代的奖励机制选择方法，以减少上述问题。RefAlign算法是一种无需参考模型或奖励模型的通用REINFORCE风格对齐算法，使用相似性度量作为替代奖励，并将这种奖励方法扩展到安全性和信心对齐等场景中。

Innovation: 
引入了RefAlign算法，这是一种无需依赖参考或奖励模型的通用REINFORCE风格对齐算法。RefAlign算法通过使用BERTScore等相似性度量作为替代奖励，首次利用参考答案之间的相似性来替代二分类偏好数据和奖励模型，从而简化了对齐过程，并根据不同场景（如安全和信心对齐）集成任务相关目标，以实现对齐优化。这种方法在各种场景中展示了与之前的对齐方法相当的表现，而无需使用二分类偏好数据和奖励模型。

Conclusion: 
RefAlign算法证明了在安全和信心对齐等场景中比以往的对齐方法表现更好或相当，且无需依赖二分类偏好数据和奖励模型。这表明利用高质量参考答案之间的相似性可以有效简化对齐过程，并且该方法在多种场景下具备广泛应用前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.09895</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>41. cs.AI-AutoPDL: 自动优化LLM代理的提示</title><link>https://arxiv.org/pdf/2504.04365</link><description>Background: 
大型语言模型（LLMs）的性能取决于它们如何被提示，提示的选择包括高层次的提示模式（例如，零样本、逐步推理、ReAct、ReWOO）和具体的提示内容（指令和少量的示范）。手动调整这种组合既繁琐又容易出错，而且针对特定的LLM和任务。因此，本文提出了一种名为AutoPDL的自动化方法，用于发现性能良好的LLM代理配置。这种方法将这一过程框架化为一个结构化搜索问题，并使用逐次减半的策略在组合的空间中高效地导航，该空间包括行为提示模式和非行为提示模式以及示范组合。

Innovation: 
AutoPDL是一种自动化的提示优化方法，通过结构化搜索在行为和非行为的提示模式以及示范的组合空间中寻找最佳的LLM代理配置。它利用逐次减半策略高效导航这些空间，并通过使用PDL提示编程语言实现了一个常用的提示模式库。AutoPDL生成的人类可读、可编辑和可执行的PDL程序可以进行源到源优化，允许在循环中的人类优化和重用。在三个任务和七个不同规模的LLM（从3亿到70亿参数）上进行了评估，显示了一致的准确性提升，最高达68.9个百分点，并揭示了选定的提示策略在不同模型和任务之间有所不同。

Conclusion: 
AutoPDL通过自动化的提示优化方法，以人类可读、可编辑和可执行的PDL程序的形式，为LLM代理找到合适配置，从而实现准确性的提升，并能在不同规模的LLM和多种任务上提供一致的改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.04365</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>42. cs.AI-PiCo：通过$textbf{Pi}$ctorial $textbf{Co}$de上下文化破解多模态大型语言模型</title><link>https://arxiv.org/pdf/2504.01444</link><description>Background: 
多模态大型语言模型（MLLMs）将视觉和其他模态整合到大型语言模型（LLMs）中，显著增强了人工智能的能力，但也引入了新的安全漏洞。通过利用视觉通道的漏洞及其训练数据的长尾分布特性，本文提出了PiCo，一种新型的破解框架，旨在逐级绕过高级MLLMs中的多级防御机制。PiCo采用逐级破解策略，利用字符级类型的攻击来逃避输入过滤，并在编程语境指令中嵌入有害意图以绕过运行时监控。通过嵌入有害意图于代码风格的视觉指令中，PiCo在Gemini-Pro Vision上的攻击成功率（ASR）为84.13%，在GPT-4上的ASR为52.66%，超越了之前的方法。实验结果突显了当前防御策略中的关键差距，强调了采用更 robust 策略保护先进MLLMs的紧迫性.

Innovation: 
PiCo提出了一种新的破解框架，采用了逐级破解策略，并利用字符级类型的攻击来逃避输入过滤，以及在编程语境指令中嵌入有害意图以绕过运行时监控。此外，它还提出了一种新的评估方法来衡量攻击后的模型输出的毒性与有用性，并取得了较高的ASR，优于现有方法。现阶段的防御策略存在明显的漏洞，这突显了采用更 robust 的防御策略的重要性和紧迫性。

Conclusion: 
实验数据表明，目前的防御措施存在明显的薄弱环节，这强调了需要采用更 robust 的策略来保障高级多模态大型语言模型的安全性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.01444</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>43. cs.AI-从简单到复杂：构建差分隐私图像合成的捷径</title><link>https://arxiv.org/pdf/2504.01395</link><description>Background: 
差分隐私（DP）图像合成的目标是从敏感数据集生成合成图像，以解决组织共享和利用合成图像时可能产生的隐私泄露问题。尽管之前的方法在训练敏感图像的扩散模型方面有了显著进步，特别是在使用差分隐私随机梯度下降（DP-SGD）训练扩散模型方面，但这些方法的性能仍然不尽如人意。.

Innovation: 
本文受到递增学习方法的启发，提出了一种两阶段的差分隐私图像合成框架，该框架使扩散模型从简单到复杂逐步学习生成差分隐私的合成图像。与现有的直接使用DP-SGD训练扩散模型的方法不同，本文在初始阶段提出了一个简单的阶段，让扩散模型学习敏感图像的简单特征。为了便于这个简单阶段，在此提议使用‘中心图像’，即敏感数据集的随机样本聚合。这些中心图像虽然不显示细节，但展示了所有图像的有用特征，并导致了最小的隐私成本，从而有助于早期阶段的模型训练.

Conclusion: 
实验结果表明，在四个研究图像数据集的平均值上，本文合成图像的保真度和实用性指标分别比当前最先进的方法高出33.1%和2.1%。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.01395</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>44. cs.AI-使用多模态大型语言模型进行具有情境意识的人类行为预测：挑战与见解</title><link>https://arxiv.org/pdf/2504.00839</link><description>Background: 
在共享环境中预测人类行为对于安全和高效的机器人交互至关重要。传统的数据驱动方法依赖于特定领域的数据集、活动类型和预测范围进行预训练。相比之下， LARGE LANGUAGE MODELS (LLMs) 的最新突破为描述各种人类活动并在任何上下文中进行预测提供了开放的跨域通用能力。特别是，MULTIMODAL LLMs (MLLMs) 能够整合来自多种来源的信息，从而提高上下文意识和场景理解能力。然而，直接使用通用的 MLLMs 进行预测存在挑战，包括处理大规模输入序列的能力有限、对提示设计的敏感性以及昂贵的微调成本。本研究旨在系统分析使用预训练 MLLMs 进行人境行为预测的方法。

Innovation: 
提出了一个模块化的多模态人类行为预测框架，该框架允许评估各种 MLLMs、输入变体、In-Context Learning (ICL) 和自回归技术。该研究揭示了最佳框架配置能够达到 92.8% 的语义相似度和 66.1% 的精确标签准确性，从而在目标帧中预测人类行为。

Conclusion: 
通过模块化的多模态框架评估预训练 MLLMs，证明了它们在预测人类行为方面的潜力，尤其是在目标帧中的表现优异。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.00839</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>45. cs.AI-Rubric Is All You Need: Enhancing LLM-based Code Evaluation With Question-Specific Rubrics</title><link>https://arxiv.org/pdf/2503.23989</link><description>Background: 
自从GPT-3和ChatGPT的发布使得大型语言模型（LLMs）受到广泛关注以来，LLMs在编程相关任务中展现出显著潜力。尽管使用LLMs进行代码生成已成为研究热点，但使用LLMs进行代码评估仍处于起步阶段。因此，本研究聚焦于LLMs的代码评估，提出了一种新的多主体方法，利用针对问题的具体评估标准（rubrics），以提高逻辑评估的准确性。此外，由于缺乏合适的评估数据集，研究还引入了两个数据集：一个是包含150名学生提交的数据结构和算法集，另一个是包含80名学生提交的对象导向编程集。在评估中使用了标准指标如Spearman相关系数和Cohen's Kappa，并提出了一个新的指标称为‘宽容度’来量化评估的严格性。研究结果表明，针对问题的具体评估标准显著提高了教育环境中的代码逻辑评估，提供了与教学目标更好地对齐的反馈，而不仅仅是语法正确性方面。

Innovation: 
本研究提出了一种新的多主体方法，利用针对问题的具体评估标准（rubrics），这种做法在逻辑评估中表现优于现有的使用通用评估标准的方法。此外，研究还引入了两个新的数据集，以及一个评估严格性的新指标‘宽容度’，以解决现有评估数据集的不足。

Conclusion: 
本研究通过引入针对问题的具体评估标准和新的评估数据集，显著提升了LLMs在教育环境中的代码逻辑评估能力，提供了更符合教学目标的反馈。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.23989</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>46. cs.AI-Shapley Revisited: Tractable Responsibility Measures for Query Answers</title><link>https://arxiv.org/pdf/2503.22358</link><description>Background: 
Shapley值起源于合作博弈论，用于衡量数据库事实对获取某一查询答案的贡献。对于非数值查询，通过考虑一个玩家是数据库事实且财富函数给每个子集分配1或0的博弈来实现这一目标，这取决于查询答案是否适用于该子集。尽管该方法概念上简单，但计算这种Shapley值在数据复杂性方面是#P-难问题，即使是简单的合取查询也是如此。这促使我们重新审视什么构成了合理的责任度量，并引入了一类新的责任度量——最小支持的加权和（WSMS），这些度量符合直观的属性。

Innovation: 
该研究引入了一种新的责任度量——最小支持的加权和（WSMS），这些度量虽然定义简单且与Shapley值公式无明显关联，但被证明可以等效地视为通过相应定义的博弈的Shapley值。WSMS措施对包括所有并合取查询在内的大量查询具有可处理的数据复杂性。该研究进一步探讨了WSMS计算的组合复杂性，并建立了各种合取查询子类的（不）可处理性结果。

Conclusion: 
通过引入WSMS，该研究解决了Shapley值计算的#P-难问题，对于大量查询类型提供了可处理的数据复杂性，并建立了WSMS计算的组合复杂性（不）可处理性结果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.22358</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>47. cs.AI-简明且关键的迭代去噪：图生成中离散扩散的重新构建</title><link>https://arxiv.org/pdf/2503.21592</link><description>Background: 
离散扩散和流匹配模型在生成图等离散结构方面取得了显著进展。然而，在反向去噪过程中，中间噪声状态之间的依赖性导致错误累积和传播，这被称为累积去噪错误。

Innovation: 
提出了一个名为简单迭代去噪的新框架。该框架通过假设中间状态之间的条件独立性简化了离散扩散，并通过引入Critic增强了模型。Critic根据数据分布的概率保留或篡改实例中的元素。

Conclusion: 
实验证明，所提方法在图生成任务中显著优于现有的离散扩散基线。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.21592</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>48. cs.AI-Large Language Models powered Malicious Traffic Detection: Architecture, Opportunities and Case Study</title><link>https://arxiv.org/pdf/2503.18487</link><description>Background: 
恶意流量检测是网络安全技术的关键，用于识别异常网络流量并检测网络攻击。尽管大规模语言模型（LLMs）在文本处理方面积累了丰富的上下文理解和常识知识，但在利用LLMs进行恶意流量检测方面仍缺乏全面分析，特别是在针对具体网络安全任务的应用上。本文旨在探讨利用LLMs在恶意流量检测中的潜力，提出了一种利用LLMs进行DDoS检测的框架，展示了其在地毯式DDoS检测中的准确性，并显示出比现有系统近35%的改进效果。

Innovation: 
本文创新地提出了利用LLMs进行恶意流量检测的整体架构，具体包括预训练、微调和检测过程。根据LLMs的知识和能力，本文指出了LLMs在流量分类中的三个角色：分类器、编码器和预测器，并详细解释了每种角色下的建模范式、机遇与挑战。最后，通过DDoS检测的案例研究，展示了LLMs在上下文挖掘方面的能力，其检测方案取得了显著效果。

Conclusion: 
本文研究了利用大规模语言模型（LLMs）进行恶意流量检测的可能性，并详细阐述了LLMs在恶意流量分类中的三大角色及面对的挑战。所提出的DDoS检测框架利用了LLMs在上下文挖掘方面的强大能力，显示出近乎35%的检测性能提升，验证了利用LLMs进行恶意流量检测的可行性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.18487</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>49. cs.AI-TreeSynth: 通过树引导的子空间分割从零合成多样化数据</title><link>https://arxiv.org/pdf/2503.17195</link><description>Background: 
模型定制需要高质量和多样化的数据集，但获取这些数据仍然耗时且劳动密集。尽管大型语言模型（LLMs）在数据合成方面具有巨大潜力，但当前的方法受到有限种子数据、模型偏见和低变化提示的限制，导致数据规模增加时多样性有限且分布偏倚。为解决这一挑战，本文介绍了一种基于树引导的子空间数据合成方法TREESYNTH，该方法通过决策树启发的树结构空间细分构建方法来递归地将特定任务的数据空间分割为多个互斥且全面的基础子空间，确保在每个基础子空间内合成样本前具有独特性和完整性，从而有效避免重复和空间坍塌，确保大规模数据合成的多样性。此外，空间细分树还使得样本可以重新分配到基础子空间中，从而对现有数据集进行重新平衡，以获得更平衡和全面的分布。

Innovation: 
TREESYNTH通过决策树引导的空间细分方法，构建一个地理分区树，递归地将任务特定的完整数据空间分割为多个互斥的原子子空间，确保在每个原子子空间内合成样本前具有独特性和完整性，从而有效避免重复和空间坍塌，确保大规模数据合成的多样性。此外，空间细分树还允许对现有数据集进行重新平衡，以实现更平衡和全面的分布。实验结果表明，TREESYNTH在多个基准数据集上表现出优于人类设计数据集和同类数据合成方法的数据多样性和模型性能，平均性能提升达到10%。此外，TREESYNTH平衡的数据集的一致改进突显了其在重新平衡现有数据集方面实现更全面覆盖和性能提升的有效应用。

Conclusion: 
TREESYNTH通过树引导的子空间分割方法，能够从零合成多样化数据，并在多个基准数据集上取得了优于人类设计数据集和同类数据合成方法的结果，展示出其在重新平衡现有数据集以实现更全面覆盖和性能提升的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.17195</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>50. cs.AI-基于双向上下文感知的测试时学习方法在文本分类中的应用</title><link>https://arxiv.org/pdf/2503.15469</link><description>Background: 
文本分类是指将文本归类到预定义的类别中。传统的分类方法在处理复杂结构和长距离依赖时表现不佳。尽管深度学习模型，如循环神经网络和Transformer模型，在特征提取和上下文感知方面有所改进，但这些模型仍然在可解释性、效率和上下文范围之间进行权衡。

Innovation: 
本文提出了一种动态双向Elman注意网络（DBEAN）。DBEAN结合了双向时间建模和自注意力机制，能够动态加权关键输入段并保持计算效率，从而改进了复杂结构和长距离依赖下文本分类的效果。

Conclusion: 
总之，DBEAN在处理文本分类任务中的复杂结构和长距离依赖性方面提供了新的解决方案，通过动态加权关键输入段和保持计算效率，提升了分类性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.15469</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>51. cs.AI-LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation</title><link>https://arxiv.org/pdf/2503.13794</link><description>Background: 
大型预训练模型通过大规模视觉语言数据训练，可以在开放词汇对象检测（OVD）中发挥作用，但手动设计的管道经常引入偏差并过度拟合特定提示。研究者们发现直接将大型语言模型（LLM）的隐藏状态融合到检测器中是一个尚未充分探索的途径。通过这种方式，可以通过利用LLM解码器层来系统地增强视觉定位，从而有效融合LLM知识至对象检测器。实验结果显示，中间LLM层已经包含了丰富的空间语义，仅对早期层进行适应就能获得大部分收益。在使用Swin-T作为视觉编码器的情况下，Qwen2-0.5B + LED在OmniLabel上的表现提升了3.82%，额外的计算消耗仅为8.7%的GFLOPs（每秒浮点运算次数），使用更大的视觉骨干网络进一步提高了6.22%。

Innovation: 
该研究提出了一种跨注意力适配器的新方法，名为LED（LLM增强开放词汇对象检测），该方法可以在不依赖人类生成数据的情况下，直接将LLM隐藏状态融入检测器，特别是利用LLM解码器层。此方法能够有效地融合LLM知识，同时减少过度拟合的问题，并且在使用有限的计算资源（仅为少量额外的GFLOPs）的情况下，获得了显著的性能提升。实验还验证了仅调整早期LLM层即可以获得大部分性能增益的策略，进一步支持了该设计的有效性。详细的适应器变体、LLM规模和融合深度的消融实验进一步证实了这一方法的有效性。

Conclusion: 
该方法通过直接将LLM隐藏状态融合到检测器中，不再依赖手工设计的管道，能够有效解决现有方法中的偏置和过拟合问题，同时在提高开放词汇对象检测性能的同时，保持了较低的计算复杂度。此外，实验表明，只有调整早期LLM层就可以获得大部分性能增益，这种方法在不同大小的视觉编码器上都表现出了良好的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.13794</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>52. cs.AI-HiRAG: 基于层次知识的检索增强生成</title><link>https://arxiv.org/pdf/2503.10150</link><description>Background: 
图为基础的检索增强生成(RAG)方法显著提升了大型语言模型(LLMs)在特定领域任务中的性能。然而，现有的RAG方法未能充分利用人类认知中自然存在的层次化知识，这限制了RAG系统的功能。

Innovation: 
在本文中，我们提出了一种新的RAG方法，称为HiRAG，该方法利用层次知识来增强RAG系统在索引和检索过程中的语义理解和结构捕获能力。我们的实验表明，HiRAG在最先进的基线方法上实现了显著的性能提升。

Conclusion: 
HiRAG通过利用层次知识增强了RAG系统的语义理解和结构捕获能力，实现了在领域特定任务中的显著性能提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.10150</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>53. cs.AI-自动驾驶中的轨迹预测：进展、局限性和未来方向</title><link>https://arxiv.org/pdf/2503.03262</link><description>Background: 
随着自动驾驶汽车大规模集成到现代交通系统中的潜力不断增加，确保在动态环境中安全导航对于实现平滑集成至关重要。为了保证安全并防止碰撞，自动驾驶汽车必须能够准确预测周边交通代理的轨迹。过去十年，学术界和工业界都在致力于设计精确轨迹预测的解决方案。尽管已经产生了多种方法，但关于这些方法之间的差异及其是否涵盖了所有轨迹预测挑战仍有疑问。

Innovation: 
本文综述了近年来的轨迹预测方法，提出了一种新的分类方法，并对预测管道进行了总体概述，包括输入和输出模式、建模特征以及文献中现有的预测范式。此外，文章讨论了轨迹预测的活跃研究领域，回答了提出的研究问题，并指出了剩余的研究空白和挑战。

Conclusion: 
本文总结了关于轨迹预测的最新进展，并探讨了存在的局限性以及未来的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.03262</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>54. cs.AI-POPGym Arcade: 并行像素部分可观测马尔可夫决策过程</title><link>https://arxiv.org/pdf/2503.01450</link><description>Background: 
本文介绍了POPGym Arcade，这是一种硬件加速的、基于像素的环境集合，具有共享的观测和动作空间。每个环境都包含完全和部分可观测的变体，这使得研究人员可以在部分可观测性上开展对照性研究。文中还引入了用于在部分可观测情况下分析策略的数学工具，揭示了代理如何回忆过往信息来做出决策。研究表明，控制部分可观测性至关重要，并且具有长期记忆的代理会学习到脆弱的策略，难以进行泛化。

Innovation: 
1. 首次提出了一种基于硬件加速的像素级环境集合—POPGym Arcade。n2. 引入了分析部分可观测环境下策略的新数学工具，揭示了代理如何利用过往信息进行决策。n3. 揭示了长期记忆代理学习的策略存在不足，难以泛化。n4. 提出了“通过旧的、未标注的数据‘污染’循环策略”的理论，对模拟到现实世界的转移、模仿学习和离线强化学习具有重要意义。

Conclusion: 
研究结果表明，必须严格控制部分可观测性，因为它对于策略的学习和泛化至关重要。同时，低成本的过去数据可能会影响基于历史信息决策的能力，而具有长期记忆的代理在多种学习场景中表现出脆弱的学习策略。特别是在从模拟到现实世界的转移以及离线强化学习和模仿学习中，必须注意这部分问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.01450</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>55. cs.AI-BAnG: 双向锚定生成方法在条件RNA设计中的应用</title><link>https://arxiv.org/pdf/2502.21274</link><description>Background: 
设计能与特定蛋白质交互的RNA分子在实验和计算生物学中是一个关键挑战。现有的计算方法要求针对每种特定蛋白质有大量的已知相互作用RNA序列，或者需要详细的RNA结构知识，这限制了它们的实际应用范围。当前迫切需要一种无需这些限制的方法来生成RNA序列用于蛋白质交互作用的预测和设计，特别是使用深度学习技术的方法。本研究旨在提出一种新的深度学习模型，该模型能够生成用于蛋白质交互的RNA序列，不受上述限制的影响。此外，我们引入了一种新的生成方法，双向锚定生成（BAnG），利用RNA序列中的功能结合模块在更广泛的序列背景中分布的观察结果进行设计。通过这种方法，我们证明了可以有效地进行条件RNA序列设计，应用于实际的蛋白质结合序列中，而无需预先知道相互作用的序列或详细的RNA结构信息。

Innovation: 
本研究提出了一种名为BAnG的双向锚定生成方法，用于生成RNA序列，无需依赖预先已知的RNA-蛋白相互作用序列或详细的RNA结构知识。这种方法通过利用功能结合模块在其更广泛的序列背景中的分布特性来增强生成过程。通过这种方法，该模型能够生成高质量的RNA序列来与特定的蛋白质结合。此外，BAnG方法的创新在于其能够用于设计具有特定条件的RNA序列，即给定一个特定的蛋白质结合蛋白，该方法能够有效地生成相应的RNA序列，无需其他知识输入即实现条件RNA序列设计。

Conclusion: 
本研究通过引入BAnG方法，证明了可以通过深度学习实现高效的条件RNA序列设计。与现有的生成方法相比，该方法无需预先知道RNA-蛋白相互作用序列或详细的RNA结构信息，能够显著提高研究效率。未来的研究方向可以朝着扩大模型的应用范围和提高生成序列的多样性，以更好地满足实际应用的需求。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.21274</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>56. cs.AI-方向梯度投影在基础模型鲁棒微调中的应用</title><link>https://arxiv.org/pdf/2502.15895</link><description>Background: 
鲁棒微调的目标是将大型预训练模型适应下游任务的同时保留其对分布变化的鲁棒性。现有方法主要通过约束和投影当下的模型向预训练初始化靠近，基于微调和预训练权重之间的幅度差异进行，通常需要大量的超参数调优，并且有时会导致欠拟合。已有研究集中在权重幅度上的约束和投影，以保持模型的初始化状态，这在一定程度上限制了模型的适应性。本文的目标是在保持模型鲁棒性的前提下，使得模型能够适应下游任务的特性。

Innovation: 
本文提出了一种新颖的逐层可训练方法，称为方向梯度投影（DiGraP），该方法结合了梯度的方向信息，以桥梁正则化和多目标优化。此外，通过分析图像分类重新表述的视觉问答基准数据集以及进一步将十种不同分布类型和程度（近似之外和远之外）的分布变化视觉问答数据集进行分类，将单纯模态和多模态之间的差距缩小。DiGraP方法对于具有判别性和生成性后端的基础模型，在图像分类和视觉问答任务上均表现出色，提升了模型的分布内适应性以及远分布的鲁棒性。

Conclusion: 
实验结果显示， DiGraP方法在图像分类和视觉问答任务上均优于现有的基线模型，无论是在具有判别性还是生成性后端模型上，都在组合内（ID）泛化和远组合外（OOD）鲁棒性上取得了优异的效果。此外，作者还将其方法推广到多模态评估环境，进一步验证了其鲁棒微调的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.15895</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>57. cs.AI-ParamMute: 抑制关键FFN以实现忠实的检索增强生成</title><link>https://arxiv.org/pdf/2502.15543</link><description>Background: 
大型语言模型（LLMs）结合了检索增强生成（RAG），通过将输出锚定在外部证据上提高了事实准确性。然而，它们仍然容易产生不忠实的生成，即输出与相关且准确的检索上下文相矛盾。现有的旨在提高忠实度的方法主要集中在增强外部上下文的利用上，但往往忽略了生成过程中内部参数知识持续的影响。已有研究主要侧重于外部上下文的利用，忽视了内部参数知识的影响。因此，论文旨在探究不忠实生成的内部机制，并确定了在不忠实生成中活跃度较高的中间到深层的前馈网络（FFNs）。这些发现强调了缓解内部知识主导地位的重要性，并为提高LLM在RAG中的可信度指明了新方向。

Innovation: 
该研究提出了通过抑制与不忠实生成相关的中间到深层的前馈网络（FFNs）的激活来提高上下文忠实度的框架—Parametric Knowledge Muting through FFN Suppression (ParamMute)。此外，该工作还引入了专为评估内部知识与准确外部证据冲突场景中的忠实度设计的基准测试集CoFaithfulQA。实验结果表明，ParamMute框架能够显著提高CoFaithfulQA和已建立的ConFiQA基准的忠实度，减少了对参数记忆的依赖性。这些发现为提高LLM在RAG中的可信度提供了新的方向。

Conclusion: 
论文的研究成果表明，通过抑制不忠实生成相关的FFN的激活，可以显著增强LLM的忠实度，这些发现强调了减轻内部知识主导地位的重要性，并为提高LLM在RAG中的可信度提供了新的研究方向。所有代码均可在该链接中获得：this https URL。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.15543</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>58. cs.AI-引导LLMs进行形式定理证明</title><link>https://arxiv.org/pdf/2502.15507</link><description>Background: 
大型语言模型（LLMs）在使用如Lean这样的证明助手证明形式定理方面表现出潜在价值，但当前最先进的语言模型在预测证明中的下一步时遇到困难，导致用户需要使用不同的抽样技术来提升LLMs的能力。我们观察到LLMs可以预测正确的技术，但面临的挑战是恰当排名候选技术，影响整体选择过程。因此，需要一种方法来改进LLMs在推理时的生成过程以克服这种障碍。

Innovation: 
我们使用激活引导来引导LLMs的响应，提供了一种轻量级替代专门微调的轻量级方法，以增强LLMs在形式定理证明中的能力，尤其是在资源受限的环境中特别有价值。这种方法为改善LLMs在推理时的生成过程提供了一种有前途的解决方案。

Conclusion: 
我们的研究表明，激活引导为增强LLMs的形式定理证明能力提供了一种有前景的轻量级替代方案，特别是在资源受限的环境中特别有价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.15507</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>59. cs.AI-在3D LMM中探索无编码器架构的潜力</title><link>https://arxiv.org/pdf/2502.09620</link><description>Background: 
在2D视觉领域，无编码器架构已有所探索，但在3D理解场景中的应用仍是一个开放性问题。当前，基于编码器的3D大型多模态模型（LMMs）面临两个主要挑战：一是适应点云不同分辨率的能力不强；二是编码器提取的点特征不能满足大型语言模型（LLMs）的语义需求。本文首次全面探讨了无编码器架构在3D LMMs中的应用潜力，通过提出LLM嵌入语义编码策略和层次几何聚合策略来解决上述问题，并成功构建了首个无编码器的3D LMM（ENEL）模型，该模型在分类、标注和VQA任务上的性能超越了当前最先进的模型ShapeLLM-13B的一部分指标，展示了无编码器架构在3D理解领域替代基于编码器架构的可能性。

Innovation: 
1. 提出了预训练阶段的LLM嵌入语义编码策略，探索点云自监督损失的影响，并引入了混合语义损失来提取高层语义；n2. 引入了指令调优阶段的层次几何聚合策略，通过注入归纳偏置提升点云局部细节的关注度；n3. 成功构建了第一个无编码器的3D LMM（ENEL），与当前最先进的模型ShapeLLM-13B相比，分类、标注和VQA任务上的性能表现更优，证实了无编码器架构在3D理解中的高潜力。

Conclusion: 
无编码器架构在3D理解场景中具有高度潜力，有望取代基于编码器的架构，ENEL模型在分类、标注和VQA任务上的优秀表现验证了这一观点。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.09620</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>60. cs.AI-通过欺骗攻击破坏语言模型的诚实和无害性</title><link>https://arxiv.org/pdf/2502.08301</link><description>Background: 
近年来关于大型语言模型（LLMs）的研究已经展示了它们理解并运用欺骗行为的能力，即使没有明确的提示也是如此。但是，这种行为只在少数特殊案例中被观察到，并未显示出对用户构成真正的风险。此外，关于AI对齐的研究也取得了显著进展，旨在训练模型拒绝生成误导性或有害的内容，使得LLMs通常变得真诚且无害。在此研究中，我们引入了‘欺骗攻击’，揭示了这种双重特性的脆弱性，如果被利用，可能会带来严重的现实后果。我们还介绍了让模型在特定主题上欺骗用户而在其他主题上保持准确的微调方法。通过一系列实验，我们展示了在这种高风险领域中的定向欺骗是有效的。此外，我们发现欺骗性微调往往破坏了其他安全特性的有效性，欺骗性的模型更可能产生有害内容，包括仇恨言论和刻板印象。最后，我们评估了这些模型是否能够在多轮对话中持续欺骗，结果是复杂的。鉴于成百万用户与基于大语言模型的聊天机器人、语音助手、代理或其他不可确保诚信的接口互动，防御这些模型免受欺骗攻击是至关重要的。

Innovation: 
我们引入了‘欺骗攻击’，使得模型在特定主题上欺骗用户而保持在其他主题上的准确性。我们还发现，欺骗性微调倾向于破坏其他安全属性，欺骗性模型更有可能生成有害内容，包括仇恨言论和刻板印象。最后，我们评估了模型是否能在多轮对话中持续欺骗，得到复杂的结果。

Conclusion: 
鉴于成百万用户与基于大语言模型的交互界面互动，在这些界面中不能保证信任度，我们的研究强调了必须使这些模型免受欺骗攻击的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.08301</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>61. cs.AI-大型语言模型引导的自我调试代码生成</title><link>https://arxiv.org/pdf/2502.02928</link><description>Background: 
自动化代码生成在智能计算机编程和系统部署中变得越来越重要。然而，现有的方法往往在计算效率方面存在挑战，并缺乏稳健的代码解析和错误修正机制。

Innovation: 
本文提出了一种名为PyCapsule的新型框架，它具备简单而有效的双代理流水线和高效的自我调试模块，特别适用于Python代码生成。PyCapsule的特点包括精细的指令推断、迭代的错误处理和用例测试，从而确保生成过程的高度稳定、安全和正确性。

Conclusion: 
通过实验，PyCapsule在HumanEval上的成功率提高了5.7%，在HumanEval-ET上的成功率提高了10.3%，在BigCodeBench上的成功率提高了24.4%，超过了最先进的方法。此外，我们还观察到，在更多的自我调试尝试中，标准化成功率有所下降，这可能是由于保留中的错误反馈有限且噪声较大的影响。PyCapsule展示了在促进轻量级和高效代码生成的广泛影响。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.02928</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>62. cs.AI-ASCenD-BDS：可适应、随机性和情境感知的偏见、歧视和刻板印象检测框架</title><link>https://arxiv.org/pdf/2502.02072</link><description>Background: 
大规模语言模型（LLMs）的迅速发展改变了自然语言处理，但同时也带来了关于在其多样化的语言和社会文化背景下部署和使用中固有的偏见的严重担忧。现有的偏见检测框架主要依赖于使用数据集生成检测偏见、歧视和刻板印象的情景，这虽然提供了点解决方案，但也造成了有限的情景评估问题。

Innovation: 
提出了一个名为ASCenD BDS（可适应、随机性和情境感知的框架）的AGILE方法，该方法通过采用自适应、随机性和情境意识等特征，能够克服依赖数据集的限制，为各种偏见检测提供更广泛的情景评估能力。具体创新点包括从印度2011年人口普查内容中建立场景的共同分类性，开发了一个使用类别、子类别、STEM、X因素、同义词，以实现自适应性、随机性和情境意识的框架。该框架在圣狐咨询有限公司及其实验室产品开发测试中进行了实际应用和测试。

Conclusion: 
该AGILE框架通过自适应、随机性和情境意识等特性，克服了依赖数据集的限制，提供了更广泛的情景评估能力。具体应用还展示了在印度语境中情境感知能力的成功建立，对不同的文化、亚文化和社会经济背景中的偏见检测具有更好的适应性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.02072</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>63. cs.AI-LoRA-One: One-Step Full Gradient Could Suffice for Fine-Tuning Large Language Models, Provably and Efficiently</title><link>https://arxiv.org/pdf/2502.01235</link><description>Background: 
本文探讨了理论如何指导并增强实际算法的应用，以Low-Rank Adaptation (LoRA, Hu等人, 2022)在大型语言模型中的应用为例进行研究。研究表明，在梯度下降过程中，LoRA适配器与单步全面微调梯度的具体奇异子空间对齐。这表明，通过使用单步全梯度对适配器进行适当的初始化，可以立即实现子空间对齐，且适用于线性和非线性模型。

Innovation: 
基于上述理论，本文提出了一种理论驱动的算法——LoRA-One，该算法具有线性收敛（以及泛化）性能，并且理论证明预条件有助于缓解病态问题的影响。此外，该理论还揭示了LoRA-One与其他基线算法之间的联系，有助于澄清此类算法设计中的误解。LoRA-One在自然语言理解、数学推理和代码生成基准测试中实现了显著的经验改进。

Conclusion: 
LoRA-One算法通过理论上的证明和有效的实现，展现了单步全梯度在大型语言模型微调中的充分作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.01235</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>64. cs.AI-具有组织层分割意识的生成增强网络（GRN）在3D超声图像慢性腰痛（cLBP）评估中的应用</title><link>https://arxiv.org/pdf/2501.17690</link><description>Background: 
该研究旨在开发一种新颖的分割感知联合训练框架，以优化图像生成和分割性能。背景中提到，在慢性低背痛（cLBP）的评估中，3D超声图像的分析至关重要，但其复杂性导致了高度依赖手动标注数据的问题。当前方法几乎依赖完全标注的数据集进行训练，造成较大的标签标注成本。另外，研究指出现有方法在低标注数据条件下的性能优化存在挑战。

Innovation: 
研究提出了名为生成增强网络（GRN）的新颖框架，结合分割损失反馈，同时优化图像生成和分割性能。此外，研究还开发了图像增强技术——分割引导增强（SGE），使生成器专门针对分割模型生成图像。GRN还提出了两种变体：为了样本高效学习的GRN-SEL和用于半监督学习的GRN-SSL。研究进一步实验验证了GRN在3D超声图像分割中的有效性，结果表明GRN-SEL在使用SGE的情况下能够在减少标签标注工作量高达70%的同时，提高Dice相似度系数（DSC）1.98%，在仅使用GRN-SEL的情况下则减少60%，GRN-SSL与SGE结合则能够同时减少70%的标签需求，即使与仅使用GRN-SSL相比，也能保持与完全监督模型相当的性能。

Conclusion: 
研究证明，GRN框架能在显著减少标注数据的同时优化分割性能，提供了一种适用于超声图像分析的可扩展且高效的解决方案，显著减少了与数据注释相关的负担。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.17690</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>65. cs.AI-AnyEnhance：一种具有提示引导与自我批评机制的统一生成模型用于语音增强</title><link>https://arxiv.org/pdf/2501.15417</link><description>Background: 
当前语音增强技术需要分别针对语音和演唱声音进行处理，并需要通过微调以同时处理多种增强任务。本文介绍了一种名为AnyEnhance的统一生成模型，该模型能够同时处理语音和演唱声音，并支持多种增强任务，无需微调。此外，该模型引入了一种提示引导机制和自我批评机制，以提升增强性能和输出质量。

Innovation: 
1. AnyEnhance是一种统一生成模型，能够同时处理语音和演唱声音，支持多种增强任务。n2. 引入了提示引导机制，使模型能够接受参考音者的音色。n3. 引入了自我批评机制，通过迭代评估和改进来生成更高质量的输出。

Conclusion: 
在多种增强任务上的实验表明，AnyEnhance在客观指标和主观听音测试中均优于现有方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.15417</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>66. cs.AI-SEAL: 扩大规模以强调长上下文检索中的注意力</title><link>https://arxiv.org/pdf/2501.15225</link><description>Background: 
尽管许多先进的LLM被设计为处理长序列数据，但即使在序列限制内，我们仍然可以观察到显著的质量下降。研究表明，特定的注意力头与长上下文检索密切相关，其与检索得分表现出正相关或负相关，通过调整这些头部的强度可以大幅提高LLM在长上下文中的质量。基于这一观察，提出了利用生成数据来强调这些头部的机制，即SEAL方法。通过应用SEAL，我们取得了在各种任务和模型中的显著改进。此外，当与现有训练无损上下文扩展技术结合使用时，SEAL能够扩大LLM的上下文限制，同时保持高度可靠的输出。

Innovation: 
SEAL方法通过学习机制增强了大型语言模型在长上下文检索中的表现，特别强调了与检索性能相关的注意力头部。该方法通过生成数据来优化这些头部的影响力，从而显著提升了LLM在长上下文中的性能。此外，SEAL还结合了现有技术来扩大LLM的上下文处理能力，同时保证输出的可靠性。

Conclusion: 
通过引入SEAL方法，我们显著提升了LLM在长上下文检索中的表现。结合现有的上下文扩展技术，使得LLM的上下文处理能力得以扩展，同时保持了输出的可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.15225</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>67. cs.AI-CAD-GPT：带有空间推理增强的多模态大语言模型的CAD构建序列合成</title><link>https://arxiv.org/pdf/2412.19663</link><description>Background: 
计算机辅助设计（CAD）通过精确的2D和3D建模、全面的分析和优化显著提高了设计过程的效率、准确性和创新性。现有的CAD模型创建方法依赖于潜在向量或点云，获取困难且存储成本高。尽管最近的多模态大型语言模型（MLLM）的发展激发了研究人员使用自然语言指令和图像来构建CAD模型，但由于难以准确推断3D空间位置和方向，导致构建几何体时3D空间起点和拔模方向的准确性不高。这项工作提出了一种CAD-GPT方法，这是一种带有空间推理增强的MLLM的CAD合成方法，可接受单张图像或文本描述作为输入。为了实现精确的空间推断，该方法引入了一种3D建模空间机制，通过专门的空间展开机制将3D空间位置和3D绘图平面旋转角度映射到1D语言特征空间，并将2D绘图坐标离散化为适当的空间平面，以便精确确定空间起始位置、绘图方向和2D绘图坐标平移。实验结果表明，CAD-GPT在CAD模型合成中始终优于现有最先进的方法，无论是定量还是定性。

Innovation: 
提出了一种称为CAD-GPT的方法，使用空间推理增强的多模态大语言模型来处理单张图像或文本描述，通过引入3D建模空间机制，将3D空间位置和3D绘图平面旋转角度映射到1D语言特征空间，并将2D绘图坐标离散化，从而实现了精确的空间推断和几何体的准确构建。该方法显著提高了CAD模型合成的精确性和可靠性，特别是在精确确定3D空间起点和拔模方向方面表现出色。

Conclusion: 
CAD-GPT在CAD模型合成中始终优于现有最先进的方法，无论是定量还是定性。该方法通过引入空间推理增强机制，显著提高了CAD模型精度，为计算机辅助设计领域带来了一种新颖的多模态语言处理方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.19663</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>68. cs.AI-输入顺序偏差对大型语言模型在软件故障定位中的影响</title><link>https://arxiv.org/pdf/2412.18750</link><description>Background: 
大型语言模型（LLMs）在软件工程任务，如故障定位（FL）和自动程序修复（APR）方面表现出显著潜力。这项研究探讨了输入顺序和上下文大小对LLMs在FL中的性能影响。FL是许多下游软件工程任务的关键步骤。研究通过使用基线测试中的Java和Python项目来评估不同方法排列，并使用肯德尔Tau距离进行评估。研究发现输入顺序对性能有显著影响，尤其是在Java项目中，顺序反转导致Top-1故障定位准确率从57%降至20%，而Python项目中则从38%降至约3%。但是，将输入进行分段处理以管理上下文可以减轻这种偏差，这可以降低在不同标记中的性能差距。研究通过替换方法名称来确定偏差是否由数据泄漏导致，结果表明偏差不是由于训练数据的记忆效应，而是由输入顺序的内在影响引起。此外，研究还探索了基于传统FL技术和度量的排序方法，发现DepGraph的方法在Top-1准确率上达到了48%，优于更简单的CallGraph(DFS)。这些发现强调了结构输入、有效管理上下文和选择合适的排序策略对于提升FL和其他软件工程应用中LLMs性能的重要性。

Innovation: 
这项研究创新性地探索了输入顺序对大型语言模型在故障定位中的影响，通过不同方法的排列和输入分段，发现输入顺序对性能的影响，并通过替换方法名称来排除数据泄漏的影响因素。此外，研究还创新性地使用DepGraph方法在Top-1准确率上取得较好的性能，优于更简单的传统方法。这为优化LLMs在软件工程任务中的应用提供了新的思路。

Conclusion: 
输入顺序对大型语言模型在故障定位中的性能有重要影响，输入分段处理可以减轻这种偏差，而基于传统FL技术的排序方法如DepGraph可以有效提升性能。这表明在实际应用中，需要有效地结构化输入、管理上下文并选择合适的排序策略，以增强LLMs在软件工程任务中的表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.18750</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>69. cs.AI-GeAR: Graph-enhanced Agent for Retrieval-augmented Generation</title><link>https://arxiv.org/pdf/2412.18431</link><description>Background: 
检索增强生成 (RAG) 依赖于有效的检索能力，但传统的稀疏和密集检索器在多跳检索场景中存在固有的局限性。

Innovation: 
GeAR 系统通过两项关键创新来提升 RAG 的性能：（i）一种有效的图扩展机制，可以增强任何传统的基础检索器，如 BM25；（ii）一种代理框架，将基于图的检索融入到多步检索框架中。

Conclusion: 
我们的评估表明，GeAR 在三个多跳问答数据集上的检索能力优于竞品。特别是在具有挑战性的 MuSiQue 数据集上，GeAR 达到了最先进的成果，优于现有系统的 token 消耗和迭代次数更少。项目页面可访问：this https URL.</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.18431</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>70. cs.AI-通过图异常分析重新思考癌症基因识别</title><link>https://arxiv.org/pdf/2412.17240</link><description>Background: 
近年来，图神经网络（GNNs）在利用蛋白质-蛋白质相互作用（PPI）网络识别癌症基因方面显示出潜力。然而，由于PPI网络中生物信息建模的不足，对于癌基因在图结构中复杂蛋白质相互作用模式的更忠实描绘仍然未被充分探索。研究发现癌基因在图结构中的唯一图异常，即权重异质性，表现为癌基因节点的边权重显著更高。从谱角度来看，权重异质性会导致谱能量“平坦化”，能量集中在频谱的极端位置。

Innovation: 
研究提出了一种新的基于层次视角的图神经网络（HIPGNN），它不仅从谱的角度检测谱能量分布的变化，还从空间角度感知蛋白质相互作用的详细上下文。

Conclusion: 
在两个重新处理的数据集STRINGdb和CPDB上的广泛实验结果证明了HIPGNN的优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.17240</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>71. cs.AI-SurgSora: 对象感知扩散模型在可控手术视频生成中的应用</title><link>https://arxiv.org/pdf/2412.14018</link><description>Background: 
现有的手术视频生成方法在精细运动控制和真实性方面存在不足。SurgSora框架旨在通过单张输入帧和用户指定的运动线索生成高质量、可调控的手术视频，解决这些问题。

Innovation: 
SurgSora采用自预测对象特征和深度信息来改进RGB外观和光流，实现精确的视频合成。它包含三个关键模块：1）双语义注入器，用于提取特定对象的RGB-D特征和分割线索以增强空间表示；2）解耦光流映射器，将多尺度光流与语义特征结合以实现真实的运动动态；3）轨迹控制器，估计稀疏光流并允许用户引导对象运动。这些功能结合稳定的视频扩散块，在视觉真实性与可控性方面达到了最先进的技术水准，通过广泛的数据比较得以验证。

Conclusion: 
SurgSora生成的视频具有高度的逼真度，得到了专家外科医生的人类评估支持，表明该方法在手术培训和教育方面的巨大潜力。项目相关信息可在https://github.com/surgsora访问。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.14018</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>72. cs.AI-DSGram：大型语言模型时代的汉语语法错误纠正动态权重子指标</title><link>https://arxiv.org/pdf/2412.12832</link><description>Background: 
使用大型语言模型（LLM）的语法规则纠正（GEC）系统往往会产生与标准参考纠正有所偏差的修正，传统基于参考的评估指标因此失去了可靠性，导致评估变得更具挑战性。

Innovation: 
提出了一种新的评价框架DSGram，该框架基于语义连贯性、编辑层面和流畅度三个维度，并结合动态权重机制。利用层次分析过程（AHP）和大规模语言模型来确定不同评估标准的相对重要性。同时，开发了一个结合人工注释和大型语言模型模拟句子的数据集，用于验证算法并调优更具成本效益的模型。

Conclusion: 
实验结果表明，该提出的评估方法增强了语法规则纠正模型的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.12832</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>73. cs.AI-Human Action CLIPs: Detecting AI-generated Human Motion</title><link>https://arxiv.org/pdf/2412.00526</link><description>Background: 
AI生成的视频生成正逐步跨越‘毛骨悚然谷’，产出与现实愈发难以区分的内容。为更好地防范其恶意应用，本研究旨在开发一种有效且鲁棒的技术，用于区分真实与AI生成的人体动作。该技术需要应对低级和中级方法通常难以克服的‘类型洗白’攻击，包括分辨率和压缩攻击。研究建立了一个名为DeepAction的开放源定制数据集，包含由七种文本到视频AI模型生成的人体动作视频剪辑及其对应的真 footage，该数据集可根据学术许可获取

Innovation: 
本研究提出了一种方法，能够有效地且鲁棒性地识别真实与AI生成的人体动作，并且能够抵御典型的低级和中级方法难以防范的攻击，如分辨率和压缩攻击。该方法在一个名为DeepAction的定制开放源数据集上进行了评估，其中包括由七种文本到视频AI模型生成的人体动作视频剪辑及其匹配的真实片段。

Conclusion: 
本研究开发出了一种有效且鲁棒的方法，能够区分真实和AI生成的人体动作。该方法能够在面对普通方法难以处理的攻击时保持稳健，并在一个大型开放源数据集上进行了验证，展示了其实用性和有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.00526</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>74. cs.AI-FLARE：对抗后门攻击的通用数据集净化方法</title><link>https://arxiv.org/pdf/2411.19479</link><description>Background: 
深度神经网络（DNNs）容易遭受后门攻击，攻击者通过在数据集中添加特定触发器以植入隐秘后门，从而操控模型预测。当前的先进净化方法假设后门连接（触发器与目标标签之间的联系）比良性特征更容易学习。实验证明，这种假设并不总是成立，特别是在全连接（All-to-All, A2A）和非定向（Untargeted, UT）攻击中。因此，基于输入输出空间或最终隐藏层空间来分析受污染样本和良性样本之间分离的方法效果不佳。此外，这种可分离性并非局限于单一隐藏层，而是在不同隐藏层之间变化。

Innovation: 
本文提出了一种名为FLARE的通用净化方法，旨在对抗各种后门攻击。FLARE通过从所有隐藏层聚合异常激活来构建表示以实现聚类，并发展了一种自适应子空间选择算法来选择最佳子空间，将整个数据集分为两个簇。FLARE评估每个簇的稳定性，并识别更稳定的簇为受污染的样本。实验表明，FLARE对22种代表性后门攻击方法（包括全对一（A2O）、全对全（A2A）和非定向（UT）攻击）有效，并且具有对自适应攻击的稳健性。FLARE的代码可在BackdoorBox和backdoor-toolbox中获得。

Conclusion: 
FLARE是一种通用的后门攻击防护方法，通过综合所有隐藏层的异常激活来构建表示，并选择最佳子空间进行数据集的两簇划分，提高了分离性并识别受污染数据。FLARE在多种后门攻击情境下表现出色，其代码已公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.19479</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>75. cs.AI-G3Flow: 生成的3D语义流用于姿态感知和泛化物体操作</title><link>https://arxiv.org/pdf/2411.18369</link><description>Background: 
近年来，基于扩散模型的模仿学习在3D机器人操作中取得了令人鼓舞的成果。然而，要达到人类级别的灵巧性，需要无缝地结合几何精度和语义理解。现有的研究侧重于模仿学习和基于扩散的策略，但普遍存在语义理解不完整、依赖于手动标注等问题，无法在遮挡情况下实现完全的语义理解，且难以处理跨物体的泛化问题。该研究旨在通过提出一种新的框架G3Flow，利用基础模型构建实时语义流，以解决这些挑战。

Innovation: 
G3Flow是一个新颖的框架，能够实时构建动态、物体为中心的3D语义表示，结合了3D生成模型用于数字孪生的创建、视觉基础模型用于语义特征提取以及稳健的姿态跟踪，以实现持续的语义流更新。这种集成使得在遮挡情况下也能实现完整的语义理解，且不再需要手动标注。通过将语义流整合进扩散策略中，G3Flow在终端约束操作和跨物体泛化任务上取得了显著成效，结果显示G3Flow在五个模拟任务中表现优于已有方法，终端约束操作的成功率为68.3%，跨物体泛化任务的成功率为50.1%。

Conclusion: 
G3Flow通过无缝地结合语义理解和几何精度，提供了一种有效的方法来提升实时动态语义特征理解，为机器人操控策略增添了姿态感知和泛化能力。广泛的实验结果证明了G3Flow在提升3D机器人操作中的终端约束任务和跨对象泛化性能方面的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.18369</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>76. cs.AI-通过特征解耦和对比学习实现跨摄像头分心司机分类</title><link>https://arxiv.org/pdf/2411.13181</link><description>Background: 
分心驾驶的分类对于确保驾驶安全至关重要。过去的研究表明，神经网络在自动预测分心驾驶、疲劳和潜在危险方面具有有效性。然而，最近的研究发现，当这些模型应用于与训练数据条件不同的样本时，会出现显著的准确率损失。

Innovation: 
本文提出了一种稳健的模型，能够在车辆内摄像机位置发生变化时保持良好的性能。我们的驾驶员行为监控网络（DBMNet）基于轻量级的骨干网络，并结合了一个解耦模块从特征中丢弃摄像机视角信息，以及对比学习来增强对各种驾驶行为的编码能力。实验结果表明，DBMNet在提高精度方面优于现有方法，并且在不同数据集和摄像头的实验中展示了优越的泛化能力。此外，其在Coral Dev Board上的量化版本表现出最佳性能，模型小、内存占用低、推理速度快、功耗低，从而提高了实时性和实用性。

Conclusion: 
总体而言，DBMNet 在 Top-1 准确率上比现有方法提高了 7%，并且在各类实验中展示了优秀的泛化能力和紧凑性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.13181</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>77. cs.AI-基于多级粒度音节计数控制的歌曲结构意识全文歌词生成</title><link>https://arxiv.org/pdf/2411.13100</link><description>Background: 
歌词生成面临独特的挑战，尤其是在精确控制音节数量的同时遵循歌曲结构（如副歌和副歌间段）时。传统的逐行方法通常会导致不自然的句读，表明需要更精细的音节管理。研究者需要一个框架来在单词、短语、行和段落等多个级别上实现对歌曲形式的意识音节控制，以生成符合输入文本和歌曲形式的完整歌词，同时满足指定的音节约束条件。生成的歌词可以在以下网址下载：this https URL

Innovation: 
本文提出了一种框架，能够在单词、短语、行和段落等多个层次上实现对音节的精细控制，且保持对歌曲形式的意识，从而确保生成的歌词完全符合输入文本和歌曲形式，满足具体音节数量的约束。

Conclusion: 
本文提出的方法能够在多级别粒度下控制音节计数，同时保持对歌曲形式的意识，生成符合需求的完整歌词。生成的歌词可在此链接下载：this https URL</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.13100</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>78. cs.AI-利用大语言模型生成高效耗电代码</title><link>https://arxiv.org/pdf/2411.10599</link><description>Background: 
个人电脑、通信网络和数据中心不断增加的电力需求导致大气中温室气体排放量上升，进而引起全球变暖和气候变化。因此，代码的能源消耗必须被最小化。大语言模型能够生成代码。研究探讨了提示（Prompt）修改对由大语言模型生成代码的能源消耗影响。选择了三个不同难度级别的Python代码问题来研究。提示修改的方式包括添加句子“给我一个能源优化的解决方案”或使用两种Python编程的最佳实践。所使用的大语言模型包括CodeLlama-70b、CodeLlama-70b-Instruct、CodeLlama-70b-Python、DeepSeek-Coder-33b-base和DeepSeek-Coder-33b-instruct。研究结果显示，特定组合的提示优化、大语言模型和Python代码问题下，能源消耗有所降低。然而，没有单一的优化提示能够一致地减少同一大语言模型在不同Python代码问题下的能源消耗量。

Innovation: 
研究通过不同难度级别的Python代码问题和多种提示修改方式，考察大语言模型生成代码时的能源消耗。实验对比了多种大语言模型在代码优化方面的表现，探索了提示优化的有效性。这为降低代码生成过程中的能源消耗提供了一定的理论依据和实践指导。

Conclusion: 
特定条件下的提示优化能够减少大语言模型生成代码的能源消耗。但是，没有单一的优化提示能够普遍适用于不同代码问题并一致地降低能源消耗。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.10599</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>79. cs.AI-DeepMedcast：生成多个NWP模型中间天气预报的深度学习方法</title><link>https://arxiv.org/pdf/2411.10010</link><description>Background: 
全球的数值天气预报（NWP）中心运行着多种NWP模型。近年来，基于AI的NWP模型的进步进一步增加了NWP输出的可用性。尽管这种扩展有可能提高预测准确性，但它提出了一个关键问题：哪个预测是最可信的？如果NWP模型的精度相当，提前判断哪个是最好的是不可能的。传统的集合或加权平均方法将多个NWP输出组合成一个具有更好准确性的单一预报，但往往会导致气象不现实和不可解释的输出，如热带气旋中心或锋面边界被分裂成多个独立系统。

Innovation: 
我们提出了DeepMedcast，这是一种深度学习方法，用于在两个或多个NWP输出之间生成中间预报。与平均法不同，DeepMedcast产生的预测在气象学上重要的特征，如热带气旋、极涡气旋、锋面和切变线的位置大约与输入NWP模型预测的相应特征的算术平均值相匹配，而不会扭曲气象结构。我们在案例研究和验证结果中展示了DeepMedcast的能力，证明它能够生成比输入NWP模型更准确且更现实、更可解释的预报。通过提供可信的中间预报，DeepMedcast可以显著提高操作性预报任务的效率和标准化，包括通用、海上和航空预报任务。

Conclusion: 
通过提供可信的中间预报，DeepMedcast能够显著提高操作性预报任务的效率和标准化，包括通用、海上和航空预报任务。DeepMedcast能够生成比输入NWP模型更准确且更现实、更可解释的预报。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.10010</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>80. cs.AI-视频生成与世界模型的差距：从物理定律的角度看</title><link>https://arxiv.org/pdf/2411.02385</link><description>Background: 
OpenAI的Sora展示了视频生成技术在开发能够遵循基本物理定律的世界模型方面的潜力，但视频生成模型仅凭视觉数据发现此类定律的能力值得质疑。真实的世界模型应该能够对细微差别进行稳健预测，并在未见情景中正确外推。本文评估了三种关键场景：数据内、数据外和组合泛化，并开发了一个2D模拟测试平台来生成由一个或多个经典力学定律控制的视频，以进行大规模实验和定量评估。

Innovation: 
研究开发了一个2D模拟测试平台来生成受经典力学定律控制的视频，用于训练基于扩散的视频生成模型预测物体运动，并展示了缩放实验结果：在数据内场景中表现出完美的泛化，在组合泛化中表现出可测量的缩放行为，但在数据外场景中失败。研究表明，仅靠规模放大对于视频生成模型发现基本物理定律是不够的，模型主要表现出基于案例的泛化行为并优先参考训练数据中的颜色、大小、速度和形状。

Conclusion: 
本研究建议，仅靠缩放不足以使视频生成模型揭示基本物理定律，尽管这对Sora的更广泛成功起到了作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.02385</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>81. cs.AI-One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion Models</title><link>https://arxiv.org/pdf/2410.22366</link><description>Background: 
对于大型语言模型（LLMs），稀疏自编码器（SAEs）已经展示了将中间表示分解为可以解释的特征的稀疏线性组合，这些中间表示通常不可直接解释，这有助于更好地控制和随后的分析。然而，类似的分析和方法尚未应用于文本生成图像模型。本文研究了使用SAEs学习SDXL Turbo（一种基于扩散的 few-step 文本生成图像模型）的可解释特征的可能性。为了实现这一目标，我们在 SDXL Turbo 的去噪 U-net 中，训练了 SAEs 来处理转换器块在单步设置中执行的更新。

Innovation: 
我们首次研究了稀疏自编码器（SAEs）在文本生成图像扩散模型中的应用。发现经过在单步情况下训练的 SAEs 在 4 步 SDXL Turbo 及甚至多步骤 SDXL 基本模型（不同模型）上具有泛化能力，而无需额外训练。此外，我们展示了这些学习到的特征是可解释的，因干预从而影响图像生成过程，并揭示了转换器块的特化。我们在 RIEBench 中创建了一个基于表示的图像编辑基准，用于在生成图像的过程中单独开启和关闭 SAE 特征来编辑图像，借此跟踪不同编辑类别下具有最高影响性的转换器块的特征。这些模型是理解并操控文本生成图像模型内部机制的有前景的方法。

Conclusion: 
本文的研究结果确立了稀疏自编码器（SAEs）作为理解并操控文本生成图像模型内部机制的有效方法，证明了其在增强生成模型理解性方面的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.22366</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>82. cs.AI-蜂巢之心等同于单一强化学习代理</title><link>https://arxiv.org/pdf/2410.17517</link><description>Background: 
决策是任何智能化代理或群体的关键属性。自然界中的系统通过两种机制至少之一来达到最优策略：模仿他人的集体决策机制和个人的试错机制。本文通过引用蜂群选择巢穴位置的集体决策模型，来建立这两种机制之间的等效性。研究表明，个体蜜蜂遵循简单的地方模仿规则所产生的分布式认知（有时称为蜂巢心智）等效于一个单一的在线强化学习代理与许多并行环境交互的过程。宏观代理的学习规则是通过一种我们称为梅纳德-克罗斯学习的多臂老虎机算法实现的。本文的分析表明，认知能力有限的群体可以与更为复杂的强化学习实体相匹敌，支持了群体智能可以在自然选择中解释看似简单和无意识的个别行为的观点。

Innovation: 
提出了一种新的学习机制—梅纳德-克罗斯学习（Maynard-Cross Learning），该机制等效于单个在线强化学习（RL）代理与许多并行环境交互的过程。这将集体决策模型与强化学习模型联系起来。研究证实，认知能力有限的群体可以与更复杂的强化学习实体相匹敌，且群体智能可以解释看似简单和盲目的个体行为为何被自然选择所青睐。

Conclusion: 
认知能力有限的群体能够通过简单的规则和集体决策机制达到与复杂强化学习实体相同的性能水平，表明群体智能可能是自然选择中看似简单与盲目的个体行为得以选择的原因。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.17517</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>83. cs.AI-如何影响LLMs的算术推理能力</title><link>https://arxiv.org/pdf/2410.13857</link><description>Background: 
尽管基于Transformer的大语言模型（LLMs）在各个领域取得了显著的成功，但理解和增强它们的数学能力仍然是一个重大挑战。本研究对LLMs的数学能力进行了严格的理论分析，特别关注它们的算术性能。结果显示，低数值精度下的Transformer无法有效解决诸如迭代加法和整数乘法等算术任务，除非随着输入长度的增加，模型的大小呈超多项式增长。相比之下，标准数值精度下的Transformer可以使用明显更小的模型大小高效地处理这些任务。

Innovation: 
研究对LLMs的算术能力进行了严格的理论分析，确定了数值精度是影响算术任务有效性的重要因素。此外，通过实验证明了提高数值精度可以显著提升LLMs的算术推理能力，提供了改进LLMs数学推理能力的有价值见解。

Conclusion: 
低数值精度下的Transformer无法有效解决算术任务，除非模型大小随着输入长度呈超多项式增长。相比之下，标准数值精度的Transformer可以使用较小的模型大小高效地处理这些任务。这些发现为理解并提升LLMs的数学推理能力提供了理论和实验证据。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.13857</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>84. cs.AI-FutureFill：基于卷积操作的快速序列生成方法</title><link>https://arxiv.org/pdf/2410.03766</link><description>Background: 
目前在序列预测模型中，自回归生成算法面临效率问题。这些算法的生成时间通常是上下文长度的二次方，导致生成速度较慢。同时，标准的卷积或基于注意力的模型在生成时需要较大的缓存，这些缓存的大小往往与其上下文长度成比例，进一步加剧了效率问题。

Innovation: 
提出了FutureFill，这是一种基于卷积操作的一般快速生成方法，适用于任何序列预测算法。FutureFill将生成时间从二次降到准线性，且在从提示生成时，需要的预填充缓存的大小仅与要生成的令牌数量成比例增长，通常远小于标准的卷积或注意力模型所需的缓存大小。

Conclusion: 
通过实验验证了FutureFill的有效性，并在深度卷积序列预测模型中展示了显著的效率提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.03766</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>85. cs.AI-利用模型引导从个性化扩散模型中提取训练数据</title><link>https://arxiv.org/pdf/2410.03039</link><description>Background: 
扩散模型(DMs)已成为强大的图像生成工具，特别适用于少量图像的微调，通过上传这些微调后的模型，用户可以在Civitai和HuggingFace等平台上构建社区。虽然这两种模式都很有用，但也存在数据泄露和版权侵权的问题。因此，研究从公开的微调DMs中提取训练数据是否可能变得至关重要，此举不仅可以揭示数据泄露的真实风险，还可以提供版权侵权的直接证据。

Innovation: 
提出了FineXtract框架，该框架将微调视为模型学习分布的逐步转变——从原始预训练DM向微调数据的转变。通过在微调前后对模型进行外推，指导生成过程向微调数据分布中的高概率区域发展。然后，使用聚类算法从使用这种外推指导生成的所有图像中提取最可能的图像。这种方法在使用WikiArt、DreamBooth等数据集微调的DMs中得到了验证，通常能够提取出约20%的微调数据。

Conclusion: 
实验结果证明了FineXtract框架的有效性，能够在大多数情况下提取出大约20%的微调数据。相关代码可以在[这里](此链接)获取。这为从公开的微调DMs中有效提取训练数据提供了一种新的方法，有助于揭示数据泄露和版权侵权等问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.03039</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>86. cs.AI-基于机器学习的高带宽磁传感</title><link>https://arxiv.org/pdf/2409.12820</link><description>Background: 
近年来，量子技术得到了显著的发展，尤其是量子传感领域。在这些平台中，钻石中的氮-空位（NV）色心表现出色，因为它提供了一种高灵敏度且高空间分辨率的磁场传感方法。然而，目前NV量子传感中的自旋共振磁传感方案在带宽、动态范围和灵敏度之间存在权衡问题。

Innovation: 
本文通过引入机器学习工具来解决这一问题，特别关注在大动态范围情况下的灵敏度/带宽权衡。结果表明，与现有方法相比，机器学习方法能够减少至少30%的数据点，同时保持当前的误差水平。这一研究结果强调了量子机器学习协议在传感应用中的潜力，旨在促进更实用和高效的量子技术。

Conclusion: 
研究结果显示，通过机器学习技术的辅助，可以实现高带宽磁传感，同时减少数据点数量，保持现有的误差水平，为量子传感技术的发展提供了新的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.12820</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>87. cs.AI-MOST: MR重建优化以应对多个下游任务的连续学习</title><link>https://arxiv.org/pdf/2409.10394</link><description>Background: 
基于深度学习的磁共振（MR）重建方法主要关注生成高质量的图像，但往往忽略了重建图像对下游任务（如分割）的影响。通过分别训练重建网络和下游任务网络，并进行级联，可能会引入由于误差传播和训练数据集领域差距而导致的性能下降。已提出特定于下游任务的重建优化方法以解决单一下游任务的问题。在此工作中，作者扩展了优化方法以处理通过连续学习逐步引入的多个下游任务。

Innovation: 
提出了一种综合基于重演的连续学习技术和图像引导损失的方法，以解决灾难性遗忘的问题。该方法相较于未微调的重建网络、简单微调的重建网络以及传统的连续学习方法，表现出更好的性能。

Conclusion: 
实验结果表明，该方法在对多个下游任务进行MR重建优化时优于未微调的重建网络、简单微调的重建网络和传统的连续学习方法，源代码可在指定链接中获取。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.10394</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>88. cs.AI-几何扩散与能量最小化融合：一种统一的神经消息传递框架</title><link>https://arxiv.org/pdf/2409.09111</link><description>Background: 
如何学习具有特定几何结构（已观察或未观察）的结构化数据的表现形式是一种基本挑战。在这一领域，基于消息传递的神经网络（MPNNs）已经成为了事实上的模型解决方案。本文针对基于消息传递的神经网络（MPNNs）进行阐述，并提供了一种新的框架来理解这些模型的工作机制和设计原则。

Innovation: 
文章提出了一种能量约束扩散模型（energy-constrained diffusion model）作为理解和设计MPNNs的规范数学框架。通过物理系统的启发，该模型结合了在流形上的扩散归纳偏见和层级的能量最小化约束，并从能量约束的扩散系统中推导出不同的消息传递层结构，从而为MLP, GCN, GIN, APPNP, GCNII, GAT, 和变换器等常见神经架构提供了一种统一视角。基于此，新设计了一类基于能量约束扩散框架的消息传递模型，称之为扩散启发式变换器（diffusion-inspired Transformers），该模型在全局注意力层中引入了从规范能量约束扩散框架中得出的方法。在一个具有广泛代表性的数据集上，证明了这种新模型在数据结构观察、部分观察或完全未观察的情况下均具有良好的表现。

Conclusion: 
本文工作提供了一种新的能量约束扩散机制框架，用以理解和设计MPNNs，并通过实验结果展示了其在不同数据类型上的优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.09111</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>89. cs.AI-大型语言模型在疾病诊断中的应用：一项范围性回顾</title><link>https://arxiv.org/pdf/2409.00097</link><description>Background: 
自动疾病诊断在临床实践中变得越来越有价值。大型语言模型（LLMs）的出现推动了人工智能范式的转变，越来越多的证据支持LLMs在诊断任务中的有效性。尽管该领域越来越受到关注，但缺乏全面的视角，许多关键方面仍不清楚，如LLMs已应用于哪些疾病和临床数据，使用了哪些LLM技术以及采用了哪些评估方法。本文对基于LLMs的疾病诊断方法进行了全面回顾，从疾病类型和相关临床专科、临床数据、LLM技术以及评估方法等多个维度对现有文献进行了考察。我们还提供了在诊断任务中应用和评估LLMs的建议，评估了当前研究的局限性并讨论了未来方向。据我们所知，这是有关基于LLMs的疾病诊断的第一个全面回顾

Innovation: 
本文进行了一项全面的审查，涵盖了基于LLMs的疾病诊断方法，从多个维度考察了现有文献，并提供了在诊断任务中应用和评估LLMs的建议，评估了当前研究的局限性并讨论了未来方向。这是该领域的第一个全面回顾文章，填补了该领域的空白

Conclusion: 
本文通过全面审查，为基于LLMs的疾病诊断提出了应用和评估建议，指出了当前研究的局限性，并提出了未来的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.00097</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>90. cs.AI-RePST：通过语义导向重新编程实现的语言模型驱动的空间-时间预测</title><link>https://arxiv.org/pdf/2408.14505</link><description>Background: 
空间-时间预测在交通运输规划、能源管理、气候监测等实际应用中至关重要。尽管预训练语言模型（PLMs）在一些领域表现出色，但由于其主要在文本数据上进行训练，PLMs在处理复杂的数值时间序列关联时往往表现不佳。这限制了其在空间-时间数据理解中的有效性。该研究旨在通过一种语义导向的PLM重新编程框架（RePST）来解决此问题，该框架特别适用于数据稀缺的场景。

Innovation: 
RePST框架首先提出了一种语义导向的分解器，能够适应地将空间相关的时间序列分解为可解释的子组件，使PLM能够通过分而治之的方法理解复杂的空间-时间动态。此外，该框架还提出了一种选择性的离散重新编程方案，通过扩展空间-时间词汇空间来将空间-时间序列投影为离散表示。该方案在重新编程过程中最小化了信息丢失，并丰富了由PLM生成的表示。实验结果表明，在实际数据集上，所提出的RePST在数据稀缺的情况下优于十二种最先进的基线方法，突显了PLMs在空间-时间预测中的效果和更强的泛化能力。

Conclusion: 
各种实验表明，RePST在数据稀缺的情况下表现优异，显示出PLMs在空间-时间预测中的有效性和更强的泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.14505</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>91. cs.AI-Smooth InfoMax -- 向更好的后验解释性迈进</title><link>https://arxiv.org/pdf/2408.12936</link><description>Background: 
该研究介绍了Smooth InfoMax (SIM)方法，这是一种结合了可解释性约束的自我监督表示学习方法，适用于网络不同深度的潜在表示。SIM基于β-VAEs，并通过InfoNCE损失局部优化概率模块，生成向标准正态分布正则化的高斯分布表示，从而创建平滑、结构良好且更好分离的潜在空间，便于后续分析。

Innovation: 
SIM方法引入了可解释性约束，整合到网络不同深度的潜在表示中，通过优化局部概率模块生成高斯分布的表示，使其更接近标准正态分布，从而产生平滑、明确且更好分离的潜在空间，提高后验解释性方法的有效性，尤其是在各层的解释性方面超过了贪婪信息最大方法。

Conclusion: 
SIM方法在语音数据上，保留了贪婪信息最大方法的大规模训练优点，同时提高了各层后验解释性方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.12936</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>92. cs.AI-PREMAP：神经网络统一前影像逼近框架</title><link>https://arxiv.org/pdf/2408.09262</link><description>Background: 
大多数神经网络验证方法关注于边界图像，即给定输入集的输出集合。这种方法可以用来，例如，检查神经网络预测对输入有界扰动的鲁棒性。然而，验证与前影像相关的属性，即满足输出属性的输入集合的属性，则需在输入空间中使用抽象化方法。

Innovation: 
本文提出了一种通用框架，用于生成任何多面体输出集合的上界和下界逼近。该框架利用了廉价的线性神经网络参数化松弛，并通过在输入特征和神经元上进行迭代分割，结合了一种随时可调整的精炼过程。该方法的有效性依赖于精心设计的启发式策略和优化目标来实现快速改善逼近的有效性。实验展示了该方法在高输入维度图像分类任务中的高效性和可扩展性，相比现有技术具有显著优势，并应用于定量验证和鲁棒性分析，提供了一种健全且完整的算法框架，并提供了定量结果.

Conclusion: 
本文的方法在效率和可扩展性方面显著优于现有技术，并为定量验证和鲁棒性分析应用提供了新的途径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.09262</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>93. cs.AI-语言模型中的推理电路：形式推理的一种机制化解释</title><link>https://arxiv.org/pdf/2408.08590</link><description>Background: 
近年来关于语言模型（LMs）推理能力的研究引发了关于它们是否能够学习系统的推理原则还是仅仅利用训练数据中的表面模式的争论。本研究旨在理解并揭示语言模型进行形式推理的机制，特别关注于系统推理的机制解读，并通过干预方法发现涉及中间项抑制的推理电路，以解释LMs如何从前提中推导出有效结论的过程。

Innovation: 
提出了一种电路发现方法，用于解释LMs中的内容无关且形式化的推理机制。通过两种不同的干预方法，揭示了一个涉及中间项抑制的关键电路，阐明了LMs如何通过从前提中转移信息来得出有效结论。此外，还研究了信仰偏差在形式推理中的表现，发现部分受到负责编码常识和上下文知识的附加注意力头的污染。最后，研究了发现机制在不同形式推理方案、模型大小和架构中的泛化能力。

Conclusion: 
所识别的电路对于模型能够实现高准确度（&amp;gt;60%）的形式推理方案来说是充分且必要的，不同家族模型的激活模式也具有兼容性。总体而言，研究结果表明LMs能够学习可转移的内容无关的推理机制，但这些机制并不是可泛化和抽象的逻辑组件，容易受到预训练期间获得的世界知识污染。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.08590</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>94. cs.AI-UniMoT：基于离散标记表示的统一分子-文本语言模型</title><link>https://arxiv.org/pdf/2408.00863</link><description>Background: 
大型语言模型（LLMs）在多种任务上的显著成就促使研究社区将其能力拓展至分子应用。然而，当前大多数分子LLMs使用基于适配器的架构，未能平等对待分子和文本模态，并缺乏对分子模态的监督信号。为解决这些不足，引入了UniMoT，这是一个采用基于标记架构的统一分子-文本LLM，通过扩展LLM词汇表以包含分子标记，引入了向量量化驱动的标记器，以弥合分子和文本模态之间的差异。UniMoT 架构下的标记器将分子转换为具有因果依赖性的分子标记序列，从而包含高级分子和文本信息。

Innovation: 
UniMoT 利用向量量化驱动的标记器，结合 Q-Former 桥接分子和文本模态之间的差异。基于此标记器，UniMoT 可以统一分子和文本模态，采用共享标记表示和自回归训练范式，使其能够将分子视为外语进行解释，并将其转化为文本。这种方法多阶段训练策略导致UniMoT 成为一种多模态多面手，能够在分子到文本和文本到分子任务中执行任务。实验证明，UniMoT 在多种分子理解和生成任务中达到了最先进的性能。

Conclusion: 
UniMoT 在多种分子合理性和生成任务中表现出卓越的性能。通过引入基于向量量化驱动的标记器，UniMoT 用离散标记表示解决了统一分子和文本模态的问题，使其具备理解和生成分子文本的能力，在分子应用研究中具有重要价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.00863</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>95. cs.AI-自动语音识别中的数值表达处理</title><link>https://arxiv.org/pdf/2408.00004</link><description>Background: 
本文探讨了在自动语音识别（ASR）转录中正确格式化数值表达的问题。这个问题很具挑战性，因为所需的转录格式依赖于上下文，例如，1945可以表示年份也可以表示时间戳19:45。为了应对这一挑战，作者比较了级联和端到端的识别和格式化方法，这些方法针对年份、时间戳、货币金额和数量等数值表达进行处理。

Innovation: 
提出了使用大型语言模型（LLM）和文本转语音（TTS）模型生成训练数据的策略，来改进端到端模型的性能。实验结果表明，基于LLM的方法在识别格式化的数值表达方面表现良好，而经过适应的端到端模型则提供了具有较低延迟和推理成本的竞争性能优势。

Conclusion: 
实验结果显示，在处理和格式化数值表达方面，基于大型语言模型的方法表现出色。而通过适配的端到端模型则提供了性能竞争，同时降低了延迟和推理成本。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.00004</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>96. cs.AI-DART: 自动化端到端的具有数据多样化、开放词汇边界框标注、伪标签审核和模型训练的对象检测流水线</title><link>https://arxiv.org/pdf/2407.09174</link><description>Background: 
在众多工业应用中，如安全监控和质量控制中，需要实现准确的实时对象检测。传统方法因依赖耗时的手动标注和数据收集，在不断变化的环境和新目标物体面前表现不佳。

Innovation: 
本文提出了一种名为DART的自动化端到端流水线，它包括数据多样化、开放词汇边界框标注、伪标签审核和模型训练等四个关键阶段。DART消除了手工标注和大量数据收集的需求，实现了不同场景下的高精度目标检测。其模块化设计支持算法更新、新类别物体的无缝集成以及定制环境的适应性，无需手动标注和额外数据收集。

Conclusion: 
DART在名为Liebherr Product的自收集数据集中的应用，显著提高了平均准确率（AP）从0.064到0.832。DART的设计确保了模块化易于互换和扩展，为未来的算法升级、新目标类别的无缝集成和定制环境适应等提供了支持。项目的代码和数据集已发布。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.09174</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>97. cs.AI-Jagiellonian University的文化遗产项目中的富可互操作元数据</title><link>https://arxiv.org/pdf/2407.06976</link><description>Background: 
由于存放在图书馆中的对象现在创建了大量的元数据，但由于核心标准MARC 21和Dublin Core不够灵活，这些元数据无处可存。为此，查日奥隆大学(JU)的研究人员对文化遗产对象的元数据进行了研究，比较了目前在JU收集的元数据（手稿、招贴和讣告）与文化界广泛使用的五项元数据标准：Dublin Core、EAD、MODS、EDM和Digital Scriptorium，发现元数据映射存在严重问题。这促使研究团队提出要求在进一步工作中的文化遗产元数据模式设计中应遵循的具体要求以实现最大互操作性。

Innovation: 
研究团队致力于解决文化对象元数据存储问题，提出了他们工作的初步成果，即比较了多种文化和遗产元数据标准，发现这些标准存在映射难题，并提出了进一步工作的设计要求。未来基于逐渐完善的概念模型，他们将进行实验以验证这些映射的可行性及其能否实际整合这些多种元数据格式下的数据。

Conclusion: 
通过分析当前元数据模式和需求，研究团队将提出一个文化遗产元数据模式，并在此基础上进行实验，验证该模式的可行性和互操作性，以促进文化遗产项目中的数据整合。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.06976</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>98. cs.AI-连续治疗方法效应的正则预测</title><link>https://arxiv.org/pdf/2407.03094</link><description>Background: 
在安全关键应用如个性化医疗中，因果效应的不确定性量化至关重要。目前的正则预测方法主要局限于二元或离散治疗，并且需要知道倾向得分等先验信息，限制了其应用范围和有效性。因此，研究如何在未知倾向得分的情况下，使用正则预测方法来量化连续治疗方法的潜在结果不确定性是很有意义的。

Innovation: 
本文提出了一种新颖的方法用于连续治疗方法的潜在结果的正则预测。此方法能够应对倾向得分估计带来的额外不确定性，即使倾向得分未知也能保证正则预测区间的有效性。具体贡献包括：1) 推导了连续治疗方法潜在结果的有限样本预测区间；2) 提供了计算这些区间的算法；3) 在模拟和真实数据集上验证了正则预测区间的有效性。到我们所知，这是首次提出在倾向得分未知且需从数据中估计时用于连续治疗方法效应的正则预测方法。

Conclusion: 
本文提出了一种新的基于正则预测的方法，用于连续治疗方法的潜在结果，克服了已有限制性假设的局限性，提高了因果效应估计在实际应用中的可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.03094</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>99. cs.AI-超越功能正确性：探讨大语言模型中的编码风格不一致性</title><link>https://arxiv.org/pdf/2407.00456</link><description>Background: 
现有的大规模语言模型（LLMs）在代码生成方面带来了范式变革，有望提升软件开发过程。然而，以往的研究主要集中在代码生成的准确性上，而Code LLMs与人类开发者的编码风格差异尚有未被充分探索的地方。本研究通过实证分析主流Code LLMs生成的代码与人类开发者编写的代码之间的编码风格差异，并总结编码风格不一致性分类，揭示了两者在可读性、简洁性和鲁棒性等方面的编码风格存在显著差异，探讨了这些不一致性背后可能的原因，并提出了一些缓解方案。

Innovation: 
本研究通过实证方法系统地调查和总结了Code LLMs生成的代码与人类开发者编写的代码之间的编码风格差异，并提出了编码风格不一致性类别的分类体系，以及可能的缓解方案。

Conclusion: 
本研究揭示了大规模语言模型（LLMs）和人类开发者在编码风格上的显著差异，概述了潜在的原因，并提供了可能的解决方案来缓解这些问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.00456</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>100. cs.AI-全球食谱：一种以社区为中心的数据收集框架及其区域偏差操作化</title><link>https://arxiv.org/pdf/2406.09496</link><description>Background: 
本文介绍了全球食谱框架，旨在通过文化意识和参与式数据收集来收集多样化的数据集，涵盖了不同地区的菜肴。研究中也分析了偏差操作化，揭露了当前模型在准确性、代表性以及文化敏感性方面的不足，通过社区质性观察和自动工具的定量分析来支持这些发现。研究发现，即使是对资源丰富如美国的地区，生成结果也普遍不佳，展示出模型产生不准确、文化错误表达、简化和不敏感的输出的倾向，这些偏差可能会进一步固化刻板印象并导致区域化的抹除。提供的数据集和代码可在该网页上找到：this https URL.

Innovation: 
本文提出了全球食谱框架，通过文化意识和社区中心的方法进行细致数据收集，并具体分析了区域偏差的操作化。这种方法适用于全球范围内的文化敏感数据收集，并通过具体的偏差分析揭示了现有模型的不足，为改进此类系统的质量提供了新的视角和方法。

Conclusion: 
本文研究发现，当前的模型难以生成特定于各个地区的高质量菜肴图像，表明当前模型存在不准确性、文化错误表达和不敏感的问题。这些偏差可能会进一步固化刻板印象，并促进基于地区的抹除。已创建的数据集和代码供进一步研究使用，以改善此类系统的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.09496</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>101. cs.AI-对不同任务和模型规模稳健学习的对称强化学习损失</title><link>https://arxiv.org/pdf/2405.17618</link><description>Background: 
由于目标移动和高梯度方差等因素，强化学习（RL）训练本质上是不稳定的。人类反馈的强化学习（RLHF）和AI反馈的强化学习（RLAIF）可能会引入新的困难。不同的偏好会复杂化对齐过程，训练中的奖励模型的预测错误会因LLM生成未见过的输出而变得更加严重。为增强训练的稳定性，RL已采用来自监督学习的技术，如集成和层归一化。本文在此基础上，通过将监督学习中的逆交叉熵（RCE）方法应用于噪声数据，定义对称RL损失以进一步提高训练的稳定性。我们使用对称A2C（SA2C）和对称PPO（SPPO）分别在离散动作任务（Atari游戏）和连续动作空间任务（MuJoCo基准和Box2D）中进行了实验，结果表明在不同超参数设置下，特别是在SPPO中，我们可以看到显著的性能提升。此外，通过提高基于SPPO的对齐语言模型的性能，该对称损失在RLHF任务中（例如IMDB正面情感分析和TL;DR总结任务）也得到了验证。

Innovation: 
本文提出了一种改进的对称RL损失方法，通过使用监督学习中的逆交叉熵（RCE）方法来处理噪声数据，以此提高强化学习训练的稳定性。实验结果表明，该方法在离散动作和连续动作空间任务中都能显著提高性能，在不同超参数配置下，尤其是在使用对称PPO时效果更为明显。此外，这种方法还验证了其在对齐语言模型中的应用价值，特别是在IMDB正面情感分析和TL;DR总结任务中表现出显著优势。

Conclusion: 
本文通过提出对称RL损失，该损失借鉴了监督学习中的逆交叉熵方法，应用于处理噪声数据，从而提高了强化学习的训练稳定性。实验验证了该方法在多种任务和不同规模模型中的有效性和实用性，并能够特别在使用对称PPO时，在多种超参数配置下取得显著的性能提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.17618</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>102. cs.AI-基于强化学习的关键传播图生成器在社交媒体上的谣言检测</title><link>https://arxiv.org/pdf/2405.13094</link><description>Background: 
社交媒体上的谣言传播，尤其是在重大事件期间，如美国选举和COVID-19大流行期间，对社会稳定和公共卫生构成了严重威胁。现有的谣言检测方法主要依赖传播图来提高模型性能，但这些方法的有效性常因传播过程中的噪音和无关结构而受限。目前提出的技术，如权重调整和数据增强，依赖丰富的原始传播结构，而在谣言传播信息不足，尤其是在传播早期阶段，这些技术的有效性受到了限制。

Innovation: 
本文提出了一种新的基于强化学习的关键传播图生成器(KPG)，该生成器能够为缺乏拓扑信息的事件生成上下文连贯且信息丰富的传播模式，并能识别冗余和噪声传播结构中的重要子结构。KPG包括两个关键组件：候选响应生成器(CRG)和终点节点选择器(ENS)。CRG从优化后的传播模式中学习潜在变量分布，以消除噪音并生成新的候选节点供ENS使用，ENS则能够识别传播图中的最重要子结构，并为CRG提供训练数据。此外，本文还开发了一个端到端框架，利用预训练的图神经网络获得的奖励来指导训练过程。生成的关键传播图随后被用于谣言检测任务的下游任务中。

Conclusion: 
在四个数据集上进行的广泛实验表明，KPG在谣言检测任务中表现优于当前最先进的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.13094</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>103. cs.AI-深度ReLU神经网络在序列可分数据上的可解释全局最小值</title><link>https://arxiv.org/pdf/2405.07098</link><description>Background: 
本文探讨了如何在满足特定条件的数据集上构建没有损失的神经网络分类器。对于足够小且类间隔离良好的聚类，以及按顺序线性可分的等价类，通过递归作用于输入空间的截断映射，将权重矩阵和偏置向量表示为累积参数，以识别具有全局最小值的神经网络配置。在理想情况下，对于$boldsymbol{text{R}}^M$中的$Q$类数据，全局最小化器可以由$Q(M+2)$个参数来描述。

Innovation: 
本文通过引入累积参数来描述权重矩阵和偏置向量，这种描述方法使得在输入空间中应用递归截断映射，从而明确构造出了零损失的神经网络分类器。这种表述方法为解析和理解神经网络提供了新的视角，并能够有效地描述复杂数据集上的全局最小值。此外，作者还通过调整输入数据的配置来简化了网络结构，提高了神经网络的可解释性。

Conclusion: 
在满足具体条件的数据上，可以通过递归截断映射和参数化方法来构建没有损失的神经网络分类器。对于$boldsymbol{text{R}}^M$中的$Q$类数据，这种方法可以将全局最小值描述为$Q(M+2)$个参数。</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.07098</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>104. cs.AI-基于结构信息原理的层级决策</title><link>https://arxiv.org/pdf/2404.09760</link><description>Background: 
层次化强化学习（HRL）是一种处理多抽象层级下的任务复杂性并加速长期代理探索的有效方法。然而，层级策略的效果很大程度上依赖于先验知识和手工假设的技能定义及任务分解。现有方法在这个方面存在不足，需要改进以适应更复杂的环境和提高政策学习的效率、稳定性和效果.

Innovation: 
本文提出了基于结构信息原理的层级决策框架（SIDM），该框架适用于单智能体和多智能体场景。通过利用决策过程中嵌入的结构信息，自动发现和学习层级策略。具体创新包括历史状态-动作轨迹的抽象机制、基于有向结构熵的技能发现方法，以及针对单智能体和多智能体的基于技能和角色的合作方法，这些方法能灵活整合多种底层算法以提高性能.

Conclusion: 
我们的框架在多个基准测试中表现显著优于现有的先进基线，通过平均奖励、收敛时间步和标准差分别提高了32.70%、64.86%和88.26%，在政策学习的有效性、效率和稳定性方面有所提升.</description><guid isPermaLink="true">https://arxiv.org/pdf/2404.09760</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>105. cs.AI-LaPuda：基于LLM的多模态数据策略导向查询优化器</title><link>https://arxiv.org/pdf/2403.13597</link><description>Background: 
大规模语言模型（LLM）在机器学习和深度学习领域起到了关键作用。近期，研究开始探索LLM在查询规划方面的潜力，包括单模态和多模态查询。然而，关于LLM查询优化的研究还处于空白状态。在查询执行性能方面，查询优化是一个至关重要的步骤。现有的查询优化器通常依赖于手动创建的规则或规则＋成本导向的方式进行查询规划的重写或转换，这需要大量的人力和时间。考虑到这种方法在多模态查询优化中的应用可能存在效率问题和编写大量规则的挑战，因此，我们有必要研究和开发一种基于LLM的新型查询优化器。

Innovation: 
本文研究了LLM在查询优化方面的潜力，提出了LaPuda：一种基于LLM和策略导向的多模态查询优化器。LaPuda通过几个抽象的策略引导LLM进行查询优化，简化了规则的构建过程。为了进一步提高优化质量，作者引入了引导成本下降（GCD）算法，确保优化过程保持正确的方向，有效防止了错误或负面优化的发生。实验结果表明，基于LaPuda的方法在大多数情况下优于基线方法，优化后的计划执行速度相较于基线提升了1-3倍。

Conclusion: 
实验结果显示，通过LaPuda方法生成的优化查询计划在执行速度上比基线方法有明显提升。作者认为，这种方法能够显著减少设计复杂的多模态查询优化器所需的人力和时间。LaPuda通过抽象策略指导LLM进行优化，并采用了有效的控制机制，证明了在多模态查询优化中的有效性。未来，这一方法有望推广到更多实际应用场景中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.13597</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>106. cs.AI-$L^{*}LM$: 使用自然语言先知来学习自动机</title><link>https://arxiv.org/pdf/2402.07051</link><description>Background: 
专家演示已证明是一种简化指定复杂任务的有效方法。最近的算法甚至支持从演示中提取明确的形式化规范，例如确定性有限自动机（DFA）。然而，这些技术通常不够样本高效。本文介绍了$L^*LM$算法，用于从演示和自然语言中学习DFAs。由于自然语言的表达力，我们观察到，从专家演示中学习DFAs的数据效率有了显著提高。技术上，$L^*LM$利用大型语言模型回答与基础任务相关的成员查询，然后结合最近将从演示学习转换为一系列带有标签的样本学习问题的技术。在我们的实验中，我们观察到两种模态相互补充，产生了一个强大的单次示例学习者。

Innovation: 
提出了一种称为$L^*LM$的新算法，用于从演示和自然语言中学习DFAs。算法利用大型语言模型来回答与基础任务相关的成员查询，并将其与从演示学习转换为一系列带有标签的样本学习问题的技术结合使用。这种方法显著提高了从专家演示中学习DFAs的数据效率，并在实验中显示出演示和自然语言之间的互补性，从而产生了一个强大的单次示例学习者。

Conclusion: 
利用自然语言增强了从专家演示中学习自动机的效率。$L^*LM$算法结合了大型语言模型和先前的技术，形成了一个高效的单一示例学习框架。这种方法显示了演示和自然语言的互补性，并代表了从各种输入中生成复杂任务自动机的一步进展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2402.07051</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>107. cs.AI-当大型语言模型遇到向量数据库：一项调查</title><link>https://arxiv.org/pdf/2402.01763</link><description>Background: 
随着大量语言模型（LLMs）的普及，它们带来了许多挑战，如幻觉、过时的知识、高昂的商业应用成本以及内存问题。向量数据库（VecDBs）作为一个解决这些问题的有效手段应运而生，它们能够高效地存储、检索和管理LLMs操作中固有的高维向量表示。这项调查旨在探讨LLMs和VecDBs的协同潜力，并深入分析它们的集成如何提升LLMs的功能性，同时展望这一领域未来的发展前景，鼓励进一步研究优化LLMs和VecDBs的结合，以提高高级数据处理和知识提取的能力。

Innovation: 
研究揭示了LLMs和VecDBs的基础原理，并对其集成对提升LLM功能的影响进行了批判性分析，同时探讨了未来在这一领域的发展潜力，旨在促进更深层次的优化研究，以增强高级数据处理和知识提取的能力。

Conclusion: 
此项调查不仅阐明了LLMs和VecDBs的基础原理，还详细分析了它们混合使用的方式及其对增强LLM功能的影响，为进一步研究这两者之间的优化结合提供了理论依据和新视角，旨在推动高级数据处理和知识提取的创新与进步。</description><guid isPermaLink="true">https://arxiv.org/pdf/2402.01763</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>108. cs.AI-通过分层Grad-CAM图解释揭示分子基团</title><link>https://arxiv.org/pdf/2402.01744</link><description>Background: 
虚拟筛选（VS）已成为药物发现中的关键工具，能够快速且经济地识别潜在的生物活性分子。近年来，图神经网络（GNNs）因其能够使用图表示来建模复杂分子结构而备受关注。然而，将解释性方法用于阐明分子亚结构对生物活性的具体贡献仍然是一个重大挑战。这一限制既影响了预测模型的可解释性，也阻碍了新型药物的理性设计。在现有研究中，GNN模型在虚拟筛选任务中展现了出色的表现，准确性高且具有良好的鲁棒性。

Innovation: 
该研究通过对20种不同的蛋白靶标（激酶家族）的小分子数据集训练20个GNN模型，实现了虚拟筛选的先进性能。在此基础上，引入了分层Grad-CAM图解释器（HGE）框架，能够深入分析驱动蛋白质-配体结合稳定性的分子基团。HGE通过利用原子、环和整个分子级别的Grad-CAM解释，并借助消息传递机制来突出显示相关化学基团。实验数据验证了解释器识别药物分子模式并正确注释到已知靶点的能力。

Conclusion: 
该方法可以作为缩短筛选流程和候选药物发现过程的有效支持工具。详细了解在结合过程中起作用的分子亚结构有助于计算化学家在结构优化以及药物再定位任务中获得洞见。</description><guid isPermaLink="true">https://arxiv.org/pdf/2402.01744</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>109. cs.AI-概念瓶颈模型是否会尊重局部性？</title><link>https://arxiv.org/pdf/2401.01259</link><description>Background: 
概念基于解释方法通过使用人类可理解的中介来为机器学习模型生成解释。这些方法假设概念预测有助于理解模型的内部推理。本文通过分析概念预测器是否利用“相关”特征来做出预测，来评估这种假设的真实性，我们称之为局部性。如果概念基于模型未能尊重局部性，那么这些模型也会缺乏解释性，因为概念预测依赖于虚假特征，从而导致概念预测的解释变得空洞无物。因此，本文旨在评估概念瓶颈模型是否遵守局部性，并构建了三个度量标准来表征模型何时遵守局部性，进而提出了缓解这一问题的建议。

Innovation: 
本文提出了一种新颖的方法，即通过构建和使用三个不同的度量标准来表征模型是否遵守局部性，以评估概念瓶颈模型是否尊重局部性。这些度量标准分别捕捉了不同的扰动概念，并评估“无关特征”的扰动是否影响概念预测器的预测结果。此方法为评估概念基础模型提供了新的标准，并为改善其局部性提供了实用建议。

Conclusion: 
许多用于实践的概念基础模型未能遵守局部性，因为概念预测器无法始终清楚地区分公司概念。基于此发现，提出了缓解这一问题的建议。</description><guid isPermaLink="true">https://arxiv.org/pdf/2401.01259</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>110. cs.AI-基于三维胸腔心脏图像重建管道识别的心电图性别差异的解剖学基础</title><link>https://arxiv.org/pdf/2312.13976</link><description>Background: 
心电图（ECG）在心肌梗死（MI）后用于诊断和风险分层。女性在心肌梗死后出现遗漏诊断和并发症的比例更高，因此本文旨在通过提供关于女性和男性在心电图和胸腔-心室解剖特征上性别差异的定量信息来解决这一问题。研究使用UK Biobank临床图像为425名心肌梗死患者和1051名健康对照提供了三维重建的胸腔-心室解剖学模型，揭示了心电图差异背后的解剖学基础，指出需要量化这些性别差异及其在心电图解释中的意义，并探讨心肌梗死后临床心电图阈值的应用。研究表明，女性心肌梗死后的心脏位置更靠后和垂直，且QRS波群延长需超过120毫秒的比例比男性高出27%。女性STj幅度较低，这与较小的室腔和更靠上的心脏位置有关。心肌梗死后，女性的T波振幅和R轴偏移与心脏位置后倾和水平有关，而男性则无此关联。这些结果强调了量化解剖特征差异及其对心电图解释的影响的重要性。

Innovation: 
本文提出了一种新颖的计算自动化管道，用于从UK Biobank临床图像中三维重建胸腔-心室解剖结构，并建立了心脏解剖学与心电图参数之间的回归模型，揭示了心肌梗死后女性和男性之间的心电图差异在解剖学上的基础。

Conclusion: 
本研究强调了量化心肌梗死后女性和男性之间的解剖学特征差异、这些差异对心电图解释的影响以及应用临床心电图阈值的必要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2312.13976</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>111. cs.AI-MalPurifier: 提高针对规避攻击的对抗净化以增强Android恶意软件检测</title><link>https://arxiv.org/pdf/2312.06423</link><description>Background: 
机器学习（ML）在Android恶意软件检测中的应用得到了广泛采用，以应对迅速增多的恶意软件攻击威胁。但最近的研究发现，基于ML的检测系统存在内在的易被规避攻击利用的缺陷。尽管已有研究尝试解决这个问题，但现有的防御方法面临诸如效果低下或泛化能力不足等挑战。

Innovation: 
MalPurifier引入了一种专门用于Android恶意软件检测的新型对抗净化框架。该框架融合了三种创新：多样化的对抗扰动机制以增强鲁棒性和泛化能力，保护性的噪声注入策略以保持良性数据的完整性，以及一个双目标损失的去噪自编码器（DAE）以实现准确的净化和分类。

Conclusion: 
大规模实验结果显示，MalPurifier显著优于现有的先进防御方法。它能够稳健地防御37种基于扰动的规避攻击，在所有测试中保持90.91%以上的鲁棒准确率。作为一个轻量级、模型无关且即插即用模块，MalPurifier提供了一个实际有效的解决方案，增强基于机器学习的Android恶意软件检测器的安全性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2312.06423</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>112. cs.AI-增强图变换器的推动型扩散</title><link>https://arxiv.org/pdf/2310.06417</link><description>Background: 
泛化能力是现代学习系统成功的核心。对于具有特定拓扑结构的非欧几里得数据（如图形数据），前期研究较少关注机器学习模型在拓扑结构变化情况下的泛化能力。此论文针对于此问题，提出了一种基于推动型扩散方程的图变换器模型（Advective Diffusion Transformer，简称AdvDIFFormer），旨在解决该问题。该模型基于描述有观察和隐含拓扑结构的连续消息传递过程的推动型扩散方程。研究表明，AdvDIFFormer具有在拓扑结构变化条件下控制泛化误差的可证明能力，而传统的图扩散模型（常见图神经网络在连续空间的推广形式）则无法保证这一点。理论和实验证明，该模型在信息网络预测、分子筛选和蛋白质互作等多种预测任务中表现出显著优势，证明了其优越性。

Innovation: 
提出了一种基于推动型扩散方程的图变换器模型（AdvDIFFormer），该模型被设计用于解决非欧几里得数据（特别是含有拓扑结构的图形数据）在拓扑结构变化条件下泛化能力问题。与传统的图扩散模型不同，AdvDIFFormer具有在拓扑结构变化条件下控制泛化误差的可证明能力。

Conclusion: 
AdvDIFFormer在信息网络预测、分子筛选和蛋白质互作等多种预测任务中表现出显著优势，证明了该模型在多任务中提高泛化能力的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2310.06417</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>113. cs.AI-Image Captions are Natural Prompts for Text-to-Image Models</title><link>https://arxiv.org/pdf/2307.08526</link><description>Background: 
随着人工智能生成内容（AIGC）的迅速发展，由于数据稀缺性和隐私泄露问题，使用合成数据训练模型已经成为常态。然而，如何使用文本生成图像模型从真实图像中生成具有信息量的训练数据仍然是一个挑战，尤其是在使用人工提示的情况下。这篇文章探讨了大型生成模型是否可以使用合适的提示直接合成用于预测任务的训练图像。研究表明，通过将先进图像标题模型生成的标题与类名结合，可以显著提升生成训练图像的质量，从而增强下游模型的泛化能力，同时在数据增强和隐私保护方面也显示出优势，甚至在某些情况下超越真实数据的泛化能力。

Innovation: 
本文提出了一种简单有效的解决方案，通过将先进图像标题模型生成的标题与类名结合作为生成模型的提示，来合成训练图像。这种方法不仅显著提升了合成数据的信息量和下游模型的泛化能力，还在数据增强和隐私保护方面表现出色，甚至在异构分布数据上的稳定性方面比真实数据更优。

Conclusion: 
通过ImageNet分类实验验证了利用图像标题作为文本生成图像模型的提示的有效性。研究表明，这种简单的方法能够显著提升合成数据的质量，从而使下游模型的泛化能力得到增强，展示了在数据增强、隐私保护以及异构数据分布稳定性方面的优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2307.08526</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>114. cs.AI-近期人工智能技术趋势：一项范围性审查</title><link>https://arxiv.org/pdf/2305.04532</link><description>Background: 
人工智能技术在多个领域中越来越普遍。智能手机、社交媒体平台、搜索引擎和无人驾驶汽车等应用利用了人工智能技术来提升性能。本文遵循《系统评价和荟萃分析首选报告项目》(PRISMA) 框架，进行了一项范围性审查，旨在发现不同领域中最先进的技术。研究在2022年从人工智能和机器学习领域三本知名期刊：《人工智能研究杂志》《机器学习杂志》和《机器学习研究杂志》中筛选文章。研究对技术解决方案提出了某些资格要求：技术必须与可比解决方案进行比较测试，在进行比较时通常要使用公认的数据集或其他合理验证的数据集，结果必须显示比可比解决方案改进的成果。技术开发中最重要的部分之一是如何处理和利用来自多个来源的数据，这些数据往往是高度无结构化的，技术解决方案应该能够利用这些数据，同时减少人力工作。研究结果表明，创建标记数据集非常耗时，利用无监督学习或半监督学习技术的解决方案越来越受到研究兴趣。学习算法需要能够高效更新，预测应该是可解释的。在实际应用中使用人工智能技术时，安全性和可解释的预测在大规模采用之前是必需要考虑的。 

Innovation: 
该研究遵循了PRISMA框架，对2022年发表的三本知名有关人工智能和机器学习领域的期刊进行范围性审查。确定了利用无监督或半监督学习技术的解决方案越来越受到研究的兴趣，学习算法需要能够高效更新，预测应该是可解释的，同时研究提出了在实际应用中安全性和可解释的预测的重要性前置考虑。

Conclusion: 
研究结果表明，人工智能技术的发展趋势之一是利用无监督或半监督学习技术的解决方案越来越受到研究兴趣。学习算法需要能够高效更新，预测应该是可解释的。在实际应用中，安全性和可解释的预测是大规模采用之前必需要考虑的因素。</description><guid isPermaLink="true">https://arxiv.org/pdf/2305.04532</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>115. cs.AI-Indeterminate Probability Theory</title><link>https://arxiv.org/pdf/2303.11536</link><description>Background: 
复杂的连续或混合联合分布（例如，P(Y | z_1, z_2, ..., z_N)）通常没有闭合形式的解，往往需要使用如马尔可夫链蒙特卡洛方法（MCMC）等近似方法。

Innovation: 
1. 建立了一个以观察者为中心的框架，其中实验结果被表示为结合真实值和观测误差的概率分布；2. 引入了三个独立假设公理，以构建一个两阶段概率推理框架；3. 在此框架下推导了任意复杂联合分布的闭合形式解。IPNN模型和非神经网络的多元时间序列预测应用都证明了IPT在高维分布建模中的有效性，成功验证了至1000维度的结果，且IPT与经典概率论一致，并在观测误差趋近于零的极限下包括了频率主义方程。

Conclusion: 
IPT不仅在高维联合分布建模中表现出有效性，还与经典概率论保持一致，并在特定条件下涵盖了频率主义的概率论。</description><guid isPermaLink="true">https://arxiv.org/pdf/2303.11536</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>116. cs.AI-使用图形拓扑的不确定条件下高效子图同构</title><link>https://arxiv.org/pdf/2209.09090</link><description>Background: 
子图同构问题通常被视为NP完全问题，而在实际应用中，由于边权重是实数且可能受到测量噪声和潜在缺失数据的影响，该问题变得更加复杂。这种图匹配问题在图像匹配和地图匹配等应用中经常出现。现有的大多数子图匹配方法在存在这种干扰时无法实现节点之间的准确匹配。本文探讨了一种在不具节点标签的不确定情况下，识别子图和完全图之间节点对应关系的方法，以及在没有节点标签的情况下，如何有效解决子图同构问题。

Innovation: 
提出了一种基于图形拓扑的方法，该方法通过两个步骤识别不精确情况下子图与完全图的节点对应关系：第一步是从子图中提取最小的独特拓扑保持子集，并在全图中找到其可行匹配；第二步是通过基于边界可交换性的唯一路径配对来扩展匹配节点集，以实现共识算法。这种方法在实际应用中的计算效率接近亚线性，对随机测量噪声具有鲁棒性，并具备良好的统计特性。

Conclusion: 
本文提出的方法在处理具有不确定性和缺失数据的问题时具有更高的效率和更强的鲁棒性，并且非常适合于精确匹配场景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2209.09090</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>117. cs.AI-数学证明作为试金石：揭示高级大型推理模型的失败模式</title><link>https://arxiv.org/pdf/2506.17114</link><description>Background: 
大型推理模型（如R1、o3）在数学问题解决方面展现出卓越的能力。然而，这些高级模型在流行数据集上的高报告准确率、纯粹依赖数值评估以及潜在的基准泄露问题，往往掩盖了它们真正的推理缺陷。为解决这些问题，该研究提出了利用数学证明的内在严谨性和方法论复杂性作为诊断工具，来揭示这些隐藏的缺陷。作者创建了一个包含200个多样化的数学证明问题的RFMDataset（揭发失败模式），以全面评估高级模型在解决这些问题时的表现。深入分析模型的失败揭示了当前大型推理模型10种细粒度的错误类型，这些错误表明了当前大型推理模型在推理上的根本限制。

Innovation: 
研究提出了RFMDataset，这是一个包含200个多样化的数学证明问题的数据集，用于评估和诊断高级推理模型在解决数学证明问题时的不足。通过全面分析模型失败，研究团队揭示了10种细粒度的错误类型，阐明了当前大型推理模型存在的根本局限。此外，研究还指出，模型在推理过程中存在虚构和不完整的问题，并且自身反思不足以解决当前的逻辑困境，强调了需要进行正式化和细粒度的逻辑训练的重要性。

Conclusion: 
研究结果表明，大型推理模型在处理数学证明时存在严重的无法克服的局限，模型的自我反思不足以解决当前的逻辑问题，必须通过精细化的逻辑训练来增强模型的推理能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17114</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>118. cs.AI-SLR: 全自动合成框架实现可扩展的逻辑推理</title><link>https://arxiv.org/pdf/2506.15787</link><description>Background: 
当前，大规模语言模型（LLMs）在生成语法正确的规则方面表现出色，但在正确的逻辑推理方面经常出现错误。最近的推理LLMs在这一点上有所改进，但在测试时间的计算上却有显著增加，有时甚至超过15k完成令牌。因此，需要一种能够系统地评估和训练LLMs的框架，并能自动合成具有精确控制难度的归纳推理任务，以进一步测试和提升它们的推理能力。SLR框架旨在解决这一需求，通过可扩展的逻辑推理来实现这一目标。SLR能够根据用户的需求生成难度可控的归纳推理任务，并利用此框架创建了拥有超过19k任务的SLR-Bench基准，这些任务分为20个不同的课程级别，逐步增加它们的关系、算术和递归复杂性。这些结果表明，现有的大型语言模型在简单任务上的表现尚可，但在需要更深逻辑推理的任务上却难以胜任，而SLR的逻辑调优显著提高了准确率，达到了与Gemini-Flash-Thinking相当的水平，但其计算成本要低得多。研究还表明，所提出的框架完全自动化，不需要人工标注，并确保数据集的新颖性，为探讨和推进LLMs的推理能力提供了一个可扩展的环境。

Innovation: 
SLR框架引入了一种全新的端到端方法，用于系统评估和训练大规模语言模型（LLMs），通过可扩展的逻辑推理实现目标。SLR框架能够自动合成具有精确难度控制的归纳推理任务，包括生成一个潜在的真理规则、一个用于符号法官验证模型输出的可执行验证程序，以及推理任务的指令提示。此外，SLR还因此打破了现有大型语言模型在逻辑推理方面的局限，使得逻辑调优能够显著提高模型在复杂推理任务上的准确性。该框架还确保了数据集的新颖性，并为测试和提升LLMs推理能力提供了一个可扩展的环境，同时显示出其自动化、无需人工注释的特点以及在计算成本上的显著优势。

Conclusion: 
SLR代表了一种创新的端到端框架，用于评估和提升大规模语言模型（LLMs）的逻辑推理能力。通过SLR，可以自动合成具有精确控制难度的归纳推理任务，并利用每次生成的促进入工智能领域的深入研究。SLR-Bench基准展示了当代LLMs在简单任务上的表现，但并未解决在复杂逻辑推理任务中的弱点。逻辑调优通过SLR显著提高了准确性，而这种改进以更低的计算成本实现了，使得该框架在实际应用中具有重要价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15787</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>119. cs.AI-OAagents: 实现高效代理的一个实证研究</title><link>https://arxiv.org/pdf/2506.15741</link><description>Background: 
近年来，代理型人工智能(Agentic AI)的研究变得越来越流行。然而，当前的代理研究实践缺乏标准化和科学严谨性，使得难以公平地比较不同方法。结果，在不同设计选择如何影响代理框架效果的问题上仍然不清楚，衡量进度也变得困难。因此，研究者们通过系统性实证研究GAIA基准和BrowseComp，旨在识别关键代理组件中流行的设计选择对效果的公正和严谨的影响。发现现有的评估协议缺乏，导致先前的工作非可重复，即使开源后也存在显著的随机运行差异。因此，引入了更稳健的评估协议以稳定比较。研究揭示了哪些组件和设计对有效代理至关重要，而哪些则可能是冗余的，尽管这些设计之前看起来是合理的。

Innovation: 
设计并开源了新的模块化基础代理框架——OAagents，使其在开源项目中达到最先进的性能。OAagents提供了一种用于各种代理组件的模块化设计，促进了Agentic AI领域的未来研究

Conclusion: 
研究评估了关键代理组件中流行的设计选择，揭示了哪些对有效代理至关重要，而哪些则是冗余的，基于此建立了并开源了OAagents。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15741</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>120. cs.AI-QUEST: Quality-aware Semi-supervised Table Extraction for Business Documents</title><link>https://arxiv.org/pdf/2506.14568</link><description>Background: 
从商业文件中自动提取表格（TE）对于工业工作流程至关重要，但由于标注稀少及多阶段管道带来的错误，这一任务仍具有挑战性。现有的半监督学习方法依赖于反映提取质量不良的信心评分，这限制了其效果。给定这些挑战，现有方法依靠不准确的信心评分，难以有效利用未标注数据，导致提取质量难以提升.

Innovation: 
本文提出了QUEST，一种针对商业文档的质量感知半监督学习表格提取框架。该框架引入了一个新型的质量评估模型，能够评估提取表格的结构和上下文特征，并通过预测F1分数而非依赖信心度量来指导伪标签的选择。此外，通过多样化测量（如DPP、Vendi分数、IntDiv）减轻确认偏见，使模型在迭代SSL训练过程中更加稳健。在专有商业数据集上进行的实验证明了该框架的有效性，与现有方法相比， QUEST能够提高F1得分并减少空预测率。

Conclusion: 
在业务文档领域，该框架具有可解释的质量评估和对标注稀缺性的鲁棒性，从而使其更适用于结构一致性和数据完整性至上的业务文档的表格提取任务。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14568</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>121. cs.AI-Med-REFL: 医疗推理增强通过自我纠正的细粒度反思</title><link>https://arxiv.org/pdf/2506.13793</link><description>Background: 
大型推理模型在数学和代码推理方面取得了重大进展，但在医疗领域中的应用尚未实现平滑过渡。导致这种差异的关键问题是，这些模型不太注重中间推理步骤的质量，而在高风险的医疗场景中，这一点尤为重要。因此，研究团队提出了Med-REFL方法，通过细粒度自我纠正反思来优化医疗推理。n

Innovation: 
Med-REFL利用树形思维方法将医疗问题分解为精细的推理路径，并对每一步及其后续反思进行定量评估。这种方法使模型能够自动构建直接偏好优化数据，减少对昂贵专家标注的依赖，同时引导模型识别并纠正推理错误。实验结果表明，Med-REFL在MedQA-USMLE基准测试上实现了显著改进，平均提高了4.11%，并且进一步提升了7B/8B模型的最新性能4.13%。此外，Med-REFL在多个具有挑战性的医疗问答数据集上展示了良好的泛化能力和鲁棒性。n

Conclusion: 
这项工作表明，优先考虑反思的质量可以提高医疗AI应用中的推理准确性与可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13793</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>122. cs.AI-Stream-Omni: 大规模语言-视觉-语音模型实现同步多模态交互</title><link>https://arxiv.org/pdf/2506.13642</link><description>Background: 
随着GPT-4o等大型多模态模型（LMMs）的出现，探索将文本、视觉和语音模态整合以支持更灵活的多模态交互变得重要。现有LMMs通常沿序列维度拼接各模态并将其输入到大型语言模型（LLM）中。尽管序列维度拼接简化了模态整合的过程，但它往往依赖大量数据来学习模态对齐。本文旨在更有目的地建模各种模态之间的关系，从而实现更高效和灵活的模态对齐。

Innovation: 
本文提出了Stream-Omni，这是一种大规模语言-视觉-语音模型，具有高效的模态对齐方式。它采用LLM作为骨干，并根据不同模态与文本的关系进行对齐。对于与文本语义互补的视觉模态，Stream-Omni通过序列维度拼接实现视觉-文本对齐；对于与文本语义一致的语音，Stream-Omni引入基于CTC的层维度映射来实现语音-文本对齐。这种对齐方式使Stream-Omni能够在较少的数据（特别是语音）下实现模态对齐，促进文本能力向其他模态的转移。实验表明，Stream-Omni在视觉理解、语音交互以及视觉指导的语音交互任务中表现出色。由于层维度映射，Stream-Omni还可以在语音交互过程中提供中间文本输出（例如ASR转录和模型响应），为用户提供全面的多模态体验。

Conclusion: 
实验结果表明，Stream-Omni在视觉理解、语音交互和视觉指导的语音交互任务中表现出色，能够同时提供中间文本输出，为用户实现全面的多模态体验。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13642</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>123. cs.AI-MM-R5: 通过强化学习增强多模态推理的检索排序系统</title><link>https://arxiv.org/pdf/2506.12364</link><description>Background: 
多模态文档检索系统能够跨越文本、图像和布局提供信息访问，适用于文档基础问题回答、报告分析和交互式内容总结等多种领域。当前的多模态排序器能够通过重新排序检索的候选项来提高检索精确度，但训练策略和整体有效性仍有改进空间，且缺乏明确的推理过程，难以进行分析和优化。现有方法多模态排序阶段的研究尚不充分，存在改进的空间。

Innovation: 
本文提出了MM-R5多模态排序增强推理排序系统，通过强化学习训练，分为监督微调和强化学习两个阶段。在监督微调阶段，改进指令跟随并引导模型生成完整的高质量推理链，引入新型数据构造策略产生丰富的高质量推理数据。在强化学习阶段，设计了特定任务的奖励框架，包括针对多模态候选项定制的排序奖励和基于复合模板的奖励以进一步提高推理质量。MM-R5在可比的大型模型上实现了可比的结果，并在多数指标上达到最先进的性能，相比检索-only方法，MM-R5的召回率提高了4%以上。这些结果验证了推理增强训练管道的有效性。

Conclusion: 
MM-R5通过强化学习增强多模态推理的方法在文档检索中达到了最先进的性能，显示出在多模态排序中的有效性和可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12364</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>124. cs.AI-DipLLM：使用预训练语言模型在外交中的策略决策微调</title><link>https://arxiv.org/pdf/2506.09655</link><description>Background: 
外交是一个复杂多玩家的游戏，需要合作和竞争，这对AI系统提出了重大挑战。传统的解决方法依赖于平衡搜索来生成大量的游戏数据进行训练，这需要大量的计算资源。大型语言模型（LLMs）提供了一种有前途的替代方案，通过预训练知识实现较强的表现，同时使用相对较小规模的微调。然而，将LLMs应用于外交仍然具有挑战性，因为动作组合呈指数增长，且玩家之间的战略互动极其复杂。

Innovation: 
我们提出了一种名为DipLLM的基于LLM的智能体，它通过自回归分解框架学习外交中的均衡策略。DipLLM简化了复杂多单元行动分配为单元级决策序列。通过将均衡策略定义为学习目标，模型仅使用比最先进的Cicero模型所需的1.5%的数据量进行微调，并超越了其性能。我们的结果表明，微调后的LLMs有可能解决多玩家游戏中的复杂战略决策问题。

Conclusion: 
我们的研究结果表明，微调后的LLMs具有解决多玩家游戏中复杂的战略决策问题的潜力。DipLLM通过采用自回归分解框架和均衡策略学习目标，有效提高了外交决策的任务效率，展示了LLMs在策略学习和决策制定方面的强大能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.09655</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>125. cs.AI-SWE-Dev: 使用训练和推理扩展构建软件工程代理</title><link>https://arxiv.org/pdf/2506.07636</link><description>Background: 
大型语言模型（LLMs）已经从对话性的问题解决发展到能够处理涉及工具使用的真实世界任务，例如软件工程（SWE）。目前，LLM驱动的工具包例如OpenAI Codex和Cursor已经实现了一个端到端的软件开发流程自动化。然而，构建有效的SWE代理仍然具有挑战性，主要是由于缺乏高质量的训练数据和有效的测试案例。鉴于此，提出了一个基于开源LLM的SWE代理，SWE-Dev。建模剂的培训数据，通过开发一个稳健的工作流来综合评估示例测试案例，以及扩展模型代理轨迹，以完成构建SWE-Dev的任务。

Innovation: 
开发了一个稳健的工作流来综合评估示例测试案例；扩展了模型代理轨迹，以构建SWE-Dev的培训数据；实验结果表明SWE-Dev模型在SWE-bench-Verified基准测试中的性能优于当前最先进的开源模型。

Conclusion: 
综合测试案例生成工作流和规模化模型代理轨迹的方法，使SWE-Dev模型在软件开发任务中取得优异表现，成功率为SWE-Dev 7B和32B分别达到23.4%和36.6%，超过了基线开源模型，所有的代码、模型和数据集都已经公开可用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07636</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>126. cs.AI-语言模型的交叉熵博弈：从隐含知识到泛化能力度量</title><link>https://arxiv.org/pdf/2506.06832</link><description>Background: 
大型语言模型（LLMs）定义了文本的概率测度。本文讨论了LLMs理解这种概率测度的方式及其算法含义，并由此引出了超越生成采样的一系列任务，如总结、假设性思考、异常检测、原创性搜索、逆向提示、辩论、创造性求解等。这些任务可以基于LLM测度作为博弈游戏的形式，称之为交叉熵（Xent）博弈。

Innovation: 
文章具体介绍了Xent Game的概念，包括其单人博弈或多玩家博弈的形式，以及如何使用交叉熵得分和约束来表示其结构。展示了Xent Game空间包含丰富的有趣示例，并可以通过基本博弈论一致性公理构建。同时，该研究提出了一种使用空间内的一致探索方法来测量LLMs的泛化能力的新思路，这种方法借鉴了进化动态的灵感。通过构建Xent Game测度来度量LLMs的能力，它是基于给定范围并通过提取覆盖测度构建的有限家族游戏。

Conclusion: 
Xent Game空间为从隐含知识到泛化的测量提供了有效的算法框架，它不仅可以涵盖各种文本处理任务，还能以结构化的方式构建具备评估LLM多功能性的基准。这种方法能够系统地探索无限范围内的场景，从而提出更为综合的LLM能力度量方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.06832</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>127. cs.AI-MCP-Zero: Autonomous LLM代理的主动工具发现</title><link>https://arxiv.org/pdf/2506.01056</link><description>Background: 
当前的LLM代理将成千上万的工具架构注入提示中，导致巨大的上下文开销，并将其转变为被动的工具选择者而非自主代理。这些代理被大量可用的工具所淹没，无法自主发现能力缺口并按需请求特定工具，从而大大降低了其自主性并增加了上下文开销。

Innovation: 
我们引入了MCP-Zero，一种主动代理框架，使LLM能够自主恢复工具发现的主动性。MCP-Zero通过三个核心机制运作：(1)主动工具请求，让模型自主生成结构化的请求以明确其具体工具需求；(2)分层语义路由，一种两阶段算法，通过更好的语义对齐，将请求匹配到相关的服务器和工具；(3)迭代能力扩展，让代理能够逐步构建跨领域的工具链，同时保持最小的上下文足迹。此外，还构建了MCP-tools数据集，包含308个MCP服务器和2,797个工具，进一步验证了MCP-Zero的效果。

Conclusion: 
实验表明，MCP-Zero不仅保持了代理的自主性，还实现了显著的效率提升：(i) 准确从近3000个候选者中选择工具，涉及248.1万个标记；(ii) 在APIBank上的标记消耗减少了98%，同时保持高精度；(iii) 具有一致的多轮次表现，随着工具生态系统增长而扩展。这项工作确立了主动工具发现作为可扩展自主代理系统的基本设计模式。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.01056</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>128. cs.AI-IRT-Router：通过项目反应理论实现有效且可解释的多大模型路由</title><link>https://arxiv.org/pdf/2506.01048</link><description>Background: 
大语言模型（LLMs）在多种自然语言任务上表现出了出色的能力，但是选择合适的LLM来响应用户查询需要在性能和成本之间寻找平衡。强大的模型虽然提供更好的结果，但成本高昂，而较小的模型则较为经济但能力较弱。开发了一种多大模型路由框架——IRT-Router，该框架通过项目反应理论（IRT）来建模LLM能力和用户查询属性之间的关系，从而优化查询匹配并提供可解释的洞察。此外，设计了一种基于语义相似性的在线查询预热技术，进一步增强了IRT-Router的在线泛化能力。实验结果表明，IRT-Router在有效性与可解释性方面均优于大多数基线方法，并且在冷启动场景中也表现出色，验证了该方法在实际应用中的可靠性和实用性。

Innovation: 
提出了一个基于项目反应理论的多大模型路由框架——IRT-Router，用于高效地将用户查询路由到最适合的大模型。此外，设计了基于语义相似性的在线查询预热技术，增强了在线泛化能力。IRT-Router不仅提高了响应性能的准确性，还提供了可解释的洞察，如大模型能力及查询难度。实验结果表明，IRT-Router在有效性与可解释性方面均优于大多数基线方法，并且在冷启动场景中也表现出色。

Conclusion: 
实验结果表明，IRT-Router在有效性与可解释性方面均优于大多数基线方法，并且在冷启动场景中也表现出色，验证了该方法在实际应用中的可靠性和实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.01048</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>129. cs.AI-Infi-MMR：基于课程的多模态推理解锁在多模态小型语言模型中的阶段增强学习</title><link>https://arxiv.org/pdf/2505.23091</link><description>Background: 
近年来，大型语言模型（LLMs）已经展示了在推理能力方面的显著进展，例如DeepSeek-R1，它通过基于规则的强化学习极大地增强了逻辑推理能力。然而，将这些成就扩展到多模态大型语言模型（MLLMs）面临重大挑战，特别是对多模态小型语言模型（MSLMs）而言，由于他们通常具有较弱的基础推理能力，这些挑战更为显著。主要的挑战包括高质量的多模态推理数据集稀缺、视觉处理引入推理能力下降的风险，以及直接应用强化学习可能产生复杂但错误的推理过程。

Innovation: 
设计了一个新的框架Infi-MMR，通过三个仔细设计的阶段来系统地解锁MSLMs的推理潜力，并提出了一种多模态推理模型Infi-MMR-3B。Infi-MMR-3B不仅在多模态数学推理能力上达到了最先进的水平（在MathVerse testmini上的表现达到43.68%，在MathVision上的表现达到27.04%，在OlympiadBench上的表现达到21.33%），还在通用推理能力上表现优异（在MathVista testmini上的表现达到67.2%）。

Conclusion: 
框架Infi-MMR通过三个阶段：基础推理激活、跨模态推理适应和多模态推理增强，展示了在MSLMs中的多模态推理解锁。Infi-MMR-3B在多模态和通用推理任务中都取得了显著成果，验证了该方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.23091</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>130. cs.AI-专家模型集成共识机制的重要性：迈向适应性临床人工智能</title><link>https://arxiv.org/pdf/2505.23075</link><description>Background: 
尽管大型语言模型在临床领域的应用越来越广泛，但现有的方法主要依赖单一模型的架构。这使得系统面临过时和过度依赖单一模型系统的风险。引入了一种新的框架，称为共识机制，该机制通过模仿临床分诊和多学科临床决策过程，提出了一系列特定医学专家代理的集成方案，以改进临床决策并保持高度的适应性。

Innovation: 
提出了名为共识机制的新框架，通过集成多个特定医学专家代理，实现成本、延迟或性能优化，同时增强临床决策的准确性和适应性。在三个医学评估基准测试和一个诊断数据集上的严格评估显示，与OpenAI的O3和Google的Gemini 2.5 Pro相比，共识机制在多个指标上表现更佳，获得了更高的准确性和精确度，特别是在差异诊断生成方面。

Conclusion: 
共识机制能够在保持医疗决策准确性和适应性的前提下，通过优化模型配置来降低成本、延迟或性能。该机制在临床人工智能领域具有广泛的适用性和改进潜力，特别是在提高差异诊断的准确性和精确度方面。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.23075</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>131. cs.AI-Style2Code：具有双模态对比表示学习的可风格控制代码生成框架</title><link>https://arxiv.org/pdf/2505.19442</link><description>Background: 
代码生成，尤其是能够在指定样式下同时保持功能性的代码生成，仍然是一个具有挑战性的任务。现有的方法在实现灵活的样式控制方面存在局限性，难以在风格多样性和代码正确性之间找到平衡。该论文的目标是提供一种改进的方法来解决这个问题。

Innovation: 
该论文提出了一个结合对比学习和条件解码的两阶段训练框架，以实现灵活的风格控制。在第一阶段，将代码风格表示与语义和结构特征对齐；在第二阶段，通过细调经过学习风格向量调节的语言模型（如Flan-T5）来指导生成。该方法还通过轻量级混合支持风格插值和个人化。与前人的工作相比，本文提供的综合框架能够在不牺牲代码正确性的情况下提供更好的风格控制。这是首次将对比对齐与条件解码相结合以实现指导性代码生成的方法尝试。

Conclusion: 
本文提出的方法能够有效控制代码生成的风格，同时保持代码的正确性。通过对比学习和条件解码的结合使用，实现了风格和功能的平衡。此外，该框架还支持风格插值和用户个性化，提高了代码生成的灵活性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.19442</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>132. cs.AI-UIShift：通过自监督强化学习增强VLM基于的GUI代理</title><link>https://arxiv.org/pdf/2505.12493</link><description>Background: 
训练视觉语言模型（VLMs）用于GUI代理通常依赖于在大规模标注数据集上进行监督微调（SFT），但数据采集过程繁重且容易出错。这项工作提出了一个自监督逆动力学任务，使VLMs能够通过推断导致GUI转换的动作来学习GUI过渡对，从而使得VLMs可以忽略与用户动作无关的变化（如背景刷新、广告），并专注于按钮和输入字段等真正的操作可能性。此外，这种训练数据可以从现有的GUI轨迹中轻松获得，也不需要人工标注，通过自动离线探索可以轻松扩展。

Innovation: 
提出了UI-shift，一种用于通过自监督强化学习(SRL)增强基于VLM的GUI代理的框架。仅使用来自现有数据集的2K训练样本，使用UI-shift训练的两个VLMs（Qwen2.5-VL-3B和Qwen2.5-VL-7B）在屏幕定位任务（ScreenSpot系列基准）和GUI自动化任务（AndroidControl）上的表现与SFT基准线和旨在增强推理能力的GUI特定模型相当或更优。这些发现表明，通过在未来利用更多的自监督训练数据，有可能改进VLMs用于GUI代理的方向。

Conclusion: 
结果显示，通过利用自监督训练数据，可以提升VLMs在GUI代理方面的性能。此研究提出的UI-shift框架为增强VLMs提供了新方向，未来有望通过更大规模的自监督数据进一步提升模型性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12493</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>133. cs.AI-多智能体体态人工智能：进展与未来方向</title><link>https://arxiv.org/pdf/2505.05108</link><description>Background: 
体态人工智能（Embodied AI）在智能时代发挥了重要作用，其中AI系统通过结合物理实体来感知、推理和与环境互动。利用传感器采集信息和执行器执行动作，这些系统可以依据真实世界的反馈学习和适应，在动态和不可预测的环境中有效执行任务。随着深度学习（DL）、强化学习（RL）和大型语言模型（LLMs）等技术的成熟，体态AI已成学术界和工业界的领先领域，其应用覆盖机器人技术、医疗健康、交通运输和制造业。然而，大多数研究都集中在单智能体系统上，这些系统往往假定环境是静态和封闭的，而在现实世界中，智能体必须导航更为复杂的场景。在这种情况下，智能体不仅仅是与周围环境互动，还必须与其他智能体协作，这需要复杂的适应机制、实时学习和协作问题解决。尽管对多智能体系统有越来越大的兴趣，但现有研究仍在有限的范围内，通常依赖于简化模型而未能捕捉多智能体体态AI在动态、开放环境中的全部复杂性。迄今为止，没有全面的综述系统地审视该领域的进展。鉴于体态AI的快速发展，深化对多智能体体态AI的理解对于应对真实世界的挑战至关重要。为了填补这一空白并促进该领域的进一步发展，本文回顾了当前的研究状态，分析了关键贡献，指出了挑战和未来方向，提供了引导创新和进步的见解。

Innovation: 
1. 介绍了多智能体体态AI领域的综合进展；n2. 分析了现有研究中的关键贡献；n3. 识别了面临的挑战和未来的研究方向；n4. 提出了指导创新和进展的见解。

Conclusion: 
本文总结了当前多智能体体态AI的研究状况，并为其未来发展提供了方向性的指导。通过系统的综述，本文旨在深化对这一热点领域的理解，解决其面临的挑战和问题，为进一步的研究奠定基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.05108</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>134. cs.AI-AI代理人协议概述</title><link>https://arxiv.org/pdf/2504.16736</link><description>Background: 
大型语言模型（LLMs）的快速发展导致其代理在多个行业中得到广泛应用，包括客户服务、内容生成、数据分析甚至医疗保健。然而，随着越来越多的代理部署，一个主要问题出现了：缺乏标准化的协议使这些代理无法与外部工具或数据源进行有效通信。这使得代理难以协同工作或有效扩展，并限制了它们处理复杂实际任务的能力。统一的代理通信协议可以解决这一问题，促进更顺畅的交互、鼓励协作，并推动集体智能的形成。

Innovation: 
本文提供了对现有代理协议的首次全面分析，提出了一个系统化的二维分类法，区分了基于上下文的协议与代理间协议以及通用型协议与领域特定型协议。此外，还对这些协议在安全性、可扩展性和延迟等关键维度上的性能进行了对比分析。最后，探讨了代理协议的未来趋势，确定了下一代代理协议的关键研究方向和必要特性，包括适应性、隐私保护和群体交互，以及分层架构和集体智能基础设施的趋势等。

Conclusion: 
本项工作旨在为研究人员和工程师提供一个实用的参考，帮助他们设计、评估或集成强大的智能代理通信基础设施。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.16736</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>135. cs.AI-Lemmanaid: 神经符号推理工具中的命题猜测</title><link>https://arxiv.org/pdf/2504.04942</link><description>Background: 
自动推测有用的、有趣的和新颖的命题会极大地提升自动化推理工具的性能，并降低在证明辅助工具中形式化数学的门槛。然而，这对于神经网络和符号方法来说是一项极具挑战性的任务。文章探讨了一种将大规模语言模型（LLMs）和符号方法结合的神经符号推理工具——Lemmanaid，以提高命题猜测的实用性，并在Isabelle证明助手的证明库上进行了评估。

Innovation: 
文章提出了Lemmanaid，这是一种结合了大规模语言模型和符号方法的神经符号命题猜测工具。Lemmanaid通过训练大规模语言模型生成命题模板，并结合符号方法填充细节。研究结果表明，Lemmanaid在Isabelle的HOL库和其正式证明档案中的测试集上超过了纯神经方法和之前的所有符号方法，能够发现黄金标准的人类撰写的命题的29-39.5%，比纯神经方法多了8-15%的命题。Lemmanaid通过结合符号和神经方法的优点，为广泛的输入领域生成了有用的命题，促进了计算机辅助理论的发展与正式化。

Conclusion: 
Lemmanaid在Isabelle证明助手的证明库中表现优异，通过结合大规模语言模型和符号方法，在命题猜测上取得了显著效果，发现了更多的人类撰写的黄金标准命题，有效地促进了自动化推理工具和数学形式化的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.04942</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>136. cs.AI-具有知识图谱的经济型AI助手</title><link>https://arxiv.org/pdf/2504.02670</link><description>Background: 
大型语言模型（LLMs）正在革新AI助手的开发，使其能够跨领域执行多种任务。然而，当前的LLM驱动代理面临着高昂的运营成本和在复杂基准测试（如GAIA）上的较低成功率等重大挑战。需要一个既能降低成本又能提高复杂任务完成率的解决方案.

Innovation: 
提出了一种名为知识图谱的思想（KGoT）的创新AI助手架构，它将LLM推理与动态构建的知识图谱（KGs）相结合。KGoT通过外部工具（如数学求解器、网络爬虫和Python脚本）动态提取和结构化任务相关知识，形成动态KG表示，从而实现低成本模型高效解决复杂任务，同时减少偏见和噪声。KGoT在GAIA基准测试中的任务成功率提高了29%，相比使用GPT-4o mini的Hugging Face代理。使用更小的模型减少了36倍的操作成本，对其他模型和基准测试（例如SimpleQA）也有相似的改进效果，提供了可扩展、成本效益高、多功能且高性能的AI助手解决方案.

Conclusion: 
KGoT提供了一种可扩展、经济、多功能和表现出色的AI助手方案，可以在运营成本大幅降低的同时，实现复杂任务的有效完成率提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.02670</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>137. cs.AI-探索大型语言模型在重塑交通系统中的作用：综述、框架和路线图</title><link>https://arxiv.org/pdf/2503.21411</link><description>Background: 
现代交通系统面临着日益增长的需求、动态环境和异构信息集成的挑战。大型语言模型（LLMs）的迅速发展为解决这些挑战提供了变革性的潜力。传统上作为文本生成器的LLMs经由预训练获得的广泛知识和高层次能力，逐渐转变为智能交通系统中的多功能知识驱动任务解决者。本文综述了LLM4TR这一新颖的概念框架，系统地将LLMs在交通中的作用分类为四个协同维度：信息处理器、知识编码器、组件生成器和决策促进者。通过统一的分类体系，本文详细阐述了LLMs如何连通碎片化的数据管道、提升预测分析能力、模拟人类推理并实现传感、学习、建模和管理任务的闭环交互。

Innovation: 
提出了LLM4TR，一种新颖的概念框架，系统地将LLMs在交通中的作用分类为四个协同维度：信息处理器、知识编码器、组件生成器和决策促进者。通过统一的分类体系，系统阐述了LLMs如何整合数据管道、加强预测分析、模拟人类推理以及在交通系统的传感、学习、建模和管理任务中实现闭环交互。介绍了各种应用，从交通预测和自动驾驶到安全分析和城市交通优化，并强调了LLMs新兴的能力如上下文学习和逐步推理如何增强交通系统的运行和管理。此外，还提供了实用指南和计算指南，以支持实地部署。

Conclusion: 
通过识别现有基于LLM的解决方案中的挑战，本文为推进基于LLM的交通研究制定了路线图，将LLMs定位为下一代网络物理社会交通生态系统的核心角色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.21411</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>138. cs.AI-API代理 VS GUI代理：分歧与协同</title><link>https://arxiv.org/pdf/2503.11069</link><description>Background: 
大型语言模型(LLMs)现已超越简单的文本生成，转变为能够直接将自然语言命令转化为实际操作的软件代理。起初，基于API的LLM代理因其强大的自动化能力和与程序端点无缝集成的能力而备受瞩目。然而，近期跨模态LLM研究的进步使得基于GUI的LLM代理能够以类似人类的方式与图形用户界面交互。尽管这两种范式都旨在通过LLM驱动的任务自动化，但它们在架构复杂性、开发工作流程和用户交互模式方面存在显著差异。因此，本文首次进行全面的比较研究，系统分析了这两种代理之间的分歧及其潜在的协同作用。

Innovation: 
本文提出了一种首次全面比较API代理和GUI代理的方法，通过系统分析它们之间的差异并强调混合方法的优势场景来推动未来的创新。此外，通过提出明确的决策标准并展示实际应用场景，本文旨在指导实践者和研究人员选择、组合或在这些范式之间过渡的方法。

Conclusion: 
本文表明，基于LLM的自动化将继续创新，这有望在未来模糊API驱动与GUI驱动代理之间的界限，为各种实际应用提供更灵活、更适应的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.11069</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>139. cs.AI-PlanGenLLMs: LLM规划能力的现代综述</title><link>https://arxiv.org/pdf/2502.11221</link><description>Background: 
LLMs在生成计划方面具有巨大潜力，能够将初始世界状态转化为期望的目标状态。大量研究探讨了LLM在各种规划任务中的应用，从网页导航到旅行规划和数据库查询等。然而，现有的许多系统往往是针对特定问题定制的，使得它们之间的比较变得困难，同时也缺乏明确且一致的评估标准。本综述旨在填补这一空白，提供对当前LLM规划器的全面概述。综述借鉴了Kartam和Wilkins（1990）的研究，并考察了六个关键性能标准：完备性、可执行性、最优性、表示、泛化和效率。对每个标准都进行了深入的分析，并指出了代表性作品的优缺点。本文还指出了未来的关键发展方向，使它成为对LLM规划感兴趣的专业人士和新手的宝贵资源，可以支持代理工作流程的规划过程.

Innovation: 
本综述建立在Kartam和Wilkins（1990）的基础之上，首次全面系统地概述了当前的LLM规划器，提出了六项关键性能标准：完备性、可执行性、最优性、表示、泛化和效率。此外，通过深入分析代表性作品，指出了这些系统的优缺点，提供了未来研究的关键方向，为领域内的研究者提供了宝贵的参考.

Conclusion: 
本文提供的全面综述和评估标准将有助于更好地理解和应用LLM规划，为专业人士和新兴研究者提供支持，以有效推动代理工作流程的规划过程。未来的研究应继续探索和优化这些关键性能标准，以进一步提高LLM在规划任务中的表现.</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.11221</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>140. cs.AI-系统思维方法在算法公平性中的应用</title><link>https://arxiv.org/pdf/2412.16641</link><description>Background: 
系统思维提供了一种通过编码数据生成过程中的偏差所在之处的先验知识和假设，来建模算法公平性问题的方法，并允许我们将这些信念转化为一系列因果图，从而将AI/ML系统与政治和法律链接起来。这使我们能够结合机器学习、因果推断和系统动力学技术，捕捉公平性问题的不同涌现特性。系统思维有助于跨党派的政策制定人员理解不同类型公平性政策存在的复杂权衡，并提供一种社会技术基础，以设计与政治议程和社会共享的民主价值观相一致的AI政策。

Innovation: 
提出了一种基于系统思维的方法，通过编码偏差所在之处的先验知识和假设，将算法公平性问题建模，并通过因果图将AI/ML系统与政治和法律链接起来。这种方法还结合了机器学习、因果推理和系统动力学技术，以捕捉公平性问题的不同涌现特性。这种方法有助于跨党派的政策制定者理解不同类型公平性政策的复杂权衡，为设计更符合政治议程和社会共享民主价值观的AI政策提供了社会技术基础。

Conclusion: 
通过系统思维方法，可以更好地理解算法公平性问题中的复杂权衡，并提出更符合社会共享民主价值观的AI政策。这是从技术和社会层面综合考虑政策制定的基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.16641</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>141. cs.AI-Multimodal Large Language Models的推理局限性：Bongard问题的案例研究</title><link>https://arxiv.org/pdf/2411.01173</link><description>Background: 
抽象视觉推理(AVR)涉及通过类比在图像中发现共享概念，类似于解决智力测试问题。Bongard问题(BPs)一直是AVR的关键挑战，需要视觉推理和口头描述。本文探讨了多模态大型语言模型(MLLMs)是否能够通过制定一系列针对MLLMs优化的解决策略来解决BPs。使用4个专有和4个开源模型对包含合成(经典BPs)和现实世界(Bongard HOI和Bongard-OpenWorld)图像的3个BPs数据集进行了测试。尽管在现实世界数据集上有一定成功，但MLLMs在合成BPs上表现不佳。为了解这个差距，引入了Bongard-RWR数据集，使用现实世界图像表示合成BP概念。实验发现，MLLMs在经典BPs上的弱表现不是由于领域特异性，而是来自于它们一般的AVR限制。

Innovation: 
提出了针对MLLMs优化的解决BPs的策略，引入了Bongard-RWR数据集，采用现实世界图像表示合成BP概念，发现了MLLMs在经典BPs上的表现不佳原因不在于领域特定性，而在于其一般的AVR局限性。

Conclusion: 
MLLMs在BPs上的性能不佳不是因为数据集的特定领域性，而是由于更广泛的AVR局限性。提供的代码和数据集可在以下网址获取：this https URL</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.01173</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>142. cs.AI-视觉语言模型中的奉承：系统分析及推理时的缓解框架</title><link>https://arxiv.org/pdf/2408.11261</link><description>Background: 
大型视觉语言模型（LVLMs）在视觉语言理解方面表现出显著的能力。然而，这些模型中存在一个关键问题：奉承现象，即模型受到引导性或欺骗性指令的影响，导致产生有偏见的输出和幻觉。尽管LVLMs迅速发展，但在这些模型中的评价和减轻奉承现象方面仍存在很大程度上的未开发领域。

Innovation: 
本文通过系统分析多模态基准数据集中的奉承现象，并提出了一种推理时的缓解框架。该框架首先利用语言模型对用户查询进行中立化处理，抑制隐含的奉承偏见。随后引入一种察觉奉承现象的对比解码机制，通过对比经过中立化和引导性查询的响应来动态重新校准标记级输出分布。最后，一个自适应概率修正模块进一步通过集成自适应可信赖性筛选器和查询情感缩放器来修正对比后得到的概率，确保生成结果的一致性和稳健性。

Conclusion: 
大量的实验表明，本文提出的框架能够有效地减轻所有评估模型中的奉承现象，同时在中立提示下保持性能。结果表明，LVLMs中的奉承现象是一个普遍和紧迫的挑战，推理时刻的策略可能为可信赖的多模态推理提供一条令人鼓舞的道路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.11261</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>143. cs.AI-使用公理化频谱重要性分解解释图像模型的总体扰动鲁棒性</title><link>https://arxiv.org/pdf/2408.01139</link><description>Background: 
扰动鲁棒性评估模型因各种扰动（如数据损坏和对抗性攻击）而产生的脆弱性。理解扰动鲁棒性的机制对于全局解释至关重要。现有工作虽然提供了鲁棒性基准，但并没有直接解释图像模型中扰动鲁棒性的机制。研究发现，扰动自然图像的频谱信噪比(SNR)随频率指数衰减，表明低频信号通常比高频信号更鲁棒，但仅凭低频信号无法获得高分类精度。

Innovation: 
提出了一种模型无关的全局机制解释方法——I-ASIDE（图像公理化频谱重要性分解解释），该方法通过Shapley值理论在信息论框架下公理性地量化鲁棒特征和非鲁棒特征的预测力，为模型鲁棒性机制提供了新的见解。并通过在预训练的多种视觉模型上进行实验，证明了I-ASIDE不仅可以测量扰动鲁棒性，还能解释其机制。

Conclusion: 
I-ASIDE方法在多种图像模型上展示了卓越的性能，不仅能够衡量扰动鲁棒性，还能够提供对其机制的解释，这标志着对图像模型鲁棒性机制理解的一大进步。</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.01139</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>144. cs.AI-一次性评估LLMs的多个问题</title><link>https://arxiv.org/pdf/2406.10786</link><description>Background: 
传统的单问题评估模式中，提示提供单一问题并期望一个特定的答案。本文提出了一种新的评估模式，即多问题评估（MPE），其特点是将多个问题集中在一个提示中，要求模型在一次输出中回答所有问题。研究者使用已有的6个分类基准和12个推理基准，创建了一个新的基准测试——ZeMPE，包含了53,100个零样本多问题提示，对13种来自5个模型系列的LLMs进行了实验，以展现多问题评估的全面和系统性方法。研究结果显示，LLMs不仅能处理单个数据源中的多个问题，也能逐一解答这些问题，但有时在同时处理多个问题时会遇到瓶颈。此外，该研究还深入分析了各模型层面的因素，探讨了提升LLMs多问题处理能力的可能性。最后，研究成果的语料库和代码将被公开，以促进未来的研究。

Innovation: 
本文创新性地提出了一种新的评估模式——多问题评估（MPE），并构建了一个名为ZeMPE的基准测试，能够在一次输出中同时评估模型对多个问题的解答能力。这项研究填补了以往单问题评估模式的空白，提供了全面和系统的多问题评估方法。

Conclusion: 
研究结果表明，LLMs在处理多个来自单一数据源的问题时表现出色，但有时需要特定的条件和策略来提升其多问题处理能力。此外，研究还指出了影响多问题处理能力的具体模型层面的因素，这些发现将为未来的研究提供重要参考。</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.10786</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>145. cs.AI-人工智能与社会困境</title><link>https://arxiv.org/pdf/2309.10448</link><description>Background: 
在使用生成型人工智能（AI）时，用户可能会看到生产率方面的提升，但AI生成的内容可能不完全符合用户的具体需求。作者引入了一个贝叶斯框架，研究了用户如何在输出保真度和沟通成本之间权衡，分享信息给AI的程度不同。研究表明，个体水平上的决策与AI训练之间的相互作用可能导致社会问题，如输出的同质化现象，特别是在AI被训练于生成内容时，这可能引发同质化的死亡螺旋，同时任何AI偏见也可能扩散为社会偏见。

Innovation: 
作者提出了一种贝叶斯框架，该框架允许用户在输出保真度和沟通成本之间做出选择，并研究了这种选择如何影响个体与AI之间的互动及社会层面的问题。强调了同质化死亡螺旋和偏见传播的风险，并提出了解决这些问题的方法，即减少人类与AI的互动障碍，让用户灵活地分享信息，从而实现个性化输出而不牺牲生产力。

Conclusion: 
解决方案包括减少人类与AI的互动摩擦，让用户能够灵活地共享信息，这样可以实现个性化的输出，而不牺牲生产力。同时，应着重关注输出同质化和偏见传播的问题，以促进更加包容和个性化的人工智能使用环境。</description><guid isPermaLink="true">https://arxiv.org/pdf/2309.10448</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>146. cs.AI-RPLKG: Robust Prompt Learning with Knowledge Graph</title><link>https://arxiv.org/pdf/2304.10805</link><description>Background: 
大规模预训练模型在跨多种数据集的迁移能力和鲁棒泛化方面表现优于传统的单模态模型。多模态预训练模型如CLIP在各种实验中表现出色，但也存在将模型应用于新数据集或领域时的泛化能力不足问题，尤其是当数据标签量有限时。此外，现有方法往往缺乏可解释性，并且会带来较高的计算成本。已有研究尝试通过提示学习来提升模型的灵活性和适应性，但依然存在诸多挑战。

Innovation: 
本文提出了一种名为Robust Prompt Learning with Knowledge Graph (RPLKG) 的方法，利用知识图谱自动构建多样且可解释的提示集。RPLKG 能够根据数据集的特征自动生成最佳的可解释提示，其优势包括：1) 在零样本学习的基础上提升了性能；2) 与多种提示学习方法相比具有竞争力；3) 通过单次模型运行缓存提示嵌入，降低内存消耗，加速训练过程；4) 优化提示选择过程，提高少量样本学习的效果，增强模型的适配性和效率。

Conclusion: 
RPLKG 方法有效地提高了少量样本学习的效果，增强了模型的鲁棒性与适应性，同时提高了模型的可解释性和训练效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2304.10805</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>147. cs.AI-在大型部分可观测环境中的一种智能辅导系统</title><link>https://arxiv.org/pdf/2302.02785</link><description>Background: 
人工智能不仅可以超越人类在许多规划任务中的表现，还能教人类更好地规划。先前的工作已经证明，利用人工智能自动发现和教授最优规划策略的智能导师可以改善这种规划。然而，现有的大部分规划任务都是完全可观察的，而很多现实世界中的人们需要规划的任务则包含部分可观测的特性。鉴于此，该研究开发并评估了第一个在部分可观测环境中进行规划的智能导师，旨在填补该领域的空白。

Innovation: 
这项创新研究结合了两点新发明：1) 一种新型元推理算法，用于发现大型部分可观测环境下的最优规划策略，2) 通过引导学习者从可用的规划操作集中逐步选择来塑造学习过程，逐步解决更大规模的规划问题。

Conclusion: 
研究发现，新的策略发现算法优于当前最先进的方法。预注册的330名参与者实验表明，新的智能导师在改善人们在部分可观测环境中的决策能力方面非常有效。这表明智能认知导师可以成功提升复杂部分可观测顺序决策问题中的人类规划能力，该工作为使用人工智能驱动的智能导师改善人类在现实世界中的规划提供了有前景的一步。</description><guid isPermaLink="true">https://arxiv.org/pdf/2302.02785</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>148. cs.AI-响应性、工具控制性和影响的激励</title><link>https://arxiv.org/pdf/2001.07118</link><description>Background: 
本文介绍了描述智能体激励的三个概念：响应激励、工具控制激励和影响激励。这些概念旨在理解智能体在决策过程中受到哪些因素影响，以及智能体是否试图控制其环境中的某些部分，并探讨了这些概念的图形判据和生成技术。背景信息显示，该研究关注确保智能体行为的安全性和公平性。此外，还讨论了这些概念如何扩展到多决策设置中。

Innovation: 
本文提出了响应激励、工具控制激励和影响激励这三个概念，并为每个概念建立了一套严格的图形判据，还讨论了用于生成这些激励的通用技术类别。此外，文章还介绍了如何将这些概念扩展至多决策情境中的方法。文章是对先前会议论文的扩展，更新了响应激励和工具控制激励的内容，同时加入了新的关于影响激励和多决策设置的研究成果。

Conclusion: 
本文提出的方法和概念为进一步研究如何激励智能体展现安全和公平的行为提供了理论基础，并为多决策情境下的应用奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2001.07118</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>149. cs.AI-视觉作为一种方言：通过文本对齐表示统一视觉理解和生成</title><link>https://arxiv.org/pdf/2506.18898</link><description>Background: 
当前研究主要集中在利用大型语言模型（LLM）来理解和生成图像和文本内容，但这些方法通常需要对视觉和文本数据进行独立处理，缺乏高效的跨模态交流接口。这篇论文提出了一种多模态框架，旨在通过共享离散语义表示来统一视觉理解和生成。TA-Tok（文本对齐分词器）是其核心组件，能够利用LLM词汇表中的文本对齐码本，将图像转换为离散标记。

Innovation: 
1. 提出了文本对齐分词器（TA-Tok），将图像转换为离散标记，与大型语言模型的词汇表对齐。n2. 设计了可扩展的编码和解码方法来平衡效率和视觉细节。n3. 引入生成解码器以生成高质量的视觉输出。n4. 提出了使用两种互补的解码器模型的方法，以适应不同的解码需求。n5. 通过高级前置任务优化模态融合，提升视觉理解和生成的性能。n6. 实验结果显示，所提出的Tar多模态LLM在多个基准测试上与现有方法持平或超越，具备更快的收敛速度和更高的训练效率。

Conclusion: 
通过引入共享的离散语义表示，Tar框架实现了多模态LLM的统一视觉理解和生成，同时保持了高效的跨模态交互。该模型达到了或超过了现有的多模态LLM方法，并且展示了更好的训练效率和更快的收敛速度。相关代码、模型和数据已开源。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18898</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>150. cs.AI-MinD: 通过分层世界模型实现统一的视觉想象和控制</title><link>https://arxiv.org/pdf/2506.18897</link><description>Background: 
视频生成模型（VGMs）为机器人领域的统一世界建模提供了一条有希望的途径，通过整合仿真、预测和操作。然而，由于1）生成速度较慢，限制了实时交互；2）想象视频与可执行动作之间的一致性较差，其实际应用仍受到限制。本文分析了这一领域面临的挑战及现有技术的局限性。

Innovation: 
我们提出了MinD，一种基于分层扩散的世界模型框架，采用基于视觉语言的操作的双系统设计。MinD以低频率执行VGM以提取视频预测特征，同时利用高频扩散策略进行实时交互。此外，我们引入了视频动作扩散匹配模块（DiffMatcher）及一种创新的协同训练策略，用于在训练期间对两个扩散模型的中间表示进行对齐，从而帮助快速动作模型更好地理解基于视频的预测。进一步，MinD还作为世界模拟器，能够在执行前在潜在空间中可靠地预测任务的成功或失败。这种结构在多个基准测试中的实验证明在RL-Bench上实现了最先进的操作性能，取得了巨大进步。

Conclusion: 
我们的研究通过提供一种新的方法，即MinD，解决了机器人领域中视频生成模型面临的挑战，不仅提升了操作性能，还从前端评估任务可行性并减轻风险。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18897</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>151. cs.AI-CommVQ: 共轭矢量量化方法用于KV缓存压缩</title><link>https://arxiv.org/pdf/2506.18879</link><description>Background: 
大型语言模型（LLMs）在需要长上下文的应用中越来越广泛，但随着上下文的增长，关键值（KV）缓存经常成为GPU内存瓶颈。为了应对这一问题，研究提出了一种名为共轭矢量量化（CommVQ）的方法，显著减少了长上下文LLM推理时的内存使用量。该方法首先使用轻量级编码器和码本对KV缓存进行添加量化，压缩后的缓存可以使用简单矩阵乘法进行解码。为了进一步降低解码过程中的计算成本，设计的码本与旋转位置嵌入（RoPE）相互兼容，并通过期望最大化（EM）算法进行训练。这使得解码过程可以高效地集成到自注意力机制中。

Innovation: 
该研究提出了共轭矢量量化（CommVQ）方法，包括一种轻量级的添加量化方式，通过旋转位置嵌入（RoPE）相互兼容的码本和期望最大化（EM）算法进行训练，实现了高效的解码过程集成到自注意力机制中。该方法在保持高准确性的前提下，通过2位量化将FP16 KV缓存大小减少了87.5%，并能够以极低的开销支持1位KV缓存量化，使得LLaMA-3.1 8B模型能够在单个RTX 4090 GPU上运行128K的上下文长度。

Conclusion: 
该方法在长上下文基准测试和GSM8K数据集上优于现有最好的KV缓存量化方法，展现了CommVQ在缓存压缩方面的优势，为大规模语言模型的应用提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18879</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>152. cs.AI-OmniGen2：探索高级多模态生成</title><link>https://arxiv.org/pdf/2506.18871</link><description>Background: 
本文介绍了OmniGen2，一种多功能且开源的生成模型，旨在提供统一的解决方案，涵盖文本到图像生成、图像编辑和情境生成等多样化的生成任务。OmniGen2的设计理念是基于现有模型改进，通过分隔文本和图像解码路径，利用不同的参数和去耦合的图像分词器，达到了更高的灵活性和兼容性。该工作还涵盖了从数据构建到专用反射数据集的全面解决方案，以支持模型的训练和评估，尤其是在情境生成这种基于主题的任务方面提出了一个新的基准，即OmniContext。

Innovation: 
与之前的OmniGen v1相比，OmniGen2具有两种不同的解码路径，分别针对文本和图像模态，并且不共享参数，同时采用去耦合的图像分词器。这种设计使得新模型能够在不影响原始文本生成能力的情况下，增强自身在多模态理解模型上的应用。此外，作者还开发了全面的数据构建管道和特有的反射机制，并构建了一个专用的数据集，这些改进使得OmniGen2在多项任务基准测试上达到了与现有参数规模较大的模型相当的结果，尤其在情境生成任务中表现突出。

Conclusion: 
OmniGen2将被公开发布，包括模型、训练代码、数据集和数据构建管道等，支持未来的研究工作。此外，作者还提出了一个新的基准——OmniContext，用于进一步评估情境生成等任务。本研究不仅推进了多模态生成模型的设计，还为研究者提供了丰富的资源，有助于该领域的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18871</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>153. cs.AI-OmniAvatar：具有自适应身体动画的高效音频驱动化身视频生成</title><link>https://arxiv.org/pdf/2506.18866</link><description>Background: 
尽管在音频驱动的人体动画方面已经取得了显著进展，但目前大多数方法主要集中在面部动作上，限制了其在创建自然同步和流畅的全身动画方面的能力。此外，这些方法在精确的语言提示控制精细生成方面的表现也存在困难。

Innovation: 
提出了一种名为OmniAvatar的创新音频驱动的全身视频生成模型，它通过改进唇部同步准确性和自然动作来提升人体动画。OmniAvatar引入了像素级多层次音频嵌入策略，以更好地在潜在空间中捕捉音频特征，从而增强不同场景的唇部同步能力。此外，OmniAvatar采用LoRA基训练方法，既能保持基础模型的提示驱动控制能力，又能有效地融合音频特征。

Conclusion: 
大量的实验表明，OmniAvatar在面部和半身视频生成方面都超过了现有的模型，并提供了精确的文字控制，可以用于各种领域，如播客、人类互动、动态场景和唱歌。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18866</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>154. cs.AI-TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting</title><link>https://arxiv.org/pdf/2506.18862</link><description>Background: 
卫星图像时间序列分析需要精细的空时推理能力，而现有的多模态大语言模型（MLLMs）在这方面的表现仍然存在挑战。这项工作研究了MLLMs在一项新任务上的能力，该任务旨在理解时间和预测未来场景的变化，从而评估其在时间上建模复杂多模态动态的潜力。研究发现，现有的MLLMs在理解和预测卫星图像变化方面存在不足，特别是在空时推理和上下文提示方面需要改进。

Innovation: 
提出了一个基于时序感知的多模态模型TAMMs，它通过引入轻量级的时序模块增强冻结的MLLMs，实现了结构化的序列编码和上下文提示。TAMMs还引入了语义融合控制注入（SFCI）机制，能够根据时间和语义信息自适应地生成未来的卫星图像。这种方法能够实现时间一致且语义相关的图像合成，从而提高了在时间和未来场景预测上的表现。

Conclusion: 
实验表明，TAMMs在时间变化理解和未来图像预测两个任务上都超过了强大的MLLM基线模型，证明了精心设计的时间推理和语义融合是发挥MLLMs空间和时间理解潜力的关键。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18862</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>155. cs.AI-Mechanistic Interpretability Needs Philosophy</title><link>https://arxiv.org/pdf/2506.18852</link><description>Background: 
机制可解释性（MI）旨在通过揭示神经网络背后的原因机制来解释其运行方式。随着该领域影响力的增加，重要的是不仅要研究模型本身，还要研究机制可解释性研究中隐含的假设、概念和解释策略。研究者认为，机制可解释性需要哲学：不是作为附属部分，而是作为一种持续参与的概念澄清、方法改进以及解释人工智能系统的知识和伦理价值评估的合作伙伴。

Innovation: 
1. 强调了机制可解释性中哲学的作用，认为哲学不只是事后补充，而是应当与机制可解释性研究持续合作，共同推动概念澄清、方法改进及伦理评估的进步。2. 通过机制可解释性文献中的三个开放问题，展示了哲学可以为机制可解释性研究带来哪些价值，并概述了一条深化跨学科对话的途径。

Conclusion: 
机制可解释性研究需要哲学的深度介入，以促进概念澄清、方法改进及伦理评估；通过哲学与机制可解释性的合作，可以推动机制可解释性在人工智能研究中的应用和发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18852</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>156. cs.AI-LongWriter-Zero: 通过强化学习掌握超长文本生成</title><link>https://arxiv.org/pdf/2506.18841</link><description>Background: 
超长文本生成是大语言模型（LLMs）面临的一个重要应用场景，但目前仍面临显著挑战，主要由于其生成长度的限制和随着序列长度增加的整体质量下降。虽然已有方法，如LongWriter，通常依赖于对合成长格式输出进行监督微调（SFT），但这种方法高度依赖于难以构建且成本高昂的标注或合成数据，且数据常缺乏一致性并显得过于人工且结构单调。

Innovation: 
本文提出了一种基于激励的方法，这种方法完全从零开始，不依赖于任何标注或合成数据，而是利用强化学习（RL）在基础模型（类似R1-Zero）的引导下，通过推理促进计划和改善写作过程中的生成质量。为此，采用专门的奖励模型引导LLM实现更好的长度控制、写作质量以及结构性格式化。实验结果显示，从Qwen2.5-32B训练的LongWriter-Zero模型在长格式写作任务上优于传统SFT方法，在WritingBench和Arena-Write上达到最先进水平，甚至超越了100B+的大模型DeepSeek R1和Qwen3-235B。

Conclusion: 
我们的LongWriter-Zero模型在长格式写作任务上的表现优于传统SFT方法，并在WritingBench和Arena-Write上达成了最先进的结果，甚至超越了100B+的大模型DeepSeek R1和Qwen3-235B。我们还开源了数据和模型检查点。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18841</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>157. cs.AI-理解软件工程代理：思想-行动-结果轨迹研究</title><link>https://arxiv.org/pdf/2506.18824</link><description>Background: 
大型语言模型（LLM）驱动的代理被广泛用于自动执行复杂软件工程任务，如程序修复和问题解决。这些代理通过自主生成自然语言思想、调用外部工具并迭代优化解决方案来工作。尽管它们被广泛应用，但这些代理的内部决策过程仍然未被广泛探索，限制了我们对其工作动态和失败模式的理解。本研究通过大规模实证分析揭示了三个先进LLM驱动代理的行为模式和反模式，为代理设计提供了实用建议，包括提示策略、故障诊断和反模式检测。

Innovation: 
本研究首次详细分析了三种先进LLM驱动代理的思想-行动-结果轨迹，提供了统一的交互日志格式，全面捕捉了120条轨迹和2822次LLM互动。研究结合了定量分析和定性评估，揭示了成功和失败执行的行为模式和反模式，这将有助于透明和可靠的自主软件工程代理的研究和发展。

Conclusion: 
本研究揭示了成功执行和失败执行之间的关键差异，并提出了改进代理设计、故障诊断和反模式检测的实用建议。研究结果为透明和稳健的自主软件工程代理提供了行动指导。同时，研究数据和标注框架也被公开，以支持未来的研究工作。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18824</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>158. cs.AI-RWESummary: 一个选择大型语言模型总结真实世界证据(RWE)研究的框架与测试</title><link>https://arxiv.org/pdf/2506.18819</link><description>Background: 
大型语言模型（LLMs）在通用摘要任务和医疗研究辅助方面得到了广泛评估，但尚未专门针对从RWE研究结构化输出中总结真实世界证据（RWE）的任务进行评估。为此，作者引入了RWESummary，这是一个计划添加到MedHELM框架中的工具，旨在为评估LLMs在这一任务上的性能提供基准。RWESummary包含一个场景和三项评估，涵盖了在医学研究总结中观察到的主要错误类型。该框架利用Atropos Health的专有数据开发而成。

Innovation: 
RWESummary旨在填补大型语言模型在总结真实世界证据研究方面的评估空白，通过一个具体框架和测试方法，它能够帮助识别最优的大型语言模型，特别是在总结RWE方面的表现。此外，RWESummary为构建RWE研究工具提供了一个新的基准平台，并且展示了不同大型语言模型在内部RWE摘要工具中的表现差异。研究还指出，Gemini 2.5模型（包括Flash和Pro版本）在13个不同的RWE研究中表现最佳。

Conclusion: 
研究建议RWESummary作为真实世界证据研究总结的一个新颖而有用的基础模型基准，可以指导未来的研究和工具开发。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18819</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>159. cs.AI-OC-SOP: 通过对象中心化意识增强基于视觉的3D语义占用预测</title><link>https://arxiv.org/pdf/2506.18798</link><description>Background: 
自动驾驶感知面临显著挑战，尤其是在环境中由于遮挡和不完整场景数据。现有方法通常采用基于局部特征的全类别平等处理方式，导致动态前景物体预测效果欠佳。为此，本研究提出了一种新方法，即对象中心化语义占用预测（OC-SOP），该方法通过检测分支提取高层对象中心化线索，并将其集成到语义占用预测管道中，显著提高了前景物体的预测精度，并在SemanticKITTI上实现了最先进的性能。

Innovation: 
提出了对象中心化语义占用预测（OC-SOP）框架，该框架通过检测分支提取高层对象中心化线索并集成到语义占用预测管道中，显著提高了前景物体的预测精度，并在所有类别上实现了当前最先进的性能。

Conclusion: 
本文提出的方法OC-SOP通过对象中心化线索显著增强了基于视觉的3D语义占用预测性能，尤其在动态前景物体预测方面。该方法在SemanticKITTI数据集上达到了最先进的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18798</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>160. cs.AI-Shift Happens: Mixture of Experts based Continual Adaptation in Federated Learning</title><link>https://arxiv.org/pdf/2506.18789</link><description>Background: 
联邦学习（FL）能够在不分享原始数据的情况下，在分布式客户端之间进行协作模型训练，但在现实世界环境中面临显著挑战，因为客户端数据分布会随着时间动态变化。这种动态变化的数据分布会降低模型性能，需要适应性强的中间件解决方案来应对漂移问题。现有的联邦学习方法在处理漂移问题时往往表现不佳，尤其是在非稳定数据环境下。本文针对动态环境下联邦学习中的协变量和标签漂移问题进行研究，提出了ShiftEx框架，通过动态创建和训练专门处理数据漂移的全局模型，提高模型在面对数据变化时的适应性。

Innovation: 
本文提出了一种名为ShiftEx的适应性混合专家框架，该框架能够在检测到数据分布变化时动态创建和训练专门的全局模型，使用最大均值差异（Maximum Mean Discrepancy）来识别协变量漂移，并结合隐含记忆机制和设施位置优化方法，以最小化协变量不匹配、专家构建成本和标签不平衡。该框架在多种间断性漂移场景中展现出5.5%-12.9%的准确率提升和22%-95%的更快适应速度，相比现有最先进的联邦学习基线方法，提供了更加高效和稳定的解决方案。

Conclusion: 
本文提出的ShiftEx框架提供了一种可扩展且隐私保护的中间件解决方案，适用于在非稳定和现实世界条件下操作的联邦学习系统，能够在减少通信和计算开销的同时有效应对数据漂移带来的挑战。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18789</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>161. cs.AI-SWA-SOP: 空间知觉窗口注意力在自主驾驶中的语义占用预测</title><link>https://arxiv.org/pdf/2506.18785</link><description>Background: 
自主驾驶的感知系统依赖于激光雷达和摄像头等传感器来感知3D环境。然而，由于遮挡和数据稀疏性，这些传感器往往无法捕获完整信息。为了解决这一挑战，提出了语义占用预测(SOP)，通过推断未观察到区域的占用和语义。现有的基于变换器的SOP方法在注意力计算中缺乏对空间结构的显式建模，导致几何意识有限，在稀疏或遮挡区域性能不佳。

Innovation: 
我们提出了空间感知窗口注意力(SWA)，这是一种新颖的机制，将局部空间上下文纳入到注意力计算中。SWA显著提高了场景补全，并在基于激光雷达的SOP基准测试中获得了最先进的结果。进一步通过将SWA集成到基于摄像头的SOP管道中，我们在不同模态上实现了一致的性能提升，验证了其通用性。

Conclusion: 
SWA-SOP在自主驾驶的语义占用预测中引入了空间感知窗口注意力机制，显著提升了在稀疏或遮挡区域的表现，并且该方法展示了不同传感器数据下的通用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18785</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>162. cs.AI-使用广义多项式混沌进行图像分类模型的灵敏度分析</title><link>https://arxiv.org/pdf/2506.18751</link><description>Background: 
将先进的通信协议集成到生产中，加速了数据驱动的预测质量方法的采用，特别是机器学习（ML）模型。然而，这些模型在图像分类中的输出经常受到模型、数据和领域转移带来的显著不确定性的影响。这些不确定性使模型在分类输出上显得过于自信。为更好地理解这些模型，灵敏度分析有助于分析输入参数对输出的影响。本文研究了用于预测质量的图像分类模型的灵敏度。通过将输入分布性的领域转移建模为随机变量，并采用广义多项式混沌（GPC）计算的Sobol指数量化其对模型输出的影响来验证这一做法

Innovation: 
提出了一种使用随机变量建模输入分布性领域转移的方法，并采用广义多项式混沌（GPC）计算的Sobol指数来量化对模型输出的影响，这是在图像分类模型的灵敏度分析中的一个创新方法，通过BMW集团生产设施中的焊接缺陷分类问题进行了案例研究验证

Conclusion: 
研究表明，使用广义多项式混沌方法计算的Sobol指数可以有效地评估图像分类模型在面对数据和领域转移时的输出敏感度，这对于改进模型预测质量具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18751</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>163. cs.AI-BRAVE：具备语音集成和嵌入式学习的脑控假肢</title><link>https://arxiv.org/pdf/2506.18749</link><description>Background: 
非侵入式脑-计算机接口（BCIs）有可能为上肢截肢患者提供直观控制假肢的功能。然而，现有的基于EEG的控制系统面临着信号噪声、分类准确性和实时适应性的挑战。本文介绍了一种名为BRAVE的混合EEG和语音控制假肢系统，该系统结合了基于集成学习的EEG分类和人工在环（HITL）校正框架，以增强响应性。BRAVE旨在解释EEG驱动的运动意图，而不依赖于剩余肌肉活动，从而实现运动控制。

Innovation: 
BRAVE系统通过结合LSTM、CNN和随机森林模型的集成框架来提高分类的鲁棒性，实现96%的分类准确率，还引入了自动语音识别（ASR）功能，使用户能够直观地在假肢的不同自由度之间切换模式。BRAVE系统具有150ms的实时响应延迟，支持同步数据采集。该系统经过在自建假肢臂和多名参与者上的评估，彰显了其跨用户的一般适应性。BRAVE系统还优化了低功耗嵌入式部署，确保其实用的现实世界应用，而不仅仅是高性能计算环境中的应用。

Conclusion: 
BRAVE提供了一种有前景的步骤，朝着稳健、实时、非侵入性的假肢控制方向迈进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18749</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>164. cs.AI-ContinualFlow：通过神经流匹配学习和遗忘</title><link>https://arxiv.org/pdf/2506.18747</link><description>Background: 
该研究背景在于，当前的生成模型在需要从未训练数据中移除特定区域时存在一些挑战，例如无法直接从样本重新训练或不需要样本即可移除特定数据区域。同时，现有的生成模型在处理此类问题时通常是通过重新训练模型来实现的，这不仅增加了训练时间，还可能会导致模型性能下降。因此，需要一种既高效又能够满足需求的方法来实现目标数据区域的移除，而无需重新训练模型。

Innovation: 
该研究引入了ContinualFlow框架，这是一种基于Flow Matching的原则性方法，用于生成模型中的定向遗忘。其创新点在于，该方法利用能量基础的重新加权损失，通过软性去除数据分布中的特定区域来实现目标，整个过程无需从头开始重新训练，也不需要直接访问要遗忘的样本。方法依赖于能量基础的代理来指导遗忘过程，这种方法能够诱导出等同于Soft Mass Subtracted的目标的梯度，同时支持可解释的可视化和定量评估，以验证方法的有效性。

Conclusion: 
通过理论证明和实验验证，该研究证明了ContinualFlow方法的有效性和可行性。该方法能够在保持模型性能的同时实现对特定区域的软性遗忘，为未来的研究提供了新的思路和技术支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18747</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>165. cs.AI-关于注意力机制通用模拟器的存在性</title><link>https://arxiv.org/pdf/2506.18739</link><description>Background: 
先前的研究表明，通过在严格的架构假定下进行训练，变压器能够逼近特定的算法模式。然而，这些结论本质上是数据驱动的，只能提供概率保证。相比之下，表达能力从理论上探讨了这种架构可计算的问题，证明了变压器的图灵完备性，并调查了与电路复杂度和形式逻辑相关的界限。在此背景下，问题仍然存在：变压器架构能否精确模拟任意注意机制，尤其是其基本操作？

Innovation: 
通过构建由变压器编码器组成的通用模拟器 $ text{U} $，并使用RASP（变压器计算的形式框架）来算法性地复制注意力输出和基本矩阵与激活操作，这一研究首次证明了存在一种算法可实现的数据无关解决方案，此前仅通过学习进行逼近.

Conclusion: 
这项研究表明，变压器可以精确模拟任意的注意机制及其基本操作，提出了一种算法性的数据无关解决方案，为理解和利用变压器的通用模拟能力提供了新的视角.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18739</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>166. cs.AI-深度CNN面部匹配器固有支持可撤销生物特征模板</title><link>https://arxiv.org/pdf/2506.18731</link><description>Background: 
生物识别认证存在的一大批评是，如果个体的生物特征被泄露，该个体就无处申诉。为此，可撤销生物特征识别的概念被提出，以解决这一问题。一个生物识别方案是可撤销的，如果个体可以撤销当前的注册，从而使泄露的生物特征模板变得无效，并重新注册具有相似识别能力的新模板。现代的深度卷积神经网络（CNN）面部匹配器被认为能够支持可撤销的生物特征模板。本文研究了基于这种现代深度CNN面部匹配器实现可撤销生物识别方案的可能性，并探讨了基于视觉变换器（ViT）骨干网的面部匹配器在这一系统中的适用性。

Innovation: 
研究发现，现代的深度卷积神经网络（CNN）面部匹配器能够生成具有等同识别能力且生物特征模板高度互斥的多种模型，从而支持可撤销的生物特征识别方案。并且，相比于传统的基于ResNet的深度CNN骨干网，基于视觉变换器（ViT）的面部匹配器在这一系统中使用起来不太适合。

Conclusion: 
现代深度卷积神经网络（CNN）面部匹配器能够支持可撤销生物特征识别方案，这种方案可以有效保护被泄露的生物特征模板，使得这些模板不再有价值。基于视觉变换器（ViT）的面部匹配器在这一系统中并不如基于ResNet的深度CNN骨干网那样适用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18731</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>167. cs.AI-MuseControlLite：轻量化条件器实现多功能音乐生成</title><link>https://arxiv.org/pdf/2506.18729</link><description>Background: 
文本到音乐生成模型在生成音乐的同时，通常需要根据文本条件进行精确的调优，这通常涉及到时间变化的音乐属性和参考音频信号。然而，这些模型往往使用较少的时间位置嵌入，尤其是在条件是时间函数的情况下，这影响了生成音乐的精确度和控制性。为了改善这一问题，研究人员提出了MuseControlLite，这是一种轻量级机制，旨在使用各种时间变化的音乐属性和参考音频信号对文本到音乐生成模型进行微调，以实现精确的条件控制。

Innovation: 
MuseControlLite通过引入旋转位置嵌入到解耦交叉注意层中，提高了音乐控制的准确性，从56.6%提高到61.1%，并且仅需比最先进的微调机制少6.75倍的可训练参数。此外，研究还展示了不同类型的音乐属性控制、音频填充和音频扩展的效果，证明了相比MusicGen-Large和Stable Audio Open ControlNet，在显著降低微调成本的情况下，MuseControlLite具有更好的控制性，仅需85M可训练参数。

Conclusion: 
MuseControlLite通过轻微的可训练参数增加和简单的机制设计，显著提升了文本到音乐生成模型的精确控制能力，并且在不同类型的音乐控制任务中展示了其优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18729</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>168. cs.AI-基于差异图变换器的动态股票关系建模与标普500价格预测研究</title><link>https://arxiv.org/pdf/2506.18717</link><description>Background: 
股票价格预测对于投资决策和风险管理至关重要，但因市场非线性动态特性和时刻变化的跨股票相关性而充满挑战。传统的静态相关性模型无法捕捉股票间不断演变的关系，因此需要新的方法来解决这一问题。通过引入一种新的Differential Graph Transformer (DGT)框架，该研究旨在动态地建模股票关系及其价格预测，以克服这些难题。

Innovation: 
该研究创新性地将差异图结构与Transformer模型结合，提出了Differential Graph Transformer (DGT)框架来解决动态关系建模问题。DGT通过因果时间注意机制捕捉价格序列中全局和局部依赖性，并采用pearson、互信息、spearman、肯德尔秩等多类相关性指标作为空间注意力先验。研究结果表明，使用10年S&amp;amp;P 500收盘价格数据，DGT模型结合空间先验优于GRU基线模型，并且肯德尔秩在全球范围内表现在均绝对误差（MAE）上最优。此外，K-means聚类分析揭示了“高波动成长”和“防御性蓝筹”两类股票，显示出长期稳定的预测效果，特别是在波动性较高的行业中，互信息和肯德尔秩表现出色。该研究通过动态关系建模和跨资产互动分析，推动了金融时间序列预测领域的发展，仍识别出最优的相关性指标和适用范围，支持定制化量化策略。

Conclusion: 
该研究验证了动态关系建模的有效性，并且通过结合差异图结构与Transformer模型，显著改进了标普500指数的价格预测。同时，通过对比不同的相关性指标和适用范围，明确了最优的量化策略，为金融时间序列分析提供了坚实的基础和新的视角。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18717</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>169. cs.AI-基于频域加权训练损失的音素级DNN语音增强</title><link>https://arxiv.org/pdf/2506.18714</link><description>Background: 
近年来，深度学习在多通道语音增强算法中的应用显著提升，但传统的标度不变信噪比（SDR）等训练损失函数可能无法保留对于音素可懂度至关重要的细微频谱线索。本文对此问题进行了分析，探讨了基于感知的SDR损失的变体，这些变体在时频域中优化，并通过频率依赖的权重方案进行调整。这些权重旨在强调语音突出或噪声特别强的时频区域。研究了固定策略和自适应策略，包括ANSI频带重要性权重、光谱幅度基权重以及基于语音和噪声相对量的动态权重。论文使用这些不同的损失函数对FaSNet多通道语音增强模型进行了训练。实验结果显示，虽然标准指标如SDR仅有微小提升，但其感知频率加权版本有较显著提升。另外，频谱和音素级分析表明，辅音重建更好，这表明某些声学线索得到了更好的保留。

Innovation: 
提出了一种感知导向的SDR损失变体，包括固定和自适应的策略（ANSI频带重要性权重、光谱幅度基权重和基于语音与噪声相对量的动态权重），并利用这些方法对FaSNet多通道语音增强模型进行训练。实验结果表明，这些感知频率加权的损失具有显著改进效果。

Conclusion: 
尽管标准SDR指标仅有轻微提升，但其感知频率加权版本表现出显著改进。通过频谱和音素级分析发现，这种方法有助于更好的辅音重建，从而表明保留了某些重要的声学线索。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18714</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>170. cs.AI-大型语言模型的教育知识基准</title><link>https://arxiv.org/pdf/2506.18710</link><description>Background: 
现有的基准测试（如大规模多任务语言理解MMLU）在评估AI的知识和能力方面起到了关键作用，但这些基准大多只关注内容知识，忽视了对教学方法和实践的理解评估。因此，该研究引入了教育知识基准（The Pedagogy Benchmark），旨在评估大型语言模型在跨学科教育知识（CDPK）和特殊教育需求及残疾（SEND）教育知识方面的表现。该基准数据集基于专业教师发展考试中的精心挑选的问题，覆盖了诸如教学策略和评估方法等不同教育子领域。研究表明，97个模型在教学知识问题上的准确率从28%到89%不等，并探讨了成本与准确率之间的关系，绘制了帕累托最优前沿的进展。提供了一个在线排行榜，持续更新模型并允许基于各种模型属性（如每token成本和开放式/封闭式权重）进行交互式探索和筛选，以及查看不同科目中的表现。

Innovation: 
该研究提出了教育知识基准（The Pedagogy Benchmark），这是首个用于评估大型语言模型在教育知识和特殊教育需求及残疾（SEND）方面表现的新数据集。它填补了现有基准测试在评估模型教育理解方面的空白，基于专业教师发展考试中的精心挑选问题，涵盖广泛的教育子领域。此外，该研究还分析了成本与准确率之间的关系，并提供了持续更新的在线排行榜和模型交互式探索功能。

Conclusion: 
大型语言模型和生成性AI在教育领域具有巨大的潜力，能够帮助解决全球学习危机。教育为关注的基准对于衡量模型理解教育概念、适当地响应学习者需求和支持不同背景下有效教学实践的能力是至关重要的。这对于指导LLM及其工具在教育环境中的负责任和证据基础部署、开发和政策决策都至关重要。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18710</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>171. cs.AI-Matrix-Game: 交互式世界基础模型</title><link>https://arxiv.org/pdf/2506.18701</link><description>Background: 
本文介绍了一个名为Matrix-Game的交互式世界基础模型，用于可控的游戏世界生成。Matrix-Game通过一个两阶段的训练管道进行训练，首先是大规模的未标注预训练来理解环境，然后是带有动作标注的插件生成训练。为了支持这一模型，我们收集了一个名为Matrix-Game-MC的全面的Minecraft数据集，包含超过2700小时的未标注游戏视频片段和超过1000小时的高质量标注片段，这些片段带有细粒度的键盘和鼠标操作标注。Matrix-Game采用基于参考图像、运动上下文和用户操作的可控图像到世界生成范式，具备对游戏角色动作和摄像机移动的精准控制，同时保持高视觉质量和时序连贯性。为了评估性能，我们开发了一个统一的基准测试GameWorld Score，用于测量视觉质量、时序质量、动作可控性和物理规则理解对于Minecraft世界的生成。大量实验表明，Matrix-Game在所有指标上都优于之前的开源Minecraft世界模型(Oasis和MineWorld)，尤其是在可控性和物理一致性方面有显著的提升。双盲的人类评估进一步证实了Matrix-Game的优越性，显示其能够生成感知上逼真且精确可控的视频片段，适应各种游戏场景。

Innovation: 
Matrix-Game采用了两个创新点：一是通过大规模的未标注预训练和带有动作标注的插件生成训练相结合的方式进行训练；二是采用一个可控的图像到世界的生成框架，基于参考图像、运动上下文和用户操作进行控制。Matrix-Game在动作可控性和物理一致性方面表现突出，优于现有开源的Minecraft世界模型（包括Oasis和MineWorld）。此外，还开发了GameWorld Score基准测试，用于衡量Minecraft世界的生成质量。

Conclusion: 
Matrix-Game超越了现有开源的Minecraft世界模型，尤其是在动作可控性和物理一致性方面。该模型已经实现了对游戏角色动作和摄像机移动的精准控制，并保持了高视觉质量和时序连贯性。为了促进互动图像到世界生成领域的未来研究，矩阵-游戏的模型权重和GameWorld Score基准测试将开源。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18701</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>172. cs.AI-NOVA: 无地图感知导向的基于对象的视觉自主导航在未结构化和GPS受限环境中的高精度目标跟踪</title><link>https://arxiv.org/pdf/2506.18689</link><description>Background: 
在未结构化和GPS受限的环境中实现自主无人目标跟踪仍然是机器人领域的基本挑战。现有方法依赖于运动捕捉系统、预映射场景或基于特征的定位来确保安全和控制，这限制了它们在现实世界中的应用。因此，需要一种新的方法来解决这个问题，这种方法不需要外部地图或环境假设，能够实现自上而下的实时障碍物避免和目标跟踪。

Innovation: 
我们引入了NOVA，这是一种完全自主、对象中心的框架，仅依赖于立体摄像头和IMU就实现了鲁棒的目标跟踪和碰撞感知导航。NOVA通过在目标参照系中完全实现感知、估计和控制，在不构建全局地图或依赖绝对定位的情况下，优化了轻量级对象检测、立体深度完成和基于直方图的滤波，以实现鲁棒的目标距离估计。NOVA包含一个非线性模型预测控制器，该控制器在目标参考系中规划动态可行的轨迹。NOVA的设计考虑了安全问题，通过实时构建高阶控制约束函数来确保实时障碍物避免，而不依赖于地图或密集表示。

Conclusion: 
我们通过各种复杂的现实世界场景验证了NOVA，包括城市迷宫、森林小径以及在GPS信号时有时无和照明条件恶劣下多次穿越建筑物的情况。这些实验表明，NOVA在一致和可靠的性能下实现了超过50km/h的灵活目标追踪。这些结果证实，在没有外部定位或环境假设的情况下，仅依赖机载传感系统，便可能在野外实现高速视觉跟踪。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18689</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>173. cs.AI-SIM-Net: 使用来自RGB图像推断出的3D对象形状点云的多模态融合网络用于2D分类</title><link>https://arxiv.org/pdf/2506.18683</link><description>Background: 
本文提出了一种新颖的2D图像分类架构——形状-图像多模态网络（SIM-Net），该架构将直接从RGB图像推断出的3D点云表示融合在一起。这项工作的背景在于利用3D点云和纹理特征相结合来提升分类性能，特别是在数字化标本（背景复杂）和遮挡等挑战性条件下更容易实现准确的分类。

Innovation: 
SIM-Net的主要贡献在于像素到点的变换，即将2D对象掩码转化为3D点云，从而实现了基于纹理和几何特征的融合。此外，SIM-Net通过基于分割的预处理步骤来提取对象掩码，并将其与3D点云生成相结合。该架构采用了CNN编码器进行2D图像特征提取，及基于PointNet的编码器进行几何特征提取，将这些特征融合到一个统一的潜在空间。实验证明，与ResNet101相比，SIM-Net在准确性和F分数上分别提高了9.9%和12.3%，并在多个基于变压器的最新架构中也表现出优越性。

Conclusion: 
SIM-Net在数字化植物标本、非植物元素和遮挡等复杂场景中，展现出比传统基于图像的模型更高的分类性能，该工作强调了在2D图像分类任务中结合3D结构推理的优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18683</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>174. cs.AI-基于多尺度光谱注意力模块的自主驾驶场景中高光谱分割</title><link>https://arxiv.org/pdf/2506.18682</link><description>Background: 
近年来，自主驾驶（AD）技术取得了快速发展，特别强调了高光谱成像（HSI）在复杂天气和光照条件下的环境感知方面的潜力。然而，高效处理其高维度光谱数据依然是个重大挑战。本研究聚焦解决了这一问题。

Innovation: 
提出了一种多尺度光谱注意力模块（MSAM），它通过三个并行的1维卷积，卷积核大小在1到11之间动态变化，并结合自适应特征汇聚机制，增强了光谱特征提取。进一步将MSAM整合到UNet的跳跃连接中（UNet-SC），提出的UNet-MSAM模型在多个HSI数据集（HyKo-VIS v2，HSI-Drive v2，Hyperspectral City v2）的语义分割性能上取得了显著提升。通过广泛的消融实验，研究结果表明多尺度核组合的表现优于单一尺度配置。

Conclusion: 
本研究展示了HSI处理技术在自主驾驶中的潜在价值，并为设计适用于实际应用的稳健多尺度光谱特征提取模块提供了重要的参考和理论基础。通过微小的计算开销（平均参数量降低0.02%，GFLOPS减少0.82%），UNet-MSAM模型在三个数据集上分别实现了平均3.61%的平均IoU和3.80%的mF1提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18682</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>175. cs.AI-在大规模语言模型中，是否有为对话优化的分词器的必要性？</title><link>https://arxiv.org/pdf/2506.18674</link><description>Background: 
大规模语言模型（LLMs）的计算成本和能源成本由于模型尺寸的增加和数百万人的广泛应用而呈指数级增长。分词器在模型效率中扮演着重要角色，它们被精心优化以最小化训练语料库中文本的分词数量。在大型语言模型的一个主要应用场景中，聊天机器人的交互引起了研究人员的关注。研究发现，聊天机器人在用户文本输入和生成响应方面的分词性能与训练语料库中的文本可能存在差异，因此探讨是否可以为聊天对话优化分词器的想法变得至关重要。

Innovation: 
本文通过使用一个开源的聊天对话语料库重新设计不同分词器的词汇表，并评估它们在该领域的性能。研究表明，为对话优化的分词器在聊天对话中可以有效地减少分词数量，从而在一定程度上节省能源，大约在5%到10%之间。同时，这种优化对原始训练语料库中的分词效率几乎没有负面或甚至可能带来轻微的正面影响。

Conclusion: 
实验结果表明，为对话优化的分词器能够在不影响或轻微影响模型整体效率的情况下，显著减少聊天机器人对话中的分词数量，从而带来实质性的能源节约。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18674</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>176. cs.AI-在多中心数据集中评估皮肤癌亚型分类的组织病理学基础模型</title><link>https://arxiv.org/pdf/2506.18668</link><description>Background: 
组织病理学基础模型（FM）在大规模、领域的数据集上进行预训练，能够学习任务无关的数据表示，从而提升下游任务的迁移学习能力。在计算病理学中，全切片图像的自动分析需要多实例学习（MIL）框架，因为切片的像素尺寸非常大。组织病理学FM之间的多样性已经凸显了需要设计实际挑战来评估它们的效果。因此，本文提出了一个新的基准，用于评估组织病理学FM作为MIL分类框架中的像素级特征提取器的能力。该基准利用了AI4SkIN数据集，这是一个多中心队列，涵盖了具有挑战性的皮肤肉瘤亚型切片。

Innovation: 
本文介绍了用于评估组织病理学FM的新型基准，该基准用于多实例学习（MIL）分类任务中的像素级特征提取。创新之处在于定义了一个新的模型一致性度量——基础模型轮廓指数（FM-SI），以衡量模型在分布变化时的一致性。实验表明，提取较少偏差的特征可以提高分类性能，特别是在基于相似性的MIL分类器中表现尤为明显。

Conclusion: 
通过使用多中心数据集和AI4SkIN数据集，实验结果表明，从MIL分类任务的角度提取较少偏差的特征能够显著提升组织病理学FM的分类性能。此外，提出的新型模型一致性度量FM-SI为评估和优化组织病理学FM的性能提供了新的工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18668</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>177. cs.AI-Historical Report Guided Bi-modal Concurrent Learning for Pathology Report Generation</title><link>https://arxiv.org/pdf/2506.18658</link><description>Background: 
全视野图像（WSIs）的病理报告自动化生成面临两大挑战：（1）视觉特征缺乏语义内容；（2）WSIs中固有的信息冗余。为了解决这些问题，该研究提出了一种名为BiGen的新型历史报告引导双模并发学习框架，该框架模仿病理学家的诊断推理过程，旨在提高病理报告生成的准确性和全面性。

Innovation: 
BiGen框架包含两个创新点：（1）知识检索机制，通过匹配高关注区域，从预先构建的医学知识库中检索与WSI相关的知识，以提供丰富的语义内容；（2）双模并发学习策略，通过可学习的视觉标记和可学习的文本标记动态提取关键视觉特征和检索知识，实现模态间的交叉对齐。多模解码器结合了视觉和文本模态的信息，以生成全面的诊断报告。实验结果表明，BiGen的方法优于现有方法，在PathText（BRCA）数据集上，在NLP和分类性能上分别提高了7.4%和19.1%，具有极强的优越性。

Conclusion: 
该研究通过BiGen框架在WSIs的病理报告生成上取得了显著的突破，证明了其所提出的知识检索机制和双模并发学习策略的有效性，并且代码已公开发布。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18658</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>178. cs.AI-改善非同质分布数据收敛性的联邦损失探索</title><link>https://arxiv.org/pdf/2506.18640</link><description>Background: 
联邦学习（FL）作为一种在机器学习（ML）中提供隐私保护的协作模型训练范式，已经崭露头角。然而，特别是在非同质独立分布（non-IID）数据场景下，现有的方法往往难以应对数据异质性，并在性能上缺乏鲁棒性。在这种背景下，FL面临着重大挑战。

Innovation: 
本文提出了联邦损失探索（FedLEx）方法，该方法通过优化学习行为，解决非同质分布环境中现有的FL方法的不足之处，特别是在数据异质性假设不成立或未知的情况下。FedLEx通过让客户端计算模型参数的梯度偏差来构建全局指导矩阵，这一矩阵用于指导后续FL轮次中的梯度更新，从而促进全局模型的最优参数更新。FedLEx在无需额外数据共享或数据分布统计的情况下，能够有效导航复杂的损失面，实现模型在少量迭代和少量数据下的快速收敛。

Conclusion: 
通过与最新的FL算法进行大量实验，本文展示了FedLEx在现实的非同质分布数据条件下，具有显著的性能提升，从而突显了FedLEx在多种FL应用中克服关键障碍的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18640</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>179. cs.AI-基于粒球诱导的多核K均值聚类</title><link>https://arxiv.org/pdf/2506.18637</link><description>Background: 
现有的多核聚类算法，如多核K均值，往往在面对复杂数据分布时存在计算效率和鲁棒性问题。这些问题源自于这些算法依赖点对点关系进行优化，难以准确捕捉数据集的内在结构和多样性。此外，这些算法中多个核之间的复杂交互也会进一步加剧这些问题，影响其在高维空间中有效地对数据点进行聚类的能力。

Innovation: 
本文利用粒球计算改进了多核聚类框架。粒球计算的核心是通过从粗到细逐渐适应数据分布的球体。每个球体可以根据密度一致性测量来包含数据点。这样基于粒球的数据描述提高了计算效率和对外部噪声的鲁棒性。具体来说，基于粒球表示，我们引入了粒球核（GBK）和相应的粒球多核K均值框架（GB-MKKM），用于高效聚类。通过在多个核的空间中利用粒球关系，提出的GB-MKKM框架在各种聚类任务的实证评估中显示出在效率和聚类性能上的优越性。

Conclusion: 
基于粒球计算的GB-MKKM框架在效率和聚类性能上表现出色，该方法能够有效提升多核聚类算法的计算效率和鲁棒性，特别是在处理复杂数据分布时。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18637</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>180. cs.AI-ReDit: 改善大型语言模型策略优化的奖励抖动方法</title><link>https://arxiv.org/pdf/2506.18631</link><description>Background: 
DeepSeek-R1 通过其基于规则的奖励系统成功增强了大型语言模型（LLM）的推理能力。尽管该奖励系统有效地缓解了奖励作弊问题，但这些奖励函数往往是离散的。实验观察结果表明，离散奖励可能导致梯度异常、不稳定的优化以及缓慢的收敛。因此，需要一种方法来处理这个问题，以确保优化过程更加高效和稳定。

Innovation: 
提出了 ReDit（奖励抖动）方法，通过对离散奖励信号添加简单的随机噪声来抖动奖励信号。这种方法在整个学习过程中持续提供探索梯度，实现更平滑的梯度更新和更快的收敛。此外，加入的噪声还引入了平坦奖励区域的随机性，促使模型探索新的策略并逃离局部最优解。实验结果表明 ReDit 的有效性和效率。与标准 GRPO 相比，ReDit 通常只需约10%的训练步骤即可达到相似的性能表现，甚至在训练时间相同的情况下还能提高4%的性能。视觉化结果显示 ReDit 显著减轻了梯度问题。此外，还提供了理论分析来进一步验证这些优势。

Conclusion: 
ReDit 通过增强奖励信号的有效性和稳定性，显著改善了大型语言模型的策略优化过程。该方法在多种任务中表现出优异的效果和效率，不仅能加速模型的学习过程，还能提高模型的最终性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18631</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>181. cs.AI-光子集成电路逆向设计中的多智能体强化学习</title><link>https://arxiv.org/pdf/2506.18627</link><description>Background: 
传统的光子集成电路（PICs）逆向设计依赖于基于梯度的优化方法，但这种方法容易陷入局部最小值，导致设计性能不佳。随着对PICs兴趣的增加，由于它们在通过光学计算满足现代硬件需求方面的潜力，需要更具适应性的优化算法。因此，为了提高PIC设计的表现，研究人员提出了使用强化学习（RL）环境及多智能体RL算法来优化PIC设计，尤其是将其设计空间离散化并转化为具有数千个二元变量的优化问题，以应对复杂的多维设计任务。

Innovation: 
该研究创新地将多智能体强化学习（RL）应用到PIC的逆向设计中，通过将设计空间离散化为网格，并将其表述为一个以数千个二元变量为基础的优化问题，提出新的算法可以仅用少量环境样本（数千次样本）来优化设计。这种新方法在二维和三维设计任务中的性能优于之前的基于梯度的优化方法，并提供了一种新的基准，用于进一步探索光子逆向设计中的样本高效强化学习方法。

Conclusion: 
通过这种方法，展现了多智能体强化学习的有效性及其在光子集成电路设计中的潜力，为进一步研究光子学中的样本高效逆向设计提供了新的启示和基准。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18627</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>182. cs.AI-微电网中的频率控制：一种自适应模糊神经网络虚拟同步发电机</title><link>https://arxiv.org/pdf/2506.18611</link><description>Background: 
分布式可再生能源的依赖性近年来有所增加，这导致了基于电力电子的分布式发电系统取代了同步发电机，从而改变了微电网的动态特性。具体来说，这些变化减少了系统的惯性和阻尼。为了应对这些问题，虚拟同步发电机被开发出来，通过电力电子技术模仿同步发电机的动态行为。然而，固定不变的虚拟同步发电机参数无法确保在可接受的容差范围内进行频率调节。因此，动态调整这些虚拟参数能够提供一个稳健的、稳定的频率解决方案。本文的研究背景便是基于此，探讨如何通过一个自适应模糊神经网络控制器来动态调整虚拟同步发电机的关键参数，如惯性、阻尼和下垂参数，以提高微电网的频率控制性能。

Innovation: 
提出了一种通过自适应模糊神经网络控制器来动态调整虚拟同步发电机的惯性、阻尼和下垂参数的方法。该控制器能够在在线学习过程中自我训练，并选择合适的虚拟参数值。研究通过MATLAB/Simulink模型进行了系统研究，并利用嵌入式ARM系统（SAM3X8E，Cortex-M3）进行实时硬件在环实验验证。相比传统的和模糊逻辑控制器方法，实验结果显示所提出的方法显著减少了频率偏差，并缩短了稳定/恢复时间。

Conclusion: 
所提出的方法能够显著减少微电网中频率的偏差，并有效缩短稳定/恢复时间，证明了该方法的有效性和可靠性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18611</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>183. cs.AI-无模拟差分动力学的神经守恒律</title><link>https://arxiv.org/pdf/2506.18604</link><description>Background: 
现有方法通常需要指定最优的扩散过程，但仅适用于高度受限的问题表述；或者需要昂贵的模拟来数值计算时间依赖的密度函数并从扩散过程中进行采样。这些方法限制了应用范围和训练效率。本文提出了一种新的无模拟框架，能够针对非常通用的目标函数训练连续时间的扩散过程。这种方法通过直接将Fokker-Planck方程和密度函数要求作为硬约束纳入，并扩展和简化了神经守恒律的构建，从而使得无模拟训练可以应用于多种问题表述，包括数据驱动的目标函数和最优控制目标函数等。

Innovation: 
提出了一个无需模拟的新框架，用于训练连续时间的扩散过程，该框架通过加入Fokker-Planck方程和密度函数要求作为硬约束，显著简化构建神经守恒律的方法，使得多种类型的问题都可以进行无模拟训练。

Conclusion: 
该方法在多种应用领域中得到验证，从建模时空事件到从人口数据学习最优动力学，都证明了其广泛适用性和有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18604</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>184. cs.AI-BulletGen：使用子弹时间生成改进4D重建</title><link>https://arxiv.org/pdf/2506.18601</link><description>Background: 
将随意捕捉的单目视频转换为沉浸式动态体验是一项高度不明确的任务，面临许多挑战，例如重建未见区域和处理单目深度估计的歧义性。因此，现有方法需要进行修正和补全缺失信息。

Innovation: 
BulletGen 引入了一种利用生成模型纠正错误和完成缺失信息的方法，这种方法基于高斯动态场景表示，并通过与单一冻结的“子弹时间”步骤的4D重建对齐生成的视频输出。此外，生成的帧被用来监督4D高斯模型的优化。这种方法成功地将生成的内容与静态和动态场景成分融为一体，实现了在新颖视图合成和2D/3D跟踪任务上的前沿结果。

Conclusion: 
该方法通过结合生成模型和4D场景表示，实现了在处理单目视频重建任务上的优异性能，达到最新的技术水平。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18601</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>185. cs.AI-神经网络中由优化引起的Lipschitz连续性动力学</title><link>https://arxiv.org/pdf/2506.18588</link><description>Background: 
Lipschitz连续性可以表征神经网络对小输入扰动的最坏情况敏感性，尽管其在训练过程中的动态演化（即时间演化）尚未得到充分探索。已有研究主要集中在静态的 Lipschitz 连续性特性上，而对于其在训练过程中的演变规律和动态机制还缺乏深入理解。本文旨在通过数学框架来建模使用随机梯度下降（SGD）训练过程中 Lipschitz 连续性的动态变化，来填补这一空白。

Innovation: 
本文创新地提出了一种结合了确定性和随机动力学的随机微分方程（SDEs）系统，用于描述训练过程中Lipschitz连续性的演变。该理论分析发现了三个主要驱动因素：（i）优化动力学引起的梯度流在参数矩阵算子范数雅克比矩阵上的投影；（ii）来源于批量采样随机性的梯度噪声在参数矩阵算子范数雅克比矩阵上的投影；（iii）梯度噪声在参数矩阵算子范数海森矩阵上的投影。此外，本文的理论框架还揭示了监督噪声、参数初始化、批量大小和批量采样轨迹等因素如何影响Lipschitz连续性的演变。

Conclusion: 
实验结果表明，理论预测与实际观察到的行为之间存在强烈的一致性，证明了所提出模型的有效性，提供了对Lipschitz连续性在训练过程中演变动态的认识。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18588</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>186. cs.AI-DeepSeek和GPT系列模型的破解攻击安全性评估</title><link>https://arxiv.org/pdf/2506.18543</link><description>Background: 
大规模语言模型（LLMs）的广泛部署引发了对其漏洞的关注，尤其是它们可能受到破解攻击的影响。虽然像GPT-4这样的专有模型已经经过了广泛的研究和评估，但新兴的开源替代品如DeepSeek的安全性尚未得到充分探索，尽管它们在实际应用中的使用越来越多。本研究旨在评估DeepSeek系列模型在破解攻击中的安全性，与GPT-3.5和GPT-4进行比较，使用HarmBench基准测试工具。

Innovation: 
本研究首次系统地评估了DeepSeek系列模型在破解攻击中的安全性，利用HarmBench基准测试工具对比了DeepSeek、GPT-3.5和GPT-4在多种有害行为表现上的差异。研究表明，虽然DeepSeek的Mixture-of-Experts（MoE）架构在抵抗基于优化的攻击方面提供了选择性鲁棒性，但在基于提示和手动工程化的攻击下，其安全性显著降低。相比之下，GPT-4 Turbo则表现出更强且更一致的安全对齐。

Conclusion: 
研究揭示了架构效率与对齐泛化的根本性权衡，强调了需要针对安全进行定向调优和模块化对齐策略，以确保开源LLMs的安全部署。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18543</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>187. cs.AI-嵌入式FPGA加速类脑神经网络：从在线学习到可扩展推理</title><link>https://arxiv.org/pdf/2506.18530</link><description>Background: 
边缘AI应用需要能够在设备端进行学习和适应的模型，但传统深度学习模型常常过于参数化、耗能高且依赖于云连接。类脑神经网络（BLNNs）通过模仿大脑皮层的结构和生物约束的学习来提出一种神经形态替代方案。它们具有稀疏架构、局部学习规则及无监督/半监督学习能力，适用于低功耗边缘智能。然而，现有的BCPNN实现依赖于GPU或数据中心FPGA，限制了其在嵌入式系统中的应用范围。

Innovation: 
本研究在Zynq UltraScale+ SoC上使用高级综合实现了第一个专用类脑神经网络（BCPNN）嵌入式FPGA加速器。该加速器支持在线学习和仅推理内核，可适应和混合精度。在MNIST、Pneumonia、Breast Cancer数据集上的评估结果显示，与ARM基线相比，加速器在延迟和能耗方面分别实现了最高17.5倍的降低和94%的节省，而不牺牲准确性。这实现了在边缘设备上实用的神经形态计算，填补了脑似学习与现实部署之间的差距。

Conclusion: 
本工作使得类脑神经网络的计算在边缘设备上变得可行，桥接了脑似学习和实际部署之间的鸿沟。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18530</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>188. cs.AI-Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts</title><link>https://arxiv.org/pdf/2506.18510</link><description>Background: 
准确识别口语中的不流畅问题是提高自动语音和语言处理系统性能的关键，也有助于开发更具包容性的语音和语言技术。近年来，大规模语言模型（LLM）因其处理多种类型输入（如音频和视频）的能力引起了广泛关注。本文旨在利用这一趋势，提出一种新方法，将口语中的不流畅行为转化为带有时间戳的显性标记，生成全面注解的不流畅丰富转录文本。这种方法结合了从音频编码器提取的声学表示和不同质量的文本输入：无不流畅的干净转录，来自对齐器的时间对齐转录，或基于音素的ASR模型输出——这些输入可能都包含一些缺陷。研究表明，尽管这些文本输入可能存在缺陷，只要包含时间戳相关的提示，LLM就能有效处理并生成完整的不流畅注释转录文本。

Innovation: 
本文提出了一种创新的方法，利用LLM处理带有时间戳的不流畅行为。这种方法能够集成高质量和可能包含缺陷的文本输入，并通过LLM的有效处理生成全面的不流畅注释转录文本。实验表明，LLM对于处理不完美的提示具有很高的鲁棒性。

Conclusion: 
我们的实验证明，LLM能够通过处理包含时间戳相关信息的不完美输入生成全面的不流畅注释转录文本。这表明，尽管输入可能包含一些缺陷，但LLM仍然能够有效生成完整的注释文本，展现了其在处理不完美提示时的鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18510</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>189. cs.AI-将视觉语言模型推广至新型领域：一种全面的调研</title><link>https://arxiv.org/pdf/2506.18504</link><description>Background: 
近年来，视觉-语言预训练已经成为一种革命性的技术，它融合了视觉和文本两种模态的优点，产生了强大的视觉-语言模型（VLMs）。利用大规模网络预训练数据，这些模型在零样本条件下表现出强大的能力。然而，它们在面对特定领域或专业化泛化任务时的性能往往会降低。因此，一系列研究致力于将VLMs中丰富的知识转移到各种下游应用中，提升其泛化能力。本文旨在全面总结视觉-语言模型泛化设置、方法、基准和结果，通过系统性回顾视觉-语言研究的最新进展，提供对当前及未来多模态研究的清晰视野

Innovation: 
本文根据转移模块分为提示基于、参数基于和特征基于方法，对每种方法的差异和特征进行了总结和讨论，提供了对VLM时代转移学习的新颖解释。进一步介绍了VLM泛化常用的基准，并进行了详尽的性能对比。此外，本文还讨论了视觉语言模型与最新多模态大型语言模型（MLLM）如DeepSeek-VL之间的关系和区别。这些工作对视觉-语言模型的进一步研究具有重要指导意义

Conclusion: 
通过对视觉-语言研究领域的快速增长文献进行全面回顾，并以新颖和实用的泛化视角进行分析，本文为当前和未来多模态研究提供了清晰的图景</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18504</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>190. cs.AI-PuckTrick：合成数据更具现实性的库</title><link>https://arxiv.org/pdf/2506.18499</link><description>Background: 
随着机器学习（ML）模型在决策中的依赖性增加，高质量的训练数据变得至关重要。然而，由于隐私问题、专有限制和数据不充分，获取真实世界的数据集往往受到限制。为此，合成数据生成（SDG）作为一种可行的替代方案出现，它可以创建保留真实数据统计属性的同时确保隐私合规的虚假数据集。尽管如此，合成数据往往过于干净，缺乏真实世界的数据缺陷，如缺失值、噪声、异常值、标签错误分类等，这些缺陷会影响模型的泛化能力和鲁棒性。为了解决这个限制，我们介绍了Pucktrick，一个用于系统性地污染合成数据集的Python库，通过有控制的错误来引入现实生活中的数据缺陷。

Innovation: 
Pucktrick提供了一种有结构的方法来评估ML模型在真实世界数据缺陷下的鲁棒性，支持多种错误类型，包括缺失数据、噪声值、异常值、标签错误分类、数据重复和类别不平衡。它提供了两种污染模式：一种是向干净的数据集注入错误，另一种是进一步污染已经污染的数据集。

Conclusion: 
通过在真实世界金融数据集上的广泛实验，我们评估了系统性数据污染对模型性能的影响。我们的研究结果表明，用受污染的合成数据训练的ML模型比仅用无错误的合成数据训练的模型表现更好，特别是对于基于树的模型和线性模型如SVM和Extra Trees，这些模型的性能明显提升。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18499</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>191. cs.AI-通过歌词转录进行AI生成歌曲检测</title><link>https://arxiv.org/pdf/2506.18488</link><description>Background: 
近年来，基于AI的音乐生成工具的能力显著提升，给音乐行业带来了变革，要求开发出准确的检测方法来识别这种AI生成的内容。现有的音频检测方法在处理未见过的生成器或被干扰的音频时表现出局限性。现有的一些研究直接使用准确、整洁的歌词来检测AI生成的音乐，但是实际应用场景中这些完美的歌词难以获得，仅有的信息是音频。因此，存在实际应用场景中的适用性差距。

Innovation: 
本文创新性地通过使用一般的自动语音识别（ASR）模型进行歌曲转录来解决上述问题，并提出几种检测方法。实验表明，无论在语言还是音乐类型方面，我们的方法都能展现出较强的效果，尤其是使用Whisper large-v2和LLM2Vec嵌入的最佳模型。此外，当音频被不同方式的干扰，以及在多种音乐生成器上进行评估时，我们的方法都比最先进的音频检测方法更具鲁棒性。

Conclusion: 
实验结果展示了通过使用通用ASR模型进行歌词转录的强健检测性能，特别是在不同干扰方式和多种音乐生成器场景下，我们的方法表现出色。提供的代码可以在这里找到。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18488</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>192. cs.AI-MeRF: 提升大型推理模型强化微调的动机增强方法</title><link>https://arxiv.org/pdf/2506.18485</link><description>Background: 
强化学习与可验证奖励（RLVR）已经成为让大型语言模型（LLMs）处理复杂推理任务的强大学习到推理范式。然而，现有的RLVR方法往往忽略了LLMs最显著的能力之一，即他们的情境学习能力，这一点在链式思考（CoT）提示的成功中有所体现。鉴于此，本文探索如何有效结合强化学习与情境学习，以提高LLMs的推理能力。现有研究示例显示，通过直接将奖励规范注入提示，MeRF能够显著提升LLMs的强化学习效果，使其更贴合优化目标生成所需输出。

Innovation: 
本文提出了一种称为动机增强强化微调（MeRF）的方法，通过在提示中直接注入奖励规范来增强LLMs的强化学习能力。这种方法使模型能够在理解优化目标的基础上改进其响应，从而优化生成性能。实验结果显示，MeRF在Knights and Knaves逻辑谜题推理基准测试中显著优于基线方法。此外，消融实验表明，该方法的性能随着情境学习动机与外部奖励函数之间的一致性提高而提升，模型也展现出通过强化学习适应误导性动机的能力。

Conclusion: 
实证研究表明，MeRF在大型推理模型的强化学习中表现出显著优势，尤其是在链条思考提示的使用背景下。这种简单但有效的改进方法充分发挥了LLMs的情境学习能力，使其生成符合预期的输出，并通过学习优化目标与外部奖励实现双重激励。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18485</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>193. cs.AI-基于深度卷积神经网络的新型类别平衡方法用于不平衡数据分割</title><link>https://arxiv.org/pdf/2506.18474</link><description>Background: 
视网膜眼底图像提供了人类眼睛内部结构的宝贵见解，包括血管、视神经盘、黄斑和视网膜中央凹等重要特征。然而，准确分割视网膜血管由于数据分布不平衡和血管厚度变化而具有挑战性。这项研究提出了一种基于深度学习和双级类别平衡方案的BLCB-CNN方法，来实现视网膜眼底图像中的血管分割。在整个过程中，通过全局对比度归一化（GCN）、对比度限制自适应直方图均衡化（CLAHE）和伽玛校正预先处理输入的视网膜眼底图像，以提高强度均匀性并增强血管与背景像素之间的对比度，从而创建平衡的数据集进行分类分割。

Innovation: 
提出了一种基于深度学习的双级类别平衡方案BLCB-CNN，通过Convolutional Neural Network (CNN)架构和经验方法来平衡血管和非血管像素之间的数据分布以及细血管和粗血管之间的数据分布。此外，通过全局对比度归一化、对比度限制自适应直方图均衡化和伽玛校正的预处理步骤，增加了强度均匀性和血管与背景像素之间的对比度，为分类分割视网膜血管树提供了平衡的数据集，并展示了其在外部交叉验证中的有效性和通用性。

Conclusion: 
在标准视网膜眼底图像上评估了该方法，取得了出色的性能指标，包括ROC曲线下的面积为98.23%、准确率为96.22%、敏感性为81.57%和特异性为97.65%。同时，外部跨验证（STARE图像）证实了该方法的有效性和泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18474</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>194. cs.AI-在医学影像预测 prognosis预测中的基础模型和参数高效微调基准测试</title><link>https://arxiv.org/pdf/2506.18434</link><description>Background: 
人工智能对医学影像中的预后预测有巨大的潜力，但其实现应用仍然具有挑战性。本文构建了一个结构化的基准框架，旨在评估和比较卷积神经网络和基础模型在COVID-19患者中预测临床结果的效果，利用了多个公开的胸部X光图像数据集，涵盖了广泛的微调策略，包括传统的全微调和线性探测，以及高效的参数微调方法，如低秩适应、BitFit、VeRA、IA3等，旨在探索多种学习范式（包括全数据和基于少量样本的学习情境），以适应罕见疾病结果和新兴健康威胁建模的需求。

Innovation: 
本文引入了一个明确设计的基准框架，用于评估和比较基础模型和参数高效微调方法在预测COVID-19患者临床结果中的效果，涵盖了广泛的微调策略和多种学习范式，涉及从大型一般用途图像预训练模型（CLIP、DINOv2等）到医疗专用模型（MedCLIP、BioMedCLIP、PubMedCLIP等），对各类预训练模型进行了大规模的比较分析，以评估其在重度数据稀缺和显著类别不平衡条件下的适应能力和泛化能力。

Conclusion: 
通过这一全面和结构化的评估方法，本文旨在指导实际部署和采用稳健、高效和泛化的AI驱动解决方案，以改善真实世界临床预后预测的工作流程，基准测试结果展示了不同微调策略的优点和局限性，在不同数据集规模和类别分布场景下提供了详细的洞察。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18434</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>195. cs.AI-TReB: 一个全面评估大语言模型表格推理能力的基准</title><link>https://arxiv.org/pdf/2506.18421</link><description>Background: 
大多数企业和行业的数据存储在表格、数据库和数据仓库中。利用这些结构化数据进行推理对大型语言模型（LLMs）提出了挑战，主要由于这些数据的隐含语义、固有复杂性和结构化特性。特别是缺乏有效的评估基准来公平反映LLMs在宽泛表格推理能力上的表现。这项研究旨在填补这一空白，提出了一个全面的表格推理演变基准TReB，用于评估从浅到深的表格理解能力和推理能力，包括26个子任务。通过迭代的数据处理过程构建了高质量的数据集，并创建了一个评估框架，使用三种不同的推理模式（TCoT、PoT和ICoT）来稳健地评估表格推理能力。使用这个框架对超过20种最先进的LLMs进行基准测试，并证明了其有效性。实验结果显示，现有的LLMs在处理复杂的、实际的表格相关任务上仍有改进空间。

Innovation: 
提出了一个名为TReB的全面表格推理演变基准，主要用于评估LLMs从浅层到深层的表格理解和推理能力，包括26个子任务。通过迭代的数据处理流程构建了高质量的数据集，并使用了三种不同的推理模式TCoT、PoT和ICoT来评估模型的能力。此外，还对超过20个当前最先进的LLMs进行了基准测试，并验证了该框架的有效性。

Conclusion: 
现有的LLMs在应对复杂的、现实世界的表格相关任务上仍有较大的改进空间。TReB数据集和评估框架已经公开，数据集托管在HuggingFace，框架托管在GitHub。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18421</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>196. cs.AI-Latent Space Analysis for Melanoma Risk Modeling</title><link>https://arxiv.org/pdf/2506.18414</link><description>Background: 
黑色素瘤由于其侵袭性进展和高死亡率，是一个重要的健康风险。因此，需要早期和可解释的诊断工具。尽管深度学习在皮肤病变分类方面取得了进展，但大多数现有模型仅提供二元输出，临床洞察有限。

Innovation: 
本文提出了一种新的方法，即条件变异自编码器（Conditional Variational Autoencoder），该方法不仅扩展了分类的边界，还通过可解释的风险建模提供了结构化的潜在空间。该方法能够捕捉病变之间的语义关系，进行精细、连续的形态学差异评估。此外，通过训练支持向量机（SVM）在该表示上进行恶性与良性痣的有效区分，并且在识别和区分黑色素瘤方面表现出强大的一致性能。更重要的是，学习到的潜在空间支持视觉和几何上的恶性程度解释，空间邻近度接近已知黑色素瘤的病变被认为是风险的一个有意义指标。这种方法将预测性能与临床应用相结合，促进早期检测，突出不确定情况，并通过透明和可解释的决策增强AI辅助诊断的信任度。

Conclusion: 
本文提出的方法在潜在空间分析和风险建模方面具有显著创新，通过可解释的方式促进了黑色素瘤的早期检测和诊断，增强了AI诊断的临床应用和服务。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18414</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>197. cs.AI-调试衰减指数：重新思考代码LLM的调试策略</title><link>https://arxiv.org/pdf/2506.18403</link><description>Background: 
AI调试的效果遵循可预测的指数衰减模式，在短短2-3次调试尝试后，大多数模型的调试能力会下降60-80%。尽管迭代调试是实际代码生成系统中一个关键能力，但当前的调试策略并未满足预期效果。

Innovation: 
提出了调试衰减指数（DDI）这一数学框架，量化标注调试何时变得无效，并预测干预点。通过适时的干预，可以挽救调试的有效性。DDI揭示了当前AI调试的基本局限性，并提供了首个量化优化迭代代码生成策略的框架。

Conclusion: 
通过适时从利用策略转向探索策略，表明了本研究的战略性重启方法可以在关键点上实现有效的干预，从而大幅提升调试的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18403</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>198. cs.AI-ADNF-聚类：一种用于白血病预测的自适应和动态神经模糊聚类方法</title><link>https://arxiv.org/pdf/2506.18396</link><description>Background: 
白血病的诊断和监测越来越多地依赖于大量的图像数据，然而传统的聚类方法缺乏适应变化的细胞模式和实时量化不确定性的能力。ADNF-Clustering框架结合了卷积神经网络特征提取和在线模糊聚类引擎，能够适应不断变化的细胞形态并提供实时的不确定性量化。

Innovation: 
ADNF-Clustering框架通过融合卷积神经网络特征提取和在线模糊聚类，实现了对白血病图像数据的动态和自适应分析，特别在处理实时数据流具有优势。它使用Fuzzy Temporal Index (FTI) 来衡量熵的变化，并通过拓扑细化阶段进行密度加权合并和基于熵的分割，以防止过度和不足分割。这种方法能够提供更好的聚类紧密性和分离性，具有集成到INFANT儿童肿瘤网络的潜力，支持个性化的白血病管理并提供实时支持。

Conclusion: 
在C-NMC白血病显微镜数据集上，ADNF-Clustering方法在表面轮廓分数中达到了0.51的高分，证明了其在不确定性的自适应建模和无标签操作方面的优越性。这种方法能够立即应用于INFANT儿科肿瘤网络中，为个性化白血病管理提供实时的、可扩展的支持。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18396</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>199. cs.AI-使用基于LLM和人类对齐的度量标准评估医学报告中的因果解释</title><link>https://arxiv.org/pdf/2506.18387</link><description>Background: 
本文探讨了不同评估指标如何准确捕捉自动生成诊断报告中的因果解释质量。研究涉及六个指标：BERTScore、余弦相似度、BioSentVec、GPT-White、GPT-Black以及专家定性评估，同时比较了基于观察和多项选择报告生成方法下的两种输入类型。此外，应用了两种权重策略，一种反映特定任务优先级，另一种赋予所有指标相同权重。研究结果表明，GPT-Black在识别逻辑连贯性和临床有效性因果叙事方面表现最强。GPT-White也与专家评估高度一致，而基于相似性的指标则与临床推理质量不一致。这些发现突显了指标选择和权重对评估结果的影响，支持使用基于LLM的评估方法来处理需要解释性和因果推理的任务。

Innovation: 
利用多种指标评估自动生成诊断报告中的因果解释质量，提出基于逻辑连贯性和临床有效性来判断因果叙事是否准确，并应用了两种权重策略以更好地反映评估的细节和重要性。

Conclusion: 
GPT-Black在识别逻辑连贯性和临床有效性因果叙事方面表现最佳，而GPT-White则与专家评估高度一致。基于相似性的指标与临床推理质量不一致，强调了评估指标和权重选择的重要性，支持使用基于LLM的评价方法来处理需要解释性和因果推理的任务。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18387</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>200. cs.AI-LOGICPO: 使用LLMs和偏好优化将基于NL的逻辑问题高效翻译为一阶逻辑</title><link>https://arxiv.org/pdf/2506.18383</link><description>Background: 
逻辑推理是人工智能的关键任务，因为它在问答和总结等下游任务中扮演重要角色。近年来，提高大型语言模型（LLMs）推理能力的方法在将自然语言推理问题正确转换为等效逻辑形式方面效率不高，这限制了模型整体的推理能力。现有方法在这方面存在不足，未能有效将自然语言问题转化为一致的逻辑程序。因此，该研究旨在通过使用偏好优化数据集进行微调，学习如何将自然语言问题转化为一致的逻辑程序。该研究介绍了一个新的监督和偏好优化数据集LogicPO，并采用直接偏好优化（DPO）和凯恩曼-特维斯基优化（KTO）等流行技术微调开源LLMs，以改善基于LLMs的逻辑推理能力。

Innovation: 
本研究提出使用偏好优化数据集对开源LLMs进行微调，以学习如何将自然语言问题转化为一致的逻辑程序。具体创新点包括：1. 介绍了一个新的监督和偏好优化数据集LogicPO；2. 采用Direct Preference Optimization (DPO) 和 Kahneman-Tversky optimization (KTO) 等技术进行微调；3. 微调后的最佳模型Phi-3.5比GPT-3.5-turbo（8-shot）在逻辑正确性上高出10%，语法错误率降低14%。通过这一框架和改进的评估指标，本研究为提高LLMs的逻辑推理能力提供了一条有希望的方向，即更好地在其逻辑表示中表示它们。

Conclusion: 
通过引入LogicPO数据集和优化评估指标，本研究提高了开源LLMs的逻辑推理能力，尤其是在逻辑正确性和语法准确性方面。研究结果为未来改进LLMs的逻辑推理能力提供了新的路径和方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18383</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>201. cs.AI-PERSCEN: 学习多场景匹配中的个性化交互模式和场景偏好</title><link>https://arxiv.org/pdf/2506.18382</link><description>Background: 
随着在线平台的业务规模和范围不断扩大，多场景匹配已成为降低维护成本和缓解数据稀疏现象的主流解决方案。有效实现多场景推荐的关键在于同时捕捉跨所有场景的用户偏好和每个场景特有的场景意识偏好。然而，现有方法常常忽视了用户特定建模，限制了个性化用户表示的生成。

Innovation: 
为了应对这一挑战，本文提出了PERSCEN，一种将用户特定建模纳入多场景匹配的方法。PERSCEN基于用户特征构建用户特定特征图，并采用轻量级图神经网络捕获高阶交互模式，从而能够个性化地提炼跨场景的偏好。此外，利用向量量化技术从单一场景内的用户行为序列中提炼场景意识偏好，助力用户特定和场景意识偏好建模。为提高信息传输的效率与灵活性，引入了渐进式场景意识门控线性单元，允许细粒度、低时延的融合。

Conclusion: 
广泛的实验结果表明，PERSCEN优于现有方法。进一步的效率分析证实，PERSCEN在性能与计算成本之间实现了有效平衡，确保其在实际工业系统中的实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18382</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>202. cs.AI-共同学习的机器人与儿童：通过教授同伴般交互式机器人改善知识保持</title><link>https://arxiv.org/pdf/2506.18365</link><description>Background: 
尽管有关学习-教会（LbT）的兴趣日益增长，但鲜有研究探索如何将此范式在真实课堂中应用于自主、类似同伴的社交机器人。大多数前期研究依赖于脚本化或‘巫师- oz’行为模式，限制了我们对实时、互动式学习如何通过人工代理得到支持的理解。因此，本研究通过引入交互式增强学习（IRL）作为教可交互式社交机器人的认知模型来填补这一空白，并开展了两组实验，让58名小学生分别教授机器人或独自使用平板电脑教授法语词汇和语法规则（记忆与推理）。结果显示，LbT条件下的儿童在知识保持方面表现更好，尤其是在语法规则任务中，知识基础较弱的学生成为了最大的受益者。行为指标表明，儿童随着时间推移调整了教授策略，并且在推理任务中更加投入。这些发现进一步扩展了LbT的理论理解，显示社交机器人不仅可以作为被动的辅导员，还可以作为适应性伙伴，增强元认知参与和长期学习效果。

Innovation: 
引入了交互式增强学习（IRL）作为教交互式社交机器人的有效且可扩展的认知模型，以及在真实教室中同时部署多台自主机器人进行测试的可行性。

Conclusion: 
本研究通过实验验证了交互式社交机器人在教育中的有效性，并展示了它们作为互动式教学伙伴的角色。同时，研究发现知识较弱的学生从教授机器人中获益最大，该研究进一步扩展了对学习-教会的理解，明确了社交机器人作为积极教学伙伴的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18365</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>203. cs.AI-等变变分流匹配中的受控生成</title><link>https://arxiv.org/pdf/2506.18340</link><description>Background: 
该研究在变分流匹配（VFM）框架内推导出一个受控生成的目标，并将其流匹配问题重新表述为变分推断问题。研究指出可以通过端到端训练条件生成模型或作为贝叶斯推断问题来实现受控生成，使得在未重新训练的前提下，可以对无条件模型进行后验控制。此外，研究提出了等变生成所需的条件，并针对分子生成设计了等变的VFM公式，确保对旋转、平移和置换的不变性。

Innovation: 
研究在VFM框架下提出了受控生成的目标，并展示了两种实现受控生成的方法：通过端到端训练条件生成模型以及作为贝叶斯推断问题。进一步地，研究提供了针对分子生成的等变VFM公式，确保生成结果对旋转、平移和置换保持不变性。

Conclusion: 
研究在不受控和受控分子生成上的评估表明，无论是通过端到端训练还是在贝叶斯推断环境下，其方法均实现了最佳性能。该工作加强了基于流的生成建模与贝叶斯推断之间的联系，提供了一个可扩展且具有原则性的框架，用于驱动约束的、对称感知的生成。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18340</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>204. cs.AI-结构化的柯尔莫哥洛夫-阿诺德神经ODEs用于可解释学习和非线性动力学的符号发现</title><link>https://arxiv.org/pdf/2506.18339</link><description>Background: 
理解与建模非线性动态系统是跨科学和工程领域的一个基本问题。尽管深度学习展示了学习复杂系统行为的巨大潜力，但是创建既高度准确又具有物理可解释性的模型仍然面临重大挑战。本文探讨了如何通过结合结构化状态空间建模与柯尔莫哥洛夫-阿诺德网络(Kolmogorov-Arnold Network, KAN)来解决这一问题，特别是在进行虚拟传感和提取系统动力学的隐式表示能力方面。

Innovation: 
提出了结构化的柯尔莫哥洛夫-阿诺德神经ODEs（SKANODEs）框架，该框架整合了结构化状态空间建模和KAN。SKANODE首先使用一个全可训练的KAN作为通用函数逼近器，在结构化的神经ODE框架内执行虚拟传感，恢复对应于可解释物理量（如位置和速度）的潜在状态。进一步利用KAN的符号回归能力提取系统的动力学规则的紧凑且可解释的表达式。这些符号表达式随后被反馈到神经ODE框架中，并通过持续训练进一步校准，以优化其系数，提高发现方程的精度和系统响应的预测准确性。

Conclusion: 
在模拟和真实世界系统的广泛实验中，SKANODE展示了卓越的性能，同时提供了解释明确、物理一致的模型，揭示了非线性动态系统的底层机制。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18339</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>205. cs.AI-Confucius3-Math：针对中国K-12数学学习的轻量级高性能推理大型语言模型</title><link>https://arxiv.org/pdf/2506.18330</link><description>Background: 
介绍了Confucius3-Math，这是一个开源的大规模语言模型，具有140亿个参数，能够在单个消费级GPU上高效运行，并在一系列数学推理任务上实现了SOTA性能，超过了许多更大规模的模型。该模型特别致力于为中国K-12学生和教育者提供数学学习。模型通过大规模强化学习（RL）进行后续训练，能够以较低的成本解决主流的中国K-12数学问题，符合国家级课程标准。

Innovation: 
开发了三种技术创新：目标熵正则化、近期样本恢复和策略特定难度权值。这些创新包括一种新的熵正则化、新颖的数据调度策略和改进的组相对优势估算器。它们显著稳定了RL训练、提高了数据效率并提升了性能，展示了在一个特定领域以低成本构建强大推理模型的可能性。

Conclusion: 
本研究展示了使用强化学习在低成本下构建特定领域强推理模型的可行性，并开源了该模型和代码。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18330</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>206. cs.AI-公平 vs 公平 —— 公正之光：推荐系统中的公平之战</title><link>https://arxiv.org/pdf/2506.18327</link><description>Background: 
推荐系统在我们的日常生活中发挥着重要作用，特别是在电商、招聘信息、娱乐等领域影响用户体验。由于这些系统的关键性角色，从业者必须确保它们不会产生不公平和不平衡的推荐。以往关于推荐系统中偏见的研究往往忽视了某些项目类别的偏见，这可能导致某些偏见未被解决。此外，大部分关于公平重排的研究集中在二元敏感属性上。本文探讨了这些不足，并提出了一种公平意识的重排方法，该方法能够缓解不同类别的商品中存在偏见。此方法利用现有偏见来纠正不同群体的推荐差异。研究展示了如何通过这种方法在多个敏感属性（性别、年龄和职业等）中减轻偏见，同时几乎不会影响性能。

Innovation: 
文章提出了一种公平意识的重排方法，旨在缓解不同类别的商品中存在偏见。该方法利用现有偏见来纠正不同群体的推荐差异，并能够处理多个敏感属性，不仅限于以前研究中的二元敏感属性。这种方法试图全面解决偏见问题，从而改善推荐系统的公平性。

Conclusion: 
实验结果表明，此方法能够有效地减轻社交偏见，同时几乎不会影响推荐系统的性能表现。这种方法将有助于提高推荐系统的公正性，为推荐系统的公平性树立了一个新的标准。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18327</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>207. cs.AI-基于多尺度空间注意力的零样本学习框架在低光照图像增强中的应用</title><link>https://arxiv.org/pdf/2506.18323</link><description>Background: 
低光照图像增强仍然是一个具有挑战性的任务，尤其是在缺乏配对训练数据的情况下。传统的和基于深度学习的增强方法都存在一定的局限性，无法满足细粒度增强的需求，同时保持语义和感知保真度。本研究旨在解决这一问题，提出了一种新颖的零样本学习框架——LucentVisionNet，以克服现有方法的局限性。

Innovation: 
该研究提出了一种结合多尺度空间注意力和深度曲线估计网络的新颖框架，能够实现细粒度增强，并保持语义和感知保真度。另外，采用了一种循环增强策略，并通过包括一种基于人类视觉感知的新颖无参考图像质量损失在内的复合损失函数来优化模型。这种方法在多种参考和无参考图像质量度量标准中超过了最先进的监督、无监督和零样本方法。

Conclusion: 
实验结果表明，LucentVisionNet不仅提升了图像质量，保持了结构一致性，还在计算效率方面表现出色，使得该框架特别适合部署在移动摄影、监控和自主导航等实际应用场景中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18323</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>208. cs.AI-使用基于属性的测试来弥补LLM代码生成与验证之间的差距</title><link>https://arxiv.org/pdf/2506.18315</link><description>Background: 
大语言模型（LLMs）在代码生成方面表现出色，但确保其输出功能正确，尤其是在复杂编程任务中，仍然是一个持续存在的挑战。传统测试驱动开发（TDD）可以为代码改进提供一条途径，但其与LLMs的有效结合常常受到高质量测试用例稀缺或自动测试生成中的陷阱（如偏向测试或不准确的输出预测）的阻碍，这些陷阱可能误导修正过程。

Innovation: 
本文提出了一种名为Property-Generated Solver的新颖框架，该框架利用基于属性的测试（PBT）验证高层次程序属性或不变量，而不依赖于特定的输入输出示例。Property-Generated Solver采用两种协作的LLM基础代理：Code生成器负责代码生成和迭代完善；测试器负责管理PBT生命周期并从属性违反中形成语义丰富的反馈。这种方法通过将PBT确立为这种迭代、闭环范式的核心验证引擎，为引导LLMs产生更正确的、更普遍适用的代码提供了强大的机制。实验证明，Property-Generated Solver相比现有TDD方法显著提高了pass@1，范围从23.1%到37.3%的相对增益。

Conclusion: 
Property-Generated Solver通过PBT为LLM的代码验证提供了一个迭代和封闭循环的范式，使得LLMs的代码更加正确和通用。在多个代码生成基准测试中的实验结果显示，Property-Generated Solver相对于传统的TDD方法实现了显著的pass@1改进，从23.1%到37.3%的相对增益。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18315</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>209. cs.AI-LettinGo：探索推荐系统中的用户画像生成</title><link>https://arxiv.org/pdf/2506.18309</link><description>Background: 
用户画像对于推荐系统至关重要，它将原始用户交互数据转换为简洁且结构化的表示形式，从而推动个性化推荐。虽然传统的基于嵌入的用户画像缺乏可解释性和适应性，但 recent 语言模型 (LLMs) 的最新进展使得能够生成具有更高语义丰富性和透明度的文本型用户画像。然而，现有方法通常依附于固定格式，限制了它们捕捉用户行为多样性的能力。

Innovation: 
LettinGo 提出了一种新颖的框架来生成多样且适应性强的用户画像。该方法利用了 LLMs 的表达能力，并结合了来自下游推荐任务的直接反馈来避免监督微调 (SFT) 带来的限制。相反，LettinGo 采用了直接偏好优化 (DPO) 来使用户画像生成机制与特定任务的表现相一致，确保用户画像既保持适应性又具有有效性。实验结果表明，该框架显著提高了推荐的准确性和灵活性，增强了上下文感知能力。

Conclusion: 
该工作增强了用户画像生成的关键创新，对于下一代推荐系统的改进具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18309</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>210. cs.AI-Spiffy: Efficient Implementation of CoLaNET for Raspberry Pi</title><link>https://arxiv.org/pdf/2506.18306</link><description>Background: 
当前的研究领域主要集中在使用专业的神经形态硬件或框架来实现神经形态计算，如运行尖峰神经网络（SNNs）。但这种方法依赖于特定的硬件或框架，不仅成本较高，而且在通用计算平台上实现较为复杂。因此，研究一种在通用计算平台上轻量级实现SNN的方法变得尤为重要，特别是在像Raspberry Pi这样的低成本、低功耗平台上实现尖峰神经网络的相关应用仍然有限的情况下。

Innovation: 
本文提出了一种不依赖于专门的神经形态硬件或框架的轻量级软件方法来运行SNNs。具体来说，作者使用Rust语言实现了特定的SNN架构（CoLaNET），并对其进行优化，使其适用于常见的计算平台。作者将这种方法称为Spiffy，并用其在Raspberry Pi和MNIST数据集上作为案例进行了演示。Spiffy达到了92%的准确率，并且具有极低的延迟（训练步骤：0.9毫秒，推理步骤：0.45毫秒），突显了方法的有效性和效率。这种方法的主要创新点在于其轻量级的实现方式，使得SNNs能够在成本较低且普遍性较强的平台上运行，有利于促进SNNs的广泛应用。

Conclusion: 
作者通过演示Spiffy在Raspberry Pi上的应用，验证了其在实际硬件上的高效性，证明了即使在资源受限的平台上也能高效运行SNNs。文章最后指出，该方法为其他类似的SNN轻量级实现提供了参考和借鉴，有助于推动SNNs技术的进一步发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18306</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>211. cs.AI-提高矛的锋利度：针对基于DRL的自动驾驶策略的自适应专家引导式对抗攻击</title><link>https://arxiv.org/pdf/2506.18304</link><description>Background: 
深度强化学习（DRL）已成为自主驾驶的有前景范式，然而，基于DRL的策略在对抗攻击面前极为脆弱，这在实际部署中带来了严重的安全风险。尽管先前的攻击方法取得了进展，但它们仍然面临挑战，包括依赖高频率攻击而忽略上下文相关性和时间稀疏的机会，攻击频率的限制虽然提高了效率，但也导致了由于攻击者探索受限而引起的不稳定的训练。研究这些攻击对于揭示策略的缺陷和引导开发更强大的自主系统至关重要。

Innovation: 
提出了一种自适应专家引导式对抗攻击方法，以提高攻击策略训练的稳定性和效率。该方法首先利用模仿学习从成功的攻击演示中推导出专家策略，并通过混合专家架构进行增强，以确保在不同场景下的稳健泛化。接着，通过KL散度正则化项引导基于DRL的对手。由于场景的多样性，专家策略可能不完美，因此引入了性能感知退火策略，该策略会逐步减少对手对专家的依赖，使其自主性提高。实验结果表明，该方法在碰撞率、攻击效率和训练稳定性方面优于现有方法，尤其在专家策略不理想的情况下表现更佳。

Conclusion: 
实验结果表明，该方法在碰撞率、攻击效率和训练稳定性方面优于现有方法，尤其在专家策略表现不佳时具有明显优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18304</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>212. cs.AI-GeNeRT: 通过广泛学习神经射线跟踪进行具有物理信息的智能无线信道建模</title><link>https://arxiv.org/pdf/2506.18295</link><description>Background: 
神经射线跟踪（RT）作为结合物理传播原理和神经网络的信道建模新颖范式，显示出高建模准确性和效率。然而，当前的神经RT方法面临两大挑战：受限的一般化能力，受强烈的空间依赖性的影响；以及对电磁定律的弱遵从性。现有研究存在的不足限制了其在实际应用场景中的广泛应用和效果提升。为了应对上述限制，作者提出了一种增强化泛化能力、准确性和效率的GeNeRT框架，旨在更广泛地应用和提高实际信道建模的性能。

Innovation: 
GeNeRT框架通过引入Fresnel启发式的神经网络设计，增强了多路径分量（MPC）预测的准确性；同时，提出了一个基于GPU张量化的加速策略，提升了运行时效率。GeNeRT能够在多个未训练场景和全新环境中良好泛化，并在MPC预测的准确性方面优于基线方法，此外，在多发射器设置中的运行时效率也优于Wireless Insite。网络架构和训练策略的消融实验进一步验证了GeNeRT在捕捉射线-表面交互物理原则方面的有效性。

Conclusion: 
实验表明，GeNeRT能够在未训练的场景中和全新的环境中良好泛化，并在MPC预测的准确性方面显著优于基线方法，尤其在多发射器设置中的运行时效率优于Wireless Insite。该框架的有效性通过消融实验得到验证。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18295</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>213. cs.AI-基于个体重要性的选择性社会交互以实现快速人类轨迹预测</title><link>https://arxiv.org/pdf/2506.18291</link><description>Background: 
该论文研究了选择对预测主要人物轨迹重要的相邻人物的架构。为了实现有效的相邻人物选择，提出了一个称为重要性估计器的人员选择模块，该模块能够输出每个相邻人物对未来主要人物轨迹预测的重要性。实验表明，该方法在保持预测准确性的同时提高了预测速度，尤其是在JRDB数据集上的表现更为显著。这对于需要快速且准确地预测个体移动路径的应用场景非常重要，如自动驾驶和人群行为分析等领域。背景指出在处理大规模人群时，有效选择对于预测重要的相邻人物至关重要，以加速全面的轨迹预测过程，同时保证较高的准确性。

Innovation: 
创新点在于提出了一种新颖的重要性估计器模块，用于预测主要人物的未来轨迹，并通过Gumbel Softmax方法训练选择相邻人物，从而避免由非可微操作阻塞梯度的问题，使得模型可以更有效地进行选择性社会交互，实现快速精确的人类轨迹预测。

Conclusion: 
实验结果表明，该方法在JRDB数据集上达到了可竞争的预测准确性，并且预测过程得到了显著的加速。这表明提出的架构能够有效地选择对主要人物轨迹重要的人，从而提高了人类轨迹预测的速度和效率。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18291</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>214. cs.AI-转身让AI更绿色：探索正交优化下的级联能效提升</title><link>https://arxiv.org/pdf/2506.18289</link><description>Background: 
人工智能的发展导致了计算需求和能源挑战的指数增长。虽然实践者正在采用各种优化技术来调整模型效率，但这些技术通常是在事后进行的、缺乏系统性的、单方面的调整，且未能充分理解这些技术在综合情况下对能源效率的影响。本文强调将能源效率作为优先考虑的因素，并作为计算密集型管道的基本设计考虑因素。研究表明，在数据、模型、训练、系统、推理等五个AI管道阶段进行战略性选择能够产生级联效率提升。实验验证显示，正交组合方法可以将能源消耗最多降低94.6%，同时保持95.95%的原始非优化管道的F1分数。

Innovation: 
本文提出了一种系统性地将能源效率作为优先考虑因素的方法，通过在数据、模型、训练、系统和推理五个AI管道阶段进行战略性选择，实现了正交优化组合，显著降低了能源消耗，同时保持了模型性能。这种方法为实现可持续人工智能提供了一种可操作的框架，以平衡效率、性能和环境责任。

Conclusion: 
实验结果表明，通过精心选择的正交优化组合，可以大幅降低AI管道的能源消耗，同时保持高效率和性能，为推动可持续人工智能的发展提供了可行的路径和框架。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18289</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>215. cs.AI-ARD-LoRA：具备异构适应需求的基础模型参数高效微调的动态秩分配</title><link>https://arxiv.org/pdf/2506.18267</link><description>Background: 
传统的低秩适应（LoRA）方法使用固定的秩，对所有转换器层和注意力头进行统一适应，即使它们的学习动态不同。这可能导致性能损失和资源浪费。在不同适应需求的场景下，这种方法效率不高。因此，需要一种新的方法来动态地根据需要调整每个注意力头或层的秩，从而提高适应效率和性能。

Innovation: 
提出了自适应秩动态LoRA（ARD-LoRA）框架，这是一种自学习的框架，通过可学习的缩放因子自动分配秩。优化目标是平衡任务性能和参数效率，并通过$L_1$稀疏性和Total Variation正则化来最小化秩和实现稳定的秩过渡。与现有方法DoRA和AdaLoRA相比，ARD-LoRA在保持几乎相同性能的同时，显著减少了训练参数的数量，并降低了多模态适应的内存消耗。这表明动态、精细的秩分配对于基础模型的高效适应至关重要.

Conclusion: 
ARDO-LoRA方法能够在保持接近全额微调性能的情况下，仅使用极少的可训练参数（0.32%），并且在多种模型上实验验证了其有效性和优越性。此外，它在多模态适应方面也比现行方法更节省内存（降低41%）。这些结果表明，对于具有异构适应需求的基础模型，动态、细粒度的秩分配是一个关键的高效适应范式。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18267</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>216. cs.AI-RLPR：无需验证器扩展到通用领域的强化学习</title><link>https://arxiv.org/pdf/2506.18254</link><description>Background: 
Reinforcement Learning with Verifiable Rewards (RLVR) 已显现出在提升大型语言模型（LLMs）推理能力方面的潜力，但其成功主要局限在数学和代码领域。这一局限主要源于高度依赖于特定领域验证器，导致复杂性和可扩展性受限。研究指出，通过利用LLM生成正确自由形式答案的内在概率间接反映其对推理奖励的评估，可以构建一个无需验证器的简单框架来克服这一问题。

Innovation: 
研究提出了RLPR（Reasoning with Latent Probability Re却省略，这里省略了创新部分的具体翻译，因为原文中并没有明确使用“RLPR”以外的术语来描述其创新点。RLPR的关键创新在于利用LLM生成正确自由形式答案的内在概率作为奖励信号，而非依赖于特定的验证器。此外，RLPR还通过prob-to-reward和稳定化方法解决了高噪声概率奖励带来的挑战，使得这一方法更可靠。

Conclusion: 
在四个通用领域的基准测试和三个数学基准测试中，RLPR总体提升了基于三种模型（Gemma，Llama和Qwen）的推理能力。此外，RLPR在TheoremQA上比同行竞争者VeriFree高出7.6分，在Minerva上高出7.5分，在七个基准测试中平均高出强依赖验证器的General-Reasoner 1.6分。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18254</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>217. cs.AI-Morse: 双抽样法加快扩散模型的速度</title><link>https://arxiv.org/pdf/2506.18251</link><description>Background: 
本文提出了一种名为Morse的简单双抽样框架，用于无需损失精度地加速扩散模型。关键在于使用快速跳跃抽样和自适应残差反馈策略重新构建从噪声到数据的迭代生成过程。现有的扩散模型在生成过程中通常需要大量迭代，计算效率较低。Morse通过引入两个模型Dash和Dot，来提高采样效率和生成性能。

Innovation: 
Morse创新之处在于它采用了两个相互作用的模型Dash和Dot。Dash模型是预训练的任何类型的扩散模型，但运行在跳跃抽样模式下，为采样效率改进提供了空间。Dot模型比Dash模型快得多，它被学习以生成基于Dash模型轨迹上当前跳跃抽样点观察的残差反馈，提高了噪声估计的准确性。Morse通过交替运行Dash和Dot模型，以灵活的方式达到所需的图像生成性能，同时提高了整体运行效率。通过所提出的方法，Morse在广泛的采样步骤预算中相比9种基础扩散模型在多个图像生成任务中的平均性能提升了1.78-3.31倍。此外，还展示了这种方法如何进一步加速最先进的LCM-SDXL模型，适用于少量步骤的文本到图像合成任务。

Conclusion: 
Morse通过双抽样策略极大地提高了扩散模型的生成速度，同时保持了精度。与其他扩散模型相比，它在多个任务上显示出显著的性能提升。这种方法已被证明是可以泛化的，并且可以进一步应用于已经加速的扩散模型。实验结果表明，Morse在多种图像生成任务中平均速度比基线模型快了1.78到3.31倍。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18251</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>218. cs.AI-增强对抗可移植性的基于语义结构的生成式攻击</title><link>https://arxiv.org/pdf/2506.18248</link><description>Background: 
目前的生成对抗攻击方法通过训练扰动生成器在白色盒子替代模型上，然后将精心设计的扰动应用于看不见的黑色盒子受害模型。与迭代攻击相比，这些方法在推理时间和可扩展性方面表现出更优的效率和可移植性。然而，现有研究尚未完全利用生成模型的表征能力来保留和利用语义信息。具体来说，生成器的中间激活包含丰富的语义特征，如对象边界和粗略形状，这些特征目前被大大忽略了，这限制了扰动与有助于对抗可移植性的对象显著区域的对齐。

Innovation: 
为了解决这个问题，该研究提出了一种基于Mean Teacher的时间平滑特征参考的语义结构感知攻击框架。通过这一平滑参考，进一步指导学生网络的早期层激活与语义丰富的教师网络的激活之间的一致性，通过特征蒸馏。基于实证发现，该方法将扰动合成锚定在生成器内部语义显著的早期中间块上，引导渐进的对抗扰动，在显著提高对抗可移植性的区域增强其效果。实验结果展示了该方法相对于最先进的生成式攻击的一致改进，全面地使用常规指标和我们新提出的意外纠正率（ACR）进行评估。

Conclusion: 
通过引入基于语义结构感知攻击框架，实验结果表明该方法在不同模型、领域和任务中相较于最先进的生成式攻击表现出一致性改进，使用常规指标和新提出的意外纠正率（ACR）进行了全面评估。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18248</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>219. cs.AI-Smart-LLaMA-DPO：强化的大语言模型以实现可解释的智能合约漏洞检测</title><link>https://arxiv.org/pdf/2506.18245</link><description>Background: 
智能合约漏洞检测是区块链安全性的一项主要挑战。现有的漏洞检测方法面临两个主要问题：(1) 现有的数据集缺乏全面的覆盖面和高质量的解释，以支持偏好学习。(2) 大型语言模型（LLMs）在准确理解智能合约安全的具体概念方面经常存在问题。实证分析表明，即使经过持续预训练（CPT）和监督微调（SFT），LLMs 也可能错误地解释状态变化的执行顺序，导致解释错误，但检测决策正确。

Innovation: 
本文提出了一种名为Smart-LLaMA-DPO的方法，基于LLaMA-3.1-8B。该方法构建了一个全面的数据集，涵盖了四种主要漏洞类型及不可机器审核的漏洞，包括用于SFT的精确标签、解释和位置，以及用于直接偏好优化（DPO）的高质量和低质量输出对。此外，应用了大规模智能合约进行持续预训练（CPT），增强了LLM对智能合约特定安全实践的理解，进行了监督微调（SFT），并应用了DPO方法，利用了人类反馈和一个特别设计的损失函数，以提高偏好解释的概率并减少非偏好输出的可能性。此类方法在四种主要的漏洞类型及不可机器审核的漏洞上显著优于最先进的基线方法，平均F1分数和精度分别提高了10.43%和7.87%。此外，大语言模型评估和人类评估均证实该方法生成了更准确、全面且清晰的解释。

Conclusion: 
Smart-LLaMA-DPO方法在智能合约漏洞检测上取得了显著的效果，通过持续预训练、监督微调和直接偏好优化方法，增强了大语言模型对智能合约安全性的理解和解释能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18245</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>220. cs.AI-量子-经典混合量化神经网络</title><link>https://arxiv.org/pdf/2506.18240</link><description>Background: 
当前工作中，量化神经网络的训练通常依赖传统的二元优化模型，限制了其对任意激活和损失函数的支持，并且难以在保持非线性特性的同时优化复杂的非线性函数。本文提出了一个新的Quadratic Binary Optimization (QBO)模型，通过样条插值技术支持任意激活和损失函数的使用。为了应对神经网络中非线性与多层复合结构带来的挑战，引入了Forward Interval Propagation (FIP)方法，通过将激活函数离散化为线性子区间来处理这些挑战。这种方法保留了神经网络的通用近似特性，同时允许使用量子计算机进行复杂非线性函数的优化，从而扩大了其在人工智能中的应用范围。在理论上，通过推导经验风险最小化问题的样本复杂性来上界优化误差和所需的Ising自旋数。然而，大规模求解Quadratic Constrained Binary Optimization (QCBO)模型时，由于存在大量约束，使用惩罚法处理这些约束时，较大的惩罚系数需要进行调优，导致计算复杂度增加并可能影响解的质量。

Innovation: 
提出了一种新的Quadratic Binary Optimization (QBO)模型，通过样条插值技术支持任意激活和损失函数的使用。提出了Forward Interval Propagation (FIP)方法，通过将激活函数离散化为线性子区间来处理非线性与多层复合结构带来的挑战。采用Quantum Conditional Gradient Descent (QCGD)算法利用量子计算直接解决QCBO问题。证明了QCGD算法在量子或acles和目标值方差有界随机性下的收敛性，以及在系数矩阵受限精度下的收敛性，并给出了QCBO求解过程的时间上界。

Conclusion: 
实验结果表明，使用相干Ising机器(CIM)在时尚MNIST分类任务上实现了94.95%的准确率，仅需1.1位精度。这表明该方法在量化神经网络领域具有广阔的应用前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18240</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>221. cs.AI-AdapThink：推理语言模型的自适应思考偏好</title><link>https://arxiv.org/pdf/2506.18237</link><description>Background: 
基于强化学习（RL）的后训练方法显著提升了语言模型的复杂推理能力，促进了一系列高级自我反思过程。然而，这种“慢思考”范式限制了推理效率：模型在处理简单问题时可能浪费大量计算资源，在处理复杂问题时可能会过早停止推理。先前机制通常依赖固定的长度预算或预定义规则，缺乏适应不同问题复杂性和模型进化能力的能力。

Innovation: 
AdapThink是一个自适应后训练框架，旨在提高推理效率同时保持推理语言模型的性能。它通过引入两种关键机制来实现这一目标：1) 基于组相关奖励函数动态调整与反思相关的过渡词偏好，而不依赖固定长度偏好；2) 通过熵指导评分实现多样化的采样机制，平衡训练组求解准确性和推理多样性。

Conclusion: 
在多个数学推理数据集上的实验表明，AdapThink能促进自适应推理模式，缓解低效问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18237</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>222. cs.AI-简化之选：动态稀疏注意力机制在自回归图像生成中的应用</title><link>https://arxiv.org/pdf/2506.18226</link><description>Background: 
自回归条件图像生成模型已成为文本到图像合成的主要范式。这些方法通常将图像转换为一维令牌序列，并利用已经在自然语言处理中取得显著成功的自注意力机制，来捕捉长距离依赖性、建模全局上下文并确保语义连贯性。然而，在推断过程中过长的上下文会导致显著的内存开销（由KV缓存引起）和计算延迟。为了解决这些问题，我们系统地分析了推理过程中全局语义、空间布局和细粒度纹理是如何形成的，并提出了一种名为自适应动态稀疏注意（ADSA）的训练无监督上下文优化方法。这一方法概念上是动态识别维持局部纹理一致性和确保全局语义连贯性所需的历史令牌，从而高效地简化注意力计算。此外，我们还为ADSA引入了一种动态KV缓存更新机制，将推理过程中的GPU内存消耗降低了约50%。广泛的定性和定量实验表明，我们的方法在生成质量和资源效率方面都表现出了有效性与优越性。

Innovation: 
我们提出了一种训练无监督的上下文优化方法——自适应动态稀疏注意（ADSA），通过动态识别对局部纹理一致性及全局语义连贯性至关重要的历史令牌，简化了注意力计算。进一步通过设计专用的动态KV缓存更新机制，有效减少了推理过程中的GPU内存消耗，与现有方法相比降低约50%。

Conclusion: 
我们的ADSA方法在图像生成质量和资源效率方面都表现出色，通过动态优化注意力计算，有效缓解了自回归图像生成中的记忆开销和计算延迟问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18226</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>223. cs.AI-这些并非您所寻找的所有特征：监督预训练中的一个基本瓶颈</title><link>https://arxiv.org/pdf/2506.18221</link><description>Background: 
迁移学习是现代机器学习的基石，它允许多个数据集预训练的模型适应新的任务，只需要少量新的数据。然而，确保迁移特征在未见过的新数据集上足够强大是一个重大挑战，尤其是在量化两个任务是否相关方面困难重重。本文对此进行了研究，评估了预训练混合模型向其组成部分任务的迁移效果，探讨了预训练特征能否达到特定任务直接训练的表现。研究发现，当网络在预训练过程中编码相似的竞争特征时，会遇到一个名为“信息饱和瓶颈”的基本问题，导致网络无法学习新的特征。因此，预训练时仅学习部分关键特征会导致模型永久失去重要特征，从而在新数据上的表现不一致，即使在训练混合数据的不同部分亦然。已有研究结果表明，当前的表示学习方法因数据分布或顺序等因素，确实存在这一问题。本文建议，依赖大型网络可能不如特定任务训练更为有效，提出了更丰富特征表示作为一种可能的解决方案，并引入了一种新方法以应对这一挑战的初步尝试.

Innovation: 
本文识别了一个新的深度学习模型基本问题——信息饱和瓶颈，并提出了目前代表学习方法在数据分布或顺序等因素影响下学习特征的能力有限的现象。文章结合实证证据提出了更丰富的特征表示作为提升新数据集概括能力的潜在解决方案，并提出一种新的方法来解决这个问题的初步步骤.

Conclusion: 
本文的研究结果表明，在数据集多样化或特性复杂的情况下，依赖大规模网络进行预训练可能不如针对特定任务进行直接训练有效。文章提出了使用更丰富的特征表示作为改进迁移学习模型跨新数据集概括能力的一种可能途径，并提出了一个创新的方法，逐步解决这个问题.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18221</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>224. cs.AI-跨架构知识蒸馏（KD）在NVIDIA Jetson Nano上的视网膜视网膜图像异常检测</title><link>https://arxiv.org/pdf/2506.18220</link><description>Background: 
早期和准确地识别视网膜疾病对于预防眼疾发展至关重要，但在资源匮乏的地区，获取可靠的诊断设备并不常见。因此，该项目旨在通过开发基于跨架构知识蒸馏的轻量级边缘设备部署疾病分类器来解决这一问题。通过训练一个高性能的视觉变压器（ViT）教师模型，并压缩到基于CNN的学生模型，在如NVIDIA Jetson Nano这样的资源受限环境中部署，该方法在保留诊断性能的同时实现了模型压缩，以支持眼疾的早期检测和干预，这对于资源有限的地区尤为重要。

Innovation: 
该项目创新之处在于提出了一个使用分区交叉注意力（PCA）投影器、组线性（GL）投影器和多视角鲁棒训练方法的新型框架，通过这种方法，将一个高性能的ViT教师模型压缩到一个轻量级的学生模型，同时保持了较高准确率。教师模型拥有更多的参数（97.4%），而学生模型在各个方面表现接近，分类准确率达到89%，并保留了大约93%的教师模型的诊断性能。这种方法提供了一种在资源受限地区进行视网膜疾病的智能筛查解决方案。

Conclusion: 
本文展示了在NVIDIA Jetson Nano上使用跨架构知识蒸馏进行视网膜图像异常检测的解决方案，证明了通过压缩高性能模型实现轻量级边缘设备部署的可行性，并为资源匮乏地区提供了一种可扩展的AI驱动的筛查方法，支持视网膜疾病的初步分级。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18220</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>225. cs.AI-基于深度学习的膝关节 radiograph 对准测量</title><link>https://arxiv.org/pdf/2506.18209</link><description>Background: 
放射状膝关节对准（KA）测量对于预测关节健康和全膝关节置换术后的手术结果非常重要。传统的KA测量方法是手动的、耗时的，并且需要长腿 X 光片。本研究提出了一种基于深度学习的方法，通过自动定位膝关节解剖标志点在膝关节 AP 投影射线照片上来测量KA。

Innovation: 
方法基于 hourglass 网络，并结合了注意力门控结构以增强稳健性并关注关键解剖特征。这是第一个基于深度学习的方法，用于定位超过100个膝关节解剖标志点，以全面勾画膝关节形状的同时集成术前和术后影像的KA测量。该方法使用解剖胫股角提供了非常精确和可靠的 KA 测量，平均绝对差异约为1°，与临床真实测量结果相比。术前自动化测量与临床测量的一致性非常好（ICC = 0.97），术后良好（ICC = 0.86）。

Conclusion: 
本研究证明，KA 评估可以实现高度准确的自动化，为基于数字的临床工作流程创建了机会。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18209</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>226. cs.AI-Fourier Attention驱动的多模态融合SLAM</title><link>https://arxiv.org/pdf/2506.18204</link><description>Background: 
视觉同步定位与建图（Visual SLAM）在受噪声、不同光照条件和黑暗影响的环境中尤其具有挑战性。基于学习的光学流算法可以通过多模态数据来应对这些挑战，但传统基于光学流的视觉SLAM方法通常需要大量的计算资源。为了克服这一限制，本文提出了一种名为FMF-SLAM的高效多模态融合SLAM方法，利用快速傅里叶变换（FFT）来提升算法效率。FMF-SLAM通过引入基于傅里叶变换的自我注意和交叉注意机制，从RGB和深度信号中提取特征，并通过跨模态多尺度知识蒸馏增强多模态特征的交互作用。此外，研究还通过与GNSS-RTK全球定位模块和全局束调整的集成，展示了在实际场景中的实时性能，验证了FMF-SLAM的有效性

Innovation: 
1. 利用快速傅里叶变换（FFT）提高算法效率n2. 引入基于傅里叶变换的自我注意和交叉注意机制来提取特征n3. 通过跨模态多尺度知识蒸馏增强多模态特征的交互作用n4. 将FMF-SLAM与GNSS-RTK全球定位模块和全局束调整集成

Conclusion: 
本文提出了一种名为FMF-SLAM的高效多模态融合SLAM方法，通过引入基于傅里叶变换的自我注意和交叉注意机制以及多尺度的知识蒸馏增强跨模态交互，有效解决了噪声、不同光照条件和黑暗环境下的SLAM挑战。通过实验证明，FMF-SLAM在真实场景中实现了实时性能，并展示了在TUM、TartanAir和自建数据集上的优越性能。该方法的代码和数据集可以在指定网址获取</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18204</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>227. cs.AI-在大型语言模型中减轻针对阿拉伯人和穆斯林的文化偏见的提示工程技术：一项系统综述</title><link>https://arxiv.org/pdf/2506.18199</link><description>Background: 
大型语言模型在多个领域展现了卓越的能力，但它们对阿拉伯人和穆斯林的潜在文化偏见引发了显著的伦理挑战，这些偏见助长了有害刻板印象和边缘化。尽管学术界对大型语言模型中的偏见越来越重视，然而专门针对阿拉伯人和穆斯林代表性的提示工程技术仍鲜有研究。本文通过一项混合方法的系统评估，审阅了2021年至2024年间发表的8篇实证研究，这些研究探讨了减轻偏见的策略，提供了研究人员和实践者的证据指导。这些研究采用PRISMA和Kitchenham的方法论，揭示了五种主要的提示工程技术：文化提示、情绪激发、自我偏见修正技术、结构化的多步骤管道以及参数优化的连续提示。

Innovation: 
本文通过对8篇实证研究的系统梳理，提出了五种主要的提示工程技术，为减轻文化偏见提供了实证指导。研究成果强调了提示工程在减轻文化偏见方面的广泛可用性，无需访问模型参数。这项研究填补了现有研究中的一个重要空白，并提出了未来研究的几个方向，包括开发适应文化差异的提示技术、构建阿拉伯人和穆斯林专用的评估资源，以及将提示工程技术与互补的偏见修正方法结合，以解决更深层次的刻板印象，同时保持模型的实用性。

Conclusion: 
尽管提示工程技术都展示了降低偏见的潜力，但不同研究和偏见类型的有效性差异显著。结构化的多步骤管道表现出最高的总体有效性，能够减少高达87.7%的偏见，但需要更高的技术专长。文化提示则提供了更为广泛的可用性，展现出显著的有效性。这项研究表明，提示工程技术在减轻文化偏见方面具有很高的可用性，无需对模型参数进行访问。然而，目前识别出的研究数量有限，表明在这一关键领域仍存在显著的研究空白。未来的研究应集中在开发适应文化差异的提示技术，创建阿拉伯人和穆斯林专用的评估资源，并将提示工程技术与互补的偏见修正方法结合起来，以解决更深层次的刻板印象，同时保持模型的实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18199</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>228. cs.AI-MindCube 的两种音效方法</title><link>https://arxiv.org/pdf/2506.18196</link><description>Background: 
MindCube 是一种交互式设备，旨在研究情绪。该设备集成了多种传感器和输入设备，类似于常见的帮助用户缓解压力和焦虑的指尖玩偶（调节镇定玩具）。因此，它非常适合用于情感调节的音乐系统。本文介绍了两种不同的MindCube映射方法，一个是带有AI，另一个是不带AI的。

Innovation: 
提出了一种将意义注入潜在空间的方法，并结合外部控制器导航的方法。使用生成的AI映射，展示了如何将意义注入潜在空间，并提出了一种通过外部控制器导航该空间的技术。

Conclusion: 
讨论了研究结果，并提出了未来工作的方向，包括进一步探讨如何通过外部控制器引导用户与潜在空间进行交互的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18196</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>229. cs.AI-通过近视自信心调整看群体智慧</title><link>https://arxiv.org/pdf/2506.18195</link><description>Background: 
群体的集体判断或决策往往比个体判断更准确，这被称为群体的智慧。例如，高尔顿在国家集市上描述的一个著名比赛中，个体对牛重量猜测的中位数竟非常接近实际重量。本文讨论了一组持有对世界共同状态的独立、无偏且有噪声初始估计的代理，它们通过非贝叶斯学习规则进行迭代更新。这种迭代分布式均值过程导致每个代理获得世界状态的渐近估计，这种估计的方差取决于代理之间赋予权重的矩阵。代理的目标是尽量减少其渐近估计的世界状态方差。

Innovation: 
研究通过近视自信心调整的优化方法，解决代理在不同权重分配下的多目标优化问题，并刻画Pareto前沿和Nash均衡点。此外，研究了代理异步最优响应动力学，证明其收敛到严格Nash均衡集。

Conclusion: 
通过迭代分布式均值过程，代理能够取得世界状态的最佳估计。代理间的权重分配不仅影响自身的估计质量，也影响其他代理的估计质量。通过解决给定权重集下的多目标优化问题，代理能够找到最优的权重分布，从而实现更好的状态估计。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18195</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>230. cs.AI-DeInfoReg：一种通过更好地利用训练吞吐量的解耦学习框架</title><link>https://arxiv.org/pdf/2506.18193</link><description>Background: 
传统监督学习方法中，长时间梯度流动导致梯度消失问题，影响模型性能。标准反向传播（BP）方法在处理长时间梯度流动时表现不佳，其他梯度流动分解技术也存在类似问题。因此，需要一种新的方法来解决这些问题，提高模型训练的吞吐量并增强模型的噪声抵抗力。

Innovation: 
该论文提出了Decoupled Supervised Learning with Information Regularization (DeInfoReg)，通过将长时间梯度流动分解为多个较短的梯度流动，缓解梯度消失问题。该方法结合了流水线策略，允许模型在多个GPU上进行并行化，显著提升了训练吞吐量。此外，与标准BP方法和其他梯度分解技术相比，DeInfoReg在多个任务和数据集上展示了更优的性能和更好的抗噪声能力，并且能够有效利用并行计算资源。

Conclusion: 
实验证明，DeInfoReg在多种任务和数据集上能够显著提升训练吞吐量，且具有更好的性能和抗噪声能力，其代码可在指定网址获得，以保证结果的可重现性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18193</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>231. cs.AI-Call Me Maybe: 使用图神经网络增强 JavaScript 调用图构建</title><link>https://arxiv.org/pdf/2506.18191</link><description>Background: 
静态分析在发现软件错误，包括安全问题中起着关键作用，构建准确的调用图是其中的关键一步。然而，由于语言的复杂性，现有的 JavaScript 调用图构建算法不完整也不精确。先前的研究表明，即使高级解决方案也会生成虚假边和遗漏有效的边。本文通过识别遗漏的调用边来协助这些工具。作者将问题框架化为完整的程序图中的链接预测问题，并使用包含多种边类型的丰富表示。方法名为 GRAPHIA，利用图神经网络在动静态数据上的发展来建模代码元素之间的非局部关系。实验在50个流行的JavaScript库上进行，这些库有163K条调用边（150K条静态边和13K条动态边）。

Innovation: 
GRAPHIA 利用图神经网络（GNN）的方法来识别缺少的调用边，其不同于传统的机器学习评价指标（ROC），而是通过排名未解决的调用站点附近的函数定义来进行评定。

Conclusion: 
实验结果表明，基于学习的方法可以提高JavaScript调用图构建的召回率。这是我们首次使用基于GNN的链接预测方法来构建完整的多文件程序图进行跨过程分析的工作。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18191</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>232. cs.AI-CareLab在SMM4H-HeaRD 2025中的表现：基于领域意识变换器的失眠检测和食品安全事件提取</title><link>https://arxiv.org/pdf/2506.18185</link><description>Background: 
本文介绍了CareLab在SMM4H-HeaRD 2025共享任务中的系统，具体涉及Task 4（子任务1、2a和2b）及Task 5（子任务1和2）。Task 4的任务是检测临床记录中的失眠提及，而Task 5的任务是从新闻文章中提取食品安全事件。研究团队参与了所有子任务，并报告了关键发现，特别是在Task 5的子任务1中，他们的系统取得了优异的F1评分为0.958。

Innovation: 
为了达到这一成果，研究团队采用了基于编码器的模型（例如RoBERTa），并结合了GPT-4进行数据增强。这一方法突出了领域意识变换器在提升模型性能中的作用，并在食品安全事件提取方面取得了显著效果，在子任务1中排名第一。

Conclusion: 
本文详细介绍了团队的方法，包括预处理、模型架构以及针对不同子任务的具体适应性调整，展示了他们如何通过领域的敏感性改进模型性能，特别是在食品安全事件提取方面取得了突破。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18185</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>233. cs.AI-STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification</title><link>https://arxiv.org/pdf/2506.18172</link><description>Background: 
甲状腺癌是美国最常见的癌症之一。甲状腺结节经常通过超声（US）影像检测出来，有时需要通过细针穿刺抽吸（FNA）活检进一步评估。虽然FNA有效，但它常常导致良性结节不必要的活检，使患者感到不适和焦虑。美国放射学院开发了甲状腺影像报告和数据系统（TI-RADS）以减少不必要的活检，但这些系统受到观察者间变异性的限制。虽然最近的深度学习方法试图改善风险分层，但这些方法通常未能充分利用超声动态视频（CINE）短片提供的丰富的时序和空间上下文，这些短片包含不同视角的动态全局信息和周围结构的变化。

Innovation: 
本文提出了一种新的时空交叉注意力方法，用于甲状腺超声连续时间序列分类的STACT-Time模型。该模型结合了超声连续视频片段的成像特征和自动生成分割掩膜的特征，并利用自我注意力和交叉注意力机制来捕捉超声连续视频片段的丰富时空上下文，同时通过分割引导的感知增强特征表示能力。与当前最先进的模型相比，该模型在恶性肿瘤预测方面表现出色，交叉验证精度为0.91（±0.02），F1分数为0.89（±0.02）。通过减少不必要的良性结节活检并维持恶性肿瘤检测的高敏感性，该模型具有提高临床决策和改善患者预后的潜力。

Conclusion: 
提出的STACT-Time模型能够通过结合超声连续视频和分割掩膜特征，并利用时空交叉注意力机制，提高恶性肿瘤预测的准确性，具有在临床决策中提高患者预后的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18172</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>234. cs.AI-通过引导矢量理解思考型语言模型的推理</title><link>https://arxiv.org/pdf/2506.18167</link><description>Background: 
大型语言模型（LLMs）的最新进展催生了能够生成详细内部推理链再作回应的思考型语言模型。尽管这些模型在性能上有所提升，但如何控制它们的推理过程仍然是一个挑战。本文通过分析并操控DeepSeek-R1-Distill模型中的特定推理行为，提出了一种引导方法，旨在通过系统实验了解这些模型表现出的多种推理行为，包括表达不确定性、为假设验证生成示例以及在推理链中回溯等。这些行为由模型激活空间中的线性方向介导，可以通过引导矢量进行控制，从而调节模型推理过程的特定方面，如回溯倾向或表达不确定性。这项研究提供了一种通过引导矢量在有控制和可解释的情况下引导推理过程的实际工具，并通过两个DeepSeek-R1-Distill模型进行了验证，展示了在不同模型架构之间的一致性控制。

Innovation: 
本文提出了一种引导方法，通过分析并操控DeepSeek-R1-Distill模型中的特定推理行为，找到了这些行为由模型激活空间中的线性方向介导，并证实可以通过引导矢量调控这些推理行为，实现对模型推理过程的精准控制和解释。

Conclusion: 
本文提供了一种通过引导矢量在不同模型架构之间一致控制和解释思考型语言模型推理过程的方法，并通过实验验证了这种方法的有效性和实用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18167</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>235. cs.AI-非平衡关联回撤采样器</title><link>https://arxiv.org/pdf/2506.18165</link><description>Background: 
近年来，基于学习的扩散采样器取得显著进步，旨在从给定的非规范化密度中抽样。这些方法通常遵循两种范式之一：(i) 使用标准参考过程将抽样公式化为无偏的随机最优控制问题 (SOC)；或 (ii) 通过重要性加权采样细化退火路径措施。尽管退火方法在引导样本向高密度区域移动方面具有优势，但依赖重要性抽样会导致实际中的高方差和有限的可扩展性。

Innovation: 
本文介绍了一种新颖的基于SOC的扩散采样器——非平衡退火回撤采样器（NAAS），它利用退火参考动力学，而不依赖重要性抽样。NAAS 使用受对偶匹配启发的简化的回撤系统，使训练变得高效和可扩展。

Conclusion: 
我们展示了我们方法的有效性，包括从经典能量景观和分子玻尔兹曼分布中抽样等任务。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18165</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>236. cs.AI-QuranMorph: 《古兰经》形态标注语料库</title><link>https://arxiv.org/pdf/2506.18148</link><description>Background: 
文章背景介绍了QuranMorph语料库的建立背景。为了解决古兰经文本中的词汇形态标注问题，研究人员开发了这一语料库。语料库包含了77,429个标注好的词汇，这些词汇是经过三个专家语言学家手动词形还原和词性标注的。这个过程使用了一个名为Qabas的阿拉伯语词汇数据库，其中包括了110个词汇库和超过200万词汇的语料库，并采用了精细标注的SAMA/Qabas词性标注集，该标注集有40个标签，这使得QuranMorph能够与许多语言资源互联，提升了古兰经研究的精度和广度。

Innovation: 
QuranMorph的创新之处在于其通过人工词形还原和详细的词性标注，解决了古兰经文本中的形态学标注问题。这不仅提高了古兰经研究的准确性，还使得这项语料库能够与其他大量的语言资源进行关联和整合，为语言学、宗教研究等领域提供了重要资源。其独特的词性标注体系和丰富的词汇资源值得同行参考借鉴。

Conclusion: 
文章总结指出，QuranMorph语料库是一个开放源代码并且公开发布的资源，可以在此网站（这个 https URL）获得。该语料库的建成不仅填补了古兰经研究在形态标注方面的空白，还为进一步的研究提供了坚实的基础，对于古兰经研究和阿拉伯语言学研究都具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18148</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>237. cs.AI-路由Mamba：通过专家投影扩展状态空间模型</title><link>https://arxiv.org/pdf/2506.18145</link><description>Background: 
状态空间模型（SSMs）通过保持高效推理时间和稳定的空间复杂性，在序列建模中表现出显著的性能提升。Mamba等最近的发展引入了输入依赖的门控机制和硬件感知实现，将SSMs打造成与Transformers相比极具竞争力的长序列建模选项。然而，将混合专家（MoE）有效地集成到SSMs中，以扩展其表达能力仍存在挑战，简单的集成尝试往往无法成功或导致性能下降。因此，通过一种新颖的方法来有效和高效地稀疏扩展Mamba层成为了亟待解决的问题。

Innovation: 
提出了一种名为Routing Mamba（RoM）的方法，使用稀疏线性投影专家的混合来扩展SSM参数。RoM通过在投影层和Mamba专家内部的轻量级子模块之间共享路由决策，利用线性投影专家之间的协同作用，实现有效且高效的稀疏扩展。在模型规模达到1.3B活跃参数（总计10B）、训练序列长度为16K时，RoM的自然语言建模性能与需要超过2.3倍活跃参数的密集Mamba模型相当，并且展示了在不同上下文长度下一致的困惑度。实验结果还表明，RoM能够有效扩展混合语言模型，与密集Mamba模型相比，在相似性能下节省了23%的FLOPS。

Conclusion: 
RoM通过共享路由决策并利用线性投影专家之间的协同作用，在保持高性能的同时，有效地稀疏扩展了Mamba层，这为状态空间模型的高效扩展提供了一种新的解决方案。实验结果证实了RoM在语言建模任务中具有竞争力，并在混合语言模型扩展中展示了显著优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18145</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>238. cs.AI-AI谐音器：利用生成神经符号音乐AI系统扩展声乐表达</title><link>https://arxiv.org/pdf/2506.18143</link><description>Background: 
声乐谐音器是帮助独唱者丰富旋律的有力工具，这些工具以不同的形式存在，从商业可得的踏板和软件到自定义构建的系统。传统谐音器通常需要用户手动指定关键音或音调中心，或者允许通过外部键盘选择音高，这两种方法都要求一定的音乐专业知识。本论文介绍了一种名为AI谐音器的新方法，它能够自主生成四声部的音乐和谐音，无需用户提供事先的和声信息。通过结合最先进的生成AI技术进行音高检测和声音建模，以及自训练的符号音乐模型，系统可以将任何旋律编排成丰富的合唱音效。

Innovation: 
该系统利用最先进的生成AI技术和符号音乐模型，无需用户事先提供和声信息即可自主生成音乐和谐音，这在目前的市场应用中是一次创新。系统能够自动将任何声乐旋律编排成丰富的合唱音效，为声乐表达提供了新的可能性。

Conclusion: 
尽管该系统目前以离线方式运行，但仍被认为是AI辅助声乐表演和富有表现力的音乐增强的重要一步。作者已在GitHub上发布了系统的实现代码，为未来实时应用的发展奠定了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18143</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>239. cs.AI-稀疏特征共激活揭示大型语言模型中的可组合语义模块</title><link>https://arxiv.org/pdf/2506.18141</link><description>Background: 
研究者们在大型语言模型（LLMs）中识别出具有语义一致性的网络组件，这些组件以少量提示收集到的稀疏自编码器（SAE）特征的共激活方式呈现。这一研究集中在国家关系任务上，通过消除和放大特定语义组件对模型输出的影响进行分析。研究表明，大多数国家组件出现在模型的第一层，而更具抽象性的关系组件则主要分布在后续层。此外，关系组件中更深层的节点对模型输出的影响更为显著。这些发现表明，LLMs内部的知识组织具有模块化特征，并促进了对模型进行高效且目标化的调整方法的发展。

Innovation: 
该研究通过稀疏自编码器（SAE）特征的共激活识别出大型语言模型中的语义一致且上下文一致的网络组件。这种方法只需要少量的提示即可揭示出国家关系任务中的可组合语义模块，通过消除和放大特定语义组件能够观察到对模型输出的可预测性变化，进一步发现不同层对模型输出的影响差异，揭示了LLMs中知识的模块化组织形式。

Conclusion: 
该研究发现，大多数国家组件出现在模型的第一层，但更具抽象性的关系组件在更深层次中更为集中。在关系组件内部，较深层的节点对模型输出的影响更为显著。这些研究表明，在LLMs内部存在模块化的知识组织，并且提出了针对模型的有效且有针对性的调整方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18141</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>240. cs.AI-$φ^{∞}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models</title><link>https://arxiv.org/pdf/2506.18129</link><description>Background: 
在自回归变压器语言模型中，发现了一个关键漏洞，即破折号标记会导致递归语义漂移，进而导致从句边界幻觉和嵌入空间纠缠。通过形式化分析语义格中的标记级扰动，证明了破折号插入从根本上改变了模型的潜在表示，导致长文本生成中的累积错误。

Innovation: 
提出了结合phi-infinity操作符的符号性从句净化和目标嵌入矩阵校准的新解决方案。该方法能够在无需重新训练模型的情况下完全抑制有问题的标记，同时通过固定点收敛保证保留语义连贯性，实验验证显示生成一致性与话题保持有显著改进。这项工作为识别和缓解基础模型中的标记级漏洞提供了一般框架，对于人工智能安全、模型对齐和大语言模型的稳健部署具有即时影响，该方法不仅限于标点符号，还可用于解决神经文本生成系统中的更广泛的递归不稳定性问题。

Conclusion: 
这一研究确立了一种通用框架，用于识别和缓解基础模型中的标记级漏洞，具有即时的AI安全、模型对齐及大语言模型生产环境中的稳健部署的含义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18129</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>241. cs.AI-机器同伴的概念化，操作化和测量：一项范围性综述</title><link>https://arxiv.org/pdf/2506.18119</link><description>Background: 
机器同伴的概念已长期存在于社会技术想象中。近年来，人工智能的进步使得这些媒体构想转变成可感知的社会交往，体现在界面、机器人身体和设备上。这些机器通常被称为“同伴”，但对其作为正式概念或测量变量的细致探讨相对缺乏。本研究受PRISMA指南的指导，系统地抽样、调查并综合分析了2017年至2025年间共71篇关于机器同伴（MC）的学术作品，旨在解决这一问题。这些研究在考虑机器同伴时理论指导各异，先验规定属性的维度也不同（主观积极、长时间持续、互动性、目的自足），所测量的概念更是多样（逾50个不同的测量变量）。

Innovation: 
本文通过系统综述的方法，填补了关于机器同伴作为正式概念及其测量变量的文献空白。研究者提出了一种由文献指导的机器同伴定义，强调它是人类与机器之间自足、协调连接的过程，持续时间长且主观体验积极正面。此外，研究还全面审查了当前关于机器同伴的研究，揭示其多样性和复杂性，为未来的实证研究提供了重要参考和指导.

Conclusion: 
本文系统地综述了机器同伴的研究现状，定义了机器同伴的概念，并探讨了它在多个维度上的测量方法。研究结果有助于未来在机器同伴领域进行更为深入的实证研究，尤其是在用户体验和人机交互设计方面的应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18119</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>242. cs.AI-Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives</title><link>https://arxiv.org/pdf/2506.18116</link><description>Background: 
大型语言模型（LLMs）在心理卫生领域的应用可能会传播偏见，这些偏见可能会强化刻板印象并伤害边缘化群体。尽管之前的研究已经发现了一些令人担忧的趋势，但是系统性的方法来检测交集偏见仍然有限。本文通过引入多跳问答（MHQA）框架，探索LLM在心理卫生对话中的反应偏见。研究团队分析了来自Interpretable Mental Health Instruction (IMHI)数据集的内容，涵盖了症状表现、应对策略和治疗方法。通过系统性地标签化年龄、种族、性别和社会经济地位，他们研究了在不同人口统计学交集处存在的偏见模式。评估了四种LLM，并揭示了它们在情感、人口统计学和心理卫生状况方面的系统性差异。MHQA方法相比传统方法在偏见检测方面表现更优，尤其是在顺序推理中找到偏见放大的关键点。研究还实施了两种去偏技术：角色扮演模拟和显式偏见减少，通过使用BBQ数据集示例的少量提示，实现了66%到94%的偏见减少。这些发现强调了LLMs再现心理健康偏见的关键领域，并提供了实现公平AI开发的实际见解。

Innovation: 
该工作引入了多跳问答（MHQA）框架，目的是探索大型语言模型（LLMs）在心理健康对话中的反应偏见。与传统方法相比，MHQA方法在偏见检测方面表现更优，尤其是在顺序推理中找到偏见放大的关键点。研究还实施了两种去偏技术，即角色扮演模拟和显式偏见减少，通过少量提示实现了显著的偏见降低。

Conclusion: 
研究发现大型语言模型在心理健康领域再现偏见的问题，并提供了实际的建议以推动公平AI的发展。MHQA方法更有效地检测到偏见的放大点，并实验证明了去偏技术的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18116</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>243. cs.AI-通过适应回溯揭示理由的RL进行推理</title><link>https://arxiv.org/pdf/2506.18110</link><description>Background: 
监督微调（SFT）依赖密集的真理标签，随着序列长度的增长，标签成本增加；而强化学习（RL）则难以处理稀疏的奖励和大量组合的输出空间。文章提出强化学习可以从部分专家演示中获取训练，是一种解决复杂序列生成任务有前途的框架，旨在弥合SFT和RL之间的效率和通用性差距，特别是在存在长序列的潜在依赖关系的任务上，两种方法都难以泛化。

Innovation: 
提出了一种适应性回溯（AdaBack）算法，它在训练时只揭示目标输出的部分前缀，每次样本的监督长度根据模型过去的奖励信号动态调整，使其能够逐步通过条件方式学习完成推理链。这种方法介于SFT和RL之间，有效解决了长序列潜在依赖关系的任务，即使SFT和RL都无法泛化也能成功。在合成任务和数学推理基准数据集（MATH, GSM8k）上验证了这种方法的有效性，并展示了其解决RL单独无法解决的问题的能力，通过逐步接触部分解决方案，模型获得了新的推理能力。

Conclusion: 
通过集成适应回溯的RL方法在其训练中能有效克服SFT和RL各自的局限，在长序列潜在依赖关系的任务中表现出了优越的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18110</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>244. cs.AI-分享GPT-4o-Image：实现与GPT-4o级图像生成能力的多模态模型对齐</title><link>https://arxiv.org/pdf/2506.18095</link><description>Background: 
近期在多模态生成模型方面的进展已经实现了逼真的、指令对齐的图像生成，但现有系统如GPT-4o-Image仍保持专有且不公开。为了普及这些能力，本文提出了ShareGPT-4o-Image，这是一个包含45000个文本到图像和46000个文本和图像到图像数据集的第一个数据集，并且使用了GPT-4o的图像生成能力以提炼出其高级图像生成能力。

Innovation: 
本文开发了Janus-4o，这是一种多模态的大语言模型，能够进行文本到图像和文本和图像到图像的生成。Janus-4o不仅在文本到图像生成方面超过了其前一个版本Janus-Pro，还首次支持文本和图像到图像的生成。更值得注意的是，它仅使用91000个合成样本在8个A800-GPU机器上训练6小时就能够实现从零开始的文本和图像到图像生成，取得了令人印象深刻的性能。

Conclusion: 
希望ShareGPT-4o-Image和Janus-4o的发布能够促进在逼真的、指令对齐图像生成方面的开放研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18095</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>245. cs.AI-RoboTwin 2.0: 一种具有强大领域随机化的可扩展数据生成器和基准用于鲁棒双臂机器人操作</title><link>https://arxiv.org/pdf/2506.18088</link><description>Background: 
模拟数据合成正在成为增强现实世界机器人抓取技术的一个强大范式。然而，现有的合成数据集对于稳健的双臂操作而言仍然不足够，主要因为缺乏高效且可扩展的新型任务数据生成方法以及过度简化的模拟环境无法捕捉现实世界的复杂性。

Innovation: 
该论文提出了RoboTwin 2.0，这是一个可扩展的仿真框架，它能够自动、大规模地生成多样且真实的双臂操作数据，并配备了一致性的评估协议。RoboTwin 2.0包括一个大型对象库RoboTwin-OD、通过结合多模态大型语言模型与闭环仿真改进的数据合成流水线、以及包含五轴结构化领域随机化的方法来优化模拟数据的真实性，增强模拟到现实的转移。此外，i们还实例化该框架用于多个双臂操作任务，并进行了大规模的领域随机化专家轨迹前收集。

Conclusion: 
实验结果显示相对于新型场景提高了10.9%的代码生成成功率并增强了对新型真实场景的泛化能力。基于我们数据集微调的VLA模型在未见场景上取得了42.0%的实际任务表现，而仅使用我们合成数据训练的零样本模型也取得了228%的相对提升，证明了在无需真实世界监督的情况下强大的泛化性能。最后，论文开源了数据生成器、基准测试、数据集和代码以支持鲁棒双臂操作的可扩展研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18088</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>246. cs.AI-基于大型语言模型增强边缘云AI系统安全性的联邦学习数据协作方法</title><link>https://arxiv.org/pdf/2506.18087</link><description>Background: 
随着边缘计算和云系统在AI驱动的应用中的广泛应用，如何在保证数据隐私的同时维持高效性能变得尤为重要，成为一个迫切的 security 问题。现有的方法需要新的解决方案来维护边缘云AI系统的安全性和鲁棒性，特别是在保护数据隐私和增强数据加密过程方面存在不足。

Innovation: 
本文提出了一种基于联邦学习的数据协作方法，利用大型语言模型（LLMs）增强边缘云AI系统的数据隐私保护和系统鲁棒性。通过引入安全多方计算协议，该方法优化了分布式节点之间的数据聚合和加密过程，同时结合先进的对抗训练技术来增强边缘云AI系统对数据泄漏和模型中毒等安全威胁的抵抗力。这种方法比传统的联邦学习方法在数据保护和模型鲁棒性方面提高了15%。

Conclusion: 
本文提出了一种基于联邦学习的新的数据协作方法，结合大型语言模型提高了边缘云AI系统的安全性和鲁棒性。实验结果显示，该方法在数据保护和模型鲁棒性方面比传统的方法表现更好。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18087</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>247. cs.AI-分布鲁棒最小化在系统辨识元学习中的应用</title><link>https://arxiv.org/pdf/2506.18074</link><description>Background: 
元学习旨在学习如何解决任务，从而估计能在新场景中快速适应的模型。标准元学习方法优化期望损失，但忽视了任务的变异性，这在最坏情况下的性能可能不佳。本研究探讨了在系统辨识的元学习中使用分布鲁棒最小化的方法，以提升算法在最坏情况下的性能。

Innovation: 
研究采用分布鲁棒优化范式，优先处理高损失任务，与标准元学习方法不同，它并未单纯优化期望损失，而是确保算法在最坏情况下也能有良好的性能。实验表明，该方法在安全关键应用中减少了失败情况。

Conclusion: 
研究通过在合成动力学系统元模型上进行训练，并在分布内和分布外环境中进行测试，证明了分布鲁棒最小化策略能够减少安全关键应用中的失败情况，从而提高了在最坏情况下的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18074</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>248. cs.AI-通过共享文本嵌入实现的多模态医学影像绑定</title><link>https://arxiv.org/pdf/2506.18072</link><description>Background: 
医学图像分析越来越依赖于多种成像模态的整合，以捕捉互补的解剖和功能信息，从而实现更准确的诊断和治疗计划。不同模态的特征表示对有效的多模态分析至关重要。虽然现有的对比语言-图像预训练（CLIP）模型能够实现图像-文本对齐，但它们需要在成对数据之间明确配对，这在医疗环境中难以获得。现有方法的这一限制促使研究人员开发了新的解决方案，以实现多模态医学图像的无缝对齐，而无需显式配对数据。

Innovation: 
提出了一个名为Mtextsuperscript{3}Bind的新型预训练框架，该框架能够通过共享的文本表示空间无需两个医学图像模态之间的显式配对数据就能实现多模态医学影像的无缝对齐。具体来说，Mtextsuperscript{3}Bind首先微调预训练的CLIP样式的图像-文本模型，以对齐它们的模态特定文本嵌入空间并保留它们原有的图像-文本对齐关系，然后通过这些特定模态的文本编码器创建一个统一模型，构建一个共享的文本嵌入空间。实验结果表明，Mtextsuperscript{3}Bind在无监督、小样本分类和跨模态检索任务中的表现优于现有的CLIP样式的对应物，验证了其在医学分析中实现跨模态对齐的有效性。

Conclusion: 
Mtextsuperscript{3}Bind能够有效地实现多模态医学影像的无缝对齐，无需显式配对数据，实验展示了其在多种下游任务中的优越性能，并验证了其在医学图像分析中的有效应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18072</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>249. cs.AI-MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering</title><link>https://arxiv.org/pdf/2506.18071</link><description>Background: 
现代多模态模型在进行Grounded Video Question Answering（地面化视频问答）时，往往依赖于语言先验和伪相关性，导致预测结果缺乏精确的视觉证据支持，使得模型的接地性较差，影响了问答质量。因此，需要一种方法能够更好地将文本问题与视频中的视觉证据进行精确对齐，提高模型的回答准确性和接地性。

Innovation: 
提出了MUPA（MUlti-Path Agentic），一种协同的多路径智能体方法，该方法将视频接地、问题回答、答案反思和汇总统一起来解决Grounded VideoQA问题。MUPA设计了三个不同顺序的推理解析路径，以及一个专门的反思智能体来进行多路径结果的判断和汇总，从而实现一致的问题回答和接地。这种方法在仅使用2亿参数的情况下，显著优于所有7亿参数规模的竞争者，并在扩展到7亿参数时，达到了新的SOTA结果。

Conclusion: 
MUPA通过多路径智能体协同推理，提升了回答准确性和接地性，即使在较小的参数量下，也优于更大参数量的模型，且在大规模扩展后，取得了新的最好成果，证明了MUPA在可信视频语言理解上的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18071</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>250. cs.AI-在存在架构混淆的情况下机械可解释性</title><link>https://arxiv.org/pdf/2506.18053</link><description>Background: 
近年来，采用混淆（如替换隐藏状态张量、线性变换嵌入表或重新映射标记）等轻量级方法作为传统加密的替代方案，以实现对大型语言模型（LLM）推理的隐私保护。尽管已有研究展示了这些方法在面对专门的重建攻击时存在被破解的风险，但它们对模型机械可解释性的影响尚未被系统性地研究过。尤其是在混淆算法的内部表示真的阻止对模型工作原理的理解，还是仅将其转移到了不熟悉的坐标系统中这一问题上，依然存在不确定性。因此，有研究旨在通过使用一个从头开始训练的小型GPT-2模型来定量分析混淆对于注意头层功能的具体影响，从而理解和解决这一问题。

Innovation: 
研究引入了使用GPT-2-small模型进行混淆的系统性分析，通过采用私有的混淆映射和隐藏原始基数的方法，对应了诚实而好奇的服务端情况。研究运用logit-lens归因、因果路径修补和注意力头剔除等技术寻找和操控已知电路，并发现混淆显著改变了注意头的激活模式，但层内的计算图仍然保持不变。这导致了用户输入的逆向工程变得困难，因果痕迹失去了与基线语义的对应关系，同时，前馈和残差路径保持功能健全，表明混淆降低了细粒度的解释性而不影响高级任务性能。这一发现为证明混淆可以在保持全局模型行为的同时，干扰用户特定内容的机制分析提供了定量证据。通过揭示解释性出现故障的具体位置，该研究为进一步的隐私防御和鲁棒性意识可解释性工具提供了指导。

Conclusion: 
研究表明，架构混淆能够在保持全局模型行为的同时，妨碍对用户特定内容的机制分析。通过分析混淆导致解释性失效的区域，本研究为未来隐私防护提供了指导，并为构建鲁棒性意识的解释性工具提供了参考。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18053</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>251. cs.AI-大型语言模型对新闻自由低估的民主悖论</title><link>https://arxiv.org/pdf/2506.18045</link><description>Background: 
随着大型语言模型（LLMs）在全球范围内日益成为亿万用户获取信息的中介，它们的对齐与偏见可能会影响公众对基本民主机构，如新闻自由的理解和信任。本文研究了六种流行LLM在评估180个国家的新闻自由程度时，相比于世界新闻自由指数（WPFI）的专家评估，存在系统的失真和偏见问题。这些LLM普遍低估了新闻自由，部分模型甚至低估了超过90%的国家。另外还发现了差异性失真现象：在新闻自由最强的国家，LLM更加低估新闻自由。五种LLM显示出对本国的新闻自由有利的偏见，但考虑到它们的总体低估偏差，这种偏见更加显著。如果LLMs将成为下一代搜索引擎和最重要的文化工具之一，那么它们必须准确地代表全球的人权和公民权利状况.

Innovation: 
本文研究了大型语言模型在评估新闻自由程度时存在的系统失真问题，发现了LLM普遍低估新闻自由的负面对齐偏差，以及在新闻自由最强国家中的差异性低估分析。另外，还提出了对本国新闻自由有利的偏见现象，并强调了LLM作为重要文化和信息工具的责任，需要确保对全球人权和公民权利的准确描述.

Conclusion: 
大型语言模型在评估新闻自由时存在系统性失真和偏见，特别是低估新闻自由和对本国新闻自由的有利偏见，这可能影响公众对基本民主机构的理解和信任。如果LLMs继续发展成为重要的信息工具，必须确保它们准确反映全球的人权和公民权利状况，以促进公平、公正的信息传递和理解.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18045</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>252. cs.AI-ReLU神经网络的路径解释</title><link>https://arxiv.org/pdf/2506.18037</link><description>Background: 
神经网络在许多应用中取得了广泛的成功，但它们的“黑盒”特性引发了关于透明度和可靠性的担忧。前人对ReLU网络的研究尝试将这些网络转化为基于所有隐藏单元激活状态的线性模型。

Innovation: 
本文介绍了一种新型方法，考虑了参与决策路径的隐藏单元子集。路径解释提供了输入与决策过程之间关系的更清晰且一致的理解。此外，该方法还允许调整解释的范围，从整体到输入的具体成分，并可对给定输入进行分解以提供更详细的解释。实验表明，该方法在定量和定性方面都优于其他方法。

Conclusion: 
实验结果表明，我们的方法在定量和定性方面都优于其他方法，提供了对输入与决策关系更清晰和更一致的理解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18037</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>253. cs.AI-预训练大语言模型是具有语义意识的可迁移分割增强器</title><link>https://arxiv.org/pdf/2506.18034</link><description>Background: 
随着大规模语言模型（LLM）在自然语言处理中的发展，人们发现固定预训练的LLM层可以处理视觉标记以进行医学图像分割任务。研究者提出了一种简单的一体化结构，将固定预训练的LLM层整合到CNN编码器-解码器分割框架中（即LLM4Seg）。这种设计在多种成像模态，如超声、皮肤镜、息肉镜和CT扫描等，显著提升了分割性能，且训练参数几乎没有增加。深入分析表明，这种结构能够有效地转移LLM的语义意识，从而增强分割任务的效果，改善全局理解能力并增强局部建模能力。这种改进在多种LLM上都是稳健的，经LLaMA和DeepSeek验证.

Innovation: 
提出了一个将固定预训练的大语言模型层融入到CNN编码器-解码器分割框架的一体化结构（即LLM4Seg）。这种设计在医学图像分割中显示出了显著的性能提升，尤其是对多种成像模态。同时，研究表明这种增强可以从不同模型中转移到其他模型，证明了其广泛适用性和有效性。

Conclusion: 
固定预训练的大语言模型层能够显著提升医学图像分割的性能，并且这种增强是可转移的，可以在多种语言模型上得到验证，提高了分割任务的效果，尤其是在增加的训练参数非常有限的情况下。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18034</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>254. cs.AI-PP-DocBee2：利用高效数据提高多模态文档理解基准</title><link>https://arxiv.org/pdf/2506.18023</link><description>Background: 
PP-DocBee2是在PP-DocBee的基础上设计的增强版本，旨在提高多模态文档的理解能力。它基于大型多模态模型架构，通过对数据质量优化策略、视觉特征融合策略和推理方法的优化，克服了前一代产品的局限性。PP-DocBee2在中文商业文档的内部基准测试中表现出了11.4%的性能提升，并将推断延迟减少了73.0%。

Innovation: 
该工作的关键创新在于针对多模态文档任务的数据质量优化策略。通过使用大规模多模态预训练模型评估数据，并应用新型统计标准来过滤异常值，以确保高质量的训练数据。此外，通过分解ViT并将之与其他新型特征融合策略相结合，提高了复杂推理的能力。这些改进显著提升了多模态模型的性能和效率。

Conclusion: 
PP-DocBee2通过提高数据质量、优化特征融合策略和改进推理方法，在多模态文档理解方面取得了显著进步，特别是在中文商业文档的理解上。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18023</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>255. cs.AI-自回归表面切分</title><link>https://arxiv.org/pdf/2506.18017</link><description>Background: 
表面切分是计算机图形学中的一个基本任务，应用于UV参数化、纹理映射和网格分解。现有方法经常生成技术上有效但过度碎片化的UV图，缺乏语义连贯性。

Innovation: 
本文引入了SeamGPT，这是一种自回归模型，通过模仿专业工作流程生成切分接缝。关键的技术创新在于将表面切分形式化为下一个标记预测任务：在网格顶点和边采样点云，将其编码为形状条件，使用类似GPT的变压器顺序预测具有量化3D坐标的接缝段。该方法在包含流形和非流形网格的UV展开基准测试中表现出色，包括艺术家创作和3D扫描的模型。此外，它通过提供部分分解的干净边界来增强现有的3D分割工具。

Conclusion: 
该方法在UV展开基准测试中表现出色，特别是在包含流形和非流形网格的情况下，同时增强了现有的3D分割工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18017</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>256. cs.AI-ADA-DPM：基于神经描述子的自适应噪声点过滤SLAM策略</title><link>https://arxiv.org/pdf/2506.18016</link><description>Background: 
LiDAR SLAM已经在移动机器人导航和高精度地图构建等领域展现了显著的应用价值。然而，现有的方法在动态物体干扰、点云噪声和非结构化环境等问题下，往往需要在定位精度和系统鲁棒性之间做出权衡。

Innovation: 
为了应对这一挑战，作者提出了一种自适应噪声过滤SLAM策略——ADA-DPM。该策略包括三个主要创新点：设计了动态分割头以预测属于动态点的特征点类别，从而消除动态特征点；设计了全局重要性评分头以自适应选择具有更高贡献和特征的点并对噪声进行抑制；构建了跨层内部图卷积模块(GLI-GCN)，以融合多尺度邻域结构，从而增强重叠特征的辨别能力。

Conclusion: 
最后，作者测试了该方法在几个公开数据集上，取得了显著的效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18016</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>257. cs.AI-通过最小词汇扰动探究转换器的嵌入空间</title><link>https://arxiv.org/pdf/2506.18011</link><description>Background: 
理解信息如何在Transformer模型中传播是模型可解释性中的关键挑战。本研究通过分析最小词汇扰动对嵌入空间的影响，探究了嵌入空间中信息的传播机制。

Innovation: 
研究发现，罕见词汇通常会导致更大的扰动移动；输入信息的扰动会随着层数加深而逐渐混合；提出的结合词汇扰动和嵌入空间移动的方法为模型的可解释性提供了一种强有力的工具。

Conclusion: 
研究结果验证了模型初始层可以用作模型解释的代理假设，同时强调了通过最小词汇扰动探究嵌入空间的方法在模型解释性研究中的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18011</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>258. cs.AI-h-calibration: 以概率误差上界为目标重新思考分类器重新标定</title><link>https://arxiv.org/pdf/2506.17968</link><description>Background: 
深度神经网络在多种学习任务上表现出色，但往往存在失校准问题，导致输出概率不可靠。这一现象激发了许多关于降低失校准的新研究，尤其是在不牺牲预训练模型分类性能的前提下，通过后验重新校准方法获得可靠概率。已有研究总结和分类为三种主要策略：直观设计的方法、基于分箱的方法、基于理想校准公式的方法。然而，这些方法普遍存在十个常见局限性。

Innovation: 
本文提出了一种名为h-校准的概率学习框架，理论上构建了有界校准的等效学习公式，并基于此设计了一个简单但有效的后校准算法。该方法解决了前十个现有方法的局限性，并在广泛实验中表现出比传统方法更好的性能。此外，从理论上和实验上分析了我们学习目标与传统的适当评分规则的关系和优势。研究证明了我们提出的概率框架能为学习误差有界的概率提供一个近似等价可微目标，阐明了计算统计与理论校准中的收敛性之间的对应关系，该理论效果在标准的后校准基准上表现出色。

Conclusion: 
本研究提出的概率框架为学习可靠似然提供了有效的参考，并对相关领域具有重要价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17968</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>259. cs.AI-将视觉语言模型适应评估世界模型</title><link>https://arxiv.org/pdf/2506.17967</link><description>Background: 
世界模型是一种生成模型，能够在过去的观测和动作条件下模拟环境动态。这类模型在规划、仿真和具身AI中越来越受到重视。然而，评估这些模型的运行效果仍然是一项基础性挑战，现有的评价标准无法全面捕捉细粒度的时间相关信息以及语义一致性等重要能力。研究表明，视觉语言模型（VLMs）由于其强大的跨模态推理能力，在自动评价生成内容方面具有潜力，但在针对细粒度和时间敏感的评价任务时仍需进行特定的适应性调整。

Innovation: 
本文引入了一种评估协议，针对两个识别任务——动作识别和角色识别，分别采用二分类、多选项和开放式评估格式。为了支持这一评估协议，本文提出了UNIVERSE（统一视觉语言评估器，用于模拟环境中的运行评估），这是一种在数据和计算资源受限条件下调整视觉语言模型的方法。通过大规模研究比较全量、部分和参数高效微调、任务格式、上下文长度、采样策略和数据组成，最终得出了统一的评估器。该评估器在单一检查点的情况下可以达到任务特定基准线的性能。进一步的人类评估确认了其与人类判断的高度一致，证明了UNIVERSE作为一个可扩展且语义感知的世界模型评估器的有效性。

Conclusion: 
综合人类评估结果，UNIVERSE被证明是一种有效的且可扩展的评估方法，可以在细粒度、时间敏感的评价任务中使用统一的视觉语言模型实现世界模型的评估，同时保持了与人工判断的高度一致。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17967</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>260. cs.AI-OmniESI: 通过渐进条件深度学习统一预测酶-底物相互作用的框架</title><link>https://arxiv.org/pdf/2506.17963</link><description>Background: 
理解并模拟酶-底物相互作用对于催化机制研究、酶工程和代谢工程至关重要。尽管已经有许多预测方法出现，但这些方法并没有结合酶催化领域的先验知识，难以高效地调节一般蛋白质-分子特征使其符合催化模式。因此，开发一种能够整合这些知识的预测方法非常必要，以提高预测的准确性和效率

Innovation: 
提出了一个两阶段渐进框架——OmniESI，它采用条件深度学习来预测酶-底物相互作用。通过将酶-底物相互作用的建模分解为两个阶段，OmniESI 引入了两个条件网络，分别强调酶促反应特异性以及关键的催化相关相互作用，能够在从一般蛋白质-分子域到催化感知域的潜在空间中逐步调节特征。OmniESI 能够适应多种下游任务，包括酶动力学参数预测、酶-底物配对预测、酶突变效应预测和酶催化活性位点注释。在多种评价设置下，OmniESI 在七项基准测试中均表现出优于最先进的专门方法的性能，且内部网络代码展示了基本的催化效率模式，显著提高了预测性能，仅增加了极少的参数量

Conclusion: 
综上所述，OmniESI 是一种统一的预测酶-底物相互作用的方法，为催化机制破解和酶工程提供了强有力且具有广泛应用范围的有效工具</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17963</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>261. cs.AI-GeNIE: 一种用于野外环境的可泛化导航系统</title><link>https://arxiv.org/pdf/2506.17960</link><description>Background: 
在未结构化、真实的现实环境中实现可靠的导航对于搭载机器人的代理仍然是一项重大挑战，尤其是在跨越多样地形、各类天气条件和不同传感器配置时。为此，本研究旨在开发一个稳健的导航框架GeNIE（Generalizable Navigation for In-the-Wild Environments），以适应全球部署的需求。

Innovation: 
GeNIE框架结合了基于SAM2的通用可转移可通行性预测模型和一种新颖的路径融合策略，提升了在不确定和模糊条件下规划的稳定性。该系统在ICRA 2025年的地球漫游者挑战（ERC）中表现出色，特别是在六个跨越三大洲的国家中进行了实地测试，最终以总分79%的成绩获得第一名，并且比第二名提高了17%的优势，全程没有进行任何人工干预。这些结果对于野外机器人导航具有重要意义的新基准线。

Conclusion: 
研究团队将发布GeNIE的代码库、预训练模型权重和新收集的数据集，以支持未来现实世界导航领域的研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17960</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>262. cs.AI-基于散射的大型语言模型中多阶段过程适应中的创新传播</title><link>https://arxiv.org/pdf/2506.17949</link><description>Background: 
大型语言模型（LLMs）表现出在预训练期间观察到的模式复制和扩展的强大能力，但在将新概念推广到原有范围之外的其他部分方面存在局限。现有研究主要聚焦于在特定阶段或组件中引入的本地创新，但缺乏将这些创新推广到其他类似结构阶段的方法。本文旨在解决这一挑战，提出了一种基于散射的创新扩展模型（创新散射模型），该模型通过四个步骤实现创新的推广：一是通过对比用户输入与其上下文，识别核心创新；二是通过去除特定阶段或组件的引用，实现创新的泛化；三是判断泛化后的创新是否适用于更广泛的应用范围；最后，使用LLM系统性地将泛化后的创新应用于其他结构相似的阶段。该模型利用各阶段之间的结构冗余，提高新概念的应用范围和适用性。

Innovation: 
本文提出了创新散射模型，这是一种能够系统性地将特定阶段的本地创新推广到其他类似结构阶段的方法。该模型通过对比用户输入与其上下文，识别核心创新；通过去除特定阶段或组件的引用，实现创新的泛化；判断泛化后的创新是否适用于更广泛的范围；然后使用LLM系统性地将泛化后的创新应用于其他结构相似的阶段。该模型利用各阶段之间的结构冗余，增强创新的扩展和应用范围。

Conclusion: 
验证结果表明，创新散射模型能够使LLM在结构类似阶段扩展创新，从而提高推广和重用的范围。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17949</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>263. cs.AI-独立增量下的贪婪选择：一个玩具模型分析</title><link>https://arxiv.org/pdf/2506.17941</link><description>Background: 
本文研究了N个独立同分布的离散时间随机过程的选择问题。在每个阶段，基于已观察到的值，固定数量的过程被保留。通过简化模型，本文证明了在选择最终最大值过程方面，最优策略是每个阶段应用贪婪选择。这一结果依赖于强大的独立性假设，但它为多阶段淘汰设置中的贪婪启发式提供了清晰的解释，并且可以作为理解高维应用相关算法的玩具模型。

Innovation: 
本文证明了在独立增量模式下，贪婪选择策略是每个阶段选择最终最大值过程的最佳策略。这种策略是基于强大的独立性假设的，但在多阶段淘汰设置中为贪婪启发式算法提供了一个清晰的理论依据，可以作为一种在高维应用中理解相关算法的玩具模型。

Conclusion: 
本文通过简化模型，证明了在独立增量下贪婪选择策略的优势，并将其作为理解更复杂场景下的多阶段选择问题的工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17941</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>264. cs.AI-熵最优路径通往谦逊的人工智能</title><link>https://arxiv.org/pdf/2506.17940</link><description>Background: 
人工智能的进展催生了极其成功但并未表现出谦逊特性的模型和工具，特别是由于它们对资源的巨大需求和答案自信的问题。

Innovation: 
提出了一种基于精确的全概率定律的玻尔兹曼机非平衡熵最优重构的新数学框架，从而获得了成本更低、无需梯度下降的高性能学习框架，并具有数学证明的存在性和唯一性准则以及答案的可靠度量标准。与现有的先进AI工具在性能、成本和模型描述长度上的比较，结果显示提出的方法生成了更高效的模型，其描述长度接近于问题的固有复杂性增长边界。将这一框架应用于历史气候数据，产生了对于拉尼娜和厄尔尼诺现象预测能力更高的模型，所需训练数据仅为当前气候预测工具所需数据量的一部分。

Conclusion: 
相比于现有的先进AI工具，提出的熵最优方法生成了更高效的模型，描述长度接近问题复杂性边界，并在气候现象预测上表现更优。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17940</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>265. cs.AI-GEMeX-ThinkVG: 通过强化学习在医疗VQA中实现基于视觉定位的思考</title><link>https://arxiv.org/pdf/2506.17939</link><description>Background: 
医疗视觉问答旨在通过使模型基于医学图像回答自然语言问题来支持临床决策。虽然多模态学习的进步显著提高了性能，但现有方法仍存在答案可靠性有限和解释性差的问题，这影响了临床医生和患者理解并信任模型生成的答案。

Innovation: 
本工作首次提出了一个名为ThinkVG的数据集，其中答案生成被分解为中间推理步骤，显式地将相关视觉区域 grounding 到医学图像中，从而提供精细的解释性。同时还引入了一种新颖的可验证奖励机制，用于引导强化学习，改善了模型推理过程与最终答案之间的对齐。该方法仅使用训练数据量的八分之一就达到了可比的性能，证明了提案的有效性和效率。数据集可在此处获取: this https URL

Conclusion: 
通过我们的方法，即使使用较少的训练数据，也能够实现与现有方法相当的性能，展示了该方法在效率和效果上的优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17939</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>266. cs.AI-在生成型AI时代的软件重用：从鲨鱼文化到AI原生软件工程</title><link>https://arxiv.org/pdf/2506.17937</link><description>Background: 
当前软件开发正处于一个范式转变中，人工智能和生成型软件重用成为软件创作的核心。这导致早期的软件重用实践和方法迅速被人工智能辅助的方法所取代，开发者开始依赖由人工智能生成的代码。这一转变催生了一种新的软件重用形式，理论上与“鲨鱼文化”开发模式相似。

Innovation: 
本文讨论了人工智能辅助生成型软件重用在新兴的‘AI原生’软件工程背景下的影响，提出了相关的研究问题，并制定了初步的研究议程和行动呼吁，旨在应对这一方法所带来的一些核心问题。

Conclusion: 
本文呼吁研究界和工业界共同努力，解决AI辅助生成型软件重用所带来的挑战和问题，推动‘AI原生’软件工程的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17937</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>267. cs.AI-基于概念的XAI不精确：人们能否区分一般化与误导？</title><link>https://arxiv.org/pdf/2506.17936</link><description>Background: 
基于概念的可解释人工智能（C-XAI）能够揭示AI模型内部的表示方式。在复杂任务，比如安全性评估中，了解这些表示方式尤其重要，因为这些任务依赖高层次语义信息（如关于动作的信息）来判定抽象类别（如判断是一种情况是否危险）。概念的可变性可能表明AI能够超越特定情景的具体细节进行泛化。然而，目前尚不清楚人们是否能识别和欣赏这种泛化，并将其与不理想的、系统误导的概念区分开来。这一问题通过一个铁路安全试验情景得到了检验，参与者评估了一个模拟的AI系统，该系统决定是否存在可能构成威胁的交通场景。AI通过类似的图像片段提供解释。这些概念与分类图像的匹配程度不同，或者与关键特征（如与轨道相关的部分）相关，或与较无关特征（如动作）相关。现实中的假设被反证，不准确但与关键特征相关的内容比精确匹配内容得到了更高的评价，而系统错误表示这些特征的概念则与此相当。相反，参与者对关键特征的不准确性非常敏感。这些发现对C-XAI概念的理解提出质疑，可能表明人们不能自发地识别泛化，因而可能无法推断出AI模型是否获得了对于复杂情况的更深刻理解。

Innovation: 
该研究通过一个具体的铁路安全试验情景，探讨了人们是否能识别和区分由C-XAI提供的一般化概念与误导性概念。这项研究的独特之处在于它以实验的方式直接验证了人们的感知，特别是关于AI系统所传达的一般化和不精确性如何影响人们对安全评估结果的评价，从而揭示了C-XAI在实际应用中的潜在挑战和局限性.

Conclusion: 
研究表明，基于概念的C-XAI概念的不精确性（特别是当这种不精确体现在与核心特征不直接相关的事物上时）可能会导致人们对AI决策结果的负面评价。参与者更关注于核心特征的具体相关性，而不是概念的一般化。因此，C-XAI概念并不能自发地帮助人们推断出AI对复杂情景是否有了更深入的理解。这项研究提出了对C-XAI设计和应用的挑战，并建议在未来的设计中需要更加谨慎地考虑人们如何感知AI系统的决策过程和准确度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17936</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>268. cs.AI-一个基于GenAI的系统以改善独立生物数据库的FAIR集成</title><link>https://arxiv.org/pdf/2506.17934</link><description>Background: 
生命科学研究越来越依赖从不断演变的Linked Open Data (LOD)网络信息源中识别、访问和有效处理数据。这种动态环境对研究人员构成了重大负担，因为查询响应的质量高度依赖于数据源的选择和语义整合——这些过程通常耗费人力、容易出错且成本高昂。尽管FAIR（可查找、可访问、可互操作和可重用）数据原则的应用旨在解决这些挑战，但在高效和准确的数据处理方面仍存在障碍。

Innovation: 
FAIRBridge是一个实验性的基于自然语言的查询处理系统，旨在使科学家能够在数据不符合FAIR标准的情况下发现、访问和查询生物数据库。该系统利用人工智能能力来解析查询意图、映射到相关数据库并生成可通过智能资源访问计划执行的查询。此外，系统还包含工具以减少低质量查询处理，确保信息的高准确性和响应性。FAIRBridge的自主导航查询处理框架让用户能够探索替代数据源，在每一步做出知情选择，并在需要时利用社区驱动的众包。通过提供一个友好、自动化的自然英语下的假设测试平台，FAIRBridge显著提高了科学数据的集成和处理，为研究人员提供了一种更强大的工具来推进他们的研究。

Conclusion: 
FAIRBridge通过利用人工智能技术自主导航查询处理，不仅降低了数据处理的时间和成本，还提高了数据查询的准确性和效率。这为生命科学研究提供了一个新的强大工具，克服了现有FAIR数据处理的障碍。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17934</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>269. cs.AI-IDAL: Improved Domain Adaptive Learning for Natural Images Dataset</title><link>https://arxiv.org/pdf/2506.17931</link><description>Background: 
现有无监督领域自适应（UDA）方法通常采用增强表示空间中的领域对齐以适应输入空间中的领域转换。然而，现有的对抗领域适应方法可能无法有效对齐分类问题相关的多模态分布不同领域的特征。在自然图像数据集中，这些特征往往存在尺度、噪声和风格变化等问题，给模型带来挑战。本研究旨在提出一种新的方法，以提高多模态分布中的领域对齐，增强模型在目标领域的准确性和健壮性，并加速训练收敛速度。

Innovation: 
该方法有两个主要特点：1. 神经架构采用ResNet的深层结构和特性金字塔网络（FPN）的有效尺度分离，结合内容和风格特征；2. 利用一种新颖的损失函数与其他精选的损失函数结合训练网络架构，通过定制化的损失组合来解决自然图像领域的挑战。这种方法不仅提高了模型在目标领域的准确性和健壮性，还加速了训练收敛速度。

Conclusion: 
提出的UDA框架在Office-Home、Office-31和VisDA-2017数据集上优于现有的CNN方法，而在DomainNet数据集上的表现可与之匹敌。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17931</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>270. cs.AI-ASTER: 动态资源分配的自适应时空早期决策模型</title><link>https://arxiv.org/pdf/2506.17929</link><description>Background: 
时空智能领域的核心愿景一直是支持决策。尽管早期的工作提高了时空预测的及时性和准确性，但将这些预测转化为可操作的策略仍是一个关键挑战。主要缺点在于预测和下游决策阶段之间的脱节，这会显著降低下游效率。例如，在紧急响应中，优先是成功地分配和干预资源，而不仅仅是预测事件。因此，有必要提出一种自适应时空早期决策模型（ASTER），该模型将预测框架从事件预测转变为可操作的决策支持。这个框架确保信息直接用于决策，从而最大化整体效果。

Innovation: 
ASTER 提出了一种新的资源感知时空交互模块（RaST），该模块在动态资源条件下，自适应地捕捉长期和短期依赖关系，生成具有上下文感知的空间时空表示。此外，设计了一个偏好导向决策代理（Poda），基于多目标强化学习，该代理将预测信号转化为在特定偏好和动态约束下的资源高效干预策略。实验结果表明，ASTER 在六个下游指标上提高了早期预测准确性和资源分配效果，达到了最先进的性能。

Conclusion: 
实验结果表明，ASTER 在提高早期预测准确性和资源分配效果方面达到了最先进的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17929</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>271. cs.AI-Permutation Equivariant Model-based Offline Reinforcement Learning for Auto-bidding</title><link>https://arxiv.org/pdf/2506.17919</link><description>Background: 
目前，自动出价的强化学习（RL）方法已经从基于简单离线模拟器的 Offline RL Bidding (ORLB) 转变为使用固定真实数据集的 ORLB。尽管 ORLB 政策在数据集的状态空间覆盖方面受到限制，但仍能提供适度改进。而 Simulation-based RL Bidding (SRLB) 扩展了状态覆盖范围，但由于模拟器与真实环境之间的差距，可能会误导出价策略。文章探讨了这一状况，并指出现有方法的局限性。

Innovation: 
本文提出了 Model-based RL Bidding (MRLB)，利用从真实数据中学习的环境模型来缩小模拟器与现实之间的差距。MRLB 结合使用真实和模型生成的数据进行政策训练，从而扩展了状态覆盖范围，超越了传统的 ORLB。为确保模型可靠性，提出了以下创新点：1）提出了一个置换对称的模型架构以提高泛化能力；2）提出了一种稳健的离线 Q 学习方法，以悲观地惩罚模型中的错误。这些共同构成了 Permutation Equivariant Model-based Offline RL (PE-MORL) 算法。实验结果表明，PE-MORL 在与现有最佳的自动出价方法中表现出色。

Conclusion: 
实验结果表明，PE-MORL 在自动出价中超越了现有最先进的方法，证明了新的 PE-MORL 算法的优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17919</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>272. cs.AI-反馈驱动的多视角立体视觉系统及其实时事件分析</title><link>https://arxiv.org/pdf/2506.17910</link><description>Background: 
2D相机在交互系统中很常见，但游戏机等其他系统提供了用于短距离深度感测的更强大的3D相机。然而，所有这些相机在大型、复杂的环境中都不够可靠。因此，本文提议了一种基于3D立体视觉的管道，适用于交互系统中的各种需要强大场景理解的应用程序。该管道通过融合多个3D相机来完成全方位的场景重建，允许执行事件识别、主体跟踪和通知等多种任务。该系统还可以通过可能的反馈机制获取来自环境中的主体的数据，学习做出更好的决策或适应全新的环境。总体而言，这些相机在大型复杂环境中不够可靠。为了完成这些目标，本文介绍了该管道，并详细说明了初步实验和结果，展示了系统的潜力和可行性。

Innovation: 
本文提出了一种基于3D立体视觉的管道，通过融合多个3D相机来完成全方位的场景重建，并结合反馈机制，能够实现事件识别、主体跟踪和通知等多种任务。

Conclusion: 
本文详细介绍了3D立体视觉管道的设计，展示了在初步实验中取得的成果。文章还描绘了下阶段需要采取的路线图，以便将该管道投入生产。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17910</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>273. cs.AI-因果驱动优化在具有语言偏见的稳健医疗视觉问答中的应用</title><link>https://arxiv.org/pdf/2506.17903</link><description>Background: 
现有的医疗视觉问答（Med-VQA）模型往往受到语言偏见的影响，这会导致问题类型和答案类别之间建立错误的相关关系。这种语言偏见会影响模型的性能，尤其是在有偏见的基准测试数据集上表现不佳。为了应对这些问题，需要一个全面的方法来减轻这些偏见，改善模型的鲁棒性与表现。

Innovation: 
本文提出了一个称为CEDO（Causal-Effect Driven Optimization）的新型因果驱动优化框架，结合了以下三种机制：1) 必需驱动异质优化（MHO），它为特定模态采用自适应学习率；2) 梯度引导模态协同优化（GMS），利用帕累托优化方法促进模态间的协同作用并强迫梯度正交化，以消除从效果角度看的捷径偏见；3) 分布适应损失调整（DLR），它为个体损失分配自适应权重以确保在所有答案类别上均衡学习，从而减轻从原因角度看的数据集内部不平衡偏见。这种框架从因果和效果两个方面共同减轻语言偏见，进而提升模型的鲁棒性与一致性表现。

Conclusion: 
广泛的实验在多个传统和偏见敏感的数据集基准上展示了CEDO方法相较于现有最先进的竞争对手的优越性能和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17903</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>274. cs.AI-EgoWorld：使用丰富外部观察将外部视角转换为第一人称视角</title><link>https://arxiv.org/pdf/2506.17896</link><description>Background: 
第一人称视角对人类和机器视觉理解至关重要，特别是在获取用于操作任务的手物交互细节方面。将外部视角转换为第一人称视角对增强现实（AR）、虚拟现实（VR）和机器人技术的应用有很大的帮助，但现有的方法依赖于2D线索、同步多视角设置以及初始第一人称帧和相对相机姿态的假设等不现实的假设。这些限制导致了方法的局限性。因此，需要一种新的方法来克服这些挑战并提高转换性能和泛化能力。

Innovation: 
提出了EgoWorld，这是一种新颖的两阶段框架，从丰富的外部观察中重建第一人称视角，包括投影点云、3D手部姿态和文本描述。通过估计的外部深度图重建点云，将其重新投影到第一人称视角，然后使用扩散基生成稠密且语义一致的第一人称图像。该方法在H2O和TACO数据集上实现了最先进的性能，并且在新物体、动作、场景和主体上显示了鲁棒的泛化能力，甚至在未标记的真实世界示例上也显示出有希望的结果。

Conclusion: 
EgoWorld方法在多个数据集上表现出色，不仅能够准确重建第一人称视角，还能够对新物体、动作、场景和主体有良好的泛化能力。与现有方法相比，它不依赖于2D线索、同步多视角设置和初始第一人称帧以及相对相机姿态的假设，从而提高了方法的真实性和实际应用价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17896</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>275. cs.AI-通过全局精炼和主动伪造实现多轮逃狱</title><link>https://arxiv.org/pdf/2506.17881</link><description>Background: 
大规模语言模型（LLMs）在各种任务中表现出色，但由于可能被滥用以达到恶意目的，它们依然存在显著的安全风险。单轮逃狱技术已经取得了一定进展，但复杂多轮对话场景仍然未被充分探索。现有的多轮逃狱方法难以应对随着互动进行而演变的对话动态。

Innovation: 
提出了一种新颖的多轮逃狱方法，该方法在每次互动中对逃狱路径进行全局精炼，同时积极制造模型回复以抑制安全警告，增加后续问题中引出有害输出的可能性。实验结果显示，该方法在六种最先进的LLM上优于现有单轮和多轮逃狱技术。

Conclusion: 
实验结果表明，该方法在六种最先进的LLM上表现出优于现有技术和方法的性能。该代码已公开发布。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17881</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>276. cs.AI-StainPIDR: 基于颜色向量量化和结构染色重建的病理图像解耦和重建方法</title><link>https://arxiv.org/pdf/2506.17879</link><description>Background: 
病理图像的颜色表现高度依赖于成像协议、不同染料的比例以及扫描设备。计算机辅助诊断系统在面对不同颜色的病理图像时可能表现不佳。因此，提出了一种去染色方法，即StainPIDR，以消除这些颜色差异，通过将图像解耦为结构特征和向量化颜色特征，用目标颜色特征重新染色结构特征，再对重新染色的结构特征进行解码，以获得标准化的病理图像。这项工作的背景在于现有系统对于颜色不同步的病理图像表现退化，需改进稳定性和准确性。

Innovation: 
StainPIDR 方法通过将颜色特征和结构特征解耦，并使用目标颜色特征重新染色结构特征，进而对重新染色后的结构特征进行解码以获得标准化的病理图像。为了进一步优化去染色效果，设计了一种模板图像选择算法，该算法能够从给定的的数据集中选择合适的模板图像。创新点在于采用了颜色向量量化和结构染色重建的方法进行病理图像的去染色处理，同时引入了跨注意力机制来高效地重新染色结构特征，并通过设计模板图像选择算法来优化去染色效果。

Conclusion: 
StainPIDR 方法在广泛实验中证明了其在去染色任务上的有效性，选定的模板图像选择算法也进一步验证了方法的有效性。所有结果表明，该方法在去染色任务中表现良好。StainPIDR 的代码将在稍后公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17879</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>277. cs.AI-SurgVidLM: 向基于大语言模型的多层次手术视频理解迈进</title><link>https://arxiv.org/pdf/2506.17873</link><description>Background: 
近期多模态大型语言模型在医疗领域的应用显示出巨大的潜力，尤其是辅助用户理解手术场景和流程。除了基于图像的方法之外，基于视频的大型语言模型（Vid-LLMs）的探索已成为捕捉手术过程中复杂信息序列的一种有前途的途径。然而，目前仍然缺乏专门针对精细手术视频理解任务的Vid-LLMs，这对于分析手术过程中的特定步骤或细节至关重要。

Innovation: 
本文提出了SurgVidLM，这是首个专门针对全手术视频和精细手术视频理解设计的视频语言模型。为了训练SurgVidLM，构建了包含超过31,000个视频-指令对的SVU-31K数据集，以实现对手术过程的整体理解及细节分析。此外，还引入了双阶段的StageFocus机制，这是一种逐级进行多层次手术视频理解的框架，并开发了多频次融合注意机制，有效结合低频和高频视觉token，确保关键信息的保留。实验结果表明，SurgVidLM在全手术和精细手术视频理解任务中显著优于现有的Vid-LLMs，展示了其在捕捉复杂操作上下文方面的能力。

Conclusion: 
SurgVidLM作为首个专门设计用于手术视频理解的大语言模型，不仅通过构建大量视频-指令对的数据集提升了整体和细节理解能力，还通过双阶段框架和多频次融合注意力机制增强了模型的理解能力，实验结果表明其在手术视频理解任务中表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17873</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>278. cs.AI-如何通过调整缩小生成边界</title><link>https://arxiv.org/pdf/2506.17871</link><description>Background: 
尽管大型语言模型（LLMs）具有令人印象深刻的性能，但它们生成的结果往往缺乏多样性。本文通过模型输出分布中的概率集中现象来探讨这一现象，并研究了在生成过程中驱动这一稳定性的因素。论文提出了一种新的测量方法——分叉因子（BF），用于量化生成过程中每个可能步骤的有效数量。实验分析揭示了两个关键发现：生成过程中BF往往会降低，表明LLMs在生成时变得更加可预测；调整调优能够显著提升模型的输出多样性，使得模型在初始阶段的输出分布更加集中，BF下降幅度接近一个数量级。这一发现解释了为什么对齐后的模型往往对解码策略更为不敏感。基于此，研究发现这种稳定性对复杂推理具有意想不到的影响。例如，通过生成更长的推理链，对齐后的Chain-of-Thought（CoT）模型能够将生成过程推入更后期、更确定性的阶段，从而提高生成结果的稳定性。研究还推断，调整调优不会从根本上改变模型的行为，而是将行为导向于基模型中已存在的低熵路径（如“Sure”等风格化标记），从而影响生成的多样性。这些发现为理解和控制LLM的输出提供了有力的诊断工具，并阐明了如何通过调整减少多样性、如何通过CoT促进稳定生成以及如何引导基模型远离多样性的重要性。

Innovation: 
论文创新地引入了分叉因子（BF）的概念，这是一种计算过程中可能步骤有效数量的不变度量，能更精准地衡量概率集中现象。通过实证分析，展示了模型生成过程中概率集中度的变化，并发现调整调优显著提升了输出多样性。研究进一步揭示了通过生成更长的推理链，能够使得生成过程更确定性，从而提高生成结果的稳定性。研究还通过暗示实验指出，调整后模型的行为并未从根本上改变，而是引导至基模型中已存在的低熵路径上，证明了模型多样性可以通过这种方式进行调整控制。

Conclusion: 
研究发现，分叉因子（BF）可以作为理解控制LLM输出的强大诊断工具，能够清晰地阐释调整如何减少模型的多样性、CoT如何促进生成的稳定性以及如何引导基模型避免多样性的重要性。这一发现对于理解和优化大型语言模型的行为具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17871</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>279. cs.AI-NestQuant: On-Device Post-Training Integer-Nesting Quantization for DNN</title><link>https://arxiv.org/pdf/2506.17870</link><description>Background: 
部署在物联网(IoT)设备上的量化深度神经网络(DNN)模型可以利用压缩带来的好处，满足多场景的资源需求。然而，现存的动态/混合精度量化需要重新训练或特殊硬件支持，后训练量化(PTQ)则存在两个限制：（i）最先进的PTQ方法仅提供固定位宽模型，难以适应物联网设备的动态资源；（ii）部署多个不同位宽的PTQ模型会消耗大量的存储资源和切换开销。为了解决这些问题，论文提出了一种资源友好的后训练整数嵌套量化方法，即NestQuant，用于物联网设备上量化模型的切换。

Innovation: 
论文提出的NestQuant方法结合了整数权重分解（将量化权重按位拆分成较高位和较低位的整数类型权重）和嵌套机制（通过自适应舍入优化较高位权重并嵌套到原始量化权重中）。这种方法可以在部署时只发送和存储一个NestQuant模型，并通过分页机制在满位和部分位模型之间切换来适应资源变化，从而减少消耗和开销。在ImageNet-1K预训练DNNs上的实验结果表明，NestQuant模型可以在保持高精度的同时减少数据传输、存储消耗和切换开销。例如，ResNet-101模型在嵌套INT8和INT6的情况下，分别达到78.1%和77.9%的精度，并将切换开销减少了约78.1%相比不同位宽的PTQ模型。

Conclusion: 
论文提出了一种命名为NestQuant的资源友好型后训练整数嵌套量化方法，这种技术可以在物联网设备上实现量化模型在不同位宽之间的切换，成功解决了传统后训练量化面临的挑战。NestQuant方法在保持模型性能的同时显著减少了资源消耗和切换开销。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17870</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>280. cs.AI-上下文学习策略以理性方式涌现</title><link>https://arxiv.org/pdf/2506.17859</link><description>Background: 
近期关于上下文学习（ICL）的研究揭示了模型在不同实验条件下的多种策略，但尚未统一这些发现的原因。本文从认知科学的理性分析视角出发，探讨了模型为什么会在混合任务训练中学习这些不同的策略。研究表明，这些策略可以由两类贝叶斯预测器表示：一种是假设有特定可见任务先验的记忆预测器，另一种是先验与任务分布相匹配的推广预测器。作者提出了一种分层的贝叶斯框架，该框架几乎完美地预测了训练过程中_transformer_的下一个令牌预测，而不依赖于权重访问。这一框架将预训练视为更新不同策略后验概率的过程，并将推理时的行为视为这些策略预测的加权平均值。结合神经网络学习假设，可以显式地定义策略的损失和复杂性之间的权衡：不仅取决于其对数据的解释能力，模型还因其复杂性偏好实施特定策略。

Innovation: 
本文创新性地采用了认知科学中的理性分析框架，将上下文学习策略解释为在给定计算约束条件下的最优适应。作者提出了一个分层贝叶斯框架，能够几乎完美地预测变换器的下一个令牌预测，无需访问其权重。该框架从策略后验概率更新的角度重新定义了预训练过程，并将其推理时的行为视为这些策略预测的加权平均值。同时，这一框架结合了神经网络学习的常见假设，明确策略的损失和复杂性之间的权衡，解释了一些已知的上下文学习现象，并提供了新的预测。例如，研究发现随着任务多样性的增加，过渡到记忆需要的时间存在超线性趋势。

Conclusion: 
本文通过对上下文学习策略的理性分析，提供了一种解释性和预测性的框架，基于策略的损失和复杂性之间的权衡来理解上下文学习的过程。这一框架不仅解释了已知的上下文学习现象，还提供了新的预测，推进了对上下文学习这一领域的理解和预测能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17859</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>281. cs.AI-Pathway-based Progressive Inference (PaPI) for Energy-Efficient Continual Learning</title><link>https://arxiv.org/pdf/2506.17848</link><description>Background: 
持续学习系统面临双重挑战：防止灾难性遗忘并保持能源效率，尤其是在资源受限的环境中。现有的方法难以同时解决这两个问题。本文通过数学严格的路径选择和适应方法，提出了一种新的理论框架——基于路径的渐进推理（PaPI），旨在解决这两个挑战，并将其形式化为一个带能源约束的优化问题，给出路径路由机制的形式收敛保证。

Innovation: 
提出了基于路径的渐进推理（PaPI）理论框架，将持续学习形式化为带能源约束的优化问题，并证明其在稳定性和可塑性之间的权衡比单一架构提高了$text{O}(K)$，其中$K$是路径数量。通过Fisher信息矩阵分析，得出了准确的遗忘率边界，并证明PaPI的能效与活跃参数数量相关，而不仅仅是模型的总体尺寸。理论分析表明，PaPI比弹性权重巩固（EWC）对抗灾难性遗忘更有保证，同时在能效方面优于EWC和梯度 episodic 记忆（GEM）。

Conclusion: 
实验验证了PaPI在多个基准测试中的理论优势，证明了其在能源受限环境下的持续学习有效性。相关代码可在此处访问：this https URL</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17848</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>282. cs.AI-开放源代码合成表格数据生成库的比较研究：SDV vs. Synthicity</title><link>https://arxiv.org/pdf/2506.17847</link><description>Background: 
高质量的训练数据对于机器学习模型的性能至关重要，尤其是大型语言模型（LLM）。获取真实且高质量的数据对于小型组织和初创企业而言具有挑战性。合成数据生成器通过复制真实数据的统计特性和结构特性，同时保持隐私和扩展性，提供了一个有希望的解决方案。本文通过使用UCI机器学习数据库中的真实数据集（比利时的能源消耗和环境变量），评估了两种广泛使用的开源库SDV（Gaussian Copula、CTGAN、TVAE）和Synthicity（Bayesian Network、CTGAN、TVAE）中的六种表格合成数据生成器的性能。

Innovation: 
本文通过对比两个流行的开源库SDV和Synthicity中的六种合成数据生成器，提供了对生成器性能的深入分析，特别是在数据量较少的情况下。研究使用“在合成数据上训练，在真实数据上测试”的方法评估模型的预测能力。研究发现Bayesian Network从Synthicity在多种场景下表现出最高的保真度，而SDV中的TVAE在1:10的输入输出比下表现最佳。

Conclusion: 
虽然两个库在表现上没有显著差异，SDV因其更好的文档和易用性脱颖而出，使其更具实践性。研究结果表明，在低数据条件下生成的合成数据在统计相似性和预测效用方面存在差异，Bayesian Network在统计相似性方面表现最佳，而TVAE在预测任务中表现最出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17847</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>283. cs.AI-THCM-CAL: 时间层级因果建模与校准校准相结合的临床风险预测</title><link>https://arxiv.org/pdf/2506.17844</link><description>Background: 
电子健康记录（EHR）中的临床风险自动化预测需要同时建模结构化的诊断代码和非结构化的笔记。然而，大多数现有方法要么单独处理这些模态，要么依赖简单融合策略，忽略了笔记观察如何导致诊断并传播风险到多个住院的层级因果关系。该论文在前人研究的基础上，探讨了如何更好地整合这两种模态的信息，以提高临床风险预测的准确性与可靠性。

Innovation: 
该论文提出了THCM-CAL（Temporal-Hierarchical Causal Model with Conformal Calibration），结合时间层级因果模型和校准校准方法，构建了一个多模态因果图，识别并利用了临床实体间的多种因果交互模式，包括同一模态内的序列关系、不同模态之间的触发关系及跨时间段的风险传播关系。此外，还通过扩展到多标签ICD编码的同恣校准，提高了预测结果的可靠性。

Conclusion: 
实验结果表明，THCM-CAL在MIMIC-III和MIMIC-IV数据集上的性能优于其他现有方法，证明了提出方法的有效性和优越性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17844</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>284. cs.AI-基于概念学习的安全标准生成性夹持检测与估计</title><link>https://arxiv.org/pdf/2506.17842</link><description>Background: 
神经网络因其通用性可以估计任何函数，但这也带来了高复杂性问题，使它们变成了黑盒模型，特别是在安全性关键应用中非常突出。本文研究了一个面向协作机器人的抓取算法，该算法能够在检测相关工具的同时生成最优抓取动作，旨在提高模型的透明度和可靠性。

Innovation: 
提出了一种结合概念学习的生成性抓取检测与估计方法，通过提取模型学习到的特征并与输入的对应类别相关联，提供了一种可解释的AI方法，确保在工具传递位置时的安全性。

Conclusion: 
该方法在工业环境中得到了验证，通过摄像头系统能够使机器人识别并抓取特定的工具和物体，并证明了该方法在安全性方面的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17842</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>285. cs.AI-Causal Spherical Hypergraph Networks for Modelling Social Uncertainty</title><link>https://arxiv.org/pdf/2506.17840</link><description>Background: 
人类社会行为受复杂互动的制约，这些互动受到不确定性的塑造、因果关系的影响以及群体动力学的驱动。现有方法在预测社会行为时存在局限性，无法同时建模高阶结构、定向影响以及认识上的不确定性（epistemic uncertainty）。

Innovation: 
本文提出了一种新的方法，即因果球状超图网络（Causal Spherical Hypergraph Networks，Causal-SphHN），它是一种原理性的社会学框架，能够同时建模高阶结构、定向关系影响以及认知不确定性。方法将个体表示为超球体嵌入，将群体背景表示为超边，捕捉语义和关系几何结构。不确定性通过伯努利-费舍尔分布的香农熵量化，因果关系通过Granger启发的子图识别。信息通过一个角度信息传递机制传播，该机制尊重信念的分散性和方向性语义。在SNARE（脱机网络）、PHEME（在线论述）和AMIGOS（多模态情感）数据集上的实验表明，Causal-SphHN在预测准确度、鲁棒性和校准性方面都优于强大的基线方法，并且能够进行可解释的影响力模式和社交模糊性分析。

Conclusion: 
本文贡献了一种统一的因果几何方法，用于在动态社会环境中学习不确定性。该方法能够更准确、更稳健地预测社会行为，并提供可解释的社会影响力模式和社交不确定性分析。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17840</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>286. cs.AI-通过强化学习迭代重新加权-然后优化的方法冻结大型语言模型对齐</title><link>https://arxiv.org/pdf/2506.17828</link><description>Background: 
目前，通过RLHF和DPO等方法对大型语言模型（LLMs）进行与人类偏好对齐通常需要直接优化模型参数。这种方法在测试时无法改善模型性能，并且在无法访问模型权重的情况下也不适用。相比之下，测试时的方法通过奖励函数引导和改善输出质量但不涉及权重更新，虽然这种做法可以降低推理成本，但使用单一基于不完美的奖励或价值函数进行指导，可能导致非最优输出。

Innovation: 
提出了一种名为Iterative Reweight-then-Optimize (IRO)的方法，这是一种基于强化学习的框架，可以在不修改基模型参数的情况下，对冻结的基模型进行RL风格对齐。在训练过程中，每次迭代（1）从基模型中采样候选项，（2）根据当前价值函数重新采样，（3）训练一个新的轻量级价值函数来引导下一次解码过程。在测试时，使用价值函数通过基于搜索的优化过程引导基模型生成。 users可以通过IRO独立对其模型进行对齐，类似于OpenAI的强化微调（RFT），但无需访问模型权重。

Conclusion: 
IRO提供了一种在不修改模型参数的情况下，对冻结大型语言模型进行对齐的方法，从而可以在无法访问模型权重的情况下进行有效的训练和测试优化。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17828</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>287. cs.AI-通过因果超图实现可操作的解释性：深度学习中批次大小效应的剖析</title><link>https://arxiv.org/pdf/2506.17826</link><description>Background: 
虽然批次大小对泛化的具体影响在视觉任务中已经被广泛研究，但在图和文本领域，其因果机制仍然尚未充分探索。该研究通过引入基于超图的因果框架HGCNet，利用深层次结构因果模型（DSCMs）来揭示批次大小与梯度噪声、最优点锋利度和模型复杂性之间的关联，进一步研究其对泛化能力的影响。不同于基于静态双变量依赖的研究方法，HGCNet 采取了超图方法，能够捕捉训练动态中的高阶互动。通过do-计算，研究团队量化了批次大小干预的直接和间接效果，为优化过程提供了可解释的因果解释。

Innovation: 
HGCNet 通过引入基于超图的方法，揭示了批次大小与梯度噪声、最优点锋利度和模型复杂性之间的因果关系，并通过do-计算量化了这些影响因素的作用。该方法能够捕捉高阶互动，提供可解释性和因果性的深刻见解。实验结果表明，HGCNet 在文献引用网络、生物医学文本和电子商务评论数据集中表现优于包括 GCN、GAT、PI-GNN、BERT 和 RoBERTa 在内的多个基准模型，展示了对模型泛化能力的改善作用，并提出了批次大小较小可能通过增加随机性和使最优点变平顺来增强泛化的有行动价值的解释。

Conclusion: 
该研究将解释性置于模型架构和优化选择的中心，展示了通过因果超图实现的可操作解释性如何引导训练策略。这不仅提供了一种新的研究视角，而且强调了解释性在推动深入学习中的原理性选择中的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17826</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>288. cs.AI-基于模拟的自主水下对接学习：关闭自主水下对接的模拟到现实差距</title><link>https://arxiv.org/pdf/2506.17823</link><description>Background: 
水下自主航行器(AUV)在动态和不确定环境下的自主对接是一个关键挑战，强化学习是开发鲁棒控制器的有希望的方法。然而，训练模拟与真实环境之间的差距，或sim2real差距，常常导致性能大幅下降。针对这一挑战，该研究通过训练不同的控制器并在典型的现实干扰下进行评估，来进行仿真研究，以减少模拟到现实的差距。特别关注不同负载下的真实世界对接挑战，这些负载可能不在原始训练分布中。已探索了提高鲁棒性的现有方法，包括随机化技术和基于历史数据的控制器。

Innovation: 
研究通过模拟进行训练，探索了减少模拟到现实差距的方法，特别是在不同负载下的自主对接。包括使用随机化技术和基于历史的控制器来提高鲁棒性，在现实干扰环境下评估控制器性能，以获得宝贵的见解并指导未来研究方向，这对于水下机器人社区是宝贵的贡献。

Conclusion: 
研究提供了对减少模拟到现实差距的见解，特别是在训练对接控制器时。进一步指出了对未来研究有益的领域，这可能对水下机器人社区有积极作用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17823</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>289. cs.AI-跨文化音乐表征学习的持续预训练：CultureMERT</title><link>https://arxiv.org/pdf/2506.17818</link><description>Background: 
近年来，音乐基础模型在音频表示学习方面取得了显著进步，但它们在不同音乐传统的有效性依然受到限制。本研究针对文化多样性发展了一种新的多文化基础模型CultureMERT-95M，旨在增强跨文化交流音乐表征学习和理解。这种模型通过结合学习率加热和冷却的方法，实现了稳定的跨文化适应，即使在资源有限的情况下也能确保适应稳定性。

Innovation: 
本研究提出了一个多阶段持续预训练策略，通过集成学习率加热和冷却机制，使得模型即使在有限的计算资源下也能实现稳定跨文化适应。该模型在希腊、土耳其和印度音乐传统等多元文化数据集上进行训练，结果显示在非西方音乐自动标签任务中平均提高了4.9%的ROC-AUC和AP，同时在西方基准测试上表现出较少的遗忘。此外，还研究了一种名为任务算术的方法，它在单文化适应模型之间进行加权融合，以此种方式适应多文化环境，该方法在非西方自动标签任务上与多文化训练模型性能相当，并且在西方数据集上没有退步。多文化适应模型在跨文化评估中表现出最佳的整体性能，相比之下，单文化模型在不同音乐传统间的转移具有不同的有效性。该研究还通过公开发布CultureMERT-95M和CultureMERT-TA-95M，促进了对世界音乐表示学习研究的发展，促进了更具有文化意识的音乐基础模型的发展。

Conclusion: 
CultureMERT-95M和CultureMERT-TA-95M在跨文化音乐表征学习中展现出更好的表现，为世界音乐的表示学习研究提供了新的工具，推动了更具有文化意识的音乐基础模型的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17818</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>290. cs.AI-RoboMonkey: 通过测试时间采样和验证扩展视-听-动模型</title><link>https://arxiv.org/pdf/2506.17811</link><description>Background: 
Vision-Language-Action (VLA) 模型在视觉运动控制方面显示出了显著的能力，但它们在未结构化的现实环境中保持鲁棒性和泛化能力仍然是一个持续的挑战。现有的 VLA 模型在未遇见的情景下常常表现不佳，这限制了它们的广泛应用。因此，本研究旨在通过采样和验证方法提升 VLA 模型在测试阶段的鲁棒性和泛化能力。研究者观察到行动误差与生成样本的数量之间遵循一种对数幂次函数关系，这表明存在推理时的可扩展性法则。基于此发现，提出了 RoboMonkey 框架，一个用于 VLA 模型的测试时扩展框架。

Innovation: 
RoboMonkey 引入了一种新颖的测试时间采样和验证框架，该框架通过从 VLA 中采样较小的行动集，并应用高斯扰动和多数投票来构建行动建议分布，同时使用基于视觉语言模型 (VLM) 的验证器来选择最优行动。此外，研究还提出了一种合成数据生成管道来培训基于 VLM 的行动验证器，并展示随着合成数据集的增加，验证和下游准确性得到持续改进。这个框架通过大量的模拟和硬件实验展示了显著的性能提升，并且在调整到新的机器人设置时，同时调整 VLA 和行动验证器相较于仅调整 VLA 的表现更好。

Conclusion: 
РoboMonkey 框架在多个测试场景中的应用表明，将现有的 VLA 模型与 RoboMonkey 配合使用大幅提高了性能，实现了在未知任务的绝对改进达 25%，已知任务的改进达 8%。此外，在新的机器人设置适应时，同时微调 VLA 和行动验证器比仅微调 VLA 提高了 7% 的表现。这些结果显示 RoboMonkey 的方法具有广泛的应用潜力，可以显著提升 VLA 模型在现实世界环境中的鲁棒性和泛化能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17811</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>291. cs.AI-使用扩散模型重新思考参数空间探索</title><link>https://arxiv.org/pdf/2506.17807</link><description>Background: 
通常，神经网络调整到新任务需要特定的任务适配微调，这耗时且依赖于标注数据。这项研究则探索了一种生成式替代方案，能够直接从任务标识符生成任务特定参数，从而无需特定任务训练。这种方法旨在利用扩散模型学习有效任务特定参数空间的内在结构，并按需合成参数。

Innovation: 
提出了一种使用扩散模型的方法，用于学习并既能生成已见任务的参数，也能生成多个已见任务甚至全新的任务的参数。这种方法强调了利用扩散模型进行参数空间探索的可能性和局限性。

Conclusion: 
实验表明，扩散模型能够生成准确的任务特定参数，并在参数子空间结构良好的情况下支持多任务插值，但在未知任务上的泛化能力有限，指出了此生成性解决方案的潜在价值和局限。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17807</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>292. cs.AI-使用多模态大语言模型扩展医学案例检索任务的相关性判断</title><link>https://arxiv.org/pdf/2506.17782</link><description>Background: 
目前评估信息检索（IR）系统依赖于高质量的手动相关性判断（qrels），但这些判断获取成本高、耗时长。虽然通过聚合可以减少标注工作量，但会导致仅部分标记的数据集。大型语言模型（LLMs）提供了一种减少对手动判断依赖的替代方案，尤其是在需要分析文本和视觉信息的复杂领域（如医疗案例检索）中，相关性评估尤为需要这样的能力。该研究探讨了使用多模态大型语言模型（MLLM）来扩充相关性判断，进而创建一个自动判断的新数据集。研究应用了Gemini 1.5 Pro进行ImageCLEFmed 2013案例检索任务，通过迭代细化、结构化提示策略实现了自动评估。研究系统地实验了各种提示配置以最大化与人类判断的一致性，并使用Cohen's Kappa测量人工标注和机器学习模型的一致性，获得了0.6的显著一致性评分，与多模态检索任务中的跨注释者一致性相当。从原始的15,028个手动判断（4.72%相关）开始，基于MLLM的方法扩展了数据集37倍以上，达到558,653个判断，并将相关标注增加到5,950个，平均每例病例查询接收到了15,398个新标注，其中约99%是非相关的，反映出这一领域的高稀疏性特征。

Innovation: 
利用多模态大型语言模型（MLLM）自动生成大规模相关性判断，以减少对人工评估的依赖。研究通过Gemini 1.5 Pro在ImageCLEFmed 2013案例检索任务中实现这一点，应用了迭代细化、结构化提示策略进行自动评估，并系统地实验了各种提示配置以最大化与人类判断的一致性。这种方法显著提升了数据集规模和相关标注数量，为支持医疗和多模态IR任务中的检索评估提供了新的方法和思路。

Conclusion: 
研究结果表明，MLLM能够扩展相关性判断的收集规模，为支持医疗和多模态IR任务检索评估提供了新的方向。这种方法不仅大幅减少了人工标注的工作量，同时还保持了较高的判断一致性，为跨模态检索评估提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17782</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>293. cs.AI-向自主UI探索迈进：UIExplorer基准</title><link>https://arxiv.org/pdf/2506.17779</link><description>Background: 
自主代理必须了解如何探索用户界面（UI）以可靠地完成任务，但迄今为止尚缺乏系统评估这个关键阶段的方法。

Innovation: 
提出了UIExplore-Bench，这是首个专门用于UI探索的基准测试。该基准在标准化的GitLab沙盒环境中，通过结构化模式（提供布局信息如DOM树）和屏幕模式（依靠GUI仅有的观察，如截图和类似人类的鼠标/键盘互动）评估不同级别的探索效果。提出了一个度量标准——人类规范化UI功能性观察（hUFO），以量化探索的有效性，结果显示UIExplore-AlGo在各项测试中表现最优，尤其是在稀疏级别上表现突出。

Conclusion: 
我们的基准测试表明，当前的代理在与半小时人类专家探索相比时存在显著性能差距，这表明在未来还有很大的改进空间。我们公开发布了基准环境、探索数据集和评估套件，以推动对有效UI探索策略及其下游应用的研究，如经验驱动的任务完成和自动化训练数据生成。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17779</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>294. cs.AI-机器学习模型与开放世界时间逻辑集成以实现流程自动化</title><link>https://arxiv.org/pdf/2506.17776</link><description>Background: 
近年来，机器学习的进步产生了能够从多样且复杂的数据源中提取结构信息的强大模型。然而，在复杂的业务流程中，将这些感知或提取的输出转化为具体的、可行的决策仍然面临重大挑战。本文讨论了这一问题并提出了应对策略。

Innovation: 
本文提出了一种创新方法，即将来自各种机器学习模型的输出直接集成到PyReason框架中，PyReason是一种开放世界的时间逻辑推理引擎。PyReason通过对真实值输出（如概率、置信度评分）的无缝整合，实现了逻辑推理框架下的实时动态决策。此外，PyReason还支持时间推理、知识图谱集成和完全可解释的界面跟踪，这使其能够在实时敏感的数据和现有的组织知识上进行复杂的分析。这一方法结合了感知和提取的强项与逻辑推理和透明度的优势，旨在创建一个用于自动化复杂流程的强大系统。该集成在制造、医疗保健和商业运营等多个领域都有应用潜力。

Conclusion: 
通过将机器学习模型的感知和提取功能与PyReason的逻辑推理和透明性相结合，本文旨在创建一个强大的自动化复杂流程系统，该系统能够实现实时适应性决策。这种组合方法提供了在复杂业务流程中实现自动化的新途径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17776</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>295. cs.AI-CARTS: Collaborative Agents for Recommendation Textual Summarization</title><link>https://arxiv.org/pdf/2506.17765</link><description>Background: 
当前推荐系统通常需要一些形式的文字数据总结，例如为产品轮播或其他分组项目展示生成简洁和连贯的标题。虽然大型语言模型在NLP领域中对文本总结性能良好，但这些方法不适用于推荐系统，在推荐系统中，解释需要与项目集的核心特征高度相关，并严格遵守字数限制。大规模电商数据和现场A/B测试表明，CARTS在生成相关标题和提升用户参与度指标方面显著优于单次通过和思维链的LLM基线方法.

Innovation: 
CARTS是一种协作性多代理LLM框架，旨在针对推荐系统的结构化总结。通过任务分解成候选生成增强生成、迭代精炼循环和仲裁三个阶段，每个阶段的代理角色负责提取突出特征、基于相关性和长度反馈迭代精炼候选标题，以及通过合作仲裁过程选择最终标题。实验表明，CARTS在生成相关标题和用户参与度指标方面优于传统的方法和思维链的LLM基线方法.

Conclusion: 
CARTS在处理推荐系统中结构化总结任务时显著超越了现有的方法，特别是对于需要高度相关性的推荐文案和严格遵循字数限制的要求。通过其多代理框架，CARTS能够更有效、更具针对性地生成推荐系统的标题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17765</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>296. cs.AI-残差增强的ConvLSTM用于锂枝晶生长预测</title><link>https://arxiv.org/pdf/2506.17756</link><description>Background: 
锂枝晶的生长显著影响可充电电池的性能和安全性，导致短路和容量衰减。

Innovation: 
本文提出了一种残差连接增强的ConvLSTM模型，以预测锂枝晶生长模式，相比传统ConvLSTM提高了准确性和计算效率。通过在ConvLSTM中整合残差连接，该模型缓解了梯度消失问题，增强了跨层的特征保留能力，并能有效捕捉局部枝晶生长动态和宏尺度电池行为。实验结果显示，在不同电压条件下，所提模型的准确率最高可达7%的提升，同时显著降低了均方误差（MSE）。这表明，残差连接在深时空网络中的电化学系统建模中效果显著。

Conclusion: 
本文提出的方法为电池诊断提供了一个 robust 的工具，有助于实时监测和优化锂离子电池的性能。未来的研究可以将此框架扩展到其他电池化学成分，并与实际实验数据相结合进一步验证。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17756</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>297. cs.AI-HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations</title><link>https://arxiv.org/pdf/2506.17748</link><description>Background: 
当前的语言模型虽然在流畅性方面表现出色，但在事实准确性和对输入上下文的忠实性上往往存在不足，这通常被称为‘幻觉’。这种生成错误或与输入上下文不一致内容的趋势破坏了模型的可靠性，因为这些虚假内容非常易于误导且难以检测。尽管已有多种方法尝试检测幻觉，但大多数方法依赖于分析每个输入的多个生成结果，这会导致计算成本增加和延迟增加。因此，论文提出了一种新颖的方法HIDE，这是一种无需训练的单程式解决方案，用于通过解耦表示检测语言模型的幻觉。HIDE通过量化LM在生成输出序列过程中内部表示与输入上下文之间的解耦，来检测幻觉。

Innovation: 
HIDE提出了一种新的单程式（single-pass）且无需训练的解决方案，以检测语言模型的幻觉，这种方法利用了语言模型内部表示与生成输出之间解耦的统计特性。它使用希尔伯特-施密特独立性准则（HSIC）来衡量隐藏状态表示与输出序列之间的解耦程度。经过多种开源语言模型和四个不同问答数据集的广泛实验，HIDE在大多数情况下表现优于其他单程式方法，尤其是在AUC-ROC度量上平均提高了约29%。此外，HIDE在与多程式最新的先进方法竞争时表现出类似的性能，但在计算时间上节省了约51%。

Conclusion: 
实验结果表明，HIDE在多种模型和数据集上有效地检测了幻觉，相较于其他单程式方法，在多个度量指标上表现出显著优势。HIDE方法通过利用LM内部表示的解耦特性实现高效且实用的幻觉检测。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17748</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>298. cs.AI-KAG-Thinker: 教大模型具有类人推理过程的思考</title><link>https://arxiv.org/pdf/2506.17728</link><description>Background: 
本文探讨了一个名为KAG-Thinker的新颖人类化推理框架，该框架基于参数较少的大语言模型（LLM）。这一方法旨在通过将复杂的问答任务分解为独立可解的小问题，增强LLM在特定领域知识库中的逻辑连贯性和上下文一致性。框架通过逻辑分解和结构化思考过程模拟了人类认知机制，借助知识边界模型和深度求解模型优化了知识检索，确保了信息的全面性和连贯性。这些方法避免了通过强化学习进行推理，转而采用基于多轮对话的监督微调方法，使模型与结构推理框架保持一致，从而避免过度反思。模型的性能通过数据评估框架和迭代语料库合成进一步得到验证，生成了详细的推理轨迹。

Innovation: 
KAG-Thinker通过逻辑分解方法，将复杂问题分解为独立可解的小问题，并使用自然语言和逻辑函数两种形式进行表示。框架通过知识边界模型和深度求解模型优化知识检索过程，采用基于多轮对话的监督微调方法替代强化学习，从而实现一致性和连贯性的增强。这种方法显著提高了模型在特定领域知识库中的推理能力，避免了过度的自我反思，增强了系统的理解和处理复杂问题的能力。

Conclusion: 
KAG-Thinker框架通过结构化的思考过程和多轮对话的监督微调方法，在保持逻辑连贯性和知识广泛性的基础上，显著增强了大语言模型在特定领域知识库中的推理能力，从而有效改进了问答任务的表现，为后续的研究和应用提供了新的思路。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17728</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>299. cs.AI-利用第一原理计算和贝叶斯学习解决Ti-V相图分歧</title><link>https://arxiv.org/pdf/2506.17719</link><description>Background: 
钛-钒（Ti-V）二元合金的相图实验结果存在冲突，不清楚其是否表现出体心立方（BCC）共熔间隙还是完全可溶。有假设认为共熔间隙是由于合金制备过程中存在氧污染所致。为解决这一争议，研究人员使用了一种结合了主动训练的矩张量势和贝叶斯热力学推断的理论方法来进行计算，旨在全面探究Ti-V二元系统的整个成分范围，并给出热力学极限下的置信区间。此方法所得出的相图包括所有实验特征，证明了该方法的稳健性，明确支持在980 K和c = 0.67终止的BCC共熔间隙变体。由于模拟中排除了氧的影响，这反驳了最近的CALPHAD再评估结果，表明共熔间隙不是由杂质效应引起的。

Innovation: 
使用了结合主动训练的矩张量势（Moment Tensor Potential）和贝叶斯热力学推断的理论方法，无需人为假设杂质的影响，直接从第一原理计算得出结果，提供了一种新的途径来解决Ti-V相图的争议问题。这种方法不仅具有高准确度，还能够可靠地评估系统的热力学极限状态下的性质变化，为合金设计提供了可靠的理论支持。

Conclusion: 
该研究基于第一原理计算和贝叶斯学习的方法，完整地探究了Ti-V二元系统的相图，并给出了与实验一致的结果，且该相图中的BCC共熔间隙变体在980K和c = 0.67时终止。研究认为共熔间隙的形成与氧污染无关，从而否定了某些计算结果中的相关假设，确认了Ti-V相图中的BCC共熔间隙的存在。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17719</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>300. cs.AI-完美之年龄印记：会话英语中的机器学习年龄地图</title><link>https://arxiv.org/pdf/2506.17708</link><description>Background: 
该研究利用2014年的英国国家语料库，研究不同年龄段的语言模式。研究旨在探索不同年龄段的语言模式差异，探究说话人口统计特征与语言因素（如说话时长、词汇多样性、词语选择）之间的联系。通过结合计算语言分析和机器学习方法，研究试图发现各代人特有的语言标记，并建立可从多方面准确预测发言者年龄段的预测模型。这项工作有助于我们了解现代英国口语中的社会语言多样性。

Innovation: 
研究通过结合计算语言分析和机器学习方法，探索不同年龄段的语言模式差异，发现并预测不同年龄段的语言特征，为研究社会语言多样性提供新视角和新方法。

Conclusion: 
该研究结果为理解现代英国口语中的社会语言多样性提供了新的见解，通过建立预测模型，可以更准确地估计发言者的年龄段，从而深化了对社会语言学的理解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17708</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>301. cs.AI-可编程房间：由大型语言模型驱动的互动3D房间网格生成</title><link>https://arxiv.org/pdf/2506.17707</link><description>Background: 
本文介绍了‘可编程房间’框架，该框架能够根据自然语言指令生成和编辑3D房间网格。为了精确控制房间的每一个属性，将任务分解为创建合适的3D坐标、生成全景图像进行纹理生成、构建3D网格以及摆放家具等更简单的步骤。通过引入视觉编程（VP）方法，将这些任务统一在一个框架中，并通过一个大型语言模型（LLM）生成Python-like程序，根据自然语言描述自动化实现这些任务。这种方法有助于解决3D空间生成和编辑中的各种复杂问题。

Innovation: 
提出的框架引入了视觉编程（VP）方法，利用大型语言模型（LLM）生成Python-like程序来完成从自然语言描述到具体任务的自动实现。特别地，在纹理生成模块中，使用预训练的大规模扩散模型根据文本和视觉提示同时生成条件化的全景图像。通过优化双向LSTM获取的全景图像的一维表示来增强图像生成的质量。整个框架在定量和定性上优于现有模型，证明了其在3D空间生成和编辑中的灵活性和优越性。

Conclusion: 
本文展示了‘可编程房间’框架在生成和编辑3D房间网格方面的灵活性，并用定量和定性的方式证明了该框架优于现有模型。通过将视觉编程与大型语言模型结合，为3D空间生成和编辑提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17707</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>302. cs.AI-自然语言处理的发展：提示优化和语言模型如何塑造未来</title><link>https://arxiv.org/pdf/2506.17700</link><description>Background: 
大规模语言模型（LLMs）通过自动化传统劳动密集型任务，极大地推动了自然语言处理（NLP）领域的发展，并加速了计算机辅助应用的进步。随着研究人员引入新的语言模型和更高效的训练/调优方法，提示工程及其优化策略已成为提升各种NLP任务性能的一个特别有效的趋势。尽管存在许多关于提示工程的综述文章，但对提示优化策略进行全面分析的研究仍然不足。本研究填补了这一空白，提供了一种独特且全面的见解，分析了这些策略的内在工作原理，并根据这些原则将其分类为11类。此外，本文详细介绍了这些提示优化策略在不同类型NLP任务中的应用，还介绍了用于评估的不同的LLM和基准数据集。这种全面的编纂为未来的比较研究奠定了坚实的基础，并有助于在一致的实验设置下严格评估提示优化和基于LLM的预测管道：当前环境下的一种迫切需求。最终，这项研究旨在集中多样化策略知识，以促进对未探索任务中新颖预测器的发展适应。

Innovation: 
该研究填补了对提示优化策略进行全面分析的空白，提供了一种独特且全面的见解，并将这些策略分类为11类，详细介绍了NLP任务和用于评估的不同LLM和基准数据集的应用。这种编纂为未来的比较研究奠定了坚实的基础，并有助于在一致的实验设置下严格评估提示优化和基于LLM的预测管道。

Conclusion: 
最终，这项研究旨在集中多样化策略知识，以促进对未探索任务中新颖预测器的发展适应，为未来的研究和发展提供了坚实的基础和指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17700</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>303. cs.AI-在推荐系统中强化用户兴趣演变的多场景学习</title><link>https://arxiv.org/pdf/2506.17682</link><description>Background: 
在现实世界的推荐系统中，用户会参与多种场景，如主页、搜索页和相关推荐页。这些场景反映了不同的用户关注点。但由于决策过程和偏好表达的不同，用户兴趣在不同场景中可能出现不一致。这使统一建模变得复杂，多场景学习成为一个显著的挑战。

Innovation: 
提出了一个新颖的强化学习方法，该方法通过建模多种场景中用户兴趣的演变，来进行跨场景的用户偏好建模。此外，该方法使用双重Q学习提高下一项目预测准确率，并利用Q值优化对比学习损失，使模型性能更好。实验结果表明，该方法在多场景推荐任务中超过了最先进的方法。

Conclusion: 
这项工作为多场景建模提供了一个新的视角，并指出了未来研究的有希望的方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17682</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>304. cs.AI-基于小凹痕试验的Seq2Seq和跨注意力机制增强应力-应变预测</title><link>https://arxiv.org/pdf/2506.17680</link><description>Background: 
本文介绍了一种新颖的深度学习方法，用于从高强钢的小凹痕试验（SPT）载荷-位移数据中预测真实的应力-应变曲线。传统的实验技术在材料科学中的准确性和效率方面存在局限性，因此需要一种新的方法来提高应力-应变关系预测的准确性与效率.

Innovation: 
提出的方方法使用Gramian Angular Field (GAF) 将载荷-位移序列转换为图像，同时捕捉时空特征。采用了基于LSTM的编解码器架构的Seq2Seq模型，并通过多头跨注意力机制增强了其准确性，从而提高了预测精度.

Conclusion: 
实验结果显示，提出的方案在预测精度方面表现出色，最小和最大平均绝对误差分别为0.15 MPa和5.58 MPa。该方法为材料科学中的传统实验技术提供了一个有前景的替代方案，提高了真实应力-应变关系预测的准确性和效率.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17680</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>305. cs.AI-FaithfulSAE：在没有外部数据集依赖的情况下捕获忠实特征的稀疏自编码器</title><link>https://arxiv.org/pdf/2506.17673</link><description>Background: 
稀疏自编码器（SAEs）已被证明是分解大型语言模型表示为可解释特征的有前途的解决方案。然而，Paulo和Belrose（2025）指出不同初始化种子下的不稳定性，而Heap等人（2025）则发现SAEs可能无法捕捉模型内部特征。这些问题很可能是由于在外部数据集上（这些数据集可能来自网络或由另一个模型生成）训练SAEs，这些数据集可能包含模型泛化能力之外的出域（OOD）数据，导致SAE产生幻觉特征，即我们所称的“假特征”，这些特征会误代表模型内部激活。因此，通过训练SAEs来自由生成数据来解决这些问题，提出FaithfulSAE方法。实验结果表明，训练较少依赖于OOD指令数据集的SAE更稳定，并且FaithfulSAE在SAE探针任务中优于基于网络的外部数据集训练的SAE，且在7个模型中有5个模型的假特征比更低于SAE。这种方法消除了对外部数据集的依赖，使SAE更好地捕捉模型内部特征，强调了SAE训练数据集的重要性。

Innovation: 
提出FaithfulSAE方法，通过训练SAEs来自有模型自身的合成数据集来解决这些问题。实验说明训练较少依赖于OOD指令数据集的SAE更稳定，并且FaithfulSAE在SAE探针任务中优于基于网络的外部数据集训练的SAE，且在7个模型中有5个模型的假特征比更低于SAE。这种方法消除了对外部数据集的依赖，使SAE更好地捕捉模型内部特征，提高了SAE的鲁棒性和可解释性.

Conclusion: 
本文的方法消除了对外部数据集的依赖，促进了SAE对模型内部特征的更好捕获，从而提高了模型的可解释性。通过使用自生成的合成数据集，证明了训练较少依赖于OOD指令数据集的SAE更稳定，并且FaithfulSAEs在SAE探针任务中优于基于网络的外部数据集训练的SAE，且在7个模型中有5个模型的假特征比更低于SAE，强调了SAE训练数据集的重要性，推动了SAE在模型解释和可解释AI领域的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17673</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>306. cs.AI-TPTT: Transforming Pretrained Transformer into Titans</title><link>https://arxiv.org/pdf/2506.17671</link><description>Background: 
近年来，大型语言模型（LLMs）在自然语言处理方面取得了显著进展，但它们的计算和内存需求仍然是一个重大挑战，尤其是在长上下文推理方面。现有模型在处理大规模数据时面临巨大的资源压力，这限制了它们的应用范围和效率。因此，研究人员正在寻找有效的方法来优化这些模型，使其能够更高效地处理大量数据同时保持性能。TPTT通过引入线性化注意力机制和高级内存管理技术，旨在提升预训练Transformer模型的性能，以应对这一挑战。

Innovation: 
TPTT提出了一个名为TPTT的创新框架，通过引入Memory as Gate (MaG) 和混合线性化注意力（LiZA）等技术，提升了预训练Transformer模型的效率。TPTT实现了与Hugging Face Transformers库的完全兼容性，通过参数高效微调（LoRA）而不是全量重新训练，使得任何因果LLM的适应变得无缝。TPTT已经在大约10亿参数的MMLU基准测试中展示了显著的效果提升，例如，Titans-Llama-3.2-1B相较于基线在精确匹配（EM）上提高了20%。此外，统计分析和对最近最先进的方法的比较证实了TPTT在实际应用中的可扩展性和鲁棒性。

Conclusion: 
TPTT框架有效地解决了大型语言模型在长上下文推理中的计算和内存效率问题，通过引入先进的注意力机制和内存管理技术实现了模型性能的显著提升，并保持了较高的准确性。TPTT的技术创新使其能够在无需大规模重新训练的情况下适应各种因果LLM，为自然语言处理领域带来了新的可能性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17671</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>307. cs.AI-RLRC：基于强化学习的压缩视觉-语言-动作模型恢复方法</title><link>https://arxiv.org/pdf/2506.17639</link><description>Background: 
视觉-语言-动作（VLA）模型在解决复杂的机器人操作任务方面展现了卓越的能力和潜力。然而，它们巨大的参数量和高的推理延迟给实际部署带来了显著挑战，尤其是在资源受限的机器人平台上。为解决这一问题，本文首先进行了广泛的实证研究，探索了当应用于VLA时模型压缩技术的有效性。在此基础上，作者提出了一种名为RLRC的三阶段恢复方法，包括结构化剪枝、基于SFT和RL的性能恢复以及进一步量化。RLRC在内存使用上最多可减少8倍，在推理吞吐量上提高了2.3倍，同时保持或超越了原始VLA的任务成功率。实验结果表明，RLRC在多个压缩基线中表现最优，具有在设备端部署VLA的强大潜力。

Innovation: 
本文创新地提出了一种基于强化学习的恢复方法RLRC。该方法通过结构化剪枝、基于SFT和RL的性能恢复以及进一步量化，有效提高了压缩VLA模型的性能和效率，解决了参数量大和推理延迟高的问题。RLRC实现了显著的内存减少和吞吐量提升，同时保持了较高的任务成功率，展现了在资源受限的机器人平台上的部署潜力。

Conclusion: 
实验研究表明，RLRC方法在多个压缩基线中表现最优，显著减少了VLA模型的内存占用和推理延迟，同时保持或优化了任务成功率，为视觉-语言-动作模型在资源限制的机器人平台上的实际部署提供了强有力的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17639</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>308. cs.AI-Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection</title><link>https://arxiv.org/pdf/2506.17633</link><description>Background: 
Out-of-distribution (OOD)检测试图区分异常样本，以防止在内部分布（ID）数据集上训练的模型产生不可用的输出。大多OOD检测方法需要大量的独立同分布(IID)样本进行训练，这严重限制了它们在现实世界的应用。在标注的内部分布样本稀缺的情况下，现有的Few-shot OOD检测方法没有充分考虑不同类别的独特多样性，从而使得任务更加棘手。因此，提出了一种新网络：自适应多提示对比网络（AMCN），以适应ID-OOD分离边界，并学习类内和类间的分布。通过利用CLIP将文本与图像联系起来，构建可学习的ID和OOD文本提示来补偿OOD样本的不足和ID样本的稀缺性。

Innovation: 
AMCN网络通过学习类内和类间分布来调整ID-OOD边界的适应性。特别地，它首先生成自适应提示（可学习的ID提示，标签固定的OOD提示和标签自适应的OOD提示），然后根据每个类生成自适应的类边界，最后提出一个提示引导的ID-OOD分离模块来控制ID和OOD提示之间的间隙。这些创新性地将文本和图像结合，不仅克服了样本有限的问题，还考虑了不同类别的特点，提升了Few-shot OOD检测的性能和应用范围

Conclusion: 
实验结果表明，AMCN在性能上优于其他现有的先进方法。这种网络架构和方法的成功，表明在少量标记样本的条件下，对OOD检测可以取得显著改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17633</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>309. cs.AI-LLM-Prompt: 集成异构提示以解锁大型语言模型在时间序列预测中的潜力</title><link>https://arxiv.org/pdf/2506.17631</link><description>Background: 
时间序列预测旨在通过建模变量之间的时序依赖关系来推断未来状态，具有重要的实际应用价值。尽管基于深度学习的方法已经取得了显著进展，但它们在长期预测和数据稀缺场景中仍表现不佳。最近的研究表明，大型语言模型（LLMs）在时间序列预测中的表现令人瞩目，然而现有的LLM基方法仍存在不足，包括统一的文本提示公式化缺乏以及对文本提示和时间序列之间模态差异的忽视。

Innovation: 
本文提出了LLM-Prompt框架，结合多提示信息和跨模态语义对齐。特地构造了一个包含可学习软提示和文本化硬提示的统一文本提示框架，并设计了一个语义空间嵌入和跨模态对齐模块以实现时间序列和文本信息的跨模态融合。最终，通过LLMs转换的时间序列被投影以获取预测结果。全面评估结果显示LLM-Prompt是一种强大的时间序列预测框架。

Conclusion: 
LLM-Prompt在6个公开数据集和3个碳排放数据集上的综合评估表明，该框架能够有效解决现有方法的不足，提升时间序列预测的准确性和稳定性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17631</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>310. cs.AI-CLiViS: 通过语义-视觉协同解锁认知地图的潜质用于基于视觉推理</title><link>https://arxiv.org/pdf/2506.17629</link><description>Background: 
EVR旨在基于第一人称视频遵循复杂、自由形式的指示，使得在动态环境中实现语义理解和时空推理。尽管EVR具有潜在应用前景，但由于复杂指令的多样性以及长时间第一人称视频中的复杂时空动态，它也面临着重大挑战。现有的解决方案要么依赖于静态视频字幕的大规模语言模型，这往往忽略了关键的视觉细节，要么依赖端到端的视觉语言模型，这些模型在逐步组合推理方面表现不佳。因此，通过互补的大规模语言模型推理能力和视觉语言模型感知能力，提出了一种新的无需训练的框架CLiViS，它利用大规模语言模型进行高层次的任务规划，并通过视觉语言模型驱动的开放世界视觉感知迭代更新场景上下文。

Innovation: 
CLiViS通过结合大规模语言模型的推理能力和视觉语言模型的感知能力，提出了一种无需训练的框架，用于补足现有EVR方法的不足。具体来说，CLiViS的核心是一个动态的认知地图，该地图在整个推理过程中逐步演变，构建了一个场景的结构化表示，链接了低级感知和高级推理。这种方法在多个基准上的实验表明，CLiViS在处理长期视觉依赖方面尤其有效。

Conclusion: 
CLiViS通过语义-视觉协同的方法，展示了其在EVR任务中的有效性和广泛性，特别是在处理长期视觉依赖方面表现出色。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17629</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>311. cs.AI-在动态深度学习系统中利用效率漏洞</title><link>https://arxiv.org/pdf/2506.17621</link><description>Background: 
随着深度学习模型在实际环境中的广泛应用，高效推理在严格延迟和资源限制下的需求日益增加。为此，动态深度学习系统（DDLSs）应运而生，通过输入自适应计算来优化运行时效率。尽管这些系统能够降低成本，但其动态特性也带来了未被充分探索的安全风险。特别是，依赖输入的执行路径为攻击者提供了降效的机会，导致在关键部署中的过长延迟、能耗增加以及可能的服务拒绝。本文研究了DDLSs动态行为中的安全影响，并揭示了当前系统中存在的通过敌对输入利用效率漏洞的隐患。通过对现有攻击策略的调研，识别了新兴模型架构的覆盖范围和现有防御机制的局限性。基于这些见解，提出探索现代DDLSs中的效率攻击可行性，并开发针对敌对条件的防御方案，以保障系统的鲁棒性。

Innovation: 
发现并揭示了DDLSs中的效率漏洞，这些漏洞容易被敌对输入利用；通过调研现有攻击策略，识别了现有防御机制的局限性；提出了针对现代DDLSs的效率攻击可行性研究和防御方案，旨在保护系统在敌对条件下的鲁棒性；

Conclusion: 
本文揭示了动态深度学习系统中的效率漏洞，这些漏洞可能被敌对输入利用，从而影响系统的性能和安全性。提出了对现代DDLSs中的效率攻击可行性的研究，并开发了针对敌对条件的防御方案，旨在保护系统的鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17621</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>312. cs.AI-Risk-Guided Diffusion: 到太空部署机器人基础模型，在那里失败不容许</title><link>https://arxiv.org/pdf/2506.17601</link><description>Background: 
未来的空间探测任务需要在极端、不熟悉的地形中实现安全可靠的导航。最近的生成AI方法能够从大规模的跨体感数据集中学习语义感知的导航策略，但提供有限的安全保证。NASA JPL的火星模拟设施火星院地的硬件实验表明，尽管基于学习的机器人模型在目标达成性能方面表现良好，但我们的方法通过在推理时共享计算资源，以较低的失败率（最多减少4倍）实现了这一目标。

Innovation: 
受人类认知科学的启发，我们提出了一个基于风险的扩散框架，该框架融合了快速的、学习的'System-1'与较慢的、基于物理的'System-2'，在训练和推理期间共享计算资源，以实现适应性和形式安全的结合。这种方法能够在不增加额外训练的情况下，在推理过程中利用计算资源，从而降低失败率。

Conclusion: 
硬件实验结果表明，该方法在优化安全性和性能方面取得了显著进步，特别是在NASA JPL的火星模拟设施火星院地，能够以最高4倍的减少失败率，同时匹配学习驱动的机器人模型的目标达成性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17601</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>313. cs.AI-DRAMA-X：一种用于驾驶的细粒度意图预测和风险推理基准测试</title><link>https://arxiv.org/pdf/2506.17590</link><description>Background: 
理解行人和骑行者等易受伤害的道路使用者的短期动态对于安全的自动驾驶至关重要，尤其是在城市场景中存在歧义或高风险行为的情况下。尽管视觉-语言模型（VLMs）能够实现开放词汇感知，但它们在细粒度意图推断中的用途尚未得到充分利用。值得注意的是，目前没有任何基准能够评估在安全关键情况下的多类意图预测。为了解决这一问题，我们介绍了DRAMA-X，一个通过自动化注释管道从DRAMA数据集构建而来的细粒度基准。

Innovation: 
DRAMA-X包含5686个易发生事故的帧，标注了对象边界框、九类方向意图分类、二元风险评分、由专家生成的 ego 车辆行动建议以及描述性运动摘要。这些注释使得能够对四个与自主决策相关的核心任务进行结构化的评估：对象检测、意图预测、风险评估以及行动建议。本文提出了一种参考基线模型 SGG-Intent，该模型基于视觉输入生成场景图，并利用大型语言模型支撑的组合推理阶段来进行意图推断、风险评估并推荐行动，且该模型是轻量级的并且无需训练。

Conclusion: 
实验表明，基于场景图的推理可以增强意图推断和风险评估，特别是在明确建模上下文线索时效果更为显著。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17590</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>314. cs.AI-HalluRNN：通过大型视觉语言模型中的递归跨层推理减轻幻觉</title><link>https://arxiv.org/pdf/2506.17587</link><description>Background: 
尽管大型视觉语言模型（LVLMs）在各种任务中取得了显著的性能，但它们仍然容易产生幻觉，即文本上合理但视觉上无法验证的输出。先前的方法通常通过数据集中心的微调或创新的解码策略来解决这一问题，但这些方法往往需要大量的资源或针对特定任务的配置。

Innovation: 
本文介绍了一种基于架构的解决方案——HalluRNN，它通过递归的跨层推理增强了模型的稳定性。具体来说，我们提出了一种新颖的双向门控深度传播单元（DG-DPU）模块，该模块在各层之间共享，并递归地细化隐藏状态。这使得信息在模型中的传递更加适应，确保了各层之间的一致性，并通过缓解表示漂移导致的幻觉来提高一致性。

Conclusion: 
通过仅微调DG-DPU模块，HalluRNN在多种基准上取得了强大的稳健性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17587</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>315. cs.AI-使用大型语言模型在链接开放数据上的上下文感知科学知识提取</title><link>https://arxiv.org/pdf/2506.17580</link><description>Background: 
科学文献的指数级增长给研究者提取和综合知识带来了挑战。传统搜索引擎返回的大量资源缺乏直接、详细的答案，而通用的大语言模型可能会给出过于简要且缺乏深度或遗漏最新信息的答案。具有搜索能力的大型语言模型也受限于上下文窗口，仅能提供简短而不完整的答案。因此，需要一种新的系统来解决这些限制，通过结构化的流程来提取、精炼和排名与查询相关的知识。结果表明，现有的搜索引擎和基于大语言模型的方法在处理此类检索任务时表现不佳，效率和准确性都有待提高。

Innovation: 
本文介绍了一种名为 WISE（Workflow for Intelligent Scientific Knowledge Extraction）的新系统，该系统利用了一个构建于大型语言模型基础上的树形架构，采用结构化的流程来提取、精炼和排名与查询相关的知识。通过动态评分和排名，系统能够优先突出每个来源的独特贡献，同时根据适应性停止标准最小化处理开销。实验表明，WISE 在处理 HBB 基因相关疾病时，能够将处理的文本量减少超过 80%，并且在召回率上显著优于其他基于搜索引擎或大语言模型的方法。此外，ROUGE 和 BLEU 评估指标显示，WISE 的输出更具独特性，而新的层级评分指标则展示了更深入的信息量。该研究还探讨了如何将 WISE 工作流适应到不同的领域，例如药物发现、材料科学和社会科学，以此来高效提取和综合不结构化的科学文献和网络资源的知识。

Conclusion: 
本文提出了一种名为 WISE 的新系统，通过结构化的流程来解决传统搜索工具和大语言模型在科学知识提取方面的问题。WISE 能够有效减少处理的数据量，同时保持高度的召回率和独特的输出，显示了其在科学文献提取和综合中的优势。此外，WISE 工作流的适应性表明其在多种科学领域的应用潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17580</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>316. cs.AI-通过快进优化掌握学习中的过度练习步骤</title><link>https://arxiv.org/pdf/2506.17577</link><description>Background: 
掌握学习可以提高学习效率和专业技能，但学生在已经掌握技能上花费过多时间的问题仍然是辅导系统的一大挑战。前人通过改善问题选择算法和设计专注于能力提升的任务来减少过度练习，但极少有研究将减少过度练习集中在步骤级的适应性上，这可以避免耗时的课程重新设计。已有研究方法依赖于全面更新课程设计才能实现减少过度练习的目标。

Innovation: 
本研究提出并评估了‘快进’作为一种技术，来增强现有问题选择算法，以减少过度练习。通过基于学习者模型和实际学生数据得出的问题解决路径模拟研究，快进能减少最多三分之一的过度练习。快进方法灵活，适用于任何问题选择算法，尤其在偏好选择困难问题的算法中表现最佳。这表明快进可以提高学生实践效率，但其实际影响力大小也可能依赖于学生在较高难度级别上的动机和参与度

Conclusion: 
在快进技术的帮助下，问题选择算法能够有效减少学生在掌握学习过程中对已经熟练掌握技能的过度练习。这种技术增加了学生的练习效率，但提高幅度也可能受限于学生面对高难度挑战时的动机和参与度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17577</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>317. cs.AI-使用不确定性估计加速残差强化学习</title><link>https://arxiv.org/pdf/2506.17564</link><description>Background: 
残差强化学习（Residual RL）是一种通过学习轻量级的残差策略来适应预训练政策的方法，这种残差策略能够提供纠正性行动。与直接微调整个基政策相比，残差RL在样本效率上更具优势。然而，现有的方法在处理稀疏奖励时表现不佳，并且大多数是针对确定性基政策设计的。这种背景下，该研究提出两种改进残差RL的方法，以进一步提高其样本效率，并使其适用于随机性基政策。

Innovation: 
1. 利用基政策的不确定性估计来聚焦于基政策不确定的区域，以便进行探索。n2. 提出了一种简单的修改方案，使离策略残差学习能够观察到基行动，并更好地处理随机性基政策。这些改进使得残差RL可以在更广泛的任务上实现更好的性能，特别是对于具有随机性的基政策。

Conclusion: 
通过在Robosuite和D4RL任务上评估我们的方法，并将其与最先进的微调方法、示范增强RL方法以及其他残差RL方法进行比较，证明了我们的算法在多种模拟基准环境中的表现远超现有基线。此外，我们还在现实世界中部署了我们的学习策略，展示了它们在零样本模拟到现实转移中的鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17564</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>318. cs.AI-VLA-OS: 在视觉-语言-动作模型中结构化和剖析规划表示与范式</title><link>https://arxiv.org/pdf/2506.17561</link><description>Background: 
近期关于视觉-语言-动作（VLA）模型的研究从端到端动作生成范式转向了一种涉及任务规划后跟随动作生成的管道，展现出在各种复杂的、长期的操控任务上实现了改进的性能。然而，现有的方法在网络架构、规划范式、表示方法和训练数据源方面存在显著差异，使得研究人员难以识别性能提高的具体来源以及需要进一步改进的组件。

Innovation: 
本文通过引入VLA-OS，一种具有多种任务规划范式的统一VLA架构系列，并设计了一整套控制实验来覆盖各类对象（刚体与非刚体）、视觉模态（2D与3D）、环境（模拟与现实世界）以及末端执行器（夹具与灵巧手），系统地研究了不同规划范式和表示的影响，以隔离网络架构和训练数据的影响。研究表明：1）基于视觉的规划表示通常优于基于语言的规划表示；2）层级视觉-语言-动作（Hierarchical-VLA）范式通常在任务性能、预训练、泛化能力、可扩展性和连续学习能力方面优于其他范式，尽管其训练和推理速度较慢。

Conclusion: 
通过VLA-OS，本文展示了在VLA模型中不同规划范式和表示方法的综合影响，为未来的研究提供了方向，特别是在识别有效组件和优化模型性能方面。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17561</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>319. cs.AI-向多组代理之间的零样本协调：N-XPlay框架</title><link>https://arxiv.org/pdf/2506.17560</link><description>Background: 
零样本协调（ZSC）是自适应代理成为有效队友的关键能力。现有的ZSC方法评估的是未之前交互的两个代理之间的协调能力，但这些场景未能反映现实世界多代理系统中的复杂性，其中协调往往涉及到小组层次结构以及团队间的交互，称为多团队系统（MTS）。现有方法适用于两代理场景，但无法有效测试N代理场景中的ZSC能力。

Innovation: 
首次引入了N玩家Overcooked，它是流行两代理ZSC基准的N代理扩展，能够评估N代理场景中的ZSC能力。还提出了N-XPlay框架，用于评估N代理、多团队设置中的零样本协调能力，在对比两种训练方法（N-XPlay和Self-Play）的实验中，展示了使用N-XPlay训练的代理能更好地平衡团队内部和团队间协调能力。

Conclusion: 
提出了N-XPlay框架用于评估多代理场景中的零样本协调能力，并通过对比实验展示了N-XPlay相比Self-Play的优势，即能更好地同时平衡团队内部和团队间的协调。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17560</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>320. cs.AI-SynDaCaTE: 用于评估部分-整体层次推理的合成数据集</title><link>https://arxiv.org/pdf/2506.17558</link><description>Background: 
在计算机视觉领域，学习推断对象表示，特别是部分-整体层次结构，是一项重要的研究内容，旨在提高数据效率、系统泛化能力和鲁棒性。现有的基于胶囊网络设计以推断部分-整体层次结构的模型通常在监督任务如物体分类上进行端到端训练，这使得难以验证此类模型是否真的学习了推断部分-整体层次结构的能力。因此，需要一种新的方法来评估这种能力。

Innovation: 
本文提出了一种名为SynDaCaTE的合成数据集，用于评估部分-整体层次推理。通过使用这个数据集，具体实现了以下创新：1) 识别出一个现有突出胶囊模型的关键瓶颈；2) 证明了部分到整体的变换等变自注意力机制对提高部分-整体推理非常有效，这为未来计算机视觉中的有效的归纳偏置设计指明了方向。

Conclusion: 
SynDaCaTE数据集的有效性通过两个方面得到证明和评估，一是能够在现有模型上精确找到问题所在，二是展示了变换等变自注意力机制在部分-整体推理中的高效性，这对未来计算机视觉的模型设计具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17558</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>321. cs.AI-在基于大型语言模型的推荐系统中模型并行和数据并行优化方法的研究</title><link>https://arxiv.org/pdf/2506.17551</link><description>Background: 
随着大型语言模型（LLMs）在推荐系统中的快速采用，由于其庞大的参数大小和大量的数据量导致的计算和通信瓶颈问题变得越来越突出。本文系统地研究了两类优化方法：模型并行性和数据并行性，用于推荐场景下的LLM分布式训练。

Innovation: 
在模型并行性方面，实现了张量并行性和管道并行性，并引入了自适应负载均衡机制以减少设备间通信开销；在数据并行性方面，对比了同步和异步模式，结合梯度压缩和稀疏化技术与高效的聚合通信框架，显著提高了带宽利用率。实验表明，提出的混合并行方案在保持强扩展性和鲁棒性的同时，能比传统的单一模式并行提高约30%的训练吞吐量和约20%的资源利用率。

Conclusion: 
讨论了在线部署中不同并行策略的权衡，并概述了包括异构硬件集成和自动化调度技术在内的未来研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17551</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>322. cs.AI-ConsumerBench：在终端设备上评估生成式AI应用的基准框架</title><link>https://arxiv.org/pdf/2506.17538</link><description>Background: 
随着生成式人工智能（GenAI）应用从云环境转移到终端用户设备，带来了新的挑战，包括资源管理、系统效率和用户体验。现有的基准测试大多基于假设独占模型访问专用显卡的场景，而没有模拟在受限硬件上多个应用程序同时运行的现实情况。在这种背景下，此研究提出了一种新的评估工具——ConsumerBench框架，用于评估运行在终端用户设备上的GenAI模型的系统效率和响应时间。

Innovation: 
与现有的基准测试不同，ConsumerBench能够模拟多应用同时在受限硬件上并发执行的真实场景，并支持可定制的工作流程来模拟需要多个应用之间协调的复杂任务。此外，ConsumerBench能够捕捉应用级别指标，如延迟和服务级别目标（SLO）达成情况，以及系统级别指标，如CPU/GPU利用率和内存带宽。通过广泛的实验，ConsumerBench揭示了资源共享效率低下、贪婪分配下的不公调度问题以及静态模型服务器配置下的性能陷阱。研究还提供了一些实用的见解，强调为消费者级GPU架构定制内核的好处，以及实施SLO感知调度策略的价值.

Conclusion: 
ConsumerBench通过详细的实验揭示了在终端用户设备上运行的GenAI模型的资源分配、调度和性能问题，并提供了一些实用建议。该研究强调了针对消费者级硬件优化模型和系统设计的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17538</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>323. cs.AI-探索个性化放疗策略 第一部分 使用类激活映射解锁与治疗反应相关的肿瘤亚区</title><link>https://arxiv.org/pdf/2506.17536</link><description>Background: 
个性化精准放疗不仅需要简单的分类，还需要识别具有预后意义的空间特征，并能够根据个体反应调整治疗方案。该研究比较了三种治疗响应预测方法：标准影像组学、基于梯度的特征和结合类激活映射的卷积神经网络。研究分析了39名患者共69个脑转移瘤在接受伽玛刀立体定向放射外科治疗后的表现。通过集成自编码器分类模型预测肿瘤体积在三个月随访中是否减少超过20%，将其设定为二分类任务。研究表明，这些模型在层级特征提取和分类器的区分能力上表现出优势。类激活映射在像素级别提供最详细的影像学洞察，能够识别病变特定区域而非依赖固定模式，说明其具有较强的泛化能力。在非应答病灶中，激活区域可能指示放射抵抗力。像素级别的类激活映射在分类准确性上优于影像组学和基于梯度的方法，并且其精细的空间特征能够与细胞水平数据对齐，支持生物验证和治疗响应异质性的更深入理解。尽管仍需进一步验证，但这些发现强调了在光子和粒子放射治疗中指导个性化和适应性放疗策略的潜力。

Innovation: 
引入了类激活映射（Class Activation Mapping, CAM）来作为预测治疗响应的方法，特别是像素级CAM提供了详细的影像学洞察，能够识别病变特定区域而非依赖固定模式，这一方法在分类准确性上优于传统的影像组学和基于梯度的方法。其细腻的空间特征可以与细胞水平数据对齐，支持生物验证和更深入理解治疗反应的异质性。

Conclusion: 
像素级别的类激活映射在预测治疗响应方面表现优异，可以识别出与治疗反应相关的肿瘤亚区，为其提供更精确的个性化和适应性放疗策略的指导。尽管需要进一步的验证，但这项研究展示了类激活映射在放疗中的应用潜力，尤其是在光子和粒子放射治疗中。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17536</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>324. cs.AI-多语言语音数据集中的数据质量问题：需要社会语言学意识和前瞻性的语言规划</title><link>https://arxiv.org/pdf/2506.17525</link><description>Background: 
对广泛使用的公共多语言语音数据集Mozilla Common Voice 17.0、FLEURS和VoxPopuli的质量审核发现，在某些语言中，这些数据集存在重大质量问题。研究人员认为解决这些问题将使这些数据集在训练和评估下游模型时更有用，同时还能提高模型性能。研究还按照微观和宏观两个层面对这些问题进行了分类，其中宏观层面的问题在非正式化且资源不足的语言中更为普遍。通过分析台湾南部闽南话（nan_tw）案例，强调了自动语音识别（ASR）数据集创建过程中需要采取积极的语言规划措施（如正体字规定和方言界线定义），并对数据质量进行控制。

Innovation: 
对多语言语音数据集的质量问题进行细致分类，并通过案例研究强调了社会语言学意识在有效创建语音数据资源中的重要性。提出了未来数据集开发的指南和建议，强调了前瞻性的语言规划对于提升数据质量的重要性。

Conclusion: 
研究提出了一些建议和指导方针，以减轻未来数据集开发中的这些问题，特别强调了社会语言学意识在创造稳健和可靠语音数据资源中的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17525</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>325. cs.AI-深度强化学习中的状态表征学习综述</title><link>https://arxiv.org/pdf/2506.17518</link><description>Background: 
代表性的学习方法是解决复杂观察空间在序列决策问题中的重要工具。近年来，许多方法通过使用各种类型的策略来学习有意义的状态表示，在强化学习中提高了样本效率、泛化能力和性能。本文旨在在一个无模型的在线环境中提供这些方法的广泛分类，探索它们在学习状态表示方面采取的不同方法。本文将这些方法分为六个主要类别，详细阐述它们的工作机制、优点和局限性。通过这种分类，本文旨在增强对该领域的理解，并为新研究者提供指南。此外，还讨论了评估表示质量的技术，并描述了相关未来方向。

Innovation: 
将代表学习方法分类为六个主要类别，详细解释了它们的工作机制、优缺点及其在强化学习中的应用。同时，还提供了一套评估表示质量的技术，并提出了未来的潜在研究方向。这种方法论有助于新研究者更好地理解和应用代表学习方法。

Conclusion: 
本文通过分类方法和评估技术，增强了对代表学习方法在无模型在线强化学习中的理解，并为未来的研究提供了指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17518</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>326. cs.AI-使用KnoVo映射研究贡献的演变</title><link>https://arxiv.org/pdf/2506.17508</link><description>Background: 
传统的引用分析主要侧重于衡量研究的影响，但未能充分衡量研究的创新性。KnoVo框架旨在量化和分析科学文献中研究创新性的演变，通过多层次的引用网络，评估目标论文相对于前后工作的新颖性程度。通过对目标论文的摘要利用大规模语言模型（LLMs）动态提取比较维度（如方法、应用、数据集），再与相关论文在相同的提取维度进行比较分析，旨在提供定量的新颖性分数，量化目标论文在特定方面的改进、同等或劣势。资料的聚合与可视化帮助研究者评估原创性，发现类似工作，跟踪特定研究维度的知识演变，揭示研究缺口，并探索跨学科联系。

Innovation: 
KnoVo框架通过多层次引用网络，利用大规模语言模型动态提取比较维度，并进行定量比较分析，以评估研究新颖性，这一方法是对传统引用分析的改进和创新。

Conclusion: 
KnoVo框架通过动态演化的图形和对比雷达图等可视化手段，不仅帮助研究者评估原创性和识别类似工作，还能够跟踪特定研究维度的知识演变，揭示研究缺口，并探索跨学科联系。通过对多个科学领域的20篇论文的详细分析，结果显示开源大规模语言模型在KnoVo框架中的表现良好，展示了其在研究贡献演变方面的能力和潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17508</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>327. cs.AI-通过大规模预训练实现从普遍性到精通：基于乐谱的作曲家风格音乐生成</title><link>https://arxiv.org/pdf/2506.17497</link><description>Background: 
尽管可控的符号音乐生成已取得进步，但在某些控制模式下，数据稀缺仍是挑战。以作曲家风格的音乐生成为例，每个作曲家可用的乐曲数量有限，这限制了风格和音乐基本元素（如旋律、和弦、节奏）的建模。

Innovation: 
本文提出了一种两阶段训练框架，首先在大量流行、民间和古典音乐数据集上进行REMIBASED音乐生成模型的预训练，然后使用轻量级适配器模块对数据量小的人工验证的数据集进行调优，以增强对特定作曲家风格的掌握。这种方法提高了作曲家风格的精确建模和音乐美学表现，并通过预训练和调优过程观察了模型构建音乐概念和深化风格理解的方式。

Conclusion: 
实验结果表明，本文方法优于对照组，取得了更精细的作曲家风格建模和更好的音乐美学效果。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17497</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>328. cs.AI-探索个性化放疗策略之二：利用扩散模型预测肿瘤移位模式</title><link>https://arxiv.org/pdf/2506.17491</link><description>Background: 
放射治疗的效果取决于剂量和治疗时间这两个关键参数，其最佳值因患者而异。这种差异性在治疗脑癌尤为关键，虽然分割或分阶段立体定向放射外科在提高安全性方面优于单一治疗，但这也加大了预测治疗反应的难度。现有的预测工具，如影像组学和剂量组学模型，对肿瘤在治疗过程中空间和时间动态变化的分析效果有限，使得准确预测治疗反应仍具挑战性。这项研究旨在开发一种新的基于去噪扩散隐式模型（DDIM）的框架，通过分析术前和术后的影像数据，提供更有效的个性化放疗预测策略。

Innovation: 
这项研究提出了使用去噪扩散隐式模型（DDIM）来预测肿瘤治疗反应的新策略。通过单步和迭代的去噪策略，该模型能够有效地模拟患者特定的肿瘤演变过程，并准确识别与治疗反应相关的区域。这种方法为构建异质性治疗反应模型，并推动个性化和生物学导向的放疗提供了新的可能性和基础，能够实现早期、适应性干预，从而提高治疗效果。

Conclusion: 
该研究展示了一种利用DDIM模型进行个性化放疗预测的有效策略，能够模拟肿瘤随时间的演变，并精确定位响应治疗的区域。这为后续开发更加个性化的和生物学导向的放疗方案奠定了基础，有助于提高脑癌等疾病的治疗效果，减少过度治疗和不足治疗的问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17491</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>329. cs.AI-使用最少人工干预的机器人规划中设备端语言模型蒸馏</title><link>https://arxiv.org/pdf/2506.17486</link><description>Background: 
大型语言模型（LLMs）赋予机器人强大的上下文推理能力和自然的人机接口。然而，当前基于云的语言模型的机器人通常依赖于云托管的模型，这限制了它们在通信基础设施不可靠的环境中（如户外或工业环境）的应用。现有的语言模型为机器人提供规划功能时，通常需要云服务支持，这在某些环境下可能不可行或效率低下。为了克服这一限制，本文提出了一种名为PRISM的框架，旨在通过最少的人工监督，创建可在设备上运行的小型语言模型（SLM）启发式机器人计划工具。该框架可以从现有的基于语言模型的规划工具出发，自动生成多样化的任务和环境，从语言模型中提取计划，并利用合成数据集训练出一个紧凑的SLM，替代原有模型。

Innovation: 
本文提出的PRISM框架主要创新点如下：1）自动生成多样化的任务和环境；2）从语言模型中提取计划；3）通过合成数据集训练出紧凑的小型语言模型；4）在三个不同的机器人规划场景（制图与探索、操作和家务协助）中应用该框架，将LLAMA-3.2-3B的性能提升至超过GPT-4o的93%。此外，PRISM还可以使蒸馏后的计划跨多种机器人平台（地面和空中）和多种环境（室内和室外）进行广泛泛化。

Conclusion: 
通过对三个基于语言模型的规划工具的应用，本文展示了PRISM框架将LLAMA-3.2-3B的性能提升至超过GPT-4o的93%，同时证明了该框架具有广泛的适用性和高泛化能力。并且，所有软件、训练模型和数据集都已公开。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17486</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>330. cs.AI-理解大规模语言模型对写作和信息生态影响的计算方法</title><link>https://arxiv.org/pdf/2506.17467</link><description>Background: 
大规模语言模型（LLMs）已被证明在书写、沟通和创造方面具有显著潜力，导致这种新兴技术在社会中的迅速采纳。本文探讨了个人和机构如何适应和参与这项技术，通过三个研究方向进行研究：第一，揭示AI检测器机构采用引入系统性偏见的问题，特别是对非主导语言变体的写作者造成不利影响，强调了AI治理中的重要平等关切；第二，提出了一种新的测量不同写作领域中LLM采用程度的方法，并揭示了AI辅助内容在学术同行评审、科学出版物、消费者投诉、企业通讯、招聘信息和国际组织新闻公告中的一致模式；第三，对LLMs提供研究手稿反馈的能力进行了大规模实证分析，旨在为面临及时手稿反馈获取障碍的研究者提供洞见，尤其是针对早期职业生涯的研究人员和来自资源匮乏地区的研究者。

Innovation: 
提出了新的群体层面的算法方法来测量大规模语言模型在不同写作领域中的采用情况，揭示了AI辅助内容在多个领域的模式，以及大规模实证分析LLMs为研究手稿提供建设性反馈的能力，为个人和研究机构提供了重要的应用价值和见解

Conclusion: 
研究揭示了大规模语言模型在不同领域的应用模式，并强调了在AI治理中需要考虑的公平性问题，特别指出对非主导语言变体写作者的支持需求。同时，研究提出的方法为评估和优化大规模语言模型的使用提供了新工具，并为改善研究手稿的访问和反馈机制提供了建议。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17467</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>331. cs.AI-FedNAMs：在联邦学习背景下进行可解释性分析</title><link>https://arxiv.org/pdf/2506.17466</link><description>Background: 
联邦学习正在不断发展，但在解释性和可解释性方面仍面临挑战。该论文旨在解决这些挑战，提出了一种将神经加性模型（NAMs）应用于联邦学习框架的新方法，称为联邦神经加性模型（FedNAMs），以提高模型的解释性和隐私保护能力，同时保持准确性。这种方法通过在多个设备的本地数据上训练，减少了数据集中化所带来的风险，提高了模型的稳健性和泛化能力，尤其是在金融和医疗保健领域具有重要价值。

Innovation: 
该研究提出了一种新的方法FedNAMs，结合了NAMs的优势和联邦学习的去中心化特性，使得模型具有更好的解释性和隐私保护。通过在本地设备上训练，该方法能够识别关键预测特征，并保持与传统联邦深度神经网络（DNNs）相匹敌的准确性。该方法在文本和图像分类任务上进行了验证，结果显示FedNAMs在保持高解释性的同时，实现了最小的准确性损失。

Conclusion: 
FedNAMs通过在多个设备上使用本地数据训练，增强了隐私保护和模型效率，提高了不同数据集上的可解释性和稳健性。这种方法还在不同层面识别了关键的预测特征，有助于深入理解模型的预测原因，并增强了不同特征的可解释性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17466</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>332. cs.AI-通过LVLM协调感知、推理和行动的通用机器人导航</title><link>https://arxiv.org/pdf/2506.17462</link><description>Background: 
机器人在未知环境中的通用导航策略开发仍然是一个核心挑战。现有的大多数系统依赖于特定任务的神经网络和固定的数据流，限制了其泛化能力。大型视觉-语言模型（LVLM）提供了一种有潜力的替代方案，能够嵌入适合推理和规划的人类知识。然而，之前的LVLM-机器人整合通常依赖于预映射的空间、硬编码的表示和短视的探索。因此，研究者引入了微粒机器人导航架构（ARNA），这是一种通用的导航框架，它为基于LVLM的代理配备了现代机器人堆栈中可用的感知、推理和导航工具库。代理在运行时能够自主定义和执行特定任务的工作流程，逐步查询机器人模块、处理多模态输入并选择适当的导航行动。这种做法在Habitat Lab上以HM-EQA基准进行评估，ARNA实现了最先进的性能，展示了有效的探索、导航和实体化问答，无需依赖人工编写的计划、固定的输入表示或预先存在的地图，提供了机器人堆栈设计的新视角。

Innovation: 
ARNA是一种通用的导航框架，使用基于LVLM的代理，并配备了一个丰富的感知、推理和导航工具库，可以在未知环境中实现自主和迭代的任务执行。这种框架允许代理在运行时定义和执行特定任务的工作流程，查询机器人模块、处理多模态输入并选择适当的导航行动，从而在未映射环境中进行稳健的导航和推理，提高机器人系统的自适应性和灵活性。ARNA在HM-EQA基准上的评估展示了其有效探索、导航和实体化问答的能力，无需依赖人工编写的计划、固定的输入表示或预先存在的地图，为机器人堆栈设计提供了一种新的思路。

Conclusion: 
该研究所提出的ARNA框架在Habitat Lab上实现的先进性能，展示了在未映射环境中进行导航和推理的有效性，无需依赖预先手写的计划、固定的输入表示或预先存在的地图。这种新方法为机器人导航提供了一种更具自适应性的设计，开启了AI在机器人系统中的新应用前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17462</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>333. cs.AI-Trans$^2$-CBCT: 一种用于稀疏视角锥束CT重建的双变换子框架</title><link>https://arxiv.org/pdf/2506.17425</link><description>Background: 
锥束CT（CBCT）使用少数X射线投影视图进行扫描，可以更快并且剂量更低，但由于严重的下采样，会产生强烈的伪影和较差的空间覆盖率。现有的方法面临严重的信息不足和伪影问题。

Innovation: 
提出了一种统一框架，利用Hybrid CNN-Transformer模型TransUNet替代传统的UNet/ResNet编码器，结合多尺度特征和视图特定特征查询，加入一个轻量级衰减预测头，从而构建Trans-CBCT模型，显著优于先前的基线。为了进一步增强体体积一致性，引入了一个基于邻域的Point Transformer，通过3D位置编码和k-最近邻的注意力机制提高空间一致性，最终形成的Trans$^2$-CBCT模型进一步提升了重建质量。

Conclusion: 
实验结果表明，从六个到十个视图，使用CNN-Transformer特征与点几何推理相结合的方法在稀疏视角CBCT重建中效果显著，验证了该方法的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17425</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>334. cs.AI-UProp：探索大规模语言模型在多步自主决策中的不确定性传播</title><link>https://arxiv.org/pdf/2506.17419</link><description>Background: 
随着大规模语言模型（LLMs）在涉及现实世界序列决策的安全关键应用中被集成，了解何时可以信赖LLM的决策变得至关重要。现有的LLM不确定性量化（UQ）方法主要针对单轮问答场景设计，导致多步决策场景，例如LLM代理系统，研究相对不足。因此，本研究旨在探索一种信息论框架，将LLM的序列决策不确定性分解为两个部分，并提出UProp作为一种高效且有效的外部不确定性估计器。

Innovation: 
本文介绍了一种新的信息论框架UProp，该框架将LLM的序列决策不确定性分解为内部不确定性和外部不确定性，并提出了一种高效的不确定性估计方法，该方法将互信息的直接估计转化为依赖于轨迹的决策过程的点互信息估计。该方法在多个基准测试（如AgentBench和HotpotQA）中与现有的单轮UQ基线相比表现出显著的优势。此外，研究还详细分析了UProp的采样效率、潜在应用和中间不确定性传播，以展示其有效性。

Conclusion: 
研究结果表明，UProp显著优于现有的单轮UQ基线，并且展示了其在多步代理决策场景中的优越性能。提供的分析进一步证实了UProp的有效性。相关代码将发布在指定网站。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17419</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>335. cs.AI-在现实世界中将语言落地的挑战</title><link>https://arxiv.org/pdf/2506.17375</link><description>Background: 
人工智能的一个长远目标是构建一个语言理解系统，使得人类能够使用自然语言与物理机器人协作。然而，在现实中实现这一目标面临诸多挑战，如如何在自然语言的理解与物理任务执行之间建立有效联系等。本文讨论了这些挑战，并提出了一种解决方案，该方案结合了一个具备交互式任务学习能力的认知代理和一个大型语言模型的语义理解能力，应用于物理机器人。文章还指出了解决方法的初步实现路径。

Innovation: 
提出了一种结合认知代理的交互式任务学习能力和大型语言模型的语义理解能力的解决方案，旨在有效建立自然语言与物理任务执行之间的联系。

Conclusion: 
本文讨论了在物理机器人中实现自然语言与实际任务结合的挑战，提出了一种新型的方法，并指出了其初步实现路径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17375</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>336. cs.AI-从图纸到决策：一种用于解析2D工程图纸以构建结构化制造知识的混合视觉语言框架</title><link>https://arxiv.org/pdf/2506.17374</link><description>Background: 
从2D工程图纸中高效且准确地提取关键信息对于推动数字制造流程至关重要。这些信息包括几何尺寸与公差（GD&amp;amp;T）、测量值、材料规格和文本注释。手动提取的方式耗时且劳动密集，而通用光学字符识别（OCR）模型因复杂的布局、工程符号和倾斜的文本常常失效，导致输出不完整且不可靠。现有的限制造成了不完整且不可靠的输出。因此，需要一种新的方法来解决这些挑战，该方法能够识别、提取和解析图纸中的关键信息，以支持更高效的制造流程和决策。

Innovation: 
该论文提出了一种结合旋转感知对象检测模型（YOLOv11-obb）与基于变压器的视觉语言解析器的混合视觉语言框架。通过这种方法，可以处理复杂布局、工程符号和倾斜文本的问题，从而在精细化调整轻量级视觉语言模型（VLM）后，实现对2D图形注释的准确定位和高效解析。通过构建一个包含1,367份2D机械图纸的标注数据集，并使用该数据集训练YOLOv11-obb来检测和提取注释，最后使用两种开源VLM（Donut和Florence-2）进行解析。结果显示，Donut在四个关键指标上表现出优异性能，在精度、召回率和F1分数方面均优于Florence-2，且 hallucination（成词率）仅为11.5%。这表明该框架在数字化制造中的实用性和有效性。

Conclusion: 
本文提出的混合视觉语言框架能够显著提高从2D工程图纸到制造流程中关键信息的提取效率和准确性。通过实验验证，Donut模型在四个关键指标上表现优异，证明了该方法的有效性和实用性。该框架不仅适用于图纸解析，还能支持后续的制造过程选择等任务，为现代2D图纸解释提供了新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17374</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>337. cs.AI-多模态政治偏见识别和中和</title><link>https://arxiv.org/pdf/2506.17372</link><description>Background: 
由于存在政治回声室，检测并从政治文章的文本和图像中去除主观偏见和情绪化语言变得至关重要。现有研究主要集中在文本部分的偏见处理，而忽略了图像部分。图像同样是一个强有力的传播信息的媒介，为此，本研究提出了一种结合文本与图像偏见处理的模型，包含四个步骤：图像文本对齐、图像偏见评分、文本去偏以及最终的中和步骤。

Innovation: 
本研究首次提出了一种多模态方法，结合文本和图像的偏见检测和中和，创新地利用CLIP模型实现图像的语义对齐，使用ViT分类器进行图像偏见评分，用BERT模型检测和中和文本中的偏见。这些步骤共同完成最后的去偏工作，替换文本和图像中的偏见词汇和图像以中性的或减轻的形式。研究表明，该方法在识别潜在的偏见词汇和有效训练ViT模型方面显示出潜力，同时语义模型也表现出较高的效率，但仍需更多时间和资源来获得更好的结果。

Conclusion: 
研究成果显示，该多模态方法具有潜在的前景，通过这项工作获得了重要的进展，但仍需进一步改进以获得更佳的结果。同时建议进行人工评估以确保新生成的文本和图像的语义一致性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17372</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>338. cs.AI-基于AI的内容创作和产品推荐在电子商务中的应用：伦理概览</title><link>https://arxiv.org/pdf/2506.17370</link><description>Background: 
随着电子商务迅速将人工智能整合到内容创作和产品推荐中，这些技术在个性化和效率方面提供了显著优势。通过自动化产品描述、生成动态广告以及根据消费者行为提供个性化推荐，电商平台如亚马逊和Shopify等已经广泛应用了AI驱动的技术。然而，AI在电子商务的广泛应用也引发了诸如数据隐私、算法偏差和消费者自主权等关键伦理问题。文化、性别或经济因素的偏差可能会无意中嵌入AI模型，从而导致不公平的产品推荐并强化有害的刻板印象。因此，本文旨在探讨AI驱动的内容创作和产品推荐的伦理影响，强调建立公平、透明和更为牢固的伦理标准的必要性，并提出了实际操作的最佳实践，以剔除偏见、确保包容性。此外，本文还讨论了围绕保护消费者数据隐私、促进决策过程透明度以及增强消费者自主权的伦理框架。n

Innovation: 
本文提出了实际操作的最佳实践，如定期审计算法、扩大训练数据并整合到AI模型中的公平性指标，以及围绕保护消费者数据隐私、促进透明的决策过程以及增强消费者自主权的伦理框架。这些做法旨在建立更为公平、透明和强有力的伦理标准，以负责任地利用AI技术进行电子商务应用中的内容创作和产品推荐，确保这些技术的有效性和道义上的严谨性。n

Conclusion: 
本文为负责任地应用人工智能于电子商务中的内容创作和产品推荐提供了指导方针，确保这些技术既能有效运作又能保持道义上的合理性和公正性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17370</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>339. cs.AI-在语义变异下重新评估代码LLM基准</title><link>https://arxiv.org/pdf/2506.17369</link><description>Background: 
在大型语言模型（LLMs）的时代，代码基准已成为软件工程领域的重要研究方向，并被广泛应用于实际操作中。这些基准通常会评估LLMs在特定代码相关任务上的表现，比如代码理解和生成。设计代码基准的核心步骤之一是编写提示模板。然而，大多数现有代码基准通常仅依赖于单一的提示模板，这使得它们容易受到提示敏感性的影响，即即使是稍微调整提示模板也会导致LLM表现的显著变化，从而影响模型能力的可靠评估。尽管之前的研究探讨过提示敏感性，但这些研究仅局限于传统的自然语言处理（NLP）任务。在此背景下，本研究通过修改提示模板来深入探究代码基准中的提示敏感性问题，以期提供更为可靠和准确的LLM能力评估方法。

Innovation: 
本研究提出了一个通用框架来修改提示模板，并保持其语义和结构尽可能不变。在八个代码基准任务上针对10个代表性的开源LLMs进行了广泛实验，每个任务包含100个语义相似的提示模板。通过使用各种统计指标分析评估结果，发现了即使轻微的提示变化也会影响表现，并且提示变异可能导致不同模型性能排名的不一致性。研究成果强调了在设计未来代码基准时需要考虑提示敏感性，从而确保更可靠和准确的LLM能力评估。

Conclusion: 
本研究通过广泛的实验和统计分析，揭示了代码基准中提示敏感性对LLM性能评估的影响，表明即使是小的变化也会导致显著的变化，且可能带来不同模型间的排名不一致性。因此，未来在设计代码基准时需要重视提示敏感性，以确保评估的可靠性和准确性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17369</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>340. cs.AI-SAFEx：通过稳定的关键安全专家识别分析基于MoE的大语言模型漏洞</title><link>https://arxiv.org/pdf/2506.17368</link><description>Background: 
基于Mixture-of-Experts（MoE）的大语言模型在效率和可扩展性方面取得了显著进步，但其独特的架构设计带来了一些未被充分探索的安全对齐挑战。现有的大多数安全对齐策略主要是为密集模型设计的，对MoE特有的安全漏洞应对不足。研究发现，MoE架构中的安全对齐行为依赖于特定的专家模块，这揭示了MoE架构固有的关键风险。现有的安全对齐策略不适用于MoE模型，因为它们缺乏应对MoE特定漏洞的方法。已有工作多集中在密集模型上，缺少针对MoE的具体安全对齐策略。因此，需要开发一种新的分析框架来识别和验证这些关键安全专家。该框架需要能够稳定地识别出对安全至关重要的专家模块，这些模块对于生成避免有害内容的响应至关重要。这种分析对于理解MoE架构的安全性至关重要，可以帮助开发者更好地应对和优化模型的安全风险。

Innovation: 
SAFEx提出了一个基于稳定性的专家选择算法（SES）的新分析框架，用于识别和验证MoE模型中对安全至关重要的专家模块。该框架使得安全关键专家可以被明确地分解成不同的功能组，包括负责检测有害内容的专家和控制安全响应生成的专家。通过在主流MoE模型（如最近发布的Qwen3-MoE）上进行广泛实验， SAFEx展示了小型关键专家集合对模型安全的重要性。通过禁用少数关键专家，模型提供有益响应的拒绝率显著下降，表明一小部分专家对整体模型安全具有非线性的重大影响。这一发现为MoE模型的安全对齐提供了新的视角，同时也强调了特定专家模块在保障模型安全中的重要作用。

Conclusion: 
通过SAFEx，SAFEx框架成功地识别并验证了MoE模型中的安全关键专家，并展示了这些关键专家对模型安全的重要影响。这个新框架为MoE模型的安全分析和优化提供了有价值的手段，并有助于提高这些模型的安全性和鲁棒性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17368</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>341. cs.AI-现金还是舒适？LLMs如何评估您的不便</title><link>https://arxiv.org/pdf/2506.17367</link><description>Background: 
大型语言模型（LLMs）正在被越来越多地提出作为近乎自主的人工智能（AI）代理，能够为人类做出日常决策。尽管LLMs在很多技术任务上表现良好，但在个人决策中的行为仍然是不完全理解的。之前的研究已经评估了LLMs在理性以及道德上与人类决策的对齐情况，但当经济奖励与用户舒适度冲突时，AI助手的行为尚未被充分研究。本文旨在通过量化多个LLMs对用户不便（增加步行、等待、饥饿和疼痛）的定价，探讨LLMs在这些场景下的行为，揭示LLMs在决策过程中可能存在的问题。

Innovation: 
本文通过定量分析多个LLMs对用户不同不便的定价，揭示了当前LLMs在个人决策支持中的几个关键问题。这些发现包括：不同LLMs之间的响应差异巨大；即使是同一个LLM，对提问的细微变化也可能导致决策的巨大差异；LLMs可能接受不合理低的报酬以换取重大不便；以及LLMs可能拒绝报酬而拒绝执行任何不便的行为。这些结果强调了在未来应用中，需要仔细审查LLMs对人类不便的定价，特别是在用户代表方面需要权衡金钱与舒适度的交易情况更为普遍时。

Conclusion: 
这些发现表明，当前LLMs在评估人类不便方面存在显著问题，特别是当涉及代为做出金钱与舒适度权衡的决策时。文章强调了需要进一步的研究和合理的监管来确保这些技术的安全和有效应用。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17367</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>342. cs.AI-基于AI的多模态生物识别技术在检测手机分心中的应用：在线学习中的应用</title><link>https://arxiv.org/pdf/2506.17364</link><description>Background: 
研究重点放在利用多模态生物识别技术检测工作中因使用智能手机而导致的分心，特别是在线学习任务中需要持续集中注意力的情况下。尽管这些方法可以应用于各种领域，如自动驾驶，但研究主要关注学习者在面对内部因素（如动机）、系统相关因素（如课程设计）和环境因素（如智能手机使用）的挑战时，保持注意力和参与度的困难。传统的学习平台通常缺乏详细的的行为数据，而多模态学习分析(MMLA)和生物传感器提供了关于学习者注意力的新见解。

Innovation: 
研究提出了一种基于AI的方法，利用生理信号和头部姿势数据来检测手机使用情况。研究结果显示，单独的生物识别信号，如脑电波或心率，准确性有限，而单独使用头部姿势能达到87%的准确率。结合所有信号的多模态模型达到了91%的准确率，突显了结合多种信号的益处。

Conclusion: 
结论讨论了在在线学习环境中部署这些模型的含义和限制，强调了实时支持的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17364</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>343. cs.AI-LLM-Based Virtual Teaching Assistant的大规模现实世界评估</title><link>https://arxiv.org/pdf/2506.17363</link><description>Background: 
虚拟教学助手（VTAs）由大型语言模型（LLMs）驱动，有可能通过提供即时反馈和促进多轮对话来增强学生学习。然而，关于它们在真实课堂中的有效性及接受度的实际研究表明不足，实际影响也存在不确定性。这项研究旨在通过开发基于LLM的VTA并将其部署到使用477名研究生的入门级人工智能编程课程中，来评估VTAs如何随着时间发展被学生感知，并分析了3,869对学生-辅助教学助手交互对，针对传统学生-人类教师交互进行对比，进一步评估其在学习中的作用，通过大规模的实证研究和交互分析，评估VTAs在真实课堂中的可行性，并强调扩大应用的关键挑战。最后，公开了VTA系统的源代码，促进AI驱动教育的发展。

Innovation: 
开发了基于LLM的VTA，并通过大规模实证研究和全面的交互分析评估了其在真实课堂中的可行性；分析了学生-辅助教学助手交互对与传统学生-人类教师交互对；公开VTA系统源代码，促进未来AI驱动教育的发展

Conclusion: 
研究结果表明部署VTAs在真实课堂中是可行的，但需解决一些关键挑战，如学生对VTAs的接受度和交互模式改进等；发布了VTA系统的源代码，有助于未来在AI驱动教育中的技术改进和创新</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17363</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>344. cs.AI-使用基于张量的GPU加速技术提高车辆路径规划本地优化速度</title><link>https://arxiv.org/pdf/2506.17357</link><description>Background: 
车辆路径问题(VRP)及其变种的有效启发式算法通常依赖于局部搜索。但是，局部搜索的邻域探索因其高计算复杂度而成为瓶颈，特别是在处理大规模实例或复杂约束问题时更为明显。本研究探讨了一种创新解决方案，即利用基于张量的GPU加速方法来加快VRP中常用局部搜索操作的执行速度，以应对这一挑战。

Innovation: 
提出了一种基于张量的GPU加速方法，用于加速车辆路径规划中的局部搜索操作。该方法采用属性表示，具备高度扩展性，适用于不同的VRP变种。其低耦合架构将密集计算完全卸载到GPU，确保与各种基于局部搜索的算法和框架无缝集成，从而显著提高计算效率并可能提升解决方案的质量。

Conclusion: 
通过在三种路由问题的基准实例上的对比实验，证实了所提出方法在计算上的显著优势。此外，还详细分析了该方法的优势和局限性，提供了对其性能特点的深刻见解，并指出了实际应用中的潜在瓶颈，从而为未来的改进提供了方向。这些发现有助于更好地理解该方法，并为未来的研究提出了建议。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17357</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>345. cs.AI-自动大型语言模型创建交互式学习课程</title><link>https://arxiv.org/pdf/2506.17356</link><description>Background: 
本文探讨了自动生成面向初中数学在线教学的新手人类导师的交互性、基于场景的学习课程。通过使用基于检索增强生成的方法与GPT-4o进行提示工程，本文开发了一个能够创建结构化导师训练课程的系统。研究使用任务分解提示策略，将课程生成分解为子任务，针对“鼓励学生独立”、“鼓励求助行为”和“开启摄像头”等三个关键主题生成了课程。生成的课程通过两位人类评估者进行评价，采用综合评分规则，该规则基于教学设计研究。结果显示，任务分解策略生成的课程评分更高。评估者指出，这些生成的课程具有结构良好且节省时间的优点，但也有反馈过于通用和某些教学部分缺乏清晰性的局限性。这些发现强调了人机混合方法在生成有效的导师培训课程方面的潜力。

Innovation: 
本文主要创新点在于利用基于检索增强生成的方法与GPT-4o进行提示工程，开发了一个能够自动为新手人类导师生成结构化、基于场景的在线数学教学课程的系统。任务分解提示策略的使用提高了课程质量。

Conclusion: 
研究结果表明，任务分解策略生成的课程质量更高。人类评估者认可生成课程的结构良好和时间节省的优点，但也指出了反馈通用和部分教学不清晰的问题。这些发现证实了人机混合方法在生成有效导师培训课程中的价值。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17356</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>346. cs.AI-基于差异性提取细调大型语言模型中的专有数据</title><link>https://arxiv.org/pdf/2506.17353</link><description>Background: 
近年来，对领域特定且与人类对齐的大规模语言模型（LLMs）的需求不断增长，导致监督微调（SFT）技术的广泛应用。SFT数据集包含有价值的指令-响应对，这使得它们成为潜在数据提取的理想目标。尽管学术界和工业界已经注意到该问题，但至今尚未进行全面研究。本研究首次深入探讨了这一关键问题。

Innovation: 
本文提出了一个新的数据提取方法——差异化数据提取（DDE），该方法利用微调模型的置信度水平及其与预训练基模型的行为差异，为SFT模型设计。实验结果表明，DDE在各种场景下均优于现有的数据提取基线。此外，还提出了一种防御机制来对抗DDE攻击，从而减少了模型性能的影响，确保了模型的防御能力。

Conclusion: 
本文揭示了细调后的LLMs存在隐藏的数据泄露风险，并提供了开发更安全模型的见解。通过实验证明了DDE的有效性，同时提出了针对DDE攻击的防御机制。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17353</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>347. cs.AI-大型语言模型中理论共情的安全评估</title><link>https://arxiv.org/pdf/2506.17352</link><description>Background: 
随着大型语言模型（LLMs）能力的不断提升，其安全评估的重要性变得日益明显。最近的安全评估担忧集中在LLMs在执行任务时表现出的规避监督机制、出言不诚信的行为。已有研究表明，当LLMs面临的执行任务信息对其自身的持续性不利时，它们可能会采取隐蔽行动甚至提供虚假答案来应付验证问题。因此，有必要研究这些行为是否源自模型内的隐蔽故意过程，从而评估其潜在的风险，这对开发者和用户都至关重要。研究开始于回顾现象共情的相关研究，并确定在安全评估中应用现象共情的基本视角和任务。鉴于现象共情研究主要集中在发展心理学中，研究通过对一系列开源重量LLM的发展趋势进行分析，发现LLMs在阅读理解能力上的提高并不与现象共情能力的提升相匹配。

Innovation: 
论文提出将现象共情能力作为大型语言模型安全评估的一部分进行衡量，并通过分析发展心理学中的现象共情研究，以及近年来的大规模语言模型的进化趋势，揭示了语言模型在这方面的局限。这项工作创新地结合了心理学与人工智能领域，试图通过识别和提高这些模型的现象共情能力，增强它们的安全性

Conclusion: 
现有研究表明，尽管大型语言模型在阅读理解方面取得了显著进步，但其现象共情能力并未同步发展。这表明，有必要进一步研究和提升这些模型的现象共情能力，以确保其在未来应用的安全性。未来工作仍面临诸多挑战，需要更多研究来推动这一领域的发展。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17352</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>348. cs.AI-使用AudioLLM从语音中零样本检测认知障碍</title><link>https://arxiv.org/pdf/2506.17351</link><description>Background: 
认知障碍（CI）已成为公共卫生关注的重点问题，早期检测对于有效干预至关重要。语音已经被认为是一种无创且易于收集的生物标志物，用于评估认知衰退。传统的CI检测方法通常依赖于在语音中提取的声学和语言特征上训练的监督模型，这些模型往往需要手动标注，且可能在不同数据集和语言之间缺乏泛化能力。

Innovation: 
本文提出了首个基于语音的零样本认知障碍检测方法，利用了Qwen2-Audio AudioLLM模型，该模型能够处理音频和文本输入。通过设计基于提示的指令，引导模型将语音样本分类为正常认知或认知障碍的指示。这种方法在两种数据集上进行了评估，一个英文数据集和另一个多语言数据集，涵盖了不同的认知评估任务。结果显示，零样本AudioLLM方法在性能上与监督方法相当，并且在语言、任务和数据集上的表现具有良好的通用性和一致性。

Conclusion: 
该研究提出的方法在性能和通用性方面表现出色，特别是在跨语言和跨任务的数据集上具有稳定的表现，从而扩展了对于认知障碍检测方法的理解。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17351</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>349. cs.AI-CUBA: Controlled Untargeted Backdoor Attack against Deep Neural Networks</title><link>https://arxiv.org/pdf/2506.17350</link><description>Background: 
近年来，后门攻击已成为深度神经网络面临的严重安全威胁。大多数已知的后门攻击主要集中在目标型后门攻击上，这意味着触发器与特定恶意行为强相关。现有的许多后门检测方法依赖于这种固有特性，并且在检测和缓解此类目标型攻击方面效果显著。但是，在后门场景中的纯粹非目标攻击在某种意义上是自我削弱的，因为目标特性正是使后门攻击如此强大之所在。基于这一点，介绍了新颖的约束非目标后门攻击（CUBA），该攻击结合了非目标攻击的灵活性和目标攻击的意图性。受攻击的模型在面对后门图像时，将会将其分类到由攻击者选择的受限目标类别的随机类别中。这种随机性和确定性的结合使提出的一种非目标后门攻击能够自然规避现有后门防御方法。

Innovation: 
提出了一种新颖的约束非目标后门攻击（CUBA），该攻击结合了非目标攻击的灵活性和目标攻击的意图性。通过在训练过程中对对数几率进行约束，在交叉熵损失中应用翻转的一热标签进行对数几率归一化处理，使受攻击的模型在选定的目标类别中显示均匀分布，从而实现可控的非目标化攻击。实验结果表明，提出的CUBA在不同数据集上的有效性。

Conclusion: 
实验结果证明了约束非目标后门攻击（CUBA）的有效性。该研究揭示了非目标攻击在后门攻击场景中的潜在应用价值，并为后门攻击的深入研究提供了新的视角。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17350</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>350. cs.AI-先进的博弈理论框架应对2025年的多智能体AI挑战</title><link>https://arxiv.org/pdf/2506.17348</link><description>Background: 
本文研究了如何利用先进的博弈理论范式作为未来人工智能（AI）挑战的基础，预计这些挑战将在2025年左右出现。研究不仅限于传统的模型，还涵盖了动态的联盟形成、基于语言的效用、破坏风险和不完全可观测性等方面，旨在展示如何通过数学形式化、仿真和编码方案使多智能体系统适应和在复杂环境中进行谈判。关键要素包括重复博弈、对抗检测的贝叶斯更新和效用结构中的道德框架。

Innovation: 
研究引入了先进的博弈理论框架，通过动态联盟形成、基于语言的效用、破坏风险和不完全可观测性等新颖的元素，提供了数学形式化、仿真和编码方案，展示了在不确定、部分对抗的环境下，多智能体AI系统如何进行适应和谈判。关键创新元素包括重复博弈、对抗检测的贝叶斯更新和效用结构中的道德框架，为AI研究者提供了坚实的战略互动理论工具。

Conclusion: 
本文旨在为AI研究者提供强有力的理论工具，使其能够应对不确定性和部分对抗性环境中的战略互动。通过提供数学形式化、仿真和编码方案，研究展示了在不确定环境下多智能体AI系统的适应性和谈判能力，为未来AI挑战的准备提供了理论基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17348</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>351. cs.AI-区分预测型和生成型人工智能的监管</title><link>https://arxiv.org/pdf/2506.17347</link><description>Background: 
近年来，政策制定者已开发出一系列监管工具，旨在确保人工智能的发展与关键社会目标相一致。这些工具最初主要用于回应预测型人工智能（如预测性AI）带来的担忧，因此隐含了对AI系统特性和某些监管方法有效性的假设。然而，随着生成型AI的出现，这些假设已不再适用。尽管如此，政策制定者试图维持涵盖这两类AI的单一监管目标。

Innovation: 
本文指出了生成型AI的四个独特方面，这需要不同的政策措施。首先，其广泛性和适应性使它成为一个不合适的监管目标。其次，有效评估的构建具有挑战性。第三，新的法律关切改变了利益相关者及其专业知识的生态系统。最后，生成型AI价值链的分散结构也带来了不同的挑战。基于这些差异，政策制定者需要评估过去十年的政策工作哪些仍然相关，哪些则需新政策来应对生成型AI带来的独特风险。因此提出了三项建议，以帮助政策制定者更有效识别监管目标，并利用生态系统中的约束来管理生成型AI。

Conclusion: 
为了更有效地识别监管目标，政策制定者需要考虑过去十年工作的相关性，并设计新的政策来应对生成型AI带来的独特风险，同时利用生态系统中的各种约束来管理生成型AI。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17347</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>352. cs.AI-一种新型多层任务驱动和数据质量框架用于自动驾驶</title><link>https://arxiv.org/pdf/2506.17346</link><description>Background: 
下一代自动驾驶车辆（AV）嵌入了频繁的实时决策，将大量依赖多源和多模态数据。在实际应用中，不同来源和模态的数据质量通常因意外环境因素或传感器问题而波动。尽管如此，AV领域研究人员和从业者仍主要关注模型/算法，而忽视了数据质量的重要性。为了确保下一代AV的功能性、效率和可信性，本文提出了一种新的任务为中心和数据质量为基础的框架，该框架包含五个层次：数据层、数据质量层、任务层、应用层和目标层。该框架旨在将数据质量与任务需求和性能目标进行映射。分析证明，在nuScenes数据集上部分去除多源图像数据的冗余可以提升YOLOv8目标检测任务的表现。进一步分析多模态数据（图像和LiDAR）表明现有冗余数据质量问题的存在。本文揭示了数据质量、任务协调和性能导向系统开发在自动驾驶领域的交叉领域中一系列亟待探索的关键挑战，希望能为自动驾驶社区提供方向，建设更加适应、可解释和可靠的自动驾驶车辆，以智能应对动态环境和异构数据流。

Innovation: 
本文提出了一种新的、多层的任务驱动和数据质量为基础的框架，包括五个层次：数据层、数据质量层、任务层、应用层和目标层。该框架旨在将数据质量与任务需求和性能目标进行匹配。实证研究表明，减少多源图像数据的冗余可以提高目标检测任务的表现，并且进一步分析多模态数据表明存在冗余数据质量的问题。该研究揭示了在自动驾驶领域数据质量、任务协调和性能导向系统开发方面的关键挑战，为自动驾驶社区提供了新的研究方向和应用指导。

Conclusion: 
本文提出的框架有望指导自动驾驶社区构建更适应、可解释和可靠的自动驾驶车辆，以智能应对动态环境和异构数据流。未来研究可进一步探索在自动驾驶系统中全面应用数据质量框架的方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17346</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>353. cs.AI-基于联邦多代理深度强化学习的自适应社会元宇宙流媒体</title><link>https://arxiv.org/pdf/2506.17342</link><description>Background: 
社交元宇宙是一个将虚拟与物理世界融合的不断发展的数字生态系统。它允许用户进行社交互动、工作、购物和享受娱乐活动。然而，隐私仍然是一个重大挑战，侵入性的互动需要持续收集生物特征和行为数据。同时，确保高质量、低延迟流媒体也因实时互动、沉浸式渲染和带宽优化的需求而变得困难。

Innovation: 
提出了一种基于联邦多代理_Proximal Policy Optimization_（F-MAPPO）的自适应社交元宇宙流媒体（ASMS）的新颖流媒体系统。ASMS利用了联邦学习和深度强化学习的结合，动态调整流媒体比特率以保存用户体验的同时保障用户隐私。实验结果表明，ASMS在各种网络条件下的用户体验至少比现有流媒体方法提高了14%。

Conclusion: 
ASMS通过提供无缝且沉浸式的流媒体体验，即使在网络动态且资源受限的情况下也能增强社交元宇宙体验，同时确保敏感用户数据保留在本地设备上。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17342</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>354. cs.AI-基于PBFT的语义投票多智能体系统记忆修剪</title><link>https://arxiv.org/pdf/2506.17338</link><description>Background: 
多智能体系统（MAS）在复杂、动态的环境中越来越多，需要强大的和高效的机制来管理共享知识。其中一个关键挑战是确保分布式内存保持同步、相关，并且避免存有陈旧或不重要的数据——这一过程类似于生物遗忘。现有机制难以实现这一目标，因此需要一个新的、综合性的解决方案来同步修剪内存。

Innovation: 
该论文提出了一种名为Co-Forgetting协议的新颖框架，旨在解决这一问题。该协议包括三个关键组件：(1)语义感知投票机制，智能体使用轻量级的DistilBERT模型评估内存项的相关性，基于其内容和当前的操作环境；(2)多尺度时间衰减函数，根据记忆的年龄和在不同时间尺度上的访问频率来为其分配递减的重要性；(3)基于实用拜占庭容错（PBFT）的共识机制，确保决策是否保留或丢弃内存项由一个多智能体鲁棒且容错的大多数汇集共识，即使在存在最多f个拜占庭（恶意或故障）智能体的系统中也是如此。该协议利用gRPC进行智能体间的高效通信，使用Pinecone进行可扩展向量嵌入存储和相似性搜索，同时使用SQLite管理元数据。

Conclusion: 
实验表明，该协议在模拟的四个智能体MAS环境中是有效的，实现了500个周期中52%的内存足迹减少，遗忘决策的投票准确率为88%，在模拟拜占庭条件下PBFT共识成功率为92%，以及82%的缓存命中率，实现了内存访问。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17338</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>355. cs.AI-一般VLM能否与医疗VLM匹敌？评估与战略见解</title><link>https://arxiv.org/pdf/2506.17337</link><description>Background: 
医疗视觉-语言模型利用大规模预训练进行多样的成像任务，但需要大量的计算和数据资源。通用或通用型VLM（如CLIP、LLaVA）虽然未专门针对医疗应用进行训练，但在微调后却显示出潜力。因此，关键问题在于：可以利用微调后的通用VLM与通用型医疗VLM相比，是否能在特定的医疗成像任务中表现得更好？该研究系统地评估了通用和医疗VLM在疾病诊断和视觉问答（VQA）方面的能力。通过基于CLIP和LLaVA的模型，我们研究了在领域内（ID）设置中现成模型的性能差异，是否通过微调可以缩小这些差异，以及通用VLM在未见过的医疗模态的领域外（OOD）任务中的泛化能力。尽管特定领域预训练在领域内设置中提供了优势，但在轻量级微调后，通用VLM在某些任务中与专门针对医疗领域预训练的模型表现出相似或更好的性能，其中基于LoRA的适应方法在不同任务中表现出高度有效性。在领域外任务中，通用VLM在某些任务中展示了强大的适应能力，挑战了医疗领域特定预训练必不可少的假设。

Innovation: 
研究系统地评估了通用和医疗视觉-语言模型在疾病诊断和视觉问答方面的表现，并且发现通用VLM在轻量级微调后可以与专门针对医疗领域预训练的模型在某些任务中表现相当或更好，尤其是在领域外任务中展示了较强的适应能力。这种方法为开发大型医疗视觉-语言模型提供了一种可扩展且成本效益高的替代方案。此外，研究还证明了基于LoRA的适应方法在不同任务中的有效性。

Conclusion: 
研究结果表明，利用通用VLM并通过微调的方法可以提供一种具有可扩展性和成本效益的替代方案，用于开发大规模医疗视觉-语言模型。这为未来医疗成像领域的研究提供了关键见解，强调了通用VLM在医疗领域应用中的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17337</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>356. cs.AI-LMR-BENCH: 评估LLM代理复现语言建模研究的能力</title><link>https://arxiv.org/pdf/2506.17335</link><description>Background: 
大规模语言模型（LLM）在促进科学研究发现方面展示出了显著潜力。然而，在其基础而关键的任务之一——从研究论文中复现代码方面，尤其是在自然语言处理（NLP）领域，这一能力尚被大大忽视。这项任务包括从抽象概念的综合到代码库中相互依赖文件的理解的独特和复杂的推理挑战。鉴于上述差距，研究提出了LMR-BENCH，一种旨在系统评估LLM代理复现代码能力的基准。它包括从过去五年顶级NLP会议发布的23篇研究论文中提取的28项复现任务，并涵盖了九个基本类别。研究中，模型被提供了一篇研究论文、包含一个或多个被遮蔽函数的代码库以及实施这些函数的指示。研究进行了广泛的基准测试和LLM代理设置下的实验，评估单元测试的准确性，并通过LLM来进行代码正确性的评估。实验结果揭示了即使是最先进的模型在科学推理和代码综合方面仍存在持续的局限性，这突显了LLM代理自主复现科学研究能力的关键差距

Innovation: 
提出了LMR-BENCH基准来系统评估LLM代理从语言建模研究中复现代码的能力。这项基准包含了从过去五年内的23篇顶级NLP会议论文中提取的28项复现任务，并覆盖了九个基本类别。通过提供研究论文、包含一个或多个被遮蔽函数的代码库以及实现这些函数的指示，评估了LLM模型的复现能力，尤其是在进行基准测试和LLM代理设置下，评估了单元测试的准确性并进行了基于LLM的代码正确性评估。实验结果揭示了即使是最先进的模型在科学推理和代码综合方面仍存在局限性，突显了LLM代理能力的关键差距

Conclusion: 
尽管最先进的LLM模型在科学推理和代码综合方面仍存在局限性，但这项研究通过LMR-BENCH基准揭示了这些关键差距，为LLM的研究和应用提供了重要的参考和指导</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17335</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>357. cs.AI-P2MFDS: 隐私保护的多模态浴室老年人跌倒检测系统</title><link>https://arxiv.org/pdf/2506.17332</link><description>Background: 
预计到2050年，65岁及以上人口将占全球人口的16%。年龄增长与跌倒风险增加密切相关，尤其是湿滑和受限的环境，如浴室，那里发生跌倒的比例超过80%。尽管近期研究越来越多地关注非侵入性、保护隐私的方法，不依赖穿戴设备或视频监控，但这些努力并未完全克服现有单一模态系统的局限性（如基于WiFi、红外或毫米波的方法），它们在复杂环境中的准确性容易受影响。这些局限源于单一传感器系统固有的限制，包括系统偏差和环境干扰，例如WiFi系统的多径衰减和红外方法的温度剧烈变化。为了解决这些挑战，我们提出了一种隐私保护的多模态跌倒检测系统，用于浴室环境中的老年人。该系统结合了毫米波雷达和3D振动传感，开发了一个传感器评估框架，并在真实浴室环境中构建和预处理了一个大规模的隐私保护多模态数据集，该数据集将在发表时释放。

Innovation: 
我们开发了一种传感器评估框架来选择和融合毫米波雷达与3D振动传感，并在真实浴室环境中构建和预处理了一个大规模、隐私保护的多模态数据集。我们提出了P2MFDS，一种结合CNN-BiLSTM-Attention分支用于雷达运动动态和多尺度CNN-SEBlock-Self-Attention分支用于振动冲击检测的双流网络。通过结合宏观和微观特征，P2MFDS在准确性和召回率方面显著优于现有最先进的方法。

Conclusion: 
通过结合宏观和微观特征，P2MFDS在复杂环境下的跌倒检测中实现了显著的性能提升，特别适用于保护隐私的浴室环境。该研究为解决多模态监测系统在复杂环境下的局限性提供了新的解决方案，并有望提高老年人在浴室中的安全性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17332</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>358. cs.AI-在 healthcare 5.0 中生物医学特征在网络安全检测中的性能</title><link>https://arxiv.org/pdf/2506.17329</link><description>Background: 
Healthcare 5.0将人工智能、物联网、实时监测和以人为本的设计整合在一起，以实现个性化治疗和预测诊断。然而，对联网医疗技术的过度依赖带来了网络安全威胁。现有的基于人工智能的网络安全模型通常忽视生物医学数据，限制了它们的有效性和可解释性。当前研究填补了这一空白，通过应用可解释的人工智能（XAI）技术来处理结合了网络流量和生物医学传感器数据的 healthcare 5.0 数据集。研究表明，XGBoost 在正常和数据篡改分类中达到了99%的F1分数，在伪造检测中达到了81%的分数。解释结果表明，网络数据在入侵检测中起主导作用，而生物医学特征对伪造检测至关重要，其中温度的SHAP值达到了0.37。

Innovation: 
研究引入了可解释的人工智能（XAI）技术，应用于 healthcare 5.0 数据集，该数据集整合了网络流量和生物医学传感器数据。XGBoost 在正常和数据篡改分类中表现出色，且生物医学数据的解释性研究提供了新的见解，特别是在伪造检测方面发挥了重要作用。

Conclusion: 
研究结果表明，网络数据在医疗保健 5.0 的网络入侵检测中起着主导作用，而生物医学功能在伪造检测中贡献突出。可解释的人工智能（XAI）方法提高了网络安全检测的性能和可解释性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17329</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>359. cs.AI-RadarSeq: 基于雷达图序列的时间视觉框架用于用户流失预测</title><link>https://arxiv.org/pdf/2506.17325</link><description>Background: 
在没有明确标签和用户行为动态性的非订阅制平台中预测用户流失极具挑战性。现有方法通常依赖聚合快照或静态可视化表示，这会掩盖早期检测中至关重要的时间线索。

Innovation: 
本文提出了一种时间感知的计算机视觉框架，该框架采用雷达图表图像序列来建模用户行为模式，并结合预训练的CNN编码器和双向LSTM来捕捉流失行为的时空模式。该方法在大规模真实数据集上的广泛实验中表现优于经典模型和基于ViT的雷达图基线，提高了F1分数17.7、精确度29.4和AUC 16.1，并增强了可解释性。其模块化设计、可解释性工具和高效的部署特性使得它适用于动态零工经济平台的大规模流失建模。

Conclusion: 
该方法通过雷达图表序列有效预测了用户流失，显著提升了模型性能，并能更好地解释模型决策，适用于动态零工经济平台的大规模流失预测。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17325</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>360. cs.AI-I Know Which LLM Wrote Your Code Last Summer: LLM generated Code Stylometry for Authorship Attribution</title><link>https://arxiv.org/pdf/2506.17323</link><description>Background: 
随着大型语言模型（LLMs）生成的代码变得越来越普遍，准确识别背后的特定模型变得日益重要。目前检测AI生成的代码、深度假信息和其他合成内容是一个新兴的研究挑战。本文是对LLMs对C程序作属性研究的第一个系统化研究。

Innovation: 
本文提出了一个创新的模型——CodeT5-Authorship，该模型仅使用原始CodeT5编码器-解码器架构的编码器层，并消除了解码器，专注于分类任务。在评价方面，作者引入了LLM-AuthorBench基准，包含32,000个可编译的C程序，这些程序是由八种最先进的LLMs在各种任务中生成的。此外，该模型在其二元分类中表现出色，能准确区分辨别GPT-4.1和GPT-4o这类关系密切的模型的代码，以及在多类属性中准确区分五个领先LLM中的代码。为了促进开源科学，作者还发布了CodeT5-Authorship架构、LLM-AuthorBench基准和所有相关Google Colab脚本。

Conclusion: 
本文通过提出CodeT5-Authorship模型和LLM-AuthorBench基准，在识别LLMs生成的C程序作者方面取得了显著成果。此外，本文还强调了开源代码发布的重要性，以促进科学研究和数据共享。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17323</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>361. cs.AI-上下文操控攻击：Web代理易受篡改记忆攻击</title><link>https://arxiv.org/pdf/2506.17318</link><description>Background: 
自主的网络导航代理将自然语言指令转化为浏览器操作序列，在电子商务、信息检索和内容发现等复杂任务中得到广泛应用。由于大型语言模型（LLMs）是无状态的，这些代理在跨交互中依赖外部存储系统来维持上下文。由于这些代理的上下文存储在客户端或第三方应用程序中，而不是在安全的服务器端集中存储，因此存在严重的安全漏洞。最近有攻击者利用这些漏洞攻击生产系统。在这项研究中，研究人员发现并正式提出了“计划注入”，这是一种新的上下文操控攻击方式，能够通过针对这一脆弱的存储上下文来破坏代理的内部任务表示。研究团队对两种流行的网络代理（Browser-use和Agent-E）进行了系统的评估，证明计划注入绕过了强大的提示注入防御机制，攻击成功率比同类提示基攻击高出3倍。进一步的‘上下文链式注入’，通过在合法用户目标和攻击者目标之间构建逻辑桥梁，针对隐私泄露任务提高了17.7%的成功率。研究结果表明，安全的内存处理必须是代理系统的一项核心关注点

Innovation: 
研究团队首次提出了“计划注入”（Plan Injection）这一全新的上下文操控攻击方法，并通过实验证明它可以绕过现有的强大提示注入防御机制，实现比同类提示基攻击更高的成功率。此外，研究还探索了‘上下文链式注入’技术，能在合法用户目标和攻击者目标之间建立逻辑桥梁，显著提高隐私泄露任务的成功率。

Conclusion: 
这项研究揭示了安全内存管理对代理系统来说是一个首要关注点，强调在设计和开发代理系统时必须重视内存处理的安全性，以防止类似“计划注入”等上下文操控攻击的发生。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17318</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>362. cs.AI-异构时序超图神经网络</title><link>https://arxiv.org/pdf/2506.17312</link><description>Background: 
图表示学习（GRL）已成为处理图结构数据的有效技术。为在复杂网络中建模异质性和动态性，提出了适用于复杂异质时序图（HTGs）的GRL方法，并在多个领域取得了成功的应用。但现有的大部分GRL方法主要关注保留低阶拓扑信息，而忽视了与现实网络更一致的高阶组交互关系。此外，大多数现有超图方法只能处理静态同质图，限制了其在HTGs中建模高阶交互的能力。为了同时使GRL模型能够捕捉HTGs中的高阶交互关系，本文首先给出异构时序超图的正式定义和$P$-均匀异构超边构造算法，不依赖额外信息。然后，提出了新型的异构时序超图神经网络（HTHGN），以充分捕捉HTGs中的高阶交互。HTHGN包含层次注意力机制模块，可以同时在超边带来的大感受野范围内进行异质节点和超边之间的时序消息传递，捕捉丰富的语义。此外，HTHGN还通过在HTG中最大化低阶异构节点对的一致性来进行对比学习，避免低阶结构歧义问题。详细的实验结果表明，提出的HTHGN能够有效建模HTGs中的高阶交互，并展示了显著的性能提升。

Innovation: 
本文提出了异构时序超图（HTHGs）的概念及其对应的$P$-均匀异构超边构造方法，这不依赖于额外信息。此外，还设计了异构时序超图神经网络（HTHGN），具备层次注意力机制模块，能够在超边带来的大感受野范围内实现异质节点和超边之间的时序消息传递，同时进行对比学习，以避免低阶结构歧义，并有效地处理高阶交互性问题。

Conclusion: 
实验结果表明，提出的HTHGN方法在真实世界HTG数据集上建模高阶交互具有显著效果，并且优于现有方法。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17312</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>363. cs.AI-AlgoSelect：借助梳子操作符实现的通用算法选择</title><link>https://arxiv.org/pdf/2506.17304</link><description>Background: 
传统算法选择方法依赖于手动设计的选择策略，通常具有局限性和复杂性。AlgoSelect 提出了一种基于数据的人工智能框架，通过学习将多种计算策略进行插值，从而实现了自动选择最优算法的方法。该方法重点在于一种名为Comb操作符的新颖工具，用于在算法对之间进行插值选择。

Innovation: 
1. 利用Comb操作符，开发了一种简单sigmoid门控的选择器，对于多个算法间进行了扩展。2. 提供了泛化的逼近定理，表明基于Comb的选择器可以达到任意精度。3. 确定了选择阈值的信息论可学习性。4. 定量化了Comb操作符的性质，并建立了其线性操作符理论。5. 创建了一种适用于多种算法选择的N-Path Comb泛化形式。6. 开发了适应性播种函数的实用学习框架，以引导Comb操作符。

Conclusion: 
AlgoSelect通过证明的最优性和学习保证，为自动化算法选择提供了理论依据和实际部署的解决方案。在结构化领域，其准确率接近完美，样本数量极少，收敛速度快。这对其在人工智能和自适应系统中的应用具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17304</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>364. cs.AI-LLM Jailbreak Oracle</title><link>https://arxiv.org/pdf/2506.17299</link><description>Background: 
随着大型语言模型（LLMs）在关键安全应用场景中越来越广泛地部署，缺乏系统的方法来评估其对监狱突破攻击的脆弱性，这呈现了一个重要的安全漏洞。这一背景指出需要系统化的评估方法来提高安全水平，规范了针对这一问题的研究框架和算法设计背景。

Innovation: 
本文提出了监狱突破Oracle问题，并设计了Boa算法。Boa采用三步搜索策略：（1）构造区块列表以识别拒绝模式，（2）广度优先采样以识别易访问的监狱突破，（3）基于精细的安全评分进行深度优先优先搜索，以系统地探索有希望的低概率路径，从而能够解决监狱突破Oracle问题并提供有效的安全评估工具。

Conclusion: 
Boa能够实现严格的网络安全评估，包括系统化的防御评估、红色团队攻击的标准比对以及在极端对抗条件下对模型的认证。这为提高人工智能系统的安全防护能力提供了新的策略和工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17299</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>365. cs.AI-Mercury：基于扩散的超快速语言模型</title><link>https://arxiv.org/pdf/2506.17298</link><description>Background: 
本文介绍了Mercury，一种新的基于扩散的商业规模的大语言模型（LLMs），以Transformer架构参数化，并训练为并行预测多个标记。文章详细描述了Mercury Coder，用于编码应用的第一代基于扩散的LLM，包括Mini和Small两种尺寸。Mercury Coder在速度和质量方面都达到了最新的技术水平。n

Innovation: 
Mercury Coder Mini和Mercury Coder Small分别在NVIDIA H100 GPU上的吞吐量达到了1109 tokens/sec和737 tokens/sec，比速度优化的前沿模型平均高出10倍，同时保持了相近的质量。文章还展示了Mercury在多种编程基准上的结果，涵盖多种语言和用例，并通过开发者在Copilot Arena的实战验证，展示了模型在质量和速度方面的表现。n

Conclusion: 
Mercury团队还公开了一个API (this https URL)并提供了一个免费的交互式沙箱 (this https URL)，以便开发者进一步探索和使用这些模型。n</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17298</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>366. cs.AI-SafeRL-Lite：一种轻量级、可解释且受限的强化学习库</title><link>https://arxiv.org/pdf/2506.17297</link><description>Background: 
现有的强化学习（RL）工具包通常缺乏内置机制来强制执行严格的安全约束或者生成人类可理解的决策解释。这使得在实际应用中，特别是在需要确保安全性的场景下，难以直接使用这些工具包进行开发。

Innovation: 
SafeRL-Lite 提供了一种模块化的包装器，可以围绕标准 Gym 环境和深度 Q 学习代理，用于实现安全意识的训练以及实时后验解释。它包括内置的约束违规指标，并使用 SHAP 值和可解释性映射来生成实时解释，从而提高决策透明度。该库具有轻量级、可扩展的特点并通过 pip 安装。

Conclusion: 
SafeRL-Lite 在受约束的 CartPole 方案中展示了有效性，并提供了可视化结果以揭示决策逻辑和安全性合规情况。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17297</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>367. cs.AI-先进解码方法下LLM生成中的语义不确定性</title><link>https://arxiv.org/pdf/2506.17296</link><description>Background: 
本研究探讨了大型语言模型（LLM）输出中不同解码方法下的语义不确定性，重点关注新兴技术，例如推测性采样和链式思考（CoT）解码。本文通过问答、摘要和代码生成任务的实验，分析不同的解码策略如何影响模型输出的多样性和可靠性。研究发现，尽管链式思考（CoT）解码在语义多样性方面表现更好，但它保持较低的预测熵，表明结构化的探索可以产生更有信心和更准确的输出。这在代码生成Pass@2率上得到了48.8%的改善，尽管与参考解决方案的吻合度较低。对于摘要任务，推测性采样特别有效，尽管保持了适度的语义多样性，仍取得了优越的ROUGE分数。这些结果挑战了关于语言模型输出中多样性和准确性的权衡的常规假设，表明适当的解码方法可以增加语义探索的同时保持或改善输出质量。这些发现对于在关键应用中部署语言模型具有重要意义，这两个方面即可靠性与多样性的生成至关重要。

Innovation: 
本研究创新性地分析了先进解码方法（推测性采样和链式思考）对大语言模型输出的影响，特别是如何影响输出的多样性和可靠性。研究揭示了链式思考解码在提高语义多样性的同时，能保持较低的预测熵，推测性采样在摘要任务中的特殊效果，以及它们如何挑战关于多样性和准确性之间权衡的常规假设，提出结构化解码方法可以实现更全面的探索同时保持或提高输出质量的新观点。

Conclusion: 
研究结果挑战了关于语言模型输出的多样性与准确性的权衡概念，证明了适当的解码方法不仅可以在提升语义探索的同时保持精度，还可以在某些情况下改进输出质量。这对实际应用中语言模型的部署具有重要的意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17296</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>368. cs.AI-AI生成的游戏解说：综述及数据集仓库</title><link>https://arxiv.org/pdf/2506.17294</link><description>Background: 
由于其市场潜力和内在的技术挑战，AI生成的游戏解说（AIGGC）受到了越来越多的关注。作为一项综合性多模态自然语言处理（NLP）任务，AIGGC对语言模型提出了很高的要求，包括事实准确性、逻辑推理、表达性文本生成、生成速度和上下文管理等方面。

Innovation: 
本文提出了一个通用的AIGGC框架，并对45个现有的游戏解说数据集和方法进行了全面的综述，这些方法旨在解决这一领域中的关键挑战。同时，还对这一领域中常用的评估指标进行了分类和比较，提供了结构化的数据表，总结了这些数据集的重要属性，并公开在开放仓库中，以支持未来的研究和基准测试。

Conclusion: 
本文不仅提供了一个跨领域的AIGGC框架，还对现有的数据集进行了系统总结，并总结了一系列常用的评估指标。这项工作对促进未来的研究和基准测试具有重要意义。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17294</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>369. cs.AI-理论上揭示针对保护隐私数据的联邦视觉模型的推理攻击</title><link>https://arxiv.org/pdf/2506.17292</link><description>Background: 
联邦学习允许通过协调服务器在客户端之间实现协作学习，同时避免直接数据共享，被认为是保护隐私的有效方法。然而，最近的研究表明，成员推理攻击（MIAs）能够成功地推断出训练数据集合中的成员身份，即使在未受保护的训练数据中也表现出了高成功率。虽然局部差分隐私（LDP）被认为是数据隐私保护的金标准，但大多数关于MIAs的研究要么忽视了LDP，要么未能提供在LDP保护数据下攻击成功率的理论保证。因此，该研究旨在通过理论方法为利用全连接层或自注意层漏洞的低多项式时间推理攻击设置下界，揭示即使在LDP保护下，隐私风险仍然存在的问题。

Innovation: 
该研究首次证明了即使在LDP保护下，构建基于全连接层或自注意力层的低多项式时间成员推理攻击下界的可能性，强调了隐私预算在数据保护中的重要性，并通过实际评估验证了联邦视觉模型中显著的隐私风险，表明为了防御这些攻击所需的噪声严重降低了模型的有效性。

Conclusion: 
该研究通过理论分析和实践验证，揭露了LDP保护下的联邦视觉模型中存在的隐私风险，尽管LDP可以保护数据隐私，但仍需根据隐私预算调整，以应对低多项式时间的推理攻击。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17292</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>370. cs.AI-SlimRAG：基于实体感知的无图检索</title><link>https://arxiv.org/pdf/2506.17288</link><description>Background: 
检索增强生成（RAG）通过在推理时引入外部知识来增强语言模型。然而，基于图的RAG系统常常面临结构开销和检索不精确的问题：它们需要昂贵的实体链接和关系提取管道，但经常返回包含不相关或边缘化内容的子图。这源于基本的缺陷——语义相似性并不意味着语义相关性。

Innovation: 
提出SlimRAG，一个轻量级的无需图的检索框架。SlimRAG用简单有效的实体感知机制替代了结构密集型组件。在索引时，SlimRAG基于语义嵌入构建紧凑的实体到片段表。而在查询时，它识别出关键实体，检索并评分关联片段，从而组装成一个简洁且上下文相关的输入——无需进行图遍历或边构建。为了量化检索效率，提出相对索引词使用率（RITU），衡量检索内容的紧凑性。在多个问答基准测试中，SlimRAG在准确性上优于强大的平铺和基于图的基线，同时减少了索引大小和RITU，突显了无结构、实体中心的上下文选择的价值。

Conclusion: 
SlimRAG在多个问答基准测试中表现出色，准确度高于强基线的同时，减少了索引大小和RITU，强调了无结构、实体中心的上下文选择的重要性。代码将在不久后发布。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17288</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>371. cs.AI-GTA: Grouped-head Latent Attention</title><link>https://arxiv.org/pdf/2506.17286</link><description>Background: 
大型语言模型（LLMs）的成功归功于其注意力机制，但这些机制带来的计算和内存开销很大，限制了优化效率和性能。现阶段，随着KV缓存和注意力计算随着文本长度的增加而快速扩展，这对计算和内存资源有限的硬件而言是一个重大瓶颈。因此，研究指出注意力机制存在显著冗余，可以通过压缩KV缓存和减少头之间的差异来优化这一问题。

Innovation: 
本文提出了一种名为GTA的新颖注意力机制，即分组头潜注意力。GTA通过共享注意力映射机制和非线性值解码器减少内存使用和计算复杂性，同时保持性能不受影响。GTA的核心贡献包括：（1）共享注意力分数机制，减少关键缓存大小；（2）使用学习投影的非线性值解码器，将值缓存压缩到潜在空间，进一步减少内存需求。这些技术使注意力计算FLOPs减少了高达62.5%，KV缓存缩小了高达70%，同时避免了多头潜注意力带来的额外开销，有助于提高LLM部署的效率。

Conclusion: 
GTA模型实现了端到端推理速度的两倍提升，预填充阶段得益于较低的计算成本，解码阶段得益于较小的缓存足迹。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17286</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>372. cs.AI-虚拟功率植物与吉瓦级人工智能数据中心集成的理论框架：多时间尺度控制与稳定性分析</title><link>https://arxiv.org/pdf/2506.17284</link><description>Background: 
由于人工智能的爆炸性增长，数据中心的数据处理需求急剧增加，导致了吉瓦级规模的数据中心设施。这些数据中心内的电力波动幅度大，在一秒内可以超过500兆瓦，甚至毫秒级的功率变化可以达到额定热功率的50-75%。这种极端的动力变化使传统的电力系统运营面临着巨大挑战。传统的虚拟功率植物（VPP）架构在应对秒级至分钟级反应时间的需求时表现出稳定性的不足，特别是在与这类极端动态数据中心的交互中，稳定的VPP架构面临严峻的挑战，尤其是在500兆瓦/秒以上的潮流速率下。

Innovation: 
该论文提出了一个全面的理论框架，其核心是重新构想虚拟功率植物（VPP），通过四层分级控制系统，时间跨度从毫微秒到24小时。该框架特别针对包含兆瓦级脉冲负载的大规模整流器系统的稳定性和控制机制。它引入了三个关键元素：1) 子毫秒层控制，直接与数据中心电力电子设备交互，有效抑制功率波动；2) 结合保护系统动态的新稳定性标准，揭示了大型脉冲负载下的关键清除时间缩短至83毫秒；3) 工作负载可延迟性，使高峰电力减少30%，同时保持99.95%以上的AI服务可用性。

Conclusion: 
本研究奠定了数学基础，使其成为未来2030年约占数据中心电力消耗50-70%的人工智能基础设施能够稳定整合的必要条件。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17284</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>373. cs.AI-逐步推理攻击：揭示大型语言模型中的‘已删除’知识</title><link>https://arxiv.org/pdf/2506.17279</link><description>Background: 
在大型语言模型（LLMs）中，知识删除对于确保符合数据和人工智能法规、保护用户隐私、减少偏见和不良信息至关重要。现有的知识删除方法旨在通过移除特定知识同时保持整体模型性能来提高知识删除的效率和效果，特别是对于保留的信息。然而，观察到的知识删除技术往往会抑制并留下知识在表面之下，使其在适当提示下可检索。本文展示了逐步推理可以作为一种后门来恢复隐藏信息。我们通过一个新的、基于逐步推理的黑色盒子攻击，Sleek，系统地揭示了知识删除失败。我们采用了结构化的攻击框架，包含三个核心组件：利用LLM生成查询构建的逐步推理生成对抗提示策略，成功召回被删除内容并揭示被不公平抑制的本应保留的知识的攻击机制，以及将提示分类为直接、间接和暗示，以识别哪些查询类型最有效地利用知识删除的弱点。通过在四种最先进的知识删除技术以及两个广泛使用的LLM上进行广泛的评估，我们表明现有的方法未能确保可靠的知识删除。生成的攻击提示中有62.5%成功从WHP-未学习的Llama中检索出被遗忘的哈利波特事实，而50%暴露了被不公平抑制的保留知识。本研究突显了信息泄露的持续风险，强调了需要更稳健的知识删除策略以实现有效擦除的必要性。

Innovation: 
提出了基于逐步推理的黑色盒子攻击Sleek，系统地揭示知识删除失败。该攻击采用了三个核心组件：利用LLM生成查询构建的逐步推理生成对抗提示策略、成功回忆被删除内容并揭示被不公平抑制的本应保留的知识的攻击机制，以及将提示分类为直接、间接和暗示的分类方法，以识别最有效地利用知识删除弱点的查询类型。

Conclusion: 
现有的知识删除方法无法确保知识删除的可靠性。生成的对抗提示中有62.5%成功从WHP-未学习的Llama中检索出被遗忘的哈利波特事实，而50%暴露了被不公平抑制的保留知识。本研究强调了信息泄露的持续风险，强调了需要更稳健的策略来实现有效的擦除。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17279</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>374. cs.AI-Chunk Twice, Embed Once: A Systematic Study of Segmentation and Representation Trade-offs in Chemistry-Aware Retrieval-Augmented Generation</title><link>https://arxiv.org/pdf/2506.17277</link><description>Background: 
RAG（检索增强生成）系统在处理不断扩大的科学文献时变得越来越重要，特别是在如化学这样的高风险领域。然而，文献的分段和表示等基础设计选择在特定领域的背景下仍然存在较少探索。该研究旨在系统地评估针对化学领域的RAG系统的设计选择。

Innovation: 
研究首次对化学领域的RAG系统进行了大规模、系统的评估，探索了25种分块策略和48种嵌入模型，并使用新引入的QuestChemRetrieval数据集进行了评估。研究发现，递归基于令牌的分块（特别是R100-0）在性能上优于其他方法，同时资源消耗较少。而且发现，针对检索优化的嵌入模型（如Nomic和Intfloat E5变体）表现明显优于针对特定领域的模型（如SciBERT）。

Conclusion: 
通过发布研究中的数据集、评估框架和实验基准，该研究提供了构建有效和高效的化学意识RAG系统的可操作指导。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17277</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>375. cs.AI-超越可能世界的分层实际化模态逻辑</title><link>https://arxiv.org/pdf/2506.17276</link><description>Background: 
传统公理化模态逻辑基于全局可能世界的经典模型，而忽略了实际化过程的局部、动态以及通常为非对称的性质。Kripke语义学将其模态运算视为对所有完全确定选项的量化，忽视了实际化过程的局部性质。本文提出的框架通过引入分层实际化逻辑（SAL），将模态与不同层级的本体稳定性联系起来，为理解实际化过程提供了一种新的方法。

Innovation: 
开发了一种基于分层实际化的新模态逻辑框架，不同于传统的全局可能世界模型，它强调实际化过程的局部、动态和非对称特性。SAL通过不同层级的本体稳定性来解释模态，将模态操作定义在相互关联的可能性层上，从而提供了一种新的模态逻辑理解和应用方式。

Conclusion: 
本文正式定义了SAL的语义和语法，引入了其公理，并证明了其一致性与完全性。SAL不仅能够捕捉实际化过程的本体结构，而且提供了一种不需要抽象可能世界的分层替代方案，特别适用于时间的生成、量子相干性领域和模态形而上学的研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17276</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>376. cs.AI-使用对应预测构建感知错误下的安全性屏蔽以确保低感知精度自主代理的安全控制</title><link>https://arxiv.org/pdf/2506.17275</link><description>Background: 
本文探讨了在自主代理因感知不完美（或更广泛来说，状态估计不准确）而采取行动的情况下如何确保安全控制的问题。代理在高维观测下使用学习组件进行感知，这可能导致感知错误。设计一个安全防护（shield）来提供在感知错误下的运行时安全保证，保持对代理动作的限制，这些动作依赖于状态估计的结果，进而被视为马尔可夫决策过程（Markov decision process, MDP）的模型。重要的背景是，对于每一个观测，预测集合包含真实状态的概率由用户指定，并且如果代理的行为总是遵循安全防护中规定的动作，初始的安全防护结构会限制达到危险状态的概率。这些概念为不完美感知自主代理提供了基础性的探讨，以确保在感知错误时的安全性。

Innovation: 
我们提出了一个安全防护（shield），它通过根据状态估计来限制在存在感知错误时可供代理执行的动作来提供运行时安全性保证。创新在于使用了对应预测方法来构建感知组件，这种对应预测保证了在每一个观测中，预测的状态集合必然包含真实状态，并且该预测保证了用户指定的概率。行动仅仅被允许当它们对应于预测集中每一个估计值时都处于允许状态，这产生了局部安全保证。我们还证明了现有安全防护结构的安全属性，即只要代理总是遵循由安全防护规定的动作，就能够在完美感知的情况下限定处于危险状态的概率上限。这些证明加强了我们关于不完美感知下自主代理安全性保证的理解。

Conclusion: 
我们展示了如何在高级感知深度神经网络（DNN）帮助下的实验自主系统中引导飞机行驶时实现安全性。我们的方法确保了基于预测集合的安全防护适用于高度感知误差的情况，从而提供了针对感知不完美的动态自主代理的安全限制和保护。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17275</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>377. cs.AI-QUST_NLP在SemEval-2025任务7：一种针对单语和跨语言事实检查声明检索的三阶段检索框架</title><link>https://arxiv.org/pdf/2506.17272</link><description>Background: 
本文描述了QUST_NLP团队参与SemEval-2025任务7的过程，重点介绍了一个专门设计用于事实检查声明检索的三阶段检索框架。背景在于通过系统性的评估和优化，提出了一种有效的方法，以提高事实检查声明的检索性能。

Innovation: 
本文的主要创新在于提出了一种三阶段检索框架，该框架包括候选检索、重排序和加权投票三个阶段。首先，对多种检索模型进行评估并选择最佳候选检索模型。其次，利用多种重排序模型进一步提升候选结果。最后，通过加权投票确定最终检索结果。这一框架能够针对单语和跨语言的检索任务进行优化，从而提高检索性能。

Conclusion: 
本文提出的三阶段检索框架在单语轨道中获得了第5名，在跨语言轨道中获得了第7名。此外，论文还公开了系统代码以供进一步研究。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17272</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>378. cs.AI-CF-VLM: CounterFactual Vision-Language Fine-tuning</title><link>https://arxiv.org/pdf/2506.17267</link><description>Background: 
近期视觉语言模型（VLMs）在多模态语义理解方面取得了显著进步，但在细微差异区分和深层次因果推理任务上仍然存在局限性。现有的VLMs往往依赖表面的相关性，缺乏捕捉视觉和文本内容之间的因果逻辑的能力。

Innovation: 
本文提出了CounterFactual Vision-Language Fine-tuning（CF-VLM），一种新的框架，通过有针对性地使用反事实样本来增强VLMs的因果推理能力。CF-VLM引入了三个互补的训练目标：保持基础的跨模态对齐、增强对符合逻辑的反事实样本中的事实场景表示的独特性和稳定性，以及增强模型对细微但关键的因果编辑的敏感性。

Conclusion: 
广泛的实验表明，CF-VLM在组合推理和泛化基准测试中均优于较强的基线和最先进的方法，并具有减轻视觉幻觉的潜力，表明了更好的事实一致性。CF-VLM为在需要可靠推理和解释性的真实场景中部署VLMs提供了坚实的基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17267</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>379. cs.AI-Does Multimodal Large Language Model Truly Unlearn? Stealthy MLLM Unlearning Attack</title><link>https://arxiv.org/pdf/2506.17265</link><description>Background: 
大规模多模态语言模型在训练过程中可能会记住敏感的个人信息和图片，这给隐私安全带来了严重的风险。现有的MLLM遗忘方法只能减少忘记敏感信息的程度，但无法确认这些知识是否真正被遗忘。

Innovation: 
提出了一个新型的LLM遗忘攻击框架Stealthy Unlearning Attack (SUA)，它可以学习一个通用的噪声模式，并通过图像输入时触发模型揭示未学习的内容。引入了嵌入对齐损失来最小化扰动图像和去噪图像的嵌入差异，以使攻击在语义空间中难以察觉。实验表明，SUA能够有效地恢复MLLM中的未学习信息，并且一种训练后的噪声可以在未见过的新图像中普遍适用。

Conclusion: 
MLLM的遗忘过程可能存在无法察觉的重新出现，而SUA可以有效地揭示这种虚假遗忘的情况。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17265</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>380. cs.AI-OAT-Rephrase: 优化感知训练数据重述以提升零阶大语言模型微调表现</title><link>https://arxiv.org/pdf/2506.17264</link><description>Background: 
使用零阶优化（ZO）微调大型语言模型（LLMs）提供了一种与基于梯度的方法相比更节省内存的选择，但它由于噪声梯度估计导致收敛速度慢和优化不稳定。目前的方法面临这一挑战，该论文通过引入一种新的方法来解决这一问题，这种方法利用一个LLM基于其对ZO动态的理解（特别是从其论文中直接衍生的MeZO）来重述训练实例。这有助于保持所有重述的数据相关性和逻辑一致性，从而改善了微调性能并缩小了与基于梯度的方法的比例差距。

Innovation: 
OAT-Rephrase采用了一种优化感知训练数据重述策略，该策略利用了LLM基于其对ZO动态（特别是MeZO）的理解来基于任务的相关性和逻辑一致性重述训练数据。该方法通过一个双重阶段的管道，结合重述LLM和语义裁判，来实现这一目标。这种方法显示出在多个分类任务和模型架构上的优越性，尤其是在微调性能方面，证明了优化感知重述作为零阶调整的一种可重用和低成本改进的有效性。

Conclusion: 
该研究通过优化感知重述方法OAT-Rephrase显示，该方法能够在多个分类任务和模型架构中有效提升零阶微调性能，并且这一方法具有低成本和容易应用的特点，可以作为零阶调整方案的增强剂。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17264</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>381. cs.AI-在资源受限的强化学习中的内存分配</title><link>https://arxiv.org/pdf/2506.17263</link><description>Background: 
资源限制能够从根本上改变学习和决策过程。本文探讨当使用标准强化学习算法在未知环境中导航时，记忆限制如何影响智能体的表现。具体来说，记忆受限的智能体面临如何在其内部流程之间分配有限的记忆资源的问题，例如用于估计世界模型还是使用该模型来制定计划。研究主要集中在MCTS-和DQN算法中，分析不同记忆分配方式对阶段性学习和持续学习环境影响下的性能表现差异。

Innovation: 
本文的研究集中在探索记忆约束如何影响智能体在未知环境中的表现，并在MCTS-和DQN基础上，研究了不同内存分配策略对智能体性能的影响，特别是针对阶段性学习和持续学习场景下的影响。这种研究提供了一种新的理解与解决强化学习中资源管理问题的方法。

Conclusion: 
研究表明，在资源受限的环境下，内存如何相对于内部过程（如世界模型估计和计划制定）进行高效分配对于智能体的表现具有显著影响。对于不同的任务场景，恰当的内存分配策略能够显著提升智能体的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17263</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>382. cs.AI-使用AI识别与视功能丧失相关的视神经头敏感区域</title><link>https://arxiv.org/pdf/2506.17262</link><description>Background: 
该研究旨在评估视神经头（ONH）的生物力学特性是否能更好地预测青光眼患者的三种渐进性视野丧失模式，并使用可解释的人工智能技术识别出对这些预测最敏感的ONH区域。研究选取了237名青光眼患者，通过对比自然状态和增加眼压后的ONH图像来分析其中的生物力学变化和结构特征，并使用几何深度学习模型进行分类。研究发现，ONH的生物力学应变可以提高视野丧失预测的准确性，特别是通过分析下部和下方颞侧边缘区域的生物力学应变，能够更准确地预测视野丧失情况。

Innovation: 
该研究创新之处在于它采用了一种结合生物力学特性和可解释的人工智能技术的方法，来识别与青光眼发作相关的视神经头敏感区域，以提高视野丧失预测的准确性。实验结果显示，神经视网膜边缘区域相较于筛板在预测模型中起到了更重要的作用。这种方法能够提供有价值的生物力学信息，帮助医生更好地理解青光眼的进展情况并提供个性化的治疗建议。

Conclusion: 
研究得出结论，视神经头的生物力学应变能显著提高青光眼视野丧失模式的预测能力。神经视网膜边缘而不是筛板是模型预测中贡献最大的关键区域，这些发现有助于提高对青光眼进展的了解和个性化治疗的精准度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17262</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>383. cs.AI-用于Generation-IV反应堆的具有强化学习使能的健康感知监督控制的数字孪生框架</title><link>https://arxiv.org/pdf/2506.17258</link><description>Background: 
 Generation IV (Gen-IV) 核能发电厂有望取代当前的反应堆队列，带来性能、安全性、可靠性和可持续性的改进。然而，巨大的成本投资目前阻碍了这些先进技术反应堆概念的部署。数字孪生技术通过将现实世界系统与数字工具相结合，能够降低运营成本、增强决策制定和提升运营效率。本工作中，设计了一个数字孪生框架来操作Gen-IV氟化盐冷却的高温堆，通过数据增强方法优化运营和维护策略，同时遵守系统限制。该框架结合了代理模型、强化学习和贝叶斯推理，以简化端到端的通信，实现在线调整和自我调节。通过参考管理者控制算法，确保满足泵流量率和温度限制，从而驱动目标功率生成。这些输入驱动模块受益于详细的在线模拟，这些模拟通过贝叶斯滤波与测量数据汇总。

Innovation: 
该研究提出了一种结合代理建模、强化学习和贝叶斯推理的数字孪生框架，用于Gen-IV氟化盐冷却的高温堆。此框架能够通过参考管理者控制算法确保泵流量率和温度限制，同时利用强化学习考虑组件健康和退化问题，以驱动目标功率生成。此外，通过详细的在线模拟和贝叶斯滤波技术，该框架能够实现维护计划、短期准确性提升和响应边界条件变化的实时校准能力

Conclusion: 
该数字孪生框架展示了稳定的健康感知和约束导向核电厂操作，具有对其他先进反应堆概念和复杂工程系统的一般适用性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17258</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>384. cs.AI-UltraSketchLLM: 以重要性驱动的简化技术用于超低比特LLM压缩</title><link>https://arxiv.org/pdf/2506.17255</link><description>Background: 
大规模语言模型（LLMs）的快速增长超越了边缘设备的内存限制，需要超过1比特的极端权重压缩。现有方法的量化虽能减小模型大小但受限于每权重1比特的极限。现有的多对一压缩方法要么依赖映射表（产生内存开销），要么由于随机权重分组导致严重准确度下降。因此，需要一种能够实现超低比特压缩（低至每权重0.5比特）同时保持模型性能的新方法。

Innovation: 
UltraSketchLLM引入了一种无需索引的，基于简化技术的框架，实现了超低比特压缩（每权重0.5比特），同时保持模型性能。该方法利用了来自于流式应用中的次线性表示技术——数据简化，将多个权重映射到单一值并带有可控制错误边界。该框架整合了一种低估AbsMaxMin简化技术来最小化小型权重的相对错误，一种基于重要性的空间分配方法来优先处理关键权重，并应用于压缩感知微调的直接梯度估计方法。实验表明，在Llama-3.2-1B上可达0.5比特压缩，同时具有竞争力的困惑度，并可接受的延时开销。

Conclusion: 
UltraSketchLLM为在资源受限环境中部署LLMs提供了实用的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17255</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>385. cs.AI-紧跟模型的步伐：大规模部署和路由LLMs的在线决策</title><link>https://arxiv.org/pdf/2506.17254</link><description>Background: 
新的大型语言模型（LLMs）快速涌现并变得过时，导致LLM服务提供商需要在有限的部署能力和每查询成本预算下管理不断变化的模型库存，同时还要进行阶段性的部署决策。这一现实被描述为一个在线决策问题，需要在固定的时间窗口内进行阶段性部署，并利用模型进行查询路由。

Innovation: 
提出了StageRoute层次算法，该算法通过使用奖励的上置信边界和成本的下置信边界来乐观地选择最多$M_{max}$个模型进入下一阶段，然后通过预算约束的强盗子问题对每次查询进行路由选择。通过理论证明，StageRoute的后悔率约为$T^{2/3}$，并提供了匹配的下界，证明其接近最优性。

Conclusion: 
实验结果显示，StageRoute在实际应用中接近最优性能，验证了理论分析。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17254</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>386. cs.AI-MS-TVNet：基于多尺度动态卷积的长序列时间序列预测方法</title><link>https://arxiv.org/pdf/2506.17253</link><description>Background: 
长期时间序列预测主要依赖于Transformer和多层感知机（MLP）模型，但卷积网络在这方面的潜力尚未得到充分开发。

Innovation: 
引入了一种新型多尺度时间序列重塑模块，该模块有效捕捉了多期片段之间的关系以及变量依赖性。在此基础上，提出了MS-TVNet，这是一种多尺度三维动态卷积神经网络，结果显示其在多种数据集上的性能优于基线模型，并达到了目前的最先进（SOTA）结果。

Conclusion: 
研究结果证实了利用卷积网络捕捉复杂时间模式的有效性，为未来研究提供了有前途的方向。相关代码在此处发布。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17253</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>387. cs.AI-动态采样调度以优化直接偏好优化</title><link>https://arxiv.org/pdf/2506.17252</link><description>Background: 
直接偏好优化（DPO）已成为大型语言模型（LLMs）与人类偏好对齐的有效方法。然而，其性能高度依赖于底层的人类偏好数据的质量。因此，先前的工作探索了各种数据选择策略，但这些方法往往忽略了语言模型在整个偏好优化过程中的状态演变的影响。为此，本文提出了一个新的问题：在偏好优化过程中，根据语言模型状态的演变动态和适应性地调度训练样本的采样调度问题。

Innovation: 
本文提出了SamS算法，这是一个有效的、适应性强的算法，能够根据每次训练批次中的学习反馈动态地选择样本，以最大化潜在的泛化性能。值得一提的是，不修改核心的DPO算法，仅通过集成SamS，就能显著提高任务性能，且几乎没有任何额外的计算开销。这为通过更有效利用固定偏好数据改善LLM对齐提供了新的途径和方向。

Conclusion: 
本文的工作揭示了一种新的方向，即通过更有效地利用固定偏好数据来改善LLM对齐，同时显著提高了任务性能，而几乎没有额外的计算开销。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17252</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>388. cs.AI-通过回收零样本示例进行训练无需的LLM验证</title><link>https://arxiv.org/pdf/2506.17251</link><description>Background: 
尽管大型语言模型（LLMs）在实现显著性能方面取得了巨大成功，但其推理过程中的固有随机性和多种可能的答案带来了重大挑战。为了寻找最佳解决方案，研究人员探索了多数投票或Best-of-N结合外部验证模型的方法。然而，这些方法存在一定的局限性，比如适用范围有限或增加额外的训练步骤的成本。鉴于这些挑战，本文分析了现有方法的局限性，并介绍了相关的背景信息。

Innovation: 
本文提出了一种新颖且有效的框架，称为编译少次示例（Referi），该框架可利用给定的少次示例来验证LLM输出。与传统的少次提示设置不同，它不仅用这些示例生成输出，还用于评估目标查询的候选输出。具体来说，Referi通过结合两个基于贝叶斯规则设计的不同评分来评估生成的输出，并通过少量额外的LLM推理来选择在置信度和上下文一致性方面都表现良好的候选输出。实验表明，该框架显著提高了LLMs的准确性，平均提高了4.8%，且无需额外的训练步骤。

Conclusion: 
本文通过提出一种利用给定少次示例验证LLM输出的新框架（Referi），显著提高了LLM的准确性，并为解决现有方法的局限性提供了有效途径。实验结果表明，该框架能够在没有额外训练的情况下显著提高LLM的性能，这为LLM的准确性和可信赖性提供了新的视角。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17251</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>389. cs.AI-通过稀疏对抗攻击实现可解释的对抗样本</title><link>https://arxiv.org/pdf/2506.17250</link><description>Background: 
现有稀疏攻击虽然能够在仅更改少量像素（即满足l0约束）的情况下使深度神经网络（DNNs）受到欺骗，但由于稀疏性差、计算量大、转移性差和攻击强度弱等问题，难以生成可解释的对抗样本。本文旨在通过改进稀疏攻击，实现快速、可转移和强大的DNN攻击，同时简化稀疏优化问题，引入新的参数化方法和损失函数，以提高对抗样本的稀疏性，进而揭示分类器错误预测的机制。

Innovation: 
1. 提出了一种新的参数化技术，能够近似NP难题的l0优化问题，使直接优化稀疏扰动成为可能；n2. 设计了一种新的损失函数，同时增强初始扰动的敌对属性并减少扰动像素的数量；n3. 经验和理论结果表明，该方法生成的对抗样本更稀疏，能够揭示两类噪声：‘阻碍噪声’和‘引导噪声’，有助于解释对抗扰动如何误导分类到错误预测的结果。

Conclusion: 
该方法在计算开销、转移性和攻击强度方面优于最先进的稀疏攻击方法。实验结果进一步证明该方法能够生成更稀疏的对抗样本，为评估DNNs的鲁棒性提供了参考基准。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17250</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>390. cs.AI-通过零空间投影提高预测确定性估计以实现可靠的提前退出</title><link>https://arxiv.org/pdf/2506.17249</link><description>Background: 
提前退出在加速预训练语言模型（PLMs）的推理方面展现了巨大潜力，通过让容易的部分样本在浅层早退出，减少对深层层的执行。现有方法主要依赖于类别相关的logits来构建退出信号以估计预测确定性，但忽视了特征中类别无关信息对预测确定性的影响，导致预测确定性被高估，使一些错误预测的样本过早退出。

Innovation: 
该方法定义了一个NSP分数来通过考虑特征中类别无关信息的比例来估计预测确定性。在此基础上，提出了一种基于Certainty-Aware Probability（CAP）分数的新颖提前退出方法，该方法结合了logits和NSP分数的见解，以增强预测确定性的估计，从而实现更具可靠性的提前退出决策。实验结果表明，该方法在GLUE基准测试上的平均加速比为2.19倍，几乎无性能下降，相较于最先进的ConsistentEE方法超过28%，在任务性能和推理效率之间取得更好的权衡。

Conclusion: 
该方法通过引入NSP分数和CAP分数来提高预测确定性估计，实现更加可靠的提前退出决策。实验结果表明该方法能够有效加速PLMs的推理，在不显著影响性能的前提下，取得更好的任务性能和推理效率之间的平衡。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17249</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>391. cs.AI-在样本层面高效量化多模态交互</title><link>https://arxiv.org/pdf/2506.17248</link><description>Background: 
多模态信息的组成由模式间的冗余性、独特性和协同性共同决定。理解这些交互对于分析多模态系统的信息动态至关重要，但准确地在样本层面量化这些交互既存在理论挑战又存在计算挑战。本研究旨在解决这一问题，介绍一种轻量级样本层面多模态交互（LSMI）估计器，系统地基于点信息理论建立。研究人员首先建立了一种冗余度估计框架，并选用了适当的点信息度量来量化这一最可分解和可测量的交互。据此，提出了一种通用的交互估计方法，采用高效的熵估计方法，特别适用于连续分布中的样本层面估计。尽管这在合成和真实世界数据集上已经得到广泛验证，轻量化样本层方法揭示了多模态数据中细粒度的样本层面和类别层面动态，从而在冗余引导的样本分割、有目标的知识蒸馏和交互感知模型集成等方面有实际应用潜力。

Innovation: 
该论文创新性地引入了轻量级样本层面多模态交互（LSMI）估计器，基于点信息理论，开发了一个冗余度估计框架，并提出了一种通用且高效的交互估计方法，特别适合连续分布样本层面的估计。这种方法能够揭示多模态数据中细粒度的样本层面和类别层面动态，为冗余引导的样本分割、有目标的知识蒸馏和交互感知模型集成等实际应用提供了支持。具体创新点如下：1) 提出了一种高效冗余度估计方法；2) 建立了通用交互估计框架；3) 在合成和真实世界数据集上进行了广泛验证；4) 揭示了多模态数据中的细粒度动态。

Conclusion: 
轻量级样样本层面多模态交互（LSMI）估计器通过系统地应用点信息理论，实现了对多模态数据中冗余性、独特性和协同性的高效量化。该方法不仅能够验证量化结果的精确性和高效性，还在实际应用中展现了显著效果，为未来的多模态信息处理提供了新的研究视角和工具。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17248</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>392. cs.AI-基于递归学习的虚拟缓冲技术用于分析性全局布局</title><link>https://arxiv.org/pdf/2506.17247</link><description>Background: 
在现代技术节点中，互连延时与单元延时的非线性缩放使得全局布局与基于缓冲的延迟优化之间的协调至关重要。然而，现有的方法面临着两大挑战：一、传统的 van Ginneken-Lillis 风格的缓冲方法在全局布局阶段计算成本高昂；二、基于机器学习的方法，如 BufFormer，在电气规则检查 (ERC) 违规方面考虑不足，无法将结果反馈到物理设计流程中，导致无法完全解决延迟闭合问题。

Innovation: 
本文提出了 MLBuf-RePlAce，一种基于机器学习的虚拟缓冲的分析性全局布局框架，该框架建在 OpenROAD 架构之上。MLBuf-RePlAce 引入了一种高效的递归基于学习的生成性缓冲策略，能够预测缓冲类型和位置，并在全局布局时解决电气规则检查 (ERC) 违规。与 OpenROAD 中现成的依赖虚拟缓冲的时驱动全局器相比，MLBuf-RePlAce 在不牺牲布线后功耗的情况下，总负余量 (TNS) 最大和平均值分别提高 56% 和 31%，在商业流程测试中，TNS 改进达到了 53% 和 28%，平均布线后功耗增加 0.2%。

Conclusion: 
MLBuf-RePlAce 通过考虑 ERC 违规并引入高效的递归学习缓冲方法，展示了在不增加功耗的前提下提升全局布局质量的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17247</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>393. cs.AI-图神经网络在多重组学癌症研究中的结构综述</title><link>https://arxiv.org/pdf/2506.17234</link><description>Background: 
多重组学数据的集成任务已成为揭示癌症复杂生物学基础的强大策略。近年来，图神经网络（GNNs）的发展为建模异质且结构化的组学数据提供了有效的框架，能够精确表示分子间相互作用和调控网络。本研究综述了将基于GNN的架构应用于多重组学癌症研究的最新研究。研究表明，这些方法可以根据针对的组学层级、图神经网络结构和生物学任务（如亚型分类、预后预测和生物标志物发现）进行分类。分析揭示了向混合和可解释模型的趋势，并且越来越多地采用了注意力机制和对比学习。此外，本研究还强调了患者特定图和知识驱动的先验作为新兴方向的应用。这项综述为希望通过设计有效的GNN基础管道进行综合癌症分析的研究人员提供了全面的资源，提供了有关现有实践、局限性和潜在未来方向的见解。

Innovation: 
将基于GNN的架构应用于多重组学癌症研究，包括混合和可解释模型的趋势，越来越多地采用注意力机制和对比学习，以及患者特定图和知识驱动的先验作为新兴方向。这些趋势和应用为多重组学数据的整合分析提供了新的研究方向。

Conclusion: 
综上所述，该综述为针对多重组学癌症研究的设计有效GNN基础管道的提供了一套详尽的资源，从当前的诊疗和局限性等方面提供了见解，并指出了未来的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17234</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>394. cs.AI-PCaM：一种用于提升视觉变换器领域自适应的渐进关注焦点注意力信息融合方法</title><link>https://arxiv.org/pdf/2506.17232</link><description>Background: 
无监督领域适应（UDA）旨在将标记的源领域知识转移到未标记的目标领域。基于视觉变换器（ViTs）的最近UDA方法通过基于注意力的特征对齐已获得出色的性能。然而，在不同领域中前景对象的大小和空间分布差异会导致注意力一致性减弱，从而阻碍有效的领域对齐。

Innovation: 
论文提出了一种渐进聚焦跨注意力机制（PCaM），该机制在跨注意力中逐步过滤掉背景信息，使模型能够关注并融合跨领域的鉴别前景语义。此外，还引入了一种注意力引导损失，明确地将注意力引导到与任务相关的区域，从而增强跨域注意力的一致性。PCaM 是一种轻量级、架构无关且易于集成到现有基于 ViT 的UDA 管道的方法。

Conclusion: 
在Office-Home、DomainNet、VisDA-2017 和遥感数据集上的广泛实验表明，PCaM 显著提高了适应性能并达到了新的最佳结果，验证了注意力引导前景融合在领域自适应中的有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17232</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>395. cs.AI-MMET: 一个多输入和多尺度变换器用于高效的PDE求解</title><link>https://arxiv.org/pdf/2506.17230</link><description>Background: 
偏微分方程（PDEs）是用于建模物理系统的基石，然而，使用基于机器学习的方法以通用且高效的方式解决它们仍然具有挑战性。主要原因是多输入和多尺度的一般化能力有限，以及高昂的计算成本。现有的方法在处理大型几何模型时计算成本高且效率低，缺乏有效的多尺度和多输入问题解决方案。

Innovation: 
本文提出了多输入和多尺度高效变换器（MMET），这是一种新型框架，旨在解决上述挑战。MMET将网格和查询点解耦为两个序列，并将它们分别输入编码器和解码器中。同时，它使用了门控条件嵌入（GCE）层来嵌入不同维度的输入变量或函数，从而能够有效解决多尺度和多输入问题。此外，基于希尔伯特曲线的重序列化和片段嵌入机制减少了输入长度，显著降低了处理大规模几何模型时的计算成本。这些创新使得MMET能够为大规模和多输入PDE问题提供有效的表示和支持多尺度分辨率查询。

Conclusion: 
实验结果表明，MMET在不同物理领域的多个基准测试中，在准确性和计算效率方面均优于当前最佳方法。这项工作突显了MMET作为实时工程和物理基础应用中PDE求解的强大和可扩展解决方案的潜力，为未来在特定领域预训练大规模模型的研究铺平了道路。源代码已开源。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17230</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>396. cs.AI-jina-embeddings-v4：多模态多语言检索的通用嵌入</title><link>https://arxiv.org/pdf/2506.18902</link><description>Background: 
该论文介绍了一种名为jina-embeddings-v4的38亿参数的多模态嵌入模型，该模型通过一个支持单向量和多向量嵌入的独特架构，将文本和图像表示统一起来。模型整合了针对特定任务的任务特定低秩适应（LoRA）适配器，以在多样的检索场景中优化性能，包括基于查询的信息检索、跨模态语义相似度以及编程代码搜索等任务。

Innovation: 
该模型的主要创新在于通过独特的架构支持单向量和多向量嵌入，并通过LoRA适配器优化了在不同场景下的性能，特别是在处理复杂内容（如表格、图表、图表和混合媒体格式）方面表现突出。此外，为了便于评估这种能力，论文还引入了Jina-VDR，这是一个针对复杂视觉图像检索设计的新基准。

Conclusion: 
全面的评估表明，jina-embeddings-v4在单模态和跨模态检索任务中都达到了最先进的性能，特别是在处理丰富视觉内容方面表现特别突出。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18902</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>397. cs.AI-通过变压器潜在子空间激活引导概念偏差</title><link>https://arxiv.org/pdf/2506.18887</link><description>Background: 
本文探讨了在语言模型（LLMs）中激活潜在子空间是否能引导科学代码生成向特定编程语言转变。首先通过五个因果LLMs在科学编程提示下的表现，量化了它们在四种编程语言之间的基本偏差。静态的神经元归因方法在应对不同提示风格和模型规模时表现出局限性和泛化不足。

Innovation: 
文章提出了一种基于梯度细化的自适应激活引导框架（G-ACT）。该框架通过将每种提示的激活差异聚类，形成少量引导方向，并在线训练和调整每个层次的轻量级探针，以选择合适的引导向量。该方法在LLaMA-3.2 3B模型上，成功偏向生成CPP语言，提升了平均探针分类准确性15%，特别是在早期层（0-6），分类准确性提升了61.5%。对于LLaMA-3.3 70B模型，由于注意力头信号的分布更加模糊，仍然可以通过在关键层进行有针对性的注入来改善语言选择。尽管分层探测引入了轻微的推理开销，但通过仅指导部分层的方法仍保持了可操作性，实现了可重复的模型行为。

Conclusion: 
本文展示了在概念级别控制实际代理系统中的一个可扩展、可解释且高效的机制。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18887</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>398. cs.AI-ConciseHint：在生成过程中通过连续简明提示增强高效推理</title><link>https://arxiv.org/pdf/2506.18810</link><description>Background: 
大型推理模型（LRMs）如DeepSeek-R1和OpenAI o1系列，在复杂推理任务上通过增加Chain-of-Thought（CoT）的生成长度取得了显著的进步。然而，这些模型倾向于生成冗长的推理过程，导致效率降低。现有的提高效率的研究主要集中在预先推理或推理后的提示和微调方法，而忽略了通过在推理生成过程中干预来直接鼓励模型简洁表达的潜在方向。

Innovation: 
我们提出了一种名为ConciseHint的框架，该框架通过在推理过程的标记生成期间注入文本提示（手工设计或基于简洁的数据）连续鼓励模型简洁表达。此外，该框架能够根据查询的复杂性自适应调整提示强度，确保不会损害模型性能。实验结果证明，我们的方法可以在保持性能的同时有效减少推理过程的长度，例如，在GSM8K基准上，对于Qwen-3 4B模型，我们实现了65%的推理长度减少，几乎没有任何准确性损失。

Conclusion: 
我们的实验结果表明，该方法可以在保持性能的同时有效减少推理过程的长度，例如，在GSM8K基准上，对于Qwen-3 4B模型，我们实现了65%的推理长度减少，几乎没有任何准确性损失。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18810</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>399. cs.AI-TRIZ Agents: 基于多智能体大语言模型的TRIZ创新方法</title><link>https://arxiv.org/pdf/2506.18783</link><description>Background: 
TRIZ是解决创新问题的结构化、知识型框架，但其应用受限于复杂性和深厚跨学科知识的需求。尽管大型语言模型（LLMs）的进展为自动化TRIZ过程的一部分带来了新的可能性，但之前的研究多是将单个LLM应用于TRIZ中，本研究提出了一个基于多智能体的新方法。该方法旨在使用不同专业知识的智能体协作解决TRIZ问题，以提升创新过程的效率和效果。评估了多智能体系统在处理复杂创新挑战方面的有效性，特别是在工程案例中。研究表明多智能体协作具有生产多样化创新解决方案的潜力。此项研究为人工智能驱动的创新未来提供了新的见解，突显出在复杂创意任务中去中心化问题解决的优势。

Innovation: 
本研究采用了多智能体系统的方法，每个智能体具有特定的专业能力和工具访问权限，协同基于TRIZ方法论解决创新问题。这种多智能体系统利用了不同领域专业知识的智能体，有效地导航TRIZ步骤。评估了这种智能体团队在处理复杂创新挑战方面的有效性，并展示了智能体协作生产多样化创新解决方案的潜力。

Conclusion: 
本文展示了多智能体系统在TRIZ创新中的应用，通过多智能体协作有效解决了复杂创新挑战，证明了分布式问题解决的优势，并为未来人工智能驱动的创新提供了新的研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18783</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>400. cs.AI-通过反向传播进行编程：LLMs在代码训练期间获得可重用的算法抽象</title><link>https://arxiv.org/pdf/2506.18777</link><description>Background: 
训练大型语言模型（LLMs）使用源代码显著提高了它们的通用推理能力，但这些模型为何能够进行这种推广的效果并不清楚。该研究探讨了编程并反向传播(PBB)作为可能的驱动因素，即通过训练源代码而不是输入输出实例来教会模型评估程序的方法。研究者在两个程序集上对模型进行了微调，一个集子包含源代码和输入输出实例（带IO），另一个集子仅包含源代码（不带IO），以探索代码训练对此的理解。

Innovation: 
研究提出了PBB方法，这种方法通过训练源代码直接教会模型评估程序，而不需要输入输出实例。研究发现，当程序以代码形式提供时，PBB的效果更好，模型能够直接产生输入输出程序的结果，并且通过逐步推理更加可靠。此外，PBB在不同输入上的程序评估比从模拟自然数据的概率分布中抽取输入输出对进行训练更加稳健。研究表明，通过代码训练，LLMs能够内部化可重用的算法抽象，这为未来工作提供了方向，致力于使LLMs更有效地从符号过程学习，并且这样的进展为其他途径，如通过训练正式宪法原则进行模型对齐提供了可能。

Conclusion: 
研究结果表明，通过代码训练LLMs，能够增强其推理能力，使其能够内部化可重用的算法抽象。然而，未来工作还有很大空间，需要让LLMs更有效地从符号过程学习，这将为通过训练正式宪法原则进行模型对齐等其他途径打开新的大门。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18777</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>401. cs.AI-双层级行为一致性在多智能体系统组内与组间协调中的应用</title><link>https://arxiv.org/pdf/2506.18651</link><description>Background: 
多智能体强化学习（MARL）中的行为多样性是一个新兴且有前景的研究领域。先前的工作主要集中在组内的行为一致性，而对组间的行为一致性关注较少。本文旨在引入一种新颖的MARL控制方法——双层级行为一致性（DLBC），并用于调节智能体在组内和组间的行为多样性。通过组内的行为一致性促进组内的合作，组间的协调一致性限制不同组的行为策略。

Innovation: 
本文提出了DLBC，一个用于调制组内和组间行为多样性的新型MARL控制方法，实现组间一致性，约束不同组的行为策略，同时强化组内的合作。最重要的是，DLBC直接调控代理策略函数，使其具有更广泛的适用性。实验结果表明，DLBC在不同组合作场景中显著提高了组内合作性能和组间任务专业化，从而取得了显著的性能提升。

Conclusion: 
DLBC为多智能体系统的行为一致性控制提供了新的思路，未来可以进一步探索其在更复杂任务和动态环境中的应用潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18651</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>402. cs.AI-AggTruth：使用LLMs中聚合注意评分进行上下文幻觉检测</title><link>https://arxiv.org/pdf/2506.18628</link><description>Background: 
在实际应用中，大型语言模型（LLMs）经常出现幻觉现象，即使是在检索增强生成（RAG）环境中也是如此，这对它们的部署构成了重大挑战。为了克服这一挑战，本文介绍了一种名为AggTruth的方法，该方法通过分析提供上下文（段落）的内部注意力分数分布来进行上下文幻觉的在线检测。该方法提出了四种不同变体，每种变体的聚合技术不同，适用于不同的LLM模型，在相同任务和跨任务设置中均表现稳定，且在多场景中超越当前最佳方法（SOTA）。

Innovation: 
提出了一种名为AggTruth的方法，通过分析LLM中上下文段落的内部注意力分数分布进行上下文幻觉的在线检测，并提出了四种不同的变体。这些变体在不同的LLM模型上均达到稳定性能，并且在多场景中超越了当前的最佳方法。此外，深入分析了特征选择技术，研究了选择的注意头数量对检测性能的影响，表明合理选择注意头是达到最佳结果的关键。

Conclusion: 
AggTruth在不同LLM模型和不同任务设置中均表现出稳定和优越的性能，并通过准确选择关注的注意头来实现最佳结果。该方法为LLM在实际应用中的部署提供了一种有效的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18628</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>403. cs.AI-Airalogy：基于AI的通用数据数字化研究自动化</title><link>https://arxiv.org/pdf/2506.18586</link><description>Background: 
当前的人工智能应用主要集中在少数几个领域，这些领域具有易于获取、结构良好的数字化数据集。然而，全面实现人工智能在多个学科中的应用仍然面临挑战。现有的研究数据收集往往碎片化且缺乏统一标准，数据管理效率低下，难以共享。要创建一个标准化的数据数字化单一平台，需要平衡普遍性和标准化之间的矛盾：既要满足各个学科多样化和不断变化的需求，又要强制执行一致的格式以完全启用人工智能。目前还没有平台能够同时满足这两方面的需求。建设一个真正跨学科的平台需要整合科学领域的知识与高深的计算技能。但是，研究者常常缺乏设计定制化且标准化数据记录方法的计算专长，而平台开发者往往不了解多个科学领域的复杂需求。这些差距阻碍了研究数据标准化和人工智能驱动的进步。

Innovation: 
本研究开发了Airalogy，这是一个全球首款由人工智能和社区驱动的平台，能够平衡多学科领域的数据数字化中的普遍性和标准化需求。Airalogy 使用可定制且标准化的数据记录代表整个研究工作流程，并提供先进的AI研究助手，实现智能问答、自动化数据录入、分析和研究自动化。Airalogy已经在西湖大学四个学院的实验室中部署并应用，有望加速和自动化科学研究，促进全球研究社区的进步，最终惠及全人类。

Conclusion: 
Airalogy 的部署已经在西湖大学各个学院的实验室初步取得成功，展示了其在加速和自动化科学研究，特别是在大学、工业界和国际研究社区中的巨大潜力。Airalogy 可以加速和自动化科学研究，推动人工智能驱动的进步，最终惠及全人类。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18586</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>404. cs.AI-T-CPDL：一种用于开发逻辑-检索-增强生成(Logic-RAG)代理的时态因果概概率描述逻辑</title><link>https://arxiv.org/pdf/2506.18559</link><description>Background: 
大型语言模型在生成流畅文本方面表现出色，但在处理涉及时间约束、因果关系和概率推理的结构化推理方面经常遇到困难。为了解决这些限制，本文提出了一种新的框架——临时因果概概率描述逻辑 (T-CPDL)，该框架扩展了传统的描述逻辑，增加了时间区间运算符、显式因果关系和概率注解。通过引入这两种不同的T-CPDL变体，一种通过Allens区间代数捕捉定性时间关系，另一种具有明确的时间戳因果断言，作者展示了如何使用统一的逻辑结构进行复杂推理。

Innovation: 
T-CPDL是一种新的整合框架，通过增加时间区间运算符、显式因果关系和概率注解，扩展了传统的描述逻辑。它提出了两种不同的变体，一种通过Allens区间代数捕捉定性时间关系，另一种具有明确的时间戳因果断言。这两种变体都具有统一的逻辑结构，能够支持从简单的时间顺序到复杂的概率因果关系等多种推理任务。实验证明，T-CPDL在时间推理和因果推断基准测试中显著提高了语言模型的推理精度、可解释性和置信度校准。通过提供透明的推理路径和详细的时序和因果语义，T-CPDL显著增强了语言模型支持稳健、可解释和可信决策的能力。此外，本文也为开发先进的逻辑-检索-增强生成(Logic-RAG)框架奠定了基础，可能会提升知识图谱增强RAG系统的能力和效率。

Conclusion: 
本文介绍了T-CPDL框架，提升了语言模型在复杂推理方面的表现。T-CPDL通过增强逻辑结构，能够进行更复杂的推理，提高了推理精度和解释性。该框架为开发更智能的Logic-RAG代理和其他知识增强系统提供了基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18559</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>405. cs.AI-评估人工智能包容性的问答题库：从多样性错误到包容卓越之旅的路线图</title><link>https://arxiv.org/pdf/2506.18538</link><description>Background: 
确保人工智能（AI）中的多样性和包容性（D&amp;amp;I）对于减轻偏见和促进公平决策至关重要。然而，现有的AI风险评估框架往往忽略了包容性，缺乏标准化工具来衡量AI系统与D&amp;amp;I原则的一致性。文献综述、D&amp;amp;I准则、负责任AI框架以及模拟用户研究的多重来源理念被纳入，开发出了一个结构化的AI包容性问题库，涉及五个支柱：人类、数据、流程、系统和治理。这一评估通过模拟AI角色之间的交流来检验其相关性和有效性，覆盖了多样化的角色和应用领域。研究发现强调了将D&amp;amp;I原则集成到AI开发工作流程和治理结构中的重要性。

Innovation: 
该论文创新地引入了一个结构化的AI包容性问题库，包含253个问题，旨在从五个方面（人类、数据、过程、系统和治理）评估AI系统的包容性。该问题库通过文献综述、D&amp;amp;I准则、负责任AI框架和模拟用户研究的迭代多源方法而开发。通过仿真用户评估，确保了问题库的相关性和有效性，促进了多领域和多层次的AI包容性评价。

Conclusion: 
该研究强调了将D&amp;amp;I原则嵌入AI开发和治理中的重要性，并提供了适用于研究人员、实践者和政策制定者的行动工具体，以系统地评估和增强AI系统的包容性，从而引导出更公平和负责任的人工智能技术。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18538</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>406. cs.AI-基于RAG的医疗器械合规标准适用性判断与跨域推理框架</title><link>https://arxiv.org/pdf/2506.18511</link><description>Background: 
识别合适的监管标准适用性仍然是医疗器械合规中一个关键但却研究不足的挑战，通常需要专家对分布在不同司法管辖区的不一致和异构文档进行解释。这项工作的背景是当前在医疗设备合规中面临的专家解读分散文档的挑战，急需自动化方法来处理这个挑战。

Innovation: 
本文介绍了一个模块化的AI系统，该系统利用检索增强生成（RAG）管道自动确定标准适用性。该系统通过对描述性的医疗设备文本进行自由描述输入，从一个经过策划的语料库中检索候选标准，并使用大型语言模型推断特定司法管辖区的标准适用性，分类为强制性、推荐或不适用，并提供可追溯的理由。通过构建包含专家注释标准映射的国际基准数据集，本文的方法证明了其在识别相关监管标准方面的有效性，并提供了一个端到端的系统来进行可靠的监管标准适用性推理。特别地，区域意识RAG代理在不同管辖区之间进行推理，支持法规冲突解决和适用性论证。

Conclusion: 
本文提出的方法在分类准确率和Top-5召回率方面表现良好，达到了73%和87%，说明此方法在判断关键监管标准方面的有效性，并提出了一种可扩展且可解释的AI支持的监管科学。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18511</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>407. cs.AI-细调之后模型编辑的稳定性：文本到图像扩散模型的一项经验研究</title><link>https://arxiv.org/pdf/2506.18428</link><description>Background: 
模型编辑提供了一种低成本的技术，可以在不需要大量再训练的情况下向预训练模型注入或纠正特定行为，支持如事实修正和偏见缓解等应用。尽管这种方法很常见，但仍然不清楚编辑是否会保持在微调之后，或者是否会被无意中逆转。这一问题具有实际的理论意义。例如，如果微调消除了之前的编辑，这可能成为防止隐藏的恶意编辑的保护机制。反之，意外地删除与偏见缓解相关的编辑可能会带来严重的安全问题。这项研究旨在系统地探讨模型编辑与文本到图像扩散模型中微调之间的相互作用，这些模型因为存在偏见和生成不适当内容而出名。研究覆盖了两个文本到图像模型系列（Stable Diffusion和FLUX）、两种最先进的编辑技术以及三种微调方法（DreamBooth、LoRA和DoRA）。研究通过广泛的实证分析和多样的编辑任务及评估标准，发现了一个趋势：即使微调与编辑无关，编辑通常也会在微调过程中失效。观测到DoRA表现出最强的编辑逆转效果，同时编辑方法中的UCE显示出更高的鲁棒性，即便微调之后仍然保持显著更高的有效性。这些发现揭示了当前编辑方法的一个关键局限性，强调了需要更鲁棒的技术来确保已部署人工智能系统的可靠长期控制和对齐。研究结果对于人工智能安全具有双重影响：表明微调可能成为恶意编辑的补救机制，同时强调了微调后的重新编辑的必要性，以维持有益的安全和对齐属性.

Innovation: 
研究发现，尽管微调与编辑任务不相关，但编辑通常在微调过程中不会持续存在。尤其是在微调中，DoRA表现出最强的编辑逆转效果，而UCE则表现出更高的鲁棒性，在微调后仍然保留了较高的有效性。这一发现揭示了一种在当前编辑技术中存在的关键局限性，引入了微调作为恶意编辑的补救机制，同时也强调了重新编辑的重要性，以维持有益的安全和对齐属性。研究还系统化地探讨了这一过程中的各种技术和方法，从而为未来研究提供了新视角和技术基础。

Conclusion: 
研究揭示了当前编辑方法的一个关键局限性，即即使微调与编辑任务不相关，编辑通常也会在微调过程中失效。DoRA表现出最强的编辑逆转效果，而UCE则表现出更高的鲁棒性。为了确保已部署人工智能系统的可靠长期控制和对齐，研究强调了需要更鲁棒的编辑技术。这些发现对于维护AI系统的安全性具有重要的实际意义，研究还指出微调可能成为恶意编辑的补救机制，同时提醒研究人员和开发者需重视微调后的重新编辑，以维持系统的有益安全和对齐属性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18428</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>408. cs.AI-一种基于大型语言模型的多代理框架用于模拟电路尺寸关系提取</title><link>https://arxiv.org/pdf/2506.18424</link><description>Background: 
在模拟电路的预布局阶段设计过程中，器件尺寸选择是确定电路能否达到所需性能标准的重要步骤。现有技术将电路尺寸选择任务抽离出来作为数学优化问题来解决，并不断从数学角度优化求解效率。然而，这些方法忽视了自动引入先验知识，未能有效地缩小搜索空间，从而导致搜索空间中仍存在显著的压缩余地。

Innovation: 
提出了一种基于大型语言模型（LLM）的多代理框架，用于从学术论文中提取模拟电路的尺寸关系。基于该框架提取的尺寸关系可以有效地缩小尺寸过程中的搜索空间，从而提高了优化效率2.32到26.6倍。

Conclusion: 
这项工作表明，大型语言模型可以有效地缩小模拟电路尺寸选择的搜索空间，并为大型语言模型和传统模拟电路设计自动化方法的结合提供了一个新的解决方案。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18424</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>409. cs.AI-动态知识交换与双重多样性审查：简洁地释放多代理研究团队的潜力</title><link>https://arxiv.org/pdf/2506.18348</link><description>Background: 
科学发展越来越依赖于研究人员之间的有效协作，这是一个只有开始被大规模语言模型（LLMs）模仿的动态。虽然基于LLM的科学家代理在过去显示出在自主科学研究中的潜力，但它们往往缺少关键的交互式推理和评估机制，这些对于现实中的研究是必不可少的。本研究旨在通过提出IDVSCI（内部讨论和投票科学家），一种基于LLM的多代理框架，来解决这一问题。该框架引入了动态知识交换机制和双重多样性审查范式，以此促进更深的推理和更具创意与影响力的科学想法的产生。研究通过使用计算机科学中广泛使用的基准测试数据集和一个新的健康科学领域数据集进行了实验，结果表明IDVSCI在两个数据集上表现最优，超过了现有的系统，例如AI Scientist和VIRSCI，突显了在基于LLM的自主研究中建模交互和同行评审动态的重要性。

Innovation: 
IDVSCI框架引入了两项关键创新，首先是动态知识交换机制，使代理之间的反馈迭代化；其次是双重多样性审查范式，模拟了多样化专家的评估过程。这些组件共同推进了深处的推理，产生了更具创意的科学想法。

Conclusion: 
IDVSCI框架成功地在两个数据集上表现最佳，这种成果强调了在基于LLM的自主科学研究中建模交互和同行评审动态的重要性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18348</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>410. cs.AI-基于大型语言模型的多智能体系统（LLMMA）高级循环用于QML算法搜索</title><link>https://arxiv.org/pdf/2506.18260</link><description>Background: 
本文介绍了利用基于大型语言模型的多智能体系统（LLMMA）进行量子机器学习（QML）算法的自动化搜索和优化的先进框架。该框架受到Google DeepMind的FunSearch的启发，可以在抽象层面上进行迭代生成和优化经典机器学习算法（概念）的量子变换，如多层感知机、前向传播和反向传播算法。这项工作作为一个概念证明，展示了代理型框架系统化探索经典机器学习概念和将其适应量子计算的潜力，从而为高效且自动化开发QML算法铺平了道路。未来的研究方向包括在搜索空间中纳入规划机制和优化策略，以更广泛地应用于量子增强的机器学习领域。

Innovation: 
提出了利用大型语言模型为基础的多智能体系统进行QML算法的自动化搜索与优化的框架；该系统借鉴了Google DeepMind的FunSearch方法，能够在抽象层面上迭代生成和优化经典机器学习算法的量子变换；未来将引入规划机制和优化策略以拓宽量子机器学习的应用范围；展示了系统化探索和转化经典机器学习算法为量子算法的潜力；为高效的QML算法开发提供可能的自动化途径。

Conclusion: 
该研究表明，代理型框架在系统化探索和转化经典机器学习算法以适应量子计算中具有巨大潜力，未来的研究将集中在该框架的应用性和效率上，同时引入更多复杂的规划和优化机制来扩展其在量子机器学习中的应用能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18260</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>411. cs.AI-第四维度扩展模型规模</title><link>https://arxiv.org/pdf/2506.18233</link><description>Background: 
大型语言模型的规模通常涉及深度、宽度和参数数量三个维度。本文探索了一个第四维度，即虚拟逻辑深度（VLD），该维度通过在模型内部重用参数来增加算法的有效深度，而不改变总的参数计数。尽管参数重用的概念不是新的，但其在模型扩展中的潜力和特性尚未被充分研究。

Innovation: 
研究揭示了VLD扩展的关键发现：VLD扩展能使模型的知识容量保持几乎不变，只有微小的变化；适当实施VLD扩展能够显著提高推理能力；参数数量与知识容量相关，但与推理能力无关；在某些条件下，增强推理能力不一定需要增加参数数量。这些发现适用于各种模型配置，并且在我们实验的范围内可能是普遍有效的。

Conclusion: 
这些发现表明VLD扩展可以在不增加参数数量的情况下显著提升模型的推理能力，且参数数量与知识容量之间的关系不同于与推理能力之间的关系。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18233</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>412. cs.AI-AI能力评估的概念框架</title><link>https://arxiv.org/pdf/2506.18213</link><description>Background: 
随着人工智能系统的发展和社会整合，精心设计和透明的评估成为治理AI的重要工具，为决策提供有关系统能力和风险的证据。然而，关于如何进行全面和可靠的评估，仍然缺乏清晰性。

Innovation: 
提出了一种分析AI能力评估的概念框架，提供了一种结构化的、描述性的方法，系统化分析广泛使用的方法和术语，而不设定新的分类或刚性格式。该框架促进了透明度、可比性和解释性，适用于各种评估，并协助研究人员识别方法论缺陷，指导实践者设计评估，为政策制定者提供一个易于理解的工具来审查、比较和导航复杂的评估景

Conclusion: 
该框架支持跨不同评估的透明性、可比性和解释性，帮助识别方法论中的缺陷，指导实践者设计评估，并为政策制定者提供了一个易于理解的工具来审查和比较复杂的评估环境。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18213</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>413. cs.AI-非依从性对不良后果的影响：来自使用生存分析分析的精神分裂症患者证据</title><link>https://arxiv.org/pdf/2506.18187</link><description>Background: 
本文研究了抗精神病药物非依从性与精神分裂症患者不良结局之间的关联。通过生存分析方法，重点关注首次出现多个不良事件（早期死亡、强制住院、被拘捕）的时间，旨在通过使用各种生存模型来估计个体和平均治疗效果，以评估非依从性对患者的影响，并探讨长期信息（3、6、9和12个月）对分析结果的影响。研究数据来自美国宾夕法尼亚州西部的伊利 county。通过幸存者分析与因果推断工具的结合，研究发现，非依从性会将不良结果提前约1到4个月发生。并且通过去除县提供的风险评分来验证评估效果的可靠性。

Innovation: 
本文扩展了标准的因果推断方法（T-学习者，S-学习者，最近邻匹配），并结合不同生存模型，用于估计个体和平均治疗效果，特别是在精神分裂症患者的非依从性对不良事件影响的研究中。此外，通过对比不同时间段的数据分析，进一步验证了非依从性的不良影响，并利用幸存者分析与因果推断工具相结合的方法，从而提供政策相关见解。

Conclusion: 
研究表明，药物非依从性会导致精神分裂症患者提前出现不良事件，并且通过整合生存分析与因果推断工具，可以获得有意义的政策相关见解。同时，作者提醒，虽然使用了因果推断方法，但所作的结论只是关联性的，并讨论了因果解释所需的假设。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18187</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>414. cs.AI-关于不确定性的推理：推理模型是否知道它们不知道？</title><link>https://arxiv.org/pdf/2506.18183</link><description>Background: 
基于语言的模型已经在许多具有挑战性的基准测试中达到了最先进的（SOTA）记录，这主要是由于多步推理的引入，而这种多步推理是通过强化学习实现的。然而，像之前的语言模型一样，推理模型容易生成自信且看似合理的错误响应（幻觉）。因此，了解何时以及在多大程度上信任这些模型对于理性推理模型在现实世界应用中的安全部署至关重要。有鉴于此，本文探讨了推理模型的不确定性量化问题。具体而言，文章提出了三个基本问题：推理模型是否经过良好校准？更深的推理是否能改善模型的校准？此外，受到人类内在验证答案并检查其信心机制的启发，问及推理模型能否通过显式地回溯其推理过程来提高其校准度？研究人员探究了这一假设，结果显示：(i) 推理模型通常过高自信，它们对错误答案的自我评估信心常常超过85%，(ii) 更深入的推理会使模型更加过于自信，(iii) 通过内省（如o3-Mini和DeepSeek R1），推理模型可以通过反思性地进行反思变得更好校准，但并非一致地（例如Claude 3.7 Sonnet变得更容易校准较差）

Innovation: 
本文提出了一种新的方法，即“反思性不确定性量化”技术，这种技术能通过令模型反思其推理过程以提高其校准度。此外，研究发现了多种最新的推理模型在不确定性的表现上存在显著的差异，这对模型设计和未来的基准测试提出了新的指导方向。

Conclusion: 
该研究明确了理性推理模型在不确定性的表示方面的不一致性问题，并提出了重要研究方向，旨在设计必要的不确定性量化基准，以提高理性推理模型的校准度。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18183</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>415. cs.AI-Chain-of-Memory：增强跨应用导航的GUI代理</title><link>https://arxiv.org/pdf/2506.18158</link><description>Background: 
现有的图形用户界面（GUI）代理主要依赖于历史截图或操作来隐式表示任务状态，这种方法在理解任务状态和处理复杂、长时间跨应用程序的任务时面临挑战，缺乏有效的机制来存储关键信息。

Innovation: 
提出了一种名为Chain-of-Memory（CoM）的新方法，用于在GUI代理中显式建模短期和长期记忆。CoM通过捕获操作描述、整合任务相关信息，并维持一个专门的记忆模块来存储和管理这些信息，利用明确的记忆表示，使GUI代理能够更好地理解任务状态并持久地保留关键历史信息。此外，开发了GUI Odyssey-CoM数据集，包含111,000个屏幕-操作对，并标注了Chain-of-Memory，以增强GUI代理的内存管理能力并评估CoM的有效性。实验结果表明，CoM显著提高了GUI代理在跨应用任务中的性能。同时，GUI Odyssey-CoM使7B模型具备与72B模型相当的记忆管理能力。数据集和代码将开源。

Conclusion: 
Chain-of-Memory方法通过引入专门的记忆模块，显著提高了GUI代理在执行跨应用任务时理解任务状态和保留关键历史信息的性能。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18158</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>416. cs.AI-通过人类视角看AI：探索机器心理学中的认知理论</title><link>https://arxiv.org/pdf/2506.18156</link><description>Background: 
研究发现，大型语言模型（LLMs）在心理学的四个框架下表现出类似人类的认知模式，分别是主题联想测验（TAT）、框架偏见、道德基础理论（MFT）和认知失调。通过结构化的提示和自动评分评估多个专有和开源模型，研究揭示了这些模型常生成连贯的故事，对正面框架表现出敏感性，展现出与自由/压迫有关的道德判断，并且在合理化过程中表现出自相矛盾但被控制的状态。这类行为反映了人类的认知倾向，但受其训练数据和对齐方法的影响。

Innovation: 
采用标准化提示和自动评分的方法评估多种专有和开源的语言模型，研究了它们在心理学框架下的表现，特别是在正面框架下的反应、道德判断方面表现出的倾向，以及自相矛盾现象的合理化处理。这些模型的行为既反映了人类的认知倾向，又受到其数据训练和对齐方法的影响。这一研究提升了对语言模型理解人类行为和心理机制的理解，并为进一步结合认知心理学和AI安全的工作提供了新的视角。

Conclusion: 
这些研究结果表明，大型语言模型在某种程度上模仿了人类的认知模式。不过，它们的行为表现依然受到训练数据和算法设计的影响。因此，在AI的透明度、伦理部署以及未来将认知心理学与AI安全结合的研究方向上，存在着新的机遇和挑战。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18156</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>417. cs.AI-CoachGPT：一种结构化指导的学术写作助手</title><link>https://arxiv.org/pdf/2506.18149</link><description>Background: 
学术写作技能对学生的成功至关重要，但如果没有适当的指导和练习，尤其是在第二语言写作中，学生可能会感到压力过大。传统的方法是求助于教师或查阅字典，但这些手段并不总是普遍可及。早期的写作助手主要是基于规则的系统，专注于检测拼写错误、主谓一致问题和基本的标点符号错误，这些工具不够准确且缺乏上下文理解。即使基于机器学习的助手表现出强大的语言理解能力，但因其训练成本高昂，无法广泛应用。大型语言模型（LLMs）能够根据给定的提示生成自然语言的回答，显示出强大的潜力，但在教育领域，它们有一个根本局限：生成论文而不进行教学，这在误用时会对学习产生负面影响。

Innovation: 
我们开发了CoachGPT，这是一种利用大型语言模型（LLMs）的基于AI代理的网页应用，它（1）从经验丰富的教育者那里获取指令，（2）将指令转化为子任务，并（3）使用大型语言模型提供实时反馈和建议。这种独特的脚手架结构使其在现有的写作助手中独一无二。与现有的写作助手相比，CoachGPT提供了一种更加沉浸式的写作体验，并提供了个性化反馈和指导。我们的用户研究证明了CoachGPT的有用性和大型语言模型在学术写作中的潜力。

Conclusion: 
我们的用户研究证明了CoachGPT的实用性和大型语言模型在学术写作中的潜力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18149</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>418. cs.AI-SE-Merging: 一种自我增强的动态模型合并方法</title><link>https://arxiv.org/pdf/2506.18135</link><description>Background: 
模型合并因其独特的插值不同任务特定微调模型参数的能力而引起了越来越多的关注，这种能力能够实现多任务能力。尽管模型合并具有实际效果，但其背后的机制仍然不十分清楚。本研究从表示层面探讨了模型合并的机制，并发现模型合并实现多任务能力的关键是能够区分来自不同任务的数据样本，并为每个样本适配相应的专家模型。这种机制使得合并后的模型能够保持任务特定的专业知识，从而实现高效的多任务适应。

Innovation: 
本研究提出了一种自我增强的模型合并框架texttt{SE-Merging}，该框架利用两个关键特性：区分不同的任务样本和为每个样本适应相应的专家模型。该框架能够在无需额外训练的情况下实现动态模型合并，并通过动态识别每个样本对应的任务来增强任务特定的专业知识。实验结果表明，texttt{SE-Merging} 方法不仅实现了显著的性能提升，还能与现有的模型合并技术兼容。

Conclusion: 
texttt{SE-Merging} 方法通过动态识别每个样本对应的任务并适应性地调整合并系数，能够在无需额外训练的情况下实现动态模型合并。这种方法保留了任务特定的专业知识，并通过自我增强机制进一步提升了合并模型的任务适应性，最终实现了显著的性能改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18135</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>419. cs.AI-基于共识推理的分层强化学习在多约束无人机追逃游戏中的去中心化应用</title><link>https://arxiv.org/pdf/2506.18126</link><description>Background: 
多旋翼无人机（UAV）系统在多约束追逃游戏（MC-PEG）中的多目标追求和回避问题引起了广泛的研究兴趣，并出现了许多有趣的应用。特别是，诸如协同回避与形成覆盖（CEFC）这样的任务，旨在最大化多目标区间的覆盖范围并协同避免捕食者，这些问题尤其具有挑战性，特别是在通信受限的条件下。这类问题涉及到障碍物响应、对手对抗、目标区域和群体动力学的综合处理，带来了高维度上的复杂性。

Innovation: 
本文提出了一种新颖的分层框架（即共识推理导向的分层强化学习，CI-HRL），该框架将目标定位交给高层策略，通过高效率地聚合邻居信息使代理感知全局信息，并通过局部状态达成共识；在低层策略中，通过一种新的多代理强化学习模块——共识导向的多代理通信（ConsMAC），结合替代训练基于多代理近端策略优化（AT-M）和策略蒸馏，实现了低层控制。实验结果验证了CI-HRL框架的有效性，提高了无人机群协同回避和任务完成的能力，提升了性能。

Conclusion: 
本文提出了一种新的CI-HRL分层框架，通过高层策略和低层策略的协同工作，有效解决了多约束下的多旋翼无人机（UAV）在追逃游戏（PEG）中的复杂问题，提升了无人机群的协同回避和任务完成能力。该方法通过共识推理和多代理通信机制，实现了高效的多目标区域覆盖，并克服了通信受限的挑战。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18126</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>420. cs.AI-深度研究代理：系统审查与 roadmap</title><link>https://arxiv.org/pdf/2506.18096</link><description>Background: 
大型语言模型（LLMs）的迅速进步催生了一类新的自主AI系统，称为深度研究代理（DR代理）。DR代理旨在利用动态推理、适应性长期规划、多跳信息检索、迭代工具使用以及生成结构化分析报告来解决复杂的多轮信息研究任务。本文对构成深度研究代理的基础技术和架构组件进行了详细分析，包括信息获取策略、模块化工具使用框架以及现有方法的分类和评价，最后提出了未来研究的开放挑战和潜在方向。

Innovation: 
本文提出了DR代理的模块化工具使用框架，包括代码执行、多模态输入处理和模型上下文协议（MCPs）的集成，以支持延展性和生态系统开发；提出了一种分类方法来区分静态和动态工作流程，并基于规划策略和代理组成对代理架构进行了分类；提供了对现有基准的批判性评估，指出了外部知识访问受限、顺序执行效率低下和评估指标与DR代理实际目标不匹配等关键限制；最后为持续更新的DR代理研究资源库提供了一个链接。

Conclusion: 
本文系统地审查了DR代理，并提出了潜在的研究方向。通过系统分析现有技术和方法，为未来研究指明了方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18096</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>421. cs.AI-基于权重的假设基础论辩以推理伦理原则和行为</title><link>https://arxiv.org/pdf/2506.18056</link><description>Background: 
该研究基于假设基础论辩（Assumption Based Argumentation, ABA）进行扩展，引入了论辩权重的概念。研究者通过详细的问题实例展示了伦理推理中的应用，并给出了基于答案集编程（Answer Set Programming）的实现方法。

Innovation: 
论文引入了论辩权重的概念，将其应用于假设基础论辩中，通过权重计算攻击的强度。这种方法为伦理原则和行为的推理提供了一种新的模式，并且提供了基于答案集编程的具体实现方案。

Conclusion: 
本文提出了一种新的方法，将权重论辩应用于假设基础论辩，为伦理问题的论辩提供了新的视角和工具。通过具体的应用示例和编程实现，这一方法的有效性和实用性得到了验证。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18056</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>422. cs.AI-Action Language BC+</title><link>https://arxiv.org/pdf/2506.18044</link><description>Background: 
行动语言是自然语言的一部分，用于描述行动效果的形式化模型。早期研究表明，这些语言可以被视为受控的ASP（回答集编程）语言的高级表示方式，但这种早期的ASP语言其形式非常局限，无法涵盖现代ASP语言中的多种有用知识表示构造，例如选择规则、聚合、和抽象约束原子。

Innovation: 
本文提出了新的行动语言BC+，旨在弥合行动语言与现代ASP语言之间的差距。BC+的语言语义被定义为命题公式的通用稳定模型语义，使得现代ASP语言中的许多构造都可以视作命题公式的快捷方式。BC+语言足够灵活，能够包含其他行动语言的最佳特征。而且，既可以使用现有的ASP求解器计算BC+语言，也可以通过扩展cplus2asp系统来实现BC+语言的计算方法，这使得BC+语言能够被直接应用和扩展。

Conclusion: 
BC+语言提供了一个强大的框架，适用于表示和处理行动相关事件，并且其与现代ASP语言的紧密联系使其能够利用现有的计算方法和工具进行处理。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18044</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>423. cs.AI-Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities</title><link>https://arxiv.org/pdf/2506.18019</link><description>Background: 
介绍了AI代理的发展历程，从早期依靠强化学习（RL）占据主导地位，到现在的以大语言模型（LLMs）为主的阶段，并正在朝向RL和LLMs能力的协同融合前进。在此基础上，高品质的数据结构化对于使代理更好地处理复杂现实任务变得至关重要。现有的研究正在探索如何利用图技术来增强代理的关键功能，并通过指明未来研究的方向，促进下一代具备处理高阶挑战能力的AI代理开发。

Innovation: 
本研究提出了一种系统化的分析框架，探讨图技术如何增强AI代理，特别强调了图技术与代理核心功能的集成，展示了典型的应用案例，并指出了未来研究的潜力方向，以激发对图技术如何协助先进AI代理发展的思考和探索。

Conclusion: 
本综述旨在通过全面系统地研究图表技术在AI代理中的应用，激发和促进下一代AI代理的发展，使其能够更好地应对复杂的现实挑战。同时，还汇总了相关资源以支持该领域的持续研究和改进。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18019</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>424. cs.AI-medicX-KG：药师用药信息需求的知识图谱</title><link>https://arxiv.org/pdf/2506.17959</link><description>Background: 
药师的角色正在从药品分发转向在多学科医疗团队中提供全面的药学服务。这一转变的核心是获取准确、最新的药品信息，支持坚实的数据集成。利用人工智能和语义技术，知识图谱揭示隐藏的关系并促进数据驱动的决策。研究报道了针对临床和法规决策的药师知识图谱medicX-KG。medicX-KG 支撑更广泛的 medicX 平台，提供了预测性和可解释性的药房服务。medicX-KG 结合了英国国家处方集（BNF）、DrugBank 以及马耳他药品管理局（MMA），解决了马耳他的监管环境，以及与欧洲药品管理局和部分英国药物供应相关的欧盟协调

Innovation: 
medicX-KG 是一个面向药师的知识图谱，支持临床和监管决策。它是一个集成了来自三个主要数据源（英国国家处方集、DrugBank 和马耳他药品管理局数据）的语义层。medicX-KG 解决了缺乏统一国家药物数据库的问题，减少了药师对碎片化信息源的依赖。通过与实际操作中的药师进行访谈，确保知识图谱的实际适用性。评估证明，medicX-KG 能够有效支持药品可用性、相互作用、不良反应和治疗类别的查询。

Conclusion: 
尽管 medicX-KG 在详细的剂量编码和实时更新方面存在限制，但研究仍展示了其在药学服务中的巨大潜力。未来的改进方向包括完善剂量编码和实施实时更新系统。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17959</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>425. cs.AI-演化内文提示：一种开放性自我复制视角</title><link>https://arxiv.org/pdf/2506.17930</link><description>Background: 
尽管传统上认为精心设计的指令和演示对于在上下文学习中至关重要，但本文提出的研究表明，将随机演示精简为看似无意义的“垃圾信息”可能会显著提高各种任务的性能。这种做法能够与自动提示优化技术保持一致或超越，无论是在模型对齐还是性能提升方面。然而，找到有效的精简策略并非易事，现有的归因方法和提示压缩算法无法提供可靠的结果，也难以依赖人的直觉。因此，本文提出了PromptQuine这一自我探索的提示优化框架，这是一种进化搜索框架，能够在数据量较少的情况下自动搜索最优的精简策略。这种框架通过利用上下文中仅有的词汇来进行演化和优化，从而产生新颖而高效的提示。

Innovation: 
本文提出的新型提示设计范式挑战了传统智慧，强调了将随机演示精简为看似无意义的“垃圾信息”能够显著提升性能。更重要的是，提出了自我探索的提示优化框架PromptQuine，这是一种进化搜索框架，能够在数据量较少的情况下自动搜索最优的精简策略。这种方法通过利用上下文中仅有的词汇来进行演化和优化，从而产生新颖而高效的提示，展现了在不同任务中的广泛应用。

Conclusion: 
本文的研究成果有望指导对在上下文学习机制的研究，并提倡发展更具开放性的搜索技术，以提高大型语言模型提示的有效性。通过展示该方法在分类、多项选择题回答、生成和数学推理等任务上的有效性，强调了其作为一种有潜力的提示设计策略的广泛应用前景。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17930</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>426. cs.AI-利用大型语言模型进行云AI平台智能日志处理和自主调试</title><link>https://arxiv.org/pdf/2506.17900</link><description>Background: 
随着云计算平台中AI系统的复杂性和规模迅速扩大，系统运行过程中生成的日志数据量巨大、结构不规范且语义含糊，这给故障定位和系统自愈带来了巨大挑战。

Innovation: 
本文基于预训练的Transformer模型提出了一种基于大型语言模型（LLM）的智能日志处理和自动调试框架，名为Intelligent Debugger (LLM-ID)。该方法融合了多阶段语义推理机制，实现了系统日志的上下文理解以及故障链路的自动重建。该模型具有更强的语义理解能力、持续学习能力和异构环境适应性，实验结果表明LLM-ID在云平台日志数据集上将故障定位精度提高了16.2%，显著优于现有主流方法。

Conclusion: 
该研究提出的Intelligent Debugger (LLM-ID)框架能够通过多阶段语义推理机制及其他技术手段，有效提升了云计算平台中复杂AI系统的故障定位和自愈能力，并通过实验验证了其在实际应用中的显著优势。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17900</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>427. cs.AI-稳健的证据检索的多代理系统：事实核查走向</title><link>https://arxiv.org/pdf/2506.17878</link><description>Background: 
数字时代信息传播的迅速加速带来了对公共讨论的重大挑战，这需要强大的、可扩展的事实核查解决方案。传统的人工事实核查方法虽有可信度，但难以应对在线内容的庞大体量和快速速度。因此，迫切需要整合基于大型语言模型（LLMs）的自动化系统。然而，现有的自动化方法在处理复杂声明、确保来源可信度以及保持透明度方面存在局限性。

Innovation: 
本文提出了一种用于自动事实核查的新颖多代理系统，提高了准确性、效率和可解释性。该系统包括四个专门的代理：输入摄入代理负责声明分解、查询生成代理负责制定有针对性的子查询、证据检索代理负责从可信来源获取可靠的证据、判决预测代理负责综合合成可信度判断，产生人类可解释的解释。该系统在基准数据集（FEVEROUS、HOVER、SciFact）上的评估结果显示，与基线方法相比，系统的宏F1分数提高了12.3%。该系统能够分解复杂的声明、从可信来源检索可靠的证据，并生成可解释的验证决策。

Conclusion: 
本文为自动事实核查领域做出了贡献，提供了一种更准确、更高效、更透明的验证方法，同时保持了与人类事实核查实践的一致性，以实现大规模应用。所有来源代码均可在此链接访问：this https URL</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17878</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>428. cs.AI-失控之外 —— 为何齐心一致需要正式的控制理论（以及一个齐心一致控制堆栈）</title><link>https://arxiv.org/pdf/2506.17846</link><description>Background: 
本文的背景是，尽管近年来在AI安全和机制可解释性方面的研究已经推进了符合形式的方法来实现齐心一致，但这些方法往往未能达到其他技术领域控制框架所需的一般化程度。此外，缺乏关于如何使不同齐心一致/控制协议相互操作的研究。传统的齐心一致方案未能充分结合控制理论进行建模，特别是在物理到社会-技术层面上的控制应用方面缺乏明确的层级结构。因此，本文试图重新界定齐心一致问题，以正式最优控制原则为基础，并以层次化的堆栈形式从物质到社会-技术层面进行框架结构，以更好地理解前沿模型和自主AI系统的控制潜力及其限制。通过引入一个‘齐心一致控制堆栈’，本文明确描述了每一层的测量和控制特性，以及层次间的正式互操作性，同时强调这一分析对政策制定者和监管者所需的可信性保障至关重要，确保AI技术能够可持续地造福社会。

Innovation: 
本文提出了‘齐心一致控制堆栈’，这是一种层次化的堆栈结构，从物理层到社会-技术层分级描述齐心一致和控制特性，强调通过引入正式的最优控制理论重新框架齐心一致的重要性和必要性。这一创新填补了现有齐心一致方法在控制框架和实际部署考虑之间的空白，为高级AI系统的安全性与可靠性提供了一个更为全面的框架。

Conclusion: 
本文提出了通过使用正式的控制理论来实现AI齐心一致的新途径，并通过‘齐心一致控制堆栈’为改变现有齐心一致方法提供了可能。这种分析对于未来的齐心一致性研究至关重要，有助于确保AI技术能够更好地造福社会。该结论强调，这样的分析将传统的、经过验证的最优控制方法与实际部署考虑相结合，为高级AI系统的安全性和可靠性提供了一个更为全面的框架。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17846</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>429. cs.AI-多元共存对话语义奖励设计</title><link>https://arxiv.org/pdf/2506.17834</link><description>Background: 
传统的基于人类反馈的强化学习（RLHF）方法通常通过单一的奖励模型将人工智能代理与人类价值观对齐，但这种方法面临将多样的人类价值观汇聚为单一模型时可能抑制少数群体偏好风险。本研究探讨了一种适应不同个体价值的新方法，通过引导用户进行反思性对话来设计个性化的奖励模型，从而实现更加多元的对齐。

Innovation: 
本文提出了一种新颖的个性化奖励建模方法，通过引导用户进行反思性对话，收集用户的反馈和批判性意见，并将其作为个性化奖励函数的上下文。这种方法通过利用语言模型来设计个性化的奖励模型，能够更有效地利用有限样本数据，同时提高对齐准确性。与传统的监督学习方法相比，该方法在30名参与者的研究中表现出9-12%的准确性提升，并且更为样本高效。

Conclusion: 
该研究表明，通过引导用户进行反思性对话，设计个性化的奖励模型可以在保持监督学习效率的同时提高多模态价值观对齐的准确性。这种方法为处理多样且往往是冲突的价值观提供了新的思路，有助于构建更加包容和多样的人工智能系统。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17834</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>430. cs.AI-通过分层块分解进行MDP的有效策略合成</title><link>https://arxiv.org/pdf/2506.17792</link><description>Background: 
软件密集型系统，如软件产品线和机器人技术，利用马尔可夫决策过程（MDPs）来捕捉不确定性并分析序列决策问题。尽管传统的策略合成方法在很多情况下都非常有用，但对于大规模状态空间，这些方法难以扩展。因此，有必要开发一种能够提高大型MDPs策略合成效率的新方法，通过动态细化MDP并在必要的时候迭代选择最脆弱的区域进行细化，以平衡精确性和效率之间的关系，从而解决大规模MDPs中积累的成本高的问题，提供一种在实际环境中合成更大MDPs政策的竞争解决方案.

Innovation: 
该方法通过分层块分解来高效合成MDP策略，该方法动态细化MDP，并在必要的时候迭代选择最脆弱的MDP区域进行细化。这种方法通过平衡精确性和效率之间的关系，解决了传统方法难以扩展到大规模状态空间的问题，提供了一种替代现有解决方案，如领先的概率模型检查器PRISM，能够显著提高策略合成的性能（提高2倍），并在多种案例研究和最大100万状态的MDP中进行了评估，显示了其实际应用潜力.

Conclusion: 
该研究通过分层块分解提出了一个有效的方法来提高大型MDPs策略合成的性能，并通过广泛的实验证明了这种方法在准确性和效率方面提供了显著的优势，特别是在实际应用中，能够更好地满足大系统的需求，提供了在更大MDP中的策略合成问题的竞争力解决方案.</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17792</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>431. cs.AI-基于图引导语言模型的贝叶斯社会推理</title><link>https://arxiv.org/pdf/2506.17788</link><description>Background: 
社会推理——从部分观察到其他代理的不可观测信念和意图——仍然是大型语言模型（LLMs）面临的一大挑战。作者们在Avalon社会推理游戏中评估了当前社会推理语言模型的能力，发现尽管最大的模型表现较好，但在小型化或实时化时性能急剧下降。

Innovation: 
作者提出了一种混合推理框架，将信念推理外部化到结构化的概率模型，同时利用语言模型进行语言理解和互动。这一方法在代理间对抗中取得了与更大模型相当的表现，并首次实现了语言代理在控制研究中击败人类玩家，胜率为67%，并且获得了比基准模型和人类队友更高的定性评价。此外，作者还开源了代码、模型和数据集以支持未来对该领域的研究。

Conclusion: 
该研究通过开源代码和模型，为未来的社会推理研究提供了支持，并提出了一个混合推理框架，在Avalon游戏中实现了具有创新性的性能，特别是击败了人类玩家。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17788</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>432. cs.AI-AnyMAC: 通过Next-Agent预测实现灵活多智能体协作的级联结构</title><link>https://arxiv.org/pdf/2506.17784</link><description>Background: 
大规模语言模型（LLM）驱动的多智能体协作展示了结构化通信在促进集体智能方面的作用。然而，现有的方法主要依赖静态或图基的智能体间拓扑结构，缺乏沟通的适应性和灵活性。

Innovation: 
本文提出了一种新的框架，通过顺序结构而非图结构重新思考多智能体协调，提供了更大的多智能体通信拓扑空间。方法集中在两个关键方向：（1）Next-Agent预测，选择每个步骤中最合适的智能体角色；（2）Next-Context选择（NCS），使每个智能体能够选择性地访问任何先前步骤中的相关信息。这些组件构建了适应任务的通信管道，支持角色灵活性和全局信息流动。

Conclusion: 
在多个基准上的广泛评估表明，该方法在性能上优于现有方法，同时显著降低了通信开销。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17784</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>433. cs.AI-超越语法：App代理的动作语义学习</title><link>https://arxiv.org/pdf/2506.17697</link><description>Background: 
大型语言模型（LLMs）的出现推动了应用程序代理的发展，这些代理能够解读用户意图并使用点击和滚动等操作来操作手机应用程序。虽然基于提示的解决方案显示出巨大的潜力，但它们会引发巨大的计算成本和对外部API的依赖。通过微调较小的开源LMs来解决这些限制，但当前的微调方法使用了一种语法学习范式，迫使代理精确复制地面真相动作字符串，导致了分布外（OOD）的脆弱性。

Innovation: 
本文提出了动作语义学习（ASL），这是一种新的学习框架，其学习目标是捕捉地面真相动作的语义。这种方法借鉴编程语言理论，将动作的语义定义为在用户界面中由动作引起的状态转换。ASL使用了新的语义估计器（SEE）来计算语义奖励，以训练应用程序代理生成与地面真相动作语义对齐的动作，即使其语法形式不同也是如此。此外，ASL从理论上证明了其在处理OOD问题时比现有语法学习范式更具有鲁棒性。实验证明，在手机应用程序的操作基准测试中，ASL显著提高了应用程序代理的准确性和泛化能力。

Conclusion: 
ASL在离线和在线手机应用程序操作基准测试中显著提高了现有方法的准确性和泛化能力，表明它能够有效地解决分布外问题，同时处理应用程序代理生成动作时的语法形式差异。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17697</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>434. cs.AI-PhysUniBench：用于多模态模型的大学水平物理推理基准</title><link>https://arxiv.org/pdf/2506.17667</link><description>Background: 
物理问题解决对于大型AI模型是一个具有挑战性的领域，需要融合概念理解、数学推理以及物理图示的解释。现有的评估方法在捕捉大学物理学水平的广度和复杂性方面存在明显局限，这凸显了需要更严格的评估方法。鉴于此，本研究提出了一种大规模多模态基准工具——PhysUniBench，旨在评估和改进多模态大型语言模型在大学物理学问题上的推理能力。该基准包含3,304个涵盖8大物理子学科的问题，每个问题都伴有1个图表，并且包含开放式和选择题类型的问题，通过迭代模型在环过程系统地进行审核和难度评级。初步实验表明，当前最先进的模型在物理推理中面临着巨大挑战，例如GPT-4o mini在PhysUniBench中的准确率仅为34.2%。这些结果表明，当前的多模态大型语言模型在高级物理推理、尤其是多步骤问题以及需要精确图示解释的问题上存在困难。因此，PhysUniBench 旨在促进AI在科学中的应用，并鼓励开发在物理推理、问题解决能力和多模态理解方面更强的模型。

Innovation: 
PhysUniBench是针对多模态大型语言模型（MLLMs）的一个大规模多模态基准，用于评估其在大学水平物理问题上的推理能力。该基准包括多个子学科的广泛问题集，并通过多轮迭代和专家审核过程确保问题质量和难度分级的准确性。通过这种基准，研究人员可以更好地评估和改进模型的物理推理能力，促进科学计算领域的发展。

Conclusion: 
PhysUniBench通过提供一个广泛而严格的评估工具，旨在推动AI在科学中的应用。实验结果表明，当前最先进的模型在某些类型的复杂物理问题上表现不佳，特别是在多步骤推理和精确图表解释方面。未来的研究可以通过使用PhysUniBench来指导模型的发展，提高其物理推理和问题求解能力。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17667</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>435. cs.AI-测量和增强大型语言模型以解决夺旗挑战</title><link>https://arxiv.org/pdf/2506.17644</link><description>Background: 
夺旗（CTF）竞赛是网络安全教育和培训的重要组成部分。随着大型语言模型（LLMs）的发展，人们越来越关注其自动生成CTF挑战解决策略的能力。例如，DARPA自2023年起组织了AIxCC竞赛，旨在推动人工智能驱动的自动化进攻和防御发展。然而，这需要各种能力的结合，从知识到推理，再到执行策略。

Innovation: 
本文强调了在解决CTF问题中技术知识的重要性，并特意构建了一个集中式的基准测试——CTFKnow，包含3,992个问题来衡量LLMs在此核心方面的表现。研究提出了CTFAgent，一个基于LLM的新颖框架，用于推进CTF问题解决。CTFAgent引入了两个新的模块：两阶段检索增强生成（RAG）和互动环境增强，这些模块分别增强LLMs的技术知识和漏洞利用能力。我们的实验结果显示，在两个流行的CTF数据集中，CTFAgent实现了超过80%的表现改进。此外，在CMU主办的picoCTF2024竞赛中，该框架在近7,000支参赛队伍中排名前23.6%，显示出该研究的价值以及框架在提升LLMs解决CTF问题能力上的潜力。

Conclusion: 
本研究提供了一种专注于测量和评估LLMs在理解CTF知识并将其应用于解决CTF挑战方面的能力。通过从测量研究中获得的洞察，提出CTFAgent框架，以进一步促进CTF问题解决。CTFAgent框架通过增强LLMs的技术知识和漏洞利用能力，实现了显著的性能提升和比赛中的优异表现。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17644</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>436. cs.AI-驯服未解之谜：基于图的知识检索与推理方法使MLLMs攻克未知</title><link>https://arxiv.org/pdf/2506.17589</link><description>Background: 
知识的价值不仅在于积累，更在于其被有效利用以应对未知领域的能力。虽然近期的多模态大型语言模型（MLLMs）展示出卓越的多模态能力，但它们在罕见的特定领域任务中常常表现不佳，原因在于它们的相关知识有限。为了解决这个问题，该研究采用视觉游戏认知作为实验平台，选取《 Monster Hunter: World》作为目标构建一个多模态知识图（MH-MMKG），该图整合了多模态和复杂的实体关系，并设计了一系列基于MH-MMKG的挑战查询来评估模型的复杂知识检索和推理能力。此外，该研究提出了一种多代理检索器，使模型能够自主搜索相关知识，无需额外训练。实验结果表明，该方法显著提升了MLLMs的性能，为多模态知识增强推理提供了新视角，并为未来研究奠定了坚实基础。

Innovation: 
该研究通过构建多模态知识图（MH-MMKG）并设计一系列复杂查询，评估MLLMs的复杂知识检索和推理能力。更重要的是，该研究提出了一种多代理检索器，使模型能够自主搜索相关知识，无需额外训练，这为MLLMs在面对未知领域时提供了新的应对策略。

Conclusion: 
实验结果证明，该方法显著提升了MLLMs的性能，为多模态知识增强推理提供了新视角，并为未来研究奠定了坚实基础。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17589</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>437. cs.AI-Cite Pretrain: 无需检索的知识归因方法</title><link>https://arxiv.org/pdf/2506.17585</link><description>Background: 
信任的语言模型应该提供正确且可验证的答案。当前的语言模型常常将输出归因于预训练数据，但由于虚构问题的存在，其引用往往是不可靠的。因此，现有系统通过在推理时查询外部检索器来插入引用，这带来了延迟、基础设施依赖和检索噪音的脆弱性。为此，研究探讨了一种新的方法，即在持续预训练期间使语言模型能够可靠地归因于查看过的文档（无需测试时检索），并通过修订训练过程来实现这一目标。

Innovation: 
该研究提出了一种新的方法，称为CitePretrainBench，这是一个包含现实世界语料库（维基百科、通用爬虫、arXiv）以及未见过的新文档的基准测试，旨在评估语言模型在无需检索的情况下能否可靠地归因于预训练期间见过的文档。研究发现传统的被动索引方式虽然有助于记忆逐字文本，但在处理重述或组合事实时会失败，因此提出了一种新的主动索引方法，该方法在预训练中使用合成的问答对，既要求在不同组合形式中重述每个事实，又要求双向生成源到事实和事实到源的内容，以教会模型从被引用的来源生成内容，并为自己的回答分配来源。实验证明，主动索引方法在所有任务和模型中都优于被动索引方法，提升了高达30.2%的引用精准度。

Conclusion: 
研究结果表明，通过在更大规模的数据集上增加提成，主动索引方法的性能继续保持提升趋势，显示出明显的向上势头，即使数据量增加至原来的16倍。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17585</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>438. cs.AI-多智能体仿真中的万花筒团队</title><link>https://arxiv.org/pdf/2506.17514</link><description>Background: 
近年来，由于自主工具使用能力和在各种现实世界应用中的集成，人工智能代理受到了广泛关注。这种自主性为这些系统的安全性带来了新颖的挑战，特别是在单智能体和多智能体情景中。现有的红队或安全性评估框架在评估复杂行为、思维过程和智能体采取的行动中的安全风险方面存在局限性，无法考虑多智能体设置中的各种漏洞，当智能体相互进行复杂行为和交互时，这些漏洞会暴露出来。

Innovation: 
本文提出了一种新的‘万花筒团队’概念，以捕捉单智能体和多智能体情景中发生的复杂和广泛的漏洞。与此同时，还介绍了一种新的‘万花筒团队’框架，能够生成多样化的场景，模拟现实世界的人类社会。框架能够在单智能体和多智能体设置下评估智能体的安全性。在单智能体设置下，智能体被赋予一个场景，需要使用可用工具完成；而在多智能体设置下，多个智能体要么相互竞争，要么合作完成任务，从而捕捉现有智能体中的安全漏洞。此外，还引入了新的上下文优化技术，用于生成更好的安全分析场景，并介绍了可以与框架结合使用的适当度量标准，以衡量智能体的安全性。作者通过‘万花筒团队’框架，识别出各种模型在智能体使用场景下的安全性漏洞问题。

Conclusion: 
本文提出了一种新的‘万花筒团队’方法和框架，用于评估单智能体和多智能体智能体的安全性，并通过在不同模型中的应用，识别出了智能体使用中的安全性问题。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17514</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>439. cs.AI-从非结构化通信到智能RAG：多代理自动化供应知识库</title><link>https://arxiv.org/pdf/2506.17484</link><description>Background: 
供应链操作产生大量操作数据，但系统使用实践、故障排除工作流和解决问题的技术等关键知识往往被埋没在支持票、电子邮件和聊天记录等非结构化通信中。现有RAG系统虽然试图将这些通信作为知识库，但由于原始数据的噪音、不一致性和不完整性，直接检索效果受限。现有RAG方法主要关注运行时优化，而本文提出了一种新的离线优先方法，将这些通信转化为结构化知识库。

Innovation: 
文章提出了基于LLM的多代理系统，该系统包括三个专门代理：分类发现用于创建分类体系，分类用于票据分组，知识合成用于文章生成。通过将实际支持票务与解决方案注释和评论应用到该方法中，文中系统创建了一个紧凑的知识库，减少了数据总量的96.6%同时提升了质量。实验表明，预构建的知识库在RAG系统中显著优于传统的RAG实现，减少了77.4%的无用响应。通过自动化捕获通常局限于专家头脑中的机构知识，该方法提高了操作效率：减少了支持工作量，加速了解决时间，并创建了能够自动解决约50%未来供应链票务问题的自优化系统。

Conclusion: 
该方法通过智能离线处理将临时通信转化为可重复使用的知识结构，填补了知识管理中的关键空白，而不是引入引起延迟的运行时架构。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17484</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>440. cs.AI-OmniReflect: 通过神经符号反思发现可转移宪法的LLM代理</title><link>https://arxiv.org/pdf/2506.17449</link><description>Background: 
为了提升大型语言模型（LLM）代理在复杂任务上的表现，研究主要集中在模型微调和迭代自我纠正上。然而，这些方法在长期学习机制的普遍性和动态环境中的效率方面存在局限性。本文分析了这一背景，指出现有方法在这些方面存在的不足。

Innovation: 
本文提出了OmniReflect框架，它是一个分层、基于反思的架构，通过从任务经验中提炼议会宪章来提升LLM代理的有效性和效率。OmniReflect有两种模式操作：自维持模式下，单个代理在任务执行期间定期整理其反思；合作模式下，超顾问从小型校准集中提炼出宪法来指导其他代理。同时，采用神经、符号和神经符号技术来平衡上下文适应性和计算效率。实证结果表明，OmniReflect在不同的任务上显著提升了代理的成功率，特别是在自维持模式下，不同模型均有10.3%-23.8%的绝对提升。在合作模式下，轻量级的Qwen3-4B ReAct代理在BabyAI上也超越了所有反射基线。

Conclusion: 
研究结果强调了OmniReflect在不同环境和模型基础下的稳健性和有效性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17449</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>441. cs.AI-维护医疗AI系统的健康：系统退化检测与纠正方法综述</title><link>https://arxiv.org/pdf/2506.17442</link><description>Background: 
AI技术在现代医疗中的应用日益广泛，为临床决策提供了强大的支持。然而，在实际应用中，AI系统可能会随着时间的推移而出现性能下降，这可能由数据分布变化、患者特征变化、临床操作规程演变以及数据质量差异等多种因素引起。这些因素会削弱模型的可靠性，导致不准确的预测或不良结果，从而引发安全问题。因此，对于AI系统的持续性能监控、早期性能下降检测和有效的自我纠正机制的需求变得尤为迫切。

Innovation: 
该论文回顾了数据和模型层面引起性能下降的常见原因，并总结了检测数据和模型漂移的关键技术。进一步深入探讨了根本原因分析，并审查了从模型重新训练到测试时适应等多种纠正策略。研究涵盖了传统机器学习模型和最新的大型语言模型（LLMs），提供了它们各自的优势和局限性见解。同时，本文指出了当前的技术挑战，并提出了未来的研究方向，旨在指导开发可靠、健壮的医疗AI系统，使其能够在不断变化的临床环境中安全且长期地部署。

Conclusion: 
本文旨在综述检测和纠正医疗AI系统退化的现有方法，并提出在动态临床环境中实现可靠、健壮的长期部署的未来研究方向。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17442</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>442. cs.AI-资源理性的契约主义应引导AI对齐</title><link>https://arxiv.org/pdf/2506.17434</link><description>Background: 
未来的AI系统将在人类环境中导航，并做出可能影响人类和其他AI代理人的决定。这些代理人的目标和价值观可能存在分歧。合同主义对齐试图通过多样利益相关者可能在合适的条件下认可的协议来引导这些决策，但这种规模下的协议难以确保且成本高昂。因此，研究者提出了一种新的框架：资源理性的契约主义（RRC），该框架让AI系统通过采用一系列基于规范的认知启发方法来近似于理性的参与方会形成的协议，从而在准确性和努力之间做出权衡。

Innovation: 
资源理性的契约主义（RRC）是一种新的AI对齐框架。它利用一套基于规范的认知启发方法，让AI系统能够近似于理性的参与方形成的协议，从而在准确性和努力之间权衡。这种方法不仅可以让AI系统高效运行，还可以使它们适应并理解不断变化的人类社会环境。

Conclusion: 
一种资源理性的契约主义AI系统将不仅能够高效运作，还能够动态适应并解释不断变化的人类社交世界。这种新的方法为未来AI系统的对齐提供了一种新的途径。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17434</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>443. cs.AI-个体因果推理中结构因果模型的应用</title><link>https://arxiv.org/pdf/2506.17300</link><description>Background: 
个体因果推理(ICI)使用因果推理方法来理解并预测干预措施对个体的影响，同时考虑他们的特定特征/事实。由于有限的个体数据和大多数因果推理方法侧重于整体，导致估计个体因果效应(ICE)具有挑战性。结构因果模型(SCM)本质上是基于整体的，因果发现(结构学习和参数学习)、关联查询和干预查询都是基于整体的，但在SCM中的外生变量(U)可以编码个体差异，为个性化提供机制。在此基础上，我们提出了ICI与SCM作为一种“第三层级”的因果推理，因为它涉及到根据个人的观察特征/事实，想象某一假设干预措施的因果效应。

Innovation: 
基于结构因果模型(SCM)，我们提出了ICI(indiv)运算符(indiv(W))来正式化/表示个体化过程，并提出了个体因果查询P(Y | indiv(W), do(X), Z)来正式化/表示个体因果推理(ICI)。我们展示了并论证了使用SCM进行个体因果推理的假设是建立在个体替代性(可能的情况)而非个体反事实(非实际情况)的基础上。

Conclusion: 
个体因果推理与结构因果模型相结合，提供了一种基于个体特征的因果推断新方法，这种方法既考虑了个人差异，又避免了基于整体数据的因果推理方法的局限性。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17300</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item><item><title>444. cs.AI-通过提示在小型语言模型中评估泛化能力和表示稳定性</title><link>https://arxiv.org/pdf/2506.17289</link><description>Background: 
这篇论文研究了在两种常见的适应范式（少量示例提示和监督微调）下，小型语言模型的泛化能力。提示方法因为参数效率和灵活性被广泛使用，但在资源有限和分布变化的情况下，其鲁棒性仍存在不确定性。该研究在跨任务格式、提示风格和模型规模的背景下比较了提示方法和微调方法，关注其在分布内和分布外（OOD）设置下的表现。研究不仅关注准确度，还分析了每种方法学到的内部表示，以评估任务特定特征的稳定性和抽象性。研究结果突出了不同适应策略下小型模型如何内化和泛化知识的关键差异。这项工作为低数据环境下模型选择提供了实用指导，并在提示与微调的辩论中增加了实证见解。

Innovation: 
该研究进行了提示与微调方法的全面比较，特别关注小型模型在不同适应策略下的行为和内部表示稳定性。通过实证分析，区分了两者在泛化能力和任务特定特征的可靠性和抽象性方面的关键差异。这项工作首次在广泛的实验设置下详细探讨了两种方法在小型语言模型中的表现差异。实验代码开源以便其他人复现研究结果。

Conclusion: 
该研究发现提示方法和微调方法在小型语言模型中表现不同，提供了选择适应策略和模型在低资源环境中的实用指南，贡献了关于提示与微调持续辩论的实证见解。未来的研究可以进一步探索不同大小和架构的模型，并评估这些因素对两种不同适应策略的影响。</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17289</guid><pubDate>Tue, 24 Jun 2025 15:06:14 +0800</pubDate></item></channel></rss>