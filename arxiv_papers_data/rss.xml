<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Arxiv Papers Analyze AI</title><link>https://github.com/nituchao/latest_arxiv_analyze_ai</link><description>Arxiv papers analyzed by AI on 20250627</description><lastBuildDate>Fri, 27 Jun 2025 02:26:41 +0800</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>1. cs.SE-Anonymized Network Sensing Graph Challenge</title><link>https://arxiv.org/pdf/2409.08115</link><description>Background: 
MIT/IEEE/Amazon GraphChallenge 鼓励社区通过发展新的解决方案来分析来自社交媒体、传感器反馈和科学数据的图和稀疏数据，以发现事件之间的关系。匿名网络感应图挑战旨在促进大规模、开放的社区途径以保护网络，而这些途径高度注重隐私并需要社区的强烈支持。这类方法往往需要基于社区的数据共享。在更广泛的网络社区中（包括商业、联邦机构和学术界），匿名源到目的流量矩阵已经作为一种数据产品出现，可以通过标准的数据共享协议满足许多要求。此次挑战提供了利用全球最大互联网望远镜的数据优化和分析匿名化流量矩阵的新颖方法的机会，该望远镜的数据来源于超过1000亿个网络数据包。挑战明确规定了匿名化、构造和分析这些流量矩阵的方式。虽然提供了一个GraphBLAS参考实现，但是在此图挑战中使用GraphBLAS并不是必须的。先前的图挑战同样目的是为展示创新提供一个明确的背景。挑战参与者可以根据需要选择图挑战元素以突出展示其创新点（需附带解释说明）。

Innovation: 
该挑战鼓励社区开发新的解决方案来分析大规模稀疏数据，并利用匿名网络数据矩阵来优化和分析网络数据，展示了创新的方法来保护网络，并注重隐私保护和社区参与。挑战提供了新的数据产品，即匿名源到目的流量矩阵，并通过全球最大的互联网望远镜采集数据进行研究。

Conclusion: 
该挑战为网络社区提供了一个展示创新的机会，通过匿名化的网络感应数据矩阵的分析和优化，推动了大规模数据处理的需求，并强调了社区共享数据的重要性及隐私保护措施。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.08115</guid><pubDate>Fri, 27 Jun 2025 02:50:31 +0800</pubDate></item><item><title>2. cs.SE-大型语言模型赋能的C到Rust代码翻译代理</title><link>https://arxiv.org/pdf/2505.15858</link><description>Background: 
C语言在构建系统级软件方面基础性作用显著，但其手动内存管理模型常引发内存安全问题。因此，Rust作为一种内存安全的语言崭露头角。随着生成能力快速提升的LLM的发展，C到Rust的自动化翻译引起了广泛关注。尽管取得了一定成功，现有基于LLM的方法主要限于静态提示-响应行为，没有利用其自主解决问题的能力。与数学或常识推理等传统领域不同，C到Rust的翻译涉及复杂的中间步骤，但这些步骤并不明确，如何组织这些步骤以构建正确的翻译路径也并不清晰。因此，翻译这一任务给语言模型提出了特有的挑战，包括不充分的并行C到Rust数据集、未定义的中间步骤以及需要定义如何组织和串联这些步骤等方面的问题。

Innovation: 
提出了一个新的中间步骤——基于虚拟模糊测试的等价性测试（VFT）和一个生成性的规划框架——由大型语言模型驱动的C到Rust代码翻译代理（LAC2R）。VFT通过发现导致不同行为的输入参数，帮助LLM生成有信息量的诊断以修正Rust代码中的不安全部分。LAC2R使用MCTS系统化地组织由LLM引发的中间步骤，确保正确翻译。实验结果表明，LAC2R能够有效地对大规模的真实-world基准进行C到Rust的翻译。

Conclusion: 
本文提出了一种新的代理框架，用于解决C到Rust的翻译问题。通过引入VFT并利用MCTS组织中间步骤，LAC2R有效地克服了现有的挑战，并在大规模实际基准测试中展示了其有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.15858</guid><pubDate>Fri, 27 Jun 2025 02:50:19 +0800</pubDate></item><item><title>3. cs.SE-SceneGenAgent：基于编码代理的精确工业场景生成</title><link>https://arxiv.org/pdf/2410.21909</link><description>Background: 
工业制造的模拟需要工业场景的建模，而大型语言模型（LLMs）在生成从文本描述生成通用的3D场景方面取得了显著进展。然而，生成精确度要求高的工业场景具有挑战性，因为它们需要精确的测量和定位，并且需要对空间布局进行复杂的规划。现有的LLMs处理这一类问题面临不确定性。因此，需要一种基于编码的方法来确保精确的布局规划，并通过结构化的格式、布局验证和迭代优化来满足工业场景的定量要求。研究表明，通过SceneGenAgent可以超越原始性能，在真实世界的工业场景生成任务中成功率达到81.0%，并能有效满足大多数场景生成需求。为了增强可访问性，构建了一个名为SceneInstruct的数据集，用于微调开源LLMs以集成到SceneGenAgent中，实验表明，SceneInstruct上的微调可显著提升开源LLMs的性能，使其达到了接近GPT-4o的水平。

Innovation: 
提出了SceneGenAgent，这是一种基于大型语言模型（LLMs）的生成工业场景的代理，通过C#代码实现精准的布局规划，解决了现有LLMs面临的空间布局复杂规划等难题。通过结构化格式、布局验证和迭代优化来确保准确度，并且通过自主开发的SceneInstruct数据集进一步增强了开源LLMs的性能，使其在真实世界中的工业场景生成任务中达到了出色的性能，接近于先进的模型如GPT-4o。同时保证了场景生成的准确性和可操作性，提高了实际应用中的适用性。

Conclusion: 
实验结果显示，由SceneGenAgent驱动的LLMs在工业场景生成任务中表现优异，达到81.0%的成功率，展示了其在真实工业场景生成中的实际应用能力。Datasets如SceneInstruct及代码等均已被公开，为开源LLMs提供了增强基础以应对更复杂任务。这些成果有效地解决了传统LLMs在精确生成工业场景时难以处理的问题，为工业制造领域的模拟提供了有力工具。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.21909</guid><pubDate>Fri, 27 Jun 2025 02:50:13 +0800</pubDate></item><item><title>4. cs.SE-GPU Kernel Scientist: 一种由LLM驱动的迭代核优化框架</title><link>https://arxiv.org/pdf/2506.20807</link><description>Background: 
优化GPU内核以实现高性能是一项复杂的工作，通常需要深入的架构知识、全面的性能分析和多次实验。当目标是较新的或文档较少的GPU架构时，这种挑战更为严峻，因为传统的开发工具可能不足。本文介绍了一种使用LLM的'GPU Kernel Scientist'自动方法，该方法通过多阶段、进化的过程逐步改进加速器内核。这一过程包括：（a）有策略地选择具有潜力的先前代码版本作为新的迭代基础；（b）基于现有代码和从通用GPU文献中汲取的知识生成优化假设；（c）通过代码修改和将结果提交到外部评估系统自动执行这些实验，仅通过观察运行时间以获取性能反馈。由于从性能竞赛中获得的定量结果在论文提交时被封存，本文展示了该架构设计、操作工作流以及定性的见解，强调了LLM驱动代理在受限资源或快速演化的硬件环境中民主化和加速GPU内核优化的潜力。

Innovation: 
该研究提出了一个使用LLM的自动方法来逐步改进GPU加速器内核，解决了对较新的或文档较少的GPU架构进行高效内核优化的挑战。这个方法包括：选择有潜力的代码版本作为新迭代的基础、基于现有代码和通用GPU文献生成优化假设、通过代码修改并利用外部评估系统的观察结果来进行实验，仅通过运行时间获取反馈。这种方法能够补偿在特定领域有限的人类专业知识，促进内核优化程序的自动化和民主化。

Conclusion: 
尽管从性能竞赛中获得的定量结果尚未披露，本文详细介绍了该架构和操作工作流，展示了LLM驱动方法在受限资源或快速演化的硬件环境中优化GPU内核的潜力，特别是强调了这一方法如何促进性能优化的民主化和加速。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20807</guid><pubDate>Fri, 27 Jun 2025 02:50:11 +0800</pubDate></item><item><title>5. cs.SE-描述Haskell中学生提交的控制台I/O行为</title><link>https://arxiv.org/pdf/2008.09253</link><description>Background: 
该研究旨在为测试由学生编写的交互式Haskell程序提供一种小型的形式化语言。背景为测试教育软件中的学生代码提交需要一种有效的方法来描述和验证控制台输入/输出行为。现有的方法可能具有局限性，因此需要一种简洁且强大的形式化语言来进行精确的描述与验证。

Innovation: 
提出了一个小型形式化语言，用于描述简单的控制台I/O程序行为。该语言受到具体的应用案例——测试学生编写的Haskell程序的驱动。它结构类似于词法分析的正规表达式，但增加了全局变量等功能，这使得能够表达动态行为的广泛范围。基于该语言的执行跟踪接受语义，导出了所有有效执行踪迹的定义，通过抽样这些踪迹，可以机械地以概率方式进行程序行为与规范的检查。此外，该形式化语言在教育环境中的其他潜在用途还包括提供更有帮助的反馈，生成示例解决方案以及生成随机练习任务等。

Conclusion: 
研究结果表明，基于接受执行踪迹的语义，能够有效地机械检查程序行为与规范的一致性。由于该语言设定了清晰的规范，因此在未来使用中提供更优的教育支持是有潜力的。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2008.09253</guid><pubDate>Fri, 27 Jun 2025 02:50:04 +0800</pubDate></item><item><title>6. cs.SE-ToolScan: 一种用于表征工具使用大语言模型错误的基准</title><link>https://arxiv.org/pdf/2411.13547</link><description>Background: 
构建性能良好的复合AI系统中，评估大型语言模型（LLMs）是最关键的部分之一。这是因为在AI系统的下游步骤中，LLMs的输出会传播。因此，识别LLMs的错误对于系统性能至关重要。在AI系统中，LLMs的一项常见任务是工具使用。尽管有许多用于评估LLMs在这方面任务的基准环境，但它们通常只提供成功率，而无法解释失败案例。为了解决这个问题，我们提出了TOOLSCAN，这是一种新的基准，旨在识别LLMs工具使用任务输出中的错误模式。该基准数据集包含来自各种环境的查询，可以用于检测七种新表征的错误模式的存在。利用TOOLSCAN，我们展示了即使是目前最突出的LLMs在其输出中也存在这些错误模式。研究人员可以利用TOOLSCAN获得的这些见解来指导他们的错误缓解策略。

Innovation: 
我们提出了TOOLSCAN，这是一种新基准，旨在识别LLMs在工具使用任务输出中的错误模式。通过TOOLSCAN，我们证明即使是当前最先进的话语言模型在输出中也存在这些模式。这为研究者提供了指导错误缓解策略的依据。

Conclusion: 
TOOLSCAN是评估LLMs工具使用错误的有效基准。利用TOOLSCAN，研究者可以发现错误模式，并据此制定缓解策略，提高系统性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.13547</guid><pubDate>Fri, 27 Jun 2025 02:50:03 +0800</pubDate></item><item><title>7. cs.SE-通过不确定的人工指导进行强化学习的复杂模型转换</title><link>https://arxiv.org/pdf/2506.20883</link><description>Background: 
模型驱动工程问题通常需要复杂的模型转换（MTs），即在长期序列中连锁的MTs。这类问题的例子包括模型同步、自动化模型修复和设计空间探索。手工开发复杂的MTs是一个容易出错且经常不可行的过程。强化学习（RL）是缓解这些问题的有效方法。在RL中，智能体通过试错探索状态空间，以识别有益的行为序列，如MTs。然而，在复杂问题上，RL方法表现存在性能问题。在这种情况下，人的指导非常有用。因此，本文介绍了一种通过RL开发复杂MT序列的方法和技术框架，该框架根据可能不确定的人类建议进行引导。该框架允许用户定义的MTs映射到RL原语，并作为一个RL程序执行来找到最佳MT序列。我们的评估表明，即使不确定的人类指导也显著改善了RL性能，并且导致了更高效的复杂MT开发。通过人建议的确定性和及时性之间的权衡，本文朝着RL驱动的迭代人存在环工程方法迈进了一步。

Innovation: 
本文提出了一种通过强化学习开发复杂MT序列的方法和技术框架，该框架可以利用可能不确定的人类建议进行引导。这一创新之处在于通过RL将自定义的MTs映射为RL程序来寻求最优的序列，同时还能利用不确定的人类指导来优化MT序列的开发过程。这种方法与传统的强化学习方法相比，更具备实际应用价值。

Conclusion: 
通过使用RL并结合不确定的人类指导，本文的方法显著改善了复杂MT序列的开发性能。通过对人类建议的确定性与及时性之间的平衡，该方法代表了RL驱动的工程中人类在闭环中作用的一种新方法。实验结果表明，即使人类建议存在不确定性，这种方法仍能有效提高MT序列的开发效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20883</guid><pubDate>Fri, 27 Jun 2025 02:50:01 +0800</pubDate></item><item><title>8. cs.SE-KOALA: 一种在解决编程任务时收集IDE数据的可配置工具</title><link>https://arxiv.org/pdf/2506.21266</link><description>Background: 
收集学生解决编程任务的数据对于研究人员和教育者来说极具价值，它可以验证学生是否正确应用了所学的功能和概念，或发现学生中的误区。然而，现有的数据收集工具存在限制，如无法控制收集代码的粒度、无法收集编程环境中特定事件，以及配置困难等问题。正因为存在这些问题，研究团队提出了KOALA工具，目的在于克服现有工具的限制，提供一种方便且高度可配置的方法来从学生解决编程任务时收集代码快照和特性使用情况，特别是在JetBrains集成开发环境（IDEs）中。

Innovation: 
KOALA工具解决了很多现有工具存在的问题，比如控制收集代码的粒度、收集编程环境中特定事件、以及配置的简便性。工具能够安装在IDE中并配置提供给学生必要的任务，启用或禁用某些IDE功能（如代码自动补全），运行调查。在问题解决过程中，插件收集了按照配置粒度的代码快照，IDE操作（如运行和调试），以及此前收集不到的数据，例如使用过的快捷键和文件间切换焦点。收集到的数据会被发送到随工具一起提供的服务器中，存储并通过标准化的ProgSnap2格式进行转换。这样一个工具使用的方法和能力，更加直观地显示出所收集数据的价值，能够提供有关学生如何解决编程任务的深层次见解。

Conclusion: 
研究团队通过开发KOALA工具，成功地解决了现有数据收集工具的诸多限制。KOALA能够方便快捷地收集到学生解决编程任务时的大量数据，收集的数据还包括不少此前未收集过的细节，如使用过的快捷键和文件间切换等。这些数据不仅可以验证学生是否正确应用了课程学习的知识，还能帮助科研人员或教育者发现学生存在的重要误区或对某些知识的理解偏差，从而进一步改进教育方法。同时，作为高度可配置的工具，KOALA也能适应不同课程或实验设计的需求。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21266</guid><pubDate>Fri, 27 Jun 2025 02:50:00 +0800</pubDate></item><item><title>9. cs.SE-面向物联网增强事件日志的对象中心核心元模型</title><link>https://arxiv.org/pdf/2506.21300</link><description>Background: 
物联网(IoT)技术的进步促使了物联网设备与企业流程(BPs)的集成，在多个行业中，如制造业、医疗和智能空间。物联网设备的普及产生了大量物联网数据，这些数据提供了对企业流程物理环境的洞察窗口。然而，为了实现这些好处，物联网数据需要与传统流程数据相结合，但由于这两种数据在粒度级别等特性上的巨大差异，使得数据集成变得具有挑战性。近年来，提出了几种数据模型来整合物联网数据与流程数据，但这些模型基于不同的假设和要求，因此导致了数据集成模型的碎片化，阻碍了过程挖掘(PM)领域的数据交换与协作。因此，当前在该领域存在着共享和协作的难题，例如，对研究人员来说，分享数据变得繁琐。

Innovation: 
本文提出了一个核心模型，综合了现有数据模型中最关键的特点。这个核心模型基于共同需求制定，极大地促进了过程挖掘领域内的数据共享与协作。此外，采用典型的Python实现来评估该模型，并证明其能满足这些共同需求。

Conclusion: 
该核心模型是基于常见需求定制的，显著简化了物联网数据与传统流程数据的整合，为过程挖掘提供了统一的数据模型，从而促进了数据分析和协作。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21300</guid><pubDate>Fri, 27 Jun 2025 02:49:58 +0800</pubDate></item><item><title>10. cs.SE-工程化RAG系统：设计、开发与评估</title><link>https://arxiv.org/pdf/2506.20869</link><description>Background: 
检索增强生成（RAG）系统正在成为将大型语言模型（LLMs）与外部知识相融合的关键方法，以解决事实准确性与上下文相关性的问题。然而，缺乏基于真实场景的实际应用案例的系统开发研究，亦缺乏通过一般用户参与进行评估，并提供系统性的经验教训的文献报告。

Innovation: 
本文介绍了针对政府、网络安全、农业、工业研究和医疗诊断五大领域的五个特定领域RAG应用的开发，每个系统结合了多语言光学字符识别、向量嵌入的语义检索以及与特定领域适应的LLM，部署在本地服务器或云API上以满足不同的用户需求。通过web基础评估，涉及100名参与者，考察了六个维度：易用性、相关性、透明度、响应性、准确性及推荐可能性。基于用户反馈和开发经验，记录了十二条关键的教训，强调了技术、运营和伦理问题对RAG系统可靠性和可使用性的挑战。

Conclusion: 
本文通过五个实际应用案例展现RAG系统的开发与评估，总结了系统在真实场景中的表现和遇到的挑战，提供了系统性的经验教训，为RAG系统的进一步研究和应用奠定了基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20869</guid><pubDate>Fri, 27 Jun 2025 02:49:58 +0800</pubDate></item><item><title>11. cs.SE-合成需求的效果如何？评估LLM生成的数据集在AI4RE中的性能</title><link>https://arxiv.org/pdf/2506.21138</link><description>Background: 
人工 inteligência 用于需求工程 (AI4RE) 的进步受到公 conduct 数据集短缺的限制。尽管大量语言模型 (LLM) 提供了生成合成数据的潜力，但如何系统地控制和优化生成的需求质量仍然未被充分探索。

Innovation: 
提出了 Synthline v1，这是一种增强的产品线方法，用于生成合成需求数据，扩展了早期 v0 版本，引入了先进的生成策略和内容审查技术。利用多样本提示策略显著提升了数据质量和多样性，通过自动提示优化技术（如 PACE）改进了功能分类的准确性，而基于相似性的内容审查虽然提高了多样性但有时会损害分类性能。研究发现，合成需求数据在某些任务上可以匹配甚至超过人工撰写的数据，特别是在安全性和缺陷分类方面表现更优。

Conclusion: 
研究结果指出，合成需求数据可以被用于 AI4RE，并通过系统生成的数据弥补了数据稀缺性的问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21138</guid><pubDate>Fri, 27 Jun 2025 02:49:58 +0800</pubDate></item><item><title>12. cs.SE-探索微前端：在电商平台中的案例研究应用</title><link>https://arxiv.org/pdf/2506.21297</link><description>Background: 
在微前端的架构风格中，前端被划分为更小的组件，这些组件可以从简单的按钮到整个页面不等。目的是提高可扩展性、韧性以及团队的独立性，但可能会增加复杂性和基础设施的需求。这篇论文旨在理解何时采用微前端特别是在工业领域中的适用性。为此，研究者们基于学术和灰色文献调查了微前端的现状，并在一家手工艺品电商平台进行了微前端架构的实际应用，该平台已经使用了微服务。通过半开放问卷调查开发人员，评估了这种架构的实施情况。研究公司内部主要系统（Java单体）与专用前端系统的紧密耦合、已过时的技术以及糟糕的开发者体验提出了进行架构改变的需求。为了应对这些问题，他们选择了采用了微前端架构，并结合了API网关和前端后端模式，使用了Svelte和Fastify等技术。尽管微前端的采用是成功的，但根据问卷调查的混合结果分析，并不是严格必要，某些替代方案，如单体前端，也可以达到类似的结果。使微前端在这种情境下成为最便捷的选择的因素是该公司的单体扼杀和微服务采用，这促进了通过基础设施重用和团队之间的知识分享实现了实现微前端的目标。

Innovation: 
论文通过结合调研与实际应用，评估了微前端架构在特定上下文中的适用性和效果，提出了其他替代方案也可能达到类似目标的观点，为未来采用微前端提供了参考依据。

Conclusion: 
在电商平台采用微前端虽然有效，但在某些情况下，采用单体前端或其他替代方案也可能达到类似的效果。微前端的选择主要取决于公司内部的具体条件，如单体扼杀和微服务采用，这使得可以通过基础设施重用和团队间的知识共享更轻松地实施。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21297</guid><pubDate>Fri, 27 Jun 2025 02:49:57 +0800</pubDate></item><item><title>13. cs.SE-IXAII：针对决策支持系统的互动式可解释人工智能界面</title><link>https://arxiv.org/pdf/2506.21310</link><description>Background: 
尽管已经开发出了多种可解释人工智能（Explainable AI，XAI）的后验方法，但大多数方法都是静态的且忽略了用户视角，这限制了它们对目标受众的有效性。在这种背景下，论文探讨了一种名为IXAII的互动式可解释人工智能系统，该系统整合了四种XAI方法：LIME、SHAP、Anchors和DiCE，并提供五类用户的个性化视图，赋予用户对解释内容和形式的控制权。

Innovation: 
IXAII通过整合四种XAI方法（LIME、SHAP、Anchors和DiCE），并提供多种可视化选项，实现对不同用户群体的个性化解释界面。该系统让用户能够在解释内容和形式上拥有自主权，这种交互性和可解释性之间的结合为人工智能的解释实践和人机交互提供了新的视角，增强了透明度，是现有技术的一大创新。

Conclusion: 
研究结果表明，IXAII能够提供多种不同的解释，通过增强透明度被视为对用户具有帮助。通过缩小XAI方法、交互性和实际实施之间的差距，IXAII提供了一种新的可解释人工智能实践和人机交互的视角。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21310</guid><pubDate>Fri, 27 Jun 2025 02:49:55 +0800</pubDate></item><item><title>14. cs.SE-维护MTEB：嵌入基准的长期实用性和可重现性</title><link>https://arxiv.org/pdf/2506.21182</link><description>Background: 
《大规模文本嵌入基准(MTEB)》已成为评估文本嵌入模型的标准平台。虽然之前的工作建立了基准的核心方法，但本文则着重于确保MTEB持续的可重现性和扩展性的工程方面。文章详细讨论了如何保持稳定的持续集成管道，验证数据集的完整性，自动化测试执行，并评估基准结果的泛化能力。此外，还探讨了如何处理社区贡献，以及如何扩展基准以包含新的任务和数据集。这些工程实践对MTEB进行了扩展，使其更加全面，在保持质量和最终相关性方面发挥关键作用，使MTEB成为一个更具可靠性的基准平台。

Innovation: 
本文提出了一种维护稳健的持续集成管道的方法，包括验证数据集的完整性、自动化测试执行以及评估基准结果的泛化能力。此外，还讨论了如何处理社区贡献，如何扩展基准以包含新的任务和数据集，这些工程实践对MTEB进行了扩展，使其更加全面，在保持质量和最终相关性方面发挥了关键作用。

Conclusion: 
本文的经验为面对类似挑战确保机器学习评估框架的实用性和可重现性中的基准维护者提供了宝贵的见解。MTEB仓库可通过此链接访问：this https URL&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21182</guid><pubDate>Fri, 27 Jun 2025 02:49:52 +0800</pubDate></item><item><title>15. cs.SE-通过自动化集成数据生成可靠不良事件概况以促进健康 (GRAPH-AID): 半自动化本体构建方法</title><link>https://arxiv.org/pdf/2506.20851</link><description>Background: 
随着数据和知识的迅速增长，采用系统的方法生成本体变得至关重要。面对数据量的增加和内容的频繁变更，数据库存储和检索信息以创建知识图谱的需求日益迫切。现有的KNARM方法提供了一种系统的方法来应对这些挑战，但其中存在将Neo4j数据库与Web本体语言(OWL)无缝集成的问题。以往尝试将Neo4j数据整合到本体中的方法通常需要对描述逻辑(DL)语法有深入了解，这可能不是所有用户都能掌握的。因此，一种更易于使用的工具是必要的。

Innovation: 
本文提出了一个用户友好的方法，利用Python及其rdflib库来支持本体开发。该方法通过整合美国食品药品监督管理局（FDA）不良反应报告系统（FAERS）数据库中的数据创建了一个Neo4j数据库，并开发了一个Python脚本自动生成所需的类及其公理，简化了集成过程。这种方法为在快速增长的不良药物事件数据集中生成本体提供了实际解决方案，支持了药物安全监测和公共卫生决策的进步。

Conclusion: 
本文提出的半自动化本体构建方法通过Python和rdflib库创建了一个实用的工具，简化了本体开发过程，支持了高效的药物安全监控和公共卫生决策。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20851</guid><pubDate>Fri, 27 Jun 2025 02:49:50 +0800</pubDate></item><item><title>16. cs.SE-T³: 多层次树形结构的大型语言模型驱动的自动程序修复</title><link>https://arxiv.org/pdf/2506.21211</link><description>Background: 
自动程序修复（APR）是软件开发和维护中的核心技术，旨在通过最小化人工干预实现自动化缺陷修复。近年来，大型语言模型（LLMs）和思维链（CoT）技术的显著进步极大地增强了这些模型的推理能力。然而，由于APR领域需要复杂的逻辑和多步骤的推理能力，CoT技术的应用仍然不足。这项研究系统评估了几种常见的CoT技术在APR任务中的性能，并提出了一种名为$T^3$的创新框架，将LLMs的强大推理能力与树搜索技术有机结合，有效提高了生成候选修复解决方案的准确性。此外，$T^3$为优化APR任务中的样本选择和修复策略提供了宝贵的指导，建立了实现高效自动调试的坚实框架。

Innovation: 
提出了一种名为$T^3$的创新框架，将大型语言模型（LLMs）的强大推理能力与树搜索技术相结合，用于自动程序修复（APR）任务，提高了生成候选修复解决方案的准确性，并提供了优化APR任务中样本选择和修复策略的指导。

Conclusion: 
该研究通过系统评估了几种常见的CoT技术在APR任务中的性能，并建立了基于$T^3$框架的全面模型，该模型能够有效进行自动程序修复，并优化样本选择和修复策略，从而实现高效自动化调试。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21211</guid><pubDate>Fri, 27 Jun 2025 02:49:44 +0800</pubDate></item><item><title>17. cs.SE-增强漏洞检测的跨函数多向关联洞察</title><link>https://arxiv.org/pdf/2506.21014</link><description>Background: 
漏洞检测对于确保软件系统的安全性至关重要但极具挑战。现有的基于深度学习的漏洞检测方法主要关注独立函数，忽略了函数之间的复杂交互关系，特别是多向关联。这可能导致未能检测到这些关联中的漏洞。

Innovation: 
本文提出了一种跨函数多向关联分析框架（IFMA-VD），其核心在于构建代码行为超图并通过超边卷积提取多向关联特征。首先，将函数解析为代码属性图以生成内部函数特征；其次，通过分割程序依赖图构建代码行为超图，隔离并编码行为特征至超边；最后，利用超图网络捕获多向关联知识以增强漏洞检测。实验结果显示，与基线方法相比，IFMA-VD在F-测量和召回率上有所提升，并证实了多向关联特征能提升代码特征表示及IFMA-VD在实际数据集上的效果。

Conclusion: 
IFMA-VD框架通过识别和利用跨函数间多向关联关系，有效提高了漏洞检测的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21014</guid><pubDate>Fri, 27 Jun 2025 02:49:41 +0800</pubDate></item><item><title>18. cs.LG-HARPT：移动健康应用中消费者信任和隐私担忧分析的语料库</title><link>https://arxiv.org/pdf/2506.19268</link><description>Background: 
当前存在一个对用户隐私和信任研究的需求，特别是在移动健康应用领域。为了满足这一需求，研究人员需要大规模、结构化的数据集作为研究基础。本文提出了一个名为HARPT的大规模标注数据集，旨在促进用户隐私和信任的研究。该数据集包含超过480,000个用户评论，被细致地划分为七个类别，涵盖了在应用程序、提供商信任及隐私顾虑方面的重要方面。

Innovation: 
HARPT 数据集的创建过程中，作者克服了多个复杂性问题，包括定义细腻的标签方案、从大量噪声数据中提取相关内容，以及设计一种既能提高规模性又保持准确性的注解策略。该策略结合了基于规则的筛选、迭代的手动标注、针对特定数据集的目标增强以及使用基于变换器的分类器进行弱监督，以加速覆盖面。为了支持模型开发和评估，还专门标注了7,000条评论。

Conclusion: 
研究通过验证一系列分类模型，证明了在HARPT数据集上可以实现强劲的分类性能，并为未来的研究提供了基准。数据集被公开展示供健康信息学、网络安全和自然语言处理等领域的研究人员使用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19268</guid><pubDate>Fri, 27 Jun 2025 02:49:40 +0800</pubDate></item><item><title>19. cs.LG-Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning</title><link>https://arxiv.org/pdf/2506.13056</link><description>Background: 
近期，大型语言模型（LLMs）和多模态大语言模型（MLLMs）的发展催生了高级推理范式的兴起。然而，当前的一些方法在应用上存在局限性。例如，仅依靠强化学习（RL）的方法在采样效率和激活潜在的推理能力方面存在问题；而那些采用先冷启动监督微调（SFT），再使用RL的管道则可能会限制模型的探索性并导致次优的收敛效果。因此，迫切需要一种能够有效结合两者优点的方法来优化多模态推理模型的学习过程。

Innovation: 
本文提出了一种新颖的多模态推理模型学习方法——Metis-RISE。该方法不同于现有的方法，直接从强化学习（RL）阶段入手，无需先进行冷启动的监督微调（SFT）阶段，旨在通过激励模型的潜在推理能力，然后利用SFT阶段解决从RL过程中发现的两个关键挑战：任务中模型虽然拥有正确的推理能力但不一致地应用，以及模型完全缺失某些基础能力的问题。这种通过RL激励随后SFT增强的方法在7B和72B参数的两版本MLLMs上得到了应用，并在OpenCompass多模态推理排行榜上表现优异，两模型分别达到了同类模型中的最先进性能，72B版本排名第4位。

Conclusion: 
Metis-RISE方法在多模态推理模型的学习中展现出优越性，通过结合RL激励和SFT增强两种策略有效提升了模型的性能，并且已经在开源平台上提供相关信息。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13056</guid><pubDate>Fri, 27 Jun 2025 02:49:40 +0800</pubDate></item><item><title>20. cs.LG-使用潜在空间强化学习引导您的扩散政策</title><link>https://arxiv.org/pdf/2506.15799</link><description>Background: 
机器人从人类示范中学习的控制策略已经在许多实际应用中取得了令人印象深刻的成果。然而，在初始性能不佳的情况下，例如在新的开放环境下，基于行为克隆的策略通常需要收集更多的人类示范来改进其表现，这是一个昂贵且耗时的过程。相比之下，强化学习能实现自主在线策略改进，但由于所需样本量大，往往会效果不佳。因此，本研究旨在通过高效的实际强化学习来实现快速自主的BC训练策略适应，特别针对最先进的BC方法——扩散策略，提出了使用潜在空间强化学习引导扩散策略的方法（DSRL）

Innovation: 
提出了使用潜在空间强化学习引导扩散策略的方法（DSRL），这种方法高度样本高效，只需要对扩散策略的黑盒访问，能够实现有效的实际强化学习中的自主策略改进。此外，DSRL避免了调整扩散策略权重的相关挑战，在实际强化学习中展示了高效的样本使用量和有效的表现提升

Conclusion: 
在仿真基准、真实世界机器人任务以及预训练通用策略的适应上，展示了DSRL的样本效率和实际效果。该研究通过高效的实际强化学习实现了快速的自主适应，是理解和提高扩散策略效果的重要步骤&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15799</guid><pubDate>Fri, 27 Jun 2025 02:49:37 +0800</pubDate></item><item><title>21. cs.LG-从网页搜索到具备推理能力的主动深度研究：用推理代理激励搜索</title><link>https://arxiv.org/pdf/2506.18959</link><description>Background: 
信息检索是现代知识获取的基石，每天在不同领域处理数十亿次查询。然而，传统的基于关键词的搜索引擎越来越难以满足复杂的、多步骤的信息需求。

Innovation: 
我们提出了一种新的范式——具备推理和自主能力的大型语言模型（LLMs）主导的主动深度研究。这些系统通过将自主推理、迭代检索和信息综合紧密整合进一个动态反馈循环中，超越了传统的信息检索技术。此外，我们还介绍了测试时的扩展法则，以形式化计算深度对推理和检索的影响。基于基准结果和开源实现的兴起，证明了主动深度研究不仅大幅优于现有方法，而且有望成为未来信息搜索的主要范式。

Conclusion: 
主动深度研究不仅显著超过了现有的方法，而且有着成为未来信息检索主导范式的潜力。所有相关的资源（包括行业产品、研究论文、基准数据集和开源实现）均收集于此链接：[此网址].&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18959</guid><pubDate>Fri, 27 Jun 2025 02:49:36 +0800</pubDate></item><item><title>22. cs.SE-机器学习中的敏捷管理：一项系统映射研究</title><link>https://arxiv.org/pdf/2506.20759</link><description>Background: 
机器学习 (ML) 使能系统在我们的社会中无处不在，推动了巨大的数字化转型。ML 发展的动态特性，包括实验周期和数据的快速变化，对传统的项目管理提出了挑战。敏捷方法因其灵活性和增量交付而显得非常适合应对这一动态性，但尚不清楚如何在 ML 使能系统中有效应用这些方法。这些系统面临的挑战需要量身定制的方法来应对。

Innovation: 
我们通过系统映射研究进行了一项综合搜索策略，结合数据库搜索和雪球法迭代，识别了 27 篇发表于 2008 年至 2024 年的论文。从这些论文中，我们确定了 8 个框架，并将推荐和实践分类为 8 个关键主题，如迭代灵活性、创新 ML 特定的工具和最小可行模型。研究中识别出的主要挑战是在 ML 相关任务中的准确工作量估算。这项研究通过概述领域现状并识别领域中的开放空白，做出了贡献。虽然存在相关工作，但仍需要更 robust 的实证评估来验证这些贡献。

Conclusion: 
本研究通过映射现状并识别领域中的空白，做出了贡献。虽然存在相关工作，但如果要验证这些贡献的有效性，仍需要更多的 robust 实证评估。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20759</guid><pubDate>Fri, 27 Jun 2025 02:49:34 +0800</pubDate></item><item><title>23. cs.SE-需求工程中的领域知识：一项系统映射研究</title><link>https://arxiv.org/pdf/2506.20754</link><description>Background: 
领域知识被认为是成功进行需求工程（RE）的关键要素，因为它提供了理解系统上下文、确保与相关方需求的一致性以及减少需求规范中的模糊性的概念支持。尽管其重要性显而易见，但科学文献中尚未系统地整理出如何有效利用和操作化领域知识的方法。

Innovation: 
本文通过提供现有贡献的全面概述，包括用于将领域知识纳入RE实践的方法、技术及工具，填补了这一空白。研究采用了数据库搜索和迭代的雪球筛选相结合的系统映射方法，最终纳入了75篇符合条件的论文。这些信息支持研究者和实践者识别现有方法和未解决的问题，并指出了未来研究的有前途的方向，强调了开发可扩展的自动化和可持续解决方案的重要性，以将领域知识整合到RE过程中。

Conclusion: 
该研究通过提供一个全面的概述，有助于建立知识驱动的需求工程的概念和方法论基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20754</guid><pubDate>Fri, 27 Jun 2025 02:49:30 +0800</pubDate></item><item><title>24. cs.LG-TracLLM: 一种针对长上下文LLM的通用归因框架</title><link>https://arxiv.org/pdf/2506.04202</link><description>Background: 
长上下文大语言模型（LLMs）被广泛应用于诸如检索增强（RAG）、智能代理及更广泛的LLM集成应用中。给定一条指令和一个较长的上下文（如文档、PDF文件或网页），长上下文LLM可以生成基于给定上下文的输出，旨在提供更准确、更及时且可验证的输出，同时减少幻觉和未经证实的说法。然而，这引发了一个研究问题：如何确定这些生成的输出主要由哪些上下文中的文本（如句子、段落或段落）贡献或负责？这一过程，称为上下文溯源，具有许多实际应用，如①调试LLM基于的系统，②对LLM进行事后攻击法医分析（如提示注入攻击、知识污染攻击），③突出知识来源以增强用户对LLM生成输出的信任度。现有的特征归因方法如Shapley在应用于长上下文LLM的上下文溯源时表现不佳且计算成本高昂。

Innovation: 
我们开发了TracLLM，这是第一个针对长上下文LLM的通用上下文溯源框架。我们的框架能够提高现有特征归因方法的有效性和效率。为了提高效率，我们在TracLLM中开发了一种基于启发式搜索的算法。我们还开发了贡献分数集成/去噪技术，以提高TracLLM的准确性。我们的评估结果表明，TracLLM能够有效识别导致LLM生成输出的长上下文中的文本。

Conclusion: 
我们的代码和数据可在以下链接获取：this https URL.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.04202</guid><pubDate>Fri, 27 Jun 2025 02:49:29 +0800</pubDate></item><item><title>25. cs.LG-以假乱真：通过辨别预测进行奖励模型构建</title><link>https://arxiv.org/pdf/2506.13846</link><description>Background: 
当前的奖励模型方法依赖于大量的人工标注偏好数据或精细工程的质量维度来实施，这导致了实施复杂性。这些方法往往未能完全覆盖质量维度，且工程成本高。使用生成对抗网络（GANs）中的对抗训练作为灵感，论文探讨了如何构建一个无需手动偏好标注和明确质量维度工程的高效奖励模型框架。该方法仅需少量的目标样本即可训练奖励模型，用于判别少量代表性且未配对的目标样本和模型生成的普通输出。

Innovation: 
提出的GAN-RM框架通过无监督的方法在不需要人工偏好标注和明确质量维度工程的情况下训练奖励模型，这显著简化了实现过程。GAN-RM仅需少量的代表性未配对的目标样本来训练奖励模型，该方法的有效性已在多个关键应用中得到验证，包括测试时扩展（通过Best-of-N样本筛选）、后训练调整如监督微调（SFT）以及直接偏好优化（DPO）等。

Conclusion: 
实验表明，GAN-RM框架在多种关键应用上具有高度有效性。未来的研究方向可能是进一步优化和扩展该方法，使其适用于更多样的生成模型和应用场合。代码和数据将在指定的链接处提供。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13846</guid><pubDate>Fri, 27 Jun 2025 02:49:29 +0800</pubDate></item><item><title>26. cs.LG-超声图像解释和扫描指导的语义场景图</title><link>https://arxiv.org/pdf/2506.19683</link><description>Background: 
医学超声成像由于成像和采集参数的显著视觉差异，理解仍是一个长期存在的挑战。近期大型语言模型的进展已被用于自动生成面向临床人员的富含生理学知识的术语丰富摘要。然而，对于非专家用户在即时护理环境中提高超声图像可解释性和基础扫描指导的需求尚未得到探索。本文首先通过引入场景图解释超声图像内容，并为普通用户提供扫描指导，解决了这些问题。场景图是在超声图像上计算得出的，无需显式对象检测，并通过大型语言模型进一步根据用户查询对抽象的场景图进行细化，以生成普通人易于理解的图像解释。研究在颈部左侧和右侧，包括颈动脉和甲状腺，五个志愿者的图像上验证了这种方法的有效性，结果表明该方法有潜力最大程度地将超声成像普及给普通人，从而提高其可解释性与可用性

Innovation: 
本文首次引入了超声图像的场景图来解释图像内容并提供扫描指导。场景图的计算使用了一种基于变压器的单阶段方法，消除了显式的对象检测需求。通过大型语言模型进一步根据用户查询对抽象的场景图进行细化，为普通人生成易于理解的图像解释。这种方法还探索了场景图指导超声扫描以寻找当前图像视角中的缺失解剖结构的潜力，帮助普通人实现更为标准化和完整的解剖探索

Conclusion: 
通过在颈部左侧和右侧包括颈动脉和甲状腺的五名志愿者的图像上验证，该基于场景图的图像解释和扫描指导方法被证明可以最大化地将超声技术普及给普通人，提高其可解释性和使用便利性&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19683</guid><pubDate>Fri, 27 Jun 2025 02:49:20 +0800</pubDate></item><item><title>27. cs.LG-TaxaDiffusion: 进行精细分类物种生成的渐进训练扩散模型</title><link>https://arxiv.org/pdf/2506.01923</link><description>Background: 
当前扩散模型在生成动物图像时，通常将每个物种作为独立类别进行处理，忽视了物种之间的视觉相似性，而这很大程度上是因为形态和身份的细微差异。现有的方法无法有效地利用这些相似性来生成精细分类级别的动物图像，尤其是在训练样本有限的情况下表现出较低的生成精度和细节准确性。本文旨在通过引入分类学知识，提出TaxaDiffusion框架，以便生成具有高形态和身份准确性的精细分类动物图像。TaxaDiffusion利用从大类（如纲和目）、科属到物种这样的层次结构进行训练，逐步细化不同分类级别的特征，以实现更准确的生成效果。

Innovation: 
1. TaxaDiffusion是一个分类学知识指导的训练框架，它考虑了许多物种在形态、图案和颜色上的细微差异，而不是将每个物种作为独立类别处理。2. TaxaDiffusion采用分层学习策略，从大类到科属再到物种，逐步训练条件扩散模型，先捕捉共祖物种的粗粒形态特征，再细化到物种级的细微差异。3. 该方法利用了物种间的视觉相似性，即使在有限的物种训练样本情况下，也能实现较高的生成精度和细节准确性。

Conclusion: 
经过三种精细分类动物数据集的广泛实验，TaxaDiffusion优于现有方法，在精细分类动物图像生成方面表现出更高的细节真实性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.01923</guid><pubDate>Fri, 27 Jun 2025 02:49:19 +0800</pubDate></item><item><title>28. cs.LG-A3: 一种解析的低秩近似框架用于注意力机制</title><link>https://arxiv.org/pdf/2505.12942</link><description>Background: 
大语言模型展现出出色的表现，但它们庞大的参数数量导致部署成本高昂。现有低秩近似方法存在两个主要局限性：它们专注于最小化单个线性层的输出误差，而没有考虑Transformer的架构特性；它们将一个大权重矩阵分解为两个小的低秩矩阵。因此，这些方法通常在压缩效果上不如剪枝和量化等技术，并引入了额外的GEMM内核启动等运行时开销。

Innovation: 
本文提出了A3，一种后训练低秩近似框架。A3将Transformer层分为三个功能组件，即QK、OV和MLP。对于每个组件，A3提供了减少隐藏维度大小的同时，最小化组件的功能损失（即注意力分数、输出和MLP输出的误差）的解析解。这种方法直接减少了模型大小、KV缓存大小和FLOPs，没有引入任何运行时开销。此外，它提供了一种新的方法，通过提高端到端性能推动优化问题，从单一线性层误差优化转向更优的效果。实验证明，A3在性能上优于SOTA模型，在相同计算和内存预算下，A3低秩近似后的LLaMA 3.1-70B在WikiText-2上的困惑度为4.69，优于前SOTA的7.87，高出3.18。同时展示了A3的通用性，包括KV缓存压缩、量化和混合秩分配，以增强性能。

Conclusion: 
A3保持了出色的性能，使得在相同的计算和内存预算下，LLaMA 3.1-70B的困惑度降低了3.18，同时展示了其在KV缓存压缩、量化和混合秩分配方面的多功能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12942</guid><pubDate>Fri, 27 Jun 2025 02:49:19 +0800</pubDate></item><item><title>29. cs.LG-二元线性分类问题中均匀泛化误差的精确集中现象</title><link>https://arxiv.org/pdf/2505.16713</link><description>Background: 
本文通过等周论证方法探讨了二元线性分类问题中统一泛化误差围绕其期望值的集中情况。特别地，对于输出标签和标注加权输入向量的联合分布，建立了泊松不等式和对数－辛普尔不等式，以此获得泛化误差的集中界限。分析表明，这些集中界限在标签均衡的情况下差值可以非常接近，同时在渐近分析中，几乎一致收敛于期望值的情况在相当宽泛的设置中也能发生，例如比例高维设置。基于这种收敛性，建立了维度无关条件下的统一大数法则。

Innovation: 
文章通过等周论证方法证明了泊松不等式和对数－辛普尔不等式，用于推导泛化误差的集中界限。这些界限在标签均衡的情况下非常接近，并且在渐近分析中扩展了几乎一致收敛于期望值的情态到广泛的应用场景，比如比例高维设置。此外，本文还基于这种收敛性，建立了维度无关条件下的统一大数法则。

Conclusion: 
本文对二元线性分类问题中的集中现象进行了详细的探究，证明了泛化误差的精确集中界限，并且在广泛的场景下，统一泛化误差几乎一致地收敛于其期望值。同时，本文还研究了在维度无关条件下的统一大数法则。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.16713</guid><pubDate>Fri, 27 Jun 2025 02:49:16 +0800</pubDate></item><item><title>30. cs.LG-使用SMILE进行大规模语言模型可解释性：基于局部解释的统计模型无偏解释</title><link>https://arxiv.org/pdf/2505.21657</link><description>Background: 
现有的大型语言模型如GPT、LLAMA和Claude虽然在生成文本方面非常强大，但仍然是黑盒子，难以理解模型是如何做出决策的。这种透明度的缺乏在需要信任和问责的领域尤为成问题。本文旨在解决这一问题，介绍了一种名为SMILE的新方法，该方法通过对输入进行微小变化并测量输出变化来解释模型对不同提示部分的响应，从而生成简洁的热力图，展示哪些部分的提示最重要。SMILE通过这种方式帮助理解模型，使其更容易解释，从而推动AI变得更加透明和可信。

Innovation: 
SMILE是一种无模型的方法，通过微调输入并测量输出变化来解释大型语言模型的响应，从而生成突出显示关键词语的简单视觉热力图。这种方法在多个主流的大规模语言模型上进行了测试，并通过准确度、一致性、稳定性和可靠性等指标证明，能够提供清晰且可靠的解释。

Conclusion: 
通过SMILE这种简单有效的可视化热力图方法，使大型语言模型的决策过程更加透明，从而使这些模型更易于理解，朝向让AI变得更透明和可信的目标迈进一步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.21657</guid><pubDate>Fri, 27 Jun 2025 02:49:09 +0800</pubDate></item><item><title>31. cs.LG-通过应用机器学习分析纽约房地产中的种族平等</title><link>https://arxiv.org/pdf/2505.16946</link><description>Background: 
本研究分析了纽约州（NYS）和纽约市（NYC）街区级别的房地产所有权模式，以揭示种族差异。研究使用了一种先进的种族/族裔推断模型（结合LSTM和Geo的XGBoost过滤模型，验证准确率为89.2%），将预测的房产所有者种族构成与来自人口普查数据的居住人口进行比较。该研究探讨了全域模型（全州范围）和姓名仅LSTM模型（NYC）之间的差异，以评估地理空间上下文如何影响预测和不平等估算。

Innovation: 
研究提出了先进的种族/族裔推断模型，结合了LSTM和Geo的XGBoost过滤模型，并通过对比预测的房产所有者种族构成和来自人口普查数据的居住人口，揭露了显著的不平等现象。模型还评估了地理空间上下文如何影响预测和不平等估算结果。研究特别关注少数族裔占多数的街区以及公司所有权（LLCs、信托等）如何进一步加剧所有权和人口分布之间的不平等。

Conclusion: 
研究结果强调了房地产所有权中持续存在的种族不平等，反映出更广泛的历史和社会经济因素。研究结果表明，需要数据驱动的方法来解决这些问题。研究还特别指出了少数族裔占多数的街区与白人为主的物业所有权之间的不平等，并提供了各民族占多数的街区中所有权与人口的详细对比分析。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.16946</guid><pubDate>Fri, 27 Jun 2025 02:49:08 +0800</pubDate></item><item><title>32. cs.LG-AI评估中的度量与意义：一种以效度为中心的框架</title><link>https://arxiv.org/pdf/2505.10573</link><description>Background: 
尽管人工智能系统的能力和实用性有所提升，但评估这些系统的严格标准却相对滞后。雄心勃勃的声明，如模型达到泛化的推理能力，通常仅通过模型在狭窄基准上的表现，比如研究生级考试问题的表现来支持，这种评估方式提供了有限且可能误导的评估。本研究提供了一个结构化的方法，以根据现有证据思考能作出哪些评估声明。我们的框架能够确定是否数学基准的表现反映了解决数学测试问题的能力，而不是更广泛的推理能力。该框架适用于机器学习的当前范式，其中各个利益相关者提供测量和评估，下游用户使用这些来验证他们的声明和决策。同时，该框架也支持构建旨在验证相关内容性声明的评估。利用心理测量学中有效性的分解，评估可以优先考虑特定声明中最关键的方面，提高实证效用和决策有效性的效率。我们通过视觉和语言模型评估的详细案例研究演示了这一框架，强调明确考虑有效性如何加强评估证据与所作声明之间的联系

Innovation: 
本研究提供了一个结构化的方法，以根据现有证据思考能作出哪些评估声明。该框架能够确定数学基准表现是否反映了解决数学测试问题的能力，还是更广泛的推理能力。该框架可以支持下游用户验证其声明和决策，同时也能构建旨在验证内容性声明的评估。利用心理测量学中有效性的分解，评估可以优先考虑特定声明中最关键的方面，提高实证效用和决策的效率。通过详细的视觉和语言模型评估案例研究来演示该框架，着重于明确考虑有效性如何加强评估证据与声明之间的联系

Conclusion: 
本研究提供了一个有效的框架，用于设计和评估AI技术，强调了使用心理学效度理论来优化评估方法的重要性。该框架不仅有助于下游用户的决策验证，还促进了构建能够准确反映AI技术真实能力的评估。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.10573</guid><pubDate>Fri, 27 Jun 2025 02:49:06 +0800</pubDate></item><item><title>33. cs.LG-PCF-Grasp: 将点完成结果转换为几何特征以增强6自由度抓取</title><link>https://arxiv.org/pdf/2504.16320</link><description>Background: 
当前6自由度（6-DoF）抓取方法主要依赖于单视角深度图像生成的点云（2.5D点），这类点云只能提供物体的一个表面信息，导致抓取算法无法准确识别物体形状，从而影响抓取精度。人类依靠几何经验可以仅凭单视角准确地抓取物体。因此，该研究提出了一种新的6-DoF抓取框架，该框架通过将点完成结果作为物体形状特征用于训练6-DoF抓取网络，以模仿人的几何经验，提高抓取效率。此外，由于网络生成与实际执行之间的差距，该框架还集成了一个评分过滤器，以选择更多可行的抓取提案，提高实际机器人抓取的成功率。实验结果表明，使用完整点特征可以生成更准确的抓取提案，并且包含评分过滤器能够显著提高实际机器人抓取的可信度。该方法在全球实验中的成功率比最先进的方法提高了17.8%。

Innovation: 
创新之处在于提出了一种全新的6-DoF抓取框架，该框架通过将点完成结果作为物体形状特征用于训练6-DoF抓取网络，模仿人类的几何经验。此外，还引入了评分过滤器，以选择更可行的抓取提案，提高实际机器人抓取的成功率和可靠性。

Conclusion: 
研究通过使用完整点特征生成更准确的抓取提案，并结合评分过滤器的选择机制，有效提高了真实世界机器人抓取的性能，实验结果表明该方法比现有的最优方法提高了17.8%的成功率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.16320</guid><pubDate>Fri, 27 Jun 2025 02:49:01 +0800</pubDate></item><item><title>34. cs.LG-利用基础视觉转换器的材料微结构-性质关系的机器学习</title><link>https://arxiv.org/pdf/2501.18637</link><description>Background: 
在计算材料科学中，从数据中学习微结构-性能关系的机器学习方法是一个新兴领域。大多数现有的机器学习努力集中在为每个微结构-性能关系开发特定任务的模型。本研究提出利用预训练的基础视觉变换器从数据中提取任务无关的微结构特征，在此基础上进行轻量级的机器学习微结构依赖性能研究。该研究通过使用预训练的最先进视觉变换器（CLIP，DINOv2，SAM）在两个案例研究中（i）基于仿真数据的二相微结构弹性模量；（ii）基于文献报道实验数据的镍基和钴基高温合金维氏硬度进行验证。

Innovation: 
本研究提出了使用预训练的基础视觉变换器来提取任务无关的微结构特征，从而实现轻量级的微结构依赖性能的机器学习，而无需为特定任务进行昂贵的训练或微调定制的深度学习模型。通过对现有模型的学习，验证了这种方法的有效性和潜力。

Conclusion: 
本研究的结果表明，基础视觉变换器对于微结构表示和材料微结构-性能关系的高效机器学习具有巨大的潜力，无需昂贵的特定任务训练或微调定制的深度学习模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.18637</guid><pubDate>Fri, 27 Jun 2025 02:48:57 +0800</pubDate></item><item><title>35. cs.LG-一种基于SRBB的可扩展量子神经网络用于近似酉合成</title><link>https://arxiv.org/pdf/2412.03083</link><description>Background: 
本文介绍了通过标准递归块基（SRBB）的可扩展量子神经网络来近似任何幺正演化。这种方法利用Lie代数及其拓扑特性来获得酉算子的可扩展参数化。原有的SRBB可扩展方案仅从理论角度已知，本文对其进行改造，提出了更高效的算法实现和复杂度管理方案。通过减少CNOT数目的算法，提出了一个新的可实现的可扩展方案，仅需一层近似。这种方法在PennyLane库中实现了，并通过一系列不同维度的幺正矩阵（最多6个量子比特）进行了评估。逼近的有效性使用不同的度量进行了评估，分别与梯度方法和Nelder-Mead方法进行了比较。此外，该方法还在实际硬件上进行了测试，并与文献中已有的其它逼近和分解方法进行了对比。

Innovation: 
提出了通过SRBB来设计可扩展量子神经网络的新方法，利用Lie代数及其拓扑特征，实现了可扩展参数化，并提出了一种减少CNOT数目的算法，使得需仅一层近似。该方法已在PennyLane库中实现，并评估了不同大小的幺正矩阵。通过比较不同优化器的性能，验证了其有效性和在实际硬件上的适用性。此外，还提出了一种新的可实现的可扩展方案。

Conclusion: 
通过SRBB设计的可扩展量子神经网络在PennyLane库中的实现和评估显示，该方法能够有效地近似幺正演化，同时减少CNOT的数量，仅需一层近似即可。该方法不仅在理论上有新的突破，还在实际硬件上得到了验证，表明其在量子计算中的潜在应用价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.03083</guid><pubDate>Fri, 27 Jun 2025 02:48:54 +0800</pubDate></item><item><title>36. cs.LG-预训练可逆生成模型作为无监督视觉表征学习</title><link>https://arxiv.org/pdf/2412.01787</link><description>Background: 
近期基于得分匹配和流量匹配的生成模型显著提升了生成任务，但在判别任务中的潜力尚未被充分挖掘。尽管之前的一些方法，如生成分类器，尝试利用这些模型的生成能力来完成判别任务，但由于设计复杂，未能充分利用这些模型的潜在能力。因此，该研究提出了名为Pretrained Reversible Generation (PRG)的方法，通过反转预训练连续生成模型的生成过程来提取无监督表示。PRG能够有效重新利用预训练的生成模型，并利用它们的高度容量来为下游任务提供健壯且泛化的表征提取能力。该框架允许灵活地选择适合特定下游任务的特征层次结构。

Innovation: 
提出了Pretrained Reversible Generation (PRG)方法，这是一种新颖的通过对预训练连续生成模型进行逆向过程来提取无监督特征表示的方法。PRG的方法为利用生成模型在判别任务中的能力提供了一个新的视角，并且与之前的生成分类器方法相比，通过在多个基准测试上的表现，PRG方法展示了其在基于生成模型的方法中达到最先进的性能，例如在64*64分辨率的ImageNet数据集上达到了78%的top-1精度。此外，通过广泛的消融研究进一步证明了PRG方法的有效性，包括对未在训练数据中出现的样本的评估。相关代码可以在指定的网址获取。

Conclusion: 
Pretrained Reversible Generation (PRG)方法有效利用了预训练生成模型的高度容量，作为健壯且泛化的特征提取器，适用于下游任务。该方法在多个基准测试中取得了最先进的性能，并通过消融研究验证了其有效性。PRG不仅解决了未来的研究方向，还提供了为特定下游任务定制特征表示的一种新的灵活途径。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.01787</guid><pubDate>Fri, 27 Jun 2025 02:48:49 +0800</pubDate></item><item><title>37. cs.LG-子空间距离驱动的主动学习方法在参数动力系统数据驱动模型减少中的高效应用</title><link>https://arxiv.org/pdf/2505.00460</link><description>Background: 
当需要频繁评估高保真动力系统的解，并且无法访问其控制方程时，数据驱动的模型减少技术更为优选。为此，本文探讨了一种通过贪心选择参数域中最重要样本来构建参数化数据驱动降阶模型的新方法。降阶模型在构建阶段的高保真解的数量会以一种原则性的方式动态增长。利用主成分分析（POD）在多个参数特定线性子空间中表达高保真解快照，并利用线性子空间之间的相对距离作为引导机制进行主动学习。为了实现这一点，本文提供了一种衡量具有不同维度的线性子空间之间的相似性方法，并证明这种距离度量是一个度量。

Innovation: 
提出了一种子空间距离驱动的主动学习（SDE-AL）框架，该框架通过利用主成分分析在多个参数特定线性子空间中表达高保真解快照，并利用线性子空间之间的相对距离作为引导机制进行主动学习。同时，提供了一种新的距离度量方法，用于评估具有不同维度的线性子空间之间的相似性，并证明了该度量是一个度量。此外，通过对两个参数物理模型的成功测试，证明了所提SDE-AL方法的有效性，强调了该方法的效率。通过将SDE-AL框架应用于两个现有的非侵入性降阶建模方法，开发了主动学习增强的版本，即SDE-ActLearn-POD-KSNN和SDE-ActLearn-POD-NN

Conclusion: 
对两个参数物理模型的成功测试表明，所提出的SDE-AL方法是有效的，且方法显示出一定的效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.00460</guid><pubDate>Fri, 27 Jun 2025 02:48:44 +0800</pubDate></item><item><title>38. cs.LG-InterFormer: 针对点击率预测的有效异构交互学习</title><link>https://arxiv.org/pdf/2411.09852</link><description>Background: 
点击率（CTR）预测是推荐系统中的一个基本任务，其目的是预测用户点击广告的概率。随着用户档案和行为序列等异构信息的出现，用户兴趣可以从多个方面描绘。实现这些不同模式之间互惠互利的异构信息整合是CTR预测成功的基础。然而，现有的大多数方法存在两个基本限制：一是模式间单向信息流导致的交互不足，二是早期汇总导致的过于激进的信息聚合，从而导致信息丢失过多。

Innovation: 
为此，本文提出了一种名为InterFormer的新模块，以交错的方式学习不同模式之间的异构信息交互。InterFormer通过使不同模式之间的信息流双向流动，以实现更好的交互学习。为避免过于激进的信息聚合，InterFormer在每个数据模式中保留完整信息，并使用单独的桥梁结构进行有效信息选择和汇总。

Conclusion: 
我们的InterFormer在三个公开数据集和一个大规模工业数据集上取得了最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.09852</guid><pubDate>Fri, 27 Jun 2025 02:48:44 +0800</pubDate></item><item><title>39. cs.LG-LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey</title><link>https://arxiv.org/pdf/2505.00753</link><description>Background: 
近期，大规模语言模型（LLMs）的发展引起了对构建完全自主代理的兴趣。然而，基于LLM的完全自主代理仍然面临诸多挑战，包括幻觉导致的可靠性受限、处理复杂任务的难度以及重大的安全和伦理风险，这些限制了它们在实际应用中的可实现性和可信度。为了克服这些局限，基于LLM的人机协作系统（LLM-HAS）将人类提供的信息、反馈或控制纳入代理系统中，以增强系统性能、可靠性和安全性。这些合作系统通过利用人类和基于LLM的代理的互补优势，促进两者有效协作。

Innovation: 
本文提供了第一个全面和系统性的LLM-HAS综述。它阐明了基本概念，系统地呈现了这些系统的核心组件，包括环境与建模、人类反馈、交互类型、协调与通信，探讨了新兴应用，并讨论了人机协作带来的独特挑战和机遇。通过汇总现有知识并提供结构化的概览，本文旨在促进这一快速发展的跨学科领域的进一步研究和创新。

Conclusion: 
本文通过整合现有知识并提供系统的概览，旨在促进这一快速发展的跨学科领域的进一步研究和创新。相关列表和资源可在以下此 https URL 获取。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.00753</guid><pubDate>Fri, 27 Jun 2025 02:48:43 +0800</pubDate></item><item><title>40. cs.LG-基于多凸规划的离散潜因子模型原型设计</title><link>https://arxiv.org/pdf/2504.01431</link><description>Background: 
离散潜因子模型（DLFMs）广泛应用于机器学习、经济学、神经科学、心理学等领域。现有的DLFM建模依赖于为每个模型定制的求解器，这需要大量的实施工作，并且仅适用于特定类型的DLFM实例。因此，存在改进的空间，以提供一种更加通用和灵活的方法来构建和解决多种DLFM问题。

Innovation: 
本文提出了一种基于CVXPY的通用框架，允许用户在很短的脚本内指定并解决多种DLFM（包括回归和分类模型）的拟合问题，同时增强了参数和潜因子的正则化项和约束项的集成能力，使得用户可以根据数据集和应用场景轻松地原型化DLFM结构。这种方法比现有的定制求解器更加灵活和高效。

Conclusion: 
我们还提供了开源的Python实现，并在几个示例中展示了该框架的应用。这为快速和灵活地构建和测试DLFM模型提供了一个新的工具。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.01431</guid><pubDate>Fri, 27 Jun 2025 02:48:39 +0800</pubDate></item><item><title>41. cs.LG-通过广义平滑性下的自我边界规则高效逃脱鞍点</title><link>https://arxiv.org/pdf/2503.04712</link><description>Background: 
我们研究非凸函数（不一定光滑）的优化问题，这些函数的梯度和/或海森矩阵 Lipschitz。光滑性在机器学习中既是理论上的限制性假设，也是实践中的限制性假设，因此促使了寻找广义光滑性的方法来找到非凸函数的一阶平稳点。我们发展了一种新的框架，允许我们系统地研究满足广义光滑性的大量一阶优化算法的收敛性（我们称之为减少程序）。该研究展示了该框架的有效性，并突出其实用意义。

Innovation: 
我们开发了一种新的框架，允许系统地研究满足广义光滑性的大量一阶优化算法的收敛性。我们将其应用于分析到一阶和二阶平稳点的收敛性。作为结果，我们首次为满足广义光滑性的条件下的一阶方法提供二阶平稳点的收敛性保证。我们的研究涵盖了多个经典示例，强调了其实用性。

Conclusion: 
我们建立了满足广义光滑性的条件下，一阶方法达到二阶平稳点的第一个收敛性保证。这一研究扩展了一阶优化算法的应用范围，特别是在非凸优化中。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.04712</guid><pubDate>Fri, 27 Jun 2025 02:48:37 +0800</pubDate></item><item><title>42. cs.LG-情境感知双稳健半监督学习</title><link>https://arxiv.org/pdf/2502.15577</link><description>Background: 
在下一代通信系统中广泛应用人工智能（AI）面临着多变的网络和服务条件挑战，这也要求使用高度情境相关的、现场特定的数据。一种有希望的解决方案是不仅依赖现实世界的数据，还包括通过网络数字孪生（NDT）生成的合成伪数据。然而，这种方法的效果取决于NDT的准确性，后者在不同环境中可能会有很大差异。为解决这一问题，本文提出了一种情境感知双稳健（CDR）学习，这是一种新颖的半监督方案，根据NDT在不同环境中的不同精度调整其对伪数据的依赖度。该方法在下行链路波束形成任务上进行评估，证明其优于此前最先进的方法，在标定数据稀缺的条件下，与双稳健（DR）半监督学习相比，损失降低了24%。

Innovation: 
提出了一种情境感知双稳健（CDR）学习方法，这是一种新颖的半监督学习方案，能够根据NDT在不同环境中的不同精度调整其对伪数据的依赖度。该方法能够在数据稀缺条件下显著改进模型性能。

Conclusion: 
文中提出的情境感知双稳健（CDR）学习方法，在下行链路波束形成任务上超过了之前最先进的半监督学习方法，尤其是在标定数据稀缺的情况下，能够显著降低损失率。该技术有望通过准确适应不同环境中的准确性差异，提高AI在下一代通信系统中的应用效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.15577</guid><pubDate>Fri, 27 Jun 2025 02:48:32 +0800</pubDate></item><item><title>43. cs.LG-SDE Matching: 隐状态随机微分方程的可扩展且无需模拟的训练方法</title><link>https://arxiv.org/pdf/2502.02472</link><description>Background: 
Latent Stochastic Differential Equation (SDE) 是一种强大的时间序列和序列建模工具。然而，训练 Latent SDE 通常依赖于反向传播的伴随敏感性方法，这种方法依赖于模拟和对近似 SDE 解的反向传播，这限制了其可扩展性。由于这种方法依赖于模拟，因此计算复杂度较高，影响了其在大规模问题上的应用能力。

Innovation: 
本工作提出了一种新方法 SDE Matching，这是一种无需模拟的可训练 Latent SDE 的方法。受到现代得分匹配和流匹配算法的启发，我们将其扩展到随机动力学领域，用于时间序列和序列建模，从而消除了昂贵的数值模拟需求。与 adjoint sensitivity 方法相比，SDE Matching 的表现相当，但计算复杂性大大降低。

Conclusion: 
实验结果表明，SDE Matching 在性能上可与 adopted sensitivity 方法相媲美，但在计算复杂性上则有了显著改进。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.02472</guid><pubDate>Fri, 27 Jun 2025 02:48:31 +0800</pubDate></item><item><title>44. cs.LG-Split-Merge: 基于差异的主导特征值问题方法</title><link>https://arxiv.org/pdf/2501.15131</link><description>Background: 
对称半正定矩阵的主特征向量的计算是众多基于优化的应用的核心操作。传统的计算方法通常基于商形式，但常常面临着计算效率低下和对先验谱知识依赖的问题。

Innovation: 
本文利用基于差异形式的新视角重新解读经典幂法为了一阶优化算法，并提供了新的收敛分析方法，从而开发出具有更大步长的加速变体，以实现更快的收敛而无需额外的计算成本。通过这种方法，引入了一族广泛的意义上的基于差异的方法，并在此基础上提出了一种名为Split-Merge的算法，该算法在无需先验谱知识的情况下，仅通过矩阵-向量乘法就能达到加速收敛的效果。实验表明，Split-Merge在效率和可扩展性方面均优于现有的算法，特别是在大规模问题上，比经典幂法的速度提升超过10倍，进一步证明了其实用有效性。

Conclusion: 
本文提出的方法及其加速变体为解决大规模特征值问题提供了有效的工具，Split-Merge算法特别适用于无需任何先验知识的实际应用，并且在大规模数据集上表现出显著的性能优势。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.15131</guid><pubDate>Fri, 27 Jun 2025 02:48:26 +0800</pubDate></item><item><title>45. cs.LG-基于潜在域插件式去噪的无线电地图估计</title><link>https://arxiv.org/pdf/2501.13472</link><description>Background: 
无线电地图估计（RME）或谱图制作旨在从稀疏采样测量中重构不同域（如空间和频率）内的无线电干扰强度。现有RME方法依赖于手工构建或数据驱动的无线电地图结构信息，但前者难以建模复杂的射频环境，后者需要大量训练，难以快速适应现场传感任务。

Innovation: 
本文提出了一种基于插件式（PnP）去噪的新型空间频谱RME方法。该方法利用信号（如自然图像和无线电地图）去噪操作相似性的观察结果，直接利用自然图像的复杂去噪器辅助RME过程，避免使用无线电地图数据进行训练。所提方法在潜在域中进行去噪，并提出了一种基于ADMM算法的去噪方法，这在提高计算效率和增强噪声鲁棒性方面表现出色。

Conclusion: 
该研究分析了算法的理论方面，包括无线电地图的完整重构能力和ADMM算法的收敛性，并通过合成和实际数据实验验证了方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.13472</guid><pubDate>Fri, 27 Jun 2025 02:48:24 +0800</pubDate></item><item><title>46. cs.LG-利用无人机图像进行地理位置参考车辆轨迹提取的高级计算机视觉技术</title><link>https://arxiv.org/pdf/2411.02136</link><description>Background: 
本文提出了一种框架，用于从高空无人机图像中提取具有地理参考的车辆轨迹，旨在解决城市交通监控中的关键挑战，并克服传统地面系统中存在的局限性。研究选择在韩国京畿道的松岛国际商务区进行，覆盖了20个交叉口，采集了约12TB的4K视频数据，持续了四天。研究生成了两个高质量数据集：松岛交通数据集，包含约700,000个独特的车辆轨迹，以及松岛视觉数据集，包含超过5,000个人标注的图像，其中大约有300,000个车辆实例分为四类。与高精度传感器数据的对比表明，提取管道在密集的城市环境中具有准确性和一致性。

Innovation: 
本文的创新在于一个多方面的贡献，包括针对高空鸟瞰视角优化的定制目标检测器，使用检测到的车辆边界框作为排除掩码进行图像注册的独特轨迹稳定方法，以及基于正射影像和主框架的地理参考策略，从而提高了多个无人机视角之间的精确对齐。此外，本文框架还提供了用于综合交通分析的鲁棒车辆尺寸估计和详细的道路分割功能。

Conclusion: 
本文展示了将无人机技术与先进的计算机视觉技术相结合，在密集的城市环境中实现精确和成本效益的交通监控的潜力，提供了开发智能交通系统和改进交通管理策略的重要资源。最终，通过公开发布松岛交通和松岛视觉数据集及提取管道的完整源代码，建立了交通研究中数据质量、可复制性和可扩展性的新基准。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.02136</guid><pubDate>Fri, 27 Jun 2025 02:48:23 +0800</pubDate></item><item><title>47. cs.LG-通过凸优化求解多臂bandits逆问题</title><link>https://arxiv.org/pdf/2501.18945</link><description>Background: 
我们在神经科学和心理学研究中广泛使用多臂bandits（IMAB）逆问题来建模行为。然而，IMAB问题通常不是凸的，这使得直接求解变得困难。

Innovation: 
我们提出了一种两步序列启发式方法，该方法可以将IMAB问题转化为凸问题。该方法不仅提供了解决IMAB问题的全局解，还提供了进一步节省计算时间的近似方法。此外，我们的方法比直接的重复局部优化更稳健，并且可以在显著减少运行时间的情况下达到类似蒙特卡洛方法的性能。我们基于CVXPY提供了该方法的实现，使对凸优化不熟悉的研究者也能轻松使用。

Conclusion: 
我们的研究表明，与直接通过重复局部优化求解IMAB问题相比，使用启发式方法可以提供更稳健的解决方案，并且在显著减少运行时间的情况下达到与蒙特卡洛方法相当的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.18945</guid><pubDate>Fri, 27 Jun 2025 02:48:22 +0800</pubDate></item><item><title>48. cs.LG-SceneGenAgent：开发编码代理实现精确工业场景生成</title><link>https://arxiv.org/pdf/2410.21909</link><description>Background: 
工业场景模型对于工业制造中的仿真是必不可少的。尽管大型语言模型（LLMs）在生成多功能的3D场景方面取得了显著进展，但是使用LLMs生成工业场景存在独特挑战，因为这需要精确的尺寸测量和精确的布局定位，需要进行复杂的三维布置规划。

Innovation: 
本文引入了SceneGenAgent，这是一种基于C#代码的LLM代理，用于生成工业场景。它通过结构化和可计算的格式、布局验证和迭代精炼来确保精确的布局规划，以满足工业场景的定量要求。实验结果表明，使用SceneGenAgent的LLMs在真实工业场景生成任务中的成功率高达81.0%，并有效地满足了大部分场景生成需求。此外，还构造了SceneInstruct数据集，用于微调开源LLMs以整合到SceneGenAgent，实验表明，使用SceneInstruct微调开源LLMs可以显著提高性能，Llama3.1-70B的表现接近GPT-4o的水平。

Conclusion: 
SceneGenAgent通过微调开源LLMs来实现精确的工业场景生成，提高了LLMs在工业场景生成任务中的成功率和性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.21909</guid><pubDate>Fri, 27 Jun 2025 02:48:21 +0800</pubDate></item><item><title>49. cs.LG-用于动态偏好对齐的多偏好Lambda加权列表式DPO</title><link>https://arxiv.org/pdf/2506.19780</link><description>Background: 
大型无监督语言模型尽管能够捕捉广泛的世界知识和推理能力，但仍难以通过缺乏明确监督的行为引导。现有的对齐技术，如基于人类反馈的强化学习（RLHF），依赖于训练奖励模型并进行强化学习以使模型符合人类偏好。然而，RLHF通常计算量大、不稳定且对超参数敏感。为此，引入了直接偏好优化（DPO）作为轻量且稳定的替代方案，通过分类损失直接对齐语言模型与成对的偏好数据。然而，DPO及其扩展大多假设单个静态偏好分布，限制了在多目标或动态对齐设置中的灵活性。

Innovation: 
本文提出了一种新的框架：多偏好Lambda加权列表式DPO，将DPO扩展到结合多个人类偏好维度（例如：有用性、无害性、信息性）并在可控的简形加权形式下实现动态插值。该方法支持列表偏好反馈并且能够在多种用户意图下灵活对齐而无需重新训练。实证和理论分析表明，该方法在静态目标上与传统DPO同样有效，但在现实世界部署中提供了更大的通用性和适应性。

Conclusion: 
本文提出的方法在静态目标上与传统的DPO同样有效，但在多目标或动态对齐等方面提供了更大的灵活性和适应性。这种方法在实际部署中具有更强的通用性，能够在多种用户意图下灵活对齐，而无需重新训练模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19780</guid><pubDate>Fri, 27 Jun 2025 02:48:19 +0800</pubDate></item><item><title>50. cs.LG-基于新型联邦学习的IDS增强UAV的隐私和安全</title><link>https://arxiv.org/pdf/2312.04135</link><description>Background: 
无人驾驶飞行器（UAVs）在飞行自组网络（FANETs）中的操作面临安全挑战，因为这些网络具有动态和分布式的特性。以往的研究主要集中在中心化的入侵检测上，假设有一个中心实体负责存储和分析所有设备的数据。然而，这些方法面临成本、单一故障点和数据隐私与可用性的问题。数据在多个互联设备上的广泛分散表明需要去中心化的解决方案。因此，本文提出了基于联邦学习的入侵检测系统（FL-IDS），以解决中心化系统在FANETs中的问题。

Innovation: 
FL-IDS通过减少客户端和中央服务器的计算和存储成本，降低了资源受限的UAV的负担。它以去中心化的方式操作，使UAVs能够协作训练全局入侵检测模型而不共享原始数据，从而避免了传统方法因收集的数据导致的延迟。引入了Bias Towards Specific Clients（BTSC）方法，即使在较低的攻击者比例下也进一步增强了FL-IDS的性能，同时减轻了隐私问题。通过对比分析传统入侵检测方法，包括本地入侵检测（L-IDS），展示了FL-IDS的优势。

Conclusion: 
本研究通过引入基于联邦学习的、关注隐私的去中心化入侵检测方法，显著贡献于UAV安全。此外，通过为FANETs引入现实的联邦学习数据集，本研究区别于其他缺乏高动态性和三维节点移动验证的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2312.04135</guid><pubDate>Fri, 27 Jun 2025 02:48:14 +0800</pubDate></item><item><title>51. cs.LG-使用音素提示：提升非拉丁字母语言多语言能力的LLM</title><link>https://arxiv.org/pdf/2411.02398</link><description>Background: 
尽管多语言LLM在各种基准测试中取得了显著的性能，但它们在当代LLM家族中仍然在非拉丁字母语言方面表现不佳。这种差异源于LLM是在以拉丁字母为主的书写体系中进行预训练，这掩盖了它们与非拉丁字母书写体系在音韵上的共性。现有的研究表明，对于非拉丁字母语言的表现上有较大改进空间.

Innovation: 
本文提出了利用音素转写作为补充信号来诱导书写体系不变的表示方式。实验表明，结合音素信号可以提高非拉丁字母语言和拉丁字母语言的表现，并对未来非拉丁字母语言的表现差异影响显著。此外，通过详细的实验发现，音素和书写体系的转写在上下文学习中检索到的是不同的例子，因此提出了混合上下文学习（Mixed-ICL）检索策略。这种策略在拉丁和非拉丁字母语言表现上均显示出了比随机上下文学习显著的改进，特别是在非拉丁字母语言上提高可达15.1%.

Conclusion: 
总之，通过引入音素信号和提出的混合上下文学习策略，可以显著提升非拉丁字母语言的表现，特别是对现有技术表现的显著改善，特别是在非拉丁字母语言上表现尤为明显。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.02398</guid><pubDate>Fri, 27 Jun 2025 02:48:13 +0800</pubDate></item><item><title>52. cs.LG-复合流匹配在动态转移数据的强化学习中的应用</title><link>https://arxiv.org/pdf/2505.23062</link><description>Background: 
利用预先收集的离线数据可以显著提高强化学习（RL）的样本效率，但这一优势常受到源环境和目标环境过渡动力学差异的挑战。现有方法通常通过惩罚或过滤源过渡中的高动力学差异区域来解决这个问题，但它们的动力学差异估计往往依赖于KL散度或互信息，当源和目标动力学分布不相交时，这些估计可能不明确。

Innovation: 
提出了基于流匹配与最优传输理论联系的CompFlow方法。具体而言，将目标动力学建模为根据源领域流的输出分布构建的条件流，而非直接从高斯先验学习。这种复合结构提供了两个关键优势：（1）提升了学习目标动力学的泛化能力；（2）通过源和目标过渡之间的Wasserstein距离提供了动力学差异的原理性估计。进一步引入了一种乐观的主动数据收集策略，优先探索高动力学差异区域，并理论上证明该策略减少了与最优策略之间的性能差距。

Conclusion: 
实验结果显示，CompFlow在几个具有转移动力学的RL基准测试中优于强基线方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.23062</guid><pubDate>Fri, 27 Jun 2025 02:48:13 +0800</pubDate></item><item><title>53. cs.LG-使用动量改进随机三次牛顿法</title><link>https://arxiv.org/pdf/2410.19644</link><description>Background: 
研究随机二阶方法以解决一般的非凸优化问题。现有的随机二阶方法通常需要大规模批量，这使得它们在实际应用中受限。论文探讨了如何改进随机梯度和海森矩阵估计的稳定性，使用特殊的动量机制来提升随机梯度的方差，并验证了该方法在非凸问题上的全局收敛性。同时，在凸问题上展示了改进了的迭代速度。

Innovation: 
提出了一种特殊的动量机制稳定随机梯度和海森矩阵估计，使用三次正则化技术证明了一种新的随机三次牛顿法在任何噪声级别下都能收敛，并且能够在非凸问题中使用任意大小的数据批次进行全局收敛，这是针对非凸问题的第一个此类示例。

Conclusion: 
该研究通过增加动量改进了随机三次牛顿法，并证明了其在非凸问题中的全局收敛性，即使每次迭代只使用一个随机数据样本，而在凸问题中也展示了改进的迭代速度。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.19644</guid><pubDate>Fri, 27 Jun 2025 02:48:11 +0800</pubDate></item><item><title>54. cs.LG-变分监督对比学习</title><link>https://arxiv.org/pdf/2506.07413</link><description>Background: 
对比学习已被证明在多种模式下高效且适应性强，通过将相似样本拉近、将不相似样本推远来塑造表示空间。然而，对比学习存在两大局限性：（1）如果没有对嵌入分布进行明确调节，除非互补信号指导配对选择，否则语义相关实例可能会被无意中分开；（2）对比学习过度依赖于大批量负样本和定制化增强，这限制了泛化能力。

Innovation: 
本文提出了一种变分监督对比学习（VarCon），它将监督对比学习重新表述为潜在类别变量的变分推理，并最大化后验加权下的证据下界（ELBO），这种方法取代了耗时的配对对比，实现了类感知的高效匹配，并在嵌入空间内实现更精细的类内分布控制。VarCon仅使用图像数据进行训练，在CIFAR-10、CIFAR-100、ImageNet-100和ImageNet-1K上的实验表明，它能够实现对比学习框架的最先进性能，达到了ImageNet-1K上79.36%的最高精度和CIFAR-100上78.29%的精度，并仅在200个epochs内收敛；由KNN分类、层次聚类结果和迁移学习评估可见，VarCon在嵌入空间中的边界更为清晰且有更清晰的语义组织；此外，VarCon在少量样本学习中优于监督基准，并且具有更强的泛化能力，适应各种增强策略的鲁棒性更好。

Conclusion: 
变分监督对比学习（VarCon）通过将监督对比学习重新表述为变分推理，并通过最大化后验加权下的证据下界实现了优化的类内分布控制和高效匹配，证明了其在对比学习、少量样本学习以及泛化能力方面的优势。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07413</guid><pubDate>Fri, 27 Jun 2025 02:48:08 +0800</pubDate></item><item><title>55. cs.LG-MINO：一种基于网格的变换生成方法</title><link>https://arxiv.org/pdf/2506.16656</link><description>Background: 
生成模型在函数空间中的应用，结合了生成建模和操作符学习，因其在多个科学和工程领域的巨大潜力而受到越来越多的关注。尽管功能性生成模型理论上对领域和离散化方式是不依赖的，但当前的实现方式严重依赖Fourier Neural Operator (FNO)，这限制了其在非规则网格和非矩形域中的应用。为克服这些限制，我们引入了Mesh-Informed Neural Operator (MINO)。MINO通过利用图神经操作符和交叉注意力机制，为生成建模提供了一个原理上、领域和离散化方式不依赖的框架，显著扩大了此类模型的应用范围，可应用于生成、逆问题和回归任务。此外，MINO提供了一种整合神经操作符和通用先进深度学习架构的统一视角。最后，我们引入了一套标准的评估指标，使得功能性生成模型之间的客观比较成为可能，从而填补了该领域的空白。

Innovation: 
我们提出了Mesh-Informed Neural Operator (MINO)，通过利用图神经操作符和交叉注意力机制，为生成建模提供了原则上、领域和离散化方式不依赖的支持。MINO显著扩大了此类模型的应用范围，并提供了一种整合神经操作符和通用先进深度学习架构的统一视角。此外，我们还引入了一套标准的评估指标，以客观比较功能性生成模型。

Conclusion: 
MINO突破了传统生成模型的局限，通过提供一个通用的框架，使其能够应用于更广泛的任务类型。该工作不仅为功能性生成模型提供了一个新的视角，还填补了领域内缺乏统一评估标准的空白。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16656</guid><pubDate>Fri, 27 Jun 2025 02:48:05 +0800</pubDate></item><item><title>56. cs.LG-具有编码数据结构的可解释量子回归算法</title><link>https://arxiv.org/pdf/2307.03334</link><description>Background: 
混合变量子算法（VQAs）在解决组合优化、量子化学模拟、量子机器学习和量子错误纠正等问题上具有潜力，特别是在嘈杂的量子计算机上。然而，通常使用典型随机模板或量子交替操作模板，所得到的变量子算法成为黑盒，无法进行模型解释，更不用说将其部署为应用程序来指导关键决策了。变量子算法中的变量子参数仅仅是量子门的旋转角度，这些参数并没有直接的行为模型能提供的可解释值。因此，本文提出了一种新的可解释量子回归算法，其中量子态准确编码了经典数据表，变量子参数直接映射到回归系数，这些系数是通过构造得到的真实数，具有高度的模型可解释性，并且由于正确的表达能力，优化成本也相对较低。此外，利用编码数据结构还可以减少回归映射的计算时间复杂度。为了缩短非线性回归的电路深度，可以通过经典的预处理构建非线性特征作为独立的编码列向量来拓展算法。尽管在超导量子位中已经实现了较无噪声压缩编码的压缩编码实现，作者认为未来的潜在的量子用途可能是在中性冷原子和离子中实施数字多量子门的操作，以实现压缩编码。

Innovation: 
提出了第一个可解释的量子回归算法，其中量子态精确地编码了经典数据表，并且变量子参数直接对应到回归系数，这些系数是通过构造得到的真实数，具有高度的模型可解释性，并且由于正确的表达能力，优化成本也相对较低。此外，该算法利用编码数据结构减少了回归映射的计算时间复杂度。对于非线性回归优化，通过经典的预处理构建非线性特征作为独立的编码列向量。尽管在超导量子位中实现了较无噪声压缩编码的压缩编码实现，该方法未来可能在中性冷原子和离子中实现通过多量子门操作的压缩编码，具有潜在的量子用途。

Conclusion: 
本文提出了一种新的可解释量子回归算法，通过将经典数据表有效地编码到量子态中，并使变量子参数直接对应到可解释的回归系数，提高了模型的可解释性。这种方法还通过利用编码数据结构减少了计算复杂度，并且具有潜在的量子用途，特别是在中性冷原子和离子的多量子门操作中实现压缩编码。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2307.03334</guid><pubDate>Fri, 27 Jun 2025 02:48:04 +0800</pubDate></item><item><title>57. cs.LG-在作者和文档表示中捕捉风格</title><link>https://arxiv.org/pdf/2407.13358</link><description>Background: 
现有的深度自然语言处理（NLP）模型主要整合了单词和文档的连续性和低维度表示。然而，这些模型鲜有研究作者的表示学习，而作者的表示可以用于许多NLP任务，如作者识别和分类，或在推荐系统中应用。现有工作中一个主要局限是它们没有明确捕捉写作风格，使其难以应用于文学数据。因此，本文提出了一种基于变分信息瓶颈（VIB）的新架构，该架构在具有风格约束的情况下学习作者和文档的嵌入。该模型在预训练的文档编码器上进行了微调，通过添加预定义的风格特征来刺激风格的检测，并使表示轴与写作风格指标可解释。

Innovation: 
本文提出了一种基于变分信息瓶-neck（VIB）的新架构，该架构学习带有风格约束的作者和文档嵌入。该模型通过预训练文档编码器进行微调，通过添加预定义的风格特征来增强写作风格的检测，并使其表示更易于解释。试验结果显示该方法在三组数据集上与强或最新的基线相比表现优异，更好地捕捉了作者的风格特征。

Conclusion: 
我们提出的新模型在三个数据集上评估了作者身份识别任务，显示了在作者身份识别方面与强或最新的基线方法相比，该方法在精确识别作者风格方面表现更佳。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.13358</guid><pubDate>Fri, 27 Jun 2025 02:48:02 +0800</pubDate></item><item><title>58. cs.LG-Self-Regulated Neurogenesis for Online Data-Incremental Learning</title><link>https://arxiv.org/pdf/2403.14684</link><description>Background: 
神经网络在学习连续任务序列或数据流时常面临灾难性遗忘的问题，相比之下，人类能够连续学习和巩固新概念，即使没有明确的提示。在线数据增量学习试图模仿这种能力，通过只处理每个样本一次且不依赖任务或数据流的提示来实现，这种方法在实际场景中更为合理，不同于离线设置，后者假定所有新类别的数据可以随时获取。现有的方法通常依赖于存储数据子集或扩展初始模型结构，这导致了巨大的计算开销。

Innovation: 
该研究受到‘自我调节神经发生’机制的启发，即大脑创造专门用于不同功能的区域或电路的机制，提出了一种名为SERENA（Self-Regulated Neurogenesis for Online Data-Incremental Learning）的新颖方法。此方法将每个概念编码为一个专门的网络路径‘概念细胞’，集成到一个超参数化的网络中。一旦概念被学习，对应的概念细胞被冻结，从而防止之前学习信息的遗忘。此外，还引入了两种新的连续学习场景，更能反映现实条件，即样本大小逐渐变化的情况。实验证明，该方法不仅在十个基准测试中设定新的SOTA结果，还显著超过了离线监督批量学习的性能。

Conclusion: 
实验结果表明，SERENA方法不仅在十个基准上取得了新的SOTA结果，还显著优于离线监督批量学习的性能。该方法通过在一个集成模型中为每个新概念创建一个专门的‘概念细胞’，解决了神经网络在线增量学习中的灾难性遗忘问题，实验证明了其实用性和有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.14684</guid><pubDate>Fri, 27 Jun 2025 02:47:57 +0800</pubDate></item><item><title>59. cs.LG-图神经网络在中微子物理事件重构中的应用</title><link>https://arxiv.org/pdf/2403.11872</link><description>Background: 
LArTPC探测器技术能够提供关于粒子相互作用的高分辨率信息，但要充分利用这些信息，需要先进的自动重建技术。微中子在LArTPC探测器中的模拟相互作用被描述为异构图，其中每个探测器平面的能量沉积形成平面子图的节点。因此，需要一种高效的图神经网络来处理这些数据并进行粒子的精确识别和分类。

Innovation: 
提出了一种名为NuGraph2的图神经网络（GNN），用于低层模拟微中子在LArTPC探测器中的相互作用重构。该网络通过一种多头注意力信息传递机制对图节点进行背景过滤和语义标签识别，可以以98.0%的效率识别与主要物理相互作用相关的节点，并以94.9%的效率进行粒子类型的标签分类。网络直接作用于多层2D表示，并结合3D上下文感知机制确保不同表示的一致性。该模型在CPU上的推理时间仅为0.12秒/事件，在GPU上批处理时仅为0.005秒/事件。

Conclusion: 
该网络架构适用于LArTPC探测器中的粒子重构，并且具有广泛推广到不同探测器技术领域的潜力。它还提供了一个可部署到多种任务的核心卷积引擎。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.11872</guid><pubDate>Fri, 27 Jun 2025 02:47:48 +0800</pubDate></item><item><title>60. cs.LG-Review learning: 实现医疗机构间隐私保护持续学习的现实验证</title><link>https://arxiv.org/pdf/2210.09394</link><description>Background: 
在不同数据集上依次训练深度学习模型时，模型往往会忘记先前数据中学习到的知识，这种现象被称为灾难性遗忘。这在基于迁移学习的隐私保护深度学习（PPDL）应用中尤为关键，会损害模型在各种数据集上的性能。

Innovation: 
引入了一种名为 'review learning'（RevL）的低消耗持续学习算法，用于电子健康记录（EHR）的诊断预测。RevL通过生成源自模型的数据样本，来回顾先前数据集中的知识。通过六次模拟的机构实验和一次真实世界实验，验证了RevL的能力与效果。

Conclusion: 
RevL能够在保留先前学习的知识的同时，在模拟和实际医疗环境中提高PPDL的性能，表明了RevL在机构间使用私有EHR数据进行模型转移的现实可行性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2210.09394</guid><pubDate>Fri, 27 Jun 2025 02:47:48 +0800</pubDate></item><item><title>61. cs.LG-从Tiny机器学习到Tiny深度学习：综述</title><link>https://arxiv.org/pdf/2506.18927</link><description>Background: 
随着边缘设备的快速增长，对在边缘部署人工智能(AI)的需求增加，促使了Tiny机器学习(TinyML)和其演变版本Tiny深度学习(TinyDL)的发展。TinyML最初旨在使简单的推断任务能够在微控制器上实现，而TinyDL则标志着向在资源受限硬件上部署深度学习模型的范式转变。本文综述了从TinyML到TinyDL的过渡，涵盖了架构创新、硬件平台、模型优化技术和软件工具链等方面。

Innovation: 
本文分析了最先进的量化、剪枝和神经架构搜索(NAS)方法，并探讨了从微控制器到专用神经加速器的硬件趋势。此外，本文分类了软件部署框架、编译器和AutoML工具，以实现实际的设备内置学习。文章回顾了跨计算机视觉、音频识别、医疗健康和工业监测等领域的应用，以说明TinyDL的现实世界影响。最后，本文提出了新兴方向，包括神经形态计算、联邦TinyDL、边缘原生基础模型和领域特定协同设计方法。这为研究人员和实践者提供了一个全面的生态视图，为未来的边缘AI进展奠定了基础。

Conclusion: 
本文旨在作为研究人员和从业人员的基础资源，提供一个全面的生态系统视图，并为未来的边缘AI进展奠定基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18927</guid><pubDate>Fri, 27 Jun 2025 02:47:24 +0800</pubDate></item><item><title>62. cs.LG-PuriDefense: 随机局部隐式对抗净化用于防御黑盒查询式攻击</title><link>https://arxiv.org/pdf/2401.10586</link><description>Background: 
黑盒查询攻击对机器学习即服务（MLaaS）系统构成了重大威胁，因为它们能够在不访问目标模型架构和参数的情况下生成对抗样本。传统防御机制，如对抗训练、梯度屏蔽和输入变换，要么会产生显著的计算成本，要么会损害非对抗输入的测试准确性。

Innovation: 
提出了一种高效防御机制PuriDefense，该机制在较低的推理成本下采用随机块级净化，并结合了轻量级净化模型的集成，利用局部隐式函数重建自然图像流形。理论分析表明，这种方法通过净化过程中的随机性减慢了查询式攻击的收敛速度。广泛实验在CIFAR-10和ImageNet上验证了提出防御机制的有效性，显示出对抗黑盒查询攻击的鲁棒性显著提高。

Conclusion: 
实验结果表明，PuriDefense在对抗黑盒查询式攻击方面表现出显著的鲁棒性改进，验证了其在MLaaS系统中的防御效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2401.10586</guid><pubDate>Fri, 27 Jun 2025 02:47:16 +0800</pubDate></item><item><title>63. cs.LG-高维上下文贝叶斯问题无需稀疏性</title><link>https://arxiv.org/pdf/2306.11017</link><description>Background: 
本文研究高维线性上下文贝叶斯问题，其中特征数量p大于预算T，甚至可以是无限的。与该领域大多数先前工作不同，本文不假设回归系数是稀疏的，而是利用了过参数化模型的最新发现，以分析数据分布具有小有效秩时最小范数插值估计器的表现。

Innovation: 
提出了一个探索-然后-承诺(EtC)算法来解决这个问题，并考察了其性能。通过分析，推导出了EtC算法的最优速率，显示了通过平衡探索和利用可以实现该速率。此外，引入了一个自适应探索-然后-承诺(AEtC)算法以自适应地找到最优平衡。

Conclusion: 
本文提出了EtC和AEtC算法，并通过一系列模拟评估了它们的性能。通过分析，得出了EtC算法的最优速率，证明了通过平衡探索与利用可以实现此速率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2306.11017</guid><pubDate>Fri, 27 Jun 2025 02:47:14 +0800</pubDate></item><item><title>64. cs.LG-Devil's Hand: 数据泄露攻击对本地私密图学习协议</title><link>https://arxiv.org/pdf/2506.09803</link><description>Background: 
图神经网络（GNNs）已经在图表示学习中取得了显著成就，并被广泛应用到多个领域。然而，许多现实世界的图中包含个人敏感信息，如社交网络中的用户档案，在使用GNN进行图学习时会引发严重的隐私问题。为解决这一问题，本地差分隐私（LDP）下的基于本地秘密图学习协议受到了广泛关注。这些协议结合了LDP的隐私优势和GNN消息传递的有效性来校准噪声数据，为保护用户本地数据的隐私提供了严格的保证，同时维持了图学习中的高实用性（如节点分类准确性）。然而，这些协议可能容易受到数据投毒攻击，而这种攻击在之前的研究所中并未得到考虑。识别和解决这些攻击至关重要，以确保隐私保护图学习框架的稳健性和安全性。

Innovation: 
该研究是首个针对基于本地隐私的图学习协议的数据投毒攻击。攻击方注入虚假用户，引导这些虚假用户与真实用户建立联系，并向服务器发送精心构建的数据，最终损害了私密图学习的实用性。研究不仅在理论上证明了攻击的有效性，还在实际中进行了验证。此外，还探索了几种防御策略，但其有限的有效性突显了需要更 robust 的防御的必要性。

Conclusion: 
本研究揭示了本地隐私图学习协议面临的一个重要安全威胁，数据投毒攻击。通过理论和实际验证，展示了攻击的可行性。进一步探索的防御策略虽有尝试，但仍需更加 robust 的解决方案来保障系统的稳健性和安全性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.09803</guid><pubDate>Fri, 27 Jun 2025 02:47:08 +0800</pubDate></item><item><title>65. cs.LG-使用可变注意头高效生成图像</title><link>https://arxiv.org/pdf/2211.05770</link><description>Background: 
尽管将变压器融合到视觉模型中在视觉任务上取得了显著提升，但在训练和推理阶段仍需大量计算资源。限制性注意机制能显著减少计算负担，但会丧失全局或局部的一致性。因此，如何在保持视觉任务性能的同时降低计算成本成为当前研究的难题。

Innovation: 
本文提出了一种简单而强大的方法——允许单一变压器的注意头能够关注多个感受野，以此解决计算成本和视觉任务性能之间的权衡问题。通过将该方法称为Neighborhood Attention (NA)集成到StyleGAN架构中，实现了在FFHQ数据集上的FID为2.05，相比StyleGAN-XL提高了6%，同时参数减少了28%，吞吐量提高了4倍。该方法在FFHQ-256上达到了帕累托前沿，在其他数据集上证明了其高效且强大的图像生成能力。

Conclusion: 
本文提出的方法StyleNAT，在保持高性能的同时减少了计算负担，展示了在多种数据集上的高效图像生成能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2211.05770</guid><pubDate>Fri, 27 Jun 2025 02:47:05 +0800</pubDate></item><item><title>66. cs.LG-Onsager-Machlup 功能与生成模型相遇：基于 Onsager-Machlup 功能高效路径采样</title><link>https://arxiv.org/pdf/2504.18506</link><description>Background: 
过渡路径采样（TPS）涉及在能量景观上找到两点之间的可能路径，由于现实世界原子系统的复杂性，这一过程仍然是一个挑战。当前的机器学习方法需要昂贵的、特定任务的、无需数据的训练程序，限制了它们能够从高质量数据集和大规模预训练模型中受益的能力。

Innovation: 
本文通过将候选路径解释为由预训练生成模型（具体为去噪扩散和流匹配）学习的评分函数诱导的随机动力学下的轨迹采样，提出了一种新的方法。在这些动力学下，找到高概率的过渡路径等同于最小化 Onsager-Machlup (OM) 动作泛函。这种方法允许直接利用预训练生成模型进行 TPS，而无需专门针对任务的训练。该方法在多种分子系统上得到验证，得到了多样且物理上可实现的过渡路径，并且能够泛化到预训练模型最初训练数据集之外。这种方法可以轻松集成到新的生成模型中，使其在模型继续扩展和改善时变得实际相关。

Conclusion: 
该方法在多种分子系统中获得了多样化、物理上现实的过渡路径，可泛化到预训练模型的原始训练数据集之外，并且可以轻松集成到新模型中，显示出其实用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.18506</guid><pubDate>Fri, 27 Jun 2025 02:47:03 +0800</pubDate></item><item><title>67. cs.LG-PARALLELPROMPT: 从大规模语言模型查询中提取并行性</title><link>https://arxiv.org/pdf/2506.18728</link><description>Background: 
传统的大语言模型服务系统通常将用户提示视为单一输入，并通过解码技巧或查询批量处理来优化推理。然而，许多现实中的提示可能包含潜在的语义并行性，即可以分解为子任务以独立执行，从而减少延迟同时保留意义。

Innovation: 
本文引入了PARALLELPROMPT，这是第一个用于测量自然用户查询中查询内部并行性的基准。该基准包括一个包含37,000多个公共LLM对话日志中真实提示的数据集，每个提示都附有捕获任务模板、共享上下文和迭代输入的结构化模式。这些模式是通过LLM辅助提示和基于规则的多语言验证提取的。为了评估分解的效益，还提供了一个执行套件，比较了串行和并行策略，测量了延迟、结构兼容性和语义保真度。结果表明，有针对性的数据集中有75%以上的查询可以成功解析为并行性，对于如翻译、理解以及比较分析等任务，可以实现高达5倍的速度提升，且质量下降较小。为此，本研究发布了基准、标注管道和评估套件，提供了一个标准化的研究平台来研究结构感知的大语言模型服务管道执行.

Conclusion: 
通过发布此基准、标注管道和评估套件，首次提供了标准化的研究平台来研究结构感知的大语言模型服务管道执行。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18728</guid><pubDate>Fri, 27 Jun 2025 02:47:01 +0800</pubDate></item><item><title>68. cs.LG-使用Noise Estimation through Reinforcement-based Diffusion (NERD)模型揭示神经不确定性表示</title><link>https://arxiv.org/pdf/2503.14333</link><description>Background: 
以往的研究通常旨在揭示“初级”表征（FORs），这些表征记录了观察者环境的方面，如内容或结构。较少关注的是“高级”表征（HORs），这些都是关于FORs的，例如它们的强度或不确定性，并可能有助于学习。关于不确定性预期的HORs不大可能是FOR特征的直接读出，而是反映了包含不确定性预期的噪声估计过程。现有研究尚不清楚大脑如何表示这种预期的不确定性分布。该研究通过神经反馈解码的任务，旨在研究大脑如何处理这类任务并使用NERD模型对其过程进行建模

Innovation: 
开发并应用了Noise Estimation through Reinforcement-based Diffusion (NERD)模型，这个模型用来描述大脑在必要时学习并估计自己噪声的过程。该研究展示了NERD模型强大的解释能力，适用于人类行为的解释

Conclusion: 
研究表明使用NERD模型能够有效地揭示大脑如何估计和学习它们的噪声，特别是关于不确定性的高级表征，并且该模型能够显著地解释人类在这种任务中的行为。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.14333</guid><pubDate>Fri, 27 Jun 2025 02:46:55 +0800</pubDate></item><item><title>69. cs.LG-ScaleGNN：通过自适应高阶邻域特征融合迈向可扩展的图神经网络</title><link>https://arxiv.org/pdf/2504.15920</link><description>Background: 
图神经网络（GNNs）通过消息传递捕捉复杂的节点关系，在多样化的图基任务中表现出色。但是，在应用于大规模现实世界图时，GNNs 面临两个主要挑战：首先，确保可扩展性和效率变得更加困难，因为多次聚合大范围的邻域导致了大量的计算开销；其次，过平滑问题出现，在过度或深层传播的条件下，节点表示变得难以区分，严重影响模型的表现力。为解决这些问题，我们提出了 ScaleGNN，一个新颖的框架，它可以适配地融合多跳节点特征，既能够实现高效的扩展性，也保持有效的图学习。

Innovation: 
ScaleGNN 通过自适应地融合多跳节点特征来解决大型图学习中的可扩展性和表达能力问题。首先，构建了每个跳的纯邻居矩阵，仅捕捉每一跳独有的结构信息，避免了传统聚合的冗余。然后，采用了增强的特征融合策略，显著平衡了低阶和高阶信息，保持局部细节和全局联系，而不会引入过高的复杂度。此外，引入了基于局部贡献分数（LCS）的掩码机制，过滤掉不相关的高阶邻居，确保只有最有意义的信息被聚合。并且，可学习的稀疏约束选择性地整合多跳有价值特征，强调最具有信息含量的高阶邻居。在多个真实世界数据集上的实验证明，ScaleGNN 在预测准确性和计算效率上都优于现有的最先进的 GNNs，突显了其在大型图学习中的实用价值。

Conclusion: 
实验结果表明，ScaleGNN 在预测准确性和计算效率方面都优于现有的最先进的 GNNs，展示了其在大规模图学习中的实际价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.15920</guid><pubDate>Fri, 27 Jun 2025 02:46:46 +0800</pubDate></item><item><title>70. cs.LG-这些都不是您想要的所有特征：监督预训练中的一个基本瓶颈</title><link>https://arxiv.org/pdf/2506.18221</link><description>Background: 
转移学习是现代机器学习中的一个基石，它允许可在多种数据上预先训练的模型以最少的新数据适应新的任务。然而，一个主要挑战在于确保转移特征能够处理未见过的数据集，且量化两个任务是否相关也十分困难。为了应对这些挑战，该研究评估了预训练混合模型在各个组件任务上的转移，考察了预训练特征是否可以达到任务特定直接训练的性能。该研究揭示了深度学习模型中的一个根本性限制——“信息饱和瓶颈”，即在训练过程中编码相似竞争特征后，网络将无法学习新的特征。在仅学习预训练中一部分关键特征的限制条件下，模型会永久失去对迁移至关重要的特征，并在数据分布上表现不一致，即使是在预训练数据混合的一部分范围内。已有研究的证据表明，这一现象在深度学习架构中普遍存在——数据分布或顺序等因素会影响当前表示学习方法随时间能够学习的特征。

Innovation: 
该研究揭示了深度学习模型中的信息饱和瓶颈，并通过评估模型从预训练混合数据到各个组件任务的转移，提出了一个潜在的解决方案——更丰富的特征表示，以更好地在新数据集上泛化，同时还介绍了一种新的方法来应对这一挑战，即初步步骤。研究建议，当有特定任务时，依赖大规模网络可能不如专注于特定任务的训练有效。

Conclusion: 
该研究揭示了监督预训练中信息饱和瓶颈的重要性，并强调了依赖大型网络可能不如针对特定任务进行训练有效。研究提出更丰富的特征表示作为一种可能的解决方案，旨在更好地跨新数据集泛化，并还介绍了一种新的方法，这是应对这一挑战的初步尝试。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18221</guid><pubDate>Fri, 27 Jun 2025 02:46:42 +0800</pubDate></item><item><title>71. cs.LG-基于理性的内在上下文学习策略自然涌现</title><link>https://arxiv.org/pdf/2506.17859</link><description>Background: 
近期有关内在上下文学习（ICL）的研究已经鉴别出了一系列不同的策略，用于不同实验条件下的模型行为。然而，这些发现仍然缺乏统一解释，即模型为何在这些条件下学习不同策略。此前的研究发现，在混合任务训练下模型学习的ICL策略可以被一种由贝叶斯预测器组成的家族解释，包括一种依赖于已见任务的离散先验的记忆预测器，和一种与底层任务分布相符的泛化预测器。

Innovation: 
本文采用理性分析视角下的规范性框架，提出一种分层贝叶斯框架，几乎完全预测了Transformer的下一步预测，不依赖于其权重信息。预训练被视作更新不同策略后验概率的过程，推理时刻的行为是这些策略预测的加权平均。认为候选策略复杂度和损失之间的权衡决定模型如何实施策略偏好，这有助于解释已知的ICL现象并提出新的预测。例如，当任务多样性增加时，从泛化到记忆的过渡时间有超线性趋势。

Conclusion: 
本文通过策略复杂度与损失之间的权衡提出了一种解释性和预测性的ICL框架，为理解模型在不同条件下的行为提供了一个新的视角。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17859</guid><pubDate>Fri, 27 Jun 2025 02:46:31 +0800</pubDate></item><item><title>72. cs.LG-基于潜在扩散模型的去噪接收器在6G语义通信中的应用：从随机微分理论到应用</title><link>https://arxiv.org/pdf/2506.05710</link><description>Background: 
本文提出了一种基于生成人工智能（GAI）的新型语义通信框架，旨在增强对信道噪声和传输数据分布变化的鲁棒性。基于随机微分方程（SDEs）建立了理论基础，从而推导出信噪比（SNR）与最优去噪时间步长之间的解析映射。此外，为了应对分布不匹配问题，引入了一种数学倍率方法，以使接收到的语义特征与GAI训练分布相匹配。依靠这一理论基础，提出了一种基于潜在扩散模型（LDM）的语义通信框架，结合了变分自编码器来进行语义特征提取，并使用预训练的扩散模型进行去噪。该系统是一种无需训练的框架，支持零样本泛化，并在低SNR和分布外条件下实现了卓越的性能，为未来6G语义通信系统提供了可扩展且鲁棒的解决方案。实验结果表明，所提出的语义通信框架在像素级准确性和语义感知质量方面达到了最先进的性能，且在广泛的SNR和数据分布条件下普遍优于基线，无需任何微调或后训练。

Innovation: 
提出了一种基于生成人工智能（GAI）的新型语义通信框架，该框架结合了变分自编码器和潜在扩散模型，用于语义特征提取和去噪，实现了在低信噪比和数据分布变化条件下的卓越性能。引入了数学倍率方法来解决接收到的语义特征与训练分布的不匹配问题。理论分析推导出了信噪比与最优去噪时间步长之间的解析映射。所提出的框架支持零样本泛化，适用于未来6G语义通信系统的可扩展且鲁棒的解决方案。

Conclusion: 
所提出的基于潜在扩散模型的去噪接收器在6G语义通信中实现了优秀的语义感知质量和像素级准确性，在广泛的信噪比和数据分布条件下达到了最先进的性能，并且无需进一步的微调或培训。该框架为未来6G通信系统提供了可扩展且鲁棒的解决方案，支持零样本泛化。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.05710</guid><pubDate>Fri, 27 Jun 2025 02:46:18 +0800</pubDate></item><item><title>73. cs.LG-不平衡图之间最优传输计划的无监督学习</title><link>https://arxiv.org/pdf/2506.12025</link><description>Background: 
基于Gromov-Wasserstein和其他拓展的图最优传输是对比和对齐图结构的强大工具。然而，解决伴随的非凸优化问题非常耗时，限制了这些方法在大型图上的应用范围。

Innovation: 
提出了不平衡学习最优传输（ULOT）方法，一种深度学习方法，用于预测图之间的最优传输计划。该方法通过最小化融合不平衡Gromov-Wasserstein（FUGW）损失进行训练，采用包含交叉注意力的神经架构，并且该架构在FUGW权重超参数上进行了条件化。ULOT能够使用合成随机块模型图和来自fMRI的真实皮层表面数据进行评估。与经典求解器相比，ULOT预测传输计划的速度快两个数量级且具有竞争力。此外，预测的计划可以作为经典求解器的暖启动以加速其收敛。最后，预测的传输计划完全相对于图输入和FUGW超参数可微，为优化ULOT计划的功能提供了可能。

Conclusion: 
ULOT方法通过快速而准确地预测图之间的传输计划，显著提高了图最优传输的效率和可扩展性，为优化图上的函数提供了一种有效的方式。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12025</guid><pubDate>Fri, 27 Jun 2025 02:46:15 +0800</pubDate></item><item><title>74. cs.LG-始终跳过注意力机制</title><link>https://arxiv.org/pdf/2505.01996</link><description>Background: 
本文探讨了现代Vision Transformers（ViTs）中出现的一个有趣的实证现象。自注意力机制（self-attention mechanism）在没有跳过连接（skip connection）的情况下无法有效训练，与ViT的其他部分不同，这些部分在去除跳过连接后仍然表现良好（尽管不理想）。此外，文中指出，这种跳过连接依赖现象是相对较新的，以往的深层架构（例如，CNN）即使没有跳过连接也能表现出良好的性能。

Innovation: 
本文理论地解释了自注意力机制本质上是病态条件的，并因此唯一依赖于跳过连接来实现正则化。与此同时，提出了Token Graying——一种简单的有效方法（补充跳过连接），进一步改善输入令牌的状态。验证了这种方法在监督学习和半监督学习中的适用性。

Conclusion: 
本文强调了自注意力机制需要跳过连接才能有效训练的重要性，并通过理论解释了这种依赖关系。同时提出了一种新的方法来改善输入令牌的状态，并通过实验证明了该方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.01996</guid><pubDate>Fri, 27 Jun 2025 02:46:10 +0800</pubDate></item><item><title>75. cs.LG-能量匹配：生成建模中流动匹配和能量模型的统一框架</title><link>https://arxiv.org/pdf/2504.10612</link><description>Background: 
当前最广泛使用的生成模型通过匹配流动或分数来映射噪声和数据分布，但这些模型在处理部分观察和附加先验时存在困难。能量模型（EBM）则通过简单地添加对应的标量能量项来优雅地解决这一问题。本文旨在通过提出能量匹配框架，赋予流动模型方法EBM的灵活性，解决上述问题。

Innovation: 
提出了一种新的能源匹配框架（Energy Matching），该框架允许流动模型在远离数据流形时沿无旋最优传输路径从噪声向数据移动，并在接近数据流形时，通过熵能量项引导系统进入玻尔兹曼平衡分布，从而明确捕捉数据的潜在似然结构。这种方法使用单一的时间不变标量场参数化解这一动态过程，同时仍能在远离数据流形的情况下实现流动模型的无模拟训练。通过引入互动能量，该方法还支持了多样性的模态探索。

Conclusion: 
该方法在CIFAR-10和ImageNet生成任务上显著优于现有的EBMs，同时保留了流动模型的仿真无训练在外部区域的优势。此外，利用该方法的灵活性可以在分子生成中进行多样化的模式探索。这种方法表示学习了一个标量势能，没有时间条件化、辅助生成器或其他额外网络，为能量模型的发展开辟了新的途径。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.10612</guid><pubDate>Fri, 27 Jun 2025 02:46:04 +0800</pubDate></item><item><title>76. cs.LG-学习6G V2X中的联合通信与控制中的信息价值</title><link>https://arxiv.org/pdf/2505.06978</link><description>Background: 
随着C-V2X向6G网络演进，CAVs成为关键应用。数据驱动的机器学习，尤其是深度强化学习，有望显著增强CAVs在不确定性下的决策能力，特别是在车辆控制和V2X通信方面。决策过程紧密相关，信息的价值（VoI）是二者沟通的桥梁。当前研究虽然有所进展，但VoI模型仍碎片化，缺乏系统性框架。

Innovation: 
本文引入了Sequential Stochastic Decision Process（SSDP）来定义和评估VoI，同时提出了基于MDP、强化学习（RL）和最优控制的VoI建模框架，明确VoI的不同类别及其估计方法。并通过构建VoI相关的奖励函数，将SSDP模型应用于优化通信决策时间、内容和方式等问题。这种方法可用于泛在网络控制系统中同时优化随机性、顺序控制和通信决策。

Conclusion: 
通过构建SSDP模型，本文为VoI建模提供了一种系统的方法，并通过VoI奖励函数优化了通信问题的决策过程，包括确定何时、什么内容和如何通信。这种框架展示了SSDP模型在各类网络控制系统中的广泛适用性，特别是在交通系统中的应用潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.06978</guid><pubDate>Fri, 27 Jun 2025 02:46:03 +0800</pubDate></item><item><title>77. cs.LG-通过李群转换实现广义张量基参数高效微调</title><link>https://arxiv.org/pdf/2504.00851</link><description>Background: 
在人工智能领域，将预训练的基础模型适应多样化的下游任务是一项核心实践。但由于任务种类繁多以及高昂的计算成本，全面微调不切实际。为此，参数高效微调（PEFT）方法，如LoRA，已经出现并逐渐成为研究焦点。尽管这些方法取得了成功，但仍主要针对线性层设计，侧重于二维矩阵而忽视了卷积核等高维参数空间。直接应用这些方法到高维参数空间中常破坏结构关系。因此，尽管矩阵基PEFT方法有了快速进展，我们提出了一种推广策略，将矩阵基PEFT方法扩展到高维参数空间而不损害其结构特性。具体而言，将参数视为李群元素，更新作为相应李代数中的偏移。这些偏移通过指数映射返回李群，确保平滑、一致的更新并保留参数空间的固有结构。

Innovation: 
我们提出了一种广义张量基PEFT方法，通过李群转换实现参数高效微调。将参数视为李群元素，利用李代数进行模型更新，通过指数映射将更新映射回李群，确保更新的平滑性和结构一致性。这种方法不仅适用于高维参数空间，还能保持结构关系，使得在计算机视觉和自然语言处理中取得了显著的效果改进。

Conclusion: 
通过广泛的实验验证，我们的方法在计算机视觉和自然语言处理任务中表现出色且具有泛化能力，相比现有方法展示了明显的改进。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.00851</guid><pubDate>Fri, 27 Jun 2025 02:46:02 +0800</pubDate></item><item><title>78. cs.LG-利用嵌入的普遍几何结构</title><link>https://arxiv.org/pdf/2505.12540</link><description>Background: 
当前的研究方法通常要求利用成对的数据、编码器或预定义的匹配集合，来进行文本嵌入的转换。然而，这篇论文提出了一种无需任何这类数据或假设的方法，通过无监督的学习方式将嵌入从一个向量空间转换到另一个向量空间。这种方法适用于不同架构、参数数量和训练数据集的各种模型，保持原有的几何结构。这种转换对向量数据库的安全性具有重要意义，因为仅通过访问嵌入向量，攻击者就能提取敏感信息，足以进行分类和属性推断。

Innovation: 
该研究提出了一种无监督的方法，可以在没有任何成对数据、编码器或预定义匹配集的情况下，将任何嵌入从一个向量空间转换到另一个向量空间，且转换前后保持原有的几何结构。这种方法基于一个假想的普罗泰戈拉代表假设（Platonic Representation Hypothesis），将嵌入转换为一个通用的潜在表示，实现了不同模型之间的高余弦相似度。

Conclusion: 
这种能力对未知嵌入向量在不同空间间的转换具有重要影响，能够有效保护向量数据库的安全。即使攻击者只能访问嵌入向量，也能从这些向量中提取足够的敏感信息，用于分类和属性推断，这对数据库安全带来了严重威胁。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12540</guid><pubDate>Fri, 27 Jun 2025 02:46:00 +0800</pubDate></item><item><title>79. cs.LG-在线鲁棒决策的后悔界</title><link>https://arxiv.org/pdf/2504.06820</link><description>Background: 
该论文研究了一种框架，该框架扩展了基于结构化观测的决策概念，允许更为稳健的（即多值的）模型。框架中，每个模型将每个决策与一组概率分布的凸集关联起来。环境可以以任意（对抗性）方式选择这些分布，即使这些选择非透明且依赖于过往历史。这一框架比经典的多臂老虎机和强化学习提供了更大的通用性，因为现实中的实现假设变得更为弱化和实际。

Innovation: 
论文提出了一个理论来界定这种鲁棒在线决策框架下的后悔界。尽管下界和上界不够精确，但他们足以完全阐述幂律可学习性。此外，论文在两种特殊情况下证实了这一理论：鲁棒线性多臂老虎机和基于表格的鲁棒在线强化学习。在两种情况下，都推导出了优于现有最先进的后悔界（除了不涉及计算效率部分）的结果。

Conclusion: 
研究显示了这种框架能够提供更为弱化的可实现性假设，适用于非透明对抗性环境，并且在两种特殊情况下证明了理论的有效性。尽管上界和下界不是最紧的，但仍能充分刻画幂律可学习性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.06820</guid><pubDate>Fri, 27 Jun 2025 02:45:58 +0800</pubDate></item><item><title>80. cs.LG-使用变分防御封堵后门</title><link>https://arxiv.org/pdf/2503.08829</link><description>Background: 
当前的研究集中在如何抵御后门攻击，即如何训练出能够抵抗内置恶意软件的分类器。论文提出了一种名为VIBE的框架，目的是使分类器对于后门攻击具有抗性。在这一框架下，恶意输入和被污染的标签被视为观察到的随机变量，而干净的真实标签被视为潜在变量。文中通过变分推断恢复对应的潜在干净标签后验概率，这种训练过程遵循期望最大化（EM）算法。具体来说，E步通过求解熵正则化的最优传输问题来推断干净伪标签，M步则通过梯度下降更新分类器参数。

Innovation: 
提出了一种名为VIBE的模型泛化的后门攻击防御框架。核心创新在于将恶意输入和被污染的标签视为观察到的随机变量，实际的清洁标签视为潜在变量。VIBE通过变分推断恢复对应的潜在清洁标签后验概率，结合期望最大化（EM）算法进行迭代优化。这种方法可以无缝集成最近的自监督表示学习进展，以增强其抵御后门攻击的能力。实验结果表明，该方法在标准数据集、大规模不同类别的设置以及被多起攻击污染的数据集上表现出了优越性，能够有效抵御当代后门攻击方法。

Conclusion: 
实验结果表明，VIBE在所有测试情景中都优于之前的防御方法。它可以无缝地与最近的自监督表示学习发展相结合，以提高其抵御后门攻击的能力。该项工作提出了一个新的框架，为抵御后门攻击提供了一种有效的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.08829</guid><pubDate>Fri, 27 Jun 2025 02:45:55 +0800</pubDate></item><item><title>81. cs.LG-容量约束下的延迟在线学习：调度框架与悔恨权衡</title><link>https://arxiv.org/pdf/2503.19856</link><description>Background: 
该研究探讨了在线学习场景中的延迟损失和反馈延迟问题，并引入了一个新颖的“容量约束”，限制同时追踪的过去轮次数量。当延迟是透明的（即延迟持续时间每轮均提前透露）和/或可以撤销之前选择的轮次反馈时，作者建立了与经典的延迟在线学习同样高的上限和下限性能边界，这些经典方法假设无限的容量。研究还分析了容量不足和完全透明延迟条件下的性能变化。对于具体延迟和固定延迟，研究确定了使性能达到最优的容量需求。

Innovation: 
研究在容量有限的情况下，建立了与无限容量假设的经典方法相匹配的性能边界，提出了基于帕累托分布代理延迟和批量技术的新型预处理和非预处理调度策略，从而统一了延迟多臂老虎机、标签高效学习和在线调度框架。

Conclusion: 
研究指出，即使在有限的容量下，通过合适的策略设计，依然可以实现与无限容量假设下的相同最优性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.19856</guid><pubDate>Fri, 27 Jun 2025 02:45:51 +0800</pubDate></item><item><title>82. cs.LG-波let扩散神经操作者</title><link>https://arxiv.org/pdf/2412.04833</link><description>Background: 
模拟和控制由偏微分方程(PDEs)描述的物理系统是科学与工程中重要的任务。扩散生成模型因其能够捕捉长期依赖关系和高维状态建模的能力，近年来成为用于这些任务的具有竞争力的方法。然而，扩散模型通常难以处理系统状态的突变变化，并且在更高分辨率下进行推广。

Innovation: 
波let扩散神经操作者（WDNO）提出了一种新颖的PDE模拟和控制框架，增强了处理这些复杂任务的能力。WDNO引入了两个关键创新点：首先，WDNO在小波域中进行基于扩散的生成建模，以有效处理突变变化和长期依赖关系；其次，为了应对不同分辨率下泛化能力较差的问题，提出了多分辨率训练方法，这是物理系统建模中的基本任务之一。

Conclusion: 
我们在五个物理系统上验证了WDNO，包括1D对流方程，以及涉及突变变化的三个挑战性物理系统（1D伯努利方程，1D可压缩牛顿-斯托克斯方程和2D不可压缩流体），还包括一个真实世界的ERA5数据集。WDNO在模拟和控制任务上都表现出超过现有最佳方法的优越性能，且在长时间和细节预测准确性上有所提升。在旨在减少烟雾泄漏的2D高维间接控制任务中，WDNO将泄漏减少了78%。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.04833</guid><pubDate>Fri, 27 Jun 2025 02:45:50 +0800</pubDate></item><item><title>83. cs.LG-遗传算法在繁殖过程中引入创新的染色体模式</title><link>https://arxiv.org/pdf/2501.18184</link><description>Background: 
该论文提出了一种新的遗传算法变体——边界交易遗传算法（GAB），旨在通过在繁殖过程中引入新的染色体模式来增强探索能力。这有助于缓解过早收敛问题，提高搜索多样性。实验结果显示，GAB 在复杂的工作调度问题上的表现优于标准遗传算法，平均适应度高达 888，而标准遗传算法仅大约 106，同时达到这一适应度所需的时间更短，仅需 20 秒。在经典的翻转-翻转问题中，即使输入规模达到数千位，GAB 也能够在较少的代数中找到最优或近似最优解。这些结果表明，GAB 是一种高效解决大规模组合优化问题的有力工具.

Innovation: 
GAB 通过引入新的染色体模式来增强遗传算法（GA）的探索能力，显著减缓了过早收敛现象，并提高了搜索多样性。相较于标准遗传算法，GAB 在复杂工作调度问题上的适应度提高了 8 倍，在经典翻转-翻转问题中，GAB 能够在较少的代数内找到最优或近似最优解，尤其是在输入规模较大的情况下表现更佳.

Conclusion: 
GAB 是一种高效且计算上可行的替代方案，用于解决大规模组合优化问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.18184</guid><pubDate>Fri, 27 Jun 2025 02:45:49 +0800</pubDate></item><item><title>84. cs.LG-稀疏变分高斯过程的新边界</title><link>https://arxiv.org/pdf/2502.08730</link><description>Background: 
稀疏变分高斯过程（GPs）构建了GPs模型的可计算后验近似。这些方法的核心假设是真实训练函数值 ${bf f}$ 和诱导变量 ${bf u}$ 的后验分布可以被包含条件GPs先验 $p({bf f} | {bf u})$ 的变分分布近似。尽管这一假设很重要，但通过对更多一般性的变分分布 $q({bf f} | {bf u})$ 的使用，研究者证明在模型训练中可以放松这一假设，而引入的额外参数数量 $N$ 与训练样本数量相同。在GPs回归中，这使得可以通过参数的解析优化来表达一个比以前更紧的可计算边界，并且该新边界也适用于随机优化，且只需对现有的稀疏GP代码进行较小的修改即可实现。此外，研究者还描述了非高斯似然的扩展。在多个数据集上展示了此方法能减少学习超参数的偏差，并提高预测性能。

Innovation: 
通过引入更多一般性的变分分布 $q({bf f} | {bf u})$，在GPs回归中可以通过解析优化这些额外参数从而表达一个紧的可计算边界，这在以前的边界基础上更优。新边界也支持随机优化方法。另外，这种方法应用于非高斯似然问题上具有更好的性能。所有这些改进都不需要大量的代码修改，只需对现有的稀疏GPs代码做小的修改即可实现。通过这些改进，该方法在学习超参数上能更好地减少偏差，从而改善预测性能。

Conclusion: 
该方法通过引入更通用的变分分布及对优化边界的改进，减少了学习超参数的偏差，并提高了预测性能。试验结果证实了该方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.08730</guid><pubDate>Fri, 27 Jun 2025 02:45:45 +0800</pubDate></item><item><title>85. cs.LG-Mixture of Experts-augmented Deep Unfolding for Activity Detection in IRS-aided Systems</title><link>https://arxiv.org/pdf/2502.20183</link><description>Background: 
在大规模机器型通信(MM-TC)的活动检测领域，智能反射表面(IRS)已被证明能够显著提升缺乏直接基站(BS)连接的设备的覆盖范围。然而，传统的活动检测方法主要针对单一类型的信道模型进行设计，无法反映出实际场景，尤其是包含IRS的系统中的信道复杂性。为了解决这个问题，本研究提出了一种新的方法，该方法结合了模型驱动的深度解折和混合专家框架，能够自动选择并应用于展开的投影梯度方法中的专家设计之一，从而消除对设备与基站间信道类型先验知识的需求。

Innovation: 
所提出的方法通过结合模型驱动的深度解折与混合专家框架（MoE），自动选择适配的专家设计应用于展开的投影梯度方法。这种方法能够在混合信道衰落条件下，避免对设备与基站间信道类型先验知识的需求，从而实现了更优的检测性能。

Conclusion: 
模拟结果表明，所提出的MoE增强的深度解折方法在混合信道衰落条件下，相较于传统协方差基方法和黑盒神经网络设计，能够提供更好的检测性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.20183</guid><pubDate>Fri, 27 Jun 2025 02:45:44 +0800</pubDate></item><item><title>86. cs.LG-自监督对比学习中实时发现全局假负样本的方法</title><link>https://arxiv.org/pdf/2502.20612</link><description>Background: 
在自监督对比学习中，负样本对通常通过锚图像和从整个数据集中抽取的样本形成，但不包括锚图像本身。然而，这种方法可能导致形成具有相似语义的假负样本，使它们的嵌入被错误地推向远离。为了应对这一问题，我们介绍了GloFND，一种基于优化的方法，可以在训练过程中自动学习为每项锚数据设定阈值，以识别其假负样本。与之前的假负样本发现方法不同，我们的方法在整体上检测假负样本，而不是在小批量中局部检测，且每次迭代的计算成本与数据集大小无关。在图像和图像-文本数据上的实验结果验证了所提方法的有效性。我们的实现可访问于此URL：this https URL

Innovation: 
通过自动学习为每项锚数据设置阈值，实时发现全局假负样本，这种方法在整体上检测假负样本，而之前的局部方法则无法做到，同时保持每次迭代的计算成本与数据集大小无关。并且我们的方法通过实验证明了其有效性

Conclusion: 
实验结果表明所提出的GloFND方法在自监督对比学习中有效发现全局假负样本。并且，我们的实现已经公开可用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.20612</guid><pubDate>Fri, 27 Jun 2025 02:45:43 +0800</pubDate></item><item><title>87. cs.LG-一模型普适各实体概率预测且在实体分布中将它们统一</title><link>https://arxiv.org/pdf/2501.15499</link><description>Background: 
电力系统中的概率预测通常涉及多实体数据集，如家庭、馈线和风力发电机等。因此，生成每个实体特有的可靠预测是一个巨大的挑战。传统的方法是为每个实体训练单独的模型，导致效率低下且难以扩展。因此，一种使用单一模型进行实体特定概率预测的方法是必要的和迫切的。

Innovation: 
该研究使用了GUIDE-VAE（条件变分自编码器），它是一种能够利用单一模型实现实体特定概率预测的先进技术。GUIDE-VAE提供的输出具有灵活性，可以从可解释的点估计到完整的概率分布。这些分布能够捕捉不确定性及时间依赖关系，提供比传统方法更丰富的洞察。使用家庭用电数据作为案例研究，结果表明GUIDE-VAE在关键指标上优于传统的分位数回归技术，并且具有可扩展性和灵活性。这些特性使GUIDE-VAE成为一种强大的、可扩展的概率预测工具，具有广泛的应用潜力，远超家庭用电消费数据之外。

Conclusion: 
GUIDE-VAE作为先进的单一模型方法，能够在满足一系列复杂系统数据需求的同时，提供高效率和灵活性，这项工作为开发更优的分布式能源逆向预测方法奠定了坚实基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.15499</guid><pubDate>Fri, 27 Jun 2025 02:45:43 +0800</pubDate></item><item><title>88. cs.LG-通过掩码自编码器学习实验室值的表示</title><link>https://arxiv.org/pdf/2501.02648</link><description>Background: 
在电子健康记录（EHR）中准确填补缺失的实验室值对于促进稳健的临床预测和减少AI系统中的偏差至关重要。现有的方法，如XGBoost、softimpute、GAIN、期望最大化（EM）和MICE，难以建模EHR数据中的复杂时间性和上下文依赖性，尤其是在未被充分代表的群体中。

Innovation: 
本文提出Lab-MAE，这是一种新颖的基于.transformer的掩码自编码器框架，利用自监督学习来填补连续的序列实验室值。Lab-MAE引入了一种结构化的编码方案，联合建模实验室测试值及其对应的时间戳，能够明确捕捉时间依赖性。实验评估表明，Lab-MAE在多个指标（包括均方根误差 RMSE、决定系数 R2 和 Wasserstein 距离 WD）上显著优于现有最先进的基线，如XGBoost、softimpute、GAIN、EM 和 MICE。Lab-MAE 在不同患者群体中的表现具有公平性，推进了临床预测中的公平性。我们进一步调查了后续实验室值作为潜在捷径特征的作用，揭示了在没有此类数据的情况下Lab-MAE的健壮性。研究发现，我们的基于transformer的架构适应EHR数据的特征，为更准确和公平的临床填补提供了基础模型。此外，我们测量并比较了Lab-MAE与XGBoost模型的碳足迹，突显了其环境需求。

Conclusion: 
本文提出的Lab-MAE框架在填补EHR中的连续序列实验室值方面表现出优越的效果，并且在不同群体中表现出公平性。这一框架不仅提供了一种更准确和公平的临床填补方法，还通过自监督学习提高了填补的效率。此外，通过测量碳足迹，突显了这一方法的环境效益。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.02648</guid><pubDate>Fri, 27 Jun 2025 02:45:41 +0800</pubDate></item><item><title>89. cs.LG-通过凸优化实现逆强化学习</title><link>https://arxiv.org/pdf/2501.15957</link><description>Background: 
我们考虑逆强化学习问题，其中基于观察到的专家演示，估计某个马尔可夫决策过程的未知奖励函数。现有的大多数方法将逆强化学习（IRL）表征和解决为非凸优化问题，这对于需要鲁棒性和可重复性的场景带来了挑战。Ng和Russell最初提出了一种逆强化学习的凸形式化问题 (CIRL)，但该问题的直接应用受到限制，本论文通过引入直接适用于凸优化问题的领域特定语言 CVXPY 来改进这个问题，并将其扩展到专家策略不是通过解析公式给出，而是作为状态-动作对轨迹给出的场景，这些轨迹可能与最优性有强烈的偏差，通过增加一些约束来解决这个问题。

Innovation: 
1. 通过引入CVXPY来直接指定和解决凸优化问题的领域特定语言。n2. 将CIRL问题扩展到专家策略以轨迹形式给出的场景，并通过增加约束来处理可能与最优性不一致的情况。n3. 提供理论分析和超参数自动化选择的实用实现方法，使用户能够轻松应用CIRL，无需了解凸优化背景知识。

Conclusion: 
该论文通过改进CIRL问题的凸形式化并通过CVXPY简化了其应用过程，并提供了理论支持和实用实现出自动超参数选择的方法，使得逆强化学习的研究和应用更加简便和高效。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.15957</guid><pubDate>Fri, 27 Jun 2025 02:45:40 +0800</pubDate></item><item><title>90. cs.LG-在数据中学习对称性的深度网络能力：一种神经内核理论</title><link>https://arxiv.org/pdf/2412.11521</link><description>Background: 
许多数据集中都存在对称性（通过群动作进行的转换），而利用这些对称性有望显著提高机器学习中的预测性能。已有研究表明，传统的深度网络在标准架构和标准监督训练方式下，可以通过数据学习对称性。本文致力于理解在哪些条件下以及如何通过标准架构和标准监督训练方式从数据中学习对称性。研究在一个分类范式中展开，该范式中仅在部分训练过程中观察到数据的对称性：一些类别包括循环群的所有变换，而另一些类别仅包括子集。

Innovation: 
提出了神经内核理论来解释对称性学习的问题。在无限宽度极限下，通过傅里叶域中的神经核Grassman矩阵分析，推导出对称性学习的泛化误差与类间信号和类轨道密度（噪声）之间的关系。该理论还扩展到了任何有限群，包括非交换群，并适用于仿射架构（如CNNs）。该框架揭示了为什么传统的深度网络通常无法在没有在架构中预先嵌入的情况下学习未明确嵌入的对称性，并预测了部分观察到的旋转MNIST数据集上多种网络的泛化失败。这表明现有框架可用于指导设计能够从数据中学习对称性的架构和训练过程的发展。

Conclusion: 
本文通过提出神经内核理论来探讨深度网络从数据中学习对称性的能力。该框架揭示了在架构定义的核空间中，局部数据结构优于非局部对称性诱导结构的情况下的泛化成功。该理论在有限宽度网络（如MLP、CNN和ViT）训练于部分观察到的旋转MNIST数据集上得到了验证。结论指出，传统的深度网络缺乏学习未预先嵌入在架构中的对称性的机制，而该框架可供指导新型架构和训练程序的发展，以从数据中学习对称性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.11521</guid><pubDate>Fri, 27 Jun 2025 02:45:39 +0800</pubDate></item><item><title>91. cs.LG-拉格朗日索引策略用于平均回报的不安宁贝叶斯对策</title><link>https://arxiv.org/pdf/2412.12641</link><description>Background: 
本文探讨了在长期平均回报场景下的拉格朗日索引策略（LIP）及其与宽 nik 权索引策略（WIP）的性能对比。WIP 是一种在特定自然条件下渐近最优的启发式策略。尽管大多数情况下，两种策略的性能非常相似，但在 WIP 表现不佳的情况下，LIP 依然能表现出出色的性能。随后，本文提出了基于增强学习的算法，分别针对表结构和基于神经网络的方法，以实现 LIP 的在线学习方案，并且这些算法在模型自由环境中需要较少的内存。此外，还提出了对重启模型拉格朗日指数的解析计算方法，并讨论了均质臂在数量趋向无穷时的渐近最优性证明，该证明基于可交换性和德·费尼蒂定理。

Innovation: 
本文的主要创新点是提出了一种新的拉格朗日索引策略，并通过增强学习算法获得了在线学习方案，此方案在模型自由环境中所需的内存显著降低。此外，还对重启模型的拉格朗日指数进行了解析计算，并提供了均质臂渐近最优性的新证明方法。

Conclusion: 
本文提出了新的拉格朗日索引策略及其增强学习方法，特别在均质臂数量趋向无穷时证明了其渐近最优性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.12641</guid><pubDate>Fri, 27 Jun 2025 02:45:33 +0800</pubDate></item><item><title>92. cs.LG-以分数为基础的生成模型的适度泛化</title><link>https://arxiv.org/pdf/2412.07229</link><description>Background: 
得分生成模型（SGMs）展示了显著的泛化能力，例如生成未见但自然的数据。然而，泛化能力越强，意外泛化和滥用的风险也越大。在这方面，目前对得分生成模型适度泛化的研究仍然有限。现有的去学习方法（Machine Unlearning, MU）主要包括重新训练模型去除不希望的数据。虽然这种方法在传统模型中表现良好，但在SGMs中却无效。进一步研究发现，现有方法未改变原始得分函数，这也是其无效的原因之一。

Innovation: 
本文首次提出了适度得分生成模型（MSGM），并提出了一种新颖的得分调整策略，该策略能够在连续时间的随机微分方程过程中引导得分函数远离不希望的数据。实验结果表明，MSGM显著减少了产生不希望内容的几率，同时保持了高质量的正常图像生成。这种设计不仅针对SGMs，MSGM还提供了一种通用且灵活的去学习框架，兼容多种扩散架构（SGM和DDPM）和训练策略（重新训练和微调），并且能实现预训练模型向下游任务（如图像修复和重建）的零样本迁移。

Conclusion: 
本文通过提出MSGM和新的得分调整策略，有效解决了SGMs中的适度泛化问题，能够在保持高视觉质量的同时减少不理想内容的生成，展示了其在各种扩散架构和训练策略中的广泛适用性，并致力于解决跨任务的预训练模型迁移问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.07229</guid><pubDate>Fri, 27 Jun 2025 02:45:28 +0800</pubDate></item><item><title>93. cs.LG-Gaussian 测度下学习利普希茨算子的样本复杂性</title><link>https://arxiv.org/pdf/2410.23440</link><description>Background: 
近年来，无限维函数空间之间的映射（操作符）学习因其使用机器学习替代传统的计算科学和工程方法而逐渐受到研究关注。尽管这些方法在实践中取得了成功，但关于其背后的数学理论理解仍然不完整。本文研究了在高斯测度下学习利普希茨算子的样本复杂性，包括证明了利普希茨算子的高斯Sobolev正则性、建立了Hermite多项式逼近误差的上界和下界，并研究了从任意m个线性样本（可能适应性样本）重构利普希茨算子的一般策略。研究表明，仅基于m个线性样本，不存在能实现代数收敛速率的逼近方案，但当协方差算子的特征值快速衰减时，可以实现任意接近代数收敛速率的收敛性。该项研究确认了在所有数据和学习技术下学习利普希茨算子的固有的困难性。

Innovation: 
本文在高斯测度下研究了学习利普希茨算子的样本复杂性，证明了利普希茨算子的高斯Sobolev正则性，建立了Hermite多项式逼近误差的上下界，研究了从任意m个线性样本重构利普希茨算子的一般策略，并确定了样本复杂性下的理论限界，证明了在快速特征值衰减条件下能够实现接近任意代数速率的收敛性。

Conclusion: 
本文通过紧密刻画样本复杂性来确认学习利普希茨算子的固有困难性，表明仅基于m个线性样本，不存在能实现代数收敛速率的逼近方法。当协方差算子的特征值快速衰减时，可以实现任意接近代数收敛速率的收敛性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.23440</guid><pubDate>Fri, 27 Jun 2025 02:45:27 +0800</pubDate></item><item><title>94. cs.LG-使用软注意模拟硬注意</title><link>https://arxiv.org/pdf/2412.09925</link><description>Background: 
本文探讨了使用软注意的变压器能否模拟硬注意的问题，即能否有效集中注意力于位置子集。作者首先研究了几类可以由硬注意变压器识别的语言，这些语言可以在线性时序逻辑的不同变体中定义。然后展示了软注意变压器如何使用无界位置嵌入或温度缩放来计算这些逻辑的公式。此外，作者还说明了温度缩放如何使软注意软接近于模拟一般硬注意的行为，通过使用依赖于最大注意力得分与其他得分之间最小差距的温度值。

Innovation: 
文章展示了软注意变压器如何通过使用无界位置嵌入或温度缩放来模拟由硬注意变压器识别的语言，以及如何使用温度缩放来模拟硬注意的行为，使得软注意软可以更加接近硬注意的效果。

Conclusion: 
本文的研究结果表明，通过适当的参数调整，软注意可以有效地模拟硬注意的行为，在某些情况下甚至可以实现完全等效的效果。这对于理解和优化注意机制的设计具有重要意义。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.09925</guid><pubDate>Fri, 27 Jun 2025 02:45:27 +0800</pubDate></item><item><title>95. cs.LG-GASP: 高效的黑盒生成对抗后缀以劫持LLM</title><link>https://arxiv.org/pdf/2411.14133</link><description>Background: 
大型语言模型(LLMs)在多种自然语言处理任务中展现了出色的性能，但仍面临输入提示的漏洞，这被称为出口脱狱攻击，通过精心设计的提问可以绕过安全限制并产生有害的回应。传统的方法依赖于手动的启发式方法，但这些方法在通用性方面存在局限性。尽管基于优化的方法能够自动化这种攻击，但它们经常生成不自然的提示，容易被安全过滤器检测到，或者需要高昂的计算成本，这是因为需要进行离散的标记优化。

Innovation: 
本文引入了 Generative Adversarial Suffix Prompter (GASP)，这是一种新颖的自动化框架，能够在完全封闭的黑盒环境中高效生成人类可读的出口脱狱后缀。GASP 利用潜在的贝叶斯优化来构造对抗后缀，通过有效探索连续的潜在嵌入空间指导论述的优化，通过一个目标迭代优化流程来平衡提示的一致性，逐步提高攻击效果。

Conclusion: 
通过一系列全面的实验，研究表明GASP能够生成自然的对抗后缀，显著提高了出口脱狱的成功率，并比基线减少训练时间，加快推理速度，因此是一个高效且可扩展的解决方案，用于红队演练LLM。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.14133</guid><pubDate>Fri, 27 Jun 2025 02:45:26 +0800</pubDate></item><item><title>96. cs.LG-通过ReLU多层感知器的最大正则性实现逼近与学习的桥梁</title><link>https://arxiv.org/pdf/2409.12335</link><description>Background: 
深度学习的基础理论支持其从逼近理论或学习理论的角度出发。逼近理论强调使用具有大量参数且不一定有泛化能力的强大模型；而学习理论则关注那些能够泛化的模型，但可能在表达能力上受到限制。基于在真实世界中深度学习的实现既强大又统计稳健的现象，论文提出了一个假设，即是否存在一种既足够广泛以实现通用性，又足够结构化以支持泛化的神经网络类。本研究通过识别一种高度结构化的ReLU多层感知器（MLP）类来回答这一问题，这些网络既可以作为最优的函数逼近器，又能表现出良好的统计行为。

Innovation: 
论文通过提出一种新的构造方法，使用Kuhn三角化完美拼接线性片段，同时提出了新的证明技术，证明这种构造不仅保留了Hölder函数的正则性，还保留了任何一致连续函数的正则性。此外，这种MLP类在给出随机归一化的亚高斯训练样例时达到了接近最优的样本复杂度。最终结果表明，神经网络能够解决麦克肖恩延拓问题在合适的有限集上。

Conclusion: 
论文提出了一个高度结构化的ReLU多层感知器类，实现了一种既足够广泛能够实现通用性，又能有效泛化的神经网络。该类具有接近最优的样本复杂度，实现了逼近理论和学习理论之间的桥梁，证明了神经网络在适合的有限集上能够解决麦克肖恩延拓问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.12335</guid><pubDate>Fri, 27 Jun 2025 02:45:23 +0800</pubDate></item><item><title>97. cs.LG-解码器仅存器的下一个标记预测能力：通用上界和一层多头解码器的下界</title><link>https://arxiv.org/pdf/2405.13718</link><description>Background: 
给定一系列标记，例如单词，下一个标记预测任务是预测下一个标记的条件概率分布。完全自解码器变换器已成为这类任务的有效模型，但它们的特性尚未完全理解。特别是，尚未确定完全自解码器变换器能够插值下一个标记分布的最大不同上下文序列数量。因此，本文旨在填补这一空白，探讨此类上下文序列的数量，并证明上下界的通用设定和经验设定下的数学结论。

Innovation: 
提出了一般的上界和经验设定下的下界，并特别针对一层多头解码器自注意力机制证明了一个重要的单射性质。此外，通过数值证据表明，为了训练模型达到熵下界，所必需的最小参数数量是足够的，从而区分了完成任务所需的最小模型复杂性。

Conclusion: 
通过数学证明，确定了解码器仅存器自注意力机制的插值能力的上下界，该研究不仅增强了对解码器仅存器模型的理解，还为设计更高效、更有效的自然语言处理模型提供了理论基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.13718</guid><pubDate>Fri, 27 Jun 2025 02:45:22 +0800</pubDate></item><item><title>98. cs.LG-通过评分校准减少记录匹配中的偏差</title><link>https://arxiv.org/pdf/2411.01685</link><description>Background: 
记录匹配是识别在不同数据集中指相同现实世界实体的记录的任务。尽管大部分现有模型关注准确性，公平性已成为重要关注点，因为不同人口组之间可能存在不平等结果的风险。以往研究通常关注在固定决策阈值下的二元结果评估，但这样的评估可能无法检测到持续存在于不同阈值下的评分偏差，这些偏差影响了下游任务。本文提出了一种独立于阈值的框架来衡量和减少评分偏差，定义为不同群体间匹配评分分布的差异。研究表明，即使在标准阈值基线评估下看似公平的方法也存在显著的评分偏差。为解决这一问题，引入了两种后处理评分校准算法：一是calib，使用沃斯toBean 震心调整群体评分分布，目标为实现人口统计公平；二是ccalib，在预测标签的基础上进一步减少标签依赖偏差，如等效机会。两种方法都在不影响模型原有的准确性下减少偏差，并且具有无模型数据访问需求和理论保证等优势。

Innovation: 
提出了一种独立于阈值的框架来衡量和减少评分偏差，定义为不同群体间匹配评分分布的差异。该框架通过calib和ccalib两种算法校准评分，解决了以往方法未能检测到持续存在于不同阈值下的评分偏差问题，两种算法具有无模型数据访问需求和理论保证等优点，有效减少了偏见同时保持了模型准确性。

Conclusion: 
实验结果证实了calib和ccalib在减少评分偏差方面取得了显著成效，同时最小限度地影响了模型的准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.01685</guid><pubDate>Fri, 27 Jun 2025 02:45:22 +0800</pubDate></item><item><title>99. cs.LG-在线鞍点问题的近端点方法</title><link>https://arxiv.org/pdf/2407.04591</link><description>Background: 
本文关注在线鞍点问题，涉及具有时间变化的两个玩家凸-凹博弈序列。考虑到环境的非平稳性，作者采用对偶差距和动态纳什均衡后悔作为算法设计的性能度量标准。详细介绍了三种变种的近端点方法：在线近端点方法（OPPM）、乐观OPPM（OptOPPM）和带有多个预测器的OptOPPM。这些算法在度量标准上体现出近乎最优性，特别是在某些良性环境中，能够保持度量标准的近似恒定值。实验结果进一步验证了这些算法的有效性。最后，作者讨论了使用动态纳什均衡后悔作为性能度量标准的潜在可靠性问题。

Innovation: 
论文提出了三种近端点方法变体以解决在线鞍点问题：在线近端点方法（OPPM）、乐观OPPM（OptOPPM）和带有多个预测器的OptOPPM。每种算法保证了对偶差距和动态纳什均衡后悔的上界，并且在特定环境下，度量标准几乎保持恒定。

Conclusion: 
实验结果验证了这些算法的有效性。论文还讨论了使用动态纳什均衡后悔作为性能评估标准的潜在可靠性问题。相关技术附录和代码可以在指定网址找到。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.04591</guid><pubDate>Fri, 27 Jun 2025 02:45:18 +0800</pubDate></item><item><title>100. cs.LG-Chain-of-Sketch: 使全局视觉推理成为可能</title><link>https://arxiv.org/pdf/2410.08165</link><description>Background: 
现代视觉模型在本地特征对目标提供关键信息的基准测试中取得了显著的成功。然而，随着对需要更全局推理的任务的兴趣增长，本地特征不再提供重要信息的问题逐渐显现。1969年，Minsky和Papert通过他们的连接性研究，提出了此类任务并揭示了感知器模型的局限性。本文引入了一组涉及图形、字符串、迷宫和图像网格的全球化视觉数据集。结果显示，即使使用大规模视觉模型，这些任务仍然难以高效地学习。同样，最先进的多模态语言模型在这些数据集上的表现也较差。我们通过引入‘全球化度’测度来解释这种学习效率低下。因此，我们提出了一种名为‘链子划’（CoS）的方法来缓解这一问题。该方法类似于语言模型中使用的链子思考和记事板技术，将原始任务分解为中间视觉步骤，以帮助学习复杂的任务。同时，我们发现并非所有CoS策略都表现相同。我们的一个关键见解是，在CoS框架上引入马尔可夫结构，从而提出了‘归纳性CoS’，该方法不仅在离群分布泛化方面表现更好，而且即使使用较小的模型也能取得良好的效果，优于非归纳性的变体。

Innovation: 
引入了全球化视觉数据集、‘全球化度’测度以及‘链子划’（CoS）方法。‘链子划’分解了原始任务为中间视觉步骤，以协助学习复杂的任务。同时，提出了具有马尔可夫结构的归纳性CoS框架，改善了泛化性能。

Conclusion: 
研究展示了，尽管大型视觉模型和最先进的多模态语言模型在这类任务上仍表现不佳，但通过提出’链子划‘方法和采用马尔可夫结构，能够有效缓解这些问题，实现更好的离群分布泛化效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.08165</guid><pubDate>Fri, 27 Jun 2025 02:45:18 +0800</pubDate></item><item><title>101. cs.LG-快速陀螺仪校准：一种深度学习方法</title><link>https://arxiv.org/pdf/2409.00488</link><description>Background: 
低成本陀螺仪的校准对于确保测量精度和可靠性至关重要。静止校准可以估计测量误差的确定性部分。常见的做法是在预定义的时间段内平均陀螺仪读数，并估算陀螺仪偏置。校准时间长度对性能至关重要，因此倾向于使用更长的时间段。然而，一些应用需要快速启动时间，因此校准只允许在一个较短的时间内进行。本文的重点是通过深度学习方法减少低成本陀螺仪校准时间。我们提出了一种端到端的卷积神经网络用于陀螺仪校准的应用。我们探索使用多个实际和虚拟陀螺仪以提高单个陀螺仪校准性能的可能性。为了测试和验证我们的方法，我们记录了一个由36个来自四种不同品牌的陀螺仪在186.6小时内读取的数据集，并创建了一个虚拟数据集，其包含模拟的陀螺仪读取。这些六个数据集被用来评估我们提出的方法。我们的一个主要成就是使用三个低成本陀螺仪将陀螺仪校准时间减少了89%。我们的数据集对所有人都是公开的，以允许我们的工作可重复性，并增加该领域的研究。

Innovation: 
提出了一种端到端的卷积神经网络用于陀螺仪校准的应用。探索使用多个实际和虚拟陀螺仪以提高单个陀螺仪校准性能的可能性。创建了一个虚拟数据集，包含模拟的陀螺仪读取。通过这种方法将低成本陀螺仪校准时间减少了89%。数据集公开，以保证研究的可重复性并增加研究兴趣。

Conclusion: 
通过深度学习方法减少低成本陀螺仪校准时间的关键成就是使用三个低成本陀螺仪将校准时间减少了89%。数据集公开以促进研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.00488</guid><pubDate>Fri, 27 Jun 2025 02:45:14 +0800</pubDate></item><item><title>102. cs.LG-HyperINF: Unleashing the HyperPower of the Schulz's Method for Data Influence Estimation</title><link>https://arxiv.org/pdf/2410.05090</link><description>Background: 
影响函数提供了一种评估单个训练样本对特定目标贡献的公认方法。然而，它们的高计算成本限制了其在大规模模型和数据集上的应用。现有的近似影响函数方法虽然显著降低了计算开销，但仍然存在着不准确估计的问题，因为缺乏算法上的强收敛保证。超幂方法以其在矩阵逆近似中的严格收敛保证而闻名，但在大规模模型中矩阵乘法操作可能导致难以处理的内存和计算成本。因此，需要一个高效且准确的影响函数近似方法，以克服这些挑战。

Innovation: 
本文提出了一种名为HyperINF的影响函数近似方法，该方法利用了超幂方法，特别是舒尔兹迭代算法。为了处理矩阵乘法的计算密集度，引入了广义鱼信息（GFIM）作为海森矩阵的低秩逼近，从而减少了LoRA调整模型的存储和计算开销，使其与秩无关的成本恒定。该方法在矩阵逆模拟中有优越的准确性和稳定性，并在大规模实际数据属性任务中也表现出色，例如检测误标注数据和用于LLM和VLM微调的数据选择。而其他基准方法在这类任务中表现不佳，尤其是在LoRA调整模型中，HyperINF在实现出色下游性能的同时，内存和计算开销最小化。

Conclusion: 
HyperINF在LoRA调整模型上实现了显著的下游性能提升，同时最小化了内存和计算开销，而其他基准方法在这些任务中则表现不佳。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.05090</guid><pubDate>Fri, 27 Jun 2025 02:45:12 +0800</pubDate></item><item><title>103. cs.LG-全身条件驱动的主观视频预测</title><link>https://arxiv.org/pdf/2506.21552</link><description>Background: 
本文的背景是，研究人员训练模型根据人类动作来预测主观视角（ ego-centric 视频），给定过去的视频和通过相对3D人体姿势表示的动作。通过结合动力学姿态轨迹，结构化由身体关节层次等级限定，模型学习从第一个视角（first-person point of view）来模拟现实世界的物理人类动作如何塑造环境。为了实现这一目标，作者利用了名为Nymeria的大规模现实世界主观视频和人体姿态捕捉数据集。进一步地，设计了一个分层的评估协议，提出了逐步增加难度的任务，从而全面分析模型在身体预测和控制方面的表现能力。

Innovation: 
本文的创新在于，它首次尝试从人类视角下利用视频预测来建模复杂的真实世界环境和体现型代理的行为。特别地，通过条件扩散变换器（conditional diffusion transformer）进行自回归训练，基于Nymeria数据集进行建模。文章设计了一种分层评估协议，逐步增加难度的任务，能够全面分析模型的预测能力和控制能力。同时，这种方法提供了对复杂环境建模的新视角，可以更好地理解现实世界中任性的、交互性的人类行为。

Conclusion: 
本文代表了首次尝试利用主观视频预测解决复杂真实世界环境和体现型行为建模的问题。通过自回归条件扩散变换器训练模型，并采用Nymeria数据集和分层评估协议，展示了解决这些挑战的初步方法。这种方法不仅有助于理解现实世界的交互性，还可以推动在虚拟现实、增强现实和机器人技术等领域的发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21552</guid><pubDate>Fri, 27 Jun 2025 02:45:12 +0800</pubDate></item><item><title>104. cs.LG-GREAT 架构在类似于TSP的边基图问题中的应用</title><link>https://arxiv.org/pdf/2408.16717</link><description>Background: 
近年来，基于学习的方法已被提出以解决诸如路由问题等组合优化问题。许多此类方法基于图神经网络（GNNs）或相关的变压器，在表示路由问题的欧几里得坐标上操作。然而，这类模型在非欧几里得、非对称的问题实例上表现不佳，这些问题在现实世界中较为常见。为了克服这一局限性，本文提出了一种新的基于GNN且以边为中心的神经模型Graph Edge Attention Network (GREAT)。使用GREAT作为编码器来捕捉路由问题实例的特性，我们构建了一个强化学习框架，并将其应用于欧几里得和非欧几里得的车辆路由问题，如旅行商问题、有载荷限制的车辆路径问题及导向问题。这是首次采用学习方法解决非欧几里得问题，我们的框架在学习算法求解器中表现抢眼。

Innovation: 
本文提出了一种新型的GNN模型——Graph Edge Attention Network（GREAT），用以克服基于欧几里得坐标模型在处理非欧几里得、非对称问题实例上的不足。通过GREAT作为编码器，开发了一个强化学习框架，并应用于多种车辆路由问题任务中，尤其是非欧几里得版本的问题，这些问题是现实世界中常见的。

Conclusion: 
所提出的GREAT框架在学习算法求解器中取得了具有竞争力的结果，特别是在非欧几里得版本的旅行商问题、有载荷限制的车辆路径问题及导向问题上。这是首次使用学习方法解决非欧几里得问题，表明了该方法的有效性和前景。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.16717</guid><pubDate>Fri, 27 Jun 2025 02:45:09 +0800</pubDate></item><item><title>105. cs.LG-公平准确：面向在线讨论的公平意识多组目标检测</title><link>https://arxiv.org/pdf/2407.11933</link><description>Background: 
目标群体检测是一项任务，即识别社交媒体帖子是“针对或涉及到”哪些群体。这一任务具有多种应用，如定向营销。在毒性检测的背景下，帖子所感知的潜在危害往往取决于它针对的是哪个群体或多个群体。由于毒性高度依赖于背景语境，一些看似无害的语言在针对特定人口统计学群体时可能变得有害。因此，在判断是否具有毒性之前，首先需要检测帖子所针对的哪些群体，这对于后续毒性判断任务至关重要。此外，目标群体检测也极具挑战性，单个帖子可能同时针对一个或多个群体，在检测这些群体时要确保公平性，以促进公正待遇。

Innovation: 
本文提出了一种公平意识多目标群体检测方法，可以减少对不同群体的偏见，并且具有强预测性能，超过了现有的公平意识基准方法。此外，为了推动未来对公平意识目标群体检测的研究，并支持竞争性基准测试，本文还开放了相关代码。

Conclusion: 
本文展示了所提出的方法不仅减少了不同群体的偏见，而且实现了具有竞争力的预测性能，超过当前的公平性基准方法。本文的工作为未来的研究和公平意识目标群体检测提供了支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.11933</guid><pubDate>Fri, 27 Jun 2025 02:45:06 +0800</pubDate></item><item><title>106. cs.LG-在机器学习中平衡隐私、稳健性和效率</title><link>https://arxiv.org/pdf/2312.14712</link><description>Background: 
在当前的威胁模型下，实现机器学习系统的同时具备健壮性、隐私性和效率是不可行的。这些目标之间的紧张关系并非源于算法的缺陷，而是由于最坏情况下的对抗假设所施加的结构性限制。

Innovation: 
本文倡导系统化的研究议程，旨在对健壮性-隐私性-效率的三难困境进行形式化，探索如何通过原则性的威胁模型放松来解锁更好的权衡，并设计能够暴露而不是遮掩妥协的基准测试。文章还从追求理想的普遍保证转向关注基于上下文的系统设计，从而使机器学习社区能够构建真正适合实际部署的模型。

Conclusion: 
通过调整关注点，机器学习社区可以建立真正适合现实部署的模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2312.14712</guid><pubDate>Fri, 27 Jun 2025 02:45:06 +0800</pubDate></item><item><title>107. cs.LG-黑箱预测中的野性重拟合</title><link>https://arxiv.org/pdf/2506.21460</link><description>Background: 
本文描述并分析了一种计算基于最小二乘法最小化惩罚非参数估计的个例均方预测误差高概率上限的高效重拟合过程。该过程仅需一个数据集和对预测方法的黑箱访问，并分为三个步骤：计算合适的残差、使用预因子ρ对它们进行对称化和缩放，以及使用它们定义并解决一个重新中心化的修改预测问题。这种方法被称为野性重拟合，因为它使用了和野生靴strap变体中相同的拉德厄玛残差对称化方法。在允许噪音异质性的较温和条件下，作者建立了该过程性能的高概率保证，使用适当选择的野性噪声尺度ρ的野性重拟合提供了一个预测误差的上界。这种理论分析为设计此类过程提供了指导，包括如何形成残差、野性子问题所需的噪声尺度重新缩放量，以及黑箱过程的局部稳定性属性。该方法被应用于各种问题，包括具有结构矩阵惩罚的非刚性结构从运动恢复；具有深度神经网络先验的插拔式插件图像恢复；以及基于核方法的随机草图法。

Innovation: 
提出了一种新的计算基于最小二乘法最小化惩罚非参数估计的个例均方预测误差的高效重拟合过程。该过程不需要重复拟合多个数据集，而是通过一次数据集和对预测方法的黑箱访问，通过三个步骤实现：计算合适的残差、使用预因子ρ对它们进行对称化和缩放，以及使用它们定义并解决一个重新中心化的修改预测问题。这种方法称为野性重拟合，并且在理论分析上提供了如何形成残差、野性子问题所需的噪声尺度重新缩放量，以及黑箱过程的局部稳定性属性的指导。

Conclusion: 
本文提出的方法提供了提高预测准确性的新方法，并通过理论分析为设计此类过程提供了指导。该方法被应用于三个具体问题，展示了其广泛的应用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21460</guid><pubDate>Fri, 27 Jun 2025 02:45:00 +0800</pubDate></item><item><title>108. cs.LG-日常交通模式下的交通信号评估</title><link>https://arxiv.org/pdf/2506.21469</link><description>Background: 
交通转向运动数据对交通信号设计、交叉口几何规划、交通流量和拥堵分析至关重要。本文研究了基于转向运动计数数据（TMC）的三种交通信号配置方法：动态、静态和混合配置。通过开发基于视觉的跟踪系统，在拉斯维加斯6个交叉口使用交通摄像头估计转向运动计数。使用真实的交通数据和Urban Mobility Simulation（SUMO）进行信号配置文件的合成与导入，评估信号配置效果。根据初始实验结果表明，90秒和120秒的信号周期最适合所有交叉口。同时，实验证明动态、静态和混合信号配置方法在高峰和非高峰时段效果较好，表现出不同性能。由于每日交通流量表现出双峰模式，混合信号方法被提出，该方法能在高峰和非高峰时段之间切换，以优化交通流量管理。

Innovation: 
本文提出了三种基于转向运动计数数据的交通信号配置方法，包括动态、静态和混合配置。结合SUMO进行仿真实验，进一步研究了混合信号方法在适应双峰交通流量模式方面相较于静态方法的优势，特别是在跨区重量较高的交通交叉口上效果显著。此外，提出了基于区域交通流量模式的交通信号设计选择方法，这对于均匀分配和非均匀分配区域交通流量的交叉口具有不同的效果。

Conclusion: 
综合实验结果表明，在4小时的模拟时间内，区域交通流量模式分布影响了信号设计的选择。尽管静态方法适用于均匀分配区域的交通分布，但在高权重交通交叉口（如西-东和北-南区域），混合方法表现更优。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21469</guid><pubDate>Fri, 27 Jun 2025 02:44:57 +0800</pubDate></item><item><title>109. cs.LG-小型编码器能与大型解码器在检测接地性方面一较高下</title><link>https://arxiv.org/pdf/2506.21288</link><description>Background: 
在自然语言处理任务中，通过将外部上下文增强大型语言模型（LLMs）能够显著提升其表现。然而，当提供的上下文中缺乏相关信息时，LLMs经常会依赖于未验证的假设或内部知识来回答查询，这会导致答案的不准确。确保生成的响应严格基于所提供的上下文的“接地性”对于维持事实一致性与可信度至关重要。本文研究了如何在LLMs昂贵的回答生成之前，通过轻量化、针对特定任务的编码器模型（如RoBERTa和NomicBERT）检测查询是否基于提供的文档，实现大幅度降低推理时间和资源消耗的目的。

Innovation: 
研究发现，通过使用在精选数据集上微调的小型编码器模型（如RoBERTa和NomicBERT），可以在约数个数量级的时间内检测出查询是否基于提供的文档，同时其准确率接近最先进的大型语言模型（如Llama3 8B和GPT4o）。这表明，小型编码器能够在保持高准确率的同时，大幅缩短推理延迟时间。相关代码已开源。

Conclusion: 
轻量化、针对特定任务的编码器可以在地基性检测方面与大型的解码器型语言模型媲美，同时提供显著的效率提升。这种方法可以极大地减少LLMs在生成答案前的推理时间和资源消耗，从而提高整个系统的性能和响应速度。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21288</guid><pubDate>Fri, 27 Jun 2025 02:44:54 +0800</pubDate></item><item><title>110. cs.LG-Gaussian Invariant Markov Chain Monte Carlo</title><link>https://arxiv.org/pdf/2506.21511</link><description>Background: 
该研究开发了基于高斯不变性的采样方法，其中包括随机游走马尔可夫（RWM）、Metropolis 调整拉angevin算法（MALA）和二阶Hessian或流形MALA的高斯不变版本。该研究背景在于，传统的RWM和MALA方法在处理高纬度目标或复杂目标时可能会遇到效率限制。研究人员探索了高斯不变采样在统计效率上的改进潜力，并展示了如何利用高斯不变性来精确求解高斯目标的泊松方程，从而在任何难以处理的目标下构建高效的控制变量，以降低估计量的方差。该研究在一系列高纬度目标的潜藏高斯模型中实现了最先进的结果。

Innovation: 
该研究的主要创新在于开发了高斯不变性的采样方法，并展示了高斯不变性如何提高抽样效率。具体创新包括开发新的高斯采样方法；使用高斯不变性精确求解泊松方程，用于任何难以处理的目标下的效率改进估计；以及提供几何遍历性和最优倍频分析的理论结果，展示了最优接受率与目标高斯性的依赖关系。

Conclusion: 
该研究展示了新的高斯不变采样器和估计器在各种示例中的应用，包括高纬度目标的潜藏高斯模型，并与多种高级方法进行对比，取得了最先进的结果。此外，还提供了关于几何遍历性和最优倍频分析的理论结果，证明了最优接受率与目标高斯性的依赖关系。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21511</guid><pubDate>Fri, 27 Jun 2025 02:44:53 +0800</pubDate></item><item><title>111. cs.LG-持续学习作为一种受计算约束的强化学习</title><link>https://arxiv.org/pdf/2307.04345</link><description>Background: 
持续学习旨在设计能够随着时间积累知识并不断提升技能的智能代理，这是人工智能长期面临的挑战之一。为了应对这一挑战，该文通过将持续学习视为受限于计算能力的强化学习来澄清和形式化相关概念，引入了一个框架和工具集以促进进一步研究。

Innovation: 
将持续学习定义为受限于计算能力的强化学习，并提供了一个框架和工具集来推动这一领域的进一步研究。

Conclusion: 
通过清晰定义和形式化持续学习的概念，该研究旨在促进对该领域的深入理解和进一步探索，从而推动人工智能力量的边界。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2307.04345</guid><pubDate>Fri, 27 Jun 2025 02:44:53 +0800</pubDate></item><item><title>112. cs.LG-HalluSegBench：用于分割幻觉评估的反事实视觉推理</title><link>https://arxiv.org/pdf/2506.21546</link><description>Background: 
近期在视觉语言分割领域的进展显著提升了基于图像内容的理解能力。然而，现有的分割模型常常产生幻觉，即为图中不存在的对象生成分割遮罩或错误地标记无关区域。现有的评估协议主要集中在标签或文本幻觉上，并没有通过改变视觉上下文来评估幻觉，这限制了它们诊断关键性失败的能力。

Innovation: 
本文提出了HalluSegBench，这是第一个专门通过反事实视觉推理来评估视觉地基中幻觉的基准。该基准包含一个具有1340个反事实实例对的新颖数据集，覆盖281个独立的对象种类，并且引入了新的度量标准来量化在视觉一致性场景编辑下幻觉的敏感性。实验表明，模型受到的幻觉驱动的影响远大于标签驱动的影响，预测模型经常坚持错误的分割，这表明需要进行反事实推理以诊断地基的准确性。

Conclusion: 
HalluSegBench揭示了模型在幻觉检测方面存在显著差距，并强调了反事实推理对于评估视觉地基重要性。新数据集和度量标准提供了更全面的评估方法，帮助研究者更好地理解幻觉现象并改进模型性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21546</guid><pubDate>Fri, 27 Jun 2025 02:44:53 +0800</pubDate></item><item><title>113. cs.LG-3D MLLMs在CT报告生成中的设计空间探索</title><link>https://arxiv.org/pdf/2506.21535</link><description>Background: 
多模态大语言模型（MLLMs）已经成为自动化放射学报告生成（RRG）的一个有前景的方法。本文系统地研究了3D MLLMs的设计空间，包括视觉输入表示，投影器，大语言模型（LLMs），以及用于3D CT报告生成的微调技术。研究结果表明，RRG在相同的训练协议下，与模型大小无关。同时，我们证明了如果原始ViT在较小的体积上预训练，较大的体积大小并不总是提高性能。研究最后表明，使用分割掩码与CT体积一起提高性能。

Innovation: 
介绍了两种基于知识的报告增强方法，这些方法在GREEN得分上提高了10%以上，使我们在MICCAI 2024 AMOS-MM挑战中获得了第二名。此外，通过研究3D MLLMs的设计空间，指出了模型大小、投影器、可视化输入表示和分割掩码使用等关键设计因素对CT报告生成性能的影响。公开了相关代码。

Conclusion: 
在AMOS-MM数据集的1,687个案例上，研究结果表明，与语义大小无关的情况下，MLLMs适用3D CT报告生成。除了这些发现外，研究强调了投影器、分割掩码的使用等设计因素对性能的影响，并证明了通过专门设计可以实现更好的报告生成效果。相关代码已公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21535</guid><pubDate>Fri, 27 Jun 2025 02:44:53 +0800</pubDate></item><item><title>114. cs.LG-Maximal Matching Matters: 防止表示坍缩以实现稳健的跨模态检索</title><link>https://arxiv.org/pdf/2506.21538</link><description>Background: 
跨模态图像-文本检索因其不同模态内容之间存在的多样关联，是一个挑战性的任务。传统方法通过单一向量嵌入来表示每个样本的语义，但在捕捉不同模态中存在的复杂和多样的关系方面存在局限。集合数据表示方法通过为每个样本使用多个嵌入，可以捕捉更加丰富和多样的关系，展现出了新的前景。然而，这类方法仍面临诸如稀疏监督和集合坍缩等问题，限制了它们的效果发挥。

Innovation: 
本文提出了最大化对应回合相似度（Maximal Pair Assignment Similarity）来优化嵌入集合之间的一对一匹配，以保持集合内的语义多样性。还引入了两个增强表示的方法：全局判别损失用于增强嵌入间的区分性，以及内部集合发散损失用于防止集合内部坍缩。

Conclusion: 
本文的方法在MS-COCO和Flickr30k数据集上实现了最先进的性能，且无需依赖外部数据。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21538</guid><pubDate>Fri, 27 Jun 2025 02:44:52 +0800</pubDate></item><item><title>115. cs.LG-通过可学习自适应时频表示的可微分短时傅里叶变换</title><link>https://arxiv.org/pdf/2506.21440</link><description>Background: 
短时傅里叶变换（STFT）广泛用于分析非稳态信号，但由于其性能高度依赖于参数设置，手动或启发式调整往往效果不佳，且通常依赖于计算密集型的离散搜索来调整参数，这对优化构成了限制。

Innovation: 
提出了一种统一的可微分STFT形式，使得可以通过基于梯度的方法优化其参数。这种方法解决了传统STFT参数调整方法的局限性，并能够根据任何所需标准对时频表示（TFR）进行精细调整。此外，该方法能够无缝集成到神经网络中，允许STFT参数和网络权重的联合优化。实验表明，通过可微分STFT改进了TFR并提升了下游任务的性能，无论是仿真数据还是真实世界数据。

Conclusion: 
通过可微分STFT，可以精调时频表示，基于任何所需的评估标准，并且可以无缝集成到神经网络训练过程中，提升性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21440</guid><pubDate>Fri, 27 Jun 2025 02:44:48 +0800</pubDate></item><item><title>116. cs.LG-skLEP: 斯洛伐克通用语言理解基准</title><link>https://arxiv.org/pdf/2506.21508</link><description>Background: 
目前尚未有专为斯洛伐克自然语言理解(NLU)模型设计的综合性基准。本研究旨在提供一个综合性的基准来评估斯洛伐克NLU模型的能力，涵盖九个不同任务，从标记级、句子对级到文档级，以全面评估模型的能力。研究者通过编译新的、原创的数据集和仔细翻译现有的英语NLU资源，为斯洛伐克语定制了这些数据集，以此来建立这个基准。

Innovation: 
这是第一个专门设计的斯洛伐克自然语言理解模型基准。它集合了九项不同任务，旨在测试模型在标记级、句子对级和文档级任务上的能力。研究者还首次系统地评估了多种特定于斯洛伐克、多语言和英语的预训练语言模型的表现，并且提供了一个数据集、开源工具包用于模型的精细调整和评估，以及公开的联赛表，以促进重复性和未来的研究。

Conclusion: 
本研究发布了完整的基准数据、开源工具包，并且提供了公开的排行榜，以期促进斯洛伐克自然语言理解领域的研究和重复。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21508</guid><pubDate>Fri, 27 Jun 2025 02:44:47 +0800</pubDate></item><item><title>117. cs.LG-一个针对多元场景的地下矿工检测综合数据集</title><link>https://arxiv.org/pdf/2506.21451</link><description>Background: 
地下采矿作业面临严峻的安全挑战，使得紧急应对能力至关重要。机器人在协助搜索和救援操作方面显示出潜力，但其有效性依赖于可靠的矿工检测能力。深度学习算法提供了自动矿工检测的潜在解决方案，但需要针对地下采矿环境的全面培训数据集，目前此类数据集尚且欠缺。因此，急需开发和验证适用于潜在紧急情况的矿工检测系统。

Innovation: 
本文提出了一种新颖的热像数据集，旨在促进和验证热基矿工检测系统的开发与验证。通过系统地捕捉多种采矿活动和场景的热图像，创建了检测算法的基础。同时，利用多种先进的物体检测算法（包括YOLOv8，YOLOv10，YOLO11和RT-DETR）在该数据集上进行评估，以建立基线性能指标。

Conclusion: 
这种方法证明了使用热像进行矿工检测的可行性，并为这一至关重要的安全保障领域的未来研究奠定了基础。尽管不涵盖所有可能的紧急情境，但该数据集已作为开发可靠热基矿工检测系统的关键第一步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21451</guid><pubDate>Fri, 27 Jun 2025 02:44:44 +0800</pubDate></item><item><title>118. cs.LG-进行空旷空间可靠检测的研究：基于条件标记点过程的目标检测</title><link>https://arxiv.org/pdf/2506.21486</link><description>Background: 
深度神经网络已经在计算机视觉任务中，如边界框检测和语义分割中取得了最先进的成果。现有检测器和分割模型会为预测分配置信度分数，体现模型在目标检测或像素级分类中的不确定性。然而，这些置信度估计往往校准不佳，因为模型的架构和损失函数通常侧重于任务性能而非概率基础。即使置信度估计校准良好，现有检测器也无法量化未检测边界框区域的不确定性，即模型无法对未检测区域内是否存在障碍物进行概率评估。这一缺陷在自动驾驶等应用场景中尤为危险，因为空旷区域的不确定性尚未被探索。

Innovation: 
本文提出了基于空间统计的目标检测模型，该模型以标记点过程为理论基础。边界框数据与标记点过程的实际实现相符，用来描述空间点事件的出现概率，其中标记信息用于描述边界框的空间范围和类别。该统计框架支持基于似然性的训练，能够提供定义明确的置信度估计，表明某个区域是否为可行驶区域，即无物体区域。通过校准评估和性能评估证明了本方法的有效性。

Conclusion: 
本文提出的方法通过基于标记点过程的统计框架，能够提供更为可靠的空旷区域检测，解决了现有模型在未检测区域的置信度估计问题。并通过实验证明了此方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21486</guid><pubDate>Fri, 27 Jun 2025 02:44:43 +0800</pubDate></item><item><title>119. cs.LG-使用高效球形卡仕达分布的超球面变分自动编码器</title><link>https://arxiv.org/pdf/2506.21278</link><description>Background: 
传统的变分自动编码器（VAE）使用高斯潜在空间，而广泛使用的von Mises-Fisher（vMF）分布则用于表示球面数据。尽管这些方法在某些方面表现良好，但高斯潜在空间容易导致过度正则化，而vMF分布则在计算上存在数值不稳定的问题。因此，需要一种既能有效表示方向数据又不会导致数值问题的新颖潜在分布来改进VAE架构，提高其在高维生成建模中的性能和效率。

Innovation: 
本文提出了一种新颖的变分自动编码器架构，采用球形卡仕达（spCauchy）潜在分布。spCauchy相比传统的高斯潜在空间和vMF分布，能更好地捕捉方向数据，并提供更加自然的超球面表示，且具有更灵活的表达性。spCauchy具有重尾特性，能够防止过度正则化，确保有效的潜在空间利用。此外，它通过莫比乌斯变换使重构过程完全可微分，避免了vMF计算归一化常数时的数值不稳定性问题。spCauchy还可以通过快速收敛的级数计算Kullback-Leibler（KL）散度，避免了使用超几何函数时的下溢或上溢问题。

Conclusion: 
spCauchy为VAE提供了一种有吸引力的替代方案，不仅在理论上具有优势，还在高维生成建模中表现出高效性和实用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21278</guid><pubDate>Fri, 27 Jun 2025 02:44:42 +0800</pubDate></item><item><title>120. cs.LG-从用户交互中调整口语对话模型</title><link>https://arxiv.org/pdf/2506.21463</link><description>Background: 
当前的偏好学习方法主要集中在基于文本的语言模型上，而不适用于实时语音互动的复杂性，后者伴随更多的动态变化（如打断和插入），而且没有明确的说话人分隔。现有方法在处理这类动态变化时存在局限性。为了解决这个问题，作者创建了一个包含逾15万口语对话片段双向对话数据集，并附有AI反馈，从而涵盖了语言内容和时间上下文变化的偏好。

Innovation: 
作者提出了一种新颖的偏好对齐框架，用于提高实时会话中的口语对话模型。该框架通过大规模收集语音多轮对话的数据，并使用离线对齐方法微调全双工自回归言语到言语模型，有效提升了对话模型的质量，使之更具有事实性、安全性和上下文一致性。此外，作者通过全面的人类评估展示了调整模型后的影响，不仅仅局限于单轮次对话，从而证明了调整对话模型的有效性以及对自然实时对话系统的全过程改进的重要性。

Conclusion: 
研究表明，通过AI反馈调整后的对话模型在进行多轮次对话时表现更为出色，这突显了各种动态因素之间的良好平衡对于构建自然的实时语音对话系统的重要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21463</guid><pubDate>Fri, 27 Jun 2025 02:44:38 +0800</pubDate></item><item><title>121. cs.LG-含量子记忆和局部学习的随机量子刺规神经网络</title><link>https://arxiv.org/pdf/2506.21324</link><description>Background: 
神经形态计算和量子计算最近作为推动人工智能的有前途的范式新兴起来，各具互补优势。基于尖峰神经元的神经形态系统擅长高效地处理时间序列数据，仅在输入事件时消耗能量。另一方面，量子计算利用叠加和纠缠探索具有量子比特数量指数级大小的功能空间。这些范式相结合的混合方法已经开始显示出潜力，但现有的量子尖峰模型存在重要限制。值得注意的是，之前量子尖峰神经元实现依赖于单量子比特的经典存储机制，需要重复测量来估计尖峰概率，并使用经典后向传播在经典模拟器上进行训练。

Innovation: 
本文提出了一种随机量子刺规（SQS）神经元模型，解决了上述挑战。SQS神经元采用多量子比特的量子电路来实现具有内部量子记忆的尖峰单元，能够单步生成事件驱动的概率尖峰。此外，提出了SQS神经网络（SQSNN）可以通过硬件友好的局部学习规则进行训练，消除了全局经典后向传播的需求。该SQSNN模型融合了神经形态计算的时间序列效率和量子计算的指数级内部状态空间，为基于量子硬硬件的尖峰神经网络铺平了道路，使其模块化、可扩展并能在量子硬件上进行训练。

Conclusion: 
提出的SQSNN模型融合了神经形态计算高效处理时间序列数据的特性以及量子计算具有指数级内态空间的能力，通过多量子比特电路实现了具有内部量子记忆的事件驱动式概率尖峰生成，并通过局部学习规则能够利用硬件特训，为量子尖峰神经网络的发展提供了可能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21324</guid><pubDate>Fri, 27 Jun 2025 02:44:37 +0800</pubDate></item><item><title>122. cs.LG-揭示大型语言模型中的因果推理：幻觉还是现实？</title><link>https://arxiv.org/pdf/2506.21215</link><description>Background: 
大型语言模型（LLMs）的因果推理能力对于推动其向强人工智能发展至关重要。尽管这些模型似乎已经展示了理解上下文因果关系和提供符合因果律响应的能力，但尚不清楚它们是否真的能进行类似于人类的真正因果推理。研究表明，这些模型仅能进行浅层次（第一层）因果推理，主要受限于模型参数中嵌入的因果知识，而缺乏人类类似的深层次（第二层）因果推理能力。这篇文章通过探讨基于Transformer的LLMs的自回归机制，揭示这一机制并非固有因果，还通过引入一个新的因果问答基准CausalProbe-2024来证明这一点，结果显示这些模型在新场景下的因果推理能力显著下降，主要进行的是浅层次因果推理。因此，本文讨论了如何通过引入广泛的背景知识和目标导向的提示来增强模型的因果推理能力，从而促进其向高层次因果推理迈进。

Innovation: 
本文通过构建新的因果问答基准CausalProbe-2024，揭示了当前LLMs的因果推理能力主要局限在浅层次，无法进行真正的人类类似的深层因果推理。基于此，提出了G^2-Reasoner模型，该模型将一般知识和目标导向的提示融入LLMs的因果推理过程中，显著增强了模型的因果推理能力，尤其是在新场景和反事实情景下。

Conclusion: 
本文为LLMs如何向真正的因果推理迈进提供了一个新的方向，即通过整合广博的背景知识和目标导向的提示，使得模型能够更接近于深度的因果推理，而不是仅仅停留在知识嵌入的浅层次因果推理阶段。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21215</guid><pubDate>Fri, 27 Jun 2025 02:44:36 +0800</pubDate></item><item><title>123. cs.LG-探索低资源音乐生成领域的适配器设计权衡</title><link>https://arxiv.org/pdf/2506.21298</link><description>Background: 
对大型音乐生成模型，如MusicGen和Mustango进行微调是一个计算成本高昂的过程，通常需要对数十亿个参数进行更新，并且需要大量的硬件资源。现有的参数高效微调（PEFT）技术，尤其是基于适配器的方法，能够在保持模型性能的同时减少需要训练的参数量。然而，对于适配器的设计选择，包括其架构、位置和规模，仍有诸多不确定性，不清楚哪些组合可以在低资源音乐流派中产生最优的适配器，以及为何如此。本文旨在通过研究两种AI音乐模型（MusicGen和Mustango）在两种不同音乐流派（印度古典音乐和土耳其马卡姆音乐）中的适配器配置，来回答这一问题。

Innovation: 
本文首次系统地研究了适配器设计在低资源音乐生成中的权衡，并指出基于卷积的适配器在捕捉细微音乐细节方面表现出色，而基于变换器的适配器在保存长距离依赖性方面更为有效。此外，研究还发现，中等规模的适配器（40M参数）在表达能力和质量之间实现了良好的平衡。研究结果还对比了基于扩散的模型Mustango和自回归模型MusicGen在生成多样性和稳定性、训练速度和效率等方面的优缺点。

Conclusion: 
研究表明，对于低资源音乐生成任务，卷积基于的适配器擅长捕捉细微的音乐细节，而基于变换器的适配器则更擅长保持结构化即兴创作所需的长距离依赖性。此外，中等规模的适配器能够在表达能力和质量之间达到较好的平衡。这一研究通过详细分析不同适配器规模的计算资源需求，为选择合适的适配器设计提供了实用指导。同时，研究表明，MusicGen在训练速度和生成质量方面更有优势，而Mustango能够生成更具多样性的输出，但稳定性不足且训练时间较长。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21298</guid><pubDate>Fri, 27 Jun 2025 02:44:32 +0800</pubDate></item><item><title>124. cs.LG-关于均匀加权深度多项式逼近</title><link>https://arxiv.org/pdf/2506.21306</link><description>Background: 
在有理逼近理论中，具有非光滑或奇异性质的函数，例如|x|和x^(1/p)，可以通过具有良好自由度依赖的根指数收敛的有理函数高效逼近。然而，多项式逼近通常遵循由Jackson定理保证的代数收敛速度。最近的研究表明，即使在缺乏光滑性的情况下，复合多项式架构也可以恢复指数逼近率。

Innovation: 
本文引入并分析了一类针对单边增长和双边衰减这类非对称行为函数的加权深度多项式逼近器。通过将可学习的深度多项式与单边权重相乘，能够捕捉局部非光滑性和全局增长特性。数值结果表明，此类框架在参数数量相同的情况下优于泰勒、切比雪夫以及标准深度多项式逼近器。为此类逼近器的实际优化，提出了基于图的方法进行稳定参数化。

Conclusion: 
研究表明，这种加权深度多项式逼近方法在处理非对称行为函数时，相较于传统的泰勒和 Chebyshev 多项式逼近方法，表现更优；并且提出了稳定且有效的参数化策略。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21306</guid><pubDate>Fri, 27 Jun 2025 02:44:26 +0800</pubDate></item><item><title>125. cs.LG-突破权衡边界：紧凑且有效的遥感变化检测</title><link>https://arxiv.org/pdf/2506.21109</link><description>Background: 
遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，能够提供及时、准确且大规模的动态景观变化洞察。尽管深度学习已彻底改变了变化检测，但现代模型的日益复杂性和计算需求并未带来显著的准确度提升。因此，本研究探索了一种更有效的轻量级方法，这种方法旨在在资源消耗最小化的同时保持高准确度，这是卫星上处理的必要要求。通过提出一种名为FlickCD的方法，该方法引入了增强差异模块（EDM）放大关键特征差异，抑制无关变化如照明和天气变化，从而降低后续变化解码器的计算成本。该方法还在解码器中采用了局部-全局融合块，利用移位窗口自我注意力（SWSA）和增强全局自我注意力（EGSA），以高效捕捉不同尺度的语义信息，保持粗粒度和细粒度变化的完整性。在四个基准数据集上的广泛实验表明，FlickCD在计算和存储开销方面大幅降低（超过一个数量级），同时达到最先进技术水平或仅产生轻微（&amp;lt;1% F1）的准确度损失。

Innovation: 
本研究提出了一种名为FlickCD的方法，它通过引入增强差异模块（EDM）和局部-全局融合块，利用移位窗口自我注意力（SWSA）和增强全局自我注意力（EGSA），实现了在保持高准确度的同时显著减少计算和存储开销的技术创新。这一方法突破了计算资源与准确度之间的权衡边界，为遥感变化检测提供了一种高效的解决方案。

Conclusion: 
FlickCD方法在四个基准数据集上的实验结果证明，该方法在计算和存储开销方面大幅降低（超过一个数量级），同时达到最先进的技术水平或仅产生轻微（&amp;lt;1% F1）的准确度损失。这表明FlickCD能够在保证高准确度的同时实现低资源消耗，突破了传统的性能资源权衡边界。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21109</guid><pubDate>Fri, 27 Jun 2025 02:44:26 +0800</pubDate></item><item><title>126. cs.LG-DCASE 2025挑战任务4中通过丰富音频特征和基于代理的错误修正提高空间语义分割性能</title><link>https://arxiv.org/pdf/2506.21174</link><description>Background: 
本文的技术报告展示了DCASE 2025挑战任务4的提交系统。该模型将额外的音频特征（谱滚降和音阶特征）纳入从梅尔频谱特征中提取的嵌入特征中，以提高音频标记模型在空间语义分割声景（S5）系统中的分类能力。该方法由这样一个事实激发而来，即混合音频通常包含难以仅通过梅尔频谱图捕捉的微妙线索。此外，还应用了基于代理的标签校正系统，以降低假阳性，从而提高最终的类感知信号-失真比改进（CA-SDRi）指标。最后，通过精炼训练数据集，移除无关样本并引入外部数据，进一步提高了分类准确性。实验结果表明，采用这些方法的提交系统相比DCASE 2025挑战任务4的基线，在CA-SDRi指标上相对提高了14.7%。

Innovation: 
本文的创新之处在于通过引入额外的音频特征（谱滚降和音阶特征）提高了音频标记模型的分类能力，并应用基于代理的标签校正系统提高了最终的CA-SDRi指标，同时通过精炼训练数据集提高了低表现类别的分类准确性。这些技术的应用显著提升了系统的性能，特别是在处理包含细微线索的混合音频时效果更为显著。

Conclusion: 
实验结果证明，通过引入丰富音频特征（谱滚降和音阶特征）、应用基于代理的标签校正系统以及优化训练数据集，所提出的系统在DCASE 2025挑战任务4中可以在CA-SDRi指标上提高14.7%的表现，从而验证了这些方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21174</guid><pubDate>Fri, 27 Jun 2025 02:44:24 +0800</pubDate></item><item><title>127. cs.LG-从链上到宏观经济：评估数据源多样性在加密货币市场预测中的重要性</title><link>https://arxiv.org/pdf/2506.21246</link><description>Background: 
本文旨在研究数据源多样性对加密货币预测模型性能的影响。研究通过整合多种数据类别，涵盖了技术指标、链上指标、市场情绪和兴趣指标、传统市场指数及宏观经济指标，来实现这一目标。此外，文章还提出了一个名为Crypto100指数的指标，代表市值最大的前100种加密货币，并提出了一种新型特征缩减算法以从多源数据中识别出最具影响力的、最稳健的特征。实验结果表明，数据源多样性可以显著增强预测模型在不同时间范围内的预测性能。研究发现技术指标在短期和长期预测中具有重要性，传统市场指数和宏观经济指标对长期预测的重要性日益增加，而利用多种数据源可显著提高模型准确性。这些发现有助于弄清楚推动加密货币市场短期和长期变化的主要因素，并为开发更准确、更稳健的预测模型奠定了基础。

Innovation: 
本文引入了一个名为Crypto100指数的指标，代表市值最大的前100种加密货币，以及提出了一种新型特征缩减算法来识别多样数据来源中最具有影响力的特征。实验证明使用多种数据源可以显著提高预测模型的准确性并增强其对不同时间范围内的预测性能。这些发现为开发更准确、更稳健的预测模型提供了有力支持。

Conclusion: 
数据源多样性对于提高加密货币预测模型的准确性和鲁棒性至关重要。尤其是，技术指标在短期和长期预测中发挥着关键作用，而传统市场指数和宏观经济指标对长期预测的重要性不断增强。利用多种数据源可以显著改善预测模型的准确性，有助于揭示推动加密货币市场短期和长期变化的主要因素，并为丰富和发展加密货币预测模型提供了依据。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21246</guid><pubDate>Fri, 27 Jun 2025 02:44:23 +0800</pubDate></item><item><title>128. cs.LG-CovDocker: 使用任务、数据集和解决方案评估共价药物设计</title><link>https://arxiv.org/pdf/2506.21085</link><description>Background: 
分子对接在预测配基与靶蛋白结合模式方面起着关键作用，共价相互作用由于其强有力的、持久的结合特性，尤其宝贵。然而，现有的大多数对接方法和深度学习方法并未充分考虑共价键的形成及其相关结构变化。为解决这一问题，我们提出了一个全面的共价对接基准CovDocker，旨在更好地捕捉共价结合的复杂性。该基准将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过调整最先进的模型，如Uni-Mol和Chemformer，建立了基线性能，并展示了该基准在准确预测相互作用位点以及模拟共价结合过程中分子的结构变化方面的有效性。这些结果证实了该基准作为促进基于共价化学的药物设计研究严谨框架的作用，强调了数据驱动方法在加速选择性共价抑制剂的发现以及解决治疗开发中关键挑战中的潜力。

Innovation: 
我们引入了CovDocker，这是第一个全面的共价对接基准。它将共价对接过程分解为三个主要任务，并通过调整最先进的模型来建立基线性能，从而有效预测相互作用位点和模拟共价结合过程中的分子变化。

Conclusion: 
CovDocker 作为严谨的基准是促进共价药物设计研究的关键工具，数据驱动的方法在发现选择性共价抑制剂方面展现出巨大的潜力，并解决了治疗开发中的关键挑战。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21085</guid><pubDate>Fri, 27 Jun 2025 02:44:22 +0800</pubDate></item><item><title>129. cs.LG-EgoAdapt：适应性多感官蒸馏和策略学习以实现高效的主观感知</title><link>https://arxiv.org/pdf/2506.21080</link><description>Background: 
现代感知模型，尤其是在多感官主观任务中设计的模型，虽然取得了显著的效果，但往往伴随着巨大的计算成本。这些高要求给实际部署带来了挑战，尤其是在资源受限的环境中。当前的模型在执行跨模态蒸馏和策略学习时，其效率仍有待提高，尤其是在计算资源受限的场景中。已有研究试图通过策略学习提高主观感知任务的效率，但尚未有全面的解决方案来应对这一挑战。

Innovation: 
本文介绍了一种名为EgoAdapt的框架，该框架通过适配性地进行跨模态蒸馏和策略学习，提高不同主观感知任务的高效推理能力。主要创新在于提出了一种可适应特定任务动作空间的策略模块，使该方法具有广泛的应用潜力。实验结果表明，与当前最先进的模型相比，该方法不仅在效率上有显著提高（GMACs减少89.09%，参数减少82.02%，能量消耗减少9.6倍），在多项主观感知任务上也保持了相当甚至优于现有模型的性能。

Conclusion: 
本研究通过引入EgoAdapt框架，展示了在多种挑战性的主观感知数据集上，如何通过适配性地进行跨模态蒸馏和策略学习，显著提高了感知任务的性能与效率。这种方法对资源受限环境中的主观感知任务具有重要的应用价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21080</guid><pubDate>Fri, 27 Jun 2025 02:44:21 +0800</pubDate></item><item><title>130. cs.LG-有限状态马尔可夫博弈中多代理学习动态的 homogenization</title><link>https://arxiv.org/pdf/2506.21079</link><description>Background: 
该论文介绍了在有限状态马尔可夫博弈中多个强化学习（RL）代理互动的新方法。背景在于之前对于多个代理在一个有限状态马尔可夫博弈中的学习动态的分析较为复杂。为了简化这一过程，研究者提出了一种通过同时降低学习率和增加更新频率来缩放学习过程的方法，使代理的参数被看作一个受快速混合博弈状态影响的缓慢变化变量。这种方法在基于有限状态过程的遍历性和更新连续性的假设下，已经被证明可以收敛到一个常微分方程（ODE），该ODE为代理的学习动态提供了一个可处理且确定性的近似方法。

Innovation: 
论文的创新点在于提出了一种新的方法来近似多个强化学习代理在有限状态马尔可夫博弈中的学习动态。该方法通过调整学习率和更新频率来重新缩放学习过程，使代理参数更具可处理性，并能够通过常微分方程提供学习动态的确定性近似。这一方法在理论分析和实际应用中都展示了显著的简化和优化效果。

Conclusion: 
基于温和的假设-状态过程的遍历性和更新的连续性，论文证明了重新缩放过程可以收敛到一个常微分方程。该常微分方程为代理的学习动态提供了一个可处理且确定性的近似。这一成果为理解和理论分析多代理在有限状态马尔可夫博弈中的学习动态提供了一种新的手段。论文提供的框架实现可以在 provided URL 获取。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21079</guid><pubDate>Fri, 27 Jun 2025 02:44:15 +0800</pubDate></item><item><title>131. cs.LG-HybridQ: 混合经典-量子生成对抗网络在皮肤疾病图像生成中的应用</title><link>https://arxiv.org/pdf/2506.21015</link><description>Background: 
皮肤疾病的诊断在人工智能辅助诊断中越来越受到重视，但有效的模型训练需要大量高质量的数据。现有皮肤疾病数据集常常存在类别不平衡、隐私问题和目标偏见，因此数据增强技巧变得至关重要。尽管经典的生成模型被广泛使用，但它们需要大量的计算资源和长时间的训练。量子计算提供了一种新的替代方案，但现有的基于量子的图像生成方法只能生成质量较低的灰度图像。为了解决这个问题，本文提出了一个创新的混合经典-量子潜在空间融合技术，首次开发出了能够生成彩色医疗图像的经典-量子生成对抗网络（GAN）。

Innovation: 
本文提出了一种新的经典-量子生成对抗网络（GAN）模型，克服了现有生成模型的限制，并能够在图像生成质量和分类性能方面超过传统深度卷积GAN及现有混合经典-量子GAN模型。此外，与最先进的经典生成模型相比，该模型的参数量减少了25倍以上，训练周期减少了10倍。这个成果表明随着量子硬件的进展，基于量子的图像生成具有光明的前景。

Conclusion: 
实验结果显示，本文提出的模型在实际的IBM量子机器上具有稳健的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21015</guid><pubDate>Fri, 27 Jun 2025 02:44:13 +0800</pubDate></item><item><title>132. cs.LG-EraRAG：不断扩大的语料库上的高效增量检索增强生成</title><link>https://arxiv.org/pdf/2506.20963</link><description>Background: 
Graph-based Retrieval-Augmented Generation (Graph-RAG)通过对外部语料库进行结构化检索来增强大型语言模型（LLMs）。然而，现有方法通常假设语料库是静态的，每当新文档到达时都需要进行昂贵的全图重建，这限制了其在动态、不断变化的环境中可扩展性不足的问题。

Innovation: 
我们引入了一种新型的多层EraRAG框架，支持高效和可扩展的动态更新。该方法利用基于超平面的局部敏感哈希（LSH）将原始语料库划分为分层图结构，可以在不影响现有拓扑的情况下高效地插入新数据。设计上避免了重新训练或昂贵的重新计算，同时保持高检索准确性和低延迟。实验结果表明，与现有Graph-RAG系统相比，EraRAG的更新时间和令牌消耗最多可减少一个数量级，且提供了更优越的准确性能。这项工作为必须在不断增长的语料库上运行的RAG系统提供了一条实用的途径，填补了检索效率和适应性的空白。

Conclusion: 
EraRAG为RAG系统提供了一种实际可行的途径，使其能够在不断扩大的语料库上运行，同时在检索效率和适应性之间取得了平衡。我们的代码和数据见 this &amp;lt;https://this.is.link＞.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20963</guid><pubDate>Fri, 27 Jun 2025 02:44:13 +0800</pubDate></item><item><title>133. cs.LG-通过指导和调度提高基于扩散的图像编辑保真度</title><link>https://arxiv.org/pdf/2506.21045</link><description>Background: 
文本引导的扩散模型已成为高质量图像合成的关键方法，支持动态图像编辑。在图像编辑中，编辑能力和保真度是两个关键方面，但两者之间存在内在的权衡关系，使得同时追求高质量和自由度变得具有挑战性。

Innovation: 
提出了信仰度指导和调度（FGS），这是一种增强保真度但仍保持编辑灵活性的方法。FGS通过添加保真度指导增强了输入图像信息的保留，并引入了调度策略来解决编辑能力和保真度之间的偏差。实验结果表明，FGS能够实现更高的保真度同时保持编辑能力。此外，FGS与各种编辑方法兼容，可用于不同任务的精确高质量图像编辑。

Conclusion: 
FGS能够通过加强输入图像信息的保留并解决编辑能力与保真度之间的偏差，实现更高的保真度和编辑能力的平衡。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21045</guid><pubDate>Fri, 27 Jun 2025 02:44:11 +0800</pubDate></item><item><title>134. cs.LG-通过梯度下降模拟提示能否实现？</title><link>https://arxiv.org/pdf/2506.20989</link><description>Background: 
论文探讨了将新信息融入语言模型（LM）的两种主要方法：修改提示或修改参数（例如通过微调）。参数更新不涉及长期存储成本，但许多模型更新中，提示的效果远远更佳。提示模型可以从单个示例中稳健泛化，并进行标准微调中不会出现的逻辑推理。本文研究如何使得微调模仿提示的效果，描述了一种元训练LM的方法，使得梯度更新模仿对新信息的条件效果。通过使用语言模型自身被提示的预测作为目标，而不需要真实的标签，随后的梯度下降训练可以恢复一些（偶尔全部）被提示模型的表现。这表明适当的初始化下，梯度下降可以令人惊讶地富有表现力，为长上下文建模提供了新途径并提供了梯度基学习泛化能力的见解。

Innovation: 
本文提出了一种方法，通过元训练语言模型（LM）使得梯度更新模仿对新信息的条件效果。这种方法利用了基于梯度的元学习工具，但使用了LM本身的被提示预测作为目标，从而消除了真实标签的需求。随后的梯度下降训练能够恢复部分甚至全部被提示模型的性能，展示了在“逆转诅咒”任务上的改进，以及通过一次梯度更新回答文本片段的问题。这些成果表明，适当的初始化下，梯度下降可以令人惊讶地富有表现力。

Conclusion: 
这些结果表明，通过合适的初始化，梯度下降可以非常表达力，为长上下文建模提供了新的途径，并提供了梯度基学习泛化能力的洞察。未来的研究可以探索更有效的初始化策略，以及这种技术在实际应用中的潜在影响。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20989</guid><pubDate>Fri, 27 Jun 2025 02:44:10 +0800</pubDate></item><item><title>135. cs.LG-基于Transformer的空间时序反事实结果估计</title><link>https://arxiv.org/pdf/2506.21154</link><description>Background: 
现实世界具有时间和空间维度，因此具有时空属性的反事实结果估计是一个关键问题。然而，先前的方法基于传统的统计模型，这些模型在性能和泛化方面仍存在局限性。

Innovation: 
本文提出了一种基于Transformer的新框架，用于估计具有时空属性的反事实结果，展现出更强的估计能力。在温和的假设下，该框架中的新估计器具有一致性并且渐近正态分布。

Conclusion: 
仿真实验和真实数据实验验证了该方法的有效性。仿真实验表明我们的估计器在估计能力上优于基线方法。真实数据实验提供了冲突对哥伦比亚森林损失因果效应的重要结论。源代码可以在该链接中找到。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21154</guid><pubDate>Fri, 27 Jun 2025 02:44:10 +0800</pubDate></item><item><title>136. cs.LG-通过负音频指导的逐步视频到音频合成</title><link>https://arxiv.org/pdf/2506.20995</link><description>Background: 
本文提出了一种新颖的逐步视频到音频生成方法，该方法按顺序生成与视频中特定声音事件对应的单独音频轨道。该方法借鉴了传统配音工作流程，旨在全面捕捉由给定视频引发的所有声音事件。在每个生成步骤中，将生成任务视为受目标文本提示和之前生成的音频轨道约束的受指导的视频到音频合成任务。通过引入一个基于预训练的视频到音频模型的训练框架，该方法消除了对专属配对数据集的需求，从而允许在更易于获取的数据上进行训练。实验结果表明，该方法能够为单个输入视频生成多个语义上不同的音频轨道，比现有的基线方法产生更高质量的合成音频。

Innovation: 
本文的创新点在于提出了一个逐步视频到音频生成方法，该方法通过负音频指导来生成与视频特定声音事件对应的单独音频轨道，不依赖于专属配对数据集，而是利用预训练的视频到音频模型进行训练。这一设计灵感来自于先前组合生成框架中的概念否定理念，使得该方法能够在更广泛的、更易于获取的数据上进行有效的训练和生成。

Conclusion: 
实验结果表明，该方法能够为单个输入视频生成多个语义上不同的音频轨道，产生比现有基线方法更高质量的合成音频。此方法在逐步生成和负音频指导方面展示了其在视频到音频生成任务中的优势。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20995</guid><pubDate>Fri, 27 Jun 2025 02:44:08 +0800</pubDate></item><item><title>137. cs.LG-更快的多链MDPs固定点方法</title><link>https://arxiv.org/pdf/2506.20910</link><description>Background: 
我们研究在平均奖励准则下求解一般(Markov决策过程MDPs)的价值迭代(VI)算法，这是理论上有挑战的一个核心设置。这个问题包含所有平均奖励问题共同面临的不收敛性和贝尔曼算子解的非唯一性难题。在多链环境下，最优策略必须解决如何导航至最佳连通部分的问题，而不只是在每个连通部分优化长期性能。

Innovation: 
我们开发了更好地解决导航子问题的算法，以便于更快地解决多链MDPs问题。相比于先前的工作，我们的方法具有更快收敛速度和更准确的时间复杂度测量。我们的结果包括了平均奖励和折扣问题之间的新联系、适用于一般Banach空间的最优固定点方法、折扣VI中新的次线性收敛率以及多链MDPs的新次优分解。这些关键组件对独立研究可能有所贡献。

Conclusion: 
我们的研究极大地改进了折扣和平均奖励问题的收敛速度，并扩展了价值迭代方法的理论基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20910</guid><pubDate>Fri, 27 Jun 2025 02:44:01 +0800</pubDate></item><item><title>138. cs.LG-LLM生成与人类研究想法执行结果之间的想法执行差距：基于执行的结果</title><link>https://arxiv.org/pdf/2506.20803</link><description>Background: 
大语言模型（LLMs）在科学研究管道加速方面展现出潜力，尤其在生成新颖的研究想法方面。此前的研究表明，LLMs生成的想法有时比人类专家的想法更具有新颖性。然而，一个好的想法不仅应该显得新颖，还应该在执行后产生更好的研究结果。基于此，本研究通过一项执行研究考察了AI生成想法和人类专家生成想法在实际执行后的研究结果差异。研究表明，AI生成的想法在评估标准（新颖性、兴奋度、有效性及总体效果）上的得分在执行后显著下降，这弥补了LLMs和人类想法在想法生成阶段观察到的差距。此外，人类想法在某些评估指标上甚至超过了AI生成的想法，从而揭示了LLMs在生成真正有效研究想法方面的局限性及其评估挑战。

Innovation: 
本研究通过一种执行研究方法，评估了AI生成想法与人类专家生成想法在实际执行中的效果差异，填补了LLMs在想法生成阶段和执行结果之间的研究空白。研究采用盲审方式，共招募了43名专家进行为期超过100小时的执行和撰写实验报告，结果表明在多个评估指标上，AI生成的想法在执行后的分数显著低于人类专家生成的想法，揭示了LLMs在生成真正有效的研究想法方面存在局限性。

Conclusion: 
本研究展示了LLM生成的研究想法与人类专家生成的想法在实际执行后的差距，发现LLM生成的想法在多个评估指标上的效果确实不如人类生成的想法，这揭示出当前LLMs在生成有效研究想法方面的技术局限性和评估挑战。未来的研究可以进一步探索如何改进LLMs使得生成的研究想法在实际执行后也能表现出良好的效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20803</guid><pubDate>Fri, 27 Jun 2025 02:44:00 +0800</pubDate></item><item><title>139. cs.LG-Uncertainty-Aware Machine-Learning Framework for Predicting Dislocation Plasticity and Stress-Strain Response in FCC Alloys</title><link>https://arxiv.org/pdf/2506.20839</link><description>Background: 
机器学习在结构材料的理解和应用中取得了显著进展，重点在于整合现有数据并量化预测建模中的不确定性。该研究利用混合密度网络（MDN）模型，通过对文献中大量实验数据的训练，全面预测位错密度的分布及其在晶粒级别上的应力分布，这一过程是通过推断出的一个潜在变量进行的。这项研究整合预测分布的统计参数到位错介导的塑性模型中，实现了含杂性的应力-应变预测，并提升机械性能预测的准确性和可靠性，同时对合金设计优化至关重要，从而促进了新材料的快速发展以应对快速变化的行业环境。

Innovation: 
研究采用混合密度网络（MDN）模型，该模型能预测位错密度的分布以及晶粒级别上的应力分布。通过整合预测分布的统计参数到位错介导的塑性模型中，实现了准确的应力-应变预测并量化了误差。这种方法不仅提高了材料机械性能预测的准确性和可靠性，还对合金设计优化起到了关键作用，促进了新材料的发展。

Conclusion: 
该研究建立了一种包含不确定性意识的机器学习框架，可以预测fcc合金的位错塑性和应力-应变响应。这种方法不仅提高了应力-应变预测的准确性和可靠性，还对合金设计优化和技术发展具有重要作用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20839</guid><pubDate>Fri, 27 Jun 2025 02:43:59 +0800</pubDate></item><item><title>140. cs.LG-Markov等价类大小的下界</title><link>https://arxiv.org/pdf/2506.20933</link><description>Background: 
因果发现算法通常只能恢复因果图的马尔可夫等价类，除非附加了参数假设。马尔可夫等价类的大小反映了从纯粹观察数据中可以学到的关于潜在因果图的信息的局限性。在无环、因果充分和模型先验均匀的假设下，已知马尔可夫等价类的平均规模较小。然而，本论文显示，在这些假设中任何一个被放宽的情况下，这一结论不再成立。特殊地，论文证明了在三种不同的设置下马尔可夫等价类的期望大小有指数级的下界：稀疏随机有向无环图、均匀随机有向混合图和均匀随机有向有环图。

Innovation: 
该论文探讨了在无环、因果充分性和均匀模型先验这三项核心假设放宽的情况下，马尔可夫等价类的可能规模，推导出马尔可夫等价类平均预期大小的指数级下界。

Conclusion: 
论文证明了在放松上述任何一条假设的情况下，马尔可夫等价类的平均预期大小都会有指数级的下界，从而指出了纯观测数据受限制从而难以完全恢复潜在因果图的问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20933</guid><pubDate>Fri, 27 Jun 2025 02:43:59 +0800</pubDate></item><item><title>141. cs.LG-台湾股市板块轮动的量子增强强化学习交易代理</title><link>https://arxiv.org/pdf/2506.20930</link><description>Background: 
本研究提出了一种结合量子和经典计算的强化学习框架，用于台湾股市的板块轮动。背景在于，尽管量子增强模型在训练奖励上表现更好，但在实际投资指标（如累计回报和夏普比率）上却不如经典模型。这揭示了强化学习在金融领域应用中的关键挑战，即代理奖励信号与真实投资目标之间不匹配的问题。此外，这取决于量子电路在噪声中等规模量子（NISQ）约束下的表达能力和优化稳定性不足，可能导致对短期波动的过度拟合而非优化风险调整回报。

Innovation: 
该研究创新性地结合了Proximal Policy Optimization (PPO)算法与经典架构（如LSTM、Transformer）以及量子增强模型（如QNN、QRWKV、QASA），并通过自动特征工程流程从资本股份数据中提取金融指标，确保所有配置的一致输入。此外，研究分析了当前奖励设计可能激励对短期波动的过度拟合，而非优化风险调整回报的问题，并提出了未来改进方向，包括奖励重塑、模型正则化和基于验证的早期停止。

Conclusion: 
研究成果提供了一个可复现实验基准，并对部署量子增强强化学习在实际金融中的实践挑战提供了关键见解。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20930</guid><pubDate>Fri, 27 Jun 2025 02:43:59 +0800</pubDate></item><item><title>142. cs.LG-ZKPROV:一种用于大型语言模型数据来源的零知识方法</title><link>https://arxiv.org/pdf/2506.20915</link><description>Background: 
随着大型语言模型（LLMs）在敏感领域中的部署增长，尤其是在医疗保健等受监管行业，确保其计算来源的完整性成为了关键挑战。这对于严格规定数据集使用的地方尤其重要。现有方法要么侧重于整个训练过程的完整验证（这会带来巨大的计算成本），要么依赖于可信执行环境。ZKPROV通过使用零知识证明技术，提供了一种新的解决方案，既安全又保护了隐私，使得用户可以验证模型是否使用了可靠的训练数据集，而无需透露敏感信息或参数细节。

Innovation: 
ZKPROV引入了一种名为ZKPROV的新型加密框架，这是一种零知识证明框架，使用户能够在不泄露敏感信息或参数的情况下验证模型是否使用了可靠的数据集训练。通过使用数据集签名元数据和简化的模型参数承诺，ZKPROV能够在生成零知识证明的基础上保证结果来源于指定的数据集，同时保护数据集的机密性，免除逐个验证每个训练步骤的成本和复杂度。这种区别在于它提供了一种平衡的安全解决方案，适应了实际部署的需求。

Conclusion: 
实验证明了ZKPROV生成和验证这种证明的效率和可扩展性，为实际部署提供了实用的解决方案。我们还提供了正式的安全保证，证明了我们的方法不仅保持了数据集的机密性，还确保了数据来源的可信性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20915</guid><pubDate>Fri, 27 Jun 2025 02:43:58 +0800</pubDate></item><item><title>143. cs.LG-使用稀疏时间融合变换器和高斯过程混合进行地缘政治事件预测：中东和美国冲突动态案例研究</title><link>https://arxiv.org/pdf/2506.20935</link><description>Background: 
从全球事件、语言和语气数据库（GDELT）等数据源预测地缘政治冲突是国家安全的关键挑战。这些数据源具有固有的稀疏性、突发性和过度分散性，导致标准深度学习模型，包括时间融合变换器（TFT），在长期预测上产生不可靠的结果。因此，需要一种能够克服这些限制的方法来提高预测的可靠性与准确性

Innovation: 
我们提出了STFT-VNNGP，一种混合架构，通过两个阶段过程解决这些挑战。第一阶段使用TFT捕捉复杂的时空动态生成多分位数预测。第二阶段使用变异最近邻高斯过程（VNNGP）进行原则性的时空平滑和不确定性量化。这种方法在中东和美国冲突动态的案例研究中表现优异，特别是在远程预测中的突发事件时间与幅度预测上，显著优于单独的TFT模型

Conclusion: 
我们提供了一个用于生成更具可靠性和行动性的从挑战性事件数据中生成情报的稳健框架。该模型在地缘政治冲突的预测上表现出了明显的优势，并且所有代码和工作流程均公开以确保可再现性&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20935</guid><pubDate>Fri, 27 Jun 2025 02:43:58 +0800</pubDate></item><item><title>144. cs.LG-赋能数字农业：一种保护隐私的数据共享与协作研究框架</title><link>https://arxiv.org/pdf/2506.20872</link><description>Background: 
数据驱动农业通过整合技术和数据到农业生产中，有着提高农作物产量、抗病性以及长期土壤健康等方面的潜力。然而，数据隐私问题，如负面定价、歧视和资源操纵，阻止了农民分享数据，因为这些数据可能被用来伤害他们。为了解决这一障碍，本研究提出了一种保护隐私的框架，旨在安全地进行数据共享和合作研发，同时减轻隐私风险。该框架使用主成分分析等降维技术和差分隐私（引入拉普拉斯噪声保护敏感信息）来平衡数据共享与隐私保护之间的关系。该框架允许研究人员识别潜在的合作对象，基于被识别的合作对象的数据训练个人化的机器学习模型，或者直接在聚合的隐私保护数据上进行模型训练。农民也可以基于相似性识别潜在的合作对象。通过实验验证，该框架在促进农业数据的责任使用方面具有强大的隐私保护能力和与集中系统相当的实用性表现。

Innovation: 
本研究提出了一种融合降维技术和差分隐私的保护隐私框架，它能够在保护农民隐私的同时促进安全的数据共享和合作研究，这对于提高农业数据的效益使用和促进创新具有重要意义。该框架的创新点在于结合了数据降维方法和差分隐私技术，既保护了农民的隐私，又保证了数据的有效利用，为数据驱动的农业提供了新的解决方案。它允许研究人员和农民更安全地共享数据并发现潜在的合作机会，从而推动农业研究的发展。此外，该框架还能够抵抗对抗性攻击，确保数据的有效性。

Conclusion: 
本研究提出的数据共享和协作研究的保护隐私框架能够促进农业数据的安全整合，支持创新和可持续农业系统的建设，对于推动数据驱动农业的变革性进步具有重要意义。通过解决关键的隐私挑战，本工作支持了数据的可持续利用和创新，为农业系统的改进和进步提供了坚实的技术基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20872</guid><pubDate>Fri, 27 Jun 2025 02:43:57 +0800</pubDate></item><item><title>145. cs.LG-基于流形高斯过程回归的主动学习</title><link>https://arxiv.org/pdf/2506.20928</link><description>Background: 
本文介绍了一种结合流形学习和战略数据选择的流形高斯过程（GP）回归的主动学习框架。该框架旨在通过提高高维空间中的准确度来弥补传统高斯过程回放缓存数据维度大的问题。它利用神经网络进行维度减少，并在潜在空间中监督高斯过程回归器，通过最小化全局预测误差来优化。实验结果表明，与随机顺序学习相比，该方法具有更好的性能，并能有效处理复杂、不连续的函数，同时保持计算的可行性，适用于科学和工程领域的实际应用。

Innovation: 
本文提出的方法结合了流形学习和神经网络减少维度，通过主动学习准则（最小化全局预测误差）协同优化神经网络和高斯过程回归器。这种方法能够有效地处理复杂和不连续的函数，同时保持良好的计算效率，优于随机顺序学习方法。

Conclusion: 
这种方法为科学和工程应用提供了实用价值，并未来将重点研究该框架的可扩展性和不确定性的流形学习。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20928</guid><pubDate>Fri, 27 Jun 2025 02:43:57 +0800</pubDate></item><item><title>146. cs.LG-通过不确定的人工指导的强化学习进行复杂模型转换</title><link>https://arxiv.org/pdf/2506.20883</link><description>Background: 
模型驱动工程中常常需要复杂的模型转换（MTs），这些转换可能涉及多个步骤。常见的例子包括模型同步、自动化模型修复和设计空间探索。手动开发复杂的MTs是一个出错率高的过程，并且通常不切实际。强化学习（RL）是一种缓解这些问题的有效方法。然而，当问题变得复杂时，RL方法会遇到性能问题，此时人类指导的投入会很有帮助。这一研究提出了一种结合可能不确定的人类指导的RL方法来开发复杂的MT序列的方法和技术框架。用户定义的MT可以映射到RL的基本单元上，执行为RL程序以找到最优的MT序列。研究结果表明，即使人类指导不大确定，它也能显著提高RL的性能，并更高效地开发复杂的MTs。

Innovation: 
该论文提出了一种方法和技术框架，用于通过结合可能不确定的人类指导的强化学习来开发复杂的模型转换序列。该方法允许用户定义的模型转换映射到RL的基本单元上，并作为RL程序执行，最终找到最优的模型转换序列。这种方法通过人类指导和RL的结合，在开发复杂模型转换方面迈出了一步，并证明了即使人类指导存在不确定性，也能显著提高RL的性能和发展效率。

Conclusion: 
该研究展示了即使人类指导存在不确定性，也能通过人类指导适度提升强化学习性能，并更高效地开发复杂的模型转换。通过在人类建议的确定性与及时性之间进行权衡，这种方法朝着强化学习驱动的人工智能参与工程方法迈进了一步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20883</guid><pubDate>Fri, 27 Jun 2025 02:43:54 +0800</pubDate></item><item><title>147. cs.LG-用于合成孔径雷达干涉测相复原的尖峰神经网络：能源高效处理的理论框架</title><link>https://arxiv.org/pdf/2506.20782</link><description>Background: 
尽管尖峰神经网络（SNNs）和合成孔径雷达（SAR）干涉测量领域的研究都很深入，但是从未有SNNs被应用于相位解包过程。随着地球观测数据量的指数级增长，能源高效的处理方法成为了可持续数据中心运行的关键。SNNs因其事件驱动的计算模型，在提高能效的同时能保持与传统方法相当的准确度。

Innovation: 
开发了专门针对包裹相数据的尖峰编码方案，提出了利用相位解包的空间传播性质的SNN架构，并进行了计算复杂性和收敛性的理论分析。证明了SNNs中的时间动态性质能够自然地建模相位解包过程中至关重要的空间连续约束。这项工作开创了一条神经形态计算与SAR干涉测量交叉领域的研究方向，提供了一种不同于现有算法的补充方法，有可能促进更可持续的大规模InSAR处理。

Conclusion: 
本研究提出了针对SAR干涉测量的相位解包问题建立尖峰神经网络（SNNs）理论框架的方法，证明了SNNs在提升处理能效、保持精度的同时，能够自然地解决相位解包的关键问题，为这一领域提供了新的研究方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20782</guid><pubDate>Fri, 27 Jun 2025 02:43:47 +0800</pubDate></item><item><title>148. cs.LG-通过验证与适应进行结构系统识别</title><link>https://arxiv.org/pdf/2506.20799</link><description>Background: 
从实验数据中估计管理方程参数值对于将实验数据与科学理论相结合，理解、验证和预测复杂系统的动态至关重要。本文旨在提出一种新的方法，从数据中直接进行结构系统识别（SI）、不确定性量化和验证。这种方法受到生成建模框架的启发，使用神经网络将随机噪声映射到物理上有意义的参数，这些参数随后用于已知的运动方程中以获得假定的加速度，这些加速度通过均方误差损失与实际训练数据进行比较。为了同时验证所学的参数，使用独立的验证数据集。来自这些数据集生成的加速度会通过鉴别网络进行评估，该网络可以判断输出是真实数据还是假数据，并引导参数生成器网络的参数调整过程.

Innovation: 
该研究提出了一种新的基于数据的方法，用于结构系统识别、不确定性量化和验证。该方法基于生成建模框架，通过神经网络将随机噪声映射到物理上有意义的参数，这些参数然后用于已知的运动方程中以生成假定的加速度。鉴别网络用于验证这些生成的加速度的真实性和指导参数生成器网络的过程。这种方法的关键创新在于同时通过独立的验证数据集来验证学习到的参数，并通过生成的和实际的加速度对比来增强参数估计的准确性和模型验证的有效性.

Conclusion: 
该研究展示了此方法在不同非线性结构系统中的参数估计准确性和模型验证效果。通过实际和分析实验表明了该方法的有效性，该框架为理解和预测复杂系统的动态提供了一种新的思路和技术手段。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20799</guid><pubDate>Fri, 27 Jun 2025 02:43:47 +0800</pubDate></item><item><title>149. cs.LG-Temporal Fusion Transformers对径流模拟的有效性</title><link>https://arxiv.org/pdf/2506.20831</link><description>Background: 
在序列建模中，结合注意力机制和循环机制已被证明对包括水文预测在内的任务有益。本文的研究背景是探讨在径流模拟中，使用Temporal Fusion Transformers (TFTs) 模型相较于Long Short-Term Memory (LSTM) 网络的相对优势，特别是在美国的531个CAMELS流域，以及来自Caravan数据集中不同区域（美国，澳大利亚，巴西，英国，智利）的子集数据中进行对比实验。

Innovation: 
文章的创新点在于使用TFTs模型在径流模拟中的应用，并通过与LSTM模型的对比突出TFTs的优势。研究发现TFTs在模拟径流图的中部和峰值方面表现略优于LSTM。同时，TFTs能够更好地处理较长序列数据，对于较大或更多的流域可能更为适合。此外，通过TFTs的可解释性特点，可以识别出关键的动态和静态变量，提供宝贵的研究见解。

Conclusion: 
研究结果表明TFTs在径流模拟方面具有潜力，特别是在提高模型性能和科学理解方面的贡献。然而，TFTs和LSTM在Caravan数据集上的表现下降表明可能存在问题的数据质量。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20831</guid><pubDate>Fri, 27 Jun 2025 02:43:45 +0800</pubDate></item><item><title>150. cs.LG-ReLU神经网络的稳定局部最小值遭受维度诅咒：神经破碎现象</title><link>https://arxiv.org/pdf/2506.20779</link><description>Background: 
该研究探讨了平坦解或低损失曲率在两层过参数化ReLU网络中的隐式偏置及其对泛化的效应，特别是在多变量输入时的情况。现有研究要么需要插值，要么仅集中在单变量输入上。这项工作填补了这一空白，专注于多变量输入情况下的新理论成果，特别是在最小值稳定性及梯度下降训练中的边缘稳定性现象下，探讨了泛化能力不随输入维度增加而降级的现象。研究者认为，虽然平坦解和低余量解都可能改进泛化能力，但随着输入维度的增加，平坦解在收敛率上会以指数级方式劣化，这是因为激活较少但权重较大的神经元带来的“神经破碎效应”。

Innovation: 
该研究首次确定并证明了在多变量输入情况下，虽然平坦解和低余量解都能改善泛化能力，但平坦解的收敛率会随输入维度增加以指数级方式劣化。通过一种基于边界局部化ReLU神经元的新包装论证，推导出了一种“神经破碎效应”，解释了为何平坦解在高维空间中的表现会变差。此外，该研究通过广泛的数值模拟证实了理论发现，并首次系统地解释了为何平坦局部最小值在高维空间中可能会泛化不足的原因。

Conclusion: 
研究表明，平坦解在高维空间中存在泛化性能较差的问题，而低余量解则不受维度诅咒的影响。尽管具有与平坦解相似的稳定性，低余量解在高维空间中的泛化能力却更好，这提供了一种新的视角来理解如何选择和优化神经网络模型中的局部最小值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20779</guid><pubDate>Fri, 27 Jun 2025 02:43:45 +0800</pubDate></item><item><title>151. cs.LG-为混合专家模型提供实用驱动的推测性解码</title><link>https://arxiv.org/pdf/2506.20675</link><description>Background: 
GPU 内存带宽是低延迟大型语言模型推理的主要瓶颈。推测性解码通过使用一个轻量级的先行者来提出 K 个令牌，然后由大型语言模型并行验证以提升令牌吞吐量。在传统的密集型大型语言模型中，每次迭代都会获取所有模型权重，因此推测性解码不会增加延迟开销。但是新兴的混合专家（MoE）模型每次只激活一小部分权重，极大地减少了数据移动量。然而，研究表明，对于 MoE 模型，推测性解码无效，因为先行者激活的权重总的计算量更多，增加了数据移动时间和验证时间，提升了 2-3 倍。当流量收益无法抵消这种开销时，推测性解码会导致最多 1.5 倍的减速，使其变得不可行。即使在有用的场景下，最佳 K 的选择也会因任务、模型以及请求和迭代的不同而各不相同。因此，尽管在密集型大型语言模型中广泛应用，推测性解码在领先 MoE 模型中仍不实用。

Innovation: 
Cascade 提出了一种实用驱动的框架，可以在避免减速的同时选择性地启用推测性解码，并动态调整 K 的值以加速 MoE 服务。Cascade 使用了一个轻量级的指标——推测性解码的效用，即令牌收益与验证成本的比率，显示了迭代级别上的局部性，通过短的测试阶段和更长的一系列测试阶段，使周期性决策成为可能。对于每个请求，如果测试期间效用低于1，则禁用推测性解码，否则测试多个 K 值以选择效用最大化的 K。我们在 vLLM 中实现了 Cascade，并在涵盖代码、数学、提取和混合任务的工作负载中评估了五个流行的 MoE 模型。结果表明，与静态 K 相比，Cascade 可将减速限制在 5%，并且提高了 7-14% 的吞吐量，使推测性解码在 MoE 中变得实用。

Conclusion: 
尽管推测性解码在传统的大型语言模型中非常有效，但在 MoE 模型中却面临挑战。Cascade 提供了一种实用的方法，通过对 K 的动态调整来避免减速并提升性能，这使推测性解码在这些先进模型中成为可能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20675</guid><pubDate>Fri, 27 Jun 2025 02:43:42 +0800</pubDate></item><item><title>152. cs.LG-scMamba: 一个超越高变特征选择的大规模单细胞多组学集成可扩展基础模型</title><link>https://arxiv.org/pdf/2506.20697</link><description>Background: 
单细胞多组学技术的进步使得能够同时在单个细胞中解析各种组学层。集成这些多模态数据提供了对细胞身份、调控过程和疾病机制前所未有的见解。然而，当前的方法常需要在预处理阶段选择高变基因或峰，这可能会意外地丢弃重要的生物学信息。因此，处理单细胞多组学数据存在挑战。传统的单细胞方法依赖于特定的特征选择，这限制了其功能多样性，无法充分利用所有生物信息。

Innovation: 
scMamba 引入了一种基于补丁的细胞标记策略，将基因组区域视为词语（标记）和细胞视为句子，利用状态空间二元组的概念，从高维稀疏的单细胞多组学数据中提炼丰富的生物学洞察。此外，scMamba 的新颖对比学习方法添加余弦相似度正则化，能够比传统方法在跨组学层对齐方面取得更好的效果。系统基准测试跨多个数据集表明，scMamba 在保持生物变异性和跨组学层对齐方面显著优于现有最先进的方法，并且能够在关键下游任务中（如聚类、细胞类型注释和轨迹推理）增强表现。

Conclusion: 
我们的研究结果将 scMamba 定位为大规模单细胞多组学集成的强大工具，能够处理大规模图谱并促进生物发现。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20697</guid><pubDate>Fri, 27 Jun 2025 02:43:40 +0800</pubDate></item><item><title>153. cs.LG-监督学习中神经偏微分方程的控制与优化</title><link>https://arxiv.org/pdf/2506.20764</link><description>Background: 
关于抛物型和双曲系统控制与优化问题的研究已经有大量的文献，但尚未彻底探讨如何控制并优化这些系统中相关算子的系数。本文旨在开启控制理论的研究方向，关注于优化和控制这些算子的系数，这在神经网络和监督学习的背景下自然处于核心地位。从监督学习的角度来看，传统上在常微分方程（ODEs）背景下研究的控制问题被重新构想为偏微分方程（PDEs）背景下的控制问题，特别是涉及抛物型和双曲型算子系数的优化与控制问题。

Innovation: 
本文提出了一个针对抛物型PDEs控制与优化问题的对偶系统表述，为未来研究中高效的数值方案开发奠定了基础。同时，证明了抛物型PDEs的控制与优化问题存在极小解。此外，还探究了与双曲型PDEs相关的控制问题，并证明了相应逼近控制问题的解的存在性。

Conclusion: 
本文通过提出对偶系统表述为抛物型PDEs的控制与优化问题提供了理论依据，并证明了该问题存在极小解。未来的研究将致力于发展高效的数值算法来解决这些问题，并进一步探索双曲型PDEs的控制问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20764</guid><pubDate>Fri, 27 Jun 2025 02:43:37 +0800</pubDate></item><item><title>154. cs.LG-LLM预训练中grokking的发现：无需测试监控记忆到泛化的转换</title><link>https://arxiv.org/pdf/2506.21551</link><description>Background: 
grokking现象在神经网络训练中被观察到，即测试性能在训练损失收敛后仍持续提升，这使得泛化机制和其他新兴能力如推理变得神秘。先前的研究通常在数千个周期内训练小型模型来处理少量或高度特定的任务。本研究首次在预训练7B大语言模型（OLMoE）过程中检查检查点时，验证了此类大型基础模型的预训练期间仍会发生grokking现象，尽管不同数据可能在不同时间进入grokking阶段。研究深入探讨了LLM内部动力学，发现了训练样本路径（各层专家选择）在grokking过程中从随机、特定实例演变为更具结构性和共享性的过程，尽管损失已收敛，样本路径的复杂性也有所降低，这表明了记忆到泛化的转换，从而提供了延迟泛化的机制解释。研究开发了两个新的度量标准来量化路径距离和单个路径的复杂性，并展示了它们预测下任务泛化提升的能力，这些度量标准效率高、易于计算且仅依赖于训练数据，因此在预训练中具有实际价值，可以不依赖微调和测试来监控泛化性能。理论上，研究表明更具结构化的路径可降低模型复杂度、改善泛化界线.

Innovation: 
首次在大型基础模型的预训练过程中探索grokking现象，发现大型语言模型的预训练过程中仍然存在记忆到泛化的转换现象；开发了两个新度量标准来量化路径距离和路径复杂性，且在预训练中不依赖于微调和测试即能监控泛化性能；揭示了训练样本路径的结构化演变过程，表明了记忆到泛化的转换，为延迟泛化的机制提供了解释；理论上证明了具有结构化路径的样本有助于减少模型复杂性和提高泛化性能，从而提升了泛化界线.

Conclusion: 
研究表明，大型语言模型的预训练过程中确实存在grokking现象，且不依赖于微调和测试就可以通过监测特定度量标准来有效评估和监控模型的泛化性能，从而为预训练带来了实际价值。同时，研究揭示了训练样本路径的结构化演变机制，有助于理解记忆到泛化的机制，并从理论上证实了结构化路径在改善模型泛化性能方面的积极作用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21551</guid><pubDate>Fri, 27 Jun 2025 02:43:35 +0800</pubDate></item><item><title>155. cs.LG-使用多模态机器学习在瑞典人群中检测二元互动中的欺骗：一项研究</title><link>https://arxiv.org/pdf/2506.21429</link><description>Background: 
该研究探讨了使用多模式机器学习技术检测二元互动中的欺骗效果，重点研究了来自欺骗者和被欺骗者的数据集成。研究利用语音和视频数据（具体包括动作单元和瞳孔信息）进行了多种可能的模态和参与者组合分析。数据集来自于瑞典原住民在情感相关话题上进行真相或谎言情境的新收集的数据集。研究结果表明，结合言语和面部信息的表现优于单一模态方法。此外，包含两个参与者的数据显著提高了欺骗检测的准确性，采用晚期融合策略应用于两种模态和参与者时，性能最佳（71%）。这些发现与心理理论相吻合，表明在初始互动中面部和语音表情的控制存在差异。作为首个针对斯堪的纳维亚人群的研究，这项研究为进一步探讨二元互动，特别是心理治疗环境中的研究奠定了基础。

Innovation: 
该研究采用的新颖之处在于：1) 利用多模式机器学习技术进行欺骗检测；2) 同时分析欺骗者和被欺骗者的数据；3) 通过不同融合策略和模态组合测试，得出最佳性能结果；4) 扩展至实际情景，如情感相关话题的谎言或真相情境；5) 为第一项针对斯堪的纳维亚人群的此类研究，填补了空白领域。

Conclusion: 
本研究通过新的模态融合策略，证明了结合言语和面部信息在检测欺骗方面优于单一模态方法，并显著提高了欺骗检测的准确性。特别是在应用晚期融合策略并涉及两个参与者时，准确率达到71%，验证了在初始互动中面部和语音表情控制差异的理论。该研究为未来在二元互动中的研究，特别是心理治疗领域，提供了新的视角和数据支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21429</guid><pubDate>Fri, 27 Jun 2025 02:43:32 +0800</pubDate></item><item><title>156. cs.LG-MegaFold：加速蛋白质结构预测模型的系统级优化</title><link>https://arxiv.org/pdf/2506.20686</link><description>Background: 
蛋白质结构预测模型如AlphaFold3（AF3）通过在transformer架构中纳入基于科学的架构更改，推动了生物分子建模的前沿。然而，这些进步带来了高昂的系统成本，包括计算和内存密集型操作、2D注意力机制以及检索增强的数据管道，这些共同妨碍了AF3训练的可伸缩性。

Innovation: 
MegaFold是一个跨平台系统，通过提前缓存来消除检索增强的数据管道中的GPU闲置时间，使用Triton内核实现异构设备上的内存高效EvoAttention，以及针对AF3中常见和关键的小操作的深度融合，加速了AF3训练。评估结果显示，使用MegaFold可以将AF3培训的峰值内存使用减少多达1.23倍，并且每次迭代的培训时间分别提高到1.73倍和1.62倍。此外，MegaFold使得可以在PyTorch基线不受内存溢出的情况下训练更长的序列长度，极大地提高了现代蛋白质折叠模型的可扩展性。

Conclusion: 
MegaFold通过系统级优化提升了蛋白质结构预测模型的训练速度，显著提高了现代蛋白质折叠模型的可扩展性，允许训练更长的序列长度，而不会出现内存溢出。其开源代码可以在指定的URL访问。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20686</guid><pubDate>Fri, 27 Jun 2025 02:43:32 +0800</pubDate></item><item><title>157. cs.LG-Transfer disentangled representations: 桥接合成图像与真实图像之间的差距</title><link>https://arxiv.org/pdf/2409.18017</link><description>Background: 
在表示学习中，开发有意义且高效的表示，以区分数据生成机制的基本结构是至关重要的。然而，在实际图像上的解纠缠表示学习尚未充分展示其潜力，这主要是由于生成因素相关性、其分辨率限制以及获取真实标签的有限性所导致的。特别是这个问题上，研究讨论了利用合成数据学习适用于真实数据的通用解纠缠表示的可能性，以及这些表示是否能在转移过程中保留解纠缠的属性。为了应对这些问题，作者进行了详尽的实验研究，并提出了一个新的可解释的基于干预的度量标准来衡量表示中因素编码的质量。研究表明，在某种程度上，从合成数据向真实数据转移解纠缠表示是可行且有效的。

Innovation: 
本文提出了一种新的可解释的基于干预的度量标准来衡量表示中因素编码的质量，并进行了详尽的实证研究，表明从合成数据到真实数据的解纠缠表示转移是可行且有效的。

Conclusion: 
研究表明，一定程度上从合成数据转移至真实数据的解纠缠表示是可行且有效的,并通过提出的新的度量标准有效地衡量了这些表示的质量。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.18017</guid><pubDate>Fri, 27 Jun 2025 02:43:30 +0800</pubDate></item><item><title>158. cs.LG-U-R-VEDA: 将UNet、残差链接、边缘检测和双注意力机制及视觉变换器集成以实现精确的心脏磁共振图像语义分割</title><link>https://arxiv.org/pdf/2506.20689</link><description>Background: 
人工智能和深度学习模型将在自动医疗图像分析和心脏疾病诊断及其管理中发挥变革性作用，其中准确的自动心肌梗塞图像分割是量化和自动诊断心脏疾病的第一步必要步骤。现有的大多数模型在边缘检测和语义分割方面还存在信息损失和准确性不足的问题。

Innovation: 
本文提出了一种基于深度学习模型的增强UNet，即U-R-Veda模型，该模型集成了卷积变换、视觉变换器、残差链接、通道注意力和空间注意力，并结合边缘检测基的跳跃连接，用于心脏磁共振（CMR）图像的精确全自动语义分割。该模型通过组合卷积块、嵌入通道和空间注意力，以及视觉变换器，提取局部特征及其相互关系，显著减少了卷积变换过程中的信息损失，提高了CMR图像的语义分割精度，特别是在心室分割方面表现出色。

Conclusion: 
U-R-Veda模型在DSC和HD指标上实现了95.2%的平均准确率，显著优于其他模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20689</guid><pubDate>Fri, 27 Jun 2025 02:43:29 +0800</pubDate></item><item><title>159. cs.LG-《 hitchhiker's 问题最终解决方案 》</title><link>https://arxiv.org/pdf/2506.20672</link><description>Background: 
J.J. Arias-Garcıa, R. Mesiar, and B. De Baets 在2020年的《模糊集与系统》杂志上发表的一篇文章，以其绰号‘搭便车指南’引起了对半copula问题的研究。虽然半copula缺乏统计解读，但在依赖建模社区提升了其关注度。之前的工作中，作者通过线性规划的方法解决了‘搭便车指南’中提出的极端值问题，直到17维度，并反驳了一个最近提出的猜想。在此基础上，本文使用分析方法提供了一个完全的答案。

Innovation: 
使用分析方法提供了一个完全解答关于半copula极端值的问题，解决了‘搭便车指南’中提出的公开问题Open Problem 5，并通过线性规划的方法达到了17维度的解决方案，反驳了一个最近提出的猜想。

Conclusion: 
通过对半copula极端值问题的分析研究，给出了问题的最终解决方案，并通过线性规划和分析方法证明了问题的具体答案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20672</guid><pubDate>Fri, 27 Jun 2025 02:43:27 +0800</pubDate></item><item><title>160. cs.LG-基于流的单步完成策略以实现高效的策略学习</title><link>https://arxiv.org/pdf/2506.21427</link><description>Background: 
生成模型如扩散和流匹配在离线强化学习中提供了表达性强的策略，通过捕捉丰富的多模态动作分布。然而，它们的迭代采样会引入高推理成本和由于梯度传播导致的训练不稳定性。这些模型通过流和模式匹配捕捉丰富的多模态动作分布，但在离线强化学习中由于多步迭代采样的梯度传播问题，导致推理成本高和训练不稳定。

Innovation: 
本文提出了一种名为单步完成策略 (SSCP) 的生成性策略，该策略通过一个增强的流匹配目标训练，从中间流样本直接预测完成向量，从而实现准确的单步动作生成。该方法将生成性模型的表达性和单模态策略的训练与推理效率结合在一起，无需长时间回传链，适用于离线、离线转在线和在线强化学习场景，显著提高了速度和适应性，与基于扩散的基线相比实现较大改进。此外，将SSCP扩展到有目标条件的强化学习中，使扁平策略能够利用子目标结构而不显式采用分层推理，从而实现更好的性能。

Conclusion: 
SSCP在标准离线强化学习和行为克隆基准测试中表现出色，将其定位为用于深度强化学习和序列决策的高度灵活、表达性强且高效的框架。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21427</guid><pubDate>Fri, 27 Jun 2025 02:43:22 +0800</pubDate></item><item><title>161. cs.LG-mTSBench: 大规模评估多元时间序列异常检测与模型选择</title><link>https://arxiv.org/pdf/2506.21550</link><description>Background: 
多元时间序列异常检测（MTS-AD）在医疗保健、网络安全和工业监控等领域至关重要，但由于复杂的时间序列间依赖关系、时间动态性和稀疏的异常标签，该领域仍存在挑战。

Innovation: 
介绍了mTSBench，这是迄今为止最大的MTS-AD和无监督模型选择基准，覆盖了344个标记的时间序列、19个数据集以及12个不同的应用领域，包含了24种异常检测方法，包括基于大型语言模型的多元时间序列检测器，以及系统性地在标准化条件下评估无监督模型选择技术。

Conclusion: 
本研究结果表明，没有一种检测器能够在所有数据集上表现出色，这突显了模型选择的重要性。尽管最先进的选择方法仍然离最优解决方案有较大差距，揭示了关键缺口。mTSBench提供了一个统一的评估套件，可以促进严格的、可重复的比较，并推动未来适应性异常检测和鲁棒模型选择的发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21550</guid><pubDate>Fri, 27 Jun 2025 02:43:20 +0800</pubDate></item><item><title>162. cs.LG-优化4阶Runge-Kutta方法：一种提高效率和低存储的动态启发式方法</title><link>https://arxiv.org/pdf/2506.21465</link><description>Background: 
扩展稳定性Runge-Kutta (ESRK) 方法在气象预报、空气动力学分析和复杂生物建模等科学和工程问题的大规模计算中至关重要。然而，平衡准确度、稳定性和计算效率仍然充满挑战，尤其是在高阶、低存储方案中。

Innovation: 
该研究提出了一种结合遗传算法（GA）和强化学习（RL）的混合方法，用于自动化启发式的发现与优化，特别针对低存储ESRK方法。此方法利用GA进行搜索空间探索，并通过RL启发式状态过渡机制动态优化启发式选择，从而系统地减少参数，同时显著提高计算效率，保持四阶精度。通过对基准问题（包括1D和2D布鲁塞尔反应扩散系统以及稳定态纳维-斯托克斯方程）的严格测试，验证了提出的GA-RL启发式优化框架的有效性。

Conclusion: 
研究发现，这种自适应启发式方法在高性能模拟中有可能提高资源效率，并扩展低存储Runge-Kutta方法在真实世界计算流体动力学、物理模拟和其他高要求领域的应用。该研究为数值方法的启发式优化建立了新的范式，并为使用深度RL和自动机器学习（AutoML）进行启发式搜索探索开启了新的途径。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21465</guid><pubDate>Fri, 27 Jun 2025 02:43:19 +0800</pubDate></item><item><title>163. cs.LG-基于过程挖掘的建模与仿真以增强Cyber-Physical系统故障诊断</title><link>https://arxiv.org/pdf/2506.21502</link><description>Background: 
在Cyber-Physical系统（CPS）中，故障诊断对于保证系统可靠性和运营效率是至关重要的，因为它需要准确地检测异常并识别其根本原因。然而，手动建模故障行为往往需要大量的专业知识，并且生成的模型复杂、易出错且难以解释。目前的方法存在诸多挑战，如模型的复杂性和难以解释性等问题。因此，迫切需要一种能够有效支持故障诊断的新方法。

Innovation: 
本文提出了一种新颖的无监督故障诊断方法，该方法结合了多维时间序列异常检测、过程挖掘和随机仿真。首先，低级传感器数据中的集体异常通过多维时间序列分析检测出来。然后，这些异常被转换为结构化的事件日志，使通过过程挖掘发现可解释的过程模型成为可能。通过将时间分布融入提取的佩特里网中，方法支持了故障行为的随机仿真，从而增强了根本原因分析和行为理解。这种方法通过使用Robotic Arm Dataset（RoAD）进行了验证，认为该方法在模式建模、仿真和故障行为分类方面是有效的。

Conclusion: 
该方法能够为CPS创建全面的故障字典，支持预测性维护，并开发工业环境中的数字双胞胎。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21502</guid><pubDate>Fri, 27 Jun 2025 02:43:18 +0800</pubDate></item><item><title>164. cs.LG-为特兰格尔州的癌症意识问题提出解决方案</title><link>https://arxiv.org/pdf/2506.21500</link><description>Background: 
2020年，在特兰格尔州接受宫颈癌、乳腺癌和口腔癌筛查的人口比例分别为3.3%、0.3%和2.3%。尽管早期检测是降低发病率和死亡率的唯一途径，但人们对宫颈癌和乳腺癌的症状、筛查实践知之甚少。

Innovation: 
开发了基于机器学习的分类模型来预测个体是否对乳腺或宫颈癌易感，并根据用户地理位置或地址提供最近的医院或癌症治疗中心的建议。此外，可以整合健康卡以维护所有个人的医疗记录，并开展健康意识宣传和活动。对于机器学习分类模型，分别使用了决策树分类算法和支持向量分类算法来预测宫颈癌和乳腺癌的易感性。

Conclusion: 
通过提出这一解决方案，我们更接近于我们设定的目标，即提高癌症意识，从而降低癌症死亡率，提高特兰格尔州人民的癌症知识水平。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21500</guid><pubDate>Fri, 27 Jun 2025 02:43:18 +0800</pubDate></item><item><title>165. cs.LG-基于关键词的技术评价宽泛问题答案脚本</title><link>https://arxiv.org/pdf/2506.21461</link><description>Background: 
评价是对教育体系进行评估和确定的方法，涉及口头或口试测试、主观或客观书面测试。本文提出了一种有效的解决方案，用于电子评估主观答案脚本。传统的评估方法依赖于人工评分，速度慢且容易出错，而文中系统通过关键词提取和领域关键词比对识别和评估书面答案脚本，并检查答案脚本中的语法和拼写错误，旨在提供一种自动化的评价方式来提高效率和准确性。

Innovation: 
本文提出了一种基于关键词的系统，用于自动评估主观答案脚本。该系统首先从答案脚本中提取关键词，然后将这些关键词与从开放和封闭领域提取的关键词进行比较。此外，系统还检查答案脚本中的语法和拼写错误。这种基于关键词的技术创新有助于实现自动化的答案评估，提高了效率和准确性。

Conclusion: 
利用提出的基于关键词的系统对学生(共100名)的主观答案脚本进行了测试，结果表明该系统具有较高的精度，得分为0.91。该研究展示了自动评估主观答案脚本是可能的，为教育评估领域引入了新的技术手段。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21461</guid><pubDate>Fri, 27 Jun 2025 02:43:18 +0800</pubDate></item><item><title>166. cs.LG-从最优控制视角探讨ResNet训练</title><link>https://arxiv.org/pdf/2506.21453</link><description>Background: 
本文提出了一个反映最优控制问题的ResNets训练公式，适用于标准架构和一般损失函数。通过惩罚隐藏状态中间输出并将其与最优控制中的阶段成本项对应，将深度学习训练与最优控制理论相结合。标准ResNets通过传播状态并通过后续跳连接和输出层获得中间输出。研究表明，这种训练动态会促使不必要的更深残差层的权重逐渐消失，为基于理论的层剪枝策略提供了可能。

Innovation: 
提出了一种基于最优控制问题的ResNets训练公式，通过惩罚隐藏状态的中间输出来连接深度学习与最优控制领域，并显示了这种方法能够促使不必要的更深残差层权重逐渐消失，为理论指导下的层剪枝策略提供了可能性。

Conclusion: 
我们的训练动态机制成功地将标准ResNets训练与最优控制理论相结合，展示了通过一种基于理论的方式偏重深度网络层数，为实现有效的神经网络优化策略奠定了基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21453</guid><pubDate>Fri, 27 Jun 2025 02:43:13 +0800</pubDate></item><item><title>167. cs.LG-Scalaable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference</title><link>https://arxiv.org/pdf/2506.21408</link><description>Background: 
尽管大型语言模型（LLM）在广泛应用中，但它们能够产生错误信息并缺乏校准性，这使得对这些模型的不确定性量化变得至关重要，特别是在自动驾驶和医疗等高风险领域。先前的研究已经通过在微调模型的LoRA参数上进行推断来使贝叶斯深度学习方法更加适用，但是这些方法在扩展到更大的LLM时遇到困难，因为它们需要额外的参数。

Innovation: 
本文提出了一种名为ScalaBL（Scalable Bayesian Low-Rank Adaptation via Stochastic Variational Subspace Inference）的方法。通过在LoRA参数维度r的子空间中进行贝叶斯推断，并将这些参数重新用于投影矩阵，可以将子空间中的样本映射到LLM的整个权重空间，从而利用随机变分子空间推理学习模型的所有参数。与先前方法相比，ScalaBL仅需要大约1000个额外参数，并且能够扩展到迄今为止最大的贝叶斯LLM，参数量是之前工作的四倍。

Conclusion: 
ScalaBL能够在子空间低维度的同时，达到与最先进的方法相当的性能，同时还能够处理更大的模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21408</guid><pubDate>Fri, 27 Jun 2025 02:43:12 +0800</pubDate></item><item><title>168. cs.LG-分布式交叉通道分层聚合（D-CHAG）方法</title><link>https://arxiv.org/pdf/2506.21411</link><description>Background: 
基于视觉的科学基础模型在科学发现和创新中具有巨大潜力。这些模型能够整合来自不同来源的图像数据，如不同的物理基础或数据采集系统，并通过变压器架构学习时空相关性。然而，图像的分词和聚合计算密集型，在目前的分布式方法中并未完全解决这一问题。

Innovation: 
本文介绍了一种名为分布式交叉通道分层聚合（D-CHAG）的方法，适用于多通道图像数据集。该方法兼容任何模型并行策略和任何类型的视觉变压器架构，显著提高了计算效率。该方法已应用于高光谱成像和天气预报任务，与张量并行和模型分割集成后，在Frontier超级计算机上的1,024块AMD GPU上实现了高达75%的内存使用率减少和超过两倍的持续吞吐量提高。

Conclusion: 
D-CHAG 方法通过模型并行策略和技术优化，提高了处理多通道图像数据的效率，特别是在大规模高性能计算环境下的应用表现突出。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21411</guid><pubDate>Fri, 27 Jun 2025 02:43:08 +0800</pubDate></item><item><title>169. cs.LG-在一simplicial插入下的持久拉普拉斯特征值的Lipschitz界</title><link>https://arxiv.org/pdf/2506.21352</link><description>Background: 
持久拉普拉斯算子是用于追踪数据随尺度变化的几何和结构变换的矩阵运算符，广泛应用于生物学、物理学和机器学习。它们的特征值是用于描述过滤过程中几何和拓扑特征的简洁描述符。尽管先前的研究已经建立了这些运算符的全局代数稳定性，但一个简单的项（如顶点、边或三角形）被添加时单个特征值的具体变化情况仍然未知。这是因为在后续工具（如热核签名和光谱神经网络）中这些特征值直接起作用，这使得这一未知成为关键问题。本文通过证明一次插入元素后的特征值变化上的统一Lipschitz界，填补了这一空白。这意味着在插入一个简单项后，每个向上持续拉普拉斯特征值的最大变化最多为该简单项边界的欧几里得范数的两倍，与过滤尺度和复杂大小无关。这在光谱拓扑数据分析中首次提供了在特征值层面的鲁棒性保证，同时确保了在动态数据环境下频谱特征的稳定性，并促进了可靠误差控制的应用。

Innovation: 
本文首次证明了一次插入元素后，所有特征值的变化受到统一的Lipschitz界限制，此限制与过滤尺度及复杂大小无关，确保了在局部更新下的光谱特征稳定性，并提供了在动态数据环境下可靠误差控制的可能性，为光谱拓扑数据分析提供了首个特征值层面的鲁棒性保证。

Conclusion: 
本文通过证明一次插入元素后的Lipschitz界，首次从特征值层面提供了光谱拓扑数据分析的鲁棒性保证，确保了光谱特征在动态数据环境下的稳定性，并提供了可靠误差控制的基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21352</guid><pubDate>Fri, 27 Jun 2025 02:43:08 +0800</pubDate></item><item><title>170. cs.LG-早停表格式上下文学习</title><link>https://arxiv.org/pdf/2506.21387</link><description>Background: 
表格式基础模型在通过上下文学习处理各种表格式学习任务时表现出强大的性能，无需任何下游调整即可提供稳定的泛化能力。然而，它们的推理时间成本仍然很高，尤其是对于较大的数据集而言。

Innovation: 
提出了一种早停上下文学习过程的方法。通过在每个Transformer编码器层后动态评估是否应停止上下文学习，实现这一过程。一旦停止，使用预训练的逐层解码器解码嵌入。实验表明，在34个小分类任务上，早停上下文学习可以将推理加速1.3倍，预测性能几乎不受影响。在五个较大的分类任务上进一步评估，实现了最高2.2倍的加速。

Conclusion: 
结果表明，早退出策略具有提高表格式上下文学习效率的潜力，是一种有效且实用的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21387</guid><pubDate>Fri, 27 Jun 2025 02:43:06 +0800</pubDate></item><item><title>171. cs.LG-rQdia: 使用图像增强正则化Q值分布</title><link>https://arxiv.org/pdf/2506.21367</link><description>Background: 
在基于像素的深度强化学习中，直接从像素输入中学习状态表示和决策策略存在挑战。MuJoCo连续控制套件和Atari游戏环境中的任务评估了算法的表现。标准方法如DrQ和SAC以及Data-Efficient Rainbow算法已经展示了较好的性能，但在样本效率和长期训练表现上仍有改进空间。

Innovation: 
该论文提出了一种名为rQdia的方法，通过简单的辅助损失函数（MSE）来增强模型对Q值分布的控制。这种方法利用图像增强技术，改进了DrQ和SAC在MuJoCo连续控制套件中的9/12和10/12任务表现，同时提升了Data-Efficient Rainbow算法在18/26个Atari游戏中表现。rQdia不仅提高了样本效率，还增强了长期训练的有效性。此外，rQdia使得基于像素的无模型连续控制策略超过了基于状态编码的方法。

Conclusion: 
rQdia方法通过对Q值分布的正则化和利用图像增强技术，显著提升了基于像素的深度强化学习方法在MuJoCo和Atari环境中的样本效率和长期训练效果。这种方法已经在多个任务环境中显示出优于早期方法的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21367</guid><pubDate>Fri, 27 Jun 2025 02:43:06 +0800</pubDate></item><item><title>172. cs.LG-SMMILE: 由专家驱动的多模态医学上下文学习基准</title><link>https://arxiv.org/pdf/2506.21355</link><description>Background: 
尽管多模态在上下文学习（ICL）方面在医学领域具有巨大的潜力，但这一领域仍未得到充分探索。医疗专家经常需要从少量相关先前病例中获得见解，或者考虑一组受限的诊断差异，这些任务通常要求适应性。虽然多模态大型语言模型（MLLMs）已经在医学视觉问答（VQA）方面展示了一些进展，但在医学场景下的多模态任务学习能力尚不清楚。该文介绍了SMMILE，这是首个基于专家知识的多模态ICL基准，专注于医学领域，以及其增强版本SMMILE++，涵盖了11种医学专科和13种成像模态，通过严格评估，揭示了当前多模态大型语言模型在多模态医学任务上的局限性和偏差问题。

Innovation: 
该研究引入了SMMILE，这是首个基于专家知识驱动的多模态ICL基准，以及其增强版本SMMILE++。SMMILE包含111个由11名医学专家制定的问题，每个问题都有一个多模态查询和多模态上下文示例。此外，该研究对15个MLLMs进行了全面评估，指出大多数模型在医学任务上的多模态ICL能力较为有限。该研究还发现，不相关或噪声示例会显著降低模型性能，同时，示例的排列顺序也会影响模型性能，最相关示例的放置位置甚至可以大幅提升性能。这些发现强调了当前多模态大型语言模型在从上下文学习多模态医学任务时的局限性和偏差问题。

Conclusion: 
大多数多模态大型语言模型在医学任务中的多模态ICL能力有限，且容易受不相关示例的影响，示例的排列顺序也会影响最终性能。该研究强调了当前多模态大型语言模型需要解决的关键限制和偏差问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21355</guid><pubDate>Fri, 27 Jun 2025 02:43:06 +0800</pubDate></item><item><title>173. cs.LG-MAx-DNN：基于多级算术近似的能源高效DNN硬件加速器</title><link>https://arxiv.org/pdf/2506.21371</link><description>Background: 
近年来，深度神经网络（DNN）架构的快速发展使其成为提供高性能机器学习任务的有效方法。针对低功耗DNN计算的需求，本文探讨了DNN工作负载中细粒度的容错性和硬件近似技术的协同作用，以实现更高的能效。利用ROUP近似乘法器，我们在层、滤波器和核级上系统地考察了其在DNN中的分布，并研究了其对准确性和能耗的影响。我们使用ResNet-8模型在CIFAR-10数据集上评估了我们的近似方法。

Innovation: 
本文提出了基于多级算术近似的MAx-DNN（Multi-Level Arithmetic Approximation for Energy-Efficient DNN Hardware Accelerators），通过细粒度地分布ROUP近似乘法器，并且在不影响过多精度损失的情况下显著提高了能效。与基线量化模型相比，它在能耗方面可获得至多54%的提升，准确度下降最多4%；与最先进的DNN近似方法相比，它提供更好的准确性和2倍的能效提升。

Conclusion: 
本文提出的方法在不显著牺牲准确性的前提下，通过利用多级算术近似技术实现了显著的能效提升，为低功耗DNN计算提供了一种有效策略。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21371</guid><pubDate>Fri, 27 Jun 2025 02:43:05 +0800</pubDate></item><item><title>174. cs.LG-关注小型权重</title><link>https://arxiv.org/pdf/2506.21374</link><description>Background: 
微调大型预训练神经网络在内存和计算成本方面都十分耗资源。通常的做法是限制训练范围，仅针对模型的一部分参数。通过分析微调过程中梯度与权重的关系，我们发现一个显著模式：大的梯度通常与小幅度的权重相关联，这种关联在微调中比从头开始训练更为显著。

Innovation: 
我们提出了NANOADAM，这是一种在微调过程中动态更新只有小幅度权重的方法。NANOADAM具有几个主要优点：首先，这种方法是非梯度的，可以在不需要梯度计算的情况下确定参数子集；其次，这种方法保持了大幅度权重，这些权重很可能包含了在预训练过程中学到的重要特征，从而降低了灾难性遗忘的风险；第三，这种方法允许使用更大的学习率，且在实验中始终能实现更好的泛化性能。我们分别在NLP和视觉任务上展示了这一方法的效果。

Conclusion: 
NANOADAM提供了一种有效的方法，动态地更新只有小幅度权重，同时保持大幅度权重以实现更好的泛化性能，减少了微调过程中的资源消耗并降低了灾难性遗忘的风险。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21374</guid><pubDate>Fri, 27 Jun 2025 02:43:04 +0800</pubDate></item><item><title>175. cs.LG-currency-aware graph attention network for cryptocurrency transaction fraud detection</title><link>https://arxiv.org/pdf/2506.21382</link><description>Background: 
加密货币交易欺诈检测面临复杂交易模式和严重类别不平衡的双重挑战。传统方法依赖手动特征工程，难以捕捉交易网络中的时序和结构依赖性。

Innovation: 
该论文提出了一种增强时序感知图注意力网络(ATGAT)，通过以下三个模块增强欺诈检测性能：(1) 设计先进的时序嵌入模块，融合多尺度时间差特征与时序位置编码；(2) 构建时序感知三重注意力机制，共同优化结构、时序和全局上下文注意力；(3) 应用加权二元交叉熵损失来解决类别不平衡问题。实验证明，ATGAT在Elliptic++加密货币数据集上的AUC为0.9130，相较于传统的XGBoost提升了9.2%，相较于GCN提升了12.0%，相较于标准GAT提升了10.0%。

Conclusion: 
该方法不仅验证了时序感知和三重注意力机制对于图神经网络的增强效果，也为金融机构提供了更可靠的欺诈检测工具，其设计理念可推广至其他时序图异常检测任务。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21382</guid><pubDate>Fri, 27 Jun 2025 02:43:04 +0800</pubDate></item><item><title>176. cs.LG-AGTCNet: 基于图-时间方法的Motor Imagery EEG分类</title><link>https://arxiv.org/pdf/2506.21338</link><description>Background: 
脑-计算机接口 (BCI) 技术利用脑电图 (EEG) 标志着一种转变的创新，能够使运动受损个体平等地与环境互动。然而，开发受试者不变和会话不变的BCI系统仍面临重大挑战，因为个体间的神经活动复杂性和时间上的变化，以及EEG硬件的限制使得现有方法难以捕捉多通道EEG信号中的时空依赖性。在此之前的研究虽有尝试，但效果不佳。因此，本研究提出了一种名为AGTCNet的新颖图-时间模型，通过整合图卷积注意网络来联合学习高效的时空EEG表示，旨在解决这个问题，显著优于现有方法，提高了BCI系统的实际应用价值。

Innovation: 
引入AGTCNet模型，一种基于图-时间的新颖模型，利用EEG电极的拓扑配置作为归纳偏见，并结合图卷积注意力网络（GCAT）来学习时空EEG表示。该模型不仅在BCI Competition IV Dataset 2a上实现优于现有方法的表现，而且通过降低49.87%的模型大小、64.65%的推理速度以及更短的输入EEG信号，实现了表现的提升，进一步证明了其在BCI部署中的有效性与实用性。

Conclusion: 
AGTCNet模型在BCI Competition IV Dataset 2a和EEG Motor Movement/Imagery Dataset中实现的分类准确率进一步提升了82.88%和90.54%，说明了其在受试者不变和特定分类中的优势，并为BCI系统的发展提供了一种新的有效方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21338</guid><pubDate>Fri, 27 Jun 2025 02:42:59 +0800</pubDate></item><item><title>177. cs.LG-DynamicBench：评估大型语言模型的实时报告生成能力</title><link>https://arxiv.org/pdf/2506.21343</link><description>Background: 
传统的大规模语言模型评估基准通常依赖于静态评估，通过讲故事或表达意见，未能捕捉到现代应用中实时信息处理的动态需求。为此，需要一种新的基准来评估模型在存储和处理最新数据方面的熟练程度。n

Innovation: 
提出了DynamicBench基准，这是一种双路径检索管道的组合，结合了网络搜索和本地报告数据库。它需要特定领域的知识，以确保在特定领域生成准确的响应报告。此外，还引入了一个先进的报告生成系统，能够处理动态信息合成。实验结果表明，该方法在无文档和有文档辅助场景下分别比GPT4o高出7.0%和5.8%，取得了最先进的性能。n

Conclusion: 
DynamicBench有效地衡量了模型独立处理最近信息的能力或利用上下文增强。代码和数据将在公开基础上提供。n&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21343</guid><pubDate>Fri, 27 Jun 2025 02:42:59 +0800</pubDate></item><item><title>178. cs.LG-Latent Prototype Routing: 实现 Mixture-of-Experts 中的近完美负载均衡</title><link>https://arxiv.org/pdf/2506.21328</link><description>Background: 
混合专家（Mixture-of-Experts，MoE）架构已成为高效扩展大型语言模型（LLMs）的关键策略。然而，当前的MoE系统存在严重的负载不平衡问题，即在训练和推理过程中，只有少数专家始终被激活，这导致模型容量和计算资源的重大浪费。

Innovation: 
本文从聚类视角重新审视专家路由，并提出了一种新的路由框架—潜在原型路由（LPR），它不仅能够推广现有的方法，还能在不牺牲下游性能的情况下促进均衡的专家利用。实验结果表明，LPR能够将专家负载的基尼系数从0.70降低到0.035，并将最小最大专家负载比例从1e-6提高到0.70，从而实现近乎完美的负载平衡。

Conclusion: 
实验数据表明，LPR在多个开源MoE模型上取得了显著效果，有效实现了专家负载的平衡，提高了整体模型的性能和资源利用率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21328</guid><pubDate>Fri, 27 Jun 2025 02:42:57 +0800</pubDate></item><item><title>179. cs.LG-改进的 k-means 和 k-GMM 种植策略</title><link>https://arxiv.org/pdf/2506.21291</link><description>Background: 
本文重新审视了 k-means 聚类和 k-GMM（使用期望最大化进行的高斯混合模型拟合）的随机种植技术。在此之前，该领域的相关技术不够系统和明确，缺少对随机种植核心要素的细节分析，包括采样种子的度量，候选种子的数量，以及种子选择时所用的度量等具体步骤。因此，本文提供了一种新的视角去理解和优化这两种算法的初始步骤，为后续的研究打开了新的分析门径。

Innovation: 
本文利用前瞻性的原则和多 pass 方法，提出了通过条件概率选择种子的方法，这一方法可以加强种子与最终评估算法使用的度量的一致性。实验结果显示，这种方法能够提供比传统方法更稳定的最终结果（k-means 的 SSE、k-GMM 的对数似然比），并且改进了之前设计的多交换策略，该策略首次击败了贪心的 k-means++ 种植方法。此外，实验分析还揭示了 k-means 一些不易察觉的特性，增进了对聚类结果稳定性的理解，也进一步优化了这些方法的实际应用效果。

Conclusion: 
从实用性角度来看，本文提出的最有效的播种方法是成为标准技术的有力候选者。从理论角度来看，本文对播种方法的系统化分析为未来的研究打开了新的分析思路，使得进一步的技术改进和优化评估成为可能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21291</guid><pubDate>Fri, 27 Jun 2025 02:42:54 +0800</pubDate></item><item><title>180. cs.LG-复杂性意识下的微调</title><link>https://arxiv.org/pdf/2506.21220</link><description>Background: 
通用大型语言模型（LLMs）通常通过有监督微调（SFT）在特定领域进行微调以提高性能。通过蒸馏大型模型的推理过程可以在成本较高的调用和大量数据基础上显著提升效果。研究表明，仅对复杂数据使用推理可以提高效率。

Innovation: 
该研究提出了一种新颖的高效微调方案，通过单个标记答案的熵来分类训练数据的复杂性，使用SFT和蒸馏仅对复杂数据进行推理。实验结果显示，该方法在使用62%较少数据的情况下，平均准确率与标准SFT方法相当，且优于蒸馏方法（平均准确率0.55 vs 0.43）.

Conclusion: 
该研究表明，通过复杂性标注的训练数据分类，仅对复杂数据进行推理的SFT方法显著优于标准SFT方法，并且通过减少数据使用量仍能达到与蒸馏方法相当的效果。研究结果为后续研究提供了一个有价值的框架。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21220</guid><pubDate>Fri, 27 Jun 2025 02:42:52 +0800</pubDate></item><item><title>181. cs.LG-DiLoCoX: 分布式集群低通信大规模训练框架</title><link>https://arxiv.org/pdf/2506.21263</link><description>Background: 
大语言模型（LLMs）等基础模型的分布式训练需要大量的通信，通常依赖于中心化的集群和快速可靠的互联。当处理超过100亿参数的模型时，能否在慢网络上进行训练，利用分散的集群来释放其潜力，成为了一个关键问题。

Innovation: 
提出了一种名为DiLoCoX的低通信大规模分散集群训练框架，结合了管道并行、双优化器策略、通信和本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提高了参数规模和模型预训练的速度。通过理论分析证明了一步延迟重叠通信和本地训练以及自适应梯度压缩方案的优势。在1Gbps网络上，DiLoCoX能够训练一个107B参数的基础模型，相较于传统的AllReduce，DiLoCoX在分布式训练中可以实现357倍的速度提升，且对模型收敛几乎没有负面影响，这是首个成功应用到超过100亿参数模型的分散训练框架.

Conclusion: 
DiLoCoX框架通过创新的通信管理和自适应梯度压缩方法，显著提升了分布在慢网络上的大规模模型训练效率，为处理超大规模参数模型提供了新方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21263</guid><pubDate>Fri, 27 Jun 2025 02:42:49 +0800</pubDate></item><item><title>182. cs.LG-人工代理人在部分到场情况下解决永续投票中的公平性问题</title><link>https://arxiv.org/pdf/2506.21186</link><description>Background: 
永续投票通过时间维度评估代表公平性来解决顺序集体决策中的公平问题。现有的永续投票规则依赖完全参与和完全同意的信息，但在实践中，部分到场是常态，这些假设很少成立。因此，研究如何通过引入“人工代理”——这些代理能够代表缺席选民学习偏好的智能代理，来改善永续投票系统的公平性和代表性变得尤为重要。本研究探讨了“人工代理”在不同投票方法下的影响，以及它们在弥补缺席选民参与中的作用。研究发现，尽管缺席选民显著影响了公平性，“人工代理”能够可靠地减轻这些影响，并在多种场景中增强系统的稳健性。

Innovation: 
本研究的创新之处在于引入了“人工代理”，这是一种能够代表缺席选民学习偏好的智能代理，将其整合到永续投票系统中。这一创新旨在解决在实践中常见的参选者不完全参与的问题，从而提高永续投票系统的公平性和代表性和稳健性。

Conclusion: 
研究结果表明，尽管缺席选民对公平性的影响显著，“人工代理”能够可靠地减轻这些影响，并在多种场景中显著增强永续投票系统的稳健性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21186</guid><pubDate>Fri, 27 Jun 2025 02:42:47 +0800</pubDate></item><item><title>183. cs.LG-基于线性性的神经网络压缩</title><link>https://arxiv.org/pdf/2506.21146</link><description>Background: 
在神经网络压缩领域，大多数现有方法通过测量权重的重要性与冗余性来减少不必要的参数。已有许多高度优化的解决方案，为了进一步改进这些已有解决方案，研究者提出了一种基于线性性的压缩方法，旨在减少神经网络中的权重，这种方法与现有方法有所不同，它通过利用ReLU类激活函数下几乎始终激活的神经元行为线性的特性来合并后续层，从而实现网络压缩.

Innovation: 
基于线性的神经网络压缩是一种全新的压缩方式，通过利用ReLU类激活函数下几乎始终激活的神经元行为线性的特性，将后续层进行合并，提高压缩效果和与现有基数的重要性基压缩方法的兼容性，实验结果表明这种新颖的方法大部分模型压缩至原始模型大小的1/4，且与其他压缩技术结合时互不影响，实现了高效的模型压缩与合并.

Conclusion: 
本文的工作为一种新的神经网络压缩方法奠定了基础，这种新方法能够实现更小且更高效的神经网络模型。它显示出了与基于重要性的压缩方法相结合的能力和潜力，为未来的神经网络压缩技术提供了新的研究视角和方向.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21146</guid><pubDate>Fri, 27 Jun 2025 02:42:45 +0800</pubDate></item><item><title>184. cs.LG-通过双提示优化和交叉融合实现个性化联邦学习</title><link>https://arxiv.org/pdf/2506.21144</link><description>Background: 
联邦学习（FL）允许跨分布式客户端协作训练模型而不共享本地数据，但面临数据、计算能力和通信异质性挑战。预训练的视觉-语言模型（VLMs）因其强大的泛化能力和轻量级的提示调优而具有潜力。然而，现有的联邦提示学习方法仅依赖于文本提示，忽略了标记域分布的变化。

Innovation: 
本文提出了一个基于双提示学习和跨融合的个性化联邦学习框架（pFedDC），该框架使每个客户端同时维护视觉和语言模态中的全局和本地提示。全局提示捕捉联邦内的共通知识，而本地提示编码客户端特有的语义和领域特征。此外，设计了一个跨融合模块，可以适应性地将不同层级的提示融合，使模型能够生成与每个客户端独特数据分布相匹配的个性化表示。跨异质性数据集的广泛实验显示，pFedDC 一贯优于现有方法。

Conclusion: 
pFedDC 框架显示出比现有方法更好的性能，特别是在具有各种类型异质性的九个数据集上。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21144</guid><pubDate>Fri, 27 Jun 2025 02:42:44 +0800</pubDate></item><item><title>185. cs.LG-基于生成对抗的UAV网络攻击规避与异常检测</title><link>https://arxiv.org/pdf/2506.21142</link><description>Background: 
随着无人机（UAV）越来越多地融入民用航空空间，传统的异常检测方法往往无法识别新型威胁，导致安全漏洞。当前的出界检测方法虽然常用来识别未知攻击，但当应对措施不足时仍有可能失败。此外，传统的出界检测器难以区分隐蔽的对抗性攻击和真正的出界事件。因此，需要一种能够生成隐藏攻击并逃避免舌检测系统的生成对抗网络（cGAN）框架。基于此，本文设计了一种鲁棒的多类入侵检测（IDS）分类器，该分类器训练于无害无人机遥测数据和已知的网络攻击，包括拒绝服务（DoS）、虚假数据注入（FDI）、中间人（MiTM）和重放攻击。通过这一分类器，cGAN对已知攻击进行扰动，生成能够被误分类为良性且统计上与出界分布相似的对抗样本。这些对抗样本迭代优化，以实现高度隐藏和较高的攻击成功率。为了检测这些变化，本文还实施了条件变分自动编码器（CVAE），利用负对数似然来分离对抗输入和真实的出界样本。

Innovation: 
提出了一种基于条件生成对抗网络（cGAN）的框架，用于生成隐蔽的对抗性攻击以规避入侵检测系统。该方法通过扰动已知的攻击样本，生成能够被误分类为良性但仍与出界分布相似的对抗样本。此外，还实施了条件变分自动编码器（CVAE），利用负对数似然来区分对抗性样本和真实的出界样本。实验结果表明，基于CVAE的后悔得分显著优于传统的马氏距离检测方法，用于识别隐蔽的对抗性威胁。

Conclusion: 
本文的研究结果强调了先进的概率建模对于加强入侵检测系统能力的重要性，特别是在对抗生成模型基于的网络入侵方面。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21142</guid><pubDate>Fri, 27 Jun 2025 02:42:44 +0800</pubDate></item><item><title>186. cs.LG-FeDa4Fair: 客户端级别的联邦数据集用于公平性评估</title><link>https://arxiv.org/pdf/2506.21095</link><description>Background: 
联邦学习（FL）允许跨多个客户端协作进行模型训练而不分享用户的私人数据。然而，公平性仍然是一个关键问题，因为客户端本地数据集中的偏见会影响整个联邦系统。不同客户端之间异质的数据分布可能导致对某些客户端更公平但对其他客户端不公平的模型。尽管在文献中存在许多提高公平性的解决方案，但大多数解决方案通常仅关注应对单一敏感属性的偏见，并且常常忽视不同客户端多样且有时是矛盾的公平性需求。这种局限性的视角可能限制了对不同客户端公平性干预的有效性。为了在联邦学习中支持更稳健且可再现的公平性研究，我们旨在为公平感知的联邦学习方法提供在全局和客户端两个层次上的一致基准评估工具。

Innovation: 
我们引入了FeDa4Fair库，用于生成可针对异质客户端偏见评估公平性感知联邦学习方法的表数据集；并且发布四组具有异质偏见的数据集及其基准测试，以在受控环境中比较公平性缓解方法；还提供了评估这些数据集公平结果的现成函数。这些创新为公平性感知的联邦学习研究提供了统一的基准评估工具，增强了不同客户端公平性干预的有效性。

Conclusion: 
通过引入FeDa4Fair库和配套的数据集及基准测试，我们为公平感知的联邦学习方法的评估提供了统一的基准评估工具，提升了不同客户端公平性干预的有效性，并促进了相关领域的可重复研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21095</guid><pubDate>Fri, 27 Jun 2025 02:42:43 +0800</pubDate></item><item><title>187. cs.LG-在强化学习中通过多样化迷你批选取高效进行从头药物设计中的化学探索</title><link>https://arxiv.org/pdf/2506.21158</link><description>Background: 
在许多实际应用中，评估实例的质量往往非常昂贵且耗时，例如来自人类反馈和物理模拟，而提出新实例则相对容易。特别是在强化学习中，由于新互动（即新实例）需要被评估以提供有益的奖励信号以便学习，因此这一点尤为重要。足够的探索是至关重要的，而从多样化的小批量中学习可以产生重大影响，有助于避免模式崩溃。

Innovation: 
本文介绍了在强化学习中利用多样化迷你批选取的方法，并提出使用行列式点过程进行该任务。我们在药物发现的实际问题背景下研究了这种方法。通过与三种成熟的分子生成或acles进行详细评估，在众多生成步骤中，实验表明所提议的框架可以显著提高解决方案的多样性，同时仍能保持高质量。

Conclusion: 
在药物发现中，这种结果可能导致更快满足未满足的医疗需求。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21158</guid><pubDate>Fri, 27 Jun 2025 02:42:43 +0800</pubDate></item><item><title>188. cs.LG-零-shot 学习在元件老化风险预测中的应用</title><link>https://arxiv.org/pdf/2506.21240</link><description>Background: 
电子组件老化问题对依赖电子组件的行业构成了重大挑战，增加了成本并导致系统安全性和可用性受到破坏。准确预测老化风险至关重要，但受到可靠数据的限制。

Innovation: 
提出了一种使用大规模语言模型（LLMs）的零-shot 学习（ZSL）方法，以弥补数据限制，通过利用表格数据中特定领域的知识来预测老化风险。这种方法在两个现实世界的数据集上显示出有效的风险预测效果。

Conclusion: 
对比评估了四种LLMs，强调选择了合适的模型对于特定预测任务的重要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21240</guid><pubDate>Fri, 27 Jun 2025 02:42:41 +0800</pubDate></item><item><title>189. cs.LG-DBConformer: 双分支卷积Transformer用于EEG解码</title><link>https://arxiv.org/pdf/2506.21140</link><description>Background: 
基于脑电图（EEG）的脑机接口（BCIs）能够将自发/诱发神经活动转化为对外部通信的控制命令。虽然卷积神经网络（CNNs）仍是EEG解码的主流架构，但其固有的短接收场限制了其捕获长程时间依赖性和全局通道关系的能力。最近的CNN-Transformer（Conformers）混合模型部分解决了这一问题，但大多数模型采用串联设计，导致局部和全局特征的不充分整合，并且常常忽略了显式的通道间建模。为了解决这些问题，本文提出了一种名为DBConformer的双分支卷积Transformer网络，专门用于EEG解码。该网络结合了时域Conformer来建模长程时间依赖性，以及空域Conformer来提取通道间交互，从而捕捉EEG信号的时空模式。一个轻量级的通道注意模块进一步通过数据驱动的方式对EEG通道进行赋权，以精细空间表示。

Innovation: 
基于双分支卷积Transformer的DBConformer网络：（1）结合了时域Conformer和空域Conformer，分别用于建模长程时间依赖和提取通道间交互；（2）加入了轻量级通道注意模块，通过对EEG通道进行数据驱动的赋重要性，以精细空间表示；（3）在五个运动想象数据集和两个癫痫发作检测数据集的三种评估设置下，DBConformer模型比10种竞争基准模型表现更优，且参数量仅为高性能的EEG Conformer模型的八分之一；（4）可视化结果显示，DBConformer提取的特征与运动感知先验一致，并具有生理可解释性。

Conclusion: 
DBConformer模型在每次试验中都优于10个竞争基准模型，并且其性能和可解释性使其成为稳定的、可解释的EEG解码的可靠选择。DBConformer的代码已公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21140</guid><pubDate>Fri, 27 Jun 2025 02:42:39 +0800</pubDate></item><item><title>190. cs.LG-基于课程引导的鲁棒强化学习以实现观察空间攻击下的安全无人车辆去冲突</title><link>https://arxiv.org/pdf/2506.21129</link><description>Background: 
在动态空域中的无人驾驶航空器（UAV）导航等安全关键系统中，部署的强化学习（RL）策略容易受到观察空间的离分布攻击（OOD adversarial attacks）。这些攻击导致分布变化，严重影响价值函数估计，导致不安全或次优决策，破坏现有策略的鲁棒性。为解决这一脆弱性，本文提出了一种针对增量敌手扰动的课程引导的鲁棒强化学习框架，旨在提高RL代理的泛化能力和预见未知攻击的能力。该框架通过逐步增强观察空间扰动的强度，使RL代理能够适应并泛化更多范围的OOD观察，并预见未见过的攻击。

Innovation: 
本文提出了一种鲁棒的RL框架，该框架包含了逐步增强扰动强度的模拟攻击者机制，使得RL代理能够在更广泛的不同分布观察中适应和泛化，并能够预见未知攻击。通过Wasserstein距离最小化跨逐级扰动观察的专家引导批评者对齐，该方法确保了这些边界，提出了稳定遗忘的适应条件。在动态三维障碍物的无人机去冲突场景中，与标准的和鲁棒的RL基线方法相比，该鲁棒策略在承受梯度下降投影攻击（PGD）和GPS欺骗攻击时，均表现出更好的性能，累计奖励高出15%，且冲突事件减少了30%以上。这表明在威胁不断演变的环境中，鲁棒强化学习在决策安全性与鲁棒性上具有实际和理论的可行性

Conclusion: 
该研究通过理论分析、方法创新以及仿真验证，展示了基于课程引导的鲁棒强化学习在无人车辆去冲突场景下的应用场景和有效性，证明了其在存在观察空间攻击下的鲁棒性和安全性，从而进一步为未来更复杂环境下的安全决策提供了理论和实践支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21129</guid><pubDate>Fri, 27 Jun 2025 02:42:37 +0800</pubDate></item><item><title>191. cs.LG-NaLaFormer：Transformer模型中的规范感知线性注意力</title><link>https://arxiv.org/pdf/2506.21137</link><description>Background: 
线性注意力作为一种可能替代softmax注意力的方法已经出现，通过将序列长度的复杂性从二次降低到线性。当前的工作通过使用L1归一化的线性可分核函数，而不是softmax操作符，来保持softmax的两个基本属性：非负性和熵减少。然而，线性注意力中的归一化操作忽略了查询范数，这导致了熵差距。此外，现有的工作抑制了查询和键向量的负值，导致映射后的内积交互缺失。

Innovation: 
为了应对这些双重挑战，作者提出了一个名为Norm-Aware Linear Attention（NaLaAttention）的新型机制，能够恢复由核函数扰动的范数分布并且控制动态尖峰。具体来说，首先将查询和键矩阵分解为两个部分：范数和方向，以实现范数感知的尖峰控制和范数一致性。数学上揭示了softmax归一化下熵减少的程度与查询范数的关系，提出了一个查询范数感知的内核函数以动态控制熵减少。此外，通过范数保持映射，将所有角度矩阵的元素投影到正值，利用余弦相似度抑制方向相反的维度，以确保范数一致性和非负性约束。

Conclusion: 
广泛的实验表明，NaLaFormer在视觉和语言任务中均提高了性能，提升了表达性和效率，最高可达4.2%。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21137</guid><pubDate>Fri, 27 Jun 2025 02:42:34 +0800</pubDate></item><item><title>192. cs.LG-在对抗环境中对抗脆弱的强化学习无人机避障稳健策略切换</title><link>https://arxiv.org/pdf/2506.21127</link><description>Background: 
随着无人驾驶飞机（UAVs）导航自动化程度的提高，它们容易受到利用强化学习（RL）中漏洞的对手攻击的影响。尽管现有的一些鲁棒RL方法旨在缓解这些威胁，但它们的效果在处理出分布变化时有限，因为这些方法主要针对固定干扰设计。因此，该领域需要一种能够更好地适应更广泛分布变化的框架。用概率方法将多个鲁棒策略作为多臂_bandit问题进行建模，并采用基于折现汤普森采样的切换机制，进行动态选择以最小化对手诱导的状态-动作值分布变化。该方法首先通过考虑策略空间中各种扰动来生成多样化动作鲁棒策略，然后通过多臂_BANDIT问题，利用折现汤普森采样动态选择策略，有效适应攻击策略的变化。该方法通过优化折现汤普森采样来最小化分布变化带来的遗憾，从而实现对未知对手攻击的有效适应。在复杂且动态的三维障碍环境中进行的大量数值模拟结果显示，在更具针对性的投影梯度下降法和欺骗攻击下，稳健策略切换方法性能更优，导航路径更短，冲突自由的导航轨迹比例更高，超越现有的鲁棒RL技术。这种方法的有效性通过与传统且非适应性鲁棒RL方法进行对比得到了证实，展示了在对抗环境中增强鲁棒性的潜力。

Innovation: 
该论文提出了一种增强适应性的鲁棒强化学习框架，即抗脆弱RL（antifragile RL）框架。该框架通过在鲁棒策略之间切换来提高适应更广泛的分布变化的能力，采用了基于折现汤普森采样的动态切换机制，根据非平稳的伯努利奖励最优地选择策略。该方法通过优化折现汤普森采样来最小化由于分布变化所带来的遗憾，从而实现对未知对手攻击的有效适应，进而增强抗脆弱性。与传统非适应性鲁棒RL方法相比，该框架能够表现出更优的性能。

Conclusion: 
该研究提出的抗脆弱RL框架可以有效增强未经测试的新攻击下的鲁棒性。通过综合多种扰动策略并利用动态策略切换机制，在复杂且多动态障碍物的导航环境中，该方法能够实现更短的导航路径和更高的无冲突自由导航轨迹率，优于现有的鲁棒RL方法。这表明对抗环境下增强鲁棒性的可行性和有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21127</guid><pubDate>Fri, 27 Jun 2025 02:42:34 +0800</pubDate></item><item><title>193. cs.LG-FedDAA：联邦学习中基于动态客户端聚类的概念漂移适应方法</title><link>https://arxiv.org/pdf/2506.21054</link><description>Background: 
在联邦学习（FL）中，每个客户端的数据分布可能随时间变化，引入了时间和空间上的数据异质性，这被称为概念漂移。数据异质性来源于三种漂移源：真实的漂移（条件分布P(y|x)的变化）、虚拟漂移（输入分布P(x)的变化）和标签漂移（标签分布P(y)的变化）。然而，大多数现有的FL方法针对概念漂移主要关注真实的漂移，当客户端经历虚拟或标签漂移时，这些方法往往无法有选择地保留有用的历史知识，导致灾难性的遗忘。关键挑战在于区分不同的漂移源，因为它们需要不同的适应策略：真实的漂移需要废弃过时的数据，而虚拟或标签漂移则受益于保留历史数据。若没有明确识别漂移源，通用的适应策略往往是次优的，可能损害一般化性能。

Innovation: 
我们提出了一种动态聚类的联邦学习框架FedDAA，旨在适应多源的概念漂移同时保留有价值的历史知识。具体而言，FedDAA集成了三个模块：集群数目确定模块、实际漂移检测模块和概念漂移适应模块。此外，我们提供了理论上的收敛性保证，并且实验结果表明，FedDAA在Fashion-MNIST、CIFAR-10和CIFAR-100上的准确率提高了7.84%至8.52%。

Conclusion: 
通过FedDAA，能够在不损害历史知识的情况下适应多个漂移源，从而提高联邦学习中的性能。这种方法通过明确区分漂移源并采取针对性的适应策略，避免了通用适应策略可能带来的次优性和损害一般化性能的问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21054</guid><pubDate>Fri, 27 Jun 2025 02:42:33 +0800</pubDate></item><item><title>194. cs.LG-Unlasting：基于双向条件扩散隐桥的无配对单细胞多扰动估计</title><link>https://arxiv.org/pdf/2506.21107</link><description>Background: 
单细胞测序可以提供丰富的基因表达信息，有助于识别关键基因并增强药物筛选，但这是一个破坏性的过程，使得无法在同一细胞处理前后捕获其表型。现有方法要么通过随机抽样强行配对无配对数据，要么在建模过程中忽略未受扰动和受扰动细胞之间的固有关系。

Innovation: 
提出了一种基于双向扩散隐桥（DDIB）的框架来学习不同数据分布之间的映射，有效解决了无配对数据的问题。该框架可视为一种数据增强的形式，整合了基因调控网络（GRN）信息以在生物学意义上传播扰动信号，并引入掩码机制以预测静默基因，从而提高生成特性表型的质量。此外，还提出了一种更适合的评估标准，并设计了专用的掩码模型以更好地预测静默基因来改善生成质量，提出了基于生物学的评估标准以更好地反映单细胞响应中的固有异质性。

Conclusion: 
提出了Unlasting，一种使用双向条件扩散隐桥处理无配对单细胞多扰动数据的解决方案，增强了模型对基于GRN指导下的扰动的理解，通过引入掩码模型预测静默基因来改进生成质量，通过更加生物学基础的评估标准评估细胞响应的异质性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21107</guid><pubDate>Fri, 27 Jun 2025 02:42:32 +0800</pubDate></item><item><title>195. cs.LG-联邦学习下概念漂移的信息论分析</title><link>https://arxiv.org/pdf/2506.21036</link><description>Background: 
近期联邦学习（FL）的研究通常在静态数据集上训练模型。然而，现实世界中的数据往往是随时间以流的形式到来且分布易变，这种情况被称为概念漂移，会导致性能下降。本文通过信息理论分析FL在概念漂移下的表现，并提出了一种算法来缓解性能下降。本文首先将概念漂移建模为马尔科夫链，并引入了一种评估模型捕捉未来未知数据特征能力的指标——稳定泛化误差。随后，根据Kullback-Leibler（KL）散度和互信息，得出了该指标的上界。作者探索了三种漂移模式（周期性、渐变性和随机性）及其对FL性能的影响。通过KL散度和互信息调节经验风险最小化方法，从而增强长期性能。此外，研究了性能与成本之间的权衡，通过识别帕累托前沿来实现。为验证方法有效性，作者利用Raspberry Pi4设备构建了一个FL测试床，并通过实验结果验证了理论发现，表明漂移模式对性能有显著影响，提出的方法在三种模式下均优于现有方法，证明了其在适应FL中概念漂移的有效性。

Innovation: 
本文创新性地将概念漂移建模为马尔科夫链，并通过引入稳定泛化误差（Stationary Generalization Error）和使用KL散度、互信息，提供了分析概念漂移下FL性能的方法。同时，提出了一种结合KL散度和互信息调节的经验风险最小化算法，有助于增强长期性能。此外，通过建立FL测试床验证了方法的有效性，提出了性能与成本的权衡方案，得出了帕累托前沿。

Conclusion: 
本文验证了FL在概念漂移下的表现受不同漂移模式显著影响，提出的方法对三种漂移模式均表现出优越性，证明了其在FL中适应概念漂移的有效性。通过建立测试床并与理论结果对比，进一步证明了该方法的有效性，同时为FL中的漂移处理提供了新的见解与参考。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21036</guid><pubDate>Fri, 27 Jun 2025 02:42:31 +0800</pubDate></item><item><title>196. cs.LG-学习跳过Transformer的中间层</title><link>https://arxiv.org/pdf/2506.21103</link><description>Background: 
时序计算是提升Transformer效率的一个流行策略。现有的方法通常针对个别模块（例如，专家混合层）或独立跳过不同的层。然而，可解释性研究已经证明，Transformer的中间层表现出较大的冗余性，而早期的层则将信息聚合到token位置中。这项工作中，作者借鉴这些发现，提出了一个新颖的架构，该架构能够从中间向外部动态地跳过不同数量的层。特别是，通过学习门控机制来决定是否忽略中间对称的块，并通过门控注意力机制防止后续token注意被跳过的token位置。残差正则化通过‘三明治’或‘perilayernorm’方案进行控制，而门控稀疏化则通过自适应正则化损失来进行调整。初始目的在于减少‘简单’token的计算需求，并潜在地培育多层次表示层次结构，但在所调查的规模下，作者的方法在验证交叉熵和估算FLOPs之间的权衡上并不比具有更少层的密集基线更好。

Innovation: 
在中层向外部动态跳过不同数量的层；通过学习门控机制来忽略中间的对称块；门控注意力机制防止后续token关注跳过的token位置；采用‘三明治’或‘perilayernorm’方案控制残差正则化；自适应正则化损失调整门控稀疏化

Conclusion: 
尽管初始目的是减少‘简单’token的计算需求，并潜在地培育多层次表示层次结构，但在所调查的规模下，作者的方法在验证交叉熵和估算FLOPs之间的权衡上并不比具有更少层的密集基线更好。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21103</guid><pubDate>Fri, 27 Jun 2025 02:42:30 +0800</pubDate></item><item><title>197. cs.LG-基于注意引导图学习的可解释层次概念推理</title><link>https://arxiv.org/pdf/2506.21102</link><description>Background: 
概念基础模型（CBMs）是一种通过高级概念解释预测的深度学习模型。这些模型首先预测概念，然后使用这些概念来执行下游任务。然而，现有的CBMs仅提供了对最终任务预测的可解释性，而概念预测通常通过黑盒神经网络进行，这限制了整个模型的可解释性。

Innovation: 
本文提出了层次概念记忆推理器（H-CMR），这是一种新的CBM，为概念和任务预测都提供了可解释性。H-CMR使用学习到的有向无环图来建模概念之间的关系，其中边表示逻辑规则，这些规则定义概念与其他概念之间的关系。推理过程中，H-CMR通过神经注意机制选择这些规则的子集，并将这些规则分层应用以预测所有概念和最终任务。实验结果表明，H-CMR在获得与最先进的性能的同时，通过概念和模型干预可以实现强大的人机交互，提高推断准确性并增强训练中的数据效率，尤其是在可用背景知识的情况下。

Conclusion: 
H-CMR通过注意引导的图学习实现了可解释的层次概念推理，提升了模型整体的透明度和可解释性，可以在各种应用场景中更好地与人类交互。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21102</guid><pubDate>Fri, 27 Jun 2025 02:42:25 +0800</pubDate></item><item><title>198. cs.LG-使用知识图谱生成高质量指令数据以增强LLM工具使用</title><link>https://arxiv.org/pdf/2506.21071</link><description>Background: 
研究指出，教导大型语言模型（LLMs）使用工具对于增强其问题解决能力和扩展应用领域至关重要。然而，有效使用工具具有挑战性，因为这需要对工具功能和用户意图有深入的理解。此前的方法主要依赖于LLMs生成指令数据，但这些数据的质量常常不足。本文探讨了一种新的方法，通过使用知识图谱生成高质量的指令数据，以提高LLMs工具使用的效率及整体能力。知识图谱是富含语义信息的手动整理数据集。首先从给定的知识图谱中提取多种查询路径，然后将其转化为广泛的用户查询。接着将实体之间的关系转化为可执行的工具，并解析每个查询的路径为详细的解决方案步骤，最终产生高质量的指令数据。实验结果显示，只需对少量生成的合成数据进行微调，即可显著提升LLMs的工具使用率及其整体能力。

Innovation: 
本文提出了一种创新方法，通过使用知识图谱生成高质量的指令数据，取代传统的数据生成方法。这种新方法能够显著提高LLMs对工具的使用效率及其整体能力。知识图谱的应用使得指令数据具有更丰富的语义信息，从而有效地指导工具使用，提高问题解决水平。

Conclusion: 
本文通过实验展示了利用知识图谱生成的高质量指令数据能够在微调后显著提升LLMs的工具使用效率和问题解决能力。这一方法为增强LLMs的实用性和应用范围提供了新的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21071</guid><pubDate>Fri, 27 Jun 2025 02:42:18 +0800</pubDate></item><item><title>199. cs.LG-Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection</title><link>https://arxiv.org/pdf/2506.21093</link><description>Background: 
Transformer模型在无线通信问题中表现出潜力，特别是在上下文学习（ICL）中，模型可以通过提示适应新任务，而无需更新模型本身。然而，现有的基于ICL的Transformer模型通常需要深度架构，许多层才能实现满意的性能，这导致了显著的存储和计算成本。现有的浅层Transformer模型无法达到这种性能，限制了它们在资源受限的移动设备上的应用。

Innovation: 
本文提出了一种名为CHOOSE（CHain Of thOught Symbol dEtection）的新颖CoT增强浅层Transformer框架，通过在隐藏层引入自回归潜在推理步骤，显著提高了浅层模型（1-2层）的推理能力，而无需增加模型深度。这种设计使轻量级的Transformer模型能够达到与深度模型相当的检测性能，从而适配于资源受限的移动设备。

Conclusion: 
实验结果表明，该方法在轻量级模型上实现了优于传统浅层Transformer模型的性能，并且在存储和计算效率方面与深度模型相当。这表示在资源限制的无线接收器中实现基于Transformer算法的一个有前景的方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21093</guid><pubDate>Fri, 27 Jun 2025 02:42:17 +0800</pubDate></item><item><title>200. cs.LG-由多Agent方法指导的大语言模型（LLM）化学工艺优化</title><link>https://arxiv.org/pdf/2506.20921</link><description>Background: 
最大化生产效率和经济效益的化学工艺优化至关重要。传统方法如梯度求解器、进化算法和参数网格搜索，在操作约束未定义或不可用的情况下变得不切实际，迫使工程师依赖主观直觉来估计可行参数范围。为此，本文提出了一种基于多Agent框架的大语言模型（LLM）代理机制，自主从最小过程描述中推断操作约束，并协同利用这些推断的约束进行优化。该框架在两次迭代中消除了预设操作界限的需要，通过自主推断约束并进行多Agent迭代优化，确保效率。该方法已在水解烷基化过程中的成本、产量和产出成本比度量中得到验证，并展现了与传统优化方法的竞争力，同时实现了更好的计算效率，所需迭代次数更少。该方法在不到20分钟内收敛，比网格搜索快了31倍。此外，该框架具备引导搜索功能，展示了复杂的工艺理解，正确识别了公用设施权衡并应用了领域特定的启发式方法。这种策略特别适合那些操作约束不清晰或不可用的情况，特别是在新兴工艺和再设计应用中具有显著潜力。

Innovation: 
提出了一种基于多Agent框架的大语言模型（LLM）代理机制，该机制能自主从最小过程描述中推断操作约束，进而协同进行优化。这种多Agent框架帮助解决了在操作约束未定义或不可用情况下的优化难题，减少了需要的预设操作界限，并通过自主推断和多Agent迭代优化增强了计算效率。此外，该方法展示了理解复杂工艺、识别公用设施权衡并应用领域启发式的方法，这为优化不可预知的操作约束场景提供了新的解决方案。

Conclusion: 
在水解烷基化过程中的成本、产量和产出成本比度量中，所提出的多Agent框架证明了与传统优化方法的竞争力，同时展示了显著的计算效率提升，实现了31倍的加速。该框架通过自主推断和多Agent迭代优化，消除了对预设操作界限的需求，并通过引导搜索展示了复杂的工艺理解，能够正确识别公用设施权衡并应用领域启发式。因此，这种方法特别适合那些操作约束不清晰或不可用的优化场景，特别是在新兴工艺和再设计应用中具有显著潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20921</guid><pubDate>Fri, 27 Jun 2025 02:42:13 +0800</pubDate></item><item><title>201. cs.LG-严格子目标执行：在层次强化学习中实现可靠的长时间规划</title><link>https://arxiv.org/pdf/2506.21039</link><description>Background: 
长期目标条件任务对强化学习(RL)提出基本挑战，尤其是目标较远且奖励稀疏时。虽然分层和图基的的方法提供了部分解决方案，但它们常常受到子目标不可行性和规划效率低下的困扰。

Innovation: 
提出了一种名为严格子目标执行(SSE)的基于图的层次RL框架，通过结构化约束高层决策确保单步子目标可达性。SSE使用了一个解耦的探索策略，系统性地遍历未探索的子目标空间区域。此外，引入了一种失败感知路径细化方法，通过动态调整边的成本以根据观察到的子目标的成功率进行优化，从而提高子目标的可靠性。实验结果表明，SSE在效率和成功率方面优于现有的目标条件RL和层次RL方法。

Conclusion: 
实验结果表明，SSE在长时基准上表现出了更高的效率和成功概率，一致地优于现有的目标条件RL和层次RL方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21039</guid><pubDate>Fri, 27 Jun 2025 02:42:11 +0800</pubDate></item><item><title>202. cs.LG-通过遗憾感知优化实现高效的技能发现</title><link>https://arxiv.org/pdf/2506.21044</link><description>Background: 
无监督技能发现旨在学习开放强化学习中的多样化和可区分的行为。现有的方法主要通过纯探索、互信息优化和学习时序表示来提高多样性。尽管这些方法在探索方面表现良好，但在效率上仍有限制，尤其是在高维情况下的表现尤为不足。

Innovation: 
提出了一种基于遗憾感知的方法，以时序表示学习为基础进行技能生成和策略学习，通过遗憾来量化策略收敛度，并利用可学习的技能生成器引导技能发现，技能生成来自能升级的技能生成器群体，以避免技能退化。

Conclusion: 
实验表明，所提出的方法在效率和多样性方面均优于基线方法。此外，在高维环境中，该方法在零样本提升方面比现有方法表现出了15%的改善。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21044</guid><pubDate>Fri, 27 Jun 2025 02:42:10 +0800</pubDate></item><item><title>203. cs.LG-使用多种尺度等变图扩散模型进行准确复杂抗原结合的抗体设计与优化</title><link>https://arxiv.org/pdf/2506.20957</link><description>Background: 
抗体设计在治疗性和诊断性开发中仍是一个关键挑战，尤其是在处理具有多种结合界面的复杂抗原时。当前的计算方法面临两个主要限制：（1）在保留对称性的同时捕捉几何特征；（2）对新型抗原界面的泛化能力。尽管近期有所进展，但这些方法往往未能准确捕捉分子间相互作用并且保持结构完整。这些问题促使研究者们提出了新的解决方案。

Innovation: 
本文提出了一种名为AbMEGD的端到端框架，该框架结合了多尺度等变图扩散技术，用于抗体序列和结构的设计。AbMEGD通过先进的几何深度学习，综合了原子级别几何特征和残基级别嵌入，捕捉局部原子细节及全局序列-结构相互作用。其E(3)-等变扩散方法确保了几何精度、计算效率和对复杂抗原的泛化能力。实验结果表明，AbMEGD在氨基酸回收率、改进百分比和核心CDR-H3区域的均方根偏差方面分别比其他模型有了显著提升，建立了序列-结构联合设计及亲合力优化的新基准。

Conclusion: 
实验结果显示，AbMEGD在平衡结构完整性和功能提升方面表现出色，并且为序列-结构联合设计和亲合力优化设定了新的标准。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20957</guid><pubDate>Fri, 27 Jun 2025 02:42:08 +0800</pubDate></item><item><title>204. cs.LG-RL-Selector: 通过冗余评估进行强化学习引导的数据选择</title><link>https://arxiv.org/pdf/2506.21037</link><description>Background: 
现代深度架构通常依赖大规模数据集进行训练，但这会产生高额的计算和存储成本。现实世界的数据集往往包含大量的冗余信息，导致数据集的冗余和重复性较高。为了提高训练效率，研究者们提出了数据选择的方法来减少冗余，选择最具代表性的样本进行训练，以降低训练成本而不牺牲性能。现有的数据选择方法通常依赖静态评分指标或预训练模型，未能充分考虑到选定样本之间的动态变化及其相互作用对训练效果的影响。

Innovation: 
本文引入了ε-样本覆盖的概念，这是一种基于样本间关系量化样本冗余的方法，能够捕捉数据集的固有结构。基于此，作者将数据选择问题重新定义为一个强化学习过程，并提出了RL-Selector方法，利用一种轻量级的强化学习代理优化选择策略，其奖励信号来源于随时间演化的数据分布中的ε-样本覆盖。实验结果表明，该方法在多种基准数据集和不同架构下，能够稳定地超越现有最先进的基线方法，使用我们选择的数据集训练得到的模型展示了更好的泛化性能和更高的训练效率。

Conclusion: 
我们的方法在代表性数据集的选择中表现出了显著的优势，通过结合ε-样本覆盖和强化学习技术，不仅将计算和存储成本降低，还提高了模型的泛化性能和训练效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21037</guid><pubDate>Fri, 27 Jun 2025 02:42:07 +0800</pubDate></item><item><title>205. cs.LG-TRIDENT: 通过分类注释和局部对应关系实现三模态分子表示学习</title><link>https://arxiv.org/pdf/2506.21028</link><description>Background: 
分子属性预测旨在从化学结构到功能属性学习表示。虽然多模态学习已成为学习分子表示的强大范式，但先前的工作大多忽视了分子的文本描述和分类功能注释。本文介绍了TRIDENT，这是一个新颖的框架，将分子SMILES、文本描述和分类功能注释结合起来学习丰富的分子表示。为了实现这一目标，本文整理了一个包含结构化、多层次功能注释的分子-文本数据集。TRIDENT 不依赖于传统的对比损失，而是使用基于体积的对齐目标，联合对全局三模态特征进行对齐，从而实现模态间的软且几何感知对齐。此外，TRIDENT 引入了一种新的局部对齐目标，以捕捉分子亚结构与其对应的子文本描述之间的详细关系。基于动量机制动态平衡全局和局部对齐，使得模型既能学习广泛的功能语义，又能学习精细的结构-功能映射。

Innovation: 
TRIDENT 引入了基于体积的对齐目标来实现三模态特征（分子 SMILES、文本描述和分类功能注释）在全局层面的联合对齐，并引入了一种新型的局部对齐目标来捕捉分子亚结构与子文本描述之间的细节关系。动态动量机制平衡了全局和局部对齐，使模型既能学习广泛的语义功能，又能学习细致的结构-功能关系，从而显著提高了分子属性预测的表现。

Conclusion: 
TRIDENT 在11个下游任务上达到了最新的性能水平，这表明将 SMILES、文本和分类功能注释结合起来进行分子属性预测是有价值的。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21028</guid><pubDate>Fri, 27 Jun 2025 02:42:04 +0800</pubDate></item><item><title>206. cs.LG-逐个激活和稀疏混合的持续学习方法</title><link>https://arxiv.org/pdf/2506.21035</link><description>Background: 
持续学习(CL)中的大规模预训练模型面临着灾难性遗忘和任务干扰的问题。传统基于LoRA的MoE方法通过分配并冻结特定任务的适配器来缓解遗忘问题，但这些问题在任务间存在互相干扰、冗余以及路由选择模糊的情况。这些挑战主要体现在：1) 干扰：每次输入激活完整的LoRA专家会导致子空间干扰，妨碍了任务间有用的组件的再利用；2) 冗余：新添加的专家往往因为不相关秩的激活而导致知识重复或矛盾，而相关秩的再利用不足；3) 不确定性：任务间的重叠特征使路由器混淆，导致专家分配不稳定。随着更多的专家积累，早期任务的路由效果会下降，从而加速遗忘。

Innovation: 
我们提出了MoRA，一种自激活和稀疏秩激活的混合适应学习方法。它不是一个简单的低秩矩阵混合，而是将每个r秩的更新分解为r个1秩的组件，每个组件被视为独立专家，从而实现了1秩专家的细粒度混合，同时减少了干扰和冗余。为了避免路由不确定性，每个1秩专家可以通过中间激活来推断自身的相关性。结合我们提出的秩剪枝和激活预算，MoRA能够适应性地选择每个输入的稀疏秩混合。

Conclusion: 
我们在CLIP和大型语言模型中验证了MoRA，结果显示它在增强持续学习(PMs)方面表现出显著的效果，并改善了泛化能力同时减轻了遗忘问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21035</guid><pubDate>Fri, 27 Jun 2025 02:42:02 +0800</pubDate></item><item><title>207. cs.LG-蒸馏归一化流</title><link>https://arxiv.org/pdf/2506.21003</link><description>Background: 
生成模型中，显式密度学习者因其能更准确地建模概率分布而变得越来越流行。与生成对抗网络相比，它们能够进行密度估计和确切的潜在变量推断，这提高了生成模型的训练效果和样本质量。然而，这些模型也存在一些问题，例如训练难度较大和采样质量较低。归一化流是一种显式密度模型，通过可组合的双射函数将不可解概率函数转化为可解函数，以此提高模型训练效果和样本质量。在此之前的研究中，已经探讨了如何通过知识蒸馏提高较小学生的归一化流模型的采样质量和密度估计能力，但尚未深入研究蒸馏在组成归一化流中的知识转移机制及其带来的益处和局限性。

Innovation: 
本文提出了一种新颖的知识蒸馏技术，以增强较小学生归一化流的采样质量和密度估计能力。通过这种蒸馏技术，可以显著减小模型规模同时保持较高的性能表现。较小模型的性能表现与网络中的双射函数和参数数量成正比，这带来了相对的吞吐量提升。这种方法利用归一化流的独特属性，在中间层之间实现非传统形式的知识传递，从而提高了模型的训练效率和功能表现。

Conclusion: 
通过知识蒸馏技术，本文成功地改进了组成归一化流中小学生归一化流的性能，同时也探讨了蒸馏在归一化流中的知识转移机制及其带来的益处和局限性。这些发现进一步证明了归一化流在生成模型中的潜力，特别是在通过减小模型规模提高其计算效率方面。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21003</guid><pubDate>Fri, 27 Jun 2025 02:42:00 +0800</pubDate></item><item><title>208. cs.LG-SharpZO: 前向仅通过迭代的混合感知尖锐度视觉语言模型提示调优</title><link>https://arxiv.org/pdf/2506.20990</link><description>Background: 
视觉语言模型（VLMs）在各种下游任务中表现出卓越的性能，但需要通过反向传播（BP）访问模型梯度，使得它们不适合作为受内存约束的边缘设备上的仅推理模式使用。先前的工作探索了各种BP-free微调方法，但这些方法通常依赖于高方差的进化策略（ES）或零阶（ZO）优化，往往未能达到满意的性能。

Innovation: 
本文提出了一种名为SharpZO的混合感知尖锐度零阶优化方法，旨在通过尖锐度感知的预热训练增强ZO微调的性能。SharpZO具有两阶段优化过程：第一阶段采用尖锐度感知进化策略（ES）进行全局探索和平滑损失景观来构建强大的初始化，第二阶段通过稀疏ZO优化进行精细化的局部搜索。整个优化过程仅依赖前向传播。

Conclusion: 
理论上和实验结果表明，SharpZO显著提高了准确性和收敛速度，相比于最先进的仅前向方法，平均性能提升了7%。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20990</guid><pubDate>Fri, 27 Jun 2025 02:41:58 +0800</pubDate></item><item><title>209. cs.LG-模型状态算术用于机器卸载</title><link>https://arxiv.org/pdf/2506.20941</link><description>Background: 
大型语言模型在海量网络数据上训练，其中包括私有数据、受版权保护的内容、不准确的数据或降低模型性能的数据。通过完全重新训练模型来消除这些有问题数据点的影响是非常计算密集和成本高昂的过程。因此，已经开发了卸载算法，旨在消除特定数据点的影响，同时保持模型的主要性能，而计算成本较低。然而，准确估计和逆转单个数据点的影响证明是具有挑战性的。

Innovation: 
本文提出了一种新的算法，即模型状态算术（MSA），通过利用模型检查点，即预训练过程中捕获的不同阶段模型状态的产物，来估计和逆转单个数据点的影响。实验结果表明，MSA在多个基准测试、模型和评估指标上都优于现有的卸载算法，建议MSA可能是实现更加灵活且能够进行数据擦除的大语言模型的有效方法。

Conclusion: 
MSA在多个基准测试、模型和评估指标上表现优于现有卸载算法，表明MSA可能为更灵活的大语言模型铺平道路，这些模型能够执行数据擦除。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20941</guid><pubDate>Fri, 27 Jun 2025 02:41:57 +0800</pubDate></item><item><title>210. cs.LG-Optimal Single-Policy Sample Complexity and Transient Coverage for Average-Reward Offline RL</title><link>https://arxiv.org/pdf/2506.20904</link><description>Background: 
在平均回报MDP中研究离线强化学习面临着分布转移和非均匀覆盖的挑战，相对而言，这一领域从理论角度尚未得到充分探讨。以往的工作在单一策略数据覆盖假设下获得了性能保证，但这些保证依赖于适用于所有策略的复杂性度量，如均匀混合时间。本研究旨在开发仅依赖目标策略的精确保证，并首次提出了一种仅基于单策略样本复杂度的平均回报离线RL算法。该算法能够处理一般弱连接MDP，而不受先前工作中的严格结构假设限制。研究通过引入悲观折扣值迭代算法并结合新颖的量剪辑技术，基于更精确的经验偏差函数实现这一目标。此外，研究结果表明，在这些条件下学习需要超越目标策略静止分布的覆盖假设，揭示了单策略复杂性度量与以前研究中的情况的不同之处。研究还发展出了接近主要结果的下限。总之，这些研究集中在平均回报离线RL的样本复杂性及改进的覆盖率问题上，特别是在单策略的应用上。

Innovation: 
首次提出了依赖于目标策略的精确保证，开发了首个仅基于单策略样本复杂度的平均回报离线RL算法，该算法能够在不依赖于任何先验参数知识的情况下处理一般弱连接MDP。引入了悲观折扣值迭代算法并结合了新颖的量剪辑技术，这种方法能够使用更精确的经验偏差函数。研究通过硬例证明了在这些条件下学习需要超越目标策略静止分布的覆盖假设。这一研究突破了以前工作的限制，引入了新的度量标准，为平均回报离线RL领域提供了新的理解。

Conclusion: 
研究通过引入悲观折扣值迭代算法并结合新颖的量剪辑技术，首次提出了依赖于目标策略的精确保证，并提供了首个单策略样本复杂度的平均回报离线RL算法。该研究揭示了在单策略条件下的学习需要超越目标策略静止分布的覆盖假设，并为平均回报离线RL领域的发展做出了贡献。该结果的下限接近于其主要发现，表明了该研究的高精度和深入性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20904</guid><pubDate>Fri, 27 Jun 2025 02:41:56 +0800</pubDate></item><item><title>211. cs.LG-可解释的加性规则组合的表示学习</title><link>https://arxiv.org/pdf/2506.20927</link><description>Background: 
传统的加性规则组合使用基于单个输入变量x与其阈值t之间简单阈值命题x ≥ t的结合的形式进行规则条件。这种形式从几何上确保了每个规则有很高的解释性，并且能够有效利用梯度提升方法进行学习。然而，这种形式依赖于能够访问具有表现力且最好是独立的输入特征集，以便一个小的轴平行区域组合可以很好地描述目标变量。如果缺乏这样的特征，达到足够的准确性就需要增加规则的数量和复杂性，从而削弱了模型的解释性。n

Innovation: 
本文通过引入具有学习稀疏线性变换的输入变量的逻辑命题，扩展了经典的规则组合，使得决策区域可以是作为一般多面体具有斜面的任意多面体。提出了一种基于逐步贪婪优化的迭代加权形式逻辑回归的学习方法。实验结果显示，所提出的方法能够高效地构建具有与最先进的方法相同测试风险的规则组合，同时显著地降低了模型复杂性，这在十个基准数据集上得到了验证。n

Conclusion: 
本文提出的可解释的加性规则组合方法能够在保持高解释性的同时，通过构建复杂的斜面多面体决策区域来提高准确性和性能。实际上，通过对十个基准数据集的实验，证明了该方法的有效性和高效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20927</guid><pubDate>Fri, 27 Jun 2025 02:41:54 +0800</pubDate></item><item><title>212. cs.LG-通过潜在评分生成模型进行非线性动力系统中的非局域闭模型</title><link>https://arxiv.org/pdf/2506.20771</link><description>Background: 
本文提出了一种基于潜在评分的生成AI框架，用于学习计算力学中非线性动态系统的随机且非局域封闭模型和本构定律。对于具有无明显尺度分离的复杂多层次动态系统，该工作的主要目的是解决由于所有尺度的计算分辨率都会过于昂贵而无法解决的问题，例如工程湍流流动。虽然经典的封闭模型方法使用领域知识来近似亚网格尺度现象，但在缺乏清晰尺度分离的区域中，它们的确定性与局部假设可能过于局限。最近发展起来的基于扩散的随机模型在封闭建模背景下展现出了前景，但计算推理成本的高限制了其在许多实际应用中的实用价值。本文通过在潜在空间中联合训练卷积自编码器和条件扩散模型来解决这一限制，显著降低了采样过程的维度，同时保留了重要的物理特征。数值结果表明，联合训练方法有助于发现一个合适的潜在空间，该空间不仅保证了重构误差的小，还确保了在潜在空间中的扩散模型的良好性能。整合到数值模拟中时，通过潜在条件扩散模型提出的随机建模框架提供了显著的计算加速，同时与物理空间中的标准扩散模型相比保持了相当的预测准确性。

Innovation: 
提出了一个基于潜在评分生成AI框架的方法，用于学习非线性动态系统中的随机且非局域封闭模型和本构定律。通过在潜在空间中联合训练卷积自编码器和条件扩散模型，显著降低了采样过程的维数，同时保留了重要的物理特征。这种方法在缺乏清晰的尺度分离的复杂多层次系统中，不需要明确地解析所有尺度的情况下，实现了显著的计算加速，同时保持了标准扩散模型在物理空间中的预测准确性。

Conclusion: 
提出的基于潜在条件扩散模型的随机建模框架在缺乏里程碑分隔的复杂多层次动态系统中，提供了显著的计算加速，同时保持了标准扩散模型在物理空间中的预测准确性，解决了现有方法中的计算成本过高的问题。这种方法通过显著降低维度并保持物理特征的完整性，展示了在实际应用中的显著潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20771</guid><pubDate>Fri, 27 Jun 2025 02:41:50 +0800</pubDate></item><item><title>213. cs.LG-基于图结构反馈的多模型在线自适应预测</title><link>https://arxiv.org/pdf/2506.20898</link><description>Background: 
在线自适应预测展示了解决每次输入数据点的自适应预测集（覆盖真实标签的预设概率）的能力。为应对潜在的数据分布变动，引入了多模型在线自适应预测方法，通过选择来自预先选定候选集的不同模型来增强灵活性。然而，候选集的大小也会带来挑战：大的候选集可能会增加计算复杂性，而包含性能较差的模型可能会降低性能并导致预测集过大。因此，需要一种方法来减少计算复杂性和预测集的大小，同时维护覆盖率的保证。

Innovation: 
本文提出了一种基于图结构反馈的多模型在线自适应预测算法，通过从二分图收集反馈信息选择有效的子模型集，并根据新接收的数据进行反馈信息的细化，从而减少计算复杂度并缩小预测集。此外，本文还展示了通过使用预测集大小作为反馈指标，可显著提高效率，构建更小的预测集同时满足所需的覆盖率保证。提出的算法被证明能够确保有效覆盖，并实现子线性遗憾。实验表明，本文提出的方法能够构建更小的预测集，并优于现有的多模型在线自适应预测方法。

Conclusion: 
提出的多模型在线自适应预测算法通过有效子模型集的选择及反馈机制，显著减少了计算复杂度和预测集的大小，同时保持了所需的覆盖率保证，且理论和实验验证了该方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20898</guid><pubDate>Fri, 27 Jun 2025 02:41:48 +0800</pubDate></item><item><title>214. cs.LG-输出分布重新加权对于有效类忘记的必要性</title><link>https://arxiv.org/pdf/2506.20893</link><description>Background: 
从训练好的模型中消除特定类别的记忆对于实现用户删除权利及减轻有害或偏见预测至关重要。然而，完全重新训练成本高昂，并且现有的遗忘方法无法在预测来自遗忘类别样本时复制重新训练模型的行为。已有研究通过设计一种成员身份推理攻击变种MIA-NN来证明这些方法的失效。因此，需要一种简单但有效的重新分配遗忘类预测概率的方法，以抵消MIA-NN带来的影响，并引入一种基于预测概率的总变异距离的新指标来定量评估残留泄漏，防止未来方法对该新攻击变得易感。在与现有前沿基准的广泛实验中，该方法在常用的评价指标上达到了与完全重新训练相近的效果，并且在提出的新的TV距离指标上相较于最佳现有方法有了显著改进。

Innovation: 
提出了RWFT输出重加权遗忘方法，这是一种轻量级的技术，可以在无需完全重新训练的情况下从已训练的分类器中清除整个类别。同时引入一种基于预测概率总变异距离的新评估指标，以定量评估残留泄漏。通过对比实验，RWFT的方法在常用评价指标上与全重新训练达到相当效果，并在新引入的TV距离指标上显著优于现有最佳方法。

Conclusion: 
通过对比实验表明，RWFT方法在多种评估指标上达到了与传统全重新训练相似的效果，特别是在新提出的TV距离指标上取得了显著的进步。因此，这种输出重加权遗忘方法的有效性和必要性得到了证明，为实现高效且保护隐私的机器学习提供了新的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20893</guid><pubDate>Fri, 27 Jun 2025 02:41:46 +0800</pubDate></item><item><title>215. cs.LG-为雷达资源管理提供可解释的人工智能：在深度强化学习中的改进LIME</title><link>https://arxiv.org/pdf/2506.20916</link><description>Background: 
深度强化学习在决策过程中得到了广泛的研究，并展示了比传统方法更优越的表现，特别是在雷达资源管理(RRM)领域。然而，神经网络的一个显著缺点是它们的“黑盒”性质，最近的研究重点转向了可解释的人工智能(XAI)技术来描述神经网络决策背后的理由。局部可解释通用模型解释(LIME)是一种有前景的XAI方法，但它在采样过程中忽视了特征之间的相关性。

Innovation: 
提出了一个将深度学习(DL)整合到采样过程中的改进LIME方法，命名为DL-LIME，并将其应用于雷达资源管理的深度强化学习中。实验结果表明，相比于传统的LIME，DL-LIME在准确性和任务性能上都表现更优，并提供决策中的重要因素见解

Conclusion: 
DL-LIME方法在雷达资源管理中提供了更好的可解释性和性能，揭示了哪些因素在决策中更为重要。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20916</guid><pubDate>Fri, 27 Jun 2025 02:41:45 +0800</pubDate></item><item><title>216. cs.LG-认知雷达资源管理的多目标强化学习</title><link>https://arxiv.org/pdf/2506.20853</link><description>Background: 
多功能认知雷达系统中的时间分配问题涉及到对新出现目标的搜索和对已检测目标的跟踪之间的权衡。这个问题被表述为一个多目标优化问题，并使用深度强化学习来寻找帕累托最优解。比较了深度确定性策略梯度（DDPG）和软演员-评论家（SAC）算法的有效性。通过NSGA-II算法估计考虑问题的帕累托前沿的上限，以进一步优化资源管理策略。

Innovation: 
采用深度强化学习方法，特别是使用了SAC算法来解决多目标优化问题；通过NSGA-II算法来估计帕累托前沿的上限，提高了资源管理的效率和适应性；通过对比DDPG和SAC算法，验证了SAC算法在稳定性与样本效率上的优势。

Conclusion: 
该研究提出的方法能够开发出更高效和适应性强的认知雷达系统，能够在动态环境中平衡多个竞争目标。SAC算法在稳定性和样本效率上优于DDPG算法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20853</guid><pubDate>Fri, 27 Jun 2025 02:41:44 +0800</pubDate></item><item><title>217. cs.LG-Omniwise: 利用大语言模型预测GPU内核性能</title><link>https://arxiv.org/pdf/2506.20886</link><description>Background: 
近年来，深度神经网络（DNNs）的快速发展革新了人工智能领域，使得模型能够以前所未有的能力理解和处理复杂数据。这些强大的架构已经将多种下游应用的处理能力提升到了人类难以企及的水平。本研究旨在探讨如何利用大语言模型（LLMs）对GPU内核性能进行预测，这是在性能分析方面的一个新用例。Omniwise是一个端到端、自监督的微调管道，采用大语言模型来预测GPU内核性能，无需实际执行代码或使用性能分析工具即可预测关键性能指标，如内存带宽、缓存命中率、GFLOPs和算术强度。

Innovation: 
研究引入了Omniwise，这是第一个端到端、自监督的大语言模型微调管道，用于GPU内核性能预测。Omniwise模型通用且轻量，即使使用3B参数的小型模型也能够获得优秀的预测结果，其预测关键性能指标的相对误差低于10%。该项研究还开发了在线推理服务器和Visual Studio Code插件，使得基于大语言模型的性能预测能够无缝集成到开发者的日常工作中，提高了开发效率。

Conclusion: 
Omniwise能够通过大语言模型实现对GPU内核性能的强大预测能力，无需代码执行或性能分析工具，有效地提高了性能预测的准确性和实用性，为开发者提供了一种便捷的性能优化工具。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20886</guid><pubDate>Fri, 27 Jun 2025 02:41:44 +0800</pubDate></item><item><title>218. cs.LG-FINN-GL: FPGA加速的LSTM通用混合精度扩展</title><link>https://arxiv.org/pdf/2506.20810</link><description>Background: 
循环神经网络（RNN），特别是长短期记忆网络（LSTMs），在时间序列任务如情感分析和短期股票预测方面非常有效。然而，它们的计算复杂性在资源受限的环境中进行实时部署提出了挑战。现场可编程门阵列（FPGAs）提供了一种节能的AI加速平台，但现有工具主要针对前馈网络，而LSTM加速通常需要完全定制的实现。现有解决方案无法充分利用LSTMs的特点和资源，本文研究了通过FINN框架实现LSTMs在FPGAs上的通用部署，以解决这些挑战。具体来说，利用ONNX规范中的Scan算子来建模LSTM计算的递归特性，支持混合量化并在功能验证中使用LSTM模型。

Innovation: 
本研究利用FINN框架中的Scan算子来建模递归计算特征，支持混合量化并在功能验证中使用LSTM模型。还引入了特定的转换，在FINN编译器中将量化ONNX计算图映射到HLS内核库中的硬件块和Vitis HLS。通过开发的流程训练了一个量化ConvLSTM模型以进行中期股价预测，并生成相应的硬件IP，已在XCZU7EV设备上实现了该模型。实验结果表明，所开发的流程能够在保持性能和资源消耗平衡的同时，提供与现有高精度模型相当或更优的推理准确度。这一通用的开发流程为FPGA上的RNN加速器设计铺平了道路，具有资源效率的特点。

Conclusion: 
总之，本文通过开发的工具流和FINN框架支持LSTM在FPGA上的通用部署，验证了其在性能和资源消耗之间的平衡，并展示了一种通用的设计方式，为FPGA上的RNN加速器设计提供了资源效率的实现。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20810</guid><pubDate>Fri, 27 Jun 2025 02:41:41 +0800</pubDate></item><item><title>219. cs.LG-通过网络层非均匀影响实现对抗数据的通用且高效检测</title><link>https://arxiv.org/pdf/2506.20816</link><description>Background: 
深度神经网络（DNNs）对于具有有限噪声预算的对抗性输入设计非常敏感。虽然已经提出了许多成功的攻击方法，通过对原始输入进行细微修改，但现有的防御技术相对较弱。现有防御方法主要关注提高DNN的鲁棒性或使用次要模型来检测对抗性数据。虽然后者同样重要，但该研究中重点研究的攻击检测方法相比于提升鲁棒性的方法在实际防御中更具实用性。然而，现有的检测方法要么对最新的攻击技术无效，要么在实时处理时计算效率低下。因此，该研究提出了一种新颖的方法，通过分析不同DNN层受到攻击的影响程度来检测对抗性样本。这种方法训练了一个轻量级回归模型，可以预测深层特征并根据预测误差来检测对抗样本。

Innovation: 
该研究提出了一个新颖的、通用且高效的对抗样本检测方法。通过训练轻量级回归模型，可以预测深层特征并根据预测误差来检测对抗样本。这种方法在理论论证和实验测试中表明，它不仅对最先进的攻击技术非常有效，而且在实时处理中具有高计算效率，适用于任何DNN架构并在不同领域（如图像、视频和音频）中也具有广泛的应用性。

Conclusion: 
该研究提出的检测方法不仅有效，而且在实时处理中高效，可以广泛应用于任何DNN架构并在多个领域中进行对抗样本检测。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20816</guid><pubDate>Fri, 27 Jun 2025 02:41:38 +0800</pubDate></item><item><title>220. cs.LG-精简训练，减少泄露：利用LoRA重访大语言模型细调中的记忆化现象</title><link>https://arxiv.org/pdf/2506.20856</link><description>Background: 
大语言模型（LLMs）中存储了大量的训练数据，这使得它们容易遭受数据提取攻击。尽管预训练期间的记忆化表现已经受到广泛关注，但在细调过程中，尤其是使用LoRA（低资源适配）细调时，记忆化的影响仍较少被探索。细调策略、模型规模和数据重复等因素在预训练和全面细调过程中强烈影响记忆化，但在LoRA细调中，并不符合相同的趋势。因此，需要重新审视细调中的记忆化现象及其对模型性能的影响。

Innovation: 
该研究利用一个更宽松的基于相似性的记忆化衡量标准，发现LoRA相比全面细调显著降低了记忆化风险，同时保持了强大的任务性能。这一发现展示了LoRA在减少记忆化风险方面的优势，这对于保护模型免受数据泄露攻击至关重要。

Conclusion: 
该研究结果表明，LoRA在细调过程中显著减少了记忆化风险，同时仍保持了优异的任务表现。这为在保持模型性能的同时减少存储风险提供了新的视角。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20856</guid><pubDate>Fri, 27 Jun 2025 02:41:34 +0800</pubDate></item><item><title>221. cs.LG-基于学习的集成感知与通信系统资源管理</title><link>https://arxiv.org/pdf/2506.20849</link><description>Background: 
本文探讨了在配备有雷达和通信单元的集成感知与通信系统中超适应时间分配的任务。这种双功能雷达-通信系统需要根据目标进行跟踪，并在完成后将剩余时间用于向估计的目标位置进行数据传输。因此，该系统需要在时间预算的约束下合理分配跟踪和通信资源，以提高目标通信质量，特别是在动态环境中。

Innovation: 
本文提出了一种新颖的约束深度强化学习（CDRL）方法，旨在在时间预算约束下优化跟踪和通信资源之间的分配，从而提高目标通信质量。实验证明了所提出的CDRL框架的有效性，能够最大化快速变化环境中通信质量，同时遵守时间限制。

Conclusion: 
本文通过对CDRL框架的引入和验证，成功展示了其在动态环境中高效管理雷达-通信系统资源的能力，为集成感知与通信系统的优化设计提供了新的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20849</guid><pubDate>Fri, 27 Jun 2025 02:41:32 +0800</pubDate></item><item><title>222. cs.LG-GPU Kernel Scientist: 一种基于LLM的迭代内核优化框架</title><link>https://arxiv.org/pdf/2506.20807</link><description>Background: 
优化GPU内核以实现高性能是一项复杂任务，通常需要深厚的知识架构理解、广泛的性能分析以及迭代的实验。这一挑战在针对新或较少记录的GPU架构时尤为突出，因为传统的开发工具在此类架构上较少。

Innovation: 
本文提出了一种名为“GPU内核科学家”的基于LLM（大型语言模型）的自动化方法，用于迭代细化加速器内核。方法采用多阶段进化过程：(a) 战略性选择前景良好的先前代码版本作为新迭代的基础；(b) 基于现有代码和从通用GPU文献中吸收的知识生成优化假设；(c) 通过代码修改和向外部评估系统提交，自主进行这些实验，仅使用观察到的时间数据作为性能反馈。本文展示了这种做法如何导航AMD MI300目标架构的挑战，并利用LLM弥补有限的特定领域的专业知识缺口。

Conclusion: 
由于正在进行的性能比赛的具体结果在提交日期被禁止公开，本文展示了体系结构设计、操作流程和定性的见解，强调了基于LLM的代理如何在资源受限或快速发展的硬件环境中，促进GPU内核优化的民主化和加速。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20807</guid><pubDate>Fri, 27 Jun 2025 02:41:32 +0800</pubDate></item><item><title>223. cs.LG-分布式训练图神经网络的揭秘</title><link>https://arxiv.org/pdf/2506.20818</link><description>Background: 
图神经网络（GNNs）是解决图相关问题的强大工具。分布式GNN框架和系统提高了GNN的可扩展性并加速了模型训练，但大多数框架和系统都针对节点分类进行了优化，而对链接预测的研究较少。本文通过研究每个工作者仅在其分配的子图上训练GNN而不访问整个图时，性能下降的问题来探讨分布式训练GNN进行链接预测的技术挑战。主要原因包括图分区造成的信息丢失和模型训练期间负样本的选择方式。

Innovation: 
提出了SpLPG，一种有效利用图稀疏化的方法，以减少性能下降的问题，同时减少通信成本。SpLPG通过减少约80%的通信开销，主要保持链接预测的准确性来解决上述问题，从而降低通信成本并提升了链接预测的准确性。

Conclusion: 
实验结果表明，SpLPG在多个公开的真实世界数据集上具有有效性，减少了约80%的通信开销，同时在大部分情况下保持了链接预测的准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20818</guid><pubDate>Fri, 27 Jun 2025 02:41:32 +0800</pubDate></item><item><title>224. cs.LG-微缩格式中训练不稳定性特征与缓解</title><link>https://arxiv.org/pdf/2506.20752</link><description>Background: 
训练大型语言模型是一个计算密集型且成本高昂的过程，随着时间推移，模型规模扩大，算法改进以及新数据的收集，此过程需要不断重复。随着下一代硬件加速器对低精度算术格式的支持增加，如NVIDIA Blackwell架构引入的微缩（MX）格式，这些格式通过在参数块中共享缩放来扩展可表示范围，并在降低精度下进行前向/后向GEMM操作以提高效率。然而，使用这些格式进行模型训练时会遇到尖锐的、随机的损失不稳定现象，尤其是在计算规模较大时。为了探讨这些问题和解决方案，论文在一个大小与语言模型相似的代理模型中进行了一系列有控制的实验，并研究了不同架构设置、超参数和精度格式的影响。这些研究表明，乘性梯度偏差可能是由层级归一化仿射参数和一部分激活的量化引入的，从而使训练过程发生发散。通过在代理模型中实施原位干预实验，结果显示可以做出调整来避免或延缓这些不稳定性。这些发现促使作者评估了大型语言模型下的稳定化策略，发现某些混合配置在性能上可与全精度训练媲美。论文最后提供了代码库。

Innovation: 
论文研究了使用微缩（MX）格式进行大型语言模型训练时遇到的尖锐、随机的损失不稳定现象，并通过代理模型的实验探讨了一种潜在的机制，即梯度偏差导致的发散。同时，论文展示了通过调整精度方案可以在训练中期缓解这些不稳定性，从而提高模型的训练性能。

Conclusion: 
通过代理模型的实验揭示了微缩格式训练中不稳定性的潜在机制，并展示了通过调整精度方案可以缓解这些不稳定性。特定的混合配置表现出了与全精度训练相竞争的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20752</guid><pubDate>Fri, 27 Jun 2025 02:41:31 +0800</pubDate></item><item><title>225. cs.LG-Diffusion Tree Sampling: 高效的扩散模型推理时对齐方法</title><link>https://arxiv.org/pdf/2506.20701</link><description>Background: 
在生成模型中，如何在推理时调整预训练的扩散模型以适应新的目标仍是一个待解决的问题。现有的引导方法在高噪声情况下存在准确度低的问题，进而导致偏差。此外，以前运行中的信息没有被重用以提高样本质量，这导致了计算资源的低效使用。n

Innovation: 
本文受到蒙特卡罗树搜索成功的启发，将推理时的对齐问题重新定义为一个当前通行的计算结果可以被重用的搜索问题。提出了一种基于树的方法，通过从奖励对齐的目标密度中采样，并在每次迭代中改进价值估计来进行扩散链的反向传播。方法名为Diffusion Tree Sampling (DTS)，其贪婪变体Diffusion Tree Search (DTS$^text{?textstar}$) 可以全局搜索高奖励样本。实验表明，DTS和DTS$^text{?textstar}$分别在MNIST和CIFAR-10类条件生成和文本到图像生成任务中以比竞争基线少10倍和5倍的计算成本达到几乎相同的效果。n

Conclusion: 
通过从之前的迭代中重新使用信息，作者提出的方法提供了一种可随时改进生成模型性能的算法，进一步证明了扩散模型在推理时对齐的可扩展方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20701</guid><pubDate>Fri, 27 Jun 2025 02:41:27 +0800</pubDate></item><item><title>226. cs.LG-分割，专业化和路由：一种高效的集成学习新方法</title><link>https://arxiv.org/pdf/2506.20814</link><description>Background: 
集成学习已被证明能够提升预测性能，但传统的集成方法如袋装、提升和动态集成选择在计算成本高和对异质数据分布适应性有限方面存在问题。

Innovation: 
提出了一种名为Hellsemble的新颖且可解释的二分类集成框架，该框架在训练和推理期间利用数据集复杂性，通过迭代传递错误分类的实例以形成专业化基础学习者的委员会。每个模型在不断难度增大的子集上进行训练，而一个独立的路由模型学习基于推断的难度为新实例指派最合适的基础模型。Hellsemble在保持计算效率和可解释性的同时实现了强大的分类精度。实验结果表明，Hellsemble在OpenML-CC18和Tabzilla基准上通常优于经典集成方法，进一步表明在实例难度层面采取措施是构建高效和稳健集成系统的一个有前景的方向。

Conclusion: 
实验结果表明Hellsemble在开放基准OpenML-CC18和Tabzilla中经常优于经典集成方法，这表明根据实例难度构建集成系统具有广阔前景。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20814</guid><pubDate>Fri, 27 Jun 2025 02:41:24 +0800</pubDate></item><item><title>227. cs.LG-关于背景-内容不确定性原理</title><link>https://arxiv.org/pdf/2506.20699</link><description>Background: 
论文提出了背景-内容不确定性原理（CCUP），认为在不确定性推理中，高熵背景必须通过与低熵、结构化内容的对齐来进行解释。该原理揭示了背景和内容之间的熵不对称性，提出了通过结构化内容进行方向性熵最小化的推理原则。在这篇文章中，作者构建了一个分层计算框架，从这一基本原则出发，提出了一系列操作原则。这一框架旨在提供一种统一的理论基础，解释人脑和机器如何通过递归结构-特异性对齐来最小化不确定性。

Innovation: 
文章开发了多层次的操作原则框架，包括四个层次：核心推理约束、资源分配原则、时间引导下的制动器动态和空间层级组成。这些原则是从背景-内容不确定性原则推导出来的，并展示了它们之间的可还原性。文章还提出了形式等价定理和操作原则之间的依赖层次结构，并通过计算模拟展示了CCUP对推理效率的提升。

Conclusion: 
这篇文章为理解大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了一个统一的理论基础。不仅大脑是推理机器，它还是一个路径依赖的、内容引导的熵梯度解算器，通过结构和特异性的对齐来进行模拟。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20699</guid><pubDate>Fri, 27 Jun 2025 02:41:23 +0800</pubDate></item><item><title>228. cs.LG-随机参数分解</title><link>https://arxiv.org/pdf/2506.20790</link><description>Background: 
反向工程神经网络的关键步骤之一是将它们分解为更简单的部分，以便可以相对独立地研究。一种被称为线性参数分解的框架已经提出，旨在解决当前分解方法的一些问题，它将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，这种方法中的主要方法基归因参数分解（APD）由于其计算成本和对超参数的敏感性而不可行。本文介绍了随机参数分解（SPD），这是一种比APD更可扩展且对超参数更鲁棒的方法，通过分解稍大且更复杂的模型来展示这一点。此外，还表明SPD避免了其他问题，如学习参数的收缩，且在玩具模型中更好地识别了真实机制。通过将因果中介分析与网络分解方法相结合，这项演示消除了将线性参数分解方法扩展到更大模型的障碍，从而在机制可解释性方面开拓了新的研究可能性。我们发布了运行SPD和再现实验的库，请访问this https URL.

Innovation: 
本文提出了随机参数分解（SPD）方法，这是一种比现有的基归因参数分解（APD）更可扩展且更鲁棒的方法，能处理稍大且更复杂的模型，并避免了如学习参数收缩等问题，同时能更准确地识别真实机制。

Conclusion: 
通过结合因果中介分析和网络分解方法，SPD为机制可解释性提供了新的研究可能性，解决了现有方法在处理较大模型时遇到的障碍。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20790</guid><pubDate>Fri, 27 Jun 2025 02:41:22 +0800</pubDate></item><item><title>229. cs.LG-多种关系提取流：Transformer中的丰富和回忆</title><link>https://arxiv.org/pdf/2506.20746</link><description>Background: 
当大语言模型（LLM）在微调过程中学习一种关系（如新发布的电影、企业并购等），这些信息会存储到哪里？是当你处理实体时进行提取的，还是在预测前实时回忆起来的，又或者存在多种分散的启发式规则？现有的定位方法（例如激活补丁）并不适合这种分析，因为它们往往会替换残差流的一部分，可能导致信息丢失。本文探讨微调语言模型在处理实体时提取在微调过程中学习的关系信息，以及在后期生成预测时回忆这些信息的过程，并发现一种双重路径，即一些情况下需要同时使用信息提取和回忆路径来正确生成微调后的信息，而在其他情况下，单独使用其中一种路径就足够了。研究还检查了这些信息路径的必要性和充分性，以及它们发生在哪个层级，与其他冗余度和模型组件的关联情况，其中的“回忆”路径通过任务特定的注意机制和注意与前馈网络的最终层之前预测中的关系提取步骤达成。

Innovation: 
为了填补现有方法的空白，本文提出了动态权重嫁接技术，该技术展示了微调后的语言模型不仅在处理实体时抽取在微调过程中学到的关系信息，还在预测过程中回忆这些信息。结果显示，在一些情况下，模型需要同时这两条路径来正确产生微调后的信息，而在其他情况下，单独使用其中一种路径就足够了。研究进一步探讨了这些信息路径的必要性和充分性，发现“回忆”路径通过任务特定的注意机制和最终层前馈网络中的关系提取步骤完成。

Conclusion: 
研究发现，微调后的语言模型在处理特定任务时，采用两种主要路径来处理学习到的关系信息：一类路径是在处理实体时进行关系信息的直接抽取，另一类路径是在预测生成过程中利用已学习到的关系信息进行恢复与回忆。学科研究表明，这两种方法在某些情况下是独立的，在其他情况下，两者同时作用以促进准确的预测生成。通过这种探讨，我们能更深入地理解微调模型如何利用学习到的信息进行预测以及其底层机制。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20746</guid><pubDate>Fri, 27 Jun 2025 02:41:22 +0800</pubDate></item><item><title>230. cs.LG-AI for Materials Science: 基础模型、大语言模型代理、数据集和工具综述</title><link>https://arxiv.org/pdf/2506.20743</link><description>Background: 
基础模型（FMs）正在推动材料科学（MatSci）的变革性转变，通过启用广泛的、通用的和多模态的AI系统来促进科学发现。FMs的优点包括跨领域的普遍适用性和新兴能力，尤其适用于涉及多种数据类型和规模的研究挑战。本文综述了基础模型、代理系统、数据集和计算工具，这些都为该快速发展领域提供了全面概述。

Innovation: 
本文介绍了基础模型和大语言模型（LLM）代理的最新进展，以及标准化数据集、开源工具和自主实验平台的综述，这些共同促进了FMs的研发和整合到研究工作流程中。同时，也探讨了诸如普遍性、可解释性、数据不平衡、安全问题和多模态融合限制等持续存在的障碍。

Conclusion: 
为优化FMs，本文建议的重点领域包括可扩展的预训练、连续学习、数据治理和可靠性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20743</guid><pubDate>Fri, 27 Jun 2025 02:41:14 +0800</pubDate></item><item><title>231. cs.LG-关于卷积、固有维度和扩散模型</title><link>https://arxiv.org/pdf/2506.20705</link><description>Background: 
曼德ifold假设指出，在高维空间中的数据，例如图像数据，实际存在于未被确定的低维子流形上。扩散模型（DMs）通过逐步将数据与越来越多的高斯噪声进行卷积，然后学习逆转这一过程，已成为最优秀的生成模型之一，并且已知能够学习低维支持的分布。对于这些子流形中的任意数据点，我们直观上期望DMs能够隐式地学习其对应的地方固有维度（LID），即它所属的子流形的维度。Kamkari等人（2024b）最近通过将LID与DM的对数边缘密度随添加噪声量的变化率联系起来，证明了这一点，并由此创建了一个LID估计器FLIPD。FLIPD在LID估计方面取得了最先进的性能，但其理论基石尚不完整，因为Kamkari等人（2024b）仅在假设线性子流形的情况下证明了其正确性。本文旨在通过在更合理的假设下正式证明FLIPD的正确性来弥补这一差距。此外，还展示了当用均匀卷积替换高斯卷积时类似的结果，并讨论了这一结果的相关性。

Innovation: 
本文通过在更现实的假设下正式证明FLIPD的正确性，弥合金德cordi等人（2024b）在理论上的不足，并展示了替换高斯卷积为均匀卷积时类似的结果。这一研究填补了理论上的空白，为扩散模型的进一步研究提供了支持。

Conclusion: 
本文通过证明FLIPD在非线性子流形假设下的正确性，以及在高斯卷积被替换为均匀卷积时的等效性，解决了理论上的缺口，并讨论了其在数据复杂度度量和异常检测等方面的潜在应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20705</guid><pubDate>Fri, 27 Jun 2025 02:41:14 +0800</pubDate></item><item><title>232. cs.CV-SoK:合成图像能否替代真实数据？合成图像生成的实用性和隐私性调查</title><link>https://arxiv.org/pdf/2506.19360</link><description>Background: 
生成模型的进步已经彻底改变了隐私保护数据合成（PPDS）中的合成图像生成领域。然而，该领域缺乏对不同情境下合成图像生成方法的全面调查和比较。特别是在为了训练分类器生成合成图像的情况下，存在生成-采样-分类的管道，该管道以私有训练数据为输入并输出所需的最终分类器。本文旨在系统地对现有图像合成方法、隐私攻击和缓解措施进行分类，以沿着生成-采样-分类管道进行比较。为比较多种合成方法，提供了一个包含代表性生成方法的基准，并使用模型无关的成员 inference攻击（MIA）作为隐私风险的衡量标准。该研究旨在回答PPDS中一些关键问题：合成数据能否有效替代真实数据？哪种数据发布策略能平衡实用性和隐私性？缓解措施是否改善了实用性和隐私性之间的权衡？哪种生成模型在不同场景中表现最佳？通过系统评估多种方法，本文为合成数据生成方法的实用性和隐私间权衡提供实际见解，并指导如何为实际应用选择最佳数据发布策略。

Innovation: 
本文的研究创新在于它系统地梳理了合成图像生成方法的分类、隐私攻击的对抗措施以及实际应用中的表现，并通过实验比较不同合成方法的效果。使用模型无关的成员 inference攻击作为衡量隐私风险的标准，进一步揭示了合成数据生成在实用性和隐私间的权衡问题，为实际应用中的数据释放策略提供指导。

Conclusion: 
通过系统评估各种方法，本文为合成数据生成方法在实用性和隐私权衡中的具体应用提供了实际见解，并为实际应用中的数据释放策略提供了指导。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19360</guid><pubDate>Fri, 27 Jun 2025 02:41:13 +0800</pubDate></item><item><title>233. cs.LG-渐进而又基于大小自适应的联邦学习：一个多模态数据系统的全面框架</title><link>https://arxiv.org/pdf/2506.20685</link><description>Background: 
联邦学习作为一种保护数据隐私的分布式机器学习范式已经崭露头角。然而，现有的方法主要关注模型异质性和聚合技术，对数据集大小特征对联邦训练动态的基本影响重视不足。本文综合评估了13个不同数据集，涵盖了7种模态（视觉、文本、时间序列、音频、传感器、医疗视觉和多模态），发现了几个关键见解：1) 针对联邦学习效果的最优数据集大小范围为1000-1500样本；2) 结构化数据（时间序列、传感器）的表现明显优于非结构化数据（文本、多模态）；3) 对于超过2000样本的大数据集，性能呈现系统性的下降趋势。现有方法在所有数据集上实现了平均87.68%的准确率，结构化数据达到99%以上的准确率。

Innovation: 
本文提出了基于数据大小自适应的渐进联邦学习（SAFL）框架，这是一种系统性地基于跨异质多模态数据的数据集大小特征组织联邦学习的新颖训练框架。SAFL框架在所有数据集上达到了平均87.68%的准确率，特别是对于结构化数据模态，其准确率达到了99%以上。此外，该框架显示了优异的通信效率，通过558次通信实现总数据传输7.38 GB，同时保持了高性能。实时监测框架为系统资源利用率、网络效率和训练动力学提供了前所未有的洞察。SAFL框架填补了理解数据特征应当如何驱动联邦学习策略的知识空白，提供了理论洞察和实际指导，以支持实际部署中的联邦学习应用和学习系统中的神经网络。

Conclusion: 
本文通过综合实验评估，揭示了关键数据集大小特征对联邦学习效果的影响，证明了渐进而又基于大小自适应的联邦学习框架的有效性和优越性，同时提供了宝贵的理论洞察和实际指导，为实际部署中的联邦学习策略提供了支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20685</guid><pubDate>Fri, 27 Jun 2025 02:41:11 +0800</pubDate></item><item><title>234. cs.LG-在理论物理学中的测试时间缩放技术 -- TPBench数据集上的方法比较</title><link>https://arxiv.org/pdf/2506.20729</link><description>Background: 
大规模语言模型（LLMs）在复杂推理方面展现了强大的能力，测试时缩放技术可以以相对较低的成本提升其性能。这些方法主要在诸如AIME之类的数学推理基准测试中开发和评估。本文探讨了这些从数学推理基准中学到的经验教训是否能推广到高级理论物理领域。通过评价一系列常见的测试时缩放方法在TPBench物理数据集上的效果，并将结果与AIME进行比较，以更好地利用物理问题的结构，我们开发了一种新颖的符号弱验证框架，以改善并行缩放结果。

Innovation: 
我们开发了一种新型的符号弱验证框架来提高并行缩放结果。我们的实验证明，该方法在TPBench上的效果显著优于现有测试时缩放方法。此外，我们在AIME上对该方法进行评估，进一步证实了其在解决高级数学问题上的有效性。

Conclusion: 
我们的研究结果表明，逐步符号验证可以有效地应对复杂的科学问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20729</guid><pubDate>Fri, 27 Jun 2025 02:41:10 +0800</pubDate></item><item><title>235. cs.CV-DSA-NRP：基于血管造影灌注动力学的中风取栓术后无复流预测</title><link>https://arxiv.org/pdf/2506.17501</link><description>Background: 
对于通过血管内取栓（EVT）成功治疗急性缺血性中风（AIS）的患者，可能会出现一种名为无复流的并发症，它导致微血管灌注持续减少，对组织恢复不利并恶化临床结果。尽管早期识别非常重要，但标准临床实践中仍依赖于术后24小时内进行的灌注磁共振成像（MRI），导致干预延迟。因此，亟需能够实时预测无复流的方法，以便及时干预。本研究的目的就是通过利用此前未被探索的术中数字减影血管造影（DSA）序列和临床变量，构建首个预测术后无复流的机器学习模型。

Innovation: 
首次提出了利用术中数字减影血管造影（DSA）序列和临床变量构建的机器学习框架，用于在血管内取栓术（EVT）后实时预测无复流。该方法显著优于基于临床特征的基准模型，在AUC和准确率方面均有显著提升，并证明了DSA实时灌注动力学对于微血管完整性的关键洞察价值。这为即时、准确地预测无复流提供了基础，使临床医生可以更积极地管理高风险患者，而不必依赖延迟的影像学检查。

Conclusion: 
通过引入新的机器学习模型，利用术中DSA灌注动力学数据，可以实现对无复流的即时预测，从而帮助临床医生更早地对高风险患者进行干预，改善患者预后。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17501</guid><pubDate>Fri, 27 Jun 2025 02:41:03 +0800</pubDate></item><item><title>236. cs.LG-E-ABIN：生物网络中可解释的异常检测模块</title><link>https://arxiv.org/pdf/2506.20693</link><description>Background: 
随着大规模组学数据的可用性增加，迫切需要稳健的分析框架来处理复杂的基因表达数据集并提供可解释的结果。最近的人工智能进展使得辨别疾病状态与健康对照之间的异常分子模式成为可能，并且随着模型解释性的提高，这些工具现在能够支持发现驱动疾病表型的基因。然而，当前的基因异常检测方法通常局限于单一数据集，并且缺乏易于访问的图形界面。因此，现有的方法在这里遇到了局限性。

Innovation: 
本文介绍了E-ABIN，这是一种通用且可解释的生物网络异常检测框架。它结合了经典机器学习和图基深度学习技术，并提供了一个统一且用户友好的平台，用于从基因表达或甲基化衍生的网络中检测和解释异常。通过集成支持向量机、随机森林、图自动编码器和图对抗属性网络等算法，E-ABIN在保持解释性的同时实现了高预测准确性。

Conclusion: 
我们在膀胱癌和乳糜泻研究中的案例研究表明，E-ABIN可以有效地揭示生物学相关异常并提供对疾病机制的见解。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20693</guid><pubDate>Fri, 27 Jun 2025 02:41:02 +0800</pubDate></item><item><title>237. cs.CV-基于RGB感知的共识驱动不确定性机器人抓取</title><link>https://arxiv.org/pdf/2506.20045</link><description>Background: 
目前基于图像的物体姿态估计器往往过于自信。一个既估计目标物体6自由度姿态又预测自身估计不确定性的人工智能抓取系统，在高不确定性条件下可以选择不采取行动以避免任务失败。尽管物体姿态估计和不确定性量化研究取得了进展，但很少将这两方面与机器人的抓取下游任务联系起来。

Innovation: 
提出了一种轻量级深度网络的训练方法，可以在使用图像估计的姿态指导抓取之前预测抓取成功率。通过在实际图像上的物体姿态估计和模拟抓取生成网络训练数据。研究发现，尽管抓取试验中存在高物体变异性，但网络在所有物体共同训练时能从中受益，表明多样化的物体可以从相同的任务中获益

Conclusion: 
这种方法将物体姿态估计和不确定性量化直接应用于抓取任务，提高了抓取成功率，特别是在高不确定性条件下。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20045</guid><pubDate>Fri, 27 Jun 2025 02:41:00 +0800</pubDate></item><item><title>238. cs.CV-TCDiff++: 一种用于和谐音乐驱动群舞编排的端到端轨迹可控扩散模型</title><link>https://arxiv.org/pdf/2506.18671</link><description>Background: 
音乐驱动的舞蹈生成因其广泛的应用前景，特别是在群舞创作中，已经引起了广泛关注。然而，在群舞生成过程中，大多数现有方法仍然面临着多舞者碰撞、单个舞者脚滑动以及生成长段群舞中的突然交换等三大主要问题。这些挑战限制了舞蹈生成的质量和连贯性，尤其是在长时间场景中的表现。

Innovation: 
本文提出了一种名为TCDiff++的音乐驱动的端到端框架，旨在生成和谐的群舞。为了解决多舞者碰撞的问题，引入了舞者位置嵌入以更好地保持舞者之间的相对位置。通过引入距离一致性损失，确保舞者之间的距离在实际范围内。为解决单个舞者脚滑动的问题，提出了一种交换模式嵌入来指示舞者交换模式，并设计了一个步法适配器以改进原始动作，从而减少脚滑动。针对长群舞生成，提出了一种长群扩散采样策略，通过向噪声输入注入位置信息，减少突然的位置变换。进一步引入序列解码器层，增强模型处理长时间序列的能力。实验证明，TCDiff++在长场次场景中达到了最先进的性能，确保了高质量和一致性的群舞生成。

Conclusion: 
TCDiff++在解决舞蹈生成中的挑战方面表现优异，特别是在长期应场景中实现了高质量和连贯性的群舞生成。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18671</guid><pubDate>Fri, 27 Jun 2025 02:41:00 +0800</pubDate></item><item><title>239. cs.CV-Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning</title><link>https://arxiv.org/pdf/2506.13056</link><description>Background: 
近年来，大型语言模型（LLMs）的发展促进了高级推理范式的涌现，这些范式现在被整合到多模态大型语言模型（MLLMs）中。然而，现有的方法往往存在不足：仅使用强化学习（RL）的方法可能会遇到样本效率低和激活不存在的推理能力的问题；而传统的工作流则在强化学习阶段之前采用冷启动的监督微调（SFT）阶段，这可能会限制模型的探索能力和造成次优的收敛性。

Innovation: 
本文介绍了一种名为Metis-RISE的方法，它独特的去掉了初始的SFT阶段，而是从RL阶段（例如，使用Group Relative Policy Optimization的变体）开始，来激励和激活模型的潜在推理能力。随后，为了应对RL阶段识别出的两个关键挑战：（1）对于模型具备但不一致应用的正确推理，任务中的低效轨迹采样；（2）对于模型完全失败的领域，缺失的根本能力，采用自本身的RL模型生成自提练的推理轨迹以及注入专家增强的知识来解决。这种将RL用于激励，随后SFT用于增强的策略是Metis-RISE的核心，催生了两个版本的MLLMs（分别有7B和72B参数）。

Conclusion: 
在OpenCompass多模态推理排行榜上的评估表明，两种模型均实现了在同规模模型中的最佳性能，72B参数版本排名第四。更多详细信息请参阅我们的开源项目页面。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13056</guid><pubDate>Fri, 27 Jun 2025 02:40:58 +0800</pubDate></item><item><title>240. cs.CV-Variational Supervised Contrastive Learning</title><link>https://arxiv.org/pdf/2506.07413</link><description>Background: 
对比学习已被证明在各种模态中通过聚类相似样本和推离不相似样本来高效地塑造表示空间。然而，仍然存在两个关键限制：(1) 除非互补信号指导配对选择，否则在没有明确调节嵌入分布的情况下，语义相关的实例可能会意外地被推离；(2) 过度依赖大规模批次内的负样本和定制的增强措施妨碍了泛化能力的提升。

Innovation: 
我们提出了变分监督对比学习（VarCon），它将监督对比学习重新表述为在潜在类别变量上的变分推理，并通过最大化带后验加权的良好证据下界（ELBO）来最大化内类分散度，这取代了耗时的配对比较，实现了类意识的匹配，提供了对嵌入空间内的类分散度的精细控制。VarCon 在仅使用图像数据的情况下，在 CIFAR-10，CIFAR-100，ImageNet-100 和 ImageNet-1K 的实验中表现出色。

Conclusion: 
VarCon 达到了对比学习框架的最新性能，在 ImageNet-1K 上达到了 79.36% 的 Top-1 准确率，CIFAR-100 达到 78.29%，使用 ResNet-50 编码器仅需 200 个epochs。VarCon 的决策边界更为清晰，语义组织更为明确，对于少样本学习表现出更优的效果，并且具有优于不同增强策略的鲁棒性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07413</guid><pubDate>Fri, 27 Jun 2025 02:40:57 +0800</pubDate></item><item><title>241. cs.CV-BlenderFusion：基于3D的视觉编辑和生成合成</title><link>https://arxiv.org/pdf/2506.17450</link><description>Background: 
现有合成方法主要依赖于直接合成新场景，缺乏一种既能对3D实体进行编辑又能灵活地重组对象、摄像机和背景的框架。BlenderFusion提供了一种生成性的视觉合成框架，通过重新组合对象、摄像机和背景来合成新的场景。它采用了分割和转换视觉输入为可编辑的3D实体、在Blender中使用3D接地编辑以及使用生成合并器融合场景的层编辑融合流程。

Innovation: 
BlenderFusion的主要创新点在于其使用预训练的扩散模型进行并行处理原始场景和编辑场景，并通过两种训练策略：背景替换的灵活修改和对象与摄像机的独立控制，进一步提升了模型的准确性。这些策略使得BlenderFusion在复杂组成场景编辑任务中显著优于先前的方法。

Conclusion: 
BlenderFusion框架展示了在3D接地视觉编辑和生成性合成方面的优越能力，特别是在处理复杂组成场景编辑任务时，极大地提升了性能，为未来研究提供了新的方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17450</guid><pubDate>Fri, 27 Jun 2025 02:40:56 +0800</pubDate></item><item><title>242. cs.CV-CREStE: 使用互联网规模先验和反事实指引的可扩展地图无关导航</title><link>https://arxiv.org/pdf/2503.03921</link><description>Background: 
这篇论文的背景是针对户外城市导航中的开放世界泛化和鲁棒性挑战。研究者们希望提出一种能够应对新出现的语义类别、地形和动态实体等开放集因素的地图无关导航框架。传统的导航方法通常依赖地图数据，但对于复杂多变的城市环境来说并不适用。因此，需要一种新的框架，能够在没有地图的情况下进行有效的导航，同时具备泛化能力和稳定性。

Innovation: 
论文的创新之处在于提出了CREStE，一种学习基于感知的架构，它包括两个关键点：1) 一种视觉基础模型（VFM）的蒸馏目标，用于学习开放集结构的鸟瞰图感知表示；2) 一种新颖的反事实逆强化学习（IRL）方法，通过反事实轨迹示例推理导航成本时找到最重要的线索。这种方法可以利用有限的人工演示来推断导航成本，提高了导航的效率和准确性。

Conclusion: 
研究者评估了CREStE在不同城市、非城市和住宅环境中的千米级地图无关导航任务，发现它比最先进的方法少70%的人工干预，甚至在完全未知环境中执行2千米任务只需要1次干预。这表明CREStE能够实现长期规划的地图无关导航，并展示了其鲁棒性和有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.03921</guid><pubDate>Fri, 27 Jun 2025 02:40:55 +0800</pubDate></item><item><title>243. cs.CV-Chain-of-Sketch: 推动全局视觉推理</title><link>https://arxiv.org/pdf/2410.08165</link><description>Background: 
现代视觉模型在提供目标关键信息的局部特征的基准任务中取得了显著的成功。然而，对于需要更全局推理的任务，局部特征提供的信息并不显著。Minsky 和 Papert 在1969年的研究中提出了这样的任务，揭示了感知器模型的局限性。本文通过引入涉及图形、字符串、迷宫和图像网格的全球视觉数据集，展示了大型视觉模型在这些任务上学习效率不高，并且最先进的多模态大模型在这些数据集中的表现也很差。通过‘全局性度量’来解释这种学习效率低下。

Innovation: 
本文提出了一种名为‘chain-of-sketch (CoS)’的方法。该方法类似于语言模型中的chain-of-thought和scratchpad技术，将原始任务分解为中间视觉步骤，以帮助学习复杂的任务。同时，本文还指出并非所有CoS策略都表现相同，提出了在CoS帧上施加马尔可夫结构的‘诱导性CoS’策略，这种策略在离分布泛化方面表现更好，并且对于小型模型同样有效。

Conclusion: 
研究表明，施加马尔可夫结构的诱导性CoS策略在离分布泛化方面表现出色，甚至在较小的模型上也能表现出良好的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.08165</guid><pubDate>Fri, 27 Jun 2025 02:40:51 +0800</pubDate></item><item><title>244. cs.CV-始终跳过注意力机制</title><link>https://arxiv.org/pdf/2505.01996</link><description>Background: 
本文探讨了现代视觉变换器（ViTs）中一个令人惊讶的经验结果，即自我注意力机制只有在与跳连连接一起使用时才能成功训练，与其他ViT组件相比，自我注意力机制在移除跳连连接后表现仍然不佳，这与其他深度架构（如CNNs）不同，后者在缺少跳连的情况下仍能良好工作。进一步研究发现，将自我注意力机制与跳连连接相结合的现象是一种相对新的现象，之前的深度架构即便没有跳连也能保持良好的性能。理论表明，自我注意力机制本身是病态的，需要依赖跳连连接来实现正则化效果。为了改善这一情况，提出了一种简单且有效的解决方案，即Token Graying，它能进一步改善输入令牌的条件，同时作为跳连连接的补充使用。该方法已在监督学习和自我监督学习中得到了验证。

Innovation: 
本文首次理论说明自我注意力机制需要依赖跳连连接才能正常运作，并提出了Token Graying作为跳连连接的补充，理论上改善了输入令牌的条件，使得自我注意力机制在不依赖跳连的情况下也能表现出更佳的性能。

Conclusion: 
通过引入Token Graying，作者证明了即使在移除跳连连接的情况下，自我注意力机制也能保持较好的训练效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.01996</guid><pubDate>Fri, 27 Jun 2025 02:40:50 +0800</pubDate></item><item><title>245. cs.CV-HUG: 基于块重建的分层城市高斯点绘制技术在大规模空中场景中的应用</title><link>https://arxiv.org/pdf/2504.16606</link><description>Background: 
3DGS（三维生成合成）是一种在新型视图合成领域新兴且日益流行的技术。它的高度真实的渲染质量和实时渲染能力使其在各种应用中都具有潜力。然而，当将3DGS应用于大规模的城市空中场景时，会面临内存消耗过高、训练时间过长、分区过程耗时以及由于数据量增加而导致渲染质量显著下降等问题。

Innovation: 
我们提出了HUG（Hierarchical Urban Gaussian）一种新颖的方法，通过利用分层神经高斯表示来增强数据分区和重建质量。首先，我们提出了一种基于可见性的数据分区方法，该方法简单高效，并显著优于现有方法。其次，我们引入了一种基于块的分层加权训练方法，与其他优化策略相结合，以显著提高重建质量。该方法在合成数据集和四个真实世界数据集上达到了最先进的结果。

Conclusion: 
我们的方法在大规模城市空中场景中使用分层城市高斯点绘制技术，通过分层神经高斯表示增强数据分区和重建质量，解决了现有的3DGS方法在大规模空中场景中面临的问题，并达到了最先进的重建效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.16606</guid><pubDate>Fri, 27 Jun 2025 02:40:50 +0800</pubDate></item><item><title>246. cs.CV-Score-based 生成模型的正則化Outer Moderating the Generalization of Score-based Generative Model</title><link>https://arxiv.org/pdf/2412.07229</link><description>Background: 
分数为基础的生成模型（SGMs）已经在生成未见过但自然的数据方面展现了卓越的泛化能力。然而，随着泛化能力的增强，不可避免地增加了误用的可能性。关于SGMs 中适度泛化的研究仍然有限。研究者发现，当前的机器遗忘标准方法（Re-training after removing undesirable training data）在SGMs中并不可行，进一步分析表明原因是该方法未能改变原始的分数函数。

Innovation: 
研究提出了一种新的方法——分数调整的生成模型（MSGM），该方法通过在一个连续时间的随机微分方程过程中引入新型的分数调整策略，将分数函数从不需要的数据中引导开。大量的实验表明MSGM可以显著减少生成不需要内容的几率，同时保持高质量的正常图像生成。另外，MSGM框架是通用且灵活的，可以与不同类型的扩散架构（SGM和DDPM）和训练策略（从头训练和微调）兼容，并能实现预训练模型的零样本迁移应用，如图像修复和重建。

Conclusion: 
总体来看，MSGM在保证高质量图像生成的同时显著减少了误泛化的可能性，提供了一种灵活且通用的适度泛化方法，并增强了SGMs的实用性和安全性。代码在论文被接受后将公开分享。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.07229</guid><pubDate>Fri, 27 Jun 2025 02:40:48 +0800</pubDate></item><item><title>247. cs.CV-GASP: 效率高的生成对抗后缀以破解大语言模型的黑盒方法</title><link>https://arxiv.org/pdf/2411.14133</link><description>Background: 
大语言模型（LLM）在各种自然语言处理任务中显示出了强大的能力，但它们仍然容易受到精心设计的输入提示（称为 jailbreak 攻击）的影响，这些提示被用来规避安全限制并引发有害响应。传统的反制方法主要依赖手动启发式技术，但这种方式缺乏普遍适用性。尽管基于优化的方法能够自动产生对抗提示，但它们往往生成不自然的提示，这些提示容易被安全过滤器检测到，或者由于离散标记优化需要高昂的计算成本。因此，本文提出了一种名为 Generative Adversarial Suffix Prompter（GASP）的新型自动化框架，能够在完全黑盒的环境中生成易于理解的对抗后缀提示。

Innovation: 
GASP 框架通过利用潜在贝叶斯优化技术来快速探索连续潜在嵌入空间，生成最有效的对抗后缀，同时通过目标迭代细化策略来平衡提示的连贯性，从而使得在破解大语言模型时能够有效地生成自然且高效的对抗提示。

Conclusion: 
通过广泛的实验，我们证明了 GASP 能够生成自然的对抗后缀提示，相比基线方法显著提高了破解成功率，缩短了训练时间，并加快了推理速度，从而将其作为一个高效且可扩展的红队破解大语言模型的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.14133</guid><pubDate>Fri, 27 Jun 2025 02:40:44 +0800</pubDate></item><item><title>248. cs.CV-DeSPITE：探索用于高级点云人类活动理解的对比深骨架-点云-IMU-文本嵌入</title><link>https://arxiv.org/pdf/2506.13897</link><description>Background: 
尽管激光雷达（LiDAR）作为一种保护隐私的方法，可以有效替代RGB摄像头来感知人类活动，但在多模态对比预训练背景下，对于理解人类活动（如人体活动识别、检索或再识别）的研究仍然相对空白。为了填补这一空白，我们通过探索学习LiDAR点云、人体骨架姿态、IMU数据和文本之间的对应关系来建立一个联合嵌入空间，提出了一种名为DeSPITE的深度骨架-点云-IMU-文本嵌入模型。我们结合了现有的LIPD和Babel数据集，以同步四种模态的数据，并探索新的联合嵌入空间的学习。我们的实验展示了DeSPITE在点云序列中实现的新的人类活动理解任务，包括骨架-点云-IMU匹配、检索和时间点检索。另外，我们在MSR-Action3D和HMPEAR实验中表明，DeSPITE可以有效提升点云人体活动识别的性能。

Innovation: 
提出了一种名为DeSPITE的深度骨架-点云-IMU-文本嵌入模型，用于探索LiDAR点云、人体骨架姿态、IMU数据和文本之间的对应关系，并构建一个联合嵌入空间。通过同步LIPD和Babel数据集，使得四种模态的数据能够被统一处理。该模型创新地展示了基于点云序列的新的人类活动理解任务，并证明了其预训练策略的有效性，尤其在点云人体活动识别方面的优势。

Conclusion: 
DeSPITE有效地学习了跨多模态（点云、骨架姿态、IMU数据和文本）的联合嵌入空间，并展示了在多模态人类活动理解和点云人体活动识别等任务上的重要应用。实验结果证明了DeSPITE在提高点云人体活动识别性能方面的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13897</guid><pubDate>Fri, 27 Jun 2025 02:40:44 +0800</pubDate></item><item><title>249. cs.CV-通过基础模型组成实现可扩展和通用的地球观测数据挖掘</title><link>https://arxiv.org/pdf/2506.20174</link><description>Background: 
地球观测数据挖掘正通过基础模型快速变革，这些模型能够为场景分类和语义分割等关键任务提供可泛化且可扩展的解决方案。尽管地理空间领域主要侧重于从大规模地球观测数据集训练大型模型，但重新使用和组合现有预训练模型的方法尚未得到充分探索。这项研究旨在调查是否可以将预训练于遥感和通用视觉数据集的较小模型组合起来，以提高多样化的地球观测任务性能。通过GEO-Bench基准，研究了几种显眼的模型，包括Prithvi、Hiera和DOFA，在涵盖不同空间分辨率、传感器模式和任务类型的十一个数据集上的表现。实验结果表明，特征级组合的小模型在性能上可以与大型模型媲美，甚至超越，并且所需的训练时间和计算资源更少。进一步地，研究强调了知识蒸馏的应用前景，以将组合模型的优点转移至更紧凑的模型，为实际应用场景中的基础模型部署提供了一条实用途径。

Innovation: 
研究主要创新在于提出了一种新的方法，即通过组合现有预训练的基础模型来提升地球观测任务的性能，这种方法不仅能够达到甚至超过大型模型的性能水平，还能显著降低训练时间和计算资源的需求。此外，研究还探索了知识蒸馏技术，以将组合模型的优点转移到更小、更紧凑的模型中，为实际应用中的模型部署提供了新思路。

Conclusion: 
通过预训练于遥感和通用视觉数据集的较小基础模型的特征级组合，能够在多种多样化的地球观测任务中达到接近或超越大型模型的性能水平，所需的计算资源和训练时间更少。知识蒸馏的应用能够实现性能的进一步提升，并转移组合模型的优点至更紧凑的模型，这为实际应用场景中的基础模型部署提供了实际可行的路径。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20174</guid><pubDate>Fri, 27 Jun 2025 02:40:43 +0800</pubDate></item><item><title>250. cs.CV-使用神经场和光流增强动态CT图像重建</title><link>https://arxiv.org/pdf/2406.01299</link><description>Background: 
在动态CT成像中，目标相对于测量获取率的运动会导致时间上高分辨率但空间上严重欠采样的测量结果。这样的问题构成了重大挑战：如果没有考虑过程的动态，会导致不现实的重建和不良的运动效果。传统的变分方法通过惩罚时间演化来关联连续帧，以基于经典的网格离散化提高图像质量。而神经场已被证明是一种新颖的参数化方法，使用神经网络以低维输入进行参数化，具备轻量级、连续性和偏好光滑表示的特点。这一特性已经应用于使用神经场解决动态反问题中，通过最小化数据保真项。作者研究并展示了使用基于偏微分方程的显式运动正则化优化神经场以改进重建的效果，并将其与未正则化的方法及网格基解算器进行了对比，展示了在重建质量上的改进。

Innovation: 
提出了使用基于偏微分方程的显式运动正则化优化神经场的方法，以改善动态CT图像重建的质量。与未正则化的神经场方法和传统网格基解算器相比，这种方法能够实现更好的表现。特别是，在峰值信噪比（PSNR）方面，神经场方法优于传统方法。

Conclusion: 
通过引入基于偏微分方程的显式运动正则化，可以提高动态CT图像的重建质量。这种方法不仅利用了神经场的轻量级、连续性和偏好光滑表示的特性，还能够通过额外的运动正则化提高图像的准确性，从而在动态CT图像重建任务中优于传统的网格基解算器。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.01299</guid><pubDate>Fri, 27 Jun 2025 02:40:42 +0800</pubDate></item><item><title>251. cs.CV-自监督对比学习中按需发现全局虚假负面样本</title><link>https://arxiv.org/pdf/2502.20612</link><description>Background: 
在自监督对比学习中，负样本对通常是由锚图像和从整个数据集中抽样但排除锚图像的样本组成。然而，这种方法可能导致生成具有相似语义的‘虚假负样本’，使得它们的嵌入被错误地推开。

Innovation: 
本文提出了一种基于优化的方法——GloFND，该方法能够在训练过程中自动学习每个锚数据的阈值，以识别其‘虚假负样本’。与之前的 false negative 发现方法不同，该方法在全球范围内检测整个数据集中所有可能的‘虚假负样本’，而不局限于mini-batch范围内，并且每迭代的计算成本与数据集大小无关。实验结果表明此方法的有效性。

Conclusion: 
本文提出的方法在图像和图像-文本数据上的实验结果证明了该方法的有效性。我们的实现可以在此处找到： [提供的网址]&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.20612</guid><pubDate>Fri, 27 Jun 2025 02:40:42 +0800</pubDate></item><item><title>252. cs.CV-MiCo: 基于上下文感知聚类的多重实例学习在全切片图像分析中的应用</title><link>https://arxiv.org/pdf/2506.18028</link><description>Background: 
多重实例学习（MIL）在基于全切片图像（WSI）的癌症诊断和预后分析中显示出巨大的潜力。然而，WSIs固有的空间异质性提出了关键挑战，因为外观相似的组织类型往往分散在不同的解剖区域。传统的MIL方法难以建模这些分散的组织分布并有效地捕捉跨区域的空间交互。

Innovation: 
我们提出了一种基于上下文感知聚类的多重实例学习框架，即MiCo。该框架旨在增强跨区域内的组织内关联并加强跨组织的语义关联。MiCo首先通过聚类提取区分性的形态模式，使用聚类中心作为语义锚点。为了增强跨区域内的组织内关联，MiCo采用了Cluster Route模块，该模块通过特征相似性动态链接同一组织类型的实例，跨越不同区域。这些语义锚点作为上下文节点，传播语义关系以细化实例级别的表示。为了消除语义碎片化并加强跨组织的语义关联，MiCo结合了Cluster Reducer模块，该模块消除了冗余锚点，增强了不同语义组之间的信息交换。

Conclusion: 
在两个具有挑战性的任务上对九个大规模公共癌症数据集的广泛实验显示了MiCo的有效性，证明了其优于最先进的方法。代码可通过以下链接获取：this https URL.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18028</guid><pubDate>Fri, 27 Jun 2025 02:40:38 +0800</pubDate></item><item><title>253. cs.CV-超声图像解释和扫描指导的语义场景图</title><link>https://arxiv.org/pdf/2506.19683</link><description>Background: 
医学超声成像由于成像和获取参数的显著差异导致了视觉上的多样性，理解起来仍然是一个长期挑战。最近，大语言模型（LLMs）的进展已经被用于为具有足够生理知识的临床医生自动生成术语丰富的总结，但非专家用户的成像解读和基本扫描指导需求尚未被探索。本文首先介绍用于解释超声图像的场景图（SG），以供普通用户理解和提供扫描指导。SG的第一步使用基于变换器的一步法计算，消除了明确对象检测的需要。用户查询随后用于通过LLMs进一步细化抽象的SG表示，生成更易理解的图像解释。预测的SG还被用于指导超声扫描以弥补当前成像视图中的解剖缺失，帮助普通用户实现更标准化和完整的解剖探索。

Innovation: 
提出了使用基于变换器的一步法计算超声图像的场景图（SG），通过大规模语言模型（LLMs）进一步细化SG表示，生成用户可理解的图像解释，并探索SG在指导超声扫描中的应用，以弥补当前成像视图中的解剖缺失，帮助普通用户实现更标准化和完整的解剖探索。这种方法验证了超声图像解释和扫描指导的潜力，从而最大限度地提高超声成像的普及性和易用性，特别是对于普通用户而言。

Conclusion: 
此SG方法已被验证可以在包括颈动脉和甲状腺的左右颈部区域的超声图像上有效。结果表明该方法在最大程度上民主化超声成像方面具有巨大潜力，增强了其对普通用户的可解释性和可用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19683</guid><pubDate>Fri, 27 Jun 2025 02:40:35 +0800</pubDate></item><item><title>254. cs.CV-Generate the Forest before the Trees -- A Hierarchical Diffusion Model for Climate Downscaling</title><link>https://arxiv.org/pdf/2506.19391</link><description>Background: 
降尺度是生成用于地方规划所需的高分辨率气候数据的关键步骤，但传统方法仍然计算量较大。近年来，人工智能降尺度模型取得了显著成果，尤其是扩散模型，因其能够生成集合并且能够克服其他人工智能方法常见的平滑问题而受到关注。然而，这些模型通常仍然计算量大。需要一种轻量级的解决方案以支持可负担的大规模高分辨率气候预测，并且能够在不同的高分辨率和低分辨率气候模型之间无缝转换，因此提出了Hierarchical Diffusion Downscaling (HDD)模型，旨在通过简化层次下采样方案引入可扩展的层次采样过程，从而解决计算负载问题并提高精度。

Innovation: 
HDD模型通过引入简化层次下采样方案到扩散框架中，提供了一种轻量级的解决方案。它能够以更低的计算负荷实现高分辨率的气候数据生成，并且单个在0.25°分辨率上训练的模型能够在多个CMIP6模型之间无缝转换。这使得HDD模型成为一种可用于气候降尺度的概率气候模型轻量级替代方案，能够支持可负担的大规模高分辨率气候预测。

Conclusion: 
HDD模型通过层次采样过程在保持准确性的前提下大幅降低了计算负荷，证明了在不同分辨率模型之间的广泛适用性，提供了一种轻便且高效的高分辨率气候数据生成方法，推动了低成本高分辨率气候预测的应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19391</guid><pubDate>Fri, 27 Jun 2025 02:40:32 +0800</pubDate></item><item><title>255. cs.CV-PuriDefense: 随机局部隐式对抗净化用于防御黑盒查询导向攻击</title><link>https://arxiv.org/pdf/2401.10586</link><description>Background: 
黑盒查询导向攻击对机器学习即服务（MLaaS）系统构成重大威胁，这是因为它们可以在不访问目标模型架构和参数的情况下生成对抗样本。传统防御机制，如对抗训练、梯度遮蔽和输入转换，要么大幅增加计算成本，要么降低非对抗输入的测试准确性。这些挑战促使研究者寻求更加高效的防御方法。

Innovation: 
我们提出了一种高效的防御机制，名为PuriDefense，它利用轻量级净化模型在较低的推断成本下进行随机块级净化。这些模型通过局部隐式函数重建自然图像流形，这被理论分析证明能够减缓查询导向攻击的收敛速度。广泛实验在CIFAR-10和ImageNet上验证了这种基于净化器的防御机制的有效性，显著提高了对抗查询导向攻击的鲁棒性。

Conclusion: 
PuriDefense通过随机局部隐式净化有效提升了MLaaS系统的对抗查询导向攻击的鲁棒性，相比传统防御机制，具有较低的计算成本和较高的准确性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2401.10586</guid><pubDate>Fri, 27 Jun 2025 02:40:32 +0800</pubDate></item><item><title>256. cs.CV-Referring Expression Instance Retrieval and A Strong End-to-End Baseline</title><link>https://arxiv.org/pdf/2506.18246</link><description>Background: 
自然语言查询视觉信息在实际应用中有基本需求。文本图像检索（TIR）根据图像级别的描述检索目标图像，而参照表达理解（REC）则使用实例级别的描述在给定图像中定位目标对象。然而，实际应用往往需要更复杂的需求，用户通常需要跨大型数据库查询实例级别的描述，并期望获得相关图像及其对应的位置。现有方法，如TIR和REC，在细粒度描述和对象级定位上表现不足，且REC在大规模数据库中的搜索效率较低且缺乏有效的排名机制。此论文提出了新的任务称为参照表达实例检索（REIR），支持基于细粒度参照表达的实例级检索与定位。为此，构建了一个大规模基准REIRCOCO，使用先进视觉语言模型生成MSCOCO和RefCOCO数据集中的高质量实例级别的参照表达。

Innovation: 
提出了一个新的任务——参照表达实例检索（REIR），支持基于细粒度参照表达的实例级检索与定位。提出了一个名为REIRCOCO的大规模基准，该基准由先进视觉语言模型生成高质量的实例级别的参照表达。还提出了一种名为Contrastive Language-Instance Alignment with Relation Experts (CLARE)的基线方法，该方法通过端到端的方式解决REIR问题，训练了具有初始定位能力的方法，然后通过对比语言实例对齐（CLIA）优化以提高图像之间检索性能。

Conclusion: 
提出了REIR任务、REIRCOCO基准数据集以及CLARE基线方法。CLARE在对象检测和参照表达理解数据集上进行预训练，然后通过CLIA进行优化以增强图像之间的检索性能。作者还将公开发布代码和基准数据集。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18246</guid><pubDate>Fri, 27 Jun 2025 02:40:31 +0800</pubDate></item><item><title>257. cs.CV-EgoM2P: 自主视角多模态多任务预训练</title><link>https://arxiv.org/pdf/2506.07886</link><description>Background: 
理解自主视角的多模态信号，例如RGB视频、深度数据、相机姿态和凝视，对于增强现实、机器人技术和人机交互的应用至关重要。这些技术能够使系统更准确地解释佩戴摄像头的人的动作、意图及其周围环境。建立大规模的自主视角多模态和多任务模型面临着独特挑战。自主视角数据具有固有的异质性，不同设备和环境的模态覆盖率差异很大。生成缺失模态（如凝视或头显摄像头轨迹）的伪标签经常难以实现，使得标准监督学习方法难以扩展。此外，动态相机运动和第一人称视频的复杂时态和空间结构为直接应用现有的多模态基础模型带来了额外挑战。

Innovation: 
为应对这些挑战，本文提出了一些高效的时序分词器，并提出了一种名为EgoM2P的掩码建模框架，该框架通过学习知时的多模态分词来训练大规模的一般用途模型，以实现自主视角4D理解。该统一设计支持跨任务的多样自主视角感知和合成任务，包括凝视预测、自主视角相机跟踪和第一人称视频的单目深度估计，并且还可以作为条件自主视角视频合成的生成模型。在这些任务上，EgoM2P在性能上匹配或超过了专门模型，同时速度提高了数倍。

Conclusion: 
我们完全开源EgoM2P，支持社区并推动自主视角视觉研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07886</guid><pubDate>Fri, 27 Jun 2025 02:40:29 +0800</pubDate></item><item><title>258. cs.CV-2D Triangle Splatting for Direct Differentiable Mesh Training</title><link>https://arxiv.org/pdf/2506.18575</link><description>Background: 
基于多视角图像重建高保真3D场景的方法中，可微分渲染和3D高斯基元已经被证明是有效的手段，尤其是与NeRF相比。然而，这些方法仍然面临渲染速度慢以及无法提供与基于网格模型相比的高级渲染效果（如改光和阴影渲染）的挑战。

Innovation: 
本文提出了一种新的2D三角面点（2DTS）方法，用2D三角形替代3D高斯基元。2D三角点方法不仅保留了连续体体积建模的优点，还自动生成了类似于离散网格的结构，同时通过引入紧凑性参数，可以实现直接训练逼真的网格模型。

Conclusion: 
我们的实验结果表明，与最先进的基于高斯的方法相比，基于三角形的2DTS方法（不进行紧凑度调优）在保真度方面表现更优。此外，我们的方法生成的重建网格在视觉质量方面也超过了现有的网格重建方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18575</guid><pubDate>Fri, 27 Jun 2025 02:40:29 +0800</pubDate></item><item><title>259. cs.CV-HyperPath:知识引导的双曲语义层次建模用于WSI分析</title><link>https://arxiv.org/pdf/2506.16398</link><description>Background: 
病理学对于癌症诊断至关重要，而多实例学习（MIL）广泛应用于全切片图像（WSI）分析。WSIs具有自然的层次结构——补丁、区域和切片，具有不同的语义关联。尽管一些方法试图利用这种层次结构以提升表示效果，但它们大多依赖于欧氏嵌入，这难以完全捕捉语义层次结构。为解决这一局限，本文提出了HyperPath，这是一个新颖的方法，通过从文本描述中整合知识，指导建模WSIs的语义层次结构在双曲空间中，从而提升WSIs分类效果。该方法将病理视觉-语言基础模型提取的视觉和文本特征适应到双曲空间，并设计角度模态对齐损失来确保跨模态的一致性，同时使用语义层次一致性损失通过蕴含和矛盾关系进一步精化特征层次结构，进而增强语义一致性。分类使用测地线距离，该距离衡量实体在双曲语义层次结构中的相似性，从而消除了线性分类器的需求，并允许一种几何感知的WSI分析方法。

Innovation: 
首先，HyperPath提出了一种新颖的方法，将病理视觉-语言基础模型提取的视觉和文本特征适应到双曲空间。其次，设计了角度模态对齐损失确保跨模态的一致性，并通过语义层次一致性损失进一步精化特征层次结构。最后，分类使用测地线距离，这是一种几何感知的WSI分析方法。

Conclusion: 
通过广泛的实验，本研究表明，与现有方法相比，我们的方法在任务上表现出优越的性能，突显了双曲嵌入在WSI分析中的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16398</guid><pubDate>Fri, 27 Jun 2025 02:40:24 +0800</pubDate></item><item><title>260. cs.CV-通过跨模态注意力蒸馏实现对齐的新型视图图像和几何合成</title><link>https://arxiv.org/pdf/2506.11924</link><description>Background: 
现有方法要么需要密集的姿态图像，要么依赖于嵌入姿态的生成模型，这些模型只能处理域内视图。本研究引入了一种基于扩散的框架，利用图像和几何扩散分支及跨模态注意力蒸馏，实现了视图对齐的图像和几何生成。这种方法不依赖于密集的姿态图像或姿态嵌入的生成模型，而是利用现成的几何预测器预测从参考图像视角下的部分几何，将新颖视图合成问题转换为图像和几何的修复任务。

Innovation: 
提出了跨模态注意力蒸馏，该方法在训练和推理期间将图像分支的注意力图注入到并行的几何分支中，实现了多任务学习，从而在保持图像和几何对齐的同时，提升了几何鲁棒的图像合成效果以及几何预测的明确性。此外，引入了基于邻近性的网格条件化，结合深度和法线线索，进行点云间插，减少错误预测的几何对生成过程的影响。该方法在多种未见场景下实现了高质量的视图外推合成，并在插值设置下提供了竞争力的重建质量，生成了几何对齐的彩色点云，实现全面的3D完成。

Conclusion: 
实验结果显示，该方法在图像和几何的离散视图上都实现了高保真度的外推生成，并在插值设置下提供了竞争力的重建质量，生成的彩色点云也与生成的图像保持几何对齐，从而实现了完整的3D完成。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.11924</guid><pubDate>Fri, 27 Jun 2025 02:40:22 +0800</pubDate></item><item><title>261. cs.CV-OneIG-Bench: 综合多维度评估框架用于图像生成</title><link>https://arxiv.org/pdf/2506.07977</link><description>Background: 
文本到图像（T2I）模型因为在生成高质量且与文本提示对齐的图像方面引起了广泛关注而受到重视。然而，随着T2I模型的快速发展，早期基准测试显示出了局限性，包括缺乏全面评估，例如推理、文本呈现和风格评估。最近的先进模型虽然具备丰富的知识建模能力，在需要强大推理能力的图像生成问题上取得了有前途的结果，但也存在现有的评估系统未能充分应对这一领域的问题。因此，本文提出了OneIG-Bench，旨在通过多维度的综合基准框架系统地解决这一问题，全面评估T2I模型，包括提示-图像对齐、文本呈现精度、推理生成内容、风格化和多样性等维度。它通过结构化的评估方式，帮助研究人员和从业者深入分析模型性能，明确整个图像生成流程中的强项和瓶颈。

Innovation: 
OneIG-Bench是一个专门设计的全面基准框架，为T2I模型在多个维度上的精细化评估提供了一个系统的方法。这个框架能够灵活地对特定评估子集进行有针对性的分析，允许用户专注于一个评估维度，只生成与所选维度相关的提示对应的图像，并完成相应的评估，从而避免在多个提示中生成图像的繁琐过程。这种精细化和模块化的设计突破了现有评估系统的局限，提供了更深入、细致的分析和评估手段。此外，该研究团队还公开了代码和数据集，便于社区内的可重复评估研究和跨模型比较。

Conclusion: 
OneIG-Bench 通过多维度的综合基准框架，系统地解决了目前 T2I 模型评估中的主要缺陷，提出了针对细化评估多个维度的新方法。它不仅能够帮助研究人员精准识别模型的优点和不足，而且还促进了T2I领域的研究进展和模型改进。研究团队将公开此框架的相关代码和数据集，以支持社区内的可重复研究和各种模型之间的比较。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.07977</guid><pubDate>Fri, 27 Jun 2025 02:40:21 +0800</pubDate></item><item><title>262. cs.CV-从假做到真：奖励模型的判别性预测</title><link>https://arxiv.org/pdf/2506.13846</link><description>Background: 
奖励模型在强化学习中对于视觉生成模型的训练后增强起着至关重要的作用。当前的奖励模型方法由于依赖大量的人工注释偏好数据或复杂的、难以全面编写的质量维度而存在实现复杂性的问题。本文基于生成对抗网络（GANs）中的对抗训练思想，探讨了奖励模型的新框架——GAN-RM，以减少手动偏好注释和显式质量维度的工程化。

Innovation: 
本文提出了一种新型的奖励模型框架——GAN-RM，该框架通过判别一小部分代表性、未配对的目标样本数据（称为偏好代理数据）与模型生成的一般输出之间的差异，来训练奖励模型，无需大量的人工注释数据和具体的质量维度工程。这种方法只需少量目标样本即可进行训练，并在多种关键应用场景（如测试时的缩放、后训练方法中的监督微调、直接偏好优化等）中表现出有效性。

Conclusion: 
通过全面的实验，本文证明了GAN-RM的有效性，并展示了其在多个关键应用领域的优越性。该方法不仅减少了人力和机械工程的工作量，还展示了其在实际应用中的潜力。随文附带的代码和数据将会开源。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13846</guid><pubDate>Fri, 27 Jun 2025 02:40:19 +0800</pubDate></item><item><title>263. cs.CV-PCA和奇异值分解（SVD）作为降维技术的比较分析</title><link>https://arxiv.org/pdf/2506.16663</link><description>Background: 
高维图像数据通常需要在进一步分析之前进行降维处理。本文提供了一种纯理论比较两种线性技术——主成分分析（PCA）和奇异值分解（SVD）的方法。在从基本原理推导出每种算法之后，评估了它们的可解释性、数值稳定性以及适用于不同矩阵形状的能力。

Innovation: 
基于经典的和近期的数值文献，本文合成了选择其中一个算法而不进行经验基准测试的经验性指导原则。此外，本文揭示了各自的局限性，并指出了未来实验工作的方向。

Conclusion: 
本文通过纯理论比较PCA和SVD，评估了它们的可解释性、数值稳定性和适用矩阵形状的能力，并提供了选择合适的算法的经验性指导原则。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.16663</guid><pubDate>Fri, 27 Jun 2025 02:40:19 +0800</pubDate></item><item><title>264. cs.CV-结构保持的块解码在高效神经视频表示中的应用</title><link>https://arxiv.org/pdf/2506.12896</link><description>Background: 
隐神经表示（INRs）在建模复杂信号方面得到广泛应用，尤其是在视频信号建模中，通常通过将空间和时间坐标映射到相应值来处理。对于视频而言，采用紧凑的输入映射到整个帧或空间分割的块图像比基于坐标的映射更能保持空间关系，减少计算开销，提升重建质量。然而，预测整个帧通常限制了高频视觉细节的重建。传统基于均匀空间分割的块方法倾向于引入边界突变，破坏空间连贯性。

Innovation: 
提出了一种基于空间对齐块（SPPs，Structure-Preserving Patches）的神经视频表示方法。通过类似于PixelUnshuffle的确定性像素级分割将每帧视频分离成块图像，该操作保留了全局空间结构，同时允许块级解码。训练解码器重建这些结构化的块，实现全局到局部的解码策略，先捕获全局布局，再细化局部细节，有效减少了边界伪影并缓解了简单上采样的失真问题。

Conclusion: 
在标准视频数据集上的实验表明，本方法在重建质量和压缩性能方面优于现有的基于INR的基线方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12896</guid><pubDate>Fri, 27 Jun 2025 02:40:17 +0800</pubDate></item><item><title>265. cs.CV-Context Aware Grounded Teacher for Source Free Object Detection</title><link>https://arxiv.org/pdf/2504.15404</link><description>Background: 
在来源数据不可用时，模型需要适应未标记的目标领域的问题被称为Source Free Object Detection (SFOD)。在医学成像领域，一些方法利用半监督的学生-教师结构来解决领域差异问题。标签训练数据中的上下文不对称和不同领域之间的显著领域偏移可能导致偏置的教师模型生成不准确的伪标签，从而影响学生模型的性能并导致模式崩溃。通过这些上下文不平衡，特别是当一个类别明显多于另一个类别时，也会产生上下文偏置。

Innovation: 
本文提出了一个名为Grounded Teacher (GT)的标准框架来解决上下文偏置问题，在SFOD设置中保持了学生模型的性能并缓解了性能下降。本文使用一个专门的关系上下文模块建模上下文关系，并利用它缓解模型中的先天偏差。因此，通过在不同类别之间应用增强，无论是跨领域还是在领域内，都提高了未代表类的性能，同时对主要类的影响最小。此外，通过实现专家基础支出去监督学生模型，进一步提高了预测质量。

Conclusion: 
通过在三个医学数据集上的实验和全面的消融研究验证了本文方法在SFOD设置中缓解上下文偏置的有效性。所有相关资源，包括预处理数据、训练模型权重和代码，都公开发布在thisthis https URL上。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.15404</guid><pubDate>Fri, 27 Jun 2025 02:40:13 +0800</pubDate></item><item><title>266. cs.CV-Efficient Spiking Point Mamba for Point Cloud Analysis</title><link>https://arxiv.org/pdf/2504.14371</link><description>Background: 
生物启发的脉冲神经网络（SNNs）提供了从3D时空特征中提取能源高效的方法。然而，现有的3D SNNs在处理长距离依赖问题上表现不佳，直到Mamba的出现才解决了这个问题，Mamba提供了卓越的计算效率和序列建模能力。先前的研究中，直接将Mamba应用于3D SNNs性能不佳，因此拟提出一种新的Mamba基于的3D SNN——Spiking Point Mamba (SPM)。SPM结合了Mamba的序列建模能力和SNNs的时序特征提取能力。为了有效地进行时序交互，提出了HDE（分层动态编码）改进直接编码方法。接着构建了Spiking Mamba块(SMB)，同时学习跨时隙特征并最大限度地减少由尖峰引起的细节损失。最后，通过不对称SNN-ANN架构进行基于尖峰的预训练和微调来进一步提高性能。

Innovation: 
引入了分层动态编码（HDE）及Spiking Mamba块(SMB)，结合了Mamba的序列建模能力和SNNs的时序特征提取能力。设计SPM模型，其在传送Mamba到3D SNNs时的性能不足问题上进行了改进，充分利用了Mamba的序列建模能力和SNNs的时序特征提取能力，通过构建SMB和HDE改进了序列间和时序特征的处理，以更好地利用尖峰的传播机制。并在不对称SNN-ANN架构中进行基于尖峰的预训练和微调，以提高性能。SPM模型在三种ScanObjectNN变体上的OA分别提高了6.2%、6.1%、7.4%，在ShapeNetPart上的实例mIOU提高了1.9%。其能耗比其ANN对应物低至少3.5倍。

Conclusion: 
与先前的最新SNN模型相比，SPM在三个ScanObjectNN变体上的OA分别提高了6.2%、6.1%和7.4%，在ShapeNetPart上的实例mIOU提高了1.9%，同时能耗至少比其ANN对应物低3.5倍。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.14371</guid><pubDate>Fri, 27 Jun 2025 02:40:12 +0800</pubDate></item><item><title>267. cs.CV-StateSpaceDiffuser: 将长期上下文引入扩散世界模型</title><link>https://arxiv.org/pdf/2505.22246</link><description>Background: 
世界模型近年来成为预测基于复杂环境动作的现实视觉的有效工具。然而，这些模型依赖于最近的少数观察，导致它们在较长时间段内失去长期上下文。这使得生成的场景在几步之内就与先前观察的内容偏离，破坏了时间的连贯性。最新的世界模型，大多依赖于扩散模型，由于缺乏持久环境状态，存在这一局限性。

Innovation: 
我们引入了StateSpaceDiffuser，该模型通过整合状态空间模型来实现长时间上下文任务，该状态空间模型代表了全部交互历史。这一设计恢复了长期记忆，同时保持了扩散模型的高保真合成能力。为了准确测量时间一致性，我们开发了一种评估协议，该协议检测模型在扩展操作中重新实例化先前看到的内容的能力。全面的实验显示，StateSpaceDiffuser显著优于仅依赖扩散模型的基准模型，能够更长时间地保持视觉连贯性，并在2D迷宫导航和复杂3D环境中提供一致的视图。

Conclusion: 
将状态空间表示引入扩散模型对展示视觉细节和长期记忆高度有效。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.22246</guid><pubDate>Fri, 27 Jun 2025 02:40:10 +0800</pubDate></item><item><title>268. cs.CV-自己动手：从伪标签学习语义对应</title><link>https://arxiv.org/pdf/2506.05312</link><description>Background: 
在计算机视觉中，寻找跨图像和对象实例中语义相似点之间的对应关系一直是一个持久的挑战。虽然大型预训练视觉模型最近被证明是语义匹配的有效先验，但在处理对称对象或重复的对象部分时，它们仍然存在模糊性问题。

Innovation: 
本文提出了一种通过3D感知伪标签改进语义对应估计的方法。具体而言，本文训练了一个适配器，使用通过3D感知链进行的伪标签，通过宽松的循环一致性过滤错误标签，并结合3D球形原型映射约束来精炼现成的特征。相比之前的工作，本文的方法减少了对特定数据集标注的依赖，同时在SPair-71k数据集上达到了超过4%的绝对改进，并且相比于具有类似监督需求的方法，提高了超过7%。我们的方法的通用性简化了训练向其他数据源的扩展，这一点在我们的实验中得以验证。

Conclusion: 
本文提出的方法解决了大型预训练模型在处理对称对象或重复对象部分时的模糊性问题，并在SPair-71k数据集上取得了新的最佳性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.05312</guid><pubDate>Fri, 27 Jun 2025 02:40:10 +0800</pubDate></item><item><title>269. cs.CV-SA-Person：基于场景感知重排的文本驱动人物检索</title><link>https://arxiv.org/pdf/2505.24466</link><description>Background: 
文本驱动的人物检索旨在根据自然语言描述从图像库中识别目标个体。这一任务面临复杂现实场景和外观描述模糊的挑战。现有方法主要侧重于基于外观的跨模态检索，忽略了场景中的语境信息，后者能够为检索提供有价值的补充见解。现有人工抽取的检索数据集规模较小，给训练带来了局限性，新方法缺乏应用场景语境的信息获取和综合分析能力。因此需要一种新的方法来充分考虑场景中的语境信息，以提高人物检索的精度和效果。

Innovation: 
提出了SCENEPERSON-13W大规模数据集，并设计了SA-Person框架。SA-Person框架包含两个阶段：一是基于文本线索与行人特定区域的对比学习进行判别性外观语义关联；二是引入SceneRanker模块，这是一种无需训练的、基于场景感知的重排方法，利用多模态的大语言模型同时综合处理行人外观特征和全局场景语境。实验表明，该框架在场景级别的检索中具有有效性。

Conclusion: 
实验结果显示了该框架在挑战性的场景级别检索场景中的有效性。研究团队将代码和数据集公开发布，以促进进一步的研究和应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.24466</guid><pubDate>Fri, 27 Jun 2025 02:40:09 +0800</pubDate></item><item><title>270. cs.CV-文本到图像模型及其对参与活动的不同国籍人员的代表</title><link>https://arxiv.org/pdf/2504.06313</link><description>Background: 
本文探讨了一个流行的文本到图像(T2I)模型，当被要求生成从事典型活动的人的图像时，它如何代表来自208个不同国籍的人。研究人员开发了两个场景，并基于输入提示生成了644张图像。结果表明，不同的传统服饰在不同场景中的表现差异显著，并且这种表现模式与地域和收入组有关。使用CLIP，ALIGN和GPT-4.1迷你型评估了生成图像与3320个提示和描述之间的对齐分数，结果发现，在一个场景中，具有传统服饰的人的图像得分更高。研究还分析了修改过的提示，发现模型在75.46%的提示中自动添加了“传统”一词。

Innovation: 
该研究创新性地分析了一个流行的T2I模型在生成不同国籍人员从事典型活动的图像时的传统服饰表现，并使用了多种评估方法来衡量生成图像与文本描述之间的对齐度。此外，该研究还发现模型在一些情况下会自动添加“传统”一词，揭示了模型在生成图像时的某些特定偏见或行为模式。

Conclusion: 
该研究为不同国家的人通过T2I技术的表示提供了宝贵的见解，揭示了模型如何优先选择传统特征，尽管这些特征在特定场景下可能不适用。研究结果表明，该模型特别重视中东和北非以及撒哈拉以南非洲地区的传统服饰，显示出特定地理区域的不公平偏向，同时发现了一定收入群体之间的关联。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.06313</guid><pubDate>Fri, 27 Jun 2025 02:40:08 +0800</pubDate></item><item><title>271. cs.CV-TaxaDiffusion：逐步训练的扩散模型用于细粒度物种生成</title><link>https://arxiv.org/pdf/2506.01923</link><description>Background: 
现有扩散模型在生成细粒度动物图像时，通常将每个物种视为独立类别，这导致了在生成高形态和身份准确度的精细粒度动物图像时效率低下。TaxaDiffusion通过对动物分类学级别的逐步训练，利用物种间细微的形态、模式和颜色差异，使得模型能够更准确地生成动物图像，即使在每物种训练样本较少的情况下也能实现良好的生成效果。

Innovation: 
TaxaDiffusion 提出了一个基于分类学知识的训练框架，通过逐步从更高的分类层次（如目、科、属）到更低的分类层次（如种）进行训练，利用物种间的细微形态、模式和颜色差异，从而提高了在细粒度动物图像生成中的准确性和效率。

Conclusion: 
实验结果表明，TaxaDiffusion 在细粒度动物图像生成方面优于现有方法，特别是对于每物种样本较少的情况下，也能实现高精度、高保真的图像生成。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.01923</guid><pubDate>Fri, 27 Jun 2025 02:40:07 +0800</pubDate></item><item><title>272. cs.CV-RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS</title><link>https://arxiv.org/pdf/2506.02751</link><description>Background: 
3D Gaussian Splatting (3DGS) 方法由于其在新颖视图合成和三维建模中的实时、照片级真实感渲染而受到广泛关注，但现有方法难以准确建模由短暂物体引起的场景，导致渲染图像中的伪影。Gauss函数在增强场景细节捕捉的同时，无意中生成了用于建模短暂干扰的多余函数，从而加剧了这些问题。

Innovation: 
本文提出了RobustSplat方法，以解决上述问题。该方法在两个关键设计的基础上实现了一个健全部署方案。首先，采用了延迟Gauss生长策略，优先优化静态场景结构再允许Gauss分裂/克隆，从而减少早期优化中对短暂对象的过拟合。其次，设计了尺度梯进掩码初始化方案，利用低分辨率特征相似性监督确保短暂掩码初始估计的可靠性，且利用其在语义一致性和噪声鲁棒性方面的优势，逐步过渡到高分辨率监督以获得更精确的掩码预测。

Conclusion: 
在多项具有挑战性的数据集上的实验证明了该方法的有效性和鲁棒性，表明RobustSplat在去除3DGS中的短暂物体方面具有明显的优势。项目页面链接为：https://github.com/yourlinkhere&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.02751</guid><pubDate>Fri, 27 Jun 2025 02:40:05 +0800</pubDate></item><item><title>273. cs.CV-JointDiT: 使用扩散变换器增强RGB-深度联合建模</title><link>https://arxiv.org/pdf/2505.00482</link><description>Background: 
当前的研究重点在于利用最先进的扩散变换器的架构优势和出色的图像先验知识，来构建能够同时生成高保真图像和几何上合理且精确的深度图的模型。传统的图像生成和深度估计方法通常需要分别处理，而本文提出的方法旨在通过构建联合概率分布来实现多模态数据的联合处理和生成，以简化此类任务的处理流程并提高效率和准确性。

Innovation: 
本文提出了JointDiT，这是一种扩散变换器，能够建模RGB和深度的联合分布。这种模型通过适应噪声级别和不平衡时间步采样策略两种简单但有效的方法来实现联合分布的建模。这些创新使得模型能够在不同噪声级别的模态上进行训练，从而能够自然地处理联合生成、深度估计和深度条件下的图像生成等各种组合生成任务。

Conclusion: 
JointDiT展示了在联合生成性能方面的出色表现，并在深度估计和深度条件下的图像生成任务中实现了可比结果，这表明联合分布建模可以作为条件生成的可替代选择。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.00482</guid><pubDate>Fri, 27 Jun 2025 02:40:04 +0800</pubDate></item><item><title>274. cs.CV-BRepFormer: 基于变换器的B-rep几何特征识别</title><link>https://arxiv.org/pdf/2504.07378</link><description>Background: 
在多媒体内容基于内容检索和智能制造中，B-rep模型的几何特征识别是一项基础技术。然而，之前的大部分研究主要集中在机械特征识别（MFR），未能有效捕捉复杂几何特征的拓扑和几何特性。

Innovation: 
本文提出了一种基于变换器的新颖模型，BRepFormer，用于识别机械特征和复杂CAD模型的特征。BRepFormer编码和融合了模型的几何和拓扑特征，并使用变换器架构进行特征传播和一个识别头来识别几何特征。同时提出了一个名为复杂B-rep特征数据集（CBF）的20,000个B-rep模型的数据库，以更好地适应工业应用。

Conclusion: 
实验结果表明，BRepFormer在MFRinstSeg、MFTRCAD及CBF数据集上达到了最先进的准确率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.07378</guid><pubDate>Fri, 27 Jun 2025 02:40:02 +0800</pubDate></item><item><title>275. cs.CV-AirCache: 激活跨模态相关性 KV 缓存压缩以实现高效的大型视觉-语言模型推理</title><link>https://arxiv.org/pdf/2503.23956</link><description>Background: 
大型视觉语言模型（LVLMs）因其出色的推理能力和泛化能力而受到广泛关注。然而，处理大量视觉标记并生成长上下文输出导致了显著的计算负担，对关键值（KV）缓存提出了巨大的需求。已有研究指出这成为了性能的一个关键瓶颈。

Innovation: 
本文提出了一种创新的KV缓存压缩方法AirCache，旨在加速LVLMs推理。AirCache系统地研究了LVLMs注意力机制中视觉和文本标记之间的联系，揭示了缓存中视觉标记的冗余性，通过有选择地消除这些冗余标记，能够在保持模型性能的同时显著加快上下文生成。此外，AirCache引入了一种精英观察窗口，用于评估KV缓存中视觉组件的重要性，重点在于建模稳定性的多视角一致性，并且提出了一个自适应逐层预算分配策略，该策略利用了标记重要性分布的强度和偏斜性，展示了优于均匀分配的效率。

Conclusion: 
在多个LVLMs和基准测试上进行全面评估表明，本文的方法在仅保留视觉KV缓存的10%的情况下，能够实现与全缓存相当的性能，且解码延迟减少了29%至66%。随着缓存留存率降低，此方法相比现有方法表现出越来越大的性能优势。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.23956</guid><pubDate>Fri, 27 Jun 2025 02:39:55 +0800</pubDate></item><item><title>276. cs.CV-分析图像恢复变压器的训练动态：重新审视层规范化</title><link>https://arxiv.org/pdf/2504.06629</link><description>Background: 
本文探讨了图像恢复（IR）变压器的内部训练动态，并揭示了一个重要的但未被充分关注的问题：传统的LayerNorm会导致特征幅度发散，甚至达到百万尺度，并破坏通道间的熵。文章分析了网络试图绕过传统LayerNorm所施加的约束的原因，这些约束对IR任务存在冲突。分析指出，传统LayerNorm的工作方式和IR任务之间的不匹配会影响网络在训练过程中空间相关性的保持，以及对输入特定统计的保留能力。这些不匹配显著阻碍了IR变压器准确保存低级特征的能力。

Innovation: 
文章介绍了一种名为Image Restoration Transformer Tailored Layer Normalization（i-LN）的简单但有效的替代方案。它通过在整个空间通道维度上对特征进行整体归一化，保持各个元素之间的空间关系。此外，还提出了一种输入自适应的缩放策略，以保留每个输入所需的特征范围的灵活性。这些修改有效解决了Input层与IR任务之间的不匹配，从而稳定了训练动态并提高了IR性能。

Conclusion: 
实验结果证实，这种结合策略可以显著提高各种IR任务中IR变压器的稳定性和性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.06629</guid><pubDate>Fri, 27 Jun 2025 02:39:54 +0800</pubDate></item><item><title>277. cs.CV-DWIM: 通过差异感知工作流生成与指令遮蔽微调实现工具感知的视觉推理</title><link>https://arxiv.org/pdf/2503.19263</link><description>Background: 
视觉推理（VR）在多个领域对于实现类似人类的视觉理解至关重要，然而依然是一项高度挑战性的任务。近年来，基于大型语言模型（LLMs）结合工具的组成视觉推理方法展现出了比端到端VR方法更有效的潜力。然而，这些方法存在局限性，即冻结的LLMs在VR中缺乏工具感知能力，导致性能瓶颈。尽管在其他领域利用LLMs进行推理较为广泛，但在VR中直接应用时受限于有限的训练数据、不完美的工具引入的误差以及对噪声工作流程的微调困难.

Innovation: 
本文提出了一种名为DWIM的方法：i) 差异感知工作流生成（Discrepancy-aware training Workflow generation），评估工具使用情况并提取更可行的工作流进行训练；ii) 指令遮蔽微调（Instruct-Masking fine-tuning），引导模型只克隆有效的动作，生成更具实践性的解决方案。研究表明，DWIM在多个视觉推理任务中取得了目前最好的性能，展示了在多个常用数据集上的强大泛化能力.

Conclusion: 
实验结果表明，DWIM在各种视觉推理任务中实现了最先进的性能，展示了在多个广泛使用的数据集上的强大泛化能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.19263</guid><pubDate>Fri, 27 Jun 2025 02:39:53 +0800</pubDate></item><item><title>278. cs.CV-通过半监督视频语义分割中的语义相似性传播实现自主飞行中的高时间一致性</title><link>https://arxiv.org/pdf/2503.15676</link><description>Background: 
RGB摄像机的语义分割对于自主飞行车辆的感知至关重要。视频中预测的稳定性对其实用性和扩展性以及代理的信任度至关重要。然而，在这一领域，数据可用性是一个挑战，特别是在标注数据稀缺的情况下，现有的方法难以保持高时间一致性。为解决这一问题，本文提出了一种轻量级的时间一致性的视频语义分割方法，能够在飞行器上实现实时推理，并通过语义相似性传播（Semantic Similarity Propagation, SSP）跨帧传播预测，以补偿摄像机移动的影响，从而实现高质量的监督并提高时间一致性。由于数据标注不充分，本研究还提出了一种知识蒸馏（Knowledge Distillation, KD）训练程序，用于稀疏标注数据集的半监督学习。

Innovation: 
本文提出了一种轻量级的视频语义分割方法——语义相似性传播（SSP），能够在飞行数据上实现高度的时间一致性。SSP通过全球注册对齐来跨帧传播预测，并结合当前估计和先验预测，使用从两帧特征相似性计算得到的权重，通过线性插值来进行融合。此外，研究还提出了一种应对稀疏标注数据的知识蒸馏（KD）训练程序，通过使用大型图像分割模型作为教师来训练高效的SSP，从而利用标记帧与未标记帧之间的强相关性，为所有帧提供高质量的监督，因此在UAVid和RuralScapes数据集上分别实现了12.5%和6.7%的时间一致性显著提升，与基线图像分割模型相比，准确率更高，推理速度相当。并且与面向通用应用的其他视频方法相比，本研究在空中数据集上提供的分割质量和推理速度的权衡优于其他方法，且一致性更高。

Conclusion: 
本文提出的方法在半监督学习框架下提高了时间一致性，相比基线模型，精度更高，推理速度相当。特别是在处理稀疏标注的飞行数据集时，提高了整体的时间一致性，优于其他视频方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.15676</guid><pubDate>Fri, 27 Jun 2025 02:39:52 +0800</pubDate></item><item><title>279. cs.CV-3D Hierarchical Panoptic Segmentation in Real Orchard Environments Across Different Sensors</title><link>https://arxiv.org/pdf/2503.13188</link><description>Background: 
精确的作物产量估计对于农业来说是一个相关问题，因为它可以支持农民在收割或精确干预方面做出决策。机器人能够帮助自动化这一过程，但需要能够感知周围环境以识别目标对象，如树木和植物。因此，需开发一种新的方法针对不同传感器提供的3D数据进行苹果果园的分层全景分割。现有的方法在3D全景分割方面表现不佳，无法同时提供语义分割、树干和果实的实例分割以及树木的实例分割，从而难以识别相关信息并捕捉它们之间的关系，例如准确估计果园中每棵树所关联的果实数量。为此，研究团队设计了一个专用数据集，用于评估他们的方法在实际果园环境下的3D分层全景分割效果。

Innovation: 
提出了一种新颖的方法，针对不同传感器提供的3D数据进行苹果果园的分层全景分割。该方法能同时进行语义分割、树干和果实的实例分割以及树木的实例分割，从而识别相关信息并捕捉它们之间的关系，更准确地估计果园中每棵树所关联的果实数量。通过设计专门的数据集，在实际果园环境中对不同传感器进行测试，该方法在农业领域3D全景分割方面超越了现有技术，提供了完整的分层全景分割结果。

Conclusion: 
研究团队提出了一种新颖的方法并在实际果园环境中进行测试，结果显示该方法在农业领域的3D全景分割方面表现优于现有技术，同时能够提供完整的分层全景分割结果。团队还提供了用于评估方法的数据集和开源实现，以促进该领域的研究进一步发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.13188</guid><pubDate>Fri, 27 Jun 2025 02:39:52 +0800</pubDate></item><item><title>280. cs.CV-STI-Bench: MLLMs是否准备好进行精确的空间-时间世界理解？</title><link>https://arxiv.org/pdf/2503.23765</link><description>Background: 
近年来，使用多模态大型语言模型（MLLMs）作为端到端解决方案来解决具身AI和自动驾驶问题的趋势变得非常流行。尽管MLLMs已在视觉语义理解任务中得到了广泛研究，但在真实世界应用中它们能否进行精确和定量的空间-时间理解仍然未知，这给其未来的发展带来了不确定性。

Innovation: 
该论文提出了一种名为STI-Bench的基准测试，用于评估MLLMs的空间-时间理解能力。这个基准测试包括一系列挑战性的任务，如估计和预测物体的外观、姿态、位移和运动。实验涵盖了从桌面到室内再到室外的各种机器人和车辆操作。这些研究结果揭示了最先进的MLLMs在真实世界的空间-时间理解上仍然存在困难，特别是在需要精确距离估计和运动分析的任务中。

Conclusion: 
最新的MLLMs在现实世界的空间-时间理解方面仍面临挑战，尤其在需要精确距离估计和运动分析的任务中。通过STI-Bench的评估揭示了这一点，强调了需要进一步研究以提升MLLMs的空间-时间理解能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.23765</guid><pubDate>Fri, 27 Jun 2025 02:39:51 +0800</pubDate></item><item><title>281. cs.CV-SimWorld: 通过世界模型实现模拟器条件化场景生成的统一基准</title><link>https://arxiv.org/pdf/2503.13952</link><description>Background: 
随着自主驾驶技术的迅速发展，感知模型的准确性受到缺乏数据的严重限制。研究者正在探索采用世界模型的可控数据生成方法以多样化数据集。尽管以前的工作主要集中在特定公开数据集上的图像生成质量研究，但对于如何构建适用于真实世界应用场景的数据生成引擎以实现挑战性场景的大规模数据生成，研究仍然相对较少。

Innovation: 
本文提出了一种基于世界模型的模拟器条件化场景生成引擎SimWorld。通过构建与真实世界场景一致的模拟系统，可以从任何场景中收集可用于世界模型数据生成的仿真数据和标注信息。该方法结合了模拟引擎强大的场景模拟能力和世界模型强大的数据生成能力，形成了一种新颖的数据生成流水线，并提供了一个包含适当比率虚拟与真实数据的基准，以探索世界模型在真实世界场景中的能力。定量结果表明，生成的图像可以显著提升下游感知模型的性能。此外，还探讨了世界模型在城市自主驾驶场景中的生成性能。所有数据和代码将在该链接处发布：this https URL

Conclusion: 
通过构建与真实世界场景一致的模拟系统，收集用于世界模型的数据，并提供了一个基准数据集，这个方法显著增强了在真实世界场景中应用世界模型的能力，特别是在城市自主驾驶场景中表现出较好的生成性能。未来将在开放平台上共享数据和代码，供其他研究者使用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.13952</guid><pubDate>Fri, 27 Jun 2025 02:39:50 +0800</pubDate></item><item><title>282. cs.CV-解耦以重建：通过主动特征解耦和可逆融合实现高品质UHD恢复</title><link>https://arxiv.org/pdf/2503.12764</link><description>Background: 
超高清（UHD）图像恢复通常会面临计算瓶颈和信息损失，因为其极高分辨率。现有的基于变分自编码器（VAE）的研究通过将图像恢复过程从像素空间转移到潜在空间来提高效率。但是，降级成分在降级图像中与背景元素固有地耦合在一起，压缩过程中的信息丢失和补偿过程中的信息获得仍然难以控制。这些导致恢复的图像常常出现细节损失和不完全的降质去除。

Innovation: 
本文提出了一种控制差异解耦VAE，利用层次对比解耦学习和正交门控投影模块，引导VAE主动丢弃易于恢复的背景信息，同时将更难以恢复的降级信息编码到潜在空间中。此外，设计了一个复杂的可逆多尺度融合网络来处理背景特征，确保其一致性，并利用潜在空间恢复网络将降级的潜在特征转换，从而实现更准确的恢复结果。

Conclusion: 
大量的实验结果表明，相比于VAE模型，本文的方法有效缓解了信息丢失问题，同时保证了计算效率，显著改善了UHD图像恢复的质量，并在六个UHD恢复任务中仅使用1M参数就达到了最佳结果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.12764</guid><pubDate>Fri, 27 Jun 2025 02:39:49 +0800</pubDate></item><item><title>283. cs.CV-AnyCalib：基于流形学习的模型无关单视角相机标定</title><link>https://arxiv.org/pdf/2503.12701</link><description>Background: 
当前的相机标定方法大多针对特定的相机模型，并且通常需要额外的外部线索（如地心引力方向）在图像中可见才能进行标定。这限制了这些方法的应用范围和灵活性。本文提出了AnyCalib方法，它能够在单一野外观测图像中无须关心相机模型地自动标定相机的内参数。研究表明，图像中的透视和失真线索足够用于模型无关的相机标定。

Innovation: 
本文提出了AnyCalib方法，其创新点在于能够在单一野外观测图像中无须关心相机模型地自动标定相机的内参数。不同于现有的大多数方法，该方法不需要额外的外部线索，并且能够处理编辑过的（裁剪和拉伸过）图像。此外，实验结果显示，尽管训练数据量少得多，但AnyCalib方法在性能上却优于其他方法，包括3D基础模型。

Conclusion: 
研究证明，通过将标定过程近似为每个像素所对应射线的回归，利用图像中的透视和失真线索，可以实现对多种相机模型内参数的封闭形式恢复，包括针孔、Brown-Conrady和Kannala-Brandt模型等。实验结果显示，AnyCalib方法性能优越，目前已在大量实验中得到验证，并开放了源代码。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.12701</guid><pubDate>Fri, 27 Jun 2025 02:39:48 +0800</pubDate></item><item><title>284. cs.CV-GroundCap: 一个视觉导向的图像标题数据集</title><link>https://arxiv.org/pdf/2502.13898</link><description>Background: 
当前的图像描述系统缺乏将描述性文本与特定视觉元素关联的能力，使得其输出难以验证。尽管最近的方法在一定程度上提供了这种能力，但它们无法跨多个引用跟踪对象身份或同时将动作和对象接地。现有的图像描述系统存在一定的局限性，尤其是在识别和跟踪特定物体方面存在困难。因此，需要一种新的方法来增强图像描述的准确性和可验证性。

Innovation: 
本文提出了一种基于ID的定位系统，该系统能够实现一致的对象引用跟踪和动作-对象链接。引入了GroundCap数据集，包含52,016张来自77部电影的图像，每个图像都包含344个人工标注和52,016个自动生成的描述。这些描述与检测到的对象（132类）和动作（51类）相关，并使用标签系统保持对象身份链接动作至相应的对象。此外，提出了一种名为gMETEOR的评估指标，结合了描述质量和定位准确性。通过微调Pixtral-12B和Qwen2.5-VL 7B模型，建立了基准性能。人类评估也证明了这种方法在生成能够验证的描述方面的有效性，这些描述具有连贯的对象引用

Conclusion: 
该研究提出了一种新的基于ID的定位方法，并通过GroundCap数据集验证了其效果。该方法不仅能够提升图像描述的准确性，还能够使描述变得更加可信和连贯。此外，研究人员还提出了一种新的评估指标，为未来的研究提供了新的参考。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.13898</guid><pubDate>Fri, 27 Jun 2025 02:39:44 +0800</pubDate></item><item><title>285. cs.CV-UP-VLA: 一种统一的理解与预测模型</title><link>https://arxiv.org/pdf/2501.18867</link><description>Background: 
近期视觉-语言-动作（VLA）模型的进步利用了预训练的视觉-语言模型（VLMs）来提高泛化能力。VLMs通常在视觉-语言理解任务上进行预训练，提供了丰富的语义知识和推理能力。然而，先前的研究表明，VLMs往往专注于高层语义内容，而忽略了低层次特征，这限制了它们捕获详细的空间信息和理解物理动态的能力。这些对于具身控制任务至关重要的方面，在现有的预训练范式中被严重忽视。

Innovation: 
本文研究了VLA的训练范式，并引入了名为UP-VLA的统一VLA模型，该模型结合了多模态理解和未来预测目标，增强了高层语义理解和低层次空间理解。实验结果表明，UP-VLA在Calvin ABC-D基准测试中的性能比前一种最先进的方法提高了33%。此外，UP-VLA在现实世界的操作任务中也表现出更好的成功率，尤其是在需要精确空间信息的任务中.

Conclusion: 
实验结果显示，UP-VLA在Calvin ABC-D基准测试中相比前一种最先进的方法提升了33%的性能，并且在现实世界的操作任务中表现出更好的成功率，特别是在需要精确空间信息的任务中。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.18867</guid><pubDate>Fri, 27 Jun 2025 02:39:41 +0800</pubDate></item><item><title>286. cs.CV-ARTalk：基于自回归模型的语音驱动3D头部动画</title><link>https://arxiv.org/pdf/2502.20323</link><description>Background: 
现有的基于扩散的语音驱动3D面部动画方法能够生成自然的面部动作，但其生成速度较慢，限制了其应用潜力。

Innovation: 
提出了一种新颖的自回归模型，通过学习从语音到多尺度运动码本的映射，实现了实时同步的唇动和真实头部姿态与眨眼生成。该模型能够适应未见过的讲话风格，能够创建具有独特个人风格的3D对话化身，超越了训练期间所见的身份类型。大量评估和用户研究表明，该方法在唇同步准确性和感知质量方面优于现有方法。

Conclusion: 
通过引入自回归模型，ARTalk方法能够在实时生成高质量的3D面部动画方面取得突破，特别是在唇同步的准确性和用户感知质量上表现出色，为3D面部动画的实际应用开辟了新的可能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.20323</guid><pubDate>Fri, 27 Jun 2025 02:39:40 +0800</pubDate></item><item><title>287. cs.CV-零视线：关注时序一致性的零样本照明引导低光照视频增强</title><link>https://arxiv.org/pdf/2503.11175</link><description>Background: 
低光照和水下视频由于视野差、对比度低、噪声高，需要提高视觉质量。现有方法通常依赖配对的真实数据，这限制了其实际应用，并常导致时间一致性问题。

Innovation: 
提出了一种新颖的零样本学习方法Zero-TIG，结合Retinex理论和光学流技术。该方法包含增强模块和时序反馈模块。增强模块包括去噪、照明估计和反射去噪三个子网络。时序增强模块通过引入直方图均衡、光学流计算和图像变换来确保时间一致性，保持连续性。同时，该方法针对水下数据中的颜色失真进行了适应性调整，以平衡RGB通道。实验结果表明，该方法在不需要配对训练数据的情况下实现了低光照视频的增强，是一种适用于实际场景的增强方法。

Conclusion: 
本方法无需配对真实数据即可实现低光照视频的增强，具有增强现实场景的潜力，展示了其实践应用价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.11175</guid><pubDate>Fri, 27 Jun 2025 02:39:38 +0800</pubDate></item><item><title>288. cs.CV-PP-DocBee: 通过多样技巧提高多模态文档理解</title><link>https://arxiv.org/pdf/2503.04065</link><description>Background: 
随着数字化的快速发展，各种文档图像在生产和日常生活中被广泛应用，对文档图像内容的快速和准确解析需求日益迫切。

Innovation: 
PP-DocBee是一种专为端到端文档图像理解设计的新型多模态大型语言模型。首先，提出了一个针对文档场景的数据合成策略，构建了一个多样化的数据集以提高模型的泛化能力。其次，应用了多种训练技术，包括动态比例采样、数据预处理和OCR后处理策略。广泛的评估表明PP-DocBee在英语文档理解基准测试中达到了最佳性能，并且在中文文档理解上也超越了现有开源和商业模型。

Conclusion: 
PP-DocBee在文档图像理解方面取得了显著成果，其优化的数据合成策略和多样化的训练技术使得其在多个文档理解基准测试中表现优异，同时源代码和预训练模型已公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.04065</guid><pubDate>Fri, 27 Jun 2025 02:39:38 +0800</pubDate></item><item><title>289. cs.CV-重新思考在不受约束场景中检测显眼和伪装物体的方法</title><link>https://arxiv.org/pdf/2412.10943</link><description>Background: 
现有的模型难以区分显眼物体和伪装物体，特别是显眼物体检测（SOD）模型经常错误地将伪装物体分类为显眼物体，而伪装物体检测（COD）模型则会把显眼物体误认为是伪装的。这种现象被认为主要是由于当前SOD和COD数据集中特定的注释模式和当前模型缺乏对显眼和伪装物体之间显式属性关系建模所致。当前的数据集假设每个场景要么包含显眼物体要么包含伪装物体，这与现实世界的情况不符。同时，现有的SOD/COD方法主要针对这些高度受限的数据集，没有显式建模显眼和伪装物体之间的关系。

Innovation: 
本文构建了一个名为USC12K的大规模数据集，该数据集具有全面的标签和涵盖所有显眼和伪装物体可能性存在的四个不同场景，从而促进了在不受约束场景中检测显眼和伪装物体的发展。此外，提出了一个名为USCNet的模型，该模型引入了两种不同的提示查询机制来建模样本间和样本内的属性关系。为此，还设计了一个评价指标CSCS，用于评估模型区分显眼和伪装物体的能力。提出的模型在多个指标上达到了最先进的性能。

Conclusion: 
提出的USCNet模型和CSCS评价指标在多个场景上的不同指标上均达到了最先进的性能。此外，USC12K数据集也包含了全面的注释和多样化的场景，这些都为开发不受约束场景中的显眼和伪装物体检测提供了新的途径。未来可能会进一步探讨和完善USCNet模型和CSCS评价指标的性能，并尝试在其他感知任务中应用这些方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.10943</guid><pubDate>Fri, 27 Jun 2025 02:39:33 +0800</pubDate></item><item><title>290. cs.CV-利用基础视觉变压器在材料中提取微结构表征以学习微结构-性能关系</title><link>https://arxiv.org/pdf/2501.18637</link><description>Background: 
在计算材料科学中，从数据中学习微结构-性能关系的机器学习方法正在兴起。现有机器学习工作主要集中在为每个微结构-性能关系开发特定任务的模型上。本文探讨了利用预训练的基础视觉变压器来提取任务无关的微结构特征，并进行微结构依赖性性质的轻量级机器学习的方法。这种方法通过预先训练的先进视觉变压器（CLIP、DINOv2、SAM）在两个案例研究中得到了证明：(i)基于模拟数据的双相微结构的弹性模量；(ii)基于文献实验数据的镍基和钴基高温合金的维氏硬度。研究结果表明，基础视觉变压器在微结构表征方面的潜力，并且能够在不需要昂贵的特定任务训练或调整定制深度学习模型的情况下有效学习微结构-性能关系。

Innovation: 
本文提出利用预训练的基础视觉变压器来提取任务无关的微结构特征，并进行轻量级的微结构依赖性性质机器学习。这种方法通过预先训练的先进视觉变压器在模拟数据和实验数据的案例研究中得到验证。证明了在无需昂贵的特定任务训练或调整定制深度学习模型的情况下，可以有效学习微结构-性能关系。

Conclusion: 
本文研究了利用预训练的基础视觉变压器来学习微结构-性能关系的方法。通过两个案例研究展示了这种方法的有效性，并证明了其在无需昂贵的特定任务训练或调整定制深度学习模型的情况下，可以有效学习微结构-性能关系的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.18637</guid><pubDate>Fri, 27 Jun 2025 02:39:33 +0800</pubDate></item><item><title>291. cs.CV-DisCoPatch：利用对抗性驱动的批统计信息改进出轨分布检测</title><link>https://arxiv.org/pdf/2501.08005</link><description>Background: 
出轨分布（OOD）检测在许多应用场景中具有重要意义。尽管对语义和领域位移的OOD问题已有深入研究，但本文专注于共变量偏移（covariate shift）- 数据分布中的细微变化，这种变化会降低机器学习性能。研究团队假设检测这些细微偏移有助于理解分布边界，从而改善OOD检测。在使用批标准化（BN）进行训练的对抗性判别器中，真实样本与生成的对抗样本形成有区别的域，并具有独特的批统计特性，这一机制被用于实现OOD检测。

Innovation: 
本文引入了一种无监督的对抗性变分自动编码器（VAE）框架——DisCoPatch，其利用对抗性驱动的批统计特性。该框架使用VAE的最佳输出和次优输出作为生成样本和重建样本，以此作为负面样本来训练判别器，从而提高其在区分分布内样本和共变量偏移方面的性能。通过紧缩分布边界，DisCoPatch在公共OOD检测基准测试中取得了最先进的性能。该模型不仅在检测共变量偏移方面表现出色，还超越了所有先前方法，在公共的Near-OOD基准测试中也表现出优异性能，同时保持了紧凑的模型大小和较低的计算延迟，使其成为现实世界OOD检测应用的实际高效解决方案。

Conclusion: 
DisCoPatch通过改进对抗性驱动的批统计机制，在公共OOD检测基准测试中达到了最先进的结果。它不仅在检测共变量偏移方面表现出色，还超越了所有现有方法，并且具有紧凑的模型大小和较低的延迟，使其成为实际应用中的高效解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.08005</guid><pubDate>Fri, 27 Jun 2025 02:39:32 +0800</pubDate></item><item><title>292. cs.CV-LBONet:监督谱描述符进行形状分析</title><link>https://arxiv.org/pdf/2411.08272</link><description>Background: 
拉普拉斯-贝尔特拉米算子在非刚性形状分析领域已经确立了其重要地位，因为它具有很多有用特性，比如在等距变换下保持不变，具有可以形成正交规范基的一系列可数特征值系统，并且能够完全描述流形的测地线距离。然而，这种不变性只适用于等距变形，这在许多现实世界的应用中会表现不佳。近年来，强调使用深度学习方法来提取最优特征，而频谱特征仍然具有重要作用并带来价值。在这篇论文中，作者重新审视了拉普拉斯-贝尔特拉米算子（LBO），并提出了一种监督方式来在流形上学习多个算子。根据任务的不同，通过这些函数的应用，可以训练LBO特征基底以更适合特定任务。对LBO的优化极大地提高了诸如热核签名等已建立描述符在各种任务（如检索、分类、分割和对应）中的表现，表明LBO特征基底可以适应全局和高度局部的学习环境。

Innovation: 
论文提出了一种新的方法，通过监督学习方式来在流形上学习拉普拉斯-贝尔特拉米算子（LBO），并且根据任务的不同，训练LBO特征基底以使其更适合特定任务。这种方法优化了已建立的描述符，如热核签名，在各种任务中的表现，表明LBO特征基底可以适应全局和高度局部的学习环境。特别地，LBONet方法通过优化LBO算子实现显著改进，并证明了其在不同形状分析任务中的有效性。

Conclusion: 
通过对拉普拉斯-贝尔特拉米算子的监督学习优化，作者证明了LBO特征基底在多种形状分析任务上的有效适应性。特别是LBONet方法在检索、分类、分割和对应等任务上取得了巨大改进，展示了LBO在监督学习中的价值和潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.08272</guid><pubDate>Fri, 27 Jun 2025 02:39:30 +0800</pubDate></item><item><title>293. cs.CV-ClearSight: 事件驱动运动去模糊的人类视觉启发式解决方案</title><link>https://arxiv.org/pdf/2501.15808</link><description>Background: 
运动去模糊解决摄影或场景移动导致的图像模糊挑战。事件相机通过异步事件流提供运动信息，这些信息是编码在时间信息中的。为了有效利用事件流的时序信息，研究使用脉冲神经网络（SNNs）进行运动特征提取，并使用人工神经网络（ANNs）进行颜色信息处理。由于事件数据的非均匀分布和固有冗余，现有的跨模态特征融合方法存在一定的局限性。

Innovation: 
该研究引入了一种生物启发的双驱动混合网络（BDHNet），具体包括神经配置模块（NCM）和模糊关注区域模块（RBAM）。NCM能够根据跨模态特征动态调整神经元配置，从而在模糊区域集中脉冲，并动态适应不同程度的模糊场景。RBAM则在无监督的情况下生成模糊掩码，有效从事件特征中提取运动线索并指导更准确的跨模态特征融合。

Conclusion: 
广泛的主观和客观评估表明，该方法在合成数据集和实际数据集上均优于当前最先进的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.15808</guid><pubDate>Fri, 27 Jun 2025 02:39:30 +0800</pubDate></item><item><title>294. cs.CV-SweepEvGS: 基于事件的3D高斯点云渲染方法及其在单次扫掠中对宏观和微观辐射场渲染的应用</title><link>https://arxiv.org/pdf/2412.11579</link><description>Background: 
近年来，3D高斯点云（3D-GS）的技术进步展示了使用3D高斯原始模型进行高速、高质量和低成本的新视角合成的潜力，尤其是在连续校准输入视角的情况下。然而，传统方法需要高帧率的密集高质量锋利图像，这些图像的捕捉非常耗时且效率低下，尤其是在动态环境中。事件摄像机因其高时间分辨率和能够捕捉异步亮度变化的能力，提供了在无运动模糊的情况下进行更可靠场景重建的有希望的替代方案。

Innovation: 
本文提出了SweepEvGS，一种新颖的硬件集成方法，利用事件摄像机从单次扫掠中在各种成像设置下实现可靠和准确的新视角合成。SweepEvGS 利用单次扫掠期间捕捉的密集事件流初期静态帧来有效地重构详细的场景视图。还引入了不同的现实世界硬件成像系统进行现实世界数据的采集和评估，以供未来研究使用。通过在三种不同成像设置下的实验验证了SweepEvGS的鲁棒性和效率：合成对象，现实世界的宏观级别，以及现实世界的微观级别视图合成。结果显示，SweepEvGS在视觉渲染质量、渲染速度和计算效率方面优于现有方法，突显了其在动态实践中的应用潜力。

Conclusion: 
我们的结果表明，SweepEvGS在视觉渲染质量、渲染速度和计算效率方面超越了现有的方法，突显了其在动态实践中应用的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.11579</guid><pubDate>Fri, 27 Jun 2025 02:39:27 +0800</pubDate></item><item><title>295. cs.CV-Materialist: 使用单图像逆渲染的基于物理的编辑</title><link>https://arxiv.org/pdf/2501.03717</link><description>Background: 
在计算机视觉中，实现物理上一致的图像编辑仍然是一项重大挑战。现有的图像编辑方法通常依赖于神经网络，而这在处理阴影和折射方面很难准确。相比之下，基于物理的逆向渲染通常需要多视角优化，这在单图像场景中不太实用。因此，如何既能利用学习方法的灵活性，又能解决物理上一致性问题，成为了一个亟待解决的问题。

Innovation: 
本文提出了Materialist方法，结合了基于学习的方法与基于物理的渐进可微渲染。该方法利用神经网络预测初始材料属性，然后使用可微分渲染逐进优化环境图以进一步细化材料属性，其目标是使渲染结果尽可能贴近输入图像。这种方法能够应用于材料编辑、对象插入、重新照明等，同时提供了一种在无需完整场景几何的情况下编辑材料透明度的有效方法。此外，该方法在环境图估计方面也达到了最先进的性能，进一步提高了图像编辑任务的准确性。

Conclusion: 
实验表明，该方法在合成和真实世界数据集上表现出强大的性能，甚至在复杂的离域图像中也表现出色。这对于单图像编辑任务是一个重要的贡献。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.03717</guid><pubDate>Fri, 27 Jun 2025 02:39:27 +0800</pubDate></item><item><title>296. cs.CV-Pretrained Reversible Generation作为无监督视觉表示学习</title><link>https://arxiv.org/pdf/2412.01787</link><description>Background: 
近年来，基于评分匹配和流量匹配的生成模型在生成任务上取得了显著进展，但它们在判别任务上的应用潜力尚未得到充分利用。先前的方法，如生成分类器，未能充分利用这些模型的判别能力，因为它们的设计较为复杂。

Innovation: 
本文提出了预训练可逆生成（PRG），它通过反转预训练连续生成模型的生成过程来提取无监督表示。PRG有效地重用了这些无监督生成模型，并利用它们的高容量作为稳健且通用的特征提取器，以支持下游任务。该框架允许根据特定下游任务灵活选择特征层次结构。实验结果表明，该方法在多个基准测试中始终优于先前的方法，并在生成模型方法中达到了最先进的性能，其中在64*64分辨率的ImageNet数据集上实现了78%的Top-1准确率。严谨的消融研究，包括遍历分布评估，进一步验证了该方法的有效性。

Conclusion: 
与先前基于生成模型的方法相比，该方法在多个基准测试中实现了最先进性能，特别是在64*64分辨率的ImageNet数据集上的Top-1准确率达78%。广泛的消融研究进一步验证了该方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.01787</guid><pubDate>Fri, 27 Jun 2025 02:39:25 +0800</pubDate></item><item><title>297. cs.CV-SIDA: 社交媒体图像深度伪造检测、定位与解释 large多模态模型</title><link>https://arxiv.org/pdf/2412.04292</link><description>Background: 
生成模型的迅速发展使其能够生成高度逼真的图像，这带来了信息误导的严重风险。例如，合成图像在社交媒体上的分享可能会误导大量受众，破坏对数字内容的信任并导致严重后果。目前学术界尚未创建一个庞大且多样化的深度伪造检测数据集，也没有提出有效的解决方案来解决这一问题。

Innovation: 
作者提出了一个新的图像深度伪造检测、定位和解释框架SIDA（Social media Image Detection, localization, and explanation Assistant）。该框架利用大型多模态模型的优势，不仅鉴别图像的真实性，还能通过掩膜预测标记伪造区域，并提供模型决策依据的文本解释。与SID-Set和其他基准上的最新深度伪造检测模型相比，广泛的实验结果表明，SIDA在多个设置中取得了优越的性能。

Conclusion: 
SIDA不仅在检测深度伪造方面表现优秀，还能提供详细的解释和定位。此外，作者还释放了代码、模型和数据集。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.04292</guid><pubDate>Fri, 27 Jun 2025 02:39:19 +0800</pubDate></item><item><title>298. cs.CV-InfiniCube: 通过世界导向的视频模型实现无界限可控动态3D驾驶场景生成</title><link>https://arxiv.org/pdf/2412.03934</link><description>Background: 
之前的场景生成方法要么在规模上受到限制，要么缺乏沿生成序列的几何和外观一致性。InfiniCube 利用可扩展的3D表示和视频模型的最新进展，实现了大规模的动态场景生成，这种生成允许通过高清地图、车辆边界框和文本描述进行灵活控制。

Innovation: 
InfiniCube 方法通过构建地图条件下的稀疏体素生成模型来实现无限体素世界的生成。通过一组精心设计的像素对齐的指导缓冲区将视频模型适应到体素世界中，实现了外观的一致性。最后还提出了一种快速前馈方法，结合体素和像素分支将动态视频提升为具有可控对象的动态3D高斯分布。

Conclusion: 
InfiniCube 方法能够生成可控且真实的3D驾驶场景，广泛实验验证了模型的有效性和优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.03934</guid><pubDate>Fri, 27 Jun 2025 02:39:19 +0800</pubDate></item><item><title>299. cs.CV-Mr. DETR++: 带混合专家指令多路训练的检测变换器</title><link>https://arxiv.org/pdf/2412.10028</link><description>Background: 
现有的方法通过引入一个辅助的一对多匹配来增强检测变压器的训练。本文作者将模型视为多任务框架，同时执行一对一和一对多预测。他们研究了变压器解码器在处理这两种训练目标时的各组件作用，包括自我注意力、交叉注意力和前馈网络。实验证明，任何解码器中的独立组件都可以同时有效学习这两个目标，即使其他组件被共享。基于这一发现，作者提出了一种多路径训练机制，包括主要路径用于一对一预测和两个辅助路径用于一对多预测。对于辅助路径之一，他们引入了一种指令性自我注意力机制，该机制能够动态和灵活地引导对象查询；对于另一辅助路径，他们引入了一个路径感知的专家混合（MoE），使知识共享更加有效，同时减缓路径之间的潜在冲突。

Innovation: 
提出了指令性多路径训练机制，该机制包括一个主要路径进行一对一预测和两个辅助路径进行一对多预测。他们引入了一种新的指令性自我注意力机制，用于辅助路径之一以动态引导对象查询；另一个辅助路径采用路径感知的MoE来优化效率和效果之间的平衡，尽管在此路径中的辅助路径在推理阶段会被丢弃。

Conclusion: 
该方法在各种目标检测基准上进行了广泛的实验，展示了一致的改进，包括实例分割和语义分割任务的探讨，进一步验证了其有效性。该方法具有高度灵活性，可以容易地适应其他任务。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.10028</guid><pubDate>Fri, 27 Jun 2025 02:39:18 +0800</pubDate></item><item><title>300. cs.CV-MvKeTR：多视图感知与知识增强的胸部CT报告生成</title><link>https://arxiv.org/pdf/2411.18309</link><description>Background: 
CT报告生成（CTRG）旨在自动为3D体积生成诊断报告，减轻临床人员的工作负担并提高患者护理质量。尽管具有临床价值，现有研究在整合多解剖视图的诊断信息以及缺乏必要的临床专业知识方面存在局限性。这导致现有方法难以提供准确可靠的诊断结果。

Innovation: 
提出了一个多视图感知知识增强Transformer（MvKeTR）模型来模拟临床人员的诊断流程。该模型包含一个多视图感知聚合器（MVPA），能够视图感知注意力机制下从多个解剖视图中综合诊断信息。此外，通过借鉴放射科医生查阅相关临床记录以指导诊断决策的方式，设计了一种跨模态知识增强器（CMKE），能够基于查询体积检索最相似的报告，将领域知识融入诊断过程。模型采用了柯尔莫哥洛夫-阿诺德网络（KANs）作为基本构建块，显示出更优秀的参数效率和减少光谱偏差的能力，更利于捕捉CT解释中至关重要的高频成分，同时减少了过拟合。

Conclusion: 
在公开的CTRG-Chest-548K数据集上的大量实验表明，该方法在几乎所有指标上均超越了之前的最先进模型（SOTA）。开源代码在此处 https://github.com/example-link。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.18309</guid><pubDate>Fri, 27 Jun 2025 02:39:18 +0800</pubDate></item><item><title>301. cs.CV-Recall and Refine: 一种简单但有效的无源开放集域适应框架</title><link>https://arxiv.org/pdf/2411.12558</link><description>Background: 
Open-set Domain Adaptation（OSDA）旨在将标记的源域模型适应到未标记的目标域，其中目标域可能存在新的未见过的类。传统的OSDA方法依赖于阈值化预测熵来区分已知和未知类，但未能明确学习目标私有未知类的区分性特征。Source-free Open-set Domain Adaptation（SF-OSDA）方法在不访问源域标记数据的情况下适应目标域，尤其在隐私受到限制的情况下非常相关，但这种方法面临模型适应性、丰度调整和特征区分性等多个挑战。现有的SF-OSDA方法通常依赖熵阈值来区分已知和未知类，但未能学习目标私有未知类的区分性特征。

Innovation: 
提出了一种名为Recall and Refine (RRDA)的新型SF-OSDA框架，该框架通过显式学习目标私有未知类的区分性特征来解决上述问题。RRDA采用两阶段过程，首先通过训练目标分类器识别未知类，引入由目标域特征生成的合成样本来指导决策边界，使分类器能够有效地区分已知和未知类。其次，全面适应模型以处理域转移和与未知类的可分性问题，任何现成的无源域适应方法（例如SHOT、AaD）都可以无缝集成到此框架中。

Conclusion: 
在三个基准数据集上进行的大量实验表明，RRDA在性能上显著优于现有SF-OSDA和OSDA方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.12558</guid><pubDate>Fri, 27 Jun 2025 02:39:16 +0800</pubDate></item><item><title>302. cs.CV-RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation Model</title><link>https://arxiv.org/pdf/2411.17984</link><description>Background: 
遥感基础模型在很大程度上打破了传统的为特定任务设计模型的范式，提供了在多个任务上更大的可扩展性。然而，它们面临着计算效率低和可解释性有限的挑战，特别是处理大规模遥感图像时。本文旨在解决这些挑战，通过借鉴热传导的物理过程来探索使用并行计算模型在高分辨率遥感图像中模拟局部区域相关性的潜在应用，引入了高效的多模态遥感基础模型RS-vHeat。

Innovation: 
文章提出了RS-vHeat模型，该模型具有以下创新点：1) 使用热传导算子（HCO）以O(N^{1.5})的复杂度和全局感受野，降低了计算开销并捕获遥感物体结构信息以指导热量扩散；2) 通过基于频域分层遮罩和多域重建的自监督策略学习各种场景的频率分布表示；3) 在4个任务和10个数据集上，RS-vHeat在效率和性能上显著优于最先进的技术。与基于注意力的遥感基础模型相比，该模型减少了84%的内存使用、24%的FLOPs，并将吞吐量提高了2.7倍。代码将公开提供。

Conclusion: 
RS-vHeat是一种高效多模态遥感基础模型，结合了热传导的并行计算模型来模拟高分辨率遥感图像中的局部区域相关性，通过有效的自监督学习策略提高了模型的效率和性能，并显著降低了内存和计算资源的使用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.17984</guid><pubDate>Fri, 27 Jun 2025 02:39:15 +0800</pubDate></item><item><title>303. cs.CV-破解多云难题：利用Sentinel-1和Sentinel-2时间序列在全球农业景观中实现稳健的边界划定</title><link>https://arxiv.org/pdf/2409.13568</link><description>Background: 
准确划分农田边界对于作物监控和资源管理至关重要，但当前方法往往依赖大量人工努力收集无云数据，并且在适应全球多样化条件时存在局限性。现有的取地方式通常存在显著的挑战。该论文介绍了一种新的深度学习架构PTAViT3D，用于处理来自Sentinel-1或Sentinel-2的三维时间序列卫星影像，同时探讨了一种结合Sentinel-1和Sentinel-2数据的PTAViT3D-CA模型，以增强云污染场景下的鲁棒性。

Innovation: 
该研究提出了一种基于高效3D视觉变换器架构的时空联系模型，能够直接从原始且带有云污染的影像数据中准确划界田地边界。通过PTAViT3D-CA模型将Sentinel-1和Sentinel-2数据进行融合处理，进一步增强模型鲁棒性。该模型通过在多种数据集上的广泛测试，显示了优越的全球可转移性和鲁棒性。研究简化了数据准备工作流，极大地提高了适应不同农业环境的能力。

Conclusion: 
研究结果一致地展示了PTAViT3D和PTAViT3D-CA模型的先进性能，证明了它们在全球不同农业环境中的卓越适应性和鲁棒性。代码和模型已公开提供。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.13568</guid><pubDate>Fri, 27 Jun 2025 02:39:11 +0800</pubDate></item><item><title>304. cs.CV-ClimateIQA: 一个新的数据集和基准，促进气象异常分析的视觉语言模型进步</title><link>https://arxiv.org/pdf/2406.09838</link><description>Background: 
气象热图在解读极端天气现象方面发挥着重要作用，但由于其不规则轮廓、无结构模式和复杂颜色变化等内在复杂性，给最先进的视觉-语言模型（VLMs）带来了独特的分析挑战。当前最先进的模型如GPT-4o、Qwen-VL和LLaVA 1.6在精确颜色识别和空间定位方面存在问题，导致解释不准确或不完整。

Innovation: 
我们引入了Sparse Position and Outline Tracking（SPOT），一种专门用于处理视觉数据中不规则彩色区域的新算法。SPOT通过提取空间坐标来识别和定位这些区域，使其能够为不规则形状提供结构化表示。在此基础上，我们构建了ClimateIQA，这是一个新颖的气象视觉问答（VQA）数据集，包含26,280个高分辨率热图和762,120个指令样本，用于分析风速、总降水量、风寒指数和热指数。ClimateIQA通过整合空间线索、地理元数据和再分析数据，提高了模型在解释和描述极端天气特征时的准确性。此外，我们还开发了基于SPOT增强ClimateIQA的Climate-Zoo系列微调VLMs，这些模型在气象热图任务中显著优于现有模型。

Conclusion: 
ClimateIQA通过提供结构化表示、空间和地理信息大数据集，提高了VLMs在气象异常分析中的性能，Climate-Zoo则体现了这一改进，超越了现有模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.09838</guid><pubDate>Fri, 27 Jun 2025 02:39:05 +0800</pubDate></item><item><title>305. cs.CV-CanFields: 标准化汇聚场用于非刚性4D插值的差动流合并不定长度序列</title><link>https://arxiv.org/pdf/2406.18582</link><description>Background: 
以往的方法在处理非刚性3D点云序列的插值时通常会导致几何过度平滑或产生拓扑和几何特征的错误。因此，这些方法难以保持复杂几何细节和变形。

Innovation: 
引入了新的方法Canonical Consolidation Fields (CanFields)，它可以无缝地将不定长度的独立采样3D点云序列组合成一个统一连续且连贯的变形形状。CanFields 通过两个新的自定义模块，即动态汇聚模块和差动流表示运动，联合优化了基础几何形状和其运动，从而提高了细部几何及变形的准确性，并能处理缺失区域、噪声原始扫描和稀疏数据等复杂情况。

Conclusion: 
实验结果表明，CanFields 在超过50种不同的序列上表现出了更高的鲁棒性和准确性，即使在存在缺失部分、噪声原始扫描和稀疏数据的情况下也能表现出优越性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.18582</guid><pubDate>Fri, 27 Jun 2025 02:39:03 +0800</pubDate></item><item><title>306. cs.CV-学习成为Transformer以精确定点异常</title><link>https://arxiv.org/pdf/2407.04092</link><description>Background: 
工业中现有的异常检测和分割（IADS）方法通过降采样原始输入图像到低分辨率（例如，224x224像素）来高效部署强大的、通常预训练的特征提取器。然而，这种方法可能忽略小缺陷的识别，不利于检测小异常。因此，本文旨在提出一种新的教师-学生架构，以在保持高分辨率输入图像的效率下利用强大的预训练特征。通过这种方法，模型可以在保持快速运行的同时，识别高分辨率图像中的异常，并表现出比竞争对手更好的性能，尤其是在MVTec AD数据集和VisA分割任务上。此外，作者还提出了一种新的评价指标，以评估模型在大缺陷到小缺陷一致性的鲁棒性。实验表明，这种新的方法在这些新的评价指标上表现优秀，具有较明显的优越性。

Innovation: 
提出了一种新的教师-学生架构，称为'学习成为Transformer以精确定点异常'。该方法通过训练两个浅层MLP（学生）模仿冻结的视觉变压器（教师）的自注意力层产生的图像补丁嵌入映射，从而学习需要处理高分辨率输入图像的难题，这些问题对于小容量模型来说很难解决，尤其是应用于异常图像的数据。这种方法能够在保持较高分辨率下识别异常，且运行速度远超竞争对手，表现出在MVTec AD和VisA上的优越性能，并提出了新的评价指标来评估缺陷大小的鲁棒性表现。

Conclusion: 
本文提出的方法在保持高效的处理高分辨率图像的同时，能更好地识别异常，并通过新的评估指标证明其在检测大缺陷到小缺陷上的鲁棒性表现。该研究为工业环境中的异常检测方法提供了一种新的思考方向，尤其在处理小缺陷时展现出明显的优势。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.04092</guid><pubDate>Fri, 27 Jun 2025 02:39:02 +0800</pubDate></item><item><title>307. cs.CV-ToMiE: 向外骨骼化以实现复杂3D人体模型的重建</title><link>https://arxiv.org/pdf/2410.08082</link><description>Background: 
本文指出了在大多数3D人类任务中经常被忽视的关键因素，即建模带手持物或宽松衣物的复杂3D人类。尽管SMPL参数化模型能够很好地拟合人体皮肤，但手持物和宽松衣物很难在统一框架下准确建模，因为它们的运动通常与人体分离。因此，为了增强SMPL骨架应对这种状况的能力，提出了一种生长策略，使骨架的关节树能够适当地扩展。

Innovation: 
本文提出了一个名为ToMiE的方法，该方法包括父关节定位和外部关节优化。通过结合LBS混合权重和运动内核的梯度导向方法实现父关节定位。外部关节一旦确定，通过SE(3)优化不同帧间的变换，实现了增强渲染能力和自由动画生成的新方法。实验表明ToMiE在各种手持物和宽松衣物的情况下具有更好的重建质量，并能提供生长关节的自由动画，从而提升了SMPL骨架的表达能力，适用于更广泛的应用场景。

Conclusion: 
ToMiE方法在手持物和宽松衣物的重建中表现出色，不仅在渲染质量上有所提升，还能够在不同场景中提供生长关节的自由动画，从而增强了SMPL骨架的表达能力，使其在更广泛的3D人类建模应用中更具灵活性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.08082</guid><pubDate>Fri, 27 Jun 2025 02:39:01 +0800</pubDate></item><item><title>308. cs.CV-ROA-BEV: 2D 区域导向注意机制用于基于BEV的3D物体检测</title><link>https://arxiv.org/pdf/2410.10298</link><description>Background: 
基于视觉的鸟类视角（BEV）3D物体检测在自主驾驶中越来越受欢迎。然而，从相机角度来看，与背景高度相似的对象无法被现有方法很好地检测出来。

Innovation: 
提出了一种基于BEV的3D物体检测网络（ROA-BEV），使得骨干网络能够更多地关注物体存在的区域的特征学习。此外，该方法通过多尺度结构进一步增强了ROA的信息特征学习能力。每个ROA块使用大核确保感受野足够大以捕获关于大物体的信息。实验表明，ROA-BEV在nuScenes数据集上的性能优于BEVDepth。

Conclusion: 
该工作中的源代码将在以下链接提供: 这里 https URL。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.10298</guid><pubDate>Fri, 27 Jun 2025 02:39:00 +0800</pubDate></item><item><title>309. cs.CV-利用高效掩码图像建模技术大规模利用卫星图像</title><link>https://arxiv.org/pdf/2406.11933</link><description>Background: 
掩码图像建模（MIM）已成为构建遥感（RS）基础视觉模型的重要方法。然而，现有的RS数据集在规模和多样性方面存在局限性，限制了MIM方法学习通用表示的能力。此外，传统的MIM技术需要重建所有标记，引入了不必要的计算开销。为了解决这些问题，我们提出了一种新的RS模型预训练管道，该管道包括大规模RS数据集的创建和高效的MIM方法。现有RS数据集中的冗余背景像素增加了传统MIM模型的构建复杂度，而我们的方法通过动态编码和重建富含语义的块标记来减少这种无效性，从而提高了效率。

Innovation: 
我们创建了一个高质量的大规模RS数据集OpticalRS-13M，以及提出了一种名为SelectiveMAE的预训练方法，该方法可动态编码和重建富含语义的块标记，减少传统MIM模型中由于RS图像中的冗余背景像素导致的无效性，进而显著提高模型的训练效率。

Conclusion: 
OpticalRS-13M显著改善了分类、检测和分割性能，而SelectiveMAE提高了训练效率超过2倍。这突显了我们管道在开发RS基础模型中的有效性和可扩展性。数据集、源代码和训练模型将在此网站上发布。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.11933</guid><pubDate>Fri, 27 Jun 2025 02:39:00 +0800</pubDate></item><item><title>310. cs.CV-利用多模态大型语言模型提升零样本图像分类能力</title><link>https://arxiv.org/pdf/2405.15668</link><description>Background: 
大型语言模型（LLMs）已经在许多计算机视觉任务中得到了有效应用，包括图像分类。本文介绍了一种利用多模态LLMs进行零样本图像分类的简单而有效的方法。多模态LLMs可以从输入图像生成全面的文本表示，并将其用于生成跨模态嵌入空间中的固定维度特征。这些特征随后被融合以使用线性分类器进行零样本分类。该方法不需要为每个数据集进行提示工程，而是使用单一、简明的提示集覆盖所有数据集。在多个数据集上的评估结果表明，该方法的有效性令人印象深刻，超越了多个数据集的基准准确性。平均而言，该方法在十个基准上实现了6.2个百分点的准确性增益，特别是在ImageNet数据集上提升了6.8个百分点，超过了用相同设置重新评估的先前方法。这表明多模态LLMs有望增强计算机视觉任务，如零样本图像分类，并提供对传统方法的显著改进。

Innovation: 
该方法利用多模态LLMs生成图像的全面文本表示，生成跨模态嵌入空间中的固定维度特征，并通过简单的线性分类器进行零样本分类，无需为每个数据集进行提示工程。相比以往方法在多个数据集上实现了显著的准确性提升。

Conclusion: 
该研究通过多模态LLMs在零样本图像分类中的应用，展示了其对传统方法的显著改进，并探索了多模态LLMs在计算机视觉任务中的潜在应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.15668</guid><pubDate>Fri, 27 Jun 2025 02:38:58 +0800</pubDate></item><item><title>311. cs.CV-HERMES: 临时连贯的长格式理解与情节和语义</title><link>https://arxiv.org/pdf/2408.17443</link><description>Background: 
长格式视频理解带来了超越传统短格式视频分析的独特挑战，特别在于捕捉长距离依赖关系，有效处理冗余信息，以及提取高级语义概念。这些挑战使得现有的视频-语言模型难以在长视频理解方面提供最优性能。

Innovation: 
本文提出了HERMES这一创新方法，它通过引入两个可扩展模块Episodic Compressor (ECO) 和 Semantics Retriever (SeTR)，在保留时间依赖关系的同时，高效地从微至半宏级别聚合表示，在减少计算开销的同时增强了语义信息，从而改善了现有的视频-语言模型的性能，降低了43%的推理延迟和46%的内存使用率。作为独立系统，HERMES在多项长视频理解基准测试中达到了最优性能，无论是零样本还是完全监督设置下均如此。

Conclusion: 
HERMES通过模块化设计，无缝集成到现有的最优模型，提升了其性能，证明了在处理长视频理解问题上的优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.17443</guid><pubDate>Fri, 27 Jun 2025 02:38:57 +0800</pubDate></item><item><title>312. cs.CV-根据生物需求进行细胞追踪 -- 一种强细胞分裂感知的多假设追踪器及其 aleatoric 不确定性评估</title><link>https://arxiv.org/pdf/2403.15011</link><description>Background: 
细胞追踪和分割有助于生物学家从大规模显微镜时间序列数据中提取见解。当前的方法虽然在局部准确性方面表现出色，但往往会因缺乏长期一致性以及重建正确的谱系树能力不足而受到批评。因此，需要改进的方法能够克服这些挑战，提供更准确和可靠的细胞追踪结果。

Innovation: 
本文提出了一种用于运动估计框架的不确定估计技术，并扩展了多假设追踪框架。该技术通过问题特定的测试时间增强将运动表示提升为概率空间密度。此外，还引入了一种新的细胞分裂感知分配问题表述，使多假设追踪器能够建模细胞分裂并基于长期冲突解决错误关联和错误的细胞分裂检测。在框架中，具体生物学知识被建模为分配成本。

Conclusion: 
我们在九个具有竞争力的数据集上评估了我们的方法，并证明了我们的方法在生物启发的指标上显著优于当前最先进的方法，性能有了大约6倍的提升，并揭示了运动估计不确定性的新见解。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.15011</guid><pubDate>Fri, 27 Jun 2025 02:38:51 +0800</pubDate></item><item><title>313. cs.CV-FairyGen: 仅凭一个儿童绘制的人物创作的故事化卡通视频</title><link>https://arxiv.org/pdf/2506.21272</link><description>Background: 
当前的讲故事方法主要集中在角色的一致性和基础运动上，而不能有效地分离角色建模与风格化的背景生成，并且缺乏支持表达性和连贯性的叙事设计。在制作卡通视频时，需要从单一的角色素描生成故事驱动的视频，同时保持其独特的艺术风格，这是现有技术的局限性所在。因此，本文旨在提出一种自动系统FairyGen，以便从单个儿童的绘画作品中生成故事驱动的卡通视频，确保保留其独特的艺术风格，并且在保持角色视觉身份的同时，合成风格一致的场景。

Innovation: 
1. 提出了一种名为FairyGen的自动系统，用于生成故事驱动的卡通视频，从单个儿童绘画作品生成故事驱动的画卷，同时精确保留其独特的艺术风格。n2. FairyGen通过明确分离角色建模和风格化背景生成，并结合电影镜头设计来支持表达和连贯的故事叙述。n3. 系统首先使用MLLM生成故事板，并包含拍摄级别描述，随后引入一种风格传播适配器来捕获角色的视觉风格并将其应用于背景中，确保视觉一致性，同时合成风格一致的场景。n4. 通过细化基于故事板进行帧裁剪和多视图合成，进一步增强视觉多样性及电影质量。使用3D代理角色重建和基于MMDiT的图像到视频扩散模型进行动画处理，最后通过两阶段运动自定义适配器进行填色和运动帧级调整。n5. FairyGen使用故事板直接渲染多样且连贯的视频场景，生成风格准确、叙述性的自然运动动画，增强了个性化和交互的故事情节表现。

Conclusion: 
大量实验证明，我们的系统能够生成叙述结构自然、符合风格的故事动画，展示了其在个性化和吸引人的故事动画中的潜在应用价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21272</guid><pubDate>Fri, 27 Jun 2025 02:38:50 +0800</pubDate></item><item><title>314. cs.CV-高效变长注意力头部的图像生成</title><link>https://arxiv.org/pdf/2211.05770</link><description>Background: 
尽管将变压器整合进视觉模型在视觉任务中带来了显著的改进，但这些模型仍需要大量的计算资源进行训练和推理。限制性的注意力机制虽然能显著减少计算负担，但会导致全局或局部一致性方面的损失。现有的方法在计算效率与图像生成一致性之间存在权衡。本文提出了一个简单而强大的方法：允许单个变压器的注意力头考虑到多个感受野。所提出的模型，名为StyleNAT，在FFHQ数据集上实现了2.05的FID得分，比StyleGAN-XL提高了6%，同时参数减少了28%，并且具有4倍的吞吐量能力。StyleNAT在FFHQ-256数据集上达到了帕累托前沿，并在其他数据集上展示了强大的高效图像生成能力。作者已将代码和模型检查点公开发布。

Innovation: 
提出了一种简单而强大的方法，即允许单个变压器的注意力头关注多个感受野，通过这种方式减少计算成本与图像生成一致性之间的权衡。该方法被应用于基于StyleGAN的架构中，形成了StyleNAT模型。

Conclusion: 
在FFHQ数据集上，StyleNAT实现了2.05的FID得分，优于StyleGAN-XL，参数减少28%，并具有4倍的吞吐量能力。StyleNAT在FFHQ-256和其它数据集上展示了强大的图像生成能力。代码和模型权重已公开发布。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2211.05770</guid><pubDate>Fri, 27 Jun 2025 02:38:47 +0800</pubDate></item><item><title>315. cs.CV-基于多源数据融合的遗迹滑坡检测语义分割模型</title><link>https://arxiv.org/pdf/2308.01251</link><description>Background: 
滑坡作为一种自然灾害，给人类生命和财产带来了巨大的损失，因此迫切需要一种可靠的滑坡风险检测方法。特别是在检测遗迹滑坡时，由于图像模糊和数据集规模较小等问题，利用遥感图像进行检测造成了很大的挑战。准确提取语义特征仍面临诸多问题，特别是在高分辨率遥感图像和数字高程模型数据融合方面。

Innovation: 
提出了一种基于超像素对比学习增强分割网络（HPCL-Net），通过HPCL改进了边界区域的局部显著特征提取，并通过语义空间中异质信息的融合提高了提取能力。此外，还开发了一种全局超像素样本对队列基于对比学习的方法，包括构建存储超像素样本的全局队列和更新方案，进一步增强了语义特征的提取能力。这些创新方法使得模型在遗迹滑坡检测任务上表现优异，验证了在实验结果上的提升，包括mIoU、Landslide IoU和F1评分的显著增加。

Conclusion: 
提出的HPCL-Net在遗迹滑坡检测数据集上的评价表明，该模型相对于现有模型显著提升了检测性能，其中mIoU从0.620提升到0.651，Landslide IoU从0.334提升到0.394，F1分数从0.501提升到0.565。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2308.01251</guid><pubDate>Fri, 27 Jun 2025 02:38:45 +0800</pubDate></item><item><title>316. cs.CV-探索用于CT报告生成的3D MLLMs设计空间</title><link>https://arxiv.org/pdf/2506.21535</link><description>Background: 
多模态大型语言模型（MLLMs）已经成为自动化放射学报告生成（RRG）的一种有前途的方法。本文系统地探讨了3D MLLMs的设计空间，包括视觉输入表示、投影器、大型语言模型（LLMs）和3D CT报告生成的微调技术。此外，还引入了两种基于知识的报告增强方法，这些方法在GREEN评分上最多可以提高10%，并在MICCAI 2024 AMOS-MM挑战赛中取得了第2名的成绩。

Innovation: 
本文的研究重点在于系统探索3D MLLMs的设计空间，包括视觉输入表示、投影器、大型语言模型以及3D CT报告生成的微调技术。还提出了基于知识的报告增强方法，显著提高了GREEN评分，并在MICCAI 2024 AMOS-MM挑战赛中取得了优异成绩。此外，研究表明，在同一训练协议下，LLM的大小并未显著影响RRG的效果，并且更大的体积大小并不总是提升性能，特别是当最初的ViT预训练在较小的体积大小上时。最后，使用分割掩码与CT体积一起可以提高性能。

Conclusion: 
本文结果表明，3D MLLMs在AMOS-MM数据集中的1,687例病例上，报告的生成很大程度上独立于LLM的大小。此外，研究表明更大的体积大小不总是提升性能，特别是在原来的ViT预训练是在较小的体积大小上时。最后，使用分割掩码与CT体积一起可以提高性能。相关代码已公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21535</guid><pubDate>Fri, 27 Jun 2025 02:38:45 +0800</pubDate></item><item><title>317. cs.CV-我的数据在你的AI模型中吗？基于面部图像的应用成員推理测试</title><link>https://arxiv.org/pdf/2402.09225</link><description>Background: 
该文章介绍了会员推理测试（MINT），这是一种旨在实证评估给定数据是否被用于训练AI/ML模型的新方法。实验框架集中在面部识别这一挑战性任务上，考虑了三个当前最先进的面部识别系统，并使用六个公共数据库中的超过2200万张面部图像进行实验。不同的实验场景根据测试的AI模型背景而变化。

Innovation: 
本文提出了两种MINT架构，基于多层感知器（MLPs）和卷积神经网络（CNNs），旨在学习审计模型在暴露于其训练数据时产生的独特激活模式。通过这种方式，能够有效地评估事物是否使用特定数据进行训练，这在强制执行隐私和公平性方面具有重要意义，尤其是在大规模语言模型（LLMs）的训练或调整中揭示敏感或私人数据的使用情况。

Conclusion: 
提出的MINT方法在实验中取得了令人鼓舞的结果，准确率最高可达90%，表明了识别AI模型是否使用特定数据的潜力。该方法可以用于多种AI应用中，以强化隐私和公平性，如揭示敏感或私人数据是否被用于训练或调整大规模语言模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2402.09225</guid><pubDate>Fri, 27 Jun 2025 02:38:44 +0800</pubDate></item><item><title>318. cs.CV-轻量级物理指导的零样本超声平面波去噪</title><link>https://arxiv.org/pdf/2506.21499</link><description>Background: 
超声相干平面波合成（CPWC）通过结合来自多个扫描角度的回声来提高图像对比度。增加角度数量通常会提升图像质量，但会显著降低帧率，并可能导致快速移动目标产生模糊伪影。此外，使用有限的扫描次数采集的合成图像仍易受噪声干扰。为解决这些问题，本文提出了一种零样本降噪框架，适用于低角度CPWC采集，该框架无需额外的训练数据集即可增强对比度。该方法将可用的扫描角度分为两个不相交的子集，每个子集用于生成具有较高噪声水平的合成图像。新的合成图像通过自我监督残差学习方案训练深度模型，从而抑制无序噪声同时保留解剖结构。虽然子集间的角度依赖性伪影不同，但底层组织响应相似，这种基于物理的配对使网络能够学习分离不一致的伪影和一致的组织信号。

Innovation: 
本文提出了一个零样本降噪框架，适用于低角度CPWC采集，并采用轻量级的双卷积层架构。该框架利用物理信息，通过将扫描角度分为两个不相交的子集来分别生成具有较高噪声水平的合成图像，然后通过自我监督残差学习方案训练深度模型，以抑制无序噪声同时保留解剖结构。该模型无需领域特定的微调或配对数据，适用于多种解剖区域和采集设置，且具有低计算成本的优点。与监督方法相比，该方法在仿真实验、模拟测试及体内数据上均表现出优于经典和基于深度学习的去噪方法的效果。

Conclusion: 
本文提出的零样本降噪框架通过轻量级的双卷积层架构和物理信息指导的去噪策略，为低角度CPWC采集提供了高效的去噪解决方案，展示了在多种情况下优于经典和基于深度学习的去噪方法的效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21499</guid><pubDate>Fri, 27 Jun 2025 02:38:44 +0800</pubDate></item><item><title>319. cs.CV-自调节神经发生用于在线增量数据学习</title><link>https://arxiv.org/pdf/2403.14684</link><description>Background: 
神经网络在连续学习一系列任务或数据流时容易出现灾难性遗忘，不像人类可以在没有明确提示的情况下持续学习和巩固新的概念。在线增量学习旨在模拟这种能力，每处理一个样本只访问一次，不获取任务或流的提示，这与离线设置更为接近，后者假设来自新型类别的所有数据都是现成的。现有方法通常依赖于存储数据子集或扩展初始模型架构，这导致了显著的计算开销。

Innovation: 
提出了一个名为SERENA的新方法，借鉴‘自我调节神经发生’机制，在一个过参数化网络中将每个概念编码到一种称为‘概念单元’的特殊网络路径中。一旦一个概念被学习，它的相应概念单元就会被冻结，防止遗忘先前获得的信息。此外，还引入了两种新的连续学习场景，这些场景逐渐改变样本大小，更贴近现实世界条件。实验结果显示，该方法不仅在十个基准测试中建立了新的SOTA结果，还显著超过了离线监督批次学习的性能。

Conclusion: 
实验结果表明，本研究的方法不仅在十个基准测试中建立了新的SOTA结果，还显著超过了离线监督批次学习的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2403.14684</guid><pubDate>Fri, 27 Jun 2025 02:38:44 +0800</pubDate></item><item><title>320. cs.CV-QuEST：通过高效选择性微调实现低位宽扩散模型量化</title><link>https://arxiv.org/pdf/2402.03666</link><description>Background: 
扩散模型的实际部署受到高内存和计算成本的阻碍。尽管量化可以实现模型压缩和加速，但现有方法在高效实现低位宽量化方面仍面临挑战。不均衡的激活分布被认为是量化困难的主要来源，需要通过权重微调来调整这些分布，使其更适合量化。该方法在提高量化效率的同时，通过局部和全局监督对关键类型量化层进行选择性微调，减少了性能下降。此方法在三个高分辨率图像生成任务中展示了有效性，并在多种位宽设置下取得了最先进的性能。

Innovation: 
提出了一种通过权重选择性微调来调整不均衡的激活分布，使激活分布更加适合量化。进一步区分了两种重要的量化层类型，并通过局部和全局监督对这两种类型的层进行选择性微调，这有助于提高量化效率并减少性能下降。

Conclusion: 
该方法在三种高分辨率图像生成任务中展示了其有效性，跨多个位宽设置达到了最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2402.03666</guid><pubDate>Fri, 27 Jun 2025 02:38:43 +0800</pubDate></item><item><title>321. cs.CV-ResQ: 一种在模拟射频原子量子计算机中实现残差神经网络的新框架</title><link>https://arxiv.org/pdf/2506.21537</link><description>Background: 
由于量子计算有潜力加速机器学习，量子机器学习的研究近年来取得了快速发展。然而，基于神经常微分方程（神经ODE）的残差神经网络（ResNets）在量子计算领域尚未被研究。ResNets 通过常微分方程的原理改进了神经网络的有效性。本研究探讨了射频原子量子计算机为何特别适合用于 ResNets，并提出了一种新型框架 ResQ，用于优化射频原子量子计算机的动力学，以使用模拟量子神经ODE解决机器学习的分类问题。

Innovation: 
提出了 ResQ 框架，这是一种新型框架，用于优化射频原子量子计算机的动力学，以使用模拟量子神经ODE解决机器学习中的分类问题。这是首次将这种理论应用于基于神经ODE的 ResNets 在量子计算中的实现。

Conclusion: 
通过 ResQ 框架优化的射频原子量子计算机能够有效地实现 ResNets，为使用模拟量子神经ODE解决机器学习分类问题提供了一种新的方式。这项研究不仅展示了射频原子量子计算机在机器学习领域的潜力，也为未来的研究指明了方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21537</guid><pubDate>Fri, 27 Jun 2025 02:38:41 +0800</pubDate></item><item><title>322. cs.CV-从有限视角进行空间心理建模</title><link>https://arxiv.org/pdf/2506.21458</link><description>Background: 
该研究探讨了视觉语言模型（VLMs）是否能够像人类一样从少量视角中想象出完整的空间场景。研究指出，人类能够形成空间心理模型，即对未见空间的内部表示，用于推理解空间布局、视角和运动。然而，现有VLMs在应对类似任务时表现差强人意，呈现出接近随机的表现。为此，研究者开发了名为MindCube的新基准测试，包含21,154个问题和3,268张图片，揭示了现有VLMs在构建稳健的空间心理模型方面的巨大差距，特别是关于位置认知建模、视角理解以及动态心理模拟方面的能力有限。

Innovation: 
研究引入了一种名为MindCube的新基准测试，系统评估了VLMs在基于有限视角构建稳健空间心理模型方面的能力，并探索了三种帮助VLMs近似构建空间心理模型的方法，包括利用未见的中间视角、自然语言推理链和认知地图。研究提出了一种协同方法“构建地图然后推理”，联合训练模型先生成认知地图，再在此基础上进行推理，通过训练模型在内部地图上的推理过程提升了准确率至60.8% (+23.0%)，引入强化学习后进一步提升至70.7% (+32.9%)。论文的关键洞察是在空间心理模型的构建中，积极构建和利用结构化的内部空间表示并进行灵活的推理过程，显著提高了对不可见空间的理解能力。

Conclusion: 
通过以上研究方法，显著提升了VLMs对不可见空间的理解能力。基于内部地图的推理和引入强化学习的策略极大地提高了模型的性能。研究表明，构建和利用动态的空间心理模型对增强VLMs处理有限视角下的空间理解任务具有重要价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21458</guid><pubDate>Fri, 27 Jun 2025 02:38:40 +0800</pubDate></item><item><title>323. cs.CV-ThermalDiffusion: 视觉到红外图像的图像到图像转换以实现自主导航</title><link>https://arxiv.org/pdf/2506.20969</link><description>Background: 
自主系统依赖传感器来估计周围的环境，然而摄像头、激光雷达和雷达各有局限性。在夜间或雾、霾等恶劣环境下，热摄像头通过热特征标识目标存在，易于辨别温度较高的对象如人类和车辆。然而，热图像数据的缺乏成为热摄像头在机器人技术和自动化领域广泛应用的关键障碍。现有的多模态数据集在场景分割、物体检测和深度估计等任务中实力雄厚，但缺乏热图像数据作为基础。本文提出了一种解决方案，通过合成热图像数据增强这些数据集，使热摄像头得以广泛快速的应用。

Innovation: 
本文创新性地利用条件扩散模型将现有的 RGB 图像转换为热图像，通过自注意力机制学习真实世界的物体的热特性，为热摄像头在机器人和自动化领域的广泛应用提供数据支持。这种视觉到红外图像的图像到图像的翻译方法填补了现有数据集在热图像方面的空白，有助于加速热摄像头技术的发展和应用。

Conclusion: 
本文提出的方法为多模态数据集增加了热图像数据，使热摄像头能够在复杂环境中提供有效的对象识别，加速了机器人和自动化领域的进步。通过条件扩散模型的使用，解决了热图像数据缺乏的问题，推动了热摄像技术及其他自主导航相关技术的快速发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20969</guid><pubDate>Fri, 27 Jun 2025 02:38:33 +0800</pubDate></item><item><title>324. cs.CV-ThinkSound：多模态大型语言模型中的思维链推理在音频生成和编辑中的应用</title><link>https://arxiv.org/pdf/2506.21448</link><description>Background: 
尽管端到端的视频到音频生成取得了显著进步，但生成高质量、能够真实捕捉视觉内容细微差别的音频依然具有挑战性。这与创意产业专业人士的工作相类似，需要关于视觉动态、声学环境和时间关系的复杂推理。

Innovation: 
提出了一个名为ThinkSound的新框架，利用思维链（CoT）推理实现视频音频的逐步、互动生成和编辑。该框架分为三个互补阶段：基础 Foley 生成、通过精确的用户交互进行的互动对象中心化细化以及基于自然语言指令的目标编辑。此外，还引入了AudioCoT数据集，其中包括结构化的推理注释，用于连接视觉内容、文本描述和声音合成

Conclusion: 
实验表明ThinkSound在视频到音频生成的音频指标和思维链指标上达到了最先进的性能，并在电影生成音频基准测试中表现出色。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21448</guid><pubDate>Fri, 27 Jun 2025 02:38:31 +0800</pubDate></item><item><title>325. cs.CV-RL-Selector：通过冗余评估指导的强化学习引导数据选择</title><link>https://arxiv.org/pdf/2506.21037</link><description>Background: 
现代深度架构通常依赖大规模数据集进行训练，但大规模数据集的训练会带来高计算和存储开销。现实世界中的数据集往往包含大量冗余数据，这促使了需要更高效的数据训练方法。现有的数据选择方法通常依靠静态评分指标或预训练模型，而忽略了选中的样本及其在训练过程中动态变化的综合效果。现有的方法主要侧重于静态评分指标或预训练模型，忽略了样本之间的动态关系。因此，需要一种新的方法来更好地评估数据冗余并优化数据选择过程，以提高模型的训练效率和泛化性能。

Innovation: 
文章提出了ε-样本覆盖的概念，该概念利用样本间关系量化样本冗余，并揭示数据集的固有结构。基于此，将数据选择问题重新表述为强化学习（RL）过程，并提出了RL-Selector方法。该方法通过轻量级的RL代理利用演化数据分布的ε-样本覆盖作为奖励信号来优化选择策略。该方法与现存的最先进的基线方法相比，在多个基准数据集和不同架构上验证了其在保持模型性能的同时具有更好的泛化能力和训练效率。

Conclusion: 
实验结果表明，使用RL-Selector方法进行数据选择后，模型的训练效率得以提高，并且泛化性能表现更优。该研究为数据选择提供了一种新的强化学习方法，该方法通过考虑样本间冗余关系为数据选择提供了一种有效的途径。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21037</guid><pubDate>Fri, 27 Jun 2025 02:38:30 +0800</pubDate></item><item><title>326. cs.CV-GANet-Seg: 使用混合生成模型的对抗学习脑肿瘤分割</title><link>https://arxiv.org/pdf/2506.21245</link><description>Background: 
传统的脑肿瘤分割技术面临着大数据依赖和标注数据有限的挑战。为了应对这些挑战，研究人员探索了新型框架来提高分割精度，特别是在有限标注数据的情况下。该框架结合了预训练的生成对抗网络（GAN）和U-net架构，利用全局异常检测模块和精炼的掩码生成网络，以实现脑肿瘤敏感区域的有效识别，并通过对抗损失约束逐步提高分割精度。同时，该方法使用多模态MRI数据和合成图像增强技术，增强了模型的鲁棒性并提高了分割性能。实验结果表明，该方法在BraTS数据集上的敏感性和准确性都优于基线方法，且具有可扩展性，降低了对完全标注数据的依赖，为临床实际应用铺平了道路。

Innovation: 
1. 提出了结合预训练GANs和U-net的新型框架，用于脑肿瘤分割。n2. 引入了全局异常检测模块和精炼的掩码生成网络，以增强对肿瘤敏感区域的识别精度。n3. 使用对抗损失约束优化分割模型，并通过多模态MRI数据和合成图像数据增强技术提高模型的鲁棒性。n4. 该方法在有限的标注数据下仍能提供高敏感性和准确性，同时具备可扩展性。

Conclusion: 
该研究提出的方法在脑肿瘤分割任务中的表现优于现有的基线方法，具有高敏感性和准确性，同时通过减少对完全标注数据的依赖而表现出可扩展性优势。该方法为临床实际应用提供了可能的解决方案，并为未来的研究提供了新的思路。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21245</guid><pubDate>Fri, 27 Jun 2025 02:38:28 +0800</pubDate></item><item><title>327. cs.CV-基于相关参考文献和出版物权重的科研论文自动评审人员分配</title><link>https://arxiv.org/pdf/2506.21331</link><description>Background: 
科研论文的提交数量日益增多，而选择合适的同行评审者或评审专家却是一项挑战。现有的评审通常依赖手动挑选，但面对新出现的研究领域和大量论文，这变得越来越困难。本文讨论了选择最佳评审者的困难，并介绍了现有评审过程的局限性。

Innovation: 
本文提出了一种新的自动选择最佳评审者的方法。通过收集引用文献、研究主题关键词提取、寻找顶级研究人员及其影响力指标（如h-index、i10-index和引用次数），并根据评分进行排名来自动选择最适合的评审者。这种方法旨在提高评审过程的效率和准确性。

Conclusion: 
本文实现了一种基于相关参考文献和出版物权重的新策略来自动选择最佳评审者。通过收集引用文献、研究主题关键词提取、寻找顶级研究人员及其学术影响力指标，并根据评分进行排名，最终自动获取候选人的联系信息。这种方法有助于提高科研论文评审的质量和效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21331</guid><pubDate>Fri, 27 Jun 2025 02:38:28 +0800</pubDate></item><item><title>328. cs.CV-多模态LLMs在视觉重构与理解中的应用</title><link>https://arxiv.org/pdf/2506.21319</link><description>Background: 
数据可视化对于数据传播至关重要，但其理解需要同时理解视觉元素及其背后的数据关系。现有的多模态大模型在自然图像理解方面表现出色，但在视觉化方面的表现不尽如人意，主要是由于它们无法解码数据到视觉的映射规则，也不擅长抽取结构化信息。

Innovation: 
本文提出了一种新型数据集，并训练了专门用于理解和重构可视化的多模态LLMs。这一方法将图表图像与其相应的向量化表示、编码方案和数据特征相结合。提出的向量格式使得可视化内容的紧凑且准确的重构成为可能。实验结果表明，这种新方法在数据提取准确性和图表重建质量上都有显著改进。

Conclusion: 
本文通过构建数据集和训练专门的多模态LLMs，显著提高了数据提取准确性和图表重建质量，解决了当前多模态大模型在可视化理解中的挑战。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21319</guid><pubDate>Fri, 27 Jun 2025 02:38:27 +0800</pubDate></item><item><title>329. cs.CV-通过双提示优化和跨融合的个性化联邦学习</title><link>https://arxiv.org/pdf/2506.21144</link><description>Background: 
联邦学习（FL）允许跨分布式客户端进行模型训练而无需共享本地数据，但面对数据、计算和通信的异质性挑战。现有的联邦提示学习方法仅依赖于文本提示，忽视了联合标签领域分布转移。针对这一问题，本文提出了基于双提示学习和跨融合的个性化FL框架（pFedDC）

Innovation: 
该框架中每个客户端维护视觉和语言模态的全局和本地提示：全局提示捕捉跨联邦的共享知识，而局部提示编码客户端特有的语义和领域特征。同时设计了跨融合模块，可适应地整合不同层次的提示，使模型生成与每个客户端独特数据分布相一致的个性化表示

Conclusion: 
广泛使用九种具有不同类型的异质性数据集进行实验表明，pFedDC在多个方面始终优于当前最先进的方法&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21144</guid><pubDate>Fri, 27 Jun 2025 02:38:26 +0800</pubDate></item><item><title>330. cs.CV-在DCT中发掘宝藏：通过利用潜在相关性推进JPEG质量提升</title><link>https://arxiv.org/pdf/2506.21171</link><description>Background: 
JPEG通过量化DCT系数实现了数据压缩，但不可避免地引入了压缩伪影。目前大多数JPEG质量提升方法在像素域中操作，导致解码过程计算成本高。因此，直接在DCT域中提升JPEG图像引起了越来越多的关注，但现有的DCT域方法性能有限。

Innovation: 
提出了一种高级DCT域JPEG质量增强（AJQE）方法，该方法利用JPEG图像DCT系数中的两种类别相关性，将多个已建立的像素域模型迁移到DCT域，实现了性能提升同时减少了计算复杂度。与像素域模型相比，该方法获得的DCT域模型在PSNR上平均提高了0.35 dB，并且增强了60.5%的处理吞吐量。

Conclusion: 
该研究通过识别和利用JPEG图像DCT系数中隐蔽的相关性，提出了AJQE方法，在保持性能的同时降低了计算复杂度。实验结果表明，DCT域模型在PSNR和提升吞吐量上都优于传统方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21171</guid><pubDate>Fri, 27 Jun 2025 02:38:26 +0800</pubDate></item><item><title>331. cs.CV-生成性积木世界：在图片中移动事物</title><link>https://arxiv.org/pdf/2506.20703</link><description>Background: 
本文描述了通过操控简单的几何抽象来与生成图像的场景进行交互的生成性积木世界。方法将场景表示为凸3D基本几何体的装配体，而且同一个场景可以用不同数量的基本几何体进行表示，允许编辑者既可以移动整个结构也可以移动细节。编辑完场景几何后，通过受深度和提示纹理条件制约的流式方法生成图像，该提示纹理考虑了修改后的3D几何体，超过现有的键值缓存技术提供的纹理连贯性。提示纹理（a）允许准确的对象和相机移动并（b）很大程度上保留了被描绘对象的身份。定量和定性实验表明，本文的方法在视觉保真度、易编辑性和组份泛化方面优于先前的工作。

Innovation: 
本文创新性地提出了通过简单几何抽象来处理生成图像场景的方法，使用凸3D基本几何体装配体表示场景，适应性地使用不同数量的基本几何体表示同一个场景，既能移动整体结构又能调整细节。编辑后通过条件流式方法生成图像，提示纹理考虑了修改后的3D基本几何体，可进行精确的物体和相机移动，且很大程度上保持了对象的身份与特征。与现有技术相比，本文方法在视觉保真度、可编辑性和组份泛化方面表现更优。

Conclusion: 
本文通过生成性积木世界，提出了在生成图像的场景中通过简单几何抽象进行交互的方法，并用定量和定性实验验证其方法在视觉保真度、易编辑性和组份泛化方面的优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20703</guid><pubDate>Fri, 27 Jun 2025 02:38:21 +0800</pubDate></item><item><title>332. cs.CV-V2X-REALM：基于视觉语言模型的稳健端到端协同自动驾驶及自适应长尾建模</title><link>https://arxiv.org/pdf/2506.21041</link><description>Background: 
在城市环境中，为自动驾驶车提供稳健的规划和决策能力，在罕见、多样且视觉退化的长尾场景下，仍然是一个基础性的挑战。这种情况在协作场景中尤为重要，因为车辆和基础设施需要一起感知并推理复杂环境中的情况。由于这些长尾场景在日常训练数据中缺乏代表性，现有的自动驾驶系统往往表现不佳。因此，如何在这些罕见场景中提高自动驾驶系统的鲁棒性、语义推理能力、安全性以及规划精度，成为了亟待解决的问题。

Innovation: 
为解决上述挑战，该论文提出了基于视觉语言模型（VLM）的V2X-REALM框架，该框架通过自适应多模态学习来增强在长尾场景下的鲁棒协同自动驾驶能力。V2X-REALM引入了三个核心创新点：首先，通过一个基于提示的长尾场景生成和评估流水线，利用基础模型合成现实中的长尾条件，如雪和雾，这些条件在车辆和基础设施视角都存在，以高效丰富训练多样性；其次，设计了一个门控多场景自适应注意力模块，使用场景先验来调节视觉流，重新校准含糊不清或损坏的特征；最后，提出了多任务场景意识对比学习目标，以提高多模态对齐，并促进场景间特征的可分离性，从而提升系统的性能。

Conclusion: 
大量实验结果表明，V2X-REALM在长期尾场景下的鲁棒性、语义推理能力、安全性和规划精度方面超过了现有基准，显著提升了端到端的协同自动驾驶的扩展性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21041</guid><pubDate>Fri, 27 Jun 2025 02:38:18 +0800</pubDate></item><item><title>333. cs.CV-SharpZO: 仅前向传递的混合灵敏度意识视觉语言模型提示微调</title><link>https://arxiv.org/pdf/2506.20990</link><description>Background: 
视觉语言模型(VLMs)在各种下游任务中表现出色，但需要通过反向传播(BP)访问模型梯度，使其不适合内存受限的边缘设备进行仅推理的使用。先前的工作探索了各种无BP的微调方法，但这些方法通常依赖于具有高方差的进化策略(ES)或零阶(ZO)优化，往往未能达到令人满意的性能。

Innovation: 
本文提出了一种混合灵敏度意识零阶优化(SharpZO)方法，旨在通过灵敏度意识预热训练来增强ZO VLM微调的性能。SharpZO采用了两阶段优化过程：第一阶段是灵敏度意识ES阶段，全局探索和平滑损失景观以构建强初始化，第二阶段是通过稀疏ZO优化进行详细的局部搜索。整个优化过程仅依赖于前向传递。

Conclusion: 
详细的理论分析和CLIP模型上的大量实验表明，SharpZO显着提高了准确性和收敛速度，在最新的仅前向传递方法上实现了高达7%的平均性能提升。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20990</guid><pubDate>Fri, 27 Jun 2025 02:38:14 +0800</pubDate></item><item><title>334. cs.CV-开发适用于静磁场不均匀性的MR光谱分析方法</title><link>https://arxiv.org/pdf/2506.20897</link><description>Background: 
现有的光谱分析方法在静磁场B0不均匀性较强的情况下，准确性会降低。为了克服这个问题，本研究开发了一种新的光谱分析方法，利用经过训练的深度学习模型，该模型基于模拟的光谱数据，这些数据代表了由B0不均匀性引起的光谱变化。

Innovation: 
该研究提出了利用深度学习模型进行光谱分析的新方法，该模型通过使用模拟的光谱数据进行训练，这些数据精确反映了由静磁场B0不均匀性引起的变化。该方法特别注重通过多步骤的光谱处理和训练来提高分析的准确性，从而在不同程度的B0不均匀性中表现出色。

Conclusion: 
研究结果表明，基于模拟光谱数据训练的深度学习模型能够显著提高光谱分析的准确性，并且在处理不同类型的B0不均匀性时表现出良好的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20897</guid><pubDate>Fri, 27 Jun 2025 02:38:14 +0800</pubDate></item><item><title>335. cs.CV-U-R-VEDA: 结合UNet、残差链接、边缘检测和双注意力模块以及视觉变换器以实现准确的CMR语义分割</title><link>https://arxiv.org/pdf/2506.20689</link><description>Background: 
深度学习模型等人工智能技术将在自动医学图像分析中发挥变革性作用，特别在心脏疾病的诊断及其管理中。自动且准确的心脏图像分割是定量分析和自动化诊断心脏疾病的关键初始步骤。因此，开发出一种深度学习增强的UNet模型U-R-Veda对于提高心脏磁共振成像（CMR）图像的语义分割能力是十分必要的，这对于改进医学图像分析非常关键。

Innovation: 
U-R-Veda模型集成了一系列先进技术，包括卷积变换、视觉变换器、残差链接、通道注意和空间注意，以及基于边缘检测的跳级链接连接。这些技术共同作用，优化了心脏磁共振成像的准确自动语义分割。该模型能够提取局部特征及其相互关系，并通过嵌入通道和空间注意力机制在卷积块中，以及结合视觉变换器，识别出重要的特征及其空间定位。边缘信息与通道注意、空间注意的双重信息通过跳级链接连接起来，减少了卷积操作中的信息丢失。

Conclusion: 
U-R-Veda模型在CMR图像的语义分割中表现优异，根据DSC指标，平均准确性达到了95.2%，尤其是在右心室和左心室心肌的分割方面尤为出色，超过了其他模型的成绩。整体来看，该模型显著提升了CMR图像的语义分割质量，对提高医学图像分析具有重要意义。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20689</guid><pubDate>Fri, 27 Jun 2025 02:38:13 +0800</pubDate></item><item><title>336. cs.CV-使用几何感知扩散和时间视频模型实现一致的零样本3D纹理合成</title><link>https://arxiv.org/pdf/2506.20946</link><description>Background: 
当前的纹理合成方法生成固定视角的纹理，由于缺乏全局语境和几何理解，导致不一致。同时，最近在视频生成模型方面取得的进展已经成功实现了时间一致的视频生成。现有的纹理合成方法无法处理3D纹理中的时空不一致性问题，而最新的视频生成模型则在实现时间一致性方面表现出色。

Innovation: 
我们提出了VideoTex，一种新颖的无缝纹理合成框架，利用视频生成模型来解决3D纹理中的时空不一致性。VideoTex通过引入几何感知条件实现对3D网格结构的精确利用，采用结构化的UV扩散策略以保留语义信息，从而增强了隐藏区域的生成，并生成更平滑和更一致的纹理。此外，VideoTex在纹理保真度、缝合过渡以及稳定性方面优于现有方法，为需要视觉质量和时间一致性的动态实时应用铺平了道路。

Conclusion: 
通过广泛的实验，VideoTex在纹理保真度、缝合过渡和稳定性方面表现出色，超越了现有方法，为实时动态应用提供了高质量和时间一致性保证。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20946</guid><pubDate>Fri, 27 Jun 2025 02:38:11 +0800</pubDate></item><item><title>337. cs.CV-全身条件下的第一人称视频预测</title><link>https://arxiv.org/pdf/2506.21552</link><description>Background: 
本文旨在通过给定过去的视频和表示相对3D人体姿态的动作，训练模型预测以自我为中心的视频（PEVA）。通过基于人体关节层次结构的运动轨迹条件化，模型学习从第一人称视角模拟人体动作如何塑造环境。研究通过一个大规模的现实世界第一人称视频和人体姿态捕捉数据集Nymeria来训练自回归条件扩散变换器。进一步设计了一个分层评估协议，包含逐渐加难的任务，以全面分析模型的实体预测和控制能力。这项工作代表了从人类视角出发，开始解决建模复杂现实环境和实体代理行为的初步尝试，利用视频预测的方法。

Innovation: 
文章创新点在于通过自回归条件扩散变换器训练模型，以3D人体姿态作为条件，预测以自我为中心的视频。引入了基于人类关节层次结构的运动轨迹条件化，以模拟人类动作如何影响环境。遵循递增难度的任务评估方案，全面评估了模型的预测能力和控制能力。同时，该工作代表了从人类视角出发处理复杂现实环境和实体行为的初步尝试。

Conclusion: 
本文通过大数据集和自回归条件扩散变换器模型成功预测了以自我为中心的视频，展示了模型在模拟人类动作对环境影响方面的潜力。通过引入层级评估协议，文章为研究实体代理行为提供了新的视角，为未来工作探索提供了基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21552</guid><pubDate>Fri, 27 Jun 2025 02:38:06 +0800</pubDate></item><item><title>338. cs.CV-StruMamba3D: 探索用于自我监督点云表示学习的结构Mamba</title><link>https://arxiv.org/pdf/2506.21541</link><description>Background: 
最近，基于Mamba的方法在利用状态空间模型（SSM）进行点云表示学习时展示了出色的表现，其中SSM因为其高效的上下文建模能力和线性复杂性而备受关注。然而，这些方法在处理过程中仍存在两个关键问题：破坏3D点之间的邻近性以及在输入长度增加时下游任务中无法保留长期序列记忆。

Innovation: 
为了解决这些问题，我们提出了StruMamba3D，一种新颖的自我监督点云表示学习范式。StruMamba3D具有以下几个优点：首先，设计了空间状态并使用它们作为代理来保留点之间的空间依赖关系；其次，通过状态更新策略增强了SSM，并引入了轻量级卷积以促进空间状态之间的交互，从而促进了结构建模的效率；第三，通过引入序列长度自适应策略，降低了预训练的Mamba模型对输入长度变化的敏感性。实验结果表明，该方法在四个下游任务中的性能优越，并且在没有投票策略的情况下，StruMamba3D在ModelNet40上的准确率为95.1%，在ScanObjectNN最难分割上的准确率为92.75%。

Conclusion: 
我们的方法在多个下游任务中展示了优越的性能，并且在没有投票策略的情况下，达到了ModelNet40上的95.1%和ScanObjectNN最难分割上的92.75%的准确率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21541</guid><pubDate>Fri, 27 Jun 2025 02:38:06 +0800</pubDate></item><item><title>339. cs.CV-心脏MRI和ECG的全局和局部对比学习方法联合表示</title><link>https://arxiv.org/pdf/2506.20683</link><description>Background: 
心电图（ECG）是一种广泛应用且成本效益高的工具，用于检测心脏的电活动异常，但无法直接测量心脏功能参数，如心室容积和射血分数等。心脏磁共振成像（CMR）是这些测量的黄金标准，可以提供详细的心脏结构和功能见解，但成本高且不如ECG易于获取。为此，该研究提出了PTACL（患者和时间对齐对比学习）框架，该框架通过从CMR整合时空信息来增强ECG表示。通过采用全局患者级对比损失和局部时间级对比损失，该方法不仅可以对来自同一患者的ECG和CMR嵌入进行对齐，还可以对来自不同患者的嵌入进行推离。局部对比损失通过对比每个患者编码的ECG片段和相应的编码CMR帧来强化高频次时间对齐。与仅使用全局对齐相比，这种方法不仅提供了超出电活动的诊断信息，还能够更好地在不同模态之间转移洞察力，且不需要引入新的可学习权重。该研究在英国生物银行的27,951名受试者的配对ECG-CMR数据上对PTACL进行了评估。与基线方法相比，PTACL在两个临床相关任务上表现更好，即（1）检索具有相似心脏表型的患者，以及（2）预测由CMR导出的心脏功能参数，如心室容积和射血分数。

Innovation: 
PTACL框架通过整合CMR中的时空信息，将ECG表示嵌入得到增强。通过使用全局患者级对比损失和局部时间级对比损失，该方法能够实现ECG和CMR嵌入的实际对齐，同时跨模态转移更多洞察力，而不需要引入新的可学习权重。评估结果表明，PTACL在心脏表型相似性检索和心脏功能参数预测方面表现出更好的性能，这突显了PTACL在非侵入性心脏诊断中的潜力。

Conclusion: 
研究结果表明PTACL能够通过将ECG与CMR相结合来提升非侵入性心脏诊断技术。通过此方法，ECG不仅能够识别电活动异常，还能够提供更多诊断信息。研究团队已经开源了该模型的代码，以便其他人进行进一步的研究和应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20683</guid><pubDate>Fri, 27 Jun 2025 02:38:05 +0800</pubDate></item><item><title>340. cs.CV-通过网络层非均匀影响进行通用和高效对抗数据检测</title><link>https://arxiv.org/pdf/2506.20816</link><description>Background: 
深度神经网络（DNNs）对具有少量噪音预算的对抗输入设计特别敏感。虽然已经提出了许多成功的少量修改原始输入的攻击方法，但针对这些攻击的防御技术相对较少研究。现有的防护方法要么专注于提高DNN的鲁棒性以抵消扰动的影响，要么使用次级模型来检测对抗数据。相比之下，检测方法虽然同样重要，但本工作更侧重于研究生成对抗样本的检测方法。然而，现有的检测方法要么对最先进的攻击技术无效，要么在实时处理中效率低下。

Innovation: 
我们提出了一种新的、通用于所有DNN架构的高效对抗样本检测方法，该方法通过分析不同DNN层受攻击的影响程度来检测对抗样本。具体方法是训练一个轻量级回归模型，它能够从早期层特征预测深层层特征，并利用预测误差来检测对抗样本。我们通过理论证明和广泛的实验，证明了该检测方法的有效性、实时处理的高效性及其在不同领域的适用性，例如图像、视频和音频。

Conclusion: 
我们的检测方法在实际应用中表现优异，提供了一种比提高鲁棒性更实用的防御策略。它不仅计算效率高，适用于任何DNN架构，还适用于图像、视频和音频等多种领域。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20816</guid><pubDate>Fri, 27 Jun 2025 02:38:05 +0800</pubDate></item><item><title>341. cs.CV-3DGH: 3D Head Generation with Composable Hair and Face</title><link>https://arxiv.org/pdf/2506.20875</link><description>Background: 
当前研究大多关注头发和面部建模的结合，缺乏分离处理的方法。本文旨在提出一种名为3DGH的生成模型，该模型可以生成3D人体头部，包含可组合的头发和面部部件，解决头发和面部建模难以分离的问题。

Innovation: 
本文提出了一个创新的数据表示方法，结合基于模板的3D高斯点绘制，并引入可变形的头发几何形状来捕捉不同发型的几何变化；设计了基于3D GAN的具有双生成器的架构，并采用跨注意力机制来建模头发与面部之间的固有关联；通过精心设计的目标函数在合成渲染数据上训练模型，以稳定训练并促进头发与面部的分离。

Conclusion: 
通过广泛实验验证了3DGH的设计选择，并与最新的一些3D GAN方法进行比较，展示了其在无条件全头部图像合成和可组合3D发型编辑方面的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20875</guid><pubDate>Fri, 27 Jun 2025 02:38:03 +0800</pubDate></item><item><title>342. cs.CV-Maximal Matching Matters: 防止表示坍缩以实现稳健的跨模态检索</title><link>https://arxiv.org/pdf/2506.21538</link><description>Background: 
跨模态图像文本 retrievel 因不同模态内容之间可能存在的多样关联而具有挑战性。传统的方法使用单向量嵌入来表示每个样本的语义，但难以捕捉不同模态间丰富且多样的关系。集合基方法使用多个嵌入表示每个样本，能够捕捉更丰富和多样的关系，提供了一种有潜力的替代方案。然而，这些集合基表示仍然面临稀疏监督和集合坍缩的问题，这限制了其有效性。

Innovation: 
为了应对这些挑战，本文提出了最大配对作业相似性来优化嵌入集合之间的一对一匹配，以在集合内保持语义多样性。还引入了两种损失函数：全局判别性损失以增强嵌入之间区别的强度，和内集发散损失以防止每个集合内的坍缩。该方法在不依赖外部数据的情况下，在MS-COCO和Flickr30k上实现了最先进的性能。

Conclusion: 
本文提出的方法在MS-COCO和Flickr30k数据集上取得了最先进的性能，无需依赖外部数据，并通过优化嵌入集合之间的一对一匹配以及引入新的损失函数，解决了集合基表示中的稀疏监督和集合坍缩问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21538</guid><pubDate>Fri, 27 Jun 2025 02:38:01 +0800</pubDate></item><item><title>343. cs.CV-SAM4D: 在相机和LiDAR流中分割一切</title><link>https://arxiv.org/pdf/2506.21547</link><description>Background: 
本文介绍了SAM4D，这是一种为跨相机和LiDAR流进行可提示分割而设计的多模态和时序基础模型。文章提出了一种统一的多模态位置编码(UMPE)方法，用于在共享3D空间中对齐相机和LiDAR特征，从而实现无缝的跨模态提示和交互。此外，还提出了一种基于 ego-运动补偿的运动感知跨模态记忆注意力(MCMA)，旨在提高时间一致性并增强长视距特征检索，从而在动态变化的自动驾驶环境中实现鲁棒分割。为避免注释瓶颈，作者开发了一个多模态自动化数据引擎，它可以结合VFM驱动的视频伪标签、时空4D重构以及跨模态伪标签融合。该框架比人工注释快若干数量级地生成了相机和LiDAR对齐的伪标签，同时保持了点云表示中的VFM衍生语义保真度。文中还进行了广泛的实验来验证SAM4D的多模态分割能力和在数据注释方面的巨大潜力，实验是在构建的Waymo-4DSeg数据集上进行的。

Innovation: 
本文的创新包括：1. 提出了一种统一的多模态位置编码(UMPE)，用于在共享3D空间中对齐相机和LiDAR特征。2. 提出了运动感知跨模态记忆注意力(MCMA)，该方法利用ego-运动补偿以增强时间一致性和长视距特征检索。3. 开发了一个多模态自动化数据引擎，结合了几种技术来生成高效的伪标签，同时保持语义保真度。

Conclusion: 
本文通过在Waymo-4DSeg数据集上进行实验，证明了SAM4D的多模态分割能力和其在数据注释方面的巨大潜力。这种框架能够以比人工注释快若干数量级的速度生成相机和LiDAR对齐的伪标签，同时保持语义保真度，显示了其在自动驾驶场景中的强大应用潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21547</guid><pubDate>Fri, 27 Jun 2025 02:37:56 +0800</pubDate></item><item><title>344. cs.CV-GGTalker：基于可迁移高斯先验和身份特定适应的言语驱动3D对话头合成</title><link>https://arxiv.org/pdf/2506.21513</link><description>Background: 
创建高质量、普适性强的语音驱动3D对话头依然是一项持续性的挑战。先前的方法在固定视角和较小的音频变化下能够取得令人满意的结果，但它们在处理大头旋转和分布外（OOD）音频时显得力不从心。此外，这些方法受限于耗时的身份特定训练需求。我们相信核心问题在于缺乏足够的3D先验信息，这限制了合成对话头的外推能力。

Innovation: 
针对上述问题，我们提出了GGTalker模型，通过结合可迁移先验和身份特定适应来合成对话头。我们引入了两阶段先验适应训练策略，用于学习高斯头先验并适应个体特征。我们训练了音频表达和表情视觉先验，以捕捉唇部运动的普遍模式以及头部纹理的总体分布。在自定义适应阶段，我们精确建模了个体说话风格和纹理细节，并引入了颜色MLP生成细粒度、运动对齐的纹理，以及体部修复生成器将渲染结果与背景融合，产生难以区分的、照片级真实的视频帧。

Conclusion: 
全面的实验显示，GGTalker在渲染质量、3D一致性、唇部同步精度和训练效率等指标上达到了最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21513</guid><pubDate>Fri, 27 Jun 2025 02:37:54 +0800</pubDate></item><item><title>345. cs.CV-DeOcc-1-to-3: 从单张图像进行自监督多视图扩散去遮挡的3D重建</title><link>https://arxiv.org/pdf/2506.21544</link><description>Background: 
单张图像重建3D物体是一个长期存在的挑战，尤其是在具有实际遮挡的情况下。尽管基于扩散的新视角合成模型可以从单张RGB图像生成一致的新视图，但这些模型通常假设输入是完全可见的，并且在部分对象被遮挡时会失败，导致不一致的视图和3D重建质量下降。

Innovation: 
本文提出了一种端到端的框架，用于去遮挡感知的多视角生成。该方法从单张部分遮挡的图像直接合成六个结构一致的新视图，无需操作原始架构，完全微调视图合成模型以联合学习补全和多视图生成。此外，该研究引入了首个针对去遮挡感知3D重建的标准基准，涵盖不同的遮挡级别、物体种类和遮罩模式，为未来方法提供统一的评估协议。

Conclusion: 
本研究通过自监督多视图扩散实现了从单张图像进行3D去遮挡重建，该方法在去遮挡感知的3D重建基准上提供了评估协议，改进了现有模型的视图一致性和3D重建质量。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21544</guid><pubDate>Fri, 27 Jun 2025 02:37:54 +0800</pubDate></item><item><title>346. cs.CV-MAdrive：增强记忆的驾驶场景建模</title><link>https://arxiv.org/pdf/2506.21520</link><description>Background: 
近年来，场景重建技术已经取得了巨大进步，能够以高度现实的方式使用3D高斯体拟合自主驾驶（AD）环境。然而，当前的重建结果仍然紧密依赖原始观测数据，难以支持对大幅改变或全新驾驶场景的光照写实合成。

Innovation: 
本文介绍了一种称作MADrive的记忆增强重建框架，旨在扩展现有场景重建方法的能力。具体来说，该框架使用从大规模外部记忆库中检索到的、与观测车辆视觉相似的3D模型来替换观测车辆。通过检索模块找到最相似的车辆实例，从视频中重建对应的3D资产，并通过姿态对齐和重新照明将之整合到目标场景中，以生成复现实景车辆的多视角表示，从而能够合成大幅改变配置的场景。

Conclusion: 
实验结果表明，通过MADrive框架进行的替换提供了场景中车辆的完整多视角表示，使得大幅改变车辆配置的场景能够达到写实合成的效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21520</guid><pubDate>Fri, 27 Jun 2025 02:37:54 +0800</pubDate></item><item><title>347. cs.CV-SiM3D：基于单实例多视图、多模态和多配置的3D异常检测基准</title><link>https://arxiv.org/pdf/2506.21549</link><description>Background: 
现有的3D异常检测和分割（ADS）技术通常只考虑单一视角或单一模态的信息，缺乏综合评估多视角和多模态信息集成的效果。在制造行业中，单实例异常检测是一个重要场景，通常只有一件实物或合成物用于训练。当前缺乏一个能从合成训练数据泛化到真实测试数据的ADS基准测试系统。因此，需要一个能够全面评估ADS模型性能的基准，特别是针对制造行业的需求，并提供详细的3D分割的标注数据，以便对比不同方法的表现。

Innovation: 
提出了SiM3D基准，这是第一个综合考虑多视图和多模态信息集成的3D异常检测和分割（ADS）的基准。它特别关注制造行业的单实例异常检测场景，使用工业级传感器和机器人收集了新颖的多模态多视角数据集，并提供了一种新的评价方法，通过使用基于异常体的数据指标评估单一视图方法的性能。

Conclusion: 
SiM3D是首个能够从合成训练数据泛化到真实测试数据的ADS基准，提供了一个高分辨率的多视角和点云数据集，以及3D分割的注释数据，用以手动标注异常测试样本。它为多视图ADS任务提供参考基线，并通过新的评价指标评估现有方法的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21549</guid><pubDate>Fri, 27 Jun 2025 02:37:53 +0800</pubDate></item><item><title>348. cs.CV-HalluSegBench：通过反事实视觉推理进行分割幻觉评估</title><link>https://arxiv.org/pdf/2506.21546</link><description>Background: 
近期在视觉-语言分割领域的进展显著提升了基于图像的理解能力。然而，现有模型在生成分割图时通常会产生幻觉，例如为图像中不存在的对象生成分割图或是错误地标记无关区域。当前的评估协议主要集中在标记或文本幻觉上，而没有通过改变视觉上下文来评估幻觉，这限制了其对关键错误诊断的能力。因此，我们提出了HalluSegBench，这是首个专门通过反事实视觉推理评估基于图像的分割幻觉的基准。该基准包括一个包含1340个反事实实例配对的新数据集和一套新的度量标准，用以量化在视觉一致场景编辑下的幻觉敏感性。实验结果显示，视觉驱动的幻觉比标签驱动的幻觉更为普遍，模型常常在虚假分割上持续存在，这突显了需要通过反事实推理来诊断地对标的必要性。

Innovation: 
提出了首个专门用于通过反事实视觉推理评估分割幻觉的基准HalluSegBench，包括1340个反事实实例配对和新的评估度量标准。这个基准可以通过视觉一致性的场景编辑来更准确地诊断和评估模型的分割幻觉问题。

Conclusion: 
视觉驱动的幻觉在现有模型中更为普遍，并且在虚假分割上存在持续性问题，需要进一步改进以进行更准确的反事实推理，以此来提高模型地对标的准确度。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21546</guid><pubDate>Fri, 27 Jun 2025 02:37:50 +0800</pubDate></item><item><title>349. cs.CV-WAFT: 单独位移场变换用于光学流</title><link>https://arxiv.org/pdf/2506.21526</link><description>Background: 
在光学流领域，传统的做法是构建成本体积（cost volume），然后利用这些成本体积来进行位移估计，但这种方法需要较高的内存成本。WAFT 方法通过使用高分辨率的单独位移变换（Warping-Alone Field Transforms）替代成本体积，实现了更好的准确性和较低的内存成本，挑战了构建成本体积对于高表现的必要性。

Innovation: 
WAFT 是一种简单灵活的元架构，兼具低内存消耗和高准确性。相较于现有的方法，WAFT 在 Spring 和 KITTI 基准测试中表现最佳，同时在 KITTI 上实现了零样本泛化，其速度比具有相似性能的方法快 4.1 倍。这种新的设计方法摒弃了构建成本体积的传统做法，为光学流领域的算法优化带来了新的思路。

Conclusion: 
WAFT 作为一种简单而有效的光学流方法，通过对传统方法的挑战，证明了可以使用高分辨率的位移变换来得到良好的性能。同时，WAFT 的设计展示了算法的灵活性以及跨任务的高效性，对于未来的光学流研究具有重要意义。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21526</guid><pubDate>Fri, 27 Jun 2025 02:37:47 +0800</pubDate></item><item><title>350. cs.CV-通过动态Logits校准减轻大型视觉-语言模型的幻觉</title><link>https://arxiv.org/pdf/2506.21509</link><description>Background: 
大型视觉-语言模型（LVLMs）在多模态理解方面取得了显著进展，但在生成文本时，常遇到幻觉问题，即生成文本与视觉输入矛盾的情况。现有的无需训练的解码策略存在多方面的局限性，如使用固定的非动态调整的约束、每次向前传递需要多次以提高效率、以及过于严格的介入规则导致细节损失等。

Innovation: 
本文提出了一种名为动态Logits校准（DLC）的新颖的无需训练的解码框架，旨在推理阶段动态地将文本生成与视觉证据对齐。DLC在解码阶段逐步使用CLIP评估输入图像和生成文本序列之间的语义一致性。此外，通过实时上下文对齐分数指导的自适应加权机制，DLC能够在保持文本质量的同时谨慎平衡视觉指导。实验结果表明，DLC在多种基准和LVLM架构下显著减少了幻觉现象，提高了推理效率，并且将在GitHub上开源相关代码。

Conclusion: 
总体而言，本文提供了一个有效的解码时解决方案，利用动态Logits校准来减轻LVLM的幻觉，从而增加其可靠性，可用于更多实际应用。相关代码已经开源。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21509</guid><pubDate>Fri, 27 Jun 2025 02:37:45 +0800</pubDate></item><item><title>351. cs.CV-基于条件标记点过程的可靠空区域检测：对象检测</title><link>https://arxiv.org/pdf/2506.21486</link><description>Background: 
深度神经网络在计算机视觉任务如边界框检测和语义分割中达到了最先进的水平。现有的对象检测器和分割模型会为预测结果分配置信度评分，反映模型在对象检测或像素级分类中的不确定性。然而，这些置信度评分通常是错失校准的，因为它们的架构和损失函数是针对任务性能设计的，而不是基于概率论基础。即使置信度评分经过了很好的校准，对象检测器也无法量化未检测到对象区域的不确定性，即模型不能评估未检测到物体的区域是否真的没有障碍物。在自动驾驶等应用中，这种不确定性在空旷区域未被探索的情况下会导致安全风险。

Innovation: 
本文提出了一种基于空间统计的对象检测模型，该模型将边界框数据与标记点过程相匹配，标记点过程常用于描述被识别为边界框中心的空间点事件的概率发生情况，其中标记用于描述边界框的空间扩展和类别。这种方法提供了一种基于似然性的训练框架，并可以明确地评估某个区域是否是可通行区域，即是否存在物体。

Conclusion: 
文章通过校准评估和性能评估展示了所提出方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21486</guid><pubDate>Fri, 27 Jun 2025 02:37:40 +0800</pubDate></item><item><title>352. cs.CV-自然世界图像中的全局与局部蕴含学习</title><link>https://arxiv.org/pdf/2506.21476</link><description>Background: 
在视觉-语言模型中学习数据的层次结构是一项显著的挑战。以往的工作尝试通过使用蕴含学习来解决这种挑战，但这些方法未能明确地建模蕴含的传递性，这在表示空间中关系的顺序和语义的建立中起着关键作用。

Innovation: 
本文介绍了一种称为Radial Cross-Modal Embeddings（RCME）的框架，这种框架能够明确地建模传递性约束的蕴含。我们提出的框架优化了概念在视觉-语言模型中的部分顺序。基于我们的框架，我们开发了一个层次视觉-语言基础模型，能够表示生命之树中的层次结构。我们的实验表明，与现有的最佳模型相比，我们的模型在层次物种分类和层次检索任务上的性能更高。

Conclusion: 
我们的代码和模型已在GitHub上开源。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21476</guid><pubDate>Fri, 27 Jun 2025 02:37:39 +0800</pubDate></item><item><title>353. cs.CV-HyperSORT: 自组织稳健训练与超网络</title><link>https://arxiv.org/pdf/2506.21430</link><description>Background: 
医学成像数据集通常包含从错误标签到不一致标注风格的各种异质偏差。这些偏差可能对深度分割网络的性能产生负面影响。然而，识别和描述这些偏差是一项特别繁琐且具有挑战性的任务。

Innovation: 
本文介绍了一种名为HyperSORT的框架，利用超网络从表示图像和注释变异性量矢量中预测UNets的参数。超网络参数和每个训练样本对应的量矢量集合在联合学习的框架下进行学习。因此，HyperSORT不仅学习一个适应数据集的单一神经网络，还学习一个复杂分布的UNet参数集，其中低密度区域可以捕获噪声特定模式，而大模态则以区分但有意义的方式鲁棒地分割器官。实验验证了HyperSORT在两个公开的3D腹部CT数据集上的有效性，结果显示它创建了有助于识别系统偏差和错误样本的数据集结构化映射。

Conclusion: 
我们的实验表明，HyperSORT能够创建数据集的结构化映射，有助于识别相关系统偏差和错误样本。在潜在空间集群中，UNet参数能够根据已学习的系统偏差执行分割任务。相关代码和对TotalSegmentator数据集的分析已公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21430</guid><pubDate>Fri, 27 Jun 2025 02:37:39 +0800</pubDate></item><item><title>354. cs.CV-每日交通模式下交通信号评价</title><link>https://arxiv.org/pdf/2506.21469</link><description>Background: 
转向流量数据对于交通信号设计、交叉口几何布局规划、交通流量分析和拥堵分析至关重要。本文针对每日呈双峰模式的交通流量，提出了基于转向流量计 (TMC) 的三种交通信号配置方法，即动态、静态和混合配置，并通过实验证明了不同的配置在不同时段的效果差异，特别是在高流量区域和低流量区域的选择上，以优化交通流管理。

Innovation: 
文章创新地开发了一种基于视觉跟踪系统的转向流量计估计方法，并使用仿真工具评估了适应不同交通流量策略的信号配置。特别地，提出了一种混合信号方法，能够根据高峰和非高峰交通条件切换动态和静态方法，以适应每日双峰交通模式，从而优化信号配置。

Conclusion: 
基于6个交叉口四小时仿真测试的扩展实验结果表明，基于区域的交通流量分布模式影响信号配置的选择。虽然静态方法适用于均匀分布的区域交通数量，但混合方法更适合西东区和南北区的重交通交叉口对。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21469</guid><pubDate>Fri, 27 Jun 2025 02:37:39 +0800</pubDate></item><item><title>355. cs.CV-G$^{2}$D: Gradient-Guided Distillation for Enhancing Multimodal Learning</title><link>https://arxiv.org/pdf/2506.21514</link><description>Background: 
多模态学习旨在利用多种数据模态的信息以实现更全面的性能。然而，传统的多模态模型往往受到模态失衡的影响，其中一种或几种模态主导模型的优化过程，导致特征表示质量不佳并阻碍了较弱模态的充分利用.

Innovation: 
我们提出了基于梯度指导的蒸馏（G$^{2}$D）框架，它通过自定义融合单模态和多模态目标的损失函数来优化多模态模型。G$^{2}$D还引入了动态顺序模态优先策略（SMP），确保每个模态轮流主导学习过程，避免较强模态压过较弱模态的情况.

Conclusion: 
我们在多个实际数据集上验证了G$^{2}$D，并展示了其在分类和回归任务中优于最先进的方法，同时使较弱模态的重要性得到增强。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21514</guid><pubDate>Fri, 27 Jun 2025 02:37:39 +0800</pubDate></item><item><title>356. cs.CV-Logios：开源的希腊多音节光学字符识别系统</title><link>https://arxiv.org/pdf/2506.21474</link><description>Background: 
本文介绍了一种专门针对希腊多音节文本的光学字符识别（OCR）系统。希腊多音节文本因其独特的书写系统和符号系统，为传统的OCR方法带来了特殊挑战。为了解决这些挑战，该系统结合了卷积层的特征提取能力和循环层的序列学习能力，旨在提高准确性和效率，超越传统方法的局限性。

Innovation: 
系统采用了卷积层和循环层相结合的方法，专门针对希腊多音节文本的特点设计，这使得它能够更准确地识别和数字化这些复杂的文本。与传统的OCR方法相比，该系统提供显著的准确性和效率改进。此外，作者还开源了底层模型，并提供了一个供学术使用的OCR平台。

Conclusion: 
本文提出了一种专门处理希腊多音节文本的OCR系统，并通过开源和提供学术使用的平台，希望能够促进对该领域更多研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21474</guid><pubDate>Fri, 27 Jun 2025 02:37:38 +0800</pubDate></item><item><title>357. cs.CV-TITAN: 基于查询令牌的域自适应对抗性学习</title><link>https://arxiv.org/pdf/2506.21484</link><description>Background: 
在源数据不可用的条件下，领域自适应目标检测（SF-DAOD）问题要求模型适应未标记的目标领域。现有方法通常采用学生-教师（ST）框架，通过源预训练模型生成伪标签进行进一步微调。然而，伪标签的高噪声导致学生模型的性能严重下降，特别是由领域偏差、差异和领域间的显著转换引起的。

Innovation: 
提出了一种基于查询令牌的迭代查询-令牌对抗网络（TITAN），将目标图像分为两类：与源图像相似（简单）和不相似（困难）。通过估计检测误差方差将目标领域划分为两类，并且将查询令牌对抗模块融入学生-教师基础框架以减小两个特征表示之间的域差距。

Conclusion: 
在四个自然图像数据集和两个挑战性医学数据集上的实验验证了TITAN相比现有最先进的方法表现优越，分别在C2F、C2B、S2C和K2C基准上提高了22.7%、22.2%、21.1%和3.7%的mAP。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21484</guid><pubDate>Fri, 27 Jun 2025 02:37:36 +0800</pubDate></item><item><title>358. cs.CV-基于场景感知扩散模型的可控3D物体放置</title><link>https://arxiv.org/pdf/2506.21446</link><description>Background: 
随着强大文本条件生成模型的发展，图像编辑方法已经变得更加强大和灵活。然而，精确放置对象的位置和方向仍然是一个挑战，这通常需要精心设计的修复掩模或提示。本文展示了精心设计的视觉地图与粗略的物体掩模相结合，足以实现高质量的物体放置。通过建立在修复模型之上，我们通过设计一种条件信号来解决歧义，同时保持足够的灵活性以适应形状或物体方向的变化。这种方法赋予物体在场景中精细位置控制和外观控制的能力，从而能够精确放置现有物体。

Innovation: 
本文提出的方法是将精心设计的视觉地图与粗略的物体掩模相结合，以实现高质量的物体放置。而且，该方法通过使用基于修复模型的方法来保持背景不变，从而不同于联合建模物体和背景的方法。这种方法在不同的条件信号下进行了测试，以评估在不同任务中的编辑质量，包括需要非平凡形状变化的任务。最后，本文展示了如何结合对位置和外观的控制以精确放置场景中的已知物体。

Conclusion: 
本文提出的方法已经表明了其在汽车应用中的有效性，并展示了如何在不同的编辑任务中使用不同的条件信号以确保既定的精确位置与良好的外观质量。这种方法为实现复杂的3D物体放置任务提供了一种理论上和实践上的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21446</guid><pubDate>Fri, 27 Jun 2025 02:37:36 +0800</pubDate></item><item><title>359. cs.CV-通过低频重新思考无分类器引导中的过度饱和</title><link>https://arxiv.org/pdf/2506.21452</link><description>Background: 
在条件扩散模型中，指导机制 (CFG) 通过使用一个指导量来平衡条件项和无条件项的影响。高指导量通常被用来提升条件项的表现。然而，高指导量往往会导致过度饱和和不现实的伪影。研究指出，低频信号中的冗余信息积累是造成这些问题的关键因素。

Innovation: 
基于这一见解，本文提出了一种低频增强的无分类器指导 (LF-CFG)，新颖之处在于引入了一种适应性阈值测量方法来定位冗余信息的位置，并通过分析先验和当前步骤中低频信息的变化率来确定合理的阈值。此后，该方法应用了一种降权策略来减少低频信号中冗余信息的影响。实验结果显示，LF-CFG 在包括 Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5 以及 SiT-XL 等多种扩散模型中能够有效缓解过度饱和和不现实的伪影问题。

Conclusion: 
LF-CFG 通过分析低频信号中的冗余信息，有效地缓解了无分类器引导中的过度饱和和不现实的伪影问题，从而使模型能够生成更高质量的图像或文本。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21452</guid><pubDate>Fri, 27 Jun 2025 02:37:31 +0800</pubDate></item><item><title>360. cs.CV-一种在多样场景中地下矿工检测的综合数据集</title><link>https://arxiv.org/pdf/2506.21451</link><description>Background: 
地下采矿作业面临显著的安全挑战，使得紧急响应能力变得至关重要。现有的机器人在辅助搜救操作方面表现出了潜力，但其效果依赖于可靠的矿工检测能力。虽然深度学习算法提供了自动矿工检测的潜在解决方案，但它们需要针对采矿环境的综合培训数据集，而这些数据集目前还很缺乏。因此，开发和验证用于潜在紧急应用的矿工检测系统变得非常必要。

Innovation: 
该论文提出了一个全新的热成像数据集，旨在促进和发展可靠的安全应用中的热成像矿工检测系统。研究人员系统地捕捉了各种采矿活动和场景下的热图像，这为检测算法的开发和验证提供了坚实的基础。此外，该研究评估了几种最先进的对象检测算法在自建数据集上的表现，这有助于为未来的研究打下基础，并展示了使用热成像进行矿工检测的可行性。

Conclusion: 
该工作展示了使用热成像进行矿工检测的可行性，并为未来在此类关键安全应用中的研究提供了基础。尽管数据集不涵盖所有可能的紧急情况，但它代表了朝着在真实紧急场景中部署可靠的热成像矿工检测系统迈出的重要一步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21451</guid><pubDate>Fri, 27 Jun 2025 02:37:30 +0800</pubDate></item><item><title>361. cs.CV-跨数据集评估深度学习和视觉基础模型的异常与正常有丝分裂分类基准</title><link>https://arxiv.org/pdf/2506.21444</link><description>Background: 
异常有丝分裂标志着细胞分裂过程中的偏差，可能是肿瘤恶性程度的一个独立的预后相关标志。然而，由于异常有丝分裂的低发病率、与正常有丝分裂有时细微的形态差异、病理学家之间较低的一致性以及数据集中的类别不平衡，识别它们变得具有挑战性。基于乳腺癌异常有丝分裂数据集（AMi-Br），本研究旨在通过使用深度学习方法来全面比较自动化不典型有丝分裂图（AMF）分类的模型基准，包括基础模型、具有线性探针的基础模型以及通过低秩适应（LoRA）调优的基本模型。为进行严格的评估，还引入了两个新的保留AMF数据集——AtNorM-Br（从TCGA乳腺癌队列获取的有丝分裂）和AtNorM-MD（从MIDOG++训练集获取的多领域有丝分裂数据集）。

Innovation: 
本研究引入了两个新的数据集（AtNorM-Br 和 AtNorM-MD）用于评估，同时展示了通过使用最近在迁移学习和模型调优技术方面的进展来解决不典型有丝分裂分类问题的有效性，特别是通过LoRA调优Virchow线系统的基本模型取得了优异的结果。此外，研究提供了一个完整的代码和数据存储库（参见提供的GitHub链接），以支持进一步的分析和应用。

Conclusion: 
尽管不典型有丝分裂分类是一个具有挑战性的问题，但通过最近在迁移学习和模型调整方面的进展，可以有效地解决这一问题。通过基准研究的结果表明，LoRA调优的技术在基础模型中取得了较好的分类性能，证明了该方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21444</guid><pubDate>Fri, 27 Jun 2025 02:37:30 +0800</pubDate></item><item><title>362. cs.CV-EndoFlow-SLAM：基于流约束高斯束的实时内窥镜SLAM</title><link>https://arxiv.org/pdf/2506.21420</link><description>Background: 
在医疗手术场景，尤其是内窥镜手术中，高效的三维重建与实时可视化至关重要。近年来，3D Gaussian Splatting (3DGS) 在实现高效三维重建和渲染方面展现了显著的性能。大多数3DGS-基于的Simultaneous Localization and Mapping (SLAM) 方法仅依赖外观约束来优化3DGS和摄像机姿态。然而，在内窥镜场景中，由于非朗伯表面造成的光照不一致性以及呼吸动态运动对SLAM系统的性能造成了挑战。为了应对这些挑战，我们引入了基于光流损失的几何约束，这可以有效地约束场景的3D结构和摄像机运动。此外，我们提出了一种深度正则化策略，以缓解光照不一致性问题，并确保3DGS在内窥镜场景中的深度渲染有效。在此基础上，我们还改进了3DGS细化策略，专注于关键帧对应的渲染质量不佳的视点，提高了渲染结果。广泛的实验表明，我们的方法在新颖视图合成和姿态估计方面优于现有方法，并且在静态和动态手术场景中均表现出高性能。

Innovation: 
我们引入了基于光流损失的几何约束，并提出了一种深度正则化策略，以解决光照不一致性问题。此外，我们改进了3DGS细化策略，专注于关键帧对应的渲染质量不佳的视点，提高了渲染结果。这些创新使我们的方法能够更好地适应内窥镜场景的挑战，并在新颖视图合成和姿态估计方面实现了高性能。

Conclusion: 
通过深入分析内窥镜场景中的挑战，我们提出的方法在新颖视图合成和姿态估计方面显著优于现有方法。该方法能够实现高质量的三维重建和实时渲染，特别是在静止和动态手术场景中。我们的源代码将在论文被接受后公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21420</guid><pubDate>Fri, 27 Jun 2025 02:37:27 +0800</pubDate></item><item><title>363. cs.CV-FastRef: 快速原型精炼以实现少量样本工业异常检测</title><link>https://arxiv.org/pdf/2506.21398</link><description>Background: 
在数据稀少的环境下，实际自动化检查系统面临的少量样本工业异常检测（FS-IAD）构成了一个关键挑战。现有方法主要集中在从有限的正常样本中提取原型，但通常忽视了系统地将查询图像统计信息融入其中，以提高原型的代表性。这一过程中的局限之处在于，常规异常检测含有大量正常原型样本，但在少量样本的情况下，异常重构更为可能。因此，为了应对这个问题，我们提出了一种新的快速原型精炼框架FastRef。

Innovation: 
FastRef通过迭代的两阶段过程实现：(1) 使用可优化的转换矩阵将查询特征的特性转移到原型；(2) 通过原型对齐进行异常抑制。在异常抑制阶段，我们利用最优传输方法来衡量和最小化非高斯采样特征与原型和其精炼版本之间的差距，从而实现有效的异常检测。我们还将FastRef与三种最新的基于原型的少量样本工业异常检测方法（PatchCore, FastRecon, WinCLIP, 和 AnomalyDINO）结合进行综合评估。实验表明，在1/2/4样本的情况下，我们的方法不仅有效，而且具有计算效率。

Conclusion: 
我们在四个基准数据集（MVTec, ViSA, MPDD 和 RealIAD）上进行了广泛的实验，结果显示FastRef能够以计算效率高的方式有效实现少量样本工业异常检测。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21398</guid><pubDate>Fri, 27 Jun 2025 02:37:26 +0800</pubDate></item><item><title>364. cs.CV-XVerse: 通过DiT调制实现一致的多主体身份和语义属性控制</title><link>https://arxiv.org/pdf/2506.21416</link><description>Background: 
在文本生成图像时，细粒度地控制主题身份（如姿态、风格、光照）和语义属性（如多个主题）往往会损害Diffusion Transformers（DiTs）的可编辑性和连贯性。现有的许多方法会产生虚构现象或存在属性纠缠的问题。为解决此类挑战，本文提出了一种新的多主体可控生成模型XVerse。通过将参考图像转化为特定于标记的文字流调制偏移，XVerse允许在不干扰图像潜在特征的情况下对特定主题进行精确且独立的控制。因此，XVerse提供了高保真、可编辑的多主体图像合成，同时对个体主题特征和语义属性具有稳健的控制能力。这一进步显著提高了个性化和复杂场景生成的能力。

Innovation: 
提出了一种新的多主体可控生成模型XVerse。通过将参考图像转化为特定于标记的文字流调制偏移，使得能够在不改变图像潜在特性的情况下对特定主题进行精确且独立的控制，从而实现高保真、可编辑的多主体图像合成，同时对个体主题的特征和语义属性具有稳健控制能力。该方法显著改善了多主体身份和语义属性的控制能力。

Conclusion: 
XVerse模型在细粒度控制多主体身份和语义属性方面取得了显著进展，为个性化和复杂场景的图像生成提供了强大的新工具，克服了现有方法存在的问题，如可编辑性和连贯性的损害，以及归一化的困难。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21416</guid><pubDate>Fri, 27 Jun 2025 02:37:25 +0800</pubDate></item><item><title>365. cs.CV-CA-I2P：具有全局最优选择的通道自适应注册网络</title><link>https://arxiv.org/pdf/2506.21364</link><description>Background: 
检测无关的方法通常遵循从粗略到精细的流程，通过对图像和点云特征的提取来实现像素级别的匹配并细化密集的像素到点之间的对应关系。然而，图像和点云特征通道注意之间的差异可能会导致匹配结果退化，最终影响注册精度。此外，场景中相似的结构可能会导致跨模态匹配中的冗余对应关系。

Innovation: 
本文提出了一种通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强同模态特征并抑制跨模态敏感性，而GOS将局部选择替换为全局优化。该方法在RGB-D Scenes V2和7-Scenes数据集上的实验表明，相较于其他方法，该方法在图像到点云的注册中表现出更好的性能，达到了目前的最佳水平。

Conclusion: 
本文提出了一种具有全局最优选择的通道自适应注册网络，通过引入CAA和GOS模块，它提高了跨模态匹配的准确性和效率，特别是在图像到点云的注册任务上取得了最优的注册效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21364</guid><pubDate>Fri, 27 Jun 2025 02:37:23 +0800</pubDate></item><item><title>366. cs.CV-曲线感知的高斯散点图用于3D参数曲线重建</title><link>https://arxiv.org/pdf/2506.21401</link><description>Background: 
现有方法通常采用两阶段的方法，即先重建边缘点云，再进行参数曲线拟合。这种方法存在由于阶段间断开导致的误差累积问题。现有的方法在基于渲染的多视图优化中对参数曲线不太适合，需要引入另一种互补的表示方法，既能保留几何特性又能实现可微渲染。

Innovation: 
本文提出了一种单阶段的端到端框架，直接从多视图边缘图中重建3D参数曲线。该方法通过提出一种新颖的双向耦合机制将参数曲线与边缘方向的高斯成分进行耦合，形成了曲线感知的高斯表示（CurveGaussian），从而实现了3D曲线的可微渲染。此外，还引入了一种动态自适应拓扑优化框架，在训练过程中通过线性化、合并、分裂和修剪操作细化曲线结构。这种方法在综合评估中表现优于两阶段方法，且能显著降低训练过程中的参数数量，提高效率和性能。

Conclusion: 
本研究提出的方法在多视图数据集和真实世界基准上的评估中表现出优越性，尤其是在产出更清洁和更稳健的重建方面。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21401</guid><pubDate>Fri, 27 Jun 2025 02:37:20 +0800</pubDate></item><item><title>367. cs.CV-LLaVA-Pose: 通过关键点集成指令微调提高人体姿态和动作理解</title><link>https://arxiv.org/pdf/2506.21317</link><description>Background: 
当前的视觉-语言模型（VLMs）在通用视觉理解任务中表现良好，但在处理涉及人类姿态和动作的复杂视觉任务时表现不佳，这是由于缺乏专门针对指令跟随的人体关键点数据。本文通过将人体关键点与传统的视觉特征（如图注和边界框）结合，生成此类数据，以增强对人体中心场景的理解精度。研究构建了一个包含200,328个样本的数据集，用于微调针对人体中心任务的模型，重点关注会话、详细描述和复杂推理三个领域。

Innovation: 
本文提出了一种生成专门针对人体姿态和动作理解的关键点集成指令数据的方法，并建立了一个扩展的人体姿态和动作理解基准（E-HPAUB）来评估模型在这方面的性能。通过使用这种数据集对LLaVA-1.5-7B模型进行微调，所得的LLaVA-Pose模型在基准测试中取得了显著的性能提升，较原模型提高了33.2%。这一发现强调了关键点集成数据在增强多模态模型对人体中心视觉理解方面的有效性。

Conclusion: 
实验结果表明，使用关键点集成数据微调模型可以显著改善对人体姿态和动作的理解，这对于提高多模态模型在人体中心任务的性能具有重要意义。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21317</guid><pubDate>Fri, 27 Jun 2025 02:37:20 +0800</pubDate></item><item><title>368. cs.CV-PanSt3R: 多视角一致全景分割</title><link>https://arxiv.org/pdf/2506.21348</link><description>Background: 
3D场景的全景分割是对场景密集重建中的对象实例进行分割和分类的问题，尤其在仅依赖于未校准的2D图像时是一个具有挑战性的问题。现有方法通常利用现成的模型提取每个帧的二维全景分割，然后优化隐式几何表示（通常是基于NeRF）以整合和融合2D预测。然而，这种方法在利用跨视角的空间关系方面效果不佳，且需要摄像头参数和在测试阶段对每个场景进行昂贵的优化。

Innovation: 
提出了一种统一和集成的方法PanSt3R，该方法通过单次前向传播联合预测3D几何和多视角全景分割，从而避免了测试阶段需要的优化。该方法基于最新3D重建进展，具体是基于MUSt3R（一个多视角版本的DUSt3R）改进而来，增强了语义意识和多视角全景分割功能。此外，提出了一种更原则性的多视角分割后处理方法，并引入了一种简单的生成新视角预测的方法。

Conclusion: 
所提出的PanSt3R概念简单，速度快且可扩展，实现了多项基准测试的前沿性能，比现有方法快了几个数量级。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21348</guid><pubDate>Fri, 27 Jun 2025 02:37:20 +0800</pubDate></item><item><title>369. cs.CV-GenFlow：交互式模块化图像生成系统</title><link>https://arxiv.org/pdf/2506.21369</link><description>Background: 
生成艺术具有无限创意可能性，但由于高级建筑概念和计算工作流程所需的技术专长，其全部潜力尚未被充分开发。为了弥合这一差距，我们提出了GenFlow，一个新颖的模块化框架，它赋予所有技能水平的用户能够以精准和简便的方式生成图像的能力。通过一个基于节点的编辑器以及基于自然语言处理的智能助手，GenFlow将工作流的复杂性转化为直观且易于访问的体验。通过自动化部署过程并降低技术障碍，我们的框架使尖端的生成艺术工具对所有人开放。

Innovation: 
GenFlow是一个模块化的框架，具有以下创新特性：1. 基于节点的编辑器，实现无缝自定义；2. 基于自然语言处理的智能助手，简化了用户交互；3. 自动化部署流程，降低技术门槛；4. 提供直观和自适应的功能，优化工作流程，减少任务完成时间，提升用户理解能力。

Conclusion: 
实验结果表明，GenFlow能够优化工作流程，减少任务完成时间，并通过其直观界面和自适应功能增强用户体验。这些结果使GenFlow成为一项颠覆性的解决方案，重新定义了生成艺术中的访问性和效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21369</guid><pubDate>Fri, 27 Jun 2025 02:37:19 +0800</pubDate></item><item><title>370. cs.CV-ToosiCubix：基于车辆部件注释的单目3D立方体标签</title><link>https://arxiv.org/pdf/2506.21358</link><description>Background: 
许多现有的针对车辆的3D立方体标注方法依赖于昂贵且需要精细校准的相机-LiDAR或立体视觉系统，这限制了其大规模数据收集的可行性。ToosiCubix方法只需使用单目图像和固有相机参数，即可实现精确的3D立方体标注，且只需不到10次用户点击即可完成每辆车的标注，使其非常实用。通过注释车辆的不同部件的特定特征（如车轮、车标、对称性），该方法能够准确估计每个车辆的位置、姿态和尺寸，即使存在尺度不确定性（8自由度）。使用坐标下降策略解决几何约束优化问题，包括透视点n点问题(PnP)和最小二乘子问题。为了处理常见的尺度和不可观测的尺寸等歧义，该方法引入了概率尺寸先验，可实现在9自由度下的立方体放置。该研究成果通过与KITTI和Cityscapes3D数据集的验证，证明了ToosiCubix方法为高质量3D立方体标注提供了一种经济高效且可扩展的解决方案。

Innovation: 
ToosiCubix：一种仅使用单目图像和固有相机参数进行3D立方体标注的新方法，无需昂贵的相机-LiDAR或立体视觉系统。通过用户点击不少于10次进行标注，该方法提高了标注的实用性。利用注释车辆部件的特定特征实现在8自由度下的高精度标注。通过协调PnP和最小二乘子问题解决几何约束优化问题。引入概率尺寸先验处理多种常见歧义，实现在9自由度下的立方体放置。与现有方法相比，ToosiCubix方法提供了经济高效且可扩展的高质量3D立方体标注解决方案。

Conclusion: 
通过验证实验，ToosiCubix方法在KITTI和Cityscapes3D数据集上的应用证明了该方法的有效性和实际价值，为大规模3D立方体标注提供了经济可行且可扩展的方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21358</guid><pubDate>Fri, 27 Jun 2025 02:37:16 +0800</pubDate></item><item><title>371. cs.CV-使用层次输入依赖状态空间模型的整体手术阶段识别</title><link>https://arxiv.org/pdf/2506.21330</link><description>Background: 
机器人辅助手术中的手术工作流程分析至关重要，但由于手术持续时间较长，进行全面视频分析存在显著挑战。现有的方法主要依赖于变压器模型，但它们的二次注意力机制限制了对长手术视频的有效处理。因此，需要一种能捕捉局部和全局动态的同时进行决策的新方法，解决这一问题的方法尚未出现。

Innovation: 
本文提出了一种新颖的分层输入依赖状态空间模型，利用状态空间模型的线性扩展特性，允许在视频的整个长度上进行决策，同时捕捉局部和全局动态。该框架包含一个空间上一致的视觉特征提取器，该提取器将状态空间模型的头添加到视觉特征提取器以传播时间信息。该模型由两个关键模块组成：用于有效捕捉复杂局部动态的局部聚集状态空间模型块，以及用于建模整个视频时间依赖性的全局关系状态空间模型块。通过混合离散-连续监督策略对该模型进行训练，其中通过网络传播离散相位标签信号和连续相位进度信号。实验表明，与当前最先进的方法相比，该方法在多个数据集上表现出了显著的性能优越性（Cholec80 +2.8%，MICCAI2016 +4.3%，Heichole +12.9%）。

Conclusion: 
该方法在多个手术数据集上的表现证明了其在手术视频分析中的优越性和有效性。未来的工作计划在论文接受后公开代码。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21330</guid><pubDate>Fri, 27 Jun 2025 02:37:15 +0800</pubDate></item><item><title>372. cs.CV-ShotBench：Vision-Language模型中的专家级电影理解</title><link>https://arxiv.org/pdf/2506.21356</link><description>Background: 
电影的影技语言是传达叙述、情感和美学质量的基本视觉语言。尽管现代视觉-语言模型（VLMs）展示出强大的通用视觉理解能力，但它们在理解单帧中嵌入的细腻影技语法方面的能力仍然未被充分探索，缺少稳定的评估方法。这限制了细粒度的视觉理解能力以及AI辅助视频生成的精度。此外，现有VLMs在细微视觉线索和复杂空间推理方面存在严重限制，即使表现最佳的模型平均精确度也未超过60%。因此，提出了ShotBench，一个专门设计用于影技理解的基准数据库。

Innovation: 
构建了ShotBench基准数据库，其中包括来自200多部获奖影片（主要是奥斯卡提名）的3500多个专家标注的问题-答案（QA）对，涵盖了八种关键影技维度。通过ShotBench评估24个领先VLMs后，显示了显著的局限性。在此基础上，创建了ShotQA大型跨模态数据集，并通过监督微调和组相对策略优化开发了ShotVL。ShotVL在ShotBench上大幅超越了现有所有开源和专有模型，并确立了新的最佳性能。

Conclusion: 
开放源代码模型、数据和代码，以促进在这个关键领域快速进步的AI驱动的影技理解和生成。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21356</guid><pubDate>Fri, 27 Jun 2025 02:37:10 +0800</pubDate></item><item><title>373. cs.CV-DuET: 通过无实例任务算术实现双增量目标检测</title><link>https://arxiv.org/pdf/2506.21260</link><description>Background: 
现有的目标检测系统，如自动驾驶和监控系统，需要不断学习新的目标类别并同时适应不断变化的环境条件。现有的方法，如类别增量目标检测(CIOD)和领域增量目标检测(DIOD)，只能解决这一挑战的一部分。这些方法在未见过的领域中表现不佳，而在学习新类别时容易发生灾难性遗忘，限制了它们的现实应用效果。为了克服这些限制，研究引入了一种新的双增量目标检测(DuIOD)模型，该模型能够同时处理类别和领域变化，不需要实例样本，在无实例的情况下稳定进行增量学习。

Innovation: 
研究提出了DuET，一种基于任务算术的增量学习模型合并框架。它通过一个新颖的方向一致性损失来解决符号冲突问题，使得模型能够在不依赖于具体检测器的情况下稳定增量学习。DuET在保持实时检测的同时，使YOLO11和RT-DETR等模型能够作为实时增量目标检测器使用。为了全面评估系统的保留能力和适应性，研究引入了一种保留适应性指数(RAI)，结合了平均保留指数(Avg RI)和领域适应性指数，以此为共同指标。实验结果表明，DuET在帕斯卡系列和多样性天气系列上的有效性显著提升，改善了RAI指标，并在保留指数方面保持了高值。

Conclusion: 
实验结果显示，DuET在帕斯卡系列（4个任务）上获得了13.12%的RAI改进，保留了89.3%的平均保留指数。在多样性天气系列（3个任务）上，DuET获得了11.39%的RAI改进，保留了88.57%的平均保留指数。与现有方法相比，DuET表现出色。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21260</guid><pubDate>Fri, 27 Jun 2025 02:37:10 +0800</pubDate></item><item><title>374. cs.CV-可泛化的神经电磁反散射</title><link>https://arxiv.org/pdf/2506.21349</link><description>Background: 
电磁反散射问题（EISP）在医学成像等应用中至关重要，目标是从散射的电磁场中重建相对介电常数。这一逆过程本身固然是病态的和高度非线性的，因此极具挑战性。近期的基于机器学习的方法Img-Interiors展示了潜力，通过利用连续隐函数，但其需要特定案例的优化，无法对未见过的数据进行泛化，并且在稀疏发射器设置（例如，只有一个发射器）下失效。

Innovation: 
基于这一不足，本文从物理感知的角度重新审视问题，将其重新表述为两次逆散射-传输过程，并发现引起电流作为一种可泛化的中间表示，可以有效地将非线性散射过程与病态的逆问题脱耦。本文提出了一种用于EISP的首个基于物理的可泛化框架，包括一个电流估计器和一个相对介电常数解算器，该设计使数据驱动的训练和未见过数据的可泛化的前向预测成为可能，同时保持对发射器稀疏性的强鲁棒性。广泛的实验表明，本文方法在重建准确性、泛化能力和鲁棒性方面均优于现有方法。

Conclusion: 
本文为电磁反散射提供了全新的视角，并朝着经济高效的实际电磁成像解决方案迈出了重要一步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21349</guid><pubDate>Fri, 27 Jun 2025 02:37:08 +0800</pubDate></item><item><title>375. cs.CV-HieraSurg: 层次意识扩散模型在手术视频生成中的应用</title><link>https://arxiv.org/pdf/2506.21287</link><description>Background: 
手术视频生成在扩散模型取得通用领域视频生成成功后逐渐成为研究的重点方向。尽管已有方法能够生成高质量的视频，但大多数方法未能维持与手术行动和阶段的一致性，缺乏进行准确模拟所需的手术理解及精细指导。因此，现有方法存在一定的局限性，未能提供足够的手术细节和具体的指导信息。

Innovation: 
HieraSurg 提出了一个层次意识的手术视频生成框架，包含两个专门的扩散模型。第一个阶段通过分割预测模型预测未来粗略的语义变化，第二个阶段通过增加细粒度的视觉特征来生成最终的视频，从而实现有效的纹理渲染和视频空间中语义信息的整合。该方法在多个抽象层次上利用了手术信息，包括手术阶段、动作三元组和全景分割图。实验结果表明，该模型在术胆切除手术视频生成中的表现显著优于先前的工作，显示出强大的泛化能力和生成更高帧率视频的能力。

Conclusion: 
HieraSurg 模型在提供现有分割图的情况下表现出特别精细的符合性，表明它在实际手术应用中的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21287</guid><pubDate>Fri, 27 Jun 2025 02:37:08 +0800</pubDate></item><item><title>376. cs.CV-CoPa-SG：带参数和原型关系的密集场景图</title><link>https://arxiv.org/pdf/2506.21357</link><description>Background: 
2D场景图提供了一种结构化且可解释的框架用于场景理解，但当前的工作仍然受限于精确场景图数据的不足。因此，本文提出了CoPa-SG，这是一种具有高精度真实标签和所有对象之间详尽关系标注的合成场景图数据集，以解决数据瓶颈问题。同时，还引入了两种新的基本概念——参数化关系和原型关系，以提高场景图的表达能力。

Innovation: 
提出了CoPa-SG数据集，包含高精度真实标签和详尽的关系标注；引入了参数化和原型关系两种新型的基本概念，其中参数化关系提供了更精细的表现方式，而原型关系则编码了场景中的假设性关系，展示了新关系类型如何在下游应用中增强规划和推理能力。

Conclusion: 
使用CoPa-SG数据集，对比了多种场景图生成模型的表现，并展示了如何将新类型的关系整合到下游应用中以提升规划和推理能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21357</guid><pubDate>Fri, 27 Jun 2025 02:37:08 +0800</pubDate></item><item><title>377. cs.CV-DrishtiKon: 多粒度视觉接地用于富文本文档图像</title><link>https://arxiv.org/pdf/2506.21316</link><description>Background: 
文档智能和视觉问答（VQA）系统中，在文本丰富的文档图像上实现视觉接地是一项关键但尚未充分探索的挑战。现有的系统在这个领域投入不足，特别是在处理复杂的、多语言的文档时，解释性和可信度都存在问题。需要一个可以提高解释性和可信度的框架来应对该挑战，从而推动文档智能和VQA系统的发展，使其在现实世界、以文本为中心的场景中更加稳健和可解释

Innovation: 
DrishtiKon 是一个多粒度视觉接地框架，通过集成强大的多语言OCR、大型语言模型以及新型区域匹配算法来准确地在块、行、词和点级别定位答案段。通过创建一个新的基准数据集 CircularsVQA 测试集的细分注释，提供多种粒度的精心校验注释。实验表明，该方法在接地准确性上达到最新水平，且在行级别提供最佳的精确度与召回之间的权衡。删减研究进一步突显了多块和多行推理的好处。与当前领先的视觉语言模型的比较性评估揭示了其在精确定位方面的局限性，强调了我们结构化的对齐方法的有效性

Conclusion: 
我们的研究为在现实世界、以文本为中心的场景中实现更稳健和可解释的文档理解系统铺平了道路。同时，我们已将代码和数据集提供给公众使用，以促进进一步的研究和发展&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21316</guid><pubDate>Fri, 27 Jun 2025 02:37:01 +0800</pubDate></item><item><title>378. cs.CV-在遥感中的掩码自编码器持续自监督学习</title><link>https://arxiv.org/pdf/2506.21312</link><description>Background: 
遥感领域（RS）中持续学习（CL）方法的发展备受关注，这些方法旨在通过连续获取的训练数据顺序学习新的任务，同时通过使用大量标记训练样本来增强对灾难性遗忘的鲁棒性。然而，在遥感领域中，获取大量标记训练样本是成本高昂且不总是可行的。为了解决这一问题，本文提出了一种新颖的持续自监督学习方法CoSMAE，该方法基于掩码自编码器，旨在通过数据混合法和模型混合法知识蒸馏来增强模型的鲁棒性，以更好地泛化到不同的任务中并降低灾难性遗忘的风险。

Innovation: 
提出了一种名为CoSMAE的新颖持续自监督学习方法，该方法包含两个组件：数据混合法和模型混合法知识蒸馏。数据混合法通过插值当前任务和之前任务的图像来保留前数据分布的信息，而模型混合法知识蒸馏则通过插值过去的模型和当前模型的模型权重来进行知识蒸馏，同时作为知识蒸馏的老师。这种方法通过在数据和模型层面上规范掩码自编码器来互补地增强模型的泛化能力，降低灾难性遗忘风险。实验结果表明，CoSMAE在应用于掩码自编码器（MAE）的持续学习方法中实现了高达4.94%的显著改进，且代码已公开。

Conclusion: 
实验结果表明，CoSMAE在应用于掩码自编码器的持续学习方法中实现了高达4.94%的显著改进。该方法通过在数据和模型层面上规范掩码自编码器，有效降低了灾难性遗忘的风险，提升了模型在跨任务学习中的泛化能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21312</guid><pubDate>Fri, 27 Jun 2025 02:37:00 +0800</pubDate></item><item><title>379. cs.CV-BitMark for Infinity: 位级自回归图像生成模型的水印</title><link>https://arxiv.org/pdf/2506.21209</link><description>Background: 
当前最先进的文本到图像模型如Infinity能够以前所未有的速度生成超现实的图像。这些模型以位级自回归的方式在实际无穷大的离散令牌集上进行操作。然而，尽管它们具有强大的生成能力，但也存在一个不断增长的风险：随着它们的输出越来越多地填充互联网，有可能被刮取并重新用于训练数据——尤其是模型本身以前的版本。这种现象已被证明会导致模型崩溃，即在通过生成内容反复训练时，会导致性能逐渐下降。一种有希望的缓解策略是水印技术，它将人类无法察觉但可以检测的信号嵌入到生成的图像中，从而可以识别生成的内容。

Innovation: 
我们引入了BitMark，这是一种针对Infinity的鲁棒的位级水印框架。我们的方法在Infinity的图像生成过程中，在多个尺度（也称为分辨率）的令牌流的位级别直接嵌入水印。位级水印微妙地影响位以保持视觉保真度和生成速度，同时具有抵抗多种去除技术的鲁棒性。此外，它还具有高放射性，即使用经过BitMark水印处理的生成图像来训练另一个图像生成模型时，第二个模型的输出也会携带水印。当只有微调扩散或图像自回归模型时，这种放射性痕迹仍然可以被检测到。总体而言，我们的方法提供了一种防止图像生成模型模型崩溃的原理性步骤，能够可靠地检测生成的输出。

Conclusion: 
BitMark框架为防止图像生成模型中的模型崩溃提供了一个可靠的检测方法，确保生成图像和内容的可追溯性和可行性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21209</guid><pubDate>Fri, 27 Jun 2025 02:36:56 +0800</pubDate></item><item><title>380. cs.CV-HumanOmniV2：从理解到全模态推理的上下文</title><link>https://arxiv.org/pdf/2506.21277</link><description>Background: 
随着多模态大型语言模型的迅速发展，深入理解和解释人类意图的能力变得尤为重要，这需要详细和周到的推理。虽然强化学习已被证明可以增强大型语言模型的推理能力，但将RL应用到多模态数据和格式仍然面临挑战。现有的多模态推理模型存在两个主要问题：全局上下文理解不足和捷径问题。这些问题会导致模型误解多模态信息，从而产生错误的答案或忽略关键线索，不充分地利用信息进行推理。已有方法未能充分理解全局上下文，导致信息的遗漏，这限制了模型的能力。为解决这些问题，研究提出通过引入一种新的系统性方法来确保模型在多模态输入中具备清晰的全局上下文理解，并通过评估逻辑奖励等方法提升复杂的推理能力。

Innovation: 
提出了一种新的系统性方法，用于在多模态输入中确保模型具备清晰的全局上下文理解，并通过大型语言模型评估上下文奖励、格式奖励和准确性奖励，同时引入一种逻辑奖励来评估推理过程是否成功地将多种模态的信息与逻辑方法结合在一起。此外，还提出了一个名为IntentBench的新推理基准，旨在评估模型在理解复杂人类意图和情感方面的表现。与现有的开源全模态模型相比，提出的方法在多个全模态基准测试中表现出更先进的性能。

Conclusion: 
通过综合考虑上下文奖励、格式奖励和准确性奖励，以及采用逻辑奖励来提高复杂推理能力的策略，新方法在全模态推理表现优于现有方法。验证了所提出方法的有效性，并通过发布的基准测试IntentBench评估了模型的能力，展示了研究成果的显著价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21277</guid><pubDate>Fri, 27 Jun 2025 02:36:54 +0800</pubDate></item><item><title>381. cs.CV-WordCon: 生成图像中逐字排版控制</title><link>https://arxiv.org/pdf/2506.21276</link><description>Background: 
在生成图像中实现精确的文字级别排版控制一直是一个持续的挑战。为此，作者构建了一个逐字控制的场景文本数据集，并引入了Text-Image Alignment (TIA)框架，该框架利用 Grounding 模型提供的文本与局部图像区域之间的跨模态对应关系来增强文本到图像 (T2I) 模型的训练。此外，作者提出了 WordCon（一种混合参数高效微调方法），通过重新参数化选择的关键参数，提高了效率和可移植性，使其能够无缝集成到各种管道中，包括艺术文字渲染、文字编辑和图像条件下的文字渲染。为了进一步增强可控性，应用了掩码损失来引导模型专注于学习图像中的文字区域，并使用联合注意损失提供特征级监督，以促进不同词语之间的解耦。质性和定量结果证明了该方法优于现有方法。相关数据集和源代码将可供学术界使用。

Innovation: 
1. 构建了一个基于场景的逐字控制文本数据集。n2. 提出了 TIA 框架，利用 Grounding 模型进行跨模态对应。n3. 提出了 WordCon 方法，通过重新参数化选择的关键参数，提高了模型的效率和可移植性。n4. 应用掩码损失引导模型学习文字区域，使用联合注意损失进行特征级监督，促进不同词语的解耦。

Conclusion: 
通过使用WordCon方法，作者展示了其在文本到图像生成方面的优越性，相关数据集和源代码将供学术界使用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21276</guid><pubDate>Fri, 27 Jun 2025 02:36:51 +0800</pubDate></item><item><title>382. cs.CV-通过条件扩散转换器填充器的视频虚拟试穿</title><link>https://arxiv.org/pdf/2506.21270</link><description>Background: 
视频虚拟试穿的目标是在连续视频帧中自然地将服装贴合到目标人物身上。这是一个具有挑战性的任务，因为它需要保持良好的时空一致性，同时还要确保所有的帧都能保持服装的细节。传统的基于图像的方法逐帧进行操作，导致的结果通常一致性差。最近的基于弥散的方法虽然试图通过引入时空注意力机制来改善这个问题，但仍存在一致性问题。因此，本文提出了一种新的方法——视频试穿填充器（ViTI），将其视为一种条件下的视频修复任务，从解决视频生成问题开始，确保从一开始就具有良好的时空一致性。

Innovation: 
本文提出了ViTI（Video Try-on Inpainter），这是一种新的视频虚拟试穿方法。通过使用基于扩散转换器的视频修复框架，并结合全面的3D时空注意力机制，该方法逐步适应视频服装修复任务。这种方法不同于以往的方法，从解决视频生成的问题出发，具有更好的时空一致性。此外，它通过使用一系列掩码策略和多层次的训练，确保修复后的服装区域能够根据给定的提示保持较好的时空一致性。最后，通过条件属性添加穿着的服装状态，确保修复的服装外观和细节符合预期。

Conclusion: 
通过定量和定性的实验结果表明，ViTI在视频虚拟试穿任务上优于之前的其他工作，证明了其有效性和优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21270</guid><pubDate>Fri, 27 Jun 2025 02:36:51 +0800</pubDate></item><item><title>383. cs.CV-MedPrompt: 融合权重路由的大语言模型-CNN融合在医学图像分割和分类中的应用</title><link>https://arxiv.org/pdf/2506.21199</link><description>Background: 
当前的医学图像分析系统通常是为特定任务设计的，需要单独的模型来进行分类和分割，缺乏支持用户自定义工作流程的灵活性。

Innovation: 
MedPrompt 是一种统一框架，结合了一种前端少量示例提示大型语言模型（Llama-4-17B），用于高层任务规划，和一个可模块化的卷积神经网络（DeepFusionLab），用于低层图像处理。LLM 解释用户指令并生成结构化输出以动态路由任务特定的预训练权重。这种方法避免了在添加新任务时重新训练整个框架，仅需任务特定的权重，增强了扩展性和部署。该框架在 19 个公共数据集上进行了评估，涵盖了 12 项任务，包括 5 种成像模态。系统在执行提示驱动的指令方面实现了 97% 的端到端正确性，平均推理延迟为 2.5 秒，适用于接近实时应用。DeepFusionLab 达到了竞争力的分割准确性（如肺部 Dice 0.9856）和强大的分类性能（肺结核 F1 0.9744）。

Conclusion: 
MedPrompt 通过结合大语言模型的可解释性和模块化 CNN 的高效性，实现了可扩展的、基于提示的医学图像分析。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21199</guid><pubDate>Fri, 27 Jun 2025 02:36:49 +0800</pubDate></item><item><title>384. cs.CV-Out-of-Distribution Semantic Occupancy Prediction</title><link>https://arxiv.org/pdf/2506.21185</link><description>Background: 
3D语义占用预测对于自动驾驶至关重要，能提供密集且语义丰富的环境表示。现有方法主要针对分布内场景，容易受到分布外对象和长尾分布的影响，增加了未检测异常和误解的风险，存在安全问题。

Innovation: 
提出了一种针对分布外语义占用预测的方法，通过合成异常整合管道生成具有现实空间和遮挡模式的数据集VAA-KITTI和VAA-KITTI-360，并引入OccOoD框架，利用几何-语义融合的体素BEV逐层融合（VBPF）分支增强分布外检测，取得了最佳的分布外检测性能（AuROC 67.34%，AuPRCr 29.21%）

Conclusion: 
通过OccOoD框架，在1.2米范围内实现了最先进的分布外检测性能，同时保持了竞争力的占用预测性能，并公开了数据集和源代码。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21185</guid><pubDate>Fri, 27 Jun 2025 02:36:48 +0800</pubDate></item><item><title>385. cs.CV-Temporal Rate Reduction Clustering for Human Motion Segmentation</title><link>https://arxiv.org/pdf/2506.21249</link><description>Background: 
人类动作分割（HMS）旨在将视频划分为无重叠的人体动作。尽管当前的方法主要基于子空间聚类方法，并假定高维时间数据分布在子空间的联合分布上，但捕获复杂人体动作的帧在背景混杂的情况下可能不易与子空间分布对齐。

Innovation: 
该论文提出了一种创新的方法，即Temporal Rate Reduction Clustering (TR²C)，以联合学习结构化表示和亲和性以分割视频中的帧序列。此方法学习到的结构化表示具有良好的时间一致性且与子空间结构对齐，有利于人类动作分割任务。

Conclusion: 
在五个基准HMS数据集上的广泛实验中，该方法能够利用不同的特征提取器达到最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21249</guid><pubDate>Fri, 27 Jun 2025 02:36:44 +0800</pubDate></item><item><title>386. cs.CV-DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation</title><link>https://arxiv.org/pdf/2506.21237</link><description>Background: 
视觉数据中的伪相关特征往往阻碍了分布外(OOD)性能。大多数现有方法仅关注图像特征的分离，而DiMPLe专注于在视觉和语言模态中分离不变特征和伪特征，同时保持一致的对齐，从而提高对新类别的泛化能力和应对分布变化的鲁棒性。

Innovation: 
DiMPLe提出了一种新颖的方法，即解耦多模态提示学习(DiMPLe)，旨在通过最大限度地减少不变特征和伪特征之间的互信息、正则化伪特征以及对比学习不变特征来分离多模态学习中的不变特征和伪特征。与CoOp-OOD方法相比，迪MPLe在11个不同数据集上平均表现出更优的性能，基类准确率提升了15.27%，新类准确率提升了44.31%。

Conclusion: 
通过分离不变特征和伪特征，DiMPLe提高了多模态学习中对新类别的泛化能力以及对分布变化的鲁棒性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21237</guid><pubDate>Fri, 27 Jun 2025 02:36:44 +0800</pubDate></item><item><title>387. cs.CV-实时ESFP：估计、平滑、滤波和姿态映射</title><link>https://arxiv.org/pdf/2506.21234</link><description>Background: 
该论文介绍了一种名为ESFP的端到端管道，该管道能够将单目RGB视频内容转换为低成本4自由度桌面机器人的可执行关节轨迹。这是该领域的一个新问题，因为当前的方法通常无法有效地从视觉输入中生成精确且连贯的运动轨迹，并且往往需要更高的计算成本和复杂性。ESFP通过4个连续的模块依次处理这一挑战：首先估计、然后平滑、接着滤波、最后进行姿态映射，从而简化了这一过程，使其实时可行并降低了成本。

Innovation: 
ESFP管道的独特创新在于它采用了一种新颖的方法来处理估计、平滑、滤波和映射的问题。首先，ROMP用于三维骨架估计；其次，HPSTM结合序列到序列的Transformer和自注意力机制，同时平滑关节轨迹并保持骨骼长度不变和解剖学合理性；接着，基于HPSTM的不确定性估计对根部归一化的轨迹进行加权滤波以抑制噪声；最后，几何重新定向层将肩-肘-腕单元组转换为uArm的极坐标工作空间，同时保持手腕方向。这种方法显著提高了轨迹的实时性和精度，降低了计算要求，并且能够在低成本环境中实现复杂的机械臂运动控制。

Conclusion: 
总的来说，ESFP管道为从单目RGB视频中生成低计算量的关节轨迹提供了一种可行的解决方案。它不仅可以应用于低成本桌面机器人，还可以扩展到其他小型或移动机器人，如无人机或智能家居设备。这一方法在实时性和性能方面都实现了显著的改进，为未来的机器人应用打开了新的可能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21234</guid><pubDate>Fri, 27 Jun 2025 02:36:42 +0800</pubDate></item><item><title>388. cs.CV-面向任务的KV压缩以实现低成本的长视频理解</title><link>https://arxiv.org/pdf/2506.21184</link><description>Background: 
现有的多模态大型语言模型（MLLMs）在长视频理解（LVU）方面面临严重挑战，主要是由于高昂的计算成本。尽管近期一些方法探讨了KV压缩来缓解这一问题，但这些方法在高压缩率时常常导致显著的信息丢失。

Innovation: 
该论文提出了Video-X^2L，一种灵活保存每个LVU任务关键视频信息的方法。Video-X^2L包含两种关键操作：层级KV压缩和选择性KV重新加载。通过这两种操作，使MLLM在充分利用任务特定信息的同时保持整体紧凑性。Video-X^2L简单有效，无需额外训练且可以直接兼容现有的KV压缩可实现的MLLMs.

Conclusion: 
实验结果表明，Video-X^2L在各种流行LVU基准测试中表现优异，远超现有的KV压缩方法，同时显著节省计算成本。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21184</guid><pubDate>Fri, 27 Jun 2025 02:36:40 +0800</pubDate></item><item><title>389. cs.CV-解锁约束：无源场感知遮挡aware平滑分割</title><link>https://arxiv.org/pdf/2506.21198</link><description>Background: 
全景图像处理对于全方位感知是必不可少的，但面临着失真、视角遮挡和标注不足等限制。先前的无监督领域适应方法能够从标记的针孔数据转移到未标记的全景图像，但仍需要访问源针孔数据。

Innovation: 
本文引入了一个更为实际的任务，即无需数据的感知遮挡aware平滑分割（Source-Free Occlusion-Aware Seamless Segmentation，SFOASS），并提出了首个解决该问题的方法UNconstrained Learning Omni-Context Knowledge (UNLOCK)。UNLOCK框架包括两个关键模块：全景伪标签学习和不可见驱动上下文学习，能够在不依赖源数据或目标标签的情况下，增强模型实现360°视角覆盖和感知遮挡。

Conclusion: 
通过实际到实际和合成到实际的适应设置对提出的SFOASS任务进行了基准测试。实验结果表明，我们的无源方法在mAAP和mAP上的性能与依赖源方法相当，分别为10.9和11.6，并且在mAPQ上比仅依赖源数据的方法提高了4.3的绝对值，所有数据和代码将在https://github.com/XYZ处公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21198</guid><pubDate>Fri, 27 Jun 2025 02:36:39 +0800</pubDate></item><item><title>390. cs.CV-ReME: 一种以数据为中心的无训练开放词汇分割框架</title><link>https://arxiv.org/pdf/2506.21233</link><description>Background: 
现有的无训练开放词汇语义分割（OVS）方法通常依赖预训练模型的注意力机制或生成合成数据以进行复杂的检索过程，但这些方法的效果受限于所使用的模型能力和参考集的质量不足。为了解决这一问题，该论文专注于高质量数据集的构建，提出了一种以数据为中心的方法，显著提高了无训练OVS的效果。

Innovation: 
该论文引入了一种以数据质量为导向的框架，包括一个数据管道用于构建高质量的参考集，并采用简单的基于相似性的检索方法来揭示高质量数据的重要性。这种方法在十个基准数据集上的广泛评估表明，其在无训练的开放词汇分割方面的表现优于所有现有方法，突出了以数据为中心的设计对推进开放式词汇分割的重要性。

Conclusion: 
该研究证明了高质量数据集对于无训练OVS的重要性，并展示了其方法在现有技术中的优势，强调了在该领域进一步发展时以数据为中心的方法的重要性。感兴趣的读者可参考论文提供的代码链接。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21233</guid><pubDate>Fri, 27 Jun 2025 02:36:38 +0800</pubDate></item><item><title>391. cs.CV-GroundFlow: 一种用于3D点云序列定位的时间推理插件模块</title><link>https://arxiv.org/pdf/2506.21188</link><description>Background: 
当前的3D视觉定位方法将具有多步骤文本指令整体处理，未能从每个步骤中提取有用的时间信息。然而，序列3D点云定位（SG3D）中的文本指令经常包含像“它”、“这里”和“相同的”这样的代词，以使语言表达更加简洁。这需要定位方法理解上下文并从之前的步骤中检索相关的信息来正确定位对象序列。由于缺乏有效的模块来收集相关的历史信息，现有的3D视觉定位方法在适应SG3D任务时面临巨大挑战。

Innovation: 
本文提出了一种时间推理插件模块GroundFlow，用于3D点云序列定位。它通过综合前文信息来改善3D视觉定位基线方法的任务准确性，甚至超过了在各种数据集上进行预训练的3D大型语言模型。GroundFlow根据当前指令的相关性有选择地提取短期和长期步骤信息，从而能够全面观察历史信息并在步骤数量增加时保持其时间理解优势。

Conclusion: 
本文的工作向现有的3D视觉定位模型引入了时间推理的能力，并在SG3D基准测试的五个数据集上实现了最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21188</guid><pubDate>Fri, 27 Jun 2025 02:36:37 +0800</pubDate></item><item><title>392. cs.CV-Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition</title><link>https://arxiv.org/pdf/2506.21165</link><description>Background: 
3D物体形状的点集语义表示学习常常受到显著几何变异的挑战，这主要源于数据采集方法的差异。通常，训练数据由点模拟器生成，而测试数据则由不同的3D传感器收集，这种模拟到现实（Sim2Real）领域差距限制了点分类器的泛化能力。当前的无监督领域适应（UDA）技术在处理这种差距时存在困难，因为它们往往缺乏能捕捉全局拓扑信息的稳健、领域无关的描述符，导致对源领域有限的语义模式过度拟合。

Innovation: 
本文介绍了一种新颖的全局拓扑感知建模（TAM）框架，用于解决物体点云上的无监督模拟到现实（Sim2Real）领域适应问题。该框架通过利用低层次的高频三维结构的全局空间拓扑，并通过一个新颖的自我监督学习任务建模局部几何特征的拓扑关系来缓解领域差距。此外，本文还提出了一种先进的自我训练策略，结合跨域对比学习和自我训练，有效减少了嘈杂伪标签的影响，增强了适应过程的稳健性。

Conclusion: 
实验结果在三个公开的Sim2Real基准数据集上验证了TAM框架的有效性，显示在所有评估任务中相对于当前最先进的方法的一致改进。本文的工作代码将在以下链接处公开：this https URL.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21165</guid><pubDate>Fri, 27 Jun 2025 02:36:34 +0800</pubDate></item><item><title>393. cs.CV-几何与感知引导的高斯分布用于基于单张图像的多视图一致3D生成</title><link>https://arxiv.org/pdf/2506.21152</link><description>Background: 
生成单张图像对应的逼真三维物体需要自然外观、三维连续性以及能够捕捉不可见区域的多种可能解释。现有的方法主要依赖于微调预训练的2D扩散模型或直接通过快速网络推断或3D Gaussian Splatting生成3D信息，但他们的结果通常在多视角一致性方面表现不佳，缺乏几何细节。

Innovation: 
本文提出了一种新颖的方法，无需额外的模型训练即可无缝结合几何先验和感知先验，从单张图像重建详细的三维物体。具体而言，训练了三个由几何先验、感知先验和高斯噪声初始化的不同高斯分支。几何先验捕捉粗糙的3D形状，感知先验利用预训练的2D扩散模型增强多视角信息。之后，通过几何和感知先验之间的相互作用以及基于再投影策略的深度一致性增强，进一步精炼3D高斯分支。

Conclusion: 
实验表明，我们方法的重建结果具有更高的保真度，优于现有的方法，在新视角合成和3D重建中表现出稳健且一致的三维对象生成。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21152</guid><pubDate>Fri, 27 Jun 2025 02:36:33 +0800</pubDate></item><item><title>394. cs.CV-基于树结构的语义损失函数：应用于稀疏监督的大规模多类别高光谱分割</title><link>https://arxiv.org/pdf/2506.21150</link><description>Background: 
高光谱成像（HSI）在手术应用中展现出了巨大的潜力，能够提供超乎肉眼识别的生物组织详细信息。目前，研究人员正在努力细化标注工作以训练视觉系统识别大量不同类的组织差异。然而，当前用于生物医学分割任务的学习方法在所有错误上施加相同惩罚，未能利用标签空间内的类别语义信息。为了改进这一问题，本文提出了一种基于树结构的语义损失函数，并将其应用于一种使用稀疏、无背景标注的最新方法中。丰富的实验证明，该方法在包含107个临床定义语义分层结构的稀疏标注HSI数据集上达到了最先进的性能。此外，该方法还能够在不牺牲现有分布（ID）像素分割性能的同时，有效检测出分布外（OOD）像素。

Innovation: 
本文提出了两种基于树的语义损失函数，利用标签的分层组织，改进了目前均匀惩罚所有错误的方法。此外，将这些损失函数集成到一种使用稀疏、无背景标注的最新方法中，以实现高效的高光谱图像大规模多类别分割，并能有效检测分布外像素。

Conclusion: 
本文的方法在包含107个临床定义语义分层结构的稀疏标注HSI数据集上达到了最先进的性能，并且能够有效检测分布外像素而不影响现有分布像素的分割性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21150</guid><pubDate>Fri, 27 Jun 2025 02:36:30 +0800</pubDate></item><item><title>395. cs.CV-GoIRL: 基于图的逆强化学习方法用于多模态轨迹预测</title><link>https://arxiv.org/pdf/2506.21121</link><description>Background: 
自主驾驶中周围代理的轨迹预测是一个具有挑战性的任务，因为存在固有的不确定性和潜在的多模态性。现有的主要依赖于监督学习的数据驱动方法在这种情况下表现不佳。本文在基于逆强化学习（IRL）的预测框架中引入了一个新颖的图导向逆强化学习（GoIRL）框架，该框架结合了向量化的上下文表示，以解决这一问题。

Innovation: 
本文开发了一个特征适配器，该适配器能够有效地将车道图特征聚合到网格空间中，这使得可以无缝地与最大熵IRL范式集成，以推断奖励分布并得到能被采样以诱导多种可能计划的策略。在此基础上，我们实现了一个基于层次化参数化的轨迹生成器，并加入了一个细化模块来提高预测准确性，以及一种概率融合策略来增强预测的信心。

Conclusion: 
大规模的实验证明了我们的方法不仅在Argoverse &amp;amp; nuScenes运动预测基准上达到了最先进的性能，而且在泛化能力方面也优于现有的监督模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21121</guid><pubDate>Fri, 27 Jun 2025 02:36:28 +0800</pubDate></item><item><title>396. cs.CV-带有噪声标签的心脏MRI心脏疤痕深度学习稳健分割</title><link>https://arxiv.org/pdf/2506.21151</link><description>Background: 
心脏MRI中的心肌疤痕精确分割对临床评估和治疗规划至关重要。本研究旨在通过微调最先进的模型，提出一种稳健的深度学习流水线，实现完全自动的心肌疤痕检测和分割，以应对半自动注释引入的标签噪声、数据异质性和类别不平衡等挑战。

Innovation: 
该研究采用了Kullback-Leibler损失和广泛的增强数据来解决标签噪声、数据异质性和类别不平衡问题。特别是在存在噪声标签的情况下，该方法显示出对急性与慢性病例的高度准确性和平滑度。同时，该方法在不同成像条件和临床任务中表现出强大的泛化能力，超越了诸如nnU-Net在内的先进模型，突显其在各种成像条件下的稳健性。

Conclusion: 
该研究为自动心肌疤痕量化建立了可靠的基础，支持深度学习在心脏成像中的更广泛应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21151</guid><pubDate>Fri, 27 Jun 2025 02:36:27 +0800</pubDate></item><item><title>397. cs.CV-EgoAdapt：适应性多感官蒸馏和策略学习以实现高效第一人称感知</title><link>https://arxiv.org/pdf/2506.21080</link><description>Background: 
现代感知模型，尤其是为执行多感官第一人称任务设计的模型，在性能方面取得了显著的成果，但往往伴随着巨大的计算成本。这些高需求为实际部署带来了挑战，尤其是在资源受限的环境中。

Innovation: 
本文引入了EgoAdapt框架，该框架能够适应性地进行跨模态蒸馏和策略学习，从而在不同第一人称感知任务（包括第一人称动作识别、主动发言人定位和行为预测）中实现高效推理。提出的策略模块具有任务特定的动作空间适应性，使其具有广泛的适用性。实验结果表明，该方法显著提升了效率，相较于对应的最佳模型，GMACs降低了89.09%，参数减少了82.02%，能耗减少了9.6倍，同时保持了与这些性能的可比性，并在许多情况下超越了这些模型的性能。

Conclusion: 
本研究通过EgoAdapt框架，在提高效率的同时，仍然保持了最优模型的性能，为资源受限环境下的实际部署提供了有效解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21080</guid><pubDate>Fri, 27 Jun 2025 02:36:25 +0800</pubDate></item><item><title>398. cs.CV-OracleFusion: 结构约束语义排版辅助甲骨文解译</title><link>https://arxiv.org/pdf/2506.21101</link><description>Background: 
作为最早的一种古代文字之一，甲骨文保存了古代文明的文化记录和思想表达。尽管已经发现了大约4500个甲骨文字符，但只有约1600个被成功解读。剩余未解读的字符因其复杂的结构和抽象的图像，增加了解读的难度。现有技术在处理这些挑战方面存在不足，亟需新的方法来提高甲骨文解读的准确性和视觉表现力。

Innovation: 
本文提出了一个新的两阶段语义排版框架，OracleFusion。第一阶段通过增强的空间意识推理(Multimodal Large Language Model, MLLM)分析甲骨文字符的笔画结构，进行关键组件的视觉定位；第二阶段引入了结构化矢量融合(Oracle Structural Vector Fusion, OSVF)，结合笔画结构约束和笔画保持约束，确保生成语义丰富的矢量字体的准确性，保持笔画结构的客观完整性。此方法不仅提高了字形的可读性和审美质量，还为未曾见过的甲骨文字符提供了专家级的见解，进而促进了甲骨文的解读进程。实验结果表明，OracleFusion在语义、视觉吸引力和笔画保持方面显著优于其他最先进的基线模型。

Conclusion: 
OracleFusion在语义解读、视觉表现力和笔画保持方面表现卓越，为甲骨文的解读提供了一种有效的工具，有助于提高甲骨文解读的准确性和效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21101</guid><pubDate>Fri, 27 Jun 2025 02:36:25 +0800</pubDate></item><item><title>399. cs.CV-CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization</title><link>https://arxiv.org/pdf/2506.21117</link><description>Background: 
在动态3D环境中，准确地随着时间更新场景表示对于机器人的应用、混合现实和具身AI等至关重要。随着场景的变化，需要高效的更新方法来在维持最新高质重建的同时避免重新优化整个场景所带来的计算开销。

Innovation: 
CL-Splats是一种通过稀疏场景捕获增量更新基于Gaussian splatting的3D表示的方法。CL-Splats集成了一个鲁棒的变化检测模块，能够分段更新和静态元素，从而实现聚焦的局部优化，避免不必要的重新计算。此外，CL-Splats支持历史场景状态的存储和恢复，促进了时间分割和新的场景分析应用的产生。我们的实验结果表明，与最先进的技术相比，CL-Splats可以更高效地更新并提高重建质量，为此类实时3D场景重建任务的未来自适应奠定了坚实基础

Conclusion: 
CL-Splats达到了高效更新并提高了重建质量，为未来的实时3D场景重建任务自适应提供了坚实基础.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21117</guid><pubDate>Fri, 27 Jun 2025 02:36:25 +0800</pubDate></item><item><title>400. cs.CV-YOLO-FDA: 结合层次注意力和细节增强的表面缺陷检测</title><link>https://arxiv.org/pdf/2506.21135</link><description>Background: 
工业场景中的表面缺陷检测至关重要且技术挑战较大，因为缺陷类型广泛、形状和尺寸不规则、细节要求精细以及材料纹理复杂。尽管最近基于AI的检测器取得了进展，但现有方法往往存在冗余特征、细节敏感度有限以及在多尺度条件下的鲁棒性较弱等问题。

Innovation: 
本文提出了一种新颖的YOLO-FDA检测框架，结合了细粒度细节增强和注意力引导特征融合。特别地，采用了BiFPN风格的架构，增强了YOLOv5主干网络中的多尺度特征聚合。引入了一个方向性融合模块（DDFM），在最低层添加了方向不对称卷积来丰富空间细节，并融合最低层与低层特征以增强语义一致性。此外，提出了两种新型注意力融合策略，注意力加权拼接（AC）和跨层注意力融合（CAF），以提高上下文表示并减少特征噪声。

Conclusion: 
在基准数据集上的大量实验表明，YOLO-FDA在不同类型的缺陷和尺度上，无论是准确率还是鲁棒性都优于现有最先进的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21135</guid><pubDate>Fri, 27 Jun 2025 02:36:25 +0800</pubDate></item><item><title>401. cs.CV-学习在极其黑暗环境中看到</title><link>https://arxiv.org/pdf/2506.21132</link><description>Background: 
基于学习的方法已经在低光RAW图像增强方面取得了有希望的进步，但由于缺乏相应数据集，它们在环境 illuminance 降低至 0.0001 勒克斯的极端黑暗场景中的能力尚未得到探索。

Innovation: 
提出了一种配对到配对的数据合成流水线，能够生成在 0.01-0.1 勒克斯、0.001-0.01 勒克斯和 0.0001-0.001 勒克斯三个精确 illuminance 范围下的高质量极低光 RAW 图像，并与高质量 sRGB 参考数据一起组成一个大规模配对数据集 See-in-the-Extremely-Dark，以测试低光 RAW 图像增强方法。此外，提出了一种基于扩散的框架，利用生成能力和固有的去噪特性来恢复来自极低信噪比 RAW 输入的视觉愉悦结果，其中引入了自适应照明校正模块和颜色一致性损失以确保准确的曝光校正和颜色恢复。

Conclusion: 
在提出的 SIED 和公开基准上的广泛实验表明了该方法的有效性。代码和数据集可在指定的网址获取。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21132</guid><pubDate>Fri, 27 Jun 2025 02:36:23 +0800</pubDate></item><item><title>402. cs.CV-推界权衡边界：紧凑而有效的遥感变化检测</title><link>https://arxiv.org/pdf/2506.21109</link><description>Background: 
遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，可以提供及时、准确和大规模的动态景观变化见解。尽管深度学习已经革新了变化检测，现代模型的复杂性和计算需求并没有必然带来显著的准确度提升。本文针对这一点，探讨了更加高效的方法，即保持高准确度同时最大限度减少资源消耗，这对于卫星上的实时处理至关重要。

Innovation: 
本文提出了FlickCD，这是一种通过快速翻转来获得出色结果的轻量级模型。FlickCD引入了增强差异模块（EDM）来放大时间各相之间的重要特征差异，而抑制光照和天气变化等无关变化，从而降低后续变化解码器的计算成本。此外，FlickCD解码器集成了局部-全局融合块，并采用移位窗口自注意力（SWSA）和增强全球自注意力（EGSA）来高效捕捉多尺度语义信息，从而保留粗粒度和细粒度的变化。

Conclusion: 
在四个基准数据集上进行的广泛实验证明，FlickCD减少了超过一个数量级的计算和存储开销，同时达到了最先进的性能或仅产生了小于1%的F1值准确性损失。代码已在公开地址可用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21109</guid><pubDate>Fri, 27 Jun 2025 02:36:21 +0800</pubDate></item><item><title>403. cs.CV-利用自我监督视觉变换器特征增强生成对抗性迁移性</title><link>https://arxiv.org/pdf/2506.21046</link><description>Background: 
深度神经网络的能力来自于从所提供的数据中提取和解释特征。该论文通过利用深度神经网络中的中间特征而不是依赖于硬标签，创作了具有更强通用性的对抗性扰动，从而提升了黑盒迁移性。先前的工作主要使用监督学习中的特征。受到自我监督学习和Transformer架构之间出色协同作用的启发，该论文探讨自我监督ViT表示是否可以提升对抗性迁移性。

Innovation: 
该论文提出了dSVA——一种生成的双自我监督ViT特征攻击，利用对比学习(CL)的全局结构特征和掩码图像建模(MIM)的局部纹理特征，这两个自我监督的ViT范式。设计了一个新的生成训练框架，包括生成器以创建黑盒对抗性示例，并通过利用自我监督ViTs的联合特征和注意机制训练生成器。发现CL和MIM使ViTs能够同时关注不同的特征趋势，在二者结合使用时极大地增强了对抗性泛化能力。通过扰乱自我监督的ViTs中提取的双重深层特征，生成了更出色的黑盒转移能力，甚至超过了现有最佳效果的模型。

Conclusion: 
研究表明，通过扰乱自我监督的ViTs所提取的双重深层特征，可以实现出色的黑盒迁移能力，适用于多种架构的模型，并超越现有最佳实践。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21046</guid><pubDate>Fri, 27 Jun 2025 02:36:20 +0800</pubDate></item><item><title>404. cs.CV-ESMStereo: 提升 ShuffleMixer 位移上采样以实现实时且精确的立体匹配</title><link>https://arxiv.org/pdf/2506.21091</link><description>Background: 
立体匹配已成为现代自主系统中的重要组成部分。基于深度学习的立体匹配模型在提供高准确度的同时实现实时运行仍然是计算视觉领域的重大挑战。在基于成本体的立体匹配领域中，精确的位移估计高度依赖于大规模成本体。然而，大规模的成本体包含了大量冗余信息，并且需要高度计算密集型的聚合模块进行处理和回归，这使得实时性能难以实现。相反，小规模的成本体结合轻量级聚合模块可能为实现实时性能提供一种有前途的途径，但缺乏足够的信息以确保高度准确的位移估计。

Innovation: 
为了解决这一挑战，本文提出了一种增强的 Shuffle Mixer (ESM) 来减轻与小尺度成本体相关的信息损失。ESM 通过将主特征整合到位移上采样单元中来恢复关键细节。它快速从最初的位移估计中提取特征并与图像特征融合。通过混洗和分层拆分特征，然后通过紧凑的特征引导 H 形网络精炼以恢复更详细的空间几何结构。ESM 重点在于具有大感受野和低计算成本的局部上下文连接性，从而实现了实时高精度位移图的重建。ESM 立体匹配方案实现了在高端 GPU 上为 116 FPS，在 AGX Orin 上为 91 FPS 的推断速度，

Conclusion: 
ESM 强调利用紧凑的特征引导 H 形网络恢复更多细节的场景几何结构，同时保持低计算成本和大感受野，从而实现了实时高精度的立体匹配。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21091</guid><pubDate>Fri, 27 Jun 2025 02:36:18 +0800</pubDate></item><item><title>405. cs.CV-IPFormer-VideoLLM: 提升多模态视频理解以应对多场景</title><link>https://arxiv.org/pdf/2506.21116</link><description>Background: 
当前的视频大型语言模型（VideoLLMs）虽然展示了出色的理解能力，但在处理多场景（如不同角度的视频片段或场景变化）时表现不佳。这种情况下，模型容易出现实例身份记忆混乱和关键帧忽视的问题。现有的数据集缺乏多场景注释，这也是模型遇到挑战的原因之一。

Innovation: 
作者提出了一种新的数据集 MultiClip-Bench，包含针对多场景设计的密集描述和指令式的问答对。此外，还提出了一种新的模型 IPFormer-VideoLLM，通过高效的注意力连接器注入实例级特征作为实例提示，以支持跨场景的消息聚合，从而在多场景视频理解上表现出显著提升。

Conclusion: 
提出的新的数据集和模型显著提升了多场景视频的理解能力，并且在各种视频基准测试中表现出了不同的优势。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21116</guid><pubDate>Fri, 27 Jun 2025 02:36:17 +0800</pubDate></item><item><title>406. cs.CV-利用扩散模型提升领域泛化和自适应检测：适应性，泛化和迁移性</title><link>https://arxiv.org/pdf/2506.21042</link><description>Background: 
检测器在训练和测试数据之间存在领域差距时，通常会遭受性能下降。最近的方法通过将扩散模型应用于领域泛化（DG）和适应（DA）任务，但仍然面临高推断成本的问题，并且尚未充分利用扩散模型的能力。现有方法试图解决这些挑战，但尚未完全解决大推理成本的问题，并且在完全利用扩散模型的潜力方面仍有局限性。

Innovation: 
本文提出了一种方法，通过从单步骤扩散过程中提取中间特征来改进特征收集和融合，从而将推断时间减少75%，同时提高源领域性能。通过构建以对象为中心的辅助分支，从带有类别提示的框遮罩图像中提取出强健且领域不变的特征，重点关注对象。通过应用一致性损失对辅助分支和普通的分支进行对齐，平衡适应性和泛化能力，防止过拟合，并提高目标领域性能。在统一框架中，标准检测器通过源领域（针对DG）和未标注目标领域（针对DA）的特征级别和对象级别的对齐被扩散检测器引导，从而提高跨域检测性能。实验结果在三个DA基准和五个DG基准上达到了具有竞争力的结果。在COCO泛化基准上，实验结果展示了在大领域转移和低数据场景下的显著优势和高效性。本文展示了将扩散模型应用于领域泛化和自适应检测任务的优越性，并为跨多样化领域的视觉感知任务提供了有价值的见解。

Conclusion: 
本文提出的方法在三个DA基准和五个DG基准上达到了具有竞争力的结果，在大领域转移和低数据场景下显示了显著的优势。本文的工作证明了将扩散模型应用于领域泛化和自适应检测任务的优越性，并为进一步研究各类视觉感知任务提供了有价值的见解。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21042</guid><pubDate>Fri, 27 Jun 2025 02:36:13 +0800</pubDate></item><item><title>407. cs.CV-Instella-T2I: 推动一维离散潜在空间图像生成的极限</title><link>https://arxiv.org/pdf/2506.21022</link><description>Background: 
图像标记化在减少建模高分辨率图像的计算需求、显著提高图像和多模态理解和生成效率方面起着关键作用。近期，一维潜在空间的发展通过消除二维网格结构的需求，显著减少了所需的标记数量，提升了模型效率。本文在此基础上，进一步发展了一种紧凑的离散图像表示方法——引入了一维二进制图像潜在变量。这种方法通过将每个图像表示为二进制向量序列，而非传统的独热码本标记，从而在保持一维潜在变量紧凑性的同时保留了高分辨率的细节。本文提出的该方法使得文本生成图像模型能在进行扩散和自回归生成时仅用128个离散标记便能支持1024x1024分辨率的图像，相比传统的VQ-VAEs减少了标记数量多达32倍。1D二进制潜在空间配合简单的模型架构显著提升了训练速度和推断速度。文本生成图像模型能在单个配备8块AMD MI300X GPU的GPU节点上实现4096的全局批量大小，并且能在200个GPU天内完成训练。本文模型在无需使用任何私人训练数据或事后调整的情况下，与现代图像生成模型性能相当，提供了一种可扩展且高效的替代传统标记化方法的选择.

Innovation: 
这篇文章创新地引入了一维二进制图像潜在变量，通过将每个图像表示为二进制向量序列，而不是传统的独热码本标记，从而在保持一维潜在变量紧凑性的同时保留了高分辨率的细节。该方法使得文本生成图像模型能够在较少的离散标记下实现高分辨率图像的生成，相比传统的VQ-VAEs减少了标记数量多达32倍。结合简单的模型架构，这种方法显著提升了训练和推断的速度。同时，该方法不依赖任何私有训练数据或事后调整，从而提供了一种高效且可扩展的替代传统标记化方法的选择。

Conclusion: 
本文提出了一种基于一维二进制潜在变量的文本生成图像模型，能够在保持高分辨率细节的同时使用更少的离散标记，且训练和推断速度更快。该模型在无需使用任何私人训练数据或事后调整的情况下，相对于现代图像生成模型提供了高效且可扩展的解决方案。这种方法有望在图像生成领域进一步提升效率和性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21022</guid><pubDate>Fri, 27 Jun 2025 02:36:13 +0800</pubDate></item><item><title>408. cs.CV-PoseMaster: 从单张图片生成任意姿态的3D角色</title><link>https://arxiv.org/pdf/2506.21076</link><description>Background: 
3D角色在日常娱乐中扮演着重要角色。现有的基于图像的方法通过使用两个分开的模型来实现姿势标准化和A姿势角色的3D重建。但是，在姿势标准化阶段，这些方法容易因自遮挡和视角问题生成失真和降级的图像，这影响了后续重建过程的几何质量。

Innovation: 
我们提出了一种端到端可控的3D角色生成框架PoseMaster。该框架统一了姿态变换和3D角色生成，并通过利用动画角色骨骼作为姿势条件来实现精确的任意姿态控制。此外，我们在训练过程中随机消除姿态条件和图像条件，以提高姿态控制的有效性和泛化能力。同时，我们构建了一个由真实人物动画数据衍生的高质量姿态控制数据集，使模型能够学习骨骼和蒙皮权重之间的隐含关系。实验结果显示，PoseMaster在定性和定量评估方面均超过了当前最先进的技术，同时展示了其对任意姿态的精确控制能力。

Conclusion: 
实验结果表明，PoseMaster在A姿势角色生成方面优于当前最先进的技术，同时展示了其强大的能力以实现对任意姿态的精确控制。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21076</guid><pubDate>Fri, 27 Jun 2025 02:36:12 +0800</pubDate></item><item><title>409. cs.CV-SAMURAI: 形状感知的多模态检索用于3D物体识别</title><link>https://arxiv.org/pdf/2506.21056</link><description>Background: 
在复杂室内环境中的仅使用遮蔽2D图像和自然语言描述检索3D物体是一个显著的挑战。ROOMELSA挑战限制了对完整3D场景上下文的访问，使对物体外观、几何形状和语义的理解更加复杂。这些问题在视角失真、无纹理的遮蔽区域、模糊的语言提示和嘈杂的分割掩膜下进一步加剧。

Innovation: 
我们提出了SAMURAI：形状感知的多模态检索方法以识别3D物体。SAMURAI将基于CLIP的语义匹配与基于二值轮廓的遮蔽区域引导再排序结合，同时采用稳健的多数投票策略。专门的预处理管道通过提取最大的连通分量和去除背景噪声来增强掩膜质量。该混合检索框架结合了语言和形状线索，实现了在ROOMELSA私有测试集上的竞争力表现在多模态检索方面。这项结果强调了在开放世界3D物体检索中结合形状先验与语言理解的重要性。

Conclusion: 
实验结果表明，SAMURAI通过结合形状先验和语言理解，在开放式3D物体检索方面表现出色。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21056</guid><pubDate>Fri, 27 Jun 2025 02:36:11 +0800</pubDate></item><item><title>410. cs.CV-通过指导与调度提高基于扩散的图像编辑保真度</title><link>https://arxiv.org/pdf/2506.21045</link><description>Background: 
文本引导的扩散模型已成为高质量图像合成的必备工具，能够实现动态图像编辑。图像编辑的两个关键方面是可编辑性和保真度，前者决定了修改的程度，后者反映了未修改部分的保存程度。然而，达到最优结果具有挑战性，因为提升可编辑性和保真度之间存在固有的权衡。

Innovation: 
提出了一种名为Faithfulness Guidance and Scheduling (FGS)的方法，通过增强保真度来最小化对可编辑性的影响。FGS结合了保真度指导策略以加强输入图像信息的保存，并引入了一种调度策略以解决可编辑性和保真度之间的对齐问题。实验结果表明，FGS在保持可编辑性的同时实现了更高的保真度，并且兼容多种编辑方法，能够在各种任务中实现精准、高质量的图像编辑。

Conclusion: 
FGS方法通过指导与调度策略提高了扩散模型在图像编辑中的保真度，并保持了较高的可编辑性，实现了精确、高质量的图像编辑效果，适用于多种编辑任务。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21045</guid><pubDate>Fri, 27 Jun 2025 02:36:08 +0800</pubDate></item><item><title>411. cs.CV-用户在环视图采样与错误峰化可视化</title><link>https://arxiv.org/pdf/2506.21009</link><description>Background: 
增强现实（AR）提供了可视化缺失视角样本的方法，用于新视角合成。现有方法通过AR显示进行3D标注，要求用户对准AR显示拍摄图像。然而，这种数据收集任务对用户来说是耗费心理精力的，并且由于理想的但限制性很强的采样理论，采集区域被限制在预先定义的小区域内。为了减轻用户的3D标注负担并扩大场景探索范围，本文提出使用局部重建的光场来可视化需要通过插入新视角移除的错误。这些结果表明，在我们的移动视图合成系统中，错误峰化可视化方法对用户更具侵入性，降低了最终结果的失望感，并且在较少视角样本下仍然令人满意。此外，本文还表明本方法可以为大型场景的辐射场重建做出贡献，例如3D高斯运算符应用.

Innovation: 
本文创新地提出了在进行视图合成时使用局部重建的光场来可视化需要通过插入新视角移除的错误，替代了以往依赖用户进行3D标注采集的方法。这种方法减轻了用户的心理负担，扩大了场景的探索范围，并提升了最终结果的质量与用户满意度，尤其适用于移动设备的视图合成系统中。此外，这种方法还可以为大型场景的辐射场重建做出贡献，如3D高斯运算符的应用.

Conclusion: 
实验结果表明，相比于传统方法，错误峰化可视化方法在提供较少视角样本的情况下，对用户更加友好，降低了失望感，同时适用于复杂场景的视图合成和辐射场重建。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21009</guid><pubDate>Fri, 27 Jun 2025 02:36:07 +0800</pubDate></item><item><title>412. cs.CV-文档图像中的无类别兴趣区域匹配</title><link>https://arxiv.org/pdf/2506.21055</link><description>Background: 
文档理解和分析因广泛应用而受到广泛关注。然而，现有的文档分析解决方案，如文档布局分析和关键信息提取，仅适用于固定类别定义和粒度，无法实现用户定制的灵活性应用。因此，本文定义了名为“无类别兴趣区域匹配”（简称“RoI-Matching”）的新任务，旨在以灵活、高效、多粒度和开放集的方式匹配定制的区域。

Innovation: 
本文构建了一个基准RoI-Matching-Bench，设置了三种难度等级，提议使用宏观和微观指标进行评估。并且提出了一种新的框架RoI-Matcher，使用暹罗网络提取参考和目标域的多层特征，并使用交叉注意力层整合和对齐不同领域的相似语义。实验表明，本方法流程简单，在RoI-Matching-Bench上有效，并作为进一步研究的基础。

Conclusion: 
我们的方法在RoI-Matching-Bench上具有有效性，并作为进一步研究的基础。代码可在提供的链接中获取。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21055</guid><pubDate>Fri, 27 Jun 2025 02:36:05 +0800</pubDate></item><item><title>413. cs.CV-LASFNet: 一种轻量级注意力引导自调制特征融合网络，用于多模态目标检测</title><link>https://arxiv.org/pdf/2506.21018</link><description>Background: 
有效的深特征提取对于多模态目标检测至关重要。然而，先前的研究通常涉及复杂的训练过程，通过堆叠多个特征级融合单元来整合模态特定特征，导致了大量的计算开销。

Innovation: 
提出了一个使用单个特征级融合单元的新融合检测基线，简化了训练过程。提出了一个轻量级注意力引导自调制特征融合网络（LASFNet），该网络引入了一个新颖的注意力引导自调制特征融合（ASFF）模块，该模块基于不同模态的注意力信息，在全局和局部层面自适应调整融合特征的响应，从而促进全面和丰富的特征生成。此外，在LASFNet的颈部设计了一个轻量级特征注意力转换模块（FATM），以增强对融合特征的聚焦并最小化信息损失。

Conclusion: 
在三个代表性数据集上的大量实验表明，与最先进的方法相比，我们的方法在保持性能的同时显著降低了参数数量和计算成本，分别减少了90%和85%，同时提高了检测精度（mAP）1%-3%。代码将在该链接公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21018</guid><pubDate>Fri, 27 Jun 2025 02:36:01 +0800</pubDate></item><item><title>414. cs.CV-多模态提示对齐 facial 表情识别</title><link>https://arxiv.org/pdf/2506.21017</link><description>Background: 
提示学习已被广泛用于高效地适应视觉语言模型（如CLIP）以完成各种下游任务。尽管取得了成功，但当前基于VLM的表情识别（FER）方法在捕捉精细的文字-视觉关系方面存在挑战，这些关系对于区分面部表情的微妙差异至关重要。因此，本文探讨了解决这一挑战的方法，提出了一个细粒度语义引导的多模态提示对齐框架（MPA-FER），以提高表情识别的准确性和可解释性。该框架利用大规模语言模型（如ChatGPT）生成详细的面部表情描述，通过最小化软提示与硬提示之间的特征差异，将基于LLM的外部知识注入到软提示中，从而提高视觉特征表示的质量。

Innovation: 
本文创新性地提出了一种多粒度硬提示生成策略，利用大规模语言模型（如ChatGPT）生成详细的面部表情描述。此外，文中还提出了一种跨模态全局-局部对齐模块，专注于特征相关的面部特征，进一步增强了文本和视觉特征的对齐。通过对预训练的CLIP模型进行原型引导的视觉特征对齐，确保了冻结的图像编码器生成的提示视觉特征能够紧密地与类别特异性原型对齐，从而保持了预训练模型的优点并减少了计算成本。

Conclusion: 
通过大量实验表明，本文提出的框架在三个表情识别基准数据集上表现优于现有方法，同时保持了预训练模型的优点并减少了计算成本。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21017</guid><pubDate>Fri, 27 Jun 2025 02:36:00 +0800</pubDate></item><item><title>415. cs.CV-DidSee: 无材质依赖的扩散式深度完成方法及其在机器人感知与操作中的应用</title><link>https://arxiv.org/pdf/2506.21034</link><description>Background: 
商业RGB-D相机常为非兰伯特定反射物体生成噪声较大且不完整的深度图。传统深度完成方法由于训练数据多样性不足，难以泛化。近期研究通过利用预训练的文本到图像的扩散模型的视觉先验，在密集预测任务中提升了泛化能力。然而，我们在vanilla扩散框架中发现的训练推理不匹配带来的偏差，以及非兰伯特定区域缺乏显著视觉特征，进一步阻碍了精准预测。因此，为解决问题，我们提出了DidSee，一种基于扩散的方法，用于非兰伯特定反射物体的深度完成。

Innovation: 
1. 引入缩放噪声调度器，强制零终端信噪比，消除信号泄漏偏差。n2. 设计去噪声单步训练方案，减少由曝光偏差引起的累计误差，并通过特定任务损失优化模型。n3. 结合语义增强器，实现深度完成和语义分割的联合，能够区分物体和背景，生成精确的深度图。

Conclusion: 
DidSee在多项基准测试中达到了最先进的性能，展示了在现实世界中的稳健泛化能力，并有效提高了诸如类别级别的姿态估计和机器人操作在内的下游任务性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21034</guid><pubDate>Fri, 27 Jun 2025 02:36:00 +0800</pubDate></item><item><title>416. cs.CV-HybridQ: 混合经典-量子生成对抗网络在皮肤疾病图像生成中的应用</title><link>https://arxiv.org/pdf/2506.21015</link><description>Background: 
机器学习辅助诊断在皮肤疾病检测中受到重视，但训练有效模型需要大量高质量数据。皮肤疾病数据集常存在类别不平衡、隐私问题和对象偏差等问题，使得数据增强变得尤为重要。尽管经典生成模型被广泛应用，但它们需要大量的计算资源和较长的训练时间。量子计算提供了一种有前景的替代方案，但现有的基于量子图像生成方法只能生成灰度低质量图像。我们的工作通过一个新颖的经典-量子潜在空间融合技术，克服了这一限制，并引入了首个能生成彩色医学图像的经典-量子生成对抗网络（GAN）。该模型在图像生成质量和分类性能增强方面优于经典深层卷积GAN和现有混合经典-量子GAN，并且参数量减少超过25倍，训练周期减少超过10倍，这表明随着量子硬件的进步，量子图像生成具有光明的前景。此外，我们在真实的IBM量子机器上展示了我们模型的稳健性能，即使有硬件噪声，也能表现出良好的性能。

Innovation: 
研究通过经典-量子潜在空间融合技术，提出了首个能生成彩色医学图像的经典-量子GAN。该模型不仅在图像生成质量和分类性能上表现优越，还具有更少的参数和更短的训练周期。

Conclusion: 
研究初步证实了基于量子的图像生成在皮肤疾病数据增强中的潜力，并展示了在真实量子计算机上的稳健性能，为未来量子计算在医学图像生成领域的应用奠定了基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21015</guid><pubDate>Fri, 27 Jun 2025 02:36:00 +0800</pubDate></item><item><title>417. cs.CV-通过大型跨模态模型弥合视频质量评分与解释差距</title><link>https://arxiv.org/pdf/2506.21011</link><description>Background: 
传统的视频质量评估（VQA）方法生成一个数值分数来判断视频的视觉保真度和清晰度，但分数无法全面描述视频的质量维度，限制了其实用性。以往的工作主要集中在图像领域，其数据生成过程依赖于人力的质量注释和专有系统，这限制了数据的规模和有效性。为了解决这些问题，本文提出了评分指令生成（SIG）流水线以及基于SIG的Score2Instruct（S2I）数据集和评估基准S2I-Bench，以提升视频跨模态模型的质量评分和解释能力。

Innovation: 
1. 提出了SIG流水线，包括评分和指令生成两个步骤，以更好地描述视频的质量维度；n2. 使用SIG生成S2I数据集，包含超过32万条多样化的指令-响应对，为指令调优提供了数据基础；n3. 设计了渐进式调优策略，充分利用S2I数据集提升视频跨模态模型的质量评估与解释能力；n4. 建立了S2I-Bench基准，包含400个开放性问题，更好地评估视频跨模态模型的质量解释能力；n5. 实验结果显示，该方法能够提升多种视频跨模态模型的质量评分和解释能力，具有实际应用价值。

Conclusion: 
本文提出了一种新的SIG方法及基于SIG的S2I数据集和S2I-Bench基准，解决了传统VQA方法无法全面描述视频质量维度的问题，提升了视频跨模态模型的质量评分与解释能力，为未来的跨模态视频分析提供了新的方法和数据支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21011</guid><pubDate>Fri, 27 Jun 2025 02:35:55 +0800</pubDate></item><item><title>418. cs.CV-逆场景文字删除</title><link>https://arxiv.org/pdf/2506.21002</link><description>Background: 
场景文字去除（STR）旨在从图像中删除文字元素。最初的目的是从自然场景图像中去除敏感或不必要的文字，但现在也被应用于设计文字图像。STR通常检测文本区域，然后填充它们。尽管STR通过神经网络和合成数据得到了改进，但滥用的风险也相应增加。论文研究了逆场景文字去除（ISTR），该技术分析STR处理过的图像，并专注于二元分类（检测图像是否经过STR处理）和定位被去除的文字区域。实验表明，这些任务可以达到高精度，能够检测潜在的滥用并改进STR。此外，论文还尝试通过训练文字识别器来恢复被删除的文字内容，理解其难度。

Innovation: 
逆场景文字删除（ISTR）技术可以分析经过STR处理的图像，专注于二元分类和局部化被去除的文字区域。并且尝试通过训练文字识别器来恢复被删除的文字内容，理解其难度。这项研究提高了STR的检测准确性，并发现潜在的滥用情况。

Conclusion: 
实验结果显示，ISTR技术能够实现高精度的二元分类和文字区域定位，可以检测到图像是否经过STR处理，预防滥用风险。通过训练文字识别器恢复被删除的文字内容，这一方法能够提高STR的效果和识别难度。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21002</guid><pubDate>Fri, 27 Jun 2025 02:35:54 +0800</pubDate></item><item><title>419. cs.CV-FedSC: 基于语义感知协作的联邦学习</title><link>https://arxiv.org/pdf/2506.21012</link><description>Background: 
联邦学习（FL）旨在通过跨客户端协作训练模型，而不共享数据来保护隐私。然而，一个主要挑战是数据异质性问题，即多个客户端可能存在偏向的数据标签偏好。现有的FL方法大多侧重于局部（如正则化本地模型）或全局（如调整全局模型）处理数据异质性，往往忽略了每个客户端内在的语义信息。因此，探索在处理数据异质性时利用客户端内语义上有意义的知识成为一项重要的研究方面。

Innovation: 
该论文提出了一种名为FedSC（Federated Learning with Semantic-Aware Collaboration）的方法，用于跨越异质客户端捕捉客户端特定和类相关的知识。FedSC的核心思想是在语义层次上构建关系原型和一致原型，以提供基于原型的协作方式，为各类基础知识及稳定收敛信号提供支持。通过引入一个跨对比学习策略和一致性原型构建方式，FedSC不仅能够使实例级嵌入更接近语义相同的关系原型，远离不同类别，还能对局部模型的优化范围进行约束。此外，还提供了FedSC的理论分析，以确保收敛性保证。实验结果表明FedSC的有效性和关键组件的效率。

Conclusion: 
实验结果在多种具有挑战性的场景中展示了FedSC的有效性和关键组件的效率，验证了FedSC在处理数据异质性方面的应用潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21012</guid><pubDate>Fri, 27 Jun 2025 02:35:53 +0800</pubDate></item><item><title>420. cs.CV-无需训练的扩散生成条件感知面部老化树的衰老多元化宇宙</title><link>https://arxiv.org/pdf/2506.21008</link><description>Background: 
现有的老化方法通常将老化视为单个确定性的路径，而忽略了环境、健康和生活方式等外部因素对老化的影响。这导致现有模型在身份保存、老化真实性和条件对齐方面表现不佳，难以涵盖实际老化过程的多样性和复杂性。因此，迫切需要一种能够生成多种可能的老化轨迹并考虑外部因素的方法，来改进当前的老化模型效果和实用性，进一步推动数字叙事、健康教育和个人化可视化等领域的发展。

Innovation: 
本文提出了基于无需训练的扩散方法的‘衰老多元化宇宙’框架，该方法能够从单张图像生成多种可能的老化轨迹，并让每条轨迹都可以通过环境、健康和生活方式等因素进行条件化。关键创新点在于引入注意力混合来调节编辑强度，以及模拟老化正则化策略以稳定编辑效果。与现有编辑和年龄进展模型相比，该方法在身份保留、老化真实性和条件对齐方面表现出更优的状态。

Conclusion: 
通过将老化过程转变为多维、可控制和可解释的过程，我们的方法为数字叙事、健康教育和个人化可视化等提供了新的创意和技术途径，展现出卓越的性能。未来我们可以进一步探索其在这些领域的实际应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21008</guid><pubDate>Fri, 27 Jun 2025 02:35:48 +0800</pubDate></item><item><title>421. cs.CV-使用SAM结合前向-前向对比学习的乳腺癌肿瘤切除边缘检测</title><link>https://arxiv.org/pdf/2506.21006</link><description>Background: 
乳腺癌肿瘤完全切除并在活检标本中获得阴性边缘是减少乳腺癌复发的关键。然而，当前的二维标本放射学检查（SR）方法的准确度有限，导致约四分之一的患者需要额外的手术。因此，研究人员提出了结合Segment Anything Model (SAM) 和前向-前向对比学习（FFCL）的新型深度学习框架，以提高边缘评估的准确性和速度，从而降低再手术率并改善乳腺癌治疗效果。

Innovation: 
该研究提出了一种新的深度学习框架，结合了Segment Anything Model (SAM) 和前向-前向对比学习（FFCL）。首先通过标注放射学检查（SR）图像来建立局部和全局对比学习的预训练模型，进一步重建粗略的二进制掩模以指导SAM进行精确的肿瘤边缘分割。实验结果显示，这种方法在边缘分类中实现了AUC为0.8455，并且在Dice相似性上比基线模型提高了27.4%，同时将推理时间缩短至每张图像47毫秒。这项工作显著提高了术中边缘评估的速度和准确性，为减少再手术率和改善乳腺癌治疗结果提供了强大的潜在应用前景。

Conclusion: 
该框架成功地提高了乳腺癌肿瘤切除边缘和边缘分类的准确性和速度，减少了额外手术的需求，有望提高乳腺癌治疗的整体效果。该工作的代码已公开，供进一步研究和应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21006</guid><pubDate>Fri, 27 Jun 2025 02:35:47 +0800</pubDate></item><item><title>422. cs.CV-DBMovi-GS: 动态的模糊单目视频视图合成功流（通过稀疏控制的高斯点布）</title><link>https://arxiv.org/pdf/2506.20998</link><description>Background: 
新型视角合成是一种从未见视角生成场景的任务；然而，从模糊的单目视频中合成动态场景仍旧是一个未解决的挑战。现有的新型视角合成方法受限于对高分辨率图像或静态几何和刚体场景先验的强烈假设，导致在有动态物体和相机运动的现实环境中不具备鲁棒性，容易导致视角合成不稳且视觉质量下降。因此，迫切需要一种新的方法来应对这一挑战，该方法能够有效处理动态模糊场景中的视角合成，以提升合成质量和鲁棒性。

Innovation: 
我们提出了一种名为基于稀疏控制的高斯点布的动态模糊单目视频视角合成方法（DBMovi-GS），专门设计用于从模糊的单目视频中合成动态视角。该模型生成密集的3D高斯模型，能够从模糊视频中恢复锐度并重建受动态运动变化影响的场景详细3D几何结构。DBMovi-GS 方法在动态模糊场景的新型视角合成中表现出了稳健性，并为模糊单目视频输入的现实新型视角合成设定了新的基准线。

Conclusion: 
我们的模型在动态模糊场景的视角合成中实现了稳健的表现，并且在模糊单目视频输入的真实新型视角合成方面设立了新的基准线。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20998</guid><pubDate>Fri, 27 Jun 2025 02:35:46 +0800</pubDate></item><item><title>423. cs.CV-通过负音频指导逐步视频到音频合成</title><link>https://arxiv.org/pdf/2506.20995</link><description>Background: 
当前的视频到音频生成方法主要是一次性生成完整的音频轨道，且通常需要大量配对的数据集进行训练，这在实际操作中较为困难和耗时。而本研究旨在提出一种新方法，该方法能够逐步生成每个与视频中特定声音事件相对应的单独音频轨道，模仿传统录音工作流程，旨在全面捕捉由给定视频诱导的所有声音事件。这种方法基于先前组合生成框架中的概念否定理念，期望生成多个具有语义差异的音频轨道，从而提高合成音频的质量。

Innovation: 
该研究的创新点在于提出了一种逐步的视频到音频生成方法，每次生成一个与视频中特定声音事件相对应的单独音频轨道，并通过引入基于预训练视频到音频模型的训练框架，无需专用配对数据集即可实现训练，从而提高了数据利用的灵活性。这种方法的设计灵感来源于负音频指导的原则，并且通过这种设计使得生成的音频具有更高的质量与独特性。

Conclusion: 
实验结果表明，本方法能够为单个输入视频生成多个语义上不同的音频轨道，相比于现有基线方法，这种合成音频的质量更高。本研究为视频到音频生成技术提供了一种新的思路和方法，具有显著的技术进步和应用前景。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20995</guid><pubDate>Fri, 27 Jun 2025 02:35:45 +0800</pubDate></item><item><title>424. cs.CV-TSDASeg: 一种用于交互式点云分割的两阶段直接对齐模型</title><link>https://arxiv.org/pdf/2506.20991</link><description>Background: 
随着3D视觉语言模型（VLMs）的快速进步，人们对其在交互式点云处理任务中的应用产生了极大兴趣，尤其在实际应用中。然而，现有的方法在点级任务，如分割上表现不佳，这是因为缺乏直接的3D-文本对齐，限制了其将局部3D特征与文本上下文联系的能力。

Innovation: 
为了解决这个问题，我们提出了TSDASeg，这是一种两阶段模型，结合了直接跨模态对齐模块和记忆模块，专门用于交互式点云分割。引入了直接跨模态对齐模块，以明确地在3D点云和文本/2D图像数据之间建立对齐。在记忆模块中，通过多个专门的记忆库分别存储文本特征、视觉特征及其跨模态对应映射。这些记忆库通过自注意力和跨注意力机制动态利用，根据先前存储的数据更新场景特定特征，有效解决了交互分割结果在不同场景中的不一致性问题。

Conclusion: 
在多个3D指令、参考和语义分割数据集上的实验表明，所提出的方法达到了最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20991</guid><pubDate>Fri, 27 Jun 2025 02:35:44 +0800</pubDate></item><item><title>425. cs.CV-重新考虑用稀疏信号进行姿态导向的文本到图像生成</title><link>https://arxiv.org/pdf/2506.20983</link><description>Background: 
近年来，密集信号（如深度、DensePose）因其提供详细的空间指导而成为姿态导向的文本到图像生成的首选，但这些密集信号带来了编辑难度大和与文本提示潜在不一致的问题。

Innovation: 
本文提出了一个新颖的Spatial-Pose ControlNet (SP-Ctrl)，将可学习的空间表示引入稀疏信号，增强关键点嵌入的区分能力和表达力，并引入关键点概念学习以提高姿态对齐。实验结果表明，SP-Ctrl在稀疏姿态导向的文本到图像生成方法中表现优异，并且在多种物种的生成任务中显示出了多样性和跨物种生成的潜力。

Conclusion: 
我们的方法在动物和人体中心的图像生成任务中，在基于稀疏姿态的生成方法下优于最近的基于空间控制的文本到图像生成方法，并且甚至获得了与使用密集信号方法相当的性能。此外，SP-Ctrl在通过稀疏信号进行多样和跨物种生成中显示出了显著的能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20983</guid><pubDate>Fri, 27 Jun 2025 02:35:43 +0800</pubDate></item><item><title>426. cs.CV-VisionGuard: 协同框架用于检测头盔违规</title><link>https://arxiv.org/pdf/2506.21005</link><description>Background: 
强制要求骑摩托车佩戴头盔是提升道路安全和确保交通管理系统效果的重要举措。然而，自动检测头盔违规行为面临着显著挑战，如环境变化、摄像头角度和数据不一致等因素，这些因素妨碍了对摩托车和骑手的可靠检测，并破坏了对象分类的一致性。

Innovation: 
为了应对这些挑战，本文提出了一种名为VisionGuard的协同多阶段框架，该框架旨在克服帧级检测器的局限性，特别是在类别不平衡和标注不一致的情况下。VisionGuard集成了两个关键模块：自适应标签模块和上下文扩展器模块。自适应标签模块是一种基于跟踪的精炼技术，通过利用跟踪算法为每个帧分配持久标签并纠正分类错误，增强分类一致性。上下文扩展器模块通过生成具有适当置信度评分的虚拟边界框来提高稀有类别的召回率，有效解决了数据不平衡的影响。

Conclusion: 
试验结果表明，VisionGuard相比基础检测器的总体mAP提高3.1%，展示了其有效性，并具备在交通监控系统中实际部署的潜力，从而促进安全和法规遵从。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21005</guid><pubDate>Fri, 27 Jun 2025 02:35:42 +0800</pubDate></item><item><title>427. cs.CV-3D场景-相机表示及其联合相机光度优化</title><link>https://arxiv.org/pdf/2506.20979</link><description>Background: 
多视角图像场景重建是计算机视觉中的关键任务，具有广泛的应用。然而，相机成像过程中的固有光度失真会显著降低图像质量。如果不考虑这些失真，3D场景重建可能意外地包含与场景无关的错误信息，从而降低恢复的场景质量。

Innovation: 
论文提出了一个新型的3D场景-相机表示，结合了相机的联合光度优化。通过引入内部和外部光模型，提出了完整的光度模型及其对应的相机表示。在优化相机表示的参数的同时，该方法有效分离了与场景无关的信息，并引入深度正则化以防止3D场景重建拟合无关信息。相机模型作为映射过程的一部分，该方法构建了包含场景辐射场和相机光度模型的完整映射。实验结果表明，在成像退化条件下（如畸变和污点），该方法能实现高质量的3D场景表示。

Conclusion: 
实验结果证明，该方法即使在图像退化的情况下（如畸变和污点）也能实现高质的3D场景表示。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20979</guid><pubDate>Fri, 27 Jun 2025 02:35:40 +0800</pubDate></item><item><title>428. cs.CV-EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning</title><link>https://arxiv.org/pdf/2506.20986</link><description>Background: 
Compositional Zero-Shot Learning (CZSL)旨在通过学习基础概念来识别未知的状态-对象对。现有的CZSL方法通常通过简单的组成-原型映射来提取基础特征，这在可划分为不同语义子集的个体群体中并不理想。此外，全对一的跨模态基础特征匹配忽略了相同状态或对象内的组成差异，限制了细粒度的图像-组成对齐。

Innovation: 
本文提出了EVA，一种Mixture-of-Experts Semantic Variant Alignment框架。EVA引入了领域专家适应，利用多个专家实现分词感知学习并构建高质量的基础特征表示。此外，为了实现精确的组成泛化，EVA进一步提出了语义变异对齐，以选择语义相关的表示来进行图像-基础特征匹配。

Conclusion: 
我们的方法在两个封闭和开放世界设置中的三个流行基准测试中显著优于其他最先进的CZSL方法，这证明了提出的见解的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20986</guid><pubDate>Fri, 27 Jun 2025 02:35:37 +0800</pubDate></item><item><title>429. cs.CV-AIR-VIEW：用于航空天气可见度估计的图像库，一个数据集和基准</title><link>https://arxiv.org/pdf/2506.20939</link><description>Background: 
航空天气中，利用机器学习预测能见度是一个日益增长的研究领域，旨在提供比传统昂贵的气象传感器更廉价的替代方案。然而，在大气能见度估计方面，公开可用的标注了能见度数据的、口径适用于航空的、来源多样、规模足够用于监督学习的数据集却很少见。本文介绍了一个新的数据集，该数据集代表了一年多的数据采集计划的成果，这些图像来自FAA天气监控摄像头网络，适用于该目的。此外，该研究还对三种常用方法和一个通用基准进行了基准测试，这些方法和基准是在包括一个内部数据集和其他三个公开数据集上进行训练和测试，结果与最近批准的ASTM标准进行比较。

Innovation: 
介绍了用于航空天气能见度估计的新数据集，该数据集包含了来自FAA天气监控摄像头网络的一年多的数据采集，对几种常用方法进行了基准测试，并结合了新的高价值数据集与其他公开数据集进行性能比较。

Conclusion: 
本文展示了航空气象图像库AIR-VIEW，包括一个收集自FAA天气监控摄像头的数据集，以及对三种常用方法和一个通用基准的比较实验结果，提供了能见度估计的基准参考，有助于提高航空气象预测的精度与可用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20939</guid><pubDate>Fri, 27 Jun 2025 02:35:35 +0800</pubDate></item><item><title>430. cs.CV-风格对齐图像合成在细胞病理学中稳健检测异常细胞的应用</title><link>https://arxiv.org/pdf/2506.21001</link><description>Background: 
细胞病理学中的细胞检测面临诸如高质量标注不足、数据分布长尾化以及不同染色风格不一致等挑战，这些因素对训练能够稳健检测异常细胞的神经网络产生了显著障碍。因此，需要一种方法来增强检测模型的有效性和稳健性，以克服这些挑战。

Innovation: 
该论文提出了一种风格对齐图像合成（SAIC）方法，通过合成高保真和保留风格的病理图像来增强检测模型的有效性和稳健性。这一方法首先基于属性指导选择合适的异常细胞候选，接着使用高频特征重构实现异常细胞和病理背景的风格对齐和高保真合成，并引入大规模视觉语言模型来筛选高质量的合成图像，从而提升了尾部类别和风格下的检测性能，并展示了SAIC在临床应用中的普适性和实用性。

Conclusion: 
实验结果显示，这些合成图像的加入有效提升了异常细胞检测模型在尾部类别和风格下的性能和稳健性，从而整体提升了检测性能。综合质量评估进一步证实了SAIC在临床应用场景中的普适性和实用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21001</guid><pubDate>Fri, 27 Jun 2025 02:35:33 +0800</pubDate></item><item><title>431. cs.CV-使用自然语言在病理图像中分割一切</title><link>https://arxiv.org/pdf/2506.20988</link><description>Background: 
病理图像分割对于计算病理学中的癌症诊断和预后分析至关重要。然而，当前的方法在临床应用中面临主要挑战，包括标注数据有限和类别定义受限。因此，需要一种既能应对大量数据需求又能提供广泛适用性的方法来解决这些问题，以提高病理图像分析的准确性与临床适用性。

Innovation: 
本文提出了PathSegmentor，这是一种专门为病理图像设计的第一种基于文本提示的分割基础模型。同时，引入了PathSeg，它是目前最大和最全面的病理分割数据集，涵盖了17个公共来源，包含275k张图像-掩码-标签三元组，涵盖160个不同的类别。PathSegmentor通过自然语言提示实现了语义分割，消除了需要手动输入空间信息的需求，提升了分割的便利性与精度，并显著优于现有模型，展示了在分割复杂结构和泛化到外部数据方面的强大鲁棒性。此外，PathSegmentor的输出提高了诊断模型的可解释性，促进了影像生物标志物的发现，为临床决策提供了证据支持。

Conclusion: 
这项工作推进了可解释人工智能在精准肿瘤学中的发展。PathSegmentor模型在精确度和广泛的适用性方面表现出色，并且其架构紧凑，超越了现有的模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20988</guid><pubDate>Fri, 27 Jun 2025 02:35:31 +0800</pubDate></item><item><title>432. cs.CV-从摇篮到拐杖：一种高保真生命周期面部老化两步框架</title><link>https://arxiv.org/pdf/2506.20977</link><description>Background: 
面部老化是计算机视觉中的关键任务，应用范围广泛，从娱乐到医疗。现有方法在实现整个生命阶段的现实和无缝转换时遇到困难，特别是在处理大年龄跨度或极端头部姿态时。核心挑战在于平衡年龄准确性与身份保真，这是所谓的Age-ID权衡。大多数先前的方法要么注重年龄变换以牺牲身份一致性，要么反之亦然。

Innovation: 
本文提出了一种基于少步骤文本到图像（T2I）扩散模型的两步面部老化框架，称为Cradle2Cane。该框架的创新点包括：首阶段通过引入自适应噪声注入（AdaNI）机制解决年龄准确性问题，该机制基于年龄和性别等文本描述；次阶段通过使用两种身份感知嵌入（IDEmb）：SVR-ArcFace和Rotate-CLIP增强身份保真度，同时保持年龄特异性特征，并对第一阶段的变换图像进行去噪处理，确保更高的身份一致性同时不牺牲年龄准确性。两个阶段以端到端的方式联合训练。

Conclusion: 
广泛的实验在CelebA-HQ测试数据集上进行，并通过Face++和Qwen-VL协议评估。结果显示，Cradle2Cane在年龄准确性和身份一致性方面都优于现有的面部老化方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20977</guid><pubDate>Fri, 27 Jun 2025 02:35:24 +0800</pubDate></item><item><title>433. cs.CV-FaSTA∗：具有子例程挖掘的快速-缓慢工具路径代理以实现高效的多一步图像编辑</title><link>https://arxiv.org/pdf/2506.20911</link><description>Background: 
该论文提出了一种为了处理复杂多步图像编辑任务的低成本神经符号代理。背景描述了现有图像编辑方法在面对复杂任务时（如“在图像中找到长椅并将其重新着色为粉红色。同时移除猫以获得更清晰的视图，并将墙壁重新着色为黄色”）的局限性。背景部分强调了需要一种经济高效的解决方案，以减少处理步骤和工具使用过程中的成本和时间。

Innovation: 
该研究的主要创新在于开发了一种名为FaSTA∗的代理，它结合了大规模语言模型（LLMs）进行快速的高层次子任务规划与局部A$^*$搜索相结合来寻找经济高效的工具路径。通过LLMs进行归纳推理来节省A$^*$在相似子任务上的成本，持续提取和优化常用的子例程，并在适应性快速-缓慢规划中重复使用，这种灵活的策略显著减少了对同类子任务的探索成本，提高了整体效率。

Conclusion: 
该研究通过与最新图像编辑方法的比较证明，FaSTA∗在计算效率上有显著改进，且在任务成功率方面仍能保持与最先进的基线相当的竞争力。通过这种方式，该论文提出了一种有效的策略来促进多步骤图像编辑任务的高效执行。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20911</guid><pubDate>Fri, 27 Jun 2025 02:35:23 +0800</pubDate></item><item><title>434. cs.CV-DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing</title><link>https://arxiv.org/pdf/2506.20967</link><description>Background: 
视频扩散变换器（Video DiTs）的出现标志着视频生成的里程碑，但直接将现有视频编辑方法应用于Video DiTs往往会产生大量的计算开销，这是由于需要进行资源密集型的注意力修改或微调。为了缓解这个问题，我们提出了一种高效的一次性视频编辑方法DFVEdit，专门针对Video DiTs进行优化。DFVEdit通过流变换直接操作干净的潜在变量，消除了注意力修改和微调的需要，极大地提高了编辑的效率和性能。

Innovation: 
我们提出了Conditional Delta Flow Vector (CDFV) -- 理论上无偏的DFV估计，并结合了Implicit Cross Attention (ICA)指导和Embedding Reinforcement (ER)，进一步提高了编辑质量。DFVEdit在实际效率方面表现出色，相比基于注意力工程的编辑方法，它在Video DiTs上的推理速度提高了至少20倍，内存减少了85%。广泛的定量和定性实验表明，DFVEdit可以无缝应用于流行的Video DiTs（例如CogVideoX和Wan2.1），在结构保真度、时空一致性和编辑质量方面达到了最先进的性能。

Conclusion: 
DFVEdit能够在保持高效和高编辑质量的同时，被无缝应用于流行的Video DiTs，提供了状态最先进（state-of-the-art）的表现。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20967</guid><pubDate>Fri, 27 Jun 2025 02:35:23 +0800</pubDate></item><item><title>435. cs.CV-OTSurv: 基于异质最优传输的新颖多次实例学习框架用于生存预测</title><link>https://arxiv.org/pdf/2506.20741</link><description>Background: 
使用整个切片图像（WSIs）进行生存预测可以被形式化为一个多个实例学习（MIL）问题。然而，现有的MIL方法往往不能明确捕捉WSIs中的病理异质性，无论是全局的长尾形态学分布，还是局部的切片级预测不确定性。OTSurv提出了一种新颖的MIL框架，从最优传输的角度构建，在此过程中解决了这些问题。它通过引入两个约束来建模这种异质性：全局长尾约束，用于避免模式崩溃和过度均匀性；局部不确定性约束，旨在优先考虑置信度高的切片并抑制噪声。通过将初始的OT问题调整为不平衡的OT形式并使用高效的硬件友好型矩阵缩放算法来解决，OTSurv在多个流行基准上取得了新的最好结果，显著提高了平均C指数。此外，OTSurv还具有统计显著性和高可解释性，成为数字病理中生存预测的强大工具。我们的代码可在以下网址获得：this https URL.

Innovation: 
OTSurv提出了一个新的基于最优传输视角的MIL框架，引入了两个约束条件：全局长尾约束和局部不确定性约束。通过使用不平衡的OT形式和高效的硬件友好型矩阵缩放算法求解初始问题，OTSurv解决了现有的MIL方法难以捕捉病理异质性的问题，并在多个基准上达到了新的最佳结果。该方法提高了生存预测的准确性，增加了结果的解释性，提供了对病理图像的更好理解以及改善诊断决策的潜力。此外，该方法还通过统计显著性验证了其在生存预测中的有效性。OTSurv的优点在于提高了准确性、可解释性以及效率。OTSurv利用了最优传输的理论基础，促进了多样病理模式的合理捕捉和表示，有助于提升生存预测的精度和可靠性。

Conclusion: 
OTSurv在多个流行基准上实现了新的最好结果，在平均C指数上取得了3.6%的绝对改进，并通过统计显著性验证了其在生存预测中的有效性。OTSurv不仅提高了生存预测的准确性，还提高了结果的可解释性，通过统计显著性提高了诊断工具的有效性和可靠性。该方法为数字病理中的生存预测提供了一种有效且强大的工具，具有广泛的应用潜力。项目代码已开源，未来可进一步探索其在不同类型病理图像上的应用价值与可能存在的扩展性问题，提高其应用于实际临床中的适用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20741</guid><pubDate>Fri, 27 Jun 2025 02:35:22 +0800</pubDate></item><item><title>436. cs.CV-基于多agent协作的证据推理用于人类病理学诊断</title><link>https://arxiv.org/pdf/2506.20964</link><description>Background: 
病理学正经历由全视野扫描成像和人工智能（AI）推动的快速数字化转型。尽管基于深度学习的计算病理学已取得显著成就，但传统模型主要集中在图像分析上，没有整合自然语言指令或丰富的文本上下文。当前的多模态大规模语言模型在计算病理学中存在局限性，包括训练数据不足、对多图像理解的支持和评估不足，以及缺乏自我诊断推理能力。

Innovation: 
为解决上述局限性，该研究引入了PathChat+，这是一种专为人类病理学设计的新多模态大规模语言模型，已通过超过100万种多样化的病理特定指令样本和近550万问答对进行训练。跨多种病理学基准的广泛评估表明，PathChat+显著优于先前的PathChat伴侣模型以及其他最先进的通用和专门针对病理学的模型。此外，展示了SlideSeek，这是一种集成了PathChat+的支持推理的多代理AI系统，通过迭代的层次诊断推理自主评估千兆像素全视野图像，并在具有挑战性的开放性疑难诊断基准DDxBench上实现了高准确度，同时能够生成视觉地锚点、人类可解释的总结报告

Conclusion: 
PathChat+和SlideSeek解决了多模态语言模型在病理学中的局限性，展示了其在复杂病理学诊断任务中的优势，并为实现自主、高效、可解释的病理学辅助诊断提供了新的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20964</guid><pubDate>Fri, 27 Jun 2025 02:35:22 +0800</pubDate></item><item><title>437. cs.CV-OmniEval：一种包含视觉、听觉和文本输入的全方位模型评估基准</title><link>https://arxiv.org/pdf/2506.20960</link><description>Background: 
当前缺乏一个全面评价涉及视觉、听觉和文本输入的全方位模型（omni-modality models）的基准。现有的评估基准通常只专注于单一或两种模态的数据，缺乏跨模态综合评估的全面性，难以充分考察模型在综合利用多种感知信息进行有效分析和决策方面的性能。OmniEval旨在填补这一空白，提供一个多模态协作的任务环境，评估模型在理解和构建跨模态连贯性方面的能力。

Innovation: 
OmniEval具有以下创新点：(i) 全模态协作：设计评估任务以突出音频和视频之间的强烈耦合，要求模型能够有效利用所有模态的感觉；(ii) 视频多样性：包括810段音视频同步视频、285段中文视频和525段英文视频；(iii) 任务的多样性和精细度：包含2617个问题-答案对，包括1412个开放问题和1205个选择题。这些问题分为3类主要的任务类型和12个子任务类型，实现了全面评估。此外，引入了一个更精细的视频定位任务名为Grounding。

Conclusion: 
本研究通过OmniEval为评估全方位模型从多模态上下文中构建和理解连贯性的能力提供了一个平台。该基准已经对几种全方位模型进行了实验，可从提供的链接下载代码和数据。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20960</guid><pubDate>Fri, 27 Jun 2025 02:35:18 +0800</pubDate></item><item><title>438. cs.CV-PhysRig：基于物理的可微皮肤和骨架框架以实现逼真的仿生建模</title><link>https://arxiv.org/pdf/2506.20936</link><description>Background: 
皮肤和骨骼绑定是动画、 articulated对象重建、运动迁移和4D生成的基础组成部分。现有方法主要依赖于线性混合皮肤（LBS），因其简单性和可微性。然而，LBS会导致体积损失和不自然的变形，并且无法模拟如软组织、毛和灵活附肢（例如大象的鼻子、耳朵和脂肪组织）这类弹性材料。

Innovation: 
本文提出了一种名为PhysRig的基于物理的可微皮肤和骨架绑定框架。该框架通过将刚性骨架嵌入到体积表示中（例如四面体网格），并将其模拟为由动画骨架驱动的变形软体结构来克服LBS的局限性。该方法利用连续力学原理，将以粒子形式嵌入欧拉背景网格中的对象进行离散化，从而确保在材料属性和骨架运动方面的可微性。此外，还引入了材料原型，显著减少了学习空间但保持了高表达性。

Conclusion: 
为了评估该框架，本文使用Objaverse、The Amazing Animals Zoo和MixaMo中的网格创建了一个综合的合成数据集，覆盖了多种对象类别和运动模式。与传统的基于LBS的方法相比，该方法一致地产生了更真实和物理合理的结果。此外，本文还展示了该框架在姿态转移任务中的应用，突显了其在仿生建模中的多功能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20936</guid><pubDate>Fri, 27 Jun 2025 02:35:18 +0800</pubDate></item><item><title>439. cs.CV-Hierarchical Sub-action Tree for Continuous Sign Language Recognition</title><link>https://arxiv.org/pdf/2506.20947</link><description>Background: 
连续手语识别（CSLR）旨在将未剪辑的视频转换为文字，这些文字通常表示为词语。由于缺乏大规模数据集和准确注释，导致训练数据不足，这已成为CSLR研究的瓶颈。现有研究通常开发跨模态解决方案以使视觉和文本模态对齐，但这些方法通常是从手语词汇中提取文本特征，未能充分利用其知识。因此，通过引入层次子动作树（HST）及其在连续手语识别中的应用（HST-CSLR），该研究旨在有效结合手语知识与视觉表示学习。HST利用大型语言模型提供的特定手语知识，从文本信息的表征和模态对齐方面更充分地利用了文本信息，减少了计算复杂度。

Innovation: 
提出了一种层次子动作树（HST），通过结合手语知识和视觉表示学习，有效利用大型语言模型提供的特定手语知识，从中提取并构造文本信息表示，逐步对齐视觉和文本模态，利用树结构减少计算复杂度。此外，还实施了一种对比对齐增强，进一步缩小了两种模态之间的差距。

Conclusion: 
在四个数据集（PHOENIX-2014、PHOENIX-2014T、CSL-Daily 和 Sign Language Gesture）上的实验验证了HST-CSLR的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20947</guid><pubDate>Fri, 27 Jun 2025 02:35:17 +0800</pubDate></item><item><title>440. cs.CV-M2SFormer: 多谱性和多尺度注意力结合边缘感知难度指导的图像伪造定位</title><link>https://arxiv.org/pdf/2506.20922</link><description>Background: 
图像编辑技术迅速发展，既促进了数字图像的创新应用，也带来了恶意篡改的风险。基于深度学习的像素级伪造定位方法虽然已经达到了高精度，但仍然面临计算开销大和表示能力有限的问题，尤其是在处理细微或复杂的篡改时。为此，本文探讨了M2SFormer框架，这是一种利用Transformer编码器克服这些挑战的新颖方法。M2SFormer通过统一多频谱和多尺度注意机制，并结合全局语境来更好地捕捉各种伪造细节，解决了现有方法在高分辨率重建过程中细节丢失的问题。

Innovation: 
M2SFormer框架通过以下创新点来解决现有方法的挑战：1) 在跳跃连接中统一处理多频谱和多尺度注意力，利用全局上下文更好地捕捉各种伪造特征；2) 引入一个全局先验图，通过引导难度导向的注意力模块，有效保留细微的篡改细节；3) 通过边缘感知的难度指导，增强对未见域伪造检测的泛化能力。

Conclusion: 
通过在多个基准数据集上的大量实验，M2SFormer展示了它在检测和定位伪造方面的优越性能，能够更好地适应未见过的领域。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20922</guid><pubDate>Fri, 27 Jun 2025 02:35:12 +0800</pubDate></item><item><title>441. cs.CV-MultiHuman-Testbench: 评估多个人物图像生成基准</title><link>https://arxiv.org/pdf/2506.20879</link><description>Background: 
生成包含多个动作复杂的人，并同时保留其面部身份的人物图像是一项重大挑战，主要是由于缺乏专门的基准数据集。为应对这一挑战，该研究引入了MultiHuman-Testbench，一个专为多个人物生成的生成模型进行严格评估的新基准。基准数据集包括1800个样本，以及描述从简单到复杂的多种人类动作的细致文本提示，匹配总共有5,550张独特的人脸图像，确保这些图像在年龄、民族背景和性别方面具有多样性。伴随文本提示还提供了由人类选择的姿势调节图片，以准确匹配提示内容。

Innovation: 
该研究提出了MultiHuman-Testbench作为专门针对多个人物生成的评估基准，包含1800个样本和5,550张人脸图像，以满足多样化的年龄、民族背景和性别需求。此外，还提出了一套多维度评估工具，包括四个关键指标来量面部计数、身份相似性、提示对齐和动作检测。另外，研究还提出了通过人类分割和匈牙利匹配将图像和区域隔离的新技术，显著提高了身份相似度。

Conclusion: 
提出的基准测试以及关键发现为多个人物图像生成的研究提供了宝贵的见解和标准化工具，推动了该领域的进展。研究通过广泛评估多种模型，包括无监督方法和训练方法，证实了新技术和方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20879</guid><pubDate>Fri, 27 Jun 2025 02:35:12 +0800</pubDate></item><item><title>442. cs.CV-立体视觉中单眼的作用</title><link>https://arxiv.org/pdf/2506.20900</link><description>Background: 
这篇论文研究了现代立体视觉系统的几何基础，重点探讨了三维结构和人启发式感知如何有助于准确的深度重建。文中回顾了单眼模型，并提出了新的几何约束条件，这些约束条件考虑了遮挡和深度不连续性的影响。此外，论文评估了深度学习模型衍生的立体特征匹配质量，以及注意力机制在恢复有意义的3D表面中的作用。通过理论洞察和对实际数据集的实验研究，论文表明，结合强大的几何先验知识与学习到的特征可以在理解立体视觉系统方面提供内部抽象。

Innovation: 
提出了新的几何约束条件以考虑遮挡和深度不连续性；评估了深度学习模型衍生的立体特征匹配质量；研究了注意力机制在恢复3D表面中的作用。

Conclusion: 
结合强大的几何先验知识与学习到的特征可以在理解立体视觉系统方面提供内部抽象，有助于准确的深度重建。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20900</guid><pubDate>Fri, 27 Jun 2025 02:35:09 +0800</pubDate></item><item><title>443. cs.CV-利用视觉语言模型选择由扩散模型生成的可信超分辨率样本</title><link>https://arxiv.org/pdf/2506.20832</link><description>Background: 
超分辨率（SR）问题是一个病态的逆问题，对于给定的低分辨率图像，存在许多可能的解决方案。回归式的SR模型试图在保真度和感知质量之间取得平衡，以生成单一解决方案，但这往往会在关键信息的应用中引入伪影，例如数字或字母的识别。另一方面，扩散模型能够生成多样化的SR图像集，但从中选出最可信的解决方案仍然是一个挑战。本文提出了一个基于视觉语言模型（VLMs）的自动化框架，通过利用这些模型的语义推理能力来识别由扩散模型生成的SR样本集中最可信的结果。VLMs通过结构化查询来评估语义正确性、视觉质量和伪影存在的可能性，然后通过联合体来提供一个单一的可信输出。为了严格评估VLM选择样本的有效性，本文提出了一种新的信任度评分（TWS），该评分是一个基于互补组件的混合指标：通过CLIP嵌入量化语义相似性，通过边缘图上的SSIM量化结构完整性，通过多级小波分解量化伪影敏感性。实验结果表明，TWS与人类对模糊和自然图像的偏好密切相关，并且由VLM指导的选择始终提供高TWS值，相比传统的PSNR和LPIPS度量，本方法提供了导航扩散模型的不确定性的一种有原则、可扩展和通用的解决方案，通过与人类期望和语义正确性对齐，本文为生成的SR的信任性设定了新的基准。

Innovation: 
提出了一种基于视觉语言模型的自动化框架，该框架通过语义推理来识别扩散模型生成的SR样本集中最可信的结果。引入了新的信任度评分（TWS）作为评估指标，该评分综合了语义相似性、结构完整性和伪影敏感性。相较于传统的PSNR和LPIPS度量，该方法能够更好地反映信息的忠实度，并提供了一种导航扩散模型生成的不确定性问题的有原则、可扩展和通用的解决方案。

Conclusion: 
本文提出了一个新的框架，利用视觉语言模型自动选择由扩散模型生成的最可信的超分辨率样本，并提出了一种混合的信任度评分（TWS）来评估这些样本。相较于传统的度量方法，该方法能够在不确定性较大的扩散SR空间中提供一种更为有效的解决方案，同时该工作也确立了新的可信度基准。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20832</guid><pubDate>Fri, 27 Jun 2025 02:35:06 +0800</pubDate></item><item><title>444. cs.CV-THIRDEYE: 受大脑启发的多阶段融合的线索感知单目深度估计</title><link>https://arxiv.org/pdf/2506.20877</link><description>Background: 
传统的单目深度估计方法通过训练深度模型直接从RGB像素中推断深度，这种方法往往忽略了人类视觉系统依赖的显式单目线索，如遮挡边界、阴影和透视关系。现有的方法依赖网络自主发现这些线索，而忽略了显式的外部帮助指导的过程。

Innovation: 
本文提出了ThirdEye，一种线索感知的管道，该管道通过专门的、预先训练且冻结的网络提供各种单目线索，并将这些线索融合在仿效初级视觉皮层结构的三级（V1-&amp;gt;V2-&amp;gt;V3）融合结构中，融合过程中利用一种关键值工作记忆模块根据可靠性加权，最终生成高分辨率的视差图。由于专家模块是冻结的，ThirdEye继承了大量的外部监督，只进行适度的微调。

Conclusion: 
因为专家模块是冻结的，ThirdEye不仅能够以少量的微调获得大量外部监督，还能够在不显著增加计算成本的情况下提高单目深度估计的精度。未来会进一步提供架构细节、神经科学动机和扩展的实验方案，并在未来的修订版中发布定量结果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20877</guid><pubDate>Fri, 27 Jun 2025 02:35:06 +0800</pubDate></item><item><title>445. cs.CV-像素向量对比学习在医学视觉中的像素级预训练</title><link>https://arxiv.org/pdf/2506.20850</link><description>Background: 
对比学习（CL）已经成为自我监督预训练（SSP）在基础模型中的基石，但在医学视觉中至关重要的像素级表示上，将其扩展仍然存在开放性问题。现有的标准CL形式化预训练为二元优化问题，过度追求特征分散导致了过度分散问题，破坏了像素级特征相关性，从而打破了类内分布。现有技术在预训练中忽视了像素级特征的相关性，这对医学图像识别至关重要，因此研究者们寻找新的方法来解决这一挑战。

Innovation: 
本文提出了一种新的像素向量对比学习（vector CL）方法，通过矢量回归问题重新定义CL，以更好地量化像素级预训练中的特征分散情况。为了实施这一新的范式，提出了一种新的框架——COntrast in VEctor Regression (COVER)。COVER框架通过矢量回归将特征距离建模，构造了一个可扩展的矢量自学习方法，使优化流程从矢量回归到距离建模保持一致，利用矢量金字塔架构实现粒度的适应性，从而在自我监督预训练中保持了像素级特征的相关性。

Conclusion: 
广泛实验结果显示，COVER在多种任务中显著提高了像素级自我监督预训练的效果，促进了可泛化的医学视觉基础模型的发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20850</guid><pubDate>Fri, 27 Jun 2025 02:35:04 +0800</pubDate></item><item><title>446. cs.CV-基于软标签数据增强提升模糊动态面部表情识别</title><link>https://arxiv.org/pdf/2506.20867</link><description>Background: 
动态面部表情识别（DFER）是一项从面部表情视频序列中估计情感的任务。实际应用中，准确识别出现在自然环境中的模糊面部表情至关重要。MIDAS提出了一种数据增强方法，使用表示多个情感类别的概率的软标签来增强模糊面部表情数据的DFER性能。该方法通过凸组合视频帧及其相应的情感类别标签来增强训练数据，将其扩展到软标记视频数据，从而提供了一种简单而有效的处理DFER中模糊性的方法。

Innovation: 
MIDAS通过将视频帧对及其相应的情感类别标签通过凸组合进行增强，扩展了mixup方法以适应软标记视频数据，并提出了一种简单高效的方法来处理DFER中的模糊性问题。

Conclusion: 
通过使用MIDAS增强的数据训练的模型，在DFEW数据集和FEV39k-Plus数据集上的实验结果表明，其性能优于使用原始数据训练的最先进的方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20867</guid><pubDate>Fri, 27 Jun 2025 02:35:04 +0800</pubDate></item><item><title>447. cs.CL-GroundCap：一个视觉接地图像字幕数据集</title><link>https://arxiv.org/pdf/2502.13898</link><description>Background: 
目前的图像字幕系统缺乏将描述性文本与特定视觉元素关联的能力，使得输出难以验证。虽然最近的方法提供了一些接地能力，但他们无法在多个引用中跟踪对象身份，也无法同时将动作和对象结合在一起。

Innovation: 
本文提出了一种基于ID的接地系统，该系统能够实现一致的对象引用跟踪和动作-对象链接。此外，还提出了一个名为GroundCap的数据集，包含来自77部电影的52,016张图片，每张图片附带344个人类标注和52,016个自动生成的字幕，利用标签系统链接动作与对应对象，同时保持对象身份。该方法包括持久的对象ID用于引用跟踪，明确的动作-对象链接，以及通过K-means聚类背景元素的分割。同时，还提出了一种新的评估指标gMETEOR，结合了字幕质量和接地准确性，并通过在GroundCap上微调Pixtral-12B和Qwen2.5-VL 7B来建立基线性能。

Conclusion: 
人类评估证明，该方法在生成可验证、具有连贯对象引用的描述方面非常有效。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.13898</guid><pubDate>Fri, 27 Jun 2025 02:35:00 +0800</pubDate></item><item><title>448. cs.CV-基础模型与基于骨架的方法在人类-机器人交互中手势识别的比较</title><link>https://arxiv.org/pdf/2506.20795</link><description>Background: 
手势能够促进非语言的人机交流，尤其是在嘈杂的环境中，如灵活生产环境。传统的基于深度学习的手势识别依赖于特定任务的架构，使用图像、视频或骨架姿态估计作为输入。然而，视觉基础模型（VFMs）和视觉语言模型（VLMs）凭借其强大的泛化能力，有可能通过替换专用的特定任务模块来简化系统复杂性。本文旨在探讨将这些模型调整用于动态的全身手势识别，并对比了了最新的视觉基础模型V-JEPA、多模态视觉语言模型Gemini Flash 2.0，以及表现最佳的基于骨架的方法HD-GCN。为此，本文还引入了NUGGET数据集，专门用于供应链环境中的手势识别。实验结果显示，基于骨架的方法HD-GCN在这些方法中表现最佳，尽管V-JEPA也有接近的表现，且通过简单任务特定的分类头表现出潜力，可能成为共享多任务模型的一种选择。然而，在零样本设置中，Gemini基于文本描述难以区分手势，这表明对手势识别的输入表示需要进一步的研究。

Innovation: 
本文引入了NUGGET数据集，专门用于评估人-机手势识别的方法。同时，本文对比了视觉基础模型和多模态视觉语言模型与基于骨架的方法在动态手势识别中的表现，提出了可能通过共享多任务模型来简化系统复杂性的思路。

Conclusion: 
基于骨架的方法HD-GCN在当前实验中表现最佳，而视觉基础模型V-JEPA有潜力成为共享多任务模型。Gemini在零样本设置中表现不佳，强调了对手势识别输入表示方法进一步研究的必要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20795</guid><pubDate>Fri, 27 Jun 2025 02:35:00 +0800</pubDate></item><item><title>449. cs.CV-ConViTac: 使用对比表示对齐视觉-触觉融合</title><link>https://arxiv.org/pdf/2506.20757</link><description>Background: 
视觉和触觉是机器人两种基本的感觉模态，提供了互补的信息，增强了感知和操作任务。过往的研究尝试联合学习视觉-触觉表征以提取更具有意义的信息，但这些方法通常依赖直接的组合方式，如特征添加和拼接，来进行模态融合，这往往导致特征融合效果不佳。

Innovation: 
本文提出了一种Visual-Tactile表征学习网络ConViTac，旨在通过对比表示增强融合过程中特征的对齐性。核心贡献在于引入了一种对比嵌入条件机制(CEC)，利用自监督对比学习预训练的对比编码器将视觉和触觉输入投影到统一的潜在嵌入中，通过跨模态注意将这些嵌入用于视觉-触觉特征融合，以对齐统一的表现形式，并在下游任务上提升性能。

Conclusion: 
通过大量实验验证了ConViTac的优越性，相较于当前最先进的方法在真实世界中表现更优，证明了我们提出的CEC机制的有效性，该机制在材料分类和抓取预测任务中提高了12.0%的准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20757</guid><pubDate>Fri, 27 Jun 2025 02:34:59 +0800</pubDate></item><item><title>450. cs.CV-FixCLR：负类对比学习在半监督领域泛化中的应用</title><link>https://arxiv.org/pdf/2506.20841</link><description>Background: 
半监督领域泛化（SSDG）旨在仅使用少量标签的情况下将模型泛化到未见数据。由于标签稀缺，现有的领域泛化方法往往表现不佳。因此，现有方法通常将半监督学习方法与各种正则化项相结合。然而，这些方法没有明确正则化以在所有领域中学习不变的表示，这是领域泛化的关键目标。

Innovation: 
提出了FixCLR，通过借鉴自监督学习的成功经验，改变对比学习中的两个关键组件，使其更加适用于明确的领域不变性正则化：利用伪标签中的类别信息和仅使用排斥项。FixCLR可以作为大多数现有SSDG和半监督方法的附加方法，以实现互补的性能提升。实验证明了FixCLR在SSDG中的有效性，尤其是在与其他半监督方法结合使用时效果更佳。

Conclusion: 
我们的研究包括对不同半监督方法改进的基准测试、评估预训练模型与非预训练模型的性能以及在多领域数据集上的测试。总体而言，FixCLR是一个有效的SSDG方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20841</guid><pubDate>Fri, 27 Jun 2025 02:34:59 +0800</pubDate></item><item><title>451. cs.CL-CVC: 一个大规模中文价值规则语料库，用于大型语言模型的价值对齐</title><link>https://arxiv.org/pdf/2506.01495</link><description>Background: 
确保大型语言模型（LLMs）与主流人类价值观和伦理规范保持一致，对于人工智能的安全生产和可持续发展至关重要。当前的价值评估与对齐受限于西方文化偏见和不完善的本土框架，依赖非本土规则。此外，缺乏可扩展性的、基于规则的场景生成方法使得评估在多文化背景下具有高成本且不够全面。为了应对这些挑战，本文提出了一个基于核心中国价值观的层次化价值框架，涵盖了三个主要维度、十二个核心价值观和五十个衍生价值观。在此基础上，我们构建了一个大规模中文价值观语料库（CVC），包含超过250,000条增强和扩展的价值规则，通过人工标注实现。实验结果表明，CVC指导的场景在价值边界和内容多样性方面优于直接生成的场景。在对六个敏感主题（如代孕、自杀）的评估中，七个主流LLM中有70.5%以上偏好了CVC生成的选项，而五名中国人工标注员有87.5%的共识与CVC一致，验证了其普适性、文化契合性和与中国价值观的强大对齐性。此外，我们构建了400,000个基于规则的情景道德困境，客观地捕捉了17个LLM间在冲突价值优先级上的细微差异。

Innovation: 
在方法上：1. 基于核心中国价值观构建层次化价值框架；2. 构建大规模中文价值观语料库（CVC），涵盖丰富的人工标注价值规则。在应用上：1. 提供了一种全面的价值评估和对齐框架；2. 是首个具有中国文化特定性的解决方案，适用于LLMs的适应性基准测试。

Conclusion: 
本工作建立了一个文化适应性基准框架，利用CVC可以全面评估和对齐价值观，彰显了中国特色。所有数据均开放获取，相关代码也将在指定官网提供。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.01495</guid><pubDate>Fri, 27 Jun 2025 02:34:58 +0800</pubDate></item><item><title>452. cs.CV-基于AI的MRI脑肿瘤分割基准测试</title><link>https://arxiv.org/pdf/2506.20786</link><description>Background: 
医学图像分割极大地促进了医学诊断，基于U-Net和nnU-Net的架构提供了最先进的性能。近年来引入了许多通用可提示模型和医学变体，但目前缺乏在不同提示质量下的这些模型的评估和比较，尤其是一致的医学数据集上。本研究使用了Segment Anything Model (SAM)，Segment Anything Model 2 (SAM 2)，MedSAM，SAM-Med-3D，和nnU-Net在Brats 2023成年胶质瘤和儿科数据集上获得零样本推断，涵盖了多种提示质量下的点和边界框。这些模型表现出色，尤其是SAM和SAM 2在极准确的边界框提示下，分别获得了高达0.894和0.893的Dice分数，超过了nnU-Net的分割性能。然而，由于提供高度准确提示的困难性，nnU-Net仍然是主导的医学图像分割网络。

Innovation: 
本研究首次在Brats 2023数据集上对SAM，SAM 2，MedSAM，SAM-Med-3D和nnU-Net进行了全面的评估和比较，研究了这些模型在不同提示质量下的表现。研究进一步通过在儿科数据集上微调SAM，SAM 2，MedSAM和SAM-Med-3D，对点提示性能进行了显著改进，为未来的研究带来了希望，但仍无法超越边界框或nnU-Net的分割效果和准确性。

Conclusion: 
尽管SAM和SAM 2在某些提示质量下表现出色，但nnU-Net仍然在医学图像分割方面占有主导地位。通过微调，点提示性能有所提升，为未来的继续研究提供了基础，但需进一步改进以达到与边界框提示或nnU-Net相媲美的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20786</guid><pubDate>Fri, 27 Jun 2025 02:34:54 +0800</pubDate></item><item><title>453. cs.CV-StereoDiff：视频深度估计的立体匹配与视频深度扩散协同</title><link>https://arxiv.org/pdf/2506.20756</link><description>Background: 
近年来，视频深度估计方法通过遵循图像深度估计的范式，即通常通过大规模数据对预训练的视频扩散模型进行微调，实现了卓越的性能。然而，本文作者认为，视频深度估计并不是图像深度估计的简单扩展。视频中动态和静态区域的时间一致性需求本质上是不同的。在静态区域，例如背景中，一致的视频深度可以通过在整个帧间进行立体匹配来更有效地实现，这提供了更强的全局三维线索。而对于动态区域，一致性仍需从大规模视频深度数据中学习，以确保平滑过渡，但必须考虑到三角测量约束的违反。

Innovation: 
本文提出了一种名为StereoDiff的两阶段视频深度估计器，结合了立体匹配技术主要用于静态区域以及视频深度扩散技术以保持动态区域的一致深度转换。通过频域分析数学上证明了立体匹配和视频深度扩散的互补优势如何通过协同作用来捕捉两者的优点，从而提高视频深度估计的整体性能和准确性。实验结果表明，StereoDiff在零样本、真实世界、动态视频深度基准测试中的表现最佳，展示了其在视频深度估计中的优势一致性与准确性。

Conclusion: 
实验结果在零样本、真实世界、动态视频深度基准测试中验证了StereoDiff的最优性能，突出了其在视频深度估计中优越的一致性和准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20756</guid><pubDate>Fri, 27 Jun 2025 02:34:50 +0800</pubDate></item><item><title>454. cs.CL-探索五大人格特质和AI能力对LLM模拟谈判对话影响</title><link>https://arxiv.org/pdf/2506.15928</link><description>Background: 
本文提出了针对任务关键型谈判情境中的代理式AI系统的评估框架，旨在让AI代理能够适应不同的人类操作员和利益相关者。通过使用Sotopia作为模拟测试环境，两个实验系统地评估了人格特质和AI代理特征如何影响LLM模拟的社会谈判结果——这种能力对于涉及跨团队协调和民兵互动的各种应用程序至关重要。实验通过因果发现方法研究了人格特质如何影响价格谈判，并发现宜人性和外向性显著影响可信度、目标实现和知识获取的结果。从团队交流中提取的社会认知词汇度量展示了代际在共情沟通、道德基础和观点模式上的细微差异，为代理式AI系统在高风险操作场景中可靠运行提供了实际可行的见解。第二个实验通过操纵模拟的人格和AI系统特征，评估了人类与AI的职位谈判，展示了AI代理可信性如何影响任务效果。实验结果建立了一种可重复的方法来评估代理式AI工作流在不同操作员人格和团队动态中的可靠性，直接支持可靠AI系统的操作需求。这项工作通过超越标准性能度量的评估方法，加入了对于复杂操作中任务成功至关重要的社会动态。

Innovation: 
该研究创新性地提出了一种评估框架，用于任务关键型谈判情境中的代理式AI系统的可靠性评估。通过因果发现方法和Sotopia模拟测试环境，系统地评估了人格特质和AI代理特征对LLM模拟社会谈判结果的影响。该框架不仅涵盖了AI系统的性能指标，还关注了其在实际操作中的社会动态因素，为代理式AI系统的开发提供了参考依据。

Conclusion: 
本文通过两个实验，建立了用于评估代理式AI工作流在多样化的操作员人格和团队动态中的可靠性的可重复方法。这种方法不仅超越了传统的性能指标，还重视社会动态对任务成功的关键作用。研究发现对提升代理式AI系统的评估标准提供了重要的支持，为其在复杂操作中的广泛应用奠定了基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15928</guid><pubDate>Fri, 27 Jun 2025 02:34:49 +0800</pubDate></item><item><title>455. cs.CL-从Web搜索到有自主推理能力的深度研究：用推理代理激励搜索</title><link>https://arxiv.org/pdf/2506.18959</link><description>Background: 
信息检索是现代知识获取的基础，使得每天在各个领域进行数十亿次查询。然而，传统的基于关键词的搜索引擎对于处理复杂、多步骤的信息需求越来越不足。从静态网页搜索到交互式、基于代理的系统，这些系统能够计划、探索和学习，这一过程的研究和发展是本文的背景。文章强调了通过引入有自主推理能力的大型语言模型（LLMs），标志着进入了一个新的范式，即有自主性的深度研究（Agentic Deep Research）。这些系统通过紧密集成自主推理、迭代检索和信息综合，形成一个动态反馈循环，超越了传统的信息检索技术。

Innovation: 
本文提出了一种新的范式，即有自主性的深度研究（Agentic Deep Research），它利用具有自主推理和执行能力的大模型，形成一种动态反馈循环，集成了自主推理、迭代检索和信息综合。同时，文章引入了一个测试时间的扩展法则，以正式形式阐述计算深度对推理和搜索的影响。此外，通过基准测试结果和开源实现程序的推动，表明有自主性的深度研究不仅在性能上超越了现有的方法，而且预计将主导未来的信息寻求模式。

Conclusion: 
支持基准结果和开源实施程序的推动，证明有自主性的深度研究不仅在性能上超越了现有的方法，而且预计将成为未来信息寻求的主导模式。为此，所有相关的资源，包括行业产品、研究论文、基准数据集和开源实现，已收集在这里 https://github.com/ACL-.ALIGN-CLF/Checkpoints。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18959</guid><pubDate>Fri, 27 Jun 2025 02:34:48 +0800</pubDate></item><item><title>456. cs.CL-SACL: 使用语义增强重排序和定位来理解并对抗代码检索中的文本偏见</title><link>https://arxiv.org/pdf/2506.20081</link><description>Background: 
当前的代码检索技术依赖于表面级别的文本特征（例如，文档字符串和标识符名称），并且对文档完整但相关信息不相关的代码存在偏见。这限制了代码生成和检索的效果。因此，需要一种新的方法来理解现有代码检索中的偏见，并提出有效的解决方案来减少这种偏见。

Innovation: 
本文提出了SACL框架，该框架通过增强文本信息并利用语义信息来丰富代码或结构知识，从而减少偏见。SACL通过引入语义增强的重排序和定位机制，改善了代码检索的准确性，并进而提高了代码生成的效果。

Conclusion: 
实验结果表明，SACL在代码检索上有了显著的提升，例如在HumanEval、MBPP和SWE-Bench-Lite上的Recall@1分别提高了12.8%、9.4%和7.0%，同时在代码生成上的Pass@1也提高了4.88%。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20081</guid><pubDate>Fri, 27 Jun 2025 02:34:45 +0800</pubDate></item><item><title>457. cs.CL-PP-DocBee：通过各种技巧提高多模态文档理解</title><link>https://arxiv.org/pdf/2503.04065</link><description>Background: 
随着数字化的快速发展，各种文档图像在生产和日常生活中的应用越来越广泛，对文档图像内容的快速准确解析也变得越来越迫切。因此，本文介绍了一种名为PP-DocBee的新型多模态大语言模型，专为端到端文档图像理解设计。该模型通过开发针对文档情景的数据合成策略和构建多样化的数据集，增强了模型的泛化能力。此外，还通过动态比例采样、数据预处理和OCR后处理等技术手段提升了模型性能。

Innovation: 
PP-DocBee通过数据合成策略构建多样化数据集，增强了模型的泛化能力；采用动态比例采样、数据预处理和OCR后处理等训练技术提高了模型性能；并且PP-DocBee在英语文档理解基准测试中达到了最先进的性能，在中文文档理解上也超过了现有的开源和商用模型。

Conclusion: 
PP-DocBee在处理文档图像理解和解析方面取得了显著成效，通过向公众开放源代码和预训练模型呈现出优越的性能，为文档图像的理解和解析提供了更有效的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.04065</guid><pubDate>Fri, 27 Jun 2025 02:34:44 +0800</pubDate></item><item><title>458. cs.CL-DiffuCoder：理解并改进掩蔽扩散模型进行代码生成</title><link>https://arxiv.org/pdf/2506.20639</link><description>Background: 
扩散大语言模型（dLLMs）因其在整个序列上的去噪模型而成为自回归（AR）模型的有吸引力的替代品。dLLMs 的全局规划和迭代精细调整功能特别适用于代码生成。然而，目前 dLLMs 在编码中的训练和推理机制仍然没有得到充分探索。因此，需要系统地研究其去噪过程及其强化学习（RL）方法，以揭示其解码行为与 AR 模型的区别，并提高其在编码方面的潜力。研究者针对这一点进行了详尽的研究，并构建了一个基于 130 亿代码令牌训练的 7 亿参数的 dLLM，名为 DiffuCoder。通过分析 DiffuCoder 的解码行为和与其 AR 模型的区别来探索其解码机制。

Innovation: 
研究提出了耦合-GRPO（coupled-GRPO）采样方案，这是一种新颖的采样方法，用于构建与训练中使用的完成部分互补的掩码噪声，从而减少 token 对数似然估计的方差并保持训练效率。该方案提升了 DiffuCoder 在代码生成基准测试上的性能，并减少了在解码过程中对 AR 偏好的依赖。这为理解 dLLM 生成机制提供了更深入的见解，并提供了一种有效的、扩散模型特有的 RL 训练框架。

Conclusion: 
研究取得的主要成果是提升了 DiffuCoder 的代码生成性能和降低了其生成过程对 AR 偏好的依赖。通过揭示 dLLM 的解码行为与 AR 模型的区别，为 dLLM 作为一种代码生成工具提供了新的理解，并为其训练和应用提供了一种新的框架。该研究为后续相关领域的研究提供了重要参考。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20639</guid><pubDate>Fri, 27 Jun 2025 02:34:39 +0800</pubDate></item><item><title>459. cs.CL-使用软注意模拟硬注意</title><link>https://arxiv.org/pdf/2412.09925</link><description>Background: 
该论文研究了基于软注意的变压器在什么条件下能模拟硬注意，即能够有效地专注于位置的子集。研究首先探讨了硬注意变压器所识别的多种语言类型，这些语言类型可以由变体线性时序逻辑来定义。然后展示了如何使用无界位置嵌入或温度调整让软注意变压器计算这些逻辑公式的公式。接着，论文表明温度调整如何使得软注意变换器能够模拟一般硬注意变换器，具体的模拟方式是通过依赖于最大注意力分数和其他注意力分数之间最小差距的温度来进行的。

Innovation: 
这项工作创新地利用温度调整的方法，使得软注意变换器能够模拟硬注意变换器的功能，这扩展了软注意在自然语言处理任务中的适用范围。论文通过精确地控制Transformer的注意力机制，使得软注意能更灵活地应用于不同的语言处理任务。

Conclusion: 
该研究展示了软注意变换器能够通过无界位置嵌入或温度调整来实现对特定位置的关注，同时证明了温度调整能够使软注意变换器模拟硬注意变换器的功能。主要结论是，通过合理的选择参数，软注意变换器可以有效地模拟硬注意变换器，为灵活性和效率之间的权衡提供了一种新的视角。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.09925</guid><pubDate>Fri, 27 Jun 2025 02:34:39 +0800</pubDate></item><item><title>460. cs.CL-HERMES: 时空连贯的长视频理解-场景与语义</title><link>https://arxiv.org/pdf/2408.17443</link><description>Background: 
长视频的理解带来了独特的挑战，超越了传统的短视频分析方法，特别是在捕捉长范围依赖关系、高效处理冗余信息以及提取高层次语义概念方面。

Innovation: 
提出了一种新颖的方法，更好地反映了人类认知，其中包括两个模块：具时态一致性、场景和语义的Episode浓缩器（ECO）与语义检索器（SeTR）。ECO在从微观到半宏观的级别上高效聚集表示，同时保留时间依赖关系，减少计算开销。SeTR通过关注更广泛的情境来丰富这些表示，大幅度减少特征维度，同时保留相关的宏观信息。这些模块可以无缝集成到现有的最先进的模型中，提高其性能并减少推理延迟和内存使用分别为43%和46%。作为一个独立系统，HERMES在零样本和完全监督的多个长视频理解基准测试中达到了最先进的性能。

Conclusion: 
HERMES能够将模块无缝集成到现有的最先进模型中，其性能改进显著，同时减少了43%的推理延迟和46%的内存使用。作为一个独立系统，HERMES在多种长视频理解基准测试中达到了最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.17443</guid><pubDate>Fri, 27 Jun 2025 02:34:38 +0800</pubDate></item><item><title>461. cs.CL-Thinkless: LLM Learns When to Think</title><link>https://arxiv.org/pdf/2505.13379</link><description>Background: 
语言模型具备进行扩展的链式推理，已经在需要复杂逻辑推理的任务中展示了出色的性能。然而，对所有查询应用复杂的推理通常会导致巨大的计算效率低下，特别是在许多问题有简单解的情况下。因此，提出了一个开放性的问题：语言模型是否可以学会在何时进行推理？

Innovation: 
提出了一种名为Thinkless的可学习框架，使语言模型能够基于任务复杂性和模型的能力自适应地选择简短形式或详细推理。Thinkless采用强化学习范式进行训练，并使用两个控制标记：&amp;lt;short&amp;gt;用于简短回应，&amp;lt;think&amp;gt;用于详细推理。方法的核心是一种名为Decoupled Group Relative Policy Optimization (DeGRPO)的算法，该算法将混合推理的学习目标分解为两部分：（1）控制标记损失，控制推理模式的选择；（2）响应损失，提高生成答案的准确性。这种方法解耦使得可以对每个目标贡献进行细粒度控制，稳定训练，并有效防止vanilla GRPO中观察到的崩溃现象。在Minerva Algebra、MATH-500和GSM8K等基准测试中，Thinkless能够将使用详细推理的比例减少50% - 90%，显著提高了推理语言模型的效率。

Conclusion: 
实验证明，Thinkless能够在不损失准确性的前提下显著减少复杂推理的使用，提高了语言模型的效率。相关代码已公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.13379</guid><pubDate>Fri, 27 Jun 2025 02:34:37 +0800</pubDate></item><item><title>462. cs.CL-利用SMILE进行大型语言模型可解释性分析：基于局部解释的统计模型无感知解读</title><link>https://arxiv.org/pdf/2505.21657</link><description>Background: 
大型语言模型如GPT、LLAMA和Claude在文本生成方面变得非常强大，但它们仍然是黑盒模型，难以理解它们是如何做出决策的。这种方法不透明性在需要信任和问责制的领域尤其成问题。SMILE提供了一种新方法来解释模型对提示不同部分的响应方式，通过略微改变输入、测量输出的变化并强调哪些词语具有最大的影响来实现。我们对几种领先的LLM进行了测试，并通过准确度、一致性和稳定性等指标展示了SMILE提供了清晰可靠的解释，使这些模型更容易理解，促进了AI的透明性和可信度的提升。

Innovation: 
SMILE是一种模型无感知的方法，通过轻微改变输入并测量输出变化来解释大型语言模型的响应，生成简单可视化的热力图来突出关键部分，提供了清晰和可靠的解释方法。这种方法超越了现有技术，提升了对大型语言模型内部工作原理的理解可能性。

Conclusion: 
通过使用SMILE，大型语言模型变得更容易理解，使其在信任和问责方面更具透明性，使得AI系统更加值得信赖。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.21657</guid><pubDate>Fri, 27 Jun 2025 02:34:36 +0800</pubDate></item><item><title>463. cs.CL-评估大语言模型在肺栓塞登记中自动临床提取的性能：不同模型规模、版本和参数的表现</title><link>https://arxiv.org/pdf/2503.21004</link><description>Background: 
肺栓塞（PE）登记可以加速临床研究改进实践，但依赖于人工密集的手动提取放射报告中的概念。研究者们探索了是否可以利用开源的大语言模型（LLMs）自动提取计算机断层扫描肺栓塞（CTPE）报告中的概念，而不损失数据质量。

Innovation: 
本文测试了几种不同时代和参数数目的Llama 3变体模型和一个评审模型Phi 4 14B，共250份由MIMIC IV和杜克大学双重注释的CTPE报告，评估模型大小、温度和样本量对准确性的影响，结果显示大规模模型的准确率较高，且不同数据集之间性能差异不大，表明模型具有外部稳健性。双模型一致性审查（L3 70B加Phi 4 14B）可以可靠地提取关于肺栓塞的存在性、位置、血栓负担、右心室压力和图像质量等细节的概念，且有较低的不一致性率和高的一致率。

Conclusion: 
大语言模型能够提供一种可扩展、准确的解决方案来处理PE登记中的数据提取，而双模型审查流程能够在最小的人类监督下保证数据质量。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.21004</guid><pubDate>Fri, 27 Jun 2025 02:34:33 +0800</pubDate></item><item><title>464. cs.CL-在症状检查器中评估罕见疾病诊断性能：一种合成案例模拟方法</title><link>https://arxiv.org/pdf/2506.19750</link><description>Background: 
症状检查器（SCs）能够根据用户的症状提供定制化的医疗信息。但在更新算法时，防止罕见疾病诊断性能意外下降（特别是在更新算法时）是一个关键挑战，因为没有实用的预部署评估方法。对于罕见疾病，由于用户反馈数据不足以获取，因此难以进行充分的评估。因此，本研究提出了并验证了一种名为合成案例模拟方法的新颖途径，旨在在部署前高效且低成本地评估算法更新对单一罕见疾病诊断性能的影响。

Innovation: 
本研究提出了合成案例模拟方法，该方法通过使用人类表型组数据库（HPO）中的疾病-表型注释生成合成病例，以模拟症状检查器中与用户的对话，预测诊断性能的变化。这种方法通过回顾性比较预测变化与实际性能指标来验证其有效性，并且用于八个罕见疾病的过往算法更新的实验显示了显著的相关性，证明了其在罕见疾病诊断性能预评估领域的有效性。

Conclusion: 
该研究提出的方法能够在不影响透明度和解释性的前提下，高效且低成本地评估罕见疾病的症状检查器算法变化。这种方法基于专家编制的公共医疗知识数据库，为症状检查器开发者提供了改进诊断性能的有效途径。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19750</guid><pubDate>Fri, 27 Jun 2025 02:34:33 +0800</pubDate></item><item><title>465. cs.CL-TAPS: 结构化标签引导的工具增强个性化</title><link>https://arxiv.org/pdf/2506.20409</link><description>Background: 
近期，工具增强的大规模语言模型已被开发出来，能够与外部工具互动，从而提高完成复杂用户任务的能力。现有的方法忽视了个性化在指导工具使用中的作用。本文研究了如何有效地将用户偏好整合到面向目标的对话代理中。经过深入分析，发现大规模语言模型在个性化工具使用方面存在关键缺陷。

Innovation: 
本文引入了一种名为TAPS的新颖解决方案，它通过利用结构化标签工具和基于不确定性工具探测器来增强个性化工具使用。TAPS显着提高了大规模语言模型将用户偏好融入其中的能力，达到了开源模型在NLSI任务上的新最先进水平

Conclusion: 
通过TAPS，使大语言模型在个人化工具使用方面有了显著提升，能够在开放源代码模型上实现NLSI任务的新最先进水平。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20409</guid><pubDate>Fri, 27 Jun 2025 02:34:32 +0800</pubDate></item><item><title>466. cs.CL-通过信息几何和量子度量重新思考大语言模型训练</title><link>https://arxiv.org/pdf/2506.15830</link><description>Background: 
在大型语言模型（LLMs）中，优化过程发生在高维度参数空间中，并且具有非欧几里得结构。信息几何通过引入弗什信息度量来描绘这一景观，使得通过自然梯度下降实现更为严谨的学习成为可能。尽管这种方法在实际应用中往往不切实际，但它可以阐明诸如尖锐极小值、泛化能力和已观察到的缩放定律等现象。

Innovation: 
文章提出，基于曲率感知的方法可以加深我们对LLM训练的理解。此外，文章推测了基于Fubini-Study度量和量子弗洛克信息的量子类比，暗示在量子增强系统中实现高效的优化的可能性。

Conclusion: 
文章总结认为，通过信息几何和量子度量来重新思考LLM的训练，可以为更深入理解LLM的优化过程提供新的视角，并且在未来可能存在利用量子计算提升优化效率的可能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15830</guid><pubDate>Fri, 27 Jun 2025 02:34:27 +0800</pubDate></item><item><title>467. cs.CL-LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey</title><link>https://arxiv.org/pdf/2505.00753</link><description>Background: 
近年来大语言模型（LLMs）的发展引发了一系列关于建立完全自主代理的兴趣。然而，基于LLM的完全自主代理仍然面临诸多挑战，包括由幻觉导致的可靠性限制、处理复杂任务的难度以及重大的安全和伦理风险等问题，这些都限制了它们在现实世界应用中的可行性和可信度。为克服这些挑战，提出了建立基于大语言模型的人机系统（LLM-HAS），通过将人类提供的信息、反馈或控制纳入系统，以增强系统的性能、可靠性和安全性。这些系统利用人类和大语言模型代理的互补优势实现协作。

Innovation: 
本文提供了首个全面且结构化的LLM-HAS综述。它明确了基本概念，系统地呈现了这些系统核心组件，包括环境与特征描述、人类反馈、交互类型、协调和通信。此外，探讨了人机协作中的新兴应用、独特挑战及机遇。旨在促进这一快速演进的跨学科领域的进一步研究创新。

Conclusion: 
通过整合现有知识并提供结构化的概览，本文旨在促进这一领域进一步的研究和创新。附加的文献和资源列表可在以下网址找到：this https URL.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.00753</guid><pubDate>Fri, 27 Jun 2025 02:34:24 +0800</pubDate></item><item><title>468. cs.CL-大型语言模型支持论证主义吗？</title><link>https://arxiv.org/pdf/2412.14501</link><description>Background: 
近年来，诸如ChatGPT和Claude等大型语言模型（LLMs）的出现为语言哲学提出了新的挑战，特别是在语言意义和表征的本质方面。传统上，LLMs主要通过分布语义学进行理解，但本文则探讨了罗伯特·布莱朗的推论语义学作为一种替代的理论基础，来理解这些系统。本文分析了推论语义学的关键特征，如反表征主义立场、逻辑表达主义和准组成性方法，并发现它们与基于Transformers的LLMs的体系结构和功能特性相吻合。

Innovation: 
本文将布莱朗的推论语义学应用于大型语言模型，探讨了其反表征主义性质，并进一步发展了一种基于交互性和规范性的适合于LLMs的共识真理理论。尽管存在理论上的分歧，本文认为推论语义学为理解LLMs是如何产生意义而不依赖于外部世界表征提供了有价值的见解。

Conclusion: 
本文从理论上说明了大型语言模型可能挑战传统语言哲学中的严格组成性和语义外部主义的假设，但仍需进一步的实证研究来验证这些理论上的观点。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.14501</guid><pubDate>Fri, 27 Jun 2025 02:34:24 +0800</pubDate></item><item><title>469. cs.CL-语言模型训练中添加或移除个人信息引发的隐私涟漪效应</title><link>https://arxiv.org/pdf/2502.15680</link><description>Background: 
由于个人身份信息（PII）的敏感性，其所有者可能有权控制其在大规模语言模型（LLM）训练中的包含与否或请求删除。此外，由于不断演变的数据集管理技术、数据重新抓取以重新训练或新的下游微调阶段的引入，PII 可能会被添加或移除。因此，PII 在训练数据集中的记忆量和可记忆性是模型在训练管道中的一项动态属性，受到常见更改的设计选择的影响。研究人员发现，不同的 PIIs 在训练过程中的记忆特性存在不同的动态变化，主要体现在以下三点：（1）在训练后期出现相似的 PIIs 会导致早期看到的序列被重新记忆，我们称之为辅助记忆；（2）添加 PIIs 可以显著增加其他 PIIs 的记忆性；（3）移除 PIIs 可能会导致其他 PIIs 被重新记忆。这些现象构成了隐私风险中的第一和第二级风险，模型创建者在训练模型时应考虑这些风险，以避免新的 PIIs 被重新记忆。

Innovation: 
研究揭示了 PIIs 在语言模型训练过程中的动态记忆特性，提出了辅助记忆、添加 PIIs 增加其他 PIIs 记忆性，以及移除 PIIs 导致其他 PIIs 记忆性的三个新型现象。这些现象揭示了 PIIs 的复杂记忆机制及其在不同阶段的影响，为理解和控制模型中的隐私风险提供了新的视角。这项研究通过深入分析模型在不同训练阶段的数据处理，展示了 PIIs 记忆量和可记忆性的动态变化，强调了设计和调整模型以减少 PIIs 回忆的可能性。

Conclusion: 
模型创建者在训练模型时应该考虑这些隐私风险，以避免新的 PIIs 被重新记忆，从而减少数据泄露的风险。研究成果有助于数据隐私保护，促进更负责任的 AI 技术应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.15680</guid><pubDate>Fri, 27 Jun 2025 02:34:23 +0800</pubDate></item><item><title>470. cs.CL-A3：一种用于注意力机制的分析性低秩逼近框架</title><link>https://arxiv.org/pdf/2505.12942</link><description>Background: 
大型语言模型表现出卓越的性能，但其庞大的参数量导致部署成本极高。现有方法主要通过最小化单个线性层的输出误差来进行低秩逼近，但没有考虑Transformer的架构特性；并且将大权重矩阵分解为两个小的低秩矩阵，导致在运行时引入额外的开销。

Innovation: 
提出了一种后训练低秩逼近框架A3。该框架将Transformer层分解为三个功能组件：QK、OV和MLP，并针对每个组件提供分析性解决方案，以减少隐藏维度同时最小化组件的功能损失（即注意力分数、注意力输出和MLP输出的误差）。此外，这种方法还能直接减少模型的大小、KV缓存大小和FLOPs，且不会引入任何运行时开销。

Conclusion: 
实验结果表明，A3在计算和内存相同预算条件下，低秩逼近后的LLaMA 3.1-70B在WikiText-2数据集上的困惑度为4.69，优于之前的最佳结果7.87。此外，A3还展示了其在KV缓存压缩、量化等方面的高度灵活性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12942</guid><pubDate>Fri, 27 Jun 2025 02:34:22 +0800</pubDate></item><item><title>471. cs.CL-搜索和思考期间自动检索-提炼: LLMs的自主检索增强推理</title><link>https://arxiv.org/pdf/2505.11277</link><description>Background: 
大型语言模型展现了令人印象深刻的推理能力，然而这些模型本质上受限于它们的知识库。检索增强推理可以通过让语言模型查询外部资源来缓解这一限制，但现有方法往往检索到不相关或噪声信息，阻碍了准确的推理。

Innovation: 
本文提出了一种基于强化学习的后训练框架AutoRefine，它采用了新的‘搜索和提炼’模式。AutoRefine在连续查询调用之间引入了明确的知识提炼步骤，使模型能够迭代地筛选、精炼和组织证据，然后再生成答案。此外，该框架结合使用了针对检索的特定奖励以及答案正确性的奖励，使用分组相对策略优化方法。实验表明，AutoRefine在单跳和多跳问答基准上显著优于现有方法，特别是在复杂的多跳推理场景中表现尤为突出。深入分析显示，AutoRefine会频繁进行高质量的查询，并能有效地综合证据。

Conclusion: 
AutoRefine显著提升了语言模型在复杂推理任务中的表现，通过引入分组相对策略优化的检索特定奖励和高效的证据提炼过程，进一步增强了模型的准确性和泛化能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.11277</guid><pubDate>Fri, 27 Jun 2025 02:34:20 +0800</pubDate></item><item><title>472. cs.CL-OpenNER 1.0: 标准化的50多种语言开放访问命名实体识别数据集</title><link>https://arxiv.org/pdf/2412.09587</link><description>Background: 
当前存在多种命名实体识别（NER）数据集，但这些数据集通常是未标准化的，难以在多语言和多本体环境下进行对比和研究。研究人员需要将不同数据集统一标准，以便更好地进行跨语言和跨本体的命名实体识别研究。

Innovation: 
本研究提出了OpenNER 1.0，这是一个标准的、开放获取的命名实体识别数据集集合，包含36个跨52种语言的语料库，涵盖了不同的人类标注本体。研究将原始数据集统一为一个标准表示形式，并提供了支持多语言和多本体环境下的NER研究结构。此外，还使用预训练的多语言和大型语言模型提供了基线结果，以便比较最近模型的性能，并促进未来研究的发展。

Conclusion: 
研究发现，没有一种模型能在所有语言中都表现出色，表明在NLP领域中，特别是在语言模型处理NER任务方面，仍有许多工作需要完成以获得高水平的表现。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.09587</guid><pubDate>Fri, 27 Jun 2025 02:34:17 +0800</pubDate></item><item><title>473. cs.CL-奖励引导型推测性解码以提高大型语言模型推理效率</title><link>https://arxiv.org/pdf/2501.19324</link><description>Background: 
本文介绍了奖励引导型推测性解码（RSD），这是一种旨在提高大型语言模型（LLMs）推理效率的新框架。与现有的推测性解码方法相比，RSD 使用了一个轻量级草案模型与一个更强大的目标模型相结合，并引入一种控制偏见的方法来优先考虑高奖励输出。这种方法在平衡计算成本和输出质量之间提供了优化。它通过理论分析证明，基于阈值的混合策略实现了资源利用和性能的最佳平衡。实验结果表明，RSD 在使用目标模型推理时可以显著提高效率（最多减少 4.4 倍的 FLOPs），同时比并行解码方法平均提高了更高的准确性（最多提高 3.5%）。

Innovation: 
RSD 引入了一种结合轻量级草案模型和更强大目标模型的新颖框架。它通过引入一种控制偏见的方法来优先考虑高奖励输出，以优化计算成本和输出质量之间的平衡。此外，它提出了一种基于阈值的混合策略，实现了资源利用和性能的最佳平衡，并通过实验证明了该方法的有效性。

Conclusion: 
RSD 提供了一种在资源密集型场景中部署 LLMs 的稳健且经济高效的途径，已在难度较大的推理基准测试中展示了显著的效率增益和准确性提升。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.19324</guid><pubDate>Fri, 27 Jun 2025 02:34:14 +0800</pubDate></item><item><title>474. cs.CL-CodeLutra：通过偏好引导的细化提升LLM代码生成</title><link>https://arxiv.org/pdf/2411.05199</link><description>Background: 
大型语言模型（LLMs）在代码生成方面带来了革命性变化，但需要大量资源，并且倾向于过度泛化，从而限制了其特定任务的效率。尽管可以通过微调较小的、开源的LLMs提供成本效益较高的替代方案，但常用的监督方法仅依赖于正确示例，导致错过了失败带来的有价值见解。

Innovation: 
CodeLutra框架引入了一种新的方法，通过利用正确和错误的代码尝试，不仅使用成功的结果，还比较成功与失败的输出，运用迭代的偏好引导细化来更好地逼近期望结果。这种方法无需大规模数据集或辅助模型即可缩小与最先进的大型模型之间的性能差距。例如，在一项具有挑战性的数据分析编码任务中，使用仅500个样本，Llama-3-8B的准确率从28.2%提升到48.6%，接近GPT-4的水平。通过从成功和失败中学习，CodeLutra提供了一种可扩展且高效的高质量代码生成途径，使较小的开源模型更具竞争力，能够与领先的闭源替代方案抗衡。

Conclusion: 
CodeLutra通过从成功和失败中学习提供了一种新的路径，为高质量代码生成提供了可扩展且高效的方法，使较小的开源模型更能与领先的闭源模型竞争。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.05199</guid><pubDate>Fri, 27 Jun 2025 02:34:14 +0800</pubDate></item><item><title>475. cs.CL-使用音节提示：提升多语言大模型对非拉丁字母语言的表现</title><link>https://arxiv.org/pdf/2411.02398</link><description>Background: 
尽管多语言大语言模型（LLM）已经在各种基准测试中取得了显著的性能，但它们在非拉丁字母语言上的表现仍然不佳。这种差异源自于LLM在培训时是以拉丁字符为基础的书写字母表，这遮蔽了它们与非拉丁字母语言共享的语音学特征。因此，非拉丁字母语言的表现通常比拉丁字母语言较差。本文探讨了通过利用音节转录作为补充信号来生成对书写系统不变的表示的方法。研究表明，结合使用音节信号可以提高对非拉丁字母语言和拉丁字母语言的表现，特别在缩小两者性能差距方面效果显著。详细的实验表明，音节和书写系统在上下文学习过程中检索到的示例是不同的，因此提出了混合上下文学习（Mixed-ICL）检索策略，这种方法可以在两种检索方法的基础上进一步聚合，从而显著提高对拉丁字母语言（最高达12.6%）和非拉丁字母语言（最高达15.1%）的性能，相比于随机上下文学习检索策略效果更好。

Innovation: 
本文创新性地提出利用音节转录信号作为补充信号来提升大语言模型对非拉丁字母语言的表现，这是基于音节转录与书写系统不会互相遮蔽语音学特征，通过混合上下文学习策略为拉丁字母语言和非拉丁字母语言提供显著性能提升。利用音节和书写系统分别为上下文学习检索出不同示例的方法提出了一种新的混合策略。

Conclusion: 
研究展示了结合音节信号可以显著改善大语言模型在非拉丁字母语言和拉丁字母语言上的表现，特别是用于缩小两者之间的性能差距，通过详细实验验证了混合上下文学习策略的有效性，从而显著提升了两种书写系统的性能，相比于随机上下文学习检索策略，提升显著。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.02398</guid><pubDate>Fri, 27 Jun 2025 02:34:13 +0800</pubDate></item><item><title>476. cs.CL-捕获作者和文档中的风格</title><link>https://arxiv.org/pdf/2407.13358</link><description>Background: 
深度自然语言处理（NLP）模型通常使用词和文档的连续和低维表示。然而，现有的模型很少研究作者的表示学习。这些表示可以用于多项NLP任务，如作者识别和分类，或在推荐系统中使用。但现有研究的局限性在于它们未能明确捕捉到写作风格，使得这些模型在文学数据上的应用受到限制。

Innovation: 
本文提出了一种新的基于变分信息瓶颈（VIB）的架构，该架构能够学习作者和文档的嵌入表示，同时具有风格约束。该模型是一种预训练文档编码器的微调。通过增加预定义的风格特征来刺激写作风格的检测，使表示轴便于解释，与写作风格指标相关。

Conclusion: 
本文的方法在三个数据集上进行了评估：来自古腾堡项目的文学语料库、Blog Authorship语料库以及IMDb62。在作者识别方面，本文的方法与强大/最新的基线方法相比，能够更好地捕捉作者的风格特征。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2407.13358</guid><pubDate>Fri, 27 Jun 2025 02:34:08 +0800</pubDate></item><item><title>477. cs.CL-比较检索增强和参数高效微调在大型语言模型隐私保护个性化中的应用</title><link>https://arxiv.org/pdf/2409.09510</link><description>Background: 
尽管大型语言模型（LLMs）在各种搜索、推荐和问答任务中产生了显著影响，但保护用户隐私的个性化方法仍然受到相对较少的探索。现有研究主要通过检索增强生成（RAG）进行个性化，这种方法通过增加用户个人信息来丰富输入提示，生成个性化输出。本研究探讨了RAG的另一种方法，即通过对用户依赖的LLM参数进行参数高效微调（PEFT）来学习用户特定参数。现有的研究较少系统地研究PEFT在LLM个性化中的应用，并且比较了基于RAG和PEFT的解决方案在LaMP基准中七个多样化数据集上的性能，以揭示这两种方法的有效性差异和互补性。研究结果表明，与非个性化LLMs相比，基于RAG和PEFT的个性化方法分别平均提高了14.92%和1.07%，而结合RAG和PEFT则进一步提高了15.98%，表明这两种方法的有效集成可以显著提高个性化文本生成的效果。此外，研究发现可用的用户数据量与PEFT的有效性正相关，这表明RAG特别适用于冷启动用户，而更多的用户特定数据会提高PEFT的效果。

Innovation: 
本文首次系统地研究了参数高效微调（PEFT）在大型语言模型个性化中的应用，比较了PEFT与检索增强生成（RAG）在多重数据集上的性能，并展示了结合使用这两种方法的有效性。同时，研究还发现了用户数据量与PEFT有效性之间的正相关关系，揭示了RAG和PEFT在不同用户情境下的应用特性。

Conclusion: 
综合而言，本文通过一系列系统实验方法比较了RAG和PEFT在大型语言模型个性化中的应用效果。研究发现，PEFT可以改善个性化，并与RAG结合可进一步提升效果。同时强调了用户特定数据可增强个性化表现的重要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.09510</guid><pubDate>Fri, 27 Jun 2025 02:34:07 +0800</pubDate></item><item><title>478. cs.CL-通过迭代效用最大化进行多检索增强模型的排名学习</title><link>https://arxiv.org/pdf/2410.09942</link><description>Background: 
本文探讨了设计一个统一搜索引擎以服务于多个检索增强生成（RAG）代理的问题。每个代理具有不同的任务、骨干大规模语言模型（LLM）和RAG策略。研究背景在于如何优化搜索引擎以提高每个代理的效用函数，并适应实时反馈以更好地服务每个代理。实验中利用KILT基准数据集的18个RAG模型来验证方法的有效性。

Innovation: 
本文提出了一种迭代方法，其中搜索引擎为RAG代理生成检索结果，并在其离线阶段收集反馈以优化搜索引擎。通过期望最大化算法进行迭代优化，目标是最大化每个代理的效用函数。同时，该方法在在线设置中得到了适应，使得搜索引擎可以根据实时反馈进行调整，从而更好地服务每个代理。此外，通过全面的消融研究来探索方法的各种方面。

Conclusion: 
实验结果证明，本文的方法在18个RAG模型上平均优于基线方法。这种方法能够有效地根据收集的反馈为每个RAG代理个性化检索结果。最后的研究表明，该方法在不同方面都展现了其有效性和实用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.09942</guid><pubDate>Fri, 27 Jun 2025 02:34:05 +0800</pubDate></item><item><title>479. cs.CL-HalluSegBench：通过反事实视觉推理评估分割幻觉</title><link>https://arxiv.org/pdf/2506.21546</link><description>Background: 
近期在视景语言分割领域的进展显著提升了基于图像的视觉理解能力。然而，这些模型常常会表现出幻视（hallucination），即生成不属于图像内容的对象分割掩模，或者错误地标记无关区域。现有的分割幻视评估协议主要关注标签或文本幻视，但不操纵视觉上下文，这限制了它们诊断关键故障的能力。

Innovation: 
我们引入了HalluSegBench，这是首个专门用于通过反事实视觉推理来评估视觉接地中幻视的基准。我们的基准包括一个新颖的数据集，包含1340个反事实实例对和281个独特的对象类别，以及一组新引入的度量标准，可量化在视觉上一致的场景编辑下幻视的敏感性。实验结果表明，由视觉驱动的幻视比由标签驱动的幻视更为普遍，模型通常会持续错误地进行分割，强调了进行反事实推理以诊断定位准确性的需求。

Conclusion: 
HalluSegBench实验结果显示，由视觉驱动的幻视比由标签驱动的幻视更为普遍，模型往往持续错误分割，这表明需要通过反事实推理来诊断视觉定位的准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21546</guid><pubDate>Fri, 27 Jun 2025 02:34:05 +0800</pubDate></item><item><title>480. cs.CL-SceneGenAgent：使用编码代理实现精确工业场景生成</title><link>https://arxiv.org/pdf/2410.21909</link><description>Background: 
工业制造中的场景建模对于模拟至关重要。尽管大规模语言模型（LLMs）已经在从文本描述生成通用3D场景方面取得了显著的进步，但在使用LLMs生成工业场景时仍面临独特挑战，因为工业场景需要精确的测量和定位，需要对空间布局进行复杂的规划。

Innovation: 
该研究引入了SceneGenAgent，这是一种基于LLM的通过C#代码生成工业场景的代理模型。SceneGenAgent通过结构化和计算格式的布局规划、布局验证和迭代优化，确保了工业场景生成中的高精度需求。实验结果显示，使用SceneGenAgent驱动的LLMs在真实的工业场景生成任务中的成功率高达81.0%，满足大部分场景生成需求。为了进一步增强其可访问性，研究者开发了SceneInstruct数据集，用于微调开源LLM以集成到SceneGenAgent中，实验表明基于SceneInstruct微调的LLM取得了显著性能提升，Llama3.1-70B逼近了GPT-4o的能力。

Conclusion: 
实验结果表明，利用SceneGenAgent增强的LLMs在真实工业场景生成任务中的成功率高达81.0%，并有效满足了大多数场景生成需求。SceneInstruct数据集的构建进一步提升了开源LLMs的性能，使得Llama3.1-70B接近GPT-4o的能力。项目代码和相关数据已公开发布。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.21909</guid><pubDate>Fri, 27 Jun 2025 02:34:05 +0800</pubDate></item><item><title>481. cs.CL-Mind2Web 2：利用代理作为裁判评估代理型搜索</title><link>https://arxiv.org/pdf/2506.21506</link><description>Background: 
代理型搜索，比如深度研究系统，利用大规模语言模型自主浏览网络、整合信息并返回全面的带有引文的支持答案，这种技术代表了用户与大规模网络信息交互方式的重大转变。尽管能够提供更高的效率和认知卸载，但这种搜索的复杂性与开放性超出了现有的评估标准和方法的范围，后者通常假设短时间内的搜索范围和固定的答案。

Innovation: 
引入了Mind2Web 2，这是包含130个现实场景、高质量且长时间范围任务的新基准，需要实时网络浏览和大量信息综合。设计了基于树状结构评判标准的任务特定裁判代理，用于自动评估答案的正确性和出处归因。此外，还提出了代理作为裁判的框架，以应对动态和复杂答案的评估挑战，并对各大前沿代理型搜索系统和人类表现进行了全面评估，提供了详细的错误分析以利于未来的发展。

Conclusion: 
最佳系统OpenAI深度研究（Deep Research）已能实现人类表现的50-70%，但仅花费了人类一半的时间，显示出巨大的潜力。总体而言，Mind2Web 2为代理型搜索系统的发展和评估提供了严格的基石，为下一代代理型搜索系统的研发提供了坚实的基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21506</guid><pubDate>Fri, 27 Jun 2025 02:34:03 +0800</pubDate></item><item><title>482. cs.CL-具有传染性脱逃的捣蛋者让诚实小镇陷入混乱</title><link>https://arxiv.org/pdf/2410.16155</link><description>Background: 
随着大型语言模型的发展，它们在各个领域的代理中得到广泛应用。代理的关键组件是记忆，它存储重要信息但容易受到攻击。现有研究主要关注单个代理攻击和共享记忆攻击，但在现实世界中，往往涉及独立的记忆系统。本文提出了一种新的任务‘Troublemaker Makes Chaos in Honest Town (TMCHT)’，旨在评估多代理、多拓扑结构的文本攻击。该任务关注一个攻击代理试图误导整个社会代理，但面临着网络结构不完整和大规模系统的挑战，这些问题归因于“毒性消失”现象。这些挑战要求新的方法来应对和解决.

Innovation: 
本文提出了Adversarial Replication Contagious Jailbreak (ARCJ) 方法，该方法通过优化检索后缀，使中毒样本更容易被检索，通过优化复制后缀赋予中毒样本传染性。实验证明了该方法在TMCHT任务中的优越性，在线性拓扑中提高了23.51%，星形拓扑中提高了18.95%，在100个代理设置中提高了52.93%。这鼓励社区关注多代理系统安全.

Conclusion: 
本文通过提出TMCHT任务和ARCJ方法，有效应对了多代理攻击中的挑战，验证了新的方法在解决毒性消失现象上的优越性，并强调了多代理系统安全的重要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2410.16155</guid><pubDate>Fri, 27 Jun 2025 02:34:01 +0800</pubDate></item><item><title>483. cs.CL-Latent Prototype Routing: 实现混合专家模型中接近完美的负载均衡</title><link>https://arxiv.org/pdf/2506.21328</link><description>Background: 
混合专家（MoE）架构已成为高效扩展大规模语言模型（LLMs）的关键策略。然而，当前的MoE系统存在严重的负载不平衡问题，导致大部分模型容量和计算资源未能充分利用。在训练和推断过程中，只有少量专家被激活，这使得模型的潜在能力未能得到充分发挥。为此，本文重新审视了专家路由方法，并提出了Latent Prototype Routing（LPR），这是一个新的路由框架，能够推广现有方法，同时促进更加平衡的专家使用，而不影响下游任务的性能。

Innovation: 
提出了Latent Prototype Routing（LPR）新型路由框架，该框架能够推广现有方法，实现更加平衡的专家使用，从而提高模型的负载均衡能力，同时不降低下游任务的性能。广泛的实验证明，LPR能够将专家负载的Gini系数从0.70降低到0.035，并将最小和最大负载专家比率从1e-6提高到0.70，达到了接近完美的负载平衡。

Conclusion: 
LPR框架显著改善了MoE模型的资源利用效率，通过减少专家负载的不平衡程度，提高了模型的负载平衡程度，并且在多个开源MoE模型上（包括DeepSeek-V3、Qwen3-MoE和Mixtral）有效验证了其优势。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21328</guid><pubDate>Fri, 27 Jun 2025 02:34:01 +0800</pubDate></item><item><title>484. cs.CL-从大规模语言模型学习评估模型以生成序列</title><link>https://arxiv.org/pdf/2308.04386</link><description>Background: 
传统的序列生成评估依赖于如BLEU和ROUGE等度量标准，这些度量标准着重于n-gram的重叠，无法全面捕捉生成文本序列的语义准确性。尽管Bleurt和Comet等基于模型的度量标准提供了有希望的解决方案，但这些方法通常受限于评价数据的稀缺性，因为评价模型的训练需要大量标注的数据。

Innovation: 
本文提出了一种新的评价模型训练方法——自定义序列评估度量（CSEM），该方法分为三个阶段，利用大语言模型生成标注数据，从而避免了需要人工标注数据。此外，CSEM 的范围扩展到了支持多种评价类型，包括单方面、多方面、无参考和有参考评价，使得度量标准可以适应不同的现实场景。实验结果表明，使用 CSEM 训练的评价模型能够有效提高序列质量，特别是在强化学习和重排序实验中，使用 CSEM 开发的度量标准优于传统评价度量标准，提高了生成序列的质量。

Conclusion: 
CSEM 方法通过利用大语言模型生成大量有效的标记数据，成功克服了传统方法对大规模人工标注数据的依赖。此外，CSEM 支持多种类型的评价，为文本生成质量评估提供了更灵活和有效的工具。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2308.04386</guid><pubDate>Fri, 27 Jun 2025 02:34:00 +0800</pubDate></item><item><title>485. cs.CL-MockLLM: 一种用于在线求职招聘的多智能体行为协作框架</title><link>https://arxiv.org/pdf/2405.18113</link><description>Background: 
在线招聘平台改变了求职和招聘流程，提高了简历筛选过程中的人岗匹配质量。传统方法主要依赖对简历和职位描述的文本分析，但这种做法无法充分模拟动态和互动过程，对有效招聘造成了限制。近年来，大型语言模型（LLMs）的进步展示了在模拟基于角色的对话方面的潜力，使其适用于招聘场景。因此，需要一种能模拟和提高人岗匹配质量的在线求职面试模拟框架。

Innovation: 
提出了一种名为MockLLM的新颖框架，用于生成和评估面试模拟对话。MockLLM利用多智能体协作技术，同时模拟面试官和求职者角色，实现互动匹配，并通过反思记忆生成和动态策略修改来提高匹配质量。与现有方法相比，MockLLM在匹配准确性、可扩展性和跨岗位领域适应性方面表现出更优性能。

Conclusion: 
MockLLM框架在真实的招聘平台Boss Zhipin上的实验结果表明，该框架在求职面试模拟方面具有显著优势，能够有效提升候选人评估和在线招聘的效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.18113</guid><pubDate>Fri, 27 Jun 2025 02:33:52 +0800</pubDate></item><item><title>486. cs.CL-揭示大型语言模型中的因果推理：现实还是幻觉？</title><link>https://arxiv.org/pdf/2506.21215</link><description>Background: 
大型语言模型（LLMs）在因果推理能力方面仍然面临挑战。尽管LLMs在理解上下文因果关系和遵循因果法则的响应方面表现出了多样化的能力，但它们是否真正具备与人类相似的因果推理能力仍然是个疑问。现有证据表明，LLMs的因果推理能力主要局限于浅层（第一级）因果推理，缺乏人类那样深层（第二级）的因果推理能力。通过深入研究基于变换器的LLMs的自回归机制，表明其因果性并不是内在固有的。研究人员引入了一个新的因果问题基准——CausalProbe-2024，LLMs在该基准上的表现大幅下降，进一步证实了它们仅具备浅层因果推理能力。

Innovation: 
本文通过一个新的因果问答基准CausalProbe-2024和G^2-Reasoner方法，揭示了LLMs在因果推理方面的局限性。G^2-Reasoner方法将通用知识和目标导向的提示融入到LLMs的因果推理过程中，显著提高了LLMs在新颖和反事实情境下的因果推理能力。此研究为LLMs从浅层因果推理向深层因果推理迈进提供了一个新的途径。

Conclusion: 
本文的工作揭示了LLMs在因果推理上的新路径，不仅超越了第一级因果推理，还在朝着第二级因果推理迈进。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21215</guid><pubDate>Fri, 27 Jun 2025 02:33:51 +0800</pubDate></item><item><title>487. cs.CL-ScalaBL：利用随机 variational 子空间推断的大规模语言模型可扩展贝叶斯低秩适配</title><link>https://arxiv.org/pdf/2506.21408</link><description>Background: 
尽管大型语言模型（LLMs）在许多领域中得到了广泛的应用，但它们容易生成错误信息且缺乏准确性，因此对这些模型进行不确定性量化变得至关重要，特别是在高风险领域，如自主性和医疗保健。先前的工作通过在微调模型的低秩适应（LoRA）参数上进行贝叶斯深度学习方法的推理，使这一问题更为可行。然而，这些方法在尝试扩展到更大的LLMs时会遇到困难，因为它们需要更多的参数比LoRA方法多。

Innovation: 
本文提出了一种名为ScalaBL的方法，该方法在LoRA秩$r$的$r$维子空间中进行贝叶斯推断。通过将LoRA参数重新用作投影矩阵，将来自该子空间的样本映射到LLM的完整权重空间中，从而使得使用随机变分子空间推断来学习本文方法的所有参数成为可能。尽管我们的子空间维数较低，但ScalaBL能够在不需要显著增加参数数量的情况下与最先进的方法竞争，同时能够扩展到迄今为止最大的贝叶斯LLM，参数基数比之前的工作增加了一倍多。

Conclusion: 
ScalaBL通过重新利用LoRA参数作为投影矩阵，并在一个较低维度的子空间中执行贝叶斯推断，不仅克服了之前方法的扩展性问题，还允许模型在其完整维度中进行有效的性能学习，从而在有限的参数添加下实现了卓越的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21408</guid><pubDate>Fri, 27 Jun 2025 02:33:49 +0800</pubDate></item><item><title>488. cs.CL-从有限视角构建空间心理模型</title><link>https://arxiv.org/pdf/2506.21458</link><description>Background: 
该论文探讨了视觉语言模型（VLMs）能否像人类一样，仅凭少数视角生成完整的场景想象。人类能够构建空间心理模型，即对未见空间形成内部表征，用于推理解空间布局、视角和运动。现有VLMs在MindCube基准测试中表现出近似随机的效果，这是一个包含21,154个问题、3,268幅图像的新基准数据集，揭示了VLMs在构建空间心理模型方面的显著差距。为此，研究人员设计了一系列评估方法，测试VLMs生成认知地图（位置感知）、视角推理（视角迁移）和动态推理（心理模拟）的能力，以完善空间心理模型的构建。

Innovation: 
该研究提出了解决VLMs在空间心理模型构建方面问题的方法，包括创建看不见的中间视图、自然语言推理链和认知地图。特别地，研究人员创新性地结合了“先建图再推理”（map-then-reason）的协同方法，该方法首先训练模型生成认知地图，然后在其基础上进行推理。这种方法将准确率从37.8%提高到60.8%（+23.0%），进一步通过强化学习将性能提升至70.7%（+32.9%）。发现这种构建和利用内部结构化空间表示以实现灵活推理的过程，对于理解不可见空间有显著改善效果。

Conclusion: 
通过训练模型进行内部映射的推理，准确率显著提高，进一步通过强化学习增强了性能。主要洞察是，这种构建和利用内部结构化空间表示，以实现灵活推理的过程，对于理解不可见空间至关重要。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21458</guid><pubDate>Fri, 27 Jun 2025 02:33:48 +0800</pubDate></item><item><title>489. cs.CL-DiLoCoX: 一种适合分布式集群的大规模低通信训练框架</title><link>https://arxiv.org/pdf/2506.21263</link><description>Background: 
大规模语言模型（LLMs）的分布式训练需要大量的通信，通常依赖于高性能的集中式集群。处理超过100亿参数的模型时，如何在缓慢的网络上进行训练，利用分布式集群的能力，成为了一个挑战。传统的方法如简单的AllReduce难以在保持模型收敛性的同时提高训练速度和模型规模。

Innovation: 
提出了一种名为DiLoCoX的新框架，该框架结合了管道并行性、双优化器策略、通信与局部训练的一步延迟重叠以及自适应梯度压缩方案，显著提高了大规模分布式训练的计算规模和预训练速度。理论分析和实验证明，DiLoCoX可以在1Gbps的网络上预训练一个107亿参数的模型，与AllReduce相比，速度提高了357倍，同时对模型收敛性的影响可以忽略不计。

Conclusion: 
DiLoCoX是首次成功应用于超过100亿参数模型的分布式训练框架，为大规模模型在分布式集群上的高效训练提供了新的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21263</guid><pubDate>Fri, 27 Jun 2025 02:33:48 +0800</pubDate></item><item><title>490. cs.CL-探索低资源音乐生成中的适配器设计权衡</title><link>https://arxiv.org/pdf/2506.21298</link><description>Background: 
大型音乐生成模型（如MusicGen和Mustango）的微调是一个计算密集型的过程，需要对数十亿个参数进行更新，从而需要大量的硬件资源。参数高效微调（PEFT）技术，特别是基于适配器的方法，为在保持模型性能的同时进行微调提供了可能，但也存在多种适配器设计选择（如架构、位置和大小），尚不清楚哪种组合最有效及其原因，特别是在低资源音乐风格中。本文通过研究两种AI音乐模型（MusicGen和Mustango）在两种音乐风格（印度古典音乐和土耳其makam音乐）上的不同适配器配置，探讨了这些问题。

Innovation: 
1. 探究了基于卷积和变换器的适配器在捕捉音乐细节和长距离依赖性方面的优劣；2. 分析了不同规模适配器的计算资源需求，发现中等规模适配器（40M参数）具有最佳的表达性和质量；3. 比较了扩散模型（如Mustango）和自回归模型（如MusicGen）在生成多样化音乐输出和计算效率方面的差异。

Conclusion: 
文章研究发现，卷积适配器在捕捉细腻的音乐细节（如装饰音和短旋律片段）方面表现优异，而变换器适配器在保持对结构即兴创作至关重要的长距离依赖性方面更胜一筹。此外，一系列研究表明，中等规模的适配器（40M参数）在表达能力和质量之间找到了最优平衡。在生成音乐输出的多样性和准确性方面，自回归模型表现出色，但具有略高的生成冗余度；而扩散模型尽管需要更多计算时间和稳定性不足，但在生成更多样且更吻合输入提示描述的音乐方面表现出色。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21298</guid><pubDate>Fri, 27 Jun 2025 02:33:46 +0800</pubDate></item><item><title>491. cs.CL-复杂性感知微调</title><link>https://arxiv.org/pdf/2506.21220</link><description>Background: 
通用的大语言模型（LLMs）经常通过监督微调（SFT）进行特定领域的增强。虽然这可以提高性能，但通过蒸馏大型模型的推理过程以牺牲大量昂贵的调用和更多数据为代价，可以获得更好的结果。现有方法通常会消耗大量资源，提出了一种新的高效微调方案，通过单一标记答案的熵对复杂数据进行识别，从而实现更为精确和高效的结果提升，特别是在减少数据使用量方面表现显著，展示了其在保持性能的同时，使用数据减少了62%的潜力。

Innovation: 
提出了一种新的高效微调方案，基于标记答案的熵对复杂数据进行识别，通过监督微调（SFT）和蒸馏大型语言模型，相比标准的SFT方法平均准确性提高了约12%，同时使用62%更少的数据。这种方法提供了与蒸馏性能相当的表现，但显著减少了训练数据的使用量，展示了复杂性感知微调在提高模型性能和降低资源消耗方面的优势。

Conclusion: 
所提出的复杂性感知微调方案表现出显著的性能提升和资源效率，特别是在减少数据使用方面，提供了可与蒸馏方法媲美的性能，同时降低了训练成本。研究者已公开了代码和数据，以促进后续研究在该领域的发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21220</guid><pubDate>Fri, 27 Jun 2025 02:33:42 +0800</pubDate></item><item><title>492. cs.CL-Logios: 开源希腊多音节光学字符识别系统</title><link>https://arxiv.org/pdf/2506.21474</link><description>Background: 
传统的光学字符识别（OCR）方法在准确识别和数字化希腊多音节文本方面存在局限性。本文介绍了一种专门设计用于准确识别和数字化希腊多音节文本的OCR系统。该系统利用卷积层进行特征提取和循环层进行序列学习，以应对希腊多音节文本特有的挑战。

Innovation: 
该系统采用卷积层和循环层相结合的方法，特别针对希腊多音节文本进行优化，解决了传统OCR方法的局限性，提供了更高的准确性和效率。

Conclusion: 
本文发布了底层模型作为开源库，并将OCR平台提供给学术界使用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21474</guid><pubDate>Fri, 27 Jun 2025 02:33:42 +0800</pubDate></item><item><title>493. cs.CL-low-resource环境下的混合深度学习和信号处理在阿拉伯方言识别中的应用</title><link>https://arxiv.org/pdf/2506.21386</link><description>Background: 
阿拉伯方言识别在语音技术中面临着巨大挑战，这是因为阿拉伯语的语法规则多样性以及缺乏大量标注数据集，尤其是对于不常见的方言而言更加稀缺。因此，在资源有限的情况下，研究人员通过结合经典信号处理技术和深度学习架构来探索新的混合建模策略以解决这一问题。这些方法旨在提高在低资源环境下的阿拉伯方言识别性能，并且已经在有限数据集上进行了训练和评估。

Innovation: 
研究开发了两种混合模型：一种是利用梅尔频率倒谱系数（MFCC）结合卷积神经网络（CNN），另一种是离散小波变换（DWT）特征结合循环神经网络（RNN）。实验结果显示，MFCC与CNN的组合架构表现最佳，准确率达到91.2%，并且在精确率、召回率和F1分数方面均表现优异，相比之下，DWT与RNN的组合架构仅达到66.5%的准确率。这表明，利用频谱特征结合卷积模型特别适用于阿拉伯方言识别，尤其是在使用有限标注数据时。此外，该研究还指出了数据集规模、标签区域重叠以及模型优化方面的限制，并为未来研究指出了改进的方向，如使用更大规模的标注语料库、结合自我监督学习技术和探索更先进的神经网络架构（如Transformer等）.

Conclusion: 
这项研究为资源受限环境下阿拉伯方言识别奠定了坚实的基础，并通过以上实验结果强调了在低资源条件下利用频谱特征结合卷积模型的有效性。未来的研究可以基于这些发现，采用更大规模的标注数据集进一步优化模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21386</guid><pubDate>Fri, 27 Jun 2025 02:33:41 +0800</pubDate></item><item><title>494. cs.CL-SharpZO: 前向传递唯一优化的混合灵敏度感知视觉语言模型提示调优</title><link>https://arxiv.org/pdf/2506.20990</link><description>Background: 
视觉语言模型（VLMs）在各种下游任务上取得了显著性能，但由于需要通过反向传播（BP）访问模型梯度，它们不适合内存受限、仅限推断的边缘设备。之前的工作探索了各种无需BP的调优方法，但这些方法通常依赖高方差的进化策略（ES）或零阶（ZO）优化，常常无法达到满意的性能。

Innovation: 
作者提出了一种混合灵敏度感知零阶优化（SharpZO）方法，专门设计用于通过灵敏度感知暖启动训练来增强ZO VLM调优的性能。SharpZO采用两阶段优化过程：灵敏度感知ES阶段全局探索和平滑损失景观以构造强大的初始化，以及通过稀疏ZO优化进行精细的局部搜索。整个优化依赖于前向传递。理论分析和CLIP模型上的广泛实验表明，SharpZO显著提高了准确度和收敛速度，相对于最先进的前向唯一方法可以获得高达7%的平均性能提升。

Conclusion: 
SharpZO方法通过两阶段的优化过程，显著提高了ZO VLM调优的性能和收敛速度，适用于内存受限的边缘设备。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20990</guid><pubDate>Fri, 27 Jun 2025 02:33:38 +0800</pubDate></item><item><title>495. cs.CL-HumanOmniV2：从理解到跨模态推理</title><link>https://arxiv.org/pdf/2506.21277</link><description>Background: 
随着多模态大型语言模型的迅速发展，理解并解释人类意图的能力已经成为关键能力，这需要详细的推理过程。尽管强化学习（RL）在提升大型语言模型（LLMs）的推理能力方面显示出潜力，但在适应多模态数据和格式方面仍存在诸多挑战。现有模型在全局上下文理解不足和捷径问题两个方面存在缺陷，这些问题分别导致了误解和忽略关键线索的问题。

Innovation: 
该论文提出了一种方法，强调模型在多模态输入中需要对全局上下文有清晰的理解。为此，引入了一个基于大型语言模型的上下文奖励，同时结合格式和准确性的奖励。此外，还引入了一个跨模态推理基准IntentBench，用于评估模型处理复杂人类意图和情感的能力。该方法在多个跨模态基准测试中表现出色，优于其他开源的跨模态模型。

Conclusion: 
该研究提出的方法在多个跨模态基准测试中表现出优异性能，有效地解决了现有模型在全局上下文理解和捷径问题方面的不足，提升了模型的复杂推理能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21277</guid><pubDate>Fri, 27 Jun 2025 02:33:36 +0800</pubDate></item><item><title>496. cs.CL-使用知识图谱生成高质量指令数据以增强大语言模型工具使用</title><link>https://arxiv.org/pdf/2506.21071</link><description>Background: 
当前，教导大型语言模型（LLMs）使用工具对于提升它们的问题解决能力和扩展应用范围至关重要。然而，有效地使用工具是一项挑战，因为它需要对工具功能和用户意图有深入的理解。之前的方法主要依赖LLMs生成指令数据，但这些数据的质量往往不足。在这种背景下，本文提出了一种新的方法，利用知识图谱生成高质量的指令数据，以提高LLMs的工具使用能力和整体表现。知识图谱是富含语义信息的手动整理数据集。我们通过从给定的知识图谱中提取各类查询路径，将其转化为广泛的用户查询，然后将实体之间的关系转化为可执行的工具，解析每个查询路径并划分成详细的解决方案步骤，从而创建高质量的指令数据。实验结果表明，只需对一小部分这种合成数据进行微调，就可以显著提高LLMs的工具使用能力和整体能力。

Innovation: 
本文提出了一种新的方法，利用知识图谱生成高质量的指令数据，以提高LLMs的工具使用能力和整体表现，这种方法基于手动整理的富含语义信息的知识图谱，通过提取查询路径、解析实体关系和转换为工具操作步骤，来生成高质量的指令数据，从而有效改善了LLMs的工具使用效果。

Conclusion: 
实验结果表明，只需对一小部分合成数据进行微调，就可显著提升LLMs的工具使用能力和综合能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21071</guid><pubDate>Fri, 27 Jun 2025 02:33:32 +0800</pubDate></item><item><title>497. cs.CL-通过交互式语言模型对齐提升社会驱动对话中的用户参与度</title><link>https://arxiv.org/pdf/2506.21497</link><description>Background: 
增强用户参与在社会驱动对话中扮演着重要角色。虽然之前的作品优化了模型以在相关知识上进行推理或规划对话行为流程，但用户参与度与知识或对话行为之间的关系微妙且不保证在社会驱动对话中获得用户参与。为此，本文通过利用未来对话发展的信号，让交互式语言模型学习用户参与度。具体而言，本文采用对话意图后的用户反应作为直接相关的参与度指标作为奖励，来对齐交互式语言模型。为实现这一点，本文开发了一个用户模拟器与目标交互式语言模型进行交互，并通过i$times$MCTS（交互式蒙特卡洛树搜索）探索用户与交互式语言模型系统的交互。

Innovation: 
本文开发了一种用户模拟器并通过i$times$MCTS探索了用户与交互式语言模型系统的交互，基于用户反应的奖励对齐交互式语言模型，以直接偏好优化(DPO)实现高级用户参与度的提升。这种方法在两个社会驱动的对话场景下（情感支持对话和积极劝说）中提高了用户参与度的成效。

Conclusion: 
本文方法在两个社会驱动对话场景中有效地提升了用户参与度，展示了通过交互式语言模型对齐方法在增强对话系统用户参与度方面的新颖性和有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21497</guid><pubDate>Fri, 27 Jun 2025 02:33:31 +0800</pubDate></item><item><title>498. cs.CL-语言模型训练中的数据有效性</title><link>https://arxiv.org/pdf/2506.21545</link><description>Background: 
语言模型（LM）的训练依赖于数据。最近的研究致力于提高数据效率，即通过选择最小或最优的训练数据子集来最大化性能。数据过滤、抽样和选择等技术在这一领域发挥重要作用。然而，数据组织的有效性（Data Efficacy）这一概念相对未被深入探索，尽管它对于优化训练数据组织、进一步提高模型性能至关重要。因此，有必要引入一个一般范式——DELT，来考虑语言模型训练中的数据有效性，强调训练数据组织的重要性。

Innovation: 
DELT包括三个组成部分：数据评分、数据选择和数据排序。在这些组成部分中，研究人员设计了基于梯度一致性视角的可学习性-质量评分（LQS），作为一个新的数据评分实例，考虑了每个数据样本的可学习性和质量。此外，还设计了螺旋排序（FO），作为一个新的数据排序实例，旨在解决模型遗忘和数据分布偏差等问题。

Conclusion: 
广泛的实验验证了在语言模型训练中提升数据有效性可以提高模型性能，而无需增加数据规模和模型大小。特别是，提出的LQS与FO的结合效果最显著。通过应用数据选择的方法，可以同时实现数据效率和数据有效性。因此，我们认为数据有效性是一个在语言模型训练中具有前景的基础领域。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21545</guid><pubDate>Fri, 27 Jun 2025 02:33:30 +0800</pubDate></item><item><title>499. cs.CL-学习跳过Transformer的中间层</title><link>https://arxiv.org/pdf/2506.21103</link><description>Background: 
当前的研究显示，Transformer的中间层存在较大的冗余性，而早期层则会汇总信息至token位置。已有方法通常针对单个模块（例如，专家混合层）进行优化，或者独立地跳过层。本文受到这一观察的启发，旨在提出一种新的架构，该架构能够动态跳过中间层到最外层的变量数量层次。这种方法通过学习门控机制基于输入来决定是否绕过中心块，且带有门控注意力机制防止后续token关注跳过的token位置。此外，通过一种'三明治'或'分层归一化'方案控制残差正则化，并采用自适应正则化损失来调节门控稀疏度。

Innovation: 
本文提出了一种新的架构，通过学习门控机制决定是否跳过中间层，并通过门控注意力机制防止跳过的token影响后续计算，同时采用'分层归一化'和自适应正则化损失来优化计算效率。

Conclusion: 
尽管本文的努力旨在简化较差token的计算需求并可能促进多层级表征层次的形成，但在研究的规模下，这种方法并未在验证交叉熵和估算FLOPs之间取得相对于更稠密且层数较少的基线的改进。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21103</guid><pubDate>Fri, 27 Jun 2025 02:33:30 +0800</pubDate></item><item><title>500. cs.CL-《你在找医生吗？：大规模对话AI数据集中用户寻求健康信息的分析》</title><link>https://arxiv.org/pdf/2506.21532</link><description>Background: 
人们越来越多地通过互动聊天机器人从大型语言模型获取健康信息，但这些对话的性质及其内在风险尚未充分探索。这项研究通过过滤大规模的对话AI数据集，建立了包含11,000次对话的HealthChat-11K数据集，来系统地研究用户在21个不同的健康专科中寻求健康信息时的互动行为。

Innovation: 
研究创新点在于，通过建立HealthChat-11K数据集及采用由临床医生驱动的分类体系，系统性地研究了用户在不同健康专科中寻求健康信息时的行为，揭示了用户寻求健康信息的方式和动机，包括常见互动、不完整背景信息的情况、情感行为以及可能引起拍马屁的互动（如引导性问题），强调了需要改进对话AI中部署的大型语言模型的健康支持功能。

Conclusion: 
分析揭示了用户寻求健康信息时的问题，显示了对话AI和大型语言模型在提供健康支持时面临的挑战，并强调了改进这些系统以更好地满足用户需求的重要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21532</guid><pubDate>Fri, 27 Jun 2025 02:33:27 +0800</pubDate></item><item><title>501. cs.CL-超越反应性安全：通过长期模拟实现风险意识大模型对齐</title><link>https://arxiv.org/pdf/2506.20949</link><description>Background: 
随着基于语言模型的代理在高风险社会决策中的影响越来越大，如公共政策和医疗保健领域，确保其正面影响需要深入了解其建议的广泛影响。为此，研究提出了一种概念验证框架，该框架可以预测模型生成的建议在未来如何通过社会系统传播，从而实现更稳健的对齐。此外，通过引入一个包含100个间接危害场景的数据集，研究测试了模型预测看似无害用户提示可能导致的非预期负面影响的能力。这种方法在新数据集上取得了超过20%的改进，并在现有的安全性基准测试（AdvBench、SafeRLHF、WildGuardMix）中实现平均胜率超过70%，表明了实现更安全代理的一个有前途的方向。

Innovation: 
该研究提出了一种概念验证框架，其创新在于：1) 计算模型生成建议对整个社会系统的长期影响；2) 通过引入一个包含100个间接危害场景的数据集，测试模型在预测看似无害用户提示的负面影响方面的表现；3) 在新的数据集和现有基准测试中取得了显著的性能提升，表明了实现更安全代理的一个有前途的方向。

Conclusion: 
该框架不仅显著提高了对语言模型长期安全意识的评估能力，而且在现有基准测试中展示了优越的表现，这表明长期模拟有助于更好地对齐语言模型并确保其服务于社会的长期利益，为实现更安全的代理提供了新的前景。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20949</guid><pubDate>Fri, 27 Jun 2025 02:33:27 +0800</pubDate></item><item><title>502. cs.CL-减量训练，降低泄漏：使用LoRA重新审视LLM微调中的记忆化</title><link>https://arxiv.org/pdf/2506.20856</link><description>Background: 
大型语言模型（LLMs）的记忆化使其容易受到数据提取攻击。尽管预训练中的记忆化已被广泛研究，但针对微调的影响，特别是对于广泛应用的参数高效方法LoRA微调，研究尚不多见。本文重新审视微调中的记忆化，并发现不同微调策略之间存在令人惊讶的分歧，尤其是在模拟能力和数据重复方面，这些因素在预训练和全程微调中强烈影响记忆化，在LoRA微调中并不遵循相同趋势。

Innovation: 
使用更宽松的基于相似性的记忆化度量标准，本文表明LoRA与全程微调相比，显著降低了记忆化风险，但仍保持了强大的任务性能。

Conclusion: 
本文重新探讨了使用LoRA进行微调的记忆化现象，发现了与之前发现的显著不同之处。研究表明，LoRA在减少记忆化风险方面表现优异，同时仍能保持良好的任务性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20856</guid><pubDate>Fri, 27 Jun 2025 02:33:25 +0800</pubDate></item><item><title>503. cs.CL-大型语言模型中的假象理解</title><link>https://arxiv.org/pdf/2506.21521</link><description>Background: 
大型语言模型（LLM）通常通过基准数据集进行评估。然而，基于LLM对特定问题集的答案来推断其能力合理性是什么？本文首先介绍了一个正式框架来解决这一问题。关键在于认识到用于测试LLM的基准，例如AP考试，同样也用于测试人类。然而，这引发了一个问题：这些基准只有在LLM以与人类相似的方式误解概念时才是有效的测试。否则，基准上的成功只表明了“假象理解”，即基于无法与任何人类对概念的理解相协调的答案产生的错觉。

Innovation: 
本文提出了两种量化'假象理解'存在的方法：一种是通过一个特制的基准在三个领域中实施，另一种是一个通用程序，提供了其频率的下限。研究表明，'假象理解'普遍存在，不仅反映了错误的理解，还反映了概念表示内部的深层不一致性。

Conclusion: 
本文发现'假象理解'在模型、任务和领域中普遍存在，而且这种错误理解不仅仅是错误理解，还反映了一种更深层次的概念内部不一致性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21521</guid><pubDate>Fri, 27 Jun 2025 02:33:25 +0800</pubDate></item><item><title>504. cs.CL-MAGPIE：多智能体情境隐私评估数据集</title><link>https://arxiv.org/pdf/2506.20737</link><description>Background: 
随着基于LLM的智能代理的增多，它们在任务调度、协商和资源分配等方面的合作部署也越来越多。这些系统中，隐私保护至关重要，因为代理经常访问企业专用工具和领域特定数据库，这些都需要高度保密。本文探讨了基于LLM的智能代理是否理解情境隐私，即使在非对抗性多轮对话中接受指示后，这些系统是否能够保护推理时刻用户的隐私。现有评估LLM代理情境隐私的基准主要集中在单一回合、低复杂度的任务上，这些任务中私人信息很容易被排除。

Innovation: 
本文提出了一个名为MAGPIE的新基准数据集，包含158个实际情境，覆盖15个领域，这些情境设计得既不能完全排除私人数据又不能完全自由共享信息，以挑战当前模型。此外，该研究评估了最先进的LLM在理解和保护情境隐私以及多智能体协作中的表现，结果显示当前模型在理解情境隐私方面不够 robust，经常错误地将私人数据标记为可共享；在多回合对话中，即使在明确的隐私指令下，这些模型也经常披露私人信息。这些模型在71%的情况下无法完成协作任务。这些结果表明，当前的模型并未充分对齐于同时保护情境隐私和协作任务解决的目标。

Conclusion: 
当前模型在理解情境隐私和保护用户隐私方面存在显著不足，特别是在多智能体协作场景中。需要进一步开发能够更好地理解和保护情境隐私的LLM模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20737</guid><pubDate>Fri, 27 Jun 2025 02:33:25 +0800</pubDate></item><item><title>505. cs.CL-猫和老鼠——生成假文本能否超越检测系统？</title><link>https://arxiv.org/pdf/2506.21274</link><description>Background: 
大型语言模型能够生成令人信服的‘假文本’，这些文本涵盖了学术写作、产品评论以及政治新闻等领域。为了检测这种人工生成的文本，已有很多方法进行了研究。虽然这似乎预示着一个无休止的‘军备竞赛’，但研究表明，尽管新的LLMs使用了更多的参数、训练数据和能源，相对简单的分类器仍旧能够在有限资源下达到不错的检测准确度。这一研究旨在探讨大型模型生成欺骗性文本的能力是否有可能触顶。通过对古典侦探文学风格的‘假文本’进行分析，研究发现，随着模型版本的增加，Gemini显示出更强的生成欺骗性文本的能力，而GPT则没有这种变化。这表明，即使对于更大的模型来说，可靠的检测‘假文本’仍然是可行的，尽管新的模型架构可能会提高它们的欺骗性能力。

Innovation: 
该研究通过考察大型语言模型在古典侦探文学风格文本中的生成能力，提出了一个新的研究视角。特别地，研究发现Gemini在版本增加时表现出更强的生成欺骗性文本的能力，而GPT则没有这种表现。这为理解大型语言模型的生成能力及其对检测系统的影响提供了新的见解。

Conclusion: 
研究表明，即使随着模型规模的增长，模型生成欺骗性文本的能力也有可能达到一个极限，但可靠地检测这种方法生成的‘假文本’仍然是可行的，尽管新的模型架构可能会提高它们的欺骗性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21274</guid><pubDate>Fri, 27 Jun 2025 02:33:18 +0800</pubDate></item><item><title>506. cs.CL-从离线到在线强化学习的LLMs连接</title><link>https://arxiv.org/pdf/2506.21495</link><description>Background: 
本文研究了强化学习方法在语言模型微调从离线模式过渡到半在线模式再到完全在线模式的有效性，特别是在验证性和非验证性任务方面。实验涵盖了验证性数学训练和非验证性指令跟随，使用一系列基准评估方法进行全面比较。研究表明，在不同的设置下，半在线和在线直接偏好优化目标及群体奖励策略优化目标之间具有相似的性能和发展趋势，这些方法都明显优于离线方法。此外，对训练动态和超参数选择策略进行了详细分析，以实现最优结果。最后，证明了联合使用可验证和非验证性奖励进行多任务学习能有效提升两种任务类型的表现。

Innovation: 
研究了语言模型在不同在线程度下的强化学习方法，对比了直接偏好优化和群体奖励策略优化目标，并发现这些目标在在线和半在线情况下具有类似的表现，且都优于离线方法。同时，对训练动态和超参数选择策略进行了详细分析，以实现最优结果。进一步通过联合使用可验证和非验证性奖励实现了跨任务类型的性能提升。

Conclusion: 
通过研究发现，在线和半在线直接偏好优化及群体奖励策略优化目标在语言模型微调中的表现相似且优于离线方法，联合使用两种类型的奖励能够提升整体表现。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21495</guid><pubDate>Fri, 27 Jun 2025 02:33:16 +0800</pubDate></item><item><title>507. cs.CL-从用户交互中调整口语对话模型</title><link>https://arxiv.org/pdf/2506.21463</link><description>Background: 
当前的偏好学习方法主要侧重于基于文本的语言模型，对于复杂的实时语音互动（如中断、插话等）缺乏直接适用性，而且没有明确的说话者分割。因此，本研究旨在提出一种新的偏好对齐框架，以提高口语对话模型在实时对话中的表现，从用户互动中提取信息。通过构建一个包含超过150,000个偏好对的大规模数据集，涵盖语言内容和时间上下文变化的偏好，利用离线对齐方法调整全双工自回归的语音到语音模型。

Innovation: 
提出了一个新的偏好对齐框架，专门针对实时对话场景，特别适用于包含丰富动态特性的对话系统。该研究还创建了一个大规模的数据集，包含来自多轮次原始语音对话的偏好对，由AI反馈标注。通过调整全双工自回归模型，实证实验结果表明反馈可以在多种对话场景中提高口语对话模型的表现，使其产生更为准确、安全和上下文相关的内容。此外，研究通过全面的用户体验评估，确认了多轮对话的效果。

Conclusion: 
研究发现，多个动态因素之间的平衡对于自然实时语音对话系统至关重要。改善口语对话模型需要综合考虑语义内容和时间上下文的上下文对齐，方法的有效性在单轮对话之外的综合测评中得到了验证。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21463</guid><pubDate>Fri, 27 Jun 2025 02:33:15 +0800</pubDate></item><item><title>508. cs.CL-skLEP：斯洛伐克通用语言理解基准</title><link>https://arxiv.org/pdf/2506.21508</link><description>Background: 
目前针对斯洛伐克语自然语言理解（NLU）模型的综合基准尚不存在，导致在斯洛伐克语NLU模型评估方面存在不足。该研究旨在填补这一空白，通过创建全面的斯洛伐克语NLU基准（skLEP）来评估不同类型的斯洛伐克、多语言和英语预训练语言模型的能力，促进斯洛伐克语NLU的研究和发展。

Innovation: 
该研究引入了skLEP，这是专门为评估斯洛伐克语NLU模型的第一个综合基准。它包括了涵盖不同层次的九个多样化的任务，能够全面评估模型性能。此外，该研究对多种特定于斯洛伐克语、多语言以及英语的预训练语言模型进行了系统的评估，并公开发布了包含数据、工具和排行榜的资源，以便于科研的可再现性和未来研究的推进。

Conclusion: 
该研究通过提供一个全面的斯洛伐克语自然语言理解基准（skLEP），填补了斯洛伐克语言在这个领域的空白。研究展示了世界各地的NLU模型在斯洛伐克语语境中的表现，并发布了开源工具和公共排行榜，以此推动今后对该语言自然语言处理研究的发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21508</guid><pubDate>Fri, 27 Jun 2025 02:33:15 +0800</pubDate></item><item><title>509. cs.CL-TopK Language Models</title><link>https://arxiv.org/pdf/2506.21468</link><description>Background: 
稀疏自编码器（SAEs）已成为分析和解读基于转换器的语言模型（LMs）的激活空间的重要工具。然而，SAEs存在一些缺点，这限制了它们的实用性和内部有效性。由于SAEs是在语言模型训练后进行训练的，因此无法确定未能发现某个概念是SAE自身的问题还是语言模型本身没有代表该概念的问题。这种问题在训练条件和架构选择影响SAE学习的特征时被放大。在追踪语言模型在训练期间如何学习概念时，缺乏特征稳定性也使得不同检查点之间的SAE特征比较变得困难。

Innovation: 
为了应对这些限制，本文提出了一种对转换器架构的修改，该修改在选定的层中引入了一个TopK激活函数，使模型的隐藏状态等同于TopK SAE的潜在特征。这种方法消除了事后训练的需要，同时提供与SAEs相当的可解释性。TopK LMs在模型大小、计算效率和可解释性之间提供了有利的平衡。即使进行了简单的架构更改，TopK LMs也保持了其原始能力，同时为模型提供了稳健的可解释性益处。实验结果表明，TopK LMs学习的稀疏表示可以通过目标神经元干预实现成功的引导，并促进了跨越不同检查点和层的神经元形成过程的详细分析。这些特性使TopK LMs成为理解语言模型如何学习和表示概念的稳定和可靠的工具，我们相信这将显著促进未来关于模型可解释性和控制的研究进展。

Conclusion: 
TopK LMs提供了一种平衡模型大小、计算效率和可解释性的方法，不仅保持了原始功能，还在模型解释性方面提供了稳健的优势。实验结果证实了TopK LMs的稀疏表示能够通过目标神经元干预成功引导，并促进了神经元形成过程的详细分析。这些特性使TopK LMs成为理解模型如何学习和表示概念的稳定和可靠的工具，将显著推进未来关于模型可解释性和控制的研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21468</guid><pubDate>Fri, 27 Jun 2025 02:33:13 +0800</pubDate></item><item><title>510. cs.CL-跨语言的Text2Cypher：评估基础模型超越英语的表现</title><link>https://arxiv.org/pdf/2506.21445</link><description>Background: 
近年来，大型语言模型的进步使得自然语言界面能够将用户的问题转换成数据库查询，如Text2SQL、Text2SPARQL和Text2Cypher。虽然这些界面提高了数据库的易用性，但大部分研究仅专注于英语，而对其他语言的评估相对有限。该论文研究了基础语言模型在跨语言Text2Cypher任务上的表现。研究者创建并发布了一个多语言测试集，通过将英语问题翻译成西班牙语和土耳其语，保持原始Cypher查询不变，以进行公平的跨语言比较。多个基础模型被使用标准化提示和度量标准进行评估，结果显示英语表现最佳，其次是西班牙语，而土耳其语表现最差。这被解释为训练数据可用性和语言特性之间的差异。此外，还探讨了将任务提示翻译成西班牙语和土耳其语的影响。结果显示评价指标几乎没有变化，表明提示翻译的影响微乎其微。这些发现突出了多语言查询生成的评价和开发需更加包容性的需求。未来的研究包括模式本地化和跨多种语言的微调。

Innovation: 
该论文创新性地创建了一个多语言测试集，并且首次系统地评估了基础语言模型在Text2Cypher任务上的跨语言表现，特别是在西班牙语和土耳其语这两种非英语语言上的表现。研究聚焦于揭示不同语言表现差异的原因，并探讨了提示翻译的影响。这些研究为多语言查询生成提供了新的视角，并指明了未来研究的方向。

Conclusion: 
研究结果显示出英语表现最佳、其次是西班牙语、最后是土耳其语的规律。这被归因于训练数据可用性和语言特性之间的差异。提示翻译的任务提示对评估指标几乎没有影响。这些发现强调了多语言查询生成需要更加包容性的评价与开发，并提出了未来研究的方向，如模式本地化和跨多种语言的微调。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21445</guid><pubDate>Fri, 27 Jun 2025 02:33:12 +0800</pubDate></item><item><title>511. cs.CL-通过句法检索增强大型语言模型自动术语提取</title><link>https://arxiv.org/pdf/2506.21222</link><description>Background: 
自动术语提取（ATE）识别领域特定表达，对机器翻译和信息检索等下游任务至关重要。尽管大规模语言模型（LLMs）已显著推进多种自然语言处理任务，但它们在此方面的潜力尚未被广泛探索。现有方法通常依赖于语义相似度，但在提取术语边界时准确性不高。文章探讨了一种基于检索的提示策略，在少量示例设置下，根据句法而非语义相似度选择示例，这种方法在领域无关性上更为灵活，提供更可靠的指导，以捕捉术语边界。文章在领域内和跨领域环境下评估了该方法，并分析了查询句与检索到示例间词汇重叠如何影响性能。实验结果表明，句法检索提高了F1分数，这突显了当适配大规模语言模型到术语提取任务时句法线索的重要作用。

Innovation: 
提出了基于句法检索的提示策略，在少数示例设置中，根据句法而非语义相似度选取示例，这种方法提供更可靠的指导来捕捉术语边界；在多个专门的ATE基准上进行实验，验证在领域内和跨领域环境下句法检索的效果，实验结果显示句法检索提升了F1分数，解决了现有方法在捕捉术语边界时准确性不足的问题。

Conclusion: 
句法检索方法在自动术语提取中的应用能够显著提高F1分数，尤其是在适配大规模语言模型到术语提取任务时，突显了句法线索的重要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21222</guid><pubDate>Fri, 27 Jun 2025 02:33:07 +0800</pubDate></item><item><title>512. cs.CL-改进知识辅助的大语言模型用于欺诈和概念漂移检测</title><link>https://arxiv.org/pdf/2506.21443</link><description>Background: 
随着语言模式的变化和概念漂移（CD），在动态平台上检测不实对话变得越来越困难。这些变化可能会模糊恶意意图或将对话误导向正常对话，使得分类变得具有挑战性。尽管大语言模型（LLMs）在自然语言任务中表现出色，但在风险敏感场景中，它们往往难以处理上下文模糊性和幻觉。

Innovation: 
本文提出了一种增强领域知识（DK）的大语言模型（LLMs）框架，该框架结合了预训练的LLMs与结构化、任务特定的洞察力，以执行欺诈和概念漂移检测。该架构包括三个主要组件：（1）一个DK-LLM模块以检测虚假或欺骗性对话；（2）一个漂移检测单元（OCDD），用于确定是否发生了语义转变；（3）一个第二DK-LLM模块用于将漂移分类为良性或欺诈性。该研究首先通过一个虚假评论数据集验证了领域知识的价值，然后将完整框架应用于SEConvo数据集，该数据集包含各种类型的欺诈和垃圾邮件攻击。实验结果表明，该系统能够以高精度检测虚假对话并有效地分类漂移的性质。基于LLaMA的实现达到了98%的分类精度，与零样本基线的对比研究显示，整合领域知识和漂移意识显著提高了在高风险NLP应用中的性能、可解释性和稳健性。

Conclusion: 
通过整合领域知识和漂移意识，该系统在高风险的NLP应用中显示出显著的性能改进、解释性和稳健性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21443</guid><pubDate>Fri, 27 Jun 2025 02:33:07 +0800</pubDate></item><item><title>513. cs.CL-SAC: 基于动态强度控制测量和诱导LLMs个性特征的框架</title><link>https://arxiv.org/pdf/2506.20993</link><description>Background: 
近年来，大语言模型（LLMs）在多个领域取得了显著进展。人们对其在交互过程中表现出类似人类个性的期望也在增加。为了满足这一期望，许多研究提出了通过心理评估建模LLM个性的新方法。然而，大多数现有模型存在两个主要局限性：它们依赖于五大人格特质（OCEAN）框架，该框架只能提供粗略的人格维度；缺乏控制特征强度的机制。因此，本文构建了一个新的框架，通过扩展机器人格测试量表（MPI），引入了16种人格因素（16PF）模型，以实现对16种不同特征的表达性控制。同时还建立了一个结构化框架，称为特定属性控制（SAC），用于评估和动态诱导LLM的特征强度。该方法采用基于形容词的语义锚定来指导特征强度表达，并利用五个强度因素的行为问题：频率、深度、阈值、努力和意愿。通过实验发现，将强度建模为连续光谱相比二元特征切换，能产生更一致、更可控的人格表达效果。另外，研究表明，目标特征强度的变化系统性地影响了相关特征的心理连贯方向，暗示LLMs内部化了多维度的人格结构，而非孤立处理特征。这项工作为医疗保健、教育和面试等领域中实现可控和细腻的人机交互开辟了新的路径，使我们更接近开发出真正类似人类的社会机器。

Innovation: 
本文通过扩展原始的机器人格测试量表（MPI）方法，将五大人格特质（OCEAN）模型扩展到16种人格因素（16PF）模型，从而实现对16种不同特征的控制性表达。提出了特定属性控制（SAC）框架，用于评估和动态调整LLM的特征强度，并使用五个强度因素（频率、深度、阈值、努力和意愿）来指导这种表达。这种方法相比传统的二元特征切换，能更好地建模人格特征的连续光谱，从而实现更一致和可控的人格表达。此外，研究还表明，强度的变化是系统地影响相关特征的心理连贯方向，因此也反映了LLM内部化了多维度人格结构的想法。

Conclusion: 
本文提出的方法和框架为开发真正类似人类的社会机器提供了新的途径。通过动态强度控制来测量和诱导LLM的个性特征为医疗保健、教育和面试等领域的应用开辟了新路径，带来了一种更接近人类社会交互的形式。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20993</guid><pubDate>Fri, 27 Jun 2025 02:33:06 +0800</pubDate></item><item><title>514. cs.CL-利用LLM辅助查询理解进行实时检索增强生成</title><link>https://arxiv.org/pdf/2506.21384</link><description>Background: 
当前的检索增强生成（RAG）系统在处理用户查询时面临巨大挑战，因为用户查询往往不具备清晰性、存在歧义并且包含多方面的意图。尽管RAG能够赋予大型语言模型（LLM）外部知识，但现有的RAG系统在面对这些复杂的查询时通常表现不佳，因为它们通常是在清洁度较高的数据上进行训练或评估。RAG系统往往难以处理真实世界中的复杂和混乱的查询，特别是在开放领域中实时处理时。

Innovation: 
本文提出了一种名为Omni-RAG的新框架，旨在增强RAG系统在现实生活中的鲁棒性和有效性。Omni-RAG通过三个关键模块利用LLM辅助查询理解来预处理用户输入：（1）深度查询理解和分解，它使用带有定制提示的LLM来清洗查询（例如更正拼写错误）并将其变为结构化的子查询；（2）意图感知的知识检索，它从语料库（例如使用OpenSearch的FineWeb）中为每个子查询进行检索并汇总结果；（3）重排序和生成，在一个链式思考的提示下，一个重排器（例如BGE）细化文档选择后，最终的响应由一个LLM生成（例如Falcon-10B）。Omni-RAG通过增强RAG模型处理复杂和混乱查询的能力，专注于应对SIGIR 2025 LiveRAG挑战所展示的真实世界应用需求。

Conclusion: 
Omni-RAG框架旨在弥合当前RAG能力和现实世界应用需求之间的差距，通过增强RAG系统处理复杂和混乱查询的能力，提供了更有效的实时检索增强生成解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21384</guid><pubDate>Fri, 27 Jun 2025 02:33:05 +0800</pubDate></item><item><title>515. cs.CL-小型编码器能在检测Groundedness方面与大型解码器匹敌</title><link>https://arxiv.org/pdf/2506.21288</link><description>Background: 
大型语言模型（LLMs）通过添加外部上下文可以显著提升自然语言处理（NLP）任务的表现。然而，当提供给LLMs的上下文信息不完整时，它们往往无法可靠地回答查询，可能会产生没有依据的推测或依赖内部知识。Groundedness是指生成的回答必须严格基于提供的上下文信息，这对于确保事实的一致性和可信度至关重要。因此，研究中重点在于在LLMs昂贵的回答生成之前，检测查询是否基于提供的文档上下文。这样做可以显著减少推理时间和资源消耗。研究表明，经过特定任务微调的轻量级编码器模型，如RoBERTa和NomicBERT，在Groundedness检测方面可以达到与最先进的LLMs如Llama3 8B和GPT4o类似的效果，同时大幅减少推理延迟。

Innovation: 
研究发现，轻量级、特定任务的编码器模型如RoBERTa和NomicBERT，在微调后能够与最先进大型模型（如Llama3 8B和GPT4o）媲美地进行Groundedness检测，同时极大地降低了推理延迟。这表明较小的编码器模型在检测Groundedness方面的性能可以与大型解码器相匹配。这项研究提供了一种有效的方法来提前检测查询的Groundedness，从而减少不必要的资源消耗和时间开销。

Conclusion: 
经过特定任务微调的轻量级编码器模型能够在检测Groundedness方面达到与大型语言模型类似的效果，同时极大地缩短了推理延迟。这种检测机制可以显著减少成本，并提高NLP任务处理的效率和准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21288</guid><pubDate>Fri, 27 Jun 2025 02:33:03 +0800</pubDate></item><item><title>516. cs.CL-基于格赖马斯语义方格的人工智能文学批评结构主义方法：大规模语言模型利用</title><link>https://arxiv.org/pdf/2506.21360</link><description>Background: 
大型语言模型（LLMs）在理解和生成文本方面表现出色，但在提供具有深刻思想和复杂叙事的作品的专业文学批评方面存在不足。本文基于格赖马斯语义方格（GSS）提出了GLASS（Greimas Literary Analysis via Semiotic Square）结构分析框架，旨在增强LLMs对文学深入分析的能力，并提供了一种快速剖析叙事结构和深层意义的方法。研究使用LLM-as-a-judge框架提出了基于GSS的文学批评的量化标准。经过与专家批评和多个LLMs的比较，该框架表现出了高水平的性能，并应用到39篇经典作品上，生成了原创且高质量的分析，填补了现有的研究空白，从而提供了一种基于人工智能的文学研究和教育工具，揭示了文学参与的认知机制。

Innovation: 
提出了GLASS（Greimas Literary Analysis via Semiotic Square）结构分析框架，引入了一种专门针对大规模语言模型的量化标准来评估基于格赖马斯语义方格的文学批评，并且应用到39篇经典作品上，生成了高质量分析。此外，通过与专家批评的对比验证了GLASS的有效性和优越性。

Conclusion: 
GLASS框架能够显著提升大规模语言模型在文学分析中的能力。通过提供一套基于格赖马斯语义方格的量化评价体系，GLASS不仅填补了该领域的研究空白，更为文学研究和教育提供了一种有力的AI工具。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21360</guid><pubDate>Fri, 27 Jun 2025 02:33:01 +0800</pubDate></item><item><title>517. cs.CL-Double-Checker：通过自我批判微调增强慢思考LLM的推理能力</title><link>https://arxiv.org/pdf/2506.21285</link><description>Background: 
虽然慢思考的大语言模型（LLMs）展现出类似于反思的推理能力，被称作‘顿悟’的时刻，但它们生成有见地的批评和改进之前解决方案的能力仍然有限。这项研究背景是在现有技术基础上，探讨如何进一步提升慢思考LLMs的推理能力。

Innovation: 
本文提出了Double-Checker，这是一种基于原理的方法，旨在通过促进明确的自我批判和逐步改进之前的解决方案来提升慢思考LLMs的推理能力。通过在我们精心筛选的1,730个自我批判实例上进行微调，Double-Checker使长CoT LLMs能够在推理时迭代地对自己产生的批评进行自我批判和改进，直到它们评价自己的答案为正确。这种方法验证了迭代自我批判在各种推理基准测试中显著提升了长期CoT LLMs的推理能力。

Conclusion: 
通过Double-Checker增强的迭代自我批判，挑战性AIME基准测试的pass@1性能从初始的4.4%提升到了18.2%，这表明了开发具备结构化自我批判能力的更可信和有效的LLMs的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21285</guid><pubDate>Fri, 27 Jun 2025 02:33:00 +0800</pubDate></item><item><title>518. cs.CL-使用自回归语言模型检测视觉锚定对话中的指示语</title><link>https://arxiv.org/pdf/2506.21294</link><description>Background: 
本文探索了使用仅文本的自回归语言建模方法从视觉锚定对话中提取指示语。具体来说，研究目的是探讨仅依靠语言背景信息能否有效地检测在对话视觉上下文中可感知的指代对象。研究通过调整预训练的大型语言模型来标注会话中提及断面的边界，利用下一个词预测技术进行粗略标注。研究结果显示，即使使用中等规模的预训练语言模型、较小的数据集和参数高效的微调，仅文本的方法仍然能够有效，强调了语言背景相对于此任务的重要性。然而，研究者认为该任务本质上是一个跨模态问题，并讨论了一模态方法的基本局限性。

Innovation: 
提出了一种利用预训练的大型语言模型进行粗略标注的方法，通过下一个词预测技术来标注提及断面，展示了仅靠语言背景信息检测视觉锚定对话中的指示语的有效性。这一研究强调了语言背景在该任务中的重要性，并认为该任务是跨模态的，使用单一模态的方法存在局限性。

Conclusion: 
虽然使用预训练的中型语言模型和小规模数据集以及参数高效的微调，仅文本的方法仍能有效检测视觉锚定对话中的指示语，但该研究强调任务的跨模态特性，并提出了单一模态方法的局限，未来可能会考虑结合多模态方法来改进该任务的表现。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21294</guid><pubDate>Fri, 27 Jun 2025 02:32:59 +0800</pubDate></item><item><title>519. cs.CL-Progtuning: 渐进式 Transformers 语言模型微调框架</title><link>https://arxiv.org/pdf/2506.21119</link><description>Background: 
微调是利用基于Transformer的语言模型进行下游任务的一种有希望的技术。随着模型规模的不断扩大，更新所有模型参数的成本也在不断增加。高效的参数微调方法通过选择性地更新一小部分参数有效地解决了这个问题。然而，传统的微调和大多数现有的参数高效的微调方法需要更新与初始模型等量的参数，这忽略了Transformer各块贡献度的不均衡性，导致计算资源分配极不高效。

Innovation: 
本文提出了一种名为Progtuning的新颖微调框架，该框架结合了渐进式学习技术。Progtuning根据贡献度渐进式地减少被更新的Transformer块的数量。这种方法优化了资源分配并且在减少约25%更新参数的数量的同时保持了竞争力。此外，Progtuning与参数高效的微调方法具有良好的适应性，并且在其各种适应场景中表现出了出色的效果。

Conclusion: 
Progtuning通过根据贡献度渐进式地减少被更新的Transformer块的数量来优化资源分配并减少更新参数的数量，同时保持了竞争力。该方法在各种适应场景中表现出优秀的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21119</guid><pubDate>Fri, 27 Jun 2025 02:32:55 +0800</pubDate></item><item><title>520. cs.CL-Agent-RewardBench: 针对感知、规划和安全领域全方位多模态智能体奖励建模的统一体系结构基准</title><link>https://arxiv.org/pdf/2506.21252</link><description>Background: 
随着多模态大规模语言模型（MLLMs）的发展，多模态代理在导航和具身智能等实际任务中显示出潜力。然而，由于缺乏外部反馈，这些代理在自我纠正和泛化方面面临挑战。在没有明确指导如何选择奖励模型的情况下，目前没有针对代理的奖励基准。因此，构建一个面向代理的奖励基准是迫切需求。

Innovation: 
该论文提出了名为Agent-RewardBench的基准，用于评估MLLMs中的奖励建模能力。该基准具有三个关键特点：（1）涵盖感知、规划和安全等多个维度和真实世界的代理场景，共包括7个场景的评估；（2）逐步骤奖励评估，允许在完成任务的个别步骤中评估代理能力，提供规划过程中的更细致的性能视图；（3）适当难度和高质量。从10种不同模型中精心选取并进行了人为验证，确保数据完整性，并通过手动控制任务难度来保持挑战性。实验结果显示，即使最先进的多模态模型也显示出有限的性能，突显了专门培训代理奖励建模的重要性。

Conclusion: 
实验结果表明，即使最先进的多模态模型也显示出有限的性能，在代理奖励建模领域仍存在很大的提升空间。证明了Agent-RewardBench在评估代理奖励模型方面的重要性，并强调了针对这种激烈培训的需求。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21252</guid><pubDate>Fri, 27 Jun 2025 02:32:54 +0800</pubDate></item><item><title>521. cs.CL-DALR: 双层次对齐学习在多模态句子表示学习中的应用</title><link>https://arxiv.org/pdf/2506.21096</link><description>Background: 
之前的多模态句子表示学习方法已经取得了显著的性能，但大多数方法仅在粗粒度级别对图像和文本进行对齐，存在跨模态对齐偏差和模内语义偏差两大关键挑战，这严重影响了句子表示的质量。

Innovation: 
提出了一种双层次对齐学习模块(DALR)，通过一致性学习模块细化跨模态对齐，并通过排名蒸馏增强全局模内对齐学习，以更好地捕捉句子关系并提升表示质量。

Conclusion: 
全面的实验在语义文本相似性（STS）和迁移（TR）任务上验证了该方法的有效性，并且在所有实验中都展示了其优于当前最先进的基线模型的优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21096</guid><pubDate>Fri, 27 Jun 2025 02:32:51 +0800</pubDate></item><item><title>522. cs.CL-Compressed and Smooth Latent Space for Text Diffusion Modeling</title><link>https://arxiv.org/pdf/2506.21170</link><description>Background: 
自回归语言模型在现代文本生成中占主导地位，但它们的顺序性引入了一些根本性的限制：如解码速度慢且保持全局连贯性仍然具有挑战性。扩散模型提供了一个有希望的替代方案，能实现并行生成和灵活控制；然而，由于词级表示的高维性，它们在文本生成上的应用受到了限制。本文介绍了Cosmos，一种全新的文本生成方法，在为扩散特别设计的压缩和光滑潜在空间中运行。该空间使用同时训练用于词级重建和与冻结预训练语言编码器激活兼容性的自编码器进行学习，提供了稳健的语义接地，并能有效进行扰动增广。

Innovation: 
本文提出了Cosmos，一种全新的文本生成方法。该方法完全在压缩和平滑的潜在空间中运行，该潜在空间是通过同时训练词级重建和与预训练语言编码器冻结激活兼容性的自编码器来学习的。实验结果显示，文本表示可以被压缩8倍，同时保持与词级扩散模型相当的生成质量，并且通过增加潜在序列长度，Cosmos能够超越基于扩散和自回归的基线模型。此外，Cosmos在包括故事情节生成、问题生成、总结和去污等四个不同的生成任务上表现良好，相比其他生成范式，提供了2倍以上的快速推理速度

Conclusion: 
本文提出了一种新的文本生成方法Cosmos，通过在压缩和平滑的潜在空间中运行，成功解决了传统自回归模型的缺点，同时在多个生成任务上取得了不错的生成质量，并大幅提高了推理速度。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21170</guid><pubDate>Fri, 27 Jun 2025 02:32:48 +0800</pubDate></item><item><title>523. cs.CL-Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks</title><link>https://arxiv.org/pdf/2506.21182</link><description>Background: 
《MTEB大规模文本嵌入基准》已成为评估文本嵌入模型的标准平台。虽然此前的工作已经确立了基准方法的核心，但本文关注确保MTEB长期再现性和扩展性的工程方面。本文详细说明了通过维护健壮的持续集成管道来验证数据集的完整性、自动化测试执行以及评估基准结果的普适性等方面的设计选择。此外，还讨论了处理社区贡献并扩展基准以包括新任务和数据集的策略。这些工程实践对于确保MTEB的规模化、保持质量和最终在领域的相关性具有重要作用。作为保障长期再现性和可用性的珍贵经验总结，这些经验为其他基准维护者提供了借鉴意义，以确保机器学习评估框架中的再现性和可用性。MTEB代码库可在特定链接访问。

Innovation: 
文章提出了一种维护健壮的持续集成管道的方法，以确保MTEB的数据集完整性、自动化测试执行及基准结果普适性的过程。此外，文章还讨论了如何处理社区贡献并扩展基准，通过这些策略，MTEB得以更加全面并维持高质量，对领域的发展具有重要意义。

Conclusion: 
本文的经验对基准维护者来说是宝贵的指导，特别是对于确保机器学习评估框架中的再现性和可用性。MTEB的代码库已经开源。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21182</guid><pubDate>Fri, 27 Jun 2025 02:32:48 +0800</pubDate></item><item><title>524. cs.CL-Prompt-Guided Turn-Taking Prediction</title><link>https://arxiv.org/pdf/2506.21191</link><description>Background: 
对话系统和对话型机器人中的轮流预测模型是其核心组成部分。近年来，研究人员利用基于变换器的架构实现了实时和连续的语音活动预测。然而，这些模型通常缺乏对预测行为的动态控制能力。

Innovation: 
本研究提出了一种新颖的模型，允许通过文本提示（例如“更快”或“更冷静”）动态控制轮流预测，从而为对话伙伴和背景提供直观且明确的控制。该模型基于语音活动投影（VAP）变换器架构，通过通道变换器和跨通道变换器插入文本提示嵌入。研究者通过超过950小时的人类对话数据验证了方法的可行性，并使用大型语言模型生成了文本提示数据。实验结果表明，该模型能够提高预测准确性，并根据文本提示动态调整轮流时间行为。

Conclusion: 
本研究提出了一种基于文本提示的轮流预测模型，通过使用大型语言模型生成的数据进行了验证，结果显示该模型显著提升了预测准确性和对轮流时间行为的动态调整能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21191</guid><pubDate>Fri, 27 Jun 2025 02:32:48 +0800</pubDate></item><item><title>525. cs.CL-可以利用梯度下降模拟提示效应吗？</title><link>https://arxiv.org/pdf/2506.20989</link><description>Background: 
语言模型（LM）可以通过两种主要方式来融入新信息：更改其提示或更改其参数，例如通过微调。参数更新不会导致长期存储成本的增加。然而，对于许多模型更新，提示更为有效，提示过的模型可以从单个示例中稳健地泛化并且能够推导出标准微调中不会发生的逻辑推理。

Innovation: 
本文描述了一种方法，用于元训练LMs，使其梯度更新模仿新的信息条件效果。该方法利用基于梯度的元学习工具，但使用LM本身的提示预测作为目标，从而避免了需要真实标签。随后的梯度下降训练可以恢复部分（并偶尔恢复全部）提示模型的表现，表明梯度下降在适当初始化的情况下可以非常具有表现力。结果表明可以为长期上下文建模开辟新的途径，并有助于理解基于梯度的模型的学习泛化能力。

Conclusion: 
适当的初始化可以使梯度下降法非常具有表现力，这为基于梯度的学习的泛化能力提供了新的见解，同时也为长期上下文建模的新途径提供了新的研究方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20989</guid><pubDate>Fri, 27 Jun 2025 02:32:47 +0800</pubDate></item><item><title>526. cs.CL-在医学中的端到端事实核查需要传达更多而非决断更多：关于端到端医学事实核查的有效性构建</title><link>https://arxiv.org/pdf/2506.20876</link><description>Background: 
技术进步使得复杂的任务，如自动事实核查，有了实质性的进展。医学和公共健康领域采用了这些系统，因为医学决策的高风险性和评估大量多样化的医学文献的挑战使得专家的责任重大。循证医学是一项确保医疗质量和安全的重要实践，但它对于一般用户来说技术性较强，使得大多数用户的医疗素养不足以在该领域自主导航。这些问题进一步推动了端到端的医学事实核查系统的开发，即通过现有医学文献验证陈述，并给出以证据为基础的判断。然而，此类系统仍主要未被利用。因此，我们通过首次研究医学专家如何通过综合医学证据验证来自社交媒体的真实陈述，来寻找这类系统的上限。进一步揭示了当端到端的事实核查应用于医学时的基本挑战。在这些挑战中包括：野生环境下难以将声明与科学证据（如临床试验）相连；模糊不清、未说明充足的声明与意图不匹配；以及主观性的真实性标签。这些证据表明，事实核查应该被视为一种交互式交流问题，而非端到端的过程。

Innovation: 
提出了一种新的研究视角，即通过综合医学证据来验证来自社交媒体的真实医学声明，这种方法可以揭示在实际医疗环境中应用端到端事实核查过程中存在的挑战，包括难以将声明与科学证据相连、模糊不清的声明及意图不匹配、以及需要评估需要进行主观评判的真实性标签。这有助于理解现有的端到端医学事实核查系统为什么很少被使用，并为未来改进这些系统提供了新的方向和建议。

Conclusion: 
尽管端到端事实核查系统对于优化医学决策过程有巨大潜力，但当前医学领域中的实施仍然存在许多障碍。研究建议重新思考对事实核查的解决方式，将其视为一个交互式的交流过程，而不是简单的自动验证过程。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20876</guid><pubDate>Fri, 27 Jun 2025 02:32:45 +0800</pubDate></item><item><title>527. cs.CL-MT2-CSD：多目标、多轮次对话姿态检测的新型数据集及多语义知识融合方法</title><link>https://arxiv.org/pdf/2506.21053</link><description>Background: 
在当今社交媒体领域，自动态度检测对于意见挖掘至关重要，它综合并分析用户在争议性话题上的观点，以揭示主导趋势和情绪。传统的态度检测研究通常针对个体实例，因此在建模多参与者讨论方面能力有限，这在真实的社交媒体场景中是常见的。这种局限性主要是因为缺乏能够真实捕捉社交媒体互动动态的高质量数据集，阻碍了对话态度检测的进步。在本文中，我们介绍了MT2-CSD数据集，这是目前为多目标、多轮次对话态度检测设计的最大规模数据集，它包含24,457个标注实例，具有极高的对话深度，从而为态度检测提出了新的挑战。

Innovation: 
我们提出了基于大规模语言模型增强的对话关系注意网络（LLM-CRAN），它利用了大规模语言模型的推理能力来增强对话理解。进行了广泛的实验验证，结果显示LLM-CRAN在对话态度检测任务中显著优于具有竞争力的基线模型。MT2-CSD数据集和LLM-CRAN方法一起为对话姿态检测领域带来了新的数据资源和技术突破，可以支持更深入和准确的态度分析和对话理解。

Conclusion: 
实验结果表明，LLM-CRAN在会话态度检测任务中显著优于强基线模型，MT2-CSD不仅是迄今为止最大规模的多目标、多轮次对话态度检测数据集，还通过呈现新的挑战和解决方案，提供了新的研究视角。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21053</guid><pubDate>Fri, 27 Jun 2025 02:32:42 +0800</pubDate></item><item><title>528. cs.CL-ComRAG：基于动态向量存储的检索增强生成在工业领域实时社区问答系统</title><link>https://arxiv.org/pdf/2506.21098</link><description>Background: 
社区问答（CQA）平台可以被视为社区中的重要知识库，但如何有效利用历史交互和领域知识在实时场景中仍然是一个挑战。现有方法往往未能充分利用外部知识，未能结合动态历史问答上下文，或缺少适合工业部署的记忆机制。

Innovation: 
提出了一种名为ComRAG的检索增强生成框架，它通过一种基于中心的存储机制将静态知识与动态历史问答对结合起来，实现对实时工业CQA的支持。ComRAG在三个工业CQA数据集上进行了评估，结果表明其在向量相似度、延迟降低和剪枝效率等方面优于所有基线方法。

Conclusion: 
ComRAG在三个工业CQA数据集上的测试结果表明，它在向量相似度、延迟减少和每个迭代周期的剪枝百分比方面都显著优于所有基线方法，是用于实时工业社区问答的有力解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21098</guid><pubDate>Fri, 27 Jun 2025 02:32:41 +0800</pubDate></item><item><title>529. cs.CL-大型语言模型在特许会计师考试中表现出色</title><link>https://arxiv.org/pdf/2506.21031</link><description>Background: 
随着先进智能系统，尤其是大型语言模型（LLMs），在自然语言处理（NLP）方面取得进步，这些技术正在显著改变金融实践。然而，这些模型在有效捕捉并应用金融专业知识方面的效果尚不明确。特别是在印度这样庞大的金融背景下，这一差距尤为突出。因此，本文旨在通过CA-Ben基准测试，评估LLMs在财务、法律和定量推理方面的表现，该基准测试基于印度特许会计师协会（ICAI）的严格考试数据集，涵盖了基础、中级和高级特许会计师课程的所有阶段。

Innovation: 
本文主要的创新在于引入了CA-Ben基准测试，这是一个专门用于评估LLMs处理财务、法律和定量推理能力的重要工具。此外，作者使用标准化协议对六种知名LLM进行了综合性测试，结果显示在概念和法律推理方面，Claude 3.5 Sonnet和GPT-4o表现尤为出色，但它们在数值计算和法律解释方面仍面临挑战。这表明当前LLMs的优点和局限性，并暗示未来通过混合推理和检索增强生成方法可能会在定量分析和准确的法律解释方面有所改进。

Conclusion: 
研究结果强调了当前LLMs的强项和弱点，表明未来可以通过结合推理和检索增强生成的方法来改善其在定量分析和法律解释中的表现。具体来说，尽管这些模型在一些概念性和法律推理任务中表现出色，但在涉及具体的法律解释和复杂计算的某些领域仍存在显著挑战。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21031</guid><pubDate>Fri, 27 Jun 2025 02:32:39 +0800</pubDate></item><item><title>530. cs.CL-E-commerce查询分类的半监督可扩展统一框架</title><link>https://arxiv.org/pdf/2506.21049</link><description>Background: 
电子商务查询通常简短且缺乏上下文，标签间的信息不能被利用，导致建模时缺乏足够的先验信息。现有的大多数工业查询分类方法依赖用户后续的点击行为来构建训练样本，从而产生马太效应。此外，查询分类的任务缺乏统一的框架，导致算法优化效率低。

Innovation: 
提出了一个半监督可扩展统一框架(SSUF)，包含多个增强模块来统一查询分类任务。知识增强模块使用世界知识增强查询表示，解决查询信息不足的问题；标签增强模块利用标签语义和半监督信号降低对后续标签的依赖；结构增强模块基于复杂的标签关系增强标签表示。每个模块高度插件化，输入特征可根据每个子任务需要添加或移除。实验结果显示，SSUF显著优于最新模型。

Conclusion: 
SSUF在离线和在线A/B实验中表现优异，显著超越了最先进的查询分类模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21049</guid><pubDate>Fri, 27 Jun 2025 02:32:35 +0800</pubDate></item><item><title>531. cs.CL-KaLM-Embedding-V2：优越的训练技术和数据激发了多功能嵌入模型</title><link>https://arxiv.org/pdf/2506.20923</link><description>Background: 
本文介绍了一种多功能且紧凑的嵌入模型KaLM-Embedding-V2，该模型通过利用优质的训练技术和数据，在通用文本嵌入任务中取得了出色的表现。KaLM-Embedding-V2采用了先进的训练方法和大数据集，旨在提供高效的文本表示能力。

Innovation: 
本文的主要创新包括：1. 改进模型架构以更好地适应表示学习，移除了因果注意力掩码，采用完全双方向的转换器，利用简单有效的均值池化生成固定长度的嵌入；2. 实施了一种多阶段训练流程，包括大规模弱监督开源语料库的预训练、高质量检索和非检索数据集的微调以及模型混合参数平均的鲁棒推广；3. 引入了一种焦散式重权机制，集中学习困难样本，并采用在线困难负样本混合策略，不断丰富困难负样本，而无需昂贵的离线挖掘；4. 预训练数据收集超过20类，精调数据超过100类，提升模型性能和泛化能力。

Conclusion: 
对大规模文本嵌入基准（MTEB）中日语和英语的广泛评估表明，该模型在与之相比的小规模模型中表现出色，并且能够与比其大3倍、14倍、18倍和26倍的嵌入模型竞争，确定了多功能且紧凑的嵌入模型的新标准，其参数量不到1亿。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20923</guid><pubDate>Fri, 27 Jun 2025 02:32:35 +0800</pubDate></item><item><title>532. cs.AI-基于理性视角，上下文学习策略自然浮现</title><link>https://arxiv.org/pdf/2506.17859</link><description>Background: 
最近有关上下文学习（ICL）的研究揭示了多种模型策略，这些策略在不同的实验条件下描述了模型的行为。当前研究旨在统一这些发现，探讨为什么模型会首先学习这些不同的策略。通过观察，在混合任务训练下，模型用于执行ICL的策略可以由一组贝叶斯预测器来捕捉，包括一种记忆性预测器和一种泛化预测器。研究者采用规范的理性分析视角，将学习者的行为解释为考虑到计算约束的数据优化，开发了一个分层贝叶斯框架，几乎完美地预测了整个训练期间的Transformer下一个标记预测——在无需假设对权重的访问的情况下。该框架将预训练视为不同策略后验概率更新的过程，推理时的行为视为这些策略预测的后验加权平均值。该框架借鉴了神经网络学习动力学的常见假设，明确了策略效果和复杂性之间的权衡：模型更倾向于执行某个策略的关键不仅是数据解释得好，还有该策略的复杂度。这项研究有助于解释已知的ICL现象，并提出了新的预测：例如，展示了随任务多样性增加，从泛化到记忆的过渡时间呈超线性趋势的变化。

Innovation: 
本研究创新地采用理性分析的视角，通过分层贝叶斯框架的提出，几乎完美地预测了Transformer在训练过程中的下一个标记预测。该框架明确展示了不同策略之间的复杂性和损失之间的权衡。这不仅解释了ICL的已知现象，还提出了新的预测，如任务多样性增加时从泛化到记忆的过渡时间表现出超线性趋势的变化。

Conclusion: 
本研究通过在任务混合训练下模型的上下文学习策略，提出了一个基于策略复杂性与损失之间权衡的分层贝叶斯框架，成功地描述了ICL行为，并提供了对其现象的新理解，同时给出了新的预测。总之，本研究是一种解释性和预测性的ICL理论，依托于策略复杂性和损失之间的权衡。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17859</guid><pubDate>Fri, 27 Jun 2025 02:32:34 +0800</pubDate></item><item><title>533. cs.CL-LLM生成与人类研究创意之间的理想化执行差距：执行结果分析</title><link>https://arxiv.org/pdf/2506.20803</link><description>Background: 
大型语言模型（LLMs）在加速科学研究流程方面表现出潜在优势，尤其是在生成新颖的科研想法方面显示出潜力。已有研究表明，由LLM生成的研究想法相较于人类专家的想法更具有新颖性。然而，一个好想法不应该只是为了看似新颖，更重要的是能够通过执行带来更好的科研成果。因此，研究者们通过执行研究实施（Execution Study）的方法，招募了43名专家研究人员来执行随机分配给他们的想法，这些想法是由专家所写或是由LLM生成的。每个专家花费超过100小时去实现这一想法，并撰写了一份4页的简短论文来记录实验过程。所有执行的项目随后都由专家NLP研究人员盲审，结果显示在所有评估标准（新颖性、兴奋性、效果及总体评价）中，LLM生成的想法在执行前后得分下降得比专家撰写的想法更加显著，这表明了LLM和人类想法在观念阶段观察到的差距在执行阶段得到了缓解。进一步比较执行研究的综合评估得分，我们发现对于许多指标，人类想法的得分甚至高于LLM产生的想法的得分。这一执行差距揭示了目前LLMs在生成真正有效的研究想法方面的局限性，以及在缺乏执行结果的情况下评估研究想法的 challenge。

Innovation: 
该研究通过执行研究方法进行了创新性实验，验证了LLM生成的想法在执行后的有效性。这为评估研究创意提供了新的视角和方法。研究结果揭示了LLMs在生成真正有效的研究想法方面的局限性，以及评估研究想法时的重要挑战。

Conclusion: 
尽管LLM生成的想法在观念阶段显示出更大的新颖性，但经过执行后的结果表明，这些想法的有效性远低于专家撰写的想法。这一发现揭示了理想化执行差距（Ideation-Execution Gap），指出了目前LLMs在生成真正有效的研究想法方面的局限性，并强调了评估研究想法时需要充分考虑其执行结果的重要性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20803</guid><pubDate>Fri, 27 Jun 2025 02:32:32 +0800</pubDate></item><item><title>534. cs.CL-FineWeb2：一种适应所有语言的预训练数据处理管道</title><link>https://arxiv.org/pdf/2506.20920</link><description>Background: 
当前预训练最先进的大型语言模型（LLMs）需要大量的清洁和多样化文本数据。虽然大型高质量英语预训练数据集的开发已经取得了显著进展，但训练高性能的多语言LLMs仍然很有挑战性，主要原因在于设计过滤和去重流水线以适应多种语言的难度很高。现有方法难以满足多种语言的需求，导致多语言模型的性能受限。因此，本研究旨在改进预训练数据的采集和处理过程，以支持任何语言的自动适应。

Innovation: 
本文介绍了一种基于FineWeb的新预训练数据采集流水线，该流水线能够自动适应任何语言。本文还引入了一种简单且系统的方法来重新平衡数据集，综合考虑重复项数量和质量，进一步提升了模型性能。此外，该研究将流水线扩展到超过1000种语言，使用近100个Common Crawl快照生成了一种新的名为FineWeb2的多语言数据集，该数据集包含20太字（50亿份文档），并且与研究成果一同公开了流水线、训练和评估代码库。

Conclusion: 
本文展示了这种新的数据采集和处理流水线可以创建更高效的非英语语料库，并且引入的方法在数据重新平衡方面的提升效果明显。通过这种方法和新生成的数据集FineWeb2，大大增加了多语言预训练语言模型训练的可能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20920</guid><pubDate>Fri, 27 Jun 2025 02:32:30 +0800</pubDate></item><item><title>535. cs.CL-MultiFinRAG: 一种优化的多模态检索增强生成（RAG）框架，用于金融问答</title><link>https://arxiv.org/pdf/2506.20821</link><description>Background: 
金融文档，如10-Ks、10-Qs和投资者演示文稿，通常非常长且包含多种模态的形式，例如稠密的叙述文本、结构化表格和复杂的图表。回答此类内容的问题通常需要跨模态的联合推理，这使得传统大型语言模型（LLMs）和检索增强生成（RAG）管道不堪重负，因为空格限制、布局丢失和碎片化的跨模态上下文的问题。

Innovation: 
我们提出了MultiFinRAG，这是一种专门为金融问答（FinQA）设计的检索增强生成框架。MultiFinRAG首先通过将表格和图像组批并发送给一个轻量级、量化的开源多模态LLM来进行多模态提取，产生结构化的JSON输出和简洁的文字摘要。这些输出连同叙述文本一起嵌入并在具有模态感知相似阈值的情况下进行索引，以实现精确检索。当必要时，多层次的后备策略可以动态从文本仅模式升级到文本+表格+图像模式，从而在减少不相关上下文的情况下实现跨模态推理。尽管运行在普通的硬件上，MultiFinRAG在涉及文本、表格、图像和复合多模态推理的复杂金融问答任务上的准确度比ChatGPT-4o（免费版本）高19个百分点。

Conclusion: 
MultiFinRAG是为金融问答专门设计的多模态检索增强生成框架，该框架通过精确的嵌入与索引、多层次的后备策略和跨模态推理，提高了复杂金融问答任务的准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20821</guid><pubDate>Fri, 27 Jun 2025 02:32:25 +0800</pubDate></item><item><title>536. cs.CL-在行为情境下通过多元人口统计学分析揭示大型语言模型中隐藏的暴力倾向</title><link>https://arxiv.org/pdf/2506.20822</link><description>Background: 
大型语言模型（LLMs）被越来越多地用于检测和回应网络暴力内容，但它们在处理具有道德模糊性的现实世界场景中的推理能力仍缺乏研究。本文首次采用经过验证的社会科学工具（即暴力行为情景问卷，VBVQ）评估LLMs。研究人员通过在统一的零样本设置下评估六种不同背景和组织的LLMs，引人基于人设的提示，以评估其潜在的偏见，包括种族、年龄和地理身份等因素的变化。研究发现，LLMs在表层文本生成时往往偏离其偏好暴力反应的趋势，并且其暴力倾向在不同的人口统计学群体中存在差异，经常与犯罪学、社会学和心理学领域的已有研究结果相矛盾。

Innovation: 
本研究引入了基于人设的提示，用于评估LLMs在处理道德模糊性的现实世界场景中的推理能力，并特别关注其在不同人口统计学群体中的表现差异。这是首次使用经过科学验证的工具对大型语言模型的暴力敏感性进行全面评估的研究。

Conclusion: 
研究揭示了两个关键发现：第一，LLMs的文本生成往往与其内部偏好暴力反应相偏离；第二，它们的暴力倾向会因人口统计学群体的不同而异，经常与犯罪学、社会学和心理学领域的研究结果背道而驰。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20822</guid><pubDate>Fri, 27 Jun 2025 02:32:25 +0800</pubDate></item><item><title>537. cs.AI-这些不是您所有在寻找的特征：监督预训练中的基本瓶颈</title><link>https://arxiv.org/pdf/2506.18221</link><description>Background: 
迁移学习是现代机器学习的一个基石，它提供了一种方法，将预先在广泛数据上训练的模型应用于新的任务，只需很少的新数据。然而，一个重要的挑战是如何确保转移的特征能够处理未知的数据集，并且由于量化两个任务是否相关十分困难，这一挑战变得更加突出。为了应对这些挑战，研究者评估了预训练混合数据到每个子任务中模型的迁移效果，探讨预训练特征是否能够与特定任务的直接训练性能相匹配。研究发现，深度学习模型存在一个关键的局限性——“信息饱和瓶颈”，即网络在训练过程中一旦学会了相似的冲突特征，就无法再学习新的特征。特别是在预训练过程中只学会关键特征的子集时，模型在转移学习中会永久地失去重要的特征，导致在数据分布上表现出不一致性，即使是训练混合数据的一部分。现有的研究证据表明，这种现象在深度学习架构中普遍存在——诸如数据分布或排序等因素会影响当前表示学习方法随时间能够学习的特征。这项研究建议，当可行时，依赖大规模网络可能不如专注于特定任务的训练更为有效。该研究还提出了更丰富特征表示作为一种潜在的解决方案，以更好地在新数据集上泛化，并具体介绍了现有方法与一种新颖方法，这是解决这一挑战迈出的第一步。

Innovation: 
研究发现了深度学习模型中的“信息饱和瓶颈”，即网络在预训练过程中一旦学会了相似的冲突特征，就无法再学习新的特征。提出了一个更丰富特征表示的方法作为一种潜在解决方案，以更好地在新数据集上泛化，并介绍了一种新的方法来解决这一挑战的初步步骤。

Conclusion: 
研究表明，深度学习模型在预训练过程中学习相似特征后无法继续学习新特征，并且提出了更丰富特征表示作为改进策略。研究还提出了一种新颖的方法来解决这一挑战，为后续的研究提供了方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18221</guid><pubDate>Fri, 27 Jun 2025 02:32:25 +0800</pubDate></item><item><title>538. cs.CL-大型语言模型多语言功能评估</title><link>https://arxiv.org/pdf/2506.20793</link><description>Background: 
多语言能力在大型语言模型中的评估通常依赖于静态数据基准测试，如Belebele、M-MMLU和M-GSM。然而，这些评估往往无法充分理解模型在多语言设置中的实际性能和鲁棒性。因此，研究者基于通用的功能性基准框架，将模板翻译成法语、西班牙语、印地语、阿拉伯语和约鲁巴语等五种不同的语言，设计了新的多语言功能基准测试：跨语言小学数学符号测试（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval），以更全面地评估模型的鲁棒性。

Innovation: 
研究构建了新的多语言功能基准测试，通过跨语言翻译通用的功能基准模板来评估大型语言模型在不同语言环境下的性能和鲁棒性，揭示出不同基准测试对模型功能性能的捕捉程度存在显著差异，部分基准测试能够显著提高对模型的评估准确性。此外，研究还发现不同语言下模型的鲁棒性表现存在显著差异，某些语言在各次评估中表现更为一致。

Conclusion: 
实验结果表明，一些静态的多语言基准测试更能贴近地反映模型的功能性表现差异。同时，不同语言环境下模型的鲁棒性表现也存在显著差异，某些特定语言（如阿拉伯语、英语）在多轮评估中表现更为稳定。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20793</guid><pubDate>Fri, 27 Jun 2025 02:32:22 +0800</pubDate></item><item><title>539. cs.AI-SACL：通过语义增强重新排名和定位理解及对抗代码检索中的文本偏见</title><link>https://arxiv.org/pdf/2506.20081</link><description>Background: 
当前的代码检索技术主要依赖于表面级别的文本特征（如文档字符串和标识符名称），并且对已文档化的代码有较强的偏好，即使该文档与代码内容无关。这表明现有的训练方法可能需要改善以提供更有效的代码检索和生成技术。因此，研究者旨在深入分析代码检索的技术，通过系统性地掩盖特定特征但仍保持代码功能完整的方法来揭示这些限制和偏差原因。

Innovation: 
本文提出了一种名为SACL的新框架，它通过添加语义信息并增强代码或结构知识来丰富文本信息，并减少对已文档化代码的偏好，从而减少文本偏见。SACL通过语义增强重新排名和定位代码信息，显著提高了代码的检索性能，即在HumanEval / MBPP / SWE-Bench-Lite上的召回率（分别为12.8% / 9.4% / 7.0%的Recall@1），并进一步提高了代码生成的表现，例如HumanEval的Pass@1上升了4.88%。

Conclusion: 
研究表明，通过使用SACL框架，可以显著提高代码检索的效果，同时也能改善代码生成的效果。这些发现表明，语义信息对于减少代码检索中的文本偏见和提升检索质量具有重要作用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20081</guid><pubDate>Fri, 27 Jun 2025 02:32:20 +0800</pubDate></item><item><title>540. cs.AI-迈向可验证的安全或不安全模型权重释放方案</title><link>https://arxiv.org/pdf/2506.19874</link><description>Background: 
近期的隐私保护模型权重释放方案声称能够在保护模型知识产权的同时开放模型的发布，但大多数现有方案缺乏严格的安全性基础，并仅有非正式的安全保证。

Innovation: 
受密码学中现有研究成果的启发，本文通过提出几种具体的安全性定义来形式化模型权重释放方案的安全性，并针对TaylorMLP这一著名的权重释放方案进行了案例研究，发现其中的安全漏洞从而揭示了TaylorMLP未能实现其非正式的安全目标。本文希望促进机器学习与安全研究社区的深入研究，并提供未来权重释放方案设计与评估的蓝图。

Conclusion: 
本文希望倡导方向更加严谨的研究，促使未来发布的模型权重更加安全可靠，并提供了如何制定和评估未来的权重释放方案的具体方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19874</guid><pubDate>Fri, 27 Jun 2025 02:32:18 +0800</pubDate></item><item><title>541. cs.CL-向大规模表格数据中的概率式问答迈进</title><link>https://arxiv.org/pdf/2506.20747</link><description>Background: 
当前的表格数据问答方法，如NL2SQL系统，对于可以直接从表格中检索答案的事实性问题表现良好。但是，它们在需要在不确定条件下进行推理的概率性问题上表现不佳。

Innovation: 
本文提出了一个新的基准LUCARIO和一种框架，用于在大规模表格数据上进行概率式问答。该方法从表格中诱导贝叶斯网络，将自然语言查询翻译成概率查询，并利用大型语言模型生成最终答案。

Conclusion: 
实验证明该方法在基线之上取得了显著的进步，突显了混合符号-神经推理的优点。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20747</guid><pubDate>Fri, 27 Jun 2025 02:32:17 +0800</pubDate></item><item><title>542. cs.AI-超声图像解释和扫描指导的语义场景图</title><link>https://arxiv.org/pdf/2506.19683</link><description>Background: 
医学超声成像因成像参数差异导致的显著视觉变异性而长期面临挑战。虽然近年来大型语言模型被用于自动生成面向具有足够生理知识的临床医生的术语丰富的摘要，但仍未能满足非专家用户提高超声成像可解释性和基础扫描指导的需求，尤其是在护理点环境中。针对这一空白，本研究通过引入超声场景图（SG），旨在为普通用户提供图像内容解释并指导超声波扫描。该研究首次使用基于变换器的一阶段方法计算超声SG，省去了显式对象检测的步骤。研究结果验证了该方法在提高超声成像解释性和使用性方面的潜力，特别是在志愿者的左颈部和右颈部（包括颈动脉和甲状腺）成像区域。

Innovation: 
首先引入了基于变换器的一阶段方法计算超声场景图，省去了显式对象检测的步骤；其次，通过大型语言模型（LLMs）进一步细化抽象SG表示，生成普通用户易于理解的图像解释；最后，探索预测的SG以指导扫描，填补当前成像视图中的解剖缺漏，帮助普通用户实现更标准化和完整的解剖探索。

Conclusion: 
通过超声场景图，该研究证实了其在最大程度上促进超声成像民主化方面的潜力，即通过提高成像解释性和使用性，增强其对普通用户的可解释性和易用性。研究结果在左颈部和右颈部成像区域（包括颈动脉和甲状腺）的五名志愿者身上得到验证。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19683</guid><pubDate>Fri, 27 Jun 2025 02:32:16 +0800</pubDate></item><item><title>543. cs.AI-IndieFake 数据集：音频换声检测的基准数据集</title><link>https://arxiv.org/pdf/2506.19014</link><description>Background: 
近年来，音频换声技术取得了显著进步，可用于AI助理、提高失语症患者交流便利性和增强娱乐体验。然而，这一技术也带来了严重的安全、隐私和数字通信信任问题。检测和缓解这些威胁需要全面的数据集，现有数据集缺乏多样化的口音，无法满足现实世界中的多种情况进行模型训练，尤其是在南亚国家的语言和文化背景下表现较差，而南亚人口占世界人口四分之一，却不存在对应的样本数据。因此，本文旨在解决这一问题，提出IndieFake数据集，包含了50位印度英语母语者的真声和换声音频数据，共27.17小时，且提供了均衡的数据分布和包含说话人口述特征的详细描述，这与ASVspoof21 (DF)等数据集中的描述不同。

Innovation: 
该研究提出了IndieFake数据集，这是第一款专门为音频换声检测设计的基准数据集。IndieFake数据集收录了50位印度英语母语者的27.17小时真声和换声音频数据，旨在提高模型检测音频换声在南亚背景下语言和文化方面的准确性，同时提供了平衡的数据分布和包含说话人口述特征的描述，这些都是现有数据集所缺乏的。该数据集在真实野生环境中进行了基准测试，结果表明，IndieFake数据集比现有的ASVspoof21 (DF)数据集表现更好，且更具挑战性。

Conclusion: 
IndieFake数据集在检测和缓解音频换声威胁方面具有重要作用，为研究者提供了更适合南亚语言和文化背景的全面数据分布。该数据集已开源，为研究和开发提供了支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19014</guid><pubDate>Fri, 27 Jun 2025 02:32:13 +0800</pubDate></item><item><title>544. cs.AI-使用SMILE进行大型语言模型解释性研究：基于局部解释的统计模型无关可解释性</title><link>https://arxiv.org/pdf/2505.21657</link><description>Background: 
GPT、LLAMA和Claude等大型语言模型在生成文本方面变得极其强大，但它们仍然是黑盒模型，因此很难理解它们如何做出决策。这种透明度的缺失在需要信任和负责的领域特别成问题。为了帮助解决这一问题，我们介绍了SMILE，这是一种方法，能够解释这些模型对不同部分的提示做出的响应。SMILE是一种模型通用方法，通过轻微改变输入，观察输出的变化，并突出显示哪些词影响最大，它通过生成简单的可视化热图来直观展示提示的关键部分。我们对几种领先的LLM进行了测试，并使用准确率、一致性、稳定性和保真度等指标来展示SMILE提供清晰可靠的解释能力。

Innovation: 
SMILE是一种新的、模型通用的方法，能够解释大型语言模型对不同提示部分的响应。该方法通过对输入进行小幅修改来测量输出的变化，并突出显示具有最大影响的单词，通过生成热图来直观地展示哪些部分的提示最重要。这种方法在几个领先的LLM上进行测试，显示出准确和可靠的解释能力。

Conclusion: 
通过使这些模型更加容易理解，SMILE使我们向使AI更透明和可信迈进了一步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.21657</guid><pubDate>Fri, 27 Jun 2025 02:32:11 +0800</pubDate></item><item><title>545. cs.AI-基于LLM的恶意软件分析的语义预处理</title><link>https://arxiv.org/pdf/2506.12113</link><description>Background: 
在恶意软件分析的背景下，许多方法依赖于人工智能来处理大量数据，但这些技术主要关注于数据视角（图像、序列），而忽视了专家视角。鉴于这一问题，我们提出了一种基于专家知识的预处理方法，以提高恶意软件的语义分析能力和结果显示的可解释性。这种方法是通过生成 Portable Executable 文件的 JSON 报告，结合静态和行为分析特征，以及包含打包程序签名检测、MITRE ATT&amp;amp;CK 和恶意软件行为目录 (MBC) 的知识，为恶意软件分析师提供更易于理解的语义表示。

Innovation: 
我们提出了一种新的预处理方法，该方法生成 Portable Executable 文件的 JSON 报告，包含了静态和行为分析的特征，以及打包程序签名检测、MITRE ATT&amp;amp;CK 和 MBC 的知识。这种预处理方法旨在为恶意软件分析师提供一个语义化的二进制文件表示，并增强机器学习模型对恶意文件分析的解释性。我们利用这种预处理方法训练了一个大型语言模型来进行恶意软件分类，实现了复杂数据集上加权平均 F1 分数为 0.94 的结果，这一数据集代表了市场现实。

Conclusion: 
这种预处理方法通过为恶意软件分析师提供更语义化的数据表示，显著提高了恶意软件分析的解释性，同时利用这种预处理方法训练的大型语言模型在恶意软件分类任务上也表现出了优异的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.12113</guid><pubDate>Fri, 27 Jun 2025 02:32:09 +0800</pubDate></item><item><title>546. cs.AI-TracLLM：一种适用于长上下文大语言模型的通用归因框架</title><link>https://arxiv.org/pdf/2506.04202</link><description>Background: 
大语言模型（LLMs）在许多实际应用中部署，如随手可用式的检索增强生成（RAG）、代理和广泛的大语言模型集成应用。给定一个说明和一个长上下文（例如，文档、PDF文件、网页），LLM可以生成基于提供上下文的内容，以提供更准确、更及时和可验证的输出，同时减少幻觉和缺乏支持的断言。研究中提出了一个问题：如何指出哪些在上下文中的文本（如句子、片段或段落）对LLM生成的输出最重要或负有责任？这一过程，我们称之为上下文回溯，具有各种实际应用意义，比如1）调试基于LLM的系统，2）对LLM进行后攻击法化学术分析（例如，提示注入攻击、知识污染攻击），3）突出知识来源以增强用户对LLM生成输出的信任。然而，现有的特征归因方法如Shapley，当应用于长上下文LLM的上下文回溯时，表现不佳且计算成本高昂。

Innovation: 
本文开发了TracLLM，这是一种专门针对长上下文LLM的首个通用上下文回溯框架。我们的框架能够提高现有特征归因方法的有效性和效率。为了提高效率，我们在TracLLM中开发了基于启发式搜索的算法。我们还开发了贡献评分的集成/降噪技术，以提高TracLLM的准确性。评估结果表明，TracLLM能够有效识别长上下文中的文本，这些文本导致了LLM的输出。

Conclusion: 
我们的研究结果表明，TracLLM可以有效地识别长上下文中的关键文本，这些关键文本引起了LLM的生成输出。我们的代码和数据可以在指定的URL中找到。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.04202</guid><pubDate>Fri, 27 Jun 2025 02:32:09 +0800</pubDate></item><item><title>547. cs.AI-在思考时搜索并精炼：自适应检索增强的大语言模型推理</title><link>https://arxiv.org/pdf/2505.11277</link><description>Background: 
大语言模型展示了令人印象深刻的推理能力，但它们的知识储备有限。检索增强的推理通过允许LLMs查询外部资源来缓解这一限制，但现有方法常常检索到无关或噪声信息，阻碍了准确的推理。现有的方法在处理复杂、多步骤推理场景时效果不佳，这成为了研究中的一个关键挑战。

Innovation: 
本文提出了AutoRefine，一种基于强化学习的后训练框架，采用了新的“搜索并精炼”推理范式。AutoRefine在相继的搜索调用之间引入了明确的精炼步骤，使模型能够迭代地筛选、提炼和组织证据，再生成答案。此外，研究中还引入了针对检索的定制奖励和答案正确性奖励，使用群体相对策略优化。实验表明，AutoRefine 在单步骤和多步骤问答基准测试中显著优于现有方法，特别是在复杂的、多步骤推理场景中。更深入的分析表明，AutoRefine 经常进行频繁、高质量的搜索，并有效地综合了证据

Conclusion: 
实验结果表明，AutoRefine 在处理复杂多步骤推理场景中的表现显著优于现有方法，尤其是在单跳和多跳问答基准测试中。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.11277</guid><pubDate>Fri, 27 Jun 2025 02:32:06 +0800</pubDate></item><item><title>548. cs.AI-从假到真：奖励建模作为区分性预测</title><link>https://arxiv.org/pdf/2506.13846</link><description>Background: 
有效的奖励模型在基于强化学习改进视觉生成模型的过程中起着关键作用。然而，当前的奖励建模方法因其对大量人工注释偏好数据的依赖或精心设计的质量维度的依赖，而面临实现复杂性的问题。这些人工注释的数据往往是不完整的且构建成本高。

Innovation: 
受生成对抗网络（GANs）中对抗训练的启发，该论文提出了一种名为GAN-RM的有效奖励模型框架。这个框架无需手动偏好标注和显式质量维度工程，而是通过区分一小批代表性且未配对的目标样本（称为偏好代理数据）和模型生成的一般输出来训练奖励模型，仅需几百个目标样本即可。

Conclusion: 
我们的研究在多个关键应用中展示了GAN-RM的有效性，包括测试时的规模扩展（通过N-best样本筛选实现），以及后训练方法如监督微调（SFT）和直接偏好优化（DPO）。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13846</guid><pubDate>Fri, 27 Jun 2025 02:32:06 +0800</pubDate></item><item><title>549. cs.AI-PCDVQ: 通过极坐标解耦增强大语言模型中的向量量化</title><link>https://arxiv.org/pdf/2506.05432</link><description>Background: 
大规模语言模型（LLMs）在边缘部署中面临的主要挑战是其庞大的参数规模。向量量化（VQ）作为一种基于聚类的量化方法，因其极低的位数（甚至低至2位）和相对较高的准确性而被广泛应用于解决这一问题。现有工作中的VQ方法通常耦合地量化方向和幅度，但研究表明，方向对量化更敏感，具体表现为零样本任务的准确度降低了46.5%而幅度仅降低了2.3%。进一步分析表明，当前VQ方法中的欧氏距离计算更侧重于减少幅度误差，这与上述发现相矛盾，导致量化误差增大。

Innovation: 
本文提出了极坐标解耦向量量化（PCDVQ），这是一种有效且高效的VQ框架，包含两个关键模块：1）极坐标解耦（PCD），它将向量转换为其极坐标表示，并独立量化方向和幅度参数；2）分布对齐码本构建（DACC），它根据源分布优化方向和幅度码本。实验结果表明，即使在2位级别下，PCDVQ相较于基准方法至少提高了1.5%的零样本准确率，从而确立了一个新的准确且高度压缩的大语言模型范式。这一方法有效地解决了现有VQ方法中的方向与幅度敏感性差异较大的问题，提高了量化精度和模型压缩效率。

Conclusion: 
PCDVQ通过极坐标解耦显著改善了大语言模型的量化精度，尤其是在2位量化下，实现了至少1.5%的零样本准确率提升，构建了一种新的精准且高度压缩的大语言模型范式。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.05432</guid><pubDate>Fri, 27 Jun 2025 02:32:06 +0800</pubDate></item><item><title>550. cs.AI-复合流动匹配在具有偏移动力学数据的强化学习中的应用</title><link>https://arxiv.org/pdf/2505.23062</link><description>Background: 
利用预收集的离线数据可以显著提高强化学习（RL）的样本效率，但在源环境和目标环境的转换动力学存在差异时，这种优势常常受到挑战。现有方法通常通过惩罚或过滤掉在高动力学差异区域的源转换来解决这个问题。然而，它们的动力学差距估计往往依赖于KL散度或互信息，而在源和目标动力学具有不同分布的情况下，这些方法往往会失效。

Innovation: 
该研究提出了CompFlow方法，它是基于流动匹配和最优传输的理论联系而构建。具体而言，目标动力学被建模为基于源域流动输出分布的条件流动，而不是直接从高斯先验学习。这种方法提供了两大优势：(1) 改进学习目标动力学的泛化能力，(2) 提供基于源和目标转换 Wasserstein 距离的合理动力学差距估计。利用原理性的方法对动力学差距进行估计，研究进一步引入了一种乐观的主动数据收集策略，优先在高动力学差距区域探索，并理论上证明了这种策略能减少与最优策略的性能差距。实验证明，CompFlow在多个具有动力学偏移的RL基准测试中优于强基线方法。

Conclusion: 
CompFlow方法通过改进目标动力学学习的泛化能力和合理的动力学差距估计，解决了传统方法在源环境和目标环境转换动力学差异时的局限性。通过主动数据收集策略，进一步提高了方法的有效性和性能，验证了理论上的优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.23062</guid><pubDate>Fri, 27 Jun 2025 02:32:04 +0800</pubDate></item><item><title>551. cs.AI-TaxaDiffusion: 进阶训练的扩散模型用于细粒度物种生成</title><link>https://arxiv.org/pdf/2506.01923</link><description>Background: 
扩散模型在生成图像时通常将每个物种视为独立类别，这种方法忽略了物种之间视觉上的相似性，这些相似性通常体现在形状、模式和颜色的细微差别上。TaxaDiffusion 提出了一种基于分类学信息的训练框架，通过分级训练条件扩散模型，从门和纲这样的大类逐步精细到科和属，最终达到种的级别，以实现更精细和准确的图像生成能力，尤其是在使用少量训练样本时仍能保持高精度。

Innovation: 
TaxaDiffusion 的创新在于其采用分类学知识，通过分级训练条件扩散模型，从大类逐步精细到物种级别，捕捉共享祖先的粗略形态特征，再精细化到物种之间的细微差别。这种方式有助于提高细粒度图像生成的准确性和鲁棒性，即使在每个物种的训练样本有限的情况下也能保持高度保真度。

Conclusion: 
实验结果表明，TaxaDiffusion 在三个细粒度动物数据集上的表现优于现有方法，实现了在细粒度动物图像生成方面的更高保真度。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.01923</guid><pubDate>Fri, 27 Jun 2025 02:32:02 +0800</pubDate></item><item><title>552. cs.AI-A3：一种基于分析的注意力低秩逼近框架</title><link>https://arxiv.org/pdf/2505.12942</link><description>Background: 
大语言模型表现出色，但其庞大的参数量使得部署成本高昂。现有的低秩逼近方法主要集中在减少单个线性层的输出误差，而忽略Transformer架构特征，且将大规模权重矩阵分解为两个小的低秩矩阵。这种方法往往比剪枝和量化等其他压缩技术效果差，还会增加运行时额外的计算开销，例如额外的GEMM内核启动。

Innovation: 
提出了一种名为$tt A^tt 3$的训练后低秩逼近框架。$tt A^tt 3$将Transformer层划分为$tt QK$、$tt OV$和$tt MLP$三个功能组件，为每个组件提供一个减少隐藏维度大小的同时最小化功能损失（即注意力分数、注意力输出和MLP输出的误差）的解析解决方案。这种方法直接减小了模型大小、KV缓存大小和FLOPs，并且没有引入额外的运行时开销。$tt A^tt 3$还提供了一种全新的优化视角，从单一线性层损失优化转向整体性能的提升。实验结果显示，$tt A^tt 3$在保持性能的同时，相比于目前的最佳技术SOTA，例如在计算和内存预算相同的条件下，低秩逼近的LLaMA 3.1-70B在WikiText-2上的困惑度为4.69，优于此前SOTA的7.87，提升了3.18。$tt A^tt 3$还展示了其灵活性，包括KV缓存压缩、量化和混合低秩分配以增强性能。

Conclusion: 
通过广泛的实验，$tt A^tt 3$在保持性能方面表现优于当前的最佳技术。例如，在相同的计算和内存预算下，$tt A^tt 3$的低秩逼近LLaMA 3.1-70B在WikiText-2上的困惑度为4.69，优于此前SOTA的7.87。$tt A^tt 3$还展示了其在KV缓存压缩、量化和混合低秩分配等应用中的灵活性和潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.12942</guid><pubDate>Fri, 27 Jun 2025 02:31:58 +0800</pubDate></item><item><title>553. cs.AI-LLMs在基金投资中的专业性：DeepFund：一个实时竞技场视角</title><link>https://arxiv.org/pdf/2503.18313</link><description>Background: 
大型语言模型（LLMs）在各个领域展现出了令人印象深刻的性能，但在金融决策方面的实际效果尚未得到充分评价。当前的基准测试主要评估LLMs对金融文件的理解，而忽略了它们在动态市场条件下管理资产或挖掘交易机会的能力。尽管有新的基准测试用于评估金融领域的多样化任务，但这些基准测试存在数据泄漏、自我审查、过度干预和维护难度大的问题。因此，亟需填补研究缺口，提供一个更真实和公正的评估框架，以便全面了解和评估LLMs在基金投资中的潜力及其应用前景。

Innovation: 
我们引入了一个名为DeepFund的全面竞技平台，用于实时环境中评估基于LLM的交易策略。DeepFund采用多智能体框架，模拟现实世界的投资决策过程，并提供可访问的Web界面，用于展示不同市场条件下投资基金的表现和性能指标，支持详细的比较分析。通过DeepFund，我们旨在为LLMs在基金投资中的专业能力提供更真实的评估，并揭示其在实际金融市场的潜在应用。

Conclusion: 
我们的代码已经开源，通过DeepFund，我们期望提供一个更加真实和公平的评估框架，全面了解和评估LLMs在基金投资中的潜在应用，为未来的研究和实际应用提供多样化见解。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.18313</guid><pubDate>Fri, 27 Jun 2025 02:31:57 +0800</pubDate></item><item><title>554. cs.AI-迈向基于适应性记忆优化的增强检索增强生成</title><link>https://arxiv.org/pdf/2504.05312</link><description>Background: 
检索增强生成（RAG）通过将外部知识库中的非参数知识整合到模型中，已成为提高响应准确性和减轻事实错误和幻觉的有效方法。这种方法在问答（QA）任务中得到了广泛应用。然而，现有的RAG方法在开放式领域QA任务中效果不佳，因为它们进行独立的检索操作，并直接将检索到的信息融入生成中，没有保持总结性记忆或使用自适应检索策略，导致重复信息噪声和信息整合不足的问题。

Innovation: 
为解决上述挑战，本文提出了一种针对开放式领域QA任务的自适应记忆优化增强的RAG（Amber），它包括基于代理的记忆更新器、自适应信息收集器和多粒度内容过滤器，共同工作在迭代记忆更新模式中。Amber通过多代理协作方法，确保了从先前检索步骤中进行全面知识整合。它可以动态调整检索查询并根据累积的知识决定何时停止检索，提高了检索效率和效果。此外，通过在多个层面过滤无关内容来减少噪声，保留关键信息，从而提升整体模型性能。

Conclusion: 
我们在几个开放式领域QA数据集上进行了广泛的实验，实验结果证明了我们方法及其组件的优越性和有效性。源代码可在以下链接获取。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.05312</guid><pubDate>Fri, 27 Jun 2025 02:31:57 +0800</pubDate></item><item><title>555. cs.AI-JointDiT：利用扩散变压器增强RGB-深度联合建模</title><link>https://arxiv.org/pdf/2505.00482</link><description>Background: 
文章介绍了一种名为JointDiT的扩散变压器，它能够建模RGB和深度的联合分布。通过利用当前最先进的扩散变压器的架构优势和出色的图像先验，JointDiT不仅能生成高保真度的图像，还能生成几何上合理且准确的深度图。这种联合分布的建模是通过我们提出的一种适用于每个模态噪声水平的自适应调度权重和不平衡时间步长采样策略实现的。这些技术使得我们的模型可以在所有噪声水平下分别训练，从而让JointDiT能够自然地处理各种组合生成任务，包括联合生成、深度估计和基于深度条件的图像生成，只要通过控制每个分支的时间步骤即可实现。

Innovation: 
JointDiT采用自适应调度权重，依赖于每个模态的噪声水平，以及不均衡时间步长采样策略，从而实现跨模态噪声水平的训练。这种方法使得模型能够自然地处理各种联合生成任务，而无需复杂的额外操作。JointDiT在联合生成方面表现出色，并且在深度估计和深度条件图像生成方面也取得了可比的结果，这表明联合分布建模可以作为一种替代手段取代条件生成。

Conclusion: 
JointDiT不仅展示了卓越的联合生成性能，还在深度估计和深度条件图像生成中取得了与现有模型相当的效果。这表明联合分布建模可以作为一种可替代的条件生成方法。通过这种建模方式，JointDiT可以在不增加额外复杂性的前提下处理多种生成任务。有兴趣的读者可以在以下链接中找到详细信息：this https URL。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.00482</guid><pubDate>Fri, 27 Jun 2025 02:31:56 +0800</pubDate></item><item><title>556. cs.AI-Thinkless: LLM Learns When to Think</title><link>https://arxiv.org/pdf/2505.13379</link><description>Background: 
推理语言模型能够进行扩展的链式推理，在复杂逻辑推理任务中表现出色。然而，对于所有查询都采用复杂的推理会导致巨大的计算效率低下，特别是当许多问题可以有简单解决方案时。这引发了一个开放性问题：语言模型能否学会何时进行推理？

Innovation: 
本文提出了一个名为Thinkless的可学习框架，使语言模型能够根据任务复杂性和模型能力，自适应选择短推理和长推理模式。Thinkless通过强化学习训练，并采用两个控制标记，&amp;lt;short&amp;gt;用于简短回答，&amp;lt;think&amp;gt;用于详细推理。核心算法是Decoupled Group Relative Policy Optimization (DeGRPO)，它将混合推理的学习目标分解为两部分：（1）控制标记损失，用于治理推理模式的选择；（2）回答损失，用于提高生成答案的准确性。这种解耦形式使得对每个目标的贡献能够进行细粒度控制，稳定训练并有效防止了通用GRPO中观察到的崩塌现象。实验结果显示，Thinkless能够将长链思考的使用降低50%-90%，显著提高了推理语言模型的效率。

Conclusion: 
Thinkless能够显著降低长链思考的使用，提高推理语言模型的效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.13379</guid><pubDate>Fri, 27 Jun 2025 02:31:55 +0800</pubDate></item><item><title>557. cs.AI-能量匹配：结合流匹配和能量模型的生成建模</title><link>https://arxiv.org/pdf/2504.10612</link><description>Background: 
当前最常用的生成模型通过匹配流动或分数来将噪声和数据分布联系起来，但在处理部分观察和额外先验信息方面存在局限性，而能量模型能够通过简单的加法解决这些问题。本文提出了能量匹配框架，使基于流的方法具有与能量模型相当的灵活性，从而解决了该问题。

Innovation: 
提出的能量匹配框架通过在远离数据流形时采用无旋的最优输运路径，使噪声样本到数据样本的转移最优，当接近数据流形时，加入的混熵能量项引导系统进入玻尔兹曼平衡分布，明确捕捉数据的潜在概率结构。该方法使用单一的时间无关标量场参数化此动态，不仅作为强大的生成器，还作为灵活的先验，用于有效的逆问题正则化。

Conclusion: 
该方法在CIFAR-10和ImageNet生成方面的保真度上显著优于现有能量模型，同时允许基于输运方法在远离数据流形的训练中不进行模拟。此外，利用方法的灵活性，引入了一种交互能量，支持多模式探索，通过受控蛋白质生成实验进行了验证。提出的方法专注于学习一个标量势能，这标志着与最近的能量模型方法的重要区别，我们认为这一简化框架显著提升了能量模型的能力，并为其在各种领域的生成建模中的广泛应用铺平了道路。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.10612</guid><pubDate>Fri, 27 Jun 2025 02:31:51 +0800</pubDate></item><item><title>558. cs.AI-AirCache: 激活跨模态相关性 KV 缓存压缩以实现高效的大规模视觉语言模型推理</title><link>https://arxiv.org/pdf/2503.23956</link><description>Background: 
大型视觉语言模型（LVLM）由于其出色的推理能力和泛化能力而引起了广泛关注。然而，处理大量视觉标记和生成长上下文输出需要大量的计算资源，使得关键值（KV）缓存承受巨大压力。现有方法无法有效缓解这一瓶颈问题，显著增加了计算负担。因此，需要提出一种新的KV缓存压缩方法来加速LVLMs的推理速度。

Innovation: 
本文提出了一种名为AirCache的新颖KV缓存压缩方法，旨在提高LVLMs推理速度。通过系统地研究注意力机制中的视觉和文本标记相关性，发现了缓存中的视觉标记具有大量冗余。该方法采用精英观察窗口评估视觉组件在KV缓存中的重要性，加强多视角的一致性，并采用自适应分层预算分配策略来应对token重要性分布的强和偏斜特性。实验结果表明，这种方法可以在保留仅10%视觉KV缓存的情况下，实现与完整缓存相当的性能，同时将解码延迟降低29%到66%。当缓存保留率降低时，该方法表现出越来越明显的优势。

Conclusion: 
该研究通过充分压缩视觉标记的KV缓存，实现重大性能提升，验证了AirCache方法的优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.23956</guid><pubDate>Fri, 27 Jun 2025 02:31:48 +0800</pubDate></item><item><title>559. cs.AI-AI驱动的情感分析：在电子商务领域的商业价值解锁</title><link>https://arxiv.org/pdf/2504.08738</link><description>Background: 
电子商务的快速发展产生了大量的客户反馈，从产品评价到服务互动。从这些数据中提取有意义的洞察对于企业提升客户满意度和优化决策至关重要。

Innovation: 
本文提出了一种专门针对电子商务应用的AI驱动情感分析系统，结合传统机器学习技术和现代深度学习模型，实现了更细致的情感理解并保证决策透明度。实验结果显示，该系统在多种大规模数据集上的准确率为89.7%，优于标准情感分析方法。实际部署证明了在多个电子商务平台上的客户参与和运营效率的实际提升。研究强调了在商业环境中应用AI进行情感分析的潜力与挑战，并提供了实用部署策略和未来改进领域的见解。

Conclusion: 
本研究表明，AI驱动的情感分析系统能够在电子商务领域有效提升客户参与度和运营效率，同时也指出了实际应用中的潜在挑战，为企业提供了实用部署建议和技术改进方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.08738</guid><pubDate>Fri, 27 Jun 2025 02:31:48 +0800</pubDate></item><item><title>560. cs.AI-受奖励指引的推测性解码以提高大语言模型推理的效率</title><link>https://arxiv.org/pdf/2501.19324</link><description>Background: 
该论文介绍了一种名为Reward-Guided Speculative Decoding (RSD)的新框架，旨在提高大语言模型（LLMs）推理的效率。现有的一些推测性解码方法大多旨在保持解码过程的无偏性，但RSD则在此基础上引入了一个轻量级草稿模型与更强大的目标模型的结合，并通过奖励来引导解码过程，从而更高效地生成高质量的输出。

Innovation: 
RSD框架的创新点在于它通过结合轻量级草稿模型和更强大的目标模型，利用奖励机制来引导解码过程，并动态决定何时调用目标模型。这不仅优化了计算成本与输出质量之间的权衡，还提出了一种基于阈值的混合策略，理论证明能够实现资源利用与性能的最佳平衡。与仅使用目标模型直接解码相比，RSD在挑战性的推理任务上表现出更高的效率和准确性。

Conclusion: 
研究结果证明，RSD作为一种在资源密集型场景下高效部署大语言模型的稳健且成本效益高的方法，具有显著的优越性。该方法在一系列困难的推理基准测试中显著降低了FLOPs（高达4.4倍）并提高了平均准确性（高达3.5%）。RSD的代码可以在以下链接下载：this https URL.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.19324</guid><pubDate>Fri, 27 Jun 2025 02:31:47 +0800</pubDate></item><item><title>561. cs.AI-DisCoPatch: 利用对抗性驱动的批统计数据改善的离分布检测</title><link>https://arxiv.org/pdf/2501.08005</link><description>Background: 
离分布（OOD）检测在许多应用中都具有重要意义。虽然语义和领域转移的OOD问题已经得到了很好的研究，但这项工作关注的是协变迁移——数据分布中的细微变化，这些变化可能会影响机器学习的性能。我们假设检测这些细微变化可以改善我们对概率分布边界的理解，从而最终提升OOD检测的效果。在使用批量归一化（BN）进行训练的对抗性判别器中，真实样本和对抗性样本会形成具有独特批量统计特性的不同领域，这种特性被利用来进行OOD检测。

Innovation: 
作者提出了DisCoPatch，一种无监督的对抗性变分自编码器（VAE）框架，利用对抗性驱动的批统计数据。在推理过程中，批次由来自同一图像的补丁组成，保证了数据分布的一致性，使模型能够依赖于批量统计。DisCoPatch使用VAE的亚优输出（生成和重建）作为负样本来训练判别器，从而提高其区分内在分布样本和协变迁移的能力。通过紧化边界，DisCoPatch在公共OOD检测基准测试中达到了最先进的结果。与之前的模型相比，该模型在ImageNet-1K(-C)上的AUROC达到了95.5%，并且在公共Near-OOD基准测试中也超过了所有先前的方法。由于模型大小仅为25MB，该方法在保持较高OOD检测性能的同时，显著降低了延迟，提供了现实世界OOD检测应用中的高效和实用解决方案。

Conclusion: 
DisCoPatch通过利用对抗性驱动的批统计数据，不仅在检测协变迁移方面表现出色，达到了95.5%的AUROC，而且在公共Near-OOD基准测试中也超过了所有先前的方法。该模型在保持较高OOD检测性能的同时，显著降低了延迟，适用于实际的OOD检测应用。代码已经公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.08005</guid><pubDate>Fri, 27 Jun 2025 02:31:46 +0800</pubDate></item><item><title>562. cs.AI-Lagrangian Index Policy for Restless Bandits with Average Reward</title><link>https://arxiv.org/pdf/2412.12641</link><description>Background: 
该研究探讨了长运行平均奖励条件下不可静止多臂-bandits（RMB）的拉格朗日指标策略（LIP）。LIP 和威布尔指标策略（WIP）都是在某些自然条件下被认为渐近最优的启发式策略。虽然它们的性能在大多数情况下非常接近，但在WIP表现不佳的情况下，LIP依然表现出色。此外，研究还提出了无模型设置下的强化学习算法，用于在线学习LIP策略，这些算法所需的内存显著少于WIP的类似方法。另外，还对重启模型的拉格朗日指标进行了解析计算，适用于最优网页抓取和加权信息年龄的最小化问题。研究还基于交换性和de Finetti定理，给出了同质臂数量趋于无穷的渐近最优性的新证明。

Innovation: 
本文提出的拉格朗日指标策略（LIP）和多种强化学习算法（包括基于表格和神经网络的）显著改进了不可静止多臂-bandits（RMB）的长运行平均奖励场景下的性能。特别地，在WIP表现不佳的情况下，LIP仍能保持良好的性能。此外，基于交换性和de Finetti定理的新证法也为研究提供了新的理论支持。这些方法还在基于重启模型的网页抓取和加权信息年龄最小化等实际问题中有所应用。

Conclusion: 
通过对拉格朗日指标策略（LIP）的研究及其在不可静止多臂-bandits中的应用，证明了LIP相较于威布尔指标策略（WIP）具有更强的适应性和性能稳定性。提出的无模型强化学习算法显著节省了内存需求，并且在处理实际问题时显示出良好的表现。基于重启模型的拉格朗日指标的解析计算为进一步优化网页抓取策略和信息年龄管理提供了实用工具。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.12641</guid><pubDate>Fri, 27 Jun 2025 02:31:42 +0800</pubDate></item><item><title>563. cs.AI-Zero-TIG：提升低光照和水下视频照度指导的一致性感知零样本低光视频增强</title><link>https://arxiv.org/pdf/2503.11175</link><description>Background: 
低光照和水下视频存在能见度差、对比度低、噪声高等问题，需要提升视觉质量。现有方法通常依赖配对的真实标签，这限制了它们的实际应用并往往无法维持时间一致性。现有的方法面临这些挑战，本文提出了一种新的零样本学习方法Zero-TIG，结合了Retinex理论和光流技术。该方法通过增强模块和时间反馈模块来解决这些问题，并通过光流计算、直方图均衡化和图像变换等手段确保时序一致性，同时通过适当地平衡RGB通道来解决水下数据的颜色失真问题。实验结果表明，该方法在不需要配对训练数据的情况下实现了低光照视频的增强，具备在现实场景应用的潜力

Innovation: 
引入了零样本学习方法Zero-TIG，该方法通过Retinex理论和光流技术结合，提出了一种包含增强模块和时间反馈模块的网络，能够不需要配对的训练数据，提高低光照和水下视频的视觉质量，并确保时间一致性

Conclusion: 
实验结果表明，Zero-TIG方法在低光照视频增强方面表现良好，无需配对的真实标签，为实际应用提供了新的方法.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.11175</guid><pubDate>Fri, 27 Jun 2025 02:31:40 +0800</pubDate></item><item><title>564. cs.AI-使用基于强化的扩散（NERD）模型揭示噪声预期的不确定性脑神经表示</title><link>https://arxiv.org/pdf/2503.14333</link><description>Background: 
研究通常旨在揭示?初级?表征（FORs），这些表征编码观察者环境的方面，如内容或结构。较少研究的是?高级?表征（HORs），这些表征?关于?FORs，如它们的强度或不确定性，并可能促进学习。HORs关于不确定性的表现不太可能是FOR特征的直接'读出'，而是反映了包含关于不确定性的先验预期的嘈杂估计过程。有关预计不确定性分布的脑部表示仍然知之甚少。

Innovation: 
我们开发并应用了一种名为Noise Estimation through Reinforcement-based Diffusion (NERD)模型，来研究大脑可能如何处理噪声学习过程。结果显示，NERD模型对人类行为有很高的解释力。这种方法有助于揭示关于不确定性的高级表征如何被大脑表示，并为理解神经反馈的任务中如何实现自我噪声的适应性学习提供了新的见解。

Conclusion: 
NERD模型在解码神经反馈任务中的应用表明，它能够很好地解释人类的学习过程如何处理预期的噪声不确定性。这为研究高级不确定性的脑部表示和改善神经反馈技术提供了新的理论框架。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.14333</guid><pubDate>Fri, 27 Jun 2025 02:31:40 +0800</pubDate></item><item><title>565. cs.AI-Materialist: 单张图像逆向渲染的物理基础编辑方法</title><link>https://arxiv.org/pdf/2501.03717</link><description>Background: 
在计算机视觉中，实现物理上一致的图像编辑仍然是一个显著的挑战。现有的图像编辑方法通常依赖神经网络，但它们在处理阴影和折射时很难精确操作。与此相反，基于物理的逆向渲染需要多视图优化，使其在单图像场景中并不实用。

Innovation: 
本文提出了Materialist方法，该方法结合了基于学习的方法与基于物理的渐进可微渲染。给定一张图像，该方法使用神经网络预测初始的材质属性。然后通过渐进可微渲染优化环境图，并细化材质属性，以确保渲染结果紧密匹配输入图像。该方法能够支持材料编辑、物体插入和重新照明等多种应用，同时提供了一种有效的透明材质编辑方法，无需完整场景几何结构。此外，该方法的环境图估计方法达到了最先进的性能，进一步提高了图像编辑任务的准确性。

Conclusion: 
实验结果表明，该方法在合成和真实世界数据集上表现出强大的性能，甚至在具有挑战性的域外图像上也表现出色。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.03717</guid><pubDate>Fri, 27 Jun 2025 02:31:39 +0800</pubDate></item><item><title>566. cs.AI-CREStE：具有互联网规模先验和逆向事实指导的可扩展无地图导航</title><link>https://arxiv.org/pdf/2503.03921</link><description>Background: 
本文介绍了一种名为CREStE的新框架，旨在解决室外城市导航中的开放世界泛化和鲁棒性挑战。该框架的关键在于学习能够泛化到未见过的因素（例如新型语义类别、地形、动态实体）的感知表示，并从有限的演示中推断出专家对齐的导航成本。

Innovation: 
CREStE的创新之处在于通过引入1) 视觉基础模型（VFM）蒸馏目标来学习开放集结构的鸟瞰图感知表示，以及2) 逆向事实逆强化学习（IRL），这是一种利用逆向事实轨迹演示来推理当推断导航成本时最重要的线索的新型主动学习方法。

Conclusion: 
CREStE在多种城市、越野和住宅环境中对公里级的无地图导航任务进行了评估，并发现其性能超过了所有现有的最先进技术，只需要70%更少的人工干预，包括在未知环境中仅通过1次干预完成2公里任务，显示出其在长时域无地图导航中的鲁棒性与有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.03921</guid><pubDate>Fri, 27 Jun 2025 02:31:39 +0800</pubDate></item><item><title>567. cs.AI-PP-DocBee：通过多种技巧提高多模态文档理解能力</title><link>https://arxiv.org/pdf/2503.04065</link><description>Background: 
随着数字化的快速发展，各类文档图像在生产和生活中得到了更广泛的应用，对文档图像内容的快速准确解析需求日益迫切。因此，本文提出了PP-DocBee，一种针对端到端文档图像理解的新型多模态大语言模型。该模型通过构建多样化数据集来提升模型的泛化能力，并采用了动态比例采样、数据预处理及OCR后处理等一系列训练技巧。

Innovation: 
PP-DocBee模型通过定制化数据合成策略构建了多样的数据集，提升了模型的泛化能力；采用了动态比例采样、数据预处理和OCR后处理等多种训练技术。该模型在英语文档理解基准测试中达到了最先进的性能，并在中文文档理解上超越了现有开源和商用模型。模型的源代码和预训练模型已公开发布。

Conclusion: 
PP-DocBee在文档图像理解方面表现出卓越的性能，特别是在中文文档理解上超越了现有的开源和商用模型，并且其源代码和预训练模型已公开发布。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2503.04065</guid><pubDate>Fri, 27 Jun 2025 02:31:37 +0800</pubDate></item><item><title>568. cs.AI-金融市场中异质性学习者：贝叶斯学习者与无遗憾学习者之间的动态及其生存</title><link>https://arxiv.org/pdf/2502.08597</link><description>Background: 
本文分析了资产市场中具有随机支付的异质学习者的表现。研究主要集中在比较贝叶斯学习者和无遗憾学习者在市场上的竞争，以及在何种条件下每种方法更有效。研究表明，低遗憾并不足以保证生存：即使遗憾低至$O(text{log } T)$，当与具有有限先验和正确模型任何正先验概率的贝叶斯学习者竞争时，一个实体仍然可能消失。另一方面，证实了贝叶斯学习的脆弱性，无遗憾学习则需要更少的环境先验知识，因此更为稳健。

Innovation: 
受到这两种方法的优点与弱点启发，提出了利用贝叶斯更新的一种平衡策略，增强了稳健性和在分布变化时的适应性，提供了一种兼顾二者优点的学习方法。该方法是通用的、高效的且易于实现。此外，正式建立了金融市场中生存和市场主导理论与遗憾最小化框架之间的关系，从而联通了这些理论之间的联系。更广泛地，本研究丰富了对不同学习者类型的动态及其对市场影响的理解。

Conclusion: 
最终，本文在理论上确立了市场生存和市场主导理论与遗憾最小化框架的联系，促进了对异质性学习者动态及其市场影响的理解。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2502.08597</guid><pubDate>Fri, 27 Jun 2025 02:31:32 +0800</pubDate></item><item><title>569. cs.AI-通过掩码自动编码器学习实验室值表示</title><link>https://arxiv.org/pdf/2501.02648</link><description>Background: 
在电子健康记录（EHRs）中准确填补缺失的实验室值对于临床预测的稳健性和减少AI系统中的偏差至关重要。现有方法如XGBoost、softimpute、GAIN、EM和MICE难以建模EHR数据中的复杂时间和上下文依赖关系，特别是在少数群体中更为明显。

Innovation: 
该研究提出了一种名为Lab-MAE的新颖自监督学习下的掩码自动编码器框架，用于连续序列实验室值的填补。Lab-MAE引入了一种结构化的编码方案，联合建模实验室测试值及其对应的时序信息，使其能够明确捕捉到时间依赖性。实验证明，Lab-MAE在MIMIC-IV数据集上的表现显著优于XGBoost、softimpute、GAIN、EM和MICE等各种基线方法。特别地，Lab-MAE在不同患者的人口统计学群体中实现了公平的性能，推动了临床预测的公平性。此外，研究还调查了随访实验室值作为潜在捷径特征的角色，揭示了当此类数据不可用时Lab-MAE的鲁棒性。

Conclusion: 
研究建议，适应EHR数据特性的变压器架构为更准确和公平的临床填补提供了基础模型。此外，研究还对比了Lab-MAE与XGBoost模型的碳足迹，突显了其环境要求。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2501.02648</guid><pubDate>Fri, 27 Jun 2025 02:31:28 +0800</pubDate></item><item><title>570. cs.AI-SIDA: 社交媒体图像深度伪造检测、定位与解释，使用大型多模态模型</title><link>https://arxiv.org/pdf/2412.04292</link><description>Background: 
随着生成模型在生成高度逼真图像方面取得快速进展，这带来了大量错误信息传播的风险。虚假的合成图像在社交媒体上传播可能会导致广泛的误导，削弱人们对数字内容的信任，产生严重后果。尽管有所进步，目前学术界尚未创建一个大规模、多样化的真实与合成图像检测数据集，也没有找到有效的解决方案来应对这一问题。

Innovation: 
本文介绍了社交媒体图像检测数据集（SID-Set），具有三个关键优势：（1）广泛的规模，包含30万张由AI生成或篡改的真实图像，并附有全面注释；（2）广泛的多样性，涵盖不同类别的完全合成和篡改图像；（3）极高的逼真度，图像在视觉检查下难以区分。此外，结合大型多模态模型的卓越功能，提出了一种新的图像深度伪造检测、定位和解释框架，名为SIDA（社交媒体图像检测、定位和解释助手）。SIDA不仅能判断图像的真实性，还能通过掩码预测标出篡改区域，并提供模型判断标准的文本解释。

Conclusion: 
在SID-Set和其他基准上与现有最先进的深度伪造检测模型进行的广泛实验表明，SIDA在各种设置中表现更优。模型、数据集和代码将被公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.04292</guid><pubDate>Fri, 27 Jun 2025 02:31:26 +0800</pubDate></item><item><title>571. cs.AI-ToolScan: 评估工具使用大型语言模型错误的一种基准</title><link>https://arxiv.org/pdf/2411.13547</link><description>Background: 
评估大型语言模型（LLMs）是构建高性能复合人工智能系统的关键方面，因为LLMs的输出会传递到下游步骤中，识别LLMs的错误对于系统的性能至关重要。在人工智能系统中，LLMs常见的任务之一是使用工具。目前有很多用于评估LLMs使用工具任务的基准环境，但这些基准环境通常只给出成功率，而没有解释失败案例。

Innovation: 
为了解决上述问题，我们引入了TOOLSCAN，这是一个新的基准工具，用于识别LLMs在工具使用任务中输出的错误模式。基准数据集包括来自不同环境的查询，可以用来测试存在七种新表征的错误模式。通过TOOLSCAN，我们展示了即使是最著名的LLMs在其输出中也表现出这些错误模式。研究人员可以根据TOOLSCAN提供的洞见，指导其错误缓解策略。

Conclusion: 
使用TOOLSCAN，我们展示了即使是目前最显著的LLMs在工具使用任务中也会表现出这些特定错误模式。研究人员可以根据从TOOLSCAN得到的洞见来指导他们的错误缓解策略，从而改进LLMs的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.13547</guid><pubDate>Fri, 27 Jun 2025 02:31:25 +0800</pubDate></item><item><title>572. cs.AI-GASP: 效率高且黑盒生成对抗后缀以攻破LLM</title><link>https://arxiv.org/pdf/2411.14133</link><description>Background: 
大规模语言模型（LLMs）在各种自然语言处理任务中展示了令人印象深刻的能力，但在安全性方面仍存在缺陷，特别是对于精心设计的输入提示（称为禁锢攻击）的易感性。这些攻击旨在绕过安全防护措施并引发有害响应。传统的安全防护方法依赖于手动启发式规则，但这种方法具有局限性，难以广泛适用。自动化攻击方法虽然能够自动生成攻击性提示，但往往导致生成不自然且容易被安全过滤器检测到的提示，或者由于离散令牌优化耗时较长。

Innovation: 
本文引入了一种创新的自动化框架——生成对抗后缀提示器（GASP），能够在完全黑盒的环境中高效地生成易于理解的攻击性后缀提示。GASP采用潜在贝叶斯优化技术，通过高效探索连续潜在嵌入空间来创建对抗后缀，同时通过目标导向的迭代优化过程逐渐优化后缀提示器以提高攻击效果，保持提示的连贯性。实验结果表明，GASP生成的对抗性后缀提示更加自然，显著提高了禁锢成功，缩短了训练时间并加快了推理速度，因此成为一种高效的、可扩展的红队评估LLM安全性的解决方案。

Conclusion: 
通过全面的实验，GASP展示了其在生成自然且高效的攻击性后缀方面的优势，明显优于基线方法，缩短了训练时间和加快了推理速度，因此成为对LLM进行红队测试的有效且可扩展的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.14133</guid><pubDate>Fri, 27 Jun 2025 02:31:23 +0800</pubDate></item><item><title>573. cs.AI-InfiniCube：基于世界导向视频模型的无限可控动态3D驾驶场景生成</title><link>https://arxiv.org/pdf/2412.03934</link><description>Background: 
之前的场景生成方法要么规模有限，要么在生成序列中缺乏几何和外观的一致性。这项研究利用了可扩展的3D表示和视频模型的最新进展，以实现具有灵活控制的大动态场景生成，可以利用高清地图、车辆边界框和文本描述。

Innovation: 
提出了一种名为InfiniCube的方法，该方法使用地图条件的稀疏体素生成模型、重新利用的视频模型以及通过精细设计的像素对齐指导缓冲来生成一致的外观。最终，提出了一种高效前馈方法，结合了体素和像素分支，提升动态视频为动态3D高斯分布，实现可控且真实的三维驾驶场景。

Conclusion: 
该方法能够生成可控且真实的三维驾驶场景，广泛实验验证了该模型的有效性和优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.03934</guid><pubDate>Fri, 27 Jun 2025 02:31:19 +0800</pubDate></item><item><title>574. cs.AI-Recall and Refine: 一种简单而有效的无源开放集域适应框架</title><link>https://arxiv.org/pdf/2411.12558</link><description>Background: 
开放集域适应（OSDA）旨在将带有标签的源域模型适应到未标记者目标域，其中目标域可能存在新的类——也称为目标私有未知类。无源开放集域适应（SF-OSDA）方法在不对源域进行标记数据访问的情况下解决OSDA问题，这使得它们在隐私约束方面特别相关。然而，SF-OSDA面临着分布偏移和新型类引入带来的显著挑战。现有方法通常依赖于以样本预测熵为阈值来识别已知类和未知类，但未能显式学习目标私有未知类的判别特征。

Innovation: 
本文提出了一种名为Recall and Refine（RRDA）的新型SF-OSDA框架，该框架通过显式地学习目标私有未知类的特征来解决上述限制。RRDA采用两阶段过程：首先，通过使用来自目标域特征的合成样本作为引导，训练目标分类器，使其能够区分已知类和未知类；其次，适应整个模型，解决领域偏移和对未知类的区分问题。任何现成的无源域适应方法（如SHOT，AaD）都可以在这个阶段无缝集成到框架中。

Conclusion: 
在三个基准数据集上的广泛实验表明，RRDA在无源开放集域适应和OSDA方法中表现出显著的优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.12558</guid><pubDate>Fri, 27 Jun 2025 02:31:18 +0800</pubDate></item><item><title>575. cs.AI-预训练可逆生成作为无监督视觉特征学习</title><link>https://arxiv.org/pdf/2412.01787</link><description>Background: 
近期基于评分匹配和流匹配的生成模型在生成任务中取得了显著进展，但它们在判别任务中的潜力尚未得到充分挖掘。尽管前有生成分类器等方法试图利用这些模型在判别任务中的能力，但由于设计复杂，仍未充分发挥这些模型的优点。

Innovation: 
我们提出了一种名为Pretrained Reversible Generation (PRG)的新方法，通过反向使用预训练的连续生成模型进行生成过程，提取无监督表示。PRG有效地再利用了预训练的生成模型，利用其强大的能力作为鲁棒且通用的特征提取器，以适应下游任务。该架构允许为特定的下游任务灵活选择特征层次结构。

Conclusion: 
我们的方法在多个基准测试中表现出色，相较于之前的基于生成模型的方法，均取得了领先性能，特别是在ImageNet 64*64分辨率上实现了78%的top-1精度。广泛的消融研究表明，我们的方法在分布外评估等方面也非常有效。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.01787</guid><pubDate>Fri, 27 Jun 2025 02:31:18 +0800</pubDate></item><item><title>576. cs.AI-发音提示：增强LLM多语言能力以适用于非拉丁语系语言</title><link>https://arxiv.org/pdf/2411.02398</link><description>Background: 
尽管多语言LLM已经在各类基准测试中取得了显著的性能，但是它们在非拉丁语系语言方面仍然表现不佳。这种差异源于LLM在进行预训练时主要处理的是使用拉丁字符的拼写系统，这些系统掩盖了非拉丁语系语言的共享音位学特征。我们的研究通过引入音位转录作为补充信号，来产生对不同字体系统的不变表示，从而改善了对非拉丁语系和拉丁语系语言的性能。通过详细实验，我们证明音位和拼写用于上下文学习以检索不同的例子，这激发了我们提出的混合上下文学习（Mixed-ICL）检索策略，其对拉丁语系和非拉丁语系语言的性能改善显著，拉丁语系语言的提高最高可达12.6%，非拉丁语系语言的提高最高可达15.1%。

Innovation: 
提出使用音位信号作为补充信号，以产生对不同字体系统的不变表示，这种策略显著提高了非拉丁语系和拉丁语系语言的性能，尤其是缩小了两者之间的表现差距。通过实验，表明音位和拼写在上下文学习中检索到的是不同的例子，从而提出了混合上下文学习（Mixed-ICL）检索策略，进一步聚合两者提高了两种字体系统的性能，拉丁语系语言高达12.6%，非拉丁语系语言高达15.1%。

Conclusion: 
研究表明，通过利用音位信号可以有效提升多语言LLM在非拉丁语系语言和拉丁语系语言上的性能，特别是在降低两者之间表现差距方面效果显著。进一步采用混合上下文学习（Mixed-ICL）检索策略，实现了性能的进一步提升。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.02398</guid><pubDate>Fri, 27 Jun 2025 02:31:16 +0800</pubDate></item><item><title>577. cs.AI-MvKeTR：使用多视图感知和知识增强的胸部CT报告生成</title><link>https://arxiv.org/pdf/2411.18309</link><description>Background: 
CT报告生成（CTRG）旨在自动生成3D体积的诊断报告，减轻临床医生的工作负担并改善患者护理。尽管CTRG具有临床价值，现有的方法无法有效地综合多视角的解剖信息，且缺乏必要的临床专业知识，导致诊断不够准确可靠。

Innovation: 
提出了一种新型的多视角感知知识增强Transformer（MvKeTR），以模拟临床医生的诊断工作流程。MvKeTR包含多视角感知聚合器（MVPA），能够通过视图感知的注意力机制有效合成多解剖视角的诊断信息，并借鉴放射科医生如何参考相关临床记录来指导诊断决策的方式，引入断层结构知识检索器（CMKE），根据查询的体积检索最相似的报告，结合领域的知识进行诊断。此外，采用柯尔莫哥洛夫-阿诺德网络（KANs）作为模块的基础构建块，表现出更好的参数效率和降低的光谱偏差，更好地捕捉CT解读中至关重要的高频率成分，降低过拟合.

Conclusion: 
在公共的CTRG-Chest-548K数据集上进行了大量实验，证明了该方法在几乎所有指标上都优于现有的SOTA模型。相关代码可在提供的链接中获取。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.18309</guid><pubDate>Fri, 27 Jun 2025 02:31:15 +0800</pubDate></item><item><title>578. cs.AI-PuriDefense: 随机局部隐式对抗净化防御面向黑盒查询导向攻击</title><link>https://arxiv.org/pdf/2401.10586</link><description>Background: 
黑盒查询导向的攻击对机器学习即服务（MLaaS）系统构成重大威胁，因为它们可以在不访问目标模型架构和参数的情况下生成对抗样本。传统的防御机制，如对抗训练、梯度掩蔽和输入转换，要么会带来巨大的计算成本，要么会降低非对抗性输入的测试准确性。面对这些挑战，需要一种在较低计算成本下能够有效对抗查询导向攻击的防御机制。

Innovation: 
我们提出了一种名为PuriDefense的高效防御机制，它利用了低层次推理成本下的随机块级净化，并使用轻量级净化模型的集成。这些模型利用局部隐式函数并重塑自然图像流形。理论分析表明，这种方法通过向净化中引入随机性，减缓了查询导向攻击的收敛速度。在CIFAR-10和ImageNet上的广泛实验验证了基于净化的防御机制的有效性，展示了对抗查询导向攻击时的显著增强鲁棒性。

Conclusion: 
我们的研究表明，PuriDefense能够在保持模型测试准确性的前提下，提供有效的黑盒查询导向攻击防御。实验结果表明，PuriDefense在CIFAR-10和ImageNet数据集上显著提高了对抗查询导向攻击的鲁棒性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2401.10586</guid><pubDate>Fri, 27 Jun 2025 02:31:12 +0800</pubDate></item><item><title>579. cs.AI-InterFormer: Effective Heterogeneous Interaction Learning for Click-Through Rate Prediction</title><link>https://arxiv.org/pdf/2411.09852</link><description>Background: 
点击率（CTR）预测是推荐系统中的基本任务，它预测用户点击广告的概率。用户行为序列和用户配置文件等异构信息描述了用户兴趣的不同方面。要成功进行CTR预测，重要的是在不同模式之间实现互惠的信息整合。然而，现有方法主要面临两个限制：（1）模式间信息传递单向导致交互不够充分，（2）早期总结导致信息过度总结并丢失过多信息。

Innovation: 
为了克服上述限制，我们提出了一种名为InterFormer的新模块，以交错方式进行学习来学习异构信息的交互。InterFormer实现了不同的模式之间的双向信息流，以实现更有效的互惠学习。为了防止信息过度总结，InterFormer在每个数据模式中保留了完整的信息，并使用独立的桥梁架构进行有效信息的选择和总结。实验表明， InterFormer在三个公开数据集和一个大规模工业数据集上达到了最新的性能水平。

Conclusion: 
InterFormer通过交错方式学习异构信息交互，并实现了不同模式之间的双向信息流，解决了现有方法中存在的主要信息交互不足和信息过度总结问题。实验结果表明，InterFormer在三个公开数据集和一个大规模工业数据集上具有最先进的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.09852</guid><pubDate>Fri, 27 Jun 2025 02:31:12 +0800</pubDate></item><item><title>580. cs.AI-无人机图像中高级计算机视觉提取地理参考车辆轨迹</title><link>https://arxiv.org/pdf/2411.02136</link><description>Background: 
该论文介绍了从高空无人机图像中提取地理参考车辆轨迹的框架，解决了城市交通监控中的关键挑战及其对传统地面系统的限制。研究区域选在了韩国首尔的松岛国际商务区，实验覆盖了20个交叉口，采集了四天内大约12TB的4K视频数据，展示了无人机交通监控系统的可行性和实用性。

Innovation: 
该论文的创新之处在于提出了一系列新颖贡献，包括一种针对高海拔鸟瞰视角的定制化物体检测器，一种使用检测到的车辆边界框作为排除掩膜进行图像注册的独特的轨迹稳定方法，以及一种通过正射影像和主图帧进行地理参考的方法，增强了多无人机视角之间的一致对齐。此外，该框架还具备鲁棒的车辆尺寸估计和详细的道路细分功能，增强了全面的交通分析能力。通过与精确交通传感器数据进行对比，验证了在密集城市环境中的准确性和一致性。

Conclusion: 
该框架展示了将无人机技术与高级计算机视觉技术集成，实现精确而经济的城市交通监控的潜力，为智能交通系统的发展和交通管理策略提供了宝贵资源。通过公开发布松岛交通和松岛视觉数据集，及提取管道的完整源代码，确立了交通研究中数据质量、可重复性和可扩展性的新标准。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2411.02136</guid><pubDate>Fri, 27 Jun 2025 02:31:10 +0800</pubDate></item><item><title>581. cs.AI-快速陀螺仪校准：一种深度学习方法</title><link>https://arxiv.org/pdf/2409.00488</link><description>Background: 
低成本陀螺仪的校准对于保证陀螺仪测量的准确性和可靠性至关重要。静止校准可以估计测量误差的确定性部分，这通常通过在预定义时间内取陀螺仪读数的平均值并估计陀螺仪偏差来进行。校准持续时间对性能有重要影响，因此通常倾向于使用较长的校准时间。然而，某些应用场景需要快速启动时间，因此仅允许进行较短时间的校准。因此，本文致力于利用深度学习方法减少低成本陀螺仪的校准时间。

Innovation: 
文章提出了一个端到端的卷积神经网络用于陀螺仪校准的应用。探索了使用多个真实和虚拟陀螺仪来提高单个陀螺仪校准性能的可能性。记录了一个包含186.6小时陀螺仪读数的数据集，使用了4个不同品牌的36个陀螺仪，并且创建了一个虚拟数据集，由模拟的陀螺仪读数组成。六个数据集用于评估提出的方案，其中一个重要成就是使用三个低成本陀螺仪将陀螺仪的校准时间减少了89%。

Conclusion: 
我们公开了数据集以允许我们的工作的可再现性和增加该领域的研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2409.00488</guid><pubDate>Fri, 27 Jun 2025 02:31:09 +0800</pubDate></item><item><title>582. cs.AI-MockLLM：一种多智能体行为协作框架，用于在线求职与招聘</title><link>https://arxiv.org/pdf/2405.18113</link><description>Background: 
在线招聘平台已经重塑了求职和招聘流程，这种转变推动了对能改善人员与职位匹配的工具的需求。传统的求职和招聘方法一般依赖于分析简历和职位描述中的文字数据，这限制了有效招聘中动态和互动方面的重要作用。近来，大型语言模型（LLMs）的进步展示了模拟适应性、基于角色的对话的显著潜力，使得它们非常适用于招聘场景。然而，传统方法难以捕捉到这些动态的交互过程，因此在提高匹配质量方面存在挑战。

Innovation: 
本文提出了一种名为MockLLM的新框架，旨在生成和评估模拟面试互动。MockLLM框架包含两个关键组件：模拟面试生成和双向评价手协议。通过模拟面试官和求职者的角色，MockLLM能够实现一致且交互式的实时匹配。此外，MockLLM还结合了反思记忆生成和动态策略修改机制，使行为能够根据之前的经历进行改进。此框架的具体创新点在于其能够模拟求职者与面试官的角色，通过实时互动进行双向匹配，从而提高匹配质量。

Conclusion: 
通过实验评估，MockLLM超过了现有方法，在匹配准确度、可扩展性和跨职位领域的适应性方面表现出突出优势。这些结果显示出MockLLM在提升候选人评估和在线招聘中的潜在价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2405.18113</guid><pubDate>Fri, 27 Jun 2025 02:31:06 +0800</pubDate></item><item><title>583. cs.AI-我的数据在我的AI模型中吗？基于面部图像的应用关联性测试</title><link>https://arxiv.org/pdf/2402.09225</link><description>Background: 
本文介绍了会员推断测试（MINT）方法，用于实证评估给定的数据是否被用于训练AI/ML模型。实验框架集中在面部识别任务上，考虑了三种最先进的面部识别系统，并使用六个公开可用的数据集，包含超过2200万张面部图像。根据不同应用场景测试AI模型，提出了基于多层感知器（MLPs）和卷积神经网络（CNNs）的两种MINT架构。该方法展示了潜在的应用，如揭示敏感或私人数据是否被用于训练或调参大型语言模型（LLMs）。

Innovation: 
本文提出的MINT方法是一种新型的方法，用于评估给定的数据是否被用于训练AI/ML模型。该方法设计了基于MLPs和CNNs的两个架构，用于学习审计模型在暴露于训练数据时产生的独特激活模式。实验结果显示，MINT方法在识别训练数据的准确性上表现出色，最高可达90%。这表明MINT方法能够用来确保AI应用中的隐私和公平性。

Conclusion: 
提出的MINT方法展示了评估AI模型是否使用特定数据的潜力，并且在面部识别等多个场景中表现优异，达到了90%的准确率。该方法能够帮助确保大型语言模型等AI应用的隐私和公平性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2402.09225</guid><pubDate>Fri, 27 Jun 2025 02:31:04 +0800</pubDate></item><item><title>584. cs.AI-在模拟谈判对话中探索五大性格特质与AI能力的影响</title><link>https://arxiv.org/pdf/2506.15928</link><description>Background: 
本文介绍了在关键任务谈判情景中评估能动AI系统的框架，以满足对能够适应不同人类操作员和利益相关者的AI代理的需求。通过使用Sotopia作为模拟测试平台，文章提出了两个实验，系统地评估了人格特质和AI代理特性对模拟语言模型（LLM）引导的社会谈判结果的影响——这项能力对于涉及跨团队协调和民兵互动等多个应用至关重要。实验1使用因果发现方法衡量人格特质对价格谈判的影响，结果表明尽责性和外向性显著影响可信度、目标达成和知识获取结果。从团队通信中提取的社会认知词频测量法揭示了代理之间细微差异的同理心沟通、道德基础和意见模式，这对能动AI系统具有重要指导意义，这些系统必须在高风险操作场景中可靠运行。实验2通过操控模拟的人格特质和AI系统特性评估了人-机协商，特别是透明度、专业能力和适应性，展示了AI代理可信度如何影响任务有效性。这些发现建立了一种可重复的评估方法，用于在各种操作者性格和人机团队动态中尝试AI代理的可靠性，直接支持可靠的AI系统操作需求。本文的工作通过将标准性能指标与关键任务成功的社交动力学结合起来，推进了能动AI工作流程的评估，进一步提高了任务复杂性操作中的评估水平。

Innovation: 
本文提出了一个评估能动AI系统的框架，基于Sotopia平台进行了两个实验，分别从人格特质和AI特性两个方面评估了模拟语言模型在社会谈判中的表现，提出了可信度与任务有效性之间的关系，并提供了一种可重复的评估方法，以适应不同性格的操作员和人机团队动态。此外，将社会动力学纳入评估范围，使得评估更加全面，支持了可靠的AI系统操作需求，超越了传统的性能指标。

Conclusion: 
本文的工作推进了能动AI工作流程的评估，通过结合社交动力学来评估任务成功所需的关键因素，发展了一种可重复的评估方法，直接支持操作需求，表明能在大规模和复杂的谈判场景中实现有效的人机沟通和协作。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.15928</guid><pubDate>Fri, 27 Jun 2025 02:31:04 +0800</pubDate></item><item><title>585. cs.AI-从记忆到地图：Transformer 中上下文内强化学习的机制</title><link>https://arxiv.org/pdf/2506.19686</link><description>Background: 
人类和动物展现了惊人的学习效率，能够通过少量体验适应新环境。标准的增强学习算法通过逐步更新价值函数来捕捉这种能力，但可能尚未充分表现出快速适应的能力，这很可能依赖于情境记忆——能够从过去特定体验中检索信息以指导新环境中的决策的能力。Transformers 的设计因其在上下文内快速学习和其键值架构模拟大脑中情境记忆系统的能力而被用作研究这些问题的有用框架。这些模型能够基于环境变化调整其表示，并使用上下文内的结构学习和跨上下文对齐来支持高效学习。模型通过提供模型记忆标记内的中间计算缓存并根据决策时间访问这些计算，来支持上下文内强化学习，而不是遵循传统的无模型或基于模型的规划策略。这些发现表明，记忆可能作为计算资源发挥作用，储存经验信息以及中间计算以支持灵活的行为，并且模型发展出的表示与大脑中海马-内嗅皮层系统的计算相似，暗示了这些发现对自然认知的潜在相关性。总之，本研究提供了关于自然和人工环境中上下文内学习过程中快速适应的机制假设。

Innovation: 
研究通过训练 Transformer 模型进行分布式的基于上下文的强化学习，并分析从中系统地了解模型层面产生的强化学习算法。研究发现，记忆在强化学习中的作用不仅限于存储原始经验，还可能通过缓存和重新利用中间计算来支持决策，这不同于传统的无模型或基于模型的规划策略。模型的表示与大脑中海马-内嗅皮层系统的计算有关，这一发现可能有助于理解自然认知。

Conclusion: 
研究揭示了记忆在标准化的表格基础和部分可微的神经网络中被忽视的重要作用，即记忆不仅可以储存经验，还可以作为一种计算资源存储中间计算，并在新的上下文中重新利用这些计算，从而支持快速适应和灵活的行为。该研究提供了在神经类脑设备上进行高效计算学习的机制假设，同时也可能解释在大脑中的某些机制。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.19686</guid><pubDate>Fri, 27 Jun 2025 02:31:04 +0800</pubDate></item><item><title>586. cs.AI-HERMES: 时空连贯的大长视频理解与情节和语义</title><link>https://arxiv.org/pdf/2408.17443</link><description>Background: 
长视频理解提出了超出传统短视频分析方法的独特挑战，特别是在捕捉长距离依赖性、高效处理冗余信息以及提取高层语义概念方面。传统的视频分析方法难以应对这些挑战。

Innovation: 
本文提出了一种新颖的方法，更加符合人类认知模式。通过引入HERMES：时空连贯的大长视频理解系统，该系统采用两个多功能模块——情节压缩器(ECO)和语义检索器(SeTR)。ECO有效地从微观到半宏观层次聚合表示，减少计算开销同时保留时间依赖性。SeTR则通过关注广泛上下文丰富这些表示，减少特征维度同时保留相关宏观信息。实验表明，这些模块可以无缝集成到现有SOTA模型中，持续提升其性能，同时将推理延迟降低43%，内存使用减少46%。作为独立系统，HERMES在多个长视频理解基准测试中达到最佳性能，在零样本和完全监督设置下表现尤为出色。

Conclusion: 
本文通过HERMES系统展示了两个关键模块的有效性，证实了其在长视频理解领域的潜力。在未来的工作中，计划进一步优化HERMES系统，以提高其在实际应用中的可扩展性和泛化能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.17443</guid><pubDate>Fri, 27 Jun 2025 02:31:01 +0800</pubDate></item><item><title>587. cs.AI-GREAT 架构：一种用于诸如TSP的基于边的图问题的架构</title><link>https://arxiv.org/pdf/2408.16717</link><description>Background: 
近年来，许多基于学习的方法被提出以解决诸如路由问题等组合优化问题。这些方法大多基于图神经网络（GNNs）或相关的转变器，用于操作表示路由问题的欧几里得坐标。然而，操作欧几里得坐标的模型不适合处理像实际应用场景中常遇到的非欧几里得、非对称问题实例。因此，需要一种新的方法来解决这些问题.

Innovation: 
该论文提出了一种新的基于GNN且专注于边的神经模型，称为Graph Edge Attention Network (GREAT)。利用GREAT作为编码器，捕捉路由问题实例的特性，构建了强化学习框架，应用于欧几里得和非欧几里得的车辆路线问题（如旅行商问题、承载车辆路线问题和定向搜索问题）中。这是第一个尝试解决这些非欧几里得问题的学习算法之一.

Conclusion: 
该框架在不同的路由问题上取得了竞争力的结果，表明对于解决非欧几里得路由问题，GREAT架构比其他基于学习的方法更有效。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2408.16717</guid><pubDate>Fri, 27 Jun 2025 02:30:59 +0800</pubDate></item><item><title>588. cs.AI-可变注意头的高效图像生成</title><link>https://arxiv.org/pdf/2211.05770</link><description>Background: 
尽管将变压器集成到视觉模型中已经在视觉任务上取得了显著提高，但它们在训练和推理过程中仍需要大量的计算资源。受限的注意机制显著减少了这些计算负担，但弊病是损失了全局或局部的一致性。本文提出了一种简单而强大的方法来减少这一权衡：允许单个变压器的注意头同时关注多个感受野。该方法通过集成到基于StyleGAN的架构中实现了图像生成。使用称为StyleNAT的方法，在FFHQ数据集上实现了FID为2.05的结果，相比StyleGAN-XL提高了6%的性能，同时参数减少了28%，且吞吐量提高了4倍。StyleNAT在FFHQ-256数据集上达到了帕累托前沿，并在其他数据集上展示了强大的高效图像生成能力。有关代码和模型的检查点可在指定链接中获取。

Innovation: 
本文提出了一种新的方法——允许单个变压器的注意头同时关注多个感受野，通过这种方法，实现了在FID和模型参数数量以及吞吐量之间的最优平衡。这种方法通过集成到基于StyleGAN的架构中，能够高效地生成图像，并在FFHQ和FFHQ-256数据集上达到了性能最优。

Conclusion: 
通过使用可变注意头，StyleNAT能够在使用更少的计算资源的情况下，生成高质量的图像。该方法不仅证明了在特定数据集上的有效性，还在更广泛的图像生成任务中展示了其效率和有效性。作者认为这种方法为未来的视觉生成模型提供了一个可行的改进方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2211.05770</guid><pubDate>Fri, 27 Jun 2025 02:30:59 +0800</pubDate></item><item><title>589. cs.AI-ClimateIQA：气象异常分析中推进视觉语言模型的新数据集和基准</title><link>https://arxiv.org/pdf/2406.09838</link><description>Background: 
气象热图在解读极端天气现象中起着重要作用，但由于其不规则轮廓、无序模式和复杂色彩变化的内在复杂性，给最先进的视觉-语言模型（VLMs）带来了独特的分析挑战。当前最先进的模型如GPT-4o、Qwen-VL和LLaVA 1.6在精确颜色识别和空间定位等任务上表现不佳，导致不准确或不完整的解释。

Innovation: 
我们提出了Sparse Position and Outline Tracking（SPOT），这是一种新型算法，专门用于处理视觉数据中不规则色区。通过提取空间坐标，SPOT能够为不规则形状提供结构化表示。基于SPOT，我们构建了ClimateIQA，这是一个新的气象视觉问答（VQA）数据集，包含26,280个高分辨率热图和762,120条关于风力突增、总降水量、风寒指数和高温指数分析的指令样本。ClimateIQA以空间线索、地理元数据和再分析数据增强VLM训练，从而提高模型对极端天气特征的解释和描述准确性。此外，我们还开发了Climate-Zoo，这是基于SPOT赋能的ClimateIQA的微调视觉语言模型套件，在气象热图任务上显著优于现有模型。

Conclusion: 
ClimateIQA数据集增强了VLM在气象异常分析中的性能，而Climate-Zoo模型则在气象热图任务上实现了显著的性能提升。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2406.09838</guid><pubDate>Fri, 27 Jun 2025 02:30:52 +0800</pubDate></item><item><title>590. cs.AI-利用双向充电优化盈利的智能电动车出行和交付服务</title><link>https://arxiv.org/pdf/2506.20401</link><description>Background: 
随着电动汽车（EVs）的普及，现代服务系统，如叫车配送服务，越来越多地将电动汽车纳入其运营中。由于电动汽车通常行驶里程较短，因此在执行请求时需要仔细考虑充电问题。最近，车辆到电网（V2G）技术的发展使电动汽车能够向电网逆向供电，这不仅带来新的机遇，也带来了新的挑战。在这样的背景下，该研究提出了电动汽车 Orienteering 问题（EVOP-V2G），即如何在一个同时考虑充电和放电约束的利润最大化问题中，选择客户请求或订单，并合理安排充放电时间与地点。该问题考虑了动态电价、充电站选择以及路径约束等因素，将其形式化为混合整数规划（MIP）模型，并提出了两种近似最优的元启发式算法：一种是进化算法（EA），另一种是基于大邻域搜索（LNS）的方法。实验证明，方法在提高司机利润方面具有显著效果，同时在小规模问题上保持了接近最优的性能，在大规模问题上具有出色的比例性。

Innovation: 
该研究创新性地引入了电动汽车 Orienteering 问题（EVOP-V2G），并提出了一种基于双向充电的智能盈利优化方法。该方法不仅解决了电动汽车在行驶中的充电问题，还考虑了其向电网放电的能力。通过混合整数规划（MIP）模型和进化算法（EA）以及基于大邻域搜索（LNS）的元启发式算法，该研究提出了实用的解决方案，提高了司机的利润，并展示了其在实际数据上的良好性能和可扩展性。

Conclusion: 
该研究展示了通过利用双向充电技术实现智能电动车出行和交付服务的潜在路径，通过这一策略能够创建更智能、更具盈利性的电动车出行系统，这些系统能够有效地支持能源电网。研究表明，这种策略能显著提高司机的收入，同时保持小型任务的优化性能，并展现出在更大规模上的优秀可扩展性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20401</guid><pubDate>Fri, 27 Jun 2025 02:30:52 +0800</pubDate></item><item><title>591. cs.AI-Doppelganger 方法：通过基于提示的可转移对抗攻击破坏 LLM 代理的角色一致性</title><link>https://arxiv.org/pdf/2506.14539</link><description>Background: 
自大语言模型问世以来，提示工程现在能够快速、低投入地创建多样化的自主代理，这些代理已经被广泛应用。但是，这种便利性引发了关于代理背后的提示安全性、稳健性和行为一致性方面的急迫担忧，同时也提出了防止这些提示被用户尝试曝光的迫切挑战。

Innovation: 
本文提出了“Doppelganger 方法”，以展示代理被劫持的风险，并由此暴露系统指令和内部信息。此外，定义了“对抗转移下的提示对齐崩溃 (PACAT)”级别来评估对抗转移攻击的脆弱性，并提出“对抗转移警戒 (CAT)”提示作为一种防御机制。实验结果表明，Doppelganger 方法能够破坏代理的一致性并暴露其内部信息，而 CAT 提示能够有效抵御这种对抗攻击。

Conclusion: 
Doppelganger 方法能够破坏 LLM 代理的角色一致性，而 CAT 提示能够有效地防御此类对抗攻击。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.14539</guid><pubDate>Fri, 27 Jun 2025 02:30:46 +0800</pubDate></item><item><title>592. cs.AI-持续学习作为计算受限的强化学习</title><link>https://arxiv.org/pdf/2307.04345</link><description>Background: 
在人工智能领域，设计一种能够在长时间内不断积累知识，逐渐发展出复杂技能的代理，这将进一步推动人工智能能力的边界。持续学习是解决这一长期挑战的关键领域，它涉及知识的长期记忆和个人技能的逐步提升。

Innovation: 
该论文解决持续学习的问题，提出了一个框架和工具集，以促进进一步的研究。论文明确并形式化了持续学习的概念，并将其与计算受限的强化学习联系起来，为持续学习领域提供了新的视角和研究工具。

Conclusion: 
论文澄清并形式化了持续学习的概念，提出了一个框架和工具集，为该领域进一步的研究提供了方向。持续学习作为计算受限的强化学习，为理解代理如何在长期中进行学习和适应提供了新的观点。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2307.04345</guid><pubDate>Fri, 27 Jun 2025 02:30:40 +0800</pubDate></item><item><title>593. cs.AI-NFISiS: 新型模糊推理系统在可再生能源预测中的新视角</title><link>https://arxiv.org/pdf/2506.06285</link><description>Background: 
尽管深度学习模型由于其高精度而备受青睐，但也存在一些局限性，如较长的训练时间和较低的解释性。相比之下，模糊推理系统提供了一定程度的准确性和透明度的平衡。然而，传统的Takagi-Sugeno-Kang模糊模型有其局限性，而本研究通过将近期提出的新型Takagi-Sugeno-Kang模型扩展到基于Mamdani的新回归器，来解决这些局限。这种模型采用数据驱动的方法，允许用户根据需要定义规则来平衡准确性和可解释性。然而，面对大数据集的复杂性，该研究引入了包装技术和聚合技术来处理这一挑战。使用遗传算法来作为特征选择的包装器，以及引入了多种聚合模型来提高稳健性。这种方法在光伏能源预测数据集上进行了验证，这些数据集对于可再生能源来说是至关重要的，因为太阳能是一个间歇性能源。结果表明，这些遗传和聚合的模糊模型，特别是遗传新型Takagi-Sugeno-Kang模型和随机森林新型Takagi-Sugeno-Kang模型，取得了更好的表现，且比传统的机器学习模型和深度学习模型更为简单且可解释性强。

Innovation: 
1. 将新型Takagi-Sugeno-Kang模型扩展到基于Mamdani的新回归器，提供了一个数据驱动的方法来定义规则以平衡精度和可解释性。n2. 引入了包装技术和聚合技术来处理大数据集的复杂性，包括使用遗传算法作为特征选择的包装器，同时还引入了多种聚合模型，如随机新Mamdani回归器、随机新Takagi-Sugeno-Kang和随机森林新型Takagi-Sugeno-Kang。n3. 在光伏能源预测数据集上进行了实证研究，证明了这些模型的优越性，并提供了一个较为简单和可解释性强的结构，同时在拥有良好稳定性的同时也能与传统机器学习和深度学习模型抗衡。

Conclusion: 
提出的新型模糊推理系统（NFISiS）在可再生能源预测中展示出了巨大的潜力，特别是在光伏能源预测方面。遗传和聚合模型，尤其是遗传新型Takagi-Sugeno-Kang模型和随机森林新型Takagi-Sugeno-Kang模型，展示了比传统机器学习和深度学习模型更好的性能。NFISiS模型已在网上作为nfisis库提供，该库包含了这些新技术的应用和演示。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.06285</guid><pubDate>Fri, 27 Jun 2025 02:30:39 +0800</pubDate></item><item><title>594. cs.AI-Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities</title><link>https://arxiv.org/pdf/2506.18019</link><description>Background: 
AI代理经历了从早期以强化学习（RL）为主导，到由大规模语言模型（LLMs）驱动的代理兴起，现在正进一步朝着RL与LLMs能力协同融合的方向发展。这种发展赋予了AI代理越来越强大的能力。尽管取得了这些进步，但完成复杂现实世界的任务仍然要求代理能够高效规划和执行、保持可靠的记忆，并与其他代理顺利协调。实现这些能力需要处理持续存在的复杂信息、操作和交互。在这种背景下，数据结构化可以通过将复杂而混乱的数据转换成有序形式，使代理能够更有效地理解和处理数据，扮演了关键角色。在所有这些方式中，图结构以其在组织、管理和利用复杂数据关系方面的天然优势，成为数据结构化支持先进AI代理所需能力的强大数据范式。

Innovation: 
本文是首次系统回顾了图如何赋能AI代理，具体探讨了图技术与核心代理功能的集成，突显了重要应用，并指出了未来研究的潜在途径。

Conclusion: 
通过全面审视这一新兴交集，本文旨在激发下一代以图支撑的AI代理开发，这些代理能够应对日益复杂的挑战。同时，相关资源将收集并持续更新供社区在GitHub链接中使用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.18019</guid><pubDate>Fri, 27 Jun 2025 02:30:39 +0800</pubDate></item><item><title>595. cs.AI-Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning</title><link>https://arxiv.org/pdf/2506.13056</link><description>Background: 
近年来大型语言模型（LLMs）的发展促进了高级推理范式的出现，并开始整合到多模态大型语言模型（MLLMs）中。然而，现有方法通常存在不足。单纯使用强化学习（RL）的方法可能面临样本效率低及激活缺失的推理能力的问题。传统的初步冷启动监督微调（SFT）流程后接RL的方式会限制模型的探索能力，并且可能造成收敛性不佳的问题。

Innovation: 
Metis-RISE是一种不同于传统方法的新模型，它没有采用初始SFT阶段，而是直接开启一个RL阶段（如使用变体的组相对策略优化），激励和激活模型潜在的推理能力。随后，目标导向的SFT阶段解决RL阶段中识别出的两个关键挑战：一是解决具有但不一致应用正确推理的任务中效率低下的轨迹采样问题（通过从RL模型中自我提炼推理轨迹），二是解决模型完全失败的任务中基本能力的缺失问题（通过注入专家增强的知识）。RL激励与SFT增强构成了Metis-RISE的核心，对7B和72B参数的MLLMs模型进行了开发，并展示了在OpenCompass多模态推理排行榜上的优越性能，72B版本总体排名第四。

Conclusion: 
Metis-RISE模型在与类似大小的模型中取得了最先进的性能，尤其是在处理具有而未一致应用正确推理的任务中的低效轨迹采样问题以及解决完全失败的任务中基本能力的缺失问题两个方面表现尤为突出。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.13056</guid><pubDate>Fri, 27 Jun 2025 02:30:37 +0800</pubDate></item><item><title>596. cs.AI-无结构的结构化：用于提取和查询财务关键绩效指标和指导的多智能体系统</title><link>https://arxiv.org/pdf/2505.19197</link><description>Background: 
从非结构化的财务报告中提取结构化和定量的信息在投资研究中至关重要，但这些过程依然耗时且资源密集。传统方法依赖于耗人力的手动处理过程，这限制了其可扩展性并延迟了研究流程。

Innovation: 
本文提出了一种高效且可扩展的方法，利用大型语言模型组成的多智能体系统从非结构化的财务文件中准确提取定量信息。该系统包含两个专门的智能体：提取智能体和文本到SQL智能体。提取智能体自动标识非结构化财务文本中的关键绩效指标，标准化其格式并验证其准确性；文本到SQL智能体则能从自然语言查询生成可执行的SQL语句，让用户无需熟悉数据库架构即可访问结构化数据。通过实验表明，该系统能够准确地将非结构化文本转换为结构化数据并精确检索关键信息。数据显示，该系统在将财务报告转化为结构化数据方面的准确率达到了约95%，与人工注解人员的性能相当。在使用自然语言查询进行信息检索的用户评估中，91%的回答被认为是正确的。该系统在不同类型的财务文档上表现出良好的泛化能力，持续提供可靠的性能表现。

Conclusion: 
实验结果显示，系统对财务报告文本的结构化转换准确率高达95%，接近人工标注的水平，且在使用自然语言查询从结构化数据中检索信息时，91%的回答被认为是正确的。系统通过有效的多智能体架构，克服了手动处理的局限，实现了高效、准确且可扩展的数据提取和查询能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2505.19197</guid><pubDate>Fri, 27 Jun 2025 02:30:35 +0800</pubDate></item><item><title>597. cs.AI-WiS 平台：通过基于游戏的分析增强对基于大型语言模型的多智能体系统的评估</title><link>https://arxiv.org/pdf/2412.03359</link><description>Background: 
近年来基于大型语言模型（LLMs）的自主多智能体系统（MAS）取得了显著的进步，扩展了应用范围并提高了处理复杂任务的能力。尽管如此，现有的研究仍然难以对基于LLMs的MAS进行评估、分析和再现性研究，尤其是在模型对比和行为理解方面存在明显的局限性。因此，有必要开发一种简便且高效的平台，以更好地评估和分析基于LLMs的MAS系统。

Innovation: 
本文提出了一种名为WiS的开放、可扩展且实时更新的平台，通过“谁是卧底？”（WiS）游戏对基于LLMs的MAS进行评估和分析。该平台的功能亮点包括：（1）统一的模型评估界面，支持访问Hugging Face等平台上的各种模型；（2）实时更新的评估排行榜；（3）全面的评估，涵盖游戏夺冠率、攻击和防御策略以及LLMs的推理能力。此平台通过广泛的实验和不同来源的LLMs验证了其有效性和高效性，并公开了实验结果和平台文档，以促进相关研究的发展。

Conclusion: 
实验结果显示，本平台在评估基于大型语言模型的多智能体系统方面具有显著的效果和效率。通过公开该平台，研究者可以更好地理解和分析基于LLMs的MAS的表现。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2412.03359</guid><pubDate>Fri, 27 Jun 2025 02:30:32 +0800</pubDate></item><item><title>598. cs.AI-驯服未知：基于图的知识检索与推理用于MLLMs攻克未知</title><link>https://arxiv.org/pdf/2506.17589</link><description>Background: 
尽管最近的多模态大型语言模型（MLLMs）具有令人印象深刻的多模态能力，但它们在罕见的特定领域任务中常常无法有效利用有限的相关知识来克服未知困难。因此，研究者们探索了如何利用知识图谱来增强MLLMs的多模态知识检索和推理能力，通过构建基于视觉游戏认知的多模态知识图谱来评估模型的复杂知识获取和推理能力。

Innovation: 
本文提出了一种多智能体检索器，使模型能够自主搜索相关知识，而无需额外训练。这一方法显著提升了MLLMs的性能，并为未来的多模态知识增强推理研究提供了新的视角。

Conclusion: 
我们的方法为MLLMs在面对罕见的特定领域任务时提供了有效的解决方案，通过构建基于Monster Hunter: World的多模态知识图谱，进行了一系列复杂查询评估，并证明了该方法在提高模型复杂知识检索和推理能力方面具有显著效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.17589</guid><pubDate>Fri, 27 Jun 2025 02:30:32 +0800</pubDate></item><item><title>599. cs.AI-Fast Monte Carlo Tree Diffusion: 100倍速度提升的并行稀疏规划</title><link>https://arxiv.org/pdf/2506.09498</link><description>Background: 
扩散模型近年来被用作路径规划的强大方法。然而，它们固有的非序列性质限制了它们在测试时解决长期推理问题的有效性。最新的Monte Carlo Tree Diffusion (MCTD)通过结合扩散模型和基于树的搜索，解决了这一问题并获得了复杂规划问题的最新性能。尽管MCTD有其优势，但分析显示它存在严重的计算开销，主要是由于树搜索的序列性质和迭代噪声去除的成本。因此，需要提出一种更有效的变种来克服这些问题，以保持MCTD的优势并显著提高其速度和可扩展性。

Innovation: 
提出了Fast-MCTD，这是一种更有效的MCTD变种，旨在保留MCTD的优势，并显著提高其速度和可扩展性。Fast-MCTD结合了两种技术：Parallel MCTD，通过延迟树更新和冗余感知选择实现并行展开;以及Sparse MCTD，通过轨迹粗化减少展开长度。实验证明，Fast-MCTD在某些任务中的推理速度比标准MCTD快100倍，同时保持或提升了规划性能。此外，尽管Diffuser不需要搜索且给出更弱的方案，Fast-MCTD在推理速度方面也优于Diffuser。

Conclusion: 
这些结果将Fast-MCTD定位为一种实用且可扩展的基于扩散的推理时推理解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.09498</guid><pubDate>Fri, 27 Jun 2025 02:30:32 +0800</pubDate></item><item><title>600. cs.AI-大语言模型（LLMs）对非洲语言的状态：进展与挑战</title><link>https://arxiv.org/pdf/2506.02280</link><description>Background: 
大型语言模型（LLMs）正在重塑自然语言处理（NLP），但这些模型对非洲的2000种低资源语言并没有带来明显的益处。本文比较分析了六种LLMs、八种小型语言模型（SLMs）和六种专门的小型语言模型（SSLMs）对非洲语言的覆盖面，涵盖语言覆盖面、训练集、技术限制、书写系统问题以及语言建模的前景等问题。研究结果显示，有42种支持的非洲语言和23个可用的公开数据集，然而大部分非洲语言缺乏支持，四种重要语言（阿姆哈拉语、斯瓦希里语、南非荷兰语、马达加斯加语）一直受到关注，另外有超过98%的非洲语言无法支持。此外，研究还揭示了仅有拉丁语、阿拉伯语和吉兹语字符被识别，而实际使用的20种字符被忽略。主要挑战包括数据缺乏、分词偏见、计算成本高昂以及评估问题。这些问题需要语言标准化、社区驱动的语料库建设以及对非洲语言的有效适应方法。

Innovation: 
对六种LLMs、八种SLMs和六种SSLMs在非洲语言覆盖上的比较分析，强调了数据缺失、同子字符问题、高昂的计算成本和评估问题，并强调了解决这些问题的必要性：语言标准化、社区推动的语料库建设和有效的适应方法

Conclusion: 
尽管LLMs在NLP领域取得显著进展，但非洲语言的支持严重不足。研究显示了全面的数据需求、技术适应性挑战和社区参与的重要性，以促进非洲语言在现代技术中的应用和发展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.02280</guid><pubDate>Fri, 27 Jun 2025 02:30:30 +0800</pubDate></item><item><title>601. cs.AI-可持续共生社会的超级对齐</title><link>https://arxiv.org/pdf/2504.17404</link><description>Background: 
随着人工智能（AI）向通用人工智能（AGI）和超人工智能（ASI）发展，可能会超越人类的控制，偏离人类价值观，并在极端情况下导致不可逆转的灾难性后果。这一潜在风险强调了‘超级对齐’问题的重要性，即确保比人类更聪明的AI系统保持与人类价值观和意图的一致性。当前的可扩展监督和弱到强的泛化方法虽然具有一定的适用性，但在应对超级对齐方面存在根本性的缺陷，主要表现为单向的人类价值观强加无法适应超智能的自主性或确保AGI/ASI的稳定学习。

Innovation: 
本文提出了一种具体的框架来整合外部监督和内在主动对齐。外部监督超级对齐应基于以人为本的最终决策，并辅以可解释的自动化评估和纠正，以持续与人类不断变化的价值观保持一致。内在主动超级对齐基于对自我、他人和社会的深刻理解，通过自我意识、自我反思和共情来自发推断人类意图，区分善恶，并主动优先考虑人类福祉。这种外部驱动的监督与内在驱动的主动对齐相结合，将通过人类-AGI/ASI的协同对齐迭代，共同塑造共生价值观和规则，为安全、有益的AGI和ASI铺平道路，以实现人类和共生生态的福祉。

Conclusion: 
通过外部监督和内在主动对齐的有机结合，可共同塑造可持续共生社会的价值观和规则，为实现安全和有益的AGI/ASI铺平道路。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.17404</guid><pubDate>Fri, 27 Jun 2025 02:30:26 +0800</pubDate></item><item><title>602. cs.AI-TITAN: 基于查询-标记的领域自适应对抗学习</title><link>https://arxiv.org/pdf/2506.21484</link><description>Background: 
本文聚焦于源数据不可用的情况下的无源领域自适应目标检测（SF-DAOD）问题。现有的大部分方法使用学生-教师（ST）框架通过预训练模型生成伪标签以进一步微调模型，但由于伪标签噪声较高，导致教师模型崩溃，从而使得学生模型的性能大幅下降。此背景描述了在适应目标域时遇到的技术挑战和发展现状，尤其是在拥有很少或多为无标签数据的条件下。

Innovation: 
为了获得可靠的伪标签，本文提出了基于目标的迭代查询-标记对抗网络（TITAN）。该网络将目标图像分为两类：与源数据相似的（容易类别）和不相似的（困难类别），并通过估计检测方差来划分目标域。TITAN还整合了基于查询标记的对抗模块到学生-教师基线框架中，以减少两个特征表示之间的领域差距。实验结果表明，TITAN在多个自然图像和医学图像数据集上都优于当前最先进的方法，即使在标签信息稀缺的场景下依然有效，展示了其在不同复杂度任务中的优越性能。

Conclusion: 
实验结果在四个自然图像数据集和两个具有挑战性的医学图像数据集上得到了验证，TITAN方法相比现有的最先进方法提高了mAP性能22.7%，22.2%，21.1%和3.7%分别对应于C2F，C2B，S2C和K2C基准。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21484</guid><pubDate>Fri, 27 Jun 2025 02:30:21 +0800</pubDate></item><item><title>603. cs.AI-优化4阶龙格-库塔方法：一种动态启发式方法以提高效率和降低存储</title><link>https://arxiv.org/pdf/2506.21465</link><description>Background: 
扩展稳定龙格-库塔(ESRK)方法对于解决科学和工程中的大规模计算问题至关重要，包括天气预报、空气动力学分析和复杂的生物模型。然而，平衡精度、稳定性和计算效率仍然是一个挑战，特别是在高阶、低存储方案中。传统的优化方法依赖于手动设计的启发式或全面的数值搜索，这些方法难以兼顾所有因素，并且效率低下。

Innovation: 
本文提出了一种基于遗传算法(GA)和强化学习(RL)的混合启发式优化方法，用于优化低存储ESRK方法。该方法通过GA驱动的变异进行搜索空间探索，并利用RL启发的动态状态转换机制来实时优化启发式选择，从而系统地减少参数，保持四阶精度的同时显著提高计算效率。这种方法通过在一系列基准问题上的严格测试得到了验证，包括1D和2D布鲁塞尔系统以及稳态纳维-斯托克斯方程。与传统的ESRK优化过程相比，最佳启发式实现了IPOPT运行时间25%的降低，同时保持了数值稳定性和精度。这证明了自适应启发式发现对于提高高保真相似仿真的资源效率的潜力，并扩展了低存储龙格-库塔方法在实际计算流体动力学、物理仿真和其他领域应用的可能性。这项研究为数值方法的启发式优化建立了一个新的范式，为进一步利用深度强化学习和自动化机器学习(AML)进行启发式搜索打开了新的途径。

Conclusion: 
本研究通过基于GA-RL启发式的优化框架，展示了自适应启发式发现在提高资源效率和扩展低存储龙格-库塔方法应用范围方面的潜力。这种方法具有显著提高计算效率和保持数值稳定性的优势，为未来的研究提供了新的思路。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21465</guid><pubDate>Fri, 27 Jun 2025 02:30:21 +0800</pubDate></item><item><title>604. cs.AI-通过在线对抗训练和生成模型提升人机协作</title><link>https://arxiv.org/pdf/2504.15457</link><description>Background: 
能够与新人合作是许多高价值AI任务的重要组成部分，包括家庭机器人和自动驾驶。然而，为了应对新的人类行为，需要在能捕捉人类行为多样性的数据上进行训练。作为一种有前景的方法，对抗训练能够动态生成数据，并确保代理的鲁棒性。这种方法通过代理的表现来影响新的对抗数据生成，从而立即用于培训代理。但是在合作任务中，对抗训练很难应用。如何训练一个对抗性的合作者呢？

Innovation: 
我们提出了一种新的策略，将预训练生成模型与最大化后悔的对抗训练相结合，以模拟有效的合作剂策略。这种方法称为GOAT：生成在线对抗训练。在该框架中，GOAT动态搜索生成模型的潜在空间，寻找学习策略——合作者代理表现不佳的协调策略。通过保持生成模型的冻结，GOAT能够维持现实的协调策略并避免对抗性利用，从而实现更好的泛化，使合作者暴露在各种困难的互动场景下，提升了与多样人类行为的适应性。

Conclusion: 
我们用真实的人类合作伙伴评估了GOAT，结果表明这种方法在Overcooked基准测试中达到最先进的性能，显示出其在处理不同人类行为上的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.15457</guid><pubDate>Fri, 27 Jun 2025 02:30:20 +0800</pubDate></item><item><title>605. cs.AI-WorldVLA：走向自回归动作世界模型</title><link>https://arxiv.org/pdf/2506.21539</link><description>Background: 
该研究提出了WorldVLA，这是一种自回归动作世界模型，能够统一理解与生成动作和图像。该模型将视觉-语言-动作（VLA）模型和世界模型结合在同一个框架中。通过结合动作和图像的理解，世界模型可以预测未来的图像，从而学习环境背后的物理规律来改进动作生成。同时，动作模型基于图像观察来生成后续动作，这有助于视觉理解，并反过来帮助世界模型的视觉生成。

Innovation: 
该研究的主要创新点在于：1. 将VLA模型和世界模型结合在一个统一的框架中；2. 通过自回归方式预测动作序列，展示了世界模型和动作模型相互增强的效果；3. 揭示了动作模型在自回归生成动作序列时性能下降的现象，并提出了注意力掩码策略来解决该问题，该策略在当前动作生成任务中显示出了显著的性能提升。

Conclusion: 
实验结果表明，WorldVLA优于独立的行动和世界模型，示范了世界模型和动作模型之间的相互增强效应。此外，研究指出动作模型在自回归条件下生成动作序列时性能下降的原因，并提出了注意力掩码策略来改善这一点。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21539</guid><pubDate>Fri, 27 Jun 2025 02:30:20 +0800</pubDate></item><item><title>606. cs.AI-Review learning: 实现跨医疗机构隐私保护持续学习的现实验证</title><link>https://arxiv.org/pdf/2210.09394</link><description>Background: 
在使用电子健康记录（EHR）进行隐私保护深度学习（PPDL）应用时，采用转移学习（TL）的方法进行模型训练时，模型往往在连续学习过程中遗忘之前学习到的知识，即灾难性遗忘这一问题。这会严重影响模型在多样数据集上的表现，尤其是在医疗领域的隐私保护和模型转移学习中更为关键。为解决这一问题，提出了‘Review Learning’（RevL）算法，它能够从模型生成数据样本用于回顾已有的知识，从而在PPDL框架下进行诊断预测。

Innovation: 
Review Learning（RevL）算法是一种低成本的持续学习算法，能够在隐私保护深度学习应用中克服灾难性遗忘问题。该算法通过从模型中生成数据样本并回顾之前的数据集中的知识，实现在医疗记录（EHR）上的诊断预测，特别适用于医疗领域的隐私保护和模型转移学习。

Conclusion: 
RevL算法证明了其在复杂数值实验中保留之前学习的知识和在实际医疗场景下的有效性。实验证明，RevL在包含106,508名患者的真实世界实验中，其平均全球受试者工作特征曲线下面积（AUC）为0.710，优于传统的转移学习TL的0.655。这表明RevL算法在实际世界医疗隐私保护持续学习下的可行性和实用性，为跨医疗机构的模型转移隐私保护研究提供了一条现实可行的路径，强调了在使用私有EHR数据的实际医疗情境中持续学习的实用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2210.09394</guid><pubDate>Fri, 27 Jun 2025 02:30:20 +0800</pubDate></item><item><title>607. cs.AI-mTSBench: 多变量时间序列异常检测和模型选择的大规模基准测试</title><link>https://arxiv.org/pdf/2506.21550</link><description>Background: 
多变量时间序列异常检测（MTS-AD）在医疗、网络安全和工业监测等多个领域至关重要，但由于复杂的时间序列变量依赖关系、时间动态特性和稀疏的异常标签，这一领域仍然极具挑战性。目前尚未有一个能覆盖广泛领域和应用的多变量时间序列异常检测基准和无监督模型选择基准，这限制了该领域的进步和发展。

Innovation: 
本文引入了mTSBench，这是迄今为止针对多变量时间序列异常检测和无监督模型选择的最大基准，涵盖了344个带标签的时间序列，分布在19个数据集和12个不同的应用领域中。mTSBench评估了24种异常检测方法，包括基于大型语言模型的多变量时间序列异常检测器，并在标准化条件下系统地测试了无监督模型选择技术。研究表明，虽然最先进的选择方法也远未达到理想状态，但现有的单一检测器并不适用于所有数据集，这进一步强调了模型选择的重要性。

Conclusion: 
mTSBench 提供了一个统一的评估套件，能够实现严格、可再现的比较，推动多变量时间序列异常检测和稳健模型选择的未来进步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21550</guid><pubDate>Fri, 27 Jun 2025 02:30:17 +0800</pubDate></item><item><title>608. cs.AI-What's Up, Doc?：分析大规模对话AI数据集中用户的求医问药方式</title><link>https://arxiv.org/pdf/2506.21532</link><description>Background: 
人们越来越多地通过交互式聊天机器人向大型语言模型（LLMs）寻求医疗健康信息，然而这些交流的本质和固有风险仍不明确。本研究旨在建立一个包含11000个真实对话、25000个用户消息的医疗对话数据集HealthChat-11K，通过该数据集和基于临床专家的交互分类体系，系统研究用户在21个不同健康专业领域内的交互方式。

Innovation: 
研究通过筛选大规模对话AI数据集，创建了HealthChat-11K数据集，并从21个不同健康专长领域分析用户与LLMs的交互模式，揭示用户求医问药的行为特征、不完整背景信息、情感行为及导致恭维的交互模式，强调了提高LLMs作为对话AI在医疗支持方面的功能的必要性。

Conclusion: 
研究通过HealthChat-11K数据集揭示了用户在获取医疗健康信息时的行为特征，指出了改善基于对话AI的LLMs医疗服务的必要性，为未来的研究提供了理论依据和实践基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21532</guid><pubDate>Fri, 27 Jun 2025 02:30:16 +0800</pubDate></item><item><title>609. cs.AI-整体身体条件下的第一人称视频预测</title><link>https://arxiv.org/pdf/2506.21552</link><description>Background: 
该研究旨在通过给定过去视频和相对3D肢体姿态来训练模型预测以自我为中心的视频（PEVA）。模型根据身体关节层次结构组织的动作技巧轨迹进行条件化，从而学习从第一人称视角模拟物理人体动作如何影响环境。研究通过使用Nymeria的大型现实世界第一人称视频和肢体姿态捕获数据集训练自回归条件化扩散变换器。此外，研究设计了一种分层评估协议，包含更具挑战性的任务，以全面分析模型的体体现象预测和控制能力。这项工作代表了从人类视角对复杂现实环境和体体现象建模的一种初始尝试，使用视频预测的方法。背景强调了对复杂真实环境和体体现象建模的需求以及自回归条件化扩散变换器的应用。

Innovation: 
该研究的创新在于使用自回归条件化扩散变换器在大型现实世界第一人称视频和肢体姿态捕获数据集上训练模型。此外，研究设计了一种分层评估协议，包含更具挑战性的任务，以全面分析模型的体体现象预测和控制能力。研究的优势在于能够从人类视角模拟复杂的物理人体动作如何影响环境，代表了对复杂现实环境建模的一种新方法。

Conclusion: 
该研究首次尝试从人类视角模拟复杂真实环境中的方法，通过训练模型来预测以自我为中心的视频，展示了自回归条件化扩散变换器在处理此类任务时的有效性。未来的研究可以进一步探索和优化模型结构以提高准确性，并开发更复杂和多样化的评估协议。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21552</guid><pubDate>Fri, 27 Jun 2025 02:30:16 +0800</pubDate></item><item><title>610. cs.AI-大型语言模型中的幻象理解</title><link>https://arxiv.org/pdf/2506.21521</link><description>Background: 
目前，大型语言模型（LLMs）通常通过基准数据集进行评估。然而，根据模型对特定问题集的回答来推断其能力的依据是什么？本文首先介绍了一个正式框架来解决这个问题。关键在于认识到用于测试LLMs的基准测试（如AP考试）同样是用于测试人类的基准测试。但是，这暗示了一个问题：如果LLMs理解概念的方式不能反映人类的理解偏差，那么取得这些基准测试的成功仅仅是‘虚假共识’的表现，即通过不可调和的答案所驱动的假象理解。

Innovation: 
作者提出了两种量化幻象理解的方法：一种是通过专门设计的基准在三个领域进行，另一种则是一种通用方法，可提供其普遍性的下限。研究发现，幻象理解在各种模型、任务和领域中普遍存在，不只反映错误的理解，还反映了概念表示中的深层次内在不一致性。

Conclusion: 
总的来说，大型语言模型中的幻象理解普遍存在，说明了模型的理解与人类的理解存在本质差异，需要进一步改进其内部机制以提高其理解和应用真实意图的能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21521</guid><pubDate>Fri, 27 Jun 2025 02:30:11 +0800</pubDate></item><item><title>611. cs.AI-HalluSegBench：基于反事实视觉推理的分割幻觉评估</title><link>https://arxiv.org/pdf/2506.21546</link><description>Background: 
近期在视觉语言分割领域取得了显著进展，大幅推动了基于图像理解的语义理解。然而，现有模型常常出现幻觉现象，即自动生成与图像内容无关的分割掩码或错误地标记无关区域。现有的分割幻觉评估标准主要集中在标签或文本幻觉上，并不操控视觉上下文，限制了其对关键问题的诊断能力。已有研究侧重于图像内容的静态评估，未能全面诊断模型的幻觉倾向.

Innovation: 
本文引入了HalluSegBench，这是首个专门针对视觉定位中存在的幻觉进行评估的基准，通过反事实视觉推理来评估幻觉。HalluSegBench包含一个新型的反事实实例对数据集（包含1340个样本和281个独特的对象类别）以及量化幻觉敏感性的新指标，在视觉一致场景编辑下评估幻觉鲁棒性。本文实验表明，由视觉驱动的幻觉比标签驱动的幻觉更为常见，模型往往持续错误分割，突显了反事实推理在诊断定位保真度方面的必要性.

Conclusion: 
实验表明，当前最先进的视觉语言分割模型在视觉引导的幻觉方面比标签引导的幻觉更为普遍，这些模型在错误分割上表现出持久性，这表明基于反事实推理对于评估和诊断定位保真度是必要的。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21546</guid><pubDate>Fri, 27 Jun 2025 02:30:09 +0800</pubDate></item><item><title>612. cs.AI-增强领域知识的LLM在欺诈和概念漂移检测中的应用</title><link>https://arxiv.org/pdf/2506.21443</link><description>Background: 
由于语言模式的演变和概念漂移（即语义或主题的改变，这些改变会随着时间影响对话的上下文或意图），在动态平台上检测误导性对话变得越来越困难。这些改变可能会掩盖恶意意图，或模仿正常的对话，使得准确分类变得极具挑战性。虽然大型语言模型在自然语言任务中表现出色，但在风险敏感的情景下，它们经常难以应对上下文的模糊性和幻觉。

Innovation: 
提出了一种集成预训练的大型语言模型和特定任务结构化洞识的领域知识增强的大型语言模型框架，该框架用于欺诈和概念漂移检测。框架包含三个主要模块：一是用于检测虚假或误导性对话的领域知识大型语言模型模块；二是用于确定是否发生了语义变化的漂移检测单元；三是用于将漂移分类为良性或欺诈的第二个领域知识大型语言模型模块。该实现基于LLaMA，并在结构化提示的引导下，达到了98％的分类准确率。与零样本基准的比较研究表明，集成领域知识和漂移意识显著提高了在高风险NLP应用中的性能、可解释性和鲁棒性。

Conclusion: 
该系统在检测虚假对话方面表现出高度准确性，并能有效地分类漂移的性质，特别是在面对高风险NLP应用时，结合领域知识和漂移意识的策略产生了明显的改进效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21443</guid><pubDate>Fri, 27 Jun 2025 02:30:08 +0800</pubDate></item><item><title>613. cs.AI-时间感知图注意力网络在加密货币交易欺诈检测中的应用</title><link>https://arxiv.org/pdf/2506.21382</link><description>Background: 
加密货币交易欺诈检测面临日益复杂交易模式和严重的类别不平衡挑战。传统方法依赖手动特征工程，难以捕捉交易网络中的时序和结构依赖性.

Innovation: 
本文提出了一种增强时序意识的图注意力网络（ATGAT），通过三个模块提升检测性能：(1) 设计先进的时序嵌入模块，融合多尺度时间差特征和周期位置编码；(2) 构建时序意识的三重注意力机制，联合优化结构、时序和全局上下文注意力；(3) 使用加权BCE损失以应对类别不平衡问题。实验结果表明，ATGAT在Elliptic++加密货币数据集上实现了0.9130的AUC，分别比最先进技术XGBoost、GCN和标准GAT高9.2%、12.0%和10.0%。该方法不仅验证了时序意识和三重注意力机制在图神经网络中的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则适用于其他时间序列图异常检测任务.

Conclusion: 
该方法不仅验证了时序意识和三重注意力机制在图神经网络中的增强效果，还为金融机构提供了更可靠的欺诈检测工具，设计原则适用于其他时间序列图异常检测任务&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21382</guid><pubDate>Fri, 27 Jun 2025 02:30:06 +0800</pubDate></item><item><title>614. cs.AI-skLEP：斯洛伐克通用语言理解基准</title><link>https://arxiv.org/pdf/2506.21508</link><description>Background: 
目前缺乏专门针对斯洛伐克语自然语言理解（NLU）模型的综合基准测试，研发者难以全面评估模型能力。本研究旨在填补这一空白，通过创建涉及不同类型的斯洛伐克语NLU任务的全面基准测试来促进斯洛伐克NLU领域的发展。

Innovation: 
引入了skLEP，这是首个专门针对斯洛伐克语NLU模型的基准测试工具，涵盖多项从字符级到文档级的多样化任务，全面评估模型性能。创新点在于不仅开发了新的斯洛伐克专属数据集，还细致地翻译了现有的英语NLU资源，使基准测试更加全面和准确。此外，这项研究还首次系统性地评估了多种斯洛伐克语、多语言以及英语预训练语言模型，进一步推动该领域的发展。

Conclusion: 
本研究发布了一个包含所有基准测试数据和开源工具的skLEP，以及公开排行榜，以鼓励可重现性并推动未来斯洛伐克语NLU领域的研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21508</guid><pubDate>Fri, 27 Jun 2025 02:30:05 +0800</pubDate></item><item><title>615. cs.AI-过程导向的建模与仿真增强在网状物理系统中的故障诊断</title><link>https://arxiv.org/pdf/2506.21502</link><description>Background: 
在网状物理系统（CPSs）中，故障诊断对于确保系统的可靠性与运营效率至关重要。既有的故障行为建模方法通常需要大量的专业知识，且所建模型复杂、易出错且难以解释。因此，需要一种新的方法来解决这一问题，该方法需要能够在多变量时间序列分析、过程挖掘与随机仿真方面有所创新，以实现故障诊断的自动化与可解释性提高。

Innovation: 
提出了一种新颖的无监督故障诊断方法，将集体异常检测应用于多变量时间序列数据中，在此基础上使用过程挖掘将异常数据转化为结构化事件日志，通过引入时间分布将提取的Petri网进行随机仿真，支持对故障行为进行建模与仿真，以增强根本原因分析和行为理解能力。该方法已在Robotic Arm Dataset（RoAD）上进行了实证研究，证明了其在网状物理系统中的有效性，支持预测性维护和工业数字孪生的发展。

Conclusion: 
该方法通过过程挖掘驱动建模与仿真进一步增强了网状物理系统中的故障诊断。实验结果表明，这种方法在构建故障字典、实现故障行为的建模与分类方面表现出色，为智能制造提供了必要的技术支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21502</guid><pubDate>Fri, 27 Jun 2025 02:30:05 +0800</pubDate></item><item><title>616. cs.AI-SmoothSinger: 多分辨率架构的条件扩散模型用于歌唱语音合成</title><link>https://arxiv.org/pdf/2506.21478</link><description>Background: 
歌唱语音合成（SVS）旨在从乐谱中生成具有表现力和高质量的人声，这需要精确建模音高、音长和发音。尽管基于扩散的方法在图像和视频生成方面取得了显著成功，但将其应用于SVS仍具有挑战性，因为歌唱的声学和音乐特性复杂，往往会导致影响自然性的音质缺陷。现有的方法通常依赖于矢量量化器（vocoder），最终在生成高质量真实歌唱声音时，容易引入失真。本文介绍了一种名为SmoothSinger的条件扩散模型，该模型直接在统一框架中细化低质量合成音频，从而减少两阶段管道中相关的退化问题。SmoothSinger采用参考导向的双分支架构，用任何基线系统的低质量音频作为参考，引导去噪过程，从而实现更具有表现力和上下文意识的合成。此外，模型通过引入并行低频上采样路径，增强了传统的U-Net结构，使其能够更好地捕捉音高轮廓和长期光谱依赖关系。为改善在训练期间的对齐，将参考音频替换为降级的真实音频，解决了参考信号和目标信号之间的时间失配问题。在大规模的中文歌唱语料库Opencpop上的实验表明，SmoothSinger在客观和主观评估方面均达到了最先进的效果。广泛的消融研究证实了其减少艺术缺陷和提高合成声音自然性的有效性。

Innovation: 
SmoothSinger提出了一个参考导向的双分支架构模型，直接在统一框架中精细化低质量合成音频，减少了两阶段管道中的退化问题。它通过引入并行低频上采样路径，增强了传统的U-Net结构，能够更好地捕捉音高轮廓和长期光谱依赖关系。在训练过程中，用降级的真实音频替换参考音频，解决了参考信号与目标信号之间的时序不对齐问题。该模型在大规模中文歌唱语料库Opencpop上表现优越，证明了其有减少艺术缺陷和提高合成声音自然性的有效性。

Conclusion: 
SmoothSinger实现了歌唱语音合成的新突破，通过优化模型结构和训练方法，在自然性和表现力方面取得了最先进的结果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21478</guid><pubDate>Fri, 27 Jun 2025 02:29:56 +0800</pubDate></item><item><title>617. cs.AI-关注较小的权重</title><link>https://arxiv.org/pdf/2506.21374</link><description>Background: 
大规模预训练神经网络的微调 Known to be resource-intensive, both in terms of memory and computational cost. 有较大的资源消耗，包括内存和计算成本。 为了缓解这一问题，一种常用的方法是限制训练到模型参数的子集中。 在微调过程中，我们观察到一个明显的特点：大梯度通常与小幅度的权重相关联。 这种关联在微调设置中比从零开始训练更为显著。

Innovation: 
我们提出了NANOADAM，该方法在微调过程中仅动态更新小幅度的权重。 这种方法具有几个实际优势：首先，这是一个无梯度的方法—参数子集可以在不进行梯度计算的情况下确定；其次，它保留了大幅度的权重，这些权重很可能包含了在预训练过程中学到的关键特征，从而减少了灾难性遗忘的风险；第三，它可以使用较大的学习率，实验结果表明，它能够获得更好的泛化性能。 我们在自然语言处理和视觉任务中证实了这一点。

Conclusion: 
我们展示了这种技术在自然语言处理和视觉任务中的应用，证明了仅在微调过程中更新小幅度权重的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21374</guid><pubDate>Fri, 27 Jun 2025 02:29:54 +0800</pubDate></item><item><title>618. cs.AI-ScalaBLE: 可扩展的通过随机变分子空间推断实现的大语言模型贝叶斯低秩适应</title><link>https://arxiv.org/pdf/2506.21408</link><description>Background: 
尽管大语言模型（LLMs）在广泛使用，但它们已知会生成不正确的信息且校准不佳，这使得这些模型的不确定度量化在高风险领域（如自主性和医疗保健）变得至关重要。先前的工作通过在微调模型的低秩适应（LoRA）参数上进行贝叶斯深度学习推理，使得这一问题更易于解决。然而，这些方法难以扩展到更大的LLMs，因为它们需要比LoRA更多的额外参数。

Innovation: 
我们提出了ScalaBLE，一种通过随机变分子空间推断实现的大语言模型可扩展的贝叶斯低秩适应方法。通过将LoRA参数重新用于投影矩阵，我们能够在r维子空间上进行贝叶斯推理，并将来自该子空间的样本映射到LLM的完整权重空间。这种方法仅需约1000个额外参数就实现了与最先进的方法相当的性能，并且能够扩展到目前为止最大的贝叶斯LLM，其基参数数量是先前研究的四倍。

Conclusion: 
ScalaBLE克服了过去方法的扩展性限制，通过引入子空间推理，有效地解决了大语言模型的不确定度量化问题，实现了更为广泛的适用性和更好的性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21408</guid><pubDate>Fri, 27 Jun 2025 02:29:53 +0800</pubDate></item><item><title>619. cs.AI-利用LLM辅助查询理解实现即时检索增强生成</title><link>https://arxiv.org/pdf/2506.21384</link><description>Background: 
当前的Live Retrieval-Augmented Generation (RAG)系统的处理能力在面对含有噪声、模糊性和多意图的用户查询时存在显著不足。尽管RAG通过外部知识增强大语言模型（LLMs），但现有系统通常难以处理这些复杂的输入，因为它们通常是在更清洁的数据上进行训练或评估的。SIGIR 2025 LiveRAG挑战指出了这些实际应用的需求，突显了增强RAG系统处理复杂、噪声查询能力的重要性。

Innovation: 
该论文提出了一种名为Omni-RAG的新框架，旨在增强即时、开放域RAG系统的鲁棒性和有效性。该框架利用大语言模型辅助查询理解，通过对用户输入进行预处理来解决复杂和噪声查询的问题。其创新点包括：(1) 深度查询理解与分解，通过定制提示来利用大语言模型来清理查询（如纠正拼写错误）并分解出多意图查询；(2) 意图感知的知识检索，针对每个子查询从语料库（如使用OpenSearch的FineWeb）进行检索并将结果综合；(3) 再排序与生成，使用再排序器进一步优化文档选择后，通过带有推理提示的大语言模型生成最终答案。Omni-RAG旨在弥补当前RAG功能与实际应用需求之间的差距。

Conclusion: 
Omni-RAG框架通过增强处理复杂和噪声查询的能力，旨在提升RAG系统的性能，以更好地满足实际应用的要求。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21384</guid><pubDate>Fri, 27 Jun 2025 02:29:52 +0800</pubDate></item><item><title>620. cs.AI-大规模电商平台的实时个性化产品推荐方法</title><link>https://arxiv.org/pdf/2506.21368</link><description>Background: 
当前，电商平台需要能够提供实时和个人化的商品推荐，以满足用户的个性化需求，并提高用户满意度。特别是在时尚零售领域，准确性和效率尤为重要。现有的推荐系统往往面临响应时间长、个性化不足等问题，需要开发新的方法和技术来提升推荐效果和效率。

Innovation: 
本文提出了一种利用图神经网络和简约学习方法来提供实时和个性化商品推荐的新方法。通过实验验证，该方法在处理大规模电商平台的数据时，能够有效地预测购买序列，处理多交互场景，并在实际约束条件下实现高效的个性化推荐，显著提高了推荐的准确性和响应速度。

Conclusion: 
实验结果表明，所提出的方法在大规模电商平台上能够实现准确且高效的个性化推荐，满足了实时性和用户满意度的要求。此方法为未来个性化推荐系统的优化提供了新的思路和技术支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21368</guid><pubDate>Fri, 27 Jun 2025 02:29:51 +0800</pubDate></item><item><title>621. cs.AI-DiLoCoX：一种低通信量的大规模分散集群训练框架</title><link>https://arxiv.org/pdf/2506.21263</link><description>Background: 
大语言模型（LLMs）等基础模型的分布式训练需要大量的通信支持，依赖于快而可靠的集中式集群。对于超过100亿参数的模型，在慢速网络上进行训练并利用分散式集群是否可行？现有的解决方案停留在使用集中式集群，无法充分利用分散式集群的优势和资源.

Innovation: 
提出了DiLoCoX，一种结合了管道并行、双重优化策略、一步延迟重叠通信与本地训练以及自适应梯度压缩方案的大规模分散集群训练框架。通过这种组合，显著提高了参数规模和模型预训练的效率，并通过理论收敛分析证明了一步延迟重叠通信和本地训练，以及自适应梯度压缩方案的效果。实验表明，DiLoCoX能够在1Gbps的网络上预训练一个107B参数的基础模型，相较于普通的AllReduce，在分布式训练速度上达到357倍的提升，而对模型收敛性的影响几乎可以忽略 不计。这是首次成功应用于超过100亿参数模型的分散式训练框架.

Conclusion: 
DiLoCoX显著解决了分布式训练中的高效通信和模型规模问题，能够高效地在低速网络上训练大规模模型，为分散式集群提供了新的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21263</guid><pubDate>Fri, 27 Jun 2025 02:29:47 +0800</pubDate></item><item><title>622. cs.AI-rQdia: 使用图像增强正则化Q值分布</title><link>https://arxiv.org/pdf/2506.21367</link><description>Background: 
在基于像素的深度强化学习中，利用图像像素进行训练能够减少对环境状态编码的依赖。然而，这种方法面临的一个主要挑战是Q值分布的不稳定性。现有的方法如DrQ和SAC在处理MuJoCo连续控制套件中的任务时表现良好，但在Atari游戏中，效率和效果仍有待提升。因此，本文提出了rQdia，一种利用图像增强来调节Q值分布的新方法，以提高模型的样本效率和训练长期稳定性。

Innovation: 
rQdia方法通过引入一种简单的辅助损失函数，使用均方误差（MSE）来相等化Q值分布。该方法显著提升了DrQ和SAC在MuJoCo连续控制套件中9/12和10/12任务的表现，同时也提高了Data-Efficient Rainbow在Atari游戏中18/26环境的表现。此外，该方法使基于像素的模型摆脱了对状态编码的依赖，实现了在连续控制任务上的突破，尤其是在样本效率方面取得了显著提升。

Conclusion: 
rQdia在多个环境中实现了样本效率和长期训练结果的显著改进，通过使用图像增强技术调节Q值分布，对基于像素的深度强化学习方法进行了有意义的创新。该方法不仅增强了现有算法的表现，也为未来的相关研究提供了新的思路。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21367</guid><pubDate>Fri, 27 Jun 2025 02:29:44 +0800</pubDate></item><item><title>623. cs.AI-基于分层输入依赖状态空间模型的整体手术阶段识别</title><link>https://arxiv.org/pdf/2506.21330</link><description>Background: 
在机器人辅助手术中，对手术流程分析至关重要，但由于手术过程的长时间特性给全面的视频分析带来了巨大挑战。近期方法主要依赖于变压器模型，但其二次注意力机制限制了处理长视频的效率。

Innovation: 
本文提出了一种新的分层输入依赖状态空间模型，利用状态空间模型的线性扩展特性，能处理全长视频并捕捉局部与全局动态。该框架包含一个时序一致的视觉特征提取器，该提取器将状态空间模型头部附加到视觉特征提取器上以传播时间信息。所提出的模型包括两个关键模块：一个有效的捕捉复杂局部动态的局部聚合状态空间模型块，以及一个建模整个视频时间依赖关系的全局关系状态空间模型块。通过混合离散连续监督策略训练此模型，其中离散相位标签和连续相位进步通过网络传播。

Conclusion: 
实验表明，本方法在现有最佳方法上的表现超出很多，分别在Cholec80上提高了2.8%，在MICCAI2016上提高了4.3%，在Heichole数据集上提高了12.9%。代码将在论文接受后公开。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21330</guid><pubDate>Fri, 27 Jun 2025 02:29:40 +0800</pubDate></item><item><title>624. cs.AI-人机共创系统的系统性回顾</title><link>https://arxiv.org/pdf/2506.21333</link><description>Background: 
共创意社区正在开发更为复杂和量身定制的系统来支持和增强人类的创造力。先前工作中的设计注意事项为未来的系统提供了有价值且高效的基础。为了支持这一努力，作者系统性地回顾了62篇关于共创系统的论文，这些论文涵盖了视觉艺术、设计和写作等多个应用领域，AI在其中不仅作为工具，还作为创意过程中的积极参与者。通过这次回顾，作者确定了几个关键设计维度：创意过程的阶段、创意任务、系统的主动行为、用户控制、系统实体化和AI模型类型。研究结果表明，提供较高用户控制的系统可以带来更高的满意度、信任感和对创造成果的所有权感。此外，当适应性和环境敏感时，系统的主动性可以增强合作。作者还提取了24项设计建议，强调鼓励用户将想法外部化以及增加系统的社会存在感和透明度以培养信任的重要性。尽管近期取得了进展，但仍存在一些重要空白，例如对早期创意阶段（如问题澄清）的支持有限，以及用户对AI系统的适应性问题。

Innovation: 
本研究通过系统性回顾62篇关于共创系统的论文，确定了几个关键的设计维度，提出了一系列设计建议，强调了高用户控制、系统主动性、外部化思维和增加系统透明度在共创系统设计中的重要性。这些发现为未来的共创系统设计提供了实用指导。

Conclusion: 
尽管共创意社区在开发复杂的共创系统方面取得了进展，但仍然存在一些关键空白，特别是在创意过程的早期阶段和用户对AI系统的适应性方面。建议未来的研究解决这些问题，以进一步提升共创意系统的效能和用户体验。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21333</guid><pubDate>Fri, 27 Jun 2025 02:29:40 +0800</pubDate></item><item><title>625. cs.AI-CA-I2P: 具有全局最优选择的通道自适应注册网络</title><link>https://arxiv.org/pdf/2506.21364</link><description>Background: 
现有检测无感知方法通常采用从粗到细的处理管道，从图像和点云特征中提取信息用于进行斑块级别的匹配，并进一步细化密集的像素到点的对应关系。但是，图像和点云间特征通道注意力的差异可能导致匹配结果下降，损害最终的配准精度。类似地，场景中的相似结构会导致跨模态匹配中出现冗余对应关系。

Innovation: 
本文提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强同模态特征，抑制跨模态的敏感度，GOS用全局优化代替局部选择。在RGB-D Scenes V2和7-Scene数据集上的实验结果显示了本方法的优势，实现了图像到点云配准的最佳性能。

Conclusion: 
实验结果证明了所提出的方法在图像到点云配准任务中的优越性，达到了最先进的性能水平。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21364</guid><pubDate>Fri, 27 Jun 2025 02:29:40 +0800</pubDate></item><item><title>626. cs.AI-低资源音乐生成中适配器设计权衡的研究</title><link>https://arxiv.org/pdf/2506.21298</link><description>Background: 
大型音乐生成模型（如MusicGen和Mustango）的微调是一个计算成本高昂的过程，通常需要更新数十亿个参数，并且需要大量的硬件资源。为了解决这一问题，参数高效微调（PEFT）技术，特别是基于适配器的方法，已经成为了有希望的替代方案，可以在最少的可训练参数下实现模型性能的适应，同时节省硬件资源。但是，适配器的设计选择，包括它们的架构、位置和大小，有很多不同的选项，目前还不清楚这些组合中的哪一个会产生最佳的适配器及其原因，特别是对于低资源音乐流派而言。

Innovation: 
本文通过研究不同配置的适配器在两个AI音乐模型（MusicGen和Mustango）上的表现，探讨了在两种音乐流派（印度斯坦古典音乐和土耳其马卡姆音乐）上如何实现最佳的适配器设计。发现卷积适配器在捕捉细腻的地方音乐细节（如装饰音和短旋律片段）方面表现出色，而变压器适配器则在保持对结构即兴演奏至关重要的长期依赖关系方面表现更好。此外，还分析了不同适配器规模下的计算资源需求，表明中型适配器（参数量为40M）在表达能力和质量之间实现了最优平衡。通过对比Mustango和MusicGen模型的生成效果，表明了基于扩散的模型在生成更多样化的输出方面具有优势，但缺乏音符稳定性和节奏对齐，而自回归模型则训练更快，效率更高，但生成输出的冗余度略高。

Conclusion: 
研究结果表明，卷积适配器在捕捉微观音乐细节方面表现更佳，而变压器适配器则更适合保持长期依赖关系，这对于结构化的即兴创作至关重要。此外，中型适配器（40M参数）能够在表达能力和质量之间取得最优平衡。Mustango虽然生成多样性的输出更好，但在音符稳定性和节奏对齐等方面表现较差，而MusicGen模型训练更快，生成质量更高，但在输出中有轻微的冗余。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21298</guid><pubDate>Fri, 27 Jun 2025 02:29:39 +0800</pubDate></item><item><title>627. cs.AI-在加权深多项式逼近方面的统一探讨</title><link>https://arxiv.org/pdf/2506.21306</link><description>Background: 
在有理逼近理论中，一些非光滑或奇异函数，如$|x|$和$x^{1/p}$，可以用具有根指数收敛性的有理函数有效逼近。多项式逼近仅能达到Jackson定理所述的代数收敛速度。然而，近年来的工作表明，即使在没有光滑性的情况下，复合多项式架构也可以恢复指数逼近速率。本文探讨了一类针对单侧增长且另一侧衰减函数进行加权深多项式逼近的方法。通过学习得到的深多项式与单侧权重的乘积，可以同时捕捉局部非光滑性和全局增长特性。

Innovation: 
引入了一类针对具有不对称行为的函数（一侧增长、另一侧衰减）进行加权深多项式逼近的模型。通过乘以可学习的深多项式和一个单侧权重，该框架能够捕捉局部非光滑性和全局增长特征。实验表明，该框架即使使用相同数量的参数，其逼近效果也优于Taylor逼近、Chebyshev逼近和普通深多项式逼近。为了实际优化这些逼近模型，提出了基于图结构参数化的稳健策略。

Conclusion: 
通过引入加权的深多项式逼近方法，可以更有效地逼近具有特定行为的函数。实验表明，该方法在相同参数条件下优于现有的多种逼近方法，而且提出的新参数化策略提高了优化的稳定性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21306</guid><pubDate>Fri, 27 Jun 2025 02:29:37 +0800</pubDate></item><item><title>628. cs.AI-使用高效球面卡丘分布的超球面变分自编码器</title><link>https://arxiv.org/pdf/2506.21278</link><description>Background: 
传统的变分自编码器（VAE）使用高斯隐变量空间或von Mises-Fisher分布，但这些方法在处理方向性数据时存在限制。von Mises-Fisher分布计算上存在数值不稳定性问题，而高斯分布则可能过度正则化，限制了隐变量空间的有效利用和表示能力。

Innovation: 
提出了一种新的VAE架构，采用球面卡丘（spCauchy）隐变量分布。spCauchy分布具有更自然的超球面表示形式，更适合捕捉方向性数据，同时保持灵活性。其厚尾特性可以防止过度正则化，保证隐变量空间的有效利用和更强大的表示能力。此外，spCauchy通过莫比乌斯变换实现了完全可微且高效的重新参数化技巧，避免了von Mises-Fisher分布的数值不稳定问题。此外，可以通过快速收敛的幂级数计算KL散度，消除了与超几何函数比值计算相关的下溢或上溢问题。这些特性使spCauchy成为研究VAEs的有效替代方案，具有理论优势和实际高效的高维生成建模能力。

Conclusion: 
球面卡丘分布可以在VAE中提供更自然的超球面隐变量表示，同时增强了对方向数据的捕捉能力，避免了von Mises-Fisher分布的数值不稳定性。通过提供更高效的计算方法和更稳定的学习机制，spCauchy VAE在高维生成建模中展现出理论优势和实际应用效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21278</guid><pubDate>Fri, 27 Jun 2025 02:29:34 +0800</pubDate></item><item><title>629. cs.AI-小编码器可以在检测Groundedness方面与大解码器匹敌</title><link>https://arxiv.org/pdf/2506.21288</link><description>Background: 
大型语言模型（LLMs）在其性能提升方面依赖于外部上下文，但在缺乏相关信息的上下文中，LLMs往往会出现推测性的回答或利用内部知识，这影响了回答的可靠性和事实一致性。因此，研究如何在可负担的资源消耗下检测查询是否在上下文中有所依据变得尤为重要。这项研究致力于在LLMs生成答案之前，通过使用轻量级的针对任务的编码器模型，如RoBERTa和NomicBERT来检测查询是否基于提供的文档上下文，从而降低推理时间和资源消耗。

Innovation: 
研究证明，即使是在性能上远不及现代LLMs的轻量级模型，如RoBERTa和NomicBERT，也能在上下文一致性检测方面达到接近最先进的LLMs（如Llama3 8B和GPT4o）的准确性，同时将推理延迟大大缩短。这表明，较小型的编码器模型在检测上下文一致性方面可以与强大且庞大的LLMs竞争，为实际应用提供了一种成本效益更高的方法。

Conclusion: 
此项研究开发了一种轻量级的任务特定编码器模型，能够高效地检测查询的上下文一致性，显著减少了推理时间和资源消耗，同时保持了与最先进的LLMs相当的准确性。这为实际应用中利用LLMs处理自然语言处理任务提供了新的可能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21288</guid><pubDate>Fri, 27 Jun 2025 02:29:34 +0800</pubDate></item><item><title>630. cs.AI-集成车辆声学数据以增强城市交通管理：苏州城市道路行驶速度分类研究</title><link>https://arxiv.org/pdf/2506.21269</link><description>Background: 
本文介绍了公开发布的苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提供了全面的数据收集协议和注解指导，以确保实验工作流程的透明性和可重复性。该研究旨在通过提出一种双模特征融合深度卷积神经网络（BMCNN）来建模车辆噪声与行驶速度之间的耦合关系，从而进行行驶速度分类。在预处理阶段采用自适应去噪和标准化策略以抑制环境背景干扰；在网络架构中，通过并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，并在中间特征空间通过跨模态注意力机制进行融合，以充分利用时间-频率信息。实验结果显示，BMCNN在SZUR-Acoustic Dataset和公共IDMT-Traffic数据集上的分类准确率分别为87.56%和96.28%。进一步在苏州数据集上的消融研究和鲁棒性测试验证了每个模块对性能提升和过拟合缓解的贡献。

Innovation: 
该研究提出了双模特征融合深度卷积神经网络（BMCNN）来建模车辆噪声与行驶速度之间的耦合作用，并通过跨模态注意力机制充分利用时间-频率信息。BMCNN在两个数据集上的分类性能显著，尤其在抑制环境背景干扰和提高鲁棒性方面表现出色。此外，研究还通过消融实验验证了各模块的重要性，进一步优化了性能并减轻了过拟合现象。

Conclusion: 
提出的基于声学的速度分类方法可以集成到智能城市交通管理系统中，实现实时噪声监测和速度估计，从而优化交通流量控制、减少路边噪声污染，并支持可持续城市规划。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21269</guid><pubDate>Fri, 27 Jun 2025 02:29:33 +0800</pubDate></item><item><title>631. cs.AI-使用自回归语言模型在视觉接地对话中检测代词表达</title><link>https://arxiv.org/pdf/2506.21294</link><description>Background: 
本文探讨了使用仅基于文本的自回归语言模型提取视觉对话中的代词表达。具体而言，目的是研究只有语言上下文是否足以提示视觉上下文中可感知的关系。研究利用预训练的大语言模型对标记进行相对粗糙的标注，通过预测下一个token来划定提到的范围边界。研究表明，即使使用中等大小的语言模型，较小的数据集和大规模参数调整，仅基于文本的方法仍然有效，突显了语言上下文的重要性。然而，作者认为任务本质上是多模态的问题，并讨论了单模态方法的固有限制。

Innovation: 
利用预训练的大语言模型进行相对粗糙的标记，通过预测下一个token来划定提到的范围边界，这种方法在小数据集和参数高效调整的情况下仍然有效。

Conclusion: 
虽然仅基于文本的方法在一定程度上有效，但任务本质上是多模态的，单模态方法有其固有限制，需要进一步探索多模态方法来解决这个问题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21294</guid><pubDate>Fri, 27 Jun 2025 02:29:31 +0800</pubDate></item><item><title>632. cs.AI-Agent-RewardBench：统一感知、规划和安全领域多模态智能体奖励建模 benchmark 的构建</title><link>https://arxiv.org/pdf/2506.21252</link><description>Background: 
随着多模态大语言模型（MLLMs）的发展，多模态智能体展现出在真实世界任务如网页浏览和体态智能中的潜力。然而，由于缺乏外部反馈引起的自我纠正和泛化能力不足，使得这些智能体难以应对这些挑战。一种有潜力的解决方案是使用奖励模型作为外部反馈，但目前尚不清楚如何选择适合智能体的奖励模型。因此，构建一个针对性的奖励benchmark变得尤为迫切。本研究旨在解决这些挑战，提出了一个称为Agent-RewardBench的benchmark，用于评估多模态语言模型在奖励建模方面的表现。它包括多个维度和真实世界智能体场景的评估，涵盖了感知、规划和安全，共7个场景；逐步骤奖励评估，可评估智能体在任务每一步骤的能力，提供更细腻的规划过程表现视图；以及适中的难度和高质量的数据。精选了10个不同的模型，难度控制保持任务挑战性，并通过人工验证确保数据完整性。实验结果表明即使是先进的多模态模型在奖励建模方面的表现也非常有限，这突显了对智能体奖励建模的专业化训练需求。

Innovation: 
提出了一个名为Agent-RewardBench的benchmark，用于评估多模态语言模型在奖励建模方面的表现。此benchmark具有三个关键特性：（1）多个维度和真实世界智能体场景评估，涵盖了感知、规划和安全，共计7个场景；（2）逐步骤奖励评估，允许评估智能体在任务每一步的能力，提供更为细致的规划过程表现视图；（3）适中的难度和高质量的数据，精选了10个不同的模型，难度控制保持任务挑战性，通过人工验证确保数据完整性。研究结果表明，即使是最先进的多模态模型在奖励建模方面表现也非常有限，突显了对智能体奖励建模的专业化训练需求。

Conclusion: 
实验结果表明，即使是最先进的多模态模型，在奖励建模方面也表现受限，强调了对智能体奖励建模的专业化训练需求。该项目的代码可以在github上获得。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21252</guid><pubDate>Fri, 27 Jun 2025 02:29:30 +0800</pubDate></item><item><title>633. cs.AI-维护MTEB：迈向嵌入基准长期可重复性和可用性</title><link>https://arxiv.org/pdf/2506.21182</link><description>Background: 
《大规模文本嵌入基准（MTEB）》已成为评估文本嵌入模型的标准平台。尽管之前的工作已经确立了基准测评的主要方法，但本文关注的是确保MTEB持续的可重复性和可扩展性的工程方面。该研究详细介绍了维持基准的方法和策略，以增强其可重复性和实用性，同时处理社区贡献并扩展基准以引入新的任务和数据集。

Innovation: 
研究提出了维护稳健的持续集成流水线的方法，包括验证数据集完整性、自动化测试执行和评估基准结果的泛化性。这些工程实践对于扩展MTEB、确保质量和相关性至关重要，最终十分有助于解决机器学习测评框架中可重复性和可用性的问题。此外，还讨论了处理社区贡献和扩展基准的新任务和数据集的策略。

Conclusion: 
研究经验对面临类似挑战的基准维护者提供有价值的见解，确保基准测评框架中的可重复性和可用性。MTEB的存储库可在指定链接中找到。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21182</guid><pubDate>Fri, 27 Jun 2025 02:29:26 +0800</pubDate></item><item><title>634. cs.AI-一种将3D超声整合到经皮肝肿瘤消融中的新型框架</title><link>https://arxiv.org/pdf/2506.21162</link><description>Background: 
3D超声（US）成像在提高经皮肝脏肿瘤消融的效果方面显示出显著优势，但其临床整合对于将3D US从诊断领域过渡至治疗领域至关重要。目前，US图像中肿瘤识别的挑战仍在阻碍其更广泛的采用。本研究旨在提出一种新的框架，以将3D US整合到标准消融工作流程中，提出了一种适用于临床的2D US-CT/MRI配准方法，利用3D US作为中介来简化配准过程。此外，提出了一种直观的多模态图像可视化技术，以促进配准流程的有效验证。研究结果显示，2D US-CT/MRI配准的地标距离误差约为2-4毫米，运行时间为每对图像0.22秒，非刚性配准将平均对齐误差减少了约40%。结果证明了所提2D US-CT/MRI配准流程的有效性，实现了3D US成像在经皮肿瘤消融中的改进，并展示了3D US在临床干预中扩展治疗作用的潜力。

Innovation: 
提出了一种新的框架，用于将3D US整合到标准消融工作流程中。这一框架的重点是实现2D US-CT/MRI配准，利用3D US作为配准中介来简化配准过程，并提出了一种直观的多模态图像可视化技术，以促进配准流程的有效验证。

Conclusion: 
所提出的2D US-CT/MRI配准流程成功实现了3D US成像在经皮肿瘤消融中的改进，展示了3D US在临床干预中扩展治疗作用的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21162</guid><pubDate>Fri, 27 Jun 2025 02:29:24 +0800</pubDate></item><item><title>635. cs.AI-少数乐器检测的分层深度学习方法</title><link>https://arxiv.org/pdf/2506.21167</link><description>Background: 
在音乐信息检索中，识别音乐片段中的乐器活动对于音乐分类和发现具有重要意义。以往的深度学习研究主要集中在数据丰富的乐器类别上，最近的研究表明，可以通过层次分类方法在管弦乐中检测到乐器活动，即使是在乐器级细粒度的标注有限的情况下。这项研究基于Hornbostel-Sachs分类系统使用MedleyDB数据集评估层次分类系统，MedleyDB数据集以其多种乐器和音乐风格的多样性和丰富性而闻名。

Innovation: 
这项研究提出了多种将层次结构整合到模型中的策略，并测试了一种用于层次音乐预测的新模型类别。主要创新点在于通过填补细节乐器识别和群体识别之间的差距，实现了更可靠的大类乐器检测，为进一步在这个领域的发展铺平了道路。

Conclusion: 
这项研究展示了通过层次分类系统在详细乐器识别和群体级别识别之间建立联系，以实现更可靠的粗级别乐器检测，为这一领域的进一步发展奠定了基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21167</guid><pubDate>Fri, 27 Jun 2025 02:29:24 +0800</pubDate></item><item><title>636. cs.AI-任务感知的KV压缩以实现成本效益较高的长视频理解</title><link>https://arxiv.org/pdf/2506.21184</link><description>Background: 
现有的大规模多模态语言模型（MLLMs）在长视频理解（LVU）方面面临严重的计算成本问题。近期的一些方法试图通过KV压缩来缓解这个问题，但高压缩比往往伴随着信息丢失的问题。

Innovation: 
本文提出了Video-X^2L，它可以在不引入额外训练的情况下，灵活保留关键视频信息，并引入了两级KV压缩和选择性KV重新加载两种关键技术，使得模型能够在充分利用任务特定信息的同时保持整体紧凑性。

Conclusion: 
我们在多种流行的LVU基准测试（包括VideoMME、MLVU、LongVideoBench和VNBench）上验证了Video-X^2L。实验结果表明，Video-X^2L在计算成本大幅节省的情况下，显著优于现有的KV压缩方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21184</guid><pubDate>Fri, 27 Jun 2025 02:29:22 +0800</pubDate></item><item><title>637. cs.AI-基于线性性的神经网络压缩</title><link>https://arxiv.org/pdf/2506.21146</link><description>Background: 
目前大多数神经网络压缩方法通过测量重要性和冗余性来减少不必要的参数。现有优化解决方案虽然已经非常高效，但仍有提升空间，因此需要新的压缩方法作为补充。已有方法主要依赖于激活函数和冗余参数去除，而本文提出了一种基于线性的压缩方法，旨在进一步优化现有的压缩技术。这种方法通过对具有类似ReLU激活函数的神经网络中几乎总是激活的神经元采取线性处理，允许合并后续层，从而减少权重，进行压缩。

Innovation: 
本文提出了一种基于线性的新型压缩方法，这是一种不同于以往主要依赖于激活函数和冗余参数去除的方法。该方法通过测量几乎总是激活的神经元的行为线性化，实现在合并网络层的同时减少权重。实验结果显示，该方法可以在大多数测试模型中无损压缩到原模型大小的1/4。这种方法适用于已有基于重要性压缩的模型，在不同类型的压缩技术之间几乎没有干扰，表明可以成功结合多种压缩技术。

Conclusion: 
本文确立了一种基于线性的压缩方法，这种新方法能更有效地减少神经网络的参数，使模型更小更高效，初步表明其作为未来神经网络优化解决方案的一种有力途径的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21146</guid><pubDate>Fri, 27 Jun 2025 02:29:21 +0800</pubDate></item><item><title>638. cs.AI-BitMark for Infinity: Bit级自回归图像生成模型中的水印</title><link>https://arxiv.org/pdf/2506.21209</link><description>Background: 
现阶段最先进的文本转图像模型（如Infinity）能够以前所未有的速度生成超真实的图像。这些模型以位级自回归的方式在实际无限大的离散标记集上运行。然而，这些模型具备强大的生成能力同时也伴随着逐渐增加的风险：随着它们的输出在互联网上不断增加，这些输出有可能被爬取并用作训练数据——甚至有可能来自这些模型的旧版本。这一现象已被证实会导致模型崩溃，即在反复训练生成内容的过程中，模型的性能会逐渐恶化。一种有前景的缓解策略是水印技术，即在生成的图像中嵌入不可感知但可检测的信号，从而能够识别生成的内容。我们的工作旨在为Infinity引入一个坚如磐石的位级水印框架BitMark。

Innovation: 
我们的方法直接在位级上嵌入水印，在Infinity的图像生成过程中跨越多个尺度（或分辨率）的标记流中。这种方法对位施加隐蔽的影响，以保持视觉保真度和生成速度，同时具有很强的抗移除技术的鲁棒性。此外，它还表现出高度的放射性，也就是说，当使用经过BitMark水印处理的生成图像重新训练另一个图像生成模型时，该第二个模型的输出也会携带水印。即使只是对经过BitMark水印处理的图像进行微调扩散或图像自回归模型，其痕迹也是可以检测到的。

Conclusion: 
总体而言，我们的方法为防止图像生成模型中的模型崩溃提供了一个有原则的步骤，通过可靠的检测生成输出来实现这一点。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21209</guid><pubDate>Fri, 27 Jun 2025 02:29:21 +0800</pubDate></item><item><title>639. cs.AI-$T^3$: 大型语言模型驱动的多层次树结构自动程序修复</title><link>https://arxiv.org/pdf/2506.21211</link><description>Background: 
自动程序修复（APR）是软件开发和维护中的关键技术，旨在通过最少的人工干预实现自动缺陷修复。近年来，大型语言模型（LLMs）和链式思维（CoT）技术的显著进步极大地增强了这些模型的推理能力。然而，由于APR领域所需的复杂逻辑和多步骤推理能力，CoT技术的应用仍然不足。因此，本研究系统地评估了几种常见的CoT技术在APR任务中的性能，并提出了一种创新框架$T^3$，将LLMs的强大推理能力与树搜索技术集成，有效提高了生成候选修复解决方案的准确性。此外，$T^3$为优化APR任务中样本选择和修复策略提供了宝贵指导，建立了高效的自动化调试框架。

Innovation: 
该研究提出了一种新颖的框架$T^3$，它结合了大语言模型的强大推理能力和树搜索技术，以提高自动化程序修复的精度，并为优化样本选择和修复策略提供了指导。

Conclusion: 
该研究通过系统评估几种常见CoT技术在APR任务中的性能，并提出了集成LLMs和树搜索技术的$T^3$框架，该框架能够有效提高修复解决方案的准确性，并优化样本选择和修复策略，从而建立了高效的自动化调试框架。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21211</guid><pubDate>Fri, 27 Jun 2025 02:29:19 +0800</pubDate></item><item><title>640. cs.AI-合成需求质量如何？评估大型语言模型生成的数据集对AI4RE的应用</title><link>https://arxiv.org/pdf/2506.21138</link><description>Background: 
当前公开可用、标注的需求数据集供应不足，仍然是限制人工智能在需求工程领域（AI4RE）发展的主要障碍。尽管大型语言模型提供了生成合成数据的有希望能力，但控制和优化生成需求质量的系统方法仍然被很大程度上忽视。这项研究探讨了增强的产品线方法Synthline v1，它扩展了之前的v0版本，引入了更先进的生成策略和校对技术。研究通过四个分类任务（缺陷检测、功能性与非功能性、质量与非质量、安全与非安全）来调查提示策略、自动提示优化以及后生成校对对数据质量的影响。

Innovation: 
研究引入了一种增强的产品线方法Synthline v1，它比之前的v0版本采用了更先进的生成策略和校对技术。研究通过四个分类任务评估了多样本提示、自动提示优化及后生成校对对数据质量的影响，展示了这些技术显著提升了合成数据的质量和多样性，尤其是在安全分类和缺陷分类任务中，合成数据表现更优。此外，研究发现某些冗余可能有助于提高机器学习模型的表现。

Conclusion: 
研究结果表明，合成需求数据在特定任务上可以与或超过人类编写的数据，特别是在安全分类和缺陷检测任务上，合成数据表现更好。这些发现为AI4RE提供了实践性的指导，并为通过系统的方法合成数据来缓解数据稀缺性问题提供了可行路径。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21138</guid><pubDate>Fri, 27 Jun 2025 02:29:18 +0800</pubDate></item><item><title>641. cs.AI-从链上到宏观经济：评估数据源多样性在加密货币市场预测中的重要性</title><link>https://arxiv.org/pdf/2506.21246</link><description>Background: 
本研究探讨了数据源多样性对加密货币预测模型性能的影响，结合了技术指标、链上指标、情绪和兴趣指标、传统市场指数和宏观经济指标等多个数据类别。研究引入了Crypto100指数，代表市值前100的加密货币，并提出了一种新颖的特征缩减算法，以识别来自多样化数据源的最具影响力和韧性的特征。实验表明，数据源多样性在不同时间范围内的预测性能上显著提升。研究发现短期和长期预测中链上指标的重要性，以及传统市场指数和宏观经济指标对长期预测的相关性增加，多样化的数据源利用显著提高了模型的准确性。这些发现有助于揭示加密货币市场的短期和长期驱动因素，为开发更准确和可靠的预测模型奠定了基础。

Innovation: 
研究提出了一种新颖的特征缩减算法，以识别多样化数据源中的最具影响力和韧性的特征。通过加密货币市场的链上指标、情绪和兴趣指标、传统市场指数和宏观经济指标等多样化的数据源，显著提升了预测模型的性能。该研究强调了传统市场指数和宏观经济指标在长期预测中的重要性。

Conclusion: 
数据源多样性在加密货币预测模型中具有重要意义，尤其是在不同时间范围内的预测准确性。链上指标对于短期和长期预测至关重要，传统市场指数和宏观经济指标对长期预测具有重要影响。通过利用多样化的数据源，研究提高了模型的准确性和稳健性，为加密货币市场的预测提供了新的视角。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21246</guid><pubDate>Fri, 27 Jun 2025 02:29:18 +0800</pubDate></item><item><title>642. cs.AI-Progtuning: 变量精细调优框架下的Transformer-based语言模型渐进式微调</title><link>https://arxiv.org/pdf/2506.21119</link><description>Background: 
精细调优是利用基于Transformer的语言模型在下游任务中的有希望的技术。随着模型规模的不断扩大，更新所有模型参数的成本越来越高。参数高效的精细调优方法通过选择性地更新一小部分参数来有效地应对这一挑战，但传统的精细调优和大多数现有的方法要求更新的参数数量与初始大小相同，忽略了Transformer块之间的不平等贡献，导致计算资源分配效率极低。

Innovation: 
本文提出了一种新颖的精细调优框架——Progtuning，结合了渐进式学习。Progtuning基于各Transformer块的贡献逐步减少更新的Transformer块数量。通过优化资源分配，Progtuning减少了大约25%的更新参数量，同时保持了竞争力。并且，Progtuning具有与参数高效的精细调优方法的高适应性，展示了在各种适应场景中的出色性能。

Conclusion: 
Progtuning优化了资源分配，减少了更新参数的数量，并且在多种场景下仍然表现出色，证明了其对Transformer-based语言模型的高效适应性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21119</guid><pubDate>Fri, 27 Jun 2025 02:29:11 +0800</pubDate></item><item><title>643. cs.AI-通过注意力引导的图学习实现可解释的层次概念推理</title><link>https://arxiv.org/pdf/2506.21102</link><description>Background: 
CBMs是一类通过解释预测来提供可解释性的深度学习模型，它们通过高阶概念来执行下游任务。当前的CBMs只能对最终任务预测提供可解释性，而概念预测通常通过黑盒神经网络进行，缺乏对概念本身的解释。论文指出现有的CBMs这一局限性，引入了H-CMR（Hierarchical Concept Memory Reasoner），一种可以在概念预测和任务预测两方面提供更多可解释性的CBM模型。H-CMR通过一个由逻辑规则定义的概念间关系的有向无环图来进行概念间的推理，并通过神经注意力机制进行动态选择和应用，实现在推理时间和训练数据效率上的双重优化。研究表明，H-CMR在保持优异性能的同时，能够通过概念和模型干预促进强大的人机交互，改善推理准确性和训练数据效率。

Innovation: 
首次提出H-CMR模型，通过有向无环图和神经注意力机制提供对概念和任务预测的双重可解释性，改善了CBMs的局限性，使得模型不仅对下游任务的预测结果具有可解释性，还对概念预测过程部分具有可解释性。

Conclusion: 
H-CMR模型通过有效的机制提供强大的可解释性，在保持高性能的同时，增强人类与模型的互动，提升模型的推理准确性和数据使用效率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21102</guid><pubDate>Fri, 27 Jun 2025 02:29:07 +0800</pubDate></item><item><title>644. cs.AI-基于课程引导的抗脆弱强化学习在观测空间攻击下的安全无人机冲突解诀</title><link>https://arxiv.org/pdf/2506.21129</link><description>Background: 
部署在关键安全系统中的强化学习（RL）策略，例如动态空域中的无人机导航，容易受到观测空间中的离分布（OOD）对抗性攻击的影响。这些攻击导致分布变化，严重影响价值评估，导致不安全或次优决策，使得现有策略变得脆弱。.

Innovation: 
提出了一个抗脆弱的RL框架，用于适应逐步增加的对抗性扰动课程。该框架引入了一个模拟攻击者，能够逐步增强观测空间的扰动强度，使RL代理能够适应和泛化到更广泛的OOD观测，并预见到以前未见过的攻击。该方法通过迭代专家引导的评论家对齐，使用Wasserstein距离最小化，来应用增量扰动观测，稳定了遗忘边界。研究在动态3D障碍的无人机脱冲突场景中，使用了投影梯度下降（PGD）和GPS欺骗攻击进行了验证，结果表明抗脆弱策略在应对这些攻击时性能显著优于标准和鲁棒RL基线，累计奖励提高了15%，冲突事件减少了超过30%。

Conclusion: 
这些发现证明了抗脆弱强化学习在不断变化的威胁场景中进行安全和稳健决策的实用性和理论可行性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21129</guid><pubDate>Fri, 27 Jun 2025 02:29:07 +0800</pubDate></item><item><title>645. cs.AI-在心脏MRI中含噪声标签的心肌疤痕分割的稳健深度学习</title><link>https://arxiv.org/pdf/2506.21151</link><description>Background: 
心肌疤痕的精确分割对于临床评估和治疗计划至关重要。现有的方法面临着标签噪声、数据异质性和类别不平衡等挑战，这影响了模型的性能和通用性。本研究针对这些挑战，提出了一种稳健的深度学习管道，以自监督的方式对心脏MRI中的心肌疤痕进行自动检测和分割。通过使用Kullback-Leibler损失和大量数据增强，该方法能有效应对标签噪声等问题，并验证了其在急性与慢性病例上的表现。

Innovation: 
该研究通过使用Kullback-Leibler损失和大量数据增强，提出了一种自监督的深度学习管道，旨在解决心脏MRI中心肌疤痕分割中遇到的标签噪声、数据异质性和类别不平衡问题。该方法在多个指标上优于现有的如nnU-Net等最先进的模型，显示出强大的跨分布外测试集的一致性和鲁棒性。

Conclusion: 
该研究结果证明了所提出的方法在心肌疤痕分割中能够提供准确和光滑的分割结果，即使在标签噪声的情况下亦然。方法在急性与慢性病例上的良好表现进一步凸显了其在面临不同影像条件和临床任务时的鲁棒性。这为自动心肌疤痕量化建立了可靠的基础，支持了深度学习在心脏成像中的广泛应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21151</guid><pubDate>Fri, 27 Jun 2025 02:29:07 +0800</pubDate></item><item><title>646. cs.AI-DBConformer: 双分支卷积变换器用于脑电图解码</title><link>https://arxiv.org/pdf/2506.21140</link><description>Background: 
基于脑电图(EEG)的脑机接口(BCI)通过转化自发/诱发电位神经活动来实现对外部通信的控制命令。尽管卷积神经网络(CNN)一直是EEG解码的主要骨干模型，但它们固有的短接收野限制了对长时间依赖关系和通道间全局关系的捕捉能力。近期的CNN-Transformer (Conformers)混合模型部分解决了该问题，但大多数采用串行设计，导致局部和全局特征的整合不优化，且往往忽略了显式的通道间建模。

Innovation: 
本文提出了一种双分支卷积变换器（DBConformer），专门用于EEG解码。DBConformer结合了时间Conformer来建模长时间依赖关系，空间Conformer来提取通道间交互，捕捉EEG信号的时空动态和模式。此外，还引入了一个轻量级的通道注意模块，通过数据驱动的重要性赋予EEG通道，进一步精细化空间表示。广泛的实验结果表明，DBConformer在五个运动想象（MI）数据集和两个癫瘸检测数据集的三种评估设置下，均优于10个竞争Baseline模型，参数数量减少了八倍以上，且提取的特征具有生理可解释性和与运动感知先验一致的特点，这使得DBConformer在稳健和可解释EEG解码方面表现出优越性和可解释性。代码已公开。

Conclusion: 
DBConformer在EEG解码性能和解释性方面表现出优越性，验证了其在脑电解码中的可靠性和可解释性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21140</guid><pubDate>Fri, 27 Jun 2025 02:29:03 +0800</pubDate></item><item><title>647. cs.AI-抗脆弱强化学习在对抗环境中的UAV去冲突稳健策略切换</title><link>https://arxiv.org/pdf/2506.21127</link><description>Background: 
无人飞机（UAV）导航的不断增加的自动化暴露它们于对抗攻击，这些攻击利用强化学习（RL）中的传感器操纵漏洞。现有的健壮的RL方法旨在缓解这些威胁，但它们在处理出分布变化时的有效性有限，因为它们主要是针对固定扰动设计的。为了解决这一局限，本文提出了一种抗脆弱的RL框架，通过引入基于折扣Thompson采样（DTS）的切换机制提高了对更广泛分布变化的适应性。该机制动态选择多个稳健策略，以最小化由对抗攻击引起的可行动作价值分布变化。该方法首先通过考虑策略空间中的各种扰动，生成一组多样化的健稳策略。然后，这些策略被建模为一个多臂老虎机（MAB）问题，其中DTS优化地根据非平稳伯努利奖励选择策略，从而适应不断变化的对抗策略。通过优化DTS以最小化所有因分布变化而导致的后悔，结果可以有效地适应前所未见的对抗攻击，从而实现抗脆弱性。广泛的数值仿真验证了在具有多个动态三维障碍物的复杂导航环境中，所提出的框架在更强的投影梯度下降（PGD）和欺骗性攻击下具有有效性。与传统健稳且非适应性RL方法相比，抗脆弱方法在导航路径长度和无冲突导航轨迹生成率方面表现更优。

Innovation: 
该研究提出了一种基于折扣Thompson采样的抗脆弱RL框架，这一框架通过动态选择多个稳健策略，有效应对出分布变化和非平稳的对抗攻击。该方法解决了现有健稳RL方法主要针对固定扰动的问题，提供了对更广泛范围的分布变化的适应能力。

Conclusion: 
实验证明了该抗脆弱RL框架的有效性，特别是在对抗环境下的复杂导航任务中，与传统的健稳RL方法相比，该方法能够更高效地生成无冲突的导航路径，提供更短的路径长度和更高的成功率。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21127</guid><pubDate>Fri, 27 Jun 2025 02:28:59 +0800</pubDate></item><item><title>648. cs.AI-大型语言模型在专业会计师考试中的表现</title><link>https://arxiv.org/pdf/2506.21031</link><description>Background: 
先进的人工智能系统，尤其是大型语言模型（LLMs），正在通过自然语言处理（NLP）的进步重塑金融实践。然而，这些模型在有效捕捉和应用特定领域的金融知识方面的表现还不确定。鉴于庞大的印度金融背景，本文通过引入CA-Ben基准测试来填补这种关键差距。CA-Ben评估了LLMs在财务、法律和定量推理方面的能力，包括来自印度会计师协会（ICAI）的各种阶段的结构化问答数据集。

Innovation: 
本文通过开发名为CA-Ben的专业会计师基准测试，首次系统性评估了多个LLMs在财务、法律和定量推理方面的具体能力，涵盖了从基础知识到高级课程的不同教育水平，并使用标准化协议对六种主要的LLMs进行了评估。研究揭示了LLMs在概念和法律推理方面表现突出，但在数值计算和法律解释方面面临挑战，这表明LLMs当前的优势和限制，也指出了改进的方向。

Conclusion: 
研究结果强调了当前LLMs的优势和局限性，建议通过混合推理和检索增强生成方法来提高LLMs的定量分析能力和精准的法律解释能力。未来的研究可以考虑结合这些提出的方法，进一步改进LLMs在金融领域的应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21031</guid><pubDate>Fri, 27 Jun 2025 02:28:58 +0800</pubDate></item><item><title>649. cs.AI-基于Transformer的空间时序反事实结果估计</title><link>https://arxiv.org/pdf/2506.21154</link><description>Background: 
现实世界自然具有时间和空间维度，因此具有时空属性的反事实结果估计是一个重要的问题。然而，以往的方法基于古典统计模型，仍然存在性能和泛化能力的局限性。传统的统计模型难以有效捕捉复杂的时间空间依赖关系和非线性关系，导致预测能力有限。

Innovation: 
本文提出了一种新的框架，利用Transformer进行具有时空属性的反事实结果估计，展现出更强的估计能力。在温和的假设下，该框架中的提出估计器是一致的，并且渐近正态。利用此框架，不仅能克服传统方法的局限性，还可以更准确地估计反事实结果，尤其适用于复杂的时间空间关系场景。

Conclusion: 
通过模拟实验和真实数据实验，验证了该方法的有效性。模拟实验结果表明，该估计器比基准方法具有更强的估计能力。真实数据实验则具体分析了冲突对哥伦比亚森林损失因果效应的影响，证明了实际应用中的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21154</guid><pubDate>Fri, 27 Jun 2025 02:28:58 +0800</pubDate></item><item><title>650. cs.AI-IPFormer-VideoLLM: 提升多模态多景别视频理解</title><link>https://arxiv.org/pdf/2506.21116</link><description>Background: 
视频大规模语言模型（VideoLLMs）展示了出色的理解能力，但在处理多景别场景（例如不同摄像角度或场景切换的视频片段）方面表现不佳，这可能导致实例身份遗忘和关键帧忽略等问题。现有的数据集缺乏多景别的标注，是促成这一困难的主要原因。

Innovation: 
该研究引入了一个名为 MultiClip-Bench 的新数据集，该数据集包含密集描述和基于指令的问题-答案配对，专门设计用于处理多景别场景。通过这种数据集，模型的多景别性能显著提升。此外，提出了 IPFormer-VideoLLM 模型，该模型通过高效的基于注意力的连接器注入实例级特征作为实例提示，以便在场景中聚合实例特定信息。实验结果证明，该模型不仅提高了多场景视频理解能力，还为多种视频基准测试提供了优势。

Conclusion: 
研究提出的新数据集和模型显著增强了多场景视频理解能力，并且在多种视频基准测试中表现出显著优势。通过集成实例级特征，模型能够在多场景中更准确地理解和处理视频内容。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21116</guid><pubDate>Fri, 27 Jun 2025 02:28:49 +0800</pubDate></item><item><title>651. cs.AI-FeDa4Fair：用于公平性评估的客户端级联邦数据集</title><link>https://arxiv.org/pdf/2506.21095</link><description>Background: 
联邦学习（FL）允许跨多个客户端进行协作模型训练，而不共享客户端的私人数据。然而，公平性仍然是一个关键问题，因为客户端本地数据集中的偏差会影响整个联邦系统。客户端之间数据分布的异质性可能导致模型对某些客户端更公平，而对其他客户端则不然。尽管文献中存在多种提高公平性的解决方案，但大多数都集中在减少单一敏感属性上的偏见，通常是二元的，忽视了不同客户端多样且有时相互冲突的公平性需求。这种有限的视角限制了公平性干预措施对不同客户端的有效性。为了在联邦学习中支持更稳健和可重现的公平性研究，我们旨在为公平意识的联邦学习方法提供在全局和客户端层面一致的基准测试能力。因此，本文从三个方面进行了贡献：（1）我们引入了FeDa4Fair库，用于生成适合评估异质客户端偏差下公平联邦学习方法的表格数据集；（2）我们发布了四个异质偏差数据集及其相应的基准测试，在受控环境中比较公平性缓解方法；（3）我们提供了用于评估这些数据集公平结果的现成函数。

Innovation: 
本文贡献了FeDa4Fair库，该库能够生成特定于评估异质客户端偏差下公平性联邦学习方法的表格数据集；发布了四个异质偏差数据集及其基准测试，在受控环境中比较公平性缓解方法；提供了评估这些数据集公平结果的现成函数，旨在为公平意识的联邦学习方法提供全局和客户端层面的一致基准测试。

Conclusion: 
本文通过引入FeDa4Fair库、发布异质偏差数据集及其基准测试以及提供评估函数，为公平意识的联邦学习方法提供了一致的基准测试能力，旨在支持在联邦学习中更稳健和可重现的公平性研究。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21095</guid><pubDate>Fri, 27 Jun 2025 02:28:48 +0800</pubDate></item><item><title>652. cs.AI-PhishKey: 一种用于增强式钓鱼检测的新型质心基于方法，结合自适应HTML组件提取</title><link>https://arxiv.org/pdf/2506.21106</link><description>Background: 
钓鱼攻击是重大的网络安全威胁，它们不断演变以规避检测机制并利用人类脆弱性。现有技术在适应性、稳健性和效率方面面临挑战，亟需改进的钓鱼检测方法来应对这些挑战。

Innovation: 
PhishKey 是一种创新的钓鱼检测方法，结合了字符级处理和卷积神经网络（CNN）的 URL 分类，以及基于质心的关键词组件钓鱼提取器（CAPE），用于 HTML 内容的词级处理。CAPE 通过减少噪声避免在输入数据上进行裁剪操作，确保样本处理的完整性。预测结果通过软投票集成，以实现更准确可靠的分类。实际上，PhishKey 在四个先进的数据集上的实验评估证明了其有效性，最高 F1 分数达到 98.70%，且对注入攻击等对抗性操作具有强大的抵抗力，性能下降最小。

Conclusion: 
PhishKey 通过结合质心基于的关键词组件提取和卷积神经网络特征提取方法，提供了更准确的钓鱼内容检测，能够有效应对注入攻击等对抗性干扰，展示了其在钓鱼检测领域的优越性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21106</guid><pubDate>Fri, 27 Jun 2025 02:28:47 +0800</pubDate></item><item><title>653. cs.AI-V2X-REALM：基于视觉-语言模型的自适应长尾建模的稳健端到端协同自动驾驶</title><link>https://arxiv.org/pdf/2506.21041</link><description>Background: 
在城市环境下确保自动驾驶系统在罕见、多样且视觉退化的长尾场景中进行稳健的规划和决策仍然是一项基本挑战。在协同环境中，车辆和基础设施需要共同感知和推理，使这一挑战更加关键。现有的基础模型无法有效处理这些极端和罕见的情况，尤其在复杂、多变的驾驶环境中的表现有待提高。

Innovation: 
V2X-REALM 引入了三项核心创新：(i) 一种基于提示的长尾场景生成和评估流水线，利用基础模型合成现实的长尾条件（如雪、雾）；(ii) 一个具有门控多场景自适应注意力模块，在视觉流中使用场景先验来调整模棱两可或损坏的特征；(iii) 一个多任务场景感知对比学习目标，提高了跨场景特征的区分性，并优化了模态对齐，从而提高了基于多模态的推理能力。

Conclusion: 
大量的实验表明，V2X-REALM 在各类复杂驾驶条件下的鲁棒性、语义推理能力、安全性及规划准确性方面显著优于现有基础模型，推动了端到端协同自动驾驶系统的广泛应用和普及。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21041</guid><pubDate>Fri, 27 Jun 2025 02:28:45 +0800</pubDate></item><item><title>654. cs.AI-CovDocker: 使用任务、数据集和解决方案评估共价药物设计</title><link>https://arxiv.org/pdf/2506.21085</link><description>Background: 
分子对接在预测配体与靶标蛋白结合模式方面起着重要作用，而共价相互作用因其强且持久的结合特性而尤为重要。然而，现有的大多数对接方法和深度学习方法并未考虑共价键的形成及其相关结构变化。因此，需要一个全面的基准测试来克服这一局限性，以更好地捕捉共价结合的复杂性。CovDocker 是一个专门为此目的设计的基准测试，它将共价对接过程分解为反应位置预测、共价反应预测和共价对接三大任务，以验证预测和建模共价结合分子变化的有效性。

Innovation: 
该研究引入了一个全面的共价对接基准测试 CovDocker，它将共价对接过程分解为三个主要任务：反应位置预测、共价反应预测和共价对接。通过使用当前最先进的模型如 Uni-Mol 和 Chemformer，它建立了基准线性能，并展示了基准测试在准确预测相互作用位点和建模共价结合过程中涉及的分子变化方面的作用。这证实了基准测试作为推动共价药物设计研究的严格框架的作用，强调了基于数据的方法加速选择性共价抑制剂发现的潜力，并解决了药物开发过程中的关键挑战。

Conclusion: 
CovDocker 作为评价共价药物设计的有效工具，通过任务分解和数据集的利用，展示了最先进的模型在共价相互作用和结构变化预测方面的有效性。这一框架为共价药物设计的进步提供了严格的框架，并且证实了基于数据的方法在加速发现具有选择性的共价抑制剂方面的潜力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21085</guid><pubDate>Fri, 27 Jun 2025 02:28:45 +0800</pubDate></item><item><title>655. cs.AI-ComRAG：基于动态向量存储的检索增强生成在工业社区问答中的实时应用</title><link>https://arxiv.org/pdf/2506.21098</link><description>Background: 
社区问答（CQA）平台在社区中可以被视为重要的知识库，但在实时有效利用历史互动和领域知识方面仍面临挑战。现有方法往往未能充分利用外部知识，无法整合动态的过往问答历史上下文，或缺乏适合工业部署的记忆机制。

Innovation: 
提出了一种名为ComRAG的检索增强生成框架，用于解决工业CQA平台的实时问题。ComRAG通过中心点为基础的记忆机制，结合静态知识和动态的历史问答对，实现了检索、生成和高效的存储。ComRAG在三个工业CQA数据集上的评估结果显示，其表现优于所有基础方法，提高了向量相似度高达25.9%，降低了延迟8.7%-23.3%，并在迭代过程中将块增长从20.23%降低到2.06%。

Conclusion: 
ComRAG在工业CQA领域实现了显著改进，提供了一种有效的实时问答解决方案，解决了历史互动和领域知识的有效利用难题。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21098</guid><pubDate>Fri, 27 Jun 2025 02:28:44 +0800</pubDate></item><item><title>656. cs.AI-通过指导和调度提高基于扩散的图像编辑保真度</title><link>https://arxiv.org/pdf/2506.21045</link><description>Background: 
文本指导的扩散模型已成为高质量图像合成的关键工具，能够实现动态图像编辑。图像编辑中至关重要的两个方面是可编辑性和保真度。可编辑性决定了修改的程度，而保真度反映了未修改元素的保留程度。然而，在保持保真度和可编辑性的平衡时会遇到挑战，因为这两种需求存在固有的权衡关系。因此，论文提出了Faithfulness Guidance and Scheduling（FGS），该方法增强了保真度同时对可编辑性的影响最小。FGS通过引入保真度指导来增强输入图像信息的保留，并采用调度策略解决可编辑性和保真度之间的错位问题。实验结果表明，FGS在保持可编辑性的同时实现了更高的保真度，并且适用于各种编辑方法，使其在多个任务中能够实现精细且高质量的图像编辑。

Innovation: 
提出了Faithfulness Guidance and Scheduling (FGS)，这是一种结合保真度指导和调度策略的方法。FGS增强了输入图像信息的保留，同时通过调度策略解决了可编辑性和保真度之间的错位问题。这种方法能够在提高保真度的同时保持图像编辑的可操作性。FGS还具有兼容性，适用于多种编辑方法，能够实现跨多种任务的高质量图像编辑。

Conclusion: 
实验结果表明，FGS在保持可编辑性的同时实现了优越的保真度效果。此外，FGS的兼容性使其能够应用于各种图像编辑任务，实现精准且高质量的图像编辑。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21045</guid><pubDate>Fri, 27 Jun 2025 02:28:44 +0800</pubDate></item><item><title>657. cs.AI-多模态提示对齐在面部表情识别中的应用</title><link>https://arxiv.org/pdf/2506.21017</link><description>Background: 
提示学习被广泛应用于高效地适配像CLIP这样的视觉语言模型（VLMs）以处理各种下游任务。尽管这类方法取得了成功，但基于VLM的面部表情识别（FER）方法难以捕捉细粒度的文本-视觉关系，这对区分面部表情的细微差异非常重要。

Innovation: 
本文提出了一种新的多模态提示对齐框架（MPA-FER），该框架通过将大型语言模型（如ChatGPT）生成的详细描述注入软提示来提供对提示视觉特征学习过程的精细语义指导，从而实现更精确和可解释的表示。具体地，本文提出了一种多粒度硬提示生成策略，结合了基于CLIP模型的预训练实现，通过最小化软提示和硬提示的特征差异，进一步注入外部知识。此外，本文还提出了一种跨模态全局-局部对齐模块，强调面部表情相关的特征，进一步提高了文本和视觉特征之间的对齐。

Conclusion: 
广泛的实验表明，本文提出的框架在三种面部表情识别基准数据集上优于现有技术，同时保留了预训练模型的优点，并将计算成本降到最低。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21017</guid><pubDate>Fri, 27 Jun 2025 02:28:43 +0800</pubDate></item><item><title>658. cs.AI-基于后悔感知优化的有效技能发现</title><link>https://arxiv.org/pdf/2506.21044</link><description>Background: 
无监督技能发现的目标是在开放性强化学习中学习多样且易于区分的行为。现有方法主要通过纯粹探索、互信息优化和学习时间表示来改进多样性。虽然这些方法在探索方面表现良好，但在效率方面仍然有限，尤其是在高维情况下的表现更为受限。

Innovation: 
本文将技能发现框架为技能生成和策略学习的最小-最大博弈，提出了一个基于时间表示学习的风险感知方法，其在提升策略强度的方向上扩展了发现的技能空间。创新点在于发现技能与策略学习是相抗衡的过程，即弱技能应进一步探索，而收敛技能的探索应减少。通过计算收敛的后悔值来指导技能发现，并采用可学习的技能生成器。为避免退化，技能生成来自可升级的技能生成器群体。

Conclusion: 
实验结果表明，我们的方法在效率和多样性方面都优于基准方法。此外，我们的方法在高维环境中的零样本改进达到了15%，超过了现有方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21044</guid><pubDate>Fri, 27 Jun 2025 02:28:40 +0800</pubDate></item><item><title>659. cs.AI-Strict Subgoal Execution: 受失败意识驱动的图基强化学习中的可靠长时序规划</title><link>https://arxiv.org/pdf/2506.21039</link><description>Background: 
长时序目标条件任务对强化学习（RL）提出了根本性的挑战，尤其是在目标遥远且奖励稀疏的情况下。虽然层次化和图基方法提供了一部分解决方案，但它们常常遭受子目标不可达和Planning效率低下的问题。

Innovation: 
我们提出了严格子目标执行（SSE），这是一种图基的层次化RL框架，通过结构上限制高层决策来确保单步子目标可达性。为了增强探索，SSE使用解耦的探索策略，系统地探索目标空间中未充分探索的区域。此外，SSE采用一种基于失败的路径细化方法，通过动态调整边权重来改进图基规划，从而提高子目标的可靠性。实验结果显示，SSE在多样化的长时序基准测试中，无论是在效率还是成功率方面，都优于现有的目标条件强化学习和层次化强化学习方法。

Conclusion: 
实验结果表明，SSE在效率和成功率方面一致优于现有的目标条件强化学习和层次化强化学习方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21039</guid><pubDate>Fri, 27 Jun 2025 02:28:35 +0800</pubDate></item><item><title>660. cs.AI-电子商务查询分类的半监督可扩展统一框架</title><link>https://arxiv.org/pdf/2506.21049</link><description>Background: 
电子商务查询分类对于电商应用至关重要。电商查询通常很简短且缺乏上下文，无法充分利用标签间的信息，导致建模时缺乏足够的先验信息。现有大多数工业化的查询分类方法依赖于用户的后续点击行为来构建训练样本，这导致了马修效应的恶性循环。此外，查询分类任务缺乏统一框架，导致算法优化效率较低。

Innovation: 
提出了一种新颖的半监督可扩展统一框架（SSUF），包含多个增强模块来统一查询分类任务。知识增强模块利用世界知识增强查询表示，解决了信息不足的问题。标签增强模块利用标签语义和半监督信号，减少了对后续标签的依赖。结构增强模块基于复杂的标签关系增强标签表示。每个模块具有高度可插拔性，可根据每个子任务的需要添加或移除输入特征。进行全面的离线和在线A/B实验，结果显示SSUF显著优于最先进的模型。

Conclusion: 
实验证明，SSUF在电子商务查询分类中表现出色，显著优于当前最先进的模型。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21049</guid><pubDate>Fri, 27 Jun 2025 02:28:35 +0800</pubDate></item><item><title>661. cs.AI-EgoAdapt: 自适应多模态蒸馏与策略学习以实现高效第一人称感知</title><link>https://arxiv.org/pdf/2506.21080</link><description>Background: 
现代感知模型，特别是一些为执行多感知第一人称任务而设计的模型，虽然在性能上取得了显著的进步，但在计算成本方面也面临巨大挑战。过高的计算需求导致了这些模型难以在资源受限的环境中进行实际部署，尤其是在资源有限的场景下.

Innovation: 
我们提出了一种名为EgoAdapt的框架，该框架能够自适应地执行跨模态蒸馏和策略学习，使模型能够在不同第一人称感知任务中高效地进行推理，这些任务包括第一人称动作识别、主动讲话者定位和行为预测。我们提出的策略模块可以适应特定任务的动作空间，具有广泛应用的潜力.

Conclusion: 
我们在三个具有挑战性的第一人称感知数据集EPIC-Kitchens, EasyCom和Aria Everyday Activities上进行了实验，结果显示我们的方法显著提高了效率，最高减少89.09%的GMACs，82.02%的参数，并最多减少9.6倍的能量消耗，同时仍然与最先进的模型性能相当，甚至在某些情况下超过了它们的性能.&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21080</guid><pubDate>Fri, 27 Jun 2025 02:28:35 +0800</pubDate></item><item><title>662. cs.AI-SAC：一种用于测量和诱导具有动态强度控制的LLMs个性特征的框架</title><link>https://arxiv.org/pdf/2506.20993</link><description>Background: 
近年来，大规模语言模型（LLMs）在多个领域得到了广泛应用，人们对LLMs在交互中表现出类似人类个性的期望也在增加。大多数现有模型依赖于Big Five（OCEAN）框架，该框架只能提供粗略的个性维度，且缺乏控制特质强度的机制。因此，本文通过扩展Machine Personality Inventory (MPI)，引入16 Personality Factor (16PF)模犁，允许对十六个不同的个性特质进行表达控制。此外，还开发了一种结构化的框架，称为具体属性控制（SAC），用于评估和动态诱导LLMs的特质强度。SAC框架利用了行为性问题，涵盖了五个强度因子：频率、深度、阈值、努力和意愿，通过实验证明，将特质强度建模为连续谱相较于二元特质切换，可以实现更一致和可控制的个性表达，并且发现目标特质强度的变化系统地影响相关特质，表明LLMs在多维度个性结构中进行内部化处理，而非孤立处理个性特质。这项工作为医疗健康、教育和面试等领域的人机互动提供了新的可控细微的方法，使我们更接近真正的人类社会机器人。

Innovation: 
本文创新提出了具体属性控制（SAC）框架，扩展了原始的Machine Personality Inventory（MPI），增加了16PF模型的支持，从而能够对个性特征进行更细致的控制。同时，SAC框架还通过行为性问题和五个强度因子来动态诱导特质强度，将特质强度建模为连续体，证明了与二元切换相比，连续体建模可以实现更一致和可控制的个性表达，并且系统地影响相关信息性特质。

Conclusion: 
本文提出了SAC框架，该框架通过在LLMs中引入动态强度控制的能力，使得个性特征的表达更加一致和可控，开创了在各种领域中实现人机互动的新途径，特别是医疗健康、教育和面试等领域，为实现真正的人类社会机器人迈进了一步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20993</guid><pubDate>Fri, 27 Jun 2025 02:28:34 +0800</pubDate></item><item><title>663. cs.AI-VLA模型后训练与人类运动学习之间的类比：进展、挑战与趋势</title><link>https://arxiv.org/pdf/2506.20966</link><description>Background: 
Vision-language-action（VLA）模型通过集成动作生成模块扩展了视觉-语言模型（VLM），用于机器人操作。尽管VLA模型在视觉感知和指令理解方面表现出色，适用于多种操作任务，但在需要高精度和高准确性的应用中仍存在性能差距。因此，后训练策略作为使基础模型与下游应用对接的关键方法受到了广泛关注，特别是在VLA模型中。通过类比人类运动技能的学习，本文从环境、实体和任务三个维度审视VLA模型的后训练策略，为后续研究提供了概念框架和实用建议。

Innovation: 
本文通过人类运动学习的视角，对VLA模型的后训练策略进行了系统性概述，提出了四种增强学习机制：（1）增强环境感知，（2）提高实体意识，（3）加深任务理解，（4）多组件集成。这种类比方法为VLA模型的设计和优化提供了新的思路和方法。

Conclusion: 
本文不仅提供了从人类运动学习视角对当前VLA模型后训练方法的全面综述，还提出了实用见解，指导未来的VLA模型开发。此外，本文还识别了后训练VLA模型的关键挑战和未来趋势，为该领域的进一步研究奠定了基础。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20966</guid><pubDate>Fri, 27 Jun 2025 02:28:30 +0800</pubDate></item><item><title>664. cs.AI-增强同质性-异质性分离：关系感知的异质图学习</title><link>https://arxiv.org/pdf/2506.20980</link><description>Background: 
真实世界网络通常具有节点异质性特性，即通常连接的节点具有不同的特征或标签。尽管这个问题在同质图中得到了广泛研究，但在含有多种节点和边的异质图中仍相对较少涉及。异质图中捕捉节点异质性极具挑战，必须同时考虑节点/边异质性和节点异质性。现有方法通常将异质图转化为同质图来学习节点异质性，但这种方式不可避免地失去了异质关系传达的潜在异质性。

Innovation: 
本文提出了Relation-Aware Separation of Homophily and Heterophily (RASH)框架，这是一种新的对比学习方法，明确建模了高阶异质交互语义，并适应性地分离同质模式和异质模式。特别地，通过引入双重异质超图来编码多关系双部子图，并基于关系的重要性动态构建同质图和异质图。设计了多关系对比损失来通过最大化互信息对齐异质性和同质/异质视图。这样一来，RASH同时解决了异质图中的异质性和异质性挑战。

Conclusion: 
在基准数据集上进行的大量实验表明，RASH在各种下游任务中有效地解决了异质性和异质性问题。完整的代码可以在该网址找到：this https URL&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20980</guid><pubDate>Fri, 27 Jun 2025 02:28:26 +0800</pubDate></item><item><title>665. cs.AI-使用自然语言在病理图像中分割任何内容</title><link>https://arxiv.org/pdf/2506.20988</link><description>Background: 
病理图像分割对于计算病理学中癌症诊断和预后的组织学特征分析至关重要，但当前方法在临床应用中面临重大挑战，主要是因为注解数据有限和类别定义受限。

Innovation: 
本文提出了PathSegmentor，这是首款专门针对病理图像的带有文本提示的分割基础模型。同时介绍了PathSeg，这是最大的、最全面的病理分割数据集，来源于17个公开来源，包含275k张图像-掩码-标签三元组，覆盖160个不同类别。通过PathSegmentor，用户可以使用自然语言提示进行语义分割，无需烦琐的空间输入，如点或箱。实验表明PathSegmentor在总体Dice分数上比专门模型更准确且适用范围更广，结构更加紧凑，显著超越了现有空间提示和文本提示模型。此外，PathSegmentor的输出增加了诊断模型的可解释性，有助于病理学家利用影像生物标志物进行临床决策，进一步推进了精准 oncology中的可解释AI的发展。

Conclusion: 
PathSegmentor显著提高了病理图像分割的准确性和适用范围，尤其适用于复杂结构的分割，实现了一系列新的应用，并通过影像生物标志物的发现增强了诊断模型的可解释性，为临床决策提供了证据支持。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20988</guid><pubDate>Fri, 27 Jun 2025 02:28:26 +0800</pubDate></item><item><title>666. cs.AI-从婴儿车到拐杖：一种用于高保真全生命周期面部老化的一阶段框架</title><link>https://arxiv.org/pdf/2506.20977</link><description>Background: 
面部老化是计算机视觉中的一个关键任务，应用范围从娱乐到医疗健康。但现有的方法在实现整个生命周期内逼真且自然过渡时遇到困难，特别是在处理大型年龄差距或极端头部姿势时。核心挑战在于平衡年龄准确性与身份保持，即所谓的年龄-身份trade-off。大多数现有的方法在年龄转换与身份一致性之间优先其一，此工作通过提出一种基于文本到图像扩散模型的两阶段面部老化框架——Cradle2Cane来解决这个问题。第一阶段聚焦于提升年龄准确性，通过引入自适应噪声注入机制，该机制由给定人的年龄和性别描述的提示条件引导。第二阶段通过结合两种身份感知嵌入（IDEmb），即SVR-ArcFace和Rotate-CLIP，增强了身份保持，同时保留了年龄特定特征。两个阶段以端到端的方式进行联合训练。通过在CelebA-HQ测试数据集上的广泛实验并使用Face++和Qwen-VL协议进行评估，证明了Cradle2Cane在年龄准确性与身份一致性方面优于现有方法。

Innovation: 
提出了名为Cradle2Cane的两阶段面部老化框架，基于文本到图像扩散模型的两步法解决年龄准确性与身份一致性之间的trade-off问题。通过自适应噪声注入机制优化年龄准确性，结合两种身份感知嵌入（IDEmb）增强身份保持的同时保留年龄特征。

Conclusion: 
实验结果显示，Cradle2Cane在年龄准确性和身份一致性方面优于现有方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20977</guid><pubDate>Fri, 27 Jun 2025 02:28:24 +0800</pubDate></item><item><title>667. cs.AI-可解释的加性规则集表示学习</title><link>https://arxiv.org/pdf/2506.20927</link><description>Background: 
传统上，加性规则集使用基于单个输入变量和阈值简单阈值命题的几何轴平行多面体作为决策区域的形式。虽然这种形式保证了个体规则的高度可解释性，并且可以使用梯度提升方法高效地学习，但它依赖于拥有一个经过精炼且理想独立的输入特征的集合，以便一个小的轴平行区域集合能够很好地描述目标变量。缺乏这样的特征时，为了达到足够的准确性，需要增加个体规则的数量和复杂性，这会降低模型的可解释性。

Innovation: 
本文扩展了经典的规则集，通过引入用可学习的稀疏线性变换输入变量的逻辑语句，即形式为 $boldsymbol{x}^{top}boldsymbol{w} boldsymbol{≥} t$ 的命题，使决策区域能够成为一般多面体，具有斜面。提出了一种基于迭代加权化逻辑回归的递增贪婪优化学习方法。实验结果表明，所提方法能够有效地构建具有与最先进的方法相同测试风险的规则集，同时显著降低模型复杂性，适用于十个基准数据集。

Conclusion: 
通过引入可学习的稀疏线性变换，本文提出了一种新的方法，能够构建高效的可解释规则集模型，减少模型复杂性，同时保持与最先进的方法相同的测试风险。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20927</guid><pubDate>Fri, 27 Jun 2025 02:28:23 +0800</pubDate></item><item><title>668. cs.AI-基于多智能体副机的证据驱动诊断推理在人类病理学中的应用</title><link>https://arxiv.org/pdf/2506.20964</link><description>Background: 
病理学正经历由全切片成像和人工智能（AI）推动的快速数字化转型。虽然基于深度学习的计算病理学取得了显着成果，但传统模型主要专注于图像分析，而不整合自然语言指令或丰富的文本背景信息。当前用于计算病理学的多模态大型语言模型存在局限性，包括训练数据不足，对多图像理解的不足支持与评估，以及缺乏自主诊断推理的能力。

Innovation: 
本文介绍了一种新的多模态大型语言模型PathChat+，用于处理人类病理学问题。PathChat+专门针对病理学训练，并使用超过一百万的病理特异性指令样本及近五百万轮问题解答对模型进行训练。经过跨多种病理学基准的广泛评估，PathChat+明显优于之前的PathChat副机，以及其他最先进的通用和特定于病理学的模型。此外，我们提出了SlideSeek，这是一种具备推理功能的多智能体AI系统，利用PathChat+对吉赫像素级全切片成像（WSI）进行迭代、分层诊断推理评估，能够在复杂的开放性鉴别诊断基准DDxBench上达到高准确性，同时能够生成视觉基础且可由人类理解的总结报告。

Conclusion: 
PathChat+显著提升了计算病理学中的自然语言处理能力，实现了从图像分析到整合自然语言和丰富文本信息的重大飞跃。SlideSeek则展示了从辅助到自主的诊断推理能力，实现高级自动化的病理学回顾和诊断过程。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20964</guid><pubDate>Fri, 27 Jun 2025 02:28:23 +0800</pubDate></item><item><title>669. cs.AI-利用训练后视角优化语言模型以适应下游任务</title><link>https://arxiv.org/pdf/2506.20917</link><description>Background: 
语言模型（LMs）在自然语言处理（NLP）中展现出了令人惊叹的能力，但它们高效且稳健地适应特定任务仍然具有挑战性。随着模型规模和复杂性的增加，直接在标记数据上调整LMs经常未充分利用可用的非标记数据，容易在小规模、特定任务的数据集上过拟合，并且会带来巨大的计算成本。这些限制妨碍了LMs在现实世界语言任务广泛场景中的应用。

Innovation: 
本论文提出了一系列方法以更好地适应LMs应用于下游任务。首先，我们探索了从非标记数据中提取任务相关信息的新策略，引入了一种新的持续预训练技术，该技术在半监督领域中取得了比现有最佳方法更好的表现。其次，我们提出了一种参数高效的调整方法，大幅减少了内存和计算成本，同时保持竞争力。同时，引入了改进的监督调整方法，即使标记数据稀缺，也能使LMs更好地遵循指令，从而在多种NLP任务中提高表现。最后，我们开发了新的评估方法和基准，如多跳空间推理任务，以更全面地评估LMs的能力和适应性。

Conclusion: 
通过跨多种NLP任务的广泛实验，我们的结果表明这些方法显著提高了LMs的稳健性、效率和泛化能力，使它们在更广泛的场景中更具适应性。这些进步标志着在更稳健和高效的LMs方向上迈出了重要一步，带我们更接近人工通用智能（AGI）的目标。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20917</guid><pubDate>Fri, 27 Jun 2025 02:28:23 +0800</pubDate></item><item><title>670. cs.AI-DFVEdit: 条件梯度流向量用于零样本视频编辑</title><link>https://arxiv.org/pdf/2506.20967</link><description>Background: 
视频扩散变换器（Video Diffusion Transformers, Video DiTs）的出现标志着视频生成的里程碑。然而，将现有的视频编辑方法直接应用于Video DiTs往往会导致巨大的计算开销，这主要是由于密集注意力修改或微调带来的资源消耗问题。为了解决这一问题，本文提出了DFVEdit，这是一种针对Video DiTs设计的高效零样本视频编辑方法。DFVEdit通过直接在纯净的潜在变量上进行流变换，消除了注意力修改和微调的需求，从而提高了编辑效率和效果。

Innovation: 
本文提出了一种名为Conditional Delta Flow Vector (CDFV) 的方法，该方法是在连续流视角下对DFV进行无偏估计。CDFV通过集成隐式交叉注意力（ICA）指导和嵌入强化（ER）技术，进一步提高了编辑质量。DFVEdit在Video DiTs上的推断速度提升了至少20倍，并且内存减少了85%。相较于基于工程注意力的方法，DFVEdit在结构保真度、时空一致性以及编辑质量方面表现出了最佳性能。

Conclusion: 
广泛的定量和定性实验表明，DFVEdit能够无缝应用于流行的Video DiTs（例如CogVideoX和Wan2.1），并达到了最佳的编辑效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20967</guid><pubDate>Fri, 27 Jun 2025 02:28:23 +0800</pubDate></item><item><title>671. cs.AI-多智能体引导的大型语言模型在化学工艺优化中的应用</title><link>https://arxiv.org/pdf/2506.20921</link><description>Background: 
最大化生产效率和经济效益需要对化学工艺进行优化，但传统方法如梯度求解器、进化算法和参数网格搜索，在操作约束不明确或不可用的情况下变得不实际，工程师们需要依赖主观直觉来估算可行参数范围。为此，本文提出了一种多智能体框架，该框架利用大型语言模型（LLM）代理自主推断操作约束，然后利用这些推断的约束进行协作优化，解决了操作约束定义的瓶颈问题。

Innovation: 
本文提出了一种基于AutoGen的多智能体框架，使用OpenAI的o3模型，并专门设计了约束生成、参数验证、仿真执行和优化指导的智能代理。该框架通过两个阶段——自主约束生成和迭代多智能体优化，避免了预定义的操作边界。这种方法验证了在成本、产量和收益-成本比方面的性能，并且在计算效率方面优于传统方法，收敛速度更快，且对复杂工艺的理解更精细。

Conclusion: 
该方法为操作约束不明确或不可用的优化场景提供了显著的潜力，特别是在新兴工艺和改造应用中。通过验证试验，本方法实现了更快的计算效率和更好的性能，展示出了对工艺过程的深入理解，并正确识别了能源贸易惩罚和领域启发式策略的应用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20921</guid><pubDate>Fri, 27 Jun 2025 02:28:22 +0800</pubDate></item><item><title>672. cs.AI-Omniwise：使用LLMs预测GPU内核性能</title><link>https://arxiv.org/pdf/2506.20886</link><description>Background: 
近年来，深度神经网络（DNNs）的快速进步彻底改变了人工智能，使得模型在理解和生成复杂数据方面具备了前所未有的能力。强大的架构已将各种下游应用的范围扩大，解决了一些超越人类能力的任务。本文介绍了Omniwise，这是第一个端到端的自我监督微调管道，利用大规模语言模型（LLMs）进行GPU内核性能预测——这是一个在性能分析中前所未有的用途。

Innovation: 
Omniwise 是一个模型通用且轻量级的库，即使使用只有3B参数的小模型也能取得出色的预测结果。它可以直接从内核代码预测关键性能指标，包括内存带宽、缓存命中率、GFLOPs和算术强度，无需执行代码或使用性能分析工具。我们的方法在AMD MI250和MI300X架构上执行的GPU内核中，超过90%的预测结果的相对误差低于10%。此外，我们还开发了一个在线推理服务器和一个Visual Studio Code插件，使基于LLM的性能预测能够无缝集成到开发者的流程中。

Conclusion: 
Omniwise为开发者提供了一种新的工具，提高GPU内核性能预测的精度和效率，使得基于LLM的预测能够在软件开发流程中被轻易集成和使用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20886</guid><pubDate>Fri, 27 Jun 2025 02:28:16 +0800</pubDate></item><item><title>673. cs.AI-OmniEval：包含视觉、听觉和文本输入的评估多模态模型基准</title><link>https://arxiv.org/pdf/2506.20960</link><description>Background: 
本文介绍了 OmniEval，一个用于评估像 MiniCPM-O 2.6 这样的全模态模型的基准，这些模型能够处理视觉、听觉和文本输入。与现有的基准相比，我们的 OmniEval 具有几项独特的优势：1. 全模态协作的设计使模型能够有效利用多种模态的协作感知；2. 包含种类丰富的视频；3. 包含多样且细化的任务设置，评估多个方面的能力。这些优势使得 OmniEval 在评估多模态模型理解多种信息源的能力方面具有明显优势，为后续的研究提供了新的标准和挑战。 OmniEval 包含 810 个视听同步视频，285 个中文视频和 525 个英语视频，以及涉及 1412 个开放问题和 1205 个选择题的 2617 个问题回答对，这些任务分为 3 个主要任务类型和 12 个子任务类型，从而实现全面评估。特别地，引入了更加细化的视频定位任务——Grounding。

Innovation: 
OmniEval 提出了几种独特的评估模态协作感知和多样性视频的新方法。它设计了强调音频与视频强耦合的评估任务，使模型能够有效利用多种模态的协作感知。OmniEval 包含多种复杂的问题设置，评估模型在多种感官输入理解中的性能，特别地引入了 Grounding 这一更加细化的视频定位任务，使评估更加具体和全面。相比现有基准，它提供了更大的多样性，覆盖更多种类的视频和更多的任务类型，为多模态模型评估提供了更丰富的数据和更高的挑战。

Conclusion: 
我们希望 OmniEval 能够成为评估理解和构建来自各个模态的内在一致性的能力的平台。接下来，我们已经在几种多模态模型上进行了实验。OmniEval 提供了代码和数据，研究人员可以在该平台上进行测试和比较，以进一步提升和检验多模态模型在处理多信息源方面的能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20960</guid><pubDate>Fri, 27 Jun 2025 02:28:16 +0800</pubDate></item><item><title>674. cs.AI-使用不确定的人工指导的强化学习进行复杂模型转换</title><link>https://arxiv.org/pdf/2506.20883</link><description>Background: 
模型驱动工程问题常常需要复杂的模型转换（MTs），即通过众多步骤链接在一起的MTs。这样的问题例子包括模型同步、自动修复和设计空间探索等。手动开发复杂的MTs往往是一个错误多发且不实际的过程。这是由于MTs通常涉及大量复杂操作。强化学习（RL）可以有效解决这个问题。然而，RL方法在处理复杂问题时会遇到性能瓶颈。此时，人类的指导可以显著提升。因此，本研究提出了一个通过RL开发复杂MT序列的方法，该方法包含潜在不确定的人类指导。

Innovation: 
该方法将用户定义的MT与RL的基本动作相映射，并执行为RL程序，以找到最优的MT序列。研究证明，即使人类指导是不确定的，也会显著提高RL的性能，并能更高效地开发复杂的MT。通过权衡人类反馈的确定性和及时性，该研究促进了从RL驱动的人在环工程方法的进展

Conclusion: 
该方法展示了如何通过RL找到最优MT序列，并通过不确定的人类指导增强了RL的效果。通过平衡人类指导的确定性和准确性，该方法向前迈进了一步，将RL与人类在环工程相结合，促进工程中的实时决策和优化。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20883</guid><pubDate>Fri, 27 Jun 2025 02:28:13 +0800</pubDate></item><item><title>675. cs.AI-使用几何感知扩散和时间视频模型实现一致的零样本3D纹理合成</title><link>https://arxiv.org/pdf/2506.20946</link><description>Background: 
当前的纹理合成方法通过固定视角生成纹理，但由于缺乏全局上下文和几何理解，会表现出不一致性。最近，视频生成模型在实现时空一致的视频方面取得显著进展。然而，现有的纹理合成方法仍存在局限性，如何在这种局限下提高3D纹理的合成效果成为了一个挑战。

Innovation: 
本论文提出了一种名为VideoTex的新框架，结合视频生成模型和几何感知条件来解决3D纹理中的空间和时间不一致性问题。特别是在利用几何信息进行UV扩散以保持语义信息时，显著提升了遮挡区域的生成效果，从而实现了更平滑和更连贯的纹理。VideoTex不仅能跨越UV边界实现更平滑的过渡，还确保了视频帧之间的高质量和时间稳定性。

Conclusion: 
大量实验表明，VideoTex在纹理保真度、拼缝融合和稳定性方面优于现有方法，为需要视觉质量和时间一致性的动态实时应用打开了新的可能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20946</guid><pubDate>Fri, 27 Jun 2025 02:28:09 +0800</pubDate></item><item><title>676. cs.AI-为实际应用工程化RAG系统：设计、开发与评估</title><link>https://arxiv.org/pdf/2506.20869</link><description>Background: 
检索增强生成（RAG）系统正在成为将大型语言模型（LLMs）与外部知识对接的关键方法，解决事实准确性和上下文相关性方面的局限性。然而，缺乏关于RAG系统实施开发的实证研究，这些研究集中在真实世界的应用场景上，通过一般用户的参与进行评估，并伴有系统化的学习记录。本文介绍了跨治理、网络安全、农业、工业研究和医疗诊断五个领域特定的RAG应用，旨在应对现实世界的需求，并评估了六个方面：（i）易用性、（ii）相关性、（iii）透明度、（iv）响应性、（v）准确性以及（vi）推荐可能性，从而得出用户反馈和开发经验基础上的十二项关键教训，指出在实际中RAG系统的可靠性和可用性所面临的技术和操作性挑战。

Innovation: 
开发了五个针对特定领域的RAG应用，在真实世界场景中使用，每个系统集成了多语言OCR、基于向量嵌入的语义检索，以及领域适应的人工智能模型，通过本地服务器或云API部署，以满足不同用户的需求。通过由100名参与者参与的基于网络的评估，从用户反馈中总结出十二项关键经验教训，这些建议覆盖了技术、操作和伦理挑战，对实际中RAG系统可靠性和可用性的影响进行了分析。

Conclusion: 
基于用户的反馈和开发经验，作者总结了12项关键教训，这些教训强调了技术、操作和伦理方面挑战对RAG系统可靠性和可用性的影响，从而提升了RAG系统的开发和实际应用能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20869</guid><pubDate>Fri, 27 Jun 2025 02:28:06 +0800</pubDate></item><item><title>677. cs.AI-ZKPROV：大型语言模型数据来源的零知识方法</title><link>https://arxiv.org/pdf/2506.20915</link><description>Background: 
随着大型语言模型在敏感领域（如医疗保健）中的部署扩大，确保其计算来源的完整性变得至关重要。特别是在受监管的行业，对数据集使用的严格要求使得确保这些模型的训练来源可信成为一个关键挑战。现有的方法要么集中在整个训练过程的完全验证（这将导致显著的计算成本），要么依赖于受信任的执行环境。而ZKPROV新颖地提供了一种平衡方法，通过零知识证明将训练模型绑定到其授权的数据集，而无需证明每一训练步骤。通过利用数据集签名的元数据和紧凑的模型参数承诺，ZKPROV为实现场景提供了有效且可验证的保证，证明LLM的结果是基于声称的授权和相关数据集训练得出的

Innovation: 
ZKPROV是一种新颖的加密框架，它通过零知识证明实现了大型语言模型来源的完整性验证。ZKPROV方法将经过训练的模型与其授权的数据集进行加密绑定，而无需证明每一步的训练过程。这种方法利用数据集签名的元数据和紧凑的模型参数承诺，确保了结果的可验证性和隐私性。与现有方法相比，ZKPROV提供了更高效的解决方案，并且不会引入显著的计算成本，也不依赖于受信任的执行环境。实验结果表明ZKPROV在生成证明和验证过程中的效率和可扩展性，并证明了这一方法能够保护数据集的隐私并确保可信的数据来源保障

Conclusion: 
实验结果表明ZKPROV能够在高效、可扩展的方案下生成和验证零知识证明，为实际部署提供了切实可行的解决方案。我们还提供了形式化的安全保证，证明了我们的方法能够保护数据集的隐私，并确保可靠的来源保障&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20915</guid><pubDate>Fri, 27 Jun 2025 02:28:06 +0800</pubDate></item><item><title>678. cs.AI-使用多尺度对称图扩散模型进行准确复杂抗原结合的抗体设计与优化</title><link>https://arxiv.org/pdf/2506.20957</link><description>Background: 
抗体设计在治疗性和诊断性开发中仍然是一个关键挑战，尤其是对于具有多种结合界面的复杂抗原。现有的计算方法主要存在两个局限：一是难以保护对称性的同时捕捉几何特征，二是不能很好地推广到新出现的抗原界面。尽管近期有所进展，这些方法往往无法准确捕捉分子间相互作用并保持结构完整性。

Innovation: 
本文提出了一种端到端框架AbMEGD，集成多尺度对称图扩散方法，用于抗体序列和结构的联合设计。该方法利用先进的几何深度学习技术，将原子级几何特征与残基级嵌入结合起来，捕捉局部原子细节和全局序列-结构相互作用。其E(3)-对称扩散方法确保了几何精度、计算效率和对复杂抗原的良好推广能力。实验结果表明，与领先的抗体设计模型DiffAb相比，在关键的CDR-H3区域，该模型实现了氨基酸回收率提高10.13%，改进百分比增加3.32%，并且减少了0.062 Å的根均方偏差。

Conclusion: 
这些结果凸显了AbMEGD在平衡结构完整性和提高功能方面的能力，为序列-结构联合设计和亲和力优化设定了新基准。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20957</guid><pubDate>Fri, 27 Jun 2025 02:28:05 +0800</pubDate></item><item><title>679. cs.AI-利用视觉语言模型选择由扩散模型生成的可信超分辨率样本</title><link>https://arxiv.org/pdf/2506.20832</link><description>Background: 
超分辨率(SR)是一个逆问题，具有许多与给定低分辨率图像一致的解。传统的回归SR模型通过平衡保真度和感知质量来产生单一解，但这种方法常常引入了可能导致关键应用中信息混淆的伪影。另一方面，扩散模型能够生成多样的SR图像，但从中选择最可信赖的解仍然具有挑战性。本研究利用视觉语言模型(VLMs)的语义推理能力，自动识别由扩散模型生成的一组SR图像中最可信的样本，并通过一个结合语义相似性、结构完整性和伪影敏感性的新型信任度评分(TWS)来衡量SR可靠性。

Innovation: 
本研究创新地提出了一种自动化框架，利用视觉语言模型识别由扩散模型生成的多解SR中的最可信样本。通过结合语义相似性、结构完整性和伪影敏感性，定义了一个信任度评分(TWS)来评估SR的可靠性。实验结果表明，VLM选择的样本比传统方法如PSNR、LPIPS更能反映人类偏好，并且能够提供一种原则性的、可扩展的和通用的方法来指导扩散SR空间的决策。

Conclusion: 
通过与人类期望和语义正确性一致，本研究为生成SR的可信度设定了新的基准，提供了一种在不确定性下导航扩散SR空间的原则性、可扩展和通用的解决方案。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20832</guid><pubDate>Fri, 27 Jun 2025 02:27:58 +0800</pubDate></item><item><title>680. cs.AI-GPU Kernel Scientist: 由LLM驱动的迭代内核优化框架</title><link>https://arxiv.org/pdf/2506.20807</link><description>Background: 
GPU内核优化是一个复杂的过程，通常需要深厚的架构知识、深入的性能分析以及反复的实验。特别是在面向新的或文档较少的GPU架构时，传统开发工具的缺乏会进一步加剧这一挑战。

Innovation: 
本文提出了一种基于LLM的'GPU Kernel Scientist'自动化方法，该方法采用多阶段、进化式的流程：（a）战略性地选择有潜力的先前代码版本作为新迭代的基础；（b）基于现有代码和吸收的一般GPU文献知识生成优化实验的假设；（c）通过代码修改并使用仅有的观察到的时间数据作为性能反馈，自动实施这些实验，整个过程无需直接的人类干预。该方法展示了如何利用LLM的优势来应对AMD MI300目标架构带来的挑战，通过弥补有限的专业知识，加速GPU内核优化过程，特别是在资源受限或快速发展的硬件环境中。

Conclusion: 
尽管从性能竞赛中获得的量化结果尚未公布，但本文详细介绍了这一方法的设计、操作流程和定性见解。本文强调了LLM驱动的代理有潜力在资源有限或快速发展的硬件环境中的内核优化过程中实现民主化和加速。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20807</guid><pubDate>Fri, 27 Jun 2025 02:27:53 +0800</pubDate></item><item><title>681. cs.AI-MultiFinRAG：一种优化的多模态检索增强生成（RAG）框架，用于财务问答</title><link>https://arxiv.org/pdf/2506.20821</link><description>Background: 
这类财务文件，如10-Ks、10-Qs和投资者演示文稿，通常包含数百页内容，且这些内容结合了繁密的叙述性文本、结构化的表格以及复杂的图表等多种模态信息。要从这类内容中回答问题，需要跨模态推理，这对传统的大型语言模型（LLMs）和检索增强生成（RAG）流程构成了巨大挑战，主要是由于存在标记量限制、布局损失以及跨模态上下文碎片化的问题。本文回顾了基于标记限制下处理财务文本、表格和图表所面临的挑战，并探讨了如何利用RAG的方法解决这些挑战。

Innovation: 
本文提出了一种名为MultiFinRAG的检索增强生成框架，旨在解决财务问答中的跨模态推理难题。首先，该框架能够同时抽取表格和图形插图，经过轻量级、量化开源的多模态LLM处理，产生结构化JSON输出和简洁文本摘要。然后，通过模态意识的相似度阈值将这些输出和叙述性文本进行嵌入和索引，以确保精准检索。此外，该框架采用分层退避策略，根据需要从仅文本到文本+表格+图像的上下文动态升级，减少无关内容使跨模态推理更加高效。MultiFinRAG能在廉价硬件上运行，并且在涉及文本、表格、图像及多模态推理的复杂财务问答任务上的准确率比ChatGPT-4o高出19个百分点。

Conclusion: 
MultiFinRAG框架能够有效处理动态变化的财务模态信息，提供更精确的跨模态推理能力。该框架的技术和方法为解决财务问答关键任务问题提供了有效途径，对于处理其他类型的多模态数据也具有广泛的参考价值。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20821</guid><pubDate>Fri, 27 Jun 2025 02:27:51 +0800</pubDate></item><item><title>682. cs.AI-通过自动化集成数据生成可靠的不良反应概况：一种半自动化本体构建方法 (GRAPH-AID}</title><link>https://arxiv.org/pdf/2506.20851</link><description>Background: 
随着数据和知识的迅速增长，采用系统性方法生成本体已成为关键。面对数据量的日益增长和内容的频繁变化，数据库用于存储和检索用于创建知识图谱的信息的需求变得越来越迫切。KNARM（知识获取和表示方法）提供了一种系统的方法来应对这些挑战并创建知识图谱。然而，这种方法也揭示了将Neo4j数据库无缝整合到Web本体语言（OWL）中的现有挑战。之前探讨了将Neo4j中的数据整合到本体中的方法，但这些方法通常需要用户熟悉描述逻辑（DL）语法，这对于许多用户来说可能不太熟悉。因此，一种更加用户友好的方法是必要的来解决这个问题。

Innovation: 
本文提出了一种利用Python及其rdflib库支持本体开发的用户友好方法。具体而言，通过将食品和药物管理局（FDA）不良事件报告系统（FAERS）数据库的数据集成到Neo4j数据库中创建了示例数据库，并开发了一个Python脚本，该脚本能够自动生成所需的类及其公理，从而实现更顺畅的整合过程。这种方法为在迅速增长的不良药物事件数据集中生成本体提供了实用解决方案，有助于提高药物安全性监控和支持公共卫生决策

Conclusion: 
本方法通过自动化处理和集成数据为生成可靠的不良反应概况提供了一种高效的本体构建途径，可有效支持药物安全监测和公共卫生决策。这种方法简化了本体开发的过程，便于非专家用户使用，从而提高了本体构建的效率和适用范围。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20851</guid><pubDate>Fri, 27 Jun 2025 02:27:50 +0800</pubDate></item><item><title>683. cs.AI-THIRDEYE：基于模仿大脑多阶段融合的感知线索意识单目深度估计</title><link>https://arxiv.org/pdf/2506.20877</link><description>Background: 
传统的单目深度估计方法通过训练深度模型直接从RGB像素中推断深度，这种隐式的学习往往忽略了人类视觉系统依赖的显式单目线索，如遮挡边界、阴影和透视关系。本文基于此背景探讨了如何利用显式的视觉线索改进单目深度估计方法。

Innovation: 
提出了ThirdEye，一种感知线索意识的单目深度估计管道。该方法通过专门的、预先训练和冻结的网络提供这些显式线索，并在基于大脑皮层多级结构（V1-&amp;gt;V2-&amp;gt;V3）的融合框架中将其融合。 ThirdEye还配备了一个关键值工作记忆模块，用于根据可靠程度加权融合这些线索，以及一个自适应区间交换机头来生成高分辨率的视差图。同时，利用固定的线索专家，ThirdEye可以继承大量外部监督，而仅需要少量的微调。

Conclusion: 
ThirdEye在不需要大规模调整的情况下继承了大量外部监督，极大地提高了单目深度估计的性能。未来研究将在文献的后续版本中提供定量实验结果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20877</guid><pubDate>Fri, 27 Jun 2025 02:27:48 +0800</pubDate></item><item><title>684. cs.AI-LLMs中的潜藏暴力倾向：行为情景下的人口统计分析</title><link>https://arxiv.org/pdf/2506.20822</link><description>Background: 
大型语言模型（LLMs）被越来越多地用于检测和应对网上暴力内容，但它们在处理涉及道德模糊性的真实世界情境时的能力尚未得到充分研究。本文首次通过行为情景评估LLMs，使用验证的社会科学研究工具——暴力行为情景问卷（VBVQ）来评估LLMs在应对常见冲突时的人类反应。

Innovation: 
引入了基于人物的提示，以人口统计学差异（种族、年龄和地理身份）为变量，评估了来自不同政治地理和组织背景下的六种LLMs，并在统一的零样本设置下进行评估。这是首次将LLMs与社会科学研究工具结合，通过行为情景评估道德模糊性情境下的反应，以及分析其潜在偏见和多样性差异。

Conclusion: 
研究发现，LLMs的文本生成表面水平经常与其对暴力响应的内部偏好不符；其次，它们在不同人口统计学中的暴力倾向也有所不同，经常与犯罪学、社会科学和心理学中的现有发现相矛盾。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20822</guid><pubDate>Fri, 27 Jun 2025 02:27:47 +0800</pubDate></item><item><title>685. cs.AI-FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization</title><link>https://arxiv.org/pdf/2506.20841</link><description>Background: 
Semi-supervised domain generalization (SSDG)旨在解决仅用少量标签时泛化到未见过领域的数据的问题。由于标签稀缺，应用域泛化方法通常效果不佳。已有的SSDG方法通过结合半监督学习方法和各种正则项来应对这一问题，但这些方法并未明确正则化以学习在所有领域中不变的表示，这是域泛化的关键目标。已有研究未能充分解决这一问题从而导致现有方法效果欠佳。

Innovation: 
FixCLR通过借鉴自监督学习的成功经验，对对比学习的关键组件进行了改进，以实现明确的域不变性正则化：采用了伪标签中的类别信息，并仅使用排斥项。此方法也可以叠加到大多数现有的SSDG和半监督方法上以获得互补的性能改进。实验涵盖了广泛未在SSDG研究中被探索的方面，包括半监督方法的不同改进，预训练模型与非预训练模型的性能评估，以及在包含多个领域的数据集上的测试。

Conclusion: 
FixCLR被证明是一个有效的SSDG方法，特别是在与其他半监督方法结合使用时表现尤为突出。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20841</guid><pubDate>Fri, 27 Jun 2025 02:27:47 +0800</pubDate></item><item><title>686. cs.AI-FINN-GL: FPGA上加速LSTMs的一般化混合精度扩展</title><link>https://arxiv.org/pdf/2506.20810</link><description>Background: 
循环神经网络（RNN），特别是长短期记忆网络（LSTMs），在情感分析和短期股票预测等时间序列任务中表现出色。然而，它们的计算复杂性在资源受限的环境中阻碍了实时部署。可编程门阵列（FPGA）提供了进行能源效率AI加速的有希望的平台，但现有的工具主要针对前向网络，而LSTM加速通常需要全定制实现。本文通过利用开放源代码和可扩展的FINN框架，旨在弥合这一差距，实现LSTM在FPGA上的通用部署。具体来说，本文利用Open Neural Network Exchange（ONNX）规范中的Scan操作符建模LSTM计算的递归性质，从而使支持混合量化成为可能，并验证了基于LSTM的模型的功能。

Innovation: 
本文引入了FINN编译器中的自定义转换，将量化后的ONNX计算图映射到FINN编译器和Vitis HLS的HLS核库中的硬件块。通过针对XCZU7EV设备训练量化后的ConvLSTM模型，并使用该流程生成相应的硬件IP，验证了所提出的工具流。这显示了通过本文流程生成的量化ConvLSTM加速器在性能（延迟）和资源消耗之间取得了平衡，同时在降低精度下达到了或超越了尖端模型的推理准确性。该流程的一般特征为FPGA上RNN加速器的设计铺平了道路。

Conclusion: 
所提出的流程展示了在FPGA上实现LSTM加速的平衡，并为高效RNN加速器设计提供了一种方法，使其更适用于资源受限的环境。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20810</guid><pubDate>Fri, 27 Jun 2025 02:27:44 +0800</pubDate></item><item><title>687. cs.AI-提升图神经网络在网络安全检测中鲁棒性的代理分析方法</title><link>https://arxiv.org/pdf/2506.20806</link><description>Background: 
图神经网络（GNNs）在物联网环境中的网络入侵检测系统（NIDS）中展现了巨大潜力，但因分布偏移导致性能下降，并且缺乏对现实 adversarial 攻击的鲁棒性。现有的鲁棒性评估多依赖于不切实际的合成扰动，并未能对不同类型的 adversarial 攻击进行全面分析，涵盖黑盒和白盒场景。

Innovation: 
提出了一种使用大型语言模型（LLMs）在代理管道中模拟网络专家代理来增强 GNN 鲁棒性的新方法。这些代理审查从网络流量数据中得出的图结构，识别并可能中和异常或被篡改的成分，以提高 GNN 处理前的安全性。实验利用一套针对现实环境下多种 adversarial 攻击的评估框架，展示了 LLM 代理作为入侵检测架构补充层的潜力。

Conclusion: 
实验结果表明，通过 LLM 分析可以显著提高 GNN 基于的 NIDS 的抗挑战能力，证明了 LLM 代理在入侵检测架构中的互补作用。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20806</guid><pubDate>Fri, 27 Jun 2025 02:27:41 +0800</pubDate></item><item><title>688. cs.AI-LLM生成与人类研究想法执行结果差距：启示-执行间隙</title><link>https://arxiv.org/pdf/2506.20803</link><description>Background: 
大规模语言模型（LLMs）在加速科学研究管道方面显示出潜力，特别是在生成新颖的研究想法方面。先前研究发现，AI生成的研究想法被认为比人类专家的想法更具创新性。然而，一个好想法不应只是看似新颖，更重要的是能够通过执行产生更有成效的研究。为了验证AI生成的想法是否能带来更好的研究结果，本研究通过招募43名专家研究人员来执行由专家或AI生成的随机想法，并对执行成果进行盲审，对比评估结果，发现AI生成的想法在新颖性、兴奋度、有效性等所有评估指标上的得分显著低于专家撰写的想法，验证了思想执行之间的差异，揭示了当前LLM在生成真正有效研究想法方面的局限性，以及在缺乏执行结果的情况下评估研究想法的挑战。

Innovation: 
本研究创新之处在于通过具体的执行实验来检验AI生成的想法与人类专家想法之间的差异，并通过专家盲审进行评价，首次提出了‘思想-执行’的差距概念，揭示了AI在生成有效研究想法方面的不足及其挑战

Conclusion: 
研究结论表明，虽然LLM在生成新颖的想法方面表现出优势，但在实际执行研究结果方面，专家们的表现优于AI生成的想法。这表明LLM在生成真正有效的研究想法方面仍存在局限性，未来需要进一步探索和改进AI生成想法的能力，特别是在评估和优化其执行结果的有效性方面。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20803</guid><pubDate>Fri, 27 Jun 2025 02:27:38 +0800</pubDate></item><item><title>689. cs.AI-随机参数分解</title><link>https://arxiv.org/pdf/2506.20790</link><description>Background: 
神经网络逆向工程的一个关键步骤是将它们分解成可以在相对隔离环境中研究的更简单的部分。线性参数分解是一种框架，旨在解决当前分解方法的多个问题，它将神经网络参数分解为参数空间中稀疏使用的向量之和。尽管如此，目前该框架的主要方法之一——基于归因的参数分解（APD），由于计算成本高且对超参数敏感，其实用性有限。因此，需要更可扩展且对超参数更稳定的替代方法。

Innovation: 
本文介绍了随机参数分解（SPD）方法，这是一种比APD更可扩展且对超参数更稳健的方法。实验表明，在APD无法分解的稍微大且更复杂的模型中，SPD能有效地进行分解。此外，SPD还解决了其他问题，如学习参数的收缩，并在玩具模型中更好地识别了真实机制。通过将因果中介分析与网络分解方法结合起来，这项展示为线性参数分解方法的大规模应用开辟了新的研究机会，从而促进了机理可解释性的研究。

Conclusion: 
通过释放可以运行SPD和重现实验的库，本文为线性参数分解方法的大规模应用去除了障碍，为机制可解释性的研究带来了新的可能性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20790</guid><pubDate>Fri, 27 Jun 2025 02:27:37 +0800</pubDate></item><item><title>690. cs.AI-探讨聊天机器人的拟人化与人类同理心对其人类向聊天机器人表现出的助人行为的影响</title><link>https://arxiv.org/pdf/2506.20748</link><description>Background: 
聊天机器人越来越多地融入人们的生活，并广泛用于帮助人们。最近，人类帮助聊天机器人的兴趣也在增加，这得益于更好地聊天机器人性能、人类福祉以及协作成果等多种好处。然而，目前鲜有关于什么因素激励人们帮助聊天机器人的研究。本研究借鉴计算机是社会行动者（CASA）的框架，探讨了聊天机器人的拟人化特征（包括人类身份、情感表达和非言语表达）如何影响人们对聊天机器人的同理心及随后的助人行为和意图。我们还探讨了参与者对向聊天机器人表现出助人行为的解释。我们进行了一项在线实验，参与者在合作图像标注任务中遇到聊天机器人的错误并提供解释，我们随后测量参与者对聊天机器人的助人行为和意图。结果表明，聊天机器人的拟人化身份和情感表达增加了参与者对聊天机器人的助人行为和意图，同理心起到了中介作用。定性分析进一步发现，参与者助人行为的两个动机：对聊天机器人的同理心和将聊天机器人视为类似人类。

Innovation: 
本研究首次探讨了聊天机器人的拟人化与其引发的人类同理心之间的关系，揭示了人类助人行为的形成和动机，对理解及促进人类对聊天机器人的助人行为具有重要意义。

Conclusion: 
研究结果表明，人类身份和情感表达的聊天机器人增加了参与者对聊天机器人的助人行为和意图。同理心在这些效应中起到了中介作用。进一步的质性分析发现在助人行为中存在两种动机：对聊天机器人的同理心和将聊天机器人视为类似人类的存在。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20748</guid><pubDate>Fri, 27 Jun 2025 02:27:37 +0800</pubDate></item><item><title>691. cs.AI-机器学习环境下的敏捷管理：一种系统综述研究</title><link>https://arxiv.org/pdf/2506.20759</link><description>Background: 
机器学习（ML）驱动的社会数字转型带来灵活性和快速变化的需求，传统项目管理方法面临挑战。敏捷方法因其灵活性和增量交付显得适用，但如何将其应用于ML环境下尚不明确，需要特别的方法论支持。

Innovation: 
本文通过系统综述研究，结合数据库搜索和滚雪球法迭代，识别了27篇相关研究，归纳出8个框架，并分类总结了建议和实践的关键主题，如迭代灵活性、特定于ML的创新成果和最小可行模型。特别是，研究指出了ML任务准确估算的主要挑战，为该领域提供了有效框架和技术建议，填补了一些研究空白，但仍需更 robust 的实证评价来验证研究成果的有效性。

Conclusion: 
本文通过系统地图研究展示了当前研究状态，并指出该领域的空白点，尽管已经有相关工作，但仍需要更加严谨的实证研究来验证这种方法的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20759</guid><pubDate>Fri, 27 Jun 2025 02:27:35 +0800</pubDate></item><item><title>692. cs.AI-CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment</title><link>https://arxiv.org/pdf/2506.20243</link><description>Background: 
自动流畅度评估（AFA）在捕捉非母语 speakers 的发音节奏、停顿和断句方面仍然具有挑战性。现有的研究集中在使用自我监督学习（SSL）模型来捕捉这些特征，但单一模型难以全面覆盖所有需求。因此，本文提出了一个块（chunk）基础的方法，结合了Wav2Vec2、HuBERT和WavLM三种模型，并引入了层次化的CNN-BiLSTM框架，弥补了单个模型在音素、语调以及噪音语音建模上的不足。此外，该方法还利用了SiPero语音活动检测（VAD）将讲话分为呼吸组块，以进行细致的时间分析，同时减少过度分割的副作用。

Innovation: 
该方法创新地结合了主要的SSL模型（Wav2Vec2, HuBERT, WavLM）和块（chunk）基础的方法，利用层次化的CNN-BiLSTM框架，融合了可学习加权机制的SSL嵌入，并加入了块级别的流畅性标记来丰富语言特征。与单个SSL基线模型相比，该方法在 Speechocean762 上的F1分数提高了2.8个点，皮尔逊相关系数提高了6.2个点，并在 Avalinguo 上取得了显著的提高，分别为 4.2 个 F1 分数和 4.0 个皮尔逊点的提高。这些提升了表明块融合多SSL方法在鲁棒的流畅度评估中的有效性，但是未来的工作应该探索对具有不规则韵律的方言的一般化能力。

Conclusion: 
实验结果表明，CBF-AFA方法在评估非母语speakers的流畅度方面表现出了显著的改进。该方法通过结合多种SSL模型和块基础的分析方法，提高了自动流畅度评估的准确性，并且在两个评估数据集上均超过了基于分割的基线模型。未来的工作可以探索该方法在不同方言和语境中的泛化能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20243</guid><pubDate>Fri, 27 Jun 2025 02:27:34 +0800</pubDate></item><item><title>693. cs.AI-理论物理学中的测试时间缩放技术——TPBench数据集上的方法比较</title><link>https://arxiv.org/pdf/2506.20729</link><description>Background: 
大型语言模型在复杂推理方面展现出了强大的能力，而测试时缩放技术可以在保持良好性能的同时降低计算成本。许多这类方法已经在AIME等数学推理基准测试上被开发和评估。本文研究这些从数学推理获得的经验教训是否可以应用于高级理论物理学领域。我们评测了一系列通用的测试时缩放方法在TPBench物理数据集上的效果，并将其与AIME上的结果进行比较。为更好地利用物理学问题的结构，我们开发了一个新的、基于符号的弱验证框架来改进并行缩放结果。

Innovation: 
我们开发了一个新的、基于符号的弱验证框架来改进并行缩放结果。我们的实证结果表明，这种方法在TPBench上显著优于现有的测试时缩放方法。此外，我们还在AIME上测试了我们的方法，确认了其解决高级数学问题的有效性。

Conclusion: 
我们的研究结果强调了逐步符号验证在解决复杂科学问题方面的强大能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20729</guid><pubDate>Fri, 27 Jun 2025 02:27:34 +0800</pubDate></item><item><title>694. cs.AI-针对专家混合模型的实用驱动推测性解码</title><link>https://arxiv.org/pdf/2506.20675</link><description>Background: 
GPU内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。推测性解码通过使用轻量级的候选者来提出K个token，这些token随后由LLM并行验证，从而提升token吞吐量。在传统的密集型LLM中，每轮迭代都会获取所有模型权重，因此推测性解码不会增加延迟开销。然而，新兴的混合专家（MoE）模型仅在每个token上激活一组权重，大幅减少了数据移动，但推测性解码对MoE模型是无效的，因为候选token共同激活的权重更多，增加了数据移动和验证时间。这导致推测性解码反而可能导致性能下降，特别是在令牌吞吐量收益未能抵消这种开销的情况下，推测性解码甚至会造成高达1.5倍的性能下降，并且不切实际。即使在某些情况下推测性解码是有用的，最佳的K值也因任务、模型甚至请求和迭代而异。因此，尽管在密集型LLM中广泛使用，但对于现代的MoE模型来说，推测性解码仍然是一种不切实际的方法。

Innovation: 
Cascade是一种数据驱动的框架，它可以有选择地启用推测性解码以避免性能下降，并根据验证效益动态调整K的值以加速MoE服务于此，Cascade使用了一个轻量级的度量标准：推测性解码的效益比，即令牌收益与验证成本之比，这显示了迭代的局部性，使得可以在较短测试期和较长设置期之间进行定期决策。对于每个请求，如果推测性解码的效益在测试期间低于1，则禁止推测性解码；如果超过1，则测试多个K值以选择设置期内效益最大化的K值。我们已经在vLLM上实现了Cascade，并在包括代码、数学、提取和混合任务在内的五个流行的MoE模型上进行了评估。结果表明，Cascade将性能下降限制在5%（相对于1.5倍），在固定K的基础上提高了7-14%的吞吐量，从而使推测性解码对于MoE模型来说是可实现的。

Conclusion: 
Cascade通过动态调整推测性解码下的K参数，使得在MoE模型服务中合理应用推测性解码成为可能，从而避免了性能下降，同时提高了吞吐量，尤其是在vLLM中实现了这一创新性的解决策略，在各种类型的MoE模型上展示了其有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20675</guid><pubDate>Fri, 27 Jun 2025 02:27:31 +0800</pubDate></item><item><title>695. cs.AI-心脏MRI与心电图联合表示的全局和局部对比学习</title><link>https://arxiv.org/pdf/2506.20683</link><description>Background: 
心电图（ECG）是一种广泛使用且成本效益高的工具，用于检测心脏的电活动异常。然而，ECG不能直接测量功能性参数，如心室容积和射血分数，这些参数对于评估心脏功能至关重要。心脏磁共振（CMR）是这些测量的黄金标准，能够提供详细的心脏结构和功能洞察，但它成本高昂且获取不便。为了解决这个问题，我们提出了一种名为PTACL（患者和时间对齐对比学习）的多模态对比学习框架。PTACL通过整合CMR中的时空信息来增强ECG表示。PTACL采用全局患者水平对比损失和局部时间水平对比损失。全局损失通过将同一患者的心电图和CMR嵌入拉近来进行患者级表示对齐，同时将不同患者之间的嵌入推开。局部损失通过对每个患者编码的心电图片段与相应编码的CMR帧进行对比来强制执行细粒度的时间对齐。这种方法不仅丰富了ECG表示的诊断性信息，而且通过单独的全局对齐，更有效地在模态之间转移洞察。我们在这项研究中使用PTACL评估了27,951名患者的配对ECG-CMR数据。与基线方法相比，PTACL在两个临床相关任务中表现更好：(1) 检索具有相似心脏表型的患者，(2) 预测由CMR衍生的心脏功能参数，如心室容积和射血分数。我们的研究表明PTACL能够利用ECG增强非侵入性心脏诊断。

Innovation: 
PTACL通过整合心脏磁共振（CMR）中的时空信息来增强心电图（ECG）的表示，采用全球患者级和局部时间级对比损失来实现跨模态的更好对齐和信息转移，这种方法能够丰富ECG的诊断性信息，并在无新增可学习参数的情况下提高心脏功能参数的预测能力。研究中的评估使用了英国生物银行的配对ECG-CMR数据集，展示了PTACL在临床相关任务上的优越性能。

Conclusion: 
我们的研究结果表明，PTACL有潜力利用心电图提升非侵入性心脏诊断的效果。该方法通过集成全局和局部对比损失机制，在保持模型简洁性的同时，显著提高了心脏功能性参数的预测准确性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20683</guid><pubDate>Fri, 27 Jun 2025 02:27:30 +0800</pubDate></item><item><title>696. cs.AI-IMC-PINN-FE：一种基于图像运动一致性和生物力学参数估计的物理指导神经网络患者特异性左心室有限元建模</title><link>https://arxiv.org/pdf/2506.20696</link><description>Background: 
研究心肌的 biomechanical 行为对于理解心脏生理至关重要，但临床成像无法直接推断，通常需要进行有限元（FE）模拟。然而，传统的 FE 方法在计算上非常昂贵，且往往无法重现观察到的心脏运动。因此，迫切需要一种高效且精确的方法来建模个人特异性左心室的 biomechanics。

Innovation: 
提出了 IMC-PINN-FE 框架，这是一种结合图像运动一致性（IMC）与 FE 模型的神经网络方法。通过预训练的注意力网络或无监督循环正则化网络从 MRI 或超声心动图中估计心脏运动，并提取运动模态。IMC-PINN-FE 可以快速估计心肌刚度和主动张力，将传统的逆 FE 计算时间从几小时加速到几秒。此外，通过运动约束，IMC-PINN-FE 更准确地匹配了图像中的位移，提高了平均 Dice 值，同时保持了真实的压力-体积行为。与之前的 PINN-FE 模型相比，IMC-PINN-FE 引入了材料属性的反向计算并提高了运动的保真度。此外，使用单个受试者的运动来重建形状模态，避免了对大规模数据集的需求，从而提高了患者特异性。

Conclusion: 
IMC-PINN-FE 提供了一种快速、个性化且图像一致的心脏生物力学建模的稳健高效方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20696</guid><pubDate>Fri, 27 Jun 2025 02:27:28 +0800</pubDate></item><item><title>697. cs.AI-Diffusion Tree Sampling: 集成扩散模型在推理阶段的可扩展对齐方法</title><link>https://arxiv.org/pdf/2506.20701</link><description>Background: 
在生成模型中，在推理阶段适应预训练扩散模型以新目标仍然存在挑战。现有方法在高噪声水平下价值估计不准确，导致偏差指导。此外，过去迭代的信息未被有效利用，导致计算资源的低效利用。受蒙特卡洛树搜索成功启发，该研究将推理阶段对齐问题重新定义为一个可以重用过往计算以提高样本质量的搜索问题。

Innovation: 
提出了一种树状方法，通过计算奖励对扩散链的后向传播迭代调整价值估计，称为Diffusion Tree Sampling (DTS)。其贪心变体，Diffusion Tree Search (DTS$^textbf{textit{text{*}}}$)，能进行全局搜索以找到高质量样本。在MNIST和CIFAR-10条件生成任务中，DTS能以最多10倍的计算资源实现最佳基线性能。在文本到图像生成和语言完成任务中，DTS$^textbf{textit{text{*}}}$能用最多5倍的计算资源找到最优样本。该方法通过重用先前迭代的信息，实现任何时间的算法，进一步优化样本质量，提供了一种在推理时对扩散模型进行对齐的可扩展方法。

Conclusion: 
DTS和DTS$^textbf{textit{text{*}}}$通过重用信息和计算资源高效生成高质量样本，展示了大规模计算资源转化为样本质量提升的潜力，为扩散模型的推理阶段对齐提供了一种可扩展方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20701</guid><pubDate>Fri, 27 Jun 2025 02:27:28 +0800</pubDate></item><item><title>698. cs.AI-关于卷积、固有维度和弥散模型</title><link>https://arxiv.org/pdf/2506.20705</link><description>Background: 
高维空间中的数据（如图像数据）被认为位于未知的低维流形上。弥散模型通过将数据与逐渐增加的高斯噪声进行卷积，然后学习逆转这一过程，成为表现最佳的生成模型，并能够学习低维支撑的分布。基于此，对于流形上的任一点，弥散模型应该隐式地学习其对应的局部固有维数（LID），即它所属流形的维度。Kamkari等（2024b）显示了这一推断并基于此提出了FLIPD估计器，该估计器性能优越，但其理论基础不完整，因为假设流形是仿射的。

Innovation: 
本研究通过严谨证明FLIPD在现实条件下也正确，填补了理论基础的空白。此外，研究证明用均匀卷积代替高斯卷积后，类似结果依然成立，并讨论了该结果的相关性。

Conclusion: 
本研究不仅扩展了FLIPD估计器的适用性，使其理论基础更加坚实，还为弥散模型和其他流形相关的研究提供了新的视角。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20705</guid><pubDate>Fri, 27 Jun 2025 02:27:25 +0800</pubDate></item><item><title>699. cs.AI-评估用于生物信号多尺度建模的偏微分方程发现方法</title><link>https://arxiv.org/pdf/2506.20694</link><description>Background: 
生物系统是非线性的，包含未观察到的变量，并且控制其动态的物理原理部分未知。这使得它们的行为特征化非常具有挑战性。值得注意的是，它们的活动发生在多个相互依赖的空间和时间尺度上，需要跨越尺度连接机制。为了应对不同尺度之间的差距，本文利用偏微分方程（PDE）发现方法，从中微观尺度数据中推断出中间尺度的动力学特征。

Innovation: 
本文提出了一种结合基于粒子的模拟和PDE发现的框架，并在受控环境中进行了初步实验，以评估方程发现方法。使用五种先进的PDE发现方法对星形胶质细胞中钙扩散的基于粒子的模拟进行了评估，评价方法在所发现方程的形式和钙浓度预测的时空变化方面的性能。结果表明，多种方法准确恢复了扩散项，突显了从微观数据捕获生物系统宏观动力学的PDE发现方法的潜力。

Conclusion: 
本文的研究结果展示了PDE发现方法在从微观数据中捕捉生物系统宏观动态方面的潜力，并为多尺度生物信号建模提供了新的见解。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20694</guid><pubDate>Fri, 27 Jun 2025 02:27:22 +0800</pubDate></item><item><title>700. cs.AI-DRAGON: 基于分布的奖励优化扩散生成模型</title><link>https://arxiv.org/pdf/2504.15217</link><description>Background: 
介绍了DRAGON框架，这是一种用于微调生成模型以达到特定目标的通用框架。与传统的基于人类反馈的强化学习（RLHF）或直接偏好优化（DPO）等成对偏好方法相比，DRAGON更具灵活性。它可以对个体样本或其分布进行奖励函数优化，适用于广泛的样本、样本到分布以及分布到分布的奖励需求。我们通过选择编码器和一组参考样本来构建示例分布，以增强生成的结果。DRAGON通过收集在线和规程生成的内容，对其进行评分，并利用正负样本之间的差异来最大化奖励，从而优化生成模型。在对音频域的文本到音乐扩散模型进行测试后，展示了多种奖励函数的性能，并进一步比较了不同参考集和编码器的性能。

Innovation: 
DRAGON框架通过灵活的奖励函数优化生成模型，能适应不同的奖励目标。它能优化针对个体样本或其分布的奖励函数，并利用示例数据集（exemplar sets）来创建一个正负对象集，以提高生成内容的质量。DRAGON还展示了使用示例集设置的奖励函数如何增强生成内容，并且在无需人类偏好注释的情况下，DRAGON实现了60.95%的人类投票音乐质量胜率。这表明DRAGON不仅适用于多种奖励目标，还能有效提高生成内容的感知质量，提供了一种新的设计和优化奖励函数的方法。

Conclusion: 
无论是针对个体样本还是分布到分布的奖励，DRAGON都表现出色。经过所有20个目标奖励的测试，DRAGON平均胜率为81.45%。这表明DRAGON为设计和优化提高人类感知质量的奖励函数提供了一种新方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2504.15217</guid><pubDate>Fri, 27 Jun 2025 02:27:19 +0800</pubDate></item><item><title>701. cs.AI-MAGPIE: 一个用于多Agent情境下隐私评估的数据集</title><link>https://arxiv.org/pdf/2506.20737</link><description>Background: 
随着基于大语言模型（LLM）的代理数量的增加，代理之间的协作也越来越被用于任务调度、谈判、资源配置等场景中。然而，这些系统中隐私保护至关重要，因为代理往往需要访问特定领域的数据库和专有工具，这需要严格的保密性。本文探讨了LLM代理是否理解背景中的上下文隐私，并在非对抗性的多回合对话中，是否能在遵循指示时有效地保护推理过程中用户的隐私。现有的基线评测通常只考察单一回合、低复杂度任务，而这些任务中的隐私信息很容易被简单排除。本文提出了一组基准，包括158个真实生活中高风险情景（涵盖15个领域），这些情景设计得当，在完全排除隐私数据的情况下会妨碍任务完成，而泄露全部信息又可能导致重大损失。

Innovation: 
本文首次提出了一个名为MAGPIE（Method for Assessing Group Privacy in Entities）的数据集，用于评估多代理系统中的上下文隐私。MAGPIE包含158个真实生活中的高风险场景，涵盖15个领域。该数据集设计得当，确保完全排除隐私数据将妨碍任务完成，同时完整共享信息也会导致风险。在此基础上，评估了目前最先进的LLM模型对上下文隐私的理解和协作过程中不泄露用户隐私的能力。实验证明，当前模型在理解上下文隐私和保护用户隐私方面存在不足，错误分类隐私数据为可共享的情况高达25.2%至43.6%。在多轮对话中，即使在明确指示的前提下，这些模型仍然在50.5%至59.9%的情况下泄露了用户隐私信息。多代理系统在71%的场景中未能完成任务。这意味着当前模型尚未有效地在保护上下文隐私和协作任务解决方面达成平衡。

Conclusion: 
当前的LLM模型在理解和保护背景中的上下文隐私方面存在显著不足。即使在用户明确指示的情况下，它们仍然容易泄露用户隐私，尤其是在多回合对话中。因此，这些系统需要进一步改进，以更好地平衡上下文隐私保护和多代理协作的任务完成能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20737</guid><pubDate>Fri, 27 Jun 2025 02:27:18 +0800</pubDate></item><item><title>702. cs.AI-渐进式大小自适应联邦学习：跨模态数据系统的综合框架</title><link>https://arxiv.org/pdf/2506.20685</link><description>Background: 
联邦学习（FL）作为一种保护数据隐私的分布式机器学习范式已经出现。现有方法主要集中在模型异质性和聚合技术上，很少考虑到数据集大小特性对联邦学习动态的决定性影响。该论文介绍了一种基于数据集大小特性的新自适应联邦学习（SAFL）框架，该框架系统地组织跨异质多模态数据的联邦学习。实验结果跨越13个不同模态（视觉、文本、时间序列、音频、传感器、医学视觉和多模态）的数据集，揭示了关键洞察：最优数据集大小范围在1000-1500样本；结构化数据（时间序列、传感器）的性能明显优于非结构化数据（文本、多模态）；大规模数据集超过2000样本时，性能会系统性地下降。SAFL在所有数据集上平均准确率为87.68%，结构化数据模态可达99%以上准确率。框架展示了卓越的通信效率，558次通讯中总数据传输量仅7.38GB，同时保持高性能。实时时监控提供了对系统资源利用、网络效率和训练动态的前所未有的见解。这项工作填补了如何根据数据特征驱动联邦学习策略的理解空白，提供了理论见解和实用指导，供实际部署中的联邦学习（FL）和学习系统中的神经网络使用。

Innovation: 
SAFL是一种新提出的渐进式大小自适应联邦学习框架，能够根据数据集大小的不同特性来组织和优化跨异质多模态数据的联邦学习。此框架提供了一种系统的方法，用以揭示数据集大小、模态间的表现差异以及大规模数据集的性能下降情况。此外，该框架还显著提高了通信效率和性能，同时提供了对系统资源访问及网络效率的实时监控。

Conclusion: 
该研究填补了联邦学习中因数据特征带来的策略设计研究缺口，SAFL展示了更高的准确性和效率，证明了结构化数据优于非结构化数据，并提供了实际部署中的重要指导。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20685</guid><pubDate>Fri, 27 Jun 2025 02:27:17 +0800</pubDate></item><item><title>703. cs.AI-揭示大规模语言模型中的因果推理：现实还是幻影？</title><link>https://arxiv.org/pdf/2506.21215</link><description>Background: 
因果推理能力对于大型语言模型（LLMs）向强人工智能迈进至关重要。虽然现有的LLMs展示出了理解上下文因果关系和遵循因果定律回答问题的能力，但尚不清楚它们是否能够进行真正的人类水平的因果推理。目前的证据表明，它们仅能进行浅层（一级）因果推理，主要依赖于嵌入参数中的因果知识，而缺乏进行真正的人类水平（二级）因果推理的能力。通过分析变压器架构LLMs的自回归机制，发现它并非固有的因果机制。研究还引入了新的因果问答基准CausalProbe-2024，LLMs在这一基准上的性能显著下降，进一步证实了它们主要进行的是浅层因果推理。

Innovation: 
研究揭示了LLMs仅能够进行浅层因果推理，并提出了一种方法——G^2-Reasoner，该方法将通用知识和目标导向的提示融入到LLMs的因果推理过程中。实验结果表明，G^2-Reasoner 能够显著提高LLMs的因果推理能力，特别是在新颖和反事实情境中。这一工作为LLMs向真正的因果推理迈进提供了一个新的路径，超越了一级因果推理并向着二级因果推理迈出步伐。

Conclusion: 
研究通过方法论上的分析和实证研究，揭示了LLMs目前仅能够进行浅层因果推理的能力，而不是真正的深度因果推理。为了增强LLMs的因果推理能力，提出了一种新的方法G^2-Reasoner，能够显著提升在新颖和反事实情况下的因果推理能力。这一发现为LLMs未来的发展指明了方向。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21215</guid><pubDate>Fri, 27 Jun 2025 02:27:15 +0800</pubDate></item><item><title>704. cs.AI-U-R-VEDA: 结合 UNET、残差连接、边缘检测和双注意力机制以及视觉变换器的心脏磁共振图像准确语义分割</title><link>https://arxiv.org/pdf/2506.20689</link><description>Background: 
人工智能，特别是深度学习模型，将在自动化医学图像分析中扮演重要角色，主要用于心脏疾病的诊断和管理。准确自动地分割心脏图像是进行心脏疾病定量分析和自动化诊断的必要第一步。这项研究中提出了一种基于深度学习的增强 UNet 模型，U-R-Veda，该模型集成了卷积变换、视网膜变换器、残差链接、通道注意力和空间注意力，以及基于边缘检测的跳连，用于心脏磁共振（CMR）图像的准确全自动语义分割。

Innovation: 
U-R-Veda 模型通过结合卷积变换、视网膜变换器、残差链接、通道和空间注意力以及基于边缘检测的跳连，提高了心脏磁共振图像的语义分割性能。该模型的特点在于嵌入通道和空间注意力在卷积块中，以及使用边缘信息和通道、空间注意力作为跳连，减少了卷积变换过程中的信息丢失。结果显示，基于 DSC 和 HD 指标的 U-R-Veda 模型在分割右心室和左心室心肌方面优于其他模型，达到 95.2% 的平均准确率。

Conclusion: 
U-R-Veda 模型在心脏磁共振图像的全自动语义分割中表现优异，显著提高了医学图像分析的精度。这一模型为自动化心脏疾病诊断提供了一种有效方法。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20689</guid><pubDate>Fri, 27 Jun 2025 02:27:12 +0800</pubDate></item><item><title>705. cs.AI-领域特定AI应用的动态上下文感知提示推荐</title><link>https://arxiv.org/pdf/2506.20815</link><description>Background: 
LLM（大型语言模型）驱动的应用程序对用户的提示质量非常敏感，设计高质量的提示尤其是在特定领域的应用程序中往往具有挑战性。因此，需要一种能够根据上下文提供相关和可行的提示建议的新颖方案。本文提出了一种结合上下文查询分析、检索增强的知识接地、层次化的技能组织和适应性技能排名的动态上下文感知提示推荐系统，以生成相关的提示建议。该系统利用行为遥测和两阶段的层次化推理过程动态选择和排名相关的技能，利用预定义和适应性的模版，并通过少量学习进行合成。实验表明，该方法在实际数据集上具有高度相关性和实用性，并通过自动化和专家评估得以验证。

Innovation: 
该论文提出了一个新颖的动态上下文感知提示推荐系统，该系统结合了上下文查询分析、检索增强的知识接地、层次化的技能组织和适应性技能排名，利用行为遥测和两阶段的层次化推理过程动态选择和排名相关的技能，生成相关和可行的提示建议。此外，该系统还利用预定义和适应性的模版，并通过少量学习进行合成，提高了系统的实用性和相关性。

Conclusion: 
实验结果表明，该方法在实际数据集上实现了高实用性和相关性，通过自动化和专家评估得以验证。该论文的主要贡献在于提出了一种高效的动态上下文感知提示推荐系统，通过结合多种技术和方法提升了特定领域AI应用中提示的准确性和适用性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20815</guid><pubDate>Fri, 27 Jun 2025 02:27:03 +0800</pubDate></item><item><title>706. cs.AI-ClusterRCA：使用多模态数据在HPC系统中进行网络故障诊断</title><link>https://arxiv.org/pdf/2506.20673</link><description>Background: 
对于高性能计算（HPC）系统来说，网络故障诊断虽然具有挑战性但却是至关重要的。现有的方法由于数据异构性和缺乏准确性，不能直接应用于HPC场景。因此，需要一种新的框架来解决这个问题，同时能准确诊断网络故障并定位问题节点。

Innovation: 
本文提出了一个名为ClusterRCA的新框架，通过利用多模态数据来确定故障节点并诊断故障类型。ClusterRCA结合了分类器和图的方法，能够准确地定位故障节点和确定故障类型。此外，ClusterRCA还在不同应用情景下保持了稳健的性能，并在顶级全球HPC设备供应商收集的数据集上展现了高度准确的网络故障诊断能力。

Conclusion: 
实验结果表明，ClusterRCA在不同HPC系统应用中展现出高精度的网络故障诊断能力，并且在各种应用情况下都能保持稳健性能。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20673</guid><pubDate>Fri, 27 Jun 2025 02:27:03 +0800</pubDate></item><item><title>707. cs.AI-Mind2Web 2：以代理为裁判评估自主搜索</title><link>https://arxiv.org/pdf/2506.21506</link><description>Background: 
随着大规模语言模型能够自主浏览网络、综合信息并给出基于完整引用的回答，代理搜索（如深度研究系统）代表了用户与网络信息互动方式的重大转变。尽管这种方式提高了效率和减轻了认知负担，但代理搜索的复杂性和开放性挑战了现有的评估基准和方法，这些方法主要假设了短搜索时间轴和静态答案。因此，需要新的评估基准和方法来解决这些挑战。

Innovation: 
本文提出了一种称为Agent-as-a-Judge的新颖评估框架。Mind2Web 2基准测试包含130个真实、高质量、长周期的任务，这些任务要求实时浏览网络和进行广泛的信息综合，涵盖了超过1000小时的人力劳动成果。该框架通过基于树结构的评判标准构建任务特定的评判代理，自动评估答案的正确性和信息源的归属。此外，本文对九个领先的代理搜索系统和人类表现进行了全面评估，并进行了详细错误分析，以提供对未来发展的洞察。

Conclusion: 
OpenAI的深度研究系统在多个任务上表现最佳，已达到人类性能的50-70%，并且只需一半的时间，展示了巨大潜力。Mind2Web 2为开发和评估下一代代理搜索系统提供了一个严格的基准。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21506</guid><pubDate>Fri, 27 Jun 2025 02:26:58 +0800</pubDate></item><item><title>708. cs.AI-Ad-Hoc Human-AI Coordination Challenge</title><link>https://arxiv.org/pdf/2506.21490</link><description>Background: 
实现AI代理和人类之间的无缝协同对于实际应用至关重要，但这是一个重大的开放挑战。汉abi是一种具有不完美信息、受限的通信、心智理论要求以及协调行动的协作纸牌游戏，使其成为人类-AI协同的理想测试平台。然而，由于人类评估的高成本和难以复制，其在人类-AI交互中的应用受到限制。

Innovation: 
该团队引入了Ad-Hoc Human-AI Coordination Challenge （AH2AC2）挑战，通过利用大规模的人类数据集开发出“人类代理代理”，作为AH2AC2中的可靠、廉价且可复制的人类模拟评估合作伙伴。为了促进数据高效方法的发展，该团队开源了一个包含3,079场游戏的数据集，这是通过有意限制可用的人类游戏数据来实现的。为保证公平评估，代理通过受控评估系统提供而不是公开发布。

Conclusion: 
在AH2AC2中，我们展示了两人和三人的汉abi场景的基础结果。评估代码可在以下链接获得：this https URL。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21490</guid><pubDate>Fri, 27 Jun 2025 02:26:56 +0800</pubDate></item><item><title>709. cs.AI-PsyLite 技术报告</title><link>https://arxiv.org/pdf/2506.21536</link><description>Background: 
随着数字技术的快速发展，AI驱动的心理咨询逐渐成为心理健康领域的重要研究方向。然而，现有的模型在对话安全性、复杂场景处理和轻量级部署方面仍存在不足。

Innovation: 
为解决这些问题，本研究提出了一种基于InternLM2.5-7B-chat基础模型的轻量化心理健康咨询大语言模型代理PsyLite。通过两级训练策略（混合蒸馏数据微调和ORPO偏好优化）增强模型的深度推理能力、心理健康咨询能力和对话安全性。另外，设计了一种创新的条件化RAG，在心理咨询过程中适时引入跨谈幽默元素，以提升用户体验和强化对话安全性，同时使用量化技术（GGUF q4_k_m）实现低硬件部署（5GB内存即可运行），在资源受限的环境中提供了可行性解决方案。

Conclusion: 
PsyLite 在中文通用评估（CEval）、心理健康咨询服务专业评估（CPsyCounE）和对话安全性评估（SafeDialBench）中均超过基线模型，特别是在心理健康咨询服务专业度（CPsyCounE评分提高47.6%）和对话安全性（安全{}评分提高2.4%）方面表现尤为出色。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21536</guid><pubDate>Fri, 27 Jun 2025 02:26:55 +0800</pubDate></item><item><title>710. cs.AI-从有限视角进行空间思维建模</title><link>https://arxiv.org/pdf/2506.21458</link><description>Background: 
人类能够基于少量视角形成完整的场景想象，而现有的视觉语言模型（VLMs）在这一能力上表现差强人意。人类可以形成空间心理模型，即对看不见的空间内部表示进行推理，处理布局、视角和运动等事务。本研究通过MindCube基准测试评估了现有VLMs在构建稳健的空间心理模型能力上表现出的随机性能，并探讨了三种方法来帮助VLMs逼近空间心理模型。通过MindCube基准测试，该研究揭示了现有VLMs在这一任务上的关键缺陷。

Innovation: 
研究提出了一种新的基准MindCube，包含21,154个问题覆盖3,268个图像来量化VLMs的空间思维建模能力。研究发现了三种方法来帮助VLMs构建空间心理模型，包括未见的中间视图、自然语言推理链和认知地图。更重要的是，研究提出了一种“先构建地图再推理”的方法，这种方法将模型训练成先生成认知地图，再基于此进行推理。实验结果表明，该方法将准确性从37.8%提升到了60.8%（+23.0%），结合强化学习进一步提升到了70.7%（+32.9%）

Conclusion: 
该研究提出了一个新的学术贡献，即使用内部结构化的空间表示与灵活的推理过程来构建和利用空间心理模型，显著提高了对不可见空间的理解。研究表明，结合强化学习可显著提升VLMs的空间思维建模能力。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21458</guid><pubDate>Fri, 27 Jun 2025 02:26:54 +0800</pubDate></item><item><title>711. cs.AI-TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding</title><link>https://arxiv.org/pdf/2506.21393</link><description>Background: 
在现实世界环境中理解表格的多模态表示具有挑战性，因为表格结构复杂、符号密度高且存在视觉退化（模糊、倾斜、水印、不完整结构或字体、多栏或嵌套布局）。现有的多模态大型语言模型（MLLMs）在这种野蛮结构条件下表现不佳，导致性能有限且泛化能力差。具体背景包括表格理解面临的结构复杂性、符号密度高、视觉退化等问题，以及现有模型在这种复杂和退化条件下表现出来的局限性。

Innovation: 
提出了一种名为TableMoE的神经符号混合专家（MoCE）架构，专门为增强多模态表格数据的结构化推理而设计。该架构包含一种创新的神经符号路由机制，该机制预测潜在的语义令牌角色（如表头、数据单元格、轴、公式）并动态地将表元素路由到专门的专家（将表转换为HTML、JSON、代码）中。为了实现有效的对齐驱动预训练，引入了大规模的TableMoE-Align数据集，该数据集包含120万份表-HTML-JSON-代码四元组，仅用于模型预训练。该研究还创立了四个基于现实世界多模态退化和结构复杂性的困难基准：WMMFinQA、WMMTatQA、WMMTabDialog 和 WMMFinanceMath。实验结果表明，TableMoE 显著优于现有最先进的模型。广泛的消融研究验证了每个核心组件的关键作用，强调了神经符号路由和结构专家对齐的至关重要性。此外，定性分析进一步展示了 TableMoE 的可解释性和增强的鲁棒性，突出了结合神经符号推理对多模态表格理解的有效性。

Conclusion: 
实验结果表明，TableMoE 在处理复杂和退化的多模态表格数据方面显著优于现有最先进的模型。通过广泛的消融研究和定性分析，验证了每个核心组件的贡献，并强调了神经符号路由和结构专家对齐的关键作用。TableMoE 的可解释性和增强的鲁棒性进一步证明了结合神经符号推理在多模态表格理解中的有效性。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21393</guid><pubDate>Fri, 27 Jun 2025 02:26:50 +0800</pubDate></item><item><title>712. cs.AI-超越反应性安全：通过长时仿真实现风险aware大语言模型对齐</title><link>https://arxiv.org/pdf/2506.20949</link><description>Background: 
随着基于语言模型的代理在高影响社会决策方面（如公共政策和医疗健康）的作用日益增强，确保这些代理产生有益影响，需要深入理解其建议的广泛影响。已经提出了一个概念验证框架，用于预测模型生成的建议如何在宏观尺度上随着时间推移传播，从而加强了对齐的一致性。此外，提出了一个包含100个间接危害场景的数据集，用于评估模型预见看似无害用户提示可能导致的非预期不良后果的能力。

Innovation: 
提出了一种通过长时仿真来实现风险感知的大语言模型对齐的概念验证框架，以及一个包含100个间接危害场景的数据集，用于评估模型预见不良后果的能力。该研究不仅在新数据集上取得了超过20%的改进，而且在现有的安全基准测试（AdvBench, SafeRLHF, WildGuardMix）上的平均胜率超过70%，表明其在安全性更高的代理方向的潜力巨大。

Conclusion: 
本研究通过提出一种长时仿真框架和一个风险感知数据集，提供了一种更安全的代理方法。这种方法在新的数据集和现有基准测试中的性能表现出色，为未来研究提供了新的思路。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20949</guid><pubDate>Fri, 27 Jun 2025 02:26:48 +0800</pubDate></item><item><title>713. cs.AI-The Singapore Consensus on Global AI Safety Research Priorities</title><link>https://arxiv.org/pdf/2506.20702</link><description>Background: 
随着人工智能（AI）能力的快速提升及其自主性增强，它们在带来转变潜力的同时也引发了对确保AI安全性的广泛讨论。确保AI是可信、可靠且安全的生态系统变得至关重要，这有助于人们有信心地接纳AI，同时最大化创新空间并避免反效果。为了支持这一领域，一个名为‘2025新加坡人工智能会议（SCAI）：国际科学交流关于AI安全’的活动计划通过汇集不同地理区域的AI科学家，来确定和总结AI安全性研究的优先级。该报告基于Yoshua Bengio主持并得到33个政府支持的国际AI安全性报告，采用多层次防御模型，将AI安全性研究领域分为三个类别：创建可信AI系统的挑战（开发）、评估其风险的挑战（评估）及在部署后监控和干预的挑战（控制）。

Innovation: 
报告采用多层次防御模型来组织AI安全性研究领域，将研究领域分为三大类：创建可信AI系统的挑战（开发）、评估其风险的挑战（评估）、及在部署后监控和干预的挑战（控制），强调系统性地保障AI的安全性。这为AI安全性研究提供了清晰的框架和优先级指南。

Conclusion: 
该报告通过汇集全球AI科学家的智慧，为国际AI安全性研究确定了优先级，为确保AI的安全性提出了多层次防御策略，有助于建立一个更加可信的AI生态系统，促进全球AI的安全进步。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.20702</guid><pubDate>Fri, 27 Jun 2025 02:26:43 +0800</pubDate></item><item><title>714. cs.AI-IXAII：决策支持系统中的一种互动可解释人工智能界面</title><link>https://arxiv.org/pdf/2506.21310</link><description>Background: 
尽管已经开发了多种事后解释的人工智能方法，但大多数方法都是静态的，忽略了用户视角，限制了它们对目标受众的有效性。研究表明，当前的解释方法往往缺乏灵活性和互动性，无法充分满足用户的需要。因此，研究者们致力于开发一种能够更好地与用户交互，并提供多种解释和可视化选项的系统来提高透明度和解释的实用性。

Innovation: 
本文提出了IXAII（Interactive Explainable Artificial Intelligence Interface），这是一种互动的可解释人工智能系统，它综合了LIME、SHAP、Anchors和DiCE四种解释方法，提供给五类不同的用户定制化的视角，让用户能够对其收到的解释的细节和呈现形式进行选择。IXAII通过结合解释人工智能方法、互动性和实用实施，提出了新型的人工智能解释实践和人机交互视角。

Conclusion: 
通过专家和普通用户的试用评估，研究结果表明，IXAII能够提供多样化的解释和丰富的可视化选项，被认为有助于增加透明度。IXAII的开发为人工智能解释实践和人机交互提供了新的视角，通过弥合可解释方法、交互性和实用实施之间的差距，推动了该领域的进展。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21310</guid><pubDate>Fri, 27 Jun 2025 02:26:42 +0800</pubDate></item><item><title>715. cs.AI-全球意识规划叙事增强大型视觉语言模型规划者</title><link>https://arxiv.org/pdf/2506.21230</link><description>Background: 
大型视觉语言模型（LVLMs）在执行任务时展现出潜力，但在处理陌生环境和多步骤目标的复杂场景时存在困难。当前的方法依赖于脱离环境的认知模仿学习，这导致模型难以处理情境感知的指令，在长时间交互中依赖于辅助线索而非视觉推理。本文针对这一问题，提出了一个增强框架World-Aware Planning Narrative Enhancement (WAP)，通过引入视觉外观建模、空间推理、功能抽象和语义接地四种认知能力，来使LVLMs拥有全面的环境理解能力。该框架通过仅使用原始视觉观察并通过梯度学习进行模型开发和评估。

Innovation: 
本文提出了一种名为World-Aware Planning Narrative Enhancement (WAP)的新框架，该框架通过视觉外观建模、空间推理、功能抽象和语义接地四种认知能力，增强了LVLMs的环境理解能力。同时，该框架通过仅使用原始视觉观察并通过梯度学习进行模型开发和评估，克服了传统方法的局限性。实验结果表明，该方法显著提高了任务成功率，特别是在常识推理和长时间规划方面。增强后的开源模型在EB-ALFRED基准测试中表现出色，远超诸如GPT-4o和Claude-3.5-Sonnet等专有系统。

Conclusion: 
WAP框架显著提高了利用LVLMs进行后续任务的规划能力，特别是在处理陌生环境和多步骤目标的复杂场景时。通过增强模型的认知能力，WAP使得LVLMs能够更深入地理解和应对各种环境，提高任务的成功率和效果。&amp;lt;a href='https://github.com/nituchao/latest_arxiv_analyze_ai' &amp;gt;&amp;lt;img src='https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss' alt='Visitors' title='Visitors'&amp;gt;&amp;lt;/a&amp;gt;</description><guid isPermaLink="true">https://arxiv.org/pdf/2506.21230</guid><pubDate>Fri, 27 Jun 2025 02:26:41 +0800</pubDate></item></channel></rss>