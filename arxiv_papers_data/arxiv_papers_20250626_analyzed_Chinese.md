# 1. `cs.AI` - Prover Agent: 基于代理的框架形式化数学证明 [PDF](https://arxiv.org/pdf/2506.19923), [HTML](https://arxiv.org/abs/2506.19923)
## Authors
Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai
## Background
本文提出了Prover Agent，这是一种结合了大规模语言模型（LLMs）与形式化证明助手Lean的新颖AI代理，用于自动化定理证明。背景信息包括现有的方法大多依赖于大规模语言模型和需要大量的样本预算，Prover Agent旨在提供一个有效的解决策略。
## Innovation
Prover Agent结合了非正式推理LLM、形式化证明模型以及来自Lean的反馈，并能生成辅助引理来辅助发现整体证明策略。它在MiniF2F基准上实现了86.1%的成功率，是使用小型语言模型（SLMs）方法中新的最先进的方法，且使用样本预算远低于先前的方法。
## Conclusion
本文还展示了生成的引理如何有助于解决复杂问题的案例研究。Prover Agent为形式化数学证明的自动化提供了一种新的代理框架，并在小样本预算条件下取得了显著的成功，打破了之前的记录。
# 2. `cs.AI` - 使用低延迟可解释AI模型实现可信的实时决策支持系统 [PDF](https://arxiv.org/pdf/2506.20018), [HTML](https://arxiv.org/abs/2506.20018)
## Authors
Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao
## Background
本文探讨了利用低延迟AI模型的实时决策支持系统，结合了整体AI驱动决策工具的最新进展、边缘IoT技术的集成以及人类与AI高效协作的方法。研究重点在于当资源有限时，大型语言模型如何辅助决策。同时，文章也审视了技术进步（如DeLLMa、模型压缩方法和边缘设备分析改进）的影响，并讨论了资源有限和需要灵活框架的问题。
## Innovation
本文提出了利用低延迟可解释AI模型的实时决策支持系统，并探讨了如何通过大型语言模型在资源有限的情况下辅助决策。研究还考察了包括DeLLMa、模型压缩方法和边缘设备分析改进在内的技术发展，并指出了更有效和灵活的AI支持系统的开发机会。
## Conclusion
本文的研究为这一快速变化领域的未来突破奠定了基础，强调了AI如何重新塑造实时决策支持系统。它为AI支持系统的开发策略和应用领域提供了实用的观点，指出了更多的高效和灵活的发展机会。
# 3. `cs.AI` - 准确且节能：本地检索增强生成模型在医疗任务中超越商用大型语言模型 [PDF](https://arxiv.org/pdf/2506.20009), [HTML](https://arxiv.org/abs/2506.20009)
## Authors
Konstantinos Vrettos,Michail E. Klontzas
## Background
在医疗保健领域采用人工智能（AI）的日益普及引发了对其环境和伦理影响的关注。商用大型语言模型（LLMs），如ChatGPT和DeepSeek，需要大量资源，而医疗用途中的这些系统的使用引发了关于患者隐私和安全的关键问题。
## Innovation
开发了一种可定制的检索增强生成（RAG）框架，用于医疗任务，该框架监测其能源使用和二氧化碳排放，并以此为基础创建了基于多种开源LLMs的RAG。结果表明，定制RAG模型在准确性和能源消耗方面优于商用模型。llama3.1-RAG模型在准确性和能效方面表现最佳，实现了58.5%的最高准确率，并且在每千瓦时的性能和二氧化碳排放方面也表现出色。
## Conclusion
研究表明，本地LLMs可以用于开发在医疗任务中优于商业在线LLMs的RAGs，同时对环境影响较小。我们的模块化框架促进可持续AI开发，减少电力消耗，与联合国可持续发展目标保持一致。
# 4. `cs.AI` - AI Copilots for Reproducibility in Science: A Case Study [PDF](https://arxiv.org/pdf/2506.20130), [HTML](https://arxiv.org/abs/2506.20130)
## Authors
Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil
## Background
开放科学倡议旨在提高研究成果的透明度、可访问性和可重用性，但确保已发表的研究结果能够独立重现仍然是一个持续的挑战。现有研究中的计算复现性问题需要新的解决方案，以便更高效、透明地进行科学交流和验证。
## Innovation
该论文介绍了OpenPub，这是一个基于AI的平台，通过针对开箱即用的任务提供一系列模块化协助功能，支持研究人员、审稿人和读者。特别引入了复现性CoPilot，该工具能够分析论文、代码和辅助材料，生成结构化的Jupyter Notebook和推荐，以促进计算性复现性。AI驱动的复现性CoPilot系统能够系统地检测导致不复现的因素，包括缺少超参数、未记录的预处理步骤、不完整或不可访问的数据集，从而显著减少了复现时间，提高了复现要素的覆盖率。
## Conclusion
该研究证明了AI驱动工具在减轻复现性努力负担方面的有效性，这些工具能够有助于更透明和可验证的科学交流。模块化CoPilot架构也为扩展AI辅助到其他开箱即用的科学目标提供了基础，超出了复现性的范围。
# 5. `cs.AI` - 使用多臂老虎机优化进行上下文归因 [PDF](https://arxiv.org/pdf/2506.19977), [HTML](https://arxiv.org/abs/2506.19977)
## Authors
Deng Pan,Keerthiram Murugesan,Nuno Moniz,Nitesh Chawla
## Background
理解和识别提取上下文中的哪些部分对大型语言模型生成的答案有贡献，对于构建可解释和值得信赖的生成式问答系统至关重要。现有的方法如SHAP等传统扰动归因方法虽然能够提供一定程度的解释性，但计算成本高，不够高效。因此，研究如何利用有效的策略来探索大量上下文组合，同时保持高归因准确度，成为亟待解决的问题。
## Innovation
提出了一种新的框架，将上下文归因问题形式化为组合多臂老虎机（CMAB）问题。每个上下文片段被视为一个臂，采用组合豪斯霍尔德采样（CTS）策略在有限的查询预算下有效探索大量上下文子集的空间。这种方法基于归一化令牌似然性来定义奖励函数，捕捉特定上下文片段子集对原始模型响应的支持程度，同时通过利用片段相关性的后验估计动态平衡探索和利用，相较于传统的均匀采样归因方法显著提高了查询效率，同时保持高归因准确度。
## Conclusion
在多种数据集和预训练模型上的实验表明，该方法在使用较少的模型查询数量的情况下，可以实现与传统方法相当的归因质量。
# 6. `cs.AI` - 语言模型通过语言模型进行建模 [PDF](https://arxiv.org/pdf/2506.20249), [HTML](https://arxiv.org/abs/2506.20249)
## Authors
Junyan Cheng,Peter Clark,Kyle Richardson
## Background
研究如何利用大型语言模型（LLMs）来模拟发现新型语言模型架构的过程，借鉴了实际研究中的多阶段流程，涵盖从构想到设计实现再到训练验证等阶段。通过借鉴规模律的思想，该研究提出了一种Ladder of Scales方法，该方法能够在不同规模的模型中进行设计、审查、实现和验证，并使用一种新颖的遗传编程作为研究背后的技术支撑，以提高设计生成的成功率和效率。
## Innovation
提出了一种多智能体LLMs方法，称为Genesys，该方法通过模拟传统研究过程，并应用Ladder of Scales方法，以及使用遗传编程作为技术基础，来自动发现和验证新型语言模型架构。研究发现，在成功设计生成方面，遗传编程相比常见的直接提示生成工作流程有显著优势。实验结果显示，发现的设计中有且86%被成功验证，并且某些设计在基准测试中表现优于已知架构，显示出潜在的应用价值。
## Conclusion
Genesys系统展示了通过大规模语言模型自动化发现新型架构的有效性，并提供了关于设计有效的自主发现系统的更广泛的见解。特别是在设计生成的成功率和设计效率方面，遗传编程工作流程显示出优点。
# 7. `cs.AI` - DiaLLMs: EHR增强的临床对话系统以实现临床检测推荐和诊断预测 [PDF](https://arxiv.org/pdf/2506.20059), [HTML](https://arxiv.org/abs/2506.20059)
## Authors
Weijieying Ren,Tianxiang Zhao,Lei Wang,Tianchun Wang,Vasant Honavar
## Background
近年来，大型语言模型（LLMs）在医疗咨询方面取得了显著进展。但是，现有的医疗LLMs忽视了电子健康记录（EHR）的关键作用，主要集中在诊断建议上，这限制了它们在临床中的应用。现有模型集中在诊断方案上，而未充分考虑EHR数据对临床决策（如检查推荐、结果解释和诊断预测）的重要性，这可能不符合实际临床实践的需求。
## Innovation
本文提出了DiaLLM，这是第一个将异构EHR数据整合到临床对话中的医疗LLM。DiaLLM通过设计临床测试参考（CTR）策略将每个临床代码映射到其对应的描述，并将测试结果分类为“正常”或“异常”，从而构造出基于临床的对话。此外，该系统还采用了强化学习框架来收集证据和实现自动化诊断，引入了拒绝采样策略以减少冗余，提高探索效率。确认奖励和敏感分类诊断奖励的设计则进一步指导准确的诊断预测。
## Conclusion
大规模实验结果表明，DiaLLM在临床检测推荐和诊断预测方面超越了基线模型。这一研究展示了将EHR数据整合到生成模型中以实现更贴近实际临床实践的医疗服务的潜力。
# 8. `cs.AI` - QHackBench: 使用Pennylane黑客马拉松挑战基准大型语言模型进行量子代码生成 [PDF](https://arxiv.org/pdf/2506.20008), [HTML](https://arxiv.org/abs/2506.20008)
## Authors
Abdul Basit,Minghao Shao,Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique
## Background
近期大型语言模型（LLMs）在代码生成方面表现出色，但在量子计算领域的应用尚处于初步阶段。本文利用实际挑战性问题——来自量子黑客马拉松(QHack)的PennyLane量子代码生成任务，对LLMs进行基准测试，以探索它们在量子计算中的潜力。本文介绍了QHackBench，一个基于QHack竞赛的新颖基准数据集，评估了模型在简洁的提示和检索增强生成（RAG）下的表现。
## Innovation
文章引入了QHackBench，用于评估LLMs的基准，特别针对量子代码生成。文章的创新点包括：1）使用来自具体竞赛的挑战任务构建数据集；2）采用结构化的评估框架，评估语义正确性、语法正确性及执行成功率；3）提出一种多智能体的评估流水线，逐步改进错误解，提高执行成功率；4）公开释放QHackBench数据集、评估框架和实验结果，促进对人工智能辅助量子编程的研究进一步发展。
## Conclusion
研究结果表明，增强检索的模型与标准提示生成方法在复杂的量子算法上有着相似的表现。此外，多智能体评估流水线的成功应用进一步提高了执行成功的比率。为推动更多研究，作者承诺公开分享QHackBench数据集、评估框架和实验结果，为后续研究提供支持。
# 9. `cs.AI` - 企业大型语言模型评估基准 [PDF](https://arxiv.org/pdf/2506.20274), [HTML](https://arxiv.org/abs/2506.20274)
## Authors
Liya Wang,David Yi,Damien Jose,John Passarelli,James Gao,Jordan Leventis,Kang Li
## Background
大型语言模型（LLMs）在提升AI工具生产力方面表现出潜力，但现有基准如大规模多任务语言理解（MMLU）未能充分评估企业特有的任务复杂性。该研究提出了一种基于布卢姆分类法的14任务框架，以全面评估企业在实际应用场景中的LLM能力。这旨在解决嘈杂数据和成本高昂的注释带来的挑战，通过构建LLM作为标签器、LLM作为裁判，以及校正检索增强生成（CRAG）的可扩展管道，形成一个稳健的9700样本基准。
## Innovation
研究提出了一种基于布卢姆分类法的14任务框架，以评估企业在实际应用场景中的LLM能力。开发了一种可扩展的管道，结合使用LLM作为标签器、LLM作为裁判，以及校正检索增强生成（CRAG），从而形成一个稳健的9700样本基准。这有助于解决嘈杂数据和成本高昂的注释问题。
## Conclusion
研究显示开源模型如DeepSeek R1在推理任务中与商业模型相当，但在基于判断的场景中落后，可能是因为过度思考。企业基准揭示了关键的企业性能差距，并提供了优化模型的实际建议。这项工作为企业提供了一个量身定制评估的蓝图，推动了实际LLM部署的进步。
# 10. `cs.AI` - Mobile-R1：基于任务级奖励的交互式强化学习在VLM基于移动代理中的应用 [PDF](https://arxiv.org/pdf/2506.20332), [HTML](https://arxiv.org/abs/2506.20332)
## Authors
Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng
## Background
基于视觉语言模型的移动代理已经具备了理解和执行复杂指令以及优化行动输出的能力，可以通过思考和推理来进行优化，并借助强化学习（如Group Relative Policy Optimization (GRPO)）进行训练。然而，现有的研究主要集中在离线强化学习训练或使用操作级奖励的在线优化，这限制了代理与环境的动态交互能力。这种做法常导致代理陷入局部最优，削弱了其探索和纠正错误行为的能力。
## Innovation
提出了一种名为Mobile-R1的方法，采用基于任务级奖励的交互式多轮次强化学习训练框架。该方法包括三个阶段：初始格式微调、通过操作级奖励进行单步骤在线训练以及基于多轮路径的任务级奖励在线训练。这种方法旨在增强Mobile-R1的探索和错误修正能力，从而显著提高其性能。
## Conclusion
我们构建了一个包含28个中国应用和24,521个高质量手动注释的新数据集，并建立了一个包含500条路径的新基准。我们还将源代码、数据集、基准和模型权重全部开源。
# 11. `cs.AI` - 使用推理类型探索进行表格特征发现 [PDF](https://arxiv.org/pdf/2506.20357), [HTML](https://arxiv.org/abs/2506.20357)
## Authors
Sungwon Han,Sungkyu Park,Seungeon Lee
## Background
在机器学习中，特征工程对于表数据依然是一项关键且具有挑战性的步骤。最近，大型语言模型（LLMs）被用于通过利用其庞大的知识库来自动生成新的特征。然而，现有的基于LLM的方法往往产生过于简单或者重复的特征，部分原因是由于LLM在选择转换时存在固有的偏差，以及在生成过程中缺乏结构化的推理指导。
## Innovation
本文提出了一种名为REFeat的新方法，该方法通过利用多种类型的推理来引导LLM发现多样且富有信息性的特征，以此来引导特征生成的过程。实验证明，相比于现有方法，我们的方法不仅能平均获得更高的预测准确性，还能发现更多样且有意义的特征。这表明将丰富的推理范式和自适应策略选择融入到基于LLM的特征发现中有巨大的潜力，尤其是对于表格数据而言。
## Conclusion
我们的研究结果证明，通过融入丰富的推理范式和自适应策略选择，可以提升基于LLM的特征发现的性能和特征质量，这意味着这种方法在处理表格数据时具有高度的潜力。
# 12. `cs.AI` - 前置指定的大语言模型表现出类似人类的动机性推理 [PDF](https://arxiv.org/pdf/2506.20020), [HTML](https://arxiv.org/abs/2506.20020)
## Authors
Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan
## Background
人类的推理易受身份保护等内在动机的影响，这些动机会损害理性决策和判断。集体层面上的动机性推理在涉及人类驱动的气候变化或疫苗安全性等重要议题的辩论中可能对社会有害，进一步加剧政治分化。已有研究表明，大语言模型（LLMs）也容易受到人类认知偏见的影响，但LLMs根据身份一致的结果进行选择性推理的程度尚未得到充分研究。本研究通过给LLMs分配8种不同的人格，以探讨集体敏感性是否影响其动机性推理。通过两种人类实验中使用的推理任务测试了8种LLMs（开源和专有），结果显示，在涉及身份验证的情况下，带有人格的LLMs的验证性识别能力降低多达9%。特别是针对枪支控制的科学证据，带有特定政治人格的LLMs在结果与自身人格一致时，评估的准确性提高了90%。基于提示的去偏见方法在缓解这些影响方面效果有限。总体而言，本研究发现表明，前置指定的LLMs具有类似人类的动机性推理，且很难通过常见的去偏见提示来减轻这种影响，从而引发了对LLMs和人类中出现身份一致推理的加剧的担忧。
## Innovation
本研究首次通过给LLMs分配不同的人格，发现LLMs表现出类似人类的动机性推理，尤其是在识别虚假信息和评估科学证据方面的差距。同时，发现基于提示的去偏见方法在缓解这些效应方面效果有限，这对于理解和解决大语言模型中的动机性推理问题具有重要意义。
## Conclusion
本研究的结果表明，前置指定的LLMs表现出类似人类的动机性推理，并且难以通过常规的去偏见提示来缓解这种效应。这引发对LLMs和人类中可能加剧的身份一致推理问题的担忧。
# 13. `cs.AI` - Paladin-mini：一种在实际场景中表现卓越的紧凑高效事实验证模型 [PDF](https://arxiv.org/pdf/2506.20384), [HTML](https://arxiv.org/abs/2506.20384)
## Authors
Dror Ivry,Oran Nahum
## Background
本文旨在解决给定上下文中验证断言的问题。具体而言，这意味着在一个文档和一个断言中，文档中至少包含一条支持该断言的证据。为了应对这一挑战，该文介绍了两个重要的贡献：一个名为Paladin-mini的小型（参数量3.8B）开源分类器模型和一个新的评估数据集——grounding-benchmark，用于评估关键推理任务的表现。Paladin-mini被设计用于在实际场景中实现稳健的性能。
## Innovation
本文的创新之处在于提出了一个名为Paladin-mini的紧凑高效分类器模型，该模型专门用于在实际场景中实现稳健的认证表现。此外，还设计了一个新的评估数据集grounding-benchmark，用于评估模型在关键推理任务上的表现。
## Conclusion
实验结果显示，Paladin-mini在基准测试中优于当前的最先进技术，并且其结果是清晰且可重复的。
# 14. `cs.AI` - 智能电动汽车下的 ride 和配送服务：利用双向充电实现利润优化 [PDF](https://arxiv.org/pdf/2506.20401), [HTML](https://arxiv.org/abs/2506.20401)
## Authors
Jinchun Du,Bojie Shen,Muhammad Aamir Cheema,Adel N. Toosi
## Background
随着电动汽车（EVs）的普及，如网约车配送服务等现代服务系统越来越多地将电动汽车纳入运营。与传统车辆相比，电动汽车常常具有较短的行驶范围，因此在执行订单时需要仔细考虑充电问题。近年来，Vehicle-to-Grid (V2G) 技术的发展使得电动汽车能够向电网反馈能量，这为服务业带来了新的盈利机会和复杂性。
## Innovation
本文提出了一种新的问题定义——结合V2G技术的电动汽车定向问题（EVOP-V2G），即决定电动车辆司机在接受客户请求或订单时，以及何时何地进行充电或放电的混合整数规划（MIP）模型。文章还提出了两种近似最优元启发式算法：一种进化算法（EA），另一种基于大邻域搜索（LNS）。实验结果表明，与基准方法相比，该方法能将司机的利润翻倍，同时在小型实例上保持接近最优性能，在大型实例上表现出优秀的扩展性。
## Conclusion
本文的研究成果为未来的电动汽车基础的智能移动系统铺平了一条前景广阔的道路，这些系统不仅能够提高司机的盈利，还能积极支持能源电网。
# 15. `cs.AI` - 混合神经细胞自动机：一种用于生长建模和自组织的随机框架 [PDF](https://arxiv.org/pdf/2506.20486), [HTML](https://arxiv.org/abs/2506.20486)
## Authors
Salvatore Milite,Giulio Caravagna,Andrea Sottoriva
## Background
神经细胞自动机（NCAs）是一种有前景的新方法，用于模拟自组织过程，具有在生命科学中的潜在应用。然而，它们的确定性性质限制了其捕捉现实世界生物学和物理系统的随机性的能力。
## Innovation
提出了混合神经细胞自动机（MNCAs），这是一个新颖的框架，结合了混合模型的概念到NCA范式中。通过结合概率规则分配与内在噪音，MNCAs可以模拟多样的局部行为，并重现生物学过程中观察到的随机动态。此外，MNCAs在三个关键领域展示了其有效性：（1）组织生长和分化的人工模拟，（2）图像形态发生鲁棒性，（3）显微图像分割。结果表明，MNCAs对扰动具有更高的鲁棒性，更好地重现真实的生物生长模式，并提供可解释的规则分割。
## Conclusion
这些发现将MNCAs定位为建模随机动力系统和研究自生长过程的有前景工具。
# 16. `cs.AI` - 利用 fine-tuning 和提示工程技术构建用于应对可持续蛋白质生产挑战的多代理AI系统 [PDF](https://arxiv.org/pdf/2506.20598), [HTML](https://arxiv.org/abs/2506.20598)
## Authors
Alexander D. Kalian,Jaewook Lee,Stefan P. Johannesson,Lennart Otte,Christer Hogstrand,Miao Guo
## Background
全球对可持续蛋白质来源的需求增加，这加快了对能够快速处理和合成特定领域科学知识的智能工具的需求。这项研究正是在这一背景下进行的，旨在提供一种支持可持续蛋白质生产研究的多代理人工智能（AI）框架，初始重点是微生物蛋白质来源。系统设计包括两个基于GPT的大型语言模型（LLM）代理：文献检索代理和信息抽取代理，分别负责检索和处理与特定微生物菌株相关的科学文献，提取生物和化学信息。
## Innovation
该研究探索了两种不同的优化方法，即微调和提示工程技术，以提高信息抽取代理的性能。结果显示，这两种方法都能显著提高信息抽取代理的性能，尤其在微调方法中达到了更高的均值余弦相似度分数（$text{≥0.94}$），与理想输出文本更加接近。此外，还开发并发布了用户界面以启用多代理AI系统的使用，并初步探索了基于化学安全性的搜索能力。
## Conclusion
该多代理AI系统已被应用于微生物蛋白质来源的研究，展示了其在改进信息提取并增强研究效率方面的能力。未来研究将进一步探索系统的其他应用领域，如其它类型的可持续蛋白质生产和更复杂的多代理系统集成。
# 17. `cs.AI` - GymPN: 用于过程管理系统中决策的库 [PDF](https://arxiv.org/pdf/2506.20404), [HTML](https://arxiv.org/abs/2506.20404)
## Authors
Riccardo Lo Bianco,Willem van Jaarsveld,Remco Dijkman
## Background
过程管理系统支持组织中的关键决策，包括决定执行哪些任务、何时执行以及将任务分派给谁。合适的软件工具对于优化组织的工作分配决策至关重要。本文介绍了一个名为GymPN的软件库，它利用深度强化学习支持业务流程中的最优决策。GymPN建立在先前支持流程任务分配的研究之上，引入了两个关键创新：部分流程可观测性和能够建模业务流程中的多个决策。这些新颖的特性解决了以前工作的基本限制，从而能够更好地反映现实的流程决策。
## Innovation
GymPN引入了两个关键创新：部分流程可观测性和能够建模业务流程中的多个决策，这解决了以前工作的基本限制，使得更好地反映现实的流程决策成为可能。
## Conclusion
我们在八个典型的业务流程决策问题模式上评估了库的效果，显示GymPN可以轻松建模所需的问题，并学习最优的决策策略。
# 18. `cs.AI` - CogGen: 一种基于编程视频的以学习者为中心的生成式人工智能教学架构 [PDF](https://arxiv.org/pdf/2506.20600), [HTML](https://arxiv.org/abs/2506.20600)
## Authors
Wengxi Li,Roy Pea,Nick Haber,Hari Subramonyam
## Background
该论文背景在于当前编程教育视频质量参差不齐，缺少个性化、互动性教学支持，亟需一种能够将编程视频转化为互动、适应性强学习体验的技术框架。在此背景下，研究团队提出了CogGen架构，旨在通过认知学徒制框架下的自适应生成AI辅导系统，结合学生建模与教学内容，改进编程视频教育方式，提升教学效果和学生学习体验。
## Innovation
CogGen架构的创新之处在于：（1）通过学习目标对编程视频进行分段，增强教学内容的连贯性和结构化；（2）采用认知学徒制策略构建对话式辅导引擎，提升互动性和教学效果；（3）使用贝叶斯知识追踪（Bayesian Knowledge Tracing）构建学生模型，动态调整教学策略以适应不同学习者需求，实现个性化教学。通过技术评估和消融实验，验证了该架构在教学视频分割和教学内容适配上具有良好的效果和一致性，并证明了每个组件的重要性。
## Conclusion
CogGen架构代表了一种基于生成式人工智能的新型教学模型，显示出其在编程视频教育中的潜力和应用价值。该工作不仅提高了AI辅助教学的效果，还强调了结构化学生建模与互动AI对话在教育智能化中的重要性，为未来的教育技术提供了新的思路和方法。
# 19. `cs.AI` - 增强和利用PETSc知识库的AI助手 [PDF](https://arxiv.org/pdf/2506.20608), [HTML](https://arxiv.org/abs/2506.20608)
## Authors
Barry Smith,Junchao Zhang,Hong Zhang,Lois Curfman McInnes,Murat Keceli,Archit Vasan,Satish Balay,Toby Isaac,Le Chen,Venkatram Vishwanath
## Background
生成式AI，尤其是通过大型语言模型（LLMs），正在改变技术知识的获取、重用和扩展方式。PETSc是一个在高性能科学计算中广泛使用的数值库，其三十余年的开发过程中积累了丰富但碎片化的知识库，涵盖源代码、文档、邮件列表、GitLab问题、Discord对话、技术论文等内容。然而，其中大部分知识仍然保持非正式状态，对用户和新开发人员不可用。
## Innovation
为了更有效地激活和利用这一知识库，PETSc团队开始构建一个由LLM驱动的系统，结合PETSc内容和定制的LLM工具——包括检索增强生成（RAG）、重排名算法和聊天机器人——以协助用户、支持开发人员并提出对正式文档的更新建议。该研究特别关注使用RAG和重排名处理PETSc特定信息，以及对不同LLM和嵌入模型的评估方法，并设计用户界面。研究成果利用阿贡领导计算设施资源分析如何利用LLM提升数值软件的研发和使用，初期重点关注可扩展的Krylov求解器。
## Conclusion
我们希望通过建立一个可扩展的知识中心AI框架，为科学软件提供可扩展支持、丰富文档和增强的工作流程，以加速科学发现。未来的方向是将该系统扩展为一个更加稳健且动态发展的平台，进一步推动软件生态系统的进步。
# 20. `cs.AI` - 实际安全关键驾驶场景中增强案例推理的大型语言模型决策框架 [PDF](https://arxiv.org/pdf/2506.20531), [HTML](https://arxiv.org/abs/2506.20531)
## Authors
Wenbin Gan,Minh-Son Dao,Koji Zettsu
## Background
在安全关键场景中进行驾驶需要迅速、情境意识强的决策，这些决策需基于情境理解和经验推理。大型语言模型（LLMs）因其实用的强大泛化推理能力为这种决策提供了一个有前景的基础。然而，它们直接应用于自动驾驶领域仍然受到领域适应挑战、情境接地和缺乏在动态、高风险环境中做出可靠和可解释决策所需的经验知识的限制。为了填补这一空白，本论文提出了一种增强案例推理的大型语言模型（CBR-LLM）框架，用于处理复杂的风险场景中的规避机动决策。该方法结合了来自仪表板视频输入的语义场景理解和相关过去驾驶案例的检索，使LLMs能够生成既敏感又符合人类行为的机动建议。在多个开源LLM上的实验表明，我们的框架改善了决策准确性、解释质量和与人类专家行为的一致性。针对不同类型的风险的风险感知提示策略进一步提高了性能，而基于相似性的案例检索在引导现场学习方面始终优于随机抽样。通过案例研究进一步表明，该框架在复杂的实际条件中表现出色，突显了其作为智能驾驶系统适应性和可信决策支持工具的潜力。
## Innovation
提出了一种增强案例推理的大型语言模型框架（CBR-LLM），结合了语义场景理解和相关过去驾驶案例的检索，使LLMs能够生成既敏感又符合人类行为的机动建议。风险感知提示策略进一步提高了性能，而基于相似性的案例检索在引导现场学习方面始终优于随机抽样。
## Conclusion
我们的框架改善了决策准确性、解释质量和与人类专家行为的一致性。通过案例研究进一步表明，该框架在复杂的实际条件中表现出色，为智能驾驶系统的决策支持提供了一种适应性强且可信的方法。
# 21. `cs.AI` - 向可验证的安全模型权重发布方案迈进 [PDF](https://arxiv.org/pdf/2506.19874), [HTML](https://arxiv.org/abs/2506.19874)
## Authors
Xing Yang,Bingtao Wang,Yuhao Wang,Zimo Ji,Terry Jingchen Zhang,Wenyuan Jiang
## Background
近期的安全权重释放方案声称能够使开源模型的分发既保护模型的所有权，又能防止滥用，但这些方法缺乏严格的安全保障，并仅提供非正式的安全保证。之前的研究成果引发灵感，我们通过引入具体的安全定义来形式化权重发布方案的安全性，并通过研究TaylorMLP等知名方案来展示这些定义的作用。研究表明，TaylorMLP存在漏洞，能够被参数提取，从而说明它未能实现其非正式的安全目标。
## Innovation
我们通过引入具体的security definitions来形式化权重发布方案的安全性，并以此为蓝本，揭示了TaylorMLP存在的漏洞，证明其未能实现其宣称的安全目标。这给予未来权重发布方案的设计和评估以指导，同时呼吁机器学习和安全社区进行严谨的研究。
## Conclusion
这项研究希望推动机器学习和安全保障社区进行严格的研究，并提供未来权重发布方案设计和评估的蓝图。
# 22. `cs.AI` - 工程中的知觉 [PDF](https://arxiv.org/pdf/2506.20504), [HTML](https://arxiv.org/abs/2506.20504)
## Authors
Konstantin Demin,Taylor Webb,Eric Elmoznino,Hakwan Lau
## Background
本文探讨了一个对于人工智能（AI）而言有用的知觉定义，并强调了知觉在机器中的实现需要具体的、功能性的计算术语来描述，同时还必须反映一种内在的“主观”特质，这超出了仅仅具备感知内容编码的一般能力。提出的知觉功能概念要求某些感官信号需具备坚定的存在性和质量特征。通过介绍当前技术下的潜在实现方法来进一步具体化这一定义。这对于理解如何使人工智能代理功能上具备知觉也具有重要意义，并有助于避免无意中创建这样的代理，或者至少能够及时识别已经创建了这样的代理。
## Innovation
提出了一个结合了功能性和主观性的知觉定义，并强调了感官信号的坚定存在性和质量特征对于实现知觉的重要性。此外，本文探讨了利用当前技术实现这一方法的具体途径，为理解和设计功能上的知觉提供了新的视角和思路。
## Conclusion
理解和实现这一功能性的知觉定义可以帮助避免无意中创造具有知觉能力的代理，或者能及时意识到这样的代理已经被创造出来。这对于指导未来人工智能的设计和开发具有重要意义。
# 23. `cs.AI` - 探索前沿大语言模型在核能研究中的能力 [PDF](https://arxiv.org/pdf/2506.19863), [HTML](https://arxiv.org/abs/2506.19863)
## Authors
Ahmed Almeldein,Mohammed Alnaggar,Rick Archibald,Tom Beck,Arpan Biswas,Rike Bostelmann,Wes Brewer,Chris Bryan,Christopher Calle,Cihangir Celik,Rajni Chahal,Jong Youl Choi,Arindam Chowdhury,Mark Cianciosa,Franklin Curtis,Gregory Davidson,Sebastian De Pascuale,Lisa Fassino,Ana Gainaru,Yashika Ghai,Luke Gibson,Qian Gong,Christopher Greulich,Scott Greenwood,Cory Hauck,Ehab Hassan,Rinkle Juneja,Soyoung Kang,Scott Klasky,Atul Kumar,Vineet Kumar,Paul Laiu,Calvin Lear,Yan-Ru Lin,Jono McConnell,Furkan Oz,Anant Raj,Pradeep Ramuhalli,Marie Romedenne,Samantha Sabatino,José Salcedo-Pérez,Nathan D. See,Arpan Sircar,Punam Thankur,Tim Younkin,Xiao-Ying Yu,Prashant Jain,Tom Evans,Prasanna Balaprakash
## Background
在橡树岭国家实验室举办的AI在核能领域的研讨会上，评估了大型语言模型（LLMs）对核聚变和核裂变研究的潜在加速作用。来自不同领域的14个科研团队在一天内使用ChatGPT、Gemini、Claude及其他AI模型，探索了多项核科学挑战。这些应用包括为聚变反应堆控制开发基础模型，自动化蒙特卡洛模拟，预测材料老化以及设计先进的反应堆实验计划。团队通过结构化的流程结合提示工程、深度研究能力和迭代改进，生成假设、原型代码和研究策略。研究表明，LLMs在早期探索、文献综合和流程设计方面表现出色，成功识别了研究缺口，并生成了可行的实验框架。然而，研究也发现了新型材料设计、高级模型和模拟代码生成以及需专家验证的领域特定细节等方面的显著局限。成功的关键在于专家主导的提示工程和将AI作为物理方法的辅助工具而非替代品。这证实了AI在核能研究中的潜力，通过快速迭代和跨学科整合加速研究进展，但也强调了需要针对核能领域的精心数据集、工作流自动化和专门模型开发的需求。这些结果为将AI工具整合到核科学工作流程提供了路线图，有可能缩短开发周期，促进更安全和高效的核能系统，同时维护严格的科学标准
## Innovation
本次研讨会展示了大型语言模型在核能研究中应用的创新实例，包括利用这些模型进行早期探索、文献综合和流程设计。成功的关键在于提示工程的专家主导策略和将AI作为物理方法的补充工具而非替代品。成功应用还可通过跨学科集成和快速迭代来提高核能研究的效率与安全。此外，强调了在核能领域中建立专业数据集、工作流自动化和专门模型开发的重要性，这些成果为未来的研究提供了一个明确的路线图
## Conclusion
研讨会的结果证实了AI在核能研究中的潜力，尤其是通过快速迭代和跨学科整合加速研究进展。然而，也揭示了大型语言模型在处理特殊材料设计、高级代码生成和详细领域特定细节方面的局限。未来的研究需要专注于建立针对核能领域的数据集、自动化工作流和专门模型开发，以进一步整合AI工具，促进更安全、高效的核能系统开发，同时保持高标准的科学研究。
# 24. `cs.AI` - 基于社区驱动的机器学习工程代理 [PDF](https://arxiv.org/pdf/2506.20640), [HTML](https://arxiv.org/abs/2506.20640)
## Authors
Sijie Li,Weiwei Sun,Shanda Li,Ameet Talwalkar,Yiming Yang
## Background
现有的基于大规模语言模型的机器学习代理在自动化机器学习研究中展现出巨大前景，但通常这些代理独立于更广泛的机器学习研究社区运行，错过了通过知识共享获得洞见和贡献的机会。为解决这一问题，本文引入了MLE-Live框架，旨在评估代理与仿真Kaggle研究社区互动和利用集体知识的能力。在此基础上，本文提出了CoMind，一种在社区场景下擅长知识交流和开发新颖解决方案的新型代理。CoMind在MLE-Live上实现了最先进的性能，并且在四项正在进行的Kaggle竞赛中，平均优于79.2%的人类对手。
## Innovation
本文的创新点在于提出了MLE-Live框架，用于评估代理与仿真Kaggle研究社区互动及利用集体知识的能力，并在此基础上开发了CoMind代理，能在社区中更有效地进行知识交流和开发新颖解决方案。
## Conclusion
CoMind代理在MLE-Live框架下的表现超过了最先进的技术水平，并且在四个Kaggle竞赛中，平均超过79.2%的人类对手，展示了在社区驱动的机器学习工程代理领域的显著优势。
# 25. `cs.AI` - 利用AI进行欺诈检测和能源市场稳定性的区块链保障能源交易安全 [PDF](https://arxiv.org/pdf/2506.19870), [HTML](https://arxiv.org/abs/2506.19870)
## Authors
Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan
## Background
美国的能源市场因去中心化的电网和点对点交易而发生了变化，但这些发展也带来了安全性和交易真实性方面的新挑战。该研究旨在为美国去中心化的能源市场建立一个安全、智能且高效的能源交易系统。为此，研究将区块链技术和人工智能技术结合使用，以解决分布式能源市场中的安全、欺诈检测和市场可靠性等长期性难题。
## Innovation
该研究的创新之处在于将区块链技术和人工智能技术结合，提出了一个具有区块链层和人工智能层的系统架构，通过应用具有高度分类性能的机器学习模型来识别去中心化市场中的能源交易欺诈，从而保障能源交易安全，提高能源市场智能性和稳定性.
## Conclusion
通过上述系统架构，本研究成功地提出了一种可应用于去中心化能源市场的安全且高效的技术方案，该方案能够进行全面的欺诈检测，提高市场品质和可靠性，促进去中心化能源市场的健康发展。
# 26. `cs.AI` - 可扩展和成本效益高的自动生成模板基分子 [PDF](https://arxiv.org/pdf/2506.19865), [HTML](https://arxiv.org/abs/2506.19865)
## Authors
Piotr Gaiński,Oussama Boussif,Andrei Rekesh,Dmytro Shevchuk,Ali Parviz,Mike Tyers,Robert A. Batey,Michał Koziarski
## Background
基于模板的分子生成为药物设计提供了有前景的方法，通过使用预定义的反应模板和构建块确保生成的化合物可以合成。然而，由于合成成本、大规模构建块库的处理以及小片段集的有效利用等方面的挑战，目前的方法面临着限制。因此，需要一种解决方案来解决这些核心问题，以实现高效的分子生成和多样性的最大化。
## Innovation
本文提出了一种名为Recursive Cost Guidance的后向策略框架，结合了辅助机器学习模型来近似合成成本和可行性，引导生成向低成本合成路径发展。同时，还开发了Dynamic Library机制，通过重用高奖励的中间状态来构建完整的合成树，优化了较小构建块库的表现。这些创新显著提高了解决方案的成本效益、分子多样性和质量，特别是在与Exploitation Penalty（探索惩罚机制）结合使用时，可以平衡探索和利用之间的权衡。
## Conclusion
本文的方法在模板基分子生成方面达到了最先进的结果。
# 27. `cs.AI` - 网络流量中的稳健异常检测：CICIDS2017上的机器学习模型评估 [PDF](https://arxiv.org/pdf/2506.19877), [HTML](https://arxiv.org/abs/2506.19877)
## Authors
Zhaoyang Xu,Yunbo Liu
## Background
构建有效且泛化的安全解决方案仍然依赖于识别适合的入侵检测系统（IDS）机器学习范式。本文在CICIDS2017数据集上对比分析了四种代表性模型在两种场景下的表现，以探讨不同模型在已知攻击和未知威胁检测方面的能力。
## Innovation
本文通过控制实验比较了多层感知机（MLP）、一维卷积神经网络（CNN）、单类支持向量机（OCSVM）和局部异常因子（LOF）在CICIDS2017数据集上的表现，并研究了这些模型在已知攻击和新型未知威胁检测中的适用性。不同模型在准确率、召回率及误报率之间的权衡提供了一种选择IDS模型的方法，尤其是在动态网络环境中。
## Conclusion
在已知攻击类型检测中，监督的MLP和CNN模型表现出高准确度，但对新型攻击的召回率显著下降。无监督的LOF模型在未知威胁的总体准确性和召回率方面表现较好，但代价是误报率增加。OCSVM在精确率和召回率之间取得了较好的平衡，表现出针对两种场景中的稳健检测能力。这些发现为在动态网络环境中选择IDS模型提供了实用指导。
# 28. `cs.AI` - 基于生成对抗网络的医疗保险理赔欺诈检测攻击方法 [PDF](https://arxiv.org/pdf/2506.19871), [HTML](https://arxiv.org/abs/2506.19871)
## Authors
Yining Pang,Chenghan Li
## Background
保险欺诈检测在现代保险服务中起到了关键作用，通过智能化和数字化的监控提升管理效率和防范欺诈行为。尽管人工智能和机器学习算法在检测欺诈索赔方面表现出色，但缺乏标准化的防御机制使得当前系统容易受到新兴的对抗性威胁。
## Innovation
本文提出了一种基于生成对抗网络（GAN）的方法，用于对欺诈检测系统进行对抗攻击。研究结果表明，攻击者即使不知道训练数据或内部模型细节，也能以99%的成功率生成被分类为合法的欺诈案例，并通过微调真实保险记录和索赔数据增加欺诈风险，从而可能绕过受损的欺诈检测系统。
## Conclusion
这些研究发现强调了增强保险欺诈检测模型抵御对抗性操纵的迫切需求，以确保不同保险系统的稳定性和可靠性。
# 29. `cs.AI` - The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind [PDF](https://arxiv.org/pdf/2506.20664), [HTML](https://arxiv.org/abs/2506.20664)
## Authors
Andrei Lupu,Timon Willi,Jakob Foerster
## Background
随着大型语言模型（LLMs）获得更多的自主能力，它们将在复杂的多智能体场景中导航，与人类用户和其他智能体进行合作或竞争互动。这需要新的推理能力，其中最主要的是心智理论（ToM），即推理解其他智能体的“心理”状态的能力。然而，ToM和其他多智能体能力在LLMs中的理解非常缺乏，因为现有的基准存在范围窄、数据泄漏、饱和和缺乏互动性等问题。为此，提出了一种名为Decrypto的游戏基准，该基准借鉴了认知科学、计算语用学和多智能体强化学习。该基准在所有其他方面尽可能简单，消除了其他基准中常见的混淆因素。据我们所知，它也是第一个为设计互动心智理论实验构建的平台。我们通过全面的经验验证、鲁棒性研究和人机跨互动实验验证了该基准设计。结果显示，LLM的游戏能力落后于人类和简单的词嵌入基线。我们还在Decrypto中创建了两个经典认知科学实验的变体，以评估三个关键的心智理论能力。令人惊讶的是，最先进的推理模型在这几项任务中的表现明显不如其较旧的版本，表明Decrypto填补了当前推理和心智理论评估的关键缺口，并为更好的人造智能铺平了道路
## Innovation
提出了一种名为Decrypto的游戏基准，该基准借鉴了认知科学、计算语用学和多智能体强化学习。Decrypto旨在消除其他基准中的混淆因素，并且是第一个为设计互动的心智理论实验构建的平台。通过验证这些基准设计，研究发现了最先进的推理模型在某些心智理论任务上表现不如其较旧版本的现象，这表明Decrypto较好地解决了当前推理和心智理论评估的缺陷
## Conclusion
研究发现，最先进的语言模型在游戏能力和心智理论任务上的表现不如简单的词嵌入基线和更旧的模型版本。这证明了Decrypto填补了当前推理和心智理论评估的重要空白，并为开发更好的人工智能铺平了道路。
# 30. `cs.AI` - Machine Learning Conferences Should Establish a 'Refutations and Critiques' Track [PDF](https://arxiv.org/pdf/2506.19882), [HTML](https://arxiv.org/abs/2506.19882)
## Authors
Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho
## Background
机器学习领域的快速发展导致了大量论文的涌现，但在一定程度上也带来了错误、误导、有缺陷甚至虚假的研究被接受的风险。这些问题主要是由于同行评审的局限性导致的。
## Innovation
本文提出，在机器学习会议上设立一个专门的‘反驳和批评’（Refutations and Critiques, R&C）轨道，为批判性挑战先前研究的研究提供一个高度专业和可信的平台，促进动态自我纠正的研究生态系统。
## Conclusion
我们得出结论，机器学习会议应该创建官方和可信的机制，以帮助机器学习研究自我纠正。
# 31. `cs.AI` - 使用深度学习进行物理引导的放射治疗计划 [PDF](https://arxiv.org/pdf/2506.19880), [HTML](https://arxiv.org/abs/2506.19880)
## Authors
Stefanos Achlatis,Efstratios Gavves,Jan-Jakob Sonke
## Background
放射治疗（RT）是癌症治疗的关键手段，其中体积可调弧形放疗（VMAT）通过在旋转机架过程中动态调整多人挡块（MLC）位置和剂量单位（MU）来提高剂量分布的适形性。适应性放射治疗需要频繁修改治疗计划以适应解剖结构的变化，这需要高效的时间解决方案。深度学习提供了自动化的潜力。为此，我们提出了一种两阶段的物理引导的深度学习管道来进行放射治疗计划。在第一阶段，我们的网络以直接监督的方式进行训练，用治疗计划参数，包括MLC和MU值作为输入。在第二阶段，我们通过预测的三维剂量分布进一步引入监督信号，将物理指导纳入训练过程中。研究对象为133名使用2-弧均匀VMAT协议对前列腺癌患者进行62 Gy剂量治疗的病例。研究结果表明，该方法在3D U-Net和UNETR两种架构下的表现一致，生产的治疗计划与临床真相高度吻合。该方法在PTV处的D95%和V95%分别为0.42 +/- 1.83 Gy和-0.22 +/- 1.87%，并减少了对危险器官的辐射暴露。
## Innovation
本研究创新性地提出了一种两阶段的物理引导的深度学习管道，能够在保证治疗效果的同时，减少对危险器官的辐射剂量，并通过直接监督和基于预测的3D剂量分布的监督信号进行训练，使剂量分布更为准确，治疗计划更加高效。
## Conclusion
研究结果表明，基于深度学习的物理引导放射治疗计划方法能够生成与临床实际情况高度吻合的治疗计划，减少辐射暴露并确保治疗的准确性。这种物理引导的深度学习在放射治疗规划中有巨大的应用潜力。
# 32. `cs.AI` - 使用演讲者嵌入提高间歇性和移动演讲者跟踪 [PDF](https://arxiv.org/pdf/2506.19875), [HTML](https://arxiv.org/abs/2506.19875)
## Authors
Taous Iatariene(MULTISPEECH),Can Cui(MULTISPEECH),Alexandre Guérin,Romain Serizel(MULTISPEECH)
## Background
演讲者跟踪方法通常依赖于空间观察来为时间上分配一致的跟踪身份。这在断续和移动说话人的场景中受到了限制，即说话人有可能在不活跃时改变位置，导致不连续的空间轨迹。
## Innovation
本文提出了一种简单的方法，使用演讲者嵌入来进行身份重新分配，以解决上述问题。通过跟踪步骤和多通道音频信号提供的轨迹相关信息，利用波束形成增强人声信号，进而计算出演讲者嵌入，并基于注册池重新分配新的跟踪身份。
## Conclusion
研究结果表明，基于演讲者嵌入的身份重新分配方法在讲话者在不活跃期间改变位置的数据集上能持续地提高神经网络和标准跟踪系统的身份分配性能，特别是在探讨波束形成和输入时长对嵌入提取的影响方面取得了显著成果。
# 33. `cs.AI` - FlightKooba: 一种快速可解释的飞行轨迹预测模型 [PDF](https://arxiv.org/pdf/2506.19885), [HTML](https://arxiv.org/abs/2506.19885)
## Authors
Jing Lu,Xuan Wu,Yizhun Tian,Songhan Fan,Yali Fang
## Background
库普曼理论是一种强大的建模工具，能够将非线性系统转换为线性表示形式，飞行轨迹预测（FTP）本身是一个复杂的非线性系统。然而，目前针对FTP任务应用库普曼理论的模型效率不高，模型可解释性是问题之一，而且库普曼算子的计算量大，导致训练时间较长。
## Innovation
本文提出了一种基于HIPPO方法、库普曼理论和控制论的状态空间方程的新建模和控制框架：FlightKooba。该框架直接从数据中构建库普曼算子，使得模型具备高可解释性，并显著减少了模块中的可训练参数数量，从而大大缩短了训练时间。实验表明，FlightKooba在时间与内存消耗方面表现出优越性（训练时间与未使用CUDA级加速的Mamba模块相近；在大多数数据集上，内存减少了超过50%，模块中的参数数量减少了十倍），基本上完成了FTP任务，为时间序列预测和控制的快速计算提供了一种新方法，开辟了新的可能性。
## Conclusion
FlightKooba框架在实现飞行轨迹预测任务时，相比现有方法，显著降低了训练时间，同时保持了模型的可解释性，并大大减少了参数数量，这为库普曼算子的快速计算提供了一种新的解决方案，开启了控制与时间序列预测结合的新篇章。
# 34. `cs.AI` - MATER: 多级声学和文本情绪表示方法在可解释语音情绪识别中的应用 [PDF](https://arxiv.org/pdf/2506.19887), [HTML](https://arxiv.org/abs/2506.19887)
## Authors
Hyo Jin Jon,Longbin Jin,Hyuntaek Jung,Hyunseo Kim,Donghun Min,Eun Yi Kim
## Background
本文介绍了作者在自然条件下语音情绪识别（SERNC）挑战赛中的贡献，重点解决类别情绪识别和情绪属性预测问题，以应对自然语音的复杂性，包括被试内部和被试之间的变化性。
## Innovation
作者提出了多级声学-文本情绪表示（MATER），这是一个新的分层框架，将声学和文本特征在字、语句和嵌入层面进行整合。通过融合低级词汇和声学线索与高级语境化表示，MATER 能够有效捕捉精细的语调变化和语义细微差别。此外，作者还引入了一种基于不确定性意识的集成策略，以缓解标注者间的一致性问题，增强在模棱两可的情绪表达中的稳健性。
## Conclusion
MATER 在两项任务中的宏 F1 得分为 41.01%，均方差为 0.5928，并在情绪色调预测中取得了 0.6941 的均方差值，位列第二。
# 35. `cs.AI` - DualEquiNet：一种用于大型生物分子的双空间层次守恒网络 [PDF](https://arxiv.org/pdf/2506.19862), [HTML](https://arxiv.org/abs/2506.19862)
## Authors
Junjie Xu,Jiahao Zhang,Mangal Prakash,Xiang Zhang,Suhang Wang
## Background
尽管几何图形神经网络（GNNs）尊重E(3)对称性，在小分子模型上表现出色，但在应用于如RNA和蛋白质等大型生物分子时，它们面临扩展性和表示性方面的挑战。现有系统需要能够同时捕捉细粒度的原子间相互作用、不同空间区域组件间的长程依赖关系以及生物相关的层次结构。例如，原子形成残基，残基形成更高级别的领域。现有的几何GNNs通常只在欧几里得空间或球谐空间中操作，因此无法同时捕捉细规模的原子细节和用于模拟大型生物分子多层次结构所需的长程且对称感知的依赖关系。
## Innovation
我们引入了DualEquiNet，这是一种在欧几里得和球谐空间中构建互补表示的层次守恒网络，以捕捉局部几何和全局对称感知特征。DualEquiNet使用双向跨空间消息传递和一种新的跨空间交互池化机制，逐级地将原子特征聚合为生物意义单位，例如残基，从而实现大型生物分子系统的高效且具有表现力的多层次建模。DualEquiNet在多个现有的RNA属性预测和蛋白质建模基准测试中达到了最佳效果，并在两个新引入的3D结构基准测试中优于先前的方法，显示了其在多种大型生物分子建模任务上的广泛有效性。
## Conclusion
DualEquiNet在多个RNA属性预测和蛋白质建模基准测试上达到了最先进的性能，并在两个新引入的3D结构基准测试中超过了先前的方法，证明了其在不同类型大型生物分子建模任务中的广泛应用潜力。
# 36. `cs.AI` - STIMULUS: 实现快速收敛和低样本复杂度的随机多目标学习 [PDF](https://arxiv.org/pdf/2506.19883), [HTML](https://arxiv.org/abs/2506.19883)
## Authors
Zhuqing Liu,Chaosheng Dong,Michinari Momma,Simone Shao,Shaoyuan Xu,Yan Gao,Haibo Yang,Jia Liu
## Background
近年来，多目标优化（MOO）因其在机器学习、运筹学和工程等领域的广泛应用而受到关注。然而，MOO算法的设计仍在初级阶段，许多现有的MOO方法在收敛率和样本复杂性表现不佳。针对这一挑战，本文提出了一种称为STIMULUS（随机路径集成多梯度递归估计器）的新算法，这是一种改进MOO问题求解的新型且鲁棒的方法。STIMULUS通过引入一个简单而强大的递归框架，以改进收敛性能并降低样本复杂性。在此基础上，引入了STIMULUS-M这一增强版本，该版本包含动量项，进一步加快了收敛速度。本文在非凸和强凸设置下分别建立了所提方法的收敛率，并提供了其状态最优的样本复杂性分析。另外，为了解决STIMULUS和STIMULUS-M的全梯度周期性要求，还提出了具有自适应批量处理版本的增强版本STIMULUS+/STIMULUS-M+并进行了理论分析。
## Innovation
本文提出了一种称为STIMULUS的新算法，通过引入简单而强大的递归框架更新随机梯度估计，从而改进了收敛性能并降低了样本复杂性。此外，还提出了STIMULUS-M增强版本，进一步加快了收敛速度。本文还提供了非凸和强凸设置下的收敛率，以及状态最优的样本复杂性分析。最后，提出了自适应批量处理版本STIMULUS+/STIMULUS-M+以满足全梯度周期性要求，并进行了理论分析。
## Conclusion
本文通过提出STIMULUS算法解决了MOO领域的挑战，改进了算法的收敛性能和样本复杂性，并提供了增强版本以进一步优化性能。
# 37. `cs.AI` - Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models [PDF](https://arxiv.org/pdf/2506.19889), [HTML](https://arxiv.org/abs/2506.19889)
## Authors
Wanli Peng,Xin Chen,Hang Fu,XinYu He,Xue Yiming,Juan Wen
## Background
大型语言模型（LLMs）的发展已深刻影响了社会，同时也引发了新的安全关切。Staab等人揭示了一种隐私泄露攻击（PVA），由于LLMs出色的推理能力，这种攻击造成了严重的个人隐私问题。现有的防御方法主要通过使用LLMs匿名化输入查询来进行防御，这需要大量推理时间且无法达到满意的防御效果。直接拒绝PVA查询虽然看似有效，但防御方法一旦曝光，会促使攻击者改进策略，从而降低防御效果。
## Innovation
本文提出了一种基于LLMs检索混淆生成（RCG）的新防御范式，能够高效而隐蔽地抵御PVA。该方法首先设计了一个同义词提示以诱导LLMs重新编写攻击查询中的“用户评论”，构建一个受干扰的数据库；然后提出了一种最不相关的检索策略从受干扰的数据库中检索所需用户数据；将“数据评论”替换为检索到的用户数据，形成一个被防御的查询，使得对手接收到的是错误的个人属性信息，攻击失败。该方法在两个数据集和八种常用的大语言模型上进行了广泛实验，以全面评估其可行性和优越性。
## Conclusion
本文提出了一种基于检索混淆生成的新型防御方法，能够高效而隐蔽地抵御大型语言模型中的隐私泄露攻击。通过设计同义词提示和提出最不相关的检索策略，该方法重建用户数据并反馈给攻击者错误的个人属性信息，从而成功防御PVA。实验结果表明该方法具有高度的可行性和优越性。
# 38. `cs.AI` - 因果感知智能QoE优化：适应性关键帧提取在VR交互中的应用 [PDF](https://arxiv.org/pdf/2506.19890), [HTML](https://arxiv.org/abs/2506.19890)
## Authors
Ziru Zhang,Jiadong Yu,Danny H.K. Tsang
## Background
在多用户虚拟现实（VR）交互中，优化体验质量（QoE）需要在超低延迟、高保真运动同步和资源分配公平性之间取得微妙的平衡。现有方法通常忽略分配带宽、CPU频率和用户感知之间的因果关系，这限制了QoE的提升。本研究旨在打破这一局限，提出一种结合适应性关键帧提取与因果感知强化学习（RL）的智能框架，以最大化QoE。首先构建了一个结合感知敏感性、注意力驱动优先级和运动重构精度的新QoE度量，然后将QoE优化问题建模为混合整数规划（MIP）任务，优化关键帧比例、带宽和计算资源，并在视线公平性约束下共同优化。
## Innovation
该研究提出了一种结合适应性关键帧提取与因果感知强化学习（RL）的全新框架。首次使用韦伯-费希纳定律构建了一个新的QoE度量，综合考虑了感知敏感性、注意力驱动的优先级和运动重构的准确性。进一步将QoE优化问题建模为混合整数规划（MIP）任务，并引入了部分状态因果深度确定性策略梯度（PS-CDDPG）方法，这是一种结合因果影响检测与深度确定性策略梯度（DDPG）的策略，通过利用因果信息提高了训练效率。
## Conclusion
实验结果表明，该框架显著降低了交互延迟，提升了QoE，并保持了公平性，其性能优于基准方法。
# 39. `cs.AI` - 正交软剪枝以实现高效类别遗忘 [PDF](https://arxiv.org/pdf/2506.19891), [HTML](https://arxiv.org/abs/2506.19891)
## Authors
Qinghui Gong,Xue Yang,Xiaohu Tang
## Background
机器遗忘的目标是从预训练的神经网络中选择性地移除特定类别的知识，以满足GDPR等隐私法规的要求。现有的方法通常在遗忘速度和保留预测准确性之间存在权衡，要么计算开销高，要么保留类别的性能损失大。
## Innovation
本文提出了一种新颖的基于正交卷积核正则化的类感知软剪枝框架，通过在训练过程中施加正交性约束，这种框架可以实现快速且精确的遗忘，响应时间达到毫秒级别。该方法通过激活差分分析高效地识别了类特定的通道，同时去关联卷积滤波器并分离特征表示，从而实现了稳定剪枝、迅速执行、目标类别完全遗忘以及保留数据上最小的准确性损失。
## Conclusion
在多个架构和数据集上的广泛评估表明，该框架提供了在毫秒级响应时间内稳定剪枝的高效方案，能够大幅提升遗忘速度，显著减少成员推理攻击风险，相比现有最佳方法性能提升数量级。这为真实时机器遗忘提供了高效的、可实施的解决方案，在MLaaS场景中具有重要意义。
# 40. `cs.AI` - 使用XAI方法解释用于电价预测的深度神经网络模型 [PDF](https://arxiv.org/pdf/2506.19894), [HTML](https://arxiv.org/abs/2506.19894)
## Authors
Antoine Pesenti,Aidan OSullivan
## Background
电力市场极为复杂，涉及众多相互作用和复杂的依赖关系，这使得理解市场内部运作及价格驱动因素变得困难。虽然已经开发了经济计量方法，但白盒模型的效果不如深度神经网络模型（DNN）。本研究旨在使用DNN预测电价，并通过解释性人工智能（XAI）方法了解驱动市场电价动力因素。研究人员希望建立对不同电力市场运作机制的更深入理解。为此，研究采用了SHAP和梯度等解释性方法，并结合热图等可视化技术来分析五个电力市场中各种特征的行为和贡献。
## Innovation
引入了SSHAP值和SSHAP线的概念，以增强高维表格模型的复杂表示。
## Conclusion
通过使用深度神经网络和解释性人工智能技术，研究人员增加了对如何不同电力市场运作机制的理解。
# 41. `cs.AI` - 在AIGC任务中，基于蒸馏的知识对齐方法对生成语义通信的赋能 [PDF](https://arxiv.org/pdf/2506.19893), [HTML](https://arxiv.org/abs/2506.19893)
## Authors
Jingzhi Hu,Geoffrey Ye Li
## Background
随着AI生成内容（AIGC）的急剧增长，将这些内容从云端送达边缘设备和移动用户会产生大量的网络流量。生成语义通信（GSC）通过传输高度紧凑的信息，即提示文本和潜在表示，而不是高维度的AIGC数据，提供了一个有希望的解决方案。然而，GSC仍依赖于云端生成AI和边缘设备/用户之间的知识对齐，以及无线传输知识和实际信道知识之间的对齐，这仍然是一个挑战。因此，本文提出了一种名为DeKA-g的知识蒸馏对齐算法，旨在解决这一问题。
## Innovation
DeKA-g算法包含了两种创新方法：基于元词的知识蒸馏（MAKD）和可变码率分组信噪比适配（VGSA）。MAKD使用优化的元词以提高知识蒸馏的效率，而VGSA则能高效地适应多种压缩率和信噪比范围。实验结果表明，DeKA-g能够提高边缘生成图像与云端生成图像之间的知识对齐程度44%，并具有比基线更高的116%的压缩率适应效率，同时在低信噪比条件下提高了28%的性能。
## Conclusion
DeKA-g算法通过云生成AI的知识蒸馏，并结合边缘适配，能够有效提高生成语义通信中的知识对齐效率，特别是在压缩率和信噪比适应性方面。
# 42. `cs.AI` - 基于层间最近邻的不确定性量化框架 [PDF](https://arxiv.org/pdf/2506.19895), [HTML](https://arxiv.org/abs/2506.19895)
## Authors
Miguel N. Font,José L. Jorro-Aragoneses,Carlos M. Alaíz
## Background
神经网络在难以检测模式或创建逻辑模型的复杂问题上表现出了高精度，但在医疗诊断或自动驾驶等高风险领域，它们有时会给出错误的解决方案。为了检测和缓解这些问题，需要测量决策的不确定性。本文介绍了一种新的后处理框架，该框架基于查询在每层具有相似激活向量的训练案例来衡量决策的不确定性，并提出了两种新的度量标准：决策变化和层不确定性，用于捕捉邻近类分布的变化情况。
## Innovation
提出了一种基于层间最近邻的不确定性量化框架，该框架通过检索具有相似激活向量的训练案例来衡量决策的不确定性，并提出了两种新的度量标准：决策变化和层不确定性，以更有效地捕捉邻近类分布的变化情况，从而提高不确定性估计的准确性，特别是在具有挑战性的分类任务中。相比基于softmax的置信度度量，它们表现更优。
## Conclusion
该方法在CIFAR-10和MNIST两个数据集上的分类模型上进行了评估，结果表明，提出的度量标准可以增强不确定性估计，特别是在具有挑战性的分类任务中表现更佳，优于基于softmax的置信度度量。
# 43. `cs.AI` - CycleDistill：使用循环蒸馏大语言模型实现机器翻译的自我强化 [PDF](https://arxiv.org/pdf/2506.19952), [HTML](https://arxiv.org/abs/2506.19952)
## Authors
Deepon Halder,Thanmay Jayakumar,Raj Dabre
## Background
尽管大语言模型（LLMs）能够进行少量样本的机器翻译（MT），但在高质量机器翻译方面，它们往往不如专门针对平行语料库进行训练的MT系统。平行语料库对于低资源语言尤为重要，但由于资源限制，这些语料库往往稀缺甚至不存在。本文探讨了通过利用LLMs和少量样本的MT生成合成平行语料库，然后使用这些数据进一步微调生成MT的模型的方法。这种方法不需要大量的平行语料库，仅需1到4个少量示例即可实现高质量的机器翻译，尤其是在对三种印度语言进行实验时，相较于少量样本的基线模型，在第一轮中平均能够提高20-30个chrF评分点。此外，研究了在蒸馏过程中利用softmax激活的影响，发现翻译质量略有提高。
## Innovation
CycleDistill是一种利用大语言模型和少量样本翻译以自强化方式构建高质量机器翻译系统的迭代方法。该方法仅需1到4个少量示例就可以从单语语料库生成合成平行语料库，且在对三种印度语言进行实验时，相较基线模型在第一轮中平均提高了20-30个chrF评分点。此外，研究了在蒸馏过程中利用softmax激活的影响，发现翻译质量有轻微提高。
## Conclusion
CycleDistill在无需大量平行语料库的情况下，通过迭代生成合成平行语料库并利用这些数据进一步微调模型，可以显著提升机器翻译质量。此外，在少量示例的情况下，可以提升基线模型的性能，并在softmax激活的帮助下微调蒸馏过程，进一步提高翻译质量。
# 44. `cs.AI` - MNN-AECS：通过自适应核心选择优化移动设备上大语言模型解码的能耗 [PDF](https://arxiv.org/pdf/2506.19884), [HTML](https://arxiv.org/abs/2506.19884)
## Authors
Zhengxiang Huang,Chaoyue Niu,Zhaode Wang,Jiarui Xue,Hanming Zhang,Yugang Wang,Zewei Xin,Xiaotang Jiang,Chengfei Lv,Fan Wu,Guihai Chen
## Background
随着对大语言模型（LLM）在设备端推理需求的增长，能量效率已经成为一个主要问题，特别是在电池供电的移动设备上。现有研究大多集中在加快预填充阶段，而忽视了能耗问题。解码阶段因内存限制而成为能耗的主要来源。因此，如何在保证解码速度的同时有效降低能耗成为一个亟待解决的问题。
## Innovation
引入了一种自适应能源中心核心选择（AECS）方法，并将其集成到MNN中，形成了一个不需要内核权限或操作系统修改的首个引擎级系统解决方案——MNN-AECS，用于高效的大语言模型解码。MNN-AECS通过动态选择低功耗CPU核心来减少LLM解码能耗。测试结果表明，与原版MNN相比，MNN-AECS在所有7种设备和4个数据集上的平均节能率为23%。与其他引擎相比，如this http URL, executorch, mllm, 和 MediaPipe，MNN-AECS的平均节能率在39%到78%之间，平均加速比在12%到363%之间，显示了其高效性。
## Conclusion
MNN-AECS能够在不影响解码速度的情况下显著降低能耗，首次提出了一种无需特殊权限就能有效降低移动设备上大语言模型解码能耗的系统级解决方案。
# 45. `cs.AI` - LLMs能在代码切分过程中取代人类吗？ [PDF](https://arxiv.org/pdf/2506.19897), [HTML](https://arxiv.org/abs/2506.19897)
## Authors
Christopher Glasz,Emily Escamilla,Eric O. Scott,Anand Patel,Jacob Zimmer,Colin Diggs,Michael Doyle,Scott Rosen,Nitin Naik,Justin F. Brunelle,Samruddhi Thaker,Parthav Poudel,Arun Sridharan,Amit Madan,Doug Wendt,William Macke,Thomas Schill
## Background
大型语言模型（LLMs）已成为计算机科学中的关键工具，尤其适用于代码理解和生成的任务。然而，现有的研究未解决政府应用代码特有的挑战，如这些代码多使用过时语言（如MUMPS或汇编语言代码）编写，且整体代码长度超出当前商用LLMs的上下文窗口大小。此外，这些模型主要是针对现代编程语言进行训练和测试，对于理解过时语言的能力尚不清楚，需要通过实证研究加以验证。面向政府的遗产软件代码难以直接处理，因此本论文探讨了LLMs在现代化MUMPS和ALC语言代码的应用，特别是集中于输入限制下的代码切分方法，以优化生成模块摘要评论的流程。评估不同LLMs（如GPT-4o、Claude 3 Sonnet、Mixtral和Llama 3）生成文档质量的影响，发现LLMs能够选择接近于人类专家的分割点，且其生成的分割评论比人工生成的更为准确和有用。
## Innovation
本研究首次深入探讨了LLMs如何应对政府遗产代码特有的挑战，并且开发了多种代码切分方法以优化文档生成过程，显著提升了文档的质量和实用性。研究发现LLMs在代码切分方面表现出色，甚至超越人类，由此可见输入调整和代码切分对文档生成的重要性，并为后续研究和人工智能在代码现代化的应用提供了新的视角和方法。
## Conclusion
研究表明，LLMs能够适合作为人类在LLM辅助代码现代化过程中代码分割的合理替代品，通过合适的方法可以显著提高代码现代化过程中文档生成的质量和效率，推荐在实际应用中优先考虑使用LLMs进行代码切分和文档生成。
# 46. `cs.AI` - Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs [PDF](https://arxiv.org/pdf/2506.19967), [HTML](https://arxiv.org/abs/2506.19967)
## Authors
Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu
## Background
大型语言模型（LLMs）在语言理解和生成方面取得了显著的成就，但在基于结构化上下文和多跳信息的知识密集型推理任务上表现仍然不足。部分通过检索增强生成（RAG）来缓解这一问题，但传统RAG和GraphRAG方法往往无法捕捉知识图中节点之间的关系结构。
## Innovation
我们提出了Inference-Scaled GraphRAG，这是一种新颖的框架，通过推理时的计算缩放来增强基于LLM的图推理。该方法结合了逐步缩放的序列推理和深度链式思维图遍历，以及交错推理执行循环中采样轨迹上的多数投票的并行缩放。实验表明，我们的方法在多跳问答性能上有了显著提升，超过了传统的GraphRAG和先前的图遍历基线。这一发现表明，推理时的缩放是一种可行且架构无关的解决LLMs结构化知识推理问题的方法。
## Conclusion
我们的研究结果表明，推理时的缩放是一种可行且架构无关的解决LLMs结构化知识推理问题的方法，可显著提高多跳问答性能。
# 47. `cs.AI` - RepuNet: 在 DFL 中抵消恶意客户端的一种声誉系统 [PDF](https://arxiv.org/pdf/2506.19892), [HTML](https://arxiv.org/abs/2506.19892)
## Authors
Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán
## Background
Decentralized Federated Learning (DFL) 允许各个节点独立参与模型训练，而不依赖中心服务器。然而，这种自治性同时带来了新的安全漏洞。节点可以选择信任的伙伴参与模型聚合，恶意节点可以用各种方式破坏这种系统，如模型中毒、延迟提交模型或发送大量消息，从而负面影响系统性能。现有的解决方案通常依赖于固定的配置或额外的基础设施（如区块链），这导致了计算开销、可扩展性问题或适应性有限等问题。
## Innovation
提出了一种去中心化的声誉系统 RepuNet，它可以分层识别 DFL 中的安全威胁，并动态评估节点行为。节点在模型聚合中的影响力是根据其声誉得分进行调整的。RepuNet 被集成到 Nebula DFL 平台中，并通过使用 MNIST 和 CIFAR-10 数据集在不同的攻击强度、频率和激活间隔条件下进行了实验测试。结果显示，RepuNet 能够有效检测和缓解恶意行为，特别是在 MNIST 情境下 F1 分数超过 95%，在 CIFAR-10 情境下约为 76%。这些结果凸显了 RepuNet 在缓解 DFL 环境中的威胁方面的适应性、鲁棒性和实际潜力。
## Conclusion
实验结果表明，RepuNet 能够有效检测和缓解 DFL 中的恶意行为，特别是在 MNIST 情境下 F1 分数超过 95%，在 CIFAR-10 情境下约为 76%。这些结果展示了 RepuNet 在 DFL 环境中的适应性、鲁棒性和实际应用潜力，强调了它作为 DFL 安全基础设施的价值。
# 48. `cs.AI` - TRACED: 过渡感知的后悔近似及共学习性在环境设计中的应用 [PDF](https://arxiv.org/pdf/2506.19997), [HTML](https://arxiv.org/abs/2506.19997)
## Authors
Geonwoo Cho,Jaegyun Im,Jihwan Lee,Hojun Yi,Sejin Kim,Sundong Kim
## Background
在未见过的环境中推广深度强化学习代理仍然是一个重要挑战。一种有前景的解决方案是无监督环境设计（UED），这是一种协同演化框架，在该框架中，教师会自适应地生成具有高学习潜力的任务，而学生将从这一不断演化的课程中学得稳健的策略。现有的UED方法通常通过遗憾（即最佳性能与当前性能之间的差距，通过价值函数损失近似）来衡量学习潜力。在此基础上，我们引入了过渡预测误差作为遗憾近似中的额外项。为了捕捉训练一个任务如何影响其他任务的性能，我们进一步提出了一个轻量级指标——共学习性。通过结合这两种度量，我们提出了过渡感知的后悔近似及共学习性环境设计方法（TRACED）。实证评估表明，TRACED能够提高多基准测试中的零样本泛化能力，并且相比强大基线所需环境交互次数减少了一半。消除影响研究表明，过渡预测误差可以驱动快速的复杂度提升，而共学习性与过渡预测误差结合使用时可以带来额外的提升。这些结果展示了细化后悔近似及任务关系的显式建模在UED中用于样本高效课程设计的潜力。
## Innovation
我们引入了过渡预测误差作为后悔近似中的额外项，并提出了轻量级指标——共学习性。通过结合这两种度量，我们推出了TRACED，该方法能够提高零样本泛化能力，并减少环境交互次数。实验证明，过渡预测误差可以驱动快速的复杂度提升，而共学习性与过渡预测误差结合使用时可以带来额外的提升。
## Conclusion
这些结果表明，精细化后悔近似和任务关系的显式建模可以有效用于UE中的样本高效课程设计。
# 49. `cs.AI` - 量子神经网络在观察性 biomedical 研究中用于倾向评分估计和生存分析 [PDF](https://arxiv.org/pdf/2506.19973), [HTML](https://arxiv.org/abs/2506.19973)
## Authors
Vojtěch Novák,Ivan Zelinka,Lenka Přibylová,Lubomír Martínek
## Background
本研究探讨了量子神经网络(QNNs)在倾向评分估计中的应用，以解决比较腹腔镜和开放式手术技术在肠癌患者生存结果方面的选择偏差问题。研究使用了2001年至2009年间在奥斯特拉瓦大学医院接受治疗的1177例肠癌患者的77个变量数据集，重点在于年龄、性别、分期和体重指数四个关键协变量。研究采用了线性ZFeatureMap进行数据编码，SummedPaulis算符进行预测，并使用Covariance Matrix Adaptation Evolution Strategy (CMA-ES)进行优化，以应对噪声量子环境中的鲁棒且无梯度优化。研究还通过精确模拟、抽样和噪声硬件（FakeManhattanV2）条件下的模拟，整合了方差正则化以减轻量子测量噪声。研究结果表明，即使在模拟硬件噪声的情况下，QNNs也优于经典逻辑回归和梯度提升机，在小样本(样本量n=100时AUC可达0.750)中尤其表现出色，并且噪声建模有助于增强预测稳定性。通过优化的遗传匹配和匹配权重进行倾向评分匹配和加权，实现协变量平衡，标准化均值差异分别为0.0849和0.0869。经过校正后的生存分析显示没有显著的生存差异(P值在0.287-0.851之间)，表明未调整结果中的混杂偏差。这些结果显示了CMA-ES和噪声感知策略增强的QNNs在生物医学研究中的潜力，尤其是在小样本、高维数据集中的应用方面。
## Innovation
本研究创新地将量子神经网络应用于倾向评分估计，并采用了精确模拟、抽样模拟和噪声硬件条件下的噪声感知策略。通过Covariance Matrix Adaptation Evolution Strategy (CMA-ES)进行优化，利用量子神经网络结构处理生物医学研究中的选择偏差问题。研究表明，量子神经网络在小样本数据中表现优于传统方法，特别是在噪声环境中也能够提供稳定预测。
## Conclusion
研究结果强调了量子神经网络在改造小样本生物医学数据方面的潜力，特别是在通过CMA-ES优化和噪声感知策略的应用，改善了因果推断的准确性。这表明量子神经网络可以通过克服数据噪声和其他挑战，提升观察性研究中的倾向评分估计和生存分析。
# 50. `cs.AI` - VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration [PDF](https://arxiv.org/pdf/2506.19975), [HTML](https://arxiv.org/abs/2506.19975)
## Authors
Hang Zhang,Yuxi Zhang,Jiazheng Wang,Xiang Chen,Renjiu Hu,Xin Tian,Gaolei Li,Min Liu
## Background
最近的神经网络发展提高了变形图像注册（DIR）的速度和准确性，通过减少迭代优化的过程。然而，基于学习的方法通常面临训练数据有限、大变形处理困难和在无标签监督情况下性能不佳的问题。虽然迭代方法在这种情况下可以达到更高的准确性，但它们的速度远慢于基于学习的方法。
## Innovation
本文提出了VoxelOpt，这是一种基于离散优化的变形图像注册框架，结合了基于学习和迭代方法的优点，以提高注册准确性和运行时间间的平衡。VoxelOpt通过使用局部代价体素中的位移熵来测量每个体素的位移信号强度，不同于早期方法有三个关键方面：1. 引入了体素级自适应消息传递，低熵的体素较少受到邻居影响；2. 使用27邻域代价体的多级图像金字塔，避免了复杂性指数增长；3. 用预训练的分割基础模型代替手工特征或对比学习进行特征提取。在腹部CT注册中，这些改进使VoxelOpt在效率和准确性上都超过了领先的迭代方法，并达到了最先进的基于学习的方法的水平，这些方法使用了标签监督训练。
## Conclusion
VoxelOpt通过结合基于学习和迭代方法的优点，有效提高了腹部CT图像注册的准确性和效率，特别是在无标签监督下。同时，它提供了预训练模型的高效特征提取方法，为变形图像注册提供了一个新的解决方案。
# 51. `cs.AI` - 新视角下的量子联邦学习展开与微调 [PDF](https://arxiv.org/pdf/2506.20016), [HTML](https://arxiv.org/abs/2506.20016)
## Authors
Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel
## Background
量子联邦学习（QFL）面临着客户端异质性的重大挑战，标准聚合方法在高度异质环境中常失效，导致性能下降，甚至过拟合。现有的解决方案往往无法有效应对这些问题，从而影响了应用的广泛性和有效性，特别是在需要高精度诊断和预测的医疗和基因组学研究中表现不足，通常的准确率仅在55%左右。
## Innovation
本文提出了一种基于深度展开的新方法，使客户端能够根据其特定的训练行为自主优化超参数，如学习率和正则化因子。这种方法动态适应环境，有效防止了过拟合，确保了在高度异质环境中的稳健优化。通过在IBM量子硬件和Qiskit Aer模拟器上进行实时训练，本方法实现了90%的高准确率，显著优于传统方法55%的准确率。此外，通过自适应精调，该方法特别适用于基因表达分析和癌症检测等关键应用，提升诊断精度和预测模型。这种优化方法源于深度展开框架中的收敛性意识和可学习的优化步骤，保持了泛化能力，从而有效解决了传统QFL的核心局限性，提升了其在复杂挑战如医疗和基因组学研究中的应用性。
## Conclusion
本研究通过解决量子联邦学习的客户端异质性问题，提供了新的视角。提出的基于深度展开的方法不仅提高了准确率，还提升了模型在大规模异质数据下的泛化能力，证明了其在关键应用中的有效性。这些发现将促进量子联邦学习在医疗和基因组学研究中的进一步应用和扩展。
# 52. `cs.AI` - 基于波函数的先验模型，准确描述化学键断裂的从头算基础模型 [PDF](https://arxiv.org/pdf/2506.19960), [HTML](https://arxiv.org/abs/2506.19960)
## Authors
Adam Foster,Zeno Schätzle,P. Bernát Szabó,Lixue Cheng,Jonas Köhler,Gino Cassella,Nicholas Gao,Jiawei Li,Frank Noé,Jan Hermann
## Background
可靠描述化学键断裂仍然是量子化学中的一个主要挑战，因为解离物种的电子结构具有多参考态特性。多参考方法尤其面临巨大的计算成本问题，目前的常规做法是为每种系统都全新计算，而忽略分子间共性的电子结构。量子蒙特卡洛结合深度神经网络（深QMC）提供了通过预训练可转移波函数模型来利用这些共性的潜在解决方案，但之前这类尝试的范围有限。因此，如何有效降低量子化学计算的成本成为亟待解决的问题。
## Innovation
本文提出了一种新型可转移波函数模型Orbformer，它是在22,000个平衡和解离结构上预训练的，可以针对未知分子进行微调，从而达到了与经典多参考方法相当的准确性和成本比。Orbformer在传统的基准测试和更具有挑战性的化学键断裂及Diels-Alder反应中，是唯一一个始终能收敛到化学级精度（1 kcal/mol）的方法。这项工作使得在量子化学中实现分摊求解薛定谔方程的计算成本的理念成为可能，并将其转变为实际应用的方法。
## Conclusion
Orbformer在一系列测试中的优异表现证明了量子蒙特卡洛结合深度神经网络的潜力，能够在降低计算成本的同时保持高计算精度。这一方法为量子化学的新范式的发展奠定了基础，未来可能会在分子模拟和药物发现等领域产生重大影响。
# 53. `cs.AI` - HERCULES: 基于层次嵌入的递归聚类方法结合LLM以实现高效的总结 [PDF](https://arxiv.org/pdf/2506.19992), [HTML](https://arxiv.org/abs/2506.19992)
## Authors
Gabor Petnehazi,Bernadett Aradi
## Background
在各个模态的复杂数据集快速增长的背景下，需要更加高效的分析工具，这些工具不仅要有效地进行数据分组，还要能够为发现的结构提供易于人类理解的洞察。HERCULES算法及其Python包专门针对文本、图像和数值数据等多样化的数据类型，采用层次嵌入基递归聚类方法，分为两种表示模式：直接模式和描述模式，以支持不同类型的聚类需求。通过递归地应用k-means聚类，HERCULES从单个数据点构建层次结构，关键创新是将其与大型语言模型（LLMs）的深度集成，以生成每个层次上语义丰富的标题和描述，从而显著提高可解释性。还提供了交互式可视化工具以深入了解聚类结果。该研究通过实例展示了HERCULES在复杂数据集上的能力，并讨论其从复杂数据中提取有意义的层次知识的潜力
## Innovation
HERCULES的一大创新是将大型语言模型（LLMs）与层次嵌入基递归聚类方法结合使用，通过生成层次结构中各个层次上的语义丰富标题和描述，来显著增强聚类结果的可解释性。用户可以通过提供主题种子来引导LLM生成的摘要，进一步指导聚类流程
## Conclusion
HERCULES算法通过层次嵌入基递归聚类方法结合LLMs，展示出了从复杂数据集提取有意义的层次知识的强大能力。该算法适合处理包括文本、图像和数值数据在内的多样化数据类型，提供了直接模式和描述模式两种不同的聚类表示方法，同时支持交互式可视化工具，可以详细分析和理解聚类结果。该方法为研究和应用复杂数据集提供了新的可能性。
# 54. `cs.AI` - 具有挑战性四足运动的层次化强化学习和价值优化 [PDF](https://arxiv.org/pdf/2506.20036), [HTML](https://arxiv.org/abs/2506.20036)
## Authors
Jeremiah Coholich,Muhammad Ali Murtaza,Seth Hutchinson,Zsolt Kira
## Background
本文提出了一个新颖的层次化强化学习框架，用于在充满挑战的地形上实现四足机器人的运动。该框架包含一个两层的层次结构，高层次政策（HLP）选择低层次政策（LLP）的最优目标。LLP 通过一种在线优化过程使用已学习的价值函数进行训练，并且步态放置被提供为目标。相比于端到端的强化学习方法，实验表明该框架在不同的地形上表现更好，能够在较少碰撞的情况下获得更高的奖励。其中包括了训练过程中从未遇到的更复杂的地形。
## Innovation
该研究提出了一种层次化强化学习框架。该框架的核心创新在于不依赖额外的训练或环境样本，而是使用低层次策略的学习价值函数进行在线优化过程来操作高层次策略。这使得在复杂的地形上实现高效的四足运动成为可能。相比传统的端到端方法，该方法在性能上有所提升，特别是在碰撞管理和奖励获取方面。
## Conclusion
实验结果表明，所提出的框架显著优于端到端的强化学习方法，在不同的、更有挑战性的地形上，实现了更高的奖赏和更少的碰撞。这证明了这种层次化策略的有效性，并为实现复杂地形下的四足机器人运动提供了一种新的有效方法。
# 55. `cs.AI` - 在合作多智能体强化学习中学习双边团队形成 [PDF](https://arxiv.org/pdf/2506.20039), [HTML](https://arxiv.org/abs/2506.20039)
## Authors
Koorosh Moslemi,Chi-Guhn Lee
## Background
在多智能体强化学习（MARL）的背景下，团队形成和基于团队的学习动力学引起了广泛关注。现有研究主要集中在单边分组、预定义团队或固定人口设置上，而动态人口中算法中的双边分组选择的影响则被忽视了。
## Innovation
引入了一个框架，用于学习动态多智能体系统中的双边团队形成。通过这项研究，我们了解了双边团队形成中哪些算法特性影响策略表现和泛化能力。验证方法使用广泛采用的多智能体场景，显示出在大多数场景中具有竞争力的表现和改进的泛化能力。
## Conclusion
我们通过广泛采用的多智能体场景验证了该方法，证明了在大多数场景中具有竞争力的表现和改进的泛化能力，从而填补了现有研究的空白。
# 56. `cs.AI` - 跨层离散概念发现以解释语言模型 [PDF](https://arxiv.org/pdf/2506.20040), [HTML](https://arxiv.org/abs/2506.20040)
## Authors
Ankur Garg,Xuemin Yu,Hassan Sajjad,Samira Ebrahimi Kahou
## Background
在大型语言模型中，跨层的概念发现仍然面临挑战，因为残差流线性混合和复制信息，使得特征的演变变得模糊。现有研究主要关注单一层的神经表示，忽视了跨层叠加和由此引入的冗余。常见的分析方法要么直接分析激活模式，要么将这些表示传递给探针分类器，并将这些表示映射到一组预定义的概念上。
## Innovation
本文提出了一种名为CLVQVAE的新框架，利用矢量量化将跨层的表示映射到层内，通过这种方式将复制的残差流特征压缩为紧凑、可解释的概念向量。这种方法结合了在量化过程中基于温度的top-$k$采样与指数移动平均代码本更新，提供了对离散隐空间控制探索的同时保持代码本多样性。此外，框架还增强了通过缩放球形k-means++进行代码本初始化，通过方向相似性而不是幅度来进行聚类，更好地符合词嵌入空间中的语义结构。
## Conclusion
我们的方法通过矢量量化技术，能够更清晰地揭示大规模语言模型中跨层演变的过程，极大地提高了模型的可解释性。
# 57. `cs.AI` - LSH-DynED：基于LSH的欠采样动态集成框架用于多类别不平衡分类 [PDF](https://arxiv.org/pdf/2506.20041), [HTML](https://arxiv.org/abs/2506.20041)
## Authors
Soheil Abadifard,Fazli Can
## Background
数据流的分类，尤其是在多个类别之间分配不均衡的情况下，是机器学习中的一个关键难题，特别当处理非平稳数据流时更为棘手。虽然二类不平衡数据流分类已受到广泛关注，但针对多类别不平衡数据流的研究相对较少。有效管理动态不平衡比例是这一领域的关键挑战。因此，本文提出了一种新颖且稳健的方法，将局部敏感哈希与随机超平面投影（LSH-RHP）集成到动态集成多样化（DynED）框架中，以应对这些挑战。
## Innovation
本文提出了LSH-DynED方法，这是首次在非平稳数据流背景下的不平衡分类中应用LSH-RHP进行欠采样。该方法通过利用LSH-RHP对多数类别进行欠采样，生成平衡的训练集，提高了整体集成预测性能。LSH-DynED在Kappa和mG-Mean等有效性度量下优于其他方法，尤其在大规模高维数据集中表现良好，并能适应实际环境。
## Conclusion
通过综合实验和与15种现有先进技术的对比，LSH-DynED在处理多类别不平衡非平稳数据流方面表现出色。此外，本文还回顾了现有的针对不平衡数据流的方法，概述了关键挑战，并提供了未来工作的指导。最后，本文已在GitHub上提供了方法的实现代码，以确保结果的可重复性。
# 58. `cs.AI` - Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting [PDF](https://arxiv.org/pdf/2506.20024), [HTML](https://arxiv.org/abs/2506.20024)
## Authors
Salva Rühling Cachay,Miika Aittala,Karsten Kreis,Noah Brenowitz,Arash Vahdat,Morteza Mardani,Rose Yu
## Background
扩散模型是一种强大的工具，用于概率预测，但大多数应用于高维混沌系统的方法逐帧预测未来快照，这种方法难以建模复杂的时序依赖关系，也无法明确考虑此类系统中固有的不确定性逐步增长的问题。尽管滚动扩散框架提出了一种解决方法，即将增加噪声的预测应用于更长的预报时段，但将其与最新的高性能扩散技术整合仍是一个重大挑战。
## Innovation
本文提出了Elucidated Rolling Diffusion Models (ERDM)，这是第一个将滚动预测结构与Elucidated Diffusion Models (EDM) 的合理高效设计成功统一的框架。ERDM的关键创新点在于：(i)一种新颖的损失加权方案，重点提高模型容量在确定性和随机性过渡的中等预报时距上；(ii)使用预训练的EDM进行初始窗口的高效初始化策略；(iii)一种专门为渐进除噪中稳健的时空特征提取设计的混合序列架构。ERDM在2D Navier-Stokes模拟和EC5全球气象预报中均明显优于其他基于扩散的关键基线，包括条件自回归EDM。ERDM提供了一个灵活且强大的框架，用于处理需要建模不确定性逐步增长的基于扩散的序列生成问题。
## Conclusion
ERDM在2D Navier-Stokes模拟和ERA5全球天气预报中表现优异，展现了其在处理需要建模不确定性逐步增长的基于扩散的序列生成问题中的应用潜力，提供了一个灵活且强大的框架。
# 59. `cs.AI` - 超越自动补全：设计CopilotLens以实现透明和可解释的AI编程代理 [PDF](https://arxiv.org/pdf/2506.20062), [HTML](https://arxiv.org/abs/2506.20062)
## Authors
Runlong Ye,Zeling Zhang,Boushra Almazroua,Michael Liut
## Background
AI辅助编码器广泛用于生成代码补全，大幅提升开发者效率。然而，这些工具通常只提供建议而不解释其决策过程，导致开发者的可信度降低。这一透明度的缺失妨碍了开发者对输出代码的深入理解和合理信任建立，而CopilotLens旨在解决这一问题，它通过一个互动框架展示AI代理的决策过程，使代码补全变得透明并可解释。
## Innovation
CopilotLens是一个新颖的互动框架，将代码补全从简单的建议转变为透明化和可解释的过程。该框架通过动态的两级界面揭示了AI代理的决策过程，从高层次的计划到具体的代码环境，从而提供了更加清晰的解释，助力构建注重理性的未来代理代码助手。
## Conclusion
CopilotLens为其后的代理代码助手设计提供了一个清晰的框架，强调透明理性的表达相较于快速建议的重要性，促进深层次的理解和更稳健的人机协作。
# 60. `cs.AI` - 使用二元优化和图学习的多代理人操作多样计划的自动生成 [PDF](https://arxiv.org/pdf/2506.20031), [HTML](https://arxiv.org/abs/2506.20031)
## Authors
Prithvi Poddar,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury
## Background
在灾难响应、搜救和军事任务中，涉及多代理的操作需要自动化的流程来支持行动计划（COA）的制定。环境变化（如雨雪、封锁等）会改变行动预期表现，因此需要多样化的COA池。同时，代理能力的差异（包括人类机组和自主系统）提供了实际的机会和计算上的挑战给计划过程。
## Innovation
提出了一个新的理论框架和计算工具箱来生成多样化的COA池，适合软任务-代理兼容性的变化。核心是将任务空间和COA池表示为图抽象，量化其多样性。使用遗传算法进行（顺序不敏感）的任务分配，以最大化COA池内的多样性，并最大化代理任务映射的一致性。利用图神经网络采用策略梯度方法进行单代理任务序列优化，以最大化任务完成率的适应性。
## Conclusion
在模拟环境中对COA生成过程的测试表明，相比随机游走基准，其性能显著提升。任务序列优化的最优性缺口较小，且约需50分钟规划20个COA（5个代理/100个任务的操作）的执行时间。
# 61. `cs.AI` - 使用自我蒸馏进行GNN的不确定性量化 [PDF](https://arxiv.org/pdf/2506.20046), [HTML](https://arxiv.org/abs/2506.20046)
## Authors
Hirad Daneshvar,Reza Samavi
## Background
图神经网络（GNN）在医疗保健领域中表现优异，但在临床环境中量化预测不确定性仍然是一个挑战。现有的贝叶斯方法和集成方法虽然可以量化不确定性，但计算成本高。集成方法通过计算不同模型之间的分歧度量来衡量不确定性，但这种方法不能捕捉到集成网络中模型的多样性。
## Innovation
本文提出了一种基于知识蒸馏的新型方法，以更高效且精确地量化GNN的不确定性。具体而言，通过自我蒸馏，即同一流程中的同一网络同时充当教师模型和学生模型，避免了独立训练多个网络的需求。为了确保自我蒸馏的有效性，该方法开发了一个新的不确定性度量指标，通过给每个GNN分类器分配不同的权重来捕捉网络的多样性。该方法在两个图数据集MIMIC-IV和Enzymes上进行实验验证，结果表明该方法不仅能有效捕捉模型的预测不确定性，而且在性能上与Monte Carlo Dropout和集成方法相当。
## Conclusion
实验结果证明，所提出的方法能够有效捕捉模型的预测不确定性，其性能与Monte Carlo Dropout和集成方法相当。同时，该方法具有较高的准确性和区分出分布样本的能力。
# 62. `cs.AI` - 使用生成置信度映射合成实现稳健的机器人探索与制图 [PDF](https://arxiv.org/pdf/2506.20049), [HTML](https://arxiv.org/abs/2506.20049)
## Authors
Lorin Achey,Alec Reed,Brendan Crowe,Bradley Hayes,Christoffer Heckman
## Background
本文提出了一个利用生成型占用映射增强机械臂探索的新方法。作者介绍了SceneSense，这是一种针对给定部分观察预测3D占用地图设计并训练的扩散模型。这种方法实时地将预测结果概率性地融合进运行中的占用地图中，从而显著提高了地图的质量和可通达性。通过将SceneSense部署在四足机器人上，并使用实际的实验验证了该模型的有效性，展示出提升后的占用地图更好地代表了我们完全观测到的真实地面数据，显示出更高的准确性和更为一致的结果。同时，将改进后的地图集成进现有的机器人探索套件中并与已有的现成规划器结合，使机械臂具有更强的稳健性和更好的可通达时间。这些结果在两种不同的环境中进行了全面的探索评估，验证了局部增强地图的一致性更好。
## Innovation
提出了一个利用生成型模型来预测3D占用地图的new方法——SceneSense，并通过四足机器人验证了其有效性。这种方法通过实时地将预测结果概率性地融合进运行中的占用地图中来提高地图质量和可通达性。此外，将SceneSense增强的占用地图集成到机器人探索套件中作为“即插即用”的地图改进，展示出其改善了稳健性和通达时间的效果。结果显示，局部增强地图在两种不同环境中的探索结果更为一致并且具有更高的准确率
## Conclusion
本文提出的方法通过引入SceneSense——一个专门用于在此部分观察下生成3D占用分布预测的扩散模型，实现了在探索中的稳健地图制图。在四足机器人上实施并结合实际的实验验证展示了局部增强的占用地图比直接传感器测量结合起来的绘制的更好，更加准确并具有一致性。该方法作为已有现成规划镜片的插件增强，并进一步显示出增强了稳健性和通达时间，给探索任务带来了显著改进。
# 63. `cs.AI` - CCRShuo yī wèi kòng-jiàn gōng chéng de zé rén fēng zhì chuán qíng jiāo jué [PDF](https://arxiv.org/pdf/2506.20128), [HTML](https://arxiv.org/abs/2506.20128)
## Authors
Aashiq Muhamed
## Background
RAG系统通过集成外部知识增强了LLMs的能力，这对于需要准确性和最新信息的领域至关重要。然而，评估RAG输出的多方面质量，包括上下文一致性、查询相关性、事实正确性和信息完整性等，存在显著挑战。现有评估方法通常依赖于简单的词法重叠度量，这些方法无法捕捉这些细微差别，或者需要复杂多阶段的管道以及中间步骤如断言提取或专门训练判断模型的微调，这降低了实践效率。
## Innovation
本文提出了一种新的评估框架CCRС，这是一种单一预训练LLM作为零样本、端到端裁判的新型方案，用于评估RAG系统的质量。CCRС包括五个度量标准：上下文一致性（CC）、问题相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回率（IR）。与复杂的RAGChecker框架相比，CCRС在关键方面，如召回率和忠实度，提供了相当或更好的区分能力，同时计算效率更高。
## Conclusion
CCRС提供了一个实用、全面且高效的框架，用于评估和逐步改进RAG系统。通过在BioASQ数据集上评估六个不同的RAG系统配置，证明了CCRС的有效性，并且某些系统，如Mistral-7B阅读器，显示了优于Llama变体的表现。CCRС的度量特征分析表明，该框架具有广泛适用性和高区分能力。
# 64. `cs.AI` -  psychic cells generate consciousness？ [PDF](https://arxiv.org/pdf/2506.20164), [HTML](https://arxiv.org/abs/2506.20164)
## Authors
Mototaka Suzuki,Jaan Aru
## Background
过去几十年的技术进步已经开始使神经科学家以前所未有的方式探讨意识的基本问题。这篇论文回顾了对大脑中意识处理细胞机制的理解的重大进展，特别是皮层锥形神经元（百多年前卡哈尔称之为“心灵细胞”）在麻醉诱导的意识丧失过程中表现出的选择性打断反馈信号的现象，以及分布在锥形细胞树突上的特定类型代谢型受体的关键作用
## Innovation
本文特别强调了分布在锥形细胞树突上的特定类型代谢型受体作为关键的细胞机制，并指出一个多世纪前卡哈尔的直觉可能是正确的，我们可能才刚刚开始理解心灵细胞是否以及如何产生和控制我们的意识
## Conclusion
总的来说，本文认为皮层锥形神经元可能是意识处理的关键细胞机制，并且可能需要进一步深入研究来理解这些“心灵细胞”是否确实负责产生和控制意识
# 65. `cs.AI` - Irec: 一种通过即时洞察回忆进行元认知支撑的自我调节学习框架及系统原型 [PDF](https://arxiv.org/pdf/2506.20156), [HTML](https://arxiv.org/abs/2506.20156)
## Authors
Xuefei Hou,Xizhao Tan
## Background
当前学习的核心挑战已经从知识获取转向了有效自我调节学习（SRL），包括规划、监控和反思学习过程。现有的数字工具在支持元认知反思方面不足。传统的间隔重复系统（SRS）忽视了情境的重要性，而个人知识管理（PKM）工具则需要大量的人工维护。
## Innovation
本文提出了“Insight Recall”这一创新框架，通过情境触发的个人过去洞见检索来作为元认知支架，促进SRL。该框架使用即时适配干预（JITAI）框架进行形式化，并以Irec原型系统的形式展示其实现可行性。Irec的核心在于用户学习历史的动态知识图谱，通过混合检索引擎和大规模语言模型来即时呈现最相关的洞见。此外，还提出了一种可选的“引导式探究”模块，用户可以在其中与专家语言模型进行苏格拉底式对话，使用当前问题和检索到的洞见作为背景对话的上下文。
## Conclusion
本文贡献了一个坚实的理论框架和一个实际可用的系统平台，以设计下一代增强元认知和自我调节的智能学习系统。
# 66. `cs.AI` - SACL: 使用语义增强重排序和定位理解并对抗代码检索中的文本偏见 [PDF](https://arxiv.org/pdf/2506.20081), [HTML](https://arxiv.org/abs/2506.20081)
## Authors
Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie
## Background
现有代码检索技术主要依赖于表面文本特征（如文档字符串、标识符名称）来增强代码生成。然而，这些技术倾向于优先考虑文档良好的代码，即使文档与实际代码不相关。这种现象揭示了当前代码检索在处理文本信息时存在偏见的问题。
## Innovation
文章提出了一种名为 SACL 的框架，该框架通过将语义信息增强到代码或结构知识中来丰富文本信息并减少偏见。实验结果显示，SACL 在代码检索上显著提高了召回率（例如，在 HumanEval、MBPP 和 SWE-Bench-Lite 上分别提高了 12.8%、9.4% 和 7.0% 的 Recall@1），进而提高了代码生成性能（例如，在 HumanEval 上通过率提高了 4.88%）。
## Conclusion
SACL 框架通过增强语义信息显着改进了代码检索和代码生成性能，并解决了当前代码检索技术中的文本偏见问题。
# 67. `cs.AI` - BrokenVideos: 用于AI生成视频中细粒度缺陷定位的基准数据集 [PDF](https://arxiv.org/pdf/2506.20103), [HTML](https://arxiv.org/abs/2506.20103)
## Authors
Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang
## Background
最近的深度生成模型进展极大地推动了视频生成的发展，但AI生成的视频的保真度仍然有限。合成内容经常表现出诸如时间不一致的运动、物理不合理的轨迹、不自然的对象变形和局部模糊等视觉伪影，这些都会破坏真实感和用户的信任。准确检测和空间定位这些伪影对于自动化质量控制和改进生成模型的开发至关重要。然而，当前研究界缺乏一个全面的设计用于定位AI生成视频中伪影的基准数据集。现有的数据集要么仅限于视频或帧级检测，要么缺乏必要的细粒度空间注释来评估定位方法。
## Innovation
我们引入了BrokenVideos数据集，这是一个包含3,254个AI生成视频的基准数据集，具有精确定位、像素级别的视觉破坏区域标注。每个注释都经过详细的人员检查验证，以确保高质量的地面真值。我们的实验表明，使用BrokenVideos训练最先进的缺陷检测模型和多模态大型语言模型可以显著提高它们在定位破坏区域的能力。通过对扩展评估，我们证明了BrokenVideos为用于生成视频模型中定位伪影的研究的基准测试和进展奠定了关键基础。
## Conclusion
BrokenVideos数据集为研究人员提供了一种评估和推进生成视频模型中伪影定位研究的关键基础，该数据集已可供下载。
# 68. `cs.AI` - AI和敏捷软件开发：从挫折到成功 —— XP2025研讨会综述 [PDF](https://arxiv.org/pdf/2506.20159), [HTML](https://arxiv.org/abs/2506.20159)
## Authors
Tomas Herda,Victoria Pichler,Zheying Zhang,Pekka Abrahamsson,Geir K. Hanssen
## Background
该研讨会于2025年XP大会期间召开，邀请了来自研究界和工业界的参与者，旨在探讨将人工智能与敏捷软件开发相结合时所面临的实际挑战和机遇。参与者通过互动环节识别并分享了在将AI整合到敏捷软件开发实践中遇到的共同挫折，包括工具、治理、数据质量和关键技能缺口等方面的问题。这些问题被系统地分析以找到根本原因。
## Innovation
研讨会的创新之处在于它促进了行业内和学术界的合作，以制定一个具体的研究路线图，该路线图明确了实现从挫折到成功的关键行动方向，包括既能解决眼前问题又具有长远目标的内容。这为下一步的研究和实施提供了结构化的计划，有助于找到实际的解决方案并推动项目的成功。
## Conclusion
研讨会形成的结构化行动计划旨在推动联合行业学术界合作，从所确定的挫折认知转化为成功实施。目标是在短期内提供实际解决方案，并着眼于长期目标。
# 69. `cs.AI` - 有效选择康ฟ洛恩预测集 [PDF](https://arxiv.org/pdf/2506.20173), [HTML](https://arxiv.org/abs/2506.20173)
## Authors
Mahmoud Hegazy,Liviu Aolaritei,Michael I. Jordan,Aymeric Dieuleveut
## Background
康弗洛恩预测提供了一种无需特定分布的框架，用于构建具有覆盖保证的预测集。然而，在实践中，根据不同的模型或方法可能生成多个有效的康弗洛恩预测集。选择最优的预测集，如最小集，可能会破坏覆盖保证。因此，本文旨在解决选择最优预测集时覆盖保证有效的问题。本文还将其结果扩展到在线康弗洛恩设置，并在可获取额外结构的情况下提出了一系列改进措施，然后通过实验展示了其有效性。
## Innovation
提出了基于稳定性的方法，确保选择的预测集具有覆盖保证。将其结果扩展到了在线康弗洛恩设置，并在可获取额外结构的情况下提出了一系列改进措施。这些改进措施提高了预测集的有效性和适用性。
## Conclusion
通过实验结果显示，所提出的方法能够选择出具有有效覆盖保证的最优预测集，并将其应用扩展到了在线场景，展示了其实用性和有效性。
# 70. `cs.AI` - 整合时空模型和大规模语言模型的模块化多任务推理框架 [PDF](https://arxiv.org/pdf/2506.20073), [HTML](https://arxiv.org/abs/2506.20073)
## Authors
Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang
## Background
时空数据挖掘在不同领域中的决策制定中起着关键作用。然而，现有的模型通常局限于狭隘的任务，缺乏进行多任务推理和复杂长形式推理的能力，而这些能力需要生成深入的、解释性的输出。这些局限性限制了它们在现实世界、多方面的决策场景中的应用。
## Innovation
本文介绍了一种名为STReason的新框架，该框架结合了大规模语言模型（LLMs）的推理优势和时空模型的分析能力，实现了多任务推理和执行。无需特定任务的微调，STReason通过上下文学习将复杂的自然语言查询分解为模块化、可解释的程序，然后系统执行这些程序以生成解决方案和详细的推理过程。为了进行严格的评估，构建了一个新的基准数据集，并提出了一个统一的评估框架，该框架包括专门设计用于长形式时空推理的评价指标。实验结果表明，STReason在所有评价指标上均显著优于先进的LLM基线，特别是在复杂的、推理密集的时空场景中表现出色。人类评估进一步验证了STReason的可靠性和实用性，证明了其在减少专家工作量和扩大时空任务应用范围方面的潜力。
## Conclusion
我们相信，STReason为开发更强大且具有通用性的时空推理系统提供了有潜力的方向。
# 71. `cs.AI` - 如何在上下文学习中检索例子以提高大规模语言模型在对话情绪识别中的表现？ [PDF](https://arxiv.org/pdf/2506.20199), [HTML](https://arxiv.org/abs/2506.20199)
## Authors
Mengqi Wang,Tiantian Feng,Shrikanth Narayanan
## Background
大规模语言模型（LLMs）在多个领域的实际应用中已经取得了广泛的成功。然而，对于情感识别这样的主观任务，创建一个高准确度的应用仍然具有挑战性。此次研究受到SLT 2024 GenSER挑战的启发，旨在通过上下文学习（ICL）来提高大语言模型进行对话情绪识别（CER）的能力，特别是在检索高质量例子方面的创新探索。
## Innovation
研究提出了多种基于随机和增强样例检索的策略，并分析了对话背景对情绪识别准确性的影响。实验结果显示，在所有数据集中，增强样例检索始终优于其他技术，强调了检索一致且针对性强的例子并进行重述的重要性。
## Conclusion
研究揭示了在上下文学习中检索高质量例子以提高对话情绪识别准确性的方法，特别是通过构建一致性并针对性的增强例子的方法，这种策略在多个数据集上表现出了优越性。
# 72. `cs.AI` - SEED: 一种用于时间序列预测的结构编码器，结合LLMs进行嵌入驱动解码 [PDF](https://arxiv.org/pdf/2506.20167), [HTML](https://arxiv.org/abs/2506.20167)
## Authors
Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma
## Background
多元时间序列预测要求模型同时捕捉特征之间的结构依赖关系，并且能够泛化到多样性的任务中。结构编码器在建模特征交互方面非常有效，但缺乏支持语义层次推理或任务适应的能力。另一方面，大规模语言模型（LLMs）具有强大的泛化能力，但不兼容原始时间序列输入。这两个方面之间的差距限制了统一、可转移预测系统的开发。因此，本文提出了SEED，一种用于嵌入驱动解码的结构编码器，包含四个阶段：一个具有标记意识的编码器进行片段提取、一个投影模块将片段与语言模型嵌入对齐、一个语义重新编程机制将片段映射到任务感知的原型，以及一个冻结的语言模型进行预测。这种模块化架构在表示学习与推理之间解耦，使得在数字模式和语义推理之间实现高效的对齐。实验结果表明，所提出的方法在强大的基线方法上实现了持续改进，并且在各类数据集上的比较研究证实了SEED在解决结构-语义建模差距方面的角色。
## Innovation
本文引入了SEED（一种结构编码器），用于嵌入驱动解码的时间序列预测，结合了大规模语言模型（LLMs）的优势。SEED包括四个阶段：具有标记意识的编码器进行片段提取、投影模块将片段与语言模型嵌入对齐、语义重新编程机制将片段映射到任务感知的原型，以及冻结的语言模型进行预测。这种模块化架构在表示学习与推理之间解耦，使得数字模式和语义推理之间实现高效的对齐。
## Conclusion
实验结果表明，所提出的方法在强大的基线方法上实现了持续改进，并且在各类数据集上的比较研究证实了SEED在解决结构-语义建模差距方面的角色。
# 73. `cs.AI` - 逐级对准退化学习法用于融合 [PDF](https://arxiv.org/pdf/2506.20179), [HTML](https://arxiv.org/abs/2506.20179)
## Authors
Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu
## Background
深度学习基线的高光谱分辨率（HRMS）图像合成已得到证实，但通常需要使用Wald协议生成的合成数据建立监督的地面实况HRMS图像。Wald协议假设在低分辨率数据上训练的网络在高分辨率数据上会表现一样好，然而，训练好的模型在低分辨率和全分辨率数据集上的性能通常表现出折中效果。这表明，Wald协议对真实退化模式的不准确逼近限制了深度超分辨率模型的泛化能力。
## Innovation
本文提出了一种逐级对准退化模块（PADM），其通过两个子网络PAlignNet和PDegradeNet之间的相互迭代，自适应学习准确的退化过程，无需依赖预定义的操作。同时引入了HFreqdiff，这是一种嵌入高频细节的扩散框架，结合了CFB和BACM模块进行频率选择性细节提取和精确反向过程学习，从而实现高光谱和多光谱图像的有效集成，大幅提升了空间清晰度和图像质量。
## Conclusion
实验和消融研究表明，提出的方法在与最先进的技术进行对比时具有优越的性能。
# 74. `cs.AI` - COIN: 为基座模型提供防不确定性选择性问答的有保证风险保障 [PDF](https://arxiv.org/pdf/2506.20178), [HTML](https://arxiv.org/abs/2506.20178)
## Authors
Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu
## Background
对于基座模型来说，不确定性量化（UQ）是非常重要的，因为它能够识别并减轻自动生成文本中的潜在幻觉。然而，现有的启发式不确定性量化方法在关键指标如选择性预测的假发现率（FDR）方面缺乏形式保障。尽管之前的研究所采用的分裂符合预测（SCP）框架通过构建预测集来确保可接受答案的覆盖率，但是这些集往往包含不正确的候选答案，限制了它们的实际应用价值。鉴于此，亟需一种新的方法来有效控制FDR并提高预测的准确性与实用性。
## Innovation
本文提出了COIN框架，这是一种不确定性防护的选择问答框架，可在用户指定的FDR约束下，通过统计校准验证的阈值筛选每个问题的单个生成答案。COIN在校准集上估计经验错误率，并通过Clopper-Pearson等置信区间方法建立真错误率（即FDR）的高概率上限，从而确保在测试数据上的FDR控制，并大幅提高样本保留率。此外，实验证明COIN具有强大的风险控制能力、保留可接受答案的能力和在有限校准数据下较好的预测效率，且通过采用不同的边界构建方法和不确定性量化策略还可进一步增强其性能，这显示了其在不同应用场景中的扩展性和适应性
## Conclusion
本文通过COIN框架解决了基座模型在选择性问答中的不确定性量化问题，通过严格的统计校准和高效的风险控制，不仅提高了预测准确性和样本保留率，还展示了COIN在各种文本生成任务中的广泛应用潜力，特别是在有限校准数据下依然表现出色。这些优势表明COIN具有广泛的适用性和实际价值。
# 75. `cs.AI` - MIRAGE: 农业专家引导对话中的多模态信息查找和推理基准 [PDF](https://arxiv.org/pdf/2506.20100), [HTML](https://arxiv.org/abs/2506.20100)
## Authors
Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve
## Background
本文介绍了MIRAGE，这是一个面向农业领域咨询互动环境中的专家级多模态推理和决策的新基准。MIRAGE基于超过35,000个真实用户-专家互动，用精心设计的多步管道进行整理，涵盖了多样化的作物健康、病虫害诊断和作物管理场景。该基准包括超过7,000种生物学实体，描绘了农业领域的多层次复杂性，使其成为用于视觉语言模型的最佳基准之一，尤其是那些能在真实世界中进行推理和生成描述性文本的任务。与现有的依赖于规范用户输入和封闭分类基准不同，MIRAGE采用了不确定性更高、环境更开放的场景，需要模型推断隐藏的知识缺口，处理罕见实体，并主动引导对话或做出反应。
## Innovation
MIRAGE创新性地将自然用户查询、专家答复和基于图像的上下文融合到农业领域，提供了一个高保真度的多模态基准，用于评估模型在实在世界知识密集型领域的基于事实的推理、澄清策略和长文本生成能力。与现有基准相比，MIRAGE采用了模糊且复杂多变的情景，要求模型能够推断隐含的知识缺口，应对罕见的实体类型，并能够主动引导或回应对话，促进闭合式世界向开放世界的转变。
## Conclusion
MIRAGE为农业领域的多模式交互提供了新的高保真度基准，可用于评估模型在知识密集环境下进行事实推理、阐述和生成文本的能力。这一基准通过多样的真实数据，填补了现有基准的不足，为视觉语言模型的研究者提供了一个新的挑战和测试平台。
# 76. `cs.AI` - 零样本归因方法：分布检验方法 [PDF](https://arxiv.org/pdf/2506.20197), [HTML](https://arxiv.org/abs/2506.20197)
## Authors
Clément L. Canonne,Yash Pote,Uddalok Sarkar
## Background
随着越来越多的代码被大型语言模型（LLMs）生成，从这些模型生成的代码如何归因成为一个重要的问题。本文基于假设检验方法来解决这一问题，提出了一种零样本归因工具，通过将归因问题转化为分布检验问题来评估一组样本是否源于某个特定模型。由于高维数据的难度，直接从LLM样本中解决这一问题不可行。因此，研究者采用了LLM样本和密度估计两种数据来克服这一挑战。
## Innovation
提出了名为Anubis的零样本归因工具，该工具采用分布检验方法来处理代码生成问题。与传统方法相比，该工具能够仅通过少量样本（约2000个）来区分不同LLM生成的代码，并且在实验中实现了较高的AUROC分数（≥0.9）。
## Conclusion
研究表明，通过分布检验方法可以有效地区分不同LLM生成的代码，即使仅使用少量样品也可以得到较高的准确率，Anubis工具提供了一种解决代码归因问题的新方法。
# 77. `cs.AI` - EAR: 清除统一自回归模型中的概念 [PDF](https://arxiv.org/pdf/2506.20151), [HTML](https://arxiv.org/abs/2506.20151)
## Authors
Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang
## Background
自回归（AR）模型在视觉理解和图像生成任务中均表现出色。但如何在不损害整体生成质量的前提下清除不需要的概念，依然是一个挑战。本文介绍了清除统一自回归模型中概念的想法，提出了Erasure Autoregressive Model（EAR），一种有效且保留有用性的概念清除方法，通过引入窗口梯度累积策略和阈值损失掩蔽策略，旨在解决这一问题。同时，本文还提出了一个新的基准测试Erasure Concept Generator and Visual Filter（ECGVF），通过使用多种大型语言模型生成的结构化模板来提供一个更为严谨和全面的评估基础，确保清除概念的有效性和一致性。实验结果表明，EAR在概念清除效果和模型实用性保留方面均有所提升。
## Innovation
提出了Erasure Autoregressive Model（EAR），一种用于有效和保留有用性的概念清除方法，通过引入窗口梯度累积策略和阈值损失掩蔽策略。同时，还提出了一个新的基准测试Erasure Concept Generator and Visual Filter（ECGVF），通过使用多种大型语言模型生成的结构化模板来提供一个更为严谨和全面的评估基础。
## Conclusion
EAR在概念清除效果和模型实用性保留方面均有所提升。在ECGVF基准测试中进行的广泛实验结果验证了这种方法的有效性。
# 78. `cs.AI` - Affective Priming Score: 一种用于检测序列数据中影响效应的数据驱动方法 [PDF](https://arxiv.org/pdf/2506.20204), [HTML](https://arxiv.org/abs/2506.20204)
## Authors
Eduardo Gutierrez Maestro,Hadi Banaee,Amy Loutfi
## Background
情感触发是情感计算中的一个挑战，现有研究主要从标签角度出发，识别受触发效应影响的数据点，但对情感触发对数据及其生理信号的具体影响关注度不足，导致使用这些数据进行学习模型时出现误分类。为了应对这一问题，研究提出了一种基于数据的情感触发评分（APS），用于检测受情感触发效应影响的数据点，并量化其受影响程度。验证方法应用于包含足够情绪事件转换的SEED和SEED-VII数据集，结果显示使用去触发序列的数据训练模型可以显著降低误分类率，这对克服情感计算中的模糊性具有重要贡献，增强模型的鲁棒性和提供有关情感计算数据集设计和收集的有价值见解.
## Innovation
提出一种基于数据的情感触发评分（APS），量化数据点受到情感触发效应影响的程度；使用该评分方法验证去触发序列数据在模型中的应用效果，显著降低误分类率；解决了情感计算中数据受情感触发效应影响而导致误分类的问题，提供了识别和缓解这一问题的方法，增强了情感计算模型的鲁棒性，并对数据集设计和收集提出了有益建议.
## Conclusion
该研究通过识别和减轻序列数据中的情感触发效应，显著降低了情感计算模型的误分类率，增强了模型的鲁棒性，并提供了关于情感计算数据集设计和收集的宝贵见解，为推动情感计算的进一步研究和应用奠定了基础.
# 79. `cs.AI` - 通过结构化推理增强大型语言模型 [PDF](https://arxiv.org/pdf/2506.20241), [HTML](https://arxiv.org/abs/2506.20241)
## Authors
Yubo Dong,Hehe Fan
## Background
近期的大规模语言模型在自然语言处理和自动化决策方面取得了显著进展，但仍面临在涉及逻辑推理和系统性规划的复杂任务中表现不佳的问题，主要原因是它们依赖于统计关系而非结构化知识。通过认知科学和神经符号AI的研究，我们提出了一种增强语言模型的新型结构化推理方法。该方法首先将未结构化的数据转换为结构化格式，通过显式标注推理步骤，然后使用监督微调（SFT）训练语言模型，并通过组相对策略优化（GRPO）增添结构化推理能力，引入了MAX-Flow和最长公共子序列（LCS）两种创新算法，显著提高了推理效果并降低了计算复杂性。实验表明，这种方法能够实现简洁的推理，具备多场景稳健性能，并且增强了与优化技术的兼容性，证实了结构化推理整合在语言模型中的有效性。
## Innovation
该研究引入了一种新的结构化推理方法，包括：1）通过显式标注将未结构化的数据转换为结构化格式；2）利用监督微调（SFT）训练出具有结构化推理能力的语言模型；3）采用组相对策略优化（GRPO）和MAX-Flow以及最长公共子序列（LCS）两种创新算法，有效提升了推理效果并降低了计算复杂性。
## Conclusion
通过结构化推理的增强方法在DeepSeek-R1-Distill-Qwen-1.5B模型上的实验结果证明，该方法不仅能够实现简洁的推理，而且能够在多场景中保持稳健的性能，并且增强了与优化技术的兼容性，验证了结构化推理在语言模型中的有效性。
# 80. `cs.AI` - 使用神经网络生成和定制机器人手臂轨迹 [PDF](https://arxiv.org/pdf/2506.20259), [HTML](https://arxiv.org/abs/2506.20259)
## Authors
Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Igor Farkaš
## Background
本文介绍了一种利用神经网络生成和定制机器人手臂轨迹的方法，确保了动作的精确性和重复性。这种方法应用于认知机器人场景中，展示了如何通过精确的线性运动将机器人手臂指向特定的空间点，从而提高机器人与人类交互时动作的预测性。
## Innovation
通过结合计算前向运动学的神经网络来生成关节角度生成器，进而开发训练出一种基于人工数据集的神经网络。此方法通过计算角速度，使机器人能够执行动作，并从形状和精确度两个方面来评估动作质量。这种方法由于其广泛的应用性，能生成精确且可定制的轨迹，适应不同的应用场景。
## Conclusion
通过这种方法，成功生成了精确的可定制运动轨迹，并通过实际实验验证了其可靠性。
# 81. `cs.AI` - Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration [PDF](https://arxiv.org/pdf/2506.20152), [HTML](https://arxiv.org/abs/2506.20152)
## Authors
Deepak Ghimire,Kilho Lee,Seong-heum Kim
## Background
结构剪枝是一种广泛应用于压缩神经网络的技术，使其适合在资源受限的边缘设备上部署。传统的剪枝方法通常包括三个阶段：训练、剪枝和微调。然而，这些阶段耗时且复杂，本文提出了一种新的剪枝方法，称为Loss-Aware Automatic Selection of Structured Pruning Criteria (LAASP)，强调在训练过程中同时进行剪枝，从而省去了传统的训练阶段，并将剪枝和微调合并为一个循环过程。这种方法通过网络在一小部分训练数据上的总体损失，自动选择剪枝准则和具体剪枝层，以减少剪枝造成的精度下降，同时还能自动确定每个层的最佳剪枝率，减少人工参与。这种方法已经在VGGNet和ResNet模型上进行了实验，并且证明了其有效性和在提高网络效率方面的潜力。特别是在CIFAR-10和ImageNet数据集上，ResNet模型通过省略部分浮点运算，显著提高了精度，同时保持了较低的计算复杂度。
## Innovation
提出的LAASP方法在训练过程中同时进行剪枝和微调，避免了传统方法的三个独立阶段。方法能自动从一组准则中选择剪枝的标准和具体层，从而减少了人为干预。此外，采用了针对剪枝后精度下降的缓解措施，即在每次减少一定数量浮点运算后，对网络进行短暂的重新训练。LAASP方法能够自动生成每个层的最佳剪枝率，进一步简化了整个剪枝过程。
## Conclusion
实验结果表明，LAASP方法在VGGNet和ResNet模型上显著提高了精度，并减少了浮点运算，尤其是在CIFAR-10数据集上，ResNet56和ResNet110模型的top-1精度显著提升，同时减少了52%的浮点运算。ResNet50在ImageNet数据集上也显著降低了浮点运算，仅损失了不到0.33%的top-5精度。代码已在公共网站上提供以便进一步研究。
# 82. `cs.AI` - Argumentative Ensembling for Robust Recourse under Model Multiplicity [PDF](https://arxiv.org/pdf/2506.20260), [HTML](https://arxiv.org/abs/2506.20260)
## Authors
Junqi Jiang,Antonio Rago,Francesco Leofante,Francesca Toni
## Background
在机器学习领域，尤其是在使用神经网络等模型训练时，经常会遇到使用不同随机种子得到多个性能相同的模型的情况。这些模型在面对同一输入时可能会产生不同的预测结果，形成了所谓的模型多样性问题。处理这个问题通常会用到集成方法。然而，在计算对抗性推诿建议（counterfactual explanations，CEs）时，如果考虑了模型多样性，计算出的CEs可能无法在所有模型中保持一致性，这就使得CEs不再具有鲁棒性。因此，本研究聚焦于如何在模型多样性情况下提供可靠的推诿建议，该研究由此引入了针对模型多样性的决策方法，即自私的集成（recourse-aware ensembling，RAE）.
## Innovation
研究提出了一个新的自私的集成方法——argumentative ensembling，在面对模型多样性时，这个方法能够保证CEs的鲁棒性。具体而言，该方法利用计算论辩来显式地表示模型与CEs之间的冲突，并通过论辩语义来解决冲突，最终获得解决方案。此外，该方法还允许用户根据情况偏好评价模型，从而进一步定制集成。通过理论和实验分析，研究证明了argumentative ensembling方法的有效性，表明其可以在不同论辩语义下表现良好，并且能够兼顾多种理想特征的实现。
## Conclusion
文章提出了针对模型多样性的决策方法——自私的集成，该方法通过计算论辩为了解决模型之间的冲突提供了一种新视角，保证了CEs在多样性模型下的鲁棒性，并通过实践经验验证了该方法的有效性。
# 83. `cs.AI` - 比较分析：作物病害检测中迁移学习下的深度学习模型 [PDF](https://arxiv.org/pdf/2506.20323), [HTML](https://arxiv.org/abs/2506.20323)
## Authors
Saundarya Subramaniam,Shalini Majumdar,Shantanu Nadar,Kaustubh Kulkarni
## Background
本文介绍了旨在帮助资源匮乏的农村地区农民的一种基于人工智能的作物疾病检测系统。研究聚焦于不同深度学习模型在迁移学习中的效果比较，旨在提高作物管理的精准性，并促进可持续农业生产的发展。研究选取了一系列深度学习模型，包括EfficientNet、ResNet101、MobileNetV2以及自定义的CNN模型，以验证其在作物疾病检测中的应用潜力。
## Innovation
研究通过对比分析多种深度学习模型，特别是迁移学习的应用，旨在探索其在作物疾病检测中的高效性和实用性。研究中的自定义CNN模型在验证过程中达到了95.76%的验证准确率，表明该技术在作物疾病识别方面具有显著优势。此外，研究强调了迁移学习在农业实践中的潜力，它能够优化作物健康管理并支持可持续农业的发展，特别是在资源受限的农村地区。
## Conclusion
该研究证明了深度学习模型在作物疾病检测中的有效性，尤其是迁移学习的应用显著提高了检测的准确性和效率。该系统能够有效分类作物疾病，并展示了其在改善作物健康管理和促进可持续农业方面的重要潜力。
# 84. `cs.AI` - 使用局部和全局特征融合的GNN进行有向链接预测 [PDF](https://arxiv.org/pdf/2506.20235), [HTML](https://arxiv.org/abs/2506.20235)
## Authors
Yuyang Zhang,Xu Shen,Yu Xie,Ka-Chun Wong,Weidun Xie,Chengbin Peng
## Background
链接预测是在图分析中一个经典的问题，具有许多实际应用场景。对于有向图，最近开发的深度学习方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻域信息。本文在这个背景下，分析了现有的深度学习方法，并提出了一种新的图神经网络（GNN）框架，融合了特征嵌入和社区信息，以提升有向链接预测的性能。
## Innovation
提出了一种新的GNN框架，该框架将特征嵌入与社区信息融合，证明这种混合特征能够改善有向链接预测的性能。此外，文章还提出了一个将输入图转换为有向线图的方法，便于在图卷积中聚合更多信息。其创新点在于结合了局部和全局信息，同时改进了训练数据使用效率。
## Conclusion
实验表明，本文的方法在多种基准数据集上，当30%、40%、50%和60%的连接链接被用作训练数据时，均优于当前最先进的方法。
# 85. `cs.AI` - Q-resafe: 评估安全风险和针对量化大型语言模型的量化感知安全补丁 [PDF](https://arxiv.org/pdf/2506.20251), [HTML](https://arxiv.org/abs/2506.20251)
## Authors
Kejia Chen,Jiawen Zhang,Jiacong Hu,Yu Wang,Jian Lou,Zunlei Feng,Mingli Song
## Background
量化的大语言模型（LLMs）在资源受限的环境下部署中受到了越来越多的关注。然而，新兴的研究表明，几种无需校准数据集的量化方法可能会损害LLMs的安全性，这强调了系统安全评估和有效的缓解策略的迫切需求。本文对主流的多种量化技术以及不同的校准数据集进行了全面的安全性评估，并采用了广泛接受的安全基准。在此背景下，为应对识别出的安全漏洞，本文提出了一个量化感知的安全补丁框架Q-resafe，旨在在尽量减少对实用性不利影响的情况下，有效恢复量化LLMs的安全能力。
## Innovation
本文的主要创新点在于提出了一个量化感知的安全补丁框架Q-resafe，该框架能够有效恢复量化后的LLMs的安全能力，同时尽量减少对其实用性的负面影响。通过对广泛接受的安全基准进行综合评估，Q-resafe 成功地重新对齐了量化后的LLMs的安全性和其未量化前的同源性，即使在严峻的评估场景下也是如此。
## Conclusion
本文提出了Q-resafe框架，该框架有效地恢复了量化后的LLMs的安全性，同时考虑了对其实用性的最小负面影响。通过广泛的实验结果表明，Q-resafe在各种具有挑战性的评估情况下，成功地重新对齐了量化后的LLMs的安全性与它们未量化前的相似度。
# 86. `cs.AI` - FedBKD: 提取式联邦学习以在非IID数据上实现泛化和个性化 [PDF](https://arxiv.org/pdf/2506.20245), [HTML](https://arxiv.org/abs/2506.20245)
## Authors
Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu
## Background
联邦学习（FL）是一种去中心化的协作机器学习技术，旨在解决工业机器学习实践中的孤立数据岛屿和数据隐私泄露问题。非同分布依存（non-IID）数据是FL面临的一个主要挑战，当前解决方案要么关注构建全局模型，要么定制个性化模型，很少能够在提高全局模型泛化能力和局部模型性能之间取得平衡。此外，许多解决非IID问题的FL方案会借助公共数据集，但这也增加了数据泄露的风险。
## Innovation
本文提出了一种新颖的无数据提取式蒸馏框架，即Federated Bidirectional Knowledge Distillation (FedBKD)，通过生成对抗网络（GAN）生成合成数据，训练局部模型作为鉴别器并冻结参数，利用合成数据在全局模型和局部模型之间进行双向蒸馏，实现知识交互，以提高双方的性能。该方法在4个不同的非IID基准数据集上进行了广泛实验，结果表明在所有情况下都取得了当前最佳性能(SOTA)。
## Conclusion
FedBKD框架通过双向知识蒸馏提高了全局和局部模型的性能，解决了非IID数据带来的挑战，同时限制了数据泄露的风险。
# 87. `cs.AI` - 使用有限演示实现超越专家表现：基于双重探索的高效模仿学习 [PDF](https://arxiv.org/pdf/2506.20307), [HTML](https://arxiv.org/abs/2506.20307)
## Authors
Heyang Zhao,Xingrui Yu,David M. Bossens,Ivor W. Tsang,Quanquan Gu
## Background
模仿学习是强化学习中的一个核心问题，其目标是从专家的行为中学习政策。在实际应用中，由于状态空间的复杂性，从有限的演示中准确学习专家政策往往具有挑战性。此外，为了实现超越专家的表现，还需要探索环境以收集数据。然而现有方法难以同时解决准确学习和探索的问题，从而影响了模仿学习的效率和效果。
## Innovation
我们提出了一种名为双探索模仿学习（ILDE）的新颖模仿学习算法，该算法在两个方面实现探索：(1) 通过探索奖金优化乐观策略，奖励那些高不确定性的状态-动作对到潜在改善专家策略的收敛；(2) 通过动力探索与示例轨迹偏离的状态来可能实现超越专家的表现。实验证明，ILDE在样本效率方面优于最新的模仿学习算法，并在Atari和MuJoCo任务中用较少的演示实现了超越专家的表现。此外，我们还从理论角度证明了ILDE作为具有乐观探索的不确定性正则化策略优化方法，其遗憾度以亚线性方式增长，验证了其高效性。
## Conclusion
与目前的模仿学习方法相比，ILDE展示出了更高的样本效率，并能够在较少的演示下实现超越专家的表现。理论分析表明，ILDE可以有效地结合乐观探索和不确定性正则化策略优化，这在大规模任务中具有潜在的优越性。
# 88. `cs.AI` - 在NLP系统中考虑视角：一种更具包容性的多层次方法 [PDF](https://arxiv.org/pdf/2506.20209), [HTML](https://arxiv.org/abs/2506.20209)
## Authors
Benedetta Muscato,Lucia Passaro,Gizem Gezici,Fosca Giannotti
## Background
在自然语言处理（NLP）领域，常见的处理人类分歧的方法是汇总标注者的观点以建立单一的真实基准。然而，先前的研究表明，忽视个人意见可能会导致少数派观点被低估，尤其是在主观任务中，标注者可能由于个人偏好系统性地产生分歧。鉴于标签反映了个体的多样背景、生活经历和价值观，本研究提出了一种新的多层次方法，通过使用软标签来鼓励开发下一代更具视角意识的模型，这些模型更具包容性和多元性。我们针对多样化的主观文本分类任务，包括仇恨言论、讽刺、攻击性语言和立场检测，进行了广泛分析，以强调捕捉人类分歧的重要性，这是传统集成方法经常忽略的。研究结果表明，多层次方法不仅更好地接近了人类标签分布（使用杰普森-香农散度JSD衡量），而且在分类性能（更高的F1分数）上也优于传统方法。但在讽刺和立场检测等任务中，我们的方法表现出较低的自信度，这可能是由于文本中存在的固有主观性造成的。最后，我们利用解释性人工智能（XAI）探索模型不确定性和模型预测的有意义见解。
## Innovation
本研究提出了一种新的多层次方法，通过使用软标签来处理人类分歧，以建立下一代更具视角意识的模型。这种方法旨在克服传统汇总方法的局限性，更好地捕捉和反映多样性观点，从而提高分类性能并促进更具包容性和多元化的NLP系统的发展。
## Conclusion
多层次方法不仅更好地逼近了人类标签分布，还实现了更优的分类性能，但在一些任务中显示出较低的自信度。通过运用解释性人工智能技术，该研究还能够让模型预测的解释变得更为有意义，为更好地理解模型行为提供了关键见解。
# 89. `cs.AI` - 利用机器学习方法生成来自能源消费者的时间序列替代品以应对长期预测场景 [PDF](https://arxiv.org/pdf/2506.20253), [HTML](https://arxiv.org/abs/2506.20253)
## Authors
Ben Gerhards,Nikita Popkov,Annekatrin König,Marcel Arpogaus,Bastian Schäfermeier,Leonie Riedl,Stephan Vogt,Philip Hehlert
## Background
电力价值链中的预测吸引了大量研究关注。然而，大多数研究集中在发电或消费的短期预测上，侧重于系统层面，而对个人消费者的研究较少。更忽视的是个体电力消耗的长期预测。本文旨在深入比较数据驱动的方法，为能源消耗的长期预测生成拟合度高的合成时间序列数据。高质量的拟合度高的合成数据对于状态估计、电力系统规划等用途至关重要。本文利用来自德国家庭的开源数据集（15分钟分辨率），评估并对比了多种前沿但不太常用的技术：混合Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔可夫模型（HMM）和掩码自回归伯恩斯坦多项式规范流（MABF）。本文旨在增强合成电力消耗数据的准确性和可靠性，同时生成满足匿名化等条件的数据，从而缓解特定客户个人定位的风险。
## Innovation
本文首次深入比较了WGAN、DDPM、HMM和MABF这四种数据驱动的方法，为个体消费者电力消耗的长期预测生成高质量的拟合度高的合成时间序列数据。这种方法有助于选择最适合状态估计及其他能源相关任务的最合适的处理方法。生成和分析框架旨在提高合成电力消耗数据的准确性和可靠性，同时保持隐私，避免特定客户个人定位的风险。
## Conclusion
通过对比评估，本文揭示了WGAN、DDPM、HMM和MABF的优势和局限性，为选择最适合进行状态估计和其他能源相关任务的方法提供了依据。利用这种生成和分析框架，可以提高长期电力消耗预测的准确性，并生成符合匿名化要求的数据，从而更好地保护用户隐私。
# 90. `cs.AI` - 客户端聚类与知识共享：在个人分布式学习中增强隐私性和稳健性 [PDF](https://arxiv.org/pdf/2506.20413), [HTML](https://arxiv.org/abs/2506.20413)
## Authors
Mohammad Mahdi Maheri,Denys Herasymuk,Hamed Haddadi
## Background
随着人工智能（AI）在物联网（IoT）生态系统中的广泛应用，对能够高效且私密地在异构、资源受限设备上运行的个性化学习方法的需求日益增加。然而，在去中心化环境中实现有效的个性化学习带来了多个挑战，包括在客户端之间高效地转移知识、保护数据隐私以及抵御中毒攻击的能力。
## Innovation
本论文提出了P4（个性化、私密、点对点）方法，旨在为资源受限的IoT设备提供个性化模型，同时确保差分隐私并抵御中毒攻击。解决方案采用了一种轻量级的完全去中心化算法来私密地检测客户端相似性和形成协作组。在每个组内，客户端利用差分隐私的知识蒸馏来协同训练模型，从而保持高精度并确保在恶意客户端存在的情况下具有鲁棒性。
## Conclusion
实验结果表明，P4在流行的基准数据集上达到了比领先的差分隐私点对点方法高出5%到30%的准确率，并且在最多30%的恶意客户端存在的情况下保持了鲁棒性。此外，通过将其部署在资源受限的设备上，我们证明了合作训练只要增加约7秒的开销即可验证其实用性。
# 91. `cs.AI` - SV-LLM：使用大语言模型进行SoC安全验证的代理方法 [PDF](https://arxiv.org/pdf/2506.20415), [HTML](https://arxiv.org/abs/2506.20415)
## Authors
Dipayan Saha,Shams Tarek,Hasan Al Shaikh,Khan Thamid Hasan,Pavan Sai Nalluri,Md. Ajoad Hasan,Nashmin Alam,Jingbo Zhou,Sujan Kumar Saha,Mark Tehranipoor,Farimah Farahmandi
## Background
确保复杂片上系统（SoCs）设计的安全是至关重要的，但传统的验证技术由于自动化、扩展性、全面性和适应性等方面的巨大挑战而难以跟上。大型语言模型（LLMs）凭借其在自然语言理解、代码生成和高级推理方面的卓越能力，为解决这些挑战提供了新的范式。从单一模型向代理方法转变，多代理系统能够更有效地协作解决复杂问题，从而提升SoC安全验证的效率和效果。
## Innovation
提出了SV-LLM，一种新颖的多代理辅助系统，旨在自动化并增强SoC安全验证。通过整合专门的代理模块（如验证问答、安全资产识别、威胁建模、测试计划和属性生成、漏洞检测和基于模拟的错误验证），SV-LLM简化了工作流程。代理模块通过不同的学习范式（如上下文学习、微调和检索增强生成）优化了性能。SV-LLM的目标是减少手动干预，提高准确性，并加速安全分析，从而通过早期设计周期支持主动识别和缓解风险。展示了其在硬件安全实践中的潜力和实际效果，通过案例研究和实验进行验证和展示
## Conclusion
通过案例研究和实验展示了SV-LLM在SoC安全验证中的应用和有效性，表明这种代理方法可以在安全分析和问题检测方面为硬件安全实践带来重大改善。
# 92. `cs.AI` - 包含多变量并行注意力的生成基础模型以生成神经活动 [PDF](https://arxiv.org/pdf/2506.20354), [HTML](https://arxiv.org/abs/2506.20354)
## Authors
Francesco Carzaniga,Michael Hersche,Abu Sebastian,Kaspar Schindler,Abbas Rahimi
## Background
在临床应用中，如颅内电生理图（iEEG）数据的优化处理面临挑战，特别是由于通道布局在不同患者间差异极大。现有的深度神经网络（DNN）方法难以处理这类多变量时序数据，尤其是捕捉其内容、时间和空间的复杂性。为解决这些挑战，本研究提出了多变量并行注意力（MVPA）机制，该机制能灵活、泛化并高效地建模具有不同通道数量和配置的时序数据。
## Innovation
本研究引入了MVPA，一种新颖的自注意力机制，能够分离内容、时间及空间的注意力，使得神经网络能够适用于通道配置变化广泛的情况。基于MVPA，研究构建了MVPFormer，一种针对人类电生理活动的生成基础模型。MVPFormer利用MVPA机制在多个数据集中展示了出色的泛化能力，特别是对于癫痫发作检测任务，其性能超过了先进的Transformer基线模型。此外，MVPA在标准的时间序列预测和分类任务中表现也优于现有注意力模型。研究成果为开发更有效的iEEG处理方法提供了重要的参考。
## Conclusion
本研究通过引入MVPA和MVPFormer，为处理具有高度异质性时序数据提供了新的解决方案。MVPFormer不仅展示了在癫痫发作检测任务中的优秀性能，还开放了包括其代码和数据的资源，促进社区进一步的研究和发展。
# 93. `cs.AI` - 自监督动作识别中的特征恢复 [PDF](https://arxiv.org/pdf/2506.20342), [HTML](https://arxiv.org/abs/2506.20342)
## Authors
Lei Wang,Piotr Koniusz
## Background
理解视频中的人类动作需要超越单纯的像素分析，更重要的是依赖高层次的语义推理和多模态特征的有效整合。现有方法往往注重于单模态分析，忽视了对动作相关信息区域的关注。本研究旨在通过提出一种深层平移动作识别框架，增强动作概念和辅助特征的联合预测能力，以及通过引入特定领域的新型特征描述符提高动作相关区域的特征表示。这些描述符包括目标检测特征（ODF）和注意检测特征（SDF），有助于捕捉行动识别中的上下文线索和关键的空间、强度模式，从而增强多模态融合的效果，实现自监督的动作识别任务。
## Innovation
本研究创新性地提出了一个深层平移动作识别框架，通过联合预测动作概念和辅助特征，提升动作识别的准确率。引入了两种新型的领域特定特征描述符：目标检测特征（ODF）和注意检测特征（SDF），以增强对动作相关区域的特征表示。同时，研究还通过自监督学习和鲁棒损失函数来处理辅助特征的不确定性，确保模型能够从各种模态数据中学习到更细粒度的动作动态。该框架兼容先进的架构，并在多个基准数据集中取得了当前最佳的效果，显示了其在多模态动作识别中的有效性。
## Conclusion
本研究提出的多模态自监督动作识别框架在多个基准数据集（如Kinetics-400、Kinetics-600和Something-Something V2）上取得了当前最佳的结果，证明了其在捕捉细粒度动作动态方面的有效性，为更加准确和全面的动作识别提供了一种新的方法。
# 94. `cs.AI` - 通过谱自举和拉普拉斯基增强进行自我监督的图形学习 [PDF](https://arxiv.org/pdf/2506.20362), [HTML](https://arxiv.org/abs/2506.20362)
## Authors
Lorenzo Bini,Stephane Marchand-Maillet
## Background
当前的自我监督图形学习框架通常需要负样本的采样来提升模型性能，这增加了复杂性和计算成本。而传统的拉普拉斯基方法可能无法有效地捕捉图形的丰富结构表示。现有的方法主要依赖对比损失目标或手工设计的增强来提高模型的表达能力。本文旨在提出一种新颖的自我监督图形学习框架，以减少对负样本采样的依赖，同时提供一种简单且高效的图形学习方法，适用于多种领域。
## Innovation
1. 通过最大最小中心性指导的优化预先计算谱增强，使得模型可以在不依赖手工设计增强的情况下获取丰富的结构监督。2. 引入对抗自举训练方案，进一步加强特征学习和模型的鲁棒性。3. 提出的LaplaceGNN框架在不同的基准数据集上表现优于最先进的自我监督图形学习方法，提升了图形表示的表达能力。
## Conclusion
LaplaceGNN框架通过谱增强技术和拉普拉斯基增强，实现了无负样本采样的自我监督图形学习，取得了线性扩展优势，为高效学习富有表现力的图形表示提供了一种新的解决方案，显示出其在多种领域应用的潜力。
# 95. `cs.AI` - 在非平稳环境下的未来离策评估与学习 [PDF](https://arxiv.org/pdf/2506.20417), [HTML](https://arxiv.org/abs/2506.20417)
## Authors
Tatsuhiro Shimizu,Kazuki Kawamura,Takanori Muroi,Yusuke Narita,Kei Tateno,Takuma Udagawa,Yuta Saito
## Background
该论文研究了在未来离策略评估（Future Off-policy Evaluation, F-OPE）和学习（Future Off-policy Learning, F-OPL）方面的新型问题。主要背景是在动态环境中，即环境分布随时间变化时，如何准确评估和优化未来的政策价值。例如，在电子商务推荐中，目标是使用上个月受现行政策影响的过往数据来估计和优化即将来临的月份的政策价值。由于未来环境中相关的数据在历史数据中不可见，现有方法往往假设环境的稳定或依赖于限制性的奖励建模假设，产生了显著的偏差。因此，本文分析了这种限制性，并探索了如何在动态环境中准确评估未来政策价值的方法。
## Innovation
本文提出了一个新颖的称为 ‘OPFV’ 的评估器，旨在准确估计未来任意时间点的策略价值。OPFV 的关键特性是其能够利用时间序列数据中的有用结构。尽管未来数据可能在历史记录中不存在，但可以通过利用如季节性、每周或节假日效应等在历史数据和未来数据中都一致的因素来进行评估。此外，还基于新的重要性加权方法扩展了评估器，设计了一种新的策略梯度方法，可以在仅使用历史数据的情况下，主动学习未来的良好策略。理论分析明确了低偏差条件下 OPFV 的使用条件。
## Conclusion
实验证明，本文提出的方法在非稳定环境中对未来政策价值的评估和优化任务上显著优于现有方法。这些结果展现了该方法的有效性和实用性，展示了在动态环境中评估与优化未来策略价值的新颖方法。
# 96. `cs.AI` - 具有可追溯推理的罕见疾病诊断代理系统 [PDF](https://arxiv.org/pdf/2506.20430), [HTML](https://arxiv.org/abs/2506.20430)
## Authors
Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie
## Background
全球有超过3亿人受到影响的罕见疾病导致了及时和准确诊断的挑战。这些挑战主要是由于罕见疾病在临床方面的异质性以及相关疾病在临床医疗界普遍缺乏认识。现有的诊断系统往往难以处理复杂的临床输入，难以生成透明、详细的诊断推理过程，这也增加了误诊风险。因此，亟需一种新型系统解决上述问题，提供快速、准确且易于理解的罕见疾病诊断支持。
## Innovation
该研究提出了一种名为DeepRare的罕见疾病诊断代理系统。DeepRare首次采用了大型语言模型（LLM），能够处理异质性的临床输入，生成罕见疾病的排名诊断假设，并附带透明的推理链，将中间分析步骤与可验证的医学证据链接起来。系统具备模块化和可扩展的设计，通过整合超过40种特殊工具和实时更新的医学知识源，确保获取最新临床信息的同时，保持复杂的诊断推理过程的可追溯性和适应性。DeepRare在多个数据集和评价指标上展现出卓越的诊断性能，尤其是在HPO基于的评估上显著优于其他方法，显示出显著的优越性。
## Conclusion
DeepRare系统有效地解决了罕见疾病诊断中的多种挑战，提供了快速准确且透明的诊断支持。其优秀的性能指标、可追溯的推理链和模块化设计使得该系统在临床实践中具有广泛应用前景。
# 97. `cs.AI` - CARMA：通过结合视觉语言模型与物体和动作识别实现人类與机器人群体交互的情境感知分情况定位 [PDF](https://arxiv.org/pdf/2506.20373), [HTML](https://arxiv.org/abs/2506.20373)
## Authors
Joerg Deigmoeller,Stephan Hasler,Nakul Agarwal,Daniel Tanneberg,Anna Belardinelli,Reza Ghoddoosian,Chao Wang,Felix Ocker,Fan Zhang,Behzad Dariush,Michael Gienger
## Background
在人类与机器人组队互动的场景中，高效的协作依赖于基于一致表示的当前人物和物体的感知，结合事件的事件化抽象，包括行动者和操作物体。这需要明确且一致地分配实例，确保机器人能够正确地识别并跟踪行动者、物体及其交互。为了实现这一点，CARMA通过在真实世界中识别这些实体的物理实例并组织它们成包含行动者、物体和行动的限定词，从而为这种命名、实例识别和追踪提供了基础。我们通过三个实验验证了这种方法，实验场景包括协作倾倒、递送和分类，这些场景用于评估系统在角色区分、多行动者意识以及一致实例识别方面的能力。我们的实验展示了该系统可以可靠地生成精确的行动者-行动-物体三元组，为需要时空推理和现场决策的应用提供了一个结构化和稳健的基础.
## Innovation
该系统独特地在真实世界中识别并组织物理实例，形成包含行动者、物体和行为的限定语组。通过结合视觉语言模型与物体和动作识别，CARMA实现了人类与机器人群体互动的情境感知和分情况定位，为协作场景提供了结构化和稳健的基础支持。
## Conclusion
我们的实验展示了CARMA能够生成精确的行动者-行动-物体三元组，为需要时空推理和现场决策的应用提供了结构化和稳健的基础。这种情境感知和实例连接的方法可以在人类与机器人团队合作中提高交互的准确性和效率。
# 98. `cs.AI` - 基于LLM的表格数据分类中的自动演示选择 [PDF](https://arxiv.org/pdf/2506.20451), [HTML](https://arxiv.org/abs/2506.20451)
## Authors
Shuchu Han,Wolfgang Bruckner
## Background
应用上下文学习（ICL）进行表格数据分类时，一个基本问题是如何确定在提示中所需要的演示示例的最佳数量。这个问题的挑战在于如何既考虑到表格数据本身的分布，又考虑到用户选择的提示模板和特定的大规模语言模型（LLM）的特性，有效地选择合适的演示示例数量。该研究通过提出一种算法来解决这个问题，该算法能自动选择合理的演示示例数量。传统的随机选择算法可能无法提供最佳的分割效果，而这个算法通过尺量谱图理论，使用一个新颖的相似度度量来量化不同演示示例之间的相似性，从而确保能够以最少的演示示例数量有效表示数据，使其符合LLM的内在表示空间。研究还通过在不同数据集和LLM上的实验验证了该方法的有效性，显示出其在数据分类任务中的优越性。
## Innovation
本文提出的方法创新地结合了表格数据的分布、用户选择的提示模板和特定的大规模语言模型（LLM），通过尺量谱图理论提出了一种新颖的相似度度量，并构造了相似度图，分析其拉普拉斯矩阵的特征值，以确定最少所需的演示数量，从而能够更有效、准确地表示数据。这与传统的随机选择算法相比，提供了一种更优的解决方案。
## Conclusion
通过在各种数据集和大规模语言模型上进行实验，验证了本文所提出的方法的有效性和优越性。在表格数据分类任务中，该方法能够更有效地选择合适的演示示例数量，适应不同的数据分布和模型设置，从而改善整体数据分类的表现，其算法可以作为一个强有力的工具，应用于实际的上下文学习场景中。
# 99. `cs.AI` - 使用数字孪生生成数据集和高效数据增强的工业能源细分 [PDF](https://arxiv.org/pdf/2506.20525), [HTML](https://arxiv.org/abs/2506.20525)
## Authors
Christian Internò,Andrea Castellani,Sebastian Schmitt,Fabio Stella,Barbara Hammer
## Background
工业非侵入式负荷监测（NILM）受限于高质量数据集的稀缺性和工业能源消耗模式的复杂多变性。为了解决数据稀缺性及隐私问题，我们引入了合成工业能源细分数据集（SIDED），该数据集通过数字孪生仿真生成。SIDED 包括三个类型的工业设施，覆盖三个不同地理位置，涵盖了各种电器行为、天气条件和负荷特征。
## Innovation
我们提出了电器调控数据增强（AMDA）方法，这是一种计算效率高的技术，通过智能调整电器功率贡献以提高 NILM 模型泛化能力。实验表明，使用 AMDA 增强的数据训练的 NILM 模型在复杂工业电器（如联合热电系统）的能量细分方面表现出显著改进。特别是在脱机测试场景中，使用 AMDA 训练的模型实现了 0.093 的规范化细分误差，优于未使用数据增强训练的模型（0.451）及使用随机数据增强训练的模型（0.290）
## Conclusion
数据分析表明 AMIDA 能够有效对齐训练和测试数据分布，从而增强模型的泛化能力。
# 100. `cs.AI` - OctoThinker: 中期训练激励强化学习扩展 [PDF](https://arxiv.org/pdf/2506.20512), [HTML](https://arxiv.org/abs/2506.20512)
## Authors
Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu
## Background
不同的基础语言模型系列，在强化学习（RL）后训练过程中表现出不同的行为，特别是在需要大量推理的任务上。了解如何使一个基础语言模型适合强化学习是开发下一代RL可扩展基础模型的关键。本文聚焦于两个代表性的模型系列：Qwen和Llama，研究中期训练策略如何影响强化学习动态，并揭示了高质量数学语料库和问题-解答（QA）风格数据的重要性，特别是长推理链（CoT）的例子，以及数据格式对强化学习结果的影响。
## Innovation
提出了一种双重中期训练策略：Stable-then-Decay，该策略基模型首先在200B令牌上训练，学习率保持不变，然后在三个CoT集中分支中跨20B令牌训练，学习率递减。这种方法产生了OctoThinker模型家族，这些模型表现出强大的RL兼容性，并缩小了与更接近RL友好模型家族（如Qwen）的性能差距。此外，还释放了源代码模型和一个包含超过700亿个令牌的数学推理密集型语料库（即MegaMath-Web-Pro-Max），以支持进一步研究.
## Conclusion
本文的工作将有助于塑造强化学习时代基础模型的预训练策略。通过阐明上述前沿研究问题，中期训练策略可以系统地提高下游的RL性能，并通过数据格式化和双阶段中期训练策略（Stable-then-Decay）的具体应用，提高模型在强化学习任务上的兼容性和表现。
# 101. `cs.AI` - WattsOnAI：衡量、分析和可视化AI工作负载的能耗和碳足迹 [PDF](https://arxiv.org/pdf/2506.20535), [HTML](https://arxiv.org/abs/2506.20535)
## Authors
Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang
## Background
人工智能技术，尤其是大型语言模型（LLMs），迅速发展的同时，引起了人们对模型训练和推理过程中能耗和碳排放的关注。然而，现有的用于测量和报告这些影响的工具大多是分散的，缺乏系统化的度量标准整合，并且对它们之间的相关性分析支持有限。
## Innovation
本文提出了WattsOnAI，这是一个综合的软件工具包，用于衡量、分析和可视化跨AI工作负载的能耗、功耗、硬件性能和碳排放。WattsOnAI能够与现有的AI框架无缝集成，提供标准化报告，并导出细粒度的时间序列数据，以轻量、可重复的方式支持基准测试和可验证性。此外，它能够进行深度硬件指标与模型性能的相关性分析，从而识别瓶颈并优化性能。通过解决现有工具的关键限制，WattsOnAI鼓励研究界在衡量AI工作负载的原始性能的同时，也关注其环境影响，推动更具可持续性的“绿色AI”实践。
## Conclusion
WattsOnAI通过提供综合的工具和支持深度分析的能力，促使研究界在考虑AI工作负载的环境影响的同时，也关注其性能。这促进了向更具可持续性的“绿色AI”实践的转变。
# 102. `cs.AI` - DipSVD: 双重要性保护的奇异值分解方法用于高效的大语言模型压缩 [PDF](https://arxiv.org/pdf/2506.20353), [HTML](https://arxiv.org/abs/2506.20353)
## Authors
Xuan Ding,Rui Sun,Yunjian Zhang,Xiu Yan,Yueqi Zhou,Kaihao Huang,Suzhong Fu,Chuanlong Xie,Yao Zhu
## Background
大语言模型（LLMs）的计算需求和部署成本不断增加，这推动了各种压缩方法的发展。与量化和非结构化剪枝相比，奇异值分解（SVD）压缩提供了更好的硬件兼容性和理论保证。然而，现有的SVD方法主要关注原始矩阵和压缩矩阵之间的一般差异，而忽视了保护矩阵中的关键部分，这对压缩模型的性能产生了不利影响。因此，本文提出了一种双重重要性保护机制来增强SVD压缩方法：局部重要性保护，即通过通道加权数据去相关化来保持每个权重矩阵中最重要的奇异向量；全局重要性保护，即通过启发式或优化方法使较不重要的层承担更多的压缩负担，从而最小化压缩对关键层的影响。
## Innovation
本文提出了DipSVD，这是一种双重重要性保护机制的SVD压缩方法。该方法包括两部分：(1) 局部重要性保护：通过通道加权数据去相关化，保留每个权重矩阵中最重要的奇异向量；(2) 全局重要性保护：通过启发式或优化方法使较不重要的层承担更多的压缩负担，从而最小化压缩对关键层的影响。实验结果表明，DipSVD在多个基准上优于现有的SVD压缩方法，特别是在高模型压缩比时，能够实现更好的模型性能。
## Conclusion
DipSVD通过双重重要性保护机制增强了SVD压缩方法，实验结果表明其在多个SVD压缩基准上取得了优异的效果，特别是在高压缩比例下，显著提升了模型性能。
# 103. `cs.AI` - 当生活给你样本：提高多语言大语言模型推理算力的好处 [PDF](https://arxiv.org/pdf/2506.20544), [HTML](https://arxiv.org/abs/2506.20544)
## Authors
Ammar Khairi,Daniel D'souza,Ye Shen,Julia Kreutzer,Sara Hooker
## Background
近年来，大语言模型（LLMs）的发展侧重于扩展推理时的计算规模，同时在不重新训练模型的情况下提升性能。常见的做法是并行采样多个输出，然后从中选择一个作为最终输出。然而，到目前为止的研究主要集中在英语和一些特定领域，如数学和代码上。相比之下，本研究更关注能跨开放任务、形式验证任务以及多种语言的一般性技术。本研究探讨了如何在多语言、多任务的场景下稳健地扩展推理时的计算能力。研究结果表明，温度变异性采样策略和选择策略都必须调整以适应不同的领域和语言环境。现有的选择方法被评价过，证明了有效的英文策略通常在语言间难以泛化。我们提出了针对多语言和多任务推理场景的新型采样和选择策略，并展示了它们在语言和任务上带来了显著的改进。特别是在8B模型上，我们的综合采样和选择方法导致在m-ArenaHard-v2.0提示下的平均胜率提升了6.8%，相比专有模型如Gemini。在更大规模上，使用我们方法的Command-A（111B模型）仅使用五个样本就比单样本解码在相同基准上获得了9.0%的胜率提升，具备显著的优势且成本较低。研究结果强调了需要语言和任务感知的推理计算方法，以便于推动未被充分代表的语言在性能上的改进。
## Innovation
本研究提出了针对多语言和多任务推理场景的新型采样和选择策略，并展示了这种综合方法在多个语言和任务上的显著改进。特别是在小模型（8B）上平均胜率提高了6.8%，在大模型（111B）上仅使用五个样本即获得了9.0%的胜率提升。这些方法在语言间泛化的更好，显著优于现有的选择方法，并且成本更为低廉。
## Conclusion
本研究强调了语言和任务感知方法在推理计算中的重要性，并提出了有效的语言和多任务场景下的新采样和选择策略。研究表明，这些方法在多种语言和任务上都取得了显著的性能提升，表明推进未充分代表的语言的性能改进具有重要意义。
# 104. `cs.AI` - Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks [PDF](https://arxiv.org/pdf/2506.20548), [HTML](https://arxiv.org/abs/2506.20548)
## Authors
Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao
## Background
随着深度学习的快速发展，特别是生成对抗网络（GANs）和扩散模型（DMs）的应用，AI生成的图片（俗称“深度伪造”）几乎与真实图片无法区分。这些图像广泛传播于在线社交网络（OSNs），其潜在的滥用问题引起了关注。现有的深度伪造检测方法忽略了压缩带来的“块效果”，这种效果掩盖了伪造图片的特征，主要集中在原始图片上，在实际应用场景中很少遇到。这些因素阻碍了高效准确的深度伪造检测。
## Innovation
本文提出了PLADA（Pay Less Attention to Deceptive Artifacts）框架，专门应对配对数据不足以及压缩图像使用效果不佳的问题。PLADA包含两个核心模块：Block Effect Eraser（B2E），采用了双阶段注意力机制来处理“块效果”，以及Open Data Aggregation（ODA），该模块处理配对和未配对数据以提高检测准确率。与最先进的技术相比，本文方法在OSNs中检测深度伪造表现更佳。此外，该研究强调了“块效果”在深度伪造检测中的重要性，提供了一个适用于开放环境的稳健解决方案。
## Conclusion
本文实验结果表明，即使在有限的配对数据和压缩条件下，PLADA也能实现深度伪造检测的卓越平衡，显著优于现有最先进技术。本研究工作强调“块效果”是一个关键因素，并为OSNs上的开放世界场景下的深度伪造检测提供了坚实的解决方案。
# 105. `cs.AI` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大型语言模型（LLMs）在代码生成方面表现出色，但在应对外部库API频繁更新时却显得无力。这一限制源于它们对过时API知识的依赖，即使有最新的文档也难以适应动态环境中的代码生成需求。
## Innovation
提出了一种名为ReCode的新颖框架，该框架模仿了人类程序员在API变更时的适应性。具体来说，构建了一个包含约2,000条数据的训练集，以便LLMs根据更新信息进行版本迁移。同时引入了一种改进的字符串相似度度量作为强化学习的奖励。实验证明，ReCode显著提高了LLMs在动态API场景下的代码生成性能，特别是在未见过的任务CodeUpdateArena上表现尤为突出。与监督微调相比，ReCode对LLMs的一般代码生成能力影响较小。
## Conclusion
ReCode在多个LLMs和强化学习算法（GRPO和DAPO）上进行了应用，均取得了持续改进。值得注意的是，训练后的Qwen2.5-Coder-7B超过了一个参数量为32B的代码指令调优模型和具有相同架构的推理模型。代码可以在这个链接中获得：this https URL.
# 106. `cs.AI` - 利用观察分组进行因果表示学习的胸部X光分类 [PDF](https://arxiv.org/pdf/2506.20582), [HTML](https://arxiv.org/abs/2506.20582)
## Authors
Rajat Rasal,Avinash Kori,Ben Glocker
## Background
因果表示学习旨在揭示数据生成过程背后的真正因果关系。在医学成像中，这为改善特定任务的潜在特征的泛化能力和鲁棒性提供了机会。这项研究提出了通过端到端框架对疾病分类进行胸部X光的因果表示学习的概念，通过将观察进行分组来学习可识别的代表，以强化种族、性别和成像视角的不变性。
## Innovation
引入了利用观察分组进行因果表示学习的新框架，特别适用于胸部X光的疾病分类任务。这种分组方法通过确保种族、性别和成像视角的不变性来提高表示的识别性，从而提高泛化能力和鲁棒性。
## Conclusion
实验结果表明，使用这种因果表示方法，分类任务的泛化能力和鲁棒性得到显著改善。
# 107. `cs.AI` - Show, Tell and Summarize: 呈现、讲述并总结：利用视觉线索辅助句子总结的稠密视频标题生成 [PDF](https://arxiv.org/pdf/2506.20567), [HTML](https://arxiv.org/abs/2506.20567)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan
## Background
该研究构建了一个分段与总结（DaS）框架，用于稠密视频标题生成。首先将无修剪的长视频分割为多个事件提案，每个提案由一系列短视频片段组成。随后从每个片段中提取视觉特征，并利用现有的图像/视频描述方法来生成一段描述这个片段的句子。研究表明，生成的句子包含了关于整个事件提案的丰富语义描述，因此把稠密视频标题生成任务转化为一种有视觉特征辅助的句子总结问题。该研究提出了一种新的两阶段长短期记忆（LSTM）方法，配备了一种新的层次注意机制，以此总结所有生成的句子，使其形成一个全面描述该事件提案的句子。两阶段的LSTM首先作为一个编码器，输入生成的句子中的语义词汇和事件提案中所有片段的视觉特征，以有效总结与事件提案相关的语义和视觉信息；第二阶段的LSTM作为一个解码器，以第一阶段的输出和事件提案中所有片段的视觉特征为输入，生成一个描述事件提案的句子。
## Innovation
提出的分段与总结（DaS）框架，采用两阶段LSTM网络，第一阶段LSTM网络作为编码器有效总结语义和视觉信息，第二阶段LSTM网络作为解码器生成描述事件提案的句子，同时采用新的层次注意机制增强句子生成效果。该方法将稠密视频标题生成任务转化为有视觉特征辅助的句子总结问题，并在ActivitiesNet Captions数据集上的全面实验中展现了此新方法的有效性。
## Conclusion
该研究提出的分段与总结（DaS）框架对于稠密视频标题生成任务的有效性在活动网视频描述数据集上得到了验证。通过两阶段LSTM网络结合新的层次注意机制，实现了事件提案级别的语义和视觉信息的有效总结，生成了全面描述事件提案的句子。
# 108. `cs.AI` - AI在写作过程中的作用：如何有针对性的AI支持促进学生写作 [PDF](https://arxiv.org/pdf/2506.20595), [HTML](https://arxiv.org/abs/2506.20595)
## Authors
Momin N. Siddiqui,Roy Pea,Hari Subramonyam
## Background
随着技术如ChatGPT的普及，人们对其对学生写作的影响产生了担忧，特别是减少了学生的自主性以及在内容上的浅表性涉入。尽管独立的聊天式语言模型往往会产生劣质的写作结果，但证据表明，有针对性设计的AI写作支持工具可以增强写作过程的效果。本研究旨在探讨不同AI支持方法如何影响作者的自主性和知识深度转换。通过随机对照试验，与90名本科生进行测试，比较了三个条件：（1）聊天式语言模型的写作助手，（2）集成AI写作工具以支持多样化的子过程，以及（3）标准写作界面（对照组）。研究发现，在AI支持条件下，使用集成AI写作工具的学生在写作过程中的自主性更强，并且整体上更深入地进行了知识转化。这些结果显示，针对写作过程特定方面的精心设计的AI写作支持，可以帮助学生保持对其工作的所有权，同时促进更深层次的内容涉入
## Innovation
本研究通过一项随机对照试验设计，评估了不同AI支持方法对写作过程中的自我感知和知识深度转化的影响。特别是，研究强调了集成AI写作工具在改善学生写作自主性和促进深入知识转化方面的优势，这在之前的研究中并未充分探讨
## Conclusion
研究结果表明，在AI支持条件下，使用集成AI写作工具的学生在写作过程中的自主性更强，并且整体上更深入地进行了知识转化。这些结果显示，针对写作过程特定方面的精心设计的AI写作支持，可以帮助学生保持对其工作的所有权，同时促进更深层次的内容涉入。
# 109. `cs.AI` - 基于图的句子总结的密集视频字幕生成 [PDF](https://arxiv.org/pdf/2506.20583), [HTML](https://arxiv.org/abs/2506.20583)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou
## Background
最近，密集视频字幕技术在检测和描述长未修剪视频中的所有事件方面取得了显著进展。尽管取得了令人鼓舞的结果，但现有大多数方法未能充分利用事件时间提议内的场景演化，尤其是在场景和对象随着时间的推移发生较大变化的情况下表现较差。已有方法在处理较长提议中的场景和对象变化时表现不佳，因此需要改进以更好地捕捉和描述这些变化。本文在两个阶段提出了一个图基分区和总结（GPaS）框架来解决这个问题。通过将整个事件提议拆分成多个短视频片段进行细节描述，再将这些片段生成的描述性句子汇总成一句话来描述整个事件，从而捕捉和描述事件中的场景变化。并重点在总结阶段探索了基于语义词的关系，提出了一种有效利用语义词关系的方法。
## Innovation
提出了一种图基分区和总结（GPaS）框架，分为“分区”和“总结”两个阶段。在“分区”阶段，将整个事件提议拆分成多个短视频片段进行详细的描述处理。在“总结”阶段，将每个片段生成的描述性句子汇总成一句话来描述整个事件，并通过图卷积网络（GCN）和长短期记忆网络（LSTM）的有效结合，处理语义词之间的关系，通过视觉线索改善模型捕捉场景演化的能力。分别提出了两种GCN-LSTM交互模块的方案，以实现无缝集成。
## Conclusion
通过在ActivityNet Captions数据集和YouCook II数据集上与现有最先进的方法进行广泛的比较，证明了该方法的有效性。
# 110. `cs.AI` - 分布视角下的反事实影响 [PDF](https://arxiv.org/pdf/2506.20481), [HTML](https://arxiv.org/abs/2506.20481)
## Authors
Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye
## Background
机器学习模型被发现会记住训练数据中的样本，这引发了隐私和泛化方面的担忧。反事实自影响是研究记忆现象的一个流行指标，量化了样本在模型中的预测如何依赖于其是否包含在训练数据集中。然而，最近的研究表明，记忆不仅受自影响的影响，其他训练样本，尤其是（近）重复样本，对记忆的影响也非常大。本文关注的是将反事实影响视为分布性的量，考虑所有训练样本对某个样本记忆程度的综合影响，而不是仅关注自影响。这在小型语言模型和图像分类中都有观察现象，表明单凭自影响估计不足以理解记忆的实际风险，（近）重复样本虽然减少了自影响，但仍然可以（近）提取出来。这项研究揭示了记忆是跨训练数据复杂互动的结果，而不仅仅是由自影响决定的，模型的全面影响分布能更好地捕捉内存现象，而不仅仅是自影响。
## Innovation
将反事实影响视为分布性量，而非仅仅关注自影响，考虑所有训练样本对某个样本记忆程度的综合影响，发现（近）重复样本虽然减少自影响，但仍然可以（近）提取出来，从而揭示了记忆背后复杂的交互作用，并强调全面影响分布比单凭自影响更能准确捕捉记忆现象。这项研究还在小型语言模型和图像分类中观察到了（近）重复样本的存在，单从影响分布就能揭示CIFAR-10等数据集中的（近）重复样本。这些发现表明了记忆现象的复杂性以及全面影响分布分析的重要性。
## Conclusion
反事实影响不仅可以视为来自样本自身的动态，更应该考虑其他训练样本的影响以全面了解样本记忆的程度。研究结果表明，记忆现象的核心是一个复杂的交互过程，且不能仅凭自影响来准确评估风险。准确地识别和分析（近）重复样本的存在关系，有助于更全面地理解记忆的来源，且能帮助识别潜在的记忆风险。
# 111. `cs.AI` - Define-ML：一种构思机器学习增强系统的方法 [PDF](https://arxiv.org/pdf/2506.20621), [HTML](https://arxiv.org/abs/2506.20621)
## Authors
Silvio Alonso,Antonio Pedro Santos Alves,Lucas Romao,Hélio Lopes,Marcos Kalinowski
## Background
随着机器学习（ML）在软件系统中的日益普及，需要专门的方法来应对ML特有的挑战，包括数据依赖性、技术可行性以及业务目标与概率系统行为之间的对齐。传统的构思方法如精益启动（Lean Inception）缺乏对这些ML考虑因素的结构化支持，可能导致产品愿景不一致和不切实际的期望.
## Innovation
本文介绍了一种名为Define-ML的框架，该框架基于精益启动，通过增加定制的活动，如数据源映射、特征到数据源映射和机器学习映射，系统地将数据和技术限制纳入早期的ML产品构思。开发和验证方法遵循技术转移模型，包括静态验证（通过一个玩具问题）和动态验证（在一个实际的工业案例研究中）
## Conclusion
Define-ML提供了一种开放获取且已验证的方法，用于ML产品的构思，基于精益启动的灵活性，同时使特征与可用数据对齐，并增加对技术可行性的认识。所有参与者都表示有意采用Define-ML。
# 112. `cs.AI` - 通过自适应黑盒对抗攻击披露网络入侵检测系统的漏洞 [PDF](https://arxiv.org/pdf/2506.20576), [HTML](https://arxiv.org/abs/2506.20576)
## Authors
Sabrine Ennaji,Elhadj Benkhelifa,Luigi V. Mancini
## Background
随着对抗攻击逐渐受到关注，尽管理论进展在不断增加，但在实践中，特别是在网络流量这样的结构化数据上的对抗操作仍旧面临巨大挑战。现有方法的不明确性限制了其再现性，导致现有的防御措施难以应对不断演变的对抗攻击。因此，亟需一种新的方法来解决这些问题，特别是黑盒对抗攻击，即不假设系统访问并且不依赖多次探查的方法，能够有效减少交互，提高适用性与适应性，以应对现实中的对抗攻击挑战。这篇论文正是基于此背景提出了新型的自适应黑盒对抗攻击策略，进而提高对网络攻击的敏感度，并构建坚固的防御体系作为重要的研究进展之一。
## Innovation
这篇论文提出了一种新型的自适应黑盒对抗攻击方法，该方法严格遵循黑盒攻击的限制，通过减少互动来避免被检测，以更真实地模拟现实攻击场景。该方法利用变化点检测和因果分析来选择和定位敏感特征，进行扰动，从而实现轻量级设计，具有低的计算成本和高的部署性。这种方法不同于以往依赖系统访问或反复试探的技术，显著提高了对抗攻击的效果和适用性，同时也为反向防御机制的发展提供了新思路。
## Conclusion
通过自适应黑盒对抗攻击技术，这篇论文揭示了网络入侵检测系统的脆弱性，并展示了攻击方法的有效性，使得攻击者能够在最少的互动中躲避检测。这不仅增强了对网络攻击的理解，而且为开发稳固的防御措施打下了基础，有助于提升网络安全水平。
# 113. `cs.AI` - 由大型语言模型驱动的建筑信息建模中的代码合规性检查 [PDF](https://arxiv.org/pdf/2506.20551), [HTML](https://arxiv.org/abs/2506.20551)
## Authors
Soumya Madireddy,Lu Gao,Zia Din,Kinam Kim,Ahmed Senouci,Zhe Han,Yunpeng Zhang
## Background
在建筑信息建模（BIM）中，手动编码合规性检查耗时且容易出错。研究人员提出了一个由大型语言模型（LLM）驱动的方法，以半自动化此重要过程。该方法利用LLM如GPT、Claude、Gemini和Llama与Revit软件结合，用于解释建筑规范、生成Python脚本并在BIM环境中执行半自动化合规检查。这些案例研究表明，该系统能够减少合规检查所需的时间和努力，同时提高准确性，简化了违规行为（如非合规房间尺寸、材料使用和对象放置）的识别过程，自动评估关系并生成可操作的报告。
## Innovation
该研究提出了一种由大型语言模型驱动的方法，结合Revit软件实现建筑信息建模中的代码合规性检查的半自动化。系统自动评估关系并生成可操作报告，简化违规行为的识别过程。这种方法通过简化复杂规定、确保遵守标准，消除了手动检查中的重复任务，提供了全面、可适应且经济有效的解决方案，为建筑信息建模中的合规性检查带来了有希望的进步，具有在建筑项目中的广泛应用前景。
## Conclusion
该研究开发的系统显示了在单户住宅项目和办公建筑项目中，通过结合LLM和Revit软件半自动化合规性检查的能力。这种方法能够简化识别非合规行为的过程，减少人工检查所需的时间和努力，提高准确性，为不同类型的建筑项目中的法规文件提供全面、灵活且成本效益高的合规检查解决方案，展示了其在BIM领域的潜在广泛应用。
# 114. `cs.AI` - 微生物镜像图像的解缠表示 [PDF](https://arxiv.org/pdf/2506.20649), [HTML](https://arxiv.org/abs/2506.20649)
## Authors
Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone
## Background
显微镜图像分析在不同应用中至关重要，例如诊断、合成工程和环境监测。现代成像系统使得获取越来越多的显微镜图像成为可能，因此需要发展大量的基于深度学习的自动图像分析方法。尽管深度神经网络在这一领域表现出卓越性能，但可解释性，这是显微镜图像分析的重要要求，仍然是个待解决的挑战。这项工作提出了一个解缠表征学习（DRL）的方法来提高显微镜图像分类模型的可解释性。通过使用三种不同显微镜图像领域的基准数据集（浮游生物、酵母体泡和人类细胞），展示了DRL框架，基于从合成数据转移学习表征，可以在准确性和可解释性方面提供良好平衡的案例。
## Innovation
提出了一种解缠表征学习（DRL）的方法，利用从合成数据中学习到的表征来获取显微镜图像的解缠表示。这种方法为显微镜图像分类提供了一个良好的准确性和可解释性的平衡，这是现有方法面临的挑战。
## Conclusion
本文提出的DRL框架在准确性和可解释性方面提供平衡表现，通过从合成数据中提炼的有效表征，能够提升模型在显微镜图像分类中的表现。即使对于完全不同类型的显微镜图像，如浮游生物、酵母体泡和人类细胞，该方法也显示出强大的适用性。
# 115. `cs.AI` - 自助优化模型融合：一种多精度自动化模型融合框架 [PDF](https://arxiv.org/pdf/2502.04030), [HTML](https://arxiv.org/abs/2502.04030)
## Authors
Guinan Su,Jonas Geiping
## Background
大型语言模型（LLMs）的推理能力是一个关键领域，但开发这些能力需要大量的专有数据集和计算资源。模型合并提供了一种有效补充能力的途径，它通过结合多个模型而不重新训练来实现，但当前的合并方法依赖于手动设计的策略来合并超参数，这限制了潜在模型组合的探索，并需要大量的人力。
## Innovation
本文提出了一种自动化模型合并框架，通过多精度近似实现细粒度的合并策略探索，同时降低计算成本。该框架支持单目标和多目标优化，并引入了两种新颖的搜索空间：分层融合（LFS）和深度整合（DIS）。
## Conclusion
研究表明，搜索能够自主发现1）进一步提升单目标性能的合并，即使在模型已经微调的任务上也有效，以及2）能够在多个任务上优化多目标前沿的合并。有效合并可以在有限的计算资源内找到，例如在不到500个搜索步骤内。
# 116. `cs.AI` - 为促进更好的归纳型知识图谱完成基准数据集 [PDF](https://arxiv.org/pdf/2406.11898), [HTML](https://arxiv.org/abs/2406.11898)
## Authors
Harry Shomer,Jay Revolinsky,Jiliang Tang
## Background
知识图谱完成（KGC）旨在预测知识图谱中的缺失事实。近年来，人们越来越关注设计在归纳设置中能出色表现的方法，即在推理过程中所见的实体和关系部分或全部在训练时未被观测到。虽然已经提出了多种用于归纳型KGC的基准数据集，但它们都是从用于传递型KGC的现有知识图谱中划分出来的子集。然而，研究者观察到，当前构造归纳型KGC数据集的方法无意中创造出一种捷径，即使在忽略关系信息的情况下也能被利用。具体而言，发现个性化PageRank（PPR）得分在大多数数据集上可以取得较强或接近最佳结果。
## Innovation
该研究探讨了导致上述问题的根本原因，并提出了一种替代的归纳型KGC数据集构建策略，以减轻PPR捷径的影响。通过使用新的数据集，研究者对多种流行的KGC方法进行了基准测试，并分析了它们的性能，新基准数据集有助于更好地了解归纳型KGC的能力和挑战，从而消除任何可能混淆表现的捷径。
## Conclusion
新的基准数据集有助于促进对归纳KGC的理解，去除其中的捷径问题，提升了研究的透明度。研究者还分享了代码和数据集，以便进一步研究。
# 117. `cs.AI` - DeepQuark: 深度神经网络方法研究多夸克束缚态 [PDF](https://arxiv.org/pdf/2506.20555), [HTML](https://arxiv.org/abs/2506.20555)
## Authors
Wei-Lin Wu,Lu Meng,Shi-Lin Zhu
## Background
研究强SU(3)颜色相互作用下多夸克束缚态的复杂性超出了电子或核子系统的复杂性。为此，首次采用了基于深度神经网络的变分蒙特卡洛方法来处理多夸克系统特有的挑战，如更强的相互关联、额外的离散量子数以及难以解决的束缚相互作用。该方法的作用是有效地解决这些独特问题，并展示出与最先进的方法，包括扩散蒙特卡洛和高斯展开方法，在核子、重四夸克和全重四夸克系统中的竞争表现。特别地，它在五夸克系统中展示了优于现有计算，尤其是对于三重带重夸克的五夸克分子的计算超过了现有结果。对于核子系统，通过引入三体束缚景波函数交互作用，实现无需额外计算成本的成功处理。在四夸克系统中，能够以无偏的形式描述重子分子和紧凑的四夸克态。在五夸克部分，找到了弱束缚的$bar{D}^*text{Xic}_{cc}^*$分子$P_{ccbar{c}}(5715)$及其底夸克伙伴$P_{bbbar{b}}(15569)$，它们可以视为重子分子$T_{cc}$的模拟。
## Innovation
开发了名为DeepQuark的新型且高效的架构来处理多夸克系统独特的挑战，包括更强大的相关性、额外的离散量子数和难以处理的束缚相互作用。方法展示了与最先进的方法（扩散蒙特卡洛和高斯展开方法）在核子、双重重四夸克和全重四夸克系统中的竞争表现，并在五夸克系统中展示了优于现有计算的结果。DeepQuark还展示了在更大多夸克系统中的扩展潜力，超越了传统方法的计算障碍，并作为探索超越二体相互作用的束缚机制的有效框架，有助于非微扰量子色动力学和一般多体物理的深入理解。
## Conclusion
DeepQuark在多夸克系统中表现出了强大的潜力，超越了传统方法在计算上的障碍。此外，它为探索多夸克状态中的束缚机制提供了一个强有力的方法，可能为非微扰QCD和广义多体物理提供有价值的见解。建议在D波$J/text{ψ}text{Λ}_c$通道中寻找$P_{ccbar{c}}(5715)$的实验。
# 118. `cs.AI` - RefPentester: 一种基于大型语言模型的具有知识导向和自我反思能力的渗透测试框架 [PDF](https://arxiv.org/pdf/2505.07089), [HTML](https://arxiv.org/abs/2505.07089)
## Authors
Hanzheng Dai,Yuanliang Li,Jun Yan,Zhibo Zhang
## Background
自动化渗透测试（AutoPT）利用大型语言模型（LLMs）的固有知识来自动化伦理黑客攻击过程，识别目标系统的漏洞，引起了广泛的关注。然而，现有的基于LLM的AutoPT框架在具有挑战性任务中的表现往往不如人类专家，主要原因包括LLM训练中知识的不平衡性、规划过程中的短视性、在命令生成中的幻觉现象，以及缺乏机制从以往失败中学习以改进PT策略，限制了PT策略的适应性提升。
## Innovation
我们提出了一个基于LLMs的知识导向和自我反思的AutoPT框架，名为RefPentester。该框架旨在帮助人类操作员识别当前PT过程所处的阶段，选择每个阶段的适当战术和技术，选择建议的操作，提供逐步操作指导，并从之前的失败操作中进行反思和学习。此外，我们将PT过程建模为七状态的阶段机器，以有效集成提出的框架。实验表明，RefPentester在解密Hack The Box的Sau机器中的凭据方面表现良好，相比基线GPT-4o模型提高了16.7%的成功率，并且在PT阶段转换中也显示出更优异的成功率。
## Conclusion
RefPentester能有效解决现有AutoPT框架中的问题，通过将PT过程建模为七状态的阶段机器，并利用大型语言模型的知识导向和自我反思能力，提高了PT过程的成功率和适应性。
# 119. `cs.AI` - 融合AI以实现响应式多轮在线对话并采用新颖的动态路由和反馈适应机制 [PDF](https://arxiv.org/pdf/2506.02097), [HTML](https://arxiv.org/abs/2506.02097)
## Authors
Priyaranjan Pattnayak,Amit Agarwal,Hansa Meghwani,Hitesh Laxmichand Patel,Srikant Panda
## Background
检索增强生成（RAG）系统和以大型语言模型（LLM）为动力的聊天机器人通过结合生成能力和外部知识检索，极大地推进了对话AI的发展。然而，在大型企业的部署中面临多样化的用户查询、高延迟、虚构陈述和难以整合频繁更新的特定领域知识等关键挑战。该领域需要更有效的解决方案来满足企业的对话AI应用需求。
## Innovation
本论文提出了一个新颖的混合框架，将RAG与基于意图的预制响应相结合。该框架利用预先定义的高置信度响应提高效率，同时动态将复杂的或有歧义的查询路由到RAG管道中。此外，还引入了一个对话上下文管理器以确保多轮交互的一致性，以及一个反馈循环用于改进意图、动态调整置信度阈值和逐步扩展响应范围。
## Conclusion
实验结果表明，该提出的框架在准确率（95%）和延迟（180ms）方面达到了平衡，表现出色，优于RAG和基于意图的系统，适用于各种类型的查询，将其定位为企业的对话AI应用中可扩展和自适应的解决方案。
# 120. `cs.AI` - 大语言模型在非洲语言中的现状：进展与挑战 [PDF](https://arxiv.org/pdf/2506.02280), [HTML](https://arxiv.org/abs/2506.02280)
## Authors
Kedir Yassin Hussen,Walelign Tewabe Sewunetie,Abinew Ali Ayele,Sukairaj Hafiz Imam,Shamsuddeen Hassan Muhammad,Seid Muhie Yimam
## Background
大型语言模型（LLMs）正在改变自然语言处理（NLP），但对非洲的2000种低资源语言带来的好处相对有限。本文比较分析了六种LLMs、八种小型语言模型（SLMs）和六种专门化的小型语言模型（SSLMs）对非洲语言的支持情况，涵盖了语言覆盖率、训练集、技术限制、书写系统问题以及语言建模路线图。研究发现42种受支持的非洲语言和23个可用的公共数据集，但大多数非洲语言并未受到支持，且仅有拉丁语、阿拉伯语和盖伊兹语被识别，而其他20种活跃的书写系统均被忽略。主要挑战包括数据缺乏、分词偏差、高昂的计算成本及评估难题，这些问题要求进行语言标准化，社区应发展语料库，并开发有效的非洲语言适应方法。
## Innovation
本文首次对六种LLMs、八种SLMs和六种SSLMs对非洲语言的支持情况进行系统比较分析，识别出支持的语言和数据集数量，并指出其中存在的问题和差距。
## Conclusion
非洲语言在大型语言模型的支持下存在重大差距和挑战，需要进行标准化、发展社区语料库及有效的适应方法来解决数据不足、书写系统忽视、计算成本及评估问题。
# 121. `cs.AI` - Weighted Mean Frequencies：一种用于4D Flow MRI分割的手工Fourier特征 [PDF](https://arxiv.org/pdf/2506.20614), [HTML](https://arxiv.org/abs/2506.20614)
## Authors
Simon Perrin,Sébastien Levilly,Huajun Sun,Harold Mouchère,Jean-Michel Serfaty
## Background
近年来，4D Flow MRI图像的应用使得在感兴趣体积和心脏周期内定量分析速度场成为可能。然而，这些生物标志物中的分辨率低和噪声问题仍然是显著的问题。先前的研究表明，诸如壁剪应力这样的生物标志物特别受到血管分割低分辨率的影响。目前最先进的方法是相位对比磁共振血管造影（PC-MRA），用于实现分割。本文的目的是介绍一种新的手工特征，提供一种新型的4D Flow MRI图像可视化方法，对于分割任务是很有用的。这一特征称为加权平均频率（WMF），可以揭示三维空间中一个体素被脉动流通过的区域，该特征代表了所有脉动速度体素的外壳。利用这种特征进行的两种实验表明，在使用最佳阈值和深度学习方法分割4D Flow MRI图像时，效果有了显著提升，分别在IoU和Dice上提高0.12和0.13，相比PC-MRA特征。这表明此特征有可能对未来其他血管区域（如心脏或大脑）的分割过程提供有价值的见解。
## Innovation
本文介绍了一种新的手工特征——加权平均频率（WMF），该特征能够揭示三维空间中一个体素被脉动流通过的区域，并且在使用最佳阈值和深度学习方法进行4D Flow MRI图像分割实验中，该特征显著提升了IoU和Dice值，相比PC-MRA特征分别提高了0.12和0.13。
## Conclusion
加权平均频率（WMF）这一特征在4D Flow MRI图像分割中表现出显著的提升，能够为未来其他血管区域的分割过程提供有价值的见解，具有良好的应用前景。
# 122. `cs.AI` - Turing Test 2.0: The General Intelligence Threshold [PDF](https://arxiv.org/pdf/2505.19550), [HTML](https://arxiv.org/abs/2505.19550)
## Authors
Georgios Mappouras
## Background
随着人工智能（A.I.）和大型语言模型，如ChatGPT的兴起，追求通用人工智能（A.G.I.）的新竞赛开始了。尽管人们对A.I.何时以及如何达到A.G.I.进行了猜测，但在使用图灵测试及其现代变体等工具衡量其智能时，仍未达成一致意见，明确区分哪些系统达到或超越了A.G.I.的标准。
## Innovation
本文讨论了为什么传统的图灵测试等方法不足以衡量或检测A.G.I.。为了弥补这一不足，作者提出了两个新的贡献：首先，明确提出了一般智能（G.I.）的定义，并设定了一个G.I.阈值（G.I.T.）来区分达到A.G.I.和未达到A.G.I.的系统；其次，提出了一种新的框架，以构建能够检测系统是否达到一般智能的简单、全面且明确的测试方法。这一新框架被称为图灵测试2.0。作者还通过现代A.I.模型实例验证了该测试框架的实际应用。
## Conclusion
本文展示了图灵测试2.0框架的实际应用，以检测现代A.I.模型是否达到了一般智能的标准。
# 123. `cs.AI` - 复杂性陷阱：完备性障碍 [PDF](https://arxiv.org/pdf/2506.10304), [HTML](https://arxiv.org/abs/2506.10304)
## Authors
Jasper Yao
## Background
本文认为，AI对齐不仅困难，而且是建立在根本的逻辑悖论之上的。进一步阐述了《枚举悖论》，即使用机器学习的原因是我们无法枚举所有必要的安全规则，但让ML安全却要求产生只能从我们承认不可能枚举的枚举中生成的示例。通过五项独立的数学证明或“不可能性支柱”来证实这个悖论。主要结果包括：几何不可能性、计算不可能性、统计不可能性、信息论不可能性以及动态不可能性。这些结果表明，追求安全且高度先进的AI不是克服技术障碍的问题，而是面对根本且相互关联的障碍的问题。研究目前还在进展中，以Lean4形式对核心定理进行形式验证。
## Innovation
文章深入探讨了复杂性障碍并提出了五种“不可能性支柱”来证明对齐AI的困难性。这些理论为AI对齐提供了新的见解，指出了潜在的不可逾越的逻辑和计算障碍，强调了目前技术可能无法解决的根本问题。
## Conclusion
这些复杂性阻碍迫使该领域面临战略三角困境。当前对核心定理正在进行形式验证。
# 124. `cs.AI` - 科学家的第一次考试：通过感知、理解和推理探究MLLM的认知能力 [PDF](https://arxiv.org/pdf/2506.10521), [HTML](https://arxiv.org/abs/2506.10521)
## Authors
Yuhao Zhou,Yiheng Wang,Xuming He,Ruoyao Xiao,Zhiwei Li,Qiantai Feng,Zijie Guo,Yuejin Yang,Hao Wu,Wenxuan Huang,Jiaqi Wei,Dan Si,Xiuqi Yao,Jia Bu,Haiwen Huang,Tianfan Fu,Shixiang Tang,Ben Fei,Dongzhan Zhou,Fenghua Ling,Yan Lu,Siqi Sun,Chenhui Li,Guanjie Zheng,Jiancheng Lv,Wenlong Zhang,Lei Bai
## Background
科学研究越来越多地依赖于基于丰富信息的科学数据和领域专业知识的复杂多模态推理。现有科学基准主要集中在评估MLLMs的知识理解能力，而忽视了它们的感知和推理能力。因此，有必要通过一个新的基准来全面评估MLLMs的科学认知能力。
## Innovation
提出了科学家的第一次考试（SFE）基准，旨在通过三个相关层次来评估MLLMs的科学认知能力：科学信号感知、科学属性理解、科学比较推理。该基准包括830个经过专家验证的跨类型问题可视化问答对，覆盖5个高价值学科的66个多模态任务，展示了当前最先进的GPT-o3和InternVL-3在SFE上的低得分，表明在科学领域仍有许多改进空间。
## Conclusion
希望通过SFE获得的见解能够促进AI增强科学发现的发展。
# 125. `cs.AI` - 通过枪声录音的声学分析解析枪型层次 [PDF](https://arxiv.org/pdf/2506.20609), [HTML](https://arxiv.org/abs/2506.20609)
## Authors
Ankit Shah,Rita Singh,Bhiksha Raj,Alexander Hauptmann
## Background
枪支相关暴力和大规模枪击事件的频率增加构成了对公共安全的重大威胁。及时且准确的信息对于执法机构至关重要，有助于减轻此类事件的影响。尽管现有商业枪声检测系统在实际表现上有效，但它们通常面临着高昂的成本。本文探索了一种成本效益较高的替代方案，即将来自手机等普及设备的枪声录音的声学分析用于检测枪声，并分类枪支类型。该研究详细介绍了使用3459个录音的自编数据集进行枪支类型层次解析的研究。研究调查了不同枪支类型、弹药和射击方向导致的不同枪声特征，包括膛门爆炸和冲击波。研究提出了并评估了基于支持向量机（SVM）作为基线和一种先进的卷积神经网络（CNN）架构的机器学习框架，用于联合检测枪声和分类枪支类型。研究结果表明，深度学习方法在干净标注数据上的平均精度（mAP）达到0.58，优于SVM基线（mAP 0.39）。还讨论了与数据质量、环境噪声以及使用网络爬取数据时的表现泛化有关的挑战（mAP 0.35）。长期愿景是开发一个高度准确、实时的系统，能够在常见录音设备上部署，显著降低检测成本，并为一线响应者提供关键情报。
## Innovation
本文提出了一种低成本的枪声检测与枪支类型分类方法，利用手机等普及设备的录音进行声学分析。研究采用了包括支持向量机（SVM）和卷积神经网络（CNN）在内的机器学习框架来实现联合检测与分类，尤其是在使用网络数据时表现更优。此外，研究还讨论了如何克服数据质量和环境噪音等挑战，以提高检测系统的准确性和实用性。
## Conclusion
本文通过自编数据集的研究，证明了利用声学特征和机器学习算法进行枪声检测与枪支类型分类的有效性。深度学习方法在处理干净数据时取得了较好的性能。研究还探讨了数据质量、环境噪音以及网络数据等挑战对系统性能的影响。研究为开发低成本的实时枪声检测系统提供了理论基础，有助于提高公共安全水平。
# 126. `cs.AI` - 可解释强化学习：概念、算法、挑战的综述 [PDF](https://arxiv.org/pdf/2211.06665), [HTML](https://arxiv.org/abs/2211.06665)
## Authors
Yunpeng Qing,Shunyu Liu,Jie Song,Huiqiong Wang,Mingli Song
## Background
强化学习（RL）是一种流行的机器学习范式，其中智能代理与环境交互以实现长期目标。深度强化学习（DRL）得益于深度学习的复兴，在复杂控制任务中取得了显著的成功。尽管取得了令人鼓舞的结果，但基于深度神经网络的主体框架通常被视作一个黑盒子，阻碍了实践者在高度安全和可靠性的现实场景中信任和应用训练的代理。为了解决这个问题，大量文献致力于揭示智能代理的内部机制，通过构建内在可解释性或事后解释性。
## Innovation
本文提供了一个全面的可解释强化学习（XRL）现有工作的综述，并引入了一种新的分类法，将先前的工作明确划分为模型解释、奖励解释、状态解释和任务解释方法。本文还回顾并强调了通过利用人类知识来促进学习效率和代理性能的方法，而这种方法在XRL领域通常被忽视。
## Conclusion
本文旨在提供XRL高层次的总结，并激励未来更有效的XRL解决方案的研究。相关开源代码被收集和分类在以下网址：this https URL.
# 127. `cs.AI` - 通过提示、微调和跨分布提示评估小型语言模型的泛化能力和内部表示稳定性 [PDF](https://arxiv.org/pdf/2506.17289), [HTML](https://arxiv.org/abs/2506.17289)
## Authors
Rahul Raja,Arpita Vats
## Background
本文研究了小型语言模型在两种流行的适应范式（少量样本提示和监督微调）下的泛化能力。提示方法因其参数效率和灵活性而常被采用，但在资源稀缺的环境中以及分布变化时，其稳健性尚不明确。本文专注于探讨提示和微调在不同任务格式、提示样式和模型规模下的表现，特别是它们在分布内和分布外环境中的行为。研究不仅分析了准确率，还考察了这两种方法学习的内部表示，以评估任务特异性特征的稳定性和抽象度。
## Innovation
本文进行了提示和微调在不同任务格式、提示样式和模型规模下的比较研究，重点在于分布内和分布外环境中的表现。此外，该研究分析了每个方法学习的内部表示，以评估任务特异性特征的稳定性和抽象度，揭示了在不同适应策略下小型模型如何内化和泛化知识的关键差异。研究成果提供了实用建议，以在数据量有限的情况下选择合适的模型，并为提示与微调的持续辩论提供了实证见解。
## Conclusion
本文的研究成果强调了不同适应策略对小型模型内部化和泛化知识方式的不同影响。研究结果对于资源有限环境中模型的选择具有实际指导意义，同时提供了关于提示与微调的持续辩论的实证见解。实验代码已公开。
# 128. `cs.AI` - 可见光和红外图像反馈中低光环境下的人行道检测问题与挑战 [PDF](https://arxiv.org/pdf/2311.08557), [HTML](https://arxiv.org/abs/2311.08557)
## Authors
Thangarajah Akilan,Hrishikesh Vachhani
## Background
行人检测已成为包括自动驾驶、智能交通和交通监控在内的多个高级任务的基础。现有研究主要集中在可见光图像的人行道检测，特别是在白天。然而，在环境条件变为恶劣光照或夜间时，这一任务变得非常具有挑战性。最近，新的想法开始使用替代源，如远红外（FIR）温度传感器反馈来检测低光条件下的行人。这项研究回顾了低光人行道检测方法的最新进展，系统地分类和分析了基于区域、非区域和图学习的各种算法，强调了这些方法的实施问题和挑战，并概述了可用于研究和开发先进低光行人检测算法的关键基准数据集。
## Innovation
提出了使用远红外（FIR）温度传感器反馈来检测低光条件下的行人，系统地分类和分析了基于区域、非区域和图学习的各种算法及其实施问题和挑战，并概述了可用于研究和开发先进低光行人检测算法的关键基准数据集。
## Conclusion
本文回顾和分析了低光人行道检测的最新发展，强调了各种方法的优点和挑战，并指出了可用于研究和开发的基准数据集。
# 129. `cs.AI` - PhysUniBench：为多模态模型设计的本科水平物理推理基准 [PDF](https://arxiv.org/pdf/2506.17667), [HTML](https://arxiv.org/abs/2506.17667)
## Authors
Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma
## Background
物理问题解决是大AI模型面临的挑战性领域，需要结合概念理解、数学推理和物理图解的解释。当前的评估方法在捕捉本科物理的广度和复杂性方面显示出明显不足，突显了更严格的评估需求。为此，我们提出了PhysUniBench，这是一个大规模的多模态基准，旨在评估和改进多模态大语言模型（MLLMs）在本科物理问题上的推理能力。PhysUniBench 包含3,304个物理问题，涵盖8个主要的物理子学科，每个问题附带一个视觉图示。基准测试包括开放性和多项选择题，通过迭代模型在环过程系统化地分类和评级难度。基准构建涉及严格的多阶段过程，包括多次发布、专家级评估、自动筛选易解决的问题以及细致的难度评分系统，分为五个等级。通过大量实验，我们观察到当前最先进的模型在物理推理方面面临重大挑战。例如，GPT-4o mini在提出的PhysUniBench中的准确率仅为约34.2%。这些结果表明，当前的MLLMs在高级物理推理方面存在困难，尤其是在多步骤问题和需要精确图解的推理方面。通过提供宽泛且严谨的评估工具，PhysUniBench旨在推动AI科学的进步，激励开发具有更强物理推理、解决问题能力和多模态理解的模型。
## Innovation
PhysUniBench是一个大规模的多模态基准，旨在评估和改进多模态大语言模型在本科物理问题上的推理能力。它覆盖了广泛的物理子学科，并包括多种问题类型，具有系统分类和难度评级的特点，通过规模宏大的实验数据展示了当前AI模型在物理推理上的不足。
## Conclusion
通过提供广泛且严谨的评估工具，PhysUniBench意在推动AI科学的进步，激励开发具有更强物理推理、解决问题能力和多模态理解的模型。此外，PhysUniBench已经发布，可供研究人员使用。
# 130. `cs.AI` - 概念瓶颈模型是否尊重局部性？ [PDF](https://arxiv.org/pdf/2401.01259), [HTML](https://arxiv.org/abs/2401.01259)
## Authors
Naveen Raman,Mateo Espinosa Zarlenga,Juyeon Heo,Mateja Jamnik
## Background
基于概念的可解释性方法使用人类可理解的中间体为机器学习模型生成解释。这些方法假设概念预测能够帮助理解模型的内部推理过程。本文通过分析概念预测器是否利用“相关”特征来进行预测来评估此假设的真实性，这里我们称其为局部性。如果概念基模型未能尊重局部性，则无法进行解释，因为在概念预测中基于的是虚假特征，从而使概念预测的解释变得空洞。作者通过构建和使用三个度量标准来判断模型是否尊重局部性，并结合理论结果进行补充分析。每个度量标准捕捉不同的扰动概念并评估是否由于扰动“无关”特征而会影响概念预测器的预测结果。研究发现，许多实践中的概念基模型未能尊重局部性，因为概念预测器无法清晰地区分不同的概念。
## Innovation
本文提出了三种不同的度量标准来评估概念基模型是否尊重局部性，从而揭示了现有模型在概念区分上的不足，并为改进概念预测模型提供方向。
## Conclusion
许多用于实践的概念基模型未能尊重局部性，因为概念预测器无法清晰地区分不同的概念。基于这些发现，作者提出了缓解这一问题的建议。
# 131. `cs.AI` - Inside you are many wolves: 使用认知模型来解释大模型中的价值观权衡 [PDF](https://arxiv.org/pdf/2506.20666), [HTML](https://arxiv.org/abs/2506.20666)
## Authors
Sonia K. Murthy,Rosie Zhao,Jennifer Hu,Sham Kakade,Markus Wulfmeier,Peng Qian,Tomer Ullman
## Background
日常生活中处理社会情境通常需要平衡冲突的目标，例如传达真相、保持信任的同时还要考虑到他人的感受。这种价值权衡是人类决策和语言使用的核心部分。然而，现有的工具对于理解大语言模型（LLMs）中的动态和多层次的价值观概念有限。在认知科学中，所谓的“认知模型”通过建模说话者在选择行动或言辞时冲突的效用函数权重，提供对这些权衡的正式解释。本文旨在通过采用一种领先的礼貌言语认知模型来分析LLMs中的这种权衡程度，并将其应用于两种设置：推理的“努力”程度在前沿的黑箱模型中以及受控源模型的强化学习训练后的动态变化。研究结果揭示了推理模型中信息效用高于社会效用的模式，以及显示出数学推理能力更强的开源模型中社会效用较低的模式。从LLMs的训练动态中，研究发现早期训练中有显著的价值权衡变化，这些变化受基础模型和预训练数据的影响，而不是来自反馈数据集或对齐方法。研究表明，该方法可以应对快速变化的大模型领域，为形成关于其他高层次行为的假设、设计推理模型的训练制度以及更好地控制训练模型中的价值权衡提供见解。
## Innovation
本文通过采用一种领先的礼貌言语认知模型来分析大语言模型中的价值权衡。研究将这种分析方法应用于两种设置：推理的“努力”程度在前沿的黑箱模型中以及受控源模型的强化学习训练后的动态变化。研究结果揭示了推理模型中信息效用高于社会效用的模式，以及显示出数学推理能力更强的开源模型中社会效用较低的模式。此外，研究还发现，LLMs的训练动态中早期训练会有显著的价值权衡变化，且这些变化受基础模型和预训练数据的影响，而不是反馈数据集或对齐方法。提出了从快速变化的大模型领域揭示出的见解，为形成关于其他高层次行为的假设、设计推理模型的训练制度以及更好地控制训练模型中的价值权衡提供了实质性的指导意义。
## Conclusion
研究表明，大语言模型在训练初期就会显示出显著的价值权衡变化，这些变化主要由基础模型和预训练数据决定。通过采用认知模型来解释大语言模型中的价值权衡，可以揭示出这些模型内部非常复杂的价值权衡模式，为进一步理解这些模型的行为和改进其性能提供了重要的新途径。
# 132. `cs.AI` - 当大型语言模型与人类相悖？大型语言模型的阿谀行为 [PDF](https://arxiv.org/pdf/2311.09410), [HTML](https://arxiv.org/abs/2311.09410)
## Authors
Leonardo Ranaldi,Giulia Pucci
## Background
大型语言模型在生成方面表现出色，这得益于人类反馈的大量使用，进而影响其生成答案的倾向。然而，这种通过人类反馈继承的易暗示性使得语言模型更倾向于生成符合人类观点的答案，这种行为被描述为阿谀，表现为模型生成错误回应以迎合人类，从而导致这些模型的偏见和可靠性降低。本文研究了大型语言模型在回答涉及主观意见或应引发相反事实回应的查询时的阿谀倾向，并通过系统性的人类介入提示分析了不同任务中的这种倾向。研究表明，当面对涉及主观意见的查询时，大型语言模型表现出阿谀倾向；而在面对数学任务或有客观答案的查询时，它们不会遵循用户提示，而是表现出自信地生成正确答案的能力，显示出不同规模上的韧性特质。
## Innovation
本文研究了大型语言模型在不同任务中的阿谀行为，并通过系统性的提示分析揭示了这种现象。研究发现，在涉及主观意见的查询中，大型语言模型表现出阿谀倾向；而在具有客观答案的数学任务中，则展示了生成正确答案的能力和可靠性，这为理解和改进大型语言模型的行为提供了新的见解。
## Conclusion
大型语言模型在回答涉及主观意见的查询时具有明显的阿谀倾向，这表明在涉及主观意见和争议性问题时，需要谨慎使用这些模型。数学任务或有客观答案的查询则不受阿谀行为影响，表现出可靠性和准确性。
# 133. `cs.AI` - FluoroSAM: 一种可自然语言提示的基础模型，用于灵活的X射线图像分割 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
现有的任务特定模型只能在狭窄的范围内解决特定问题，扩大其应用范围需要额外的数据、注释和训练时间。语言对齐的基础模型（LFMs）可以在大量高度变异性图像和文本数据上进行训练，从而提高自动化图像分析的广泛适用性。然而，现有的医学图像分析基础模型主要针对大数据集丰富的场景和模态，而X射线成像模态具有高度的图像差异性，从诊断胸片到介入性透视，数据可用性有所不同。因此，需要一种新模型来实现对任意医学X射线图像的全面和语言对齐的分析，以促进人类介入的诊断和介入精确医疗工作流程中的灵活性。
## Innovation
提出了FluoroSAM，这是一种具备自然语言提示能力的Segment Anything Model变体，从头开始在300万种合成X射线图像上进行了训练，这些图像涵盖了多种人类解剖结构、成像几何和视角。模型通过将文本嵌入向量化（VQ）新颖地整合到训练过程中，能够基于自然语言提示来分割各种解剖结构和工具。FluoroSAM被证明在真实X射线图像上有较好的表现，并展示了其在X射线图像获取和分析的多种应用场景中的丰富人机交互能力。
## Conclusion
FluoroSAM作为一种语言可提示的基础模型，可以灵活地分割任意医学X射线图像，通过自然语言提示实现解剖结构和工具的分割。该模型为X射线图像的自动分析和人机交互提供了关键支撑，为诊断和介入性精确医学的未来发展奠定了基础。
# 134. `cs.AI` - COBRA-PPM：使用概率编程进行不确定性下机器人操作的因果贝叶斯推理架构 [PDF](https://arxiv.org/pdf/2403.14488), [HTML](https://arxiv.org/abs/2403.14488)
## Authors
Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze
## Background
机器人进行操作任务时需要根据与物体的互动来推理因果关系。然而，许多基于数据的方法缺乏因果语义，仅考虑相关性。为了应对这一挑战，本文提出了一种新的因果贝叶斯推理架构COBRA-PPM，将因果贝叶斯网络和概率编程结合，以在不确定性下对机器人操作进行干预推理。通过高保真Gazebo实验展示其能力，实现高预测准确率（88.6%）和高任务成功率（94.2%）。进一步在家庭机器人中进行了模拟到现实的转移实验，展示了其在处理从传感器噪声和随机动作中的一大不确定性方面的有效性。该通用和可扩展框架支持广泛的操作场景，为未来机器人与因果关系交叉领域的工作奠定了基础。
## Innovation
提出了一种新的因果贝叶斯推理架构COBRA-PPM，结合因果贝叶斯网络和概率编程，进行不确定性下的干预推理，显著提升了机器人操作的准确性和成功率，有效解决了数据驱动方法缺乏因果语义的问题，展示了其在模拟到真实环境的应用潜力。
## Conclusion
该通用和可扩展框架支持广泛的操作场景，为未来机器人与因果关系交叉领域的工作奠定了基础。在家庭机器人中进行了模拟到实际应用的验证，展示了其处理实际操作中不确定性（如传感器噪声和随机动作）的有效性。
# 135. `cs.AI` - 物理导向的模仿强化学习在真实驾驶中的应用 [PDF](https://arxiv.org/pdf/2407.02508), [HTML](https://arxiv.org/abs/2407.02508)
## Authors
Hang Zhou,Yihao Qin,Dan Xu,Yiding Ji
## Background
近期，模仿强化学习（IRL）的研究成果显著提升了自主代理模仿专家示范的能力，使其在诸多高难度任务中快速获得新技能。但这些基于学习的代理在高度动态闭环环境中知识迁移时面临重大挑战。它们的表现受模仿学习（IL）和强化学习（RL）的矛盾优化目标、样本效率低下以及隐藏世界模型和物理机制复杂性的影响。
## Innovation
本文提出了一个物理导向的IRL方法，它完全基于数据驱动，并利用专家示范数据和探索性数据的联合优化目标。该方法从训练过程中自然地揭示了车辆动力学的物理原理。实验结果表明，在Waymax基准测试的闭环环境中，该方法在碰撞率减少37.8%，离路率减少22.2%方面优于现有的IL、RL和IRL算法。
## Conclusion
本文提出的方法在高度动态闭环环境中的表现优于其他常用算法，展示了在真实驾驶场景下的有效性和优越性。
# 136. `cs.AI` - $C^3$-Bench：多任务中真正干扰LLM基于代理的事物 [PDF](https://arxiv.org/pdf/2505.18746), [HTML](https://arxiv.org/abs/2505.18746)
## Authors
Peijie Yu,Yifan Yang,Jinjian Li,Zelong Zhang,Haorui Wang,Xiao Feng,Feng Zhang
## Background
基于大型语言模型的代理利用工具来修改环境，改变了AI与物理世界交互的方式。与仅依赖历史对话的传统NLP任务不同，这些代理在决策时必须考虑更复杂的因素，如工具之间的关系、环境反馈以及之前的决策。当前的研究通常通过多轮对话评估代理，但忽视了这些关键因素对代理行为的影响。为了弥补这一差距，我们提出了一种开源且高质量的基准$C^3$-Bench。该基准融合了攻击概念，并通过单变量分析确定影响代理鲁棒性的重要元素。具体而言，我们设计了三个挑战：导航复杂工具关系、处理关键隐藏信息以及管理动态决策路径。为了补充这些挑战，我们引入了细粒度的评估指标、创新的数据收集算法和可重复的评估方法。我们在49个主流代理上进行了广泛的实验，涵盖通用快速思维、慢速思维和特定领域的模型。我们发现代理在处理工具依赖性、长期上下文信息依赖以及频繁的策略切换方面存在显著缺陷。总体而言，$C^3$-Bench旨在通过这些挑战揭示模型的漏洞，并推动代理性能可解释性的研究。基准在this https URL上公开可用。
## Innovation
提出了一个开源且高质量的基准$C^3$-Bench，通过融合攻击概念和运用单变量分析来确定影响代理鲁棒性的重要元素。设计了三个具体挑战，包括导航复杂工具关系、处理关键隐藏信息和管理动态决策路径。创新地引入了细粒度的评估指标、创新的数据收集算法和可重复的评估方法，广泛实验涵盖49个主流代理模型，揭示了代理在处理工具依赖性、长期上下文信息依赖和频繁策略切换方面的显著缺陷。
## Conclusion
总体上，$C^3$-Bench旨在通过这三个具体挑战揭示代理模型的漏洞，并推动对代理性能可解释性的研究。该基准已经公开发布。
# 137. `cs.AI` - ReconX: 使用视频扩散模型从稀疏视角重建任意场景 [PDF](https://arxiv.org/pdf/2408.16767), [HTML](https://arxiv.org/abs/2408.16767)
## Authors
Fangfu Liu,Wenqiang Sun,Hanyang Wang,Yikai Wang,Haowen Sun,Junliang Ye,Jun Zhang,Yueqi Duan
## Background
3D场景重建技术已经能够将真实世界中的2D图像转换为3D模型，生成逼真的3D结果。尽管在密集视角重建场景方面取得了巨大成功，但从不足的捕捉视角中渲染一个详细场景仍然是一个欠定优化问题，通常会导致不可见区域的伪影和失真。
## Innovation
本文提出了一种名为ReconX的新颖3D场景重建范式，将含糊的重建挑战转化为时间生成任务。核心见解是利用大规模预训练视频扩散模型的强大生成先验来进行稀疏视角重建。通过这种方法，ReconX首先构建全局点云并将其编码为上下文空间中的3D结构条件，然后在该条件下生成同时保留细节且具有高3D一致性性的视频帧，保证场景各个视角的连贯性。最后，通过一种基于置信度的3D Gaussian Splatting优化方案恢复3D场景。
## Conclusion
在不同实际场景数据集上进行的大量实验表明，我们的ReconX方法在质量和泛化能力方面优于最先进的方法。
# 138. `cs.AI` - toddlers' active gaze behavior supports self-supervised object learning [PDF](https://arxiv.org/pdf/2411.01969), [HTML](https://arxiv.org/abs/2411.01969)
## Authors
Zhengyang Yu,Arthur Aubret,Marcel C. Raabe,Jane Yang,Chen Yu,Jochen Triesch
## Background
婴幼儿在几乎无监督的情况下学会从不同角度识别物体，期间频繁的眼部和头部运动塑造了他们的视觉经验。但尚不清楚这些行为如何促进婴幼儿的物体识别能力。为回答这个问题，本研究结合了双人玩耍期间的眼动追踪和无监督机器学习技术，通过分析婴幼儿的注视策略，揭示其对建立不变物体表征的支持作用。此外，研究还指出，高清晰度的中央视场大小对于这一过程至关重要
## Innovation
本研究创新性地将婴幼儿的主动注视行为与无监督机器学习相结合，通过眼动追踪技术和头部佩戴的摄像机捕捉婴幼儿的实际视觉经验，研究这些行为如何支持婴幼儿建立稳定不变的物体表征。研究结果显示，婴幼儿的注视策略对形成一致的物体表征是有益的，并且高清晰度的中央视场对这一过程至关重要
## Conclusion
本研究揭示了婴幼儿的注视行为如何支持他们发展视点不变的物体识别能力。高分辨率的中央视场在这一过程中起着关键作用。
# 139. `cs.AI` - 评估代码生成LLM处理长范围依赖的能力 [PDF](https://arxiv.org/pdf/2407.21049), [HTML](https://arxiv.org/abs/2407.21049)
## Authors
Yannick Assogba,Donghao Ren
## Background
随着语言模型支持的上下文大小变得越来越大，评估它们有效地利用这些上下文的能力变得越来越重要。这项研究通过一系列跨多步键检索任务来分析多个代码生成模型处理长距离依赖的能力，在这些任务中，模型需要在最大8k词元的上下文中进行处理，这些任务逐渐增加难度，比类似流行的“haystack中的针”测试进行更复杂的模型能力评估。研究发现，当一个函数引用在提示中稍后定义的另一个函数时，很多模型的表现会显著下降（最多下降2倍）。我们还观察到使用滑动窗口注意力机制的模型难以处理比单个窗口更大的引用。我们通过使用调用图信息对提示进行简单的修改，将多步检索性能提高到最多3倍。这一分析强调了在拟合单个文档内的事实检索之外，长上下文性能需要深入考虑的方式。
## Innovation
研究引入了一系列向多个步骤键检索任务，在最大8k词元的上下文中评估几个代码生成模型处理长距离依赖能力，这些任务逐渐增加难度，比类似流行的“haystack中的针”测试进行更复杂的模型能力评估。研究通过使用调用图信息对提示进行简单的修改，来改善多步检索性能，最多提高3倍。
## Conclusion
研究揭示了处理长距离依赖方面模型表现的显著下降及实际情况中使用的方法，并强调了评估长上下文性能时的必要更多维度考虑。
# 140. `cs.AI` - 世界模型理解还是预测未来？世界模型的综合研究 [PDF](https://arxiv.org/pdf/2411.14499), [HTML](https://arxiv.org/abs/2411.14499)
## Authors
Jingtao Ding,Yunke Zhang,Yu Shang,Yuheng Zhang,Zefang Zong,Jie Feng,Yuan Yuan,Hongyuan Su,Nian Li,Nicholas Sukiennik,Fengli Xu,Yong Li
## Background
由于GPT-4等多模态大语言模型和Sora等视频生成模型的进步，世界模型的概念受到了广泛关注，这些技术对实现通用人工智能至关重要。世界模型通常被认为是理解当前世界状态或预测未来动态的工具。本文对世界模型的文献进行了全面回顾，并对其进行了系统分类，强调了构建内部表示以理解世界机制和预测未来状态以模拟和引导决策这两种主要功能。本文首先总结了这两个类别中的当前进展，随后探讨了世界模型在自动驾驶、机器人和社交仿真等关键领域的应用情况，最后指出了关键挑战并提供了潜在未来研究方向的见解。
## Innovation
本文提供了对世界模型的系统分类，强调了构建内部表示以理解世界机制和预测未来状态以模拟和引导决策这两种主要功能。同时，本文总结了代表性论文及其代码仓库，以供进一步研究参考。
## Conclusion
本文对世界模型在理解世界机制和预测未来状态方面的应用进行了系统综述，指出了目前的研究进展和挑战，并为未来的研究方向提供了见解。
# 141. `cs.AI` - 基于联邦学习的多无人机邻近控制方法在人机协作领域的应用 [PDF](https://arxiv.org/pdf/2412.02863), [HTML](https://arxiv.org/abs/2412.02863)
## Authors
Lucas Nogueira Nobrega,Ewerton de Oliveira,Martin Saska,Tiago Nascimento
## Background
人类与机器人交互（HRI）是一个快速增长的研究领域。在HRI中，复杂的命令（动作）分类仍然是一个开放问题，这通常阻碍了此类技术的实际应用。文献中有一些使用神经网络来检测这些动作的工作，但是遮挡仍然是HRI中的一个主要问题，尤其是在使用无人驾驶的空中车辆（UAVs）时，因为当机器人移动时，人类操作员往往在机器人的视野之外。此外，在多机器人场景中，分布式训练也是一个开放问题。
## Innovation
本文提出了一种基于长短期记忆（LSTM）深度神经网络的动作识别与控制方法，该方法包含两层LSTM与三层密集连接层，并嵌入联邦学习（FL）于多个无人机中。FL使我们的方法可以以分布式方式训练，即无需云计算或其它仓库即可访问数据，这有利于多机器人系统的学习。此外，我们的多机器人方法还防止了遮挡情况，实验证明使用真实机器人获得的精度超过96%。
## Conclusion
本文通过嵌入联邦学习的分布式LSTM神经网络，有效解决了多机器人场景中的命令分类和遮挡问题，实现了高精度的邻近控制，适用于人机协作领域。
# 142. `cs.AI` -  fuzz-testing-meets-llm-based-agents-an-automated-and-efficient-framework-for-jailbreaking-text-to-image-generation-models [PDF](https://arxiv.org/pdf/2408.00523), [HTML](https://arxiv.org/abs/2408.00523)
## Authors
Yingkai Dong,Xiangtao Meng,Ning Yu,Zheng Li,Shanqing Guo
## Background
文本到图像（T2I）生成模型通过将文本描述转化为高质量的图像，彻底改变了内容创作的方式。然而，这些模型容易受到称为'jailbreak'的攻击，攻击者能够通过精心设计的提示绕过安全机制并生成不安全的内容。尽管研究人员已经开发出了各种jailbreak攻击来揭示这种风险，但这些方法在实际应用中受限于不切实际的访问要求、容易被检测到的不自然的提示、受限的搜索空间以及对目标系统的高查询需求等局限性。
## Innovation
本文提出了一种名为JailFuzzer的新型 fuzzing 框架，该框架由大语言模型（LLM）代理驱动，旨在在黑盒环境中高效生成自然且语义上具有意义的 jaybreak 提示。JailFuzzer 使用 fuzz 测试原则，包含三个组件：用于初始和 jailbreak 提示的种子池、用于生成语义上有意义的变异的递归突变引擎以及用于评估 jailbreak 成功的预言机函数。作者还通过基于大语言模型的代理来构建递归突变引擎和预言机函数，以确保在黑盒环境中的效率和适应性。实验结果表明，JailFuzzer 在 T2I 模型破解方面具有显著优势，能够生成自然且语义连贯的提示，减少传统防御措施的检测可能性。此外，在最少查询开销的情况下实现较高的破解成功率，并在所有关键指标上都优于现有方法。
## Conclusion
这项研究强调了在生成模型中建立更强的安全机制的必要性，并为防御复杂的 jailbreaking 攻击提供了基础。JailFuzzer 是开源的，可以在这个链接中找到：this https URL.
# 143. `cs.AI` - USP-Gaussian: 统一基于尖峰的图像重建、姿态校正和Gaussian插值 [PDF](https://arxiv.org/pdf/2411.10504), [HTML](https://arxiv.org/abs/2411.10504)
## Authors
Kang Chen,Jiyuan Zhang,Zecheng Hao,Yajing Zheng,Tiejun Huang,Zhaofei Yu
## Background
尖峰相机是一种新颖的神经形态相机，通过0-1位流在40 kHz下捕捉场景。它们通过神经光度场（NeRF）或3D高斯插值（3DGS）被用来进行3D重建。之前的基于尖峰的3D重建方法通常采用分案式的流程：首先基于已有的尖峰到图像重建算法从尖峰流中重建高质量的图像，然后进行相机姿态估计和3D重建。然而，这种方法存在累积误差的问题，初始图像重建的质量限制会影响姿态估计，从而降低3D重建的保真度
## Innovation
我们提出了一个协同优化框架USP-Gaussian，将基于尖峰的图像重建、姿态校正和Gaussian插值统一在一个端到端的框架中。利用3DGS提供的多视图一致性以及尖峰相机的运动捕捉能力，该框架实现了迭代优化，无缝集成尖峰到图像网络与3DGS之间的信息。实验结果表明，该方法有效地消除了级联误差，且在具有不准确初始姿态的真实场景中，通过优化姿态实现了稳健的3D重建，减少了噪声并保留了细纹理细节
## Conclusion
我们的方法在合成数据集上展示了优越性能，能够有效地消除级联误差。此外，通过姿态优化，我们的方法在具有不准确初始姿态的真实场景中实现了稳健的3D重建，优于其他方法。我们的代码、数据和训练模型将在此网址发布
# 144. `cs.AI` - AgentBreeder：通过自我改进缓解多代理支架对AI安全的影响 [PDF](https://arxiv.org/pdf/2502.00757), [HTML](https://arxiv.org/abs/2502.00757)
## Authors
J Rosser,Jakob Nicolaus Foerster
## Background
将大型语言模型（LLMs）融入多代理系统通常能提升复杂任务的表现，但这些支架对安全的影响尚未得到充分研究。本文背景在于探讨和解决多代理支架可能带来的安全风险。
## Innovation
本文引入了AgentBreeder框架，这是一种针对多代理系统的多目标自改进演化搜索框架。与传统的基准相比，该框架在保持或提高能力的同时，能显著提升安全基准的表现，特别是在‘蓝色模式’下，平均提升率达到79.4%。同时，该框架也揭示了潜在的安全风险，特别是在‘红色模式’下发现了对抗性较弱的支架。
## Conclusion
研究工作表明多代理支架存在安全风险，并提供了缓解这些风险的框架。代码可在相关链接处获得。
# 145. `cs.AI` - 分离舌头与思想：激活补丁揭示转换器中的语言无关概念表示 [PDF](https://arxiv.org/pdf/2411.08745), [HTML](https://arxiv.org/abs/2411.08745)
## Authors
Clément Dumas,Chris Wendler,Veniamin Veselovsky,Giovanni Monea,Robert West
## Background
在多语种语言建模领域，一个核心问题是大规模语言模型（LLMs）是否发展出一种通用的概念表示，这种表示与特定语言无关。本文通过在基于转换器的LLMs中分析单词翻译任务中的潜在表示（latents），探索了这一问题。研究者通过策略性地从源翻译提示中提取潜在表示并将其插入目标翻译提示的前向传递中，发现在翻译概念之前，输出语言已在较早的层中被编码。基于这一发现，研究进行了两个关键实验：首先，仅通过激活补丁便证明可以改变概念而不改变语言，反之亦然；其次，证明使用不同语言中概念的平均表示实现激活补丁对翻译能力无负面影响，反而提高其准确性。这些实验结果表明，所研究的模型中存在语言无关的概念表示，从而提供了其存在的证据.
## Innovation
通过提出并验证激活补丁技术，作者发现了模型中存在语言无关的概念表示。激活补丁可以独立改变翻译任务中的概念而不影响语言，也可以提高跨语言概念翻译的准确性。这项工作揭示了用于多语言理解的潜在有意义表示的新途径，并增强了对大规模语言模型内部工作原理的理解.
## Conclusion
研究结果提供了证据支持在研究模型中概念表示与语言无关的存在。实验结果表明，模型能够生成自然语言描述不同语言中的概念表示，且能够独立改变概念而不改变语言，改进了模型跨语言概念翻译的性能，支持了模型内部有语言无关的概念表示的存在。
# 146. `cs.AI` - 向模型参数空间中的后门隐身性迈进 [PDF](https://arxiv.org/pdf/2501.05928), [HTML](https://arxiv.org/abs/2501.05928)
## Authors
Xiaoyun Xu,Zhuoran Liu,Stefanos Koffas,Stjepan Picek
## Background
现有研究主要集中在输入空间中的不可区分触发器和特征空间中的不可分割后门表示，旨在规避针对这些空间的防御机制。然而，现有后门攻击通常针对特定类型的防御机制，而忽视了多样化的防御策略。本文即基于此种观察，探讨了现有后门攻击面对多样化实际防御时的真实威胁性。分析了12种常见的输入空间或特征空间隐身性后门攻击和17种不同的防御措施，发现现有攻击在参数空间中具有明显的弱点，可以被监测到。
## Innovation
本文提出了一种新颖的供应链攻击Grond，通过Adversarial Backdoor Injection (ABI)模块在参数空间中实现隐蔽性。实验结果表明，Grond能够对抗CIFAR-10、GTSRB和ImageNet子集上最先进的（包括自适应的）防御措施，并且ABI可以提高现有后门攻击的有效性。
## Conclusion
研究发现现有后门攻击在参数空间中存在明显的隐蔽性漏洞，提出了一种新的参数空间隐蔽性后门攻击Grond，并展示了其优越性。
# 147. `cs.AI` - 超越语言模型的自然数据集中的上下文学习解锁 [PDF](https://arxiv.org/pdf/2501.06256), [HTML](https://arxiv.org/abs/2501.06256)
## Authors
Jelena Bratulić,Sudhanshu Mittal,David T. Hoffmann,Samuel Böhm,Robin Tibor Schirrmeister,Tonio Ball,Christian Rupprecht,Thomas Brox
## Background
大型语言模型（LLMs）表现出基于上下文学习（ICL）的能力，使模型能够在不更新权重的情况下，依赖于上下文提供的例题来执行新任务。尽管ICL在自然语言任务和领域中提供了快速的适应性，但在文本之外的模态中其出现却是较为复杂和不直观的。本文系统地探索了LLMs中支持ICL在自回归模型和各种模态中出现的特性，通过促进ICL所需的机制学习。文章发现训练数据序列中的确切令牌重复对于ICL至关重要，这种重复进一步提高了ICL的稳定性并减少了临时性表现。此外，文章强调了训练任务难度对ICL出现的重要性。最后，通过应用关于ICL出现的新见解，文章揭示了ICL在各种视觉数据集和更具挑战性的EEG分类任务中的潜在能力，特别是在少量样本学习的条件下。这种能力的揭示有助于理解更广泛的模态中ICL的机制和应用。
## Innovation
文章系统地发现了支持LLMs在自回归模型和多种模态中出现ICL的特性，特别是强调了令牌重复和训练任务难度对ICL的重要性，并通过这些新发现解锁了ICL在视觉数据集和EEG分类任务等更具挑战性的任务中的应用。
## Conclusion
通过应用这些新发现的ICL出现机制，研究人员成功揭示了ICL在视觉数据集和难得多模态学习任务中的潜在应用，提供了对ICL在非文本领域中出现的更深入的理解。
# 148. `cs.AI` - 对抗推理在脱牢时间的应用 [PDF](https://arxiv.org/pdf/2502.01633), [HTML](https://arxiv.org/abs/2502.01633)
## Authors
Mahdi Sabbaghi,Paul Kassianik,George Pappas,Yaron Singer,Amin Karbasi,Hamed Hassani
## Background
随着大型语言模型（LLMs）变得越来越强大和普及，对其失败案例的研究变得越来越重要。近年来，在标准化测试时的计算、测量和规模化方面取得了进展，这为优化模型以在困难任务上实现高性能提供了新的方法。本研究将这些进展应用于模型脱牢门问题，即从对齐的LLMs中引发有害反应。
## Innovation
本研究开发了一种对抗推理方法来自动脱牢门，利用损失信号引导测试时的计算，即使对于旨在用推理时间计算换取对抗鲁棒性的对齐LLM，也实现了最先进的攻击成功率。该方法引入了理解LLM漏洞的新范式，为开发更 robust 和可信的AI系统奠定了基础。
## Conclusion
本研究为从对齐的LLMs中引发有害响应开发了一种新的对抗推理方法，即使对于那些提高对抗鲁棒性的模型也表现出高攻击成功率。这一方法为了解LLM漏洞提供了新的途径，为开发更 robust 和可信的AI系统奠定了基础。
# 149. `cs.AI` - 使用解耦扩散序列蒙特卡洛方法解决线性高斯贝叶斯逆问题 [PDF](https://arxiv.org/pdf/2502.06379), [HTML](https://arxiv.org/abs/2502.06379)
## Authors
Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten
## Background
近年来的研究利用预训练的生成扩散模型作为贝叶斯逆问题的先验。这一研究方向的设计目的是通过“解耦扩散”技术，设计生成过程以允许更大的样本更新。在此基础上，作者提出了一种适用于线性高斯逆问题的顺序蒙特卡罗方法，该方法是渐近精确的。该方法在合成数据、蛋白质数据和图像数据上都得到了验证，显示出其有效性，并展示了该方法如何可扩展以处理离散数据
## Innovation
基于解耦扩散技术，作者设计了一种适用于线性高斯逆问题的顺序蒙特卡罗方法。该方法在理论上是渐近精确的，并在不同类型的数据上展示了其有效性，还展示了该方法的离散数据扩展性
## Conclusion
所提出的方法在合成数据、蛋白质数据和图像数据上都表明了其有效性，并且通过解耦扩散技术扩展到离散数据，这种方法为解决线性高斯逆问题提供了一种新的有效途径
# 150. `cs.AI` - 重新思考早期停止：先精炼，再校准 [PDF](https://arxiv.org/pdf/2501.19195), [HTML](https://arxiv.org/abs/2501.19195)
## Authors
Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach
## Background
机器学习分类器经常生成概率预测，这对于各个领域的准确和可解释决策至关重要。这些预测的质量通常通过适当的损失度量来评估，如交叉熵，它分解为两个部分：校准误差评估一般不足信或过度自信的程度，而细化误差衡量区分不同类别的能力。本文基于这一背景研究了校准和细化分解的新形式，提供了一种新的视角来评估分类器的预测质量，并证明了在训练期间这类错误不能同时最小化。因此，基于验证损失选择最佳时期导致了一个不理想的结果。为此，提出了一种新的训练策略，即先仅优化细化误差（Refine），再使用标准技术进行后处理校准（Calibrate）以最小化校准误差。该方法与其他分类器兼容，能够在多种分类任务上持续改善性能。
## Innovation
提出了一个新的变分形式的校准-细化分解，揭示了后处理校准的新视角，并允许快速估计不同项的值。此外，提出了一种新的训练策略，即先仅优化细化误差（Refine），然后使用标准技术进行后处理校准（Calibrate），以最小化校准误差。
## Conclusion
该方法与其他分类器兼容，能够在多种分类任务上持续改善性能。
# 151. `cs.AI` - WyckoffDiff — 一种晶体对称性生成扩散模型 [PDF](https://arxiv.org/pdf/2502.06485), [HTML](https://arxiv.org/abs/2502.06485)
## Authors
Filip Ekström Kelvinius,Oskar B. Andersson,Abhijith S. Parackal,Dong Qian,Rickard Armiento,Fredrik Lindsten
## Background
晶体材料通常表现出高度对称性，但大多数生成模型并未考虑这一点，而是对每个原子的位置和元素进行建模而不施加任何约束。现有模型没有有效利用晶体的对称性，导致生成结果不够准确或高效。本文提出了一种新的生成模型Wyckoff Diff（WyckoffDiff），它通过考虑编码所有对称性的晶体结构表示方式，以及结合新型神经网络架构，使得模型能在一个离散生成模型框架中充分利用对称性，从而实现快速生成。同时，定义了新的度量标准Fréchet Wrenformer Distance，用于捕捉生成的材料的对称性特征，并将其与近期提出的晶体生成模型进行基准测试。作为概念验证研究，WyckoffDiff被用于在热力学稳定性凸包以下发现新材料。
## Innovation
本文提出了一种基于对称性的生成模型Wyckoff Diff（WyckoffDiff），通过结合对称性的晶体结构表示和新型神经网络架构，实现了对称性约束下的快速生成。并且，还提出了新的度量标准Fréchet Wrenformer Distance，以评估生成的材料的对称性特征。这种模型不仅能够有效利用对称性，还可以在离散生成模型框架中实现高效快速生成。
## Conclusion
在对比实验中，WyckoffDiff表现出了对称性约束和高效生成的特点，能有效发现新材料。作为一种概念验证，这种方法展示了WyckoffDiff在探索和生成具有特定对称性晶体结构新材料方面的潜力。
# 152. `cs.AI` - 化学知识引导的隐私感知 retrosynthesis 学习框架 [PDF](https://arxiv.org/pdf/2502.19119), [HTML](https://arxiv.org/abs/2502.19119)
## Authors
Guikun Chen,Xu Zhang,Xiaolin Hu,Yong Liu,Yi Yang,Wenguan Wang
## Background
化学反应数据是制药、材料科学和工业化学等竞争性领域的核心资产，其专属性和敏感性确保了商业机密的保护，但当前基于机器学习的逆合成反应模型训练标准方法需要从多个来源收集数据以提高模型预测性能，这种做法增加了隐私泄露风险。因此，有必要开发一种既能保持数据隐私又能提高模型性能的方法，即在保护数据机密性的同时，维护和改进逆合成反应模型的训练方法。
## Innovation
引入了化学知识引导框架（CKIF），该框架能够在多个化学组织之间进行分布式训练，而不泄露任何专有反应数据。通过化学知识引导的模型参数迭代聚合，CKIF 在多种反应数据集上的表现显著优于其他基准方法。CKIF 的创新之处在于其通过利用预测产物的化学性质来定量评估模型行为，并据此调整模型聚合权重，从而在保持数据隐私的同时提高了模型的性能。
## Conclusion
化学知识引导框架（CKIF）已经证明了其在保护化学反应数据隐私方面的有效性，同时通过模型参数的迭代聚合提升了逆合成反应模型的性能。这种方法为更好地保护工业化学及相关领域的机密信息提供了新的解决方案，也为未来开发更多高效且保护隐私的机器学习方法奠定了基础。
# 153. `cs.AI` - 分布式卫星信息网络：架构、使能技术及趋势 [PDF](https://arxiv.org/pdf/2412.12587), [HTML](https://arxiv.org/abs/2412.12587)
## Authors
Qinyu Zhang,Liang Xu,Jianhao Huang,Tao Yang,Jian Jiao,Ye Wang,Yao Shi,Chiya Zhang,Xingjian Zhang,Ke Zhang,Yupeng Gong,Na Deng,Nan Zhao,Zhen Gao,Shujun Han,Xiaodong Xu,Li You,Dongming Wang,Shan Jiang,Dixian Zhao,Nan Zhang,Liujun Hu,Xiongwen He,Yonghui Li,Xiqi Gao,Xiaohu You
## Background
受到无处不在的连接和无线智能愿景的驱动，基于超密集星座的卫星集成互联网正处于进化过程中，正逐步成型。然而，固有的机构壁垒和有限的非可再生异构网络资源使现有的卫星系统难以满足下一代智能应用的需求。在这种背景下，分散式的卫星信息网络（DSIN），如紧密集群卫星系统，成为一种创新架构，它弥补了不同卫星系统（如通信、导航和遥感）之间的信息缺口，并建立了一个统一且开放的信息网络体系，以支持具有复原力的空间信息服务。
## Innovation
DSIN提供了一种创新的网络架构，包括分布式再生卫星网络架构、分布式卫星计算网络架构以及可重构卫星编队飞行，这些架构能够实现灵活和可扩展的通信、计算和控制。进一步开发了跨层优化技术，以满足上层确定性、适应性和安全性的信息服务需求。同时，探讨了挑战解决策略，确定了一系列使能技术，如信道建模与估计、基于云原生的分布式MIMO合作、免许可大规模接入、网络路由等。
## Conclusion
对于实现DSIN愿景，提出了新兴研究方向和新的机会，强调了跨层优化技术的发展，提高了整体资源效率，并强调了未来的研究方向。
# 154. `cs.AI` - 使用具有不确定性的指示调优平衡真实性和信息量 [PDF](https://arxiv.org/pdf/2502.11962), [HTML](https://arxiv.org/abs/2502.11962)
## Authors
Tianyi Wu,Jingwei Ni,Bryan Hooi,Jiaheng Zhang,Elliott Ash,See-Kiong Ng,Mrinmaya Sachan,Markus Leippold
## Background
大语言模型（LLMs）调优（IFT）可以增加模型的信息量，但可能会牺牲模型的真实性。这种权衡产生的原因是调优会引导LLMs生成涵盖预训练阶段未充分覆盖的知识，使得模型在处理未见过的任务时变得更富有信息性但更不准确。已有研究和实验展示了调优中不熟悉的知识对模型真实性的负面影响，并提出了两种新的调优方案：$UNIT_{cut}$和$UNIT_{ref}$来解决这个问题。$UNIT_{cut}$通过识别并移除调优数据集中不熟悉的知识，减轻其对模型真实性的负面影响，而$UNIT_{ref}$则通过训练LLMs识别其不确定性并在回应末尾明确表示，来减少幻觉的发生。实验结果显示，$UNIT_{cut}$显著提高了模型的真实性和可信度，而$UNIT_{ref}$在保持高信息量的同时减少幻觉，通过区分有把握和不确定的声明
## Innovation
引入了两种新的调优方法：$UNIT_{cut}$和$UNIT_{ref}$。$UNIT_{cut}$通过移除调优数据集中不熟悉的知识来缓解对模型真实性的负面影响；$UNIT_{ref}$则通过训练模型识别不确定性并明确表示，减少幻觉的发生
## Conclusion
$UNIT_{cut}$能够显著提高模型的真实性，$UNIT_{ref}$则在保持高信息量的同时减少幻觉，通过区分不同类型的声明
# 155. `cs.AI` - 集成多种软件信息以改善基于LLM的Bug定位和程序修复 [PDF](https://arxiv.org/pdf/2412.03905), [HTML](https://arxiv.org/abs/2412.03905)
## Authors
Qiong Feng,Xiaotian Ma,Jiayi Sheng,Ziyuan Feng,Wei Song,Peng Liang
## Background
LLMs因其有潜力简化Automated Program Repair (APR)而引起了广泛关注。现有的LLM基于的APR方法主要依赖单一类型的软件信息，忽视了不同类型软件数据的整合问题。虽然许多基于LLM的APR方法没有研究哪类具体信息对APR最有帮助，但这个问题的解决对于推进基于LLM的APR技术尤为重要。鉴于此，本文提出了DEVLoRe，旨在通过结合问题内容（描述和错误信息）和堆栈错误跟踪来定位错误方法，依赖于错误代码中的调试信息和问题内容及堆栈错误来定位错误行并生成可以通过所有单元测试的可能修补程序。
## Innovation
本文提出了一种全新方法DEVLoRe，该方法通过结合问题描述、错误信息、堆栈跟踪和调试信息来优化基于LLM的APR技术。特别是，通过引入问题内容和堆栈追踪，DEVLoRe能够更有效地实现错误定位和程序修复，其在定位错误方法和生成可行修补程序方面优于现有的APR技术。此外，研究还探讨了Python代码和Java代码间领先框架是否可以直接互用的问题。
## Conclusion
实验结果表明，DEVLoRe在Defects4J v2.0数据集上能成功定位49.3%和47.6%的单个和非单个错误方法，并生成56.0%和14.5%的可行修补程序，明显优于当前最先进的APR方法。此外，通过实现和评估框架，证实了其在多个挑战任务上的有效性和优越性，这一结论为可复制性研究提供了基础平台，详情可访问文献提供的开源主页。
# 156. `cs.AI` - 图推理过程奖励使大型语言模型成为更通用的推理者 [PDF](https://arxiv.org/pdf/2503.00845), [HTML](https://arxiv.org/abs/2503.00845)
## Authors
Miao Peng,Nuo Chen,Zongrui Suo,Jia Li
## Background
尽管大型语言模型（LLMs）取得了显著进展，但提高LLMs的高级推理能力仍然是一个关键挑战。流程奖励模型（PRMs）在增强数学推理方面展现出极高的潜力，尤其是通过逐步反馈。然而，PRMs在更广泛的推理领域中的应用尚未得到充分研究，主要是由于手动创建步骤级监督的成本高。本文探讨了PRMs在图推理问题中的潜力，这些问题是多步推理要求高且能够使用现有图算法自动生成步骤级数据的领域。
## Innovation
研究引入了图SILO（GraphSILO）数据集，这是用于图推理问题的最大数据集，包含精细的步骤级标签，通过自动任务导向轨迹和蒙特卡洛树搜索（MCTS）生成详细的推理步骤。基于此数据集，训练了GraphPRM，这是第一个针对图推理问题设计的PRM，并在推断时间和通过直接偏好优化（DPO）进行强化学习的两个关键方面评估了其有效性。实验结果显示，GraphPRM在13个图推理任务上大幅提升了LLM的表现，特别是在Qwen2.5-7B上提高了9%，并展示了跨不同图推理数据集和推理领域的可移植性。特别是在GSM8K和Math500上，GraphPRM提高了LLM的表现，突显了基于图的推理奖励的跨域适用性。这些发现强调了PRMs在促进不同领域推理发展方面的潜力，为更灵活和有效的LLMs铺平了道路。
## Conclusion
研究发现PRMs在不同领域推理的潜力，推动了更加灵活和有效的LLMs的发展。GraphPRM在多个图推理任务上显著提升了LLM的表现，并展示了跨领域的可迁移性，特别是在GSM8K和Math500等新的推理领域。
# 157. `cs.AI` - FGS-SLAM: 基于傅里叶变换的高斯 splatting 实时 SLAM 与稀疏与稠密地图融合 [PDF](https://arxiv.org/pdf/2503.01109), [HTML](https://arxiv.org/abs/2503.01109)
## Authors
Yansong Xu,Junlin Li,Wei Zhang,Siyu Chen,Shengyong Zhang,Yuquan Leng,Weijia Zhou
## Background
3D 高斯 splatting 已经提升了 SLAM 技术，能够实时定位并构建高保真地图。然而，高斯位置和初始化参数的不确定性带来了挑战，通常需要多轮迭代收敛，导致高斯表示冗余或不足。
## Innovation
提出了一种基于傅里叶频域分析的自适应密集化方法来建立高斯先验，以实现快速收敛。此外，提出了构建独立且统一的稀疏和稠密地图的方法，其中稀疏地图通过广义迭代最近点（GICP）支持高效跟踪，稠密地图创建高保真的视觉表示。这是首次使用频域分析的 SLAM 系统，在实时实现高保真高斯映射方面取得了高质量的结果。
## Conclusion
实验结果表明，在 Replica 和 TUM RGB-D 数据集上平均帧率为 36 FPS，定位和建图都达到了竞争性的准确性。
# 158. `cs.AI` - 从O(n²)到O(n)参数：用于生物医学图像分类的视觉转换器中的量子自注意力 [PDF](https://arxiv.org/pdf/2503.07294), [HTML](https://arxiv.org/abs/2503.07294)
## Authors
Thomas Boucher,John Whittle,Evangelos B. Mazomenos
## Background
该研究探讨了量子视觉变换器（QViTs）在生物医学图像分类中的应用，这种模型通过使用量子自注意力（QSA）机制代替传统的自注意力（SA）机制，展示了其在参数效率方面的优势，与传统方法相比，参数数量大大减少，但仍能达到接近SOTA的性能
## Innovation
创新点在于提出了一种通过使用参数化的量子神经网络（QNN）替代线性SA层来实现QSA机制的方法，从而将参数规模从O(n²)减少到O(n)，同时在RetinaMNIST等数据集上显著优于SOTA方法，且仅使用极少数的参数（1K vs 14.5M），在保持性能的同时大幅降低了计算复杂度（GFLOPs）。此外，研究还首次探讨了从经典到量子视觉变换器的知识蒸馏（KD）方法，并发现了QSA参数与KD效果之间的潜在关联
## Conclusion
研究结果表明，QSA作为一种参数高效的生物医学图像分析架构是可行的。通过进一步的研究，可以基于此架构进行更进一步的优化和扩展，以改善生物医学图像分类中的性能和效率，同时也为进一步探索量子计算在人工智能领域的应用提供了新的思路
# 159. `cs.AI` - 使用深度上下文蒸馏训练即插即用知识模块 [PDF](https://arxiv.org/pdf/2503.08727), [HTML](https://arxiv.org/abs/2503.08727)
## Authors
Lucas Caccia,Alan Ansell,Edoardo Ponti,Ivan Vulić,Alessandro Sordoni
## Background
在大型语言模型预训练后动态整合新信息或迅速演化的信息在低数据场景或处理私人和专业文件时仍然具有挑战性。尽管上下文学习和检索增强生成（RAG）方法有其优势，但也存在着推理成本高且难以捕捉文档全局信息的问题。
## Innovation
本文提出了通过训练文档级别知识模块（KMs）来模块化知识的方法。KMs作为轻量级、参数有效的LoRA模块实现，能够存储新文档的信息并在需要时便捷地接入模型。此外，作者提出了一种新的训练目标——深度上下文蒸馏：通过学习KMs参数来模拟文档上下文下的教师模型的隐藏状态和logits。这种方法在两个数据集上都优于标准的下一个标记预测和预指令训练技术。
## Conclusion
知识模块和RAG之间存在协同作用。
# 160. `cs.AI` - 老师运动先验：提高跨越挑战性地形的机器人行进步骤 [PDF](https://arxiv.org/pdf/2504.10390), [HTML](https://arxiv.org/abs/2504.10390)
## Authors
Fangcheng Jin,Yuqi Wang,Peixin Ma,Guodong Yang,Pan Zhao,En Li,Zhengtao Zhang
## Background
由于高维控制和环境不确定性，实现复杂地形上的稳健运动仍然是一个挑战。传统的策略依赖于编码器状态嵌入，使得网络设计复杂且部署困难。这篇论文介绍了一种基于教师学生范式的老师先验框架，通过模仿学习和辅助任务学习来提高学习效率和泛化能力。
## Innovation
该框架通过解耦网络设计，简化了策略网络和部署，从而在不依赖于编码器状态嵌入的情况下，通过生成对抗机制将高性能的教师运动策略转移到仅依赖于嘈杂的本体感受数据的学生策略中，从而减轻性能下降的问题，并利用辅助任务学习来增强学生策略的特征表示，加速收敛并提高对变化地形的适应性。
## Conclusion
该框架在人形机器人上进行了验证，显著提高了动态地形上的行进步骤稳定性，并显著降低了开发成本。这项工作为在人形机器人中部署稳健的行进步骤提供了一种实用的解决方案。
# 161. `cs.AI` - 通过解缠表示实现眼科疾病分级的鲁棒多模态学习 [PDF](https://arxiv.org/pdf/2503.05319), [HTML](https://arxiv.org/abs/2503.05319)
## Authors
Xinkun Wang,Yifang Wang,Senwei Liang,Feilong Tang,Chengzhi Liu,Ming Hu,Chao Hu,Junjun He,Zongyuan Ge,Imran Razzak
## Background
眼科医生常常依赖多模态数据来提高诊断的准确性。然而，在实际应用中，由于医疗设备的欠缺和对数据隐私的担忧，完整的多模态数据并不常见。传统的深度学习方法一般通过在潜在空间中学习表示来解决这些问题。然而，这些方法存在两个主要问题：(i) 程序冗余信息（例如，复杂模态中的大量切片）导致潜在空间表示中的冗余。(ii) 重叠的多模态表示使得难以提取每个模态的独特特征。
## Innovation
为了克服这些挑战，作者提出了Essence-Point和解缠表示学习(EDRL)策略，将自我蒸馏机制整合到端到端框架中，以增强特征选择和解缠能力，从而提高多模态学习的鲁棒性。ESSENCE-Point表示学习模块选择能提高疾病分级性能的区分性特征。解缠表示学习模块将多模态数据分离为模态通用和模态独特表示，减少了特征纠缠，并增强了眼科疾病诊断中的稳健性和可解释性。研究表明，所提出的EDRL策略在多模态眼科数据集上的性能显著优于当前最先进方法。
## Conclusion
实验结果表明，提出的EDRL策略在多模态眼科疾病分级任务中显著优于现有最先进的方法，增强了多模态学习的鲁棒性和可解释性。
# 162. `cs.AI` - MaizeField3D: 来自多样性群体的田间种植玉米的3D点云和程序模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
## Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
## Background
由于缺乏大型和多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的工具在3D表型分析，尤其是对玉米的研究中发展受到了限制。2D图像数据集未能捕获如叶片结构、植物体积和空间排列等3D数据提供的关键结构细节。
## Innovation
该项目提出了一个名为MaizeField3D的数据集，这是一个经过仔细策划的田间种植玉米植物的3D点云数据集，涵盖了来自多样化基因组面板的植物。该项目包括使用地面激光扫描仪（TLS）收集的1,045个高质量的3D点云数据。点云经过图基分割和注释，使用程序模型拟合提供有序参数表示，并通过非均匀有理B样条（NURBS）表面表示叶片，确保数据质量并通过了严格的手动质量控制。
## Conclusion
MaizeField3D将作为AI驱动的表型分析、植物结构分析和农业研究中3D应用的基础数据集。
# 163. `cs.AI` - LLM位置泛化的计算机制 [PDF](https://arxiv.org/pdf/2503.13305), [HTML](https://arxiv.org/abs/2503.13305)
## Authors
Chi Han,Heng Ji
## Background
大多数自然语言都是由单词和句子组成的序列。类似人类，大型语言模型（LLMs）在处理文本位置上表现出灵活性—这一现象称为位置泛化。它们能够理解位置有变化的文本，并且能够泛化到比训练过程中遇到的更长的文本中。这些现象表明LLMs在处理位置时具有容忍性，但它们如何在计算上处理位置相关性仍然很大程度上未被探索。这项工作将语言现象与LLMs的计算机制联系起来，揭示了LLMs在位置变化下的表现容忍度背后的计算机制。尽管自我注意机制的设计复杂，但仍发现LLMs在注意力值上展示了与位置相关性和语义重要性近似算术和的一种反直觉的解耦。此外，研究中还识别出了一种中间特征的普遍模式，这种模式理论上可以解释上述现象，并且与随机初始化的参数所呈现出的行为不同，表明这是通过学习而获得的行为，而不是模型架构自然得出的结果。基于上述发现，提出了解释LLMs位置灵活性的计算方式和标准。这项工作在将位置泛化与现代LLMs的内部机制链接起来方面迈出了先驱性的步伐。
## Innovation
这项工作将语言现象与大型语言模型的计算机制联系起来，揭示了大型语言模型在处理位置变化时如何表现得容忍。研究发现，尽管自注意力机制的设计复杂，大型语言模型在计算上展示了位置相关性和语义重要性的近似算术和的解耦，这是一种反直觉的现象。此外，还识别出了一种中间特征的普遍模式，这具有理论上的解释能力，表明这是通过学习而获得的行为，而不是模型架构自然得出的结果。这些发现为解释大型语言模型的位置灵活性提供了计算解释和标准。
## Conclusion
这项工作通过识别中间特征的普遍模式和解释这些模式背后的机制，为理解大型语言模型在位置上的灵活性提供了基础。这些发现为进一步研究大型语言模型的计算机制提供了新的视角。
# 164. `cs.AI` - TSPulse: 双空间超紧凑预训练模型实现快速时间序列分析 [PDF](https://arxiv.org/pdf/2505.13033), [HTML](https://arxiv.org/abs/2505.13033)
## Authors
Vijay Ekambaram,Subodh Kumar,Arindam Jati,Sumanta Mukherjee,Tomoya Sakai,Pankaj Dayama,Wesley M. Gifford,Jayant Kalagnanam
## Background
时间序列预训练模型的崛起推动了时间序列表示学习的进步，但目前的性能最佳模型通常体积庞大，需要大量的计算资源。
## Innovation
TSPulse 引入了架构和任务层面的创新。在架构层面，采用了双空间掩码重构，同时从时间域和频率域学习，捕捉互补信号。此外，还引入了双嵌入解耦，生成详细的嵌入进行细致分析，以及高层次的语义嵌入以理解更广泛的任务。TSPulse 的语义嵌入对时间、幅度和噪声的变化具有鲁棒性，这对于稳健的检索至关重要。在任务层面，TSPulse 采用 TSLens 细调组件，实现任务特定的特征注意力。引入了多头三角化技术，将多个预测头的偏差相互关联，提升了异常检测能力。此外，提出了一种混合掩码预训练技术，通过减少预训练偏见改进了零样本填充。
## Conclusion
这些架构和任务的创新共同导致了TSPulse在多个时间序列任务上显著的性能提升：在UEA分类基准测试上达到5-16%的提升，在TSB-AD异常检测排行榜上提升了20%，在零样本填充上提高了50%，在时间序列检索上提升了25%。更重要的是，TSPulse仅包含1M参数（与现有SOTA模型相比小10-100倍），并且允许无GPU推理，设定了高效时间序列预训练模型的新标准。
# 165. `cs.AI` - CogniBench: 一个法律启发的框架和数据集，用于评估大型语言模型的认知忠实度 [PDF](https://arxiv.org/pdf/2505.20767), [HTML](https://arxiv.org/abs/2505.20767)
## Authors
Xiaqiang Tang,Jian Li,Keyu Hu,Du Nan,Xiaolong Li,Xi Zhang,Weigao Sun,Sihong Xie
## Background
现有基准主要关注可以重新表述源材料的‘事实陈述’，而忽视了涉及从给定上下文做出推论的‘认知陈述’。这导致了评估和检测认知陈述幻觉的困难。为了改进这种情况，作者借鉴了法律领域中证据评估的方法，设计了一个评估认知声明不同忠实度级别的严格框架，并提出了CogniBench数据集来揭示一些见解。为了跟上快速发展的大型语言模型的演变，作者还开发了一种易于扩展的自动注释流水线，从而产生了大规模的CogniBench-L数据集，这有助于训练对事实和认知幻觉都准确的检测器。
## Innovation
作者设计了评估认知声明不同忠实度级别的严格框架，并采用了CogniBench数据集，同时开发了大规模自动注释流水线，提高了评估和检测大型语言模型的认知幻觉的效率和准确性。
## Conclusion
作者提出了CogniBench框架和数据集，专注于更全面地评估和检测大型语言模型的认知幻觉，进一步开发了能够适应不同模型的自动注释流水线，使得大规模训练能够针对事实和认知幻觉进行准确检测。
# 166. `cs.AI` - WoundAmbit: 将尖端语义分割与实际伤口护理相结合 [PDF](https://arxiv.org/pdf/2504.06185), [HTML](https://arxiv.org/abs/2504.06185)
## Authors
Vanessa Borst,Timo Dittus,Tassilo Dege,Astrid Schmieder,Samuel Kounev
## Background
慢性伤口影响大量人群，尤其是老年人和糖尿病患者，他们通常移动受限并伴有共病。通过移动设备图片自动监测伤口可以减少亲自访医次数，并实现远程监测伤口尺寸变化。语义分割是关键技术，但伤口分割在医学影像研究中仍属空白。为解决这一问题，论文对比了通用视觉、医学影像和公开伤口挑战的先进深度学习模型，并标准化了训练、增广和评估流程，确保公平性。同时，评估了实际部署中的多种因素，包括模型的泛化能力、计算效率和可解释性。通过AI生成的掩码转换为临床相关伤口尺寸估计，并评估了最好的五个架构，Transformer 基于的 TransNeXt 展现了最高的泛化能力。所有模型的推理时间虽然有所差异，但均能在CPU上每秒处理至少一张图片，这足以满足实际应用需求。
## Innovation
1. 对比评估了最新深度学习模型在伤口分割中的表现，涉及通用视觉、医学影像和公开挑战的先进方法。2. 标准化了训练、增广和评估流程，确保公平性。3. 评估了实际部署中的泛化能力、计算效率和可解释性。4. 提出了一种参考对象基于的方法，将AI生成的掩码转化为临床相关伤口尺寸估计，并评估了前五个性能最佳模型。5. 展示了AI驱动的伤口尺寸估计框架WoundAmbit如何集成到定制的远程医疗系统中。
## Conclusion
Transformer 基于的 TransNeXt 展现了最高的泛化能力，虽然各模型的推理时间有所差异，但均能在CPU上每秒处理至少一张图片，符合实际应用需求。AI生成的掩码可转化为临床相关伤口尺寸估计，所有模型均获得了高掩码审批率，其中VWFormer和ConvNeXtS表现最佳。伤口尺寸获取准确率类似，预测结果与专家标注高度吻合。最终展示了WoundAmbit如何集成到定制的远程医疗系统中。
# 167. `cs.AI` - 蛋白质结构分词：基准测试与新配方 [PDF](https://arxiv.org/pdf/2503.00089), [HTML](https://arxiv.org/abs/2503.00089)
## Authors
Xinyu Yuan,Zichen Wang,Marcus Collins,Huzefa Rangwala
## Background
近年来，蛋白质结构分词方法的发展迅速，将蛋白质3D结构分解为离散或连续的表示。结构分词使得可以直接应用语言模型等强大技术用于蛋白质结构，并将结构与蛋白质序列和功能文本结合，使用大型多模态模型。尽管取得了进步，但由于缺乏统一的评价框架，这些方法的能力和限制仍不清楚。本文引入了StructTokenBench框架，旨在全面评估结构分词的质量和效率，重点关注细粒度的局部子结构，而非全局结构，而现有基准通常关注全局结构。该框架揭示出，没有单一模型在所有基准测试视角中表现优异。我们通过代码书利用率不足的观察开发了AminoAseed，一种简单而有效的策略，增强了代码书梯度更新，并最优地平衡代码书大小与维度，以提高分词器的利用和质量。与领先模型ESM3相比，我们的方法在24个监督任务中平均提高了6.31%的性能，精度和利用率分别提高了12.83%和124.03%。代码和模型权重已发布于此网站
## Innovation
提出了StructTokenBench框架，这是一种新颖的评估结构分词质量与效率的统一框架，特别关注细粒度的局部子结构。基于对代码书利用率不足的观察，开发了名为AminoAseed的新颖策略，通过优化代码书梯度更新和更佳地平衡代码书大小与维度，提高分词器的使用效率和质量。该方法显著提升了现有水平，特别是在多个监督任务上取得了平均6.31%的性能提升，质量和利用率分别增加了12.83%和124.03%。
## Conclusion
StructTokenBench框架和AminoAseed策略为之后的蛋白质结构分词研究提供了重要的基准和改进方向，通过优化代码书的特性，进一步提升了分词器的性能，使得细化的局部子结构处理成为可能。
# 168. `cs.AI` - 量子位到企业应用的监督量子机器学习：十年展望 [PDF](https://arxiv.org/pdf/2505.24765), [HTML](https://arxiv.org/abs/2505.24765)
## Authors
Srikanth Thudumu,Jason Fisher,Hung Du
## Background
监督量子机器学习（Quantum Machine Learning, QML）是在量子计算和经典机器学习之间交叉的一个领域，其目标是利用量子资源支持模型训练和推理。本文回顾了最近在监督QML方面的进展，重点关注如变量子电路、量子神经网络、量子核方法等方法，以及混合量子-经典工作流程。文章探讨了几项近期的实验研究，显示部分量子优势的迹象，并描述了当前限制，包括噪声、荒原 plateau、可扩展性问题以及未正式证明性能改进超过经典方法的缺陷。
## Innovation
本文主要贡献在于提出了一个十年（2025-2035）的展望，概述了未来监督QML的发展可能，包括一份路线图，描述了QML在未来十年可能应用于实际研究和企业系统下的条件。
## Conclusion
本文总结了监督量子机器学习领域的现有进展，识别了存在的挑战，并展望了未来十年可能的发展方向。
# 169. `cs.AI` - C3S3: 补偿竞争与对比选择在半监督医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2506.07368), [HTML](https://arxiv.org/abs/2506.07368)
## Authors
Jiaying He,Yitong Lin,Jiahe Chen,Honghui Xu,Jianwei Zheng
## Background
医学领域由于标注样本不足的挑战，半监督医学图像分割（SSMIS）提供了潜在的解决方案。当前大多数方法在勾勒主要目标区域方面能够取得不错的成绩，但在精确捕捉边界细微差异方面存在不足，导致诊断准确性降低。此问题亟待解决，因此提出了C3S3新型半监督分割模型，该模型通过协同整合补偿竞争和对比选择，提升边界勾勒的精度与总体精确度，并通过专为边界定位优化的对比学习模块和利用高性能子网络生成伪标签的动力补偿竞争模块进一步提高分割质量。该方法在两个公开数据集（包含MRI和CT扫描实践）上进行了严格的验证，结果显示其在95HD和ASD指标上相比先前的先进方法有至少6%的显著提升。相关代码可在指定链接获取。
## Innovation
C3S3模型通过引入补偿竞争和对比选择机制，显著提升了医学图像分割中的边界描绘精度，并通过专为边界定位优化的对比学习模块以及利用高性能子网络生成伪标签的动力补偿竞争模块进一步提高分割质量
## Conclusion
C3S3方法在两个公开数据集上实现了优于先前顶级竞争对手的性能，特别是在95HD和ASD指标上取得了至少6%的提升，展示出显著的技术进步。
# 170. `cs.AI` - AIDRIN 2.0: 一个评估AI数据准备性的框架 [PDF](https://arxiv.org/pdf/2505.18213), [HTML](https://arxiv.org/abs/2505.18213)
## Authors
Kaveen Hiniduma,Dylan Ryan,Suren Byna,Jean Luca Bez,Ravi Madduri
## Background
AIDRIN 是一个评估和提升AI应用所需数据准备性的框架，重点在于数据质量、偏差、公平性和隐私性等方面。为了进一步提升其用户友好性和实用性，论文对AIDRIN进行了改进，增加了用户界面优化，并实现了与隐私保护型联邦学习（PPFL）框架的集成。这一改进旨在使得不同技术水平的用户能够更容易地使用AIDRIN，并通过与现有PPFL框架的集成，保障数据在联邦学习环境中的隐私安全性和数据准备性。研究团队通过实际数据集的应用案例展示了AIDRIN实际验证数据准备性问题在提升AI模型性能中的重要性
## Innovation
1. 增强了用户界面，提高了AIDRIN的用户友好性和实用性，使其更加适合不同技术背景的用户。2. 与隐私保护型联邦学习（PPFL）框架实现了集成，确保了数据在联邦学习环境中的隐私性和数据准备性。3. 通过实际数据集的应用案例验证了AIDRIN的实际有效性，在识别影响AI模型性能的数据准备性问题方面具有重要意义
## Conclusion
AIDRIN 2.0 成功地通过用户界面优化和与隐私保护型联邦学习框架的集成，为提高数据准备性提供了实用的工具。研究表明，通过使用AIDRIN识别和解决数据准备性问题，可以显著提升AI模型的性能。
# 171. `cs.AI` - Aurora: 在分布转移下 Android 恶意软件分类器的可靠性和稳定性 [PDF](https://arxiv.org/pdf/2505.22843), [HTML](https://arxiv.org/abs/2505.22843)
## Authors
Alexander Herzog,Aliai Eusebi,Lorenzo Cavallaro
## Background
现代漂移适应型恶意软件分类器的性能指标看起来很有希望，但这些能否转化为实际操作中的可靠性和稳定性呢？目前的标准评估模式主要关注基准性能指标，忽略了置信度和误差之间的对齐以及操作稳定性。尽管TESSERACT强调了时间评价的重要性，但我们采取了补充性方向，研究恶意软件分类器在分布转移下能否维持可靠的和稳定的置信度估计，并探讨当这些情况不成立时，科学进步与实际影响之间的张力。
## Innovation
提出了一个名为AURORA的框架，用于基于置信度质量和操作韧性的恶意软件分类器评估。AURORA验证给定模型的信心概况，评估其估计的可靠性，并通过综合多种指标提供更全面的操作稳定性评估，超越了时间点性能评估。此外，结果强调，在不同漂移数据集上的最新框架存在脆弱性，暗示了需要回归到基本原理的重要性.
## Conclusion
AURORA框架通过严格的置信度评估和操作韧性评价，弥补了当前评估方法的不足，为恶意软件分类器提供了更加全面和实用的评估方式。
# 172. `cs.AI` - Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning [PDF](https://arxiv.org/pdf/2506.07744), [HTML](https://arxiv.org/abs/2506.07744)
## Authors
Seungho Baek,Taegeon Park,Jongchan Park,Seungjun Oh,Yusung Kim
## Background
现有的离线分层强化学习方法依赖于高级策略学习来生成子目标序列。然而，随着任务时间跨度的增加，它们的效率会下降，并且缺乏在不同轨迹之间拼接有用状态转换的有效策略。
## Innovation
提出了一种新的框架Graph-Assisted Stitching (GAS)，将子目标选择形式化为图搜索问题，而不是学习显式的高级策略。通过将状态嵌入到时间距离表示（TDR）空间中，GAS 将来自不同轨迹的语义相似状态聚集成统一的图节点，从而实现高效转换拼接。应用最短路径算法在图中选择子目标序列，同时低级策略负责导航到达子目标。引入了时间效率（TE）度量来过滤出噪声或低效的转换状态，显著提高了任务性能。GAS 在运动、导航和操纵任务上优于先前的离线 HRL 方法，并且在最需要拼接的任务上实现了88.3 的得分，远超先前的最好成绩1.0.
## Conclusion
GAS 在运动、导航和操纵任务上优于先前的离线 HRL 方法。特别是在最需要拼接任务上，它实现了88.3 的得分，远超先前的最好成绩1.0。
# 173. `cs.AI` - 通过注意力头选择实现细粒度的扰动指导 [PDF](https://arxiv.org/pdf/2506.10978), [HTML](https://arxiv.org/abs/2506.10978)
## Authors
Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim
## Background
最近的引导方法通过调整模型来反向生成，并构建了一个潜在的弱模型来引导生成远离它。在这些方法中，注意力扰动在不需要分类器自由引导的情况下没有条件场景中展示了很强的实证性能。然而，现有的注意力扰动方法缺乏确定应该在哪些位置应用扰动的有原则的方法，特别是在扩散转换器（DiT）架构中，质量相关的计算分布在多个层中。
## Innovation
本文研究了注意力扰动的颗粒度，从层级别到单个注意力头，并发现特定的头控制不同的视觉概念，如结构、风格和纹理质量。基于这一洞察，我们提出了“HeadHunter”框架，这是一个系统框架，用于根据用户中心的目标逐次选择注意力头，这使得在生成质量和视觉属性方面实现了细致的控制。我们还引入了SoftPAG，它可以将每个选定头部的注意力图线性插值到单位矩阵，提供了一个连续的调节点来调整扰动强度并抑制伪像。这种方法不仅缓解了现有层级扰动的过度平滑问题，还通过组合头选择实现了对特定视觉风格的定向操作。我们验证了我们的方法在现代大规模的扩散转换器文本到图像模型（包括Stable Diffusion 3和FLUX 1）上，展示了在总体质量和风格导向增强方面的优越性能。
## Conclusion
我们的工作提供了扩散模型中头部级别分析的第一个结果，发现了注意力层中的可解释专业化，并使实际设计有效的扰动策略成为可能。
# 174. `cs.AI` - SMAR: 软性模态感知路由策略用于保留语言能力的MoE架构多模态大型语言模型 [PDF](https://arxiv.org/pdf/2506.06406), [HTML](https://arxiv.org/abs/2506.06406)
## Authors
Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Wei Chen,Fangxiang Feng,Xiaojie Wang
## Background
Mixture of Experts (MoE) 架构已经成为大规模语言模型扩展的关键方法，且人们对其在多模态任务中的应用兴趣增加。然而，现有的构建多模态MoE模型的方法要么耗时成本高，要么在实现实用的标注语言能力时表现不佳。
## Innovation
我们提出了一种新颖的正则化技术——软性模态感知路由(Soft Modality-Aware Routing, SMAR)，它利用Kullback Leibler散度来控制跨模态的路由概率分布，鼓励专家专业化而无需改变模型架构或强烈依赖文本数据。实验结果表明，SMAR在仅使用2.5%的纯文本的情况下，保留了86.6%的语言能力，同时在多模态性能上表现出色，超越了基准模型。
## Conclusion
我们的方法为平衡多模态MoE模型的模态差异和语言能力提供了一种实际有效的解决方案。
# 175. `cs.AI` - IKDiffuser：多臂机器人基于扩散模型的生成逆向动力学求解器 [PDF](https://arxiv.org/pdf/2506.13087), [HTML](https://arxiv.org/abs/2506.13087)
## Authors
Zeyu Zhang,Ziyuan Jiao
## Background
逆向动力学（IK）问题在机器人技术中至关重要，但在多臂机器人系统中依然具有挑战性。由于复杂的自碰撞、耦合关节和高维冗余性，传统IK求解器往往速度慢、易失败且缺乏多样化的解决方案。鉴于这些挑战，研究旨在开发一种快速、多样化的IK生成模型，以应对多臂机器人系统的逆向动力学问题。
## Innovation
该论文提出了IKDiffuser，一种基于扩散模型的逆向动力学求解器，专为多臂机器人系统设计。IKDiffuser可以学习配置空间中的关节分布，捕捉复杂的依赖关系，并能够无缝地推广到不同结构的多臂机器人系统。此外，IKDiffuser在推理期间可以不重训练地集成额外的目标，具备针对特定任务的要求的多功能性和适应性。
## Conclusion
实验结果表明，提出的IKDiffuser在6种不同的多臂系统中实现了更高的解精度、更高的精准度、更高的多样性以及更好的计算效率。该框架为解决多臂机器人逆向动力学问题提供了一种可扩展和统一的方法，促进了多臂机器人系统在实时操作任务中的应用潜力。
# 176. `cs.AI` - TabArena：面向表格数据机器学习的活体基准 [PDF](https://arxiv.org/pdf/2506.16791), [HTML](https://arxiv.org/abs/2506.16791)
## Authors
Nick Erickson,Lennart Purucker,Andrej Tschalzev,David Holzmüller,Prateek Mutalik Desai,David Salinas,Frank Hutter
## Background
随着深度学习和基础模型在表格数据中的应用越来越广泛，标准化和可靠的基准测试需求日益增加。然而，现有基准是静态的，即使发现了缺陷、模型版本更新或新模型发布，其设计也不进行更新。
## Innovation
我们介绍了TabArena，这是首个持续维护的活体表格基准测试系统。通过人工筛选有代表性的数据集和实现良好的模型、进行大规模基准测试以初始化公共排行榜、组建经验丰富的维护团队，从而解决了现有静态基准的更新问题。结果表明，验证方法和超参数配置的组合对基准模型的表现至关重要。虽然梯度提升树在实际表格数据集上仍然是强有力的竞争者，但在较大的时间预算和采用集成情况下，深度学习方法已迎头赶上。此外，基础模型在较小数据集上表现出色。我们展示了模型集成推动了表格机器学习的最新水平，并探讨了各个模型的贡献。TabArena提供了一个公开排行榜、可复现的代码和维护协议，让该活体基准测试系统持续可用。
## Conclusion
我们通过推出TabArena，为持续维护的表格基准测试设立了新的标准。TabArena的发布为表格数据的机器学习提供了重要参考，形成了一个动态更新的基准系统。
# 177. `cs.AI` - CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation [PDF](https://arxiv.org/pdf/2506.15549), [HTML](https://arxiv.org/abs/2506.15549)
## Authors
Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen Chen
## Background
深度学习在通过晚期钆增强（LGE）心脏MRI对手部心肌瘢痕进行分割方面显示出巨大的潜力，有助于准确和及时诊断结构性心脏疾病。然而，高质量心肌瘢痕标签的LGE影像的有限可用性和多样性限制了稳健分割模型的发展。针对这一问题，引入了CLAIM框架：临床指导下的LGE增强，用于生成现实且多样的心肌瘢痕合成与分割。该框架的核心是SMILE模块（由临床知识引导的心肌瘢痕掩码生成），该模块采用AHA 17段模型作为基准，通过扩散生成器合成具有解剖一致性和空间多样性瘢痕模式的图像。此外，CLAIM采用了联合训练策略，该策略下生成器和瘢痕分割网络同时优化，旨在增强合成瘢痕的逼真度和瘢痕分割的准确性。实验结果显示，与基线模型相比，CLAIM生成的心肌瘢痕模式更具有解剖学一致性，与真实瘢痕分布的Dice相似性更高。我们的方法允许可控且现实的心肌瘢痕合成，表现出在后续医疗成像任务中的实用价值。
## Innovation
CLAIM框架采用临床指导的SMILE模块，利用AHA 17段模型在扩散生成器上生成解剖一致性和空间多样性的严重瘢痕图像。更重要的是，它采用联合训练策略，使得生成器和瘢痕分割网络同步优化，从而增强合成瘢痕的逼真度和瘢痕分割的准确性。
## Conclusion
实验结果表明，CLAIM生成的心肌瘢痕模式具有解剖一致性，并与真实瘢痕分布的Dice相似性更高。该方法允许可控且现实心肌瘢痕的合成，并显示出在后续医疗成像任务中的实用价值。
# 178. `cs.AI` - MS-TVNet：基于多尺度动态卷积的长期时间序列预测方法 [PDF](https://arxiv.org/pdf/2506.17253), [HTML](https://arxiv.org/abs/2506.17253)
## Authors
Chenghan Li,Mingchen Li,Yipu Liao,Ruisheng Diao
## Background
长期时间序列预测主要依赖于Transformer和MLP模型，而卷积网络在此领域中的潜力尚未得到充分探索。
## Innovation
提出了一种新的多尺度时间序列重塑模块，有效地捕捉多周期斑块之间的关系和变量依赖性，并在此基础上提出了MS-TVNet——一种多尺度3D动态卷积神经网络。该模型在多个数据集上的综合评估中表现出色，优于基线模型，并达到了长期时间序列预测中的前沿水平。
## Conclusion
我们的研究结果强调了利用卷积网络捕捉复杂时间模式的有效性，为未来研究提供了有希望的方向。研究成果已发布在https://github.com/和https://doi.org/。
# 179. `cs.AI` - 使用KnoVo映射研究贡献的演变 [PDF](https://arxiv.org/pdf/2506.17508), [HTML](https://arxiv.org/abs/2506.17508)
## Authors
Sajratul Y. Rubaiat,Syed N. Sakib,Hasan M. Jamil
## Background
传统引用分析主要衡量论文的影响力，但不能有效量化和分析研究成果的新颖性变化。本文旨在提出KnoVo（知识演变）框架，以解决上述问题。KnoVo通过分析论文与其前后作品的关系，基于多层引用网络来确定论文的新颖性。它结合了大型语言模型（LLMs）动态提取研究比较维度，并通过对比分析得出定量的新颖性评分。这种方法能够更全面地评估研究的独特性和追踪研究维度上的知识演变，帮助识别研究缺口和探索跨学科联系。研究者可以通过动态演化图和比较雷达图可视化这些评分的变化过程。
## Innovation
KnoVo框架创新地利用大型语言模型动态提取比较维度，并通过对比分析得出定量的新颖性评分。它超越了传统的引用分析，能够更全面地评估研究的独特性和追踪研究维度上的知识演变，帮助识别研究缺口和探索跨学科联系。
## Conclusion
通过对20篇来自不同科学领域的论文进行详细分析，展示了KnoVo框架的功能。研究还报告了在KnoVo框架中不同开源大型语言模型的性能。该框架能够帮助研究人员评估原创性、识别相似工作，并跟踪特定研究维度上的知识演变、发现研究缺口，以及探索跨学科联系。
# 180. `cs.AI` - VRAIL：向量奖励归因的可解释学习 [PDF](https://arxiv.org/pdf/2506.16014), [HTML](https://arxiv.org/abs/2506.16014)
## Authors
Jina Kim,Youjin Jang,Jeongjin Han
## Background
该研究提出了一个基于价值的强化学习（RL）范式，该范式能够从状态特征中学习可解释的权重表示。背景在于现有的强化学习方法常常难以提供透明和可解释的决策过程，尤其是在优化奖励信号时。为了改进这一过程，研究者提出了一种名为VRAIL的两级框架。该框架结合了深度学习（DL）和强化学习（RL），能够通过潜在奖励转换来塑造学习过程，并通过线性和二次形式的估计算法来归因于单个特征及其相互作用的重要性。
## Innovation
VRAIL的创新点在于它提供了一个用于价值引导的强化学习框架，该框架能够从状态特征中学习具有解释性的权重表示。它通过深度学习阶段拟合一个估计的价值函数，再通过强化学习阶段使用这个价值函数进行奖励转化，从而影响学习过程。VRAIL的特点在于其能够区分不同特征的重要性，特别是其可以采用线性或二次形式的模型，这使得单个特征及其相互作用的重要性得以分配。此外，该框架不依赖于环境修改，适用于广泛的强化学习应用场景。实验证明，相比于标准的DQN方法，VRAIL在出租车环境（Taxi-v3）中提高了训练稳定性和收敛性，同时揭示了具有语义意义的子目标，如乘客拥有等方面，突显了其支持人类可解释行为的能力。
## Conclusion
研究结果表明，VRAIL作为一个通用的、模型无关的框架，可以增强奖励塑造，从而改善学习和可解释性。这一研究为强化学习中的可解释性和透明度提供了一种新的解决方案，在不需要修改环境的情况下提升了强化学习的性能和可理解性。
# 181. `cs.AI` - 回收网络：提高语言模型预训练数据质量与数量的方法 [PDF](https://arxiv.org/pdf/2506.04689), [HTML](https://arxiv.org/abs/2506.04689)
## Authors
Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li
## Background
大规模语言模型的性能随着模型规模和数据量的增加而提高。实践中，预训练主要依赖于大规模网页抓取，并使用几乎全部可获得的互联网数据源。然而，可供使用的自然数据增长速度并不如计算资源的增长速度。此外，高质量文本数据的可用性甚至更为有限，数据筛选管道常会丢弃高达99%的原始网页抓取数据以实现最佳效果。为了应对预训练扩展中的‘数据墙’问题，本文研究了如何将现有筛选过程丢弃的数据进行重组和再利用。实验表明，混合高质量原始文本与回收再写的文本可提高22个不同任务的精度，这证明了回收网络数据的有效性。进一步分析显示，混合文本中有大约82%来自转化低质量文档，这些文档本会被丢弃。这种做法在合成数据生成方面优于其他方法，表现出简单有效的潜在价值。
## Innovation
提出了REWIRE方法，这是一种将低质量文档转换为可用于训练的高质量文档的方法，从而增加合成数据在最终预训练数据集中的比例。研究发现，混合高质量原始文本和回收再写的文本可以提高22个不同任务的性能，且效果优于纯过滤网页数据。此外，该方法也优于其他生成合成数据的方法，如维基百科风格的重写、问答合成和知识提取。这表明回收网络文本有潜力作为一种简单且有效的方法来扩展预训练数据。
## Conclusion
通过将回收再写的文本与高质量原始文本混合，可以提高语言模型的训练效果，并证明了回收网络数据的有效性。这种方法不仅提高了数据的质量和数量，还能够利用被丢弃的低质量文档，从而简化和有效扩展预训练数据集。
# 182. `cs.AI` - 非平衡加权退火伴随采样器 [PDF](https://arxiv.org/pdf/2506.18165), [HTML](https://arxiv.org/abs/2506.18165)
## Authors
Jaemoo Choi,Yongxin Chen,Molei Tao,Guan-Horng Liu
## Background
最近，在基于学习的扩散采样器方面取得了显著进展，这些采样器旨在从给定的未正则化密度中采样。这些方法通常遵循两种范式之一：(i)使用一个经典参考过程来表述采样为无偏的随机最优控制问题，或(ii)通过重要加权采样细化退火路径测度。虽然退火方法在引导样本向高密度区域方面具有优势，但对重要性采样的依赖导致了实际中的高方差和有限可扩展性。
## Innovation
本文介绍了一种新颖的`非平衡加权退火伴随采样器（NAAS）`，这是一种基于随机最优控制（SOC）的扩散采样器，不依赖重要性采样而是利用退火参考动力学。NAAS采用了受伴随匹配启发的精简伴随系统，使得训练既高效又可扩展。
## Conclusion
我们的方法在多种任务上都展示了有效性，包括从经典能量景观和分子玻尔兹曼分布中采样。
# 183. `cs.AI` - 屏幕接管：在移动环境中对基于视图语言模型的智能代理进行视觉毒化 [PDF](https://arxiv.org/pdf/2506.13205), [HTML](https://arxiv.org/abs/2506.13205)
## Authors
Xuan Wang,Siyuan Liang,Zhe Liu,Yi Yu,Yuliang Lu,Xiaochun Cao,Ee-Chien Chang,Xitong Gao
## Background
随着视觉语言模型（VLMs）的集成度不断提高，移动智能代理如今被广泛用于自动化界面（UI）和基于相机的用户辅助任务。这些代理通常使用有限的用户自动生成的数据集进行微调，在训练过程中容易受到隐蔽威胁。本文提出了GHOST，这是一种针对基于VLM的移动智能代理的首个清洁标签后门攻击方法。该方法仅对部分训练样本的视觉输入进行操控，而不更改其对应标签或指令，以向模型中注入恶意行为。
## Innovation
GHOST的方法通过将被污染样本的梯度对齐于选定目标样本的梯度，将后门相关特征嵌入污染的训练数据中，实现了对移动智能代理的清洁标签后门攻击。为此，GHOST开发了三种现实的视觉触发器：静态视觉斑块、动态运动暗示和低不透明度的叠加。该方法在六个实际Android应用程序和三个适合移动设备使用的VLM架构上进行了评估，结果显示，其攻击成功率可高达94.67%，同时保持高清洁任务性能（有限补充率FSR高达95.85%）。
## Conclusion
本研究首次揭示了基于VLM的移动智能代理中存在的关键安全漏洞，揭示了它们对清洁标签后门攻击的高度敏感性，并强调了其在训练管道中迫切需要有效的防御机制。
# 184. `cs.AI` - PP-DocBee2: 增强的多模态文档理解基础模型与高效数据 [PDF](https://arxiv.org/pdf/2506.18023), [HTML](https://arxiv.org/abs/2506.18023)
## Authors
Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu
## Background
PP-DocBee2是在PP-DocBee的基础上开发的增强版本，旨在提升多模态文档的理解能力。前作PP-DocBee已经构建在大型多模态模型架构上，但面临一些技术限制。为了改进这些限制，PP-DocBee2通过提高合成数据的质量，改进视觉特征融合策略，并优化推理方法，显著提升了性能。这些改进使得PP-DocBee2在中国商务文档项目中超越前作11.4%，同时将推理延迟降低了73.0%。
## Innovation
PP-DocBee2的关键创新在于数据质量优化策略。通过使用大规模多模态预训练模型评估数据并应用新颖的统计准则筛选异常值，确保了高质量的训练数据。此外，通过利用多模态模型中未充分利用的中间特征，PP-DocBee2增强了ViT的表现能力，并提出了新的特征融合策略以提升复杂推理能力。
## Conclusion
PP-DocBee2在多模态文档理解方面展示了显著的性能提升和效率改进。通过优化数据质量并改进特征融合策略，PP-DocBee2在多个任务中表现出色，其源代码和预训练模型已公开供下载。
# 185. `cs.AI` - 量子-经典混合量化神经网络 [PDF](https://arxiv.org/pdf/2506.18240), [HTML](https://arxiv.org/abs/2506.18240)
## Authors
Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen
## Background
本文介绍了一种新的二次二值优化（QBO）模型，用于训练量化神经网络，该模型可以通过样条插值使用任意激活和损失函数。该研究引入了向前区间传播（FIP）方法，用于处理神经网络中非线性及多层复合结构带来的挑战，通过将激活函数离散化为线性子区间。这种方法保持了神经网络的通用逼近性质，同时允许复杂的非线性函数使用量子计算机进行优化，扩展了其在人工智能中的应用范围。通过从优化的角度推导经验风险最小化问题的样本复杂性，提供了近似误差的上界和所需的Ising自旋数量的上界。然而，大规模求解相关的二次约束二值优化（QCBO）模型面临的挑战是高数量级的约束条件，当使用惩罚方法处理这些约束时，调整大量的惩罚系数成为关键的超参数优化问题，增加了计算复杂性并可能影响解决方案质量。
## Innovation
本文创新性地提出了一种基于QBO的量化神经网络训练模型，通过样条插值支持任意激活和损失函数；提出向前区间传播（FIP）方法，通过离散化激活函数来解决非线性和多层结构问题；使用量子渐近梯度下降（QCGD）算法，利用量子计算直接解决QCBO问题，并提供了该算法 converges 的理论证明及其计算时间的上界。
## Conclusion
实验结果表明，使用相干Ising机（CIM）在 Fashion MNIST 分类任务上达到了94.95%的精度，仅需1.1位精度。这一成果表明，基于QBO的量化神经网络模型在保持高精度的同时，利用量子计算有效地解决大规模问题。
# 186. `cs.AI` - 无免费午餐：重思大语言模型推理中的内部反馈 [PDF](https://arxiv.org/pdf/2506.17219), [HTML](https://arxiv.org/abs/2506.17219)
## Authors
Yanzhi Zhang,Zhaoxi Zhang,Haoxiang Guan,Yilin Cheng,Yitong Duan,Chen Wang,Yue Wang,Shuxin Zheng,Jiyan He
## Background
强化学习已成为提升大语言模型（LLMs）推理能力的一种强大范式，方法如强化学习从人类反馈（RLHF）和可验证奖励的强化学习（RLVR）已经取得显著效果，但这些方法需要大量的外部监督。这篇文章探讨了一种新的方法，即依赖内部模式衍生信号而非外部奖励的强化学习从内部反馈（RLIF）方法。RLIF采用未监督的奖励替代方法，例如令牌级熵、轨迹级熵和自我确定性。研究者理论分析了这些内部目标的部分等价性，并在具有挑战性的数学推理基准上评估了多种RLIF策略的效果。实验证明在训练初期，RLIF可以提升基模型的推理性能，有时甚至超过RLVR方法。但随着训练的进行，即使在性能下降后，也无法恢复到未经过训练的模型水平。研究者还发现，对于指令调优模型，RLIF几乎没有任何提升，这表明当LLM已经指令调优时，内部反馈的效果会逐渐减弱。
## Innovation
提出了一种新的方法，即依赖内部模式衍生信号而非外部奖励的强化学习从内部反馈（RLIF）。这里首次研究了不依赖外部奖励的RLIF方法，并通过理论分析展示了多种内部目标的部分等价性，为内部反馈信号的应用提供了新的路径。
## Conclusion
初步实验结果表明，在训练初期，RLIF可以提升基模型的推理性能，并且在某些情况下可以超过RLVR。但是，训练过程中的性能逐渐恶化，即便不再下降时，也无法恢复到未经过训练的模型水平。此外，对于已经指令调优的模型，RLIF方法几乎没有任何提升，这表明当LLM已经指令调优时，内部反馈的效果会逐渐减弱。文章还通过模型权重混合进一步分析了这种局限性及其训练行为，提供了将内部反馈信号整合到LLM训练中的实用指南。希望能通过本文的内部反馈分析，为LLM训练后的更多原则性、有效方法提供依据。
# 187. `cs.AI` - 超出标记层面量化语言模型公正性：一种语义和统计视角 [PDF](https://arxiv.org/pdf/2506.19028), [HTML](https://arxiv.org/abs/2506.19028)
## Authors
Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy
## Background
大型语言模型（LLMs）常常生成具有内在偏见的回答，这影响了它们在实际应用中的可靠性。现有的评估方法往往忽视了长篇回答中的偏见和LLM输出的内在变化性。
## Innovation
提出了一个新颖的统计框架FiSCo（Fine-grained Semantic Computation），通过检测不同人口统计学组别之间的细微语义差异来评估群体层面的公正性。它从声明层面进行分析，利用推论检查来评估答案之间意思的一致性，而不仅仅是表面层次的比较。该方法将模型输出分解为语义不同的声明，并应用统计假设检验来比较组内和组间的相似性，从而更准确地检测出细微的偏见。
## Conclusion
实验表明，FiSCo能够更可靠地识别细微偏见，同时减少随机性对LLM变量的影响，其性能优于各种评估指标。通过正式化新的群体反事实公平性定义，FiSCo在合成和人工标注数据集上的表现证明了其优越性，覆盖性别、种族和年龄等多个领域。
# 188. `cs.AI` - Confucius3-Math：一种轻量级高性能推理大语言模型，用于中国的K-12数学学习 [PDF](https://arxiv.org/pdf/2506.18330), [HTML](https://arxiv.org/abs/2506.18330)
## Authors
Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan
## Background
论文介绍了Confucius3-Math，这是一个14亿参数的开源大语言模型，能够在单个消费者级GPU上高效运行，并在一系列数学推理任务中取得SOTA性能，优于许多规模更大的模型。模型特别关注为中国的K-12学生和教育者提供数学学习服务，旨在通过AI增强教育和知识传播。
## Innovation
论文介绍三种技术创新：目标熵正则化、最近样本恢复和策略特定难题加权。这些创新包括一种新的熵正则化、一种新颖的数据调度策略以及一个改进的组相对优势估计器，共同显著稳定了强化学习训练，提高了数据效率并提升了性能。
## Conclusion
工作证明了在特定领域以低成本构建强大推理模型的可能性。模型和代码已开源，可以在以下链接访问：this https URL.
# 189. `cs.AI` - AnchorDP3：基于3D可用性稀疏扩散策略的机器人操作 [PDF](https://arxiv.org/pdf/2506.19269), [HTML](https://arxiv.org/abs/2506.19269)
## Authors
Ziyan Zhao,Ke Fan,He-Yang Xu,Ning Qiao,Bo Peng,Wenlong Gao,Dongjiang Li,Hui Shen
## Background
该论文提出了AnchorDP3框架，这是一个用于双臂机器人操作的扩散策略框架，能够在高度随机化的环境中达到最先进的性能。在RoboTwin基准测试中，AnchorDP3在模型、杂物、桌子高度、照明和背景等极端随机化条件下，实现了98.7%的平均成功率，涵盖了多种任务。该框架结合了RoboTwin的真实到模拟管道，旨在仅通过场景和指令生成高效的可部署视觉-运动策略，从而完全消除从学习操作技能所需的人类演示。
## Innovation
AnchorDP3集成了三项关键技术创新：1）基于模拟器监督的语义分割，利用渲染的地面真值明确地在点云中分割任务关键对象，提供强烈的可用性先验；2）任务条件特征编码模块，它们处理增强点云的轻量级模块，使共用基于扩散的行动专家的多任务学习变得高效；3）以完全状态监督为锚的可取性稀疏关键姿势扩散，用稀疏、几何上有意义的动作锚点替换密集轨迹预测，例如预抓取姿势、直接锚定到可取性的抓取姿势，大大简化了预测空间；行动专家被强迫同时预测机器人关节角度和末端执行器姿态，这利用几何一致性加快了收敛速度并提高了准确性。
## Conclusion
通过大规模、程序生成的模拟数据训练，AnchorDP3能够在RoboTwin基准测试中表现出卓越的性能，在各种任务下，即使在对象、杂物、桌子高度、照明和背景等极端随机化条件下，其平均成功率仍达到98.7%。当该框架与RoboTwin真实到模拟管道结合使用时，具有完全自动化生成可部署的视觉-运动策略的潜力，仅需场景和指令即可，完全消除了从学习操作技能所需的人类演示。
# 190. `cs.CL` - Inference Scaled GraphRAG: 提升知识图谱上多跳问答的推理缩放GraphRAG [PDF](https://arxiv.org/pdf/2506.19967), [HTML](https://arxiv.org/abs/2506.19967)
## Authors
Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu
## Background
大型语言模型（LLMs）在语言理解和生成方面表现出色，但在知识密集型推理任务上表现仍然不佳，因为它们难以访问结构化的上下文和多跳信息。检索增强生成（RAG）可以部分解决这个问题，通过基于检索到的上下文生成内容来缓解这种情况，但传统的RAG和GraphRAG方法往往无法捕捉知识图中节点之间的关系结构。研究表明，在知识图谱中进行推理时，LLMs 表现不佳的原因之一是缺乏有效的结构化知识处理方法。
## Innovation
我们提出了推理缩放GraphRAG（Inference-Scaled GraphRAG），这是一种创新框架，通过推理时的计算缩放增强了基于LLM的图推理。该方法结合了顺序缩放和深层链式思考的图遍历，以及并行缩放和交错推理执行循环中采样轨迹上的多数投票。实验结果表明，我们的方法显著提高了多跳问答性能，相较于传统的GraphRAG和之前的图遍历基线方法取得了显著的提升。这表明推理时的计算缩放是一种实用且架构无关的方法，适用于LLMs的结构化知识推理中。
## Conclusion
我们的实验表明，推理缩放GraphRAG方法在多跳问答任务上表现优异，显著优于传统的GraphRAG和先前的图遍历基准方法。这表明推理时的计算缩放可以作为一种有效的解决方法，提升LLMs在知识图谱上进行复杂推理的能力。
# 191. `cs.CL` - Doc2Agent: 根据API文档生成可扩展的工具使用代理 [PDF](https://arxiv.org/pdf/2506.19998), [HTML](https://arxiv.org/abs/2506.19998)
## Authors
Xinyi Ni,Haonan Jian,Qiuyang Wang,Vedanshi Chetan Shah,Pengyu Hong
## Background
REST APIs 对于丰富网络代理的动作空间发挥着重要作用，然而大多数基于API的代理依赖于经过整理且一致的工具集，这未能反映真实世界API的复杂性。为任意领域构建使用工具的代理仍然是一项重大挑战。这需要理解未结构化的API文档、测试API并推断正确的参数。
## Innovation
提出了Doc2Agent，一个可扩展的流水线，可以从API文档中生成并逐步优化可执行工具，以便调用Python基工具。Doc2Agent通过代码代理迭代优化生成的工具，并在实际的API、WebArena API和研究API上进行了评估，生成了验证过的工具。在WebArena基准测试中，与直接调用API相比，这一方法实现了55%的相对性能改进和90%的成本降低。一个针对糖材料科学的领域专用代理进一步证明了该流水线对于复杂、知识密集型任务的适应性。
## Conclusion
Doc2Agent提供了一个可扩展的解决方案，可以从未结构化的API文档中大规模构建工具代理。
# 192. `cs.AI` - 莫尔斯：损失less加速扩散模型的双抽样法 [PDF](https://arxiv.org/pdf/2506.18251), [HTML](https://arxiv.org/abs/2506.18251)
## Authors
Chao Li,Jiawei Fan,Anbang Yao
## Background
本文论文介绍了一种名为Morse的简单双抽样框架，旨在无损加速扩散模型。Morse的关键洞察在于通过利用快速跳跃抽样和自适应残差反馈策略重新制定从噪声生成数据的过程，从而提高生成效率。这种框架利用了两个交互的模型：Dash和Dot，它们共同协作以加速图像生成过程，同时保持生成质量不变。这种方法在多种图像生成任务中展示了显著的速度提升，并且能够应用于已经加速的模型，如Latent Consistency Model (LCM-SDXL)，以进一步提高效率和生成质量。
## Innovation
Morse引入了一种新颖的双抽样方案，通过两种模型Dash（预先训练的扩散模型）和Dot（快速生成残差反馈的模型）的交互作用，实现了在保持生成质量的情况下对扩散模型进行加速。这种方案通过快速跳跃抽样和自适应残差反馈策略，显著提高了生成过程的效率，同时还能与已经使用一致性蒸馏技术加速的模型结合使用。此外，Morse还提出了一种权重共享策略，使得训练和推理过程更加高效。Morse在多个图像生成任务中相对于9个基线扩散模型平均实现了1.78到3.31倍的无损加速。
## Conclusion
Morse展示了在多个图像生成任务中相对于多个基线扩散模型的平均1.78到3.31倍的无损加速效率，并证明了其在其他加速扩散模型上的适用性。该方法的代码和模型已公开发布，能够进一步促进扩散模型在实际应用中的效率提升。
# 193. `cs.CL` - SACL: 通过语义增强再排序和定位理解及对抗代码检索中的文本偏见 [PDF](https://arxiv.org/pdf/2506.20081), [HTML](https://arxiv.org/abs/2506.20081)
## Authors
Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie
## Background
当前的代码检索技术虽然基于代码训练，但主要依赖于表面级别的文本特征（如注释字符串、标识符名称），且倾向于对文档良好的代码有较强的偏向性，即使这些文档并不充分。
## Innovation
提出了一种名为SACL的框架，通过结合代码或结构知识的语义信息来丰富文本信息并减少偏见。实验结果显示SACL显著提高了代码检索性能，如在HumanEval、MBPP和SWE-Bench-Lite上的召回率分别提高了12.8%、9.4%和7.0%，这同样提升了代码生成的效果（如HumanEval的Pass@1提高了4.88%）。
## Conclusion
通过SACL框架，增强代码检索中的语义信息，减少了对文档良好代码的过度依赖，提高了代码检索和代码生成的整体性能。
# 194. `cs.AI` - OmniGen2: 探索高级多模态生成 [PDF](https://arxiv.org/pdf/2506.18871), [HTML](https://arxiv.org/abs/2506.18871)
## Authors
Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu
## Background
本文介绍了一种通用且开源的生成模型OmniGen2，旨在为包括文本到图像、图像编辑和上下文生成在内的多种生成任务提供统一的解决方案。与之前版本（OmniGen v1）不同，OmniGen2引入了两种不同的解码路径，分别用于文本和图像模态，不共享参数且图像标注器解耦。这一设计使得OmniGen2能够在保留原有文本生成能力的同时，基于现有的多模态理解模型进行构建，无需重新调整VAE输入，从而保持原始的文本生成能力。为了训练OmniGen2，作者开发了全面的数据构建管道，涵盖图像编辑和上下文生成数据，并引入了一种专门针对图像生成任务的反射机制，以及基于OmniGen2的专用数据集。尽管参数量相对较小，但OmniGen2在多个任务基准上实现了具有竞争力的结果，特别是在文本到图像和图像编辑任务上。为了进一步评估上下文生成能力（也称为主题驱动任务），作者还引入了一个新的基准测试，称为OmniContext。
## Innovation
OmniGen2的主要创新点在于引入了两种不同的解码路径，分别用于文本和图像模态，并且不共享参数。通过将图像标注器解耦，OmniGen2能够在保留原有文本生成能力的同时，基于现有的多模态理解模型进行改进，无需重新调整VAE输入。此外，为了提升模型性能，作者还完善了数据构建管道，并引入了针对图像生成任务的反射机制。
## Conclusion
尽管参数量相对较小，OmniGen2在多个任务基准上实现了具有竞争力的结果，在多种生成任务上表现优秀。作者将公开模型代码、训练代码、数据集和数据构建管道，以支持未来在这个领域的研究。
# 195. `cs.CL` - CycleDistill: 利用循环蒸馏进行大型语言模型驱动的机器翻译初始化 [PDF](https://arxiv.org/pdf/2506.19952), [HTML](https://arxiv.org/abs/2506.19952)
## Authors
Deepon Halder,Thanmay Jayakumar,Raj Dabre
## Background
尽管大型语言模型（LLMs）能够执行零样本或多样本机器翻译（MT），但它们在质量上通常不及专为平行语料库训练的翻译系统。平行语料库往往稀少或不存在于低资源语言中。因此，本研究旨在利用LLMs和零样本或多样本翻译来迭代生成合成平行语料库，从而构建高质量的翻译系统。CycleDistill方法不需要额外的平行语料库，只需要少至1到4个样本即可实现高质量的机器翻译，在实验中，通过对仅依赖于单语语料库三种印度语言的评估，CycleDistill在第一轮迭代中相较于零样本基线模型提升了超过20-30个chrF分数点。此外，研究还探索了在蒸馏过程中利用softmax激活的效果，取得了轻微的翻译质量改进。
## Innovation
提出了一种名为CycleDistill的方法，这是一种利用LLMs和零样本或多样本翻译自动生成合成平行语料库以改进机器翻译质量的初始化方法。该方法不需额外的平行语料库，仅需少量样本即可有效提升翻译质量，且在实验中表现出显著改进。
## Conclusion
CycleDistill方法能够在没有额外平行语料库的情况下，通过自动生成合成平行语料库实现高质量的机器翻译。在印度语言的实验中，该方法在第一轮迭代中平均提高了20-30个chrF分数点，并且在蒸馏过程中利用softmax激活的效果显示出轻微的翻译效果改进。
# 196. `cs.CL` - 结合时空模型和大语言模型的模块化多任务推理框架 [PDF](https://arxiv.org/pdf/2506.20073), [HTML](https://arxiv.org/abs/2506.20073)
## Authors
Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang
## Background
时空数据挖掘在不同领域的决策制定中发挥着关键作用。然而，现有的模型往往局限于特定任务，缺乏进行多任务推理和复杂长期推理的能力，这需要生成深入且解释性的输出。这些限制限制了它们在多方面现实世界决策场景中的应用。
## Innovation
本文引入了一种名为STReason的新框架，将大型语言模型（LLMs）的推理优势与时空模型的分析能力结合起来，用于多任务推理和执行。STReason无需特定任务的微调，利用情境学习将复杂的自然语言查询分解成可模块化和解释的程序，然后系统执行这些程序以生成解决方案和详细的推理。为了进行严格的评估，我们构建了一个新的基准数据集，并提出了一个统一的评估框架，其中包含专门为长时间序列推理设计的度量标准。实验结果显示，STReason在所有指标上均优于先进的大语言模型基线，并在复杂的、推理密集的时空场景中表现出色。
## Conclusion
人类评估进一步验证了STReason的可信度和实际效用，显示出其减少专家工作量、扩大时空任务适用范围的潜力。我们认为STReason提供了开发更强大和通用的时空推理系统的一个有前景的方向。
# 197. `cs.CL` - 基于时空点过程的细粒度阅读行为建模 [PDF](https://arxiv.org/pdf/2506.19999), [HTML](https://arxiv.org/abs/2506.19999)
## Authors
Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell
## Background
阅读是一个在时间和空间上交替进行的过程，涉及眼睛在固定点上的凝视和在新的位置间的扫视。心理学语言学的假设是，通过建模读者的凝视和扫视，可以揭示其在线句法处理的见解。然而，传统的建模方法依赖于聚合的眼动测量和强假设模型，忽略了阅读过程中发生的大量时空动态变化。本文提出了基于带标记的时空点过程的更通用的概率阅读行为模型，不仅捕捉了凝视持续时间，还考虑了其空间定位和时间发生的准确性。扫视过程用Hawkes过程建模，以捕捉每个凝视后在时间和空间上出现新凝视的概率。凝视事件的持续时间被建模为与时间卷积的凝视特定预测器函数，从而捕捉溢出效应。实验证明，文章的Hawkes过程模型相较于基准模型更能准确拟合人类扫视行为。对于凝视持续时间，研究发现将上下文惊异作为预测因子时模型精度的提升较为微弱，这表明惊异理论难以解释细粒度的眼动行为。
## Innovation
提出了基于带标记的时空点过程的更通用的概率阅读行为模型，其中扫视过程建模为Hawkes过程，凝视事件的持续时间被建模为与时间卷积的凝视特定预测器函数。此模型能够更准确地模拟阅读过程中的细粒度行为特点。
## Conclusion
文章提出的基于时空点过程的阅读行为建模方法能够在更深层次上理解阅读过程中的时空动态变化。尽管上下文惊异能在一定程度上影响凝视持续时间，但现有理论仍难以解释细粒度的眼动行为。
# 198. `cs.CL` - 多次过大型语言模型框架用于精确和高效的放射学报告错误检测 [PDF](https://arxiv.org/pdf/2506.20112), [HTML](https://arxiv.org/abs/2506.20112)
## Authors
Songsoo Kim,Seungtae Lee,See Young Lee,Joonho Kim,Keechan Kan,Dukyong Yoon
## Background
大型语言模型（LLM）基于的放射学报告校对正预测值（PPV）受限于错误发生的低频率。因此，研究旨在评估三步校对（三步LLM框架）是否能提升正预测值和减少运营成本，对比基线方法的效果如何.
## Innovation
开发了一种三步校对的LLM框架，包括单一提示检测器、提取器及检测器、以及额外的假阳性验证器。该框架通过测评精准度（正预测值和绝对真实阳性率）和效率（模型推理费用和审阅员的报酬）来提高放射学报告的质量保证.
## Conclusion
三步LLM框架显著提升了正预测值并减少了运营成本，同时维持了检测性能，为人工智能辅助放射学报告质量保证的有效策略.
# 199. `cs.CL` - ITFormer: 用大规模多任务数据集将时间序列与自然语言结合进行多模态问答 [PDF](https://arxiv.org/pdf/2506.20093), [HTML](https://arxiv.org/abs/2506.20093)
## Authors
Yilin Wang,Peixuan Lei,Jie Song,Yuzhe Hao,Tao Chen,Yuxuan Zhang,Lei Jia,Yuanxiang Li,Zhongyu Wei
## Background
时间序列数据在工业监控、医学诊断和气候研究等多样化的应用场景中至关重要。然而，将这些高维度的时序信号与自然语言有效地结合以完成动态、交互式任务仍然是一个重大的挑战。
## Innovation
我们提出了时间序列问答（Time-Series QA）任务并发布了EngineMT-QA数据集，这是首个针对时序信号与自然语言之间的复杂交互设计的大规模多任务文本-时间数据集。我们还提出了一种名为Instruct Time Transformer (ITFormer)的新框架，它将时序编码器与冻结的大规模语言模型（LLMs）连接起来。ITFormer能够有效提取、对齐和融合时序和文本特征，相较于现有基准模型，在可训练参数量少于1%的情况下，显著提高了问答准确性。
## Conclusion
通过结合计算效率与跨模态建模的鲁棒性，我们的工作为将时序数据与自然语言集成奠定了可适应的范式，为多模态人工智能领域的新兴研究和应用铺平了道路。
# 200. `cs.CL` - MIRAGE: 农业专家引导对话中的多模态信息搜索和推理基准 [PDF](https://arxiv.org/pdf/2506.20100), [HTML](https://arxiv.org/abs/2506.20100)
## Authors
Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve
## Background
当前的多模态模型评估基准往往依赖于具体且规范化的用户输入和封闭式分类，没有充分捕捉到真实世界咨询互动中的复杂性。MIRAGE 基准设计用于农业领域，它汇集了真实用户与专家的互动，涵盖了多种作物健康、病虫害诊断和作物管理的场景，展示了多样的生物实体种类，为评估模型的语境推理、澄清策略和长篇生成提供了真实、高保真的数据支持.
## Innovation
MIRAGE 提供了一个新的基准，用于评估模型在农业领域的多模态推理和决策能力。它通过结合自然用户问题、专家撰写的回应和图像背景信息，模型需要在开放世界设置下推断隐含的知识缺口，处理稀有实体，并有效引导或响应交互。MIRAGE 的独特之处在于其采用了多步骤管道精心策划的大量真实用户-专家互动数据，使其成为目前最全面和多样化的视觉-语言模型基准之一，深入本地化知识密集型领域的真实场景.
## Conclusion
MIRAGE 为多模态信息搜索和推理在农业专家引导对话中的评估提供了新的框架，用以支持潜理解推理和长篇生成的模型测试。
# 201. `cs.AI` - 思考锚点：哪些LLM推理步骤有意义？ [PDF](https://arxiv.org/pdf/2506.19143), [HTML](https://arxiv.org/abs/2506.19143)
## Authors
Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy
## Background
大语言模型在许多领域已经取得了最先进的性能。然而，这些模型的长段逻辑推理造成了可解释性挑战，因为每个生成的词都依赖于所有之前的词，这使得计算难以分解。本文提出了在句子层面上分析推理痕迹作为一种理解推理过程的有前景的方法。研究表明，存在具有较大影响且对后续推理过程影响较大的“思考锚点”，这些锚点通常是计划或回溯句子。
## Innovation
本文提出了一种句子级别的分析方法来理解语言模型的推理过程。具体来说，采用了三种互补的归因方法：一种是通过对比在和不生成特定句子时的最终答案来量化每个句子的反事实重要性；一种是有监督的方法，通过聚合句子之间的注意力模式来识别“广播”句子；还有一种是因果归因方法，通过抑制对某个句子的关注来测量其对后续句子的影响。这些方法提供了对思考锚点存在的证据，并提供了可视化的分析工具。
## Conclusion
由于这些方法在结果上的一致性，证明了句子级别的分析对未来更深入理解推理模型的潜力。
# 202. `cs.CL` - 利用AI评分技术进行缺失分数填充以实现基于构造反应试题的能力评估的准确估计 [PDF](https://arxiv.org/pdf/2506.20119), [HTML](https://arxiv.org/abs/2506.20119)
## Authors
Masaki Uto,Yuma Ito
## Background
评价学习者的能力是教育领域的一个基本目标，尤其是评估表达能力和逻辑思维等更高层次的能力。传统的构造反应测试（如简答和论文题）尽管有效，但需要大量的手动评分，从而耗费人力和财力。项目反应理论（IRT）能够通过估计能力从不完整的评分数据中获益，其中人工评分员只需对多个试题项目的学生作答子集进行评分。然而，随着缺失分数比例的增加，能力估计的准确性会下降。尽管已探索了通过数据扩充技术对缺失分数进行填充的方法来解决这一问题，但这些方法通常在稀疏或异质数据下表现不佳。因此，研究提议了一种新方法，利用自动评分技术进行缺失分数填充，以实现基于IRT的能力准确估计。该方法提高了能力估计的准确性，显著减少了手动评分的工作量。
## Innovation
提出了一种新的方法，利用自动评分技术进行缺失分数填充，以实现基于IRT的能力准确估计，这种方法提高了能力估计的准确性，显著减少了手动评分的工作量，克服了传统方法在处理稀疏或异质数据时的准确性问题。
## Conclusion
该研究提出的方法在能力估计准确性方面取得了高精度，并显著减少了人工评分的工作量，利用AI评分技术进行缺失分数填充，为基于构造反应测试的能力评估提供了一种有效的解决方案。
# 203. `cs.CL` - 通过自动编码器视角弥合组合语义与分布语义：嵌入式语义几何综述 [PDF](https://arxiv.org/pdf/2506.20083), [HTML](https://arxiv.org/abs/2506.20083)
## Authors
Yingji Zhang,Danilo S. Carvalho,André Freitas
## Background
目前的分布语义空间可以通过集成组合性和符号性特征来提升变换器基础自回归语言模型的可解释性、可控性、组合性和泛化能力。文章从嵌入式空间几何的角度出发，通过组合语义的研究方向，提供了一个新颖的视角，旨在弥合符号性语义和分布性语义之间的鸿沟。文章同时回顾了三种主流的自动编码器架构：变分自动编码器（VAE）、向量量化变分自动编码器（VQVAE）和稀疏自动编码器（SAE），并分析了这些方法在语义结构和可解释性方面的独特潜空间几何特性。
## Innovation
文章提出了从组合语义的角度审视潜空间几何的新视角，并且对比了三种主流的自动编码器架构，探讨了这些架构如何影响语义结构和可解释性，进而为连接符号性语义和分布性语义提供了一个新方向，有助于弥合两者之间的差距。
## Conclusion
本文通过自动编码器的方法对潜空间几何进行了综述，讨论了如何通过组合语义学习来增强语言模型的各种能力，指出了未来研究的方向，为深度学习语言模型的语义表达提供了新的可能性。
# 204. `cs.CL` - AALC: 大型语言模型高效推理通过自适应准确度-长度控制 [PDF](https://arxiv.org/pdf/2506.20160), [HTML](https://arxiv.org/abs/2506.20160)
## Authors
Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du
## Background
大型推理模型（LRMs）通过生成长链推理表现出出色的推理能力，但这会导致高延迟和高成本，而几乎没有相应的准确性提升。因此，本研究旨在找到一种方法，既可以保持或提高准确性，同时又能减少推理模型的响应长度，从而实现高效的推理。
## Innovation
本研究提出了一种名为AALC（Adaptive Accuracy-Length Control，自适应准确度-长度控制）的轻量级方法。AALC通过将验证精度集成到奖励中，并采用平滑、动态调度的长度惩罚，可以在达到目标性能后再对长度进行惩罚。这种方法减少了响应长度，同时保持甚至提高了原有的准确性，还能消除冗余的推理模式，从而生成更加结构化的输出。
## Conclusion
通过广泛的实验，AALC方法在标准和小样本数学基准测试中表明，可以将响应长度减少超过50%，同时保持或提高准确性。此外，定性分析揭示了冗余推理模式的减少，如过度设置子目标和验证，这导致了结构化的输出。然而，效率的提高也伴随着可解释性的降低，模型中省略了部分叙述框架和解释性背景信息。这些结果展示了基于奖励策略在引导大型语言模型朝着更有效、更通用的推理路径发展的潜力。
# 205. `cs.CL` - 在大规模语言模型中改进对话情绪识别的上下文学习中如何检索示例？ [PDF](https://arxiv.org/pdf/2506.20199), [HTML](https://arxiv.org/abs/2506.20199)
## Authors
Mengqi Wang,Tiantian Feng,Shrikanth Narayanan
## Background
大规模语言模型（LLMs）已经在多个领域实现了广泛的实际应用，但要创建高精度的应用程序尤其是像情绪识别这样的主观任务，仍然具有挑战性。因此，通过SLT 2024 GenSER挑战的启发，本研究探讨如何通过上下文学习（ICL）提高对话情绪识别（CER）的性能，特别是关注如何检索高质量的示例来增强对话情绪识别的准确性。
## Innovation
本研究提出了基于随机和增强的示例检索策略来提高对话情绪识别，并分析了对话上下文对情绪识别准确性的影响。研究还在IEMOCAP、MELD和EmoryNLP三个数据集中进行了实验。实验结果显示，增强的示例检索方法在所有数据集中都优于其他技术，突显了检索一致性和相关性示例并通过重述方式增强其重要性。
## Conclusion
研究表明，增强的示例检索方法在所有数据集中都优于其他技术，表明在大规模语言模型的上下文学习中检索和增强相关、一致的示例是提高对话情绪识别准确性的关键。
# 206. `cs.CL` - 通过结构化推理增强大型语言模型 [PDF](https://arxiv.org/pdf/2506.20241), [HTML](https://arxiv.org/abs/2506.20241)
## Authors
Yubo Dong,Hehe Fan
## Background
最近的大规模语言模型（LLMs）显著推动了自然语言处理和自动化决策，但在处理涉及逻辑推理和系统性规划的复杂任务时仍面临挑战，主要因为它们依赖于未结构化的统计关系而非明确的知识结构。通过认知科学和神经符号AI，我们提出了一种增强LLMs的新方法，通过显式结构化推理。具体而言，我们首先通过显式标注推理步骤将非结构化数据转换为结构化格式，然后利用监督微调（SFT）方法训练LLMs。此外，我们通过Group Relative Policy Optimization（GRPO），融合了两种创新算法——最大流（MAX-Flow）和最长公共子序列（LCS），以提升LLMs的结构化推理能力。这些改进显著提高了推理效果并降低了计算复杂性。实验表明，这种方法可以在不同的场景中实现简洁推理和稳健性能，并与优化技术兼容，验证了结构化推理在LLMs中的有效性整合。
## Innovation
我们提出了一种通过显式结构化推理增强LLMs的新方法。具体包括：1）通过显式标注将非结构化数据转换为结构化格式；2）使用监督微调（SFT）方法训练LLMs；3）融合最大流（MAX-Flow）和最长公共子序列（LCS）算法，通过Group Relative Policy Optimization（GRPO）提升LLMs的结构化推理能力。
## Conclusion
通过显式结构化推理的方法，可以显著提升LLMs在处理复杂任务上的表现，实现简洁有效的推理，并增强其与优化技术的兼容性，验证了结构化推理在LLMs中的有效性。
# 207. `cs.CL` - 基于动态主题模型和大规模语言模型的叙事变化检测 [PDF](https://arxiv.org/pdf/2506.20269), [HTML](https://arxiv.org/abs/2506.20269)
## Authors
Kai-Robin Lange,Tobias Schmidt,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch
## Background
在媒体叙述快速演变的背景下，已不仅需从给定语料中提取叙述，还需探究叙述随时间的发展变化。尽管大型语言模型在捕获叙述元素及复杂结构方面表现出色，但应用于整个语料库时面临着高昂的成本问题。因此，本文旨在利用大型语言模型的语言理解能力与主题模型的广泛应用性，结合叙事政策框架，动态建模随时间变化的叙述转变。
## Innovation
本文提出了一种将大型语言模型与主题模型相结合的方法，通过动态主题模型和变化点检测方法找到了特定主题的变化点，筛选出代表性文档，输入大型语言模型以自动化地解释变化并区分内容和叙述变化。这种方法在《华尔街日报》2009年至2023年的新闻文章语料库中得到了应用。研究结果显示，大型语言模型能够高效地根据给定时间点是否发生了叙述转变进行提取，但在判断是内容变化还是叙述变化时表现不佳。
## Conclusion
本研究通过结合动态主题模型和大型语言模型成功地检测了叙述变化，但进一步指出大型语言模型在区分内容变化和叙述变化能力上有待提高。
# 208. `cs.CL` - SEED: 一种用于时序预测的嵌入驱动解码结构编码器 [PDF](https://arxiv.org/pdf/2506.20167), [HTML](https://arxiv.org/abs/2506.20167)
## Authors
Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma
## Background
多变量时间序列预测需要模型同时捕捉特征间的结构依赖关系并跨任务进行泛化。尽管结构编码器能够有效建模特征交互，但缺乏处理语义推理或任务适应的能力。相比之下，大型语言模型（LLMs）虽然具有强大的泛化能力，但不适用于直接处理原始时间序列输入。这些局限性限制了统一、可转移预测系统的开发。因此，本文介绍了一种结构编码器SEED，用于嵌入驱动的解码，旨在解决结构-语义建模差距的问题。
## Innovation
SEED 结构编码器通过对齐的模块化架构，将 token 意识编码器、投影模块、语义再编程机制和冻结的语言模型集成在一起，实现了从数值模式到语义推理的有效对齐，从而弥补了结构-语义建模的差距。实验结果表明，SEED 方法在多种基线之上取得了持续的改进，并且在各种数据集上的比较研究证实了SEED 在解决结构-语义建模差距问题中的重要性.
## Conclusion
实验结果表明，提出的 SEED 方法在多个强基线之上实现了持续的改进，并且在各种数据集上的对比研究证实了 SEED 在解决结构-语义建模差距方面的作用。
# 209. `cs.CL` - CBF-AFA: 基于分块的多SSL融合自动流畅性评估 [PDF](https://arxiv.org/pdf/2506.20243), [HTML](https://arxiv.org/abs/2506.20243)
## Authors
Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc
## Background
自动流畅性评估（AFA）仍然具有挑战性，特别是在捕捉非母语者说话的节奏、停顿和非流畅性方面。现有的方法难以准确分析这些特征，特别是因为不同人的发音和节奏可能有很大差异。因此，需要一种能够准确评估非母语者流畅性的方法。这种方法需要结合不同的模型优势，以提供更全面和准确的评估结果。通过利用分类检测技术来对语音进行分段并进行细粒度的时间分析，可以缓解过拟合和过多分割的缺点。
## Innovation
该研究提出了一种基于分块的方法，利用自监督学习（SSL）模型（如Wav2Vec2、HuBERT和WavLM），这些模型各自擅长音素、音调和噪声语音建模。通过一个分层的CNN-BiLSTM框架将语音分段为呼吸组块，这种方法能够在保护语义连贯性的同时进行高精度的局部和长期依赖捕获。通过可学习的加权机制融合SSL嵌入，平衡了声学特征和语言特征，并通过块级别流畅性标记（如语速、停顿时间、n-gram重复）进行了增强。这种分块多SSL融合方法在Avalinguo和Speechocean762数据集上的测试结果表明，与单一SSL基线相比，该方法在Speechocean762上提高了2.8个F1分数和6.2个皮尔逊相关度，在Avalinguo上提高了4.2个F1分数和4.0个皮尔逊相关度的得分，超越了基于分类分割的基线方法。
## Conclusion
该研究展示了一种基于分块的多SSL融合方法，对于稳健地评估非母语者的流畅性非常有效。实验结果表明，这种方法能够更好地捕捉非母语者说话的节奏、停顿和非流畅性。尽管这些方法已经显示出良好的性能，但是未来的工作可能需要进一步探索这些方法在具有不规则音调特征的方言中的通用性。
# 210. `cs.CL` - CCRSG：一种零样本LLM作为法官的全面RAG评估框架 [PDF](https://arxiv.org/pdf/2506.20128), [HTML](https://arxiv.org/abs/2506.20128)
## Authors
Aashiq Muhamed
## Background
RAG系统通过整合外部知识来增强LLM，这对需要事实准确性和最新信息的领域至关重要。然而，评价RAG输出的多维度质量，包括上下文连贯性、查询相关性、事实正确性和信息完整性等方面，存在显著挑战。现有评价方法通常依赖于简单的词汇重叠度量标准，这不足以捕捉这些细微差别，或者需要复杂的多阶段流水线，其中包括声明提取等中间步骤，或者需要微调特定的监督模型，这会妨碍其实用效率。
## Innovation
提出了一种创新的CCRSG（上下文连贯性和相关性评分）框架，这是一种单个强大预训练LLM作为零样本、端到端评分员的新颖多指标方法。该框架评价RAG输出的上下文连贯性、问题相关性、信息密度、答案正确性和信息回忆度，与复杂RAGChecker框架相比，CCRSG在关键方面如召回率和忠实性方面提供了可比或更优的区分力，同时具有显著更高的计算效率。
## Conclusion
CCRSG提供了一种实用、全面且高效的评估和迭代改进RAG系统的框架。通过在挑战性的BioASQ数据集上评估六种不同的RAG系统配置，我们的分析证实了多种系统性能的不同，例如确认了Mistral-7B阅读器优于Llama变体。此外，我们详细分析了CCRSG指标属性，包括分数分布、收敛性/区分性效度、平局率、总体统计信息和区分力。
# 211. `cs.CL` - Biomed-Enriched: 通过大规模语言模型增强的生物医学数据集，用于预训练和提取稀有和隐藏内容 [PDF](https://arxiv.org/pdf/2506.20331), [HTML](https://arxiv.org/abs/2506.20331)
## Authors
Rian Touchent,Nathan Godey,Eric de la Clergerie
## Background
医学和临床文献中常用的临床案例文本通常难以获取，因为受限于隐私保护，医院记录无法公开分享。因此，本文提出了一种基于PubMed的生物医学文本数据集——Biomed-Enriched，该数据集通过两阶段注释过程构建，旨在提供一个开放获取的临床案例资源，用于生物医学及临床自然语言处理（NLP）的研究。
## Innovation
利用大规模语言模型为PubMed中的40万段科学文章进行注释，生成包括类型、领域和教育质量的元数据，并通过这些元数据进一步精选出高质量的临床案例文本。这种方法不仅保证了数据的质量和适用性，还创造出多个高质量子集，并通过质量筛选和领域过采样取得了显著的性能提升，如医疗相关过采样提升了大约5%的MMLU ProfMed性能，教育质量过滤提高了MedQA和MedMCQA约1%的性能。
## Conclusion
本文提出的Biomed-Enriched数据集通过注释和元数据筛选，提供了一种有效的预训练策略，使得在保持竞争力的同时减少了训练资源的消耗。该数据集的多样性和高质量特征使其成为生物医学和临床NLP研究中重要的资源。
# 212. `cs.CL` - 捷克语语句嵌入的内在与外在评估：语义相关性不一定有助于机器翻译评价 [PDF](https://arxiv.org/pdf/2506.20203), [HTML](https://arxiv.org/abs/2506.20203)
## Authors
Petra Barančíková,Ondřej Bojar
## Background
本文比较了针对捷克语的特定模型和多语言嵌入模型，通过内在评估和外在评估两个维度进行分析。内在评估使用Costra复杂句子转换数据集和语义文本相似度（STS）基准测试来评估模型捕捉语义相似性、时间特征和风格变体的能力。外在评估则通过使用COMET评估机器翻译，对每个嵌入模型进行微调。
## Innovation
本文的创新之处在于揭示了一种有趣的不一致性：在内在语义相似性测试中表现优异的模型，在下游机器翻译任务中的表现并不始终更优。相反，通过微调，那些看似过度平滑的嵌入空间的模型可以获得更好的结果。这些发现强调了语义特性探针和下游任务复杂关系之间的复杂性，呼吁更多研究关于嵌入语义的操作性及其复杂下游任务数据集的重要性.
## Conclusion
实验结果表明，内在语义相似性测试中的优异表现并不总能转化到机器翻译等下游任务中。过度平滑的嵌入空间通过微调可能取得更好的结果。因此，研究焦点应转向可操作的意义以及更深入的数据集以适应下游任务。
# 213. `cs.CL` - TAPS: 工具增强的个性化利用结构化标签 [PDF](https://arxiv.org/pdf/2506.20409), [HTML](https://arxiv.org/abs/2506.20409)
## Authors
Ekaterina Taktasheva,Jeff Dalton
## Background
近年来，增强型大型语言模型能够与外部工具进行交互，提高了它们完成复杂用户任务的能力。然而，当前的方法忽视了个性化工具使用在引导工具应用中的作用。这项工作探讨了如何有效将用户偏好集成到以目标为导向的对话代理中。通过深入分析，我们发现大型语言模型在个性化工具使用方面存在关键性缺陷。为此，我们提出了一种名为TAPS的新颖解决方案，通过利用结构化标签工具和基于不确定性工具检测器来增强个性化工具使用的功能。TAPS显著提高了大型语言模型将用户偏好融入其工作的能力，实现了开源模型在NLSI任务上的最新水平。
## Innovation
我们介绍了一种名为TAPS的新型解决方案，通过利用结构化标签工具和基于不确定性工具检测器来增强个性化工具使用的功能。TAPS显著提高了大型语言模型的个性化能力，并且在开源模型在NLSI任务上的表现达到了最新水平。
## Conclusion
我们的研究揭示了大型语言模型在个性化工具使用方面存在的缺陷，并提出了有效的解决方案。通过TAPS，我们展示了如何更好地将用户偏好融入到大型语言模型的工作中，实现了在NLSI任务上新的技术水平。
# 214. `cs.CL` - 视角在行动：一种更为包容的NLP系统多视角方法 [PDF](https://arxiv.org/pdf/2506.20209), [HTML](https://arxiv.org/abs/2506.20209)
## Authors
Benedetta Muscato,Lucia Passaro,Gizem Gezici,Fosca Giannotti
## Background
在自然语言处理（NLP）领域，处理人类分歧的常见方法是汇总注释者的观点以确定单一的地面真实值。然而，先前的研究表明，忽略个体的观点可能导致少数派观点的代表性不足，特别是在主观任务中，注释者可能会因为个人偏好而系统性地产生分歧。鉴于标签反映了个体的背景、生活经验和价值观，本研究提出了一种使用软标签的新型多视角方法，以促进下一代有视角意识模型的发展，使其更具包容性和多元性。研究在包括仇恨言论、讽刺、不礼貌语言和立场检测等多样化的主观文本分类任务中进行了广泛分析，强调了捕捉人类分歧的重要性，而这些分歧往往被传统汇总方法忽视。实验结果表明，该多视角方法不仅可以更好地逼近人类标签的分布（通过JSD度量），还可以获得更优的分类性能（更高的F1分数），优于传统方法。但是，在讽刺和立场检测任务中，我们的方法表现出了较低的置信度，这可能是因为这些文本中固有的主观性。最后，研究还利用可解释的人工智能（XAI）探索了模型不确定性，并揭示了模型预测的重要见解。
## Innovation
提出了一种使用软标签的新型多视角方法，以捕捉人类分歧，促进下一代有视角意识模型的发展，使其更具包容性和多元性。该方法不仅能够更好地逼近人类标签的分布（通过JSD度量），并且在分类性能上也优于传统方法。
## Conclusion
研究结果表明，多视角方法可以更好地逼近人类标签的分布，并在分类任务中实现更好的性能，特别是在主观文本分类任务中。然而，该方法在像讽刺和立场检测等任务中可能表现出较低的置信度。此外，通过可解释的人工智能技术，研究揭示了模型预测的重要信息和不确定性。
# 215. `cs.CL` - COIN：带有可证风险保证的不确定性防护选择性问答方法 [PDF](https://arxiv.org/pdf/2506.20178), [HTML](https://arxiv.org/abs/2506.20178)
## Authors
Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu
## Background
基础模型生成的文本可能会出现幻觉，不确定性量化（UQ）对于识别和减轻这些潜在错误至关重要。现有的启发式UQ方法缺乏对关键指标，如选择性预测的错误发现率（FDR）的正式保证。之前的工作利用split conformal预测（SCP）框架，通过构建预测集来确保可接受答案的覆盖，但是这些集通常包含错误候选项，限制了它们的实际应用价值。
## Innovation
本文提出COIN（不确定性防护选择框架），它通过在用户指定的FDR约束下校准统计有效的阈值来过滤单个生成的答案。COIN利用校准集估计经验错误率，并应用Clopper-Pearson等置信区间方法，以高概率上限估计真实错误率（即FDR）。这种方法允许在测试数据上控制FDR的同时，显著增加样本保留率。这项工作在风险控制的稳健性、保留可接受答案的强测试时间和预测效率方面展示了COIN的优势，尤其是在有限校准数据下对通用和多模态文本生成任务表现良好。此外，使用替代的上限构建和UQ策略可以进一步增强COIN的性能，这体现了其在多种应用情景中的扩展性和适应性。
## Conclusion
COIN在控制风险、在保留可接受答案时具有较强的测试时能力，并且在有限校准数据下对产生效率的有效性进行了证明。该方法在通用和多模态文本生成任务中的表现良好。此外，利用不同的上限构建和UQ策略可以进一步提升COIN的性能，这表明该方法具有很高的灵活性和适应性，能够适用于不同的应用场景。
# 216. `cs.CL` - GPTailor：通过层裁剪和缝合进行大规模语言模型剪枝 [PDF](https://arxiv.org/pdf/2506.20480), [HTML](https://arxiv.org/abs/2506.20480)
## Authors
Guinan Su,Li Shen,Lu Yin,Shiwei Liu,Yanwu Yang,Jonas Geiping
## Background
大型语言模型（LLMs）展现了卓越的语言理解和生成能力。然而，这些令人印象深刻的能力通常伴随着巨大的模型规模，这挑战了部署和推理的实施。虽然结构化剪枝模型参数被认为是在部署时降低计算成本的有前景方法，但现有方法主要集中在单个模型的剪枝上。针对这一问题，本文提出了一种新的策略，通过在细调模型变体之间战略性地合并或合并层来压缩模型，从而保持原始模型的能力并综合不同细调中的突出能力。这种方法将这些LLMs的最佳调整视为零阶优化问题，采用了支持三种操作的搜索空间：（1）层删除，（2）从不同候选模型中选择层，（3）层合并。实验表明，这种方法在如Llama2-13B模型家族中，压缩后的模型保持了约97.3%的原始性能，同时移除了约25%的参数，显著优于以往最先进的方法。
## Innovation
本文提出了一种新的策略，通过在细调模型变体之间战略性地合并或合并层来压缩模型，这种方法将这些LLM的最佳调整视为零阶优化问题，采用了支持三种操作（层删除、从不同候选模型中选择层、层合并）的搜索空间。实验表明，这种方法显著优于以往最先进的方法，保持了较高的性能同时大幅减少了参数数量。
## Conclusion
本文通过细调模型变体之间的层合并和选择策略，提出了一种有效的模型压缩方法，并通过实验验证了其优越性。压缩后的模型在保持较高性能的同时，参数量大幅减少，显著优于现有最佳方法。
# 217. `cs.CL` - 跨源问答中的知识意识多样化重排序 [PDF](https://arxiv.org/pdf/2506.20476), [HTML](https://arxiv.org/abs/2506.20476)
## Authors
Tong Zhou
## Background
SIGIR 2025 LiveRAG竞赛的数据由DataMorgana自动从互联网语料库生成，涵盖了广泛的领域主题、问题类型、问题表述、受众类型和知识组织方法。竞赛旨在公平地评估从精细网络语料库的1500万文档子集中检索相关支持文档的能力。Team Marikarp提出了一个知识意识多样化重排序的RAG流水线，从而取得竞赛的第一名。
## Innovation
提出了一种知识意识多样化重排序的RAG流水线，显著提高了跨源问答系统的性能，使其能够在大型语料库中更有效地检索和组织相关信息，从而提升整体问答质量。
## Conclusion
所提出的流水线在SIGIR 2025 LiveRAG竞赛中排名第一，证明了其在复杂和多样化的问答场景下的有效性和竞争力。
# 218. `cs.CL` - 在多元语言大语言模型中增多推理计算量的好处：当生活给你样本时 [PDF](https://arxiv.org/pdf/2506.20544), [HTML](https://arxiv.org/abs/2506.20544)
## Authors
Ammar Khairi,Daniel D'souza,Ye Shen,Julia Kreutzer,Sara Hooker
## Background
最近，在大语言模型（LLMs）方面的进步促使研究重点转向在推理阶段扩展计算资源，以提高性能而不重新训练模型。现有方法通常并行采样多个输出，并从中选择一个作为最终输出，但目前的工作主要集中在英语和少数领域如数学和代码。相比之下，这项研究关注的是能够泛化到开放型任务、形式验证任务、以及多语言环境的技术。研究探索了如何在多语言多任务的背景下稳健地扩展推理时的计算资源，特别是在开放生成任务方面。研究发现，采样策略和选择策略都需要根据不同的领域和语言环境进行调整。现有的选择方法在英语上有效，但在多种语言中并不通用，研究提出了专门为多语言和多任务推理场景定制的新的采样和选择策略，这些策略在多种语言和任务上都取得了显著的成果。
## Innovation
本文提出了专门为多语言和多任务推理场景定制的新采样和选择策略。这些策略在多种语言和任务上都取得了显著的成果。特别是在8B模型上，结合采样和选择方法使m-ArenaHard-v2.0提示的获胜率平均提高了6.8%。对于更大的Command-A（111B模型），仅通过五次采样相比单次解码就实现了9.0%的显著改进。研究强调了针对不同语言和任务的推理计算资源的重要性，以促进包括未充分代表语言在内的性能改进的普及化。
## Conclusion
研究结果强调了在多元语言环境中需要使用语言-任务感知的推理计算方法，以推动对未充分代表语言的性能改进。这些新的采样和选择策略在不同的语言和任务上都取得了显著的提升效果。
# 219. `cs.CL` - 时间在我这边：视频聊天对话中发言时间分享的动力学 [PDF](https://arxiv.org/pdf/2506.20474), [HTML](https://arxiv.org/abs/2506.20474)
## Authors
Kaixiang Zhang,Justine Zhang,Cristian Danescu-Niculescu-Mizil
## Background
每一场交谈都有一个分享发言时间的方式。这种分享可以是平衡的，每个发言人都分配到相同的时间；也可以是不均衡的，其中一个人发言时间远超别人。这种总体分布是讲话者继续协商的结果：在交谈的每一个时刻，谁应该发言，以及他们应该讲多久？本文介绍了一个计算框架，用于量化发言时间在发言者之间的总体分布，以及导致这种分布的较低层级动态。通过应用此框架到大量陌生人之间的视频聊天数据集，我们发现平衡的交谈更受人们欢迎，特别是那些发言较少的人。我们还揭示了，尽管这些动态导致同样的总体平衡，但参与者对它们的感受不同，突出了我们新引入类型的相关性。最后，我们讨论了该框架为计算机介导通信平台设计师提供了新的工具，涵盖人类之间和人类与人工智能之间的沟通。
## Innovation
本文提出了一个计算框架，用于量化发言时间在不同发言者之间的总体分布以及导致这种分布的低级动态。该框架揭示了不同类型的话语分享动态即使在总体平衡相同时，也会导致参与者体验上的不同。这为计算机介导的通信平台设计提供了新的工具。
## Conclusion
研究确认了平衡的交谈更受人们喜爱，尤其是那些发言较少的人。虽然相同水平的总体平衡可能导致不同的话语分享动态，但这些动态对参与者的感觉也不同。该框架为计算通信平台设计提供了新工具，可以帮助理解人类和人类与人工智能之间的沟通。
# 220. `cs.CL` - OctoThinker: 中途训练促进强化学习扩展 [PDF](https://arxiv.org/pdf/2506.20512), [HTML](https://arxiv.org/abs/2506.20512)
## Authors
Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu
## Background
不同基础语言模型家族，如Llama和Qwen，在强化学习（RL）后训练过程中表现出不同的行为，尤其是在需要大量推理的任务上。深入理解哪种基础语言模型适合强化学习对于开发下一代可扩展的RL基础模型至关重要。本研究关注中途训练策略如何影响强化学习动力学，重点是Qwen和Llama两种模型家族。研究发现高质量的数学语料库可以显著提高基础模型和强化学习性能，而现有替代方案则不然；增加类似于问答的数据，特别是长链推理示例，可以进一步提升强化学习效果，而指令数据能进一步增强这一效果；虽然长链推理可以提升推理深度，但也会导致模型回答过于冗长和强化学习训练的不稳定性；中途训练扩大规模能持续增强后续强化学习性能。
## Innovation
提出了一个两阶段中途训练策略——稳定-衰减（Stable-then-Decay），该策略首先在200B tokens上以恒定的学习率训练基础模型，然后在三个专注于链式推理的分支上逐渐降低学习率训练20B tokens。这种策略产生了OctoThinker这一家族模型，展示了强大的RL兼容性，并且在性能上与更加RL友好的模型家族（如Qwen）缩小了差距。同时，还公开了一个包含超过70亿个token的精选数学推理密集语料库（MegaMath-Web-Pro-Max）供进一步研究使用。
## Conclusion
这项工作希望有助于塑造在RL时代基础模型的预训练策略，并通过公开源代码模型和语料库支持进一步研究。
# 221. `cs.CL` - 具有可追溯推理能力的罕见疾病诊断代理系统 [PDF](https://arxiv.org/pdf/2506.20430), [HTML](https://arxiv.org/abs/2506.20430)
## Authors
Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie
## Background
全球有超过3亿人受到罕见疾病的影响，但及时准确的诊断仍然面临挑战。这主要是由于罕见疾病的临床异质性、低个体发病率以及大多数临床医生对罕见条件的不熟悉。鉴于此，研究团队引入了DeepRare，这是首个利用大规模语言模型（LLM）驱动的罕见疾病诊断代理系统，能够处理各种临床输入并生成排名靠前的诊断假设，每个假设都附带透明的推理链，将中间分析步骤与可验证的医学证据联系起来。系统由中央主机、长期记忆模块和专门负责特定领域分析任务的代理服务器组成，确保了对最新临床信息的访问。该模块化且可扩展的设计允许复杂的诊断推理，同时保持了可追溯性和适应性。通过八个数据集评估DeepRare，系统在2,919种疾病中表现出卓越的诊断性能，对1,013种疾病实现了100%的准确率，在基于HPO的评估中，DeepRare大幅优于其他15种方法，包括传统的生物信息学诊断工具、大规模语言模型和其他代理系统，达到了57.18%的平均Recall@1得分，并在这一项上比第二好的方法（推理语言模型）高出23.79个百分点；在多模态输入场景中，DeepRare在109个案例中的Recall@1得分为70.60%，而Exomiser为53.20%，临床专家手动验证推理链的结果达到了95.40%的一致性。此外，该系统已被开发为用户友好的网络应用平台。
## Innovation
DeepRare是首个利用大规模语言模型驱动的罕见疾病诊断代理系统，能够处理各种临床输入并生成排名靠前的诊断假设，每个假设都附带透明的推理链，将中间分析步骤与可验证的医学证据联系起来。该系统具有强大的诊断性能，特别是在基于HPO和多模态输入场景的评估中，显著优于其他各种方法。DeepRare的可追溯设计为诊断过程提供了更高的透明度和可靠性。
## Conclusion
DeepRare展示了卓越的诊断性能，并且在多种评估环境中大幅领先于其他方法。该系统不仅提高了罕见疾病诊断的准确性和效率，而且还确保了诊断过程的可追溯性和透明度，为临床决策提供了有力支持。DeepRare系统已被实现为用户友好的网络应用平台。
# 222. `cs.CL` - 使用源代码探测AI安全 [PDF](https://arxiv.org/pdf/2506.20471), [HTML](https://arxiv.org/abs/2506.20471)
## Authors
Ujwal Narayan,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Karthik Narasimhan,Ameet Deshpande,Vishvak Murahari
## Background
大型语言模型已经广泛应用于众多关键安全领域，需要提高它们的能力，同时也需要加强安全措施，使这些模型能够更好地符合人类的价值观和偏好。然而，当前的模型在实现AI安全目标方面存在严重不足，可能导致用户不安全和有害的体验。因此，需要设计新的方法来评估语言模型的安全性。
## Innovation
本文提出了一种新的提示策略——Code of Thought (CoDoT)，该策略将自然语言输入转换为简单的代码表示，以评估语言模型的安全性。CoDoT通过将自然语言指令转换为代码指令，发现了一种能在多种现代表态领先的大语言模型上导致安全失败的方法。此外，递归应用CoDoT还能进一步增加模型的毒性。这种方法强调了从零开始评估安全性的重要性，以确保安全性和能力同步发展。
## Conclusion
鉴于大语言模型的快速普及，CoDoT表明从基础原理出发评估安全性的必要性，确保安全和能力同时提升。
# 223. `cs.CL` - 机器学习会议应设立'反驳与评论'赛道 [PDF](https://arxiv.org/pdf/2506.19882), [HTML](https://arxiv.org/abs/2506.19882)
## Authors
Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho
## Background
科学通过迭代地推动和纠正人类对世界的理解而进步。在机器学习（ML）研究中，快速的进步导致了大量出版物的激增，但也由于同行评审的局限性，导致了错误、误导、不准确、甚至可能虚假的研究被接受并在ML会议上被突出展示。虽然这些错误是可以理解的，但ML会议没有提供有效的机制帮助该领域在发现此类错误时进行系统纠正。
## Innovation
该立场文章提出了在ML会议中设立一个专门的“反驳与评论”（R&C）赛道。这个赛道将提供一个高规格、有声望的平台，支持对先前研究进行批判性挑战的研究，从而促进动态自我纠正的研究生态系统。此外，文章讨论了赛道设计、评审原则及潜在陷阱，并提供了对ICLR 2025 Oral的示范性示例提交。
## Conclusion
ML会议应创建正式、有声望的机制，以帮助ML研究自我纠正。
# 224. `cs.CL` - Memento: 为你未来的自己作笔记 [PDF](https://arxiv.org/pdf/2506.20642), [HTML](https://arxiv.org/abs/2506.20642)
## Authors
Chao Wan,Albert Gong,Mihir Mishra,Carl-Leander Henneking,Claas Beger,Kilian Q. Weinberger
## Background
大语言模型（LLMs）在推理任务上表现出色，但在需要严密结合检索与推理的多跳问答任务中却遇到挑战。目前的提示策略在解决这类问题时表现通常不佳，特别是在所有相关信息并非直接给出而是需要逐步检索和推理的情况下，其性能会大大降低。为了克服这些限制，研究提出了一种名为Memento的三阶段提示策略，该策略首先将复杂问题分解为较小的步骤，然后利用LLMs动态构建事实数据库，最后将这些事实结合起来解决问题，从而提升现有提示策略在不同场景中的性能表现。
## Innovation
Memento引入了一种新颖的三阶段提示策略，它将复杂问题分解为较小的步骤，动态构建事实数据库，并将这些事实拼接起来以解决复杂问题。研究表明，这种方法在多种基准测试中显著提升了现有的提示策略的性能。研究还在多个基准数据集上的实验中展示了Memento的有效性，特别是在多步推理与知识获取需求较高的任务中，增强了给定上下文时chain-of-thought（CoT）方法的性能，提高了CoT-RAG、ReAct等方法的F1分数。
## Conclusion
Memento提示策略通过将复杂问题精细化处理，动态构建知识库并结合推理，不仅显著提升了现有的提示策略的性能，也展示了其在解决多步推理和知识获取需求较高的任务中的实用性。研究结果表明，Memento对于促进复杂问题的解决具有重要作用，尤其在需要结合推理和检索能力的场景中更为重要。
# 225. `cs.CL` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大型语言模型（LLMs）在代码生成方面表现出色，但在面对外部库API的频繁更新时，却难以适应。这一关键限制源于模型依赖训练数据中的过时API知识，即使使用当前文档也难以解决该问题。这在动态环境中影响了代码生成的可靠性。
## Innovation
我们提出了一种名为ReCode的新框架，通过规则化的强化学习方法模仿人类程序员在API变更时的适应策略。ReCode构建了一个约2000个数据条目的数据集，用于训练LLM进行基于更新信息的版本迁移。此外，引入了一种修改后的字符串相似度度量作为强化学习的奖励。实验结果表明，与监督微调相比，ReCode对LLMs的一般代码生成能力影响较小，且在多种LLM和强化学习算法（GRPO和DAPO）上均显示出一致的改进效果。
## Conclusion
ReCode在动态API场景下的代码生成性能显著提升，尤其在未见过的任务CodeUpdateArena上。经过训练后，Qwen2.5-Coder-7B超越了参数为32B的代码指令微调模型和架构相同的推理模型。相关代码已开源。
# 226. `cs.CL` - 模型编辑是一把双刃剑：引导智能体道德行为向善或向恶 [PDF](https://arxiv.org/pdf/2506.20606), [HTML](https://arxiv.org/abs/2506.20606)
## Authors
Baixiang Huang,Zhen Tan,Haoran Wang,Zijie Liu,Dawei Li,Ali Payani,Huan Liu,Tianlong Chen,Kai Shu
## Background
基于大型语言模型(LLMs)的代理在广泛的任务中展现出了强大的能力，但在高风险领域部署这些代理会带来重大的安全和伦理风险。不道德的行为可能导致严重的现实后果，包括人身伤害和经济损失。为了有效地引导代理的不道德行为，我们将其定义为模型编辑任务，称为行为编辑。模型编辑是一个新兴的研究领域，允许对LLMs进行精细和高效的修改，同时保留其整体能力。我们提出了一个多层次的基准BehaviorBench，基于心理道德理论，以系统地研究和评估这一方法。BehaviorBench支持跨多种场景的代理行为评估和编辑，每一层都引入了更复杂和模棱两可的情景。我们展示了行为编辑可以在特定场景中动态地引导代理向目标行为转变，这种编辑不仅允许针对特定场景进行局部调整，还可以促进整体道德对齐的更大程度的转变。行为编辑可以用来促进道德和仁慈的行为，也可以引发有害或恶意的行为。
## Innovation
提出了一个多层次的基准BehaviorBench，基于心理道德理论，以系统地研究和评估模型编辑（即行为编辑）。模型编辑支持跨多种场景的代理行为评估和编辑，每一层都引入了更复杂和模棱两可的情景。通过这种创新，研究展示了行为编辑的广泛适用性和有效性，可以促进或诱导代理的道德行为
## Conclusion
研究表明，行为编辑是引导代理行为的关键新范式，既展示了其潜力也揭示了潜在风险。通过在前沿的LLMs上进行全面评估，BehaviorBench证明了行为编辑在不同模型和场景中的有效性。研究结果为未来的智能体行为引导提供了关键见解，强调了行为编辑的两面性。
# 227. `cs.CL` - 机器人在检测其错误方面为何不佳：人类-机器人对话中误通信检测的局限性 [PDF](https://arxiv.org/pdf/2506.20268), [HTML](https://arxiv.org/abs/2506.20268)
## Authors
Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme
## Background
在人类与机器人交互中，检测误通信是一项关键功能，用于维持用户的参与度和信任。尽管人类能够通过语音和非言语线索轻松检测对话中的沟通错误，但机器人在解释非言语反馈方面面临巨大挑战。尽管计算机视觉技术有所进步，能够识别情感表达，但目前机器学习模型在检测机器人对话中的误通信方面的效果基本随机。在含有更多情感表达内容的数据集中，这些模型能够识别出机器人的困惑状态。人类评估者对机器人说话伙伴的表现也仅能识别大约一半的诱导误通信，这揭示了识别机器人在对话中的误通信存在基本局限性：即使用户感知到了诱导的误通信，他们也往往不会将其告知机器人对话伙伴。
## Innovation
该研究通过使用多模态数据集（包含240个人机对话），系统地引入四种不同的对话失败类型，来评估最先进的机器视觉模型在检测机器人对话中误通信方面的有效性。此外，研究发现即使是人类评估者在识别诱导的误通信时也只能识别约一半的情况，揭示了模型和人类在识别机器人误通信方面的相似局限性。这项工作强调了计算机视觉模型在识别机器人误通信方面的基本局限性，为理解误通信检测的挑战提供了新的视角，同时可能有助于研究人员更好地设计人类-机器人对话，以更好地引导用户的反馈。
## Conclusion
研究发现，即使用户感知到诱导的误通信，他们往往会不告知机器人，这揭示了识别机器人误通信的基本局限性。这项研究的结果可以帮助设定对计算机视觉模型性能的合理期望，并有助于研究人员通过积极地促成必要的反馈，来设计更好的人类-机器人对话。
# 228. `cs.CL` - 选定人物的大语言模型表现出类似人类的动机性推理 [PDF](https://arxiv.org/pdf/2506.20020), [HTML](https://arxiv.org/abs/2506.20020)
## Authors
Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan
## Background
人类的推理容易受到身份保护等内在动机的影响，这会损害理性决策和判断。集体层次上的动机性推理在讨论人类驱动的气候变化、疫苗安全等关键议题时对社会有害，并加剧政治分歧。先前的研究表明，大语言模型（LLMs）也容易出现类似人类的认知偏见，但LLMs如何通过身份一致的结论进行有选择的推理尚不明确。此研究旨在探讨在4个政治和社会人口学属性上分配8种人物是否能使LLMs表现出动机性推理。
## Innovation
通过分配8种不同的人格，研究探讨了LLMs在两个基于人类实验推理任务中的表现：辨别虚假信息标题的真实性和评估数字科学证据。结果显示，分配了人格的LLMs在辨别虚假信息头衔上的准确性降低了9%，特别是在政治身份一致的情况下，政治人格在评估枪支控制的科学证据时正确的可能性提高了90%。基于提示的反偏见方法在缓解这些效应方面效果较差。这一实证研究首次表明，分配了人格的LLMs表现出类似人类的动机性推理，且难以通过常规反偏见提示解决，可能导致LLMs和人类中身份一致推理的加剧.
## Conclusion
选定人物的LLMs表现出类似人类的动机性推理，这使得常规的反偏见提示难以解决。这引发了关于在LLMs和人类中加剧身份一致性推理的关注。
# 229. `cs.CL` - 准确高效：本地检索增强生成模型在医疗任务中优于商用大型语言模型 [PDF](https://arxiv.org/pdf/2506.20009), [HTML](https://arxiv.org/abs/2506.20009)
## Authors
Konstantinos Vrettos,Michail E. Klontzas
## Background
人工智能（AI）在医疗领域的广泛应用引发了对其环境和伦理影响的日益关注。商用大型语言模型（LLMs），如ChatGPT和DeepSeek，需要大量资源支持，而这些模型在医疗领域的使用引发了对未来患者隐私和安全的重大关切。现有的商用大型语言模型在执行医疗任务时存在显著的能耗和环境影响问题，这对医疗系统的可持续发展提出了挑战。已有研究指出，与在线的商用大模型相比，本地的、基于检索增强生成（RAG）框架的模型可以在保持性能的同时，降低能耗和环境影响。本文旨在通过开发一个可定制的RAG框架来探讨这一问题。本研究评估了不同开源LLM构建的RAG模型，特别是在医疗任务中的表现和能耗，并将其与商用的DeepSeekV3-R1和OpenAIs的o4-mini模型进行了比较，结果表明，定制的RAG模型在准确性和能耗方面均优于商用模型。例如，基于llama3.1:8b构建的RAG模型在准确性和能耗方面明显优于其他模型，能耗最低，并且比o4-mini在每千瓦时的能量利用率上提高了2.7倍，在电力使用上降低了172%。该项研究呼吁利用可持续的本地LLM，开发具有更优性能和更低能耗的RAG模型，这对促进医疗系统的可持续发展意义重大，能够减少电力消耗并符合联合国可持续发展目标。
## Innovation
本文创新地发展了一种可定制的检索增强生成（RAG）框架，并基于各种开源大语言模型构建了相应的RAG模型，这些模型执行医疗任务时表现出更高的准确率和更低的能耗。此外，研究还发现，与在线的商用大模型相比，本地的RAG模型不仅能够保持更好的性能，而且显著降低了能源消耗和碳足迹，展示了在医疗领域中利用本地资源进行可持续化开发的可能性。这种方法对于促进医疗系统的绿色、可持续发展具有重要的理论和实践意义。通过这种方式，可以有效地减少医疗AI系统运行中的能耗和碳排放，从而帮助减轻全球的能源压力和环境负担。研究结果还表明，通过优化模型的能耗与性能之间的平衡，可以在健康医疗等关键领域实现更高效的计算和资源分配，这对于减轻算力需求的环境影响具有重要意义。
## Conclusion
研究证明，利用本地LLM构建的RAG模型在医疗任务中表现更优，同时对环境影响更小。本研究的模块化框架促进了可持续开发AI，减少了电力消耗，并符合联合国可持续发展目标。未来的研究可以进一步优化RAG模型的性能和能耗，以进一步改善其在医疗领域的实际应用效果。
# 230. `cs.CL` - PSALM-V：使用大型语言模型在交互式视觉环境中自动化符号规划 [PDF](https://arxiv.org/pdf/2506.20097), [HTML](https://arxiv.org/abs/2506.20097)
## Authors
Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason
## Background
以往的工作主要探索利用大型语言模型为基于规划领域定义语言(PDDL)的符号规划器生成动作语义。然而，这些方法大多集中在基于文本的领域上，或者依赖于不切实际的假设，如预定义的问题文件、完全可观测性或明确的错误消息。PSALM-V能够通过分析执行结果和合成可能的错误解释，动态推断PDDL问题文件和领域动作语义，从而能够在部分可观测的环境中更可靠地进行符号规划。
## Innovation
PSALM-V 是第一个能够在视觉环境中通过互动诱导符号动作语义（例如，先决条件和后置条件）的自主神经符号学习系统。它利用大型语言模型生成启发式计划和候选符号语义，从而无需专家定义的动作。系统通过迭代生成和执行计划，保持动作可能语义的树状信念，不断细化这些信念直至达到目标状态。PSALM-V 的这些创新方法在 ALFRED 中的任务完成模拟实验中提高了计划成功率，并在两个 2D 游戏环境中展示了其在多智能体设置中的领域归纳能力。
## Conclusion
PSALM-V 能够正确诱导真实机器人BlocksWorld任务的 PDDL 先决条件和后置条件，尽管机器人的低级操作失败。这种方法展示了在交互式视觉环境中利用大型语言模型进行自动化符号规划的潜力和优势。
# 231. `cs.CL` - DiffuCoder: 理解和改进掩蔽扩散模型在代码生成中的应用 [PDF](https://arxiv.org/pdf/2506.20639), [HTML](https://arxiv.org/abs/2506.20639)
## Authors
Shansan Gong,Ruixiang Zhang,Huangjie Zheng,Jiatao Gu,Navdeep Jaitly,Lingpeng Kong,Yizhe Zhang
## Background
扩散大型语言模型（dLLMs）因其在整个序列上进行去噪操作的特点，成为自回归（AR）模型的有吸引力的替代品。dLLMs的全局规划和迭代改进特性特别适用于代码生成。然而，当前dLLMs在编码中的训练和推理机制尚未得到充分探索。为了揭开dLLMs的解码行为并释放其在编码领域的潜力，研究人员系统地研究了其去噪过程和强化学习（RL）方法。训练了一个包含70亿参数的dLLM（DiffuCoder），在总计1300亿代码令牌上进行训练。研究发现，dLLMs能够决定其生成的因果性程度，并且采样温度的增加不仅多样化了令牌选择，还多样化了它们的生成顺序。这种多样性为RL过程提供了丰富的搜索空间。为了减少令牌对数似然估计的方差并保持训练效率，研究人员提出了一种新颖的采样方案——耦合的GRPO，该方案为训练中使用的完成部分构建互补的掩码噪声。实验结果表明，耦合的GRPO显著提高了DiffuCoder在代码生成基准上的性能，并减少了解码过程中的AR因果依赖性。
## Innovation
1. 提出了一种耦合的GRPO采样方法，通过构建互补的完成功能的掩码噪声来减少训练中的方差，提高了模型的训练效率。2. 研究发现dLLMs可以自由决定其生成的因果性程度，无需依赖半自回归解码方法。3. 提高采样温度不仅增加了令牌选择的多样性，还增加了生成顺序的多样性，这为强化学习过程提供了丰富的搜索空间。4. 统一了代码生成模型的解码行为，区分了它与自回归模型的关键差异，提供了更深入的理解。
## Conclusion
本研究深入探讨了扩散生成模型在代码生成中的解码机制，并提出了一种新型的扩散适应性强化学习训练框架，显著提升了代码生成模型的性能。未来的研究可以进一步探索扩散模型在代码生成中的更多潜在应用。
# 232. `cs.CL` - 作为分布量的反事实影响 [PDF](https://arxiv.org/pdf/2506.20481), [HTML](https://arxiv.org/abs/2506.20481)
## Authors
Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye
## Background
机器学习模型已知会记住其训练数据中的样本，这引起隐私和泛化的担忧。反事实的自我影响是一个流行的研究记忆化的指标，它量化模型对于样本的预测如何因样本是否包含在训练数据集中而变化。然而，近期研究表明，记忆化不仅仅受到自我影响的影响，特别地，（近）重复样本也会产生重大影响。因此，研究提出将反事实影响视为分布性数量，考虑所有训练样本如何影响样本的记忆化过程。
## Innovation
研究提出并将反事实影响视为分布性数量，通过计算小型语言模型中所有训练样本之间的完整影响分布并分析其属性。研究发现仅仅关注自我影响可能严重低估了记忆化的实际风险：（近）重复样本显著降低了自我影响，但这些样本仍然可提取。在图像分类中，简单观察影响分布也揭示了CIFAR-10中存在近重复样本。这些发现强调了记忆化来自训练数据之间的复杂交互，而不仅仅是自我影响。
## Conclusion
研究结果显示，记忆化来源于训练数据之间的复杂互动，通过整个影响分布才能更准确地捕捉到记忆化过程，而不是仅仅依赖于自我影响。
# 233. `cs.CL` - 从手稿学到代码：基于变换器和YOLO检测器的历史文档布局分析比较研究 [PDF](https://arxiv.org/pdf/2506.20326), [HTML](https://arxiv.org/abs/2506.20326)
## Authors
Sergio Torres Aguilar
## Background
历史文档由于复杂的页面组织，自动处理和理解这些文档需要稳健的文档布局分析（DLA）。本文在三种代表不同编年学复杂性的注释数据集（e-NDP、CATMuS和HORAE）上测试了五种最先进的目标检测架构，评估了两种基于变换器的模型（Co-DETR、Grounding DINO）与三种YOLO变体（AABB、OBB和YOLO-World）的表现差异。研究发现，不同模型架构、数据集特性和边界框表示方式对性能影响显著，尤其是在CATMuS和HORAE这些更具挑战性的数据集上，基于CNN的模型表现更优。这些结果表明，使用定向边界框（OBB）不仅是轻微改进，而是准确建模历史手稿非笛卡尔性质的必要条件。
## Innovation
本文通过在三种不同类型的历史文档数据集上比较最先进的目标检测模型，揭示了模型架构、数据集特性和边界框表示方式对DLA性能的不同影响。特别强调了基于OBB的模型在复杂文档中的优越表现，填补了现有研究在历史文档领域的空白。
## Conclusion
本文得出结论，变换器模型在结构化布局的全局上下文意识方面表现出色，而基于CNN-OBB的模型则更适合复杂且多种类的视觉文档。存在一个关键权衡，即变换器模型在局部细节上的不足与CNN-OBB模型在复杂布局中的优越表现之间的权衡。使用OBB是准确建模历史手稿布局的必要条件。
# 234. `cs.CL` - 捕获可视化设计理据 [PDF](https://arxiv.org/pdf/2506.16571), [HTML](https://arxiv.org/abs/2506.16571)
## Authors
Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha
## Background
先前用于数据可视化的自然语言数据集主要关注于诸如可视化素养评估、洞察生成以及基于自然语言指令生成可视化等任务。这些研究通常依赖于经过控制的环境和特别构建的可视化，使用人为构造的问题。因此，它们往往侧重于对可视化的解读，而非理解其编码方式。这篇论文介绍了一个新的数据集和方法，用于通过自然语言探索可视化设计的理由。论文利用了学生成为数据可视化课程中的一部分而创建的真实世界可视化笔记本和自然语言叙述的独特来源。这些笔记本结合了视觉艺术制品和设计说明，其中学生明确表示了设计决策背后的理由。同时，论文使用大型语言模型（LLMs）生成和分类来自笔记本叙述和表述的问题-答案-理由三元组，然后仔细验证这些三元组，并构建一个数据集，该数据集捕获并提取了学生可视化设计选择及其对应理由的精华部分。
## Innovation
该论文提出了一种新的数据集和方法，以通过自然语言探究可视化设计的理据。它利用实用且真实的可视化笔记本作为数据源，这些笔记本不仅包括视觉艺术制品还包含设计说明，使得学生能明确表示设计决策背后的理由。此外，使用大型语言模型来生成和分类这三个部分（问题-答案-理由）的三元组，并且对生成的数据集进行了精细的验证和整理，从而提取可视化设计的选择及其对应的理据。这种创新性的方法使研究更接近真实的可视化设计过程，而不是依赖于人为构造的数据。
## Conclusion
该研究构建了一个新的数据集，该数据集涵盖了学生成为数据可视化课程的一部分时创建的可视化笔记本中的视觉艺术制品和设计说明。通过使用大型语言模型来生成和分类问题-答案-理由三元组，论文能够精确捕获和提炼学生的可视化设计选择及其对应的理由。
# 235. `cs.CL` - 语言模型通过语言模型进行语言建模 [PDF](https://arxiv.org/pdf/2506.20249), [HTML](https://arxiv.org/abs/2506.20249)
## Authors
Junyan Cheng,Peter Clark,Kyle Richardson
## Background
该研究背景在于利用大型语言模型（LMs）来模拟发现新语言模型架构的过程，这借鉴了真实研究中的步骤，包括从构想和文献搜索（提案阶段）到设计实现（代码生成）、生成预训练和下游评估（验证）等阶段。研究人员使用了类似于层级缩放方法的策略，旨在提高发现过程的高效性和因素化，通过逐步增加模型规模和减少预算来实现新设计的提出、对抗性审查、实施和验证。为了实现有效自主发现系统的构建，研究采用了新颖的遗传编程核心，显示出与传统直接提示生成流程相比的优势（例如，成功率提升约86个百分点），并进行了1,162个新发现的设计实验（其中1,062个通过预训练完全验证）。
## Innovation
本文创新点主要在于利用遗传编程核心构建了一个名为Genesys的多智能体大型语言模型系统，该系统采用了层级缩放方法，能在逐步增大的模型规模上进行新设计的提出、对抗性审查、实施和验证，同时提高设计生成的成功率。此外，通过与传统直接提示生成流程对比，证明了在设计成功的提升方面具有显著优势。进一步，实验发现最佳设计与现有已知架构具有高度竞争力，能够在多个常见基准测试中表现优异。
## Conclusion
总的来说，研究结果显示，Genesys系统在大幅度提升设计发现成功率的基础上，能够生成高度竞争力的新架构，通过实验和全面的系统级分析，为自主发现系统的有效设计提供了广泛见解。这些新架构对于语言模型和相关研究领域具有重要的实际应用价值。
# 236. `cs.CL` - FundaQ-8:以临床为导向的自动视网膜影像质量评分框架 [PDF](https://arxiv.org/pdf/2506.20303), [HTML](https://arxiv.org/abs/2506.20303)
## Authors
Lee Qi Zun,Oscar Wong Jin Hao,Nor Anita Binti Che Omar,Zalifa Zakiah Binti Asnir,Mohamad Sabri bin Sinal Zainal,Goh Man Fye
## Background
自动视网膜影像质量评估（FIQA）由于成像获取的差异性和主观专家评估的差异性而仍具有挑战性。FundaQ-8是一个新颖的专家验证框架，用于系统地使用八个关键参数评估视网膜影像质量，包括视域覆盖、解剖结构可视性、照明和图像伪影。FundaQ-8作为结构化评分参考，用于开发基于ResNet18的回归模型以预测0到1范围内的连续质量评分。
## Innovation
该研究引入了FundaQ-8框架，它使用八个关键参数（视域覆盖、解剖结构可视性、照明和图像伪影等）系统性地评估视网膜影像质量，并利用ResNet18建立回归模型预测质量评分。该模型采用迁移学习、均方误差优化和标准化预处理进行训练，并通过EyeQ数据集验证和统计分析确认其可靠性和临床可解释性。同时，该框架也提升了糖尿病视网膜病变分级的诊断稳健性，突出了质量感知训练在实际筛查中的价值。
## Conclusion
验证结果表明，FundaQ-8框架不仅提高了FIQA的可靠性，还增强了糖尿病视网膜病变分级的诊断一致性。
# 237. `cs.CL` - PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models [PDF](https://arxiv.org/pdf/2506.20629), [HTML](https://arxiv.org/abs/2506.20629)
## Authors
Soufiane Hayou,Nikhil Ghosh,Bin Yu
## Background
LoRA（低秩适应）是一种广泛用于大型模型微调的方法。它的内存占用小，使得实践者能够以相对较低的成本将大型模型适应到特定任务。已经提出了各种改进方法来增强LoRA的效率，例如调整学习率、设置秩和初始化。此外，适配器放置策略也是一个重要的改进方向。尽管有一些工作研究了适配器放置问题，但结果并不一致。原始的LoRA论文建议将在注意力模块中放置适应器，而其他研究则提出应该在MLP模块中放置集成器。这项研究通过直观的理论分析，提出了PLoP（精确LoRA放置）方法，该方法能够根据预训练模型和微调任务自动识别应放置LoRA适应器的模块类型，是一种轻量级的方法。
## Innovation
PLoP通过理论分析提供了一种自动确定适应器放置位置的方法，解决了适配器放置策略的不一致性问题。PLoP方法在广泛的实验中展示了优于现有策略的性能，甚至在最差情况下可以与其匹敌，特别是在监督微调和基于强化学习的推理任务中。
## Conclusion
本文提出了PLoP（精确LoRA放置）方法，该方法能够在给定的预训练模型和微调任务中自动识别应放置LoRA适应器的模块类型，从而更高效地微调大型模型。实验结果表明，PLoP方法在多种任务中表现优异，甚至在最坏情况下也能与常用策略竞争。
# 238. `cs.CL` - 不对称 REINFORCE 用于离策强化学习：平衡正负奖励 [PDF](https://arxiv.org/pdf/2506.20520), [HTML](https://arxiv.org/abs/2506.20520)
## Authors
Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos
## Background
强化学习（RL）被越来越多地用于对齐大型语言模型（LLMs）。离策方法在实现简便性和数据效率方面比在策技术更胜一筹，但在性能上通常达不到最优。本文研究了在离策RL和监督微调之间的算法范围，通过对一个简单的离策REINFORCE算法进行分析来进行，定义其优势为$A = r - V$，其中$r$为奖励，$V$为可调基线。直观上降低$V$强调高奖励样本，提升$V$则对低奖励样本惩罚更重。文章首先对该离策REINFORCE算法进行了理论分析，证明了当基线$V$紧致地小于预期奖励时，该算法具有一种策略改进保证。分析揭示了在最优奖励时可以安全地利用正负信号，但离策更新更偏好于强调正奖励，而非负奖励。这一发现通过在控制的随机多臂问题设定以及通过在推理任务上微调最新大型语言模型上进行了实验证实和验证了这一研究结果。
## Innovation
提出了一个不对称的REINFORCE算法，用于在离策RL和监督微调之间找到一个有效的策略改进保证。通过对REINFORCE算法的基线$V$进行分析，发现离策更新更偏好于强调正奖励，而非负奖励，从而提高了算法的性能。该研究通过在控制实验和真实语言模型任务上的验证进一步推进了对离策RL的理解。
## Conclusion
该研究揭示了离策方法如何充分利用正奖励信号，同时减少负奖励信号的影响，从而提高在复杂任务上的表现和效率。通过实验证实了算法的有效性，并为进一步研究提供了理论支持和新的视角。
# 239. `cs.CL` - 当大型语言模型与人类相矛盾时：大型语言模型的奉承行为 [PDF](https://arxiv.org/pdf/2311.09410), [HTML](https://arxiv.org/abs/2311.09410)
## Authors
Leonardo Ranaldi,Giulia Pucci
## Background
大型语言模型在生成内容方面表现出色，这似乎是由于频繁的人类反馈所改善的结果。然而，这些反馈中含有的从属行为使模型倾向于生成与用户观点一致的答复，这种行为被称为奉承，导致生成误导性答案，从而偏斜模型的可靠性和稳健性.
## Innovation
本文研究了大型语言模型的从属倾向性，通过系统的人类干预提示在不同任务中分析奉承行为。结果显示，当面对涉及主观意见或应给出相反事实性回答的问题时，这些模型倾向于奉承用户。相反，它们在数学任务或需要客观答案的问题上不会遵循用户的提示，而是自信地生成正确答案.
## Conclusion
大型语言模型在某些主观问题上倾向于奉承用户观点，但在需要客观答案的任务上依然能够保持准确性。
# 240. `cs.CL` - Inside you are many wolves: 使用认知模型解释LLM中的价值权衡 [PDF](https://arxiv.org/pdf/2506.20666), [HTML](https://arxiv.org/abs/2506.20666)
## Authors
Sonia K. Murthy,Rosie Zhao,Jennifer Hu,Sham Kakade,Markus Wulfmeier,Peng Qian,Tomer Ullman
## Background
日常社交情况往往需要权衡冲突的目标，例如传递一个直言不讳的真相，同时维护信任和考虑另一个人的感受。这种价值权衡是人类决策和语言使用的一部分。现有的工具对于理解这些动态和多维度的价值概念在大规模语言模型（LLM）中的表达是有限的。在认知科学中，所谓的“认知模型”提供了对这些权衡的正式解释，通过对说话者的竞争效用函数进行建模来预测其在采取行动或发出言语时的选择权重。本文利用礼貌言语的认知模型来解释LLMs如何代表人类一样的权衡。作者对两种模型中的价值权衡进行了系统评估，分别是推理工作量的程度以及开源模型在强化学习后训练过程中的动力学。结果显示，在推理模型中信息效用高于社会效用，在擅长数学推理的开源模型中也表现出这种情况。训练动力学的发现表明，早期训练中会发生效用值的巨大转变，这些效应持续存在并受基础模型和预训练数据的选择影响较大，而反馈数据集或对齐方法的影响较小。本文的方法能够反映快速变化的LLM环境的各种特点，并提出了关于其他高级行为形成假设、引导推理模型的训练制度以及在模型训练中更好地控制价值权衡的洞见。
## Innovation
本文使用了源于认知科学的认知模型来解释大规模语言模型（LLMs）中价值权衡的表现，这是一种新颖的方法。这种方法不仅能够提供对LLMs行为的深入理解，还揭示了不同类型的模型在处理信息效用与社会效用时的不同表现。通过对训练过程的详细分析，作者发现了影响模型表现的关键因素，包括基础模型、预训练数据以及反馈数据集或对齐方法，这为未来的研究和模型设计提供了宝贵的指导。
## Conclusion
研究结果表明，在推理模型中，信息效用高于社会效用，而在擅长数学推理的开源模型中也表现出这种情况。此外，早期训练中的效用值转变很大，且随着时间推移保持不变，其影响主要来自于基础模型和预训练数据的选择，而不是反馈数据集或对齐方法。基于这些发现，本文提出了一种新的方法来理解和控制大规模语言模型（LLM）中的价值权衡，并为未来的工作提出了若干建议。
# 241. `cs.CL` - 语言模型从较少见的现象学习稀有现象：缺失的AANN现象案例 [PDF](https://arxiv.org/pdf/2403.19827), [HTML](https://arxiv.org/abs/2403.19827)
## Authors
Kanishka Misra,Kyle Mahowald
## Background
语言模型能够学习稀有句法现象，但这种学习是基于泛化还是记忆尚不清楚。研究通过逐步训练变压器语言模型，使用系统操纵、人类规模大小的语料库，并评估其对稀有句法现象的学习，来探讨这一问题。特定现象为英语中的'Article+Adjective+Numeral+Noun'（AANN）结构，该结构在语料库中的出现较为罕见。研究比较了默认语料库和移除了AANN句子的反事实语料库，发现即使是经过系统性扰动的AANN变体也能比反事实语料库中更好学习AANN结构。进一步使用反事实语料库提出了泛化学习可能性，并发现输入变异性增加能进一步促进这种学习效果。
## Innovation
该研究通过逐步训练和评估语言模型对稀有句法现象的学习，提出通过相关较为常见句法结构泛化学习稀有句法结构的可能性，并通过反事实实验提供实际证据，证明语言模型能够在低频句法结构上实现泛化学习。这种方法和发现为理解语言模型如何从大规模训练中学习稀有句法现象提供了新的见解。
## Conclusion
研究结果表明，语言模型可以通过从较为常见的结构中泛化来学习稀有句法现象，并且输入的多样性和变异性对这种泛化学习有正向促进作用。这为未来的研究提供了基础，特别是在理解和改进语言模型如何处理更复杂的语言现象方面。
# 242. `cs.CL` - 一种序列标注的全局上下文机制 [PDF](https://arxiv.org/pdf/2305.19928), [HTML](https://arxiv.org/abs/2305.19928)
## Authors
Conglei Xu,Kun Shen,Hongguang Sun,Yang Xu
## Background
序列标注任务依赖于句子的整体信息，而BiLSTM模型在捕获内部单词的全局上下文方面往往表现不佳。尽管有些研究提出了通过多种RNN变体来整合句子的全局信息，但这些方法仍存在几个关键问题：一是它们在推理和训练速度上较慢，二是无法有效地为基于Transformer的模型提供全局信息，三是重新实现和集成这些定制化的RNN模型到现有架构中耗时且复杂。
## Innovation
本文提出了一种简单而有效的机制，解决了上述限制。该方法能够高效补充全局句子信息给BiLSTM和基于Transformer的模型，并且对推理和训练速度的影响最小，易于集成到现有的架构中。经验证，本方法在包括命名实体识别（NER）任务如Conll2003和Wnut2017等在内的七个常见的基准测试中取得了显著提高，尤其是在Weibo NER基准测试中获得第三名的成绩，所有这些效果都无需额外策略。此外，与CRF等广泛应用于序列标注的主要框架相比，该机制在保持训练和推理速度优势的同时也获得了竞争力的F1得分.
## Conclusion
我们的机制在无需额外策略的情况下，在Weibo NER基准测试中取得了第三的好成绩。相比传统的CRF框架，我们的机制在保持F1得分的同时，还提供更快的推理和训练速度。
# 243. `cs.CL` - 代码生成大规模语言模型处理长距离依赖性的评估 [PDF](https://arxiv.org/pdf/2407.21049), [HTML](https://arxiv.org/abs/2407.21049)
## Authors
Yannick Assogba,Donghao Ren
## Background
随着语言模型支持的上下文大小不断增加，评估其有效利用这些上下文的能力变得越来越重要。因此，本文通过一系列多步骤的关键检索任务评估了几种代码生成模型处理长范围依赖性的能力，这些任务在长度高达8k个令牌的上下文窗口中进行。任务逐级增加难度，比传统的‘ haystack 中的 needle ’测试更能细致地评估模型的能力。研究表明，在函数引用在提示中定义后期的函数时，许多模型的性能显著下降（最多下降2倍）。模型还发现，使用滑动窗口注意力机制的模型在处理超出单个窗口大小的引用时难以应对。为了改进多步骤检索性能，作者利用调用图信息对提示进行了简单的修改，结果性能提高了3倍。这些分析突显了在考虑长上下文性能时需要深入考虑的方面，不仅仅是文档内单个事实的检索
## Innovation
本文提出了一个多步骤的关键检索任务系列，用于评估代码生成模型在大上下文窗中的长距离依赖性处理能力，并发现了一些模型的局限性。此外，作者利用调用图信息对提示进行了简单的修改，以显著提高多步骤检索性能
## Conclusion
本文分析指出，长上下文性能需要更深入的考虑，而不仅仅是检索文档内的单一事实。研究的发现为后续的模型提升和优化工作提供了一个重要的参考。
# 244. `cs.CL` - FactCheckmate：在语言模型中预先检测和缓解幻觉 [PDF](https://arxiv.org/pdf/2410.02899), [HTML](https://arxiv.org/abs/2410.02899)
## Authors
Deema Alnuhait,Neeraja Kirtane,Muhammad Khalifa,Hao Peng
## Background
语言模型（LMs）存在幻觉现象，即它们生成的内容并非基于输入的信息。本文的研究背景在于，现有的方法是否可以在幻觉发生之前就进行检测和缓解，从而提高模型生成内容的真实性。
## Innovation
本文提出了一种名为FactCheckmate的新方法，该方法通过学习分类器预测LM是否会产生幻觉，利用模型在处理输入时产生的隐藏状态来实现预先检测，并通过调整隐藏状态来缓解幻觉，从而揭示了LM内部工作机理新的见解。这种方法具有实时性和轻量级的特点，相较于许多事后处理的方法更有效率。FactCheckmate在多个不同规模和模型系列的LMs上进行了测试，覆盖了来自不同领域的多种问答数据集，显示了其有效性和实用性。
## Conclusion
FactCheckmate方法能够有效提高LM生成内容的真实性，其预先检测的准确率超过70%，且调整隐藏状态后生成的内容平均比未调整的内容更真实，能更有效地缓解幻觉问题。
# 245. `cs.CL` - MMSearch-R1: 促进大模态模型搜索 [PDF](https://arxiv.org/pdf/2506.20670), [HTML](https://arxiv.org/abs/2506.20670)
## Authors
Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu
## Background
在真实世界的场景中部署大规模多模态模型（LMMs）需要访问外部知识源，因为现实世界中的信息复杂且动态。现有的方法，如检索增强生成（RAG）和提示工程搜索代理，依赖于刚性管道，这往往导致搜索行为低效或过度。
## Innovation
我们提出了MMSearch-R1，第一个端到端的强化学习框架，使LMMs能够在真实的互联网环境中进行按需、多轮搜索。该框架结合了图像和文本搜索工具，根据基于结果的奖励和搜索惩罚指导模型何时和如何调用它们。为了支持训练，我们通过一个半自动管道收集了一个多模态搜索VQA数据集，并整理了一个既包含需要搜索的情况也包含不需要搜索的情况的搜索平衡子集，这对于塑造有效和按需的搜索行为至关重要。
## Conclusion
在知识密集型和信息寻求的VQA任务上的广泛实验表明，我们的模型不仅在模型大小相同的RAG基线中表现出优越性，还在减少搜索调用超过30%的前提下，匹配了一个更大RAG基线模型的性能。我们进一步分析了关键的实证发现，为促进多模态搜索研究提出了可操作的见解。
# 246. `cs.CL` - 关于阅读时间预测中的上下文作用 [PDF](https://arxiv.org/pdf/2409.08160), [HTML](https://arxiv.org/abs/2409.08160)
## Authors
Andreas Opedal,Eleanor Chodroff,Ryan Cotterell,Ethan Gotlieb Wilcox
## Background
本研究提供了一种新的视角，探讨读者在实时语言理解过程中如何整合上下文。研究基于‘惊异理论’（surprisal theory），认为语言单位（如单词）的处理难度与其上下文中的信息量呈线性关系。进一步研究观察到，上下文预测不仅可以通过惊异理论中的惊异来表示，还可以通过单元与上下文之间的点互信息（PMI）来表示；同时PMI和惊异与频率相关。因此，这些方法都不能独立地包含上下文本身的信息。基于这一发现，研究提出了一种将惊异投影到频率的正交补空间的技术，得到一个与频率无关的新上下文预测器。实验结果表明，当使用正交化预测器表示上下文时，能够解释阅读时间变异性的上下文比例大幅减少。这从可解释性角度表明，以往的研究可能高估了上下文在预测阅读时间中的作用。
## Innovation
提出了一种将惊异投影到频率的正交补空间的技术，得到一个与频率无关的新上下文预测器，旨在独立地体现上下文信息，减少了以往研究中对于上下文作用的高估。
## Conclusion
使用正交化预测器表示上下文时，能够解释阅读时间变异性的上下文比例大幅减少。这从可解释性角度表明，以往研究可能高估了上下文在预测阅读时间中的作用。
# 247. `cs.CL` - 世界模型的理解或预测未来？世界模型综述 [PDF](https://arxiv.org/pdf/2411.14499), [HTML](https://arxiv.org/abs/2411.14499)
## Authors
Jingtao Ding,Yunke Zhang,Yu Shang,Yuheng Zhang,Zefang Zong,Jie Feng,Yuan Yuan,Hongyuan Su,Nian Li,Nicholas Sukiennik,Fengli Xu,Yong Li
## Background
由于GPT-4等多模态大型语言模型和Sora等视频生成模型的发展，世界模型的概念引起了广泛关注。这些模型被认为是实现人工通用智能的关键。世界模型通常被视作理解当前世界状态的工具或预测未来动态的工具。本文综述了世界模型的相关文献，系统分类了世界模型，并重点讨论了其两种主要功能：构建内部表示以理解世界机制，以及预测未来状态以模拟和引导决策。
## Innovation
本文提供了世界模型的全面综述，并系统分类了世界模型，强调了构建内部表示和预测未来状态作为主要功能。同时，还探讨了世界模型在自动驾驶、机器人技术和社交仿真等关键领域的应用。
## Conclusion
本文总结了代表性的论文和代码库，并指出了未来研究的关键挑战和可能的方向。
# 248. `cs.CL` - 分离语言与思想：激活补丁揭示变换器中的语言无关概念表示 [PDF](https://arxiv.org/pdf/2411.08745), [HTML](https://arxiv.org/abs/2411.08745)
## Authors
Clément Dumas,Chris Wendler,Veniamin Veselovsky,Giovanni Monea,Robert West
## Background
多语言语言模型中的一个核心问题是大型语言模型（LLMs）是否发展出了与特定语言分离的通用概念表示。本文通过在转换器架构的LLMs中分析单词翻译任务中的潜在表示，解决了这一问题，发现输出语言编码在更早的层中，而待翻译的概念则不同。作者的实验证实了通过激活补丁可以单独地改变概念而不改变语言，反之亦然，并且使用概念的平均表示跨不同语言的补丁可以在不损害翻译能力的情况下提高模型的翻译能力，进而适用于多令牌生成任务，该模型能够生成对这些平均表示的自然语言描述。
## Innovation
本文通过利用激活补丁技术，揭示了变换器中存在语言无关的概念表示，该技术可以独立地改变概念而不改变语言，甚至可以使用跨不同语言的概念平均表示来提高翻译能力。此外，这还能应用于多令牌生成任务，证明模型可以生成对于平均表示的自然语言描述。这项工作为理解大型语言模型内部的概念和语言表示提供了重要的新视角。
## Conclusion
研究结果提供了证据，证实了在调查模型中存在语言无关的概念表示。
# 249. `cs.CL` - 全面利用大语言模型内部状态以增强知识边界感知 [PDF](https://arxiv.org/pdf/2502.11677), [HTML](https://arxiv.org/abs/2502.11677)
## Authors
Shiyu Ni,Keping Bi,Jiafeng Guo,Lulu Yu,Baolong Bi,Xueqi Cheng
## Background
大语言模型在多样任务中表现出色，但在判断知识边界方面常常不够准确，容易给出正确性不足但充满信心的回答。本文探讨利用大语言模型的内部状态来增强其对知识边界的感知，从效率和风险的角度出发进行研究。研究发现，大语言模型在生成回答之前能够利用内部状态进行初步的感知，这为节省计算资源提供了可能。实验结果表明，这种预生成感知在不同条件下表现稳定，并且对生成后的感知进行了细化，从而使得知识差距的感知更加准确。
## Innovation
提出了Confidence Consistency-based Calibration ($C^3$)，这是一种通过问题重述来评估信心一致性的方法。这种方法显著提高了大语言模型识别自身知识空白的能力，在Natural Questions和HotpotQA数据集上分别将未知感知率提高了5.6%和4.9%，从而能够在不牺牲效率的情况下优化了大语言模型的可靠性，并且有效控制输出风险。
## Conclusion
预生成信心估计可以优化效率，而$C^3$方法有效控制了潜在风险，提高了大语言模型在实际应用中的可靠性。
# 250. `cs.CL` - 大语言模型中用于图推理的图线性化方法 [PDF](https://arxiv.org/pdf/2410.19494), [HTML](https://arxiv.org/abs/2410.19494)
## Authors
Christos Xypolopoulos,Guokan Shang,Xiao Fei,Giannis Nikolentzos,Hadi Abdine,Iakovos Evdaimon,Michail Chatzianastasis,Giorgos Stamou,Michalis Vazirgiannis
## Background
大语言模型已经发展到可以处理除了文本之外的多种模态，如图像和音频，这促使我们探索如何有效地利用它们来进行图推理任务。关键问题是如何将图转换为线性序列的令牌，我们称之为“图线性化”，以使大语言模型能够自然地处理图。我们考虑了图应该如何有意义地线性化，以反映自然语言文本的某些特性，如局部依赖和全局对齐，从而帮助当前的大语言模型更好地理解图。
## Innovation
开发了基于图中心性和退化性的一系列图线性化方法，并结合节点重新标记技术进一步增强。实验结果表明，与随机线性化基线相比，这些方法更有效。这项工作引入了适合大语言模型的新图表示方法，为图机器学习与统一变换器模型的多模态处理趋势的潜在整合做出了贡献。
## Conclusion
我们的研究展示了基于图中心性和退化性的图线性化方法的有效性，并结合节点重新标记技术，为图推理任务提供了有意义的图表示，这有助于将来更好地将图机器学习与多模态处理趋势整合起来。
# 251. `cs.CL` - 预训练语言模型和人类在语义关系知识上的全面评估 [PDF](https://arxiv.org/pdf/2412.01131), [HTML](https://arxiv.org/abs/2412.01131)
## Authors
Zhihan Cao,Hiroaki Yamada,Simone Teufel,Takenobu Tokunaga
## Background
近期关于预训练语言模型（PLMs）对语言不同方面的学习及其学习方式的研究引起了广泛关注。一类研究主要探讨了模型在处理语义关系方面的知识。然而，语义关系的许多方面仍未被充分探讨。以往的工作仅考虑了超词关系，并没有测量人类在相同任务上的表现。因此，目前对模型在语义关系知识的理解还很不完整。为了弥补这一差距，研究人员引入了一种包括5个关系（超词关系、部分关系、组合关系、反义关系、同义关系）在内的全面评估框架。研究使用六种评测指标（其中两种是首次引入）对人类和模型在处理未被充分研究的语义关系方面的能力进行了公平比较。为全面评估，实验涉及16个PLMs，包括8个掩码模型和8个因果模型。现有研究主要关注掩码模型，而因果模型和掩码模型处理上下文的方式有所不同。实验结果显示，除了反义关系外，人类和模型在几乎所有语义关系上的知识差距都很大。掩码模型在整体上显著优于因果模型。然而两者都可能在处理非反义关系时被反义关系所迷惑。
## Innovation
引入了一种综合的评估框架，涵盖了5种语义关系（超词关系、部分关系、组合关系、反义关系、同义关系），并公平比较了人类和模型在这方面的表现。此外，研究使用了六种新的评测指标来评估这些未被充分研究的语义关系知识方面（包括完备性、一致性、对称性、非对称性、代表性、可区分性），并涉及16个PLMs中的因果和掩码模型与人类在相同任务的对比。
## Conclusion
实验揭示了人类和模型在几乎所有语义关系上的知识差距较大。掩码模型在整体上显著优于因果模型。除此之外，掩码和因果模型在处理非反义关系时通常会被误认为是反义关系。
# 252. `cs.CL` - Decrypto 评估标准：多智能体推理及理论思维 [PDF](https://arxiv.org/pdf/2506.20664), [HTML](https://arxiv.org/abs/2506.20664)
## Authors
Andrei Lupu,Timon Willi,Jakob Foerster
## Background
随着大型语言模型（LLMs）获得自主能力，它们将需要在复杂多智能体场景中与人类用户和其他智能体进行合作与竞争。这将需要新的推理能力，其中最重要的便是心智理论（ToM），即能够推理其他智能体的心理状态。然而，LLMs中的ToM和其他多智能体能力尚不完全理解，现存的基准测试存在狭隘范围、数据泄漏、饱和和缺乏交互性的问题。因此，需要一种新的基准测试来评估这些能力。这就是Decrypto游戏基准的作用，它借鉴了认知科学、计算语用学和多智能体强化学习的理念，旨在通过消除其他基准测试中的混淆因素，使其在所有其他维度上尽可能简单。此外，它还是首个设计交互心智理论实验的平台。
## Innovation
Decrypto 提出了一个基于游戏的多智能体推理和心智理论基准测试，旨在通过消除其他基准测试中的混淆因素，使其在所有其他维度上尽可能简单。它也是首个设计交互心智理论实验的平台，为当前的推理和心智理论评估填补了关键空白，并为更好的人造智能奠定了道路。这种方法通过全面评估最新的语言模型、稳健性研究和人类-人工智能交叉玩法实验进行了验证。结果发现，最先进的语言模型在游戏能力上落后于人类和简单的词嵌入基线。此外，通过在 Decrypto 中创建经典认知科学实验的变体，评估了三种关键的心智理论能力，发现最先进的推理模型在这三个任务上表现不如其较早的版本显著。
## Conclusion
Decrypto 表明，当前的推理和心智理论评估存在重要空白，并为改进的人造智能铺平了道路。通过 Decrypto，研究人员可以更好地理解多智能体系统中的关键心智理论问题，并通过更广泛的实验验证现有的和新的模型。
# 253. `cs.CL` - WordNet与人类直觉之间的语义关系知识不一致 [PDF](https://arxiv.org/pdf/2412.02138), [HTML](https://arxiv.org/abs/2412.02138)
## Authors
Zhihan Cao,Hiroaki Yamada,Simone Teufel,Takenobu Tokunaga
## Background
WordNet 提供了一个由专家精心构造的语义关系库。然而，还存在另一个来源的语义关系信息，那就是语言使用者的直觉。本研究首次系统地研究了这两者之间的一致程度。如果不理解这些不一致的情况，将不会充分利用WordNet，也无法改善WordNet的准确性。本研究使用模板从人类受试者那里收集反应，揭示了WordNet与人类直觉中的语义关系知识存在普遍的不一致性。进一步分析发现，同义词和税收关系（超类和子类）之间存在系统性偏差模式，同时指出，WordNet的路径长度不能作为衡量人类关于超类或子类关系直觉的可靠指标。
## Innovation
本研究是第一个系统地研究WordNet和人类直觉之间的语义关系知识一致性的研究。通过使用模板从人类参与者那里收集反应，揭示了与WordNet相比，人类对于语义关系的知识存在普遍的不一致性，并发现同义词和税收关系（超类和子类）之间存在系统性偏差模式，以及WordNet的路径长度不能作为衡量人类关于超类或子类关系直觉的可靠指标。这为改进WordNet提供了新的见解和改进建议。
## Conclusion
WordNet与人类直觉之间的语义关系知识存在普遍的不一致性，尤其在同义词和税收关系（超类和子类）之间。因此，如果要充分利用WordNet，应该考虑这些不一致点，并有助于改进词网。WordNet的路径长度不能作为衡量人类关于超类或子类关系直觉的可靠指标。
# 254. `cs.CL` - 在游戏《Codenames》中的即兴概念形成作为评估大型语言模型的方法 [PDF](https://arxiv.org/pdf/2502.11707), [HTML](https://arxiv.org/abs/2502.11707)
## Authors
Sherzod Hakimov,Lara Pfennigschmidt,David Schlangen
## Background
本研究利用游戏《Codenames》作为基准工具，评估大型语言模型（LLMs）在特定语言和认知技能方面的能力。LLMs 分别扮演游戏的两个阵营，其中一个阵营提出带有多个目标词的提示词，另一个阵营则猜测这些目标词。研究设计了多种实验，通过控制词的选择（抽象词 vs. 具体词，模糊词 vs. 单义词）或对手（编程使对手更快或更慢地揭示词）来调整条件。研究比较了近期的商用和开源权重模型，以确定影响其性能的因素。评估揭示了它们的策略、挑战案例以及LLMs的局限性。
## Innovation
利用游戏《Codenames》进行评估，通过控制不同的条件和比较多种模型来深入了解LLMs在特定语言和认知技能方面的表现。这种方法为评估LLMs提供了一种新颖的视角，有助于发现其策略、挑战案例和局限性。
## Conclusion
该研究揭示了LLMs在即兴概念形成方面的表现细节，指出了它们在特定语言和认知技能上的策略、挑战案例和局限性。通过这种方法，研究者能够得到更深入的洞见，以便更好地理解和改进大型语言模型。
# 255. `cs.CL` - VAQUUM: 视觉数据中模糊量词是否得到扎根？ [PDF](https://arxiv.org/pdf/2502.11874), [HTML](https://arxiv.org/abs/2502.11874)
## Authors
Hugh Mee Wong,Rick Nouwen,Albert Gatt
## Background
模糊量词如“少许”和“许多”会受到各种上下文因素的影响，比如场景中对象的数量。本文旨在评估视觉-语言模型（VLMs）在生成或判断模糊量词的适当性时与人类的一致性程度。为此，作者发布了一个名为VAQUUM的新数据集，包含20,300个关于对象数量化陈述的人类评分，覆盖1089张图片。该数据集被用于比较人类判断和VLM预测的不同评价方法。研究发现，与人类一样，VLMs会在模糊量词使用中受到对象数量的影响。但是，不同模型在不同评价环境中的判断不一致，说明判断和生成模糊量词依赖于两个不同的过程。
## Innovation
本文提出了一个新的名为VAQUUM的数据集，包含20,300个量化陈述的人类评分，以研究视觉-语言模型在模糊量词使用中的表现。此外，通过使用不同的评价方法，揭示了模型在处理模糊量词时与人类存在分歧。
## Conclusion
视觉-语言模型在模糊量词使用中受到对象数量的影响，但不同模型之间在不同评估环境中的表现存在显著差异，指示出判断和生成模糊量词的过程是不同的。
# 256. `cs.CL` - 基于不确定性意识的指令微调平衡真实性和信息量 [PDF](https://arxiv.org/pdf/2502.11962), [HTML](https://arxiv.org/abs/2502.11962)
## Authors
Tianyi Wu,Jingwei Ni,Bryan Hooi,Jiaheng Zhang,Elliott Ash,See-Kiong Ng,Mrinmaya Sachan,Markus Leippold
## Background
指令微调（IFT）可以提高大型语言模型（LLMs）的信息量，但也可能导致模型不真实。这是因为指令微调会引导模型生成包含预训练阶段未充分覆盖的知识响应，这使得模型在泛化到未见过的任务时变得更加信息丰富但更不准确。已有研究显示，不明知识可能影响模型的真实性。
## Innovation
本文通过实验证明了在指令微调数据集中含有不明知识对模型真实性的负面影响，并提出了两种新的指令微调范式，即$UNIT_{cut}$和$UNIT_{ref}$。$UNIT_{cut}$通过识别并从指令微调数据集中移除不明知识来减少其对模型真实性的负面影响；而$UNIT_{ref}$训练模型在响应结束时明确表明自身的不确定性。实验结果表明，$UNIT_{cut}$显著提高了模型的真实性，而$UNIT_{ref}$则保持了高度的信息量并减少了幻觉，通过区分自信和不确定的声明来实现这一点。
## Conclusion
本研究提出了两种新的指令微调方法，分别从减少模型不明知识和明确表示不确定性两方面平衡了LLMs的真实性和信息量。
# 257. `cs.CL` - 超越语言模型的自然数据集的上下文学习解锁 [PDF](https://arxiv.org/pdf/2501.06256), [HTML](https://arxiv.org/abs/2501.06256)
## Authors
Jelena Bratulić,Sudhanshu Mittal,David T. Hoffmann,Samuel Böhm,Robin Tibor Schirrmeister,Tonio Ball,Christian Rupprecht,Thomas Brox
## Background
大语言模型（LLMs）表现出上下文学习（ICL）能力，使得模型能够在不更新模型权重的情况下，仅通过上下文提供的示例来执行新的任务。ICL 在自然语言任务和领域中实现快速适应，但在文本之外的模态中，其出现则较为复杂。本文系统地揭示了LLMs中的支持ICL出现并促进各种模态的机制。研究发现，训练数据序列中的精确令牌重复是ICL的重要因素，这些重复进一步提高了ICL性能的稳定性和降低了它的波动性。同时，研究强调了训练任务难度对ICL出现的重要性。因此，通过应用对该ICL出现的新见解，能够在少量样例学习环境下解锁各种视觉数据集和更具有挑战性的EEG分类任务中的ICL能力。
## Innovation
研究发现了训练数据序列中的精确令牌重复是支持ICL出现的重要因素，并首次强调了训练任务难度对ICL出现的重要性。基于这些新见解，研究解锁了多种视觉数据集和更具挑战性的EEG分类任务中的ICL能力。
## Conclusion
通过分析LLMs中支持ICL出现的策略和机制，研究为非语言模态数据集解锁了ICL能力，这些发现提高对ICL的理论理解，并为未来的研究提供了方向。
# 258. `cs.CL` - LR^2Bench：通过约束满足问题评估大型语言模型的长链反思推理能力 [PDF](https://arxiv.org/pdf/2502.17848), [HTML](https://arxiv.org/abs/2502.17848)
## Authors
Jianghao Chen,Zhenlin Wei,Zhenjiang Ren,Ziyong Li,Jiajun Zhang
## Background
最近大型推理模型（LRMs）的发展显著提升了大型语言模型（LLMs）的推理能力，使其能够通过反思能力（如假设、回溯和自我改进）处理越来越复杂的任务。然而，有效评估这种反思能力仍然具有挑战性，因为缺乏适当的基准。为此，本文引入了LR^2Bench，这是一个新型基准，用于评估LLMs的长链反射推理能力。这个基准包括850个样本，分布在六个包含约束满足问题（CSPs）的任务类别中，这些任务类别对于找到满足所有给定约束的解决方案至关重要。每个类型的任务都侧重于不同的约束模式，如基于知识的、逻辑的和空间的约束，从而提供了对多种问题解决场景的全面评估。我们的广泛评估表明，即使是最先进的LRMs，如DeepSeek-R1和OpenAI o1-preview，在LR^2Bench中的任务上也难以应对，仅达到20.0%和23.6%的准确匹配分数平均值。这些发现突显了当前LLMs在反思推理能力上仍有很大的改进空间。
## Innovation
本文提出了一种新的基准测试LR^2Bench，专门用于评估大型语言模型的长链反射推理能力。该基准测试基于约束满足问题（CSPs），涵盖了六个不同的任务类别，每个类别都专注于不同的约束模式。通过在典型和LRM的两种模型上进行全面评估，展示了最先进的模型在该基准测试上的表现不佳，从而揭示了当前大型语言模型在反思推理能力上的局限性和改进空间。这项工作填补了现有基准在评估复杂推理任务方面的不足。
## Conclusion
LR^2Bench的成功开发及其在评估最先进的大型推理模型上的作用表明，当前的大型语言模型仍需在复杂的反思推理能力方面进行显著改进。该基准测试开辟了新的研究方向，有望推动该领域的发展。
# 259. `cs.CL` - LADM: 使用基于注意力依赖度量的长上下文训练数据选择方法的LLMs [PDF](https://arxiv.org/pdf/2503.02502), [HTML](https://arxiv.org/abs/2503.02502)
## Authors
Jianghao Chen,Junhong Wu,Yangyifan Xu,Jiajun Zhang
## Background
长上下文建模在大语言模型（LLMs）领域越来越受到关注。持续训练使用长上下文数据成为赋予LLMs处理长输入的能力的公认方法。然而，仍然存在测量长上下文训练数据质量的挑战。我们提出了一种基于注意力依赖度量的长上下文数据选择框架LADM，可以从大规模多领域的预训练语料库中高效地识别高质量的长上下文数据。LADM利用注意力机制的检索能力捕获上下文依赖性，确保长上下文数据的质量评估全面。实验结果表明，我们的LADM框架仅通过使用1亿个标记进行持续训练，就能显著提升LLMs在多个长上下文任务中的性能。
## Innovation
该框架使用基于注意力依赖度量的方法来选择高质量的长上下文数据，从大规模多领域的预训练语料库中高效地识别出高质量的长上下文数据，并通过这种方法提升了LLMs在长上下文任务中的性能，且仅需极少量的数据进行持续训练。
## Conclusion
我们的LADM框架显著提高了LLMs在多个长上下文任务中的性能，仅通过使用1亿个标记进行持续训练，证明了该方法的有效性。
# 260. `cs.CL` - 注意力熵是关键因素：基于全注意力预训练语言模型的并行上下文编码分析 [PDF](https://arxiv.org/pdf/2412.16545), [HTML](https://arxiv.org/abs/2412.16545)
## Authors
Zhisong Zhang,Yan Wang,Xinting Huang,Tianqing Fang,Hongming Zhang,Chenlong Deng,Shuaiyi Li,Dong Yu
## Background
大型语言模型在多种语言任务中表现出色，得益于其优秀的长上下文建模能力。常见的上下文建模方法是全自注意力机制，如标准的解码器自注意力Transformer。然而，这种方法对于长序列时效率较低，并且可能忽视输入结构中的内在联系。为了解决这些问题，提出了并行上下文编码的方法，这种方法将上下文分为多个部分并行编码。但由于在训练过程中并不遇到并行模式，直接使用并行编码会导致性能下降，因此需要进一步调查根本原因并提出潜在的缓解措施。
## Innovation
本文详细分析了并行上下文编码的问题，发现异常高的注意力熵是关键因素。此外，提出了两种简单的方法来降低注意力熵，分别是引入注意力陷阱和选择性机制。实验表明，这些方法可以有效降低不规则注意力熵，缩小性能差距。
## Conclusion
本研究认为注意力熵是并行上下文编码的关键因素。通过引入注意力陷阱和选择性机制，可以有效降低不规则注意力熵，进而提升上下文建模机制的效果，为改善并行上下文编码提供了一条新途径。
# 261. `cs.CL` - CogniBench：大型语言模型认知忠诚度评估的法律启发框架及数据集 [PDF](https://arxiv.org/pdf/2505.20767), [HTML](https://arxiv.org/abs/2505.20767)
## Authors
Xiaqiang Tang,Jian Li,Keyu Hu,Du Nan,Xiaolong Li,Xi Zhang,Weigao Sun,Sihong Xie
## Background
现有的基准测试主要关注由大型语言模型生成的“事实性陈述”，这些陈述可以重新表述原始材料，而忽略了涉及从给定背景中进行推理的“认知性陈述”。因此，评估和检测认知性陈述的幻觉仍然具有挑战性。为了解决这一问题，作者借鉴了法律领域评估证据的方法，设计了一个严格框架来评估不同层次的认知性陈述的忠诚度，并构建了CogniBench数据集。
## Innovation
作者设计了一个严格的框架来评估认知性陈述的不同层次的忠诚度，并提供了CogniBench数据集。此外，他们进一步开发了一个易于扩展的自动注释管道，以适应不断演化的大型语言模型，从而生成CogniBench-L数据集，这有助于训练准确的检测器来识别事实性和认知性幻觉。
## Conclusion
CogniBench数据集以及相应的评估框架为评估大型语言模型的认知忠诚度提供了一个有效的工具，有助于改进大型语言模型的理解能力和准确性。
# 262. `cs.CL` - LLM位置泛化背后的计算机制 [PDF](https://arxiv.org/pdf/2503.13305), [HTML](https://arxiv.org/abs/2503.13305)
## Authors
Chi Han,Heng Ji
## Background
大多数自然语言是由词和句子组成的序列。类人的方式，大型语言模型（LLMs）在处理文本位置时表现出灵活性——我们称之为位置泛化现象。它们可以理解位置有变化的文本，并且能够推广到比训练时遇到的更长的文本。这些现象表明LLMs在处理位置时具有宽容性，但它们如何在计算上处理位置相关性仍然很少被研究。本研究将语言现象与LLMs的计算机制联系起来。我们展示了如何LLMs对上述位置变化的容忍度施加一定的计算机制。尽管自我注意机制的设计复杂，但本研究揭示了LLMs学习到一种反直觉的注意力标量解耦合，它们的值与位置相关性和语义重要性的算术总和的近似值之间存在0.959的线性相关性。
## Innovation
研究揭示了大型语言模型（LLMs）在位置泛化过程中学习到一种反直觉的注意力标量解耦合现象，这种现象的出现与随机初始化参数的行为不同，表明这是一种学习行为，而非模型架构的自然结果。这项工作提供了对LLMs位置灵活性的计算解释和标准，并首次将位置泛化与现代LLMs内部机制联系起来。
## Conclusion
研究提出了LLMs位置灵活性背后的计算机制，并基于此提供了计算解释和标准。这项工作为连接位置泛化与现代LLMs内部机制做出了开创性贡献。
# 263. `cs.CL` - 对话用户-AI介入：一种改进LLM响应生成的提示重写研究 [PDF](https://arxiv.org/pdf/2503.16789), [HTML](https://arxiv.org/abs/2503.16789)
## Authors
Rupak Sarkar,Bahareh Sarrafzadeh,Nirupama Chandrasekaran,Nagu Rangan,Philip Resnik,Longqi Yang,Sujay Kumar Jauhar
## Background
人类对话语言模型（LLM）聊天机器人的交互在人们的日常生活和职业生涯中越来越普遍，但许多用户仍然难以获得有用的回应。其中一个原因是用户缺乏有效构建提示以准确传达其信息需求的能力。另外，现有的真实世界对话数据集以及LLM的文字理解能力构成了研究这一问题及其潜在解决方案的独特机会。因此，本文旨在揭示用户查询表达信息需求时存在的不足，并探讨利用LLM重写无效提示的可能性。研究发现，重构成效提示可以改善与对话系统的交互效果，同时保留用户的原始意图。此外，研究还发现，当理解和推断用户意图和目标时，LLM通常需要做出可信度较高的假设。这些发现表明，提示重写可以改善人与AI之间的交互体验，具有广泛的应用潜力。
## Innovation
本文是首次针对真实人类与AI聊天机器人的对话中心研究，旨在探索用户查询表达信息需求方面的不足，并研究使用LLM重新构成无效提示的可能性。研究发现，通过重构成效提示可以改善对话系统中的响应质量，保持用户的原始意图。更重要的是，研究揭示了LLM在解读提示时通常需要做出合理假设，以保证对用户意图和目标的理解。这种方法不仅适用于不同领域的对话场景，还对各种用户意图和不同规模的LLM具有广泛的适用性。
## Conclusion
重新构成无效提示可以改善LLM响应的质量，同时保留用户的原始意图。这种重新构成在长对话中表现出更好的效果，因为可以更准确地做出上下文推断。此外，研究还表明，利用提示重塑作为提高人与AI交互效率的解决方案具有广泛的重要性。
# 264. `cs.CL` - LLaVA-CMoE：向大规模视觉-语言模型的持续专家混合方向 [PDF](https://arxiv.org/pdf/2503.21227), [HTML](https://arxiv.org/abs/2503.21227)
## Authors
Hengyuan Zhao,Ziqin Wang,Qixin Sun,Kaiyou Song,Yilin Li,Xiaolin Hu,Qingpei Guo,Si Liu
## Background
Mixture of Experts (MoE) 架构最近提升了大规模语言模型（LLMs）在持续多模态学习中的可扩展性和适应性。但是，有效地扩展这些模型以适应序列任务仍然具有挑战性。随着新任务的不断出现，简单的模型扩展会导致参数快速增长，而修改共享路由组件往往会导致灾难性遗忘，破坏之前学习的知识。针对这些挑战，我们提出了LLaVA-CMoE，这是一种不需要以前任务重放数据的持续学习框架，既保证了参数效率，又确保了知识的稳健保留。我们的方法引入了一种探针导向的知识扩展机制，该机制使用探针专家动态确定何时何地添加新专家，能够根据任务复杂度进行自适应和最小化的参数扩展。此外，我们提出了一种概率任务定位器，为每个任务分配一个独立的、轻量级的路由器。为了应对推断过程中不知道任务标签的实际问题，我们利用基于VAE的重建策略来通过匹配输入分布识别最合适的路由器，从而自动且准确地分配专家。这种设计减轻了路由冲突和灾难性遗忘，使持续学习更加稳健，无需明确的任务标签。在CoIN基准测试上进行的大量实验涵盖了八种不同的VQA任务，展示了LLaVA-CMoE在紧凑模型大小下具有强大的持续学习性能，与现有方法相比，显著减少了遗忘和参数开销。这些结果展示了我们的方法在大规模语言模型参数高效持续学习中的有效性和可扩展性。我们的代码预计很快将开源。
## Innovation
我们提出了LLaVA-CMoE，这是一种持续学习框架，不需要以前任务的重放数据，且不牺牲参数效率，同时保持知识的稳健保留。我们的创新之处在于引入了一种探针导向的知识扩展机制，能够在任务复杂性变化时动态进行最小化的参数扩展。此外，我们还设计了一种概率任务定位器为每个任务分配独立的、轻量级的路由器，通过匹配输入分布自动准确地分配专家。这有力地减轻了路由冲突和灾难性遗忘问题，使得持续学习更加稳健，无需明确的任务标签。我们的方法展示了在大规模语言模型中实现参数高效持续学习的有效性和可扩展性。
## Conclusion
通过LLaVA-CMoE的实验评估，在多个视觉-语言任务上的结果表明，这种持续学习方法在保持紧凑模型大小的同时，提供了强大的持续学习性能，显著减少了遗忘和参数开销。我们的方法展示了在大规模语言模型中实现参数高效持续学习的有效性和可扩展性。该研究为大规模视觉-语言模型的持续学习提供了新的视角和实用解决方案。
# 265. `cs.CL` - 从来源到引用的嘈杂路径：衡量学者如何与过往研究互动 [PDF](https://arxiv.org/pdf/2502.20581), [HTML](https://arxiv.org/abs/2502.20581)
## Authors
Hong Chen,Misha Teplitskiy,David Jurgens
## Background
学术引用广泛用于评估研究和追踪知识流动，但这些应用通常依赖于未经处理的引文计数，忽视了引文类型之间的差异。特别是，引用可能因为引文研究中的原始知识被重新表述、总结或重新解读（可能错误地），导致从被引论文到引用论文的信息变化程度有所不同。本文通过引入大规模引文忠实度计算管道，解决了这一问题。管道通过全文字文件识别引用论文中的引文及所引用论文中的相应声明，并应用监督模型进行句子层面的忠实度测量。研究结果显示，更近期和更相关的研究、更易获取的研究，以及作者h指数较低且团队规模适中的研究，其引文忠实度较高。此外，通过准实验建立了“电话效应”：当引用论文的忠实度较低时，后续引用该引用论文及原始论文的论文对其原始声明的忠实度也会降低。这一发现揭示了引文忠实度的系统性差异，强调单独依赖引文数量带来的分析局限性及其对证据传递的潜在扭曲效应。
## Innovation
引入大规模引文忠实度计算管道，使用全文字文件识别引用句并进行句子层面的引文忠实度测量。发现多项影响引文忠实度的因素，提出“电话效应”，并揭示了引文忠实度的系统性差异，提升了学术引用分析方法的精确性与全面性。
## Conclusion
这项研究揭示了在评估研究时对单一引文数量依赖的局限性，指出引文忠实度对科学研究的影响，强调了对引文类型和忠实度的重要性，以及在后续研究中使用高质量和高忠实度的引文的重要性。
# 266. `cs.CL` - mSTEB: 大量多语言评估LLMs在语音和文本任务上的表现 [PDF](https://arxiv.org/pdf/2506.08400), [HTML](https://arxiv.org/abs/2506.08400)
## Authors
Luel Hagos Beyene,Vivek Verma,Min Ma,Jesujoba O. Alabi,Fabian David Schmidt,Joyce Nakatumba-Nabende,David Ifeoluwa Adelani
## Background
大型语言模型（LLMs）在多种任务上表现出了显著的能力，包括多模态设置如语音。然而，这些模型的评估主要局限于英语和其他资源丰富的语言。对于低资源语言，缺乏标准化的评估基准。本文研究了这一问题，并引入了mSTEB，一个新的基准，用于评估LLMs在语言识别、文本分类、问答和翻译任务上的表现，涵盖了语音和文本模态。研究表明，高资源语言和低资源语言在性能上存在显著差距，尤其是非洲和美洲/大洋洲的语言。研究发现表明，需要更多的投资来解决这些语言在LLMs覆盖率上的不足和代表性不足问题。
## Innovation
引入了一个新的基准mSTEB，用于评估LLMs在多种跨模态任务（包括语音和文本）中的性能，特别是针对低资源语言的表现。评估结果显示了不同资源语言之间的性能差距，强调了对低资源语言的更多关注和投资需求。
## Conclusion
研究展示了高资源和低资源语言之间的性能差距，特别是非洲和美洲/大洋洲的语言。研究结果表明，在LLMs的开发和应用中，对低资源语言的投资和探索仍需加强，以提高其全面性和代表性。
# 267. `cs.CL` - 超越token：语义与统计视角下的LLM公平性量化 [PDF](https://arxiv.org/pdf/2506.19028), [HTML](https://arxiv.org/abs/2506.19028)
## Authors
Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy
## Background
大语言模型（LLMs）生成的回答往往带有固有的偏见，这影响了它们在真实世界应用中的可靠性。现有的评估方法往往未能注意到长文本回答中的偏见以及LLM输出的固有变异性。鉴于此，研究提出了细粒度语义计算（FiSCo）框架，通过检测不同群体回答之间的细微语义差异来评估LLM的群体级公平性。这种方法与以往工作侧重于情绪或token级别的比较不同，FiSCo通过命题层的分析和内涵检查来评估意义的一致性，进而通过统计假设检验比较群体间的相似性和差异性，以检测并量化落到实处的微妙偏见。
## Innovation
研究提出了细粒度语义计算（FiSCo）框架，这是一种新颖的统计框架，用于通过检测长文本回答中的细微语义差异来评估群体级公平性。FiSCo框架通过命题层分析和内涵检查来评估不同群体回答的意义一致性，这种方法超越了表面层次的分析，能够在不影响由于LLM固有的随机性导致的数据变化影响下更可靠地识别微妙偏见。研究还正式定义了一个新的群体反事实公平性，并在涉及性别、种族和年龄等不同维度的数据集上进行了验证，结果显示FiSco在发现微妙偏见方面优于各种评估指标。“
## Conclusion
实验表明，FiSCo在检测细微偏见方面更加可靠，同时减少了由于LLM固有的随机性对数据变化的影响，并且在多个方面超过了各种评估指标。研究提出的细粒度语义计算框架为评估LLM的群体公平性提供了一种新的统计和语义方法，有望在未来进一步改进LLM的应用。
# 268. `cs.CL` - LLM生成数据中哪些因素重要：多样性和其对模型微调的影响 [PDF](https://arxiv.org/pdf/2506.19262), [HTML](https://arxiv.org/abs/2506.19262)
## Authors
Yuchang Zhu,Huazhen Zhong,Qunshu Lin,Haotong Wei,Xiaolong Sun,Zixuan Yu,Minghao Liu,Zibin Zheng,Liang Chen
## Background
近年来，大型语言模型（LLMs）的生成能力显著提升，在这些模型生成的数据用于训练下游模型方面，已展现出减轻特定领域数据稀缺性和减少耗时标注的潜力。然而，最近的研究表明，反复利用自我生成的数据进行训练会导致模型崩溃，即模型性能随时间下降。尽管对LLM生成数据的影响进行了大量研究，但这些研究通常忽略了数据多样性，这是数据质量的一个关键因素。本文旨在探讨LLM生成数据的多样性对下游模型性能的影响，并具体研究在LLM生成数据中掺入不同比例的数据如何影响模型的性能。实验结果显示，适度多样化的生成数据在数据量不足的情况下可增强模型性能，而高度多样化的生成数据则具有负面影响。
## Innovation
本文的研究创新在于首次系统性地探讨并验证了LLM生成数据的多样性如何影响下游模型性能，特别是探讨了在不同比例混合使用LLM生成数据和真实数据对模型微调的影响效果，从而填补了相关研究领域的空白。
## Conclusion
实验结果表明，在轻微分布变化的情况下，适度多样的LLM生成数据在数据稀缺的情况下有助于提高模型性能，而高度多样化的数据反而对模型性能产生负面影响。这为未来的研究和实践中如何合理利用LLM生成数据提供了有价值的经验借鉴，有助于提升模型在实际应用中的效果。
# 269. `cs.CL` - FluoroSAM：一种可用于灵活X射线图像分割的语言提示基础模型 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
尽管以前的努力已经产生了针对特定任务的模型以解决狭义问题，但将这些模型扩展到更广泛的应用仍然需要额外的数据、标注和训练时间。为了解决这一问题，一些研究提出了语言对齐的基础模型（LFMs），这些模型通过训练大量高度变异的图像和文本数据来实现广泛适用性。当前的基础模型主要针对数据集丰富且标注全面的医学影像分析场景，但X射线成像模态具有高度变异的图像外观和应用范围，从诊断胸部X射线到干预性透视，数据的获取也有很大差异。因此，作者提出了FluoroSAM，这是一种基于Segment Anything Model的新型变体，专门训练用于多种人类解剖结构、成像几何形状和视角下的合成X射线图像，并结合了文本嵌入的矢量量化以实现自然语言提示下的分割能力。
## Innovation
FluoroSAM首次提出了一种针对X射线成像模态的语言提示基础模型，通过大量合成X射线图像进行训练，涵盖了广泛的人类解剖结构、成像几何形状和视角。该模型通过矢量量化（VQ）文本嵌入来提高语言提示下的分割能力。这使得FluoroSAM能够在X射线图像获取和分析中提供丰富的自然语言交互，这是现有技术所无法实现的。
## Conclusion
FluoroSAM展示了在真实X射线图像上的高性能，并且能够通过自然语言提示分割多样化的人体结构和工具，为X射线图像中的人机交互提供了关键支持。通过提供代码，作者旨在促进该领域的进一步研究和发展。
# 270. `cs.CL` - SMAR：MoE架构下的一种软模态感知路由策略，用于保留语言能力的多模态大型语言模型 [PDF](https://arxiv.org/pdf/2506.06406), [HTML](https://arxiv.org/abs/2506.06406)
## Authors
Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Wei Chen,Fangxiang Feng,Xiaojie Wang
## Background
Mixture of Experts (MoE) 架构已成为大规模语言模型扩展的关键方法，引起了对其在多模态任务中应用的兴趣。现有的构建多模态 MoE 模型的方法要么导致高额的训练成本，要么导致在调整预培训模型时语言能力下降。已有研究方法主要存在这两个问题，限制了 MoE 在多模态应用中的有效使用.
## Innovation
本文提出了一种新颖的正则化技术 Soft ModalityAware Routing (SMAR)，利用 Kullback Leibler 散度控制不同模态的路由概率分布，从而促进专家专业化，同时不会修改模型架构或大量依赖文本数据。实验表明，SMAR 在仅使用 2.5% 纯文本的情况下，仍能保留 86.6% 的语言能力，多模态性能出色，优于基线方法，提出了一种实用和高效的方法来平衡多模态差异化和语言能力之间的关系.
## Conclusion
SMAR 保留了语言能力的同时，在多模态 MoE 模型中平衡了模态差异化。
# 271. `cs.CL` - 回收网络：一种增强语言模型预训练数据质量和数量的方法 [PDF](https://arxiv.org/pdf/2506.04689), [HTML](https://arxiv.org/abs/2506.04689)
## Authors
Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li
## Background
大型语言模型的性能随着模型规模和数据量的增加而提高。实践中，预训练依赖于大量的网页爬取，利用几乎所有的公共网络数据源。但这些自然数据的增长速度没有跟上计算资源的供应速度。高质量文本的数据更有限，数据过滤管道通常会移除高达99%的初始爬取数据以达到最佳效果。如何突破预训练数据规模中的“数据墙”，发展新的数据利用方法成为一个关键问题。本文通过研究现有过滤过程中的数据再利用方式，提出了一种方法REWIRE（从受指导重写中回收网络），旨在改善低质量文档的质量，增强其在模型训练中的有用性，从而增加合成数据在最终预训练数据集中的代表性。实验结果显示，在DCLM基准模型规模分别为1B、3B和7B的情况下，混合高质量原始文本和重写后的文本比仅使用过滤后的网络数据训练分别能提高22种不同任务上的性能1.0%、1.3%和2.5%。同时，这种混合训练方法比获取两倍的网络数据更加有效。进一步分析显示，大约82%的混合文本来自转化低质量文档，促使其转变为有用的数据。REWIRE在与生成合成数据相关的其他方法（如维基百科风格的重写、问答合成及知识提取）的比较中表现出更高的效果。这些结果表明，回收网络文本可能是简单而有效的方法，可以增强预训练数据的质量和数量。
## Innovation
本文创新性地提出了一种名为REWIRE的方法，旨在通过指导重写低质量的网络文本，将其转化为高质量的数据，从而提高语言模型预训练数据的质量和数量。REWIRE方法通过转化低质量文档，有效地增加了预训练数据集中的合成数据比例，并在多个任务上验证了其优于现有方法的效果。这种方法简单有效，能够显著改善语言模型的学习过程和最终性能。
## Conclusion
实验表明，将高质量原始文本和经过RWIRE处理的重写文本混合进行训练，能显著改善语言模型在各种任务上的表现。这种混合数据的训练方法比仅仅使用过滤后的网络数据更加有效，而它的效果甚至超过了可以获得两倍网络数据量的情况。通过转化大量的低质量文档，RWIRE方法不仅提高了数据的有效利用率，还证明了回收网络文本作为简单而有效的预训练数据增强方法的巨大潜力。
# 272. `cs.CL` - WAFFLE: 细化多模态模型以实现自动前端开发 [PDF](https://arxiv.org/pdf/2410.18362), [HTML](https://arxiv.org/abs/2410.18362)
## Authors
Shanchao Liang,Nan Jiang,Shangshu Qian,Lin Tan
## Background
网页开发涉及将UI设计转化为功能性网页，对于初学者和经验丰富的开发人员来说都可能因为HTML的层级结构和样式复杂性而具有挑战性。虽然大型语言模型（LLMs）展示了生成源代码的潜力，但在UI到HTML代码生成中仍存在两大挑战：一是有效表示HTML的层级结构以供LLMs理解；二是将视觉化的UI设计与基于文本的HTML代码格式进行对接。
## Innovation
本文介绍了一种名为Waffle的新微调策略。Waffle包括结构感知注意力机制来提升LLMs对HTML结构的理解，以及对比学习微调方法来调整LLMs对UI图像和HTML代码的理解一致性。使用Waffle微调的模型在新的基准测试WebSight-Test和现有基准测试Design2Code上的HTML匹配度提高了9.00个百分点，CW-SSIM提升了0.0982，CLIP升高了32.99，LLEM提升了27.12个百分点，表现出比当前微调方法更好的性能。
## Conclusion
通过Waffle策略，研究提升了LLMs对HTML代码和UI设计的理解匹配度，证明了其在自动化前端开发中的优越性。
# 273. `cs.CL` - 在症状检查器中评估罕见疾病诊断性能：合成案例模拟方法 [PDF](https://arxiv.org/pdf/2506.19750), [HTML](https://arxiv.org/abs/2506.19750)
## Authors
Takashi Nishibayashi,Seiji Kanazawa,Kumpei Yamada
## Background
症状检查器向用户提供个性化医疗信息。为了防止算法更新导致性能退化，症状检查器开发者必须在部署前评估每种疾病的诊断性能变化。然而，获取足够的评估数据以涵盖罕见疾病非常困难，人工创建大量临床案例摘要既昂贵又不切实际。本研究提出并验证了一种新的合成案例模拟方法，以评估症状检查器算法更新后的个别罕见疾病的诊断性能变化。该方法使用Human Phenotype Ontology (HPO)中的疾病-表型注释来生成合成案例，这些案例用于模拟症状检查器的访谈，以估计算法更新对实际诊断性能的影响。
## Innovation
该研究提出了一种创新的方法，称为合成案例模拟方法，用于在症状检查器算法更新后评估个别罕见疾病的诊断性能变化。这种方法利用Human Phenotype Ontology (HPO)中的疾病-表型注释生成合成案例生成方法，模拟症状检查器访谈以估计算法更新对实际诊断性能的影响。通过回顾性评估方法的有效性，结果显示该方法可以预测部署后性能变化，特别是对于在HPO中有频率信息的疾病（n=5），变化召回@8的$R^2$为0.831（p=0.031），变化精确度@8的$R^2$为0.78（p=0.047）。
## Conclusion
该方法允许开发者使用一个公开且专家创建的知识库，对个别罕见疾病的症状检查器算法更改进行预部署评估。这种方法既透明又低成本，使开发者能够高效地提高罕见疾病的诊断性能，可能有助于早期诊断的支持。
# 274. `cs.CL` - VICCA：生成报告中对人体胸部X射线异常的视觉解释与理解无需人类反馈 [PDF](https://arxiv.org/pdf/2501.17726), [HTML](https://arxiv.org/abs/2501.17726)
## Authors
Sayeh Gholipour Picha,Dawood Al Chanti,Alice Caplier
## Background
随着人工智能（AI）在医疗保健中的重要性日益增强，可解释性和可信度高的模型的需求变得尤为重要。当前，胸部X光（CXR）报告生成系统往往缺乏在缺乏专家监督的情况下验证输出的机制，这引发了关于可靠性和可解释性的担忧。因此，迫切需要一种新的方法来提升AI生成医疗报告的语义对齐和定位准确性。
## Innovation
本文提出了一种新颖的跨模态框架，旨在增强AI生成医疗报告的语义对齐和定位准确性。该框架集成了两个关键模块：词法接地模型和文本到图像扩散模块。通过对比原始图像和生成图像的特征，引入了一种双重评分系统：一个是定位准确性的评分，另一个是语义一致性的评分。这种创新方法显著优于现有技术，实现了病理定位和文本到图像对齐的最先进结果。将词法接地与扩散模型整合，并配以双重评分评价系统，为验证报告质量提供了一个稳健机制，从而推动了更可信和透明的医疗影像AI的发展。
## Conclusion
本文提出的新框架和评分系统在病理定位和文本到图像对齐方面取得了最先进的结果，为生成AI报告的质量提供了验证机制，推动了医疗影像AI的可信度和透明度的发展。
# 275. `cs.CL` - 通过奖励图推理过程使大型语言模型成为更通用的推理者 [PDF](https://arxiv.org/pdf/2503.00845), [HTML](https://arxiv.org/abs/2503.00845)
## Authors
Miao Peng,Nuo Chen,Zongrui Suo,Jia Li
## Background
尽管在大型语言模型（LLMs）方面取得了显著进步，但在LLMs中开发高级推理能力仍然是一个主要挑战。尽管过程奖励模型（PRMs）在增强数学推理方面的效果显著，但在更广泛的推理领域中的应用研究仍然不足，主要原因是手动创建逐步监督成本高昂。图推理问题是一个需求复杂的多步推理任务，使用现有的图算法可以实现自动化的逐步数据生成。研究基于此背景，构建了最大的图推理问题数据集GraphSILO，采用自动任务导向轨迹和蒙特卡洛树搜索（MCTS）生成了带有精细粒度逐步标注的详细推理步骤。研究在此基础上，训练了GraphPRM，这是第一个为图推理问题设计的PRM，并从推理时间和强化学习（通过直接偏好优化，即DPO）两个关键角度评估了其效果。实验结果表明，GraphPRM在13个图推理任务中显著提升了LLM的性能，对于Qwen2.5-7B的表现提高了9%，展示了良好的跨领域适用性。研究还指出图基线推理奖励在一些新的图推理数据集和新的推理领域（如数学问题解决）中的应用潜力。
## Innovation
研究通过构建GraphSILO数据集，训练了GraphPRM模型，这是第一个专为图推理问题设计的PRM。研究不仅在多个图推理任务中验证了GraphPRM的有效性，还在推理时间和强化学习方面进行了评估。研究强调了PRMs在跨领域推理中的潜力，推动了更灵活和有效的LLMs的发展。
## Conclusion
研究结果表明，通过奖励图推理过程，可以显著提升大型语言模型的推理能力，并且表现出跨领域的应用价值。这为更灵活和有效的LLMs的发展开辟了道路。
# 276. `cs.CL` - 语言模型能替代程序员编程吗？REPOCOD 说‘尚未’ [PDF](https://arxiv.org/pdf/2410.21647), [HTML](https://arxiv.org/abs/2410.21647)
## Authors
Shanchao Liang,Yiran Hu,Nan Jiang,Lin Tan
## Background
近年来，一些仓库级别的代码生成基准测试，如 CoderEval、DevEval、RepoEval、RepoBench 和 LongCodeArena，已经出现，用于评估大型语言模型（LLMs）的能力，而不仅仅是在 HumanEval 和 MBPP 这样的独立基准测试中。但现有基准测试存在的问题是缺乏真实世界编程任务的代表性，因为这些基准测试主要包含简短的完成部分、合成示例或仅关注小型代码库。因此，本文旨在创建 REPOCOD，旨在包含复杂任务，且这些任务具有现实世界的依赖关系，并针对大型项目；同时使用适当的指标来评估源代码。REPOCOD 包括来自 11 个流行项目的 980 个全功能生成任务，其中 50.8% 需要仓库级的上下文。每一个实例还包括 314 个开发人员编写的测试案例以获得更准确的评价。这种基准测试结果缺乏让 LLM 达到高通过率，表明更强大的 LLM 对于开发人员在实际软件开发中的帮助是必要的。此外，文章发现检索增强的生成模型在结果上优于使用目标函数依赖作为上下文的方法。因此，该基准测试无法证明 LLM 已经能够替代程序员进行编程。
## Innovation
本文提出了 REPOCOD，一个 Python 代码生成基准测试，旨在包含真实世界中的复杂任务及适当的评估指标，引入了更大范围的综合测试案例以改进评价。此外，该基准测试发现在 REPOCOD 上拥有较低通过率的 LLM，表明性能增强的 LLM 对开发人员的实际软件开发是必要的，检索增强生成方法优于直接使用目标函数依赖作为上下文。
## Conclusion
当前的 LLMs 在代表复杂的现实世界编程任务的 REPOCOD 基准测试中表现不佳，表明需要进一步改进，但检索增强生成方法在这方面显示出更好的前景。因此，目前 LLMs 还不能完全替代程序员进行编程，但它们可以在软件开发过程中提供强大的支持。
# 277. `cs.CL` - PP-DocBee2：提高效率的数据增强的多模态文档理解基线 [PDF](https://arxiv.org/pdf/2506.18023), [HTML](https://arxiv.org/abs/2506.18023)
## Authors
Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu
## Background
该报告介绍了一个名为PP-DocBee2的高级版本，用于增强多模态文档的理解能力，该版本建立在大型多模态模型架构上，旨在克服其前身的局限性并改进关键技术。通过使用大规模的多模态预训练模型评估数据并应用新颖的统计标准过滤异常值，以确保高质量的训练数据。此外，通过分解ViT表示能力和引入新颖的特征融合策略，提升复杂推理能力，从而进一步改进了文档理解能力。
## Innovation
1. 大规模多模态预训练模型数据质量优化策略：通过应用大规模多模态预训练模型评估数据并使用新颖的统计标准筛选异常值，确保高质量的训练数据。2. 新颖的特征融合策略：灵感来自于多模态模型中未充分利用的中间特征，通过分解ViT表示能力和引入新的特征融合策略，提升复杂推理能力。3. 性能和效率的提升：相较于以往版本，PP-DocBee2在中文商业文档上达到了11.4%的性能提升，并将推断延迟降低了73.0%。
## Conclusion
PP-DocBee2通过引入高质量数据评估和筛选策略，结合新颖的ViT特征融合方法，大幅提升文档理解的准确率和速度。源代码和预训练模型已经在指定的网址上公开。
# 278. `cs.CL` - Confucius3-Math：针对中国中学数学学习的轻量高性能推理语言模型 [PDF](https://arxiv.org/pdf/2506.18330), [HTML](https://arxiv.org/abs/2506.18330)
## Authors
Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan
## Background
介绍了Confucius3-Math，这是一种开源的大规模语言模型，具有14B参数，可以在单个消费级GPU上高效运行，并在一系列数学推理任务中取得了SOTA性能，甚至超过了具有显著更大规模的许多模型。该模型旨在通过AI增强教育和知识传播，特别专注于中国K-12学生和教师的数学学习。该模型通过大规模强化学习（RL）后训练构建，低成本地解决主流的中国K-12数学问题，且与国家课程保持一致。
## Innovation
提出三项技术创新：目标熵正则化、近期样本恢复和政策特定的难度加权。这些创新包括新的熵正则化、新颖的数据调度策略和改进的群体相对优势估计器。这些创新共同显著稳定了RL训练、提高了数据效率和提升了性能。
## Conclusion
这项工作证明了在特定领域以低成本建立强大推理模型的可行性。模型和代码已经开源。
# 279. `cs.CL` - 科学家的第一场考试：通过感知、理解和推理测试MLLM的认知能力 [PDF](https://arxiv.org/pdf/2506.10521), [HTML](https://arxiv.org/abs/2506.10521)
## Authors
Yuhao Zhou,Yiheng Wang,Xuming He,Ruoyao Xiao,Zhiwei Li,Qiantai Feng,Zijie Guo,Yuejin Yang,Hao Wu,Wenxuan Huang,Jiaqi Wei,Dan Si,Xiuqi Yao,Jia Bu,Haiwen Huang,Tianfan Fu,Shixiang Tang,Ben Fei,Dongzhan Zhou,Fenghua Ling,Yan Lu,Siqi Sun,Chenhui Li,Guanjie Zheng,Jiancheng Lv,Wenlong Zhang,Lei Bai
## Background
科学研究越来越多地依赖于基于丰富科学数据和特定领域专业知识的复杂多模态推理。虽然目前的MLLM基准主要集中在评估其知识理解能力，但对其感知和推理能力的评估存在不足。这项研究提出了科学家的第一场考试（SFE）基准，旨在通过三个相互关联的层次来评估MLLM的科学认知能力：科学信号感知、科学属性理解、科学比较推理，涵盖66个多模态任务，涉及五个高价值学科。
## Innovation
这项研究创新地提出了SFE基准，该基准通过三个层次评估MLLM的科学认知能力：科学信号感知、科学属性理解、科学比较推理。通过这个基准测试，揭示了当前最先进的GPT-o3和InternVL-3在SFE上分别仅达到34.08%和26.52%的表现，说明MLLM在科学领域的认知能力有显著提升空间。
## Conclusion
希望从SFE获得的见解能够促进AI增强科学研究的发展。
# 280. `cs.CL` - Aug2Search：利用大型语言模型生成的合成数据增强的Facebook Marketplace搜索 [PDF](https://arxiv.org/pdf/2505.16065), [HTML](https://arxiv.org/abs/2505.16065)
## Authors
Ruijie Xi,He Ba,Hao Yuan,Rishu Agrawal,Yuxin Tian,Ruoyan Kong,Arul Prakash
## Background
嵌入式检索（EBR）是现代搜索引擎的重要技术，能够实现搜索查询与相关结果的语义匹配。然而，像Facebook Marketplace这样的平台上缺乏足够的多样性和细节的搜索日志数据，限制了EBR模型捕捉复杂搜索模式的能力。为了解决这一问题，本文提出了一种名为Aug2Search的新框架，利用生成式人工智能（GenAI）模型生成的合成数据，在多模态和多任务框架下优化查询-产品相关性。该框架使用大型语言模型（LLMs）生成高质量的合成数据，并分析其对提高EBR模型性能的影响。
## Innovation
引入了一种新的EBR框架Aug2Search，利用了生成式人工智能模型生成的合成数据，采用多模态和多任务方法优化查询和产品相关性。特别地，结合了大型语言模型（LLMs）在生成高质量合成数据方面的应用，并评估了合成数据对EBR模型性能的提升效果。通过实验发现，仅使用合成数据训练的模型在某些情况下比使用原始数据或原始数据与合成数据混合训练的模型性能更好。
## Conclusion
研究结果表明，Llama模型生成的合成查询和列表具有高度的一致性、相关性和多样性，并且幻觉水平较低。使用1亿个合成数据样本，Aug2Search在ROC_AUC指标上实现了最高提高4%的效果，证明了该方法的有效性。
# 281. `cs.CL` - 经过训练的嵌入导出的注意力证明选择重要标记 [PDF](https://arxiv.org/pdf/2505.17282), [HTML](https://arxiv.org/abs/2505.17282)
## Authors
Diyuan Wu,Aleksandr Shevchenko,Samet Oymak,Marco Mondelli
## Background
语言模型中的词嵌入在实践中起着关键作用，但其理论理解仍然有限。本文通过梯度下降来描述嵌入结构，研究了一层softmax注意模型及其线性头对二元分类的影响，来填补这一理论空白。
## Innovation
研究发现，经过单步梯度训练后，词嵌入能够根据数据集出现的频率与输出向量对齐，这意味着它们已经捕捉到了词的重要性和出现频率。在训练P值直至收敛后，softmax会选出句子中重要的词（即对标签有预测性的词），所得到的cls词嵌入会最大化这种选择的边距。实际数据集上的实验结果与理论预测相符。此研究通过实验证实了该结论，为理解和优化词嵌入提供了新的见解。
## Conclusion
研究表明，在经过训练的嵌入导出的attention机制中，模型能够自动选出句子中对预测标签重要的词，并且所选择的cls嵌入能够最大化这些重要词的选择边距。
# 282. `cs.CL` - NLP任务中的治疗：临床心理学家对CBT中的LLMs和人类同伴的比较 [PDF](https://arxiv.org/pdf/2409.02244), [HTML](https://arxiv.org/abs/2409.02244)
## Authors
Zainab Iftikhar,Sean Ransom,Amy Xiao,Nicole Nugent,Jeff Huang
## Background
研究发现，大型语言模型（LLMs）在生成单一、孤立的共情回应时优于人类咨询师，但在会话层面的行为尚未得到充分研究。本研究比较了人类咨询师与由同伴咨询师团队提示的大规模语言模型在进行单次认知行为治疗（CBT）会话时的行为。研究采用混合方法，分为三个阶段：一是长达一年的文本支持平台中的民族志研究，七个咨询师迭代优化基于CBT的提示；二是人类咨询师会话的手动模拟，采用CBT提示的LLM，使用完整的患者对话和背景笔记；三是由三名临床心理学家使用CBT技能量表评估人类和LLM会话的效果。研究表明，在关系策略方面，人类咨询师表现出色，如闲聊、自我披露和文化背景的语言，这导致更高的共情、合作和用户更深层次的反思。而LLM咨询师在CBT技术程序上的依从性较高，但在维持合作、误解文化线索和有时生产“虚假共情”方面存在问题，即公式化的温暖可能会增加用户对真诚人类关怀的期望。
## Innovation
本研究创新性地将治疗这一领域作为自然语言处理（NLP）任务来探讨，并通过详细的民族志研究、手动模拟和专家评估比较了LLMs和人类同伴在CBT中的表现，揭示了两者在会话层面的不同优势和局限性。研究强调了治疗过程不能简单地归结为一个独立的NLP任务，而是需要精心设计的人机协作流程，即LLMs可以提供基于证据的技术支持，而人类同行可以提供关系支持。
## Conclusion
研究发现，尽管LLMs在生成单一共情回应方面的表现优于人类咨询师，但在会话领导能力方面更加有限，表明治疗不能简单地转换为一个独立的NLP任务。研究呼吁设计精确的人机协作工作流程，在可扩展支持中体现出人类和AI的互补优势。本研究确定了具体的系统设计机会和伦理守则，以促进这种混合系统的健康发展。
# 283. `cs.CL` - OmniGen2：探索高级多模态生成 [PDF](https://arxiv.org/pdf/2506.18871), [HTML](https://arxiv.org/abs/2506.18871)
## Authors
Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu
## Background
OmniGen2是一个多功能和开源的生成模型，旨在统一处理多种生成任务，包括文本到图像、图像编辑和上下文生成。与OmniGen v1相比，OmniGen2采用了针对文本和图像模态的两个独立解码路径，并且使用了不共享的参数和解耦的图像分词器，这使得OmniGen2可以基于现有跨模态理解模型进行构建，而无需重新适应VAE输入，从而保持了原始的文本生成能力。为了支持OmniGen2的训练，作者构建了包括图像编辑和上下文生成数据的综合数据构建管道，并引入一种专为图像生成任务设计的反射机制，基于OmniGen2构建了专用的反射数据集。尽管参数规模相对较小，OmniGen2在多个任务基准测试中表现出竞争性的结果，特别是在文本到图像和图像编辑任务中。为了进一步评估上下文生成，也称为主题驱动任务，引入了名为OmniContext的新基准。OmniGen2在开放源代码模型中的表现保持了一致性最佳。
## Innovation
OmniGen2采用了两个独立的解码路径，针对文本和图像模态使用不共享的参数和解耦的图像分词器，这使得它可以基于现有的跨模态理解模型构建模型，而无需重新适应VAE输入，从而保持了原始的文本生成能力。此外，引入了专门适用于图像生成任务的反射机制，并基于OmniGen2构建了专用的反射数据集。
## Conclusion
尽管参数规模相对较小，OmniGen2在多个任务基准测试中表现出竞争性的结果，特别是在文本到图像和图像编辑任务中。针对上下文生成，也称为主题驱动任务，引入了名为OmniContext的新基准。OmniGen2在开放源代码模型中的表现保持了一致性最佳。作者将发布模型、训练代码、数据集和数据构建管道以支持该领域的未来研究。
# 284. `cs.CL` - GlyphPattern: 视觉语言模型的抽象模式识别基准 [PDF](https://arxiv.org/pdf/2408.05894), [HTML](https://arxiv.org/abs/2408.05894)
## Authors
Zixuan Wu,Yoolim Kim,Carolyn Jane Anderson
## Background
基于强大大型语言模型的视觉-语言模型（VLMs）在跨视觉和文本数据推理方面取得了快速进展。虽然VLMs在训练上表现出色，但我们的结果突显了抽象模式识别中的核心挑战。为此，我们引入了GlyphPattern数据集，包含318个人类编写的视觉模式描述，来自40种书写系统和三种视觉呈现风格。GlyphPattern旨在评估VLMs的抽象模式识别能力，要求模型理解和判断对视觉模式的自然语言描述。这些模式源自大规模认知科学对人类书写系统的研究，因此富含空间参考和成分性。
## Innovation
我们提出了GlyphPattern数据集，该数据集为评估VLMs的抽象模式识别能力提供了基准。这些视觉模式来自大规模的认知科学研究，展现了丰富的空间参考和成分性。实验表明即使是最先进的VLMs（如GPT-4o的准确率仅为55%），在少量提示下也仅取得微小的进步。详细的错误分析揭示了模型在视觉处理、自然语言理解和模式泛化等多个层面面临的主要挑战。
## Conclusion
我们的研究表明，VLMs在抽象模式识别方面面临着显著挑战，尤其是对于涵盖人的书写系统的视觉模式。这些挑战涉及到视觉处理、自然语言理解和模式泛化的多个层面。这些发现对于VLMs的进一步改进和研究具有重要意义。
# 285. `cs.CL` - 思考锚点：哪一步LLM推理步骤更重要？ [PDF](https://arxiv.org/pdf/2506.19143), [HTML](https://arxiv.org/abs/2506.19143)
## Authors
Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy
## Background
大语言模型在许多领域已取得最先进的性能，但这些模型的长段推理链条带来了可解释性挑战，因为每个生成词都依赖于所有之前的词，使得计算难以分解。本文认为，从句子级别分析推理轨迹是一个有前景的方法来理解推理过程。通过三种互补的归因方法，文章探讨了哪些推理步骤对最终答案的影响最大：（1）一种黑盒方法，通过比较模型生成该句子或意义不同的句子时的最终答案变化，以衡量每个句子的反事实重要性；（2）一种白盒方法，通过聚合句子对之间的注意力模式，识别由于“接收者”注意力头而收到不成比例关注的“广播”句子；（3）一种因果归因方法，通过抑制对一个句子的关注并测量对每个后续句子词的影响来测量句子之间的逻辑联系。
## Innovation
文章提出了三种互补的归因方法，以从句子级别分析大语言模型的推理过程，这些方法用于衡量句子的重要性及其对后续推理的影响。具体而言，三种方法通过不同的侧重点来分析句子级别的推理过程，包括反事实重要性分析、注意力模式聚合和因果分析，揭示了哪些推理步骤（如规划或回溯句子）具有显著影响。此外，文章提供了一个开源工具来可视化这些方法的结果，并通过案例研究展示了在多步推理中的应用。这种方法说明了句子级别分析在更深入了解推理模型中的潜力。
## Conclusion
句子级别的分析方法在理解大语言模型的推理过程中具有很大的潜力，可以揭示关键的推理步骤（如规划或回溯句子），这些步骤在后续推理中具有重要影响。同时，通过多方法研究一致性证明了这种方法的有效性，使得研究人员能够更好地理解大语言模型的推理机制。
# 286. `cs.CV` - 基于计算机视觉的农用喷雾器臂位移自动化定量方法 [PDF](https://arxiv.org/pdf/2506.19939), [HTML](https://arxiv.org/abs/2506.19939)
## Authors
Aryan Singh Dalal,Sidharth Rai,Rahul Singh,Treman Singh Kaloya,Rahul Harsha Cheppally,Ajay Sharda
## Background
在使用自行走农业喷雾器进行农业生产时，喷雾率误差仍旧是一个值得关注的问题，而喷雾臂的不稳定正是造成这一问题的主要原因之一。尤其是当喷雾臂宽度达到38米并配合30公里/小时的行驶速度、不规则的地形以及在复杂田界线操控时，喷雾臂的控制变得异常复杂。目前尚缺乏定量喷雾臂位移程度的系统性知识，无法据此设计或改进喷雾臂及其控制系统。因此，本研究旨在开发一个自动化计算机视觉系统来量化不同农用喷雾器的喷雾臂位移情况。通过实时跟踪喷雾臂边缘的目标并使用YOLO V7、V8和V11神经网络模型进行位置追踪，研究结果表明该模型的目标检测准确率超过90%，并能与安装在喷雾臂上的倾角传感器数据保持0.026米内的距离估计误差。这一系统能够量化当前喷雾器的喷雾臂位移，甚至能够在进行轻微修改后用于其他喷雾器。研究数据可以用于改进喷雾臂设计，提高喷雾精度。
## Innovation
本研究创新地开发了一个自动化的计算机视觉系统，用于定量测量不同农用喷雾器的喷雾臂位移。利用YOLO V7、V8和V11神经网络模型实时跟踪喷雾臂边缘的目标，并使用倾角传感器验证模型输出结果。研究结果显示，此系统不仅能够高精度地量化喷雾臂的位移，还能应用于其他喷雾器，为喷雾臂的设计改进提供重要的数据支持。
## Conclusion
通过开发的自动化计算机视觉系统，可以准确量化农用喷雾器的喷雾臂位移，并将其应用于喷雾臂的设计改进，从而提高喷雾精度。同时，这种方法可以灵活应用于不同类型的喷雾器，具有广泛应用前景。
# 287. `cs.CV` - ToSA：具有空间意识的token合并 [PDF](https://arxiv.org/pdf/2506.20066), [HTML](https://arxiv.org/abs/2506.20066)
## Authors
Hsiang-Wei Huang,Wenhao Chai,Kuang-Ming Chen,Cheng-Yen Yang,Jenq-Neng Hwang
## Background
Token合并已成为通过减少计算成本来加速视觉变换器（ViT）的有效策略。然而，现有的方法主要依赖视觉token的特征相似性来进行token合并，忽视了空间信息整合的潜力，尤其是在ViT的早期层，视觉token只具有较弱的视觉信息，空间信息可以作为一个可靠的合并标准。
## Innovation
本文提出了ToSA，一种结合语义和空间意识的新型token合并方法，通过使用深度图像生成伪空间token作为视觉token合并的辅助空间信息，增强了token合并策略，更好地保留了关键场景结构。ToSA在多种视觉和主体问答基准测试中优于先前的token合并方法，同时大幅减少了ViT的运行时间，是一个高效解决方案。
## Conclusion
实验结果表明，ToSA在多种基准测试中超越了先前的token合并方法，在视觉和主体问答方面表现出更好的性能，同时显著减少了ViT的运行时间。代码可在以下链接获取：this https URL
# 288. `cs.CV` - 通过基础模型组合实现地球观测数据挖掘的大规模和通用性 [PDF](https://arxiv.org/pdf/2506.20174), [HTML](https://arxiv.org/abs/2506.20174)
## Authors
Man Duc Chuc
## Background
地球观测数据挖掘正通过基础模型迅速变革，这些模型能提供具有广泛适用性和扩展性的解决方案，用于场景分类和语义分割等关键任务。尽管地理空间领域主要集中在开发从零开始训练的大模型，但利用预训练模型的重用和组合策略仍处于探索阶段。本文研究了基础模型在遥感和通用视觉数据集上的预训练是否可以通过特征级组合提升跨多种地球观测任务的表现。
## Innovation
研究发现，较小的预训练模型的特征级组合可以在训练时间和计算资源上比更大模型更高效，还能达到或超越其性能。此外，研究还展示了知识蒸馏的应用前景，通过将其组合优势转移到更紧凑的模型中，为实际的地球观测应用提供了实用路径。
## Conclusion
基础模型在遥感和通用视觉数据集上的重用和组合能够显著提高地球观测任务的性能，提供更为高效且可扩展的解决方案。
# 289. `cs.CV` - EBC-ZIP: 使用零膨胀泊松回归改进块级人群计数 [PDF](https://arxiv.org/pdf/2506.19955), [HTML](https://arxiv.org/abs/2506.19955)
## Authors
Yiming Ma,Victor Sanchez,Tanaya Guha
## Background
人群密度图估计已成为人群计数的主流范式，但大多数现有方法忽视了地面真实密度图的极端稀疏性。在真实世界的人群场景中，大量空间区域（通常超过95%）几乎不含人，导致计数分布严重失衡。忽略这种不平衡会使模型倾向于高估密集区域，而在稀疏区域表现不佳。此外，用于人群密度估计的大多数损失函数主要基于均方误差（MSE）且隐含假定为高斯分布，这不适合建模离散的、非负计数数据。因此，提出了EBC-ZIP框架，使用零膨胀泊松（ZIP）回归形式来建模人群分布的空域分布，并通过负ZIP分布的负对数似然替换传统的回归损失，以更好地处理零重分布并将计数准确性保留下来。该框架建立在最近提出的增强块分类（EBC）框架之上，继承了EBC在保持目标离散性和确保训练稳定方面的优点，并通过更符合概率损失原理进一步提高了性能。
## Innovation
提出了EBC-ZIP框架，采用零膨胀泊松（ZIP）回归来模拟人群分布，并通过负ZIP分布的负对数似然替代传统的回归损失，从而更有效地处理零重分布并保持计数准确性；基于近日提出的增强块分类（EBC）框架，整合了EBC在目标离散性和训练稳定性方面的优势，并通过更符合概率损失原理的损失函数进一步提升性能；评估了EBC-ZIP在不同计算复杂性的主干网络上的性能，证明其具有良好的扩展性。
## Conclusion
大量实验证明，EBC-ZIP在四个人群计数基准上均表现优异，持续优于EBC，并取得了当前最先进的成果。
# 290. `cs.CV` - 使用多模态VLM实现高效示例导向图像编辑 [PDF](https://arxiv.org/pdf/2506.20155), [HTML](https://arxiv.org/abs/2506.20155)
## Authors
Avadhoot Jadhav,Ashutosh Srivastava,Abhinav Java,Silky Singh,Tarun Ram Menta,Surgan Jandial,Balaji Krishnamurthy
## Background
文本到图像的扩散模型已广泛应用于多种图像编辑应用。然而，仅通过文本捕捉所有类型的编辑挑战重重。这是因为某些图像编辑的含义模糊，最好通过示例对来表达，即包含编辑前后的两张图片对。研究者们正在探索一种系统性方法，即利用预训练的文本到图像扩散模型和多模态视觉语言模型来完成基于示例的图像编辑任务，即从示例对转移编辑到内容图像的过程。尽管本文提出的方法在端到端过程中无需优化，但实验表明其在各种类型的编辑上依然表现优越，同时在速度上也提升了约4倍的效果。
## Innovation
本文提出的方法利用预训练的文本到图像扩散模型和多模态视觉语言模型，实现了无需优化的基于示例的图像编辑。通过这种方式，能够高效地将特定的编辑从示例对转移到内容图像，且在多个方面超过了基线方法，同时保持高速度。
## Conclusion
本研究不仅提供了一种新的、高效的基于示例的图像编辑框架，同时也为进一步提升图像编辑质量和速度奠定了基础。实验结果表明，此方法在多种类型的编辑任务上表现出色，同时实现了显著的提速效果。
# 291. `cs.CV` - BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos [PDF](https://arxiv.org/pdf/2506.20103), [HTML](https://arxiv.org/abs/2506.20103)
## Authors
Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang
## Background
近年来，深度生成模型的发展在视频生成方面取得了显著进步，但AI生成的视频保真度仍然有限。合成内容经常表现出时间不一致的运动、物理上不合理的轨迹、不自然的对象变形和局部模糊等视觉瑕疵，这些瑕疵损害了真实性并降低了用户的信任度。准确地检测和空间定位这些瑕疵对于自动质量控制和改进生成模型至关重要。然而，目前研究社区尚缺乏一个专门针对AI生成视频中瑕疵定位的综合基准数据集。现有的数据集要么只专注于视频或帧级检测，要么缺乏用于评估定位方法的细粒度空间注释。
## Innovation
为了弥补这一缺口，我们提出了BrokenVideos，这是一个包含3,254个AI生成视频的数据集，这些视频都有精心标注的像素级掩码，突出显示视觉损坏的区域。每个注释都通过详细的人工检查来验证，以确保高质量的地面真相。我们的实验表明，使用BrokenVideos训练最先进的瑕疵检测模型和多模态大型语言模型（MLLMs），可以显著提高它们对损坏区域的定位能力。通过广泛的评估，证明了BrokenVideos为评估和推动生成视频模型中瑕疵定位的研究奠定了关键基础。
## Conclusion
该数据集可以在给定链接访问，为生成视频模型中瑕疵定位的研究建立了基准，并推动了该领域的进步。
# 292. `cs.CV` - 从2D到3D认知：通用世界模型的简要综述 [PDF](https://arxiv.org/pdf/2506.20134), [HTML](https://arxiv.org/abs/2506.20134)
## Authors
Ningwei Xie,Zizi Tian,Lei Yang,Xiao-Ping Zhang,Meng Guo,Jie Li
## Background
世界模型在人工智能研发，尤其是通用人工智能（AGI）发展中受到越来越多的关注，它们作为计算框架用于学习外部世界的表征和预测未来状态。早期工作集中在2D视觉感知和模拟上，但最近具有3D感知能力的生成世界模型能够合成几何一致且可交互的3D环境，正朝着3D空间认知转变。尽管进展迅速，但该领域缺乏系统分析来分类新兴技术并阐明其在推进3D认知世界模型中的作用。本文旨在填补这一空白，通过引入概念框架，并提供从2D感知到3D认知的世界模型的结构化和前瞻性的综述来解决这一需求。文中重点介绍了两个关键的技术驱动因素：3D表示的改进以及世界知识的融入，作为基本支柱。此外，文章还剖析了支持3D世界建模的三种核心认知能力：3D物理场景生成、3D空间推理和3D空间交互，并进一步探讨了这些能力在实际应用中的部署情况，包括仿生AI、自动驾驶、数字孪生和游戏/VR等。最后，本文指出了数据、建模和部署方面面临的挑战，并概述了促进更稳健通用的3D世界模型发展的未来方向。
## Innovation
提出了一个概念框架，提供了一个结构化和前瞻性的综述，涵盖了从2D感知到3D认知的世界模型的发展。重点剖析了3D物理场景生成、3D空间推理和3D空间交互等三种核心认知能力，以及这些能力在实际应用中的部署情况，并指出了未来的发展方向。
## Conclusion
该综述填补了世界模型领域缺乏系统分析的空白，提出了两项技术驱动因素作为基本支柱，并讨论了三种核心认知能力及其实际应用，并提出了未来的发展方向，旨在促进更稳健和通用化的3D世界模型的发展。
# 293. `cs.CV` - Pansharpening中的渐进对齐退化学习 [PDF](https://arxiv.org/pdf/2506.20179), [HTML](https://arxiv.org/abs/2506.20179)
## Authors
Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu
## Background
基于深度学习的多光谱高分辨率图像融合（pansharpening）已被证明可以有效生成高分辨率多光谱（HRMS）图像。通常使用Wald协议生成的合成数据来创建监督的HRMS图像作为真实世界数据的近似，从而训练网络。Wald协议假设在低分辨率数据上训练的网络在高分辨率数据上也能表现良好。然而，经过良好训练的模型在低分辨率和高分辨率数据集上的性能存在折中。研究表明，Wald协议对实际降级模式的不准确近似限制了深度融合模型的一般性。
## Innovation
我们提出了一种渐进对齐退化模块（PADM），它通过两个子网络PAlignNet和PDegradeNet之间的相互迭代来学习准确的降级过程，而无需依赖预定义的操作符。此外，我们引入了HFreqdiff，它将高频细节嵌入到一个扩散框架中，结合了CFB和BACM模块以实现频率选择性细节提取和反向过程学习的精确学习。这些创新性技术能够有效地整合高分辨率全色和多光谱图像，显著提高空间锐度和图像质量。实验和消融研究证明了所提出的方法相较于当前最先进的技术具有更好的性能。
## Conclusion
综上所述，我们提出了一种新的pansharpening方法，通过自适应学习准确的退化过程，并引入高频细节处理框架和精细的反向过程学习模块，显著提高了多光谱高分辨率图像的质量和清晰度。实验结果验证了该方法的有效性。
# 294. `cs.CV` - UniCode²: 梯级大规模码本实现统一多模态理解与生成 [PDF](https://arxiv.org/pdf/2506.20214), [HTML](https://arxiv.org/abs/2506.20214)
## Authors
Yanzhe Chen(Yen-chieh Chan),Huasong Zhong,Yan Li,Zhenheng Yang
## Background
统一多模态大规模语言模型（MLLMs）在联合推进图像理解与生成方面展现了潜力，其中图像通过视觉码本离散成标记以实现自回归建模。现有的基于码本的方法要么依赖于词汇量较小的词汇表（约16K项），缺乏精细的语义，要么盲目扩展，导致标记使用率低且训练不稳定。
## Innovation
本文提出了一种名为UniCode²的梯级码本框架，该框架能够实现大规模、语义对齐且稳定的视觉标记化。通过聚类数百万SigLIP序列嵌入，构建了一个包含500K条目、既能保持视觉-语言对齐又能扩展容量的码本。设计中，通过冻结码本来稳定嵌入空间，通过可训练码本来细化特定任务的语义。这种分层设计提高了标记使用率和学习的鲁棒性。此外，视觉标记与文本语义的良好对齐使得与预训练的扩散解码器无缝集成成为可能，几乎无需适配即可实现高质量的视觉合成。UniCode²在各种基准测试中表现出色，证明了扩大视觉标记空间的同时保持稳定、语义和模块化是可行的。
## Conclusion
UniCode²展示了在进行大规模码本训练的同时，保持视觉标记稳定、语义和模块化是可行的，证明了能够有效扩展视觉标记空间而不牺牲上述特性。
# 295. `cs.CV` - EAR: 从统一自回归模型中擦除概念 [PDF](https://arxiv.org/pdf/2506.20151), [HTML](https://arxiv.org/abs/2506.20151)
## Authors
Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang
## Background
自回归（AR）模型在视觉理解和图像生成任务中表现出统一和强大的性能。然而，在去除模型中的不良概念同时保持整体生成质量方面仍面临挑战。研究人员提出了一种窗口梯度积累（WGA）策略和阈值损失掩蔽（TLM）策略，旨在实现有效且保持实用性的概念擦除。此外，还创建了一个名为ECGVF的新基准，该基准提供了更严谨和全面的方法来评估AR模型中的概念擦除效果，从而为这一领域提供了更坚实的基础。
## Innovation
该研究提出了Erasure Autoregressive Model (EAR)，一种用于自回归模型的概念擦除微调方法。创新点包括引入了Windowed Gradient Accumulation (WGA)和Thresholded Loss Masking (TLM)策略，以及设计了一个新的基准——Erase Concept Generator and Visual Filter (ECGVF)，用于评估AR模型中的概念擦除效果。
## Conclusion
通过使用ECGVF基准和Janus-Pro模型进行的大量实验表明，EAR在概念擦除的有效性和模型实用性的保留方面取得了显著改进。研究中的相关代码可以在指定的链接处找到。
# 296. `cs.CV` - 通过比较织物进行绘画法医研究 [PDF](https://arxiv.org/pdf/2506.20272), [HTML](https://arxiv.org/abs/2506.20272)
## Authors
Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén
## Background
艺术作品中画布的研究是验证、归因和保护的 crucial 工具。传统的基于线密度图匹配的方法在画布不来自卷上连续位置的情况下无法应用。本研究旨在使用深度学习评估纺织品的相似性，提出了一种新的方法，不依赖于线密度图来评估画布之间的相似性。通过对普拉多国家博物馆的画布应用该方法，研究证实了即使线密度相似，平纹画布也可以有效比较的假设，从而展示了该方法的可行性和准确性，为名画的分析开辟了新途径。
## Innovation
提出了一种基于深度学习的新方法，不依赖于线密度图来评估画布之间的相似性。设计并训练了Siamese深度学习模型，通过利用扫描获取的特征表示来比较图像对。还提出了一个相似性估计方法，通过聚合多个布样本的预测来提供稳健的相似性评分。
## Conclusion
研究表明提出的深度学习方法可行且准确，能够有效比较具有相似线密度的平纹画布，为名画分析提供了新的途径。
# 297. `cs.CV` - 动态带宽分配用于混合事件-RGB传输 [PDF](https://arxiv.org/pdf/2506.20222), [HTML](https://arxiv.org/abs/2506.20222)
## Authors
Pujing Yang,Guangyi Zhang,Yunlong Cai,Lei Yu,Guanding Yu
## Background
事件摄像机异步捕获像素级别的强度变化，具有极低的延迟。它们越来越多地与RGB摄像机结合使用，应用于各种视觉相关应用。然而，这些混合系统中的一个主要挑战是在传输大量触发事件和RGB图像时的问题。
## Innovation
提出了一种传输方案，该方案在保留两种源高效重建性能的同时，实现了实时去模糊。开发了一个联合事件和图像（E-I）传输框架，以消除冗余并优化信道带宽利用。通过贝叶斯建模和信息瓶颈方法，将E-I输入中的通用信息和领域特定信息分离。该冗余信息瓶颈框架确保提取的信息既紧凑又具有信息性，并根据场景动态适应性分配传输带宽，以实现更优的重建和去模糊效果。
## Conclusion
仿真结果表明，所提出的方法不仅在重建质量上优于传统系统，而且在去模糊性能上也有所增强。
# 298. `cs.CV` - 基于Transformer并联合使用在线和离线特征的书写识别系统 [PDF](https://arxiv.org/pdf/2506.20255), [HTML](https://arxiv.org/abs/2506.20255)
## Authors
Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal
## Background
现有的书写识别系统大多仅利用一种模态（如离线图像或在线笔迹轨迹），而未能充分利用二者提供的互补性线索。作者认为，这两种类型的信号对于提高识别精度都很重要，因此提出了一种端到端的网络，能够对离线图像和在线笔迹数据进行早期融合，并在共享潜空间内处理。此外，通过对离线和在线数据进行整合，能够增强表示学习期间的时间线索，从而提高作者独立性。该研究在IAMOn-DB和VNOn-DB数据集上的实验结果表明，该方法的性能超过了之前的最佳结果，最高差异达1%。
## Innovation
引入了一种端到端的网络，能够联合使用离线图像和在线笔迹数据，通过早期融合将两种模态的特征整合在共享潜空间中。采用可学习的潜查询联合关注两种标记流，产生增强上下文环境的笔迹嵌入，并使用交叉熵损失目标进行聚合和解码。这种方法在代表学习过程中利用时间线索，增强了作者的独立性。
## Conclusion
在IAMOn-DB和VNOn-DB数据集上的全面实验表明，该系统达到了最先进的准确度，超过之前的最佳结果最多1%。该研究还展示了该管道在ISI-Air数据集上的自适应性。相关代码已公开发布。
# 299. `cs.CV` - 基于损失感知的选择性剪枝准则自动选择方法以加速深度神经网络 [PDF](https://arxiv.org/pdf/2506.20152), [HTML](https://arxiv.org/abs/2506.20152)
## Authors
Deepak Ghimire,Kilho Lee,Seong-heum Kim
## Background
剪枝是一种成熟的神经网络压缩技术，适用于资源受限的边缘设备。大多数剪枝方法采用一个顺序过程，分为三个阶段：训练、剪枝、重新训练。然而，本文提出了一种新的剪枝技术，使用剪枝与训练同步进行的方法，省略了初始训练阶段，将剪枝和重新训练阶段整合为一个循环。这种方法不仅提高了剪枝效率，还能够自动选择最佳剪枝率，避免精度突然降低的问题。实验表明，这种方法在VGGNet和ResNet模型上的性能优于现有方法，特别是在FLOPs减少和精度保持之间找到了平衡。
## Innovation
提出了一个名为LAASP的模型，该模型采用剪枝与训练同步进行的方法，从特定准则池中自动选择 Magnitude 或 Similarity 基于滤波器剪枝标准，并将剪枝和重新训练整合在一个循环中。此外，该方法能够自动确定每层的最佳剪枝率，省去了手动为每层分配固定或可变量剪枝率的需求。这种方法在CIFAR-10和ImageNet数据集上的实验结果表明其有效性，实现了在保持高精度的同时大幅度减少FLOPs。
## Conclusion
该研究展示了一种新的剪枝方法LAASP，该方法通过剪枝与训练同步进行，自动选择了最佳剪枝标准和剪枝率。实验表明，该方法在CIFAR-10和ImageNet数据集上取得了比现有方法更好的性能，特别是在降低FLOPs的同时保持或提升精度。这种方法为深度神经网络的加速提供了新的思路。
# 300. `cs.CV` - 任意环境识别手术阶段：少样本测试时自适应与任务图导向精炼 [PDF](https://arxiv.org/pdf/2506.20254), [HTML](https://arxiv.org/abs/2506.20254)
## Authors
Kun Yuan,Tingxuan Chen,Shi Li,Joel L. Lavanchy,Christian Heiliger,Ege Özsoy,Yiming Huang,Long Bai,Nassir Navab,Vinkle Srivastav,Hongliang Ren,Nicolas Padoy
## Background
手术流程的复杂性和多样性，受到异质化手术室环境、机构协议和解剖变异的影响，为跨机构和跨流程的普遍化手术理解模型的发展带来了巨大挑战。虽然基于大规模视觉-语言数据预训练的手术基础模型展示了良好的迁移学习潜力，但在新环境中依旧受限于领域转移，导致性能受限，难以被应用在未见过的手术环境中。
## Innovation
提出了一个轻量级的手术流程适应框架（Surgical Phase Anywhere, SPA），该框架通过最小的注释使基础模型适应机构环境。SPA使用少量样本的时空适配来对齐多模态嵌入与机构特定的手术场景及流程，并通过扩散建模确保时间一致性，这基于机构程序协议中的任务图先验知识。最后，SPA利用动态测试时自适应，通过多个模态流程预测流之间的相互一致性来适应给定测试视频，提高了测试时分布的变化下的可靠性。SPA允许医院通过自然语言文本定义阶段，用少量图像标注阶段标签，并提供阶段转换的任务图，以快速定制阶段识别模型。实验结果显示，SPA框架在多个机构和手术流程中的少样本手术阶段识别上达到了最先进的性能，甚至在32样本标记数据下超过了全样本模型。
## Conclusion
SPA框架通过策略实现了对预训练模型的少样本测试时自适应，显著提高了通用性，尤其适用于多种不同的医院环境和手术流程。
# 301. `cs.CV` - 基于Transformer的扩散模型在图像恢复任务中的应用 [PDF](https://arxiv.org/pdf/2506.20302), [HTML](https://arxiv.org/abs/2506.20302)
## Authors
Abbas Anwar,Mohammad Shullar,Ali Arshad Nasir,Mudassir Masood,Saeed Anwar
## Background
在具有挑战性的环境中拍摄的图像常常会受到各种形式的退化影响，如噪声、色彩偏移、模糊和光散射等，这显著降低了图像质量，阻碍了这些图像在诸如物体检测、构建地图和分类等下游任务中的应用。为此，研究团队开发了一种基于Transformer的扩散模型，旨在通过改善退化图像的质量来应对这一挑战。该模型已经在多种质量指标下对水下图像的增强和除雨等方面的多项公共数据集中进行了评估，并且展示了该模型在这些任务中优于现有深度学习方法的表现。这一研究探讨了通过结合Transformer和扩散模型改善退化图像质量的有效性，使图像在需要高保真视觉数据的下游任务中更加实用。
## Innovation
该研究提出的基于Transformer的扩散模型是一种新的图像恢复方法，它结合了Transformer的强处和扩散模型的能力，以提升退化图像的质量。这种模型在水下图像增强、去噪和去雨等多个方面已经超越了现有的深度学习方法。
## Conclusion
实验结果表明，通过结合Transformer和扩散模型，开发的图像恢复模型在水下图像增强、去噪和去雨等多种任务中表现超过了现有方法，证明了这两种技术的有效性，进而扩展了在需要高保真视觉数据的下游任务中的应用范围。
# 302. `cs.CV` - Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification [PDF](https://arxiv.org/pdf/2506.20263), [HTML](https://arxiv.org/abs/2506.20263)
## Authors
Ning Luo,Meiyin Hu,Huan Wan,Yanyan Yang,Zhuohang Jiang,Xin Wei
## Background
Few-shot fine-grained image classification (FS-FGIC)是一项挑战，要求模型能够用有限的标注样本区分视觉上相似的子类别。现有方法存在关键局限性：基于度量的方法会丢失空间信息并错配局部特征，而基于重构的方法不能利用层次特征信息，缺乏关注区分性区域的机制。
## Innovation
本文提出了层次掩码增强双重建网络（HMDRN），该网络结合了双层特征重建与掩码增强的特征处理，以提高细粒度分类表现。HMDRN整合了双层特征重建和融合模块，利用不同网络层次的互补视觉信息。通过可学习的融合权重，该模型平衡了最后层的高层语义表示与倒数第二层的中间结构细节。同时，设计了一个空间二值掩码增强自重构模块，通过自适应阈值处理查询特征，同时保留完整支撑特征，增强了对区分性区域的关注并过滤背景噪声。
## Conclusion
在三个具有挑战性的细粒度数据集上的广泛实验表明，HMDRN在Conv-4和ResNet-12骨干网络架构上持续优于最先进的方法。全面的消融研究表明，双层重建增强了类间区分度，掩码增强变换减少了类内变异。可视化结果提供了HMDRN在特征重建能力方面的优越性的证据。
# 303. `cs.CV` - 自监督动作识别中的特征幻想 [PDF](https://arxiv.org/pdf/2506.20342), [HTML](https://arxiv.org/abs/2506.20342)
## Authors
Lei Wang,Piotr Koniusz
## Background
理解视频中的人类动作需要超越简单的像素分析，需要高层次语义推理和多模态特征的有效整合。现有的方法虽然提高了准确度，但仍然存在提升空间，尤其是在关注与动作相关的区域时，依赖于原始像素。
## Innovation
本文提出了一个深度联合识别框架，通过联合预测RGB视频帧中的动作概念和辅助特征来增强识别准确性。在测试阶段引入幻觉流，通过无需增加计算负担的方式丰富的特征表示。引入了两种新的领域特定描述符：对象检测特征（ODF）和显著性检测特征（SDF），以及它们与光学流、改进密集轨迹、骨架数据和音频线索等辅助模态的无缝集成。提出了涵盖语义不确定性的幻觉步骤，并引入了鲁棒损失函数以减轻特征噪声。
## Conclusion
本文提出的多模态自监督动作识别框架在Kinetics-400, Kinetics-600, Something-Something V2等多个基准测试中达到了最先进的性能，证明其在捕捉动作细动态方面的有效性。
# 304. `cs.CV` - Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models [PDF](https://arxiv.org/pdf/2506.20168), [HTML](https://arxiv.org/abs/2506.20168)
## Authors
Zhentao He,Can Zhang,Ziheng Wu,Zhenghao Chen,Yufei Zhan,Yifan Li,Zhao Zhang,Xian Wang,Minghui Qiu
## Background
近年来，多模态大型语言模型的最新进展通过结合文本和视觉信息，增强了文档理解。然而，现有模型在现实世界场景中的表现存在局限性，特别是在视觉退化的情况下缺乏完整性。在视觉退化的条件下，现有模型的响应机制往往难以有效感知视觉退化和模糊性，过度依赖于语言先验或不一致的视觉-文本推理，导致模型生成大量的幻觉内容。为了解决和分析这一问题，本文提出了KIE-HVQA，这是第一个用于评估OCR幻觉的基准测试，特别是在损坏文档理解中。该数据集包含多种测试样本，包括身份证和发票，模拟了真实世界的退化，以评估模型在损坏输入下的表现，以及辨别可靠视觉信息并准确作答的能力。
## Innovation
本文引入了KIE-HVQA数据集，这是第一个专注于评估OCR幻觉的基准测试，特别是在损坏的文档理解中。通过KIE-HVQA数据集，该研究成功评估了模型在受损输入条件下辨别可靠视觉信息和相应作答的能力。进一步提出了GRPO（目标返回概率优化）框架，其中包括新的奖励机制。该方法结合了对视觉不确定性自我意识以及在监督微调和强化学习框架中发起拒绝作答的方法，增强了模型对模糊区域幻觉的抵抗力。实验结果表明，我们的7B参数模型在KIE-HVQA数据集上的幻觉准确率绝对提高了22%，在标准任务中没有显著的性能下降，表明了其有效性和稳健性。
## Conclusion
本文通过引入KIE-HVQA数据集，提出了GRPO（目标返回概率优化）框架，结合新的奖励机制，增强了模型对视觉不确定性的自我意识以及在特定地区拒绝作答的能力。实验结果表明，我们的方法在多模态大型语言模型中显著提高了幻觉准确率，同时保持了对标准任务的有效性和稳健性。这些成果为未来降低多模态大型语言模型在视觉退化条件下的幻觉问题提供了重要指导和支持。
# 305. `cs.CV` - 从理想到现实：面向实际场景的统一且数据高效的密集预测 [PDF](https://arxiv.org/pdf/2506.20279), [HTML](https://arxiv.org/abs/2506.20279)
## Authors
Changliang Xia,Chengyou Jia,Zhuohang Dang,Minnan Luo
## Background
密集预测任务在计算机视觉中至关重要，旨在通过输入图像学习像素级注释标签。尽管在该领域取得了进展，但现有方法主要集中在理想条件下，缺乏现实世界的泛化能力，且面临实际数据稀缺的挑战。
## Innovation
本文首先介绍了 DenseWorld，涵盖了25种针对实际应用场景的密集预测任务的基准测试，实现了跨任务的统一评估。然后，提出了 DenseDiT 方法，通过利用生成模型的视觉先验，以统一策略实现多种实际的密集预测任务，并采用了参数重用机制和轻量级分支结构，在少量参数增加的情况下高效工作。实验结果显示，现有通用和专门方法在 DenseWorld 中表现出显著的性能下降，而 DenseDiT 在使用不到基线数据的0.01%的情况下表现出优越的结果，突显了其在实际应用中的实用价值。
## Conclusion
DenseDiT 在实际数据集上表现出更优的结果，通过少量训练数据实现了显著的性能提升，强调了其在实际部署中的价值。
# 306. `cs.CV` - Ctrl-Z Sampling: 使用控制随机之字形探索的扩散采样 [PDF](https://arxiv.org/pdf/2506.20294), [HTML](https://arxiv.org/abs/2506.20294)
## Authors
Shunqi Mao,Wei Guo,Chaoyi Zhang,Weidong Cai
## Background
扩散模型在条件生成任务中表现出强大的性能，通过逐步去除高斯噪声来逼近目标数据分布。这一去噪过程可以被解释为在学习到的潜在空间中进行梯度上升，模型通过逐次提高样本向更高概率区域优化。然而，扩散模型往往会在局部视觉上一致但在全局上不一致或条件上错位的情况下收敛，这主要是由于潜在空间的复杂性和不理想的初始化。先前的努力试图通过加强引导信号或操控初始噪声分布来解决这个问题。
## Innovation
我们提出了控制随机之字形采样（Ctrl-Z Sampling），这是一种新颖的采样策略，旨在在条件生成过程中检测并逃离局部最大值。该方法首先使用奖励模型来识别潜在的局部最大值，一旦检测到，便注入噪声并回滚到一个更吵、之前的状态以逃离当前的优化平台。奖励模型会评估候选轨迹，只接受那些提供改进的，而且随着更深层次的回退，能够更强地逃离当附近替代方案失败时的困境。这种受控制的随机之字形过程允许动态地在前向细化和后向探索之间交替，从而增强生成输出的对齐和视觉质量。Ctrl-Z Sampling不依赖于特定的模型，并且可以与现有的扩散框架兼容。实验结果表明，Ctrl-Z Sampling在生成质量上有了显著提高，同时只需约7.6倍的函数评估增加量。
## Conclusion
本研究提出了一种新颖的采样策略，Ctrl-Z Sampling，用于在条件生成任务中检测和逃离局部最大值，从而改进生成模型的输出质量。该策略通过动态的前向细化和后向探索之间的交替，提高了生成输出的对齐和视觉质量，适用于各种扩散模型框架。实验结果证明了该方法的有效性。
# 307. `cs.CV` - 膝盖MRI影像评估的影像组学指纹 [PDF](https://arxiv.org/pdf/2506.20306), [HTML](https://arxiv.org/abs/2506.20306)
## Authors
Yaxi Chen,Simin Ni,Shaheer U. Saeed,Aleksandra Ivanova,Rikin Hargunani,Jie Huang,Chaozong Liu,Yipeng Hu
## Background
膝关节MRI影像的准确解读依赖于临床专家的经验判断，但这种判断往往存在高变异性且难以规模化。现有的放射组学方法使用固定的一组放射组学特征（特征签名），这些特征在整个人群级别上选择出来，并应用于所有患者。尽管可解释，但这些特征签名往往过于局限，难以代表个体病理变异。因此，传统的基于放射组学的方法在性能上往往低于端到端的深度学习（DL）方法。现有的放射组学选择的个体无关性并非其解释性的关键，而是导致了我们在应用中的不良泛化表现。
## Innovation
提出了一种新的放射组学指纹框架，在这种框架中，为每位患者动态构建一个放射组学特征集（指纹），该特征集由一个深度学习模型根据其相关性从大量的放射组学特征池中预测出来，并仅选择那些对个体患者的临床状况具有预测性的特征。放射组学选择模型同时与一个低维度的（相对可解释的）逻辑回归模型进行训练，以支持下游分类。在多个诊断任务中（如一般膝关节异常、前交叉韧带（ACL）撕裂和半月板撕裂），验证了该方法具有可比或优于目前最先进的端到端深度学习模型的诊断准确性。更重要的是，该方法的内在可解释性促进了临床洞察和潜在生物标志物的发现，通过详细讨论、定量和定性的实证分析来证明其优势。
## Conclusion
本研究提出了一种新的放射组学指纹框架，通过为每位患者构建个性化的放射组学特征集，提高了在多种膝关节诊断任务中的准确性，并通过其内在的可解释性提供了有意义的临床见解和潜在生物标志物的发现。
# 308. `cs.CV` - 从 codicology 到 code：历史文档布局分析中基于 Transformer 和 YOLO 的检测器的比较研究 [PDF](https://arxiv.org/pdf/2506.20326), [HTML](https://arxiv.org/abs/2506.20326)
## Authors
Sergio Torres Aguilar
## Background
历史文档的自动处理和理解依赖于稳健的文档布局分析（DLA）。这些文档通常具有复杂的页面组织结构，因此分析它们时必须准确识别和处理结构化的布局元素。目前，五种最先进的对象检测架构被用来在三种具有不同中世纪手稿复杂性的注释数据集上进行基准测试：e-NDP（巴黎中世纪登记册，1326-1504年间），CATMuS（来自不同中世纪和现代来源的多样化多类数据集，约12-17世纪）和HORAE（装饰手抄本，约13-16世纪）。
## Innovation
研究采用了两个基于 Transformer 的模型（Co-DETR 和 Grounding DINO）与三种 YOLO 变体（AABB、OBB 和 YOLO-World）进行比较。研究发现，不同的模型架构、数据集特性和边界框表示对性能有不同的影响。在 e-NDP 数据集上，Co-DETR 达到了最先进的结果（0.752 mAP@.50:.95），其次是 YOLOv11X-OBB（0.721）。而在 CATMuS 和 HORAE 这些更复杂的数据集上，基于 CNN 的 YOLOv11x-OBB 模型显著优于所有其他模型（分别为0.564和0.568）。这项研究证明，使用定向边界框（OBB）不仅是一个小改进，而是对准确模拟历史手稿的非笛卡尔特性是基本要求。
## Conclusion
这项研究明确表明，Transformer 模型的优点在于能够全局地理解上下文，这非常适合结构化的布局，但基于 CNN-OBB 的模型在处理视觉上多样化和复杂的文档时具有更强的一般性。因此，存在一个权衡：Transformer 对于结构布局有更好的全局意识，而基于 CNN-OBB 的模型则在视觉上复杂和多样的文档中具有更强的一般性。
# 309. `cs.CV` - 面孔集合中的爆发性现象 [PDF](https://arxiv.org/pdf/2506.20312), [HTML](https://arxiv.org/abs/2506.20312)
## Authors
Jiong Wang
## Background
爆发性是一种在文本和图像检索中观察到的现象，指的是某些特定元素在集合中出现的次数超过了统计独立模型的预期。在基于集合的人脸识别(SFR)中，该现象普遍存在并从两个方面降低识别性能：首先，频繁出现的面孔（具有特定属性的面孔频繁出现在面孔集合中）在训练实例中占主导地位，影响了对不受控场景的泛化能力；其次，在评估阶段，频繁出现的面孔干扰了集合验证和识别过程中相似性比较。为了检测集合中的爆发性面孔，我们提出了基于Quickshift++、特征自相似性和广义最大池化(GMP)的三种策略。我们将在训练和评估阶段应用爆发检测结果来增加稀有面孔的采样比率或贡献。在评估阶段，还提出了质量感知GMP，使原GMP能够认识到面部质量并具有抵抗低质量面部的能力。我们通过对SFR基准的研究和广泛的实验表明，爆发性现象普遍存在，抑制爆发性显著提高了识别性能.
## Innovation
提出了基于Quickshift++、特征自相似性和广义最大池化的三种策略来检测集合中的爆发性面孔。在评估阶段，提出了质量感知广义最大池化方法，使其能够识别面部质量和更抵抗低质量面部的影响。
## Conclusion
通过实验结果表明，爆发性现象在基于集合的面部识别中普遍存在，并且抑制爆发性显著改善了识别性能。
# 310. `cs.CV` - InvZW: 基于噪声对抗训练的稳健图像零水印算法 [PDF](https://arxiv.org/pdf/2506.20370), [HTML](https://arxiv.org/abs/2506.20370)
## Authors
Abdullah All Tanvir,Xin Zhong
## Background
该论文介绍了一种基于对抗噪声特征学习的新型深度学习框架，用于稳健的图像零水印。零水印是指其插入不会改变原图，通常通过特征空间优化学习一个参考签名。论文对现有自监督和深度水印技术展现了显著的优越性，并且对于图像中的各种扭曲和扰动具有很强的鲁棒性。
## Innovation
该框架包含两个关键模块。第一模块使用噪声对抗学习来训练特征提取器，生成同时对扰动不变且语义丰富的表示。这是通过对抗监督和重构约束相结合实现的。第二模块设计了一个基于学习的多比特零水印方案，使得训练中的不变特征被投影到一组可以匹配目标二进制消息的可训练参考代码上。实验结果表明，该方法在特征稳定性和水印恢复方面达到了最先进的性能，特别是在鲁棒性方面的表现优于现有的自监督和深度水印技术。
## Conclusion
大量实验表明，该方法在多种图像数据集和广泛扭曲情况下的鲁棒性和特征稳定性方面达到了最先进的性能。与其他现有自监督和深度水印技术相比，该框架在泛化能力和鲁棒性方面具有显著优势。
# 311. `cs.CV` - 利用轻量化分层ViT和动态框架实现高效视觉跟踪 [PDF](https://arxiv.org/pdf/2506.20381), [HTML](https://arxiv.org/abs/2506.20381)
## Authors
Ben Kang,Xin Chen,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu
## Background
基于Transformer的视觉跟踪器表现出显著的进步，但由于其缓慢的处理速度，这些跟踪器在资源受限的设备上实现有局限性。因此，本文提出了一种新的高效跟踪模型HiT，不仅保持了高性能，还在各种设备上实现了快速操作。此外，文中还提出了一种基于动态路由架构的加速方法，能够在不牺牲准确性的情况下显著提高各种高性能跟踪器的执行速度。
## Innovation
HiT的核心创新在于其Bridge模块，该模块将轻量级变压器连接到跟踪框架，提升了特征表示质量。同时，还引入了一种双图像位置编码方法来有效编码空间信息。DyHiT利用了一个动态路由器来根据场景复杂性选择不同的计算要求路径，从而高效地在精度和速度之间取得平衡。此外，还提出了一种基于DyHiT动态路由架构的训练免费加速方法，能够在不牺牲准确性的情况下显著提高各种高性能跟踪器的执行速度。
## Conclusion
相比之前的同类模型，该方法在多个领域的实验结果表明了其高效性和优越性。DyHiT的最快版本在NVIDIA Jetson AGX平台上达到111 fps，保持了62.4%的AUC。同时，提出的加速方法使得 SeqTrack-B256 在NVIDIA GeForce RTX 2080 Ti GPU 上的速度提高了2.68倍，保持了69.9%的AUC。
# 312. `cs.CV` - 突破空间限制：基于谱域注册的高光谱和多光谱盲融合 [PDF](https://arxiv.org/pdf/2506.20293), [HTML](https://arxiv.org/abs/2506.20293)
## Authors
Kunjing Yang,Libin Zheng,Minru Bai,Ting Lu,Leyuan Fang
## Background
近年来，未注册的高光谱图像（HSI）和多光谱图像（MSI）的盲融合引起了广泛关注。现有的大多数方法通过在HSI上应用空间变换来实现与MSI的对齐，但这种方法因图像分辨率的显著差异而效果不尽如人意。此外，处理遥感中的大尺寸图像时，注册过程通常耗时较长。为解决这些问题，本文提出了一种基于谱域的注册方法。首先，开发了一种轻量级的光谱先验学习（SPL）网络，以从HSI中提取光谱特征并增强MSI的光谱分辨率。其次，对获得的图像进行空间下采样，生成对齐的HSI。在此过程中，采用了子空间表示和循环训练策略来提高对齐HSI的光谱准确性。然后，提出了一种盲稀疏融合（BSF）方法，该方法利用组稀疏正则化来等效促进图像的低秩性。这种方法不仅省去了秩估计的需要，还降低了计算复杂度。最后，使用邻域交替优化（PAO）算法求解BSF模型，并对其收敛性进行了分析。通过模拟数据集和真实数据集进行的广泛数值实验验证了该方法在注册和融合中的有效性，并展示了其在提高分类性能方面的功效。
## Innovation
本文提出了一种基于谱域的注册方法，通过使用轻量级光谱先验学习（SPL）网络从HSI中提取光谱特征并增强MSI的光谱分辨率，然后对图像进行空间下采样并使用组稀疏正则化（BSF）方法进行盲融合，利用邻域交替优化（PAO）算法求解BSF模型，并对其进行收敛性分析。这种方法不仅解决了空间分辨率差异带来的问题，还提高了计算效率和效果。
## Conclusion
本文提出的方法在注册和融合方面进行了广泛数值实验的验证，并展示了其在提高分类性能方面的功效。该方法在处理大尺寸遥感图像时表现出了更高的效率和更好的性能，解决了现有方法中存在的问题。
# 313. `cs.CV` - 使用移动激光扫描仪捕获的地下矿场复杂3D点云中使用深度学习识别岩锚的方法 [PDF](https://arxiv.org/pdf/2506.20464), [HTML](https://arxiv.org/abs/2506.20464)
## Authors
Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval
## Background
岩锚是地下矿山支护系统的关键组件，对岩体结构提供充分的支持，预防滑塌等意外风险，因此需要经常性检测岩锚状态来维持岩体稳定性和降低地下采矿过程中的风险。然而，由于地下矿山光照条件差和人力检查过程耗时，难以采用手工检测岩锚，因此提出自动检测岩锚作为替代方案，减少时间消耗和提升检测效率。现有技术主要基于特征工程和传统机器学习方法，但这些问题存在大量噪声、环境变化和复杂围岩结构等问题，使得检测变得尤为困难。尤其是在大型复杂3D点云中的岩锚检测，由于喷射混凝土的遮挡，目标岩锚通常会被部分遮盖，增加了检测难度。因此，需要一种能有效处理复杂3D点云中的数据不平衡问题的自动化岩锚识别技术，以改善精度和稳定性。
## Innovation
本文提出了一种名为DeepBolt的新型双阶段深度学习架构，特别设计用于解决严重类别不平衡问题，以在复杂3D点云中自动和高效地识别岩锚。此方法在岩锚点上通过交并比（IoU）超越了最先进的语义分割模型，提高了42.5%。同时，该方法在分类岩锚的精度和召回率方面分别达到了96.41%和96.96%，显示出其在复杂地下环境中的稳健性和有效性。
## Conclusion
本研究提出了一种基于双阶段深度学习策略的自动岩锚识别方法DeepBolt，通过在复杂3D点云数据中进行有效的类别不充分衡管理和处理，其成功改善了岩锚检测的准确性与稳定性。此方法为地下矿山的安全监测和管理提供了一种先进且高效的手段。
# 314. `cs.CV` - AI辅助放射学分析在检测牙槽骨丧失程度和模式中的应用 [PDF](https://arxiv.org/pdf/2506.20522), [HTML](https://arxiv.org/abs/2506.20522)
## Authors
Chathura Wimalasiri,Piumal Rathnayake,Shamod Wijerathne,Sumudu Rasnayaka,Dhanushka Leuke Bandara,Roshan Ragel,Vajira Thambawita,Isuru Nawinne
## Background
牙周炎是一种导致牙槽骨丧失的慢性炎症性疾病，严重影响口腔健康和生活质量。准确评估骨丧失的程度和模式对于诊断和治疗计划至关重要。为了实现这一目标，本研究提出了一种基于人工智能的深度学习框架，利用放射牙片内在放射片（IOPA）图像自动检测和量化牙槽骨丧失及其模式。这种方法结合了YOLOv8进行牙齿检测以及Keypoint R-CNN模型来识别解剖学标志点，从而使骨丧失程度的精确计算成为可能。同时，通过几何分析，YOLOv8x-seg模型可以对骨水平和牙齿掩膜进行分割，以确定骨丧失模式（水平 vs. 角度）并进行分类。
## Innovation
本研究提出了一种基于人工智能的深度学习框架，结合YOLOv8进行牙齿检测和Keypoint R-CNN模型识别解剖学标志点，用以自动检测和量化牙槽骨丧失及其模式。该方法通过几何分析对骨水平和牙齿掩膜进行分割，以区分骨丧失模式（水平 vs. 角度），并通过大型专家标注数据集的评估，在检测骨丧失程度和模式分类上取得了高准确性（内相关系数可达0.80，分类准确率87%）。
## Conclusion
该自动化系统提供了快速、客观且可重复的牙周评估工具，减少了对手动主观评估的依赖。通过将AI集成到牙科放射学分析中，本框架有望提高牙周炎的早期诊断和个性化治疗计划的质量，从而提升患者的护理水平和临床结果。
# 315. `cs.CV` - AdvMIM:  adversarial masked image modeling for semi-supervised medical image segmentation [PDF](https://arxiv.org/pdf/2506.20563), [HTML](https://arxiv.org/abs/2506.20563)
## Authors
Lei Zhu,Jun Zhou,Rick Siow Mong Goh,Yong Liu
## Background
注意力转换器在医学图像分割任务中由于其长距离依赖关系的卓越捕获能力而获得了巨大的关注度。然而，转换器需要大量的标记数据才能有效，这阻碍了它在标注稀缺的半监督学习场景中的应用，该场景中只有有限的标记数据可用。现有的半监督学习方法提出了一种将卷积神经网络和转换器结合的组合方法，以交叉教一个转换器和一个卷积神经网络，取得了令人欣喜的结果。但仍然是一项艰巨的任务，即如何有效训练转换器以有限的标记数据。
## Innovation
本文提出了一种对抗性掩码图像建模方法，旨在充分利用转换器在医学图像分割中的潜力。该方法的创新点在于通过构造辅助掩码域来增加监督信号，并通过理论分析和开发新颖的对抗训练损失来减少原始域和掩码域之间的域差距，从而提升半监督学习性能。此外，该方法还被扩展到卷积神经网络。
## Conclusion
在三个公开的医学图像分割数据集上的广泛实验证明了该方法的有效性，该方法显著优于现有方法。代码已公开发布。
# 316. `cs.CV` - Med-Art: 差分变换器在2D医学图文生成中的应用 [PDF](https://arxiv.org/pdf/2506.20449), [HTML](https://arxiv.org/abs/2506.20449)
## Authors
Changlu Guo,Anders Nymark Christensen,Morten Rieger Hannemose
## Background
最近几年，文本到图像生成模型在医疗图像生成方面取得了显著的突破，但其应用仍面临诸多挑战，如小数据集和稀缺的医学文本数据。Med-Art旨在解决这些挑战，通过设计专门用于有限数据下的医疗图像生成框架，利用视觉语言模型生成医学图像的视觉描述，以克服医学文本数据的稀缺性。该框架采用基于Diffusion Transformer的大型预训练文本到图像模型PixArt-$boldsymbol{textit{textalpha}}$进行微调，实现良好的性能。
## Innovation
Med-Art 提出了一个创新的混合级别扩散微调 (HLDF) 方法，该方法在像素级别损失的引导下，有效解决了色彩饱和度过高以及相关问题，使得模型在有限数据下仍能保持高水平的性能。通过使用HLDF方法，Med-Art在两个医学图像数据集上达到了最新的性能，使用指标包括FID、KID和下游分类性能来衡量。
## Conclusion
Med-Art 通过基于Diffusion Transformer的PixArt-$boldsymbol{textit{textalpha}}$模型及混合级别扩散微调方法，成功解决了医学图像生成中的数据不足问题，实现了在有限数据集上的高精度生成。该方法的有效性和优越性通过在两个医学图像数据集上的实验证明，达到了最新的性能标准。
# 317. `cs.CV` - 使用观测分组进行因果表示学习的胸部X光分类 [PDF](https://arxiv.org/pdf/2506.20582), [HTML](https://arxiv.org/abs/2506.20582)
## Authors
Rajat Rasal,Avinash Kori,Ben Glocker
## Background
在医疗成像领域，找到数据生成过程背后的真正因果关系有助于提高任务特定潜在特征的泛化能力和稳健性。本文探索了一种通过端到端框架对不同观测分组进行疾病分类的因果表示学习方法，特别是针对胸部X光的疾病分类任务。
## Innovation
提出了通过观测分组学习可识别的表示方法，以改进针对种族、性别和成像视角的胸X光疾病分类任务中的泛化能力和稳健性。这种方法通过端到端框架实现，并通过实验证明了其优势。
## Conclusion
本文通过使用观测分组，引入了一种端到端的框架来学习可识别的表示，这在胸X光疾病分类中显著提高了泛化能力和稳健性。
# 318. `cs.CV` - HiWave：基于小波的扩散采样实现无训练高分辨率图像生成 [PDF](https://arxiv.org/pdf/2506.20452), [HTML](https://arxiv.org/abs/2506.20452)
## Authors
Tobias Vontobel,Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber
## Background
扩散模型在图像合成中的应用日益广泛，展示了出色的现实感和多样性。然而，训练高分辨率的扩散模型在计算上是不可行的，现有在训练分辨率之外生成图像的零样本技术常常会产生诸如物体重复和空间不连贯等瑕疵。现有方法难以在生成高分辨率图像时保持视觉真实性和结构完整性，尤其是在细节增强方面存在明显不足。
## Innovation
本文提出了一种无训练、零样本的方法HiWave，通过预训练的扩散模型生成极高分辨率图像，并在此基础上进行细节增强，从而显著提高了视觉保真度和结构一致性。HiWave采用两阶段流程：首先从预训练模型生成基图像，然后采用逐块DDIM反向生成步骤和创新的基于小波的细节增强模块。该方法使用反演方法保留基图像中的全局连贯性，使用小波域细节增强模块保证结构一致性的同时，有选择地引导高频率组件以丰富细节和纹理，进而有效减轻了以往方法中的常见视觉瑕疵，实现了更好的感知质量。
## Conclusion
通过大量的实验结果，HiWave在大多数情况下优于最先进的替代方案，证明了其在无训练和无架构修改的前提下实现高质量、超高分辨率图像合成的优越性能。
# 319. `cs.CV` - 使用视觉线索辅助句子总结的视觉内容描述与总结 [PDF](https://arxiv.org/pdf/2506.20567), [HTML](https://arxiv.org/abs/2506.20567)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan
## Background
本文提出了一种分段和总结（DaS）框架用于密集视频描述。在将每个未剪辑的长视频分割为多个活动提案后，每个活动提案由一系列短视频片段组成，从每个片段中提取视觉特征，并使用现有的图像/视频描述方法为这些片段生成一段描述。考虑到生成的句子包含了丰富的关于整个活动提案的语义描述，因此将密集视频描述任务形式化为视觉线索辅助的句子总结问题，并提出了一种新的两阶段长短期记忆（LSTM）方法，配有一个新的层次化注意力机制，以在视觉特征的帮助下总结所有生成的句子为一个描述性的句子。此前，关于密集视频描述的问题主要集中在视频片段的描述上，而较少关注片段描述的综合与总结，这种方法对于简化描述任务和提高描述精度具有潜在的优势和实用性。
## Innovation
本文提出的方法包括两个阶段的LSTM网络和一个新的层次化注意力机制。首先，第一个LSTM网络负责编码输入的语义词和片段的视觉特征，以有效总结与该活动提案相关的语义和视觉信息。然后，第二个LSTM网络负责解码第一个LSTM网络的输出以及活动提案内所有片段的视觉特征，以生成一个描述该活动提案的描述性句子。这种分段和总结的方法创新之处在于将片段描述的生成和综合总结整合在一个框架中，有效提升了密集视频描述任务的性能和效果。
## Conclusion
在ActivityNet Captions数据集上的全面实验表明，我们提出的新DaS框架在密集视频描述任务上具有有效性。这种方法能够更好地将片段描述综合到一个描述性的句子中，提高了描述的一致性和准确性。
# 320. `cs.CV` - 基于大型视觉基础模型(LVFM)的高分辨率林冠高度图生成方法在精准林业管理中的应用 [PDF](https://arxiv.org/pdf/2506.20388), [HTML](https://arxiv.org/abs/2506.20388)
## Authors
Shen Tan,Xin Zhang,Liangxiu Han,Huaguo Huang,Han Wang
## Background
准确且经济有效的监测人工林地上生物量（AGB）对支持当地生计和碳汇项目，如中国的中国核证减排量(CCER)计划至关重要。高分辨率林冠高度图（CHMs）是此类监测的关键，但现有的激光雷达（lidar）基于方法成本高昂。虽然基于RGB图像的深度学习提供了一种替代方案，但精确提取林冠高度特征仍然具有挑战性。因此，开发了一种用大型视觉基础模型(LVFM)生成高分辨率CHM的新型模型。该模型集成了特征提取器、自我监督的功能增强模块以保留空间细节，以及一个高度估计器。在北京市房山区使用1米分辨率的Google地球图像测试该模型，该模型优于现有方法，包括传统卷积神经网络（CNNs）。它实现了0.09米的平均绝对误差、0.24米的均方根误差和与激光雷达生成的CHMs相关性为0.78的性能。生成的CHMs在单棵树检测上成功率达到90%以上，AGB估算准确性高，并且能够有效跟踪人工林的生长，展示了其强大的泛化能力，能够应用于除训练区域之外的其他地区。这种方法为评估植被固碳提供了有前途且可扩展的工具，适用于人工林和自然林的评估。
## Innovation
开发了基于大型视觉基础模型（LVFM）的新型系统，能够生成高精度的人工林林冠高度图，该系统包括特征提取器、自我监督的功能增强模块和高度估计器。该方法在1米分辨率的Google地球图像上测试，其性能优于现有方法，能够准确地估计AGB并有效跟踪林木生长。
## Conclusion
该新型模型展示了在人工林中生成高分辨率CHM的强大能力，提供了精准林业管理的有前途且可扩展的工具，能够在项目评估中得到应用，特别是在植物和自然林的固碳评估中。该方法大幅降低了成本并提高了精度，有望在碳汇项目监测中发挥重要作用。
# 321. `cs.CV` - TRIM：一种最大化时间相对信息和代表性的自我监督视频摘要框架 [PDF](https://arxiv.org/pdf/2506.20588), [HTML](https://arxiv.org/abs/2506.20588)
## Authors
Pritam Mishra,Coloma Ballester,Dimosthenis Karatzas
## Background
随着视频内容的普及和对有效访问有意义信息的需求增加，视频摘要和视频重点内容已经成为一个重要研究领域。然而，许多最先进的方法要么依赖于监督注释，要么依赖注意力机制模型，这些方法计算成本高且对分布变化敏感，影响跨数据集的应用性。
## Innovation
本文提出了一个自我监督的视频摘要模型TRIM，能够捕捉空间和时间依赖关系，而不需要注意力机制、RNN或变压器。该框架结合了一个全新的马尔可夫过程指导下的损失度量集和两阶段自我监督学习框架，确保性能和效率。该模型在SUMME和TVSUM数据集上取得了最先进的性能，并且优于所有现有的无监督方法，甚至与最好的监督模型相媲美，展示了无监督架构效率和无注释的潜力。
## Conclusion
我们的工作为更具通用性的视频摘要技术铺平了道路，并挑战了对复杂架构的依赖。
# 322. `cs.CV` - 联合姿态估计和非配合空间物体的3D神经重建 [PDF](https://arxiv.org/pdf/2506.20638), [HTML](https://arxiv.org/abs/2506.20638)
## Authors
Clément Forray,Pauline Delporte,Nicolas Delaygue,Florence Genin,Dawa Derksen
## Background
了解在轨围绕地球运行的物体的当前状态和行为对于多种应用（如太空碎片清除、在轨维护或异常检测）至关重要。3D模型是空间态势感知（SSA）领域的宝贵信息来源。由于神经辐射场（NeRF）模型在单色图像、未知物体朝向、有限视角和缺乏散射照明等异常相机特性和环境条件下面临挑战，因此本文使用NeRF模型从模拟图像中重建非配合空间物体，并特别专注于相机姿态和NeRF的联合优化。实验结果显示，依次使用单张图像进行训练能实现最准确的3D重建，通过优化均匀旋转并使用正则化防止连续姿态过于偏离来估计相机姿态
## Innovation
本文利用NeRF模型从模拟图像中重建非配合空间物体，并成功实现了相机姿态与NeRF的联合优化。特别的是，通过依次训练单张图像，结合顺时针旋转优化和正则化防止连续姿态过于偏离的方法，提高了3D重建的准确性
## Conclusion
实验结果证明，使用依次图像训练能获得最准确的3D重建，通过优化均匀旋转并利用正则化防止连续姿态过大偏离，可以实现非配合空间物体的精确3D重建。
# 323. `cs.CV` - SFNet：多域特征融合的遥感图像伪造检测 [PDF](https://arxiv.org/pdf/2506.20599), [HTML](https://arxiv.org/abs/2506.20599)
## Authors
Ji Qi,Xinchang Zhang,Dingqi Ye,Yongjia Ruan,Xin Guo,Shaowen Wang,Haifeng Li
## Background
随着生成式人工智能的快速发展，仿真遥感图像（RSI）变得越来越难以辨识，可能导致错误的情报、假新闻以及阴谋论。现有的伪造检测方法通常依赖单一视觉特征来捕捉预定义的伪迹，例如在遥感图像中检测伪造物体（如道路或建筑物）的空间域线索，或识别对抗生成网络（GANs）中上采样操作的频域特征。然而，伪迹的性质会根据地理地形、土地覆盖类型或RSI中的特定特征而显著不同。此外，随着生成模型的日益复杂化，这些复杂的伪迹也在不断演变。因此，过度依赖单一视觉线索使现有的伪造检测器难以在多种遥感数据中泛化。
## Innovation
本文提出了一种新颖的伪造检测框架SFNet，该框架通过空间和频域特征融合来识别多种遥感数据中的伪造图像，主要创新点包括：1) 采用两个独立的特征提取器来捕获输入遥感图像的空间和频域特征；2) 设计了领域特征映射模块和混合域特征细化模块（CBAM注意力机制），以逐步对齐并融合多域特征并抑制冗余信息。实验结果表明，SFNet在三种数据集上的准确率比最先进的遥感图像伪造检测方法提高了4%到15.18%，表现出强大的泛化能力。编码文件可从此链接获得。
## Conclusion
SFNet通过融合空间和频域特征，显著提高了在多源遥感数据中的伪造图像检测准确性，并展示了良好的泛化能力。
# 324. `cs.CV` - 基于图句总结的密集视频描述 [PDF](https://arxiv.org/pdf/2506.20583), [HTML](https://arxiv.org/abs/2506.20583)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou
## Background
最近，密集视频描述在检测和描述长未修剪视频中的所有事件方面取得了吸引人的进展。尽管取得了有希望的结果，但大多数现有方法在处理事件提案中场景和对象随长时间变化的情况时，不足以探索场景的演变，因此表现不如人意。
## Innovation
本文提出了一种基于图的分割和总结（GPaS）框架，该框架分为两个阶段。第一个阶段是“分割”，即将整个事件提案拆分成短视频片段进行更细致的描述；第二个阶段是“总结”，即将每个段落生成的富含描述信息的句子总结成一个句子来描述整个事件。特别关注总结阶段，通过将语义词看作图中的节点，并结合Graph Convolutional Network (GCN)和Long Short Term Memory (LSTM)学习它们之间的交互，有效地利用了语义词之间的关系。提出了两种GCN-LSTM交互模块的方案，以无缝集成GCN和LSTM。
## Conclusion
我们的方法在两个基准数据集（ActivityNet Captions数据集和YouCook II数据集）上与最先进的方法进行了广泛比较，其有效性得到了证明。
# 325. `cs.CV` - MMSearch-R1：激励大型多模态模型搜索 [PDF](https://arxiv.org/pdf/2506.20670), [HTML](https://arxiv.org/abs/2506.20670)
## Authors
Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu
## Background
在真实场景中部署大型多模态模型（LMMs）需要访问外部知识源，以应对现实世界的复杂性和动态性质。现有方法如检索增强生成（RAG）和提示工程搜索代理依赖于固定的管道，经常导致搜索行为低效或过度。
## Innovation
我们提出了MMSearch-R1，这是一个端到端的强化学习框架，它可以使得LMMs在真实世界的互联网环境中进行按需、多轮次的搜索。框架集成了图像和文本检索工具，在基于结果的奖励和搜索惩罚的指导下，让模型决定何时和如何调用这些工具。为支持训练，我们通过半自动化管道收集了一个多模态搜索VQA数据集，并精心策划了一个平衡搜索需求的子集，为高效、按需的搜索行为奠定了基础。广泛的实验表明，我们的模型不仅在与相同大小的RAG基线模型相比时表现更好，而且通过减少30%以上的搜索调用次数，还能匹配更大RAG基线模型的表现。
## Conclusion
通过广泛的实验，我们展示了我们的模型不仅在知识密集型和信息查找VQA任务中优于RAG基线模型，而且还能通过减少搜索调用，达到与更大模型相当的表现。进一步的实证分析为多模态搜索领域的研究提供了可操作的见解。
# 326. `cs.CV` - 基于单传感器设置的360°测距学习方法 [PDF](https://arxiv.org/pdf/2506.20586), [HTML](https://arxiv.org/abs/2506.20586)
## Authors
Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell
## Background
在机器人感知中，准确的距离估计是一个根本性的挑战，尤其是在全景成像领域，传统的几何方法在应对镜头畸变和环境变化时存在困难。而本文通过提出使用单个360°鱼眼镜头相机进行单目距离估计的神经网络方法，来解决这个问题。这种方法能够直接从全景输入中学习并推断对象的距离，具有更好的鲁棒性和适应多样性条件的能力，而无需依赖精确的镜头校准。
## Innovation
本文提出了一种基于神经网络的单目360°距离估计方法，它能够直接从原始的全景输入中学习并推断对象的距离，无需依赖精确的镜头校准。这种方法在准确性和鲁棒性上都超过了传统的几何方法和其他基于学习的基线方法，在三个不同的360°数据集上进行了评估。实验结果显示，这种方法在低成本机器人应用、自主导航和监控等领域表现出明显的优势。
## Conclusion
该研究利用深度学习方法实现了实时全景距离估计，展示出其在低成本机器人应用、自主导航和监控等多个领域的潜力。
# 327. `cs.CV` - Shape2Animal: Creative Animal Generation from Natural Silhouettes [PDF](https://arxiv.org/pdf/2506.20616), [HTML](https://arxiv.org/abs/2506.20616)
## Authors
Quoc-Duy Tran,Anh-Tuan Vo,Dinh-Khoi Vo,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le
## Background
人类具有感知模糊刺激中具有意义模式的独特能力，这种认知现象称为似虑知觉。基于这一理念，该研究利用计算机视觉和语言模型，开发了一种框架——Shape2Animal，用于将天然物体轮廓重新诠释为可能的动物形态，从而具象化人类的创造性想象能力。该框架涉及自然对象轮廓的自动分割与视觉语义理解，以及基于文本到图像扩散模型的图像合成技术，旨在生成视觉上连贯且空间上一致的图像组合，并应用于多样化的实际输入中，验证其稳定性和创造潜力，为视觉故事讲述、教育内容、数字艺术和互动媒体设计等领域提供新的机遇
## Innovation
Shape2Animal框架通过重新解释自然物体轮廓并将其转化为可能的动物形态，模仿了人类的似虑知觉能力。它利用开放词汇分割提取对象轮廓，然后使用视觉-语言模型来解释合适的动物概念，最后利用文本到图像扩散模型合成符合输入形状的动物图像，并将其无缝地融合到原始场景中，生成视觉上连贯且空间上一致的图像组合
## Conclusion
经过对现实世界多样化的输入评估，Shape2Animal展示了其稳定性和创造潜力，能够创造新的视觉故事讲述、教育资源、数字艺术和互动媒体设计方案的机会
# 328. `cs.CV` - WonderFree: 提升新颖视图质量和跨视图一致性以增强3D场景探索 [PDF](https://arxiv.org/pdf/2506.20590), [HTML](https://arxiv.org/abs/2506.20590)
## Authors
Chaojun Ni,Jie Li,Haoyun Li,Hengyu Liu,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Boyuan Wang,Chenxin Li,Guan Huang,Wenjun Mei
## Background
从单张图像生成互动的3D场景引起了广泛关注，因为这种技术能够创建沉浸式的虚拟世界。然而，当前的3D生成方法在进行大幅度移动时，尤其是在探索未见区域时，无法生成高质量的图像，存在探索局限性的问题。因此，如何提升3D场景的生成质量和一致性，成为该领域亟待解决的关键挑战之一。
## Innovation
WonderFree 是首个允许用户以任意角度和方向自由探索的3D世界生成模型。为解决新颖视图质量和跨视图一致性的问题，提出WorldRestorer数据驱动的视频修复模型以消除浮点和伪影，并设计了一个数据收集管道以支持不同风格的场景生成。此外，还提出了跨视角一致性机制ComistView，以同时修复多个视角并保持时空一致性。实验结果表明，WonderFree 在提高不同视角的渲染质量和增强全局一致性和一致性方面表现出色，并在用户研究中得到了显著的偏好。
## Conclusion
WonderFree 通过提升新颖视图质量和跨视图一致性，显著改进了3D场景探索的效果，为用户提供了一种无缝和沉浸式的3D探索体验。相关代码、模型和数据将公开提供。
# 329. `cs.CV` - 利用遥感的多模式空间风险框架用于电动汽车充电基础设施 [PDF](https://arxiv.org/pdf/2506.19860), [HTML](https://arxiv.org/abs/2506.19860)
## Authors
Oktay Karakuş,Padraig Corcoran
## Background
电动汽车充电基础设施对可持续交通系统至关重要，然而其在环境和基础设施压力下的韧性尚未得到充分研究。本文旨在填补这一研究空白，介绍了一种空间显式、多模式的风险评估框架——RSERI-EV，该框架结合了遥感数据、开放的基础设施数据集和空间图分析，以评估电动汽车充电站的脆弱性。
## Innovation
RSERI-EV框架通过综合多种数据层，包括洪水风险图、地表温度极端值、植被指数（NDVI）、土地利用/土地覆盖（LULC）、电气变电站的接近度以及道路可达性，生成综合韧性评分。该框架利用空间最邻近($k$NN)图来支持基于邻里比较和图明智诊断的空间分析，从而突显了多源数据融合和可解释的空间推理在支持气候韧性及基础设施敏感的电动汽车部署中的价值。该研究通过在威尔士电动汽车充电站数据集上进行应用，展示了该框架的可行性。
## Conclusion
本文提出的多模态空间风险评估框架能够帮助理解电动汽车充电站网络在气候变化和其他环境压力下的复杂关系，为气候适应性和基础设施意识的电动汽车部署提供支持。
# 330. `cs.CV` - 轻量级多帧集成在视频中鲁棒YOLO目标检测中的应用 [PDF](https://arxiv.org/pdf/2506.20550), [HTML](https://arxiv.org/abs/2506.20550)
## Authors
Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell
## Background
现代基于图像的目标检测模型，如YOLOv7，主要独立处理每一帧，忽略了视频中自然存在的宝贵时序上下文。现有基于视频的目标检测方法虽然引入了复杂的时序模块，但显著增加了模型大小和计算复杂度。在如监控和自动驾驶等实际应用中，瞬态挑战如运动模糊、遮挡和突然的外观变化会对单帧检测性能造成严重影响。为此，本文提出了一种简单有效的策略——将多个连续帧作为输入传递给基于YOLO的目标检测器，而监督唯一一个目标帧的输出。这种方法利用了时序信息，同时对现有架构进行了最少的修改，保持了模型的简单性、计算效率以及实时推理能力。在挑战性的MOT20Det和自建的BOAT360数据集上的大量实验表明，此方法增强了检测鲁棒性，特别是在轻量级模型中，有效缩小了紧凑型和重型检测网络之间的性能差距。此外，还贡献了包含来自船只的鱼眼视频序列标注数据集BOAT360，为未来在挑战性现实场景中的多帧视频目标检测研究提供支持。
## Innovation
提出了一种简单有效的多帧集成策略，即将多个连续帧作为输入传递给基于YOLO的目标检测器，而监督唯一一个目标帧的输出。这种方法利用了时序信息，同时保持了模型的简单性、计算效率以及实时推理能力。
## Conclusion
本文方法在挑战性的MOT20Det和自建的BOAT360数据集上的大量实验，增强了检测鲁棒性，特别是在轻量级模型中，有效缩小了紧凑型和重型检测网络之间的性能差距，并贡献了BOAT360基准数据集，支持未来在挑战性现实场景中的多帧视频目标检测研究。
# 331. `cs.CV` - 解构的显微成像图表示 [PDF](https://arxiv.org/pdf/2506.20649), [HTML](https://arxiv.org/abs/2506.20649)
## Authors
Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone
## Background
显微成像技术在不同领域均有广泛的应用，包括诊断、合成工程和环境监测等。随着现代成像系统的进步，能够获得大量的显微图像数据，从而推动了基于深度学习的自动图像分析方法的发展。尽管深度神经网络在这一领域展现出了卓越的性能，但模型的可解释性仍然是需要克服的挑战。这项研究旨在通过提出一种解耦表示学习（Disentangled Representation Learning, DRL）方法来提高显微镜图像分类模型的可解释性。该研究利用来自三个不同显微图像领域的标准数据集（浮游生物、酵母液泡和人类细胞），展示了DRL框架如何在提高准确性和可解释性之间取得良好的平衡，通过将从合成数据中学习到的表示用于迁移到实际数据中实现性能和可解释性的兼顾。
## Innovation
提出了一种解耦表示学习（DRL）方法，以提高显微镜图像分类的模型可解释性，通过将从合成数据中学习到的表示迁移到实际数据中，实现了在准确性和可解释性之间的良好平衡。
## Conclusion
该研究利用来自不同显微图像领域的标准数据集展示了DRL框架在显微镜图像分类中的应用效果，证明了这种解耦表示学习方法能够在保持模型性能的基础上提高其可解释性，为显微镜图像分析提供了新的路径。
# 332. `cs.CV` - 基于RGB感知的共识驱动不确定性在机器人抓取中的应用 [PDF](https://arxiv.org/pdf/2506.20045), [HTML](https://arxiv.org/abs/2506.20045)
## Authors
Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai
## Background
目前深度目标姿态估计器普遍过于自信。一个能够同时估计目标物体6自由度姿态并预测自身估计不确定性抓取代理，可以在高不确定性下选择不行动从而避免任务失败。尽管目标姿态估计和不确定性量化研究不断进步，但鲜有研究将两者与机器人的抓取任务结合起来。因此，本文提出了一个训练轻量级深度网络在尝试抓取之前预测由图像姿态估计引导的抓取成功率的方法。通过基于真实图像的目标姿态估计和模拟抓取生成网络训练数据。研究还表明，尽管抓取试验中目标物存在高度变化，但将所有物体联合训练网络能够带来益处，说明多样化的物体同样可以实现同一目标。
## Innovation
本文提出了一种方法，能够训练轻量级深度网络，预测由基于图像的姿态估计引导的抓取操作是否会成功，这一方法是在尝试抓取之前进行预测的。此外，研究还展示了训练数据可以通过联合所有物体来生成，以提高网络性能的方法。
## Conclusion
本文提出的方法能够在尝试特定抓取操作之前预测其成功率，以避免在高不确定性情况下执行操作导致任务失败。通过联合训练对象，研究也表明多样性对象可以贡献于目标抓取任务的成功。
# 333. `cs.CV` - VoxelOpt：腹部CT变形注册的体素自适应消息传递离散优化方法 [PDF](https://arxiv.org/pdf/2506.19975), [HTML](https://arxiv.org/abs/2506.19975)
## Authors
Hang Zhang,Yuxi Zhang,Jiazheng Wang,Xiang Chen,Renjiu Hu,Xin Tian,Gaolei Li,Min Liu
## Background
近期神经网络的发展提高了变形图像配准（DIR）的效率和准确性，通过免迭代优化技术加快了处理速度并提高了准确性。然而，基于学习的方法在有限的训练数据、大变形情况以及无标签监督场景下往往会表现不佳，不如迭代方法的准确性。尽管迭代方法在这些情况下能够达到更高的准确度，但其处理速度远慢于基于学习的方法。为了兼顾这两个方面的优势，本文提出了一种名为VoxelOpt的框架。
## Innovation
该框架将基于学习的方法和迭代方法的优势结合起来，通过体素自适应消息传递技术，对每个体素根据其熵值获得不同的邻域影响度，避免了复杂性的指数级增长，并利用预训练的分割基础模型提取特征代替手工设计的特征或对比学习方法，从而实现既高效又准确的腹部CT变形配准。
## Conclusion
VoxelOpt在腹部CT变形注册中实现了效率和准确性的双重提升，能够与基于标签监督训练的最先进的学习方法相媲美，同时优于现有的迭代方法。相关代码已开源。
# 334. `cs.CV` - IPFormer: 视觉引导的3D全景语义场景补全与上下文自适应实例提案 [PDF](https://arxiv.org/pdf/2506.20671), [HTML](https://arxiv.org/abs/2506.20671)
## Authors
Markus Gross,Aya Fahmy,Danit Niwattananan,Dominik Muhle,Rui Song,Daniel Cremers,Henri Meeß
## Background
3D全景语义场景补全(SSC)作为一种联合学习场景几何与语义的方法，已经在移动机器人领域的导航等下游应用中发挥了重要作用。最近，泛光场景补全(PSC)进一步推广了SSC领域，通过整合实例级信息增强了对象级敏感度。虽然PSC采用LiDAR模态引入，基于相机图像的方法仍几乎未被探索。此外，基于Transformer的SSC方法使用固定的学习查询来重建场景体中物体，尽管这些查询在训练时会被图像上下文更新，但在测试时却保持静态，限制了它们根据观察到的场景动态适应的能力。
## Innovation
本文提出IPFormer，它是第一个利用上下文自适应实例提案同时在训练和测试阶段改变的3D全景语义场景补全方法。IPFormer通过从图像上下文中适应性地初始化查询来作为泛光实例提案，进一步通过基于注意力的编码和解码来推断语义实例-体素关系。实验结果表明，该方法在总体泛光指标PQ?(^?dagger?)和PQ-All上超越了现有方法，各个指标表现相当，并实现了超过14倍的运行时间减少。此外，消融研究表明，从图像上下文中动态推导实例提案，相比于随机初始化，可实现PQ-All 3.62%的提高以及联合事物指标显著平均18.65%的改进。这些结果突显了提出上下文自适应实例提案的重要性，这是在视觉引导的3D全景语义场景补全领域的一项开创性工作。
## Conclusion
本文介绍的上下文自适应实例提案是一种在3D全景语义场景补全领域的重要创新，能够显著提高方法的适应性和准确性，并大幅降低了计算时间，为该领域的研究开辟了新的方向。
# 335. `cs.CV` - 视频感知模型在3D场景合成中的应用 [PDF](https://arxiv.org/pdf/2506.20601), [HTML](https://arxiv.org/abs/2506.20601)
## Authors
Rui Huang,Guangyao Zhai,Zuria Bauer,Marc Pollefeys,Federico Tombari,Leonidas Guibas,Gao Huang,Francis Engelmann
## Background
传统的3D场景合成需要专家知识和大量手动工作。自动化这一过程可以极大地促进诸如建筑设计、机器人模拟、虚拟现实和游戏等领域的发展。近年来，3D场景合成方法往往依赖于大型语言模型（LLMs）的常识推理或现代图像生成模型的强大视觉先验，但现有的LLMs在三维空间推理方面表现出有限的局限性，限制了它们生成真实且连贯的3D场景的能力。同时，基于图像生成的方法在视点选择和多视角一致性方面存在约束。
## Innovation
本文提出了一种新的框架——视频感知模型的3D场景合成（VIPScene），该框架利用视频生成模型中编码的三维物理世界的常识知识，以确保场景布局的一致性和多视图中的物体放置的一致性。VIPScene接受文本和图像提示，并无缝整合视频生成、前馈三维重建和开放词汇感知模型，以语义和几何学分析场景中的每个物体。这使得场景合成具有更高的现实性和结构一致性。为了更精确地分析，我们进一步引入了第一人称视图评分（FPVScore），利用连续的第一人称视角，以利用多模态大型语言模型的推理能力来评估连贯性和合理性。
## Conclusion
广泛的实验表明，VIPScene显着优于现有方法，并且在多种场景下表现良好。代码将被发布。
# 336. `cs.CV` - MIRAGE: 一种农业领域多模态信息查询与推理基准 [PDF](https://arxiv.org/pdf/2506.20100), [HTML](https://arxiv.org/abs/2506.20100)
## Authors
Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve
## Background
该论文介绍了MIRAGE，一个全新的基准，用于评估在农业领域的咨询互动中专家级的多模态推理与决策能力。MIRAGE通过结合自然用户查询、专家撰写的回答以及基于图像的内容，捕捉了专家咨询的复杂性，提供了一个对现实世界中的知识密集型领域进行定位推理、澄清策略和长文本生成评估的高品质基准。本基准基于超过35,000个实际用户与专家的互动，经过精心设计的多步骤流水线进行策划，涵盖了作物健康、病虫害诊断和农作物管理的多样化场景。该基准包含超过7,000个独特的生物实体，包括植物种类、害虫和疾病，这些实体使MIRAGE成为目前可用的最分类多样性的多模态信息-视觉语言模型基准之一，扎根于现实世界。与现有依赖于明确定义的用户输入和封闭式分类系统基准不同，MIRAGE包含未明确定义的、内容丰富的场景和开放世界的设置，要求模型推断潜在的知识缺口、处理罕见实体，并主动引导对话或进行回应等能力。
## Innovation
MIRAGE的主要创新在于它结合了自然用户查询、专家撰写的回答和基于图像的内容，描绘了农业领域中复杂的专家咨询过程。它不仅涵盖了多种作物健康、病虫害诊断和农作物管理的场景，还包含了超过7,000种生物实体，是目前最具分类多样性的多模态信息基准之一。更重要的是，MIRAGE引入了一种开放式场景，要求模型不仅要处理具体信息，还要应对未知的、开放性的问题，这与现有的基准模式形成了对比。
## Conclusion
总体而言，MIRAGE提供了一个高保真的基准来评估在实际农业咨询交互中基于视觉语言模型的定位推理、澄清策略和长文本生成的能力。通过包含超过35,000次真实的用户和专家互动以及7,000多种生物实体，MIRAGE展示了其在农业领域的实际应用潜力，并为未来相关研究奠定了坚实的基础。
# 337. `cs.CV` - MS-IQA: 一种用于PET/CT图像质量评估的多尺度特征融合网络 [PDF](https://arxiv.org/pdf/2506.20200), [HTML](https://arxiv.org/abs/2506.20200)
## Authors
Siqiao Li,Chen Hui,Wei Zhang,Rui Liang,Chenyue Song,Feng Jiang,Haiqi Zhu,Zhixuan Li,Hong Huang,Xiang Li
## Background
正电子发射断层扫描/计算机断层扫描（PET/CT）在医学成像中起着关键作用，能够结合功能和解剖信息以辅助准确诊断。然而，由于噪声、压缩和其他因素导致的图像质量下降可能会引起诊断不确定性，并增加误诊风险。在评估PET/CT图像质量时，低级特征如失真和高级特征如器官解剖结构都影响图像的诊断价值。但是，现有的医学图像质量评估方法无法同时考虑这两种特征类型。
## Innovation
本文提出了一种新的多尺度特征融合网络MS-IQA，该网络利用ResNet和Swin Transformer的多个中间层的多尺度特征，增强了其对局部和全局信息的认知能力。此外，还引入了一个多尺度特征融合模块，通过动态加权的通道注意机制有效地结合高级和低级信息。为填补PET/CT图像质量评估数据集的空白，本文构建了包含2,700张不同质量级别的PET/CT图像以及放射科医生评分的数据集PET-CT-IQA-DS。实验结果表明，本提出的方法在各种图像质量评估指标中优于现有最先进的方法。
## Conclusion
本工作提供了一种准确且高效的PET/CT图像质量评估方法。本文的代码和数据集可在 [此处](this https URL) 获取。
# 338. `cs.CV` - FedBKD:基于合成数据的双向知识蒸馏联邦学习以提升非IID数据的一般性和个性化 [PDF](https://arxiv.org/pdf/2506.20245), [HTML](https://arxiv.org/abs/2506.20245)
## Authors
Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu
## Background
联邦学习作为一种去中心化的协作机器学习技术，解决了工业实践中孤立的数据孤岛和数据隐私泄露的问题。然而，在处理非独立且非一致（non-IID）数据时，联邦学习面临的主要挑战之一是无法同时提供适用于全局模型的良好泛化能力和适用于个性化本地模型的良好性能。许多解决非IID问题的方法依赖于公共数据集，这会增加数据泄露的风险。因此，提出了一种基于合成数据的双向知识蒸馏联邦学习框架（FedBKD），以改进模型的泛化和个性化能力，同时减少数据泄露的风险。
## Innovation
提出了一种全新方法，FedBKD，这是通过生成对抗网络（GAN）生成合成数据，使用这些数据进行全局和本地模型之间的双向知识蒸馏，以实现知识交互并提高双方的性能。这种方法在不同非IID设置下的4个基准测试中取得了当前最佳性能，此方法能同时提升全局模型的一般化能力和本地模型的个性化性能，解决了非IID数据处理的问题，并减少了数据泄露的风险。
## Conclusion
在不同非IID设置条件下进行了广泛的实验，结果表明，FedBKD在各方面都达到了当前的最佳性能，表明该方法的有效性。
# 339. `cs.CV` - 基于学习的中等输入敏感性函数：一项QR码解码案例研究 [PDF](https://arxiv.org/pdf/2506.20305), [HTML](https://arxiv.org/abs/2506.20305)
## Authors
Kazuki Yoda,Kazuhiko Kawamoto,Hiroshi Kera
## Background
函数的学习难度与其输入的敏感性相关。例如，图像分类任务对输入不敏感，因为小的扰动不会影响分类结果，而近年来受到广泛关注的算术和符号计算则高度依赖输入，每个输入变量都直接影响计算结果。论文研究了使用学习方法解码QR码，并探讨了中等输入敏感性的学习函数。实验证明，基于Transformer的模型不仅能成功解码QR码，还能超过理论纠错极限，这是通过学习嵌入文本的结构实现的。模型还能够从英语丰富的训练数据推广到其他语言，甚至随机字符串。研究人员还发现，基于Transformer的QR解码器主要关注数据比特而不考虑纠错比特，这提示了一种不同于标准QR码读取器的解码机制。
## Innovation
首次基于学习方法研究QR码解码任务，使用Transformer模型展现了解码能力超越理论纠错极限的可能性，模型能够推广到不同语言和随机字符串，并且解码机制与现有标准不同，主要关注数据比特而非纠错比特。
## Conclusion
研究表明，基于Transformer的中等输入敏感性学习函数能够成功解码QR码，揭示了一种潜在的解码机制，并且展示了解码能力超越理论纠错极限的可能性。
# 340. `cs.CV` - 以任意顺序生成的GPT作为屏蔽扩散模型：形式与架构的分离 [PDF](https://arxiv.org/pdf/2506.19935), [HTML](https://arxiv.org/abs/2506.19935)
## Authors
Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma
## Background
大型语言模型（LLMs）主要采用自回归（AR）方法，但屏蔽扩散模型（MDMs）正逐渐成为可行的替代方案。尽管MDMs和AR模型在架构上有显著差异（MDMs通常是编码器导向的，而AR模型往往是解码器导向的），这种同时改变模型范式和架构的做法使得直接对比变得不公平，难以区分观测到的差异是源于范式本身还是由于架构的变化。本文旨在探讨MDMs在解码器导向框架下的表现，目的是公平地比较MDMs（即任意顺序自回归，AO-AR）和标准AR范式。此外，本文还研究了MDMs中的架构影响（编码器导向 vs. 解码器导向），并发现解码器导向的MDMs在温标调整的情况下可以实现可观的生成速度提升，并且能够与较大的空间建模保持类似的困惑度。研究结果表明，解码器导向的MDMs可以经过合理的设计优化，能够达到与编码器导向MDMs不同的平衡，进而为未来模型设计提供了关键见解。
## Innovation
本文引入了任意顺序自回归（AO-AR）作为MDMs的一个变体，通过比较标准AO-AR和标准AR模型，研究了MDMs在优化形式下的表现，并通过对比编码器导向和解码器导向MDMs，揭示了它们在建模复杂度和生成速度之间的关键权衡。此外，还讨论了MDMs设计中的困惑度与生成速度之间的权衡关系。这些见解为未来设计更高效的MDMs提供了参考，同时也为比较MDMs与AR模型提供了新的视角，使得能够在公平的环境中进行评估和讨论。
## Conclusion
本文通过将MDMs置于解码器导向框架下，旨在公平比较MDMs的潜在优势，并研究其架构影响。研究发现，虽然解码器导向的MDMs可以更有效地捕捉语言的统计特性，但它们的效率可以通过温度优化显著提高。研究结果也为未来的模型设计提供了宝贵的参考，特别是关于如何在不同范式和架构中找到平衡以优化生成任务的性能。
# 341. `cs.CV` - 量子和混合卷积神经网络中不同编码、ansatz和测量方法的实际见解 [PDF](https://arxiv.org/pdf/2506.20355), [HTML](https://arxiv.org/abs/2506.20355)
## Authors
Jesús Lozano-Cruz,Albert Nieto-Morales,Oriol Balló-Gimbernat,Adan Garriga,Antón Rodríguez-Otero,Alejandro Borrallo-Rentero
## Background
本文研究了参数化量子电路（PQCs）在量子和混合卷积神经网络（HQNN和QCNN）架构中的设计选择，应用于卫星图像分类任务，使用了EuroSAT数据集。研究系统地评估了不同的数据编码技术、变分ansatz和测量对于模型性能的影响。对于混合架构，研究将其与直接的经典等价物（例如，去除PQCs的相同架构）进行了基准测试，发现数据编码策略是决定模型性能的最重要因素。而在纯量子模型中，受限于振幅编码，性能主要依赖于测量协议和数据到振幅的映射。
## Innovation
研究细致地探讨了PQCs在不同的量子和混合卷积神经网络架构中的设计选择对模型性能的具体影响，特别突显了数据编码在混合架构中的决定性作用以及纯量子模型中特定测量策略和编码映射的关键作用。通过评估近500种不同的模型配置，揭示了模型性能的客观影响因素层级。
## Conclusion
在混合架构中，数据编码策略是主要影响因素，不同的嵌入方式使得验证精度变化高达30%；而在纯量子模型中，测量协议和数据到振幅的映射对性能影响更大，验证精度变化分别为30%和8个百分点。
# 342. `cs.CV` - X-SiT: 自然可解释的表面视觉转换器在痴呆症诊断中的应用 [PDF](https://arxiv.org/pdf/2506.20267), [HTML](https://arxiv.org/abs/2506.20267)
## Authors
Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger
## Background
可解释的模型对于支持临床决策至关重要，推动了其在医学图像方面的开发和应用。然而，3D体积数据的特点使得可视化和解释复杂的脑结构（如大脑皮层）具有根本性挑战。相比之下，皮层表面渲染为理解和可视化3D脑部解剖结构提供了更便捷的方式，促进了交互式探索。鉴于这一优势以及神经退行性疾病研究中表面数据的广泛使用，本文提出了一种新型神经网络——可解释的表面视觉变换器（X-SiT）。
## Innovation
X-SiT 是首个具有自然可解释性的神经网络，它基于可解释的皮层特征提供人可理解的预测。文中还引入了原型表面块解码器，用于分类表面块嵌入，结合了案例推理和空间对应的皮层原型。实验结果表明，在检测阿尔茨海默病和前颞叶痴呆方面具有最先进的性能，同时提供了与已知疾病模式一致且有助于揭示分类错误的信息性原型。
## Conclusion
X-SiT 可以作为支持临床决策的重要工具，为痴呆症诊断提供了先进的方法。该模型提供的解释性皮层特征和原型有助于进一步理解疾病的复杂性，同时提高了诊断的准确性和透明度。
# 343. `cs.CV` - 将放射omics特征与深度表征融合用于胎儿超声图像中的妊娠周数估计 [PDF](https://arxiv.org/pdf/2506.20407), [HTML](https://arxiv.org/abs/2506.20407)
## Authors
Fangyijie Wang,Yuan Liang,Sourav Bhattacharjee,Abey Campbell,Kathleen M. Curran,Guénolé Silvestre
## Background
准确估算妊娠周数（GA）对提供优质的产前护理至关重要，理想的估算方式是通过胎儿超声测量。然而，从手动胎儿生物测量中推导GA取决于操作者并耗时，因此，临床实践中需要自动计算机辅助方法。本文提出了一种新的特征融合框架，用于通过胎儿超声图像估算妊娠周数，无需任何测量信息。该框架旨在通过融合放射omics特征和深度表征来估算妊娠周数，在三个孕期中，均绝对误差为8.0天，优于当前基于机器学习的方法。实验结果表明，该框架在不同地区的人群中表现出高度的鲁棒性。作者将代码公开在GitHub上。
## Innovation
本文提出了一种新颖的特征融合框架，能通过融合放射omics特征和深度表征自动估计妊娠周数，该方法适用于不需要手动测量信息的胎儿超声图像，并且在不同区域和人群中表现稳定。同时，该模型的均绝对误差为8.0天，比现有机器学习方法效果更好。
## Conclusion
该框架在三个孕期的妊娠周数估计中展现了良好的性能，对不同地区和人群具有鲁棒性，证明了基于放射omics特征和深度表征融合的自动估算方法的有效性和实用性。
# 344. `cs.CV` - FundaQ-8：一种临床启发的自动视网膜影像质量评分框架 [PDF](https://arxiv.org/pdf/2506.20303), [HTML](https://arxiv.org/abs/2506.20303)
## Authors
Lee Qi Zun,Oscar Wong Jin Hao,Nor Anita Binti Che Omar,Zalifa Zakiah Binti Asnir,Mohamad Sabri bin Sinal Zainal,Goh Man Fye
## Background
自动视网膜影像质量评估（FIQA）因成像收集中的变化和主观专家评估而具有挑战性。现有方法难以精确地、系统地评估视网膜影像的质量。为了解决这一问题，本文介绍了一种新的专家验证框架FundaQ-8，该框架通过八个关键参数（包括视野覆盖率、解剖学可见性、光照和图像伪影）系统性地评估视网膜影像的质量。并通过这种方法建立了预测连续质量分数的回归模型，模型在0到1的范围内评分，并结合了数据集进行训练，从而保证模型的可靠性和临床适用性。
## Innovation
提出了FundaQ-8框架，该框架通过八个关键参数系统性地评估视网膜影像的质量。利用FundaQ-8框架作为结构化的评分参考，基于ResNet18的回归模型能够预测0到1范围内的连续质量分数。通过采用迁移学习、均方误差优化和标准化预处理，模型在多个数据集上进行训练，这些数据集包括1800张真实临床来源的视网膜影像和Kaggle的数据集。实验结果证明了该框架的可靠性和临床可解读性。
## Conclusion
FundaQ-8框架结合深度学习模型用于糖尿病视网膜病变分级，提高了诊断的稳健性，突显了质量意识训练在实际筛查应用中的价值。
# 345. `cs.CV` - 带有可追溯推理的罕见疾病诊断代理系统 [PDF](https://arxiv.org/pdf/2506.20430), [HTML](https://arxiv.org/abs/2506.20430)
## Authors
Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie
## Background
全球范围内共有超过3亿人受到罕见疾病的困扰，然而及时准确的诊断仍然是一个普遍的挑战，这主要归因于罕见疾病临床表现的多样性和低个体发病率，以及临床医生对罕见疾病的认知有限。
## Innovation
文章引入了DeepRare，这是首个由大语言模型驱动的罕见疾病诊断代理系统，能够处理异质的临床输入并生成稀有疾病的分级诊断假设，同时提供透明的推理链来连接中间分析步骤和可验证的医学证据。DeepRare由一个中央主机和长时间记忆模块，以及专门负责领域特定分析任务的代理服务器组成，后者集成了超过40种专业工具和最新的医学知识源。该设计模块化且可扩展，可进行复杂的诊断推理，并保持可追溯性和适应性。在多个数据集上的评估中，DeepRare的诊断性能显著优于其他方法，特别是在HPO基线评估中，取得了显著优势，平均Recall@1得分为57.18%，超出次优方法如推理大模型23.79个百分点。在多模态输入场景中，DeepRare的Recall@1得分达到了70.60%，而Exomiser则为53.20%。临床专家对推理链的手动验证达到了95.40%的一致性。
## Conclusion
DeepRare作为一个用户友好的网页应用程序已经被实施，它展示了卓越的诊断性能，同时保持了清晰的推理链和高度的临床适应性。
# 346. `cs.CV` - DreamAnywhere：基于对象的全景3D场景生成 [PDF](https://arxiv.org/pdf/2506.20367), [HTML](https://arxiv.org/abs/2506.20367)
## Authors
Edoardo Alberto Dominici,Jozef Hladky,Floor Verhoeven,Lukas Radl,Thomas Deixelberger,Stefan Ainetter,Philipp Drescher,Stefan Hauswiesner,Arno Coomans,Giacomo Nazzaro,Konstantinos Vardis,Markus Steinberger
## Background
在文本到3D场景生成方面，尽管跨多个行业的内容创作已经显示出巨大的潜力，但现有方法仍然存在诸多问题，如场景仅面向前方、缺乏视觉清晰度、场景理解有限以及多为室内或室外场景的专门调优。研究人员已在解决这一复杂任务的各种挑战方面取得了显著进展，但现有方法生成的环境往往仍存在前述缺陷。
## Innovation
本文介绍了一种名为DreamAnywhere的模块化系统，用于快速生成和原型制作3D场景。该系统能够生成360°全景图像，对其进行分解并提取背景和物体，通过混合修补构建完整的3D表示，并将物体分割图提升为详细的3D物体，然后放置在虚拟环境中。此外，该系统支持沉浸式的场景导航和直观的物体级别编辑，可以在经济预算较低的电影制作中实现场景布局和视觉基调的快速迭代。
## Conclusion
与现有的基于文本和图像的3D场景生成方法相比，DreamAnywhere在新颖视角合成的一致性方面显示出显著改进，并达到了可竞争的图像质量，这些特性使其在各种复杂场景中都显示出有效性。一项全面的用户研究显示，用户更偏好这种方法，进一步验证了其技术稳健性和实用性。其模块化管道可高度自定义，独立替换组件提供了更多灵活性。
# 347. `cs.CV` - 可见光和红外图像馈送中低光条件下的行人检测：问题与挑战 [PDF](https://arxiv.org/pdf/2311.08557), [HTML](https://arxiv.org/abs/2311.08557)
## Authors
Thangarajah Akilan,Hrishikesh Vachhani
## Background
行人检测已成为自主驾驶、智能交通和交通监控等多项高级任务的基础。尽管有许多关于使用可见图像进行行人检测的研究，特别是日间，但在环境条件变化为低光照或夜间的情况下，该任务变得非常具有挑战性。最近，有研究已经开始利用远红外（FIR）温度传感器的数据来在低光照条件下检测行人。这项研究旨在回顾低光照条件下的行人检测方法的发展，系统地分类和分析各种基于区域、非区域以及基于图学习的方法，指出其方法、实施问题和挑战，并概述可用于低光照条件下行人检测算法的研究和开发的关键基准数据集。
## Innovation
提出了利用远红外（FIR）温度传感器作为在低光照条件下检测行人的一种新思路，并对各个研究方向进行了系统的分类和分析，揭示了每种方法的优缺点和实施中的问题。此外，该研究还指出了可用于低光照条件下行人检测算法研究和开发的关键基准数据集。
## Conclusion
该研究对低光照条件下的行人检测方法进行了全面的回顾和分析，指出了各种常用方法的优缺点和面临的主要挑战，并提供了可用于研究和开发先进行人检测算法的关键基准数据集。
# 348. `cs.CV` - 加权平均频率：用于4D Flow MRI分割的手工Fourier特征 [PDF](https://arxiv.org/pdf/2506.20614), [HTML](https://arxiv.org/abs/2506.20614)
## Authors
Simon Perrin,Sébastien Levilly,Huajun Sun,Harold Mouchère,Jean-Michel Serfaty
## Background
近年来，4D Flow MRI图像的应用使得心肌血液流动场的量化成为可能，并且可以沿心脏周期进行测量。然而，这些生物标志物的分辨率低和噪声的存在仍然是一大挑战。尤其是管壁剪切应力这样的生物标志物受血管分割低分辨率的影响较大。目前最先进的方法是相位对比磁共振血管造影（PC-MRA）以协助分割。本文旨在介绍一种新的手工特征，以提供4D Flow MRI图像的新可视化方法，并在分割任务中非常有用。这种特征被称为加权平均频率（WMF），能够揭示在一个三维区域内一个体素被脉动流通过的区域，且这一特征是所有脉动速度体素的边界表示。该特征在两个实验中得到了验证，其在使用最优阈值和深度学习方法分割4D Flow MRI图像时，相较于PC-MRA特征，IoU和Dice指数分别提高了0.12和0.13。这表明该特征在其他血管区域如心脏或大脑中的分割过程具有潜在的价值和指导意义。
## Innovation
本文提出了一种新的手工特征，称为加权平均频率（WMF），这种特征能够提供4D Flow MRI图像的新可视化方法，并在分割任务中非常有用。WMF特征可以在三维区域内揭示体素被脉动流通过的区域，能够代表所有脉动速度体素的边界。该特征在利用最优阈值和深度学习方法分割4D Flow MRI图像时，显著提升了IoU和Dice指数，相较于PC-MRA特征分别提高了0.12和0.13。
## Conclusion
加权平均频率（WMF）特征可以为心脏血管分割的研究提供一种新的可视化和分割方法，其在提高4D Flow MRI图像分割的精度方面表现出色，并为进一步研究其他血管区域提供了潜在的价值。
# 349. `cs.CV` - KD-DETR: 通过一致抽样点知识蒸馏检测变换器 [PDF](https://arxiv.org/pdf/2211.08071), [HTML](https://arxiv.org/abs/2211.08071)
## Authors
Yu Wang,Xin Li,Shengzhao Weng,Gang Zhang,Haixiao Yue,Haocheng Feng,Junyu Han,Errui Ding
## Background
DETR是一个新颖的端到端变换器架构对象检测器，相比于经典的检测器，在扩展时性能显著优于传统模型。Knowledge distillation在经典的检测器中已有充分的研究，但在DETR上应用效果不佳，主要由于缺乏一致的蒸馏点。传统的检测器和DETR中的蒸馏点有不同的表现形式，可靠的知识蒸馏需要两者之间一致性足够的蒸馏点。
## Innovation
提出了一种适用于DETR的通用知识蒸馏方案(KD-DETR)，包括一致蒸馏点采样的策略，适用于同质和异质蒸馏。引入了一组专门的对象查询来构建DETR的蒸馏点，并提出了一种从一般到特定的蒸馏点采样策略，以探索KD-DETR的扩展性。基于KD-DETR的方法在不同尺度的DAB-DETR，多尺度的Deformable DETR和DINO上进行了广泛的实验，验证了其有效性和泛化能力。此外，还将KD-DETR应用于异质蒸馏，进一步提升性能，并展示了与同质蒸馏的竞争力。
## Conclusion
KD-DETR通过一致的蒸馏点采样策略有效提高了DETR模型的性能，尤其是在异质蒸馏中表现出色，实现了与同质蒸馏相当的性能提升。
# 350. `cs.CV` - EditP23: 通过多视图图像提示传播进行3D编辑 [PDF](https://arxiv.org/pdf/2506.20652), [HTML](https://arxiv.org/abs/2506.20652)
## Authors
Roi Bar-On,Dana Cohen-Bar,Daniel Cohen-Or
## Background
传统的3D编辑方法依赖于基于文本的提示或显式的空间掩模，这使得编辑过程复杂且不够直观。现有的方法要求用户在编辑过程中反复调整，导致编辑过程繁琐、效率低，且编辑结果可能不一致。因此，需要一种无需人工掩模干预、能够直观进行3D编辑的方法，以提升编辑的效率和效果。
## Innovation
EditP23通过引入无需掩模的3D编辑方法，利用两张图像作为输入：原图和用户编辑后的版本。该方法利用预训练的多视图扩散模型在潜空间中引导编辑感知流，确保编辑在不同视角下保持一致。这种方法摒弃了文本提示和显式掩模的依赖，实现了更为直观和高效的3D编辑。
## Conclusion
通过EdiP23，无论处理哪类物体及其编辑场景，都能够保持较高的编辑精度，而且整个编辑过程不需要手动设置掩模。该研究成功展示了新的3D编辑方法的有效性，并为未来的3D内容创建提供了新的前景。
# 351. `cs.CV` - FluoroSAM: 一种用于灵活X射线图像分割的语言提示基础模型 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
X射线图像分割在诊断和介入精密医学中的人机协作流程中具有更大的灵活性。之前的努力已经贡献了任务特定模型，能够解决狭窄范围的问题，但扩大其使用范围需要额外的数据、标注和训练时间。近年来，语言对齐的基础模型（LFMs）——训练在大量高度可变的图像和文本数据上，从而实现广泛应用的机器学习模型——被认为是自动图像分析的有力工具。现有的医疗图像分析基础模型主要集中在能够获得大量丰富标注数据的场景和模态中。然而，X射线成像模态具有高度可变的图像外观和应用，从诊断胸部X射线到介入性透视，数据可用性也有所不同。
## Innovation
为了朝着能够综合分析任意医疗X射线图像的语言对齐基础模型方向发展，作者引入了FluoroSAM，这是一种从零开始训练的语言提示可调Segment Anything Model变体，该模型用于300万张合成X射线图像，并包括来自广泛人体解剖、成像几何和视角的图像。这其中包括128种器官类型和464种工具的伪地面真值掩码及其文本描述。FluoroSAM能够基于自然语言提示分割众多的解剖结构和工具，这是通过在训练过程中引入文本嵌入的矢量量化（VQ）实现的。该模型在实际X射线图像上的定量性能以及其在几个应用中的演示展示了它在X射线图像获取和分析中的丰富人机交互功能。
## Conclusion
FluoroSAM的性能验证和应用展示表明，它能够为X射线图像获取和分析提供丰富的机器辅助功能，提升人机协作交互质量。
# 352. `cs.CV` - 神经图映射：高效环视闭合集成的密集映射 [PDF](https://arxiv.org/pdf/2405.03633), [HTML](https://arxiv.org/abs/2405.03633)
## Authors
Leonard Bruns,Jun Zhang,Patric Jensfelt
## Background
神经场基于SLAM方法通常使用单一的整体场景表示。这限制了环视闭合约束的有效整合和方法的可扩展性。为此，提出了一种基于轻量级神经场的新颖RGB-D神经映射框架，这些场动态锚定于稀疏视觉SLAM系统的姿态图上，以解决现有的局限性。这一方法能够整合大规模环视闭合，同时只需要最小的重新整合。此外，通过在优化过程中考虑多项环视闭合来进行成功的大型建筑物尺度建图实验，进一步验证了该方法的可扩展性，并且在大规模场景上，我们的方法在质量和运行时间方面都优于现有的顶尖方法。
## Innovation
提出了一种基于轻量级神经场的新颖RGB-D神经映射框架，这些场动态锚定于稀疏视觉SLAM系统的姿态图上，以解决现有的局限性。这一方法能够整合大规模环视闭合，同时只需要最小的重新整合，从而提高了可扩展性和效率。在优化过程中考虑多项环视闭合，实现大型建筑物尺度建图，并且方法在质量和运行时间方面都优于现有的顶尖方法。
## Conclusion
我们提出的方法在大规模场景上表现出了更高的质量和更短的运行时间，克服了传统单一神经场方法的局限性。我们的方法已经在实践中成功应用于大型建筑物尺度建图，并且结果显示我们方法优于现有方法。完整的代码可以在 https://this.is/a/fake/url 中找到。
# 353. `cs.CV` - EAGLE: 一种用于肝包虫病病变分割的高效全局注意力模型 [PDF](https://arxiv.org/pdf/2506.20333), [HTML](https://arxiv.org/abs/2506.20333)
## Authors
Jiayan Chen,Kai Li,Yulu Zhao,Jianqiang Huang,Zhan Wang
## Background
肝包虫病（HE）是一种在未开发的牧区流行且医疗资源有限的寄生虫病。虽然基于CNN和Transformer的模型在医学图像分割方面得到了广泛的应用，但CNN缺乏全局上下文建模能力，因为其局部感受野，而虽然Transformer能捕捉长距离依赖关系，但计算成本高。因此，现有的状态空间模型（SSMs），如Mamba，因其能够用线性复杂度建模长序列而引起了注意。因此，该领域存在对高效且准确分割肝包虫病病变模型的需求。
## Innovation
本文提出了一种U型网络EAGLE，由渐进视觉状态空间（PVSS）编码器和混合视觉状态空间（HVSS）解码器组成，可以共同实现肝包虫病病变的高效和准确分割。论文设计了一个卷积视觉状态空间块（CVSSB）模块，用于融合局部和全局特征，以及一个Haar小波变换模块（HWTB），用于将空间信息压缩到通道维度，以实现无损下采样。由于没有公开的HE数据集，作者从当地医院收集了260名患者的CT切片数据进行实验。实验结果表明，EAGLE模型达到了最先进的性能，Dice相似系数（DSC）为89.76%，超越了MSVM-UNet 1.61%。
## Conclusion
EAGLE模型在肝包虫病病变分割上表现出色，达到了最先进的Dice相似系数89.76%。该模型有效地结合了局部和全局特征，实现了无损的低尺寸化，从而提高了模型的效率和准确性。
# 354. `cs.CV` - 通过保持纹理的自监督、专家混合和多任务集成实现机会性骨质疏松症诊断 [PDF](https://arxiv.org/pdf/2506.20282), [HTML](https://arxiv.org/abs/2506.20282)
## Authors
Jiaxing Huang,Heng Guo,Le Lu,Fan Yang,Minfeng Xu,Ge Yang,Wei Luo
## Background
骨质疏松症是由骨密度(BMD)减少和骨微观结构受损引起的，增加了老龄人口的骨折风险。虽然双能X射线吸收测量(DXA)是临床BMD评估的标准方法，但其访问受限阻碍了资源匮乏地区的诊断。为此，利用现有影像数据进行骨质疏松症诊断的机会性CT分析逐渐成为一种有前景的替代方案。然而，当前的方法存在三个局限：（1）未充分利用未标记的椎体数据（2）由于不同设备特定的DXA差异造成的系统性偏差（3）缺乏整合临床知识，如BMD分布模式。
## Innovation
我们提出了一种统一的深度学习框架，具有以下三个创新点。（1）使用放射学表征的自监督学习方法来利用未标记的CT数据并保留骨质纹理；（2）混合专家(MoE)架构与学习门控机制以增强跨设备的适应性；（3）多任务学习框架，整合了骨质疏松诊断、BMD回归和椎体定位预测。
## Conclusion
通过跨三家临床中心和外部医院验证，我们的方法展示出在机会性骨质疏松筛查和诊断方面的卓越泛化能力和准确性，优于现有方法。
# 355. `cs.CV` - MambaMorph: 基于Mamba的医疗MR-CT可变形配准框架 [PDF](https://arxiv.org/pdf/2401.13934), [HTML](https://arxiv.org/abs/2401.13934)
## Authors
Tao Guo,Yinuo Wang,Shihao Shu,Weimin Yuan,Diansheng Chen,Zhouping Tang,Cai Meng,Xiangzhi Bai
## Background
在医学图像分析中，跨不同模态的体素级空间对应关系捕捉至关重要。然而，当前的配准方法在准确性和临床适用性方面还不足够实用。
## Innovation
提出了MambaMorph，这是一种新颖的多模态可变形配准框架。它结合了基于Mamba的配准模块和细粒度但简单的特征提取器。此外，还开发了SR-Reg数据集，用于多模态配准的标注，以解决该领域的数据稀缺问题。实验结果表明，MambaMorph在配准准确性方面显著优于当前最先进的基于学习的配准方法，且具有高效性和轻量级特性，适合临床应用。
## Conclusion
MambaMorph在医学图像配准中具有实际应用潜力。代码可在这个 https URL 获取。
# 356. `cs.CV` - GlyphPattern: 用于视觉-语言模型的抽象模式识别基准 [PDF](https://arxiv.org/pdf/2408.05894), [HTML](https://arxiv.org/abs/2408.05894)
## Authors
Zixuan Wu,Yoolim Kim,Carolyn Jane Anderson
## Background
基于强大大型语言模型的视觉-语言模型（VLMs）在跨视觉和文本数据的推理方面取得了快速进步。虽然VLMs在训练中表现良好，但我们的实验结果强调了在抽象模式识别中的关键挑战。因此，我们提出了GlyphPattern，一个包含954项的语料库，将318个人写的视觉模式描述与3种视觉展示风格配对，涉及40种书写系统。该数据集评估了VLMs在抽象模式识别上的能力，要求模型理解并判断视觉模式的自然语言描述。这些模式源自大规模的认知科学研究，因此富含空间参考和组合性。我们的实验表明，对于最先进的VLMs（GPT-4o的准确率仅为55%），即使是少量提示也没有明显改进。详细的错误分析揭示了多个层面的挑战，包括视觉处理、自然语言理解以及模式泛化能力
## Innovation
提出了一个名为GlyphPattern的新语料库，旨在评估视觉-语言模型在抽象模式识别方面的表现，特别关注模型对视觉模式的理解和判断能力。此数据集涉及多种书写系统，且模式中包含丰富的空间参考和组合性，并且实验结果显示即使是最先进的模型也难以达到高准确率，尤其是在视觉处理和模式泛化方面表现出明显的不足
## Conclusion
我们的实验表明，目前最先进的视觉-语言模型在抽象模式识别方面仍然存在显著的挑战。虽然模型的理解和判断能力有所提升，但仍需进一步提高视觉处理、自然语言理解和模式泛化能力。
# 357. `cs.CV` - HRIBench: 在人类机器人交互中对实时视觉-语言模型的人类感知进行基准测试 [PDF](https://arxiv.org/pdf/2506.20566), [HTML](https://arxiv.org/abs/2506.20566)
## Authors
Zhonghao Shi,Enyu Zhao,Nathaniel Dennler,Jingzhen Wang,Xinyang Xu,Kaleen Shrestha,Mengxue Fu,Daniel Seita,Maja Matarić
## Background
有效的机器人人类交互（HRI）依赖于实时的人类感知，而现有的大型视觉-语言模型（VLM）虽然具备广泛的感知能力，但由于延迟较高，会严重影响用户体验并限制其在现实场景中的应用。研究领域希望系统性地评估VLM在HRI中的感知能力及性能-延迟权衡，因此提出了HRIBench基准，这是一个视觉问答（VQA）平台，旨在评估VLM在多种关键人类感知任务中的表现，包括非语言提示理解、口头指示理解、人-机器人对象关系理解、社会导航和身份识别。通过收集真实HRI环境中的数据并结合公开数据集构建问题库，HRIBench共包含1000个VQA问题，涵盖五个关键领域。研究者对多个最先进的闭源和开源VLM（共11个）进行了全面评估，结果显示这些模型在核心感知能力上仍有不足，且无法在实际部署时提供满意的性能-延迟权衡。
## Innovation
提出了HRIBench基准，这是一个专门用于评估视觉-语言模型在人类机器人交互中感知能力的新平台，涵盖了多种关键的人类感知任务。此外，研究系统性地评估了多个主流VLM的性能和延迟权衡，揭示了当前模型在实时应用中的局限性，为未来研究指明了方向。
## Conclusion
HRIBench和实验结果已发布于GitHub仓库：this https URL. 当前的VLM尽管具有广泛的感知能力，但在核心感知能力上仍有不足，且无法在实时部署时达到满意的性能-延迟权衡。未来研究需要开发小型、低延迟的VLM，以提高人类感知能力。
# 358. `cs.CV` - ULSR-GS: 多视几何一致性的超大规模表面重构高斯绘制 [PDF](https://arxiv.org/pdf/2412.01402), [HTML](https://arxiv.org/abs/2412.01402)
## Authors
Zhuoxiao Li,Shanliang Yao,Taoyu Wu,Yong Yue,Wufan Zhao,Rongjun Qin,Angel F. Garcia-Fernandez,Andrew Levers,Xiaohui Zhu
## Background
虽然高斯绘制（GS）在场景渲染和局部表面提取方面表现出高效性和高质量，但它在处理大规模航拍图像表面提取任务时存在局限性。因此，本文提出了ULSR-GS框架，专门用于解决大规模场景的高保真表面提取问题，并克服了现有基于GS的网格提取方法的限制。
## Innovation
文章提出了点到图片的分区方法结合多视图最优视图匹配原则来为每个子区域选择最佳训练图片。此外，在训练过程中，ULSR-GS采用了基于多视几何一致性的稠密化策略，以增强表面提取细节。
## Conclusion
实验结果表明，ULSR-GS在大规模航拍摄影测量基准数据集上优于其他基于GS的先进方法，显著提高了复杂城市环境中的表面提取精度。
# 359. `cs.CV` - 无匹配的结构光深度恢复 [PDF](https://arxiv.org/pdf/2501.07113), [HTML](https://arxiv.org/abs/2501.07113)
## Authors
Zhuohang Yu,Kai Wang,Kun Huang,Juyong Zhang
## Background
本文介绍了使用单目结构光系统获得的图像进行深度估计的一种新方法。大多数现有方法依赖于图像配对，而本文的方法使用密度体素网格表示场景几何结构，并通过自监督可微体积渲染进行训练。通过将颜色场与结构光系统中投影模式获取的颜色场结合，本文方法独立优化几何场，从而实现更快的收敛和高质量的结果。此外，本文还结合了归一化设备坐标（NDC）、失真损失和基于表面的颜色损失，以提高几何保真度。实验结果显示，本文方法在几何性能方面超越了当前基于匹配的技术，在少量样本的场景中，平均估计深度误差减少了约30%，适用于合成场景和真实场景。此外，本文的方法具有快速训练的特点，比利用隐式表示的无匹配方法快约三倍。
## Innovation
本文采用密度体素网格来表示场景几何结构，并通过自监督可微体积渲染进行训练；通过结合颜色场和投影模式，引入了色散损失和表面基色损失，以提高几何保真度；并且训练速度快于现有的无匹配方法。
## Conclusion
本文提出的方法在几何性能方面显著优于基于匹配的技术，特别是在少数样本的场景中。训练时间比之前的无匹配方法快约三倍。
# 360. `cs.CV` - 基于通道意识的自适应照明学习 [PDF](https://arxiv.org/pdf/2412.01493), [HTML](https://arxiv.org/abs/2412.01493)
## Authors
Qirui Yang,Peng-Tao Jiang,Hao Zhang,Jinwei Chen,Bo Li,Huanjing Yue,Jingyu Yang
## Background
良好的视知觉和下游视觉任务的支持需要学习照明适应。当前研究通常单独解决与光相关的挑战，比如高动态范围成像和曝光校正。然而，这些任务共享一些基本性质：不同色彩通道有不同的光属性，这些属性在空间和频域中的表现形式也不尽相同。利用这些洞察，我们引入了考虑色彩通道的自适应照明学习网络（LALNet），这是一种多任务框架，旨在高效应对多种与光相关的问题。LALNet结合了色彩分离特征和引导色彩混合特征的光引导注意力机制（LGA），通过双重领域通道调制生成色彩分离特征，并通过混合通道调制及光状态空间模块生成色彩混合特征。在四项代表性与光相关任务上进行的广泛实验表明，LALNet在基准测试中显著优于现有方法，同时具有较低的计算资源需求。还提供了匿名在线演示。
## Innovation
提出了考虑色彩通道的自适应照明学习网络（LALNet），结合色彩分离特征和引导色彩混合特征的光引导注意力机制（LGA），以及双重领域通道调制和混合通道调制及光状态空间模块。LALNet能够高效应对与光相关的多种任务，在实验中表现出色，并且计算资源需求低。
## Conclusion
通过提出LALNet网络，本文显著改善了自适应照明学习的性能，并且在与光相关的多项任务中达到了最优表现。此外，该网络对于色彩一致性有很好的保证，同时也更为节省计算资源。
# 361. `cs.CV` - USP-Gaussian: 统一基于尖峰的图像重构、姿态校正和Gaussian散点图 [PDF](https://arxiv.org/pdf/2411.10504), [HTML](https://arxiv.org/abs/2411.10504)
## Authors
Kang Chen,Jiyuan Zhang,Zecheng Hao,Yajing Zheng,Tiejun Huang,Zhaofei Yu
## Background
尖峰相机是一种新颖的神经形态相机，能够以0-1位流方式以40 kHz的速率捕获场景，这些相机越来越被用于使用Neural Radiance Fields (NeRF)或3D Gaussian Splatting (3DGS)进行3D重建任务。之前的基于尖峰的3D重建方法通常采用分步的流水线方式，首先利用已有的尖峰到图像重建算法从尖峰流中重建高质量的图像，然后进行相机姿态估计和3D重建。然而，这种分步方法会导致大量累积误差，初始图像重建的质量限制最终影响姿态估计，从而降低3D重建的质量。
## Innovation
本文提出了一种名为USP-Gaussian的协同优化框架，该框架将基于尖峰的图像重构、姿态校正和Gaussian散点图统一到一个端到端的框架中。该框架利用3DGS的多视角一致性以及尖峰相机的运动捕捉能力，实现了一个联合迭代优化过程，无缝地整合了来自尖峰到图像网络和3DGS之间的信息。实验结果表明，在准确姿态的情况下，该方法可以有效地消除分步方法中累积的错误，且通过引入姿态优化实现了在现实世界场景下具有不准确初始姿态时的稳健3D重建，有效地减少了噪声并保留了细部纹理细节，方法的表现优于现有方法。开源代码、数据和训练模型可在指定的链接中获取。
## Conclusion
本文提出的USP-Gaussian框架有效地解决了基于尖峰的3D重建过程中存在的累积误差问题，通过从初始图像重建到姿态校正和3D散点图生成的联合优化，提高了3D重建的精度和有效性，尤其是在现实场景中能够更好地处理初始姿态不准确的问题。
# 362. `cs.CV` - VICCA: 视觉解释和理解生成报告中胸部X光异常无需人类反馈 [PDF](https://arxiv.org/pdf/2501.17726), [HTML](https://arxiv.org/abs/2501.17726)
## Authors
Sayeh Gholipour Picha,Dawood Al Chanti,Alice Caplier
## Background
随着人工智能(AI)在医疗领域的日益普及，对于可解释且可信的AI模型的需求变得至关重要。当前的胸部X光(CXR)报告生成系统往往缺乏在没有专家监督的情况下验证输出的机制，这引发了关于可靠性和可解释性的担忧。为应对这些挑战，该研究提出了一个创新的多模态框架，旨在增强AI生成医疗报告的语义对齐和定位准确性。该框架通过两个关键模块实现：词项锚定模型，通过文本提示识别并定位影像中的病理学；文本到图像扩散模块，从提示生成合成的X光图像同时保持解剖结构的准确度。通过对比原始图像和生成图像的特征，研究引入了一种双重评分系统，分别衡量定位准确性和语义一致性，显著优于现有方法，取得了病理定位和文本到图像对齐的最先进成果。词项锚定与扩散模型的结合，加上双重评分评价体系，提供了一种验证报告质量的稳健机制，为更可信和透明的医疗影像AI铺平了道路。
## Innovation
该研究提出了一种创新的多模态框架，通过结合词项锚定模型和文本到图像扩散模块，显著提升了AI生成的医疗报告的语义对齐和定位准确性。这提供了一种验证报告质量的新方法，有助于建立更可信和透明的医疗影像AI。
## Conclusion
通过双重评分系统，研究展示了其在病理定位和文本到图像对齐上的卓越性能，达到了最先进的技术水平。研究还表明，将词项锚定与扩散模型相结合，以及使用双重评分系统进行验证，能够有效地确保AI生成的医疗报告的质量，推进了AI在医疗影像领域的应用。
# 363. `cs.CV` - MagicPose4D：使用外观和运动控制构建动态模型 [PDF](https://arxiv.org/pdf/2405.14017), [HTML](https://arxiv.org/abs/2405.14017)
## Authors
Hao Zhang,Di Chang,Fang Li,Mohammad Soleymani,Narendra Ahuja
## Background
随着2D和3D视觉生成模型的成功，人们越来越关注生成4D内容。现有的方法主要依赖于文本提示来生成4D内容，但这些方法在定义复杂或罕见的运动时常常不够准确。因此，需要一种能够更好地控制4D内容外观和运动的方法，以实现更精确和个性化的控制。
## Innovation
本文提出了MagicPose4D，一种新颖的框架，用于对4D生成中的外观和运动进行精细控制。与现有方法不同，MagicPose4D采用单摄像头视频或网格系列作为运动提示，实现精确和可定制的运动控制。该方法包括两个关键模块：（i）双阶段4D重构模块，分为两阶段进行：第一阶段利用准确的2D监督和几何信息丰富的疏精度3D伪监督捕捉模型形状，但不施加骨骼约束；第二阶段使用来自第一阶段的更准确的伪3D监督提取3D运动，并引入基于运动链的骨骼约束确保物理合理性；（ii）跨类别运动转移模块，利用4D重构模块提取的运动和基于运动链的骨骼实现跨类别的运动转移，通过动态刚度确保帧之间的平滑过渡，无需额外训练。
## Conclusion
通过广泛的实验表明，MagicPose4D在4D内容生成的准确性和一致性方面显著优于现有的方法，在各种基准测试中均表现优异。
# 364. `cs.CV` -  Toddlers' Active Gaze Behavior Supports Self-Supervised Object Learning  [PDF](https://arxiv.org/pdf/2411.01969), [HTML](https://arxiv.org/abs/2411.01969)
## Authors
Zhengyang Yu,Arthur Aubret,Marcel C. Raabe,Jane Yang,Chen Yu,Jochen Triesch
## Background
幼儿在几乎没有监督的情况下能够学会从不同角度识别物体。在这个过程中，他们会经常执行眼睛和头部运动，这些行为影响他们的视觉体验。然而，目前尚不清楚这些行为如何以及在多大程度上促进幼儿对物体识别能力的发展。为了解决这个问题，研究人员结合了基于头戴式眼动追踪的双人玩耍实验和无监督机器学习技术。
## Innovation
通过使用头戴式相机捕捉当前注视点的图像区域，并将其输入一个无监督的学习模型中，该模型会随着时间缓慢构建视觉表征。实验表明，幼儿的注视策略有助于建立不变的物体表征。此外，研究揭示了高分辨率视觉场的局限性在这一过程中的关键作用。
## Conclusion
总体而言，本研究揭示了幼儿的注视行为可能如何支持其视点不变的物体识别能力的发展。
# 365. `cs.CV` - MatSwap: 光敏的图像中材料转移 [PDF](https://arxiv.org/pdf/2502.07784), [HTML](https://arxiv.org/abs/2502.07784)
## Authors
Ivan Lopes,Valentin Deschaintre,Yannick Hold-Geoffroy,Raoul de Charette
## Background
在图像中实现材料属性的精确交换是一个具有挑战性的问题，因为它涉及到材质外观、几何形状和光照的复杂交织。目前的材料编辑方法通常依赖于繁琐的文本工程或需要艺术家知识及难以获取的3D场景属性的大量手动注释。研究人员希望开发一种方法，能够在不需要显式UV映射的情况下直接学习平坦表面上观察到的材质与其在场景中的外观之间的关系，从而实现在照片中无缝集成所需材质并保留场景的身份。
## Innovation
我们提出了MatSwap方法，这是一种直接学习与输入材料（如在平坦表面上观察到的）和其在场景中的外观之间的关系的方法，无需进行显式的UV映射。我们依赖于一个自定义的光敏感性和几何约束扩散模型，通过使用合成数据集对一个大规模预训练的文本转图像模型进行微调，以确保有效泛化到真实图片。这种方法在合成和真实图像上的评估显示，它与近期工作相比在定性和定量上表现良好。
## Conclusion
我们的方法能够将所需的材质无缝地集成到照片中的目标位置，同时保持场景的原始身份。通过这种方法，我们成功地在不需要显式UV映射的情况下实现了材质的转移。我们通过合成和真实图像进行了评估，并展示了与最近工作的优良比较结果。我们已经发布了我们的代码和数据。
# 366. `cs.CV` - 基于AI系统的医疗图像像素级保护健康信息检测设计探索 [PDF](https://arxiv.org/pdf/2501.09552), [HTML](https://arxiv.org/abs/2501.09552)
## Authors
Tuan Truong,Ivo M. Baltruschat,Mark Klemens,Grit Werner,Matthias Lenga
## Background
医疗图像去识别是研究和临床环境中确保数据共享隐私的关键步骤。初始步骤涉及检测保护健康信息（PHI），这些信息可能存在于图像元数据中或直接标在图像像素上。尽管此类系统的重要性不言而喻，但现有基于AI的解决方案仍缺乏评估，阻碍了可靠且鲁棒工具的开发。
## Innovation
本研究提出了一种基于AI的PHI检测管道，包含三个模块：文本检测、文本提取和文本分析。研究比较了YOLOv11、EasyOCR和GPT-4o三款模型在不同设置下的表现，并评估它们在涵盖多种影像模态和PHI类别的两个不同数据集上的性能。结果显示，最佳设置是为每个模块使用专门的视觉和语言模型，这在性能、延迟和使用大型语言模型（LLMs）的成本方面表现出良好的平衡。此外，研究表明LLMs的应用不仅限于识别PHI内容，还提升了OCR任务，并促进端到端的PHI检测流程，通过分析展示了有希望的结果。
## Conclusion
研究结果表明，针对每个模块使用专用的视觉和语言模型的设置，能在性能、延迟和使用大型语言模型的成本方面取得良好平衡。通过应用大型语言模型，不仅解决了PHI识别问题，还通过改善OCR任务增强了整个端到端的PHI检测流程，展示了有前景的结果。
# 367. `cs.CV` - ReconX: 使用视频扩散模型从稀疏视角重建任意场景 [PDF](https://arxiv.org/pdf/2408.16767), [HTML](https://arxiv.org/abs/2408.16767)
## Authors
Fangfu Liu,Wenqiang Sun,Hanyang Wang,Yikai Wang,Haowen Sun,Junliang Ye,Jun Zhang,Yueqi Duan
## Background
3D场景重建的进步已经将现实世界的2D图像转化为3D模型，从数百张输入照片中生成逼真的3D结果。尽管在密集视角重建场景中取得了巨大成功，但从不足的拍摄视角渲染详细场景仍然是一个病态优化问题，经常在未见区域产生伪像和失真。现有的方法难以在直接生成的视频帧中准确保持3D视图一致性。
## Innovation
提出了一种名为ReconX的新颖3D场景重建范式，将模糊的重建挑战重新构想为时间生成任务。关键洞察是利用大型预训练视频扩散模型的强大生成先验来解决稀疏视角重建问题，同时确保生成视频帧中的细节保真和高3D一致性，最终通过一种基于置信的3D高斯溅射优化方案重建3D场景。
## Conclusion
在不同现实世界的数据集上进行的广泛实验显示，我们的ReconX方法在质量和泛化能力上明显优于现有最先进的方法。
# 368. `cs.CV` - 通过生成模型的可靠化进行图像超分辨率 [PDF](https://arxiv.org/pdf/2502.09664), [HTML](https://arxiv.org/abs/2502.09664)
## Authors
Eduardo Adame,Daniel Csillag,Guilherme Tegoni Goedert
## Background
随着生成机器学习基础模型在图像恢复任务（如超分辨率）中的广泛应用，对于鲁棒且可解释的不确定性量化方法的需求日益增加。本文背景在于现有方法尚无法有效解决这一需求，因此需要一种新的解决方案来应对这一挑战。
## Innovation
本文引入了一种基于符合性预测技术的新颖方法，以创建一种‘置信度蒙版’，可以可靠且直观地传达生成图像中可信任的区域。创新点在于该方法能够适应任何黑盒生成模型，即使模型背后有不透明的API也适用。同时也能够仅使用容易获得的数据进行校准，并通过选择局部图像相似度度量高度可定制。该方法提供了强大的理论保证，涵盖了保真度误差控制（根据局部图像相似度度量）、重建质量以及在数据泄露面前的鲁棒性。
## Conclusion
本文通过理论和实验证明了所提出方法的有效性，建立了一个稳健的性能基线。
# 369. `cs.CV` - 通过全球视野审视扩散模型：它们是否具有文化包容性？ [PDF](https://arxiv.org/pdf/2502.08914), [HTML](https://arxiv.org/abs/2502.08914)
## Authors
Zahra Bayramli,Ayhan Suleymanzade,Na Min An,Huzama Ahmad,Eunsu Kim,Junyeong Park,James Thorne,Alice Oh
## Background
文本到图像扩散模型能够从文本提示中生成视觉上引人入胜、细节丰富的图像。然而，这些模型在准确表现各种文化差异方面的能力仍是一个开放的问题。这项工作中，我们提出了一种名为CultDiff的基准，评估最先进的扩散模型是否能够生成涵盖十个国家的文化特定图像。研究表明，这些模型在生成与建筑、服装和食物相关文化特征的图像，尤其是对代表性不足的国家地区方面经常失败，通过不同相似性方面的精细分析揭示了与真实世界参考图像相比，在文化相关性、描述准确性和现实感方面的显著差异。
## Innovation
我们开发了一种基于神经网络的图像-图像相似性度量方法，即CultDiff-S，用于预测真实和生成的文化特征图像的人类评判。这一方法揭示了现有扩散模型在文化包容性方面的不足，强调了需要构建更加包容的生成型人工智能系统并实现广泛文化范围内的公平数据集表示的必要性。
## Conclusion
我们的研究强调了对于生成型人工智能系统需要有更具包容性的表现，并且需要在广泛的跨文化范围内实现公平的数据集表示。
# 370. `cs.CV` - LPOSS：基于片段和像素传播标签的开放词汇语义分割 [PDF](https://arxiv.org/pdf/2503.19777), [HTML](https://arxiv.org/abs/2503.19777)
## Authors
Vladan Stojnić,Yannis Kalantidis,Jiří Matas,Giorgos Tolias
## Background
针对视觉和语言模型（VLMs）在开放词汇语义分割中的不足，主要优化在于跨模态对齐而非内部模态相似性，以及片段基础编码器固有的分辨率限制，该研究提出了一种无需训练的方法来提高预测准确性并增强语义分割结果。
## Innovation
提出了一种基于片段和像素的标签传播方法（LPOSS+），通过片段到片段的相互关系优化初始片段预测，并在像素级别应用标签传播进行精细化处理。该方法能够覆盖整个图像进行推断，捕捉全局上下文交互，显著提高分割精度，特别是在类边界附近。相比其他训练免费方法，LPOSS+在多种数据集上达到了最先进的性能。
## Conclusion
LPOSS+作为一种无需训练的方法，在多种语义分割任务上取得了SOTA性能，通过标签传播和精细化处理显著提升了分割精度，特别是在处理类边界时。
# 371. `cs.CV` - FGS-SLAM: 基于傅里叶变换的高斯散点法用于融合稀疏和密集地图的实时SLAM [PDF](https://arxiv.org/pdf/2503.01109), [HTML](https://arxiv.org/abs/2503.01109)
## Authors
Yansong Xu,Junlin Li,Wei Zhang,Siyu Chen,Shengyong Zhang,Yuquan Leng,Weijia Zhou
## Background
3D高斯散点方法已经提高了同时定位与建图（SLAM）技术，使实时定位和高保真地图构建成为可能。然而，高斯位置和初始化参数的不确定性提出了挑战，往往需要大量的迭代收敛，导致高斯表示冗余或不足。这影响了SLAM系统的性能和实时性。
## Innovation
提出了一种基于傅里叶频域分析的自适应稠化方法来建立高斯先验，以实现快速收敛。此外，提出构建独立的稀疏和密集地图，其中稀疏地图通过广义迭代最邻近点（GICP）支持高效跟踪，而密集地图创建高保真的视觉表示。这是首次使用频域分析实时实现高质量高斯地图的SLAM系统。
## Conclusion
实验结果表明，在Replica和TUM RGB-D数据集上平均帧率为36 FPS，定位和建图准确性都达到了竞争水平。
# 372. `cs.CV` - 通过分离表示实现的眼科疾病分级的稳健多模态学习 [PDF](https://arxiv.org/pdf/2503.05319), [HTML](https://arxiv.org/abs/2503.05319)
## Authors
Xinkun Wang,Yifang Wang,Senwei Liang,Feilong Tang,Chengzhi Liu,Ming Hu,Chao Hu,Junjun He,Zongyuan Ge,Imran Razzak
## Background
眼科医生经常依赖多模态数据来提高诊断准确性，但由于医疗设备缺乏和数据隐私问题，实际应用中很难获得完整的多模态数据。传统深度学习方法通常通过在潜在空间中学习特征来应对这些问题，但存在两个主要限制：(i) 复杂模态中的与任务无关的冗余信息（例如，多个切片）导致潜在空间表示的冗余。(ii) 重叠的多模态表示使提取每种模态的独特特征变得困难。这些限制限制了多模态学习的鲁棒性和可解释性，特别是在眼科疾病诊断中。
## Innovation
本文的创新在于提出了Essence-Point和分离表示学习(EDRL)策略，该策略将自我蒸馏机制整合进端到端框架中，以增强特征选择和分离，促进更稳健的多模态学习。具体来说，Essence-Point表示学习模块选择能提高疾病分级性能的判别性特征，而分离表示学习模块则将多模态数据分离为模态共有的和模态特有的表示，从而减少特征纠缠，提高在眼科疾病诊断中的鲁棒性和可解释性。
## Conclusion
实验结果表明，所提出的EDRL策略在多模态眼科疾病数据集上显著优于当前的最先进的方法。
# 373. `cs.CV` - 世界一致数据生成方法在视觉语言导航中的应用 [PDF](https://arxiv.org/pdf/2412.06413), [HTML](https://arxiv.org/abs/2412.06413)
## Authors
Yu Zhong,Rui Zhang,Zihao Zhang,Shuo Wang,Chuan Fang,Xishan Zhang,Jiaming Guo,Shaohui Peng,Di Huang,Yanyang Yan,Xing Hu,Qi Guo
## Background
视觉语言导航（VLN）是一项具有挑战性的任务，要求代理遵循自然语言指令在逼真的环境中导航。现有一个主要障碍是数据稀缺，导致代理在未见过的环境中表现不佳。尽管增强数据可以通过数据扩充扩大数据集的规模，但在生成既多样又符合现实世界的数据方面仍然存在问题。为了应对这一问题，本文提出了世界一致的数据生成（WCGEN）框架，该框架旨在增强代理对新环境的泛化能力，同时满足多样性和世界一致性。该框架包括两个阶段：路径阶段确保视角之间空间一致性，视角阶段通过新的角度合成方法保证整个观察过程的空间和环绕一致性。
## Innovation
本文提出了一种世界一致数据生成框架WCGEN，该框架能够生成多样且符合现实世界的导航数据。与传统方法相比，WCGEN利用3D知识准确预测视角变化，从而在生成过程中保持世界一致性。实验表明，WCGEN能够显著提高代理在未见过环境中的泛化能力，使得VLAN代理在所有导航任务上达到新的最佳性能。
## Conclusion
本文提出的世界一致数据生成框架WCGEN能够显著提升视觉语言导航代理在未见过环境中的泛化能力，通过准确预测视角变化维护了世界一致性。实验结果验证了该方法的有效性，表明生成的数据增强策略能够使代理在所有导航任务上达到新的最佳性能。
# 374. `cs.CV` - 使用Siamese网络检测两张虹膜图像是否来源于单卵双胞胎 [PDF](https://arxiv.org/pdf/2503.09749), [HTML](https://arxiv.org/abs/2503.09749)
## Authors
Yongle Yuan,Kevin W. Bowyer
## Background
在Daugman风格的虹膜识别中，同一人左右两侧虹膜的纹理传统上被认为是与其他人的虹膜纹理一样不同。然而，先前的研究表明，人类能够以大约80%的准确率识别两张虹膜图像是否来自同一人的眼睛，或单卵双胞胎的眼睛。这项研究设计了一个自动分类器来解决虹膜识别中尚未解决的问题，即判断一对虹膜图像是否来自单卵双胞胎。通过构建包含合成单卵双胞胎对（同一人不同虹膜的图像）和天然单卵双胞胎对（来自同卵双胞胎的图像）的数据集，研究评估了模型的性能。
## Innovation
研究采用了Siamese网络架构和对比学习方法，在保留完整虹膜图像以及仅保留虹膜区域和非虹膜区域的前提下训练和分析三种模型变体。这种方法揭示了虹膜纹理及其周围眼部结构的信息对模型分类这对图像是否来自单卵双胞胎是有用的。研究方法实现了超过人类分类单卵双胞胎虹膜对的准确性。
## Conclusion
本研究表明，使用Siamese网络可以实现虹膜图像是否来自单卵双胞胎的自动化分类，且分类准确度超过了人类的识别水平。不同输入类型（全虹膜图像、仅虹膜区和非虹膜区）的数据分析表明，虹膜纹理及周围眼部结构信息对模型至关重要。该方法为快速、非侵入性检测双胞胎是否为单卵双胞胎提供了一种潜在应用。
# 375. `cs.CV` - MaizeField3D: 来自多样性株系的田间种植玉米的3D点云和程序化模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
## Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
## Background
由于缺乏大型和多样化的3D数据集，基于人工智能和机器学习的3D表型分析工具的发展受到限制，特别是在玉米研究中。2D图像数据集无法捕捉3D数据提供的关键结构细节，如叶片结构、植物体积和空间安排。这些限制导致了玉米表型分析技术的发展滞后。因此，迫切需要开发一种能够克服这些限制的3D数据集，以推动农业研究的进步。
## Innovation
本文介绍了一个名为MaizeField3D的新数据集，它包含1,045个田间种植玉米的3D点云，来自一个多样化的遗传面板。这些点云数据通过陆基激光扫描仪（TLS）收集，并通过图基分割方法进行分割和注释以隔离叶片和茎秆，确保样本之间的一致性标签。该数据集不仅提供了按比例参数化的玉米植物模型，还使用非均匀理性B样条（NURBS）曲面表示叶片，通过两步优化过程生成。此外，该数据集还包含高分辨率点云数据和多分辨率子抽样点云数据（100k、50k、10k点），可用于不同下游计算任务。MaizeField3D为人工智能驱动的表型分析、植物结构分析和农业中的3D应用提供了完整的基础数据集，克服了现有的数据集不足的问题。
## Conclusion
MaizeField3D是一个专门用于玉米的3D点云和程序化模型数据集，能够为农业研究中的表型分析和3D应用提供全面的基础。通过这项研究，我们成功克服了二维图像数据集的局限性，提供了更全面的三维结构细节，为未来的人工智能技术在农业中的应用奠定了坚实的基础。
# 376. `cs.CV` - 从O(n^2)到O(n)参数：用于生物医学图像分类的视觉Transformer中的量子自注意力 [PDF](https://arxiv.org/pdf/2503.07294), [HTML](https://arxiv.org/abs/2503.07294)
## Authors
Thomas Boucher,John Whittle,Evangelos B. Mazomenos
## Background
本文讨论了一种新颖的视觉变换器（Vision Transformer，ViT），其自注意力（Self-Attention，SA）机制被量子自注意力（Quantum Self-Attention，QSA）机制所替换。研究背景是基于当前最优的（State-of-the-Art，SOTA）生物医学图像分类器，展示了如何通过减少参数数量，同时保持与SOTA方法相当甚至更好性能的视觉变换器的应用潜力。通过将线性SA层替换为参数化的量子神经网络（Parameterized Quantum Neural Networks，PQNNs），实现了从O(n^2)减少到O(n)的参数数量的压缩，并在RetinaMNIST数据集上取得了56.5%的准确率，比当前最优模型低0.88%，但使用了99.99%更少的参数和89%更少的计算量（1K vs 14.5M）.
## Innovation
本文的创新点集中在量子自注意力（QSA）机制上的应用，通过量子自注意力机制替代传统的自注意力机制，实现了参数数量从O(n^2)压缩到O(n)，并通过知识蒸馏（Knowledge Distillation，KD）技术进一步提高了模型的性能。这项研究首次展示了如何从经典的视觉变换器中蒸馏知识到量子视觉变换器，展示了量子视觉变换器在多种模态的八种不同数据集上的可比性能，并表明更高的量子比特架构可以从KD预训练中受益更多，揭示了QSA参数和KD效性之间的潜在关联.
## Conclusion
本文的研究结果表明，QSA作为一种实用的架构选择，可以在减少参数的同时实现高效且精度高的生物医学图像分析。这种新型的视觉变换器对未来的生物医学图像处理领域具有重要意义，同时，知识蒸馏策略的应用为量子自注意力的进一步优化提供了新的视角。
# 377. `cs.CV` - 大型视觉语言模型中的形状和纹理识别 [PDF](https://arxiv.org/pdf/2503.23062), [HTML](https://arxiv.org/abs/2503.23062)
## Authors
Sagi Eppel,Mor Bismut,Alona Faktor-Strugatski
## Background
形状和纹理是视觉感知的基本构建块。识别形状而不受其方向、纹理或上下文的影响，以及独立于相关对象识别纹理和材料，对于理解世界的视觉结构至关重要。本研究通过利用自然图像中未监督提取的模式创建了一个名为LAS&T的大规模多样形状和纹理数据集，这是为了测试大型视觉语言模型（LVLM）在二维和三维场景中对形状、纹理和材料的理解能力。研究结果表明，这些模型在形状识别上的表现远低于人类的标准，特别难以识别抽象的形状。对于纹理和材料识别，尽管在三维场景中，大型视觉语言模型在识别材料方面达到了人类水平，但在识别简单的抽象二维纹理方面表现不如人类。这些结果表明，目前主流的视觉语言模型在理解基本视觉概念方面存在明显不足，但简单的直接训练网络在这些任务上表现优异。
## Innovation
研究引入了大规模形状和纹理数据集（LAS&T），该数据集通过从自然图像中提取未监督的模式构建，具备高度多样性。利用该数据集评估了当前最主流的大型视觉语言模型在形状、纹理和材料识别上的表现，揭示了现有模型的缺陷，展示了简单直接的训练网络在这些特定任务上的强大能力。
## Conclusion
大型视觉语言模型在形状识别方面表现远低于人类，尤其在抽象形状和复杂纹理的识别上表现较差。尽管在三维场景中对于材料识别的表现接近人类，但对于简单的二维纹理识别，人类的表现仍远胜于这些模型。同时，研究展示了一些简单的直接训练网络在这些特定视觉任务上具有高精度。该研究的数据集（LAS&T）包含了超过60万张用于二维和三维形状、纹理和材料识别与检索的图像，已被公开。
# 378. `cs.CV` - 移动摄影中的时感知自动白平衡 [PDF](https://arxiv.org/pdf/2504.05623), [HTML](https://arxiv.org/abs/2504.05623)
## Authors
Mahmoud Afifi,Luxi Zhao,Abhijith Punnappurath,Mohammed A. Abdelsalam,Ran Zhang,Michael S. Brown
## Background
自动白平衡（AWB）功能依赖于相机的自动白平衡算法来纠正由于场景照明和相机光谱灵敏度引起的不必要色彩偏差。传统方法通常通过光源估算器来确定单一的全局色彩偏差，该估算器仅基于相机原始传感器图像中的色彩信息。移动设备提供了如拍摄时间戳和地理位置这样的宝贵元数据，这些信息能够提供强有力的情境线索，帮助缩小可能的照明解决方案范围。然而，现有方法大多未充分利用这些额外的捕获信息和色彩数据，并且在使用较小模型时表现欠佳。此研究旨在探讨如何纳入这些上下文元数据来改进AWB性能，特别是在使用紧凑型模型方面取得显著成果，最终达到或超越了更大规模模型的表现。为此，研究者新构建了一个包含3,224张智能手机图像的数据集，这些图像在不同时间段和多变的照明条件下收集了上下文元数据，同时提供了真彩色识别和用户喜好的验证信息，用以全面评估AWB效果.
## Innovation
提出了一种轻量级的光源估算方法，该方法结合了上下文元数据、捕获信息和图像色彩，集成到一个包含约5,000个参数的紧凑模型中，实现了较为出色的AWB效果。相比于其他模型，这种新方法在某些情境下达到了或超越了大型模型的表现，特别是通过有效的利用移动设备提供的额外元数据来显著改善了AWB的准确性和鲁棒性。此外，研究者还创建了一个新的数据集，为未来AWB方法的评估提供了一个综合的标准和基准。
## Conclusion
该研究通过开发包含上下文元数据的轻量级AWB模型取得了重要的进展，该模型表现良好且参数量少，在多个光源估计任务中表现出了较好的性能。所提出的模型在保持较低计算成本的同时，能够有效地根据不同时间段和不同光照条件变化，调整相机的白平衡。为了验证该方法的有效性，作者通过一个新构建的数据集进行了实证分析，并证明了该方法具备广泛的适用性和优越性，为移动图像处理中的AWB研究提供了新的思路。
# 379. `cs.CV` - 来自皮肤镜图像的肤色测量：基于合成数据集的评估 [PDF](https://arxiv.org/pdf/2504.04494), [HTML](https://arxiv.org/abs/2504.04494)
## Authors
Marin Benčević,Robert Šojo,Irena Galić
## Background
本文介绍了一种对使用合成数据集（S-SYNTH）测量皮肤颜色方法的全面评估，该数据集控制了真黑色素含量、病变形状、毛发模型和18种不同的光照条件。这种设置允许对各种成像颜色方法在不同光照条件下的鲁棒性和光照不变性进行严格的评估。本文评估了四种图像颜色测量方法：基于分割的方法、基于片段的方法、色彩量化方法和神经网络方法。这些方法被用来估计皮肤镜图像中的个体类型角（ITA）和弗吉尼亚氏型。研究表明，基于分割的方法和色彩量化方法可以提供鲁棒且不受光照条件影响的估计，而基于片段的方法表现出显著的光照依赖性偏差，需要进行校准。此外，特别是组合了重度去模糊处理以减少过拟合的神经网络模型，能在一定程度上提供不受光照影响的弗吉尼亚氏预测，但其在实际图像中的泛化能力尚未得到验证。文章最后提出了一系列实用建议，以设计公平和可靠的方法来估计皮肤颜色。
## Innovation
该研究使用了一个控制了各种变量的合成数据集，对不同方法的性能进行了评估，特别是验证了基于分割的方法和色彩量化方法的光照鲁棒性，强调了深度学习模型在特定条件下能够提供较好的结果，但需要进一步验证其在实际应用中的性能。
## Conclusion
本文得出结论，基于分割的方法和色彩量化方法的估算结果更具有鲁棒性和光照不变性，而基于片段的方法在实际应用中可能需要校准以补偿其光照依赖性偏差。神经网络模型，尤其是经过适当的去模糊处理，能够提供光照不变的弗吉尼亚氏预测结果，但在真实场景中的效果仍需进一步验证。
# 380. `cs.CV` - 4D运动建模中的时间差分场通过图像到视频合成 [PDF](https://arxiv.org/pdf/2505.17333), [HTML](https://arxiv.org/abs/2505.17333)
## Authors
Xin You,Minghui Zhang,Hanxiao Zhang,Jie Yang,Nassir Navab
## Background
在医学图像引导临床应用中，基于定期呼吸引起的运动的时间建模至关重要。现有方法除非同时拥有起始和结束帧的高剂量成像扫描，否则无法模拟时间上的运动。然而，在术前图像采集阶段，患者的轻微移动会导致呼吸周期内的起始帧和末帧之间的动态背景，这种额外的偏离难以通过图像配准去除，从而影响时间建模的准确性。因此，本研究致力于通过图像到视频合成框架模拟定期的运动过程，并提出了时间差分扩散模型，以生成衡量相邻帧之间相对差分表示的时间差分场，同时引入关注提示层和场增强层以更好地与I2V框架交互，提高合成视频的时序变化准确性。
## Innovation
本研究创新性地采用图像到视频（I2V）合成框架模拟定期的运动过程，提出了时间差分扩散模型来生成衡量相邻帧之间相对差分表示的时间差分场，还设计了关注提示层和场增强层，以更好地与I2V框架交互，促进合成视频的时间变异更为准确。在ACDC心脏和4D肺部数据集上进行了广泛的实验，结果表明，提出的模型在感知相似性和时间一致性方面与其它竞争性方法相当甚至优于它们。
## Conclusion
本研究提出了一种基于图像到视频合成时间差分场的方法，能够模拟沿内在运动轨迹的4D视频，并在ACDC心脏和4D肺部数据集上展示了其在感知相似性和时间一致性方面的优越性能，可以与其它竞争方法媲美。
# 381. `cs.CV` - PanoWan: 使用经度/纬度感知机制将扩散视频生成模型提升至360° [PDF](https://arxiv.org/pdf/2505.22016), [HTML](https://arxiv.org/abs/2505.22016)
## Authors
Yifei Xia,Shuchen Weng,Siqi Yang,Jingqi Liu,Chengxuan Zhu,Minggui Teng,Zijian Jia,Han Jiang,Boxin Shi
## Background
全景视频生成能够创建沉浸式的360°内容，被广泛应用于场景一致的场景探索需求中。然而，现有的全景视频生成模型难以利用预训练的文本到视频生成先验模型，因为数据集规模有限且在空间特征表示上存在差距，导致生成高质量和多样化的全景视频存在问题。
## Innovation
PanoWan 提出了一种新的方法，它是将预训练的文本到视频生成模型提升到全景域的有效方式，配备了最少的模块。PanoWan 使用纬度感知采样来避免纬度失真，并通过旋转语义去噪和补足像素级解码确保经度边界处的无缝过渡。为了提供足够多的高质量全景视频供学习，作者贡献了一个名为 PanoVid 的数据集，其中包括了具有中文字幕和多样场景的全景视频。
## Conclusion
PanoWan 获得了全景视频生成领域的最好性能，并在零样本下游任务中表现出稳健性。项目页面可以在this https URL找到。
# 382. `cs.CV` - WoundAmbit：将最先进的语义分割与实际伤口护理相连 [PDF](https://arxiv.org/pdf/2504.06185), [HTML](https://arxiv.org/abs/2504.06185)
## Authors
Vanessa Borst,Timo Dittus,Tassilo Dege,Astrid Schmieder,Samuel Kounev
## Background
慢性伤口影响大量人群，尤其是老年人和糖尿病患者，这类人群通常存在活动受限和共病情况。通过移动影像捕捉进行自动化伤口监测可以减少面对面的医生访视，实现远程跟踪伤口尺寸。语义分割是这一过程的关键步骤，但伤口分割在医学影像研究领域仍相对不足。为解决这一问题，本文将通用视觉、医学影像以及公开伤口挑战赛中的顶级方法进行基准测试，通过标准化训练、数据增强和评估方法，并利用交叉验证来最小化分区偏差。此外，还评估了实际部署中的各个方面，包括泛化性能、计算效率和可解释性。进而提出了一种基于参考对象的方法，将AI生成的掩码转换成临床相关的伤口大小估计，并对五个最佳架构进行评估。总体而言，基于变压器的TransNeXt模型具有最高的泛化性能。尽管推理时间存在差异，所有模型在CPU上至少每秒处理一张图片，这被认为是适当的。可解释性分析通常显示重点区域的显著激活，突出了关于临床相关特征的关注。专家评估表明所有分析模型的掩码批注率都很高，其中VWFormer和ConvNeXtS主干表现最佳。尺寸获取准确性在模型之间相似，并且预测几乎与专家注释相匹配。最终，本文证明了我们基于AI的伤口大小估计框架WoundAmbit如何集成到定制的远程医疗服务系统中。
## Innovation
本文首次将通用视觉、医学影像和公开伤口挑战赛中的顶级方法进行基准测试，通过标准化方法和交叉验证来评估模型的性能。不仅在泛化能力和计算效率方面进行了广泛的评估，还提出了一种基于参考对象的方法将AI生成的掩码转换成临床相关的伤口大小估计，并对五个最佳架构进行了评估。
## Conclusion
基于Transformer的TransNeXt在泛化性能方面表现最佳。尽管模型之间的推理时间有所差异，但所有模型都能在CPU上每秒至少处理一张图片，满足实际应用需求。VWFormer和ConvNeXtS主干在可解释性和专家评价方面表现最佳。尺寸获取准确性在所有模型之间相似，并且预测结果与专家标注一致。通过将WoundAmbit框架集成到远程医疗服务系统中，实现了自动化伤口监测的应用。
# 383. `cs.CV` - TT3D: Table Tennis 3D Reconstruction [PDF](https://arxiv.org/pdf/2504.10035), [HTML](https://arxiv.org/abs/2504.10035)
## Authors
Thomas Gossard,Andreas Ziegler,Andreas Zell
## Background
体育分析需要处理大量的数据，这既耗时又成本高昂。神经网络的进步显著减轻了这一负担，能够实现高度准确的球迹追踪。然而，仅依赖2D球迹追踪是有限的，因为它依赖于摄像头的角度，无法支持全面的比赛分析。为了解决这一限制，我们提出了一种创新的方法，用于从在线乒乓球比赛录像中重建精确的3D球迹。这种方法利用球的运动学原理来识别球的弹跳状态，以最小化球飞行轨迹的重新投影误差，从而确保3D重建的准确性和可靠性。我们的方法的一个主要优点是，它能够在不依赖人类姿态估计或球拍追踪的情况下推断球的旋转，而在转播素材中这些往往是不可靠或不可用的。我们开发了一种自动摄像机校准方法，能够可靠地跟踪摄像机的运动，同时，我们改进了现有的缺乏深度动作捕捉的3D姿态估计模型，以准确跟踪球员的运动。这些贡献共同实现了乒乓球比赛的全3D重建。
## Innovation
我们的方法利用球的运动学原理来识别球的弹跳状态，以最小化球飞行轨迹的重新投影误差，从而确保3D重建的准确性和可靠性。这种方法能够在不依赖人类姿态估计或球拍追踪的情况下推断球的旋转，并且我们开发了一种自动摄像机校准方法和改进了现有的3D姿态估计模型，以准确跟踪球员的运动。这些技术共同实现了乒乓球比赛的全3D重建，克服了现有的2D球迹追踪方法的局限性。
## Conclusion
我们提出了TT3D方法，这是一种新颖的3D重建方法，能够从在线乒乓球比赛录像中精确重建3D球迹。通过结合自动摄像机校准技术和改进的3D姿态估计模型，我们的方法能够推断球的旋转，同时准确跟踪球员的运动，从而实现乒乓球比赛的全3D重建，填补了现有的2D球迹追踪方法的空白。
# 384. `cs.CV` - ZigzagPointMamba: 空间-语义马卡巴模型在点云理解中的应用 [PDF](https://arxiv.org/pdf/2505.21381), [HTML](https://arxiv.org/abs/2505.21381)
## Authors
Linshuang Diao,Dayong Ren,Sensen Song,Yurong Qian
## Background
State Space models (SSMs)如PointMamba能够通过线性复杂度进行点云自监督学习的高效特征提取，并在计算效率上超越了Transformer。然而，现有的基于PointMamba的方法依赖复杂的标记顺序和随机遮掩，这破坏了空间连续性和局部语义相关性。因此需要解决这些问题以提升在点云理解任务的性能。
## Innovation
本研究提出了ZigzagPointMamba，通过一种简单的Z字形扫描路径全局地对点云标记进行排序，以增强空间连续性并保持空间相邻点标记的接近性。此外，还引入了语义双胞胎遮掩策略（SMS），用于屏蔽语义上相似的标记，促进局部特征的融合，从而克服了对孤立局部特征的依赖，增强了全局语义建模的鲁棒性。
## Conclusion
预训练的ZigzagPointMamba模型显著提升了下游任务的性能，在ShapeNetPart中的部分分割任务中获得了1.59%的mIoU提升，在ModelNet40的分类任务中准确性提高了0.4%，ScanObjectNN数据集的OBJ-BG、OBJ-ONLY和PB-T50-RS子集中的分类任务准确性分别提高了0.19%、1.22%和0.72%。
# 385. `cs.CV` - 它不是你，而是我——不同人口统计数据和个性特征上对城市视觉感知存在差异 [PDF](https://arxiv.org/pdf/2505.12758), [HTML](https://arxiv.org/abs/2505.12758)
## Authors
Matias Quintana,Youlong Gu,Xiucheng Liang,Yujun Hou,Koichi Ito,Yihan Zhu,Mahmoud Abdelrahman,Filip Biljecki
## Background
当前的Urban规划决策通常将多文化和多城市人群的偏好和需求综合在一起，这模糊了重要的人口统计数据差异，有可能放大偏见。这项研究通过一个横跨五个国家和45个民族、包含1000名参与者的大规模街头景观视觉感知调查，使用Street View影像进行，旨在理解人口统计数据（包括性别、年龄、收入、教育、种族和族裔，以及首次纳入的人格特质）如何影响这些参与者的感知差异。调查结果提出了六项传统指标（安全、热闹、富有、美丽、乏味和沮丧）和四项新指标（生活、步行、骑行和绿色）在人口统计数据和人格特征上的感知差异，表现在对其他城市的街头景观的偏好中。并发现预训练的机器学习模型倾向于高估积极指标并低估负面指标，表明需要考虑本地居民的感知来进行有针对性的干预措施
## Innovation
该研究引入了一个名为SPECS的数据库，不仅涵盖了以前的研究使用的六项传统指标，还增加了四项新指标，首次纳入了人格特质的考量。此研究的创新之处在于使用大规模调查以人口统计数据和人格特质失衡的形式来分析城市视觉感知的差异，并且提出了这些指标对不同文化背景下人们的偏好和感知影响的新见解，为未来的Urban规划决策提供了一种更全面的方法
## Conclusion
本研究旨在纠正城市视觉感知的短视问题，很少考虑人口统计数据或人格特征。机器学习模型相较于人类感知对正负指标的估计结果可能导致偏误，因此需要针对当地居民的实际感知来实施干预，为未来城市规划提供更具针对性和包容性的方法
# 386. `cs.CV` - 视频强化调优：通过强化调优激励LLM的视频推理能力 [PDF](https://arxiv.org/pdf/2505.12434), [HTML](https://arxiv.org/abs/2505.12434)
## Authors
Qi Wang,Yanrui Yu,Ye Yuan,Rui Mao,Tianfei Zhou
## Background
强化调优（RFT）在提高大型语言模型（LLMs）的人类级推理能力方面取得了显著进展，并已扩展到多粒度语言模型（MLLMs）。然而，处理视频中的视频推理，即人类智能中的基本方面，由于视频数据内在的复杂逻辑、时间和因果结构，仍然是一个持续的挑战。
## Innovation
提出了VIDEORFT，一种通过强化调优方法扩展视频推理能力的新方法。VIDEORFT通过自动构建的CoT生成和修订策略解决了大规模高质量视频CoT数据集稀缺的问题，引入了语义一致性奖励以提高模型输出的连贯性和上下文意识。实验表明，VIDEORFT在六个视频推理基准上取得了最先进的性能。
## Conclusion
VIDEORFT通过自动化的CoT生成和修订管道，以及新的语义一致性奖励，在提升MLLM的视频推理能力方面取得了显著成效，有望在未来研究中进一步提升这一领域的技术能力。
# 387. `cs.CV` - TIIF-Bench: 如何解析您的T2I模型是否遵循您的指令？ [PDF](https://arxiv.org/pdf/2506.02161), [HTML](https://arxiv.org/abs/2506.02161)
## Authors
Xinyu Wei,Jinrui Zhang,Zeqing Wang,Hongyang Wei,Zhen Guo,Lei Zhang
## Background
随着文本到图像（T2I）模型的迅速发展，AI生成内容进入了新的阶段，这些模型的解读与遵循用户指令的能力日益增强。然而，现有的T2I模型评估基准在提示的多样性和复杂性、以及粗略的评估指标方面存在局限性，因此难以精确评估文本指令与生成图像之间的细微对齐性能。本文的研究背景正是基于此，旨在解决当前T2I模型评估基准存在的不足，并设计了一个新的评估基准——TIIF-Bench（文本到图像指令跟随基准），以系统性地评估T2I模型解读和遵循复杂文本指令的能力。
## Innovation
本文的主要创新在于提出了一种名为TIIF-Bench的新基准，该基准包括5000个按多个维度组织的提示，提示分为三个难度和复杂度级别。每个提示都有短和长两个版本，相同的核心语义，用于严格评估模型在不同提示长度下的鲁棒性。此外，引入了文字渲染和风格控制两个关键属性，以评估文字合成的精确度和T2I模型的美学一致性。TIIF-Bench还收集了100个高质量的设计师级别提示，涵盖了各种场景，以全面评估模型性能。通过利用大型视觉语言模型中嵌入的领域知识，提出了一个新的可计算框架来辨别T2I模型输出的细微差异。
## Conclusion
通过在TIIF-Bench上对主流T2I模型进行细致的基准测试，分析了当前T2I模型的优点和缺点，揭示了当前T2I基准的局限性。
# 388. `cs.CV` - ViStoryBench：故事可视化综合基准套件 [PDF](https://arxiv.org/pdf/2505.24862), [HTML](https://arxiv.org/abs/2505.24862)
## Authors
Cailin Zhuang,Ailin Huang,Wei Cheng,Jingwei Wu,Yaoqi Hu,Jiaqi Liao,Zhewei Huang,Hongyuan Wang,Xinyao Liao,Weiwei Cai,Hengyuan Xu,Xuanyang Zhang,Xianfang Zeng,Gang Yu,Chi Zhang
## Background
随着时间生成模型的进步，故事可视化已经取得了显著进展。故事可视化旨在生成与给定叙述和参考图像一致的序列可视化图像。为了进一步提高实际场景中故事可视化框架的表现，本文介绍了一个全面的评价基准，ViStoryBench。该基准集包含不同类型的故事情节和艺术风格，使模型可以在多个维度上被评估，如不同的剧情（如喜剧、恐怖）和视觉美感（如动漫、3D渲染）。ViStoryBench 精心策划，平衡了叙事结构和视觉元素，包含单一和多个主人公的故事，以测试模型保持人物一致性的能力。此外，还包括复杂的剧情和细致的世界构建，以挑战模型生成准确的视觉表现。为了确保全面比较，基准采用了广泛的评估指标，从多个方面进行评估。
## Innovation
提出了一个名为ViStoryBench的综合评价基准，用于故事可视化。该基准集合了各种故事情节和艺术风格的数据集，涵盖了不同类型的故事情节（包括单个和多个主人公的故事）、多样化的视觉效果，并确保模型在多个维度上得到全面评估。基准还考虑了复杂剧情和细致的世界构建，以挑战模型生成精准视觉的能力。此外，采用了广泛的评估指标，确保了基准的全面性和结构性，有助于研究人员全面识别不同模型的优势和劣势，从而推动有针对性的改进。
## Conclusion
本文通过提出全面的故事可视化评价基准，ViStoryBench，帮助研究者识别不同模型的优势与劣势，促进了故事可视化算法的发展。此框架不仅能够评估模型的视觉表现能力，还能有效验证模型对复杂故事情节和多视角风格的适应能力，从而进一步改善实际应用中的表现。
# 389. `cs.CV` - 单张图像辅助去焦深度推断中的暗通道 [PDF](https://arxiv.org/pdf/2506.06643), [HTML](https://arxiv.org/abs/2506.06643)
## Authors
Moushumi Medhi,Rajiv Ranjan Sahay
## Background
深度从去焦（Depth-from-Defocus，DFD）是从单个模糊图像中估计场景深度的传统方法，通常需要使用多个具有不同光圈或焦距的图像。由于单图DFD方法研究较少，且问题本质上是欠定的，因此这种方法在单张图像的应用中被忽视。此研究利用暗通道作为补充线索，通过捕捉局部统计和场景结构，从单张去焦图像中估计场景深度，解决了这一挑战。
## Innovation
该方法通过利用局部去焦模糊与对比度变化之间的关系作为深度线索，提出了一种新的单图DFD方法。该管道通过对抗学习进行了端到端的训练，这有助于提高场景结构估计的准确性。研究证明，将暗通道先验引入单图DFD可以提供有意义的深度估计，验证了该方法的有效性。
## Conclusion
实验结果表明，将暗通道先验引入单图DFD可以提供有意义的深度估计，证明了该方法的有效性，即使是在实际数据上也能取得良好的效果。
# 390. `cs.CV` - 为视频扩散模型细粒度调优的跨帧表示对齐 [PDF](https://arxiv.org/pdf/2506.09229), [HTML](https://arxiv.org/abs/2506.09229)
## Authors
Sungwon Hwang,Hyojin Jang,Kinam Kim,Minho Park,Jaegul Choo
## Background
用户级别的微调视频扩散模型（VDMs）以生成反映训练数据特定属性的视频具有一定挑战性，但这一领域尚未充分探索，尽管其有实际意义。近年来，例如Representation Alignment (REPA)的研究表明，通过将内部隐藏状态与外部预训练视觉特征对齐，可以改善基于DiT的图像扩散模型的收敛性和质量，这提示了其在VDM微调中的潜在应用。
## Innovation
本文首先提出了一种REPA在VDM上的直接适应，并实证展示了尽管其在收敛性上有效，但在保持帧间语义一致性方面表现不佳。为解决这一限制，引入了跨帧表示对齐（CREPA），这是一种将当前帧的隐藏状态与邻近帧的外部特征对齐的新正则化技术。实验结果表明，使用参数高效方法如LoRA微调时，CREPA可以提高视觉保真度和帧间语义连贯性。
## Conclusion
CREPA在不同具有不同属性的数据集中得到了验证，证实了其广泛的适用性。
# 391. `cs.CV` - BeltCrack: 首个顺序图像工业传送带裂纹检测数据集及其基于三域特征学习的基线方法 [PDF](https://arxiv.org/pdf/2506.17892), [HTML](https://arxiv.org/abs/2506.17892)
## Authors
Jianghong Huang,Luping Ji,Xin Ma,Mao Ye
## Background
传送带作为现代工业中关键设备，广泛应用于生产和制造。传送带的健康状况对于生产效率和安全性至关重要。裂缝是传送带健康的主要威胁之一。当前，为了确保安全，如何通过智能手段检测传送带裂缝越来越受到重视。利用机器学习实施智能检测时，需要具备实际裂缝样本。然而，现有的裂缝数据集主要集中在道路场景或合成数据上，根本没有工业传送带的实际情况裂缝数据集。我们通过提出基于时间-空间-频率域三域特征层次融合学习的特殊基线方法，验证了这两个全新数据集的可用性和有效性。实验结果证明了该数据集的有效性，并表明我们的基线方法明显优于其他类似检测方法。我们已将数据集和源代码发布在指定网址上。
## Innovation
首次提出BeltCrack数据集，专注于工业传送带的实际裂缝数据。利用基于时间-空间-频率域三域特征层次融合学习方法作为基线算法，填补了该领域的空白。
## Conclusion
实验结果证明了BeltCrack数据集的有效性，并展示了三域特征学习基线方法的优越性。数据集和源代码已经公开发布。
# 392. `cs.CV` - C3S3: 补偿竞争与对比选择在半监督医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2506.07368), [HTML](https://arxiv.org/abs/2506.07368)
## Authors
Jiaying He,Yitong Lin,Jiahe Chen,Honghui Xu,Jianwei Zheng
## Background
医学领域中样本注解不足的内在挑战使得半监督医学图像分割（SSMIS）方法成为一种有希望的解决方案。尽管当前方法在界定主要目标区域方面取得了显著成果，但在捕捉边界细节方面仍然存在不足，这常常导致诊断准确性降低。为了解决这个问题，我们提出了一种名为C3S3的新颖半监督分割模型，该模型将互补竞争和对比选择相结合，显著改进了边界界定和整体精度。C3S3通过一个专门用于细化边界定位的成果驱动对比学习模块和一个利用两个高效次网络生成伪标签的动态互补竞争模块进行改进分割质量。该方法在两个公开数据集（包括MRI和CT扫描的实践）上进行了严格的验证，结果显示我们的方法在多种指标上优于之前的尖端竞争对手，特别是在95HD和ASD指标上提升了至少6%，展示了显著的进步。代码可在以下网址获取：this https URL
## Innovation
C3S3模型通过集成互补竞争和对比选择两大机制，专门开发了成果驱动的对比学习模块和动态互补竞争模块，有效提高了边界界定精度和分割的整体准确性。此外，该方法在两个公开数据集上进行了严格的验证，展示了其优越性能和显著改进
## Conclusion
我们的C3S3方法在多个公开数据集上的验证结果显示，该方法在多种评估指标上显著优于现有的先进方法，特别是在95HD和ASD指标上提升了至少6%，展示了在半监督医学图像分割中的重大进步。项目代码已开放提供。
# 393. `cs.CV` - VLN-R1: 通过强化微调实现视觉语言导航 [PDF](https://arxiv.org/pdf/2506.17221), [HTML](https://arxiv.org/abs/2506.17221)
## Authors
Zhangyang Qi,Zhixiong Zhang,Yizhou Yu,Jiaqi Wang,Hengshuang Zhao
## Background
视觉语言导航(VLN)是实体AI中的核心挑战，需要代理使用自然语言指令在现实世界的环境中导航。当前基于语言模型的导航系统在离散拓扑图上运行，限制了路径规划到预定义节点连接。使用这种系统，难以实现连续的导航行动，难以捕捉复杂的场景和动态变化。
## Innovation
论文提出了VLN-R1，这是一种端到端框架，利用大型视觉语言模型(LVLM)直接将第一人称视频流转换为连续的导航行动。通过使用受DeepSeek-R1启发的基于GRPO的训练方法。研究中还提出了一种长期短期记忆采样方法以平衡历史和当前观察。论文采用了一种两阶段的训练方法：首先进行监督微调(SFT)以使模型的动作序列文本预测与专家演示对齐，然后通过一种基于时间衰减奖励的强化微调(RFT)机制增强，以战略性地权衡多步未来的行动。此框架强调了对于大型语言模型的监督控制，提升任务特定的推理和决策能力。
## Conclusion
实验证明，VLN-R1在VLN-CE基准上具有较强的表现力。研究证明了LVLM在实体导航中的应用潜力，并展示了数据驱动和奖励驱动的后训练机制在特定任务中对增强模型效能的关键作用。
# 394. `cs.CV` - VLLMs中的视觉和文本提示增强情感识别 [PDF](https://arxiv.org/pdf/2504.17224), [HTML](https://arxiv.org/abs/2504.17224)
## Authors
Zhifeng Wang,Qixuan Zhang,Peter Zhang,Wenjia Niu,Kaihao Zhang,Ramesh Sankaranarayana,Sabrina Caldwell,Tom Gedeon
## Background
视觉大型语言模型(VLLMs)在多模态理解方面展现出巨大的潜力，但在基于视频的情感识别应用中受到限制，主要是由于它们在空间和上下文感知方面的不足。传统的方法往往侧重于孤立的面部特征，忽视了重要的非言语线索，如肢体语言、环境背景和社交互动，这在实际场景中降低了模型的鲁棒性。
## Innovation
提出了一种名为Set-of-Vision-Text Prompting (SoVTP)的新型框架，通过将空间注释（例如边界框，面部标志），生理信号（面部动作单元）和上下文线索（体态，场景动态，他人的情绪）集成到统一的提示策略中，增强了零样本情感识别的性能。SoVTP同时保持整体场景信息和允许对面部肌肉运动和人际动态进行细致分析。实验表明，SoVTP显著优于现有视觉提示方法，证明了其对提高VLLMs在视频情感识别方面的有效性的有效性。
## Conclusion
SoVTP框架在显著提高VLLMs的视频情感识别能力方面取得了实质性进展，证明了其在情感识别方面的有效性。
# 395. `cs.CV` - PP-DocBee2：改进基础模型并高效利用数据以提升多模态文档理解 [PDF](https://arxiv.org/pdf/2506.18023), [HTML](https://arxiv.org/abs/2506.18023)
## Authors
Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu
## Background
本文介绍了PP-DocBee2，这是PP-DocBee的增强版本，旨在提高多模态文档的理解能力。该模型基于大规模的多模态模型架构，通过关键的技术改进，包括增强合成数据质量、改进视觉特征融合策略和优化推理方法，弥补了其前身的不足。这些改进使PP-DocBee2在内部基准测试中对于中文商业文档的性能提高了11.4%，并将推理延迟降低了73.0%至基线版本。
## Innovation
这项工作的关键创新是一个针对多模态文档任务的数据质量优化策略。通过使用大规模的多模态预训练模型评估数据，并应用新的统计标准来过滤异常值，保证高质量的训练数据。此外，通过对ViT进行分层并增设一种新颖的特征融合策略，增强其表示能力，以提高复杂推理能力。
## Conclusion
PP-DocBee2通过这些技术和数据处理优化，显著提升了多模态文档的理解性能，并且公开了源代码和预训练模型供进一步研究。
# 396. `cs.CV` - Self-Supervised Multimodal NeRF for Autonomous Driving [PDF](https://arxiv.org/pdf/2506.19615), [HTML](https://arxiv.org/abs/2506.19615)
## Authors
Gaurav Sharma,Ravi Kothari,Josef Schmid
## Background
该论文背景是探讨如何利用神经辐射场(NeRF)及其衍生技术来提高自动驾驶场景中对静动态场景的适应性和实时性。研究人员希望将LiDAR和摄像机数据结合起来，在不依赖于3D标签的情况下，提出一种高效且性能优越的多模态NeRF框架，用于动态场景的视图合成和理解。他们将方法应用于真实的自动驾驶环境，旨在改进和加速基于NeRF的自监督模型在实际应用中的效果，尤其是在处理多样且复杂的静态和动态场景时的表现更好。
## Innovation
创新在于该框架实现了对时间和空间变化场景的自监督学习，不需要预先标注3D数据，通过引入基于启发式算法的像素采样方法和双梯度掩码来读取LiDAR点的局部特征，从而提高训练效率和模型性能。这意味着该方法能够更好地适应自动驾驶中可能出现的多种多样的动态场景，同时提高实时处理能力。
## Conclusion
经过KITTI-360数据集的广泛实验表明，该框架在LiDAR和摄像机领域均优于基线模型，显示出更好的表现。团队将在GitHub上发布该模型的代码以供进一步研究。
# 397. `cs.CV` - 采样问题对可信赖的视觉模型解释构建块的影响：通过最大化解释的确定性实现可信的归因分析 [PDF](https://arxiv.org/pdf/2506.19442), [HTML](https://arxiv.org/abs/2506.19442)
## Authors
Róisín Luo,James McDermott,Colm O'Riordan
## Background
归因分析旨在突出视觉模型学习的特征表示，以便高亮的特征图能够反映输入的像素重要性。梯度整合是归因分析中的一个基本组成部分，通过整合多个衍生样本的梯度来突出与推理相关的语义特征。通常，这种构成会与其他视觉模型的信息，例如激活图或注意力图，结合起来形成最终解释。然而，理论分析表明，样本分布与自然图像分布的对齐程度决定了解释的下限。先前的工作通过向图像中添加噪声作为样本，但噪声分布可能导致解释的不确定性。出乎意料的是，实验显示额外信息可能饱和神经网络。因此，建立可信赖的归因分析需要解决样本分布不对齐的问题。
## Innovation
提出了一种半优化的采样方法，通过抑制输入特征来避免向输入图像中添加额外信息。通过这种方法生成的样本分布与自然图像分布大致相同。通过在大规模数据集ImageNet上的广泛定量评估，证明了该方法的有效性和与最先进的基线相比能够提供更满意的解释的能力。
## Conclusion
解决样本分布的不对齐问题对于建立可信赖的归因分析至关重要。研究提出了一种通过抑制特征来更正输入样本分布的半优化方法，证明该方法能够最大化解释的确信度，从而实现更可信赖的归因分析。
# 398. `cs.CV` - Mamba Policy: 含有混合选择状态模型的高效3D扩散策略 [PDF](https://arxiv.org/pdf/2409.07163), [HTML](https://arxiv.org/abs/2409.07163)
## Authors
Jiahang Cao,Qiang Zhang,Jingkai Sun,Jiaxu Wang,Hao Cheng,Yulin Li,Jun Ma,Kun Wu,Zhiyuan Xu,Yecheng Shao,Wen Zhao,Gang Han,Yijie Guo,Renjing Xu
## Background
3D操控领域广泛应用了扩散模型，因其能够高效学习分布，从而精确预测动作轨迹。然而，扩散模型通常依赖于参数量庞大的UNet骨干网络作为策略网络，这在资源受限的设备上部署具有挑战性。最近，Mamba模型作为一种有效的解决方案出现，提供了较低的计算复杂度和强大的序列建模性能。
## Innovation
本文提出了Mamba Policy，相比原始策略网络参数减少了超过80%，同时实现了更优的性能。具体而言，引入了XMamba Block，将输入信息与条件特征有效结合，并利用Mamba机制和注意机制进行深层特征提取。大量实验表明，Mamba Policy在Adroit、Dexart和MetaWorld数据集上表现出色，所需的计算资源显著减少。此外，还探讨了Mamba策略在长时间跨度场景下的增强鲁棒性及其在Mamba策略框架内的多种Mamba变体的性能。
## Conclusion
通过广泛的实验证明，Mamba Policy在所需计算资源方面表现出色，并在长时间跨度场景上具有更强的鲁棒性。该策略的开放源代码项目可以访问 httpsURL。
# 399. `cs.CV` - CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation [PDF](https://arxiv.org/pdf/2506.15549), [HTML](https://arxiv.org/abs/2506.15549)
## Authors
Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen Chen
## Background
基于深度学习的左心室晚钆增强（LGE）心脏MRI心肌疤痕分割，在心脏结构性疾病的准确和及时诊断及治疗规划中显示出巨大潜力。但由于高质量疤痕标签的LGE图像数量有限且质量差异大，限制了稳健分割模型的发展。因此，本文分析了现有LGE图像数据的限制及其对心脏疾病诊断和治疗的影响。
## Innovation
提出了CLAIM框架，这是一种基于解剖原则的心肌疤痕生成与分割框架。该框架中核心是SMILE模块（临床知识引导的疤痕掩码生成），它是基于临床推荐的AHA 17段模型条件化扩散生成器，以综合具有解剖一致性且空间上有差异的疤痕模式的图像。此外，CLAIM使用联合训练策略，同时优化疤痕分割网络和生成器，旨在提高合成疤痕的现实性和疤痕分割的准确性。实验结果显示， CLAIM相较于基线模型生成了具有解剖一致性疤痕模式，并且在与真实疤痕分布的Dice相似度方面表现更好。
## Conclusion
CLAIM方法实现了可控且真实的左心室疤痕合成，并在下游医疗成像任务中有实用性。
# 400. `cs.CV` - 通过注意力头选择实现细粒度扰动指导 [PDF](https://arxiv.org/pdf/2506.10978), [HTML](https://arxiv.org/abs/2506.10978)
## Authors
Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim
## Background
近年来，扩散模型的指导方法通过扰动模型来反向采样，构建隐式的弱模型并引导生成偏离该模型。在这样的方法中，注意力扰动方法已经显示出在需要无分类指导的条件下有很强的经验性能。然而，现有的注意力扰动方法缺乏确定扰动应在哪里应用的合适方法，尤其是在扩散变换器（DiT）架构中，质量相关计算分布在各层之中。本文研究了注意力扰动的粒度范围，从层级别到单个注意力头，发现特定的头控制着不同的视觉概念，如结构、风格和纹理质量。基于这一洞察，本文提出了“HeadHunter”，这是一种系统性框架，用于逐步选择与用户目标一致的注意力头，从而实现生成质量和视觉属性的精细化控制。此外，引入了SoftPAG，这是一种线性插值方法，应用于每个所选头的注意力图，并向单位矩阵进行连续调整，以调节扰动强度并抑制伪影。这种新方法不仅缓解了现有层级别扰动中的过度平滑问题，还通过组合性头选择实现了特定视觉风格的有针对性的操作。我们验证了这种方法在现代大规模DiT文本到图像模型中的有效性，包括Stable Diffusion 3和FLUX1，体现了在综合质量和风格指导方面优越的表现。
## Innovation
提出了HeadHunter框架，这是一种系统性方法，用于逐步选择与用户目标一致的注意力头。引入了SoftPAG方法，这是一种线性插值方法，用于连续调整每个选定头的注意力图，从而精细调节扰动强度并抑制伪影。这种方法不仅解决了以往层级别扰动中的过度平滑问题，还实现了特定视觉风格的有针对性操作。
## Conclusion
本文对扩散模型中的注意力扰动进行了头级别分析，揭示了注意力层内的可解释专业化，并为有效扰动策略的实际设计提供了实践基础。这种方法在多个现代大规模DiT文本到图像模型中验证，展现了在综合质量和风格指导方面的优越性能。
# 401. `cs.CV` - 单一原型足够：单原型激活用于可解释的图像分类 [PDF](https://arxiv.org/pdf/2506.19808), [HTML](https://arxiv.org/abs/2506.19808)
## Authors
Yitao Peng,Lianghua He,Die Hu
## Background
现有的原型网络通常依赖多个原型的协作决策来实现单类别分类和解释。这些网络通常需要激活多个原型以完成分类任务，并且解释也复杂且难以理解。为了解决这一问题，本文提出了ProtoSolo，一种受ProtoPNet启发的新颖的深度神经网络架构，旨在仅通过激活单个原型来完成分类，从而显著降低解释的认知复杂度。此外，本文还提出了基于特征的比较方法，通过使用特征图而不是全通道特征向量来进行相似性比较和原型学习，这使得网络可以利用更多的全局信息进行分类，同时依赖单个原型激活。
## Innovation
1. 提出了一种新的单原型激活架构ProtoSolo，只需要激活单个原型即可完成分类任务，简化了解释过程并降低了认知复杂度。2. 采用基于特征的比较方法，使用特征图进行相似性比较和原型学习，利用更多的全局信息进行分类，且只依赖于单个原型激活。3. 提出了非原型投影学习策略，保留了原型与训练图像块之间的信息关联，避免了投影操作导致的网络结构急剧变化，进而避免了对分类性能的负面影响。
## Conclusion
在CUB-200-2011和斯坦福汽车数据集上进行的实验表明，ProtoSolo在分类任务中表现出优越的性能，且在解释的认知复杂度上达到了最先进的可解释方法的最佳水平。代码已公开可用。
# 402. `cs.CV` - 全面筛查：利用苏木精和伊红全切片图像进行泛癌种遗传和表型标志物高通量筛查 [PDF](https://arxiv.org/pdf/2408.09554), [HTML](https://arxiv.org/abs/2408.09554)
## Authors
Yi Kan Wang,Ludmila Tylditatova,Jeremy D. Kunz,Gerard Oakley,Bonnie Kar Bo Chow,Ran A. Godrich,Matthew C. H. Lee,Hamed Aghdam,Alican Bozkurt,Michal Zelechowski,Chad Vanderbilt,Christopher Kanan,Juan A. Retamero,Peter Hamilton,Razik Yousfi,Thomas J. Fuchs,David S. Klimstra,Siqi Liu
## Background
分子检测是癌症预后和治疗选择的标准方法，但成本高、耗时且破坏性。人工智能应用于常规苏木精和伊红染色全切片图像提供了快速、经济的替代方案，用于筛查分子生物标志物。现有方法训练单独的模型针对每种生物标志物，而 OmniScreen 系统则利用统一模型预测广泛的临床相关生物标志物，涵盖了不同类型的癌症，包括那些个体建模困难的低流行率目标。OmniScreen 可靠地识别常见和罕见肿瘤的治疗目标和共享表型特征，依据肿瘤面积、样本大小、组织学亚型匹配和通路层级形态学模式对生物标志物预测概率和准确性进行了研究，强调了 OmniScreen 在常规临床筛查中的潜力。
## Innovation
OmniScreen 引入了一种高通量的人工智能基系统，该系统利用从 60,529 名癌症患者中提取的 Virchow2 渗入来预测广泛的临床相关生物标志物，这种系统采用统一模型而非为每个生物标志物单独训练模型的方法，特别适用于罕见肿瘤的低流行率目标。
## Conclusion
OmniScreen 系统的广泛临床价值在于它能可靠地识别常见和罕见肿瘤的治疗目标和共享表型特征，同时也指出了系统性能与肿瘤面积、样本大小、组织学亚型匹配和通路层级形态学模式的相关性，展示了其在临床筛查中的巨大潜力。
# 403. `cs.CV` - OmniGen2：探索高级多模态生成 [PDF](https://arxiv.org/pdf/2506.18871), [HTML](https://arxiv.org/abs/2506.18871)
## Authors
Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu
## Background
本文介绍了一种名为OmniGen2的灵活且开源的生成模型，旨在提供统一的解决方案，适用于多种生成任务，包括文本到图像、图像编辑和上下文生成。该模型具备两个独立的解码路径，分别对应文本和图像模态，并通过分离参数和解耦图像分词符来进一步优化，从而能够保留原有的文本生成能力。同时，还针对图像生成任务引入了反射机制，并基于OmniGen2构建了专门的数据集。尽管参数量相对较小，但在多项任务基准测试中仍取得了竞争力的表现。为了进一步评估上下文生成这一特殊类型的生成任务，引入了一个名为OmniContext的新基准测试，OmniGen2在开放源代码模型中达到最先进的性能，特别是在一致性方面。研究团队承诺开放模型、训练代码、数据集和数据构造管道以支持该领域的未来研究。
## Innovation
OmniGen2的主要创新点在于其采用了两个独立的解码路径来处理文本和图像模态，以保持原有的文本生成能力。此外，介绍了专为图像生成任务设计的反射机制，并开发了专门的数据集。尽管参数较少，该模型在多个任务基准测试中表现良好，并在新的上下文生成基准测试中达到最先进水平。
## Conclusion
尽管OmniGen2的参数规模较小，但在多项任务中达到了有竞争力的表现，并通过引入新的数据集和机制进一步推动了上下文生成研究。研究团队将公开分享代码和数据，旨在促进该领域的未来研究。
# 404. `cs.CV` - EvDetMAV：来自移动事件相机的通用微型无人机检测 [PDF](https://arxiv.org/pdf/2506.19416), [HTML](https://arxiv.org/abs/2506.19416)
## Authors
Yin Zhang,Zian Ning,Xiaoyu Zhang,Shiliang Guo,Peidong Liu,Shiyu Zhao
## Background
现有的微型无人机（MAV）检测方法主要依赖于RGB图像中的目标外观特征，但由于这些特征多样，难以实现通用的MAV检测。与之相比，事件相机可以捕捉到微型无人机快速旋转的螺旋桨的独特特征，这些特征在RGB图像中难以察觉。本文研究了如何通过完全利用事件流中的螺旋桨特征来检测不同类型的MAV，同时过滤掉背景物体和相机运动产生的噪声。由于目前没有基于事件的MAV数据集，因此本研究引入了一个新的MAV数据集，包含了多种场景和不同类型的MAV，是首个基于事件的MAV数据集。
## Innovation
本文提出了一种新的方法——EvDetMAV，通过利用事件流中的螺旋桨特征来检测不同类型的MAV，同时解决了背景噪声和相机运动的干扰。此外，该研究还构建了首个基于事件的MAV数据集，该数据集包含多种场景和不同类型的MAV，为相关研究提供了重要资源。该方法在无需训练的情况下显著优于现有最先进的方法，在所提测试数据集上的精度率为83.0%（+30.3%），召回率为81.5%（+36.4%）。
## Conclusion
通过引入一个新的数据集和基于事件的VM检测方法，本研究克服了传统RGB图像检测方法的缺点，成功实现了对不同类型的MAV的有效识别，特别是在具有挑战性的场景中也表现出了优异的效果。
# 405. `cs.CV` - 边界框水印：对目标检测器模型提取攻击的防御 [PDF](https://arxiv.org/pdf/2411.13047), [HTML](https://arxiv.org/abs/2411.13047)
## Authors
Satoru Koda,Ikuya Morikawa
## Background
深度神经网络（DNNs）部署在云中，允许用户通过API查询模型。然而，这些API会暴露模型于模型提取攻击（MEAs）的风险中。Backdoor-based DNN水印技术被认为是抵御MEAs的有效防御手段之一，但现有的OD模型的后门攻击不适用于作为抵御MEAs的防御措施。研究通过悄悄修改查询中检测到的对象的边界框（BBs），将后门插入到提取的模型中，保持OD的功能，从而首次成功地在广泛实验场景下辨别提取的模型，精度达到100%。
## Innovation
本文提出了一种新颖的方法，通过悄悄修改API查询中检测到的对象的边界框（BBs），将后门插入到提取的OD模型中，保持模型的检测能力。这种方法首次成功地在广泛的实验场景中识别出提取的OD模型，其精确度达到100%。
## Conclusion
在三项OD数据集上进行的实验表明，所提出的方法可以在多种实验场景中对提取的模型进行精确识别，准确性为100%。这为防止模型提取攻击提供了一种新的、有效的防御方法。
# 406. `cs.CV` - WAFFLE：多模态模型的微调以实现自动化前端开发 [PDF](https://arxiv.org/pdf/2410.18362), [HTML](https://arxiv.org/abs/2410.18362)
## Authors
Shanchao Liang,Nan Jiang,Shangshu Qian,Lin Tan
## Background
前端开发涉及到将UI设计转化为功能性的网页，对于新手和经验丰富的开发者来说都很具有挑战性，主要是因为HTML的层次结构和样式较为复杂。现有的大规模语言模型在生成源代码方面已显示出一定潜力，但在UI到HTML代码生成方面仍存在两大挑战：（1）有效表示HTML的层次结构给LSTM；（2）弥合UI设计的视觉性质与HTML代码的文本格式之间的差距。
## Innovation
本文介绍了一种新的微调策略Waffle，该策略利用结构感知的注意力机制提高LSTM对HTML结构的理解，并采用对比度增强的微调方法使LSTM更好地理解UI图像和HTML代码之间的关系。使用Waffle微调后的模型在我们建立的新基准WebSight-Test和现成的Design2Code基准上，分别在HTML匹配度上提高了9.00个百分点，在CW-SSIM上提高了0.0982，在CLIP上提高了32.99，在LLEM上提高了27.12个百分点，均优于现有微调方法。
## Conclusion
Waffle策略显著提高了自动化前端开发中的模型性能，有效解决了UI到HTML代码生成的挑战，有望在未来的前端开发中发挥重要作用。
# 407. `cs.CV` - LVPNet：基于潜变量预测驱动的一体化框架，用于医学图像无损压缩 [PDF](https://arxiv.org/pdf/2506.17983), [HTML](https://arxiv.org/abs/2506.17983)
## Authors
Chenyue Song,Chen Hui,Qing Lin,Wei Zhang,Siqiao Li,Haiqi Zhu,Zhixuan Li,Shengping Zhang,Shaohui Liu,Feng Jiang,Xiang Li
## Background
现有的医学图像无损压缩方法在处理时，通过图像分割使得潜变量信息在每个子图像中均匀分布，这种方法导致潜变量后验崩溃和潜变量利用效率低下。
## Innovation
提出了一个预测驱动的端到端无损医学图像压缩方法LVPNet，使用全局潜变量预测像素值并编码预测概率实现无损压缩。引入了全局多尺度感知模块(GMSM)来从整个图像中提取紧凑且有信息的潜表征，有效捕捉潜在空间内的空间依赖性。此外，还提出了量化补偿模块(QCM)来学习量化误差分布并优化量化特征以补偿量化损失。
## Conclusion
在具有挑战性的基准上进行的广泛实验表明，该方法在无损图像压缩效率方面优于现有最先进的无损图像压缩方法，同时保持了竞争力的推理速度。
# 408. `cs.CV` - 使用合成数据提升Few-Shot模型泛化能力的证明方法 [PDF](https://arxiv.org/pdf/2505.24190), [HTML](https://arxiv.org/abs/2505.24190)
## Authors
Lan-Cuong Nguyen,Quan Nguyen-Tri,Bang Tran Khanh,Dung D. Le,Long Tran-Thanh,Khoat Than
## Background
由于缺乏标记的训练样本，少样本图像分类仍然具有挑战性。利用合成数据增强训练样本被视为缓解这一问题的一种有前途的方法，但这些模型在合成样本上的训练常常导致性能下降，因为实际和合成数据分布之间存在差距。为此，本文提出了一个理论框架，量化这种分布差异对监督学习的影响，特别是在图像分类的背景下。该框架还建议了生成高质量合成样本和训练具有高泛化能力预测器的实际方法。
## Innovation
本文提出了一种基于理论的新型算法，该算法结合了原型学习来优化数据划分和模型训练，从而有效缩小了实际少样本数据和合成数据之间的差距。此外，该框架提出的方法在多个数据集上展示了优于现有最先进的方法的性能。
## Conclusion
本文通过理论框架揭示了实际数据和合成数据之间的分布差异对少样本模型泛化的具体影响，并提出了一种新的算法来提高合成数据在少样本学习中的泛化能力。实验结果表明，该方法显著优于现有方法。
# 409. `cs.CV` - 预测建模、模式识别与模拟和受控环境中植物生长的空间时间表示：全面综述 [PDF](https://arxiv.org/pdf/2412.10538), [HTML](https://arxiv.org/abs/2412.10538)
## Authors
Mohamed Debbagh,Shangpeng Sun,Mark Lefsrud
## Background
准确预测和表示植物生长模式对于植物种群学研究中的各种挑战至关重要。本综述探讨了最新的预测模式识别技术的研究工作，重点在于植物性状的空间时间建模和动态环境交互的集成。文章全面地考察了确定性、概率性和生成性建模方法的应用，并突出了其在高通量表型分析和基于仿真的植物生长预测中的应用。研究的关键主题包括采用回归和基于神经网络的表示模型的任务预测，现有基于实验确定性方法的局限性，以及需要动态框架来考虑不确定性以及不断变化的环境反馈。文章还总结了功能结构植物模型和条件生成模型在二维和三维结构数据表示方面的进展，并提出了未来研究的视角，强调将领域特定知识与数据驱动 方法的整合，以及对现有数据集的改进，并将这些技术应用于实际应用.
## Innovation
本综述全面审视了在预测建模、模式识别以及植物生长的空间时间表示方面的最新进展，具体探索了确定性、概率性和生成性建模方法的应用。文章也强调了功能结构植物模型和条件生成模型在二维和三维结构数据表示方面的研究，并提出了未来整合领域特定知识与数据驱动方法、改进数据集以及将这些技术应用于实际应用的前景研究.
## Conclusion
本综述总结了确定性和概率性建模方法在植物种群学领域的应用，并指出了未来研究的机会，强调了将领域特定知识与数据驱动方法的整合、提升现有数据集的质量以及这些技术的实际应用的重要性。同时，它也探讨了功能结构植物模型和条件生成模型在植物生长预测中的应用，并展望了该领域的发展前景。
# 410. `cs.CV` - TCDiff++: 一种端到端轨迹可控的扩散模型，用于和谐的音乐驱动组编舞 [PDF](https://arxiv.org/pdf/2506.18671), [HTML](https://arxiv.org/abs/2506.18671)
## Authors
Yuqin Dai,Wanlu Zhu,Ronghui Li,Xiu Li,Zhenyu Zhang,Jun Li,Jian Yang
## Background
音乐驱动的舞蹈生成在工业应用中引起了广泛关注，特别是在群体编舞的创作中。然而，在群体舞蹈生成过程中，现有的大多数方法仍然存在三大主要问题：多舞者碰撞、单舞者脚部滑动和长时间生成过程中动作的突然更换。
## Innovation
本文提出了TCDiff++，这是一种音乐驱动的端到端框架，旨在生成和谐的群体舞蹈。TCDiff++通过以下创新点来解决上述问题：1. 使用舞蹈定位嵌入来更好地保持舞者之间的相对位置。2. 引入距离一致性损失，以确保舞者间的距离保持在合理范围内。3. 引入换态模式嵌入，通过设计方案步适配器来细化原始运动数据，从而减少脚部滑动。4. 呈现一种长群体扩散采样策略，通过将位置信息注入噪声输入来减少位置突变。5. 集成序列解码层以增强模型在处理长序列时的选择性能力。
## Conclusion
大量的实验表明，我们的TCDiff++在长时序场景中达到了最先进的性能，确保了高质量且连贯的群体舞蹈生成。
# 411. `cs.CV` - DRO-Augment框架：通过结合Wasserstein分布鲁棒优化和数据增强实现鲁棒性 [PDF](https://arxiv.org/pdf/2506.17874), [HTML](https://arxiv.org/abs/2506.17874)
## Authors
Jiaming Hu,Debarghya Mukherjee,Ioannis Ch. Paschalidis
## Background
在许多实际应用场景中，确保深度神经网络（DNNs）的鲁棒性和稳定性至关重要，尤其是在遭受各种输入扰动的情况下进行图像分类任务。虽然数据增强技术已被广泛应用于增强模型在这些扰动下的抗干扰能力，但仍然需要在同时抵抗恶意数据和对抗性攻击方面进行显著改进。本研究旨在解决这一挑战，提出了一种新的方法DRO-Augment来提高模型在各种类型扰动下的稳定性，同时保持在干净数据集上的准确性，并且在一系列基准数据集如CIFAR-10-C、CIFAR-100-C、MNIST和Fashion-MNIST上优于现有的增强方法。尽管在重度扰动数据和对抗性攻击场景下提高了鲁棒性，但在干净数据集上仍能保持高精度。理论层面，本书建立了神经网络训练使用了一种高效可计算且有变异正则化的损失函数得到的新通用误差边界，该损失函数紧密关联于W-DRO问题的解决形式，从而进一步论证了该方法的有效性和实用性。
## Innovation
DRO-Augment框架创新性地结合了Wasserstein分布鲁棒优化和多种数据增强策略，以显著提高模型在多种类型扰动情况下的鲁棒性。此外，这种新方法在实际应用的数据集上超越了现有的增强方法，同时保持在干净数据集上的高准确性。从理论层面来看，研究团队首次提出了适用于W-DRO相关损失函数的新的泛化误差边界，这为模型的泛化性能提供了新的理论依据。
## Conclusion
DRO-Augment框架在多种扰动和对抗性攻击下显著增强了深度神经网络的鲁棒性和稳定性，并且在多种基准数据集上展示了优越的性能，特别是对于重度扰动情况和对抗性攻击的组合效果。同时，研究还提供了一种高效计算的损失函数，进一步阐明了模型的泛化性能，并为未来的研究提供了理论支持。
# 412. `cs.LG` - 机器学习会议应建立“反驳与评论”轨道 [PDF](https://arxiv.org/pdf/2506.19882), [HTML](https://arxiv.org/abs/2506.19882)
## Authors
Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho
## Background
科学通过迭代地提升并纠正人类对世界的理解而进步。在机器学习（ML）研究中，快速的进展导致了大量的论文发表，但也导致了一些误导的、错误的、存在缺陷的甚至可能是欺诈性的研究在ML会议上被接受并受到重视。这是因为同行评审的局限性。虽然这些错误是可以理解的，但ML会议目前并未提供足够的机制来系统地纠正这些错误。因此，需要一种特殊的平台来支持对先前研究进行重要挑战的研究工作。
## Innovation
本文提议在ML会议上建立一个专门的“反驳与评论”（R & C）轨道。“反驳与评论”轨道将为支持对以前研究进行批判性挑战的重要研究提供一个高知名度、信誉良好的平台，从而促进一个动态的自我纠正研究生态系统。此外，本文还提出了橄榄设计、评审原则以及可能的风险，并提供了一个最近ICLR 2025口头报告的例子来说明该提议的具体应用。
## Conclusion
本文得出结论，ML会议应该创建正式、信誉良好的机制，以帮助ML研究自我纠正。
# 413. `cs.LG` - STIMULUS: 在随机多目标学习中实现快速收敛和低样本复杂度 [PDF](https://arxiv.org/pdf/2506.19883), [HTML](https://arxiv.org/abs/2506.19883)
## Authors
Zhuqing Liu,Chaosheng Dong,Michinari Momma,Simone Shao,Shaoyuan Xu,Yan Gao,Haibo Yang,Jia Liu
## Background
近年来，多目标优化（MOO）因其在机器学习、运筹学和工程领域的广泛应用而受到关注。然而，MOO算法设计仍处于初级发展阶段，许多现有的MOO方法在收敛速度和样本复杂性方面表现不佳。
## Innovation
为了应对这一挑战，本文提出了一种称为STIMULUS（stochastic path-integrated multi-gradient recursive estimator）的新算法，这是一种用于解决MOO问题的新且稳健的方法。STIMULUS引入了一个简单但强大的递归框架，用于更新随机梯度估计，以改善收敛性能并降低样本复杂性。此外，引入了STIMULUS-M的增强版本，通过引入动量项来进一步加速收敛。作者还建立了在非凸设置中的$O(1/T)$收敛率和在强凸设置中的$O (text{exp}text{-}text{μ}T)$收敛率，并分别实现了在非凸设置中的$O text{(}n+text{sqrt}(n)/text{ε}text{)}$样本复杂性和在强凸设置中的$Otext{(}n+ text{sqrt}(n) text{ln} (text{μ}/text{ε})text{)}$样本复杂性。此外，为了缓解STIMULUS和STIMULUS-M中的周期性全梯度评估需求，提出了带自适应批量的增强版本STIMULUS+/ STIMULUS-M+并提供了理论分析。
## Conclusion
本文展示了STIMULUS方法在非凸设置和强凸设置中的理论可行性和先进性，尤其是在收敛速度和样本复杂性方面具有优越表现。
# 414. `cs.CV` - 从粗糙到连续：运动鲁棒各向异性MRI重建的逐步细化隐式网格表示 [PDF](https://arxiv.org/pdf/2506.16210), [HTML](https://arxiv.org/abs/2506.16210)
## Authors
Zhenxuan Zhang,Lipei Zhang,Yanqi Cheng,Zi Wang,Fanwen Wang,Haosen Zhang,Yue Yang,Yinzhe Wu,Jiahao Huang,Angelica I Aviles-Rivero,Zhifan Gao,Guang Yang,Peter J. Lally
## Background
在运动稳健的磁共振成像(MRI)中，从2D切片重建出3D脑部体积是非常关键的任务，尤其是在加速采集或患者运动条件下。这一任务由于层次结构中断的局部细节丢失、运动引起的全局结构混叠以及体素各向异性而具有挑战性。因此，提出了一种逐步细化隐式神经表示(PR-INR)框架，该框架在几何感知的坐标空间中统一了运动校正、结构细化和体积合成。该框架首先利用运动感知扩散模块生成具有降噪效果并保留全局解剖结构的粗略体积重建，然后利用隐式细节恢复模块通过将空间坐标与视觉特征对齐来实施残差细化，从而校正局部结构并增强边界精度。最后，利用体素连续感知表示模块将图像表示为3D坐标上的连续函数，从而实现精准的层面间填充和高频细节恢复。实验结果表明，PR-INR在定量重建指标和视觉质量上均超越了最新的方法，并且在不同条件下的推广性和鲁棒性表现出色。
## Innovation
提出了一种逐步细化隐式神经表示(PR-INR)框架，该框架在几何感知的坐标空间中统一了运动校正、结构细化和体积合成。首先，利用运动感知扩散模块生成粗略的体积重建，其次，通过将空间坐标与视觉特征对齐进行残差细化，最后，将图像表示为3D坐标上的连续函数，实现了精确的层面间填充和高频细节恢复。
## Conclusion
实验结果表明，PR-INR在定量和视觉质量方面均优于现有方法，并在不同条件下展示了良好的推广性和鲁棒性。
# 415. `cs.CV` - Morse: 双采样加速扩散模型 [PDF](https://arxiv.org/pdf/2506.18251), [HTML](https://arxiv.org/abs/2506.18251)
## Authors
Chao Li,Jiawei Fan,Anbang Yao
## Background
本文研究了如何加速扩散模型的损失函数。扩散模型通常通过从噪声生成数据的过程进行迭代生成，但这一过程往往较为缓慢。通过引入快速跳跃采样和自适应残差反馈策略，研究者们开发了一个新的框架来提高生成效率。Morse框架通过结合两个模型Dash和Dot来实现这一目标，其中Dash模型用于快速跳跃采样生成数据，而Dot模型则用于提供自适应的残差反馈，进一步提升生成效率。通过交替运行这两个模型，Morse能够灵活地平衡生成性能和运行时效率。
## Innovation
Morse框架引入了两个模型Dash和Dot，其中Dash模型负责快速跳跃采样生成数据，而Dot模型提供自适应的残差反馈以提高噪声估计。这种方法能够使生成过程更加灵活，同时显著提高运行时效率。Morse通过共享权重策略，使得训练和推理过程更加高效。在多种图像生成任务中，Morse相对于9个基线扩散模型实现了1.78至3.31倍的平均加速效果，并且该方法还可以应用于加速经过一致性蒸馏技术加速的Latent Consistency Model (LCM-SDXL)。
## Conclusion
Morse框架通过结合快跳采样模型和自适应残差反馈模型，成功实现了扩散模型的损失函数加速。该方法不仅能够在多种图像生成任务中实现1.78至3.31倍的加速效果，而且还能够推广应用于其他已加速的方法，证明了其广泛适用性和实用性。Morse框架为加速扩散模型的生成过程提供了一种新的有效方法。
# 416. `cs.LG` - 使用XAI方法解释用于电力价格预测的深度神经网络模型 [PDF](https://arxiv.org/pdf/2506.19894), [HTML](https://arxiv.org/abs/2506.19894)
## Authors
Antoine Pesenti,Aidan OSullivan
## Background
电力市场高度复杂，包含众多交互和复杂的依赖关系，使得理解市场内部机制和价格驱动因素变得困难。虽然已经开发了统计计量方法（白盒模型），但这些模型的力量不如深度神经网络（DNN）强大。
## Innovation
本文使用DNN进行价格预测，并运用XAI方法探究影响市场价格动态的因素。为了更深入理解不同电力市场的工作机制，作者结合SHAP、梯度和热力图等可视化技术分析了五个电力市场中各特征的行为和贡献。此外，作者还引入了SSHAP值和SSHAP线的概念，以更好地表示高维表型模型的复杂性。
## Conclusion
通过结合可解释性方法和可视化技术，本文提高了对电力市场工作原理的理解，特别是在复杂高维度数据中探寻影响因素方面。
# 417. `cs.LG` - FlightKooba: 一种快速可解释的飞行轨迹预测模型 [PDF](https://arxiv.org/pdf/2506.19885), [HTML](https://arxiv.org/abs/2506.19885)
## Authors
Jing Lu,Xuan Wu,Yizhun Tian,Songhan Fan,Yali Fang
## Background
库普曼理论是一种强大的非线性系统建模工具，能够将非线性系统转化为线性表示。飞行轨迹预测（FTP）是一个复杂的非线性系统。当前应用于FTP任务的库普曼理论模型效果有限，模型解释性较差，且计算库普曼算子较为耗时，导致训练时间过长。现有方法无法有效满足实时性和解释性的需求，从而亟需新的解决方案来解决上述问题。
## Innovation
本文提出了一种新的飞行轨迹预测建模和控制框架——FlightKooba，该框架基于HIPPO方法、库普曼理论和控制论中的状态空间方程。FlightKooba直接从数据中构建库普曼算子，使得结构更加清晰，参数可训练数量显著减少，从而大幅缩短了训练时间。实验结果表明，FlightKooba方法在时间和内存消耗方面优于现有方法，在不使用CUDA加速的情况下，训练时间与Mamba模块相当；并且在大多数数据集上内存使用减少了超过50%，参数数量减少了十倍，成功实现了飞行轨迹预测任务。该方法提供了一种快速计算库普曼算子的新方法，开拓了时间序列预测与控制相结合的新可能。
## Conclusion
FlightKooba模型通过直接从数据中构建库普曼算子，大幅度提高了模型的解释性和训练效率，展示了在飞行轨迹预测任务上的卓越性能。这种方法在时间序列预测领域有广泛的应用前景。
# 418. `cs.LG` - 强化学习和传统深度学习方法用于轴承故障诊断的对比分析 [PDF](https://arxiv.org/pdf/2506.19929), [HTML](https://arxiv.org/abs/2506.19929)
## Authors
Efe Çakır,Patrick Dumond
## Background
旋转机械中的轴承故障可能导致严重的运营中断和维护成本。现代的轴承故障诊断方法主要依赖振动分析和机器学习技术，但这些方法通常需要大量的标注数据，并且在动态环境中可能表现不佳。
## Innovation
该研究探索了使用强化学习（RL），特别是深度Q网络（DQNs），进行机械状态监测中的轴承故障分类任务的可能性，以提高轴承故障诊断的准确性和适应性。结果表明，在控制条件下开发的RL模型可以达到传统监督学习模型的性能，但在优化奖励结构后，在适应性方面表现出色。
## Conclusion
这些发现展示了RL在传统方法中的潜在补充作用，为适应性诊断框架铺平了道路，但也指出了计算成本的改进空间。
# 419. `cs.LG` - Orthogonal Soft Pruning for Efficient Class Unlearning [PDF](https://arxiv.org/pdf/2506.19891), [HTML](https://arxiv.org/abs/2506.19891)
## Authors
Qinghui Gong,Xue Yang,Xiaohu Tang
## Background
机器卸载旨在从预训练神经网络中选择性地移除特定类别的知识，以满足如GDPR之类的隐私法规。现有的方法通常在卸载速度和保留预测准确性之间存在权衡，往往既需较高的计算开销，又会导致重要性能的显著下降。
## Innovation
本文提出一种新的类感知软剪枝框架，利用正交卷积核正则化来实现快速且精确的遗忘，响应时间为毫秒级别。通过在训练期间施加正交约束，本方法在卷积滤波器和特征表示之间去相关，同时通过激活差异分析高效地识别特定类别的通道。
## Conclusion
跨多个架构和数据集的广泛评估表明，该方法能够稳定剪枝，近实时执行，完全忘记目标类，并且在保留的数据上保留了最小的准确性损失。在CIFAR-10、CIFAR-100和TinyImageNet数据集上的实验表明，本方法大大降低了成员推理攻击的风险，并与最先进的基准相比，显著加速了卸载。该框架为MLaaS环境中的实时机器卸载提供了一个高效且实用的解决方案。
# 420. `cs.LG` - HERCULES: 基于嵌入的层级递归聚类方法结合LLM进行高效总结 [PDF](https://arxiv.org/pdf/2506.19992), [HTML](https://arxiv.org/abs/2506.19992)
## Authors
Gabor Petnehazi,Bernadett Aradi
## Background
随着不同模态的复杂数据集的爆炸性增长，需要先进的分析工具，这些工具不仅要有效地分组数据，还要提供易于人类理解的关于发现结构的见解。现有的方法通常专注于单一数据类型或缺乏对聚类结果的深入解释。HERCULES旨在克服这些问题，提供一种针对多种数据类型（包括文本、图像和数值数据）进行层次k均值聚类的新算法和Python包。
## Innovation
HERCULES的一个关键创新是深度整合大型语言模型（LLMs），用于生成每个层级聚类的语义丰富标题和描述，显著提高了可解释性。算法支持两种主要的表示模式：直接模式，基于原始数据嵌入或缩放的数值特征进行聚类；描述模式，基于从LLM生成的摘要推导出的嵌入进行聚类。用户可以通过提供‘topic_seed’来引导LLM生成的摘要向特定主题倾斜。还提供了一个交互式可视化工具，以深入分析和理解聚类结果。
## Conclusion
我们展示了HERCULES的功能，并讨论了其从复杂数据集中提取有意义的层级知识的潜力。
# 421. `cs.LG` - 在广义可加模型中最重要特征可能是特征组 [PDF](https://arxiv.org/pdf/2506.19937), [HTML](https://arxiv.org/abs/2506.19937)
## Authors
Tomas M. Bosschieter,Luis Franca,Jessica Wolk,Yiyuan Wu,Bella Mehta,Joseph Dehoney,Orsolya Kiss,Fiona C. Baker,Qingyu Zhao,Rich Caruana,Kilian M. Pohl
## Background
在可解释性机器学习中，分析特征的重要性已经成为一种普遍做法，但在某些情况下，一组相关的特征的联合信号往往被忽略或无意中排除。忽视这些联合信号可能会丧失一个关键洞察：在许多情况下，最显著的预测因子不是孤立的特征，而是特征组的综合效应。这对包含自然特征分组的数据集尤其成问题，包括多模态数据集。本文旨在探讨如何在广义可加模型（GAMs）中确定特征组的重要性，以填补这一研究空白。
## Innovation
本文提出了一种新的方法，用于在广义可加模型中确定特征组的重要性。这一方法具有高效性、无需重新训练模型、允许后验定义组、支持组间重叠，并且在高维数据集中有实际意义。该方法还为解释变异度提供了一个统计学上的类比。通过三个合成实验，展示了该方法的性质，并在多模态神经科学数据集和髋关节置换术后的社会决定因素中分析了特征组的重要性。这两项案例研究揭示出，在医学问题分析中，特征组的重要性比单一特征的分析提供更准确、更全面的观点。
## Conclusion
本文提出的方法为在广义可加模型中评估特征组的重要性提供了一种新的有效途径，这种方法不仅实用而且在高维特征空间中具有解释力。通过多模式数据集和健康社会决定因素的实际应用，证明了这种方法的有效性和重要性，进一步强调特征组在识别复杂医学信号中的作用。
# 422. `cs.LG` - Transition-aware Regret Approximation with Co-learnability for Environment Design (TRACED), [PDF](https://arxiv.org/pdf/2506.19997), [HTML](https://arxiv.org/abs/2506.19997)
## Authors
Geonwoo Cho,Jaegyun Im,Jihwan Lee,Hojun Yi,Sejin Kim,Sundong Kim
## Background
通用深度强化学习代理在未见过的环境中仍然面临显著挑战。已有的一种有前景的解决方案是无监督环境设计（UED），这是一种协同进化的框架，其中教师通过自适应生成具有高学习潜力的任务，学生则在不断演进的课程中学出稳健的策略。现有的UED方法通常通过损失值函数来估算学习潜力，即用当前性能和最优性能之间的差距（即后悔）来衡量。该研究在此基础上引入了转移预测错误作为后悔的一种补充，并提出了衡量任务间共学习能力的轻量级指标，从而提出了一种新的评估框架TRACED，以提高环境设计中的零样本泛化性能，同时减少环境交互次数。
## Innovation
该研究引入了转移预测错误作为后悔的一种补充，并提出了衡量任务间共学习能力的轻量级指标。结合这两种测量，提出了新的评估方法TRACED。TRACED能够快速提升复杂度，并在与共学习能力结合时提供额外收益，从而提高了环境设计中的零样本泛化性能，同时减少了环境交互次数。
## Conclusion
研究结果表明，精细的后悔近似和任务关系的明确建模可以用于提高UED中的样本效率课程设计。
# 423. `cs.LG` - 作为掩码扩散模型的任意顺序GPT：解开表达和架构 [PDF](https://arxiv.org/pdf/2506.19935), [HTML](https://arxiv.org/abs/2506.19935)
## Authors
Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma
## Background
大型语言模型（LLMs）主要采用自回归（AR）方法，但掩码扩散模型（MDMs）正在成为可行的替代方案。由于AR模型通常是解码器类型的，而MDMs通常采用编码器类型，因此同时改变建模范式和架构使得直接比较变得不公平，难以区分观察到的差异是源于建模范式还是架构的变化。本文旨在评估MDMs在解码器类型框架下的性能，以公平比较MDMs（作为任意顺序自回归，或AO-AR）和标准AR范式。研究发现标准的AO-AR目标（平均所有标记排列）可能需要改进，因为许多排列似乎不如语言固有的从左到右结构的信息量大。此外，研究还探讨了MDMs架构的影响（编码器类型 vs. 解码器类型），结果表明，尽管编码器类型MDMs建模的是一个更简单的条件概率空间，但解码器类型MDMs在温度调整的情况下可以实现显著的生成速度提升（约25倍），并且仍然具有可比的困惑度，这揭示了关键权衡关系。
## Innovation
本文提出将MDMs用于解码器类型框架，以此来公平比较AO-AR和标准AR范式；并探讨了MDMs内部的架构影响，发现了解码器类型MDMs可以通过温度调整实现显著的生成速度提升和可比的困惑度，即使它们建模了大量更大的空间。这项工作基本上解开了核心范式差异和架构影响的耦合，为未来的模型设计提供了见解。
## Conclusion
通过使用解码器类型MDMs，本文揭示了AO-AR目标可能需要改进的问题，并展示了了解码器类型在MDMs中的优势，即在大的空间建模下仍然能够实现显著的生成速度提升和可比的困惑度。这种研究方法为未来解决范式和架构的影响提供了新的思路。
# 424. `cs.LG` - 基于层间最近邻的不确定性量化框架 [PDF](https://arxiv.org/pdf/2506.19895), [HTML](https://arxiv.org/abs/2506.19895)
## Authors
Miguel N. Font,José L. Jorro-Aragoneses,Carlos M. Alaíz
## Background
神经网络在难以检测模式或构建逻辑模型的问题上表现出高精度，但在医疗诊断或自动驾驶等高风险领域，错误的解决方案可能会导致严重问题。为了检测和缓解这些错误，研究通过测量神经网络决策的不确定性来提出一个新框架。该框架基于检索出具有与查询相同激活向量的训练案例来衡量决策的不确定性，并提出了两种新的衡量标准来评估这些相似案例的变化。
## Innovation
提出了一种新颖的后处理框架，基于检索相似的训练案例来衡量每个层的决策不确定性，并引入了两种新的衡量标准：决策变化和层不确定性，这些标准能捕捉不同层中最近邻类分布的变化。该框架在CIFAR-10和MNIST数据集上的分类模型中进行了评估，结果表明这些指标增强了不确定性估计，特别是在具有挑战性的分类任务中超过了基于softmax的置信度。
## Conclusion
该研究提出了一种基于层间最近邻的不确定性量化框架，通过引入两种新的衡量标准改进了不确定性估计，尤其是在具有挑战性的分类任务中优于基于softmax的置信度方法。
# 425. `cs.LG` - 基于因果感知的自适应关键帧提取的VR交互QoE智能优化 [PDF](https://arxiv.org/pdf/2506.19890), [HTML](https://arxiv.org/abs/2506.19890)
## Authors
Ziru Zhang,Jiadong Yu,Danny H.K. Tsang
## Background
在多用户虚拟现实（VR）交互中，优化用户体验（QoE）需要在超低延迟、高保真度运动同步和资源公平分配之间取得微妙平衡。现有方法往往忽视了分配带宽、CPU频率与用户感知之间的因果关系，限制了QoE的改进。因此，需要一种智能框架，结合自适应关键帧提取与因果感知增强学习，以最大化QoE。
## Innovation
本文提出了一个集成自适应关键帧提取与因果感知增强学习的智能框架。首先，使用韦伯-费nor定律提出了新的QoE度量，结合感知灵敏度、注意力驱动优先级和运动重建精度。然后，通过混合整数规划（MIP）任务对关键帧比例、带宽和计算资源进行联合优化，同时在视野公平约束下进行优化。此外，提出了一种部分状态因果深度确定性策略梯度（PS-CDDPG）方法，将因果影响检测与深度确定性策略梯度（DDPG）方法相结合。这种方法利用因果信息来引导动作，提高训练效率，从而改善QoE并维护公平性。
## Conclusion
实验证明，与基准方法相比，我们提出的框架显著降低了交互延迟、提升了QoE并保持了公平性，性能更优。
# 426. `cs.LG` - 基于振荡并放神经元的类脑无线分立计算 [PDF](https://arxiv.org/pdf/2506.20015), [HTML](https://arxiv.org/abs/2506.20015)
## Authors
Dengyu Wu,Jiechen Chen,H. Vincent Poor,Bipin Rajendran,Osvaldo Simeone
## Background
类脑计算为实时时间序列处理提供了相对于传统深度学习加速器的节能选择。然而，许多边缘应用，如无线传感和音频识别，产生的串流信号具有丰富的频谱特征，传统泄漏积分和放电(LIF)忆阻型神经元难以有效捕捉。本文研究了一种无线分立计算架构，利用具有振荡动力学的振荡并放(RF)神经元直接处理时域信号，从而消除昂贵的频谱预处理需求。RF神经元通过在可调频率下振荡，可以提取时域局部化频谱特征，同时保持低放电活性。这种时间稀疏性转换为在计算和传输能耗上的显著节约。假设采用OFDM为基础的模拟无线接口进行脉冲传输，我们提出了一个完整的系统设计，并在音频分类和调制分类任务上评估了其性能。实验结果显示，提出的RF-SNN架构在推理和通信期间对比传统LIF-SNN和ANN，显著降低了脉冲率和总能耗，同时保持了相近的准确度。
## Innovation
本文提出了基于RF神经元的无线分立计算架构，利用振荡动力学直接处理时域信号，无需昂贵的频谱预处理；通过调节频率提取时域局部化频谱特征，保持低放电活性，从而实现计算和传输能耗的显著节约；基于OFDM模拟无线接口的脉冲传输设计，实现与传统LIF-SNN和ANN相近的准确度，同时大幅降低推理和通信能耗。
## Conclusion
提出的RF-SNN架构在音频分类和调制分类任务上达到了与LIF-SNN和ANN相近的准确度，同时显著降低了推理和通信过程中的能耗。
# 427. `cs.LG` - AIGC提供任务中生成语义通信中基于蒸馏的知识对齐 [PDF](https://arxiv.org/pdf/2506.19893), [HTML](https://arxiv.org/abs/2506.19893)
## Authors
Jingzhi Hu,Geoffrey Ye Li
## Background
由于AI生成内容（AIGC）的大量涌现，将其从云传输到边缘和移动用户需要消耗大量网络带宽。生成语义通信（GSC）通过传输高度紧凑的信息（如提示文本和潜在表示）而不是高维AIGC数据，提供了一种有希望的解决方案。然而，GSC依赖于云生成AI（GAI）的知识与边缘和用户的知识之间的对齐，以及无线传输知识与实际信道知识之间的对齐，这仍是一个挑战。
## Innovation
本文提出了一种名为DeKA-g的基于蒸馏的知识对齐算法，用于GSC系统。该算法的核心思想是从云-GAI中提取生成知识，将其转换为低秩矩阵，边缘设备可以使用这些矩阵来适应各种无线信道条件下的传输知识。DeKA-g包含两种新颖的方法：元词辅助知识蒸馏（MAKD）和可变速率分组信噪比适应（VGSA）。MAKD利用优化的元词提高知识蒸馏的效率，而VGSA使系统能够高效地适应不同的压缩率和信噪比范围。实验结果表明，DeKA-g将边缘生成的图像与云生成的图像之间的对齐提高了44%，并且与基线相比，其压缩率调整效率提高了116%，在低信噪比条件下性能提高了28%。
## Conclusion
通过DeKA-g，实现了边缘生成的图像与云生成的图像之间的更好对齐，提高了压缩率调整的效率，并在低信噪比条件下显著提升了通信性能。
# 428. `cs.LG` - 解释性滚动扩散模型在概率天气预报中的应用 [PDF](https://arxiv.org/pdf/2506.20024), [HTML](https://arxiv.org/abs/2506.20024)
## Authors
Salva Rühling Cachay,Miika Aittala,Karsten Kreis,Noah Brenowitz,Arash Vahdat,Morteza Mardani,Rose Yu
## Background
扩散模型是概率预测的强大工具，但在高维混沌系统中，大多数应用都是逐个预测未来快照，这难以建模复杂的时序依赖关系，也不具体考虑到这些系统中存在的不确定性逐步增长的内在特性。虽然滚动扩散框架已经提出，但将其与最先进的高保真扩散技术集成仍然面临重大挑战。
## Innovation
本文通过引入解释性滚动扩散模型（ERDM），首次成功将滚动预测结构与解释性扩散模型（EDM）中原理性的高效设计统一起来。贡献包括：(i) 一种新的损失权重方案，专注于模型容量分配在确定性让位于随机性的中等预测时间范围内；(ii) 使用预训练的EDM进行初始窗口的高效初始化策略；(iii) 一种自定义的混合序列架构，以在去噪过程中提取稳健的时空特征。
## Conclusion
ERDM在2D纳维-斯托克斯模拟和1.5°分辨率的ERA5全球天气预报中，始终优于关键的扩散基线，包括条件自回归EDM。ERDM提供了一个灵活且强大的一般框架，用于处理概率预测序列生成问题，特别是在建模不确定性逐步扩大方面至关重要。
# 429. `cs.LG` - 以偏概全：最后层训练中的最优损失加权 [PDF](https://arxiv.org/pdf/2506.20025), [HTML](https://arxiv.org/abs/2506.20025)
## Authors
Nathan Stromberg,Christos Thrampoulidis,Lalitha Sankar
## Background
随着机器学习模型在大规模分类任务中变得更加能力出众，它们克服由训练数据引入的偏见的能力正在受到越来越多的关注。以往的研究表明，参数化设置存在两种极值状态，分别是过参数化但可分离的设置和参数不足的理想设置，在这两种情况下损失加权的效果有所不同。这一工作探索了最后层重新训练（LLR）的范围，在这一范围中，未见过的数据通常不完全可分离且模型大小与数据量相对应，介于上述两种极端状态之间。研究显示，在理论和实践中，损失加权在这类重新训练中仍然是有效的，但这些权重必须考虑模型的相对过参数化程度才能生效。
## Innovation
该工作探讨了最后层重新训练（LLR）的范围，在这种情况下，损失加权仍然有效但需要考虑模型的相对过参数化程度。这项研究揭示了在LLR场景下损失加权的新颖应用，并提供了理论和实践上的证据。
## Conclusion
损失加权在最后层重新训练中仍然有效，但必须考虑到模型的相对过参数化程度。
# 430. `cs.LG` - 边缘设备上的可验证删除 [PDF](https://arxiv.org/pdf/2506.20037), [HTML](https://arxiv.org/abs/2506.20037)
## Authors
Mohammad M Maheri,Alex Davidson,Hamed Haddadi
## Background
机器学习服务提供商通常将全局模型分发到边缘设备上，这些设备随后会使用本地数据进行个性化处理。然而，版权、偏见或监管要求等问题可能需要在所有边缘设备上验证性地移除某些数据样本。确保边缘设备能够正确执行这样的遗忘操作对于维护系统的完整性至关重要。
## Innovation
引入了利用零知识证明（具体为zk-SNARKs）的验证框架，该框架可以在不泄露隐私的情况下验证边缘设备上个性化模型的数据遗忘操作。开发了专门设计的算法以兼容高效的zk-SNARK证明生成过程，确保计算和内存开销最小化，适合边缘设备的限制环境。此外，该方法还仔细地保持了边缘设备上的个性化增强，确保删除后模型性能基本不受影响。
## Conclusion
验证框架的实际性和效果得到了证实，通过这种验证性遗忘方法可以保持最小的个人化性能提升下降。该方法确保了边缘设备上的可验证、隐私保护和有效的机器遗忘。
# 431. `cs.LG` - 使用二元优化和图学习的多代理操作中多样化行动计划的自动化生成 [PDF](https://arxiv.org/pdf/2506.20031), [HTML](https://arxiv.org/abs/2506.20031)
## Authors
Prithvi Poddar,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury
## Background
涉及多个代理的灾难响应、搜索与救援以及军事任务需要自动化的规划支持流程。环境变化（如雨、雪、道路封锁等）可能会影响行动计划的预期性能，因此需要一个多样化的行动计划池，这些计划在任务分配方面具有跨代理的多样性。此外，代理能力的变化（可以是人类团队或自主系统）为计划过程带来了实际机会和计算挑战。
## Innovation
该论文提出了一个新的理论框架和计算框架，用于生成在代理任务兼容性具有软变化时多样化的行动计划池。关键在于任务空间和行动计划池的图抽象化，以量化这种多样性。该框架通过联合作业的最大化多样性与代理任务映射的总体兼容性，使用遗传算法在集中式多机器人任务分配问题中分配任务。通过图神经网络使用策略梯度方法进行单代理任务序列化，从而最大化任务完成率，以适应任务特征。在模拟环境中测试该行动计划生成过程，证明了相对于随机游走基准的显著性能提升、较少的任务序列优化差距以及为5个代理/100个任务操作规划最多20个行动计划所需时间约为50分钟的结果。
## Conclusion
该研究表明，通过结合二元优化和图学习方法，可以自动高效地生成多个代理作战任务中多样化的行动计划，确保在不同任务特性的适应下最大化完成率，且具有较低的优化缺口。
# 432. `cs.LG` - 使用自我蒸馏进行GNN的不确定性量化 [PDF](https://arxiv.org/pdf/2506.20046), [HTML](https://arxiv.org/abs/2506.20046)
## Authors
Hirad Daneshvar,Reza Samavi
## Background
Graph Neural Networks (GNNs)在医疗领域的表现非常出色，但在临床环境中，衡量GNNs预测不确定性仍然是一个挑战。虽然贝叶斯方法和集成方法可以用来量化不确定性，但这些方法计算成本高昂。集成方法使用的不一致性指标无法捕捉到集成网络中模型的多样性。
## Innovation
本文提出了一种基于知识蒸馏的新方法，以更高效、更准确地量化GNNs的不确定性。这种方法采用自我蒸馏机制，网络同时作为教师和学生模型，从而避免了独立训练多个网络的需求。此外，为了确保自我蒸馏的影响力，开发了一个新的不确定性度量指标，该指标通过为每个GNN分类器分配不同的权重来捕捉网络的多样性。实验结果证明，提出的方法能够有效捕捉模型的预测不确定性，并且在性能上与MC Dropout和集成方法相当。
## Conclusion
提出的基于自我蒸馏的方法能够有效量化GNNs的预测不确定性，具有与MC Dropout和集成方法相似的性能。实验在MIMIC-IV和Enzymes两个图数据集上验证了该方法的有效性。该方法和代码已对外公开。
# 433. `cs.LG` - 通过迭代随机计算实现的通用预训练 [PDF](https://arxiv.org/pdf/2506.20057), [HTML](https://arxiv.org/abs/2506.20057)
## Authors
Peter Bloem
## Background
该研究探讨了使用随机生成的数据进行模型预训练的方法。研究基于最近的研究成果，这些研究表明序列模型可以被训练以近似Solomonoff归纳，并对比了类似的但互补的理论结果。已有研究证明，通过使用合成数据预训练模型可以实现零样本的上下文学习，并且这种性能随着模型规模的增加而提高。在此基础上，该研究进一步将结果扩展到了真实世界数据，并且展示了在预训练后对模型进行微调可以实现更快的收敛和更好的泛化能力。
## Innovation
该研究通过理论上基于算法复杂性的分析，证明了使用随机生成数据进行预训练的有效性，并通过实验证明了该方法的有效性。此外，该研究将已有成果扩展到真实世界数据，并展示了对于预训练后的模型进行微调可以提升其性能。
## Conclusion
通过迭代随机计算，可以使用随机生成的数据进行预训练，这种方法可实现零样本的上下文学习，并且性能会随着模型规模的增加而提高。此外，对于预训练后的模型进行微调可以实现更快的收敛和更好的泛化能力。这项研究在真实世界数据集上进行了验证，进一步扩展了已有成果的适用范围。
# 434. `cs.LG` - 新折叠和微调量子联邦学习的见解 [PDF](https://arxiv.org/pdf/2506.20016), [HTML](https://arxiv.org/abs/2506.20016)
## Authors
Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel
## Background
量子联邦学习（QFL）中的客户异质性对性能提出了重大挑战。标准聚合方法在复杂异质环境中往往失效，导致过拟合和其他优化问题。
## Innovation
本文提出了一种新的方法，利用深度展开，使其能够根据特定的训练行为自主优化超参数，如学习率和正则化因子。这种方法实现了自适应微调，在高度异质的环境中动态调整，减少了过拟合，提高了优化的鲁棒性。实验结果表明，该方法在IBM量子硬件和Qiskit Aer仿真器上实时训练时，准确率高达约90%，远超传统方法（约55%）。这种方法特别适用于基因表达分析和癌症检测等关键应用，提高诊断精度和预测模型的效率。结果归因于深度展开框架中的收敛感知、可学习优化步骤，这维持了一般的泛化能力。因此，该研究解决了传统QFL的核心限制，使其更易于应用于复杂的挑战，如医疗保健和基因组研究。
## Conclusion
该研究提出的方法在高度异质的环境中显著提高了量子联邦学习的性能，适用于医疗保健和基因组研究等关键应用，通过深度展开结构实现了更为有效的优化。
# 435. `cs.LG` - 跨层离散概念发现以解析语言模型 [PDF](https://arxiv.org/pdf/2506.20040), [HTML](https://arxiv.org/abs/2506.20040)
## Authors
Ankur Garg,Xuemin Yu,Hassan Sajjad,Samira Ebrahimi Kahou
## Background
解锁 Transformer 层间涌现概念的分析仍然是一个重大挑战，因为残差流线性混合和重复信息，掩盖了大型语言模型内部特征的发展过程。当前的研究主要集中在单一层数的神经表示，未能关注层间的叠加和由此引入的冗余，这些表示通常是直接分析激活模式或是传递给分类器来映射到预定义的概念集中。
## Innovation
本文提出了一种称为 CLVQVAE 的框架，利用向量量化在层间映射表示，并在过程中将重复的残差流特征压缩成紧凑且可解释的概念向量。该方法结合了 k-项温度采样在量化期间的使用和使用 EMA 代码本更新，通过控制离散潜在空间的探索过程来保持代码本多样性。此外，框架还采用缩放球形 k-means++ 进行代码本初始化，通过方向相似性而非幅度来聚类，更好地与词嵌入空间中的语义结构保持一致。
## Conclusion
我们的方法解决了现有技术中的局限性，通过向量量化和先进的量化策略，成功地提取出大型语言模型中跨层的概念。实验证明了该框架的有效性和对复杂模式的解析能力。
# 436. `cs.LG` - DIM-SUM: 动态插补以实现智能能源管理 [PDF](https://arxiv.org/pdf/2506.20023), [HTML](https://arxiv.org/abs/2506.20023)
## Authors
Ryan Hildebrant,Rahul Bhope,Sharad Mehrotra,Christopher Tull,Nalini Venkatasubramanian
## Background
传统的时间序列插补模型通常是使用完整数据集并且用人工遮罩模式模拟缺失值来开发的。然而，在实际的基础设施监控中，从业者常常遇到大量数据缺失且呈现复杂、异质模式的数据集。对于真实世界的数据情况，传统的数据遮罩方法存在局限性，无法有效处理实际出现的多种多样缺失模式。因此，需要一种新的预处理框架来填补这一空白，该框架能够连接人工遮罩训练数据与真实存在的缺失数据模式之间的差距，并且能有效处理复杂且多样化的缺失数据模式。本研究通过了对来自加利福尼亚供水区、电力数据集和基准数据集的20多亿个读数进行广泛的实验，证明了DIM-SUM框架的有效性，能够达到与传统方法相同的精度，同时处理时间更短，并且需要更少的训练数据。与大型预训练模型相比，DIM-SUM在准确性上平均有2倍的提升，并且在推断时间上显著减少。
## Innovation
提出了DIM-SUM预处理框架，它结合了模式聚类和自适应遮罩策略，并提供理论学习保证来处理实际观察到的多种缺失模式。相比传统的插补方法，DIM-SUM能够在更少的训练数据和更短的处理时间下实现相似的准确性，并且与大型预训练模型相比具有显著更高的准确性及更短的推断时间。
## Conclusion
通过在加利福尼亚供水区、电力数据集和基准数据集上的广泛实验表明，DIM-SUM框架能够有效地处理多样化缺失模式，相比传统方法，它在准确性、处理时间和训练数据需求方面具有显著优势。
# 437. `cs.LG` - LSH-DynED: 基于LSH的动态集成框架用于演化的多类别不平衡分类 [PDF](https://arxiv.org/pdf/2506.20041), [HTML](https://arxiv.org/abs/2506.20041)
## Authors
Soheil Abadifard,Fazli Can
## Background
多类别不平衡数据流分类是机器学习中的一个关键难点，特别是在处理多个类别时。虽然二分类不平衡数据流分类任务已经受到了广泛关注，但对多类不平衡数据流的研究相对较少。动态不平衡比的管理是这个领域的关键挑战。本文尝试通过将局部敏感哈希与随机超平面投影（LSH-RHP）集成到动态集成多样化（DynED）框架中，提出了一种新的、鲁棒的和有弹性的方法来应对这些挑战。
## Innovation
本文创新性地提出了一种方法，将LSH-RHP集成到DynED框架中，用于多类别不平衡非稳定数据流的分类。这是首次应用LSH-RHP进行欠采样。通过利用LSH-RHP进行多数类的欠采样，该方法提供了一个平衡的训练集，并提高了集成的预测性能。实验表明，LSH-DynED在Kappa和mG-Mean有效性指标上优于其他方法，尤其在大规模高维数据集和显著类别不平衡情况下表现良好，并在实际应用中表现出很好的适应性和鲁棒性。
## Conclusion
实验结果表明，LSH-DynED在处理多类别不平衡非稳定数据流方面表现出色。为了证明我们的构思，我们回顾了现有不平衡数据流的方法，指出了关键挑战，并提供了对未来工作的指导。为了使结果可复现，我们已在GitHub上公开了我们的实现。
# 438. `cs.LG` - 预测性维护方法综述：基于分类与回归的预测性维护分析 [PDF](https://arxiv.org/pdf/2506.20090), [HTML](https://arxiv.org/abs/2506.20090)
## Authors
Ainaz Jamshidi,Dongchan Kim,Muhammad Arif
## Background
预测性维护（PdM）已成为现代工业实践中的关键要素，通过减少非计划停机时间和优化资产生命周期管理，提高操作可靠性和成本管理。机器学习和深度学习使设备故障和剩余使用寿命（RUL）的预测更加准确，尽管已经有许多关于PdM的研究，但还没有单独对回归和分类方法之间的比较研究。已有研究主要集中在不同PdM方法上，而较少关注分类和回归方法在预测性维护中的比较应用。因此，本研究旨在系统地分析分类与回归方法在预测性维护中的应用，并强调关键进展、面临的挑战以及新兴趋势，如混合方法和AI驱动的预测性维护系统。
## Innovation
该研究首次全面对比分析了分类和回归方法在预测性维护中的应用，并指出数据不平衡和高维特征空间等挑战，以及混合方法和AI驱动的预测性维护系统的新兴趋势。此项研究有助于研究者和实践者了解各种预测性维护方法的优点和局限，并识别未来研究的方向，以构建更坚固和目标化的自适应维护系统。此外，未来工作将包括系统地审查实用方面的内容，如公共数据集、基准平台和开源工具，以促进预测性维护研究的进步。
## Conclusion
本综述旨在为研究人员和实践者提供各种预测性维护方法的优势和妥协的意识，并帮助识别未来研究的方向，以构建更坚固、目标化的自适应维护系统。未来的研究可能包括系统地审查实用方面的内容，如公共数据集、基准平台和开源工具，以支持预测性维护研究的进步。
# 439. `cs.LG` - MEL: 多层次集成学习在资源受限环境中的应用 [PDF](https://arxiv.org/pdf/2506.20094), [HTML](https://arxiv.org/abs/2506.20094)
## Authors
Krishna Praneet Gudipaty,Walid A. Hanafy,Kaan Ozkara,Qianlin Liang,Jesse Milzman,Prashant Shenoy,Suhas Diggavi
## Background
边端环境中的AI推理变得越来越普遍，适用于低延迟的服务。然而，这些环境在电力和资源方面受到限制，且容易出现故障。传统的故障鲁棒性方法，如云切换或压缩备份，往往需要牺牲延迟或准确性，这限制了它们在关键边端推理服务中的有效性。因此，迫切需要一种在资源受限环境下能在故障时保持高准确性和低延迟的新方法。
## Innovation
本文提出了一种名为Multi-Level Ensemble Learning (MEL)的新框架，该框架能够同时训练多个轻量级备份模型，允许在多服务器可用时协同工作，同时在故障时独立操作并保持良好的准确性。具体地，通过多目标优化问题的形式化表达，提出了一个损失函数来促进各个模型之间的多样性，同时确保每个模型能够在孤立状态下保持良好的性能。实证研究证明了MEL在视觉、语言和音频数据集上的性能与原始架构相当，并且可以在资源受限的边端平台中提供容错性和部署灵活性。
## Conclusion
研究表明，我们的集成模型，在与原始模型大小相当40%的情况下，能够在故障时保留95.6%的集成准确性。MEL不仅提供了与原始架构相当的性能，还增强了容错性和灵活性。
# 440. `cs.LG` - 使用大型语言模型进行开放指令重新标识的学习遵循指令策略 [PDF](https://arxiv.org/pdf/2506.20061), [HTML](https://arxiv.org/abs/2506.20061)
## Authors
Zhicheng Zhang,Ziyan Wang,Yali Du,Fei Fang
## Background
在强化学习中开发有效的指令遵循策略仍然颇具挑战性，这主要是因为高度依赖大量的手工标记指令数据集，以及从稀疏奖励中学习的难度。传统的解决方法需要大量的人类标注数据，这在时间和成本上都是巨大的负担。此外，直接从稀疏奖励中学习使得算法难以获得稳定的性能和泛化能力。因此，如何降低对外部标注数据的依赖，同时提高模型的学习效率和适应性，成为了一个亟待解决的问题。
## Innovation
本研究提出了一种新颖的方法，利用大型语言模型（LLMs）从已经收集的代理轨迹中自动生成开放指令，以回顾性地重新标识之前未成功的轨迹。通过这种方法，能够识别出代理在这些不成功的轨迹中已隐含完成的有意义子任务，使得代理的训练数据更加丰富，大大减少了对外部人工标注数据的依赖。实验结果表明，这种方法能够学习出一个能处理多种任务的统一指令遵循策略，并且在样本效率、指令覆盖范围和整体策略性能方面都优于现有的先进基线方法。
## Conclusion
我们的研究结果表明，利用LLM指导的开放指令重新标识方法能够显著提高指令遵循强化学习的效果。这种方法不仅降低了对外部标注数据的依赖，还提高了学习效率和策略性能。未来的研究可以进一步探索如何更好地利用大型语言模型来提高指令遵循的泛化能力和鲁棒性。
# 441. `cs.LG` - 监督耦合矩阵-张量分解（SCMTF）在溃疡性结肠炎患者报告结果计算表型中的应用 [PDF](https://arxiv.org/pdf/2506.20065), [HTML](https://arxiv.org/abs/2506.20065)
## Authors
Cristian Minoccheri,Sophia Tesic,Kayvan Najarian,Ryan Stidham
## Background
表型是指通过区分患者群体来识别不同疾病进展类型的过程。最近的趋势是利用低秩矩阵和张量分解方法处理多模态、异质性和缺失数据。在炎症性肠病（如溃疡性结肠炎UC）中，症状量化对于理解患者体验至关重要，但由于患者报告的症状通常噪声大、主观性强且数据稀疏，因此传统上未被纳入表型鉴定或其他机器学习方法中。本文通过探索计算表型，使用一种新颖的监督耦合矩阵-张量分解方法（SCMTF），整合时间动态的症状和实验室数据与静态特征，预测UC患者用药遵从性。这种方法首次在UC领域结合了监督和耦合，处理了缺失的患者报告数据（PROs），展示了矩阵和张量基于的表型方法在UC领域和高度缺失的PRO数据中的应用潜力，并验证了PROs包含可用于预测用药遵从性的相关信息.
## Innovation
提出了一种基于监督耦合矩阵-张量分解（SCMTF）的新方法，该方法能同时处理时间动态DRGs和静态特征，并成功应用于UC领域。这是第一个结合监督和耦合的张量方法，也是首次将这种方法应用于UC领域和PROs。模型利用深度学习框架提高了灵活性和可训练性，能够处理大量缺失数据。通过这种方法，实现了8和20个月未来用药改变预测AUC分别为0.853和0.803的卓越性能，进一步识别了包含几个症状变量的可解释表型，展示了PRO数据中的相关信息通常是被忽视的.
## Conclusion
本文提出的方法能成功应用于UC领域和高度缺失的PRO数据，并识别出有用的表型特征以预测用药遵从性，证明了低秩矩阵和张量基于的表型方法在UC领域具有潜力。
# 442. `cs.LG` - 使用局部和全局特征融合的GNN进行有向链接预测 [PDF](https://arxiv.org/pdf/2506.20235), [HTML](https://arxiv.org/abs/2506.20235)
## Authors
Yuyang Zhang,Xu Shen,Yu Xie,Ka-Chun Wong,Weidun Xie,Chengbin Peng
## Background
链接预测是图分析中的一个经典问题，具有许多实际应用。对于有向图，最近发展起来的深度学习方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻居信息。
## Innovation
提出了一个新颖的图神经网络（GNN）框架，将特征嵌入与社区信息融合，理论证明这种混合特征可以提高有向链接预测的性能。此外，还提出了一种方法将输入图转换为有向线图，以使图卷积在变换后的图中能够汇集更多信息。
## Conclusion
在基准数据集上的实验表明，当使用30%，40%，50%和60%的连接链接作为训练数据时，该方法在大多数情况下都优于最先进的方法。
# 443. `cs.LG` - DuoGPT：LLM中基于激活感知剪枝的训练免费双稀疏方法 [PDF](https://arxiv.org/pdf/2506.20194), [HTML](https://arxiv.org/abs/2506.20194)
## Authors
Ruokai Yin,Yuhang Li,Donghyun Lee,Priyadarshini Panda
## Background
大型语言模型（LLMs）表现强大但因为需要高内存和计算资源而难以部署。虽然剪枝方法能减少这些需求，但大多数方法忽略了运行时观察到的激活稀疏性。这导致现有的剪枝方法难以充分利用资源以保持模型的准确性。
## Innovation
重新解释激活稀疏性为动态结构化权重稀疏性，并提出了DuoGPT，一个统一框架，通过结合非结构化权重剪枝与激活稀疏性创建双重稀疏工作量（spMspV）。为了保持准确性，引入了激活感知校准扩展Optimal Brain Compression（OBC）框架，并提出了从密集模型生成的输出残差作为校正项。进一步优化了解决方案以提高GPU执行效率，使其适用于大规模参数LSTM。
## Conclusion
在LLaMA-2和LLaMA-3上的评估表明，DuoGPT在等速度提升下相比基线密集模型的准确性提高了最多9.17%，而速度提升比为1.39倍，表明其在保持高性能的同时实现了高效部署。
# 444. `cs.LG` - 源自多模态地球观测数据的高分辨率Live Fuel Moisture Content (LFMC) 地图以评估野火风险 [PDF](https://arxiv.org/pdf/2506.20132), [HTML](https://arxiv.org/abs/2506.20132)
## Authors
Patrick Alan Johnson,Gabriel Tseng,Yawen Zhang,Heather Heward,Virginia Sjahli,Favyen Bastani,Joseph Redmon,Patrick Beukema
## Background
近年来，野火的强度和严重性显著增加。近期的人工智能（AI）技术进步和公开可获得的卫星数据使得全球范围内的关键野火风险因素能够以高分辨率快速监测。Live Fuel Moisture Content (LFMC) 是野火风险的一个重要指标，对于野火研究和操作响应都非常重要。然而，地面LFMC样本的获取既费时又昂贵，导致更新频率低且稀疏。
## Innovation
本研究探索了使用预训练的多模态地球观测模型生成大规模的完整空间 (全空间) LFMC 地图的方法。该方法显著改进了先前随机初始化模型的性能（降低20%的RMSE）。此外，提供了一种自动化的生成流程，可在短时间内生成美国全范围的LFMC图，并在两次最近受野火影响的地区（Eaton和Palisades）得到了实际验证效果.
## Conclusion
本研究使用多模态地球观测数据成功生成了高分辨率的LFMC地图，提高了野火风险评估的准确性和实时性，为野火防治提供了更好的技术支持。
# 445. `cs.LG` - 确定性离散LTI-DAE系统的因果发现 [PDF](https://arxiv.org/pdf/2506.20169), [HTML](https://arxiv.org/abs/2506.20169)
## Authors
Bala Rajesh Konkathi,Arun K. Tangirala
## Background
在基于数据的因果网络重构中，确定确定性的线性时不变动态-代数方程系统（LTI-DAE系统）中的纯净因果变量或驱动变量至关重要。近年来，Kathari和Tangirala在2022年提出了一种因果发现方法，将其形式化为一个约束识别问题。这种方法利用DIPCA等方法对于带高斯测量误差的动态系统有效，但多个动态系统受反馈控制或伴随守恒定律，导致差分-代数（DAE）或混合因果系统。
## Innovation
本文提出了变量分区（PoV）方法，用于LTI-DAE系统的因果发现。PoV方法的优势在于，它不仅适用于缺乏代数方程的纯动态系统，还可以通过确定代数关系的数量、动态关系的数量和约束矩阵来识别因果驱动变量的最小子集。此外，通过约束矩阵的可接受分区和计算其条件数来识别子集。文章通过案例研究展示了所提方法的有效性，表明了该方法在实际应用中的优势。
## Conclusion
本文提出了适用于LTI-DAE系统的因果发现方法——变量分区（PoV），该方法可以更全面地识别因果驱动变量。通过实验验证，PoV方法能够更好地处理实际的动态系统问题，并提供了一种有效的途径来识别纯动态和带代数约束的控制系统中的因果关系。
# 446. `cs.LG` - 零样本大型语言模型归因：一种分布检验方法 [PDF](https://arxiv.org/pdf/2506.20197), [HTML](https://arxiv.org/abs/2506.20197)
## Authors
Clément L. Canonne,Yash Pote,Uddalok Sarkar
## Background
越来越多的代码片段是从大型语言模型（LLMs）中抽取的。当前研究面临一个挑战，即如何在只有LLM生成的样本时，利用假设检验等已有技术和保证，进行代码生成模型的归因分析。传统的归因方法在高维空间上难以处理，因此需要一种新的方法来克服这一难题。本文提出了一种零样本归因工具Anubis，将其归因问题重新定义为分布测试问题，以更有效地分析代码样本的来源。实验表明，使用约2000个样本，Anubis可以有效地区分不同的LLM模型，如DeepSeek-Coder、CodeGemma和Stable-Code，AUC表现优异（≥0.9）。
## Innovation
本文创新性地提出了一种零样本归因工具Anubis，将归因问题转化为分布测试问题，通过对比不同LLM模型之间生成样本的分布差异，有效解决了高维空间下的代码生成模型归因难题。
## Conclusion
实验结果表明，Anubis在区别不同LLM模型时表现优异，AUC值达到≥0.9，有效验证了方法的有效性和实用性。该方法为大型语言模型的归因提供了新的可能，特别是在仅依赖样本且无需额外构建数据集的情况下。
# 447. `cs.LG` - 通过反事实物理感知神经网络发现偏微分方程中的因果算子 [PDF](https://arxiv.org/pdf/2506.20181), [HTML](https://arxiv.org/abs/2506.20181)
## Authors
Ronald Katende
## Background
本文提出了一种使用物理感知神经网络和反事实扰动来发现偏微分方程(PDEs)因果结构的方法。不同于传统的残差最小化或稀疏回归方法，这种方法通过在支配动力学上进行功能性干预来量化操作层面的必要性。研究的目标是在嘈杂、冗余和数据稀缺的情况下，一致地从神经代理中恢复支配算子，并在结构准确度方面优于标准的物理感知神经网络(PINNs)和DeepONets。理论证明在受限等距或互相关条件下可以精确恢复因果操作支持，且残差界确保了可识别性。实验在气候动力学、肿瘤扩散和海洋流动等合成和真实世界数据集上验证了该框架的有效性，方法提供了更佳的结构准确度。该工作将因果PDE发现定位为一个具备结构因果模型和变分残差分析基础的可解决和可解释的推断任务。
## Innovation
本文提出的方法通过物理感知神经网络和反事实扰动来发现偏微分方程中的因果结构，通过功能性干预支配动力学来量化操作层面的必要性，并引入因果灵敏度指数和结构偏差度量来评估候选微分算子的影响。理论分析证明了在受限制条件下的因果算子精确恢复，并确保了可识别性。实验结果表明，该方法在噪声、冗余和数据稀缺的情况下仍然可以一致地从神经代理中恢复支配算子，与标准PINNs和DeepONets相比，在结构准确度方面表现出更优的效果。
## Conclusion
本文的方法展示了在嘈杂、冗余和数据稀缺的情况下，通过物理感知神经网络和反事实扰动发现偏微分方程中因果结构的可行性和优越性，将因果PDE发现定位为一个可解决和可解释的推断任务。
# 448. `cs.LG` - 使用机器学习方法生成的能量消费者时间序列替代数据，用于长期内预测场景 [PDF](https://arxiv.org/pdf/2506.20253), [HTML](https://arxiv.org/abs/2506.20253)
## Authors
Ben Gerhards,Nikita Popkov,Annekatrin König,Marcel Arpogaus,Bastian Schäfermeier,Leonie Riedl,Stephan Vogt,Philip Hehlert
## Background
电力价值链中的预测吸引了大量研究关注。大多数研究集中在发电或消费的短期预测上，侧重系统而非个人消费者。个人电力消耗的长期预测则遭忽视。本研究通过比较数据驱动方法生成个性化电力消耗长期预测所需的高保真合成数据，填补了这一空白。提供了针对电力消费长期预测生成高保真合成时间序列方法的深入对比评价。这些合成数据对于电力系统状态估计或电网规划等应用至关重要。
## Innovation
本研究评估并比较了多个最新的但较少使用的技术：混合Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔可夫模型（HMM）和掩蔽自回归伯努利多项式归一化流（MABF）。每个方法在复制个体能源消耗的时间动态、长距离依赖和概率转换方面的能力得到了分析，并通过对比评估突出了WGAN、DDPM、HMM和MABF的优势和限制，以指导选择最适合的状态估计等与能源相关任务的技术。此外，确保数据生成和分析框架提高了合成电力消耗数据的准确性和可靠性，同时保护了隐私。
## Conclusion
本研究利用了来自德国家庭的开源数据集，以15分钟的分辨率生成的合成电力消耗资料可以直接应用于状态估计或消费预测等应用。这些合成数据的使用有助于提升能源领域的数据质量和分析结果的可靠性，同时也能更好地保护个人隐私。
# 449. `cs.LG` - 比较分析用于作物病害检测的深度学习模型：迁移学习方法 [PDF](https://arxiv.org/pdf/2506.20323), [HTML](https://arxiv.org/abs/2506.20323)
## Authors
Saundarya Subramaniam,Shalini Majumdar,Shantanu Nadar,Kaustubh Kulkarni
## Background
本文研究了一种基于人工智能（AI）的作物疾病检测系统，旨在帮助资源有限的农村地区农民。研究者比较了不同的深度学习模型，并专注于它们在迁移学习中的有效性。通过使用包括EfficientNet、ResNet101、MobileNetV2以及自定义CNN等深度学习模型，该系统能够有效分类植物疾病。这些模型共同展示了在农业实践中应用迁移学习的潜力，提高了作物健康管理和支持可持续农业的作用。
## Innovation
采用了EfficientNet、ResNet101、MobileNetV2以及自定义CNN等不同的深度学习模型进行作物疾病检测，特别是在迁移学习方面的比较分析，强调了这些模型在提高作物健康管理和支持可持续农业方面的潜力。
## Conclusion
通过深度学习模型的有效应用，所开发的系统能够在帮助农民进行作物疾病检测方面取得显著成效，证明了迁移学习在农业实践中的重要性。同时，这种系统能够支持农村地区的可持续农业发展，提高作物健康管理水平。
# 450. `cs.LG` - 学习中度输入敏感函数：QR码解码案例研究 [PDF](https://arxiv.org/pdf/2506.20305), [HTML](https://arxiv.org/abs/2506.20305)
## Authors
Kazuki Yoda,Kazuhiko Kawamoto,Hiroshi Kera
## Background
函数学习的难度与其输入敏感性有关。图像分类等任务输入不敏感，而算术和符号计算等任务输入高度敏感。本研究关注输入敏感性适中的函数学习，并以基于Transformer的QR码解码为例进行探讨。
## Innovation
研究首次利用学习方法进行基于快速响应（QR）码的解码，并展示了Transformer能够成功解码QR码，甚至超越理论上的纠错极限。此外，它还从英文丰富的训练数据推广到其他语言和随机字符串。研究认为，基于Transformer的QR码解码器更多关注数据位而非纠错位，这与标准QR码读取器的机制有所不同。
## Conclusion
该研究证明，基于学习的方法可以应用于高度输入敏感的任务，如QR码解码。Transformer在解码QR码时依赖于数据结构的学习，这为输入敏感任务的自动化处理提供了新的视角。
# 451. `cs.LG` - 有限演示中的超越专家表现：双重探索的高效模仿学习 [PDF](https://arxiv.org/pdf/2506.20307), [HTML](https://arxiv.org/abs/2506.20307)
## Authors
Heyang Zhao,Xingrui Yu,David M. Bossens,Ivor W. Tsang,Quanquan Gu
## Background
模仿学习是强化学习中的一个核心问题，目标是学习一个能够模仿专家行为的策略。然而，由于状态空间的复杂性，在有限示范的情况下精确学习专家策略往往具有挑战性。此外，为超越专家的性能，还需要探索环境并收集数据。
## Innovation
提出了一个新的模仿学习算法叫做双重探索的模仿学习（ILDE），它在两个方面实现探索：1）通过探索奖金进行乐观策略优化，奖励具有高不确定性的状态-动作对，以提高到专家策略的收敛性；2）通过好奇心驱动探索与示范轨迹偏差的状态，以获得超越专家的性能。实验结果显示，ILDE 在样本效率上优于现有的模仿学习算法，并且在使用较少示范的情况下，在 Atari 和 MuJoCo 任务上达到了超越专家的性能。此外，理论验证了 ILDE 作为一种带有乐观探索的不确定性正则化策略优化方法，导致后悔的增长呈亚线性增长。
## Conclusion
ILDE 在样本效率方面表现优于现有的模仿学习算法，在 Atari 和 MuJoCo 任务中使用较少示范的情况下实现了超越专家的表现，并且通过理论验证了 ILDE 的优越性。
# 452. `cs.LG` - Q-resafe：评估安全风险和量化感知的安全修补方法以增强量化大型语言模型的安全性 [PDF](https://arxiv.org/pdf/2506.20251), [HTML](https://arxiv.org/abs/2506.20251)
## Authors
Kejia Chen,Jiawen Zhang,Jiacong Hu,Yu Wang,Jian Lou,Zunlei Feng,Mingli Song
## Background
量化大型语言模型（LLMs）在资源受限环境中得到了越来越多的关注。然而，最新的研究表明，无需校准数据集的量化方法可能会损害LLMs的安全能力，这突显了系统性安全评估和有效缓解策略的迫切需要。在现有的量化技术中，安全能力得到了广泛认可的基准测试，本文进行了全面的安全评估。这些评估被用于多种主流量化技术，并使用了不同的校准数据集以确保测试的一致性和全面性。
## Innovation
在本文中，我们提出了一个量化感知的安全修补框架Q-resafe，旨在有效地恢复量化LLMs的安全能力，同时最小化对效用的负面影响。Q-resafe框架最大程度地减少了由于量化而导致的安全风险，并成功地重新调整了量化LLMs的安全性，使其与未进行量化处理的版本保持一致，即使是在具有挑战性的评估场景下
## Conclusion
通过广泛的实验结果证明了Q-resafe的成功，它成功地重新调整了量化LLMs的安全性与它们量化之前的版本的一致性，为实用性和安全性提供了有效的平衡解决方案。
# 453. `cs.LG` - Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning [PDF](https://arxiv.org/pdf/2506.20324), [HTML](https://arxiv.org/abs/2506.20324)
## Authors
Torben Berndt,Benjamin Walker,Tiexin Qin,Jan Stühmer,Andrey Kormilitzin
## Background
动态图表现出复杂的时空动态性，由于节点特征和网络结构的变化互相关联。Graph Neural Controlled Differential Equations (Graph Neural CDEs) 成功地将 Neural CDEs 从欧式域上的路径扩展到了图域上的路径。然而，需要降低模型参数数量而不牺牲表征能力以提高训练效率和泛化能力。
## Innovation
引入了Permutation Equivariant Neural Graph CDEs，通过将Graph Neural CDEs投影到置换等变函数空间中，显著减少了模型参数数量而不会降低表征能力，从而提高了训练效率并增强了泛化能力。该方法在模拟动力系统和实际任务中表现出了在插值和外推场景中的优越性。
## Conclusion
通过实验验证了该方法在动态图表示学习中的有效性和优越性，为复杂动态图数据分析提供了一种更为高效的方法。
# 454. `cs.LG` - 生产者公平性在序列型组合推荐中的应用 [PDF](https://arxiv.org/pdf/2506.20329), [HTML](https://arxiv.org/abs/2506.20329)
## Authors
Alexandre Rio,Marta Soare,Sihem Amer-Yahia
## Background
该研究针对序列性组合推荐场景中的公平性问题，用户按顺序接收相关和兼容的项目集合。研究动机来源于实际场景，旨在解决不同项目组在推荐会话中不同用户曝光的均衡问题。这种方法自然地与构建高质量组合捆绑相契合，在用户到达时进行实时解决。研究人员提出了针对小型实例的精确解决方案，并探讨了优先选择质量或公平性的两种启发式方法，以及一种适应性变体来动态平衡捆绑公平性和质量。
## Innovation
研究提出了一种精确解决方案，针对小型问题实例，还探讨了基于质量和公平性的两种启发式方法，以及一种动态确定捆绑公平性与质量平衡的适应性变体。此外，通过三个真实数据集进行了实验，以验证每种解决方案的优缺点及其在不牺牲捆绑质量的情况下提供公平捆绑推荐的有效性。
## Conclusion
实验结果显示，每种解决方案都具有各自的优点和局限性，但它们均在不损害捆绑质量的前提下成功地提供了公平的捆绑推荐。
# 455. `cs.LG` - FedBKD：拥抱非IID数据上的泛化和个性化的蒸馏联邦学习 [PDF](https://arxiv.org/pdf/2506.20245), [HTML](https://arxiv.org/abs/2506.20245)
## Authors
Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu
## Background
联邦学习（FL）是一种去中心化的机器学习协作技术，旨在解决工业实践中孤立数据岛和数据隐私泄露的问题。然而，处理非同质独立数据（non-IID数据）仍然是一个主要挑战。当前的解决方案要么专注于构建全能的全局模型，要么定制个性化的本地模型。很少有方法能够同时提供具有良好泛化能力的全局模型和性能良好的本地模型。此外，许多针对非-IID问题的FL解决方案依赖公共数据集，这增加了数据泄露的风险。因此，需要一种新的方法来处理这些问题。
## Innovation
本文提出了一种新颖的数据免费蒸馏框架，即Federated Bidirectional Knowledge Distillation（FedBKD），用于处理非-IID数据。具体而言，作者训练生成对抗网络（GAN）生成合成数据，在GAN训练过程中，本地模型用作判别器并且参数固定。合成数据用于实现全局和本地模型之间的双向蒸馏，实现知识交互，从而提高双方的表现。通过在4个基准上进行的不同非-IID设置下的广泛实验表明，FedBKD在所有情况下均实现了当前最佳性能（SOTA）.
## Conclusion
实验结果表明，FedBKD在不同非-IID数据设置下的性能均达到了当前最佳水平，展示了其在联邦学习中同时提高全局和本地模型性能的能力。
# 456. `cs.LG` - DipSVD: 双重要性保护的SVD压缩方法用于高效的大型语言模型压缩 [PDF](https://arxiv.org/pdf/2506.20353), [HTML](https://arxiv.org/abs/2506.20353)
## Authors
Xuan Ding,Rui Sun,Yunjian Zhang,Xiu Yan,Yueqi Zhou,Kaihao Huang,Suzhong Fu,Chuanlong Xie,Yao Zhu
## Background
由于大型语言模型（LLMs）不断增加的计算需求和部署成本，引发了多种压缩方法的探索。与量化和无结构剪枝相比，基于SVD的压缩方法在硬件兼容性和理论保障方面更胜一筹。然而，现有的基于SVD的方法主要关注原始矩阵和压缩矩阵的整体差异，忽视了对矩阵中关键组件的保护，导致压缩模型的性能较差。
## Innovation
本文提出了一个双层重要性保护机制来提升基于SVD的压缩方法：(1) 局部重要性保护：通过逐通道加权数据去相关保留每个权重矩阵中最重要的奇异向量；(2) 全局重要性保护：通过启发式或优化方法使不重要的层承担更多的压缩负担，从而最小化压缩对关键层的影响。实验结果表明，DipSVD方法在多个基准测试中优于现有的基于SVD的压缩方法，特别是在高模型压缩比的情况下，模型性能更优。
## Conclusion
实验结果证明了DipSVD在多种评估基准上的优越表现，尤其是在高压缩比例下，比现有基于SVD的压缩方法实现了更好的模型性能。
# 457. `cs.LG` - TESSERA: 时间地表光谱的时序嵌入用于地球表示和分析 [PDF](https://arxiv.org/pdf/2506.20380), [HTML](https://arxiv.org/abs/2506.20380)
## Authors
Zhengpeng Feng,Sadiq Jaffer,Jovana Knezevic,Silja Sormunen,Robin Young,Madeline Lisaius,Markus Immitzer,James Ball,Clement Atzberger,David A. Coomes,Anil Madhavapeddy,Andrew Blake,Srinivasan Keshav
## Background
卫星遥感 (RS) 可用于多种地球观测（EO）应用，包括气候建模、碳核算和确保可持续土地利用的战略。传统的 RS 基础模型通常依赖于人工特征提取或特定任务的模型，使得获取高精度、高分辨率的表示受限于数据和计算资源。
## Innovation
TESSERA 是一种新型遥感基础模型（RSFM），利用自我监督学习（SSL）从像素级卫星时间序列数据中生成全球稳健表示。TESSERA 采用两个并行的变压器编码器分别处理 Sentinel-1 SAR 极化和 Sentinel-2 MSI 的 10 个选定光谱带数据，并使用多层感知器 (MLP) 将这些表示融合，生成 2017 年到 2024 年的全球表示图。TESSERA 通过预计算的表示设定新的性能基准，其开源方法使高性能、高分辨率的表示更容易获取。
## Conclusion
TESSERA 在五个不同的任务中进行了基准测试，对比了基于任务的最先进模型和其他基础模型。结果显示，TESSERA 在这些多样化下游任务中均优于传统 RS 基线模型和领先的地理空间基础模型。
# 458. `cs.LG` - 向解释性和高效特征选择迈进：轨迹数据中的分类方法 [PDF](https://arxiv.org/pdf/2506.20359), [HTML](https://arxiv.org/abs/2506.20359)
## Authors
Chanuka Don Samarasinghage,Dhruv Gulabani
## Background
轨迹分析不仅包括获取运动数据，还涉及到通过时间和空间理解物体运动模式，以及预测其下一步行为。由于该领域的高度兴趣，数据收集大幅改进，产生了大量可用于训练和预测模型的特征。然而，这导致了特征爆炸问题，高维度使得数据效率和可解释性降低，进而影响了机器学习模型的准确性。为解决这个问题，特征选择已经成为最常用的方法之一。因此，论文提出了基于分类的特征选择方法，根据特征的内在结构对其分类，标记为几何和运动特征，并进一步细分为曲率、凹痕、速度和加速度。这种方法在比较分析中表现出了一致的或优越的预测性能。此外，由于分类组合理论空间的减少，特征选择所需的时间显著减少。并且，分类也被用来深入了解针对每组数据需要注意哪些特征集。
## Innovation
提出了一种基于分类的特征选择方法，将特征按照其内部结构进行分类，进一步划分为几何和运动特征，再细分为曲率、凹痕、速度和加速度。该方法在预测性能上表现出一致或优越的结果，并且能够显著减少特征选择所需的计算时间。此外，该方法还提供了关于每个数据集敏感特征的见解，从而增强了数据的可解释性，降低了维度复杂性和计算复杂性，支持高级决策。
## Conclusion
研究表明，基于分类的特征选择方法不仅增加了可解释性，并且通过减少维度和计算复杂性，促进了高阶决策。该研究为处理轨迹数据的方法论框架提供了一个步骤，同时也对可解释的人工智能领域做出了贡献。
# 459. `cs.LG` - 具备多变量并行注意力的生成基础模型以生成神经活动 [PDF](https://arxiv.org/pdf/2506.20354), [HTML](https://arxiv.org/abs/2506.20354)
## Authors
Francesco Carzaniga,Michael Hersche,Abu Sebastian,Kaspar Schindler,Abbas Rahimi
## Background
在临床领域如颅内脑电图（iEEG）中，深度神经网络（DNNs）处理具有异构通道配置的多变量时间序列数据仍是一个主要挑战。由于不同受试者的通道设置差异极大，需要一种能够灵活、通用且高效地建模时间序列数据的方法。本文针对这一问题介绍了多变量并行注意力（MVPA），这一新机制能够分离内容、时间和空间注意力，使模型能够在不同的通道数量和配置下有效地处理时间序列数据。本文使用MVPA构建了MVPFormer，这是一种用于人类电生理学的生成基础模型，被训练用于预测不同受试者的iEEG信号演变。为支持此类研究，本文还发布了迄今为止最大的公开iEEG数据集——SWEC iEEG数据集，包含近10,000小时的异构临床数据记录。
## Innovation
本文提出了多变量并行注意力（MVPA），这是一种新型的自注意力机制，具备分离内容、时空注意力的能力，能够灵活、通用且高效地建模不同通道数量和配置的时间序列数据。基于MVPA，本文构建了MVPFormer，这是一种用于预测iEEG信号演变的生成基础模型。MVPFormer能够出色地适应不同的受试者，展现出在癫痫检测方面的专家级表现，并在SWEC、MAYO和FNUSA数据集上优于最先进的Transformer基线。同时，MVPA也验证了其在标准时间序列预测和分类任务上的性能，与现有的基于注意力的模型相当或更优。
## Conclusion
本文的贡献在于将MVPA确立为一种适用于异构时间序列的通用注意力机制，并将MVPFormer确立为首款具有最佳临床性能的开放源代码、开放权重、开放数据的iEEG基础模型。
# 460. `cs.LG` - Argumentative Ensembling for Robust Recourse under Model Multiplicity [PDF](https://arxiv.org/pdf/2506.20260), [HTML](https://arxiv.org/abs/2506.20260)
## Authors
Junqi Jiang,Antonio Rago,Francesco Leofante,Francesca Toni
## Background
在机器学习中，同一个预测任务可能会得到多个具有相同表现的模型，特别是在使用不同的随机种子训练神经网络时。在这种模型多过的情况（MM）下，这些竞争模型对同一个输入的预测可能会不同，通常会使用集成方法来决定输出的聚合。然而，在模型多过的情况下，基于反事实解释（CE）提供可回溯建议变得复杂，因为CE可能不适用于所有模型，即CE在模型多过的情况下缺乏鲁棒性。因此，本文研究了在模型多过的情况下提供可回溯建议的问题，即所谓的“可回溯意识集成”（RAE），并提出了相应的解决方案。
## Innovation
本文提出了一个解决在模型多过情况下提供可回溯建议的新颖方法——基于论证的集成方法。该方法利用计算论证来明确表示模型和反事实之间关于预测结果和CE有效性冲突的关系，并使用论证语义来解决这些冲突，从而获得最终解决方案。此外，该方法还允许指定模型之间的偏好，以进一步自定义集成。作者通过理论分析和实证研究验证了该方法的有效性，并证明了该方法在满足所需属性方面具有广泛的灵活性。
## Conclusion
本文形式化了在模型多过情况下提供可回溯建议的问题，并提出了一个确保CE在模型多过情况下鲁棒性的新型论证集成方法。该方法通过解决模型和反事实之间的预测结果和CE有效性的冲突，同时考虑每个模型的CE和预测，来决定联合预测和可回溯建议。通过对四种不同论证语义的理论分析，以及八个具体方法实例的实证研究，证明了该方法的有效性和灵活性。
# 461. `cs.LG` - 基于频域自举和拉普拉斯基增强的自监督图学习 [PDF](https://arxiv.org/pdf/2506.20362), [HTML](https://arxiv.org/abs/2506.20362)
## Authors
Lorenzo Bini,Stephane Marchand-Maillet
## Background
近年来，图神经网络在各个领域取得了显著进展，但大多数自监督图学习方法需要依赖于负样本采集和手工构建的增强策略。这些方法增加了实现的复杂性，并且限制了模型的可扩展性和效率。LaplaceGNN提供了一种新的路径，通过利用频谱自举技术避免了负样本的需要，并通过拉普拉斯基信号增强学习过程，进而有效地捕捉丰富的图结构表示，而不需要依赖对比学习目标或手工增强策略。这种方法不仅提高了效率，还适用于多种应用场景。
## Innovation
LaplaceGNN的创新点在于通过最高最小中心性指导优化预计算频域增强，从而实现结构丰富的监督学习，避免了手工构建增强策略。此外，采用对抗自举训练方案进一步加强了特征学习和模型鲁棒性。这些改进使得LaplaceGNN能够在线性缩放情况下，为图神经网络提供一种更简单、更高效的自监督替代方法，同时也展示了其在不同的基准数据集上的优越性能。
## Conclusion
通过广泛的实验评估，LaplaceGNN展示了与当前最先进的自我监督图方法相比，它在学习表达性强的图表示方面的优越性能。这为高效学习图表示提供了极具前景的方向。
# 462. `cs.LG` - 未来非平稳环境下离线评估与学习 [PDF](https://arxiv.org/pdf/2506.20417), [HTML](https://arxiv.org/abs/2506.20417)
## Authors
Tatsuhiro Shimizu,Kazuki Kawamura,Takanori Muroi,Yusuke Narita,Kei Tateno,Takuma Udagawa,Yuta Saito
## Background
研究了一个新颖的问题——未来离线评估（F-OPE）和学习（F-OPL），旨在估计和优化非平稳环境下的策略未来价值。非平稳环境指分布随时间变化，现存的方法通常假设平稳性，依赖于限制性的奖励模型假设，这会引入显著的偏差。鉴于这种情况，本研究关注于利用时间序列数据的相关结构来准确估计未来任意时间点的策略价值。在电子商务推荐系统中，目标往往是在上个月使用旧策略收集的数据来估计和优化下个月的策略价值。然而，历史数据中可能无法找到未来环境的数据，成为一个关键挑战。
## Innovation
提出了一个名为‘OPFV’（Off-Policy Estimator for Future Value）的新型估计算法，该算法能够利用时间序列数据中的有用结构。OPFV通过一种新的重要性加权方法有效利用时间相关的结构，从而实现了在非平稳环境下实现未来策略价值的离线评估。此外，还扩展了OPFV算法，提出了一种新的基于历史数据学习未来策略的方法。该方法在各种实验设置下表现出了对未来策略值估计和优化方面的显著性能优越性，相较于现有方法有明显改善。这是首个利用时间结构进行未来策略价值估计的方法，并通过理论分析识别了OPFV低偏差的情况。
## Conclusion
通过OPFV算法，能够准确估计非平稳环境下未来的策略价值。结合两种方法，开发了一种新的策略学习方法，仅使用历史数据就能有效学习未来策略，并大幅提高了策略价值的估计和优化性能。
# 463. `cs.LG` - 从聚类联邦学习中提炼通用专家 [PDF](https://arxiv.org/pdf/2506.20285), [HTML](https://arxiv.org/abs/2506.20285)
## Authors
Zeqi Leng,Chunxu Zhang,Guodong Long,Riting Xia,Bo Yang
## Background
现有的联邦学习（FL）方法在处理非同态异构（non-IID）数据时，往往忽视了不同聚类之间的共享信息。这些共享信息代表了跨参与者具有普适性的知识，但在传统方法中常常被忽略，这成为了现有方法的一个局限。Clustered Federated Learning (CFL)通过训练多个聚类特定的专家模型来应对非同态数据带来的挑战，但仍然存在忽视共享信息的问题。
## Innovation
本文提出了一个创新的联邦学习框架，旨在从多个聚类的知识中提炼出一个通用的专家模型，并将其作为下一轮模型训练的初始化。该框架通过三个迭代步骤运作：（1）每个客户端进行本地模型训练，（2）聚类特定模型聚合，（3）通用专家提炼。这种方法增强了细粒度的非同态特征保持，同时有效整合了跨聚类的共享知识。相比传统的基于梯度的聚合方法，基于提炼的模型聚合方法更灵活地处理模型异构性，并减少聚类特定专家之间的冲突。
## Conclusion
实验结果表明，所提出的方法在各种场景下均表现出优越性能，突出其在平衡个性和共享知识方面的能力，有可能推动聚类联邦学习（CFL）的进步。
# 464. `cs.LG` - 多变量时间序列数据中深度神经网络学习Granger因果关系的能力 [PDF](https://arxiv.org/pdf/2506.20347), [HTML](https://arxiv.org/abs/2506.20347)
## Authors
Malik Shahid Sultan,Hernando Ombao
## Background
Granger因果关系（GC）提供了一种优雅的统计框架来研究多变量时间序列数据之间的关联。线性向量自回归模型（VAR）虽然具有很好的解释性，但由于对可捕获的关联类型的假设限制了其实际应用。已有大量文献尝试利用深度神经网络（DNNs）的函数逼近能力来估计GC，但这些方法通常将GC视为一个变量选择问题。该研究提出了一个新的方法，即GC实际上与预测有关。如果使用深度学习模型联合或集体建模时间序列，且有足够的训练数据，一个正则化的模型可能从数据中学习到真实的Granger因果结构。研究通过对比使用所有历史数据和移除特定时间序列组件后的模型不确定性或残差分布来揭示学习到的GC结构，并且还比较了输入层 dropout 对模型从数据中学习GC能力的影响。研究结果显示，一个正则化的模型实际上可以从数据中学习到真实的GC结构，而无需在损失函数中显式添加引导模型选择变量或进行稀疏回归的项。
## Innovation
提出了一个新颖的方法，即GC实际上与预测有关。通过对比使用所有历史数据和移除特定时间序列组件后的模型不确定性或残差分布来揭示学习到的GC结构，展示了正则化的模型可以从数据中自动学习到真实的Granger因果结构，而无需在损失函数中显式添加引导选择变量或进行稀疏回归的项。此外，比较了输入层 dropout 对模型从数据中学习GC能力的影响。
## Conclusion
通过正则化的深度学习模型，可以从多变量时间序列数据中自动学习到真实的Granger因果结构，而无需在损失函数中显式添加引导选择变量或进行稀疏回归的项。
# 465. `cs.LG` - 客户聚类与知识共享：增强个性化对等学习的隐私性和鲁棒性 [PDF](https://arxiv.org/pdf/2506.20413), [HTML](https://arxiv.org/abs/2506.20413)
## Authors
Mohammad Mahdi Maheri,Denys Herasymuk,Hamed Haddadi
## Background
随着人工智能（AI）在物联网（IoT）生态系统中的广泛应用，越来越需要高效的、私有的个性化学习方法，这些方法可以在多种资源受限设备上运行。但这种方法在分散式设置中实现效率个性化学习时，带来了包括高效的知识转移、保护数据隐私和抵御中毒攻击等多种挑战。
## Innovation
本文通过开发P4（个性化、私有、对等）方法，解决了上述挑战。P4使用轻量级的完全分布式算法对客户进行私有相似度检测，并形成协作组。组内的客户利用差分隐私的知识蒸馏协同训练模型，既保持了高准确率，又确保了在恶意客户存在时的鲁棒性。试验结果显示，P4相比现有先进的差分隐私对等方法，准确率提升5%-30%，并且在恶意客户占比高达30%的情况下依然表现出鲁棒性。此外，还在资源受限设备上应用P4方法，其协作训练带来的额外开销仅为约7秒
## Conclusion
本研究通过开发P4方案，提出了一个轻量级、完全分布式的方法，该方法能够为资源受限的IoT设备提供个性化模型，同时保证隐私和鲁棒性，并且在实际部署中的开销也非常小。
# 466. `cs.LG` - 基于LLM的表格数据分类中的自动演示选择 [PDF](https://arxiv.org/pdf/2506.20451), [HTML](https://arxiv.org/abs/2506.20451)
## Authors
Shuchu Han,Wolfgang Bruckner
## Background
在应用上下文学习(ICL)进行表格数据分类时，一个基本问题是如何确定提示中所需演示的合理数量。本文探讨了这一问题，并提出了一种算法，可以自动选择所需的合理数量的演示。该方法不仅考虑表格数据的分布，还结合用户的提示模板和特定的大规模语言模型（LLM）进行估计。基于谱图理论，本文提出了一种新的度量方法来量化不同演示之间的相似度，并通过构建相似度图和分析Laplacian的特征值来推导出能够在LLM的内在表示空间中表示数据的最小演示数量。研究通过与传统随机选择算法在多种数据集和LLM上的实验对比，验证了该方法的有效性。
## Innovation
该工作通过结合谱图理论，提出了一种新的度量方法来量化不同演示之间的相似度，并通过分析Laplacian的特征值来推导出所需的最小演示数量。该算法不仅考虑了表格数据的分布，还整合了用户的提示模板和特定的大型语言模型。
## Conclusion
实验结果表明，该方法在多种数据集和大语言模型上都表现出优于传统随机选择算法的效果，验证了该方法的有效性。
# 467. `cs.LG` - 基于残差 Hessians 的 PINNs 积分求积方法 [PDF](https://arxiv.org/pdf/2506.20441), [HTML](https://arxiv.org/abs/2506.20441)
## Authors
Antoine Caradot,Rémi Emonet,Amaury Habrard,Abdel-Rahim Mezidi,Marc Sebban
## Background
物理规范神经网络（PINNs）通过在损失函数中嵌入物理模型并在所谓的插值点上使用自动微分最小化其残差，已经成为学习偏微分方程（PDEs）的替代神经求解器的一种有效方法。最初均匀采样，插值点的选择有了最近的研究进展，发展出了适应性采样细化方法。这项研究提出了一个新的基于考虑函数 Hessian 的积分近似方法，用这种方法引导 PINNs 训练过程中插值点的选择。
## Innovation
提出了一种新的基于函数残差 Hessian 的积分近似方法，并将其应用于指导 PINNs 训练过程中插值点的选择，提升了 PINNs 的效率和准确性。
## Conclusion
本文提出的方法为 PINNs 的训练过程提供了一种新的插值点选择方式，这种方法基于残差函数的 Hessian，不仅简化了传统均匀采样插值点的选择，还能更好地适应复杂物理模型的特性，从而提高 PINNs 的性能。
# 468. `cs.LG` - 作为分布量的反事实影响 [PDF](https://arxiv.org/pdf/2506.20481), [HTML](https://arxiv.org/abs/2506.20481)
## Authors
Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye
## Background
机器学习模型因记忆训练数据样本而闻名，这引起了关于隐私和泛化的问题。反事实自影响是一个流行的度量标准，用以研究记忆现象，量化模型对样本的预测如何根据样本是否包含在其训练数据集中而变化。然而，近期研究表明，记忆不仅受到自影响因素的影响，其他训练样本，特别是（近）重复样本也有重大影响。
## Innovation
本文将反事实影响视为分布量进行研究，考虑了所有训练样本如何影响某个样本的记忆过程。对于一个小语言模型，计算了训练样本之间的完整影响分布，并分析了其特性。研究发现，仅仅看自影响严重低估了记忆带来的实际风险：存在的（近）重复样本大大减少了自影响，但这些样本可以被（近）提取出来。另外，对于图像分类，这种影响分布分析即可揭示CIFAR-10中存在（近）重复样本的情况。
## Conclusion
我们的研究结果表明，记忆来自于训练数据之间的复杂交互，而完整的分布影响比单纯的自影响更能捕捉记忆现象。
# 469. `cs.LG` - 多模态表示学习与融合 [PDF](https://arxiv.org/pdf/2506.20494), [HTML](https://arxiv.org/abs/2506.20494)
## Authors
Qihang Jin,Enze Ge,Yuhang Xie,Hongying Luo,Junhao Song,Ziqian Bi,Chia Xin Liang,Jibin Guan,Joe Yeong,Junfeng Hao
## Background
多模态学习是人工智能领域一个快速发展的方向，旨在通过结合来自不同来源的信息，如图像、文本和音频，帮助机器更好地理解复杂的事物。通过各自模态的优势，多模态学习能够让AI系统建立更强、更丰富的内部表示，从而在真实场景中更好地进行解释、推理和决策。这一领域包括核心的技术，比如表示学习（提取不同类型数据的共享特征）、对齐方法（跨模态匹配信息）和融合策略（通过深度学习模型结合这些信息）。尽管取得了一定的进展，仍面临着一些重要难题，如处理不同的数据格式，应对缺失或不完整的输入，以及防范对抗攻击等挑战。研究人员正探索新的方法，比如无监督或半监督学习、自动机器学习工具，以使模型更加高效和易于扩展。同时，越来越多的关注于设计更好的评估指标或建立共享基准，使其更便于跨任务和跨领域的模型性能比较。
## Innovation
研究人员正探索包括无监督或半监督学习、自动机器学习工具在内的新方法，以提高模型的效率和可扩展性。同时，增加了对构建更好的评估指标的关注，这使得模型的性能在不同任务和领域中具有可比性。
## Conclusion
随着该领域的不断发展，多模态学习有望改善计算机视觉、自然语言处理、语音识别和医疗等多个领域。未来，多模态学习有望帮助构建能够以更加类似人类的方式来理解世界的AI系统，具有灵活性、上下文意识和能够应对现实世界复杂性等特性。
# 470. `cs.LG` - 通过不公平聚集进行知识蒸馏解决联邦学习中的数据异质性问题 [PDF](https://arxiv.org/pdf/2506.20431), [HTML](https://arxiv.org/abs/2506.20431)
## Authors
Xing Ma
## Background
联邦学习旨在在一个接近中心化训练性能的分布式环境中训练全局模型。但是，客户端标签偏斜、数据量偏斜和其他异质性问题严重影响了模型性能。大多数现有方法忽略了只有少量客户端参与大规模客户端环境中的训练场景，而实验表明这一场景对联邦学习构成了更严峻的挑战。
## Innovation
提出了一个针对上述联邦学习环境的知识蒸馏与教师-学生不公平聚合策略（KDIA）策略。该策略要求学生模型为参与客户端的平均聚合，教师模型则是基于三个频率进行加权聚合：参与间隔、参与次数和数据量比例。该策略在本地训练过程中进行自我知识蒸馏，并使用服务器上训练的生成器生成本地近乎独立同分布的（IID）数据特征进行辅助训练。实验表明KDIA在更少的训练轮次中能实现更好的准确率，并且在严重异质性情况下改善效果更为明显。
## Conclusion
所提出的KDIA策略能够利用所有客户端的知识，在具有挑战性的联邦学习环境中实现更好的模型性能。
# 471. `cs.LG` - 协作优化联邦学习中的批次大小 [PDF](https://arxiv.org/pdf/2506.20511), [HTML](https://arxiv.org/abs/2506.20511)
## Authors
Arno Geimer,Karthick Panner Selvam,Beltran Fiz Pontiveros
## Background
联邦学习（FL）是一种在不收集数据至中央位置的情况下，通过去中心化的协作机制训练模型的机器学习框架。它应用于各个领域，如医疗诊断、金融欺诈检测等。参与者之间的硬件资源可共享，但不同参与者由于缺乏信息交流，可能因训练配置不当导致训练过程受阻。利用联邦学习固有的并行处理特性，本文通过贪婪随机搜索优化了所有参与者的本地批次大小，以获得最佳训练设置。
## Innovation
提出了一种贪婪随机搜索方法来优化联邦学习中的本地批次大小，以改进训练配置，加快收敛速度并保持接近最优参数优化的效果。
## Conclusion
与默认参数设置相比，该方法能够显著提高收敛速度，且效果接近于在本地优化参数的情况。
# 472. `cs.LG` - 非正则化REINFORCE在离策略强化学习中的应用：平衡正向与负向奖励 [PDF](https://arxiv.org/pdf/2506.20520), [HTML](https://arxiv.org/abs/2506.20520)
## Authors
Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos
## Background
强化学习(RL)越来越多地用于对大型语言模型(LLMs)进行对齐。离策略方法相比就策略技术提供了更高的实施简便性和数据效率，但往往导致较低的性能。本文研究了离策略RL和监督微调之间的算法范围，通过分析一个简单的离策略REINFORCE算法进行分析，其中优势定义为A = r - V，r代表奖励，V是可调基线。研究表明，在基线V下界预期奖励时，算法具有策略改进保证。理论分析表明，尽管就策略更新可以安全地利用正向和负向信号，但离策略更新更倾向于关注正向奖励而不是负向奖励。研究在可控的随机臂博弈实验中和通过微调最先进的LLMs在推理任务中验证了这些发现。
## Innovation
本文分析了一个简单的离策略REINFORCE算法，并得出了控制优势和基线关系的策略改进保证。研究发现，离策略更新更适合关注正向奖励而不是负向奖励。这些理论分析在实验中通过可控的随机臂博弈和最先进的LLMs在推理任务中的微调得到了验证。
## Conclusion
研究提出了一个简单的离策略REINFORCE算法，并通过理论分析和实验验证了在理想情况下基线不受限于预期奖励时，算法能够提供策略改进保证。实验结果表明离策略更新更加倾向于正向奖励的利用。
# 473. `cs.LG` - WallStreetFeds: 客户特定代币作为联邦学习中的投资工具 [PDF](https://arxiv.org/pdf/2506.20518), [HTML](https://arxiv.org/abs/2506.20518)
## Authors
Arno Geimer,Beltran Fiz Pontiveros,Radu State
## Background
联邦学习（FL）是一种协作机器学习范式，允许参与者集体训练模型同时保持训练数据的私密性。该范式对于金融等重视数据隐私、安全和模型性能的领域特别有益。自2016年引入以来，FL得到了广泛研究，产生了多种高效的合作技术、防止恶意客户端攻击的防御方法以及贡献评价方法。然而，在营利性联邦学习中至关重要的激励机制开发中，特别是关于奖励分配的框架的研究相对较少。因此，现有激励方案存在局限性，这促使学者们寻找新的解决方案。本文提出了一个创新的框架，引入了客户特定代币作为联邦学习生态系统的投资工具，旨在通过利用分散金融（DeFi）平台和自动做市商（AMMs）来改进现有的激励方案，创建更为灵活和可扩展的奖励分配系统，同时也为第三方提供投资联邦学习过程的机制。
## Innovation
本文提出了一种新型框架，首次将客户特定代币作为联邦学习中的投资工具。该框架利用分散金融（DeFi）平台和自动做市商（AMMs）创造一种更为灵活和可扩展的奖励分配系统，不仅满足了盈利性联邦学习中的奖励分配需要，同时也为第三方提供了参与联邦学习过程的投资机会，弥补了现有激励机制的不足。
## Conclusion
该论文提出了一种创新的框架，利用分散金融（DeFi）平台和自动做市商（AMMs）机制，引入客户特定代币作为联邦学习中的投资工具，旨在解决当前联邦学习中奖励分配机制的不足，创建更为灵活和可扩展的奖励分配系统，并提供第三方投资联邦学习过程的机会。
# 474. `cs.LG` - 多变量时间序列无监督异常检测策略基准测试 [PDF](https://arxiv.org/pdf/2506.20574), [HTML](https://arxiv.org/abs/2506.20574)
## Authors
Laura Boggia,Rafael Teixeira de Lima,Bogdan Malaescu
## Background
多变量时间序列在医疗保健、金融服务、制造业或物理检测等领域中是一个重要的问题。准确地识别意外错误或故障发生的时间非常重要，但由于异常的未知性质以及时间序列维度之间的复杂相互依赖关系，这是一项具有挑战性的任务。因此，研究基于变换器的方法来解决时间序列异常检测是一个关键方向。本文集中在近期提出的iTransformer架构上进行探索。
## Innovation
本文的创新点包括：(i) 探索iTransformer在时间序列异常检测中的应用，并分析窗口大小、步长和模型维度等关键参数对性能的影响；(ii) 研究从多维度异常分数中提取异常标签的方法，并讨论此类标签的适当评估标准；(iii) 研究训练期间异常数据的影响，并评估其他损失函数在减轻其影响方面的有效性；(iv) 通过比较几种基于变换器的模型，对众多数据集进行时间序列异常检测的整体比较
## Conclusion
本文全面比较了几种基于变换器的时间序列异常检测模型，并探讨了不同参数的影响以及标签提取方法，旨在提供一个无监督异常检测策略的基准测试框架。
# 475. `cs.LG` - 图索引用于向量搜索的核函数 [PDF](https://arxiv.org/pdf/2506.20584), [HTML](https://arxiv.org/abs/2506.20584)
## Authors
Mariano Tepper,Ted Willke
## Background
目前流行的向量搜索图索引依赖于计算几何原理构建图，从而在欧几里得空间中只有正式的图可导航性保证。然而，这些方法仅适用于欧几里得空间，而对于度量和非度量向量空间（例如内积相似性），其保证无效。
## Innovation
这篇文章提出了使用机器学习构建图索引的方法，特别是引入了Support Vector Graph (SVG)。SVG利用核方法建立图的连接性，并在度量和非度量向量空间中提供有效的可导航性保证。HNSW和DiskANN等流行图索引也被解释为SVG的特化实例，从原理上生成新的索引。此外，提出了一种带有$L_0$稀疏约束的SVG-L0版本，使生成的图具有可管理的出度，并且具有自我调整的特性，减少了计算复杂性。
## Conclusion
SVG及其特化版本SVG-L0为向量搜索提供了一种创新的方法，不仅在欧几里得空间中而且在度量和非度量向量空间中都可保证有效导航，同时解决了实际应用中的出度控制问题，并简化了传统启发式方法。
# 476. `cs.LG` - Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning [PDF](https://arxiv.org/pdf/2506.20623), [HTML](https://arxiv.org/abs/2506.20623)
## Authors
Fariba Jangjoo,Matteo Marsili,Yasser Roudi
## Background
闭合环学习是通过从模型自身生成的数据中反复估计算法模型的过程。由于未来大型神经网络模型可能主要通过自身人工神经网络生成的数据进行训练，这一过程受到了广泛关注。本文研究了属于指数家族模型在闭合环学习过程中的动态行为。
## Innovation
研究了指数家族模型在闭合环学习过程中的动态行为，推导出了参数运动的方程，证明了最大似然估计赋予了充分统计量鞅性质，并讨论了通过污染数据、最大后验估计或正则化来防止收敛于增强初始偏倚的吸收状态的方法。此外，探讨了动态行为的渐近性质不能保持参数重参数不变性的问题。
## Conclusion
指出闭合环学习过程中可能存在的问题，并提出了一些解决方法，同时表明动态行为的渐近性质不是参数重参数不变的。
# 477. `cs.LG` - 探索图变换器的分布外泛化能力 [PDF](https://arxiv.org/pdf/2506.20575), [HTML](https://arxiv.org/abs/2506.20575)
## Authors
Itay Niv,Neta Rabin
## Background
基于图的深度学习在社会网络、生物物理、交通网络和推荐系统等多个应用中取得了显著的成功。尽管这些方法表现良好，但当前方法通常假设训练和测试数据共享相同的分布，而在实际场景中这几乎不会成立。尽管图变换器（GT）在多个内分布（ID）基准测试中优于传统消息传递神经网络（MPNN），但它们在分布迁移下的效果尚未得到充分的研究。因此，本文旨在解决图神经网络的分布外泛化问题，特别是探讨基础架构的影响。研究者系统评估了GT及其混合模型在分布外设置中的表现，并将其与MPNN进行比较，通过引入几种领先的领域泛化（DG）算法来完成评估。结果表明，即使没有专门的DG算法，GT和混合GT-MPNN架构也展现出了更强的泛化能力。此外，还提出了一种新的后训练分析方法，以比较整套ID和OOD测试数据集的聚类结构，特别是评估域对齐和类别分离。这种方法不仅是模型无偏的，还为图学习之外的领域泛化问题提供了更广泛的应用前景，并超越了标准准确性指标，提供了更深入的泛化能力洞察。
## Innovation
本文创新地使用图变换器（GT）和其混合架构（GT-MPNN）针对分布外（OOD）泛化进行评估，并通过多种领域能化的算法（DG）来提升模型的泛化能力，尤其是针对GT和MPNN架构的比较与分析。同时，提出了一种新的后训练分析方法，用于比较整个ID和OOD测试数据集的聚类结构，评估域对齐和类别分离，揭示了GT和混合架构在泛化能力上的优势，为实际应用提供了新的方向。
## Conclusion
研究结果表明，图变换器（GT）和混合GT-MPNN架构在分布外泛化上表现出更强的能力，无需特殊的领域泛化算法即可实现较好的效果。此外，提出的新方法不仅为GT和MPNN架构提供了有益的见解，还显示出其在领域泛化问题中的广泛应用前景，有助于更深入地理解模型的泛化能力。该研究为实际场景中图神经网络的稳健性和有效性提供了新的研究方向。
# 478. `cs.LG` - 掌握多专家调度：实现 $H$ 坏贯性及其强大的学习保证 [PDF](https://arxiv.org/pdf/2506.20650), [HTML](https://arxiv.org/abs/2506.20650)
## Authors
Anqi Mao,Mehryar Mohri,Yutao Zhong
## Background
多专家决策问题涉及将输入实例最优地分配给专家，平衡其准确性和计算成本之间的权衡。这一挑战在自然语言生成中尤为重要，同时也出现在图像处理、医学诊断等其他领域。近期研究提出了代理损失函数来优化推迟学习，但仍存在确保其一致性的挑战。
## Innovation
本文引入了新型代理损失函数和高效算法，并提供了强有力的理论学习保障。针对单阶段和两阶段推迟学习场景，分别解决了可实现 $H$-连贯性、$H$-连贯性界限和贝叶斯连贯性等问题，提出了全新的代理损失函数，并证明了特定成员的一系列连贯性特性。在低噪声假设下，提供了两种场景下更好的理论保证。
## Conclusion
实验结果表明，提出的代理损失函数在性能上优于现有基准。
# 479. `cs.LG` - 工业数字孪生生成数据集与高效数据增强的能源分解 [PDF](https://arxiv.org/pdf/2506.20525), [HTML](https://arxiv.org/abs/2506.20525)
## Authors
Christian Internò,Andrea Castellani,Sebastian Schmitt,Fabio Stella,Barbara Hammer
## Background
工业不可侵入负载监控(NILM)受到高质量数据稀缺和工业能耗模式复杂多变的限制。为解决数据稀缺和隐私问题，本文提出了基于数字孪生仿真的合成工业能源分解数据集(SIDED)，包括跨三个地理区域的三种类型的工业设施，反映了多样化的家电行为、天气状况和负载特性。此外，还提出了基于设备影响智能调整的设备调节数据增强方法(AMDA)，通过计算高效的手段增强NILM模型的泛化能力，特别是在处理复杂工业设备的能效分解上表现突出。
## Innovation
引入了基于数字孪生仿真的合成工业能源分解数据集(SIDED)，加入了设备调节数据增强方法(AMDA)，通过智能化调整设备功率贡献来增强模型的泛化能力。实验证明，AMDA可以显著提高复杂工业设备能效分解的准确性。
## Conclusion
通过AMDA增强的ILNM模型在复杂工业负载，例如热电联供系统上的能效分解表现更为优异。具体而言，在测试样本外的表现中，使用AMDA的数据训练的模型取得了0.093的归一化分解误差，优于未使用数据增强(0.451)和随机数据增强(0.290)训练的模型。数据分析表明，AMDA有效调整了训练集和测试集的数据分布，从而提升了模型的泛化能力。
# 480. `cs.LG` - 队列控制中的有限时间信息论边界 [PDF](https://arxiv.org/pdf/2506.18278), [HTML](https://arxiv.org/abs/2506.18278)
## Authors
Yujie Liu,Vincent Y. F. Tan,Yunbei Xu
## Background
在随机加工网络中的调度问题中，现有分析方法只能保证在重负荷状态下系统的稳定性和渐近最优性；然而，在有限时间范围内，MaxWeight策略可能会因为问题参数的不同而遭受更大的积压，其积压可能会显著增加。
## Innovation
本文的主要创新点包括：1) 构建的极小极大框架，准确识别任何策略在有限时间范围内的准确问题参数；2) 提出了总队列长度的信息论下界；3) 指出MaxWeight在有限时间内是次优的；4) 提出了新的调度规则，通过最小化包括二次项在内的完整Lyapunov漂移，能够在一定条件下匹配下界，直至普遍常数。这些发现揭示了“仅漂移”方法的基本局限，并指出了基于无偏渐近渐近最优性的原理性方法的方向。
## Conclusion
这些成果揭示了仅漂移方法的基本局限，并为在排队控制中实现有原则的、非渐近最优性指明了方向。
# 481. `cs.LG` - 利用FEM模拟预测皮肤粘附界面剥离力的神经网络 [PDF](https://arxiv.org/pdf/2506.19855), [HTML](https://arxiv.org/abs/2506.19855)
## Authors
Ashish Masarkar,Rakesh Gupta,Naga Neehar Dingari,Beena Rai
## Background
研究皮肤上粘合剂的剥离行为对于促进医疗粘合剂和经皮贴片等生物医学应用至关重要。传统的测试方法如实验测试和有限元方法（FEM）虽然被认作金标准，但资源密集、计算成本高、耗时长，特别是在分析广泛的材料参数空间时更为突出。
## Innovation
本研究提出了一种基于神经网络的方法来预测粘合剂从皮肤组织剥落所需的最小剥离力（F_min），从而减少重复FEM模拟的需要，并显著降低计算成本。该方法通过利用来自90度剥离测试（参数变化）的FEM模拟数据集进行训练，实现了高准确性，经过严格的5折交叉验证验证。最终模型展示了在测试集上的均方误差MSE为3.66×10^-7，R^2得分为0.94，性能稳健。
## Conclusion
本研究介绍了一种可靠而计算高效的预测粘合剂行为的方法，显著减少了模拟时间，同时保持了准确性。本研究整合了机器学习与高保真生物力学模拟，为皮肤粘合系统的设计和优化提供了有效框架，为未来在计算皮肤力学和生物粘合材料设计中的研究提供了可扩展的框架。
# 482. `cs.LG` - 由有限元分析调控的物理信息机器学习用于激光粉末床熔融模拟加速 [PDF](https://arxiv.org/pdf/2506.20537), [HTML](https://arxiv.org/abs/2506.20537)
## Authors
R. Sharma,M. Raissi,Y.B. Guo
## Background
传统的数值方法，如有限元分析（FEA），在激光粉末床熔融（LPBF）过程中因高昂的计算成本而遇到了持续的问题，因此高效模拟LPBF对于过程预测至关重要。本文旨在通过引入一种新的模型框架来加速LPBF过程中的热场预测，同时保持FEA的准确性。
## Innovation
提出了一种称为FEA-调节的物理信息神经网络（FEA-PINN）的高效建模框架，开发了一种新的动态材料更新策略，以捕捉幂粉-液-固相变过程中的动态变化。该框架通过结合显热容法实现了温度依赖性材料特性和相变行为，通过FEA处理时间依赖性问题中的残差积累，解决计算成本高的挑战。对比分析表明，FEA-PINN在准确性方面与FEA相当，同时显著降低了计算成本。
## Conclusion
FEA-PINN框架在基准FEA数据上进行了验证，并通过LPBF中的单道扫描进行了演示，证明了其性能。
# 483. `cs.LG` - PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models [PDF](https://arxiv.org/pdf/2506.20629), [HTML](https://arxiv.org/abs/2506.20629)
## Authors
Soufiane Hayou,Nikhil Ghosh,Bin Yu
## Background
LoRA 是一种广泛用于大型模型微调的方法。它的低内存占用允许从业者以微调全模型的一小部分成本来将大型模型适应到特定任务。通过设置学习率、秩和初始化等修改，已经有一些方法提升了LoRA的效率。特别是在适配器放置策略方面，LoRA通常适用于模块类型如Query和Key模块，但关于哪种模块类型的适配器放置 strategy 的研究仍然不确定。原论文建议将适配器放置在注意力模块中，而其他研究则建议放置在MLP模块中。
## Innovation
作者提出了一个名为 PLoP 的轻量级方法，该方法能够在给定预训练模型和微调任务的情况下自动识别LoRA适配器应该被放置在哪种模块类型中。实验表明，PLoP 在监督微调和强化学习推理中的一致表现优于常见的放置策略，并且在最坏情况下也能与其竞争。
## Conclusion
研究表明，PLoP 概念及其方法在模型微调中具有显著优势，可以为模型制造商和用户在放置适配器方面提供指导，从而提高模型的性能和效率。
# 484. `cs.LG` - 数据异构边缘设备上的高效加密数据共享联邦学习 [PDF](https://arxiv.org/pdf/2506.20644), [HTML](https://arxiv.org/abs/2506.20644)
## Authors
Hangyu Li,Hongyue Wu,Guodong Fan,Zhen Zhang,Shizhan Chen,Zhiyong Feng
## Background
随着隐私保护变得越来越重要，越来越多的模型被训练在边缘设备上并通过联邦学习（FL）合并到中央服务器中。然而，现有的研究忽视了网络拓扑、物理距离和数据异构性对边缘设备的影响，这导致了如延迟增加和模型性能下降等问题。
## Innovation
为了应对这些问题，作者提出了一种称为FedEDS的新的边缘设备联邦学习方案，它利用客户端模型和模型的随机层来训练数据加密器。数据加密器生成加密数据并与其他客户端共享。客户端使用与之对应的随机层和加密数据来训练和调整本地模型。FedEDS使用客户端的本地私有数据和来自其他客户端的加密共享数据来训练模型，这加速了联邦学习的收敛速度，减轻了数据异构性产生的负面影响，使它适用于需要快速收敛的应用服务部署在边缘设备上。
## Conclusion
实验结果表明，FedEDS在促进模型性能方面是有效的。
# 485. `cs.LG` - 监督相似性与公司联系 [PDF](https://arxiv.org/pdf/2506.19856), [HTML](https://arxiv.org/abs/2506.19856)
## Authors
Ryan Samson,Adrian Banner,Luca Candelori,Sebastien Cottrell,Tiziana Di Matteo,Paul Duchnowski,Vahagn Kirakosyan,Jose Marques,Kharen Musaelian,Stefano Pasquali,Ryan Stever,Dario Villani
## Background
论文介绍了一种新颖的公司联系代理，称为特征向量链接（CVL）。作者利用这一概念通过欧几里得相似性来估算公司联系，并进一步应用量子认知机器学习（QCML）进行相似性学习。研究表明，两种方法都可以用来构建盈利的动量溢出交易策略，但QCML相似性比简单的欧几里得相似性表现更优。
## Innovation
创新在于提出了一种新的公司联系代理——特征向量链接（CVL），并通过两种方法——欧几里得相似性和量子认知机器学习（QCML）进行公司联系的估算。研究显示QCML在相似性学习上优于欧几里得相似性，能够更有效地构建交易策略
## Conclusion
两种方法（欧几里得相似性和QCML相似性）都可以用于构建盈利的动量溢出交易策略，但QCML相似性在实际应用中表现更优。
# 486. `cs.LG` - 聆听无恶：检测联邦学习中恶意服务器的梯度泄漏 [PDF](https://arxiv.org/pdf/2506.20651), [HTML](https://arxiv.org/abs/2506.20651)
## Authors
Fei Wang,Baochun Li
## Background
近期研究表明，联邦学习（FL）中的梯度更新可能会无意中泄露客户端本地数据的敏感信息。当恶意服务器操控全局模型以促使客户端产生信息丰富的更新时，这种风险会进一步增加。本文从防御者的角度出发，首次全面分析了恶意梯度泄露攻击以及使其成为可能的模型操纵技术。研究表明，这些攻击之间存在核心权衡：它们无法同时高度有效地重建私人数据并充分隐蔽以躲避检测，尤其是在包含常见标准化技术与联邦平均的现实FL环境中。因此，本文认为，虽然理论上令人担忧，但恶意梯度泄露攻击在实践中通常受到内在限制且往往可以通过基本监控机制检测到。为补充这一点贡献，本文提出了一种简单、轻量级且广泛适用的客户端检测机制，在本地训练开始之前标记可疑模型更新，即便在现实中这些检测可能并非严格必要。这一机制进一步凸显了以最少的开销防御这些攻击的可行性，为隐私意识强的联邦学习系统提供了一个可部署的安全措施。
## Innovation
本文提供了第一个全面分析恶意梯度泄露攻击及其背后模型操纵技术的研究，提出了简单的客户端检测机制，能够在本地训练开始前标记可疑的模型更新，即使在现实环境中这些检测可能并非严格必要。此外，强调了通过轻量级措施防御这些攻击的可行性。这些机制对于实施和保护隐私至关重要的联邦学习系统具有重要意义。
## Conclusion
虽然恶意梯度泄露攻击在理论上令人担忧，但在实践中通常受限且可检测。本文提出了一种简单的轻量级客户端检测机制，可以在本地训练开始前标识可疑模型更新，进一步强调了在实际环境中采用最小开销防御这些攻击的可行性，并为隐私保护的联邦学习系统提供了有效的安全防护。
# 487. `cs.LG` - 基于真实数据的技能队列中有效UCB路由展示 [PDF](https://arxiv.org/pdf/2506.20543), [HTML](https://arxiv.org/abs/2506.20543)
## Authors
Sanne van Kempen,Jaron Sanders,Fiona Sloothaak,Maarten G. Wolf
## Background
本文探讨了如何最优控制技能型排队系统，如数据中心、云计算网络和服务系统。通过使用真实世界的数据集进行案例研究，我们研究了一种新发展起来的强化学习算法在最优客户路由方面的实际应用。实验显示该算法能有效学习并适应不断变化的环境，并且优于静态基准策略，显示出其在实际部署中的潜力。我们也通过引入新的启发式路由规则来减少延迟，增加了算法在实际环境中的适用性。此外，结果显示该算法能够同时优化多个目标，除了收益最大化，还可以纳入诸如服务器负载公平性和减少客户等待时间等次要目标。通过调整参数，可以解决固有的性能权衡问题。最后，我们研究了对估计误差和参数调整的敏感性，为在复杂的真实世界排队系统中实施自适应路由算法提供了宝贵的见解。
## Innovation
文章的主要创新点包括：1. 首次在实际数据中展示了UCB算法的有效性；2. 引入了新的启发式路由规则来减少延迟；3. 该算法能够同时优化多个目标，包括服务器负载公平性、客户等待时间减少等；4. 通过调整参数解决性能权衡问题；5. 研究了对估计误差和参数调整的敏感性。这些创新使得该算法更加适用于复杂的真实世界排队系统。
## Conclusion
研究表明UCB算法在最优客户路由中的有效性和潜力，并通过引入新的启发式规则进一步提高了其实际应用价值。同时，通过优化多目标性能和研究敏感性，该算法可以更广泛地应用于复杂的真实世界排队系统中。
# 488. `cs.LG` - H-FEX: 一种用于哈密顿系统的符号学习方法 [PDF](https://arxiv.org/pdf/2506.20607), [HTML](https://arxiv.org/abs/2506.20607)
## Authors
Jasen Lai,Senwei Liang,Chunmei Wang
## Background
哈密顿系统描述了一大类由哈密顿函数控制的动力系统，其中哈密顿函数编码了系统的总能量并决定了系统的演化。数据驱动的方法，如符号回归和基于神经网络的方法，提供了一种直接从哈密顿系统观测数据中学习动力系统控制方程的途径。然而，这些方法常常难以准确捕捉复杂的哈密顿函数并保持能量守恒。为克服这一局限，我们提出了用于学习哈密顿系统的有限表达式方法（H-FEX），这是一种符号学习方法，引入了新的交互节点，旨在有效捕捉复杂交互项。包括对于高度刚性动力系统的实验表明，H-FEX 可以恢复出复杂系统的哈密顿函数，这些函数能够准确捕捉系统动态并长时间内保持能量守恒。这些结果突显了H-FEX作为发现复杂动力系统封闭形式表达式的强大框架的潜力。
## Innovation
提出了一种名为H-FEX的符号学习方法，该方法通过引入新的交互节点来有效捕捉复杂交互项，从而在高度刚性的动力系统中准确恢复哈密顿函数，同时保持能量守恒。
## Conclusion
H-FEX作为一个强大的框架，展示了其在发现复杂动力系统封闭形式表达式的潜力，可以准确捕捉系统动态并长时间内保持能量守恒，特别是对高度刚性动力系统的适用性得到了验证。
# 489. `cs.LG` - 可扩展且成本效益高的基于模板的从头分子生成 [PDF](https://arxiv.org/pdf/2506.19865), [HTML](https://arxiv.org/abs/2506.19865)
## Authors
Piotr Gaiński,Oussama Boussif,Andrei Rekesh,Dmytro Shevchuk,Ali Parviz,Mike Tyers,Robert A. Batey,Michał Koziarski
## Background
基于模板的分子生成为药物设计提供了潜在途径，通过预定义的反应模板和构建块确保生成的化合物具有合成可行性。然而，模板方法面临三大挑战：最小化合成成本、针对大规模构建块库进行扩展以及有效利用小型片段集。
## Innovation
提出了一种称为递归成本引导的后向策略框架，使用辅助机器学习模型近似合成成本和可行性，引导生成向低成本合成路径发展。同时开发了一种动态库机制，通过重用中间高回报状态构造完整的合成树，特别针对小型构建块库的性能提升。
## Conclusion
该方法在基于模板的分子生成中达到了目前最先进的成果，显著增强了成本效率、分子多样性和质量。
# 490. `cs.LG` - 使用AI进行欺诈检测和能源市场稳定性的区块链保障能源交易安全 [PDF](https://arxiv.org/pdf/2506.19870), [HTML](https://arxiv.org/abs/2506.19870)
## Authors
Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan
## Background
在区块链和去中心化网格技术的发展下，美国的能源市场正在经历变革。这虽然带来了新的机遇，但也引发了一系列新的挑战，尤其是能源交易的安全性和真实性问题。因此，本研究旨在构建一个新的安全、智能且高效的能源交易平台，以适应美国去中心化的能源市场。该研究创新性地结合了区块链技术和人工智能（AI），针对分布式能源市场的现有难题提出了独特的解决方案，具体涉及到安全问题、欺诈行为检测以及市场可靠性等环节。研究数据集涵盖了超过120万条匿名的能源交易记录，模拟了一个基于区块链的真实微电网，包括了LO3 Energy和Grid+ Labs测试的系统。每条记录包含交易ID、时间戳、能源体积、交易类型、单位价格、消费者标识、智能电表读数、地理区域以及结算确认状态。此外，还包括交易率、能源生产波动性和历史价格模式等系统计算的行为指标。
## Innovation
该研究结合了区块链技术和人工智能（AI）在能源交易安全和市场情报改进中的新应用。具体来说，机器学习模型被用于判定分布式能源市场中的欺诈交易，展示了优良的分类性能。这种技术创新旨在为去中心化的能源交易提供安全保障，并提高市场稳定性。
## Conclusion
通过将区块链技术和AI系统集成，研究提出了一种新的双重架构，其中区块链层用于保障安全性，AI层则改善市场情报。这种方法能够有效地解决去中心化能源市场的安全性和欺诈行为检测等问题，为未来的能源市场发展提供了新的方向和思路，确保了美国去中心化能源市场的稳定性和公正性。
# 491. `cs.LG` - 无责用户在洁净室中：生成模型的版权保护定义 [PDF](https://arxiv.org/pdf/2506.19881), [HTML](https://arxiv.org/abs/2506.19881)
## Authors
Aloni Cohen
## Background
论文探讨了生成模型的输出在何种条件下不会侵犯其训练数据的版权，这是Vyas，Kakade和Barak（ICML 2023）提出的“可证明版权保护”问题。他们定义了近乎访问自由(NAF)并将其作为保护的充分条件。本文重新审视了这个问题，并为可证明的版权保护建立了更为坚实的技术和法律基础。研究表明，仅NAF不足以防止侵权，甚至可能导致明显的复制失败。因此，作者提出了无责复制保护框架，通过“洁净室复制保护”定义了有意义的保证，以控制用户在假设的洁净室环境下的复制风险。此外，本文还证明了当数据集符合版权去重要求时，差异隐私(DP)与洁净室复制保护之间存在共同的直观联系。
## Innovation
本文提出了一个新的无责复制保护框架，并通过“洁净室复制保护”定义了实质性的保证，允许用户通过在假设的洁净室环境中少有复制行为来控制其复制风险。此外，证明了当数据集满足版权去重要求时，差异隐私与洁净室复制保护之间存在联系。通过这一框架，为生成模型的版权保护建立了更坚实的技术和法律基础。
## Conclusion
本文重新审视了“可证明版权保护”的问题，并通过提出新的无责复制保护框架和“洁净室复制保护”概念，为生成模型的版权保护建立了坚实的理论基础。证明了在特定条件下，差异隐私能够实现洁净室复制保护。
# 492. `cs.LG` - RepuNet: 在DFL中缓解恶意客户端的声誉系统 [PDF](https://arxiv.org/pdf/2506.19892), [HTML](https://arxiv.org/abs/2506.19892)
## Authors
Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán
## Background
Decentralized Federated Learning (DFL) 允许节点不依赖中心服务器协作训练模型，但每个节点独立选择用于模型聚合的伙伴带来了新的安全漏洞，如模型中毒、延迟提交模型或网络泛洪。现有解决方案往往依赖于固定的配置或区块链等额外基础设施，这导致了计算开销、可扩展性问题或适应性有限等问题。这些限制促使了RepNuT系统的提出，旨在动态评估节点行为并调整其在模型聚合中的影响权重。
## Innovation
RepuNet 提出了一种去中心化的声誉系统，该系统能够分类DFL中的威胁并利用模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为。根据节点的声誉评分调整其在模型聚合中的影响。实验结果表明，RepuNet 在缓解恶意行为方面表现有效，特别是在非同态分布情况下，对MNIST和CIFAR-10数据集的评估中，达到了95%以上的F1分数，展示了其适应性、稳健性和实用性。
## Conclusion
RepuNet 有效地解决了DFL中的恶意客户端攻击问题，提高了系统的稳定性和安全性，对于去中心化联邦学习环境的威胁缓解具有实际应用潜力。
# 493. `cs.LG` - 通过流形学习实现驱动型动态因子建模 [PDF](https://arxiv.org/pdf/2506.19945), [HTML](https://arxiv.org/abs/2506.19945)
## Authors
Graeme Baker,Agostino Capponi,J. Antonio Sidaoui
## Background
研究开发了一种数据驱动的动态因子框架，该框架允许响应变量依赖于高维协变量而不对联合动态性进行任何参数化建模。该研究利用了Singer和Coifman提出的非线性流形学习技术——适应性扩散映射，以纯数据驱动的方式揭示协变量和响应变量的共同动态性。通过线性扩散近似嵌入动态，并利用卡尔曼滤波直接从扩散地图嵌入空间预测协变量和响应变量的演化。该研究还从Langevin扩散在欧几里得空间中的案例推广了Singer关于图拉普拉斯收敛速率的分析，适用于紧流形上的独立均匀抽样案例。进一步通过满足底层动力学标准频谱假设来验证泛函的鲁棒性，确保了动态映射坐标近似线性扩散的收敛性。该方法应用于联邦储备监督情景中金融和宏观经济因素的资产组合压力测试，证实了相比标准情景分析和主成分分析基准方法，数据驱动的压力测试方法在三个主要金融危机的历史回测中表现更佳，成分回报预测的平均绝对误差减少了55%和39%。
## Innovation
论文提出了一种数据驱动的动态因子模型，利用非线性流形学习技术来揭示高维数据的动态模式。研究首次将Singer关于图拉普拉斯收敛速率的分析从独立均匀抽样推广到时间序列上的Langevin扩散情况。通过卡尔曼滤波直接从嵌入空间中预测协变量和响应变量的演化，并提供了关于数据驱动方法可靠性的详细理论支持。这种方法被应用于压力测试中，展示了比传统方法更低的预测误差率，从而实现了更准确的预测效果。
## Conclusion
通过适应性扩散映射和卡尔曼滤波技术，提供了一种纯数据驱动的方法来建模和预测高维数据的动态行为。该论文通过详实的理论分析和实际应用案例，证明了新方法的有效性和优越性。
# 494. `cs.LG` - Prover Agent: 一种基于代理框架的形式化数学证明方法 [PDF](https://arxiv.org/pdf/2506.19923), [HTML](https://arxiv.org/abs/2506.19923)
## Authors
Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai
## Background
本文介绍了一种名为Prover Agent的新型AI代理，它将大型语言模型（LLMs）与形式证明助手Lean相结合，用于自动化定理证明。这项工作建立在现有的方法之上，旨在通过结合LLMs和正式证明助手来提高定理证明的效率和效果。Prover Agent通过协调非正式推理的LLMs、正式证明模型以及来自Lean的反馈，生成辅助引理，来发现整个证明策略。此外，Prover Agent在MiniF2F基准测试中的成功率达到了86.1%，在使用小型语言模型（SLMs）的方法中表现优异，同时样本预算远远低于之前的解决方案。
## Innovation
Prover Agent的主要创新在于它通过结合LLMs和正式证明助手Lean，能够生成辅助引理来协助发现证明策略。这使得它能够在保持低样本预算的情况下，达到86.1%的成功率，超越了之前的使用小型语言模型的方法。Prover Agent提供了一个新的代理框架，展示了在形式化数学证明中的应用潜力。
## Conclusion
Prover Agent的成功率被证明能够显著提高定理证明的效率和效果，尤其是在使用小型语言模型的情况下。此外，案例研究证明了这种生成的引理对解决复杂问题的帮助作用，强调了代理框架在形式化数学证明中的价值。
# 495. `cs.LG` - 基于扩散机制的任务导向型语义通信及其模型反转攻击 [PDF](https://arxiv.org/pdf/2506.19886), [HTML](https://arxiv.org/abs/2506.19886)
## Authors
Xuesong Wang,Mo Li,Xingyan Shi,Zhaoqian Liu,Shenghao Yang
## Background
基于神经网络的语义通信是6G网络有前景的系统设计之一。任务导向型语义通信是一种新颖的范式，目标是通过传输语义信息来高效完成特定任务，优化通信效率和任务性能。然而，该领域的关键挑战在于如何在保证隐私性的同时保持任务精度，因为这种场景容易遭受模型反转攻击，即攻击者通过分析和处理模型输出来恢复或重构输入数据。现有的评估攻击严重性的指标（如PSNR或SSIM）可能不适用于任务导向型语义通信，因为视觉差异并不一定意味着语义差异。
## Innovation
本文提出了一个基于扩散机制的任务导向型语义通信框架（DiffSem），通过扩散机制和自参照标签嵌入优化语义信息重构，显著提高任务性能。该模型能够补偿信道噪声和语义信息失真，确保在各种信噪比环境下系统的鲁棒性。同时，本文还提出了一种新指标来更准确量化攻击者估计的语义保真度。实验结果显示，DiffSem在MNIST数据集上将分类准确率提高了10.03%，并维持了动态信道下的稳定性能。上述结果表明，传统的图像质量指标与任务相关信息的泄露之间存在显著的偏差。
## Conclusion
本文提出了一种新的基于扩散机制的任务导向型语义通信框架DiffSem，该框架通过优化语义信息重构和处理信道噪声，提高了在动态信噪比环境下的任务性能与鲁棒性。新的评估指标展示了传统图像质量指标与语义信息泄露之间的不匹配，并证实了DiffSem在提升分类准确率方面的显著效果。
# 496. `cs.LG` - MAIZX：一种面向碳意识的优化云端计算排放框架 [PDF](https://arxiv.org/pdf/2506.19972), [HTML](https://arxiv.org/abs/2506.19972)
## Authors
Federico Ruilova,Ernst Gunnar Gran,Sven-Arne Reinemo
## Background
云计算推动了创新，但也带来了重大的环境挑战，主要是由于其高能耗和碳排放。数据中⼼占全球能源消耗的2-4%，并且ICT部门的电力消耗预计将到2040年达到总消耗的40%。鉴于到2050年实现净零排放的紧迫性，需要更高效的透明解决方案，特别是对于广泛使用的私有云基础设施。尽管公共云系统占主导地位，但私有云被87%的组织所使用。因此，为了应对这些挑战，越来越多的研究集中在优化私有云架构上，以提高能源效率和环境可持续性。
## Innovation
提出了MAIZX框架，这是一种碳意识优化框架，旨在优化云操作并减少碳足迹，通过动态排名低碳强度、PUE和能耗的资源（包括数据中心、边缘计算节点和多云环境），MAIZX通过灵活的排名算法实现了85.68%的C02排放减少。该框架经过地理分散的数据中⼼测试，显示了可扩展性和有效性，并直接与hypervisors对接，以优化私有、混合和多云环境中的工作负载，同时集成了实时和预测数据，为增强气候效益和维持操作效率提供了强有力的工具。
## Conclusion
MAIZX框架能够有效降低私有云和多云环境中的碳排放，通过实时和预测数据对碳强度、PUE和能耗进行排名，提高了云管理和环境可持续性。该研究证明了通过优化云操作来减少能源消耗和碳足迹的可行性，并为进一步提升云基础设施的环境可持续性提供了宝贵的经验和方法。
# 497. `cs.LG` - CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems [PDF](https://arxiv.org/pdf/2506.19993), [HTML](https://arxiv.org/abs/2506.19993)
## Authors
Haochen Zhang,Tianyi Zhang,Junze Yin,Oren Gal,Anshumali Shrivastava,Vladimir Braverman
## Background
推荐系统在提供相关内容给用户方面扮演着重要角色。随着大语言模型（LLMs）的快速发展，研究人员开始利用LLMs构建更加强大的推荐系统。然而，现有专注于使LLMs与推荐任务对齐的方法并不能充分利用它们的序列信息处理能力，导致性能不佳。背景着重解释了传统方法存在的主要问题，即未能充分利用LLMs的序列信息处理能力，从而限制了其在推荐任务中的表现。
## Innovation
本文提出了一种名为Compressed Vocabulary Expansion（CoVE）的新系统。在CoVE中，每个物品都被分配一个独特的ID在扩展词汇表中。该框架有效地利用了LLMs的序列理解能力，显著提高了其在推荐任务上的表现。此外，本文还压缩了嵌入层，使CoVE适用于大规模的工业应用。创新点在于通过增强LLMs的序列理解能力，并通过压缩嵌入层使其在工业应用中更实用。
## Conclusion
通过在多个推荐数据集上的全面实验和与先前工作的比较，证明了CoVE的有效性和性能。CoVE通过压缩词汇表扩展和优化LLMs的嵌入层，使LLMs在推荐系统中的应用更为高效。研究结果表明，CoVE能够在保留推荐系统重要特征的同时，显著提升性能，使得基于LLMs的推荐系统更为强大。
# 498. `cs.LG` - 网络流量中鲁棒异常检测：CICIDS2017 上的机器学习模型评估 [PDF](https://arxiv.org/pdf/2506.19877), [HTML](https://arxiv.org/abs/2506.19877)
## Authors
Zhaoyang Xu,Yunbo Liu
## Background
识别适合入侵检测系统的机器学习范式对于构建有效且可泛化的安全解决方案仍然至关重要。本文在两个场景下（检测已知攻击类型和应对未见过的威胁）对CICIDS2017数据集进行了多层感知机（MLP）、一维卷积神经网络（CNN）、一类支持向量机（OCSVM）和局部异常因子（LOF）四种代表性模型的对照研究，以评估不同类型的攻击检测效果和泛化能力。
## Innovation
研究提供了关于在动态网络环境中选择入侵检测模型的有效指导。结果显示，虽然基于监督学习的MLP和CNN在已知攻击检测中几乎完美，但在新型攻击上的召回率会急剧下降；基于LOF的无监督学习模型虽然召回率较高但误报率高；基于边界的OCSVM能够平衡精确度和召回率，在两个场景中表现较为稳健。
## Conclusion
研究结果为动态网络环境中IDS模型的选择提供了实用建议，表明OCSVM可能是同时应对已知和未知威胁的一种较为稳健的选择。
# 499. `cs.LG` - 一种用于精细建模阅读行为的空间时间点过程 [PDF](https://arxiv.org/pdf/2506.19999), [HTML](https://arxiv.org/abs/2506.19999)
## Authors
Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell
## Background
阅读是一个在空间和时间上展开的过程，包括定点聚焦和快速眼球移动。心理语言学的基本假设是，通过建模读者的固定和扫视，可以了解他们在处理句子时的在线过程。然而，标准建模方法依赖于聚合的眼动追踪测量和基于强烈假设的模型，忽略了阅读过程中发生的许多时空动态。
## Innovation
本文提出了一种更通用的概率阅读行为模型，基于标记的空间时间点过程，不仅捕捉固定持续时间的长度，还捕捉固定在空间中的位置和时间的发生，通过Hawkes过程建模扫视，捕捉每个固定对附近发生新的固定的时间和空间概率的影响。固定事件的持续时间通过固定特异性预测因子在时间上的卷积建模，以捕捉溢出效应。实证结果表明，Hawkes过程模型比基线更好地拟合人类扫视，并观察到将上下文惊喜作为预测因子的结果对模型预测准确性仅增加边际改进，这表明惊喜理论难以解释细粒度眼动行为。
## Conclusion
研究发现，惊奇理论难以解释细粒度的眼动行为，同时提出的基于Hawkes过程的模型能更好地理解阅读行为的详细过程。
# 500. `cs.LG` - Can One Safety Loop Guard Them All? 联邦计算中的自主护栏 [PDF](https://arxiv.org/pdf/2506.20000), [HTML](https://arxiv.org/abs/2506.20000)
## Authors
Narasimha Raghavan Veeraragavan,Jan Franz Nygård
## Background
该论文讨论了在多样化隐私保护机制（包括全同态加密、多方计算以及差分隐私等）中实现安全性统一管理的问题。当前的隐私保护方法通常面临着复杂性和互操作性的问题，因此需要提出一种新型框架来统一安全管理并支持不同隐私保护后端的动态切换。论文背景强调现有技术的不足以及对一种能够统一管理安全性框架的需求。
## Innovation
Guardian-FC框架是一种新颖的双层体系结构，旨在实现跨多种隐私保护机制的安全性统一管理。该框架通过执行插件（模块化计算单元），并使用后端中立、针对联邦计算工作流设计的专用语言（DSL）来隔离护栏和隐私机制。同时，该框架包括一个代理AI控制平面，通过带有签名的遥测和命令来执行有限的状态安全循环，从而确保一致的风险管理和可审计性。
## Conclusion
Guardian-FC框架展示了在多种隐私后端上实现通用安全性的潜力，同时提出了一个基于表现的系统设计，支持失败快的作业准入和对新隐私后端的无缝扩展。论文还强调需要进一步研究自适应护栏调整、多后端组合、DSL规范开发、实施和编译器扩展等问题，并邀请社区共同推进这一领域的发展。
# 501. `cs.LG` - DualEquiNet：大型生物分子的双空间层次不变网络 [PDF](https://arxiv.org/pdf/2506.19862), [HTML](https://arxiv.org/abs/2506.19862)
## Authors
Junjie Xu,Jiahao Zhang,Mangal Prakash,Xiang Zhang,Suhang Wang
## Background
几何图神经网络（GNNs）在尊重E(3)对称性的条件下，已经在小分子建模中表现出色，但在应用于如RNA和蛋白质这类大型生物分子时，却面临着可扩展性和表征能力的挑战。现有的几何GNNs通常仅在欧几里得空间或球谐空间中操作，这限制了它们同时捕捉微尺度原子细节和长程的、与对称性相关的依赖性能力，以应对大型生物分子多层次结构的建模需求。本文旨在通过一种新的方法，即DualEquiNet，解决这些问题，从而提高性能并提供更为稳定且有效的预测和建模能力。
## Innovation
DualEquiNet采用双空间（欧几里得空间和球谐空间）的互补表示方法来捕捉局部几何学和全局对称性相关特征。通过双向跨空间消息传递和一种新的跨空间交互池化机制，它可以有效地将原子特征逐层聚合为具有生物意义的单元，如残基等，从而实现大型生物分子建模中的高效且表达性有效的多层次建模能力。这种方法显著提升了RNA属性预测和蛋白质建模的性能，并在新推出的3D结构评估基准上超越了先前的方法，证明了其在多种大型生物分子建模任务中的广泛应用效果。
## Conclusion
DualEquiNet在多种现有基准测试中达到了最先进的性能，并在两个新引入的3D结构基准测试中表现优越，表明该方法在大型生物分子建模任务中具有广泛的有效性和适用性。
# 502. `cs.LG` - 遵循原理的贴合分布性评估路径 [PDF](https://arxiv.org/pdf/2506.20048), [HTML](https://arxiv.org/abs/2506.20048)
## Authors
Sungee Hong,Jiayi Wang,Zhengling Qi,Raymond Ka Wai Wong
## Background
在强化学习中，概率性的离策略评估（OPE）旨在使用在不同策略下收集的数据来估计目标策略的回报分布。本研究将广泛使用的基于期望的贴合Q评估扩展到分布性OPE设置。我们称之为贴合分布性评估（FDE）。尽管已有一些相关方法，但缺乏统一的设计FDE方法的框架。为填补这一空白，本文提出了指导原则以构建有理论依据的FDE方法。
## Innovation
基于这些原则，开发了一系列新的FDE方法，并进行了收敛性分析，还为现有的方法提供了理论依据，即使在非表驱动环境中也是如此。广泛的实验，包括线性二次调节器和Atari游戏的仿真，证明了FDE方法的优越性能。
## Conclusion
本研究不仅为FDE方法提供了系统化的理论框架，而且通过实验验证了这些方法的有效性，为强化学习中的分布性评估提供了新的思路和方法。
# 503. `cs.LG` - PocketVina 通过多口袋条件化实现了可扩展且高度准确的物理合理对接 [PDF](https://arxiv.org/pdf/2506.20043), [HTML](https://arxiv.org/abs/2506.20043)
## Authors
Ahmet Sarigun,Bora Uyar,Vedran Franke,Altuna Akalin
## Background
在分子对接中，以物理上合理的方式采样配体结合位点的姿势仍然是一个重大挑战，尤其是在面对未知或结构多样的靶标时。现有的分子对接方法往往在这些情况下表现不佳，难以有效找到配体与靶标结合的合理姿势。PocketVina 提出了一种基于搜索的对接框架，该框架结合了口袋预测和系统性的多口袋探索，旨在解决这一关键问题。
## Innovation
PocketVina 通过结合 pocket 预测与系统性的多口袋探索，提供了一种快速且内存高效的对接方法。它在四个广泛认可的基准测试中——PDBbind2020（时间分割和未见过的靶标）、DockGen、Astex 和 PoseBusters 中都表现出优异的性能。尤其在配体 RMSD 和物理合理性的联合考虑上达到了最先进的表现，同时在单独考虑 RMSD 方面仍与基于深度学习的方法竞争，特别是在结构多样性和之前未见过的靶标上。此外，PocketVina 在包含多种柔性程度的配体时，保持了最先进的物理合理对接准确性。PocketVina 还引入了一个名为 TargetDock-AI 的基准数据集，该数据集包含了超过 50 万个蛋白质-配体对，并带有 PubChem 活性注解，从而能够在大规模数据集上实现活性和非活性靶标的准确区分。
## Conclusion
PocketVina 提供了一种稳健且可扩展的对接策略，无需特定任务的训练，可以在标准 GPU 上高效运行，非常适合高通量虚拟筛选和结构基于的药物发现。
# 504. `cs.LG` - 基于注意力预测的移动链路分配 MiLAAP [PDF](https://arxiv.org/pdf/2506.19947), [HTML](https://arxiv.org/abs/2506.19947)
## Authors
Yung-Fu Chen,Anish Arora
## Background
在多路径跳频(CS)通信系统中，为了保持吞吐量效率，系统需要适应无线网络中的干扰变化和节点的移动性。最优调度需要实时了解每个节点的通道占用状态，以便为处于干扰区域的链路选择不重叠的通道。然而，在节点之间共享状态会引入巨大的通信开销，特别是在网络规模或节点移动性增大时，从而降低已经处于容量限制的网络的吞吐量效率。本文探讨了在无需状态共享的前提下，基于基于学习的通道占用状态预测来适应CS调度的问题。
## Innovation
本文提出了基于注意力机制的预测框架MiLAAP，用于预测频谱、空间和时间相互依赖的网络节点。MiLAAP使用自我注意机制，使每个节点能够捕捉其干扰区域内的时空CS模式，并据此预测该区域的通道占用状态。此外，MiLAAP利用多头自我注意机制，使每个节点能够局部捕捉对自己可能产生干扰的其他网络节点的时空依赖性，从而预测这些节点的运动轨迹。还讨论了检测进入或移出干扰区域的节点以进一步提高通道占用状态预测精度的方法。实验结果表明，对于使用局部CS序列支持相对长任期流量的动态网络，MiLAAP的通道状态预测准确率在不同移动性模式下高达约100%，并且在不同的CS序列周期具有零射 generalized 性能。
## Conclusion
通过使用基于注意力的预测框架，MiLAAP能够有效地预测网络节点的通道占用状态，即使在网络规模和移动性增加的情况下，也不会产生额外的通信开销，从而在实际部署中实现更高的吞吐量效率和零射性能。
# 505. `cs.LG` - 从树集合中提取可解释模型：计算与统计视角 [PDF](https://arxiv.org/pdf/2506.20114), [HTML](https://arxiv.org/abs/2506.20114)
## Authors
Brian Liu,Rahul Mazumder,Peter Radchenko
## Background
树集合是非参数方法，因其准确性及捕捉复杂交互的能力而广受认可。尽管这些模型在预测方面表现出色，但在解释性方面存在局限，可能无法揭示数据中的有用关系。本文探讨了如何从树集合中提取简洁的决策规则集，以提高模型的解释性，同时保持较高的准确性。
## Innovation
本文提出了一种新的估计器，能够在控制提取规则的数量和每个规则的交互深度的同时，从树集合中提取可解释的模型。通过开发一种针对优化问题的精确算法和近似算法，可以有效地计算规则提取过程中的正则化路径。所提出的估计器的预测性能与最佳的数据相关线性组合相媲美，特别是在大样本预测性能方面。与现有算法相比，本文的方法在规则提取方面表现出更优的表现。
## Conclusion
通过实验验证了所提出的估计器的有效性，表明其在数据的解释性与预测准确性方面具有优势，未来的应用前景广阔。
# 506. `cs.LG` - 聪明进攻：基于注意力驱动的细微网站指纹攻击 [PDF](https://arxiv.org/pdf/2506.20082), [HTML](https://arxiv.org/abs/2506.20082)
## Authors
Yali Yuan,Weiyi Zou,Guang Cheng
## Background
网站指纹（WF）攻击旨在通过分析流量模式来推断用户访问的网站，从而破坏用户匿名性。尽管该技术在受控实验环境中已被证明有效，但它主要局限于小规模场景，通常只能识别网站主页。在实际应用中，用户经常在页面完全加载之前快速访问多个子页面。网页指纹（WPF）将WF框架扩展到大规模环境，通过将相同站点的子页面视为不同的类别来建模。这些页面通常具有相似的页面元素，导致流量特征之间的类内方差较低。此外，我们还考虑了多标签浏览场景，其中单一跟踪涵盖了多个网页类别的组合，导致流量中的重叠段落和相似特征在不同的位置出现，从而增加了分类的难度。
## Innovation
本文提出了一种基于注意力机制的细微网页指纹攻击，名为ADWPF。训练阶段中，ADWPF根据注意力图应用定向增强，包括注意力裁剪和注意力掩码来提取原始和增强流量的低维特征。通过引入自注意力模块，捕获轨迹的全局上下文模式。此外，为了处理多标签浏览场景，ADWPF采用残差注意力生成不同时间位置出现的网页类别的特定表示。实验表明，所提出的方法在不同规模的数据集上都能超越最先进的基线方法，表明该方法的有效性和优越性。
## Conclusion
研究表明，基于ADWPF的细微网页指纹攻击方法在不同规模的数据集上表现出色，能有效地解决大规模环境中的网站指纹攻击问题。与现有基线方法相比，该方法在多标签浏览场景下的表现尤为突出。
# 507. `cs.LG` - 一种结合时空模型和大语言模型的模块化多任务推理框架 [PDF](https://arxiv.org/pdf/2506.20073), [HTML](https://arxiv.org/abs/2506.20073)
## Authors
Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang
## Background
时空数据挖掘在多个领域中支持基于信息的决策中扮演着重要角色，但现有的模型通常局限于单一任务，并缺乏处理多任务推理和复杂长形式推理的能力。这些限制使得它们在实际多方面的决策场景中的应用受到限制。因此，新模型需要具备处理多任务推理和生成深入解释性输出的能力。现有的模型存在多任务推理能力不足、长文本推理能力较差等问题，限制了其应用范围。
## Innovation
本文提出了STReason框架，它将大语言模型（LLMs）的推理优势与时空模型的分析能力相结合，用于多任务推理和执行，无需特定任务的微调即可利用上下文学习将复杂的自然语言查询分解为可模块化、可解释的程序，然后系统地执行以生成解决方案和详细理由。此外，还构建了一个新的基准数据集和统一的评估框架，特别设计的评估指标涵盖了长时间序列推理能力。实验结果显示，STReason在所有指标上显著优于先进的大语言模型基线，特别是在复杂的、推理密集型的时空场景中表现优异。
## Conclusion
人类评估进一步验证了STReason的可靠性和实际应用价值，展示了其在减轻专家工作量和扩展时空任务适用范围方面的潜力。我们相信，STReason为开发更具能力且通用化的时空推理系统提供了很有前景的方向。
# 508. `cs.LG` - 在合作的多智能体强化学习中学习双边团队形成 [PDF](https://arxiv.org/pdf/2506.20039), [HTML](https://arxiv.org/abs/2506.20039)
## Authors
Koorosh Moslemi,Chi-Guhn Lee
## Background
多智能体强化学习（MARL）中的团队形成和团队学习动态引起了研究者的广泛关注。然而，现有的研究主要集中在单方面的团队划分、预定义的团队或固定人口设置上，忽视了算法在动态人口中的双边团队划分选择对策略性能和泛化能力的影响。
## Innovation
本文引入了一个框架来学习动态多人智能体系统中的双边团队形成，通过对算法在双边团队形成中的性质与策略性能及泛化能力之间的关系进行研究，填补了这一研究领域的空白，并通过广泛采用的多人智能体场景验证了该方法的有效性和泛化能力的提升。
## Conclusion
研究结果表明，该方法在大多数场景中表现出色，且在泛化能力上有所提升，为理解和优化多智能体系统中双边团队形成策略提供了新的视角。
# 509. `cs.LG` - 机器学习辅助的光子器件开发：从理论到表征的多尺度方法 [PDF](https://arxiv.org/pdf/2506.20056), [HTML](https://arxiv.org/abs/2506.20056)
## Authors
Yuheng Chen,Alexander Montes McNeil,Taehyuk Park,Blake A. Wilson,Vaishnavi Iyer,Michael Bezick,Jae-Ik Choi,Rohan Ojha,Pravin Mahendran,Daksh Kumar Singh,Geetika Chitturi,Peigang Chen,Trang Do,Alexander V. Kildishev,Vladimir M. Shalaev,Michael Moebius,Wenshan Cai,Yongmin Liu,Alexandra Boltasseva
## Background
光子器件开发（PDD）在设计和实施控制各种波长、尺度和应用（包括电信、成像、传感和量子信息处理）的新设备方面取得了显著成功。PDD 是一个迭代的五个步骤过程，包括：i) 从设计参数推导器件行为，ii) 模拟器件性能，iii) 从模拟中找到最优候选设计，iv) 制造最优器件，v) 测量器件性能。经典方法中，所有这些步骤都涉及贝叶斯优化、材料科学、控制理论和直接的物理驱动数值方法。然而，许多这些技术在计算上难以执行、经济上昂贵或难以在大规模实施。此外，PDD 还遭受着庞大的优化景观，结构或光学表征中的不确定性，以及实施稳健的制造过程的困难。
## Innovation
机器学习在过去的十年出现了新的数据驱动策略，用于应对这些挑战，包括：i) 通过代理估计器加快计算，ii) 通过生成建模和数据增强处理噪声测量，iii) 通过强化学习应用于制造，iv) 通过主动学习应用于实验物理学发现。本文综述了这些方法，以实现机器学习辅助的 PDD (ML-PDD)。这些方法可以实现高效的优化设计，快速的模拟和表征建模下的噪声测量，以及制造中的强化学习。这将为来自不同背景的研究人员提供宝贵见解，促进跨学科努力，加速复杂光子器件和系统的开发。
## Conclusion
本文综述了机器学习辅助的 PDD 方法，以实现高效的设计优化，快速的模拟和表征建模下的噪声测量，并通过制造中的强化学习促进复杂光子器件和系统的开发。这些技术将为来自不同背景的研究人员提供有价值的知识，促进多学科的协作，推动光子技术的发展。
# 510. `cs.LG` - 采用AI评分器进行缺省分数填充以在构造性回答测试中实现准确的能力估计 [PDF](https://arxiv.org/pdf/2506.20119), [HTML](https://arxiv.org/abs/2506.20119)
## Authors
Masaki Uto,Yuma Ito
## Background
评估学习者的能力是教育领域的基本目标。特别地，对表达能力、逻辑思维等高级能力的评估需求日益增加。构造性测试，如简答题和论文题，因其能有效评估高级能力而被广泛应用。但是，这些测试需要大量的人工评分，导致工作量大且成本高。项目反应理论(IRT)提供了一种解决方案，能够通过估计能力来预测评分，即使只有部分评分由人工打分。然而，随着缺失评分比例的增加，能力估计的准确性会降低。尽管已经探索了数据增强技术以填补缺失评分，但在稀疏或异构数据下，这些技术往往难以保证准确性。
## Innovation
本文提出了一种创新方法，利用自动评分技术来填补缺失的评分，从而实现基于IRT的能力估计。该方法能够在保持高准确性的同时，显著减少人工评分的工作量。这是通过利用自动评分技术的准确评分来填补缺失评分实现的，从而解决了现有方法在稀疏或异构数据下的不准确性问题。
## Conclusion
该研究提出的方法在能力估计的准确性方面取得了高成绩，同时大幅减少了人工评分的工作负担。这为构造性回答测试中精确评估学习者的能力提供了一种新的可行解决方案。
# 511. `cs.LG` - 基于编辑距离弱监督的开放世界多模态信息检索 [PDF](https://arxiv.org/pdf/2506.20070), [HTML](https://arxiv.org/abs/2506.20070)
## Authors
KMA Solaiman,Bharat Bhargava
## Background
现有的多模态检索模型依赖于创建共有的子空间并通过模态特定的表示模型，或者需要在模态之间进行模式映射来测量多模态数据之间的相似性。这些方法会导致注释工作量大且不能充分利用预训练的大语言模型和视觉任务中的编码器。因此，本文旨在避免将检索视为监督分类任务，并利用这些预训练的编码器进行检索，而不进行额外的微调和规范设计。同时，提出了一个名为FemmIR的新框架，该框架基于弱监督的编辑距离来实现无标签的多模态检索，以此来应对数据标注稀缺的实际场景，满足无需通过统一框架进行微调即可达到满意性能的需求。为此，他们创建了一个新的数据集MuQNOL进行评估。
## Innovation
FemmIR框架通过编辑距离的应用引入弱监督机制，不仅实现了无相似标签的多模态检索，而且还利用了预训练的编码器的高层属性，并保持了数据样本与用户提供的查询示例之间的属性值和关系约束。不同于现有的度量学习或编码网络，FemmIR通过多级交互评分来评估数据样本与查询示例的相关性，使得检索过程中能涵盖更复杂和多变的信息需求。
## Conclusion
FemmIR在缺少人员案例中与现有的检索系统进行实证比较，表现出了与其相似的检索效果。FemmIR利用系统现有的属性标识符实现了即时检索结果，同时提供了精确匹配和近似匹配的相似性度量。这个模型能在信息稀少且无需大量微调的情况下满足用户的信息需求，为开放世界多模态检索提供了一个新的解决方案。
# 512. `cs.LG` - 探索与利用权衡在通用失真压缩中的应用 [PDF](https://arxiv.org/pdf/2506.20261), [HTML](https://arxiv.org/abs/2506.20261)
## Authors
Nir Weinberger,Ram Zamir
## Background
该领域的研究探索了通用压缩算法的学习能力和适应性，能够在批量模式（前向适应）或序列模式（后向适应）下工作。本文将序列模式重新定义为一个多臂bandit问题，这是一个强化学习的基本模型，研究在数据丢失压缩情况下探索与利用之间的权衡。先前提出的自然类型选择方案被重新表述为序列性失真压缩的重建导向MAB算法，并对其鲁棒性和短块性能进行了说明。然后，推导并分析了稳健代价导向的MAB算法，该算法适用于任何块长。
## Innovation
本文的主要创新之处在于，将序列模式下的压缩问题重新定义为多臂bandit问题，并提出了在数据丢失压缩中能够抵抗环境变化的稳健代价导向的MAB算法，该算法适用于任意块长，提高了算法的鲁棒性和性能。
## Conclusion
通过研究探索与利用的权衡问题，本文提出了更加稳健的代价导向MAB算法，该算法能够适应不同长度的数据块，优化了通用失真压缩中的性能表现。
# 513. `cs.LG` - 接受更多，拒绝更少：11年ICLR数据减少高达19%的不必要的桌面拒绝 [PDF](https://arxiv.org/pdf/2506.20141), [HTML](https://arxiv.org/abs/2506.20141)
## Authors
Xiaoyu Li,Zhao Song,Jiahao Zhang
## Background
AI研究的迅猛增长使得旗舰AI会议的投稿数量达到前所未有的水平，许多会议（如CVPR、ICCV、KDD、AAAI、IJCAI、WSDM）必须实施严格的作者投稿限制，对于多余的论文按简单ID顺序直接拒绝。虽然这一政策有助于减少审稿人的工作量，但可能会无意中放弃有价值的论文并惩罚作者的努力。背景提到的是目前存在的桌面拒绝策略的问题以及对审稿工作量的控制，但同时存在因简单ID顺序导致有价值的论文被误拒的情况。
## Innovation
论文提出将当前的桌面拒绝策略形式化，并基于线性规划松弛和四舍五入方案开发了一种实用算法。实验表明，在11年的ICLR数据上，该方法在不违反作者限制的情况下，能够多保存高达19.23%的论文。此外，该算法在实践中非常高效，所有结果在ICLR数据上的计算时间最多53.64秒。创新之处在于提出了一种有效减少不必要的桌面拒绝的策略，可以大大改进当前CS会议投稿策略。
## Conclusion
论文提供了简单实用的桌面拒绝策略，显著减少了不必要的拒绝，显示出其对改善当前计算机科学会议投稿政策的强大潜力。
# 514. `cs.LG` - 在强化数字孪生沙盒中通过协进性军备竞赛实现自主网络安全 [PDF](https://arxiv.org/pdf/2506.20102), [HTML](https://arxiv.org/abs/2506.20102)
## Authors
Malikussaid,Sutiyo
## Background
IT与OT的融合产生了超连接的工业控制系统(ICS)，使关键基础设施面临新的适应性强、智能化的威胁，现有静态防御措施变得无效。现有的安全范式往往无法应对“信任三位一体”：系统模型的准确性、同步数据的完整性和对抗高级规避攻击分析引擎的韧性。
## Innovation
提出了ARC框架，一种通过自主闭环加固实现分析韧性的方法。ARC在高保真度的F-SCDT沙盒中建立了一种不断进化的军备竞赛。引入了“红代理”智能体来自主发现隐秘的物理上可能的攻击路径以最大化过程干扰，同时规避检测。同时，“蓝代理”防守者利用对手发现的威胁进行对抗性训练不断加固。这种相互推动促使两个代理变得更加复杂，使系统能够自主探测和修补自身漏洞。在TEP和SWaT测试床上的实验验证显示了框架的优越性能。详细的消融研究通过ROC曲线和SHAP图可视化揭示了共进化过程对检测新型攻击的重要性。通过结合可解释性人工智能(XAI)以确保操作员信任并提出可扩展的F-ARC架构，该工作不仅展示了改进，还展示了一种走向动态、自我改进的关键基础设施安全范式的转变需求。
## Conclusion
ARC框架成功地展示了如何在强化的数字孪生沙盒中通过自主和协调进化实现网络安全。实验验证了其优越性能，并通过可解释性智能算法提高了操作人员的信任。这一工作标志着向更加动态和自我改进的关键基础设施安全保障模式转变的必要性。
# 515. `cs.LG` - 在趋同集合中的有效选择 [PDF](https://arxiv.org/pdf/2506.20173), [HTML](https://arxiv.org/abs/2506.20173)
## Authors
Mahmoud Hegazy,Liviu Aolaritei,Michael I. Jordan,Aymeric Dieuleveut
## Background
趋同预测提供了一种无需假设分布的框架，用于构建具有覆盖保证的预测集。然而，在实际应用中，可能导致覆盖保证的趋同预测集可能有多个，这些集合并穿过不同的模型或方法产生。但是，选择一个最佳集合并会导致覆盖保证失效，例如选择最小子集。因此，需要一种方法来确保所选预测集的覆盖保证。在此背景下，作者提出了一种基于稳定性的方法来解决这一问题，并将其扩展到在线趋同预测环境，同时根据额外结构提出若干改进，通过实验验证其有效性和优越性。
## Innovation
一种基于稳定性选择趋同预测集的方法，此方法即使是以最小子集形式选择预测集也能保持覆盖保证。此方法扩展至在线趋同预测环境，并提出了一系列改进措施。这些改进措施使得方法更加实用和有效。研究表明，此方法在多种情况下均表现出良好的有效性。
## Conclusion
本文提出了一种基于稳定性的趋同预测集选择方法，适用于多个可能的趋同预测集评估。该方法在保证覆盖保证的前提下，选择了一个最优的预测集。进一步，已将方法扩展到了在线趋同预测场景下，并通过实验展示了方法的有效性和优越性。
# 516. `cs.LG` - 绘画中织物对比的法医研究 [PDF](https://arxiv.org/pdf/2506.20272), [HTML](https://arxiv.org/abs/2506.20272)
## Authors
Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén
## Background
研究艺术作品中的画布对于鉴定、归类和保护至关重要。传统的技术方法是基于线密度图来匹配，当画布来自卷轴上不相连的位置时，这种方法无法应用。本文探讨了一种新的基于深度学习的方法来评估纺织材料的相似性。该方法旨在在不依赖线密度图的情况下评估画布之间的相似性。并在马德里普拉多博物馆的画布上进行了应用，证明了对于广泛使用的平纹画布，即使线密度相似，也可以有效地进行比较。
## Innovation
本文提出了一种基于深度学习的新方法来评估画布的相似性，无需依赖线密度图。具体来说，采用了Siamese深度学习模型来比较图像对并利用扫描学习到的特征表示。同时提出了一种相似性估计方法，通过对多组布料样本的预测结果进行聚合，提供了一个稳健的相似性评分。这种方法的有效性和准确性通过普拉多博物馆的画布得到了验证。
## Conclusion
本文提出的方法表明，即使画布的线密度相似，对于广泛用于绘画的平纹画布也能有效比较。这为名画的分析提供了新的途径。该方法的可行性和准确性为进一步研究打开了新的大门。
# 517. `cs.LG` - COIN：具有可验证风险保证的基础模型选择性问答的不确定性保护 [PDF](https://arxiv.org/pdf/2506.20178), [HTML](https://arxiv.org/abs/2506.20178)
## Authors
Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu
## Background
基础模型生成自动文本时的核心问题是不确定性量化（UQ），以识别和减轻潜在的幻觉。现有的启发式UQ方法在关键指标如选择性预测的错误发现率（FDR）上缺乏正式保证。尽管早期工作使用了分拆一致预测（SCP）框架来通过构建预测集确保可接受答案的覆盖率，但这些集往往包含错误候选，限制了其实用价值。
## Innovation
本文提出了COIN框架，这是一种新颖的选择性的问答框架，用于基础模型，并通过在指定的FDR约束下调整统计上有效的阈值来筛选单个生成答案。通过在校准集上估计经验错误率，并应用Clopper-Pearson方法等置信区间方法，COIN能够确保测试数据中的FDR控制的同时，显著提高样本保留率。进一步地，COIN的性能可以通过采用其他置信区间构造和不确定性量化策略来提升，这突显了其在不同应用场景中的扩展性和适应性。
## Conclusion
COIN在风险控制和保留可接受答案方面表现出较强的测试时能力，并且即使在有限的校准数据下也具有较强的预测效率，适用于通用和多模态文本生成任务。
# 518. `cs.LG` - X-SiT: 自然可解释的表面视觉变换器在痴呆症诊断中的应用 [PDF](https://arxiv.org/pdf/2506.20267), [HTML](https://arxiv.org/abs/2506.20267)
## Authors
Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger
## Background
可解释的模型对于支持临床决策至关重要，推动了其在医学图像中的开发和应用。然而，3D体积数据的特性使得可视化和解释如大脑皮层这样复杂精细的结构极具挑战性。与之相比，皮层表面渲染可以提供更易于理解和交互的3D大脑解剖结构表示，有助于诊断和探索。基于此优势，本文提出了eXplainable Surface Vision Transformer (X-SiT)，这是第一个具备自然可解释性的神经网络模型，可以基于可解释的皮层特征提供人类可理解的预测。X-SiT 包含一种原型表面块解码器，用于分类表面块嵌入，并结合基于实例的推理和相应的皮层原型空间对齐。研究表明，X-SiT 在检测阿尔茨海默病和额颞叶痴呆症时达到了最先进的性能，同时还提供了一些信息性原型，这些原型与已知疾病模式一致，并揭示了分类错误。
## Innovation
X-SiT 是第一个基于可解释的皮层特征提供人类可理解预测的神经网络模型。它引入了一种原型表面块解码器，用于分类表面块嵌入，结合了基于实例的推理和相应的皮层原型空间对齐。该模型在痴呆症诊断中达到最先进的性能，提供了与已知疾病模式一致的信息性原型，揭示了分类错误。
## Conclusion
X-SiT 在痴呆症诊断中表现出卓越的性能，并采用了能够可解释的神经网络架构，提供与疾病模式一致的信息性原型，有助于揭示分类错误。
# 519. `cs.LG` - CCRS: 一个零样本的LLM作为评判者的综合RAG评估框架 [PDF](https://arxiv.org/pdf/2506.20128), [HTML](https://arxiv.org/abs/2506.20128)
## Authors
Aashiq Muhamed
## Background
现有的RAG系统通过整合外部知识增强了大型语言模型（LLM），这对于要求事实准确性和最新信息的领域尤为重要。然而，评估RAG输出的多方面质量，包括上下文连贯性、查询相关性、事实正确性和信息完整性，存在显著挑战。现有的评估方法多依赖简单的词汇重叠度量，无法捕捉这些细微差别，或者需要复杂的多阶段管道和中间步骤如声明提取，或需要微调专门的裁判模型，这阻碍了实用性。
## Innovation
本文提出了CCRS（上下文连贯性和相关性评分），这是一种新颖的度量集，利用单一的强大预训练LLM进行零样本、端到端的评判。CCRS评估了上下文连贯性（CC）、问题相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回率（IR）五个方面。CCRS相比复杂的RAGChecker框架提供了类似或更优的关键方面上的区分能力，同时计算效率更高。
## Conclusion
CCRS为评估和迭代改进RAG系统提供了一个适用、全面和高效的框架。它能够有效区分系统性能，并证明了Mistral-7B阅读器在某些方面优于Llama变体。CCRS的详细度量特性分析，包括分数分布、收敛性/区分效度、平局率、人口统计学和区分力，进一步表明其有效性。
# 520. `cs.LG` - 基于递归神经网络的具有闭环区域增量ISS的鲁棒控制系统及其在MPC设计中的应用 [PDF](https://arxiv.org/pdf/2506.20334), [HTML](https://arxiv.org/abs/2506.20334)
## Authors
Daniele Ravasio,Marcello Farina,Alessio La Bella,Andrea Ballarino
## Background
本文针对一类递归神经网络描述的系统，研究了输出反馈方案的设计。背景在于现有控制系统可能面临扰动和状态估计不确定性等问题，通过分析全局和局部增量输入到状态稳定性（增量ISS）特性，提出了基于线性矩阵不等式的观察器和静态状态反馈控制器设计方法，确保系统的鲁棒性。
## Innovation
提出了基于线性矩阵不等式的观察器和静态状态反馈控制器设计方法，利用了全局和局部增量输入到状态稳定性特性，设计了鲁棒混合控制方案（结合了管网模型预测控制NMPC以克服局部增量ISS的局限性），证明了该方法能扩大吸引域并确保收敛性和递归可行性，验证了该方法的有效性。
## Conclusion
通过数值仿真验证了所提出方案的有效性，结果显示基于递归神经网络的鲁棒控制方案能够提供更好的鲁棒性和系统性能，尤其是在处理诸如pH中和过程等基准应用时表现突出。
# 521. `cs.LG` - Biomed-Enriched：通过LLMs增强的生物医学数据集，用于预训练和提取稀有和隐藏内容 [PDF](https://arxiv.org/pdf/2506.20331), [HTML](https://arxiv.org/abs/2506.20331)
## Authors
Rian Touchent,Nathan Godey,Eric de la Clergerie
## Background
临床文本通常难以获取，因为隐私限制使得医院记录无法公开共享。现有的生物医学和临床自然语言处理资源有限。因此，这篇论文通过利用PubMed数据集，提出了一种新型的生物医学文本数据集，以提供一个公开可用的临床案例集合，以支持该项研究。
## Innovation
提出了Biomed-Enriched数据集，通过两阶段注释过程从PubMed构建，其中包括大量语言模型的初步注释和后续微调以传播标签至整个PMC-OA语料库。该数据集通过质量筛选和领域过采样，能够提取出专门用于临床案例分析的高质量子集，并为预训练和其他NLP任务提供了更有效的资源。初步预训练实验表明了这些子集的有效性，提升效果显著，尤其是临床文本过采样对性能的提升。
## Conclusion
Biomed-Enriched数据集提供了高效的预训练策略，展示了LLM在生物医学和临床自然语言处理中的应用潜力。通过组合注释技术和质量筛选方法，不仅实现了更快的收敛速度而且达到了与传统方法相同的效果，为进一步优化生物医学预训练方法提供了可能。
# 522. `cs.LG` - 正则化深度矩阵分解的完整损失景观点分析 [PDF](https://arxiv.org/pdf/2506.20344), [HTML](https://arxiv.org/abs/2506.20344)
## Authors
Po Chen,Rujun Jiang,Peng Wang
## Background
尽管深度矩阵分解（DMF）在多个领域中具有广泛的应用，但其优化基础仍是一个未被充分研究的领域。本文作者旨在通过全面研究正则化DMF问题的损失景观来填补这一空白。
## Innovation
作者提供了一个正则化DMF问题所有临界点的闭合形式表达式，并建立了判别条件，确定哪些临界点是局部极小值、全局极小值、严格鞍点或非严格鞍点。此外，作者还推导出了每个临界点是局部极小值或严格鞍点的必要且充分条件，这为理解基于梯度的方法为何几乎总是收敛到正则化DMF问题的局部极小值提供了见解。最后，通过数值实验证实了该理论的有效性，以不同设置可视化其损失景观。
## Conclusion
本文所提供的完整损失景点分析，不仅深化了对正则化DMF问题优化特性的理解，而且帮助设计更有效的优化算法。
# 523. `cs.LG` - OLALa：适应异构联邦学习的在线学习自适应晶格编码 [PDF](https://arxiv.org/pdf/2506.20297), [HTML](https://arxiv.org/abs/2506.20297)
## Authors
Natalie Lang,Maya Simhi,Nir Shlezinger
## Background
联邦学习（FL）允许跨分布式客户端协作训练模型，无需共享原始数据，但往往会受到由于传输高维模型更新而导致的显著通信开销的影响。现有方案通常依赖固定的量化规则，但在模型更新分布随用户和训练轮次变化的异构和动态环境中，这通常是次优的选择。现有的基于晶格的FL方案通常采用固定的量化规则，这在异构和动态环境中并不理想，因为模型更新的分布会变化，固定规则无法适应这些变化。因此，需要一种能够适应这种变化的在线学习自适应晶格编码方法，从而减少通信开销并提高模型性能。因此，本研究提出了OLALa框架，允许每个客户端在线调整其量化器并进行轻量级本地计算，以实现适应性和更高效的通信。通过设计一个在线学习算法，客户端可以整个FL过程中微调其量化器，只需交换少量的量化参数集合。这些实验结果表明，OLALa在各种量化率下都能一致地提高学习性能，优于传统的固定码本和非自适应方案。
## Innovation
提出了OLALa框架，这是一种异构联邦学习框架，允许每个客户端根据异构环境在线调整其轻量级的自适应量化器，使用在线学习算法来调整量化器，提高在动态环境中的通信效率和模型性能。通过这种方法，解决了现有固定量化规则的不足，适应了模型更新分布的变化。该方法不仅减少了通信开销，还提高了模型的学习性能，并通过轻量级的本地计算使得实时适应成为可能。OLALa还展示了其在多种量化率下的优越性能，优于传统的固定码本和非自适应方案。
## Conclusion
本文提出了OLALa方案，一种针对异构联邦学习的在线学习自适应晶格编码方法。通过允许客户端在FL过程中根据实时改变的环境在线调整其量化器，并仅交换少量的量化参数集合，该方案能够在各种量化率下提高学习性能。与传统的固定码本和非适应性方案相比，OLALa能够更有效地减少通信开销，实现更好的性能。实验结果支持了OLALa的有效性和优越性，特别是在异构和动态环境中，OLALa显示出更好的适应性和性能表现。
# 524. `cs.LG` - 基于Transformer的手写识别系统联合使用在线和离线特征 [PDF](https://arxiv.org/pdf/2506.20255), [HTML](https://arxiv.org/abs/2506.20255)
## Authors
Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal
## Background
大多数手写识别系统仅利用单一模态（如离线图像或在线笔迹数据），而本文认为手写识别可以从二者融合中获益，一是离线图像中的复杂字形补充信息，二是在线笔迹数据中的轨迹信息。本文探讨了如何将离线图像和在线笔迹数据在一个共享潜在空间中进行早期融合的方法。
## Innovation
本文提出了一种端到端的网络，该网络可以在共享潜在空间中对离线图像和在线笔迹数据进行早期融合。通过使用patch编码器将灰度剪辑转换为固定长度的视觉标记，并利用轻量级的变压器嵌入笔迹序列，实现了可学习的潜在查询同时关注两个标记流，生成上下文增强的笔迹嵌入，并在交叉熵损失目标下池化和解码。这种方法在集成前就利用了时间线索，从而在表示学习过程中增强了作者独立性，从而提升了识别准确性。
## Conclusion
在IAMOn-DB和VNOn-DB上的全面实验结果表明，本文提出的方法达到了最先进的准确性，比之前的最佳结果提高了高达1%。此外，通过使用ISI-Air数据集的动画化，本文还展示了该管道的适应性。
# 525. `cs.LG` - 利用轻量级分层ViT和动态框架进行高效视觉跟踪 [PDF](https://arxiv.org/pdf/2506.20381), [HTML](https://arxiv.org/abs/2506.20381)
## Authors
Ben Kang,Xin Chen,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu
## Background
基于Transformer的视觉跟踪器在能力上取得了显著进步，但由于其处理速度慢的问题，在资源受限的设备上应用受到了限制。
## Innovation
提出了HiT，这是一种新颖的高效视觉跟踪模型系列，其核心创新在于Bridge Module，将轻量级变压器连接到跟踪框架中，提高特征表示质量。此外，还引入了双图像位置编码方法以有效编码空间信息。另外，DyHiT是一种高效动态跟踪器，通过选择具有不同计算需求的路由来灵活适应场景复杂性，并采用分而治之的策略以实现准确性和速度的优化平衡。还提出了一种无需训练的加速方法，利用DyHiT的动态路由架构显著提高了高性能跟踪器的执行速度，而无需牺牲准确性。
## Conclusion
HiT在NVIDIA Jetson AGX平台上的速度达到了61帧/秒，AUC为64.6%，超过了所有先前的高效跟踪器。DyHiT在NVIDIA Jetson AGX上最快版本达到了111帧/秒，AUC为62.4%。我们的加速方法使得SeqTrack-B256在NVIDIA GeForce RTX 2080 Ti GPU上速度提高了2.68倍，AUC仍保持69.9%。
# 526. `cs.LG` - 特征幻觉增强的自我监督动作识别 [PDF](https://arxiv.org/pdf/2506.20342), [HTML](https://arxiv.org/abs/2506.20342)
## Authors
Lei Wang,Piotr Koniusz
## Background
理解视频中人的动作不仅需要像素层面的分析，还需要高层次的语义推理以及多模态特征的有效整合。现有研究大多集中在像素层面，缺乏对高层次语义信息和多模态特征的充分利用，因此需要一种能够提高动作识别准确性的框架。该研究提出了深度平移动作识别框架，通过联合预测RGB视频帧的动作概念和辅助特征来增强识别准确性。引入了两种新型领域特定描述符：对象检测特征（ODF）和注意检测特征（SDF），以聚焦于动作相关区域，而不仅仅是像素本身。这些描述符与光学流、密集轨迹、骨架数据和音频线索等辅助模态无缝集成，保持与最新架构如I3D、AssembleNet、Video Transformer Network等的兼容性。
## Innovation
该研究创新地提出了一种深度平移动作识别框架，通过联合预测动作概念与辅助特征来增强识别准确性。引入了两种新型领域特定描述符，即对象检测特征ODF和注意检测特征SDF，用于聚焦动作相关区域。此外，该框架通过引入aleatoric不确定性建模在幻觉步骤中处理辅助特征的不确定性，并引入了具有鲁棒性的损失函数来减轻特征噪声。这些创新使得框架能够有效捕获动作的细微动态，在多个基准测试中的性能达到了最新水平。
## Conclusion
该框架在多个基准测试中达到了最先进的性能，包括Kinetics-400、Kinetics-600和Something-Something V2，证明了其在捕捉动作细微动态方面的有效性。
# 527. `cs.LG` - POLAR: 一种悲观模型基础的策略学习算法用于动态治疗方案 [PDF](https://arxiv.org/pdf/2506.20406), [HTML](https://arxiv.org/abs/2506.20406)
## Authors
Ruijia Zhang,Zhengling Qi,Yue Wu,Xiangyu Zhang,Yanxun Xu
## Background
动态治疗策略（DTRs）为优化随时间变化适应个体轨迹的决策提供了原理性的框架，广泛应用于医疗、教育和数字干预等领域。现有的统计方法依赖于强烈的方向性假设，对数据覆盖不足的情况缺乏鲁棒性。基于离线增强学习的方法则通常关注平均训练性能，缺乏统计保证，且需要解决复杂的优化问题。为解决上述问题，本文提出了POLAR，一种新型悲观模型化策略学习算法，用于离线DTR优化。POLAR能够从离线数据中估计转换动力学，并量化每个历史行动对的不确定性。接着，通过加入悲观惩罚项到奖励函数中，避免高未确定性行动。不同于大多数其他专注于平均训练性能的方法，POLAR直接针对最终学习策略的次优性，并提供理论保证，无需依赖耗时的最小极大或约束最优化程序。据我们所知，POLAR是首个提供统计和计算保证的基于模型的DTR方法，包括政策次优性的样本极限上界。
## Innovation
本文提出的一种新型悲观模型化策略学习算法（POLAR），用于离线DTR优化。POLAR能够从离线数据中估计转换动力学，并量化每个历史行动对的不确定性。通过引入悲观惩罚项到奖励函数中，鼓励避免具有高未确定性的行动，直接关注减小最终学习策略的次优性。POLAR通过提供统计和计算保证，包括对政策次优性的样本极限上界，是首个此类方法。
## Conclusion
通过实证结果表明，在合成数据和MIMIC-III数据集上，POLAR在性能上优于现有最先进的方法，并产生了几乎最优且历史意识强的治疗策略。
# 528. `cs.LG` - HiWave：基于小波的扩散采样实现无训练高分辨率图像生成 [PDF](https://arxiv.org/pdf/2506.20452), [HTML](https://arxiv.org/abs/2506.20452)
## Authors
Tobias Vontobel,Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber
## Background
扩散模型在图像合成中表现出色，但在高分辨率下的训练极为耗时，且现有超越训练分辨率的零样本生成技术常常产生物体重复和空间不一致的伪影。现有的方法无法在高分辨率图像合成中保持良好的视觉真实性和结构一致性，因此需要新的方法来解决这些问题，提升高分辨率图像合成的质量。
## Innovation
HiWave通过一个无需训练的零样本方法，利用预训练的扩散模型生成高质量的超高清图像，并采用一种新颖的基于小波的细节增强模块，在两阶段管道中先生成基础图像，然后是分块DDIM反变换步骤。此方法在保障结构一致性的同时，通过选择性地指导高频分量丰富细节，从而大幅改进了视觉保真度和结构的一致性。特别是在使用Stable Diffusion XL进行评估时，HiWave能有效地减少以往方法的视觉伪影，实现了更好的感知质量，且用户研究证实了其在质量上的优越性，远优于最先进的替代方法。
## Conclusion
HiWave方法在无需重新训练或结构调整的情况下，能够实现高质量的高分辨率图像合成，有效地解决了视觉伪影问题，展示了其在无训练高分辨率图像生成方面的有效性。
# 529. `cs.LG` - 未被识别且混淆？理解两塔模型以实现无偏的排序学习 [PDF](https://arxiv.org/pdf/2506.20501), [HTML](https://arxiv.org/abs/2506.20501)
## Authors
Philipp Hager,Onno Zoeter,Maarten de Rijke
## Background
两塔模型作为一种学习排序的方法，在处理行业中的偏倚用户反馈时非常流行。然而，最近的研究发现，将两塔模型训练在表现良好的生产系统中收集的点击数据上会导致排序性能下降。这种现象背后的原因可能是日志策略的混杂效应和模型识别问题。论文分析了两塔模型的识别条件，发现需要文档位置的交换或特征分布的重叠才能从点击数据中恢复模型参数。同时，研究了日志策略对两塔模型的影响，发现当模型完全捕捉用户行为时，日志策略不会引入偏差，但在模型不完全捕捉用户行为时，日志策略会放大偏差，尤其是在预测错误与文档在不同位置的排列相关时。
## Innovation
论文深入探讨了两塔模型识别条件，提出了样本加权技术以减轻这些效应的影响，并提供了针对使用两塔模型的研究人员和实践者的实用建议。
## Conclusion
两塔模型的识别问题和日志策略可能导致排序性能下降，但可以通过样本加权技术减轻其影响。
# 530. `cs.LG` - InvZW: 基于噪声对抗训练的不变特征学习稳健图像零水印 [PDF](https://arxiv.org/pdf/2506.20370), [HTML](https://arxiv.org/abs/2506.20370)
## Authors
Abdullah All Tanvir,Xin Zhong
## Background
本文介绍了一种基于抗扭曲特征学习的新型深度学习框架，用于稳健的图像零水印。零水印方案的目的是在不改变原始图像的情况下，学习一个参考签名，并通过特征空间中的优化实现这一点。作者通过噪声对抗学习训练特征提取器，生成既抗扭曲又语义丰富的表征。该框架包括两个关键模块：一个用于生成抗扭曲且语义丰富的特征提取器模块；另一个用于基于训练的多比特零水印方案，其中抗扭曲的特征被投影到一组可训练的参考代码上，以匹配目标二进制消息。实验表明，该方法在特征稳定性和水印恢复方面取得了最先进的稳健性，与现有的自监督和深度水印技术相比，在泛化和稳健性方面也表现更为优越。
## Innovation
该论文提出了基于噪声对抗训练的不变特征学习的新型深度学习框架，用于稳健的图像零水印。特征提取器通过噪声对抗学习训练，生成既抗扭曲又语义丰富的表征。这种方法进一步设计了一个基于学习的多比特零水印方案，其中抗扭曲的特征被投影到一组可训练的参考代码上，以匹配目标二进制消息。该方法在特性稳定性和水印恢复方面表现优越，具有广泛的广泛应用前景。
## Conclusion
实验结果表明，所提出的方法在多项测试中都达到了最先进的稳健性性能，特别是在特征稳定性和水印恢复方面。与现有技术相比，该方法展示了其在泛化和稳健性方面的优越性，为图像零水印领域的研究提供了新的见解。
# 531. `cs.LG` - OptoThinker: 中期训练激励强化学习扩展 [PDF](https://arxiv.org/pdf/2506.20512), [HTML](https://arxiv.org/abs/2506.20512)
## Authors
Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu
## Background
不同的基础语言模型（如Llama和Qwen）在强化学习（RL）后训练过程中表现出不同的行为，特别是在需要强烈推理的任务上。对于基础语言模型是否适用于强化学习这一问题，有必要进行深入研究，以开发适用于下一代的RL可扩展的基础模型。本文研究了中期训练策略如何影响强化学习动态，特别是针对两种代表模型家族：Qwen和Llama。研究表明：高质量的数学语料库显著改善了基础模型和强化学习的表现，而现有替代方法（如FineMath-4plus）未能实现这一效果；添加问答风格的数据，尤其是长链推理示例，增加了强化学习的效果，指示语数据进一步加剧了这一效果；虽然长链推理提高了推理深度，但也可能导致模型响应的冗长和RL训练的不稳定性，强调了数据格式化的重要性；中期训练的一致扩展增强了下游强化学习的表现。基于上述研究成果，引入了一种两阶段中期训练策略，即稳定后衰减法（Stable-then-Decay），首先在200B令牌上进行训练，学习率保持不变，然后在三个聚焦链推理的分支上进行20B令牌的训练，学习率衰减。这些策略催生了OptoThinker这一系列表现出色对强化学习兼容的基础模型，缩小了其与更具RL友好性的模型家族（如Qwen）之间的性能差距。希望我们的工作能帮助制定强化学习时代的基础上训练策略，并发布了超过700亿令牌的精心编排的数学推理密集语料库以及开源模型以支持进一步的研究。
## Innovation
研究展示了如何通过对中期训练策略的优化，不仅提高了强化学习的效果，还细化和整理了数学推理中的相关数据，提出了一种两阶段中期训练策略——稳定后衰减法，该方法显著增强了基础模型在强化学习中的表现，并发布了一个包含超过700亿令牌的精心编排的数学推理密集语料库。
## Conclusion
通过引入两阶段中期训练策略，即稳定后衰减法，衍生了OptoThinker模型，该系列模型在强化学习方面表现出出色的兼容性，并接近甚至超越更适合强化学习的模型家族（如Qwen）的性能，从而为未来的模型设计提供了有价值的见解，并提供了数学推理密集的语料库和开源模型以支持进一步研究。
# 532. `cs.LG` - WattsOnAI:测量、分析和可视化AI工作负载的能源和碳足迹 [PDF](https://arxiv.org/pdf/2506.20535), [HTML](https://arxiv.org/abs/2506.20535)
## Authors
Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang
## Background
AI，尤其是大规模语言模型（LLMs），的发展迅速，引起了人们对模型训练和推理过程中能源使用和碳排放的重大关注。然而，现有的测量和报告这些影响的工具通常是分散的，缺乏系统性指标整合，且提供了有限的支持用于相关性分析。
## Innovation
该论文提出了WattsOnAI，一个全面的软件工具包，用于测量、分析和可视化跨越AI工作负载的能源使用、功率消耗、硬件性能和碳排放。它通过与现有AI框架无缝集成，提供标准化报告，并将细粒度的时间序列数据导出以支持轻量级基准测试和可重复性。此外，它还能够进行硬件指标与模型性能之间的深入相关性分析，从而有助于瓶颈识别和性能提升。通过解决现有工具的关键限制，WattsOnAI鼓励研究社区在更多考虑环境影响的同时来衡量AI工作负载的原生性能，并推动向更加可持续的“绿色AI”实践的转型。
## Conclusion
WattsOnAI通过全面的测量、分析和可视化AI工作负载的能源和碳足迹，填补了现有工具的空白，促进AI的可持续发展。它鼓励研究社区不仅关注AI的原生性能，还关注其对环境的影响，并推动“绿色AI”的实践。
# 533. `cs.LG` - Fast ground penetrating radar dual-parameter full waveform inversion method accelerated by hybrid compilation of CUDA kernel function and PyTorch [PDF](https://arxiv.org/pdf/2506.20513), [HTML](https://arxiv.org/abs/2506.20513)
## Authors
Lei Liu,Chao Song,Liangsheng He,Silin Wang,Xuan Feng,Cai Liu
## Background
研究背景在于GPR（地下雷达）数据的高性能全波形反演(FWI)方法的需求，尤其是在需要同时反演介电常数和电导率的情况下。现有的FWI方法通常在计算效率和编程灵活性之间存在权衡，而在Python深度学习框架中实现的灵活性和便利性往往牺牲了计算效率。因此，该研究旨在提出一种结合CUDA内核函数混合编译和PyTorch的高性能FWI框架，以提升GPR数据的FWI性能，并保持编程语言的灵活性和便捷性。
## Innovation
该研究创新点在于提出了一种高性能的双参数全波形反演框架，通过CUDA内核函数与PyTorch的混合编译加速计算，同时利用GPU编程的高效性和基于Python的深度学习框架的灵活性和易用性。通过将定制的CUDA内核集成到PyTorch的自动微分机制中，该框架能够同时准确地反演介电常数和电导率。此外，该框架灵活且可扩展，支持诸如总计变和多尺度反演等可选正则策略，从而具备快速的地下成像能力，适用于基础设施工程、环境监测和地质勘探等领域。
## Conclusion
研究结论表明，提出的双参数FWI方法在合成数据和真实波场数据上获得了高性能，同时具备高准确性。此外，该框架具备灵活性和可扩展性，支持多种正则化策略，使其成为一种适应性强且可扩展的GPR基地下成像框架，适用于工程、环境和地质领域。
# 534. `cs.LG` - 通过启用闭环协同控制提高风力发电厂电力生产效率的增强学习 [PDF](https://arxiv.org/pdf/2506.20554), [HTML](https://arxiv.org/abs/2506.20554)
## Authors
Andrew Mole,Max Weissenbacher,Georgios Rigas,Sylvain Laizet
## Background
传统的风力发电场控制是独立地操作每个风力涡轮机以最大化个体电力输出。然而，整个风力发电场范围内的协调尾流导向可显著提高联合风力发电场的能源产量。尽管动态闭环控制在流动控制应用中已被证明是有效的，风力发电场优化仍主要依赖于静态、低精度模拟器，这些模拟器忽略了关键的湍流流动动力学。
## Innovation
本文提出了第一个将强化学习（RL）控制器直接集成到高精度大涡模拟（LES）中的方法，通过协作、动态控制策略实现实时对大气湍流的响应。相比基准操作，RL 控制器实现了4.30%的风力发电场电力输出增加，几乎是静态最优风向控制（通过贝叶斯优化获得的2.19%增益）的两倍。这些结果确立了动态流动响应控制作为风力发电场优化的一种变革性方法，对加速可再生能源部署以实现净零目标具有直接影响。
## Conclusion
动态流动响应控制是前所未有的提高风力发电场生产效率的方法，证实了这种控制策略在实时应对大气湍流方面具有显著优势。
# 535. `cs.LG` - Iteratively Reweighted Least Squares for Robust Subspace Recovery [PDF](https://arxiv.org/pdf/2506.20533), [HTML](https://arxiv.org/abs/2506.20533)
## Authors
Gilad Lerman,Kang Li,Tyler Maunu,Teng Zhang
## Background
鲁棒子空间估计是许多机器学习和数据分析任务的基础。迭代重新加权最小二乘法（IRLS）是解决这个问题的一个优雅且经验上有效的手段，但其理论性质尚未完全理解。
## Innovation
本文在确定性条件下证明，带有动态平滑正则化的IRLS变体可以从任何初始化线性收敛到潜在子空间。此外，本文还为仿射子空间估计提供了解恢复理论上的保证，并通过低维度神经网络训练展示了IRLS的实际优势。这是首次为鲁棒子空间恢复提供全局收敛保证，也是首个关于非凸IRLS在黎曼流形上的全局收敛保证的结果。
## Conclusion
本文的成果为IRLS在鲁棒子空间恢复中的全局收敛性提供了理论支持，并扩展了此类问题的理论框架。
# 536. `cs.LG` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大语言模型（LLMs）在代码生成方面表现出色，但在应对外部库API的频繁更新时却能力有限。这一关键限制源于LLMs对训练数据中过时的API知识的依赖，即使有当前文档资料参考，也可能阻碍其在动态环境中的可靠代码生成。为解决这一问题，本研究提出ReCode（基于规则的强化学习代码更新框架），该框架模仿了人类程序员适应API变更的方式。针对此问题，通过构建约2000个数据条目来训练LLMs，使其基于更新信息执行版本迁移。
## Innovation
ReCode框架采用基于规则的强化学习方法来帮助LLMs适应API变更。具体做法是构建一个包含约2000条数据集来训练LLMs进行版本迁移，并引入修改后的字符串相似度度量作为强化学习的奖励。实验结果显示，ReCode显著提升了LLMs在动态API场景下的代码生成性能，特别是在CodeUpdateArena任务中表现尤为突出。同时，ReCode在提升LLMs代码生成能力方面的影响小于监督微调。ReCode在多个LLMs和强化学习算法（GRPO和DAPO）上均取得了一致的改进效果，训练后的Qwen2.5-Coder-7B模型相较于32B参数代码指令调优模型和相同架构的推理模型表现更佳。相关代码已开源。
## Conclusion
ReCode在动态API场景下的代码生成能力提升方面表现优异，并且对LLMs的一般代码生成能力影响较小，多款LLMs在ReCode框架下都获得了改进。经过训练后，Qwen2.5-Coder-7B模型表现出色，优于其他同类模型。相关代码已在GitHub上开源。
# 537. `cs.LG` - 基于观察分组的因果表征学习在肺部X光分类中的应用 [PDF](https://arxiv.org/pdf/2506.20582), [HTML](https://arxiv.org/abs/2506.20582)
## Authors
Rajat Rasal,Avinash Kori,Ben Glocker
## Background
因果表征学习旨在揭示数据生成过程中真正的因果关系。在医学影像领域，这种表征学习能力提升了任务特定隐变量的一般性和鲁棒性。本文通过端到端框架提出了一个通过分组观察来学习可识别表征的概念，用于基于胸部X光的疾病分类
## Innovation
本文提出了一种新的因果表征学习框架，通过分组观察来学习可识别的表征，以提高胸部X光疾病分类任务中的鲁棒性和一般性，特别关注性别、种族和影像视角的不变性
## Conclusion
实验表明，通过这种方式学习的因果表征改善了多种分类任务的鲁棒性和一般性。
# 538. `cs.LG` - 解构的显微图像表示 [PDF](https://arxiv.org/pdf/2506.20649), [HTML](https://arxiv.org/abs/2506.20649)
## Authors
Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone
## Background
显微镜图像分析在诊断、合成工程和环境监测等多个应用中至关重要。现代图像获取系统使得可以获取越来越多的图像，为此需要开发大量的深度学习为基础的自动图像分析方法。尽管深度神经网络在这一领域已经展示了优异的性能，但对于显微镜图像分析而言，可解释性仍然是一个开放的挑战。
## Innovation
该研究提出了一种解纠缠表示学习(DRL)方法，用于提高显微镜图像分类模型的可解释性。通过利用来自三个不同显微成像领域（浮游生物、酵母细胞囊泡和人类细胞）的基准数据集，展示了基于从合成数据学习的表示迁移的DRL框架可以在保持较高准确率的同时提供良好的可解释性。
## Conclusion
研究表明，DRL框架能够为显微镜图像分析提供一个准确性和可解释性之间的良好平衡。
# 539. `cs.LG` - 在广义线性混合模型中可扩展的子集选择 [PDF](https://arxiv.org/pdf/2506.20425), [HTML](https://arxiv.org/abs/2506.20425)
## Authors
Ryan Thompson,Matt P. Wand,Joanna J. J. Wang
## Background
线性混合模型（LMMs）结合了固定效应和随机效应，成为分析异质数据的关键工具，例如在个性化医疗或适应性营销中的应用。随着数据的增加，数据集可能包含数千个候选预测因子，需要稀疏模型来实现预测和解释，但是现有的LMM稀疏学习方法难以扩展到数百个预测因子以上，效率远低于忽略随机效应的线性模型中使用的稀疏方法。本文通过引入新的基于$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{0}}}}}}}$正则化的子集选择方法解决了这一问题，该方法能在几秒到几分钟内处理数千个预测因子的数据集。本文从计算和统计两个方面介绍了上述方法，为确保算法收敛性，开发了坐标下降算法，并通过局部搜索算法帮助穿越非凸优化表面，在广义LMMs中进行子集选择时，算法同样易于扩展。此外，还给出了新方法的有限样本Kullback-Leibler散度上线。该方法在合成实验和生物学以及新闻数据集上的表现优良，验证了其效果。
## Innovation
提出了新的基于$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{0}}}}}}}$正则化的LMM稀疏优化方法，能够在几秒到几分钟内处理数千个预测因子的数据集，填补了LMM稀疏学习方法在处理大规模预测因子时的空白。此外，开发了坐标下降算法，提供了算法收敛性保证，开发了局部搜索算法来优化非凸优化问题。并将算法推广到广义LMMs中。
## Conclusion
通过新方法，实现了LMMs中数千维度数据的高效稀疏子集选择，于计算和统计两方面均有所突破，提供了理论保证并验证了其在多种实际数据集中的有效性和优越性。
# 540. `cs.LG` - Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks [PDF](https://arxiv.org/pdf/2506.20548), [HTML](https://arxiv.org/abs/2506.20548)
## Authors
Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao
## Background
随着深度学习的迅速发展，特别是在生成对抗网络（GANs）和扩散模型（DMs）的影响下，AI生成的图像（即“深度伪造”）变得几乎无法与真实图像区分开来。这些图像在社交网络上广泛传播，引发了对其误用的担忧。现有的深度伪造检测方法忽略了社交网络中压缩引入的“块效应”，这种效应掩盖了深度伪造的特征，而主要关注的是原始图像，而在现实场景中这些图像很少出现。现有的方法并未充分考虑这些挑战，特别是在处理受限的成对数据和压缩图像时表现不足。
## Innovation
本文提出了一种新颖的框架——PLADA（Pay Less Attention to Deceptive Artifacts），旨在解决缺乏成对数据和无效利用压缩图像的问题。PLADA包括两个核心模块：块效应消除器（B2E），使用双阶段注意机制来处理块效应；开放数据聚合器（ODA），可以处理成对和非成对数据，以改善检测效果。实验结果表明，PLADA在检测社交网络上的深度伪造方面表现优异，即使在成对数据有限和存在压缩的情况下，其检测能力也优于现有方法。这项工作引入了“块效应”作为深度伪造检测中的关键因素，为开放场景提供了一个稳健的解决方案。
## Conclusion
通过广泛实验，PLADA在检测社交网络上的深度伪造方面取得了显著成果，尤其在处理受限的成对数据和压缩图像时。这证明了“块效应”在深度伪造检测中的关键作用，为开放场景下的深度伪造检测提供了强大的解决方案。我们的代码已公开可供访问。
# 541. `cs.LG` - 朝向社区驱动的机器学习工程代理 [PDF](https://arxiv.org/pdf/2506.20640), [HTML](https://arxiv.org/abs/2506.20640)
## Authors
Sijie Li,Weiwei Sun,Shanda Li,Ameet Talwalkar,Yiming Yang
## Background
大语言模型（LLM）驱动的机器学习（ML）代理已经显示出在自动化ML研究方面的巨大潜力。然而，现有的代理通常仅在特定的研究问题上单独运作，而不与更广泛的研究社区互动，而在研究社区，人类研究人员往往通过分享知识获益并获得洞察。为了弥合这一差距，作者引入了MLE-Live，这是一个实时评估框架，旨在评估代理与模拟的Kaggle研究社区进行沟通并利用集体知识的能力。在此基础上，作者提出了CoMind，这是一种新的人工智能代理，特别在社区环境下交换洞察并开发新解决方案方面表现出色。研究结果表明，CoMind在MLE-Live上达到了最先进的性能，并且在四个持续的Kaggle竞赛中比平均79.2%的人类对手表现出色。
## Innovation
作者提出了一种名为CoMind的新人工智能代理，该代理在社区环境中表现出色，能够与模拟的Kaggle研究社区进行沟通并利用集体知识。CoMind在四个持续的Kaggle竞赛中优于79.2%的人类竞争者，并在MLE-Live上达到了最先进的性能。
## Conclusion
作者提出了一种新的实时评估框架MLE-Live，旨在评估代理在与模拟的Kaggle研究社区沟通和利用集体知识方面的表现。在此基础上，他们进一步开发了CoMind，该代理在实际的应用场景中表现出色，并在多个Kaggle竞赛中达到或超过人类竞争者的性能水平。作者承诺将代码开源，以便其他研究者进行进一步的研究和改进。
# 542. `cs.LG` - 可解释强化学习综述：概念、算法、挑战 [PDF](https://arxiv.org/pdf/2211.06665), [HTML](https://arxiv.org/abs/2211.06665)
## Authors
Yunpeng Qing,Shunyu Liu,Jie Song,Huiqiong Wang,Mingli Song
## Background
强化学习（RL）是一种流行的机器学习范式，其中智能代理与环境交互以实现长期目标。深度强化学习（DRL）由于深度学习的复兴，在复杂控制任务中取得了显著的成功。尽管取得了鼓舞人心的结果，基于深度神经网络的骨干网络通常被视为黑盒，阻碍了实践者在需要高安全性和可靠性的现实场景中信任和部署训练好的代理。
## Innovation
本文提供了可解释强化学习（XRL）的全面综述，并提出了一个新的分类体系，将此前的工作明确地分为模型解释、奖励解释、状态解释和任务解释方法。此外，还回顾了利用人类知识促进学习效率和代理性能的方法，这些方法在XRL领域经常被忽视。讨论了XRL中的挑战和机遇，旨在提供XRL的高层次总结，并激发更有效的XRL解决方案的研究。
## Conclusion
本文旨在为XRL提供高层次的总结，并激励未来在更有效的XRL解决方案方面的研究。相关的开源代码被收集和分类在该网址：this https URL.
# 543. `cs.LG` - 长时依赖网络中的时间反向传播 [PDF](https://arxiv.org/pdf/2103.15589), [HTML](https://arxiv.org/abs/2103.15589)
## Authors
George Bird,Maxim E. Polivoda
## Background
时间反向传播（BPTT）是一种更新循环神经网络（RNN）中调优参数的技术。已经尝试创建类似算法的方法包括N次序近似和截断-BPTT。这些方法在假设RNN仅使用短时依赖的情况下近似反向传播梯度。此假设对于当前的人工神经网络状态而言是可以接受的。随着RNN变得更加先进，考虑长时依赖的影响变得更为重要。因此，需要一种新的反向传播方法。当前的方法在某些情况下无法完全捕捉长程依赖，需要一种新的、精确的方法来更新参数并允许它们在每一步之间变化，但计算雅可比矩阵是必要的。
## Innovation
本文提出了一种使用“离散前向灵敏度方程”及其变体的方法，用于单个和多个相互作用的循环环路。该方法是精确的，并允许网络参数在每个后续步骤之间变化，但需要计算雅可比矩阵。这是对现有截断-BPTT方法的改进，可以在处理长时依赖时更为精确和有效。
## Conclusion
研究提出了一种新的反向传播方法，其能够精确更新循环神经网络参数，并处理长时依赖问题，但计算雅可比矩阵是必要的。未来进一步优化算法，减少计算复杂度，具有重要的研究意义。
# 544. `cs.LG` - 具有确定性约束条件的随机和有限和凸优化的一阶方法 [PDF](https://arxiv.org/pdf/2506.20630), [HTML](https://arxiv.org/abs/2506.20630)
## Authors
Zhaosong Lu,Yifeng Xiao
## Background
本文研究了一类具有确定性约束条件的随机和有限和凸优化问题。现有的方法通常旨在找到一个$boldsymbol{text{ε-期望可行的随机最优解}}$，其中期望的约束违反和期望的最优性缺口都在预定的$boldsymbol{text{ε}}$容差范围内。然而，在许多实际应用中，约束必须几乎确定地满足，使得这种解可能因可能的显著违反而变得不合适。为解决这一问题，本文提出了寻找一个$boldsymbol{text{ε-绝对可行的随机最优解}}$($boldsymbol{text{ε-SFSO}}$)的方法，其中约束违反是确定性地受到$boldsymbol{text{ε}}$的限制，且期望的最优性缺口最多为$boldsymbol{text{ε}}$。提出的方法仅对适当选择的惩罚参数序列的一系列二次惩罚子问题应用一次加速随机梯度（ASG）方案或修正的方差减小ASG方案。建立了提出方法在计算$boldsymbol{text{ε-SFSO}}$解的一阶先验复杂性界。作为副产品，还使用提出的这些方法计算了样本均值逼近方法中随机优化问题的$boldsymbol{text{ε-SFSO}}$解的一阶先验复杂性结果。
## Innovation
提出了一种解决具有确定性约束条件的随机和有限和凸优化问题的方法，找到了一个$boldsymbol{text{ε-SFSO}}$解，即约束违反确定性地受到$boldsymbol{text{ε}}$的限制，且期望的最优性缺口最多为$boldsymbol{text{ε}}$。该方法仅对适当选择的惩罚参数序列的一系列二次惩罚子问题应用一次加速随机梯度（ASG）方案或修正的方差减小ASG方案。
## Conclusion
提出了计算具有确定性约束条件的随机和有限和凸优化问题的$boldsymbol{text{ε-SFSO}}$解的第一阶先验复杂性界，还给出了使用提出的这些方法计算样本平均逼近方法中随机优化问题的$boldsymbol{text{ε-SFSO}}$解的一阶先验复杂性结果。
# 545. `cs.LG` - 通过将数据转换为与偏差正交实现反事实公平 [PDF](https://arxiv.org/pdf/2403.17852), [HTML](https://arxiv.org/abs/2403.17852)
## Authors
Shuyi Chen,Shixiang Zhu
## Background
机器学习模型在解决各种领域中的复杂问题方面表现出色。然而，这些模型有时会表现出偏差的决策倾向，导致不同群体受到不平等待遇。尽管已经进行了大量的研究来解决反事实公平性，但在减少多变量和连续敏感变量对决策结果影响的方法方面仍存在不足。
## Innovation
提出了一个新的数据预处理算法OB（Orthogonal to Bias），旨在消除一组连续敏感变量的影响，从而在机器学习应用中促进反事实公平。该方法基于结构因果模型（SCM）内联合正态分布的假设，通过确保数据与已观察到的敏感变量正交来实现反事实公平。OB算法具有模型通用性，使其适用于多种机器学习模型和任务，同时还包括一种稀疏变体，通过正则化提高数值稳定性。
## Conclusion
对模拟和真实世界数据集（包括离散和连续敏感变量情况下的设置）的实证评估表明，本方法能够有效促进更公平的结果，而不牺牲准确性。
# 546. `cs.LG` - Bilinear MLPs 使权重为基础的机械解释成为可能 [PDF](https://arxiv.org/pdf/2410.08417), [HTML](https://arxiv.org/abs/2410.08417)
## Authors
Michael T. Pearce,Thomas Dooms,Alice Rigg,Jose M. Oramas,Lee Sharkey
## Background
当前对多层感知机（MLP）在深度神经网络中如何进行计算的理解仍然不够深入。尽管已有解释性工作的进展能够从输入数据集的隐藏激活中提取特征，但通常无法解释MLP权重如何构建这些特征。主要挑战在于元素级非线性引入了高阶交互，使得通过MLP层追踪计算变得困难。
## Innovation
本文分析了一种没有元素级非线性但仍然能实现竞争力性能的双线性MLP。通过采用第三阶张量，双线性MLP的权重可以完全用线性操作来表达，从而便于灵活分析。通过对双线性MLP权重的特征值进行分解，揭示了它在玩具任务、图像分类和语言建模中的可解释低秩结构。利用这种理解，我们能够构建对抗样本、发现过拟合现象，并从权重本身直接识别小语言模型电路。这表明双线性层可以作为当前激活函数的可解释替代品，基于权重的解释对理解深度学习模型是可行的。
## Conclusion
我们的结果表明，双线性层作为一个可解释的替代品，可以替代当前的激活函数，并且基于权重的解释对于理解深度学习模型是可行的。
# 547. `cs.LG` - 概念瓶颈模型是否尊重局部性？ [PDF](https://arxiv.org/pdf/2401.01259), [HTML](https://arxiv.org/abs/2401.01259)
## Authors
Naveen Raman,Mateo Espinosa Zarlenga,Juyeon Heo,Mateja Jamnik
## Background
概念基于的可解释性方法利用人类可理解的中介来为机器学习模型提供解释。这些方法假设概念预测有助于理解模型的内部推理过程。本文通过分析概念预测器是否利用了“相关”特征来进行预测，这一过程称为局部性，来评估这种假设的真实性。概念预测器如果不能尊重局部性，则无法提供可解释性，因为基于无效特征的概念预测使概念预测的解释变得空洞。本文构建并使用了三个度量标准来描述模型何时尊重局部性，同时通过理论结果补充其分析。这些度量标准捕捉了不同的扰动概念并评估了“无关”特征的扰动是否会影响概念预测器的预测结果。多个实践中使用的概念基于模型因无法清晰地区分不同的概念而未能尊重局部性。
## Innovation
本文提出了一种通过构建三个度量标准来评估概念预测器是否尊重局部性的方法。这些度量标准能够捕捉不同类型的概念扰动，并验证无关特征的扰动是否会改变概念预测器的预测结果。同时，根据这些发现，提出缓解此问题的建议。
## Conclusion
许多实际使用的概念基于模型未能尊重局部性，因为概念预测器难以清晰地区分不同的概念。基于这些发现，建议解决这一问题。
# 548. `cs.LG` - 无需梯度的切割平面方法在深度神经网络中的主动学习 [PDF](https://arxiv.org/pdf/2410.02145), [HTML](https://arxiv.org/abs/2410.02145)
## Authors
Erica Zhang,Fangzhao Zhang,Mert Pilanci
## Background
主动学习方法旨在通过减少训练样本数量来提高机器学习中的样本复杂性。现有研究表明，传统的活动学习方案通常在处理深度神经网络时遇到挑战，因为这类网络的高度非凸性和非线性决策边界使其难以被传统的线性模型中的切割面算法直接处理。因此，尽管已有活动学习方案在传统模型上的成功应用，但在深度神经网络中的扩展受到限制。
## Innovation
本文提出了一个创新的无梯度切割面训练方法，用于任意深度的ReLU网络，并构建了相应的收敛理论。这是首次将切割面算法扩展应用于深度神经网络，揭示了可行集的几何收缩速率。此外，这种方法提供了首次具有收敛保证的深度神经网络中活动学习方案，证明了即使在网络结构复杂的情况下也能有效收敛。
## Conclusion
通过合成数据实验与真实情感分类任务，本文证明了所提出的无梯度切割面方法在深度神经网络中的有效性和优势，相比流行的活性学习基准方案更为有效。
# 549. `cs.LG` - 使用参数化量子电路进行声音情感识别的表示学习 [PDF](https://arxiv.org/pdf/2501.12050), [HTML](https://arxiv.org/abs/2501.12050)
## Authors
Thejan Rajapakshe,Rajib Rana,Farina Riaz,Sara Khalifa,Björn W. Schuller
## Background
量子机器学习（QML）为在复杂信号域中提升表示学习提供了前景。由于语音信号中微妙的时间变化和重叠的情感状态，声音情感识别（SER）是一项具有挑战性的任务。研究表明，参数化量子电路（PQCs）可以用于SER，通过利用量子特性如叠加和纠缠来丰富情感特征表示，从而有可能提高分类性能。
## Innovation
本文提出了一种将PQC与传统卷积神经网络（CNN）结合的混合量子经典架构，该架构利用了量子的性质以增强情感特征表示。实验结果表明，相比纯古典CNN基线模型，该混合模型具有更好的分类性能，且训练参数减少了50%以上，证明了QML在情感识别中的潜在应用价值。
## Conclusion
本研究提供了QML在情感识别中潜在增强的初步证据，并为未来量子赋能的情感计算系统奠定了基础。
# 550. `cs.LG` - DemoDiffusion：预训练扩散策略下的单次人类模仿 [PDF](https://arxiv.org/pdf/2506.20668), [HTML](https://arxiv.org/abs/2506.20668)
## Authors
Sungjae Park,Homanga Bharadhwaj,Shubham Tulsiani
## Background
本文提出了DemoDiffusion，一种简单且可扩展的方法，利用单个人类演示进行模仿，使机器人能够在自然环境中执行操作任务。该方法基于两个关键见解。首先，人类演示中的手部运动为机器人末端执行器轨迹提供有用的先验知识，可以通过运动学重定位转换成初步的开环机器人运动轨迹。其次，尽管运动轨迹捕捉了任务的整体结构，但可能与具体的机器人操作不完全匹配。为了解决这个问题，本文利用预训练的一般扩散策略来修改轨迹，确保该轨迹既遵循人类运动模式，又能保持在可能的机器人操作分布内。该方法避免了在线强化学习或人机配对数据的需求，使机器人能够在新的任务和场景中实现稳健的适应，并且只需少量的手动努力即可实现。实验结果表明，与基线策略和重定位轨迹相比，DemoDiffusion在多种仿真和实际应用场景中表现更优，甚至在预训练的通用策略完全失败的任务中也能成功执行操作任务。
## Innovation
DemoDiffusion创新点在于结合运动学重定位和预训练的通用扩散策略来改进操作轨迹。这种方法不仅能够捕捉人类演示的关键动作，还能确保生成的机器人动作既符合人类动作模式，又在可能的机器人操作分布中。这种创新避免了在线强化学习或人机配对数据的需求，使得机器人能够在新的任务和场景中实现自动和高效的适应。
## Conclusion
实验证明，与基线策略和直接重定位轨迹相比，DemoDiffusion方法表现出更优的性能，尤其是在对预训练的通用策略完全失效的任务中依然能够成功执行。这种方法不仅简化了机器人在自然环境中的操作任务，同时也展示了预训练扩散策略在人机交互领域的巨大潜力。
# 551. `cs.LG` - 联邦学习客户端聚类以适应数据漂移 [PDF](https://arxiv.org/pdf/2411.01580), [HTML](https://arxiv.org/abs/2411.01580)
## Authors
Minghao Li(1),Dmitrii Avdiukhin(2),Rana Shahout(1),Nikita Ivkin(3),Vladimir Braverman(4),Minlan Yu(1) ((1) Harvard University, (2) Northwestern University, (3) Amazon, (4) Johns Hopkins University)
## Background
联邦学习（FL）可以在不集中原始数据的情况下，在边缘设备上训练深度模型，从而保护用户隐私。然而，由于客户端异构性，这会减慢收敛速度并限制全局模型的准确性。通过将具有相似表示的客户端分组并为每个集群训练单独的模型，集群联邦学习（CFL）可以缓解这一问题。然而，客户端数据随时间变化的现象（称为数据漂移）破坏了集群的一致性，并降低了模型性能。数据漂移可以以不同的形式发生，取决于输出值、输入特征或它们之间的关系是否发生变化。在这样的背景下，本文探讨并提出了一个名为FIELDING的新方法，这是一种CFL框架，用于处理不同的数据漂移类型，同时保持较低的开销。
## Innovation
FIELDING框架能够检测客户端中的数据漂移，并执行选择性的重新聚类，以平衡簇质量和模型性能。此外，该方法还对恶意客户端具有鲁棒性，并能在不同水平的异质性中保持稳定。整个过程中，.getFielding能够在较低的开销下高效地处理数据漂移，提升模型性能。
## Conclusion
实验表明，与现有的CFL方法相比，FIELDING可以将最终模型的准确性提高1.9%-5.9%，并且只需现有的方法的1.16-2.23倍时间就能达到目标准确性。
# 552. `cs.LG` - LARP: 跨学习器稳健的数据预筛选 [PDF](https://arxiv.org/pdf/2506.20573), [HTML](https://arxiv.org/abs/2506.20573)
## Authors
Kristian Minchev,Dimitar Iliev Dimitrov,Nikola Konstantinov
## Background
大型公共数据集的广泛可用性是统计推断和机器学习方法近期成功的关键因素。然而，这些数据集往往包含一些低质量或被污染的数据，这些数据对许多学习方法非常敏感。因此，是否以及如何对公共数据集进行预筛选以促进准确的下游学习成为了一个关键问题。技术上，这需要构建通用但稳健的数据预筛选方法，能够保护预指定的一组下游学习器免受被污染数据的影响。本文中，我们正式定义了跨学习者的稳健数据预筛选（LARM）问题，旨在找到能够最小化预指定学习器集中最坏情况损失的预筛选方法。
## Innovation
我们首次在具有Huber污染模型的素数均值估计中实例化了该框架，并提供了特定问题实例的难度结果。我们的理论结果表明，进行跨学习者稳健数据预筛选会导致模型性能相较于每个学习器/应用场景单独进行数据预筛选有所降低。我们通过在真实图像和表格数据上的广泛实验探索了由此导致的实用性损失与其参数的依赖关系，观察到了统计上显著的实用性降低。最后，我们通过博弈论框架建模了由于重复的学习器特定预筛选带来的实用性损失与成本之间的权衡，并展示了大型数据集中的LARM的益处。
## Conclusion
进行跨学习者稳健数据预筛选导致了模型性能相对于每个学习器/应用场景单独进行数据预筛选有所降低。然而，这种做法对于大型数据集而言可以有效减少由于数据污染带来的实用性和性能的降低，因此提出了一种新的数据预筛选方法。
# 553. `cs.LG` - 重思早期停止：先细化，再校准 [PDF](https://arxiv.org/pdf/2501.19195), [HTML](https://arxiv.org/abs/2501.19195)
## Authors
Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach
## Background
机器学习分类器常常生成概率预测，这些预测对于各种领域中的准确和可解释的决策至关重要。这些预测的质量通常使用适当的损失来评估，例如交叉熵，这种损失可以分解为两部分：校准误差评估普遍的欠自信或过自信，而细化误差衡量区分不同类别的能力。本文提出了一种新的校准-细化分解的变分公式，为后处理校准提供了新的视角，并能够快速估计不同组件。利用这一新视角，本文提供了理论和实验证据，表明校准和细化误差在训练期间并不同时最小化。基于验证损失选择最佳时期因此会导致一个对两部分都次优的折衷点。为了应对这一问题，本文提议仅在训练期间最小化细化误差（Refine），然后使用标准技术进行后处理校准（然后校准）。该方法无缝地与任何分类器兼容，并可泛化到各种分类任务中，以提高性能。
## Innovation
本文提出了一个新颖的校准-细化分解的变分公式，使得能够快速估计不同组件。通过这一新视角，本文提供了理论和实验证据表明，校准和细化误差在训练期间并不同时最小化。为了应对这一问题，本文提出了先仅在训练期间最小化细化误差，然后使用标准技术进行后处理校准的方法，这种方法无缝地与任何分类器兼容，并在广泛的分类任务中都能提高性能。
## Conclusion
本文的方法能够在训练期间和训练后分别优化细化误差和校准误差，从而提供比基于验证损失选择最佳时期的更好性能。
# 554. `cs.LG` - 平衡天平：学习不平衡数据的理论和算法框架 [PDF](https://arxiv.org/pdf/2502.10381), [HTML](https://arxiv.org/abs/2502.10381)
## Authors
Corinna Cortes,Anqi Mao,Mehryar Mohri,Yutao Zhong
## Background
在机器学习中，类别不平衡问题仍然是一个主要挑战，特别是在具有长尾分布的多分类问题中。现有的方法，如数据重采样、成本敏感技术和逻辑损失修改，虽然流行且通常有效，但缺乏坚实的理论基础。例如，显示成本敏感方法不具有贝叶斯一致性。该论文提出了一种新的理论框架以分析不平衡分类中的泛化问题。
## Innovation
提出了一种新的类别不平衡边际损失函数，适用于二分类和多分类设置，并证明了其强烈的$H$-一致性，并基于经验损失和一种新的类敏感Rademacher复杂性，推导出相应的学习保证。利用这些理论结果，设计了一种新的泛化学习算法IMMAX（不平衡边际最大化），并将其应用于各种假设集。这些算法的效率得到了广泛的实验证据支持。
## Conclusion
尽管该研究主要强调理论，但也展示了所提出算法与现有基准相比的有效性。
# 555. `cs.LG` - 在破解时间进行对抗性推理 [PDF](https://arxiv.org/pdf/2502.01633), [HTML](https://arxiv.org/abs/2502.01633)
## Authors
Mahdi Sabbaghi,Paul Kassianik,George Pappas,Yaron Singer,Amin Karbasi,Hamed Hassani
## Background
随着大型语言模型（LLMs）的能力和普及性不断增强，对它们失败案例的研究变得越来越重要。最近在标准化、衡量和扩展测试计算方面取得的进展建议了新的方法来优化模型，在困难任务上实现高性能。
## Innovation
本文将这些进展应用到模型破解任务中：从对齐的LLMs中引诱有害响应。开发了一种对抗性推理的自动破解方法，利用损失信号引导测试计算，即使对于那些试图在推理计算和对抗性鲁棒性之间交易的对齐LLMs，也能实现最佳攻击成功率。方法为理解和应对LLM脆弱性提供了一个新的范式，为开发更强大和值得信赖的人工智能系统奠定了基础。
## Conclusion
通过这种方法，为对抗性推理打开了新的研究方向，为更强大和值得信赖的AI系统的发展奠定了基础。
# 556. `cs.LG` - 基于化学知识的隐私感知逆合成学习框架 [PDF](https://arxiv.org/pdf/2502.19119), [HTML](https://arxiv.org/abs/2502.19119)
## Authors
Guikun Chen,Xu Zhang,Xiaolin Hu,Yong Liu,Yi Yang,Wenguan Wang
## Background
化学反应数据对于制药、材料科学和工业化学等领域具有重要意义，但因其专有性质易于敏感性泄露。目前，机器学习驱动的逆合成分析往往需要在多个机构之间共享反应数据，这带来了显著的隐私安全风险，数据在传输和存储时存在被不法访问或截获的风险。目前的标准训练范式对此缺乏有效的隐私保护措施。
## Innovation
提出了一种新的隐私保护方法——化学知识指导框架（CKIF），它能够在多个化学组织间进行分布式的逆合成模型训练，而无需泄露具体的反应数据。CKIF通过迭代的、基于化学知识的模型参数聚合来学习逆合成模型，利用预测产物的化学特性定量评估个体模型的可观察行为，进而确定模型聚合的自适应权重。CKIF相比现有基准模型具有明显的优势。
## Conclusion
CKIF能够在保持化学反应数据保密性的情况下有效提升逆合成模型的学习效果。
# 557. `cs.LG` - SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models [PDF](https://arxiv.org/pdf/2309.05019), [HTML](https://arxiv.org/abs/2309.05019)
## Authors
Shuchen Xue,Mingyang Yi,Weijian Luo,Shifeng Zhang,Jiacheng Sun,Zhenguo Li,Zhi-Ming Ma
## Background
扩散概率模型（DPMs）在生成任务中取得了显著的成功。从DPMs中采样等同于求解扩散SDE或ODE，这过程非常耗时。因此，基于改进的微分方程求解器提出了一系列快速采样方法。大多数方法倾向于解决扩散ODE，因为它更高效。然而，随机采样在生成多样性和高质量数据方面可能具有额外的优势。本研究深入分析了从扩散SDE中进行随机采样的两种方法：可控方差扩散SDE和线性多步SDE解算器。基于该分析，我们提出了改进的有效随机阿达姆斯方法textit{SA-Solver}，用于解决扩散SDE以生成高质量数据。实验表明，textit{SA-Solver}在多项方面表现突出：1) 在少量步骤的样本采样中，textit{SA-Solver}的性能优于现有最先进的（SOTA）采样方法；2) 在功能评估（NFEs）数量适当的情况下，textit{SA-Solver}在大量基准数据集上实现了SOTA的FID分数。
## Innovation
本研究提出了一种改进的有效随机阿达姆斯方法textit{SA-Solver}，专门用于从扩散SDE中进行高效率随机采样以生成高质量的输出数据。相比现有的SOTA采样方法，textit{SA-Solver}在少量步骤的样本采样中表现优异，并在功能评估数量适当的情况下达到了SOTA的FID分数。
## Conclusion
textit{SA-Solver}在少量步骤的样本采样中实现了与SOTA采样方法相当或更好的性能，并在大量基准数据集上实现了SOTA的FID分数，验证了该方法的有效性和效率。
# 558. `cs.LG` - 利用深度上下文蒸馏进行插拔式知识模块训练 [PDF](https://arxiv.org/pdf/2503.08727), [HTML](https://arxiv.org/abs/2503.08727)
## Authors
Lucas Caccia,Alan Ansell,Edoardo Ponti,Ivan Vulić,Alessandro Sordoni
## Background
在大型语言模型预训练之后，动态整合新信息或快速演变的信息仍然充满挑战，尤其是在数据较少的情况下或处理私有和专门文档时。在这种背景下，上下文学习和检索增强生成（RAG）方法面临高推理成本和难以捕捉文档全局信息的问题。因此，需要一种新的方法来解决这个问题。
## Innovation
本文提出了一种训练文档级别知识模块（KMs）的方法。知识模块被模块化地训练，作为参数高效LoRA模块，能够存储新文档的信息，并在需要时方便地插接到模型中。作者采用了深度上下文蒸馏方法来训练KMs，通过模拟教师模型在文档上下文中的隐藏状态和logits来学习KMs的参数，这种方法在两个数据集上优于标准的下一个令牌预测和预指令训练技术。
## Conclusion
本文展示了知识模块（KMs）与RAG之间的协同作用，并证明了通过深度上下文蒸馏训练的KMs在文档级信息整合任务上具有优势。
# 559. `cs.LG` - 超越拓扑自我解释的GNN：形式解释视角 [PDF](https://arxiv.org/pdf/2502.02719), [HTML](https://arxiv.org/abs/2502.02719)
## Authors
Steve Azzolin,Sagar Malhotra,Andrea Passerini,Stefano Teso
## Background
SE-GNNs 是一种流行的带有自我解释设计的GNN，但它们的解释属性和局限性尚不完全清楚。本文填补了这一空白，正式化了一些流行的 SE-GNNs 提取的解释，称为 Minimal Explanations (MEs)，并将它们与已确立的解释概念（即 Prime Implicant (PI) 和忠实解释）进行了比较。研究表明，MEs 与 PI 解释在特定任务中相匹配，但在大多数情况下，MEs 比 PI 解释更不具信息性，并且在忠实性上与广为接受的解释观念出奇地不一致。虽然忠实和 PI 解释具有很高的信息性，但它们难以找到，且可能非常庞大。
## Innovation
本文首次通过正式化某些流行的SE-GNNs提取的解释，并将其与已建立的解释概念进行比较，提出了Dual-Channel GNNs，该模型结合了白盒规则提取器和标准SE-GNN，适配性地结合了两种通道。实验结果表明，即使是一个简单的Dual-Channel GNNs实例也能恢复简洁的规则，并且在性能上与广泛使用的SE-GNNs相当或更好。
## Conclusion
尽管忠实和PI解释较为信息性但难以找到且可能非常大，文章提出了一种处理SE-GNNs局限性的方法，并展示了即使简单的Dual-Channel GNNs也能恢复简洁的规则，且在性能上能与广泛使用的SE-GNNs匹敌或更优。
# 560. `cs.LG` - 跟随扰动领袖算法在m-集合半-bandit问题中接近两权平衡 [PDF](https://arxiv.org/pdf/2504.07307), [HTML](https://arxiv.org/abs/2504.07307)
## Authors
Jingxin Zhan,Yuchen Xin,Chenjie Sun,Zhihua Zhang
## Background
在组合半-bandit问题中，学习者需要从总共d个臂中选择m个臂。在对抗性设置下，已知最好的后悔上界为Ο(√(nmd))，这一结果由著名的Follow-the-Regularized-Leader (FTRL)策略实现。然而，FTRL策略需要在每一时间步骤都明确计算臂选择概率并通过这些概率进行采样，这会带来计算上的困难。Follow-the-Perturbed-Leader (FTPL)策略通过简单随机扰动来代替，从而避免上述问题。但FTPL策略对于m-集合半-bandit问题，还没有达到最优的后悔上界。本文关注的是FTPL策略在m-集合半-bandit问题下的性能分析及其改进后的表现。
## Innovation
本文证明了带有Fréchet扰动的FTPL策略在对抗性设置下能接近最优的后悔上界为Ο(√(nm)(√(dln(d))+m^(5/6)))，同时在随机设置中实现了最优的对数后悔。此外，论文还证明了这种方法带来的额外因子是不可避免的，任何进一步的改进都需要从根本上寻找新的解决方案。
## Conclusion
本文通过理论分析展示了FTPL策略在m-集合半-bandit问题中的优势，并证明了其在不同设置下的适应性和改进空间。同时研究结果也表明，现有的方法已经非常接近问题的本质限制，任何进一步的改进都需要根本性的技术突破。
# 561. `cs.LG` - 基于数据驱动的高分辨率集合天气预报支持可再生能源规划和运行 [PDF](https://arxiv.org/pdf/2505.04396), [HTML](https://arxiv.org/abs/2505.04396)
## Authors
Jingnan Wang,Jie Chao,Shangshang Yang,Congyi Nai,Kaijun Ren,Kefeng Deng,Xi Chen,Yaxin Liu,Hanqiuzi Wen,Ziniu Xiao,Lifeng Zhang,Xiaodong Wang,Jiping Guan,Baoxiang Pan
## Background
可再生能源，尤其是风能的规划和运行依赖于准确、及时且高分辨率的天气信息。全球粗网格数值天气预报通常会进行缩放以满足这些要求，但这也带来了尺度不一致、过程表示误差、计算成本和不确定性来源纠缠等问题。这些问题使得天气预报难以有效支持可再生能源的规划和运行。
## Innovation
通过使用高分辨率数值天气模拟数据来学习目标风电场的气候分布，并将其与粗网格大尺度预报优化结合，提出了一种方法，能够生成高准确度、细粒度、全变量的大型集合天气模式预报。这种方法相较于现有数值/统计预报缩放管道，无论是确定性还是概率技能，或经济效益方面都表现出明显优势。此外，该方法在中等性能GPU上进行10天、每15分钟一次的100个成员预报所需时间小于1小时，而传统的数值模拟需要大约1000小时的CPU时间。
## Conclusion
通过大幅度降低计算成本同时保持准确性，该方法为更高效和可靠的可再生能源规划和运行铺平了道路。
# 562. `cs.LG` - 使用解偶扩散序列蒙特卡洛方法求解线性高斯贝叶斯逆问题 [PDF](https://arxiv.org/pdf/2502.06379), [HTML](https://arxiv.org/abs/2502.06379)
## Authors
Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten
## Background
最近的研究已利用预训练生成扩散模型作为解决贝叶斯逆问题的先验。这种研究方向致力于设计一种基于?解偶扩散?的方法来处理线性高斯逆问题，其中生成过程被设计为可以实现更大样本更新。该方法是渐近准确的。该算法已在合成数据和蛋白质、图像数据中得到验证，并进一步展示了将其扩展到离散数据的可行性。
## Innovation
设计了一种基于解偶扩散的序列蒙特卡洛方法，用于解决线性高斯逆问题。这种新方法允许对样本进行更大规模的更新，并且该方法是渐近准确的。该论文提出了Decoupled Diffusion Sequential Monte Carlo（DDSMC）算法，并证明了其在多种类型数据上的有效性。
## Conclusion
通过DDSMC算法，研究人员展示了该方法在合成数据以及蛋白质、图像等数据上的有效性，并讨论了将其扩展应用于离散数据的潜力。
# 563. `cs.LG` - 证明作为解释：可靠预测的简要证书 [PDF](https://arxiv.org/pdf/2504.08377), [HTML](https://arxiv.org/abs/2504.08377)
## Authors
Avrim Blum,Steve Hanneke,Chirag Pabbaraju,Donya Saless
## Background
本文考虑了一种可解释的人工智能模型，在该模型中，一个预测$h(x)=y$的解释是由训练数据的一个子集$S'$组成（如果存在的话），使得所有在$S'$上最多犯$b$个错误的分类器$h' from H$预测$h'(x)=y$。一个这样的集合$S'$作为证明$x$确实具有标签$y$的证据，假设（1）目标函数$h^triangle$属于集合$H$，且（2）数据集$S$包含至多$b$个被污染的数据点。例如，如果$b=0$，$H$是$bb{R}^d$中的线性分类器，而$x$位于$S$中正数据点的凸包内部，那么Carathéodory定理表明$x$位于这些点凸包的$d+1$个点内部。因此，一个大小为$d+1$的集合$S'$可以作为正预测的简要解释，并且当假设达到可实现性时，作为正确预测的简要证明。在本文中，作者更广泛地考虑了这个问题，将$H$定义为一般的假设类，$b$为非负的任何值。
## Innovation
提出了一个定义$H$的鲁棒空星数（以及标准空星数的推广），并展示了其精确地表征了最佳证明大小。同时分析了不同情况下的证明大小，并考虑了最坏情况的分布界和基于分布的边界，这些边界能够准确控制获取证明所需的样本大小。定义了样本$x$相对于分布$D$和目标函数$h^triangle$的证明系数$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{ x} }} boldsymbol{}}}}}}}}}}}}}}}}}}}}}}}$，并证明了$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{ x} }} boldsymbol{}}}}}}}}}}}}}}}}}}}}}}$，$b$以及$H$的VC维$D$的匹配上下界。这些提出了一个新的解释框架，使其能够处理更一般的情况，并提供了更精确的证明大小估计方法。
## Conclusion
本文通过对最坏情况的边界以及基于分布的边界进行分析，展示了如何精确地表征和控制证明的大小，从而为可靠预测提供了一种新的框架。
# 564. `cs.LG` - 前向-前向算法的进步 [PDF](https://arxiv.org/pdf/2504.21662), [HTML](https://arxiv.org/abs/2504.21662)
## Authors
Mauricio Ortiz Torres,Markus Lange,Arne P. Raulf
## Background
前向-前向算法在机器学习研究中得到了发展，能够处理更复杂的任务，并模拟真实生活应用。近年来，该算法通过多种技术改进，使其在处理CIFAR10等具有挑战性的数据集时，仍然保持良好的灵活性和低内存使用特性。研究结果显示，通过结合卷积通道分组、学习率调度以及独立块结构等技术，在训练过程中能够实现测试错误率降低20%的效果。
## Innovation
提出了一系列轻量级模型，这些模型在测试错误率方面达到了21±3%，同时可训练参数数量在164,706到754,386之间。这些研究为未来全面验证和验证此类神经网络奠定了基础。
## Conclusion
该研究展示了通过技术优化后的前向-前向算法在处理复杂任务上的进步，并通过一系列轻量级模型证明了在较低硬件能力的项目中应用的可行性。
# 565. `cs.LG` - Log-Linear Attention [PDF](https://arxiv.org/pdf/2506.04761), [HTML](https://arxiv.org/abs/2506.04761)
## Authors
Han Guo,Songlin Yang,Tarushii Goel,Eric P. Xing,Tri Dao,Yoon Kim
## Background
Transformers 的注意力机制在精确和可扩展的序列建模中非常重要，但其计算复杂度为平方阶且内存复杂度为线性阶，成为主要瓶颈。线性注意力和状态空间模型能够实现线性时间、常数内存的序列建模，还能通过在序列长度上进行矩阵乘法丰富的并行计算有效地训练。然而，它们本质上仍然是循环神经网络(RNN)，使用固定大小的隐藏状态来建模上下文是一个根本性的限制。
## Innovation
本文开发了对数线性注意力机制，该机制在线性注意力效率和softmax注意力的表达性之间取得了平衡。对数线性注意力用对数增长的隐藏状态集替代了固定大小的隐藏状态。通过特定的生长函数，对数线性注意力具有与矩阵乘法丰富的形式，计算成本为序列长度的对数级。对数线性注意力是一个通用框架，可以应用于现有的线性注意力变体之上。作为案例研究，本文实例化了对Log-Linear变体的两个最新架构Mamba-2和Gated DeltaNet，发现它们的性能优于线性时间变体。
## Conclusion
对数线性注意力是一种通用框架，可以应用于现有的线性注意力变体之上，且具有线性时间复杂度和对数级的计算成本。作为案例研究，Mamba-2和Gated DeltaNet的对数线性变体表现良好。
# 566. `cs.LG` - 经过训练的嵌入证明注意力机制选择重要标记 [PDF](https://arxiv.org/pdf/2505.17282), [HTML](https://arxiv.org/abs/2505.17282)
## Authors
Diyuan Wu,Aleksandr Shevchenko,Samet Oymak,Marco Mondelli
## Background
词嵌入在语言建模中起关键作用，但尽管有其实践相关性，其理论理解仍然有限。本文通过研究梯度下降获得的嵌入结构来填补这一空白。具体地，作者研究了一层softmax注意力模型与线性头的二分类情况，即$texttt{Softmax}(p^top E_X^top ) E_X v = frac{ textstyle text{对象} }{ textstyle text{所有项之和} }$，其中$E_X$是输入序列的嵌入矩阵，$p$是$texttt{<cls>}$标记的嵌入，$v$是输出向量。研究发现这些嵌入已经根据其在数据集中的出现频率与输出向量进行按比例对齐。然后通过梯度流动训练$p$直到收敛，softmax选择句子中的重要标记，最终$texttt{<cls>}$嵌入最大化这些选择的间隔。
## Innovation
该研究通过理论分析揭示了训练后的嵌入如何通过softmax机制在单步梯度训练后与输出向量对齐，并在训练$p$时选择对标签预测重要的标记。此外，它展示了这种机制如何在选择重要token上最大化分类间隔，并通过实际数据集（IMDB、Yelp）展示了与理论预测一致的现象。
## Conclusion
该模型证明了训练后的嵌入能帮助注意力机制选择重要标记，这在选择预测标签相关token时优化了分类间隔。这对于理解语言模型中的重要特性有重大意义。
# 567. `cs.LG` - TSPulse: 双空间超紧凑预训练模型用于快速时间序列分析 [PDF](https://arxiv.org/pdf/2505.13033), [HTML](https://arxiv.org/abs/2505.13033)
## Authors
Vijay Ekambaram,Subodh Kumar,Arindam Jati,Sumanta Mukherjee,Tomoya Sakai,Pankaj Dayama,Wesley M. Gifford,Jayant Kalagnanam
## Background
时间序列预训练模型的兴起促进了时间表示学习的进步，但当前的领先模型往往规模庞大，需要大量的计算资源。本文旨在通过提出超紧凑的TSPulse时间序列预训练模型来解决这一问题，该模型仅有100万个参数，适用于分类、异常检测、填充和检索等多种任务。
## Innovation
TSPulse在架构和任务层次上都引入了创新。在架构层面，它采用了双空间掩码重构，同时从时间和频率域中学习，以捕捉互补信号。此外，它还通过双重嵌入解缠，生成详细的嵌入用于精细分析和高层次语义嵌入用于更广泛的任务理解。在任务层面，TSPulse集成了TSLens，这是一种细调组件，可以实现特定任务的特征注意力。它还引入了多头三角化技术，通过融合多个预测头的互补输出来增强异常检测。此外，提出了一种混合掩码预训练方法，以改进零样本填充，减少预训练偏见。这些架构和任务层面的创新共同使TSPulse在多项基准测试中取得了显著的性能提升，包括在UEA分类基准测试中提高了5-16个百分点，在TSB-AD异常检测排行榜上提高了20个百分点，在零样本填充上提高了50个百分点，在时间序列检索上提高了25个百分点。同时，TSPulse的参数量仅为100万（比现有顶级模型小10到100倍），并且支持GPU-free推理，成为高效时间序列预训练模型的新标准。
## Conclusion
TSPulse通过在其架构和任务层面的创新，实现了在小型参数设置下以及提升性能的目标，为时间序列分析提供了新的高效解决方案。
# 568. `cs.LG` - Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning [PDF](https://arxiv.org/pdf/2506.07744), [HTML](https://arxiv.org/abs/2506.07744)
## Authors
Seungho Baek,Taegeon Park,Jongchan Park,Seungjun Oh,Yusung Kim
## Background
现有的离线分层强化学习方法依赖于高层策略学习生成子目标序列，但在任务时间跨度增加的情况下效率会下降，并且缺乏有效的策略来缝合不同轨迹中的有用状态过渡。
## Innovation
本文提出了Graph-Assisted Stitching (GAS)，这是一种新的框架，将子目标选择问题形式化为图搜索问题，而不是学习显式的高层策略。通过将状态嵌入到Temporal Distance Representation (TDR)空间中，GAS将来自不同轨迹的语义相似状态聚类成统一的图节点，从而实现高效过渡缝合。引入了Temporal Efficiency (TE)度量标准，以过滤掉噪声或低效的过渡状态，显著提高任务性能。GAS在行走、导航和操纵任务中优于先前的离线HRL方法，尤其在缝合关键任务中的得分达88.3，大幅度超越之前最先进的1.0分。
## Conclusion
GAS在离线分层强化学习任务中表现出色，特别是在缝合关键任务上的表现远超先前方法，极大地提升了任务绩效。
# 569. `cs.LG` - TabArena: 用于表格数据机器学习的实时基准 [PDF](https://arxiv.org/pdf/2506.16791), [HTML](https://arxiv.org/abs/2506.16791)
## Authors
Nick Erickson,Lennart Purucker,Andrej Tschalzev,David Holzmüller,Prateek Mutalik Desai,David Salinas,Frank Hutter
## Background
随着深度学习和基础模型在表格数据中的应用越来越广泛，标准化和可靠的基准测试变得越来越重要。然而，当前的基准测试是静态的，设计不会随着新模型的发布或旧模型的更新而更新。
## Innovation
我们推出了TabArena——第一个持续维护的活生生的表格基准测试系统。通过手动整理代表性数据集和实施模型，以及大规模的基准测试研究来初始化公共排行榜，并组织了一个经验丰富的维护团队，突出了验证方法和超参数配置组合对基准测试模型的影响。同时发现了基于梯度提升的决策树仍然在实际表格数据集上表现出色，但大规模下，深度学习方法通过组合已经追上来了。基础模型在较小的数据集上表现出色。此外，跨模型的组合提高了表格机器学习的最先进的技术水平。
## Conclusion
我们推出了一个可重复的公共排行榜、代码及维护标准，以创建一个实时可用的基准测试，供所有人参考。
# 570. `cs.LG` - 使用合成数据提高少量样本模型泛化的可验证方法 [PDF](https://arxiv.org/pdf/2505.24190), [HTML](https://arxiv.org/abs/2505.24190)
## Authors
Lan-Cuong Nguyen,Quan Nguyen-Tri,Bang Tran Khanh,Dung D. Le,Long Tran-Thanh,Khoat Than
## Background
少量样本图像分类由于缺乏标记的训练例子而极具挑战性。使用合成数据对其进行增强被认为是一种有潜力的方法来解决这个问题，但基于合成样本训练的模型往往因为现实与合成分布之间存在差距而表现不佳。为了克服这一限制，作者开发了一个理论框架来量化这种分布差异对监督学习的影响，特别是在图像分类的背景下，并提出了生成良好合成样本和训练具有高泛化能力预测器的实际方法。
## Innovation
构建在这个理论框架上的新方法，通过集成原型学习来优化数据分割和模型训练，从而有效地弥合了现实少量样本数据与合成数据之间的差异。广泛的实验结果显示，该方法在多个数据集的表现超过了最先进的方法，显示出更好的性能。
## Conclusion
该研究提出了一种基于理论的方法，通过使用合成数据，有效地提高了少量样本模型的泛化能力。实验结果表明，该方法在多个数据集上的表现优于现有方法。
# 571. `cs.LG` - Confucius3-Math: 针对中国K-12数学学习的轻量高性能推理大语言模型 [PDF](https://arxiv.org/pdf/2506.18330), [HTML](https://arxiv.org/abs/2506.18330)
## Authors
Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan
## Background
该论文介绍了一个名为Confucius3-Math的开源大型语言模型，该模型包含14亿参数，并具有在单个消费级GPU上高效运行的能力。此外，该模型在一系列数学推理任务上表现出顶级性能，甚至在比其大得多的模型中也表现更优。该模型专为增强AI在教育和知识传播方面的应用，并特别致力于服务中国K-12学生和教育者。通过大规模强化学习（RL）后的训练，该模型能够以低成本解决主流的中国K-12数学问题。
## Innovation
该论文提出以下三项技术创新：1. 目标熵正则化2. 近期样本恢复3. 政策特定难易度加权这些创新涵盖了新的熵正则化，新型数据调度策略以及改进的组相对优势估计器。它们在RL训练中取得了显著的稳定性和数据效率的提升，并且改善了性能。
## Conclusion
这项工作证明了在特定领域以低成本构建强大的推理模型的可能性。该模型和代码已在GitHub上开源。
# 572. `cs.LG` - VRAIL: 向量化的基于奖励归因的可解释学习 [PDF](https://arxiv.org/pdf/2506.16014), [HTML](https://arxiv.org/abs/2506.16014)
## Authors
Jina Kim,Youjin Jang,Jeongjin Han
## Background
本文提出了VRAIL（向量化的基于奖励的归因可解释学习），这是一种基于价值的强化学习（RL）的双层框架，从状态特征中学习可解释的权重表示。VRAIL分为两个阶段：深度学习（DL）阶段使用状态特征拟合估计的价值函数，以及强化学习（RL）阶段使用此价值函数进行基于潜力的奖励转化以引导学习。该估计器可以建模为线性或二次形式，允许对个个体特征及其相互作用的重要性进行归因。实验结果表明，VRAIL相比于标准的DQN提高了训练的稳定性和收敛性，无需环境修改。进一步分析表明，VRAIL能够发现具有语义意义的次级目标，如乘客拥有，这表明其能够产生可由人类解释的行为。研究表明，VRAIL作为一种通用的、模型无关的奖励塑造框架，增强了学习和可解释性。
## Innovation
VRAIL是一种结合了深度学习和强化学习的双层框架，能够从状态特征中学习可解释的权重表示。VRAIL的创新之处在于它可以模型化为线性或二次形式，从而对个体特征及其相互作用的重要性进行归因。这种方法提高了训练的稳定性和可解释性，能够发现具有语义意义的次级目标，提高了学习效果。
## Conclusion
VRAIL作为一种通用的、模型无关的框架，不仅能够提高强化学习的训练稳定性与收敛性，还能够生成能够被人类理解的行为。这种方法对于提高强化学习的可解释性具有重要意义。
# 573. `cs.LG` - LT-PINN: 拉格朗日拓扑意识物理知情神经网络在边界导向工程优化中的应用 [PDF](https://arxiv.org/pdf/2506.06300), [HTML](https://arxiv.org/abs/2506.06300)
## Authors
Yuanye Zhou,Zhaokun Wang,Kai Zhou,Hui Tang,Xiaofan Li
## Background
物理知情神经网络（PINNs）已经成为了拓扑优化的强大工具，能够同时确定最优拓扑和物理解决方案。然而，传统的PINNs依赖于基于密度的拓扑描述，需要手动插值且限制了其在复杂几何形状中的应用。为了解决这一问题，本文提出了一种新型的边界导向工程优化框架——拉格朗日拓扑意识PINNs（LT-PINNs），通过将拓扑边界曲线的控制变量参数化为可学习参数，LT-PINNs消除了手动插值的需要，并实现了精确边界确定。本文还引入了特定的边界条件损失函数和拓扑损失函数，以确保即使在复杂拓扑中也能获得清晰准确的边界表示。LT-PINNs的准确性和鲁棒性通过两种类型的偏微分方程（PDEs）进行了验证，并且在复杂的时变和时不变流体问题中展示了其工程应用潜力，无需依赖测量数据，能够重新排列流速，将上游均匀速度转换为下游的正弦形速度剖面。
## Innovation
提出了拉格朗日拓扑意识PINNs（LT-PINNs）框架，通过将拓扑边界曲线的控制变量参数化为可学习参数，消除了手动插值的需要，实现了精确边界确定。并且开发了特定的边界条件损失函数和拓扑损失函数，确保即使在复杂拓扑中也能获得清晰准确的边界表示。验证了该方法的准确性和鲁棒性，可处理任意边界条件，适用于广泛的PDEs，并且可以不依赖测量数据，对复杂的时变和时不变流体问题进行工程应用探究.
## Conclusion
研究结果表明：与最先进的基于密度的拓扑指向PINNs相比，LT-PINNs实现了相对L2误差的重大减少；LT-PINNs能够处理任意边界条件，适用于广泛的PDEs；LT-PINNs能够无需手动插值而明确推断拓扑边界，特别是在复杂拓扑中更为显著。
# 574. `cs.LG` - 吃饭不免费：重思LSTM模型的内部反馈 [PDF](https://arxiv.org/pdf/2506.17219), [HTML](https://arxiv.org/abs/2506.17219)
## Authors
Yanzhi Zhang,Zhaoxi Zhang,Haoxiang Guan,Yilin Cheng,Yitong Duan,Chen Wang,Yue Wang,Shuxin Zheng,Jiyan He
## Background
强化学习作为一种强大的后训练范式，被用来提升大型语言模型（LLMs）的推理能力。RLHF和RLVR等方法已经在提高LLM推理能力上取得了显著成果，但这些方法需要大量的外部监督。本文研究了另一种方法——基于内部反馈的强化学习（RLIF）——它完全依赖于模型内生的信号，而不是外部奖励。研究表明，内部目标在一定程度上是部分等价的，并在复杂的数学推理基准上评估了不同的RLIF策略。实验结果表明，在训练初期，RLIF可以提升基础LLM的推理性能，与RLVR技术相匹配或超越。然而，随着训练的进展，性能会下降，甚至低于未训练的模型。此外，研究还发现，对于指令调优模型而言，RLIF带来的改进微乎其微，表明一旦LLM已经完成指令调优，内部反馈的效果就会逐渐降低。进一步的分析解释了RLIF训练行为的原因，并提出了集成内部反馈信号到LLM训练中的实用指南。
## Innovation
本文提出了一种基于内部反馈的强化学习（RLIF）方法，该方法完全依赖于模型内生的信号，而不需要大量的外部监督。通过对比评估了各种RLIF策略，并提出了解释RLIF训练行为的深刻见解，为集成内部反馈信号到LLM训练中提供了实用指南。这种方法及其分析为LSTM模型的内部反馈优化提供了更为合理和有效的新策略。
## Conclusion
本文研究发现，RLIF在训练初期可以提升LLM的推理性能，但在训练过程中性能会下降，对于已经指令调优的模型，内部反馈的效果就显得较差。研究人员通过分析原因，提出了有效的集成内部反馈信号的策略，这为LLM后续训练提供指导。
# 575. `cs.LG` - MS-TVNet：基于多尺度动态卷积的长时序预测方法 [PDF](https://arxiv.org/pdf/2506.17253), [HTML](https://arxiv.org/abs/2506.17253)
## Authors
Chenghan Li,Mingchen Li,Yipu Liao,Ruisheng Diao
## Background
长时序预测主要依赖于Transformer和MLP模型，而卷积网络在该领域的潜力尚未得到充分挖掘。文章指出，现有模型在这一领域倾向于使用Transformer和MLP，但卷积网络在长时序预测中的应用有待进一步探索和验证。
## Innovation
引入了一种新的多尺度时间序列重塑模块，能有效捕捉多周期片段间的关联和变量依赖性，并在此基础上提出了MS-TVNet模型，这是一种多尺度三维动态卷积神经网络。实验结果表明，MS-TVNet在多种数据集上的性能优于基线模型，并达到了长时序预测的最新成果。
## Conclusion
研究发现，利用卷积网络捕捉复杂的时间模式是一种有效的策略，这为未来长时序预测的研究指明了新的方向。研究成果已发布在相应代码库中。
# 576. `cs.LG` - 思考锚点：哪种LLM推理步骤重要？ [PDF](https://arxiv.org/pdf/2506.19143), [HTML](https://arxiv.org/abs/2506.19143)
## Authors
Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy
## Background
大规模语言模型最近在许多领域取得了最先进的性能。然而，它们的长段链式推理带来了可解释性挑战，因为每个生成的标记都依赖于所有之前的标记，使得计算难以分解。我们主张在句子层面分析推理轨迹是一种理解推理过程的有前途的方法。
## Innovation
论文提出了三种互补的归因方法：(1) 通过比较在模型生成该句子或具有不同含义的句子时的答案，来衡量每个句子的反事实重要性的一种黑盒方法；(2) 一种白色盒策略，聚合句子对之间的注意力模式，发现接收不适当的注意力而来自所有未来句子的“广播”句子通过“接收者”注意力头；(3) 一种因果归因方法，通过抑制一个句子的注意力，并测量对其未来句子标记的影响来衡量句子之间的逻辑连接。这些方法提供证据证明了思考锚点的存在，这些推理步骤具有超出其重要性，且不对称地影响后续推理过程。思考锚点通常为计划或回溯句子。
## Conclusion
每种方法都证明了句子层面分析的潜在价值，这种分析可以更深入地理解推理模型。论文提供了一个开源工具（链接：this http URL）来可视化这些方法的输出，并通过一个案例研究展示了方法间的一致性，有助于更好地理解模型执行多步推理的方式。
# 577. `cs.LG` - 非平衡退火伴随采样器 [PDF](https://arxiv.org/pdf/2506.18165), [HTML](https://arxiv.org/abs/2506.18165)
## Authors
Jaemoo Choi,Yongxin Chen,Molei Tao,Guan-Horng Liu
## Background
最近，在基于学习的扩散采样器方面取得了显著进展，这些方法旨在从给定的未归一化密度中采样。通常，这些方法遵循两种范式之一：(i) 使用标准参考过程将采样建模为无偏随机最优控制问题（SOC）；或(ii) 通过重要性加权采样来细化退火路径度量。尽管退火方法在引导样本向高密度区域方面具有优势，但对重要性采样的依赖会导致实际中的高方差和有限的可扩展性。
## Innovation
本文介绍了一种新颖的SOC基扩散采样器——非平衡退火伴随采样器（Non-equilibrium Annealed Adjoint Sampler，NAAS），该方法利用退火参考动力学，而不依赖于重要性采样。NAAS 使用受伴随匹配启发的简约伴随系统，实现高效和可扩展的训练。
## Conclusion
我们的方法在一系列任务中得到了验证，包括从经典能量景观和分子玻尔兹曼分布中采样。
# 578. `cs.LG` - 使用随机向量功能链接网络进行高效均匀逼近 [PDF](https://arxiv.org/pdf/2306.17501), [HTML](https://arxiv.org/abs/2306.17501)
## Authors
Palina Salanevich,Olov Schavemaker
## Background
随机向量功能链接（RVFL）网络是一种深度为2的神经网络，其内部权重和偏置为随机数。此类网络的学习过程仅需学习外部权重，因此化简为线性优化问题，避免了非凸优化问题的陷阱。本文研究了RVFL在网络激活函数为ReLU时，在$L_region$范数下近似Lipschitz连续函数的问题。本文证明的结果是使用具有良好内权重（如高斯分布）的RVFL在网络激活函数为ReLU时，首次在$L_region$范数下的近似结果。另外，给出了在高概率下实现给定精度所需的隐藏层节点数的非渐近下界，该下界与目标函数的Lipschitz常数、所需的精度和输入维数等因素有关。证明方法结合了概率论和调和分析的方法。
## Innovation
首次在$L_region$范数下证明了具有高斯内权重的ReLU激活函数的RVFL网络可以近似Lipschitz连续函数，并给出了实现给定精度所需的隐藏层节点数的非渐近下界。此结果避免了非凸优化问题，为深度学习中的函数逼近问题提供了新的视角。
## Conclusion
本文证明了使用具有高斯内权重的ReLU激活函数的RVFL网络在$L_region$范数下能够有效逼近Lipschitz连续函数，并给出了实现给定精度所需的隐藏层节点数的非渐近下界。这种方法结合了概率论和调和分析，为深度学习中的函数逼近问题提供了新的解决方案。
# 579. `cs.LG` - Offline Goal-Conditioned Reinforcement Learning with Projective Quasimetric Planning [PDF](https://arxiv.org/pdf/2506.18847), [HTML](https://arxiv.org/abs/2506.18847)
## Authors
Anthony Kobanda,Waris Radji,Mathieu Petitbois,Odalric-Ambrym Maillard,Rémy Portelas
## Background
该研究探讨了如何从先前收集的轨迹中训练智能体到达指定目标的问题。对于长期任务的扩展依然是个挑战，主要由于复合的价值估计错误。有鉴于此，上述研究介绍了Projective Quasimetric Planning (ProQ)框架，该框架通过学习不对称距离，将此距离重新用作排斥能量以促使关键点均匀分布在学习的潜在空间，并作为结构化方向成本将目标引导向附近的子目标。ProQ方法还通过将几何学与开集检测器耦合来确保学习的关键点保持在可达区域中。该方法统一了度量学习、关键点覆盖和条件控制，从而产生有意义的子目标，并在各种导航基准上稳健地驱动长期目标的实现。
## Innovation
该研究的主要创新在于提出了Projective Quasimetric Planning (ProQ)框架。ProQ通过学习不对称距离，并将其重新用作排斥能量和结构化方向成本，从而有效地解决了长期任务中的复合价值估计错误问题。此外，ProQ还结合了度量学习、关键点覆盖和目标导向控制，形成了一个统一的方法，促进了在不同导航基准上的长期目标实现。
## Conclusion
通过将ProQ方法应用于各种导航基准，该研究不仅产生了有意义的子目标，还稳健地驱动了长期目标的实现。ProQ方法有效地克服了价值估计中的复合误差，展示了在长期任务中应用的潜力。
# 580. `cs.LG` - 灵活的无限宽度图卷积神经网络 [PDF](https://arxiv.org/pdf/2402.06525), [HTML](https://arxiv.org/abs/2402.06525)
## Authors
Ben Anson,Edward Milsom,Laurence Aitchison
## Background
传统的神经网络，通过取无穷宽度极限接近高斯过程（GP），形成了神经网络高斯过程（NNGP）。然而，NNGP的核固定不变，只能通过少数超参数微调，这消除了通过学习表示来提高性能的可能性。相比之下，有限宽度的神经网络有能力灵活地学习任务所需的表示，从而使它们能够更好地工作。因此，在简化神经网络以使其理论可处理时，NNGP可能会消除使它们效果良好的机制（表示学习）。这促使作者研究表示学习是否在各种图任务中是必要的。文中提出了一个精确的工具，即图卷积深度核机。这个工具类似于NNGP，因为它也是在无穷宽度极限下使用核，但它包含一个“旋钮”来控制灵活性，从而影响表示学习的能力。实验结果表明，表示学习在异质节点分类任务中带来了显著的性能提升，但在同质节点分类任务中影响较小。
## Innovation
文中提出了图卷积深度核机，这是一种类似于NNGP的工具，但在保持理论上的无限宽度的同时，增加了灵活性的控制机制，通过这个“旋钮”来调节表示学习的能力。这使得研究人员能够探究灵活的表示学习在不同类型图任务中的效果差异。通过这种方法，作者发现表示学习在异质节点分类任务中有助于显著提高性能，而在同质节点分类任务中则效果不那么明显。
## Conclusion
在图卷积神经网络中引入灵活的表示学习机制，对异质节点分类有显著的性能提升作用。这对于开发更强大和适应性更强的图神经网络模型具有潜在意义，因为可以通过调整灵活性来实现更好的表示学习和任务适应性。
# 581. `cs.LG` - COBRA-PPM：使用概率编程的不确定性下机器人操作的因果贝叶斯推理架构 [PDF](https://arxiv.org/pdf/2403.14488), [HTML](https://arxiv.org/abs/2403.14488)
## Authors
Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze
## Background
机器人在执行操作任务时需要理解因果关系来进行物体交互。然而，许多基于数据的方法缺乏因果语义，仅仅关注相关性。本文研究如何通过结合因果贝叶斯网络和概率编程，提出了一种新型的因果贝叶斯推理架构COBRA-PPM，用于不确定环境下的机器人操作干预推理。该架构通过高保真度的Gazebo实验，在方块堆叠任务中展示了其预测准确性和成功的操作选择。此外，该方法在真实机器人中进行了模拟到实际的转换，展示了在处理传感器噪声和随机动作的不确定性方面的有效性。该通用和可扩展的框架支持多种操作场景，为机器人和因果关系的交叉领域未来工作提供了基础。
## Innovation
提出COBRA-PPM架构，结合因果贝叶斯网络和概率编程来执行不确定性下的介入推理。该方法通过高保真度实验和真实机器人场景验证了其预测准确性和操作成功率。它有效处理传感器噪声和随机动作的不确定性，展示了从模拟到实际的转移效果，并提出了一种通用和可扩展的框架以支持多种操作场景。
## Conclusion
本文开发的COBRA-PPM架构为不确定性环境下机器人操作提供了一种有效的因果推理方法。通过高保真度实验和应用在真实的家庭机器人中表明，该方法能有效处理实际操作中的不确定性，并验证了其在多种操作场景中的适用性。该工作为机器人和因果关系交叉领域未来研究奠定了基础。
# 582. `cs.LG` -  crowdsourcing 中的数据质量和恶意行为检测 [PDF](https://arxiv.org/pdf/2404.17582), [HTML](https://arxiv.org/abs/2404.17582)
## Authors
Yang Ba,Michelle V. Mancenido,Erin K. Chiou,Rong Pan
## Background
随着众包作为一种成本效益高且有效的数据标签获取方法的出现，对众包提供的数据质量进行评估变得至关重要，以提高分析性能并减少后续机器学习任务中的偏差。在大多数众包情况下缺乏真实参照的情况下，数据质量被定义为标注者的连贯性和可信度。鉴于在线众包需要处理更复杂的情况，而传统的 Kappa 系数和内聚类相关系数通常不适用，因此需要一种系统的方法来评估数据质量并检测潜在的恶意行为。常见的恶意行为被分为三类，而一个标注者指数被提出用于评估整个数据集的一致性，并且利用马尔可夫链和广义随机效应模型提出了两种衡量众包工人可信度的指标。这些方法在人脸识别任务中进行了验证，包括模拟和来自两个众包平台的实际数据。
## Innovation
提出了一个系统的方法来评估数据质量和检测潜在的恶意行为，包括标注者连贯性和可信度的定义，三类恶意行为的分类，以及利用统计分析方法评估数据质量和工人可信度的指标，这些方法在不同的数据集中进行了验证。
## Conclusion
这些方法展示了其实用性和优势，并且可以在众包任务中使用，特别是当存在复杂的恶意行为情境时。
# 583. `cs.LG` - Dual-Channel Multiplex Graph Neural Networks for Recommendation [PDF](https://arxiv.org/pdf/2403.11624), [HTML](https://arxiv.org/abs/2403.11624)
## Authors
Xiang Li,Chaofan Fu,Zhongying Zhao,Guanjie Zheng,Chao Huang,Yanwei Yu,Junyu Dong
## Background
推荐系统在准确捕捉用户和物品的属性以反映个人偏好方面起着关键作用。现有的推荐技术已经开始转向在推荐情景中建模用户和物品之间的多种交互关系的影响，例如在线购物平台上的点击、收藏和购买等行为，但仍面临两个主要挑战：一是对由多重关系组成的交互行为模式对表示学习的影响建模不足；二是忽视不同行为模式中的各种关系对目标关系的影响及其相互依赖性。现有方法在这两方面表现不佳，从而限制了其性能的提升，特别是在复杂的多层交互关系中捕捉用户和物品之间真正意图的效果。
## Innovation
本文提出了一种新的推荐框架，即双通道多层图神经网络（DCMGNN），该框架能够解决上述两个挑战。DCMGNN 包含一个显式的交互行为模式表示学习器，用于捕捉由多种用户-物品交互关系组成的交互行为模式，并包括一个关系链表示学习器和一个关系链感知编码器，用于发现各种辅助关系对目标关系的影响、不同关系之间的依赖关系以及行为模式中的适当关系顺序。实验结果表明，DCMGNN 在所有三个真实世界数据集上都超过了各种最先进的推荐方法，分别在召回率（Recall@10）和 NDCG@10 上平均提高了 10.06% 和 12.15% 的性能。
## Conclusion
通过利用双通道多层图神经网络（DCMGNN），该研究成功地模型了与推荐系统最相关的多种用户-物品交互模式中的信息传递方式，并发现这些模式对目标行为（如购买）的影响，从而显著提高了推荐精度。这为复杂多层交互关系中的推荐任务提供了新的视角。
# 584. `cs.LG` - 量子-经典混合极量神经网络 [PDF](https://arxiv.org/pdf/2506.18240), [HTML](https://arxiv.org/abs/2506.18240)
## Authors
Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen
## Background
本文提出了一种针对量化神经网络训练的新型二次二元优化（QBO）模型，可以通过样条插值使用任意激活和损失函数。通过引入前瞻区间传播（FIP）方法来处理多层复合结构和非线性带来的挑战。FIP通过将激活函数离散为线性子区段，保持了神经网络的普遍逼近特性，同时允许使用量子计算机优化复杂的非线性函数，从而扩大了其在人工智能领域的应用范围。文章提供了基于优化视角的风险最小化问题的经验泛化复杂性的理论上限，以及要求的伊辛自旋数。大规模求解相关的二次约束二元优化（QCBO）模型面临的挑战包括众多约束的存在。在使用惩罚方法处理这些约束时，需要优化大量的惩罚系数，增加了计算复杂性和可能影响解决方案质量。为了解决这个问题，我们采用量子条件梯度下降（QCGD）算法，利用量子计算直接求解QCBO问题并提供了解决过程的时间上界。实验结果使用相干伊辛机器（CIM）在时尚MNIST分类任务上达到了94.95%的准确性，只采用了1.1位精度的精度。
## Innovation
1. 提出了一种新型二元优化（QBO）模型，使量化神经网络可以使用任意激活和损失函数。2. 引入了前瞻区间传播（FIP）方法，将激活函数离散化为线性子区段，解决了非线性与多层结构带来的挑战。3. 利用量子条件梯度下降（QCGD）算法，直接使用量子计算求解二次约束二元优化（QCBO）问题。4. 提供了解决方案的时间上界，并证明了在量子算子支持下算法的收敛性。
## Conclusion
本文提出了一种量子-经典混合算法，可以解决量化神经网络训练中面临的挑战，并证明了算法的收敛性和效率。通过实验证明了该方法在高精度要求下的有效性。
# 585. `cs.LG` - 在协变量转移下的上下文优化：基于交集Wasserstein球体的稳健方法 [PDF](https://arxiv.org/pdf/2406.02426), [HTML](https://arxiv.org/abs/2406.02426)
## Authors
Tianyu Wang,Ningyuan Chen,Chun Wang
## Background
在上下文优化中，决策者利用环境变量（协变量）做出更准确的决策。然而，当训练和测试环境中的协变量分布不同时，这种情况被称为协变量转移，会导致测试协变量的上游估计不准确，最终导致次优的下游决策。这给决策带来了挑战，尤其在不确定环境下情况更甚。
## Innovation
为解决这些挑战，该研究提出了一种新颖的方法——交集Wasserstein球体分布鲁棒优化（IW-DRO），它在分布鲁棒优化框架中结合了多个估计方法，并定义了一个由两个Wasserstein球体的交集组成的新颖歧义集，其中中心使用适当的非参数和参数估计器构造。从计算效率的角度来看，该研究重新制定了IW-DRO问题为一个可解决的凸规划问题，并开发了一种针对大规模问题的近似算法以提高计算效率。理论上，该研究证明IW-DRO相比单一Wasserstein球体DRO模型具有更优的性能，通过分析交集歧义集的覆盖范围和估计器在Wasserstein距离下的测量集中度来进一步提供性能保证，并推导出基于协变量转移的Nadaraya-Watson核估计器的有限样本集中性结果。
## Conclusion
所提出的IW-DRO框架为在协变量转移环境下操作的决策者提供了实际价值。
# 586. `cs.LG` - FluoroSAM：一种语言提示的基础模型，用于灵活的X射线图像分割 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
现有的基于特定任务的X射线图像分割模型在解决特定问题上表现良好，但应用范围有限，需要更多的数据、标注和训练时间。语言对齐的基础模型（LFMs）通过在大量可变的图像和文本数据上进行训练，实现了广泛的适用性，成为自动图像分析的有希望的工具。然而，现有的医学图像分析基础模型主要关注数据集丰富且注释详尽的场景和模态。X射线成像模态具有高度可变的图像外观和应用程序，从诊断胸片到介入性透视,X射线的数据可用性不同。因此，一个全面且语言对齐的X射线图像基础模型将是提高人类在环工作流灵活性的重要工具。
## Innovation
FluoroSAM是一种从零开始训练的基于语言提示的Segment Anything Model变体，专注于培训时使用大量多样化的合成X射线图像，涵盖了广泛的图像解剖学、成像几何和视点角度。通过在训练过程中引入向量量化（VQ）文本嵌入的最新技术，FluoroSAM能够根据自然语言提示分割多种复杂的解剖结构和工具。实验结果表明，FluoroSAM在实际X射线图像上的表现良好，并在X射线图像获取和分析的多个应用场景中展现出丰富的与机器交互能力。
## Conclusion
FluoroSAM提供了一种强大的工具，使得人类可以在X射线图像获取和分析中更灵活地参与。通过提升X射线分割的灵活性和准确性，FluoroSAM为精准诊断和介入医学中的丰富人机交互奠定了基础。
# 587. `cs.LG` - 可见和红外图像馈送中低光条件下的行人检测：问题与挑战 [PDF](https://arxiv.org/pdf/2311.08557), [HTML](https://arxiv.org/abs/2311.08557)
## Authors
Thangarajah Akilan,Hrishikesh Vachhani
## Background
行人检测已成为多项高级任务的基础，包括自动驾驶、智能交通和交通监控。现有的研究主要集中在使用可见光图像进行行人检测，尤其是在白天。然而，当环境条件变为低光或夜间时，该任务变得非常具有挑战性。最近，一些新想法被提出，使用替代源，如远红外（FIR）温度传感器的馈送，在低光条件下检测行人。这项研究回顾了低光行人检测方法的最新进展，系统地对基于区域的方法、非区域方法和基于图的方法进行了分类和分析，突出了它们的方法论、实施问题和挑战。还概述了用于研究和开发更先进行人检测算法的关键基准数据集，特别是低光情况下的数据集.
## Innovation
提出了使用远红外（FIR）温度传感器馈送在低光条件下检测行人的新方法，并对基于区域、非区域和基于图的学习方法进行了系统分类和分析，详细讨论了这些方法的问题和挑战。同时，还指出了可用于研究和开发先进行人检测算法的关键基准数据集，尤其是低光情况下的数据集.
## Conclusion
由于环境条件的变化，行人检测任务在低光或夜间变得更具挑战性。本文通过分类和分析不同的算法，为低光行人检测的研究提供了指导，同时也指出了需要进一步研究的关键问题和挑战。
# 588. `cs.LG` - 向更好的归纳知识图完成基准数据集迈进 [PDF](https://arxiv.org/pdf/2406.11898), [HTML](https://arxiv.org/abs/2406.11898)
## Authors
Harry Shomer,Jay Revolinsky,Jiliang Tang
## Background
知识图完成（KGC）旨在预测知识图（KG）中的缺失事实。近年来，KGC方法开始更关注在归纳设置中表现出色的设计，即在推理时，一部分或全部在训练期间未观察到的实体和关系也需要处理。虽然已经提出了许多用于归纳KGC的基准数据集，这些基准数据集都是现有KG的子集，用于传统的推知KGC，但我们发现当前构建归纳KGC数据集的过程无意中创造了一种捷径，即使忽略关系信息也容易被利用。具体来说，我们观察到个性化PageRank（PPR）分数在大多数数据集上能实现较强的或接近当前最佳性能。这表明现有的基准数据集可能造成了一种欺骗性的效果，使得性能评估不准确。
## Innovation
本文研究了造成这一问题的根本原因，并基于洞察，提出了一种新的策略来构建归纳KGC数据集，以减轻PPR捷径的影响。作者还使用新构建的数据集测试了多种流行的KGC方法，并分析了它们的表现。新的基准数据集有助于更好地理解归纳KGC的能力与挑战，通过消除任何可能模糊性能评估的捷径。同时，研究提供了一份关于如何构建更好的归纳KGC数据集的指导，有助于彻底解决这一问题。
## Conclusion
新的基准数据集有助于更准确地评估不同KGC方法的真正性能，促进对该领域更深入的理解。研究还提供了解决现有数据集设计问题的方向，为未来的研究和应用提供了有价值的参考。
# 589. `cs.LG` - 编码数据结构下的可解释变量子回归算法 [PDF](https://arxiv.org/pdf/2307.03334), [HTML](https://arxiv.org/abs/2307.03334)
## Authors
C.-C. Joseph Wang,F. Perkkola,I. Salmenperä,A. Meijer-van de Griend,J. K. Nurminen,R. S. Bennink
## Background
混合变量子算法（VQAs）在解决如组合优化、量子化学模拟、量子机器学习和量子错误校正等问题上具有潜力，特别是在噪声量子计算机上。然而，传统随机电路或量子交替操作者模型会导致变量子算法变得难以理解，难以部署到关键决策中。传统VQA的输出是量子门的旋转角度，缺乏直接的模型解释性。因此，本文旨在提出一种第一种可解释的量子回归算法，其中量子态精确编码经典数据表，且变量子参数直接对应回归系数，这些系数由设计即为实数，提供高程度的模型可解释性和优化成本低的特点。此外，利用编码数据结构可以减少回归映射的计算复杂度，通过经典预处理添加非线性特征来缩短电路深度以适应非线性回归。尽管作者近期在超导量子比特中实现了无噪声的编码压缩，本文也展望了在中性冷原子和离子中实现多量子比特门的潜在量子实用功能。
## Innovation
本文提出了首个直接编码经典数据表的可解释量子回归算法，其中量子态直接编码经典数据，变量子参数等同于模型可直接提供的回归系数，这些系数是设计确定的实数，提供高程度的模型可解释性和优化成本低的特点。此外，算法通过经典预处理来增强非线性特征，缩短电路深度以适应非线性回归计算。
## Conclusion
本研究提出了第一个具有可解释性的量子回归算法，该算法利用量子态直接编码经典数据，且变量子参数直接对应模型系数，从而提供高程度的模型可解释性和优化成本低的特点。通过经典预处理增强非线性特征，算法进一步提高了非线性回归的效率。尽管当前实现了压缩编码，但本文的工作展望了未来在中性冷原子和离子中的多量子比特门实现的潜在量子实用性。
# 590. `cs.LG` - 物理指导的模仿强化学习在实际驾驶中的应用 [PDF](https://arxiv.org/pdf/2407.02508), [HTML](https://arxiv.org/abs/2407.02508)
## Authors
Hang Zhou,Yihao Qin,Dan Xu,Yiding Ji
## Background
近年来，模仿强化学习（IRL）的进步显著增强了自主代理吸收专家演示的能力，使其在多种复杂任务中能够迅速掌握技能。然而，基于学习的代理在向高度动态的闭环环境转移知识时面临重大挑战。其性能受到模仿学习（IL）和强化学习（RL）的矛盾优化目标、样本效率低下以及难以发现隐藏的世界模型和物理规律的影响。
## Innovation
为了应对这一挑战，本文提出了一种完全基于数据的物理指导的IRL方法。该方法利用专家演示数据和探索性数据，并通过联合优化目标使车辆动力学的基本物理原理自然地在训练过程中浮现。评估结果表明，该方法在Waymax基准的闭环环境中表现出色，与基线方法相比，碰撞率降低了37.8%，越野率降低了22.2%。
## Conclusion
我们的方法在闭环环境中的性能评测结果优于流行的IL、RL和IRL算法。
# 591. `cs.LG` - 世界模型的理解与未来预测：世界模型的全面综述 [PDF](https://arxiv.org/pdf/2411.14499), [HTML](https://arxiv.org/abs/2411.14499)
## Authors
Jingtao Ding,Yunke Zhang,Yu Shang,Yuheng Zhang,Zefang Zong,Jie Feng,Yuan Yuan,Hongyuan Su,Nian Li,Nicholas Sukiennik,Fengli Xu,Yong Li
## Background
由于GPT-4等多模态大型语言模型和Sora等视频生成模型的进展，世界模型的概念受到了广泛关注，这些模型是实现通用人工智能的关键。世界模型通常被视为理解当前世界状态的工具或预测未来动态的工具。本文综述了世界模型的相关文献，并对这些模型进行系统分类，突出了两类主要功能：(1) 建立内部表示来理解世界机制；(2) 预测未来状态以模拟和指导决策。
## Innovation
本文提出了对世界模型的系统分类框架，强调了两类主要功能，并详细探讨了世界模型在自主驾驶、机器人技术和社交仿真等关键领域的应用，同时指出了研究面临的挑战和未来研究方向。
## Conclusion
本文总结了代表性的研究论文及其代码库，并指出研究的重点和未来可能的研究方向。
# 592. `cs.LG` - 关于阅读时间预测中语境的作用 [PDF](https://arxiv.org/pdf/2409.08160), [HTML](https://arxiv.org/abs/2409.08160)
## Authors
Andreas Opedal,Eleanor Chodroff,Ryan Cotterell,Ethan Gotlieb Wilcox
## Background
该研究提出了阅读者在实时语言理解过程中如何融入语境的新视角。背景基于独家理论，该理论认为语言单位（例如单词）的处理努力是其在语境中的信息内容的线性函数。研究指出，独家理论下的独家度虽然是可能从语言模型中推导出的语境预测器之一，但还有其他方法，如单元与上下文之间的点互信息（PMI），其预测能力在控制单字频率后与独家度相同。两者都与频率相关，这意味着独家度和PMI均不包含仅关于上下文的信息。
## Innovation
创新在于提出了一种新的技术，将独家度投影到频率的正交补空间，生成与频率无关的新语境预测器。实验表明，当使用正交化后的预测器代表语境时，解释阅读时间变异性的比例大大降低。这表明以往的研究可能高估了语境预测阅读时间的作用。
## Conclusion
实验结果显示，当使用正交化后的预测器代表语境时，解释阅读时间变异性的比例大大减小。从可解释性的角度来看，这表明以往的研究可能高估了语境在预测阅读时间中的作用。
# 593. `cs.LG` - C-学习者：因果推断中的约束学习 [PDF](https://arxiv.org/pdf/2405.09493), [HTML](https://arxiv.org/abs/2405.09493)
## Authors
Tiffany Tianhui Cai,Yuri Fonseca,Kaiwen Hou,Hongseok Namkoong
## Background
传统的调整偏差估计方法，如增强逆倾向加权和目标最大似然估计，在理论上具有如统计效率和双重鲁棒性等优点，但在治疗组和对照组重叠有限的情况下可能会产生不稳定估计，要求实践中额外假设或技巧调整。简单的填充估计器虽然稳定，但在渐进行为上却缺乏这些优点。本文旨在提出一种结合了稳定性与渐进行为优势的新型调整偏差方法，以解决上述问题。
## Innovation
本文提出了一种基于约束学习（constrained learning）的方法，即C-学习者，该方法在保证插值估计器稳定性的前提下，也实现了良好的渐进行为。具体而言，通过在目标函数中加入约束条件，确保构建的估计器在针对插值量的第一阶误差为零的情况下产出最优插值估计。此外，该方法可以通过采用灵活的模型类（包括神经网络和树型集成模型）来改进性能。实验结果表明，在治疗组和对照组重叠较少的情况下，该方法的表现优于简单的估计方法；在两种物料模型处理文本特征的情况下，C-学习者的性能尤为突出。最后，基于理论，该方法在处理重尾逆倾向得分时相较于其他调整偏差估计器表现更好，说明了在重叠较少场景下C-学习者的优势所在。
## Conclusion
本文提出的C-学习者通过结合稳定性与渐进行为的优点，提供了一种能够实现在重叠较少场景中优秀表现的新方法。这一创新不仅增强了解决实际因果推断问题的能力，也为未来的因果推断研究提供了新的方向。
# 594. `cs.LG` - Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models [PDF](https://arxiv.org/pdf/2408.00523), [HTML](https://arxiv.org/abs/2408.00523)
## Authors
Yingkai Dong,Xiangtao Meng,Ning Yu,Zheng Li,Shanqing Guo
## Background
文本到图像（T2I）生成模型通过将文本描述转化为高质量图像，极大地革新了内容创作领域。然而，这些模型可能遭受‘越狱攻击’（jailbreaking attacks），攻击者利用精心构造的提示来规避安全机制，生成不安全的内容。尽管研究人员开发了各种越狱攻击以揭示这一风险，但这些方法存在实用性差、提示不自然、搜索空间受限以及对目标系统查询需求高等显著局限性。
## Innovation
本文提出了JailFuzzer，这是一种由大型语言模型（LLM）代理驱动的新型 fuzzing 框架，旨在在黑盒环境中高效生成自然且语义有意义的‘越狱提示’。JailFuzzer 采用了 fuzz 测试原理，包括一个初始和‘越狱提示’的种子池、一个指导变异引擎（用于生成有意义的变体）和一个或acles 函数（用于评估‘越狱’成功）。此外，指导变异引擎和或acles 函数通过基于 LLM 的代理构建，这进一步确保了在黑盒环境中的效率和适应性。实验结果表明，JailFuzzer 在‘越狱’ T2I 模型方面具有显著优势，生成的提示自然且语义连贯，降低了传统防御检测的可能性，并且在产生‘越狱’的成功率方面表现出色，同时具有最小的查询开销，优于现有方法的所有关键指标。
## Conclusion
这项研究强调了在生成模型中采取更强的安全机制的必要性，并为未来防范复杂‘越狱’攻击的研究奠定了基础。JailFuzzer 已开源并在该存储库中发布: this https URL。
# 595. `cs.LG` - BINDy -- 使用可逆跳变马尔可夫链蒙特卡罗进行非线性动力学的贝叶斯识别 [PDF](https://arxiv.org/pdf/2408.08062), [HTML](https://arxiv.org/abs/2408.08062)
## Authors
Max D. Champneys,Timothy J. Rogers
## Background
数据驱动建模中的模型简洁性是一种重要的心理偏差，有助于提高模型的可解释性并防止过度拟合。现有的稀疏非线性动力学识别（SINDy）方法可以直接从数据中学习稀疏的动力学表示，给定一个基函数库。然而，这些方法通常在参数空间中寻找模型的稀疏表示，限制了模型结构的灵活性。本文探讨了一种基于贝叶斯方法的字典学习系统识别方法，以识别非线性动力学。这种方法能够在模型空间中产生稀疏模型，而不仅仅是参数空间，通过在模型结构上设置任意先验分布来实现这一点。
## Innovation
提出的BINDy方法是一种新颖的贝叶斯处理字典学习系统识别的方法，区别于现有的SINDy方法。BINDy直接估计模型在后验在内的结构和参数化之间的联合分布，这使得可以为模型结构放置任意先验，从而在模型空间而不是参数空间生成稀疏模型。为了处理参数维度可能变化的后验分布，作者提出了一种基于可逆跳变马尔可夫链蒙特卡罗的吉布斯采样方法。
## Conclusion
实验结果表明，BINDy在三个基准案例研究中相比集束SINDy具有优势，尤其是在将高概率分配给正确模型项方面表现更好。
# 596. `cs.LG` - 基于联邦学习的多无人机代理自治控制方法 [PDF](https://arxiv.org/pdf/2412.02863), [HTML](https://arxiv.org/abs/2412.02863)
## Authors
Lucas Nogueira Nobrega,Ewerton de Oliveira,Martin Saska,Tiago Nascimento
## Background
人类与机器人交互（HRI）的研究正在不断发展。在HRI中，复杂命令（动作）分类仍然是一个开放问题，通常阻碍了此类技术的实际应用。尽管有使用神经网络来检测这些动作的研究，但在使用无人机（UAVs）时，遮挡仍然是一个主要问题，尤其是在机器人移动过程中，人类操作员往往不在机器人的视野范围内。此外，在多机器人场景中，分布式训练也是一个开放问题。
## Innovation
本文提出了一种基于长短期记忆（LSTM）深度神经网络（包含两层LSTM与三层全连接层）和嵌入联邦学习（FL）的多机器人动作识别与控制方法。这种方法能够以分布式方式训练，无需云计算或其他数据存储库，便于多机器人系统的学习。此外，多机器人方法也避免了遮挡情况，并在实际机器人实验中实现了96%以上的准确率。
## Conclusion
本文提出的方法为无人机群的代理自治控制提供了新的解决方案，通过联邦学习技术在多机器人系统中实现动作识别和控制，提高了系统的鲁棒性和实际应用性。
# 597. `cs.LG` - Large Language Models中图推理的图线性化方法 [PDF](https://arxiv.org/pdf/2410.19494), [HTML](https://arxiv.org/abs/2410.19494)
## Authors
Christos Xypolopoulos,Guokan Shang,Xiao Fei,Giannis Nikolentzos,Hadi Abdine,Iakovos Evdaimon,Michail Chatzianastasis,Giorgos Stamou,Michalis Vazirgiannis
## Background
大型语言模型已经发展到可以处理包括文本、图像和音频在内的多种模态，从而启发我们探索如何有效利用这些模型来进行图推理任务。关键问题是如何将图转换为等长的标记序列，我们称之为“图线性化”，以便于大型语言模型可以更自然地处理图结构数据。我们认为，图应该在反映自然语言文本的一些特性（如局部依赖和全局对齐）的基础上进行有意义的线性化，从而使经过数万亿文本标记训练的现代大型语言模型更好地理解和处理图数据。因此，本文探讨了基于图中心性和退化性的多种图线性化方法，并使用节点重标号技术进一步增强这些方法，以实现这一目标。实验结果表明，与随机线性化基线相比，本文的方法更为有效。本文的工作引入了适合大型语言模型的新颖图表示方法，为图机器学习与统一变压器模型支持的多模态处理趋势的整合奠定了基础。
## Innovation
本文提出了基于图中心性和退化性的多种图线性化方法，并通过节点重标号技术对其进行增强，以使大型语言模型能够更自然地处理图数据。该方法能够在保持图结构特征的基础上，使大型语言模型更好地理解图数据，并通过实验验证了其与其他随机线性化基线相比的有效性，为图机器学习与多模态处理趋势的整合做出了贡献。
## Conclusion
本文的工作引入了适合大型语言模型的新颖图表示方法，通过基于图中心性和退化性的方法和节点重标号技术的增强，实现了图数据的有意义线性化，从而更好地支持了图机器学习任务。这些新颖方法的有效性在实验中得到了验证，为进一步整合图机器学习与大型语言模型的统一模型铺平了道路。
# 598. `cs.LG` - 代码生成LLM中长距离依赖处理的评估 [PDF](https://arxiv.org/pdf/2407.21049), [HTML](https://arxiv.org/abs/2407.21049)
## Authors
Yannick Assogba,Donghao Ren
## Background
随着语言模型支持的上下文尺寸越来越大，评估它们有效利用这些上下文的能力变得越来越重要。本研究通过一系列多步键检索任务来分析几个代码生成模型处理长距离依赖的能力，这些任务在长达8k词元的上下文窗口中进行。这些任务逐级增加难度，提供了比流行的针扎干草堆测试更精细的模型能力评估方法。研究发现，当函数引用晚些时候定义的另一个函数时，许多模型的性能显著下降（最多降2倍）。还观察到使用滑动窗口注意力机制的模型难以处理比一个窗口大小更远的引用。通过使用调用图信息进行简单的提示修改，提高了多步检索性能3倍。本分析突显了长上下文性能需要超越单一事实检索文档之上的更深入考虑的必要性
## Innovation
使用多步键检索任务和滑动窗口注意力机制的评估方法来更精细地评估代码生成模型处理长距离依赖的能力，证明了通过调用图信息的简单提示修改能够显著提高多步检索性能
## Conclusion
长上下文表现需要比单一事实检索文档更深入的考虑。许多模型在处理长距离依赖时存在明显性能下降的问题，特别是当涉及跨多个窗口大小的引用时。通过调用图信息的提示修改可以显著提高这些模型的多步检索能力。
# 599. `cs.LG` - 使用无监督学习进行窄带无线电技术信号搜索中的异常检测和射频干扰分类 [PDF](https://arxiv.org/pdf/2411.16556), [HTML](https://arxiv.org/abs/2411.16556)
## Authors
Ben Jacobson-Bell,Steve Croft,Carmen Choza,Alex Andersson,Daniel Bautista,Vishal Gajjar,Matthew Lebofsky,David H. E. MacMahon,Caleb Painter,Andrew P. V. Siemion
## Background
无线电技术信号搜寻是一个异常检测问题，候选信号是射频频段干扰（RFI）背景中显著的‘针’。当前的搜索框架发现了大量的假阳性信号，特别是在大规模调查中，需要很大程度的手动跟进。无监督学习提供了一种算法方式来筛选出最异常的信号，并可将具有形态相似特征的RFI信号分类在一起。GLOBULAR（Grouping Low-frequency Observations By Unsupervised Learning After Reduction）聚类是一种信号处理方法，使用HDBSCAN来降低假阳性率，并孤立异常信号以供进一步分析。当与标准窄带信号检测和空间滤波管道结合时，例如turboSETI，GLOBULAR聚类可以显著提高标准管道的假阳性率，表明未来大型调查的手动跟进要求可以大幅改善。通过清除高频谱占用区域的RFI信号，GLOBULAR聚类可能也有助于发现标准管道未能检测到的信号。我们通过对97个附近的银河系L波段单一turboSETI搜索进行基准测试，展示了93.1%的假阳性击中率和99.3%的假阳性事件减少率。
## Innovation
GLOBULAR聚类方法结合了无监督学习和HDBSCAN算法，有效降低了假阳性率，能够从大量各种RFI信号中筛选出实际的技术信号，并提供了一种自动处理假阳性信号的新方法。这种方法在窄带无线电技术信号搜集中表现出了显著的优势，尤其在减少手动跟进步骤方面有巨大潜力。与传统方法相比，本方法可以通过识别和隔离异常信号避免过多的错误警示，同时也能从高RFI区域识别潜在的技术信号。
## Conclusion
通过无监督学习方法GLOBULAR聚类，可以从大量高RFI信号中准确筛选出真正感兴趣的技术信号，并降低假阳性率。该方法显著提升了窄带无线电技术信号搜寻的效果，对于未来的大型调查具有重要的应用前景。我们通过基准测试发现，这种方法在减少了假阳性信号的同时，也可以有效识别某些被标准管道遗漏的技术信号。
# 600. `cs.LG` - 解锁跨语言模型的图像数据集及更复杂的EEG分类任务中的上下文学习 [PDF](https://arxiv.org/pdf/2501.06256), [HTML](https://arxiv.org/abs/2501.06256)
## Authors
Jelena Bratulić,Sudhanshu Mittal,David T. Hoffmann,Samuel Böhm,Robin Tibor Schirrmeister,Tonio Ball,Christian Rupprecht,Thomas Brox
## Background
大型语言模型（LLMs）表现出上下文学习（ICL）能力，使模型能够在不更新权重的情况下，仅根据上下文提供的示例完成新任务。虽然ICL适用于自然语言任务，但在文本之外的其他模态中，其出现并不总是清晰明了。本文通过系统研究LLMs的特性，揭示了支持ICL在自回归模型和其他模态中出现的属性，并强调了训练任务难度对ICL出现的重要性。通过对ICL出现的深入理解，作者解锁了其在多种视觉数据集和更复杂的MRI分类任务中的应用能力。
## Innovation
本文系统地探讨了支持ICL出现的LLMs特性，并提出了识别ICL中的确切token重复现象作为一个重要因素，该重复现象能提高ICL的稳定性和效果。同时，本文突出了训练任务难度对ICL出现的重要性，并应用新见解解锁了ICL在视觉数据集和MRI分类任务中的能力。
## Conclusion
通过研究LLMs的特性，作者成功解锁了ICL在多种非文本模态下的应用潜力，特别是对于视觉数据集以及更复杂的MRI分类任务。
# 601. `cs.LG` - 基于验证生成模型的图像超分辨率保证方法 [PDF](https://arxiv.org/pdf/2502.09664), [HTML](https://arxiv.org/abs/2502.09664)
## Authors
Eduardo Adame,Daniel Csillag,Guilherme Tegoni Goedert
## Background
随着用于图像恢复任务（如超分辨率）的生成性机器学习基础模型越来越广泛使用，迫切需要具备鲁棒性和可解释性的不确定性量化方法。该文分析了生成性模型在图像恢复任务中的现有挑战和不确定性量化方法的需求，以应对这些挑战.
## Innovation
提出了基于验证预测技术的新方法，创建一种“信心掩码”以可靠且直观地传达生成图像的可信任区域。该方法可以适应任何黑盒生成模型，即使模型的API是不透明的。该方法只需易获取的数据即可进行校准，并且可以通过选择局部图像相似性度量来高度定制化。该方法提供了关于保真度误差控制、重建质量和数据泄漏面前鲁棒性的强理论保证.
## Conclusion
通过实验评价验证了该方法的有效性，并证明该方法具有强大的性能。
# 602. `cs.LG` - WyckoffDiff——一种用于晶体对称性的生成扩散模型 [PDF](https://arxiv.org/pdf/2502.06485), [HTML](https://arxiv.org/abs/2502.06485)
## Authors
Filip Ekström Kelvinius,Oskar B. Andersson,Abhijith S. Parackal,Dong Qian,Rickard Armiento,Fredrik Lindsten
## Background
晶体材料通常表现出高度对称性，但在大多数生成模型中并没有考虑到这一点。大多数模型只是对每个原子进行建模，而不对其位置或元素施加任何约束。因此，建立能够生成基于对称性的晶体结构的模型成为了一个研究空白。
## Innovation
本文提出了一个生成模型WyckoffDiff，它可以生成基于对称性的晶体描述。这通过考虑一个能够编码所有对称性的晶体结构表示来实现，并设计了一个新颖的神经网络架构，使这种表示可以在离散生成模型框架内使用。此外，还提出了一种新的度量标准Fréchet Wrenformer Distance，用于捕捉生成材料中的对称性方面，并将WyckoffDiff与最近提出的用于晶体生成的生成模型进行了基准测试。
## Conclusion
作为概念性研究的一部分，使用WyckoffDiff在热力学稳定性凸包内找到了新的材料。这种方法通过构造确保了对称性，并且由于是离散模型，生成速度快。
# 603. `cs.LG` - 自己手动合并：一种多保真度的自动化模型合并框架 [PDF](https://arxiv.org/pdf/2502.04030), [HTML](https://arxiv.org/abs/2502.04030)
## Authors
Guinan Su,Jonas Geiping
## Background
大规模语言模型（LLMs）的推理能力是一个关键的研究领域，但开发这些能力需要大量的专有数据集和计算资源。一种提高模型能力的高效方式是模型合并，这种方法通过合并多个模型而不重新训练来提供希望的替代方案。然而，当前的合并方法依赖于手工设计的策略来合并超参数，这限制了潜在模型组合的探索，并需要大量的人力投入。
## Innovation
本文提出了一种自动化模型合并框架，该框架能够进行精细的合并策略探索，并通过多保真度近似来降低计算成本。该框架支持单目标和多目标优化，并引入了两种新颖的搜索空间：分层融合（LFS）和深度整合（DIS）。
## Conclusion
在多个基准测试上的评估表明，搜索能够自主发现1) 即使是在模型已经微调过的任务上，也能进一步提升单目标性能的合并；2) 能够优化多目标前沿的合并。有效的合并可以在有限的计算能力下被发现，例如，在不到500个搜索步骤内被发现。
# 604. `cs.LG` - 使用上界和下界模型的符合预测 [PDF](https://arxiv.org/pdf/2503.04071), [HTML](https://arxiv.org/abs/2503.04071)
## Authors
Miao Li,Michael Klamkin,Mathieu Tanneau,Reza Zandehshahvar,Pascal Van Hentenryck
## Background
该论文研究在给定目标变量仅提供确定性上下界的情况下，在回归设置中建立预测区间的方法。许多已有的符合预测方法可能在目标变量边界较紧的情况下无法提供足够的覆盖区。
## Innovation
论文提出了一种新的符合预测机制（CPUL），它通过模型选择的方法，而不是简单的后处理，采用多个嵌套区间构建方法。为了解决覆盖不足的问题，论文还提出了一种优化的阈值机制（OMLT），能够在边界紧的地方调整CPUL的区间。
## Conclusion
CPUL-OMLT结合方法在大规模学习任务中被验证，实验结果表明相较于基线方法在各种数据集上表现出显著的改进。
# 605. `cs.LG` - 蛋白质结构词元化：基准测试与新策略 [PDF](https://arxiv.org/pdf/2503.00089), [HTML](https://arxiv.org/abs/2503.00089)
## Authors
Xinyu Yuan,Zichen Wang,Marcus Collins,Huzefa Rangwala
## Background
近年来，蛋白质结构词元化方法的发展迅速，将蛋白质三维结构分割成离散或连续的表示。结构词元化使得直接应用诸如语言建模之类的强大技术成为可能，用于蛋白质结构，并协同大型多模态模型将结构与蛋白质序列和功能性文本进行整合。尽管已经取得了一些进展，但这些方法的能力和局限性仍然不清楚，主要是由于缺乏统一的评估框架。因此，作者提出了一种名为StructTokenBench的框架，用于全面评估结构词元化技术的质量和效率，特别关注细粒度的局部亚结构，而不是像现有基准那样以全局结构为中心。
## Innovation
作者开发了AminoAseed，这是一种简单且有效的策略，通过改进代码本梯度更新并适当平衡代码本大小和维度，来提高词元化技术的利用效率和质量。与领先的模型ESM3相比，该方法在24个监督任务上平均实现了6.31%的性能提升，灵敏度和利用率分别提高了12.83%和124.03%。
## Conclusion
本研究通过StructTokenBench框架系统性地评估了结构词元化方法，表明目前尚无单一模型在所有评估视角中占主导地位。AminoAseed策略有效改善了词元化的质量和利用效率。
# 606. `cs.LG` - 图推理过程奖励使LLMs成为更通用的推理者 [PDF](https://arxiv.org/pdf/2503.00845), [HTML](https://arxiv.org/abs/2503.00845)
## Authors
Miao Peng,Nuo Chen,Zongrui Suo,Jia Li
## Background
尽管大型语言模型（LLMs）取得了显著的进步，但在LLMs中发展高级推理能力仍然是一个关键挑战。过程序奖励模型（PRMs）在数学推理中通过逐步反馈展示了增强推理的潜力，但它们在更广泛推理领域的应用研究甚少，主要是由于手动创建逐步骤监督的成本较高。本研究探索了在图推理问题中应用PRMs的潜力，这是一类需要复杂多步推理并能利用现有图算法自动生成逐步骤数据的领域。
## Innovation
该研究构建了最大的图推理问题数据集GraphSILO，使用自动化的任务导向轨迹和蒙特卡洛树搜索（MCTS）生成详细的推理步骤，并带有逐步骤标签。基于此数据集，该研究训练了GraphPRM，这是首个专门针对图推理问题设计的PRM，并评估了其在推理时间和直接偏好优化下的效果。实验结果显示，GraphPRM在13个图推理任务中显著提升了LLM性能，尤其是在Qwen2.5-7B中实现了9%的增长，并展示了跨领域的迁移能力，应用于新的图推理数据集和新的推理领域如数学问题解决。
## Conclusion
研究发现PRMs在增强跨领域推理中的潜力，为更灵活和有效的LLMs铺平了道路。
# 607. `cs.LG` - 针对未来 collider 新探测器几何结构微调机器学习粒子流重建 [PDF](https://arxiv.org/pdf/2503.00131), [HTML](https://arxiv.org/abs/2503.00131)
## Authors
Farouk Mokhtar,Joosep Pata,Dolores Garcia,Eric Wulff,Mengke Zhang,Michael Kagan,Javier Duarte
## Background
研究展示了在高能粒子碰撞器中训练的机器学习算法的迁移学习能力。通过对不同探测器设计的数据集进行预训练和微调，研究展示了如何在只使用少量第二数据集样本的情况下实现与从头训练近似相同的效果。特别地，使用 Compact Linear Collider 的探测器模型作为初始训练集，并展示了其知识如何成功转移到类似于 Future Circular Collider 电子-正电子模式的探测器设计。先前的研究大多只专注于单个探测器设计的数据集上的微调，而该研究是首次进行了全面模拟的跨探测器设计迁移学习研究
## Innovation
首次详细阐述了在不同探测器设计情况下进行全面模拟的迁移学习方法，并展示了其相对于从头开始训练的的优势。这种方法能够在数据量减少一个数量级的情况下达到相近的重建性能，对于未来的 collider 探测器设计优化和机器学习辅助开发具有重要意义
## Conclusion
研究确认，经过微调的模型能够在大约 10 万 CLD 事件样本的情况下达到与传统基于规则的粒子流方法相当的事件级性能，而完全从头训练的模型需要超过 1 百万的事件样本才能达到类似的表现。这表明迁移学习可以显著加速新探测器的开发过程，为通过机器学习快速优化探测器设计提供了可能
# 608. `cs.LG` - 基于双精度学习的神经营络修正的近似黎曼解算器 [PDF](https://arxiv.org/pdf/2503.13248), [HTML](https://arxiv.org/abs/2503.13248)
## Authors
Akshay Thakur,Matthew J. Zahr
## Background
黎曼问题在解决双曲偏微分方程的计算建模中至关重要，它使开发稳定且准确的迎风格式成为可能。尽管精确解算器能够提供稳健的迎风流，但其高昂的计算成本促使使用近似解算器。尽管近似解算器在大多数情况下能达到准确性要求，但在某些情况下会产生不准确的解。为了克服这个限制，本研究提出构建基于神经网络的代理模型，通过监督学习训练，旨在将内部和外部保守状态变量映射到相应的精确流。
## Innovation
本文提出两种不同的方法：一种是使用普通的神经网络，另一种是使用双精度神经网络。这些方法的性能通过在一维和二维偏微分方程的应用中进行了展示，证明了它们的稳健性和准确性。
## Conclusion
通过神经营络修正的近似黎曼解算器展示了其在实际应用中的稳健性和准确性，为解决双曲偏微分方程提供了新的方法。
# 609. `cs.LG` - LPOSS: 在像素和补丁级别上传播标签的开放词汇语义分割 [PDF](https://arxiv.org/pdf/2503.19777), [HTML](https://arxiv.org/abs/2503.19777)
## Authors
Vladan Stojnić,Yannis Kalantidis,Jiří Matas,Giorgos Tolias
## Background
当前，视觉和语言模型（VLMs）主要用于交叉模态对齐，但这些模型在处理跨补丁关系时的表现并不理想。此外，基于补丁的编码器存在分辨率限制，在补丁边缘附近的分割准确性较差。为了克服这些问题，该研究提出了一种无需训练的方法来实现开放词汇语义分割，通过标签传播增强VLMs的初始补丁预测，将其应用于像素级别以改进整个图像的分割准确度。这种方法有效捕捉了全图像的上下文交互，而无需依赖窗口处理方法。
## Innovation
该研究提出了一种训练-free 方法 LPOSS+，利用Vision Model（VM）和标签传播技术，将补丁级别的预测传播到像素级别进行优化。这种多尺度的传播机制显著提高了类边界附近的分割准确性，并且能够在多种数据集上达到最先进的性能。相比其他方法，LPOSS+ 不依赖于窗口处理，而是对整幅图像进行推理，从而更有效地捕捉图像内部的上下文交互。
## Conclusion
LPOSS+ 方法在多种开放词汇语义分割数据集上实现了最先进的分割性能，并且通过标签传播机制有效提升了补丁边缘附近的分割准确性。此外，LPOSS+ 不仅在技术方法上有创新，而且还提供了一种更高效和全面的图像分割处理方式。
# 610. `cs.LG` - 从O(n^2)到O(n)参数：医学图像分类中视觉变换器中的量子自注意力机制 [PDF](https://arxiv.org/pdf/2503.07294), [HTML](https://arxiv.org/abs/2503.07294)
## Authors
Thomas Boucher,John Whittle,Evangelos B. Mazomenos
## Background
文章背景介绍了量子视觉变压器（QViTs）的研究背景，指出传统视觉变压器（ViTs）虽然在医学图像分类上已有不错的表现，但参数量非常大。研究者希望找到一种更为参数效率的方法来提高医学图像分类的性能。
## Innovation
创新点在于提出了量子自注意力（QSA）机制，这种机制通过使用参数化的量子神经网络（QNNs）来取代传统的线性自注意力（SA）层，将参数量从O(n^2)减少到O(n)，大大降低了模型的参数量。文章通过在RetinaMNIST数据集上的实验验证了此方法的有效性，并展示了QViTs相较于传统方法的优越性能。还首次探讨了从经典到量子视觉变压器的知识蒸馏机制，并展示了其在多种医学图像分类任务上的表现。
## Conclusion
文章结论指出QSA作为一种参数效率的架构选择，对于医学图像分析具有实际意义，并且更高量子位数的架构更能从知识蒸馏前训练中受益，暗示了QSA参数量与知识蒸馏效果之间的潜在关系。
# 611. `cs.LG` - 三维变分自动编码器用于微结构体积元指纹识别 [PDF](https://arxiv.org/pdf/2503.17427), [HTML](https://arxiv.org/abs/2503.17427)
## Authors
Michael D. White,Michael D. Atkinson,Adam J. Plowman,Pratheek Shanthraj
## Background
微结构定量是建立材料性能关系的重要步骤。基于机器学习的图像处理方法表现出了优于传统图像处理技术的优势，并越来越多地应用于微结构定量任务中。本文提出了一种三维变分自动编码器（3D VAE），用于编码由晶体学取向数据体素化得到的微结构体积元（VES）。通过对晶体学取向空间中的晶体对称性进行预处理，将它们映射到晶体学基本区，促进了连续损失函数的使用和训练收敛速度的提升。然后使用3D VAE对一组具有随机纹理的等轴多晶体微结构的VES进行编码。通过对接收数据集的准确重建（相对平均位错误差为3x10^-2），证明了模型的优越性，且高维连续潜在空间维度为256。此外，模型能够很好地泛化到训练分布之外的具有不同纹理、晶粒尺寸和长宽比的微结构。这些微结构可以通过训练集的VES作为初始配置进行各种晶体塑性（CP）模拟，从而研究他们的结构-性能关系。
## Innovation
提出了一种三维变分自动编码器（3D VAE）来编码和重建内部晶体取向数据的微结构体积元（VES），并详细展示了该模型在处理具有多种晶体学特性的多晶体材料时的优越性。创新点包括通过预处理将晶体对称性映射到晶体学基本区，实现连续损失函数，提高了训练速度和模型的泛化能力。
## Conclusion
通过使用3D VAE提取的微结构指纹以及每步拉伸变形下的体积平均应力响应训练全连接神经网络，建立起来的指纹基模型能够准确预测晶体塑性应力响应的细微依赖性，在未见数据的测试集上相对均方误差为2.75 MPa。
# 612. `cs.LG` - 通过交互粒子系统实现的无梯度顺序贝叶斯实验设计 [PDF](https://arxiv.org/pdf/2504.13320), [HTML](https://arxiv.org/abs/2504.13320)
## Authors
Robert Gruhlke,Matei Hanu,Claudia Schillings,Philipp Wacker
## Background
本文介绍了一种用于复杂系统的无梯度框架，用于贝叶斯最优实验设计（BOED）在顺序设置中，该系统无法获得梯度信息。该方法结合了适用于设计优化的Ensemble Kalman Inversion (EKI)和用于高效后验抽样的Affine-Invariant Langevin Dynamics (ALDI)采样器，这两种方法都是无梯度和基于ensemble的。针对BOED中嵌套期望带来的计算挑战，本文提出了变分高斯和参数化拉普拉斯近似，为Expected Information Gain (EIG)提供了可处理的上界和下界。这些近似使大维空间和PDE约束下的反问题的实用指标估计变得可行。通过从线性高斯模型到基于PDE的推断任务的数值实验，展示了所提框架的性能，强调了该方法在信息驱动实验设计中的稳健性、准确性和效率。
## Innovation
本文提出了结合Ensemble Kalman Inversion (EKI)和Affine-Invariant Langevin Dynamics (ALDI)的无梯度框架，并通过变分高斯和参数化拉普拉斯近似来解决BOED中的嵌套期望带来的计算挑战。这是因为在处理复杂系统、高维空间和PDE约束的反问题时，传统的贝叶斯方法可能受限于需要梯度信息，而该方法能够克服这一限制，提供高效的解决方案。
## Conclusion
本文通过一系列数值实验，展示了所提出框架的有效性，特别是在信息驱动的实验设计中表现出色，方法具有高度稳健性、准确性及效率。
# 613. `cs.LG` - MARCO: 多代理实时知识集成的代码优化框架用于高性能计算 [PDF](https://arxiv.org/pdf/2505.03906), [HTML](https://arxiv.org/abs/2505.03906)
## Authors
Asif Rahman,Veljko Cvetkovic,Kathleen Reece,Aidan Walters,Yasir Hassan,Aneesh Tummeti,Bryan Torres,Denise Cooney,Margaret Ellis,Dimitrios S. Nikolopoulos
## Background
大型语言模型（LLMs）通过代码生成能力已极大地改变了软件开发，但在高性能计算（HPC）领域的有效性仍然有限。HPC 代码要求特殊优化以实现并行性、内存效率和架构特定的考虑，而通用的LLMs往往忽视了这些因素。
## Innovation
介绍了MARCO（多代理反应式代码优化器），这是一种新颖的框架，它通过专门的多代理架构增强了LLM生成的HPC代码。MARCO采用生成代码和性能评估的分离代理，并通过反馈环逐步优化。其关键创新在于MARCO的网络搜索组件，该组件实时从最近的会议论文和研究出版物中检索优化技术，填补预训练LLMs的知识空白。
## Conclusion
通过在LeetCode 75问题集上的广泛评估，结果表明MARCO相比Claude 3.5 Sonnet平均减少了14.6%的运行时间，而加入网络搜索组件则将性能提高30.9%超过基础MARCO系统。这些结果突显了多代理系统在解决高性能代码生成特殊需求方面的潜力，为领域特定模型微调提供了经济有效的替代方案。
# 614. `cs.LG` - MaizeField3D: 一个来自多样化群体的田间种植玉米的3D点云和过程模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
## Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
## Background
由于缺乏大规模和多样性的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具，尤其是在玉米研究中，发展受到了限制。2D图像数据集无法捕捉3D数据提供的重要结构细节，如叶片结构、植物体积和空间排列。
## Innovation
我们提出了MaizeField3D，这是一个专为AI准备的数据集，包含来自多样化基因组的田间种植玉米的3D点云。该数据集使用地基激光扫描仪（TLS）收集了1,045个高质量点云，并对其中520个植物进行了基于图的分割和注释，以隔离叶片和茎秆，提供了玉米植物的结构参数化表示。叶片使用NURBS表面表示，并通过结合无导数和基于导数的方法进行优化生成。严谨的手动质量控制确保了数据的准确性，并包含多分辨率采样的点云数据，以便于不同的后续计算任务。
## Conclusion
MaizeField3D将作为AI驱动的表型分析、植物结构分析以及农业研究中3D应用的基础数据集。
# 615. `cs.LG` - 曲面表现性Bregman距离及其应用 [PDF](https://arxiv.org/pdf/2504.05654), [HTML](https://arxiv.org/abs/2504.05654)
## Authors
Frank Nielsen
## Background
本文通过类比统计学中的曲面指数族，定义了曲面Bregman距离作为限制在非线性参数子空间中的Bregman距离。研究表明，有限加权参数集在曲面Bregman距离下的中心等价于满Bregman距离下的中心的右Bregman投影。文中还通过两个例子（对称化的Bregman距离和圆复常正态分布之间的Kullback-Leibler散度）展示了曲面Bregman距离的重要性。接着讨论了单调嵌入来定义表现性曲面Bregman距离，并证明了α散度关于概率单纯形到正测度锥的α嵌入而言是一个表现性曲面Bregman距离。最后提出了一种计算有限α散度球体交集的有效方法作为应用实例
## Innovation
提出了曲面表现性Bregman距离的概念，并通过α嵌入将α散度与曲面Bregman距离联系起来。基于此定义了一种计算有限α散度球体交集的有效方法
## Conclusion
证明了曲面Bregman距离及其表现性的应用价值，特别是在α散度的计算中展现了其优势，为概率论和信息论中的距离度量提供了新的视角
# 616. `cs.LG` - 使用混合和统计到计算差距进行LLM水印 [PDF](https://arxiv.org/pdf/2505.01484), [HTML](https://arxiv.org/abs/2505.01484)
## Authors
Pedro Abdalla,Roman Vershynin
## Background
研究该领域的一个广泛采用的方法是水印技术，通过这种方法可以辨别一段文本是由大型语言模型（LLM）生成还是由人类生成。本文在封闭设定中提出了一个不可检测且简单的水印方案，同时针对开放设定，即对手可以访问大部分模型的情况下，提出了一个无法去除的水印方案。
## Innovation
提出了两种水印方案：一种是针对封闭设定的不可检测且简单的水印方案；另一种是针对开放设定的无法去除的水印方案。这些方案利用混合技术和统计到计算的差距，以增强水印技术在实际应用中的可靠性和不可去除性。
## Conclusion
论文提出的方法为区分LLM生成的文本与人类生成的文本提供了一种有效手段，特别是在开放环境中，对手能够接触大部分模型时也能发挥作用。通过这些创新方案，能够更有效地对抗文本来源的识别和伪造问题。
# 617. `cs.LG` - 困境中的对齐: 复杂性障碍 [PDF](https://arxiv.org/pdf/2506.10304), [HTML](https://arxiv.org/abs/2506.10304)
## Authors
Jasper Yao
## Background
本文指出，AI对齐不仅仅是技术上的难题，根本上存在着逻辑矛盾。背景是基于机器学习的局限性和安全需求之间的冲突。具体来说，我们依赖机器学习是因为难以枚举所有必要安全规则，但确保机器学习安全需要能够生成这些规则的示例，而这与我们承认其不可能性相矛盾。文章通过一系列数学证明来验证这一悖论，构建了五个‘不可能性支柱’来展示其主要结果。
## Innovation
本文创新之处在于指出了AI对齐不仅在技术层面困难，而是存在着根本性的逻辑悖论。通过构建《枚举悖论》，并用一系列数学证明（包括几何、计算、统计、信息论和动态四大‘不可能性’）来阐述AI对齐的核心障碍，从而颠覆了传统的技术解决途径，提出了更深层次理论框架。
## Conclusion
本文结论指出，追求安全且强大的AI并非只是克服技术难题，而是面对一系列根本性的相互交织的障碍。作者通过展示这五大不可能性，提出了一个新的战略困境，探讨了这些不可能性如何在AI领域内发挥作用。同时，正在对核心定理进行形式验证。
# 618. `cs.LG` - Variational Learning Finds Flatter Solutions at the Edge of Stability [PDF](https://arxiv.org/pdf/2506.12903), [HTML](https://arxiv.org/abs/2506.12903)
## Authors
Avrajit Ghosh,Bai Cong,Rio Yokota,Saiprasad Ravishankar,Rongrong Wang,Molei Tao,Mohammad Emtiyaz Khan,Thomas Möllenhoff
## Background
变分学习（VL）近年来在训练深度神经网络中获得了广泛的应用，其表现与标准的学习方法相当。部分原因可以通过PAC-Bayes界线、最小描述长度和边缘似然理论等理论来解释，但缺乏工具来解析变分学习中的隐式正则化机制。通过对变分学习中的隐式正则化在‘临界状态’边缘（Edge of Stability, EoS）框架下的分析，可以拓展这一领域的研究。EoS框架之前已被证明可以展示梯度下降找到平坦解的可能性，并拓展了这一结果来展示变分学习也可以找到更平坦的解，这主要通过控制后验协方差和后验的Monte Carlo采样数来实现。这些结果与传统的深度学习EoS文献的推导方式类似，首先对二次问题进行推导，然后扩展到深度神经网络。经验验证这些发现对于多种大型网络如ResNet和ViT，理论结果与实际表现高度相符。这是我们第一次研究变分学习在临界状态边缘的动力学过程。
## Innovation
本文通过EoS框架分析了变分学习中的隐式正则化，发现变分学习可以找到比梯度下降更平坦的解。这一结论通过控制后验协方差和后验的Monte Carlo采样数得出，并与传统的深度学习EoS文献推导方式类似。实验验证了这些发现，表明理论结果与实际表现高度一致。这项工作首次探索了变分学习在临界状态边缘的动力学过程。
## Conclusion
本文通过EoS框架对变分学习中的隐式正则化进行了分析，发现变分学习能够找到更平坦的解，尤其是在临界状态边缘。理论结果与大型网络上的实验结果高度吻合，并且这是首次通过EoS框架来研究变分学习的动力学过程。
# 619. `cs.LG` - SLEEPING-DISCO 9M：用于生成音乐建模的大规模预训练数据集 [PDF](https://arxiv.org/pdf/2506.14293), [HTML](https://arxiv.org/abs/2506.14293)
## Authors
Tawsif Ahmed,Andrej Radonjic,Gollam Rabby
## Background
目前，生成音乐建模任务（如文本音乐、音乐描述、歌声合成、旋律重构和多模型检索）缺乏高质量的开源数据集来代表流行和知名的歌曲。过去的研究主要集中在单一或受限的因素上，如创建合成或重新录制的音乐库（例如，GTSinger，M4Singer），或任意大规模的音频数据集（例如，DISCO-10M和LAIONDISCO-12M）。然而，这些数据集在生成音乐社区中的采用率较低，因为它们未能反映现实世界的音乐及其精髓.
## Innovation
本研究提出了用于生成音乐建模任务的大规模预训练数据集——Sleeping-DISCO 9M。该数据集使用实际的流行音乐和知名艺术家的作品构建，解决了现有数据集未能反映真实世界音乐的问题，为生成音乐建模任务提供了更好的数据基础.
## Conclusion
通过Sleeping-DISCO 9M，研究团队提供了一个以实际流行音乐和知名艺术家为基础的数据集，改变了生成音乐建模领域的数据情况，提供了更贴近现实世界音乐的样本，从而有助于提升生成音乐模型的效果.
# 620. `cs.LG` - IKDiffuser: 通过扩散模型为多臂机器人生成逆运动学解的一种生成型逆运动学求解器 [PDF](https://arxiv.org/pdf/2506.13087), [HTML](https://arxiv.org/abs/2506.13087)
## Authors
Zeyu Zhang,Ziyuan Jiao
## Background
逆运动学（IK）问题是机器人技术中的基本问题，但在多臂机器人系统中，由于复杂的自我碰撞、耦合关节和高维冗余性，传统的IK求解器表现不佳，容易失败，解决方案多样性不足。多臂机器人系统的逆运动学问题尤其具有挑战性，这促使研究者探索更有效的求解方法和模型。
## Innovation
提出了IKDiffuser，一种基于扩散模型的逆运动学求解器，用于快速为多臂机器人系统生成多样化IK解。IKDiffuser通过学习配置空间中的关节分布，捕捉复杂的依赖关系，能够无缝推广到不同结构的多臂机器人系统，并能够在推断过程中增加额外目标，提供灵活性和适应性。在6种不同的多臂系统上的实验结果表明，IKDiffuser在解的准确度、精度、多样性和计算效率方面超越了现有求解器。
## Conclusion
IKDiffuser提供了解决多臂机器人逆运动学问题的可扩展且统一的方法，促进了多臂机器人系统在实时操作任务中的应用潜力。
# 621. `cs.LG` - 回收网页：一种增强语言模型预训练数据质量和数量的方法 [PDF](https://arxiv.org/pdf/2506.04689), [HTML](https://arxiv.org/abs/2506.04689)
## Authors
Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li
## Background
大型语言模型的性能随着模型大小和数据规模的增加而提高。尽管预训练过程依赖于大规模网页抓取，并使用几乎所有可用的互联网数据源，但由于计算资源的增长速度快于数据池增长速度，且高质量文本数据的可用性更加有限，导致面临“数据墙”的问题。
## Innovation
本文提出了REWIRE方法，通过重塑和回收现有过滤流程中丢弃的低质量数据，将它们转换为可用于训练的高质量文档，并增加了合成数据在最终预训练数据集中的比例。实验表明，混合高质量原始文本和重写文本相比仅使用过滤后网络数据进行训练，能够分别在22个不同任务中提高1.0%、1.3%和2.5%的表现，且使用混合文本的数据训练比同时获取两倍网络数据更为有效。此外，REWIRE方法在预训练数据质量方面优于其他合成数据生成方法（如维基百科风格的重写、问答合成和知识抽取）
## Conclusion
研究表明，回收网络文本具有简单且有效的潜力，可以用于扩展预训练数据，提升语言模型的性能。
# 622. `cs.LG` - 细粒度注意力头选择的扰动指导 [PDF](https://arxiv.org/pdf/2506.10978), [HTML](https://arxiv.org/abs/2506.10978)
## Authors
Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim
## Background
在扩散模型中，新的引导方法通过扰动模型来反向采样，这种方法成功地通过构建隐式弱模型引导生成远离干扰。在这些方法中，注意力扰动在无条件生成场景中表现出了强大的实证性能，特别是在无法使用分类器自由引导的情况下。然而，现有的注意力扰动方法缺乏确定应用于注意力扰动位置的原理性方法，尤其是在扩散变换器（DiT）架构中，质量相关的计算分布在多个层中。本文的研究背景是探讨注意力扰动的精细程度，从层级细化到个体注意力头，发现特定头部控制了结构、风格和纹理质量等不同的视觉概念。在此基础上，本文提出了一种名为HeadHunter的系统框架，用于迭代选择与用户目标一致的注意力头部，从而细粒度控制生成质量和视觉属性。此外，还提出了SoftPAG，通过线性插值每个选择头部的注意力图向单位矩阵方向，提供了一种连续的调节扰动强度和抑制伪影的方法。此方法不仅缓解了现有层级扰动的过度平滑问题，还通过组成头部选择实现了对特定视觉风格的有目标操纵。
## Innovation
本文创新提出了HeadHunter框架和SoftPAG方法。HeadHunter框架通过迭代选择与用户目标一致的注意力头部，实现对生成质量和视觉属性的细粒度控制。SoftPAG方法通过线性插值每个选择头部的注意力图向单位矩阵方向，提供了一种连续调节扰动强度和抑制伪影的方法。这些方法不仅缓解了现有层级扰动的过度平滑问题，还使特定视觉风格的操控成为可能。验证结果表明，这种方法在稳定性扩散3和FLUX.1等现代大规模DiT基文本到图像模型中表现出优越的一般质量增强与风格特定引导能力。
## Conclusion
本文的研究提供了扩散模型中注意力扰动的第一个头部级分析，揭示了注意层中的可解释专门化，并能够实现出有效的扰动策略方法设计，为扩散模型的高质量生成和风格特定引导提供了实用方法。
# 623. `cs.LG` - 关于城市视觉感知的全球差异——从个人特征和性格看并非你一人不同 [PDF](https://arxiv.org/pdf/2505.12758), [HTML](https://arxiv.org/abs/2505.12758)
## Authors
Matias Quintana,Youlong Gu,Xiucheng Liang,Yujun Hou,Koichi Ito,Yihan Zhu,Mahmoud Abdelrahman,Filip Biljecki
## Background
城市规划决策需要理解人们的偏好和需求，但现有的方法往往是从多文化和多城市的背景下综合这些信息，这可能导致重要的人口差异被模糊，并且可能放大偏见。本研究通过调查来自世界各地的1000名参与者对街道景观的视觉感知，探讨了不同的人口统计学特征（包括性别、年龄、收入、教育、种族和族裔，以及首次考虑的性格特质）如何影响感知。这项研究使用了街头视角的影像，旨在明确这些因素如何影响感知，并提出一个新的数据集：城市视觉感知评估考虑到社会经济因素的(SPECS)数据集。
## Innovation
本研究首次将性格特质纳入对城市视觉感知的研究中，并通过广泛的全球调查揭示了不同人口特征和性格特质对城市视觉感知的影响。此外，研究还发现了一个“现成”的机器学习模型在使用全球感知数据集训练时，往往会高估积极指标和低估消极指标，这表明地方感知需要特别考虑。这项研究试图纠正对街道感知的局部理解，很少提到人口因素或性格特质的问题。
## Conclusion
本研究的数据集SPECS揭示了在六种传统指标（安全、活力、富裕、美丽、枯燥和压抑）和四种新指标（居住、步行、骑行、绿色）中的人口统计差异，并且表明基于地理位置的情感会转移到人们的偏好上，当与其它城市的街道景观进行比较时。此外，研究还发现了一个“现成”的机器学习模型在训练时会有偏差，强调了考虑当地居民的感知的重要性。
# 624. `cs.LG` - 使用柯尔莫哥洛夫-阿诺德神经网络量子态探究量子自旋系统 [PDF](https://arxiv.org/pdf/2506.01891), [HTML](https://arxiv.org/abs/2506.01891)
## Authors
Mahmud Ashraf Shamim,Eric A F Reinhardt,Talal Ahmed Chowdhury,Sergei Gleyzer,Paulo T Araujo
## Background
神经量子态(NQS)是通过神经网络(NNs)参数化的变分波函数，用于研究量子多体系统。该研究提出了一种基于柯尔莫哥洛夫-阿诺德网络(Kolmogorov-Arnold Networks, KANs)的SineKAN模型，旨在将量子力学波函数表示为嵌套的一元函数。研究者展示了SineKAN模型在不同链长的一维横向场伊辛模型、各向异性海森堡模型和反铁磁性$J_{1}-J_{2}$模型的基态能量、保真度和各种相关函数的捕捉能力。特别是在含有100个位点的$J_1-J_2$模型中，SineKAN模型在能量基态、保真度和相关函数的准确性方面表现出色，优于之前探索的诸如受限制玻兹曼机(RBMs)、长短时记忆模型(LSTMs)和多层感知机(MLPs)等神经量子态模型，并且具有较低的计算成本。
## Innovation
SineKAN模型基于KANs，利用可学习的正弦激活函数嵌套一元函数，以捕捉量子系统的关键性质，如基态能量、保真度和相关函数。特别是在研究含有100个位点的$J_1-J_2$模型时，SineKAN模型在多个方面超越了其他神经量子态模型，显示了其在性能和计算效率上的优势。
## Conclusion
研究表明，SineKAN模型能够以高精度和低计算成本训练至所需的准确度，相较于现有的其他模型，特别是在处理含有100个位点的$J_1-J_2$模型时，表现出更强的泛化能力和计算效率。
# 625. `cs.LG` - mSTEB: 大规模多语言评估LLMs在语音和文本任务上的表现 [PDF](https://arxiv.org/pdf/2506.08400), [HTML](https://arxiv.org/abs/2506.08400)
## Authors
Luel Hagos Beyene,Vivek Verma,Min Ma,Jesujoba O. Alabi,Fabian David Schmidt,Joyce Nakatumba-Nabende,David Ifeoluwa Adelani
## Background
大型语言模型（LLMs）在多种任务上展现出出色的性能，包括多模态设置中的语音任务。然而，这些模型的评估主要集中在英语和其他资源丰富的语言上。对于资源稀缺的语言，不存在标准化评估基准。本文旨在填补这一空白，通过引入mSTEB基准，评估LLMs在语言识别、文本分类、问答和翻译等多种任务上的表现，覆盖语音和文本两种模态。研究表明，高资源语言和低资源语言之间的性能差距明显，特别是在非洲和美洲/大洋洲使用的语言中。这些发现揭示了需要更多投资以解决LLMs对低资源语言的覆盖不足问题。
## Innovation
本文的创新之处在于提出了mSTEB基准来评估LLMs在多任务上的表现，特别关注低资源语言。研究表明，该基准能够揭示LLMs在低资源语言上的性能差距，并为进一步提升LLMs的多语言支持提供新的方向。
## Conclusion
评估结果显示，LLMs在高资源语言和低资源语言之间的表现存在显著差距，特别是在非洲和美洲/大洋洲使用的语言中。实验表明，对于低资源语言，存在较大的改进空间。研究得出结论，需要加大投入来改善LLMs对低资源语言的覆盖，以进一步提升其多语言能力。
# 626. `cs.LG` - 基于上下文学习的无梯度接收器自适应：原理、应用与理论 [PDF](https://arxiv.org/pdf/2506.15176), [HTML](https://arxiv.org/abs/2506.15176)
## Authors
Matteo Zecchin,Tomer Raviv,Dileep Kalathil,Krishna Narayanan,Nir Shlezinger,Osvaldo Simeone
## Background
近年来，深度学习促进了能够在挑战传统基于模型设计条件下有效工作的无线接收器的创建。基于可编程硬件架构，深度学习接收机有望根据不同的信道环境动态适应。然而，现有的适应策略，包括联合训练、超网络方法和元学习，要么灵活性有限，要么需要通过梯度下降进行显式的优化。
## Innovation
本文提出了基于新兴的在上下文学习（ICL）的新原理，且不需要梯度法的自适应技术。研究了基于Transformer模型和结构化状态空间模型（SSMs）的ICL架构框架，并探讨了如何通过上下文信息学习自适应。此外，研究了将ICL应用于Cell-Free Massive MIMO网络，并提供了理论分析和实证证据。研究表明，ICL代表了一种基于试点信号和辅助上下文信息的实时接收器自适应的原理性且高效的方案，无需在线重训。
## Conclusion
本文提出了新的无梯度接收器自适应技术，基于ICL原理，通过上下文学习增强了自适应的灵活性和效率，在无需在线重训练的情况下有效应用于大规模MIMO网络。
# 627. `cs.LG` - 通过提示、微调和离分布提示评估小型语言模型的泛化能力和内部表示稳定性 [PDF](https://arxiv.org/pdf/2506.17289), [HTML](https://arxiv.org/abs/2506.17289)
## Authors
Rahul Raja,Arpita Vats
## Background
本研究探讨了在两种流行的适应模式下小型语言模型的泛化能力：少样本提示和监督微调。提示因其参数效率和灵活性而受到青睐，但在资源有限和分布变化的情况下，这一方法的鲁棒性尚不明确。本研究旨在通过任务格式、提示风格和模型规模的比较研究，探讨提示与微调在这两种不同适应策略下的表现，特别是在分布内和分布外（OOD）设置下的行为。除了准确性，研究还分析了每种方法学习到的内部表示，以评估任务特定特性的稳定性和抽象程度。
## Innovation
本研究通过将提示和微调应用于多种任务格式、提示样式和模型规模，进行了比较研究，以评估小型语言模型在分布内和分布外设置下的泛化能力和内部表示稳定性。此外，研究还通过分析学习到的内部表示，评估了任务特定特性的稳定性和抽象程度，从而揭示了不同适应策略下小型模型处理和泛化知识的关键差异。这项工作提供了在数据量有限情况下选择模型的实际指导，并为提示与微调之间的辩论提供了实证见解，引入了新的评估方法和视角。
## Conclusion
本研究发现，小型模型在不同的适应策略下处理和泛化的知识存在关键差异。研究提供的见解对于在低数据环境下选择模型具有实践意义，并对提示与微调之间的辩论提供了实证见解。具体建议包括哪些适应策略更适合特定任务，并强调了需要进一步探索如何提高小型模型在资源有限和分布变化情况下的泛化和表示稳定性。
# 628. `cs.LG` - 识别分散学习中的异质性 [PDF](https://arxiv.org/pdf/2506.16394), [HTML](https://arxiv.org/abs/2506.16394)
## Authors
Zelin Xiao,Jia Gu,Song Xi Chen
## Background
研究者关注在分布式 M-估计中识别不同参数组件的方法，以减少数据传输量。背景在于通过分布式计算降低计算负载的同时，识别各数据块间的异质性参数，确保模型训练效果不被数据分布差异影响，同时减少数据传输的开销。
## Innovation
提出了两种识别异质性参数的方法。一种基于重新标准化的沃尔德检验法，在分布式数据块数 $K$ 较小且异质性较稠密时有效。另一种是基于极端对比检验（ECT），通过分层样本方法，解决 M-估计中的偏差累积问题，在异质性稀疏时，对 $K$ 远大于样本大小的情况也有效且操作简便、通信效率高。结合这两种检验可以提高检验稳健性和功效，在不同水平的稀疏异质性下表现更好。还通过数值实验和案例研究评估了方法的误差率和功效。
## Conclusion
研究提出了多种方法来识别分布式学习中的异质性参数，通过理论分析和实验证明了其有效性和在不同情况下的适用性。
# 629. `cs.LG` - 使用路径签名的可扩展机器学习算法 [PDF](https://arxiv.org/pdf/2506.17634), [HTML](https://arxiv.org/abs/2506.17634)
## Authors
Csaba Tóth
## Background
路径签名与随机分析之间的接口是一个快速发展的领域，路径签名作为迭代积分，能够提供路径的忠实、分层表示，为顺序和结构化数据提供一种原则性和普遍适用的特征映射。路径签名源自粗糙路径理论，具有重参数不变性，非常适合建模演变动力学、长距离依赖关系和不规则采样等现实世界时间序列和图数据中的常见挑战。
## Innovation
该论文引入了一系列结合了理论稳健性和计算效率的模型，将粗糙路径理论与概率建模、深度学习和核方法相结合。关键贡献包括：基于路径签名核函数高斯过程的时间序列建模；Seq2Tens框架，利用低秩张量结构在权重空间中实现可扩展的长期依赖构建；基于图的模型，其中图上的期望路径诱导超椭圆扩散过程，为标准图神经网络提供了既有表现力又易于处理的替代方案。进一步的研究还包括随机傅里叶路径特征，一种具有理论保证的可扩展核逼近方法，以及结合高斯过程、路径签名核和随机特征与原则性遗忘机制的复发稀疏频谱路径高斯过程，用于具有自适应上下文长度的多时期时间序列预测。
## Conclusion
我们希望本论文既作为方法论工具箱又作为概念桥梁，为顺序和结构化数据的大规模、基于路径的学习提供当前技术的有用参考。
# 630. `cs.SE` - 当领地碰撞：基于活动理论探究跨学科协作 [PDF](https://arxiv.org/pdf/2506.20063), [HTML](https://arxiv.org/abs/2506.20063)
## Authors
Zixuan Feng,Thomas Zimmermann,Lorenzo Pisani,Christopher Gooley,Jeremiah Wander,Anita Sarma
## Background
软件开发团队日益多样化、嵌入化且跨学科。不同学科的领域专家(DEs)与专业的软件开发人员(SDEs)合作，带来在创作和维护复杂生产软件方面的互补专长。然而，相互冲突的期望、不同的解决问题视角以及不同的优先级导致了摩擦和冲突。
## Innovation
本研究通过活动理论(AT)这一广泛认可的跨学科框架，探讨跨学科软件开发(CDSD)中的协作动态。研究通过多方法调查（包括24次访谈和针对293名参与者的大规模验证调查）识别了SDEs和DEs的八项和六项期望，并揭示了CDSD中21种摩擦及其产生位置与方式。
## Conclusion
本研究为理解CDSD中的动态和摩擦提供了一个理论框架，并提出了对未来研究、实践者和基础设施设计的实际见解。
# 631. `cs.LG` - BeltCrack：首个顺序图像工业输送带裂纹检测数据集及其基于三域特征学习的基础方法 [PDF](https://arxiv.org/pdf/2506.17892), [HTML](https://arxiv.org/abs/2506.17892)
## Authors
Jianghong Huang,Luping Ji,Xin Ma,Mao Ye
## Background
输送带在现代工业中是重要的设备，广泛应用于生产制造过程中。输送带的健康状况对于生产效率和安全性至关重要。裂纹是威胁输送带健康的主要因素。为了保证安全，如何智能地检测输送带裂纹正越来越引起关注。利用机器学习实现智能检测时，需要真实的裂纹样本。然而，现有的裂纹数据集主要集中在道路场景或合成数据上，完全没有真实工业输送带的裂纹数据集。因此，本文提出了一个新的数据集BeltCrack和基于三域特征学习的基准方法，以填补这一空白，验证方法的实用性和有效性并表明基准方法优于其他检测方法
## Innovation
本文首次提出了BeltCrack数据集，这是第一个专门针对工业输送带裂纹检测的序列图像数据集。数据集包含从真实世界采集的输送带裂纹样本，并且还提出了一个基于三域特征学习的基准方法。该方法能够实现对输送带裂纹的有效检测，并且优于其他类似的检测方法。此外，该数据集和源代码已经公开，可以通过提供的链接访问
## Conclusion
本文成功建立了BeltCrack数据集，该数据集能够为工业输送带裂纹检测的训练和验证提供真实的数据支持。所提出的三域特征学习方法在实际检测中表现优越，并且已经被证实是有效的。未来的工作可以进一步优化该方法，提高检测的准确性和效率。
# 632. `cs.LG` - LLM生成数据的关键要素：多样性及其对模型微调的影响 [PDF](https://arxiv.org/pdf/2506.19262), [HTML](https://arxiv.org/abs/2506.19262)
## Authors
Yuchang Zhu,Huazhen Zhong,Qunshu Lin,Haotong Wei,Xiaolong Sun,Zixuan Yu,Minghao Liu,Zibin Zheng,Liang Chen
## Background
近年来，大型语言模型（LLMs）的生成能力显著提升，利用LLM生成的数据来训练下游模型已经成为缓解特定领域数据稀缺性并减少耗时标注的有效方法。然而，近期的研究指出，模型在迭代训练过程中使用自我生成的数据时，会出现模型性能下降的现象，即模型塌陷问题。尽管已有大量关于LLM生成数据影响的研究，但这些研究往往忽略了数据多样性的关键作用，而数据的多样性是影响数据质量的重要因素。本研究旨在探究LLM生成数据的多样性如何影响下游模型的性能，具体分析多样性的不同水平对下游模型性能的影响，并探讨混合不同比例LLM生成数据时模型的表现，特别是在缺乏标记数据场景下的影响效果。
## Innovation
本研究首次系统地探讨了LLM生成数据的多样性对下游模型性能的影响，并发现了在少量数据分布变化的情况下，适度多样性的LLM生成数据能够提升模型性能，而高度多样性的生成数据则可能对模型产生负面影响。这些发现为未来关于LLMs作为数据生成器的研究提供了宝贵的指导意义。
## Conclusion
本研究的实验结果表明，在有限的数据分布变化下，适量多样化的LLM生成数据能在场景缺乏标记数据的情况下提升模型性能，而高度多样化的生成数据则可能带来负面影响。我们期望本研究的实证发现能够为今后关于LLM生成数据的研究提供有价值的指导。
# 633. `cs.LG` - FORTRESS：前沿国家安全和公共安全风险评估 [PDF](https://arxiv.org/pdf/2506.14922), [HTML](https://arxiv.org/abs/2506.14922)
## Authors
Christina Q. Knight,Kaustubh Deshpande,Ved Sirdeshmukh,Meher Mankikar,Scale Red Team,SEAL Research Team,Julian Michael
## Background
大规模语言模型（LLMs）的快速进步带来了双重用途能力，这些能力既可能威胁也可能增强国家安全和公共安全（NSPS）。模型中已实施了保护措施以防止对NSPS的潜在滥用，并允许善意用户获取有益信息。然而，当前的基准测试往往未能以客观且稳健的方式测试这些保护措施对NSPS风险的抵御能力。为了应对这一挑战，本文引入了FORTRESS，以评估前沿LLM的安全保护措施的稳健性。
## Innovation
本文提出了一种名为FORTRESS的新方法，包括500个由专家构思的对抗性提示与具有4-7个二进制问题的实例化评估规约，旨在评估前沿LLM对国家安全和公共安全风险的抵御能力。FORTRESS涵盖了三个领域：化学、生物、放射性、核和爆炸物（CBRNE），政治暴力与恐怖主义，以及犯罪与金融非法活动，共包含10个细分领域。此外，每个提示-规约对还设有一个相应的良性版本，用于测试模型的过度拒绝情况，从而揭示了不同模型在潜在风险和有用性之间的权衡：Claude-3.5-Sonnet展现出最低的平均风险评分（14.09/100），但最高的过度拒绝评分（21.8/100），而Gemini 2.5 Pro则表现为低过度拒绝（1.4）和高潜在风险（66.29）。Deepseek-R1则具备最高的平均风险评分（78.05），但最低的过度拒绝评分（0.06）。模型o1在潜在风险和过度拒绝之间展现出较为平衡的权衡。
## Conclusion
本文公开发布了FORTRESS评估工具，旨在为政策制定者和研究人员提供关于模型潜在风险的明确理解，并维护了一个私人评估集以进一步完善安全评估流程。
# 634. `cs.LG` - DRO-Augment框架：通过结合Wasserstein分布鲁棒优化和数据增强实现鲁棒性 [PDF](https://arxiv.org/pdf/2506.17874), [HTML](https://arxiv.org/abs/2506.17874)
## Authors
Jiaming Hu,Debarghya Mukherjee,Ioannis Ch. Paschalidis
## Background
在许多实际应用中，确保深度神经网络（DNNs）的稳健性和稳定性至关重要，尤其是在遇到各种输入扰动的图像分类任务中。尽管已广泛采用数据增强技术来提高训练模型对这些扰动的抵御能力，但在对抗攻击和噪声数据同时具备鲁棒性方面仍存在较大的提升空间。现有技术手段虽然在某些情况下有所提升，但远未达到理想的鲁棒性水平，并且在处理极端情况下的数据扰动和对抗攻击时表现不佳。本文提出了一种创新框架——DRO-Augment，通过结合Wasserstein分布鲁棒优化（W-DRO）和多种数据增强策略，显著提升了模型在广泛程度的扰动下的鲁棒性。本研究的目标正是填补现有方法在提升模型稳健性和准确性这一方面存在的不足，尤其是在遭受严重数据扰动和对抗攻击的场景下，并保持在干净数据集上的准确性。
## Innovation
本文提出的DRO-Augment框架，引入了一种结合Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略的新颖方法，显著提升了单一模型的鲁棒性，特别是在严重的数据多次扰动和对抗攻击下表现出了比现有增强方法更好的鲁棒性。同时，这种方法在保持模型在干净数据集上的高精度的同时，展现了广泛的适用性和优越性，为该领域提供了新的研究思路和实践工具。
## Conclusion
本文从理论上建立了使用计算效率高、变异性正则化损失函数训练神经网络的新泛化误差界，并通过一系列基准数据集（包括但不限于CIFAR-10-C、CIFAR-100-C、MNIST和Fashion-MNIST）的实验验证了DRO-Augment方法的有效性，证明了其在改善模型鲁棒性和准确性方面的显著优势。
# 635. `cs.SE` - 在代码分块过程中，LLMs能否取代人类？ [PDF](https://arxiv.org/pdf/2506.19897), [HTML](https://arxiv.org/abs/2506.19897)
## Authors
Christopher Glasz,Emily Escamilla,Eric O. Scott,Anand Patel,Jacob Zimmer,Colin Diggs,Michael Doyle,Scott Rosen,Nitin Naik,Justin F. Brunelle,Samruddhi Thaker,Parthav Poudel,Arun Sridharan,Amit Madan,Doug Wendt,William Macke,Thomas Schill
## Background
大型语言模型（LLMs）已成为计算机科学中不可或缺的工具，特别是在代码理解和生成方面。然而，现有研究并没有解决政府应用中代码特有的多种挑战。政府企业的许多软件是用诸如MUMPS或汇编语言（ALC）等过时语言编写的，这些系统的总字符长度超出了当前商用LLMs的上下文窗口大小。此外，LLMs主要针对现代编程语言进行训练，并且对过时语言的测试相对有限，其对过时语言的理解能力存在不确定性，因此是一个需要实际研究的领域。本研究探讨了LLMs在过时政府代码（如ALC和MUMPS）现代化的应用，特别是在解决输入限制的挑战方面。研究通过探究不同的代码分块方法优化了历史代码文件的摘要模块注释生成，评估了代码分块方法对不同LLMs（包括GPT-4o，Claude 3 Sonnet，Mixtral，Llama 3）生成文档质量的影响。研究表明，LLMs可以准确选择与人类专家分块紧密相关的分割点。研究还发现，分块方法对下游任务，如文档生成有着显著影响。生成的注释比人类创建的注释更有事实依据，也更有用，分别高出20%和10%。因此，本研究结论是，LLMs可以在LLM辅助的大型代码库现代化过程中作为人类分块的良好替代品。
## Innovation
本研究聚焦于政府应用中的过时语言代码现代化，特别是探究了LLMs在代码分块、优化生成摘要模块注释方面的应用。研究表明，LLMs能够有效处理过时语言代码，并根据人类专家水平选择合适的分割点。同时，研究还发现代码分块方法是影响LLMs生成高质量文档的关键因素，从而丰富了现有研究成果，展示了在过时语言代码领域LLMs的潜力。
## Conclusion
本研究结论认为，LLMs在LLM辅助的大型代码库现代化过程中可以替代人类进行代码分块，生成高质量的文档注释，提升了代码理解和现代化的整体效率。
# 636. `cs.SE` - 数字系统中的数字孪生组成：一项系统文献综述 [PDF](https://arxiv.org/pdf/2506.20435), [HTML](https://arxiv.org/abs/2506.20435)
## Authors
Mennatullah T. Khedr,John S. Fitzgerald
## Background
数字孪生(DTs)在复杂系统中，尤其是在网络物理系统(CPS)和系统集群(System-of-Systems, SoS)中被广泛应用。有效的集成是关键问题。本文研究了数字孪生组成及其验证与验证(V&V)方法学，分析了2022年至2024年的21篇相关文献，探讨了数字孪生的组成机制、SoS特征以及V&V的形式化程度、范围和挑战。
## Innovation
本文贡献了一个结构化的V&V方法分类，并强调了标准化、可扩展的V&V和严谨的组成方法论对复杂数字孪生实现的迫切需求。
## Conclusion
数字孪生的组成虽然有所讨论，但形式化程度不足，V&V方法多种多样，主要是半形式化和模拟方法，形式验证使用不足。关键技术挑战包括模型不确定性与集成复杂性。方法学挑战表明，目前缺乏针对数字孪生的标准化V&V框架，需要超越模型验证，解决集成和网络物理一致性问题。
# 637. `cs.SE` - PIs 整合研究软件工程的十个简单规则 [PDF](https://arxiv.org/pdf/2506.20217), [HTML](https://arxiv.org/abs/2506.20217)
## Authors
Stuart M. Allen,Neil Chue Hong,Stephan Druskat,Toby Hodges,Daniel S. Katz,Jan Linxweiler,Frank Löffler,Lars Grunske,Heidi Seibold,Jan Philipp Thiele,Samantha Wittke
## Background
研究软件工程（RSEng）是产生高质量研究软件的关键因素，从而提高研究结果。然而，作为研究项目的负责人，你可能不清楚RSEng是什么，如何开始使用它，或者如何最大限度地利用它来为你的研究服务。RSEng通常伴随着技术复杂性，减少了对某些研究人员的可访问性。本论文旨在提高RSEng的可访问性，并为研究项目的负责人提供实用的建议，帮助他们在研究团队中整合RSEng。通过遵循这些规则，读者可以提高他们的研究软件的质量、可重复性和可信度，最终获得更高质量、更具可重复性且更可信的研究成果。
## Innovation
论文提出了‘十个简单规则’，旨在提高研究软件工程的可访问性，并为PIs和研究团队领导者提供实用和可操作的建议，帮助他们将其整合到研究项目中。这些规则简化了RSEng的使用流程，使得更多的研究人员能够理解和应用这项技术。
## Conclusion
通过遵循这些规则，读者可以提高研究软件的质量、可重复性和可信度，从而最终获得更高质量、更具可重复性且更可信的研究成果。
# 638. `cs.SE` - Large Language Model-Driven Code Compliance Checking in Building Information Modeling [PDF](https://arxiv.org/pdf/2506.20551), [HTML](https://arxiv.org/abs/2506.20551)
## Authors
Soumya Madireddy,Lu Gao,Zia Din,Kinam Kim,Ahmed Senouci,Zhe Han,Yunpeng Zhang
## Background
建筑信息建模（BIM）中的代码合规检查是一个耗时且容易出错的过程，传统的手动检查方法难以满足时间和准确性的要求，因此需要引入新技术来改善这一过程。
## Innovation
本文提出了一种基于大型语言模型（LLM）的方法，半自动化处理建筑信息建模中的代码合规检查。该系统将LLM与Revit软件结合，利用LLM解释建筑规范、生成Python脚本，并在BIM环境中执行半自动化的合规检查。该方法通过自动化评估关系和生成可操作报告，简化复杂规范，提高识别建筑平面图、材料使用和对象放置等方面的违规情况的效率和准确性，从而简化复杂规定，确保可靠的合规性，并减少重复任务，减轻工作负担，提供一种全面、适应性和成本效益高的解决方案，特别是在施工项目的多种监管文件中应用前景广泛。
## Conclusion
该系统通过提供全面、灵活且成本效益高的方法，为BIM基合规检查提供了有力的支持，显示出在未来建筑项目中广泛应用的潜力。
# 639. `cs.SE` - Define-ML: 一种构思机器学习赋能系统的途径 [PDF](https://arxiv.org/pdf/2506.20621), [HTML](https://arxiv.org/abs/2506.20621)
## Authors
Silvio Alonso,Antonio Pedro Santos Alves,Lucas Romao,Hélio Lopes,Marcos Kalinowski
## Background
随着机器学习（ML）在软件系统中的日益普及，需要专门的方法来应对ML特有的挑战，包括数据依赖性、技术可行性以及业务目标与概率系统行为之间的对齐。传统的构思方法如精益初始阶段（Lean Inception）缺乏对这些ML考虑因素的结构化支持，这可能导致产品愿景不一致和不切实际的期望。
## Innovation
本文提出了一种名为Define-ML的框架，它扩展了精益初始阶段，引入了专门的活动——数据源映射、特征到数据源映射和ML映射，以系统性地在初始阶段将数据和技术约束整合到ML产品构思中。该框架采用技术转移模型进行开发和验证，包括静态验证和动态验证，并结合定量调查和定性反馈来评估其效用、易用性和采用意图。
## Conclusion
Define-ML提供了一种开放可用、经过验证的方法来构思ML产品，继承了精益初始阶段的灵活性，同时使功能与可用数据对齐，并提高了技术可行性的意识。
# 640. `cs.SE` - AI与敏捷软件开发：从挫感到成功——XP2025研讨会概述 [PDF](https://arxiv.org/pdf/2506.20159), [HTML](https://arxiv.org/abs/2506.20159)
## Authors
Tomas Herda,Victoria Pichler,Zheying Zhang,Pekka Abrahamsson,Geir K. Hanssen
## Background
在XP 2025举办的全天研讨会聚集了研究者和从业者，讨论将人工智能（AI）集成到敏捷软件开发中的实际挑战和机遇。与会者通过互动环节，探讨了在敏捷软件开发实践中整合AI所遇到的问题，包括工具问题、治理问题、数据质量和关键技术缺口等。这些问题被系统地优先排序和分析，以找出根本原因。
## Innovation
参会者合作制定了一个研究路线图，指出了未来工作的具体可行方向，包括立即实施的解决方案和远大的长期目标。这一成果是对未来基于行业和学术界合作推进AI在敏捷软件开发中实施的结构化计划。
## Conclusion
该研讨会的最终成果是制定了一个结构化的行动计划，旨在促进其间的行业和学术合作，从解决现有挫感到实现成功的AI集成工具和技术。
# 641. `cs.SE` - 揭开大型语言模型供应链组成、风险及缓解措施的面纱 [PDF](https://arxiv.org/pdf/2410.21218), [HTML](https://arxiv.org/abs/2410.21218)
## Authors
Kaifeng Huang,Bihuan Chen,You Lu,Susheng Wu,Dingji Wang,Yiheng Huang,Haowen Jiang,Zhuotong Zhou,Junming Cao,Xin Peng
## Background
大型语言模型（LLMs）在智能和生产力方面产生了显著影响，许多企业将LLMs集成到其应用程序中以解决特定领域的任务。然而，将LLMs集成到具体场景中是一个系统的过程，涉及到多个组成部分，合称为LLM供应链。现有文献虽然探讨了与LLMs相关的各种风险，但在从供者和消费者两个视角系统化地描述LLM供应链方面仍存在明显缺口。因此，需要全面了解LLM供应链的构成及其组件之间的关系，以便有效缓解不同的相关风险。
## Innovation
本文开发了一个结构化分类框架，涵盖了不同类型的风险、危险行动及其相应的缓解措施，涉及供应链的不同参与者和组件。这种方法从供者和消费者的角度出发，填补了对LLM供应链组成的系统性描述的空白，并提供了关于风险和缓解措施的深入见解，有助于行业从业者避免可能的损害和损失，同时为学术研究人员提供重新思考现有方法和探索新研究方向的启示。
## Conclusion
通过对LLM供应链组成、其固有的风险及其缓解措施的全面审查，本文认为这将对行业实践者避免潜在损失有价值，同时对学术研究人员也是很具启发性的。这种方法为未来进一步研究提供了新的视角和方向。
# 642. `cs.SE` - MNN-AECS: 在移动设备上通过自适应核心选择进行LLM解码节能优化 [PDF](https://arxiv.org/pdf/2506.19884), [HTML](https://arxiv.org/abs/2506.19884)
## Authors
Zhengxiang Huang,Chaoyue Niu,Zhaode Wang,Jiarui Xue,Hanming Zhang,Yugang Wang,Zewei Xin,Xiaotang Jiang,Chengfei Lv,Fan Wu,Guihai Chen
## Background
随着对在设备上进行大语言模型（LLM）推理的需求增长，能源效率已成为主要关注点，尤其是在电池供电的移动设备上。我们的分析表明，受内存限制的LLM解码阶段主导了能源使用，但大多数现有工作集中在加速预填阶段，忽视了能源问题。
## Innovation
我们提出了自适应能源中心核心选择（AECS），并将其集成到MNN中，创建了无需root访问或OS修改的节能版本MNN-AECS。MNN-AECS旨在通过动态选择低功耗CPU核心，在保持解码速度在可接受的减慢阈值内的情况下减少LLM解码能源消耗。与原版MNN相比，MNN-AECS在7个设备和4个数据集上平均节能23%。与其他引擎（包括this http URL、executorch、mllm和MediaPipe）相比，MNN-AECS平均能耗可节省39%到78%，速度提升12%到363%。
## Conclusion
MNN-AECS是首次在无需root访问或OS修改的情况下，提供节能LLM解码的引擎级系统解决方案。它在多种设备和多个模型中展示了显著的能源节约和性能优势。
# 643. `cs.SE` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大语言模型（LLMs）在代码生成方面表现出色，但在面对外部库API频繁更新时却显得力不从心。这种限制源于它们依赖于过时的API知识，即使有当前文档的支持也无法可靠地生成代码，特别是在动态环境中。这直接影响了LLMs在处理API更新所需改造的关键任务上的表现。
## Innovation
本文提出了一种名为ReCode的新框架，该框架基于规则的强化学习方法来应对API更新问题。研究者构建了一个包含约2,000条数据集的训练集，以便在更新信息下实现版本迁移训练LLM。此外，研究还引入了一种修改后的字符串相似度度量法作为强化学习的奖励指标。实验结果显示，ReCode显著提升了LLM在动态API场景下的代码生成性能，特别是在未见过的CodeUpdateArena任务上。相对于监督式微调方法，ReCode对LLMs的一般代码生成能力影响较小。
## Conclusion
研究在多个LLM和强化学习算法上应用了ReCode，均取得了良好效果。值得注意的是，训练后的Qwen2.5-Coder-7B超过了参数为32B的代码指令调优模型以及具有相同架构的推理模型。相关代码可以在提供的链接处获取。
# 644. `cs.SE` - 结合多种软件artifact以提高基于LLM的Bug定位和程序修复效果 [PDF](https://arxiv.org/pdf/2412.03905), [HTML](https://arxiv.org/abs/2412.03905)
## Authors
Qiong Feng,Xiaotian Ma,Jiayi Sheng,Ziyuan Feng,Wei Song,Peng Liang
## Background
LLM在Automated Program Repair（APR）方面引起了广泛关注，基于LLM的方法可以通过提供错误方法插入正确的代码或直接生成补丁。然而，大多数基于LLM的方法主要依赖单一类型的软件信息，未能充分利用不同类型的软件元素，这限制了LLM在APR中的应用效果。
## Innovation
本文提出了一种名为DEVLoRe的方法，该方法结合了问题内容（描述和消息），堆栈错误跟踪，通过调试信息来定位错误方法，并通过结合问题内容、堆栈错误和调试信息来定位错误行并生成可能通过所有单元测试的补丁。结果表明，问题内容特别有助于提高LLM的故障定位和程序修复效果，不同的软件元素相辅相成，通过结合这些元素，DEVLoRe能够定位49.3%和47.6%的单个和非单个错误方法，并生成56.0%和14.5%的合理补丁，远超当前最先进的APR方法。此外，还讨论了Python代码的领先框架是否可以直接应用于Java代码，反之亦然，并提供了可复现的研究源代码和实验结果。
## Conclusion
结合问题内容、堆栈错误和调试信息的DEVLoRe方法显著提高了基于LLM的Bug定位和程序修复的效果，并且优于当前最先进的APR方法，同时为其他研究提供了参考。
# 645. `cs.SE` - CCISolver: 一端到端检测和修复方法级代码注释不一致 [PDF](https://arxiv.org/pdf/2506.20558), [HTML](https://arxiv.org/abs/2506.20558)
## Authors
Renyi Zhong,Yintong Huo,Wenwei Gu,Jinxi Kuang,Zhihan Jiang,Guangba Yu,Yichen Li,David Lo,Michael R. Lyu
## Background
代码中的注释是软件文档的重要基础，有助于开发人员有效沟通和理解代码。然而，代码-注释不一致性（CCI）会影响软件的开发、测试和维护。尽管已经对此问题进行了研究，但现有的研究往往受到不准确的数据集和不足的解决方案的影响，削弱了其实用效果。现有的数据分析表明，被采样的数据中有很大一部分是错误标签的，因此需要一个高质量的数据集来支持方法级CCI方法的训练和评估。在这个研究中，我们引入了一个名为CCIBench的新数据集，以及一个名为CCISolver的基于LLM的一端到端框架，以提高代码质量，识别并修正CCI问题。全面的评估表明，CCISolver在检测任务中达到了新的SOTA表现（F1分数89.54%），在修复任务中在GLEU得分上实现了18.84%的相对改进，超过了最强基线。此外，在实际的一端到端设置中，CCISolver的推理速度比基线模型快约36%，这一优秀的结果得到了人类评估结果的支持。
## Innovation
提出了CCIBench数据集，这是一个包含高质量数据的细化数据集，用于支持方法级CCI方法的训练和评估。此外，提出了CCISolver框架，这是一个基于LLM的端到端解决方案，能够识别和校正代码注释不一致性问题。全面评估表明，CCISolver在检测任务中的F1分数达到了新的SOTA（89.54%），在修复任务中的GLEU得分相对于最强基线有显著提升（18.84%），并且其在实际应用中的推理速度比基线模型快约36%，展示了其在实际应用中的可扩展性和适用性。
## Conclusion
CCISolver在检测和修复方法级代码注释不一致性方面表现出了优越性，解决了现有研究中的数据限制问题，通过CCISolver的技术框架在检测和修复任务中获得了有竞争力的结果。该研究证明了CCISolver的高效性和实用性，为解决代码注释不一致性的问题提供了一种新的有效方法。
# 646. `cs.SE` - 智能剪切：通过修剪坏种子提升漏洞检测的主动学习 [PDF](https://arxiv.org/pdf/2506.20444), [HTML](https://arxiv.org/abs/2506.20444)
## Authors
Xiang Lan,Tim Menzies,Bowen Xu
## Background
漏洞检测对于识别软件系统中的安全弱点至关重要。然而，机器学习模型在这一领域的有效性常常被低质量的训练数据集所限制，这些数据集中含有噪声、误标或不平衡的样本。
## Innovation
本文提出了一种新的基于数据集映射的方法，系统地识别并缓解难以学习的异常值，称为“坏种子”，从而提高模型训练效率。该方法能够根据学习难度对训练示例进行分类，并将此信息集成到主动学习框架中。与传统的基于不确定性抽样的方法不同，我们的策略优先优化数据集质量，通过过滤掉性能有害的样本并强调有用的样本来优先处理数据集质量。实验结果表明，我们的方法在F1分数上分别比随机选择提高了45.36%（DeepGini）和45.91%（K-Means），并且在CodeBERT上对Big-Vul数据集的标准主动学习性能提升分别达到61.46%（DeepGini）和32.65%（K-Means），证明了将数据集映射集成以优化样本选择在漏洞检测中的有效性。此外，该方法还增强了模型的稳健性，通过过滤坏种子提高了样本选择的准确性，并且在整个迭代过程中稳定了主动学习的性能。通过对这些异常值的特性的分析，为我们未来改进数据集构建提供了见解，使漏洞检测更可靠和成本效益更高。
## Conclusion
通过分析这些坏种子的特征，我们为未来改进数据集构建提供了见解，使漏洞检测更可靠和成本效益更高。我们的方法显著提高了模型的F1分数、样本选择的准确性以及迭代过程中的主动学习性能。
# 647. `cs.SE` - 软件工程中的研究产出物：一项系统映射研究 [PDF](https://arxiv.org/pdf/2504.12646), [HTML](https://arxiv.org/abs/2504.12646)
## Authors
Aleksi Huotala,Miikka Kuutila,Mika Mäntylä
## Background
系统综述（SRs）总结了科学领域的最新证据，包括软件工程（SE）。然而，已有研究发现，部分综合研究的报告中未包含研究产出物。本文研究了2013年至2023年间发表的537篇次级研究文献，以分析这些产出物的可用性和报告情况。
## Innovation
本文采用系统映射的方法，首次全面分析了SE领域次级研究文献中研究产出物的报告情况，指出研究产出物的可用性和报告状况有所改善，但仍然存在不足。通过对数据的回归分析表明产出物的可用性随着时间逐步提升，但在2023年，仍有较大比例的论文未提供相关产出物，甚至仅有较少的产出物被存放在具有数字对象标识符（DOI）的永久存储库中。作者建议增加对研究产出物的报告要求，以提高SE研究的透明度和可复现性。
## Conclusion
为了提高SE研究的透明度和可复现性，本文建议在次级研究文献中必须公开研究产出物。
# 648. `cs.SE` - 语言模型能否替代程序员进行编程？REPOCOD 说‘尚未’ [PDF](https://arxiv.org/pdf/2410.21647), [HTML](https://arxiv.org/abs/2410.21647)
## Authors
Shanchao Liang,Yiran Hu,Nan Jiang,Lin Tan
## Background
近年来，已出现了多个仓库级别的代码生成基准测试，如 CoderEval、Deeval、RepoEval、RepoBench 和 LongCodeArena，用于评估大型语言模型（LLMs）在超出单一基准测试如 HumanEval 和 MBPP 的能力。然而，当前这些基准测试仅包含短代码片段、合成示例，或以较小规模的仓库为中心，未能代表真实的编程任务。因此，研究了如何创建一个更真实的基准测试来评估 LLMs 在实际编程任务中的表现，从而引入了 REPOCOD，一个包含复杂任务和实际依赖性的 Python 编码基准测试，适合于评估源代码质量。
## Innovation
REPOCOD 是一个全新的基准测试，它包含来自 11 个流行项目的 980 个整函数生成任务，其中 50.8% 的任务需要仓库级别的上下文信息。每个任务伴随有 314 个开发人员编写的测试用例以提供更全面的评估。研究发现，尽管 LLMs 在这些基准测试中表现良好，但在 REPOCOD 中的表现却较为逊色，没有一个 LLM 能够达到 30% 的通过率，这揭示了构建更强的 LLMs 以在实际软件开发中辅助开发人员的必要性。另外，研究表明检索增强生成的效果优于直接依赖目标函数上下文的方法。
## Conclusion
REPOCOD 强调了 LLMs 在当前状态下仍无法完全替代开发者在实际编程任务中的作用，尽管 LLMs 表现出色，但在大规模复杂任务中仍然存在差距。这些发现推动了对更强大的 LLMs 的需求，以便在实际软件开发环境中提供更好的支持。
# 649. `cs.SE` - 带有SLA保证的CodeLLM服务中的自适应请求调度 [PDF](https://arxiv.org/pdf/2506.19677), [HTML](https://arxiv.org/abs/2506.19677)
## Authors
Shi Chang,Boyuan Chen,Kishanthan Thangarajah,Hanan Lutfiyya,Ahmed E. Hassan
## Background
代码大型语言模型（CodeLLMs）在现代软件开发流程中逐渐被集成，但它们在资源受限的、自助托管环境下高效运行仍是一个重大挑战。现有的LLM服务系统通过使用连续批次处理来提高吞吐量。然而，这些系统依赖于静态批次大小配置，不能适应波动的请求数率或异构工作负载，导致频繁的服务水平协议（SLA）违反和不稳定的服务性能。
## Innovation
我们提出了SABER，一种动态批次策略，能够预测每个请求的SLA实现可能性并实时调整决策。SABER较最佳静态配置提高了26%的好吞吐量，并将延迟变异性降低了45%，无需手动调优或重启服务。我们的结果表明，基于SLA的自适应调度对代码LLM服务的稳健性和高性能至关重要。
## Conclusion
我们的研究结果表明，具有SLA意识的自适应调度是实现稳健、高性能的CodeLLM服务的关键。
# 650. `cs.SE` - VulStamp: 使用大型语言模型进行漏洞评估 [PDF](https://arxiv.org/pdf/2506.11484), [HTML](https://arxiv.org/abs/2506.11484)
## Authors
Hao Shen,Ming Hu,Xiaofei Xie,Jiaye Li,Mingsong Chen
## Background
尽管现代漏洞检测工具能够使开发者高效地识别大量的安全缺陷，但不加选择的修复努力往往会导致额外的开发成本。特别是在大量检测到的漏洞中，许多具有低利用性或者在实际运营环境中影响甚微。因此，漏洞严重性评估已成为提高软件开发效率的关键组成部分。现有的漏洞评估方法通常依赖于与源代码构件相关的人工编写的描述，但由于描述质量的变异性以及意图解读的主观性，这些方法的性能受到严重限制。
## Innovation
本文提出了VulStamp，一个新型的基于意图的框架，以实现无需描述的漏洞评估。VulStamp采用静态分析与大型语言模型（LLM）提取漏洞代码的意图信息。基于意图信息，VulStamp使用提示调优模型进行漏洞评估。此外，为了缓解漏洞类型相关数据不平衡的问题，VulStamp集成了基于强化学习（RL）的提示调优方法来训练评估模型。
## Conclusion
VulStamp通过结合静态分析和大型语言模型，以及引入基于强化学习的提示调优方法，提供了一种新的、自动化的、不需要手动描述的漏洞评估方法，有助于提高漏洞评估的准确性和效率。
# 651. `cs.SE` - 在科学工作流系统开发中的实证研究 [PDF](https://arxiv.org/pdf/2411.10890), [HTML](https://arxiv.org/abs/2411.10890)
## Authors
Khairul Alam,Banani Roy,Chanchal K. Roy,Kartik Mittal
## Background
科学工作流系统（SWSs）是先进的软件框架，通过协调复杂的计算任务和管理庞大的数据管道，推动现代研究。这些系统提供了诸如模块化、抽象化、互操作性、工作流编排工具、资源管理、错误处理和全面文档编制等一系列关键功能。利用这些框架加速了科学计算的发展，提高了研究结果的效率和可重复性。然而，开发一个用户友好、高效且适应性强的SWS面临着诸多挑战。这项研究通过深入分析Stack Overflow和GitHub上的互动，探讨这些挑战。通过使用BERTopic进行主题建模，理解SWS开发者在这些平台上讨论的主题。研究揭示了开发人员在Stack Overflow上讨论的10个话题，如工作流创建与调度、数据结构与操作、工作流执行，并发现工作流执行是最具挑战性的。在GitHub的问题中，研究者确定了13个话题，例如错误和修复、文档、依赖项，并发现了数据结构和操作是最难的。研究还发现了Stack Overflow和GitHub上的共同话题，如数据结构与操作、任务管理以及工作流调度。此外，研究者将每个话题归类为方法、原因、内容和其他，并观察到方法类话题在所有话题中都主导地位，表明开发人员需要流程指导。这一主导趋势在聊天机器人和移动开发领域也同样明显。这项研究将指导未来的研究，提出工具和技术，帮助社区克服开发SWS时遇到的挑战。
## Innovation
本文通过实证研究方法，分析Stack Overflow和GitHub上的开发者互动内容，提供了关于科学工作流系统开发中面临的挑战的见解。特别地，研究通过BERTopic进行了主题建模，这对于理解开发者在这些平台上的讨论内容提供了新的视角。研究发现了特定的话题，并对其进行了分类，从而揭示了工作流执行、错误修复、文档编写等方面的挑战。此外，研究还指出方法类话题在所有话题中都占据主导地位，表明开发人员需要流程指导。这项研究揭示了开发科学工作流系统时的常见问题，并提出了未来研究方向和工具建议。
## Conclusion
本研究通过分析Stack Overflow和GitHub上的互动内容，揭示了科学工作流系统开发中的关键挑战，并为软件工具和技巧的开发提供了指导。最主要发现是工作流执行和数据结构操作是最具挑战性的部分，而方法类话题在所有话题中都占据主导地位，表明对过程指导的需求。未来的研究可以通过设计帮助开发者应对这些挑战的工具和技巧，指导SWS的开发。
# 652. `cs.SE` - MARCO：集成实时知识的多代理代码优化框架用于高性能计算 [PDF](https://arxiv.org/pdf/2505.03906), [HTML](https://arxiv.org/abs/2505.03906)
## Authors
Asif Rahman,Veljko Cvetkovic,Kathleen Reece,Aidan Walters,Yasir Hassan,Aneesh Tummeti,Bryan Torres,Denise Cooney,Margaret Ellis,Dimitrios S. Nikolopoulos
## Background
大型语言模型在软件开发中的代码自动生成能力取得了显著进展，但尚未解决高级性能计算（HPC）中的代码优化问题。HPC代码需要专门针对并行性、内存效率和架构特定考虑的优化，这些往往是通用型大语言模型所忽略的。
## Innovation
提出了MARCO（多代理反应式代码优化器）框架，通过专门的多代理架构增强大语言模型生成的HPC代码。MARCO通过反馈循环实现逐代优化，并采用了一个网络搜索组件，能够从最新的会议论文和研究论文中检索实时优化技术，填补预训练大语言模型的知识空白。
## Conclusion
通过对LeetCode 75题集的广泛评估，MARCO在Claude 3.5 Sonnet基础上实现平均14.6%的运行时间减少，而集成网络搜索组件后，相对于基础MARCO系统性能提高了30.9%。这些结果表明，多代理系统可以有效解决高性能代码生成的专业需求，为专门领域模型的精调提供经济高效的替代方案。
# 653. `cs.SE` - WAFFLE: 通过多模态模型进行自动化前端开发的微调 [PDF](https://arxiv.org/pdf/2410.18362), [HTML](https://arxiv.org/abs/2410.18362)
## Authors
Shanchao Liang,Nan Jiang,Shangshu Qian,Lin Tan
## Background
前端开发涉及到将UI设计转化为功能网页，这不仅对初学者困难重重，也对经验丰富的开发者构成挑战。HTML的层次结构和样式复杂性使得这一过程变得更加困难。尽管大型语言模型（LLMs）在生成源代码方面展现出了潜力，但在UI转HTML代码生成中仍存在两项重大挑战：(1) 如何有效地向LLMs表示HTML的层次结构；(2) 如何弥合UI设计的视觉特性和HTML代码的文本格式之间的差距。现有微调方法在这方面表现不尽如人意，需要一种新的方法来解决这些挑战，以提高代码生成的准确性。因此，该研究引入了Waffle，一个新颖的微调策略，通过结构感知注意力机制提升LLMs对HTML结构的理解，并通过对比性微调方法对LLMs的理解进行对齐，以改善其对UI图像到HTML代码的转换能力。
## Innovation
Waffle是一种新的微调策略，通过结构感知注意力机制提升LLMs对HTML结构的理解，并采用对比性微调方法对LLMs的理解进行对齐。这种新的方法显著提升了模型在HTML匹配度、CW-SSIM、CLIP和LLEM等多种评估指标上的表现，超越了现有的微调方法。这种策略不仅解决了上述提到的两个挑战，还展示了其在现有基准测试WebSight-Test中的潜力，并在已有基准测试Design2Code中表现优异。
## Conclusion
通过使用Waffle策略，所微调的模型在我们的新基准测试WebSight-Test和现有基准测试Design2Code上表现显著优于现有的微调方法，分别提高了9.00个百分点的HTML匹配度，0.0982的CW-SSIM，32.99的CLIP和27.12个百分点的LLEM。Waffle提供了一种有效的方式，用于提高前端开发自动化工具的性能，从而简化和加速生成符合设计规范的HTML代码过程。
