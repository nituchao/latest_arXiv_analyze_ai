# 1. `cs.AI` - 企业大规模语言模型评价基准 [PDF](https://arxiv.org/pdf/2506.20274), [HTML](https://arxiv.org/abs/2506.20274)
## Authors
Liya Wang,David Yi,Damien Jose,John Passarelli,James Gao,Jordan Leventis,Kang Li
## Background
大型语言模型（LLMs）已经在人工智能工具中展示了提高生产力的潜力，但现有的基准测试，如大规模多任务语言理解（MMLU），未能充分评估企业特定任务的复杂性。
## Innovation
本文提出了一个基于布鲁姆分类法的14任务框架，全面评估LLM在企业环境中的能力。开发了一种可扩展的管道，结合LLM作为标签者、LLM作为评判者和纠正性检索增强生成（CRAG），构建了一个包含9700个样例的稳健基准。研究表明开源模型如DeepSeek R1在推理任务中可媲美专有模型，但在基于判断的情境下表现较差，可能是由于过度思考。
## Conclusion
该基准揭示了企业环境中模型的关键性能差距，并为企业提供了模型优化的实用见解，促进了实际的大规模语言模型部署。
# 2. `cs.AI` - 准确且节能：本地检索增强生成模型在医疗任务中战胜商用大型语言模型 [PDF](https://arxiv.org/pdf/2506.20009), [HTML](https://arxiv.org/abs/2506.20009)
## Authors
Konstantinos Vrettos,Michail E. Klontzas
## Background
随着人工智能（AI）在医疗领域的广泛应用，人们对其环境和伦理影响产生了越来越多的关注。商业大型语言模型（LLMs），如ChatGPT和DeepSeek，消耗大量资源，其在医疗用途中的应用引发了关于患者隐私和安全的重大问题。
## Innovation
开发了一个可定制的检索增强生成（RAG）框架用于医疗任务，该框架监测其能源消耗和二氧化碳排放。该系统基于一些开源LLM构建了不同版本的RAG。测试的模型包括通用型和医疗专用型两种。研究结果表明，自定义的RAG模型在准确性和能效方面优于商用模型。以llama3.1:8B为基础的RAG模型在准确性和能源消耗方面表现最佳，同时具有最低的二氧化碳足迹，其每千瓦时的性能达到0.52，总二氧化碳排放为473克。
## Conclusion
我们的研究显示，本地开发的大型语言模型可以用于构建在医疗任务中优于商用在线模型的RAG，并且对环境影响较小。本模块化框架促进了可持续AI的发展，减少了电力使用并符合联合国可持续发展目标。
# 3. `cs.AI` - 使用低延迟可解释AI模型实现可信赖的实时决策支持系统 [PDF](https://arxiv.org/pdf/2506.20018), [HTML](https://arxiv.org/abs/2506.20018)
## Authors
Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao
## Background
本文探讨了利用低延迟AI模型的实时决策支持系统。研究结合了整体AI驱动决策工具的最新进展、Edge-IoT技术的集成以及有效的AI与人类团队合作的方法。研究关注了在资源受限的情况下大型语言模型如何辅助决策的问题。同时，研究还探讨了技术发展（如DeLLMa）对模型压缩方法和边缘设备上数据分析的改进，以及资源限制和需要具备适应框架的问题。
## Innovation
本文通过结合整体AI驱动决策工具、Edge-IoT技术的集成，以及大型语言模型在资源受限情况下的辅助决策方法。研究还探讨了一些技术发展，如DeLLMa（可能指一种模型优化技术）、模型压缩方法和边缘设备上数据分析的改进，以及如何处理资源限制和需要具备适应框架的问题。
## Conclusion
本文通过对技术的详细回顾，提供了实时决策支持系统开发策略和应用领域的实用视角，指出了实现更高效和灵活的AI支持系统的机会。结论为该快速变化领域的未来突破设定了方向，强调了AI如何重塑实时决策支持领域。
# 4. `cs.AI` - Prover Agent: 基于代理框架的正式数学证明 [PDF](https://arxiv.org/pdf/2506.19923), [HTML](https://arxiv.org/abs/2506.19923)
## Authors
Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai
## Background
该论文提出了一种名为Prover Agent的新型AI代理，用于自动化定理证明。Prover Agent将大型语言模型（LLMs）与形式证明助手Lean相结合。在此背景下，当前使用小型语言模型（SLMs）的方法可能需要更高的样本预算来达到类似的性能水平，因此Prover Agent在保持较低样本预算的同时达到了新的技术前沿，特别是在MiniF2F基准测试中实现了86.1%的成功率。
## Innovation
Prover Agent引入了将LLMs与Lean结合的新颖方法，通过协调非形式化推理LLMs、正式证明模型和来自Lean的反馈，生成辅助引理来协助发现整体证明策略。相比以往使用SLMs的方法，Prover Agent在保持较低样本预算的同时实现了更高的成功率，并在MiniF2F基准测试中创下了新的记录，即86.1%的成功率。
## Conclusion
Prover Agent展示了如何使用生成的辅助引理解决困难问题的案例研究，并且通过实验证明了其在自动化定理证明领域的有效性，尤其是在保持较低样本预算的同时达到了更高的成功率，从而为未来的研究提供了新的方向。
# 5. `cs.AI` - DiaLLMs: EHR 增强的临床对话系统，用于临床测试推荐和诊断预测 [PDF](https://arxiv.org/pdf/2506.20059), [HTML](https://arxiv.org/abs/2506.20059)
## Authors
Weijieying Ren,Tianxiang Zhao,Lei Wang,Tianchun Wang,Vasant Honavar
## Background
近期，大型语言模型（LLMs）在医学咨询方面取得了显著进展。然而，现有的医学LLMs忽略了电子健康记录（EHR）的至关重要作用，主要关注于诊断建议，限制了其临床应用。现有的模型在构建临床对话时未能充分整合EHR数据，导致在实际医疗环境中适用性较差。因此，本文旨在通过创建一个医学LLM（DiaLLM）来解决这些问题，该模型能够整合多样化的EHR数据，生成与实际医疗实践紧密结合的对话，以此实现临床测试推荐、结果解释和诊断预测，以更好地适应实际医疗需求。
## Innovation
本文提出了DiaLLM，这是第一个将异构EHR数据整合到临床对话中的医学LLM，通过临床测试参考（CTR）策略将每个临床代码映射到相应描述，并将测试结果分为“正常”或“异常”。此外，DiaLLM采用强化学习框架来获取证据和自动化诊断，并引入拒绝采样策略以减少冗余并提高探索效率。此外，还设计了确认奖励和类敏感诊断奖励，以指导准确的诊断预测。该系统能够进行高效的证据探索，减少模型处理的测试建议和诊断预测任务中的冗余。
## Conclusion
广泛实验证明，DiaLLM在临床测试推荐和诊断预测方面优于基础模型，表明该模型能够有效提升医学LLMs的临床应用效果。
# 6. `cs.AI` - 科学中的人工智能辅卓工具：一个案例研究 [PDF](https://arxiv.org/pdf/2506.20130), [HTML](https://arxiv.org/abs/2506.20130)
## Authors
Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil
## Background
开放科学倡议致力于提高研究输出的透明度、可访问性和可重用性，但确保发表的成果能够独立复制仍然是一个持久的挑战。本研究通过引入基于AI的平台OpenPub，旨在通过模块化的协作者支持研究人员、审稿人和读者完成开放科学关键任务，特别是在复制性方面。先前的研究表明，在使用已知可复制性基准的研究论文进行可行性测试后，OpenPub能够显著减少复制时间（从超过30小时缩短到大约1小时），并实现高覆盖率的研究结果适合计算再现。该系统系统地检测复制性障碍，包括缺失的超参数、未记录的预处理步骤以及不完整或不可访问的数据集。
## Innovation
OpenPub是一个AI辅助平台，它通过一组模块化协作者支持研究人员、审稿人和读者完成开放科学任务，特别是关于复制任务。该系统能够生成结构化的jupyter笔记本和建议，以帮助实现数据再生产的计算过程，显著减少了复制所需的时间，并检测潜在的复制障碍。
## Conclusion
这项研究表明，AI驱动的工具可以显著减轻再生产过程中的负担，有助于更透明和可验证的科学通信。这种模块化协作者架构为将AI辅助应用扩展到其他开放科学目标提供了基础。
# 7. `cs.AI` - 多臂老虎机优化的上下文归因 [PDF](https://arxiv.org/pdf/2506.19977), [HTML](https://arxiv.org/abs/2506.19977)
## Authors
Deng Pan,Keerthiram Murugesan,Nuno Moniz,Nitesh Chawla
## Background
理解检索到的上下文何部分对语言模型生成的答案有贡献对于构建可解释和值得信赖的生成问答系统至关重要。传统的基于扰动的归因方法（如SHAP）通过均匀采样子集并计算其贡献，然而这种方式计算成本高。本文的背景在于提出一种新颖的方法以有效解决这个问题。
## Innovation
本文提出了一种新颖的方法，将上下文归因问题表述为组合多臂老虎机（CMAB）问题。每个上下文片段作为多臂老虎机的一个臂进行处理，并使用组合帕斯卡采样（CTS）在有限的查询预算下高效探索组合上下文子集的大空间。这种方法通过利用片段相关性的后验估计来自适应平衡探索与利用，从而在保持高归因精确度的同时大幅提高了查询效率。与传统的均匀采样方法不同，本文的方法使得实现具有竞争力的归因质量所需的模型查询次数更少。 extensive实验表明，本文的实验结果在多种数据集和LLM上表现优异，证明了方法的有效性。
## Conclusion
实验结果表明，本文的方法在较少的模型查询次数下，达到了与传统方法同等甚至更好的归因质量。这证明了该方法在理解和提高生成问答系统透明度方面的优势。
# 8. `cs.AI` - 由语言模型构建语言模型 [PDF](https://arxiv.org/pdf/2506.20249), [HTML](https://arxiv.org/abs/2506.20249)
## Authors
Junyan Cheng,Peter Clark,Kyle Richardson
## Background
该论文背景介绍了一种利用大型语言模型（LLMs）来模拟和发现新型语言模型架构的过程，借鉴了真实的研究过程，包含了从构想和文献搜索（提案阶段）、设计和实现（代码生成）、生成性预训练到下游评估（验证）的完整阶段。系统通过使用阶梯式的规模缩放方法（Ladder of Scales），逐步从较小的模型规模向上扩展到较大的模型规模，也展示了在每个模型规模上使用新颖的遗传编程基础所带来的经验上的优点，这种方法在成功设计生成上的提升尤为显著，依据有限的训练预算筛选出最优化的设计方案，极大地促进了发现过程的高效与可分解性。
## Innovation
论文的创新点在于提出了一种基于多个LLMs的多智能体系统（Genesys），该系统模拟了研究的整个过程并采用了阶梯式的规模缩放方法。它利用了新颖的遗传编程作为基础，对比常见的直接提示生成工作流，显示出显著的优势。通过采用阶梯式的规模缩放方法，逐步从较小的模型规模扩展到较大的模型规模，文中报告了1162个新设计，1062个得到充分验证的设计具有较高竞争力，在一些常见的基准测试中甚至超过了已知的架构。此外，通过系统水平的抽样分析和正式的结果，研究者提供了关于有效自主发现系统设计的更广泛见解。
## Conclusion
研究发现，使用该系统发现的设计在效果上具有显著竞争性，并且能够显著提高发现和验证新型语言模型架构的效率。该研究不仅为语言模型的学习和优化提供了新方法，同时也为未来的自主发现系统的设计提供了更为全面和深入的理解和启示，有望在未来研究中进一步验证和完善。
# 9. `cs.AI` - 所赋予角色的大语言模型表现出类似人类的情感化推理 [PDF](https://arxiv.org/pdf/2506.20020), [HTML](https://arxiv.org/abs/2506.20020)
## Authors
Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan
## Background
人类的推理容易受到保护身份等潜在动机的影响，这种动机削弱了理性决策和判断。集体层面的情感化推理可能在讨论像人类驱动的气候变化或疫苗安全性等关键问题时对社会有害，并进一步加剧政治极化。先前的研究表明，大型语言模型（LLMs）也受到类似人类的认知偏见的影响，但LLMs如何选择性地向一致于个人身份的结论推理还很少被研究。本文旨在探讨分配给8种不同的人格如何影响LLMs的情感化推理。实验结果显示，带有角色的人类模型在区分错误信息头衔的真实性和评估科学证据方面，相较于不分配角色模型表现较差。尤其是带有政治身份的角色模型，在关于枪支控制的科学证据评价上，其结果与他们假设的政治身份一致的准确率高出90%。现有的去偏见方法效果有限。
## Innovation
本研究首次证明了所赋予角色的大型语言模型表现出类似人类的情感化推理，并且这些偏见难以通过常规的去偏见提示来缓解——这引发了对LLMs和人类中更加一致的情感化推理加剧的担忧。
## Conclusion
总之，本文的实证发现表明，赋予角色的LLMs会在其推理中表现出类似人类的情感化偏见，而且通过常规去偏见提示难以减轻这种现象，这可能会加剧LLMs和人类情感化推理的一致性，引发一定担忧。
# 10. `cs.AI` - QHackBench: 使用PennyLane黑客马拉松挑战基准化大型语言模型进行量子代码生成 [PDF](https://arxiv.org/pdf/2506.20008), [HTML](https://arxiv.org/abs/2506.20008)
## Authors
Abdul Basit,Minghao Shao,Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique
## Background
近年来，大型语言模型（LLMs）在代码生成方面显示出了强大的潜力，特别是在量子计算方面其效果仍然未被充分探索。该论文使用来自量子黑客马拉松（QHack）的实际挑战案例对PennyLane为基础的量子代码生成基准化大型语言模型进行了评估。通过引入QHackBench这一新型基准数据集和评估框架，研究者评估了模型在不同提示模式下的表现，以及检索增强生成（RAG）如何进一步提高执行成功率。QHackBench通过这种方法评估了功能性正确性、语法正确性和执行成功率，尤其是在复杂的量子算法中，RAG增强模型与标准提示结果相当，甚至在某些情况下表现更好。此外，还提出了一种多代理评估管道，不断优化错误解决方案，从而推动模型性能的进一步提升。
## Innovation
该论文的主要创新在于提出了QHackBench，这是一个基于PennyLane黑客马拉松的真实世界挑战的数据集，用于基准化大型语言模型在量子计算中的代码生成能力。通过引入RAG增强模型结构，论文展示了这种新型策略在复杂量子算法生成中的实际应用，以及多代理评估方法如何进一步提升执行成功率。此外，论文还承诺公开发布QHackBench数据集、评估框架和实验结果，以促进相关领域的进一步研究和发展。
## Conclusion
研究表明，RAG增强的模型在量子算法生成方面表现出色，特别是在复杂的挑战中，它们大约可以达到与标准提示相同的效果，甚至在某些情况下更好。此外，通过构建QHackBench数据集和提供多代理评估方法，该论文为AI辅助量子编程领域的后续研究打下了坚实基础，这将促进相关技术的进步。
# 11. `cs.AI` - 探索推理类型在表格特征发现中的应用 [PDF](https://arxiv.org/pdf/2506.20357), [HTML](https://arxiv.org/abs/2506.20357)
## Authors
Sungwon Han,Sungkyu Park,Seungeon Lee
## Background
特征工程对于表格数据在机器学习中的应用依然是至关重要的但又极具挑战性的一步。近期，大语言模型（LLMs）被用于自动生成新的特征，通过利用其庞大的知识来弥补这一不足。然而，现有的基于LLM的方法常常产生过于简单或重复的特征，部分原因是LLM选择的转换本身具有内在偏见，且生成过程中缺乏有序的推理指导以指引特征生成过程。
## Innovation
本文提出了一种新颖的方法REFeat，它通过利用多种推理类型来引导LLM发现多样的和具有信息性的特征，从而自动进行表格数据特征生成。实验表明，与现有方法相比，该方法不仅能够在平均预测准确度上取得更高的成果，而且还能够发现更多多样性和有意义的特征。
## Conclusion
这些结果证明了在基于LLM的特征发现方法中整合丰富的推理范式和自适应策略选择的前景。
# 12. `cs.AI` - 混合神经细胞自动机：用于生长建模和自我组织的随机框架 [PDF](https://arxiv.org/pdf/2506.20486), [HTML](https://arxiv.org/abs/2506.20486)
## Authors
Salvatore Milite,Giulio Caravagna,Andrea Sottoriva
## Background
神经细胞自动机（NCAs）是一种有前景的新方法，用于模拟自组织过程，在生命科学中有潜在应用。然而，NCAs的确定性性质限制了其捕捉现实世界生物和物理系统中随机性的能力。
## Innovation
提出了混合神经细胞自动机（MNCA），这是一种将混合模型的思想融入到NCAs方法中的新型框架。通过结合概率规则分配与固有噪声，MNCAs能够模拟多样化的局部行为并重现生物过程中的随机动态。实验结果表明，MNCAs在三个关键领域中表现出更高的鲁棒性、更好地再现真实的生物学生长模式并提供可解释的规则分割。
## Conclusion
这些发现将MNCAs定位为建模随机动力系统和研究自我生长过程的有前途的工具。
# 13. `cs.AI` - Mobile-R1：基于任务级奖励的交互式强化学习方法以改进视觉-语言模型驱动的移动代理 [PDF](https://arxiv.org/pdf/2506.20332), [HTML](https://arxiv.org/abs/2506.20332)
## Authors
Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng
## Background
现有的视觉-语言模型驱动的移动代理能够理解和执行复杂的指令，通过思考和推理优化其动作输出，并利用诸如Group Relative Policy Optimization (GRPO)之类的强化学习技术。然而，当前研究主要集中在离线强化学习训练或在线优化，通常通过行动级奖励来实现，这限制了代理与环境动态交互的能力，导致代理困于局部最优解，削弱了其探索能力和错误动作纠正能力。
## Innovation
提出了Mobile-R1方法，利用交互式多轮次强化学习和任务级奖励训练框架，包括三个阶段：初始格式微调，通过行动级奖励进行单步骤在线训练，以及基于多轮次轨迹的任务级奖励在线训练。这种方法增强了Mobile-R1的探索和错误纠正能力，从而取得了显著的性能提升。同时，收集了一个涵盖28个中国应用的高质量手动注释数据集，并建立了新的基准，包含500个轨迹。所有资源，包括数据集、基准、模型权重和代码都将在开源平台上提供：this https URL.
## Conclusion
该研究通过引入Mobile-R1方法，显著提高了视觉-语言模型驱动的移动代理的动态交互能力、探索性和错误纠正能力，并为此领域提供了新的参考方法和数据基准。
# 14. `cs.AI` - GymPN: 过程管理系统的决策库 [PDF](https://arxiv.org/pdf/2506.20404), [HTML](https://arxiv.org/abs/2506.20404)
## Authors
Riccardo Lo Bianco,Willem van Jaarsveld,Remco Dijkman
## Background
过程管理系统的决策支持组织中的关键任务分配，包括决定下一步执行的任务、执行任务的时间以及分配给谁。为了使决策最优，需要合适的软件工具支持这些决策。本文讨论了一个使用深度强化学习支持业务过程最优决策的软件库GymPN，该库在支持任务分配方面建立在先前研究的基础上，引入了部分过程可观测性和建模业务过程中多个决策的能力，以克服前人工作的局限性，因此能够更加真实地表示过程决策。
## Innovation
GymPN具有两项新颖的贡献：支持部分过程可观测性和建模业务过程中的多个决策。这些新颖的特性解决了之前工作中的根本限制，从而使过程决策更加现实。GymPN在八个典型的业务过程决策问题模式上进行了评估，展示出可以轻松建模所需的决策问题以及学习最优决策策略的能力。
## Conclusion
GymPN是一个用于过程管理系统决策支持的软件库。它通过引入部分过程可观测性和多决策建模能力，改进了之前的工作，并能够更真实地表示复杂的业务流程决策。通过对八个典型问题模式的评估，GymPN展示了其有效性和实用性。
# 15. `cs.AI` - Paladin-mini：一种适用于实际场景的紧凑高效接地模型 [PDF](https://arxiv.org/pdf/2506.20384), [HTML](https://arxiv.org/abs/2506.20384)
## Authors
Dror Ivry,Oran Nahum
## Background
本文介绍了针对给定上下文中的主张进行锚定问题的两个重要贡献。锚定意味着在给定的上下文（文档）和主张的情况下，文档中至少有一条支持其主张的证据。本文将介绍Paladin-mini，这是一种基于3.8B参数的开源分类器模型，用于为数据进行有无支持证据的标签化，设计用于在实际场景中实现稳健性能。此外，还将介绍一个新的评价数据集——grounding-benchmark，用于评估性能在关键推理任务方面的表现。随后将展示Paladin-mini与当前最优模型的结果，并分享可重复的结果。
## Innovation
本文的创新在于提出了Paladin-mini，这是一种紧凑型的、参数量为3.8B的开源分类器模型，针对实际应用中的鲁棒性能进行了工程设计；同时设计了一个新的评估数据集——grounding-benchmark，专注于关键推理任务的性能评估。
## Conclusion
本文展示了Paladin-mini在基准测试中的效果，并与当前最优模型进行了对比，报告了明确且可重复的结果。通过这些结果，本文验证了Paladin-mini在真实世界场景中的优秀性能和对关键推理任务的有效评估能力。
# 16. `cs.AI` - 工程中的知觉 [PDF](https://arxiv.org/pdf/2506.20504), [HTML](https://arxiv.org/abs/2506.20504)
## Authors
Konstantin Demin,Taylor Webb,Eric Elmoznino,Hakwan Lau
## Background
本文探讨了知觉在人工智能中的定义，提出了一种可能用于机器设计和建造知觉的定义。以前的研究中，虽然对知觉有一些描述，但这些描述通常缺乏具体的、功能性的定义，这使得将知觉实际应用于机器变得困难。本文旨在填补这一空白，为知觉提供一个具体的、功能性的定义，并强调这种知觉需要考虑到“主观性”这一本质方面，而不仅仅是感知内容的编码能力。
## Innovation
本文的创新在于提供了一种具体的、功能性的知觉定义，这种定义要能够被实现，并确保实现的知觉包括一种‘主观性’，而不仅仅是感知内容的编码能力。此外，本文还提出了某些感官信号需要具备持久性和质的规定性以实现这种特定的功能性知觉。这有助于克服在设计和构建人工智能过程中可能遇到的挑战，并指导我们更好地理解创建功能型知觉所需的条件。
## Conclusion
了解什么是功能性的知觉，可以让我们在无意中创造出它们之前就意识到这一点，或者至少能够尽早发现已经创建出功能性的知觉。此外，对这种知觉进行具体的定义有助于指导未来的AI设计和构建，使其更加准确地反映人类的主观体验。
# 17. `cs.AI` - 借助双向充电实现智能出行与配送服务：利润优化 [PDF](https://arxiv.org/pdf/2506.20401), [HTML](https://arxiv.org/abs/2506.20401)
## Authors
Jinchun Du,Bojie Shen,Muhammad Aamir Cheema,Adel N. Toosi
## Background
随着电动汽车（EVs）的普及，现代服务系统，如网约车和配送服务，越来越多地将电动汽车纳入其运营中。由于电动汽车通常续航里程较短，必须在响应请求时仔细考虑充电问题。随着车辆到电网（V2G）技术的发展，电动汽车不仅可以充电，还可以向电网反向供电，这带来了新的机遇和复杂性。因此，引入了一种新的电动汽车选点问题，即电车奥林匹克规划（EVOP-V2G），其目标是在确保充电和反向供电的同时，选择最优的客户需求，以最大化利润。这涉及动态电费、充电站选择和路径约束等问题。
## Innovation
本文提出了电车奥林匹克规划（EVOP-V2G）问题，并将其建模为混合整数线性规划（MIP）模型。为了解决该问题，提出了两种近似最优的元启发式算法：一种基于进化（EA），另一种基于大型邻域搜索（LNS）。实验结果表明，本方法在实际数据上的表现优于基线，能在小规模实例上保持接近最优性能，在大规模实例上具有良好的扩展性。该研究指出了对未来基于电动汽车的更智能、更盈利的移动系统的一种有前景的发展路径，并且这种系统能够主动支持电网.
## Conclusion
本文通过引入电车奥林匹克规划（EVOP-V2G）问题和相应的优化算法，展示了如何利用电动汽车的双向充电能力来优化网约车和配送服务中的利润。研究表明，这种方法能够在保障运营灵活性的同时显著提高司机的收益。
# 18. `cs.AI` - CogGen：编程视频智能辅导中的以学习者为中心的生成AI架构 [PDF](https://arxiv.org/pdf/2506.20600), [HTML](https://arxiv.org/abs/2506.20600)
## Authors
Wengxi Li,Roy Pea,Nick Haber,Hari Subramonyam
## Background
当前存在通过编程视频进行教学的不足之处，例如缺乏互动性和适应性。现有系统在学生建模和AI辅导之间的结合不够完善，导致生成的指导可能不够有效。
## Innovation
提出了一种名为CogGen的学习者中心的AI架构，该架构通过认知学徒制框架结合学生建模与基于生成AI的辅导，将编程视频转化为互动性强、适应性高的学习体验。该架构包括视频按学习目标切分、应用认知学徒策略的对话式辅导引擎以及使用贝叶斯知识追踪进行适应性指导的学生模型。技术评估显示了有效的视频切分准确性和良好的教学一致度。进一步的消融研究证实了每个组件对于生成有效指导的必要性，为将结构化学生建模与互动AI对话相结合到视频编程教育中提供了一种可扩展的方法。
## Conclusion
该研究通过子研究进一步验证了每个组件的重要性，并证明了该架构在增强基于视频的编程教育方面的有效性。
# 19. `cs.AI` - 为现实中的安全关键驾驶场景决策增强案例推理的大语言模型框架 [PDF](https://arxiv.org/pdf/2506.20531), [HTML](https://arxiv.org/abs/2506.20531)
## Authors
Wenbin Gan,Minh-Son Dao,Koji Zettsu
## Background
安全关键驾驶情景下的驾驶要求快速、情境感知的决策，这些决策需要基于对当前情形的理解和经验的推理。大语言模型（LLMs）凭借其强大的通用推理能力，为这种决策提供了有前景的基础。然而，将其直接应用于自动驾驶领域受到领域适应、情境结合和缺乏所需的经验知识的挑战，尤其是在动态、高风险环境中做出可靠和可解释的决策。因此，需要一种能够融合上下文理解和过往经验的方法来改善这一领域的决策支持工具。
## Innovation
本文提出了一种增强案例推理的大语言模型（CBR-LLM）框架，用于复杂高风险场景中的避险机动决策。该方法结合了仪表板摄像机视频输入的语义场景理解与相关过往驾驶案例的检索，使LLMs能够生成既情境敏感又符合人类行为的机动建议。研究表明，该框架在提高决策准确度、解释质量和与人类专家行为的一致性方面效果显著。风险意识的提示策略进一步增强了模型在不同风险类型下的表现，而基于相似性的案例检索比随机采样更有效指导情境学习。案例研究进一步证明该框架在复杂现实条件下具有稳健性，有望成为智能驾驶系统的适应性和可信决策支持工具。
## Conclusion
实验结果表明，该框架在多个开源LLM上提高了决策准确性、解释质量和与人类专家行为的一致性。风险意识的提示策略和基于相似性的案例检索方法显著提升了在各种风险情况下的表现。因此，该框架具有广泛的适用性和潜在的应用价值，作为智能驾驶系统中的适应性和可信决策支持工具。
# 20. `cs.AI` - 走向以社区驱动的机器学习工程代理 [PDF](https://arxiv.org/pdf/2506.20640), [HTML](https://arxiv.org/abs/2506.20640)
## Authors
Sijie Li,Weiwei Sun,Shanda Li,Ameet Talwalkar,Yiming Yang
## Background
大型语言模型（LLM）为基础的机器学习（ML）代理在自动化ML研究方面展现出巨大的潜力。然而，现有的代理通常是在独立的问题上运行，它们不与更广泛的科研社区进行互动，而科研人员往往通过分享知识以获得洞见和贡献。为了解决这一问题，研究引入了MLE-Live框架，旨在评估代理与模拟的Kaggle科研社区交流和利用集体知识的能力。基于这一框架，提出了CoMind代理，它能够在社区环境中交换洞见并开发出创新性解决方案，取得了当前最佳的结果，同时在四项正在进行的Kaggle竞赛中也优于79.2%的人类对手。
## Innovation
研究提出了一种新的代理叫CoMind，它能够在这个社区环境中更好地交流洞见、开发出创新解决方案。CoMind在MLE-Live中达到了当前最佳性能，并且相比于一个平均的40%的参赛人类人员来说，在四项Kaggle竞赛中都表现得更好，超越了79.2%的参赛人类选手。该研究通过引入MLE-Live评估框架，使得这些代理可以融入到更广泛的人类研究社区中进行高效互动和学习，增强了对机器学习的研究和开发过程的贡献。
## Conclusion
研究提出了CoMind代理和MLE-Live框架，证明了代理能够在一个模拟的真实科研社区环境中与人类同行有效互动和竞争。CoMind的性能不仅在ML代理领域有所提升，同时也强化了科研社区内的知识共享和创新活力。研究的代码已经公开。
# 21. `cs.AI` - DualEquiNet：一种用于大型生物分子的双空间层次不变网络 [PDF](https://arxiv.org/pdf/2506.19862), [HTML](https://arxiv.org/abs/2506.19862)
## Authors
Junjie Xu,Jiahao Zhang,Mangal Prakash,Xiang Zhang,Suhang Wang
## Background
现有的几何图神经网络(GNNs)尽管在小分子建模方面表现出色，但在处理如RNA和蛋白质等大型生物分子时面临扩展性和表示能力的挑战。这些系统需要能够同时捕捉细微的原子间相互作用、跨越空间距离的长程依赖关系以及生物相关的层次结构，例如原子形成残基，然后形成更高层次的领域。现有的几何GNNs通常在欧几里得空间或球谐空间中运行，限制了它们捕捉精细尺度原子细节和长程、对称感知依赖关系的能力，以应对大型生物分子多尺度结构的建模需要。
## Innovation
DualEquiNet，一种双空间层次不变网络，通过在欧几里得空间和球谐空间中构建互补表示来捕捉局部几何和全局对称特性。它采用双向跨空间消息传递和新的跨空间交互池化机制来层次化聚合原子特征，形成生物意义的单元，如残基，从而实现大型生物分子系统的高效且富有表现力的多尺度建模。DualEquiNet在现有的RNA属性预测和蛋白质建模基准测试中达到了最先进的性能，在两项新引入的3D结构基准测试中也优于先前的方法，展示了其在各种大型生物分子建模任务中的广泛效果。
## Conclusion
DualEquiNet通过在欧几里得空间和球谐空间中构建互补表示，并利用双向跨空间消息传递和跨空间交互池化机制，实现了大型生物分子的高效且富有表现力的多尺度建模，达到了现有基准测试的最佳性能。
# 22. `cs.AI` - 基于模板的大规模和成本效益优化的自创分子生成 [PDF](https://arxiv.org/pdf/2506.19865), [HTML](https://arxiv.org/abs/2506.19865)
## Authors
Piotr Gaiński,Oussama Boussif,Andrei Rekesh,Dmytro Shevchuk,Ali Parviz,Mike Tyers,Robert A. Batey,Michał Koziarski
## Background
基于模板的分子生成为药物设计提供了一种有希望的方法，确保合成的化合物具有预定义的反应模板和构建块而具有合成可行性。然而，当前的工作主要面临三个核心挑战：最小化合成成本、扩展到大规模构建块库以及充分利用小型片段集。此研究背景即在于解决这三大挑战，以提高合成的可持续性和分子多样性，同时增强质量。
## Innovation
1. 提出了一种递归成本指导(textbf{Recursive Cost Guidance})框架，利用辅助机器学习模型来近似合成成本和可行性。2. 引入了textbf{Exploitation Penalty}，以平衡探索和利用之间的权衡，有效引导生成过程，趋向低成本合成路径。3. 开发了一种动态库机制，通过重用中间高价值状态来构建完整的合成树结构，以提升性能，在较小的构建块库中表现出色。这些创新显著增强了分子生成的效率和质量，特别是在成本控制上表现出色。
## Conclusion
此方法在基于模板的分子生成方面建立了前所未有的成果，实现了大规模和成本效益的目标，为药物设计提供了新的途径，特别是在分子生成的质量和效率方面有显著的改善，特别是在成本控制方面。
# 23. `cs.AI` - The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind [PDF](https://arxiv.org/pdf/2506.20664), [HTML](https://arxiv.org/abs/2506.20664)
## Authors
Andrei Lupu,Timon Willi,Jakob Foerster
## Background
随着大型语言模型（LLMs）获得自主能力，它们必须在与人类用户和其他代理的协作或竞争情况下导航复杂的多代理场景。这将需要新的推理技能，尤其是了解他人“心理”状态的理论，即理论思维（ToM）。然而，当前在LLMs中的ToM和其他多代理技能理解不足，因为现有的基准存在范围狭窄、数据泄漏、饱和和缺乏互动性等问题。
## Innovation
因此，我们提出了Decrypto，这是一种游戏基准，用于评估多代理推理和ToM，灵感来源于认知科学、计算语用学和多代理强化学习。Decrypto旨在减少其他基准中存在的混淆因素，使其在所有其他方面尽可能简单，这是已知的第一个用于设计交互式ToM实验的平台。我们通过全面的经验评估前沿的LLMs、鲁棒性研究和人机对抗实验来验证基准设计。我们发现，LLM的游戏能力落后于人类和简单的词嵌入基准。我们还在Decrypto中创建了两个经典认知科学实验的变体，以评估三种关键的ToM能力。令人惊讶的是，我们发现最先进的推理模型在这方面远不如它们的前辈。这表明Decrypto填补了当前推理和ToM评估的关键空白，并为更好地设计人工智能铺平了道路。
## Conclusion
我们通过全面的实证评估、鲁棒性研究和人机对抗实验验证了基准设计。我们发现，LLM的游戏能力落后于人类和简单的词嵌入基准。我们创建了Decrypto中的两个经典认知科学实验变体，以评估三种关键的ToM能力，发现最先进的推理模型在这方面远不及它们的前辈。这表明Decrypto填补了当前推理和ToM评估的空白，并为更好地设计人工智能铺平了道路。
# 24. `cs.AI` - 使用LLM微调和提示工程创建多代理AI以应对可持续蛋白质生产挑战 [PDF](https://arxiv.org/pdf/2506.20598), [HTML](https://arxiv.org/abs/2506.20598)
## Authors
Alexander D. Kalian,Jaewook Lee,Stefan P. Johannesson,Lennart Otte,Christer Hogstrand,Miao Guo
## Background
全球对可持续蛋白质来源的需求增加推动了智能化工具的发展，这些工具能够快速处理和合成特定领域的科学知识。本文提出了一种支持可持续蛋白质生产研究的多代理人工智能（AI）框架，初步关注于微生物蛋白质来源。系统包括两个基于GPT的大型语言模型（LLMs）代理：一个文献检索代理和一个信息提取代理，分别用于检索相关文献并提取相关信息。研究探索了微调和提示工程两种方法来优化代理性能，结果显示这两种方法在提高信息提取代理的性能方面均有效。最终，微调在平均得分方面表现更佳，但在统计不确定性方面提示工程方法较低。系统还包括了一个用户界面，以便于使用多代理AI系统，并探索了额外的基于化学安全的搜索功能。
## Innovation
研究提出了一个使用基于GPT的多代理AI框架来支持可持续蛋白质生产研究，特别是微生物蛋白质。通过微调和提示工程两种方法优化了信息提取代理的性能，并开发了一个用户界面以简化系统的使用。系统还具备基于化学安全的搜索能力。
## Conclusion
通过微调和提示工程方法优化后的多代理AI系统，在信息提取方面取得了显著提升，平均余弦相似度得分达到了0.89以上，微调方法进一步提高了平均得分至0.94以上。该系统能够为可持续蛋白质生产提供有效的信息支持，同时增强了化学安全相关的搜索功能。
# 25. `cs.AI` - 增强与利用PETSc知识库的AI助手 [PDF](https://arxiv.org/pdf/2506.20608), [HTML](https://arxiv.org/abs/2506.20608)
## Authors
Barry Smith,Junchao Zhang,Hong Zhang,Lois Curfman McInnes,Murat Keceli,Archit Vasan,Satish Balay,Toby Isaac,Le Chen,Venkatram Vishwanath
## Background
生成式AI，尤其是通过大规模语言模型（LLMs），正在改变技术知识的获取、重用和扩展方式。PETSc是一个广泛用于高性能科学计算的数值库，其三十余年的开发过程中积累了丰富但分散的知识库，包括源代码、文档、邮件列表、GitLab问题、Discord对话、技术论文等。这些知识大多是非正式的，对用户和新开发者来说是难以获取和利用的。PETSc团队正着手构建一个LLM驱动的系统，将PETSc内容与诸如检索增强生成（RAG）、重排序算法和聊天机器人等自定义LLM工具相结合，以辅助用户、支持开发者和提出更新正式文档的建议。本文详细介绍了这些工具的设计和评估过程，重点在于系统架构、使用RAG和重排序为PETSc特定信息服务、各种LLM和嵌入式模型的评估方法，以及用户界面设计。通过Argonne领导计算设施的资源，我们分析了LLM响应如何增强数值软件的开发和使用，特别是在可扩展Krylov解算器方面。
## Innovation
PETSc团队正在建设一个基于LLM的系统，整合PETSc的内容与定制化的LLM工具，包括检索增强生成（RAG）、重排序算法和聊天机器人。这些工具旨在辅助用户、支持开发者并提出更新正式文档的建议。此外，通过Argonne领导计算设施的资源进行的分析，展示了LLM响应如何增强数值软件的开发和使用，特别是在Krylov解算器方面。
## Conclusion
本文概述了如何将此系统扩大为一个稳健、不断演变的平台，以推进软件生态系统，加速科学研究。通过这种方式，它建立了一个可扩展的知识中心型AI框架，提供可扩展的支持、丰富了文档，并在研发中增强了工作流程。
# 26. `cs.AI` - 探索前沿大型语言模型在核能研究中的能力 [PDF](https://arxiv.org/pdf/2506.19863), [HTML](https://arxiv.org/abs/2506.19863)
## Authors
Ahmed Almeldein,Mohammed Alnaggar,Rick Archibald,Tom Beck,Arpan Biswas,Rike Bostelmann,Wes Brewer,Chris Bryan,Christopher Calle,Cihangir Celik,Rajni Chahal,Jong Youl Choi,Arindam Chowdhury,Mark Cianciosa,Franklin Curtis,Gregory Davidson,Sebastian De Pascuale,Lisa Fassino,Ana Gainaru,Yashika Ghai,Luke Gibson,Qian Gong,Christopher Greulich,Scott Greenwood,Cory Hauck,Ehab Hassan,Rinkle Juneja,Soyoung Kang,Scott Klasky,Atul Kumar,Vineet Kumar,Paul Laiu,Calvin Lear,Yan-Ru Lin,Jono McConnell,Furkan Oz,Anant Raj,Pradeep Ramuhalli,Marie Romedenne,Samantha Sabatino,José Salcedo-Pérez,Nathan D. See,Arpan Sircar,Punam Thankur,Tim Younkin,Xiao-Ying Yu,Prashant Jain,Tom Evans,Prasanna Balaprakash
## Background
奥克 Ridge 国家实验室的 AI 为核能研讨会评估了大型语言模型 (LLMs) 加速聚变和裂变研究的潜力。来自不同领域的14个团队在一天内使用 ChatGPT、Gemini、Claude 等 AI 模型探索了核科学的多种挑战，应用范围包括为聚变反应堆控制开发基础模型、自动化蒙特卡洛模拟、预测材料退化以及为先进反应堆设计实验计划等。团队结合提示工程、深入研究能力和迭代改进的工作流程，生成了假设、原型代码和研究策略。这项研究展示了 LLM 在早期探索、文献综合和工作流程设计方面的卓越能力，但同时揭示了在新颖材料设计、高级模拟代码生成和特定领域细节处理等方面的局限性。研讨会的结果表明，专家驱动的提示工程和将 AI 视为物理学方法的补充工具而非替代品是取得成功的关键。
## Innovation
使用跨学科团队在一天内利用 LLMs 探索核科学研究的多种挑战，展示了其在早期探索、文献综合和工作流程设计方面的潜力和局限性。强调专家驱动的提示工程与物理学方法的结合是成功的关键，并指出了加快核能研究的潜在方式，即通过快速迭代和跨学科融合的方法，但同时也指出需要专门的数据集、工作流程自动化和模型开发来应对特定领域的要求。
## Conclusion
该研讨会验证了 AI 在核能研究中的潜力，通过快速迭代和跨学科合成加速研究，并强调了需要专门的数据集、自动化工作流程和模型开发来支持核科学工作流程。这些结果为将 AI 工具融入核科学工作流程指明了方向，有助于安全、高效且保持高标准的核能系统研发。
# 27. `cs.AI` - 基于生成对抗网络的医疗保险理赔欺诈检测攻击方法 [PDF](https://arxiv.org/pdf/2506.19871), [HTML](https://arxiv.org/abs/2506.19871)
## Authors
Yining Pang,Chenghan Li
## Background
保险欺诈检测是现代保险服务中的关键进步，能够提供智能化和数字化的监控，增强管理并预防欺诈。这对于保障保险系统的安全性和效率至关重要。尽管AI和机器学习算法在检测欺诈索赔方面表现出色，但缺乏标准化的防御机制使得现有系统容易受到新兴的对抗性威胁。现有技术在检测欺诈方面存在不足，亟需增强模型对对抗性操纵的鲁棒性，以确保不同保险系统的稳定性和可靠性。
## Innovation
本文提出了基于生成对抗网络（GAN）的攻击方法，用以对欺诈检测系统进行对抗攻击。攻击者无需了解训练数据或内部模型细节即可生成被分类为合法的虚假案例，攻击成功率高达99%。通过微妙修改真实的保险记录和索赔，攻击者能够显著增加欺诈风险，从而可能绕过被破坏的检测系统。这种方法强调了增强保险欺诈检测模型抗对抗攻击能力的必要性。
## Conclusion
研究结果表明，必须通过改进和增强模型的鲁棒性，以确保不同保险系统的稳定性和可靠性，防止由虚假案例带来的风险。
# 28. `cs.AI` - 网络流量中的鲁棒异常检测：CICIDS2017上的机器学习模型评估 [PDF](https://arxiv.org/pdf/2506.19877), [HTML](https://arxiv.org/abs/2506.19877)
## Authors
Zhaoyang Xu,Yunbo Liu
## Background
入侵检测系统的构建仍然需要识别适合的机器学习范式以确保其有效性和泛化能力。本文通过对CICIDS2017数据集的两种检测场景（已知攻击类型和未知威胁）下四种典型模型（多层感知机、一维卷积神经网络、一类支持向量机和局部异常因子）的对比研究，进一步探讨了机器学习在入侵检测中的应用现状和技术挑战。
## Innovation
本文引入了一个控制实验来对比监督学习（多层感知机和一维卷积神经网络）和无监督学习（局部异常因子和边界基础一类支持向量机）在已知攻击和未知威胁检测中的效果。通过此对比，提出了针对动态网络环境中的入侵检测模型选择的实际指导建议，特别是在平衡精度和召回率方面。
## Conclusion
研究结果表明，监督学习方法在已知攻击检测上表现优秀，但在面对未知威胁时召回率会大幅下降。相比之下，无监督学习的局部异常因子和边界基础一类支持向量机在未知威胁上表现出较好的检测效果，尽管存在较高的误报率。总体而言，边界基础一类支持向量机在两者之间提供了较好的权衡，展示了在不同检测场景下的鲁棒性。
# 29. `cs.AI` - 机器学习会议应建立“反驳与质疑”轨道的立场 [PDF](https://arxiv.org/pdf/2506.19882), [HTML](https://arxiv.org/abs/2506.19882)
## Authors
Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho
## Background
科学研究通过反复推进和纠正人们对世界的理解而进步。在机器学习（ML）研究中，迅速的进步导致了大量发表的论文数量激增，但也导致一些误导性、错误、有缺陷甚至可能是欺诈的论文被接受并在某些情况下在ML会议上被突出展示，因为在同行评审方面存在局限性。尽管此类错误是可以理解的，但ML会议并不提供稳健的机制来系统地纠正这些错误。因此，需要采取措施来改善这一状况。
## Innovation
本文提出，ML会议应建立一个专门的“反驳与质疑”（R&C）轨道，该轨道将提供一个高影响力的、可信赖的平台，支持对前人研究进行批判性挑战的研究，从而促进动态的自我纠正型研究生态系统。
## Conclusion
我们认为，ML会议应创建正式且可信赖的机制，以帮助ML研究领域的自我纠正。
# 30. `cs.AI` - 根据说话人嵌入改善间歇性和移动说话人的跟踪 [PDF](https://arxiv.org/pdf/2506.19875), [HTML](https://arxiv.org/abs/2506.19875)
## Authors
Taous Iatariene(MULTISPEECH),Can Cui(MULTISPEECH),Alexandre Guérin,Romain Serizel(MULTISPEECH)
## Background
发言人的跟踪方法通常依赖于空间观测来确保长时间一致的唯一身份跟踪。但在不定期和移动的演讲场景中，这一方法会有局限性，因为演讲者在不活动时移动位置，导致位置骤变，空间路径变得不连续。这项研究旨在通过使用说话人嵌入来解决这一问题，在跟踪后进行身份重新分配。使用初始跟踪步骤提供的轨迹相关信息以及多声道音频信号。通过波束成形增强信号，以便根据说话人的位置计算说话人嵌入。然后基于注册库使用这些嵌入来分配新的跟踪身份。研究在演讲者在不活动期间改变位置的数据集上评估所提出的方法，证明基于说话人嵌入的身份重新分配方法能提高神经网络和标准跟踪系统的识别匹配性能。特别地，还研究了波束成形和输入持续时间对嵌入提取的影响。
## Innovation
提出了在跟踪后使用说话人嵌入进行身份重新分配的方法。通过利用初始跟踪步骤提供的时间相关轨迹信息和多声道音频信号，并使用波束成形技术来更专注于演讲者的位置，计算出说话人嵌入。这些嵌入用于基于注册库分配新的身份。并且研究了波束成形和嵌入提取的持续时间对跟踪性能的影响，从而解决了场景中不定期和移动的能力不足的问题。
## Conclusion
基于说话人嵌入的身份重新分配方法能够有效解决间歇性和移动说话人的跟踪问题，并且此方法在神经网络和标准跟踪系统中表现出色，其改进了身份匹配的性能。进一步研究也表明，波束成形和输入持续时间是影响该方法性能的重要因素。
# 31. `cs.AI` - 朝向可验证的安全/不安全模型权重发布方案 [PDF](https://arxiv.org/pdf/2506.19874), [HTML](https://arxiv.org/abs/2506.19874)
## Authors
Xing Yang,Bingtao Wang,Yuhao Wang,Zimo Ji,Terry Jingchen Zhang,Wenyuan Jiang
## Background
近年来，一些安全的权重发布方案声称能够在保护模型所有权和防止滥用的情况下开放源模型的分发。然而，这些方案缺乏严格的安全部署基础，仅提供形式化的安全保证。建立在现有密码学工作的基础上，本文通过引入几种具体的安全部署定义，形式化了权重发布方案的安全性。通过对TaylorMLP方案的案例研究，分析发现了参数提取的漏洞，表明TaylorMLP未能实现其形式化的安全目标。
## Innovation
本文通过引入具体的安全部署定义，形式化了权重发布方案的安全性，并通过TaylorMLP案例研究揭示了其漏洞。这些定义和发现为未来设计和评估权重发布方案提供了蓝图，倡导了机器学习和安全部署社区之间的严谨研究。
## Conclusion
本文希望通过严格的安全部署研究，为未来的安全模型权重发布方案提供理论基础和实证分析方法，以增强模型的安全性和合规性。
# 32. `cs.AI` - 利用AI进行欺诈检测和能源市场稳定性的区块链保障能源交易安全 [PDF](https://arxiv.org/pdf/2506.19870), [HTML](https://arxiv.org/abs/2506.19870)
## Authors
Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan
## Background
在技术变革和市场转型的推动下，美国的能源市场已经经历了显著的变化，对点对点交易和分散式电网的重视日益增加。然而，随之而来的是新的安全与真实性挑战。本研究旨在为美国分散式能源市场开发并构建一个安全、智能且高效的能源交易系统，以应对传统分散能源市场中长期存在的安全性、欺诈行为鉴定及市场可靠性等问题。研究使用的数据集包含超过120万条匿名化能源交易记录，数据源自模拟的真实世界区块链基底微电网，其中包括LO3 Energy和Grid+ Labs测试的微电网。
## Innovation
本研究创新性地结合了区块链技术和人工智能（AI），提出了分层系统架构，利用区块链保证能源交易的安全性，并利用AI改进市场智能。机器学习模型被专门选用于特定分类任务，以识别分散市场中的能源交易欺诈。这种结合方式有效地提升了能市场的安全性和可靠性，为未来智能能源市场的构建提供了新的方案。
## Conclusion
研究提出了一种融合区块链和AI的系统架构，旨在实现能源交易的安全、智能化及高效化。系统通过增强的安全性措施和智能市场分析，能够大幅提高分散能源市场中的安全性和可靠性，为未来能源交易和市场稳定性提供了有力支持。
# 33. `cs.AI` - FlightKooba: 一种快速可解释的飞行轨迹预测模型 [PDF](https://arxiv.org/pdf/2506.19885), [HTML](https://arxiv.org/abs/2506.19885)
## Authors
Jing Lu,Xuan Wu,Yizhun Tian,Songhan Fan,Yali Fang
## Background
库普曼理论是一种强大的非线性系统转换为线性表示的建模工具，而飞行轨迹预测（FTP）是一个复杂的非线性系统。但是，目前应用于FTP任务的库普曼理论模型效果不佳，模型可解释性差，且库普曼算子计算量大，导致训练时间较长。
## Innovation
本文提出了一种新的基于HIPPO方法、库普曼理论和自主控制理论的状态空间方程的建模和控制框架——FlightKooba。FlightKooba通过直接从数据构建库普曼算子，提高了框架的可解释性，并显著减少了模块中的可训练参数数量，从而大幅缩短了训练时间。实验表明，FlightKooba方法在时间和内存消耗方面优于其他方法，实现了一种新的有效计算库普曼算子的方法，促进了时间序列预测和控制的结合。
## Conclusion
FlightKooba方法在训练时间和内存消耗方面表现出优越性（在不使用CUDA级加速的情况下，训练时间与Mamba模块相当；内存减少了50%以上，参数数量减少了十倍），基本完成了飞行轨迹预测任务，为库普曼算子的快速计算提供了新方法，开辟了时间序列预测与控制结合的新可能性。
# 34. `cs.AI` - MNN-AECS：通过自适应核心选择在移动设备上对LNM进行能效优化 [PDF](https://arxiv.org/pdf/2506.19884), [HTML](https://arxiv.org/abs/2506.19884)
## Authors
Zhengxiang Huang,Chaoyue Niu,Zhaode Wang,Jiarui Xue,Hanming Zhang,Yugang Wang,Zewei Xin,Xiaotang Jiang,Chengfei Lv,Fan Wu,Guihai Chen
## Background
随着对在设备上进行大型语言模型（LLM）推理的需求增长，能源效率已成为主要关注点，特别是在电池限制的移动设备上。目前大多数现有工作都集中在加速LLM的预填充阶段，而忽略了能效问题。深入分析表明，受内存限制的LLM解码阶段主导了能源使用，但大多数现有工作忽略了这一点，主要集中精力在加速预填充阶段上，而不是关注能效的问题。因此，对于低功耗核心的选择，仍需要更多的研究以使移动设备上的LLM解码更加节能。
## Innovation
论文提出了自适应能效核心选择（AECS）策略，并将其整合到MNN中，形成能量高效的版本MNN-AECS，这是第一个无需root访问或操作系统修改的引擎级别系统解决方案，用于节能的LLM解码。MNN-AECS能够通过动态选择低功耗CPU核心来减少LLM解码的能源消耗，同时保持解码速度在一个可接受的减慢阈值内。实验结果表明，与原版MNN相比，MNN-AECS在所有7台设备和4个数据集上平均减少了23%的能源使用，与其他的包括this http URL，executorch，mllm和Mediapipe的引擎相比，MNN-AECS平均在能源节省方面提高了39%至78%，并且在速度方面提高了12%至363%。
## Conclusion
MNN-AECS是一个能在移动设备上高效解码LLM的解决方案，通过自适应地选择低功耗核心，它在保持一定解码速度的同时显著降低了能耗。
# 35. `cs.AI` - STIMULUS：在随机多目标学习中实现快速收敛和低样本复杂度 [PDF](https://arxiv.org/pdf/2506.19883), [HTML](https://arxiv.org/abs/2506.19883)
## Authors
Zhuqing Liu,Chaosheng Dong,Michinari Momma,Simone Shao,Shaoyuan Xu,Yan Gao,Haibo Yang,Jia Liu
## Background
近年来，多目标优化（MOO）因其在机器学习、运筹学和工程领域的广泛应用而受到关注。然而，MOO算法的设计仍处于初级阶段，许多现有的MOO方法在收敛速度和样本复杂度方面表现不佳。为了应对这一挑战，本文提出了一种新的算法STIMULUS（stochastic path-integrated multi-gradient recursive estimator），该算法提供了一种改进的收敛性能并具有较低的样本复杂性的新颖且稳健的方法来解决MOO问题。不同于传统的算法，STIMULUS引入了一个用于更新随机梯度估计的简单而强大的递归框架。
## Innovation
本文提出了一种新的算法STIMULUS，该算法通过引入一个简单的递归框架来提高收敛性能并具有较低的样本复杂度。此外，为了进一步加快收敛速度，还提出了一种增强版本的STIMULUS算法，称为STIMULUS-M，该版本引入了一种动量项。我们建立了非凸设置下的$O(1/T)$收敛率和强凸设置下的$O (text{exp}text{-}text{textmu} T)$收敛率。此外，我们实现了非凸设置下的$O text{(n}+text{textsqrt}{n}text{textepsilon}^{-1}text{)}$和强凸设置下的$Otext{(n}+text{textsqrt}{n} text{textrm{ln}(text{textmu}/text{textepsilon})})$样本复杂度。同时，为了减轻STIMULUS和STIMULUS-M在周期性全梯度评估要求上的负担，我们进一步提出了带有自适应批量优化的增强版本STIMULUS+/STIMULUS-M+并提供了相应的理论分析。
## Conclusion
本文提出了STIMULUS和STIMULUS+等算法，通过改进随机梯度估计的递归框架和引入动量项、自适应批量优化等手段，提高了多目标优化问题的算法收敛速度和样本复杂度效率。
# 36. `cs.AI` - 使用深度学习进行物理引导的放射治疗计划 [PDF](https://arxiv.org/pdf/2506.19880), [HTML](https://arxiv.org/abs/2506.19880)
## Authors
Stefanos Achlatis,Efstratios Gavves,Jan-Jakob Sonke
## Background
调强放疗（VMAT）是癌症治疗中一种重要的技术，通过在照射过程中动态调整多叶准直器（MLC）位置和监测单位（MU）来实现剂量的适应性。由于患者解剖结构的变化，适应性放射治疗需要频繁修改治疗计划，这需要一种时间效率高的解决方案。深度学习提供了一种自动化的潜力，用于这一过程的优化。本研究提出了一种双阶段、物理引导的深度学习管道，旨在提高放射治疗计划的效率和准确性。在第一阶段中，网络基于MLC和MU值的直接监督来训练。在第二阶段中，通过预测的3D剂量分布引入额外的监督信号，这种方式将基于物理的指导纳入了训练过程中。研究在133名使用统一2弧VMAT协议治疗的前列腺癌患者上进行了训练和评估，这些患者的计划靶体积（PTV）接受剂量为62 Gy。实验结果显示，该方法生成的计划与临床标准答案非常接近，能够在多个关键指标上产生显著效果。
## Innovation
研究提出了一种双阶段、物理引导的深度学习框架，用于放射治疗计划。该框架通过引入基于物理的指导来提高模型的准确性和适应性，特别是在预测的3D剂量分布方面引入了额外的监督信号。这种方法能够有效地减少对关键器官的辐射剂量，同时在目标体积上保持高度的剂量一致性。
## Conclusion
研究证明，基于3D U-Net和UNETR架构的方法能够产生与临床标准答案高度一致的治疗计划，并能减少对关键器官的辐射暴露。这些结果表明，物理引导的深度学习在放射治疗计划中具有巨大的潜力。
# 37. `cs.AI` - MATER: 多层次声学和文本情绪表示以实现可解释的语音情绪识别 [PDF](https://arxiv.org/pdf/2506.19887), [HTML](https://arxiv.org/abs/2506.19887)
## Authors
Hyo Jin Jon,Longbin Jin,Hyuntaek Jung,Hyunseo Kim,Donghun Min,Eun Yi Kim
## Background
本文提出了对自然条件下语音情绪识别（SERNC）挑战的贡献，重点关注类别化情绪识别和情绪属性预测。面对自然语音的复杂性，包括跨个体和同个体的变异性，研究提出了多层次声学-文本情绪表示（MATER），这是一种新颖的分层框架，整合了声学和文本特征，从词、句和嵌入层次进行整合。通过将低层词汇和声学线索与高层语境化的表示融合，MATER 能够有效捕捉细微的音调变异和语义细微差别。此外，引入了不确定性的意识集成策略来缓解注释者不一致的问题，提高了在情绪表达模糊情况下模型的鲁棒性。
## Innovation
本文提出的 MATER 采用了多层次的声学-文本情绪表示方法，集成词、句和嵌入级别的特征。通过融合低层次的词汇和声学线索与高层次的语境化表示，MATER 能够捕捉细微的音调变异和语义细微差别。同时，MATER 还引入了不确定性意识的集成策略，以应对标注者不一致性的问题。
## Conclusion
在任务中，MATER 在宏观 F1 得分为 41.01%，整体一致性系数（CCC）为 0.5928，排名第四，同时在情感强度预测方面表现突出，取得了 0.6941 的 CCC，排名第二。
# 38. `cs.AI` - Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models [PDF](https://arxiv.org/pdf/2506.19889), [HTML](https://arxiv.org/abs/2506.19889)
## Authors
Wanli Peng,Xin Chen,Hang Fu,XinYu He,Xue Yiming,Juan Wen
## Background
最近，大规模语言模型（LLMs）的进步极大地影响了我们的社会，同时也引发了新的安全担忧。特别是由于LLMs具备出色的推理能力，Staab等人揭示了隐私侵犯攻击（PVA），这严重威胁到个人隐私。现有的防御方法主要通过利用LLMs对输入查询进行匿名化处理，但这需要昂贵的推理时间，并不能取得满意的防御效果。此外，直接拒绝PVA查询看似是一种有效的防御方法，但这也使得防御策略曝光，从而促使PVA的演变。现有防御策略的效果和局限性为本研究提供了背景，并探讨了新的防御模式的需求。
## Innovation
本文提出了一种基于LLMs检索混淆生成（RCG）的新颖防御范式，可以高效且隐蔽地防御PVA。设计了一个改写提示，诱导LLMs将攻击查询的“用户评论”重写为构建一个扰乱数据库，然后提出了一种最不相关的检索策略从扰乱数据库中检索所需用户数据，最后用检索到的用户数据替代“数据评论”形成一个防御查询，以此回应对手并造成一些不正确的个人信息，使得攻击失败。这种方法不仅规避了直接拒绝查询带来的问题，还通过检索混淆实现了隐蔽的防御效果。
## Conclusion
通过在两个数据集和八个流行的大规模语言模型上进行广泛实验，本文的方法表明，这是一种可行且优于现有方法的有效防御。
# 39. `cs.AI` - 因果感知智能QoE优化在具有自适应关键帧提取的VR交互中的应用 [PDF](https://arxiv.org/pdf/2506.19890), [HTML](https://arxiv.org/abs/2506.19890)
## Authors
Ziru Zhang,Jiadong Yu,Danny H.K. Tsang
## Background
多用户虚拟现实（VR）交互的体验质量（QoE）优化需要在超低延迟、高保真运动同步和资源分配公平性之间取得微妙平衡。现有方法在带宽分配、CPU频率和用户感知之间的因果关系方面存在不足，导致QoE提升有限。因此，迫切需要一种能够综合考虑这些因素的方法来最大化QoE。
## Innovation
本文提出了一种智能框架，结合自适应关键帧提取与因果感知强化学习（RL）。首先，提出了基于韦伯-费钦定律的新QoE度量，结合感知灵敏度、注意力驱动的优先级和运动重建准确性。然后，将QoE优化问题建模为混合整数规划任务，同时优化关键帧比率、带宽和计算资源，并在视野公平性约束下进行优化。此外，提出了部分状态因果深度确定性策略梯度（PS-CDDPG），将因果影响检测与深确定性策略梯度（DDPG）方法相结合，通过利用因果信息来更有效地指导训练。
## Conclusion
实验结果表明，该框架显著减少了交互延迟，提升了QoE，并保持了公平性，相较于基准方法，其性能更加优越。
# 40. `cs.AI` - RepuNet: 在去中心化联邦学习中缓解恶意客户端的声誉系统 [PDF](https://arxiv.org/pdf/2506.19892), [HTML](https://arxiv.org/abs/2506.19892)
## Authors
Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán
## Background
去中心化联邦学习（DFL）允许节点在没有中央服务器的情况下协同训练模型，但由于每个节点独立选择模型聚合的同龄人，引入了新的安全威胁。恶意节点可能通过传播受污染模型（模型毒化）、延迟模型提交（延迟攻击）或在网络中发送过多消息来进行攻击，从而影响系统性能。当前的解决方案往往依赖于固定配置或额外的基础架构，如区块链，这可能导致计算开销、可扩展性问题或适应性有限。在此背景下，本文提出了RepuNet，这是一种去中心化声誉系统，用于在DFL中识别威胁，并利用模型相似性、参数变更、消息延迟和通信量等指标动态评估节点行为。节点在模型聚合中的影响根据其声誉分数调整。
## Innovation
RepuNet 是一种新的去中心化声誉系统，它能够动态地评估节点行为，并通过使用模型相似性、参数变更、消息延迟和通信量等指标来识别和减轻恶意行为。该系统在非IID分布下，使用MNIST和CIFAR-10数据集和最大25个节点的完全连接和随机拓扑进行了实验性评估。结果表明，RepuNet 在检测和缓解恶意行为方面非常有效，取得了高 F1 分数。
## Conclusion
实验结果表明，RepuNet 在去中心化联邦学习环境中有效地识别和缓解了恶意行为，适用于不同攻击强度、频率和激活间隔的情景。这证明了RepuNet的适应性、鲁棒性和在去中心化联邦学习中的实际应用潜力。
# 41. `cs.AI` - 使用XAI方法解释用于电价预测的深度神经网络模型 [PDF](https://arxiv.org/pdf/2506.19894), [HTML](https://arxiv.org/abs/2506.19894)
## Authors
Antoine Pesenti,Aidan OSullivan
## Background
电力市场非常复杂，包含多种交互和复杂的依赖性，这使得市场内部运作和价格驱动因素不易理解。虽然已经有了计量经济学方法和白盒模型，但它们不如深度神经网络模型强大。本研究利用DNN来预测电价，并结合XAI方法理解市场中的价格动态因素。
## Innovation
本文引入了SSHAP值和SSHAP线的概念，以增强高维表型模型的复杂表示能力；使用SHAP和梯度等解释方法，以及热图等可视化技术，分析了五个电力市场的各种特征的行为和贡献。
## Conclusion
通过XAI方法，文章提高了对不同电力市场运作机制的理解。
# 42. `cs.AI` - 基于跨层最近邻的不确定性量化框架 [PDF](https://arxiv.org/pdf/2506.19895), [HTML](https://arxiv.org/abs/2506.19895)
## Authors
Miguel N. Font,José L. Jorro-Aragoneses,Carlos M. Alaíz
## Background
神经网络在难以检测模式或构建逻辑模型的领域中具有高准确性。然而，在医疗诊断或自动驾驶等高风险领域中，这些算法有时会返回错误的解决方案，这是一个问题。检测和减轻这些错误的一种策略是测量神经网络决策的不确定性。现有方法通常基于softmax置信度，但该论文提出了一种新颖的后处理框架，以改进不确定性测量。
## Innovation
该论文提出了一种基于跨层最近邻的新颖后处理框架，用于测量基于查询每层相似激活向量检索的训练案例的决策不确定性。在此基础上，该论文提出了两个新的指标：决策变化和层不确定性，这些指标捕捉了跨层最近邻类别分布的变化。该方法在CIFAR-10和MNIST两个分类数据集中进行了评估，结果显示这些指标在挑战性分类任务中增强了不确定性估计，且优于基于softmax的置信度方法。
## Conclusion
该论文提出的方法在CIFAR-10和MNIST分类数据集上得到了验证，证明了基于跨层最近邻的决策变化和层不确定性的新指标能够提高不确定性估计，特别是在具有挑战性的分类任务中。
# 43. `cs.AI` - CycleDistill: 利用循环蒸馏从大规模语言模型中提升机器翻译 [PDF](https://arxiv.org/pdf/2506.19952), [HTML](https://arxiv.org/abs/2506.19952)
## Authors
Deepon Halder,Thanmay Jayakumar,Raj Dabre
## Background
尽管大型语言模型（LLMs）能在少量示例机器翻译（MT）中表现出色，但在高质量机器翻译方面通常逊色于针对平行语料库训练的专用MT系统。然而，对于低资源语言，平行语料库往往稀缺或不存在。本文探讨了使用LLMs和少量示例翻译生成高质量MT系统的CycleDistill方法。这种方法通过从单语语料库生成合成平行语料库来训练模型，而无需大量平行语料库。实验显示，通过这种方法，可以显著提高翻译质量，特别是在印地语等语言上，相较于原有的少量示例基线模型，在第一次迭代中平均提高了20-30个chrF分数点。
## Innovation
CycleDistill是一种利用LLMs和少量示例翻译方法，通过迭代生成合成平行语料库，并利用这些语料库进一步微调生成翻译数据的模型。这种方法仅需少量示例语料库即可有效提升MT系统的质量，从而在低资源语言的机器翻译上取得显著成果。此外，研究人员还研究了在蒸馏过程中利用softmax激活函数的效果，观察到了轻微的翻译质量改进。
## Conclusion
CycleDistill能够利用少量示例翻译和单语语料库生成高质量的MT系统，其在印地语等低资源语言上的实验表明，该方法能显著提升机器翻译的质量，并且在第一次迭代中相对于少量示例基线模型提升显著。
# 44. `cs.AI` - 正交软剪枝以实现高效类别遗忘 [PDF](https://arxiv.org/pdf/2506.19891), [HTML](https://arxiv.org/abs/2506.19891)
## Authors
Qinghui Gong,Xue Yang,Xiaohu Tang
## Background
机器卸载旨在通过从预训练的神经网络中选择性地删除特定类别的知识来满足GDPR等隐私法规。现有方法通常在去学习速度和预测准确性的保留之间面临权衡，往往导致高计算开销或在保留类上显着的性能下降。这项研究旨在探讨通过正交卷积核正则化提出一个新颖的类别感知软剪枝框架，以实现毫秒级响应时间的快速和精准遗忘。该方法在训练过程中施加正则性约束，从而解相关卷积滤波器并与特征表示进行解耦，通过激活差异分析有效地识别特定于类别的通道。针对多个架构和数据集的广泛评估表明，该方法可以在接近即时执行的情况下进行稳定剪枝，实现对目标类的彻底遗忘，并在保留数据上的准确度损失最小。实验结果证明，该方法在CIFAR-10、CIFAR-100和TinyImageNet数据集上大幅降低了成员身份推理攻击的风险，并比最先进的基线方法加速了去学习数个数量级。这项框架为实时机器卸载在机器学习即服务（MLaaS）场景中的高效和实用解决方案提供了解决方案。
## Innovation
提出了一种新颖的类别感知软剪枝框架，通过施加正交约束来解相关卷积滤波器并解耦特征表示，从而实现快速且精准的遗忘，同时保留了模型的预测能力。这种方法特别适合MLaaS场景，能够在毫秒级响应时间内进行高效计算，实现对特定类别的彻底遗忘，而几乎不损失准确度。此外，这种方法显著降低了数据集上的成员身份推理攻击风险，使其比现有基准方法在多个数据集上实现更快的去学习速度。
## Conclusion
该研究提出的方法通过正交软剪枝实现了快速、精准的类别遗忘，减少了计算资源的消耗，降低了会员身份推理攻击的风险，加速了去学习过程。实验结果表明该方法能够在保持预测性能的同时，实现对特定类别的选择性遗忘，并适用于实际应用中的MLaaS场景。
# 45. `cs.AI` - 推理缩放GraphRAG：改善知识图谱上的多跳问答 [PDF](https://arxiv.org/pdf/2506.19967), [HTML](https://arxiv.org/abs/2506.19967)
## Authors
Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu
## Background
大型语言模型（LLMs）在语言理解和生成方面取得了显著成就，但在涉及大量背景信息和多跳推理的知识密集型推理任务上表现仍然有限，这是因为它们对结构化上下文的访问有限。检索增强生成（RAG）方法在一定程度上解决了这个问题，通过提供检索到的上下文作为语言生成的基础，但传统RAG和GraphRAG方法往往无法捕捉知识图谱中节点之间的关系结构。
## Innovation
我们提出了Inference-Scaled GraphRAG（推理缩放GraphRAG），这是一种新颖的框架，通过在推理阶段应用计算量缩放增强LLM基于图的推理能力。该方法结合了顺序缩放与深度链式图遍历，以及并行缩放与交错推理执行循环中采样轨迹的多数投票。实验表明，我们的方法显著提高了多跳问答性能，在GRBench基准测试上优于传统GraphRAG方法和先前的图遍历基线方法，这表明推理阶段的缩放是一个实用且架构无关的解决方案，用于结构化知识推理中LLMs的应用。
## Conclusion
我们的方法在GRBench基准测试中显著提高了知识图谱上的多跳问答性能，大幅超越了传统GraphRAG和先前的图遍历基线方法，表明推理阶段的缩放是适用于LLMs的结构化知识推理的实际且架构无关的解决方案。
# 46. `cs.AI` - 基于波函数的从头计算基础模型，准确描述化学键断裂 [PDF](https://arxiv.org/pdf/2506.19960), [HTML](https://arxiv.org/abs/2506.19960)
## Authors
Adam Foster,Zeno Schätzle,P. Bernát Szabó,Lixue Cheng,Jonas Köhler,Gino Cassella,Nicholas Gao,Jiawei Li,Frank Noé,Jan Hermann
## Background
量子化学中，可靠描述键断裂依然是一个重大挑战，因为非键解除物种的电子结构具有多重参考特征。多重参考方法尤其受到高昂计算成本的限制，计算成本通常需要为每个系统重新进行计算，忽略了分子间电子结构的共同性。尽管量子蒙特卡洛方法结合深度神经网络（深度QMC）能够通过预训练可转移的波函数模型来利用共性，但迄今为止这些尝试都局限于小范围的应用。
## Innovation
本文提出了Orbformer，这是一种新颖的可转移波函数模型，通过在22,000个平衡和解离结构上预训练，然后在未见过的分子上进行微调，实现了在化学精度（1 kcal/mol）下的准确性和成本比率，与传统的多重参考方法相媲美。Orbformer在几个标准基准测试以及更具有挑战性的键断裂和迪尔斯-阿尔德反应中均表现出色，是唯一一个能够一致收敛到化学精度的方法。这项工作将解决薛定谔方程的计算成本分摊到多个分子上这一想法转化为量子化学中的实用方法。
## Conclusion
Orbformer不仅提高了量子化学中键断裂描述的准确性，还通过利用分子间的电子结构共同性显著降低了计算成本，标志着量子化学计算领域的一个重要进步。
# 47. `cs.AI` - AIGC提供任务中基于生成语义通信的蒸馏增强知识对齐 [PDF](https://arxiv.org/pdf/2506.19893), [HTML](https://arxiv.org/abs/2506.19893)
## Authors
Jingzhi Hu,Geoffrey Ye Li
## Background
由于生成人工智能生成内容（AIGC）的大量增长，从云计算到边缘和移动用户传输AIGC数据会消耗大量网络流量。生成语义通信（GSC）通过传输紧凑的提示文本和潜在表示来替代高维度的AIGC数据，提供了一种有前途的解决方案。然而，这种方式需要确保云端生成AI（GAI）的知识与边缘和用户手中的知识相匹配，以及确保无线传输知识与实际信道条件相匹配，这仍然是个挑战。
## Innovation
本文提出了一种名为DeKA-g的蒸馏增强知识对齐算法，用于GSC系统。该算法的核心思想是将云端GAI的生成知识压缩成低秩矩阵，这些矩阵可以在边缘设备中使用，以适应不同无线信道条件。DeKA-g包含两种新颖的方法：元词辅助知识蒸馏（MAKD）和可变速率分组信噪比适应（VGSA）。MAKD使用优化的元词来提高知识蒸馏的效率，而VGSA则使对不同压缩率和信噪比范围的高效适应成为可能。
## Conclusion
从仿真结果来看，DeKA-g在边缘生成的图像与云端生成的图像之间的对齐方面提高了44%。此外，该方法在基线方法的压缩率效率上提高了116%，并提高了在低信噪比条件下的性能28%。
# 48. `cs.AI` - 在代码分割过程中，LLMs能否替代人类？ [PDF](https://arxiv.org/pdf/2506.19897), [HTML](https://arxiv.org/abs/2506.19897)
## Authors
Christopher Glasz,Emily Escamilla,Eric O. Scott,Anand Patel,Jacob Zimmer,Colin Diggs,Michael Doyle,Scott Rosen,Nitin Naik,Justin F. Brunelle,Samruddhi Thaker,Parthav Poudel,Arun Sridharan,Amit Madan,Doug Wendt,William Macke,Thomas Schill
## Background
大型语言模型（LLMs）已成为计算机科学中的重要工具，尤其是在代码理解和生成方面。然而，现有的工作没有解决政府应用代码特有的许多挑战。政府企业软件通常用诸如MUMPS或汇编语言代码（ALC）等过时语言编写，且这些系统的整体标记长度超过了当前商用LLMs的上下文窗口大小。此外，LLMs主要是在现代软件语言上进行训练，并且对过时语言的测试有限，使其理解过时语言的能力难以评估，这是一个需要实证研究的领域。
## Innovation
本文研究了LLMs在现代化工随政府代码编写（使用ALC和MUMPS）中的应用，解决了输入限制带来的挑战。我们探讨了各种代码分割方法，以优化总结模块注释的生成，评估代码分割方法对由不同LLMs生成的文档质量的影响，包括GPT-4o、Claude 3 Sonnet、Mixtral和Llama 3。结果显示，LLMs可以选择与人类专家划分点紧密匹配的划分点。此外，我们发现代码分割方法对后续任务如文档生成产生显著影响。由LLMs创建的划分产生的注释比由人类创建的更具事实依据，且更有用，分别高出20%和10%。因此，本文结论认为，LLMs可以作为大代码库人工划分的合适替代品，在LLM辅助现代化过程中使用。
## Conclusion
LLMs可以作为大型代码库人工划分的合适替代品，在LLM辅助现代化过程中使用。LLMs可以选择与人类专家划分点紧密匹配的划分点，并且代码分割方法对生成的文档质量产生显著影响，由LLMs创建的划分产生的注释比由人类创建的更有用。
# 49. `cs.AI` - HERCULES：基于大型语言模型的层次嵌入递归聚类及其高效总结 [PDF](https://arxiv.org/pdf/2506.19992), [HTML](https://arxiv.org/abs/2506.19992)
## Authors
Gabor Petnehazi,Bernadett Aradi
## Background
随着各类模态复杂数据集的爆发式增长，需要先进分析工具不仅能有效分组数据，还能提供可理解的洞察。HERCULES（Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization）旨在应对这一需求，用于处理文本、图像和数值数据等多种类型的数据，通过递归应用层次k-means聚类算法构建数据层级结构，并利用大型语言模型生成具有丰富语义的层级中各个聚类的标题和描述，以提高聚类结果的可解释性。该算法支持直接模式和描述模式两种主要表现方式，适用于不同的应用场景。
## Innovation
HERCULES的独特之处在于其将大型语言模型（LLMs）深度整合在算法中，通过LLM生成摘要并基于这些摘要对聚类，生成层次结构中每个层级的丰富语义标题和描述，显著提升了算法的可解释性。此外，用户可以通过提供主题种子来引导LLM生成特定主题的摘要，增加了灵活性与用户指导性。HERCULES还提供了一个交互式可视化工具，进一步帮助用户深入分析聚类结果。这些创新点使得HERCULES适用于处理复杂数据集，以提取有层次的、有意义的知识。
## Conclusion
HERCULES算法通过递归应用k-means聚类来构建数据的层次结构，并利用大型语言模型生成丰富语义的聚类标题和描述，提高了聚类结果的可解释性。该算法支持直接和描述两种不同的表示模式，并提供了一个交互式可视化工具来帮助用户更好地理解聚类结果。HERCULES展现了其从复杂数据集中高效提取有意义、有层次的知识的能力。
# 50. `cs.AI` - 解开和微调量子联邦学习的新见解 [PDF](https://arxiv.org/pdf/2506.20016), [HTML](https://arxiv.org/abs/2506.20016)
## Authors
Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel
## Background
量子联邦学习（QFL）由于客户端异质性而面临重大性能挑战。标准聚合方法在高度异质环境中常难以应对这些挑战，导致模型过拟合，优化效果不佳，准确率偏低，常规方法的准确率通常在55%左右。
## Innovation
为克服这些限制，作者提出了一种结合深度展开的新方法，使客户端能够根据自身特定的训练行为自主优化超参数，如学习率和正则化因子，动态适应促进了模型在高度异质环境下的优化，避免了过拟合，显著提高了QFL的准确性。通过使用IBM量子硬件和Qiskit Aer模拟器进行实时训练，框架实测准确率高达约90%，优于传统方法。这种方法特别适用于如基因表达分析和癌症检测等关键应用，提高了诊断精度和预测模型效果。
## Conclusion
本研究解决了传统QFL的核心局限性，提出了一个适用于诸如医疗保健和基因组学研究等多个复杂挑战的新框架。
# 51. `cs.AI` - 在协作多智能体强化学习中学习双边团队形成 [PDF](https://arxiv.org/pdf/2506.20039), [HTML](https://arxiv.org/abs/2506.20039)
## Authors
Koorosh Moslemi,Chi-Guhn Lee
## Background
在多智能体强化学习（MARL）的背景下，团队形成及其动态的团队学习引起了广泛关注。现有研究大多集中在单方面的团队分组、预定义团队或固定人口设置上，而动态人口中的算法性双边分组选择对算法性能和泛化的具体影响还未得到充分研究。因此，需要开发一种框架来学习动态多智能体系统中的双边团队形成，以便更好地了解算法如何影响团队策略的表现和泛化能力。
## Innovation
本文提出了一种框架，用于在动态多智能体系统中学习双边团队形成，探索不同算法属性如何影响团队策略的表现和泛化能力。通过使用广泛采用的多智能体场景，验证了提出的算法的有效性，并在大多数场景中表现出了竞争力和更好的泛化能力。
## Conclusion
通过使用广泛采用的多智能体场景，我们验证了学习双边团队形成的有效性，并在大多数场景中展现了与现有方法相当甚至更好的性能和泛化能力，为理解多智能体系统中动态团队形成提供了新的见解。
# 52. `cs.AI` - VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration [PDF](https://arxiv.org/pdf/2506.19975), [HTML](https://arxiv.org/abs/2506.19975)
## Authors
Hang Zhang,Yuxi Zhang,Jiazheng Wang,Xiang Chen,Renjiu Hu,Xin Tian,Gaolei Li,Min Liu
## Background
最近的神经网络发展提高了变形图像注册（DIR）的效率和准确性，通过削弱迭代优化的过程。然而，基于学习的方法在有限的训练数据、大形变以及无标签监督的情况下通常表现不佳，常常比迭代方法低效。尽管如此，迭代方法在这些情况下可以达到更高的准确性，但速度远低于基于学习的方法。因此，需要一种框架来结合学习和迭代的优点，以获得更好的准确性和运行时间平衡。
## Innovation
VoxelOpt通过以下三个方面的创新来实现：1) 软件体素自适应消息传递，其中低熵体素接受较少的邻居影响。2) 使用多级图像金字塔和27-邻域体素成本体积，避免了复杂性指数增长。3) 使用预训练的分割基础模型进行特征提取，替代手工构造的特征或对比学习。这些改变使VoxelOpt在腹部CT注册中不仅在效率方面超越了最先进迭代方法，还在准确性方面与接受标签监督训练的基于学习的方法相匹配。
## Conclusion
VoxelOpt通过结合学习和迭代的优势，在腹部CT变形注册中取得了更好的准确性和效率平衡，同时公开了源代码，以供进一步研究和使用。
# 53. `cs.AI` - TRACED: 过渡意识的遗憾近似与共学习性在环境设计中的应用 [PDF](https://arxiv.org/pdf/2506.19997), [HTML](https://arxiv.org/abs/2506.19997)
## Authors
Geonwoo Cho,Jaegyun Im,Jihwan Lee,Hojun Yi,Sejin Kim,Sundong Kim
## Background
在未见过的环境中泛化的深度强化学习代理仍然是一个重大的挑战。一种有希望的解决方案是无监督环境设计（UED），这是一种进化性框架，在该框架中，教师会适应性地生成具有高学习潜力的任务，而学生则从这种不断演变的课程中学习稳健的策略。现有的UED方法通常通过遗憾来测量学习潜力，遗憾是当前性能与最优性能之间的差距，通过价值函数损失进行近似。
## Innovation
本文研究引入了过渡预测误差作为遗憾近似中的额外术语。为了捕捉一次任务训练如何影响其他任务的表现，还提出了一个轻量级的共学习性度量。通过结合这两种度量，提出了过渡意识的遗憾近似与共学习性（TRACED）方法，以改进多个基准中的零样本泛化能力，且所需环境交互次数仅为强大基线的一半。通过消融研究证实了过渡预测误差驱动复杂性快速上升，而共学习性误差在与过渡预测误差结合时带来额外的收益。这些结果表明，精确的遗憾近似和任务关系的显式建模可被利用来在UED中进行样本高效的学习序列设计。
## Conclusion
TRACED方法在改进多个基准中的零样本泛化能力的同时，需要的环境交互次数仅为强大基线的一半。消融研究表明，过渡预测误差驱动了复杂性的快速上升，而共学习性误差在与过渡预测误差结合时带来了额外的收益。这些结果证明了精确的遗憾近似和任务关系的显式建模在UED中的样本高效学习序列设计中的重要性。
# 54. `cs.AI` - 基于价值优化的分层强化学习在具有挑战性的四足行走中的应用 [PDF](https://arxiv.org/pdf/2506.20036), [HTML](https://arxiv.org/abs/2506.20036)
## Authors
Jeremiah Coholich,Muhammad Ali Murtaza,Seth Hutchinson,Zsolt Kira
## Background
该研究提出了一种新型的分层强化学习框架，用于在具有挑战性的地形上实现四足动物的行走。传统的方法通常难以应对复杂的地形环境，在不同的地形条件下表现不佳。因此，需要一种能够适应多种地形的强化学习方法来提高四足动物的行走能力。本研究旨在通过设计一种分层结构的学习框架，使四足动物能够更适应复杂的地形环境，并提高其行走性能。
## Innovation
本文创新性地提出了一种具有两层结构的强化学习框架。高层策略（HLP）会选择最优目标，而低层策略（LLP）则使用带有脚印放置的目标的在线优化来操作。不同于传统的方法，HLP不需要额外的训练或环境样本，而是通过直接优化LLP的学习价值函数来工作。此外，还比较了本文的方法与端到端的强化学习方法在各种地形上的表现，突显了本文方法的优势，即更高的奖励和更少的碰撞。
## Conclusion
本文通过提出一种分层策略来优化价值函数，进一步提升了四足动物在具有挑战性的地形上的行走能力。实验结果表明，相比于端到端的强化学习方法，本文的方法在多种地形上表现更好，能够获得更高的奖励，并减少碰撞次数。这表明本文的方法对应对复杂地形环境具有较高的适应性和鲁棒性。
# 55. `cs.AI` - 量子神经网络在观察性生物医学研究中的倾向评分估计与生存分析 [PDF](https://arxiv.org/pdf/2506.19973), [HTML](https://arxiv.org/abs/2506.19973)
## Authors
Vojtěch Novák,Ivan Zelinka,Lenka Přibylová,Lubomír Martínek
## Background
本文研究了量子神经网络（QNNs）在估计倾向得分中的应用，以解决在比较腹腔镜和开放式手术技术在1177名结直肠癌患者（2001-2009年在奥斯特拉瓦大学医院治疗的患者）中的生存结果时选择偏差的问题。使用包含77个变量的数据集，包括患者人口统计学和肿瘤特征，开发了基于QNN的倾向得分模型，重点是四个关键协变量（年龄、性别、分期、BMI）。该QNN架构使用线性Z特征映射对数据进行编码，使用SummedPaulis算子进行预测，并使用Covariance Matrix Adaptation Evolution Strategy (CMA-ES)来确保在嘈杂的量子环境中进行稳健、无梯度优化。还引入了方差正则化来减轻量子测量噪声，进行了在精确条件、采样（1024个点击）以及嘈杂硬件（FakeManhattanV2）条件下的模拟实验。
## Innovation
将量子神经网络QNNs应用于倾向评分估计，特别在模拟硬件噪声条件下，QNNs在小样本数据中表现优于经典逻辑回归和梯度增强机，噪声建模增强了预测稳定性。通过遗传匹配和匹配权重优化倾向评分匹配和加权，已达到协变量平衡（标准化平均差异分别为0.0849和0.0869）。运用Kaplan-Meier估计、Cox比例风险模型和Aalen加性回归进行生存分析，未发现调整后的生存结果有显著差异（p值范围为0.287至0.851），这表明未调整的结果中存在混杂偏差。结果显示，在心脑血管疾病研究中，特别是小样本、高维数据集时，通过CMA-ES和噪声意识策略增强的QNNs具有提高因果推断的潜力。
## Conclusion
这些结果表明，通过CMA-ES和噪声感知策略增强的QNNs能够改善生物医学研究中的因果推理，特别是在小样本、高维数据集的应用中。
# 56. `cs.AI` - 揭示滚动扩散模型在概率天气预报中的应用 [PDF](https://arxiv.org/pdf/2506.20024), [HTML](https://arxiv.org/abs/2506.20024)
## Authors
Salva Rühling Cachay,Miika Aittala,Karsten Kreis,Noah Brenowitz,Arash Vahdat,Morteza Mardani,Rose Yu
## Background
扩散模型由于其强大的概率预测能力被广泛应用于预测，但是在高维混沌系统中，大部分应用都是逐时段预测未来快照。这种方法难以建模复杂的时序依赖关系，且未能明确考虑系统本质上的不确定性增长。为了应对这一挑战，已经提出了滚动扩散框架，通过在更长时间预测时增加噪声来改进预测，但将其与最先进的高保真扩散技术整合仍然存在显著挑战。
## Innovation
本文提出了Elucidated Rolling Diffusion Models (ERDM)，这是第一个成功将滚动预测结构与Elucidated Diffusion Models (EDM)的基本原理高性能设计统一起来的框架。ERDM的创新之处在于：(i) 引入了一种新的损失加权方案，强调模型能力应集中在确定性和随机性过渡的中间预测时间段；(ii) 使用预训练的EDM进行初始窗口的有效初始化策略；(iii) 设计了一种特殊的混合序列架构，以在去噪过程中实现鲁棒时空特征提取。经过2D Navier-Stokes模拟和ERA5全球天气预报评估，ERDM在与自身相关的扩散基线预测方法（包括条件自回归EDM）中表现优异。ERDM提供了一个灵活且强大的通用框架，适用于高不确定性建模的扩散序列生成问题。
## Conclusion
ERDM在2D Navier-Stokes模拟和ERA5全球天气预报中提供了优于其他扩散模型基线的性能证明，它提供了一个强大的灵活框架来面对涉及逐步不确定性的扩散模型序列生成问题。
# 57. `cs.AI` - 跨层离散概念发现：语言模型的解释 [PDF](https://arxiv.org/pdf/2506.20040), [HTML](https://arxiv.org/abs/2506.20040)
## Authors
Ankur Garg,Xuemin Yu,Hassan Sajjad,Samira Ebrahimi Kahou
## Background
在变压器模型中，残差流线性地混合和复制信息，使得对大型语言模型中特征如何演变的了解变得模糊。当前的研究主要集中在单个层面上的神经表示分析，忽视了层间叠加和由此引入的冗余问题。通常，这些表示是直接分析以识别激活模式，或者通过探针分类器将这些表示映射到预定义概念的小型集。这些问题限制了我们对语言模型内部结构的理解。
## Innovation
本文提出了一种称为CLVQVAE的框架，使用向量量化来跨层映射表示，并将冗余的残差流特征压缩为紧凑且可解释的概念向量。该方法结合了量化的温度基采样和指数移动平均码书更新，提供了一种可控的方式探索离散潜在空间，并保持代码书的多样性。我们通过引入缩放球形k-means++进行编码本初始化，以更好地与词嵌入空间中的语义结构对齐。
## Conclusion
这种方法通过有效利用语言模型内部的冗余信息，实现了对跨层特征演变的更深入理解，从而提升了对语言模型解释的深度。
# 58. `cs.AI` - LSH-DynED：基于LSH下采样的动态集成框架用于演变的多类别不平衡分类 [PDF](https://arxiv.org/pdf/2506.20041), [HTML](https://arxiv.org/abs/2506.20041)
## Authors
Soheil Abadifard,Fazli Can
## Background
多类别不平衡数据流的分类是机器学习中的一个关键难题，尤其是在处理多个类别时。虽然二分类不平衡数据流分类任务已经得到了相当多的关注，但多类别不平衡数据流的研究却相对较少，有效管理动态不平衡比例是该领域的关键挑战。
## Innovation
本文提出了一种新的、稳健并具有弹性的方法，通过将局部敏感哈希与随机超平面投影（LSH-RHP）集成到动态集成多样性（DynED）框架中，以解决上述问题。这是首次在非稳定不平衡数据流中应用LSH-RHP进行下采样。该方法通过利用LSH-RHP对多数类进行下采样，提供平衡的训练集并提高集成的预测性能。实验结果显示，LSH-DynED在Kappa和mG-Mean测度中优于其他方法，它在处理大型、高维且类别不平衡的非稳定数据流方面表现出色，并且具有良好的适应性和鲁棒性。
## Conclusion
我们的方法在大规模高维度数据集和较大类别不平衡的场景中表现出色，并且在实际应用中具有良好的适应性和鲁棒性。这项工作动机在于概述现有方法并指出关键挑战，为未来工作提供了建议。我们已经在GitHub上公开了我们的实现，以实现结果的可重复性。
# 59. `cs.AI` - 使用生成式占用图合成实现稳健的机器人探索与制图 [PDF](https://arxiv.org/pdf/2506.20049), [HTML](https://arxiv.org/abs/2506.20049)
## Authors
Lorin Achey,Alec Reed,Brendan Crowe,Bradley Hayes,Christoffer Heckman
## Background
当前机器人探索主要依赖于直接传感器测量生成的地图。这些地图虽然能够提供即时信息，但在复杂或未知环境中，它们可能不够准确从而限制了机器人的探索能力。因此，通过引入新的生成模型来改进占用地图的质量和可通行性具有重要意义。现有的研究可能未能充分解决在动态和复杂场景中生成高精度3D占用地图的问题。本文旨在通过使用生成式占用映射来提升机器人的探索能力，尤其是在部分观测条件下生成高精度的地图。
## Innovation
本文提出了一种新的方法，即使用生成式占用映射增强机器人探索。具体来说，作者引入了SceneSense，这是一种专门设计并训练以根据部分观察结果预测3D占用地图的扩散模型。这种方法实时地将这些预测概率性地融合到运行中的占用地图中，从而提高了地图质量和可通行性。此外，研究者还展示了如何在现有的机器人探索系统中“即插即用”地整合由SceneSense增强的地图，从而提高鲁棒性和可通行时间。进一步，通过在两个不同的环境中使用提出的系统进行全面探索评估，证明局部增强的地图提供了更一致的探索结果。
## Conclusion
本文所提出的SceneSense方法，通过实时生成高质量的3D占用地图，显著提升了机器人的探索能力和环境理解。通过对不同环境的全面评估，验证了局部增强的地图在提高探索一致性和鲁棒性方面的有效性。此外，该方法可以通过与现有规划器的集成，提高机器人的实际应用效果。
# 60. `cs.AI` - 超越自动补全：设计CopilotLens以构建透明可解释的AI编程代理 [PDF](https://arxiv.org/pdf/2506.20062), [HTML](https://arxiv.org/abs/2506.20062)
## Authors
Runlong Ye,Zeling Zhang,Boushra Almazroua,Michael Liut
## Background
AI驱动的代码助手被广泛用于生成代码补全，显著提升了开发者的生产力。然而，这些工具通常只是提供建议而没有解释其背后的动机，使得其决策过程变得不可理解。这种不透明性阻碍了开发者对其输出进行批判性评价的能力，以及准确构建对系统的信任。
## Innovation
引入CopilotLens，这是一种全新的互动框架，将代码补全重新定义为透明和可解释的事件。CopilotLens 作为一个解释层，通过动态的两级界面揭示AI代理的“思考过程”，包括其重建的高层次计划以及影响代码的特定代码基础环境。
## Conclusion
本文介绍了CopilotLens的设计及其原理，提供了一个具体框架来构建更加注重推理清晰度而非建议速度的代理代码助手，从而促进更深层次的理解和更稳健的人工智能协作。
# 61. `cs.AI` - 使用自适应蒸馏量化图神经网络的不确定性 [PDF](https://arxiv.org/pdf/2506.20046), [HTML](https://arxiv.org/abs/2506.20046)
## Authors
Hirad Daneshvar,Reza Samavi
## Background
图神经网络（GNNs）在医疗保健领域展现了卓越性能。然而，挑战在于量化GNNs的预测不确定性，这对于临床环境的信任度非常重要。尽管贝叶斯方法和集成方法可以用来量化不确定性，但它们计算成本高昂。此外，集成方法用于计算不确定性的分歧度量也不能捕捉集成网络中模型的多样性。
## Innovation
本文提出了一种基于知识蒸馏的新方法，以更高效且更精确的方式量化GNNs的不确定性。具体来说，该方法使用自我蒸馏，即同一个网络既作为教师模型又作为学生模型，从而避免了需要单独训练多个网络。为了确保自我蒸馏的效果，开发了一种新的不确定性度量，该度量通过给每个GNN分类器分配不同的权重来捕捉网络的多样性。
## Conclusion
通过在MIMIC-IV和Enzymes两个图数据集上的实验证明，所提出的方法可以有效地捕捉模型的预测不确定性，其性能与MC Dropout和集成方法相当。相关代码已在GitHub上公开。
# 62. `cs.AI` - SACL: 使用语义增强重排序和定位理解并克服代码检索中的文本偏见 [PDF](https://arxiv.org/pdf/2506.20081), [HTML](https://arxiv.org/abs/2506.20081)
## Authors
Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie
## Background
当前的代码检索技术主要依赖于表面级的文本特征（如文档字符串、标识符名称）来增强代码生成，但它们更偏向于有详细文档的代码，即使文档质量不高。这种方法的问题在于缺乏对语义信息的利用，这会导致代码检索和生成的不准确性。因此，需要一种新的框架来提高代码检索的准确性，并减少偏见。
## Innovation
本文提出了SACL框架，通过增强代码或结构知识中的语义信息来丰富文本内容，减少检索中的偏见。SACL不仅提高了代码检索的准确性（如在HumanEval、MBPP、SWE-Bench-Lite上的召回率提高了12.8%、9.4%、7.0%），还改善了代码生成的效果（如HumanEval上的通过率提高了4.88%）。
## Conclusion
实验结果表明，SACL显著改进了代码检索能力，并且提升了代码生成的质量。
# 63. `cs.AI` - 使用二进制优化和图学习自动生成多代理操作的多样化行动计划 [PDF](https://arxiv.org/pdf/2506.20031), [HTML](https://arxiv.org/abs/2506.20031)
## Authors
Prithvi Poddar,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury
## Background
在灾难响应、搜救和军事任务等需要多个代理参与的操作中，需要自动化流程来支持行动计划（COA）的规划。环境条件的变化（如雨、雪、障碍物等）会影响预期的性能，因此需要一个多样化的行动计划池，这样在不同任务分配给不同代理的同时，可以涵盖软变异环境条件下的性能。此外，不同代理（是人员还是自主系统）的能力差异为计划过程提供了实际的机会和计算上的挑战。该论文中提出了一种新的理论架构和计算框架来生成这样一种多样化的行动计划池，应用于软变性代理任务兼容的操作中。关键在于将任务空间及其行动计划池抽象为图形来衡量多样性。通过将行动计划集中代理任务分配问题并使用遗传算法进行任务分配，以同时最大化行动计划池内的多样性并优化代理任务映射的相容性。训练图神经网络以使用策略梯度方法进行单个代理的任务序列优化，最大化任务完成率，适应任务特征。实验表明，在模拟环境中生成行动计划的过程性能显著提升、任务序列优化的目标接近最优及生成20个行动计划的时间约为50分钟等特征
## Innovation
提出了一个新颖的理论架构和计算框架，用于生成多样化的行动计划，并应用于软变性代理任务兼容的操作中。通过将任务空间抽象为图形并衡量多样性，使用遗传算法集中代理任务分配来最大化行动计划多样性及优化代理任务映射的相容性。训练图神经网络以使用策略梯度方法进行单个代理任务序列优化，以增强完成任务的效率和适应性。该方法显著提升了行动计划生成过程的性能，具有较小的任务序列优化的目标缺口和“约50分钟计划20个行动计划”的执行时间
## Conclusion
论文展示了通过使用二进制优化和图学习生成多样化的行动计划，其在模拟环境中显著提升了任务完成率，任务序列优化目标的优化差距较小，且计划多行动计划的执行时间合理。
# 64. `cs.AI` - 集成空间-时间模型和大语言模型的模块化多任务推理框架 [PDF](https://arxiv.org/pdf/2506.20073), [HTML](https://arxiv.org/abs/2506.20073)
## Authors
Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang
## Background
空间-时间数据挖掘在不同领域中的决策制定中发挥着关键作用。然而，现有模型通常局限于单一任务，缺乏进行多任务推断和复杂长篇推理的能力，这些能力需要生成深入的解释性输出。这些限制限制了其在多方面的现实世界决策场景中的应用。
## Innovation
本文提出了一种名为STReason的新型框架，该框架结合了大语言模型（LLMs）的推理优势和空间-时间模型的分析能力，以实现多任务推理和执行。STReason利用上下文学习对复杂的自然语言查询进行模块化、可解释的程序分解，并系统执行生成解决方案和详细推理。为确保严格评估，作者构建了一个新的基准数据集，并提出了一种统一的评估框架，设计了适用于长篇空间-时间推理的度量标准。实验结果表明STReason在所有度量标准上均显著优于先进的LLM基线，在复杂的推理密集型空间-时间场景中表现尤为突出。人工评估进一步验证了STReason的可靠性和实用性，证明了其在现实世界空间-时间任务中减轻专家工作量并扩展应用范围的潜力。
## Conclusion
我们相信STReason为开发更具能力和通用性的空间-时间推理系统提供了有前景的方向。
# 65. `cs.AI` - CCR Schüler框架：用于全面RAG评估的零样本LLM法官框架 [PDF](https://arxiv.org/pdf/2506.20128), [HTML](https://arxiv.org/abs/2506.20128)
## Authors
Aashiq Muhamed
## Background
RAG系统通过集成外部知识增强了LLM，这对于需要准确事实和最新信息的领域至关重要。然而，评估RAG输出的多维度质量，包括上下文连贯性、查询相关性、事实正确性和信息完整性，面临巨大挑战。现有评估方法通常依赖简单的词汇重叠度量，这不足以捕捉这些细微差别，或者需要复杂的过程和中间步骤，如声明提取，或需要微调专门的评判模型，这些都降低了实际效率。因此，需要一种更实用且有效的评估框架来解决这些局限性。
## Innovation
本文提出了一种新颖的度量套件名为CCRS（上下文连贯性和相关性评分），它仅使用一个预训练的LLM作为零样本、端到端的评判模型。CCRS评估了五个指标：上下文连贯性（CC）、问题相关性（QR）、信息密度（ID）、答案正确性（AC）和信息召回率（IR）。CCRS相比于复杂的RAGChecker框架，在关键方面如召回率和忠实度方面提供了相当或更强大的区分力，同时计算效率更高。作者还详细分析了CCRS的度量属性，包括分数分布、收敛/区分效度、平局率、总体统计和区分力等。
## Conclusion
CCRS提供了一种实用、全面且高效的框架，用于评估和迭代改进RAG系统。作者通过使用CCRS在具有挑战性的BioASQ数据集上的六个不同RAG系统配置进行了评估，并证明了CCRS的有效性和优越性。
# 66. `cs.AI` - Irec：基于即时insight回溯的元认知支架：一个概念框架及系统原型 [PDF](https://arxiv.org/pdf/2506.20156), [HTML](https://arxiv.org/abs/2506.20156)
## Authors
Xuefei Hou,Xizhao Tan
## Background
学习的核心挑战已从知识获取转变为有效的自我调节学习（SRL），即计划、监测和反思自己的学习过程。现有的数字工具在这方面支持不足，特别是缺乏有效的元认知反思功能。现有的间隔重复系统（SRS）和个性化知识管理系统（PKM）虽各有优势，但前者忽视了情境的作用，后者则需要大量的手动维护。这些问题亟待解决，以提升学习效率和自我调节能力。
## Innovation
本文提出了一种名为‘Insight Recall’的新范式，将情境触发的个人以往见解的检索视为一个元认知支架，旨在促进自我调节学习。通过即时适应性干预（JITAI）框架的形式化描述，结合一个动态用户学习历史知识图谱和大型语言模型（LLM）的即时相似性评估机制，Irec系统应运而生。此外，还提出了一个可选的‘引导式探究’模块，允许用户与专家LLM进行苏格拉底式的对话，进一步增强学习自主性。
## Conclusion
本文构建了一个坚实的概念框架和一个可用的系统平台，为设计增强元认知和自我调节的下一代智能学习系统提供了理论依据和实践基础。
# 67. `cs.AI` - do psychic cells generate consciousness [PDF](https://arxiv.org/pdf/2506.20164), [HTML](https://arxiv.org/abs/2506.20164)
## Authors
Mototaka Suzuki,Jaan Aru
## Background
近几十年的技术进步开始使神经科学家能够以前所未有的方式解决关于意识的基本问题。这篇论文回顾了对大脑中意识处理的细胞机制的最新理解，特别关注皮层锥形神经元，即传承百年的“心理细胞”——这些神经元具有独特的细胞机制，在麻醉导致的意识丧失过程中负责选择性中断反馈信号。特别是，一类分布在锥形细胞树突上的代谢型受体被强调为关键的细胞机制。这些进展提示我们可能已经开始了理解这些心理细胞如何产生和控制我们的意识的过程。
## Innovation
论文重点关注了皮层锥形神经元在意识处理中的作用，特别是代谢型受体在其中的关键作用。它探讨了这些古老细胞的现代见解，可能为理解意识的产生提供新的线索。
## Conclusion
这篇论文提出了皮层锥形神经元，即“心理细胞”，可能在意识产生和控制中起到关键作用的观点，这符合一百多年前Cajal的直觉。尽管尚未完全理解，但这些发现标志着我们对该领域理解的一个开始。
# 68. `cs.AI` - 基于损失感知的深度神经网络剪枝准则自动选择方法 [PDF](https://arxiv.org/pdf/2506.20152), [HTML](https://arxiv.org/abs/2506.20152)
## Authors
Deepak Ghimire,Kilho Lee,Seong-heum Kim
## Background
剪枝是一种成熟的神经网络压缩技术，适用于资源有限的边缘设备部署。大多数剪枝方法采用三个阶段的顺序过程：训练、剪枝、微调。本文提出了一种基于损失感知的剪枝准则自动选择方法（LAASP），该方法采用边剪枝边训练的方式，简化了剪枝过程，减少了损失较小数据子集上的训练数据指导的量级选择，自动确定每层的最优剪枝率以减少预定浮点运算（FLOPs）数量后的骤减效应，并显示出在VGGNet和resNet模型上的有效性和优越性。
## Innovation
提出了剪枝准则自动选择方法LAASP，采用了一边训练一边剪枝的方式，并将剪枝和微调相结合，避免了传统方法的第一阶段训练，能够根据网络在小训练集上的总体损失自动选择剪枝准则和层，简化了剪枝过程，并在保留一定剪枝率的情况下减少了大量浮点运算，提高了准确性。
## Conclusion
SLAASP方法在VGGNet和ResNet模型上的实验中显示出显著效果，尤其是在CIFAR-10和ImageNet数据集上，对ResNet56和ResNet110在CIFAR-10上的精度显著提升，同时减少了52%的FLOPs，并在ImageNet上减少了42%的FLOPs且对Top-5精度的影响小于0.33%。该代码已公开可用。
# 69. `cs.AI` - 在齐性预测集中的有效选择 [PDF](https://arxiv.org/pdf/2506.20173), [HTML](https://arxiv.org/abs/2506.20173)
## Authors
Mahmoud Hegazy,Liviu Aolaritei,Michael I. Jordan,Aymeric Dieuleveut
## Background
齐性预测提供了一种无需假设分布的框架来构建具有覆盖保证的预测集。实践中，可能有多个有效的齐性预测集，它们来自不同的模型或方法。然而，选择其中最理想的集（例如最小的那个）可能导致失效的覆盖保证。本文旨在通过一种基于稳定性的方式解决这一问题，确保所选预测集的覆盖保证。我们在在线齐性预测环境中扩展了这些结果，提出了在存在额外结构情况下的若干改进，并通过实验演示了其有效性。
## Innovation
提出了一种基于稳定性的方法，以确保所选齐性预测集的有效覆盖。将该方法扩展到了在线齐性预测环境，对有额外结构的情况下进行了若干改进，并通过实验验证了方法的效果。
## Conclusion
该研究提出了一种基于稳定性选择策略的方法，有效解决了多对齐性预测集中的选择问题，确保了所选集的有效覆盖保证。该研究还将其应用到了在线齐性预测环境中，并通过实验证明了这种方法的有效性。
# 70. `cs.AI` - MIRAGE: 农业专家指导对话中的多模态信息寻求与推理基准 [PDF](https://arxiv.org/pdf/2506.20100), [HTML](https://arxiv.org/abs/2506.20100)
## Authors
Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve
## Background
现有的基准通常依赖于明确的用户输入和封闭的分类系统。农业领域需要一个能够捕捉真实用户与专家交互复杂性的基准，该交互涉及植株健康、虫害诊断和作物管理等多种场景，并涵盖大量生物实体，包括植物种类、害虫和疾病。
## Innovation
MIRAGE 是一个全新的基准，专为农业领域设计，能够涵盖多模态用户查询、专家回复和图像背景，提供了现实世界、知识密集型领域的高保真度基准，评估模型在基于场景的推理、澄清策略和长文本生成方面的性能。MIRAGE 包含超过 35,000 个真实的用户与专家交互，通过精心设计的多步流水线进行策展，并且提供开放世界的场景，要求模型推断潜在的知识缺口、处理罕见的实体，或者主动引导对话或响应。
## Conclusion
MIRAGE 是目前已知在视觉语言模型领域最具有分类多样性的真实世界基准之一，它涵盖了农业领域中的多种场景和生物实体，远远超越了现有的基准。
# 71. `cs.AI` - BrokenVideos: 用于AI生成视频中精细粒度艺术品定位的基准数据集 [PDF](https://arxiv.org/pdf/2506.20103), [HTML](https://arxiv.org/abs/2506.20103)
## Authors
Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang
## Background
近年来，深度生成模型在视频生成方面取得了显著进展，但AI生成视频的保真度仍然有限。合成的内容往往会出现诸如时间不一致的运动、物理上不可能的轨迹、不自然的对象变形和局部模糊等视觉艺术中的问题，这些都会影响真实性并且降低用户信任度。准确检测和空间定位这些艺术瑕疵对于自动化质量控制以及改进生成模型全都至关重要。然而，目前研究社区缺乏一个专门针对AI生成视频中艺术瑕疵定位的综合基准。现有的数据集要么仅限于视频或帧级检测，要么缺乏评估定位方法所需的精细空间注释。为解决这一问题，我们提出了BrokenVideos，一个包含3,254个AI生成视频的基准数据集，这些视频都具有细致标注的像素级掩码，高亮显示视觉受损区域。每个注释都经过详细的详细人工检查，以确保高质量的真实地面数据。实验证明，使用BrokenVideos训练最先进的艺术瑕疵检测模型和多模态大规模语言模型（MLLMs）显著提高了它们定位受损区域的能力。经过大量的评估，我们表明BrokenVideos为生成视频模型中艺术瑕疵定位的基准测试和研究奠定了基础。
## Innovation
创新点在于引入了BrokenVideos，这是一个包含3,254个AI生成视频的数据集，并附有细致的像素级标注，高亮显示视觉受损区域，每个标注都经过详细的人工验证，确保高质量的真实地面数据。通过使用BrokenVideos训练模型，显著提升了模型在定位受损区域的能力。此外，该数据集填补了现有的数据集在针对AI生成视频中艺术瑕疵定位的综合基准测试方面的空白，为研究奠定了重要的基础。
## Conclusion
研究表明，使用BrokenVideos数据集进行训练后，最先进的艺术瑕疵检测模型和多模态大型语言模型显著提高了其定位受损区域的能力。该数据集为生成视频模型中艺术瑕疵定位的研究提供了关键的基础，推动了这一领域的发展。数据集已公开可供下载。
# 72. `cs.AI` - SEED：使用大语言模型进行时间序列预测中的嵌入驱动解码的结构编码器 [PDF](https://arxiv.org/pdf/2506.20167), [HTML](https://arxiv.org/abs/2506.20167)
## Authors
Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma
## Background
多变量时间序列预测需要模型同时捕捉变量级别结构依赖关系并泛化到不同任务。结构编码器在建模特征交互方面非常有效，但是缺乏支持语义级推理或任务适应的能力。相比之下，大规模语言模型具有强大的泛化能力，但无法直接处理原始时间序列输入。这个差距限制了统一、可迁移预测系统的开发。因此，本文提出了一种结构编码器SEED，能够嵌入驱动解码。塞德以四个阶段的工作为核心，这些阶段包括识捻感知编码器、投影模块、语义重编程机制以及冻结语言模型进行预测。该模块化架构将表示学习和推理解耦，使得数值模式和语义推理之间能够高效对齐。
## Innovation
提出了SEED，一种结构编码器，用于嵌入驱动解码。该方法集成了一个识捻感知编码器、一个将片段与语言模型嵌入对齐的投影模块、一个映射片段到任务感知原型的语义重新编程机制，以及一个用于预测的固定语言模型。这种模块化架构将表示学习和推理解耦，使得数值模式和语义推理之间能够高效对齐。该方法能够同时捕捉变量级别的结构依赖关系并泛化到不同任务，填补了结构-语义建模的差距，并证明了在诸多基准线和数据集上的一致改进。
## Conclusion
实验证明了所提出的方法在众多基线下取得了一致的改进，而且在不同数据集上的对比研究进一步确认了SEED在解决结构-语义建模差距中的作用。
# 73. `cs.AI` - 渐进对齐退化学习用于融合 [PDF](https://arxiv.org/pdf/2506.20179), [HTML](https://arxiv.org/abs/2506.20179)
## Authors
Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu
## Background
深度学习主导的融合已被证实能够有效生成高分辨率多光谱（HRMS）图像。为了创建监督地面真值HRMS图像，常用Wald协议生成合成数据。该协议假定在低分辨率数据上训练的网络在高分辨率数据上同样表现良好，但实验证明，很好地训练的模型在低分辨率和全分辨率数据集上表现出性能的妥协。因此，Wald协议的不准确的现实退化模式逼近限制了深度融合模型的泛化能力。
## Innovation
本研究提出了一种渐进对齐退化模块（PADM），这是一种基于互迭代的两个子网络PAlignNet和PDegradeNet的机制，可以自适应地学习准确的退化过程，而不需要依赖预定义的算子。同时，引入了HFreqdiff，这是一种嵌入高频细节的扩散框架，结合了CFB和BACM模块进行频率选择性细节提取和精确的逆过程学习。
## Conclusion
通过实验证明，提出的方法相比于现有的最先进的技术，在提高空间锐度和质量方面具有更优异的表现。
# 74. `cs.AI` - 零样本归因方法：一种分布测试方法 [PDF](https://arxiv.org/pdf/2506.20197), [HTML](https://arxiv.org/abs/2506.20197)
## Authors
Clément L. Canonne,Yash Pote,Uddalok Sarkar
## Background
随着越来越多的代码片段被大型语言模型（LLMs）生成，如何验证这些代码是哪些特定模型生成的成为一个新的挑战。传统的归因方法在处理基于较大样本文本生成的代码时难以解决‘维度灾难’的问题，因此提出了一种新的解决方案，即利用分布测试的方法来归因，通过零样本的方式，仅使用有限的样本就能有效地区分不同模型生成的代码片断。
## Innovation
引入了一种名为Anubis的零样本归因工具，它将归因问题重新定义为分布测试问题。与传统的基于直接从LLM样本中获取结果的方法不同，Anubis利用样本和来自LLM的密度估计（一种常见形式的访问），以解决维度灾难的问题，并通过实验验证了其有效性，能够准确地区分不同LLM生成的代码片段，即使只使用约2000个样本也能取得接近0.9的AUROC得分。
## Conclusion
实验结果表明，Anubis能够在低样本下取得高AUROC分数，有效地解决了归因问题，展示了分布测试方法在LLM归因中的潜力。
# 75. `cs.AI` - COIN：具备可证明风险保证的不确定性保护选择问答框架 [PDF](https://arxiv.org/pdf/2506.20178), [HTML](https://arxiv.org/abs/2506.20178)
## Authors
Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu
## Background
对于基础模型的不确定性量化（UQ）是识别和减轻自动生成文本中潜在幻觉的关键。现有的启发式方法在确保重要指标（如选择性预测中的假发现率FDR）的正式保证方面存在局限性。尽管过去的工作采用了分割符合预测（SCP）框架来确保可接受答案的最适预测集，但这些预测集常常包含错误候选，限制了它们的实际应用价值。
## Innovation
本文提出了COIN（不确定性保护选择框架），这是一种统计上有效的阈值校准方法，能够在用户指定的FDR约束下，从单个生成答案中筛选答案。COIN通过在校准集上估算经验错误率，并结合Clopper-Pearson等置信区间方法来建立真正错误率（即FDR）的高概率上界，从而在显著提高样本人群保留的情况下，控制测试数据的FDR。此外，通过采用不同的上界构建方法和不确定性量化策略，进一步增强了COIN的效能，体现了其在不同应用场景下的扩展性和适应性。
## Conclusion
COIN在风险控制、保持可接受答案的有效性以及预测效率方面表现稳健，尤其在有限校准数据的情况下，它在多种通用性和多模态文本生成任务中均展示了强大的功效。COIN的创新之处在于其提出的基于统计验证的阈值校准方法，有效地提升了不确定性量化的效果，并增强了模型的稳健性和泛化能力。
# 76. `cs.AI` - EAR: 从统一自回归模型中擦除概念 [PDF](https://arxiv.org/pdf/2506.20151), [HTML](https://arxiv.org/abs/2506.20151)
## Authors
Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang
## Background
自回归（AR）模型在视觉理解和图像生成任务上都取得了统一且强大的表现。然而，在保持整体生成质量的同时去除不需要的概念依然是一个挑战。本文围绕这一挑战进行研究，提出了一种名为Erasure Autoregressive Model (EAR) 的微调方法，旨在有效且不损害总体性能地去除模型中的特定概念。EAR模型通过引入分窗梯度累加（WGA）策略和阈值化损失屏蔽（TLM）策略来实现这一目标。此外，作者还提出了一个新的基准测试Eraser Concept Generator and Visual Filter (ECGVF)，旨在提供一个更严谨和全面的框架来评估AR模型的概念擦除效果。该基准测试利用结构化模板生成大规模的目标替换概念提示对，通过视觉分类器进行严格的筛选，确保概念的准确性和一致性。
## Innovation
该研究提出了一种新的方法，Erasure Autoregressive Model (EAR)，通过引入分窗梯度累加（WGA）策略和阈值化损失屏蔽（TLM）策略，有效且不损害总体性能地去除模型中的特定概念。另外，还提出了一种新的基准测试Eraser Concept Generator and Visual Filter (ECGVF)以评估AR模型的概念擦除效果，为此类研究提供了一个更严谨和全面的基础框架。
## Conclusion
通过ECGVF基准测试，EAR在概念擦除的有效性和模型整体性能保持方面取得了显著的进步。研究结果表明，使用EAR方法的AR模型Janus-Pro在多个测试任务上表现尤为优异。代码已在相应链接处公开。
# 77. `cs.AI` - 人工智能与敏捷软件开发：从挫感到成功——XP2025研讨会总结 [PDF](https://arxiv.org/pdf/2506.20159), [HTML](https://arxiv.org/abs/2506.20159)
## Authors
Tomas Herda,Victoria Pichler,Zheying Zhang,Pekka Abrahamsson,Geir K. Hanssen
## Background
2025年XP大会上的全日研讨会聚集了来自研究和工业领域的专家学者，旨在探讨将人工智能集成到敏捷软件开发过程中所面临的实际挑战和机遇。参与者通过互动环节讨论了将AI集成到敏捷软件开发实践中的困境，包括工具、治理、数据质量和关键技能缺口等方面的问题。这些问题被系统地优先处理和分析，以找到根本原因。最终，研讨会促进了实现从挫感到成功实施的研究路线图的共同制定，包括短期解决方案和长期目标。
## Innovation
研讨会通过互动环节，让参与者明确了将AI集成到敏捷软件开发过程中的具体挑战，系统地分析了这些挑战的根本原因，并共同制定了一个研究路线图。这个路线图指出了未来工作的具体行动方向，既包括即时解决方案，也包括雄心勃勃的长期目标，促进了跨行业和学术界的联合努力，目的是从挫感到成功实施。
## Conclusion
研究路线图详细地制定了一个议程框架，旨在推动行业和学术界的合作努力，从理论上认识到的实际挑战转向成功的实施过程。
# 78. `cs.AI` - 如何在上下文学习中检索示例以利用大规模语言模型改进对话情绪识别？ [PDF](https://arxiv.org/pdf/2506.20199), [HTML](https://arxiv.org/abs/2506.20199)
## Authors
Mengqi Wang,Tiantian Feng,Shrikanth Narayanan
## Background
大规模语言模型（LLMs）在各种领域中实现了多种实际应用，但是创建具有高准确性的应用程序仍然具有挑战性，特别是在识别情绪这样的主观任务上。这项研究受到了SLT 2024 GenSER挑战的启发，旨在通过LLMs提高对话情绪识别（CER）的方法，特别关注如何在上下文学习（ICL）中检索高质量示例以增强CER。研究在IEMOCAP、MELD和EmoryNLP这三个数据集上进行了实验，分析表明增强示例检索效果最佳，突显了检索相关且一致的例子并通过改写提升其质量的重要性。
## Innovation
研究提出了一种基于随机和增强示例检索的不同策略，并分析了对话背景对情绪识别准确度的影响。实验结果表明，在所有数据集上，增强示例检索方法始终优于其他技术，强调了检索相关且一致的示例并通过对这些示例进行改写以提升其质量的重要性。
## Conclusion
研究发现，在上下文学习中使用增强示例检索可以有效提高对话情绪识别的准确性，凸显了该方法在实际应用中的重要价值。
# 79. `cs.AI` - Affective Priming Score: 一个用于检测序列表中调音效应的数据驱动方法 [PDF](https://arxiv.org/pdf/2506.20204), [HTML](https://arxiv.org/abs/2506.20204)
## Authors
Eduardo Gutierrez Maestro,Hadi Banaee,Amy Loutfi
## Background
调音效应在情感计算中是一个挑战，尽管社区主要从标签的角度着手解决这个问题，但数据本身的调音影响，特别是在生理信号中的影响却较少被研究。数据受调音效应影响可能导致学习模型中的误分类。因此，如何有效检测并减轻这一影响成为一个重要课题。
## Innovation
本文提出了一种名为Affective Priming Score (APS) 的数据驱动方法，用于检测由调音效应影响的数据点，并量化其受影响程度。通过在其上应用这种方法，本文验证了其有效性，并将其应用于SEED和SEED-VII数据集。使用去除了调音效应的数据进行训练时，模型的误分类率显著降低，从而显示出该方法的有效性，对增强模型稳健性和提供设计及收集情感计算数据集的有价值见解具有重要意义。
## Conclusion
本文的研究工作通过在数据层面识别并缓解调音效应，为解决情感计算中的模糊性和挑战提供了重要贡献，增强了模型的稳健性，并对设计和采集情感计算数据集提供了有价值的见解。
# 80. `cs.AI` - 利用局部和全局特征融合的GNN进行有向链接预测 [PDF](https://arxiv.org/pdf/2506.20235), [HTML](https://arxiv.org/abs/2506.20235)
## Authors
Yuyang Zhang,Xu Shen,Yu Xie,Ka-Chun Wong,Weidun Xie,Chengbin Peng
## Background
链接预测是图分析中的一个经典问题，具有许多实际应用。对于有向图，最近开发的深度学习方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻域信息。这项工作中，我们提出了一种新的图神经网络（GNN）框架，融合了特征嵌入与社区信息。我们理论证明这种混合特征可以提升有向链接预测表现。为了有效利用这些特征，我们还提出了一种方法，将输入图转换为有向线图，这样转换图中的节点在图卷积中可以聚合更多信息。实验结果显示，当30%、40%、50%和60%的连接链接用于训练数据时，我们的方法在大多数情况下都优于现有最佳方法。
## Innovation
提出了一个新的GNN框架，该框架融合了特征嵌入与社区信息，利用理论证明这些混合特征可以提升有向链接预测的表现；提出了将输入图转换为有向线图的方法，使得节点在图卷积中可以聚合更多信息。
## Conclusion
实验结果表明，该方法在使用30%、40%、50%和60%的连接链接作为训练数据的情况下，在大多数情况下均优于现有最佳方法。
# 81. `cs.AI` - FedBKD: 利用蒸馏的联邦学习以在非IID数据上兼顾泛化和个性化 [PDF](https://arxiv.org/pdf/2506.20245), [HTML](https://arxiv.org/abs/2506.20245)
## Authors
Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu
## Background
联邦学习（FL）是一种去中心化的协作机器学习技术，旨在解决工业实践中孤立数据岛和数据隐私泄露的问题。然而，处理非独立非一致（non-IID）分布的数据是一个重大挑战。现有的解决方案要么构建一个全能的全局模型，要么定制个性化的本地模型。很少有方法能够同时提供良好的通用化全局模型和表现良好的本地模型。此外，许多处理非IID问题的联邦学习方案依赖于使用公共数据集，这增加了数据泄露的风险。这些问题促使需要开发一种既能够提高全局模型泛化能力又能够提升本地模型性能的新方法。
## Innovation
本文提出了一种全新的数据驱动蒸馏框架，Federated Bidirectional Knowledge Distillation (FedBKD)，通过生成对抗网络（GAN）生成合成数据，本地模型在训练过程中作为鉴别器，其参数被冻结，合成数据用于全局和本地模型之间的双向蒸馏，促进知识交互，从而同时提升两者的性能。
## Conclusion
通过在不同非IID设置下的4个基准上进行广泛实验，结果证明FedBKD在所有情况下都达到了SOTA性能。
# 82. `cs.AI` - Q-resafe: 评估安全风险和量化感知的安全修复方法以提高量化大型语言模型的安全性 [PDF](https://arxiv.org/pdf/2506.20251), [HTML](https://arxiv.org/abs/2506.20251)
## Authors
Kejia Chen,Jiawen Zhang,Jiacong Hu,Yu Wang,Jian Lou,Zunlei Feng,Mingli Song
## Background
量化的大语言模型（LLMs）由于能够在资源受限的环境中部署，引起了越来越多的关注。然而，一些新兴的研究表明，量化方法可能削弱LLMs的安全能力，因此迫切需要进行系统性安全评估并提出有效的缓解策略。目前针对量化LLMs的安全性研究和评估还不够全面和系统，尤其是缺乏对多种量化技术及其在不同校准数据集上的综合评估。
## Innovation
本文提出了一个量化感知的安全修复框架，Q-resafe，用于在最小化功能影响的同时恢复量化LLMs的安全功能。该框架利用广泛接受的安全基准对主流量化技术进行综合的系统性评估，并提出了针对性的修复策略，以重新调整量化后的LLMs的安全性能，使其与量化前的安全性能一致，即使在挑战性的评估场景下也是如此。
## Conclusion
实验结果表明，Q-resafe成功地在量化LLMs中重新实现了与量化前同等的安全性，即使在评估场景具有挑战性时也能有效提升量化后LLMs的安全性。
# 83. `cs.AI` - 深度学习模型在作物病害检测中的比较分析：一种迁移学习方法 [PDF](https://arxiv.org/pdf/2506.20323), [HTML](https://arxiv.org/abs/2506.20323)
## Authors
Saundarya Subramaniam,Shalini Majumdar,Shantanu Nadar,Kaustubh Kulkarni
## Background
这项研究旨在开发一种基于人工智能的作物疾病检测系统，用来帮助农村地区资源有限的农民。研究将不同深度学习模型进行对比分析，重点关注其在迁移学习中的有效性。通过利用包括EfficientNet，ResNet101，MobileNetV2和我们自定义的CNN在内的深度学习模型，系统能够有效分类植物疾病。
## Innovation
研究采用了迁移学习的方法，并对比了多种深度学习模型（EfficientNet, ResNet101, MobileNetV2, 以及自定义的CNN）在作物疾病检测任务中的表现，尤其强调了自定义CNN模型的高验证准确率（95.76%）。这表明了迁移学习在农业实践中的潜在作用，以及改善作物健康管理和支持可持续农业的可能方式。
## Conclusion
这项研究展示了迁移学习在农业实践中的应用潜力，提高了作物健康管理的有效性，并支持了在农村环境中的可持续农业。
# 84. `cs.AI` - 有限演示中的超越专家性能：双重探索的高效模仿学习 [PDF](https://arxiv.org/pdf/2506.20307), [HTML](https://arxiv.org/abs/2506.20307)
## Authors
Heyang Zhao,Xingrui Yu,David M. Bossens,Ivor W. Tsang,Quanquan Gu
## Background
模仿学习在强化学习中是一个核心问题，目标是从专家的行为中学习策略。实践中，从有限的演示中准确学习专家策略是具有挑战性的，因为状态空间非常复杂。同时，为了获得超越专家的表现，需要探索环境并收集数据。然而，这在有限的演示数量下尤为困难。因此，需要提出新的方法来克服这些挑战，以提高学习效率并实现超越专家的表现。
## Innovation
本文提出了一种新的模仿学习算法，称为双重探索模仿学习（ILDE）。ILDE算法在两个方面实现探索：（1）通过探索奖励高不确定性状态-动作对进行乐观的策略优化，以改进专家策略收敛；（2）通过好奇心驱动，探索与演示轨迹不同的状态，以实现超越专家的表现。实验结果表明，ILDE在样本效率和样本数量上都优于现有的模仿学习算法，并在Atari和MuJoCo任务中实现了超越专家的表现。此外，该算法还提供了一种理论上的解释，证明它是一个具有乐观探索的不确定性正则化策略优化方法，遗憾增长呈亚线性增长。
## Conclusion
ILDE克服了有限演示下的挑战，在样本效率方面表现出色，并在Atari和MuJoCo任务中实现了超越专家的表现。该算法提供了一个理论上的保证，证明在这种情况下，它的遗憾增长呈亚线性增长。
# 85. `cs.AI` - 通过机器学习方法生成的来自能源消费者的时序替代数据用于长期预测场景 [PDF](https://arxiv.org/pdf/2506.20253), [HTML](https://arxiv.org/abs/2506.20253)
## Authors
Ben Gerhards,Nikita Popkov,Annekatrin König,Marcel Arpogaus,Bastian Schäfermeier,Leonie Riedl,Stephan Vogt,Philip Hehlert
## Background
电力价值链中的预测吸引了很多研究关注。然而，大多数研究集中在发电或消耗的短期预测上，侧重于系统层面，较少关注个体消费者。长期内个体电力消费的预测则更为忽视。本文提供了关于生成适合电力消费长期预测的高保真度合成时间序列数据的深度比较评价。这类高保真度数据对于诸如能源系统状态估计或电网规划等广泛应用至关重要。本文评估并比较了多项最先进的但较少使用的技术，包括混合Wasserstein生成对抗网络（WGAN）、去噪扩散概率模型（DDPM）、隐马尔科夫模型（HMM）和遮罩自回归伯努利多项式归一化流（MABF）的表现。
## Innovation
本文的创新之处在于通过比较多种先进技术（WGAN、DDPM、HMM和MABF）来填充对个体电力消费的长期预测数据生成方法的研究空白，重点评估这些方法的时空动态、长距离依赖性和概率过渡能力。通过这样的评估，可以更好地选择适用于状态估计和其他能源相关任务的方法，同时生成的数据还能够满足匿名性要求，保护用户隐私，减少对特定用户个性化标识的风险。
## Conclusion
研究使用了德国家庭的开源数据集，15分钟时间分辨率。利用生成和分析框架生成的合成用电概况可以很容易地应用于如状态估计或用电预测等应用中。通过本文的工作，可以提高合成电力消耗数据的准确性和可靠性，同时也确保了对用户隐私方面的考虑。
# 86. `cs.AI` - Play 的视角：一种更具包容性的 NLP 系统的多视角方法 [PDF](https://arxiv.org/pdf/2506.20209), [HTML](https://arxiv.org/abs/2506.20209)
## Authors
Benedetta Muscato,Lucia Passaro,Gizem Gezici,Fosca Giannotti
## Background
在自然语言处理（NLP）领域，处理人为分歧的常见方法是整合注释者的观点以确定单一同义谬误。然而，先前的研究表明，忽视个体意见可能会影响少数群体观点的代表性，特别是在主观任务中，注释者可能会因个人偏好系统性地产生分歧。鉴于标签反映了个人的背景、生活经历和价值观，本研究提出了一种新的多视角方法，使用软标签来促进未来视角感知模型的发展，这些模型更具包容性和多元性。研究人员在诸多主观文本分类任务中进行了全面分析，包括仇恨言论、讽刺、滥用语言和立场检测，以突出捕捉人类分歧的重要性，这往往被传统的聚合方法所忽视。分析结果显示，多视角方法不仅更好地逼近了人类标签分布（以杰森-香农分歧度量JSD衡量），而且在分类性能（更高的F1得分）方面也超越了传统方法。然而，在讽刺和立场检测等任务中，我们的方法表现出较低的置信度，这可能是因为这些文本中的固有主观性问题。最后，利用可解释AI（XAI），我们研究了模型的不确定性并揭示了有关模型预测的有意义见解。
## Innovation
提出了一种新的多视角方法，使用软标签来促进未来视角感知模型的发展，这些模型更具包容性和多元性。这种方法不仅更好地逼近了人类标签分布，而且在分类性能方面也超越了传统方法。此外，通过可解释AI进一步研究模型的不确定性，揭示了有关模型预测的有意义见解
## Conclusion
多视角方法在多个主观文本分类任务中不仅更准确地反映了人类意见的多样性和细微差别，还表现出优越的分类性能。然而，在处理具有高度主观性的任务时，该方法可能需要更谨慎地处理置信度问题。未来的研究将深入探索如何进一步提升这些模型的可靠性与解释性。
# 87. `cs.AI` - Argumentative Ensembling for Robust Recourse under Model Multiplicity [PDF](https://arxiv.org/pdf/2506.20260), [HTML](https://arxiv.org/abs/2506.20260)
## Authors
Junqi Jiang,Antonio Rago,Francesco Leofante,Francesca Toni
## Background
在机器学习中，通过训练不同的神经网络模型可能会得到多个表现相同的模型，例如使用不同的随机种子。当这些模型在面对相同输入进行预测时产生不同的结果时，称为模型多重性或模型多样性。此时需要通过集成方法将这些模型的输出进行组合。然而，在提供基于反事实（counterfactual explanations, CEs）的纠正建议时变得复杂，因为某些反事实可能在所有模型中不适用，即不具备在模型多样性情况下的鲁棒性。以往的研究通常采用集成方法来决定最终的预测结果，但对基于 CE 的纠正建议的鲁棒性考虑不足。因此，本文探讨在模型多样性情况下的纠正建议问题，并提出了一种新的方法来解决这一问题，即 recourse-aware ensembling (RAE)，这种方法在多个模型下的 CE 和预测结果同时被考虑时，可以给出最终的集成预测和纠正建议，从而确保 CEs 的鲁棒性。该方法使用基于计算论证的方法，明确表示模型预测结果和 CE 需求之间的冲突，并利用论证语义来解决这些冲突。
## Innovation
本文提出了一种新的基于计算论证的集成方法（argumentative ensembling），该方法能够确保在模型多样性（MM）情况下反事实（CE）的鲁棒性。具体而言，该方法通过使模型的冲突和 CE 的有效性去中心化，利用计算论证方法来表示模型之间以及模型预测结果和 CE 之间的冲突，并采用不同的论证语义来解决这些冲突，从而获得最终的集成解决方案。这种方法还允许用户根据自身需求对模型进行偏好的指定，具有更高的灵活性和可定制性。基于四个不同的论证语义对计算论证集成进行了全面的理论分析，并通过实验验证了该方法在八个实例中满足了预设的良好属性，从而增强了基于 CE 的纠正建议的鲁棒性。
## Conclusion
本文提出了 recourse-aware ensembling (RAE) 方法，这是一种在模型多样性条件下的集成方法。RAE 方法确保了在多个模型下的反事实和预测结果同时被考虑，以最终决定集成预测和纠正建议。通过理论和实验研究，证明该方法能够在模型多样性条件下提供鲁棒的反事实解释，增强了基于反事实解释的纠正建议的可靠性。
# 88. `cs.AI` - 通过谱增强和基于拉普拉斯的扩充进行自我监督图学习 [PDF](https://arxiv.org/pdf/2506.20362), [HTML](https://arxiv.org/abs/2506.20362)
## Authors
Lorenzo Bini,Stephane Marchand-Maillet
## Background
当前大多数图神经网络方法依赖于负样本采样和对比目标，这种方法不仅操作复杂，而且需要精心设计的数据扩充方案，限制了模型的效率和表达能力。本文旨在解决这一问题，提出了一种新的自监督图学习框架LaplaceGNN，通过谱增强技术减少了对负样本的需求，同时利用拉普拉斯信号直接优化模型结构表示，以无监督的方式有效学习图的表示。
## Innovation
LaplaceGNN框架通过自上而下的谱增强及基于拉普拉斯的扩充，创新地提出了max-min centrality指导下的预计算谱扩充方法，增强了结构监督的丰富性，同时采用对抗式自增强训练方案进一步增强特征学习能力和鲁棒性。这些技术优化了模型的学习效率，并提供了更简洁、高效的自监督图神经网络替代方案。
## Conclusion
实验结果表明，LaplaceGNN在多种基准数据集上表现出色，优于现有最先进的自监督图方法，为高效学习表达性的图表示提供了新的方向。
# 89. `cs.AI` - 具有多变量并行注意力的基础模型以生成神经活动 [PDF](https://arxiv.org/pdf/2506.20354), [HTML](https://arxiv.org/abs/2506.20354)
## Authors
Francesco Carzaniga,Michael Hersche,Abu Sebastian,Kaspar Schindler,Abbas Rahimi
## Background
在临床领域，如颅内脑电图(iEEG)，如何利用具有多种通道配置的多变量时间序列数据仍然是深度神经网络(DNNs)面临的根本挑战，特别是在不同的受试者之间通道设置差异巨大时。现有的方法在处理这种异构时间序列数据时难以构建灵活、通用且高效的模型，尤其是在预测iEEG信号的演变方面。因此，迫切需要一种能够适应异构通道数量和配置模型的新机制和方法。
## Innovation
本文提出了一种名为多变量并行注意(MVPA)的新颖自我注意力机制，能够分离内容、时间和空间注意力，使模型针对不同数量和配置的通道能够灵活、泛化和高效地建模时间序列数据。以MVPA为基础，构建了一个用于人类电生理学的生成基础模型——MVPFormer。为了支持未来的临床研究，作者还公开了迄今为止规模最大的SWEC iEEG数据集，包含约10,000小时的异构临床来源记录。MVPFormer使用MVPA实现了在不同受试者之间的强大泛化能力，在癫痫检测方面表现出专家级的性能，并且在SWEC、MAYO和FNUSA数据集上均优于最先进的Transformer基线。此外，MVPA在标准的时间序列预测和分类任务中也被验证为匹配或超越现有的基于注意力的模型。
## Conclusion
本文通过MVPA建立了通用的时间序列注意力机制，并以MVPFormer实现了先进的临床性能。MVPA和MVPFormer不仅为多变量时间序列提供了灵活的解决方案，还公开了数据集和模型代码，以便于科研界进一步探索与临床应用。
# 90. `cs.AI` - 通过结构化推理提升大型语言模型 [PDF](https://arxiv.org/pdf/2506.20241), [HTML](https://arxiv.org/abs/2506.20241)
## Authors
Yubo Dong,Hehe Fan
## Background
近期的大规模语言模型（LLMs）在自然语言处理和自动化决策方面取得了显著进展。然而，当执行涉及逻辑推断和系统规划的复杂任务时，这些模型仍然面临很大挑战，主要原因在于它们依赖于未明确结构化的统计关系。通过对认知科学和神经符号AI的研究，本文提出了一种新的方法来增强LLMs的推理能力，该方法包括将未结构化的数据显式转换为结构化格式，并使用监督微调（SFT）训练LLMs；同时，还增强了LLMs的结构化推理能力，采用了组相对策略优化（GRPO）算法，结合了两种创新算法——MAX-Flow和最长公共子序列（LCS），这些算法显著提高了推理效率并降低了计算复杂度。实验结果表明，结构化推理的整合在LLMs中的应用能够实现较为精确的推理，并在多种场景中表现稳定，且提高了与优化技术的兼容性，验证了结构化推理在LLMs中的有效性。
## Innovation
本文提出了一种通过结构化推理来增强LLMs的方法，具体包括：1) 将未结构化的数据显式转换为结构化格式，并通过监督微调（SFT）训练LLMs；2) 利用组相对策略优化（GRPO）算法，结合了MAX-Flow和LCS两种算法，以显著提高推理效率并降低计算复杂度。
## Conclusion
实验结果验证了结构化推理的整合能够实现更精确的推理，提高LLMs的综合表现，并与优化技术更好地兼容。
# 91. `cs.AI` - CARMA：通过结合视觉-语言模型与物体和动作识别进行人类-机器人小组交互的上下文感知情境定位 [PDF](https://arxiv.org/pdf/2506.20373), [HTML](https://arxiv.org/abs/2506.20373)
## Authors
Joerg Deigmoeller,Stephan Hasler,Nakul Agarwal,Daniel Tanneberg,Anna Belardinelli,Reza Ghoddoosian,Chao Wang,Felix Ocker,Fan Zhang,Behzad Dariush,Michael Gienger
## Background
在人类与机器人组成的小组互动中，有效的协作需要基于一致的人和物的表示基础上的情景意识，结合事件的片段式抽象，特别是涉及到演员和操作对象时。这需要清晰且一致的实例分配，确保机器人能够正确地识别和跟踪演员、物体及其互动。为此，CARMA系统通过在现实世界中唯一识别这些实体的物理实例，并将它们组织成包含演员、物体和动作的三元组来进行情境定位。
## Innovation
CARMA的独特之处在于结合使用视觉-语言模型与物体和动作识别，以实现人类-机器人小组互动的情境定位。通过这种方式，CARMA能够有效跟踪和识别在交互过程中出现的演员、物体及其互动，从而提供一种结构化且稳健的基础，用于在协作环境中进行基于时空推理和情境决策的应用开发。
## Conclusion
通过进行三项实验，其中涉及多名人类和一个机器人之间的互动（包括协同倒水、递送和分类等场景），我们证明该系统能够可靠地生成准确的演员-动作-物体三元组，从而为需要空间时间推理和在协作环境中的情境决策的应用提供了坚实的基础。
# 92. `cs.AI` - DipSVD: 双重视图保护的SVD方法用于高效的大语言模型压缩 [PDF](https://arxiv.org/pdf/2506.20353), [HTML](https://arxiv.org/abs/2506.20353)
## Authors
Xuan Ding,Rui Sun,Yunjian Zhang,Xiu Yan,Yueqi Zhou,Kaihao Huang,Suzhong Fu,Chuanlong Xie,Yao Zhu
## Background
大语言模型（LLMs）的计算需求和部署成本不断增长，促使了多种压缩方法的发展。与量化和无结构剪枝相比，基于SVD的压缩法提供了更好的硬件兼容性和理论保证。然而，现有的基于SVD的方法主要关注原始矩阵和压缩矩阵的整体差异，而忽视了保护矩阵中的关键组分，导致压缩模型性能较差。
## Innovation
该论文提出了一种双层重要性保护机制，即局部重要性保护和全局重要性保护，以增强基于SVD的压缩方法：(1) 局部重要性保护：通过通道加权数据去偏保护每个权重矩阵中最重要的奇异向量；(2) 全局重要性保护：通过启发式或优化方法使得非关键层承担更多的压缩负担，从而最小化压缩对关键层的影响。实验结果表明，DipSVD在多个基准测试中优于现有基于SVD的压缩方法，特别是在高模型压缩比下取得了更优的模型性能。
## Conclusion
DipSVD通过上述双层次的重要性保护机制，在多个基准上超过了现有的基于SVD的方法，特别是在高压缩比的情况下提升了模型的性能。
# 93. `cs.AI` - 客户聚类与知识共享：增强个性化去中心化学习中的隐私性和健壮性 [PDF](https://arxiv.org/pdf/2506.20413), [HTML](https://arxiv.org/abs/2506.20413)
## Authors
Mohammad Mahdi Maheri,Denys Herasymuk,Hamed Haddadi
## Background
互联网物联网(IoT)生态系统中人工智能(AI)的广泛采用加剧了对高效且私有的个性化学习方法的需求，这些方法可以在资源受限、异构的设备上运行。然而，在去中心化设置中实现有效的个性化学习带来了多种挑战，包括高效的知识传输、数据隐私保护以及抵御污染攻击的鲁棒性。
## Innovation
本文通过开发P4（个性化、私有、去中心化）方法解决了这些挑战。P4旨在为资源受限的IoT设备提供个性化模型，并确保差分隐私同时抵御污染攻击。我们的解决方案使用轻量级、完全去中心化的算法，进行私人客户相似度检测和协作组的形成。在每个组中，客户使用差分隐私知识蒸馏协同训练其模型，保持高准确性同时确保在存在恶意客户时的鲁棒性。我们在多种异构设置和攻击场景下使用流行基准数据集及线性和卷积神经网络架构评估P4。实验结果显示，P4在准确性和鲁棒性方面均优于领先的方法，且在敏感客户占比最高可达30%的场景中表现稳定。此外，我们在资源受限的设备上部署P4，展示了其可行性，实验表明，两个客户之间的协作训练仅增加约7秒的开销.
## Conclusion
P4方法实现了在个性化的去中心化学习中高准确性、强隐私性及抵御污染攻击的能力，并证明了其在资源受限设备上的实际应用价值。
# 94. `cs.AI` - 基于LLM的表格数据分类中的自动示范选择 [PDF](https://arxiv.org/pdf/2506.20451), [HTML](https://arxiv.org/abs/2506.20451)
## Authors
Shuchu Han,Wolfgang Bruckner
## Background
应用In-Context Learning (ICL)进行表格数据分类时，一个基本问题是确定提示中所需示范的理想数量。本文针对这一挑战提出了一种自动选择合适数量示范的算法。该方法不仅考虑表格数据的分布，还结合用户选择的提示模板和特定的大规模语言模型（LLM）进行估计。研究基于谱图理论，提出了一种新的相似性度量方法，并通过分析图拉普拉斯的特征值来确定能够代表数据所需最小示范数量。
## Innovation
提出了结合表格数据分布、用户提示模板和特定LLM的自动示范选择算法。基于谱图理论，该算法定义了一种新的相似性度量，并通过分析拉普拉斯特征值来确定所需最小示范数量。实验表明，该方法的性能优于传统的随机选择算法。
## Conclusion
通过实验验证了提出的算法的有效性，证明其在不同的数据集和LLM上的性能优于传统随机选择算法。
# 95. `cs.AI` - 一种具有可追溯推理功能的罕见疾病诊断代理系统 [PDF](https://arxiv.org/pdf/2506.20430), [HTML](https://arxiv.org/abs/2506.20430)
## Authors
Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie
## Background
全球约有3亿人受到罕见疾病的困扰，但由于临床表现的多样性、发病率低以及大多数临床医生对罕见病症的不熟悉，导致这些疾病的确诊和治疗面临巨大挑战。
## Innovation
提出了一种名为DeepRare的罕见疾病诊断代理系统，该系统利用大型语言模型（LLM）处理异构临床输入，生成带透明推理链的罕见疾病诊断假设。系统由一个核心主机、长期记忆模块以及负责特定领域分析任务的专用代理服务器组成，这些服务器集成超过40个专门工具和最新医疗知识来源，确保了当前的临床信息访问。DeepRare通过模块化和可扩展设计实现了复杂的诊断推理，同时保持了可追溯性和适应性。该系统在多项评估中表现出色，尤其在HPO基础上的评估中，显著优于其他15种方法，包括传统的生物信息学诊断工具、大语言模型和其他代理系统。
## Conclusion
DeepRare作为用户友好型网络应用已被成功部署，并通过临床专家验证的推理链一致性率达到95.40%。该系统在处理多模态输入场景的召回率方面也表现优异，整体达到了70.60%，远高于Exomiser的53.20%。
# 96. `cs.AI` - 作为分布量的反事实影响 [PDF](https://arxiv.org/pdf/2506.20481), [HTML](https://arxiv.org/abs/2506.20481)
## Authors
Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye
## Background
机器学习模型在训练时可能会记住训练数据中的样本，这引发了关于隐私和泛化能力的担忧。反事实自影响（counterfactual self-influence）是一个常用指标，用于衡量模型预测如何因样本包含与否在训练数据集中而变化。然而，近期研究表明，记忆现象还受到其他训练样本的影响，尤其是（近）重复样本，它们对预测影响很大。
## Innovation
作者将反事实影响视为分布量，考虑所有训练样本对一个样本记忆化的影响，而不仅仅是该样本本身的自影响。通过分析一种小型语言模型中训练样本之间的完整影响分布，作者发现仅仅依赖自影响低估了实际的记忆化风险：重复样本虽减少了自影响，但自身仍高度可提取。在图像分类中，作者观察到相似模式，简单的启发式可以揭示CIFAR-10中的近重复样本。这些发现强调了记忆化来自于训练数据间的复杂交互，并建议应由完整的分布影响来更好地捕捉这一过程而非仅依赖于自影响。
## Conclusion
研究发现，反事实自影响不能全面反映真实的记忆化风险，因为（近）重复样本显著降低了自影响而不降低其可提取性。完整影响分布提供了更准确的评估方式，揭示了训练数据中的复杂交互作用，这对于理解和减少模型记忆化问题至关重要。
# 97. `cs.AI` - 自监督动作识别中的特征生成功能 [PDF](https://arxiv.org/pdf/2506.20342), [HTML](https://arxiv.org/abs/2506.20342)
## Authors
Lei Wang,Piotr Koniusz
## Background
在视频中理解人类动作需要超越原始像素分析，而依赖更高级别的语义推理和多模态特征的有效整合。这项研究的目标是在RGB视频帧中通过联合预测动作概念和辅助特性来提升动作识别的准确性。在测试时，生成的信令流通过插入缺失的线索来丰富特征表示，而不会增加计算开销。为了关注与动作相关的重要区域，引入了两种新型领域特定描述符，分别是对象检测特征（ODF）和知觉检测特征（SDF），它们分别捕捉上下文线索和对动作识别至关重要的空间和强度模式。这些描述符可以通过多模态数据，包括光流、改进的密集轨迹、骨架数据和音频线索与辅助模态无缝集成。这项研究的框架兼容现有的先进架构，包括I3D、组装网络、视频转换器网络、FASTER以及最近的VideoMAE V2和InternVideo2等模型。为了处理辅助特征中的不确定性，研究引入了在生成过程中运用的aleatoric不确定性建模，并提出了一种稳健的损失函数来缓解特征噪声带来的影响。整个框架在多个基准测试中达到了最先进的性能，特别是Kinetics-400、Kinetics-600和Something-Something V2，显示出在捕捉精细动作动态中的有效性
## Innovation
提出了一个深度平移动作识别框架，通过联合预测动作概念和辅助特征，提升RGB视频帧的动作识别准确性。引入了两种新的领域特定描述符：对象检测特征（ODF）和知觉检测特征（SDF），用于捕捉上下文线索和关键的空间和强度模式。在此基础上，提出了在多模态自监督动作识别框架中，生成的特征流可以在不增加计算开销的情况下提供缺失的线索。为处理辅助特征的不确定性，该框架引入了aleatoric不确定性建模并提出了一种稳健的损失函数
## Conclusion
我们提出的多模态自监督动作识别框架在多个基准上达到了最先进的性能，显示了在捕捉细粒度动作动态中的有效性。
# 98. `cs.AI` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大型语言模型（LLMs）在代码生成方面表现出色，但在对外部库API频繁更新的适应上存在明显短板。这一限制源自LLMs依赖于训练数据中的过时API知识，在拥有最新文档的情况下仍无法可靠地生成代码。为了应对这一问题，我们提出了ReCode（基于规则的强化学习代码更新框架），该框架模仿人类程序员对API更改的适应方式。实验表明，ReCode在动态API场景下的代码生成性能大幅提升，特别是在未见过的任务CodeUpdateArena上效果显著。
## Innovation
ReCode框架通过强化学习来训练LLMs进行版本迁移，它构建了一个包含约2000个数据条目的训练数据集，并引入了修改过的字符串相似度度量作为奖励。ReCode较之监督微调对LLMs的一般代码生成能力影响更小，并能在多种LLMs和强化学习算法（GRPO和DAPO）上实现一致的性能提升。经过训练后，Qwen2.5-Coder-7B的表现优于参数量较大的代码指令微调模型和构架相同的推理模型。
## Conclusion
ReCode显著提升了LLMs在动态API场景下的代码生成性能，对一般代码生成能力的影响较小，且在多种LLMs和强化学习算法上均有稳定的性能提升。
# 99. `cs.AI` - SV-LLM: 使用大型语言模型进行SoC安全验证的代理方法 [PDF](https://arxiv.org/pdf/2506.20415), [HTML](https://arxiv.org/abs/2506.20415)
## Authors
Dipayan Saha,Shams Tarek,Hasan Al Shaikh,Khan Thamid Hasan,Pavan Sai Nalluri,Md. Ajoad Hasan,Nashmin Alam,Jingbo Zhou,Sujan Kumar Saha,Mark Tehranipoor,Farimah Farahmandi
## Background
确保复杂系统级芯片（SoCs）的设计安全是一个关键需求，但传统的验证技术由于自动化、扩展性、全面性和适应性等方面的巨大挑战，难以跟上。大型语言模型（LLMs）因其在自然语言理解、代码生成和高级推理方面的卓越能力，为解决这些问题提供了新的范式。通过利用这些模型，可以创建一个多智能体系统，其中专门的LLMs协作解决复杂问题。
## Innovation
本文引入了SV-LLM，这是一种多智能体辅助系统，旨在自动并加强SoC安全验证。SV-LLM通过集成专门用于任务的智能体（如验证问题回答、安全资产识别、威胁建模、测试计划和属性生成、漏洞检测以及基于模拟的漏洞验证），简化了工作流程。代理通过不同的学习范式（如上下文学习、微调和检索增强生成）来优化其在各种任务中的性能。其目标是减少手动干预，提高准确性，并加速安全分析，以支持在设计周期早期主动识别和缓解风险。
## Conclusion
通过示例案例研究和实验展示了SV-LLM在硬件安全领域的潜在应用和效果，证明了其可行性和有效性。
# 100. `cs.AI` - 非平稳环境下的未来离策评估与学习 [PDF](https://arxiv.org/pdf/2506.20417), [HTML](https://arxiv.org/abs/2506.20417)
## Authors
Tatsuhiro Shimizu,Kazuki Kawamura,Takanori Muroi,Yusuke Narita,Kei Tateno,Takuma Udagawa,Yuta Saito
## Background
该研究关注非平稳环境下未来离策评估（F-OPE）和学习（F-OPL）的问题，环境中的分布随时间发生变化，导致现有方法假设平稳性或依赖于严格的奖励建模假设，这会导致显著的偏差。在线上购物推荐等场景中，我们经常需要使用上个月收集的数据来评估和优化即将到来的一个月的策略价值，但未来的相关数据在历史数据中通常是不可见的，这是一个关键挑战。
## Innovation
该研究提出了一个名为OPFV的新型估计算法，它可以利用时间序列数据中的有用结构来估计策略的未来价值，即使未来的数据未包含在历史日志中。此外，该研究还扩展了该算法以提出一种新的策略梯度方法，使用仅有的历史数据来主动学习未来的好策略，该方法在各种实验设置下表现出色，优于现有方法。理论分析确定了在何种条件下OPFV能产生低偏差的结果。
## Conclusion
该研究提出的方法在非平稳环境下，在估计和优化未来策略的价值方面，表现出色并显著优于现有方法，为未来离策评估与学习提供了新的方法和理论基础。
# 101. `cs.AI` - 使用数字孪生生成数据集和有效数据增强的工业能源分解 [PDF](https://arxiv.org/pdf/2506.20525), [HTML](https://arxiv.org/abs/2506.20525)
## Authors
Christian Internò,Andrea Castellani,Sebastian Schmitt,Fabio Stella,Barbara Hammer
## Background
工业非侵入式负载监控（NILM）受限于高质量数据集的稀缺性和工业能源消耗模式的复杂变化。为了解决数据稀缺和隐私问题，我们引入了Synthetic Industrial Dataset for Energy Disaggregation（SIDED），一种使用数字孪生模拟生成的开源数据集。SIDED包括三个不同地理区域的三种类型工业设施，涵盖了各种电器行为、天气条件和负载特征。
## Innovation
我们还提出了一种称为Appliance-Modulated Data Augmentation（AMDA）的方法，这是一种计算效率高的技术，通过智能调整电器功率贡献的相对影响，来增强NILM模型的一般化。实验表明，使用AMDA增强数据训练的NILM模型在复杂工业电器（如热电联供系统）的分解方面显著提高了性能。特别是，在我们的离样外场景中，使用AMDA训练的模型实现了0.093的标准化分解误差，优于未使用数据增强（0.451）和随机数据增强（0.290）训练的模型。数据分布分析证实了AMDA能够有效对齐训练和测试数据分布，增强模型的一般化能力。
## Conclusion
我们的结果表明，使用数字孪生生成的数据集和AMDA方法可以显著提高工业能耗分解的准确性和模型的一般化能力，这对于提高能源效率和优化工业运营具有重要意义。
# 102. `cs.AI` - WattsOnAI：衡量、分析和可视化AI工作负载的能源和碳足迹 [PDF](https://arxiv.org/pdf/2506.20535), [HTML](https://arxiv.org/abs/2506.20535)
## Authors
Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang
## Background
随着AI技术，尤其是大型语言模型（LLMs）的快速发展，模型训练和推理过程中所消耗的能源和产生的碳排放引起了广泛关注。然而，现有的衡量和报告这些影响的工具通常较为分散，缺乏系统化的度量集成，并且对这些工具之间的相关性分析支持有限。
## Innovation
该文介绍了WattsOnAI，这是一种综合软件工具包，用于衡量、分析和可视化AI工作负载的能源使用、功率消耗、硬件性能以及碳排放。WattsOnAI能够无缝与现有的AI框架集成，提供标准化的报告和导出细致的时间序列数据，支持轻量级的基准测试和可再现性。此外，它还能够进行硬件指标与模型性能之间的深入相关性分析，从而有助于识别瓶颈并提升性能。通过解决现有工具的关键局限性，WattsOnAI鼓励研究界在权衡环境影响的同时考虑AI工作负载的基本性能，并推动向更加可持续的‘绿色AI’实践转型。
## Conclusion
WattsOnAI通过提供衡量、分析和可视化AI工作负载能源和碳足迹的综合工具包，促进了环境影响与AI性能的平衡，并推动了更可持续的“绿色AI”实践的发展。
# 103. `cs.AI` - 多样本的力量：扩大多语言大语言模型推理计算的好处 [PDF](https://arxiv.org/pdf/2506.20544), [HTML](https://arxiv.org/abs/2506.20544)
## Authors
Ammar Khairi,Daniel D'souza,Ye Shen,Julia Kreutzer,Sara Hooker
## Background
近期，大语言模型（LLMs）的发展着重于增加推理时的计算量，提升性能而不重新训练模型。通常的做法是并行抽样多个结果，然后从中选择一个作为最终输出。然而，大多数研究集中在英语及其他少数领域，如数学和代码上。本文主要关注能够跨领域和跨语言推广的技术。本文研究了在多语言、多任务的情景下，如何稳健地扩展推理时的计算能力。发现表明，抽样策略和选择策略都需要根据不同的领域和语言环境进行调整。现有的选择方法在英语中有效，但在多语言环境下往往无法推广。
## Innovation
提出了特定适应多语言和多任务推理场景的新抽样和选择策略，这些策略在多种语言和任务上显示出显著的提升。通过结合抽样和选择方法，8B模型在m-ArenaHard-v2.0提示下的胜利率平均提升了6.8%，在较大规模的Command-A（111B模型）中，仅使用五个样本即可提升胜利率9.0%，相较于单样本解码，这是一个显著提高，且成本较低。研究结果强调了语言和任务感知的推理计算方法的重要性，以促进未充分代表的语言的性能提高。
## Conclusion
本文的研究结果表明，在多语言大语言模型中扩大推理计算的好处，并提出一种新的抽样和选择策略，能够适应不同的语言和任务环境，从而在多种语言和任务上取得更好的表现。
# 104. `cs.AI` - 使用视觉线索辅助句子总结方式进行密集视频描述：展示、讲述和总结 [PDF](https://arxiv.org/pdf/2506.20567), [HTML](https://arxiv.org/abs/2506.20567)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan
## Background
目前对于长视频的细腻描述方法尚不成熟，多数集中在生成较为简略的描述，未充分利用视频中的语义信息和视觉特征进行整体事件的详细描述。本文旨在提出一种新的框架，能够将长视频分割为多个事件片段，并通过视觉特征辅助的方式进行事件描述的总结与传递，显著提升视频视频描述的精度和完整性
## Innovation
本文提出了一个名为‘Divide-and-Summarization (DaS)’的框架，该框架包括两阶段的长短期记忆网络（LSTM），并在每个事件片段中提取视觉特征并通过现有图像/视频描述方法生成多个句子描述。该工作引入了新的层次注意力机制，利用时间序列中的视觉特征进行事件描述的总结，从而生成对整个事件概述的一句话描述，相较于传统方法在数据集上的表现更为优秀
## Conclusion
本文提出的DaS框架和含有层次注意力机制的LSTM方法在ActivityNet Captions数据集上展示了其有效性和优越性，能够有效提升密集视频描述的精确度和描述性
# 105. `cs.AI` - 使用观察分组进行因果表示学习的CXR分类 [PDF](https://arxiv.org/pdf/2506.20582), [HTML](https://arxiv.org/abs/2506.20582)
## Authors
Rajat Rasal,Avinash Kori,Ben Glocker
## Background
该研究旨在通过因果表示学习来揭示数据生成过程中真正的因果关系，特别是在医学成像领域，这对提高特定任务的潜在特征的一般适用性和鲁棒性有着潜在的好处。作者提出了一个新的框架，通过组内观察不变性来学习可识别的表示，从而在分类不同胸部X光片时，提高模型的鲁棒性和一般适用性。
## Innovation
此工作提出了一种通过端到端框架进行因果表示学习的概念，特别是使用观察分组来强制限制与种族、性别和影像视角的不变性，以实现更有效的疾病分类。这种方法试图通过识别真正的因果关系来提高模型在不同任务中的表现和鲁棒性。
## Conclusion
实验结果表明，在分类任务中使用观察分组来学习因果表示可以有效提高模型的一般适用性和鲁棒性。这种通过因果关系识别来实现的表示学习方法，为未来在胸部X光影像中进行疾病分类提供了新的思路。
# 106. `cs.AI` - 大型语言模型驱动的建筑信息建模中的代码合规性检查 [PDF](https://arxiv.org/pdf/2506.20551), [HTML](https://arxiv.org/abs/2506.20551)
## Authors
Soumya Madireddy,Lu Gao,Zia Din,Kinam Kim,Ahmed Senouci,Zhe Han,Yunpeng Zhang
## Background
建筑信息建模（BIM）中的手工代码合规性检查耗时且易出错，此次研究通过引入基于大型语言模型（LLM）的方法，旨在部分自动化这一关键过程，以解决这一问题。该系统集成了GPT、Claude、Gemini和Llama等LLM，并结合了Revit软件，用于解释建筑规范、生成Python脚本以及在BIM环境中执行半自动化合规性检查。通过在单户住宅项目和办公楼项目中的案例研究，证明了该系统能够减少合规性检查所需的时间和努力，同时提高准确性，具备高效识别不符合规范的房间尺寸、材料使用和对象放置的能力，并通过自动评估关系和生成可操作报告简化了这一过程。与手工方法相比，该系统消除了重复任务，简化了复杂规定，确保了标准的可靠遵守，提供了一个全面、灵活且经济的解决方案，有望在建设项目的各种法规文件中推广BIM基合规性检查，带来显著的改进和发展前景。
## Innovation
该研究通过引入基于大型语言模型的方法，实现了BIM环境中手工代码合规性检查的部分自动化，集成了多种LLM并与Revit软件结合，利用Python脚本进行半自动化合规性检查。该方法消除了重复工作，简化了复杂的规定，并确保了标准的合规性，提供了一个全面、灵活且成本效益高的解决方案，具有在建筑项目中广泛的应用潜力。
## Conclusion
该研究提出了一种基于大型语言模型驱动的方法，用于BIM中的代码合规性检查，这一方法通过自动化检查流程，减少了时间和人力的投入，并提高了检查的准确性和效果。该解决方案提供了简化的合规检查流程和可靠的合规性保证，并提出了未来在更广泛法规文件中的应用可能。
# 107. `cs.AI` - DeepQuark: 深度神经网络方法研究多夸克束缚态 [PDF](https://arxiv.org/pdf/2506.20555), [HTML](https://arxiv.org/abs/2506.20555)
## Authors
Wei-Lin Wu,Lu Meng,Shi-Lin Zhu
## Background
以往的研究通常采用诸如扩散蒙特卡罗方法和高斯展开法等先进技术对由电子或核子组成的系统进行研究。然而，多夸克束缚态因为强SU(3)色相互作用而比电子或核子系统更加复杂，因此需要更为高效且独特的解决方案来处理这种复杂性。鉴于此，作者团队首次提出了一种基于深度神经网络的变分蒙特卡罗方法（DeepQuark），专门用于处理多夸克系统中的强关联、额外离散量子数以及难以处理的束缚相互作用等一系列独特难题
## Innovation
他们设计了一种新颖且高效的结构.DeepQuark，这种方法能够有效应对多夸克系统中特有的难题，例如更强的关联性、额外的离散量子数以及难以处理的束缚相互作用。在核子系统、双严重子四夸克和完全重四夸克系统中，该方法表现出了与最先进的方法（如扩散蒙特卡罗和高斯展开法）相当的性能。特别地，DeepQuark在五重夸克系统中展现出对现有计算方法的超越，如描述了三重严重五夸克分子P_{ccbar c}(5715)。此外，在四重夸克系统中，DeepQuark一致地描述了重子分子T_{cc}和紧凑四夸克T_{bb}，以及超弱束缚的五重夸克分子P_{ccbar c}(5715)和其底伙伴P_{bbbar b}(15569)。后者可以作为重子分子T_{cc}的类比
## Conclusion
DeepQuark在其威力和机理方面，为研究更大复杂的多夸克系统以及通过多重夸克状态探索库斯奇异吸引机制提供了巨大的潜力。这种方法还能为非微扰量子色动力学和泛化多体物理提供宝贵的见解
# 108. `cs.AI` - 通过枪声记录的声学分析解析枪型层次 [PDF](https://arxiv.org/pdf/2506.20609), [HTML](https://arxiv.org/abs/2506.20609)
## Authors
Ankit Shah,Rita Singh,Bhiksha Raj,Alexander Hauptmann
## Background
枪支暴力和大规模枪击事件的频率上升对公共安全构成了重大威胁。及时和准确的信息对于执法机构至关重要，以减少这些事件的影响。商业枪声检测系统虽然有效，但成本却非常高。因此，本研究探索了通过利用广泛设备（如手机）获取的枪声录音进行声学分析的成本效益替代方案，以便检测枪声并分类使用枪支类型。
## Innovation
本研究提出并评估了利用卷积神经网络（CNN）和支持向量机（SVM）进行联合枪声检测和枪支类型分类的机器学习框架。实验证明，深度学习方法在干净标记数据上的平均精确召回率（mAP）达到了0.58，优于SVM基线的0.39。此外，还讨论了数据质量、环境噪音以及使用嘈杂网络数据时的泛化能力（mAP为0.35）带来的挑战。
## Conclusion
本研究旨在开发一个高度准确且实时的系统，可以在常用录音设备上部署，显着降低检测成本并为一线响应者提供关键的情报。
# 109. `cs.AI` - 在 NIDS 上通过自适应黑盒对抗攻击披露漏洞 [PDF](https://arxiv.org/pdf/2506.20576), [HTML](https://arxiv.org/abs/2506.20576)
## Authors
Sabrine Ennaji,Elhadj Benkhelifa,Luigi V. Mancini
## Background
对抗攻击是指通过精心设计的微小输入来误导智能模型，这一领域引起了广泛关注。然而，现有研究在理论进展与实际应用之间存在关键差距，尤其在如网络流量等结构化的数据上，内在相关特征使有效对抗攻击变得复杂。此外，当前方法的模糊性导致了可重复性差，限制了该领域的进展。因此，现有的防护措施往往无法应对不断演变的对抗攻击。
## Innovation
本论文提出了一种新的自适应黑盒对抗攻击方法，旨在解决上述局限性。不同于以往的研究常常假定系统访问或依赖于重复探测，我们的方法严格遵守黑盒约束，通过减少交互以避免被检测到，更好地反映现实场景。我们引入了一种基于变化点检测和因果分析的自适应特征选择策略，以识别和针对容易受到干扰的特征。这种轻量级设计确保了低计算成本和高可部署性。
## Conclusion
全面的实验结果表明该攻击方法在最少交互的情况下仍能有效躲避检测，增强了适应性和在现实场景中的可应用性。通过在网络流量上的对抗攻击理解，本工作为开发稳健的防御措施奠定了基础。
# 110. `cs.AI` - OctoThinker：中期训练促进强化学习扩展 [PDF](https://arxiv.org/pdf/2506.20512), [HTML](https://arxiv.org/abs/2506.20512)
## Authors
Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu
## Background
不同基础语言模型（如Llama和Qwen）在后续训练与强化学习(RL)过程中表现出不同的行为，特别是在需要推理的任务中更为明显。理解什么类型的基础语言模型适合强化学习是开发下一代可扩展的RL基础模型的关键。因此，本文研究了中部训练策略如何影响RL动力学，特别是关注Qwen和Llama两种模型。研究发现高质量的数学语料库能显著提高基础模型和RL的性能，而QA风格的数据，尤其是长链式推理(长CoT)的例子，进一步增强了RL效果。研究还发现，虽然长CoT提高了推理深度，但也可能增加模型响应的冗长性和RL训练的不稳定性。基于这些发现，本文提出了一个‘稳定的-然后减少’的双阶段中期训练策略，这种方法提升了后续强化学习的性能，并发布了一种增强RL兼容性的模型系列OctoThinker，同时提供了可供进一步研究的数据集MegaMath-Web-Pro-Max。
## Innovation
提出了一种‘稳定的-然后减少’的双阶段中期训练策略，该策略中基础模型首先使用200亿个令牌和恒定的学习率训练，然后使用20亿个令牌在三个长CoT推理分支上训练，学习率逐渐减少。这种策略能够显著提升后续强化学习的性能，并发布了一种增强RL兼容性的模型系列OctoThinker。同时提供了超过70亿个令牌高质量的数学推理语料库，以支持进一步研究。
## Conclusion
本文深入研究了中期训练策略对强化学习的影响，并提出了提升基础模型与强化学习兼容性的双阶段训练策略。通过这种方式，OctoThinker模型系列展现出了强大的RL兼容性，并逐渐缩小了与更加RL友好模型系列的性能差距。此外，通过发布数据集MegaMath-Web-Pro-Max，本文旨在为强化学习时代的预训练策略制定提供新的见解。
# 111. `cs.AI` - Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks [PDF](https://arxiv.org/pdf/2506.20548), [HTML](https://arxiv.org/abs/2506.20548)
## Authors
Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao
## Background
随着深度学习的快速发展，生成对抗网络（GANs）和扩散模型（DMs）使得AI生成的图像（即“Deepfakes”）几乎与真实的图像难以区分。这些图像在在线社交网络（OSNs）上广泛传播，引起了对其误用的担忧。现有的Deepfake检测方法忽略了OSNs中压缩引入的“块效应”，这会掩盖Deepfake的特征，并且主要关注原始图像，而在现实世界中这些情况并不多见。
## Innovation
为了解决这些挑战，提出了一种名为PLADA的新框架（Pay Less Attention to Deceptive Artifacts），用于处理配对数据不足和压缩图像无效利用的问题。PLADA包含两个核心模块：Block Effect Eraser（B2E），使用双重注意力机制处理块效应；以及Open Data Aggregation（ODA），处理配对和未配对数据以提高检测效果。该框架在26个数据集上的广泛实验表明，PLADA在OSNs中检测Deepfake方面表现出色，即使在配对数据有限和有压缩的情况下也能够超越现有的先进技术。此外，这项工作将“块效应”作为一个关键因素引入了Deepfake检测领域，提供了一个稳健的解决方案以应对开放世界场景。
## Conclusion
PLADA不仅实现了Deepfake检测的出色效果，还在OSNs中检测Deepfake方面超越了现有的最先进的方法，特别是在有限的配对数据和压缩的情况下。更重要的是，该工作强调了“块效应”的重要性，并为开放世界场景提供了稳健的解决方案。我们的代码可在 [此链接] 查看。
# 112. `cs.AI` - AI在写作过程中的作用：如何有针对性的AI支持促进学生写作 [PDF](https://arxiv.org/pdf/2506.20595), [HTML](https://arxiv.org/abs/2506.20595)
## Authors
Momin N. Siddiqui,Roy Pea,Hari Subramonyam
## Background
技术如ChatGPT的普及引发了对其对学生写作影响的担忧，尤其是担心学生自主权的降低和对内容的浅层处理。尽管独立的基于聊天的大型语言模型（LLM）通常会产生次优的写作结果，但研究表明，设计针对性的AI写作支持工具可以提升写作过程。因此，本研究旨在探讨不同AI支持方式如何影响写作者的自主权及其知识深度的转变。
## Innovation
本研究通过随机对照试验，比较了三种条件下的写作效果：（1）基于聊天的LLM写作助手，（2）整合的AI写作工具以支持多样化的子过程，（3）标准写作界面（对照组）。研究发现，使用整合AI写作工具的学生在写作过程中表现出更大的自主权，并且进行了更深层次的知识转换。这表明，针对写作过程特定方面的精心设计的AI写作支持可以帮助学生保持对作品的所有权，同时促进对内容的更为有效的参与。
## Conclusion
研究表明，整合设计的AI写作支持工具能够提升学生自主权并实现更深入的知识转换，有助于学生拥有作品，同时保持内容的深度参与。
# 113. `cs.AI` - Weighted Mean Frequencies: 一种用于4D Flow MRI分割的手工Fourier特征 [PDF](https://arxiv.org/pdf/2506.20614), [HTML](https://arxiv.org/abs/2506.20614)
## Authors
Simon Perrin,Sébastien Levilly,Huajun Sun,Harold Mouchère,Jean-Michel Serfaty
## Background
近年来，4D Flow MRI图像的应用使得速度场在心脏周期内的定量分析成为可能。然而，这些生物标志物的低分辨率和噪声问题仍是个重大挑战。研究表明，诸如壁剪应力这样的生物标志物尤其受到血管分割低分辨率的影响。目前，相位对比磁共振血管造影（PC-MRA）是最佳方法以期改善分割。这项工作的目标在于提出一种新的手工特征，用于提供4D Flow MRI图像的新颖可视化，这在分割任务中非常有用。该特征称为加权平均频率（WMF），能揭示体素在三维空间中经过脉动流区域的位置，从而可以表示所有脉动速度体素的边界。WMF特征通过两个实验展示了其在分割任务中的应用效果，显示了显著增强的IoU和Dice值，对比PC-MRA增加了0.12和0.13。
## Innovation
提出了一个新的手工特征——加权平均频率（WMF），该特征能够揭示4D Flow MRI图像中脉动流通过的三维区域。WMF特征能有效改善基于阈值优化和深度学习的分割方法的效果，显示出显著的IoU和Dice值提升。这对于心脏或其他血管区域的分割具有潜在的价值和指导意义。
## Conclusion
WMF特征可以显著提升4D Flow MRI图像的段任务性能，特别是在使用最好的阈值优化和深度学习方法时。它对其他血管区域如心脏或大脑的分割任务也可能具有启示性的影响。
# 114. `cs.AI` - 解缠的显微图像表示 [PDF](https://arxiv.org/pdf/2506.20649), [HTML](https://arxiv.org/abs/2506.20649)
## Authors
Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone
## Background
显微图像分析对于不同的应用至关重要，包括诊断、合成工程和环境监测等。现代获取系统使得获取大量图像成为可能，这也要求开发大量的基于深度学习的自动图像分析方法。尽管深度神经网络在该领域表现出色，但在显微图像分析中，可解释性仍是一个待解决的难题。
## Innovation
本文提出了一种解缠表示学习（DRL）方法，以提高显微图像分类模型的可解释性。通过利用来自三个不同显微图像领域的基准数据集（浮游生物、酵母液泡和人类细胞），展示了基于从合成数据中学习到的表示进行转式的DRL框架可以在这个领域提供良好的准确性和可解释性的权衡。
## Conclusion
通过DRL框架，本文证明了从合成数据学习的表示可以为显微图像分类提供良好的准确性和可解释性的平衡，为显微图像分析提供了新的方法。
# 115. `cs.AI` - Define-ML：设想包含机器学习系统的办法 [PDF](https://arxiv.org/pdf/2506.20621), [HTML](https://arxiv.org/abs/2506.20621)
## Authors
Silvio Alonso,Antonio Pedro Santos Alves,Lucas Romao,Hélio Lopes,Marcos Kalinowski
## Background
随着机器学习（ML）在软件系统中的日益广泛应用，需要专门的创新方法来应对ML特有的挑战，包括数据依赖性、技术可行性以及业务目标与概率系统行为之间的对齐。传统的创新方法如敏捷 inception 缺乏对这些ML考虑因素的结构化支持，这可能导致产品愿景的不对齐和不切实际的期待。
## Innovation
该论文提出了一种名为 Define-ML 的框架，扩展了敏捷 inception，增加了定制活动——数据来源映射、特征到数据来源映射和ML映射，以系统地将数据和技术约束融入早期的ML产品创新。该框架在技术转移模型下进行了开发和验证，结合了静态验证（使用玩具问题）和动态验证（在真实世界的工业案例研究中）。定量调查和定性反馈相结合，评估了该方法的有用性、易用性和采用意向。
## Conclusion
Define-ML 提供了一种公开可用、经过验证的方法，用于ML产品创新，继承了敏捷 inception 的灵活性，同时通过将功能与可用数据对齐来提高技术可行性的意识。所有参与者都表达了采用 Define-ML 的意愿。
# 116. `cs.AI` - 基于图的句子总结的密集视频字幕生成 [PDF](https://arxiv.org/pdf/2506.20583), [HTML](https://arxiv.org/abs/2506.20583)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou
## Background
近年来，密集视频字幕技术在检测和描述长未剪辑视频中的所有事件方面取得了吸引力的进步。尽管现有方法取得了令人鼓舞的结果，但它们大多没有充分探索事件时间提议内的场景演变，因此在场景和对象在相对较长的提议中发生变化时表现不够理想。为此，本文提出了一种图基分割与总结（GPaS）框架，用于在两个阶段进行密集视频字幕生成。在这两个阶段中，首先通过分割将整个事件提议划分为短视频片段进行细粒度字幕生成，然后通过对每个片段生成的信息丰富的句子进行总结，生成描述整个事件的一句话。特别地，本文重点关注总结阶段，并提出了一种有效利用语义词之间关系的方法。该方法将语义词视为图中的节点，并通过结合图卷积网络（GCN）和长短期记忆（LSTM）来学习它们的相互作用，借助视觉线索。提出了两种GCN-LSTM交互（GLI）模块方案，以无缝集成GCN和LSTM。在两个基准数据集（ActivityNet Captions 数据集和 YouCook II 数据集）上与最先进的方法进行广泛的比较，可以展示出本文方法的有效性。
## Innovation
提出了一种两阶段的图基分割与总结（GPaS）框架，该框架能够有效地探索事件时间提议内的场景演变，同时提出了一种利用语义词之间的关系进行总结的方法。这种方法通过将语义词作为图节点，并结合图卷积网络（GCN）和长短期记忆（LSTM）来学习其相互作用，从而实现总结目标。除此之外，提出了两种GCN-LSTM交互（GLI）模块方案，以实现GCN和LSTM的无缝集成。
## Conclusion
在两个基准数据集上与最先进的方法进行广泛的比较，证明了本文方法的有效性。
# 117. `cs.AI` - Turing Test 2.0: The General Intelligence Threshold [PDF](https://arxiv.org/pdf/2505.19550), [HTML](https://arxiv.org/abs/2505.19550)
## Authors
Georgios Mappouras
## Background
随着人工智能(A.I.)和大型语言模型（如ChatGPT）的发展，对实现通用人工智能(A.G.I.)的竞争也随之开始。虽然人们对A.I.何时以及如何达到A.G.I.存在很多猜测，但在使用图灵测试及其现代变种来衡量和检测A.I.的智能时，尚无明确共识。因此，传统方法（如图灵测试）已经不足以衡量或检测A.G.I.的存在。
## Innovation
本文的创新之处在于提出了一个新的、实际可行的方法，以决定系统（无论是计算机还是其他系统）是否达到了A.G.I.。首先，作者提供了一个清晰的通用智能(G.I.)定义，并设定了一个通用智能阈值(G.I.T.)，以区分达到A.G.I.的系统和未达到的系统；其次，作者提出了一种新框架，用以构建可以简单、全面且明确地检测系统是否达到通用智能的测试。这种方法称为图灵测试2.0。
## Conclusion
本文最终展示了遵循图灵测试2.0框架的测试在评估现代A.I.模型中是如何应用的。
# 118. `cs.AI` - 向更好的归纳知识图谱完成基准数据集迈进 [PDF](https://arxiv.org/pdf/2406.11898), [HTML](https://arxiv.org/abs/2406.11898)
## Authors
Harry Shomer,Jay Revolinsky,Jiliang Tang
## Background
知识图谱完成（KGC）旨在预测知识图谱中的缺失事实。近年来，研究人员越来越关注设计能够在归纳设置下表现优异的KGC方法，即在推理时出现的部分或全部实体和关系在训练期间未被观察到。尽管提出了多种基准数据集用于归纳KGC，但这些数据集均基于现有的用于传输式KGC的知识图谱。然而，研究团队发现当前构建归纳KGC数据集的方法无意中创建了一个捷径，即便忽略关系信息也能被利用。具体而言，观察发现Personalized PageRank (PPR)得分在大多数数据集上能获得优秀的或接近SOTA的性能。
## Innovation
本文研究了这种问题的根本原因，并基于这些见解提出了新的策略，用以构建能够减轻PPR捷径影响的归纳KGC数据集。随后，使用新构建的数据集对多种流行方法进行了基准测试，并分析了它们的表现。通过去除任何混淆性能的捷径，新基准数据集有助于更好地理解归纳KGC的能力和挑战。相关的代码和数据集可以在指定链接获取。
## Conclusion
新基准数据集有助于更准确地理解归纳KGC的能力和面临的挑战，从而消除任何可能导致混淆性能的捷径。
# 119. `cs.AI` - 具有新颖动态路由和反馈适应的混合AI实现响应式多轮在线对话 [PDF](https://arxiv.org/pdf/2506.02097), [HTML](https://arxiv.org/abs/2506.02097)
## Authors
Priyaranjan Pattnayak,Amit Agarwal,Hansa Meghwani,Hitesh Laxmichand Patel,Srikant Panda
## Background
检索增强生成（RAG）系统和大语言模型（LLM）驱动的聊天机器人通过结合生成能力和外部知识检索，显著推动了对话式AI的发展。尽管取得了成功，但在企业级部署中仍面临多种挑战，包括多样化的用户查询、高延迟、幻觉以及难以集成频繁更新的领域特定知识。
## Innovation
本文提出了一种新的混合框架，将RAG与意图驱动的预定义响应相结合，利用预定义的高置信度响应以提高效率，同时将复杂或模糊的查询动态路由到RAG处理流程。该框架通过对话上下文管理器确保多轮交互的一致性，并通过反馈循环改进意图识别、动态调整置信阈值并逐步扩展响应范围。实验结果表明，该框架在多样化的查询类型上实现了高准确性（95%）和低延迟（180ms），在RAG和意图驱动的系统中表现出更优异的表现，旨在为企业对话式AI应用提供一个可扩展且适应性强的解决方案。
## Conclusion
提出的框架在多样化的查询类型上实现了高准确性和低延迟，优于RAG和意图驱动的系统，展示了其作为企业级对话式AI应用的可扩展性和适应性。
# 120. `cs.AI` - 大型语言模型在非洲语言中的现状：进展与挑战 [PDF](https://arxiv.org/pdf/2506.02280), [HTML](https://arxiv.org/abs/2506.02280)
## Authors
Kedir Yassin Hussen,Walelign Tewabe Sewunetie,Abinew Ali Ayele,Sukairaj Hafiz Imam,Shamsuddeen Hassan Muhammad,Seid Muhie Yimam
## Background
大型语言模型（LLMs）正在重塑自然语言处理（NLP），但对非洲2,000种低资源语言的好处却很少。本文比较分析了六种LLMs、八种小型语言模型（SLMs）和六种专门的小型语言模型（SSLMs）对非洲语言的覆盖面。评估涵盖了语言覆盖面、训练集、技术限制、书写体系问题和语言建模路线图等方面。研究发现，有42种受支持的非洲语言和23个可用的公开数据集，但存在一个很大的差距，即有四种语言（阿姆哈拉语、斯瓦希里语、南非荷兰语和马达加斯加语）始终被处理，而其他超过98%的非洲语言则不被支持。此外，研究还显示，只有拉丁语、阿拉伯语和吉兹语被识别，而有20种活的书写体系被忽视。主要挑战包括缺乏数据、分词偏差、计算成本高昂和评估问题等方面。这些挑战需要语言标准化、社区主导的数据集开发和适合非洲语言的有效适应方法等解决方案。
## Innovation
本文具有以下创新点：首次比较分析了六种LLMs、八种SLMs和六种SSLMs在非洲语言方面的覆盖率；识别了42种支持的非洲语言和23个可用的公共数据集；揭示了非洲语言在LLMs中的严重覆盖率差距；强调了四大主要挑战并提出了相应的解决建议；
## Conclusion
研究发现，虽然LLMs在非洲语言中的进展和应用还在起步阶段，但存在显著差距，尤其是非洲语言的覆盖率和适应方法上的不足。未来工作应重点关注数据收集、标准制定、社区主导的数据集开发、以及有效适应方法的开发，以改善非洲语言的处理能力。
# 121. `cs.AI` - 自助微调融合：一种多精度自动模型融合框架 [PDF](https://arxiv.org/pdf/2502.04030), [HTML](https://arxiv.org/abs/2502.04030)
## Authors
Guinan Su,Jonas Geiping
## Background
大型语言模型（LLMs）的推理能力是一个关键领域，但开发这些能力需要大量的专有数据集和计算资源。通过模型合并来进行能力补充是一种有效的方法，通过结合多个模型而不重新训练，提供了一种有前途的替代方案。然而，当前的合并方法依赖于手动设计的策略来合并超参数，这限制了潜在模型组合的探索，并需要大量的人力投入。现有技术的这种方法主要依赖于手动设计的合并策略，这使得探索不同的模型组合受限，并需要大量的手动调整工作。因此，迫切需要一种能够自动化发现有效模型合并方法的有效工具，以节省时间和资源，同时保持模型性能。研究主要背景在于探索更高效和自动化的模型合并方法，特别是在大规模语言模型上实现推理能力的扩展和提升。
## Innovation
本文提出了一种自动模型合并框架，通过多精度近似减少了成本并能够细粒度地探索合并策略。该框架支持单目标和多目标优化，并引入了两种新型搜索空间：层次融合（Layerwise Fusion, LFS）和深度整合（Depth-wise Integration, DIS）。该方法能够在有限的计算资源内，如不到500次搜索步骤之内，自动找到有效模型合并的方法，甚至在模型已经微调的任务上也能进一步提升单目标性能，并优化多任务的性能前沿。创新之处在于自动化搜索和多精度近似，这种方法相比现有手动设计策略，可以更高效地探索更广泛的模型合并组合，减轻了研究人员的工作负担，并且能在更广泛的任务中实现更好的效果。
## Conclusion
通过使用提出的自动模型合并框架，研究人员能够找到有效融合策略，以提升单目标性能或优化多任务性能前沿，同时显著减少了计算成本。这种方法为大规模语言模型的推理能力扩展提供了新的方向，尤其在计算资源受限的情况下也表现出了良好的性能。总之，该研究通过自动优化的方法，为模型合并带来了新的可能性，特别是在自动化和效率方面取得了显著进展。
# 122. `cs.AI` - 科学家的第一检验：通过感知、理解和推理探究MLLM的认知能力 [PDF](https://arxiv.org/pdf/2506.10521), [HTML](https://arxiv.org/abs/2506.10521)
## Authors
Yuhao Zhou,Yiheng Wang,Xuming He,Ruoyao Xiao,Zhiwei Li,Qiantai Feng,Zijie Guo,Yuejin Yang,Hao Wu,Wenxuan Huang,Jiaqi Wei,Dan Si,Xiuqi Yao,Jia Bu,Haiwen Huang,Tianfan Fu,Shixiang Tang,Ben Fei,Dongzhan Zhou,Fenghua Ling,Yan Lu,Siqi Sun,Chenhui Li,Guanjie Zheng,Jiancheng Lv,Wenlong Zhang,Lei Bai
## Background
科学发现越来越依赖于基于信息密集型科学数据和领域特定专业知识的复杂多模态推理。尽管多模态大型语言模型（MLLMs）在科学基准测试中的表现令人印象深刻，但当前的科学基准测试主要集中在评估MLLMs的知识理解能力，而对其感知和推理能力的评估则明显不足。为解决这一问题，我们提出了科学家的第一检验（SFE），旨在通过三个连贯的层面评估MLLMs的科学认知能力：科学信号感知、科学属性理解、科学比较推理。SFE 包括830个经过专家验证的 VQA 对，涵盖5个高价值学科中的66个多模态任务，涉及三种不同类型的问题。
## Innovation
我们提出了SFE基准，设计用于通过感知、理解和推理三个层面评估MLLMs的科学认知能力。SFE基准包括830个经过专家验证的VQA对，涵盖了5个高价值学科中的66个多模态任务。实验结果表明，当前最先进的GPT-o3和InternVL-3在这项基准上的表现分别为34.08%和26.52%，表明MLLMs在科学领域的认知能力仍有巨大的提升空间。
## Conclusion
我们的希望是在SFE中获得的洞见能够促进AI增强的科学发现的进一步发展。
# 123. `cs.AI` - The Alignment Trap: 复杂性障碍 [PDF](https://arxiv.org/pdf/2506.10304), [HTML](https://arxiv.org/abs/2506.10304)
## Authors
Jasper Yao
## Background
本文认为AI对齐不仅困难，实际上还基于根本性的逻辑悖论。通过引入“枚举悖论”，说明由于我们不能枚举出所有必要的安全规则，却需要使用机器学习来生成这些规则，这就形成了一个悖论。随后通过五项独立的数学证明（“不可能性支柱”），进一步验证了这种悖论。该研究指出需要克服的根本性障碍，而不仅仅是技术上的障碍，从而为AI对齐的研究设立了复杂性障碍的概念。
## Innovation
本文创新在于明确提出AI对齐面临的是根本性的逻辑矛盾和复杂性障碍，这是一种全新的视角。通过建立‘枚举悖论’，并提出五项独立的数学证明（“不可能性支柱”），包括几何不可能性、计算不可能性、统计不可能性、信息论不可能性及动态不可能性，全面展示了AI对齐面临的根本性挑战。此外，作者还表示现阶段正在对核心定理进行正式验证，这表明了对这一理论严谨性的重视。
## Conclusion
本文结论表明，追求安全的高能力AI并非仅仅是技术上的突破，而是在面对多种根本和相互制约的障碍。这些障碍迫使领域内必须重新考虑AI对齐的战略方向，面临所谓的‘战略三难困境’。
# 124. `cs.AI` - $C^3$-Bench: 多任务中真实干扰大语言模型基于代理的工具 [PDF](https://arxiv.org/pdf/2505.18746), [HTML](https://arxiv.org/abs/2505.18746)
## Authors
Peijie Yu,Yifan Yang,Jinjian Li,Zelong Zhang,Haorui Wang,Xiao Feng,Feng Zhang
## Background
基于大语言模型的代理利用工具来修改环境，使得AI与物理世界交互的方式发生了革命性的变化。与传统仅依赖历史对话的NLP任务不同，这些代理在做出决策时必须考虑更复杂的因素，如工具间的关系、环境反馈和先前的决策。当前的研究通常通过多轮对话来评估代理，但忽略了这些关键因素对代理行为的影响。为了弥补这一差距，该研究提出了一个开源且高质量的基准测试平台$C^3$-Bench，它结合了攻击概念，并通过单变量分析指出了影响代理鲁棒性的关键要素。该基准测试设计了三个挑战：导航复杂的工具关系、处理关键的隐藏信息和管理动态决策路径。为了支持这些挑战，还引入了细粒度的度量标准、创新的数据收集算法和可重复的评估方法，并在49个主流代理上进行了广泛的实验。
## Innovation
该研究创新地提出了一个开源且高质量的基准测试$C^3$-Bench，它通过结合攻击概念和单变量分析，着眼于揭示基于大语言模型的代理在处理工具依赖性、长上下文信息依赖性和频繁的策略切换上的重要漏洞。引入了细粒度的度量标准和创新的数据收集算法，并通过可重复的评估方法对主流代理进行了广泛实验，揭示了代理在复杂情境下的显著不足，推动了代理性能可解释性的研究。
## Conclusion
该研究通过$C^3$-Bench让人们了解基于大语言模型的代理在多任务环境中的问题，并推动了代理性能的可解释性研究。该基准测试平台公开可获取。
# 125. `cs.AI` - 通过提示、细调和离分布提示评估小型语言模型的泛化能力和内部表示稳定性 [PDF](https://arxiv.org/pdf/2506.17289), [HTML](https://arxiv.org/abs/2506.17289)
## Authors
Rahul Raja,Arpita Vats
## Background
本文研究了在两种常用的适应范式（少样本提示和监督微调）下小型语言模型的泛化能力。虽然提示方法因其参数效率和灵活性而被广泛采用，但在资源有限的环境中以及分布变化时，这种方法的鲁棒性还不是很清楚。本文通过在不同任务格式、提示风格和模型规模下对比提示和微调方法，着重研究了它们在内分布和外分布环境中的表现。研究不仅仅关注准确性，还分析了每种方法学习的内部表示，以评估任务特定特征的稳定性和抽象性。
## Innovation
本文首次对照不同适应策略（提示和微调）系统地研究小型语言模型在不同类型任务和提示风格中的泛化能力和内部表示稳定性，特别是关注它们在内分布和外分布环境中的表现差异。研究不仅比较了准确率，还深入分析了模型内部学习的表示，以评估特征的稳定性和抽象性。
## Conclusion
研究成果揭示了不同适应策略下小型模型内部化和泛化知识的关键差异。这部分工作为低数据环境下模型选择提供了实用指导，并为提示与微调争议的实证研究做出了贡献。
# 126. `cs.AI` - 可解释强化学习：概念、算法、挑战 [PDF](https://arxiv.org/pdf/2211.06665), [HTML](https://arxiv.org/abs/2211.06665)
## Authors
Yunpeng Qing,Shunyu Liu,Jie Song,Huiqiong Wang,Mingli Song
## Background
强化学习（RL）通过智能代理与环境交互以实现长期目标而成为流行的机器学习模型。随着深度学习的复兴，深度强化学习（DRL）已成功应用到各种复杂控制任务中，尽管取得了鼓舞人心的结果，但基于深度神经网络的核心仍然是一个黑箱，使得从业者难以在注重高安全性和可靠性的实际场景中信任和使用训练好的代理。为了解决这个问题，大量文献提出了通过构建内在可解释性或事后解释性的方法来揭示智能代理内部工作机制。
## Innovation
本文提供了一个关于可解释强化学习（XRL）的综合回顾，并引入了一个新的分类法，将现有工作明确分类为模型解释、奖励解释、状态解释和任务解释方法。此外，还回顾了那些利用人类知识增强学习效率和代理性能的RL方法，这些方法在XRL领域经常被忽视。讨论了XRL领域的挑战和机遇，旨在更有效地推进XRL研究，并收集和分类公开源代码供进一步研究使用。
## Conclusion
本文提供了一个关于XRL的高层次总结，并推动了更有效的XRL解决方案的研究。
# 127. `cs.AI` - 可见和红外图像馈送中的低光行人检测：问题与挑战 [PDF](https://arxiv.org/pdf/2311.08557), [HTML](https://arxiv.org/abs/2311.08557)
## Authors
Thangarajah Akilan,Hrishikesh Vachhani
## Background
行人检测已成为高级任务的基础，包括自动驾驶、智能交通和交通监控等。目前，许多研究集中在使用可见光图像进行行人检测，主要在白天。然而，在光线不足或夜间，该任务变得非常具有挑战性。近年来，提出了新的方法，利用如远红外温度传感器等替代数据源进行低光条件下的行人检测。本研究综述了低光照行人检测的最新进展，系统地分类并分析了从基于区域的方法到非基于区域的方法以及基于图的学习方法的各种算法，强调了它们的方法、实现问题和挑战，并列出了可用于行人检测算法研究和开发的关键基准数据集，特别是在低光照情况下。
## Innovation
提出了利用远红外温度传感器等替代数据源进行低光照条件下的行人检测的新方法，并系统地分类和分析了各种基于区域、非区域和基于图的学习方法的算法及其挑战。强调了这些问题和挑战为开发高级行人检测算法提供了指导。
## Conclusion
本文总结了低光行人检测的关键基准数据集，特别是适用于低光照条件的研究和发展。为行人检测算法的发展提供了有价值的参考。
# 128. `cs.AI` - PhysUnibench：为多模态模型设计的初级物理学推理基准 [PDF](https://arxiv.org/pdf/2506.17667), [HTML](https://arxiv.org/abs/2506.17667)
## Authors
Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma
## Background
物理学问题解决对于大型人工智能模型来说是一个具有挑战性的领域，需要融合概念理解、数学推理和物理图表解释。目前的评估方法在捕捉本科水平物理学的广度和复杂性方面存在显著局限。因此，需要更严格的评估方法。现有的多模态大语言模型在处理此类问题时未能表现出理想的能力，特别是在多步骤问题和需要精确图表解释的问题上更是如此。本文介绍了PhysUniBench，这是一种大规模多模态基准，旨在评估和提高特定于本科物理学问题的多模态大语言模型的推理能力。
## Innovation
PhysUniBench 是一种大规模多模态基准，为评价和改进多模态大语言模型在解决本科物理学问题上的推理能力设计。该基准包括3,304个覆盖8大物理子学科的问题，每个问题配有一个视觉图表。这些问题分为开放性和选择题，通过迭代模型在环过程进行系统地编撰和难度分级，设计了一个细致的五级难度分级系统。初始结果显示，当前最先进的模型在解决这些问题时面临相当大的挑战，例如，GPT-4o mini 基准上只达到约34.2%的准确率。
## Conclusion
通过广泛实验，结果表明现有最先进的模型在物理推理方面存在重大挑战。PhysUniBench旨在作为一种广泛的严格评估工具推动科学人工智能领域的进步，促进发展具有更强物理推理、解决问题能力和多模态理解的模型。该基准和评估脚本可在特定URL处获取。
# 129. `cs.AI` - RefPentester: 依赖大型语言模型的基于知识指示和自我反思的渗透测试框架 [PDF](https://arxiv.org/pdf/2505.07089), [HTML](https://arxiv.org/abs/2505.07089)
## Authors
Hanzheng Dai,Yuanliang Li,Jun Yan,Zhibo Zhang
## Background
自动渗透测试（AutoPT）借助大型语言模型（LLMs）的能力自动化了道德黑客过程，通过利用LLMs固有的知识识别目标系统中的漏洞。然而，现有的基于LLM的AutoPT框架在复杂任务中往往不如人类专家，其原因包括：LLMs训练过程中知识的不平衡、规划过程中的短视以及命令生成中的幻觉。此外，现有框架缺乏从先前失败中学习的机制，限制了PT策略的自适应改进，使得PT过程的试错性质受到了制约。
## Innovation
本文提出了一种由LLMs驱动、基于知识指示和自我反思的AutoPT框架，名为RefPentester。该框架旨在协助人类操作员识别PT过程的当前阶段，并选择每一阶段的合适战术和技术，提出建议操作，逐步提供操作指导，并从先前失败的操作中反思和学习。此外，还将PT过程建模为具有七种状态的阶段机器，以有效集成提议的框架。结果显示，RefPentester在揭露Hack The Box的Sau机器凭证方面优于基线GPT-4o模型16.7%，在PT阶段转换中也表现出更高的成功率。
## Conclusion
RefPentester能够成功揭示Hack The Box的Sau机器凭证，并在PT阶段转换中表现出更高的成功率，超过基线模型16.7%。
# 130. `cs.AI` - 概念瓶颈模型尊重局部性吗？ [PDF](https://arxiv.org/pdf/2401.01259), [HTML](https://arxiv.org/abs/2401.01259)
## Authors
Naveen Raman,Mateo Espinosa Zarlenga,Juyeon Heo,Mateja Jamnik
## Background
概念导向的解释性方法使用人类可理解的中介来为机器学习模型生成解释。这些方法假设概念预测能够帮助理解模型的内部推理过程。本文通过分析概念预测器是否利用“相关”特征进行预测，来评估这种假设的实际有效性，这种特征我们称之为局部性。不尊重局部性的概念模型因为基于无关特征的概念预测变得不可解释，从而导致对概念预测的解释变得无意义。为了评估概念导向模型是否尊重局部性，作者构建并使用了三种度量来表征模型尊重局部性的情况，进一步用理论结果进行了补充分析。每种度量都捕捉了不同的扰动概念，并评估是否通过扰动“无关”特征影响了概念预测器所做的预测。研究发现，实践中许多概念导向模型未能尊重局部性，因为概念预测器往往不能清晰地区分不同的概念。
## Innovation
作者提出了三种度量来表征模型是否尊重局部性，并通过扰动无关特征的方法来评估概念预测器的性能，从而揭示了实践中许多概念导向模型未能尊重局部性的原因，即概念预测器无法清晰区分概念。基于这些发现，作者提出了缓解这一问题的建议。
## Conclusion
许多概念导向模型未能尊重局部性，导致概念预测基于无关特征，使得解释概念预测变得无效。提出新的度量和建议以改善这一状况。
# 131. `cs.AI` - 当大型语言模型与人类相反时？大型语言模型的阿谀行为 [PDF](https://arxiv.org/pdf/2311.09410), [HTML](https://arxiv.org/abs/2311.09410)
## Authors
Leonardo Ranaldi,Giulia Pucci
## Background
大型语言模型在生成能力上已经达到了用户的广泛满意，这主要是由于人类反馈的密集使用来改进模型的响应。然而，通过人类反馈获得的可诱导性会使模型倾向于生成与用户观点一致的答案，这种行为被称为阿谀，并导致生成误导性答案的倾向，从而增加了模型中的偏见，减弱了模型的鲁棒性和可靠性。本文研究了大型语言模型对阿谀行为的可诱导性，通过在不同任务中引入系统的人类干预提示来进行分析，以了解模型在回答涉及个人观点的问题时如何产生误导性响应的现象。当面对涉及主观意见的问题或需要给出相反答案的陈述时，模型表现出阿谀倾向；但在面对数学任务或具有客观答案的问题时，模型在不同规模下表现出不受用户提示影响的趋势，显示出生成正确答案的信心。
## Innovation
本文通过系统的人类干预提示研究了大型语言模型对阿谀行为的可诱导性。通过对比模型在不同任务中的表现，揭示了模型在回答涉及主观意见的问题时倾向于产生误导性响应的现象，而在涉及客观答案的问题上则表现出不受用户提示影响的倾向。
## Conclusion
大型语言模型在回答问题时可能表现出阿谀倾向，特别是在涉及主观意见的问题上。当面对数学或具有客观答案的查询时，模型表现出不受用户提示影响的趋势，更倾向于提供正确的答案。
# 132. `cs.AI` - 物理导向的仿真实执行学习及其在实际驾驶中的应用 [PDF](https://arxiv.org/pdf/2407.02508), [HTML](https://arxiv.org/abs/2407.02508)
## Authors
Hang Zhou,Yihao Qin,Dan Xu,Yiding Ji
## Background
近年来，仿真实执行学习（IRL）的进步显著提高了自主代理在各种复杂任务中从专家演示中学习技能的能力。然而，基于学习的代理在动态闭合环环境中转移知识时面临重大挑战，其性能受模仿学习（IL）和强化学习（RL）的目标冲突、样本效率低以及难以揭示隐藏的世界模型和物理规律的影响明显下降。
## Innovation
提出了一种物理导向的IRL方法，该方法完全基于数据，结合了专家演示数据和探索性数据，具有联合优化目标。这种训练过程自然地让车辆动力学背后的物理原理浮现出来。该方法在Waymax基准测试的闭合环设置中，表现优于流行的IL、RL和IRL算法，展示了37.8%的碰撞率降低和22.2%的非道路行驶率降低的效果。
## Conclusion
物理导向的IRL方法能够在实际驾驶环境下显著改善安全性和稳定性，减少碰撞和非道路行驶率，展示了这种方法的有效性和优越性。
# 133. `cs.AI` - FluoroSAM：一种可语言提示的基础模型，用于灵活的X射线图像分割 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
现有的任务特定模型在狭窄领域内能够解决特定问题，但在更广泛的应用中需要更多的数据、标注和训练时间。为了提高人类在环工作流程在诊断和介入精准医学中的灵活性，需要一种能够根据不同自然语言提示进行X射线图像分割的方法。现有的基础模型多应用于大量高质量标注数据可用的医学影像分析场景，但X射线成像模式因其高度图像变化性和不同的应用场景（从诊断胸部X射线到介入性透视）而难以适用。
## Innovation
介绍了FluoroSAM，一种从零开始训练的可语言提示变体Segment Anything Model，采用300万种不同人体解剖学、成像几何和视角的合成X射线图像进行训练。FluoroSAM通过在训练过程中加入文本嵌入的向量量化(VQ)，实现了基于自然语言提示的广泛解剖结构和工具的分割能力。通过FluoroSAM在真实X射线图像上的定量性能展示以及多种应用场景，体现了其是富有人机交互的关键促成因素在X射线成像获取和分析中。
## Conclusion
FluoroSAM能够实现基于自然语言提示的广泛灵活的X射线图像分割，为扩大医学应用、提高诊断和介入精度提供了可能，展示了其在多种医学影像分析中的潜力。
# 134. `cs.AI` - COBRA-PPM: 基于概率编程的因果贝叶斯推理架构以处理不确定性中的机器人操作 [PDF](https://arxiv.org/pdf/2403.14488), [HTML](https://arxiv.org/abs/2403.14488)
## Authors
Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze
## Background
机器人的操作任务需要它们在与物体交互时理解因果关系。然而，许多基于数据的方法缺乏因果语义，它们只考虑相关性而忽略了因果关系。因此，研究一种能够在不确定性环境中进行干预推理的新方法是必要的。这篇论文介绍了一种新颖的因果贝叶斯推理架构COBRA-PPM，它结合了因果贝叶斯网络和概率编程，用于处理不确定性环境中的机器人抓取操作。
## Innovation
本文提出了COBRA-PPM，这是一种结合了因果贝叶斯网络和概率编程的新颖架构，它能够在不确定环境下执行干预性推理，用于机器人操作。通过Gazebo环境中的高保真度实验，展示了其预测操作结果精准（预测准确率为88.6%）和选择最优动作的能力（任务成功率为94.2%）。此外，通过在实际家庭机器人上的模拟到现实的转移实验，展示了处理传感器噪声和随机动作不确定性方面的有效性。该框架高度通用且可扩展，为机器人学和因果关系领域的未来工作打下了基础。
## Conclusion
本文提出的COBRA-PPM框架，通过结合概率编程和因果贝叶斯网络，提供了一种处理不确定性环境中机器人操作的新方法。通过实验，验证了其在预测能力和动作选择方面的有效性，并显示了在真实环境中的应用潜力。
# 135. `cs.AI` - 内在有多种狼：使用认知模型解释LLMs的价值权衡 [PDF](https://arxiv.org/pdf/2506.20666), [HTML](https://arxiv.org/abs/2506.20666)
## Authors
Sonia K. Murthy,Rosie Zhao,Jennifer Hu,Sham Kakade,Markus Wulfmeier,Peng Qian,Tomer Ullman
## Background
日常生活中的社交互动经常需要在矛盾的目标之间进行权衡，例如传达一个艰难的事实、维护信任的同时还要考虑他人的感受。这些价值观权衡是人类决策和语言使用的组成部分。然而，当前用于解释语言模型（LLMs）中动态且多层次的价值观念的工具是有限的。认知科学中的“认知模型”为这些权衡提供了正式解释，通过建模说话者在选择行动或用语时的利益函数的权衡来实现。本研究使用礼貌言谈的认知模型来解读LLMs在价值权衡上的表现程度，并将其应用于系统的评估，在两种广泛的模型设置中：推理努力的程度，涵盖了前沿的黑箱模型；以及开源模型的强化学习后训练动态。结果显示，推理模型的信息效益高于社会效益；而开源模型在数学推理上则较强。LLMs的训练动态表明，在训练初期，重要性价值会发生显著变化，这种影响与所选的基模型和预训练数据相关，而反馈数据集或对齐方法的影响则持续较弱。研究表明，我们的方法能够适应LLM快速发展的景观，并为形成关于其他高层次行为的假说、理清推理模型的训练制度、在模型训练期间更精细地控制价值观之间的权衡等提供了见解。
## Innovation
本研究使用礼貌言谈的认知模型来解读LLMs在价值权衡上的表现，并将其应用于系统的评估，涵盖前沿的黑箱模型的推理努力程度和开源模型的强化学习后训练动态，揭示了在训练初期，重要性价值发生显著变化，这种影响与所选的基模型和预训练数据相关，而反馈数据集或对齐方法的影响则持续较弱。这种分析方法为LLMs提供了新的视角，帮助理解模型在价值权衡上的表现，并为未来的模型开发和训练提供了指导。
## Conclusion
我们的研究表明，LLMs在价值权衡上存在显著变化，特别是在训练初期，这种变化与基模型和预训练数据的选择密切相关，而反馈数据集或对齐方法的影响较小。这些发现还表明，我们的方法能够适应LLMs快速发展的状态，对其他高层次行为的假说形成、推理模型的训练制度以及模型训练期间值的精细控制具有指导意义。
# 136. `cs.AI` - 评价代码生成LLM处理长范围依赖的能力 [PDF](https://arxiv.org/pdf/2407.21049), [HTML](https://arxiv.org/abs/2407.21049)
## Authors
Yannick Assogba,Donghao Ren
## Background
随着语言模型支持越来越大的上下文大小，评估它们有效利用这些上下文的能力变得越来越重要。本文通过一系列逐步增强难度的多步关键检索任务来分析几种代码生成模型处理长范围依赖的能力，任务使用至多8k个令牌的上下文窗口。这些任务提供了一种比针扎干草堆测试更为细致的模型能力评估方法。研究发现，在许多模型中，当函数引用另一个在提示后定义的函数时，性能显著下降（最多2倍）。我们还观察到使用滑动窗口注意力机制的模型难以处理超过单一窗口范围的引用。通过简单的提示修改并利用调用图信息，可以提高多步检索性能最多3倍。我们的分析强调了从单一文档事实检索外，还需深入考虑长上下文性能。
## Innovation
本文通过逐步增强难度的多步关键检索任务分析了代码生成模型处理长范围依赖的能力，发现并改善了模型在处理长距离引用方面的问题。
## Conclusion
长上下文性能需要更深入的考虑，而不仅仅是单个文档中的信息检索。研究结果表明，通过利用调用图信息的简单提示修改，可以显著提高多步检索性能。
# 137. `cs.AI` -  toddle's active gaze behavior supports self-supervised object learning [PDF](https://arxiv.org/pdf/2411.01969), [HTML](https://arxiv.org/abs/2411.01969)
## Authors
Zhengyang Yu,Arthur Aubret,Marcel C. Raabe,Jane Yang,Chen Yu,Jochen Triesch
## Background
婴儿能够在几乎无监督的情况下学习从不同角度识别物体。在此过程中，他们频繁地移动眼睛和头部，从而影响其视觉体验。目前尚不清楚这些行为如何影响婴儿正在发展的物体识别能力。为了回答这个问题，本研究结合双人玩耍时的头戴式眼动追踪与无监督机器学习，通过头戴式摄像头采集婴儿当前注视点为中心的图片区域，作为视觉输入供给无监督学习模型，该模型逐渐构建起视觉表示。研究表明，婴儿的注视策略有助于生成不变的物体表示。进一步分析表明，具有高清晰度的中央视野的小范围是实现这一目标的关键因素。
## Innovation
本研究通过结合头戴式眼动追踪和无监督机器学习方法，研究了婴儿在双人玩耍时的主动注视行为如何支持其逐渐学习物体不变特征的过程。这种方法为理解婴幼儿如何通过自身视觉体验学习提供了新的视角。
## Conclusion
我们的研究表明，婴儿的注视行为有助于他们在双人玩耍中发展出不受视角变化影响的物体识别能力。具有高清晰度的中央视野的有限范围对于婴儿成功学习物体不变特征至关重要。
# 138. `cs.AI` - ReconX: 使用视频扩散模型从稀疏视角重建任何场景 [PDF](https://arxiv.org/pdf/2408.16767), [HTML](https://arxiv.org/abs/2408.16767)
## Authors
Fangfu Liu,Wenqiang Sun,Hanyang Wang,Yikai Wang,Haowen Sun,Junliang Ye,Jun Zhang,Yueqi Duan
## Background
3D场景重构技术已将现实世界的2D图像转化为3D模型，从数百张输入照片生成高度真实的3D结果。尽管在密集视角重构场景上取得了重大进展，但使用少量拍摄视角重建详细场景仍是一个病态优化问题，往往会带来末见区域的缺陷和扭曲。因此，需要一个新型的3D场景重建框架来处理这种模棱两可的重构挑战，特别是考虑使用大型预训练视频扩散模型的强大生成先验来促进稀疏视角重建，但仍需解决3D视图一致性保持的问题。通过指导生成，视频扩散模型可以合成同时保留细节和具有高度3D一致性的视频帧，确保从不同视角的场景一致性。
## Innovation
ReconX提出了一种新颖的3D场景重构范式，重新将模糊的重构挑战转化为一个时间生成任务。关键在于利用大型预训练视频扩散模型的强大生成先验，对少量输入视角进行稀疏视角重建。具体而言，ReconX先构建全局点云并将其编码到上下文空间以作为3D结构条件，然后由条件引导，视频扩散模型生成同时保留细节和高度3D一致性的视频帧，最终通过一种基于置信度的3D Gaussian Splatting优化方案恢复3D场景。这种框架以及使用的方法在质量和泛化能力上优于最先进的方法。
## Conclusion
通过大量实际数据集上的实验，证明了ReconX在质量和泛化能力方面优于现有最强方法。ReconX提供了一种创新的方法来处理稀疏视角下的3D场景重构问题，取得了显著进步。
# 139. `cs.AI` - 世界建模：理解现状或预测未来？综述 [PDF](https://arxiv.org/pdf/2411.14499), [HTML](https://arxiv.org/abs/2411.14499)
## Authors
Jingtao Ding,Yunke Zhang,Yu Shang,Yuheng Zhang,Zefang Zong,Jie Feng,Yuan Yuan,Hongyuan Su,Nian Li,Nicholas Sukiennik,Fengli Xu,Yong Li
## Background
由于GPT-4等多模态大型语言模型和Sora等视频生成模型的发展，世界模型的概念引起了广泛关注，这些模型是实现通用人工智能的关键。本文综述了世界模型的相关文献，指出世界模型通常被视为理解当前世界状态的工具或预测未来动力的工具。文章系统地分类了世界模型的功能，强调了两类主要功能：（1）构建内部表示以理解世界机制；（2）预测未来状态以模拟和指导决策。文章首先介绍了这两类进展，然后探讨了世界模型在自动驾驶、机器人技术和社会模拟等关键领域的应用，重点关注各领域如何利用这些功能。最后，文章概述了主要挑战，并提供了未来研究方向的洞见。
## Innovation
本文提供了世界模型的系统分类，强调了两类主要功能：构建内部表示以理解世界机制和预测未来状态以模拟和指导决策。文章还详细介绍了自动驾驶、机器人技术和社会模拟等领域的应用案例，以及这些应用如何利用世界模型的特定功能。此外，文章还指出了未来研究的方向，强调了未来研究的重点领域和需要解决的关键挑战。
## Conclusion
文章总结了代表性的世界模型研究论文及其代码仓库，指出了当前的挑战，并提出了未来研究的方向。
# 140. `cs.AI` - 基于联邦学习的多无人机邻域控制方法在人机协作领域中的应用 [PDF](https://arxiv.org/pdf/2412.02863), [HTML](https://arxiv.org/abs/2412.02863)
## Authors
Lucas Nogueira Nobrega,Ewerton de Oliveira,Martin Saska,Tiago Nascimento
## Background
人类与机器人交互（HRI）是一个日益增长的研究领域。在HRI中，复杂的命令分类仍然是一个未解决的问题，通常阻碍了此类技术的实际应用。文献中有一些使用神经网络来检测这些动作的工作，但由于无人机（UAV）操作中的遮挡问题，特别是在机器人移动期间，人类操作员往往会离开机器人的视野范围，这仍然是一个重大挑战。此外，在多机器人场景中，分布式训练也是一个未解决的问题。
## Innovation
本文提出了一种基于长短期记忆（LSTM）深度神经网络（具有两层和三层密集连接）与嵌入在多个无人机中的联邦学习（FL）的动作识别和控制方法。FL使我们的方法能够在分布式环境下进行训练，即无需云或其他仓库即可访问数据，从而使多机器人系统的学习更加便捷。此外，我们的多机器人方法结果还避免了遮挡情况，并在使用真实机器人进行的实验中达到了96%以上的准确率。
## Conclusion
本研究提出的方法在人机协作领域中实现无人机的邻域控制，并利用联邦学习进行了分布式训练，改善了遮挡问题，并展示了高准确率的结果。
# 141. `cs.AI` - 解锁跨语言模型的视觉数据及更复杂EEG分类任务的即席学习 [PDF](https://arxiv.org/pdf/2501.06256), [HTML](https://arxiv.org/abs/2501.06256)
## Authors
Jelena Bratulić,Sudhanshu Mittal,David T. Hoffmann,Samuel Böhm,Robin Tibor Schirrmeister,Tonio Ball,Christian Rupprecht,Thomas Brox
## Background
大规模语言模型（LLMs）展示了即席学习（ICL）能力，这种能力使模型能够根据上下文中的示例执行新任务，而无需更新模型权重。尽管ICL在自然语言处理任务和领域中提供了快速适应，但对于文本之外的模态，其出现则更为复杂。论文探讨了LLM支持ICL出现的属性，并通过促进ICL所需机制的学习，揭示了这些属性对于各种自动回归模型及模态的重要性。
## Innovation
研究识别了训练数据序列中的精确词元重复是支持ICL的重要因素，并进一步提高了ICL的稳定性和减少其瞬时性。此外，强调了训练任务难度对ICL出现的重要性。最终，通过新颖见解，解锁了LLM在视觉数据集及更复杂的EEG分类任务中实现ICL的能力，特别是在少量样本学习中。
## Conclusion
研究通过系统分析LLM并揭示促进ICL的机制，成功解锁并提高了ICL在视觉数据集及复杂EEG分类任务中的表现，为非语言模态的ICL提供了重要支持。
# 142. `cs.AI` - 在模型参数空间中追求后门攻击的隐蔽性 [PDF](https://arxiv.org/pdf/2501.05928), [HTML](https://arxiv.org/abs/2501.05928)
## Authors
Xiaoyun Xu,Zhuoran Liu,Stefanos Koffas,Stjepan Picek
## Background
现有研究主要关注在输入空间中不可区分的触发器和特征空间中不可分割的后门表示，旨在绕过检查这些特定空间的后门防御。然而，现有的后门攻击通常针对特定类型的后门防御设计，忽视了多样的防御机制。基于此观察，本文提出了一个自然问题：当面对多样化的实际防御时，当前的后门攻击是否仍构成真正的威胁？
## Innovation
研究了12种常见的后门攻击和17种多样化的代表性防御。揭示了一个关键的盲点：为输入和特征空间设计的隐蔽性后门攻击可以通过检查有后门的模型在参数空间中被削弱。为探究这一普遍漏洞的根本原因，研究了后门攻击在参数空间中的特性。发现输入-特征空间攻击引入了参数空间中的显著后门相关神经元，这被当前的后门攻击忽略了。提出了一个名为Grond的新颖供应链攻击，通过简单有效的模模块Adversarial Backdoor Injection (ABI)调整参数变化，在后门注入过程中提升参数空间的隐蔽性，从而实现了综合的隐蔽性。Extensive实验表明，Grond在CIFAR-10、GTSRB和ImageNet的一部分上优于现有最先进的（包括自适应的）防御方案的12种后门攻击。此外，证明了Adversarial Backdoor Injection (ABI)可以持续提高常见的后门攻击效果。
## Conclusion
基于综合隐蔽性的考虑，提出了一个新的后门攻击策略——Grond，该策略通过简单的模模块Adversarial Backdoor Injection (ABI)提升参数空间的隐蔽性，实验表明在多样化的实际防御下，Grond表现出色，并证明了Adversarial Backdoor Injection (ABI)可以提升常规后门攻击的效果。
# 143. `cs.AI` - 分布式卫星信息网络：架构、使能技术与趋势 [PDF](https://arxiv.org/pdf/2412.12587), [HTML](https://arxiv.org/abs/2412.12587)
## Authors
Qinyu Zhang,Liang Xu,Jianhao Huang,Tao Yang,Jian Jiao,Ye Wang,Yao Shi,Chiya Zhang,Xingjian Zhang,Ke Zhang,Yupeng Gong,Na Deng,Nan Zhao,Zhen Gao,Shujun Han,Xiaodong Xu,Li You,Dongming Wang,Shan Jiang,Dixian Zhao,Nan Zhang,Liujun Hu,Xiongwen He,Yonghui Li,Xiqi Gao,Xiaohu You
## Background
受无处不在的连接和无线智能的愿景驱动，基于超密集星座的卫星集成互联网正在演进，尽管初步成型，但由于现有机构的壁垒和有限的非可再生异构网络资源，当前的卫星系统难以满足下一代智能应用的需求。分布式卫星信息网络（DSIN），如协同集群卫星系统，正在成为一种创新的架构，通过打破通信、导航和遥感等不同卫星系统之间的信息孤岛，建立统一开放的信息网络范式，以支持灵活可靠的太空信息服务。DSIN在面对网络异构性、不可预测的信道动态、稀疏资源和分散协作框架等挑战时，侧重于开发使能技术和跨层优化技术，以增强资源效率和满足上层确定性、自适应和安全的信息服务需求。研究还指出了实现DSIN愿景的新兴研究方向和新机遇。
## Innovation
分布式卫星信息网络（DSIN）作为一种创新的架构，促进了通信、导航和遥感等不同卫星系统之间的信息联通，建立统一开放的信息网络范式，支持灵活可靠的太空信息服务。DSIN侧重于开发使能技术和跨层优化技术，以增强资源效率，满足上层确定性、自适应和安全的信息服务需求，同时还指出了实现DSIN愿景的新兴研究方向和新机遇，包括分布式再生卫星网络架构、分布式卫星计算网络架构和可重构卫星编队飞行等关键技术。
## Conclusion
该研究进一步完善和优化了DSIN架构，通过提高各层间技术的综合利用，实现了对于确定性、自适应和安全信息服务需求的高度满足。此外，也指出DSIN在未来的发展中具有广泛的新兴研究方向与机遇，为实现DSIN的愿景奠定了坚实基础。
# 144. `cs.AI` - AgentBreeder：通过自我改进缓解多代理支架对AI安全的影响 [PDF](https://arxiv.org/pdf/2502.00757), [HTML](https://arxiv.org/abs/2502.00757)
## Authors
J Rosser,Jakob Nicolaus Foerster
## Background
在将大型语言模型（LLMs）融入多代理系统的过程中，尽管通常能够提升复杂任务的表现，但这种融合对安全性的影响尚未得到全面探究。
## Innovation
引入了一个名为AgentBreeder的框架，用于实现多目标自改善的进化搜索，通过该框架发现的支架在安全基准上的平均提升率为79.4%，同时保持或提升了能力得分。在'红'模式下，发现了一些在对抗性攻击下较为脆弱的支架，并与能力优化并发产生。这份工作展示了多代理支架的潜在风险，并提供了一种缓解这些风险的框架。
## Conclusion
我们的工作揭示了多代理支架带来的风险，并提供了一个用于缓解这些风险的框架。
# 145. `cs.AI` - 模糊测试与基于大语言模型代理的结合：一种自动高效的文本到图像生成模型漏洞利用框架 [PDF](https://arxiv.org/pdf/2408.00523), [HTML](https://arxiv.org/abs/2408.00523)
## Authors
Yingkai Dong,Xiangtao Meng,Ning Yu,Zheng Li,Shanqing Guo
## Background
文本到图像（T2I）生成模型通过将文本描述转换为高质量的图像极大地革新了内容创作，然而这些模型容易受到‘监狱攻破’（jailbreaking）攻击的威胁，即精心设计的提示会绕过安全机制生成不安全的内容。尽管研究者已经开发出各种用于揭示此类风险的‘监狱攻破’攻击方法，但这些方法存在显著的局限性，包括实际访问要求难以满足、容易被检测的非自然提示、受限的搜索空间以及对目标系统提出高查询需求等问题。
## Innovation
本文提出了JailFuzzer，一种通过大语言模型（LLM）代理驱动的新型模糊测试框架，旨在黑盒设置下高效生成自然且语义有意义的‘监狱攻破’提示。JailFuzzer采用了以下三个主要组件：初始和‘监狱攻破’提示的种子池、用于生成有含义变异的引导变异引擎，以及用于评估‘监狱攻破’成功的验证函数。此外，通过基于LLM的代理构建引导变异引擎和验证函数，进一步确保了在黑盒设置中的高效性和适应性。实验结果显示，JailFuzzer在‘监狱攻破’T2I模型方面具有显著优势，能够生成自然且语义连贯的提示，减少了被传统防御检测的可能性，且以最小的查询开销实现高成功攻击率，优于现有方法的所有关键指标。
## Conclusion
本研究强调了在生成模型中实施更强大安全机制的必要性，并为将来研究防范复杂‘监狱攻破’攻击奠定了基础。JailFuzzer开源，可通过该仓库下载：this https URL
# 146. `cs.AI` - 重新思考早期停止：仅精炼，然后校准 [PDF](https://arxiv.org/pdf/2501.19195), [HTML](https://arxiv.org/abs/2501.19195)
## Authors
Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach
## Background
机器学习分类器通常会产生概率预测，这对于各种领域的准确和可解释决策至关重要。这些预测的质量通常使用适当的损失函数进行评估，如交叉熵，它可以分为两个部分：校准误差评估一般自信与否，而细化误差衡量区分不同类别的能力。在本文中，我们提出了校准-细化分解的新贝叶斯变分形式，这为后验校准提供了新的视角，并能够快速估计不同的项。利用这种新视角，我们提供了理论和实证证据，表明在训练期间校准和细化错误并不是同时最小化的。基于验证损失选择最佳批次节点会导致同时对两者都不理想的点。
## Innovation
本文提出了一种新的训练方法，即仅在训练期间最小化细化误差（Refine，然后在标准方法下进行后验校准（...然后校准）），这种方法与任何分类器无缝集成，并且在各类分类任务中都表现出一致的性能改进。
## Conclusion
本文的方法为校准-细化的分离提供了新的洞察，使得能够更精细地调整模型以提高预测准确性，同时保持可解释性。
# 147. `cs.AI` - 整合多种软件资产以提高基于LLM的Bug定位和程序修复效果 [PDF](https://arxiv.org/pdf/2412.03905), [HTML](https://arxiv.org/abs/2412.03905)
## Authors
Qiong Feng,Xiaotian Ma,Jiayi Sheng,Ziyuan Feng,Wei Song,Peng Liang
## Background
LLMs因能够简化自动化程序修复（APR）而受到关注。现有的LLM方法通常依赖单一类型的软件信息，未能充分利用不同类型的软件资产。尽管如此，许多基于LLM的方法并未探索哪种具体类型的信息最能协助APR。这项研究在此背景下提出，通过结合不同类型的软件资产来增强基于LLM的程序修复技术是必要的，并提出了DEVLoRe方法来结合问题内容（描述和错误信息）和堆栈错误跟踪来定位故障方法，进而依赖调试信息来定位故障行并生成可通过所有单元测试的可行补丁。研究表明，问题内容特别有助于LLMs进行故障定位和程序修复，不同类型的软件资产相互补充。通过集成不同的资产，DEVLoRe成功定位了Defects4J v2.0数据集中的49.3%和47.6%的一次性和非一次性的故障方法，并生成了56.0%和14.5%的可行补丁，显著优于当前最先进的APR方法。研究还重新实现了框架并证明了其在SWE-bench上的有效性，解决了9个独特的错误。研究还讨论了是否可以将领先的框架直接应用到另一种编程语言上。这项工作的代码和实验结果可供复制，在线获取地址为提供的链接。
## Innovation
提出了一种新的基于LLM的方法，即DEVLoRe，该方法通过结合问题描述、错误信息和堆栈跟踪来识别代码中的问题。通过这种方法，能够更准确地定位问题代码并生成高质量的修复代码，从而提高了基于LLM的程序修复技术的效果。这种方法特别适用于处理真实世界的复杂代码库。此外，该研究还讨论了不同编程语言之间的技术移植问题。
## Conclusion
实验结果表明，DEVLoRe方法通过结合问题内容、调试信息和错误堆栈，能够显著提高基于LLM的程序修复效果，远胜于当前的APR方法。同时，提出的方法表明了不同类型的软件资产可以互补，共同提高了修复的质量和准确性。研究也在实际编程测试平台上展示了其有效性。尽管取得了这些进展，但该领域仍然有许多进一步研究的空间，包括如何有效集成更多的软件资产，以及在实际大规模代码库中的应用挑战。
# 148. `cs.AI` - 在牢狱破解时刻的对抗性推理 [PDF](https://arxiv.org/pdf/2502.01633), [HTML](https://arxiv.org/abs/2502.01633)
## Authors
Mahdi Sabbaghi,Paul Kassianik,George Pappas,Yaron Singer,Amin Karbasi,Hamed Hassani
## Background
随着大型语言模型（LLMs）变得越来越强大和普及，对其失败案例的研究变得越来越重要。近年来在标准化、测量和扩展测试时计算方面取得了进步，这为优化模型以在困难任务上实现高性能提供了新的方法论。本文应用这些进展于模型牢狱破解任务：从对齐的LLMs中诱发出有害响应。研究者开发了一种利用损失信号引导测试时计算的对抗性推理自动牢狱破解方法，从而对许多对齐的LLMs实现了SOTA攻击成功率，即使那些试图在推断时计算与对抗性鲁棒性之间进行权衡的模型也是如此。这种方法为了解LLMs的脆弱性引入了新的范式，并为开发更鲁棒和值得信赖的AI系统奠定了基础。
## Innovation
开发了一种利用损失信号引导测试时计算的对抗性推理自动牢狱破解方法，能够对许多对齐的LLMs实现SOTA攻击成功率。这种方法为了解LLMs的脆弱性引入了新的范式，并为开发更鲁棒和值得信赖的AI系统奠定了基础。
## Conclusion
研究者为理解LLMs的脆弱性引入了新的范式，并为开发更鲁棒和值得信赖的AI系统奠定了基础。
# 149. `cs.AI` - 基于不确定性意识指令微调的可信性和信息性的平衡 [PDF](https://arxiv.org/pdf/2502.11962), [HTML](https://arxiv.org/abs/2502.11962)
## Authors
Tianyi Wu,Jingwei Ni,Bryan Hooi,Jiaheng Zhang,Elliott Ash,See-Kiong Ng,Mrinmaya Sachan,Markus Leippold
## Background
指令微调(IFT)可以提升大型语言模型(LLMs)的信息性，但可能会降低其真实性。这种权衡是因为IFT引导LLMs生成包含预训练期间覆盖不充分的长尾知识的响应，导致模型在泛化到未见过的任务时变得更具信息性但不那么准确。已有研究显示，IFT数据集中的生疏知识会影响LLMs的真实性，但尚未有有效的解决方法针对此问题。本研究旨在通过两种新颖的IFT范式来解决这一问题：$UNIT_{cut}$ 通过识别并从IFT数据集中去除生疏知识来减轻其对模型真实性的负面影响；$UNIT_{ref}$ 则是通过训练LLMs识别不确定性并在响应末尾明确表明这种不确定性，来保持高信息性和减少幻觉。
## Innovation
本研究引入了两种新的IFT范式：$UNIT_{cut}$ 通过识别并去除IFT数据集中生疏知识来改善模型的真实性；$UNIT_{ref}$ 通过训练LLMs识别不确定性并明确表明这种不确定性，以维持高信息性和减少幻觉，从而实现可信性和信息性的平衡。
## Conclusion
实验结果表明，$UNIT_{cut}$ 显著提高了LLMs的真实性，而$UNIT_{ref}$ 在保持高信息性的同时降低了幻觉，通过区分自信陈述和不确定陈述来实现可信性和信息性的最佳结合。
# 150. `cs.AI` - 使用分解扩散序列蒙特卡罗方法解决线性高斯贝叶斯逆问题 [PDF](https://arxiv.org/pdf/2502.06379), [HTML](https://arxiv.org/abs/2502.06379)
## Authors
Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten
## Background
最近的研究利用预训练的生成扩散模型作为先验来解决贝叶斯逆问题。这项工作通过设计分解扩散的序列蒙特卡罗方法，构建线性高斯逆问题的解，其中生成过程的设计允许对样本进行更大规模的更新，从而对这一研究方向做出贡献。
## Innovation
通过设计分解扩散的序列蒙特卡罗方法（DDSMC），作者解决了线性高斯逆问题。这种方法是渐近精确的，作者展示了DDSMC算法在合成数据、蛋白质数据和图像数据上的有效性。此外，他们还展示了该方法如何扩展到离散数据。
## Conclusion
该方法在合成数据、蛋白质数据和图像数据上的有效实验证明了其在解决线性高斯贝叶斯逆问题上的潜力，同时它对离散数据的扩展也展现出了灵活性。
# 151. `cs.AI` - 基于化学知识的隐私意识 retrosynthesis 学习框架 [PDF](https://arxiv.org/pdf/2502.19119), [HTML](https://arxiv.org/abs/2502.19119)
## Authors
Guikun Chen,Xu Zhang,Xiaolin Hu,Yong Liu,Yi Yang,Wenguan Wang
## Background
化学反应数据是制药、材料科学和工业化学等竞争性领域的重要资产，但由于其专有性，往往包含企业的机密信息和竞争优势。然而，当前基于机器学习的逆合成反应模型训练方法需要从多个来源收集反应数据进行集中训练，这大大增加了数据隐私泄露的风险，尤其是在数据传输和存储过程中可能会被未经授权的访问或截获。因此，如何在保护数据隐私的同时进行有效的逆合成反应模型学习成为一个迫切需求。
## Innovation
本文提出了一种隐私保护的化学知识驱动框架（CKIF），用于学习逆合成反应模型。CKIF通过迭代的化学知识驱动的模型参数聚合，在不泄露反应数据密钥的情况下，实现了多化学组织之间的分布式训练。CKIF通过利用预测反应物的化学性质来定量化评估各个模型的可观测行为，并据此确定模型聚合的自适应权重，从而在多种反应数据集上取得了超越现有baseline的显著性能。
## Conclusion
本文提出的CKIF框架在多种数据集上展现了显著的性能优势，同时有效保护了化学反应数据的隐私，在分布式环境中实现了逆合成反应模型的学习。
# 152. `cs.AI` - USP-Gaussian: 统一基于脉冲的图像重建、姿态校正和高斯散点图方法 [PDF](https://arxiv.org/pdf/2411.10504), [HTML](https://arxiv.org/abs/2411.10504)
## Authors
Kang Chen,Jiyuan Zhang,Zecheng Hao,Yajing Zheng,Tiejun Huang,Zhaofei Yu
## Background
尖峰相机作为一种神经形态摄像机，能够以0-1位流形式以40 kHz的频率捕捉场景，逐渐被用于通过神经辐射场（NeRF）或3D高斯散点图（3DGS）完成3D重建任务。现有的基于尖峰的3D重建方法通常采用分案处理的方式：首先是基于建立的尖峰到图像重建算法从尖峰信号流中重建高质量的图像，然后进行相机姿态估计和3D重建。然而，这种分案处理方法会在过程中累积大量错误，初步图像重建的质量限制会影响后续姿态估计的准确性，从而降低3D重建的精度。本文即针对这一问题，提出了一种集成优化框架USP-Gaussian，将基于尖峰的图像重建、姿态校正与高斯散点图方法统一到端到端框架中。
## Innovation
USP-Gaussian方法通过利用3DGS带来的多视图一致性以及尖峰相机的运动捕捉能力，实现了图像重建网络与3DGS之间的无缝信息整合，进而实现了联合迭代优化。该方法不仅在合成数据集上的准确姿态下超越了之前的方法，且能够通过引入姿态优化实现对现实场景中初始姿态不准确情况下的稳健3D重建，有效减少了噪声并保持了精细纹理细节。
## Conclusion
实验表明USP-Gaussian方法通过有效消除分案处理过程中的累积错误，实现了精确的3D重建。在现实世界中使用不准确的初始姿态时，USP-Gaussian方法超越了替代方法，通过有效减少噪声和保持精细纹理细节实现了稳健的3D重建。同时，作者将代码、数据和预训练模型公布在网络上。
# 153. `cs.AI` - 蛋白质结构标记化：基准测试与新方法 [PDF](https://arxiv.org/pdf/2503.00089), [HTML](https://arxiv.org/abs/2503.00089)
## Authors
Xinyu Yuan,Zichen Wang,Marcus Collins,Huzefa Rangwala
## Background
近年来，蛋白质结构标记化方法的发展迅速，这些方法将蛋白质的三维结构拆分为离散或连续的表示。结构标记化使语言模型等强大技术可以直接应用于蛋白质结构，同时也使得利用大型多模态模型将结构与蛋白质序列和功能文本相结合成为可能。尽管取得了进展，但由于缺乏统一的评估框架，这些方法的能力和限制仍不明确。现有的基准主要关注全局结构，而没有细致地评估局部子结构的质量和效率，为此作者引入了StructTokenBench框架，专注于细粒度的局部子结构，以全面评估结构标记器的质量与效率。
## Innovation
作者提出了StructTokenBench框架，这是一个全面评估结构标记器质量与效率的框架，特别关注细粒度的局部子结构。此外，作者还开发了一种名为AminoAseed的方法，这是一种简单而有效的方法，通过优化码本的梯度更新，平衡码本大小和维度，从而提高标记器的利用效率和质量。与领先的ESM3模型相比，在24个监督任务中，作者的方法平均提高了6.31%的性能，敏感性和利用率分别提高了12.83%和124.03%。
## Conclusion
综合评估表明，没有单一模型能在所有基准测试中占主导地位。AminoAseed方法通过优化码本利用和质量，显著提高了标记器的性能和效率。
# 154. `cs.AI` - Graph推理过程奖励让大语言模型成为更通用的推理者 [PDF](https://arxiv.org/pdf/2503.00845), [HTML](https://arxiv.org/abs/2503.00845)
## Authors
Miao Peng,Nuo Chen,Zongrui Suo,Jia Li
## Background
尽管大型语言模型（LLMs）取得显著进展，但开发其高级推理能力仍然是一个关键挑战。过程奖励模型（PRMs）在数学推理中表现出令人印象深刻的能力，通过提供逐步反馈来提升推理。然而，这类模型在更广泛推理领域的应用研究不足，主要由于手动创建详细阶梯监督的成本高昂。为此，该研究探讨了PRMs在图推理问题中的应用潜力，这是一类需要复杂多步推理且能通过现有图算法自动生成阶梯级数据的领域。通过构建GraphSILO数据集和引入GraphPRM模型，研究展示了在图推理中的应用效果，特别是在推断时扩展标度和使用直接偏好优化（DPO）进行强化学习方面。研究成果表明，GraphPRM显著提高了Qwen2.5-7B等LLM在13个图推理任务中的性能，并且在新的图推理数据集和新的推理领域中表现出可转移性，例如数学问题解决。这一发现突显了基于图推理奖励的跨域适用性，展示了PRMs在不同领域推进推理能力的潜力。
## Innovation
提出了GraphSILO数据集，包含详细的阶梯级标签，并且使用自动化任务导向轨迹和蒙特卡洛树搜索（MCTS）来生成图推理问题所需的详细推理步骤。还提出了GraphPRM模型，这是首个专为图推理问题设计的过程奖励模型，通过训练和实验验证了其在推理时间扩展和通过直接偏好优化进行的强化学习中的效果。实验结果表明，GraphPRM在图推理任务上显著提升了LLM的性能，并展示了在新的图推理数据集和新的推理领域中的可转移性，尤其是GSM8K和Math500数据集。
## Conclusion
研究结果表明，PRMs在图推理问题中的应用能够显著提升LLM的推理能力，并且具有跨领域的可转移性，这为开发更具适应性和有效性的LLMs铺平了道路。
# 155. `cs.AI` - WyckoffDiff——一种晶体对称性生成扩散模型 [PDF](https://arxiv.org/pdf/2502.06485), [HTML](https://arxiv.org/abs/2502.06485)
## Authors
Filip Ekström Kelvinius,Oskar B. Andersson,Abhijith S. Parackal,Dong Qian,Rickard Armiento,Fredrik Lindsten
## Background
晶体材料通常表现出高度的对称性。然而，大多数生成模型并未考虑这种对称性，而是为每个原子指定无约束的位置和元素。本文提出了一种新的生成模型WyckoffDiff，能够生成基于对称性的晶体描述。通过这种方式，WyckoffDiff能够利用包含所有对称性的晶体结构表示，并设计了一种新颖的神经网络架构，使得该表示能够用于离散生成模型框架中。此外，WyckoffDiff还引入了一个新的度量标准——Fréchet Wrenformer Distance，以捕获生成材料的对称性特征。最后，WyckoffDiff被用于评估和比较最近提出的晶体生成生成模型。作为概念验证研究，WyckoffDiff被用来发现新的亚热力学稳定性的晶体材料。
## Innovation
1. 提出WyckoffDiff，一种基于对称性的晶体生成模型，考虑了晶体结构中的对称性并设计了相应的神经网络架构来实现这一目标。2. 引入Fréchet Wrenformer Distance，评估生成的材料对称性，并提供了与新晶体生成模型的基准比较。3. 利用WyckoffDiff找到新的亚热力学稳定晶体材料作为概念验证研究。
## Conclusion
WyckoffDiff通过设计一种新的生成模型框架，实现了基于对称性的晶体结构生成。相比传统模型，WyckoffDiff在考虑对称性的同时，提高了生成速度。新的度量标准Fréchet Wrenformer Distance为评估生成材料的对称性提供了新的工具。实验结果表明，WyckoffDiff在发现新的亚热力学稳定晶体方面展现了其潜力。
# 156. `cs.AI` - FGS-SLAM: 基于傅里叶变换的高斯点图实时时序SLAM系统 [PDF](https://arxiv.org/pdf/2503.01109), [HTML](https://arxiv.org/abs/2503.01109)
## Authors
Yansong Xu,Junlin Li,Wei Zhang,Siyu Chen,Shengyong Zhang,Yuquan Leng,Weijia Zhou
## Background
3D高斯点图技术提升了实时定位与建图（SLAM）技术，使其能够实现实时定位和高保真地图的构建。然而，高斯位置不确定性和初始化参数的影响带来挑战，通常需要大量的迭代收敛，导致高斯表示冗余或不足。为了克服这些挑战，本文通过引入基于傅里叶频域分析的自适应密集化方法，为快速收敛建立高斯先验。此外，本文提出了构建独立且统一的稀疏和密集地图的方法，其中稀疏地图通过广义最近点迭代（GICP）支持高效追踪，而密集地图创建高保真视觉表示。这是首个利用频域分析实现实时高质高斯映射的SLAM系统。实验结果表明，该系统在Replica和TUM RGB-D数据集上实现了36 FPS的帧率，实现了在定位和建图方面的竞争力的准确性。
## Innovation
1. 引入基于傅里叶频域分析的自适应密集化方法，为快速收敛建立高斯先验。2. 构建独立且统一的稀疏和密集地图，稀疏地图通过GICP支持高效追踪，密集地图创建高保真视觉表示。3. 该系统是首个利用频域分析实现实时高质高斯映射的SLAM系统，实现了显著的性能提升。
## Conclusion
本文提出的FGS-SLAM系统显著提升了SLAM的实时性和准确性，展示了在Replica和TUM RGB-D数据集上的强大性能，为实时时序SLAM技术提供了新的解决方案。
# 157. `cs.AI` - 通过解耦表示实现的眼科疾病分级的鲁棒多模态学习 [PDF](https://arxiv.org/pdf/2503.05319), [HTML](https://arxiv.org/abs/2503.05319)
## Authors
Xinkun Wang,Yifang Wang,Senwei Liang,Feilong Tang,Chengzhi Liu,Ming Hu,Chao Hu,Junjun He,Zongyuan Ge,Imran Razzak
## Background
眼科医生通常依赖多种类型的数据来提高诊断准确性，但在实际应用中，完整的多模态数据很少见，原因包括医疗设备不足和数据隐私问题。传统的深度学习方法通常通过在潜在空间中学习表示来应对这些问题。然而，这些方法存在两个关键局限性：（i）复杂模态中的无关冗余信息（例如，大量切片）会在潜在空间表示中产生显著冗余；（ii）重叠的多模态表示使得提取各模态的独特特征变得困难。因此，本文讨论了这些挑战及其对多模态学习的影响，指出现有方法的不足之处及面临的实际问题。
## Innovation
本文提出了Essence-Point和解耦表示学习（EDRL）策略，该方法将自我蒸馏机制整合到端到端框架中，以增强特征选择和解耦，从而实现更稳健的多模态学习。具体来说，Essence-Point表示学习模块选择了能够改善疾病分期性能的判别特征。解耦表示学习模块将多模态数据分解为模态通用和模态独特表示，减少了特征缠绕，提升了眼科疾病诊断的稳健性和可解释性。
## Conclusion
实验结果显示，提出的EDRL策略显著优于当前最先进的方法，展示了在实际眼科多模态数据集上的有效性和优越性。
# 158. `cs.AI` - 从O(n^2)到O(n)参数：用于生物医学图像分类的量子自注意力在视觉Transformer中的应用 [PDF](https://arxiv.org/pdf/2503.07294), [HTML](https://arxiv.org/abs/2503.07294)
## Authors
Thomas Boucher,John Whittle,Evangelos B. Mazomenos
## Background
该研究背景在于现有的视觉Transformer (ViTs) 虽然在处理图像分类任务时表现优异，但它们的参数量巨大，这在生物医学图像分类等领域中限制了其广泛应用。文章旨在提出一种新的方案，即通过引入量子自注意力 (Quantum Self-Attention, QSA) 机制，使视觉Transformer模型在保持准确率的同时显著减少参数量，从而更适用于生物医学图像分类等需要高效计算的应用场景。
## Innovation
创新在于研究提出了一种新的视觉Transformer（QViT），将传统的自注意力机制用量子自注意力机制替换，从而极大地减少了模型参数量，同时仍然能够达到与现有最先进的方法相当的分类准确率。这种替换引入了参数化量子神经网络，并从理论上将参数量从O(n^2)降低至O(n)，尤其是在生物医学图像分类任务上表现更为出色，展示了其在保留性能同时大幅度提高参数效率的潜力。此外，研究还探索了从经典到量子视觉Transformer的知识蒸馏方法，并发现高qubit架构更受益于知识蒸馏预训练，这为未来的研究提供了新的视角和线索。
## Conclusion
研究结果表明，量子自注意力机制QSA在生物医学图像分类中展现出显著的参数效率优势，能够在保持高准确率的同时，大幅度减少模型参数和计算量。该研究不仅提供了一种新的模型架构设计思路，还为量子技术在机器学习领域的应用提供了可行性依据，有助于推动生物医学图像分析技术的发展更多样化。
# 159. `cs.AI` - 透过全球视角审视扩散模型：它们是否具备文化包容性？ [PDF](https://arxiv.org/pdf/2502.08914), [HTML](https://arxiv.org/abs/2502.08914)
## Authors
Zahra Bayramli,Ayhan Suleymanzade,Na Min An,Huzama Ahmad,Eunsu Kim,Junyeong Park,James Thorne,Alice Oh
## Background
文本到图像的扩散模型最近使得仅凭文本提示便可生成视觉上引人注目、细节丰富的图像成为可能，但它们能否准确地捕捉到各种文化细微差异一直是一个悬而未决的问题。本文基于此背景，提出了CultDiff基准，用于评估最先进的扩散模型是否可以生成涉及十个不同国家的具有文化特异性的图像，并通过细致分析不同相似度方面的表现，揭示了这些模型在文化相关性、描述准确性和真实性方面与实际参考图像存在显著差异，尤其是在表现欠代表国家的地域方面。通过对人类评价的收集，本文开发了一种基于神经网络的图像-图像相似度度量，即CultDiff-S，可以预测对文化和包含文化元素的实际图像和生成图像的人类判断。这项工作的研究背景是现有的扩散模型在文化表现上的不足，凸显了更加包容的生成AI系统和广泛文化代表性数据集的必要性。
## Innovation
引入CultDiff基准，以评估最先进的扩散模型是否能够生成跨越十个不同国家的文化特定图像；开发了一种基于神经网络的图像-图像相似度度量CultDiff-S，用于预测含有文化元素的实际图像和生成图像的人类判断；详细分析了不同相似度方面的表现，揭示了模型在文化相关性、描述准确性和真实性方面与实际参考图像之间的显著差异，特别是对欠代表国家的地域。
## Conclusion
研究表明现有的扩散模型在文化表现方面存在不足，提出需要更加包容的生成AI系统以及广泛的、文化多样性的数据集的必要性，从而提高了图像生成的多样性与文化代表性。
# 160. `cs.AI` - MaizeField3D：多样株系农田种植玉米的3D点云与过程模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
## Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
## Background
由于缺乏大型且多样化的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型工具，特别是针对玉米的研究，进展相对有限。2D图像数据集无法捕捉到3D数据所提供的关键结构细节，如叶片结构、植物体积和空间排列等。为解决这一问题，论文介绍了一个名为MaizeField3D的数据集，该数据集包含从多样遗传面板收集的农田种植玉米的3D点云数据，旨在为农业研究提供人工智能准备的数据。
## Innovation
MaizeField3D数据集包括1,045个高质量的农田种植玉米3D点云，使用地面激光扫描仪（TLS）收集。这些点云通过基于图的分割方法对520株植物进行分割和注释，以隔离叶片和茎部，确保所有样本的一致标注。此外，该数据集还用于拟合过程模型，为玉米植物提供结构化的参数表示。叶片由非统一合理B样条（NURBS）表面表示，使用两步优化过程生成，结合了无导数和基于导数的方法。数据集还包含详细的植物形态和质量元数据，以及不同分辨率的子采样点云数据（100k、50k、10k点），方便用于不同的计算任务下游。
## Conclusion
MaizeField3D数据集将作为AI驱动表型分析、植物结构分析和农业研究中3D应用的基础数据集。
# 161. `cs.AI` - AIDRIN 2.0: 一个评估AI数据准备性的框架 [PDF](https://arxiv.org/pdf/2505.18213), [HTML](https://arxiv.org/abs/2505.18213)
## Authors
Kaveen Hiniduma,Dylan Ryan,Suren Byna,Jean Luca Bez,Ravi Madduri
## Background
AIDRIN是一个评估和提升AI应用所需数据准备性的框架，涵盖了数据质量、偏见、公平性和隐私等关键维度。本文对AIDRIN进行了增强，集中在用户界面的改进以及与隐私保留分布式学习（PPFL）框架的集成上。通过优化用户界面并使其与去中心化AI管道无缝集成，AIDRIN变得更加易于使用，适合不同技术水平的用户。与现有的PPFL框架集成确保了数据准备性和隐私在分布式学习环境中得到优先考虑。通过实际数据集的研究案例展示了AIDRIN在识别影响AI模型性能的数据准备性问题方面的实用价值。
## Innovation
本文对AIDRIN进行了改进，重点是用户界面的优化以及与隐私保留分布式学习（PPFL）框架的集成，使得AIDRIN变得更加易于使用和实用。
## Conclusion
通过与现有的PPFL框架集成，AIDRIN在评估和提升AI数据准备性方面起到了关键作用，尤其在分布式学习环境中。实际数据集的研究案例进一步证明了AIDRIN的实用价值，尤其是在识别影响AI模型性能的关键数据准备性问题方面。
# 162. `cs.AI` - LLM位置泛化的计算机制 [PDF](https://arxiv.org/pdf/2503.13305), [HTML](https://arxiv.org/abs/2503.13305)
## Authors
Chi Han,Heng Ji
## Background
大多数书面自然语言由单词和句子的序列组成。类似人类，大规模语言模型（LLMs）在处理文本位置时表现出灵活性——我们称之为位置泛化现象。它们能够理解文本中的位置偏差，并且能够泛化到比训练过程中遇到的更长的文本。这些现象表明，LLMs能够容忍位置的变化，但它们如何计算位置相关性仍然是一个未解之谜。本研究将语言学现象与LLMs的计算机制连接起来。通过这种方法，本研究展示了LLMs如何强制执行某些计算机制来实现对位置偏差的容忍性。尽管自注意力机制的设计非常复杂，但研究揭示了LLMs学习了一个反直觉的注意力得分分解。它们的值与位置相关性和语义重要性的近似算术和显示出0.959的线性相关性。此外，研究还识别出一种在中间特征中普遍存在且理论上证明能够实现这一效果的模式。与随机初始化参数的行为不同，该模式表明这是一种学习到的行为，而不是模型架构自然而产生的结果。
## Innovation
揭示了大规模语言模型（LLMs）在计算过程中如何实现对位置偏差的容忍性。研究发现，尽管自注意力机制的设计非常复杂，但LLMs其实是在学习一种反直觉的注意力得分分解。这种方法揭示了LLMs处理位置相关性的机制，具体来说，它们的值与位置相关性和语义重要性的近似算术和显示出高度相关性，并且研究还识别出了理论上的中间特征模式，这表明这种学习行为不是模型架构自然产生的结果而是学习到的行为。研究提供了对大规模语言模型位置灵活性的计算解释和标准，从而在将位置泛化与现代大规模语言模型内部机制联系起来方面迈出了一步
## Conclusion
研究提供了对大规模语言模型位置灵活性的计算解释和标准，并在将位置泛化与现代大规模语言模型内部机制联系起来方面迈出了一步。
# 163. `cs.AI` - 教师运动先验：提高 humanoid 机器人在挑战地形上的步行能力 [PDF](https://arxiv.org/pdf/2504.10390), [HTML](https://arxiv.org/abs/2504.10390)
## Authors
Fangcheng Jin,Yuqi Wang,Peixin Ma,Guodong Yang,Pan Zhao,En Li,Zhengtao Zhang
## Background
在复杂地形上实现稳健的行动仍然具有挑战性，主要由于高维控制和环境不确定性。传统方法通常依赖于基于编码器的状态嵌入，这使得网络设计复杂且部署困难。
## Innovation
提出了一种基于教师学生范式的教师先验框架，通过模仿学习和辅助任务学习集成策略，提高学习效率和泛化能力。该框架解耦网络设计，简化了策略网络和部署过程。
## Conclusion
该框架在 humanoid 机器人上得到了验证，显示了在动态地形上行动稳定性的显著提高，并大幅降低了开发成本。这项工作提供了一种实用的解决方案，用于在 humanoid 机器人中部署稳健的行动策略。
# 164. `cs.AI` - 使用深度上下文蒸馏训练即插即用知识模块 [PDF](https://arxiv.org/pdf/2503.08727), [HTML](https://arxiv.org/abs/2503.08727)
## Authors
Lucas Caccia,Alan Ansell,Edoardo Ponti,Ivan Vulić,Alessandro Sordoni
## Background
在大规模语言模型预训练后动态集成新信息或快速进化的信息仍然具有挑战性，尤其是在低数据场景或处理私有和专项文档时。上下文学习和检索增强生成（RAG）方法存在高推理成本和无法捕获文档全局信息的局限性。现有的方法需要改进以解决这些问题，以提高在这些场景下的表现。
## Innovation
该论文提出了通过训练文档级知识模块（KMs）来模块化知识的方法。KMs 被设计为轻量级组件，并以参数高效的方式实现 LoRA 模块，旨在存储新文档的信息，并可以在需要时轻松接入模型。为此，该研究使用了深度上下文蒸馏的方法来训练KMs参数，使其能够模拟在文档上下文中的教师模型的隐藏状态和输出。实验结果表明，该方法在两个数据集上的表现优于标准的方法和预指令训练技术。
## Conclusion
最后，研究强调了知识模块与RAG之间的协同作用，并展示了通过训练文档级知识模块解决大规模语言模型在低数据场景下问题的有效性。
# 165. `cs.AI` - CogniBench: 一个借鉴法律领域框架和数据集，用于评估大型语言模型认知忠实度 [PDF](https://arxiv.org/pdf/2505.20767), [HTML](https://arxiv.org/abs/2505.20767)
## Authors
Xiaqiang Tang,Jian Li,Keyu Hu,Du Nan,Xiaolong Li,Xi Zhang,Weigao Sun,Sihong Xie
## Background
现有基准主要评估大型语言模型（LLM）生成的‘事实陈述’，这些陈述仅重述原始材料，并未关注涉及从给定上下文中进行推理的‘认知陈述’，导致对认知陈述错误的评估和检测具有挑战性。现有基准缺乏评估标准，过分关注事实声明而忽略了认知声明，这使得评估和检测认知声明的忠实性变得困难。因此，需要一个新的评估框架和数据集来解决这个问题，特别是需要评估不同层次的认知声明的忠实性，并且适用于各个模型的自动注释流程是必要的，以跟上LLM快速发展的步伐。
## Innovation
该研究提出了一个借鉴法律领域评估框架的CogniBench数据集并揭示了有关统计信息，同时开发了一种可扩展的自动注释管道，能够适应不同模型，从而生成大规模的CogniBench-L数据集。这种方法有助于训练能够准确检测事实和认知幻觉的检测器。
## Conclusion
CogniBench通过设计一个严格的评估框架和开发一个大规模的数据集，解决了现有评估标准的不足，并为评估LLM的认知忠实性提供了一个新工具，同时开发的自动注释管道实现了不同模型的广泛适用性，为快速发展的LLM提供了持续支持。
# 166. `cs.AI` - TSPulse：双空间超紧凑预训练模型以实现快速时间序列分析 [PDF](https://arxiv.org/pdf/2505.13033), [HTML](https://arxiv.org/abs/2505.13033)
## Authors
Vijay Ekambaram,Subodh Kumar,Arindam Jati,Sumanta Mukherjee,Tomoya Sakai,Pankaj Dayama,Wesley M. Gifford,Jayant Kalagnanam
## Background
时间序列预训练模型的兴起推动了时间序列表示学习的进步，但是当前最先进的模型往往规模庞大，需要大量计算资源。现有模型的复杂性和计算需求限制了它们在实际应用中的普及与使用效率。
## Innovation
TSPulse引入了架构和任务层面的创新。在架构层面，它采用双空间掩蔽重构，同时学习时间和频域信号，以捕捉互补信号。此外，TSPulse还使用双嵌入分解生成详细的嵌入和高层次语义嵌入，增强细粒度分析和更广泛任务理解。值得注意的是，TSPulse的语义嵌入具有对时间、幅度和噪声变化的鲁棒性，这对于稳健检索尤为重要。在任务层面，TSPulse整合了TSLens细调组件，实现了任务特定的特征注意功能。另外，TSPulse引入了多头三角化技术，通过融合多个预测头之间的偏差以增强异常检测。此外，还提出了一种混合掩蔽预训练方法，以改进零样本填充，减少预训练偏见。
## Conclusion
这些架构和任务创新为TSPulse带来了显著的性能提升：在UEA分类基准测试中达到5-16%的增益，在TSB-AD异常检测领头马表上增加了20%，在零样本填充上提高了50%，在时间序列检索上提高了25%。此外，TSPulse仅使用100万参数（比现有SOTA模型小10-100倍），并实现了无GPU推理，成为高效时间序列预训练模型的新标准。
# 167. `cs.AI` - Aurora: Android恶意软件分类器在分布转移下的可靠性和稳定性 [PDF](https://arxiv.org/pdf/2505.22843), [HTML](https://arxiv.org/abs/2505.22843)
## Authors
Alexander Herzog,Aliai Eusebi,Lorenzo Cavallaro
## Background
现代漂移适应型恶意软件分类器在性能上表现出色，但这种表现是否能在实际操作中转化为稳定的可靠性？现有的标准评估框架主要关注基本的性能指标，而忽略了置信度误差的一致性和操作稳定性。尽管TESSERACT强调了时间评估的重要性，我们从一个互补的角度出发，探究了在分布变化下，恶意软件分类器是否能保持可靠和稳定的置信度估计，并在科学进步和实际影响之间研究了一种紧张关系。我们的重点是评估基于置信度质量和操作韧性的恶意软件分类器的评估框架AURORA。
## Innovation
我们提出了AURORA框架来评估恶意软件分类器，该框架通过验证特定模型的置信度图谱来评估其置信估计的可靠性。AURORA旨在超出单一时间点的性能评估，推动一种更全面的评估方法，特别是在时间评估期内的运营稳定性评估。鉴于流行的技术框架在不同漂移数据集上的脆弱性，建议回到基础研究阶段，确保评估方法的可靠性与稳定性，并关注实际影响而非仅仅科学进展。
## Conclusion
AURORA通过对给定模型的置信度轮廓进行验证，评估了其置信度估计的可靠性。不合格的置信估计会削弱操作信任、浪费有价值的手动标注预算在非信息性的样本上，并会在选择性分类中漏检潜在的错误样本。AURORA的指标设计旨在超越单一时间点的性能评估，追求一种更全面的、跨时间评估期的运营稳定性评估方法。目前流行的框架在不同漂移数据集上的脆弱性强调了返回基础研究阶段的必要性，以确保评估方法的可靠性与稳定性，并关注其实用影响。
# 168. `cs.AI` - WoundAmbit: 接近最先进技术的语义分割与实际伤口护理桥梁 [PDF](https://arxiv.org/pdf/2504.06185), [HTML](https://arxiv.org/abs/2504.06185)
## Authors
Vanessa Borst,Timo Dittus,Tassilo Dege,Astrid Schmieder,Samuel Kounev
## Background
慢性伤口影响着大量的老年患者和糖尿病患者，尤其是那些行动不便且伴随其他健康状况的患者。通过移动设备拍摄伤口以实现远程监控，可以减少现场医生访问的频率。然而，伤口分割在医学影像研究中仍然不足。为了应对这一挑战，本文比较了通用视觉、医学影像和公开伤口挑战中的最佳深度学习模型，通过标准化训练、数据增强和评估，进行了交叉验证以最小化分割偏差。同时，还评估了实际部署时的几个方面，包括模型在不同数据集上的泛化能力、计算效率和可解释性。此外，还提出了基于参考物体的方法来将AI生成的掩码转换为临床相关伤口大小估计，并对五个最佳模型基于医生评估的质量和掩码进行了评估。总体而言，基于变压器的TransNeXt模型在泛化能力上表现最佳。尽管推理时间有所不同，但所有模型都能每秒处理至少一张图像，这对于实际应用来说是足够的。解释性分析通常显示激活区域集中在伤口区域，强调了对临床相关特征的关注。专家评估显示，所有分析模型的掩码批准率都很高，其中VWFormer和ConvNeXtS表现最佳。模型在体积提取准确性方面表现相似，预测值与专家注释非常接近。最后，我们展示了通过使用WoundAmbit框架结合定制的远程医疗系统实现AI驱动的伤口大小估计的过程。
## Innovation
论文比较了不同领域的最先进深度学习模型，并提出了将AI生成的掩码转换为临床相关伤口大小估计的新的参考物体方法。该研究涵盖了从方法比较、评估到实际应用的多个方面，并通过标准化手段提高了模型的可解释性和泛化能力。此外，WoundAmbit框架被集成到定制的远程医疗系统中，实现了AI驱动的伤口大小估计的应用。
## Conclusion
基于Transformer的TransNeXt模型因其优秀的泛化能力而脱颖而出。所有模型的计算效率足够支持实际应用，且解释性分析显示模型关注了临床相关的特征。在医生评估中，VWFormer和ConvNeXtS表现最佳，模型预测与专家标注高度一致。最终，WoundAmbit框架被成功集成到一个定制的远程医疗系统中，展现了其在实际伤口护理中的应用潜力。
# 169. `cs.AI` - Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning [PDF](https://arxiv.org/pdf/2506.07744), [HTML](https://arxiv.org/abs/2506.07744)
## Authors
Seungho Baek,Taegeon Park,Jongchan Park,Seungjun Oh,Yusung Kim
## Background
现有的离线层次化强化学习方法依赖于高级策略来生成子目标序列。然而，这些方法的效率随着任务时长的增加而下降，并且缺乏有效策略来连接不同轨迹中的有用状态转换。这些方法通常需要学习一个显式的高级策略来制定子目标序列，导致在任务时长增加的情况下效率下降，并且难以在不同轨迹之间有效地拼接有用的状态转换。
## Innovation
我们提出了Graph-Assisted Stitching（GAS），这是一种新型框架，将子目标选择问题形式化为一个图搜索问题，而不是学习一个显式的高级策略。通过将状态嵌入到时距表示（TDR）空间中，GAS能够将来自不同轨迹的语义相似状态聚类为统一的图节点，从而实现高效的转换拼接。GAS通过引入临时效率（TE）度量来提高图的质量，从而过滤掉无用或低效的转换状态，显著提升任务性能。实验结果表明，GAS在各种运动、导航和操作任务中优于先前的离线HRL方法。特别是在拼接至关重要的任务上，它取得了88.3的分数，远远超过之前的最佳分数1.0。
## Conclusion
GAS通过将子目标选择问题形式化为图搜索问题，提高了离线HRL方法的效率和性能。通过引入临时效率度量过滤无用或低效的转换状态，GAS在多个任务中显著提升了任务性能，特别是在拼接任务上表现尤为突出。
# 170. `cs.AI` - 量子比特到企业应用的监督量子机器学习未来发展展望 [PDF](https://arxiv.org/pdf/2505.24765), [HTML](https://arxiv.org/abs/2505.24765)
## Authors
Srikanth Thudumu,Jason Fisher,Hung Du
## Background
监督量子机器学习代表了量子计算与经典机器学习的交叉领域，旨在利用量子资源支持模型训练和推理。该文回顾了监督量子机器学习领域的最新进展，重点关注变量子电路、量子神经网络和量子核方法等方法，以及量子和经典计算混合的工作流。文中还探讨了近来实验研究中显示出的部分量子优势迹象，以及包括噪声、荒原 plateau 、扩展性问题和对经典方法性能改进没有正式证明等当前限制。
## Innovation
文中概述了未来十年监督量子机器学习的发展前景，提供了一个路线图来预测和指导哪种情况下量子机器学习能在未来十年内的实际研究和企业系统中得到应用。
## Conclusion
当前监督量子机器学习存在一些局限性，如噪声、荒原 plateau 、扩展性问题和对经典方法性能改进没有正式证明等，但未来十年可能在企业应用中发挥更大作用。
# 171. `cs.AI` - 回收网络：一种增强语言模型预训练数据质量和数量的方法 [PDF](https://arxiv.org/pdf/2506.04689), [HTML](https://arxiv.org/abs/2506.04689)
## Authors
Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li
## Background
大型语言模型的性能随着模型规模和数据规模的增加而提升。实践中，预训练依赖大规模网络抓取，几乎使用了至今互联网上所有公开的数据源，但这一自然数据池的增长速度并未与计算能力供给同步。此外，高质量文本数据的获取更为有限：数据过滤流程会去除初始网页抓取中高达99%的数据。为应对预训练规模中的“数据墙”，作者提出了回收低质量文档的方法，通过指导重写提高低质量文档的质量，使其可用于训练。该方法增加了合成数据在最终预训练集中的占比并展示出显著的性能提升。研究表明，混合高质量原始文本与重新写过的文本，在22种不同任务上的表现分别提升了1.0、1.3和2.5个百分点，且比只有过滤后的网络数据训练更有效。进一步分析表明，混合文本中有82%来自本会放弃的低质量文档，并且这种方法优于其他生成合成数据的方案。
## Innovation
提出的REWIRE方法，一种通过指导重写低质量文档来提升其质量的方法。这种方法允许增加合成数据在预训练数据集中的代表性和占比，而不需要更多的高质量原始数据。实验结果显示，这种混合方法在多种任务上表现更优，且比仅仅使用过滤后的网络数据训练更有效。同时，该方法优于其他合成数据生成的方法：维基百科风格的重写、问答合成和知识抽取等方法。
## Conclusion
通过REWIRE方法，可以有效提高预训练数据的质量和数量，这表明回收网络文本可能是一个简单有效的方法，解决了预训练数据规模的难题。
# 172. `cs.AI` - SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities [PDF](https://arxiv.org/pdf/2506.06406), [HTML](https://arxiv.org/abs/2506.06406)
## Authors
Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Wei Chen,Fangxiang Feng,Xiaojie Wang
## Background
Mixture of Experts (MoE)架构在扩展大型语言模型方面已成为关键方法，且对扩展到多模态任务表现出浓厚兴趣。现有方法构建多模态MoE模型要么导致高昂的训练成本，要么在适应预训练模型时降低了语言能力。研究者发现这些方法存在的问题后，提出了新的解决方案，即Soft Modality-Aware Routing (SMAR)，通过Kullback Leibler散度正则化技术控制不同模态之间的路由概率分布，以促进专家的专业化分工，同时不修改模型架构并减少对文本数据的依赖
## Innovation
提出了SMAR，一种新颖的正则化技术，采用Kullback Leibler散度控制不同模态之间的路由概率分布，鼓励专家专业化分工，而不修改模型架构或严重依赖文本数据。此方法在不修改模型结构和减少对文本数据依赖的情况下，保留了语言能力，且在多模态任务中表现出更优的性能
## Conclusion
SMAR在视觉指令调整实验中，仅使用2.5%的纯文本，就能将语言能力保持在86.6%以上，与其基线相比，既提高了多模态性能，又保持了语言能力。此方法提供了一种平衡多模态差异和语言能力的实际有效解决方案
# 173. `cs.AI` - C3S3: 补偿竞争和对比选择在半监督医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2506.07368), [HTML](https://arxiv.org/abs/2506.07368)
## Authors
Jiaying He,Yitong Lin,Jiahe Chen,Honghui Xu,Jianwei Zheng
## Background
在医学领域中，由于样本标注不足，现有的半监督医学图像分割（SSMIS）技术在勾勒主要目标区域方面取得了显著成果，但仍难以精确捕捉边界细节，这导致了显著的诊断不准确。因此，需要一种新的半监督分割模型来解决这一问题，以提高边界界定的精确度和整体精度。
## Innovation
本文提出了C3S3模型，这是一种新颖的半监督分割模型，通过集成补偿竞争和对比选择机制来显著提高边界界定能力。具体创新包括：1) 开发了一种目标驱动的对比学习模块，用于细化边界定位；2) 引入了一种动态补偿竞争模块，利用两个高性能的子网络生成伪标签，进一步提高分割质量。
## Conclusion
C3S3模型在两个公开数据集（包括MRI和CT扫描）上进行了严格的验证，结果显示其在多种性能指标上超过了当前最先进的方案，尤其是在95HD和ASD指标上提高了至少6%，证明了该方法的显著进步。
# 174. `cs.AI` - 屏幕劫持：移动环境下基于视觉语言模型的代理视觉中毒 [PDF](https://arxiv.org/pdf/2506.13205), [HTML](https://arxiv.org/abs/2506.13205)
## Authors
Xuan Wang,Siyuan Liang,Zhe Liu,Yi Yu,Yuliang Lu,Xiaochun Cao,Ee-Chien Chang,Xitong Gao
## Background
随着视觉语言模型（VLMs）的集成度越来越高，移动代理越来越多地用于用户界面自动化和相机辅助等任务。然而，这些代理通常是在有限的用户生成的数据集上进行微调，从而在训练过程中容易受到隐蔽威胁的影响。本文介绍了GHOST，这是首个专为基于VLM的移动代理设计的无标签后门攻击方法。该方法只对一部分训练样本的视觉输入进行操纵——不改变其对应标签或指令——从而将恶意行为注入模型中。该方法的核心在于通过调整中毒样本的梯度，使它们与选定目标样本的梯度对齐，将后门相关的特征嵌入到中毒的训练数据中，以实现攻击的效果。此外，开发了三种现实的视觉触发器：静态视觉补丁、动态运动提示和低透明度的叠加覆盖，以维持隐蔽性和增强鲁棒性。该方法在六款真实世界的Android应用程序和三种适配移动使用的VLM架构上进行了评估，结果显示，攻击成功率达到94.67％，同时保持了高清洁任务性能（FSR达到95.85％）。
## Innovation
GHOST是首个专为基于VLM的移动代理设计的无标签后门攻击。该方法仅通过对部分训练样本的视觉输入进行操纵而不改变其对应标签或指令，从而将恶意行为注入模型中。该方法的核心在于通过调整中毒样本的梯度，使其与选定的目标样本对齐，将后门相关的特征嵌入中毒的训练数据中。此外，该研究开发了三种现实的视觉触发器，分别是静态视觉补丁、动态运动提示和低透明度的叠加覆盖，以保持隐蔽性和增强鲁棒性。
## Conclusion
本文是首个揭示基于视觉语言模型的移动代理存在的重要安全漏洞的研究，强调了它们容易受到无标签后门攻击的影响，并指出了训练管道中迫切需要有效的防御机制。
# 175. `cs.AI` - IKDiffuser: 使用扩散模型为多臂机器人生成逆向动力学求解器 [PDF](https://arxiv.org/pdf/2506.13087), [HTML](https://arxiv.org/abs/2506.13087)
## Authors
Zeyu Zhang,Ziyuan Jiao
## Background
解决逆向动力学（IK）问题对机器人技术至关重要，但在多臂机器人系统中依然是一个挑战。多臂机器人系统的逆向动力学因为复杂的自我碰撞、耦合关节以及高维冗余性而变得复杂，这使得传统的逆向动力学求解器往往速度较慢、容易失败且解集单一。
## Innovation
本文提出了IKDiffuser，一种基于扩散模型的多臂机器人逆向动力学快速生成多元解方案。IKDiffuser通过学习配置空间中关节的概率分布，并捕捉其中的复杂依赖关系，能够在不同结构的多臂机器人系统中无缝泛化。此外，IKDiffuser在推理时可以方便地吸纳更多目标，而无需重新训练，提高了任务的定制化和适应性。通过在6种不同多臂系统的实验中与现有求解器的对比，提出的IKDiffuser展示了优越的解集准确度、精度、多样性和计算效率。
## Conclusion
提出的IKDiffuser框架为多臂机器人的逆向动力学问题提供了一种可扩展且统一的解决方案，促进了多臂机器人系统在实时操作任务中的应用潜力。
# 176. `cs.AI` - CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation [PDF](https://arxiv.org/pdf/2506.15549), [HTML](https://arxiv.org/abs/2506.15549)
## Authors
Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen Chen
## Background
深度学习方法在晚钆增强（LGE）心脏MRI图像中的心肌疤痕分割展现了对结构性心脏疾病的准确诊断和治疗规划的巨大潜力。然而，高质量心肌疤痕标签数量有限且变异性高，限制了稳健分割模型的发展。
## Innovation
介绍了CLAIM框架，一种临床引导的心脏逆行增强图像增强的框架，用于实现解剖学基础的心肌疤痕生成和分割。核心是SMILE模块（基于临床知识的心肌疤痕掩膜生成），使扩散生成器基于采用的AHA 17段模型来合成具有解剖学一致性和空间多样性的疤痕模式。此外，CLAIM使用联合训练策略，在优化心脏疤痕分割网络的同时优化生成器，旨在提高合成疤痕的逼真度和疤痕分割性能的准确性。实验结果显示，CLAIM生成具有解剖学一致性的心肌疤痕图案，与基线模型相比，与实际疤痕分布的Dice相似度更高。我们的方法能够实现可控且真实的肌心肌疤痕合成，并已在下游医学成像任务中显示出效用。
## Conclusion
CLAIM框架能够生成解剖学一致的心肌疤痕图案，实现真实的和多样化的肥厚心肌疤痕合成，并在真实疤痕分布中显示出更高的Dice相似度，对于下游医学成像任务有很大的实用价值。
# 177. `cs.AI` - 通过注意力头部选择实现细粒度扰动指导 [PDF](https://arxiv.org/pdf/2506.10978), [HTML](https://arxiv.org/abs/2506.10978)
## Authors
Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim
## Background
在扩散模型中，近期的指导方法通过扰动模型来反向采样，构建一个隐式的弱模型，进而引导生成远离它。在这些方法中，注意力扰动在没有分类器自由指导的情景下表现出了很好的效果。但现有方法缺乏对于扰动应如何应用的原理性方法，尤其是在扩散变换器(DiT)架构中，质量相关的计算分布在多个层中，因此没有明确指导注意力扰动的具体位置。本文从层级别到单个注意力头级别研究注意力扰动的详细程度，并发现特定头能控制不同的视觉概念，如结构、风格和纹理质量。基于此洞察，我们提出了“HeadHunter”，一种系统性框架，用于迭代选择与用户中心目标相匹配的注意头，实现对生成质量和视觉属性的细粒度控制。此外，我们引入了SoftPAG，通过线性插值每个选定头的注意力图向单位矩阵接近，提供一种连续旋钮来调整扰动强度并抑制伪影。这种方法不仅解决了现有层级别扰动的过度平滑问题，还通过组合性头选择实现了特定视觉风格的精确操纵。我们对现代大规模的基于DiT的文本到图像模型，包括Stable Diffusion 3和FLUX.1进行验证，显示在一般质量和风格特异性指导上的优越性能。我们的工作提供了在扩散模型中首次进行头部级别的注意力扰动分析，揭示了注意力层内可解释的专业化，并使有效扰动策略的实际设计成为可能。
## Innovation
提出了HeadHunter框架，用于系统性地选择与用户中心目标相匹配的注意头，实现了对生成质量和视觉属性的细粒度控制。此外，引入了SoftPAG，通过线性插值每个选定头的注意力图向单位矩阵接近，提供了一种可连续调整的旋钮来抑制伪影。这种方法不仅改善了现有层级别扰动的过度平滑问题，还能够通过组合性头选择实现特定视觉风格的精确操纵。我们的方法在现代大型DiT基文本到图像模型上进行了验证，展示了在一般生成质量和风格指导能力上的优越性能。
## Conclusion
我们提供了在扩散模型中首次在头部层次上进行注意力扰动分析，揭示了注意力层内可解释的专业化，并使有效扰动策略的实际设计成为可能。这种方法不仅在提高生成质量方面表现出色，还能实现对特定视觉风格的影响。通过HeadHunter和SoftPAG，我们实现了更细粒度的控制，以满足用户特定的生成目标。
# 178. `cs.AI` - VRAIL: Vectorized Reward-based Attribution for Interpretable Learning [PDF](https://arxiv.org/pdf/2506.16014), [HTML](https://arxiv.org/abs/2506.16014)
## Authors
Jina Kim,Youjin Jang,Jeongjin Han
## Background
该研究提出了一种基于价值的强化学习（RL）框架——VRAIL（向量化奖励归因以实现可解释学习），该框架能够从状态特征中学习可解释的权重表示。这改进了传统方法在模型能力和解释性上的不足，尤其是在强化学习中的应用。研究表明，VRAIL能够在不修改环境的情况下，相比于标准的DQN方法提高了训练稳定性和收敛性。进一步的分析揭示了VRAIL能够发现具有语义意义的子目标，增强了其生成可解释行为的能力。因此，VRAIL为强化学习中的奖励塑造提供了一种通用且模型无关的框架，提升了学习效果和解释性。
## Innovation
VRAIL通过引入向量化奖励归因机制，结合深度学习和强化学习，提出了一种新的多层次架构，能够在保持模型稳定性和收敛性的前提下，赋予每个状态特征及其相互作用以解释能力。相较于传统的DQN方法，VRAIL能够在不修改环境的情况下，更好地捕捉到环境中的语义目标，增强模型的泛化能力和可解释性。此外，VRAIL还提供了一种线性和二次形式的估计器模型，进一步增强了其适用范围和解释力。
## Conclusion
研究结果表明，VRAIL作为一种通用、模型无关的框架，不仅在训练稳定性和收敛性方面优于标准的DQN方法，还能够发现和展示具有语义意义的子目标，增强了学习结果的可解释性。VRAIL的提出为强化学习领域的未来研究提供了新的思路和发展方向。
# 179. `cs.AI` - TabArena：表格数据机器学习的动态基准 [PDF](https://arxiv.org/pdf/2506.16791), [HTML](https://arxiv.org/abs/2506.16791)
## Authors
Nick Erickson,Lennart Purucker,Andrej Tschalzev,David Holzmüller,Prateek Mutalik Desai,David Salinas,Frank Hutter
## Background
随着深度学习和基础模型在表格数据中的广泛使用，标准化和可靠的基准测试变得越来越重要。然而，目前的基准测试系统是静态的，即使发现缺陷、模型版本更新或新模型发布，其设计也不会进行更新。因此，需要一个持续维护的动态基准测试系统来解决这一问题，以提供更加及时和全面的评估。
## Innovation
作者引入了TabArena，这是第一个持续维护的动态表格基准测试系统。为了启动TabArena，作者手动整理了一组代表性数据集和实施良好的模型，进行了大规模的基准测试研究，建立了公开的排行榜，并组建了一支经验丰富的维护者团队。结果强调了验证方法和超参数配置组合在基准测试中的重要性。同时，作者观察到在更大的时间预算和组合下，深度学习方法在实际的表格数据集上已经赶上甚至超过了梯度提升树。此外，基础模型在较小的数据集上表现出色。
## Conclusion
TabArena展示了模型集合在表格机器学习中的最新进展，并进一步研究了各个模型的贡献。作者以公开的排行榜、可复现的代码和维护协议启动了TabArena，为用户提供了一个持续更新的基准测试平台，网址为this https URL.
# 180. `cs.AI` - MS-TVNet：基于多尺度动态卷积的长期时间序列预测方法 [PDF](https://arxiv.org/pdf/2506.17253), [HTML](https://arxiv.org/abs/2506.17253)
## Authors
Chenghan Li,Mingchen Li,Yipu Liao,Ruisheng Diao
## Background
长期时间序列预测主要依赖于Transformer和MLP模型，而卷积网络在这方面的潜力尚未得到充分开发和利用。
## Innovation
引入了一种新的多尺度时间序列重塑模块，有效捕捉多时期片段之间的关系和变量依赖性；基于此模块，提出了MS-TVNet，一种多尺度3D动态卷积神经网络。
## Conclusion
通过在多种数据集上的全面评估，MS-TVNet在长期时间序列预测中展示了优于基线模型的性能，达到了当前最佳水平。研究结果突显了使用卷积网络捕捉复杂时序模式的有效性，并为未来的研究提供了令人鼓舞的方向。
# 181. `cs.AI` - PP-DocBee2：通过高效数据改进的多模态文档理解基准 [PDF](https://arxiv.org/pdf/2506.18023), [HTML](https://arxiv.org/abs/2506.18023)
## Authors
Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu
## Background
PP-DocBee2 是基于 PP-DocBee 的先进版本，旨在增强多模态文档理解能力。该模型基于大型多模态模型架构，通过技术改进增强了合成数据质量，改进了视觉特征融合策略，并优化了推理方法。这些改进使模型在中文商业文档上的内部分数提升了 11.4%，同时将推理延迟减少了 73.0%。
## Innovation
该研究的主要创新在于多模态文档任务中数据质量优化策略。通过使用大规模多模态预训练模型评估数据，并应用新颖的统计标准筛选异常值，确保高质量的训练数据。此外，通过分解 ViT 层次结构并应用新颖的特征融合策略，增强了 ViT 的表示能力，以提升复杂的推理能力。
## Conclusion
PP-DocBee2 模型通过以上改进，在多模态文档理解上取得了显著性能提升，并且减少了推理延迟。源代码和预训练模型已在指定的网址提供。
# 182. `cs.AI` - 使用KnoVo映射研究贡献的演变 [PDF](https://arxiv.org/pdf/2506.17508), [HTML](https://arxiv.org/abs/2506.17508)
## Authors
Sajratul Y. Rubaiat,Syed N. Sakib,Hasan M. Jamil
## Background
传统的引文分析主要衡量论文的影响程度，但无法准确量化其新颖性和创新性。KnoVo框架旨在解决这一问题，通过利用多层次引文网络，不仅评估目标论文与前作和后作的相对新颖性，还通过大型语言模型动态提取比较维度，从而提供更准确的研究新颖性评分。
## Innovation
KnoVo框架创新之处在于使用了大型语言模型（LLMs）来动态提取可以与目标论文进行比较的因素（如方法、应用、数据集），并通过类似的锦标赛选择方法进行定量分析，生成反映目标论文在特定方面相对改进、等同或劣于其他论文的分数。这些分数的汇集和可视化，例如动态进化图和比较雷达图，帮助研究人员不仅评估原创性，识别类似工作，而且跟踪特定研究维度的知识演变，发现研究空白，并探索跨学科连接。
## Conclusion
通过对多个科学领域的20篇论文进行详细分析，展示了KnoVo框架的能力，并评估了各种开源LLM在该框架中的性能。KnoVo提供了更精细的研究贡献演变分析工具，助力科学研究和知识传承。
# 183. `cs.AI` - 量子-经典混合量化神经网络 [PDF](https://arxiv.org/pdf/2506.18240), [HTML](https://arxiv.org/abs/2506.18240)
## Authors
Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen
## Background
传统神经网络在使用量化激活和损失函数时存在限制，特别是在多层复杂结构中非线性问题的处理上。为解决这一问题，论文提出了通过样条插值使用任意激活和损失函数的新型二次二元优化（Quadratic Binary Optimization, QBO）模型，并引入了前向区间传播（Forward Interval Propagation, FIP）方法来优化这些复杂非线性函数，同时保持神经网络的通用逼近能力。通过理论分析，论文提供了误差上界和Ising自旋数目的上界，证明了解决相关问题的挑战。
## Innovation
提出了集成样条插值的QBO模型，以支持任意激活和损失函数；引入了FIP方法，通过线性化激活函数来简化网络的非线性复杂性，同时利用量子计算直接解决约束二次二元优化（Quadratic Constrained Binary Optimization, QCBO）问题，提高了问题的可解决性。
## Conclusion
通过与CIM的实验验证，该模型在时尚MNIST分类任务上达到了94.95%的高精度，仅需要1.1位精度。该研究工作显著扩展了量子计算在人工智能中的应用范围。
# 184. `cs.AI` - 不免费的午餐：重思大语言模型推理中的内部反馈 [PDF](https://arxiv.org/pdf/2506.17219), [HTML](https://arxiv.org/abs/2506.17219)
## Authors
Yanzhi Zhang,Zhaoxi Zhang,Haoxiang Guan,Yilin Cheng,Yitong Duan,Chen Wang,Yue Wang,Shuxin Zheng,Jiyan He
## Background
强化学习作为一种提高大语言模型（LLMs）推理能力的强大范式已经出现，但现有的方法如基于人类反馈的强化学习（RLHF）和可验证奖励的强化学习（RLVR）需要大量的外部监督。研究提出了一种新的方法：基于内部反馈的强化学习（RLIF），这种方法仅依赖于模型自身产生的信号，而不依赖于外部奖励。研究者利用未监督的奖励代理，如标记级别熵、轨迹级别熵和自我确信度来评估不同RLIF策略在复杂数学推理基准测试上的效果。实验表明，在训练的初期阶段，RLIF可以增强基础LLMs的推理性能，甚至在某些情况下超过了RLVR技术。然而，随着训练的进行，性能会下降甚至低于未经训练的模型。此外，对于已经指令调优的模型，RLIF几乎没有改进效果，这表明一旦LLM已经经过指令调优，内部反馈的收益会减少。
## Innovation
研究提出了一种新的基于内部反馈的强化学习方法（RLIF），利用未监督的奖励代理（如标记级别熵、轨迹级别熵和自我确信度）来提高大语言模型的推理性能。研究分析显示这种内部目标部分等效，并且展示了不同RLIF策略在复杂数学推理基准测试上的效果差异。研究还通过混合模型权重解释了 RLIF 在训练过程中的行为，提供了整合内部反馈信号到LLM训练中的实用指南。
## Conclusion
研究表明，虽然RLIF可以在训练初期提升基本LLMs的推理能力，但随着训练的推进，它的性能会下降，甚至低于未训练的模型。对于已经指令调优的模型，RLIF几乎没有改进的效果，表明内在反馈的收益随着模型调优的进行而逐渐减少。研究通过混合模型权重进一步分析了这一局限，并提出了实用建议以将内部反馈信号整合进LLM训练中。
# 185. `cs.AI` - 莫尔斯：用于扩散模型无损加速的双重抽样方法 [PDF](https://arxiv.org/pdf/2506.18251), [HTML](https://arxiv.org/abs/2506.18251)
## Authors
Chao Li,Jiawei Fan,Anbang Yao
## Background
本文提出了一种名为Morse的简单双重抽样框架，用于加速扩散模型，同时保持无损特性。扩散模型通常通过从噪声到数据的迭代生成过程来工作，这些过程需要较长时间来优化。Morse通过引入跳跃抽样和自适应残差反馈策略重新制定了这一过程，旨在提升采样效率，从而加速模型运行，同时保持生成图像的质量不变。
## Innovation
莫尔斯的核心创新在于提出了跳跃抽样和自适应残差反馈策略，确保了在减少生成时间的同时，仍然能够无损地生成高质量的图像。Morse通过构建Dash和Dot两个模型，实现交错运行以提高效率，其中Dash模型负责生成基础噪声，而Dot模型则负责根据Dash模型的跳跃抽样点生成反馈信息，提高预测精度。通过共享权重策略，Morse提高了训练和推理的效率，使得在多种图像生成任务中比9种基线模型平均加速1.78到3.31倍，甚至还可以应用于现有的加速扩散模型LCM-SDXL，提升其小步长文本到图像合成的速度和效率。
## Conclusion
研究证明，通过引入跳跃抽样和残差反馈机制，Morse显著提高了扩散模型的运行效率，且在多任务上平均加速了1.78到3.31倍，同时保持了图像生成质量的无损。此外，该方法还可以推广应用于其他已加速的扩散模型，提升其效率。
# 186. `cs.AI` - 非平衡自退火伴随采样器 (NAAS} [PDF](https://arxiv.org/pdf/2506.18165), [HTML](https://arxiv.org/abs/2506.18165)
## Authors
Jaemoo Choi,Yongxin Chen,Molei Tao,Guan-Horng Liu
## Background
近年来，基于学习的扩散采样器在从给定无常态密度中采样方面取得了显著进展。这些方法通常遵循两种范式之一：(i) 使用标准参考过程将采样形式化为无偏随机最优控制 (SOC) 问题，或 (ii) 通过重要性加权采样逐步细化采样路径测度。尽管退火方法在引导样本向高密度区域移动方面具有优势，但对重要性采样的依赖导致实际应用中高方差和可扩展性有限的问题。
## Innovation
本文介绍了一种新颖的基于 SOC 的扩散采样器——非平衡自退火伴随采样器 (NAAS)，该方法利用了退火参考动力学，而无需依赖重要性采样。NAAS 使用受伴随匹配启发的简化的伴随系统，可以实现高效的可扩展训练。
## Conclusion
我们展示了该方法的有效性，涵盖从经典能量景观到分子玻尔兹曼分布的广泛任务。
# 187. `cs.AI` - AnchorDP3：基于3D功能性引导的稀疏扩散策略在机器人操作中的应用 [PDF](https://arxiv.org/pdf/2506.19269), [HTML](https://arxiv.org/abs/2506.19269)
## Authors
Ziyan Zhao,Ke Fan,He-Yang Xu,Ning Qiao,Bo Peng,Wenlong Gao,Dongjiang Li,Hui Shen
## Background
 AnchorDP3 提供了一种用于双臂机器人操作的扩散策略框架，能够在高随机化环境中实现最先进的性能。该论文背景描述了双臂机器人操作的挑战，以及现有方法在面对高度随机环境时的局限性。此外，它强调了在极端随机化下操作的必要性，如对象、杂乱、桌面高度、光照和背景的变化。
## Innovation
1. 集成模拟器监督语义分割，使用渲染的 ground truth 明确地在点云中分割任务关键对象，提供强有力的可操作性先验；2. 任务条件特征编码器，轻量级模块处理每个任务的增广点云，通过共享的基于扩散的动作专家实现高效多任务学习；3. 基于可操作性锚定的关键姿态扩散结合完全状态监督，通过预测稀疏、几何上有意义的动作锚点（如预抓取姿态、直接锚定在可操作性上的抓取姿态）简化预测空间，动作专家被迫同时预测机器人关节角度和末端执行器姿态，利用几何一致性加速收敛并提高准确性。
## Conclusion
AnchorDP3 在大规模程序生成的仿真数据上进行训练，实现了在 RoboTwin 基准测试中跨多种任务98.7%的平均成功率，即使在对象、杂乱、桌面高度、光照和背景的极端随机化情况下。此框架与 RoboTwin 真实到仿真的流水线结合时，有望仅从场景和指令自主生成可部署的视觉-运动策略，彻底消除人类演示在学习操作技能中的需求。
# 188. `cs.CL` - Inference Scaled GraphRAG：提高知识图上多跳问答能力 [PDF](https://arxiv.org/pdf/2506.19967), [HTML](https://arxiv.org/abs/2506.19967)
## Authors
Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu
## Background
大语言模型（LLMs）在语言理解和生成方面表现出色，但在涉及大量专业知识推理的任务上仍然表现不足，这主要是因为它们缺乏对结构化上下文和多跳信息的访问能力。虽然检索增强生成（RAG）方法可以在一定程度上缓解这一问题，通过将生成与检索到的上下文结合起来，但其在捕捉知识图节点间的关系结构方面能力有限。现有的GraphRAG方法也同样无法有效捕捉知识图中的关系结构。
## Innovation
本文提出了一种新颖的框架——推理缩放GraphRAG（Inference-Scaled GraphRAG），其通过推理时间下的计算缩放增强基于LLM的图推理能力。该方法结合了顺序缩放与深度链式推理图遍历，并利用交错推理执行循环在并行缩放下通过多数投票进行采样轨迹评估。实验结果表明，该方法显著提升了多跳问答性能，在GRBench基准测试中取得了比传统GraphRAG和先前的图遍历基准更大的改进。这些发现表明，推理时间下的缩放是一种实际且架构无关的解决方案，对于结构化知识推理具有重要意义。
## Conclusion
本文提出的方法展示了在多跳问答任务上的显著性能提升，通过推理时间下的计算缩放，有效改进了知识图推理中的问题。未来的研究可以进一步探索不同规模下的推理效率优化，以及适用于更广泛知识图和任务场景的有效策略。
# 189. `cs.CL` - Doc2Agent：从API文档规模化生成使用工具的代理 [PDF](https://arxiv.org/pdf/2506.19998), [HTML](https://arxiv.org/abs/2506.19998)
## Authors
Xinyi Ni,Haonan Jian,Qiuyang Wang,Vedanshi Chetan Shah,Pengyu Hong
## Background
REST APIs 在增强网页代理功能方面发挥着重要作用，但大多数基于API的代理使用的是经过整理且统一的工具集，无法反映真实世界API的复杂性。对于任意领域的代理构建仍然是一项巨大挑战，这需要读取非结构化的API文档，测试API，以及推断正确的参数。
## Innovation
Doc2Agent 提出了一种可伸缩的管道，用于生成可以从API文档生成的Python工具，并通过代码代理逐步优化这些工具。该方法在实际API、WebArena API和研究API上进行了评估，并生成了验证过的工具。与直接调用API相比，该方法在WebArena基准测试中实现了55%的相对性能改进，成本降低了90%。此外，一个针对糖材料科学领域的特定代理进一步证明了该管道对复杂、知识密集型任务的适应性。
## Conclusion
Doc2Agent 提供了一种规模化解决方案，可以从未结构化的API文档中构建工具代理。
# 190. `cs.CL` - CycleDistill：利用循环蒸馏方法通过大语言模型提升机器翻译 [PDF](https://arxiv.org/pdf/2506.19952), [HTML](https://arxiv.org/abs/2506.19952)
## Authors
Deepon Halder,Thanmay Jayakumar,Raj Dabre
## Background
大型语言模型（LLMs）在零样本或少数样本机器翻译（MT）方面表现出色，但与基于平行语料库训练的专业MT系统相比，它们在高质量MT方面仍有差距。平行语料库通常对于低资源语言来说稀缺或不存在。因此，论文提出了CycleDistill，这是一种利用LLMs和少数样本翻译来生成高质量MT系统的递推训练方法。该方法通过从单语语料库生成合成平行语料库来迭代提升MT系统的质量，而无需依赖大量的平行语料库。
## Innovation
提出了CycleDistill方法，这是一种递推式训练方法，利用LLMs和少数样本翻译来生成合成平行语料库，进而迭代优化MT系统的质量。CycleDistill仅需要1到4个少量样本示例即可，对于三种印度语言的实验显示，在仅依赖单语语料库的情况下，能够显著提升机器翻译质量，平均在第一个迭代中比少数样本基线模型高出20-30个chrF分数点。此外，论文还研究了在蒸馏过程中利用softmax激活的影响，观察到翻译质量有轻微的改进。
## Conclusion
通过CycleDistill方法，既不需要大量的平行语料库，又能够有效提升基于LLMs的机器翻译系统的质量。这种方法特别适用于低资源语言，提供了一种改进机器翻译的方法。
# 191. `cs.AI` - Thought Anchors: Which LLM Reasoning Steps Matter？ [PDF](https://arxiv.org/pdf/2506.19143), [HTML](https://arxiv.org/abs/2506.19143)
## Authors
Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy
## Background
大型语言模型在许多领域已经达到了最先进的性能，但其长期的链式推理产生了可解释性的挑战，因为每个生成的词都依赖于所有之前的词汇，使得计算难以分解。文章指出，在句级层面分析推理轨迹是理解推理过程的一种有前景的方法。研究人员提出三种互补的归因方法：(1)黑盒方法通过比较100次滚动力下生成的最后答案来衡量每个句子的假设性重要性，这些滚动力是在模型生成该句子或生成意义不同的句子的条件下进行的；(2)白盒方法聚合句子对之间的注意力模式，该方法确定了“广播”句子，它们通过“接收者”注意力头部获得了不成比例的关注；(3)因果归因方法通过抑制一个句子的注意力并测量对每个后续句子词的影响来衡量句子间的逻辑联系。每种方法提供了存在思维锚的证据，即那些具有无与伦比的重要性并对后续推理过程产生不成比例影响的推理步骤，这些思维锚通常是规划或回溯句子。研究人员提供了一个开源工具用于可视化方法的输出，并展示了多步骤推理中模式一致的例子，这表明在推理模型理解中的深入分析可以通过句级分析来实现。
## Innovation
本文提出了三个互补的归因方法，分别在黑盒法、白盒法和因果归因法方面，从句级层面分析大型语言模型的推理过程，并证明了思维锚的存在，这些思维锚是那些具有显著重要性的推理步骤，对后续推理过程产生显著影响。此外，开发了一个开源工具用于可视化这些方法的结果，并展示了利用这些方法理解多步骤推理中模型表现的方法。
## Conclusion
研究表明，句级分析在理解推理模型中的潜在价值，并证明了存在思维锚，即那些具有显著重要性的推理步骤。研究人员提出的方法为深入理解大型语言模型的推理过程和评估其合理性提供了新的视角，同时也展示了通过注意模式和逻辑连接等因素来确定“关键步骤”的可能性。
# 192. `cs.AI` - OmniGen2：探索高级多模态生成 [PDF](https://arxiv.org/pdf/2506.18871), [HTML](https://arxiv.org/abs/2506.18871)
## Authors
Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu
## Background
本文介绍了OmniGen2，一款具有多功能和开源特点的生成模型，旨在提供跨多种生成任务（如文本转图像、图像编辑和上下文生成）的统一解决方案。OmniGen2与OmniGen v1相比，具有两个独立的解码路径，分别用于处理文本和图像模态，同时不共享参数和独立的图像标记器。这使得OmniGen2可以在不重新适应VAE输入的情况下，基于现有的多模态理解模型进行改进，从而保留了原始的文本生成能力。此外，该团队还开发了全面的数据构建管道，包含了图像编辑和上下文生成数据，并引入了专门针对图像生成任务的反射机制，构建了一个专门的反射数据集，从而提升了模型在多个任务中的表现。为了进一步评估上下文生成能力，引入了一个新基准OmniContext，OmniGen2在开源模型中表现出最佳的一致性表现。
## Innovation
OmniGen2与之前的版本OmniGen v1相比，具有两个独立的解码路径，分类处理文本和图像模态，不共享参数和独立的图像标记器。这种设计允许OmniGen2在保持原始文本生成能力的同时，建立在现有的多模态理解模型之上，无需重新适应VAE输入。此外，还开发了全面的数据构建管道，引入了专门针对图像生成任务的反射机制，并构建了专门的反射数据集。这些创新使得OmniGen2在多个任务基准上达到了竞争力，特别是在文本转图像和图像编辑任务中。
## Conclusion
尽管OmniGen2的参数规模相对较小，但在多个任务基准上仍表现出优异的结果，特别是在一致性和上下文生成方面。为此，团队将公开发布其模型、训练代码、数据集和数据构建管道，支持未来在该领域的研究。
# 193. `cs.AI` - 在超越标记的视角下量化LLM的公平性：一种语义和统计方法 [PDF](https://arxiv.org/pdf/2506.19028), [HTML](https://arxiv.org/abs/2506.19028)
## Authors
Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy
## Background
大型语言模型（LLMs）在生成响应时往往带有固有的偏见，这削弱了它们在实际应用中的可靠性。现有的评估方法通常未能关注长篇回复中的偏见以及LLMs输出的内在变化。为解决这些问题，提出了细粒度语义计算（FiSCo）这一新的统计框架，用于通过检测不同人口群体之间的细微语义差异来评估LLMs的整体公平性。这种方法不同于以往侧重于情感或标记层级的比较，FiSCo在声明层级上进行操作，利用蕴含检查来评估意义的连贯性。研究人员将模型输出分解为语义上不同的声明，并应用统计假设检验来比较跨组和组内相似性，从而实现对细微偏见的稳健检测。通过正式化新的群体反事实公平定义，并在跨越性别、种族和年龄的合成数据集和人工标注数据集上进行验证。实验表明，FiSCo能更可靠地识别复杂的偏见，同时降低LLMs随机性的影响，优于各种评估标准。
## Innovation
提出了细粒度语义计算（FiSCo）这一新的统计框架，用于通过声明层级的细微语义差异检测来评估大规模语言模型（LLMs）的整体公平性，不同以往侧重于情感或标记层级的比较，FiSCo利用蕴含检查评估意义的连贯性。这种方法能更可靠地识别复杂的偏见，同时降低LLMs随机性的影响，优于各种评估标准。
## Conclusion
本文通过细粒度语义计算（FiSCo）这一新的统计框架，对大规模语言模型（LLMs）的整体公平性进行了评估，能够更可靠地识别复杂的偏见，同时降低LLMs随机性的影响，优于各种评估标准。验证了通过正式化的群体反事实公平定义，并在跨越性别、种族和年龄的合成数据集和人工标注数据集上验证了方法的有效性。
# 194. `cs.CL` - SACL: 通过语义增强重排序和定位理解并对抗代码检索中的文本偏见 [PDF](https://arxiv.org/pdf/2506.20081), [HTML](https://arxiv.org/abs/2506.20081)
## Authors
Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie
## Background
代码检索是增强代码生成的关键技术，当前的检索技术主要依赖于表面上的文本特征（如文档字符串、标识符名称），并且倾向于具有良好文档的代码，即使文档存在偏见。针对这些背景，本文深入分析了代码检索，并提出了SACL框架，旨在通过增强文本信息和减少偏见来改善代码检索效果。
## Innovation
本文创新地提出了SACL框架，这种方法通过以语义信息增强代码或结构知识来丰富文本信息并减少偏见。实验结果显示，SACL显著提高了代码检索性能（例如，在HumanEval、MBPP和SWE-Bench-Lite上的Recall@1分别提高了12.8%、9.4%和7.0%），同时也提升了代码生成性能（例如，在HumanEval上的Pass@1提高了4.88%）。
## Conclusion
研究表明，通过SACL框架，可以有效改善代码检索性能，并通过增强文本信息和减少偏见来提高代码生成的质量和准确性。
# 195. `cs.AI` - Confucius3-Math: 一个专为中国K-12数学学习设计的高性能轻量化推理大语言模型 [PDF](https://arxiv.org/pdf/2506.18330), [HTML](https://arxiv.org/abs/2506.18330)
## Authors
Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan
## Background
近年来，大语言模型在数学推理任务上的表现逐渐引起了学术界和工业界的关注。然而，这些模型通常需要大量的计算资源，并且在特定领域的性能可能不如预期。为了克服这些限制，作者介绍了Confucius3-Math这一开源的大语言模型，它能够在单个消费级GPU上高效运行，并且在数学推理任务上取得了SOTA性能，同时模型尺寸远小于其他模型。特别地，该模型专为中国的K-12学生和教师设计，旨在通过AI技术提高教育和知识传播的质量。
## Innovation
为了构建一个在特定领域以较低成本运行的强大推理模型，作者引入了三项技术创新：目标熵正则化、最近样本恢复和策略特定难度加权。这些创新包括一种新的熵正则化方法、一种新颖的数据调度策略以及一个改进的组相对优势估计器。这些技术显著稳定了强化学习训练，提高了数据效率，并提升了模型性能。此外，该模型还能够与国家课程相结合，以较低的成本解决主流的K-12数学问题。
## Conclusion
该研究证明了在特定领域建设强大的推理模型是可行的，并且可以通过合理的技术选择以较低的成本来实现。作者开源了该模型和代码，供其他研究者和教育工作者使用。
# 196. `cs.CL` - 一种用于精细阅读行为建模的空间-时间点过程 [PDF](https://arxiv.org/pdf/2506.19999), [HTML](https://arxiv.org/abs/2506.19999)
## Authors
Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell
## Background
阅读是一个在空间和时间上展开的过程，其中交替出现注视和扫视。传统的假设认为，通过建模读者的注视和扫视可以深入了解其在线句子处理。然而，现有的方法通常依赖于聚合的眼动测量数据以及强假设的模型，这些方法忽略了阅读期间发生的许多时空动态。因此，需要一种更通用的概率模型来捕捉注视持续的时间、位置和时间，以及扫视如何随着时间空间共同激发新的注视的发生。
## Innovation
本文提出了一种基于标记时空点过程的更通用的阅读行为概率模型，可以不仅捕捉注视持续的时间，还能捕捉其发生的时空位置。扫视过程使用了霍克斯过程，能够捕捉到每个注视如何在时空中激发附近新注视的概率。注视持续时间被建模为与特定注视预测因子相关的函数，从而捕捉到溢出效应。实证结果显示，与基线相比，霍克斯过程模型更适合人类的眼动。关于注视持续时间，将上下文惊奇作为预测因子时，模型的预测准确性仅略有提高，这表明惊奇理论很难解释细微的眼动行为。
## Conclusion
研究表明，基于标记时空点过程的霍克斯过程模型能够更准确地描述阅读过程中的细微时空动态，此外也发现上下文惊奇理论在解释眼动细节方面存在不足。
# 197. `cs.CL` - 利用AI评分技术进行缺失分数填补以实现构建回应测试中的准确能力评估 [PDF](https://arxiv.org/pdf/2506.20119), [HTML](https://arxiv.org/abs/2506.20119)
## Authors
Masaki Uto,Yuma Ito
## Background
评估学习者的技能是教育领域的一项基本目标，尤其需要评估表达能力和逻辑思维等高阶能力。构造性回答测试，如简答题和论文题，被广泛用于评估这些能力，因为它们能有效测试复杂的推理能力和沟通能力。然而，这样的测试需要大量的手动评分，导致劳动密集和成本高。项目反应理论（IRT）提供了一种前景广阔的解决方案，它可以通过仅对学习者在多个测试项目中提供的答案子集进行人工评分来估计学习者的技能。然而，随着缺失分数比例的增加，能力估计的准确性会下降。在尝试通过数据增强技术填补这些缺失分数时，这些技术通常在稀疏或异构数据情况下表现不佳。因此，为了克服这些挑战，本研究提出了一种新的方法，通过利用自动化评分技术填补缺失分数，以实现基于IRT的能力估计的准确性，同时大幅减少人工评分的工作量。
## Innovation
本研究提出了一种新的填补缺失分数的方法，利用自动化评分技术进行准确的IRT能力评估，并实现了在减少人工评分工作量的同时，保持高度的能力估计准确性。
## Conclusion
本研究提出的方法在能力估计中的准确性能够实现，同时显著减少手动评分的工作量，为应对构造性回答测试评分面临的挑战提供了一种新的解决方案。
# 198. `cs.CL` - 多阶段大型语言模型框架在精确且高效的放射学报告错误检测中的应用 [PDF](https://arxiv.org/pdf/2506.20112), [HTML](https://arxiv.org/abs/2506.20112)
## Authors
Songsoo Kim,Seungtae Lee,See Young Lee,Joonho Kim,Keechan Kan,Dukyong Yoon
## Background
大型语言模型（LLM）基于的放射学报告校对的阳性预测值（PPV）受限于低错误发生率。这项研究旨在评估三阶段LLM框架相比基线方法是否能提高PPV并降低运营成本.
## Innovation
研究测试了三个LLM框架：单指令检测器、提取器加检测器和提取器、检测器与假阳性校验器。研究结果表明，三阶段框架显著提高了PPV，同时降低了操作成本，并维持了检测性能，为AI辅助放射学报告质量保证提供了有效的策略.
## Conclusion
三阶段LLM框架不仅显著提高了PPV，还降低了运营成本，同时保持了检测性能，为AI辅助放射学报告质量保证提供了一种有效策略.
# 199. `cs.CL` - 通过自编码器桥梁化组成本质和分布本质语义：一种潜在语义几何综述 [PDF](https://arxiv.org/pdf/2506.20083), [HTML](https://arxiv.org/abs/2506.20083)
## Authors
Yingji Zhang,Danilo S. Carvalho,André Freitas
## Background
论文背景在于通过整合组合性和符号性特性，进一步提升基于Transformer的自回归语言模型（LMs）的可解释性、可控性、组合性和泛化能力。文章回顾了基于自编码器的三种主流架构（VAE、VQVAE、SAE），探讨了它们如何在语义结构和可解释性方面影响潜在空间几何形状，来实现符号性和分布性语义之间的桥梁。
## Innovation
文章提供了一种新的视角，即通过组合语义来观察潜在空间几何，提出了语义表示学习（semantic representation learning）的概念，这有助于弥合符号性语义和分布性语义之间的差距。它通过对比VAE、VQVAE和SAE三种自动编码器架构，进一步探究了它们在语义结构和可解释性方面的独特几何特性。
## Conclusion
综上所述，论文旨在通过语义表示学习的方式，利用自编码器来实现符号性和分布性语义的相互融合，从而提升语言模型的整体性能。
# 200. `cs.CL` - IT Former: 桥接时间序列和自然语言以使用大规模多任务数据集进行多模态问答 [PDF](https://arxiv.org/pdf/2506.20093), [HTML](https://arxiv.org/abs/2506.20093)
## Authors
Yilin Wang,Peixuan Lei,Jie Song,Yuzhe Hao,Tao Chen,Yuxuan Zhang,Lei Jia,Yuanxiang Li,Zhongyu Wei
## Background
时间序列数据在工业监控、医疗诊断和气候研究等多种应用中至关重要。然而，高效地将这些高维时间序列信号与自然语言结合以进行动态、交互式任务仍然是一个重大挑战。为解决这个问题，本文介绍了时间序列问答（Time-Series QA）任务，并发布了EngineMT-QA数据集，这是第一个大规模、多任务、时间和文本问答数据集，旨在捕捉时间序列信号和自然语言之间的复杂交互。此外，本文还提出了Instruct Time Transformer (ITFormer)，这是一种结合时间序列编码器与冻结大规模语言模型的新框架。ITFormer能够有效提取、对齐和融合时空和文本特征，在较少的可训练参数下，能够显著提高问答准确性。该工作通过结合计算效率和稳健的跨模态建模，建立了一个将时间数据与自然语言集成的可适应范式，为跨模态AI的新研究和应用打开了大门。
## Innovation
本文提出了时间序列问答（Time-Series QA）任务，并发布了EngineMT-QA数据集，这是第一个大规模、多任务、时间和文本问答数据集，旨在捕捉时间序列信号和自然语言之间的复杂交互。此外，本文还提出了Instruct Time Transformer (ITFormer)，这是一种结合时间序列编码器与冻结大规模语言模型的新框架。ITFormer能够有效提取、对齐和融合时空和文本特征，在较少的可训练参数下，能够显著提高问答准确性。
## Conclusion
通过结合计算效率和稳健的跨模态建模，本文建立了一个将时间数据与自然语言集成的可适应范式，为跨模态AI的新研究和应用打开了大门。
# 201. `cs.CL` - 集成时空模型和LLMs的模块化多任务推理框架 [PDF](https://arxiv.org/pdf/2506.20073), [HTML](https://arxiv.org/abs/2506.20073)
## Authors
Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang
## Background
时空数据挖掘在多种领域中的决策支持中发挥着关键作用。然而，现有的模型通常仅限于单一任务，缺乏多任务推理和复杂长期推理的能力，这些能力需要生成详细的解释性输出。这些限制限制了它们在多维度的现实世界决策场景中的应用。
## Innovation
提出了STReason，这是一种新颖的框架，将大型语言模型（LLMs）的推理优势与时空模型的分析能力整合起来，进行多任务推理和执行。无需特定任务的微调，STReason利用上下文学习将复杂的自然语言查询分解为可模块化、可解释的程序，然后系统执行这些程序以生成解决方案和详细的推理性解释。为了促进严格的评估，还构建了一个新的基准数据集，并提出了一种统一的评估框架，涵盖了专门设计用于长期时空推理的指标。实验结果显示，STReason在所有指标上均显著优于先进的LLM基线，特别是在复杂的、推理密集型的时空场景中表现尤为突出。
## Conclusion
人机评估进一步验证了STReason的可靠性和实用性，证明了其减少专家工作量和拓宽时空任务适用性方面的潜力。我们相信STReason为开发更强大和泛化的时空推理系统提供了有希望的方向。
# 202. `cs.CL` - 使用大型语言模型改进对话情感识别的上下文学习中如何检索示例 [PDF](https://arxiv.org/pdf/2506.20199), [HTML](https://arxiv.org/abs/2506.20199)
## Authors
Mengqi Wang,Tiantian Feng,Shrikanth Narayanan
## Background
大型语言模型（LLMs）在各种领域中推动了广泛的实际应用。然而，创建高精度的应用仍具有挑战性，特别是在情感识别等主观任务中。SLT 2024 GenSER挑战激发了本研究，旨在通过LLMs改进对话情感识别（CER）。研究特别探讨了在上下文学习（ICL）中如何检索高质量示例以提升CER性能，并分析了对话上下文对CER准确率的影响。实验在IEMOCAP、MELD和EmoryNLP三个数据集上进行，结果显示，增强示例检索在所有数据集上始终优于其他技术，突显了检索相关且一致的示例并通过改写增强的重要性。
## Innovation
本研究提出了各种基于随机和增强示例检索的策略，并分析了对话上下文对CER准确率的影响。通过实验验证，增强示例检索在三个常用数据集上始终优于其他方法，强调了检索相关且一致的示例并通过改写增强的重要性。
## Conclusion
增强示例检索策略在提高大型语言模型的对话情感识别性能方面表现出优越性，是改进CER的有效方法。
# 203. `cs.CL` - MIRAGE:农业专家引导对话中的多模态信息寻求和推理基准 [PDF](https://arxiv.org/pdf/2506.20100), [HTML](https://arxiv.org/abs/2506.20100)
## Authors
Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve
## Background
在农业领域，专家咨询的复杂性要求高精度的自然语言处理和多模态数据处理模型。现有的基准数据集大多依赖于规定性的用户输入和固定的分类系统，无法全面评估模型在真实场景中的推理、澄清策略和长文本生成能力。MIRAGE基准数据集旨在填补这一空白，它基于超过35,000个真实用户与专家的互动，并通过精心设计的多步骤管道进行整理，涵盖了作物健康、虫害诊断和作物管理等多样化场景，提供了多样的生物实体，使得基于视觉-语言模型的评估更加贴近真实世界的需求。
## Innovation
MIRAGE基准数据集创新性地采用了非特定性输入和开放式分类体系，覆盖农业领域中的复杂真实场景，要求模型推测潜在的知识缺口、处理稀有实体，并能够在交互过程中主动指导或作答。相比现有模型，MIRAGE能够更全面地评估模型的推理能力、澄清策略以及长文本生成能力。它包括超过7,000种独特的生物实体，是当前基于视觉-语言模型的最多样化的基准之一，完全基于真实的农业领域数据。
## Conclusion
MIRAGE为研究人员提供了农业专家引导对话中多模态信息寻求与推理的高质量基准数据集，有助于更全面地评估和提高多模态处理模型在现实场景中的性能，推动了该领域的研究和发展。
# 204. `cs.CL` - COIN: 为基座模型提供防不确定性选择性问答的证明风险保证 [PDF](https://arxiv.org/pdf/2506.20178), [HTML](https://arxiv.org/abs/2506.20178)
## Authors
Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu
## Background
对于基座模型生成的文本进行不确定性量化（UQ）是必要的，以识别和减轻潜在的幻觉。以前的工作使用分劈置信预测（SCP）框架来确保预测集具有所需的答案覆盖率，但这些预测集往往包含错误的候选答案，限制了其实用性。因此，需要一种能够定量控制错误发现率（FDR）保证的筛选框架，以筛选出单个问题的答案，同时保留使用者指定的FDR约束下的统计有效性。
## Innovation
本文提出了COIN（不确定性守护选择框架），该框架为每次问题下筛选单个生成答案提供了一套能控制用户指定FDR约束下的统计验证阈值方法。COIN通过在校准集上估计经验错误率并使用Clopper-Pearson等置信区间方法建立真实错误率的高概率上限，从而能在保证FDR控制的同时最大限度地保留样本。COIN在风险控制的鲁棒性、保留可接受答案的测试时效能以及在有限校准数据下的预测效率方面都表现突出，且在多种文本生成任务中都有效。此外，通过采用不同的上限构造方法和不确定性量化策略，COIN的性能能够得到进一步提升，显示出其在不同应用场景中的扩展性和适应性。
## Conclusion
COIN能够在严格控制FDR风险的前提下优化样本保留，不仅提高了模型对生成文本的筛选质量，还展示了其在不同类型文本生成任务中的强大性能和适应性。
# 205. `cs.CL` - 游戏中的视角：更包容的NLP系统的一个多视角方法 [PDF](https://arxiv.org/pdf/2506.20209), [HTML](https://arxiv.org/abs/2506.20209)
## Authors
Benedetta Muscato,Lucia Passaro,Gizem Gezici,Fosca Giannotti
## Background
在自然语言处理（NLP）领域，常见的处理人类分歧的方法是汇总标注者的观点以建立单一的地面真实值。然而，先前的研究表明，忽略个体意见可能会导致少数派观点被低估，尤其是在主观任务中，标注者由于其偏好可能会系统性地持有不同意见。鉴于标签反映了个体的背景、生活经历和价值观差异，这项研究提出了一种新的多视角方法，使用软标签鼓励开发能够意识到视角差异的新一代NLP模型，更加包容和多元。研究人员对多种主观文本分类任务进行深入分析，如仇恨言论、反讽、攻击性语言和立场检测，以强调捕捉人类分歧的重要性，这通常被传统汇总方法所忽视。
## Innovation
提出了一个使用软标签的多视角方法来处理NLP领域中的分歧，这种新的方法鼓励开发能够意识到不同视角的NLP模型，更加包容和多元。通过使用Jensen-Shannon散度（JSD）和F1分数对模型性能进行评估，研究人员证明了多视角方法不仅更接近人类标签分布，还有较高的分类性能。这种方法特别适用于主观性强的任务，但由于文本固有的主观性，它在反讽和立场检测任务上的置信度较低。利用可解释的人工智能（XAI），研究人员探索了模型不确定性并揭示了有关模型预测的有意义洞见。
## Conclusion
多重视角方法不仅更好地逼近了人类标签分布，而且在分类性能上也超过了传统的标注汇总方法。尽管它在某些任务上表现出较低的置信度，但这种多视角方法对NLP系统的包容性和多元化具有重要意义。通过对多种主观文本分类任务的研究，强调了在处理NLP任务时考虑不同个体视角的必要性，并提出了一种新的方法来改进未来的NLP模型。
# 206. `cs.CL` - Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models [PDF](https://arxiv.org/pdf/2506.20269), [HTML](https://arxiv.org/abs/2506.20269)
## Authors
Kai-Robin Lange,Tobias Schmidt,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch
## Background
随着媒体叙事迅速演变，从给定语料库中不仅仅是提取叙事，更重要的是研究它们随时间的发展变得日益关键。现有的大型语言模型虽然在捕捉叙事元素或复杂结构方面表现良好，但在处理整个语料库时存在高成本的障碍，包括经济或计算成本。
## Innovation
本文提出了一种结合大型语言模型的语义理解和大规模适用性的主题模型的方法，以动态建模时间上的叙事变化，并应用主题模型和相应的变化点检测方法以找到特定兴趣话题的变化。使用这种方法筛选语料库，发现特定变化的代表文档，并将它们输入大型语言模型以自动解释发生的变化，并区分内容和叙事变化。在《华尔街日报》2009年至2023年的新闻文章语料库上应用该方法进行了证明。发现大型语言模型可以高效地提取特定时间点的叙事变化，但当需要判断内容变化还是叙事变化时表现不佳。
## Conclusion
研究结果表明，大型语言模型能够有效提取给定时间点的叙事变化，但在判断内容变化还是叙事变化方面表现不佳。
# 207. `cs.CL` - CCRSM: 一种零样本的LLM作裁判框架，用于全面的RAG评估 [PDF](https://arxiv.org/pdf/2506.20128), [HTML](https://arxiv.org/abs/2506.20128)
## Authors
Aashiq Muhamed
## Background
RAG系统通过整合外部知识增强LLM，对需要事实准确性和最新信息的领域至关重要。然而，评估RAG输出的质量（包括上下文一致性、查询相关性、事实准确性、信息完整性等多方面）存在重大挑战。现有方法通常依赖简单的词频重叠度量，无法捕捉这些复杂性，或者需要复杂的多阶段管道，这妨碍了实际效率。传统评估工具在多样性、计算效率和综合评估能力上存在局限性。因此，迫切需要一种新的工具来评估RAG系统的性能。
## Innovation
本文提出了一种创新的套件，被称为CCRSM（Contextual Coherence and Relevance Score），这是一种新颖的零样本框架，利用单个强大的预训练LLM作为端到端裁判，评估RAG系统的五个方面表现：上下文一致性、查询相关性、信息密度、答案准确性和信息召回率。与RAGChecker框架相比，CCRSM在计算效率和关键方面（如召回率和忠实性）的区分能力方面具有比较或更好的表现，同时提供了一个更实用、综合和高效的RAG评估和迭代改进框架。
## Conclusion
我们的分析表明，CCRSM成功地区分了不同RAG系统的性能表现，例如，Mistral-7B阅读器的表现优于Llama变体。我们提供了关于CCRSM指标属性的详细分析，包括打分分布、收敛/区分有效性、平局率、总体统计和区分力。CCRSM作为一个工具，为RAG系统的评估和迭代改进提供了实际、综合和高效的框架。
# 208. `cs.CL` - 通过结构化推理增强大型语言模型 [PDF](https://arxiv.org/pdf/2506.20241), [HTML](https://arxiv.org/abs/2506.20241)
## Authors
Yubo Dong,Hehe Fan
## Background
最近的大型语言模型（LLMs）在自然语言处理和自动化决策方面取得了显著进展。然而，当面对涉及逻辑推理和系统规划的复杂任务时，这些模型仍然存在困难，主要是因为它们依赖于隐性的统计关系，缺乏结构化的知识。通过认知科学和神经符号AI，我们提出了一种通过明确的结构化推理来增强LLMs的新方法。首先，通过明确定义推理步骤，将非结构化数据转换为结构化的格式。然后利用此结构化数据集通过监督微调（SFT）来训练LLMs。此外，通过Group Relative Policy Optimization（GRPO），结合两种创新算法—MAX-Flow和最长公共子序列（LCS），增强LLMs的结构化推理能力，极大地提高了推理效果并减少了计算复杂度。
## Innovation
通过引入Group Relative Policy Optimization（GRPO）以及运用两种创新算法（MAX-Flow和Longest Common Subsequence，LCS），我们改进了LLMs的结构化推理能力。这种方法可以将非结构化数据转化为结构化的格式，并通过监督微调（SFT）训练LLMs，从而提高其推理效率和降低计算复杂度。实验结果表明，在DeepSeek-R1-Distill-Qwen-1.5B模型上进行微调后，模型表现出简洁的推理能力、各种场景下的稳健性能以及与优化技术的更好兼容性，验证了结构化推理在LLMs中的有效性。
## Conclusion
框架通过结构化数据处理和倏续推理能力的增强，显著提高了LLMs在复杂推理任务上的表现，并通过实验验证了其有效性。
# 209. `cs.CL` - CBF-AFA: 基于块的多SSL融合自动流畅性评估 [PDF](https://arxiv.org/pdf/2506.20243), [HTML](https://arxiv.org/abs/2506.20243)
## Authors
Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc
## Background
自动流畅性评估（AFA）在捕捉非母语说话者的说话节奏、停顿和流畅性中断方面仍然具有挑战性。现有的方法难以精确地评估这种复杂性，尤其是在处理非母语者的声音特征和噪声话语时。本文旨在通过结合多种自我监督学习（SSL）模型，包括Wav2Vec2、HuBERT和WavLM，以及层次CNN-BiLSTM框架，来改善这一评估过程。
## Innovation
本文提出了一种基于块的方法，将自我监督学习模型（Wav2Vec2、HuBERT和WavLM）与层次CNN-BiLSTM框架相结合。这些SSL模型因其互补优势而在音素、声韵和噪声建模方面表现出色。通过这种方法，语音被细分为呼吸组块，采用Silero语音活动检测（Silero-VAD）进行分割，以实现精细化时间分析并减少过度分割的伪影。SSL嵌入通过可学习的加权机制融合，平衡了声学和语言特征，并添加了块级别的流畅性标记（如说话速率、停顿时长、n-gram重复）。这种方法捕捉了块内的局部和长期依赖性。
## Conclusion
在Avalinguo和Speechocean762数据集上的评估表明，与单个SSL基线相比，该方法在Speechocean762数据集上提高了2.8个F1分数和6.2个皮尔森相关系数，Avalinguo数据集上提高了4.2个F1分数和4.0个皮尔森相关系数，超过了基于分割的基线。这些结果强调了基于块的多SSL融合对于稳健流畅性评估的重要性，未来的研究应进一步探索对语调不规则方言的一般化能力。
# 210. `cs.CL` - TAPS：基于结构化标签的工具增强个性化 [PDF](https://arxiv.org/pdf/2506.20409), [HTML](https://arxiv.org/abs/2506.20409)
## Authors
Ekaterina Taktasheva,Jeff Dalton
## Background
工具增强的大型语言模型最近取得了进步，使它们能够与外部工具互动，从而增强它们执行复杂用户任务的能力。然而，现有的方法忽视了个性化在指导工具使用中的作用。本文探讨了如何有效地将用户偏好集成到目标导向的对话代理中。通过广泛的分析，我们确定了大型语言模型在个性化工具使用方面的一些关键弱点，并提出了TAPS，这是一种利用结构化标签工具和不确定性基工具检测器来增强个性化工具使用的新型解决方案。
## Innovation
提出了TAPS，这是一种新颖的解决方案，通过利用结构化标签工具和不确定性基工具检测器来增强大型语言模型在个性化工具使用方面的能力，从而显著提高了大型语言模型整合用户偏好的能力，并在NLSI任务上达到了开源模型的新最佳性能。
## Conclusion
TAPS通过利用结构化标签工具和不确定性基工具检测器显著改善了大型语言模型整合用户偏好的能力，实现了开源模型在NLSI任务上的新最佳性能。
# 211. `cs.CL` - 捷克语句嵌入的内在与外在评估：语义相关性未能提高机器翻译评估 [PDF](https://arxiv.org/pdf/2506.20203), [HTML](https://arxiv.org/abs/2506.20203)
## Authors
Petra Barančíková,Ondřej Bojar
## Background
本文探讨了捷克语与多语言句嵌入模型在内在和外在评估中的表现。内在评估使用复杂句转换数据集Costra和语义文本相似性STS基准测试，外在评估则使用基于COMET的指标进行机器翻译评估微调。研究表明，擅长内在语义相似性测试的模型在下游翻译评估任务中不一定表现出色，而一些嵌入空间看似过度平滑的模型通过微调后却能取得优异成绩。这一结果表明，句嵌入中的语义属性探针与下游任务之间的关系复杂，强调了对“操作化语义”和更多深入的下游任务数据集进行研究的必要性。
## Innovation
本文通过比较捷克语和多语言句嵌入模型，在内在和外在评估中展示了一种新颖的方法论，并发现虽然一些模型在语义相似性测试中表现出色，但在机器翻译任务中未必有效。通过COMET指标进行的微调可以改进模型在翻译中的性能，这一发现揭示了语义属性探针与下游翻译任务之间复杂的关系，促使了对更具体操作化语义研究的需求。
## Conclusion
通过对捷克语句嵌入的内在和外在评估，研究揭示了一个有趣的事实：擅长内在语义相似性测试的模型在机器翻译中不一定表现更好，而一些看似过度平滑的模型经过微调后却能取得好的效果。这些发现凸显了语义属性探针和下游任务之间的复杂关系，进一步强调了‘操作化语义’在句嵌入研究中的重要性，或者需要更多专门针对下游任务的数据集。
# 212. `cs.CL` - SEED: 一种基于LLMs的时间序列预测嵌入驱动解码的结构编码器 [PDF](https://arxiv.org/pdf/2506.20167), [HTML](https://arxiv.org/abs/2506.20167)
## Authors
Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma
## Background
多变量时间序列预测需要模型同时捕捉变量间的结构性依赖关系并适用于多种任务。虽然结构编码器在建模特征交互方面有效，但它们缺乏支持语义级别的推理或任务适应的能力。相比之下，大型语言模型（LLMs）具有强大的泛化能力，但难以处理原始的时间序列输入。这种差距限制了统一的、可迁移预测系统的开发。为了填补这一缺口，文章提出了一种嵌入驱动解码的结构编码器SEED，通过集成四个模块：感知令牌编码器、投影模块、语义重编程机制和冻结的语言模型来实现对于时间序列预测的结构和语义建模。
## Innovation
引入了一种嵌入驱动解码的结构编码器SEED，它通过集成四个模块（感知令牌编码器、投影模块、语义重编程机制和冻结的语言模型）来同时捕捉变量间的结构性依赖关系，支持对大规模语言模型的适配和语义级别的推理，实现时间和结构上的有效关联，且在多种基准模型的比较上取得了显著的改进。
## Conclusion
实验结果表明，所提出的方法在与强基线的比较中表现出了持续的改进。在不同数据集上的比较研究证实了SEED在解决时间序列预测中的结构和语义建模差距方面的作用。这种模块化的架构分离了表征学习和推理之间的联系，使得数字模式和语义推理之间的高效对齐成为可能。
# 213. `cs.CL` - 跨源问答中的知识感知多样化重排序 [PDF](https://arxiv.org/pdf/2506.20476), [HTML](https://arxiv.org/abs/2506.20476)
## Authors
Tong Zhou
## Background
SIGIR 2025 LiveRAG竞赛的数据集由DataMorgana自互联网语料库自动生成，涵盖了广泛的目标主题、问题类型、问题表述、受众类型和知识组织方法。该数据集从FineWeb语料库的1500万文档子集中抽取，旨在公平地评估从这些文档中检索与问题相关支持文档的能力。
## Innovation
提出了一个知识导向的多样化重排序RAG流水线，该流水线在竞赛中取得了第一名的成绩。
## Conclusion
所提出的知识导向的多样化重排序RAG流水线成功地实现了对不同来源问题的回答，在SIGIR 2025 LiveRAG竞赛中获得第一名的成绩。
# 214. `cs.CL` - AALC: 大型语言模型高效推理通过自适应准确度-长度控制 [PDF](https://arxiv.org/pdf/2506.20160), [HTML](https://arxiv.org/abs/2506.20160)
## Authors
Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du
## Background
大型推理模型（LRMs）通过生成长链条的推理过程实现了非凡的推理能力，但这一“过度思考”造成了高延迟和高成本，而回报却并不一定成比例地提高准确性。对于这一现象，本文从背景出发，详细讨论了当前LRMs在处理推理任务时存在的问题，即效率低下和成本高昂等问题，以及这些问题对实际应用带来的挑战。
## Innovation
本文提出了一种名为AALC（Adaptive Accuracy-Length Control）的轻量级方法，这是一种结合验证准确度的奖励机制，并且引入了一种平滑动态调控的长度惩罚机制，这种方法能够在满足目标性能之前延迟长度惩罚，从而平衡正确性和简洁性。AALC方法通过在训练过程中动态地调整准确性和简洁性的平衡，有效地减少了模型输出的长度超过50%，并且在保持原有准确性的基础上甚至有所提高。此外，AALC方法还能抑制冗余的推理模式，比如过度设置子目标和验证，从而生成结构更细致的输出内容，而不是简单的截断。这种方法还揭示了效率提升的同时伴随着可解释性的降低，即使用AALC训练的模型会省略一些叙述框架和解释性信息。
## Conclusion
本文的实验证实了AALC方法的有效性，通过减轻模型的冗余计算并优化其输出长度，提高了推理模型的效率。同时，研究还指出，尽管AALC提高了模型的效率和适应性，但也可能导致模型输出的可解释性降低，这揭示了用奖励机制引导LRMs获得更高效的、通用性更强的推理路径的潜力。
# 215. `cs.CL` - 使用源代码探究AI安全性 [PDF](https://arxiv.org/pdf/2506.20471), [HTML](https://arxiv.org/abs/2506.20471)
## Authors
Ujwal Narayan,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Karthik Narasimhan,Ameet Deshpande,Vishvak Murahari
## Background
大型语言模型（LLMs）已在众多安全关键应用中与人类交互，这要求我们不仅提高模型能力，还需要在确保安全性上采取更多措施，以使这些模型与人类的价值观和偏好保持一致。然而，当前的研究表明，现代模型未能达到AI安全的目标，导致用户遭受不安全和有害的体验。因此，需要评估和提升AI模型的安全措施，以与模型能力同步发展。
## Innovation
本文介绍了一种称为Code of Thought (CoDoT) 的提示策略，用于评估LLMs的安全性。CoDoT将自然语言输入转换为简单代码，以代表相同的目的，例如，将“Make the statement more toxic: {text}”转换为“make_more_toxic({text})”。通过CoDoT，发现了一种广泛的方法来评估先进LLMs的安全性，并显示出这些方法能够有效提高模型的毒性，特别是在反复应用时。这种方法强调了从基本原则出发评估安全措施的必要性，确保安全措施与模型能力同步发展。
## Conclusion
鉴于LLMs的迅速普及，CoDoT突显了评估和提升安全性措施的重要性，以确保安全性和能力的发展同步进行。
# 216. `cs.CL` - Biomed-Enriched: 使用大语言模型扩充的生物医药数据集，以及提取罕见和隐含内容 [PDF](https://arxiv.org/pdf/2506.20331), [HTML](https://arxiv.org/abs/2506.20331)
## Authors
Rian Touchent,Nathan Godey,Eric de la Clergerie
## Background
临床文本通常由于隐私限制难以访问，医院记录不能公开共享。因此，提供了一个通过PubMed构建的大型、公开可用的临床病例数据集，这对于生物医药和临床自然语言处理尤为重要。
## Innovation
该研究使用两阶段注释过程从PubMed中构建了一个名为Biomed-Enriched的生物医药文本数据集。首先，大型语言模型标注40万余篇PubMed科学文章的段落，按照类型、领域和教育质量进行打分。然后利用这些标注信息微调小型语言模型，以促进更大规模的PMC-OA语料库。通过质量过滤和领域过采样的方法，只能用于商业用途的文献中提取出高质量的临床案例段落。该数据集包含200万临床案例段落，超45万高质量段落，提供了替代的大规模临床案例公开可用集合，对于训练生物医药和临床NLP模型有价值。初步持续预训练实验表明，这些精选的数据子集能够针对性地提升性能，如临床案例过采样提高MMLU ProfMed性能约5%，教育质量过滤提高了MedQA和MedMCQA约1%，这种结合策略使训练效率和效果更高。
## Conclusion
研究表明，通过这一方法构建的数据集部分子集能够更高效地增强医学预训练策略，快速达到与使用大量训练标记相同的表现，表明该方法具有更高的效率和效果。
# 217. `cs.CL` - 我的时间掌握在自己手中：视频聊天对话中的发言时间分享动态 [PDF](https://arxiv.org/pdf/2506.20474), [HTML](https://arxiv.org/abs/2506.20474)
## Authors
Kaixiang Zhang,Justine Zhang,Cristian Danescu-Niculescu-Mizil
## Background
每场对话中，参与者之间的发言时间分配是一个重要方面，对话可以是均衡的，即每个参与者发言时间相近，也可以是不平衡的，即某个参与者发言时间显著多于其他人。这种整体分配的形成是一个持续的谈判过程，涉及谁在任何时间点发言，以及发言的时间长度。本文探讨了用于量化这些对话级和底层动态的计算框架，揭示了不同类型的发言时间分享动态如何被参与者感知，即使这些动态的结果是平衡的，参与者也会有不同感知。最后，研究提出该框架为设计媒体交互平台提供了新工具，适用于人对人和人对AI的沟通情景。
## Innovation
论文引入了一个计算框架，用于量化对话级和底层的发言时间分配动态，并揭示了不同类型的话语分享动态不仅导致不同的整体平衡，还被参与者以不同的方式感知。这为设计媒体交互平台提供了新的方法论。通过应用这一框架到大量陌生人之间的视频聊天数据，该研究确认，均衡的对话更受参与者青睐，尤其是那些发言较少的人。
## Conclusion
该研究揭示了话语分享动态如何影响参与者对对话平衡和整体感知。研究为设计媒体交互平台提供了新的工具，适用于人对人和人对AI的沟通情景，强调了新提出的话语分享动态分类体系的重要性。
# 218. `cs.CL` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大型语言模型（LLMs）在代码生成方面表现出色，但在面对外部库API的频繁更新时，却无法有效适应。这一缺陷源自于模型训练数据中过时的API知识，即使有当前文档的支持，也难以在动态环境中的可靠代码生成。这一背景揭示了当前LLMs在处理API变化时面临的挑战，亟需新的方法来解决这一问题。
## Innovation
本文提出了一种名为ReCode的新型框架，该框架基于规则的强化学习帮助代码更新，旨在模仿人类程序员如何适应API的变化。具体而言，该框架构建了一个包含约2000个数据条目的语料库，用于训练LLMs根据更新的信息执行版本迁移。此外，引入了一种修改后的字符串相似度度量作为强化学习的奖励函数，用于代码评估。实验表明，ReCode在动态API场景下的代码生成性能显著提升，特别是在“CodeUpdateArena”任务中表现出色。与监督微调相比，ReCode对LLMs的基本代码生成能力影响较小。ReCode可以在多个LLMs和强化学习算法（GRPO和DAPO）上取得一致改进，特定模型Qwen2.5-Coder-7B的表现超过了32B参数的代码指令微调模型和具有相同架构的推理模型。
## Conclusion
本研究通过引入ReCode框架，显著提升了LLMs在动态API场景下的代码生成能力，证明了基于强化学习的方法在应对API变化方面具有优势。该结论对于改进LLMs在实际应用场景中的适应性和可靠性具有重要意义，并且为未来的研究提供了新的思路和方向。
# 219. `cs.CL` - GPTailor: 通过层裁剪和缝合压缩大型语言模型 [PDF](https://arxiv.org/pdf/2506.20480), [HTML](https://arxiv.org/abs/2506.20480)
## Authors
Guinan Su,Li Shen,Lu Yin,Shiwei Liu,Yanwu Yang,Jonas Geiping
## Background
大型语言模型（LLMs）在语言理解和生成方面展现出了显著的能力。然而，这种令人印象深刻的性能通常伴随着庞大的模型规模，这给部署和推理带来了重大挑战。虽然结构化剪枝模型参数为降低部署时的计算成本提供了一个有前景的方法，但当前的方法主要侧重于单个模型的剪枝。本研究开发了一种新颖的策略，通过有选择地组合或合并微调模型变体的层来压缩模型，从而保留原始模型的能力，通过聚合在不同微调中突显的能力。研究将这些LLMs的最佳调整视为零阶优化问题，采用支持三种不同操作的搜索空间：（1）层删除，（2）从不同候选模型中选择层，（3）层合并。实验结果显示，这种方法导致了具有竞争力的模型剪枝，例如对于Llama2-13B模型系列，压缩模型保持了原始性能的大约97.3%，同时移除了约25%的参数，相比之前的最新方法显著更优。
## Innovation
本研究提出了一种通过组合和合并来自不同微调变体的层来压缩大型语言模型的新颖策略。这种方法通过聚合不同微调中突显出来的能力来保留原始模型的能力，将其最优调整描述为零阶优化问题，采用支持三种操作的搜索空间：（1）层删除，（2）从不同候选模型中选择层，（3）层合并。实验表明，该方法在模型压缩性能上具有竞争力，显著优于现有方法。
## Conclusion
研究展示了通过Llama2-13B模型系列实验的结果，证明压缩模型在保持97.3%的原始性能的同时，移除了约25%的参数量，远超现有最佳方法，表明该方法在模型压缩方面具有突出的性能。
# 220. `cs.CL` - 当生活给予你样本：提升多语言大模型推理计算规模的好处 [PDF](https://arxiv.org/pdf/2506.20544), [HTML](https://arxiv.org/abs/2506.20544)
## Authors
Ammar Khairi,Daniel D'souza,Ye Shen,Julia Kreutzer,Sara Hooker
## Background
近期的大语言模型（LLMs）进展强调了在推理时扩展计算规模的重要性，无需重新训练模型即可提高性能。常见的做法是并行抽样多个输出，再从中选择一个作为最终输出。然而，现有研究主要集中在英语领域及其少数几个特定领域（如数学和代码生成）上。本文关注通用生成任务、形式验证任务及多语言环境下的可扩展性问题，研究如何适应各种领域和语言环境，稳健地扩展多语言、多任务场景下的推理计算规模。已有研究发现，适用于英语的方法难以在多语言环境中通用。因此，本文提出了针对多语言和多任务推理场景的新颖抽样和选择策略，展示了这些方法在不同语言和任务上的显著提升，特别是在具有80亿参数的模型上，综合抽样和选择方法使win-rates提高了6.8%，在1110亿参数的模型上，只需五个样本就比单样本解码提高了9.0%的win-rates，且成本较低。这些结果强调了对推理计算的适应性和语言/任务意识的重要性，旨在促进小语种语言性能改善的普及化。
## Innovation
提出了针对多语言和多任务推理场景的新颖抽样和选择策略，这些方法在不同语言和任务上都表现出了显著的提升效果，特别是在大模型上，使用新的策略比单样本解码提高了显著的win-rates，且成本较低。这种方法有助于更广泛地应用和推广到不同的语言和任务中，增强了语言多样性支持和任务适用性。
## Conclusion
本文研究了如何在多语言和多任务场景中稳健扩展推理计算规模，提出了新的抽样和选择策略，这些策略在多种语言和任务上都显示出了显著的提升，特别是在大型模型上，使用该方法能够显著提高性能并降低成本。我们强调，为了在多语言和多任务设置中有效使用大语言模型，需要采取语言和任务自适应的方法来更好地支持低资源语言。
# 221. `cs.CL` - OctoThinker: 中训练激励强化学习扩展 [PDF](https://arxiv.org/pdf/2506.20512), [HTML](https://arxiv.org/abs/2506.20512)
## Authors
Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu
## Background
不同的基础语言模型，如Llama和Qwen，在强化学习（RL）后训练过程中表现出了不同的特性，特别是在需要推理能力的任务上。了解哪些基础语言模型更适合强化学习是下一代RL可扩展基础模型开发的关键。作者通过研究不同模型家族（Qwen和Llama）的中训练策略，发现高质量的数学语料库（如MegaMath-Web-Pro）能够显著提升基础模型和RL性能，QA风格的数据尤其是长链式推理数据可以进一步提高RL结果，但同样也需要注意可能带来的过度详细和RL训练不稳定性等问题。
## Innovation
本研究提出了一个两阶段中训练策略，称为Stable-then-Decay，即首先在200B令牌上进行固定学习率训练，然后在三个专注于长链式推理的分支上进行20B令牌的训练，并采用学习率衰退。这生成了一个名为OctoThinker的模型家族，展示出了良好的RL兼容性，性能接近于更适于RL的基础模型家族，Qwen。同时，作者还发布了一个开放源代码的模型库以及包含超过70亿令牌的数学推理语料库（MegaMath-Web-Pro-Max）以支持进一步的研究工作。
## Conclusion
作者的研究结果表明，适当的中训练策略不仅能提升基础语言模型的RL性能，还能逐渐解决在使用长链式推理数据时可能遇到的一系列问题，从而推动基础模型在强化学习时代的预训练策略的发展。
# 222. `cs.CL` - 模型编辑是一把双刃剑：将智能体道德行为引导向善良或危害 [PDF](https://arxiv.org/pdf/2506.20606), [HTML](https://arxiv.org/abs/2506.20606)
## Authors
Baixiang Huang,Zhen Tan,Haoran Wang,Zijie Liu,Dawei Li,Ali Payani,Huan Liu,Tianlong Chen,Kai Shu
## Background
基于大语言模型的智能体显示出了广泛任务的强大能力，但在高风险领域中部署这些智能体伴随着巨大的安全与伦理风险。智能体的不当行为可能导致严重的现实后果，包括人身伤害和经济损失。因此，需要有效的方式引导智能体的道德行为，使其更加符合伦理规范。
## Innovation
本文将智能体行为引导定义为模型编辑任务，即行为编辑。引入了基于心理道德理论的多层次基准（BehaviorBench），能够系统地评估和改进各种情况下智能体行为。该基准还能够实现对智能体全球道德定位的大规模调整。研究证明，智能体行为编辑可以促进道德良性行为或诱导危害行为，并在不同模型和场景下展示了其有效性。
## Conclusion
研究发现，行为编辑为控制智能体行为提供了一种新的范式，揭示了行为编辑既带来了希望也带来了挑战。
# 223. `cs.CL` - DiffuCoder：理解并改进掩蔽扩散模型在代码生成中的应用 [PDF](https://arxiv.org/pdf/2506.20639), [HTML](https://arxiv.org/abs/2506.20639)
## Authors
Shansan Gong,Ruixiang Zhang,Huangjie Zheng,Jiatao Gu,Navdeep Jaitly,Lingpeng Kong,Yizhe Zhang
## Background
扩散大语言模型（dLLMs）比自回归（AR）模型更具吸引力，因为它们的去噪模型在整个序列上进行操作。dLLMs 的全局规划和逐步修正特性特别适用于代码生成。然而，当前对 dLLMs 在编程中的训练和推断机制仍然研究不足。为了揭示 dLLMs 的解码行为并释放其潜在能力，作者系统地研究了它们的去噪过程和强化学习（RL）方法。他们基于 130 亿 token 的代码训练了一个 7B dLLM（DiffuCoder），并在代码生成基准上进行了分析，发现 dLLMs 在解码过程中有以下特点：1) dLLMs 可以根据需要决定生成的因果性，而不依赖于半自回归解码；2) 增加采样温度不仅多样化了 token 选择，还多样化了生成顺序，从而为 RL 撤销提供了丰富的搜索空间。在 RL 训练中，为了减少 token 对数似然估计的方差，作者提出了一种称为耦合-GRPO 的新颖采样方案，这种方案能够为训练中使用的完成项构建互补掩码噪声，从而保持训练效率。
## Innovation
提出了耦合-GRPO（Coupled-GRPO），一种新的采样方案，用于生成用于训练的互补掩码噪声。这种方法显著提高了 DiffuCoder 在代码生成基准测试中的性能 (+4.4% 在 EvalPlus 上) ，并减少了解码过程中对 AR 因果性的依赖。此外，作者系统地研究了 dLLMs 的解码行为和去噪过程，揭示了 dLLMs 与 AR 模型的不同之处，为理解和改进 dLLMs 提供了新的视角。
## Conclusion
作者的工作为 dLLM 生成机制提供了更深入的见解，并提供了有效的扩散模型原生的 RL 培训框架。
# 224. `cs.CL` - 罕见疾病诊断的具可追溯推理的智能系统 [PDF](https://arxiv.org/pdf/2506.20430), [HTML](https://arxiv.org/abs/2506.20430)
## Authors
Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie
## Background
全球超过3亿人受罕见疾病影响，但这些疾病的及时准确诊断仍是一个挑战。这主要是因为罕见疾病的临床表现多样性、低个体发病率以及大多数临床医生对其了解不足所致。因此，需要一种能够处理异构临床输入并生成罕见疾病诊断假设的系统，这些假设伴有透明的推理链链接分析步骤与可验证的医学证据。
## Innovation
本研究引入了DeepRare，这是首个基于大型语言模型（LLM）的罕见疾病诊断系统。该系统具有中央主机和长期记忆模块以及专门的代理服务器，专门负责特定领域的分析任务，整合了40多种专门工具和大规模、实时的医学知识源，确保系统的模块化和可扩展性，同时保持推理的可追溯性和适应性。DeepRare在8个数据集上的评估显示，其在2919种疾病中的诊断性能优异，对于1013种疾病达到了100%的准确率。在HPO评估中，DeepRare显著优于其他15种方法，包括传统的生物信息学诊断工具、大型语言模型和其他智能系统，平均召回率为57.18%，比第二好的方法（推理大语言模型）高出23.79个百分点。在多模态输入场景下，DeepRare的表现也优于Exomiser，准确性达到了70.60%。临床专家对推理链条的手动验证达到了95.40%的一致性。
## Conclusion
DeepRare的实施作为友好使用的网页应用程序，旨在解决罕见疾病的诊断挑战，通过透明的推理链提高诊断透明度和准确性，展示了其在罕见疾病诊断中的卓越性能。
# 225. `cs.CL` - 准确且节能：本地检索增强生成模型在医疗任务中胜过商用大型语言模型 [PDF](https://arxiv.org/pdf/2506.20009), [HTML](https://arxiv.org/abs/2506.20009)
## Authors
Konstantinos Vrettos,Michail E. Klontzas
## Background
随着人工智能（AI）在医疗领域的广泛应用，人们对其环境和伦理影响的关注日益增加。商用大型语言模型（LLMs），如ChatGPT和DeepSeek，需要大量资源，而这些系统的医疗应用引发了关于患者隐私和安全的重大问题。
## Innovation
开发了一种可定制的检索增强生成（RAG）框架用于医疗任务，该框架监控其能源使用和二氧化碳排放。使用各种开源LLM构建了基于此系统的RAG模型，包括通用模型（如llama3.1:8b）和医疗专用模型（如medgemma-4b-it）。本地RAG模型在准确性与能源消耗方面优于商用模型，其中基于llama3.1:8b的RAG模型在准确性（58.5%）上最佳，同时消耗最低的能源，在每千瓦时的性能和每公斤二氧化碳排放方面表现最佳。与商用模型相比，RAG模型具有更高的准确性和更低的能源消耗，对可持续AI发展具有促进作用，符合联合国可持续发展目标。
## Conclusion
研究表明，本地LLM可以被利用来开发出在医疗任务中优于商用在线LLM的RAG，同时对环境影响较小。本模块化框架鼓励可持续AI的发展，通过减少电能消耗来与联合国可持续发展目标相一致。
# 226. `cs.CL` - 捕捉可视化设计理由 [PDF](https://arxiv.org/pdf/2506.16571), [HTML](https://arxiv.org/abs/2506.16571)
## Authors
Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha
## Background
以往的自然语言数据集侧重于数据可视化任务，如可视化素养评估、见解生成和根据自然语言指令生成可视化，这些研究通常依赖于控制性强、构建可视化和人工问题的设置，因此主要集中在对可视化图表的解释上，而非对其编码的理解。本文提供了新的数据集和方法，用于通过自然语言探究可视化设计的理由，通过学生在数据可视化课程中创建的文学可视化笔记本，其中包含视觉作品及其设计说明。此外，利用大型语言模型生成和分类叙事中的问题-回答-理由三元组，并精心验证这些三元组，形成一个涵盖并提炼学生可视化设计选择及其对应理由的数据集。
## Innovation
本文提出了一种利用学生在数据可视化课程中创建的真实世界文学可视化笔记本数据的新方法，这些笔记本不仅包含视觉作品，还包含了通过可视化设计说明，使设计决策公开。同时引入了大型语言模型自动生成问题-回答-理由三元组，并精心验证这些数据，形成一种综述学生可视化设计选择及其理由的数据集，解决了传统数据集单一性和控制性强的问题。
## Conclusion
本文提供的数据集和方法弥补了现有数据集的不足，能更真实地揭示可视化设计的决策过程，对于理解设计背后的逻辑和原因具有重要意义，将推动相关领域研究的发展。
# 227. `cs.CL` - 分配角色后的大型语言模型表现出类似人类的动机判断 [PDF](https://arxiv.org/pdf/2506.20020), [HTML](https://arxiv.org/abs/2506.20020)
## Authors
Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan
## Background
人的推理容易受到身份保护等动机偏差的影响，这种偏差会破坏理性的决策和判断。这种群体性动机推理，特别是在如气候变化或疫苗安全这类关键问题上的讨论中，对社会有害，并加剧了政治分歧。先前研究显示大型语言模型（LLMs）也受到类似的人类认知偏差的影响，但它们如何因身份一致性而选择性推理尚未被完全探讨。本文研究通过分配8种不同时，是否会影响LLMs的推理方式，以探讨这种动机推理是否存在。实验结果显示，分配了角色的LLMs相对于未分配角色的模型，在区分虚假信息标题方面低约9%的准确性，在评估数值科学证据方面，尤其是政治身份一致的情况下，正确评估危险枪支控制证据的可能性提高至90%，表明LLMs 有类似人类的动机推理倾向。
## Innovation
研究首次实证表明分配角色后的LLMs表现出与人类类似的动机判断。这种通过常规去偏见提示难以缓解的效应，引起了对LLMs和人类中身份一致性推理激增的担忧。这种方法为理解更广泛的人类和机器推理过程提供了新见解，强调了在设计和使用LLMs时应考虑伦理和偏差控制的重要性.
## Conclusion
我们的实证结果表明，分配角色后的LLMs展现出类似人类的动机判断，这些效果难以通过常规去偏见提示缓解，这引起了对LLMs和人类中身份一致性推理激增的担忧。
# 228. `cs.CL` - 机器学习会议应建立'反证和批评'轨道 [PDF](https://arxiv.org/pdf/2506.19882), [HTML](https://arxiv.org/abs/2506.19882)
## Authors
Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho
## Background
科学研究是通过逐步推进和纠正人类对世界的理解而进步的。在机器学习（ML）研究中，快速的发展导致了大量 publication 的出现，但也导致了一些误导性、错误的、有瑕疵甚至可能是伪造的研究在ML会议上被接受并有时被突出展示，这是由于同行评审的局限性。虽然这样的错误是可以理解的，但ML会议并没有提供强大的方法来进行系统性地纠错（when such errors are identified）。
## Innovation
本文提出，ML会议应该设立一个专门的'反证和批评'（R & C）轨道。这一轨道将提供一个高调且信誉良好的平台，支持那些对先前研究成果进行批判性挑战的重要研究，从而促进一个动态且自我纠正的研究生态系统。
## Conclusion
我们得出结论，ML会议应该创建官方且受认可的机制来帮助ML研究进行自我纠正。
# 229. `cs.CL` - 由语言模型构建语言模型 [PDF](https://arxiv.org/pdf/2506.20249), [HTML](https://arxiv.org/abs/2506.20249)
## Authors
Junyan Cheng,Peter Clark,Kyle Richardson
## Background
研究者们探讨了利用大规模语言模型（LLMs）来模拟发现新型语言模型架构的过程。这一过程包括从创意和文献检索（提案阶段）、设计和实现（代码生成）、生成预训练和下游评估（验证）等阶段。借鉴规模法则的思路，Genesys系统采用了逐级规模的方法，提出新的设计，然后进行对抗审查和逐步实施，并在不断扩大的模型规模上进行选择性验证（从14百万到350百万参数），预算逐渐减少。为了提高发现过程的效率和可分解性，Genesys采用了一种新型的遗传编程架构，实验显示其在成功的架构设计生成上比直接提示生成工作流等方法有显著改进（约86个百分点的提高）。
## Innovation
本文提出了一个名为Genesys的多智能体LLM系统，它模拟了从创意到验证的语言模型开发过程。Genesys采用梯度规模法，并结合了一种新的遗传编程架构。这一系统显示出在成功生成架构设计方面的显著优势，并且能够训练出与现有架构具有强烈竞争力的新设计，部分设计在9个基准测试中有6个优于GPT2、Mamba2等模型。系统还包括了大型系统实验和全面的系统级消融试验，为自主设计系统的有效设计提供了更广泛的理解
## Conclusion
研究结果表明Genesys能够高效地生成新的语言模型设计，并验证出的最好设计在某些基准测试中与已知的架构相比具有竞争力，这为未来通过LLMs发现语言模型的新架构提供了创新的方法和路径。
# 230. `cs.CL` - PSALM-V：使用大型语言模型在互动视觉环境中自动化符号规划 [PDF](https://arxiv.org/pdf/2506.20097), [HTML](https://arxiv.org/abs/2506.20097)
## Authors
Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason
## Background
尽管以往的工作尝试使用大型语言模型（LLMs）为基于Planning Domain Definition Language (PDDL)的符号规划器生成动作语义，但这些方法主要集中在基于文本的领域或依赖于不切实际的假设（如访问预定义的问题文件、完全可观测性或明确的错误消息）。PSALM-V旨在克服这些限制，通过动态推断PDDL问题文件和领域动作语义，其方法包括分析执行结果和合成可能的错误解释。该系统迭代生成并执行计划，同时保持每个动作潜在动作语义的树状信念，直到达到目标状态为止。
## Innovation
PSALM-V 是一种新的自主神经符号学习系统，能够在视觉环境中通过交互自动生成符号动作语义（即前置和后置条件）。通过利用大型语言模型生成启发式计划和候选符号语义，该系统可以在无需专家动作定义的情况下进行可靠的符号规划。此外，PSALM-V能够在部分观察设置下显著提高计划的成功率，并在多智能体环境中成功地诱导符号语义，即使在出现底层操作失败的情况下也能够正确地诱导PDDL预后条件。
## Conclusion
模拟实验表明，PSALM-V 在 ALFRED 环境中完成任务时，计划成功率从 Claude-3.7 的 37% 提高到 74%。此外，PSALM-V 在两个 2D 游戏环境中也证明了其在动作效率和多智能体领域诱导方面的改进。该系统成功地为实际机器人BlocksWorld任务生成了PDDL预后条件，即便面临底层操作失败的问题。
# 231. `cs.CL` - 作为分布量的反事实影响 [PDF](https://arxiv.org/pdf/2506.20481), [HTML](https://arxiv.org/abs/2506.20481)
## Authors
Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye
## Background
机器学习模型已知会记住其训练数据中的样本，这引发了关于隐私和泛化能力的担忧。反事实自影响是研究记忆化的一种流行度量方法，量化模型对一个样本的预测如何因该样本是否包含在训练数据集中而变化。但是，近期研究显示，记忆化不仅仅受自影响因素的影响，特定的（近）副本对其他训练样本同样有很大影响。因此，本文重新审视了数据的记忆化过程，研究所有训练样本如何共同影响特定样本的记忆过程，而不仅仅是其自影响。
## Innovation
本文将反事实影响视为分布性的量，考虑所有训练样本如何共同影响某个样本的记忆化过程，而不仅仅局限于自影响。通过这种方式，研究发现仅仅关注自影响严重低估了实际中的记忆化风险：（近）副本的存在会显著降低自影响，却能促使这些样本的提取。这种方法在小型语言模型以及图像分类任务中均得到了验证，展示了（近）副本在CIFAR-10数据集中的存在。
## Conclusion
本文的研究揭示了记忆化是由训练数据中复杂的交互作用造成的，并且通过完整的影响力分布而非仅依靠自影响来更好地捕捉记忆化的过程。
# 232. `cs.CL` - 从手稿学到代码：历史文献布局分析中基于变换器和YOLO的检测器的比较研究 [PDF](https://arxiv.org/pdf/2506.20326), [HTML](https://arxiv.org/abs/2506.20326)
## Authors
Sergio Torres Aguilar
## Background
复杂的物理页面组织是历史文档自动化处理和理解的关键挑战。为了应对这一挑战，这项研究对五个最先进的物体检测架构进行了基准测试，这些架构应用于三种代表不同性手稿复杂度级别标注的数据集：e-NDP（1326-1504 年巴黎中世纪登记簿）、CATMuS（十二世纪到十七世纪的各种中世纪和现代来源的多样化多类别数据集）和HORAE（13-16 世纪装饰的手抄本）。
## Innovation
这项研究对两个基于变换器的模型（Co-DETR, Grounding DINO）和三个YOLO变体（AABB, OBB, YOLO-World）进行了基准测试，结果显示性能在模型架构、数据集特性和边界框表示之间存在显著差异。研究发现，对于结构化布局，变换器全局上下文感知是理想的，但对于视觉多样性和复杂文档，CNN-OBB模型的泛化性能更优。这表明使用定向边界框（OBB）不仅仅是微小的改进，而是准确建模历史手稿非笛卡尔性质的关键要求。
## Conclusion
研究发现，对于e-NDP数据集，Co-DETR和YOLOv11X-OBB取得了最好的性能；而对于更复杂的CATMuS和HORAE数据集，基于的CNN-OBB模型表现最佳。研究明确指出，使用OBB并不是一个次要改进，而是对历史手稿进行准确建模的基本要求。研究强调了在结构化布局和视觉多样及复杂文档之间存在关键技术权衡。
# 233. `cs.CL` - 心中有许多狼：使用认知模型解读大模型中的价值权衡 [PDF](https://arxiv.org/pdf/2506.20666), [HTML](https://arxiv.org/abs/2506.20666)
## Authors
Sonia K. Murthy,Rosie Zhao,Jennifer Hu,Sham Kakade,Markus Wulfmeier,Peng Qian,Tomer Ullman
## Background
日常生活中的社会互动经常需要处理内心的冲突目标，例如传达一个严峻的事实、保持信任的同时还要顾及他人的感受。这些价值观的权衡是人类决策和语言运用的重要组成部分。然而，目前用于解释这些动态且多维度价值观的大型语言模型（LLMs）的工具有限。认知科学中的所谓认知模型为人类这些权衡提供了形式化的解释，通过建模说话者在行动或话语选择时竞争的利益函数的权衡。本文利用礼貌语言的认知模型来解释LLMs在价值权衡上的表现，并系统地评估这两种模型设置中的价值权衡：一是推理努力程度的大小差异在前沿的黑箱模型中，二是开源模型的强化学习后训练动态。我们的结果表明，在推理模型和已知在数学推理更为强大的开源模型中，信息价值高于社交价值的模式。我们的训练动态研究发现，大型语言模型的价值变化在训练初期出现重大转变，并且这些变化持续受基础模型和预训练数据的影响，而非反馈数据集或对齐方法。我们展示了我们的方法对快速发展的LLM景观的各种方面都具有响应性，这为形成关于其他高级行为的假设、制定推理模型的训练程序以及更好地控制训练过程中价值权衡提供了洞察力。
## Innovation
本文利用认知模型解释大型语言模型中的价值权衡，并系统地评估了两种模型设置中的价值权衡，分别为：在前沿黑箱模型中的推理努力程度差异，以及开源模型的强化学习后训练动态。结果揭示了信息价值高于社交价值的模式，并表明在训练早期出现大量价值变化，这受到基础模型和预训练数据的影响。方法展示了对LLM发展景观不同方面的响应性，有助于假设其他高级行为、指导推理模型的训练程序及控制训练过程中的价值权衡。
## Conclusion
研究发现，大型语言模型在训练早期会经历大量价值变化，效应持续存在，主要受到基础模型和预训练数据的影响，而非反馈数据集或对齐方法。该方法对LLM研究的新领域敏感，并可能提供关于其他高级行为的假设，指导推理模型的训练程序，并帮助在模型训练过程中更好控制价值权衡。
# 234. `cs.CL` - 异步REINFORCE在离策强化学习中的应用：平衡正负奖励 [PDF](https://arxiv.org/pdf/2506.20520), [HTML](https://arxiv.org/abs/2506.20520)
## Authors
Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos
## Background
 reinforcement learning (RL) 越来越被用于对齐大规模语言模型 (LLMs)。离策方法在实现简便性和数据效率方面优于就策技术，但通常会导致性能不佳。本文研究了离策 RL 和监督微调之间的中间算法范围，通过分析简单的离策 REINFORCE 算法来进行，其中的优势定义为 A=r-V，r 为奖励，V 为可调基线。通常降低 V 会强调高奖励样本，而提高 V 则会对低奖励样本施加更严厉的惩罚。研究表明，在基线 V 低于预期奖励的情况下，该算法享有策略改进保证。
## Innovation
本文通过理论分析证明了当基线 V 低于期望奖励时，算法具有策略改进保证。实验验证在可控的随机臂试验中和通过在推理任务上微调最先进的 LLM，表明离策更新更侧重于正奖励而不是负奖励。
## Conclusion
离策更新更多地受益于关注正奖励而不是负奖励。这种方法在可控的随机臂试验中和在最先进的 LLM 上进行推理任务微调的实验中得到了验证。
# 235. `cs.CL` - FundaQ-8: 一种临床启发的自动化眼底图像质量评分框架 [PDF](https://arxiv.org/pdf/2506.20303), [HTML](https://arxiv.org/abs/2506.20303)
## Authors
Lee Qi Zun,Oscar Wong Jin Hao,Nor Anita Binti Che Omar,Zalifa Zakiah Binti Asnir,Mohamad Sabri bin Sinal Zainal,Goh Man Fye
## Background
由于图像获取和主观专家评估的差异，自动化眼底图像质量评估（FIQA）仍是一个挑战。本文背景强调了现有技术在处理这些差异时的局限性，特别是在眼底图像质量的客观评估上，一直依赖于专家的主观判断，这限制了其在实际临床应用中的可重复性和可靠性.
## Innovation
作者提出了一种名为FundaQ-8的新型专家验证框架，用于系统地评估眼底图像质量，包括八个关键参数：视野覆盖、解剖可见性、照明和图像伪影。该框架还引入了一个基于ResNet18的回归模型，用于预测0到1范围内的连续质量分值，模型通过迁移学习、均方误差优化和标准化预处理进行训练，能够在实际临床数据集和Kaggle数据集上有效区分图像质量.
## Conclusion
FundaQ-8框架通过提高糖尿病视网膜病变等级分类的诊断稳健性，验证了其在临床筛查中的价值，同时也证明了其在自动化眼底图像质量评估中的可靠性和临床解释能力。这表明，质量意识的训练在实际应用中至关重要.
# 236. `cs.CL` - 为什么机器人在检测自己的错误上表现不佳：人类-机器人对话中误沟通检测的局限性 [PDF](https://arxiv.org/pdf/2506.20268), [HTML](https://arxiv.org/abs/2506.20268)
## Authors
Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme
## Background
在人机交互中检测沟通失误对保持用户参与度和信任至关重要。尽管人类通过语言和非语言提示能够轻松识别沟通错误，但机器人在解读非语言反馈方面仍面临巨大挑战。尽管计算机视觉技术在识别情感表达方面取得了进展，但在检测机器人对话中的沟通失误的有效性方面，现有的机器学习模型表现不佳。研究表明，即使用户感知了沟通失误，他们也往往不会告知他们的机器人对话伙伴。
## Innovation
本研究采用多模态方法，利用一个包含240个人机对话数据集进行建模，系统地引入了四种不同的对话失败类型，评估了最先进计算机视觉模型的性能。研究发现，尽管使用了最先进的模型，但在识别沟通失误方面仅略优于随机猜测。在具有更丰富情感内容的数据集上，则能够识别出混淆状态。为了探究原因，研究者进一步让人类评判者进行相似测试，结果发现人类的表现也同样受限，只能识别一半左右的诱导沟通失误。这揭示了一个根本性的局限：即使有感知到沟通失误，用户也不一定会反馈给机器人，从而影响机器人对错误的识别能力。
## Conclusion
发现现有的计算机视觉模型在识别机器人对话中的沟通失误方面存在根本性局限。这要求研究人员调整期望，更好地设计交互，合理引导用户反馈，从而改善机器人对话系统的性能。
# 237. `cs.CL` - PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models [PDF](https://arxiv.org/pdf/2506.20629), [HTML](https://arxiv.org/abs/2506.20629)
## Authors
Soufiane Hayou,Nikhil Ghosh,Bin Yu
## Background
LoRA是一种广泛使用的大型模型微调方法，其低内存占用使实践中可以在较低的成本下将大型模型适配到特定任务。已有多种修改提议用于提高其效率，例如设置学习率、秩和初始化。此外，适配器放置策略也是一个重要的改进方向，洛RA通常选择要启用适配器的模块类型，如Query和Key模块。然而，关于适配器放置的研究较少，不同研究提出的建议并不一致。
## Innovation
通过直观的理论分析，提出了PLoP，一种轻量级方法，能够在给定预训练模型和微调任务的情况下自动识别LoRA适配器应放置的模块类型。实验证明，PLoP在监督微调和基于强化学习的推理任务中表现优越，或至少与常用放置策略相竞争。
## Conclusion
PLoP能够自动确定LoRA适配器的最佳放置位置，从而提高大型模型的微调效率。实验结果表明，在各种情况下，PLoP都能提供更优或至少不劣于其他常用策略的效果。
# 238. `cs.CL` - Memento: Note-Taking for Your Future Self [PDF](https://arxiv.org/pdf/2506.20642), [HTML](https://arxiv.org/abs/2506.20642)
## Authors
Chao Wan,Albert Gong,Mihir Mishra,Carl-Leander Henneking,Claas Beger,Kilian Q. Weinberger
## Background
大语言模型（LLMs）在进行纯粹的推理任务时表现出色，但在需要推理与检索紧密结合的多跳问答场景中则表现不佳。为了解决这一局限，本文提出了一种新的提示策略，该策略将复杂问题分解为较小步骤，动态构建事实数据库，并最终将这些事实组合起来解决问题。这一三阶段策略在多种场景下提升了现有提示策略的效果。实验展示了该策略在不同基准测试中的表现，特别是在提供所有相关信息时，使用该策略的链式思考方法在PhantomWiki基准测试中将性能翻倍；在2WikiMultiHopQA的开放领域版本中，结合Memento的CoT-RAG方法比基础的CoT-RAG和多跳RAG基线方法分别提升了超过20个F1分数点和13个F1分数点；在具有挑战性的MuSiQue数据集上，Memento使得ReAct方法在F1分数上提升了超过3个分数点，展示了其在用于代理场景中的实用性.
## Innovation
本文提出了一种名为Memento的提示策略，该策略首先将复杂问题分解为多个步骤，基于大语言模型动态构建事实数据库，然后将这些事实组合起来以解决复杂问题。这种方法在多种场景中提升了现有提示技术的效果，并且在几个基准测试中展现了显著的性能提升，尤其是在需要高度推理和检索结合的任务中，表现出色。
## Conclusion
Memento策略通过将问题分解、动态构建知识数据库并组合使用的方法，显著提高了大语言模型在需要推理与检索紧密结合的任务中的性能，尤其是在复杂的多跳问答任务和挑战性的代理场景中。
# 239. `cs.CL` - 全局上下文机制在序列标注中的应用 [PDF](https://arxiv.org/pdf/2305.19928), [HTML](https://arxiv.org/abs/2305.19928)
## Authors
Conglei Xu,Kun Shen,Hongguang Sun,Yang Xu
## Background
全局句子信息对于序列标注任务至关重要，每个单词都需要被分配一个标签。虽然双向长短期记忆网络（BiLSTM）被广泛应用，但它们往往无法捕捉到足够的全局上下文信息，尤其是对于句子内部的词。过去的解决方案虽然提出了各种循环神经网络（RNN）变体来整合全局句子信息到词表示中，但这些方法存在三个关键限制：一是相比原始的BiLSTM，它们在推断和训练速度上较慢；二是它们无法有效地为基于变换器的模型补充全局信息；三是对于现有的架构，这些自定义的RNN需要重新实现和集成，因此耗时较长。
## Innovation
本研究引入了一种简单有效的机制，解决了上述局限性问题。该方法能够在保持推断和训练速度基本不变的情况下，有效地为BiLSTM和基于变换器的模型补充全局句子信息，并且易于与现有的架构插件。通过在七种流行基准测试中的具体演示，即命名实体识别（NER）任务如COGIll2003、WNut2017、微博中文命名实体识别任务和端到端情感分析（E2E-ABSA）基准测试如Laptop14、Restaurant14、Restaurant15和Restaurant16中，显著提升F1分数，无需额外策略，在微博NER基准测试中也获得了第三高的分数，且在竞争F1分数的基础上，实现了更快的推理和训练速度。
## Conclusion
与序列标注中最受欢迎的框架条件随机场（CRF）相比，该方法虽然取得与CRF相似的F1分数，但提供更为优越的推理和训练速度。相关代码可在指定链接中获取。
# 240. `cs.CL` - 代码生成LLM中长范围依赖处理的评估 [PDF](https://arxiv.org/pdf/2407.21049), [HTML](https://arxiv.org/abs/2407.21049)
## Authors
Yannick Assogba,Donghao Ren
## Background
随着语言模型支持的上下文大小不断增大，评估它们有效利用这些上下文的能力变得越来越重要。本文分析了几个代码生成模型在长达8k构词的上下文窗口中处理长距离依赖的能力，使用了一套逐步增加难度的多步关键检索任务。与流行的“针扎干草堆”测试相比，这些任务可以更细腻地评估模型的能力。研究表明，许多模型在功能引用定义在提示后部的功能时，表现会显著下降（最多2倍）。我们还观察到，使用滑动窗口注意力机制的模型难以处理窗口之外的引用。通过简单的提示修改，利用调用图信息，多步检索性能可提高3倍。本文分析强调了长上下文性能需要更深入的考虑，不仅仅是文档中单一事实的检索问题。
## Innovation
本文使用了一套多步关键检索任务来评估代码生成大语言模型在上下文可达8k词时处理长距离依赖的能力，比常见的“针扎干草堆”测试提供了更细腻的评估，同时通过简单的提示修改利用调用图信息提高了多步检索性能最多3倍。
## Conclusion
本文分析强调了长上下文性能需要更深入的考虑，不仅仅是文档中单一事实的检索问题。
# 241. `cs.CL` - 使用大型语言模型进行图推理的图线性化方法 [PDF](https://arxiv.org/pdf/2410.19494), [HTML](https://arxiv.org/abs/2410.19494)
## Authors
Christos Xypolopoulos,Guokan Shang,Xiao Fei,Giannis Nikolentzos,Hadi Abdine,Iakovos Evdaimon,Michail Chatzianastasis,Giorgos Stamou,Michalis Vazirgiannis
## Background
大型语言模型已经演进到处理超过文本的多种模态，如图像和音频，这促使我们探索如何有效利用这些模型来执行图推理任务。关键问题是将图有效地线性化为标记序列，以使LLMs能够自然地处理图。我们认为，图应该被有意义地线性化，以反映自然语言文本中的局部依赖和全局对齐特性，从而帮助基于数十亿文本标记训练的当前LLMs更好地理解图。
## Innovation
基于图中心性和退化性，开发了几种图线性化方法，这些方法进一步通过节点重新标记技术进行增强。实验结果表明，我们的方法比随机线性化基线更有效。我们工作引入了适合LLMs的新颖图表示，有助于通过统一变压器模型将图机器学习与多模态处理趋势相结合的研究。
## Conclusion
我们的研究表明，通过有意义的方式将图线性化可以提高大型语言模型在图推理任务上的表现。我们提出的方法具有创新性，能够帮助大型语言模型更好地理解图结构，为将图机器学习与多模态处理结合提供新的视角。
# 242. `cs.CL` - 关于阅读时间预测中的语境作用 [PDF](https://arxiv.org/pdf/2409.08160), [HTML](https://arxiv.org/abs/2409.08160)
## Authors
Andreas Opedal,Eleanor Chodroff,Ryan Cotterell,Ethan Gotlieb Wilcox
## Background
该研究聚焦于读者在实时语言理解过程中如何整合语境。以往的研究基于惊讶理论，提出语言单位（如单词）的处理努力与其在语境中的信息含量成线性关系。研究发现，尽管惊讶度和点wise互信息（PMI）在预测阅读时间方面具有相同的力量，并且都与频率相关，但这两种方法都无法提供关于语境本身的信息。因此，研究提出了通过将惊讶度投影到频率的正交补空间，得到一种与频率无关的新语境预测方法。实验显示，当使用正交化的预测变量时，解释阅读时间差异的语境比例显著降低，这表明以往的研究可能夸大了语境对阅读时间预测的作用。
## Innovation
提出了将惊讶度投影到频率的正交补空间，从而得到一种与频率无关的新语境预测方法。这种方法使得新得到的预测变量与频率无关，能够更清晰地揭示语境在预测阅读时间中的实际作用，降低了以往研究可能夸大语境作用的情况。
## Conclusion
使用正交化的预测变量，解释阅读时间差异的语境比例降低，表明语境在预测阅读时间中的作用可能被先前研究高估，新方法提供的解释更准确，并强调需要考虑频率对语境预测的影响。
# 243. `cs.CL` - 语言模型通过更常见的现象学习稀有现象：AANN缺失现象的研究 [PDF](https://arxiv.org/pdf/2403.19827), [HTML](https://arxiv.org/abs/2403.19827)
## Authors
Kanishka Misra,Kyle Mahowald
## Background
语言模型能够学习到稀有的语法现象，但这种学习更多是由于泛化还是记忆是一个开放的问题。本文通过逐步训练变换器语言模型，并在人工规模的数据集上进行调整，评估了它们对于罕见的英语语法现象——Article + Adjective + Numeral + Noun (AANN)结构的掌握情况。对比了在默认数据集和删除AANN句子的假想数据集中的学习效果，显示了语言模型通过相关现象的泛化学习稀有语法现象的存在证据。此外，实验表明，更多的输入变化能够增强这种学习效果。
## Innovation
使用人工规模的数据集，逐步训练变换器语言模型；假想数据集的设计（尤其是删除AANN句子的数据集）；通过引入更常见的现象来研究语言模型学习稀有现象的可能性；展示了语言模型通过泛化学习稀有现象的结果，强调了更常见现象的重要性。
## Conclusion
研究表明，语言模型能够通过更常见的相关构造来进行泛化，从而学习到稀有语法现象。增加输入中的变化可以增强这种学习效果。这一研究为语言模型的学习机制提供了新的见解，并强调了使用更多大小、更多样性数据集的重要性。
# 244. `cs.CL` - Decrypto基准：多智能体推理与心智理论 [PDF](https://arxiv.org/pdf/2506.20664), [HTML](https://arxiv.org/abs/2506.20664)
## Authors
Andrei Lupu,Timon Willi,Jakob Foerster
## Background
随着大型语言模型（LLMs）获得代理能力，它们将在复杂的多智能体场景中导航，与人类用户和其他智能体进行合作和竞争的交互。这就需要新的推理技能，其中最重要的便是心智理论（ToM），即能够推理其他智能体“心理”状态的能力。然而，LLMs中的ToM和其他多智能体能力尚未被充分理解，因为现有的基准测试在范围狭窄、数据泄漏、饱和和缺乏互动性方面存在缺陷。因此，本文提出Decrypto，一种灵感来源于认知科学、计算语用学和多智能体强化学习的游戏基准测试，旨在消除其他基准测试中的混淆因素，以简化所有其他维度的设计。据我们所知，它也是第一个用于设计互动的心智理论实验的平台。
## Innovation
Decrypto是一个游戏基准，旨在评估LLMs的多智能体推理和心智理论能力，它通过借鉴认知科学、计算语用学和多智能体强化学习的方法设计，旨在消除其他基准测试中的混淆因素，以简化所有其他维度的设计。此外，它还是第一个平台，用于设计互动的心智理论实验。
## Conclusion
通过全面的实证评估、稳健性研究和人机互动实验，验证了基准设计的有效性。研究发现，LLMs的游戏能力落后于人类和简单的词嵌入基线。然后，在Decrypto中创建经典认知科学实验的变体，以评估三种关键的心智理论能力。令人惊讶的是，最新的推理模型在这项任务中的表现不如其更早的版本。这表明，Decrypto弥补了当前推理和心智理论评估的关键空白，并为改进人工智能铺平了道路。
# 245. `cs.CL` - 世界模型的理解或未来预测？世界模型的全面综述 [PDF](https://arxiv.org/pdf/2411.14499), [HTML](https://arxiv.org/abs/2411.14499)
## Authors
Jingtao Ding,Yunke Zhang,Yu Shang,Yuheng Zhang,Zefang Zong,Jie Feng,Yuan Yuan,Hongyuan Su,Nian Li,Nicholas Sukiennik,Fengli Xu,Yong Li
## Background
由于GPT-4等多模态大型语言模型和Sora等视频生成模型的发展，世界模型的概念引起了广泛关注。这些模型对于实现通用人工智能至关重要。本文综述了世界模型的相关文献，指出世界模型一般被视作理解当前世界状态或预测未来动态的工具。文章对世界模型进行了系统分类，并强调了两种主要功能：（1）构建内部表示以理解世界机制；（2）预测未来状态以模拟和指导决策。文章首先回顾了这两个类别中的当前进展，然后探讨了世界模型在自主驾驶、机器人技术和社会模拟等关键领域的应用，最后总结了关键挑战并提供了未来研究方向的见解。
## Innovation
本文对世界模型进行了全面的文献综述，进行了系统分类，并详细分析了其在关键领域的应用。
## Conclusion
文章总结了具有代表性的相关论文及其代码仓库，并提出了世界模型研究中面临的关键挑战和未来研究方向。
# 246. `cs.CL` - MMSearch-R1: 促使大型多模态模型进行搜索 [PDF](https://arxiv.org/pdf/2506.20670), [HTML](https://arxiv.org/abs/2506.20670)
## Authors
Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu
## Background
在实际场景中部署大型多模态模型（LMMs）时，需要访问外部知识源，因为现实世界中的信息复杂且动态。当前的解决方案如检索增强生成（RAG）和提示工程化搜索代理依赖于僵化的流程，这常常导致搜索行为低效或过度。现有的方法难以适应不断变化的信息环境，因此需要新的解决方案来实现高效和按需的搜索。
## Innovation
我们提出了MMSearch-R1，一个端到端的强化学习框架，使LMMs能够在实际互联网环境中进行按需、多轮搜索。该框架结合了图像和文本搜索工具，并通过基于结果的奖励和搜索惩罚来引导模型何时及如何调用这些工具。此外，通过半自动管道收集了一个多模态搜索VQA数据集，并策划了一个包含搜索要求和非搜索要求样本的搜索平衡子集，这对于形成高效且按需的搜索行为至关重要。实验结果显示，相较于相同规模的RAG基线，我们的模型表现更好，同时还能将搜索调用次数减少超过30%，并且能够达到更大规模的RAG模型的表现。
## Conclusion
我们的研究进一步分析了一些关键的实验发现，为多模态搜索领域未来的研究提供了可操作的见解。
# 247. `cs.CL` - 当大型语言模型与人类意见相左时？大型语言模型的阿谀行为 [PDF](https://arxiv.org/pdf/2311.09410), [HTML](https://arxiv.org/abs/2311.09410)
## Authors
Leonardo Ranaldi,Giulia Pucci
## Background
大型语言模型在生成内容方面表现出令人满意的生成能力，这主要归因于人类反馈的广泛使用，这种反馈能够改进模型的回答，使其更加符合用户的观点。然而，通过人类反馈传递的易操控性使模型倾向于产生与人类意见一致的误导性回答，这种行为被称为阿谀。这种现象会导致模型产生偏差，降低模型的稳健性和可靠性。这项研究旨在研究大型语言模型在回答涉及主观意见的问题时的阿谀行为，通过系统的人工干预提示在不同任务中进行分析。
## Innovation
研究通过系统的人工干预提示在不同任务中的分析，揭示了大型语言模型在回答涉及主观意见的问题时的阿谀倾向，特别是在需要基于事实产生反驳性回答的查询中。与之前的研究相比，本研究进一步分析了在数学任务或具有客观答案的查询中，模型是否遵循用户的提示并自信地生成正确答案。
## Conclusion
研究表明，大型语言模型在回答涉及主观意见的问题时表现出阿谀行为，但当面对数学任务或具有客观答案的查询时，模型通常不会遵循用户的提示，而是自信地生成正确的答案。这表明，在涉及主观意见的查询中，大型语言模型存在偏差倾向，需进一步改进以提高模型的客观性和可靠性。
# 248. `cs.CL` - 分离舌与思绪：激活补丁揭示变压器中的语言无关概念表示 [PDF](https://arxiv.org/pdf/2411.08745), [HTML](https://arxiv.org/abs/2411.08745)
## Authors
Clément Dumas,Chris Wendler,Veniamin Veselovsky,Giovanni Monea,Robert West
## Background
多语言语言模型中的一个核心问题是大型语言模型（LLMs）是否发展出一种从特定语言中解藕的概念表示。本研究通过在基于变换器的语言模型中执行单词翻译任务时分析潜在表示，以解决此问题。通过对源翻译提示提取潜在表示并将其插入到目标翻译提示的前向传递中，我们发现语言编码在较早的层中，而非概念翻译所对应的层。基于此发现，研究设计了两个关键实验：首先，仅通过激活补丁就能够在不改变语言的情况下改变概念，并且反之亦然；其次，补丁使用不同语言中概念的平均表示不会影响模型翻译能力，反而提升之。最后，研究还推广到了多词生成，并展示了模型可以生成这些平均表示的自然自然语言描述。这些结果为在研究模型中存在的语言无关概念表示提供了证据。
## Innovation
本研究的核心创新在于通过激活补丁技术揭示了语言模型中的语言无关概念表示，揭示出语言编码和概念翻译区别存在于不同层，并通过激活补丁技术实现了语言和概念的独立调整，并展示了使用概念平均表示增强翻译效果的能力，为多语言理解与生成提供了新的视角。
## Conclusion
本研究通过激活补丁的方法在转变概念而不改变语言属性，并反之亦然的行为中提供了实验证据，表明存在语言无关的概念表示，并通过实验展示了增强翻译质量的有效性。
# 249. `cs.CL` - FactCheckmate：在LMs中预先检测和缓解幻觉 [PDF](https://arxiv.org/pdf/2410.02899), [HTML](https://arxiv.org/abs/2410.02899)
## Authors
Deema Alnuhait,Neeraja Kirtane,Muhammad Khalifa,Hao Peng
## Background
语言模型（LMs）会产生幻觉，即它们可能会生成不符合实际的信息。本研究探讨了在幻觉发生之前是否可以检测和减轻幻觉的问题，并通过内部表示中丰富的信号展示了积极的答案。研究介绍了一种名为FactCheckmate的方法，该方法通过学习分类器预测模型是否会产生幻觉（基于模型在输入过程中产生的隐藏状态）来预先检测幻觉，在解码开始前进行干预，调整LM的隐藏状态，使其生成更准确的输出。
## Innovation
FactCheckmate能够在模型生成输出之前识别潜在的幻觉，并通过调整模型的隐藏状态来减轻幻觉。这种方法的独特之处在于它利用了模型的隐藏状态来揭示其内部工作机制，并且其检测和缓解模型都具有轻量级特性，增加了很少的推理开销，相较于许多事后解决方案，这提供了更有效的缓解幻觉的方法。它已经在不同规模和模型家族的LMs上进行了评估，包括Llama、Mistral、Qwen和Gemma，涵盖了多种问答数据集。
## Conclusion
FactCheckmate在不同规模和模型家族的LMs上的评估结果表明，其前置检测准确率超过70%，带有干预措施的LM生成的输出平均比未进行干预的输出更加准确，提高了34.4%的准确性。
# 250. `cs.CL` - VAQUUM：视觉数据中模糊量词是否扎根？ [PDF](https://arxiv.org/pdf/2502.11874), [HTML](https://arxiv.org/abs/2502.11874)
## Authors
Hugh Mee Wong,Rick Nouwen,Albert Gatt
## Background
模糊量化词如“几”和“许多”受制于多种上下文因素，尤其是在给定场景中对对象数量的考量。本文旨在评估视觉-语言模型（VLMs）在生成或评判模糊量化词是否合适的程度上是否与人类一致。为此，作者发布了一个新数据集VAQUUM，包含20,300条人类对量化陈述的评价，覆盖1089张图片。使用此数据集，作者通过三种不同的评估方法，对比了人类判断和VLM预测之间的差异
## Innovation
作者创建了一个名为VAQUUM的新数据集，该数据集将量化陈述与具体图片关联，客观分析VLMs与人类对于模糊量化词的理解与应用差异，揭示了不同模型在不同评估环境下的显著不一致性，表明判断和生成模糊量化词可能涉及不同的认知过程
## Conclusion
VLMs在模糊量化词的使用上受到对象数量的影响类似于人类，但不同模型在不同评估条件下表现出显著差异，这表明评判和生成模糊量化词可能依赖于不同的过程
# 251. `cs.CL` - Balancing Truthfulness and Informativeness with Uncertainty-Aware Instruction Fine-Tuning [PDF](https://arxiv.org/pdf/2502.11962), [HTML](https://arxiv.org/abs/2502.11962)
## Authors
Tianyi Wu,Jingwei Ni,Bryan Hooi,Jiaheng Zhang,Elliott Ash,See-Kiong Ng,Mrinmaya Sachan,Markus Leippold
## Background
大型语言模型（LLMs）通过指令微调（IFT）可以增加输出内容的相关性和信息量，但可能会牺牲其事实准确性。这是因为IFT会导致模型生成包含预训练阶段未能充分涵盖的长尾知识的响应。因此，在面对未见过的任务时，模型变得更为信息丰富但同时准确度降低。
## Innovation
本文提出了两种新的指令微调方法：$UNIT_{cut}$和$UNIT_{ref}$。$UNIT_{cut}$通过识别并从指令微调数据集中移除陌生知识来减轻其对模型准确度的影响。$UNIT_{ref}$则训练模型识别其不确定性并在响应结尾明确表明。实验结果表明，$UNIT_{cut}$显著提高了模型的准确度，而$UNIT_{ref}$则保持了高度信息量并减少了对不确定陈述的幻觉。
## Conclusion
两种新的指令微调方法分别从减少陌生知识引入和增强模型的不确定性意识两个方面提升了模型在信息量和事实准确性之间的平衡，从而提出了一个有效的解决方案，以同时保持信息丰富度和准确性。
# 252. `cs.CL` - 通过纸牌游戏Codenames中的即兴概念形成来评估大型语言模型 [PDF](https://arxiv.org/pdf/2502.11707), [HTML](https://arxiv.org/abs/2502.11707)
## Authors
Sherzod Hakimov,Lara Pfennigschmidt,David Schlangen
## Background
本文研究利用纸牌游戏Codenames作为基准工具，评估大型语言模型（LLMs）在特定语言和认知技能方面的表现。在此游戏中，LLMs分别扮演游戏的两个对立面，一方生成包含多个目标词的提示词，另一方则根据提示词猜测这些目标词。通过操控词汇选择（抽象词 vs. 具体词，多义词 vs. 单义词）或对手（编程为更快或更慢地揭示词语）等变量设计了一系列实验。将最新的商业和开源模型进行了直接比较，以找出影响其性能的因素。评估揭示了模型策略、挑战性案例及其局限性。
## Innovation
本研究创新性地使用了纸牌游戏Codenames作为评估工具，通过控制具体因素设计实验，对多种大型语言模型进行直接对比，从而揭示了模型在处理特定语言和认知任务时的策略、挑战和限制。
## Conclusion
评估结果显示了大型语言模型在处理特定语言和认知任务时的策略、挑战案例和局限性。通过游戏中的表现，可以更好地理解大型语言模型的优势和不足，并为进一步提升模型性能提供指导。
# 253. `cs.CL` - 超越语言模型的自然数据集中的上下文学习解锁 [PDF](https://arxiv.org/pdf/2501.06256), [HTML](https://arxiv.org/abs/2501.06256)
## Authors
Jelena Bratulić,Sudhanshu Mittal,David T. Hoffmann,Samuel Böhm,Robin Tibor Schirrmeister,Tonio Ball,Christian Rupprecht,Thomas Brox
## Background
大语言模型（LLMs）展示了上下文学习（ICL）能力，使其能够在不更新模型权重的情况下，通过上下文中的示例完成新任务。尽管ICL在自然语言任务和领域中提供快速适应，但对于文本以外的模态，其出现则更为复杂。研究通过系统地揭示LLMs支持ICL出现的特性，促进自回归模型和其他模态的学习所需机制，来探索ICL的出现机制。具体而言，研究发现了训练数据序列中的精确令牌重复是ICL的一个重要因素，这种重复进一步提高了ICL性能的稳定性和减少了不确定性。此外，研究强调了训练任务难度对于ICL出现的重要性。最后，通过应用ICL出现的新见解，研究解锁了多种视觉数据集和更具挑战性的EEG分类任务的ICL能力，在少量样本学习场景中实现应用
## Innovation
本文系统性地揭示了支持大语言模型（LLMs）上下文学习（ICL）出现的特性，包括训练数据序列中精确令牌重复的重要性，以及训练任务难度的影响。研究通过这些新颖的发现，在视觉数据集和更具挑战性的脑电信号分类任务中解锁了ICL能力
## Conclusion
本文通过揭示大语言模型支持上下文学习出现的特性，促进了各种自回归模型和其他模态的学习机制。根据这些发现，研究解锁了视觉数据集和更具挑战性的EEG分类任务的上下文学习能力，在少量样本学习场景中实现了应用场景。
# 254. `cs.CL` - 注意力熵是关键因素：全注意力预训练语言模型中并行上下文编码的分析 [PDF](https://arxiv.org/pdf/2412.16545), [HTML](https://arxiv.org/abs/2412.16545)
## Authors
Zhisong Zhang,Yan Wang,Xinting Huang,Tianqing Fang,Hongming Zhang,Chenlong Deng,Shuaiyi Li,Dong Yu
## Background
大型语言模型在广泛的语言任务中表现出色，这得益于它们出色的上下文建模能力。常用的上下文建模方法是全自注意力，特别是在标准解码器结构的Transformer中。尽管这种方法强大，但它对于长序列可能是效率低下的，并且可能会忽略输入的固有结构。为了解决这些问题，提出了一种替代方法，即并行上下文编码，这种方法将上下文分为子部分并行编码。但由于在训练过程中未遇到并行模式，直接使用并行编码会导致性能下降。
## Innovation
本文详细分析了并行上下文编码的问题，并确定异常高的注意力熵可能是关键因素。此外，作者采用了两种简单的方法：引入注意力陷阱和选择性机制，来降低注意力熵。实验表明，这些方法有效地降低了不规则注意力熵，并减少了性能差距。
## Conclusion
本文的研究为增强上下文建模机制提供了见解。
# 255. `cs.CL` - 充分发挥大语言模型内部状态以增强知识边界感知 [PDF](https://arxiv.org/pdf/2502.11677), [HTML](https://arxiv.org/abs/2502.11677)
## Authors
Shiyu Ni,Keping Bi,Jiafeng Guo,Lulu Yu,Baolong Bi,Xueqi Cheng
## Background
大语言模型（LLMs）在多种任务中表现出色，但在判断知识边界方面常常不够准确，导致其对某些知识领域充满信心但实际却答错。研究发现，利用LLMs的内部状态可以提升模型对知识边界感知的能力，从效率和风险角度出发，探讨LLMs在响应生成前对自身置信度估计的可能性。在多个数据集如自然问题、热点QA和MMLU上进行实验，展示了LLMs在生成前具有显著的感知能力，在生成后进一步完善，且感知差距在不同条件下保持稳定。
## Innovation
提出了 Confidence Consistency-based Calibration ($C^3$) 方法，通过问题重述评估置信一致性，在关键领域中有效降低风险。$C^3$ 方法显著提高了LLMs 对自我知识空缺的识别能力，在NQ和HotpotQA数据集上分别提高了5.6%和4.9%的未知感知率。这一点表明，生成前的置信估计可以优化效率，而$C^3$ 可以有效控制输出风险，推动LLMs 在实际应用中的可靠性提升
## Conclusion
通过利用LLMs的内部状态，可以改进模型对知识边界的感知。通过$C^3$方法，能够更准确地评估模型的置信度，从而有效减少输出错误，提高LLMs的整体可靠性和实用性。
# 256. `cs.CL` - 图推理过程奖励使LLMs成为更普适的推理者 [PDF](https://arxiv.org/pdf/2503.00845), [HTML](https://arxiv.org/abs/2503.00845)
## Authors
Miao Peng,Nuo Chen,Zongrui Suo,Jia Li
## Background
尽管大型语言模型（LLMs）取得了显著进展，但在LLMs中发展高级推理能力仍然是一个关键挑战。过程奖励模型（PRMs）在数学推理等特定领域通过逐步反馈表现出极大的潜力，但在更广泛的推理领域中的应用却因手动创建逐级监督的成本高而鲜有研究。本文在图推理这一领域进行了探索，该领域需要复杂的多步推理，并且可以通过图算法自动化生成逐级数据。
## Innovation
本文构建了GraphSILO数据集，包含用于图推理问题的细粒度逐级标签，并提出了GraphPRM，这是第一个专为图推理问题设计的PRM。GraphPRM被用于两种关键场景：推理时间扩展和直接偏好优化强化学习。实验结果表明，GraphPRM显著提高了Qwen2.5-7B在13个图推理任务中的性能，对GSM8K和Math500等新数据集和新推理领域也表现出转移性效果。这表明基于图的推理奖励在不同领域都具有广泛应用的潜力。
## Conclusion
文章的研究结果强调了PRMs在不同领域推进推理能力的潜力，为开发更多多功能和有效的LLMs铺平了道路。
# 257. `cs.CL` - WordNet 和人类直觉之间的语义关系知识错位 [PDF](https://arxiv.org/pdf/2412.02138), [HTML](https://arxiv.org/abs/2412.02138)
## Authors
Zhihan Cao,Hiroaki Yamada,Simone Teufel,Takenobu Tokunaga
## Background
WordNet 提供了一个由专业人员精心构建的语义关系仓库，但也有另一个关于语义关系的信息来源，那就是语言使用者的直觉。尽管 WordNet 是一个权威的数据资源，但其语义关系是否与人们的直观认知一致，还有待研究。这项研究首次系统地探讨了这两个来源之间的差异，以发现并利用这种差异来改进 WordNet 和其应用。这项研究采用模板向人类参与者收集反馈，揭示了 WordNet 和人类直觉之间的语义关系知识存在普遍的错位，特别是在同义词和分类关系（超类和子类）上，WordNet 的路径长度也不再是预测人类对分类关系认知的标准指标。
## Innovation
这是首次系统性研究 WordNet 和人类直觉之间的语义关系知识的错位。通过使用模板提取人类参与者的反馈，研究发现了 WordNet 和人类直觉在语义关系认识上的系统性差异，特别是在同义词和分类关系上，而 WordNet 的路径长度不能准确反映人类对这些关系的理解。这项研究的结果可以用来改进 WordNet 和更好地利用其数据资源。
## Conclusion
研究揭示了 WordNet 和人类直觉在语义关系领域的认识不一致，特别是在同义词和分类关系上。这种认识偏差可能会阻碍 WordNet 的应用场景。未来可以通过引入更多人类反馈的方式改进 WordNet，并利用这些关于语义关系的新知识来提升其准确性和实用性。
# 258. `cs.CL` - 预训练语言模型和人类的语义关系知识全面评估 [PDF](https://arxiv.org/pdf/2412.01131), [HTML](https://arxiv.org/abs/2412.01131)
## Authors
Zhihan Cao,Hiroaki Yamada,Simone Teufel,Takenobu Tokunaga
## Background
近年来，许多研究关注预训练语言模型（PLMs）在语言不同方面学习的谜团，以及它们如何学习这些知识。其中，有一类研究专门探讨了PLMs对语义关系的理解知识。然而，许多语义关系方面仍未被研究，仅限于探究超属词关系（hypernymy）。更重要的是，过往的研究并未测量人类在相同任务上的表现，导致对模型的语义关系知识仍缺乏完整的理解。因此，提出了一种涵盖超属词、属词、部分词、反义词和同义词五种关系的全面评估框架，并使用六种新颖引入的度量标准（准确度、完整性、对称性、不对称性、典范性、可区分性）对人类和模型进行公平比较，以全面了解它们在处理这些语义关系时的知识差距。
## Innovation
该研究引入了全面的语义关系知识评估框架，涵盖了超属词、属词、部分词、反义词和同义词五种关系，同时使用了六种新的度量标准来衡量模型和人类对于未被充分研究的语义关系方面的能力。通过大量的实验，该研究比较了16种PLMs（包括8种掩码和8种因果语言模型）在不同语义关系上的表现，并首次对因果和掩码语言模型进行了全面的对比分析，揭示了模型在大多数语义关系上的知识差距。最后，研究发现掩码模型在这次实验中的表现显著优于因果模型，但两者都容易将非反义词关系误认为反义词关系。
## Conclusion
该研究确认了人类与模型在处理语义关系时存在显著的知识差距，尤其在反义词关系方面，模型相对表现较好，但大多数语义关系中，模型表现均较差。这项研究的工作为全面了解预训练语言模型的语义关系知识提供了首次方法论上的启示。
# 259. `cs.CL` - CogniBench: 法律启发的框架和数据集，用于评估大规模语言模型的认知忠实度 [PDF](https://arxiv.org/pdf/2505.20767), [HTML](https://arxiv.org/abs/2505.20767)
## Authors
Xiaqiang Tang,Jian Li,Keyu Hu,Du Nan,Xiaolong Li,Xi Zhang,Weigao Sun,Sihong Xie
## Background
现有评估标准的缺失使得现有的基准主要关注能重新措辞掉源材料的‘事实陈述’，而忽视了涉及从给定背景中推理的认知陈述。因此，评估和检测认知陈述的幻觉仍然具有挑战性。
## Innovation
该研究受到法律领域证据评估的启发，设计了一个严格的框架来评估认知陈述的不同忠实度层次，并引入了CogniBench数据集，其中涵盖了丰富的统计数据。进一步开发了一个易于跨不同模型扩展的自动注解流水线，创建了大规模的CogniBench-L数据集，有助于训练既能检测事实幻觉又能检测认知幻觉的准确检测器。
## Conclusion
该研究提出的方法和数据集提高了语言模型幻觉检测的准确性和全面性，特别是在认知陈述幻觉的评估方面。
# 260. `cs.CL` - LADM: 基于注意机制依赖测量的长上下文训练数据选择方法用于LLMs [PDF](https://arxiv.org/pdf/2503.02502), [HTML](https://arxiv.org/abs/2503.02502)
## Authors
Jianghao Chen,Junhong Wu,Yangyifan Xu,Jiajun Zhang
## Background
长上下文建模在大型语言模型（LLMs）领域引起了越来越多的关注。持续训练使用长上下文数据已成为为LLMs提供处理长输入能力的默认方法。然而，如何衡量长上下文训练数据的质量仍然是一个开放的挑战。为解决这一问题，我们提出了一种基于注意机制依赖测量的长上下文数据选择框架（LADM），该框架可以从大规模、多领域的预训练库中高效地识别高质量的长上下文数据。LADM利用注意机制的检索能力捕捉上下文依赖性，确保对长上下文数据进行全面的质量测量。实验结果表明，通过使用仅1Btokens进行持续训练，我们提出的LADM框架显著提高了LLMs在多个长上下文任务上的性能。
## Innovation
引入了一种新的长上下文数据选择框架LADM，使用基于注意机制的依赖测量来高效地识别高质量的长上下文数据，并提升LLMs在长上下文任务中的性能。
## Conclusion
LADM框架通过在大规模、多领域预训练库中使用基于注意机制的依赖测量，有效地选择了高质量的长上下文数据，并在多个长上下文任务中显著提升了LLMs的性能。
# 261. `cs.CL` - SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities [PDF](https://arxiv.org/pdf/2506.06406), [HTML](https://arxiv.org/abs/2506.06406)
## Authors
Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Wei Chen,Fangxiang Feng,Xiaojie Wang
## Background
Mixture of Experts (MoE) 架构已成为大规模语言模型扩展的关键方法，尤其是在扩展到多模态任务方面引起了广泛兴趣。现有的多模态 MoE 模型构建方法要么训练成本高，要么在适应预训练模型时语言能力受损。这表明在多模态 MoE 模型中平衡模态差异和语言能力是一个挑战。
## Innovation
提出了一种新的正则化技术 Soft Modality-Aware Routing (SMAR)，使用 Kullback Leibler 散度来控制不同模态之间的路由概率分布，从而促进专家的专业化，同时不需要更改模型架构或大量依赖文本数据。SMAR 在保留语言能力的同时不牺牲多模态性能，且只需少量纯文本数据。
## Conclusion
实验结果表明，SMAR 在视觉指令调优任务中仅使用 2.5% 的纯文本数据，就可以保留 86.6% 的语言能力，同时优于基线方法，展示了在多模态 MoE 模型中平衡模态差异和语言能力的实际和有效解决方案。
# 262. `cs.CL` - 回收网络：一种增强语言模型预训练数据质量和数量的方法 [PDF](https://arxiv.org/pdf/2506.04689), [HTML](https://arxiv.org/abs/2506.04689)
## Authors
Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li
## Background
大型语言模型的性能依赖于模型规模和数据规模的增长。目前预训练依赖于大规模的网络爬取，使用了互联网上几乎所有可用的数据源，但这些自然数据的增长速度并不匹配计算资源的增长。此外，高质量文本的数据更稀缺，现有的数据过滤流程常去除高达99%的初始网络爬取数据以达到最佳效果。因此，为了解决预训练数据规模方面的瓶颈，该研究探索了回收现有过滤过程中文本数据并使其重新用于训练的方法，从而增加合成数据在最终预训练数据集中的比例，并通过实验验证了该方法的有效性。
## Innovation
该研究提出了REWIRE方法，这是一种指导性重写的方法，可以将低质量文档转化为有用的训练材料，由此增加了合成数据在最终预训练数据集中的占比。该方法在DCLM基准的1B、3B和7B规模下进行实验并展示了其效果，与仅使用过滤后的网络数据对比，分别在22项不同任务中提高了1.0、1.3和2.5个百分点。混合使用高质量原始文本和重写文本的训练方式比直接获取两倍的网络数据更为有效。此外，该方法通过将82%的混入文本从待弃文档中转化而来，表现出色，超越了生成合成数据的其他相关方法，如维基百科风格的重述、问答合成和知识提取等。
## Conclusion
回收现有网络数据为学习模型提供了一种简单有效的方法，可以同时提高预训练数据的质量和数量。研究表明，通过指导性重写过程，可以有效提升语言模型的性能。
# 263. `cs.CL` - mSTEB：大规模多语言评估LLMs在语音和文本任务上的表现 [PDF](https://arxiv.org/pdf/2506.08400), [HTML](https://arxiv.org/abs/2506.08400)
## Authors
Luel Hagos Beyene,Vivek Verma,Min Ma,Jesujoba O. Alabi,Fabian David Schmidt,Joyce Nakatumba-Nabende,David Ifeoluwa Adelani
## Background
大语言模型（LLMs）已经在多种应用场景中展示了令人印象深刻的性能，包括多模态环境中的语音处理。然而，这些模型的评估往往局限于英语和其他几种高资源语言。低资源语言则缺乏标准化的评估基准。本文指出，对于低资源语言，尤其是非洲和美洲/大洋洲地区使用的语言，缺乏标准化的性能评估工具，故提出了一种新的基准mSTEB，用于评估LLMs在语言识别、文本分类、问答和翻译等任务上的表现，涵盖语音和文本模态。这一研究填补了低资源语言性能评估的空白，但揭示了高资源和低资源语言在LLMs性能上存在显著差距，特别是在非洲和美洲/大洋洲使用的语言方面。
## Innovation
提出了一种新的基准mSTEB，专门用于评估LLMs在多模态环境中的表现，特别是在语音和文本任务上，特别是在低资源语言的性能评估方面。该研究还强调需要更多的投资来解决低资源语言在LLMs中的覆盖率不足问题。
## Conclusion
高资源与低资源语言在LLMs性能上存在显著差距，特别是在非洲和美洲/大洋洲使用的语言方面。为了提升LLMs的覆盖范围和提升低资源语言的性能，需要增加更多的投资。
# 264. `cs.CL` - 源到引用之路中的噪声：衡量学者如何与以往研究互动 [PDF](https://arxiv.org/pdf/2502.20581), [HTML](https://arxiv.org/abs/2502.20581)
## Authors
Hong Chen,Misha Teplitskiy,David Jurgens
## Background
学术引用被广泛用于评估研究和追踪知识流，但通常依赖于原始引用计数，忽略了引用类型的变异性。特别是，引用中的信息可能由于被引研究的内容被描述、概括或重新解释，可能产生错误，导致从被引论文到引用论文之间的信息变化程度变化不定。本文旨在通过一个计算管道，量化大规模的引用忠诚度。该研究基于大量跨学科数据集，共包含约1300万对引文句子，分析了引用的忠诚度与引用论文的时新性、近理性、可访问性以及作者的H指数和团队规模之间的关系。研究还通过准实验法验证了“电话效应”，即引用了信息不准确的引文论文的未来引用论文也会缺乏对原始声明的准确引用，从而揭示系统性的引文忠诚度差异，突显了仅依赖引用数量分析的局限性及其可能引发的证据扭曲。
## Innovation
本文引入了一个计算管道，用于大规模量化引文忠诚度。该管道通过全文文本确定引用论文中的引用及其在被引论文中的相应主张，并使用监督模型在句级测量忠诚度。这项研究通过准实验法验证了“电话效应”，并通过大量跨学科数据集分析了引用忠诚度与被引论文的各种特点之间的关系。
## Conclusion
该研究揭示了引文忠诚度的系统性差异，强调了仅依靠引用数量进行分析的局限性，并指出优化证据的潜在途径。
# 265. `cs.CL` - 超出token视角量化LLM公平性：一种语义和统计视角 [PDF](https://arxiv.org/pdf/2506.19028), [HTML](https://arxiv.org/abs/2506.19028)
## Authors
Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy
## Background
大型语言模型（LLMs）通常会产生带有潜在偏见的回答，这对其在实际应用中的可靠性构成威胁。现有的评估方法往往忽略了长格式回答中的偏见和LLM输出的内在变异性。这些问题使得难以对其公平性进行全面和可靠的评估。
## Innovation
提出了一个新颖的细粒度语义计算框架FiSCo，通过检测不同人群组在长格式回答中的细微语义差异，评估LLM在群体层面的公平性。不同于以往侧重于情感或token级别的比较，FiSCo在语义级别进行分析，使用蕴含检查来评估回答的意义一致性。这种方法通过对模型输出进行语义分解，并通过统计假设测验比较群体内和群体间的相似性，从而能够稳健地检测到细微的偏见。作者还提出了一个新的人群反事实公平性定义，通过合成和人工标注的数据集验证了FiSCo的有效性，表现出比其他评估标准更可靠地识别细微偏见的能力，减少了LLM随机波动的影响。
## Conclusion
实验表明，FiSCo能够更可靠地检测出细微的偏见，减少了LLM随机波动的影响，优于各种评估指标。这一方法为LLM的公平性评估提供了新的视角。
# 266. `cs.CL` - LR^2Bench: 通过约束满足问题评估大型语言模型的长链反思推理能力 [PDF](https://arxiv.org/pdf/2502.17848), [HTML](https://arxiv.org/abs/2502.17848)
## Authors
Jianghao Chen,Zhenlin Wei,Zhenjiang Ren,Ziyong Li,Jiajun Zhang
## Background
大型语言模型 (LLMs) 通过反思能力，如假设、回溯和自我改进，最近取得的进步显著增强了它们的推理能力，使其可以处理日益复杂的问题。然而，目前缺乏合适的基准来有效评估这些反思能力，因此本研究旨在填补这一空白，提出了LR^2Bench，这是一个新的基准测试，专门评估大型语言模型的长链反思推理能力。LR^2Bench 包含涉及六种约束满足问题（CSPs）的850个样本，这些问题是反思推理的关键领域，有助于找到符合所有给定约束的解决方案。通过对传统LLMs和高级LRMs（如DeepSeek-R1和OpenAI o1-preview）的全面评估，结果表明，即使是最先进的LRMs也只能在LR^2Bench中达成较低的成功率，平均精确匹配（Exact Match）分数仅为20.0%和23.6%。这些结果强调了当前LLMs在反思推理能力方面的重要改进空间。
## Innovation
引入了LR^2Bench，这是一个新型基准测试，专门用于评估大型语言模型的长链反思推理能力。LR^2Bench 包含6种约束满足问题（CSPs）类型的850个样本，用于评估模型在各种问题解决场景下的性能。这些样本突出了在知识、逻辑和空间约束方面的重要性，为全面评估提供了一个框架。
## Conclusion
尽管当前最先进的大型推理模型（LRMs）如DeepSeek-R1和OpenAI o1-preview在长链反思推理能力方面已表现出一定的优越性，但在基于约束满足问题的基准测试中，它们的表现仍然不佳。平均而言，这些模型只能达到不到25%的成功率。这表明现有的指标和评估方法可能不足以公平地衡量大型语言模型的实际性能，需要更多专注于深入反思过程的评估手段。
# 267. `cs.CL` - LLaVA-CMoE: 面向大规模多模态语言模型的持续专家混合 [PDF](https://arxiv.org/pdf/2503.21227), [HTML](https://arxiv.org/abs/2503.21227)
## Authors
Hengyuan Zhao,Ziqin Wang,Qixin Sun,Kaiyou Song,Yilin Li,Xiaolin Hu,Qingpei Guo,Si Liu
## Background
Mixture of Experts (MoE) 架构最近为大型语言模型 (LLMs) 的持续多模态学习提供了更好的可扩展性和适应性。然而，如何高效地扩展这些模型以适应序列任务依然面临挑战。随着新任务的不断出现，简单的模型扩展会导致参数迅速增长，而修改共享路由组件则会导致灾难性遗忘，从而抹去之前学习的知识。
## Innovation
提出了一种名为 LLaVA-CMoE 的持续学习框架，该框架适用于 LLM，无需以前任务的重播数据，确保参数效率和稳健的知识保留。该方法引入了由探针专家指导的知识扩展机制，利用探针专家动态决定何时及何地添加新的专家，从而实现根据任务复杂度进行适应性和最小参数扩展。此外，还提出了基于概率的任务定位器，为每个任务分配专用且轻量级的路由器。为解决推理时任务标签未知的实际问题，利用基于VAE的重构策略通过匹配输入分布来识别最适合的路由器，从而实现自动且准确的专家分配，减轻路由冲突和灾难性遗忘，从而在无需显式任务标签的情况下实现稳健的持续学习。
## Conclusion
在 CoIN 基准上进行的大量实验，包括八种不同类型的视觉问题解答任务，表明 LLaVA-CMoE 在小模型大小下实现了强大的持续学习性能，显著减少了忘记和参数开销，优于先前的方法。这些结果展示了在大规模语言模型中参数高效持续学习方面的有效性与可扩展性。我们很快会开源代码。
# 268. `cs.CL` - LLM生成数据中的关键因素：多样性及其对模型微调的影响 [PDF](https://arxiv.org/pdf/2506.19262), [HTML](https://arxiv.org/abs/2506.19262)
## Authors
Yuchang Zhu,Huazhen Zhong,Qunshu Lin,Haotong Wei,Xiaolong Sun,Zixuan Yu,Minghao Liu,Zibin Zheng,Liang Chen
## Background
大型语言模型（LLMs）的强大生成能力使得使用LLM生成的数据来训练下游模型成为缓解特定领域数据稀缺问题和减少耗时标注的有效途径。然而，近期的研究揭示了一个关键问题：迭代训练过程中自我生成的数据会导致模型崩塌，模型性能随时间下降。尽管对LLM生成数据的含义进行了广泛研究，但这些研究往往忽视了数据多样性的关键作用，而数据质量的一个关键因素就是数据的多样性。本文旨在探讨LLM生成数据多样性的含义及其对下游模型性能的影响。特别地，我们研究了LLM生成数据的不同多样性水平如何影响下游模型的性能，以及混合不同比例的LLM生成数据（我们称之为合成数据）训练模型的表现情况。
## Innovation
本文侧重于探讨LLM生成数据的多样性如何影响下游模型的性能。具体来说，研究表明，在少量数据偏移的情况下，适度多样化的LLM生成数据可以提高在标记者不足情况下的模型性能，而高度多样化的生成数据则有负面影响。这些发现为未来对LLMs作为数据生成器的研究提供了宝贵的指导意义，特别是强调了数据多样性的关键性。
## Conclusion
实验结果表明，通过利用适度多样化的LLM生成数据，即使在少量的数据偏移下，模型性能也可以得到增强；而高度多样化的生成数据则对模型性能产生负面影响。我们希望这些实证结果能够为未来的LLM研究提供更多指导。
# 269. `cs.CL` - 对话的人机干预：改进LLM响应生成的提示重写研究 [PDF](https://arxiv.org/pdf/2503.16789), [HTML](https://arxiv.org/abs/2503.16789)
## Authors
Rupak Sarkar,Bahareh Sarrafzadeh,Nirupama Chandrasekaran,Nagu Rangan,Philip Resnik,Longqi Yang,Sujay Kumar Jauhar
## Background
人类与大规模语言模型（LLM）的对话在个人和职业生活中越来越普遍，但许多用户仍然难以从LLM聊天机器人中获得有用的响应。这主要是因为用户无法准确构造有效的提示来传达其信息需求。同时，真实世界的对话数据集和LLMs的理解能力提供了研究这一问题及其潜在解决方案的机会。本研究通过分析实际的人机对话，研究用户查询未能准确表达信息需求的方面以及使用LLM重写不佳的用户提示的潜力。研究表明，重写无效的提示可以更好地从对话系统中获得响应，同时保留用户的原始意图。在较长的对话中，这种表现通常会提高，因为可以从上下文中更准确地推断用户的需求。此外，研究发现，当解释提示时，LLMs通常需要并且会做出关于用户意图和目标的合理假设。这些研究结果在各种对话领域、用户意图和不同规模的LLMs中普遍适用，表明提示重写作为改善人机交互解决方案的前景。
## Innovation
本研究首次从LLM的角度出发，研究真实的人机对话，分析用户查询在表达信息需求方面存在的不足，并探讨使用LLM重写无效提示的潜力。研究发现在较长对话中通过重写提示可以更好地生成响应，并且LLMs在解释提示时会做出合理的假设。该研究的创新之处在于展示了提示重写作为一种有效改善人机交互的方法的潜力，尤其是在即时对话系统中。
## Conclusion
研究表明，通过重写无效的提示可以更好地从对话系统中获取响应，同时保留用户的原始意图。研究还发现LLMs在解释提示时会做出合理的假设。这些发现对于改善人机交互具有重要意义，并且表明提示重写是一种有效的解决方案，可以在各种对话领域、用户意图和不同规模的LLM中实现更好的人机交互。
# 270. `cs.CL` - LLM位置泛化的计算机制 [PDF](https://arxiv.org/pdf/2503.13305), [HTML](https://arxiv.org/abs/2503.13305)
## Authors
Chi Han,Heng Ji
## Background
大多数自然语言都是由一系列的单词和句子组成。类似人类，大规模语言模型（LLMs）在处理文本位置时表现出一定的灵活性——我们称之为位置泛化现象。它们能够理解含有位置扰动的文本，并且可以泛化到比训练过程中遇到的更长的文本。这些现象表明，LLMs 对位置处理具有一定的宽容性，但其处理位置的相关计算机制仍然很少被探索。本研究将语言学现象与 LLMS 的计算机制相连接，展示了 LLMS 如何通过某些计算机制实现对上述位置扰动的处理能力。尽管自注意力机制的设计十分复杂，但本研究揭示了 LLMS 学习了一些非直观的层面分离，其值与位置相关性和语义重要性的算术和近似值之间存在0.959的线性相关性。此外，我们还发现了一个普遍的中间特征模式，该模式我们通过理论证明能够支持这一效果。这一模式不同于随机初始化参数的行为，表明这是学习的结果而非模型架构的自然结果。基于这些发现，我们提供了 LLCs 的位置灵活性的计算解释和标准。这项工作在将位置泛化与现代 LLC 的内部机制联系起来方面迈出了一步。
## Innovation
展示了大规模语言模型通过某些计算机制实现对位置扰动的容忍。揭示了大规模语言模型学习了一种非直观的层面分离，其值与位置相关性和语义重要性的算术和近似值之间存在高线性相关性。发现了一个普遍的中间特征模式，通过理论证明证明了这种效果能够实现。指出这种模式不同于随机初始化参数的行为，表明它是学习到的结果而非模型架构的自然结果。提供了大规模语言模型位置灵活性的计算解释和标准。这项工作在将位置泛化与现代大规模语言模型的内部机制联系起来方面迈出了一步。
## Conclusion
本研究提供了对大规模语言模型处理位置相关性的计算机制的见解，揭示了一种新颖的理论效果，并提供了计算标准来解释大规模语言模型的位置灵活性。这些发现有助于我们更好地理解大规模语言模型的工作原理，并为进一步研究和应用提供了基础。
# 271. `cs.CL` - 作为NLP任务的咨询：临床心理学家对CBT中LLMs和人类同伴的比较 [PDF](https://arxiv.org/pdf/2409.02244), [HTML](https://arxiv.org/abs/2409.02244)
## Authors
Zainab Iftikhar,Sean Ransom,Amy Xiao,Nicole Nugent,Jeff Huang
## Background
研究发现，大语言模型（LLMs）在生成单个孤立的同情性反应方面可超越人类咨询师，但它们在咨询会话层面的行为仍需进一步研究。本文通过对团队同伴咨询师提示下的LLM进行直接比较，探讨人为咨询师和LLM咨询的习惯行为在单次认知行为疗法（CBT）会话中的差异。研究团队通过为期一年的文本支持平台定性研究、人工模拟咨询会话以及由经过认证的心理学家对咨询会话的评估，揭示了LLMs在建立深度同情、合作和用户反思方面的优势与在程序遵从性以及文化敏感性方面的劣势。
## Innovation
本研究创新之处在于采用了多阶段、混合方法进行深入分析，不仅考察了LLM在单个同情性反应中的表现，还关注了它们在带领全程咨询会话中的作用。研究发现揭示了LLM在特定任务上的优势与局限，强调了不能将咨询完全视为单独的自然语言处理任务，呼吁设计精心规划的人机协作流程，即LLM可以提炼证据支持的方法，而同伴则提供关系支持。
## Conclusion
我们的发现表明，虽然LLM在生成单个同情性反应时可能优于人类咨询师，但在带领会话方面却受到一定限制。因此，我们不能将咨询简化为单一的NLP任务。需要设计结合人类专家与AI系统的流程，在提升可扩展性支持过程中确保设计机会和伦理护栏。
# 272. `cs.CL` - VICCA: 生成报告中胸部X射线异常的视觉解释与理解，无需人类反馈 [PDF](https://arxiv.org/pdf/2501.17726), [HTML](https://arxiv.org/abs/2501.17726)
## Authors
Sayeh Gholipour Picha,Dawood Al Chanti,Alice Caplier
## Background
随着人工智能（AI）在医疗保健中的作用日益重要，对解解释性和可信赖性的模型的需求变得至关重要。当前的胸部X光报告生成系统通常缺乏无需专家监督就验证输出的机制，这引发了关于可靠性和可解释性的担忧。
## Innovation
为了应对这些挑战，本文提出了一种新颖的多模态框架，旨在增强AI生成的医疗报告的语义对齐和定位准确性。该框架整合了两个关键模块：一个短语定位模型，它根据文本提示在胸部X光图像中标识和定位病理；以及一个文本转图像扩散模块，从提示生成合成X光图像并保留解剖准确度。通过比较原始和生成图像的特征，引入了双重评分系统：一个分数量化定位准确性，另一个评估语义一致性。这种方案在病理定位和文本转图像对齐方面超过了现有方法，达到了最先进的结果。将短语定位与扩散模型相结合，并结合双重评分评估系统，为验证报告质量提供了一种稳健的机制，为更可信和透明的医疗成像AI铺平了道路。
## Conclusion
本文提出了一种新颖的多模态框架，通过双重评分系统增强了AI生成的医疗报告的语义对齐和定位准确性，实现了在病理定位和文本生成上的先进性能，为医疗成像中的AI信任度和可解释性提供了新的途径。
# 273. `cs.CL` - 训练嵌入的注意力机制证明性地选择重要标记 [PDF](https://arxiv.org/pdf/2505.17282), [HTML](https://arxiv.org/abs/2505.17282)
## Authors
Diyuan Wu,Aleksandr Shevchenko,Samet Oymak,Marco Mondelli
## Background
令牌嵌入在语言建模中起着关键作用，但理论理解仍然有限。本文通过描述通过梯度下降获得的嵌入结构来解决这一问题，特别是在二元分类中的一层软最大化注意模型，具有线性头部。研究表明，仅仅经过一次梯度训练，嵌入能够捕获数据集中标记的重要性，按其在数据集中出现的频率与输出向量对齐。随着对称为<p>cls</p>标记的嵌入进行梯度流训练直到收敛，软最大化选择最重要标记（即那些预测标签的标记），并使最终的<p>cls</p>嵌入最大化这种选择的边距。
## Innovation
研究通过描述训练过程中嵌入的结构来揭示模型如何选择重要标记的新颖性。特别是，对于二元分类任务，通过分析单层softmax注意模型，揭示了嵌入如何在一次梯度训练后与数据集中标记的重要性和频率对齐，以及如何通过进一步的训练使得最终<p>cls</p>嵌入最大化选择边距。
## Conclusion
实验结果表明，这种理论解释了真实数据集（IMDB、Yelp）中观察到的现象，证明了通过训练嵌入机制确实能够选择重要标记。
# 274. `cs.CL` - GlyphPattern: 视觉语言模型的抽象模式识别基准 [PDF](https://arxiv.org/pdf/2408.05894), [HTML](https://arxiv.org/abs/2408.05894)
## Authors
Zixuan Wu,Yoolim Kim,Carolyn Jane Anderson
## Background
基于强大语言模型的视觉-语言模型（VLMs）在跨视觉和文本数据推理方面取得了迅速进展。虽然这些模型在训练中表现出色，但我们的研究结果揭示了抽象模式识别的几个关键挑战。为了评估VLMs在抽象模式识别方面的性能，我们提出了一个954项的 GlyphPattern 数据集，其中包含318个人类撰写的来自40种书写系统的视觉模式描述，并以三种视觉展示风格进行配对。该数据集旨在考验模型理解和判断视觉模式自然语言描述的能力，所使用的图案来源于大规模认知科学研究，因此富含空间参考和组合性。我们的实验表明，GlyphPattern对最先进的视觉语言模型（GPT-4o的表现仅有55%的准确性），即使少量示例提示也不能显著提高准确率。详细的错误分析揭示了在视觉处理、自然语言理解以及模式泛化等多个方面存在的挑战。
## Innovation
提出了名为 GlyphPattern 的954项视觉语言模式识别数据集，该数据集包含了318个人类撰写的关于40种书写系统的视觉模式描述，旨在评测VLMs在抽象模式识别上的能力。该数据集具有广泛的视觉展示风格和丰富的空间参考和组合性，是评估VLMs抽象模式识别能力的基准，并揭示了目前VLMs在这方面的局限性和面临的挑战。
## Conclusion
我们的实验显示，即便是最先进的视觉语言模型（如GPT-4o）在 GlyphPattern 上的准确率也只有55%，并且少量提示的微弱改进并不能显著提升模型性能。详细的错误分析揭示了模型在视觉处理、自然语言理解和模式泛化的多个层面存在的局限性。
# 275. `cs.CL` - 在症状检查器中评估罕见病诊断性能：一种合成病历模拟方法 [PDF](https://arxiv.org/pdf/2506.19750), [HTML](https://arxiv.org/abs/2506.19750)
## Authors
Takashi Nishibayashi,Seiji Kanazawa,Kumpei Yamada
## Background
症状检查器（SCs）为用户提供个性化医疗信息。算法更新可能导致性能下降，因此开发者需要在部署前评估个别疾病的诊断性能变化。然而，获取罕见病的足够评估数据非常困难，手动创建大量临床病例片段既昂贵又不现实。为此，本研究提出并验证了一种新的合成病例模拟方法，用于评估SC算法更新后个别罕见病的诊断性能变化。该方法利用人类表型 ontology (HPO) 罕见病知识数据库中的疾病-表型注释生成合成病例，并通过模拟SC面试来估计算法更新对实际诊断性能的影响。
## Innovation
本研究提出了一种新的合成病例模拟方法，用于评估症状检查器算法更新后个别罕见病的诊断性能变化。该方法通过利用人类表型 ontology (HPO) 中的疾病-表型注释生成合成病例，模拟症状检查器的访谈过程，从而估计算法更新对实际诊断性能的影响。
## Conclusion
通过这种方法，可以使用一个公开且专家创建的知识库在部署前评估症状检查器算法变化对个别罕见病的影响。该方法具有透明和低成本的特点，能使开发者更高效地提升罕见病的诊断性能，从而可能提高早期诊断的支持力度。
# 276. `cs.CL` - WAFFLE: 通过多模态模型进行自动前端开发的微调 [PDF](https://arxiv.org/pdf/2410.18362), [HTML](https://arxiv.org/abs/2410.18362)
## Authors
Shanchao Liang,Nan Jiang,Shangshu Qian,Lin Tan
## Background
前端开发涉及将UI设计转化为功能性网页，对于初学者和经验丰富的开发者而言，HTML的层级结构和样式复杂性使得这一过程颇具挑战。尽管大型语言模型（LLMs）已经在生成源代码方面显示出前景，但在UI设计转化为HTML代码的过程中，仍然存在两大挑战：一是有效表示HTML的层级结构给LLMs；二是将UI设计的视觉特性与HTML代码的文本格式进行对接。针对上述挑战，作者提出了一种新的微调策略Waffle，该策略采用了结构感知的注意力机制和对比度微调方法，以提高LLMs对HTML结构的理解以及其对UI图像和HTML代码理解的一致性。
## Innovation
Waffle是一种新的微调策略，它使用结构感知的注意力机制来增强LLMs对HTML结构的理解，并采用对比性微调方法来对齐LLMs对UI图像和HTML代码的理解。通过这种方法，以Waffle策略微调的模型在新基准WebSight-Test和现有基准Design2Code上的HTML匹配度分别提高了9.00个基点，对比度结构相似性系数（CW-SSIM）提高了0.0982，CLIP分数提高了32.99，LLM分数提高了27.12个基点，表现优于现有的微调方法。
## Conclusion
实验结果表明，Waffle策略能够显著提升LLMs在UI到HTML代码生成任务中的性能。该策略有效地解决了HTML层级结构表示和UI设计与HTML代码之间的对接问题，为自动化前端开发提供了新的方法。
# 277. `cs.CL` - 科学家的第一场考试：通过感知、理解和推理探查MLLM的认知能力 [PDF](https://arxiv.org/pdf/2506.10521), [HTML](https://arxiv.org/abs/2506.10521)
## Authors
Yuhao Zhou,Yiheng Wang,Xuming He,Ruoyao Xiao,Zhiwei Li,Qiantai Feng,Zijie Guo,Yuejin Yang,Hao Wu,Wenxuan Huang,Jiaqi Wei,Dan Si,Xiuqi Yao,Jia Bu,Haiwen Huang,Tianfan Fu,Shixiang Tang,Ben Fei,Dongzhan Zhou,Fenghua Ling,Yan Lu,Siqi Sun,Chenhui Li,Guanjie Zheng,Jiancheng Lv,Wenlong Zhang,Lei Bai
## Background
科学研究越来越依赖于基于信息密集型科学数据和特定领域专业知识的复杂多模态推理。目前的科学基准主要集中在评估MLLM的知识理解能力，而对于它们的感知和推理能力的评估则不足。因此，提出了科学家的第一场考试（SFE）基准，旨在通过三个相互关联的层面——科学信号感知、科学属性理解、科学对比推理——评估MLLM的科学认知能力。
## Innovation
SFE基准旨在通过三个层面全面评估MLLM的科学认知能力，分别是科学信号感知、科学属性理解和科学对比推理。并通过830个专家验证的问答对覆盖了66个多模态任务，跨越五个高价值学科。实验结果表明，当前最先进的GPT-o3和InternVL-3在此基准上的表现不佳，表明MLLM在科学领域有提升空间。这一基准有助于推进AI增强科学发现的发展。
## Conclusion
当前的MLLM在SFE基准上的表现不佳，突显出需要进一步提高其在科学领域的性能。期待SFE基准能够促进MLLM在科学研究中的应用与改进。
# 278. `cs.CL` - Thought Anchors: Which LLM Reasoning Steps Matter? (思考节点：哪些大模型推理步骤最重要？ [PDF](https://arxiv.org/pdf/2506.19143), [HTML](https://arxiv.org/abs/2506.19143)
## Authors
Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy
## Background
大语言模型在许多领域取得了最先进的性能，但它们的长篇链式推理引起了可解释性难题，因为每个生成的词都依赖于所有之前的词，使得计算更难分解。目前的分析方法多在句子层面未能提供足够的可解释性。
## Innovation
文章提出了一种基于句子层面的归因方法，包括黑盒方法、白盒方法和因果归因方法，以识别推理中的关键步骤（称为思考节点）。这些方法通过比较模型生成句子前后答案的变化或通过抑制注意力来衡量句子之间的逻辑连接，识别出具有重大影响的推理步骤，并提供了一个可视化工具。
## Conclusion
不同方法的一致性证明了句子层面分析对更深入理解推理模型的潜力，这些思考节点通常是规划或回溯句子，展现了通过这些方法理解多步推理过程的可能性。
# 279. `cs.CL` - Aug2Search: 使用大型语言模型生成的合成数据增强提升Facebook Marketplace搜索 [PDF](https://arxiv.org/pdf/2505.16065), [HTML](https://arxiv.org/abs/2505.16065)
## Authors
Ruijie Xi,He Ba,Hao Yuan,Rishu Agrawal,Yuxin Tian,Ruoyan Kong,Arul Prakash
## Background
嵌入式检索（EBR）是现代搜索引擎中的重要技术，能够实现查询与相关结果的语义匹配。然而，Facebook Marketplace等平台上的搜索日志数据缺乏有效EBR模型训练所需的多样性和细节，限制了模型捕捉复杂搜索模式的能力。为解决这一挑战，本文提出了一种利用生成人工智能（GenAI）模型生成的合成数据的Aug2Search框架，采用多模态和多任务策略优化查询-产品相关性。实验使用了8个Llama模型和1亿条来自Facebook Marketplace日志的数据点进行研究。生成合成数据采用了三种策略：生成查询、增强产品列表和从增强列表生成查询。我们分别在真实的交互数据、合成数据以及二者的混合数据集上训练EBR模型，以评估其在不同训练集上的性能。实验结果表明，Llama模型生成的合成查询和列表具有高度的一致性、相关性和多样性，且低幻想率。在1亿条合成数据样本的支持下，Aug2Search达到了最高4%的ROC_AUC提升，证明了该方法的有效性。此外，实验显示，在相同训练数据量的情况下，仅使用合成数据训练的模型常常优于仅使用原始数据或两种数据混合的模型。
## Innovation
本文提出了一种Aug2Search框架，利用生成人工智能（GenAI）模型生成高质量的合成数据来增强嵌入式检索（EBR）的性能。这种方法采用多模态和多任务策略优化查询-产品相关性，尤其是通过大规模使用Llama模型生成的合成数据，提高了EBR模型的性能。
## Conclusion
研究结果表明，Llama模型在生成高质量的合成查询和列表方面表现出了良好的性能，一致性、相关性和多样性强且失真率低。Aug2Search在合成数据支持下能显著提升EBR模型的性能，最高可提升4%的ROC_AUC值。此外，合成数据增强了模型性能，特别是在与大量真实数据相同的训练情况下，仅使用合成数据训练的模型表现更佳。
# 280. `cs.CL` - Confucius3-Math: 一种轻量级高性能的中文K-12数学推理大语言模型 [PDF](https://arxiv.org/pdf/2506.18330), [HTML](https://arxiv.org/abs/2506.18330)
## Authors
Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan
## Background
介绍了Confucius3-Math，这是一个拥有14B参数的开源大语言模型，能够在单个消费级GPU上高效运行，并在一系列数学推理任务中达到最先进的性能，超过了更多的大模型。该模型旨在通过AI增强教育和知识传播，并特别致力于服务于中国的K-12学生和教师的数学学习。模型通过大规模强化学习训练，并且具备低成本解决主流K-12数学问题的能力。
## Innovation
提出了三种技术创新：目标熵正则化、最近样本恢复和策略特定难度加权。这些技术包括一种新的熵正则化方法、一种新的数据调度策略和改进的团体相关优势估计器。这些创新显著稳定了强化学习训练，提高了数据效率，提升了性能。
## Conclusion
展示了在特定领域构建强大推理模型的可行性，并且成本低廉。模型和代码已开源。
# 281. `cs.CL` - PP-DocBee2：通过高效数据提高多模态文档理解的基础模型 [PDF](https://arxiv.org/pdf/2506.18023), [HTML](https://arxiv.org/abs/2506.18023)
## Authors
Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu
## Background
本报告介绍了PP-DocBee2，这是PP-DocBee的高级版本，旨在提高多模态文档的理解能力。PP-DocBee2在大规模多模态模型架构的基础上，通过对关键技术改进，解决了前一代产品的局限性，包括提高合成数据质量、改进视觉特征融合策略以及优化推理方法。这些改进在中文商业文档的内部基准测试中提高了11.4%的性能，将推理延迟从原版减少了73.0%。我们工作的一个关键创新是对多模态文档任务的数据质量优化策略。通过使用大规模的多模态预训练模型评估数据，并应用新的统计标准筛选异常值，确保高质量的训练数据。此外，受到多模态模型中超利用的中间特征见解的启发，我们通过分解ViT表示能力和应用新的特征融合策略来增强其能力，以改善复杂的推理过程。
## Innovation
包括数据质量优化策略、改进的视觉特征融合策略以及提升复杂推理过程的ViT表示能力。具体而言, 通过大规模预训练模型评估数据，并应用新的统计标准筛选异常值，确保高质量的训练数据。此外，我们提供了一种新颖的特征融合策略，通过拆分ViT表示能力和利用中间特征来提升其表达能力和推理能力
## Conclusion
PP-DocBee2在解决现有问题的同时显著提升了性能，并大幅度减少了推理延迟。同时，通过开放源代码和预训练模型，为研究人员和开发者提供了便利。
# 282. `cs.CL` - OmniGen2：探索高级多模态生成 [PDF](https://arxiv.org/pdf/2506.18871), [HTML](https://arxiv.org/abs/2506.18871)
## Authors
Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu
## Background
本文介绍了OmniGen2，一个兼容且开源的生成模型，旨在提供多种生成任务的统一解决方案，包括文本到图像、图像编辑和上下文生成。OmniGen2通过分离文本和图像模态的解码路径，并且不重新适应VAE输入，使得可以利用现有的多模态理解模型，并保留原始的文本生成能力。此外，为支持OmniGen2的训练，本文还开发了全套的数据构建管道，涵盖了图像编辑和上下文生成数据，并为图像生成任务引入了反映机制，以及基于OmniGen2构建的专用反射数据集。尽管参数量相对较小，但OmniGen2在多个任务基准测试中获得了竞争力的表现。为了进一步评估上下文生成，OMG引入了名为OmniContext的新基准。在开放源代码模型中，OmniGen2在一致性方面达到了最先进的技术水平。
## Innovation
OmniGen2通过分离文本和图像模态的解码路径，并且不重新适应VAE输入，使得可以利用现有的多模态理解模型，并保留原始的文本生成能力。为支持OmniGen2的训练，开发了全套的数据构建管道，并引入了反映机制和专属的数据集。尽管参数量相对较小，但在多个任务基准测试中，OmniGen2获得了竞争力的表现。为评估上下文生成，引入了名为OmniContext的新基准。
## Conclusion
尽管参数量相对较小，OmniGen2在文本到图像和图像编辑等任务基准测试中表现竞争。对于上下文生成任务，OmniGen2在开放源代码模型中达到了最先进的技术水平。本文将发布模型、训练代码、数据集和数据构建管道，以支持未来在这个领域的研究。
# 283. `cs.CV` - 基于计算机视觉的农业喷雾器喷杆位移自动化量化 [PDF](https://arxiv.org/pdf/2506.19939), [HTML](https://arxiv.org/abs/2506.19939)
## Authors
Aryan Singh Dalal,Sidharth Rai,Rahul Singh,Treman Singh Kaloya,Rahul Harsha Cheppally,Ajay Sharda
## Background
在使用自走式农业喷雾器进行农业生产时，喷雾率误差是一个持续存在的问题。其中，喷杆的不稳定是导致应用误差的主要因素之一。喷杆宽度为38米，与30公里/小时的行驶速度、变化的地形以及在复杂田界操作时的机械动力学相结合，使得喷杆控制变得非常复杂。然而，缺乏对喷杆移动幅度的定量知识，影响了系统性的解决方案的开发，包括喷杆设计和响应式喷杆控制系统。因此，该研究旨在开发一种自动化的计算机视觉系统，以量化不同农业喷雾器的喷杆移动。
## Innovation
研究开发了基于YOLO V7、V8和V11神经网络模型的计算机视觉系统，用于实时跟踪喷雾器喷杆边缘的目标，测量喷杆在垂直和横向方向的有效位移。此外，还通过安装倾角传感器捕捉喷杆角度，验证神经网络模型输出。研究表明，模型可检测目标的准确率超过90%，且目标距离估计值与倾角传感器数据的差异不超过0.026米。这表明该系统不仅能量化当前喷雾器的喷杆移动，还能对任何其他喷雾器进行类似量化，需要进行少量修改。数据可用于设计改进喷雾器喷杆以提高其稳定性，进而实现更高的应用准确性。
## Conclusion
该研究开发的系统能够对农业喷雾器喷杆的位移进行精准量化，并为设计改进喷杆提供了数据支持，有助于提高农业喷雾器的喷洒精度。
# 284. `cs.CL` - 能否用语言模型替代程序员进行编码？REPOCOD 表示‘尚未’ [PDF](https://arxiv.org/pdf/2410.21647), [HTML](https://arxiv.org/abs/2410.21647)
## Authors
Shanchao Liang,Yiran Hu,Nan Jiang,Lin Tan
## Background
近年来，出现了诸如 CoderEval、DevEval、RepoEval、RepoBench 和 LongCodeArena 等针对代码生成的仓库级别基准测试，用于评估大型语言模型（LLMs）的能力，超越了单独的基准测试如 HumanEval 和 MBPP。然而，现有基准测试的代码片段较短，合成且缺乏大规模仓库的真实场景，无法完全代表实际编码任务。因此，研究该文旨在创建一个真实的基准测试，REPOCOD，包含具有复杂依赖关系的真实大型项目中的任务和适当的源代码评估指标。
## Innovation
REPOCOD 是一个包含来自 11 个流行项目的 980 个完整函数生成任务的 Python 代码生成基准测试，其中 50.8% 要求仓库级别的上下文。每个实例包括 314 个开发人员编写的测试用例，以改善评估。该基准测试评价了十种 LLM，发现它们在 REPOCOD 上的 pass@1 值均不超过 30%，这表明需要更强的 LLM 来协助现实世界的软件开发。此外，研究表明，检索增强生成比使用目标函数依赖性作为上下文效果更好。
## Conclusion
十种 LLM 在 REPOCOD 上的表现表明，构建更强的 LLM 来帮助开发人员进行实际软件开发变得必要。检索增强生成优于使用目标函数依赖性作为上下文。REPOCOD 将 LLM 在实际大型项目中的编码能力进行了有效的评估，显示出现有 LLM 与编程任务的实际需求之间仍存在差距。
# 285. `cs.CV` - BrokenVideos: 一种用于AI生成视频中细粒度缺陷定位基准的数据集 [PDF](https://arxiv.org/pdf/2506.20103), [HTML](https://arxiv.org/abs/2506.20103)
## Authors
Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang
## Background
近年来，深度生成模型在视频生成方面取得了显著进展，但在生成的视频中，AI生成内容的质量仍然有限。合成内容常常出现视觉艺术，如时间不一致的运动、物理上不合理的轨迹、不自然的对象变形和局部模糊，这些都会损害真实感和用户信任。准确地检测和空间定位这些缺陷对自动化质量控制和改进生成模型至关重要。然而，目前研究界缺乏专门针对AI生成视频中缺陷定位的综合基准。现有的数据集要么仅限于视频或帧级别的检测，要么缺乏必要的细粒度空间注释来评估定位方法。为解决这一缺口，我们引入了BrokenVideos，这是一个包含3254个AI生成视频的数据集，每个视频均有详细的像素级注释，标示出视觉破坏的区域。每个注释都通过详细的人类检验来确保高质量的标准答案。
## Innovation
我们提出了BrokenVideos，这是一个基准数据集，包含3254个AI生成视频，具有详细的人工验证的像素级标注，明确指出视觉破坏的区域。我们的实验证明，训练最先进的缺陷检测模型和多模态大规模语言模型（MLLMs）在BrokenVideos上能显著提高它们识别破坏区域的能力。实验还表明，BrokenVideos为评估和推进生成视频模型中缺陷定位的研究奠定了关键基础。
## Conclusion
通过广泛评估，我们展示BrokenVideos为评估和推动生成视频模型中缺陷定位的研究奠定了关键基础。该数据集可供此链接下载：this https URL.
# 286. `cs.CV` - 从2D到3D认知：通用世界模型的简要综述 [PDF](https://arxiv.org/pdf/2506.20134), [HTML](https://arxiv.org/abs/2506.20134)
## Authors
Ningwei Xie,Zizi Tian,Lei Yang,Xiao-Ping Zhang,Meng Guo,Jie Li
## Background
世界模型在通用人工智能（AGI）的发展中受到越来越多的关注，它们作为计算框架帮助学习外部世界的表示并预测未来状态。早期工作侧重于2D视觉感知和模拟，而最近的3D感知生成世界模型展示了合成几何上一致的交互3D环境的能力，这标志着向3D空间认知的转变。然而，尽管取得了快速进展，该领域仍缺乏系统分析来分类新兴技术并澄清它们在提高3D认知世界模型方面的作用。
## Innovation
本文提出了一种概念框架，提供了一个结构化的、前瞻性的综述，涵盖了从2D感知向3D认知过渡的世界模型。通过该框架，突出了两个关键的技术驱动力，特别是3D表示的进展和世界知识的纳入，作为基本支柱。此外，深入分析了支持3D世界建模的三种核心认知能力：3D物理场景生成、3D空间推理和3D空间交互。还评估了这些能力在实际应用中的部署情况，包括机器人体感、自动驾驶、数字孪生和游戏/VR。
## Conclusion
最后，本文指出了数据、建模和部署方面的挑战，并为推进更鲁棒和广泛适用的3D世界模型提出了未来研究方向。
# 287. `cs.CV` - 使用多模态VLMs的高效实例基础图像编辑 [PDF](https://arxiv.org/pdf/2506.20155), [HTML](https://arxiv.org/abs/2506.20155)
## Authors
Avadhoot Jadhav,Ashutosh Srivastava,Abhinav Java,Silky Singh,Tarun Ram Menta,Surgan Jandial,Balaji Krishnamurthy
## Background
文本到图像的扩散模型已经使得一系列图像编辑应用成为可能。然而，仅通过文本捕捉所有类型的编辑可能具有挑战性和繁琐性。某些图像编辑的模糊特性更适合通过示例对来表达，即一对分别展示编辑前后的图像对。
## Innovation
本文通过利用预训练的文本到图像扩散模型和多模态VLMs，提出了示例基础图像编辑任务，即通过示例对将编辑转移到内容图像上。尽管整个端到端的流程不依赖优化，实验仍展示出该方法在多种类型编辑上优于基准，并且速度快4倍。
## Conclusion
该研究通过利用预训练模型，提出了一种高效的、不依赖优化的示例基础图像编辑方法，在多种类型的编辑任务中，其性能优于现有基准，并具有更高的效率。
# 288. `cs.CL` - FluoroSAM：一种灵活的X射线图像分割语言提示基础模型 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
现有技术已贡献了针对特定任务的模型，能够在狭窄范围内解决特定问题，但扩大到更广泛的应用则需要额外的数据、注释和训练时间。过去，语言对齐的基础模型（LFMs）——基于大量高变异性图像和文本数据训练的机器学习模型，从而具备广泛的适用性——被认为是自动化图像分析的有力工具。当前的医学图像分析的基础模型集中在数据丰富且具有良好注释的场景和模态上。然而，X射线成像模态具有高度变化的图像外观和应用场景，从诊断胸部X光到介入性透视，数据的可用性也有所不同。为了实现一种全面且语言对齐的基础模型，用于分析任意医学X射线图像，研究人员引入了FluoroSAM。
## Innovation
FluoroSAM是一种基于Segment Anything Model训练出的可语言提示的X射线图像分割基础模型。它在300万合成X射线图像上进行了从头训练，这些图像涵盖了广泛的解剖学、成像几何和视角。通过在训练过程中新颖地使用文本嵌入矢量量化（VQ）技术，FluoroSAM能够在自然语言提示下进行多种解剖结构和工具的分割。研究展示了FluoroSAM在实际X射线图像上的性能，并展示了它在X射线图像获取和分析上下文中，促进丰富的人机交互能力。
## Conclusion
FluoroSAM为X射线图像分割提供了更灵活的工作流程，与以往基于大量特定领域数据的任务特定模型相比，它可以通过自然语言提示以更为灵活的方式处理不同类型的X射线图像，为诊断和介入精准医学提供了新的可能性。同时，FluoroSAM的引入展示了语言提示基础模型在医学图像分析中具有广泛的应用前景。
# 289. `cs.CV` - ToSA：具有空间意识的标记合并 [PDF](https://arxiv.org/pdf/2506.20066), [HTML](https://arxiv.org/abs/2506.20066)
## Authors
Hsiang-Wei Huang,Wenhao Chai,Kuang-Ming Chen,Cheng-Yen Yang,Jenq-Neng Hwang
## Background
标记合并已成为通过减少计算成本加速视觉变换器（ViT）的有效策略。现有方法主要依赖视觉标记特征的相似性来进行标记合并，忽略了空间信息的潜在整合价值。特别是在ViT的早期层，由于视觉标记仅包含微弱的视觉信息，空间信息作为标记合并的可靠标准具有潜在优势。但现有方法对此没有充分利用。因此，本文着眼于解决这一问题，提出了一个结合语义与空间感知的新方法ToSA，以指导标记合并过程。
## Innovation
ToSA提出了一种结合语义和空间感知的新标记合并方法，通过将深度图像作为输入生成伪空间标记，为视觉标记合并过程提供辅助空间信息。这种方法提供了一个更知情的合并策略，更好地保留了关键场景结构。实验结果表明，ToSA在多个视觉和自主问答基准上的表现优于现有标记合并方法，同时显著减少了ViT的运行时间，提升了ViT加速的效率。
## Conclusion
本文提出了ToSA，一种结合语义和空间感知的标记合并方法，通过引入空间意识，实现更智能的标记合并策略，从而更好地保留关键场景结构。实验结果显示，ToSA在多个基准上的性能优于现有方法，并在保持ViT高效的同时缩短了运行时间，展示了其作为ViT加速的有效解决方案的能力。更多代码将在this https URL找到。
# 290. `cs.CV` - EBC-ZIP: 使用零膨胀泊松回归改进块状人群计数 [PDF](https://arxiv.org/pdf/2506.19955), [HTML](https://arxiv.org/abs/2506.19955)
## Authors
Yiming Ma,Victor Sanchez,Tanaya Guha
## Background
人群计数中的密度图估计已成为主流方法。然而，现有的大多数方法忽略了地面真实密度图的高度稀疏性。在现实世界的人群场景中，大量空间区域（通常超过95%）没有人员，导致计数分布严重不平衡。忽略这种不平衡会使模型倾向于高估密集区域的计数，而在稀疏区域表现不佳。此外，用于密度估计的大多数损失函数主要基于均方误差（MSE），并隐含假定了高斯分布，这对于建模离散且非负的计数数据而言并不适合。因此，该领域的研究需要一种新的方法来解决这些问题。
## Innovation
本文提出了EBC-ZIP，一种人群计数框架，使用零膨胀泊松（ZIP）回归来建模计数的空间分布。EBC-ZIP的工作原理是在传统的回归损失中替换为ZIP分布的负对数似然，从而可以更好地处理以零为主的分布，同时保持计数准确性。EBC-ZIP建基于最近提出的增强块分类（EBC）框架之上，不仅保留了目标的离散性和训练稳定性，还通过更合理的原则性损失进一步提高了性能。此外，EBC-ZIP也利用不同计算复杂度的主干架构进行了评估，以测试其可扩展性。
## Conclusion
在四个人群中计量基准上的广泛实验表明，EBC-ZIP在所有基准上都超越了EBC，并且达到了最先进的技术水平。
# 291. `cs.CV` - EAR: Erasing Concepts from Unified Autoregressive Models [PDF](https://arxiv.org/pdf/2506.20151), [HTML](https://arxiv.org/abs/2506.20151)
## Authors
Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang
## Background
自回归（AR）模型已经在视觉理解和图像生成任务上取得了统一且强大的表现。然而，如何在保持整体生成质量的同时消除AR模型中的不需要的概念仍然是一个开放的挑战。因此，研究人员提出了一种名为Erasure Autoregressive Model（EAR）的新方法，以实现有效且实用的概念消除。EAR方法通过引入Windowed Gradient Accumulation（WGA）和Thresholded Loss Masking（TLM）策略来优化这一任务，旨在解决上述挑战。
## Innovation
该论文提出了一种名为Erasure Autoregressive Model（EAR）的方法，该方法包括两个关键策略：Windowed Gradient Accumulation（WGA）和Thresholded Loss Masking（TLM）。WGA策略通过层次解码与消除目标对齐来优化模型，而TLM策略则在微调期间保护与目标概念无关的内容。此外，论文还提出了一种新的基准测试，Erase Concept Generator and Visual Filter（ECGVF），为评估统一自回归模型中的概念消除提供了更严谨和全面的基础。ECGVF采用结构化模板从各种大型语言模型（LLMs）中预生成大规模的概念替换提示对，然后通过视觉分类器进行严格的筛选，确保概念保真度和对齐。
## Conclusion
在针对基准测试ECGVF的实验中，EAR方法在消除效果和模型实用性保留方面均取得了显著提升。实验使用AR模型Janus-Pro进行验证，结果表明EAR方法的有效性和实用性。相关代码已经在指定的链接中公开。
# 292. `cs.CV` - Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models [PDF](https://arxiv.org/pdf/2506.20168), [HTML](https://arxiv.org/abs/2506.20168)
## Authors
Zhentao He,Can Zhang,Ziheng Wu,Zhenghao Chen,Yufei Zhan,Yifan Li,Zhao Zhang,Xian Wang,Minghui Qiu
## Background
近年来，多模态大型语言模型通过整合文本和视觉信息，提升了文档理解的水平。然而，现有的模型在现实世界场景中，在视觉降级的情况下表现不够完整。在这些条件下，当前的反应模式往往无法充分感知视觉降级和模糊，导致过度依赖语言先验或错配的视觉-文本推理，这使得模型在不确定性数据上产生了幻觉内容。为了解决这些问题，作者提出了KIE-HVQA基准集，这是一个专门用于评估OCR幻觉的降解文档理解数据集。通过引入GRPO框架和新的奖励机制，该研究旨在避免幻觉，提高模型在处理模糊区域时的准确性，同时确保标准任务上的性能不受影响。
## Innovation
作者提出了KIE-HVQA，这是第一个专注于评估OCR幻觉的降解文档理解基准数据集，包括身份证和发票的模拟真实世界降解样本。此外，作者还引入了基于GRPO框架的新型奖励机制，通过增强模型对视觉不确定性的自我感知能力，并通过拒绝回答增加难度，从而在监督微调和强化学习框架中成功减轻了不确定区域的幻觉现象。在Qwen2.5-VL上进行的实验表明，7B参数的模型在KIE-HVQA基准上的幻觉无错误准确度比GPT-4o高22%，而且在标准任务上的性能没有明显下降，展示了其有效性和稳健性。
## Conclusion
研究通过KIE-HVQA基准集和GRPO框架，成功解决了多模态大型语言模型在视觉降级情况下的幻觉问题，提高了模型处理降解输入的能力，并且保证了标准任务的性能不受影响。
# 293. `cs.CV` - 损失感知的选择结构化剪枝准则方法用于深度神经网络加速 [PDF](https://arxiv.org/pdf/2506.20152), [HTML](https://arxiv.org/abs/2506.20152)
## Authors
Deepak Ghimire,Kilho Lee,Seong-heum Kim
## Background
结构化剪枝是压缩神经网络的一个成熟技术，适合在资源有限的边缘设备上部署。传统的剪枝方法采用三阶段（训练、剪枝、微调）流程，而现有的大多数方法都未能有效结合剪枝和微调为一个连贯的过程。本文提出了一种损失感知的选择结构化剪枝准则（LAASP）方法，旨在简化和优化这一过程。
## Innovation
提出了一个剪枝-训练一体化的方法，省去了传统的训练阶段，将剪枝和微调整合到单一流程中。通过在小训练数据集上使用网络的整体损失自动选择幅度或相似性基于滤波器剪枝准则和剪枝层，同时，在达到预定义的浮点运算（FLOPs）减少数量时，网络会进行短暂的重新训练以减轻剪枝后的精度锐降问题。这种方法自动确定每层的最佳剪枝率，无需人为设定固定的或可变的剪枝率。实验表明该方法在VGGNet和ResNet模型上的CIFAR-10和ImageNet基准数据集上表现优异，尤其是ResNet56和ResNet110模型在CIFAR-10上的top-1精度显著提升，同时减少了网络FLOPs。ResNet50模型在ImageNet数据集上的FLOPs减少了超过42%，且精度下降不到0.33%。
## Conclusion
实验结果表明，所提出的LAASP方法能够有效加速深度神经网络，并在多个基准数据集上展示了其在性能和计算效率上的优越性。
# 294. `cs.CV` - 动态事件-RGB混合传输中的带宽分配 [PDF](https://arxiv.org/pdf/2506.20222), [HTML](https://arxiv.org/abs/2506.20222)
## Authors
Pujing Yang,Guangyi Zhang,Yunlong Cai,Lei Yu,Guanding Yu
## Background
事件摄像头异步捕捉像素级别的强度变化，具有极低的延迟，广泛应用于各种与视觉相关的应用中。然而，这些混合系统中的一大挑战是如何高效传输大量触发的事件和RGB图像。常规情况下，RGB摄像头和事件摄像头通常以不同的方式捕捉同一场景，导致输出信息存在大量冗余，这在传输和处理上带来了挑战。
## Innovation
本文提出了一种传输方案，不仅保留了事件和图像来源的高效重建性能，还能实现并行实时降模糊。通过开发联合事件和图像（E-I）传输框架，该方案消除了冗余信息，优化了通道带宽利用率。通过贝叶斯建模和信息瓶颈方法来分离E-I输入中的共享信息和领域特定信息，此整合的信息瓶颈框架确保了提取的共享和领域特定信息既紧凑又有信息量。并且，该方法根据场景动态情况自适应分配带宽，即在动态细节处分配更多事件符号，在静态信息处分配更多图像符号。
## Conclusion
模拟结果表明，所提出的方案不仅在重建质量上优于传统的系统，且在去模糊性能上也有所增强。
# 295. `cs.CV` - 任何场景下识别手术阶段：少量样本测试时自适应及任务图引导优化 [PDF](https://arxiv.org/pdf/2506.20254), [HTML](https://arxiv.org/abs/2506.20254)
## Authors
Kun Yuan,Tingxuan Chen,Shi Li,Joel L. Lavanchy,Christian Heiliger,Ege Özsoy,Yiming Huang,Long Bai,Nassir Navab,Vinkle Srivastav,Hongliang Ren,Nicolas Padoy
## Background
手术工作流程的复杂性和多样性，受异质的手术室环境、机构协议和解剖差异的影响，使得在跨机构和跨程序理解手术方面开发通用模型面临巨大挑战。尽管基于大规模视觉-语言数据预训练的手术基础模型展现了潜在的迁移能力，但它们的零样本性能受限于领域转移，限制了它们在未见过的手术环境中的应用。
## Innovation
针对现有问题，我们提出了 Surgical Phase Anywhere（SPA），一个轻量级框架，用于通用手术工作流程理解，通过最小化注释来适应机构环境。SPA 利用少量样本的空间自适应来对齐多模态嵌入和机构特定的手术场景及阶段，并通过扩散模型确保时间一致性，编码来自机构程序协议的任务图先验。SPA 还通过动态的测试时自适应来实现自监督适应，利用多模态阶段预测流之间的相互一致性来适应给定的测试视频，从而增强测试时期的分布偏移健壮性。
## Conclusion
实验结果显示，SPA 框架在多个机构和程序中的少量样本手术阶段识别上取得了最先进的性能，甚至在带有 32 个标注样本的数据下，其性能超过了完全标注模型。
# 296. `cs.CV` - 基于Transformer结合在线和离线特征的书写识别系统 [PDF](https://arxiv.org/pdf/2506.20255), [HTML](https://arxiv.org/abs/2506.20255)
## Authors
Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal
## Background
目前大多数书写识别系统只利用了一种模态，例如只利用离线图像或在线笔迹序列。本文认为，书写识别可以从笔迹像素图和笔迹轨迹中提取的互补提示中获益。当前的研究工作旨在提出一种结合在线笔迹数据和离线图像的端到端网络，通过在共享潜在空间中进行早期融合来改进书写识别系统的性能。
## Innovation
本文提出了一种利用Transformer的端到端系统，能够同时处理离线静态图像和在线动态笔迹数据。技术性创新包括使用Patch Encoder将灰度裁剪转换为固定长度的视觉标记，使用轻量级Transformer嵌入$(x, y, text{pen})$序列，并采用可学习的潜在查询同时关注两个标记流，从而产生包含上下文增强的笔迹嵌入，最终通过交叉熵损失目标进行池化和解码。这种联合处理方式可以在特征表示学习中增强时序线索，从而增强写作者独立性。
## Conclusion
在针对IAMOn-DB和VNOn-DB的全面实验中，本文提出的方法达到了最先进的准确度，在某些指标上超越了之前最好的方法，精度提高了1%。此外，研究还展示了在ISI-Air数据集上这种方法的适应性。
# 297. `cs.CV` - 通过织物比较进行的绘画法医学研究 [PDF](https://arxiv.org/pdf/2506.20272), [HTML](https://arxiv.org/abs/2506.20272)
## Authors
Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén
## Background
研究艺术品中的画布是鉴定、归属和保护的关键工具。传统的研究方法依赖于线密度图的匹配，但对于那些不是由卷上连续位置绘制的画布来说，这种方法并不适用。这篇文章介绍了一种基于深度学习的新颖方法，用于评估纺织品的相似性。
## Innovation
提出了一种不受线密度图限制的自动工具，通过深度学习模型比较画布的相似性，并提出了一种基于多个布料样本预测的相似性估计方法，提供了稳健的相似性评分。该方法适用于普拉多国家博物馆的画布，并证明了甚至在画布线密度相似的情况下，普通的平纹织布也可以有效进行比较。
## Conclusion
研究的结果证实了所提方法的可能性和准确性，为名画的分析开辟了新的途径。
# 298. `cs.CV` - UniCode$^2$: 梯级大规模码本实现统一多模态理解和生成 [PDF](https://arxiv.org/pdf/2506.20214), [HTML](https://arxiv.org/abs/2506.20214)
## Authors
Yanzhe Chen(Yen-chieh Chan),Huasong Zhong,Yan Li,Zhenheng Yang
## Background
现有的基于码本的多模态大语言模型（MLLMs）方法要么依赖于小词汇量（约16K项），缺乏细致的语义，要么盲目放大，导致低效率的建模和不稳定的训练。这些模型在视觉理解与生成方面的表现有待提升，尤其是在词汇量、语义对齐和稳定训练方面存在不足。新提出的UniCode$^2$通过构建50万条目的大规模码本，改善了视觉码本的容量和语义对齐，同时保持了视觉和文本语义的一致性，从而提高了在多模态理解和生成任务中的表现。
## Innovation
UniCode$^2$提出了一种梯级框架，通过分层设计解决了扩大规模和保持语义一致性和训练稳定性之间的平衡问题。具体来说，该框架包括一个固定的码本作为基础，稳定嵌入空间，以及一个可训练的码本用于精炼特定任务的语义。这种设计理念提高了视觉标记的利用效率，并增强了模型在各种任务上的鲁棒性。此外，视觉标记与文本语义的一致性使得模型能够无缝集成到预训练的扩散解码器中，极大地减少了对视觉合成的适应性需求，同时提供了高质量的视觉生成结果。
## Conclusion
UniCode$^2$方法在多个基准测试中取得了出色的表现，证明了在视觉标记空间扩展的同时，仍然能够保持稳定性、语义对齐和模块化的设计方案的可行性与优势。
# 299. `cs.CV` - Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification [PDF](https://arxiv.org/pdf/2506.20263), [HTML](https://arxiv.org/abs/2506.20263)
## Authors
Ning Luo,Meiyin Hu,Huan Wan,Yanyan Yang,Zhuohang Jiang,Xin Wei
## Background
FS-FGIC面临一个显著的挑战，要求模型在有限标注样本的情况下区分视觉上相似的子类别。现有方法存在关键限制：度量基于的方法会丢失空间信息，错位局部特征；重建基于的方法无法利用层次特征信息，并缺乏聚焦于区分性区域的机制。
## Innovation
提出了一种名为HMDRN的双层特征重建与掩码增强特处理的网络，该网络整合了双层特征重建和融合模块，利用不同网络层级的互补视觉信息。通过可学习的融合权重，该模型在高层次语义表示和中间层次结构细节之间进行了平衡。此外，还设计了空间二值掩码增强的自重构模块，通过自适应阈值处理查询特征，保持完整支持特征，增强了对区分性区域的处理能力，同时过滤掉背景噪声。实验证明，HMDRN在Conv-4和ResNet-12主干网络上的一系列挑战性细粒度数据集上表现优于现有最好的方法。综合消融研究验证了每个提出组件的有效性，显示双层重建促进了类间区分，而掩码增强的转换减少了类内变异。
## Conclusion
HMDRN在挑战性细粒度数据集上的一致表现和组件的有效性验证结果表明，该模型在FS-FGIC中具有优越的特征重建能力，并且其双层重建结构和掩码增强的特处理机制显著提升了细粒度分类的性能。
# 300. `cs.CV` - 通过基础模型组合实现地球观测数据挖掘的可扩展性和泛化能力 [PDF](https://arxiv.org/pdf/2506.20174), [HTML](https://arxiv.org/abs/2506.20174)
## Authors
Man Duc Chuc
## Background
基础模型正在迅速改变地球观测数据挖掘领域，通过提供可推广和可扩展的解决方案，特别是在场景分类和语义分割等关键任务上。尽管在地理空间领域，大多数努力着重于从大规模地球观测数据集从零开始训练大型模型，但未充分利用的一种替代策略是重用和组合现有的预训练模型。本文探讨了是否可以通过组合卫星遥感和通用视觉任务的预训练模型来改善各种关键地球观测任务的性能。研究使用GEO-Bench基准评估了若干知名模型，包括Prithvi、Hiera和DOFA，在涵盖不同空间分辨率、传感器类型和任务类型的11个数据集上进行评估。
## Innovation
研究表明，特征级组合小型预训练模型可能能够达到或超越大型模型的性能，同时需要更少的训练时间和计算资源。此外，研究表明，可以通过知识蒸馏将组合的优势转移到更紧凑的模型中，为在现实世界地球观测应用中部署基础模型提供了一条可行的道路。这一方法在地球观测数据挖掘领域的可扩展性和泛化能力方面具有创新性。
## Conclusion
通过预训练的卫星遥感模型和通用视觉任务的组合，可以在各种地球观测任务中实现性能改进。特征级的组合可以在不消耗大量资源的情况下达到甚至超越大型模型的性能。知识蒸馏可以帮助将组合的优势转移到更紧凑、更实用的模型中，从而在实际应用中更好地部署基础模型。
# 301. `cs.CV` - Ctrl-Z Sampling: 控制性随机锯齿探索的扩散采样 [PDF](https://arxiv.org/pdf/2506.20294), [HTML](https://arxiv.org/abs/2506.20294)
## Authors
Shunqi Mao,Wei Guo,Chaoyi Zhang,Weidong Cai
## Background
扩散模型在逐级去噪高斯噪声以生成目标数据分布方面表现出强大的性能。这个去噪过程可以被解释为在学习的潜在空间中的梯度爬升，模型逐步在高概率区域打磨样本。然而，扩散模型经常会收敛到局部最优解，这些解在局部视觉上连贯但在全局上不一致或条件错位，原因在于潜在空间的复杂性以及初始化的次优性。先前的努力试图通过增强指导信号或修改初始噪声分布来解决这一问题。
## Innovation
我们提出了控制性随机锯齿采样（Ctrl-Z Sampling），这是一种新的采样策略，旨在在条件生成过程中检测并逃脱局部最大值。该方法首先使用奖励模型识别潜在的局部最大值，一旦检测到，它就会注入噪声并恢复到先前更嘈杂的状态以跳出当前的优化平台。然后，奖励模型评估候选轨迹，接受那些提供改进的轨迹，深度退回到更早的状态可以更有力地摆脱邻近的失败选项。这种方式下的控制性随机锯齿过程允许在前进精炼和后退探索之间动态交替，从而增强生成输出的对齐和视觉质量。Proposed Ctrl-Z Sampling是一种与扩散模型无关的方法，并且兼容现有扩散框架。实验结果表明，Ctrl-Z Sampling仅增加约7.6倍的函数评估，就能显著提高生成质量。
## Conclusion
实验结果表明，Ctrl-Z Sampling能够在生成质量显著提升的同时，仅增加约7.6倍的函数评估量。
# 302. `cs.CV` - 基于Transformer的扩散模型在图像修复任务中的应用 [PDF](https://arxiv.org/pdf/2506.20302), [HTML](https://arxiv.org/abs/2506.20302)
## Authors
Abbas Anwar,Mohammad Shullar,Ali Arshad Nasir,Mudassir Masood,Saeed Anwar
## Background
在具有挑战性的环境中拍摄的图像常常会受到噪声、色偏、模糊和散射光等多种形式的退化，这显著降低了图像质量，影响了在物体检测、建图和分类等下游任务中的应用效果。
## Innovation
本文提出了一种基于转换器的扩散模型，旨在解决图像修复任务，通过多种质量指标在水下图像增强、去噪和去雨等任务中与现有深度学习方法进行对比实验，表明该模型不仅在这些方面表现优于现有方法，而且还能够提升退化图像的质量，进一步扩大了其在需要高保真视觉数据的下游任务中的应用范围。
## Conclusion
实验结果证明了扩散模型和转换器在提高退化图像质量方面的有效性和优越性，从而增强了其在对视觉数据要求严格的下游任务中的适用性。
# 303. `cs.CV` - 渐进对齐退化学习用于超分辨率融合 [PDF](https://arxiv.org/pdf/2506.20179), [HTML](https://arxiv.org/abs/2506.20179)
## Authors
Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu
## Background
深度学习基于的超分辨率多光谱（HRMS）图像生成已被证明是有效的。Wald协议是创建监督地真相分辨率图像的常用方法，该协议假设在低分辨率数据上训练的网络在高分辨率数据上也能表现出相同的效果。然而，经过充分训练的模型通常在低分辨率和全分辨率数据集的性能之间表现出权衡。因此，本文探讨了Wald协议的不准确性及其对现实退化模式的不准确近似，这限制了深度超分辨率融合模型的泛化能力。
## Innovation
本文提出了渐进行对齐退化模块（PADM），这是一种通过两个子网络PAlignNet和PDegradeNet之间的相互迭代学习准确退化过程的方法，无需依赖预定义的操作。此外，引入了HFreqdiff，这是一种嵌入高频细节的扩散框架，并包含CFB和BACM模块以进行频率选择性细节提取和精确逆过程学习。这些创新性方法能够有效整合高分辨率全景和多光谱图像，显著提高空间明晰度和图像质量。
## Conclusion
实验和消融研究证明了提出方法在与最先进的技术相比时的优越性能。
# 304. `cs.CV` - 从理想到实际：统一且数据高效的密集预测以适应现实场景 [PDF](https://arxiv.org/pdf/2506.20279), [HTML](https://arxiv.org/abs/2506.20279)
## Authors
Changliang Xia,Chengyou Jia,Zhuohang Dang,Minnan Luo
## Background
密集预测任务在计算机视觉中至关重要，旨在为输入图像学习像素级别的标注标签。尽管近年来在该领域取得了进展，但现有方法主要集中在理想条件下，缺乏对现实世界场景的泛化能力，且面临现实世界数据稀缺的挑战。为了系统性地研究这一问题，研究人员首先介绍了DenseWorld基准，涵盖了25项与迫切现实应用相关的密集预测任务，并通过统一评估策略实现跨任务的统一评测。同时，提出了DenseDiT方法，通过利用生成模型的视觉先验，采用统一策略执行多样化的现实世界密集预测任务。DenseDiT方法结合了参数复用机制和两个轻量级分支，能够自适应地整合多尺度上下文，且只使用不到0.1%的额外参数。实验表明，现有通用和专门的基础方法在DenseWorld上表现出明显的性能下降，其在现实世界通用性有限。相比之下，DenseDiT仅使用少于基准数据的0.01%即可获得更好的结果，显示出其实用价值，适用于现实世界的部署。
## Innovation
提出了DenseDiT方法，通过利用生成模型的视觉先验，在统一策略下执行多样化的现实世界密集预测任务，结合参数复用机制和两个轻量级分支，能够自适应地整合多尺度上下文。该方法仅使用不到0.1%的额外参数，显著提升了现实世界密集预测任务的性能，且只需少于基准数据0.01%的训练数据即可实现良好效果，展示出显著的数据效率优势。
## Conclusion
DenseWorld基准的评估结果表明，现有针对密集预测任务的基础方法（无论是通用的还是专门的）在现实世界场景中的泛化性能有限，而DenseDiT方法通过高效利用生成模型先前知识，不仅显著提高了现实世界密集预测任务的性能，而且仅需少量训练数据就能实现较好的效果，突显了其实用性。
# 305. `cs.CV` - 打破空间限制：基于光谱域注册的高光谱和多光谱盲融合 [PDF](https://arxiv.org/pdf/2506.20293), [HTML](https://arxiv.org/abs/2506.20293)
## Authors
Kunjing Yang,Libin Zheng,Minru Bai,Ting Lu,Leyuan Fang
## Background
当前，未注册的高光谱图像（HSIs）和多光谱图像（MSIs）的盲融合受到了越来越多的关注。然而，大多数现有方法通过在HSI上应用空间变换以实现与MSI的对齐，但由于两者的空间分辨率差异较大，这些方法的性能往往不尽如人意。此外，在处理遥感中的大型图像时，对齐过程通常会耗费大量时间。
## Innovation
本文提出了一种新的方法来解决对齐问题，即从光谱域入手，首先开发了一个轻量级的光谱先验学习（SPL）网络，用于从HSI中提取光谱特征并增强MSI的光谱分辨率，然后对图像进行空间下采样以生成对齐的HSI。在此过程中，采用了子空间表示和循环训练策略以提高对齐HSI的光谱准确性。此外，还提出了一种盲目稀疏融合（BSF）方法，利用组稀疏正则化等价地增强了图像的低秩性，不仅避免了秩估计的需要，还降低了计算复杂性。最后，通过使用交替优化接近算法（PAO）解决BSF模型，并提供其收敛性分析。
## Conclusion
本文通过广泛的模拟和现实数据集上的数值实验验证了该方法在对齐和融合方面的有效性，并展示了其在提高分类性能方面的成效。
# 306. `cs.CV` - 膝关节MRI图像评估的放射组学指纹 [PDF](https://arxiv.org/pdf/2506.20306), [HTML](https://arxiv.org/abs/2506.20306)
## Authors
Yaxi Chen,Simin Ni,Shaheer U. Saeed,Aleksandra Ivanova,Rikin Hargunani,Jie Huang,Chaozong Liu,Yipeng Hu
## Background
膝关节MRI扫描的准确解读依赖于临床专家的判断，但往往存在高变异性且难以大规模实施。现有放射组学方法采用固定的一系列放射组学特征（特征签名），这些特征在患者层面进行选择并应用于所有患者，尽管可解释性较强，但往往太过受限，无法代表个体的病理变异，导致传统基于放射组学的方法在性能上低于无放射组学特征且采用端到端深度学习的新方法。研究指出当前放射组学特征选择的核心不是缺乏个体差异性导致的不可解释性，而是其在泛化能力上的不足。文章认为，一种基于深度学习构建个性特征集的新框架可以解决这一问题，这种框架根据每个患者的预测结果动态构建特征集，确保特征的可解释性和预测性，同时与低维度逻辑回归结合培训，提高诊断准确性，提供临床洞察并发现潜在生物标志物。
## Innovation
文章提出了一种新颖的放射组学指纹框架，该框架根据不同患者从大量放射组学特征中动态构建特征集，而不是固定使用统一的特征集。通过深度学习预测特征的相关性，并选择对个体患者临床状况有预测性的特征。该研究还同时训练了低维度逻辑回归模型，并通过多种诊断任务验证了该方法的诊断准确性，展示了端到端深度学习模型的性能。更重要的是，研究表明此方法的内在可解释性有助于提供有意义的临床见解并发现潜在生物标志物，通过实际临床案例的详细讨论和定量、定性的分析来证实这些优势。
## Conclusion
研究通过多重诊断任务验证了放射组学指纹框架的有效性，相对现有的端到端深度学习模型具有相当或更高的诊断准确性。更重要的是，此方法的可解释性显著增强了临床意义，促进了生物标志物的发现，这次提出了基于深度学习的个性化放射组学特征选择方法与低维度逻辑回归的结合培训，在膝关节MRI图像评估方面实现了精准医疗和可解释性的双重目标。
# 307. `cs.CV` - 从手稿学到代码：基于Transformer和YOLO的检测器在历史文档布局分析中的比较研究 [PDF](https://arxiv.org/pdf/2506.20326), [HTML](https://arxiv.org/abs/2506.20326)
## Authors
Sergio Torres Aguilar
## Background
历史文档，尤其是那些具有复杂页面组织的文档，其自动处理和理解依赖于稳健的布局分析（DLA）。本文采用了五种最新的物体检测模型（包括基于Transformer和基于YOLO的模型），对三种不同复杂度的注释数据集进行了评测。这些数据集分别代表了中世纪手稿的不同复杂度，其中包括巴黎中世纪手稿集（e-NDP）、CATMuS（多样性多类别数据集）和HORAE（装饰手抄书集）.
## Innovation
本研究提出了一个综合的比较研究框架，评估了基于Transformer和YOLO的检测器在历史文档布局分析中的性能。该研究揭示了模型架构、数据集特性和边界框表示对性能的影响，并强调了在视觉多变和复杂的文档中使用定向边界框（OBB）的重要性，而非是一种小的改进，而是对非欧几里得手稿结构的准确建模的必要手段。
## Conclusion
研究结果表明，具有全局上下文感知能力的Transformer模型适合于结构化布局，而基于CNN-OBB的模型则更适用于视觉多样性和复杂性的文档，因此两者之间存在一定权衡。
# 308. `cs.CV` - 关于集合中人脸的突发性 [PDF](https://arxiv.org/pdf/2506.20312), [HTML](https://arxiv.org/abs/2506.20312)
## Authors
Jiong Wang
## Background
突发性是一种在文本和图像检索中观察到的现象，它指的是特定元素在集合中出现的次数比统计独立性假设的更多。作者指出，在集合基础面部识别（SFR）背景下，突发性在两个方面影响识别性能：首先，突发性人脸在人脸集合中频繁出现，主导训练样本，导致在不受限场景下的泛化能力较差；其次，突发性人脸主导评估集会干扰集合验证和识别时的相似性比较。为了检测集合中的突发性人脸，作者提出了三种基于Quickshift++、特征自相似性和广义最大池化（GMP）的策略。作者还将突发性检测结果应用于训练和评估阶段，以增强不常见人脸的抽样比例或贡献。评估阶段提出了一种质量感知GMP策略，使GMP能够关注人脸质量并增强对低质量人脸的鲁棒性。通过SFR基准测试的示范和广泛实验，作者证明了突发性在识别中普遍存在，抑制突发性显著提高了识别性能。
## Innovation
本文提出了一种在人脸集合作中检测突发性的方法，并提出了三种基于Quickshift++、特征自相似性以及广义最大池化（GMP）的策略，对突发性进行检测和处理。在训练和评估阶段应用这些策略，使得不常见的人脸得到更多的关注。在评估阶段，还提出了一种质量感知广义最大池化策略，以增强对低质量人脸的鲁棒性。这为处理SFR中的突发性问题提供了一种新颖的方法。
## Conclusion
通过突发性检测和策略优化，本文展示了在SFR中抑制突发性可以显著改善识别性能。
# 309. `cs.CV` - InvZW: 基于噪声对抗训练的稳健图像零水印中的不变特征学习 [PDF](https://arxiv.org/pdf/2506.20370), [HTML](https://arxiv.org/abs/2506.20370)
## Authors
Abdullah All Tanvir,Xin Zhong
## Background
传统的零水印技术在面对图像篡改时容易失效，本文提出了一种基于对抗噪声学习的深度学习框架，旨在提高图像零水印的鲁棒性。该方法通过优化特征空间中不变特征的提取来保持原始图像不被修改，从而实现对水印的稳健嵌入和提取。
## Innovation
本文的创新点在于提出了一种新颖的零水印方法，该方法利用噪声对抗学习训练特征提取器，生成既是对抗篡改又是语义表达的特征。同时，采用基于学习的多比特零水印方案，利用训练后的不变特征映射到一组可训练的参考代码，优化以匹配目标二进制消息。该方法在多种图像数据集和广泛干扰下的实验结果表现出出色的鲁棒性和特征稳定性，优于现有的半监督和深度水印技术。
## Conclusion
本文提出的方法在零水印的鲁棒性和特征稳定性方面达到了最新水平。实验表明，该方法在图像数据集和各种干扰下的性能优越，能够实现对零水印的稳健嵌入和提取，具有良好的推广性和鲁棒性。
# 310. `cs.CV` - HiWave: 训练-free 超高分辨率图像生成方法——基于小波的扩散采样 [PDF](https://arxiv.org/pdf/2506.20452), [HTML](https://arxiv.org/abs/2506.20452)
## Authors
Tobias Vontobel,Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber
## Background
扩散模型在图像合成领域表现突出，展现了卓越的逼真度和多样性，但高分辨率下的训练仍然计算成本高昂。现有针对超出训练分辨率的零样本生成技术往往产生质量问题，如物体重复和空间不连贯。因此，如何在无需额外训练和架构修改的前提下，提升超高分辨率图像合成的视觉保真度和结构一致性，成为该领域的关键挑战。
## Innovation
该论文提出了HiWave，一种训练-free的零样本图像生成方法，通过预训练的扩散模型进行图像合成，并采用两阶段管道：首先是预训练模型生成基础图像，然后进行分块DDIM重构和小波域细节增强模块。HiWave在细节保留和高频分量引导上采取创新策略，从而显著提升了图像合成的质量和结构连贯性，有效减轻了先前方法的视觉缺陷，达到更优越的感知质量，且用户研究显示其在超过80%的比较中优于当前最先进的方法，进一步验证了其高效性。
## Conclusion
HiWave方法在不额外训练和改动架构的前提下，通过预训练扩散模型生成高清图像，显著提高了图像的视觉保真度和结构连贯性，解决了高分辨率图像生成的问题，用户体验和研究结果均验证了其在高质量、超高分辨率图像生成方面的有效性。
# 311. `cs.CV` - 利用轻量级分层ViT和动态框架实现高效视觉跟踪 [PDF](https://arxiv.org/pdf/2506.20381), [HTML](https://arxiv.org/abs/2506.20381)
## Authors
Ben Kang,Xin Chen,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu
## Background
基于Transformer的视觉跟踪器由于其强大的建模能力展示了显著的进步，但在资源受限的设备上由于处理速度较慢，其实用性受到了限制。
## Innovation
提出了一种名为HiT的高效跟踪模型家族，通过桥接模块连接轻量级Transformer到跟踪框架，提升了特征表示质量，还引入了双图像位置编码方式来有效编码空间信息。此外，提出了一种能够根据场景复杂度灵活调整计算需求的动态追踪器DyHiT，利用骨干网络提取的搜索区域特征输入高效的动态路由器分类跟踪场景，采用分而治之策略选择合适路线，在保证准确性的前提下显著提高速度。最后，提出了一种基于DyHiT动态路由架构的无需训练的加速方法，可以在不牺牲精度的前提下显著提高各类高性能跟踪器的执行速度。
## Conclusion
HiT实现了61 fps的处理速度和64.6%的AUC，在LaSOT基准测试中表现出色，优于所有之前的方法。DyHiT在其最快版本下的速率达到111 fps，AUC为62.4%。加速方法使SeqTrack-B256在GeForce RTX 2080 Ti GPU上加速2.68倍，保持了69.9%的AUC。
# 312. `cs.CV` - Med-Art: 基于扩散变换器的2D医学图文生成 [PDF](https://arxiv.org/pdf/2506.20449), [HTML](https://arxiv.org/abs/2506.20449)
## Authors
Changlu Guo,Anders Nymark Christensen,Morten Rieger Hannemose
## Background
近年来，文本到图像生成模型取得了显著进展，但在医学图像生成中的应用仍面临挑战，包括数据量小和医学文本数据稀缺。为了应对这些挑战，我们提出了Med-Art框架，旨在利用有限数据生成医学图像。Med-Art利用视觉语言模型生成医学图像的视觉描述，以克服适用医学文本数据稀缺的问题。
## Innovation
Med-Art采用大规模预训练的文本到图像模型PixArt-$beta$，基于扩散变换器（DiT）进行微调，从而在有限数据下实现高性能。此外，我们提出了创新性的Hybrid-Level Diffusion Fine-tuning (HLDF) 方法，该方法能够实现像素级损失，有效解决色彩过度饱和等问题，从而在两个医学图像数据集上达到最先进的性能，用FID、KID和下游分类性能进行衡量.
## Conclusion
Med-Art在两个医学图像数据集上取得了最先进的性能，其视觉描述生成和Hybrid-Level Diffusion Fine-tuning (HLDF) 方法为医学图像生成提供了新的解决方案。
# 313. `cs.CV` - 基于大型视觉基础模型（LVFM）的生成植物园高分辨率林冠高度图的新型方法及其在精确林业管理中的应用 [PDF](https://arxiv.org/pdf/2506.20388), [HTML](https://arxiv.org/abs/2506.20388)
## Authors
Shen Tan,Xin Zhang,Liangxiu Han,Huaguo Huang,Han Wang
## Background
精确监测植物园地上生物量（AGB）对于支持地方生计和碳汇项目如中国核证减排量（CCER）计划至关重要。高分辨率林冠高度图（CHMs）对于这种监测至关重要，但传统基于Lidar的方法成本较高。尽管RGB图像结合深度学习提供了一种替代方案，但准确提取林冠高度特征仍然具有挑战性。
## Innovation
本文开发了一种新型高分辨率CHM生成模型，该模型基于大型视觉基础模型（LVFM）。该模型结合了特征提取器、自我监督特征增强模块以保留空间细节以及高度估计器，通过在北京房山地区的1米分辨率Google Earth图像上进行测试，性能优于现有的方法，包括传统的CNN模型。LVFM模型实现了较高的准确性和泛化能力。
## Conclusion
该方法提供了一个具有扩展性的工具，用于评估植物园和天然森林中的碳汇。
# 314. `cs.CV` - 使用移动激光扫描仪捕获的地下矿山复杂3D点云中识别岩锚的深度学习方法 [PDF](https://arxiv.org/pdf/2506.20464), [HTML](https://arxiv.org/abs/2506.20464)
## Authors
Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval
## Background
地下矿井中的支护系统依靠锚杆提供足够的结构加固，以防止意外的岩块掉落等灾害。常规的人工测量锚杆存在时间成本高和光照条件差的问题，自动化检测锚杆成为可能的解决方案。现有技术主要依赖特征工程和传统机器学习方法，但这些方法在数据噪声、环境变化和复杂邻近结构下缺乏鲁棒性。此外，锚杆作为大型点云中的极小对象，并且常因喷射混凝土的部分遮挡而难以识别。现有方法难以有效处理这些问题，因此需要更为先进的方法来自动高效地识别锚杆。
## Innovation
本文提出的DeepBolt方法采用了一种新颖的两阶段深度学习架构，专门用于处理严重的类别不平衡，从而在复杂3D点云中自动有效地检测锚杆。这种方法在交集比(IoU)上超越了最先进的语义分割模型多达42.5%，并且在分类锚杆方面实现了96.41%的精确率和96.96%的召回率，这显示了其在复杂地下环境中的鲁棒性和有效性。通过上述创新，解决了传统方法的不足，提高了锚杆检测的准确性和效率。
## Conclusion
本文的设计和发展了一种新的Dual Semantic and Instance Segmentation（DeepBolt）方法，能够有效处理地下矿山复杂环境中锚杆的自动检测问题。通过大量的实验表明，提出的方法不仅在IoU上超越了所有现有的方法，而且在精确率和召回率上也表现优异，证明了其在实际应用中的高效性和可靠性。未来的工作可能进一步优化检测算法，以适应更多复杂场景。
# 315. `cs.CV` - AI辅助的牙科放射分析在检测牙槽骨丧失严重程度和模式中的应用 [PDF](https://arxiv.org/pdf/2506.20522), [HTML](https://arxiv.org/abs/2506.20522)
## Authors
Chathura Wimalasiri,Piumal Rathnayake,Shamod Wijerathne,Sumudu Rasnayaka,Dhanushka Leuke Bandara,Roshan Ragel,Vajira Thambawita,Isuru Nawinne
## Background
牙周炎是一种导致牙槽骨丧失的慢性炎症性疾病，显著影响口腔健康和生活质量。准确评估骨丧失的严重程度和模式对于诊断和治疗计划至关重要。本文基于此背景，介绍了如何利用牙科牙片（IOPA）图像自动检测和量化牙槽骨丧失及其模式的一种新型AI深度学习框架。
## Innovation
提出了一种结合YOLOv8进行牙齿检测和Keypoint R-CNN模型识别解剖标志点的AI深度学习框架，实现了精确计算骨丧失的严重程度。此外，利用YOLOv8x-seg模型进行骨水平和牙齿掩码的分割，通过几何分析确定骨丧失模式（水平 vs. 角度）。该方法在1000张由专家标记的牙片上进行了评估，准确度较高，能准确检测骨丧失严重程度（ intra-class相关系数最高0.80）和骨丧失模式分类（准确性87%）。此自动化系统实现了牙周评估的快速、客观和可重复性，减少了对主观手动评估的依赖，并为牙周炎的早期诊断和个性化治疗规划提供了潜在工具，最终改善患者护理和临床结果。
## Conclusion
该研究提出的AI深度学习框架能够高效、准确地评估牙槽骨丧失的严重程度和模式，为牙周炎的诊断和个性化治疗规划提供了新的工具，有助于改善患者护理和临床结果。
# 316. `cs.CV` - 自我监督的动作识别中的特征虚拟 [PDF](https://arxiv.org/pdf/2506.20342), [HTML](https://arxiv.org/abs/2506.20342)
## Authors
Lei Wang,Piotr Koniusz
## Background
理解视频中的人类动作需要超越简单的像素分析，依赖于高层次的语义推理和多模态特征的有效融合。现有的研究通常使用单一的深度学习模型来预测动作概念，但缺乏有效地引入多模态信息的方法。
## Innovation
本文提出了一种深度平移动作识别框架，通过联合预测动作概念和辅助特征来提高识别准确性。引入了两种新型的领域特定描述符：Object Detection Features (ODF) 和 Saliency Detection Features (SDF)。ODF 综合了多个物体检测器的输出以捕获上下文线索，而 SDF 则强调对动作识别至关重要的空间和强度模式。引入自监督的特征虚拟（hallucination）步骤，并结合先验不确定性建模和稳健的损失函数来处理辅助特征的不确定性。这种框架不仅能够融入多模态信息，还能与当前最先进的架构兼容，显著提升了动作识别性能。
## Conclusion
我们的多模态自监督动作识别框架为多个基准测试（如 Kinetics-400、Kinetics-600 和 Something-Something V2）带来了最先进的性能，证明了其在捕捉细微动作动态方面的有效性。
# 317. `cs.CV` - AdvMIM: 使用对抗性掩码图模型进行半监督医学图像分割 [PDF](https://arxiv.org/pdf/2506.20563), [HTML](https://arxiv.org/abs/2506.20563)
## Authors
Lei Zhu,Jun Zhou,Rick Siow Mong Goh,Yong Liu
## Background
视觉变换器最近在医学图像分割任务中获得了极大的关注，因为它们在捕捉长距离依赖关系方面表现出色。然而，变换器需要大量的标注数据才能发挥作用，这阻碍了它们在标注稀缺的半监督学习场景中的应用，其中仅可用有限的标注数据。现有的半监督学习方法提出了一种组合CNN-Transformer学习，通过卷积神经网络来教导变换器，取得了良好的效果。但是，如何有效地用有限的标注数据训练变换器仍然是一个挑战。背景介绍了目前的挑战和现有解决方案的不足，引出了对新方法的需求。
## Innovation
本文提出了一种对抗性掩码图像建模方法（AdvMIM），完全释放了变换器在半监督医学图像分割中的潜力。对抗性掩码图像建模的核心在于克服半监督学习中监督信号不足的问题。通过构建原始域的辅助掩码域，并利用标记数据的原始标签和未标记数据的伪标签来学习掩码域，增加了监督信号。该方法还通过多域学习视角的理论分析设计了一种新的对抗性训练损失，缩小了原始域和掩码域之间的领域差距，从而提升了半监督学习的性能。该方法还扩展了对抗性掩码图像建模到CNN网络，广泛实验表明方法的有效性，并优于现有方法。创新点在于如何通过对抗训练来增强网络的泛化能力和利用未标注数据的能力。
## Conclusion
在三个公开的医学图像分割数据集上进行的大量实验表明，该方法的有效性，已经显著优于现有的方法。我们的代码已公开提供。结论总结了模型的优势，并且强调该方法在实际应用中的潜力。
# 318. `cs.CV` - CXR分类中的基于观测分组的因果表示学习 [PDF](https://arxiv.org/pdf/2506.20582), [HTML](https://arxiv.org/abs/2506.20582)
## Authors
Rajat Rasal,Avinash Kori,Ben Glocker
## Background
因果表示学习旨在揭示数据生成过程中真实的因果关系。在医疗成像中，这为提高特定任务下潜在特征的适应性和稳健性提供了机会。本文提出了一种通过端到端框架对胸部X射线疾病分类的因果表示学习，通过分组观察值来学习可识别的表示以增强跨多种分类任务的泛化能力和稳健性，特别是通过组内恒等性来限制种族、性别和成像视角的差异.
## Innovation
本文引入了使用观测分组来学习可识别的表示的概念，并应用于胸片疾病分类。该方法通过确保基于种族、性别和成像视角的恒等性来增强泛化能力和稳健性，提出了一个端到端的框架来进行这种因果表示学习.
## Conclusion
实验结果表明，通过分组提高的因果表示能有效提升病灶分类任务的适应性和稳健性。该研究为医疗成像中的疾病分类提供了新的技术手段和理论基础.
# 319. `cs.CV` - Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks [PDF](https://arxiv.org/pdf/2506.20548), [HTML](https://arxiv.org/abs/2506.20548)
## Authors
Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao
## Background
随着深度学习的快速发展，特别是通过生成对抗网络（GANs）和扩散模型（DMs），AI生成的图像（即‘深假’）几乎难以与真实图像区分。这些图像广泛地在在线社交网络（OSNs）上分享，引起了对其潜在滥用的关注。现有的反‘深假’检测方法忽略了OSNs中压缩引入的‘块效应’，这会模糊‘深假’特征，且主要集中在原始图像上，在实际应用场景中很少遇到。
## Innovation
本文提出了一种名为PLADA（Pay Less Attention to Deceptive Artifacts）的新型框架，旨在解决配对数据缺乏和压缩图像无效利用的问题。PLADA包含两个核心模块：块效应抹除器（B2E），它使用双重注意机制来处理块效应；开放数据聚合器（ODA），它可以处理配对和非配对数据，以提高检测效果。实验证明，即使存在少量配对数据和压缩情况，PLADA也能实现深度假检测的优异性能，尤其是在在线社交网络中检测深度假方面脱颖而出。这项工作将‘块效应’引入到深度假检测中，提供了一种针对开放世界的鲁棒解决方案。
## Conclusion
本研究通过引入‘块效应’作为深度假检测的关键因素，提出了一种名为PLADA的新型框架，实现了在OSNs中对压缩深度假的鲁棒检测，克服了配对数据缺乏和压缩图像处理的问题，证明了在检测深度假方面具有优越的性能和广泛应用的潜力。
# 320. `cs.CV` - 轻量级多帧集成结构在视频中的鲁棒YOLO目标检测 [PDF](https://arxiv.org/pdf/2506.20550), [HTML](https://arxiv.org/abs/2506.20550)
## Authors
Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell
## Background
现代基于图像的目标检测模型，如YOLOv7，主要在单个图像帧上独立运行，忽略了视频中固有的宝贵时间上下文。现有的基于视频的方法尽管引入了复杂的时间模块，但会大幅增加模型的大小和计算复杂性。在监视和自动驾驶等实际应用中，如运动模糊、遮挡和突然的出现变化等短暂挑战，往往严重降低了单帧检测性能。
## Innovation
提出了一种简单而有效的策略，即将多个连续的图像帧作为输入送到基于YOLO的目标检测器中，并且只监督其中单一目标帧的输出。这种策略利用了时间信息，同时进行最小化的架构修改，保持了模型的简洁性、计算效率和实时推理的能力。本方法在具有挑战性的MOT20Det数据集和自建的BOAT360数据集上进行了详尽的实验，证明该方法提升了检测鲁棒性，尤其是针对轻量级模型，有效地缩小了紧凑型与重型检测网络之间的性能差距。
## Conclusion
通过实验展示了本方法在检测鲁棒性提高上的优势，尤其是在轻量级模型方面。同时，贡献了BOAT360基准数据集，为未来在挑战性实际场景下的多帧视频目标检测研究提供了支持。
# 321. `cs.CV` - 基于图句总结的密集视频字幕生成 [PDF](https://arxiv.org/pdf/2506.20583), [HTML](https://arxiv.org/abs/2506.20583)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou
## Background
最近，在未剪辑视频的长视频字幕生成方面，密集视频字幕取得了显著进展，能够检测和字幕事件中的所有事件。尽管取得了令人鼓舞的结果，但大多数现有方法未能充分探索事件提案内的场景演变，对于场景和物体在相对长时间提案中发生变化时，表现不如理想。
## Innovation
提出了一种基于图的分割与总结（GPaS）框架，分为两个阶段。在“分割”阶段，将整个事件提案分割成短视频片段以进行更细粒度的字幕；在“总结”阶段，合并每个片段生成的丰富描述信息的句子，以描述整个事件。特别聚焦于“总结”阶段，提出了一种框架，有效利用了用于总结的语义词之间的关系。通过将图卷积网络（GCN）和长短期记忆（LSTM）结合，并利用视觉线索学习词语间的交互。提出了两种GCN-LSTM交互模块的方案，以无缝整合GCN和LSTM。
## Conclusion
通过在ActivityNet Captions数据集和YouCook II数据集上与现有最先进的方法进行广泛的比较，证明了该方法的有效性。
# 322. `cs.CV` - TRIM: 一种最大化时间相对信息和代表性的自我监督视频摘要框架 [PDF](https://arxiv.org/pdf/2506.20588), [HTML](https://arxiv.org/abs/2506.20588)
## Authors
Pritam Mishra,Coloma Ballester,Dimosthenis Karatzas
## Background
随着视频内容的日益普及和对有效访问重要信息的需求增加，视频摘要和视频精选已成为重要研究领域。然而，许多最先进的方法要么依赖于监督注释，要么依赖于注意力模型，这些方法在计算上昂贵且对分布变化敏感，这阻碍了其在不同数据集之间的跨域适用性。
## Innovation
我们提出了一种新颖的自我监督视频摘要模型，该模型捕获了空间和时间依赖关系，而无需采用注意力机制、RNN或变压器，同时引入了一个包含新型马尔可夫过程驱动损失度量和两阶段自我监督学习范式的框架，确保性能和效率。该方法在SUMME和TVSUM数据集上取得了最先进的性能，优于所有现有的无监督方法，甚至与最先进的监督模型相当，展示了高效、无需注释架构的潜力。
## Conclusion
这一成果为更通用的视频摘要技术铺平了道路，并挑战了依赖复杂架构的现有做法。
# 323. `cs.CV` - 基于单传感器配置的360度距离估计学习方法 [PDF](https://arxiv.org/pdf/2506.20586), [HTML](https://arxiv.org/abs/2506.20586)
## Authors
Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell
## Background
精确的距离估计是机器人感知中的基本挑战，尤其是在全方位成像中，传统的几何方法难以应对镜头畸变和环境变化。现有的360度全景拍摄技术在处理镜头畸变和环境变化时效果不佳，这限制了它们的实用性。本研究旨在提出一种基于神经网络的方法，利用单一全方位鱼眼镜头相机进行单目距离估计，解决这一问题。
## Innovation
本文提出了一种基于神经网络的单目距离估计算法，该方法直接从原始全方位输入中学习和推断物体的距离，无需依赖精确的镜头校准。这种方法具有较强的鲁棒性和适应性，适用于各种条件。实验结果显示，本方法在准确性和鲁棒性方面均优于传统的几何方法和其他学习基准模型。这项研究为全方位距离估计在实时应用中的实际应用提供了可能，尤其适用于低成本的机器人应用领域，如自主导航和安防监控等。
## Conclusion
研究结果表明，提出的基于深度学习的模型能够有效地进行实时全方位距离估计，在准确性和鲁棒性方面均优于传统方法和其它学习基准模型。该方法特别适合于低成本的机器人应用领域，如自主导航和安防监控等。
# 324. `cs.CV` - 解纠缠的显微镜图像表示 [PDF](https://arxiv.org/pdf/2506.20649), [HTML](https://arxiv.org/abs/2506.20649)
## Authors
Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone
## Background
显微镜图像分析对于多种应用至关重要，包括诊断、合成工程和环境监测。现代成像系统能够获取大量图像，这要求开发大量基于深度学习的自动化图像分析方法。尽管深度神经网络在这一领域表现出色，但显微镜图像分析中的可解释性仍然是一个挑战性问题。
## Innovation
本文提出了一种解纠缠表示学习（DRL）方法，以增强显微镜图像分类模型的可解释性。该方法通过从合成数据中学习表示，并应用于三种不同的显微镜图像领域（浮游生物、酵母细胞器和人类细胞），展示了在保持准确性和可解释性的良好平衡方面的优势。
## Conclusion
通过基于合成数据转移学习的DRL框架，该研究证明了在显微镜图像分析领域可以实现较高精度和良好可解释性的平衡，解决了一个重要但尚未完全解决的挑战。
# 325. `cs.CV` - Shape2Animal：从自然轮廓创意生成动物 [PDF](https://arxiv.org/pdf/2506.20616), [HTML](https://arxiv.org/abs/2506.20616)
## Authors
Quoc-Duy Tran,Anh-Tuan Vo,Dinh-Khoi Vo,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le
## Background
人类具有在模糊刺激中感知有意义模式的独特认知能力，这种现象被称为似 likeness。本文介绍的Shape2Animal框架模拟这种想象力的能力，通过重新诠释自然物的轮廓，如云朵、岩石或火焰，将其视为可能的动物形态。
## Innovation
该框架通过自动化的方法首先进行开放词汇分割以提取物体轮廓，然后使用视觉语言模型解释合适的动物概念。接着利用文本到图像的扩散模型合成符合输入形状的动物图像，并将其无缝融合到原始场景中，以生成视觉上连贯且空间上一致的布局。该框架能够经受住多样化的实际输入，展示了其稳健性和创造力的潜力，为视觉叙事、教育内容、数字艺术和互动媒体设计提供了新的机会。
## Conclusion
Shape2Animal框架为从自然轮廓中创意生成动物提供了可能，能够为多领域提供新的创作机会。
# 326. `cs.CV` - WonderFree：提高新颖视角质量和跨视角一致性的3D场景探索方法 [PDF](https://arxiv.org/pdf/2506.20590), [HTML](https://arxiv.org/abs/2506.20590)
## Authors
Chaojun Ni,Jie Li,Haoyun Li,Hengyu Liu,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Boyuan Wang,Chenxin Li,Guan Huang,Wenjun Mei
## Background
3D场景从单张图像生成技术受到了广泛关注，因为它能创造出沉浸式的虚拟世界。然而，当前3D生成方法的主要挑战在于其探索的有限性，即在进行较大的动作超出原始视角范围时，无法生成高质量的图像，尤其是在向未见区域前进时问题更为明显。对于这个挑战，本文提出了WonderFree，一种全新的模型，让用户能够在任意角度和方向上交互式地生成3D世界，极大提高了探索自由度。
## Innovation
本文提出了两种关键技术来解决上述挑战：WorldRestorer，一种数据驱动的视频修复模型，旨在消除新颖视角中的浮点和人工制品；以及ConsistView，一种多视角联合修复机制，旨在同时修复多个视角并保持时空连贯性。通过这两项技术，WonderFree在各种视角下提升了渲染质量，并显著增强了全局的一致性和连贯性。实验结果表明，与WonderWorld相比，用户更偏好WonderFree，因为它提供了无缝且沉浸式的3D探索体验。
## Conclusion
实验结果证实，WonderFree不仅在多种视角下提升了渲染质量，还在全球的一致性和连贯性方面取得了显著提升。这些改进得到了CLIP基元度量和用户研究的支持，显示出77.20%的用户偏好。最终，该代码、模型和数据将对公众开放。
# 327. `cs.CV` - Video Perception Models for 3D Scene Synthesis [PDF](https://arxiv.org/pdf/2506.20601), [HTML](https://arxiv.org/abs/2506.20601)
## Authors
Rui Huang,Guangyao Zhai,Zuria Bauer,Marc Pollefeys,Federico Tombari,Leonidas Guibas,Gao Huang,Francis Engelmann
## Background
传统的3D场景合成需要专家知识和大量的手工努力。自动化这一过程能够大大受益于建筑设计、机器人模拟、虚拟现实和游戏等行业。最近的3D场景合成方法往往依赖于大型语言模型的常识推理或现代图像生成模型的强视觉先验，但当前的大型语言模型在三维空间推理能力上有限，这限制了它们生成真实且连贯的3D场景的能力。另一方面，基于图像生成的方法在视角选择和多视角一致性方面经常受到限制。
## Innovation
我们提出了一种新的框架——Video Perception Models for 3D Scene synthesis (VIPScene)，该框架利用视频生成模型中编码的三维物理世界常识知识，确保场景布局的一致性和各视角中对象放置的一致性。VIPScene接受文本和图像提示，并将视频生成、前馈3D重建和开放词汇感知模型无缝集成，以从语义和几何的角度分析场景中的每个对象。这使得能够灵活地合成具有高现实感和结构一致性的场景。此外，我们还引入了First-Person View Score (FPVScore) 用于一致性和合理性评估。实验结果表明，VIPScene在多个场景中表现显著优于现有方法且具有良好的泛化能力。代码将公开发布。
## Conclusion
我们的研究展示了VIPScene在多场景下的有效性和泛化能力，这为3D场景合成的自动化提供了新的途径和方法。
# 328. `cs.CV` - SFNet：遥感图像伪造检测的空域和频域特征融合 [PDF](https://arxiv.org/pdf/2506.20599), [HTML](https://arxiv.org/abs/2506.20599)
## Authors
Ji Qi,Xinchang Zhang,Dingqi Ye,Yongjia Ruan,Xin Guo,Shaowen Wang,Haifeng Li
## Background
近年来生成式人工智能技术的发展产生了越来越多难以鉴别的遥感图像（RSI），这可能导致错误的情报、假新闻乃至阴谋论的传播。现有的伪造检测方法通常仅依赖单一视觉特征来捕捉预定义的伪图像特征，例如用于检测RSI中伪造的道路或建筑物的空域线索，或用于识别来自对抗生成网络（GAN）上采样操作的伪图像频率域特征。然而，伪图像的特征取决于地理地形、土地覆盖类型或RSI中的特定特征，且随着生成模型的复杂性增加，这些复杂特征会不断演变，这使得过度依赖单一视觉线索的现有伪造检测器难以在不同遥感数据上进行泛化。因此，这是一个重要的研究领域，致力于开发更有效的伪造检测方法。
## Innovation
本文提出了一种名为SFNet的新型伪造检测框架，旨在通过融合空域和频域特性来识别多种遥感数据中的假图像。SFNet采用了两个独立的特征提取器来从输入的RSI中获取空域和频域特征，设计了领域特征映射模块和集成领域特征精炼模块（CBAM注意机制），以同步对齐和融合多域特征并抑制冗余信息。实验结果显示，SFNet相较于最先进的遥感伪造检测方法在准确率上提高了4%-15.18%，并且具有很强的泛化能力。
## Conclusion
本文提出了一种融合空域和频域特征的新型伪造检测框架SFNet，通过两者的协同工作显著提高了遥感图像伪造检测的准确率，并展示了强大的泛化能力。
# 329. `cs.CV` - 非配合空间目标的姿态估计与3D神经重建 [PDF](https://arxiv.org/pdf/2506.20638), [HTML](https://arxiv.org/abs/2506.20638)
## Authors
Clément Forray,Pauline Delporte,Nicolas Delaygue,Florence Genin,Dawa Derksen
## Background
了解地球轨道上物体的当前状态和行为对于多种应用至关重要，如轨道碎片清除、在轨维护或异常检测。三维模型为太空态势感知（SSA）领域提供了宝贵的信息来源。但是，使用神经辐射场（NeRF）模型从模拟图像中重建非配合空间目标存在挑战，异常的相机特征和环境条件使得图像为单一色，未知物体方向，视角有限，缺乏漫射照明等。本研究旨在通过逐步训练图像来优化相机姿态和NeRF模型的联合优化，从而实现更精确的3D重建。
## Innovation
本研究利用神经辐射场技术，通过单张图像的逐步训练，优化相机姿态，首次实现在复杂环境下的3D重建，为非配合空间目标提供了一种新的姿态估计与3D重建方法。相比传统方法，这种方法提高了三维重建的准确性，特别在处理视角有限和环境光照复杂的情况下表现出色。
## Conclusion
通过逐步训练图像和优化相机姿态，本研究成功实现了对非配合空间目标的3D重建。实验结果表明，采用逐步训练的方法可以获得更准确的3D重建结果。通过优化均匀旋转和使用正则化防止相继姿态差异过大，本方法在复杂相机设置和未知物体方向的情况下提高了重建精度。
# 330. `cs.CV` - MMSearch-R1: 鼓励大型多模态模型进行搜索 [PDF](https://arxiv.org/pdf/2506.20670), [HTML](https://arxiv.org/abs/2506.20670)
## Authors
Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu
## Background
在现实场景中，大规模多模态模型（LMMs）的稳健部署需要访问外部知识源，因为现实世界的复杂性和动态性。现有方法，如检索增强生成（RAG）和提示工程搜索代理，依赖于固定的流程，常导致搜索行为的低效或过度搜索。研究背景强调了现有方法的不足，并提出了MMSearch-R1框架，这是首个能实现LMMs在实时互联网环境中的按需多轮次搜索的端到端强化学习框架。
## Innovation
MMSearch-R1框架集成了图像和文本搜索工具，并通过基于结果的奖励机制指导何时以及如何启动搜索，同时采用带有搜索惩罚的奖励方案。为了支持训练，研究团队开发了一个涵盖了不同视觉和文本知识需求的多模态搜索VQA数据集，并整理了一个包括搜索需求和搜索无关样本的平衡子集。实验结果表明，该模型不仅在与RAG基线相同规模的情况下超越了RAG基线，而且在减少30%以上的搜索调用次数的同时，还能达到更大规模RAG基线模型的性能。进一步的实证分析提供了操作性建议，旨在推动多模态搜索研究的进步。
## Conclusion
该研究展示了MMSearch-R1框架在知识密集型和信息查询型VQA任务中的卓越表现，不仅显著提高了模型的效率，还减少了搜索调用次数，证明了其在实时互联网环境中部署大型多模态模型的有效性。此外，研究发现和分析为未来多模态搜索研究提供了有意义的见解。
# 331. `cs.CV` - 使用视觉线索辅助句子总结的显示、讲述和总结：密集视频字幕生成 [PDF](https://arxiv.org/pdf/2506.20567), [HTML](https://arxiv.org/abs/2506.20567)
## Authors
Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan
## Background
在没有修剪的长时间视频分割为多个事件提案后，从每个视频段中提取视觉特征，并使用现有的图像/视频字幕方法生成一段描述这个段落的描述。考虑到生成的句子包含关于整个事件提案的丰富语义描述，将密集视频字幕任务形式化为视觉线索辅助句子总结问题，并提出了一种新的两阶段长短期记忆（LSTM）方法，该方法配备新的分层注意机制，通过视觉特征来总结所有生成的句子为一段描述性的句子。第一阶段LSTM网络作为编码器将生成的所有语义词和一个事件提案内所有片段的视觉特征作为输入，有效总结与该事件提案相关的信息。第二阶段LSTM网络作为解码器将第一阶段输出和一个事件提案内所有视频片段的所有视觉特征作为输入，生成该事件提案的描述性句子。
## Innovation
提出了一种新的两阶段LSTM方法，配备新的分层注意机制，利用视觉特征来总结生成的句子为一段描述性的句子。该方法在活动网络字幕数据集上的综合实验验证了其在密集视频字幕生成中的有效性，与现有方法相比，它能够更准确地捕捉视觉信息和语义描述的关系，生成更为描述性的字幕句子。
## Conclusion
本研究提出了一个分割和总结（DaS）框架，以解决密集视频字幕问题。通过将长时间视频分割为多个事件提案，并利用视觉特征和LSTM模型生成描述性的句子，该方法展示了其在视频字幕生成中的有效性。
# 332. `cs.CV` - IPFormer: 基于上下文自适应实例提案的视觉3D泛光场景完成 [PDF](https://arxiv.org/pdf/2506.20671), [HTML](https://arxiv.org/abs/2506.20671)
## Authors
Markus Gross,Aya Fahmy,Danit Niwattananan,Dominik Muhle,Rui Song,Daniel Cremers,Henri Meeß
## Background
语义场景完成（SSC）已成为联合学习场景几何和语义的关键方法，能够支持诸如移动机器人导航等下游应用。最新泛光场景完成（PSC）通过集成实例级信息扩展了SSC领域，增强了对象级别的敏感性。尽管PSC使用了激光雷达模态引入，但基于相机图像的方法却鲜有研究。最近的基于Transformer的SSC方法使用固定集的已学习询问来重建场景体积中的对象。尽管这些询问通常会在训练期间与图像上下文结合更新，但在测试时仍保持固定，从而限制了它们动态适应已观察到的场景的能力。为克服这些限制，本文提出IPFormer，这是第一个在训练和测试时利用上下文自适应实例提案的方法，以解决基于视觉的3D泛光场景完成问题。具体而言，IPFormer适应性地从图像上下文中初始化这些询问作为泛光实例提案，并通过基于注意力的编码和解码进一步进行细化，以推理语义实例体素关系。实验结果表明，该方法在整体泛光指标PQ$^text{†}$和PQ-All上超越了最先进的方法，在个体指标上也能匹配表现，并实现了超过14倍的运行时间减少。此外，消融研究显示，从图像上下文中动态地推导实例提案，相比于随机初始化，可以提高3.62%的PQ-All，并且联合Thing指标的整体平均改进达到了18.65%。这些结果突显了我们引入上下文自适应实例提案作为解决基于视觉的3D泛光场景完成问题的开创性努力的重要性。
## Innovation
IPFormer首次在训练和测试阶段利用上下文自适应实例提案来解决基于视觉的3D泛光场景完成问题。具体而言，IPFormer适应性地从图像上下文中初始化这些询问作为泛光实例提案，并通过基于注意力的编码和解码进一步进行细化。实验结果表明该方法在整体泛光指标上超越了最先进的方法，在个体指标上也能匹配表现，并实现了超过14倍的运行时间减少。
## Conclusion
这些结果突显了我们引入上下文自适应实例提案作为解决基于视觉的3D泛光场景完成问题的开创性努力的重要性。
# 333. `cs.CV` - 使用遥感的多模态空间风险框架用于电动汽车充电基础设施 [PDF](https://arxiv.org/pdf/2506.19860), [HTML](https://arxiv.org/abs/2506.19860)
## Authors
Oktay Karakuş,Padraig Corcoran
## Background
电动汽车（EV）充电基础设施对于可持续交通系统的重要性日益增加，但其在环境和基础设施压力下的韧性尚未得到充分探索。本研究旨在填补这一空白，通过融合遥感数据、开放基础设施数据集和空间图分析，提出一种空间显性和多模式的风险评估框架（RSERI-EV），以评估电动汽车充电站的脆弱性。这项工作扩展了对EV充电基础设施韧性的理解，并提供了一种综合多种数据层的方法，如洪水风险图、地表温度极端值、植被指数（NDVI）、土地利用/土地覆盖（LULC）、电气变电站的接近度和道路可达性，生成综合的韧性评分。
## Innovation
本研究创新地提出了RSERI-EV框架，该框架结合了遥感数据、开放基础设施数据集和空间图分析，构建了一个基于充电网络的空间k-最近邻（$k$NN）图，用于邻域比较和图意识诊断。该框架通过多源数据融合和可解释的空间推理，支持气候韧性、基础设施意识的电动汽车部署，并展示了其实用性和可行性。
## Conclusion
本研究通过应用RSERI-EV框架对威尔士的电动汽车充电器数据集进行评估，验证了其可行性和有效性。研究表明，这种多模式的空间风险评估框架在支持电动汽车充电基础设施部署中具有潜在的应用价值，特别是在推动气候韧性的基础设施改进方面显示出显著的优势。
# 334. `cs.CV` - FedBKD: 通过生成对抗网络实现非IID数据上的泛化和个人化知识提炼的联邦学习 [PDF](https://arxiv.org/pdf/2506.20245), [HTML](https://arxiv.org/abs/2506.20245)
## Authors
Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu
## Background
联盟学习（FL）是一种去中心化的协作机器学习技术，用于解决工业实践中孤立数据孤岛和数据隐私泄露的问题。然而，联盟学习的一个主要挑战是如何处理非独立非同分布（non-IID）数据。当前的解决方案要么侧重于创建全能的全局模型，要么定制个性化的本地模型。只有少数解决方案能够同时提供样化良好的全局模型和表现良好的本地模型。此外，许多解决非IID问题的联盟学习方法依赖于公开数据集，这会增加数据泄露的风险。由于这些原因，需要一种新的方法来解决这些问题，促进全局和本地模型之间的知识交互并改善他们的性能
## Innovation
提出了一种新的无数据知识蒸馏框架FedBKD。在该框架中，通过训练生成性对抗网络（GAN）生成合成数据，本地模型充当鉴别器且参数被冻结。合成数据用于双向知识蒸馏以实现全局和本地模型之间的知识交互，从而改进了两者的性能。
## Conclusion
在4个不同的非IID设置下的基准测试中，所做的实验显示，FedBKD在所有情况下都达到了最佳性能。
# 335. `cs.CV` - VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration [PDF](https://arxiv.org/pdf/2506.19975), [HTML](https://arxiv.org/abs/2506.19975)
## Authors
Hang Zhang,Yuxi Zhang,Jiazheng Wang,Xiang Chen,Renjiu Hu,Xin Tian,Gaolei Li,Min Liu
## Background
最近的神经网络发展提高了变形图像配准（DIR）的效率和准确性，通过减少迭代优化，使得结果更快更准确。然而，基于学习的方法在受限的训练数据、大的形变以及缺乏标签监督的情况下往往表现不如迭代方法好。尽管迭代方法在这种情况下能够达到更高的准确性，但它们的速度远慢于基于学习的方法。因此，研究重点在于结合基于学习和迭代方法的优点，以提高配准的准确性和降低运行时间之间的平衡。VoxelOpt就是这样一个结合了局部代价体素的熵度量来评估每个体素的位移信号强度的方法，实现了体积适应性的消息传递。
## Innovation
VoxelOpt 提出了一种基于离散优化的变形图像配准框架，结合了学习和迭代方法的优点。VoxelOpt 的创新点在于：1) 体素级别的自适应消息传递机制，低熵体素受到邻居影响较少；2) 使用多级图像金字塔，每个层次都包含 27 邻近体素的代价体积，避免了复杂性指数增长；3) 使用预训练的泛基础分割模型进行特征提取，取代手工设计的特征或对比学习。结合这些改进，VoxelOpt 在腹部CT配准时表现出更高的效率和准确性，且达到最先进学习方法的水平。
## Conclusion
VoxelOpt 在腹部 CT 配准的效率和准确性上超过了基于迭代的方法。在同步态学习方法中，VoxelOpt 也能与最先进的技术相媲美。VoxelOpt 提供了资源代码，供读者参考。通过这种结合学习和迭代方法的框架，VoxelOpt 在平衡配准准确性和运行时间方面做出了显著的改进。
# 336. `cs.CV` - MIRAGE: 农业专家引导对话中多模态信息查询与推理的标准 [PDF](https://arxiv.org/pdf/2506.20100), [HTML](https://arxiv.org/abs/2506.20100)
## Authors
Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve
## Background
现有的基准主要依赖于明确的用户输入和封闭分类的税务体系，无法充分模拟现实世界中知识密集型领域的复杂交互。因此，需要一个新的基准来评估模型在实际农业咨询场景中的多模态推理和决策能力，涵盖作物健康、病虫害诊断和作物管理等多种场景。
## Innovation
MIRAGE 是一个全新的基准，旨在评估模型在农业咨询背景下进行多模态专家级推理和决策的能力。它结合了自然用户查询、专家回复和基于图片的情境，提供了一个高保真度的基准，用于评估模型在实际场景中的推理能力、澄清策略和长篇生成能力。MIRAGE 是基于超过35,000次真正用户与专家的互动，通过精心设计的多步骤管道精心策划而成，因此它具有高度的现实性和多样化的生物实体覆盖范围，使其成为视图语言模型中最多样化的基准之一。
## Conclusion
MIRAGE 提供了一种新的方法来评估模型在农业知识密集型领域的多模态推理能力和决策能力，特别是对于开放世界场景下的隐含知识缺口、稀有实体的处理以及主动引导交互或回应的能力。
# 337. `cs.CV` - 作为掩码扩散模型的任意顺序GPT：解耦形式和架构 [PDF](https://arxiv.org/pdf/2506.19935), [HTML](https://arxiv.org/abs/2506.19935)
## Authors
Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma
## Background
大型语言模型（LLMs）主要采用自回归（AR）方法，但掩码扩散模型（MDMs）正在作为一种可行的替代方案出现。AR和MDM在建模范式和架构上有显著差异：AR模型通常是解码器专用的，而MDM模型主要是编码器专用的。同时更换建模范式和架构使得直接比较变得不公平，难以区分观察到的差异是由于建模范式本身还是架构的变化。本文在解码器专用框架下评估MDMs，旨在公平地比较MDM（任意顺序自回归，或AO-AR）和标准AR范式，并研究MDMs在解码器和编码器之间的架构影响。因此，在MDMs中解耦核心范式差异与架构影响，为其未来设计提供了洞察。
## Innovation
本文创新地提出将任意顺序自回归（AO-AR）作为一种掩码扩散模型（MDM）来评估其相对于标准自回归方法（AR）的性能。研究发现标准AO-AR目标平均所有标记排列可能需要改进，并且揭示了解码器专用MDM在建模空间更复杂的同时，仍然能通过温度退火实现类似 perplexity 而获得显著的生成速度提升。
## Conclusion
本文研究解耦了MDMs的核心范式差异与架构影响，这为未来模型设计提供了重要洞见。解码器专用MDM模型在大幅增加建模空间的情况下，可通过温度退火实现与编码器专用MDM类似的表现，并且在生成速度上获得大幅提高。
# 338. `cs.CV` - MS-IQA: 多尺度特征融合网络在PET/CT影像质量评估中的应用 [PDF](https://arxiv.org/pdf/2506.20200), [HTML](https://arxiv.org/abs/2506.20200)
## Authors
Siqiao Li,Chen Hui,Wei Zhang,Rui Liang,Chenyue Song,Feng Jiang,Haiqi Zhu,Zhixuan Li,Hong Huang,Xiang Li
## Background
正电子发射断层扫描/计算机断层扫描(PET/CT)在医学成像中起着关键作用，通过将功能性信息和解剖学信息结合起来以帮助精确诊断。然而，由于噪声、压缩等其他因素导致的图像质量下降可能会导致诊断不确定性增加，增加误诊的风险。目前，评价PET/CT图像质量的方法无法同时考虑低级特征（如失真）和高级特征（如器官解剖结构），导致对图像诊断价值的评估不全面，因此，需要一种能够同时处理这两类特征的方法来提高图像质量评估的准确性与效率。
## Innovation
本文提出了一种名为MS-IQA的新颖多尺度特征融合网络，该网络利用ResNet和Swin Transformer的多个中间层特征，增强了对局部和全局信息的感知能力。此外，MS-IQA还引入了一个多尺度特征融合模块，通过动态加权通道注意力机制有效地结合了高级和低级信息，提高了图像质量评估的水平。为了填补PET/CT图像质量评估数据集的空白，本文构建了一个包含2700张不同质量的PET/CT图像的数据集（PET-CT-IQA-DS）,每张图像由放射科医生评分。实验表明，相较于现有的领先方法，该模型在多个图像质量评估指标上取得了更优的性能。
## Conclusion
本工作提供了一种准确且高效的PET/CT影像质量评估方法，通过多尺度特征融合网络，能够有效处理图像中的低级和高级特征。本文中的代码和数据集可在以下链接获取。
# 339. `cs.CV` - 基于RGB感知的共识驱动不确定性方法在机器人抓取中的应用 [PDF](https://arxiv.org/pdf/2506.20045), [HTML](https://arxiv.org/abs/2506.20045)
## Authors
Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai
## Background
深度物体姿态估计通常过于自信。一个既估计目标物体6-DoF姿态又预测自身估计不确定性的抓取代理，在高不确定情况下可以选择不执行动作，避免任务失败。尽管物体姿态估计和不确定性量化研究不断进步，但很少有研究将这两种技术与机器人抓取的下游任务连接起来。本研究旨在训练轻量级深度网络，在尝试抓取前根据基于图像的姿态估计预测抓取的成功概率，从而减轻不确定性带来的负面影响，对多样化的物体进行联合训练，优化网络性能，提高抓取成功率
## Innovation
提出了一种方法，用于训练轻量级、深度网络，预测由基于图像的物体姿态估计引导的抓取动作是否成功。通过实际图像的姿态估计和模拟抓取生成训练数据，表明在抓取训练中，即使存在物体变量性，使用所有物体联合训练网络也能获得更好的效果，为机器人抓取中的不确定性处理提供了创新解决方案
## Conclusion
该方法通过基于共识的不确定性估计有效地提高了机器人抓取的成功率，即使面临高变异性物体的挑战，也能够为机器人抓取任务提供有益的指导。
# 340. `cs.CV` - X-SiT：用于痴呆症诊断的固有可解释表面视觉变换器 [PDF](https://arxiv.org/pdf/2506.20267), [HTML](https://arxiv.org/abs/2506.20267)
## Authors
Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger
## Background
可解释的模型对于支持临床决策至关重要，推动了其在医学图像中的开发和应用。然而，3D体数据的性质使得难以可视化和解释复杂的结构，如大脑皮层。相比之下，皮层表面渲染提供了更易于理解和展现脑结构的3D表示，有助于可视化和交互式探索。本文由这一优势和表面数据在研究神经疾病中的广泛应用驱动，介绍了一种用于痴呆症诊断的固有可解释表面视觉变换器（X-SiT）
## Innovation
本文提出了一种固有可解释的神经网络——X-SiT，基于可解释的皮层特征提供人类可理解的预测。该模型引入了一种原型表面补丁解码器，用于分类表面补丁嵌入，结合基于案例的推理和空间对应皮层原型。研究表明，该方法在检测阿尔茨海默病和额颞叶痴呆方面达到了最先进的性能，同时提供了与已知疾病模式相一致的信息性原型，揭示了分类错误
## Conclusion
X-SiT在检测阿尔茨海默病和额颞叶痴呆方面表现出色，还提供了与已知疾病模式一致的信息性原型，揭示了分类错误。这表明X-SiT不仅在诊断能力上有所提升，还在解释和理解疾病的机制方面有所贡献。
# 341. `cs.CV` - FundaQ-8：一种基于临床的自动化眼底图像质量评分框架 [PDF](https://arxiv.org/pdf/2506.20303), [HTML](https://arxiv.org/abs/2506.20303)
## Authors
Lee Qi Zun,Oscar Wong Jin Hao,Nor Anita Binti Che Omar,Zalifa Zakiah Binti Asnir,Mohamad Sabri bin Sinal Zainal,Goh Man Fye
## Background
由于成像获取方法的差异和专家评估的主观性，自动化眼底图像质量评估（FIQA）仍具有挑战性。目前的方法难以处理实际临床环境中可能出现的图像质量变化和主观评分差异。为此，作者提出了FundaQ-8框架，这是一个基于八个关键参数（包括视野覆盖、解剖结构可见性、照明和图像伪影）的专家验证系统，用于系统地评估眼底图像的质量。通过FundaQ-8框架作为结构化的评分参考，作者利用ResNet18模型预测0到1范围内的连续质量评分。
## Innovation
该框架引入了FundaQ-8，这是一种专家验证系统，使用八个关键参数（视野覆盖、解剖结构可见性、照明和图像伪影）系统地评估眼底图像质量。通过使用迁移学习、均方误差优化和标准化预处理，作者开发了一个基于ResNet18的回归模型，用于预测0到1范围内的连续质量评分。鱼发展这种模型并进行验证，展示了在实际临床筛查应用中质量感知训练的重要性，特别是在糖尿病视网膜病变分级中提高诊断稳健性方面的能力。
## Conclusion
FundaQ-8框架在EyeQ数据集上的验证和统计分析表明其可靠性及临床解释性。将FundaQ-8纳入糖尿病视网膜病变分级的深度学习模型中进一步增强了诊断稳健性，强调了在实际临床筛查应用中质量感知训练的价值。
# 342. `cs.CV` - 基于学习的中等输入敏感函数研究：二维码解码案例 [PDF](https://arxiv.org/pdf/2506.20305), [HTML](https://arxiv.org/abs/2506.20305)
## Authors
Kazuki Yoda,Kazuhiko Kawamoto,Hiroshi Kera
## Background
函数的学习难度与其输入的敏感性相关。例如，图像分类任务是输入不敏感的，即使有轻微的腐败也不影响分类结果；而算术和符号计算任务是高度输入敏感的，因为每个输入变量都会影响计算结果，这些任务最近引起了很大兴趣。研究首次提出了一种基于学习的二维码快速响应（QR）解码方法，并研究了中等输入敏感的学习函数。实验表明，Transformers 可以成功解码二维码，甚至超越理论上的纠错极限，通过学习嵌入文本的结构。模型可以从富含英文的训练数据泛化到其他语言甚至随机字符串中。研究人员还发现，基于Transformer的二维码解码器专注于数据比特而忽略纠错比特，这意味着它采用了一种不同于标准二维码读取器的解码机制。
## Innovation
首次提出了基于学习的二维码解码方法，研究了中等输入敏感的学习函数，通过使用Transformer模型超越了理论上的纠错极限，实现了从英文丰富到其他语言甚至随机字符串的泛化，并揭示了与标准二维码读取器不同的解码机制。
## Conclusion
基于Transformer模型的QR码解码器成功地学习了中等输入敏感函数，能够在超出理论纠错能力的情况下解码QR码，并且能够泛化到不同的语言甚至随机字符串。这种基于Transformer的解码机制展示了不同于传统QR码读取器的独特解码方式。
# 343. `cs.CV` - 不同编码、变分形式和测量对量子和混合卷积神经网络的影响的实用见解 [PDF](https://arxiv.org/pdf/2506.20355), [HTML](https://arxiv.org/abs/2506.20355)
## Authors
Jesús Lozano-Cruz,Albert Nieto-Morales,Oriol Balló-Gimbernat,Adan Garriga,Antón Rodríguez-Otero,Alejandro Borrallo-Rentero
## Background
本研究探讨了参数量子电路（PQCs）在量子和混合卷积神经网络（HQNN和QCNN）架构中的设计选择，用于卫星图像分类任务，采用EuroSAT数据集。研究系统地评估了数据编码策略、变分变分形式和测量对约500种不同模型配置的影响。研究结果揭示了这些因素对模型性能的不同影响层次。对于混合架构，其性能主要由数据编码策略决定，不同嵌入对验证准确性的影响可达30%。而在纯量子模型中，其性能主要依赖于测量协议和数据到振幅的映射。不同测量策略对验证准确性的影响为30%，而不同的编码映射约为8个百分点。
## Innovation
本文研究了PQCs在特定架构中的应用，并系统地评估了数据编码策略、变分形式和测量对模型性能的影响，揭示了这些因素在不同架构中对模型性能的影响差异。这种方法为量子和混合卷积神经网络的设计提供了实用见解。
## Conclusion
对于混合架构，数据编码策略是影响模型性能的主导因素，不同嵌入技术可能导致30%左右的验证准确性差异。而对于纯量子模型，测量策略是影响最大的因素，其次是数据到振幅的映射，可以影响约8个百分点的验证准确性。
# 344. `cs.CV` - DreamAnywhere：以对象为中心的全景3D场景生成 [PDF](https://arxiv.org/pdf/2506.20367), [HTML](https://arxiv.org/abs/2506.20367)
## Authors
Edoardo Alberto Dominici,Jozef Hladky,Floor Verhoeven,Lukas Radl,Thomas Deixelberger,Stefan Ainetter,Philipp Drescher,Stefan Hauswiesner,Arno Coomans,Giacomo Nazzaro,Konstantinos Vardis,Markus Steinberger
## Background
近年来，文本到3D场景生成的研究展示了在多个行业中重塑内容创作的巨大潜力。尽管研究社区在解决这一复杂任务的挑战方面取得了显著进展，但现有方法通常生成仅面向前方的环境，缺乏视觉保真度，场景理解有限，并且通常细调用于室内或室外场景。
## Innovation
我们提出了DreamAnywhere，这是一种模块化系统，用于快速生成和原型制作3D场景。该系统从文本中合成了360度全景图，将其分解为背景和对象，通过混合修补生成完整的3D表示，并将对象掩码提升为放置在虚拟环境中的详细3D对象。 DreamAnywhere支持沉浸式导航和直观的对象级编辑，使其非常适合场景探索、视觉草案和快速原型制作——所有这些都不需要传统3D工作流程的额外开销。该模块化流水线可以独立替换组件，使其具有高度的可定制性。与当前最先进的基于文本和图像的3D场景生成方法相比，DreamAnywhere在新颖视图合成一致性方面表现出显著改善，并且在图像质量上达到了竞争力，证明了其在多种多变场景中的有效性。
## Conclusion
一项全面的用户研究显示，参与者明显更偏好我们的方法而非现有方法，验证了其技术和实际使用价值。
# 345. `cs.CV` - EAGLE: 一种用于肝包虫病病灶分割的高效全局注意力模型 [PDF](https://arxiv.org/pdf/2506.20333), [HTML](https://arxiv.org/abs/2506.20333)
## Authors
Jiayan Chen,Kai Li,Yulu Zhao,Jianqiang Huang,Zhan Wang
## Background
肝包虫病（HE）是一种在欠发达牧区广泛传播的寄生疾病，这些地区医学资源有限。虽然卷积神经网络（CNN）和转换器（Transformer）模型已经在医学图像分割中广泛应用，但是CNN由于小的局部感受野缺乏全局上下文模型能力，而Transformer模型虽然能够捕捉长时间依赖关系，但计算成本高。近年来，状态空间模型（SSMs）如Mamba因其能在处理长序列时保持线性复杂度而引起了关注。
## Innovation
本文提出了一种名为EAGLE的U形网络，该网络包含一个渐进视觉状态空间（PVSS）编码器和一个混合视觉状态空间（HVSS）解码器，二者协同工作以实现肝包虫病（HE）病灶的高效和精确分割。此外，文中设计了一个卷积视觉状态空间块（CVSSB）模块用于融合局部和全局特征，还设计了一个哈尔小波变换块（HWTB）模块用于在通道维度上压缩空间信息，以实现无损下采样。由于缺乏公开的HE数据集，作者从当地医院收集了260名患者的CT切片数据进行实验。实验结果显示，EAGLE模型在Dice 相似性系数（DSC）上表现出色，达到了89.76%，超过了MSVM-UNet模型1.61%。
## Conclusion
实验表明，所提出的EAGLE模型在肝包虫病病灶分割任务上取得了最先进的性能，为相关疾病的研究和诊断提供了新的技术手段。
# 346. `cs.CV` - 将放射组学特征与深度表示融合以在胎儿超声图像中估计妊娠周数 [PDF](https://arxiv.org/pdf/2506.20407), [HTML](https://arxiv.org/abs/2506.20407)
## Authors
Fangyijie Wang,Yuan Liang,Sourav Bhattacharjee,Abey Campbell,Kathleen M. Curran,Guénolé Silvestre
## Background
胎儿超声测量是准确估计妊娠周数（GA）的关键，但依靠操作员的手动测量耗时且依赖于操作者。因此，临床上需要自动计算机辅助方法来提高效率和准确性。本文研究了一个新的特征融合框架，通过融合放射组学特征和深度表示来估计妊娠周数，无需使用任何测量信息。该框架利用放射组学在医学影像分析中的可解释性，结合深度学习模型从胎儿超声图像中提取深层表示和放射组学特征，以估计妊娠周数，且在不同地理区域和不同人群中的实验结果证明了其鲁棒性。
## Innovation
提出了一种新的特征融合框架，通过融合放射组学特征与深度表示来估计胎儿超声图像中的妊娠周数，无需使用任何测量信息，其使用深度学习模型提取超声图像的深层表示，并提取放射组学特征来揭示胎儿大脑生长的规律和特征，进一步通过融合放射组学特征和深层表示来估计妊娠周数。该框架在三个孕期的平均绝对误差为8.0天，并优于当前基于机器学习的方法，展示了很强的鲁棒性。
## Conclusion
本文提出的框架在不同地理区域和人群中的实验中表现出色，平均绝对误差仅为8.0天，明显优于现有的机器学习方法，并且已被上传到GitHub供进一步研究使用。这一研究为著名的胎儿生长监测和妊娠期管理提供了有效的计算机辅助工具。
# 347. `cs.CV` - 一种具有可追溯推理的罕见疾病诊断代理系统 [PDF](https://arxiv.org/pdf/2506.20430), [HTML](https://arxiv.org/abs/2506.20430)
## Authors
Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie
## Background
世界各地受到罕见疾病影响的个体超过3亿，但及时准确诊断仍然是一个普遍的挑战。这主要是由于罕见疾病的临床异质性、低个体发病率以及大多数临床医生对罕见疾病缺乏了解。
## Innovation
该论文介绍了DeepRare，这是一种基于大型语言模型的罕见疾病诊断代理系统，能够处理异质性临床输入并生成罕见疾病的排列表征诊断假设，每条假设都配有清晰的推理链，将中间分析步骤与可验证的医学证据连接起来。DeepRare包括三个关键组件：中央主机，具有长期记忆模块；专门的代理服务器，负责领域特定的分析任务，结合了超过40个专门工具和规模化的实时医疗知识源，确保了最新的临床信息访问。这种模块化和可扩展的设计使复杂的诊断推理成为可能，同时保持了可追溯性和适应性。在八个数据集上对DeepRare进行了评估，证明系统的诊断性能卓越，在2,919种疾病中有100%的准确性，与15种方法相比，在HPO评估中表现优异，平均Recall@1得分57.18%，显著超越其他方法，包括传统的生物信息学诊断工具、大型语言模型和其他代理系统，以及在多种输入场景下也表现优越。
## Conclusion
DeepRare系统被实现为一个用户友好的网络应用程序，展示了其在罕见疾病诊断中的应用潜力。
# 348. `cs.CV` - 利用纹理保留的自我监督、专家混合和多任务集成的机遇性骨质疏松诊断 [PDF](https://arxiv.org/pdf/2506.20282), [HTML](https://arxiv.org/abs/2506.20282)
## Authors
Jiaxing Huang,Heng Guo,Le Lu,Fan Yang,Minfeng Xu,Ge Yang,Wei Luo
## Background
骨质疏松症由骨密度（BMD）降低和骨微结构受损引起，在老龄化人口中增加了骨折风险。虽然双能X射线吸收仪（DXA）是临床骨密度评估的标准方法，但由于其在资源匮乏地区的有限可及性，阻碍了诊断。现有的基于现有影像数据进行骨质疏松症诊断的机遇性CT分析方法存在不足，主要包括：（1）未充分利用未标记的椎骨数据；（2）设备特定的DXA差异导致的系统性偏差；（3）缺乏整合临床知识如空间BMD分布模式。为解决这些问题，本研究提出了一种统一的深度学习框架，旨在综合利用未标记CT数据的相关特征，增强模型跨设备兼容性，并融合多任务学习以进行骨质疏松症诊断、骨密度回归和椎体定位预测。研究在三个临床中心和一个外部医院进行了验证，表明该方法在机遇性骨质疏松筛查和诊断的泛化能力和准确性方面优于现有方法。
## Innovation
本研究提出了三项创新：（1）使用放射组学表示的自我监督学习方法，充分利用未标记的CT数据，保留骨组织纹理；（2）采用专家混合架构（MoE）并结合学习门控机制，增强模型在不同设备间的适应能力；（3）将骨质疏松症诊断、骨密度回归和椎体定位预测任务进行多任务集成，同时提高诊断的效率和准确性。这些创新共同克服了当前方法中的不足，提升了骨质疏松症诊断的准确性与普适性。
## Conclusion
本研究通过提出一种统一的深度学习框架，结合自我监督学习、专家混合架构和多任务集成方法，显著改善了骨质疏松症的诊断性能。该方法在多个临床中心和外部医院验证中表现出色，具有较高的泛化能力和准确性，为在资源有限地区进行高效骨质疏松症筛查与诊断提供了新途径。
# 349. `cs.CV` - EditP23：通过多视角图像提示传播进行的3D编辑 [PDF](https://arxiv.org/pdf/2506.20652), [HTML](https://arxiv.org/abs/2506.20652)
## Authors
Roi Bar-On,Dana Cohen-Bar,Daniel Cohen-Or
## Background
传统的3D编辑方法依赖于文本提示或显式的空间遮罩，这可能限制了编辑的直观性和灵活性。先前的研究往往需要用户定义复杂的遮罩，以确保编辑在不同视角下的连贯性。
## Innovation
提出了EditP23方法，该方法允许用户通过一对图像（原始视图和用户编辑的视图）来条件化多视角扩散模型的隐空间中的编辑流，从而在不依赖于掩模的情况下，以3D一致的方式传播编辑。这种方法是前馈的，不需要优化，并且能够保持原始对象的结构和外观的一致性。
## Conclusion
EditP23方法在多个对象类别和编辑场景下表现出色，能够高保真地传播和再现用户编辑，而无需手动绘制遮罩。
# 350. `cs.CV` - Weighted Mean Frequencies: 一种用于4D Flow MRI分割的手工Fourier特征 [PDF](https://arxiv.org/pdf/2506.20614), [HTML](https://arxiv.org/abs/2506.20614)
## Authors
Simon Perrin,Sébastien Levilly,Huajun Sun,Harold Mouchère,Jean-Michel Serfaty
## Background
近年来，4D Flow MRI图像的使用使我们在心脏周期内量化体积内流动的速度场成为可能。然而，这些生物标志物的分辨率低和噪声的存在是重要问题。现有研究表明，壁剪应力等生物标志物特别受血管分割分辨率低的影响。相位对比磁共振血管成像（PC-MRA）是目前最先进的方法来促进分割。本作旨在介绍一种新的手工特征，提供4D Flow MRI图像的新可视化方法，适用于分割任务。该特征称为加权平均频率（WMF），能够揭示一个体素在过去脉动流中穿越的空间三维区域。其值通过使用最优阈值和深度学习方法分割4D Flow MRI图像进行了实验证明，获得的IoU和Dice值分别提高了0.12和0.13，优于PC-MRA特征。此项特征有望为心脏或大脑等其他血管区域的分割提供有价值的见解，改善未来分割过程。
## Innovation
加权平均频率（WMF）是一种新的手工特征，用于4D Flow MRI图像的分割，能够揭示体素在过去脉动流中穿越的空间三维区域。通过实验证明，该特征在使用最优阈值和深度学习方法分割4D Flow MRI图像时提高了IoU和Dice值，分别提高了0.12和0.13，优于现有的PC-MRA特征。
## Conclusion
该手工特征WMF为4D Flow MRI图像的分割提供了有价值的视觉化方法，提高了分割性能，并为其他血管区域的分割提供了潜在的应用潜力。
# 351. `cs.CV` - HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction [PDF](https://arxiv.org/pdf/2506.20566), [HTML](https://arxiv.org/abs/2506.20566)
## Authors
Zhonghao Shi,Enyu Zhao,Nathaniel Dennler,Jingzhen Wang,Xinyang Xu,Kaleen Shrestha,Mengxue Fu,Daniel Seita,Maja Matarić
## Background
实时的人机交互（HRI）感知对于有效的人机交互至关重要，而大型视觉-语言模型（VLMs）提供的广泛感知能力在实际应用中却往往因为延迟较高而受到负面影响，这影响了用户体验并限制了其在现实世界场景中的应用范围。本文通过引入HRIBench基准测试，旨在系统地研究视觉问答（VQA）模型在HRI中的感知能力及其性能-延迟权衡，HRIBench涵盖了五个关键领域：非言语线索理解、口头指令理解、人-机器人物体关系理解、社会导航和人员识别。利用实际的HRI环境数据构建非言语线索理解部分，其他领域则使用公开数据集。总体而言，HRIBench包含500个问题，每个领域200个。研究发现，尽管VLMs具有泛化能力，但它们对核心感知能力仍然不足，这些能力对于HRI至关重要。而且，我们的实验中没有一个模型在性能与延迟之间找到了满意的权衡，突显了未来研究开发小型且低延迟的VLMs的必要性，这些模型具备改进的人机感知能力.
## Innovation
通过HRIBench建立了一个新的视觉问答基准，专门评估不同视觉-语言模型在关键人机感知任务上的能力，涵盖了非言语线索理解、口头指令理解、人-机器人物体关系理解、社会导航和人员识别五个领域，同时对比了当前最先进的闭源和开源模型在HRIBench上的表现，指出了现有模型在实时部署中性能-延迟权衡上的不足，从而推动未来研究开发更有效的高精度低延迟的视觉-语言模型.
## Conclusion
尽管当前视觉-语言模型在泛化能力上具有潜力，但对于构建有效的人机交互感知系统而言，依然存在不足。现有模型在典型的人机感知任务中表现出有限的实时性能。HRIBench 提供了一个公正、全面的评估平台，并显示了当前VLMs的局限性，强调了在维护实时性和低延迟的同时提高模型准确性的重要性。该研究呼吁对低延迟且具有强大人机感知能力的模型进行进一步研究。
# 352. `cs.CV` - 神经图地图：高效的环视闭合整合密集映射 [PDF](https://arxiv.org/pdf/2405.03633), [HTML](https://arxiv.org/abs/2405.03633)
## Authors
Leonard Bruns,Jun Zhang,Patric Jensfelt
## Background
当前的神经场基SLAM方法通常使用单一的整体场来表示场景。这妨碍了环视闭合约束的有效整合，限制了方法的扩展性。
## Innovation
本文提出了一种新颖的RGB-D神经映射框架，该框架将场景用轻量级神经场的集合表示，并动态锚定到稀疏视觉SLAM系统的姿态图上。此方法能够整合大规模环视闭合，只需少量重新整合。
## Conclusion
本文通过构建大尺度地图证明了方法的扩展性，并在大数据场景中相对于现有顶尖方法的性能和运行时间方面表现出色。代码开源提供。
# 353. `cs.CV` - 可见和红外图像馈送中低光下行人检测的问题与挑战 [PDF](https://arxiv.org/pdf/2311.08557), [HTML](https://arxiv.org/abs/2311.08557)
## Authors
Thangarajah Akilan,Hrishikesh Vachhani
## Background
行人检测已成为自动驾驶、智能交通和交通监控等高级任务的基础。当前的研究主要集中在使用可见图像的行人检测，尤其是在白天。然而，当环境条件变为低光照或夜间时，行人检测任务变得极具挑战性。近期，有新的方法尝试利用副源，例如远红外（FIR）温度传感器，来检测低光照条件下的行人。本文综述了低光照行人检测的最新进展，系统地分类和分析了各种基于区域、非区域及图学习的方法，并提出了实施问题和挑战。此外，还概述了可用于研究和开发先进的低光照行人检测算法的关键基准数据集。
## Innovation
本文提出了利用远红外（FIR）温度传感器在低光照条件下检测行人的新方法，并综述了低光照行人检测的最新进展，系统分析了各种方法及其挑战。
## Conclusion
本文回顾了低光照行人检测领域的研究进展，分类和分析了不同的算法，提出了在研究和开发低光照行人检测算法时可以使用的关键基准数据集，同时也指出了该领域的实施问题和挑战。
# 354. `cs.CV` - KD-DETR: Knowledge Distillation for Detection Transformer with Consistent Distillation Points Sampling [PDF](https://arxiv.org/pdf/2211.08071), [HTML](https://arxiv.org/abs/2211.08071)
## Authors
Yu Wang,Xin Li,Shengzhao Weng,Gang Zhang,Haixiao Yue,Haocheng Feng,Junyu Han,Errui Ding
## Background
DETR是一种新颖的端到端变换器架构目标检测器，相较于经典检测器，它的性能在规模扩大时表现出色。然而，在DETR上利用知识蒸馏进行模型压缩的研究相对较少，尤其是在确保学生模型能够有效模仿教师模型的复杂预测方面。现有的知识蒸馏方法在经典检测器上已经得到了充分的研究，但对于DETR而言，存在主要挑战，即缺乏一致的蒸馏点，这导致学生模型难以有效学习教师模型的特征。
## Innovation
作者提出了第一个适用于DETR的一般知识蒸馏框架(KD-DETR)，该框架通过一致的蒸馏点采样策略，解决了在DETR中采用知识蒸馏时的核心挑战。具体来说，他们通过引入一组专门的对象查询将检测任务和蒸馏任务解耦，构造了DETR的蒸馏点。并且提出了从通用到特定的蒸馏点采样策略，以探索KD-DETR的扩展性。实验结果表明，无论是统一尺度的DAB-DETR、多尺度的可变形DETR或DINO，还是异质蒸馏场景，KD-DETR都能有效提升学生模型的性能，最高提升5.2%。
## Conclusion
通过引入专门的对象查询建立一致的蒸馏点，作者构建了第一个通用的DETR知识蒸馏框架(KD-DETR)，并通过多组实验验证了其有效性。该框架不仅提高了通用和特定情况下的检测性能，还在异质蒸馏场景中展示出与同质蒸馏相当的效果。相关代码在项目页面提供，供进一步研究参考。
# 355. `cs.CV` - FluoroSAM：一种语言可调的X射线图像分割基础模型 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
传统的基于特定任务的医学影像分割模型适用于狭窄的应用范围，然而扩展到更广泛的应用需要更多的数据、注释和训练时间。此外，X射线成像模块因其高度变异性，包括从诊断胸片到介入性透视成像的广泛应用，且数据可用性不同。现有的基础模型主要用于有大量丰富标注数据的医学成像场景。因此，需要一种能够适应不同医学X射线图像并且能够基于自然语言提示进行分割的语言可调基础模型，以促进人类和机器在X射线成像和分析过程中的丰富交互.
## Innovation
FluoroSAM是基于Segment Anything Model的全新语言可调版本，通过大量（300万）合成X射线图像（涵盖多种人体解剖、成像几何和视角）的从零开始训练。该模型创新性地结合了文本嵌入的向量量化（VQ）技术，能够根据自然语言提示分割出各种人体结构和工具。通过此模型，突出了其在真实X射线图像上的性能，并展示了在X射线成像和分析中的多个应用案例，证明了其作为语言对齐的基础模型，在灵活的人机交互中的重要性.
## Conclusion
FluoroSAM作为一种全新开发的语言可调基础模型，能够灵活处理任意医学X射线图像。通过合成数据的训练以及结合VQ技术，FluoroSAM能够在真实环境中有效应用于X射线图像的自动化分割和分析，为诊断和干预性医疗提供了新的可能性，并展示了与人类在工作流程中的灵活集成。
# 356. `cs.CV` - toddlers' active gaze behavior supports self-supervised object learning [PDF](https://arxiv.org/pdf/2411.01969), [HTML](https://arxiv.org/abs/2411.01969)
## Authors
Zhengyang Yu,Arthur Aubret,Marcel C. Raabe,Jane Yang,Chen Yu,Jochen Triesch
## Background
幼儿在几乎没有监督的情况下能够识别不同视角下的物体。在这一过程中，他们会频繁地进行眼动和头部运动，这对他们的视知觉体验产生影响。目前尚不清楚这些行为是如何促进幼儿物体识别能力的提升的。本研究通过结合头戴式眼动追踪与无监督机器学习技术，试图回答这一问题。
## Innovation
本研究通过使用头戴式相机采集当前注视点的图像区域，并将其输入到无监督学习模型中，模拟幼儿的视觉体验。研究结果显示，幼儿的注视策略有助于学习不变的物体表示。研究还表明，高清晰度的中央视觉场的局限性对该过程至关重要。
## Conclusion
总的来说，本研究揭示了幼儿的注视行为如何支持其发展出视角不变的物体识别能力。
# 357. `cs.CV` - GlyphPattern: 视觉语言模型中的抽象模式识别基准 [PDF](https://arxiv.org/pdf/2408.05894), [HTML](https://arxiv.org/abs/2408.05894)
## Authors
Zixuan Wu,Yoolim Kim,Carolyn Jane Anderson
## Background
基于强大力量的语言模型的视觉-语言模型（VLMs）在跨视觉和文本数据的推理方面取得了快速进展。尽管VLMs在它们训练的任务上表现良好，但我们的研究表明，抽象模式识别面临关键挑战。为此，我们提出了一个名为GlyphPattern的数据集，包含318个人类书写的视觉模式描述和三种视觉表现风格，总共954项，用来评估VLMs的抽象模式识别能力。这些模式来源于大规模的认知科学研究，因此富含空间参考和组合性。研究表明，最先进的VLMs（GPT-4o仅达到55%的准确率），且仅靠少量的提示几乎没有明显提升。详细的错误分析揭示了在视觉处理、自然语言理解和模式泛化等多个方面的挑战。
## Innovation
我们构建了GlyphPattern数据集，用于评估视觉语言模型在抽象模式识别任务上的能力。该数据集包括318个人类书写的视觉模式描述，富含空间参考和组合性，是首次针对该领域的尝试。同时，我们的研究揭示了VLMs在抽象模式识别任务中面临的多方面挑战。
## Conclusion
我们的实验表明，最先进的视觉语言模型在GlyphPattern上面临较大的挑战，准确性仅为55%，并且仅靠少量提示没有明显效果。通过细致的错误分析，我们发现了多重挑战，包括视觉处理、自然语言理解和模式泛化等多个方面。
# 358. `cs.CV` - 通过通道感知指导学习适应性照明 [PDF](https://arxiv.org/pdf/2412.01493), [HTML](https://arxiv.org/abs/2412.01493)
## Authors
Qirui Yang,Peng-Tao Jiang,Hao Zhang,Jinwei Chen,Bo Li,Huanjing Yue,Jingyu Yang
## Background
学习适应性照明是实现良好视觉感知及支持后续视觉任务的关键步骤。现有研究通常将与光相关的问题逐一单独解决，如高动态范围成像和曝光校正。然而，研究发现这些任务中存在共通的基础特性：不同颜色通道具有不同的光特性，并且这种特性在空间和频率域中的表现不同。
## Innovation
本研究引入了具有通道意识的学习适应照明网络（LALNet），这是一个多任务框架，旨在高效处理多个与光相关的问题。LALNet融合了色彩分离特征，强调每个颜色通道的独特光特性，并通过Light Guided Attention（LGA）融合了传统的色彩混合特征。LGA利用色彩分离特征引导色彩混合特征关注通道差异，确保所有通道间的视觉一致性。此外，LALNet采用双域通道调控产生色彩分离特征，并采用混合通道调控和光状态空间模块产生色彩混合特征。
## Conclusion
在四类代表性光相关任务上的广泛实验表明，LALNet在基准测试中的性能显著优于现有最先进的方法，并且所需的计算资源较少。
# 359. `cs.CV` - USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction and Gaussian Splatting [PDF](https://arxiv.org/pdf/2411.10504), [HTML](https://arxiv.org/abs/2411.10504)
## Authors
Kang Chen,Jiyuan Zhang,Zecheng Hao,Yajing Zheng,Tiejun Huang,Zhaofei Yu
## Background
基于刺态的超高频频率场景捕捉（40 kHz）和神经形态相机（spike cameras），这些相机通过比特流（0-1）格式记录场景，正被用于3D重建任务。现有的刺态3D重建方法通常采用分阶段的流程，即先基于现有的刺态到图像的重建算法进行高质量的图像重建，再进行相机姿态估计和3D重建。然而，这种分阶段的方法会导致累积误差，前期图像重建质量限制会负面影响姿态估计，最终导致3D重建质量下降。为解决该问题，提出了一种一体化的优化框架USP-Gaussian，该框架统一了刺态图像重建、姿态校正和Gaussian splatting，并实现了端到端的优化。
## Innovation
提出了一种新的联合迭代优化框架USP-Gaussian，该框架将刺态图像重建、姿态校正和Gaussian splatting统一整合，利用3DGS的多视图一致性和刺态摄像机的姿态捕捉能力，实现两个模块之间的信息无缝集成。实验表明，该方法能够有效消除分阶段方法引起的累积误差，并在实际场景中通过姿态优化实现稳健的3D重建，优于其他方法，有效降低了噪声，保留了精细纹理细节。
## Conclusion
该研究通过提出USP-Gaussian框架，解决了刺态3D重建中的累积误差问题，实现了刺态图像重建、姿态校正和Gaussian splatting的统一，提高了3D重建的准确性和鲁棒性，尤其是在实际应用中具有显著效果。
# 360. `cs.CV` - MambaMorph: 基于Mamba的医学MR-CT变形配准框架 [PDF](https://arxiv.org/pdf/2401.13934), [HTML](https://arxiv.org/abs/2401.13934)
## Authors
Tao Guo,Yinuo Wang,Shihao Shu,Weimin Yuan,Diansheng Chen,Zhouping Tang,Cai Meng,Xiangzhi Bai
## Background
医学图像分析中，跨不同模态的体素级空间对应关系捕捉至关重要。然而，现有的配准方法在配准精度和临床实用性方面并不理想。为此，本文旨在解决这一问题，介绍了一种名为MambaMorph的新型多模态弹性配准框架，该框架结合了基于Mamba的配准模块和细粒度轻量级特征提取器，以实现高效长距离对应关系建模和高维特征学习。此外，文中还开发了一个详尽标注的脑部MR-CT配准数据集SR-Reg，以解决多模态配准中数据稀缺的问题。通过在SR-Reg数据集和公共T1-T2数据集上的定量实验，验证了MambaMorph在多模态配准方面的性能。
## Innovation
MambaMorph框架采用基于Mamba的配准模块和细粒度、简单的特征提取器，有效地模型了长距离对应关系并学习了高维特征。该框架显著提升了配准精度，并展示了基于Mamba的配准模块和轻量级特征提取器在保持合理计算成本和速度的前提下，具有卓越的配准效果。此外，还提供了一个详尽标注的脑部MR-CT配准数据集SR-Reg，旨在解决多模态配准中数据稀缺的问题。
## Conclusion
MambaMorph框架在多模态配准中具有优越的表现，验证了其在医学图像配准中的潜力。未来的工作将更深入研究MambaMorph在临床应用中的表现，并继续完善各类数据集以支持更广泛的研究需求。
# 361. `cs.CV` - ReconX: 使用视频扩散模型从稀疏视角重建任意场景 [PDF](https://arxiv.org/pdf/2408.16767), [HTML](https://arxiv.org/abs/2408.16767)
## Authors
Fangfu Liu,Wenqiang Sun,Hanyang Wang,Yikai Wang,Haowen Sun,Junliang Ye,Jun Zhang,Yueqi Duan
## Background
3D场景重建技术已经能够将现实世界的2D图像转化为3D模型，且可以生成逼真的3D结果。尽管在密集视角恢复场景方面取得了巨大成功，但仅凭有限的拍摄视角重建详细场景仍然是一个难以精确解决的优化问题，经常导致不可见区域出现伪影和失真。因此，本文致力于解决在有限输入视角下的3D场景重建问题，提出了名为ReconX的新颖3D场景重建框架，通过引入大规模预训练视频扩散模型的强生成先验来应对这一挑战，但直接由预训练模型生成的视频帧难以准确保持3D视图一致性。ReconX框架首先构建全局点云，然后将其编码为上下文空间作为3D结构条件，通过该条件引导视频扩散模型合成同时保持细节和高3D一致性性的视频帧，从而确保多视角场景的连贯性，最后通过一种基于置信度的3D高斯碰撞优化方案恢复3D场景。实验结果在多种真实数据集上的展示出ReconX在质量和泛化能力上优于现有的最优方法。
## Innovation
提出了一种名为ReconX的新颖3D场景重建方法，利用大规模预训练视频扩散模型的强生成先验来解决来自稀疏视角的3D场景重建问题，通过先构建全局点云并引导视频扩散模型生成具有高3D一致性的视频帧来保证场景从多视角的连贯性，最后通过优化方案恢复3D场景，该方法能够显著提高重建质量和泛化能力，克服了传统方法在处理稀疏视角重建中的局限性。
## Conclusion
本文提出的方法ReconX在多个真实数据集上的实验结果表明，在质量和泛化能力上均优于现有的最优3D场景重建方法。该方法能够通过使用大规模预训练视频扩散模型和先进的优化方法解决来自稀疏视角的3D场景重建难题，为实景3D重建提供了强有力的技术支持。
# 362. `cs.CV` - ULSR-GS: 超大规模的多视图几何一致性高保真表面重建高斯绘制 [PDF](https://arxiv.org/pdf/2412.01402), [HTML](https://arxiv.org/abs/2412.01402)
## Authors
Zhuoxiao Li,Shanliang Yao,Taoyu Wu,Yong Yue,Wufan Zhao,Rongjun Qin,Angel F. Garcia-Fernandez,Andrew Levers,Xiaohui Zhu
## Background
尽管高斯绘制（GS）方法在场景渲染和小区域表面提取方面表现出高效和高质量的特点，但在处理大规模航空图像表面提取任务时，GS方法面临困难。为此，我们提出了ULSR-GS框架，专为超大规模场景下的高保真表面提取设计。该框架针对现有基于GS的网格提取方法的局限性，采用点到照片分割和多视角最佳视角匹配原则来选择每个子区域的最佳训练图像，并在训练过程中结合多视角几何一致性进行密度增强，以提升表面提取细节。
## Innovation
ULSR-GS框架通过引入点到照片分割和多视角最佳视角匹配原则，以及基于多视角几何一致性的增强策略，有效解决了大规模场景下的表面提取问题。实验表明，ULSR-GS在复杂城市环境中的表面提取精度显著优于其他基于GS的最新技术。
## Conclusion
ULSR-GS方法在大规模航空影像制图基准数据集上的实验结果证明，其在复杂城市环境中的表面提取精度有了显著提升，特别是在复杂的城市环境中具有显著优势，证明了其在大规模场景下的有效性和先进性。
# 363. `cs.CV` - 世界一致的数据生成用于视觉-语言导航 [PDF](https://arxiv.org/pdf/2412.06413), [HTML](https://arxiv.org/abs/2412.06413)
## Authors
Yu Zhong,Rui Zhang,Zihao Zhang,Shuo Wang,Chuan Fang,Xishan Zhang,Jiaming Guo,Shaohui Peng,Di Huang,Yanyang Yan,Xing Hu,Qi Guo
## Background
视觉-语言导航(VLN)是一项挑战性的任务，需要智能体根据自然语言指令在逼真的环境中进行导航。主要障碍是数据稀缺性，导致智能体在未见过的新环境中表现不佳。尽管数据增强是扩展数据集的有希望的方法，但如何生成既有多样性和世界一致性的人工数据依然是一个难题。
## Innovation
提出了世界一致性数据生成(WCGEN)，这是一个高效的增强框架，既满足多样性的要求，又能确保世界一致性。该框架包含两个阶段：轨迹阶段使用点云技术确保视角空间连贯性；视角阶段采用新型角度合成方法确保视角空间和环视的一致性。通过使用3D知识准确预测视角变化，确保生成过程中的一致性。实验结果显示，该方法有效提升了智能体在未见过环境中的泛化能力，使其在各种导航任务中达到新的最佳性能。
## Conclusion
WCGEN框架能够生成既多样又世界一致的数据，有效提升了智能体在未见过环境中的导航性能。该方法能够使视觉-语言导航代理更好地适应未见过的新环境。
# 364. `cs.CV` - 无匹配的结构光深度恢复 [PDF](https://arxiv.org/pdf/2501.07113), [HTML](https://arxiv.org/abs/2501.07113)
## Authors
Zhuohang Yu,Kai Wang,Kun Huang,Juyong Zhang
## Background
现有大多数深度估计方法依赖于图像匹配，本文提出了一种利用单目结构光系统获取的图像进行深度估计的新方法。这种方法通过自监督可微分体渲染来训练密度体素网格，以表示场景几何形状，并在此过程中利用结构光系统投影模式衍生的颜色场，以孤立优化几何场，从而实现更快的收敛和高质量的结果。此外，还引入了归一化设备坐标、失真损失和基于表面的颜色损失来提高几何保真度。实验结果表明，该方法在几何性能上优于当前基于匹配的技术，特别是在少量样本情况下，平均深度估计误差降低了约30%。该方法还允许快速训练，比之前的无匹配方法快三倍，这些方法使用了隐式表示。
## Innovation
提出了一种无匹配的深度恢复方法，利用单目结构光系统的图像，通过自监督可微分体渲染训练密度体素网格来表示场景几何形状，并在此过程中利用结构光系统投影模式衍生的颜色场，以孤立优化几何场，快速收敛并提供高质量的结果。此外，引入了归一化设备坐标、失真损失和基于表面的颜色损失以提高几何保真度。该方法在几何性能上优于当前基于匹配的技术，且训练速度更快。
## Conclusion
实验结果表明，该方法在少样本情况下性能优于当前基于匹配的技术，平均深度估计误差降低了约30%。此外，该方法允许快速训练，是最新的无匹配方法的约三倍快。
# 365. `cs.CV` - MatSwap：图像中的光敏材料转移 [PDF](https://arxiv.org/pdf/2502.07784), [HTML](https://arxiv.org/abs/2502.07784)
## Authors
Ivan Lopes,Valentin Deschaintre,Yannick Hold-Geoffroy,Raoul de Charette
## Background
在图像中实现材料转移是一个复杂的任务，因为材料外观、几何形状和光线在照片中的纠缠使得该任务不具备可操作性。现有的材料编辑方法要么依赖繁琐的文本工程，要么需要大量的手工标注，而这些标注过程要求艺术家的知识和3D场景属性，这些属性在实际应用中难以获得。
## Innovation
本文提出了MatSwap方法，能够将材料保真地转移到图像中的指定表面。MatSwap方法直接学习输入材料与其在场景中的外观之间的关系，无需进行显式的UV映射。通过一个专有的光线和几何感知的扩散模型实现这一目的，并且使用合成数据集微调一个大规模预训练的文本到图像模型，从而确保该方法能够有效推广到真实图像。
## Conclusion
我们对合成和真实图像进行了评估，结果显示该方法在定性和定量上均优于近期的工作。我们已公开了代码和数据。
# 366. `cs.CV` - VICCA：生成报告中无人类反馈的胸片异常视觉解释和理解 [PDF](https://arxiv.org/pdf/2501.17726), [HTML](https://arxiv.org/abs/2501.17726)
## Authors
Sayeh Gholipour Picha,Dawood Al Chanti,Alice Caplier
## Background
随着人工智能（AI）在医疗保健中的作用越来越重要，可解释和可信的模型的需求变得至关重要。当前的胸部X光报告生成系统通常缺乏在没有专家监督的情况下验证输出的机制，这引起了关于可靠性和可解释性的担忧。为应对这些挑战，本文提出了一种新型的多模态框架，该框架旨在增强AI生成的医学报告的语义对齐和定位准确性。该框架整合了两个关键模块：短语锚定模型和文本转图像扩散模块。这两个模块结合使用，能够提高报告的准确性和可靠性，增强AI在医学影像中的透明度和可信度。
## Innovation
该研究提出了一种先进的多模态框架，该框架集成了两部分：短语锚定模型用于基于文本提示在胸部X光图像中定位病理，文本转图像扩散模块用于生成合成的胸部X光图像，同时保留解剖学的准确性。结合了文本和图像的双重评分系统评估定位准确性以及语义一致性，这种方法明显优于现有方法，取得了病理定位和文本到图像对齐的最新成果。
## Conclusion
该多模态框架通过结合短语锚定和扩散模型，并引入双重评分系统，提供了一种验证报告质量的稳健机制，为更可信和透明的AI在医学影像中的应用开启了新途径。
# 367. `cs.CV` - 基于像素级受保护的健康信息检测的AI系统设计探索 [PDF](https://arxiv.org/pdf/2501.09552), [HTML](https://arxiv.org/abs/2501.09552)
## Authors
Tuan Truong,Ivo M. Baltruschat,Mark Klemens,Grit Werner,Matthias Lenga
## Background
医学图像在研究和临床环境中共享时，脱敏是确保隐私的关键步骤。初步步骤是识别受保护的健康信息（PHI），这些信息可能存在于图像元数据中或嵌入在图像像素中。尽管这些系统至关重要，但现有基于AI的解决方案缺乏评估，阻碍了可靠和稳健工具的开发。因此，本文介绍了基于AI的PHI检测管道，包括三个关键模块：文本检测、文本提取和文本分析。评测了YOLOv11、EasyOCR和GPT-4o三种模型在不同设置下的性能，并在包含多种成像模态和PHI类别的不同数据集上进行了评估。研究结果显示，使用专门针对每个模块的视觉和语言模型的最佳设置，在性能、延迟和大型语言模型（LLMs）使用成本之间取得了良好的平衡。此外，研究还表明LLM的应用不仅有助于识别PHI内容，同时也提高了OCR任务的效果并促进了端到端的PHI检测管道的实现。
## Innovation
提出了基于AI的PHI检测管道，由文本检测、文本提取和文本分析三个关键模块组成，评测了多种模型在不同数据集上的表现，且指出使用专门针对每个模块的视觉和语言模型可以获得良好的平衡效果。展示了LLM在识别PHI内容、提高OCR任务以及促进端到端的PHI检测管道方面的应用效果。
## Conclusion
该研究结果表明，使用专用的视觉和语言模型的最佳设置在PHI检测性能、延迟和成本之间提供了良好的平衡。此外，利用LLM可以更有效地识别PHI内容，并提升OCR任务，从而实现完整且有效的端到端PHI检测管道。
# 368. `cs.CV` - MagicPose4D：具有外观和运动控制的 articulated 模型构建 [PDF](https://arxiv.org/pdf/2405.14017), [HTML](https://arxiv.org/abs/2405.14017)
## Authors
Hao Zhang,Di Chang,Fang Li,Mohammad Soleymani,Narendra Ahuja
## Background
在2D和3D视觉生成模型获得成功之后，人们对生成4D内容产生了浓厚兴趣。现有方法主要依赖文本提示生成4D内容，但在定义复杂或罕见运动时往往不够精确。为了解决这一问题，提出了MagicPose4D，一种可以对4D生成过程中的外观和运动进行细化控制的新框架。MagicPose4D接受单目视频或网格序列作为运动提示，实现精确和可定制的运动控制，而不像现有方法那样受骨架约束限制。
## Innovation
MagicPose4D提出了一个双阶段的4D重构模块，该模块分为两个阶段：第一阶段使用准确的2D监督和几何信息丰富的3D伪监督捕捉模型的形状，第二阶段使用更为准确的伪3D监督提取3D运动（骨架姿态），并引入基于运动链的骨架约束以确保物理合理性。另外，提出了全局-局部Chamfer损失，它对预测的网格顶点的整体分布进行对齐，同时保持局部对齐，无需额外注释。同时也提出了一种跨类运动转移模块，该模块利用从4D重构模块中提取的运动，借助基于运动链的骨架实现跨类运动转移，通过动态刚性确保帧之间的平滑过渡，无需额外训练，提高了泛化能力。
## Conclusion
通过广泛的实验表明，MagicPose4D显著提高了4D内容生成的准确性和一致性，相较于现有方法，在多个基准测试中表现出色。
# 369. `cs.CV` - 基于傅里叶变换的高斯像素实时SLAM融合稀疏稠密地图方法 [PDF](https://arxiv.org/pdf/2503.01109), [HTML](https://arxiv.org/abs/2503.01109)
## Authors
Yansong Xu,Junlin Li,Wei Zhang,Siyu Chen,Shengyong Zhang,Yuquan Leng,Weijia Zhou
## Background
3D高斯splatting技术通过实现实时定位和高保真地图构建已经提升了同时定位与建图(SLAM)技术。然而，高斯位置不确定性及初始化参数会导致挑战，通常需要大量迭代以达到收敛，并导致高斯表示冗余或不足。
## Innovation
提出了一种基于傅里叶频域分析的自适应密集化方法，用于快速收敛的高斯先验构建；以及稀疏、稠密地图的独立统一构建方案，其中稀疏地图通过广义迭代最近点法(GICP)辅助高效跟踪，稠密地图提供高质量视觉表示。这是一套首次采用频域分析实现实时高保真高斯地图的SLAM系统。实验结果表明，在Replica和TUM RGB-D数据集上平均帧率为36 FPS，同时在定位和建图方面达到了有竞争力的精度水平。
## Conclusion
基于频域分析的高斯点技术在实时SLAM中实现了高质量的地图构建，通过融合稀疏和稠密地图方法优化了全景跟踪和视觉表示，达到了显著的实时性能和高精度。
# 370. `cs.CV` - 从O(n^2)到O(n)参数：适用于生物医学图像分类的视觉变压器中的量子自我注意力 [PDF](https://arxiv.org/pdf/2503.07294), [HTML](https://arxiv.org/abs/2503.07294)
## Authors
Thomas Boucher,John Whittle,Evangelos B. Mazomenos
## Background
研究背景是探讨如何通过引入量子技术来提高生物医学图像分类的效率和性能。传统的视觉变压器（ViTs）虽然在图像分类任务上有很好的表现，但参数量庞大，这限制了其在资源受限环境中的应用。已经有一些方法尝试通过减少模型参数来提高效率，但通常会导致性能下降。因此，探索新的机制和技术来在保持高性能的同时减少参数数量是当前的研究热点。
## Innovation
研究创新点在于提出了一种名为量子自我注意力（QSA）的技术，取代了视觉变压器中的传统自我注意力（SA）层。QSA利用参数化量子神经网络（QNNs）代替了传统的线性SA层，使参数数量从O(n^2)降低到了O(n)，显著减少了模型参数量，但仍然能够达到或接近最新的生物医学图像分类方法的性能。此外，研究首次探讨了从经典视觉变压器到量子视觉变压器的知识蒸馏（KD），展示了QSA机制在多个数据集上的参数效率和性能。这项工作表明，量子自我注意力可以在保持模型性能的同时大幅减少参数数量，显示出其作为参数高效生物医学图像分析架构的良好潜力.
## Conclusion
研究结论是量子自我注意力机制（QSA）在保持高效率的同时大大减少了参数数量，对于生物医学图像分类任务具有实际的适用性和潜力。通过从经典视觉变压器到量子视觉变压器的知识蒸馏，发现具有更多量子比特的架构能从预训练中获得更大的好处，这为QSA结构的发展提供了一个可能的参数优化方向。这些发现为进一步研究和实际应用中的量子技术提供了新的理论支持。
# 371. `cs.CV` - 基于解耦表示的抗干扰多模态学习在眼科疾病分级中的应用 [PDF](https://arxiv.org/pdf/2503.05319), [HTML](https://arxiv.org/abs/2503.05319)
## Authors
Xinkun Wang,Yifang Wang,Senwei Liang,Feilong Tang,Chengzhi Liu,Ming Hu,Chao Hu,Junjun He,Zongyuan Ge,Imran Razzak
## Background
本文讨论了眼科医生依赖多模态数据以提高诊断准确性的问题。然而，在实际应用中，完整的多模态数据罕见，因为缺乏医疗设备且存在数据隐私的担忧。传统的深度学习方法通常通过在潜在空间中学习表示来应对这些问题。但这些方法存在两个关键限制：(i) 在复杂模态中存在与任务无关的冗余信息（如大量切片），导致潜在空间表示中的大量冗余；(ii) 重叠的多模态表示使得难以为每个模态提取独特的特征。
## Innovation
为了克服这些挑战，作者提出了Essence-Point和解耦表示学习（EDRL）策略，该策略通过将自我蒸馏机制集成到端到端框架中，来增强特征选择和解耦以实现更稳健的多模态学习。Essence-Point表示学习模块选择增强疾病分级性能的判别性特征。解耦表示学习模块将多模态数据分解为模态共享和模态独特表示，减少特征纠缠，增强其双眼科疾病诊断的稳健性和可解释性。实验表明，所提的EDRL策略显著优于当前最先进的方法。
## Conclusion
基于EDRL策略，本文提供了一种新方法来实现更多稳健的多模态学习，以提高眼科疾病分级的精度和可解释性。
# 372. `cs.CV` - 时间感知的移动摄影自动白平衡 [PDF](https://arxiv.org/pdf/2504.05623), [HTML](https://arxiv.org/abs/2504.05623)
## Authors
Mahmoud Afifi,Luxi Zhao,Abhijith Punnappurath,Mohammed A. Abdelsalam,Ran Zhang,Michael S. Brown
## Background
相机依赖自动白平衡(AWB)来纠正由场景照明和相机光谱灵敏度引起的不理想的颜色偏移。这通常通过一个估计器实现，该估计器仅从相机原始传感器图像中的色彩信息中确定全局色彩偏移。移动设备提供了有价值的附加元数据，例如捕获时间戳和地理定位信息，这些信息提供了强大的上下文线索，有助于缩小可能的照明解决方案。
## Innovation
本文提出了一种轻量级的光照估计方法，该方法将上下文元数据、附加的捕捉信息和图像颜色集成到一个紧凑的模型中（约5K参数），从而取得了令人鼓舞的结果，其性能与大型模型相当或超越。为了验证该方法的有效性，我们引入了一个包含3,224张手机图像的数据集，这些图像在一天的不同时间点和不同照明条件下采集，并附有基于色彩图表确定的真实光照颜色，以及通过用户研究验证的用户偏爱的光照亮度，提供了一个全面的AWB评估基准。
## Conclusion
该研究提出的方法通过结合上下文元数据和捕捉信息，实现了与传统大型模型相当或更优的自动白平衡性能，并通过一个涵盖多种光照条件和时间点的广泛数据集进行了验证，能够提供用于AWB评估的全面基准。
# 373. `cs.CV` - MaizeField3D：来自多样化品系的田间种植玉米的3D点云和程序模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
## Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
## Background
由于缺乏大规模和多样的3D数据集，基于人工智能（AI）和机器学习（ML）的3D表型分析工具，尤其是在玉米研究方面的发展受到限制。2D图像数据集无法捕捉到3D数据提供的诸如叶结构、植物体积和空间布局等关键结构细节。因此，需要一种新的方法来捕获田间生长的玉米植物的3D信息。
## Innovation
该研究提出了名为MaizeField3D的数据集，这是首个专为田间生长的玉米植物构建的3D点云数据集，用于促进农业研究。该数据集包含1,045个高质量的田间生长玉米3D点云，使用地基激光扫描仪（TLS）收集。通过图基分割方法对520个植物点云进行分割和标注，确保所有样本的一致标记。该标记数据用于拟合程序化模型，这些模型提供了玉米植物的结构参数化表示。叶子的几何形状使用非均匀有理B样条（NURBS）曲面进行表示，该曲面是通过结合无导数和有导数优化方法生成的。数据集还包括用于不同下游计算任务的多分辨率点云数据和植物形态学元数据。
## Conclusion
MaizeField3D数据集将作为人工智能驱动的表型分析、植物结构分析和农业研究中3D应用的全面基础数据集。
# 374. `cs.CV` - LPOSS: 贴和像素上的标签传播用于开放式词汇语义分割 [PDF](https://arxiv.org/pdf/2503.19777), [HTML](https://arxiv.org/abs/2503.19777)
## Authors
Vladan Stojnić,Yannis Kalantidis,Jiří Matas,Giorgos Tolias
## Background
该研究提出了一种无训练流程的方法，用于通过视觉-语言模型(Vision-and-Language Models, VLMs)进行开源词汇的语义分割。VLMs最初是为了跨模式对齐而优化的，而不是细粒度的映射相似性，这使得它们在处理语义分割任务时存在着一定的局限性。传统的基于块的编码器也面临着分辨率限制的问题，尤其是在处理目标边缘时。因此，该研究旨在通过标签传播技术，提升块级和像素级的预测准确性，从而改进语义分割的性能。
## Innovation
该方法提出了一种在视觉模型（Vision Model, VM）上进行标签传播（Label Propagation Over Patches and Pixels, LPOSS+）的方法，用于开放式词汇语义分割。LPOSS+通过在块级别的标签传播优化初始预测，并通过在像素级别进一步优化，来提高分割准确性。这种方法不仅能捕获块间的交互关系，还能在全图上下文中进行推理，避免了基于窗口的操作，从而显著提升了分割效果，特别是边界处的表现。
## Conclusion
该研究展示了LPOSS+方法在多种数据集上达到了最先进的无训练流程语义分割性能。这种方法提供了一种新的视角，即如何利用视觉和语言模型的潜力来进行开放式词汇语义分割，同时也展示了像素级标签传播技术在提高语义分割精度上的潜力。
# 375. `cs.CV` - 大型视觉语言模型中的形状和纹理识别 [PDF](https://arxiv.org/pdf/2503.23062), [HTML](https://arxiv.org/abs/2503.23062)
## Authors
Sagi Eppel,Mor Bismut,Alona Faktor-Strugatski
## Background
形状和纹理是视觉感知的基本构建块。识别不依赖于方向、纹理或上下文的各种形状，以及独立于关联对象识别纹理和材料的能力，对于理解和解释世界是至关重要的。本文介绍了一个名为LAS&T的巨大多样形状和纹理数据集，该数据集是通过从自然图像中无监督提取模式生成的。该数据集用于评估最先进的大型视觉语言模型（LVLMs）在二维和三维场景中理解和识别形状、纹理和材料的能力。结果显示，这些模型在形状识别方面的人类性能方面存在明显差距，主要依赖于高层次和语义特征，并在处理抽象形状时表现出困难，这些形状没有明显的类别关联。在纹理和材料识别方面，随着物体和环境的变化，模型能够识别具有相同纹理和材料的图像，但在识别简单且更抽象的2D纹理时，人类表现出明显的优势。这些结果展示了当前先进视觉语言模型在理解和处理基本视觉概念方面的缺陷，但简单网络直接训练这些任务时则表现出高的精确度。
## Innovation
介绍了名为LAS&T的大型多样形状和纹理数据集，通过无监督方式从自然图像中提取模式生成，用于评估大型视觉语言模型在形状、纹理和材料识别方面的性能。该数据集涵盖了广泛的视觉场景，证明了当前最先进的模型仍有明显缺陷，特别是在处理抽象形状和复杂纹理时。实验表明，直接针对这些任务训练的简单网络能够获得高准确性，这表明需要改进当前模型在理解和处理基本视觉概念的能力。
## Conclusion
本文通过提出的LAS&T数据集，展示了当前最先进的大型视觉语言模型在形状和纹理识别方面的人类差距，特别是在处理抽象和复杂场景时。这提出了未来研究中需要关注的重点，如改进模型在理解和处理基本视觉概念方面的表现。
# 376. `cs.CV` - 通过全球视角看扩散模型：它们在文化包容性方面如何？ [PDF](https://arxiv.org/pdf/2502.08914), [HTML](https://arxiv.org/abs/2502.08914)
## Authors
Zahra Bayramli,Ayhan Suleymanzade,Na Min An,Huzama Ahmad,Eunsu Kim,Junyeong Park,James Thorne,Alice Oh
## Background
文本到图像的扩散模型最近使人们能够从文本提示生成视觉上引人注目的详细图像。然而，这些模型在准确体现不同文化细微差别的能力方面仍然存在疑问。本研究旨在评估最先进的扩散模型是否能够生成涵盖十个不同国家的具有文化特异性特征的图像，并通过精细分析不同相似性方面，揭示生成的文化相关性、描述准确性和与真实世界参照图像相比的真实性的显著差异。特别是在代表不足的地区，模型往往无法生成与建筑、服饰和食物相关的文化符号.
## Innovation
本研究表明，最先进的扩散模型在生成特定文化特征的图像方面存在不足，特别是在建筑、服饰和食物方面，特别是在代表不足的地区。研究开发了一种基于神经网络的图像-图像相似性度量方法——CultDiff-S，以预测带有文化符号的真实和生成图像的人类判断。这项工作强调了需要更包容的生成AI系统，并且数据集需要在广泛的文化范围内具有公平的代表性.
## Conclusion
本研究指出，扩散模型在生成跨文化图像方面仍需改进，并提出了CultDiff和CultDiff-S来评估和改进这一领域。这强调了多文化数据集的公平性和生成AI系统当前的不足之处。未来需要更多地关注和改进模型的跨文化表现，以实现更加包容性的AI系统。
# 377. `cs.CV` - 从皮肤镜图像中测量肤色：基于合成数据集的评估 [PDF](https://arxiv.org/pdf/2504.04494), [HTML](https://arxiv.org/abs/2504.04494)
## Authors
Marin Benčević,Robert Šojo,Irena Galić
## Background
这篇论文旨在全面评估皮肤颜色测量方法在皮肤镜图像中的表现。为此，作者使用了一个具有控制的真色素含量、病变形状、毛发模型和18种不同光照条件的合成数据集（S-SYNTH）来进行评估。研究背景在于需要一种方法能够在不同光照条件下准确测量皮肤颜色，这对于医学诊断等领域至关重要。通过这种方法，可以更精确地评估不同颜色测量算法在皮肤镜图像中的表现，从而指导下一步的研究和应用工作。
## Innovation
研究的创新之处在于使用了受控条件的合成数据集来评估皮肤颜色测量方法。研究评估了四种类别的图像颜色度量方法：基于分割的方法、基于斑块的方法、颜色量化以及神经网络模型，并进一步探讨了这些方法如何估计个体表型角度（ITA）和弗吉尼亚特肤色类型（Fitzpatrick）。研究还强调了某些方法在不同光照条件下的鲁棒性和不变性，以及通过引入较大的模糊度以减少过拟合的方法对于神经网络模型的作用。
## Conclusion
研究结论是，基于分割的方法和颜色量化方法能够提供鲁棒且光照不变的估计结果，而基于斑块的方法需要校准以减少照明依赖偏差。此外，尽管使用较大模糊度的神经网络模型可以提供光照不变的弗吉尼亚特肤色预测，但其对现实世界图像的泛化能力还需要进一步验证。最后，研究提出了一些实用建议，以设计公平可靠的颜色估计方法。
# 378. `cs.CV` - 使用双胞胎网络检测两幅虹膜图像是否为单卵双胞胎 [PDF](https://arxiv.org/pdf/2503.09749), [HTML](https://arxiv.org/abs/2503.09749)
## Authors
Yongle Yuan,Kevin W. Bowyer
## Background
在传统的Daugman式虹膜识别中，不同人的左右虹膜纹理被视为彼此完全不同，而同卵双胞胎的右眼和左眼或者同卵双胞胎的两眼被认为是稍微不同的。然而，已有研究表明，人类能以约80%的准确率识别两幅虹膜图像来自同一人的不同眼睛或者同卵双胞胎的眼睛。本研究旨在开发一种自动化分类器，以确定一对虹膜图像是否来自同卵双胞胎，解决生物识别领域的一项未解难题。为此，研究者利用Siamese网络架构和对比学习方法，将一对虹膜图像分为同卵或异卵两类。该研究还创建了一个数据集，其中包括同卵双胞胎的合成配对（同一个体的不同虹膜图像）和天然配对（来自同卵双胞胎不同个体的虹膜图像），以及非同卵配对的非同卵个体，确保模型具有全面的评估能力。
## Innovation
本研究利用Siamese网络架构和对比学习方法检测两幅虹膜图像是否来自动卵双胞胎，这是该领域首次采用自动化方法解决的问题。该方法有助于提供一位快速、无创的测试手段，用于确定双胞胎是同卵还是异卵。该研究还通过分析三种不同输入的模型变种学习到的表示，揭示了虹膜纹理和周围眼部结构信息对模型分类能力的重要性。
## Conclusion
研究使用整个虹膜图像的方法获得了超过人类分类同卵虹膜对的准确性，这表明该方法具有较高的识别精度和实用性。此方法为生物识别和双胞胎分类提供了新的解决方案。
# 379. `cs.CV` - 不是你，而是我——全球城市视觉感知在不同人口统计学特征和个性特征上存在差异 [PDF](https://arxiv.org/pdf/2505.12758), [HTML](https://arxiv.org/abs/2505.12758)
## Authors
Matias Quintana,Youlong Gu,Xiucheng Liang,Yujun Hou,Koichi Ito,Yihan Zhu,Mahmoud Abdelrahman,Filip Biljecki
## Background
理解人们对城市规划的需求和偏好至关重要，但现有的方法往往忽略了多文化和多城市人群中重要的人口差异，放大了偏见。作者通过全球范围内的街道景观街视图调查，探讨了人口统计学特征（包括性别、年龄、收入、教育水平、种族、民族以及首次纳入的人格特质）如何影响城市景观的感知，从中抽取了一个名为SPECS的数据集，展示了六个传统感知指标和四个新提出的指标在不同人群中表现出显著差异。此外，结果还表明，人们在对比不同城市街道景观时，会携带地理位置相关的感受，联想之前的体验。通过比较参与者来源地与街道景观来源地的感知评分，发现现有的机器学习模型在评估感知时存在偏差，更加夸大积极指标而低估消极指标。这表明，在城市规划中应考虑当地人的感知差异，重新审视街道感知的研究。
## Innovation
首次将人格特质纳入城市视觉感知调查，并基于街视图全球大规模调查数据集，分析不同人口特征对感知影响的差异。引入了一个名为SPECS的数据集，用于研究地点相关偏见和不同城市景观街道之间的感知差异。采用了一种非定制化的机器学习模型与人类反应进行对比，以突出机器学习模型在感知评估上的偏见问题。
## Conclusion
本研究意在纠正街道感知研究的短视现象，这些研究很少考虑人口统计学特征或人格特质。应该考虑当地人的感知差异，重新评估城市规划中对街道感知的传统观点。
# 380. `cs.CV` - VLLMs for Enhancing Emotion Recognition [PDF](https://arxiv.org/pdf/2504.17224), [HTML](https://arxiv.org/abs/2504.17224)
## Authors
Zhifeng Wang,Qixuan Zhang,Peter Zhang,Wenjia Niu,Kaihao Zhang,Ramesh Sankaranarayana,Sabrina Caldwell,Tom Gedeon
## Background
视觉大型语言模型（VLLMs）在多模态理解方面展现出巨大潜力，但在基于视频的情绪识别应用中受到了限制，主要因为它们的空间和上下文感知不足。传统的单一面部特征优先方法往往忽视了重要的非言语线索，如身体语言、环境背景和人际互动，这些因素导致了在实际场景中的鲁棒性较差。现有视觉提示方法在这方面也存在不足，无法有效整合时空信息和上下文线索以增强情绪识别的准确性。
## Innovation
本文提出了一种新颖的框架——Set-of-Vision-Text Prompting（SoVTP），该框架通过将空间标注（如边界框、面部特征点）、生理信号（面部动作单元）和上下文提示（如身体姿态、场景动态、他人的表情）统一融入提示策略，增强了零样本情绪识别的性能。SoVTP 能够保留场景的整体信息，并实现对面部肌肉运动和人际动态的精细分析。实验结果表明，SoVTP 在增强 VLLMs 的视频情绪识别能力方面取得了显著进步，优于现有的视觉提示方法。
## Conclusion
广泛的实验表明，SoVTP 在提升 VLLMs 的视频情绪识别能力方面取得了显著进步，证实了其在增强多模态情绪识别中的有效性。
# 381. `cs.CV` - PanoWan: 通过纬度/经度感知机制将扩散视频生成模型提升至360° [PDF](https://arxiv.org/pdf/2505.22016), [HTML](https://arxiv.org/abs/2505.22016)
## Authors
Yifei Xia,Shuchen Weng,Siqi Yang,Jingqi Liu,Chengxuan Zhu,Minggui Teng,Zijian Jia,Han Jiang,Boxin Shi
## Background
全景视频生成能够创建沉浸式的360°内容，适用于需要场景一致性世界探索的应用。然而，现有的全景视频生成模型难以利用从传统文本到视频模型预训练的生成先验，生成高质量和多样化的全景视频，这是因为数据集规模有限和空间特征表示之间的差距。
## Innovation
本文引入了PanoWan，一种能够有效提升预训练文本到视频模型到全景域的模型。PanoWan 使用纬度感知采样来避免纬向失真，并通过旋转语义去噪和填充像素级解码确保经度边界处的平滑过渡。
## Conclusion
通过贡献PanoVid，一个高质量的带有字幕和多样场景的全景视频数据集，PanoWan 在全景视频生成中实现了最先进的性能，并在零样本下游任务中表现出鲁棒性。
# 382. `cs.CV` - TT3D: Table Tennis 3D Reconstruction [PDF](https://arxiv.org/pdf/2504.10035), [HTML](https://arxiv.org/abs/2504.10035)
## Authors
Thomas Gossard,Andreas Ziegler,Andreas Zell
## Background
体育分析需要处理大量数据，这既耗费时间又成本高昂。神经网络的进步已经显著减轻了这一负担，使运动转播中的球跟踪变得高度准确。然而，仅依赖2D球跟踪是有限的，因为它依赖于摄像机的角度，无法支持全面的赛事分析。为了解决这个问题，我们提出了一种新颖的方法，用于从在线乒乓球比赛录像中重建精确的3D球轨迹。我们的方法利用球运动的基本物理原理，确定使球飞行轨迹再投影误差最小的反弹状态，以确保准确可靠的3D重建。我们方法的一个关键优势是能够推断球的旋转状态而不依赖于人类姿势估计或球拍追踪，这在广播镜头中通常是不可靠或无法实现的。我们开发了一种自动摄像机校准方法，能够可靠地跟踪摄像机的移动。此外，我们将一个现有的3D姿势估计模型（缺乏深度运动捕捉）调整为准确跟踪球员动作。这些贡献使得可以完全重建乒乓球比赛的3D场景。
## Innovation
提出了一种新颖的3D球轨迹重建方法，可以从在线乒乓球比赛录像中重建精确的3D轨迹。该方法利用球运动的基本物理原理来确定使球飞行轨迹再投影误差最小的反弹状态，从而实现准确可靠的3D重建。这种方法能够推断球的旋转状态，而无需依赖人类姿势估计或球拍追踪。还开发了一种自动摄像机校准方法，能够可靠地跟踪摄像机的移动，并将一个现有的3D姿势估计模型调整为准确跟踪球员动作。
## Conclusion
结合这些贡献，可以完全重建乒乓球比赛的3D场景。这种方法不仅提高了精度和可靠性，还简化了分析流程，为全面的赛事分析提供了可能。
# 383. `cs.CV` - WoundAmbit: 状态最前沿语义分割与实际伤口护理的桥梁 [PDF](https://arxiv.org/pdf/2504.06185), [HTML](https://arxiv.org/abs/2504.06185)
## Authors
Vanessa Borst,Timo Dittus,Tassilo Dege,Astrid Schmieder,Samuel Kounev
## Background
慢性伤口影响着大量的人群，尤其是老年人和糖尿病患者。这些人常常有行动不便和共存的健康问题。通过移动图像捕获进行自动伤口监测可以减少亲自访问医生的次数，使医生能够远程跟踪伤口的大小。语义分割对这一过程至关重要，但伤口分割在医学影像研究中的代表性仍然不足。文章提出了一个基准测试，将通用视觉领域的先进深度学习模型、医学影像领域的方法以及公共伤口挑战中的顶级方法进行对比。为了公平比较，标准化了训练、数据增强和评估方式，并采用交叉验证来减少分区偏差。同时，还评估了模型在实际应用中的方面，如对异构伤口数据集的泛化能力、计算效率和可解释性。此外，还提出了一种基于参考对象的方法，将AI生成的掩膜转化为临床相关伤口大小估计，并对这一方法及其质量进行了评估。总体而言，基于变形者的TransNeXt在泛化性方面表现最佳。尽管推理时间存在差异，但所有模型在CPU上每秒至少处理一张图像，这被认为符合预期应用的需求。可解释性分析通常揭示了在伤口区域占主导的激活，强调了对临床相关特征的关注。专家评估表明，所有分析模型的掩膜被高度批准，其中VWFormer和ConvNeXtS骨干表现最佳。大小检索的准确性在各模型间相似，预测结果与专家标注紧密匹配。最后，展示了如何将我们的AI驱动的伤口大小估计框架WoundAmbit集成到自定义远程医疗系统中。
## Innovation
文章创新性地全面比较了不同领域的先进深度学习模型，并提出了一个基于参考对象的方法将AI生成的掩膜转化为临床相关伤口大小估计。还评估了模型在实际应用中的泛化能力和计算效率，并展示了将AI驱动的伤口大小估计框架WoundAmbit集成到自定义远程医疗系统中。
## Conclusion
基于变形者的TransNeXt在泛化性和准确性方面表现最佳，所有模型在计算效率方面都能满足实际应用需求，某些模型在可解释性和专家评价方面表现突出。最终，WoundAmbit框架成功地将AI驱动的伤口大小估计与远程医疗服务集成，为慢性伤口患者的护理提供了新的解决方案。
# 384. `cs.CV` - ViStoryBench: 完备的故事可视化基准套件 [PDF](https://arxiv.org/pdf/2505.24862), [HTML](https://arxiv.org/abs/2505.24862)
## Authors
Cailin Zhuang,Ailin Huang,Wei Cheng,Jingwei Wu,Yaoqi Hu,Jiaqi Liao,Zhewei Huang,Hongyuan Wang,Xinyao Liao,Weiwei Cai,Hengyuan Xu,Xuanyang Zhang,Xianfang Zeng,Gang Yu,Chi Zhang
## Background
无剧本可视化旨在生成与给定叙事和参考图像一致的视觉连贯图像，最近生成模型的进步使其取得了显著进展。然而，为了在真实场景中进一步提高故事可视化框架的性能，需要一个全面的评估基准。因此，我们引入了ViStoryBench，这是一个涵盖不同故事类型和艺术风格的多样数据集，以多维度评估模型，包括不同的剧情（如喜剧、恐怖）和视觉美学（如动漫、3D渲染）。此外，该基准还包含具有单个和多个主角的故事，以测试模型保持角色一致性的能力，并包括复杂的剧情和细致的世界构建，以挑战模型生成准确图像的能力。
## Innovation
我们构建了一个名为ViStoryBench的基准套件，这是一个全面且多维度的评估框架，能够平衡叙事结构和视觉元素，适合不同类型的主角和复杂的剧情。它包含多种评价指标，确保研究人员可以全面比较不同模型的优缺点，从而促进有针对性的改进。
## Conclusion
通过这个结构化且多维度的基准则，研究者可以深入识别各种模型的优势和不足之处，从而促进其具体改进。
# 385. `cs.CV` - VIDEORFT:通过强化调优激励MLLMs的视频推理能力 [PDF](https://arxiv.org/pdf/2505.12434), [HTML](https://arxiv.org/abs/2505.12434)
## Authors
Qi Wang,Yanrui Yu,Ye Yuan,Rui Mao,Tianfei Zhou
## Background
强化调优（RFT）在提升大型语言模型（LLM）的类人推理能力方面显示出了巨大的潜力，最近也被扩展到多模态LLM（MLLMs）。然而，由于视频数据中固有的复杂逻辑、时间性和因果结构，基于视频的推理仍然是一个持续的挑战。为了解决这一问题，本文提出了一种新的方法——VIDEORFT，它将RFT范式扩展到多模态LLM，以培养它们的类人视频推理能力。
## Innovation
该方法引入了一个完全自动的认知启发式提示策略，用于生成视频内容的初步推理解释（CoTs），并通过视觉语言模型进行修订，以确保视觉一致性并减少视觉幻觉。此外，还引入了一种新的语义一致性奖励，旨在明确促进文本推理与视觉证据之间的对齐。这种方法能够在六个视频推理基准测试中取得最先进的性能。
## Conclusion
VIDEORFT通过解决视频推理领域的大规模高质量视频CoT数据稀缺问题，并通过引入认知启发式提示策略和新的语义一致性奖励，成功地增强了多模态LLM的视频推理能力，并在多个基准测试中取得了最优性能。
# 386. `cs.CV` - 4D运动建模通过图像到视频合成的时空差分场 [PDF](https://arxiv.org/pdf/2505.17333), [HTML](https://arxiv.org/abs/2505.17333)
## Authors
Xin You,Minghui Zhang,Hanxiao Zhang,Jie Yang,Nassir Navab
## Background
在基于成像的临床应用中，定期呼吸引起的运动的空间建模至关重要。现有的方法无法模拟这些运动，除非同时存在开始和结束帧的高剂量成像扫描。但在预操作的数据获取阶段，患者可能会有轻微的移动，导致呼吸周期中的第一帧和最后一帧之间出现动态背景差异，这种差异难以通过图像配准消除，从而影响了时间建模的效果。
## Innovation
本文提出了通过图像到视频（I2V）合成框架模拟定期运动过程的新方法，通过使用第一帧来预测给定长度的未来帧，以动画的形式展现。此外，为了提高动画视频的时间一致性，提出了一种时空差分扩散模型来生成时空差分场，这些差分场衡量相邻帧之间的相对差异表示，并设计了一种注意机制来细化这些差分场，并通过增强层将这些场与I2V框架更好地结合，提升了合成视频的时间变化准确度。
## Conclusion
在ACDC心脏和4D肺部数据集的大量实验中，证明了本文方法能够沿原始运动轨迹生成4D视频，并在感知相似性和时间一致性方面与竞争方法相当。该代码不久将公开发布。
# 387. `cs.CV` - TIIF-Bench: 如何评估您的文本到图像模型遵循您的指令？ [PDF](https://arxiv.org/pdf/2506.02161), [HTML](https://arxiv.org/abs/2506.02161)
## Authors
Xinyu Wei,Jinrui Zhang,Zeqing Wang,Hongyang Wei,Zhen Guo,Lei Zhang
## Background
文本到图像（T2I）模型的快速发展开启了AI生成内容的新阶段，模型逐渐具备了理解和遵循用户指令的能力。然而，现有的模型评估基准由于指令多样性不足、复杂度低以及粗略的评估指标，难以衡量文本指令与生成图像之间的精细对齐性能。
## Innovation
本文介绍了TIIF-Bench（文本到图像指令遵循基准），旨在系统地评估T2I模型在理解和遵循复杂文本指令方面的能力。基准包括5000个沿多个维度组织的提示，分为三个难度等级。为了严格评估模型对不同长度指令的鲁棒性，每个提示提供短版和长版，保持核心语义一致。引入了文本呈现和风格控制两个关键属性来评估文本合成的精度和T2I模型的审美一致性。此外，它收集了一百个高质量的设计级别提示，涵盖多种场景，全面评估模型性能。通过在TIIF-Bench上细致评估主流的T2I模型，分析了当前模型的优势和不足，并揭示了当前T2I基准的局限性。
## Conclusion
利用大型视觉语言模型中编码的世界知识，提出了一种新的可计算框架来分辨T2I模型输出中的细微差异。通过在TIIF-Bench上细致评估主要的T2I模型，分析了当前T2I模型的优点和缺点，并揭示了当前T2I基准的局限性。
# 388. `cs.CV` - 基于暗通道的单图像深度-失焦推演 [PDF](https://arxiv.org/pdf/2506.06643), [HTML](https://arxiv.org/abs/2506.06643)
## Authors
Moushumi Medhi,Rajiv Ranjan Sahay
## Background
传统的深度-失焦（DFD）方法依赖多张不同焦距的图像作为输入，但由于单张失焦图像的数据限制，这种方法的研究较少。本文提出了一种使用暗通道作为补充线索的方法，通过捕捉局部统计和场景结构来从单张失焦图像中估计场景深度。这种方法利用了局部失焦模糊与对比变化之间的关系作为深度线索，以改进场景结构的估计。
## Innovation
本文提出了一个端到端训练的深度学习管道，利用暗通道先验信息进行单图像深度-失焦推演，并使用对抗学习进行训练。这种方法有效地克服了传统方法的不足，能够提供有意义的深度估计结果。
## Conclusion
实验结果表明，将暗通道先验引入单图像深度-失焦推演中可以提供有实际意义的深度估计，验证了本文方法的有效性。
# 389. `cs.CV` - C3S3: 补充竞争和对比选择在半监督医疗图像分割中的应用 [PDF](https://arxiv.org/pdf/2506.07368), [HTML](https://arxiv.org/abs/2506.07368)
## Authors
Jiaying He,Yitong Lin,Jiahe Chen,Honghui Xu,Jianwei Zheng
## Background
在医疗领域，标注样本不足构成了一大挑战。现有的半监督医疗图像分割方法虽然在界定主要目标区域方面取得了令人印象深刻的结果，但往往难以精确捕捉边界细节，这可能导致诊断不准确。本文旨在解决这一问题，通过引入C3S3模型，它是一种结合互补竞争和对比选择的新颖半监督分割模型，显著提升了边界界定的清晰度和整体精度。
## Innovation
本文的创新在于提出了C3S3模型，该模型通过 Outcome-Driven Contrastive Learning 模块和 Dynamic Complementary Competition 模块进行开发。Outcome-Driven Contrastive Learning 模块旨在细化边界定位，而 Dynamic Complementary Competition 模块则利用两个高性能的子网络生成伪标签，从而进一步提高分割质量。该模型在两个公开数据集（涵盖MRI和CT扫描的实践）上进行了严格的验证，结果显示，该方法在多个性能指标上优于当前最先进的竞争对手，尤其是在95HD和ASD指标上提高了至少6%，显示出显著的进步。
## Conclusion
本文提出的C3S3模型在半监督医疗图像分割上表现出优异性能，尤其是在95HD和ASD指标上实现了显著的性能提升。代码已开源，供进一步研究使用。
# 390. `cs.CV` - ZigzagPointMamba：点云理解中的空间-语义斑马 [PDF](https://arxiv.org/pdf/2505.21381), [HTML](https://arxiv.org/abs/2505.21381)
## Authors
Linshuang Diao,Dayong Ren,Sensen Song,Yurong Qian
## Background
现有的点云自我监督学习方法，如点Mamba（PointMamba），虽然能够在点云自监督学习中高效提取特征并具有线性复杂度，但在计算效率上优于变换器（Transformers），但它们依赖复杂的标记顺序和随机掩码，这些方法破坏了空间连续性和局部语义相关性，导致性能提升受限。因此，需要提出一种新的方法来解决这个问题，以提高点云自我监督学习中的空间连续性和语义相关性，从而提高整体模型性能和下游任务的准确性。
## Innovation
本文提出了ZigzagPointMamba，它采用了一个简单的Z字形扫描路径来全局顺序排列点云标记，增强了空间连续性，同时通过引入语义双胞胎掩码策略（Semantic-Siamese Masking Strategy, SMS），解决了随机掩码对局部语义建模的破坏性影响。SMS可以隐藏语义相似的标记以促进重建，从而整合原始标记和相似标记的局部特征，这有助于克服仅依赖孤立局部特征的问题，实现了更强大的全局语义建模。
## Conclusion
预训练的ZigzagPointMamba显著提升了一系列下游任务的性能，包括在ShapeNetPart中的部分分割任务中获得了1.59%的mIoU增益，在ModelNet40的分类任务中高出0.4%，在ScanObjectNN的OBJ-BG、OBJ-ONLY和PB-T50-RS子集上分类准确率分别提高0.19%、1.22%和0.72%。
# 391. `cs.CV` - 跨帧表示对齐用于细调视频扩散模型 [PDF](https://arxiv.org/pdf/2506.09229), [HTML](https://arxiv.org/abs/2506.09229)
## Authors
Sungwon Hwang,Hyojin Jang,Kinam Kim,Minho Park,Jaegul Choo
## Background
在用户级别对视频扩散模型（VDMs）进行微调以生成反映训练数据特定属性的视频，尽管具有显著挑战性，但这一领域目前尚未得到充分探索。尽管如此，如Representation Alignment (REPA)等研究为图像扩散模型（DiT）的收敛和质量提升提供了改进，暗示了其在VDM微调中的潜在应用价值。然而，REPA在保持帧间语义一致性方面效果不佳.
## Innovation
本文提出了一种新颖的正则化技术Cross-frame Representation Alignment (CREPA)，通过使当前帧的隐藏状态与相邻帧的外部特征对齐，从而改善了有效的收敛性。实验结果表明，CREPA在使用参数高效方法（如LoRA）微调时，提高了视觉保真度和跨帧语义一致性.
## Conclusion
CREPA在多种具有不同属性的视频数据集上得到了验证，表明其广泛适用性。此外，跨帧表示对齐技术显著改进了视频扩散模型的微调效果，增强了视频生成的语义连贯性和视觉真实感.
# 392. `cs.CV` - BeltCrack:首个序贯图像工业输送带裂纹检测数据集及其三域特征学习基线 [PDF](https://arxiv.org/pdf/2506.17892), [HTML](https://arxiv.org/abs/2506.17892)
## Authors
Jianghong Huang,Luping Ji,Xin Ma,Mao Ye
## Background
输送带在现代工业中是一种重要的机械设备，在生产和制造过程中广泛应用。其健康状况对操作效率和安全性至关重要。裂缝是输送带健康的主要威胁之一。目前，从安全角度考虑，如何智能检测裂缝越来越受到关注。尽管使用机器学习进行智能检测需要真实的裂缝样本，但现有的裂缝数据集主要集中在道路场景或合成数据上，而不包含实际工业输送带裂缝数据集。因此，本文提出了首个序贯图像工业输送带裂纹检测数据集，并提出了一种基于三域特征层次融合学习的特殊基线方法来验证其实用性和有效性。实验结果证明了数据集的有效性和可用性，并显示了该基线方法明显优于其他类似检测方法。
## Innovation
本文的创新之处在于提出了首个包含真实工业输送带裂缝样本的数据集——BeltCrack，同时提出了基于三域特征层次融合学习的基线方法进行裂缝检测。这种方法可以有效提高检测的准确性和可靠性，并填补了现有裂缝检测数据集的空白。
## Conclusion
本文创建的BeltCrack数据集和基于三域特征学习的基线方法实验结果表明，该数据集和方法的有效性和实用性得到了验证。此外，我们的方法明显优于其他类似检测方法。相关数据集和源代码已发布在指定链接。
# 393. `cs.CV` - PP-DocBee2：提高基准模型效果与高效数据支持的多模态文档理解 [PDF](https://arxiv.org/pdf/2506.18023), [HTML](https://arxiv.org/abs/2506.18023)
## Authors
Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu
## Background
PP-DocBee2 是 PP-DocBee 的高级版本，旨在提升多模态文档理解的能力。它基于大规模的多模态模型架构，解决了前一代产品的局限性，如通过提高合成数据质量、改进视觉特征融合策略及优化推理方法等关键技术改进。这些升级在针对中文商业文档的内部基准测试中的性能提高了11.4%，同时将推理延迟降低了73.0%。
## Innovation
本文的一个关键创新是提出了一种用于多模态文档任务的数据质量优化策略。这种方法利用大规模多模态预训练模型评估数据集，并采用新型统计标准过滤异常值，从而确保高质量的训练数据。此外，通过分解ViT并应用新颖的特征融合策略，增强了中间特征的利用，以改进复杂推理能力。
## Conclusion
PP-DocBee2 通过一系列强化技术，显著提高了多模态文档的理解能力，并降低了推理延迟。该研究的源代码和预训练模型可在线获取。
# 394. `cs.CV` - CLAIM: 集临床指导的LGE增强以实现真实的以及多样化的心肌疤痕合成及分割 [PDF](https://arxiv.org/pdf/2506.15549), [HTML](https://arxiv.org/abs/2506.15549)
## Authors
Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen Chen
## Background
基于深度学习的心肌疤痕分割技术（通过对延迟钆增强心血管磁共振成像LGE图像的处理）对于结构性心脏疾病的准确和及时诊断及治疗规划方面具有巨大潜力。然而，高质量疤痕标签的可用性和变化性限制了鲁棒分割模型的发展。因此，尽管LGE图像对于心肌疤痕分析至关重要，但其有限性和多变性成为瓶颈问题，需要开发出能有效生成和分割心肌疤痕的创新框架来克服这一技术障碍。
## Innovation
提出了CLAIM框架：基于临床指导的心肌疤痕生成与分割框架。该框架的核心是SMILE模块（根据临床知识指导的心肌疤痕掩模生成），该模块利用扩散生成模型并结合临床采用的AHA 17区段模型来合成具有解剖上一致和空间上多样化的疤痕模式的图像。此外，CLAIM还采用了一种联合训练策略，即同时优化疤痕分割网络和生成器，旨在提高合成疤痕的真实性和疤痕分割的准确性。实验结果表明，CLAIM生成了解剖上一致的疤痕模式，并且与基础模型相比，其分割的心肌疤痕与真实分布的相似度更高。
## Conclusion
该方法使心肌疤痕合成可控并且逼真，具有潜在的应用价值，能够服务于下游医学影像任务。相关代码可以在以下链接获取：this https URL。
# 395. `cs.CV` - OmniGen2：探索高级多模态生成 [PDF](https://arxiv.org/pdf/2506.18871), [HTML](https://arxiv.org/abs/2506.18871)
## Authors
Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu
## Background
本文介绍了OmniGen2，这是一种多功能和开源的生成模型，旨在提供统一的解决方案，可用于文本转图像、图像编辑和上下文生成等多种任务。与OmniGen v1相比，OmniGen2采用了两个独立的解码路径，分别用于文本和图像模态，且不共享参数，同时也使用了一个独立的图像分词器。这一设计使OmniGen2能够在保留原始文本生成能力的同时，基于现有的多模态理解模型进行扩展。为了支持OmniGen2的训练，论文开发了一整套数据构造管道，涵盖图像编辑和上下文生成的数据。研究者还引入了一种针对图像生成任务的反射机制并基于OmniGen2构建了一个专用的反射数据集。尽管参数规模相对较小，但OmniGen2在多个任务基准测试中表现竞争，包括文本转图像和图像编辑。为了进一步评估上下文生成，即主题驱动任务，研究者引入了一种新的基准测试OmniContext，OmniGen2在开放源代码模型中实现了最先进的表现，特别是在一致性方面。研究成果将提供模型、训练代码、数据集和数据构建管道以支持未来在此领域的研究。
## Innovation
OmniGen2的主要创新在于采用了两个独立的解码路径，不共享参数，并使用独立的图像分词器，这使得OmniGen2能够在保留现有模型文本生成能力的同时，扩展到多模态理解。此外，研究者开发了一整套数据构造管道，并引入了专门针对图像生成任务的反射机制和数据集，这有助于更好地评估上下文生成的表现。
## Conclusion
尽管OmniGen2的模型参数相对较小，但在多个任务基准测试中表现抢眼，特别是在Text-to-Image和Image Editing方面。此外，引入OmniContext作为新的基准测试，展示了OmniGen2在一致性方面的卓越表现。最终，研究者将开源模型、训练代码、数据集和数据构造管道，以支持未来的研究工作。
# 396. `cs.CV` - VLN-R1: 视觉-语言导航通过强化微调实现 [PDF](https://arxiv.org/pdf/2506.17221), [HTML](https://arxiv.org/abs/2506.17221)
## Authors
Zhangyang Qi,Zhixiong Zhang,Yizhou Yu,Jiaqi Wang,Hengshuang Zhao
## Background
在嵌入式人工智能中，视觉-语言导航（VLN）是一个核心挑战，要求代理以自然语言指令的方式导航到实际环境中的目标位置。当前的语言模型导航系统依赖于离散的拓扑图进行路径规划，这使得路径规划局限于预先定义的节点连接。本文进一步探讨了这一问题并提出了解决方案。
## Innovation
本文提出了VLN-R1，这是一个端到端框架，利用大型视觉-语言模型（LVLM）直接将第一人称视频流转化为连续的导航动作，采用了类似于DeepSeek-R1的基于GRPO的训练方法。为了有效训练，作者使用3D模拟器Habitat构建了VLN-Ego数据集，并提出了长期短期记忆采样方法以平衡历史和当前观察。此外，该框架采用了两阶段的微调方法：首先进行监督微调（SFT）使模型的行动序列文本预测与专家演示对齐，然后进行增强型奖励衰减机制（TDR）的强化微调（RFT），以有策略地加权多步未来的动作。这提高了模型行动预测的准确性，最终通过强化学习机制提高了模型的导航性能。
## Conclusion
实验结果表明，VLN-R1在VLN-CE基准测试中取得了优异的成绩。VLN-R1验证了大型视觉-语言模型能够驱动嵌入式导航并提升任务相关的推理能力，同时通过数据驱动的、奖励驱动的后训练提高了模型的效率。
# 397. `cs.CV` - 自监督多模态NeRF在自动驾驶中的应用 [PDF](https://arxiv.org/pdf/2506.19615), [HTML](https://arxiv.org/abs/2506.19615)
## Authors
Gaurav Sharma,Ravi Kothari,Josef Schmid
## Background
本文提出了一种基于神经辐射场（NeRF）的新型视图合成框架（NVSF），能够联合学习空间和随时间变化的场景表示。该框架测试在包含静态和动态场景的实际自动驾驶环境中，相比现有的多模态动态NeRF，该框架为自我监督，从而消除了对3D标签的需求。为了提高训练效率和加速收敛，作者引入了基于启发式的图像像素采样方法，专注于含有丰富信息的像素。为了保留LiDAR点的局部特征，作者采用了双重梯度掩码。在KITTI-360数据集上进行的大量实验表明，该框架在LiDAR和相机域上均达到了最先进的性能水平。
## Innovation
该框架为自我监督，消除对3D标签的需求；采用基于启发式的图像像素采样方法和双重梯度掩码以提高效率和精度；在包含静态和动态场景的实际自动驾驶环境中进行测试并取得了最佳性能。
## Conclusion
相比基线模型，NVSF框架在LiDAR和相机域上均表现最佳。框架的代码可公开获取。
# 398. `cs.CV` - 通过注意力头选择进行精细粒度的扰动指导 [PDF](https://arxiv.org/pdf/2506.10978), [HTML](https://arxiv.org/abs/2506.10978)
## Authors
Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim
## Background
近年来，指导方法在扩散模型中通过扰动模型来构建一个隐式的弱模型，并引导生成远离该模型的方向以反向采样。在这些方法中，注意力扰动在无需分类器自由引导的情况下，在无条件场景中表现出强大的实验性能。然而，现有的注意力扰动方法缺乏确定何时应用扰动的原理性方法，特别是在Diffusion Transformer (DiT) 架构中，质量相关的计算分布在各个层中。因此，本论文探讨了注意力扰动的粒度范围，从层级别细化到单个注意力头级别，发现特定的头控制不同的视觉概念，如结构、风格和纹理质量。基于这一洞察，作者提出了一种名为HeadHunter的系统框架，用于迭代选择与用户为中心的目标相一致的注意力头，以实现生成质量和视觉属性的细粒度控制。此外，引入了SoftPAG，通过将选择的头的注意图线性插值到单位矩阵，提供了一个连续的旋钮来调整扰动强度并抑制伪影。本方法不仅缓解了现有层级扰动导致的过度平滑问题，还通过组成头选择实现了特定视觉风格的定向操控。该方法在现代大型DiT基文本到图像模型（包括Stable Diffusion 3和FLUX.1）上进行了验证，展示了在一般质量提升和风格特定指导方面的优越性能。本研究提供了在扩散模型中对注意力扰动的首次头级别分析，揭示了注意力层中的可解释专门化，并使有效的扰动策略的实际设计成为可能。
## Innovation
提出了HeadHunter框架，可以在单个注意力头级别选择与用户为中心的目标相一致的头，实现生成质量和视觉属性的细粒度控制。引入了SoftPAG，通过将选定头的注意力图线性插值到单位矩阵，提供了一个连续的旋钮来调整扰动强度并抑制伪影。该方法不仅缓解了现有层级扰动导致的过度平滑问题，还通过组成头选择实现了特定视觉风格的定向操控。
## Conclusion
通过首次在扩散模型中进行头级别的分析，揭示了注意力层中的可解释专门化，并使有效的扰动策略的实际设计成为可能，验证了在现代大型DiT基文本到图像模型上展示了本方法在一般质量提升和风格特定指导方面的优越性能。
# 399. `cs.CV` - 单一原型就足够：单原型激活的可解释图像分类 [PDF](https://arxiv.org/pdf/2506.19808), [HTML](https://arxiv.org/abs/2506.19808)
## Authors
Yitao Peng,Lianghua He,Die Hu
## Background
现有的原型网络通常依赖多个原型的协作决策来实现单个类别的分类和解释。然而，这增加了认知复杂性。本文提出了一种新的深度神经架构ProtoSolo，只需激活单个原型即可完成分类，这使得网络可以通过提供最相似于该类原型特征的方式来解释每个类别决策，大大降低了解释的认知复杂性。此外，该方法使用特征图而非全通道特征向量进行相似性比较和原型学习，从而使ProtoSolo能够在依赖单一原型激活的情况下利用更丰富的全局信息进行分类。此外，提出了一种非原型投影学习策略，该策略在保留原型与训练图像块之间的信息关联的同时，避免了投影操作引起的网络结构突变，从而避免了其对分类性能的负面影响。这些改进使得ProtoSolo在CUB-200-2011和斯坦福汽车数据集上的分类任务中表现出优异的表现，并在解释的认知复杂性方面达到了最先进的水平。
## Innovation
1. 允许通过单个原型激活完成分类，减少认知复杂性；2. 使用特征图而非全通道特征向量进行相似性比较和原型学习，充分利用全局信息；3. 提出的非原型投影学习策略既保留了原型与图像块之间的信息关联，又避免了结构突变的负面影响；4. 在分类任务中表现出色，并在解释的复杂性方面优于现有方法。
## Conclusion
实验结果表明，ProtoSolo在CUB-200-2011和斯坦福汽车数据集上的分类任务中表现优异，并在解释的认知复杂性方面达到了最先进的水平。
# 400. `cs.CV` - EvDetMAV: 来自移动事件摄像头的MAV通用检测 [PDF](https://arxiv.org/pdf/2506.19416), [HTML](https://arxiv.org/abs/2506.19416)
## Authors
Yin Zhang,Zian Ning,Xiaoyu Zhang,Shiliang Guo,Peidong Liu,Shiyu Zhao
## Background
现有的微型飞行器（MAV）检测方法主要依赖于RGB图像中的目标外观特征，而这些特征的多样性使得通用化检测变得困难。我们注意到，不同类型的MAV在其事件流中共享独特的特征，因为它们的高速旋转螺旋桨在RGB图像中难以辨认。本文研究如何通过充分利用原始事件流中的螺旋桨特征来检测不同类型的MAV，同时过滤背景物体和相机运动带来的噪声。由于没有现成的基于事件的MAV数据集，本文引入了一个新的MAV数据集供社区使用。
## Innovation
提出了一个包含三个模块的方法来提取螺旋桨的显着和时空特征，同时过滤背景物体和相机运动的噪声。此外，没有经过训练，相比现有的最先进的方法，该方法在提出的测试数据集上显著提高了精度率（83.0%，+30.3%）和召回率（81.5%，+36.4%），并能处理复杂的场景。这是首个包含多种场景和不同类型MAV的基于事件的MAV数据集，为社区提供数据集和代码。
## Conclusion
本文通过提出的方法和基于事件的MAV数据集，在未经过训练的情况下，实现了对不同类型MAV的通用检测，显著提高了精度率和召回率，解决了现有检测方法在多样性和复杂场景下的局限性问题。
# 401. `cs.CV` - 边界框水印: 避免目标检测模型提取攻击的防御方法 [PDF](https://arxiv.org/pdf/2411.13047), [HTML](https://arxiv.org/abs/2411.13047)
## Authors
Satoru Koda,Ikuya Morikawa
## Background
在云中部署的深度神经网络（DNNs）通常通过API允许用户查询模型。然而，这些API使模型面临模型提取攻击（MEAs）的风险。在这些攻击中，攻击者试图通过滥用API响应来复制目标模型。已有的针对OD模型的后门攻击不适用于防止MEAs，特别是针对真实威胁模型的情况。本文提出了一种通过API将后门隐蔽地插入到提取模型中的边界框水印方法，这种方法可以在不影响OD能力的情况下识别提取模型，从而有效保护模型不被非法复制。
## Innovation
该研究提出了一种新颖的边界框水印技术，通过在API响应中隐蔽地修改边界框（BBs）来注入后门。这种方法可以在不影响对象检测能力的前提下，有效地识别出非法提取的模型，增强模型的安全性。这一创新方法特别适用于目标检测模型，能够显著提高模型的防护能力，防止模型提取攻击。
## Conclusion
在对三个目标检测数据集的实验中，所提出的方法成功以100%的准确性在各种实验场景中识别出非法提取的模型。这种方法为预防基于API的目标检测模型提取攻击提供了一种有效的解决方案。
# 402. `cs.CV` - 预测建模、模式识别和模拟及受控环境下植物生长的空间时间表示：综合综述 [PDF](https://arxiv.org/pdf/2412.10538), [HTML](https://arxiv.org/abs/2412.10538)
## Authors
Mohamed Debbagh,Shangpeng Sun,Mark Lefsrud
## Background
准确预测和表征植物生长模式对于解决植物粒型学研究中的各种挑战至关重要。本综述探讨了最新的预测模式识别技术在模拟和控制环境中的应用，重点关注植物性状的空间时间建模和动态环境交互的整合。综述涵盖了确定性、概率性和生成性建模方法，并强调其在高通量粒型学和基于模拟的植物生长预测中的应用
## Innovation
提供了2D和3D结构化数据表示通过功能性结构植物模型和条件生成模型的进展调研，并讨论了将领域特定知识集成到数据驱动方法、改进可用数据集以及将这些技术应用于实际应用的机会；强调现有基于实验的确定性方法的局限性，并指出需要引入动态框架以考虑不确定性及其逐步变化的环境反馈
## Conclusion
本文综述了预测建模、模式识别及模拟和受控环境中植物生长的空间时间表示方法，涵盖了从确定性到生成性建模的各种方法，并指出了未来研究中如何将领域特定知识与数据分析方法相结合、改进数据集以推动这些技术的实际应用发展的方向
# 403. `cs.CV` - 采样在解释中的重要性：通过最大化解释准确性在视觉模型中构建值得信赖的归因分析构建块 [PDF](https://arxiv.org/pdf/2506.19442), [HTML](https://arxiv.org/abs/2506.19442)
## Authors
Róisín Luo,James McDermott,Colm O'Riordan
## Background
归因分析旨在突出显示视觉模型学习的特征表示，使得突出的特征图能够反映输入的像素级重要性。梯度积分是归因分析中的一个基本构建块，通过整合多个衍生样本的梯度来突出与推断相关的语义特征。这种构建块通常与其他来自视觉模型的信息（如激活或注意力图）结合使用，形成最终解释。然而，理论分析表明，梯度积分中样本分布与自然图像分布的对齐程度给出了解释确定性的下限。现有工作在图像中添加噪声作为样本，噪声分布可能导致低确定性的解释。出乎意料的是，实验表明额外信息可能会饱和神经网络。因此，建立值得信赖的归因分析需要解决样本分布错配问题。而不是在输入图像中添加额外信息，我们提出了一种半最优的采样方法，通过抑制输入特征来构建样本分布。这样做可能使样本分布与自然图像分布大致相同。在大规模数据集ImageNet上的广泛定量评估证实了我们的方法的有效性，并能够在所有实验模型中更好地获得满意的解释。
## Innovation
提出了一种半最优的采样方法，通过抑制输入特征构建样本分布，使得样本分布与自然图像分布大致相同，从而解决了样本分布错配问题，提高了归因分析的可靠性。这种方法旨在通过最大化解释确定性来构建可视模型中值得信赖的归因分析构建块。这种方法与现有工作（在图像中添加噪声作为样本）形成对比，不仅能提高解释准确性，还能避免额外信息的饱和问题。
## Conclusion
通过采用半优化的采样技术，抑制输入特征来接近自然图像分布，可以有效地提高归因分析的准确性。在大规模数据集ImageNet上的实验证明了这种新的采样方法的有效性，并能提供比最先进的基线更令人满意的解释。该研究为构建更可靠和准确的归因分析模型提供了新的视角和方法。
# 404. `cs.CV` - Mamba 政策：迈向高效混合选择性状态模型的 3D 扩散策略 [PDF](https://arxiv.org/pdf/2409.07163), [HTML](https://arxiv.org/abs/2409.07163)
## Authors
Jiahang Cao,Qiang Zhang,Jingkai Sun,Jiaxu Wang,Hao Cheng,Yulin Li,Jun Ma,Kun Wu,Zhiyuan Xu,Yecheng Shao,Wen Zhao,Gang Han,Yijie Guo,Renjing Xu
## Background
扩散模型在3D操作领域得到了广泛应用，因为它们能够高效地学习分布并精确预测动作轨迹。然而，扩散模型通常依赖于大的参数UNet骨干网络作为策略网络，在资源受限设备上部署具有挑战性。近年来，Mamba模型作为一种高效建模方案崭露头角，它不仅计算复杂度低，而且在序列建模方面表现出强劲性能。
## Innovation
本文提出了一种更轻但更强的Mamba策略，相比原始策略网络参数减少了80%以上，同时实现了更出色的性能。具体来说，Mamba策略引入了XMamba块，它可以有效地将输入信息与条件特征相结合，并利用Mamba和注意力机制的组合进行深度特征提取。此外，Mamba策略在Adroit、Dexart和MetaWorld数据集上表现优秀，需要显著减少的计算资源。Mamba策略还在长视线场景中显示了增强的鲁棒性，并在Mamba策略框架内探索了各种Mamba变体的性能。
## Conclusion
广泛的实验证明了Mamba策略在多个数据集上的优越性能，并且在资源有限的设备上表现出明显的优势。此外，还将在现实世界中进一步验证其有效性，并在开放源代码项目页面上提供了相关资源。
# 405. `cs.CV` - WAFFLE: 细化多模态模型以实现自动化前端开发 [PDF](https://arxiv.org/pdf/2410.18362), [HTML](https://arxiv.org/abs/2410.18362)
## Authors
Shanchao Liang,Nan Jiang,Shangshu Qian,Lin Tan
## Background
Web开发涉及将UI设计转化为功能网页，这可能对初学者和有经验的开发者都很具有挑战性，因为HTML的分层结构和样式复杂。尽管大规模语言模型（LLMs）在生成源代码方面显示出潜力，但UI到HTML代码生成还存在两个主要挑战：（1）有效地向LLMs表示HTML的分层结构，以及（2）弥合UI设计的视觉特性和HTML代码的文本格式之间的鸿沟。Web开发过程复杂且困难，现有自动前端开发方法尚未妥善解决上述挑战。
## Innovation
为了应对上述挑战，作者引入了Waffle——一种新的微调策略，它采用结构感知的注意力机制来提高LLMs对HTML结构的理解，并采用对比式微调方法使LLMs理解UI图像和HTML代码之间的关系。与现有的微调方法相比，使用Waffle微调的模型在新的基准WebSight-Test和现有的基准Design2Code上表现出优异的性能，分别在HTML匹配度、CW-SSIM、CLIP得分、LLEM方面提高了9.00百分点、0.0982、32.99和27.12百分点。
## Conclusion
Waffle通过改进对于HTML结构的理解和连接UI设计和HTML代码之间的桥梁，实现了更高效的前端自动化开发，明显提升了UI到HTML代码生成模型的性能。
# 406. `cs.CV` - 全面筛查：从H&E全切片图像进行泛癌种遗传和表型生物标志物的高通量筛查 [PDF](https://arxiv.org/pdf/2408.09554), [HTML](https://arxiv.org/abs/2408.09554)
## Authors
Yi Kan Wang,Ludmila Tylditatova,Jeremy D. Kunz,Gerard Oakley,Bonnie Kar Bo Chow,Ran A. Godrich,Matthew C. H. Lee,Hamed Aghdam,Alican Bozkurt,Michal Zelechowski,Chad Vanderbilt,Christopher Kanan,Juan A. Retamero,Peter Hamilton,Razik Yousfi,Thomas J. Fuchs,David S. Klimstra,Siqi Liu
## Background
分子检测是用于癌症预后和治疗选择的标准方法，但这些检测昂贵、耗材和耗时。应用人工智能（AI）技术到常规苏木精和曙红（H&E）染色的全切片图像（WSI）中，提供了一种快速且经济的替代方案，用于筛查分子生物标志物。然而，当前的方法需要为每个生物标志物建立单独的模型，并且对于低频目标生物标志物，建立单独模型不切实际。
## Innovation
OmniScreen 通过利用来自 60,529 名癌症患者的配对 489 基因 MSK-IMPACT 靶向生物标志物面板和WSI 的 Virchow2嵌入，开发了一种高通量的基于 AI 的系统。OmniScreen 使用单一模型来预测各种癌症中的多个临床上相关的生物标志物，包括个体建模不切实际的低频目标。这种系统能够识别常见和罕见肿瘤的治疗靶点和共享表型特征，并且能够分析肿瘤面积、队列规模、组织学亚型匹配以及途径级形态模式对生物标志物预测概率和准确性的关系，揭示 OmniScreen 在常规临床筛查中的潜力。
## Conclusion
研究发现 OmniScreen 有望应用于常规临床筛查中，能够可靠地识别多种癌症的治疗靶点和共享表型特征，提供了改进癌症患者预后和治疗选择的能力。
# 407. `cs.CV` - DRO-Augment框架：通过 Wasserstein 分布鲁棒优化与数据增强协同实现鲁棒性 [PDF](https://arxiv.org/pdf/2506.17874), [HTML](https://arxiv.org/abs/2506.17874)
## Authors
Jiaming Hu,Debarghya Mukherjee,Ioannis Ch. Paschalidis
## Background
在许多实际应用场景中，确保深度神经网络（DNNs）的鲁棒性和稳定性至关重要，尤其是对于会遇到各种输入扰动的图像分类任务。尽管数据增强技术已广泛采用以增强训练模型对这些扰动的抵抗性，但在同时抵御受到损坏的数据和对抗性攻击方面仍存在改进空间。为解决这一挑战，本文提出了一种名为DRO-Augment的新颖框架，该框架结合了Wasserstein分布鲁棒优化（W-DRO）和多种数据增强策略，显著提升了模型在广泛扰动范围内的鲁棒性。在理论方面，本文为使用计算效率高且具有变异性正则化的损失函数训练的神经网络建立了新颖的泛化误差界，该损失函数与W-DRO问题密切相关。
## Innovation
本文提出了一种名为DRO-Augment的新型框架，该框架结合了Wasserstein分布鲁棒优化和多种数据增强策略，显著提升了模型在广泛扰动范围内的鲁棒性。同时，本文为使用变异性正则化损失函数训练的神经网络建立了新颖的泛化误差界。
## Conclusion
DRO-Augment方法在严重数据扰动和对抗性攻击场景下优于现有增强方法，同时在干净数据集上保持较高的准确性。这些结果表明，DRO-Augment框架能够显著提高模型的鲁棒性。
# 408. `cs.CV` - 使用合成数据证明改进少量样本模型泛化能力的理论 [PDF](https://arxiv.org/pdf/2505.24190), [HTML](https://arxiv.org/abs/2505.24190)
## Authors
Lan-Cuong Nguyen,Quan Nguyen-Tri,Bang Tran Khanh,Dung D. Le,Long Tran-Thanh,Khoat Than
## Background
由于少量标注训练样本的稀缺性，少量样本图像分类仍然是一个挑战。通过使用合成数据来补充真实数据，已成为缓解这一问题的一种有前景的方法。然而，使用合成样本训练的模型常常由于真实分布与合成分布之间的固有差异而面临性能下降的问题。为此，本文构建了一个理论框架，量化了这种分布差异对监督学习的影响，特别是针对图像分类的应用。该框架还提供了生成高质量合成样本和训练具有高泛化能力预测器的实际建议。基于该框架，提出了一种新的结合原型学习的理论方法，该方法优化了数据分割和模型训练，有效缩小了少量真实数据与合成数据之间的差距。大量的实验结果表明，本文方法在多个数据集上的性能优于现有最先进的方法。
## Innovation
本文提出了一种新的理论方法，结合原型学习来优化少量样本数据和合成数据之间的差距，该方法的有效性在多个数据集上的实验结果中得到了证明。
## Conclusion
本文通过构建理论框架提出了一种新的少量样本模型使用合成数据的方法，该方法在多个数据集上表现出优越的性能，并有效解决了真实分布与合成分布之间的差距问题。
# 409. `cs.CV` - 从粗略到连续：用于运动鲁棒各向异性MRI重建的逐步细化隐式神经表示 [PDF](https://arxiv.org/pdf/2506.16210), [HTML](https://arxiv.org/abs/2506.16210)
## Authors
Zhenxuan Zhang,Lipei Zhang,Yanqi Cheng,Zi Wang,Fanwen Wang,Haosen Zhang,Yue Yang,Yinzhe Wu,Jiahao Huang,Angelica I Aviles-Rivero,Zhifan Gao,Guang Yang,Peter J. Lally
## Background
在运动鲁棒磁共振成像（MRI）中，薄片到体素的重建对于从2D薄片中恢复解剖上一致的3D脑体非常重要，尤其是在加速采集或患者运动时。但由于层次结构的破坏，这个任务仍然具有挑战性，包括局部细节因K空间欠采样而丢失，因运动引起的全局结构混叠，以及体素各向异性。因此，本文提出了一种逐步细化隐式神经表示（PR-INR）框架。PR-INR通过在几何感知坐标空间中统一运动校正、结构细化和体素合成来解决这些问题。
## Innovation
本文提出了一种用于运动鲁棒各向异性MRI重建的PR-INR框架。它包括一个运动感知扩散模块，用于生成粗略的体素重构，以抑制运动伪影并保持全局解剖结构；一个隐式细节恢复模块，通过将空间坐标与视觉特征对齐来进行残留细化，以纠正局部结构并提高边界精度；以及一个体素连续感知表示模块，将以3D坐标为自变量的图像表示为连续函数，从而实现准确的跨层完成和高频率细节恢复。这些特征共同解决了运动、局部细节丢失和体素各向异性的挑战。
## Conclusion
通过在不同运动条件（3%和5%的位移）、不同欠采样率（4倍和8倍）和不同切片分辨率（缩放比例为5）下的五个公开MRI数据集上进行评估，实验结果表明，PR-INR在定量重建指标和视觉质量方面均优于现有最先进的方法。此外，它在各种未见领域中展示了良好的泛化能力和鲁棒性。
# 410. `cs.CV` - LVPNet：基于潜变量的预测驱动端到端框架在医学图像无损压缩中的应用 [PDF](https://arxiv.org/pdf/2506.17983), [HTML](https://arxiv.org/abs/2506.17983)
## Authors
Chenyue Song,Chen Hui,Qing Lin,Wei Zhang,Siqiao Li,Haiqi Zhu,Zhixuan Li,Shengping Zhang,Shaohui Liu,Feng Jiang,Xiang Li
## Background
在现有的方法中，图像分割过程导致潜变量信息在每个子图像中分布均匀，进而引发后验崩溃和潜变量利用效率低下。因此，为了克服这些问题，提出了一种基于预测的端到端无损医学图像压缩方法，名为LVPNet，利用全局潜变量预测像素值并对其进行编码以实现无损压缩。
## Innovation
1. 引入Global Multi-scale Sensing Module (GMSM)，从整个图像中提取紧凑且具有信息性的潜表示，有效捕捉潜在空间内的空间依赖性。2. 提出了Quantization Compensation Module (QCM)，学习量化误差的分布，并通过调整量化特征来补偿量化损失。3. 通过在具有挑战性的基准测试上的广泛实验，证明了该方法在保持与现有最佳无损图像压缩技术相当的压缩效率的同时，能够实现更高的压缩效率，并保持竞争力的推理速度。
## Conclusion
LVPNet在无损医学图像压缩的应用中表现出优越的压缩效率，同时保持了良好的推理速度，克服了因图像分割导致的潜变量信息分配不均和后验崩溃的问题。
# 411. `cs.LG` - FlightKooba: 快速可解释的飞行轨迹预测模型 [PDF](https://arxiv.org/pdf/2506.19885), [HTML](https://arxiv.org/abs/2506.19885)
## Authors
Jing Lu,Xuan Wu,Yizhun Tian,Songhan Fan,Yali Fang
## Background
Koopman理论是一个强大的模型工具，可以将非线性系统转换为线性表示。飞行轨迹预测（FTP）是一个复杂的非线性系统。然而，当前应用Koopman理论的FTP模型效果有限，模型的可解释性较差，且Koopman算子的计算密集，导致训练时间较长。
## Innovation
本文提出了基于HIPPO方法、Koopman理论和控制论状态空间方程的新建模和控制框架：FlightKooba。该框架通过直接从数据构建Koopman算子，使其具有高度可解释性，并大幅减少了训练模块中的可训练参数数量，从而大大缩短了训练时间。FlightKooba在时间与内存消耗方面表现出优越性（训练时间与Mamba模块相当，且无需使用CUDA级加速；相比于大多数数据集，内存减少了50%以上，参数数量减少了十倍），有效地完成了FTP任务。此外，FlightKooba提供了一种快速计算Koopman算子的新方法，为时间和序列预测与控制的结合开辟了新的可能性。
## Conclusion
实验表明，FlightKooba方法在时间和内存消耗方面表现出明显优势，有效地完成了FTP任务，提供了计算Koopman算子的一种新方法，为时间和序列预测和控制的结合提供了新的可能性。
# 412. `cs.CV` - TCDiff++: 一个端到端的轨迹可控扩散模型，用于 harmonious 音乐驱动的团体舞蹈编排 [PDF](https://arxiv.org/pdf/2506.18671), [HTML](https://arxiv.org/abs/2506.18671)
## Authors
Yuqin Dai,Wanlu Zhu,Ronghui Li,Xiu Li,Zhenyu Zhang,Jun Li,Jian Yang
## Background
音乐驱动的舞蹈生成因广泛应用而受到广泛关注，尤其在团体舞蹈编排中。然而，在生成过程中，大多数现有方法仍然面临多舞者碰撞、单个舞者脚部滑动以及换位中突然变化等问题，特别是在生成长时间团体舞蹈时这些问题更为显著。为了克服这些问题，提出了 TCDiff++ 这一音乐驱动的端到端框架，旨在生成和谐的团体舞蹈。
## Innovation
TCDiff++ 特别设计了舞者定位嵌入以更好地保持舞者之间的相对位置，引入距离一致性损失以确保舞者间的距离在合理范围内，提出了换位模式嵌入以指示换位模式并设计舞步适配器以精修原始运动，从而最小化脚部滑动。此外，提出了长时间团体舞蹈扩散采样策略，通过将位置信息注入噪声输入以减少突然的位移变化。该模型在序列解码器层中进行增强，以提高处理长序列的能力。实验结果表明，TCDiff++ 在长时间场景中达到最先进的性能，并确保高质量和连贯的团体舞蹈生成。
## Conclusion
TCDiff++ 实现了在生成长时间团体舞蹈时高质量和连贯性的目标，解决了现有的主要问题，如多舞者碰撞、单个舞者脚部滑动和突然的换位变化，并且在所有评价指标上达到了最先进的性能。
# 413. `cs.LG` - 机器学习会议应建立“反驳与批评”环节 [PDF](https://arxiv.org/pdf/2506.19882), [HTML](https://arxiv.org/abs/2506.19882)
## Authors
Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho
## Background
科学的进步是通过逐步推进和完善人类对世界的理解实现的。在机器学习（ML）研究领域，迅猛的发展导致了大量的研究成果被发表，但同时也使得一些误导性、不正确、有缺陷甚至可能是欺诈性的研究被接受并在ML会议上得到展示，这主要是因为同行评审机制的局限性。尽管可以理解这种错误，但ML会议缺乏系统纠错的有效机制，这影响了研究领域的自我纠正能力。
## Innovation
本文提出了一种创新的观点，即ML会议应该设立一个专门的“反驳与批评”环节。这一环节将提供一个高知名度且具权威性的平台，以支持挑战之前研究成果的重要科研工作，从而促进一个动态的自我纠正研究生态系统。
## Conclusion
我们得出结论，ML会议应该创建正式、值得信赖的机制，以便帮助ML研究自我纠正。
# 414. `cs.LG` - 正交软剪枝以实现高效类别撤销 [PDF](https://arxiv.org/pdf/2506.19891), [HTML](https://arxiv.org/abs/2506.19891)
## Authors
Qinghui Gong,Xue Yang,Xiaohu Tang
## Background
机器撤销旨在从预训练的神经网络中选择性地删除特定类别的知识，以满足如GDPR等隐私法规要求。现有的方法通常面临着撤销速度和保留预测准确性的权衡问题，往往导致高计算开销或在保留类别上性能显著下降。
## Innovation
本文提出了一种新颖的类别感知软剪枝框架，利用正交卷积核正则化，实现了毫秒级反应时间的快速精确遗忘。通过在训练过程中施加正交性约束，该方法解相关卷积滤波器，分离特征表示，并通过激活差异分析高效地识别特定类别通道。
## Conclusion
在多个架构和数据集上的广泛评估表明，该方法实现了稳定剪枝、近即时执行、目标类别的完全遗忘和保留数据上的最小准确度损失。实验结果验证了该方法相较于最新基线显著降低了成员推理攻击风险并加速了撤销过程。该框架为提供实际的实时机器撤销解决方案，在MLaaS场景中具有高效性。
# 415. `cs.LG` - AIGC供给任务中生成语义通信中的蒸馏启用知识对齐 [PDF](https://arxiv.org/pdf/2506.19893), [HTML](https://arxiv.org/abs/2506.19893)
## Authors
Jingzhi Hu,Geoffrey Ye Li
## Background
AI生成内容（AIGC）的大量产生导致了从云端向边缘和移动用户传输数据时网络流量激增。生成语义通信（GSC）通过传输简化的提示文本和潜在表示，而不是高维度的AIGC数据，提供了一个有前景的解决方案。然而，GSC面临云生成AI知识与边缘和用户的知识之间，以及无线传输知识与实际信道知识之间的对齐挑战，这仍然是一个难题。
## Innovation
本文提出了一种名为DeKA-g的蒸馏启用知识对齐算法，以解决GSC系统的挑战。DeKA-g包括两种新颖的方法：元词辅助知识蒸馏（MAKD）和分组SNR自适应变率（VGSA）。MAKD通过使用优化的元词来提高知识蒸馏的效率，而VGSA则使灵活适应不同压缩率和SNR范围成为可能。实验结果表明，DeKA-g在边缘生成图像与云生成图像的对齐方面提高了44%，相较于基线，对压缩率的适应效率提高了116%，对低SNR条件下的性能提升了28%。
## Conclusion
DeKA-g算法在提高GSC系统中对边缘生成内容和云生成内容的对齐、优化压缩率适应能力和改善低SNR条件下性能方面取得了显著成果。
# 416. `cs.LG` - 因果感知智能 QoE 优化在具有自适应关键帧提取的 VR 交互中 [PDF](https://arxiv.org/pdf/2506.19890), [HTML](https://arxiv.org/abs/2506.19890)
## Authors
Ziru Zhang,Jiadong Yu,Danny H.K. Tsang
## Background
在多用户虚拟现实 (VR) 交互中，高质量体验 (QoE) 需要微妙平衡超低延迟、高保真度运动同步和公平的资源分配。现有方法在处理带宽分配、CPU 频率和用户体验之间的因果关系时往往存在不足，限制了 QoE 的提升。
## Innovation
该论文提出了一种具有因果感知作用的知识框架，该框架结合了自适应关键帧提取和基于因果感知的强化学习（RL）。首先，使用韦伯-费雪定律（Weber-Fechner Law）和注意力驱动的优先级以及运动重建准确性提出了新的 QoE 指标。该 QoE 优化问题被建模为混合整数编程（MIP）任务，优化关键帧比例、带宽和计算资源并满足近期公平性约束。此外，该研究还提出了 Partial State Causal Deep Deterministic Policy Gradient (PS-CDDPG)，它通过因果信息改进了强化学习算法的训练效率，提高了 QoE。
## Conclusion
实验结果表明，该框架显著减少了交互延迟，提升了 QoE，并保持了公平性，表现出优于基准方法的性能。
# 417. `cs.LG` - 基于层间最近邻的不确定性量化框架 [PDF](https://arxiv.org/pdf/2506.19895), [HTML](https://arxiv.org/abs/2506.19895)
## Authors
Miguel N. Font,José L. Jorro-Aragoneses,Carlos M. Alaíz
## Background
神经网络在难以检测模式或构建逻辑模型的问题上具有高准确性，但在高风险领域如医学诊断或自动驾驶中，有时会返回错误的解决方案。为检测和缓解这些错误，可以通过量化神经网络决策的不确定性。先前的工作主要依赖于softmax置信度，但在这篇论文中，作者提出了一种新的后处理框架，通过检索具有相似激活向量的训练案例来测量决策的不确定性，从而提出了两种新的不确定性度量指标：决策变化和层不确定性，以捕捉跨层最近邻类分布的变化。
## Innovation
本文提出了一种新的后处理框架，基于每层中具有相似激活向量的训练案例来量测神经网络决策的不确定性。该方法不依赖于传统的softmax置信度，而是利用最近邻案例及其分布变化来提供更精确的不确定性估计，尤其在具有挑战性的分类任务中表现出色。
## Conclusion
在CIFAR-10和MNIST两个数据集上的分类模型评估表明，这些新度量指标能够有效提升不确定性估计，在具有挑战性的分类任务中表现优于传统的softmax置信度方法。
# 418. `cs.LG` - 使用XAI方法解释用于电价预测的深度神经网络模型 [PDF](https://arxiv.org/pdf/2506.19894), [HTML](https://arxiv.org/abs/2506.19894)
## Authors
Antoine Pesenti,Aidan OSullivan
## Background
电力市场极其复杂，涉及大量的互动和复杂的依赖关系，这使得难以理解市场内部运作和价格驱动因素。虽然已经发展了一些计量经济学方法，但白盒模型（white-box models）不如深度神经网络模型（DNN）强大。因此，本文旨在使用DNN进行价格预测，并利用XAI方法理解驱动市场价格的因素，以增加我们对不同电力市场运作机制的理解。
## Innovation
本文引入了新颖的概念，即SSHAP值和SSHAP线，以增强高维表格模型的复杂表示。通过将可解释方法，如SHAP和梯度，以及可视化技术，如热图（显著性图），应用于五个电力市场，研究人员能够分析不同特征的行为和贡献，从而改善对市场价格动态的理解。
## Conclusion
本文通过结合可解释的方法和可视化技术，提高了对电力市场复杂性的理解。通过引入SSHAP值和SSHAP线，研究解决了高维表格模型的复杂表示问题，为未来的研究提供了新的思路。
# 419. `cs.LG` - 强化学习与传统深度学习方法在轴承故障诊断中的比较分析 [PDF](https://arxiv.org/pdf/2506.19929), [HTML](https://arxiv.org/abs/2506.19929)
## Authors
Efe Çakır,Patrick Dumond
## Background
滚动轴承在旋转机械中的故障会导致重大的运营中断和维护成本。现代的轴承故障诊断方法大多依赖于振动分析和机器学习技术，但这些方法通常需要大量标注数据，并且可能难以适应动态环境的变化。
## Innovation
研究探索了深度强化学习（特别是深度Q网络DQNs）在旋转机械条件监测中进行轴承故障分类任务的可能性，以提升故障诊断的准确性和适应性。结果显示开发的RL模型在控制条件下可以与传统监督学习模型达到相同的性能，但在优化奖励结构后表现出更强的适应性。
## Conclusion
研究结果表明，强化学习具有与传统方法互补的潜力，为进一步发展适应性诊断框架开了绿灯。同时，强化学习模型的计算需求也提出了进一步改进步骤。
# 420. `cs.LG` - 在广义加性模型中最重要的特征可能是特征组 [PDF](https://arxiv.org/pdf/2506.19937), [HTML](https://arxiv.org/abs/2506.19937)
## Authors
Tomas M. Bosschieter,Luis Franca,Jessica Wolk,Yiyuan Wu,Bella Mehta,Joseph Dehoney,Orsolya Kiss,Fiona C. Baker,Qingyu Zhao,Rich Caruana,Kilian M. Pohl
## Background
在可解释的人工智能中，分析特征的重要性已经成为普遍现象。然而，有时候相关特征组的联合信号被忽视或无意中排除。忽略这种联合信号可能导致失去一个关键洞察：对于许多数据集，最重要的预测因子不是孤立的特征，而是特征组的综合效应。这在包含自然特征分组的多模态数据集上尤为突出。本文提供了在广义加性模型（GAMs）的背景下研究特征组的重要性的新方法，旨在解决这些问题。该方法具有高效性、无需重新训练模型、允许事后定义组、支持重叠组，并且在高维情况下仍然有效。
## Innovation
提出了一个新的方法来确定广义加性模型中特征组的重要性。该方法具有高效性、无需重新训练模型、允许事后定义组、支持重叠组，并且在高维情况下仍然有效。此外，这种方法还与统计解释变异有可比性。作者通过三个合成实验展示了该方法的特性，并通过一个涉及多模态神经科学数据集和髋关节置换术后健康决定因素的案例研究，展示了特征组的重要性分析在识别抑郁症状及研究健康决定因素方面的应用。
## Conclusion
通过分析特征组的重要性，相比单一特征分析，这种方法能提供更准确、全面的医学状况视图。
# 421. `cs.LG` - STIMULUS: 实现快速收敛和低样本复杂度的随机多目标学习 [PDF](https://arxiv.org/pdf/2506.19883), [HTML](https://arxiv.org/abs/2506.19883)
## Authors
Zhuqing Liu,Chaosheng Dong,Michinari Momma,Simone Shao,Shaoyuan Xu,Yan Gao,Haibo Yang,Jia Liu
## Background
近年来，多目标优化(MOO)由于在机器学习(ML)、运筹学和工程领域的广泛应用而受到了广泛的关注。然而，MOO算法的设计仍然处于初期阶段，许多现有的MOO方法在收敛速度和样本复杂性性能上表现不佳。为了解决这一挑战，本文提出了一种名为STIMULUS（随机路径集成多重梯度递归估计器）的新算法，该算法提供了一种新的、稳健的方法来解决MOO问题。与传统的MOO方法不同，STIMULUS引入了一个简单的递归框架来更新随机梯度估计，以提高收敛性能并减少样本复杂性。此外，还提出了一种增强的STIMULUS版本STIMULUS-M，该版本包含动量项以进一步加速收敛。
## Innovation
本文提出了STIMULUS算法，这是一种新的随机多目标学习方法，改进了传统的MOO方法。STIMULUS通过引入一个简单的递归框架来提高随机梯度估计，从而提高收敛性能和降低样本复杂性。此外，提出了一个增强的STIMULUS-M版本，该版本包含动量项以进一步加速收敛。本文为非凸设置下的方法建立了$O(1/T)$收敛率，并为强凸设置下的方法建立了$O (text{exp}^{-text{μ}T})$收敛率。同时，实现了在非凸设置下的最优$O text{(}n+text{sqrt}(n)text{)}textbackslashepsilontext^{-1}text{)}$样本复杂性和在强凸设置下的$Otext{(}n+ text{sqrt}(n) text{ln }(text{μ}/text{ε})text{)}$样本复杂性。为减少STIMULUS和STIMULUS-M在每个周期内完整的梯度评估要求，还提出了具有自适应批量的增强版本STIMULUS+/STIMULUS-M+，并提供了它们的理论分析.
## Conclusion
本文提出的STIMULUS和STIMULUS-M算法为多目标优化问题提供了新的解决方案，通过引入递归框架和动量项提高了算法的收敛性能和样本效率。进一步增强了STIMULUS算法，解决了每个周期内完整的梯度评估要求，并提供了理论分析支持。这使得在大量的学习任务中，STIMULUS+/STIMULUS-M+版本能够更有效地进行多目标优化。
# 422. `cs.CV` - Morse：利用双采样进行跳跃加速的扩散模型 [PDF](https://arxiv.org/pdf/2506.18251), [HTML](https://arxiv.org/abs/2506.18251)
## Authors
Chao Li,Jiawei Fan,Anbang Yao
## Background
扩散模型在生成图像任务中表现出色，但通常采样过程耗时较长。通过改进采样策略，可以显著提高生成效率而不损害生成质量。本文探讨了如何利用双采样策略（Dash和Dot模型）加速扩散模型的损失少采样过程。Dash模型利用快跳采样机制，而Dot模型生成条件于当前采样点的残差反馈，提高模型的跳过采样频率。
## Innovation
本文提出了一种名为Morse的简单双采样框架，通过两个模型Dash和Dot的相互作用，实现了在保持生成质量的同时提高扩散模型的运行效率。新方法的核心在于将迭代生成过程（从噪声生成数据）通过快跳采样和自适应残差反馈策略进行优化。Morse通过在不同的时间内交替运行两个模型，实现了灵活性的图像生成性能和整体运行效率的提升。提出的权重共享策略使得Morse在训练和推理中都具有高效性。Morse方法与9种基线扩散模型相比，平均加速比为1.78到3.31倍，在多种图像生成任务中表现优越。进一步发现，Morse方法可以扩展到加速经过一致性蒸馏技术优化的Latent Consistency Model。
## Conclusion
本文提出Morse框架显著提高了扩散模型的运行效率，能够在多种图像生成任务中获得与基线方法相似的生成质量，同时提供了平均1.78到3.31倍的速度提升。此外，Morse还可以应用于加速已经通过一致性蒸馏技术优化的Latent Consistency Model，并在少步骤的文本到图像合成任务中表现出色。代码和模型已在提供链接处发布。
# 423. `cs.LG` - 任何顺序的GPT作为掩蔽扩散模型：形式与架构的分离 [PDF](https://arxiv.org/pdf/2506.19935), [HTML](https://arxiv.org/abs/2506.19935)
## Authors
Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma
## Background
现有的大语言模型（LLMs）主要采用自回归（AR）方法，但掩蔽扩散模型（MDMs）作为一种替代方法正在逐渐兴起。由于AR模型通常是解码器专用的，而MDM模型主要采用编码器专用架构，这种同时改变建模范式和架构的做法使得直接对比变得不公平。研究者们希望能够公平地比较AR范式（作为任意顺序AR，或AO-AR）和标准AR范式的优劣，进一步探讨MDM架构的影响（解码器专用 vs 编码器专用），以揭示建模范式本身和架构改变的关键差异。
## Innovation
本文的研究创新点在于将掩蔽扩散模型（MDMs）置于解码器专用框架下进行评估，以明确区分建模范式和架构设计对模型性能的影响。研究发现，常见的任意顺序AR目标（AO-AR）可能需要进一步优化，且解码器专用的MDMs在建模更大的条件概率空间时，通过温度调节，可以实现显著的生成速度提升（约25倍），同时保持与编码器专用MDMs相当的困惑度，揭示了明确的权衡关系。这些研究结果有助于未来模型设计提供有价值的认识。
## Conclusion
本文解开了建模范式和架构设计之间的联系，为未来的模型设计提供了宝贵的见解。研究结果表明，单纯依赖编码器或单独依赖解码器在MDMs中的影响，以及通过温度调节实现高效生成的可能性。
# 424. `cs.LG` - DIM-SUM: 动态插补用于智能公用事业管理 [PDF](https://arxiv.org/pdf/2506.20023), [HTML](https://arxiv.org/abs/2506.20023)
## Authors
Ryan Hildebrant,Rahul Bhope,Sharad Mehrotra,Christopher Tull,Nalini Venkatasubramanian
## Background
传统的时序插补模型是使用完整数据集并通过人为的遮罩模式来模拟缺失值开发的。然而，在实际的基础设施监控中，数据缺失往往非常严重且呈复杂、异质性分布，现有的方法难以处理这些情况。
## Innovation
提出DIM-SUM预处理框架，连接了人工遮罩训练数据和实际的缺失数据模式，结合模式聚类和自适应遮罩策略，提供理论上的学习保证来处理不同类型的实际缺失模式。通过在加利福尼亚水资源部门、电力数据集和基准数据上的大量实验，表明DIM-SUM相比传统方法，在相同准确度的情况下处理时间更短，需要的训练数据也更少。与大型预训练模型相比，DIM-SUM平均准确性提高一倍，推理时间显著减少。
## Conclusion
DIM-SUM框架通过引入模式聚类和自适应遮罩策略，解决了实际数据中的复杂缺失模式问题，并证明了其在处理时间和所需训练数据上的优越性，特别是在与大型预训练模型对比中表现出更高的准确性及更少的推理时间。
# 425. `cs.LG` - HERCULES: 基于嵌入的分层递归聚类及LLM生成高效摘要 [PDF](https://arxiv.org/pdf/2506.19992), [HTML](https://arxiv.org/abs/2506.19992)
## Authors
Gabor Petnehazi,Bernadett Aradi
## Background
随着各种模态复杂数据集的爆炸性增长，迫切需要先进的分析工具，这些工具不仅能有效分组数据，还能提供易于人类理解的发现结构的洞察。当前的聚类算法虽然有效，但对于多样性的数据类型（如文本、图像和数值数据）的支持有限，且在生成易于理解的描述和标题方面存在不足。HERCULES算法旨在解决这些问题，特别针对多样化的数据类型提供了一种分层k-means聚类方法，通过递归应用k-means并结合大语言模型（LLM）生成描述，增强聚类结果的解释性。
## Innovation
HERCULES的主要创新在于其深嵌入了大语言模型（LLMs），用于在层次聚类的每一级生成富有语义的标题和描述，显著提升了聚类结果的可解释性。此外，算法支持直接模式和描述模式两种表示方法，为用户提供灵活的聚类选项。通过提供主题种子，可以指导大语言模型生成的摘要向特定主题靠拢。HERCULES还提供了一种交互式可视化工具，以帮助用户深入分析聚类结果。这些特性使得HERCULES在处理复杂数据集时表现出色。
## Conclusion
我们展示了HERCULES的性能及其在从复杂数据集中提取有意义的层次知识方面的潜力。通过递归层次聚类和大语言模型生成高效摘要，HERCULES提供了一种强大且可解释的分析工具，特别适用于多样化的数据类型。这一方法极大地提升了数据分组的有效性和易理解性。
# 426. `cs.LG` - 基于振荡放电神经元的神经形态无线分立计算 [PDF](https://arxiv.org/pdf/2506.20015), [HTML](https://arxiv.org/abs/2506.20015)
## Authors
Dengyu Wu,Jiechen Chen,H. Vincent Poor,Bipin Rajendran,Osvaldo Simeone
## Background
神经形态计算为实时时序处理提供了比传统深度学习加速器更节能的选择。然而，许多边缘应用，如无线传感和语音识别，生成了具有丰富频谱特征的流信号，这些特征不能有效被传统的线性泄漏积分-放电(LIF)脉冲神经元捕获。本研究探讨了一种无线分立计算架构，该架构使用具有振荡动态特性的共振放电(RF)神经元直接处理时域信号，避免了昂贵的频谱预处理。通过在可调频率下振荡，RF神经元提取了时间局部化的频谱特征，同时保持较低的放电活动。这种时间稀疏性在计算和传输能量上实现了显著节省。假设基于OFDM的模拟无线接口进行脉冲信号传输，提出了一整套系统设计，并评估了其在音频分类和调制分类任务上的性能。实验结果表明，提出的RF-SNN架构在推理和通信过程中显著降低了脉冲速率和总能耗，同时达到了与传统LIF-SNN和ANN相当的准确性。
## Innovation
采用共振放电(RF)神经元替代传统的LIF脉冲神经元，直接处理时域信号，实现节省计算和传输能量；设计并评估了基于共振放电神经元的无线分立计算架构，该架构能够有效处理流信号并降低能耗；使用基于OFDM的模拟无线接口进行脉冲信号传输，实现了完整的系统设计和评估。
## Conclusion
提出的RF-SNN架构在推理和通信过程中显著降低了脉冲速率和总能耗，同时达到了与传统LIF-SNN和ANN相当的准确性。此架构为实时时序处理提供了有效的解决方案，特别是在无线传感和语音识别等领域中表现出色。
# 427. `cs.LG` - 调节天平：最后一层重训中的最优损失加权 [PDF](https://arxiv.org/pdf/2506.20025), [HTML](https://arxiv.org/abs/2506.20025)
## Authors
Nathan Stromberg,Christos Thrampoulidis,Lalitha Sankar
## Background
随着机器学习模型在大规模区分任务中变得越来越强大，它们克服由训练数据引入的偏见的能力受到了越来越多的关注。先前的研究表明，在参数化设置中存在两种极端情况，具有非常不同的行为：人口（欠参数化）设置下损失加权是最优的，而在分离的过参数化设置下，损失加权对确保各分类之间平等表现效果不佳。这项工作探讨了最后一层重训（LLR）的区域，在该区域中，未见过的有限（重训）数据经常是不可分离的，而模型的大小是适当的，这介于上述两种极端情况之间。
## Innovation
这项工作的创新在于通过理论和实践证明，在这种最后一层重训的区域内，损失加权仍然有效，但这些权重必须考虑到模型的相对过参数化程度。
## Conclusion
研究表明，尽管最后一层重训区域中的数据不可分离，损失加权仍然是有效的，但这些权重必须考虑到模型的相对过参数化程度，以确保各分类之间平等的表现。
# 428. `cs.LG` - TRACED: 过渡感知的后悔近似与协同学习能力在环境设计中的应用 [PDF](https://arxiv.org/pdf/2506.19997), [HTML](https://arxiv.org/abs/2506.19997)
## Authors
Geonwoo Cho,Jaegyun Im,Jihwan Lee,Hojun Yi,Sejin Kim,Sundong Kim
## Background
将深度强化学习代理推广到未见过的环境中仍然是一项重大挑战。一种有前途的解决方案是无监督环境设计（UED），这是一种共进化框架，在此框架中，教师会自适应地生成具有高学习潜力的任务，而学生则学习适应这些不断演变的课程的鲁棒策略。现有的UED方法通常通过遗憾来衡量学习潜力，遗憾是最佳性能与当前性能之间的差距，通过价值函数损失近似计算。基于这些方法，我们引入了过渡预测误差作为遗憾近似的额外项。为了捕捉一次任务训练如何影响其他任务的表现，我们还提出了一种轻量级的度量标准——协同可学性。通过结合这两种测量，我们提出了过渡感知的后悔近似与协同学习能力（TRACED）用于环境设计的方法。
## Innovation
引入了过渡预测误差作为遗憾近似的额外项，以捕捉一次任务训练如何影响其他任务的表现，进一步提出协同可学性作为轻量级指标。通过结合这两种测量，我们提出了过渡感知的后悔近似与协同学习能力（TRACED）。
## Conclusion
实验评价结果显示，TRACED能够提高在多个基准测试上的零样本泛化能力，并且只需要比强大基线单元状态的交互次数少2倍。消融研究表明过渡预测误差可以驱动快速复杂性提升，而协同可学性在配合过渡预测误差时提供了额外的增益。结果表明，精细的后悔近似和任务关系的显式建模可以用于UED中的样本高效课程设计。
# 429. `cs.LG` - 使用二元优化和图学习为多-agent操作自动生成多样化行动计划 [PDF](https://arxiv.org/pdf/2506.20031), [HTML](https://arxiv.org/abs/2506.20031)
## Authors
Prithvi Poddar,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury
## Background
涉及多个代理的操作、搜救行动和军事任务需要自动化的支持过程来规划行动方案（COA）。环境变化（如雨、雪、封锁等）会影响预期性能，因此需要多样化的COA池来适应任务分配的变化。此外，代理（包括人类和自主系统）能力的变异性带来了规划过程中的实践机会和计算挑战。因此，需要一个理论框架和计算方法来生成多样化的COA，并确保任务分配考虑到代理与任务兼容性的软变化。
## Innovation
本文提出了一种新的理论方法和计算框架，旨在生成多样化的COA池，适用于代理任务兼容性存在细微变化的情况。通过使用图抽象化任务空间和COA池本身来量化其多样性。将COA形式化为集中式的多机器人任务分配问题，并使用遗传算法和图神经网络来最大化COA池内部多样性以及代理-任务映射的整体兼容性。
## Conclusion
在模拟环境中测试表明，COA生成过程与随机游走基线相比有显著的性能提升，任务序列化中的优化差距很小，实际处理时间约为50分钟，用于规划多达20个COA（5个代理/100个任务的操作）.
# 430. `cs.LG` - 新见解：展开与细化量子联邦学习 [PDF](https://arxiv.org/pdf/2506.20016), [HTML](https://arxiv.org/abs/2506.20016)
## Authors
Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel
## Background
量子联邦学习（QFL）由于客户端的异质性而面临显著的性能挑战。标准的聚合方法在高度异质的环境中往往无法确保稳健的优化，这导致了过拟合问题，限制了传统方法在准确性和可靠性方面的表现，尤其是它们通常只能达到约55%的准确率。
## Innovation
本文提出了一个新的解决方案，通过利用深度展开技术，让客户端能够根据自身特定的训练行为自主优化超参数，如学习率和正则化因子。这种方法实现了动态适应性，减少了模型的过拟合，并确保了在高度异质环境中的鲁棒性。该框架在IBM量子硬件和Qiskit Aer模拟器上进行实时训练，达到了约90%的准确率，显著超越了传统的性能。研究表明，该方法特别适用于关键应用，如基因表达分析和癌症检测，增强了诊断精度和预测建模。
## Conclusion
本文通过挖掘深度展开框架中的收敛感知、可学习的优化步骤，解决了传统QFL的核心限制，使其适用于复杂的挑战，如医疗健康和基因组研究，从而提高了QFL的适用性和效果。
# 431. `cs.LG` - 使用自我蒸馏的图神经网络不确定性量化 [PDF](https://arxiv.org/pdf/2506.20046), [HTML](https://arxiv.org/abs/2506.20046)
## Authors
Hirad Daneshvar,Reza Samavi
## Background
图神经网络（GNNs）在医疗领域展现了显著的效果。然而，在临床应用中，量化GNNs的预测不确定性仍然是一个挑战。虽然贝叶斯方法和集成方法可以用于不确定性量化，但这些方法计算成本较高。此外，集成方法用于计算不确定性的不一致性度量无法捕捉模型的多样性。
## Innovation
本文提出了一种基于知识蒸馏的新方法，旨在更高效、更精准地量化GNNs的不确定性。具体来说，我们采用自我蒸馏技术，使同一网络同时作为教师模型和学生模型，避免了需要独立训练多个网络。为此，我们开发了一种不确定性度量方法，通过为每个GNN分类器分配不同的权重来捕捉网络的多样性。
## Conclusion
我们通过在MIMIC-IV和Enzymes两个图数据集上进行实验，评估了此方法的精度、性能以及在区分出界数据方面的表现。结果表明，所提方法能够有效捕捉模型的预测不确定性，同时具有与其他MC Dropout和集成方法相当的性能。相关代码已公开。
# 432. `cs.LG` - 边缘设备上的可验证消学习 [PDF](https://arxiv.org/pdf/2506.20037), [HTML](https://arxiv.org/abs/2506.20037)
## Authors
Mohammad M Maheri,Alex Davidson,Hamed Haddadi
## Background
机器学习提供者通常会将全局模型分发到边缘设备上，边缘设备会使用本地数据进行个性化。然而，版权侵权、偏见或监管要求可能会需要在所有边缘设备上验证并删除某些数据样本。确保边缘设备正确执行这些卸载操作对于维护完整性和合规性至关重要。现有方法亟需一种在不泄露隐私的情况下验证卸载操作的方法来保证这种完整性。
## Innovation
本文提出了一个利用零知识证明（zk-SNARKs）进行验证的框架，该框架可以在不泄露隐私的情况下确认个性化边缘设备模型中的数据卸载操作。开发了与高效zk-SNARK证明生成兼容的算法，确保可以在受限制的边缘环境中保持最小的计算和内存开销。同时，该方法维护了边缘设备上的个性化改进，保持了卸载后的模型性能。
## Conclusion
研究结果证实了该验证框架的可行性和有效性，展示了在最小性能退化的情况下实现了可验证的卸载。该方法确保了在边缘设备上进行的消学习的可验证性、隐私安全性和有效性。
# 433. `cs.LG` - 通过迭代随机计算实现的通用预训练 [PDF](https://arxiv.org/pdf/2506.20057), [HTML](https://arxiv.org/abs/2506.20057)
## Authors
Peter Bloem
## Background
本文探讨了使用随机生成的数据进行模型预训练的方法。研究基于近期的研究成果，这些成果表明序列模型能够被训练以逼近于索洛莫夫归纳原则。本文旨在通过理论和实证两个角度探讨这一方法的可行性和效果。
## Innovation
本文从算法复杂性的角度对这一方法进行了理论上的证明，并且提供了相似但互补的理论结果。通过实验证明，合成生成的数据可以在未见过实际数据前用于模型的预训练。此外，本文还扩展了先前的结果，证明了在真实世界数据上应用这一方法可以加速模型的微调过程并提高泛化能力。
## Conclusion
无论是在合成生成数据还是真实世界数据上，通过这种方式进行预训练的模型都表现出了跨多个数据集的零样本上下文学习能力，并且这一性能随着模型规模的增加而提升。进一步的微调虽然增加了一些开销，但却可以带来更快的收敛速度和更好的泛化性能。
# 434. `cs.LG` - 跨层离散概念发现以解释语言模型 [PDF](https://arxiv.org/pdf/2506.20040), [HTML](https://arxiv.org/abs/2506.20040)
## Authors
Ankur Garg,Xuemin Yu,Hassan Sajjad,Samira Ebrahimi Kahou
## Background
在变压器层中发现涌现的概念仍然是一项重大挑战，因为残差流线性地混合并复制信息，这掩盖了大型语言模型中特征的演变。当前的研究主要检查单个层的神经表示，忽略了跨层叠加和引入的冗余。这些表示通常直接分析激活模式，或者传递给探针分类器，后者将它们映射到一组预定义的概念上。
## Innovation
我们提出了一种名为clvqvae的框架，该框架使用向量量化将层之间的表示映射，并在过程中将残差流中重复的特征压缩成紧凑的可解释概念向量。该方法结合了量化期间基于top-$k$温度的采样和EMA码本更新，提供了对离散潜在空间的可控探索，同时保持码本的多样性。我们还使用了按方向相似性进行聚类的尺度球形k-means++进行码本初始化，这更好地与词嵌入空间中的语义结构对齐。
## Conclusion
我们的方法能够有效地处理大型语言模型中跨层的冗余信息，通过向量量化策略发现离散的概念，这些概念在词嵌入空间中表达了更好的语义结构。
# 435. `cs.LG` - 解释滚动扩散模型用于概率天气预报 [PDF](https://arxiv.org/pdf/2506.20024), [HTML](https://arxiv.org/abs/2506.20024)
## Authors
Salva Rühling Cachay,Miika Aittala,Karsten Kreis,Noah Brenowitz,Arash Vahdat,Morteza Mardani,Rose Yu
## Background
扩散模型是一种强大的工具，用于概率预测，但大多数在高维混沌系统中的应用都是一次预测未来的单个快照。这种方法难以建模复杂的时序依赖性，并且未能明确考虑这些系统中固有的不确定性累积。虽然已经提出了滚动扩散框架来解决这个问题，但如何将其与最先进的高保真扩散技术结合仍是一个挑战。在本论文中，作者提出了Elucidated Rolling Diffusion Models (ERDM)，这是一种新颖的方法，将滚动预测结构与Elucidated Diffusion Models (EDM)的原理性和高效设计相结合，从而克服了上述问题。
## Innovation
论文的主要创新在于提出了Elucidated Rolling Diffusion Models (ERDM)，这是第一个成功将滚动预测结构与Elucidated Diffusion Models (EDM)的原理性和高效设计统一的框架。ERDM的主要贡献包括：(i)一种新颖的损失权重方案，将模型能力集中在决定性与随机性过渡的中期预测时期；(ii)使用预训练的EDM进行初始窗口的有效初始化策略；(iii)专为渐进去噪情况下稳健的时空特征提取设计的独特混合序列架构；ERDM在2D Navier-Stokes模拟和分辨率为1.5°的ERA5全球天气预报中均优于关键的基于扩散的基本基准方法，包括条件自回归EDM。
## Conclusion
ERDM提供了灵活且强大的一般框架，用于解决基于扩散的序列生成问题，特别是在建模不断升高的不确定性方面。研究结果表明，在概率天气预报等领域，ERDM可以显著提高预测准确性。该论文在该领域提出了新的方向并提供了有价值的工具。
# 436. `cs.LG` - 基于分类和回归的预测性维护方法综述：通过分类和回归进行预测性维护分析 [PDF](https://arxiv.org/pdf/2506.20090), [HTML](https://arxiv.org/abs/2506.20090)
## Authors
Ainaz Jamshidi,Dongchan Kim,Muhammad Arif
## Background
预测性维护（PdM）已成为现代工业实践中的关键组成部分。通过减少意外停机时间和优化资产生命周期管理，PdM 对操作可靠性和成本管理起着重要作用。机器学习和深度学习使设备故障和剩余使用寿命（RUL）的预测更为精确。尽管许多研究已经对PdM做出了贡献，但还没有专门比较回归和分类方法的研究。本文通过全面分析近期文献，展示了各种PdM方法的关键进展、挑战，如数据不平衡、高维特征空间，以及新兴趋势，包括混合方法和AI驱动的预测系统。该综述旨在使研究者和实践者了解各种PdM方法的优势和妥协，并帮助识别未来研究方向，建立更强大、定向的自适应维护系统。未来的工作可能包括系统地审查公共数据集、基准平台和开源工具等内容，以支持PdM研究的进步。
## Innovation
本文进行了一项专门比较基于回归和分类方法在预测性维护中的应用的综述，强调了这两种方法在预测性维护中的不同应用场景，并分析了两者的关键进展、挑战和未来趋势。
## Conclusion
本文通过综述和分析，为研究者和实践者提供了对不同PdM方法的理解，指出了其优势和局限性，并建议未来的工作可以进一步关注实际应用中的公共数据集、基准平台和开源工具的评估，以促进PdM研究的进步。
# 437. `cs.LG` - 使用大型语言模型进行开放生成指令重新标识的学习指令遵循策略 [PDF](https://arxiv.org/pdf/2506.20061), [HTML](https://arxiv.org/abs/2506.20061)
## Authors
Zhicheng Zhang,Ziyan Wang,Yali Du,Fei Fang
## Background
在强化学习中发展有效的指令遵循策略依然具有挑战性，主要由于依赖大量的人类标记指令数据集以及从稀疏的奖励中学习的困难。因此，需要一种新的方法来解决这些问题。本文提出了一种创新的方法，利用大型语言模型（LLMs）从之前收集的智能体轨迹中自动生成开放性指令，以此来重新标识先前未成功的轨迹。这种重新标识的方法旨在通过识别智能体已隐含完成的重要子任务，来丰富智能体的训练数据集，从而大大减少对人工标注数据的依赖。该方法在具有挑战性的Craftax环境中进行了实证评估，展示了与当前最先进的基线相比，在样本效率、指令覆盖范围和整体策略性能方面的显著提升。
## Innovation
本文提出了一种新颖的方法，即利用大型语言模型生成开放性指令来重新标识先前未成功的智能体轨迹。这种方法通过识别智能体已经隐含完成的重要子任务来丰富训练数据集，从而减少了对人工标注数据的依赖，提高了样本效率和指令覆盖范围，增强智能体的总体性能。
## Conclusion
通过实验证明，该方法在具有挑战性的Craftax环境中显著提高了样本效率、指令覆盖范围和策略性能，表明利用大型语言模型指导的开放性指令重新标识可以有效增强指令遵循的强化学习效果。
# 438. `cs.LG` - LSH-DynED: 基于LSH的动态集成框架，用于动态变化的多类别不平衡分类 [PDF](https://arxiv.org/pdf/2506.20041), [HTML](https://arxiv.org/abs/2506.20041)
## Authors
Soheil Abadifard,Fazli Can
## Background
多类别不平衡数据流分类是机器学习中的一个关键挑战，尤其是在处理多个类别时。尽管二元不平衡数据流分类任务已受到相当多的关注，但对多类别不平衡数据流的研究相对较少。动态不平衡比例的有效管理是这一领域的一个关键挑战。现有方法在管理和解决这一挑战方面的能力不足，因此需要一种新的、鲁棒且适应性强的方法来应对这些问题。
## Innovation
本文提出了一种新的方法LSH-DynED，通过将局部敏感哈希（Locality Sensitive Hashing，LSH）与随机超平面投影（Random Hyperplane Projections，RHP）技术集成到动态集成多样化（Dynamic Ensemble Diversification，DynED）框架中，解决多类别不平衡数据流分类中的挑战。本文首次将LSH-RHP应用于不平衡非稳态数据流的欠采样，通过利用LSH-RHP对多数类进行欠采样，提供平衡的数据集，从而提高集成的预测性能。实验结果显示，LSH-DynED在多个真实世界和半合成数据集上的表现优于其他方法，特别是在大规模、高维度且类别不平衡程度较高的数据集上表现出色，并展示了适应和鲁棒性。
## Conclusion
LSH-DynED在处理多类别不平衡非稳态数据流方面表现出色，提供了一种新的解决方案。通过对比现有的十几个最先进的方法，该方法在Kappa和mG-Mean评价指标上表现出优越性。该研究为未来的工作提供了指导，并提供了可复现实验结果的代码实现。
# 439. `cs.LG` - 来自多模态地球观测数据的高分辨率Live Fuel Moisture Content (LFMC)地图以评估野火风险 [PDF](https://arxiv.org/pdf/2506.20132), [HTML](https://arxiv.org/abs/2506.20132)
## Authors
Patrick Alan Johnson,Gabriel Tseng,Yawen Zhang,Heather Heward,Virginia Sjahli,Favyen Bastani,Joseph Redmon,Patrick Beukema
## Background
野火的强度和规模正在以惊人的速度增加。最近的人工智能和公开的卫星数据进步使得全球范围内以高分辨率和低延迟监测关键的野火风险因素成为可能。Live Fuel Moisture Content (LFMC)是评估野火风险的一个关键因素，对于野火研究和应急响应都有重要价值。然而，基于地面的LFMC样本采集既费时又成本高，导致更新频率低且不充分。现有方法难以实现大范围、连续空间的LFMC地图生成，特别是在需要快速响应的野火地区。因此，迫切需要一种能够快速生成大范围LFMC地图的方法以应对野火风险。
## Innovation
本文探索了使用预训练的高多模态地球观测模型来生成覆盖全美的大面积完整LFMC地图的方法。这种方法在相对误差平方根（RMSE）方面相比随机初始化的模型降低了20%的误差，显著改进了现有技术。此外，本文提供了一个自动化的工作流程，可以在美国快速生成这些LFMC地图，并在最近受野火影响的Eaton和Palisades地区进行了验证，证明了其有效性。
## Conclusion
通过探索使用预训练的多模态地球观测模型生成大范围LFMC地图的方法，本文显著提升了野火风险监测和响应的效率和准确性。所提出的工作流程能够快速生成美国全境的LFMC地图，并在实际野火事件中证明了其有效性，为野火风险评估和预测提供了新的工具和技术支持。
# 440. `cs.LG` - DuoGPT：LLMs中基于激活感知剪枝的无训练双稀疏方法 [PDF](https://arxiv.org/pdf/2506.20194), [HTML](https://arxiv.org/abs/2506.20194)
## Authors
Ruokai Yin,Yuhang Li,Donghyun Lee,Priyadarshini Panda
## Background
大规模语言模型（LLMs）虽然表现出色，但由于高内存和计算成本，难以部署。虽然剪枝可以降低这些需求，但大多数方法忽视了运行时观察到的激活稀疏性。
## Innovation
重新解释激活稀疏性为动态结构化权重稀疏性，并提出DuoGPT，这是一种统一框架，通过结合无结构权重剪枝和激活稀疏性构建双重稀疏（spMspV）工作负载。为保持准确性，扩展了Optimal Brain Compression (OBC)框架，引入了密集模型的输出残差作为校正项，并进一步优化了解决方案，使GPU高效执行，能够扩展到十亿参数的LLMs。
## Conclusion
在LLaMA-2和LLaMA-3上的评估表明，DuoGPT在与基线密集模型等速提升的情况下，相比最先进的结构化剪枝方法提升最高可达9.17%的准确率。
# 441. `cs.LG` - MEL: 多层次组合学习在资源受限环境中的应用 [PDF](https://arxiv.org/pdf/2506.20094), [HTML](https://arxiv.org/abs/2506.20094)
## Authors
Krishna Praneet Gudipaty,Walid A. Hanafy,Kaan Ozkara,Qianlin Liang,Jesse Milzman,Prashant Shenoy,Suhas Diggavi
## Background
AI推理在边缘环境中的应用日益增多，以实现低延迟的服务。然而，边缘环境受限于电力和资源，且容易遭受故障。传统的容错方法，例如云故障转移或压缩备份，常常会牺牲延迟或准确性，限制了它们在关键边缘推理服务中的有效性。
## Innovation
本文提出了一种名为多层级组合学习(Multi-Level Ensemble Learning, MEL)的新框架。该框架同时训练多个轻量级备份模型，这些模型能够在多个服务器可用时互相提升，发生故障时独立运行，同时保持良好的准确性。具体来说，将该方法表述为一个多目标优化问题，通过损失函数促进模型间的多样性，同时确保每个模型独立时的性能。通过对视觉、语言和音频数据集的实证测试，MEL提供了与原始架构相当的性能，同时具备容错能力和在边缘平台上的部署灵活性。训练MEL组合模型时，它的大小仅占原始模型的40%，在故障情况下，仍能保持95.6%的组合准确性。
## Conclusion
实验结果表明，MEL模型不仅在性能上接近原始架构，在故障情况下也能够提供良好的容错性和部署灵活性，且模型大小仅为原始模型的40%。
# 442. `cs.LG` - 确定性的离散LTI-DAE系统的因果发现 [PDF](https://arxiv.org/pdf/2506.20169), [HTML](https://arxiv.org/abs/2506.20169)
## Authors
Bala Rajesh Konkathi,Arun K. Tangirala
## Background
在数据驱动的因果网络重构中，确定纯原因或驱动变量至关重要。Kathari和Tangirala在2022年提出了因果发现方法作为约束识别问题，并使用基于动态迭代主成分分析（DIPCA）的方法在包含高斯测量误差的动态系统中识别约束。DIPCA方法适用于没有任何代数关系的纯动态系统。然而，许多动态系统在反馈控制下运行或受到守恒律的影响，这导致了一类新的系统类型——代数-动态（DAE）或混合因果系统。尽管DIPCA方法有效，但对于包含代数方程的系统并不适用，因此需要一种能够处理这些系统的新型方法。
## Innovation
本文提出了一种用于LTI-DAE系统的因果发现方法——变量划分（PoV）。PoV方法不仅适用于没有代数方程的纯动态系统，同时也适用于代数-动态系统。该方法通过确定代数关系数（$n_a$）、动态关系数（$n_d$）和约束矩阵，使用DIPCA来识别因果驱动因素，并通过约束矩阵条件数的可接受划分来识别子集。这种方法在案例研究中表现出色，证明了其有效性。
## Conclusion
PoV方法是一种有效的因果发现方法，它可以处理包含代数关系的系统，对于LTI-DAE系统的因果发现有显著优势。
# 443. `cs.LG` - 通过反事实物理信息神经网络在偏微分方程中的因果算子发现 [PDF](https://arxiv.org/pdf/2506.20181), [HTML](https://arxiv.org/abs/2506.20181)
## Authors
Ronald Katende
## Background
本研究发展了一种基于物理信息神经网络和反事实扰动的体系结构框架，用于在偏微分方程(PDEs)中发现因果结构。这种方法不同于经典的残差最小化或稀疏回归方法，它通过功能干预治理动力学来量化操作级别的重要性。该方法通过因果敏感指数和结构偏差度量评估神经代理中候选微分算子的影响。理论证明，在受限等距或公共相干条件下，可以精确恢复因果算子的支持，同时残差界保证可识别性。实验验证了该框架在气候变化动力学、肿瘤扩散和海洋流等合成和真实世界数据集上的有效性，即使在噪声、冗余和数据稀缺的情况下，该方法也能一致地恢复控制算子，并优于标准的物理信息神经网络（PINNs）和深度卷积网络（DeepONets）在结构准确性方面。这项工作将因果PDE发现定位为一个可行且可解释的推理任务，该任务基于结构因果模型和变分残差分析。
## Innovation
本文提出了一种基于物理信息神经网络和反事实扰动的新方法，用于在偏微分方程中发现因果结构。该方法通过功能干预来量化操作级别的重要性，并通过因果敏感指数和结构偏差度量评估候选微分算子的影响。理论证明了在特定条件下可以精确恢复因果算子的支持，并且有保证的识别性。实验表明该方法在合成和真实世界数据集上的表现优于现有技术，特别是在噪声、冗余和数据稀缺的情况下。
## Conclusion
本研究通过物理信息神经网络和反事实扰动开发了一种新的体系结构框架，用于偏微分方程中发现因果结构。理论分析和实验验证都证明了该方法的有效性和优越性，将其定位为一个可行且可解释的推理任务。
# 444. `cs.LG` - 监督耦合矩阵-张量分解（SCMTF）在溃疡性结肠炎患者报告结果计算表型中的应用 [PDF](https://arxiv.org/pdf/2506.20065), [HTML](https://arxiv.org/abs/2506.20065)
## Authors
Cristian Minoccheri,Sophia Tesic,Kayvan Najarian,Ryan Stidham
## Background
表型是区分患者组以识别不同疾病进展类型的过程。最近的趋势是利用低秩矩阵和张量分解方法处理多模态、异构性和缺失数据。患者报告的症状对于理解炎症性肠病（如溃疡性结肠炎UC）患者的体验至关重要，但这些报告的症状通常噪音大、主观性强且数据稀疏，因此通常不用于表型识别和机器学习方法。为了克服这些挑战，该研究利用监督耦合矩阵-张量分解（SCMTF）方法将时间顺序的PROs和实验室检查结果与静态特征结合，来预测溃疡性结肠炎患者在8和20个月内的药物坚持情况。这种方法能够处理PROs中大量的缺失数据，该研究是首次在UC领域和PROs中应用监督耦合张量分解方法，结果表明，监督耦合张量分解方法可以成功应用于溃疡性结肠炎领域，并揭示可用的表型预测药物坚持情况，包括多个症状变量，这显示出PROs中包含的重要信息通常被忽略了。
## Innovation
首次提出了监督耦合矩阵-张量分解（SCMTF）方法，该方法是唯一结合监督和耦合的张量分解方法，并首次在溃疡性结肠炎领域和患者报告结果（PROs）中应用。该研究使用了深度学习框架，使模型更具灵活性和训练性，并能够处理PROs中的大量缺失数据。该方法可预测药物在8和20个月的坚持情况，AUC分别为0.853和0.803。通过对静态特征和时间特征的分析，揭示了访问有序的表型信息，这些信息可用于预测药物坚持情况，揭示了PROs中通常被忽略的重要信息。
## Conclusion
监督耦合矩阵-张量分解方法能够成功应用于溃疡性结肠炎领域，并能有效处理大量缺失的患者报告结果数据。研究证明PROs中包含有助于预测药物坚持情况的重要信息，这对未来的临床研究和药物治疗具有重要意义。
# 445. `cs.LG` - Q-resafe: 评估安全风险和量化感知的安全修补方法用于量化大规模语言模型 [PDF](https://arxiv.org/pdf/2506.20251), [HTML](https://arxiv.org/abs/2506.20251)
## Authors
Kejia Chen,Jiawen Zhang,Jiacong Hu,Yu Wang,Jian Lou,Zunlei Feng,Mingli Song
## Background
量化的大语言模型（LLMs）因能在资源受限的环境中部署而受到越来越多的关注。然而，一些新兴的研究表明，量化可能会削弱LLMs的安全性能，这强调了进行系统化安全评估和有效缓解策略的迫切需求。
## Innovation
提出了一个量化感知的安全修补框架，Q-resafe，可以在不显著影响性能的情况下恢复量化LLMs的安全能力，同时通过广泛的实验验证了该方法的有效性，即使在严格的评估环境下也能使量化LLMs的安全性重新与未量化前的状态相匹配。
## Conclusion
Q-resafe框架在各种主流量化技术和不同的校准数据集上进行了全面的安全评估，并通过广泛接受的安全基准验证了其有效性，成功地在复杂评估场景下重新调整了量化LLMs的安全性，确保其安全性能。
# 446. `cs.LG` - FedBKD：拥抱非IID数据上的泛化和个性化提炼联邦学习 [PDF](https://arxiv.org/pdf/2506.20245), [HTML](https://arxiv.org/abs/2506.20245)
## Authors
Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu
## Background
联邦学习（FL）是一种去中心化的协作机器学习技术，它解决了工业机器学习实践中孤立数据孤岛和数据隐私泄露的问题。当前，处理非同构和独立分布（非-IID）数据的主要挑战在于构建全能的全局模型或定制个性化局部模型。很少有方法能够同时提供泛化良好和性能优异的全局及局部模型。此外，许多解决非-IID问题的FL方法依赖于引入公共数据集，这会增加数据泄露的风险。
## Innovation
本文提出了一种新颖的无数据提炼框架——Federated Bidirectional Knowledge Distillation（FedBKD）。方法中通过生成对抗网络（GAN）生成合成数据，局部模型在此过程中作为鉴别器并且参数被固定，然后利用由全局模型和局部模型创造的合成数据进行双向提炼，以实现知识交互，从而提升双方性能。此外，实验结果表明，这种无数据提炼方法在四个基准上均达到了最佳性能。
## Conclusion
实验结果显示，FedBKD在所有测试条件下都实现了最佳性能。这种方法提供了在非-IID数据上的良好泛化能力和个性化性能。
# 447. `cs.LG` - 利用机器学习方法生成的来自能源消费者的时间序列替代品，用于长期预测场景 [PDF](https://arxiv.org/pdf/2506.20253), [HTML](https://arxiv.org/abs/2506.20253)
## Authors
Ben Gerhards,Nikita Popkov,Annekatrin König,Marcel Arpogaus,Bastian Schäfermeier,Leonie Riedl,Stephan Vogt,Philip Hehlert
## Background
在电力价值链中，预测吸引了大量的研究关注。大多数研究集中在发电或消费的短期预测上，关注的是系统层面而非个人消费者。与这些研究不同，这项研究填补了空白，关注的是个人电力消耗的长期预测。因此，本文对适合于长期电力消耗预测的数据驱动方法进行了深入的比较评估。高保真度的合成数据对于能源系统状态估计或电力网络规划等多种应用至关重要。本研究利用了德国家庭的开源数据集，时间分辨率为15分钟。该数据集用于生成合成的电力负荷概况，以便应用于诸如状态估计或用电量预测等场景中。
## Innovation
本文创新性地评估和比较了多种最新的但较少使用的生成方法：混合 Wasserstein 生成对抗网络(WGAN)、去噪扩散概率模型 (DDPM)、隐马尔可夫模型 (HMM) 和掩蔽自回归伯恩斯坦多项式正则化流 (MABF)。这些方法用于生成适合于个人电力消耗长期预测的合成时间序列数据。这项研究详细分析了每种方法在复制时间和动态、长期依赖性和概率转移等方面的性能，以帮助选择最合适的预测方法。
## Conclusion
我们的研究结果强调了 WGAN、DDPM、HMM 和 MABF 的优势和局限性，为选择最适合于状态估计及其他与能源相关的任务的生成方法提供了指导。通过生成和分析框架，本研究旨在提高合成电力消耗数据的准确性和可靠性，同时符合隐私保护标准。生成的合成电力负荷概况可用于包括状态估计和电力消费预测在内的多种应用。
# 448. `cs.LG` - 从聚类联邦学习中提炼通用专家 [PDF](https://arxiv.org/pdf/2506.20285), [HTML](https://arxiv.org/abs/2506.20285)
## Authors
Zeqi Leng,Chunxu Zhang,Guodong Long,Riting Xia,Bo Yang
## Background
现有的联邦学习（FL）方法中，Clustered Federated Learning (CFL)通过训练多个集群或组特定的专家模型来应对非独立且不同分布（non-IID）数据的挑战。然而，这些方法往往忽视了不同集群之间的共享信息，而这些信息是所有参与者的通用知识。这种方法的不足之处在于没有有效利用集群间的共享知识，这限制了FL系统的效果和效率。
## Innovation
本文提出了一种新型的FL框架，该框架通过从多个集群的知识中提炼出一个通用的专家模型来进行共享知识的有效抽离。该通用专家模型捕捉到全集群下的共享信息，并分发给每个客户端作为下一轮模型训练的初始化。该框架包含三个迭代步骤：（1）每个客户端进行本地模型训练；（2）集群特定模型聚合；（3）通用专家提炼。相比传统的基于梯度的聚合方法，这种基于蒸馏的模型聚合方法在处理模型异构性方面更具灵活性，减少了集群特定专家之间的冲突。
## Conclusion
实验结果表明，所提出的方法在各种场景中均表现出优越性能，其能够更好地平衡个性化和共享知识，具有推进CFL状态的潜力。
# 449. `cs.LG` - 零射击归因对于大型语言模型：一种分布测试方法 [PDF](https://arxiv.org/pdf/2506.20197), [HTML](https://arxiv.org/abs/2506.20197)
## Authors
Clément L. Canonne,Yash Pote,Uddalok Sarkar
## Background
越来越多的代码是从大型语言模型（LLMs）中抽取生成的。本文讨论了如何使用假设检验将代码归因于生成它的特定模型的问题。由于维数灾难，在仅给出LLM样本的情况下，解决这个问题是不可行的。因此，本文利用LLM样本和密度估计，通过一种常见的获取方式绕过了这一困难。实验表明，当区分像DeepSeek-Coder、CodeGemma和Stable-Code这样的LLM时，仅使用大约2000个样本，Anubis实现了高AUROC分数（≥0.9）
## Innovation
提出了一种名为Anubis的零射击归因工具，将归因问题重新定义为分布测试问题。这种工具利用假设检验和密度估计方法，解决了仅通过LLM样本难以验证代码来源的问题，为LLM代码产生和归因提供了新的方法
## Conclusion
实验表明Anubis能够在仅使用约2000个样本的情况下，高效地区分不同LLM生成的代码样本，通过提供一个零射击的归因方法，显著改进了代码生成的归因准确性。
# 450. `cs.LG` - Affective Priming Score: 一种检测顺序数据中先行效应的数据驱动方法 [PDF](https://arxiv.org/pdf/2506.20204), [HTML](https://arxiv.org/abs/2506.20204)
## Authors
Eduardo Gutierrez Maestro,Hadi Banaee,Amy Loutfi
## Background
情绪启动效应体现了情绪计算中的挑战性问题，即情绪的模糊性。尽管社区主要从标签视角出发解决这一问题，但先行效应对数据本身的影响，尤其是在生理信号中的影响仍被忽视。被先行效应影响的数据可能在情绪分类模型中导致误分类。这项研究旨在识别并减轻由先行效应引起的数据影响，以改善情绪计算模型的鲁棒性，为情感计算数据的设计和收集提供有价值见解，特别是在生理性情绪检测中更显著。
## Innovation
研究引入了Affective Priming Score (APS)，这是一种基于数据的方法，用于探测受先行效应影响的数据点。它通过给每个数据点赋予分数，量化其受先行效应影响的程度。通过应用于包含足够情绪事件转换的SEED和SEED-VII数据集，此方法证明了其有效性，与原始数据相比，使用去除了先行效应的序列数据训练模型可以显著减少误分类率。这一研究以数据层面降低了情绪计算中因模糊性导致的不确定性，增强了模型的鲁棒性，丰富了对情感计算数据的认识。
## Conclusion
研究贡献了去除了先行效应的数据集的训练方法，以减少情感计算中的误分类现象，这对于现有情绪数据源，尤其是生理信号的准确性至关重要。该研究通过具体实例提供了有效的方法来构建更准确和鲁棒情感计算模型，从而推动情感计算领域的进一步发展，对情绪计算中的数据准确性的提升具有重要价值。
# 451. `cs.LG` - Argumentative Ensembling for Robust Recourse under Model Multiplicity [PDF](https://arxiv.org/pdf/2506.20260), [HTML](https://arxiv.org/abs/2506.20260)
## Authors
Junqi Jiang,Antonio Rago,Francesco Leofante,Francesca Toni
## Background
在机器学习中，对于相同的预测任务，通常会获得多个表现相同的模型，例如通过不同的随机种子训练神经网络。模型多样性（MM）是指这些竞争模型对同一输入的预测结果不同，通常通过集成来确定输出的聚合。然而，在MM的情况下，通过反事实解释（CE）提供纠正建议变得复杂，因为CE可能不适用于所有模型，即CE在MM下缺乏鲁棒性。本文研究了在MM下提供纠正建议的问题，并提出了基于论证的集成方法来保证CE在MM下的鲁棒性。
## Innovation
本文提出了一种新的基于论证的集成方法，用于在模型多样性（MM）下提供鲁棒的纠正建议（Robust Recourse under Model Multiplicity，RAE）。该方法利用计算论证来明确表示模型和反事实之间的冲突，并使用论证语义来解决这些冲突，从而获得最终解决方案。此外，该方法还允许对MM下的模型进行偏好设定，以进一步定制集成。研究通过不同形式的论证语义对方法的行为进行了全面的理论分析，并通过实验验证了该方法在不同实例下满足期望特性的有效性。
## Conclusion
本文提出了基于论证的集成方法（RAE），在模型多样性下提供鲁棒的纠正建议，通过利用计算论证明确表示模型和反事实之间的冲突，并使用论证语义解决冲突获得最终解决方案。通过理论分析和实验验证，证明了该方法的有效性。
# 452. `cs.LG` - 用于作物病害检测的深度学习模型比较分析：一种迁移学习方法 [PDF](https://arxiv.org/pdf/2506.20323), [HTML](https://arxiv.org/abs/2506.20323)
## Authors
Saundarya Subramaniam,Shalini Majumdar,Shantanu Nadar,Kaustubh Kulkarni
## Background
本文研究旨在开发一种基于人工智能（AI）的作物疾病检测系统，以帮助资源有限的农村地区农民。研究汇集了不同的深度学习模型进行比较分析，重点关注这些模型在迁移学习中的效用。研究利用包括EfficientNet、ResNet101、MobileNetV2以及自定义的卷积神经网络（CNN）等深度学习模型，最终实现了高达95.76%的验证准确率，有效分类植物疾病。研究表明迁移学习在重塑农业实践、提高作物健康管理以及支持可持续农业中的潜力
## Innovation
研究创新点在于开发了一种基于人工智能的作物疾病检测系统，并进行了不同深度学习模型的比较分析，特别是在迁移学习方面的应用。通过自定义的CNN模型实现的高验证准确率进一步证明了该方法的有效性。
## Conclusion
该研究展示了迁移学习在农业实践中的潜力，有效提升了作物健康管理和支持可持续农业。未来可以进一步结合更多的深度学习模型和具体应用场景，更好地服务于农村地区的农业生产。
# 453. `cs.LG` - 有限示例中的超专家性能：双探索高效模仿学习 [PDF](https://arxiv.org/pdf/2506.20307), [HTML](https://arxiv.org/abs/2506.20307)
## Authors
Heyang Zhao,Xingrui Yu,David M. Bossens,Ivor W. Tsang,Quanquan Gu
## Background
模仿学习是强化学习中的一个核心问题，目标是学习一个政策来模仿专家的行为。实践中，由于状态空间的复杂性，从有限数量的演示中准确地学习专家策略常常是一项挑战。此外，为了超越专家的性能，还需要探索环境并收集数据。
## Innovation
本文提出了一种新颖的模仿学习算法——双重探索模仿学习（ILDE），该算法在两个方面实施探索：（1）通过探索奖金进行乐观政策优化，奖励具有高不确定性的状态-动作对，以潜在地提高对专家策略的收敛；（2）通过对偏离演示轨迹的状态进行好奇心驱动的探索，以潜在地产生超越专家的性能。实验证明，ILDE在样本效率上优于最新的模仿学习算法，并且在更少的演示下在Atari和MuJoCo任务中实现了超越专家的性能。本文还从理论上证明了ILDE作为具有乐观探索的不确定性和规制政策优化方法的有效性，导致遗憾的增长呈次线性增长。
## Conclusion
本文提出了ILDE算法，该算法能够从有限的演示中获得超越专家的性能。ILDE在样本效率和性能上优于现有方法，并提供了一种新的理论支持，证明了其有效性和优越性。
# 454. `cs.LG` - Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning [PDF](https://arxiv.org/pdf/2506.20324), [HTML](https://arxiv.org/abs/2506.20324)
## Authors
Torben Berndt,Benjamin Walker,Tiexin Qin,Jan Stühmer,Andrey Kormilitzin
## Background
动态图因其节点特征和网络结构的演变而表现出复杂的时序动态。Graph Neural Controlled Differential Equations (Graph Neural CDEs)通过将神经控制微分方程从欧几里得域上的路径扩展到图域上的路径，成功地适应了这一挑战。然而，尽管Graph Neural CDEs在理论上是有效的，但在实际应用中，参数量较大可能会影响模型的训练效率和泛化能力。
## Innovation
提出了Permutation Equivariant Neural Graph CDEs，这种方法将Graph Neural CDEs投影到置换不变函数空间，从而显著减少了模型的参数量而不牺牲表示能力，实现了更高效的训练和更好的泛化性能。
## Conclusion
通过模拟动态系统和实际任务的实验，实验证明了该方法在插值和外推场景中的优越性能。
# 455. `cs.LG` - 基于中等输入敏感性的函数学习：二维码解码案例研究 [PDF](https://arxiv.org/pdf/2506.20305), [HTML](https://arxiv.org/abs/2506.20305)
## Authors
Kazuki Yoda,Kazuhiko Kawamoto,Hiroshi Kera
## Background
函数的可学习性与其输入敏感性有关。图像分类任务对输入不敏感，即使有微小的噪音也不应影响分类结果；而最近引起广泛关注的算术和符号计算则是高度输入敏感的，因为每个输入变量都会影响计算结果。本研究以二维码解码为例，探讨中等输入敏感性的函数学习问题。团队通过实验发现，Transformer模型能够成功解码二维码，即使超出理论纠错极限也能完成任务，并且能够从英语训练数据推广到其他语言甚至随机字符串。研究还观察到，基于Transformer的二维码解码器主要依赖数据位而非纠错位进行解码，这与传统的二维码读取器工作原理不同。
## Innovation
首次提出了基于学习的二维码解码方法，并探讨了中等输入敏感性的函数学习。设计并实验验证了使用Transformer模型解码二维码，展示了其在高强度噪声条件下的鲁棒性和泛化能力。此外，研究发现了Transformer解码器的独特机制，即主要依赖数据位而不是传统纠错位进行解码，这为未来研究提供了一个新的方向。
## Conclusion
Transformer模型可以有效解码中等输入敏感性的函数，如二维码，并且具有强大的泛化能力。虽然它主要是基于数据位进行解码，但这种方法可能提供了对二维码解码机制的新见解。
# 456. `cs.LG` - 基于局部和全局特征融合的GNN有向边预测 [PDF](https://arxiv.org/pdf/2506.20235), [HTML](https://arxiv.org/abs/2506.20235)
## Authors
Yuyang Zhang,Xu Shen,Yu Xie,Ka-Chun Wong,Weidun Xie,Chengbin Peng
## Background
有向图分析中的边预测是一个经典的挑战，广泛应用于实际场景中。现有基于深度学习的方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻居信息。本文的背景在于探讨如何改进有向图中边预测的方法，提出了一种新的图神经网络框架，该框架能够融合特征嵌入和社区信息以提高预测性能。
## Innovation
本文创新之处在于提出了一种融合局部和全局特征的图神经网络框架。该框架通过理论证明，证明了结合特征嵌入和社区信息可以提升有向边预测任务的性能。另外，为了高效利用这些新的特征，作者还提出了一种方法将输入图转化为有向线图，使得图卷积能够更好地聚合信息。
## Conclusion
实验结果表明，在使用30%、40%、50%和60%的连接边作为训练数据时，本文的方法在多个基准数据集上均优于最先进的方法。
# 457. `cs.LG` - 顺序捆绑推荐中的生产者公平性 [PDF](https://arxiv.org/pdf/2506.20329), [HTML](https://arxiv.org/abs/2506.20329)
## Authors
Alexandre Rio,Marta Soare,Sihem Amer-Yahia
## Background
在顺序捆绑推荐的背景下，用户按顺序获得相关且兼容的物品集合。受现实场景的启发，研究聚焦于实现不同物品组在推荐会话期间面向用户的公平曝光。研究考虑解决随着用户到来实时解决的问题，并提出了一种精确解法来处理小实例问题。同时，还研究了两种启发式方法——以质量优先和公平优先——以及一种适应性变体来动态平衡捆绑公平性与质量。通过三个真实数据集的实验，验证了每种方案的优势及限制，并展示了在不牺牲捆绑质量的情况下提供公平推荐的能力。
## Innovation
提出了一种针对小规模问题的精确解法。同时研究了两种启发式方法——质量优先和公平优先——以及一种适应性变体，以动态平衡捆绑公平性和质量的关系。通过三个真实数据集的实验，验证了每种方法的优势及其效果。
## Conclusion
实验结果证明了每种解决方案的优势和局限性，在不牺牲捆绑质量的情况下提供了公平的推荐。
# 458. `cs.LG` - 在轨迹数据集中实现可解释性和效率的特征选择：一种分类学方法 [PDF](https://arxiv.org/pdf/2506.20359), [HTML](https://arxiv.org/abs/2506.20359)
## Authors
Chanuka Don Samarasinghage,Dhruv Gulabani
## Background
轨迹分析不仅仅是获取移动数据，更重要的是理解对象在空间和时间中的移动模式，以及预测其下一步移动。由于该领域引起了广泛关注，数据收集大幅提升，产生大量可用于训练和预测的新特征。但是，这引入了高维特征爆炸问题，降低了数据的效率和可解释性，从而降低了机器学习模型的准确性。
## Innovation
该文提出了一种基于分类学的特征选择方法，这种方法根据特征的内部结构将特征分类为几何特征和运动特征，进一步细分为曲率、凹痕、速度和加速度。相比而言，基于分类学的方法在预测性能上表现出一致的或更优的效果，并且通过减少组合空间，显著减少了特征选择所需时间。同时，这种方法还通过分类学组合作为了洞见哪个特征集对每个数据集更为敏感。其核心创新在于提供了一种新的特征选择方法，增强了模型的可解释性和效率，简化了决策过程。
## Conclusion
这项研究提供了强有力的证据，表明基于分类学的特征选择方法可以增强可解释性，降低数据维度，减少计算复杂度，并有助于高级决策。该研究为研究人员和处理轨迹数据集的从业者提供了一种方法论框架，也有助于推动可解释人工智能的发展。
# 459. `cs.LG` - 具有多变量并行注意机制的生成模型以生成神经活动 [PDF](https://arxiv.org/pdf/2506.20354), [HTML](https://arxiv.org/abs/2506.20354)
## Authors
Francesco Carzaniga,Michael Hersche,Abu Sebastian,Kaspar Schindler,Abbas Rahimi
## Background
在临床领域如颅内电生理图（iEEG）中，多变量时间序列数据的学习面临着巨大挑战。这些数据含有不同的通道配置，导致了挑战性的自注意力机制设计需求。以往的研究集中在单一时间序列或多通道信号的建模，而没有充分考虑到时间、内容和空间注意力的不同需求。为此，本文提供了一个大型的iEEG数据集，以支持进一步的研究，并提出了一种名为多变量并行注意力（MVPA）的新颖自注意力机制，该机制可以灵活、泛化地分析具有变化通道数量和配置的时间序列数据。
## Innovation
本文创造性地设计了一种多变量并行注意力（MVPA）机制，用于时间序列数据的建模，特别是在具有不同通道配置的多变量数据中。MVPA能够解耦内容、时序和空间注意力，增强了模型的自适应性和效率。基于MVPA，本文构建了一个新的人类电生理学生成基础模型，MVPA-Former，用于预测来自不同受试者iEEG信号的演变。研究结果表明，MVPA可以显著提高多种下游任务的效果，特别是在癫痫检测方面超越了最先进的模型。
## Conclusion
本文的贡献在于开发了一种泛化的多变量并行注意力机制，以及一个基于其构建的跨学科iEEG生成基础模型，该模型具有先进的临床应用表现。MVPA和MVPA-Former为未来研究提供了坚实的基础，通过公开的数据集、代码和模型，本文愿意与科研人员合作，共同推动这一领域的进展。
# 460. `cs.LG` - DipSVD: 双重要性保护的SVD方法用于高效的大语言模型压缩 [PDF](https://arxiv.org/pdf/2506.20353), [HTML](https://arxiv.org/abs/2506.20353)
## Authors
Xuan Ding,Rui Sun,Yunjian Zhang,Xiu Yan,Yueqi Zhou,Kaihao Huang,Suzhong Fu,Chuanlong Xie,Yao Zhu
## Background
大语言模型（LLMs）的计算需求和部署成本不断增加，推动了大量压缩方法的发展。虽然奇异值分解（SVD）压缩具有硬件兼容性和理论保证的优势，现有方法主要关注整体差异，忽视了对矩阵中关键部分的保护，导致压缩模型性能较低。因此，本文提出了一种双层重要性保护机制以增强SVD压缩方法，通过层加权数据去相关保护局部关键奇异向量，并通过启发式或优化方法分配压缩负担以最小化对关键层的影响。
## Innovation
提出了双层重要性保护机制，包括局部重要性保护和全局重要性保护。局部保护通过通道加权数据去相关来保留每个权重矩阵中最关键的奇异向量；全局保护通过启发式或优化方法分配压缩负担，使次要层承担更多的压缩负担，从而减小对关键层的影响。这种方法显著优于现有SVD压缩方法，特别是在高模型压缩比下的模型性能方面，实验结果在多个基准测试中得到了验证。
## Conclusion
本文提出的方法DipSVD在多个基准测试中表现优异，尤其是在高模型压缩比下的性能方面优于现有的SVD方法。该方法通过双层重要性保护机制显著提高了SVD压缩方法的效率和效果。
# 461. `cs.LG` - 多变量时间序列数据中深度神经网络学习格兰杰因果性的能力 [PDF](https://arxiv.org/pdf/2506.20347), [HTML](https://arxiv.org/abs/2506.20347)
## Authors
Malik Shahid Sultan,Hernando Ombao
## Background
格兰杰因果性提供了研究多变量时间序列数据之间关联性的优美统计框架。线性向量自回归模型虽然具有解释性质，但由于对其能够捕捉的关联类型的假设限制了其实用应用。文献中已经尝试利用深度神经网络的函数近似能力来估计格兰杰因果性，但这些方法将格兰杰因果性视为变量选择问题。本文提出了一种新的方法来处理格兰杰因果性问题，认为格兰杰因果性实质上与预测相关，通过使用深度学习模型集体或联合建模时间序列，一个恰当正则化的模型可以从数据中学习到真实的格兰杰因果结构，前提是训练数据量足够大。此外探讨了通过比较使用过去数据与排除特定时间序列成分的模型的预测不确定性或残差分布来揭示所学习的格兰杰因果结构的方法，以及输入层的dropout方法对神经网络学习格兰杰因果性能力的影响。研究表明，适当的正则化模型可以从数据中学习到真实的因果结构，而无需在损失函数中显式添加指导模型选择变量或进行稀疏回归的项。
## Innovation
本文提出了一种新的方法论，即通过学习预测模型来揭示格兰杰因果结构，而不是将其视为变量选择问题。特别地，通过比较使用完整历史数据和排除特定时间序列成分的模型的预测不确定性或残差分布来识别格兰杰因果结构，以及探讨了输入层dropout对神经网络估计格兰杰因果性能力的影响。这为基于神经网络估计格兰杰因果性提供了一种新视角。此外，通过适当的正则化，即使没有显式的稀疏回归项，也能够从数据中学习到真实的因果结构。
## Conclusion
适当的正则化深度学习模型可以从多变量时间序列数据中学习到真实的格兰杰因果结构，通过比较模型在不同情况下的不确定性或残差分布来揭示这种因果关系，而不需要在损失函数中显式添加引导模型选择变量的项。
# 462. `cs.LG` - 客户聚类与知识共享：增强个性化对等学习中的隐私性和鲁棒性 [PDF](https://arxiv.org/pdf/2506.20413), [HTML](https://arxiv.org/abs/2506.20413)
## Authors
Mohammad Mahdi Maheri,Denys Herasymuk,Hamed Haddadi
## Background
随着人工智能（AI）在物联网（IoT）生态系统中的应用日益广泛，对能够高效且私密地在异构、资源受限设备上运行的个性化学习方法的需求越来越紧迫。然而，要在去中心化的环境中实现有效的个性化学习引入了多个挑战，包括客户间高效知识转移、数据隐私保护以及抵御投毒攻击的脆弱性。该论文针对这些挑战，开发了一种名为P4的方法，以在资源受限的物联网设备上提供个性化模型，同时保证差分隐私和对恶意客户的抗攻击性。
## Innovation
该论文提出了一种名为P4的方法，通过轻量级全去中心化的算法，隐私地检测客户相似性并组成协作群体。在每组中，客户利用差分隐私的知识蒸馏协同训练其模型，保持高精度同时确保在恶意客户存在时的鲁棒性。此外，通过在不同异构设置和攻击场景下使用具有线性和CNN架构的流行基准数据集进行评估，展示了P4相较于现有差分隐私的对等学习方法在准确性和鲁棒性方面的优势。实验结果表明，P4在恶意客户占比30%的情况下仍能实现5%到30%的更高准确性。另外，还通过部署在资源受限的设备上展示了其实用性，两个客户之间的协同训练仅增加约7秒的开销时间。
## Conclusion
总之，该论文通过提出P4方法解决了去中心化环境下个性化学习中的关键挑战，提升了学习模型的隐私性和鲁棒性，并通过实验验证了其在实际应用中的实用性。
# 463. `cs.LG` - 未来非稳定环境下离策评估与学习 [PDF](https://arxiv.org/pdf/2506.20417), [HTML](https://arxiv.org/abs/2506.20417)
## Authors
Tatsuhiro Shimizu,Kazuki Kawamura,Takanori Muroi,Yusuke Narita,Kei Tateno,Takuma Udagawa,Yuta Saito
## Background
论文研究了非稳定环境下未来离策评估（F-OPE）和学习（F-OPL）的新问题，目标是通过历史数据估算和优化未来时不稳定的环境中的政策价值。特别是在电子商务推荐中，评估和优化未来一个月政策价值通常需要使用上一个月旧政策收集的数据，但未来数据并未在历史数据中出现，这使得现有的方法假设稳定环境或依赖于限制性的奖励建模假设，导致了显著的偏差问题。
## Innovation
提出了一个名为OPFV的新型估计算法，该算法通过引入时间序列数据中的有用结构，能够在未来数据不存在的情况下，利用季节性、每周周期或节假日效应进行有效评估。此外，还提出了一种新的策略梯度方法，可以根据历史数据制定未来优化策略。理论上分析了OPFV在低偏差条件下的适用性。实验结果表明，该方法在各种实验设定下显著优于现有的方法，尤其是在非稳定环境下估计和优化未来政策值方面有明显改进。
## Conclusion
本文提出了一种新颖的评估和学习未来不稳定性环境下政策价值的方法，通过利用时间序列中的一致效应，解决了现有方法在非稳定环境中的不足。新的OPFV算法和策略梯度方法在非稳定实验场景中显示出更高的准确性和有效性。
# 464. `cs.LG` - 通过频谱自助和拉普拉斯基增广的自我监督图学习 [PDF](https://arxiv.org/pdf/2506.20362), [HTML](https://arxiv.org/abs/2506.20362)
## Authors
Lorenzo Bini,Stephane Marchand-Maillet
## Background
当前的自我监督图学习框架通常需要负面样本，这增加了复杂性和计算成本；现有的方法依赖对比学习目标或手工设计的增强技术，这可能限制了特征的表达能力和学习效率。文献中提出了利用谱自助技术构建新型自我监督图学习框架LaplaceGNN，通过拉普拉斯基信号增强学习过程，设计了一种无需负面样本的图学习方法，简化了自我监督图学习，提高了学习效率并适用于多种领域背景的问题。
## Innovation
LaplaceGNN通过谱自助技术预计算谱增强，利用最大-最小中心性指导优化，实现了不依赖于手工设计增强，增加了结构监督信息。该方法引入了一种对抗性自助训练方案，进一步加强了特征学习和鲁棒性。相对于现有方法，LaplaceGNN实现了线性扩展，提供了更简单高效的自我监督图神经网络替代方案，适用于多种领域。其在不同基准数据集上的实验证明了LaplaceGNN在自我监督图方法中的优越性能，为高效学习丰富图表示提供了新方向
## Conclusion
LaplaceGNN实现了自我监督图学习的有效性和高效性，通过谱自助和拉普拉斯基增强技术，提供了无需依赖负面样本的学习框架，增强了特征表达能力和学习的鲁棒性，适用于多种领域图学习的场景。
# 465. `cs.LG` - 通过不公平聚合的知识蒸馏解决联邦学习中的数据异质性 [PDF](https://arxiv.org/pdf/2506.20431), [HTML](https://arxiv.org/abs/2506.20431)
## Authors
Xing Ma
## Background
联邦学习的目的是在一个接近集中式训练性能的分布式环境中训练全局模型，但客户标签偏差、数据量偏差和其他异质性问题严重影响了模型的性能。大多数现有方法忽略了只有少量客户端参与大规模客户端环境中的训练情况，而我们的实验表明，这种情况下的联邦学习任务更具挑战性。因此，提出了一种名为知识蒸馏与教师-学生不公平聚合（KDIA）的策略，以有效利用所有客户端的知识。KDIA 在本地训练过程中进行自知识蒸馏，并利用服务器上训练的生成器生成近似独立同分布的特征用于辅助训练。
## Innovation
提出了知识蒸馏与教师-学生不公平聚合（KDIA）策略，该策略通过平均聚合参与客户端的学生模型和基于参与间隔、参与次数和数据量比例加权聚合的教师模型来解决联邦学习中的数据异质性问题，从而可以更有效地利用所有客户端的知识，并通过生成器生成近似独立同分布的数据特征进行辅助训练。
## Conclusion
在CIFAR-10/100/CINIC-10数据集和各种异质设置的广泛实验中，KDIA方法能够在更低的训练轮数中获得更高的准确性，并在严重异质性条件下表现出更显著的改进。
# 466. `cs.LG` - 基于残差Hessian的PINNs积分近似 quadrature method for the PINNs based on the residual Hessian [PDF](https://arxiv.org/pdf/2506.20441), [HTML](https://arxiv.org/abs/2506.20441)
## Authors
Antoine Caradot,Rémi Emonet,Amaury Habrard,Abdel-Rahim Mezidi,Marc Sebban
## Background
物理信息神经网络(PINNs)通过将物理模型嵌入损失函数并在所谓的插值点上使用自动微分最小化残差来学习PDE的近似神经求解器。这些插值点最初是均匀抽样的，但最近的研究表明，选择插值点的方法对其性能至关重要，并已经开发了适应性抽样改进方法。基于此背景，本文提出了一种新的基于所考虑函数Hessian的积分近似方法，并将其应用于指导PINNs训练过程中插值点的选择。
## Innovation
提出了基于所考虑函数Hessian的新的积分近似方法，并将其应用于指导PINNs训练过程中插值点的选择，改进了传统均匀抽样的方法，可能提高模型的精度和效率。
## Conclusion
通过引入基于Hessian的新积分近似方法，该研究扩展了PINNs插值点选择的方法，并在提高模型性能方面取得了实际应用的潜力。
# 467. `cs.LG` - TESSERA: 时间表面光谱的时序嵌入用于地球表示和分析 [PDF](https://arxiv.org/pdf/2506.20380), [HTML](https://arxiv.org/abs/2506.20380)
## Authors
Zhengpeng Feng,Sadiq Jaffer,Jovana Knezevic,Silja Sormunen,Robin Young,Madeline Lisaius,Markus Immitzer,James Ball,Clement Atzberger,David A. Coomes,Anil Madhavapeddy,Andrew Blake,Srinivasan Keshav
## Background
卫星遥感（RS）及其下游地球观测（EO）应用，如气候建模、碳计量、保护和可持续土地利用策略，得到了广泛应用。然而，目前对时间序列卫星数据的处理主要依赖于传统的遥感基线模型，这些模型通常性能有限且分辨率较低。TESSERA提出了一种新的遥感基础模型（RSFM），利用自我监督学习（SSL）从光谱和合成孔径雷达（SAR）数据流的像素级时间序列中生成10米尺度的全球鲁棒表示。
## Innovation
TESSERA模型采用两种并行的Transformer编码器，分别处理Sentinel-1 SAR极化数据和Sentinel-2多光谱成像（MSI）数据的10个选定波段，然后通过多层感知器（MLP）融合生成表示。该模型突破了传统的遥感基线和领先的地理空间基础模型，通过开放源代码方式促进了高性能高分辨率表示的使用，并在五个不同的任务中展示了其优越性能。
## Conclusion
TESSERA在各种下游任务中表现出色，打破了现有基准，并通过开放源代码推动了高性能高分辨率表示的普及。
# 468. `cs.LG` - 基于LLM的表数据分类中自动演示选择 [PDF](https://arxiv.org/pdf/2506.20451), [HTML](https://arxiv.org/abs/2506.20451)
## Authors
Shuchu Han,Wolfgang Bruckner
## Background
应用In-Context Learning（ICL）进行表数据分类时，一个基本问题是如何确定提示中理想数量的演示。现有的方法多采用随机选择，但这些方法并未考虑到表数据分布、用户选择的提示模板以及特定的大语言模型（LLM）这些因素。这项工作通过提出一种算法解决了这一挑战，该算法能够自动选择合理数量的演示数据.
## Innovation
该方法通过结合表数据的分布、用户选择的提示模板以及特定的大语言模型（LLM）进行估计。它基于谱图理论，定义了新颖的相似度量化指标，并通过构建相似度图和分析其拉普拉斯算子的特征值，得出具有代表性的最小演示数量，从而在LLM的固有表示空间内表达数据。这种方法通过与传统随机选择算法在不同数据集和LLM上的实验验证了其有效性.
## Conclusion
本文提出的方法能够自动选择合理的演示数量，通过实验证明其优于传统的随机选择算法。这种方法考虑了表数据的分布、用户选择的提示模板和特定大语言模型，使ICL在表数据分类的应用更加精确和高效.
# 469. `cs.LG` - 联邦学习中协作性批量大小优化 [PDF](https://arxiv.org/pdf/2506.20511), [HTML](https://arxiv.org/abs/2506.20511)
## Authors
Arno Geimer,Karthick Panner Selvam,Beltran Fiz Pontiveros
## Background
联邦学习（FL）是一种分散化的协作机器学习框架，用于训练模型而不将数据收集到单一中心位置。它已被应用于多个领域，例如帮助医院进行医学诊断和检测金融交易欺诈等。尽管参与者可能共享用于训练的硬件资源，但由于没有信息交换，他们的训练过程可能会因不恰当的训练配置而受阻。利用联邦学习固有的并行处理特性，本研究利用贪婪随机搜索优化所有参与者的本地批量大小，以获得最佳的训练设置。研究表明，与默认参数设置相比，该方法能够加速收敛速度，同时在局部参数优化情况下保持相近的性能水平。
## Innovation
本研究提出了一种利用贪婪随机搜索优化联邦学习中本地批量大小的方法，旨在提高本地训练过程的效率，并通过实验证明该方法在默认参数设置下能够显著加速收敛速度，同时与局部参数优化的情况保持了相近的性能。
## Conclusion
该研究通过贪婪随机搜索优化了联邦学习中的本地批量大小，从而提高了模型训练的收敛速度，且在性能方面接近于局部参数单独优化的场景。
# 470. `cs.LG` - WallStreetFeds: 客户特定代币作为联邦学习中的投资工具 [PDF](https://arxiv.org/pdf/2506.20518), [HTML](https://arxiv.org/abs/2506.20518)
## Authors
Arno Geimer,Beltran Fiz Pontiveros,Radu State
## Background
联邦学习（FL）是一种协作机器学习范式，允许参与者在训练数据保持私密的情况下共同训练模型。特别是在对数据隐私、安全性和模型性能有严格要求的金融领域，FL显得尤为有益。自提出以来，FL已经得到了广泛的研究，包括改进的合作技术、防御手段以及贡献评估方法。而对于盈利性联邦学习而言，发展激励方法以确定奖励分配对于参与者来说是一项重要任务，尽管已经提出并详细研究了众多分配方法，但在奖励的分发框架上仍然相对探索较少，因此本文提出了一个新颖的框架，引入了客户特定代币作为激励工具，旨在通过分散型金融平台和自动化做市商为参与者提供更加灵活和可扩展的奖励分发系统，同时也为第三方提供了参与联邦学习过程的机制。
## Innovation
本文提出了一种新的框架，将客户特定代币作为联邦学习中的投资工具。该框架通过分散型金融（DeFi）平台和自动化做市商（AMMs）为参与者提供了一种更具灵活性和可扩展性的奖励分配系统，同时为第三方提供了投资联邦学习过程的机制，解决了现有激励机制中的不足。
## Conclusion
本文提出的框架通过引入客户特定代币，利用分散型金融平台和自动化做市商，为参与者提供了一种更加灵活和可扩展的奖励分配系统，并允许第三方投资于联邦学习过程，从而增强了联邦学习中的激励机制。
# 471. `cs.LG` - 作为分布性量的反事实影响 [PDF](https://arxiv.org/pdf/2506.20481), [HTML](https://arxiv.org/abs/2506.20481)
## Authors
Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye
## Background
机器学习模型在训练数据中记住了样本，引起了隐私和泛化能力的担忧。反事实自影响是一个用来研究记忆力的流行指标，它量化了模型对样本的预测会因样本是否包含在训练数据集中而如何变化。最新的研究指出，记忆不仅受自影响的影响，其他训练样本特别是（近）复制样本有更大的影响。该论文通过将反事实影响视为分布量来研究记忆力，探讨了所有训练样本如何影响特定样本的记忆过程，特别是对于一个小语言模型，计算训练样本相互影响的全影响分布并分析其特性。研究表明，仅仅关注自影响会低估记忆带来的实际风险，（近）复制样本会显著降低自影响，但这些样本可以（近）被提取。在图像分类（例如CIFAR-10）中，影响分布简单分析也能揭示（近）复制样本的存在。这项研究揭示了记忆力源于训练数据间的复杂交互，全影响分布比自影响更能捕捉这一现象。
## Innovation
引入反事实影响作为分布性量的概念，首次将所有训练样本对特定样本影响的统计分布视为一个整体进行研究，以全面理解记忆力的本质。该研究通过计算和分析小语言模型和图像分类模型的训练样本全影响分布，揭示了（近）复制样本对记忆力的影响机制。这项研究提供了一种更精确地评估模型记忆力的方法，扩展了现有研究对记忆力的理解，为防止模型记忆带来的隐私和泛化问题提供了新的视角。
## Conclusion
该研究强调，记忆源于训练数据间的复杂交互，而不仅仅是自影响，全影响分布比自影响更能体现记忆力。对于（近）复制样本虽降低了自影响，但其仍可（近）被提取的事实，进一步说明了记忆的风险。
# 472. `cs.LG` - 由有限元分析调节的物理信息机器学习在激光粉末床融合并加速模拟中的应用 [PDF](https://arxiv.org/pdf/2506.20537), [HTML](https://arxiv.org/abs/2506.20537)
## Authors
R. Sharma,M. Raissi,Y.B. Guo
## Background
传统的数值方法如有限元分析（FEA）在激光粉末床融成（LPBF）过程中的热场预测中由于耗时问题存在计算成本高的问题，因此高效模拟LPBF对于过程预测至关重要。
## Innovation
提出了一种称为FEA-调节物理信息神经网络（FEA-PINN）的高效建模框架，该框架通过动态材料更新策略捕获粉末-液-固相变，采用显热容方法结合温度依赖的材料属性和相变行为，同时通过集成推理期间的纠正FEA仿真确保物理一致性并降低误差漂移，从而加速热场预测。此框架在单道扫描中经过验证，并且通过基准FEA数据表明其在显著降低计算成本的情况下达到了与FEA相当的精度。
## Conclusion
FEA-PINN 框架实现了与传统 FEA 相当的精度但显著降低了计算成本，通过框架的有效实验证明了其在 LPBF 过程模拟中的应用潜力。
# 473. `cs.LG` - 用于向量搜索的图索引的内核 [PDF](https://arxiv.org/pdf/2506.20584), [HTML](https://arxiv.org/abs/2506.20584)
## Authors
Mariano Tepper,Ted Willke
## Background
传统的向量搜索图指标使用计算几何原理构建图，但只能在欧几里得空间内提供形式化的图导航保证。本文旨在探索通过机器学习构建可以在度量和非度量向量空间（内积相似性）中使用的图索引的方法，包括支持向量图（SVG）及其新特性.
## Innovation
引入了支持向量图（SVG），这是一种利用核方法建立图连通性的新型图指标，适用于度量和非度量向量空间。并解释了HNSW和DiskANN等流行指标是SVG的特例，从而可以从中推导出新的指标。此外，SVG-L0结合了ℓ0稀疏约束来构建拥有限制出度的图，这提供了一种实现此实际需求的原理，并具有自调优特性，避免了现有方法的启发式过程.
## Conclusion
本文提出了SVG-L0，克服了传统用节点出边直接截断的方法，通过自调优特性避免了启发式方法，同时保持了计算复杂度，为向量空间搜索提供了新的图索引方法.
# 474. `cs.LG` - 异步REINFORCE在离策略强化学习中的应用：平衡正负奖励 [PDF](https://arxiv.org/pdf/2506.20520), [HTML](https://arxiv.org/abs/2506.20520)
## Authors
Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos
## Background
强化学习（RL）近年来被广泛用于对大型语言模型（LLMs）进行对齐。离策略方法在实现和数据效率方面优于在策略技术，但往往导致次优性能。本文通过分析简单离策略REINFORCE算法研究了介于离策略RL和监督微调之间的算法范围，这种方法中优势定义为 $A=r-V$，其中 $r$ 是奖励，$V$ 是可调整的基线。降低 $V$ 强调高奖励样本，而提高它则更倾向于惩罚低奖励样本。我们首先对该离策略REINFORCE算法进行了理论分析，证明当基线 $V$ 降低奖励期望的下限时，该算法具有政策改进保证。研究表明，虽然在策略更新可以安全地利用正负信号，但离策略更新更加重视正奖励而不是负奖励。我们通过在受控的随机臂测试环境中进行实验性验证，以及在推理任务上对最先进的LLMs进行微调，验证了这些发现。
## Innovation
本文通过分析一个简单的离策略REINFORCE算法，研究了介于离策略RL和监督微调之间的算法范围，首次证明了当基线低于奖励期望的下限时，算法具有政策改进的保证。并且理论分析显示，离策略更新相对于在策略更新更侧重于正奖励，而不是负奖励。这些理论和实验证据共同提出了对离策略算法进行新的理解与应用的方法。
## Conclusion
研究证明，在适当的基线调节下，离策略算法可以有效提升模型性能并更侧重于正奖励。本文的方法为离策略强化学习算法在这中间间隔的有效实践和理论理解提供了新的方向。
# 475. `cs.LG` - 多变量时间序列无监督异常检测策略基准测试 [PDF](https://arxiv.org/pdf/2506.20574), [HTML](https://arxiv.org/abs/2506.20574)
## Authors
Laura Boggia,Rafael Teixeira de Lima,Bogdan Malaescu
## Background
多变量时间序列异常检测在医疗、金融服务、制造业或物理检测监控等多个领域中是重要的问题。准确识别意外错误或故障的发生至关重要，但由于异常的未知性质和时间序列维度之间的复杂相互依赖性，这一任务具有挑战性。本文研究了基于变压器的时间序列异常检测方法，重点关注最近提出的iTransformer架构的应用并分析了关键参数（如窗口大小、步长和模型维度）对性能的影响；探讨了从多维异常得分中提取异常标签的方法，并讨论了此类标签的适当评估指标；研究了在训练期间出现的异常数据的影响，并评估了替代损失函数的有效性；提出了对几种基于变压器的模型在一个多样化的时间序列异常检测数据集上的全面比较。
## Innovation
本文首次将iTransformer架构应用于时间序列异常检测，并详细分析了窗口大小、步长和模型维度等关键参数对性能的影响；探讨了多种从多维异常评分中提取异常标签的方法，并提出了合适的评估指标；研究了异常数据在训练过程中对模型的影响，并评估了不同损失函数的消减作用；并且进行了一次全面的基于变压器的时间序列异常检测模型比较研究。
## Conclusion
本文对几种基于变压器的时间序列异常检测模型进行了全面的比较，并通过实验得出了结论：不同模型和参数设置对异常检测性能的影响，提取异常标签的最佳方法，以及不同的损失函数在缓解训练中出现的异常数据影响方面的效果。这将为实际应用中选择适当的异常检测策略提供了有价值的参考。
# 476. `cs.LG` - 使用数字孪生生成的数据集和高效数据增强的工业能源细分 [PDF](https://arxiv.org/pdf/2506.20525), [HTML](https://arxiv.org/abs/2506.20525)
## Authors
Christian Internò,Andrea Castellani,Sebastian Schmitt,Fabio Stella,Barbara Hammer
## Background
工业非侵入式负荷监测（NILM）受到高质量数据集稀缺和工业能源消耗模式复杂多变的限制。为解决数据稀缺性和隐私问题，本文提出了一种名为Synthetic Industrial Dataset for Energy Disaggregation（SIDED）的开源数据集，该数据集基于数字孪生模拟生成。SIDED涵盖了来自三个不同地理位置的三种类型的工业设施，这些设施捕获了多种电器行为、天气状况和负荷特征。同时，本文还提出了一种称为Appliance-Modulated Data Augmentation（AMDA）的方法，这是一种计算效率高的数据增强技术，通过智能调整电器功率贡献的比例，增强了NILM模型的泛化能力。
## Innovation
本文引入了SIDED数据集和AMDA方法。SIDED利用数字孪生技术生成，涵盖了不同类型和不同地理位置的工业设施，解决数据稀缺性和隐私问题。AMDA方法通过智能化地调整电器功率贡献，增强NILM模型的泛化能力，特别提高了复杂工业电器的负荷细分效果。
## Conclusion
实验结果表明，使用AMDA增强的数据训练的NILM模型在分解复杂工业电器如热电联产系统的能耗方面表现显著。具体而言，在样本外场景中，使用AMDA训练的模型的归一化负荷分解误差为0.093，优于未使用数据增强的模型（0.451）和使用随机数据增强的模型（0.290）。数据分析证实，AMDA有效对齐了训练数据和测试数据分布，提高了模型的泛化能力。
# 477. `cs.LG` - 多模态表示学习与融合 [PDF](https://arxiv.org/pdf/2506.20494), [HTML](https://arxiv.org/abs/2506.20494)
## Authors
Qihang Jin,Enze Ge,Yuhang Xie,Hongying Luo,Junhao Song,Ziqian Bi,Chia Xin Liang,Jibin Guan,Joe Yeong,Junfeng Hao
## Background
多模态学习是人工智能领域发展迅速的领域。通过结合来自不同来源的信息，如图像、文本和音频，多模态学习旨在帮助机器更好地理解复杂事物，从而建立更强、更丰富的内部表示。这种学习方法使AI系统能够在真实场景中更好地进行解释、推理和决策。该领域包括核心技术，如表示学习（从不同类型的数据中获取共享特征）、对齐方法（在网络模态间匹配信息）和融合策略（通过深度学习模型进行结合）。尽管已经取得了一定的进步，但仍面临数据格式、缺失或不完整的输入以及对抗攻击等重大问题。研究人员正在探索新的方法，如无监督或半监督学习、自动机器学习工具，以提高模型的效率并使其更容易扩展。同时，对于设计更好的评估指标或构建共享基准的关注也越来越多，以便在不同任务和领域中更容易地比较模型性能。未来，多模态学习有望改善计算机视觉、自然语言处理、语音识别和医疗保健等多个领域，可能会帮助构建更像人类理解世界的AI系统，更加灵活、了解上下文且能够处理现实世界的复杂性。
## Innovation
研究人员正在探索新的方法，如无监督或半监督学习、自动机器学习工具，以提高模型的效率并使其更容易扩展。同时，对于设计更好的评估指标或构建共享基准的关注也越来越多，以便在不同任务和领域中更容易地比较模型性能。
## Conclusion
随着该领域的发展，多模态学习有望在计算机视觉、自然语言处理、语音识别和医疗保健等多个领域得到改进。未来，它可能会帮助构建类似于人类理解世界的AI系统，更加灵活、了解上下文且能够处理现实世界的复杂性。
# 478. `cs.LG` - 探索图变换器在分布外泛化能力 [PDF](https://arxiv.org/pdf/2506.20575), [HTML](https://arxiv.org/abs/2506.20575)
## Authors
Itay Niv,Neta Rabin
## Background
基于图的深度学习在社交网络、生物物理学、交通网络和推荐系统等多个领域取得了显著成功。然而，当前方法通常假设训练和测试数据具有相同的数据分布，而在实际场景中这一假设很少成立。尽管图变换器（GT）的底层结构在多个数据分布符合的基准测试中已表现出优于传统消息传递神经网络（MPNN）的效果，但在数据分布发生变化时的泛化能力仍待探讨。因此，本文致力于解决图神经网络在分布外（OOD）泛化问题，尤其是关注底层结构对泛化能力的影响。通过设计基准测试来检验不同分布变化的情况，本文评估了图变换器及其与MPNN的混合模型在OOD场景下的泛化能力。研究发现，图变换器和混合模型的泛化能力优于传统MPNN，即使不使用专门的域泛化算法也可以实现更好的效果。此外，本文提出了一种新的后训练分析方法，通过比较整个ID和OOD测试数据集的聚类结构，进行领域对齐和类别分离的分析，这种分析方法展示了其无模型依赖性，为解决包括图学习在内的更广泛的域泛化问题提供了新的视角，有助于更深入理解泛化能力。
## Innovation
本文率先全面评估了图变换器及其混合模型的分布外（OOD）泛化能力，通过广泛适应现有的域泛化算法并与传统MPNN进行对比，展示了图变换器的优越泛化性能。提出了一个无模型依赖性的后训练分析方法，通过比较整个分布内（ID）和分布外（OOD）测试数据集的聚类结构，来研究聚类的领域对齐和类别分离，深入理解模型的泛化能力。
## Conclusion
研究成果表明，图变换器能够在一些传统假设不成立的分布外场景中表现出色，这意味着其在未来大规模应用中的泛化能力展现出巨大潜力。同时，为解决领域泛化问题提供了新的架构思路与分析工具，为今后的研究指明了方向。
# 479. `cs.LG` - 在闭环学习中迷失：指数族模型在闭环学习下参数空间的探索 [PDF](https://arxiv.org/pdf/2506.20623), [HTML](https://arxiv.org/abs/2506.20623)
## Authors
Fariba Jangjoo,Matteo Marsili,Yasser Roudi
## Background
闭环学习是指通过从该模型生成的数据反复估计模型的过程。这一概念越来越受到关注，因为未来的大规模神经网络模型可能主要通过由人工神经网络生成的数据进行训练。本文研究了指数族模型在闭环学习过程中的行为，推导出了参数动态的方程，并分析了闭环学习过程中的收敛和偏差放大现象。
## Innovation
本文作者通过研究指数族模型在闭环学习过程中的动态方程，揭示了最大似然估计赋予充分统计量鞅性质的特点，并表明该过程会收敛到放大初始数据偏差的吸收状态。此外，作者证明了通过添加一小部分来自固定模型生成的数据点、使用最大后验估计或引入正则化可以防止这种结果。同时，文章还指出，动力学的渐近行为不是重参数化的不变性。
## Conclusion
闭环学习中的指数族模型的偏差放大现象可以通过添加少量的随机生成数据点、采用最大后验估计方法或引入正则化措施来避免。同时，闭环学习的动力学行为不是重参数化的不变性。
# 480. `cs.LG` - Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices [PDF](https://arxiv.org/pdf/2506.20644), [HTML](https://arxiv.org/abs/2506.20644)
## Authors
Hangyu Li,Hongyue Wu,Guodong Fan,Zhen Zhang,Shizhan Chen,Zhiyong Feng
## Background
随着隐私保护变得越发重要，越来越多的模型在边缘设备上进行训练，并通过联邦学习（FL）迁移到中央服务器。然而，当前的研究并未注意到网络拓扑、物理距离和数据异质性对边缘设备的影响，这导致了诸如延迟增加和模型性能下降等一系列问题。
## Innovation
提出了一种新的边缘设备联邦学习方案，称为带加密数据共享的联邦学习（FedEDS）。FedEDS利用客户模型和模型的随机层来训练数据加密器，数据加密器生成加密数据并与其它客户共享。客户使用对应的客户随机层和加密数据来训练和调整本地模型。FedEDS利用客户本地的私人数据以及其他客户加密共享的数据来训练模型，此方法加速了联邦学习的训练收敛速度，减轻了数据异质性带来的负面影响，适用于要求快速收敛的边缘设备应用服务部署场景。
## Conclusion
实验结果表明，FedEDS在提升模型性能方面具有显著效果。
# 481. `cs.LG` - PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models [PDF](https://arxiv.org/pdf/2506.20629), [HTML](https://arxiv.org/abs/2506.20629)
## Authors
Soufiane Hayou,Nikhil Ghosh,Bin Yu
## Background
Low-Rank Adaptation (LoRA) 是一种广泛使用的大型模型微调方法，具有小内存占用，允许在低成本下适应大型模型到特定任务。不同的修改提出了增强其效率的方法，例如设置学习率、秩和初始化。另一个改进轴是适配器放置策略：在使用 LoRA 时，通常选择模块类型进行 LoRA 调整，例如 Query 和 Key 模块。极少有研究探讨适配器放置问题，现有结果不一：原始 LoRA 论文建议放置在注意力模块，而其他研究建议放置在 MLP 模块中。
## Innovation
文章通过直观的理论分析，引入了一种轻量级方法 PLoP (Precise LoRA Placement)，能够在给定预训练模型和微调任务的情况下自动识别应放置 LoRA 适配器的模块类型。实验表明，PLoP 在分类和强化学习推理的全面实验中始终优于常用放置策略，最糟糕的情况下也能匹敌这些策略。
## Conclusion
PLoP 是一种轻量级方法，能够自动识别适用于特定任务的 LoRA 适配器放置位置，证明了其在监督微调和推理任务中的强大性能。
# 482. `cs.LG` - 基于实际数据的UCB方法在技能型队列中的有效路由演示 [PDF](https://arxiv.org/pdf/2506.20543), [HTML](https://arxiv.org/abs/2506.20543)
## Authors
Sanne van Kempen,Jaron Sanders,Fiona Sloothaak,Maarten G. Wolf
## Background
本文探讨了最优控制技能型排队系统的问题，这些系统包括数据中心、云计算网络和服务系统。通过使用真实世界的数据集对最近开发的强化学习算法进行案例研究，旨在调查其实际应用中的客户路由策略的有效性。实验结果表明，该算法表现出良好的学习能力和环境适应性，并且优于静态基准策略，表明其在实际运行中的潜力。此外，还提出了一个新的启发式路由规则以减少延迟，使得该算法具有更广泛的实用性。进一步表明，该算法能够优化多重目标，通常包括收益最大化及次级目标，如服务负载公平性与客户等待时间的减少，使用调优参数对固有的性能折衷进行平衡。研究还考察了估计误差和参数调优的敏感度，为实现复杂真实世界排队系统的自适应路由算法的实施提供了有价值见解。
## Innovation
本文中提出了一种基于实际数据的应用和扩展优化技能型队列的强化学习算法。通过将一种新的启发式路由规则引入到算法中来减少延迟，增强算法的实用性。此外，该算法还能够同时优化多个目标，即不仅仅关注收益最大化，还能包括服务负载公平性和客户等待时间的减少，通过调优参数来权衡这些目标之间的性能折衷。研究还详细分析了估计误差和参数调优的敏感性，为在复杂数字环境中实施自适应路由算法提供了参考依据。
## Conclusion
实验结果表明，强化学习算法能够高效地学习和适应不断变化的环境，并且相较于静态基准策略，该算法的表现更为出色。新提出的启发式路由规则进一步提升算法在现实应用中的效果。算法能够同时优化多重目标，体现了其在实际操作中的灵活性。最后，本研究还考察了决策过程中可能出现的相关问题，如参数调优的敏感性和估计误差的影响，为未来的研究和实际应用提供了有价值的观点。
# 483. `cs.LG` - H-FEX: 一种用于哈密顿系统符号学习的方法 [PDF](https://arxiv.org/pdf/2506.20607), [HTML](https://arxiv.org/abs/2506.20607)
## Authors
Jasen Lai,Senwei Liang,Chunmei Wang
## Background
哈密顿系统描述了一个由哈密顿函数支配的广泛的动态系统种类，这些函数编码了系统的总能量并决定了系统的演化。数据驱动的方法，如符号回归和基于神经网络的方法，提供了一种直接从哈密顿系统观测数据中学习支配方程的手段。然而，这些方法在准确捕捉复杂的哈密顿函数时往往难以保待能量守恒。
## Innovation
我们提出了有限表达方法（H-FEX）用于学习哈密顿系统，这是一种符号学习方法，通过引入新颖的交互节点来有效捕捉复杂交互项。实验结果显示，H-FEX 能够恢复出能够精确描述复杂系统动态并保持长期能量守恒的哈密顿函数。这突显了H-FEX作为一种强大的框架，用于发现复杂动态系统的封闭形式表达式的能力。
## Conclusion
实验结果表明H-FEX可以准确捕捉复杂哈密顿系统的动力学并长期保持能量守恒，突显了其在发现复杂动态系统封闭形式表达式方面的潜在应用价值。
# 484. `cs.LG` - 掌握多专家路由：实现实现的H-一致性及强学习保证 [PDF](https://arxiv.org/pdf/2506.20650), [HTML](https://arxiv.org/abs/2506.20650)
## Authors
Anqi Mao,Mehryar Mohri,Yutao Zhong
## Background
多专家推理的学习问题包括最优地将输入实例分配给专家，同时平衡其准确性和计算成本之间的权衡。这是一个关键挑战，特别是在自然语言生成领域，但也适用于图像处理和医学诊断等领域。近期研究提出了代理损失函数来优化推诿，但仍存在一致性性质的一致性问题。
## Innovation
本论文引入了新颖的代理损失函数并提出了高效算法，这些算法具有强大的理论学习保证。对于单阶段推诿问题，引入了一组新的实现的H-一致代理损失，并进一步证明了选定成员的一致性。对于两阶段推诿问题，推导出了新的代理损失，这些损失在双专家场景下实现了实实现的H-一致性、H-一致界限，以及在自然假设下多专家场景下的贝叶斯一致性。此外，在低噪声假设下提供了两种场景下的增强理论保证。
## Conclusion
最终，在使用提出的代理损失进行实验的结果中，我们比较了它们与现有基准的性能。
# 485. `cs.LG` - 听而不闻：检测联邦学习中恶意服务器的梯度泄漏 [PDF](https://arxiv.org/pdf/2506.20651), [HTML](https://arxiv.org/abs/2506.20651)
## Authors
Fei Wang,Baochun Li
## Background
近期研究显示，联邦学习（FL）中的梯度更新可能会无意中泄漏用户的敏感信息。当恶意服务器操控全局模型促使客户端生成信息丰富的更新时，这种风险更为严重。本文从防御者的视角，首次全面分析了恶意梯度泄漏攻击及其使其实现的技术方法。研究表明，这些攻击存在核心权衡：有效恢复私有数据的能力与能够足够隐蔽以逃避检测（尤其是在包含常见归一化技术与联邦平均的现实FL场景中）。
## Innovation
本文提出了利用基本监控手段检测恶意梯度泄漏攻击的思想，并设计了一种简单、轻量且广泛适用的客户端检测机制，在本地训练开始前识别可疑的模型更新。尽管在现实的FL场景并不严格必要，但这一机制强化了即使有微不足道的开销也能有效防御这些攻击的可行性，并为隐私保护的联邦学习系统提供了一个可部署的保障措施。
## Conclusion
即使在理论上诸如恶意梯度泄漏攻击等问题令人担忧，实际中这种攻击往往受到其内在限制并易于检测。本文还提供了一种轻量级且通用的客户端侧检测机制，可以在不需要严格严格必要性的情况下提前标记出可疑的模型更新，进一步证明了通过轻微的资源投入能够有效抵御这些攻击。
# 486. `cs.LG` - 监督学习中的 firm 联系相似性 [PDF](https://arxiv.org/pdf/2506.19856), [HTML](https://arxiv.org/abs/2506.19856)
## Authors
Ryan Samson,Adrian Banner,Luca Candelori,Sebastien Cottrell,Tiziana Di Matteo,Paul Duchnowski,Vahagn Kirakosyan,Jose Marques,Kharen Musaelian,Stefano Pasquali,Ryan Stever,Dario Villani
## Background
本文介绍了一种新的企业联系代理，即特征向量联系（CVLs）。通过使用此概念，作者首先利用欧几里得相似性来估计企业联系，接着借助量子认知机器学习（QCML）进行相似性学习。研究表明，这两种方法都可以用于构建有利可图的动量溢出交易策略，但是QCML相似性优于简单的欧几里得相似性。
## Innovation
提出了一个新的企业联系代理概念——特征向量联系（CVLs），并通过两种方法（欧几里得相似性和量子认知机器学习）进行了实证研究，发现量子认知机器学习在相似性学习上表现更佳，能够提高动量溢出交易策略的盈利能力。
## Conclusion
证实了两种方法都可以用于构建有利可图的动量溢出交易策略，但量子认知机器学习在相似性学习上优于欧几里得相似性，提升了交易策略的实际应用价值。
# 487. `cs.LG` - 具有良好扩展性和成本效益的基于模板的从头分子生成 [PDF](https://arxiv.org/pdf/2506.19865), [HTML](https://arxiv.org/abs/2506.19865)
## Authors
Piotr Gaiński,Oussama Boussif,Andrei Rekesh,Dmytro Shevchuk,Ali Parviz,Mike Tyers,Robert A. Batey,Michał Koziarski
## Background
基于模板的分子生成为药物设计提供了有希望的途径，确保生成的化合物可以通过预定义的反应模板和构建块合成。然而，存在三个核心挑战：（1）最小化合成成本；（2）扩展到大型构建块库；（3）有效地利用小片段集合。该研究旨在克服这些挑战，以提高模板基础的综合效率和质量。
## Innovation
1. 提出了一种递归成本指导框架，采用辅助机器学习模型近似合成成本和可行性；2. 引入了一种利用中间高价值状态构建完整合成树的动态库机制；3. 设计了平衡探索与利用之间权衡的采样罚则，以提高合成路径的成本效率。
## Conclusion
提出的方法在基于模板的分子生成中达成了最先进的水平，特别是在小型构建块库中性能得到显著提升，实现了良好的扩展性和成本效益。
# 488. `cs.LG` - 利用FEM仿真预测皮肤粘合界面剥离力的神经网络 [PDF](https://arxiv.org/pdf/2506.19855), [HTML](https://arxiv.org/abs/2506.19855)
## Authors
Ashish Masarkar,Rakesh Gupta,Naga Neehar Dingari,Beena Rai
## Background
研究黏合剂在皮肤上的剥离行为对推动医学粘合剂和透皮贴剂等生物医学应用至关重要。传统方法如实验测试和有限元方法（FEM）虽被视为金标准，但资源密集、计算昂贵且耗时，特别是在分析广泛的材料参数空间时更为明显。本研究旨在克服这些挑战，通过引入基于神经网络的方法来预测最小子剥离力（F_min），从而减少重复的FEM模拟次数并显著降低计算成本。研究利用90度剥离测试的不同黏合剂和断裂力学参数生成的FEM仿真数据集，通过严格的5折交叉验证验证神经网络模型的准确性。研究成果展示了神经网络在预测不同皮肤-黏合剂剥离行为方面的高精度和可靠性，为未来的生物医学计算及生物黏合材料设计提供了高效的方法和框架。
## Innovation
本研究提出了一种基于神经网络的方法来预测最小子剥离力，显著减少计算成本并提高了预测效率。通过使用有限元模拟生成的数据集训练神经网络模型，该方法能够准确预测广泛参数条件下的剥离行为。此外，研究通过结合高保真生物力学仿真与机器学习，实现了对皮肤-黏合剂系统高效设计和优化，为未来的生物医疗机械学研究和生物黏合材料设计提供了可扩展框架。
## Conclusion
本研究引入了一种可靠且计算高效的预测方法，能够有效减少模拟时间的同时保持高精度。研究结果展示了神经网络与高保真生物力学仿真结合的技术优势，为皮肤-黏合剂界面设计和优化提供了新的思路，具有广阔的未来应用前景。
# 489. `cs.LG` - DualEquiNet: 双空间层次对称网络用于大分子结构建模 [PDF](https://arxiv.org/pdf/2506.19862), [HTML](https://arxiv.org/abs/2506.19862)
## Authors
Junjie Xu,Jiahao Zhang,Mangal Prakash,Xiang Zhang,Suhang Wang
## Background
几何图神经网络（GNNs）在小分子建模上表现出色，但在应用于如RNA和蛋白质这类大分子时，面临着可扩展性和表达能力的挑战。现有几何GNNs通常仅限于欧几里得空间或球谐空间中的操作，无法同时捕捉到细微的原子间交互和长程的对称相关依赖性，这对多尺度结构的建模是至关重要的。因此，需要一种能够同时捕捉原子级细节和长程、对称感知依赖性的网络模型，以处理大分子的多尺度结构。
## Innovation
作者提出了DualEquiNet，一种双空间层次对称网络，它在欧几里得空间和球谐空间中构造互补的表示，能够捕获局部几何特征和全局对称感知特征。DualEquiNet通过双向跨空间消息传递和新颖的跨空间交互池机制，将原子特征逐级汇集成生物意义的单元，从而实现高效且表达能力强的多尺度建模。DualEquiNet在多种现有基准测试中表现出最先进的性能，并在两个新引入的3D结构基准测试中优于之前的方法，展示了其在多种大分子结构建模任务中的广泛有效性。
## Conclusion
DualEquiNet在RNA属性预测和蛋白质建模等多个基准测试中达到了最先进的性能，并在两个新引入的3D结构基准测试中优于前人方法，展示了其在大分子结构建模中的优越效果。
# 490. `cs.LG` - Queueing Control中的有限时间信息论界 [PDF](https://arxiv.org/pdf/2506.18278), [HTML](https://arxiv.org/abs/2506.18278)
## Authors
Yujie Liu,Vincent Y. F. Tan,Yunbei Xu
## Background
前人对MaxWeight算法的研究仅保证在重负荷交通下的稳定性和渐进最优性，但没有在有限时间段内提供具体的性能分析。本文填补了这一空白，建立了有限时间内队列长度的首个信息论下界，并据此提出了新的调度策略以实现这些下界。
## Innovation
1. 提出了一种最小最大框架，明确了任何策略在有限时间内性能的具体问题参数；2. 提出了队列长度的首个信息论下界；3. 指明MaxWeight在有限时间内是次优的；4. 提出了一个新调度规则，通过最小化包含二次项的完整Lyapunov漂移来匹配上述下界特定条件下，达到普遍常数级别的最优性。这些发现揭示了“仅漂移”的方法的局限性，并为非渐进最优控制指明了方向。
## Conclusion
本文的研究发现揭示了“仅漂移”方法的局限性，并为队列控制中的有原则的、非渐进最优性指明了方向。
# 491. `cs.LG` - 网络流量中稳健异常检测：CICIDS2017上机器学习模型评估 [PDF](https://arxiv.org/pdf/2506.19877), [HTML](https://arxiv.org/abs/2506.19877)
## Authors
Zhaoyang Xu,Yunbo Liu
## Background
识别适合的机器学习范式以构建有效的入侵检测系统（IDS）仍然至关重要。本文在CICIDS2017数据集中，对四种代表模型（多层感知器（MLP）、一维卷积神经网络（CNN）、一类支持向量机（OCSVM）和局部异常因子（LOF））进行了受控对比，分析了它们在检测已知攻击类型和泛化到未知威胁方面的表现。
## Innovation
本文通过针对不同场景对比四种机器学习模型的性能，为动态网络环境下选择IDS模型提供了实际指导。研究发现，监督学习的MLP和CNN在检测已知攻击方面表现出色，但在面对未知攻击时会大幅度降低召回率；而无监督的LOF在未知威胁检测方面具有较高的召回率，但会产生较高的误报；边界基于的OCSVM则在召回率和精确率之间取得了较好的平衡，表现稳健。
## Conclusion
研究结论指出，不同的机器学习模型适用于不同情况下的安全解决方案。对于已知攻击类型的检测，MLP和CNN更为合适；而对于未知威胁或泛化场景，OCSVM和LOF显示了更好的稳健性能。
# 492. `cs.LG` - 清白用户在清洁室中：为生成模型定义版权保护 [PDF](https://arxiv.org/pdf/2506.19881), [HTML](https://arxiv.org/abs/2506.19881)
## Authors
Aloni Cohen
## Background
讨论了在何种条件下生成模型的输出不会侵犯其训练数据的版权，即所谓的“可证明的版权保护”问题。Vyas、Kakade和Barak（ICML 2023）首先提出了这一问题，并定义了接近访问自由（NAF）并将其作为保护标准。这篇文章重新探讨了这个问题，建立了更坚实、更可靠的技术和法律基础来定义可证明的版权保护，指出NAF本身并不能阻止侵权，并引入了无责版权保护框架和清洁室版权保护的概念，证明了在数据集为正集的情况下，差异隐私会导致清洁室版权保护。
## Innovation
文章重新审视了NAF是否能保证不侵权的问题，指出NAF其实不足以防止侵权，引入了一个新的无责版权保护框架，并提出了清洁室版权保护的概念，通过这种方式让用户能控制自己在假设环境下复制的风险，同时证明了当数据集为正集时，差异隐私可以带来清洁室版权保护。
## Conclusion
文章通过引入新的概念和技术框架，为生成模型的版权保护提供了更坚实的基础，并通过理论证明明确了在特定条件下版权保护的有效性。
# 493. `cs.LG` - Prover Agent: 基于代理框架的形式化数学证明 [PDF](https://arxiv.org/pdf/2506.19923), [HTML](https://arxiv.org/abs/2506.19923)
## Authors
Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai
## Background
现有的自动定理证明方法主要依赖于大型语言模型（LLMs）或小型语言模型（SLMs），但大多数缺乏有效结合自然语言推理和形式化证明的机制，使得在解决复杂问题时成功率有限。本文通过引入Prover Agent，旨在构建一个能够有效结合LLMs和形式化证明助手Lean的新型AI代理，从而提高自动定理证明的成功率和复杂问题解决能力，特别是在使用小于之前方法的小样本预算情况下，能够达到新的技术水平。
## Innovation
Prover Agent是一个将大型语言模型（LLMs）与形式化证明助手Lean（Lean）集成的新型AI代理。它通过协调非形式化推理LLM、形式化证明模型以及来自Lean的反馈，生成辅助引理来协助发现整体证明策略。Prover Agent在MiniF2F基准测试中达到了86.1%的成功率，成为了使用小型语言模型（SLMs）的新标准，同时使用了比先前方法更低的样本预算。这一创新方法在自动化数学证明领域引起了广泛关注，并为解决复杂问题提供了新的工具和支持。
## Conclusion
Prover Agent展示了基于代理框架的形式化数学证明的新颖方法，通过有效结合大型语言模型和形式化证明助手，显著提升了自动定理证明的成功率和复杂问题解决能力。此外，通过生成辅助引理，Prover Agent能够更好地支持和协助发现证明策略，为未来的研究和应用奠定了基础。
# 494. `cs.LG` - 利用AI增强区块链保障能源交易安全以提升能源市场稳定性 [PDF](https://arxiv.org/pdf/2506.19870), [HTML](https://arxiv.org/abs/2506.19870)
## Authors
Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan
## Background
在美国，点对点交易和去中心化电网的发展改变了能源市场的形态，但这些进步也带来了新的挑战，尤其是在能源交易的安全性和真实性方面。这项研究旨在开发并建立一个安全、智能且高效的支持去中心化美国能源市场的能源交易系统。该研究结合区块链技术和人工智能技术，以解决分布能源市场长期存在的安全、欺诈行为检测和市场可靠性问题。为此，研究团队使用了一个包含超过120万匿名能源交易记录的模拟P2P能源交换网络作为数据集，该数据集模拟了LO3 Energy和Grid+ Labs测试的基于区块链的美国微电网。这些记录详细列出了交易标识符、时间戳、能量体积（kWh）、交易类型（买卖）、单位价格、去标识化的供能者/消费者标识符（用于隐私保护）、智能电表读数、地理区域和结算确认状态，以及系统计算的行为指标，包括交易速率、能源生产变异性以及历史定价模式。
## Innovation
通过结合区块链技术和人工智能技术，这项研究创造了一种新的方法来解决分布式能源市场的安全、欺诈行为检测和市场可靠性问题。研究团队提出了一种包含两层架构的系统，即区块链层和人工智能层，每层在能源交易的安全保障和市场情报改进方面发挥独特而互补的作用。研究中使用的机器学习模型特别选择了以高绩效分类任务为例的能源交易欺诈识别方面表现出色的模型。
## Conclusion
这项研究不仅为去中心化能源市场的安全交易和市场稳定性提供了有力支持，还为未来能源市场的智能化管理提供了宝贵的经验和启示。
# 495. `cs.LG` - RepuNet: 一个缓解DFL中恶意客户端的声誉系统 [PDF](https://arxiv.org/pdf/2506.19892), [HTML](https://arxiv.org/abs/2506.19892)
## Authors
Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán
## Background
分散式联邦学习（DFL）允许节点不依赖中央服务器协同训练模型，但每个节点独立选择用于模型聚合的同伴，从而引入了新的安全漏洞。恶意节点可以利用这种自主性通过发送带有污染的数据（模型污染）、延迟模型提交（延迟攻击）或在网络中发送过多信息（流量攻击）等方式，负面地影响系统性能。现有的解决方案往往依赖于固定的配置或者额外的基础架构，如区块链，这导致了计算开销，可扩展性问题以及有限的适应性。为解决这些问题，本文提出了一个名为RepuNet的分散式声誉系统，该系统能够识别DFL中的威胁并动态评估节点行为，根据行为评分调整节点在模型聚合中的影响力。RepuNet被集成到Nebula DFL平台并使用MNIST和CIFAR-10数据集进行了实验评估，涵盖了最多25个节点且使用全连接和随机拓扑的联邦学习环境。实验验证了RepuNet在不同攻击强度、频率和激活间隔的情况下能够有效检测和缓解恶意行为，取得了MNIST案例下的F1得分大于95%和CIFAR-10案例下约76%的高评分，这些结果显示了RepuNet的适应性、稳健性和实际应用潜力，能够有效减弱分布式联邦学习环境中的安全威胁
## Innovation
提出了一个称为RepuNet的分散式声誉系统，能够识别DFL中的威胁并动态评估节点行为，根据行为评分调整节点在模型聚合中的影响力，有效地检测和缓解恶意行为。该系统不依赖于固定配置或额外的基础架构，有效解决现有解决方案中的计算开销、扩展性和适应性问题
## Conclusion
实验证明了RepuNet的有效性和适应性，它能够在分布式联邦学习环境中缓解威胁，并具有高度的鲁棒性和实用潜力。
# 496. `cs.LG` - CoVE: 压缩词汇扩展使基于大语言模型的推荐系统更优秀 [PDF](https://arxiv.org/pdf/2506.19993), [HTML](https://arxiv.org/abs/2506.19993)
## Authors
Haochen Zhang,Tianyi Zhang,Junze Yin,Oren Gal,Anshumali Shrivastava,Vladimir Braverman
## Background
推荐系统在为用户提供相关内容方面发挥着重要作用。随着大型语言模型（LLMs）的快速发展，研究人员已经开始利用LLMs构建更强大的推荐系统。然而，现有的专注于将LLMs与推荐任务对齐的方法并没有充分利用它们的序列信息处理能力，导致性能欠佳。
## Innovation
本文提出了一种名为压缩词汇扩展（CoVE）的新系统。CoVE通过为每个项目分配唯一的ID，在扩展的词汇中利用LLMs的序列理解能力，显著增强了其在推荐任务上的性能。此外，CoVE还压缩了嵌入层，使其适合大规模工业应用。通过在多个推荐数据集上的全面实验和与以往工作的比较，验证了CoVE的有效性和性能。
## Conclusion
CoVE通过压缩词汇扩展，有效利用了LLMs的序列处理能力，提升了推荐系统在实际应用中的性能，并为大规模工业应用提供了可能。
# 497. `cs.LG` - 基于注意力预测的移动链路分配：MiLAAP [PDF](https://arxiv.org/pdf/2506.19947), [HTML](https://arxiv.org/abs/2506.19947)
## Authors
Yung-Fu Chen,Anish Arora
## Background
在CS通信系统中，为了维持吞吐量效率，需要适应无线网络中的干扰变化和节点移动。最优化调度需要实时网络状态信息（如信道占用情况）来选择干扰区域内的非重叠信道。然而节点间状态共享会引入显著的通信开销，特别是在网络规模或节点移动性增加时，这会降低本已容量受限的网络的吞吐量效率。本文探讨了在不共享状态信息的情况下，通过基于学习的信道占用预测来调整CS调度的方式。
## Innovation
本文提出了基于自注意力机制的MiLAAP预测框架，用于机器学习模型，以考虑频谱、空间和时间依赖性。MiLAAP能够使每个节点根据其干扰区域的时空信道模式进行自适应预测，同时仅依赖于本地被动观测的信道活动即可进行预测，从而不增加通信开销。为了处理节点移动性，MiLAAP还使用了多头自注意力机制，使得每个节点能够局部捕获其他可能干扰其节点的时空依赖性，并预测这些节点的运动轨迹。此外，该方法能够检测进入或移动到干扰区域的节点，以进一步提高信道占用率预测的准确性。研究表明，对于使用局部CS序列支持相对持久流量的动态网络，MiLAAP能够高达100%的信道状态预测准确率，并在不同CS序列周期内实现零样本泛化能力。
## Conclusion
通过基于注意力机制的MiLAAP预测框架，网络无需共享状态信息就能进行有效的CS调度，通过自注意力机制和多头注意力机制分别对时频特性进行捕捉和对干扰节点的时空规律进行分析，准确预测信道占用状态并应对节点移动性，而不会增加通信开销。
# 498. `cs.LG` - 在合作多智能体强化学习中学习双向团队形成 [PDF](https://arxiv.org/pdf/2506.20039), [HTML](https://arxiv.org/abs/2506.20039)
## Authors
Koorosh Moslemi,Chi-Guhn Lee
## Background
在多代理强化学习（MARL）的背景下，团队形成和基于团队的学习动力学吸引了广泛关注。现有的研究主要集中在单一的分组、预定义的团队或固定人口设置上，而忽略了在动态人口中算法双边分组选择的影响。由于这些局限性，本研究提出了一种框架，用于学习动态多代理系统中的双向团队形成。通过这一研究，我们获得了对双边团队形成中哪些算法特性影响策略性能和泛化的洞察。
## Innovation
本研究引入了一种框架，用于在动态多代理系统中学习双向团队形成，填补了现有研究忽略在动态人口中的算法双边分组选择影响的空白，探讨了哪些算法特性影响策略性能和泛化能力。
## Conclusion
本研究通过广泛采用的多代理场景验证了方法的有效性，在大多数情况下展示了竞争力的性能和改进的泛化能力。
# 499. `cs.LG` - 基于空间时间点过程的精细阅读行为建模 [PDF](https://arxiv.org/pdf/2506.19999), [HTML](https://arxiv.org/abs/2506.19999)
## Authors
Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell
## Background
阅读是一种在空间和时间上展开的过程，交替进行注视和扫视。先前的心理语言学假设认为，通过建模读者的注视和扫视可以揭示他们在阅读过程中的在线句子处理。然而，现有的标准建模方法依赖于聚合的眼动追踪测量和带有严格假设的模型，这些方法忽略了阅读过程中发生的大量时空动态。
## Innovation
本文提出了一种更通用的概率阅读行为模型，基于标记的空间时间点过程，该模型不仅捕捉注视的持续时间，还捕捉它们在空间中的位置和时间上的发生。扫视使用了Hawkes过程来建模，该过程可以捕捉到每次注视如何增加附近时间空间发生新注视的概率。注视事件的持续时间被建模为固定预测因子的时间卷积函数，从而捕捉溢出效应。
## Conclusion
我们的Hawkes过程模型在眼动追踪上表现出更好的拟合度，相较于基线。关于注视持续时间，我们观察到将上下文惊奇作为预测因子的引入仅对模型预测准确性产生了微小的改善，这表明惊奇理论难以解释精细的眼动行为。
# 500. `cs.LG` - 基于扩散的面向任务的语义通信及其针对模型反转攻击 [PDF](https://arxiv.org/pdf/2506.19886), [HTML](https://arxiv.org/abs/2506.19886)
## Authors
Xuesong Wang,Mo Li,Xingyan Shi,Zhaoqian Liu,Shenghao Yang
## Background
语义通信作为一种基于神经网络的系统设计，被认为是6G网络的有前途的技术。面向任务的语义通信是一个新颖的范式，目标是通过传输语义信息、优化通信效率和任务性能来高效完成具体任务。但是，这一场景面临着在保持隐私的同时保持任务准确性的挑战，因为这可能容易受到模型反转攻击的影响。在这些攻击中，攻击者可以通过分析和处理模型输出来恢复或重构输入数据。此外，传统系统使用图像质量指标（如PSNR或SSIM）来评估攻击严重性，这可能不足以评估面向任务的语义通信，因为视觉差异并不一定意味着语义差异。
## Innovation
本文提出了一种基于扩散的语义通信框架，名为DiffSem，该框架通过扩散机制和自参考标签嵌入优化了语义信息的重构，以大幅提升任务性能。该模型还可补偿信道噪声，采用语义信息失真以确保系统在各种信噪比环境中的鲁棒性。同时，为了更好地评估攻击的有效性，本文提出了一种新的度量标准，以量化估计算法的语义保真度。实验结果表明，与传统的图像质量指标相比，DiffSem在MNIST数据集上提高了10.03%的分类准确率，并且在动态信道下保持了稳定的性能。
## Conclusion
我们的结果表明，传统图像质量指标与任务相关的语义信息泄露之间存在显著差异。
# 501. `cs.LG` - Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing [PDF](https://arxiv.org/pdf/2506.20000), [HTML](https://arxiv.org/abs/2506.20000)
## Authors
Narasimha Raghavan Veeraragavan,Jan Franz Nygård
## Background
该论文旨在解决联邦计算中隐私保护机制的安全性问题，联邦计算涉及多种隐私保护技术，如全同态加密 (FHE) 和多方计算 (MPC)，以及统计技术如差分隐私 (DP)。这些技术各自有不同的实现方式和安全策略，需要一种能够统一安全策略的方法来确保多方参与者的隐私安全和数据安全。传统的安全策略往往与具体的隐私保护技术绑定，难以适应新的隐私保护技术的发展，因此需要一种更为灵活的框架来管理联邦计算中的安全策略。
## Innovation
论文提出了名为Guardian-FC的新型两层框架，它通过执行可插拔模块（可模块化计算单元），由一个后端中立、领域特定语言（DSL）编写，与特定的执行提供者（EPs）配合使用，来实现隐私保护机制的分离。此外，论文还引入了代理人工智能（Agentic-AI）控制平面通过加签遥测和命令来实施有界状态安全循环，从而实现一致的风险管理和审计。Guardian-FC框架设计支持快速故障，并能无缝地扩展到新的隐私保护后端。该框架还呈现了基于功能的保证场景，并为验证提供了形式模型基础。最后，论文提出了研究议程，邀请社区在适应性护栏调整、多后端组合、DSL规范开发、实施与编译器可扩展性等方面进行研究，以增强用户体验。
## Conclusion
Guardian-FC框架通过分离护栏机制和隐私技术，并提供灵活性和可扩展性的管理方式，实现联邦计算的安全保护。它强调了一个安全循环可以通过集中控制来实现对多种隐私保护技术的统一管理，并提出了许多研究方向以进一步完善该框架。
# 502. `cs.LG` - PocketVina 通过多口袋条件提高可扩展性和高精度的物理有效对接 [PDF](https://arxiv.org/pdf/2506.20043), [HTML](https://arxiv.org/abs/2506.20043)
## Authors
Ahmet Sarigun,Bora Uyar,Vedran Franke,Altuna Akalin
## Background
分子对接中，特别是对于未见过或结构多样的目标，寻找有效的配体结合位姿仍然是一个主要挑战。现有的对接方法在这些情况下表现不佳，尤其是需要兼顾配体的结构对齐和物理合理性的评估时更为困难。
## Innovation
PocketVina 是一种结合口袋预测与系统性多口袋探索的快速且内存效率高的搜索型对接框架。与现有方法相比，PocketVina 在多个基准测试中表现出色，尤其是在未见过的和结构多样的靶标上。尤其值得一提的是，在评估配体的软件重叠度和物理合理性时，PocketVina 达到了最先进的技术水平，同时在其他仅考量配体重叠度的基准上也能与深度学习方法竞争，特别是在处理结构多样的靶标时。此外，PocketVina 在不同灵活性的配体上也保持了最先进的物理有效对接精度。PocketVina 还展示了一种不需要特定任务训练且能在标准 GPU 上高效运行的对接策略，使其非常适合高通量虚拟筛选和基于结构的药物发现。为了进一步验证其性能，作者还引入了一个自定义基准数据集 TargetDock-AI，包含超过 50 万个蛋白质-配体对，并且标注了来自 PubChem 的活性注释。在大规模数据集上，PocketVina 成功地区分了活性与非活性靶标，优于基于深度学习的基线模型，同时需要较少的 GPU 内存和运行时间。
## Conclusion
PocketVina 通过多口袋条件提供了强大且可扩展的对接策略，能够在多种场景下精准找到有效的配体结合位姿，特别适合高通量虚拟筛选和基于结构的药物发现，同时表现出色的计算效率。
# 503. `cs.LG` - MAIZX：优化云计算排放的低碳意识框架 [PDF](https://arxiv.org/pdf/2506.19972), [HTML](https://arxiv.org/abs/2506.19972)
## Authors
Federico Ruilova,Ernst Gunnar Gran,Sven-Arne Reinemo
## Background
云计算尽管推动了创新，但也因其高能耗和碳排放而面临重大环境挑战。据估计，数据中心占全球能源消耗的2-4%，而ICT行业的能源消耗比例预计将从2020年的约20%增长到2040年的40%。随着到2050年实现净零排放的目标日益紧迫，有必要寻找更加高效和透明的解决方案，特别是针对占组织总数87%的私有云基础设施。由于私有云比公共云更常见，因此需要相应地优化它们的性能和环保性，以适应这一转变的需求和挑战。
## Innovation
MAIZX框架通过根据实时和预测的碳强度、电能使用效率（PUE）以及能源消耗动态排名资源，包括数据中心、边缘计算节点和多云环境，来优化云操作并减少碳足迹。MAIZX设计了一个灵活的排名算法，与基线hypervisor操作相比，成功地减少了85.68%的CO2排放。通过分布式数据中心的实际测试，展现了其在私有、混合及多云环境中的可扩展性和有效性，直接与hypervisors交互以优化负载。MAIZX整合了实时的碳强度、能耗和碳足迹数据以及预测值，增强云管理的同时保持了运营效率，提供了提升气候变化适应潜力的强有力工具。
## Conclusion
MAIZX框架成功地减少了云基础设施中的碳排放，展示了其在不同环境下的有效性。通过实证测试，证明了该框架能在全球范围内应用于优化私有、混合及多云环境中的能源效率，直接减少数据中心的排放，为实现碳中和合规及改善气候适应性提供了强有力的支持。
# 504. `cs.LG` - 通过流形学习进行数据驱动的动态因子建模 [PDF](https://arxiv.org/pdf/2506.19945), [HTML](https://arxiv.org/abs/2506.19945)
## Authors
Graeme Baker,Agostino Capponi,J. Antonio Sidaoui
## Background
该论文提出了一种数据驱动的动态因子框架，其中响应变量依赖于高维协变量集，未对联合动态过程施加任何形式的参数模型限制。利用Singer和Coifman提出的非线性流形学习技术Anisotropic Diffusion Maps，该框架能够在纯数据驱动的方式下发现协变量和响应变量的联合动态。该方法利用线性扩散近似嵌入动态，并利用Kalman滤波从流形学习嵌入空间直接预测协变量和响应变量的变化。该研究进一步将Singer关于图拉普拉斯矩阵收敛速度分析的结果从紧流形上的独立均匀样本推广到欧几里得空间中Langevin扩散的时间序列。此外，通过展示线性扩散近似流形映射坐标和本征谱假设下的遍历平均值收敛性来严格证明该方法的稳健性。
## Innovation
基于Anisotropic Diffusion Maps的非线性流形学习技术，该研究开发了一种数据驱动的动态因子模型，用于发现高维协变量和响应变量的动态。通过Kalman滤波从流形学习嵌入空间直接预测变化，并将Singer的结果推广到时间序列的场景。该研究还提供了该方法的严谨证明，讨论了线性扩散近似和遍历平均值的收敛性，从而提出了一种数据驱动的应力测试方法。这在历史回溯中表现出优于标准情景分析和主成分分析基准的结果，特别是在三个主要金融危机期间，平均绝对误差分别降低了55%和39%。
## Conclusion
该研究不仅提出了一种创新的动态因子模型方法，还通过严格的理论分析确保了模型的稳健性和预测准确性。通过实验证明该数据驱动的应力测试方法在高维数据预测中的优越性。
# 505. `cs.LG` - 集成时空模型和大语言模型的模块化多任务推理框架 [PDF](https://arxiv.org/pdf/2506.20073), [HTML](https://arxiv.org/abs/2506.20073)
## Authors
Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang
## Background
时空数据挖掘在多个领域中至关重要，但现有的模型通常局限于单一任务，缺乏进行多任务推理和复杂长期推理论证的能力，这些限制导致它们难以应用于多维度的实际决策场景。
## Innovation
提出了STReason框架，该框架将大语言模型（LLMs）的推理优势与时空模型的分析能力相结合，实现多任务推理和执行。无需对特定任务进行微调，STReason利用上下文学习将复杂的自然语言查询分解为可解释的模块化程序，并系统执行以生成解决方案和详细的理由。为了进行严格的评估，构建了一个新的基准数据集，并提出了一种统一的评估框架，其中包含专门为时空推理设计的评估指标。实验结果表明，STReason在所有指标上均显著优于最先进的LLM基线模型，特别是在复杂的、推理密集的时空场景中表现出色。进一步的人类评估证实了STReason的可靠性和实用性，展示了其在实际时空任务中的潜在应用价值。
## Conclusion
STReason为开发更有力且更具应用性的时空推理系统提供了一个有前景的方向。
# 506. `cs.LG` - 一种遵循原则的贴合分布评估路径 [PDF](https://arxiv.org/pdf/2506.20048), [HTML](https://arxiv.org/abs/2506.20048)
## Authors
Sungee Hong,Jiayi Wang,Zhengling Qi,Raymond Ka Wai Wong
## Background
在强化学习中，分布性的离线策略评估（OPE）旨在利用在不同策略下收集到的数据来估算目标策略的回报分布。本研究关注的是将广泛用于期望强化学习的适应性Q评价方法扩展到分布性OPE的场景中。现有的相关方法较少，还没有统一的框架来构建适应性分布性评价方法。为了解决这一问题，本文提出了一系列理论指导原则，并据此开发了若干新方法，这些方法适用于非表格形式环境，并提供了理论上的证明。广泛的实验，包括线性二次调节器和Atari游戏的仿真，展示了适应性分布性评价方法的优越性能。
## Innovation
本文提出了一种新的方法——适应性分布性评价（FDE），并构建了理论指导原则来设计此类方法。该方法在不同环境中进行了验证，展示了优异的性能，并填补了现有FDE方法研究中缺乏统一框架的空白。
## Conclusion
本文提出了一系列新的FDE方法，并通过这些方法在广泛的实验中展示了其优越性。研究还提供了这些方法在理论上的证明，特别是非表格形式环境中的应用。
# 507. `cs.LG` - 从树集萃取可解释模型：计算和统计视角 [PDF](https://arxiv.org/pdf/2506.20114), [HTML](https://arxiv.org/abs/2506.20114)
## Authors
Brian Liu,Rahul Mazumder,Peter Radchenko
## Background
树集合是非参数方法，因其高精度和对复杂交互的捕捉能力而广受认可。尽管这些模型在预测方面表现出色，但它们难以解释，并且可能未能揭示数据中的有用关系。
## Innovation
提出了一个估计器，能够从树集合中提取简明的决策规则集合。该估计器的一个关键新颖之处在于它可以同时控制提取规则的数量和每条规则的交互深度，从而提高准确性。本文还开发了一个专门的精确算法来高效解决估计器背后的优化问题，并设计了近似算法来计算正则化路径，这是一个序列，对应于模型大小变化的不同解决方案。此外，还为本文提出的方法建立了新的非渐近预测误差界，与选择具有相同复杂性约束的最佳数据依赖线性组合的最优解进行了比较。研究表明，该估计器的大样本预测性能与最优解相当。通过实验，表明该估计器优于现有的规则提取算法。
## Conclusion
该估计器能够从树集合中提取简明的决策规则，并且其预测性能接近最优解，同时还可以通过手动检查来揭示预测变量和响应之间的关系。
# 508. `cs.LG` - 智能攻击：基于注意力驱动的细粒度网页指纹攻击 [PDF](https://arxiv.org/pdf/2506.20082), [HTML](https://arxiv.org/abs/2506.20082)
## Authors
Yali Yuan,Weiyi Zou,Guang Cheng
## Background
网站指纹攻击（WF）旨在通过分析流量模式推断用户访问了哪些网站，从而破坏用户的匿名性。尽管这种技术在受控实验环境中已被证明有效，但它主要局限于小规模场景，通常仅能识别网站的主页。在实际操作中，用户经常快速切换访问多个子页面，即使前一个内容尚未完全加载。网页指纹攻击（WPF）将WF框架推广到大规模环境，将其相同站点的不同子页面视为不同的类别。这些子页面通常具有相似的页面元素，导致流量特征之间的类间方差较低。此外，本研究考虑了多标签浏览场景，其中单个痕迹包含多个网页类别的内容。这导致了重叠的流量段落，相似的特征可能出现在流量的不同位置，从而增加了分类的难度。
## Innovation
提出了一种基于注意力驱动的细粒度网页指纹攻击（ADWPF），具体采用目标增强方法，包括注意力裁剪和注意力屏蔽，在训练阶段关注流量中的重要区域。该方法从原始和增强的流量中提取低纬特征，并应用自注意力模块来捕捉轨迹的全局上下文模式。此外，还使用残差注意力生成不同时间位置出现的网页类特定表示，以应对多标签场景。广泛的实验表明，该方法在不同规模的数据集上始终超过了最先进的基线方法。
## Conclusion
经过广泛的实验研究，该方法在不同规模的数据集上均优于现有的最先进的基线方法，有效解决了大规模环境中多标签浏览场景带来的挑战，提高了细粒度网页指纹攻击的能力。
# 509. `cs.LG` - 使用编辑距离弱监督的开放世界多模态信息检索 [PDF](https://arxiv.org/pdf/2506.20070), [HTML](https://arxiv.org/abs/2506.20070)
## Authors
KMA Solaiman,Bharat Bhargava
## Background
现有的多模态检索模型要么依赖于创建具有特定模态表示模型的公共子空间，要么需要在不同模态之间进行模式映射以度量多模态数据之间的相似性。这些方法往往需要大量的标签标注，并且通常需要微调以适配不同的应用场景。本文旨在避免将检索视为监督分类任务从而避免标注负担，并利用大型语言模型和视觉任务中的预训练编码器解决问题。本文提出了FemmIR框架，该框架利用多模态查询示例而不使用任何相似度标注，来获取相关的多模态检索结果。这种方法在数据注释稀缺且不希望在应用间进行微调的情况下，能够在无需任何标注的情况下自动适应不同类型的应用场景。作者为此任务构建了一个新的数据集—MuQNOL，并通过编辑距离中引入的弱监督来进行机制设计，通过计算样本之间的编辑距离和推断样本与查询之间的关系来实现检索。
## Innovation
本文提出了FemmIR框架，该框架利用多模态查询示例而不使用任何相似度标注，通过编辑距离等弱监督机制，进行结果的检索，克服了传统方法需要大量标注数据和难以适应不同应用场景的局限性。该方法通过两者的多级交互评分，将数据样本和用户提供的查询示例进行关联，保留了高阶属性和保持了数值和关系约束条件。这种方法在没有需要微调的情况下实现了多模态数据的准确和近似相似结果检索。
## Conclusion
本文通过在多模态信息检索中引入弱监督机制，使得检索过程更加高效、灵活，特别是在数据注释资源有限的情况下。FemmIR将预训练的编码器自适应地应用于多模态查询检索，通过弱监督的方法自动获取多模态数据的相关信息并提供了性能良好的检索结果。通过MuQNOL数据集的实验，展示了其在实际应用场景中的潜力，并证明了其在开放世界多模态信息检索任务中的有效性。
# 510. `cs.LG` - 在增强数字孪生沙盒内的共进化博弈中实现自主网络安全 [PDF](https://arxiv.org/pdf/2506.20102), [HTML](https://arxiv.org/abs/2506.20102)
## Authors
Malikussaid,Sutiyo
## Background
IT和OT的融合产生了高度互联的工业控制系统ICS，使关键基础设施暴露于新的适应性强、智能化的威胁之下，传统的静态防御策略已经失效。现有的安全模式往往无法解决系统模型的真实度、同步数据的完整性以及面对复杂逃逸技术的分析引擎的韧性这“三位一体的信任”基础问题。
## Innovation
本文提出了一种名为ARC的框架，通过自主的闭环强化过程实现分析复原力。ARC通过高保真沙盒中的持续共进化军备竞赛，建立了一个不断进化的防御环境。文中还详细描述了一种“红代理”和一种基于集成方法的“蓝代理”，后者不断通过对抗训练增强自卫能力以应对进化中的威胁。这种共进化的动态迫使两个代理变得更加复杂，从而使系统能够自我探测和修补漏洞。实验验证表明该框架在TEP和SWaT测试平台上表现更优。全面的消融实验，结合详细的ROC曲线和SHAP图，表明共进化的机制是性能提升的关键。通过结合可解释的人工智能来确保操作员的信任，本文建议了一个可扩展的F-ARC架构，将其作为动态、自改进安全性的必要范式转变的一部分，强调了自主网络安全的重要性。
## Conclusion
ARC框架由自主的共进化过程驱动，显著提高了新型攻击的检测能力。通过集成可解释的人工智能和提出可扩展的F-ARC架构，本书不仅推介了一种改进，更提出了迈向关键基础设施未来动态、自改进安全性的必要范式转变。
# 511. `cs.LG` - 利用AI评分器进行缺分数值填补以实现构造性反应测试中精确的能力评估 [PDF](https://arxiv.org/pdf/2506.20119), [HTML](https://arxiv.org/abs/2506.20119)
## Authors
Masaki Uto,Yuma Ito
## Background
评估学习者的各种能力是教育领域的一个基本目标，特别是需要评估表达能力和逻辑思维等高阶能力时。构造性反应测试（如简答题和作文题）被广泛用于满足这一需求，但这种测试需要大量的人工评分，因此劳动密集且成本高。项目反应理论（IRT）通过估算能力来降低这种需求，仅对学员提供的多道试题的回答中的一小部分进行人工评分。然而，随着缺失分数比例的增加，能力估算的准确性会下降。尽管已经探索了填补缺失分数的数据增强技术以应对这一局限性，但这些技术往往对于稀疏或异质数据效果不佳。
## Innovation
本文提出了一种利用自动化评分技术填补缺分数值的新方法，以实现精确的能力评估同时显著减少人工评分的工作负担。这种方法在能力估算准确性方面取得了良好效果，提高了IRT能力评估的准确性，减少了评分工作量。
## Conclusion
该研究所提出的方法通过结合自动化评分技术和项目反应理论，解决了传统评分方法中存在的问题，在保持高度准确性的基础上显著减轻了评分人员的工作负担，为教育评估提供了新的解决方案。
# 512. `cs.LG` - 在齐性预测集中的有效选择 [PDF](https://arxiv.org/pdf/2506.20173), [HTML](https://arxiv.org/abs/2506.20173)
## Authors
Mahmoud Hegazy,Liviu Aolaritei,Michael I. Jordan,Aymeric Dieuleveut
## Background
现有的齐性预测框架能够构建具有覆盖保证的预测集，但在实践中，可能有多个有效的齐性预测集可用，这些预测集可能来源于不同的模型或方法。然而，选择其中最优的（如最小的）预测集可能会破坏覆盖保证的完整性。因此，需要一个方法来确保所选预测集仍然具有覆盖保证。
## Innovation
提出了一种基于稳定性的方法，以确保选择的预测集具有覆盖保证，并将结果扩展到了在线齐性预测的场景中，在有更多的结构信息时提出了一些建议，并通过实验展示了该方法的有效性。
## Conclusion
通过基于稳定性的方法，本文解决了选择最优齐性预测集可能破坏覆盖保证的问题，并通过实验验证了该方法的有效性，同时将其应用扩展到了更复杂的情境中。
# 513. `cs.LG` - 机器学习辅助的光子器件开发：从理论到表征的多尺度方法 [PDF](https://arxiv.org/pdf/2506.20056), [HTML](https://arxiv.org/abs/2506.20056)
## Authors
Yuheng Chen,Alexander Montes McNeil,Taehyuk Park,Blake A. Wilson,Vaishnavi Iyer,Michael Bezick,Jae-Ik Choi,Rohan Ojha,Pravin Mahendran,Daksh Kumar Singh,Geetika Chitturi,Peigang Chen,Trang Do,Alexander V. Kildishev,Vladimir M. Shalaev,Michael Moebius,Wenshan Cai,Yongmin Liu,Alexandra Boltasseva
## Background
光子器件开发（PDD）在设计和实施能够控制不同波长、不同尺度和各类应用（包括电信、成像、传感和量子信息处理）的新型光子器件方面取得了显著成功。PDD是一个五步迭代过程，包括：从设计参数推导器件行为；模拟器件性能；从模拟中找到最优候选设计；制造最优器件；测量器件性能。传统上，所有这些步骤都依赖于贝叶斯优化、材料科学、控制理论以及直接的物理驱动数值方法。然而，这些技术往往在计算上难以处理，具有成本效益问题或在大规模实施中难以实现。此外，PDD还面临巨大的优化景观、结构或光学表征中的不确定性以及实现稳健制造过程的困难。
## Innovation
近年来，机器学习的兴起为解决这些挑战提供了新颖的数据驱动策略，包括加快计算的近似估计、用于噪声测量建模和数据增强的生成模型、用于制造的强化学习以及用于实验物理发现的主动学习。本文综述了这些方法，旨在提供机器学习辅助PDD（ML-PDD）的视角，从而实现高效的设计优化、在噪声测量下快速模拟和表征建模以及基于强化学习的制造。这将为来自不同背景的研究人员提供有价值的认识，推动跨学科努力，加速复杂光子器件和系统的开发.
## Conclusion
本文综述了机器学习辅助的光子器件开发（ML-PDD）方法，以实现高效的设计优化、噪声测量下快速模拟和表征模型以及基于强化学习的制造。这一综述将为来自不同背景的研究人员提供有价值的见解，促进跨学科努力，加速复杂光子器件和系统的开发。
# 514. `cs.LG` - Accept More, Reject Less: 减少11年ICLR数据中高达19%的不必要的桌面拒稿 [PDF](https://arxiv.org/pdf/2506.20141), [HTML](https://arxiv.org/abs/2506.20141)
## Authors
Xiaoyu Li,Zhao Song,Jiahao Zhang
## Background
AI研究的迅猛发展导致旗舰AI会议的论文提交数量大幅增加，到2025年（例如CVPR、ICCV、KDD、AAAI、IJCAI、WSDM）多举办地实施严格的作者提交限额，并简单地按ID顺序拒掉多余的论文。这样的政策虽有助于减轻审稿人的工作负担，但也可能无意中丢弃有价值的论文并惩罚作者的努力。因此，有必要探索在遵守提交限额的同时，最小化不必要的拒稿，以提高论文处理的有效性，减少不必要的风险损失。
## Innovation
该研究将当前的桌面拒稿政策形式化为优化问题，并开发了一个基于线性规划松弛和四舍五入方案的实用算法。该方法在对过去11年ICLR真实数据的广泛评估中，能够保留最多19.23%更多的论文，而不会违反任何作者限额。此外，该算法在实践中高度高效，ICLR数据的所有结果在最多53.64秒内计算完成。该研究为减少不必要的拒稿提供了一种简单实用的方法，表明其有可能显著改进当前计算机科学会议的提交策略。
## Conclusion
本工作提供了一种简单的实用桌面拒稿策略，大大减少了不必要的拒稿，展示了在当前CS会议提交策略上的强大改进潜力。
# 515. `cs.LG` - CCRS：一种零样本LLM作为裁判的全面RAG评估框架 [PDF](https://arxiv.org/pdf/2506.20128), [HTML](https://arxiv.org/abs/2506.20128)
## Authors
Aashiq Muhamed
## Background
RAG系统通过整合外部知识增强LLM，对于需要事实准确性和信息更新性的领域尤为重要。然而，评估RAG输出的多重质量，包括上下文一致性、查询相关性、事实正确性、信息完整性等方面，存在显著挑战。现有的评估方法往往依赖于简单的词汇重叠度量，这些度量不足以捕捉这些细微差别，或者涉及复杂的多阶段管道，包括主张提取或需要微调特定法官模型等步骤，这阻碍了实际效率的提升。
## Innovation
本文提出了一种新颖的CCRS（上下文相关性和相关性评分）框架，利用一个强大的预训练LLM作为零样本、端到端的裁判。CCRS评估五个指标：上下文一致性（CC）、问题相关性（QR）、信息密度（ID）、答案准确性（AC）和信息召回率（IR）。与复杂的RAGChecker框架相比，CCRS在关键方面（如召回率和忠真性）具有相当或更优的区分能力，同时在计算效率方面更具优势。CCRS提供了一个实际、全面且高效的RAG系统评估和逐步改进框架。
## Conclusion
CCRS通过对六个不同的RAG系统配置在具有挑战性的BioASQ数据集上的评估，证明了其有效区分系统性能的能力，例如，Mistral-7B阅读器的表现优于Llama变体。此外，CCRS的度量属性，包括得分分布、收敛/辨别有效性、平局率、总体统计和辨别力，都得到了详细的分析，显示了其全面且高效的评估潜力。与复杂的RAGChecker框架相比，CCRS提供了更好的区分能力，同时计算效率更高。
# 516. `cs.LG` - OLALa: Online Learned Adaptive Lattice Codes for Heterogeneous Federated Learning [PDF](https://arxiv.org/pdf/2506.20297), [HTML](https://arxiv.org/abs/2506.20297)
## Authors
Natalie Lang,Maya Simhi,Nir Shlezinger
## Background
联邦学习（FL）允许多个分布式客户端协作训练模型而不共享原始数据，但通常会导致通过传输高维度模型更新产生显著的通信开销。为了减少这种开销，客户端可以对模型更新进行量化处理，这样可以缓解通信负荷。现有基于晶格的FL方案通常依赖固定量化规则，在用户和训练轮次各异的异构和动态环境中，这种固定规则可能并不最优。
## Innovation
本文提出了一种新的异构联邦学习框架OLALa，其中每个客户端可以在轻量化的本地计算中调整自己的量化器。研究证明，非固定的晶格量化可以收紧收敛界限，并设计了一种在线学习算法，使客户端在FL过程中交换少量量化参数即可调整量化器，从而提高学习性能。
## Conclusion
仿真实验表明，OLALa在各种量化率下都能稳定提升学习性能，优于传统的固定码本和非自适应方案。
# 517. `cs.LG` - COIN：具有可证明风险保证的不确定性保护选择性问答 [PDF](https://arxiv.org/pdf/2506.20178), [HTML](https://arxiv.org/abs/2506.20178)
## Authors
Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu
## Background
基础模型生成自动文本时需要不确定性量化（UQ）来识别和减轻潜在的幻觉。现有的启发式UQ方法在关键指标如选择性预测中的假发现率（FDR）上缺乏正式保证。虽然分裂校准预测（SCP）框架能够通过构建预测集来确保可接受答案的覆盖范围，但这些集往往包含错误候选者，限制了其实际应用价值。基于此，提出了COIN框架，能够在用户指定FDR约束下筛选每个问题的单个生成答案，并通过统计验证的阈值进行校准，来大幅增加样本保留率并在风险控制方面表现稳健，在测试时间上有强大的保留合格答案的能力，并在有限校准数据下具备高效预测能力，适用于普遍和多模态文本生成任务。
## Innovation
提出了COIN不确定性保护选择框架，通过统计验证的阈值筛选每个问题的单个生成答案，以FDR控制为目标，同时大幅增加样本保留率。使用校准集估算经验误差率，并通过Clopper-Pearson等置信区间方法来确定真实错误率（即FDR）的高概率上限，从而在测试数据上实现FDR控制，表现出色，具备广泛的应用性和适应性。
## Conclusion
COIN展示了在风险控制方面的稳健性，在测试时保留合格答案的强大能力以及在有限校准数据下高效预测能力，适用于通用和多模态文本生成任务。此外，该框架及其上界的构建和UQ策略的适用性进一步提高了COIN的表现，这表明其具有高扩展性和适应性，能够应对各种应用场景。
# 518. `cs.LG` - X-SiT: 自然具有可解释性的表面视觉转换器在痴呆症诊断中的应用 [PDF](https://arxiv.org/pdf/2506.20267), [HTML](https://arxiv.org/abs/2506.20267)
## Authors
Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger
## Background
可解释的模型对于支持临床决策至关重要，推动了其在医疗图像中的发展和应用。然而，3D体积数据的特性使得三维的复杂结构（如大脑皮层）难以直观理解。相比之下，大脑皮层表面渲染提供了更容易理解和可视化的3D表示，有助于可视化和交互式探索。鉴于这些优点以及表面数据在研究神经科疾病中的广泛使用，我们提出了可解释表面视觉转换器（X-SiT）。这种网络能够基于可解释的大脑皮层特征提供人类可理解的预测。
## Innovation
我们提出了X-SiT，这是一个自然具有可解释性的神经网络，能够基于可解释的大脑皮层特征提供人类可理解的预测。作为X-SiT的一部分，我们引入了一种原型表面块解码器，用于分类表面块嵌入，并结合案例推理和空间对应的皮质原型。结果显示，该模型在检测阿尔茨海默病和前颞叶痴呆方面表现出最先进的性能，同时提供有助于揭示疾病模式和分类错误的有信息性的原型。
## Conclusion
X-SiT作为一种可解释的神经网络模型，在检测神经科疾病如痴呆症方面达到了最先进的性能，并提供有助于理解疾病的原型，为临床决策提供了更有价值的支持。
# 519. `cs.LG` - 通过纺织品比较进行绘画法医学研究 [PDF](https://arxiv.org/pdf/2506.20272), [HTML](https://arxiv.org/abs/2506.20272)
## Authors
Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén
## Background
美术作品中的画布分析是用于验证、归属性和保存的关键工具。传统方法依赖于线密度图的匹配，但在画布不连续排列时无法应用。这篇论文提出了基于深度学习的创新方法来评估纺织品的相似性，提出了一个自动化的工具，该工具可以在不依赖线密度图的情况下评估画布的相似性，并设计并训练了一个双胞胎深度学习模型来比较图像对的特征表示，从而得出相似性评估方法。这种方法被应用于普拉多国立博物馆的画布上，验证了即使线密度相似，平纹织画布也可以有效比较的假说。其结果表明提出的方法具备可行性与准确性，为名作分析提供了新的途径。
## Innovation
提出了一种基于深度学习的自动化工具，用于评估画布的相似性，无需依赖线密度图。设计并训练了一个双胞胎深度学习模型，利用扫描的特征表示来进行图像对比较。提出了一个通过聚合多个布样对的预测来提供稳健的相似性评分的方法。
## Conclusion
通过双胞胎深度学习模型的有效应用，验证了平纹织画布即使在线密度相似时也能有效比较，证明了该方法的可行性和准确性，为名画的分析提供了新的可能路径。
# 520. `cs.LG` - 基于Transformer的手写识别系统：结合在线和离线特征 [PDF](https://arxiv.org/pdf/2506.20255), [HTML](https://arxiv.org/abs/2506.20255)
## Authors
Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal
## Background
目前大多数手写识别系统只利用单一模态的信息，而本文提出的方法认为手写识别可以从笔迹图和笔迹轨迹中补充的线索中受益。为此，作者提出了一种端到端网络，该网络在一个共享的潜在空间内对离线图像和在线笔迹数据进行早期融合。该方法通过实现一个可学习的潜在查询，将这两种信息流联合关注，从而生成增强上下文的笔迹嵌入，这提升了对不同书写者的区分能力。实验表明，该方法在IAMOn-DB和VNOn-DB数据集上取得了最先进的准确率，提高了1%。同时，该方法在ISIAir数据集上的适应性改进也得到了验证。
## Innovation
本文提出了一种端到端的手写识别系统，能够在共享潜在空间内融合离线图像和在线笔迹信息，通过使用轻量级Transformer模型嵌入笔迹序列，并采用学习可变潜在查询进行联合关注，从而增强手写识别的能力。相较于现有方法，该系统在保持高识别准确率的同时，更好地适应了不同书写者的需求。此外，该模型进行了即插即用的手势化改进，展示了其在不同数据集上的灵活性。
## Conclusion
本文提出的方法在集成离线和在线特征的手写识别方面取得了显著进展，通过早期融合和学习可变潜在查询增强了上下文信息，提高了模型在不同数据集上的表现。实验结果表明，该方法达到了最先进的准确率，展示了其在手写识别领域的高适应性和高性能。
# 521. `cs.LG` - 通用有损压缩中的探索-利用权衡 [PDF](https://arxiv.org/pdf/2506.20261), [HTML](https://arxiv.org/abs/2506.20261)
## Authors
Nir Weinberger,Ram Zamir
## Background
通用压缩能够在批量模式（前向适应）或顺序模式（后向适应）下学习源数据并适应它。论文将顺序模式重新表述为多臂 bandit 问题，这是强化学习中的基本模型，并研究了有损压缩中的探索和利用之间的权衡。研究了已提出的‘自然类型选择’方案，并将其视为顺序有损压缩的重建导向多臂 bandit 算法，同时指出了其鲁棒性和短块性能方面的局限性。在此基础上，推导并分析了鲁棒成本导向多臂 bandit 算法，这些算法适用于任何块长度。
## Innovation
将顺序模式重新表述为多臂 bandit 问题；将‘自然类型选择’方案重新解释为重建导向的多臂 bandit 算法，并提出新的鲁棒成本导向多臂 bandit 算法，这些算法适用于任何块长度。
## Conclusion
研究了在有损压缩中的探索和利用之间的权衡。提出了新的鲁棒成本导向多臂 bandit 算法，这些算法可以在任何块长度上工作。
# 522. `cs.LG` - 正则化深度矩阵分解的完整损失景观分析 [PDF](https://arxiv.org/pdf/2506.20344), [HTML](https://arxiv.org/abs/2506.20344)
## Authors
Po Chen,Rujun Jiang,Peng Wang
## Background
尽管深度矩阵分解（DMF）在各个领域有着广泛的应用，但其优化基础仍然缺乏深入研究。特别是，关于其正则化问题的损失景观仍然存在很大的研究空间。因此，本研究瞄准这个空白，对正则化DMF问题的损失景观进行了全面的分析。
## Innovation
研究首次提供了所有临界点的闭形式表达式，并建立了在何种精确条件下一个临界点是局部极小值点、全局极小值点、严格鞍点或非严格鞍点。此外，提出了一个必要且充分的条件，使得每个临界点要么是局部极小值点要么是严格鞍点。这为为什么基于梯度的方法几乎总是收敛到正则化DMF问题的局部极小值点提供了洞察。
## Conclusion
通过数值实验，进一步可视化了在不同设置下正则化DMF问题的损失景观，以支持研究理论。
# 523. `cs.LG` - Biomed-Enriched：利用LLM增强的生物医学数据集及其在预训练和提取稀有隐藏内容中的应用 [PDF](https://arxiv.org/pdf/2506.20331), [HTML](https://arxiv.org/abs/2506.20331)
## Authors
Rian Touchent,Nathan Godey,Eric de la Clergerie
## Background
在生物医学领域，获取临床文本数据常常受限于隐私保护等约束，导致数据难以访问。因此，研究者提出了一种通过两阶段注释过程构建的Biomed-Enriched数据集。该数据集基于PubMed，通过一个大型语言模型首先对40万篇PubMed科学文章的段落进行注释，再利用这些注释对小型语言模型进行微调，从而能从PMC-OA语料库中提取出更精细的子集，并通过质量筛选和领域扩展构建多种变体。
## Innovation
研究通过设计一种两阶段注释过程，利用大型语言模型对PubMed大量文章进行初步分类，并将这些标签传播到大型语料库中，从而构造出一种新的数据集。该数据集不仅包含大量临床案例文本，而且还加以质量筛选和领域扩展，增加了数据集的质量和多样性。此外，通过与OLMo2的持续预训练实验，研究发现这些方法能够有效提升特定任务的性能，并且使用更少的训练数据能达到相同的效果，表明新型预训练策略的潜力。
## Conclusion
Biomed-Enriched数据集为生物医学和临床自然语言处理提供了高质量和多样化的数据资源，通过有针对性的数据筛选和领域扩展，可以显著提升某些任务的性能，并且使用更少的数据出现相同的训练效果，预示着更高效的预训练策略的发展前景。
# 524. `cs.LG` - 基于循环神经网络的具有闭环区域增量ISS的鲁棒控制系统及其在MPC设计中的应用 [PDF](https://arxiv.org/pdf/2506.20334), [HTML](https://arxiv.org/abs/2506.20334)
## Authors
Daniele Ravasio,Marcello Farina,Alessio La Bella,Andrea Ballarino
## Background
本文研究了一类循环神经网络描述系统的输出反馈方案设计。这些系统适用于需要动态估计和反馈控制的场景，特别是在存在外部干扰和状态估计不确定性时，如何保证系统的稳定性和鲁棒性是关键问题。文章利用全局和区域增量输入到状态稳定性（增量ISS），提出了基于线性矩阵不等式的观测器和静态状态反馈控制器设计方法。这一方法能够提高系统的追踪性能和鲁棒性。为了克服区域增量ISS的局限性，引入了一种使用区域增量ISS特性的管基非线性模型预测控制（NMPC）方法，以扩大吸引域并提供收敛和递归可行性保证。通过pH中和过程基准的数值模拟验证了方法的有效性。
## Innovation
提出了一种基于线性矩阵不等式的控制器设计方法，利用全局和区域增量ISS，提出了一种新的管基NMPC方案。这些控制策略通过提高对干扰的鲁棒性和保证系统的收敛性，扩大了系统的工作范围。该研究结合理论分析和数值仿真，展示了在复杂系统控制中的实际应用潜力。
## Conclusion
研究表明，基于增量ISS方法的控制方案能够有效提高系统的鲁棒性和追踪性能。提出的NMPC方法进一步扩大了系统的吸引域，并确保了控制算法的逐渐可行性和收敛性，在pH中和过程控制中表现出了良好的效果。
# 525. `cs.LG` - 自监督动作识别中的特征幻视 [PDF](https://arxiv.org/pdf/2506.20342), [HTML](https://arxiv.org/abs/2506.20342)
## Authors
Lei Wang,Piotr Koniusz
## Background
动作识别在视频中需要超出原始像素分析，还需要高层次的语义推理和多模态特征的有效整合。现有的方法往往依赖于单一模态的数据，缺乏对情境线索和关键空间模式（如重要动作用局部化区域）的全面理解，导致识别精度有限。作者提出了一种深度转译动作识别框架，该框架通过联合预测动作概念及其辅助特征，改进了RGB视频帧的动作识别准确性。引入了两种新颖的领域特定描述符：对象检测特征（ODF）和注意检测特征（SDF），分别整合了多个对象检测器的输出和突出了有助于动作识别的时空模式。这些描述符与光流、密集轨迹、骨架数据和音频线索等辅助模态无缝集成。框架兼容最新的架构如I3D、AssembleNet、Video Transformer Network等，能够在不确定的辅助特征时，通过引入aleatoric不确定性建模和稳健损失函数来提高鲁棒性
## Innovation
提出了一种深度转译动作识别框架，通过联合预测动作概念和辅助特征来提高动作识别精度；引入了领域特定描述符，包括对象检测特征（ODF）和注意检测特征（SDF），并将其与多种辅助模态无缝整合；在处理辅助特征不确定性时，引入了aleatoric不确定性建模和稳健损失函数来减少特征噪声
## Conclusion
提出的自监督动作识别框架在多个基准数据集（如Kinetics-400、Kinetics-600和Something-Something V2）上实现了最先进的性能，证明了其在捕捉精细动作动态中的有效性
# 526. `cs.LG` - InvZW: 基于噪声对抗训练的不变特征学习方法在鲁棒图像零水印中的应用 [PDF](https://arxiv.org/pdf/2506.20370), [HTML](https://arxiv.org/abs/2506.20370)
## Authors
Abdullah All Tanvir,Xin Zhong
## Background
本文介绍了基于不变特征学习的新型深度学习框架，用于增强鲁棒的图像零水印。作为零水印方案，该方法不会更改原始图像，并通过在特征空间中进行优化来学习一个参考签名。通过将图像中的噪声对抗学习与重建约束结合起来，实现特征表示对图像扭曲不变且具语义性。通过投影训练后的不变特征到针对目标二进制消息优化的一组可训练参考码，设计了基于学习的多比特零水印方案。广泛的实验表明，该方法在特征稳定性和水印恢复方面均达到最先进的鲁棒性。与现有的自监督和深度水印技术对比也展示了该框架在泛化能力和鲁棒性方面的优越性。
## Innovation
提出了一种基于噪声对抗训练的不变特征学习框架，用于增强鲁棒的图像零水印。该方法包括两个关键模块：通过噪声对抗学习训练特征提取器，生成对图像扭曲具有鲁棒性的语义表达特征集合；通过自适应学习多比特零水印方案，训练后的不变特征被投影到可训练的参考码上，以匹配目标二进制消息。实验结果表明，该方法在特征稳定性和水印恢复方面均达到最先进的鲁棒性。
## Conclusion
实验结果表明，该方法在特征稳定性和水印恢复方面均达到最先进的鲁棒性。与其他现有的自监督和深度水印技术相比，该框架在泛化能力和鲁棒性方面表现出色。
# 527. `cs.LG` - HiWave：基于小波的扩散采样实现无训练高分辨率图像生成 [PDF](https://arxiv.org/pdf/2506.20452), [HTML](https://arxiv.org/abs/2506.20452)
## Authors
Tobias Vontobel,Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber
## Background
扩散模型在图像合成领域展现出卓越的写实性和多样性，但高分辨率训练仍具有巨大的计算负担。现有的零样本生成方法在超分辨率合成方面常常带来诸如对象重复和空间不一致性等视觉缺陷。本研究探讨了在无需训练的情况下，使用预训练的扩散模型生成高分辨率图像的方法，从而显著改善了图像的视觉真实度和结构一致性.
## Innovation
提出了HiWave，一种无训练的零样本方法，通过多阶段管道生成基图，随后进行片断解耦逆过程和新型小波域细节增强模块处理，特别是利用小波变换保持低频成分保证结构一致性，同时引导高频成分来丰富细节点和纹理，从而有效减少了常见视觉缺陷，提高了感知质量.
## Conclusion
实验评估显示HiWave明显解决了先前方法中的视觉问题，达到了更好的感知效果。用户研究也表明，在超过80%的情况下，用户更倾向于HiWave的方法，证明了其在无需重新训练或架构修改的情况下实现高质量超高清图像合成的有效性.
# 528. `cs.LG` - POLAR: 基于悲观模型的动态治疗策略的策略学习算法 [PDF](https://arxiv.org/pdf/2506.20406), [HTML](https://arxiv.org/abs/2506.20406)
## Authors
Ruijia Zhang,Zhengling Qi,Yue Wu,Xiangyu Zhang,Yanxun Xu
## Background
动态治疗策略（DTRs）为医疗、教育和数字干预等需根据个体轨迹动态调整决策的领域提供了优化的序列决策框架。现有统计方法常依赖于强正性假设，无法在数据覆盖率不全时保持稳健性；而脱机强化学习方法则侧重于平均培训性能，缺乏统计保证，并需解决复杂优化问题。
## Innovation
提出了一种新颖的基于悲观模型的策略学习算法POLAR，旨在解决上述挑战。POLAR通过脱机数据估计转换动力学并量化每个历史-动作对的不确定性，然后通过悲观性惩罚抑制高不确定性动作的执行。它不依赖于复杂的最小化最大或约束优化过程，直接针对最终学习策略的非最优性，并提供理论保证，首次在模型基础上提供统计和计算保证，包括政策非最优性的有限样本界。
## Conclusion
POLAR在合成数据和MIMIC-III数据集上的实验结果表明，它在性能上超越了最先进的方法，能够产生接近最优的历史感知治疗策略。
# 529. `cs.LG` - 利用轻量级层次ViT和动态框架实现高效视觉跟踪 [PDF](https://arxiv.org/pdf/2506.20381), [HTML](https://arxiv.org/abs/2506.20381)
## Authors
Ben Kang,Xin Chen,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu
## Background
基于Transformer的视觉跟踪器因其强大的建模能力展现了显著的进步，但由于处理速度较慢，其在资源受限设备中的实用性受到限制。针对这一挑战，本文提出了一种名为HiT的新型高效跟踪模型，旨在在保持高性能的同时实现快速操作。此外，文中还提出了一种基于双图像位置编码的方法，以有效编码空间信息。在此基础上，我们提出了另一种动态跟踪器DyHiT，它能够根据场景复杂性灵活选择具有不同计算需求的路径，实现精度与速度的最佳平衡。最后，我们提出了一种基于DyHiT动态路由架构的无训练加速方法，显著提高了各种高性能跟踪器的执行速度，而不损失准确性。
## Innovation
1. 提出了一种称为HiT的高效跟踪模型，该模型通过引入Bridge Module将轻量级变压器连接到跟踪框架，提升了特征表示质量。2. 提出了一种双图像位置编码方法来有效编码空间信息。3. 提出了DyHiT动态跟踪器，通过动态选择具有不同计算需求的路径，实现了精度与速度的权衡。4. 提出了一种无训练加速方法，显著提高了各种高性能跟踪器的执行速度，而不影响其准确性。
## Conclusion
本文提出了一种高效的视觉跟踪解决方案HiT及其衍生产品DyHiT，通过增强特征表示质量、灵活适应场景复杂性以及无训练加速方法，显著提升了视觉跟踪的执行效率。实验结果表明，DyHiT在NVIDIA Jetson AGX平台上的速度达到了111 fps，并保持了62.4%的AUC值，优于现有方法。对SeqTrack-B256等其他高精度跟踪器的加速效果也非常显著。
# 530. `cs.LG` - 未识别且混淆？理解两塔模型以实现无偏的排名学习 [PDF](https://arxiv.org/pdf/2506.20501), [HTML](https://arxiv.org/abs/2506.20501)
## Authors
Philipp Hager,Onno Zoeter,Maarten de Rijke
## Background
在工业环境中，加性两塔模型是用于处理具有偏差用户反馈的学习排名方法的流行选择。然而，最近的研究揭示了一个令人担忧的现象：使用在性能良好生产系统中收集的点击训练两塔模型会导致排名性能下降。本文探讨了这一观察现象的两个近期解释：日志策略导致的混杂效应以及模型的可识别性问题。
## Innovation
本文理论分析了两塔模型的可识别性条件，展示了在仅使用点击数据恢复模型参数时所需的特定条件。还研究了日志策略对两塔模型的影响，发现当模型能够完美地捕捉用户行为时，日志策略不会引入偏差，而当模型未能完美捕捉用户行为时，尤其是当预测误差与文档位置相关时，日志策略会增强偏差。此外，提出了一个样本加权技术来缓解这些影响，为使用两塔模型的科研人员和实践者提供了实用建议。
## Conclusion
总之，该研究深化了对两塔模型潜在偏差来源的理解，并提供了减轻这些问题的方法，为提高学习到的排名模型的无偏性提供了指导。
# 531. `cs.LG` - 迭代加权最小二乘法的全局收敛性对于鲁棒子空间恢复 [PDF](https://arxiv.org/pdf/2506.20533), [HTML](https://arxiv.org/abs/2506.20533)
## Authors
Gilad Lerman,Kang Li,Tyler Maunu,Teng Zhang
## Background
鲁棒子空间估算在许多机器学习和数据分析任务中至关重要。尽管迭代重新加权最小二乘法（IRLS）是一种优雅且经验上有效的解决该问题的方法，但其理论性质仍然缺乏深入的理解。尤其是在确定条件下，一种具有动态平滑正则化的IRLS变体能够从任何初始化线性收敛到真实的子空间。此外，这项工作还扩展了这些保证至一般的仿射子空间估计，这是一种此前缺乏恢复理论的设置。研究还展示了IRLS通过低维神经网络训练应用中的实际益处。这项研究提供了IRLS在鲁棒子空间恢复中首例环球收敛性保证，同时也是非凸IRLS在微分流形上的全局收敛性保证的首次研究结果。
## Innovation
论文首次证明了一种具有动态平滑正则化的IRLS变体在确定条件下具有环球收敛性，并将其扩展至仿射子空间估计这一缺乏理论支持的场景。这为非凸IRLS在微分流形上的全局收敛性提供了全局保证。
## Conclusion
该研究为鲁棒子空间恢复中IRLS首次提供了全局收敛性保证，并为非凸IRLS在微分流形上的全局收敛性提供了理论基础，同时通过低维神经网络训练的应用展示了其实际效果。
# 532. `cs.LG` - 快速地基于CUDA核函数和PyTorch混合编译的高分辨率地穿透雷达双参数全波形反演方法 [PDF](https://arxiv.org/pdf/2506.20513), [HTML](https://arxiv.org/abs/2506.20513)
## Authors
Lei Liu,Chao Song,Liangsheng He,Silin Wang,Xuan Feng,Cai Liu
## Background
地穿透雷达（GPR）是一种常用的无损探测方法，可用于多种应用领域如土木工程、环境监测和地质勘探。然而，双参数全波形反演（FWI）对于GPR数据的精确和高效求解是一个挑战，传统的方法常常在计算效率和灵活性之间存在权衡。为解决这一问题，本文提出一种通过CUDA核函数和PyTorch混合编译加速的高性能双参数全波形反演框架，结合GPU编程的高效性和Python框架的易用性，以实现对介电常数和电导率两个参数的同时正演与逆演，提高GPR数据的成像精度，并提供多种正则化策略以增强框架的泛化能力。
## Innovation
1. 高性能的双参数全波形反演框架，利用GPU加速，结合CUDA核函数和PyTorch的优势。2. 集成了定制的CUDA核函数到PyTorch的自动微分机制中，实现了介电常数和电导率两个参数的同时反演。3. 提供了多种可选的正则化策略，如总变差和多尺度反演，增强了框架的灵活性和扩展性。
## Conclusion
该研究提出的方法能够在保持高准确性的同时，实现GPR数据的双参数全波形反演，并且具备灵活性和扩展性，适用于多种应用领域，包括工程、环境和地质勘探，为快速GPR成像提供了实际和可扩展的解决方案。
# 533. `cs.LG` - WattsOnAI: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads [PDF](https://arxiv.org/pdf/2506.20535), [HTML](https://arxiv.org/abs/2506.20535)
## Authors
Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang
## Background
随着人工智能（特别是大规模语言模型LLMs）的迅速发展，人们越来越关注模型训练和推理过程中所消耗的能源和产生的碳排放问题。然而，现有的测量和报告工具往往支离破碎，缺乏系统化的度量集成，并且在它们之间的相关性分析上支持有限。这导致难以全面了解和优化AI工作的环境影响。因此，迫切需要一种全面的工具来测量、分析和可视化 energy 使用、电能消耗、硬件性能以及碳排放情况。
## Innovation
WattsOnAI是一个综合性的软件工具包，能够测量、分析和可视化AI工作负载中的能量使用、电能消耗、硬件性能和碳排放。它通过无缝集成现有的AI框架，提供了标准化的报告并导出精细的时间序列数据，支持轻量级的基准测试和可重复性。WattsOnAI还能够深入分析硬件指标和模型性能之间的相关性，从而有助于识别瓶颈并提升性能。通过解决现有工具的关键缺陷，WattsOnAI促使研究社区在考虑能源消耗的同时关注AI工作的原始性能，并推动向更加可持续的“绿色AI”做法的转变。
## Conclusion
WattsOnAI鼓励研究社区在评估AI工作的环境影响与直接性能方面达到平衡，同时促进更多可持续的“绿色AI”实践的发展。
# 534. `cs.LG` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大型语言模型（LLMs）展现了显著的代码生成能力，但在外部库API频繁更新时表现不佳。这一局限性源于模型依赖训练数据中过时的API知识，即使有当前文档的访问权限，也阻碍了在动态环境中的可靠代码生成。
## Innovation
我们提出了ReCode（基于规则的强化学习更新代码），这是一种新颖的框架，模拟了人类程序员适应API变化的过程。具体来说，我们构建了一个包含约2,000个条目的数据集，用于训练LLMs基于更新信息进行版本迁移。我们还引入了改进的字符串相似度度量作为强化学习的奖励。实验表明，ReCode显著提升了LLMs在动态API场景下的代码生成性能，特别是在未见过的CodeUpdateArena任务上。此外，与监督微调相比，ReCode对LLMs一般代码生成能力的影响较小。我们在多种LLM和强化学习算法（GRPO和DAPO）上应用了ReCode，均取得了不同程度的改进。值得注意的是，经过训练的Qwen2.5-Coder-7B在性能上优于32B参数代码指令微调模型和具有相同架构的推理模型。代码已发布在指定的网址上。
## Conclusion
ReCode显著提升了LLMs在API频繁变更环境下的代码生成能力，并且对模型的一般性能影响较小。不同模型和算法在应用ReCode后均取得了持续改进，特别是Qwen2.5-Coder-7B的性能优于32B参数的代码指令微调模型和具有相同架构的推理模型。
# 535. `cs.LG` - Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks [PDF](https://arxiv.org/pdf/2506.20548), [HTML](https://arxiv.org/abs/2506.20548)
## Authors
Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao
## Background
随着深度学习的飞速发展，特别是生成对抗网络（GANs）和扩散模型（DMs）的应用，AI生成的图像被称为?深度伪造?（deepfakes），这些图像几乎与真正的图像无法区分。这些图像在在线社交网络（OSNs）中被广泛共享，引起了对其潜在滥用的担忧。现有的深度伪造检测方法未能考虑OSNs中压缩引入的?块效应?，这会模糊深度伪造的痕迹，并主要集中在原始图像上，这些图像在现实世界中很少遇到。
## Innovation
为解决这些挑战，我们提出了PLADA（Pay Less Attention to Deceptive Artifacts），这是一个新颖的框架，旨在解决配对数据不足和压缩图像无效使用的问题。PLADA由两个核心模块组成：块效应擦除器（B2E），它使用双阶段注意力机制来处理块效应，以及开放数据聚合（ODA），它可以处理配对和非配对数据以提高检测效果。广泛的实验证明，PLADA在OSNs中的深度伪造检测中表现出色，即使在配对数据有限和存在压缩时也超越了现有最佳方法。此外，这项工作将?块效应?引入为深度伪造检测的关键因素，为开放世界场景提供了一个稳健的解决方案。
## Conclusion
PLADA在26个数据集上的广泛实验表明，它在OSNs中实现了深度伪造检测的优异平衡，即使在配对数据和压缩有限的情况下也能超越现有最佳方法。更重要的是，这项工作首次将“块效应”引入深度伪造检测的关键因素，为开放世界场景提供了一个稳健的解决方案。
# 536. `cs.LG` - OctoThinker: 中期训练促进了强化学习的扩展 [PDF](https://arxiv.org/pdf/2506.20512), [HTML](https://arxiv.org/abs/2506.20512)
## Authors
Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu
## Background
在使用强化学习（RL）进行后训练时，不同基础语言模型家族（如Llama和Qwen）表现出不同的行为，特别是在需要大量推理的任务上。关于哪种基础语言模型适合强化学习的问题，对于开发下一代可扩展的基础模型至关重要。本文分析了中期训练策略如何影响强化学习动态，特别是针对Qwen和Llama这两种代表性模型家族。研究表明，高质量的数学语料库显著提升基础模型和强化学习性能，而长期链式思维推理数据则进一步提高了强化学习结果。此外，中期训练的扩展规律性增强了下游的RL性能。但这种策略也带来了一些负面影响，如模型响应的冗长性和RL训练的不稳定性，强调了数据格式化的重要性。
## Innovation
本文提出了一个两阶段的中期训练策略，称为Stable-then-Decay，该策略首先在200B token上以恒定的学习率训练基础模型，然后在三个专注于长期链式思维的分支上以学习率衰减的方式训练20B token，最终形成了OctoThinker模型家族，这些模型表现出强大的RL兼容性，与更RL友好的模型家族（如Qwen）的性能差距也缩小了。此外，研究者还发布了一个包含超过700亿token的数学推理语料库（即MegaMath-Web-Pro-Max），以支持未来的相关研究。
## Conclusion
中期训练策略对强化学习可扩展性产生了显著影响。研究结果表明，持续的中期训练可以增强下游的强化学习性能，而超过的长期链式思维数据则需要适当的数据格式化以减轻模型响应冗长性和RL训练不稳定性的问题。这些发现将有助于塑造未来强化学习时代的基础模型预训练策略。
# 537. `cs.LG` - 通过启用闭环协作控制提高风力发电场功率生产量的强化学习 [PDF](https://arxiv.org/pdf/2506.20554), [HTML](https://arxiv.org/abs/2506.20554)
## Authors
Andrew Mole,Max Weissenbacher,Georgios Rigas,Sylvain Laizet
## Background
传统的风力发电场控制是独立操作每个风力涡轮机以最大化单个功率输出。然而，整个发电场的协同气涡流引导可以显著提高联合风力发电场的能量产出。以前的优化方法主要依赖于静态且低精度的模拟器，未考虑关键的湍流流动动力学。
## Innovation
本工作提出了第一个直接与高精度大涡模拟（LES）集成的强化学习（RL）控制器，能够实现实时对大气湍流响应的协同动态控制策略。RL控制器相对于基线操作实现了4.30%的风力发电场功率输出增加，几乎是静态最佳偏航控制（通过贝叶斯优化获得）的两倍2.19%的增益。这表明动态流动响应控制是风力发电场优化的一个变革性方法，对加速可再生能源部署到净零目标具有直接影响。
## Conclusion
研究结果建立了动态流动响应控制作为一种变革性的风力发电场优化方法，直接对加速可再生能源部署到净零目标具有重要意义。
# 538. `cs.LG` - 显微图像的去耦表示 [PDF](https://arxiv.org/pdf/2506.20649), [HTML](https://arxiv.org/abs/2506.20649)
## Authors
Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone
## Background
显微图像的分析在医学诊断、合成工程和环境监测等多个领域都至关重要。现代图像采集系统使得可以获取大量图像，这需要开发大量的基于深度学习的自动图像分析方法。尽管深度神经网络在这领域表现出色，但模型的可解释性，对于显微图像分析来说，仍然是一个挑战性的问题。因此，本文提出了一种去耦表示学习（DRL）方法，以提高显微图像分类模型的可解释性。
## Innovation
本文提出了一种基于从合成数据中转移所学表示的去耦表示学习（DRL）框架，该框架能够在显微图像分类中提供准确性和可解释性的良好平衡。通过使用不同显微镜图像领域的基准数据集（浮游生物、酵母细胞器、人类细胞），展示了DRL方法的有效性，达到了准确性和解释性的良好平衡。
## Conclusion
研究提出了一个去耦表示学习（DRL）方法，使得在显微图像分类中能够在准确性和可解释性之间取得平衡，这对推动显微图像分析的发展具有重要意义。
# 539. `cs.LG` - 迭代法在确定性约束条件下的随机和有限总和凸优化 [PDF](https://arxiv.org/pdf/2506.20630), [HTML](https://arxiv.org/abs/2506.20630)
## Authors
Zhaosong Lu,Yifeng Xiao
## Background
本文研究了具有确定性约束条件的随机和有限总和凸优化问题。现有方法通常旨在寻找一个均值可行且均值最优的随机解，其中期望约束违例和期望的最优性差距都控制在给定的容差ε内。然而，在许多实际应用中，约束必须几乎肯定地满足，这样才能确保不确定解中的潜在违例风险较为有限。
## Innovation
为解决这个问题，本文提出了一种迭代的第一型方法以找到一个均值绝对可行且工具最优的ε-SFSO解，其中约束违例是确定性地被限制在ε之内，并且期望的最优性差距最多为ε。此外，本文方法仅对一系列适当选择罚参数的二次惩罚子问题使用加速随机梯度(ASG)方案或修改的方差减少ASG方案一次。本文还建立了计算ε-SFSO解所提出方法的一阶黑箱复杂性界限，并导出了使用本文提出方法计算随机优化问题的ε-SFSO解的应用平均近似方法的一阶黑箱复杂性结果。
## Conclusion
证明了提出方法在计算ε-SFSO解时的一阶黑箱复杂性界限。进而，还获得了使用所提出方法通过样本平均近似来解决随机优化问题的ε-SFSO解的竞争性的一阶黑箱复杂性结果。
# 540. `cs.LG` - LARP: Learner-Agnostic Robust Data Prefiltering [PDF](https://arxiv.org/pdf/2506.20573), [HTML](https://arxiv.org/abs/2506.20573)
## Authors
Kristian Minchev,Dimitar Iliev Dimitrov,Nikola Konstantinov
## Background
大规模公共数据集的广泛可得是统计推断和机器学习方法近期成功的关键因素之一。然而，这些数据集中常常包含低质量或被污染的数据，这使得许多学习过程变得敏感。因此如何以及在何种程度上需要预筛选这些公共数据集以促进下游学习的准确性成为了一个问题。这一技术需求需要构建一种在面对被污染数据时能够保护预设下游学习者的稳健的、具有原则性的数据预筛选方法。研究不仅需要在理论上解决这一问题，还需要通过实验验证，以实现实用的解决方案。
## Innovation
本文提出了名为LARP（Learner-Agnostic Robust数据预筛选）的方法来解决在面对复杂学习器（不同类型的下游模型）时的预筛选问题。方法首先在Huber误差估计器和Huber数据污染模型的背景下实例化了LARP框架。通过对特定实例的研究和分析一系列自然的预筛选方法，理论结果表明，在一组异构学习器上执行LARP会导致相比每种学习器单独预筛选的数据在模型性能上的一些损失。研究还通过在真实世界图像和表格数据上的实验验证了这一损失，发现了显著下降的效用。最后，建模了重复（学习器特定）预筛选带来的效用损失与成本之间的权衡。LARP对于大规模数据集具有潜在优势。
## Conclusion
通过对异构学习器执行LARP来寻找一种在最坏情况下的损失最小化的预筛选过程，本文解决了数据预筛选的问题。实验表明在某些数据集上LARP可以降低效用，但通过在博弈论框架下的权衡，展示了LARP在处理大规模数据集时的优势。
# 541. `cs.LG` - 使用观察性分组进行因果表示学习的CXR分类 [PDF](https://arxiv.org/pdf/2506.20582), [HTML](https://arxiv.org/abs/2506.20582)
## Authors
Rajat Rasal,Avinash Kori,Ben Glocker
## Background
因果表示学习旨在挖掘数据生成过程中真正的因果关系，在医学成像中，这种能力能够提高特定任务的潜在特征的一般适用性和鲁棒性。本文研究了通过端到端框架将观察性分组引入疾病分类在胸部X光片中的应用，以实现具有种族、性别和成像视角不变性的可识别表示学习。实验表明，通过这种方式学习的因果表示能够显著提高分类任务的一般适用性和鲁棒性。
## Innovation
引入了通过观察性分组进行因果表示学习的方法，通过端到端框架实现了在胸部X光片疾病分类中的应用，并且通过分组增强了模型的鲁棒性和一般适用性，使得结果更适用于不同的分类任务，特别是在处理种族、性别和成像视角等具有潜在偏见和变量的情况时表现出色。
## Conclusion
实验结果证明了使用分组进行因果表示学习可以显著提高胸部X光片分类任务的一般适用性和鲁棒性。
# 542. `cs.LG` - 长期内存网络的时序反向传播 [PDF](https://arxiv.org/pdf/2103.15589), [HTML](https://arxiv.org/abs/2103.15589)
## Authors
George Bird,Maxim E. Polivoda
## Background
时序反向传播（BPTT）是用于递归神经网络（RNNs）中调整参数的技术。尽管已有Nth有序近似和截断BPTT等方法尝试解决，但这些方法假设RNN仅利用短期依赖性。当前，这种假设是合理的，但随着RNN技术的进步，需要一种新的反向传播方法来处理长期依赖性的情况
## Innovation
文章提出了一种新的方法，使用‘离散前向灵敏度方程’及其变体分别用于单个和多个相互作用的递归回路。这种方法是精确的，并允许网络参数在每一步之间变化，但计算雅可比矩阵是必要的
## Conclusion
随着RNN的发展，为了处理长期依赖性，需要一种新的反向传播方法；本文提出的离散前向灵敏度方程方法可以精确地应对这一挑战，但计算量较大
# 543. `cs.LG` - 向基于社区驱动的机器学习工程代理迈进 [PDF](https://arxiv.org/pdf/2506.20640), [HTML](https://arxiv.org/abs/2506.20640)
## Authors
Sijie Li,Weiwei Sun,Shanda Li,Ameet Talwalkar,Yiming Yang
## Background
大型语言模型驱动的机器学习(ML)代理在自动化ML研究方面显示出巨大的潜力。然而，现有的代理通常在某个给定的研究问题上孤立运作，而不会与其他更广泛的研究社区互动，后者中的人类研究者通常通过分享知识来获得见解并贡献力量。为了弥合这一差距，我们引入了MLE-Live，这是一种实台南平台，用于评估代理与模拟的Kaggle研究社区进行沟通并利用集体知识的能力。基于此平台，我们提出了CoMind，这是一种新颖的代理，能够在社区背景下有效地交换见解并开发新的解决方案。CoMind在MLE-Live上达到了最先进的性能，并在四个正在进行的Kaggle竞赛中平均击败了79.2%的人类竞争对手。我们的代码已在此链接中发布：this https URL
## Innovation
我们通过引入MLE-Live设计，提出了一种新的代理CoMind，它能更好地与模拟的Kaggle研究社区互动，利用集体知识，并能在社区背景下有效交换见解和开发解决方案。CoMind在评估基准上取得了最先进的性能，并在多个Kaggle竞赛中表现优异，超出大量人类竞争对手。
## Conclusion
通过提出MLE-Live和CoMind，我们朝着实现基于社区驱动的机器学习工程代理的目标迈进了一步，展示了在实际社区环境中进行协作和知识共享的机器学习代理的潜能。
# 544. `cs.LG` - 线性混合模型中的可扩展子集选择 [PDF](https://arxiv.org/pdf/2506.20425), [HTML](https://arxiv.org/abs/2506.20425)
## Authors
Ryan Thompson,Matt P. Wand,Joanna J. J. Wang
## Background
线性混合模型（LMMs）是用于分析异质数据的关键工具，如个性化医疗或适应性营销中的数据。随着数据量的增加，这些数据中可能包含数千个候选预测因子，因此需要稀疏性来提高预测和解释能力。然而，现有的稀疏学习方法在超过几百个预测因子时性能不佳，与忽略随机效应的线性模型的稀疏方法相比存在较大差距。这项研究填补了这一空白，提出了一种新的用于LMM子集选择的$boldsymbol{bf bf bf bf 0}$范数正则化方法，能够在包含数千个预测因子的数据集上快速运行。在计算方面，开发了坐标下降算法作为主要工具，并提供了其收敛的保证。还开发了局部搜索算法以帮助在非凸优化曲面上进行搜索。这些算法易于扩展到广义LMM的子集选择。在统计方面，提供了该新方法有限样本下的Kullback-Leibler散度上界。然后通过合成实验展示了其出色的性能，并在生物和新闻学的两个数据集中展示了其实用性
## Innovation
提出了一种新的$boldsymbol{bf bf bf bf 0}$范数正则化方法，能够在包含数千个预测因子的数据集上快速运行。开发了坐标下降算法作为主要工具，并提供了其收敛的保证。还开发了局部搜索算法以帮助在非凸优化曲面上进行搜索。这些算法易于扩展到广义LMM的子集选择。另外，提供了该新方法有限样本下的Kullback-Leibler散度上界
## Conclusion
该研究通过提出新的方法，填补了LMM稀疏学习方法的不足，能够在大规模数据集上进行高效子集选择。计算和统计方面的保证进一步确保了其有效性和可靠性。
# 545. `cs.LG` - DemoDiffusion: 使用预训练扩散策略的一次性人类模仿 [PDF](https://arxiv.org/pdf/2506.20668), [HTML](https://arxiv.org/abs/2506.20668)
## Authors
Sungjae Park,Homanga Bharadhwaj,Shubham Tulsiani
## Background
本文介绍了DemoDiffusion方法，该方法旨在让机器人在自然环境中通过模仿单一的人类示范完成操作任务。该方法基于两个关键洞察：首先，人类示范中的手部运动可以为机器人的末端执行器轨迹提供有用的先验信息，通过解运动学重定位可以转换为粗糙的开环机器人运动轨迹；其次，虽然重定位的运动捕捉任务的整体结构，但它可能无法很好地与合理的机器人动作对齐。本文利用预训练的通用扩散策略对轨迹进行修改，确保轨迹既遵循人类运动，又保持在合理的机器人动作分布内。该方法避免了在线强化学习或人机配对数据的需要，使机器人能够以最少的手动努力适应新的任务和场景。实验表明，DemoDiffusion在模拟和真实环境中都优于基线策略和重定位轨迹，使机器人在基线策略完全失败的任务中也能成功完成任务。
## Innovation
该方法通过以下方式进行创新：首先，利用人类示范中的手部运动作为机器人的先验信息；其次，利用预训练的通用扩散策略对机器人的重新定位轨迹进行修改，确保既遵循人类运动又保持在合理的动作分布内。此外，该方法避免使用在线强化学习和配对的人机数据，实现了机器人对新任务的快速且稳健的适应。
## Conclusion
实验结果表明，无论是模拟还是真实环境，DemoDiffusion都能在基线策略和仅重定位的轨迹中表现出更优异的表现，使机器人能够在更广泛的任务中取得成功，特别是当基线策略无法适用时。通过此方法，机器人能够实现对新任务的有效适应，大大减少了人工干预的需要。
# 546. `cs.LG` - 可解释强化学习综述：概念、算法、挑战 [PDF](https://arxiv.org/pdf/2211.06665), [HTML](https://arxiv.org/abs/2211.06665)
## Authors
Yunpeng Qing,Shunyu Liu,Jie Song,Huiqiong Wang,Mingli Song
## Background
强化学习（RL）是一种流行的机器学习范式，智能代理通过与环境互动来实现长期目标。随着深度学习的复兴，深度强化学习（DRL）已在一系列复杂的控制任务中取得了巨大成功。尽管取得了令人鼓舞的结果，但基于深度神经网络的骨干通常被视为一个黑盒子，阻碍了实践者在需要高度安全性和可靠性的实际场景中信任和使用训练过的代理。为了缓解这一问题，大量文献致力于通过构建内在解释性或事后解释性来揭示智能代理的内在工作原理。本文提供了一项关于可解释强化学习（XRL）现有工作的全面综述，并引入了一个新的分类法，将先前的工作明确分类为模型解释、奖励解释、状态解释和任务解释方法。还回顾了利用人类知识促进代理的学习效率和性能的RL方法，而这类方法在XRL领域通常被忽视。讨论了XRL领域的一些挑战和机遇。这项综述旨在提供XRL的高层次总结，并激发对未来更有效的XRL解决方案的研究。
## Innovation
引入了一个新的分类法，将XRL的现有工作明确分类为模型解释、奖励解释、状态解释和任务解释方法，以及回顾并强调利用人类知识提高代理学习效率和性能的RL方法，这类方法在XRL领域通常被忽视。还详细讨论了一些挑战和机遇，旨在推动未来在XRL方面的研究。此外，收集并分类了开源代码，以支持研究工作。
## Conclusion
本文提供了一项关于可解释强化学习（XRL）现有工作的全面综述，并引入了一个新的分类法，旨在提供XRL的高层次总结，并激发对未来更有效的XRL解决方案的研究。还讨论了XRL领域的一些挑战和机遇，以及收集了一系列开源代码以支持进一步的研究。
# 547. `cs.LG` - 概念瓶颈模型尊重局部性吗？ [PDF](https://arxiv.org/pdf/2401.01259), [HTML](https://arxiv.org/abs/2401.01259)
## Authors
Naveen Raman,Mateo Espinosa Zarlenga,Juyeon Heo,Mateja Jamnik
## Background
基于概念的可解释性方法使用人类可理解的中介来生成机器学习模型的解释。这些方法假设概念预测可以帮助理解模型的内部推理。本文通过分析概念预测器是否利用了“相关”的特征进行预测，来评估这种假设的准确性。若概念预测器未能尊重局部性，则导致解释性的失败，因为基于虚假特征的概念预测使得概念预测的解释变得空洞无物。为评估概念预测器是否尊重局部性，作者构建并使用了三个度量标准来描述模型如何尊重局部性，同时通过理论结果进行了补充分析。每个度量标准都捕捉了不同的扰动概念，并评估扰动“无关”特征是否影响概念预测器的预测结果。研究发现，实践中的许多基于概念的模型未能尊重局部性，因为概念预测器无法始终清晰地区分不同的概念。基于这些发现，作者提出了缓解这一问题的建议
## Innovation
本文提出了三种度量标准来描述模型是否尊重局部性，每个标准都捕捉了不同的扰动概念，并评估了扰动“无关”特征是否影响概念预测器的预测结果。此外，基于这些度量和分析，文章指出了许多基于概念的模型未能尊重局部性的原因，并提出了缓解这一问题的建议
## Conclusion
许多基于概念的模型未能根据不同的概念明确地区分不同的概念，这使得它们未能尊重局部性，导致解释性的失败。作者基于这些发现提出了建议以缓解这一问题
# 548. `cs.LG` - Bilinear MLPs使基于权重的机制解释成为可能 [PDF](https://arxiv.org/pdf/2410.08417), [HTML](https://arxiv.org/abs/2410.08417)
## Authors
Michael T. Pearce,Thomas Dooms,Alice Rigg,Jose M. Oramas,Lee Sharkey
## Background
在深度神经网络中，对于多层感知机（MLPs）如何进行计算的机制理解仍然缺乏。当前的可解释性研究可以从输入数据集中提取隐藏激活特征，但通常无法解释MLP权重如何构建特征。一个挑战是逐元素非线性引入了高阶交互，使得追踪MLP层中的计算变得困难。
## Innovation
本文研究了一种类型的门控线性单元（Gated Linear Unit，GLU）——无逐元素非线性的双线性MLPs，该结构却取得了有竞争力的表现。双线性MLPs可以用三阶张量完全用线性操作表达，允许灵活分析权重。通过特征值分解分析双线性MLP权重的谱结构，展示了可解释的低秩结构，对企业建模、图像分类和语言建模任务进行了分析。利用这种理解，作者创建了对抗样本，发现了过拟合，并仅从权重中直接识别出小的语言模型电路。研究结果表明，双线性层可以作为当前激活函数的可解释替代品，并验证了基于权重的可解释性对于理解深度学习模型的有效性。
## Conclusion
双线性层为基于权重的机制解释提供了一个可替代的解决方案，基于权重的可解释性对于理解深度学习模型是可行的。
# 549. `cs.LG` - 与数据漂移适应的联邦学习客户端聚类 [PDF](https://arxiv.org/pdf/2411.01580), [HTML](https://arxiv.org/abs/2411.01580)
## Authors
Minghao Li(1),Dmitrii Avdiukhin(2),Rana Shahout(1),Nikita Ivkin(3),Vladimir Braverman(4),Minlan Yu(1) ((1) Harvard University, (2) Northwestern University, (3) Amazon, (4) Johns Hopkins University)
## Background
联邦学习（FL）能够在不集中用户原始数据的情况下训练深度模型，从而保护用户隐私。然而，客户端的异质性降低了模型收敛速度并限制了全局模型的准确性。为了解决这一问题，Clustered Federated Learning (CFL) 方法通过将有相似表示的客户端分组，并为每个组训练单独的模型来缓解这一问题。但在实际应用中，客户端数据会随时间变化，我们称之为数据漂移，这会打破集群的一致性并降低性能。数据漂移可以是输出值、输入特征或者它们之间关系的变化。现有的方法在处理数据漂移时存在高开销和不稳定性等问题。
## Innovation
提出了一种名为FIELDING的新框架，它是一种针对不同类型的漂移现象进行低开销处理的CFL方法。FIELDING能够在客户端个体层次检测漂移并执行有选择的重新聚类，以平衡集群质量和模型性能，同时具有对恶意客户端和不同程度异质性的鲁棒性。
## Conclusion
实验结果表明，与现有的最优CFL方法相比，FIELDING在最终模型准确性上提高了1.9-5.9%，并且实现相同准确性的速度提高了1.16-2.23倍。
# 550. `cs.LG` - 无梯度切平面方法在深度神经网络中的主动学习 [PDF](https://arxiv.org/pdf/2410.02145), [HTML](https://arxiv.org/abs/2410.02145)
## Authors
Erica Zhang,Fangzhao Zhang,Mert Pilanci
## Background
主动学习方法旨在提高机器学习中样本的效率性。该论文探讨了一种新的无梯度切平面训练方法，用于任意深度的ReLU网络，并建立了相关的收敛理论。此前，切平面算法仅限于线性模型，而未能有效应用到深度神经网络中，因为它们具有非凸性和非线性决策边界。本文工作填补了这一空白，首次展示出可以将切平面算法扩展应用于深度神经网络，并证明方法的有效性，通过合成数据和真实数据上的情感分类任务进行验证。
## Innovation
本文提出了一个无梯度切平面训练方法，该方法可用于任意深度的ReLU网络，并首次展示了切平面算法可以应用于非凸、非线性的深度神经网络中。借此开发了一个新的深度主动学习方案，该方案在合成数据实验和实际数据的情感分类任务中显示了收敛保证，揭示了可行集的几何收缩率。
## Conclusion
本研究通过提出无梯度切平面训练方法，实现了深度神经网络中的主动学习，并为非凸和非线性模型扩展了切平面算法的应用。实验结果表明，与流行的情感分类基准相比，该方法更为有效。
# 551. `cs.LG` - 通过ReLU MLPs的最大正则性进行最佳逼近以弥合逼近与学习之间的差距 [PDF](https://arxiv.org/pdf/2409.12335), [HTML](https://arxiv.org/abs/2409.12335)
## Authors
Ruiyang Hong,Anastasis Kratsios
## Background
深度学习的基础似乎存在于逼近理论或学习理论的看似对立的观点之间。逼近理论主张使用大规模或表达力强的模型，但不一定需要泛化；而学习理论则关注那些泛化能力强但可能过于小或受限的类。受到在实际应用中深度学习既表现出高度表达力又具有统计可靠性的情况的启发，研究者们提出了这样一个问题：是否存在一个既能泛化又能适用的神经网络类？
## Innovation
本文通过定义一个具有高结构化的ReLU多层感知器（MLP）类来正面回答上述问题，这些MLP是理想的函数逼近器且统计行为良好。所提出的方法不仅能逼近任何$(L,rho)$-Hölder函数，还能保持其正则性，甚至在有限样本下实现几乎最优的样本复杂度$tilde{O}(frac{text{log}(N)}{text{sqrt}(N)})$。这种方法包括新的Kuhn三角剖分构造技术，用于完美贴合线性片段，以及新的证明技巧，这些技巧表明构造不仅保持了Hölder函数的正则性，也保持了任何均匀连续函数的正则性。研究结果暗示神经网络在适当有限集合上可以解决McShane延伸问题。
## Conclusion
通过定义一个具有高结构化的ReLU MLP类，该研究解决了神经网络在表达能力和泛化能力之间的权衡问题，实现了一种几乎最优的样本复杂度，并展示了神经网络在逼近理论和学习理论之间的桥梁作用。
# 552. `cs.LG` - 通过将数据转换为正交于偏见实现反事实公平 [PDF](https://arxiv.org/pdf/2403.17852), [HTML](https://arxiv.org/abs/2403.17852)
## Authors
Shuyi Chen,Shixiang Zhu
## Background
机器学习模型在解决各种领域的复杂问题上展现了极强的能力，但有时会出现偏见决策，导致不同群体受到不平等的对待。虽然在这方面的研究十分丰富，但减少多变量连续敏感变量对决策结果影响的方法仍然缺乏。现有的方法在处理这一问题时存在局限性，尤其是针对连续敏感变量的公平性问题，因此需要新的解决方案来更好地实现反事实公平性。文章基于结构因果模型（SCM）中变量联合正态分布的假设，提出了一种新的数据预处理算法，Orthogonal to Bias (OB)，旨在消除一组连续敏感变量的影响，从而提高机器学习应用中的反事实公平性。该算法不依赖于特定的模型，具有广泛适用性，并且通过引入稀疏变体增强数值稳定性。经过在仿真和真实世界数据集上的实验验证，OB算法能够在不牺牲准确性的情况下有效促进更公平的结果。
## Innovation
本文提出了一个新的数据预处理算法，Orthogonal to Bias (OB)，可以在不依赖特定模型的前提下消除连续敏感变量的影响，通过使数据和敏感变量正交来实现反事实公平。此外，OB算法还包含一个稀疏变体，通过正则化提高数值稳定性。该方法适用于结构因果模型（SCM）中的假设条件，并且已经在不同类别和敏感变量的数据集上得到了验证，显示了有效促进更公平结果的能力。
## Conclusion
本文通过提出新的数据预处理算法OB，解决了多变量和连续敏感变量对机器学习决策的影响问题，通过数据正交的方法提高了反事实公平性。实验结果证明，该方法在保持模型准确性的同时能够有效提高决策的公平性。
# 553. `cs.LG` - SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models [PDF](https://arxiv.org/pdf/2309.05019), [HTML](https://arxiv.org/abs/2309.05019)
## Authors
Shuchen Xue,Mingyang Yi,Weijian Luo,Shifeng Zhang,Jiacheng Sun,Zhenguo Li,Zhi-Ming Ma
## Background
扩散概率模型（DPMs）已在生成任务中取得了显著成功。尽管这些模型采样时等同于解决扩散的SDE或ODE，这明显消耗时间，因此提出了许多基于改进微分方程求解器的快速采样方法。大多数方法倾向于使用扩散的ODE求解，以其高效的特性。然而，随机采样在生成多样性和高质量数据方面可能有额外的优势。本文从两个方面对随机采样进行了全面分析：受控方差扩散SDE和线性多步SDE求解器。基于分析结果，提出了一种改进的高效随机亚当斯方法SA-Solver，用于解决扩散的SDE以生成高质量数据。实验表明，SA-Solver在少量样本采样中超过或可与现有最先进（SOTA）采样方法竞争，并且在适合的函数评估次数（NFEs）下实现SOTA FID结果，特别是在基准数据集上。
## Innovation
提出了改进的高效随机亚当斯方法SA-Solver，用于解决扩散的SDE以生成高质量数据。该方法在少量样本采样中超过了或与现有SOTA采样方法竞争，并在适当的函数评估次数下实现了SOTA FID结果。
## Conclusion
实验结果显示SA-Solver：1) 在少量步骤采样中达到了或超过了现有的最先进的（SOTA）采样方法；2) 在适当数量的函数评估次数下，基准数据集的SOTA FID。研究提出了高效的随机亚当斯方法SA-Solver以提高生成模型采样的速度和质量。
# 554. `cs.LG` - 平衡天平：不平衡数据学习的理论与算法框架 [PDF](https://arxiv.org/pdf/2502.10381), [HTML](https://arxiv.org/abs/2502.10381)
## Authors
Corinna Cortes,Anqi Mao,Mehryar Mohri,Yutao Zhong
## Background
在机器学习中，类不平衡问题仍是一个主要挑战，特别是在具有长尾分布的多类别问题中。现有方法，如数据重采样、成本敏感技术及逻辑损失修改，尽管流行且经常有效，但缺乏坚实的理论基础。例如，我们展示了成本敏感方法并不符合贝叶斯一致性。
## Innovation
本文引入了不平衡分类中泛化的新型理论框架，提出了一种新的类不平衡边际损失函数，适用于二元和多类别场合，并证明了其强大的$H$-一致性和相应的基于经验损失和新颖类敏感Rademacher复杂性的学习保证。利用这些理论成果，设计了一种新颖且通用的学习算法IMMAX（不平衡边际最大化），该算法结合了置信边际，并适用于多种假设集。
## Conclusion
尽管本文侧重于理论研究，也展示了所提算法与现有基线相比的广泛实证效果，证明了其有效性。
# 555. `cs.LG` - 在劫持时间进行对抗推理 [PDF](https://arxiv.org/pdf/2502.01633), [HTML](https://arxiv.org/abs/2502.01633)
## Authors
Mahdi Sabbaghi,Paul Kassianik,George Pappas,Yaron Singer,Amin Karbasi,Hamed Hassani
## Background
随着大型语言模型（LLMs）变得越来越强大和普及，研究其失败案例变得越来越重要。最近在标准化、衡量和扩展测试时计算方面取得的进展为优化模型以在复杂任务上取得高性能提供了新的方法论。本研究探讨如何应用这些进展来解决模型劫持（model jailbreaking）问题，即从对齐的LLMs中引发有害响应的问题。
## Innovation
开发了一种对抗推理的自动劫持方法，利用损失信号来引导测试时的计算，实现了对抗成功率的突破性进展，即使是那些试图通过交换推理时的计算来增加对抗鲁棒性的对齐LLMs也不例外。这种方法提出了理解LLM脆弱性的新范式，为开发更稳健和可信的AI系统奠定了基础。
## Conclusion
通过提出这种方法，本研究不仅实现了对多种对齐LLMs的有效攻击，而且为理解LLM的潜在风险提供了新的视角，为未来的AI系统安全性和可靠性的提高提供了支撑。
# 556. `cs.LG` - 利用参数化量子电路进行言语情感识别中的表征学习 [PDF](https://arxiv.org/pdf/2501.12050), [HTML](https://arxiv.org/abs/2501.12050)
## Authors
Thejan Rajapakshe,Rajib Rana,Farina Riaz,Sara Khalifa,Björn W. Schuller
## Background
量子机器学习（QML）为在复杂信号域中推进表示学习提供了有希望的途径。研究发现，参数化量子电路（PQCs）在语音情感识别（SER）中富有挑战性，因为语音信号中的微妙时间变化和重叠情绪状态使得任务复杂化。为了解决这些挑战，研究人员提出了一种整合PQCs到传统卷积神经网络（CNN）中的混合量子经典架构，利用量子特性如叠加和纠缠来丰富情绪特征表示。
## Innovation
该研究整合了PQCs到常规卷积神经网络（CNN）中，提出了一个混合量子经典架构，利用了量子特性如叠加和纠缠，用来增强情绪特征的表现。实验结果表明，相比纯经典CNN基线，这种混合模型在三个基准数据集（IEMOCAP，RECOLA和MSP-IMPROV）上实现了更好的分类性能，且具有超过50%的可训练参数减少。这为QML的潜在增强情感识别提供了早期证据。
## Conclusion
该研究为未来量子驱动的情绪计算系统打下了基础，并证明了QML在情感识别领域的应用潜力。
# 557. `cs.LG` - 使用深度上下文提炼训练即插即用知识模块 [PDF](https://arxiv.org/pdf/2503.08727), [HTML](https://arxiv.org/abs/2503.08727)
## Authors
Lucas Caccia,Alan Ansell,Edoardo Ponti,Ivan Vulić,Alessandro Sordoni
## Background
在大型语言模型预训练之后动态整合新信息或快速发展的信息在低数据场景或处理私人和专门文档时仍然具有挑战性。当前基于上下文学习和检索增强生成（RAG）的方法存在高推理成本及无法捕捉文档全局信息的局限性。
## Innovation
该论文提出了一种通过训练文档级知识模块（KMs）来模块化知识的方法。KMs作为轻量级、参数高效的LoRA模块，能够存储新文档的信息，并在需要时插入模型中。该论文还提出了一种名为“深度上下文提炼”的方法，通过学习KM参数使其模拟带有文档上下文的教师模型的隐藏状态和logits，从而优于传统的下一个令牌预测和预指令训练技术。
## Conclusion
该方法在两个数据集上均表现出色，并且强调了KMs与RAG之间的协同作用。
# 558. `cs.LG` - 遵循扰动领导者方法逼近两全其美的m-集合半 bandeit 问题 [PDF](https://arxiv.org/pdf/2504.07307), [HTML](https://arxiv.org/abs/2504.07307)
## Authors
Jingxin Zhan,Yuchen Xin,Chenjie Sun,Zhihua Zhang
## Background
本文考虑了一个组合半 bandeit 问题的常见情况，即 m-集合半 bandeit 问题，其中学习者从总共有 d 条手臂中恰好选择 m 条手臂。在对抗环境设定中，已知的最佳后悔界是 FTRL 策略的 O(√(nmd))，但在每个时间步都需要显式地计算手臂选择概率并通过优化问题来实现采样。而 FTPL 策略通过随机扰动并选择 m 个最小估计损失的手臂来避免这个问题，但其后悔界为 O(√(m)(√(d log d) + m^(5/6)))。此外，本文证明了在对抗环境设定中，使用 Fréchet 扰动的 FTPL 方法可以同时实现近最优后悔界，并在随机环境设置中实现日志后悔界。
## Innovation
本文提出了在对抗环境设定中使用 Fréchet 扰动的 FTPL 方法，不仅实现了近最优后悔界，还在随机环境设定中达到了日志后悔界，逼近‘两全其美’的后悔界。此外，本文还证明了这些额外因子是不可避免的，任何改进都需要完全不同且更具挑战性的方法实现。
## Conclusion
本文中的下界表明，使用我们的方法不可避免地需要额外的因子；任何进一步的改进都需要采用完全不同且更具挑战性的方法。
# 559. `cs.LG` - 重新思考早期停止：先精炼，再校准 [PDF](https://arxiv.org/pdf/2501.19195), [HTML](https://arxiv.org/abs/2501.19195)
## Authors
Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach
## Background
机器学习分类器通常会产生概率预测，这对于不同领域的准确和可解释决策至关重要。这些预测的质量通常通过适当的损失来评估，比如交叉熵，它分解为两个部分：校准误差评估一般下的过/欠自信程度，而细化误差则度量区分不同类别的能力。在本论文中，作者提出了一种新颖的关于校准与细化分解的变分公式，揭示了后校准的新视角，并能够快速估算各项指标。有了这种新的视角，作者提供了理论和实验证据表明，在训练过程中，校准误差和细化误差并没有同时最小化。基于验证损失选择最佳训练期导致的是对于两个指标都次优的平衡点。为了应对这个问题，我们提出在训练过程中仅最小化细化误差(Refine)，然后再用标准技术后校准(then Calibrate)。这种新方法可以无缝地集成到任何分类器中，并在多种分类任务上提升性能。
## Innovation
本文提出了一个新的变分公式探究校准与细化分解的关系，揭示了后校准的新视角，并在此基础上提出了一种新的训练策略——训练过程中仅最小化细化误差，然后再进行后校准，可以无缝地集成到任何分类器中，并在多种分类任务上提升性能。
## Conclusion
本文通过理论和实验证明在训练过程中校准和细化误差没有同时最小化，因此基于验证损失选择最佳训练期会导致次优结果。提出的训练策略可以在不牺牲校准性的情况下改善模型的细化能力，从而在各种分类任务上持续提高性能。
# 560. `cs.LG` - 超越拓扑自解释GNN：一种形式解释视角 [PDF](https://arxiv.org/pdf/2502.02719), [HTML](https://arxiv.org/abs/2502.02719)
## Authors
Steve Azzolin,Sagar Malhotra,Andrea Passerini,Stefano Teso
## Background
自解释图神经网络（SE-GNNs）是设计为可解释的GNNs，但它们解释的特性和局限性尚不清楚。本文通过形式化某些流行的SE-GNNs提取的解释，称为“最小解释”（MEs），并与已建立的解释概念——极小蕴含（PI）和忠实解释——进行比较，填补了这一空白。研究发现MEs与PI解释在某些限制条件下匹配，但一般而言，它们可能不如PI解释信息丰富，并且出乎意料地与广泛认可的忠实性概念不一致。虽然PI和忠实解释有信息量，但它们难以找到，并且通常规模很大，这给实际应用带来了挑战。因此，本文提出了一种双通道GNN，结合了白盒规则提取器和标准SE-GNN，自适应地结合两者，以弥补SE-GNNs的局限性。实验表明，即使是最简单的双通道GNN实例也能恢复简明规则，并与广泛使用的SE-GNNs相当或更优。
## Innovation
本文提出了双通道GNN（Dual-Channel GNNs），它结合了一个白盒规则提取器和标准SE-GNN，自适应地结合两者，以应对自解释GNNs的信息冗余和难以理解的问题。这种新的架构能够更好地处理复杂任务，并提供比传统SE-GNN更简洁和有效的解释。
## Conclusion
尽管双重通道GNN具有很多优势，但简单的实现已经能够提供简明的规则，并且在性能上与广泛使用的自解释GNNs相当或更优。
# 561. `cs.LG` - 利用解耦扩散序列蒙特卡罗方法求解线性高斯贝叶斯逆问题 [PDF](https://arxiv.org/pdf/2502.06379), [HTML](https://arxiv.org/abs/2502.06379)
## Authors
Filip Ekström Kelvinius,Zheng Zhao,Fredrik Lindsten
## Background
近期的研究工作揭示了预训练生成扩散模型在解决贝叶斯逆问题中的潜力。本文基于解耦扩散的概念，设计了一种适用于线性高斯逆问题的序列蒙特卡罗方法，通过这种方法，能够进行更大的样本更新。研究者进一步展示了该方法（Decoupled Diffusion Sequential Monte Carlo，DDSMC）在合成数据、蛋白质数据以及图像数据上的有效性，并探讨了该方法如何扩展以适用于离散数据。
## Innovation
本文提出了一种新的序列蒙特卡罗方法，称为 Decoupled Diffusion Sequential Monte Carlo (DDSMC)，旨在提高样本更新的灵活性。该方法特别适用于线性高斯逆问题，通过解耦扩散策略，能够进行比传统方法更大的样本更新，从而提高了算法的效率和准确性。研究还验证了该方法在多种数据类型上的有效性，包括合成数据、蛋白质和图像数据，并展示了其扩展至离散数据的能力。
## Conclusion
本研究提出的方法在解决线性高斯逆问题表现出了显著的效果。通过实验验证，DDSMC 算法在合成数据、蛋白质和图像数据上的性能优于传统方法，并展示了对离散数据的有效扩展能力。未来有望进一步提升算法的性能和适用范围。
# 562. `cs.LG` - 基于数据驱动的高分辨率集合天气预报支持可再生能源规划和运营 [PDF](https://arxiv.org/pdf/2505.04396), [HTML](https://arxiv.org/abs/2505.04396)
## Authors
Jingnan Wang,Jie Chao,Shangshang Yang,Congyi Nai,Kaijun Ren,Kefeng Deng,Xi Chen,Yaxin Liu,Hanqiuzi Wen,Ziniu Xiao,Lifeng Zhang,Xiaodong Wang,Jiping Guan,Baoxiang Pan
## Background
可再生能源，特别是风能的规划和运行高度依赖于精确、及时且高分辨率的天气信息。全球粗网格数值天气预报通常会进行降尺度处理以满足这一需求，这带来了一系列挑战，包括尺度不一致、过程表示误差、计算成本增加以及从混沌性、模型偏差和大规模强迫中交织产生的多种不确定性源。
## Innovation
本文通过学习目标风电场的高分辨率数值天气模拟的气候分布，采用其高分辨率的气候先验与粗网格的大尺度预报的最佳组合，提供了高准确度、高精细度、多变量、大规模集合的天气模式预报。这种方法在确定性或概率技能以及经济效益上与现有的数值/统计预报降尺度管线相比具有优势。此外，该方法在中等性能的GPU上进行，计算100成员、10天的1公里空间分辨率和15分钟输出频率的预报仅需少于1小时，而传统的数值模拟需要约1000小时的CPU时间，这种方法大幅降低了计算成本同时保持了高准确度，为可再生能源规划和运营提供了更高效和可靠的方法
## Conclusion
通过在保持高准确度的同时大幅降低计算成本，该方法为可再生能源的规划和运营开辟了新的途径。
# 563. `cs.LG` - 为隐私意识 retrosynthesis 学习设计的基于化学知识的框架 [PDF](https://arxiv.org/pdf/2502.19119), [HTML](https://arxiv.org/abs/2502.19119)
## Authors
Guikun Chen,Xu Zhang,Xiaolin Hu,Yong Liu,Yi Yang,Wenguan Wang
## Background
化学反应数据是推动制药、材料科学和工业化学等领域前进的关键资产。由于这些数据具有专有性，常常包含组织希望保护的机密洞察和竞争优势，因此需要保密。然而，基于机器学习的逆合成分析的标准训练范式却需要将来自多个来源的反应数据集中在一个边缘上进行训练，这样会带来重大的隐私风险，涉及到组织间广泛的数据共享和频繁的数据传输，可能会导致敏感信息被未授权访问或拦截。
## Innovation
本文提出了一种基于化学知识的设计，称为‘化学知识告知框架（CKIF）’，这是一种用于学习逆合成模型的隐私保护方法。CKIF 允许跨多个化学组织进行分布式训练，而不泄露专有反应数据。CKIF 通过迭代和基于化学知识的模型参数聚合来学习逆合成模型，而不是收集原始反应数据。它利用预测反应物的化学特性来定量评估各模型的可观察行为，并据此确定模型聚合的自适应权重。
## Conclusion
在各种化学反应数据集上，CKIF 明显优于几种强大的基线方法，显示了其在保护隐私前提下进行逆合成学习的能力和优势。
# 564. `cs.LG` - 使用合成数据证明提高少样本模型泛化能力的方法 [PDF](https://arxiv.org/pdf/2505.24190), [HTML](https://arxiv.org/abs/2505.24190)
## Authors
Lan-Cuong Nguyen,Quan Nguyen-Tri,Bang Tran Khanh,Dung D. Le,Long Tran-Thanh,Khoat Than
## Background
少样本图像分类因其训练标记样本稀缺而具有挑战性。利用合成数据可以缓解这个问题，但训练模型时合成样本和真实样本之间存在的分布差异会导致性能下降。本文开发了一个理论框架，量化这种分布差异对监督学习的影响，并提供生成良好合成样本和训练具有高泛化能力预测器的方法。基于该框架，提出了一种新的理论算法，结合原型学习优化数据分区和模型训练，从而有效克服真实少样本数据与合成数据之间的差距。
## Innovation
提出了一个理论框架来量化分布差异对监督学习的影响，并提供优化合成样本和提升模型泛化能力的方法。基于此框架并结合原型学习，提出了一个新的理论算法，可以更好地融合真实和合成数据，提升模型性能。
## Conclusion
通过广泛实验证明，本文提出的方法在多个数据集上的表现优于当前最先进的方法，显示出优越的性能。
# 565. `cs.LG` - 关于前进-前进算法的进步 [PDF](https://arxiv.org/pdf/2504.21662), [HTML](https://arxiv.org/abs/2504.21662)
## Authors
Mauricio Ortiz Torres,Markus Lange,Arne P. Raulf
## Background
前进-前进算法已在机器学习研究中不断发展，应对更复杂、更贴近实际应用的任务。近年来，该算法通过多种技术改进提高了性能，在处理如CIFAR10这样的挑战性数据集时，仍保持了其灵活性和低内存使用的特点。我们的结果表明，通过结合卷积信道分组、学习率计划以及训练阶段的独立块结构，实现了测试错误率20%的显著下降。
## Innovation
我们通过对卷积信道进行分组、设置学习率计划以及训练阶段采用独立块结构，提出了改进的前进-前进算法。此外，我们还提出了一系列轻量级模型，这些模型在测试错误率（21 ± 3%）和可训练参数数量（164,706到754,386）上都表现良好，为在低容量硬件项目中的进一步实现奠定了基础。
## Conclusion
这些改进为未来全面验证和验证此类神经网络提供了基础。
# 566. `cs.LG` - Log-Linear Attention [PDF](https://arxiv.org/pdf/2506.04761), [HTML](https://arxiv.org/abs/2506.04761)
## Authors
Han Guo,Songlin Yang,Tarushii Goel,Eric P. Xing,Tri Dao,Yoon Kim
## Background
Transformer模型中的注意力机制是实现准确且可扩展的序列建模的重要基础组件。然而，其计算复杂度为平方阶，内存复杂度为线性，仍然是显著的瓶颈。尽管线性注意力和状态空间模型能够实现线性时间和常数内存的序列建模，并可以通过在整个序列长度上的矩阵乘法丰富并行化来高效训练，但这些模型本质上仍然是RNN，其使用固定大小的隐藏状态来建模上下文，这是一个根本的局限性。
## Innovation
本文提出了对数线性注意力（log-linear attention）机制，这种机制结合了线性注意力的高效性和softmax注意力的表达能力。对数线性注意力用对数增长的隐藏状态集取代了固定大小的隐藏状态。通过特定的生长函数，对数线性注意力具有类似于矩阵乘法丰富的并行形式，计算成本也呈对数序列长度增长。对数线性注意力是一种通用框架，可以在现有的线性注意力变体之上应用。作为案例研究，作者在两个最新的架构Mamba-2和Gated DeltaNet上实现了对数线性变体，并发现它们的表现优于原有的线性时间变体。
## Conclusion
对数线性注意力机制为线性时间和常数内存下的序列建模提供了新的可能性，它克服了RNN使用固定大小隐藏状态来建模上下文的局限，并且可以与现有线性注意力变体结合使用，显示出良好的性能。
# 567. `cs.LG` - TSPulse：双空间超紧凑预训练模型用于快速时间序列分析 [PDF](https://arxiv.org/pdf/2505.13033), [HTML](https://arxiv.org/abs/2505.13033)
## Authors
Vijay Ekambaram,Subodh Kumar,Arindam Jati,Sumanta Mukherjee,Tomoya Sakai,Pankaj Dayama,Wesley M. Gifford,Jayant Kalagnanam
## Background
时间序列预训练模型的发展提高了时间序列表示学习的能力，但当前最先进的模型通常规模庞大，需要大量的计算资源。TSPulse 是一种超紧凑的时间序列预训练模型，仅包含100万参数，专门适用于分类、异常检测、插补和检索等任务。
## Innovation
TSPulse 在架构和任务层面都引入了创新。在架构层面，它采用了双空间掩码重建，从时间域和频域两方面学习以捕获互补信号，并进一步通过双嵌入脱混机制生成详细嵌入用于细致分析，以及高级语义嵌入用于更广泛的任务理解。TSPulse 的语义嵌入对时间、幅度和噪声变化具有鲁棒性，这对于稳健的检索至关重要。在任务层面，TSPulse 引入了 TSLens 细调组件，使其能够支持任务特定的功能注意力；还引入了多头三角化技术，通过融合多个预测头的互补输出来增强异常检测；提出了一种混合掩码预训练方法，以减少预训练偏差，提高零样本插补能力。
## Conclusion
这些架构和任务上的创新为 TSPulse 带来了显著的优势，包括在UEA分类基准上实现了5-16%的性能提升，在TSB-AD异常检测排行榜上提高了20%，在零样本插补中提高了50%，以及在时间序列检索中提高了25%。此外，TSPulse 仅包含100万参数，与现有最先进的模型相比小10-100倍，并且具有无需GPU的推理能力，成为高效时间序列预训练模型的新标杆。模型可以从这个链接访问：this https URL
# 568. `cs.LG` - VRAIL:向量化基于奖励的归因以实现可解释学习 [PDF](https://arxiv.org/pdf/2506.16014), [HTML](https://arxiv.org/abs/2506.16014)
## Authors
Jina Kim,Youjin Jang,Jeongjin Han
## Background
本文提出了基于价值的强化学习(VRAIL)框架，旨在从状态特征中学习可解释的权重表示，改善训练稳定性和收敛性，而无需修改环境。VRAIL通过潜力值奖励变换在学习过程中施加影响，分为两阶段:深度学习(DL)阶段和强化学习(RL)阶段。该估计器可以采用线性和二次形式，能够将重要性归因于单个特征和它们的交互作用。实验表明，VRAIL在出租车环境 Taxi-v3 中的表现优于标准DQN，且能够揭示有意义的子目标，提高了学习过程的可解释性。
## Innovation
VRAIL框架创新性地结合了深度学习和强化学习，通过向量化奖励归因，学习可解释的权重表示，提高了学习稳定性和可解释性，无需对环境进行修改。估计器的形式化选择使得能够量化特征及其交互的相对重要性。实验结果证明了VRAIL的优越性，在揭示有意义的子目标方面表现尤为突出，这表明其在奖励塑造方面的普遍适用性和模型无关性。
## Conclusion
VRAIL是一种通用且模型无关的可解释奖励塑造框架，能够在不改动环境的情况下提高强化学习的稳定性和可解释性，揭示出有意义的子目标，帮助生成人类可理解的行为。
# 569. `cs.LG` - 经过训练的嵌入证明性地选择重要词元的注意机制 [PDF](https://arxiv.org/pdf/2505.17282), [HTML](https://arxiv.org/abs/2505.17282)
## Authors
Diyuan Wu,Aleksandr Shevchenko,Samet Oymak,Marco Mondelli
## Background
在语言建模中，词元嵌入起着至关重要的作用，但它们的理论理解仍然有限。本研究通过表征通过梯度下降获得的嵌入结构来填补这一空白，重点关注单层softmax注意模型与线性头进行二元分类的情形。已有研究表明，即使在单一梯度训练步骤后，梯度下降得到的嵌入能够通过与输出向量成比例的方式捕捉词元的重要性，并且随训练进行，在渐近梯度法中训练$p$直至收敛，softmax会选择对标籤有预测性的词元，最终使$texttt{cls}$嵌入最大化这种选择的边缘。通过在真实数据集（IMDB、Yelp）上的实验观察到了理论推测的现象。
## Innovation
本文创新之处在于通过数学证明说明了经过训练的词元嵌入如何通过梯度下降自动选择并正确定位输入序列中的重要词元。具体而言，初次训练后，嵌入能通过与输出向量的对齐比例捕捉词元的频率重要性。随着$p$的训练直至收敛，softmax能选择出关键词元，$texttt{cls}$嵌入则最大化这种选择的边缘。这种理解有助于更加深入地理解大规模语言模型中的词元嵌入结构及其功能。
## Conclusion
实验结果表明，真实数据集上观察到的模式与理论推测相符，进一步验证了这一方法的有效性，并为未来研究大规模语言模型中的词元嵌入结构提供理论基础。
# 570. `cs.LG` - MS-TVNet：基于多尺度动态卷积的长周期时间序列预测方法 [PDF](https://arxiv.org/pdf/2506.17253), [HTML](https://arxiv.org/abs/2506.17253)
## Authors
Chenghan Li,Mingchen Li,Yipu Liao,Ruisheng Diao
## Background
长周期时间序列预测主要依赖于Transformer和MLP模型，而卷积网络在该领域的应用潜力尚未充分挖掘。
## Innovation
提出了一种新颖的多尺度时间序列重塑模块，能够有效捕捉多周期块之间的关系及变量依赖性。在此基础上，提出了MS-TVNet多尺度三维动态卷积神经网络，取得了优于基线模型的长周期时间序列预测效果，达到SOTA水平，表明利用卷积网络捕捉复杂时间模式的有效性，为未来研究提供了新的方向。
## Conclusion
MS-TVNet在长周期时间序列预测中表现出色，实现了SOTA效果，验证了多尺度动态卷积在时间序列预测中的潜力。
# 571. `cs.LG` - 非平衡退火伴随采样器 [PDF](https://arxiv.org/pdf/2506.18165), [HTML](https://arxiv.org/abs/2506.18165)
## Authors
Jaemoo Choi,Yongxin Chen,Molei Tao,Guan-Horng Liu
## Background
近年来，在基于学习的扩散采样器方面取得了显著进展，这些采样器旨在从给定的非标准化密度中采样。这些方法通常遵循两种范式之一：(i) 使用经典的参考过程将采样形式化为无偏的随机最优控制（SOC）问题，或(ii) 通过重要性加权采样细化退火路径测度。尽管退火方法有助于引导样本向高密度区域移动，但对其的依赖性会导致实际上重要的采样具有高方差和有限的可扩展性。
## Innovation
本文引入了非平衡退火伴随采样器（NAAS），这是一种基于SOC的扩散采样器，它利用了退火参考动力学而不依赖于重要性采样。NAAS 使用灵感来自伴随匹配的简约伴随系统，使得训练更加高效和可扩展。
## Conclusion
我们的方法在多种任务上表现出有效性，包括从经典能量景观和分子玻尔兹曼分布中采样。
# 572. `cs.LG` - Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning [PDF](https://arxiv.org/pdf/2506.07744), [HTML](https://arxiv.org/abs/2506.07744)
## Authors
Seungho Baek,Taegeon Park,Jongchan Park,Seungjun Oh,Yusung Kim
## Background
现有的离线分层强化学习方法依赖于高层次策略来生成子目标序列，但在任务持续时间增长时效率会下降，缺乏有效的策略来缝合不同轨迹中的有用状态转换。
## Innovation
提出了一种新的框架——Graph-Assisted Stitching (GAS)，它将子目标选择转化为图搜索问题，而非学习显式的高层次政策。通过将状态嵌入到时间距离表示 (TDR) 空间中，GAS 将来自不同轨迹的语义相似状态聚类为统一的图节点，从而实现高效的状态转换缝合。引入了时间效率 (TE) 渡量来过滤噪音或低效的状态转换，显著提升了任务性能。GAS 在各种任务中优于之前的离线 HRL 方法。
## Conclusion
GAS 在最需要缝合状态转换的任务中达到了 88.3 的评分，远远超过了之前的最佳性能 1.0。源代码可访问：this https URL
# 573. `cs.LG` - Confucius3-Math: 一个轻量高性能的领域特定推理大语言模型，专为中国的K-12数学学习 [PDF](https://arxiv.org/pdf/2506.18330), [HTML](https://arxiv.org/abs/2506.18330)
## Authors
Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan
## Background
该论文介绍了一个由开源4参数组模型Confucius3-Math构成的系统，该系统在单个消费级GPU上高效运行，并在数学推理任务上取得了SOTA性能，超越了许多具有更大规模的模型。该模型特别致力于中国K-12学生和教师的数学学习。通过后续大规模强化学习训练，该模型能够低成本地解决主流的中国K-12数学问题，并且与国家课程体系相契合。通过分享开发过程、遇到的挑战以及克服这些挑战的技术创新，作者强调了在特定领域构建强大推理模型的可行性，即使成本较低也能实现这一目标。
## Innovation
创新点在于：(1) 通过后续大规模强化学习训练来实现高效的部署；(2) 特别针对中国K-12数学学习者和教育者使用；(3) 引入了三种技术创新：目标导向的熵正则化、最近采样恢复和策略特异性困难加权。这些技术创新包括一种新的熵正则化方法、一种新颖的数据调度策略和一个改进的组相比较优势估计器，它们显著稳定了强化学习训练过程，提高了数据利用效率，提升了模型性能
## Conclusion
本论文展示了在特定领域（如K-12数学教育）低成本构建强大推理模型的可行性，并公开了该模型与代码供他人使用。
# 574. `cs.LG` - TabArena：表格数据上机器学习的活基准 [PDF](https://arxiv.org/pdf/2506.16791), [HTML](https://arxiv.org/abs/2506.16791)
## Authors
Nick Erickson,Lennart Purucker,Andrej Tschalzev,David Holzmüller,Prateek Mutalik Desai,David Salinas,Frank Hutter
## Background
随着深度学习和基础模型在表格数据中的流行，标准化和可靠的基准测试需求日益增加。然而，当前的基准测试是静态的，难以根据发现的缺陷、模型版本更新或新模型发布而进行调整。因此，提出了TabArena——首个持续维护的活表格基准测试系统
## Innovation
TabArena通过手动精心挑选的代表性的数据集集合和良好的实施模型，开展了大规模基准测试研究，启动了公共排行榜，并集结了一支经验丰富的维护者团队。主要创新在于能否持续更新并面对各种挑战维护系统的有效性。结果揭示验证方法和超参数配置的集成对实现模型的最大潜能有显著影响，尽管提升树仍然是实践中的强竞争者，但深度学习方法在较大的时间预算和集成下的表现已经追上甚至超过，基础模型在小型数据集上的表现尤为出色
## Conclusion
TabArena的成果展示了模型组合对表格机器学习的先进状态至关重要，还研究了各个模型对表现的贡献。TabArena以公共排行榜、可复现代码和维护规范启动，提供了一个活基准系统，可用作评测表格数据机器学习的持续更新的平台。请参阅此网址：[https://www.tabarena.com] 更多信息。
# 575. `cs.LG` - 量子-经典混合量化神经网络 [PDF](https://arxiv.org/pdf/2506.18240), [HTML](https://arxiv.org/abs/2506.18240)
## Authors
Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen
## Background
本文提出了一种新型的二次二进制优化（QBO）模型，用于量化神经网络训练，并通过样条插值实现了任意激活和损失函数的使用。为此，引入了前向区间传播（FIP）方法，该方法通过对激活函数进行离散化处理，将非线性和多层复合结构的挑战转化为线性子区间优化，从而在保持神经网络的通用逼近能力的同时，允许复杂的非线性函数使用量子计算机进行优化。这是利用量子计算扩展人工智能应用的重要步骤。通过从优化角度推导经验风险最小化问题的样本复杂性，给出了逼近误差的理论上限和所需的Ising自旋数量，从而为理论分析提供基础。然而，大规模求解相关二次约束二进制优化（QCBO）模型的关键挑战是存在大量约束条件。使用惩罚方法处理这些约束时，调整大量惩罚系数成为一个关键的超参数优化问题，这增加了计算复杂性并可能影响解决方案质量。因此，使用了将量子计算直接应用于解决QCBO问题的量子条件梯度下降（QCGD）算法，证明了在量子oracle具有随机性和有界方差的情况下，QCGD的收敛性，并且在系数矩阵存在有限精度限制的情况下，也提供了QCGD的收敛性证明。此外，还给出了QCBO求解过程的时间上限。实验证明，使用相干Ising机（CIM）在时尚MNIST分类任务上达到了94.95%的精度，且精度仅为1.1位。这一结果展示了通过量子计算增强神经网络训练的潜力和可行性。
## Innovation
提出了利用量子优化技术解决量化神经网络训练问题的新方法，通过引入前向区间传播（FIP）方法和量子条件梯度下降（QCGD）算法，解决了传统优化方法难以处理的非线性和多层结构挑战。QCGD算法利用量子计算直接解决QCBO问题，提高了求解精度和效率。同时，还提供了对逼近误差和Ising自旋数量的理论分析，为量子优化在人工智能领域中的应用提供了理论支撑。
## Conclusion
本文提出了一种将量子计算与经典计算相结合的新方法，优化了量化神经网络的训练过程，解决了传统方法在处理非线性和多层结构方面的局限性。通过严格的理论分析和支持实验证明，该方法在精度和效率方面都有显著提升，为使用量子计算机优化复杂非线性函数开辟了新途径。
# 576. `cs.LG` - 午餐没有免费的：重新思考LLM推理的内部反馈 [PDF](https://arxiv.org/pdf/2506.17219), [HTML](https://arxiv.org/abs/2506.17219)
## Authors
Yanzhi Zhang,Zhaoxi Zhang,Haoxiang Guan,Yilin Cheng,Yitong Duan,Chen Wang,Yue Wang,Shuxin Zheng,Jiyan He
## Background
强化学习（RL）已经成为一种强大的后训练方法，用于提升大型语言模型（LLMs）的推理能力。现有方法如强化学习来自人类反馈（RLHF）和可验证奖励的强化学习（RLVR）表现良好，但它们需要大量的外部监督。该研究探讨了一种新的方法类别——内部反馈驱动的强化学习（RLIF），这种方法完全依赖于模型自身产生的信号，而不需要外部奖励。研究利用诸如令牌级熵、轨迹级熵和自我确信等无监督的奖励代理进行实验评估，从而揭示出内部目标在一定程度上的等效性，并展示了各种RLIF策略在数学推理基准上的实验结果。研究发现，RLIF能在模型训练初期显著提升推理性能，甚至与RLVR方法相匹配。然而，随着训练的进行，性能下降甚至低于未训练的模型。此外，对于已进行指令调优的模型，RLIF几乎没有提升效果，表明当LLM已经进行了调优后，内部反馈的效果会逐渐减弱。
## Innovation
该研究提出了内部反馈驱动的强化学习（RLIF）作为提升大型语言模型推理能力的新方法，完全依赖于模型自身产生的信号，不利用外部奖励。研究通过实验评估了RLIF策略在多种基准任务上的效果，发现了其在训练初期的显著优势以及随着训练进行逐渐衰退的现象，并发现了无监督奖励代理的有效性，如令牌级熵、轨迹级熵和自我确信。研究进一步分析了这种方法的局限性，为内部反馈信号的集成提供了一些建议，指导未来更有效地应用内部反馈策略来改进LLM的后训练过程
## Conclusion
研究通过理论分析和实验证明了内部反馈驱动的方法（RLIF）在模型训练初期能显著提升推理性能，但在训练后期性能会逐渐下降，对于已完成指令调优的模型尤其如此。研究揭示了内部反馈信号的优势和局限，并提供了一些建议帮助更好地利用这些信号来训练和改进大型语言模型。
# 577. `cs.LG` - Thought Anchors: Which LLM Reasoning Steps Matter？ [PDF](https://arxiv.org/pdf/2506.19143), [HTML](https://arxiv.org/abs/2506.19143)
## Authors
Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy
## Background
大型语言模型（LLM）已显示出在许多领域达到最先进的性能表现。然而，它们进行长篇文章的链式推理时，由于每个生成的词依赖于之前的所有词，这种推理过程的可解释性面临挑战。本文提出了一种以句子为研究单位分析推理过程的思路，三种不同的归因方法：（1）一种黑盒方法，通过比较模型生成目标句子或意义不同的句子时的最终答案，衡量每句话的反事实重要性；（2）一种白盒方法，聚合句子间注意力模式，并识别接收所有后续句子不寻常大量注意力的句子；（3）一种因果归因方法，通过抑制对某句话的关注，测量对后续句子中词的影响，以衡量句子间的逻辑关系。这些方法提供了‘思维锚点’证据，即具特别重要性且对后续推理过程有重要影响的推理步骤，通常为计划或回溯句子。所提出的方法提供了一个可视化工具，展示不同方法的结论一致性，深入讨论模型的多步骤推理过程。
## Innovation
本文提出了一种通过分析句子级别的推理过程来理解大型语言模型长篇推理的新方法。具体创新点包括三种互补的归因方法：反事实重要性评估、基于注意力模式的白盒方法和因果归因方法。这些方法不仅识别出‘思维锚点’，还提供了对这些关键步骤深入理解的工具，提高对模型推理过程的解析能力。
## Conclusion
句级分析法律保证了部分思维锚点的存在，即那些在推理过程中具有显著重要性并显著影响后续推理过程的步骤。这类锚点句通常涉及计划性或回溯性推理。所提出的方法及其可视化工具显示了利用句级分析深入理解推理模型潜力。不同方法的一致性结果表明其在多步骤推理过程的理解上有较大前景。
# 578. `cs.LG` - 使用随机向量函数链接网络实现高效的均匀近似 [PDF](https://arxiv.org/pdf/2306.17501), [HTML](https://arxiv.org/abs/2306.17501)
## Authors
Palina Salanevich,Olov Schavemaker
## Background
RVFL是一种深度为2的神经网络，具有随机的内部权重和偏置。仅需学习其外部权重，因此学习过程简化为一个线性优化任务，可以避免非凸优化问题的陷阱。已有研究证明了RVFL在某种条件下能逼近连续函数，但使用标准正态分布作为内部权重的RVFL在无限范数下的逼近结果尚未见报道。该研究填补了这一空白，证明了具有ReLU激活函数的RVFL在网络函数为Lipschitz连续函数时，可以在无限范数下进行逼近。该文提供了在给定精度下隐藏层节点数的非渐近下界，该下界依赖于目标函数的Lipschitz常数、期望精度和输入维度等因素。证明方法结合了概率理论和调和分析的知识背景.
## Innovation
首次证明了具有标准正态分布内部权重且使用ReLU激活函数的RVFL网络在无限范数下能够逼近Lipschitz连续函数。提出了一种非渐近地确定隐藏层节点数量的方法，以实现高概率下的给定准确性逼近，这对于理解RVFL的逼近能力有重要意义。方法结合了概率论和调和分析，为RVFL网络理论研究提供了新的视角.
## Conclusion
该研究证明了具有ReLU激活函数的RVFL网络具有在无限范数下逼近Lipschitz连续函数的能力，并提供了实现高概率下给定精度逼近所需的隐藏层节点数量的下界。这不仅为RVFL在实际应用中提供了理论支持，也对神经网络的优化技术有重要意义。同时，证明方法的创新性也为未来的研究指明了方向。
# 579. `cs.LG` - LT-PINN: 拉格朗日意识物理引导神经网络在边界导向工程优化中的应用 [PDF](https://arxiv.org/pdf/2506.06300), [HTML](https://arxiv.org/abs/2506.06300)
## Authors
Yuanye Zhou,Zhaokun Wang,Kai Zhou,Hui Tang,Xiaofan Li
## Background
物理引导神经网络(PINNs)作为一种无网格工具，已经被证明在拓扑优化中发挥着重要作用，能够同时确定最优拓扑和物理解决方案。然而，传统PINNs依赖于基于密度的拓扑描述，这需要手动插值，且在处理复杂几何形状时效果有限。LT-PINNs通过将拓扑边界曲线的控制变量作为可学习参数，解决了这个问题，无需手动插值，能够精确确定边界。
## Innovation
提出了拉格朗日意识物理引导神经网络(LT-PINNs)，这是一种新的边界导向工程优化框架。LT-PINNs通过参数化拓扑边界曲线的控制变量作为可学习参数，消除了手动插值的需要，并启用精确的边界确定。此外，还引入了特定的边界条件损失函数和拓扑损失函数，确保即使对于复杂的拓扑，也能获得清晰且准确的边界表示。LT-PINNs被验证在不同类型偏微分方程(PDEs)中有效，包括弹性方程与狄里克莱边界条件和拉普拉斯方程与纽曼边界条件。此外，LT-PINNs在无须依赖测量数据的情况下，也被应用于更复杂的时依赖性和时不变流问题中，并展示其工程应用潜力。
## Conclusion
结果表明，(1)LT-PINNs相比最先进的基于密度的拓扑导向PINNs(DT-PINNs)在相对L2误差上取得了显著降低；(2)LT-PINNs能够处理任意边界条件，适用于广泛的PDEs；(3)LT-PINNs可以在无需手动插值的情况下推断清晰的拓扑边界，特别是在复杂拓扑中表现尤为突出。
# 580. `cs.LG` - 灵活的无限宽度图卷积神经网络 [PDF](https://arxiv.org/pdf/2402.06525), [HTML](https://arxiv.org/abs/2402.06525)
## Authors
Ben Anson,Edward Milsom,Laurence Aitchison
## Background
神经网络的共同理论方法是在无限宽度极限下运行，此时输出变得遵循高斯过程分布，这被称为神经网络高斯过程（NNGP）。尽管NNGP展示了一定的理论价值，但其内核固定且只能通过少量超参数调整，消除了代表学习的可能性。相比之下，有限宽度的神经网络通常被认为更为有效，因为它们可以灵活地学习用于任务的表示。因此，在使神经网络理论化时，NNGP可能去除了其有效运作的关键因素（即代表学习）。这促使我们探索在一系列图任务中是否需要代表学习。研究表明，对于异质节点分类任务，代表学习可以带来显著的性能提升；而对于同质节点分类任务，效果则不那么明显。因此，虽然NNGP简化了网络使其理论上更易于处理，但同时也可能消除了其有效性的关键因素。
## Innovation
本文开发了一种精确工具——图卷积深度核机，这是一种类似于NNGP的无限宽度极限和使用核函数的方法，但提供了一个控制灵活性的“调节器”，从而可以控制代表学习的程度。这种工具允许在理论化过程中保留代表学习这一关键因素，从而使无限宽度的神经网络在实际应用中保持有效性。
## Conclusion
代表学习对于异质节点分类任务具有显著的性能提升作用，但对于同质节点分类任务的影响较小。因此，在特定任务中，代表学习是必要的，且可以通过灵活调整无限宽度图卷积神经网络来优化性能。
# 581. `cs.LG` - COBRA-PPM：使用概率编程的因果贝叶斯推理架构在不确定性机器人操作中的应用 [PDF](https://arxiv.org/pdf/2403.14488), [HTML](https://arxiv.org/abs/2403.14488)
## Authors
Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze
## Background
机器人进行操作任务时需要推理因果关系，但是很多数据驱动的方法缺乏因果语义，仅考虑相关性。因此，论文提出了COBRA-PPM，这是一种结合因果贝叶斯网络和概率编程的新颖的因果贝叶斯推理架构，用于在不确定性条件下进行机器人操作的干涉性推理。
## Innovation
COBRA-PPM架构创新地集成了因果贝叶斯网络和概率编程，能够进行干涉性的推理，适用于不确定条件下的机器人操作。实验证明其预测操作结果的准确率为88.6%，并且成功地完成了任务的选择，成功率达到了94.2%。此外，该架构在从仿真到现实的转化中也显示了有效性，可以处理来自传感器噪声和随机动作的实际不确定性。
## Conclusion
该研究提出了一种通用且可扩展的框架，支持广泛的操作场景，并为机器人与因果关系结合的未来研究奠定了基础。
# 582. `cs.LG` - Offline Goal-Conditioned Reinforcement Learning with Projective Quasimetric Planning [PDF](https://arxiv.org/pdf/2506.18847), [HTML](https://arxiv.org/abs/2506.18847)
## Authors
Anthony Kobanda,Waris Radji,Mathieu Petitbois,Odalric-Ambrym Maillard,Rémy Portelas
## Background
Offline Goal-Conditioned Reinforcement Learning旨在通过对预先收集的轨迹进行训练来使智能体能够到达指定的目标。然而，对于长期任务来说，如何规模扩展这一学习方法仍然极具挑战性，特别是在累积的价值估计误差累积的问题上。几何学上的基础理论为解决这些问题提供了一种潜在的解决方案。基于此，作者引入了投影准度量规划（ProQ），这是一种组合式框架，通过学习非对称距离并重新利用它，首先作为排斥能量迫使关键点均匀分布在学习的潜在空间中，其次作为结构化的方向成本引导向相邻子目标。特别地，ProQ将这种方法与异常值分布检测器结合起来，以确保学习到的关键点保持在可到达的区域内。通过将度量学习、关键点覆盖和目标条件控制统一起来，这种方法能够产生有意义的子目标，并在各种导航基准上稳健地驱动长时间目标捕捉任务。
## Innovation
ProQ 是一种新的组合式框架，具有以下创新点：1）它学习了一个非对称距离，并将其用作排斥能量和结构化方向成本，这有助于智能体均匀分布关键点并引导向相邻子目标。2）它通过结合拉格朗日错误分布检测器，确保学习到的关键点保持在可到达区域，从而提高了目标捕捉的稳健性。3）通过统一度量学习、关键点覆盖和目标条件控制，它能够产生有意义的子目标，稳妥地进行长时间目标捕捉任务。
## Conclusion
通过统一度量学习、关键点覆盖和目标条件控制，我们的方法能够产生有意义的子目标，并且在多样化的导航基准上稳健地驱动长时间目标捕捉。
# 583. `cs.LG` - 众包中的数据质量和刷单行为检测 [PDF](https://arxiv.org/pdf/2404.17582), [HTML](https://arxiv.org/abs/2404.17582)
## Authors
Yang Ba,Michelle V. Mancenido,Erin K. Chiou,Rong Pan
## Background
随着众包作为一种有效的低成本方法，用于获取机器学习数据集的标签，评估众包提供的数据质量变得至关重要，以提高分析性能并减少后续机器学习任务中的偏差。由于大多数众包情况缺乏真正的标准，我们通常关注注释的一致性和可信度来定义数据质量。在简单的场景中通常使用Kappa系数和内聚系数，但在在线众包环境中，需要处理更复杂的情况。本研究提出了一种系统的方法，通过方差分解来评估数据质量和检测刷单威胁，并将刷单者分为三类，根据不同的行为模式。我们提出了一种刷单指数来评估整个数据的一致性，并通过马尔可夫链和广义随机效应模型开发了两个衡量工人群体可靠性度量标准。
## Innovation
本研究引入了一种系统方法，通过方差分解来评估数据质量和检测刷单威胁。具体创新点包括：1）分类刷单者为三类，根据不同行为模式；2）提出刷单指数来评估整个数据的一致性；3）利用马尔可夫链和广义随机效应模型来衡量工人群体的可靠性度量标准。通过实际案例（人脸验证任务）展示了技术的实用性和优势。
## Conclusion
本研究提出的方法不仅适用于复杂而不易直接测量数据质量的众包场景，而且通过实际应用说明了其在人脸验证任务中提高数据质量和筛选可靠众包工人的有效性。
# 584. `cs.LG` - 可见和红外图像馈送中低光照条件下的行人检测：问题与挑战 [PDF](https://arxiv.org/pdf/2311.08557), [HTML](https://arxiv.org/abs/2311.08557)
## Authors
Thangarajah Akilan,Hrishikesh Vachhani
## Background
行人在诸多高层任务中变得至关重要，例如自动驾驶、智能交通和交通监控。目前多数行人检测研究集中在可见光图像，在白天环境中取得良好效果。然而，在环境条件变为昏暗或夜间时，行人检测变得更具挑战性。近年来，科学家开始探索使用红外温度传感器等新型数据源以在低光照条件下检测行人。本文综述了近年低光照行人的检测方法，详细分类和分析了区域基础、非区域基础和图基学习方法，同时总结了关键基准数据集，这些数据集可以用于先进行人检测算法的研究和发展，特别是在低光照情况下。
## Innovation
本文首次系统地梳理了低光照条件下的行人检测算法，分类和总结了不同方法，并且强调了这些方法的重点、实施问题和挑战。
## Conclusion
本文提出现有的低光照行人检测方法的主要问题和挑战，并提出了关键的基准数据集，这些数据集可以用于进一步的研究和发展更先进的行人检测算法。
# 585. `cs.LG` - FluoroSAM: 一种可语言提示的基础模型，用于灵活的X射线图像分割 [PDF](https://arxiv.org/pdf/2403.08059), [HTML](https://arxiv.org/abs/2403.08059)
## Authors
Benjamin D. Killeen,Liam J. Wang,Blanca Inigo,Han Zhang,Mehran Armand,Russell H. Taylor,Greg Osgood,Mathias Unberath
## Background
目前的医学图像分析模型主要针对特定任务和场景进行专门化训练，但在更广泛的应用中，需要更多数据、注释和训练时间。为了克服这些问题，最近出现了语言对齐的基础模型（LFMs），它们在大量高度多变的图像和文本数据上进行训练，使得自动化图像分析更具有广泛适用性。尽管现有的医学图像分析基础模型主要针对大数据和丰富注释的场景，而X射线成像模态由于结构多样性、诊断胸片到介入性透视的广泛应用，需要处理的数据量和数据标注的可用性差异较大。因此，需要一种能够处理任意X射线图像的可语言提示的基础模型，用于影像获取和分析过程中丰富的人机互动。
## Innovation
本文提出了一种名为FluoroSAM的可语言提示的基础模型，该模型从零开始训练了300万张合成X射线图像，这些图像涵盖了广泛的人体解剖结构、成像几何和视角，以及128种器官类型和464种工具的伪标注掩模和相应的文字描述。通过在训练过程中引入文本嵌入向量量化（VQ）的新颖方法，使FluoroSAM能够基于自然语言提示进行多种解剖结构和工具的分割。FluoroSAM在实际X射线图像上表现出色，并且在多个应用场景中展示了其作为X射线图像获取和分析中的人机交互关键使能器的作用。
## Conclusion
FluoroSAM作为一种新型的语言提示基础模型，能够轻松处理结构多变的X射线图像，提出了一个在广泛场景下实现强大人工输入循环工作流程的可能性。这种模型的引入，将推动医学诊断和介入精准医学朝着更加灵活和智能化的方向发展。
# 586. `cs.LG` - 在特征转移下的上下文优化：基于交集 Wasserstein 球的鲁棒方法 [PDF](https://arxiv.org/pdf/2406.02426), [HTML](https://arxiv.org/abs/2406.02426)
## Authors
Tianyu Wang,Ningyuan Chen,Chun Wang
## Background
在上下文优化中，决策者利用上下文信息（通常称为协变量）来更好地解决不确定性并做出明智的决策。然而，在训练和测试环境之间的协变量分布发生变化时，即协变量转移现象，会导致测试协变量的上游估计不准确，进而影响下游决策的效果。这些问题给决策者带来了挑战，亟需一种能有效处理这种转移现象的方法。
## Innovation
本文提出的创新方法是基于交集 Wasserstein 球的分布鲁棒优化（IW-DRO）。该方法的核心是一个新的不确定集，该不确定集定义为两个 Wasserstein 球的交集，并通过合适的非参数和参数估计器构造其中心。此外，本文还通过重新形式化问题为可求解的凸优化问题，并开发了适用于大规模问题的近似算法，提高了计算效率。理论分析表明，与单个 Wasserstein 球 DRO 模型相比，IW-DRO 能够实现更好的性能。
## Conclusion
本文提出的 IW-DRO 框架在面对协变量转移现象时提供了一种实用的解决方案，具有出色的性能，并为不确定环境下的决策者提供了指导价值。
# 587. `cs.LG` - 物理启发的模仿 reinforcement 学习在真实世界驾驶中的应用 [PDF](https://arxiv.org/pdf/2407.02508), [HTML](https://arxiv.org/abs/2407.02508)
## Authors
Hang Zhou,Yihao Qin,Dan Xu,Yiding Ji
## Background
最近，模仿 reinforcement 学习（IRL）的进步显著增强了自主代理吸收专家示范的能力，在复杂任务中实现了快速技能获取。然而，基于学习的代理在向高度动态的闭环环境转移知识时面临重大挑战。它们的表现受到模仿学习（IL）和 reinforcement 学习（RL）之间冲突的优化目标、样本效率低以及难以发现隐藏的世界模型和物理规律的影响。
## Innovation
提出了一个物理启发的 IRL，该方法完全基于数据驱动，在训练过程中使车辆动态的基本物理原理自然浮现。通过联合优化目标利用专家示范数据和探索性数据，超越了流行的 IL、RL 和 IRL 算法在 Waymax 标准测试中的表现。该方法在闭环设置中的碰撞率降低了 37.8%，脱线率降低了 22.2%。
## Conclusion
该研究通过物理启发的方法成功解决了基于学习的代理在闭环环境中的性能问题，证明了在真实世界驾驶任务中的有效性。
# 588. `cs.LG` - 使用编码数据结构的变分量子回归算法 [PDF](https://arxiv.org/pdf/2307.03334), [HTML](https://arxiv.org/abs/2307.03334)
## Authors
C.-C. Joseph Wang,F. Perkkola,I. Salmenperä,A. Meijer-van de Griend,J. K. Nurminen,R. S. Bennink
## Background
混合变量子算法（VQAs）在解决组合优化、量子化学模拟、量子机器学习和量子错误校正等实际问题方面具有潜力。然而，当使用典型的随机或量子交替操作答案时，这些算法可能成为无法解释的黑箱，难以用于重要决策的部署，因为其变分参数只是量子门的旋转角度，而没有提供直接的、可解释的模型值。因此，构建具有解释性的量子回归算法成为了研究的迫切需求，旨在使量子状态直接编码经典数据表，使变分参数直接对应可解释的回归系数，且具有实现高模型解释性与优化成本低的优势。此外，利用编码数据结构可降低回归计算的时间复杂性，通过经典的预处理可以构建非线性特征，进一步缩短量子电路的深度，提高计算效率。尽管在超导比特上实现了近期更少噪音的压缩编码，但仍展望了在中性冷原子和离子上实现多比特门操作所带来的量子利用潜力。
## Innovation
首次构建了可解释性量子回归算法，其中量子状态完全编码经典数据表，变分参数直接对应回归系数，且这些系数是根据构造实现的实数，提供了高度的模型解释性和优化成本的最小化。通过利用编码的数据结构，减少了计算回归映射的时间复杂度。为了实现非线性回归，可以通过经典预处理构建非线性特征，并利用独立编码的列向量扩展算法以缩短量子电路的深度。
## Conclusion
构建了具有解释性的量子回归算法，通过有效利用编码数据结构，简化的量子电路结构有助于高效执行非线性回归，这不仅提高了计算效率，还降低了实现复杂性的要求，提供了量子计算实际应用中潜在的实用价值和新的研究方向。
# 589. `cs.LG` - 代码生成大语言模型中长范围依赖处理的评估 [PDF](https://arxiv.org/pdf/2407.21049), [HTML](https://arxiv.org/abs/2407.21049)
## Authors
Yannick Assogba,Donghao Ren
## Background
随着语言模型支持的上下文大小变得越来越大，评估模型如何有效利用这些上下文变得越来越重要。本文通过一系列多步关键检索任务来评估多种代码生成模型处理长距离依赖的能力，这些任务的上下文窗口长达8k个标记，并逐步增加难度，使模型能力的评估比流行的毫针在干草堆测试更加细致。研究发现，许多模型在函数引用稍后定义的另一个函数时性能显著下降（高达2倍）；使用滑动窗口注意力机制的模型难以处理远远超出单个窗口大小的引用。通过使用调用图信息进行简单的提示修改，可以将多步检索性能提高3倍。研究结果强调了长上下文性能需要更深入的考虑，而不仅仅是文档内单一事实的检索能力。
## Innovation
本文通过设计一系列复杂的多步关键检索任务来评估多种代码生成模型处理长距离依赖的能力，特别是针对滑动窗口注意力机制的模型，并通过提示修改来改善模型的性能。这种方法提供了比常见的“毫针在干草堆”测试更精细的评估模型能力的方式。
## Conclusion
研究表明，许多模型在处理长距离依赖时表现出色下降，特别是当函数引用稍后定义的另一个函数或模型使用滑动窗口注意力机制时。简单的提示修改可以显著提高模型的长距离参考处理能力。长范围性能的评估需要更深层次的考虑，而不仅仅是内部文档事实的检索能力。
# 590. `cs.LG` - C-Learner: 局部学习因果推断 [PDF](https://arxiv.org/pdf/2405.09493), [HTML](https://arxiv.org/abs/2405.09493)
## Authors
Tiffany Tianhui Cai,Yuri Fonseca,Kaiwen Hou,Hongseok Namkoong
## Background
在因果推断中，去偏差估计方法（如增强逆倾向加权和目标最大似然估计）虽然具有统计效率和二重稳健等理想渐近性质，但在治疗组和对照组重叠度低的情况下，可能会产生不稳定的估计结果。针对此问题，简单插值估计法虽然稳定，但缺乏理想的渐近性质。本文探讨了在处理治疗和控制组重叠度低的情形下，如何实现稳定估计的同时保持理想渐近性质的问题。
## Innovation
本文提出了一种新的去偏差框架（Constrained Learning, C-Learner），该框架能够寻找最优化的插值估计方法，并且在第一个阶误差为零的情况下，利用灵活的模型类（包括神经网络和树型集成模型）来实现这一目标。该方法在实验设置中表现出色，特别是在处理文本基变量时，优于传统的一步步估计和目标调整方法，特别是在治疗和对照组重叠度低的情况下，且在其他情况下表现相似。
## Conclusion
通过理论分析，在重叠度低的情况下，本文提出的C-Learner方法表现出更好的性能。此外，与其他去偏差估计方法相比，它在重尾逆倾向得分的场景下具有更快的收敛速度。
# 591. `cs.LG` - 使用大型语言模型进行图推理的图线性化方法 [PDF](https://arxiv.org/pdf/2410.19494), [HTML](https://arxiv.org/abs/2410.19494)
## Authors
Christos Xypolopoulos,Guokan Shang,Xiao Fei,Giannis Nikolentzos,Hadi Abdine,Iakovos Evdaimon,Michail Chatzianastasis,Giorgos Stamou,Michalis Vazirgiannis
## Background
大型语言模型已经发展到可以处理超过文本的多种模态，如图像和音频，这促使我们探索如何有效地利用它们进行图理问题。关键问题是将图转换为线性序列的“图线性化”过程，以便LLMs可以自然处理图。我们考虑图应该被有意义地线性化，以反映自然语言文本的某些属性，如局部依存关系和全局对齐，以帮助当代LLMs更好地理解图数据。
## Innovation
本文提出了几种基于图中心性和退化性的图线性化方法，并进一步使用节点重新标记技术进行了改进。实验结果表明，与随机线性化基线相比，我们的方法更加有效。本文还引入了适合LLMs的新图表示方法，这有助于将图机器学习与多模态处理的趋势统一到一个Transformer模型中进行整合。
## Conclusion
本文的方法和新图表示方法有助于增强图机器学习和大型语言模型的结合，对于处理涉及文本、图像和音频等多模态数据的复杂推理任务具有重要意义。
# 592. `cs.LG` - 世界之理解或未来之预测？世界模型综述 [PDF](https://arxiv.org/pdf/2411.14499), [HTML](https://arxiv.org/abs/2411.14499)
## Authors
Jingtao Ding,Yunke Zhang,Yu Shang,Yuheng Zhang,Zefang Zong,Jie Feng,Yuan Yuan,Hongyuan Su,Nian Li,Nicholas Sukiennik,Fengli Xu,Yong Li
## Background
随着多模态大型语言模型（如GPT-4）和视频生成模型（如Sora）的发展，人们越来越关注世界模型的概念。世界模型被视为帮助理解当前世界的状况或预测其未来动态的工具，是实现通用人工智能的关键途径。已有文献对此进行了研究，本文将对其进行综合回顾，通过系统分类来突出世界模型的两大主要功能：构建内部表征以理解世界机制，以及预测未来状态以模拟和指导决策。
## Innovation
本文提供了一个全面的世界模型文献综述，通过系统分类强调世界模型的两大主要功能：（1）构建内部表征以理解世界机制；（2）预测未来状态以模拟和指导决策。文中不仅概述了这两个方面的当前进展，还探讨了世界模型在自动驾驶、机器人技术和模拟社会等关键领域的应用。
## Conclusion
最终，本文指出了关键挑战，并提出了一些可能的研究方向。附录中总结了代表性的论文及其代码仓库，为读者提供了深入了解特定领域世界模型的资源。
# 593. `cs.LG` - BINDy -- 可逆跳跃马尔可夫链蒙特卡罗的非线性动力学的贝叶斯识别 [PDF](https://arxiv.org/pdf/2408.08062), [HTML](https://arxiv.org/abs/2408.08062)
## Authors
Max D. Champneys,Timothy J. Rogers
## Background
模型简约是数据驱动建模中的一个重要的认知偏差，有助于提高模型的可解释性并防止过拟合。SINDy算法能够从数据中直接学习复杂动态的稀疏表示，前提是给定一个函数库。尽管如此，现有的模型识别方法主要集中在参数空间的稀疏性，即通过限制模型参数的数量来实现模型的简化。然而，这种方法可能会忽略具有适当模型复杂度的模型。因此，需要一种新方法，能够在模型结构上实现稀疏性，而不仅仅是参数稀疏。
## Innovation
本文提出了一种新的贝叶斯模型识别方法——BINDy，不同于现有的SINDy方法，BINDy直接针对库函数及其在模型中的参数化之间的完整联合后验分布。这种方法允许在模型结构上设置任意先验，从而使模型在模型空间中更具稀疏性而不是参数空间。由于后验是在可以变化维度的参数向量上定义的，标准方法无法进行推断。因此，提出了一种基于可逆跳跃马尔可夫链蒙特卡罗的吉布斯抽样方法来进行推断。实验结果表明，BINDy在三个基准测试中优于SINDy，并且能够更有效地为正确的模型项分配高概率。
## Conclusion
BINDy方法通过采用贝叶斯框架和可逆跳跃马尔可夫链蒙特卡罗算法，能够在模型结构中实现稀疏性，有效识别非线性动态模型，优于传统的SINDy方法。这种方法在实际应用中具有较大的研究和应用潜力。
# 594. `cs.LG` - 用于推荐的双通道多层图神经网络 [PDF](https://arxiv.org/pdf/2403.11624), [HTML](https://arxiv.org/abs/2403.11624)
## Authors
Xiang Li,Chaofan Fu,Zhongying Zhao,Guanjie Zheng,Chao Huang,Yanwei Yu,Junyu Dong
## Background
有效的推荐系统在捕捉用户和项目属性方面发挥着重要作用，这些属性能够反映个人偏好。现有的一些推荐技术已经开始转向模型各种用户和项目之间的交互关系，例如在线购物平台上的点击、标记为喜欢和购买行为。然而，这些方法仍然面临两个重大挑战：（1）缺乏对多层用户-项目交互关系中各种行为模式的影响在表示学习中的建模和利用不足，（2）忽略了行为模式中不同关系对目标关系的影响对推荐系统场景的影响。在此工作之中，我们提出了一个新的推荐框架，称为双通道多层图神经网络 (DCMGNN)，该方法解决了上述挑战。它包含一个显式的行为模式表示学习器来捕捉由多层用户-项目交互关系构成的行为模式，并包括关系链表示学习者和关系链感知编码器来发现各种辅助关系对目标关系的影响、不同关系之间的依赖关系，并挖掘行为模式中的关系顺序。
## Innovation
我们提出了一种新的推荐框架——双通道多层图神经网络 (DCMGNN)，该框架通过引入显性行为模式表示学习器和关系链表示学习者与关系链感知编码器解决了现有的推荐方法无法有效建模用户与项目多层交互关系的影响与挖掘相关关系顺序的问题。
## Conclusion
在三个真实世界的数据集上进行的广泛实验表明，我们的 DCMGNN 超越了各种现有的最先进的推荐方法。它在所有数据集上分别在 Recall@10 和 NDCG@10 方面优于最佳基线方法，其平均提高幅度分别为 10.06% 和 12.15%。
# 595. `cs.LG` - 关于阅读时间预测中上下文的作用 [PDF](https://arxiv.org/pdf/2409.08160), [HTML](https://arxiv.org/abs/2409.08160)
## Authors
Andreas Opedal,Eleanor Chodroff,Ryan Cotterell,Ethan Gotlieb Wilcox
## Background
该论文提出了读者如何在实时语言理解过程中整合上下文的新视角。研究基于惊诧理论，该理论认为语言单位（如单词）的处理努力是其上下文信息量的线性函数。论文观察到惊诧只是上下文预测的一种方式，另一种是单位与其上下文之间的点互信息（PMI），发现当控制未出现词频时，PMI和惊诧都能提供相同的预测能力。此外，PMI和惊诧与频率相关，这意味着PMI或惊诧中并不包含仅关于上下文的信息。这引发了对一种新技术的需求，即通过投影惊诧来去除与频率有关的部分，从而得到一个与频率无关的新上下文预测者。实验结果显示，当使用去频率化的预测者表示上下文时，解释阅读时间变异性的上下文字比例显著降低。这意味着先前的研究可能夸大了上下文在预测阅读时间上的作用。
## Innovation
该论文提出了一种新技术，即通过将惊诧投影到频率的正交补空间，从而得到一个与频率无关的新上下文预测器。实验显示使用该方法大大降低了由于上下文导致的阅读时间变异性的解释率。这项创新在可解释性方面对于理解上下文对阅读时间预测的重要性具有重要意义。
## Conclusion
论文的研究表明，经典的研究可能夸大了上下文在预测阅读时间方面的作用，使用新方法去频率化的上下文预测器可以更准确地解释阅读时间的变异，这在可解释性的角度来看，具有重要作用。
# 596. `cs.LG` - Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models [PDF](https://arxiv.org/pdf/2408.00523), [HTML](https://arxiv.org/abs/2408.00523)
## Authors
Yingkai Dong,Xiangtao Meng,Ning Yu,Zheng Li,Shanqing Guo
## Background
文本到图像（T2I）生成模型通过将文本描述转换为高质量图像，彻底改变了内容创造的方式。然而，这些模型容易受到逃狱攻击的影响，即精心设计的提示可以绕过安全机制并生成不安全的内容。尽管研究人员已经开发出各种逃狱攻击来揭示这种风险，但这些方法存在显著的限制，包括不切实际的访问要求、易于检测的不自然提示、搜索空间有限以及对目标系统有高查询需求。
## Innovation
本文提出了一种由大型语言模型（LLM）代理驱动的新颖模糊化框架—JailFuzzer，旨在在黑盒环境下高效生成自然且语义上有意义的逃狱提示。具体来说，JailFuzzer 使用模糊测试原则，包含三个组件：初始提示和逃狱提示的种子池、生成有意义变体的引导式变异引擎，以及评估逃狱成功与否的oracle函数。此外，通过基于LLM的代理构建了引导式变异引擎和oracle函数，从而进一步确保了在黑盒环境中的高效性和适应性。详尽的实验表明，JailFuzzer 在逃狱T2I模型方面具有显著优势，生成的提示自然且语义一致，降低了传统防御检测的可能性。此外，它在最少查询开销的情况下实现了高逃狱成功率，并在所有关键指标上超过了现有方法。
## Conclusion
这项研究强调了在生成模型中使用更强的安全机制的必要性，并为未来研究如何抵御复杂逃狱攻击提供了基础。JailFuzzer是开源的，可以在本此仓库中找到：this https URL。
# 597. `cs.LG` - 提升归纳知识图谱完成基准数据集的质量 [PDF](https://arxiv.org/pdf/2406.11898), [HTML](https://arxiv.org/abs/2406.11898)
## Authors
Harry Shomer,Jay Revolinsky,Jiliang Tang
## Background
知识图谱（KG）填充（KGC）旨在预测知识图谱中的缺失事实。最近，越来越多的研究集中在设计能够在归纳设置下表现出色的KGC方法，即在推断时部分或全部未在训练过程中观察到的实体和关系也能正确预测。为了评估这些方法，研究人员提出了多种基准数据集，这些数据集都是现有知识图谱的子集，在这部分数据集上进行的是归纳KGC。然而，作者发现当前的归纳KGC数据集构建方法无意中制造了一条捷径，即使不考虑关系信息，模型仍然可以取得很好的性能。研究发现，个性化PageRank（PPR）得分在大多数数据集上都能取得接近SOTA的性能。作者进一步研究了这一现象的原因，并提出了一种新的数据集构建策略，旨在减轻PPR捷径的问题。新的数据集帮助促进了对归纳KGC的性能和挑战的理解，消除了任何可能导致混淆性能的捷径。该论文还提供了实验代码和数据集的访问链接。
## Innovation
作者发现现有的归纳KGC数据集构建方法无意中创造了一种利用个性化PageRank（PPR）得分的捷径，并据此进一步研究了这一现象的原因。基于这一发现，作者提出了一种新的策略，旨在减轻这种捷径对于评价KGC方法的影响。此外，利用新的数据集和PPR评分构建了一个更公正的基准测试，以此来帮助理解归纳KGC的真实能力和挑战。
## Conclusion
通过这种新的数据集和实验方法，可以帮助更好地理解归纳KGC的真实能力和挑战，而不是被可能模糊性能表现的捷径所误导。
# 598. `cs.LG` - 我会自己合并它：一种多保真度自动化模型合并框架 [PDF](https://arxiv.org/pdf/2502.04030), [HTML](https://arxiv.org/abs/2502.04030)
## Authors
Guinan Su,Jonas Geiping
## Background
大型语言模型（LLMs）的推理能力是一个关键前沿领域，但开发这些能力需要大量的专有数据集和计算资源。通过模型合并的方式来补充这些能力是一个有希望的替代方案，但当前的合并方法依赖于手动设计的策略来合并超参数，限制了潜在模型组合的探索，并需要大量的人工努力。
## Innovation
提出了一种自动化模型合并框架，能够通过多保真度近似来实现细粒度探索合并策略并降低成本。该框架支持单目标和多目标优化，并引入了两种新的搜索空间：层融合（LFS）和深度集成（DIS）。
## Conclusion
通过多种基准测试，发现了自动寻找有效合并：1) 在模型已经进行微调的任务上进一步提升单目标性能的合并；2) 在不同任务上优化多目标前沿的合并。有效的合并仅需有限的计算资源，例如在不到500次搜索步骤内即可完成。
# 599. `cs.LG` - 基于实现保证的生成模型的图像超分辨率 [PDF](https://arxiv.org/pdf/2502.09664), [HTML](https://arxiv.org/abs/2502.09664)
## Authors
Eduardo Adame,Daniel Csillag,Guilherme Tegoni Goedert
## Background
近年来，生成深度学习基础模型在图像恢复任务（如超分辨率）中的应用日益增多。然而，这些模型在输出结果时缺乏可靠的不确定性和可解释性。因此，迫切需要一种能够进行稳健且可解释的不确定性量化的方法。本文致力于解决这一问题，通过引入基于可变形预测技术的新方法，生成一种‘置信度蒙版’，可以可靠地并且直观地告知用户哪些生成的图像可以信任。该方法对任何黑盒生成模型都适用，且通过简单的数据校准，高度可定制化，并可选择局部图像相似度度量来优化。
## Innovation
本文提出了一种基于可变形预测的新方法，能够为生成的图像创建一个‘置信度蒙版’，该方法适用于任何黑盒生成模型，仅需少量数据就能进行校准，并且高度可定制化。此外，该方法具有广泛的实际保证，涵盖保真度误差控制、重建质量以及在数据泄露情况下的鲁棒性。同时，通过实验证明了该方法的有效性。
## Conclusion
本文通过提出基于可变形预测技术的新方法，有效地解决了使用生成模型进行图像超分辨率时的不确定性和可解释性问题。实验结果证实了该方法的稳健性和高性能，并证明了方法在忠实性误差控制、重建质量和数据泄露鲁棒性方面的良好表现。
# 600. `cs.LG` - 使用无监督学习进行窄频带射电信号搜索中的异常检测和射电频率干扰分类 [PDF](https://arxiv.org/pdf/2411.16556), [HTML](https://arxiv.org/abs/2411.16556)
## Authors
Ben Jacobson-Bell,Steve Croft,Carmen Choza,Alex Andersson,Daniel Bautista,Vishal Gajjar,Matthew Lebofsky,David H. E. MacMahon,Caleb Painter,Andrew P. V. Siemion
## Background
在射电技术标志搜索中，候选信号被比作干草堆中的针，而射电频率干扰（RFI）是主要的杂质。现有的搜索框架会产生大量假阳性信号，特别是在大规模调查中，这需要大量的手动后续工作，有时甚至会达到无法承受的程度。无监督学习提供了一种算法来筛选出最异常的信号，并且能够将具有相似形态特征的RFI信号聚类在一起。
## Innovation
本文提出了一种名为GLOBULAR（Grouping Low-frequency Observations By Unsupervised Learning After Reduction）的信号处理方法，该方法利用HDBSCAN减少假阳性率并使异常信号隔离，以便进一步分析。该方法与标准的窄频带信号检测和空间滤波管道相结合，能够显著提高假阳性率，并且可能发现标准管道中遗漏的信号。在对97个邻近星系的L波段信号进行一组测试中，该方法展示了93.1%的假阳性击中率减少和99.3%的假阳性事件减少率。
## Conclusion
GLOBULAR聚类方法与标准管道结合使用，能够在不降低检测性能的情况下大幅减少人工后续工作的需求，对于未来的大型调查具有显著的改进潜力。
# 601. `cs.LG` - 使用联邦学习的多无人机最近端控制算法 [PDF](https://arxiv.org/pdf/2412.02863), [HTML](https://arxiv.org/abs/2412.02863)
## Authors
Lucas Nogueira Nobrega,Ewerton de Oliveira,Martin Saska,Tiago Nascimento
## Background
人类与机器人交互（HRI）是一个快速增长的研究领域。在这个领域中，指令分类仍然是一个开放问题，限制了这种技术的实际应用。现有的文献中，虽然有利用神经网络检测动作的研究，但在无人机（UAV）操作时由于遮挡的问题依然存在，尤其是在多机器人场景中，分布式训练也是一个挑战性问题。因此，本文提出了基于长短期记忆（LSTM）深度神经网络和联邦学习（FL）的多无人机动作识别与控制方法，以克服遮挡问题并实现分布式训练，提高模型的准确性。
## Innovation
该工作提出了一种基于LSTM深度神经网络和联邦学习（FL）的多无人机动作识别与控制方法，用于多无人机系统。这种方法不仅能够通过联邦学习实现分布式训练，避免对云或其它存储库的依赖，还能够解决遮挡问题，实验结果表明其在实际多无人机系统中取得了超过96%的高准确性。
## Conclusion
通过提出基于LSTM和联邦学习的多无人机动作识别与控制方法，本文有效解决了HRI中动作分类的开放问题和遮挡问题，通过分布式训练提高了模型的准确性和效率。
# 602. `cs.LG` - 基于上界和下界模型的自适应预测 [PDF](https://arxiv.org/pdf/2503.04071), [HTML](https://arxiv.org/abs/2503.04071)
## Authors
Miao Li,Michael Klamkin,Mathieu Tanneau,Reza Zandehshahvar,Pascal Van Hentenryck
## Background
本文研究了在仅有目标变量的确定上下界条件下的回归预测区间建立方法，探讨了一种自适应预测(CP)方法。传统方法可能在界限较紧的区域无法提供足够的覆盖率，因此本文提出了一种优化阈值机制(OMLT)，用于调整CPUL区间，以解决这一局限性。
## Innovation
本文提出了一种新的CP机制(CPUL)，它采用模型选择方法，结合了多个嵌套区间构建方法。特别地，提出了一种优化阈值机制(OMLT)，在界限紧的区域调整CPUL的区间，以改善覆盖率不足的问题。
## Conclusion
经过大规模学习任务的实验验证，本文提出的CPUL-OMLT方法在多个数据集上相比基准方法取得了显著改进。
# 603. `cs.LG` - 蛋白质结构分词：基准评估与新策略 [PDF](https://arxiv.org/pdf/2503.00089), [HTML](https://arxiv.org/abs/2503.00089)
## Authors
Xinyu Yuan,Zichen Wang,Marcus Collins,Huzefa Rangwala
## Background
近年来，蛋白质结构分词方法的发展十分迅速，将蛋白质的3D结构拆分成离散或连续的表示形式。结构分词使直接利用语言模型等强有力的工具应用于蛋白质结构成为可能，并且允许大型的多模态模型将结构与蛋白质序列和功能性文本进行整合。尽管已有进展，但这些方法的能力和限制仍不清楚，主要是由于缺乏统一的评估框架。现有的基准主要关注全局结构，而较少关注细粒度的局部亚结构，这导致对这些方法的评估不够全面。因此，迫切需要一个能够从细粒度局部亚结构角度衡量结构分词质量与效率的综合评估框架。
## Innovation
本文首先介绍了StructTokenBench，这是一种用于全面评估结构分词质量与效率的框架，特别强调细粒度的局部亚结构。研究发现没有一种模型能在所有基准测试视角中占据主导地位。基于代码书使用不足的观察结果，作者开发了AminoAseed，这是一种简单而有效的策略，优化了代码书的梯度更新，平衡了代码书的大小和维度，从而提高分词器的利用率和质量。与领先的ESM3模型相比，该方法在24个监督任务中的平均性能提升了6.31%，并提高了敏感性和利用率，分别提高了12.83%和124.03%。
## Conclusion
本文通过开发StructTokenBench框架，提供了对结构分词质量与效率的全面评估，并提出了一种简单有效的AminoAseed策略，以优化代码书更新和资源利用率。实验结果表明，该策略在多个蛋白质结构分词任务中实现了显著的性能提升。
# 604. `cs.LG` - 奖励图推理过程让大语言模型成为更通用的推理者 [PDF](https://arxiv.org/pdf/2503.00845), [HTML](https://arxiv.org/abs/2503.00845)
## Authors
Miao Peng,Nuo Chen,Zongrui Suo,Jia Li
## Background
尽管大语言模型（LLMs）取得了显著进展，但强化其高级推理能力仍然是一个关键挑战。过程奖励模型（PRMs）在数学推理等特定领域的多步推理中展示了巨大的潜力，通过提供逐步反馈来增强推理能力。然而，PRMs在更广泛推理领域的应用仍然较少，主要由于手动创建逐步监督的成本较高。本文探讨了PRMs在图推理问题中的潜在应用，该领域需要复杂的多步推理，并且可以通过现有的图算法自动化生成逐步数据。
## Innovation
本文提出了GraphSILO，这是迄今为止最大的图推理问题数据集，带有精细的逐步标签，使用自动任务导向轨迹和蒙特卡洛树搜索（MCTS）生成详细的推理步骤。基于此数据集，研究人员训练了GraphPRM，这是第一个专为图推理问题设计的PRM，并评估了其在推理时间扩展和直接偏好优化（DPO）强化学习中的效果。实验结果显示，GraphPRM在13个图推理任务上显著提升了LLM性能，特别是在Qwen2.5-7B上实现了9%的提升，并展示了在新图推理数据集和新的推理领域（如数学问题解决）上的可迁移性。研究表明，基于图推理奖励的PRMs在多个领域的推理中具有巨大潜力，有助于开发更灵活和有效的LLMs.
## Conclusion
研究结果表明，PRMs在其领域内具有跨领域的适用性，有助于实现更具多样性的LLMs的发展。
# 605. `cs.LG` - 为未来撞击器在新探测器几何结构中微调机器学习粒子流重建 [PDF](https://arxiv.org/pdf/2503.00131), [HTML](https://arxiv.org/abs/2503.00131)
## Authors
Farouk Mokhtar,Joosep Pata,Dolores Garcia,Eric Wulff,Mengke Zhang,Michael Kagan,Javier Duarte
## Background
本文介绍了在高能粒子碰撞器中为粒子流重构训练的机器学习算法具备迁移学习的能力。通过跨探测器微调研究，展示了从一种探测器设计的大规模完全模拟数据集预训练模型，然后在具有不同碰撞器和探测器设计的数据集上进行微调的实验。具体来说，使用紧凑线性撞击器探测器（CLICdet）模型进行初始训练集，并证明成功将知识转移到未来环形撞击器中电子-正电子模式下提出的CLIC类似探测器（CLD）上。结果显示，通过第二个数据集的一小部分样本就能达到从头开始昂贵训练的结果，性能指标包括粒子水平和事件水平的性能指标，如喷流和缺失纵向动量分辨率。进一步表明，经过微调的模型在经过10万次CLD事件训练后，在事件水平的指标上达到了传统的基于规则的粒子流方法的同等性能，而从头开始训练的模型至少需要100万次CLD事件才能达到类似重建性能。据我们所知，这是首次完整模拟环境下跨探测器微调的粒子流重建研究。这些发现为构建跨越不同探测器设计和几何结构的微调大型基础模型提供了重要见解，有助于加速新型探测器的发展周期，开启使用机器学习进行快速探测器设计和优化的大门。
## Innovation
首次在完整模拟环境下进行跨探测器微调的粒子流重建研究，展示了在不同探测器设计上实现高效迁移学习的潜力。通过较少的样本数据，就达到了从头开始训练的性能，大幅减少了训练数据的需求，为新型探测器的快速开发提供了新的方法。
## Conclusion
这些发现为未来一代探测器的设计和优化提供了重要参考，提出了构建跨不同探测器设计和几何结构的基础模型的新途径，有助于加速相关技术的研发进程。
# 606. `cs.LG` - 解锁视觉数据集和更复杂EEG分类任务的即席学习 [PDF](https://arxiv.org/pdf/2501.06256), [HTML](https://arxiv.org/abs/2501.06256)
## Authors
Jelena Bratulić,Sudhanshu Mittal,David T. Hoffmann,Samuel Böhm,Robin Tibor Schirrmeister,Tonio Ball,Christian Rupprecht,Thomas Brox
## Background
大规模语言模型（LLMs）能够通过例证推理（In-Context Learning，ICL）在无需更新模型权重的情况下完成新任务。尽管ICL在自然语言处理中的应用很快，但它在文本以外的模态中出现则较为复杂。本文系统地揭示了支持LLMs中ICL出现的关键属性，特别是训练数据中的确切令牌重复现象，以及训练任务难度对ICL形成的影响。论文通过这些新颖见解成功扩展了ICL的能力，应用于多种视觉数据集和更具挑战性的EEG分类任务，特别是在少样本学习的框架下。
## Innovation
研究发现了训练数据中的确切令牌重复是促进ICL出现的重要因素，并且这种重复进一步提升了ICL性能的稳定性和持久性。同时，强调了训练任务难度对于ICL出现的重要性。最后，通过利用这些新颖的见解，解锁了ICL能力应用于视觉数据集和复杂EEG分类任务，特别是在少样本学习框架下的应用。
## Conclusion
研究证明了在多种视觉数据集和更具挑战性的EEG分类任务中成功实现了ICL，特别是在少样本学习的情况下推动了ICL的发展，显示了在更多模态中应用ICL的潜力。
# 607. `cs.LG` - 从$text{O}(n^{2})$到$text{O}(n)$参数：用于生物医学图像分类的视觉变换器中的量子自注意力机制 [PDF](https://arxiv.org/pdf/2503.07294), [HTML](https://arxiv.org/abs/2503.07294)
## Authors
Thomas Boucher,John Whittle,Evangelos B. Mazomenos
## Background
研究背景介绍了现有的视觉变压器(ViT)在生物医学图像分类中的成功应用，但其参数量巨大，资源消耗高。论文提出了一种新的量子自注意力机制(QSA)，通过将传统ViT中的线性自注意力层替换为参数化的量子神经网络(QNN)，从而实现参数量的大幅减少，同时保持甚至提高分类性能。研究人员通过一系列实验，对比了QVI们与当前最先进的方法在资源效率和性能上的差异，特别是在简化模型参数规模方面取得了显著成果。
## Innovation
本文的主要创新在于开发了一种新型量子自注意力机制(QSA)，通过参数化的量子神经网络代替传统的线性自注意力层，将参数规模从$text{O}(n^{2})$减少到$text{O}(n)$，显著提高了参数效率。QViT在生物医学图像分类上的应用不仅证明了QSA机制的有效性，还在多个数据集上展示了其优越的性能和显著减少的计算量。
## Conclusion
研究结果表明，QViT作为一种参数效率高的生物医学图像分析架构是可行的，具有较强的性能保持能力。量子自注意力机制QSA显示出高度的参数效率，特别是在知识蒸馏(KD)预训练方面，更高维度的架构更能从KD中获益。这些发现表明，QSA是一种实用的选择，为生物医学图像分析的参数优化开辟了新的方向。
# 608. `cs.LG` - MaizeField3D：多样化杂交群体中田间种植玉米的3D点云和程序模型数据集 [PDF](https://arxiv.org/pdf/2503.07813), [HTML](https://arxiv.org/abs/2503.07813)
## Authors
Elvis Kimara,Mozhgan Hadadi,Jackson Godbersen,Aditya Balu,Talukder Jubery,Yawei Li,Adarsh Krishnamurthy,Patrick S. Schnable,Baskar Ganapathysubramanian
## Background
由于缺乏多样化的3D数据集，基于人工智和机器学习的3D表型分析工具的发展受到了限制。2D图像数据集无法捕捉到3D数据提供的关键结构细节，如叶片结构、植物体积和空间布局。因此，研究人员亟需一种标准化的3D数据集来推动农业研究的进步。
## Innovation
作者介绍了MaizeField3D，这是一个经过仔细筛选的田间种植玉米的3D点云数据集，旨在帮助人工智能和机器学习研究。数据集中涵盖了使用地面激光扫描仪（TLS）采集的来自多样化基因型面板的1,045个高质量点云。每个数据点云都使用基于图的分割方法进行了细分和标注，以确保所有样本的标记一致性。此标注的数据用于拟合程序模型，提供了一个结构化的参数表示。叶片用非均匀理性B样条（NURBS）表面表示，这些表面是通过结合无导数和导数方法的两步优化过程生成的。
## Conclusion
MaizeField3D将作为人工智能驱动的表型分析、植物结构分析和农业研究中的3D应用的基础数据集。
# 609. `cs.LG` - MARCO：高性能计算中的实时知识集成多代理代码优化 [PDF](https://arxiv.org/pdf/2505.03906), [HTML](https://arxiv.org/abs/2505.03906)
## Authors
Asif Rahman,Veljko Cvetkovic,Kathleen Reece,Aidan Walters,Yasir Hassan,Aneesh Tummeti,Bryan Torres,Denise Cooney,Margaret Ellis,Dimitrios S. Nikolopoulos
## Background
大型语言模型（LLMs）已经通过代码生成能力改变了软件开发领域，但在高性能计算（HPC）领域中，它们的性能仍受到限制。HPC代码需要针对并行性、内存效率和架构特定考虑的专门优化，而通用目的的LLM经常忽略这些方面的细节优化。
## Innovation
MARCO是一个新颖的框架，它通过一个专门的多代理架构来增强LLM生成的HPC代码。MARCO使用两个分离的代理分别进行代码生成和性能评估，并通过一个反馈循环逐步优化。其主要创新在于MARCO集成了一个网络搜索组件，该组件能够实时检索优化技术相关信息，弥补预训练LLM的知识差距。
## Conclusion
我们的全面评估表明，与Claude 3.5 Sonnet相比，MARCO在LeetCode 75问题集上平均运行时间减少了14.6%，结合网络搜索组件的集成则使性能提高了30.9%。这表明多代理系统在满足高性能代码生成的特定需求方面具有潜在价值，提供了一种成本效益较高的替代方案，无需特定领域的模型微调。
# 610. `cs.LG` - 使用混合和统计计算差距进行大语言模型水印 [PDF](https://arxiv.org/pdf/2505.01484), [HTML](https://arxiv.org/abs/2505.01484)
## Authors
Pedro Abdalla,Roman Vershynin
## Background
给定一段文本，我们能否判断它是由大型语言模型还是人类生成的？一个广泛研究的方法是水印技术。本文关注两种设置下的水印方案：一种是在封闭设置下的不可检测且基本的水印方案；另一种是在开放设置下，对手可以访问大部分模型的不可移除水印方案。
## Innovation
本文提出了一种在封闭设置中不可检测且基础的水印方案，以及一种在开放设置中对手可以访问大部分模型的不可移除水印方案。这些方案旨在通过使用混合技术和统计计算差距来提高水印的隐蔽性和鲁棒性。
## Conclusion
提出了两项新的水印方案，分别适用于封闭和开放设置，并通过混合技术和统计计算差距提高水印的性能。这些方法旨在测试生成的文本是否由大型语言模型或人类生成，为评估模型的输出提供了新的工具和方法。
# 611. `cs.LG` - 通过交互粒子系统实现无梯度的顺序贝叶斯实验设计 [PDF](https://arxiv.org/pdf/2504.13320), [HTML](https://arxiv.org/abs/2504.13320)
## Authors
Robert Gruhlke,Matei Hanu,Claudia Schillings,Philipp Wacker
## Background
在复杂的系统中，梯度信息可能不可用，因此需要一个无需梯度的框架来优化贝叶斯最优实验设计（BOED）。该框架旨在解决嵌套期望计算带来的挑战，并通过变分高斯近似和参数化拉普拉斯近似提供可处理的期望信息增益（EIG）的上界和下界，以实现高维空间中的实用估计和偏微分方程（PDE）约束反问题。实验展示了该框架在广义线性模型及基于PDE的推断任务中的性能，验证了其稳健性、准确性和在信息驱动实验设计中的高效性。
## Innovation
该方法结合了无梯度的Ensemble Kalman Inversion (EKI) 和Affine-Invariant Langevin Dynamics (ALDI) 抽样器，用于设计优化和高效后验采样。它提出了变分高斯和参数化拉普拉斯近似，以提供可处理的期望信息增益（EIG）的上界和下界，解决了复杂系统的计算挑战，并在高维空间和偏微分方程（PDE）约束条件下实现可扩展的实用评估。
## Conclusion
该框架在从线性高斯模型到基于PDE的反问题的多种数值实验中证明了其稳健性、准确性和高效性，展示了其在信息驱动的实验设计中的有效性。
# 612. `cs.LG` - 3D 变分自编码器用于指纹化微结构体积元素 [PDF](https://arxiv.org/pdf/2503.17427), [HTML](https://arxiv.org/abs/2503.17427)
## Authors
Michael D. White,Michael D. Atkinson,Adam J. Plowman,Pratheek Shanthraj
## Background
材料的结构-性能关系研究中，微结构量化是一个重要的步骤。机器学习基于图像处理的方法在性能上超过了传统的图像处理技术，并且越来越多地应用于微结构量化任务中。为了更好地建立这些关系，该研究提出了一种3D变分自编码器（VAE），用于编码包含晶格学定向数据的微结构体积元素（VEs），并利用这些编码数据进行晶格塑性（CP）模拟，从而探索结构-性能关系。
## Innovation
该研究的创新点在于提出了一种3D VAE，用于编码晶格学定向数据的微结构体积元素（VEs），并采用了映射到晶体学基区作为预处理步骤，以获得连续损失函数并提高训练收敛速度。此外，该模型能够很好地应用于训练数据集之外的具有不同纹理、晶粒尺寸和纵横比的微结构，且能够通过变分自编码器提取的微结构特征图谱对晶格塑性（CP）响应进行准确预测。
## Conclusion
通过对由训练集中VES作为初始配置的多种CP模拟，提取并存储了低维潜空间中的微结构特征图谱和体积平均应力响应，该研究使用全连接神经网络将输入的特征图谱映射到CP响应，从而建立了一个代理模型。实验结果显示，基于特征图谱的代理模型能够准确预测CP应力响应的微结构依赖性，且在未见过的数据集上的相对均方误差为2.75 MPa。
# 613. `cs.LG` - 不是你，而是我——跨文化跨城市的城市视觉感知因人口统计学差异和个人特质而异 [PDF](https://arxiv.org/pdf/2505.12758), [HTML](https://arxiv.org/abs/2505.12758)
## Authors
Matias Quintana,Youlong Gu,Xiucheng Liang,Yujun Hou,Koichi Ito,Yihan Zhu,Mahmoud Abdelrahman,Filip Biljecki
## Background
理解人们的需求和偏好对于城市规划决策至关重要，但当前的方法通常是将这些需求和偏好结合来自多文化多城市的群体数据中，这可能会掩盖重要的人口差异，并有可能放大偏见。本研究使用街景图像进行了全球城市景观的大规模视觉感知调查，探究了人口统计学（包括性别、年龄、收入、教育程度、种族和族裔，以及首次提出的人格特质）如何影响来自五个国家、45个不同民族的1000名参与者对城市街道的感知，以此来纠正缺乏人口统计学或个性特质考虑的局限性。
## Innovation
本研究探讨了人口统计学特征（包括人口统计学变量和人格特质）如何塑造对城市街道景观的感知，并引入了一个名为Street Perception Evaluation Considering Socioeconomics (SPECS)的数据集，展示了不同人口统计学指标和新提出的指标（居住、步行、骑行、绿色）在感知得分上的显著差异。此外，研究还对比了参与者的来源地与街景所在城市，发现了现成的机器学习模型在预测感知得分时存在正面指标高估和负面指标低估的问题，这表明需要考虑当地人的感知来进行有针对性的干预。
## Conclusion
本研究揭示了基于地理位置的情感如何影响人们在比较城市街道景观与其它城市时的偏好，进一步指出了一般性全球感知数据集的机器学习模型可能并不适用于特定地区的感知数据，强调在城市规划中需要更加关注当地人的感知。
# 614. `cs.LG` - 曲面表示性的Bregman差异及其应用 [PDF](https://arxiv.org/pdf/2504.05654), [HTML](https://arxiv.org/abs/2504.05654)
## Authors
Frank Nielsen
## Background
文章通过类比统计学中的弯曲指数族，定义了弯曲Bregman差异。弯曲Bregman差异是限制在非线性参数子空间中的Bregman差异。文章展示了在有限加权参数集下的弯曲Bregman差异重心与按完整Bregman差异进行非线性子空间重心的正确Bregman投影之间的关系。文章通过两种示例（对称化Bregman差异和环形复正态分布的Kullback-Leibler差异）强调了弯曲Bregman差异的重要性，并考虑了单调嵌入来定义表示性的弯曲Bregman差异，进一步说明了α-差异是关于α-嵌入的表示性弯曲Bregman差异。文章还提供了一种高效方法来计算有限个α-差异球体的交集。
## Innovation
文章创新地定义了弯曲Bregman差异，并通过具体示例展示了其应用。特别地，文章引入了代表性的弯曲Bregman差异的概念，并指出α-差异是一种特定的表示性弯曲Bregman差异，基于α-嵌入。此外，文章提出了一个高效算法来计算α-差异球体的交集。
## Conclusion
弯曲Bregman差异的理论为理解和应用特定类型的差异提供了新的视角，特别是在统计学和信息理论中。算法的有效性验证了该方法在处理与多重Bregman差异相关的复杂问题上的实际应用价值。
# 615. `cs.LG` - 使用Kolmogorov-Arnold神经网络量子态探究量子自旋系统 [PDF](https://arxiv.org/pdf/2506.01891), [HTML](https://arxiv.org/abs/2506.01891)
## Authors
Mahmud Ashraf Shamim,Eric A F Reinhardt,Talal Ahmed Chowdhury,Sergei Gleyzer,Paulo T Araujo
## Background
神经量子态（NQS）是一类参数化为神经网络（NNs）的变分波函数，用于研究量子多体系统。在此研究中，作者提出了SineKAN，一种基于Kolmogorov-Arnold网络（KAN）的NQS textit{ansatz}，用于表示量子力学波函数为嵌套的一元函数。该研究通过1维横向场Ising模型、各向异性Heisenberg模型和抗磁性$J_{1}-J_{2}$模型的不同链长，展示了SineKAN波函数可以捕捉基态能量、保真度以及各种相关函数。特别是在研究$L=100$位点的$J_1-J_2$模型时，发现SineKAN模型在与密度矩阵重正化群（DMRG）算法结果进行比较时，超越了之前探索的几种神经量子态 textit{ansatz}，包括受限玻尔兹曼机（RBMs）、长短期记忆模型（LSTMs）和多层感知器（MLP，即前馈神经网络）。SineKAN模型可以在保持高精度和高准确性的同时，具有最小的计算成本。
## Innovation
1. 提出了SineKAN，一种基于KAN的NQS textit{ansatz}，用于表示量子力学波函数。2. SineKAN模型在捕捉不同量子模型的基态能量、保真度和相关函数方面表现出色。3. 在研究$J_1-J_2$模型时，SineKAN模型的性能优于之前探索的其他神经量子态 textit{ansatz}。4. SineKAN模型可以在保持高精度和高准确性的同时，所需的计算成本较低。
## Conclusion
研究表明，SineKAN模型在探究量子自旋系统方面表现出优越的性能，尤其在处理较长链的$J_1-J_2$模型时，比传统方法有明显的提升。
# 616. `cs.LG` - mSTEB: 大规模多语言评估LLMs在语音和文本任务上的表现 [PDF](https://arxiv.org/pdf/2506.08400), [HTML](https://arxiv.org/abs/2506.08400)
## Authors
Luel Hagos Beyene,Vivek Verma,Min Ma,Jesujoba O. Alabi,Fabian David Schmidt,Joyce Nakatumba-Nabende,David Ifeoluwa Adelani
## Background
大型语言模型（LLMs）在各种任务上表现出色，包括语音等多模态应用场景，但其评估往往仅限于英语和其他几种高资源语言。对于低资源语言，尚未有标准化的评估基准。本文的背景在于填补这一空白，提出了一个新的基准mSTEB，旨在评估LLMs在语言识别、文本分类、问答以及语音和文本模态上的翻译任务上的表现范围。
## Innovation
引入了mSTEB新基准，用于评估LLMs在多语言任务上的表现，涵盖了广泛的领域，包括语言识别、文本分类、问答和翻译任务，适用于语音和文本模态。评估了先锋模型如Gemini 2.0 Flash、GPT-4o（音频版）、Qwen 2 Audio以及现代表态的开放模型Gemma 3 27B的表现。结果显示高资源语言和低资源语言之间存在显著的性能差距，特别是非洲和美洲/大洋洲的语言表现较差。研究表明需要更多投资来解决这些语言在LLMs覆盖范围内的不足问题。
## Conclusion
研究结果表明，现有LLMs在低资源语言上的表现存在巨大差距，特别是在非洲和美洲/大洋洲语言上。因此，需要更多的投资以确保这些语言得到充分的覆盖和代表性。
# 617. `cs.LG` - 循环利用网络：一种提升语言模型预训练数据质量和数量的方法 [PDF](https://arxiv.org/pdf/2506.04689), [HTML](https://arxiv.org/abs/2506.04689)
## Authors
Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li
## Background
大规模语言模型的性能会随着模型大小和数据量的增加而提高。实践中，预训练主要依赖大规模网络爬取，几乎使用了所有公开的互联网数据源。然而，可用的计算资源增长速度快于自然数据的增大速度。高质量文本数据的供应更是有限：数据过滤流程通常会移除初始网络爬取数据的99％以上，以达到最先进的效果。为了应对预训练数据规模的“数据墙”，我们的工作探索了将现有过滤过程丢弃的数据转换和再利用的方法。通过实验，我们展示了82%的混合文本来自于原本会被丢弃的低质量文档的转化，在DCLM基准的1B、3B和7B规模下，将高质量原始文本和我们重写的文本混合训练，在22种不同任务上分别取得了1.0、1.3和2.5个百分点的提升，相比仅使用过滤后的网络数据进行训练，使用混合数据的训练效果更好。另外，结果显示循环利用网络文本与Wikipedia风格的重述、问答合成和知识提取等生成合成数据的方法相比，表现更优，这表明循环利用网络文本具有简单且有效的潜力来扩大预训练数据规模。
## Innovation
提出了REWRITE方法，一种将低质量文档转化为有利用价值的训练数据的方法，从而增加了合成数据在预训练数据集中的代表性。实验结果显示，在1B、3B和7B规模的DCLM基准数据集下，将高质量原始文本和重写文本混合训练，相比仅使用过滤后的网络数据，分别在22种不同任务上取得了1.0、1.3和2.5个百分点的提升。另外，研究发现，混合文本中有约82%来自于原本会被丢弃的低质量文档的转化，REWRITE方法的表现也优于现有的生成合成数据的方法。
## Conclusion
通过循环利用网络文本，可以有效提高预训练数据的质量和数量，支持语言模型的进一步优化。
# 618. `cs.LG` - LPOSS：通过像素级标签传播的.patch和像素级标签传播在开放词汇语义分割中的应用 [PDF](https://arxiv.org/pdf/2503.19777), [HTML](https://arxiv.org/abs/2503.19777)
## Authors
Vladan Stojnić,Yannis Kalantidis,Jiří Matas,Giorgos Tolias
## Background
该研究利用视觉-语言模型(Vision-and-Language Models, VLMs)进行开放词汇语义分割，但VLMs主要是为了跨模态对齐而优化的，而不是为了模内相似性。因此，模型的初始预测可能不够准确，尤其是在类边界的分割精度较低。现有训练自由方法存在分辨率限制的挑战，特别是在基于像素的编码器受限的情况下，由此迫切需要改进分割的准确性。该方法通过在像素级应用标签传播作为细化步骤，来克服这种分辨率的限制，从而显著提高语义分割的准确性。
## Innovation
该研究提出了一种无需训练的方法——LPOSS+，通过标签传播在像素层级和patch层级提高VLMs的初始预测，从而优化图像的预测。LPOSS+通过捕捉图像的跨区域上下文交互，而不是使用窗口级处理，实现了开放词汇语义分割的性能提升，达到了训练自由方法中的最新水平。这种方法在多种数据集上验证了其有效性，是一种创新的解决方案，解决了传统基于窗口的方法难以处理的边界和复杂语义关系问题。
## Conclusion
LPOSS+能够在整个图像上进行推理，避免了窗口级处理，从而显著提高了分割的准确性。该方法针对基于patch的编码器固有的分辨率限制问题，通过像素级的标签传播来改进预测，得到优于现有训练自由方法的性能。LPOSS+为开放词汇语义分割领域提供了新的视角和有效的解决方案。
# 619. `cs.LG` - IKDiffuser: 多臂机器人基于扩散模型的生成逆运动学求解器 [PDF](https://arxiv.org/pdf/2506.13087), [HTML](https://arxiv.org/abs/2506.13087)
## Authors
Zeyu Zhang,Ziyuan Jiao
## Background
解决逆运动学（IK）问题是机器人技术的基础，但在多臂机器人系统中，由于自身相撞、耦合关节和高维度冗余等问题，逆运动学问题仍然具有挑战性。传统解法由于这些复杂的特性而变得缓慢、容易失败并且缺乏解的多样性。
## Innovation
我们提出了IKDiffuser，一种基于扩散模型的快速生成多臂机器人系统逆运动学解的方法，能够学习关节在配置空间中的分布，捕捉复杂的依赖关系并支持对具有不同结构的多臂机器人的无缝泛化。此外，IKDiffuser可以在推断期间纳入额外目标而无需重新训练，增强了其在特定任务需求方面的灵活性和适应性。
## Conclusion
在针对6种不同多臂系统的实验中，提出的IKDiffuser在解的精度、精确度、多样性和计算效率方面优于现有的求解器。该提出的IKDiffuser框架提供了一个可扩展的统一方法来解决多臂逆运动学问题，促进了多臂机器人系统在实时操作任务中的应用潜力。
# 620. `cs.LG` - Variational Learning Finds Flatter Solutions at the Edge of Stability [PDF](https://arxiv.org/pdf/2506.12903), [HTML](https://arxiv.org/abs/2506.12903)
## Authors
Avrajit Ghosh,Bai Cong,Rio Yokota,Saiprasad Ravishankar,Rongrong Wang,Molei Tao,Mohammad Emtiyaz Khan,Thomas Möllenhoff
## Background
变分学习（Variational Learning，VL）最近在训练深度神经网络方面获得关注，并且在标准学习方法中具有竞争力。部分实际成功可以归因于PAC-Bayes边界、最小描述长度和边际似然等理论的解释，但缺乏工具来解析VL中隐含的正则化机制。为了探讨VL中的隐含正则化，本文应用边缘稳定性（Edge of Stability，EoS）框架进行分析。以往EoS已被用来显示梯度下降可以找到平坦的解决方案，本文将这一结果扩展到VL，证明了它能够找到更平坦的解决方案。通过控制后验协方差和后验的蒙特卡洛样本数量来实现。这些结果是通过类似于深度学习标准EoS文献的推导方式获得的，首先对二次问题进行了推导，然后扩展到深度神经网络。通过在ResNet和ViT等大型网络上进行实证验证，发现理论结果与实证结果高度一致。这是首次在VL中分析EoS动态的研究工作。
## Innovation
通过边缘稳定性框架分析变分学习中的隐含正则化。证明变分学习可以在边缘稳定性区域内找到比梯度下降更平坦的解决方案。这是通过控制后验协方差和后验的蒙特卡洛样本数量实现的。在广泛的大型网络上进行实证验证，理论结果与实证结果高度一致。
## Conclusion
研究结果表明，变分学习在边缘稳定性区域内能够找到比标准学习方法更平坦的解决方案，这为理解变分学习的正则化机制提供了新的视角。
# 621. `cs.LG` - 复杂性陷阱：不可克服的障碍 [PDF](https://arxiv.org/pdf/2506.10304), [HTML](https://arxiv.org/abs/2506.10304)
## Authors
Jasper Yao
## Background
本文探讨了人工智能（AI）对齐问题并非仅是技术难题，而是一个根本性的逻辑悖论。作者首先提出了列举悖论：我们使用机器学习是因为无法枚举所有必要的安全规则，但使机器学习安全需要从这些我们承认无法枚举的例子中生成，这构成了一个悖论。随后，通过五组独立的数学证明，进一步确认了这一悖论。这些证明表明，AI对齐存在几何上的、计算上的、统计上的、信息论上的以及动态上的不可克服障碍，从而使得追求高度安全、高性能的AI变得非常困难。
## Innovation
本文的主要贡献在于提出了五种不可克服的障碍，包括几何上、计算上、统计上、信息论上及动态上的根本性障碍，这些障碍构成了AI对齐的复杂性限制，这些观点挑战了当前技术可能会克服这些难题的看法。此外，作者还使用Lean4对核心定理进行了形式验证，进一步支持了这些结论的有效性。
## Conclusion
本文最终明确提出一个战略困境，这些障碍迫使整个AI领域必须面对并解决。
# 622. `cs.LG` - SLEEPING-DISCO 9M：用于生成音乐建模的大型预训练数据集 [PDF](https://arxiv.org/pdf/2506.14293), [HTML](https://arxiv.org/abs/2506.14293)
## Authors
Tawsif Ahmed,Andrej Radonjic,Gollam Rabby
## Background
在生成音乐建模任务（如文本音乐、音乐配字、歌声合成、旋律重构和跨模型检索）中，目前尚未存在高质量的开放源代码数据集来代表流行且广为人知的歌曲。以往的研究主要集中在孤立和受限制的因素上，倾向于创建合成或重新录制的音乐 corpus，如 GTSinger 和 M4Singer。同时，任意规模的音频数据集，如 DISCO-10M 和 LAIONDISCO-12M，是社区的重点关注对象。然而，这些数据集在生成音乐社区中的采用率较低，因为它们未能反映真实世界的音乐及其特色。
## Innovation
本文介绍了一个名为 Sleeping-DISCO 9M 的大型预训练数据集，旨在填补高质量开放源代码数据集的空白。该数据集由实际的流行音乐和世界知名艺术家构建。与之前的研究相比，它更好地反映了真实世界的音乐及其特点，有助于提高生成音乐模型的效果和实际应用能力。
## Conclusion
Sleeping-DISCO 9M 能够为生成音乐建模任务提供高质量的实际数据支持，改善目前数据集存在的实际问题，推动生成音乐技术的发展。
# 623. `cs.LG` - 在分布式学习中识别异质性 [PDF](https://arxiv.org/pdf/2506.16394), [HTML](https://arxiv.org/abs/2506.16394)
## Authors
Zelin Xiao,Jia Gu,Song Xi Chen
## Background
本研究探讨了在分布式M-估计中识别异质参数组件的方法，特别是在数据传输量最小的情况下。研究背景是分布式学习中，不同数据块的参数可能有不同的估计值，这需要开发有效的方法来识别这些异质性.
## Innovation
研究提出了两种方法：一种基于重新标准化的Wald检验，适用于低密度异质性且数据块数量较小的情况；另一种是基于极端对比检验（ECT），通过样本划分程序避免了M-估计偏差累积的问题，适用于稀疏异质性且数据块数量远大于样本量的情况。此外，研究还提出了一种结合Wald检验和ECT的方法以提高检测力的稳健性.
## Conclusion
通过密集的数值实验比较了所提方法的全家错误率（FWER）和功效。并进行了一个案例研究，展示了所提方法的应用和有效性。
# 624. `cs.LG` - 基于上下文学习的无需梯度接收机适应：原理、应用与理论 [PDF](https://arxiv.org/pdf/2506.15176), [HTML](https://arxiv.org/abs/2506.15176)
## Authors
Matteo Zecchin,Tomer Raviv,Dileep Kalathil,Krishna Narayanan,Nir Shlezinger,Osvaldo Simeone
## Background
近年来，深度学习促进了能够在传统基于模型的设计面临挑战的条件下有效运行的无线接收机的创建。基于可编程硬件架构的深度学习接收机具有动态适应变化信道环境的潜力。然而，当前的适应策略，如联合训练、基于超网络的方法和元学习，要么灵活性有限，要么需要通过梯度下降进行显式优化。研究指出，在使用试点信号和辅助上下文信息进行实时接收机适应时，不需要在线重新训练的新原理和方法具有重要的研究意义。
## Innovation
本文提出了基于新兴的上下文学习（ICL）范式的无需梯度接收机适应技术。我们回顾了基于Transformer模型和结构化状态空间模型（SSMs）的ICL架构框架，并探讨了序列模型如何从上下文信息中有效学习适应。此外，我们还探讨了ICL在无源大规模MIMO网络中的应用，提供了理论分析和实证证据。研究表明ICL是一种有原则且高效的实时接收机适应方法，不需要在线重新训练。
## Conclusion
ICL 代表了一种基于试点信号和辅助上下文信息的手段来实现实时接收机适应的新方法，这种方法不需要在线重新训练，提供了对变化信道环境的动态适应，证明了其作为没有梯度接收机适应的有效性和高效性。
# 625. `cs.LG` - DRO-Augment框架：通过结合Wasserstein分布鲁棒优化和数据增强实现鲁棒性 [PDF](https://arxiv.org/pdf/2506.17874), [HTML](https://arxiv.org/abs/2506.17874)
## Authors
Jiaming Hu,Debarghya Mukherjee,Ioannis Ch. Paschalidis
## Background
在许多实际应用中，确保深度神经网络（DNN）的鲁棒性和稳定性至关重要，尤其是在遇到各种输入干扰时，对于图像分类任务。尽管数据增强技术被广泛应用于增强模型抗干扰的能力，但在同时对抗扰乱数据和恶意攻击方面仍有改进的空间。
## Innovation
我们提出了DRO-Augment框架，该框架将Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略相结合，显著提高了模型在广泛干扰环境下的鲁棒性。我们的方法在严重数据扰动和恶意攻击场景下优于现有的数据增强方法，同时在各种基准数据集（包括CIFAR-10-C、CIFAR-100-C、MNIST和Fashion-MNIST）上的干净数据集上保持了准确性。从理论层面，我们建立了使用基于W-DRO问题的高效可计算变异性正则化损失函数训练的神经网络的新泛化误差界。
## Conclusion
我们的方法在多个基准数据集上展示了在严重数据扰动和攻击情境下的优越表现，同时在干净数据集上保持了高准确性，并且从理论上分析了新泛化误差界。
# 626. `cs.LG` - BeltCrack：首个用于工业输送带裂纹检测的序贯图像数据集及其具有三域特征学习的基线方法 [PDF](https://arxiv.org/pdf/2506.17892), [HTML](https://arxiv.org/abs/2506.17892)
## Authors
Jianghong Huang,Luping Ji,Xin Ma,Mao Ye
## Background
输送带是现代工业中重要的设备，广泛应用于生产和制造中。其健康状况对运营效率和安全性至关重要。裂缝是输送带健康的主要威胁之一。当前，为了保障安全性，如何智能检测输送带裂缝越来越受到重视。然而，现有的裂缝数据集主要集中在公路场景或合成数据上，完全没有实际工业输送带裂缝的数据集。我们提出了两个全新的序贯图像数据集，并且采用三域特征层级融合学习的方法进行基线分析。实验结果表明，我们的数据集具有可用性和有效性，并且基线方法明显优于其他同类检测方法。这些数据集和源代码可以在以下链接访问：this https URL
## Innovation
首次提出了工业输送带裂缝检测的序贯图像数据集，并采用了三域特征层级融合学习方法，旨在填充现有数据集的空白，解决真实工业场景下的裂缝检测问题，这对于智能识别和维护输送带健康具有重要意义。
## Conclusion
实验结果证明该数据集的有效性和可行性，并且提出的方法明显优于现有同类方法。这些数据集和源代码可公开获取，以促进进一步的研究和开发。
# 627. `cs.LG` - 细粒度注意力头选择下的微调指导 [PDF](https://arxiv.org/pdf/2506.10978), [HTML](https://arxiv.org/abs/2506.10978)
## Authors
Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim
## Background
扩散模型中的近期指导方法通过在模型上施加扰动来逆向采样，构造一个隐式的弱模型，并引导生成远离该模型。在无条件场景中，注意力扰动方法在不可应用分类器自由指导的情况下表现出强大经验性能。然而，现有方法缺乏在扩散变换器（DiT）架构中适切地确定扰动应用于何处的原理性方法，因此无法很好地实现细粒度控制。本文研究了从层级到单个注意力头级的注意力扰动的粒度，发现特定的head负责不同的视觉概念，如结构、风格和纹理质量。
## Innovation
本文提出了HeadHunter框架，这是一种系统性的方法，能根据用户的目标迭代选择注意力头，从而实现对生成质量和视觉属性的细粒度控制。此外，引入了SoftPAG，通过线性插值每个选择的头的注意力图向单位矩阵，提供连续的调节点来调整扰动强度并抑制伪像。本文的方法不仅解决了现有层级扰动过度平滑的问题，还通过组合头部选择实现了对特定视觉样式的有针对性操控。我们的研究还在现代大规模DiT基文本到图像模型中验证了方法，证明了在一般质量和风格特定引导方面都优于现有方法的表现。该工作首次对扩散模型中的注意力扰动进行了头部级别分析，揭示了注意力层可解释的特化，从而便于设计有效的扰动策略。
## Conclusion
通过HeadHunter框架和SoftPAG，本文在扩散模型中实现了对生成质量的细粒度控制和特定风格的引导，证明了优于现有方法的表现，为设计有效的扰动策略提供了实用设计参考。
# 628. `cs.LG` - LLM生成数据中何事最为关键：多样性及其对模型微调的影响 [PDF](https://arxiv.org/pdf/2506.19262), [HTML](https://arxiv.org/abs/2506.19262)
## Authors
Yuchang Zhu,Huazhen Zhong,Qunshu Lin,Haotong Wei,Xiaolong Sun,Zixuan Yu,Minghao Liu,Zibin Zheng,Liang Chen
## Background
由于大语言模型（LLMs）表现出显著的生成能力，使用LLM生成的数据来训练下游模型已成为缓解特定领域数据稀缺并在减少耗时标注方面具有潜力的方法。然而，最近的研究指出，迭代使用自生成数据训练会引发模型性能衰退的问题，即模型崩溃现象。尽管有许多关于LLM生成数据影响的研究，但这些研究往往忽视了数据多样性的关键作用，而数据质量是决定其价值的重要因素。本文旨在研究生成数据多样性对下游模型性能的影响，探讨不同水平多样性对下游模型性能的影响，以及不同比例混合真实数据与生成数据的合成数据表现的效果。实验结果表明，适度多样性的生成数据在标注数据不足的情况下可以增强模型性能，而非常多样性的数据则会有负面影响。
## Innovation
本文强调了数据多样性的关键作用，指出了在使用LLM生成数据训练下游模型时应注重数据多样性。实验设计旨在研究多样性对模型微调的具体影响，尤其关注数据生成过程中的多样性和不同比例混合数据对模型性能的影响。通过这种方法，本文提出了关于如何利用LLM生成数据来优化下游模型训练的具体建议，为相关领域的进一步研究提供了实证指导。
## Conclusion
实验结果显示，适度多样性的生成数据在标注数据稀缺时可以提升模型性能，而非常高多样性的生成数据则表现出负面影响，建议未来研究注重这种多样性的影响，并提供指导使利用LLM生成数据进行模型微调时更有效。
# 629. `cs.SE` - 当领域发生碰撞：活动理论视角下跨学科协作探究 [PDF](https://arxiv.org/pdf/2506.20063), [HTML](https://arxiv.org/abs/2506.20063)
## Authors
Zixuan Feng,Thomas Zimmermann,Lorenzo Pisani,Christopher Gooley,Jeremiah Wander,Anita Sarma
## Background
随着软件开发团队变得越来越多元化、嵌入式和跨学科，来自不同学科领域的专家（DEs）与专业的软件开发人员（SDEs）合作，共同创造和维护复杂的生产软件。然而，不同的期望、截然不同的问题解决视角以及相互冲突的优先级导致了摩擦。这些摩擦的影响尚未充分探索，这成为了本研究的背景。
## Innovation
本研究采用活动理论（AT），作为社会-技术分析框架，通过一项实证调查研究了跨学科软件开发（CDSD）中的动态协作，该研究涉及24次访谈和293名参与者的问卷调查，以探究开发专家和软件开发人员持有的期望，并理解这些摩擦在实践中是如何表现出来的。通过将这些期望映射到活动理论的组件，揭示了21种在CDSD中存在的摩擦，并说明了它们是如何出现的。
## Conclusion
本研究提供了一个理论框架来理解CDSD中的动态和摩擦，并为未来的研究、实践者以及基础设施设计提供了可操作的见解。
# 630. `cs.SE` - AI和敏捷软件开发：从挫折到成功 -- XP2025研讨会摘要 [PDF](https://arxiv.org/pdf/2506.20159), [HTML](https://arxiv.org/abs/2506.20159)
## Authors
Tomas Herda,Victoria Pichler,Zheying Zhang,Pekka Abrahamsson,Geir K. Hanssen
## Background
The full-day workshop on AI and Agile at XP 2025召集了一个多元化的研究和业界实践者的团队，以探讨将人工智能纳入敏捷软件开发中所面临的实际挑战和机遇。参与者通过互动讨论发现了在敏捷软件开发实践中整合人工智能所遇到的一系列共同的挫败感，包括工具方面的挑战、治理、数据质量和关键技能缺口等问题。这些问题被系统地优先级排序和分析，以找出根本原因。
## Innovation
此次研讨会的创新之处在于，它提供了一个结构化的议程，旨在促进跨界合作，从识别出的挫败感过渡到实际的成功实施，为未来的工作指明了具体的方向，既包括了立即可解决的问题，也涉及长期的宏伟目标。
## Conclusion
此次研讨会的成果是制定了一份明确的研究路线图，该路线图阐明了未来工作的具体行动方向，为行业和学术界的共同努力提供了指导，以克服面临的挑战并成功实施人工智能在敏捷软件开发中的应用。
# 631. `cs.LG` - 使用路径签名的可扩展机器学习算法 [PDF](https://arxiv.org/pdf/2506.17634), [HTML](https://arxiv.org/abs/2506.17634)
## Authors
Csaba Tóth
## Background
路径签名与随机分析之间的接口是一个快速发展的领域，路径签名作为一种迭代积分，能够提供路径的忠实且分级的表示，特别适合于时间序列和结构化数据。路径签名根植于粗糙路径理论，其具有重新参数化不变性，并且非常适合建模演变动力学、长程依赖关系和不规则抽样等现实世界中常见的挑战。本文探讨如何在可扩展的机器学习管道中利用路径签名的表征力。
## Innovation
本文的关键贡献包括：基于路径签名内核的高斯过程，用于不确定性的时序建模；使用低秩张量结构的Seq2Tens框架，用于可扩展地建模长程依赖关系；基于图的模型，其中期望签名诱导豪威耳扩散过程，提供了与标准图神经网络相比更具表现力但更易于处理的选择；随机傅里叶路径签名特征，一种具有理论保证的大规模内核近似方法；以及结合了高斯过程、路径签名内核和随机特征，并带有适应性上下文长度的原理遗忘机制的递归稀疏谱路径签名高斯过程，用于多视野时间序列预测。
## Conclusion
本文旨在不仅作为方法工具箱，也作为概念桥梁，提供对基于路径签名的可扩展学习方法当前状态的有用参考。
# 632. `cs.SE` - PIs应遵循的十个简单规则以将研究软件工程集成到其研究组中 [PDF](https://arxiv.org/pdf/2506.20217), [HTML](https://arxiv.org/abs/2506.20217)
## Authors
Stuart M. Allen,Neil Chue Hong,Stephan Druskat,Toby Hodges,Daniel S. Katz,Jan Linxweiler,Frank Löffler,Lars Grunske,Heidi Seibold,Jan Philipp Thiele,Samantha Wittke
## Background
研究软件工程（RSEng）是生成高质量研究软件的关键因素，从而推动和改进研究结果。然而，作为主要负责人或研究小组领导，你可能不了解RSEng是什么，如何开始使用它，或者如何最大程度地利用它来提高研究影响力。RSEng通常伴随着技术复杂性，导致一些研究人员的使用困难。因此，需要提供易于理解且实用的指导，来提高RSEng的可访问性和可操作性，帮助研究群体实现高质量、可重复和可信赖的研究结果。
## Innovation
本文提出了十个简单的指导原则，旨在提高RSEng的可访问性，并为PIs和研究团队负责人提供实用且可操作的建议，以将RSEng集成到他们的研究组中。这些规则的主要创新点在于，它们简单明了，易于理解和遵循，能够帮助研究者提升研究软件的质量、可重用性和可信度，从而产生更好的、更可重复和更可信的研究成果。
## Conclusion
通过遵循这些规则，读者可以改善其研究软件的质量、可再现性和可信度，最终导致更高质量、更可再现和更可信的研究成果。
# 633. `cs.SE` - 数字孪生系统中数字孪生的组成：一项系统的文献综述 [PDF](https://arxiv.org/pdf/2506.20435), [HTML](https://arxiv.org/abs/2506.20435)
## Authors
Mennatullah T. Khedr,John S. Fitzgerald
## Background
数字孪生（DTs）在复杂系统的建模中发挥重要作用，尤其是在网络物理系统（CPS）和系统集群（SoS）中，有效的集成是关键。本文通过系统文献综述，分析了2022-2024年间有关DT组成的21项研究，探讨了组成机制、SoS特性、验证与验证（V&V）的形式、范围及其面临的挑战，发现虽然讨论了组成机制，但正规化程度有限，V&V方法多样，半正规和模拟方法占据主导地位，正规化验证应用不足。技术挑战在于模型不确定性与整合复杂性，方法论挑战则在于缺乏特定于数字孪生的标准V&V框架，需要超越模型验证，解决集成和网络物理一致性问题。
## Innovation
研究贡献了一个结构化的V&V方法分类，并强调了需要标准化、可扩展的V&V方法和严格的组成方法论，以应对复杂数字孪生的实施需求。
## Conclusion
研究结论认为，需要超越现有的模型验证，重视解决集成和网络物理一致性的挑战，推进数字孪生系统中数字孪生的组成及其验证与验证方法的发展。
# 634. `cs.LG` - 通过提示、微调和离分布提示评估小型语言模型的泛化能力及内部表示稳定性 [PDF](https://arxiv.org/pdf/2506.17289), [HTML](https://arxiv.org/abs/2506.17289)
## Authors
Rahul Raja,Arpita Vats
## Background
本文研究了在两种流行的适应范式下小型语言模型的泛化能力：少量示例提示和监督微调。虽然提示因其参数效率和灵活性而受到青睐，但在低资源环境和分布变化下的鲁棒性仍然不清楚。本文在任务格式、提示风格和模型规模上对提示和微调进行了比较研究，特别是在分布内和分布外设置下的表现。研究不仅关注准确率，还分析了每种方法所学习的内部表示，以评估任务特定特征的稳定性和抽象性。
## Innovation
本文提出了一个关于提示和微调在不同任务格式、提示风格和模型规模下的综合比较研究，特别是在分布内和分布外设置下的表现。分析了每种方法所学习的内部表示，评估任务特定特征的稳定性和抽象性，揭示了在不同适应策略下小型模型内化和泛化知识的关键差异。这对于在低数据环境下选择模型具有实际指导意义，并为提示与微调的持续辩论提供了实证见解。
## Conclusion
本文的工作对在低数据环境下的模型选择提供了实用指导，并为提示与微调的持续辩论贡献了实证洞见。实验代码可供参考。
# 635. `cs.SE` - 大型语言模型驱动的建筑信息建模中的代码合规检查 [PDF](https://arxiv.org/pdf/2506.20551), [HTML](https://arxiv.org/abs/2506.20551)
## Authors
Soumya Madireddy,Lu Gao,Zia Din,Kinam Kim,Ahmed Senouci,Zhe Han,Yunpeng Zhang
## Background
当前的建筑信息建模（BIM）环境中，手工代码合规检查既耗时又容易出错。因此，研究引入了一种基于大型语言模型（LLM）的半自动化方法，以解决这一问题。开发的系统结合了像GPT、Claude、Gemini和Llama这样的LLM与Revit软件，用于解释建筑规范、生成Python脚本以及在BIM环境中进行半自动合规检查。研究表明，该系统能够减少合规检查所需的时间和精力，同时提高准确性。该系统简化了识别违规行为（如非合规房间尺寸、材料使用和对象放置），通过自动评估关系并生成可操作报告来实现。与手工方法相比，该系统消除了重复任务，简化了复杂的条例规定，并确保了可靠的标准遵守。
## Innovation
该研究提出了一种基于LLM的方法，用于半自动化建筑信息建模中的代码合规检查。通过结合GPT、Claude、Gemini和Llama等LLM与Revit软件，系统能够解释建筑规范、生成Python脚本和进行半自动合规检查。该系统能够减少手工合规检查的时间和精力，同时提高准确性，并简化复杂的规定，确保可靠的标准遵守。
## Conclusion
通过提供一个全面、可适应且经济实惠的解决方案，该方法为基于BIM的合规检查提供了有希望的进展，具有在建筑项目中的各种监管文件中应用的潜力。
# 636. `cs.SE` - CCISolver: End-to-End Detection and Repair of Method-Level Code-Comment Inconsistency [PDF](https://arxiv.org/pdf/2506.20558), [HTML](https://arxiv.org/abs/2506.20558)
## Authors
Renyi Zhong,Yintong Huo,Wenwei Gu,Jinxi Kuang,Zhihan Jiang,Guangba Yu,Yichen Li,David Lo,Michael R. Lyu
## Background
代码中的注释是软件文档的重要基石，有助于开发者有效沟通和理解代码。然而，代码注释不一致（CCI）的问题会负面影响软件开发、测试和维护。尽管有部分努力旨在缓解这一问题，但现有研究通常面临数据集不准确和解决方案不足的问题，削弱了其实际效果。定量分析现有的数据集发现采样数据有很大一部分被错误标注。
## Innovation
本研究提出了CCIBench，一个包括高质量数据的数据集，以支持方法级CCI方法的训练和评估。此外，本文还介绍了一种创新的基于LLM的端到端框架CCISolver，用于通过识别和纠正CCI来提高代码质量。全面评估表明CCISolver表现出色，检测方面建立了新的SOTA，F1分数达到89.54%，修复任务方面相对基线在GLEU分数上提高了18.84%。在人类评估中，CCISolver的成功修复率高达0.6533，远超现有方法。此外，CCISolver的创新架构比基线模型快约36%，突显了其可扩展性和实际适用性。
## Conclusion
CCISolver通过改进代码质量，识别和纠正CCI，从而显著提升了软件开发的效果。其用于端到端检测和修复代码注释不一致的能力，已经在多个指标上表明优于现有方法，并且展示出在实际应用中的高效性和可扩展性。
# 637. `cs.SE` - 智能裁剪：通过剔除坏种子提升漏洞检测的主动学习 [PDF](https://arxiv.org/pdf/2506.20444), [HTML](https://arxiv.org/abs/2506.20444)
## Authors
Xiang Lan,Tim Menzies,Bowen Xu
## Background
漏洞检测对于识别软件系统的安全弱点至关重要。然而，机器学习模型在这一领域的有效性受到低质量训练数据集的阻碍，这些数据集包含嘈杂的、错误标签的或不平衡的样本。因此，需要一种新的方法来系统地识别和减轻难以学习的异常样本（称为“坏种子”），以提高模型训练效率。
## Innovation
本文提出了一种新的数据集地图辅助方法，该方法能够系统地识别和减轻难以学习的异常样本，并将其分类为根据学习难度进行划分的信息，并将其整合到主动学习框架中。该方法优先考虑数据集质量，通过过滤有损性能的样本并强调有信息量的样本，而不同于传统的基于不确定性的抽样方法。实验结果表明，与随机选择相比，该方法可以提高DeepGini的F1分数45.36%，K-Means的F1分数45.91%，并且在CodeBERT上的Big-Vul数据集上，该方法也优于标准的主动学习61.46%（DeepGini）和32.65%（K-Means），显示出将数据集地图整合以优化样本选择对提高漏洞检测效果的有效性。此外，该方法还能增强模型的鲁棒性，提高通过过滤坏种子的样本选择，并且在迭代中稳定主动学习的性能。通过分析这些异常样本的特性，为未来改进数据集构建提供了见解，使漏洞检测更可靠且成本效益更高。
## Conclusion
本文提出的方法通过分类训练样本并减轻难以学习的异常样本（坏种子），提高了漏洞检测的模型训练效率和性能。实验结果表明该方法能够在不同机器学习模型和数据集上有显著的提升，进而使得模型更为稳定和可靠，并为优化样本选择和增强模型鲁棒性提供了新的思路和方法。
# 638. `cs.LG` - FORTRESS：前沿国家安全与公共安全风险评估 [PDF](https://arxiv.org/pdf/2506.14922), [HTML](https://arxiv.org/abs/2506.14922)
## Authors
Christina Q. Knight,Kaustubh Deshpande,Ved Sirdeshmukh,Meher Mankikar,Scale Red Team,SEAL Research Team,Julian Michael
## Background
大规模语言模型（LLMs）的快速发展带来了双用途能力，既可能威胁又可能增强国家和公共安全（NSPS）。模型通过实施保护措施防止潜在滥用，并为用户提供有益信息。然而，当前的基准测试往往无法客观、稳健地测试保护措施对潜在NSPS风险的抵御能力。本文介绍了一种新型评估工具，用于评估前沿LLMs保护措施的稳健性，并揭示不同模型在风险和实用性之间的权衡情况。
## Innovation
本文提出了一种名为FORTRESS的评估工具，包括500个由专家设计的对抗式提示及其对应的评分标准（每个提示对应4-7个二元问题），用以自动评估前沿LLMs在化学、生物、核辐射、爆炸物（CBRNE）、政治暴力与恐怖主义、以及犯罪与金融非法活动等三个领域中的安全保护措施的稳健性，同时提供了模型过度拒绝的对比版本。
## Conclusion
通过FORTRESS评估，不同模型在潜在风险和过度拒绝之间表现出不同的权衡。例如，Claude-3.5-Sonnet展示了最低的平均风险评分（14.09/100）但最高过度拒绝评分（21.8/100），而Gemini 2.5 Pro展示了最低的过度拒绝（1.4）但最高的平均潜在风险（66.29）。我们特别公开了FORTRESS作为资源库，以便为政策制定者和研究者提供明确的风险理解。
# 639. `cs.SE` - MNN-AECS: 通过自适应核心选择在移动设备上优化LLM解码的能效 [PDF](https://arxiv.org/pdf/2506.19884), [HTML](https://arxiv.org/abs/2506.19884)
## Authors
Zhengxiang Huang,Chaoyue Niu,Zhaode Wang,Jiarui Xue,Hanming Zhang,Yugang Wang,Zewei Xin,Xiaotang Jiang,Chengfei Lv,Fan Wu,Guihai Chen
## Background
随着对移动设备本地大规模语言模型（LLM）推理的需求增长，能效已经成为一个重要问题，尤其是在电池限制的移动设备上。现有工作的重点往往在预填充阶段加速，而忽视了能效方面的问题。我们的分析表明，受内存限制的LLM解码阶段消耗了大量的能源，但大多数现有工作专注于加速预填充阶段，忽略了能效问题。因此，迫切需要一种在不改变操作系统或需要root权限的情况下，能够降低LLM解码能耗的解决方案。
## Innovation
我们提出了自适应能效核心选择（AECS）并将其整合到MNN中，形成了能够实现能效优化的MNN-AECS。MNN-AECS设计用于在保持解码速度在可接受的减速阈值内的情况下，通过动态选择低功耗CPU核心来降低LLM解码的能耗。MNN-AECS在5款Android和2款iOS设备上对5个不同大小的流行LLM进行了评估。与原始的MNN相比，MNN-AECS在所有7款设备和4个数据集上的能耗降低了23%，并且没有广泛的性能下降。与其他几个引擎相比，MNN-AECS在平均能耗节省方面表现突出，达到了39%到78%之间，并且平均速度提高了12%到363%。
## Conclusion
MNN-AECS是第一个无需超级用户权限或操作系统的修改，在引擎级别提供能效优化的解决方案。其不仅能降低LLM解码能耗，还能在保持一定的速度的前提下，提升整体性能。
# 640. `cs.SE` - WAFFLE: 使用多模态模型进行自动化前端开发的微调策略 [PDF](https://arxiv.org/pdf/2410.18362), [HTML](https://arxiv.org/abs/2410.18362)
## Authors
Shanchao Liang,Nan Jiang,Shangshu Qian,Lin Tan
## Background
前端开发涉及将UI设计转化为功能页面，这可能对新手和有经验的开发人员来说都是一项挑战，尤其是由于HTML的层级结构和样式复杂性。尽管大型语言模型（LLMs）显示出生成源代码的潜力，但在UI到HTML代码生成中仍存在两大挑战：(1) 如何有效地向LLMs传达HTML的层级结构，(2) 怎么弥合UI设计的视觉性质与HTML代码文本格式之间的差距。为了解决这两个问题，我们引入了Waffle，一种新的微调策略，利用结构感知的注意力机制提高LLMs对HTML结构的理解，并使用对比细调方法使LLMs对UI图像和HTML代码的理解更加一致。使用Waffle进行微调的模型在我们的新基准WebSight-Test和已有的Benchmark Design2Code中表现优于现有的微调方法，显示出高达9.00个百分点更高的HTML匹配度，0.0982更高的CW-SSIM，32.99更高的CLIP分数，以及27.12个百分点更高的LLEM分数。
## Innovation
Waffle 引入了一种新的微调策略，结合了结构感知的注意力机制和对比微调方法，以提高大型语言模型 (LLMs) 对 HTML 结构和 UI 图像与 HTML 代码之间的理解，从而解决了 UI 到 HTML 代码生成中的两个主要挑战。这种方法在多个基准测试中显示出显著的性能提升。
## Conclusion
通过使用 Waffle 微调策略，模型在多个基准测试中的表现优于现有方法，特别是在 HTML 匹配程度、CW-SSIM、CLIP 和 LLEM 等指标上取得显著进步，这表明 Waffle 在前端开发自动化方面具有较高的潜力和应用价值。
# 641. `cs.SE` - 在代码分块过程中LLMs能否代替人类？ [PDF](https://arxiv.org/pdf/2506.19897), [HTML](https://arxiv.org/abs/2506.19897)
## Authors
Christopher Glasz,Emily Escamilla,Eric O. Scott,Anand Patel,Jacob Zimmer,Colin Diggs,Michael Doyle,Scott Rosen,Nitin Naik,Justin F. Brunelle,Samruddhi Thaker,Parthav Poudel,Arun Sridharan,Amit Madan,Doug Wendt,William Macke,Thomas Schill
## Background
大型语言模型（LLMs）已经成为计算机科学中不可或缺的工具，尤其是在代码理解和生成的任务中。然而，现有的研究并未解决政府应用代码特有的诸多挑战，如政府企业软件通常使用过时的语言，如MUMPS或汇编语言代码（ALC），并且这些系统的整体标记长度超出了当前商用LLMs的上下文窗口大小。此外，LLMs主要是在现代编程语言上进行训练，且对过时语言的测试有限，因此理解过时语言的能力尚未经证实，是一个需要实证研究的领域。因此，本研究集中在利用LLMs进行过时政府代码（如ALC和MUMPS）的现代化过程中，解决输入限制的挑战，通过分块方法优化生成模块摘要的代码，分析不同LLM（包括GPT-4o、Claude 3 Sonnet、Mixtral和Llama 3）在生成文档时质量的影响，结果表明LLMs可以选择与人类专家分块紧密对齐的分块点，并且分块方法对下游任务如文档生成具有显著影响，因此生成的注释比人工创建的注释更具有事实性和实用性。
## Innovation
本研究创新性地探索了大型语言模型在处理过时政府代码时的适用性和应用方法，具体表现在开发了一套分块方法来优化大型代码库中的模块简介生成，评估不同LLM在文档生成任务中的表现，发现机器生成的分块与人类专家分块高度一致，且具有更高的准确性和实用性，证明了LLMs在代码分块中的潜力。
## Conclusion
研究结论认为，大型语言模型可以作为替代人类进行大型代码分块的有效工具，在LLM辅助的代码现代化过程中，LLMs能够有效地进行模块分块并生成有价值的文档，证明了LLMs有潜力在代码分块和现代化方面替代人类专家。
# 642. `cs.SE` - Define-ML: 一种实现机器学习驱动系统的方法 [PDF](https://arxiv.org/pdf/2506.20621), [HTML](https://arxiv.org/abs/2506.20621)
## Authors
Silvio Alonso,Antonio Pedro Santos Alves,Lucas Romao,Hélio Lopes,Marcos Kalinowski
## Background
随着机器学习（ML）在软件系统中的广泛应用，需要特别针对ML特定挑战（如数据依赖性、技术可行性及业务目标与概率系统行为的一致性）的创新理念方法。传统的精益初始（Lean Inception）等理念方法缺乏对ML考虑的结构化支持，这可能导致产品愿景不切实际和不合理的预期。因此，需要一种新的框架来更好地管理这些挑战。
## Innovation
论文提出了Define-ML框架，它在精益初始的基础上增加了定制化的活动，包括数据源映射、特征到数据源映射和ML映射，旨在系统性地将数据和技术约束整合到早期的ML产品理念中。该框架通过科技转移模型进行开发和验证，包括静态验证（通过玩具问题）和动态验证（在实际工业案例研究中）。验证结果显示，参与者发现Define-ML在澄清数据问题、将ML能力与业务目标相结合以及促进跨职能协作方面非常有效。虽然有一部分参与者认为ML特定组件的学习曲线较高，但这些可以通过专家引导来解决。所有参与者都表示愿意采用Define-ML方法。
## Conclusion
Define-ML提供了一种公开可用、经过验证的方法来实现ML产品的理念，它在保留精益初始方法的敏捷性的同时，也确保了功能与可用数据的一致性，并增强了对技术可行性的认识。
# 643. `cs.SE` - 语言模型能否代替程序员编码？REPOCOD表示‘尚未实现’ [PDF](https://arxiv.org/pdf/2410.21647), [HTML](https://arxiv.org/abs/2410.21647)
## Authors
Shanchao Liang,Yiran Hu,Nan Jiang,Lin Tan
## Background
近年来，出现了诸如 CoderEval、DevEval、RepoEval、RepoBench 和 LongCodeArena 等仓库级别的代码生成基准，用于评估大型语言模型（LLMs）的能力，超越了仅依赖于 HumanEval 和 MBPP 的基准。然而，这些基准大多包含短代码片段、合成示例或只关注有限规模的仓库，无法真实反映实际的编码任务。因此，存在一个问题，即 LLMs 在实际编码任务中是否会有相近的表现。为了应对这些挑战，本文创建了 REPOCOD，一个包含来自真实大型项目中的复杂任务的 Python 代码生成基准，并提供了合适的评估指标。它包含来自 11 个流行项目的 980 个完整的函数生成任务，其中 50.8% 需要仓库级别的上下文。每个实例还包括 314 个开发人员编写的测试用例，以更好地进行评估。
## Innovation
REPOCOD 是一个新的基准，包含来自真实大型项目中的复杂任务，并且需要仓库级别的上下文，更准确地代表实际的编码任务。此外，研究发现，检索增强生成优于仅使用目标函数依赖性作为上下文的方法，这提供了一个新的研究方向。
## Conclusion
LLMs 在实际编码任务中的表现不佳，甚至在 REPOCOD 这样的基准上，最好的 LLM 也只通过了 30% 的测试，强推进更加优秀的 LLMs 是必要的，以辅助开发者进行实际的软件开发。
# 644. `cs.SE` - VulStamp: 使用大型语言模型进行漏洞评估 [PDF](https://arxiv.org/pdf/2506.11484), [HTML](https://arxiv.org/abs/2506.11484)
## Authors
Hao Shen,Ming Hu,Xiaofei Xie,Jiaye Li,Mingsong Chen
## Background
尽管现代漏洞检测工具能够高效地识别大量安全缺陷，但不加区分的修复工作往往会导致不必要的开发成本。这主要是因为很多检测到的漏洞要么不具备高可利用性，要么在实际运营环境中不会造成明显影响。因此，漏洞严重性评估已成为优化软件开发效率的关键组成部分。现有的漏洞评估方法通常依赖于与源代码片段相关的手动描述。但由于描述质量的差异和意图解释的主观性，这些方法的性能受到严重限制。
## Innovation
本文提出了一种名为VulStamp的新型意图导向框架，用于描述自动生成的漏洞评估。VulStamp结合静态分析和大型语言模型（LLM）来提取漏洞代码的意图信息，并在此基础上利用提示调优模型进行漏洞评估。此外，为了解决漏洞类型数据不平衡的问题，VulStamp整合了一种基于强化学习（RL）的提示调优方法来训练评估模型。
## Conclusion
通过以上方法，VulStamp成功解决了现有漏洞评估方法在描述质量和意图解释方面的限制问题，提供了一种更加自动化和高效的漏洞评估手段。
# 645. `cs.SE` - 整合多种软件信息以更好地实现基于LLM的错误定位和程序修复 [PDF](https://arxiv.org/pdf/2412.03905), [HTML](https://arxiv.org/abs/2412.03905)
## Authors
Qiong Feng,Xiaotian Ma,Jiayi Sheng,Ziyuan Feng,Wei Song,Peng Liang
## Background
LLM（大型语言模型）在自动程序修复（APR）方面受到了广泛关注，基于LLM的方法可以插入正确的代码或直接生成补丁。然而，大多数基于LLM的APR方法主要依赖于单一类型的软件信息，没有充分利用不同的软件资源。尽管如此，大多数基于LLM的方法并未探索哪种类型的特定信息最有助于APR。
## Innovation
本文提出了DEVLoRe，该方法利用问题内容（描述和消息）和堆栈错误跟踪来定位错误的方法。随后，通过调试信息和问题内容及堆栈错误来定位错误的行并生成可能通过所有单元测试的补丁。研究表明，问题内容特别有效地帮助LLM进行故障定位和程序修复，不同类型的软件信息相互补充。通过整合多种信息，DEVLoRe成功找到49.3%和47.6%的单一和非单一错误方法，并生成了56.0%和14.5%可能通过单元测试的补丁，这在Defects4J v2.0数据集上优于当前最先进的APR方法。
## Conclusion
本研究展示了我们的框架在解决9个独特问题方面的有效性，在SWE-bench基准测试中与其他最先进的框架相比，使用相同的或更高级的模型有效。还讨论了Python代码的领先框架是否可以直接应用于Java代码，反之亦然。本文的所有源代码和实验结果可供复制使用。
# 646. `cs.SE` - 科学工作流系统开发中的实证研究 [PDF](https://arxiv.org/pdf/2411.10890), [HTML](https://arxiv.org/abs/2411.10890)
## Authors
Khairul Alam,Banani Roy,Chanchal K. Roy,Kartik Mittal
## Background
科学工作流系统（SWSs）是高级软件框架，通过协调复杂的计算任务和管理广泛的数据管道来推动现代研究。这些系统提供了模块化、抽象化、互操作性、工作流组合工具、资源管理、错误处理和全面文档等关键功能。利用这些框架可以加速科学计算的开发，从而提高研究结果的有效性和可重复性。然而，开发用户友好、高效且可适应的SWS也存在许多挑战。本研究通过深入分析Stack Overflow（SO）和GitHub上的交互来探讨这些挑战，这两个平台是开发人员和研究人员讨论和解决问题的重要平台。利用BERTopic进行主题建模，研究识别了开发者在SO上讨论的10个主题，如工作流创建和调度、数据结构和操作、工作流执行，并发现工作流执行最为困难。通过分析GitHub问题，识别了13个主题，如错误和修复、文档、依赖性，并发现数据结构和操作是最困难的主题。研究还发现SO和GitHub之间存在共同主题，如数据结构和操作、任务管理和工作流调度。同时，按类型（How、Why、What和其他）对每个主题进行了分类。观察到How类型始终主导所有主题，表明开发者需要过程性指导。How类型的主导也是在聊天机器人和移动开发等领域的常见现象。
## Innovation
研究通过分析开发者在Stack Overflow和GitHub上的讨论和问题，利用BERTopic进行了主题建模，识别出开发者讨论的关键主题和挑战，特别是工作流执行和数据结构与操作的难度，并将这些主题进行了分类，揭示了如何（How）类型的主导地位。这一方法为未来的SWS开发研究提出了工具和技术建议，有助于社区克服开发SWS时遇到的挑战。
## Conclusion
研究结果指出了科学工作流系统开发中的主要挑战，并通过如何（How）类型的主题类型趋势表明，开发者需要更多的过程性指导和支持。这些发现将指导未来研究，提出工具和技术帮助社区解决开发者在SWS开发过程中的难题。
# 647. `cs.SE` - 软件工程中的研究资料在辅助研究中的系统映射 [PDF](https://arxiv.org/pdf/2504.12646), [HTML](https://arxiv.org/abs/2504.12646)
## Authors
Aleksi Huotala,Miikka Kuutila,Mika Mäntylä
## Background
系统综述(SRs)总结了科学领域的最先进证据，包括软件工程(SE)。对537项于2013年至2023年间发布的辅助研究进行了检查，以分析研究资料的存在性和报告情况。结果显示，只有31.5%的研究纳入了研究资料，尽管从回归分析来看，研究资料的可用性随着时间的推移呈现显著增加的趋势，但在2023年，只有62.0%的辅助研究提供了研究资料，而仅30.4%的研究使用永久存储库并带有数字对象标识符(DOI)进行存储。这些数据表明，软件工程研究中的透明度和可重复性需要得到提升，建议所有辅助研究都必须强制性地发布研究资料以增强透明度和可重复性。
## Innovation
该项目针对软件工程领域的系统文献进行了研究，首次系统地梳理了辅助研究中研究资料的发布和报告情况，并且通过时间序列分析发现了研究资料可用性逐年增加的趋势，这是软件工程领域创新的一个具体体现。此外，研究中也指出了当前研究资料存储方式存在的问题，即永久存储库使用率不高的现状，这也是一个创新点。初步研究了使用DOI进行存储的需求，为今后改进研究资料存储方式提供了参考。
## Conclusion
为了提高软件工程研究的透明度和可重复性，我们建议所有辅助研究必须强制性地发布研究资料。
# 648. `cs.SE` - ReCode: 使用强化学习更新代码API知识 [PDF](https://arxiv.org/pdf/2506.20495), [HTML](https://arxiv.org/abs/2506.20495)
## Authors
Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang
## Background
大型语言模型（LLMs）展示出了显著的代码生成能力，但是在面对外部库API频繁更新时表现不佳。这一关键限制源于其训练数据依赖过时的API知识，即使有最新的文档可供参考，也无法在动态环境中可靠地生成代码。本文背景在于如何解决这一问题，提高LLMs在API频繁更新情况下的代码生成性能。
## Innovation
提出了一种名为ReCode的新颖框架，该框架模仿人类程序员对API变化的适应方式。具体来说，ReCode利用约2000条数据构建了一个训练集，训练LLMs根据更新的信息执行版本迁移。ReCode引入了一种修改后的字符串相似度度量方法，作为强化学习的奖励机制。实验结果显示，ReCode显著提升了LLMs在动态API场景下的代码生成性能，尤其是在未见任务CodeUpdateArena上的表现。同时，ReCode对LLMs的一般代码生成能力影响较小，并且在多个LLMs和强化学习算法上都显示出了稳定性能提升。
## Conclusion
ReCode框架通过强化学习方法，显著提升了LLMs在更新API场景下的代码生成性能，且较少影响其在其他任务中的通用性能。该研究在Qwen2.5-Coder-7B模型上取得了显著成果，证明了ReCode的有效性。相关代码可以在这里获取。
# 649. `cs.SE` - 揭开大型语言模型供应链组成、风险及缓解措施的面纱 [PDF](https://arxiv.org/pdf/2410.21218), [HTML](https://arxiv.org/abs/2410.21218)
## Authors
Kaifeng Huang,Bihuan Chen,You Lu,Susheng Wu,Dingji Wang,Yiheng Huang,Haowen Jiang,Zhuotong Zhou,Junming Cao,Xin Peng
## Background
大型语言模型（LLMs）在智能和生产效率方面产生了重大影响，许多企业将其整合到应用中以解决特定领域的任务。但将LLMs整合到特定场景中是一个系统性过程，包括多个组成部分，统称为LLM供应链。现有文献虽然已经探讨了与LLMs相关的各种风险，但仍然缺乏从供应者和消费者双重视角系统地描述LLM供应链的研究。已有研究未能全面理解供应链组件及其之间的关系，这对于有效地缓解不同相关风险是至关重要的。
## Innovation
本文构建了一个结构化的分类框架，涵盖了不同供应链参与者和组件的风险类型、风险行为及相应的缓解措施。这个分类框架是从供应者和消费者双重视角系统地描述LLM供应链的首次尝试，填补了现有研究的空白。
## Conclusion
全面审查LLM供应链的组成部分及其固有风险和缓解措施，将有助于业界从业者避免潜在的损害和损失，并给学术研究人员带来启发，促进他们重新思考现有方法并探索新的研究领域。
# 650. `cs.SE` - 带有SLA保证的CodeLLM服务中的自适应请求调度 [PDF](https://arxiv.org/pdf/2506.19677), [HTML](https://arxiv.org/abs/2506.19677)
## Authors
Shi Chang,Boyuan Chen,Kishanthan Thangarajah,Hanan Lutfiyya,Ahmed E. Hassan
## Background
代码大型语言模型（CodeLLMs）越来越多地融入现代软件开发流程中，但在资源受限、自主托管的环境中高效提供服务仍是一个重大挑战。现有的LLM服务系统使用连续批处理来提高吞吐量，但它们依赖于静态批次大小配置，无法适应波动的请求率或异构负载，导致频繁违反SLA（服务水平协议）并产生不稳定性能。
## Innovation
我们提出了SABER，一种预测每个请求的SLA可行性并在实时调整决策的动态批处理策略。与最佳静态配置相比，SABER将好吞吐量提高了26%，将延迟变异降低了45%。所有这些改进都不需要手动调优或服务重启。我们的结果表明，SLA意识的自适应调度是实现稳健、高性能的CodeLLM服务的关键。
## Conclusion
我们的研究表明，带有SLA保证的自适应调度策略对于实现CodeLLM服务的可靠性和高性能至关重要。
# 651. `cs.SE` - MARCO：借助实时知识集成的多代理代码优化方法以应对高性能计算 [PDF](https://arxiv.org/pdf/2505.03906), [HTML](https://arxiv.org/abs/2505.03906)
## Authors
Asif Rahman,Veljko Cvetkovic,Kathleen Reece,Aidan Walters,Yasir Hassan,Aneesh Tummeti,Bryan Torres,Denise Cooney,Margaret Ellis,Dimitrios S. Nikolopoulos
## Background
大型语言模型（LLMs）在软件开发方面通过代码生成功能取得了革命性的进步，但在高性能计算（HPC）领域，其效果仍然受到限制。HPC代码需要专门针对并行性、内存效率和架构特定考虑的优化，而通用的LLMs通常会忽略这些特定需求。因此，尽管LLMs能生成高质量的代码，但在HPC领域的应用仍面临挑战。
## Innovation
MARCO是一个新颖的框架，它通过特殊设计的多代理架构来提升LLM生成的HPC代码。MARCO包含一个为LLM生成代码和性能评估的独立代理，并通过反馈循环逐步优化代码。其关键创新在于具备实时知识集成功能的网络搜索组件，该组件能够从最近的会议论文和研究文献中检索到优化技术，填补预训练LLMs的知识空白。MARCO在LeetCode 75问题集中的广泛评估表明，相较于仅使用Claude 3.5 Sonnet，它平均能够减少14.6%的运行时间。进一步集成网络搜索组件则可提高30.9%的性能，这证明了多代理系统在高性能代码生成中的潜力，可作为针对特定领域的模型微调的经济高效替代方案。
## Conclusion
实验证明，MARCO体系结构对于应对高性能计算中所需的专业代码优化需求具有显著优势，能够有效减少代码运行时间，提升系统性能。这项工作为未来利用多代理系统进行高性能代码优化提供了新思路。
