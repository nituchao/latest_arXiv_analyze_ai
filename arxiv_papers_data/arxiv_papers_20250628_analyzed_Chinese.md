# 20250628
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 全球AI安全研究优先事项的新加坡共识 [PDF](https://arxiv.org/pdf/2506.20702), [HTML](https://arxiv.org/abs/2506.20702)
### Authors
Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić
### Background
随着AI能力与自主性的迅速提升，虽然带来了巨大的变革潜力，但也引发了关于如何确保AI安全的重要讨论。确保AI安全，即信任、可靠和安全，构建一个可信赖的生态系统变得至关重要。这有助于人们信心满满地拥抱AI，并为创新留出空间，避免出现反噬效应。为此，新加坡举办了2025年国际AI安全会议，汇集来自不同地区的AI科学家，共同确定和总结AI安全领域的研究优先级。根据该报告的组织模型，AI安全研究领域被分为三项挑战：创造可信AI系统的挑战（开发）、评估其风险的挑战（评估）以及在部署后进行监控和干预的挑战（控制）。
### Innovation
该报告采用了多层次防御模型，将AI安全研究领域划分为三个类型，分别为：开发可信AI系统的挑战、评估其风险的挑战以及在部署后进行监控和干预的挑战。这一创新分类有助于更加系统地管理AI安全问题，推进学术界、政府和行业之间的合作。报告基于柳晓光主席和33个国家的支持，国际AI安全报告，进一步巩固了研究共识。
### Conclusion
报告强调了构建可信赖AI生态系统的重要性，这不仅有助于人们有信心地接受AI，同时也为创新提供了空间，同时避免了反噬效应。该总结报告建立了全球视角下的AI安全研究优先事项，促进了学术界与政府、行业的合作与共识，推进AI的健康发展。
## 2. `cs.AI` - 揭示大型语言模型中的因果推理：幻觉还是现实？ [PDF](https://arxiv.org/pdf/2506.21215), [HTML](https://arxiv.org/abs/2506.21215)
### Authors
Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han
### Background
因果推理能力对于推动大型语言模型（LLMs）向强人工智能发展至关重要。尽管多用途的LLMs似乎展示了理解上下文因果关系和提供符合因果定律响应的能力，但是它们是否进行了类似人类的真正因果推理仍然存在疑问。当前的证据表明，LLMs仅能够进行浅层次（第一级）因果推理，并且主要依赖于嵌入在其参数中的因果知识。它们缺乏真正的人类级（第二级）因果推理的能力。研究者通过深入探讨基于Transformer的LLMs的自回归机制，发现这种机制本身不具备因果性。并通过引入一个新的因果问答基准测试（CausalProbe-2024），进一步验证了LLMs在该基准上的表现与早期基准相比显著下降，证明了它们主要进行的是第一级因果推理。这对促进LLMs进行真正意义上的因果推理能力和实现高级因果推理提出了挑战。
### Innovation
本文提出了一种新的方法G^2-Reasoner，这种方法结合了通用知识和目标导向提示，旨在改进LLMs的因果推理能力。实验表明，这种新方法显著提高了LLMs在新鲜和反事实情景中的因果推理能力。这项工作为LLMs迈向真正的因果推理能力提供了一条新的途径，超越了第一级因果推理，朝着第二级目标迈进。
### Conclusion
本文揭示了当前的大规模语言模型在因果推理方面的限制和不足，开发了一种增强因果推理的新方法G^2-Reasoner，并证明其能有效提升LLMs在新情景中的因果推理能力。这为未来研究提供了新方向，推动LLMs迈向真正的人类级因果推理能力。
## 3. `cs.AI` - MAGPIE：多智能体上下文隐私评估的数据集 [PDF](https://arxiv.org/pdf/2506.20737), [HTML](https://arxiv.org/abs/2506.20737)
### Authors
Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang
### Background
语言模型（LLM）驱动的代理正在被广泛部署，用于执行调度、谈判、资源分配等任务。然而，在这些系统中，隐私保护至关重要，因为代理通常需要访问专有的工具和领域特定的数据库，这要求极高的机密性。现有对LLM代理隐私保护能力的评估基准主要集中在单轮低复杂度任务上，这些任务可以通过排除敏感信息来进行测试。作者注意到这些基准难以评估复杂的多轮对话过程中代理对上下文敏感信息的理解和处理能力。因此，他们构建了一个包含158个涉及15个不同领域的高风险情境的评估框架，这些情境设计中既无法完全排除敏感信息也不能随意共享信息，以模拟更复杂的真实场景。
### Innovation
作者首次提出了一个名为MAGPIE的基准评估数据集，包含大量复杂的真实场景。与现有技术不同，MAGPIE不仅评估代理对上下文敏感信息的理解能力，还评估代理在多轮对话中如何在用户隐私受到明显保护的情况下进行协作。实验结果显示，目前的模型在全球顶尖的GPT-4o和Claude-2.7-Sonnet中，对上下文敏感信息的理解存在较大偏差，在多轮对话中即便在明确隐私指示的情况下也会泄露敏感信息。另外，多智能体系统在71%的高危情境下无法完成任务。这表明当前技术在上下文隐私保护和协作任务解决方面存在局限性。
### Conclusion
当前的模型在上下文隐私保护方面并不理想，对于复杂的多轮对话和协作任务也缺乏可靠的支持。MAGPIE数据集的引入旨在填补这一评估缺口，并强调目前的模型还需要在这些方面进行改进。
## 4. `cs.AI` - 世界意识规划叙事增强大型视觉语言模型规划者 [PDF](https://arxiv.org/pdf/2506.21230), [HTML](https://arxiv.org/abs/2506.21230)
### Authors
Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu
### Background
大型视觉语言模型（LVLMs）在执行体会式规划任务方面表现出潜力，但在涉及不熟悉环境和多步骤目标的复杂场景中存在困难。目前的方法依赖于与环境无关的模仿学习，这种方法会断开指令与环境上下文之间的联系，导致模型在处理上下文敏感的指令时表现不佳，需要依赖额外提示而非视觉推理来进行长时交互。
### Innovation
提出了World-Aware Planning Narrative Enhancement (WAP)框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和句法接地），在仅使用原始视觉观察并通过课程学习开发和评估模型的过程中，使LVLMs获得全面的环境理解。这种方法在EB-ALFRED基准测试中表现出显著改进，Qwen2.5-VL在任务成功率方面提高了60.7%，特别是在常识推理方面提高了60.0%，在长时规划方面提高了70.0%。此外，我们的增强模型的开源版本在EB-ALFRED基准测试中的表现优于GPT-4o和Claude-3.5-Sonnet等专有系统的大规模优势。
### Conclusion
WAP框架通过嵌入LVLMs所需的认知能力，显著提高了它们在各种复杂规划任务中的表现，并且开源的WAP模型在EB-ALFRED基准测试中也表现优异，超越了商业模型。
## 5. `cs.AI` - 领域特定AI应用的动态上下文感知提示推荐 [PDF](https://arxiv.org/pdf/2506.20815), [HTML](https://arxiv.org/abs/2506.20815)
### Authors
Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy
### Background
LLM（大型语言模型）驱动的应用高度依赖于用户提示的质量，而制作高质量的提示对用户来说常常具有挑战性，特别是在特定领域应用中。本文背景讨论了提示质量的重要性以及在特定领域应用中制作高质量提示的难度。
### Innovation
本文提出了一个新颖的动态上下文感知提示推荐系统，该系统结合了上下文查询分析、检索增强的知识接地、层次化的技能组织以及适应性的技能排名，以生成相关的、可操作的提示建议。系统利用行为遥测和两阶段的层次推理过程动态选择和排序相关技能，并使用预定义和适应性的模板结合少量样本学习来综合生成提示。实验结果表明，该方法通过自动评估和专家评估验证，实现了高实用性和相关性，显著提高了特定领域AI应用中的信息呈现质量。
### Conclusion
实验证明，本文提出的方法在实际数据集上有效地实现了高质量的提示推荐，通过自动化和专家评估的方法得到了验证，证明了系统的有效性。
## 6. `cs.AI` - 主动推断AI系统用于科学发现 [PDF](https://arxiv.org/pdf/2506.21329), [HTML](https://arxiv.org/abs/2506.21329)
### Authors
Karthik Duraisamy
### Background
人工智能的快速发展带来了对科学发现转型的期望，但当前系统仍受限于其操作架构、脆弱的推理机制以及与实验现实的分离。因此，科学推理需要内部表示法支持行动和响应的模拟，因果结构区分相关性和机制，以及持续校准。
### Innovation
该研究提出，为推动AI驱动的科学进步，需要关闭三个基本差距——抽象差距、推理差距和现实差距，而不是依赖模型规模、数据或测试时间计算。定义了基于主动推断的AI系统用于科学发现，这些系统包括维护因果自监督基础模型支撑的长期研究记忆，配备贝叶斯防护栏的符号或神经-符号计划者，建立持久的知识图谱，通过与高保真模拟器和自动化实验室的闭环互动改进内部表示法，使发现起源于内部模型使能的反事实推理和外部验证使假说基于现实的交互作用。同时，强调了从实验和模拟反馈中固有的模糊性和潜在不确定性，人类判断的重要性不仅仅作为临时支架，而是作为永久的建筑构件。
### Conclusion
主动推断AI系统是通过内部模型支持反事实推理并结合外部验证，将假设扎根于现实，从而实现科学发现的架构。
## 7. `cs.AI` - TableMoE: 神经符号路由在多模态表格理解中的结构专家推理 [PDF](https://arxiv.org/pdf/2506.21393), [HTML](https://arxiv.org/abs/2506.21393)
### Authors
Junwen Zhang,Pu Chen,Yin Zhang
### Background
在实际使用中解析表格是一项具有挑战性的任务，因为表格结构复杂、符号密集且图像质量不佳（例如模糊、倾斜、水印、结构或字体不完整、多行或分层嵌套布局）。现有的多模态大语言模型（MLLMs）在这种困难的多模态结构（WildStruct）条件下表现不佳，导致性能有限且泛化能力差。因此，需要一种专门设计来应对这些挑战的方法，以实现多模态表格数据的稳健结构推理。
### Innovation
TableMoE 提出了一种神经符号连接专家混合架构（MoCE），并引入了一种创新的神经符号路由机制，该机制预测潜在的语义标记角色（如表头、数据单元格、轴、公式），并根据符号推理图的置信度感知门控策略动态路由表元素到专业专家（Table-to-HTML, Table-to-JSON, Table-to-Code）。此外，通过大尺度的 TableMoE-Align 数据集进行有效的预训练，并提出了四种挑战性的 WildStruct 基准测试，以精确评估模型在实际多模态降解和结构复杂度下的性能。研究表明，TableMoE 显着优于现有最先进模型，并且实验证明每个核心组件的重要性，尤其是神经符号路由和结构化专家对齐。
### Conclusion
通过定性的分析，进一步展示了 TableMoE 的可解释性和增强的鲁棒性，突显了集成神经符号推理在多模态表格理解中的有效性。
## 8. `cs.AI` - 从有限视角进行空间心智建模 [PDF](https://arxiv.org/pdf/2506.21458), [HTML](https://arxiv.org/abs/2506.21458)
### Authors
Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei
### Background
人类能够利用有限视角构建空间心智模型，形成内部对未见空间的表征，用于推理布局、视角和运动。现有视觉语言模型（VLMs）在MindCube基准测试上的表现几乎随机，暴露了这一关键差距。MindCube基准测试包括21,154个问题和3,268张图像，用于评估VLMs在构建稳健的空间心智模型方面的表现，包括表示位置（认知制图）、方向（视角推理）和动态（心理模拟）等能力。
### Innovation
本文提出了一种新的名为MindCube的基准测试，填补了现有VLMs在空间心智建模能力上的空缺。通过引入诸如未见中的中期视角、自然语言推理链和认知地图等三种方法，VLMs能够更好地构建空间心智模型。特别是“制图-推理”策略，通过先生成认知地图，再在这之上推理，显著提升了准确性（从37.8%提升到60.8%，增加23.0%），进一步通过强化学习提升到70.7%（增加32.9%）。这表明，通过主动性构建和利用内部结构化空间表征，并灵活地进行推理过程，能够显著提高对不可观察空间的理解能力。
### Conclusion
通过MindCube测试，本文展示了现有VLMs的空间心智建模能力的局限性，并提出了一种新的方法，即“制图-推理”策略，通过神经网络训练学会了构建认知地图，并在这些内部地图的基础上进行推理，最终显著提升了对空间心智模型的构建。强化学习的引入进一步提升了性能，表明这种构建和利用内部结构化空间表征并进行灵活推理的方法对理解不可观察空间有重要影响。
## 9. `cs.AI` - 超越反应式安全：基于长期模拟的风险感知大语言模型对齐 [PDF](https://arxiv.org/pdf/2506.20949), [HTML](https://arxiv.org/abs/2506.20949)
### Authors
Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji
### Background
论文背景在于随着基于语言模型代理在高风险社会决策中的影响不断增加，例如公共政策和医疗保健领域，确保这些代理产生的建议是积极影响社会的至关重要。这需要理解这些建议对社会系统的广泛影响。研究者们提出了一种原型框架，该框架能够模拟模型生成的建议如何在长时间尺度上通过社会系统传播，从而增强长期对齐的稳健性。同时，该研究通过构建一个包含100种间接危害情景的数据集来评估语言模型的长期安全性意识，测试其对看似无害用户提示可能发生不利非显性后果的预见能力，验证了这一方法的有效性。
### Innovation
研究的创新点在于提出了一种基于长期模拟的原型框架，通过该框架可以预测模型生成的建议如何在长时间尺度上影响社会系统，并引入了包含100种间接危害情境的数据集。该方法不仅在新数据集上的性能提高了超过20%，而且在现有安全基准测试中表现优异，具有超过70%的胜率，这些结果表明了为更安全的代理提供了新的前景。
### Conclusion
该框架结合了宏观传播模拟与长期风险评估，不仅显著提升了语言模型的预见能力，还展示了其在现有安全基准测试中的优越性能，为设计更安全的代理系统提供了有希望的新方向。
## 10. `cs.AI` - Ad-Hoc Human-AI Coordination Challenge [PDF](https://arxiv.org/pdf/2506.21490), [HTML](https://arxiv.org/abs/2506.21490)
### Authors
Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster
### Background
在现实世界的应用中，实现人工智能代理与人类之间的无缝协调是非常关键的，但这一目标仍然是一个重要但尚未解决的挑战。Hanabi是一种具有不完美信息、约束通信、心理理论要求以及协调行动特点的合作纸牌游戏，这使它成为人类与AI协调的理想测试平台。然而，由于人类评估的高成本和难以复现性，Hanabi在人类与AI互动方面的应用受到限制。
### Innovation
本文作者提出了Ad-Hoc Human-AI Coordination Challenge (AH2AC2)挑战，以解决昂贵且难以重现的人类评估的限制。此外，作者开发了大规模的人类数据代理小工具，这些工具在AH2AC2中充当了坚强、低成本且可重复的人类评估伙伴。为了鼓励数据高效方法的开发，作者还开放了一个包括3,079场比赛的游戏数据集，故意限制可用的人类游戏数据量。作者还建立了代理小工具的受控评估系统，以确保公平评估，同时未将代理小工具公开释放。
### Conclusion
作者研究了单人和三人汉诺伊场景的基线结果，并将代码发布在指定链接中以便进一步研究。
## 11. `cs.AI` - Mind2Web 2: 使用代理作为评判者评估自主搜索引擎 [PDF](https://arxiv.org/pdf/2506.21506), [HTML](https://arxiv.org/abs/2506.21506)
### Authors
Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su
### Background
自主搜索引擎如深研系统，使大型语言模型自主浏览网络、综合信息并提供全面的引文支持答案，代表了用户与大规模网络信息交互方式的重大转变。然而，这种搜索方式日益增长的复杂性和开放性已经超过了现有的评估标准和方法，这些标准和方法主要假设短搜索窗口和静态答案。因此，亟需新的评估基准和方法来应对时间变化和复杂的回答挑战。
### Innovation
本研究推出了Mind2Web 2基准，包含130个具有高度现实性、高质量和长期视角的任务，这些任务要求实时网络浏览和大量信息综合，通过超过1000小时的人工劳动构建而成。为此，研究提出了一种新的“代理即评判者”框架，利用树结构评分表设计构建任务特定的评判代理，自动评估答案的正确性和来源归因。
### Conclusion
对九个前沿自主搜索引擎的全面评估结果显示，OpenAI深度研究系统已经实现了人类表现的50-70%，同时花费了一半的时间，展现了巨大的潜力。Mind2Web 2为开发和测试下一代自主搜索引擎提供了严格的框架基础。
## 12. `cs.AI` - PsyLite 技术报告 [PDF](https://arxiv.org/pdf/2506.21536), [HTML](https://arxiv.org/abs/2506.21536)
### Authors
Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang
### Background
随着数字技术的迅速发展，AI驱动的心理咨询服务逐渐成为心理健康研究领域的重要研究方向。然而，现有模型在对话安全性、详细场景处理和轻量级部署方面仍然存在不足。
### Innovation
为解决这些问题，研究提出了基于基模型InternLM2.5-7B-chat开发的轻量级心理咨询服务大语言模型代理PsyLite。通过两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），PsyLite增强了模型的深度推理能力、心理咨询服务能力和对话安全性。设计了一种创新的条件RAG，在适当时候引入跨话幽默元素，以提高用户体验并加强对话安全性。
### Conclusion
评估结果表明，PsyLite在中文通用评估（CEval）、心理咨询服务专业评估（CPsyCounE）和对话安全性评估（SafeDialBench）中均优于基线模型，特别是在心理咨询服务专业化（CPsyCounE得分提升47.6%）和对话安全性（safe{}得分提升2.4%）方面。此外，该模型采用量化技术（GGUF q4_k_m）实现低硬件部署（5GB内存即可运行），为资源受限环境中的心理咨询服务应用提供了可行解决方案。
## 13. `cs.AI` - IXAII：决策支持系统中的互动可解释人工智能界面 [PDF](https://arxiv.org/pdf/2506.21310), [HTML](https://arxiv.org/abs/2506.21310)
### Authors
Pauline Speckmann,Mario Nadj,Christian Janiesch
### Background
尽管已经开发了多种事后可解释AI方法，但大多数都是静态的，忽视了用户的视角，限制了其对目标受众的有效性。现有方法未能充分考虑到用户的实际需求和交互性，导致它们在促进透明度方面显得不足。
### Innovation
我们开发了一个名为IXAII的互动可解释智能系统，它结合了四种可解释AI方法（LIME、SHAP、Anchors、DiCE），并提供定制化的视图以适应五个不同的用户组。IXAII允许用户在内容和格式方面对解释进行个性化选择，增强了用户对解释过程的控制权。我们通过专家和普通用户进行的访谈评估了IXAII，结果显示该系统能有效提高透明度认知，并有助于填补可解释AI方法、互动性和实际应用之间的差距，为AI解释实践和人机交互提供了新的视角。
### Conclusion
IXAII通过多种可视化选项提供不同的解释，被认为有助于增强透明度，通过弥合可解释AI方法、互动性和实际实施之间的差距，它对AI解释实践和人机交互提供了新颖的视角。
## 14. `cs.AI` - ClusterRCA：使用多模态数据进行HPC系统的网络故障诊断 [PDF](https://arxiv.org/pdf/2506.20673), [HTML](https://arxiv.org/abs/2506.20673)
### Authors
Yongqian Sun,Xijie Pan,Xiao Xiong,Lei Tao,Jiaju Wang,Shenglin Zhang,Yuan Yuan,Yuqi Li,Kunlin Jian
### Background
高性能计算（HPC）系统的网络故障诊断具有挑战性但又至关重要。现有的方法由于数据异构性和准确性的缺乏，不能直接应用于HPC场景。
### Innovation
提出了一种名为ClusterRCA的新型框架，通过利用多模态数据，来定位故障节点和确定故障类型。ClusterRCA结合了基于分类器的方法和基于图的方法，通过构建故障图和进行定制化的随机游走，实现对故障根源的准确定位。实验结果表明，ClusterRCA在诊断HPC系统网络故障方面具有高精度，并保持了在不同应用场景中的稳健性能。
### Conclusion
ClusterRCA框架通过使用多模态数据有效地诊断HPC系统中的网络故障，实现了高精度和稳健性。
## 15. `cs.AI` - DRAGON: 分布式奖励优化扩散生成模型 [PDF](https://arxiv.org/pdf/2504.15217), [HTML](https://arxiv.org/abs/2504.15217)
### Authors
Yatong Bai,Jonah Casebeer,Somayeh Sojoudi,Nicholas J. Bryan
### Background
本文介绍了DRAGON（Distributional RewArds for Generative OptimizatioN）框架，这是一种灵活的调优媒体生成模型的方法，以实现特定结果。与传统的基于人类反馈强化学习（RLHF）或直接偏好优化（DPO）的对偏好进行直接优化的方法相比，DRAGON更具灵活性，可以优化个体样本或它们的分布的奖励函数。研究人员利用这一灵活性构建了新颖的奖励函数，通过选择编码器和一组参考示例来创建示例分布。
### Innovation
DRAGON提出了一个通用的框架，可以调优奖励函数，从而让媒体生成模型达到特定的结果。它与传统的基于人类反馈的强化学习方法或直接偏好优化方法相比，更具有灵活性，能够优化针对个体样本或样本分布的奖励函数。这种方法适用于广泛的实例级、实例到分布级和分布到分布级的奖励函数。此外，DRAGON使用在线和策略生成，通过对比正示例集合与负示例集合来最大化奖励。这种方法在音频领域文本到音乐扩散模型上进行了验证，并取得了显著的效果。在所有20个目标奖励中，DRAGON实现了81.45%的平均胜率。该方法还展示了基于示例集的奖励函数增强生成的质量，与基于模型的奖励函数相似。使用适当的示例集，DRAGON在无需训练人类偏好注解的情况下实现了60.95%的人类投票的音乐质量胜率。
### Conclusion
本文介绍的DRAGON框架提供了一种设计和优化用于提高人类感知质量的奖励函数的新方法，特别是在音频领域的文本到音乐生成方面。它展示了基于示例集的奖励函数的有效性，并提出了一种无需使用人类偏好注解即可提高生成音乐质量的方法。
## 16. `cs.AI` - 评价用于多尺度建模的偏微分方程发现方法 [PDF](https://arxiv.org/pdf/2506.20694), [HTML](https://arxiv.org/abs/2506.20694)
### Authors
Andréa Ducos(AISTROSIGHT),Audrey Denizot(AISTROSIGHT),Thomas Guyet(AISTROSIGHT),Hugues Berry(AISTROSIGHT)
### Background
生物系统是非线性的，包含未观察到的变量，并且无法完全了解控制它们动态的物理原理。这使得对其行为的描述极具挑战性。由于生物活动涉及多个相互依赖的空间和时间尺度，因此需要在不同尺度之间建立机制连接。为了解决跨越尺度的挑战，我们利用偏微分方程（PDE）发现技术。PDE发现能够从微观尺度数据推断中观尺度动力学特性。本文介绍了结合基于粒子的模拟和PDE发现的框架，并在受控环境中进行了初步实验以评估方程发现方法的性能。我们在星形胶质细胞中的钙扩散基于粒子的仿真中测试五种最先进的PDE发现方法，从发现方程的形式和预测的钙浓度时间变化两方面对其进行评估。结果显示，一些方法成功地恢复了扩散项，这突显了PDE发现方法在从微观尺度数据捕获生物系统宏观动态方面的潜力。
### Innovation
本文提出了一个结合基于粒子的模拟和PDE发现的框架，并在不同的PDE发现方法上进行了初步实验，以评估其性能。通过在基于粒子的星形胶质细胞中的钙扩散仿真中对五种最先进的PDE发现方法进行测试，展示了方法在恢复扩散项上的准确性和其在多尺度建模生物信号中的潜在价值。
### Conclusion
研究表明，不同方法能够较好地恢复扩散项，这表明PDE发现技术在从微观尺度数据捕捉生物系统中的宏观动态方面具有巨大潜力。
## 17. `cs.AI` - 渐进式大小自适应联邦学习：异构多模态数据系统的全面框架 [PDF](https://arxiv.org/pdf/2506.20685), [HTML](https://arxiv.org/abs/2506.20685)
### Authors
Sajid Hussain,Muhammad Sohail,Nauman Ali Khan,Naima Iltaf,Ihtesham ul Islam
### Background
联邦学习（FL）作为一种保持数据隐私的分布式机器学习模式已经出现。现有方法主要集中在模型异构性和聚合技术上，而忽视了数据集大小特征对联邦学习动态的深刻影响。这项研究基于数据集大小特征，为异构多模态数据系统设计了一种新型渐进而又适应大小的联邦学习框架（SAFL）.
### Innovation
首次在联邦学习框架中引入了基于数据集大小特征的系统化组织方法。通过13个涵盖7种模式（视觉、文本、时间序列、音频、传感器、医疗视觉、多模态）的数据集的全面实验评估揭示了重要发现：1）联邦学习效果的最佳数据集大小范围是1000-1500个样本；2）结构化数据在多模态数据中表现出显著优势；3）超过2000个样本的数据集性能呈现系统性下降。SAFL框架实现了所有数据集的平均准确率为87.68%，结构化数据模态达到99%以上的准确率。该框架展示了卓越的通信效率，减少总数据传输至7.38 GB，同时保持高性能。实时监控框架提供了前所未有的系统资源利用率、网络效率和训练动态洞察.
### Conclusion
这项研究填补了数据特征如何驱动联邦学习策略理解的关键空白，提供了理论洞察和现实联邦学习部署在神经网络和学习系统中的实用指导。
## 18. `cs.AI` - CBF-AFA: 基于块的多SSL融合自动流畅性评估 [PDF](https://arxiv.org/pdf/2506.20243), [HTML](https://arxiv.org/abs/2506.20243)
### Authors
Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc
### Background
自动流畅性评估（AFA）仍然是一个挑战，特别是在捕捉非母语者的语音节奏、停顿和语不畅方面。现有的技术在处理这些问题时存在困难，因此需要新的方法来改进性能，特别是在非母语者的语音特征检测上。
### Innovation
本文引入了一种基于块的方法，结合了具有互补优势的自监督学习（SSL）模型（Wav2Vec2、HuBERT和WavLM），并通过层次化的CNN-BiLSTM框架融合这些模型的嵌入。进一步地，语音通过Silero语音活动检测（Silero-VAD）分割成呼吸组块，消除了过度分割的不足。融合机制结合了可学习的加权方法，平衡了声学和语言特征。此外，还加入了块级别的流畅性标记以丰富嵌入信息，以期提高模型对语音流畅性的识别能力。相较于单个SSL基线在Speechocean762数据集上的表现，该方法在F1分数和皮尔森相关系数上分别取得了2.8和6.2的提升，表现出色。
### Conclusion
该研究提出了基于块的多SSL融合方法，显著提高了自动流畅性评估的性能，特别是在处理非母语者的语音数据时效果更佳。研究结果表明，此方法在评估非母语者语音流畅性方面非常有效，但在将来的研究中仍需进一步探索其在不同方言识别上的一般化能力。
## 19. `cs.AI` - 基于效用驱动的Mixture-of-Experts推测性解码 [PDF](https://arxiv.org/pdf/2506.20675), [HTML](https://arxiv.org/abs/2506.20675)
### Authors
Anish Saxena,Po-An Tsai,Hritvik Taneja,Aamer Jaleel,Moinuddin Qureshi
### Background
低延迟大型语言模型（LLM）推理的主要瓶颈是GPU内存带宽。推测性解码通过使用轻量级的先行者来提议K个令牌，这些令牌由LLM并行验证，从而提高令牌吞吐量。传统密集型LLM中，每次迭代都会加载所有模型权重，所以推测性解码不会增加延迟开销。但是，新兴的混合专家（MoE）模型每次只激活一小部分权重，极大地减少了数据移动。然而，研究发现MoE模型中推测性解码是无效的，因为它会使数据移动和验证时间增加2-3倍。当令牌吞吐量增益不能抵消这些开销时，推测性解码会导致高达1.5倍的性能下降，从而不可行。即使在某些情况下推测性解码是有用的，最佳K值依赖于任务、模型以及请求和迭代的不同而变化。因此，尽管推测性解码在密集型LLM中被广泛使用，但在主要的MoE模型中仍是不实用的。
### Innovation
提出了一种效用驱动框架（Cascade），该框架可以根据需要选择性地启用推测性解码并动态调整K值以加速MoE服务。Cascade利用一种轻量级的效用指标，即令牌增益与验证成本的比率，显示迭代级别的局部性，从而通过短测试周期和较长设置周期进行定期决策。对于每个请求，如果测试过程中效用低于1，则禁用推测性解码，当效用超过1时，多次测试不同的K值以选择最大化效用的K值设置阶段。已经在vLLM中实现Cascade，并在五个流行MoE模型上进行评估，这些模型的工作负载覆盖了代码、数学、抽取和混合任务。结果表明，Cascade将性能下降限制在5%（相对于1.5倍）以内，相比固定K值，吞吐量提高了7-14%，使推测性解码在MoE中变得实用.
### Conclusion
除了在密集型LLM中广泛使用推测性解码之外，在主要的MoE模型中它是不可行的。提出的一种效用驱动框架(Cascade)可以避免推测性解码带来的性能下降，并动态调整K值以加速MoE服务，使得推测性解码在MoE中变得实用。
## 20. `cs.AI` - Diffusion Tree Sampling: 规模化的扩散模型推理时开端齐 [PDF](https://arxiv.org/pdf/2506.20701), [HTML](https://arxiv.org/abs/2506.20701)
### Authors
Vineet Jain,Kusha Sareen,Mohammad Pedramfar,Siamak Ravanbakhsh
### Background
在生成建模中，推理时将预训练的扩散模型适应新的目标仍然是一个开放问题。现有的引导方法在高噪声级别下会遭受不准确的值估计问题，从而导致偏见的指导。此外，过去运行的信息没有被重用以提高样本质量，导致计算资源的低效利用。受蒙特卡洛树搜索成功的启发，我们通过将推理时的对齐问题视为一个重新利用先前计算的搜索问题来解决这些局限性。
### Innovation
我们引入了一种基于树的方法，通过在扩散链中反向传播终端奖励并逐步改进价值估计来从奖励对齐的目标密度中抽样。我们提出的方法Diffusion Tree Sampling (DTS) 在无限滚动的情况下产生与目标分布一致的样本，并且其贪婪变体Diffusion Tree Search (DTS$^text{textasciicircumtextbackslash star}$) 能够在全球范围内搜索高奖励样本。在MNIST和CIFAR-10分类生成中，DTS 的计算量最多减少10倍，能够达到最优基线的FID。在文本到图像生成和语言补全任务中，DTS$^text{textasciicircumtextbackslash star}$ 通过搜索高奖励样本最多减少5倍的计算量来匹配最佳样本。通过在每次生成中重用之前生成的信息，我们获得了一种可随时等候的算法，随着计算资源的增加，样本质量稳步提升，提供了扩散模型推理时对齐的一种可扩展方法。
### Conclusion
Diffusion Tree Sampling 和其贪婪变体 Diffusion Tree Search 提供了一种高效且可扩展的方式来在扩散模型的推理时进行目标对齐。这两种方法都利用了过去产生的信息，使得更多的计算可以转化为质量更好的样本，为生成建模领域提供了一种新的思路。
## 21. `cs.AI` - 敏捷管理在机器学习中的应用：一项系统综述研究 [PDF](https://arxiv.org/pdf/2506.20759), [HTML](https://arxiv.org/abs/2506.20759)
### Authors
Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski
### Background
机器学习（ML）驱动的社会数字化转型中，敏捷方法由于其灵活性和迭代交付特性，似乎适用于应对ML开发中的动态挑战。然而，如何将这些方法应用于ML系统管理仍不明确，需要定制化的方法来解决由此产生的特定问题和挑战。
### Innovation
通过系统映射研究，识别了从2008年至2024年间出版的27篇相关论文，发现了8个方法框架，并将推荐和实践归类为8个主要主题，如迭代灵活性、创新的ML特定工具等。研究指出准确估计与ML相关的任务所需努力的主要挑战，并贡献了对该领域的现状图景和空白的研究。
### Conclusion
该研究通过映射现状并识别领域空白，为未来的实证研究提供了方向。
## 22. `cs.AI` - 心脏MRI和ECG联合表示的全局和局部对比学习 [PDF](https://arxiv.org/pdf/2506.20683), [HTML](https://arxiv.org/abs/2506.20683)
### Authors
Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert
### Background
心电图(ECG)是一种广泛应用且成本低廉的心脏电活动检查工具，但无法直接测量心脏功能参数，如心室容积和射血分数。心脏磁共振成像(CMR)是测量这些功能参数的标准方法，能提供详细的心肌结构和功能信息，但成本高且获取相对困难。本文旨在通过提出一种结合心脏MRI和ECG信息的方法来弥补这一差距，从而改善非侵入性心脏诊断。
### Innovation
本文提出了一种名为PTACL（Patient and Temporal Alignment Contrastive Learning）的多模态对比学习框架，通过集成心脏MRI的时空信息来增强ECG表示。该框架包含全局患者级别对比损失和局部时间级别对比损失。全局损失通过拉近同一患者的心电图和磁共振成像的嵌入表示，同时将不同患者的嵌入表示推开，实现患者级别的表示对齐；局部损失在每个患者级别上强制进行细致的时间对齐，通过对比编码的心电图片段与相应的编码磁共振影像帧来实现。这种方法能够丰富心电图的诊断信息，使模态间的转移学习更加深刻，而不增加新的可学习权重。评估结果表明，相较于基础方法，PTACL在临床相关任务上表现更好，包括相似心脏表型的患者检索以及预测由CMR获得的心脏功能参数如心室容积和射血分数。
### Conclusion
本研究采用PTACL框架增强了ECG表示，并通过心脏MRI和ECG数据的对比学习丰富了诊断信息，显著提升了非侵入性心脏诊断的性能。相关代码可在指定网址获取。
## 23. `cs.AI` - 关于卷积、固有维数和扩散模型 [PDF](https://arxiv.org/pdf/2506.20705), [HTML](https://arxiv.org/abs/2506.20705)
### Authors
Kin Kwan Leung,Rasa Hosseinzadeh,Gabriel Loaiza-Ganem
### Background
高维空间中的数据（如图像数据）被认为分布在未知的低维流形上。扩散模型（DMs）通过逐步添加高斯噪声并学习反向过程，已成为表现最好的生成模型，且已知能够学习具有低维支撑的分布。在流形上的给定点，理论上应假设扩散模型已隐式地学习该点对应的局部固有维数（LID），即其所属流形的维数。Kamkari等人（2024b）曾通过将LID与扩散模型的对数边缘密度相对于添加噪声量的变化率联系起来，提出了FLIPD估计器，证明了这一假设。FLIPD在固有维数估计方面表现出色，但其理论基础不完善，因为Kamkari等人只在高度不现实的仿射流形的假设下证明了其正确性。本研究旨在填补这一缺口，通过在更现实的假设下证明FLIPD的正确性。此外，当高斯卷积被替换为均匀卷积时，我们还展示了类似的结果，并讨论了这一结果的相关性。
### Innovation
论文正式证明了FLIPD在更现实假设下的正确性，还讨论了当使用均匀卷积而非高斯卷积时类似结论的成立，从而填补了该领域的理论空白，并扩大了FLIPD应用的范围。
### Conclusion
本研究通过在现实假设下证明了FLIPD的正确性，解决了之前的理论缺陷，并展示了在不同类型的卷积情况下FLIPD的有效性，为理解扩散模型的固有维数学习提供了更坚实的理论基础。
## 24. `cs.AI` - 探讨聊天机器人的拟人化和人类同理心对其助人行为的影响 [PDF](https://arxiv.org/pdf/2506.20748), [HTML](https://arxiv.org/abs/2506.20748)
### Authors
Jingshu Li,Zicheng Zhu,Renwen Zhang,Yi-Chieh Lee
### Background
聊天机器人逐渐融入人们的生活，并被广泛用于帮助人们。最近，人们也开始对另一种方向产生兴趣——人类帮助聊天机器人，这得益于多种好处，包括提高聊天机器人的性能、改善人类福祉以及协作成果。然而，很少有研究探索人们帮助聊天机器人的动机。为了弥补这一空白，本文基于计算机是社会演员（CASA）的框架，研究聊天机器人的拟人化，包括人类身份、情感表现和非言语表现，如何影响人们对聊天机器人的同理心及其后续的助人行为和意图。我们还探讨了参与者对自己助人行为的解释。我们通过一项在线实验（n=244）研究聊天机器人在协作图像标注任务中犯错误并向参与者解释原因后，参与者对聊天机器人的助人行为和意图。我们的研究表明，聊天机器人的拟人化，尤其是其人类身份和情感表达，能够增加参与者的助人行为和意愿，同理心在其中起中介作用。质性分析进一步发现参与者助人行为的两个动机：对机器人的同理和支持其拟人化的观点。
### Innovation
文章基于计算机是社会演员（CASA）的框架，研究聊天机器人的拟人化如何影响人们对聊天机器人的同理心、助人行为和意愿。通过对参与者的助人行为进行量化和质性分析，揭示了参与者助人行为的动机，并讨论了这些结果对于理解和支持人类对聊天机器人的助人行为的意义。
### Conclusion
研究发现，聊天机器人的拟人化特征，特别是其人类身份和情感表达，会增强参与者对其的助人行为和意愿，且这种助人行为与同理心有关。质性研究进一步指出两个动机：对聊天机器人的同理心与将其视作人类的表现。研究结果对于理解并促进人类对聊天机器人的助人行为具有重要意义。
## 25. `cs.AI` - U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs [PDF](https://arxiv.org/pdf/2506.20689), [HTML](https://arxiv.org/abs/2506.20689)
### Authors
Racheal Mukisa,Arvind K. Bansal
### Background
人工智能够，在心脏疾病诊断和管理的自动化医学图像分析中，将扮演变革性角色。准确地分割心脏影像作为心脏疾病量化和自动化诊断的第一步是至关重要的。因此，本文提出了一种基于深度学习增强的UNet模型，U-R-Veda，该模型结合了卷积变换、视觉变换器、残差连接、通道注意和空间关注，以及基于边缘检测的跳连结，以实现心脏磁共振（CMR）图像的准确全自动语义分割。
### Innovation
该研究创新性地提出的U-R-Veda模型通过结合多种先进技术和架构，显著提高了CMR图像的语义分割性能。具体创新包括：1) 综合了卷积变换、视觉变换器、残差连接、通道注意和空间关注等技术；2) 提出了嵌入通道和空间注意机制的卷积块，以识别重要特征及其空间定位；3) 利用边缘信息与通道和空间注意相结合的跳连结构，减少卷积变换期间的信息损失；4) 设计了一种双注意模块（通道和空间注意）的算法。
### Conclusion
研究表明，U-R-Veda模型基于DSC指标实现了95.2%的平均准确率，并且在心脏右心室和左心室心肌的轮廓化方面表现尤为出色，优于其他基于DSC和HD指标的模型。模型的整体改进显著提高了医学影像分析的质量。
## 26. `cs.AI` - IMC-PINN-FE：一种具有图像运动一致性及生物力学参数估计的物理感知神经网络，用于患者特异性左心室有限元建模 [PDF](https://arxiv.org/pdf/2506.20696), [HTML](https://arxiv.org/abs/2506.20696)
### Authors
Siyu Mu,Wei Xuan Chan,Choon Hwai Yap
### Background
阐明心肌的生物力学行为对于理解心脏生理至关重要，但不能直接从临床成像中推断出来，通常需要进行有限元(FE)仿真。然而，传统FE方法计算成本高，并且经常不能再现观察到的心脏运动。IMC-PINN-FE物理感知神经网络框架结合了成像运动一致性(IMC)与FE建模，用于患者特异性左心室(LV)生物力学。
### Innovation
IMC-PINN-FE通过引入材料属性的反向计算和更好的运动保真度，超越了先前的PINN-FE模型。使用单一受试者的运动重建形模态，避免了需要大型数据集，并提升了患者的特异性。IMC-PINN-FE大大加速了计算，缩短了从小时到秒级别，同时保持了现实的压力-体积行为，从而提高了商及一致性 Dice 平均分数。
### Conclusion
IMC-PINN-FE为快速、个性化、图像一致性心脏生物力学建模提供了一种稳健且高效的方法。
## 27. `cs.AI` - 测试时缩放技术在理论物理中的应用——TPBench数据集上方法的比较 [PDF](https://arxiv.org/pdf/2506.20729), [HTML](https://arxiv.org/abs/2506.20729)
### Authors
Zhiqi Gao,Tianyi Li,Yurii Kvasiuk,Sai Chaitanya Tadepalli,Maja Rudolph,Daniel J.H. Chung,Frederic Sala,Moritz Münchmeyer
### Background
大型语言模型（LLMs）在复杂推理方面展现了强大的能力，测试时的缩放技术可以以较低的成本提升其性能。这些技术在数学推理基准测试如AIME上得到了广泛的研究和评估。然而，这些方法在先进理论物理领域的有效性尚未得到证实。因此，本文研究了这些基准测试中的经验教训是否适用于理论物理领域，并在TPBench物理数据集上评估了一系列常见的测试时缩放方法，与AIME上的结果进行了比较。为了更好地利用物理问题的结构，本文还开发了一个新的符号弱验证框架，以改进并行缩放结果。
### Innovation
本文开发了一个名为符号弱验证的新框架，用于改进并行缩放结果。通过实验证明，该方法在TPBench数据集上的表现显著优于现有测试时缩放方法。此外，该方法还被用于AIME数据集的评估，展示了其解决高级数学问题的有效性。
### Conclusion
本文的经验结果表明，逐步的符号验证对于解决复杂的科学问题具有强大的能力。
## 28. `cs.AI` - FINN-GL: FPGA加速LSTM的通用混合精度扩展 [PDF](https://arxiv.org/pdf/2506.20810), [HTML](https://arxiv.org/abs/2506.20810)
### Authors
Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker
### Background
递归神经网络（RNN），特别是长短期记忆网络（LSTM），在情感分析和短期股票预测等时间序列任务中表现出色。然而，它们对计算复杂性的要求在资源受限的环境中进行实时部署时带来了挑战。虽然现场可编程门阵列（FPGA）为AI加速提供了一种节能平台，但现有的工具主要针对卷积神经网络（CNN），LSTM加速通常需要完全自定义实现。本文通过利用开源且可扩展的FINN框架，利用ONNX规范中的Scan操作来建模LSTM计算的递归性质，支持混合量化并在LSTM模型中进行功能验证，来填补这一空白。
### Innovation
本文引入了针对FINN编译器的自定义转换，将量化ONNX计算图映射到FINN编译器HLS内核库和Vitis HLS的硬件块。通过使用最小化精度的ConvLSTM模型对中价股票预测任务进行训练，并生成相应的硬件IP，表明通过该流程生成的量化ConvLSTM加速器能够在性能（延迟）和资源消耗之间取得平衡，同时与最先进的模型相比，在精度上表现出相匹配甚至更好的效果。
### Conclusion
所提议的流程具有通用性，将为FPGA上的资源高效RNN加速器设计开辟道路。
## 29. `cs.AI` - 通过基于代理的分析增强GNN在网络入侵检测中的鲁棒性 [PDF](https://arxiv.org/pdf/2506.20806), [HTML](https://arxiv.org/abs/2506.20806)
### Authors
Zhonghao Zhan,Huichi Zhou,Hamed Haddadi
### Background
图神经网络（GNNs）在物联网环境下的网络入侵检测系统（NIDS）中展现出巨大的潜力，但由于分布偏移导致性能下降，并且缺乏对现实环境中 adversarial 攻击的鲁棒性。现有鲁棒性评估很大程度上依赖于不现实的合成扰动，缺乏对不同类型 adversarial 攻击的系统分析，包括黑盒和白盒场景的攻击。
### Innovation
本文提出了一种新的方法，通过在基于代理的管道中使用大型语言模型（LLMs）来增强GNN的鲁棒性和泛化能力。代理审查从网络流量数据中提取的图结构，识别并可能缓解可疑或被 adverarial 扰动的元素，从而在GNN处理之前进行干预。实验结果表明，通过这种代理分析，可以显著提高基于GNN的NIDS的鲁棒性，展示了大型语言模型代理在入侵检测架构中作为补充层的潜力。实验使用了一个框架，该框架可以进行现实评价和使用各种 adversarial 攻击（包括从物理试验床收集的数据集）进行测试。
### Conclusion
将代理分析与GNN结合可以显著提高网络入侵检测系统的鲁棒性，展示了大型语言模型代理作为入侵检测架构补充层的潜在价值。
## 30. `cs.AI` - 在行为情景分析中揭示LLMs隐藏的暴力倾向：基于人口统计学的研究 [PDF](https://arxiv.org/pdf/2506.20822), [HTML](https://arxiv.org/abs/2506.20822)
### Authors
Quintin Myers,Yanjun Gao
### Background
近年来，大型语言模型（LLMs）被广泛提议用于检测和回应线上暴力内容，然而它们在处理具有道德模糊性的真实世界场景中的推理能力尚未得到充分研究。为了填补这一研究空白，本研究首次利用了经过验证的社会科学工具——暴力行为情景问卷（VBVQ）来评估LLMs。该研究通过引入基于人设的提示方法，突显了不同种族、年龄与地理身份的角色特征，以评估潜在偏见。在统一的零样本设置下，来自不同政治和组织背景的六种LLMs被评估，结果显示LLMs在生成表面上看似暴力的文字时往往偏离其内部偏好，并且它们的暴力倾向在不同的人口统计学群体中差异显著，这与犯罪学、社会科学和心理学中的既定结论存在分歧。
### Innovation
本研究的创新在于：首先使用了经过验证的社会科学工具评价LLMs处理现实世界中道德模糊场景的能力；其次，通过引入基于人设的提示方法来评估人设因素对LLMs生成暴力文本的影响，从而揭示了LLMs在不同人口统计学群体中的潜在偏见和分歧。
### Conclusion
本研究发现，LLMs在表面文本生成时经常偏离其内部的非暴力偏好，同时，它们在不同的人口统计学群体中的暴力倾向也存在显著差异，这些发现与犯罪学、社会科学和心理学中的既定结论存在矛盾。
## 31. `cs.AI` - LLM生成与人类研究想法的执行差距：执行结果 [PDF](https://arxiv.org/pdf/2506.20803), [HTML](https://arxiv.org/abs/2506.20803)
### Authors
Chenglei Si,Tatsunori Hashimoto,Diyi Yang
### Background
大型语言模型（LLMs）在加速科学研究管道方面显示出了潜力，研究表明，这些模型产生的研究想法有时比人类专家的想法更具有新颖性。然而，一个想法不仅应该看似新颖，还应该在执行后产生更好的研究结果。为了检验AI生成的想法是否能带来更好的研究结果，研究者招募了43名专家研究者来执行随机分配的想法，这些想法有的是由专家撰写的，有的是由LLM生成的。每个专家花费超过100小时实施想法，并撰写4页实验报告。所有执行的项目都由专家自然语言处理（NLP）研究者匿名评审。对比执行前后的评审分数，表明LLM生成的想法在所有评价标准上的得分相比专家撰写的想法显著下降，这在构想阶段观察到的人工智能与人类想法之间的差距有所缩小。当比较执行研究的汇总评审分数时，甚至出现了许多指标下人类想法排名高于LLM想法的情况。这一构想-执行差距突显了当前LLMs生成真正有效的研究想法能力的限制，并且在没有执行结果的情况下评估研究想法的挑战由此显现出来。
### Innovation
研究者通过招募专家研究者执行由LLM生成和专家撰写的随机分配想法，比较了两种不同想法在执行后的真实效果，这是评估AI生成想法的有效性的一个创新方法。研究结果显示，不仅在执行前的构想阶段，人类想法被认为更具优势，在执行后人类想法的优势进一步凸显，这表明当前的LLMs在生成真正具有执行价值的想法方面仍存在不足。
### Conclusion
尽管人工生成的研究想法在构想阶段可能更具有创新性，但在实际执行后，结果显示LLM生成的想法在有效性等方面不如人类提出的想法。这一发现揭示了当前LLMs在生成真正有效研究想法方面的局限性，并证明了在研究构想阶段和实际执行之间存在一个显著差距，这强调了进一步改进LLMs以提高它们的执行价值的重要性。
## 32. `cs.AI` - FixCLR: 负类对比学习在半监督领域泛化中的应用 [PDF](https://arxiv.org/pdf/2506.20841), [HTML](https://arxiv.org/abs/2506.20841)
### Authors
Ha Min Son,Shahbaz Rezaei,Xin Liu
### Background
半监督领域泛化（SSDG）旨在使用少量标记数据解决领域外数据泛化的问题。由于标签稀缺，现有的领域泛化方法往往表现不佳。因此，现有的SSDG方法结合了半监督学习方法和各种正则项。但是，这些方法没有明确地对学习所有领域不变表示进行正则化，这是领域泛化的一个关键目标。
### Innovation
本文提出了FixCLR，该方法借鉴了自监督学习的成功经验，通过改变两个关键组件来赋予对比学习进行明确领域不变性正则化的功能：利用伪标签中的类别信息和仅使用排斥项。FixCLR可以叠加在大多数现有的SSDG和半监督方法之上，以提供补充的性能提升。研究结果包括对半监督方法改进的基准测试、评估预训练模型与非预训练模型的表现，并测试具有多个领域数据集的表现。
### Conclusion
实验证明，FixCLR是有效的SSDG方法，特别是在与其他半监督方法结合使用时表现更为突出。
## 33. `cs.AI` - MultiFinRAG：一种优化的多模态检索增强生成（RAG）框架用于金融问答 [PDF](https://arxiv.org/pdf/2506.20821), [HTML](https://arxiv.org/abs/2506.20821)
### Authors
Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh
### Background
金融文档如10-Ks、10-Qs和投资者演示文稿篇幅数百页，包含密集的文字叙述、结构化表格和复杂图表等多种模态信息。回答这类文档中的问题通常需要跨模态联合推理，而传统的大型语言模型（LLMs）和检索增强生成（RAG）流水线由于标记限制、布局损失和跨模态上下文碎片化等问题难以胜任。因此，需要一种专门针对金融领域的问答系统的多模态检索增强生成框架以应对这些问题。
### Innovation
提出了MultiFinRAG，这是一种专为金融问答设计的多模态检索增强生成框架。框架首先进行多模态提取，将表和图图像分组并发送给一个轻量级且量化的开源多模态LLM，生成结构化的JSON输出和简洁的文本摘要。这些输出与叙述性文本一起被嵌入并根据模态感知相似度阈值进行索引，实现精确检索。在必要时，采用分层后备策略动态从仅文本到文本+表+图像的上下文中升级，从而实现跨模态推理同时减少无关紧要的上下文。即使在普通硬件上运行，MultiFinRAG在涉及文本、表格、图像和多模态推理的复杂金融问答任务中也比ChatGPT-4o（免费版）高出19个百分点的准确性。
### Conclusion
MultiFinRAG通过专门设计的多模态提取和索引策略提升了对于涉及多种模态信息的复杂金融问答任务的准确率，即使在普通硬件上也能实现高效处理和精确检索。
## 34. `cs.AI` - THIRDEYE:以大脑启发的多阶段融合实现特征意识的单目深度估计 [PDF](https://arxiv.org/pdf/2506.20877), [HTML](https://arxiv.org/abs/2506.20877)
### Authors
Calin Teodor Ioan
### Background
传统的单目深度估计方法训练深度模型直接从RGB像素推断深度，但这种隐式的学习方式往往忽略了人类视觉系统依赖的显式单目线索，如遮挡边界、阴影和透视关系。这些研究往往期望网络自行发现这些线索，但这种方法并不理想。
### Innovation
本文提出了ThirdEye，一种线索意识的管线，通过专门的、预先训练好的和冻结的网络故意提供每个线索。这些线索在三层神经元层次结构（V1-V2-V3）融合，并通过一个键值工作记忆模块根据可靠性加权。随后，自适应分箱变压器头部生成高分辨率的视差图。ThirdEye利用大量外部监督，只需要少量的微调。此外，该版本还提供了额外的架构细节、神经科学动机和扩展的实验协议；定量结果将在未来的修订中发表
### Conclusion
ThirdEye继承了大量的外部监督，仅需少量微调即可工作。该方法通过多阶段融合和可靠性的加权，更接近于人类的单目深度感知过程。这种方法的性能有望超越现有技术。
## 35. `cs.AI` - 为现实应用构建RAG系统：设计、开发与评估 [PDF](https://arxiv.org/pdf/2506.20869), [HTML](https://arxiv.org/abs/2506.20869)
### Authors
Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson
### Background
Retrieval-Augmented Generation (RAG) 系统正逐渐成为将大型语言模型（LLMs）与外部知识对接的关键方法，以解决事实准确性与上下文相关性方面的局限性。然而，目前缺乏关于基于实际应用场景的RAG实现的实证研究，这些研究通过广泛的用户参与进行评估，并且缺乏系统性的经验教训记录。
### Innovation
该论文介绍了五个针对治理、网络安全、农业、工业研究和医疗诊断等特定领域的RAG应用系统。每个系统结合了多语言OCR、向量嵌入的语义检索和领域适应的语言模型，并通过本地服务器或云API部署，以满足不同的用户需求。通过一个基于Web的评估，共有100名参与者从六个维度（易用性、相关性、透明度、响应性、准确性以及推荐意愿）对系统进行了评估，并总结了十二条关键经验教训，强调了技术、操作和伦理方面的挑战对RAG系统可靠性和可用性的影响。
### Conclusion
根据用户反馈和开发经验，作者记录了十二条关键经验教训，突出了在实践中影响RAG系统可靠性和易用性的技术、操作和伦理挑战。
## 36. `cs.AI` - 通过自动集成数据生成可靠不良事件概况以促进健康 (GRAPH-AID): 半自动化本体构建方法 [PDF](https://arxiv.org/pdf/2506.20851), [HTML](https://arxiv.org/abs/2506.20851)
### Authors
Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty
### Background
随着数据和知识的快速扩展，采用系统方法生成本体变得至关重要。由于数据量的不断增加和内容的频繁变化，对能够存储和检索信息以构建知识图谱的数据库的需求日益迫切。KNARM（知识获取与表示方法）已经提供了一种系统的方法来应对这些挑战并创建知识图谱，但这种方法在与Web本体语言（OWL）集成Neo4j数据库方面存在明显的难点。现有的集成方法通常要求用户了解描述逻辑（DL）语法，这对许多用户来说可能是陌生的。因此，需要一种更易于使用的解决方案来弥合这一差距。本研究提出了一种基于Python及其rdflib库的用户友好的方法，该方法通过与药物不良事件报告系统（FDA FAERS）数据库集成的Neo4j数据库展示了这一方法。
### Innovation
本文提出了一种基于Python及其rdflib库的用户友好的方法，通过与药物不良事件报告系统（FDA FAERS）数据库集成的Neo4j数据库实现了自动化的本体构建。该方法能够通过处理来自FDA FAERS数据库的数据，自动生成所需的类及其公理，从而实现更顺滑的集成过程。
### Conclusion
该方法提供了一种实用的解决方案，用于在不良药物事件数据集快速增长的背景下构建本体，这有助于增强药物安全监控和公共卫生决策。
## 37. `cs.AI` - 利用视觉语言模型选择由扩散模型生成的可信超分辨率样本 [PDF](https://arxiv.org/pdf/2506.20832), [HTML](https://arxiv.org/abs/2506.20832)
### Authors
Cansu Korkmaz,Ahmet Murat Tekalp,Zafer Dogan
### Background
超分辨率（SR）是一个病态的逆问题，具有许多与给定的低分辨率图像一致的解。传统的回归SR模型旨在在保真度和感知质量之间取得平衡，以获得单一解，但这种权衡往往引入了可能导致在识别数字或字母等关键信息时产生混淆的伪影。另一方面，扩散模型生成了多样的SR图像，但选择其中最可信赖的样本仍然是一个挑战。本文通过利用视觉语言模型（VLMs）的语义推理能力，介绍了一个鲁棒且自动化的框架来从由扩散模型生成的图像集中选择最可信的SR样本。这包括使用结构化查询评估SR样本的语义正确性、视觉质量和伪影。我们还提出了一种新的可信度评分（TWS），这是一种混合度量，用于基于语义相似性、结构完整性和伪影敏感性三个互补组件来定量评估SR的可靠性。实验证明，TWS与人类在模糊和自然图像中的偏好高度相关，且由VLM指导的选择通常具有较高的TWS评分。与像PSNR和LPIPS这样的传统度量相比，我们的方法提供了一种原则性、可扩展且通用的解决方案来解决扩散生成的SR空间中的不确定性问题。通过使输出与人类期望和语义正确性一致，这项工作为生成SR中的可信度设定了新的基准。
### Innovation
介绍了一个基于视觉语言模型(VLMs)的自动化框架，用于从由扩散模型生成的图像集中选择最可信的SR样本。提出了一种新的可信度评分（TWS），这是一种混合度量，用于基于语义相似性、结构完整性和伪影敏感性三个互补组件来定量评估SR的可靠性。与传统的度量方法相比，该方法提供了一种更加原则性、可扩展和通用的解决方案。
### Conclusion
通过使用视觉语言模型进行语义推理，并提出了一种新的可信度评分（TWS），该研究提供了一种新的方法来解决生成SR中的可信度问题。通过与人类偏好和伪影敏感性相关的定量评估，该项工作为解决生成SR中的不确定性问题设定了新基准。
## 38. `cs.AI` - GPU Kernel Scientist: 一种由LLM驱动的迭代内核优化框架 [PDF](https://arxiv.org/pdf/2506.20807), [HTML](https://arxiv.org/abs/2506.20807)
### Authors
Martin Andrews,Sam Witteveen
### Background
优化GPU内核以获得高性能是一个复杂的过程，通常需要深厚的架构知识、广泛的性能分析和多次实验。这一挑战在针对较新的或文档较少的GPU架构时尤为突出，因为在这些架构上传统的开发辅助工具较为稀缺。AMD的MI300目标架构就是其中之一，需要深入了解其特性和优化策略。传统的内核优化方法依赖于人类专家的知识，但在资源受限或硬件快速迭代的环境中，这可能不够充分。此次研究探索了一种通过LLM（语言模型）驱动的方法，旨在自动化和迭代优化GPU内核，以解决这一问题。
### Innovation
提出了一种基于LLM的“GPU Kernel Scientist”，这是一种自动化的内核优化方法。该方法采用了多阶段、进化的流程：（a）战略性地选择有潜力的前期代码版本作为新迭代的基础；（b）基于现有代码和从广泛GPU文献中吸收的知识生成优化实验的假设；（c）通过代码修改和向外部评估系统提交代码实现这些实验，并仅使用观察到的计时数据作为性能反馈进行自主实施。这种方法旨在帮助克服有限的领域特定专业知识问题，特别是在资源有限或硬件快速变化的环境中。
### Conclusion
由于性能竞赛的定量结果尚未公布，本文详细介绍了该方法的架构设计、操作流程及定性洞察，强调了LLM驱动的代理在内核优化中的潜力，特别是在资源限制或硬件快速发展的环境中，有助于加速和普及内核优化的过程。
## 39. `cs.AI` - 通过不确定人类指导的强化学习实现复杂模型变换 [PDF](https://arxiv.org/pdf/2506.20883), [HTML](https://arxiv.org/abs/2506.20883)
### Authors
Kyanna Dagenais,Istvan David
### Background
模型驱动工程问题通常需要复杂的模型变换（MT），如链式序列中的相互连接。这样的问题包括模型同步、自动化模型修复和设计空间探索等。人工开发复杂模型变换既容易出错又难以实现。强化学习（RL）在这种情况下是一种有效的方法，它依赖于一个自主代理通过尝试和错误探索状态空间，以识别有益的动作序列，如模型变换。然而，在复杂问题中，RL方法表现出性能不足，此时人类指导变得非常有用。该研究涉及通过可能不确定的人类指导，使用RL开发复杂模型变换序列的方法和技术框架。研究者将其用户定义的模型变换映射到RL的基本构建块上，并作为RL程序执行，以寻找最优的模型变换序列。研究结果表明，即使指导是不确定的，它也能显著改善RL性能，更高效地开发复杂的模型变换。通过人类指导的确定性和及时性之间的权衡，该方法朝着强化学习驱动的人机协作工程方法迈出了一步。
### Innovation
提出了一种利用可能不确定的人类指导通过强化学习开发复杂模型变换序列的方法和技术框架。用户定义的模型变换被映射到RL的基本构建块上，并作为RL程序执行，以找到最优的模型变换序列。这种方法在复杂问题中提高了RL的性能，并且通过确定性和及时性之间的权衡，朝着强化学习驱动的人机协作工程方法迈进。
### Conclusion
研究表明，即使人类指导是不确定的，它也可以显著提高RL性能，并更有效地开发复杂的模型变换序列。该方法展示了强化学习在复杂任务中的潜力，尤其是在结合人类的不确定指导时。
## 40. `cs.AI` - Omniwise: 使用LLMs预测GPU内核性能 [PDF](https://arxiv.org/pdf/2506.20886), [HTML](https://arxiv.org/abs/2506.20886)
### Authors
Zixian Wang,Cole Ramos,Muhammad A. Awad,Keith Lowery
### Background
近年来，深度神经网络（DNNs）的迅速进步彻底改变了人工智能领域，使得模型能够以前所未有的能力理解和处理复杂数据。这些强大的架构已经改变了广泛下游应用，可以处理人类无法完成的任务。
### Innovation
 Omniwise 是第一个端到端、自监督微调流水线，采用了大型语言模型（LLMs）来预测 GPU 内核性能——一个新的性能分析用例。Omniwise 具有模型无关且轻量级的特点，即便是一个小的 3B 参数模型也能取得出色的成果。它可以不依赖代码执行或分析工具，直接从内核代码预测关键性能指标，包括内存带宽、缓存命中率、GFLOPs 和算术强度。而且，该方法在 AMD MI250 和 MI300X 架构上运行的 GPU 内核上达到了超过 90% 的预测准确率，相对误差不超过 10%。此外，该论文还开发了用于在线推理的服务和 Visual Studio Code 插件，让基于 LLM 的性能预测无缝集成到开发者的工作流程中。
### Conclusion
该研究引入了 Omniwise，一种端到端的自监督微调流水线，利用 LLM 预测 GPU 内核性能，结果表明其准确性和效率高，同时提供了一个在线推理服务和 Visual Studio Code 插件，方便集成到开发者的日常工作中。
## 41. `cs.AI` - ZKPROV：大型语言模型数据来源的零知识方法 [PDF](https://arxiv.org/pdf/2506.20915), [HTML](https://arxiv.org/abs/2506.20915)
### Authors
Mina Namazi,Alexander Nemecek,Erman Ayday
### Background
随着大型语言模型（LLMs）在敏感领域中的广泛应用，确保其计算源的完整性成为一个关键挑战，尤其是在如医疗保健这样的监管领域，对数据集的使用有严格要求。现有的方法要么专注于训练过程的完全验证（这会带来巨大的计算成本），要么依赖受信任的执行环境。ZKPROV提供了一种新的平衡方案，通过零知识证明将训练好的模型与授权的数据集绑定，同时避免了对每个训练步骤的证明，并通过数据集签名的元数据和紧凑的模型参数承诺提供安全且隐私保护的保证。
### Innovation
ZKPROV提出了一种新颖的加密框架，能够生成零知识证明以验证大型语言模型的来源，而无需透露数据集或模型参数的敏感信息。与以前的方法相比，该方法在验证时避免了每一步训练的详细信息，只专注于将训练好的模型与授权的数据集绑定。通过这种方式，ZKPROV提供了高效且可扩展的解决方案，能够在实际部署中提供大数据集来源的可信保障，同时保证隐私和安全。
### Conclusion
实验结果显示，ZKPROV在生成和验证这种证明方面是高效的和可扩展的，为现实世界的部署提供了一个实用的解决方案。此外，该方法还提供了形式的安全保证，证明了它在确保数据集机密性的同时保持了可信的数据集来源。
## 42. `cs.AI` - 优化语言模型以适应下游任务：后训练视角 [PDF](https://arxiv.org/pdf/2506.20917), [HTML](https://arxiv.org/abs/2506.20917)
### Authors
Zhengyan Shi
### Background
语言模型（LMs）在自然语言处理（NLP）中表现出色，但是在效率和鲁棒性方面将其适配到特定任务依然具有挑战。随着这些模型规模和复杂性增加，利用标记数据的微调常常在利用未标记数据方面不尽如人意，并且在小规模特定任务集中容易发生过拟合，还会产生巨大的计算成本。这些限制因素限制了它们在实际世界语言任务开放场景中的应用。
### Innovation
提出了相关方法以更高效地适配LMs至下游应用。首先探索了如何从未标记数据中提取任务相关信息，并引入了一种创新的连续预训练技术，此技术超越了最先进的半监督方法。其次，提出了一种参数高效微调方法，可大幅降低运行时的内存和计算成本同时保持竞争力的性能。还引入了改进的有监督微调方法，使模型可以在标注数据稀缺的条件下更好地遵循指令，提升其在多种形式NLP任务中的表现，特别是开放生成性任务。最后，开发了新的评估方法和基准任务，如多跳空间推理任务，以更全面地评估LM能力及其适应性。
### Conclusion
通过广泛的实证研究，在不同的NLP任务中展示了这些方法显著提高LM的鲁棒性、效率和通用性，使其具有更好的适应能力，能够应用在更广泛的领域。这些进展标志着朝着更加稳健高效的语言模型迈出的重要一步，将我们向人工通用智能的目标更近了一步。
## 43. `cs.AI` - 随机参数分解 [PDF](https://arxiv.org/pdf/2506.20790), [HTML](https://arxiv.org/abs/2506.20790)
### Authors
Lucius Bushnaq,Dan Braun,Lee Sharkey
### Background
神经网络逆向工程中的关键步骤是将神经网络分解成更简单的部分，以便于相对独立地进行研究。现有的参数分解框架，如基于贡献的参数分解(APD)，虽然旨在解决当前分解方法存在的问题，但也存在着计算成本高、对超参数敏感等缺点。因此，本研究旨在提出一种更符合实际应用的参数分解方法，以克服现有方法的局限性。通过引入基于概率的参数分解方法，该研究希望解决现有的参数分解技术的不可扩展性和超参数敏感性问题，并且通过实验证明其在分解更大、更复杂的模型方面的优势，以及在一些简单模型中更好地识别真实机制的能力。这种方法还能连接因果中介分析与网络分解方法，进一步推动机制化可解释性研究的发展。
### Innovation
本研究提出了一种新的参数分解方法——基于概率的参数分解（Stochastic Parameter Decomposition, SPD），该方法相较于现有的基于贡献的参数分解（APD）更加可靠且具有扩展性。SPD通过模拟解耦参数空间中的稀疏使用向量来分解神经网络参数，相比APD，SPD解决了参数压缩问题，并且能够更好地识别现实模型中的真实机制，从而能够应对稍大且更复杂的模型。此外，SPD 还具备更好的超参数鲁棒性，减少了解析过程中对超参数的调节依赖，提高了模型分解的效率和准确性。
### Conclusion
通过引入SPD方法，研究证明了其不仅能够有效地扩展到更大、更复杂的模型，还能够在一些简单模型中更准确地识别真实机制。此次研究在机制化可解释性领域取得了一定的突破，开发了一种更可靠的参数分解技术，并通过一个可复现的实验库展示了其实际应用价值。这种方法有效地解决了原有分解技术的局限性，推动了该领域的进一步发展。该研究为机制化可解释性研究提供了一种新的工具和技术，为后续研究提供了实验基础。
## 44. `cs.AI` - 使用几何感知扩散和时序视频模型实现一致的零样本3D纹理合成 [PDF](https://arxiv.org/pdf/2506.20946), [HTML](https://arxiv.org/abs/2506.20946)
### Authors
Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik
### Background
当前的纹理合成方法产生从固定视角生成的纹理，因为缺乏全局上下文和几何理解，导致存在不一致性。同时，近期的视频生成模型在实现时序一致的视频方面取得了显著成功。然而，这些方法在处理3D纹理的空间和时间不一致性方面仍存在局限性。
### Innovation
本文提出了一种新的框架VideoTex，利用视频生成模型解决3D纹理的空间和时间不一致性问题。该方法结合了几何感知条件，实现了3D网格结构的精确利用。此外，还提出了一种结构化的UV扩散策略，通过保留语义信息增强了对遮挡区域的生成，从而实现更平滑和更连贯的纹理。VideoTex不仅实现了UV边界更平滑的过渡，还能在视频帧中确保高质量的时间稳定纹理。
### Conclusion
广泛的实验表明，VideoTex在纹理保真度、缝合混合和稳定性方面优于现有方法，为需要视觉质量和时间连贯性的动态实时应用铺平了道路。
## 45. `cs.AI` - VLA模型后训练与人类运动学习之间的类比：进展、挑战与趋势 [PDF](https://arxiv.org/pdf/2506.20966), [HTML](https://arxiv.org/abs/2506.20966)
### Authors
Tian-Yu Xiang,Ao-Qun Jin,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Sheng-Bin Duan,Fu-Chao Xie,Wen-Kai Wang,Si-Cheng Wang,Ling-Yun Li,Tian Tu,Zeng-Guang Hou
### Background
视觉-语言-动作(VLA)模型在视觉语言模型(VLM)的基础上，通过整合动作生成模块增强了机器人的操作能力。尽管VLA模型在多种操作任务中展现出良好的泛化能力，但在需要高精度和高准确性的应用中却表现出不足，需要进一步适应。这些领域的证据突显出了模型后训练在调整基础模型以满足下游应用需求中的重要作用，促进了对VLA模型后训练的深入研究。
### Innovation
本文通过从人类运动学习的角度审视VLA模型的后训练策略，提出了一个结构化的分类体系，涵盖环境、实体和任务三个维度，并将其进一步细分为增强环境感知、提升实体意识、深化任务理解以及多组件集成四个方面。这为未来的VLA模型研究提供了概念框架和实用见解，旨在指导VLA模型的发展。
### Conclusion
本文为当前VLA模型的后训练方法提供了一个全面的综述，并从人类运动学习的角度提出了实际指导，明确了VLA模型后训练中的关键挑战和未来趋势。
## 46. `cs.AI` - 基于多代理方法的大型语言模型引导的化学过程优化 [PDF](https://arxiv.org/pdf/2506.20921), [HTML](https://arxiv.org/abs/2506.20921)
### Authors
Tong Zeng,Srivathsan Badrinarayanan,Janghoon Ock,Cheng-Kai Lai,Amir Barati Farimani
### Background
化学过程优化对最大化生产效率和经济效益至关重要。传统方法，如梯度基求解器、进化算法和参数网格搜索，在操作约束不明确或不可用的情况下变得不切实际，工程师们不得不依赖主观的启发式方法来估计可行的参数范围，这导致了操作约束定义的瓶颈问题。为了解决这一问题，本文提出了一种基于多代理框架的大型语言模型（LLM）代理系统，该系统能够从简化的过程描述中自主推断操作约束，并在推断的约束下协作指导优化。
### Innovation
该多代理框架使用基于AutoGen的代理系统，并结合了OpenAI的o3模型，拥有专门的约束生成、参数验证、仿真执行和优化指导等代理。该框架通过两个阶段消除预定义的操作范围需求：首先是自主约束生成利用嵌入的专业领域知识，其次是迭代的多代理优化。该框架在氢解烷基化过程中经过验证，展示了与传统优化方法相当甚至更优的竞争性能，同时在达收敛所需迭代次数上更为高效。这一框架在计算效率和推理引导搜索方面表现出色，揭示了对过程有深入了解，能正确识别资源权衡，并应用领域启发式方法。
### Conclusion
该多代理框架在优化场景中显示出巨大潜力，特别是在操作约束不明确或不存在的情况下，尤其适用于新兴过程和改造工程。通过两个阶段的迭代优化，它能够显著提高优化效率，验证过程中证明在20分钟内即可实现31倍的加速。
## 47. `cs.AI` - 证据驱动的人工智能多智能体副机对人类病理诊断推理 [PDF](https://arxiv.org/pdf/2506.20964), [HTML](https://arxiv.org/abs/2506.20964)
### Authors
Chengkuan Chen,Luca L. Weishaupt,Drew F. K. Williamson,Richard J. Chen,Tong Ding,Bowen Chen,Anurag Vaidya,Long Phi Le,Guillaume Jaume,Ming Y. Lu,Faisal Mahmood
### Background
近年来，病理学正经历由全切片成像和人工智能驱动的快速数字化转型。尽管基于深度学习的计算病理学取得了显著成果，传统的模型大多专注于图像分析，而没有集成自然语言指令或丰富的文本背景信息。当前用于计算病理学的多模态大型语言模型面临数据不足、多图像理解支持不足以及自主诊断推理能力不足等问题。
### Innovation
该研究引入了一种名为PathChat+的新多模态大型语言模型，专门用于病理学，并通过超过100万份具体的病理指令样本和近550万轮问题解答，解决了以往模型的限制。该模型在多个病理基准测试中的广泛评估证明，PathChat+显著优于之前的PathChat副机和最新的通用及专用病理模型。此外，还提出了一个基于PathChat+的多代理AI系统SlideSeek，能够通过迭代、层次化的诊断推理自动评估千兆像素级全切片成像（WSI），在具有挑战性的开放性诊断基准DDxBench上达到了高准确率，同时也能生成可视化支持、人性可解释的总结报告。
### Conclusion
该工作展示了一种新的解决方案，能够显著提高计算病理学的诊断能力，并展示了其在复杂诊断任务中的强大潜力。
## 48. `cs.AI` - OmniEval: 一种用于评估视听文本多模态模型的标准 [PDF](https://arxiv.org/pdf/2506.20960), [HTML](https://arxiv.org/abs/2506.20960)
### Authors
Yiman Zhang,Ziheng Luo,Qiangyu Yan,Wei He,Borui Jiang,Xinghao Chen,Kai Han
### Background
当前，多模态模型如MiniCPM-O 2.6得到了广泛应用，这些模型能够处理视觉、听觉和文本输入。然而，现有的多模态评估基准无法充分体现这些模型的跨模态协作特性，也无法全面覆盖多样化的视频数据和任务类型，因此有必要提出一种新的多模态基准来促进这一领域的研究和发展。
### Innovation
 OmniEval是一个全新的多模态模型基准，具有以下创新点：(i) 全模态协作：设计了强调音频和视频之间强耦合的评估任务，要求模型有效利用多种模态的协作感知；(ii) 多样化的视频内容：包含810个音频-视频同步视频、285个中文视频和525个英语视频；(iii) 多样性和颗粒度的任务：包含2617个问题答案对，包括1412个开放式问题和1205个多选题，分为3大类任务和12个小类任务，实现全面评估，且引入了更细致的视频定位任务Grounding.
### Conclusion
通过在OmniEval上对多个多模态模型进行实验，我们的目的是为评估这些模型从各种模态上下文构建和理解连贯性提供一个平台。相关的代码和数据可以在指定的网址找到。
## 49. `cs.AI` - 增强同质性-异质性区分：基于关系感知的异质图学习 [PDF](https://arxiv.org/pdf/2506.20980), [HTML](https://arxiv.org/abs/2506.20980)
### Authors
Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu
### Background
现实中的网络通常具有节点异质性的特性，即连接的节点通常具有不同的特征或标签。这个问题在同质图中已经得到广泛研究，但在异质图中却尚未得到充分探索。异质图中存在多种类型的节点和边，捕捉节点异质性非常具有挑战性，因为不仅要考虑节点和边的异质性，还要考虑节点异质性。现有的方法通常将异质图转换为同质图来学习节点异质性，但这会不可避免地丢失异质关系传达的潜在异质性信息。
### Innovation
本文提出了一种新型对比学习框架Relation-Aware Separation of Homophily and Heterophily（RASH），该框架可以明确建模高层次的异质交互语义，并根据关系的重要性动态构建同质图和异质图。RASH设计了一种多关系对比损失，通过最大化互信息在异质视图和同质/异质视图之间进行对齐。通过这种方式，RASH同时解决了异质图中的异质性和异质性挑战。
### Conclusion
在基准数据集上的广泛实验证明，RASH在各种下游任务中具有有效性。代码可在该链接中获得：this https URL.
## 50. `cs.AI` - 从摇篮到拐杖：一种高保真生命周期面部老化两阶段框架 [PDF](https://arxiv.org/pdf/2506.20977), [HTML](https://arxiv.org/abs/2506.20977)
### Authors
Tao Liu,Dafeng Zhang,Gengchen Li,Shizhuo Liu,Yongqi Song,Senmao Li,Shiqi Yang,Boqian Li,Kai Wang,Yaxing Wang
### Background
面部老化已成为计算机视觉中一项至关重要的任务，应用范围从娱乐到医疗保健。现有的方法在实现生命的整个阶段的真实且无缝的转换方面遇到困难，尤其是在处理大的年龄差距或极端头部姿态时。核心挑战在于平衡年龄准确性和身份保真度，即我们称为Age-ID折中。大多数先前的方法要么优先考虑年龄转换而牺牲身份一致性，要么反之亦然。在这项工作中，我们通过提出基于少量文本到图像（T2I）扩散模型的两阶段面部老化框架Cradle2Cane，解决了这一问题。
### Innovation
我们提出的Cradle2Cane框架采用两阶段方法，首先通过引入自适应噪声注入（AdaNI）机制解决年龄准确性问题。第二阶段则通过将模型条件化在两种身份感知嵌入（IDEmb）：SVR-ArcFace和Rotate-CLIP上，增强身份保真度同时保持年龄特定特征。两个阶段以端到端的方式联合训练。在广泛实验中，我们的Cradle2Cane在年龄准确性和身份保真度方面优于现有面部老化方法。
### Conclusion
我们的Cradle2Cane在CelebA-HQ测试数据集上通过Face++和Qwen-VL协议评估表明，该方法在年龄准确性和身份一致性方面取得了优异表现，优于现有的面部老化方法。
## 51. `cs.AI` - 可解释的加性规则集合的表示学习 [PDF](https://arxiv.org/pdf/2506.20927), [HTML](https://arxiv.org/abs/2506.20927)
### Authors
Shahrzad Behzadimanesh,Pierre Le Bodic,Geoffrey I. Webb,Mario Boley
### Background
传统上，加性规则集合使用基于单个输入变量x和阈值t的一次简单阈值陈述的连结规则条件，几何上形成轴平行多面体作为决策区域。这种方法确保了个人规则的高度可解释性，并可以通过梯度提升方法高效地学习，但需要访问一个经过筛选的、理想上独立的输入特征集合，这样才能用少量的轴平行区域很好地表示目标变量。缺乏这种特征时，为了达到足够的准确性，需要增加规则的数量和复杂性，从而降低了模型的可解释性。
### Innovation
本文通过引入具有可学习稀疏线性变换的输入变量的逻辑命题（形式为 xT w ≥ t，其中w是可学习的稀疏权重向量），扩展了经典的规则集合。这使得决策区域可以是具有斜边面的一般多面体。提出了基于逻辑回归迭代加权形式的逐次贪婪优化的学习方法。实验结果表明，该方法可以在十个基准数据集上高效地构建具有与最新方法相同测试风险的同时显著降低模型复杂性.
### Conclusion
本文提出了一种高效的可解释的加性规则集合的学习方法，能够在保持与最新方法相似测试风险的同时显著降低模型复杂性。
## 52. `cs.AI` - 使用自然语言在病理图像中进行分割 [PDF](https://arxiv.org/pdf/2506.20988), [HTML](https://arxiv.org/abs/2506.20988)
### Authors
Zhixuan Chen,Junlin Hou,Liqi Lin,Yihui Wang,Yequan Bie,Xi Wang,Yanning Zhou,Ronald Cheong Kin Chan,Hao Chen
### Background
病理图像分割是计算病理学中分析与癌症诊断和预后相关的组织学特征的关键步骤。现有方法在临床应用中面临巨大挑战，主要是由于标注数据有限和类别定义受限。
### Innovation
提出了PathSegmentor，这是一种专门设计用于病理图像的首批基于文本提示的分割基础模型。同时，PathSeg是迄今为止最大和最全面的病理分割数据集，来自17个公开来源，包含275,000个图像-掩模-标签三元组，跨越160个不同类别。用户可以通过自然语言提示进行语义分割，无需手动定位空间输入。实验结果表明，PathSegmentor在准确性及适用性方面优于专门模型，同时保持紧凑的架构，并且在Dice得分上显著超越现有基于空间和文本提示的模型。此外，PathSegmentor的输出能够增强诊断模型的解释性，通过特征重要性估计和成像生物标志物发现为病理学家提供基于证据的支持，从而推动精准肿瘤学中可解释人工智能的发展。
### Conclusion
PathSegmentor在病理图像分割中表现出色，不仅具有更好的准确性，还增强了诊断模型的可解释性和临床决策支持。这项工作推进了精准肿瘤学中可解释人工智能的发展。
## 53. `cs.AI` - 使用多尺度对称图扩散模型进行准确复杂抗原结合的抗体设计与优化 [PDF](https://arxiv.org/pdf/2506.20957), [HTML](https://arxiv.org/abs/2506.20957)
### Authors
Jiameng Chen,Xiantao Cai,Jia Wu,Wenbin Hu
### Background
抗体设计仍是治疗和诊断开发的关键挑战，尤其是对于具有多种结合界面的复杂抗原。当前的计算方法面临两大限制：(1) 在保留对称性的同时捕捉几何特征，(2) 适应新型抗原界面。尽管近期有进展，但这些方法往往无法准确捕捉分子间相互作用和维持结构完整性。针对这些挑战，该论文提出了一种端到端框架AbMEGD，该框架结合了多尺度对称图扩散来协同设计抗体序列和结构。AbMEGD利用先进的几何深度学习，结合原子级几何特征和残基级嵌入，捕捉局部原子细节和全局序列-结构相互作用。其E(3)-对称扩散方法确保几何精度、计算效率和对复杂抗原的强大泛化能力。实验使用SAbDab数据库表明，与领先的抗体设计模型DiffAb相比，氨基酸回收率提高了10.13%，改进百分比提高了3.32%，关键CDR-H3区域的均方根偏差减少了0.062 Å。这些结果表明，AbMEGD能够在保持结构完整性的前提下提高功能，从而为序列-结构协同设计和亲和力优化设立了新的基准。
### Innovation
提出的AbMEGD框架结合了多尺度对称图扩散来协同设计抗体序列和结构，利用先进的几何深度学习捕捉局部原子细节和全局序列-结构相互作用，确保几何精度、计算效率和对复杂抗原的强大泛化能力。实验结果显著提高了抗体设计的准确性，特别是关键CDR-H3区域的结构和功能匹配度。
### Conclusion
该研究提出了一种新的端到端框架AbMEGD，通过多尺度对称图扩散技术增强了抗体设计的精确性和功能。实验结果证明了其在复杂抗原结合中的优势，为抗体设计和优化设立了新基准。
## 54. `cs.AI` - 多模态提示对齐用于面部表情识别 [PDF](https://arxiv.org/pdf/2506.21017), [HTML](https://arxiv.org/abs/2506.21017)
### Authors
Fuyan Ma,Yiran He,Bin Sun,Shutao Li
### Background
提示学习已被广泛应用于高效地将类似CLIP的视觉语言模型（VLMs）适应于各种下游任务。尽管取得了成功，但当前基于VLM的面部表情识别（FER）方法难以捕捉细微的文本-视觉关系，这对于区分面部表情之间的细微差异至关重要。
### Innovation
本文提出了一个用于FER的多模态提示对齐框架（MPA-FER），该框架通过利用大型语言模型（如ChatGPT）为每个面部表情生成详细的描述，以精细地指导提示视觉特征的学习过程，生成更精确和可解释的表示。特别是，引入了多层次硬提示生成策略，利用大型语言模型外的先验知识，通过最小化软提示和硬提示之间的特征差异进行注入。同时，提出了一个跨模态全局-局部对齐模块，集中于与表情相关的面部特征，进一步提高了文本和视觉特征的对齐。该框架在三个FER基准数据集上优于最先进的方法，同时保留了预训练模型的通用性能并降低了计算成本。
### Conclusion
广泛的实验表明，我们的框架在三个FER基准数据集上优于最先进的方法，同时保留预训练模型的优点并减少了计算成本。
## 55. `cs.AI` - 通过指导与调度提高基于扩散的图像编辑保真度 [PDF](https://arxiv.org/pdf/2506.21045), [HTML](https://arxiv.org/abs/2506.21045)
### Authors
Hansam Cho,Seoung Bum Kim
### Background
文本指导的扩散模型已成为高质量图像合成的重要工具，支持动态图像编辑。在图像编辑中，编辑的可操作性和保真度是两个至关重要方面，前者决定了修改的范围，后者反映了未改动元素的保存程度。然而，如何在这两者之间实现最佳效果是一个极具挑战性的任务，因为它们之间存在固有的权衡关系。
### Innovation
本文提出了一种名为 Faithfulness Guidance and Scheduling (FGS) 的方法，通过增强保真度同时最小化对可操作性的影响，解决编辑过程中的保真度与可操作性之间的矛盾。FGS 方法集成了保真度指导策略以增强输入图像信息的保存，并引入调度策略来解决保真度与可操作性之间潜在的不一致问题。实验结果显示，FGS 方法能够同时保持保真度和可操作性，并且兼容多种编辑方法，支持多样任务的精准高质量图像编辑。
### Conclusion
FGS 方法通过指导和调度策略大幅提高了基于扩散模型的图像编辑保真度，即使在保持较高可操作性的情况下也实现了这一点。这种方法为图像编辑任务提供了更精确、高质量的编辑结果。
## 56. `cs.AI` - DFVEdit: 条件Delta流向量及其在零样本视频编辑中的应用 [PDF](https://arxiv.org/pdf/2506.20967), [HTML](https://arxiv.org/abs/2506.20967)
### Authors
Lingling Cai,Kang Zhao,Hangjie Yuan,Xiang Wang,Yingya Zhang,Kejie Huang
### Background
视频扩散变换器（Video DiTs）的出现为视频生成带来了重要突破，但直接将现有的视频编辑方法应用于Video DiTs往往会导致计算开销巨大，这是由于需要进行资源密集型注意修改或微调。因此，需要一种高效的方法，能够在不进行这些修改和微调的情况下，提供视频编辑功能。
### Innovation
本文提出了一种名为DFVEdit的高效零样本视频编辑方法，特别适用于Video DiTs。DFVEdit通过流变换直接作用于干净的潜在变量来消除注意修改和微调的需要。此外，还提出了一种条件Delta流向量（CDFV）作为DFV的无偏估计，并引入了隐式交叉注意力（ICA）指导和嵌入强化（ER）来进一步提高编辑质量。DFVEdit在实际效率方面表现出色，与基于注意工程的方法相比，提供了至少20倍的推理速度提升和85%的内存减少，并且能够在流行视频DiT（如CogVideoX和Wan2.1）中无缝应用，达到在结构保真、时空一致性和编辑质量上的最优表现。
### Conclusion
通过广泛进行定量和定性实验，证明DFVEdit可以在各种视频DiT中实现无缝编辑，并且其性能达到了目前的最优水平，在结构保真、时空一致性和编辑质量方面表现出色。
## 57. `cs.AI` - 严格子目标执行：层次强化学习中的可靠长期规划 [PDF](https://arxiv.org/pdf/2506.21039), [HTML](https://arxiv.org/abs/2506.21039)
### Authors
Jaebak Hwang,Sanghyeon Lee,Jeongmo Kim,Seungyul Han
### Background
长远目标条件任务对强化学习（RL）提出了根本性的挑战，尤其是当目标遥远且奖励稀疏时。尽管层次化和基于图的方法提供了部分解决方案，但它们经常会遇到子目标不可行和规划效率低下的问题。
### Innovation
我们引入了严格子目标执行（SSE），这是一种基于图的层次化RL框架，通过结构上约束高层决策来确保单步子目标可达性。为了增强探索，SSE采用了一种解耦的探索策略，系统地探索目标空间的未探索区域。此外，SSE还采用了基于故障的路径细化，通过动态调整边成本来优化图基于的规划，从而提高子目标的可靠性。
### Conclusion
在不同长期目标基准实验中，SSE在效率和成功率方面均优于现有的目标条件RL和层次化RL方法。
## 58. `cs.AI` - 电子商务查询分类的半监督可扩展统一框架 [PDF](https://arxiv.org/pdf/2506.21049), [HTML](https://arxiv.org/abs/2506.21049)
### Authors
Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law
### Background
电子商务查询分类对于电子商务应用程序至关重要，但现有查询分类方法通常依赖于用户的后验点击行为来构建训练样本，这导致马太效应循环。此外，查询分类的子任务缺乏统一框架，导致算法优化效率低下。电子商务查询通常很短且缺乏上下文，标签之间的信息无法利用，这使得建模时缺乏足够的先验信息。
### Innovation
本文提出了一种新型的半监督可扩展统一框架（SSUF），该框架包含多个增强模块来统一查询分类任务。知识增强模块利用世界知识增强查询表示，解决查询信息不足的问题；标签增强模块利用标签语义和半监督信号减少对后验标签的依赖；结构增强模块基于复杂的标签关系增强标签表示。每个模块高度可插拔，输入特征可以根据每个子任务的需要添加或移除。
### Conclusion
进行广泛的离线和在线A/B实验，结果显示SSUF在性能上显著优于最先进的模型。
## 59. `cs.AI` - SAC: 动态强度控制下测量和诱导LLM个性特征的框架 [PDF](https://arxiv.org/pdf/2506.20993), [HTML](https://arxiv.org/abs/2506.20993)
### Authors
Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar
### Background
近年来，大型语言模型（LLMs）已在多个领域取得了显著进展，但也存在期望它们在互动中展示出类人的人格特质。然而，现有的大多数组织模型依赖于‘大五’人格模型，只能提供粗略的人格维度，并且缺乏控制特质强度的机制。为了克服这些局限性，作者提出了扩展Machine Personality Inventory（MPI），通过结合16PF模型来控制16种不同的人格特质，以及一个名为Specific Attribute Control（SAC）的方法，用于评估和动态诱导LLM的人格特质强度。该方法通过短语锚定来指导强度表达，并利用五个强度因素：频率、深度、阈值、努力和意愿来实现。实验结果表明，将强度视为连续光谱可获得更一致和可控制的人格表达，改变目标特质的强度会系统地影响相关特质，表明LLMs内部化了多维度的人格结构。
### Innovation
本文通过扩展MPI模型，结合16PF模型来实现对16种不同人格特质的表达控制；提出了SAC框架以动态控制LLM的性格特质强度；通过引出形容词语义锚定和五个强度因素，来指导强度的表达；实验表明，强度为连续光谱时，人格表达更为一致和可控；人格特质的强度变化会导致紧密相关特质的系统性影响，表明LLM内部化了多维度的人格结构而非孤立处理特质。
### Conclusion
本文的工作为医疗、教育和面试等领域的可控、精致的人机交互打开了新的路径，使得LLM更加接近真正的人类互动社会机器。
## 60. `cs.AI` - V2X-REALM：基于视觉语言模型的具有适应性长尾建模的鲁棒端到端协同自动驾驶 [PDF](https://arxiv.org/pdf/2506.21041), [HTML](https://arxiv.org/abs/2506.21041)
### Authors
Junwei You,Pei Li,Zhuoyu Jiang,Zilin Huang,Rui Gan,Haotian Shi,Bin Ran
### Background
在城市环境中，确保在罕见的、多样的以及视觉退化的长期尾场景下进行稳健的规划和决策依然是自动驾驶面临的基本挑战。这一问题在协同场景下更加严峻，因为车辆和基础设施需要共同感知和推理跨复杂环境的情况。现有的解决方案难以处理这些复杂条件下的鲁棒性和准确度问题。
### Innovation
V2X-REALM引入了三项核心创新：（i）一种基于提示的长期尾场景生成和评估管道，利用基础模型合成现实中的长期尾条件，如雪和雾，以有效丰富多样性；（ii）一种带有门控多场景自适应注意力模块，根据场景先验调节视觉流，校准模糊或损坏特征；（iii）一种多任务场景感知对比学习目标，改善多模态对齐并促进跨场景特征可分性。
### Conclusion
广泛的实验表明，V2X-REALM在复杂的驾驶条件下具有稳健性、语义推理、安全性和规划精度方面的显著优势，推动了端到端协同自动驾驶的可扩展性。
## 61. `cs.AI` - 大型语言模型在特许会计师考试中表现优异 [PDF](https://arxiv.org/pdf/2506.21031), [HTML](https://arxiv.org/abs/2506.21031)
### Authors
Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta
### Background
当前，先进的智能系统，尤其是大型语言模型（LLMs），通过自然语言处理（NLP）的进步正在重塑金融实践。然而，这些模型在捕捉和应用特定金融领域的知识方面的能力尚不明确。特别是在广阔且复杂的印度金融背景下，这项研究填补了这一空白，旨在评估LLMs在金融、法律和定量推理方面的表现。为此，研究设计了CA-Ben基准，包含了印度特许会计师协会（ICAI）严格进行的各类考试题目的结构化问题解答数据集。
### Innovation
研究通过设计CA-Ben基准，首次系统评估了包括GPT-4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4在内的六种主流LLM在金融、法律和定量推理方面的能力。研究发现，Claude 3.5 Sonnet和GPT-4o在这次评估中表现最好，特别是在概念和法律推理方面；而在数值计算和法律解释方面，LLMs面临显著挑战。这表明了现有LLMs的优势与局限，并指出了未来改进的方向，特别是在定量分析和准确的法律解释方面，可能需要结合混合推理和检索增强生成方法进行改进。
### Conclusion
研究强调了CA-Ben基准对评估和改进LLMs在金融、法律和定量推理方面表现的重要性，同时也指出了未来的研究方向和改进方法。
## 62. `cs.AI` - EgoAdapt: 调适多感觉蒸馏和策略学习以实现高效的自身体验感知 [PDF](https://arxiv.org/pdf/2506.21080), [HTML](https://arxiv.org/abs/2506.21080)
### Authors
Sanjoy Chowdhury,Subrata Biswas,Sayan Nag,Tushar Nagarajan,Calvin Murdock,Ishwarya Ananthabhotla,Yijun Qian,Vamsi Krishna Ithapu,Dinesh Manocha,Ruohan Gao
### Background
现代感知模型在多感官自身体验任务中表现出卓越的性能，但通常需要大量的计算资源，这对实际部署提出了挑战，尤其是在资源受限的环境中。现有的模型在执行不同的自身体验感知任务时，如自身体验动作识别、主动讲话者定位和行为预测时，面临着高计算成本的挑战，这限制了它们的应用范围。
### Innovation
本文提出了一种名为EgoAdapt的框架，该框架自适应地执行跨模态蒸馏和策略学习，使自身体验感知任务能够在不同的情境下实现高效推理。EgoAdapt具有可调任务空间的策略模块，使其具有广泛的应用性。实验结果表明，EgoAdapt方法在EPIC-Kitchens、EasyCom和Aria Everyday Activities等三个具有挑战性的自身体验数据集上的GMACs、参数和能耗分别减少了最多89.09%、82.02%和9.6倍，同时在性能上与最先进的模型相当并在某些情况下超过了它们。
### Conclusion
本文提出的方法EgoAdapt通过自适应跨模态蒸馏和策略学习，显著提高了自身体验感知任务的效率，同时证明了在多个自身体验数据集上的性能优势。
## 63. `cs.AI` - ComRAG：基于动态向量存储的检索增强生成方法在工业实时社区问答中的应用 [PDF](https://arxiv.org/pdf/2506.21098), [HTML](https://arxiv.org/abs/2506.21098)
### Authors
Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan
### Background
社区问答（CQA）平台被认为是社区中的重要知识库，但在实时利用历史互动和领域知识方面仍存在挑战。现有方法经常未能有效利用外部知识，未能整合动态历史问答背景，或缺乏适合工业部署的记忆机制。
### Innovation
提出了一种名为ComRAG的新框架，用于工业实时CQA的检索增强生成。ComRAG通过基于质心的记忆机制整合静态知识和动态历史问答对，实现了检索、生成和高效存储三位一体的方法。在三个工业CQA数据集上评估表明，ComRAG在向量相似度上提高了25.9%，减少了8.7%到23.3%的延迟，并将迭代中的片段增长从20.23%降低到2.06%。
### Conclusion
ComRAG在工业CQA中表现出众，通过整合静态和动态知识，以及优化检索和生成机制，有效提升了实时系统的效果。
## 64. `cs.AI` - 通过后悔意识优化实现高效技能发现 [PDF](https://arxiv.org/pdf/2506.21044), [HTML](https://arxiv.org/abs/2506.21044)
### Authors
He Zhang,Ming Zhou,Shaopeng Zhai,Ying Sun,Hui Xiong
### Background
无监督技能发现的目标是在开放性强化学习中学习多样性和区分性的行为。现有方法主要通过纯探索、互信息优化和学习时间表示来提升多样性。尽管在探索方面表现良好，但在效率方面仍然受限，尤其是在高维情况下的表现尤为明显。
### Innovation
提出了一个基于时间表示学习的min-max博弈框架下的后悔意识方法。该方法通过增强可升级策略强度的方向扩展发现的技能空间。核心思想是技能发现是与策略学习对抗的，即弱策略技能应进一步探索，而收敛的技能不需要太多探索。通过使用后悔作为技能强度收敛度的评分，并通过可学习的技能生成器引导技能发现。为了防止退化，技能生成来自可升级的技能生成器群体。实验结果表明，该方法不仅在效率和多样性上优于基线方法，还在高维度环境中的零样本改进上实现了15%的提升。
### Conclusion
我们的方法在不同复杂度和维度的环境中均表现出了更高的效率和多样性。与现有方法相比，在高维度环境中实现了15%的零样本改进。
## 65. `cs.AI` - FeDa4Fair：用于公平性评估的客户端级联邦数据集 [PDF](https://arxiv.org/pdf/2506.21095), [HTML](https://arxiv.org/abs/2506.21095)
### Authors
Xenia Heilmann,Luca Corbucci,Mattia Cerrato,Anna Monreale
### Background
联邦学习（FL）可以让多个客户端协作训练模型而不共享客户端的私人数据，但公平性仍然是一个重要问题，因为客户端本地数据集中的偏差可能会影响整个联邦系统。客户端的数据分布差异可能导致对不同客户端来说公平性不同的模型。尽管文献中已有一些增强公平性的解决方案，大多数方法仅关注一个单一的敏感属性，通常为二元属性，而忽略了不同客户端多样且有时相互矛盾的公平性需求。这种有限的观点可能会限制不同客户端公平性干预的有效性。为了支持更稳健和可重复的联邦学习中的公平性研究，本研究旨在为全球和客户端层面提供公平性感知联邦学习方法的一致基准测试方法。
### Innovation
贡献了 FeDa4Fair，一个生成适用于评估在不同客户端偏差下公平联邦学习方法的特殊表数据集的库；发布了四个带有对应基准的偏见异质数据集，以便在受控环境中比较公平性缓解方法；提供了方便使用以评估这些数据集的公平性结果的功能。
### Conclusion
通过提供 FeDa4Fair，旨在为公平感知联邦学习方法的全球和客户端层面提供一致的基准测试方法，支持更稳健和可重复的公平性研究。
## 66. `cs.AI` - CovDocker: 利用任务、数据集和解决方案评估共价药物设计 [PDF](https://arxiv.org/pdf/2506.21085), [HTML](https://arxiv.org/abs/2506.21085)
### Authors
Yangzhe Peng,Kaiyuan Gao,Liang He,Yuheng Cong,Haiguang Liu,Kun He,Lijun Wu
### Background
分子对接在预测配体与靶标蛋白的结合模式中起着关键作用，共价相互作用因其强韧、持久的结合特性尤其有价值。然而，现有的大多数分子对接方法和深度学习方法在计算共价键形成及其相关结构变化方面做得并不充分。本文基于此研究背景，介绍了CovDocker基准工具，旨在更好地捕捉共价结合的复杂性，将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接，从而填补这一空白。
### Innovation
本文提出了一种新颖的共价对接基准CovDocker，该工具通过将共价对接过程分组成反应位点预测、共价反应预测和共价对接三个主要任务，进一步细化了共价结合的研究。通过使用如Uni-Mol和Chemformer等先进模型，该基准工具建立了基线性能并证明了其在准确预测相互作用位点和模拟共价结合过程中分子转变的有效性，从而有力推进了共价药物设计研究，并强调了数据驱动方法在加速发现选择性共价抑制剂方面的潜力。
### Conclusion
CovDocker作为严苛的研究框架，被用来推进共价药物设计研究，证实了适用于共价药物设计的数据驱动方法对理解和应对治疗开发中的关键挑战具有重要意义。
## 67. `cs.AI` - PhishKey: 一个基于中心点的增强型钓鱼检测新方法，利用自适应HTML组件提取 [PDF](https://arxiv.org/pdf/2506.21106), [HTML](https://arxiv.org/abs/2506.21106)
### Authors
Felipe Castaño,Eduardo Fidalgo,Enrique Alegre,Rocio Alaiz-Rodríguez,Raul Orduna,Francesco Zola
### Background
钓鱼攻击是网络安全领域的一个重要威胁，它在不断进化以绕过检测机制并利用人类的漏洞。现有的钓鱼检测方法在其适应性、健壮性和效率方面面临挑战，因此需要一种新的解决方案来应对这些挑战。
### Innovation
PhishKey 引入了一种新的钓鱼检测方法，通过自动从混合源中提取特征来增强适应性、健壮性和效率。该方法结合了基于字符级别的处理与卷积神经网络（CNN）进行URL分类，以及一个基于中心点的关键内容钓鱼提取器（CAPE）用于HTML内容的词级处理。CAPE技术减少了噪声，确保了样本处理的完整性，避免了输入数据的裁剪操作。预测结果通过软投票集成来实现更准确可靠地分类。
### Conclusion
对四个最先进的数据集的实验评估表明，PhishKey 有效提升了钓鱼检测的性能。它可以达到高达98.70%的F1分数，并且对诸如注入攻击之类的对抗性操纵具有很强的抵抗力，且性能下降最小。
## 68. `cs.AI` - Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models [PDF](https://arxiv.org/pdf/2506.21119), [HTML](https://arxiv.org/abs/2506.21119)
### Authors
Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu
### Background
细调是一种利用基于Transformer的语言模型执行下游任务的有希望的技术。随着模型规模的不断扩大，更新所有模型参数的成本也在不断增加。参数高效细调方法通过有选择地更新一小部分参数有效地解决了这一问题。然而，传统的细调以及大多数现有的参数高效细调方法在更新参数时忽略了不同Transformer块之间的不平等贡献，从而导致计算资源分配非常低效。随着模型规模的增加，这一问题越发严重。
### Innovation
本文提出了Progtuning，一种与渐进式学习相结合的新颖细调框架，针对基于Transformer的语言模型。具体而言，Progtuning根据贡献程度逐阶段减少更新的Transformer块的数量。与传统方法相比，这种方法优化了资源分配，将需要更新的参数减少约25%，同时仍能保持竞争力。并且，它还具有高度的适应性，能够与参数高效细调方法很好地结合，表现出色，适用于各种适应场景。
### Conclusion
Progtuning通过逐阶段减少需要更新的Transformer块的数量，优化了资源分配，同时保持了竞争力，并能够很好地适应各种适应场景，因此在参数高效细调方法的应用上具有重要意义。
## 69. `cs.AI` - 抗脆性强化学习中针对敌对环境的无人机去冲突稳健策略切换 [PDF](https://arxiv.org/pdf/2506.21127), [HTML](https://arxiv.org/abs/2506.21127)
### Authors
Deepak Kumar Panda,Weisi Guo
### Background
无人驾驶航空器（UAVs）的导航自动化增加了它们遭受对抗性攻击的风险，这些攻击通过传感器操作利用强化学习（RL）中的漏洞。虽然现有的鲁棒RL方法试图减轻这些威胁，但它们在针对超出理想值分布的出界转移方面的能力有限，因为它们主要针对的是固定扰动。
### Innovation
本文提出了一种抗脆性RL框架，该框架通过引入基于折扣Thompson采样的切换机制，增强了对更广泛分布转移的适应性。该机制动态选择多个鲁棒策略以最小化由对抗性诱导的状态-动作-价值分布转移。此外，通过优化折扣Thompson采样来最小化分布转移引起的总体遗憾，从而实现对未见过的对抗性攻击的有效适应，从而增强了抗脆性。
### Conclusion
广泛的数值仿真在具有多种动态三维障碍物的复杂导航环境中验证了所提出框架的有效性，表现出了较短的导航路径长度和更高的无冲突导航轨迹生成率，优于现有的鲁棒RL技术，尤其是在面对更强的项目梯度下降（PGD）和欺骗性攻击时。
## 70. `cs.AI` - 线性为基础的神经网络压缩 [PDF](https://arxiv.org/pdf/2506.21146), [HTML](https://arxiv.org/abs/2506.21146)
### Authors
Silas Dobler,Florian Lemmerich
### Background
在神经网络压缩中，大多数现有方法通过测量重要性和冗余性来减少不必要的参数。已有高度优化的解决方案需要进一步改进，本文提出了基于线性的压缩方法作为一种新的减少权重的方式，它允许合并后续层，从而降低神经网络的权重.
### Innovation
提出了一种基于线性的压缩方法，适用于具有ReLU类似激活函数的神经网络，这种激活函数使得几乎总是被激活的神经元表现出线性行为，允许合并后续层，从而实现无损压缩，缩小模型大小超过原来的一半。与基于重要性的剪枝方法结合使用时，效果良好，展示了不同压缩技术的有效结合.
### Conclusion
本文通过理论和实验验证，提出了一种新的压缩方法，能够将大多数测试模型无损压缩至原始模型大小的1/4，同时还验证了与基于重要性的剪枝方法结合使用的可能性，为更小、更高效的神经网络模型铺平了道路.
## 71. `cs.AI` - IPFormer-VideoLLM: 提升多模态视频理解在多镜头场景中的能力 [PDF](https://arxiv.org/pdf/2506.21116), [HTML](https://arxiv.org/abs/2506.21116)
### Authors
Yujia Liang,Jile Jiao,Zhicheng Wang,Xuetao Feng,Zixuan Ye,Yuan Wang,Hao Lu
### Background
视频大语言模型（VideoLLMs）在理解和处理视频方面展现出了出色的能力，但它们在多镜头场景中的处理能力尚未充分开发。具体来说，这类模型在处理具有不同摄像角度或场景变化的视频剪辑时常常遇到困难。这一挑战会导致实例身份遗忘以及关键帧忽视等问题。现有数据集缺乏针对多镜头场景的标注，是造成这一问题的主要原因之一。目前的模型通常以离散或有损的方式编码实例特征，因而容易丢失关键信息。本文作者针对这一问题，首先引入了一个新的数据集MultiClip-Bench，旨在为多镜头场景训练和评估视频大语言模型提供支持。同时，作者提出了一种新的模型IPFormer-VideoLLM，通过引入实例级特征作为实例提示来改善模型在多镜头场景中的表现，从而显著提高了视频多场景理解的能力.
### Innovation
文章创新性地提出了一种新的数据集MultiClip-Bench，专门针对多镜头场景训练和评估大模型；同时，作者提出了一种新的模型IPFormer-VideoLLM，通过注入实例层面的特征作为实例提示，利用高效注意力连接器实现了场景间的实例特定信息聚合。这种方法使得模型在多场景视频理解方面表现显著提升，且在多种视频评估指标上展现出独特优势。
### Conclusion
本文通过引入新的数据集MultiClip-Bench和构建新型模型IPFormer-VideoLLM，显著提升了视频大语言模型在多镜头场景理解方面的表现，并通过实验证明了这两种创新方法的有效性，为未来研究提供了新的视角。
## 72. `cs.AI` - 基于Transformer的空间-时间反事实结果估计 [PDF](https://arxiv.org/pdf/2506.21154), [HTML](https://arxiv.org/abs/2506.21154)
### Authors
He Li,Haoang Chi,Mingyu Liu,Wanrong Huang,Liyang Xu,Wenjing Yang
### Background
现实世界本身具有时间和空间的维度。因此，具有空间-时间属性的反事实结果估算是一个关键问题。然而，以前的方法基于传统的统计模型，这些模型在性能和泛化能力方面仍然存在局限性。
### Innovation
本文提出了一种新的框架，利用Transformer来估算具有时空属性的反事实结果，这种新框架具有更强的估算能力。在温和假设下，该框架中的估算器是一致的，并且渐近正态的。通过仿真实验和真实数据实验，验证了该方法的有效性，仿真实验表明，我们的估算器比基线方法具有更强的估算能力，真实数据实验则验证了冲突对哥伦比亚森林损失的因果效应。
### Conclusion
实验数据提供了关于冲突对哥伦比亚森林损失影响的有价值结论，相关的源代码可在指定的URL获取。
## 73. `cs.AI` - 使用噪声标签的心脏MRI myocardial scar分割的稳健深度学习 [PDF](https://arxiv.org/pdf/2506.21151), [HTML](https://arxiv.org/abs/2506.21151)
### Authors
Aida Moafi,Danial Moafi,Evgeny M. Mirkes,Gerry P. McCann,Abbas S. Alatrany,Jayanth R. Arnold,Mostafa Mehdipour Ghazi
### Background
从心脏MRI中准确分割心肌疤痕对于临床评估和治疗规划至关重要。现有方法难以应对标签噪声、数据异质性和类别不平衡等问题，需要一种稳健的深度学习流水线来解决这些问题，以实现全自动心肌疤痕检测和分割。
### Innovation
本文提出了一种通过微调现有最佳模型来解决标签噪声、数据异质性和类别不平衡问题的稳健深度学习流水线。该方法使用Kullback-Leibler损失和大量数据增强，能够在即使标签噪声的情况下生成准确且平滑的分割结果，尤其在噪声标签下优于现有模型，表现出强大的泛化能力。
### Conclusion
本文的方法在急性与慢性病例中均表现出较高的评估性能，特别是在分布外测试集中表现出良好的稳健性和通用性。这些结果为自动心肌疤痕量化建立了可靠的基础，并支持了深度学习在心脏成像中的更广泛应用。
## 74. `cs.AI` - DBConformer: 双分支卷积Transformer用于EEG解码 [PDF](https://arxiv.org/pdf/2506.21140), [HTML](https://arxiv.org/abs/2506.21140)
### Authors
Ziwei Wang,Hongbin Wang,Tianwang Jia,Xingyi He,Siyang Li,Dongrui Wu
### Background
EEG脑机接口（BCI）技术通过变换自发/诱发神经活动为外部通信的控制命令。虽然卷积神经网络（CNN）依然是EEG解码的主流基础模型，但它们固有的短受域难以捕捉长时间依赖和跨通道关系。近期的CNN-Transformer（Conformers）混合模型虽在一定程度上解决了这一问题，但大多数设计采用串行架构，导致局部和全局特征的最优整合受限，且往往忽略了明确的通道间模型。
### Innovation
本文提出了DBConformer，一种专为EEG解码设计的双分支卷积Transformer网络。该网络结合了时空Conformer模块，分别用于建模长程时间依赖和提取跨通道交互，同时捕捉EEG信号中的时空模式。轻量级的通道注意力模块进一步细化了空间表示，通过数据驱动的方式赋予EEG通道不同的重要性。该方法在五个运动想象（MI）数据集和两个癫痫检测数据集下的三种评估设置下，广泛实验表明DBConformer在性能上持续超越10种竞争基准模型，参数量比高容量的EEG Conformer基准模型少八倍以上。此外，可视化结果显示DBConformer提取的特征具有生理可解释性，与运动感觉先验相一致，这使得DBConformer在鲁棒性和可解释性方面表现出更强的优势。
### Conclusion
DBConformer因其实现的优异性能和解释性，成为可靠的EEG解码方法，代码已公开。
## 75. `cs.AI` - 通过注意力引导的图学习实现可解释的层次概念推理 [PDF](https://arxiv.org/pdf/2506.21102), [HTML](https://arxiv.org/abs/2506.21102)
### Authors
David Debot,Pietro Barbiero,Gabriele Dominici,Giuseppe Marra
### Background
概念基模型（CBMs）是一种深度学习模型，通过使用高层概念来解释预测，从而提供解释性。这些模型首先预测概念，然后使用这些概念来执行下游任务。然而，目前的CBMs仅对最终任务预测提供解释性，而概念预测本身通常是由黑盒神经网络完成的。该研究旨在解决这一限制，提出了一种新的CBM，即层次概念记忆推理器（H-CMR），它为概念和任务预测都提供了解释性。H-CMR利用一个学习得到的有向无环图来建模概念之间的关系，其中边表示逻辑规则，以概念之间的其他概念来定义概念。在推理过程中，H-CMR使用神经注意力机制选择这些规则的子集，并在层次上应用它们来预测所有概念和最终任务。实验结果表明，H-CMR与现有最佳性能相当，同时通过概念和模型干预增强了人类交互，前者显著提高了推理时的准确度，后者在背景知识可用时提高了数据效率和训练效率。
### Innovation
提出了层次概念记忆推理器（H-CMR），这是一种新的可解释概念基模型（CBM），既能解释概念预测也能解释任务预测。H-CMR使用学习得到的有向无环图来建模概念之间的关系，并通过神经注意力机制在推理过程中选择和应用这些规则，从而实现了层次的推理和概念解释。此外，H-CMR通过概念干预和模型干预增强了人类与模型的交互。
### Conclusion
H-CMR 与现有最佳性能相当，同时通过概念和模型干预增强了人类交互。其中，概念干预显著提高了推理时的准确度，而模型干预在背景知识可用时提高了数据效率和训练效率。
## 76. `cs.AI` - 基于课程引导的抗脆性强化学习方法以在观测空间攻击下的无人机冲突解除实现安全飞行 [PDF](https://arxiv.org/pdf/2506.21129), [HTML](https://arxiv.org/abs/2506.21129)
### Authors
Deepak Kumar Panda,Adolfo Perrusquia,Weisi Guo
### Background
在安全关键系统中部署的强化学习（RL）策略，如在动态空域中用于无人机（UAV）导航的策略，可能会受到观测空间中的离分布攻击（OOD adversarial attacks）。这些攻击会导致观测分布的变化，显著降低价值估计，从而导致不安全或次优的决策，使现有策略变得脆弱。鉴于此问题，本文分析了现有 RL 策略在应对观测空间攻击时的脆弱性，并提出了一个新的抗脆性强化学习框架。
### Innovation
提出了一个抗脆性强化学习框架，该框架旨在适应渐增的对抗性扰动课程。该框架引入了一个模拟攻击者，该攻击者逐步增加观测空间中扰动的强度，从而使 RL 剂能够适应和泛化到更广泛的 OOD 观测，并预测以前未见过的攻击。该框架通过 Wasserstein 距离最小化在渐增扰动观测中逐步对齐专家指导的评论来实施这些边界。研究结果表明，该抗脆性策略在面对投影梯度下降（PGD）和 GPS 伪造攻击时，始终优于标准的和鲁棒的强化学习基线，实现了更高的累计奖励和更少的冲突事件。
### Conclusion
这些结果表明，抗脆性强化学习在存在演化威胁情景的环境中，对于安全和稳健的决策制定具有实际和理论上的可行性。这个框架可以通过强化学习适应和泛化到更广泛的 OOD 观测空间，以提高其在安全关键系统中的鲁棒性和抗脆性表现。
## 77. `cs.AI` - 合成需求的质量如何？评估LLM生成的数据集在AI4RE中的表现 [PDF](https://arxiv.org/pdf/2506.21138), [HTML](https://arxiv.org/abs/2506.21138)
### Authors
Abdelkarim El-Hajjami,Camille Salinesi
### Background
目前，公开可用且有标注的需求数据集仍然不足，这严重阻碍了人工智能在需求工程（AI4RE）的应用进展。虽然大规模语言模型（LLM）具有合成数据生成的潜在能力，但控制和优化生成数据质量的系统方法仍处于探索阶段。
### Innovation
本文介绍了一个名为Synthline v1的增强型产品线方法，用于生成合成需求数据，它扩展了早期版本（v0）的功能，并引入了高级生成策略和策展技术。此外，通过四个提示策略、自动化提示优化和生成后策凭证据质量产生了重要影响。研究发现提示策略和自动化提示优化在不同分类任务上的效果，特别是在多功能性分类上的显著提升（+32.5分）。此外，合成需求数据在某些安全性和缺陷分类任务上展现出优于人类撰写的源头数据（分别提高7.8分和15.4分）
### Conclusion
合成需求数据可以与或优于人类撰写的源头数据，尤其是对于安全性和缺陷分类任务表现最为显著。这些发现对AI4RE具有实用性指导意义，显示了一条通过系统合成生成缓解数据稀缺性的可行路径。
## 78. `cs.AI` - 少数乐器检测的分层深度学习方法 [PDF](https://arxiv.org/pdf/2506.21167), [HTML](https://arxiv.org/abs/2506.21167)
### Authors
Dylan Sechet,Francesca Bugiotti,Matthieu Kowalski,Edouard d'Hérouville,Filip Langiewicz
### Background
在音乐信息检索中，识别音频片段中的乐器活动至关重要，对于音乐分类和发现具有重要意义。先前的深度学习研究主要集中在数据充足的大类乐器上。近期研究表明，即使在细分类标注有限的情况下，分层分类方法也能有效检测管弦乐的乐器活动。基于哈农库特-萨克斯分类系统，该研究使用MedleyDB数据集评估了分层分类系统，该数据集涵盖多种乐器和音乐风格，具有多样性和丰富性。研究探讨了如何将分层结构整合到模型中，并测试了一种新的分层音乐预测模型方法，以实现更可靠的整体乐器检测，填补了详细乐器识别和组级识别之间的空白，为该领域的进一步发展铺平了道路。
### Innovation
提出了少数乐器检测的分层深度学习方法，基于哈农库特-萨克斯分类系统，使用MedleyDB数据集进行评估。该研究通过引入分层结构整合到模型中，并测试了一种新的分层音乐预测模型，实现了更可靠的总体乐器检测，填补了详细乐器识别和组级识别之间的空白，为该领域的进一步发展提供了新方法。
### Conclusion
该研究展示了一种更可靠的整体乐器检测方法，通过填补详细乐器识别和组级识别之间的空白，为乐器分类和发现提供了更精确的手段，为该领域的未来研究奠定了基础。
## 79. `cs.AI` - 维护MTEB：嵌入基准的长期实用性和可重复性 [PDF](https://arxiv.org/pdf/2506.21182), [HTML](https://arxiv.org/abs/2506.21182)
### Authors
Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen
### Background
大规模文本嵌入基准（MTEB）已成为文本嵌入模型的标准评估平台。尽管先前的工作已经确定了核心基准方法论，但本文重点介绍了确保MTEB持续可重复性和扩展性的工程方面。文章详细说明了保持连续集成管道稳健，验证数据集完整性的方法，自动化测试执行以及评估基准结果的泛化性。此外，文章还讨论了如何处理社区贡献并扩展基准以添加新任务和数据集的策略。这些工程实践使MTEB能够成为更加全面的同时仍能保持质量和相关性。我们的经验对于基准维护者确保机器学习评估框架中的实用性和可重复性具有重要意义。MTEB存储库可在特定链接找到。
### Innovation
提出了维护稳健的持续集成管道的方法，验证数据集完整性，自动化测试执行，评估基准结果的泛化性。讨论了如何处理社区贡献并扩展基准以添加新任务和数据集的策略。这些工程实践有助于MTEB成为更加全面的同时仍保持质量和相关性。
### Conclusion
这些工程实践在确保MTEB的实用性和可重复性方面发挥了关键作用，使之能够成为更加全面的同时仍保持质量和相关性的基准。我们的经验为其他基准维护者提供了宝贵的经验教训，帮助他们确保机器学习评估框架中的实用性和可重复性。MTEB存储库已公开。
## 80. `cs.AI` - T³：基于大型语言模型的多级树形自动程序修复 [PDF](https://arxiv.org/pdf/2506.21211), [HTML](https://arxiv.org/abs/2506.21211)
### Authors
Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li
### Background
自动程序修复（APR）是软件开发和维护的核心技术之一，旨在能够利用大型语言模型（LLMs）和链式思考（CoT）技术进行自动缺陷修复，减少人工干预。然而，这些技术在处理复杂逻辑和多步推理时的应用仍然不足，特别是对于APR领域的应用存在局限性。因此，研究人员开始系统地评估多种CoT技术在APR任务中的性能，并提出了一种新颖的方法T³，将LLMs的强大推理能力与树搜索相结合，有效地提高了生成候选修复解决方案的准确性。
### Innovation
T³框架将大型语言模型的强大推理能力与树搜索技术相结合，有效地提高了生成候选修复解决方案的准确性。此外，T³还为优化APR任务中的样本选择和修复策略提供了有价值的指导，建立了高效的自动化调试框架。
### Conclusion
T³框架提供了一个强大的框架，用于实现高效的自动化调试，通过结合LLMs的强大推理能力和树搜索技术，显著提高了自动程序修复的精度和效率。
## 81. `cs.AI` - BitMark for Infinity: 对比特斯特拉-无穷模型进行比特级自回归图像生成模型的水印 [PDF](https://arxiv.org/pdf/2506.21209), [HTML](https://arxiv.org/abs/2506.21209)
### Authors
Louis Kerner,Michel Meintz,Bihe Zhao,Franziska Boenisch,Adam Dziedzic
### Background
最新的文本到图像模型如Infinity可以以前所未有的速度生成超真实的图像。这些模型以位级自回归的方式对几乎无限数量的离散标记进行操作。然而，这些模型强大的生成能力带来了越来越大的风险：随着它们生成的内容在互联网上越来越多地被使用，这些内容可能会被提取并用作新的训练数据，甚至可能被同一个模型重新训练。这种现象会导致模型崩溃，即通过反复训练生成的内容（尤其是模型自己的早先版本），模型性能会逐渐下降。一种有前途的缓解策略是水印技术，可以在生成的图像中嵌入人类无法察觉但可以检测的信号，以便识别生成内容。
### Innovation
我们提出了BitMark，一种针对Infinity的鲁棒的比特级水印框架。我们的方法在Infinity的图像生成过程中直接在令牌流的比特级别上嵌入水印，跨越多个尺度（即分辨率）。这种方式微妙地影响比特，以保持视觉保真度和生成速度，同时保持对各种移除技术的鲁棒性。此外，这种方法还表现出高度的放射性，即当水印生成的图像用于训练另一个图像生成模型时，该第二个模型的输出也将携带水印。当仅在水印图像上微调扩散或图像自回归模型时，这种放射性痕迹仍然可以检测到。总体而言，我们的方法为通过可靠的生成输出检测防止图像生成模型的模型崩溃提供了一个原则性的步骤。
### Conclusion
我们的方法为防止图像生成模型的模型崩溃提供了一个概念性的步骤，通过使生成输出的可靠检测成为可能。
## 82. `cs.AI` - 任务感知的KV压缩以实现成本效益的长视频理解 [PDF](https://arxiv.org/pdf/2506.21184), [HTML](https://arxiv.org/abs/2506.21184)
### Authors
Minghao Qin,Yan Shu,Peitian Zhang,Kun Lun,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu
### Background
现有的多模态大型语言模型（MLLM）在长视频理解（LVU）上仍面临重大挑战，主要是因为高昂的计算成本。最近的研究尝试通过KV压缩来缓解这个问题，但这些方法在高压缩比下往往会导致重要信息的大量丢失。这些方法效果不理想，主要在于不能灵活保留关键视频信息以适应不同的LVU任务需求。
### Innovation
本文提出了一种新的方法，称为Video-X^2L，它通过两级KV压缩和选择性KV加载操作，灵活地保存了每个LVU任务的关键视频信息。这种方法保证在压缩KV的同时，能够捕获视频的细粒度细节，同时减少计算成本，且无需额外的训练，可以直接兼容现有的KV压缩的MLLM。
### Conclusion
将Video-X^2L应用于多种流行的LVU基准测试，包括VideoMME、MLVU、LongVideoBench和VNBench，实验结果表明，Video-X^2L在保持压缩效果的同时显著优于现有的KV压缩方法，大幅节省了计算成本。
## 83. `cs.AI` - 一种将3D超声集成到经皮肝肿瘤消融中的新型框架 [PDF](https://arxiv.org/pdf/2506.21162), [HTML](https://arxiv.org/abs/2506.21162)
### Authors
Shuwei Xing,Derek W. Cool,David Tessier,Elvis C.S. Chen,Terry M. Peters,Aaron Fenster
### Background
3D超声成像在肝脏肿瘤经皮消融治疗中表现出显著优势，但其临床应用仍受限于肿瘤在超声图像中识别的困难。现有的3D超声成像在治疗领域中的应用尚不广泛，因此，仍需通过技术创新来完善3D超声的应用流程，特别是提高其在图像注册和多模态图像可视化方面的表现，以克服肿瘤识别难题，推动其在治疗领域的发展和应用。
### Innovation
提出了一种创新的框架，重点是开发出一种实用的2D超声-CT/MRI图像配准方法，利用3D超声作为中介简化配准工作；并提出了一种直观的多模式图像可视化技术，以提高配准工作流程的效率。实验结果表明，2D超声-CT/MRI图像配准方法能够有效地实现约2-4毫米的路标距离误差，并在每对图像上仅需0.22秒的运行时间。与刚性配准相比，非刚性配准可将平均对齐误差减少约40%。
### Conclusion
通过该集成框架，3D超声成像在经皮肝肿瘤消融中的应用能力得到了提高，证明了3D超声在临床干预中的治疗潜力有望进一步扩大。
## 84. `cs.AI` - Agent-RewardBench：在感知、规划和安全领域跨现实多模态代理的统一奖励建模基准 [PDF](https://arxiv.org/pdf/2506.21252), [HTML](https://arxiv.org/abs/2506.21252)
### Authors
Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao
### Background
随着多模态大规模语言模型（MLLMs）的进步，多模态代理在现实世界任务，如网络导航和嵌入式智能方面展现出前景。然而，由于缺乏外部反馈，这些代理在自我纠正和泛化方面存在困难。一种有前景的方法是使用奖励模型作为外部反馈，但还缺乏如何选择适合代理的奖励模型的明确策略。为此，需要构建一个专门针对代理的奖励基准。
### Innovation
本文提出了Agent-RewardBench，一种旨在评估MLLMs的奖励模型能力的基准。该基准具有三大特点：(1) 多维度和真实世界的代理场景评估，涵盖感知、规划和安全七个场景；(2) 步骤级别的奖励评估，允许在任务的各个步骤中评估代理的能力，提供更细腻的性能视图，特别是在规划过程中的表现；(3) 适当的难度和高质量，通过精心选择10个不同的模型，控制难度确保任务的挑战性，并进行人工验证确保数据的完整性。实验结果表明，即使是最先进的多模态模型，在代理奖励建模方面也表现出有限的效果，强调了专门训练的重要性。
### Conclusion
实验结果显示，即使是最先进的多模态模型，在代理奖励建模方面的表现也有限，这突显了专门训练的重要性。代码可在GitHub获取。
## 85. `cs.AI` - DiLoCoX：分布式集群中低通信的大规模训练框架 [PDF](https://arxiv.org/pdf/2506.21263), [HTML](https://arxiv.org/abs/2506.21263)
### Authors
Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich
### Background
基础模型，尤其是大规模语言模型（LLMs），在分布式训练过程中需要大量通信。这导致它们高度依赖于具有快速可靠连接的集中式集群。当处理超过100亿参数的模型时，能否在慢速网络上进行训练，进而利用分散式的集群资源？
### Innovation
本文提出了DiLoCoX，这是一种结合了管道并行、双优化器策略、一步延迟重叠通信和局部训练以及自适应梯度压缩方案的大规模分布式集群训练框架。这一组合显著提高了参数规模和模型预训练的速度。通过理论分析和实验证明了一步延迟重叠通信和局部训练、自适应梯度压缩方案的优势。结果显示，DiLoCoX 在1Gbps网络上可以进行一个107B基础模型的预训练，并且在分布式训练中比标准AllReduce快357倍的同时保持了微乎其微的模型收敛退化。
### Conclusion
至我们所知，这是首次成功将分布式训练框架应用于超过100亿参数的模型。
## 86. `cs.AI` - 将车辆声学数据集成以增强城市交通管理：苏州速度分类研究 [PDF](https://arxiv.org/pdf/2506.21269), [HTML](https://arxiv.org/abs/2506.21269)
### Authors
Pengfei Fan,Yuli Zhang,Xinheng Wang,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Shangbo Wang
### Background
本文介绍了并公开发布了苏州城市道路声学数据集（SZUR-Acoustic Dataset），该数据集包括了全面的数据采集协议和标记指南，以确保实验工作的透明性和可重现性。该研究旨在结合车辆噪声与驾驶速度之间的耦合模型，提出了一种双模态特征融合的深度卷积神经网络（BMCNN）方法。在预处理阶段，通过一种自适应去噪和规范化策略来抑制环境背景噪音，网络架构由并行分支分别提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，在中间特征空间通过跨模态注意力机制进行融合，充分利用了时频信息。实验结果表明，BMCNN在SZUR-Acoustic Dataset上的分类准确率为87.56%，在公共IDMT-Traffic数据集上的分类准确率达到了96.28%。在苏州数据集上进行的消融研究和鲁棒性测试进一步验证了每个模块对性能增强和防止过拟合的贡献。该基于声学的速度分类方法可以集成到智能城市交通管理系统中，实现实时噪音监控和速度估计，从而优化交通流量控制，减少路边噪音污染，支持可持续城市规划。
### Innovation
本文提出了一种双模态特征融合的深度卷积神经网络（BMCNN），在预处理阶段应用了自适应去噪和规范化策略来抑制环境背景噪音，并在网络架构中利用跨模态注意力机制融合梅尔频率倒谱系数和小波包能量特征，以充分利用时频信息。该方法的实验结果表明其在多个数据集上的强大分类性能，并通过消融研究和鲁棒性测试进一步验证了模型的有效性。
### Conclusion
本文提出了基于声学的速度分类方法，并展示了其在多个数据集上的高分类准确率，同时通过消融研究和鲁棒性测试验证了模型的有效性。该方法可以集成到智能城市交通管理系统中，实现实时噪音监控和速度估计，有助于优化交通流量控制、减少路边噪音污染和支持可持续城市规划。
## 87. `cs.AI` - 使用自回归语言模型在视觉接地对话中检测指示表达 [PDF](https://arxiv.org/pdf/2506.21294), [HTML](https://arxiv.org/abs/2506.21294)
### Authors
Bram Willemsen,Gabriel Skantze
### Background
本文探索了仅使用文本的自回归语言模型方法在视觉接地对话中提取指示表达的应用。具体来说，研究关注局部语言上下文如何能有效地帮助识别有视觉感知对象的提及。研究通过微调一个预训练的大规模语言模型，利用下一个标记预测对文本中的提及跨度进行标注，从而进行讨论。研究结果表明，即使使用中等大小的语言模型、相对较小的数据集以及参数高效微调，仅依赖文本的方法仍能取得一定的效果。但同时也指出，该任务本质上是一个多模态问题，单一模态方法存在一定的局限性。
### Innovation
本文创新地提出了使用大规模语言模型对视觉接地对话中的提及进行标注的研究，主要特点是仅依赖文本，无需显式利用视觉信息。这种方法通过下一个标记预测的方式，对提及的边界进行标注，从而进行局部语境下的指示表达检测。这种方法的优势在于相对较少的数据需求和高效的参数微调。
### Conclusion
尽管本文的研究结果表明，仅依赖语言模型的方法在一定程度上是有效的，但对于更精细的指示表达检测而言，该任务本质上是一个多模态问题，因此单一模态方法存在局限性，未来可能需要结合多模态信息以提高检测精度。
## 88. `cs.AI` - 关于一端加权深度多项式逼近的研究 [PDF](https://arxiv.org/pdf/2506.21306), [HTML](https://arxiv.org/abs/2506.21306)
### Authors
Kingsley Yeon,Steven B. Damelin
### Background
在有理逼近理论中，某些非光滑或奇异函数，如|x| 和 x^(1/p)，可以用具有根指数收敛特征的有理函数高效逼近。多项式逼近则仅能以杰克逊定理所描述的代数收敛速度逼近。近期研究表明，即使没有光滑性，组合多项式架构也能恢复指数逼近速度。本文探讨了一类针对一边增长另一边衰减的不对称函数的加权深度多项式逼近方法，通过结合可训练的深度多项式和单边权重，同时捕捉局部非光滑性和全局增长特性。
### Innovation
本文提出了一种针对具有不对称行为的函数的加权深度多项式逼近方法，这类函数在一侧无界增长，而在另一侧衰减。这种方法通过对深度多项式应用可学习的单边权重来同时捕捉局部非光滑性和全局增长特性。实验表明，这种方法在相同参数数量下优于泰勒多项式、切比雪夫多项式和标准深度多项式逼近。作者还提出了一种基于图结构的参数优化策略来实现这些逼近的实践优化。
### Conclusion
本文引入了一种针对具有不对称行为的函数的加权深度多项式逼近方法，证明了该方法在参数数量相同的情况下优于现有方法，并提出了一种图结构参数化策略来优化这些逼近。
## 89. `cs.AI` - 从链上到宏观：评估数据源多样性在加密货币市场预测中的重要性 [PDF](https://arxiv.org/pdf/2506.21246), [HTML](https://arxiv.org/abs/2506.21246)
### Authors
Giorgos Demosthenous,Chryssis Georgiou,Eliada Polydorou
### Background
本研究探讨了数据源多样性对加密货币预测模型性能的影响，通过整合技术指标、链上指标、情绪与兴趣指标、传统市场指数和宏观经济指标等不同类别的数据。研究引入了Crypto100指数，代表市值前100的加密货币，并提出了一种新型特征减少算法，用于识别来自多样数据源的最有影响力和最 resilient 的特征。研究通过全面实验表明，数据源多样性可以显著提升预测模型在不同时间范围内的预测性能。短中期预测的重要性和宏观经济指标及传统市场指数在长期内的重要性研究结果揭示了加密货币市场的驱动因素，并为开发更准确和更稳健的预测模型奠定了基础。
### Innovation
本研究创新性地引入了Crypto100指数，并提出了一种新型特征减少算法，能够从多样性数据源中识别出关键的、有影响的特征；此外，研究揭示了短中期预测与长期预测的重要性变化，并强调了链上指标的主导地位及其对市场的潜在影响
### Conclusion
数据源多样性对加密货币预测模型的性能有显著的正面影响，尤其是在不同时间范围内的预测中。链上指标对于短期和长期预测都至关重要，而在长期预测中，传统市场指数和宏观经济指标的重要性也在增加。结合多样数据源的利用显著提高了预测模型的准确性。这些发现有助于揭示短期和长期推动加密货币市场的主要因素，并为开发更准确和更稳健的预测模型奠定了基础。
## 90. `cs.AI` - 基于分层输入依赖状态空间模型的整体手术阶段识别 [PDF](https://arxiv.org/pdf/2506.21330), [HTML](https://arxiv.org/abs/2506.21330)
### Authors
Haoyang Wu,Tsun-Hsuan Wang,Mathias Lechner,Ramin Hasani,Jennifer A. Eckhoff,Paul Pak,Ozanan R. Meireles,Guy Rosman,Yutong Ban,Daniela Rus
### Background
在机器人辅助手术中，对手术工作流程的分析至关重要，然而长时间的手术过程对全面的视频分析造成了巨大挑战。近年来的方法主要依赖于变压器模型，但其二次注意力机制限制了对长时间手术视频的高效处理。
### Innovation
本文提出了一种新颖的分层输入依赖状态空间模型，该模型利用状态空间模型的线性扩展特性，能够对完整的视频进行决策判断，同时捕捉局部和全局动态。框架内包含一个时间上一致的视觉特征提取器，该提取器将状态空间模型头部添加到视觉特征提取器，以传播时间信息。该模型由两个关键模块组成：一个局部聚合状态空间模型块，有效捕获复杂的局部动态，以及一个全局关系状态空间模型块，建模整个视频中的时间依赖性。该模型通过混合离散-连续监督策略进行训练，其中离散相位标签和连续相位进展信号在网络中传播。实验结果表明，本文方法在Cholec80、MICCAI2016和Heichole数据集上的性能明显优于当前最先进的方法（分别提高了2.8%、4.3%和12.9%）
### Conclusion
我们的方法在所有评估数据集上都优于最先进的方法，表明该框架的有效性。代码将在论文接受后公开。
## 91. `cs.AI` - 人类与AI协同创作系统的系统综述 [PDF](https://arxiv.org/pdf/2506.21333), [HTML](https://arxiv.org/abs/2506.21333)
### Authors
Saloni Singh,Koen Hndriks,Drik Heylen,Kim Baraka
### Background
随着协同创造力社区的发展，人们正在开发更复杂且个性化的系统来支持和增强人类的创造力。过去的系统设计考虑可以作为未来系统的基础。为了推进这一领域，研究团队进行了一项针对62篇有关协同创作系统的文献的系统性回顾，这些系统涵盖了视觉艺术、设计和写作等多个应用领域，在这些领域中，AI不仅作为工具，更作为创作过程中的积极合作者。
### Innovation
通过系统文献回顾，研究者确定了多个关键的系统设计维度，包括创作过程的阶段、创造性任务、系统的行为、用户控制、系统实体以及AI模型类型。研究发现，提供较高用户控制的系统能提高满意度、建立更多的信任感并增强对创作成果的归属感。主动系统在适应性和语境敏感性方面也能增强合作。研究还提取了24项设计考量，突出了鼓励用户外部化思维、增加系统社会存在感和透明性的重要性，以培养信任。尽管取得了进展，但仍存在一些关键缺口，比如对早期创作阶段如问题澄清的支持有限，以及用户适应AI系统中的挑战等.
### Conclusion
尽管对未来设计有益，但在支持初期创作阶段和促进用户对AI系统的适应性方面仍然存在挑战。
## 92. `cs.AI` - CA-I2P：具备全局最优选择的通道自适应注册网络 [PDF](https://arxiv.org/pdf/2506.21364), [HTML](https://arxiv.org/abs/2506.21364)
### Authors
Zhixin Cheng,Jiacheng Deng,Xinjun Li,Xiaotian Yin,Bohao Liao,Baoqun Yin,Wenfei Yang,Tianzhu Zhang
### Background
检测免模型通常遵循自上而下的处理流水线，从图像和点云中提取特征进行像素级别、块级别的匹配，并细化密集的像素-点对应关系。不过，图像和点云之间通道关注度的区别可能会导致精度降低，最终影响配准效果。场景中相似结构的存在还可能导致跨模态匹配中的冗余对应关系。
### Innovation
本文提出了Channel Adaptive Adjustment Module (CAA)和Global Optimal Selection Module (GOS)。CAA通过增强内在模式特征并抑制跨模式的敏感性来改进特征。GOS用全局优化代替局部选择。本研究通过在RGB-D Scenes V2和7-Scenes数据集上的实验，展示了该方法在图像到点云配准时的优越性能，并达到了最先进的技术水平。
### Conclusion
提出的CA-I2P模型结合CA模块和GOS模块，能够有效改善跨模态配准中的准确性和减少冗余对应关系，实现了图像到点云配准的最新性能。
## 93. `cs.AI` - 探索低资源音乐生成中的适配器设计权衡 [PDF](https://arxiv.org/pdf/2506.21298), [HTML](https://arxiv.org/abs/2506.21298)
### Authors
Atharva Mehta,Shivam Chauhan,Monojit Choudhury
### Background
音乐生成模型如MusicGen和Mustango的细调是一个计算成本高昂的过程，通常需要大量硬件资源和数亿个参数的更新。为了解决这个问题，适应器高效细调(PEFT)技术，尤其是基于适配器的方法，成为了有前景的替代方案，允许在可训练参数最少的情况下保持模型性能。然而，适配器的设计选择包括其架构、位置和大小等，这些都在不断变化，关于这些配置之间哪种组合会产生最佳适配器以及为什么仍然不清楚。本文试图通过研究两种AI音乐模型MusicGen和Mustango在两种音乐类型——印度古典音乐和土耳其玛卡姆音乐上的多种适配器配置来回答这一问题。
### Innovation
研究表明，卷积基础上的适配器在捕捉细粒度的局部音乐细节（如装饰和短旋律短语）上表现优越，而变体结构基础的适配器则更好地保持了对于有结构即兴创作至关重要的长期依赖关系。此外，分析了不同规模的适配器的计算资源需求，发现中等规模的适配器（40M参数）在表达性和质量之间取得了最佳平衡。并且，发现基于扩散的模型Mustango生成的输出更具有多样性且更符合输入提示描述，但在音符稳定性、节奏对齐和美学方面表现不佳。与之相对，自回归模型MusicGen在训练速度和效率上更有优势，可以生成更高质量的输出，但生成的内容略显重复。
### Conclusion
研究结果揭示了不同规模适配器在音乐生成中的优势和权衡，为低资源音乐生成模型的适配器设计提供了指导。中等规模的适配器可以同时提高模型的表演性和质量，而基于卷积或变体结构的适配器分别适用于捕捉局部细节和保持长期依赖。基于扩散的音乐生成模型如Mustango在生成多样化的音乐输出方面表现较好，但在音符稳定性、节奏对齐和美学方面的表现较弱。自回归模型如MusicGen虽然在生成质量上更优，但相对具有一些冗余性。
## 94. `cs.AI` - 为大型电子商务平台提供实时且个性化的商品推荐 [PDF](https://arxiv.org/pdf/2506.21368), [HTML](https://arxiv.org/abs/2506.21368)
### Authors
Matteo Tolloso,Davide Bacciu,Shahab Mokarizadeh,Marco Varesi
### Background
针对大型电子商务平台，特别是在时尚零售领域，提供实时且个性化的商品推荐需求日益增加。现有推荐系统虽然能够提供一定效果的个性化推荐，但在响应时间和处理能力等方面存在不足，特别是在大规模数据集和多交互场景下难以实现高效和准确的推荐服务。
### Innovation
该研究提出了一种利用图神经网络和简洁学习方法相结合的方式，以实现快速响应（具有最小响应时间）、精细个性化和高效扩展的实时和个人化商品推荐方法。通过大规模电子商务平台的数据集进行实验，验证了该方法在预测购买序列和处理多交互场景方面的有效性，从而能够在实际应用中提供高效的个性化推荐服务，满足用户需求的多样性与及时性要求。
### Conclusion
该方法在大规模数据集的条件下能够实现高效且准确的实时和个人化商品推荐，适用于大型电子商务平台。通过利用图神经网络和简洁学习方法，该方法能够在保证推荐准确性的同时，有效提升系统处理效率，从而极大地提高用户满意度。
## 95. `cs.AI` - 数字货币交易欺诈检测中的时间感知图注意力网络 [PDF](https://arxiv.org/pdf/2506.21382), [HTML](https://arxiv.org/abs/2506.21382)
### Authors
Zhi Zheng,Bochuan Zhou,Yuping Song
### Background
数字货币交易欺诈检测面临日益复杂交易模式和严重类别不平衡的双重挑战。传统方法依赖手动特征工程，难以捕捉交易网络中的时间及结构依赖关系。
### Innovation
提出了一种增强的时间感知图注意力网络（ATGAT），通过以下三个模块增强检测性能：1. 设计高级时间嵌入模块，融合多尺度时间差特征与时序位置编码；2. 构建时间感知三重注意机制，联合优化结构、时间和全局上下文注意；3. 使用加权二元交叉熵损失以应对类别不平衡问题。实验结果表明，ATGAT在Elliptic++数字货币数据集上达到0.9130的AUC，分别比最佳传统方法XGBoost、GCN和标准GAT高9.2%、12.0%和10.0%。该方法不仅验证了时间意识和三重视觉机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，并且其设计原则可以泛化到其他时间图异常检测任务中。
### Conclusion
该方法不仅验证了时间意识和三重视觉机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，并且其设计原则可以泛化到其他时间图异常检测任务中。
## 96. `cs.AI` - rQdia: 使用图像增强正则化Q值分布 [PDF](https://arxiv.org/pdf/2506.21367), [HTML](https://arxiv.org/abs/2506.21367)
### Authors
Sam Lerman,Jing Bi
### Background
在基于像素的深度强化学习中，Q值分布的不均衡是影响算法性能的一个关键问题。特别是连续控制和 Atari 游戏环境中的表现尤为明显。传统的算法如DrQ和SAC在这些任务上的表现有限，而数据高效的 Rainbow 在 Atari 环境中也受限于样本效率。因此，提出了一种新的方法 rQdia，旨在通过图像增强方式来均衡Q值分布，从而提升算法的整体表现和效率。
### Innovation
rQdia 通过引入一种简单的辅助损失，使用均方误差（MSE）来正则化Q值分布。这种正则化方法使得算法在 MuJoCo 连续控制套件和 Atari 赌机环境中表现更好。在 MuJoCo 任务中，rQdia 分别在9/12和10/12的任务上提升了DrQ和SAC的表现；在 Atari 环境中，rQdia 提升了 Data-Efficient Rainbow 的性能，在26个游戏中达到了18/26。此外，rQdia 的引入使得模型自由的连续控制方法首次在像素输入上超越了基于状态编码的方法。
### Conclusion
rQdia 通过图像增强的方法有效提升了基于像素输入的连续控制和 Atari 游戏环境中的算法性能，特别是在样本效率方面表现突出。这一方法不仅提高了现有算法的表现，还扩展了模型自由方法在像素输入上的应用范围。
## 97. `cs.AI` - 使用高效球形洛奇分布的超球面变分自编码器 [PDF](https://arxiv.org/pdf/2506.21278), [HTML](https://arxiv.org/abs/2506.21278)
### Authors
Lukas Sablica,Kurt Hornik
### Background
传统的变分自编码器（VAE）通常使用高斯潜在空间或广泛使用的von Mises-Fisher（vMF）分布。然而，这些分布可能存在不足，例如在表示方向数据时不够自然，且可能引起数值不稳定问题。文章提出了一种新的VAE架构，采用球形Cauchy（spCauchy）潜在分布，旨在改善这些问题，提供更灵活且更有效的潜在空间表示。
### Innovation
该研究提出了一种新的VAE架构，利用球形Cauchy分布作为潜在变量的表示方式。与传统的高斯潜在空间或von Mises-Fisher分布相比，球形Cauchy提供了更加自然的超球面表示法，可以更好地捕捉方向数据，并在保持灵活性的同时避免过度正则化。此外，球形Cauchy通过Möbius变换实现了可微且高效的重新参数化技巧，与von Mises-Fisher相比，避免了数值不稳定问题。相比于von Mises-Fisher的计算，spCauchy使用快速收敛的幂级数来计算KL散度，减少了数值下溢或上溢的风险。这些特性使得球形Cauchy成为VAE的有效替代选择，特别是在高维生成建模中表现出理论优势和实际效率。
### Conclusion
本文提出的球形Cauchy（spCauchy）分布具有重尾特性，能够防止过度正则化，并提供灵活且表达能力更强的潜在空间表示。这种新颖的VAE架构通过Möbius变换实现了高效的重新参数化技巧，并通过快速收敛的幂级数计算KL散度，解决了数值稳定性问题。因此，该模型在高维生成建模中表现出更好的理论优势和实际效率。
## 98. `cs.AI` - 利用LLM辅助查询理解进行实时检索增强生成 [PDF](https://arxiv.org/pdf/2506.21384), [HTML](https://arxiv.org/abs/2506.21384)
### Authors
Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng
### Background
当前实时检索增强生成（RAG）系统在处理用户查询时面临诸多挑战，这些查询往往是不干净、模棱两可且包含多个意图的。尽管RAG通过引入外部知识增强了大型语言模型（LLMs），但现有系统通常难以应对这类复杂的输入，因为它们通常是在更加干净的数据集上进行训练或评估的。因此，当前RAG系统的鲁棒性和有效性在处理复杂和噪声数据时受到了限制。
### Innovation
本文提出了Omni-RAG，这是一种新的框架，旨在提高RAG系统在实时、开放领域环境中的鲁棒性和有效性。Omni-RAG包括三个关键模块：(1) 深度查询理解和分解，利用针对特定提示进行培训的LLM来清理查询（例如纠正拼写错误）并分解具有多个意图的查询为结构化的子查询；(2) 意图感知的知识检索，为每个子查询从语料库中（例如使用OpenSearch的FineWeb）进行检索并汇总结果；(3) 重新排名和生成，重新排名器（例如BGE）对文档选取进行优化，之后通过带有链式思考提示的LLM（例如Falcon-10B）生成最终回应。Omni-RAG旨在通过稳健处理复杂和噪声查询，弥合当前RAG功能与SIGIR 2025 LiveRAG挑战所提出的真实场景应用需求之间的差距。
### Conclusion
Omni-RAG旨在改进RAG系统在处理复杂和噪声查询方面的表现，从而更好地满足现实世界中的应用需求，并通过引入LLM辅助查询理解和多阶段处理流程（包括重新排名和生成），旨在提高RAG系统的鲁棒性和有效性。
## 99. `cs.AI` - 小型编码器可以在检测语境相关性方面与大型解码器媲美 [PDF](https://arxiv.org/pdf/2506.21288), [HTML](https://arxiv.org/abs/2506.21288)
### Authors
Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar
### Background
大型语言模型（LLMs）通过添加外部上下文可以显著提高其在自然语言处理（NLP）任务中的表现。然而，当提供的上下文信息不足时，LLMs往往依赖不切实际的猜测或内部知识来回答查询，这导致了不一致性和不信任。在这种情况下，确保生成的答案严格基于提供的上下文信息至关重要。因此，本研究旨在开发一种机制，在LLMs进行昂贵的回答生成之前，首先检测给定查询是否基于提供的文档上下文。这种检测机制可以大幅减少推理时间和资源消耗。研究表明，使用RoBERTa和NomicBERT等轻量级、任务特定的编码器模型，在微调后能达到与当时最新的LLMs，如Llama3 8B和GPT4o相当的精度，同时极大地减少了推理延迟。
### Innovation
研究发现，轻量级、任务特定的编码器模型，如RoBERTa和NomicBERT，在微调后能够与大型解码器模型如Llama3 8B和GPT4o在语境相关性检测方面达到相似的准确度。更重要的是，这些轻量级模型极大地减少了推理延迟。
### Conclusion
本研究提出了一种轻量级编码器模型，能够高效且准确地检测给定查询是否基于提供的上下文信息，从而显著减少大型语言模型的推理时间和资源消耗。具体的代码已经开源。
## 100. `cs.AI` - 关注小权重 [PDF](https://arxiv.org/pdf/2506.21374), [HTML](https://arxiv.org/abs/2506.21374)
### Authors
Chao Zhou,Tom Jacobs,Advait Gadhikar,Rebekka Burkholz
### Background
微调大规模预训练神经网络在内存和计算成本上都属于资源密集型。为了缓解这一问题，一种常见方法是限制培训到模型参数的一个子集。通过分析微调过程中的梯度和权重关系，观察到一个明显的模式：大梯度经常与小幅度的权重相关。这种关联在微调设置中比从头开始训练更加明显。
### Innovation
本文提出了一种名为NANOADAM的动态更新方法，仅在微调过程中更新小幅度权重。这种方法具有几个实用优势：首先，这一标准是梯度自由的，可以不通过梯度计算来确定参数子集；其次，它保留了大幅度权重，这些权重在预训练中很可能编码了重要的特征，从而降低了灾难性遗忘的风险；最后，它允许使用更大的学习率，并且在实验中能够一致地带来更好的泛化性能。
### Conclusion
本文对自然语言处理和视觉任务中都验证了这种方法的有效性。
## 101. `cs.AI` - ScalaBL：大规模语言模型基于随机变分子空间推断的可扩展贝叶斯低秩适应 [PDF](https://arxiv.org/pdf/2506.21408), [HTML](https://arxiv.org/abs/2506.21408)
### Authors
Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha
### Background
尽管大规模语言模型（LLMs）在广泛应用中表现出色，但它们会错误地生成信息并且缺乏校准，这就使得对这些模型的不确定性量化变得至关重要，特别是在高风险领域，如自主驾驶和医疗保健中。为了应对这一问题，以往的研究采用了基于贝叶斯深度学习的方法，并通过在微调模型的低秩适应（LoRA）参数上执行推理来使问题更具操作性。然而，这些方法在扩展到更大的LLMs时遇到了困难，因为它们需要额外的参数来与LoRA参数竞争。
### Innovation
我们在ScalaBL（可扩展贝叶斯低秩适应）中提出了一个新的方法。ScalaBL在LoRA秩$r$的$r$维子空间中执行贝叶斯推断。通过将LoRA参数重新用于投影矩阵，我们可以将来自这个子空间的样本映射到LLM的全权重空间。这使得我们可以仅使用随机变分推断来学习我们方法的所有参数。尽管我们的子空间维度较低，但ScalaBL仍能实现与最先进的方法相当的性能，同时仅需约1000个额外参数。此外，ScalaBL还允许我们扩展到目前最大的贝叶斯LLM，其基础参数比先前研究多四倍。
### Conclusion
ScalaBL通过在低秩子空间中使用随机变分推断，成功地应对了大规模语言模型的不确定性量化问题，并在较小的参数开销下达到了与最先进的方法相当的性能，同时还支持更大规模的模型使用。
## 102. `cs.AI` - 增强领域知识的大型语言模型在欺诈和概念漂移检测中的应用 [PDF](https://arxiv.org/pdf/2506.21443), [HTML](https://arxiv.org/abs/2506.21443)
### Authors
Ali Şenol,Garima Agrawal,Huan Liu
### Background
随着动态平台上语言模式的演变和概念漂移（即语义或主题的变化导致的交互背景或意图变化），检测欺骗性对话变得越来越困难。这些变化可能掩盖恶意意图或模仿正常对话，增加了准确分类的难度。尽管大型语言模型在自然语言任务中表现出色，但它们在风险敏感场景下常难以应对语境模糊性和幻觉问题。
### Innovation
提出了一种增强领域知识的大型语言模型框架，该框架结合预先训练的大型语言模型与结构化、任务特定的见解，以实现欺诈和概念漂移检测。该框架包含三大模块：1）检测假对话或欺骗性对话的领域知识增强型大型语言模型模块；2）检测语义变化的漂移检测单元（OCDD）；3）第二个领域知识增强型大型语言模型模块，用于将漂移分类为良性或欺诈性质。通过使用领域知识和漂移意识，该系统在高风险自然语言处理应用中的性能、可解释性和稳健性得到了显著提高。
### Conclusion
通过使用领域知识验证，该研究利用基于LLaMA的实施实现了98%的分类准确率。与零样本基线的对比研究表明，整合领域知识和漂移意识可以显著改善高风险NLP应用中的性能、可解释性和稳健性。
## 103. `cs.AI` - skLEP: 斯洛伐克通用语言理解基准 [PDF](https://arxiv.org/pdf/2506.21508), [HTML](https://arxiv.org/abs/2506.21508)
### Authors
Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko
### Background
目前缺乏针对斯洛伐克语自然语言理解（NLU）模型的全面基准。已有基准多是为其他语言设计，不适合斯洛伐克语的特定需求，因此需要一个专门的基准来评估斯洛伐克语NLU模型的能力和性能。
### Innovation
论文提出了一种全新的名为skLEP的基准，旨在评估斯洛伐克语NLU模型。它包含了九个不同类型的任务，涵盖了从词级到文档级的各种挑战，能够系统地评估模型能力。此外，研究者还创建了新的斯洛伐克语数据集以及翻译的英文NLU资源，提供了全新的评估视角。通过skLEP基准，首次对多语言、斯洛伐克语方言、和英文预训练语言模型进行了全面的系统评估。
### Conclusion
论文公开了完整的skLEP基准数据集、开源工具包以及公共排行榜，旨在促进斯洛伐克语NLU的研究透明性和可重复性，推动未来斯洛伐克语NLU的研究进展。
## 104. `cs.AI` - 优化4th-Order Runge-Kutta方法：一种基于动态启发式方法的高效低存储方案 [PDF](https://arxiv.org/pdf/2506.21465), [HTML](https://arxiv.org/abs/2506.21465)
### Authors
Gavin Lee Goodship,Luis Miralles-Pechuan,Stephen O'Sullivan
### Background
扩展稳定性Runge-Kutta (ESRK) 方法对于解决科学和工程中的大规模计算问题至关重要，如天气预报、空气动力学分析和复杂的生物建模。然而，平衡准确度、稳定性和计算效率仍然是一个挑战，特别是在高阶、低存储方案方面。
### Innovation
本文提出了一种结合遗传算法 (GA) 和强化学习 (RL) 的混合方法，用于自动启发式发现，优化低存储 ESRK 方法。这种新颖的方法利用GA的变异进行搜索空间探索，并采用RL启发的态转移机制动态改进启发式选择，从而系统地减少参数，同时保持四阶精度并显著提高计算效率。这种方法通过基准问题（包括1D和2D Brusselator系统和稳态Navier-Stokes方程）的严格测试得到验证。
### Conclusion
研究结果表明，自适应启发式发现可以提高高保真模拟中的资源效率，并扩大低存储Runge-Kutta方法在计算流体动力学、物理模拟和其他需求领域中的应用范围。本文为数值方法的启发式优化开辟了新范式，并为后续使用深度强化学习和自适应机器学习（AutoML）基于启发式搜索的研究打开了通道。
## 105. `cs.AI` - TITAN: 基于查询-标记的领域自适应对抗学习 [PDF](https://arxiv.org/pdf/2506.21484), [HTML](https://arxiv.org/abs/2506.21484)
### Authors
Tajamul Ashraf,Janibul Bashir
### Background
在源数据不可用时进行领域自适应目标检测（SF-DAOD）问题遇到挑战，传统的自监督方法利用学生-教师框架生成伪标签进行进一步微调，但学生模型的性能往往因教师模型的坍塌而大幅下降，主要原因在于伪标签中的高噪声，这些噪声源于领域偏差、差异以及领域之间的显著偏移。因此，获得可靠的伪标签变得尤为重要，这是本研究的背景所在。
### Innovation
本研究提出了基于查询-标记的迭代查询-标记对抗网络（TITAN）。该方法将目标图像分为两类：与源图像相似的（简单）和不相似的（困难）。此方法利用检测方差和召回率之间的关系来区分目标领域，并结合查询标记对抗模块到学生-教师框架中，以减少两个特征表示之间的领域差距，从而提高目标领域适应性。实验结果表明TITAN优于现有最先进的方法，在四个自然成像数据集和两个具有挑战性的医学数据集上分别提高了22.7%、22.2%、21.1%和3.7%的mAP值，远超过当前最先进的方法（SOTA）在C2F、C2B、S2C和K2C基准上的表现。
### Conclusion
TITAN通过有效分区目标领域并结合查询标记对抗模块来提高伪标签的准确性，从而显著提高了领域自适应目标检测的性能，实验结果验证了TITAN相较于现有方法的优越性。
## 106. `cs.AI` - What's Up, Doc?: 分析用户在大规模对话人工智能数据集中寻求健康信息的方式 [PDF](https://arxiv.org/pdf/2506.21532), [HTML](https://arxiv.org/abs/2506.21532)
### Authors
Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal
### Background
随着人们越来越多地通过交互聊天机器人获取健康信息，这些对话的本质及潜在风险尚未被充分研究。本文旨在探索和分析大规模对话人工智能数据集中的用户与人工智能模型之间的交互模式，特别是当用户寻求健康信息时所涉及的21种不同健康专科的具体情况。
### Innovation
本文通过筛选大量对话数据集，构建了一个包含11000个真实对话和25000条用户消息的医学对话集——HealthChat-11K。利用一个由临床专家驱动的分类体系，对用户向大型语言模型（LLMs）寻求健康信息的交互进行系统性研究。本文的新颖之处在于深入分析了用户的健康信息查询方式，包括常见的交互模式、缺省上下文的情况以及可能导致奉承等行为的互动模式，从而强调了提高作为对话人工智能部署的LLMs的健康支持能力的必要性。
### Conclusion
本文的研究揭示了用户寻求健康信息的方式和原因，这为进一步改进部署为对话人工智能的LLMs的健康支持能力提供了有益的见解。相关代码和可获取的分析集资料可在以下链接找到：this https URL。
## 107. `cs.AI` - 大型语言模型中的假象理解 [PDF](https://arxiv.org/pdf/2506.21521), [HTML](https://arxiv.org/abs/2506.21521)
### Authors
Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan
### Background
现有对大型语言模型（LLMs）的能力评估主要依赖于基准数据集。然而，这种评估方法的有效性受到质疑，因为仅仅基于模型对特定问题的解答来推断其全面能力可能并不能准确反映模型的真实理解水平。特别是，如果模型的表现仅仅是表面的或伪装的，就像是'木偶城'的建筑一样，即模型对概念的理解存在根本性的不一致性，这带来的假象必须被识别和量化。文章首先引入了一个正式框架来探讨这一问题，提出了'木偶理解'的概念，指出传统基准测试的有效性依赖于模型对概念的理解方式是否与人类理解方式一致。如果不一致，则表现出假象理解。
### Innovation
文章提出了一种正式的框架来探讨基于传统基准测试推断大型语言模型能力的有效性，并定义了'木偶理解'的概念。为了测量和量化这种假象理解，引入了两种方法：特定领域设计的基准测试方法和一般性方法。这两种方法分别针对不同场景提供了对'木偶理解'存在的确认和下限估计。研究发现这种假象理解在多个模型、任务和领域中普遍存在，而且不仅仅是对概念的理解错误，还反映在概念表示的内部不一致性上。
### Conclusion
文章的研究结果表明，大型语言模型普遍存在假象理解现象。这种假象理解不仅是对概念的误解问题，更是模型内部概念表示存在根本性的不一致性。这一发现强调了对模型深度理解评估的重要性，以及现有基准测试方法评估模型能力的潜在不足之处。
## 108. `cs.AI` - 基于过程挖掘的建模与仿真以增强Cyber-Physical系统中的故障诊断 [PDF](https://arxiv.org/pdf/2506.21502), [HTML](https://arxiv.org/abs/2506.21502)
### Authors
Francesco Vitale,Nicola Dall'Ora,Sebastiano Gaiardelli,Enrico Fraccaroli,Nicola Mazzocca,Franco Fummi
### Background
在Cyber-Physical系统(CPSs)中，故障诊断至关重要，因为这能确保系统的可靠性和操作效率，通过准确检测异常并识别其根本原因。然而，手动建模故障行为通常需要大量的专业知识，并生成复杂、易出错且难以解释的模型。为了应对这一挑战，该研究提出了一种新的无监督故障诊断方法，该方法结合了多变量时间序列集体异常检测、过程挖掘和随机仿真。该方法先从底层传感器数据中使用多变量时间序列分析检测集体异常，然后将这些异常转换为结构化事件日志，可通过过程挖掘发现可解释的过程模型。通过将时间分布纳入提取的Petri网中，该方法支持以故障行为为特征的随机仿真，从而增强根本原因分析和行为理解。该方法使用已广泛认可的智能制造基准数据集Robotic Arm Dataset (RoAD)进行了验证，实验结果显示该方法在建模、仿真和分类CPS中的故障行为方面具有有效性，能够创建全面的故障字典，支持预测维护和工业环境的数字孪生开发。
### Innovation
提出了一种新颖的无监督故障诊断方法，该方法结合了多变量时间序列集体异常检测、过程挖掘和随机仿真。该方法首先从低级传感器数据中使用多变量时间序列分析检测集体异常，然后将这些异常转换为结构化事件日志，使过程挖掘能够发现可解释的过程模型。通过将时间分布纳入提取的Petri网中，该方法支持以故障行为为特征的随机仿真，从而增强了根本原因分析和行为理解。这种方法相较于传统的手动建模方法具有更大的灵活性和更强大的异常检测能力，能够处理更为复杂和未知的故障模式。
### Conclusion
该方法通过验证得到证实，证明了其在模式建模、仿真的有效性以及对CPS中故障行为的分类能力，这一方法可以支持预测维护，并有助于开发工业环境中的数字孪生体。
## 109. `cs.AI` - WorldVLA：走向自回归动作世界模型 [PDF](https://arxiv.org/pdf/2506.21539), [HTML](https://arxiv.org/abs/2506.21539)
### Authors
Jun Cen,Chaohui Yu,Hangjie Yuan,Yuming Jiang,Siteng Huang,Jiayan Guo,Xin Li,Yibing Song,Hao Luo,Fan Wang,Deli Zhao,Hao Chen
### Background
当前的研究主要集中在动作理解和生成上，通常分为单独的动作理解与生成模型。然而，这些模型通常无法共同优化，且在生成连续动作序列时表现出较差的泛化能力，容易出现顺序误差的问题。
### Innovation
本文提出了一种名为WorldVLA的自回归动作世界模型，该模型将视觉-语言-动作（VLA）模型与世界模型整合在一个框架中。WorldVLA通过同时利用动作和图像理解来预测未来图像，旨在学习环境的物理原理，从而提升动作生成能力。此外，该模型还能基于图像观察生成后续动作，进而辅助视觉理解并帮助世界的视觉生成。研究发现，通过引入注意力掩码策略，可以在生成当前动作时选择性地屏蔽先前的动作，从而显著提高动作片段生成任务上的表现。
### Conclusion
实验结果表明，WorldVLA相比单个动作和世界模型均表现出更优的效果，且通过注意力掩码策略可以有效克服自回归生成中动作顺序误差的问题。
## 110. `cs.AI` - 全身条件化自我中心视频预测 [PDF](https://arxiv.org/pdf/2506.21552), [HTML](https://arxiv.org/abs/2506.21552)
### Authors
Yutong Bai,Danny Tran,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik
### Background
该研究致力于通过给定过去视频和由相对3D肢体姿态表示的动作来训练模型预测以自我为中心的视频（PEVA）。该模型通过条件化于由身体骨架层次结构结构化的动力学姿态轨迹来学习模拟第一人称视角下人类动作如何塑造环境。研究还旨在解决通过视频预测构建复杂现实环境及人体代理行为建模的挑战。
### Innovation
研究提出了一种条件自回归扩散变换器模型，该模型在Nymeria大规模实际自我中心视频和肢体姿态采集数据集上进行训练。此外，研究设计了一种分层评估方案，包含递进难度的任务，以全面分析模型的体现预测和控制能力。
### Conclusion
该工作代表了从人类视角出发，首次尝试解决复杂现实环境和体现代理行为建模挑战的一次初步尝试。
## 111. `cs.AI` - Review 学习：医学机构之间的隐私保护连续学习的现实世界验证 [PDF](https://arxiv.org/pdf/2210.09394), [HTML](https://arxiv.org/abs/2210.09394)
### Authors
Jaesung Yoo,Sunghyuk Choi,Ye Seul Yang,Suhyeon Kim,Jieun Choi,Dongkyeong Lim,Yaeji Lim,Hyung Joon Joo,Dae Jung Kim,Rae Woong Park,Hyeong-Jin Yoon,Kwangsoo Kim
### Background
在对不同数据集进行顺序训练时，深度学习模型常常会忘记之前学习到的知识，这是所谓的灾难性遗忘问题，这会损害模型在多元化数据集上的性能，并对于基于转移学习的隐私保护深度学习（PPDL）应用尤为关键。在这样的背景下，为了解决这个问题，文中提出了‘Review学习’（RevL）算法，旨在通过电子健康记录（EHR）在PPDL框架下实现诊断预测的低开销连续学习方法，使模型能够循环利用过去的数据知识。文中通过模拟实验和真实世界实验测试了RevL的效果，以证明其在真实世界PPDL场景中的有效性
### Innovation
文中提出的Review学习（RevL）是一种在隐私保护深度学习（PPDL）框架下，针对诊断预测的实际应用，使用电子健康记录（EHR）实现连续学习的方法。RevL算法旨在通过生成模型的数据样本，实现对于之前学习到的知识的复习，从而解决了模型灾难性遗忘的问题。实验结果表明，RevL在真实世界数据集上具有更好的性能，进一步证明了其在实际应用中的有效性
### Conclusion
本文研究建立了一种基于机构间模型迁移的PPDL现实研究管道，通过真实世界的数据验证了Review学习算法的有效性和实用性，在保护患者隐私的前提下，提高疾病诊断的准确性。
## 112. `cs.AI` - HalluSegBench：视觉反事实推理在分割幻觉评估中的应用 [PDF](https://arxiv.org/pdf/2506.21546), [HTML](https://arxiv.org/abs/2506.21546)
### Authors
Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou
### Background
近期在视觉-语言分割方面取得了显著进步，推动了基于图像的理解。然而，这些模型往往会出现幻觉现象，即生成与图像内容无关的分割掩码，或者错误地标记无关区域。现有分割幻觉评估协议主要集中在标签或文本幻觉上，并未改变视觉上下文，限制了它们诊断关键错误的能力。
### Innovation
我们提出了HalluSegBench，这是首个专门用于通过反事实视觉推理评估视觉定位中幻觉的基准。HalluSegBench包含一个新颖的数据集，由1340个反事实实例对和一系列新的度量标准组成，用于量化在视觉连贯场景编辑下的幻觉敏感性。实验表明，由视觉驱动的幻觉比由标签驱动的幻觉更为普遍，模型在虚假分割上往往持续存在，强调了反事实推理对诊断定位准确性的必要性。
### Conclusion
实验结果表明，由视觉驱动的幻觉比由标签驱动的幻觉更为普遍，模型在虚假分割上往往持续存在，强调了反事实推理对诊断定位准确性的必要性。
## 113. `cs.AI` - mTSBench: 在大规模下评估多元时间序列异常检测和模型选择 [PDF](https://arxiv.org/pdf/2506.21550), [HTML](https://arxiv.org/abs/2506.21550)
### Authors
Xiaona Zhou,Constantin Brif,Ismini Lourentzou
### Background
多元时间序列异常检测（MTS-AD）在医疗、网络安全和工业监控等领域至关重要，但仍然具有挑战性，因为存在复杂的变量间依赖关系、时序动态性和稀疏异常标签。现有的基准测试和模型选择方法未能充分解决这些问题，并且没有单一的方法能够适用于所有数据集，强调了模型选择的重要性，但当前最好的选择方法也不尽如人意，揭示了关键的缺陷。
### Innovation
引入了迄今为止最大的MTS-AD基准测试mTSBench，涵盖了19个数据集和12个不同的应用领域，共有344个带标签的时间序列数据。它评估了24种异常检测方法，包括基于语言模型的多元时间序列检测器，并系统性地对无监督模型选择技术在标准化条件下进行了基准测试。
### Conclusion
我们的结果显示，没有单一的检测器适用于所有数据集，强调了模型选择的重要性。然而，即使最先进的选择方法也远未达到最优，揭示了关键差距。mTSBench提供了一个统一的评估套件，用于严格的、可重复的比较，并促进了适应性异常检测和稳健模型选择的未来进展。
## 114. `cs.AI` - SmoothSinger:一个多分辨率架构的条件扩散模型用于歌声合成 [PDF](https://arxiv.org/pdf/2506.21478), [HTML](https://arxiv.org/abs/2506.21478)
### Authors
Kehan Sui,Jinxu Xiang,Fang Jin
### Background
歌声合成（SVS）旨在根据乐谱生成带有表现力且高质量的歌声，要求精确地建模声调、时长和发音。虽然基于扩散的方法在图像和视频生成中取得了显著成功，但它们在SVS的应用仍然具有挑战性，因为唱歌的复杂声学和音乐特性常常导致影响自然性的缺陷。以前的方法通常依赖于最终阶段的声码器，往往会引入失真。SmoothSinger通过在一个统一的框架中直接精炼低质量的合成音频，减少了两阶段管道相关的降解。模型采用参考指导的双分支架构，并且通过将低质量音频作为参考，引导去噪过程，从而使合成更具表现力和上下文意识。此外，它还增强了传统的U-Net，引入了一条并行的低频上采样路径，允许模型更好地捕捉声调轮廓和长期光谱依赖关系；为了改善训练期间的对齐，用退化的真实音频替换参考音频，解决了参考信号和目标信号之间的时间不匹配问题。这些改进使得SmoothSinger在目标评估和主观评估中均达到了最先进的效果，且消融研究确认了其减少瑕疵并提高合成声音自然性的有效性。
### Innovation
SmoothSinger采用参考指导的双分支架构，将低质量的音频作为参考，引导去噪过程，从而实现更为表现力和上下文感知的合成。与传统的两阶段管道相比，它不仅提高了声音的自然度，还增强了U-Net，引入了一条并行的低频上采样路径，以更好地捕捉声调轮廓和长期光谱依赖关系。此外，通过用退化的真实音频替换参考音频，解决了参考信号和目标信号之间的时间不匹配问题，从而提高了训练期间的对齐效果。这些创新使得SmoothSinger在评估中表现优异，具有显著的技术进步。
### Conclusion
SmoothSinger在大型中文歌唱语料库OpenCP dataset上的实验表明，该模型在客观和主观评价中均达到了最先进的效果。广泛的消融研究表明，SmoothSinger在减少瑕疵并提高合成声音自然性方面表现出色。这就证明了SmoothSinger在歌声合成中的优越性能，为未来的研究奠定了坚实的基础。
## 115. `cs.AI` - WiS平台：通过基于游戏的分析提升LLM基础多智能体系统的评估 [PDF](https://arxiv.org/pdf/2412.03359), [HTML](https://arxiv.org/abs/2412.03359)
### Authors
Chengwei Hu,Jianhui Zheng,Yancheng He,Hangyu Guo,Junguang Jiang,Han Zhu,Kai Sun,Yuning Jiang,Wenbo Su,Bo Zheng
### Background
近期基于大规模语言模型（LLMs）的自主多智能体系统（MAS）的应用场景和性能得到提升，但仍存在评估、分析和复现能力不足的问题。当前研究在评估LLM基础MAS方面的不足促使作者提出了解决方案，即开发一个平台来解决这些问题，该平台基于“Who is Spy?”（WiS）游戏构建，旨在改善现有方法。
### Innovation
引入一个开放、可扩展并实时更新的平台，该平台基于WiS游戏来访问和分析LLM基础MAS。该平台的特点包括：（1）一个统一的模型评估界面，支持Hugging Face上的各种模型；（2）实时更新的排行榜，用于模型评估；（3）全面的评估，涵盖游戏胜利率、攻击与防御策略及逻辑推理。实验结果证明该平台的有效性和效率，并展示了不同代理在游戏中的不同且有趣的动态行为。
### Conclusion
通过广泛的实验覆盖各种开源和闭源的LLMs，该平台有效地评估了LLM基础MAS，并展示了其效能和效率。平台及其文档公开可在提供的链接获取。
## 116. `cs.AI` - 通过在线对抗训练和生成模型提高人机合作 [PDF](https://arxiv.org/pdf/2504.15457), [HTML](https://arxiv.org/abs/2504.15457)
### Authors
Paresh Chaudhary,Yancheng Liang,Daphne Chen,Simon S. Du,Natasha Jaques
### Background
在许多经济有价值的人工智能任务中，如家庭机器人和自动驾驶，能够与新人合作是一项重要能力。为了实现这一目标，训练数据需要捕捉人类行为的多样性。对抗性训练可以动态生成数据，使智能体更加稳健，但它难以应用于协作任务。因此，需要一种新的策略来优化这种合作中的对抗性学习过程，从而实现更好的泛化能力。
### Innovation
提出了一种名为GOAT（生成式在线对抗训练）的新策略，它结合了预训练的生成模型模拟有效的合作智能体策略，并使用对抗性训练最大化遗憾值。这种方法能够在生成模型的潜在空间中动态搜索未被学习策略（合作者）充分利用的协作策略，从而让合作者面对多样的挑战性交互场景，并保持生成模型不变，避免了对抗性利用可能带来的负面影响。
### Conclusion
GOAT方法在Overcooked基准测试中的结果显示了其在多样的人类行为泛化能力上的卓越表现，证明了其在提高人机合作方面的能力。
## 117. `cs.AI` - 可持续共生社会的超级协同 [PDF](https://arxiv.org/pdf/2504.17404), [HTML](https://arxiv.org/abs/2504.17404)
### Authors
Yi Zeng,Feifei Zhao,Yuwei Wang,Enmeng Lu,Yaodong Yang,Lei Wang,Chao Liu,Yitao Liang,Dongcheng Zhao,Bing Han,Haibo Tong,Yao Liang,Dongqi Liang,Kang Sun,Boyuan Chen,Jinyu Fan
### Background
随着人工智能（AI）的发展，尤其是朝着通用人工智能（AGI）和超人工智能（ASI）方向迈进，AI有可能超越人类的控制，背离人类价值观，甚至在极端情况下导致不可逆的灾难性后果。这一潜在风险凸显了‘超级对齐’问题的重要性——即确保AI系统即使比人类聪明得多，也能保持与人类（相容）意图和价值观的一致。虽然当前的可扩展监督和弱到强的一般化方法显示出一定的适用性，但它们在解决超级对齐范式方面存在根本性缺陷，特别是单向的人类价值观强加无法适应超智能的自主性，也无法保证AGI/ASI的稳定学习。
### Innovation
本文提出了一种具体的框架，整合了外部监督和内在主动对齐。外部监督对齐应在以人为本的终极决策基础上进行，并通过可解释的自动化评估和纠正来补充，以实现与人类不断演变的价值观的持续对齐。内在主动对齐则扎根于对自我的深刻理解、对他人的认知以及对社会的认识，通过自我意识、自我反省和同理心来自发推理人类意图，区分善恶，并主动优先考虑人类福祉。该框架旨在通过迭代的人类-AGI/ASI共对齐，共同塑造共生价值观和规则，为实现安全和有益的AGI和ASI铺平道路，造福于人类以及共生生态。
### Conclusion
作者提出了一种名为‘超级协同’的愿景，即通过外部监督和内在主动对齐的结合，实现可持续共生社会，确保AI系统保持与人类价值观的一致性，并为AGI和ASI的安全与有益应用奠定基础。
## 118. `cs.AI` - Doppelganger 方法：通过基于提示的可转移对抗攻击破坏 LLM 代理的角色一致性 [PDF](https://arxiv.org/pdf/2506.14539), [HTML](https://arxiv.org/abs/2506.14539)
### Authors
Daewon Kang,YeongHwan Shin,Doyeon Kim,Kyu-Hwan Jung,Meong Hi Son
### Background
自从大型语言模型问世以来，提示工程现在能够快速、低耗地创建多样化的自主代理，并且这些代理已经广泛使用。然而，这种便利性也引发了人们对底层提示的安全性、鲁棒性和行为一致性以及防止这些提示被用户滥用的紧迫担忧。
### Innovation
本文提出了一种名为'Doppelganger 方法'的新方法，用于展示代理被劫持的风险，从而暴露系统的指令和内部信息。此外，定义了'对抗转移下的提示对齐崩溃 (PACAT) 水平'来评估对该类型攻击的脆弱性，并提出了'对抗转移告诫 (CAT) 提示'以抵御 Doppelganger 方法。实验结果表明，Doppelganger 方法会破坏代理的一致性并暴露其内部信息，而 CAT 提示则能够有效防御对抗攻击。
### Conclusion
Doppelganger 方法可以破坏代理角色的一致性和暴露其内部信息，而 CAT 提示则能够有效地抵御此类对抗攻击。
## 119. `cs.AI` - Fast Monte Carlo Tree Diffusion: 100x Speedup via Parallel Sparse Planning [PDF](https://arxiv.org/pdf/2506.09498), [HTML](https://arxiv.org/abs/2506.09498)
### Authors
Jaesik Yoon,Hyeonseo Cho,Yoshua Bengio,Sungjin Ahn
### Background
扩散模型最近成为轨迹规划的强大方法。然而，它们的非顺序特性限制了在测试时进行长期推理任务的效果。Monte Carlo Tree Diffusion (MCTD) 近期提出了一个解决方法，通过将扩散模型与基于树的搜索结合，已在复杂规划问题上达到最新性能。尽管 MCTD 算法在多项测试中展示了其优势，但我们的分析显示，计算开销依然很高，这是由于基于树的搜索的顺序性质以及迭代降噪过程的成本。
### Innovation
我们提出了 Fast-MCTD，这是一种更有效的变体，保留了 MCTD 的优势，同时显著提高了其速度和可扩展性。Fast-MCTD 结合了两种技术：通过延迟树更新和冗余感知选择实现的并行 MCTD；以及通过轨迹约简实现的稀疏 MCTD。实验结果表明，与标准 MCTD 相比，Fast-MCTD 在某些任务中可实现高达 100 倍的速度提升，同时保持或改善了规划性能。值得注意的是，即使 Diffuser 要求无搜索但提供了较弱解决方案，Fast-MCTD 甚至在某些任务中的推理速度上仍然更胜一筹。
### Conclusion
Fast-MCTD 被定位为基于扩散模型的实用且可扩展的推理时间推断解决方案，在实际应用中展示了显著的优势。
## 120. `cs.AI` - Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities [PDF](https://arxiv.org/pdf/2506.18019), [HTML](https://arxiv.org/abs/2506.18019)
### Authors
Yuanchen Bei,Weizhi Zhang,Siwen Wang,Weizhi Chen,Sheng Zhou,Hao Chen,Yong Li,Jiajun Bu,Shirui Pan,Yizhou Yu,Irwin King,Fakhri Karray,Philip S. Yu
### Background
近期AI代理经历了范式的转变，从早期以强化学习(Reinforcement Learning, RL)为主导，到后来由大型语言模型(Large Language Models, LLMs)驱动，再到进一步融合RL与LLMs的能力。这一进展赋予了AI代理越来越强的能力。然而，为完成复杂现实任务，代理仍然需要有效规划与执行、保持可靠的记忆力以及与其他代理顺利协调。面对日益复杂的任务需求，亟需提升代理的数据结构化能力，将复杂的非结构化数据转换为便于理解与处理的结构化形式。图技术凭借其组织、管理和利用复杂数据关系的天然优势，在解决这一需求方面展现出强大的潜力。
### Innovation
本文提供了一个系统性的回顾，探讨如何通过利用图技术来增强AI代理的能力。具体来说，本文探索了将图技术与核心代理功能的结合，强调了典型应用，并指出了未来研究的潜在方向。
### Conclusion
通过全面概述这一新兴领域，本文旨在激发开发具备图技术的下一代AI代理，以应对更加复杂的挑战。此外，相关资源在GitHub页面上进行了汇总和持续更新，以支持社区研究。
## 121. `cs.AI` - 大型语言模型（LLMs）对非洲语言的状态：进展与挑战 [PDF](https://arxiv.org/pdf/2506.02280), [HTML](https://arxiv.org/abs/2506.02280)
### Authors
Kedir Yassin Hussen,Walelign Tewabe Sewunetie,Abinew Ali Ayele,Sukairaj Hafiz Imam,Shamsuddeen Hassan Muhammad,Seid Muhie Yimam
### Background
大型语言模型（LLMs）正在改变自然语言处理（NLP），但它们对非洲的2,000种低资源语言带来了较少的好处。本文通过比较分析六种LLMs、八种小型语言模型（SLMs）和六种专门的小语言模型（SSLMs）非洲语言的覆盖率，并涵盖了语言覆盖率、训练集、技术限制、文字问题和语言建模路线图的评估。研究表明有42种支持的非洲语言和23个可用的公开数据集，但仍然存在很大的差距，因为有四种语言（阿姆哈拉语、斯瓦希里语、南非荷兰语和马达加斯加语）总是被处理，而超过98%的非洲语言未被支持。同时，研究发现只识别了拉丁、阿拉伯和吉扎语三种文字，而有20种活动的文字被忽略。主要挑战包括缺乏数据、分词偏差、计算成本非常高以及评估问题。这些问题需要语言标准化、社区的语料库开发和针对非洲语言的有效适应方法.
### Innovation
本文通过比较分析六种大型语言模型、八种小型语言模型和六种专门的小语言模型，首次清晰地展示了非洲语言在这些模型中的覆盖率和面临的问题.
### Conclusion
需要语言标准化、社区的语料库开发和针对非洲语言的有效适应方法来解决存在的问题。现有的技术限制和数据不足意味着非洲语言的处理进步还有很长的路要走.
## 122. `cs.AI` - 驯服未知：基于图的知识检索与推理使MLLMs对抗未知 [PDF](https://arxiv.org/pdf/2506.17589), [HTML](https://arxiv.org/abs/2506.17589)
### Authors
Bowen Wang,Zhouqiang Jiang,Yasuaki Susumu,Shotaro Miwa,Tianwei Chen,Yuta Nakashima
### Background
知识的价值不仅仅在于积累，还在于有效利用知识来解决未知问题。尽管近期多模态大型语言模型（MLLMs）展示了令人印象深刻的多模态能力，但在罕见的专门领域任务中，由于缺乏相关知识，这些模型经常表现不佳。为了研究该问题，我们选择视觉游戏认知作为测试平台，并选择了《怪物猎人：世界》这款游戏来构建一个多模态知识图谱（MH-MMKG），该图谱整合了多种模态和复杂的实体关系。我们还设计了一系列基于MH-MMKG的具有挑战性的查询，以评估模型的复杂知识检索和推理能力。进一步提出了一种多剂恢复算法，允许模型自主搜索相关知识而无需额外训练，实验结果表明该方法显著提高了MLLMs的表现，为未来研究提供了新的视角和坚实的基础。
### Innovation
我们提出了一种多剂恢复算法，使模型能够自主搜索相关知识而无需额外训练，并基于多模态知识图谱（MH-MMKG）进行复杂查询，从而增强了MLLMs的能力，展示了基于图的知识检索与推理方法的新视角。
### Conclusion
我们的方法显著提升了MLLMs的表现，提供了多模态知识增强推理的新视角，并为未来研究奠定了坚实的基础。
## 123. `cs.AI` - 结构化无结构数据：多智能体系统提取和查询财务关键绩效指标和指导 [PDF](https://arxiv.org/pdf/2505.19197), [HTML](https://arxiv.org/abs/2505.19197)
### Authors
Chanyeol Choi,Alejandro Lopez-Lira,Yongjae Lee,Jihoon Kwon,Minjae Kim,Juneha Hwang,Minsoo Ha,Chaewoon Kim,Jaeseon Ha,Suyeol Yun,Jin Kim
### Background
从非结构化的财务报告中提取结构化和定量的见解对于投资研究至关重要，但目前这仍旧是一个耗时且资源密集的过程。传统方法依赖于劳动密集型的手动处理过程，这限制了可扩展性和研究工作流程的速度。本文旨在提出一个高效且可扩展的方法，利用大语言模型和多智能体系统从非结构化的财务文件中准确提取定量见解。
### Innovation
提出了一个多智能体系统，通过使用大语言模型自动识别关键绩效指标（KPI）并生成可执行的SQL语句，从而实现非结构化文本向结构化数据的转换，同时支持自然语言查询以访问结构化数据。该系统通过实验证明了其有效性和高准确性，达到了与人类标注者相当的水平，并能够跨不同类型的财务文件泛化，保持可靠的表现。
### Conclusion
通过实验展示了所提出的系统能够准确地将非结构化文本转换为结构化数据，并能精确检索关键信息。系统的表现接近人类标注者，91%的自然语言查询结果被人工评价者评为正确答案。该系统的跨文档类型的一致性能表明其可靠性和有效性。
## 124. `cs.AI` - Metis-RISE：RL激励和SFT增强多模态推理模型学习 [PDF](https://arxiv.org/pdf/2506.13056), [HTML](https://arxiv.org/abs/2506.13056)
### Authors
Haibo Qiu,Xiaohan Lan,Fanfan Liu,Xiaohu Sun,Delian Ruan,Peng Shi,Lin Ma
### Background
近期，大规模语言模型（LLMs）的发展推动了高级推理范式的出现，并将其集成到多模态大规模语言模型（MLLMs）中。然而，现有方法存在局限性：单纯采用强化学习（RL）的方法可能面临样本效率低和激活缺失的推理能力的问题；传统的从冷启动监督微调（SFT）阶段开始，然后才进行RL的流水线可能会限制模型的探索能力并面临次优收敛问题。
### Innovation
本文提出了一种名为Metis-RISE的新方法，该方法不同于传统的去除初始SFT阶段，从RL阶段开始，使用Group Relative Policy Optimization等变种激励并激活模型的潜在推理能力。在RL后，SFT阶段通过自推理以解决RL过程中识别的两个关键挑战：（1）任务中模型虽然具备但不一致应用正确推理时的低效轨迹采样问题；（2）模型完全失败时的功能缺失问题，通过注入专家增强的知识来解决。这一RL激励后SFT强化的设计理念构成了Metis-RISE的核心，从而构建了两种参数为7B和72B的MLLMs模型，并在OpenCompass多模态推理排行榜上展示了优异的性能。
### Conclusion
Metis-RISE在7B和72B参数的多模态推理模型中实现了最佳表现，72B模型在全球排名中位列第四。研究结果表明，这种方法比传统的SFT方法更有效，可以更好地激活和利用模型的潜在推理能力，同时通过SFT阶段进行优化，提高模型性能。这一工作为多模态大型语言模型的学习提供了一种新的解决方案和思路。
## 125. `cs.AI` - 在LLM模拟谈判对话中探索五大人格特质和人工智能能力的影响 [PDF](https://arxiv.org/pdf/2506.15928), [HTML](https://arxiv.org/abs/2506.15928)
### Authors
Myke C. Cohen,Zhe Su,Hsien-Te Kao,Daniel Nguyen,Spencer Lynch,Maarten Sap,Svitlana Volkova
### Background
本文提出的框架用于评估关键任务谈判情境下的代理型人工智能系统，并且需要具有能够适应多样化人类操作者和相关方的AI代理。研究目的在于评估代理型AI系统在跨团队协调、民政军事互动等涉及多方协调的应用中的表现。文章利用Sotopia模拟测试平台进行了两个实验，以系统地评估人格特质和代理型AI系统特性如何影响基于语言模型（LLM）的社交谈判结果，这对于实时问题解决和复杂任务协调至关重要。研究发现，五大人格特质中的宜人性和外向性对谈判成效有显著影响，并提供了具体的方向以提升代理型AI在高风险操作场景下的可靠性能。同时，通过模拟人与AI系统特性（如透明度、专业性、适应性）的变化，第二实验考察了这种变异性对谈判中人际信任的影响，从而影响任务效率。这两项实验建立了代理型AI系统可靠性的衡量标准，适用于探索在不同操作者个性和人机团队动态下的AI系统表现，直接支持了对于高度可靠的人工智能系统的需求。研究将评估代理型人工智能的工作流程超越了传统的性能指标，进一步整合了对于复杂操作成功而言必不可少的社会动态因素。
### Innovation
本文创新地提出了一种针对关键任务谈判情境下代理型AI系统的评价框架，使用累积的语言模型（LLM）进行模拟试验，同时深入研究了五大人格特质和代理型AI系统特性对谈判结果的影响。通过这两个实验，文章不仅提供了关于如何提升代理型AI系统可靠性的具体建议，而且通过整合社会动态因素为评估代理型AI系统方法的创新提供了新的视角，即超越传统的性能指标评价，强调对复杂操作中的成功所需的必要社会动态因素的评估。
### Conclusion
本文的工作为进一步评价代理型人工智能的工作流程提供了新的方法，通过引入社会动态因素，这种评价方法可以更好地确保这些系统在高风险任务中的可靠性和有效性，直接支持了对于高度依赖的人工智能系统的操作需求。
## 126. `cs.AI` - 持续学习作为计算受限的强化学习 [PDF](https://arxiv.org/pdf/2307.04345), [HTML](https://arxiv.org/abs/2307.04345)
### Authors
Saurabh Kumar,Henrik Marklund,Ashish Rao,Yifan Zhu,Hong Jun Jeon,Yueyang Liu,Benjamin Van Roy
### Background
持续学习是指一种机制，能够随着时间的推移高效积累知识并发展出越来越复杂的技能。这一领域一直是人工智能领域的一项长期挑战，因其要求系统能够在整个生命周期中持续从新数据中学习并适应新环境，而不会遗忘已学习的内容。这需要解决学习任务的终身性问题，即所谓的永久性遗忘和灾难性遗忘问题。这篇文章通过将持续学习作为计算受限的强化学习来阐述和完善这一主题，旨在为后续研究提供更清晰的概念和工具框架。
### Innovation
文章提出了一个关于持续学习的新视角，将其视为计算受限的强化学习。通过这种方式，它可以为解决持续学习中的高效学习问题提供新的解决方案，并为该领域的进一步研究奠定了基础。文章还引入了一个关于持续学习的框架和工具集，以促进该领域的后续研究和发展。这一创新不仅对理解持续学习的机制有重要意义，还能推动实际应用中的性能改进。
### Conclusion
本文通过简化和形式化持续学习的概念，提出了一种新的计算受限的强化学习模型，并提供了相关框架和工具集。这些工作为更好地理解和设计能够随着时间和经验不断进化的高级人工智能代理奠定了理论基础，对未来人工智能的发展具有重大意义。
## 127. `cs.AI` - 智能电动车辆的乘车和配送服务：利用双向充电实现利润优化 [PDF](https://arxiv.org/pdf/2506.20401), [HTML](https://arxiv.org/abs/2506.20401)
### Authors
Jinchun Du,Bojie Shen,Muhammad Aamir Cheema,Adel N. Toosi
### Background
随着电动车辆（EVs）的日益普及，现代服务系统，如乘车服务和配送服务，越来越多地将EVs集成到其运营中。与传统车辆不同，EVs的行驶距离较短，因此需要在满足请求时仔细考虑充电问题。最近 Vehicle-to-Grid (V2G) 技术的发展使EVs能够向电网反向供电，带来了新的机会和复杂性。
### Innovation
本文提出了Electric Vehicle Orienteering Problem with V2G (EVOP-V2G)问题：一个利润最大化问题，要求电动车辆驾驶员在满足客户请求或订单的同时，必须管理何时何地充电或反向供电。该问题需要管理动态电价、充电站选择和路径约束。本文将该问题建模为混合整数规划（MIP）模型，并提出了一种基于进化的（EA）和基于大规模邻域搜索（LNS）的近优化元启发式算法。实验证明，该方法与基线相比可使驾驶员利润翻倍，同时在小实例上维持接近最优性能，并在大实例上具有出色的扩展性。
### Conclusion
本文的研究成果揭示了一条改进电动车辆为主要运输系统的道路，能够提高效率并支持电力网络。
## 128. `cs.AI` - 高效注意力头的变域注意机制在图像生成中的高效图像生成 [PDF](https://arxiv.org/pdf/2211.05770), [HTML](https://arxiv.org/abs/2211.05770)
### Authors
Steven Walton,Ali Hassani,Xingqian Xu,Zhangyang Wang,Humphrey Shi
### Background
尽管将变压器集成到视觉模型中在视觉任务上取得了显著的改进，但这些模型在训练和推理时仍需要大量的计算资源。受限的注意机制显著减少了这些计算负担，但会牺牲全局或局部的连贯性。为了减少这些权衡，论文提出了一种简单有效的方法：允许单个变压器的注意头可以关注多个感受野。该方法被应用到基于StyleGAN的架构中，从而提出了一种名为StyleNAT的新模型。
### Innovation
提出了一种简单的但强有力的变域注意机制（Variadic Attention Heads），允许单个变压器的注意头可以关注多个感受野，从而在保持全局和局部连贯性的同时减少计算负担。在基于StyleGAN的架构中实现了该机制，命名为StyleNAT模型，在FFHQ数据集上实现了2.05的FID值，比StyleGAN-XL减少了6%的参数，并且吞吐量提升了4倍。StyleNAT在FFHQ-256上实现了帕累托前沿，并在其他数据集上展示了强大的高效的图像生成能力。
### Conclusion
通过StyleNAT，可以在保持模型效果的同时显著减少计算需求，展示了在基于StyleGAN架构中的有效应用和高效图像生成。
## 129. `cs.AI` - PuriDefense：针对黑盒查询型攻击的随机局部隐式对抗净化防御机制 [PDF](https://arxiv.org/pdf/2401.10586), [HTML](https://arxiv.org/abs/2401.10586)
### Authors
Ping Guo,Xiang Li,Zhiyuan Yang,Xi Lin,Qingchuan Zhao,Qingfu Zhang
### Background
黑盒查询型攻击对机器学习即服务（MLaaS）系统构成了重大威胁，因为这类攻击能够生成对抗样本而不接触目标模型的架构和参数。传统的防御机制，如对抗训练、梯度掩蔽和输入变换，要么会导致大量的计算成本，要么会损害非对抗性输入的测试准确性。鉴于这些挑战，迫切需要一种有效且低成本的防御机制来应对这些攻击。
### Innovation
本文提出了一种高效的防御机制PuriDefense，该机制利用轻量级净化模型中的随机块级净化技术，在较低的推理成本下工作。PuriDefense通过随机性集成局部隐式函数，重新构建自然图像流形，从而减慢基于查询的攻击的收敛速度。这种基于净化器的防御机制在CIFAR-10和ImageNet上的广泛实验中证明了其有效性和对基于查询的攻击的强大鲁棒性，显示出显著的改进。
### Conclusion
理论分析表明，通过在净化过程中引入随机性，可以减慢基于查询的攻击的收敛速度。大量实验验证了基于净化器的防御机制的有效性，表现出对基于查询的攻击的显著改进。PuriDefense为MLaaS系统提供了一种有效的低成本防御方案，能够抵抗黑盒查询型攻击。
## 130. `cs.AI` - GREAT 架构：解决TSP等边缘基图问题 [PDF](https://arxiv.org/pdf/2408.16717), [HTML](https://arxiv.org/abs/2408.16717)
### Authors
Attila Lischka,Filip Rydin,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár
### Background
近年来，基于学习的方法被提出用于解决诸如路由问题等组合优化问题。这些方法大多基于图神经网络（GNNs）或相关变压器，这些操作基于代表路由问题的欧几里得坐标。然而，在现实中，很多问题实例是非欧几里得且不对称的，传统的在欧几里得坐标上操作的模型并不适合这些情况。目前没有学习型求解器很好地应对非欧几里得的这些问题版本，因此需要一个新的模型来克服这种局限性。
### Innovation
本文提出了一个新的边缘聚焦的GNN模型——Graph Edge Attention Network (GREAT)，使用GREAT作为编码器来捕捉路由问题实例的特性，并构建了一个强化学习框架，应用于欧几里得和非欧几里得版本的车辆路线问题，如旅行商问题（TSP），容量受限车辆路线问题和开拓者问题。这是首个解决这些非欧几里得问题版本的框架之一，表现出与基于学习的求解器竞争的结果
### Conclusion
本文提出的方法能够有效地解决非欧几里得的组合优化问题，并且在强化学习框架下实现了与现有学习型求解器相比具有竞争力的结果。
## 131. `cs.AI` - NFISiS: New Perspectives on Fuzzy Inference Systems for Renewable Energy Forecasting [PDF](https://arxiv.org/pdf/2506.06285), [HTML](https://arxiv.org/abs/2506.06285)
### Authors
Kaike Sa Teles Rocha Alves,Eduardo Pestana de Aguiar
### Background
尽管深度学习模型因其广受欢迎而被广泛应用，但它们也面临着长期的训练时间和缺乏可解释性等挑战。相比之下，模糊推理系统提供了一种准确性和透明度之间的平衡。传统的Takagi-Sugeno-Kang模糊模型在处理复杂性较大的数据集时存在局限性。为了解决这些问题，本文通过将最近提出的新型Takagi-Sugeno-Kang模型扩展为基于Mamdani的新模型，来解决传统Takagi-Sugeno-Kang模糊模型的局限性。这些模型是数据驱动的，允许用户定义规则的数量以平衡准确性和可解释性。为了处理大数据集的复杂性，该研究整合了包装和集成技术。使用遗传算法作为包装器进行特征选择，并创建了该模型的遗传版本。此外，还介绍了集成模型，包括随机新型Mamdani回归器、随机新型Takagi-Sugeno-Kang和随机森林新型Takagi-Sugeno-Kang模型，以提高模型的稳健性。这些模型在光伏能源预测数据集上进行了验证，这是由于太阳能电力的间歇性性质，使其成为一个关键的应用。
### Innovation
1. 将最近提出的新型Takagi-Sugeno-Kang模型扩展为基于Mamdani的新模型，以解决传统模型的局限性。2. 使用遗传算法作为特征选择的包装器，创建了遗传版本的模型。3. 引入了集成模型，如随机新型Mamdani回归器、随机新型Takagi-Sugeno-Kang和随机森林新型Takagi-Sugeno-Kang模型，以提高模型的稳健性。4. 模型通过光伏能源预测数据集进行了验证，并展示了比传统机器学习和深度学习模型更好的性能，同时提供了一个更简单且更可解释的基于规则的结构
### Conclusion
所提出的模型在光伏能源预测数据集上表现出优越的性能，通常优于传统机器学习和深度学习模型。这些模型在简化和可解释性方面提供了更简单且更可解释的结构。所提出的模型已经在名为nfisis的库中提供。
## 132. `cs.AI` - ClimateIQA: 气候IQA-一个新的数据集和基准以推动气象异常分析中的视觉-语言模型 [PDF](https://arxiv.org/pdf/2406.09838), [HTML](https://arxiv.org/abs/2406.09838)
### Authors
Jian Chen,Peilin Zhou,Yining Hua,Dading Chong,Meng Cao,Yaowei Li,Wei Chen,Bing Zhu,Junwei Liang,Zixuan Yuan
### Background
气象热图在揭示极端天气现象方面发挥着重要作用，但由于其不规则的轮廓、无序的模式和复杂的颜色变化，给最先进的视觉-语言模型（VLMs）带来了独特的分析挑战。当前最先进的模型，如GPT-4o、Qwen-VL和LLaVA 1.6，在精确颜色识别和空间定位方面存在困难，导致不准确或不完整的解释。
### Innovation
为了应对这些挑战，作者引入了Sparse Position and Outline Tracking (SPOT)算法，这是一种专门设计用于处理视觉数据中不规则形状彩色区域的新算法。SPOT通过提取空间坐标来识别并定位这些区域，从而提供不规则形状的结构化表示。基于SPOT，作者构建了ClimateIQA，这是一个新的气象视觉问答（VQA）数据集，包含26,280个高分辨率热图和762,120个面向风速、总降水量、风寒指数和热指数分析的指令样本。ClimateIQA通过整合空间线索、地理元数据和再分析数据来增强VLM培训，并提高模型在解释和描述极端天气特征方面的准确性。此外，作者还开发了Climate-Zoo，这是基于SPOT增强的ClimateIQA的精细调整视觉语言模型套件，使其在气象热图任务上显著优于现有模型。
### Conclusion
ClimateIQA通过提供新的维数和增强的训练数据集，进一步促进了视觉-语言模型在气象异常分析中的性能和准确性。
## 133. `cs.AI` - MockLLM：一种用于在线求职和招聘的多智能体行为协作框架 [PDF](https://arxiv.org/pdf/2405.18113), [HTML](https://arxiv.org/abs/2405.18113)
### Authors
Hongda Sun,Hongzhan Lin,Haiyu Yan,Yang Song,Xin Gao,Rui Yan
### Background
在线招聘平台重塑了求职和招聘流程，增加了对提升人岗匹配的应用需求，传统方法主要依赖于分析简历和职位描述中的文本数据，这限制了动态交互等有效招聘的关键方面。近年来，大型语言模型（LLMs）的进步展示了在模拟适应性、角色对话方面的显著潜力，使其非常适合招聘场景。然而，传统的基于文本的方法缺乏交互性和动态调整能力，无法满足上述需求，亟需创新方法来提高人岗匹配的效率和质量。
### Innovation
该研究提出了MockLLM，一个用于生成和评估模拟面试对话的新型框架。该系统包括模拟面试生成和双向握手协议评价两大部分。通过模拟面试官和求职者角色，MockLLM能够实现一致且协作的互动，从而促进即时双向匹配。更重要的是，它还结合了反思记忆生成和动态策略修改，以基于先前的经验来完善行为。与现有方法相比，MockLLM在匹配准确性、可扩展性和跨领域适应性方面表现出色，表明其在候选人评估和在线招聘方面的潜在优势。
### Conclusion
通过在一家大型中国招聘平台Boss Zhipin上的实际数据评估，MockLLM证明了它在提高人岗匹配质量方面的显著优势，为求职和招聘提供了新的解决方案，标志着在线招聘技术的一个重要进步。
## 134. `cs.AI` - HERMES: 与时间和情节相一致的长期形式理解 [PDF](https://arxiv.org/pdf/2408.17443), [HTML](https://arxiv.org/abs/2408.17443)
### Authors
Gueter Josmy Faure,Jia-Fong Yeh,Min-Hung Chen,Hung-Ting Su,Shang-Hong Lai,Winston H. Hsu
### Background
长视频理解面临着超越传统短视频分析方法的独特挑战，特别是在捕捉长范围依赖性、高效处理冗余信息和提取高层次语义概念方面。现有的方法难以有效应对这些挑战。
### Innovation
本文提出了HERMES方法，这是一种两模块结合的方法，包括高效的情境压缩模块（ECO）和语义检索模块（SeTR）。ECO能够高效地从微至半宏观层次聚合表示，减少计算开销同时保留时间依赖性。SeTR通过聚焦于更广泛的上下文来丰富这些表示的语义信息，从而减少特征维度并保留相关宏观层级的信息。这些模块能够无缝集成到现有的SOTA模型中，提升性能的同时将推理延迟降低多达43%，内存使用率降低46%。作为独立系统，HERMES在多个长视频理解基准上取得了最先进的性能，在零样本和全监督设置下也不例外。
### Conclusion
HERMES通过其新颖的设计显著提高了长视频理解的准确性和效率，在多个基准测试中表现出色。
## 135. `cs.AI` - 从无人机影像中提取地理位置标记的车辆轨迹的高级计算机视觉技术 [PDF](https://arxiv.org/pdf/2411.02136), [HTML](https://arxiv.org/abs/2411.02136)
### Authors
Robert Fonod,Haechan Cho,Hwasoo Yeo,Nikolas Geroliminis
### Background
本文讨论了从高空无人机影像中提取地理位置标记的车辆轨迹的方法，解决了城市交通监控中的关键挑战以及传统地面系统限制。该研究在韩国首尔的松岛国际商务区进行，使用多无人机实验覆盖20个交叉口，采集了四天约12TB的4K视频数据。
### Innovation
本文做出了多个创新贡献，包括专门为高空鸟瞰视角优化的对象检测器，用于图像对齐时作为排除掩码的检测到的车辆边界框的独特轨迹稳定方法，以及基于正射影像和主画面的空间参考策略，利用这些策略增强从多个无人机视角中一致性对齐。此外，该框架还包括了强大的车辆尺寸估计和详细的道路分割功能，这使得全面的交通分析成为可能。
### Conclusion
研究结果表明，结合无人机技术和高级计算机视觉技术可以在城市环境中实现精确且成本效益高的交通监控，并为智能交通系统的发展提供了宝贵的资源。公开发布的松岛交通数据集和松岛视觉数据集以及提取管道的完整源代码为交通研究设立了新的基准，提供了高质量、可复现性和扩展性的数据。
## 136. `cs.AI` - 从记忆到地图：Transformer 中上下文内强化学习的机制 [PDF](https://arxiv.org/pdf/2506.19686), [HTML](https://arxiv.org/abs/2506.19686)
### Authors
Ching Fang,Kanaka Rajan
### Background
人类和动物表现出显著的学习效率，能够在有限的经验中适应新的环境。现有的强化学习算法依赖逐次的价值更新，未能充分捕捉这种能力。快速适应能力可能依赖于情景记忆，即检索特定的过去经验来指导在新环境中做出的决策。Transformers 由于其能够快速在上下文中学到和其关键-值架构与大脑中情景记忆系统相似的原因，成为了研究这些问题的良好体系。
### Innovation
提出了一个训练 Transformer 在灵感源自于啮齿类行为分布的规划任务中进行上下文内强化学习的方法。该方法找到了代表学习的支持机制，包括上下文内部结构学习和跨上下文对齐，使得表示能够在不同感官刺激的环境中对齐。同时，证明了模型发展的强化学习策略无法解释为标准的模型自由或基于模型的规划，而是证明在模型的记忆令牌中缓存中间计算，在决策时访问这些令牌支持上下文内强化学习。研究发现记忆可能作为计算资源，存储原始经验和缓存的计算，以支持灵活的行为。
### Conclusion
总的来说，研究发现记忆在支持上下文内学习中可能作为计算资源，存储备份经验和缓存计算，以支持灵活行为。模型发展的表示与大脑中的海马-内嗅皮质系统中的计算相关，表明该研究发现可能与自然认知有关。整体来说，该工作为理解上下文内学习的快速适应机制提供了机制性假设。
## 137. `cs.AI` - InterFormer：点击率预测中有效的异构交互学习 [PDF](https://arxiv.org/pdf/2411.09852), [HTML](https://arxiv.org/abs/2411.09852)
### Authors
Zhichen Zeng,Xiaolong Liu,Mengyue Hang,Xiaoyi Liu,Qinghai Zhou,Chaofei Yang,Yiqun Liu,Yichen Ruan,Laming Chen,Yuxin Chen,Yujia Hao,Jiaqi Xu,Jade Nie,Xi Liu,Buyun Zhang,Wei Wen,Siyang Yuan,Hang Yin,Xin Zhang,Kai Wang,Wen-Yen Chen,Yiping Han,Huayu Li,Chunzhi Yang,Bo Long,Philip S. Yu,Hanghang Tong,Jiyan Yang
### Background
点击率（CTR）预测是推荐系统中的一个基本任务，它预测用户点击广告的概率。异质信息，如用户资料和行为序列，从不同角度描绘了用户兴趣。异质信息的有效整合是CTR预测成功的关键。然而，现有方法存在两个根本性问题：一，由于模式间单向信息流动导致的交互不足；二，由于过早地信息汇总导致的信息丢失过多。
### Innovation
为解决上述问题，本文提出了一种名为InterFormer的新模块，以交错方式进行异质信息交互学习。InterFormer实现了不同模式之间的双向信息流动以促进互惠学习。同时，它保留了每个数据模式中的完整信息，并使用独立的桥梁结构进行有效的信息选择和汇总，从而避免了过度的信息聚合。
### Conclusion
提出的InterFormer在三个公开数据集和一个大规模工业数据集上都达到了最先进的性能。
## 138. `cs.AI` - Recall and Refine: 一种简单而有效的无源开放集域适应框架 [PDF](https://arxiv.org/pdf/2411.12558), [HTML](https://arxiv.org/abs/2411.12558)
### Authors
Ismail Nejjar,Hao Dong,Olga Fink
### Background
Open-set域适应（OSDA）旨在将标记的源域模型适应到未标记的目标域，其中目标域可能存在新的未见过的类。无源Open-set域适应（SF-OSDA）方法在不访问源域标记数据的情况下解决OSDA问题，使其在隐私受限的情况下尤为重要。然而，SF-OSDA存在显著挑战，如分布偏移和新类的引入。现有SF-OSDA方法通常通过阈值化样本的预测熵来识别已知或未知类，但未能明确学习针对目标特定未知类的区分特征。
### Innovation
提出了一种新颖的SF-OSDA框架Recall and Refine（RRDA），通过明确学习目标特定的未知类特征来解决现有方法的局限性。RRDA包含两阶段过程：首先，通过使用目标域特征生成的合成样本训练目标分类器，并提供额外的决策边界，增强模型识别未知类的能力。其次，使整个模型适应目标域，解决域偏移和与未知类的区分问题，允许无缝集成任何现成的无源域适应方法。
### Conclusion
广泛的实验证明RRDA在三个基准数据集上显著优于现有SF-OSDA和OSDA方法。
## 139. `cs.AI` - 快速陀螺仪校准：一种深度学习方法 [PDF](https://arxiv.org/pdf/2409.00488), [HTML](https://arxiv.org/abs/2409.00488)
### Authors
Yair Stolero,Itzik Klein
### Background
低消耗陀螺仪的校准对于确保其测量的准确性和可靠性至关重要。静态校准用于估计测量误差的确定部分，方法是测量期间将陀螺仪读数平均化并估计陀螺仪偏差。校准的持续时间在性能上起着重要作用，因此通常更倾向于使用较长的校准时间。然而，某些应用需要快速启动时间，因此允许进行短时间校准。本文研究了使用深度学习方法来减少低消耗陀螺仪校准时间的方法，探索了利用多个实际和模拟的陀螺仪来提高单个陀螺仪校准性能的可能方法。本文使用包含186.6小时陀螺仪读数的数据集和模拟数据集来训练并验证我们的方法，该数据集由36个不同品牌的陀螺仪记录生成，并将其用于评估我们的方法。这项工作的核心成就是使用三个低消耗陀螺仪将陀螺仪校准时间减少至多89%。该数据集已经公开，以确保研究的可复现性和促进相关领域的研究.
### Innovation
本文提出了一种端到端的卷积神经网络，用于陀螺仪校准的应用。探索利用多个实际和虚拟陀螺仪以提高单个陀螺仪校准性能的可能性。使用包含186.6小时陀螺仪读数的数据集和模拟数据集来训练和验证方法，并成功地将校准时间减少了最多89%，这对于需要快速启动的应用非常重要。该数据集已经公开，促进了相关领域的研究和重复实验的进行.
### Conclusion
本文成功地使用深度学习方法减少了低消耗陀螺仪的校准时间，通过端到端的卷积神经网络和多个实际与虚拟陀螺仪的应用实现校准性能的提升。通过对不同品牌的36个陀螺仪进行采集的数据集以及模拟数据集，验证了方法的有效性，实现了一次最大89%的校准时间效率提升，这将对于需要快速校准的应用场景非常有益。数据集的公开将促进进一步的实验研究并提高科学验证的能力。
## 140. `cs.AI` - 我的数据在我的AI模型中吗？基于面部图像的应用识别测试 [PDF](https://arxiv.org/pdf/2402.09225), [HTML](https://arxiv.org/abs/2402.09225)
### Authors
Daniel DeAlcala,Aythami Morales,Julian Fierrez,Gonzalo Mancera,Ruben Tolosana,Javier Ortega-Garcia
### Background
本文介绍了Membership Inference Test (MINT)，一种新的方法，旨在实证评估给定数据是否被用于训练AI/ML模型。实验框架集中于面部识别这一具有挑战性的任务上，考虑了三项最先进的面部识别系统。实验使用了六个公开的数据集，总共包含超过2200万张面部图像。根据AI模型测试的上下文，考虑了不同的实验场景。该研究所提出的MINT方法取得了显著成果，准确率高达90%，显示出识别特定数据是否被用于训练或调整AI模型的潜力。MINT方法可以应用于多种AI应用，例如揭示是否使用了敏感或私人数据来训练或调整大型语言模型（LLMs）
### Innovation
提出了两种MINT架构，基于多层感知器（MLPs）和卷积神经网络（CNNs），用于学习审计模型在暴露于其训练过程中使用的数据时产生的独特激活模式。这提供了实证评估训练数据识别的新方法，尤其是在面部识别等具有挑战性任务的应用中
### Conclusion
所提出的MINT方法在不同的实验场景中取得了令人鼓舞的结果，准确率达90%，表明了识别特定数据是否被用于训练或调整AI模型的潜力。MINT方法可以用于促进AI应用中的隐私和公平性，例如揭示大型语言模型（LLMs）等是否使用了特定的敏感或私密数据进行训练或调整
## 141. `cs.AI` - 预训练可逆生成作为无监督视觉特征学习 [PDF](https://arxiv.org/pdf/2412.01787), [HTML](https://arxiv.org/abs/2412.01787)
### Authors
Rongkun Xue,Jinouwen Zhang,Yazhe Niu,Dazhong Shen,Bingqi Ma,Yu Liu,Jing Yang
### Background
近年来，基于评分匹配和流匹配的生成模型在生成任务中取得了显著进展，但它们在判别任务中的潜力尚未得到充分探索。以往的生成分类等方法未能充分利用这些模型在判别任务中的能力，因为这些模型的设计较为复杂。
### Innovation
本文提出了一种名为Pretrained Reversible Generation (PRG)的方法，该方法通过反转预训练连续生成模型的生成过程来提取无监督表示。PRG能够有效重用无监督生成模型，利用其高容量作为鲁棒且通用的特征提取器，适用于下游任务。此外，该框架还允许灵活选择特定下游任务的特征层次结构。实验结果表明，该方法在多个基准测试中均优于先前的方法，特别是在生成模型基础上的方法中取得了最佳性能，具体来说，在64*64分辨率的ImageNet数据集上的top-1精度达到了78%。进一步的消融实验证明了该方法的有效性。
### Conclusion
我们的方法在多种基准测试中均表现出色，尤其是在基于生成模型的方法中达到了最先进的性能。此外，我们进行了广泛的消融研究和离域评估，进一步验证了该方法的有效性。
## 142. `cs.AI` - InfiniCube：基于世界引导的视频模型的无界限控制性动态3D驾驶场景生成 [PDF](https://arxiv.org/pdf/2412.03934), [HTML](https://arxiv.org/abs/2412.03934)
### Authors
Yifan Lu,Xuanchi Ren,Jiawei Yang,Tianchang Shen,Zhangjie Wu,Jun Gao,Yue Wang,Siheng Chen,Mike Chen,Sanja Fidler,Jiahui Huang
### Background
现有场景生成方法要么规模有限，要么在生成序列中缺乏几何和外观一致性。本文通过利用可扩展的3D表示和视频模型的最新进展，提出了InfiniCube方法，可以在高清地图、车辆边界框和文本描述驱动下生成灵活控制的大规模动态场景。
### Innovation
InfiniCube方法利用了基于稀疏体素的3D生成模型，通过精心设计的像素对齐指导缓冲器重新利用视频模型，实现了一致的外观合成。最后，通过体素和像素分支相结合的快速前馈方法，将动态视频转化为可控的动态3D高斯分布。相比以往方法，InfiniCube可以在无边界条件下生成可控制、真实的3D驾驶场景，并通过大量实验验证了其有效性和优越性。
### Conclusion
InfiniCube方法可以生成具有可控制性和真实性的3D驾驶场景，实验结果证明了该模型的有效性和优越性能。
## 143. `cs.AI` - ToolScan: 一种表征工具使用大型语言模型错误的标准 [PDF](https://arxiv.org/pdf/2411.13547), [HTML](https://arxiv.org/abs/2411.13547)
### Authors
Shirley Kokane,Ming Zhu,Tulika Awalgaonkar,Jianguo Zhang,Thai Hoang,Akshara Prabhakar,Zuxin Liu,Tian Lan,Liangwei Yang,Juntao Tan,Rithesh Murthy,Weiran Yao,Zhiwei Liu,Juan Carlos Niebles,Huan Wang,Shelby Heinecke,Caiming Xiong,Silivo Savarese
### Background
评估大型语言模型（LLMs）是构建高性能复合AI系统的关键方面。由于LLMs的输出会传递到后续步骤中，识别LLMs的错误对于系统的性能至关重要。在AI系统中，LLMs的一个常见任务是使用工具。尽管有一些用于评估LLMs工具使用任务的标准环境，但它们通常只提供成功率，而不解释失败案例。ToolSCAN是一个新的基准，旨在识别LLMs在工具使用任务中输出中的错误模式。该基准的数据集包括来自不同环境的查询，可以用来测试七个新表征的错误模式的存在。
### Innovation
ToolSCAN是一个新的基准，旨在识别LLMs在工具使用任务中输出中的错误模式。它提供了更具体的错误识别和分析方法，能够表征并分类LLMs的错误。此外，使用ToolSCAN，研究人员能够发现即使是最杰出的LLMs在其输出中也存在这些错误模式，这为错误缓解策略提供了指导依据。
### Conclusion
ToolSCAN展示了大型语言模型在工具使用任务中存在多种模式的错误，研究人员可以利用这些洞察来指导错误缓解策略。
## 144. `cs.AI` - SIDA：使用大规模多模态模型的社交媒体图像深度假信息检测、定位与解释 [PDF](https://arxiv.org/pdf/2412.04292), [HTML](https://arxiv.org/abs/2412.04292)
### Authors
Zhenglin Huang,Jinwei Hu,Xiangtai Li,Yiwei He,Xingyu Zhao,Bei Peng,Baoyuan Wu,Xiaowei Huang,Guangliang Cheng
### Background
生成模型的迅速发展使得生成极具真实感的图像成为可能，这同时也带来了信息误导的风险。例如，合成图像在社交媒体上共享时，可能会误导大量受众，损害数字内容的信任度，导致严重后果。然而，学术界尚未创建一个庞大且多样化的深度假信息检测数据集，也未提出有效的解决办法。文献回顾指出这一研究缺口，强调了当前领域面临的挑战。
### Innovation
本文提出了一种新的图像深度假信息检测、定位和解释框架SIDA，同时发布了名为 SID-Set 的数据集。SID-Set 具备以下三个特点：首先，其数量庞大，包含30万张AI生成/篡改和真实图像，且具有全面的注释；其次，其多样性广泛，涵盖了各类全合成和篡改图像；最后，其真实度高，大多数图像在视觉上不可辨认。此外，该框架利用了大型多模态模型的优势，实现了图像的深度假信息检测与定位，并提供了模型决策依据的文本解释。与现有最先进的深度假信息检测模型在 SID-Set 以及其它基准上的比较实验显示，SIDA在多样化设置中表现出更优性能。
### Conclusion
大量的实验表明，SIDA 在各种环境下均表现出众，优于现有最先进的模型。为此，发布的代码、模型和数据集为后续研究提供了基础。
## 145. `cs.AI` - 拉格朗日指数策略用于平均回报的歇息多臂老虎机 [PDF](https://arxiv.org/pdf/2412.12641), [HTML](https://arxiv.org/abs/2412.12641)
### Authors
Konstantin Avrachenkov,Vivek S. Borkar,Pratik Shah
### Background
本文研究了长期平均回报歇息多臂老虎机的拉格朗日指数策略（LIP），并将其与韦尔布尔指数策略（WIP）进行了比较。尽管两种策略在大多数情况下的表现非常相似，但在WIP表现出不佳性能的情况下，LIP仍然表现出色。此外，文章还提出了一种无需模型的拉格朗日指数策略的强化学习算法，该算法比WIP的类似算法所需的内存更少。此外，该研究还分析了重启模型的拉格朗日指数，适用于最优网页爬取和最小化加权信息年龄的情况。作者还基于交换性和De Finetti定理，给出了同质多臂老虎机数量趋于无穷时渐近优化性的新证明。
### Innovation
文章创新性地提出了拉格朗日指数策略（LIP）和韦尔布尔指数策略（WIP）在长期平均回报歇息多臂老虎机中的比较；提出了一种无需模型的拉格朗日指数策略的强化学习算法；重新解析并给出了同质多臂老虎机渐近优化性的证明。突出特点是LIP在WIP表现不佳时仍有出色性能，且记忆占用少.
### Conclusion
文章证明了在特定条件下，拉格朗日指数策略（LIP）在退激多臂老虎机中具有渐近最优性。此外，该研究还对重启模型下的LIP进行了指数计算，并提供了新的同质多臂老虎机渐近最优性的证明。
## 146. `cs.AI` - GASP：生成对抗后缀以黑盒方式高效破解大型语言模型 [PDF](https://arxiv.org/pdf/2411.14133), [HTML](https://arxiv.org/abs/2411.14133)
### Authors
Advik Raj Basani,Xiao Zhang
### Background
大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但仍然易于受到精心设计的输入提示（jailbreak攻击）的影响，这些攻击可以绕过安全防线并产生有害的回应。传统方法依靠手动启发式规则，但这种方法的通用性有限。尽管基于优化的攻击方法可以自动生成，但它们往往会产生不自然的提示，这些提示容易被安全过滤器检测到，或者需要大量的计算资源进行离散标记优化。
### Innovation
本文引入了一种新颖的自动化框架——生成对抗后缀提示器（GASP），能够在完全黑盒环境下高效生成具有人类可读性的破解大型语言模型的提示。GASP利用潜在贝叶斯优化来精心设计对抗后缀，通过高效探索连续的潜在嵌入空间，逐步优化后缀提示器，同时通过目标迭代优化稳定生成对抗样本，提高了攻击的有效性并保持提示的一致性。
### Conclusion
全面的实验表明，GASP能够生成自然的对抗样本，显著提高了破解大型语言模型的成功率，减少了训练时间并加快了推理速度，因此，GASP是一种高效且可扩展的解决方案，用于对大型语言模型进行红队测试。
## 147. `cs.AI` - Materialist: 单张图像逆渲染的基于物理的编辑 [PDF](https://arxiv.org/pdf/2501.03717), [HTML](https://arxiv.org/abs/2501.03717)
### Authors
Lezhong Wang,Duc Minh Tran,Ruiqi Cui,Thomson TG,Anders Bjorholm Dahl,Siavash Arjomand Bigdeli,Jeppe Revall Frisvad,Manmohan Chandraker
### Background
在计算机视觉中，实现物理上一致的图像编辑仍然是一个显著的挑战。现有方法通常依赖神经网络，但无法准确处理阴影和折射。相比之下，基于物理的逆渲染往往需要多视图优化，这在单图像场景中具有局限性。
### Innovation
论文提出了Materialist方法，结合了基于学习的方法与基于物理的逐次可微渲染。具体而言，给定一张图像，该方法利用神经网络预测初始材料属性，然后通过逐次可微渲染优化环境图并细化材料属性，目标是使渲染结果与输入图像尽可能一致。此外，该方法还引入了一种有效的透明材质编辑方法，无需完整场景几何结构，同时在合成和真实世界数据集上实现了超越现有方法的环境图估计性能，增强了图像编辑任务的准确性。实验结果表明该方法在合成和真实世界数据集上表现出色，甚至在具有挑战性的跨领域图像上也表现出色。
### Conclusion
实验结果表明，Materialist方法在合成和真实世界数据集上的表现非常强大，甚至在具有挑战性的跨领域图像上也表现出色。此外，该方法还为基于单图像的物理编辑提供了有效的方法，特别是在材料编辑、对象插入和重新照明等方面。
## 148. `cs.AI` - MvKeTR：基于多视角感知和知识增强的胸部CT报告生成 [PDF](https://arxiv.org/pdf/2411.18309), [HTML](https://arxiv.org/abs/2411.18309)
### Authors
Xiwei Deng,Xianchun He,Jianfeng Bao,Yudan Zhou,Shuhui Cai,Congbo Cai,Zhong Chen
### Background
CT报告生成（CTRG）旨在自动生成针对3D体积的诊断报告，减轻临床医护人员的工作负担并改善患者护理。尽管具备临床价值，现有工作在纳入来自多个解剖视角的诊断信息方面不够有效，缺乏准确可靠的诊断所需的临床专业知识。为了解决这些不足，本研究提出了一种新的多视角感知知识增强Transformer（MvKeTR），模仿临床医生的诊断流程。该方法首先利用多视角感知聚合器（MVPA）结合视图感知注意力从多个解剖视角综合诊断信息，随后引入了一种跨模态知识增强器（CMKE），根据查询的体积检索最相似的报告，以将领域知识融入诊断过程。此外，该方法采用柯尔莫哥洛夫-阿诺尔德网络（KANs）作为各个模块的基础构建块，以提高参数效率，减少光谱偏差，更好地捕捉CT解释中关键的高频成分，同时减轻过拟合问题。
### Innovation
研究提出了一种多视角感知知识增强Transformer（MvKeTR），以克服现有技术在融合多个解剖视角信息和缺乏相关临床知识方面的不足。具体创新点包括：1) 提出视图感知注意力的多视角感知聚合器（MVPA），有效整合来自多个解剖视角的诊断信息；2) 设计跨模态知识增强器（CMKE），通过检索相似报告将领域知识融入诊断过程；3) 采用柯尔莫哥洛夫-阿诺尔德网络（KANs）作为构建块，优于传统多层感知机（MLPs），表现出优异的参数效率和光谱偏置减少特性，提高CT解释能力并减轻过拟合问题。
### Conclusion
在公共CTRG-Chest-548K数据集上的广泛实验表明，该方法在几乎所有指标上都优于之前的最先进的（SOTA）模型。此研究通过提出MvKeTR，显著提升了CT报告生成的准确性和可靠性，为提高医疗效率和质量提供了新的解决方案。
## 149. `cs.AI` - UP-VLA: 统一理解与预测模型用于具身智能体 [PDF](https://arxiv.org/pdf/2501.18867), [HTML](https://arxiv.org/abs/2501.18867)
### Authors
Jianke Zhang,Yanjiang Guo,Yucheng Hu,Xiaoyu Chen,Xiang Zhu,Jianyu Chen
### Background
近期的Vision-Language-Action (VLA)模型利用了预训练的Vision-Language Model (VLM)以提升泛化能力。尽管VLM们通常在视觉语言理解任务上进行了预训练，并能提供丰富的语义知识与推理能力，但已有研究表明VLMs倾向于关注高层次的语义内容而忽略低级别的特征，从而限制了它们对细微空间信息的理解和物理动态的把握。这些对于具身控制任务来说至关重要的方面，在现有的预训练范式中尚未得到充分探索。本研究将关注这一问题，寻找适用于VLA训练的方法，并引入了同时具备多模态理解和未来预测目标的统一训练框架。
### Innovation
提出了一个统一的VLA训练模型，称为UP-VLA，该模型结合了多模态理解和未来预测目标，提升了高层次语义理解和低层次空间理解能力。实验结果显示，UP-VLA在Calvin ABC-D基准测试中相比之前最先进的方法提高了33%的性能，并且在需要精确空间信息的现实世界操作任务中表现更出色。
### Conclusion
UP-VLA在提升VLA模型低层级空间理解能力的同时，也提高了高层级语义理解能力，进而取得了在具身控制任务上的显著性能提升，并展示了在实际操作任务中更好的表现。
## 150. `cs.AI` - 通过掩码自动编码器学习实验室值表示 [PDF](https://arxiv.org/pdf/2501.02648), [HTML](https://arxiv.org/abs/2501.02648)
### Authors
David Restrepo,Chenwei Wu,Yueran Jia,Jaden K. Sun,Jack Gallifant,Catherine G. Bielick,Yugang Jia,Leo A. Celi
### Background
准确填补电子健康记录（EHR）中的缺失实验室值对于临床预测具有重要意义，并能减少AI系统中的偏见。现有的方法，如XGBoost、softimpute、GAIN、期望最大化（EM）和MICE，难以建模EHR数据中的复杂时序和上下文依赖关系，尤其是对于非代表性人群。
### Innovation
本文提出了一种新颖的基于变压器的掩码自编码器框架Lab-MAE，用于连续序列实验室值的填补。该框架利用自监督学习机制，引入了一种结构化编码方案，能够联合建模实验室测试值及其相应的时间戳，使时序依赖关系更加明确。实验结果表明，Lab-MAE在多个指标上（包括均方根误差（RMSE）、R²和Wasserstein距离（WD））显著优于现有的基线方法。同时，Lab-MAE在不同的人口统计学组表现一致，体现了更公平的临床预测。我们还进一步研究了随访实验室值作为潜在捷径特征的作用，显示了Lab-MAE在缺乏此类数据时的鲁棒性。
### Conclusion
基于变压器的Lab-MAE架构为更准确和公平的临床填补提供了一个基础模型。我们还衡量并比较了Lab-MAE和XGBoost模型的碳足迹，强调了其环境需求。
## 151. `cs.AI` - DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection [PDF](https://arxiv.org/pdf/2501.08005), [HTML](https://arxiv.org/abs/2501.08005)
### Authors
Francisco Caetano,Christiaan Viviers,Luis A. Zavala-Mondragón,Peter H. N. de With,Fons van der Sommen
### Background
在许多应用中，out-of-distribution (OOD) 检测具有重要意义。虽然对于语义和领域转移 OOD 问题已有深入研究，但本研究关注的是协变量移位（covariate shifts），即数据分布中的微妙变化，这些变化可能降低机器学习性能。通过检测这种微妙的变化，可以改进对分布边界的理解，从而提升 OOD 检测效果。研究发现，在使用 Batch Normalization（BN）训练的对抗判别器中，真实样本和对抗样本形成了具有独特批次统计的独立领域，这是实现 OOD 检测的关键机制。
### Innovation
本研究提出了一种无监督的对抗变分自编码器（VAE）框架，即 DisCoPatch。该框架利用对抗判别器中真实样本和对抗样本形成的独立领域中独特的批次统计特性，以检测协变量移位。通过利用 VAE 的次优生成和重构输出作为负面样本来训练判别器，从而提高判别器在内分布样本和协变量移位之间划界的能力。DisCoPatch 通过缩小这个边界，达到了公共 OOD 检测基准中的最新性能。具体而言，在 ImageNet-1K(-C) 数据集上取得了 95.5% 的 AUROC，而在公共 Near-OOD 挑战中的表现也超越了所有先前的方法，模型大小仅为 25MB，具有更高的 OOD 检测性能和显著较低的延迟，使得 DisCoPatch 成为一种高效且实用的 OOD 检测解决方案。
### Conclusion
DisCoPatch 在公共 OOD 检测基准中达到了最先进的性能，特别适用于检测协变量移位，在 ImageNet-1K(-C) 上 AUROC 达到 95.5%，在公共 Near-OOD 挑战中也超越了所有先前的方法。此外，模型大小仅为 25MB，提供显著较低的延迟，使得 DisCoPatch 成为一种高效的 OOD 检测解决方案，适用于实际应用。研究的代码已经公开。
## 152. `cs.AI` - 市场中的异质代理：贝叶斯学习者与非遗憾学习者之间的动态与生存 [PDF](https://arxiv.org/pdf/2502.08597), [HTML](https://arxiv.org/abs/2502.08597)
### Authors
David Easley,Yoav Kolumbus,Eva Tardos
### Background
本文分析了在具有随机收益的资产市场中不同类型的学习代理的性能。主要关注比较贝叶斯学习者和没有遗憾的学习者在市场中的竞争，并确定每种方法更有效的条件。研究发现，遗憾小不足以确保生存，贝叶斯学习者的表现更为脆弱，而没有遗憾学习者所需环境知识较少，更稳健。此外，通过将市场中的生存和市场主导地位与遗憾最小化框架联系起来，正式建立了经济研究中这些概念之间的关系，从而填补了理论上的空白。
### Innovation
提出了结合贝叶斯更新的平衡策略，既提高了稳健性又增强了对分布变化的适应性，实现了一种兼顾两者的学习方法。该方法具有通用性、高效性和易于实现的特点。
### Conclusion
研究将经济学中关于不同学习代理动态及其对市场影响的理解推向了一定深度，并通过与后悔最小化框架的连接，建立了新的理论基础。
## 153. `cs.AI` - Zero-TIG：增强意识的零样本光照引导低光照视频增强 [PDF](https://arxiv.org/pdf/2503.11175), [HTML](https://arxiv.org/abs/2503.11175)
### Authors
Yini Li,Nantheera Anantrasirichai
### Background
低光照和水下视频存在低可见度、低对比度和高噪声的问题，需要提高视觉质量。现有方法通常依赖于配对的 ground truth，这限制了它们的实际应用，并且常常无法保持时间一致性。
### Innovation
该论文提出了一种新颖的零样本学习方法 Zero-TIG，结合了Retinex理论和光学流技术。Zero-TIG 网络包含一个增强模块和一个时间反馈模块。增强模块由三个子网络组成：低光照图像去噪、光照估计和反射去噪。通过引入直方图均衡化、光学流计算和图像变形，时间增强模块确保了时间一致性，同时保持连续性。此外，还通过适应性平衡RGB通道解决了水下数据的色彩失真问题。
### Conclusion
实验证明，该方法无需配对训练数据即可实现低光照视频增强，为实际场景下的增强提供了一个有前途且适用的方法。
## 154. `cs.AI` - PP-DocBee：通过各种技巧提高多模态文档理解 [PDF](https://arxiv.org/pdf/2503.04065), [HTML](https://arxiv.org/abs/2503.04065)
### Authors
Feng Ni,Kui Huang,Yao Lu,Wenyu Lv,Guanzhong Wang,Zeyu Chen,Yi Liu
### Background
随着数字化的快速发展，各种文档图像在生产和日常生活中的应用越来越广泛，对文档图像内容的快速和准确解析需求愈发迫切。因此，本报告介绍了PP-DocBee，这是一种专门为端到端文档图像理解设计的新颖多模态大型语言模型。在构建过程中，优化了针对文档场景的数据合成策略，构建了一个多样化的数据集以提高模型的泛化能力，并应用了动态比例采样、数据预处理和OCR后处理策略等多种训练技术。
### Innovation
PP-DocBee采用了定制化数据合成策略、动态比例采样、数据预处理和OCR后处理策略等技术，提出了一个多样化的数据集以增强模型的泛化能力，并展示了卓越的性能，在英语文档理解基准测试中达到最先进水平，甚至在中文文档理解中表现出色，超过了现有的开源和商用模型。公开提供的源代码和预训练模型可以在指定链接访问。
### Conclusion
PP-DocBee在文档图像理解方面表现出优秀的性能，特别是在中文文档理解中超越了现有开源和商用模型。其灵活性和可扩展性使得该模型能够应用于不同场景下的文档解析任务。
## 155. `cs.AI` - 基于奖励引导的推测性解码以提高大语言模型推理效率 [PDF](https://arxiv.org/pdf/2501.19324), [HTML](https://arxiv.org/abs/2501.19324)
### Authors
Baohao Liao,Yuhui Xu,Hanze Dong,Junnan Li,Christof Monz,Silvio Savarese,Doyen Sahoo,Caiming Xiong
### Background
本文介绍了一种名为奖励引导推测性解码（RSD）的新型框架，旨在提高大型语言模型（LLMs）推理的效率。现有推测性解码方法倾向于强制执行无偏性，而RSD通过引入一个轻量化草稿模型与更强大目标模型结合，并加入可控偏见，关注高奖励输出，打破了这一传统。RSD利用过程奖励模型来评估解码的中间步骤，动态决定是否调用目标模型，从而在计算成本和输出质量之间实现最优权衡。理论研究表明，基于阈值的混合策略可以在资源利用和性能之间取得最佳平衡。在涉及奥林匹克级别的推理挑战基准测试中，RSD相较于仅使用目标模型解码，显著提高了效率（最多减少了4.4倍的FLOPs），并相比并行解码方法在平均准确度上也有所提升（最多提高了3.5%）。这些结果突显了RSD在资源密集型场景下部署LLMs作为一种稳健且经济高效的途径。代码可在以下链接获取：[提供的链接]。
### Innovation
RSD创新点在于它通过引入奖赏引导机制和可控偏差来提高推理效率。具体来说，它结合了一个轻量化草稿模型与强大的目标模型，在评估解码的中间步骤时使用过程奖励模型，并在资源和性能之间动态调整以获得最优结果。此外，它通过实验示证了基于阈值的混合策略可以在资源利用率和性能之间找到最优平衡。
### Conclusion
本文提出的RSD方法通过提高大型语言模型推理的效率和准确度，为资源密集型场景下的部署提供了稳健且经济高效的方案。实验结果展示了其显著的优势，特别是在减少计算成本的同时提高了准确率。此外，RSD方法具有广阔的应用前景，可以进一步应用于更广泛的场景和任务中。
## 156. `cs.AI` - 使用噪声估计通过强化学习的扩散（NERD）模型揭示神经不确定性表示 [PDF](https://arxiv.org/pdf/2503.14333), [HTML](https://arxiv.org/abs/2503.14333)
### Authors
Hojjat Azimi Asrari,Megan A. K. Peters
### Background
研究通常关注第一级表示（FORs），这些表示编码观察者环境的部分特征，如内容或结构。较少关注的是更高层级的表示（HORs），这些表示“关于”FORs，例如它们的强度或不确定性等，并可能有助于学习。有关不确定性的HORs通常不是FOR特征的直接读数，而是反映了包括对不确定性预期的噪声估计过程，但大脑如何表示这种预期的不确定性分布仍然鲜有探索。因此，本文使用了一个脑成像任务，即解码神经反馈，其中人类参与者通过自愿生成目标神经模式来学习，研究了这种过程中用于处理噪声的期望表示，采用了一种名为 Noise Estimation through Reinforcement-based Diffusion (NERD) 的模型来探索这一过程及其解释力较高的表现。
### Innovation
本文创新性地使用了Noise Estimation through Reinforcement-based Diffusion (NERD) 模型来研究大脑如何在解码神经反馈任务中处理噪声预期，揭示了有关不确定性的更高层级神经表示。该研究填补了认知科学领域在该领域研究的空白，提供了一种新的探索方式和技术工具。
### Conclusion
研究结果表明，NERD模型能够有效地解释人类在解码神经反馈任务中的行为，进一步揭示了大脑通过强化学习方式来处理神经不确定性表示的机制。这为理解大脑如何预期和处理不确定性提供了新的见解，并为未来的相关研究提供了新的方向。
## 157. `cs.AI` - 针对增强检索增强生成的自适应记忆优化方法 [PDF](https://arxiv.org/pdf/2504.05312), [HTML](https://arxiv.org/abs/2504.05312)
### Authors
Qitao Qin,Yucong Luo,Yihang Lu,Zhibo Chu,Xianwei Meng
### Background
检索增强生成（RAG）通过从外部知识库集成非参数化知识，已经证明是一种有成效的方法，可以提高响应准确性并减少事实错误和幻觉。现有RAG方法在开放式领域问答（QA）任务中遇到挑战，因为它们独立进行检索操作且直接将检索信息融入生成中，没有保持总结性记忆或使用自适应检索策略，从而导致冗余信息和信息整合不足。现有方法在这种情况下表现出局限性。
### Innovation
提出了针对开放式领域问答任务的自适应记忆优化增强RAG（Amber），这一方法包括基于代理的记忆更新器、自适应信息收集器和多粒度内容过滤器，它们在一个迭代的记忆更新框架中协同工作。具体来说，Amber通过多代理协作的方法集成和优化语言模型的记忆，确保了先前检索步骤的综合知识整合。它动态调整检索查询并根据积累的知识决定是否停止检索以增强检索效率和效果。此外，Amber通过在多个级别上过滤无关内容减少了噪声，保留了关键信息以提高整体模型性能。
### Conclusion
我们在多个开放式领域问答数据集上进行了广泛的实验，结果表明了我们方法及其组成部分的优越性和有效性。源代码可在指定链接获取。
## 158. `cs.AI` - AI-驱动的情感分析：在电子商务领域的商业价值解锁 [PDF](https://arxiv.org/pdf/2504.08738), [HTML](https://arxiv.org/abs/2504.08738)
### Authors
Qianye Wu,Chengxuan Xia,Sixuan Tian
### Background
电子商务的迅速发展产生了大量客户反馈，从产品评价到服务互动，数据量巨大。从这些数据中提取有意义的见解对企业提高客户满意度和优化决策至关重要。为此，本文提出了一种针对电子商务应用的AI驱动情感分析系统，该系统平衡了准确性和可解释性。该方法结合了传统的机器学习技术和现代深度学习模型，使对客户情感的理解更加深入，同时确保了决策的透明性。实验证明，该系统在多样化的大型数据集上实现了89.7%的准确率，优于标准情感分析方法。此外，多个电子商务平台的实际应用表明，它在提高客户参与度和运营效率方面也取得了一定成效。该研究强调了应用AI进行情感分析在商业环境中的潜力与挑战，并提出了实际部署策略和未来精化方向的见解。
### Innovation
该研究提出了一种结合传统机器学习技术和现代深度学习模型的AI驱动情感分析系统，实现了在电子商务应用中的精确性和可解释性的平衡。实验证明其在多种大型数据集上的表现优于标准方法，具有更高的准确率。此外，其在多个电子商务平台的实际应用也展示了实际业务中的价值。
### Conclusion
该研究表明，AI在情感分析中的应用具有巨大的商业潜力，但在实际应用中存在挑战。研究提出了实际部署策略，并指出了未来需要改进的方向。
## 159. `cs.AI` - 思虑期间搜索并精炼：基于自主检索增强的大语言模型推理 [PDF](https://arxiv.org/pdf/2505.11277), [HTML](https://arxiv.org/abs/2505.11277)
### Authors
Yaorui Shi,Sihang Li,Chang Wu,Zhiyuan Liu,Junfeng Fang,Hengxing Cai,An Zhang,Xiang Wang
### Background
大语言模型展现了强大的推理能力，但受到知识来源的限制。检索增强推理通过允许模型查询外部资源来缓解这一限制，但现有方法经常检索到无关或嘈杂的信息，影响了推理的准确性。
### Innovation
本文提出了一种基于增强学习的后训练框架AutoRefine，采用新的‘搜索-精炼-思考’范式，在连续搜索调用之间引入了显式的知识精炼步骤，使模型能够迭代过滤、浓缩并组织证据再生成答案。此外，引入了针对检索特定的奖励和答案正确性奖励相结合的方法，使用组相对策略优化。
### Conclusion
在单跳和多跳问答基准测试中，AutoRefine明显优于现有方法，特别是在复杂的多跳推理场景中。详细分析显示，AutoRefine经常发出高质量的搜索并有效整合证据。
## 160. `cs.AI` - JointDiT: 使用扩散变换器增强RGB-深度联合建模 [PDF](https://arxiv.org/pdf/2505.00482), [HTML](https://arxiv.org/abs/2505.00482)
### Authors
Kwon Byung-Ki,Qi Dai,Lee Hyoseok,Chong Luo,Tae-Hyun Oh
### Background
本文介绍了一种名为JointDiT的扩散变换器，它可以同时建模RGB和深度图的概率分布。通过利用最新扩散变换器的架构优势和出色的图像先验，JointDiT不仅生成高质量的图像，还能产生几何上合理且准确的深度图。通过提出两种简单而有效的技术——适应性调度权重和不平衡时间步采样策略，实现了这种联合分布建模。这些技术使得JointDiT能够自然地处理如联合生成、深度估计和深度条件化图像生成等各种组合生成任务，仅需通过控制每个分支的时间步即可实现。
### Innovation
提出了一种名为JointDiT的扩散变换器，它可以联合建模RGB和深度图的联合分布。创新之处在于采用了适应性调度权重和不平衡时间步采样策略，以提高生成质量和几何准确性，并且能够自然地处理多种生成任务。此外，JointDiT在深度估计和深度条件化图像生成方面表现出色，表明联合分布建模可以作为一种可替代的替代方案来实现条件生成。
### Conclusion
JointDiT在联合生成性能上表现出色，同时在深度估计和深度条件化图像生成方面也达到了较高水平，表明联合分布模型可以作为一种替代方案用于条件生成。
## 161. `cs.AI` - 能量匹配：统一流匹配与能量基础模型的生成建模方法 [PDF](https://arxiv.org/pdf/2504.10612), [HTML](https://arxiv.org/abs/2504.10612)
### Authors
Michal Balcerak,Tamaz Amiranashvili,Antonio Terpin,Suprosanna Shit,Lea Bogensperger,Sebastian Kaltenbach,Petros Koumoutsakos,Bjoern Menze
### Background
目前最常用的生成模型是通过匹配流动或分数将噪声和数据分布进行映射，但在处理部分观测和额外先验信息方面存在困难。能量基础模型（EBMs）能够通过添加相应的标量能量项优雅地解决这一问题。本文提出了一种名为“能量匹配”的框架，这是为了赋予基于流动的方法EBMs所具有的灵活性。在远离数据流形的时候，样本会沿着无旋的最佳传输路径从噪声流向数据。当样本接近数据流形时，熵能量项将系统引导至玻尔兹曼平衡分布，从而明确地捕捉到数据的潜在似然结构。
### Innovation
本文提出了一种名为“能量匹配”的框架，结合了流匹配方法和能量基础模型的灵活性。通过单一的时间不变标量场参数化这一动态过程，不仅作为强大的生成器还作为有效的逆问题正则化灵活先验。该方法在CIFAR-10和ImageNet生成方面表现出更高的保真度，并且保留了基于传输的方法在远离数据流形时的无模拟训练能力。利用此方法的灵活性，引入了交互能量支持不同的模态探索，并在受控的蛋白质生成设置中进行了验证。不同于最近EBM方法的时间调节、辅助生成器和额外网络，本文的方法通过学习一个标量势能，进一步简化了框架，推动了EBMs在生成建模中的更广泛应用。
### Conclusion
本文提出的方法主要在CIFAR-10和ImageNet生成方面表现出显著的优越性，同时保持了训练的简化过程。此外，该方法的灵活性允许引入新的交互能量，用于支持多模态探索，增强了EBMs的能力，为在多个领域中的广泛采用奠定了基础。
## 162. `cs.AI` - AirCache: 激活跨模态相关性 KV 缓存压缩以实现高效大型视觉-语言模型推理 [PDF](https://arxiv.org/pdf/2503.23956), [HTML](https://arxiv.org/abs/2503.23956)
### Authors
Kai Huang,Hao Zou,Bochen Wang,Ye Xi,Zhen Xie,Hao Wang
### Background
大型视觉语言模型（LVLMs）因其实现的卓越推理能力和泛化能力而获得了广泛关注。然而，处理大量的视觉标记和生成长上下文输出带来了巨大的计算负担，导致对关键-值（KV）缓存的高需求。为此，研究如何有效降低KV缓存的需求已成为一个关键挑战。
### Innovation
本文提出了一种称为AirCache的新颖KV缓存压缩方法，旨在加速LVLMs推理。该方法系统地研究了LVLMs的注意力机制中视觉和文本标记之间的相关性。实验分析显示，在KV缓存中视觉标记存在大量冗余，通过战略性地消除这些标记可以在大幅加快上下文生成同时保持模型性能。此外，还开发了一种自适应的逐层预算分配策略，利用标记重要性分布的特点，比均匀分配展现出更好的效率。综合评估表明，该方法在保留10%的视觉KV缓存时可达到与完整缓存相似的性能，各批次大小和提示长度的解码延迟分别减少29%到66%。随着缓存保留率的降低，该方法在性能上展现出比现有方法更大的优势。
### Conclusion
本文提出并验证了AirCache方法，该方法通过有效压缩KV缓存显著降低了计算负担，同时还保持了模型性能，特别适用于大规模视觉-语言模型的推理任务。
## 163. `cs.AI` - CREStE: 使用互联网规模先验和反事实指导的可扩展无地图导航 [PDF](https://arxiv.org/pdf/2503.03921), [HTML](https://arxiv.org/abs/2503.03921)
### Authors
Arthur Zhang,Harshit Sikchi,Amy Zhang,Joydeep Biswas
### Background
当前户外城市导航面临开放世界泛化和鲁棒性挑战。实现可靠的无地图导航需要能够对未见过的因素进行泛化的感知表示，以及基于有限的示范推断出与专家一致的导航成本。现有方法在处理这种挑战时表现不佳，特别是在长时程的无地图导航场景中需要大量的人工干预。
### Innovation
该论文提出了CREStE框架，采用学习感知表示的方法解决开放世界泛化和鲁棒性问题。具体创新点包括：1) 通过视觉基模型（VFM）蒸馏目标学习开放集结构的鸟瞰图感知表示；2) 引入反事实逆强化学习（IRL），通过反事实轨迹示范推理出导航成本中的关键线索。该方法在多种城市、非公路和住宅环境下的千米级无地图导航任务中表现优异，相较于现有的最先进的方法有70%的减少的人工干预，验证了其在长远导航任务中的鲁棒性和有效性。
### Conclusion
CREStE框架通过学习感知表示和反事实逆强化学习，成功解决了无地图导航中的泛化和鲁棒性问题，不仅在多种场景下表现出色，还在未见过的环境中仅需一次人工干预就完成2公里任务，展示了较强的鲁棒性和实际应用价值。
## 164. `cs.AI` - A3：一种用于注意力机制的分析性低秩逼近框架 [PDF](https://arxiv.org/pdf/2505.12942), [HTML](https://arxiv.org/abs/2505.12942)
### Authors
Jeffrey T. H. Wong,Cheng Zhang,Xinye Cao,Pedro Gimenes,George A. Constantinides,Wayne Luk,Yiren Zhao
### Background
大型语言模型展现了卓越的性能，但由于参数量庞大，部署成本高昂。低秩逼近提供了压缩解决方案，但现有方法存在两大限制：一是专注于最小化单个线性层的输出误差，忽略了Transformer的架构特征；二是将大型权重矩阵分解为两个小型低秩矩阵，导致相比修剪和量化等其他压缩技术效果不佳，并引入了额外的计算开销。
### Innovation
提出了一种后训练低秩逼近框架A3，A3将Transformer层分为三个功能组件：QK、OV和MLP。为每个组件提供一个降低隐藏维度大小的解析解，同时最小化组件的功能损失（即注意力分数、注意力输出和MLP输出的误差），从而不引入任何运行时开销地直接减少了模型规模、KV缓存大小和FLOPs。此外，A3推进了从单个线性层损失优化向端到端性能优化的优化问题表述。
### Conclusion
通过大量实验表明，A3在模型性能上优于当前最佳模型，例如在WikiText-2数据集上，对于相同的计算和内存缩减预算，低秩逼近的LLaMA 3.1-70B达到了4.69的 perplexity，优于前一SoTA的7.87，提升了3.18。此外，A3展示了其在KV缓存压缩、量化和混合秩分配等方面的普适性，促进性能增强。
## 165. `cs.AI` - TaxaDiffusion: 逐步训练的扩散模型用于细粒度物种生成 [PDF](https://arxiv.org/pdf/2506.01923), [HTML](https://arxiv.org/abs/2506.01923)
### Authors
Amin Karimi Monsefi,Mridul Khurana,Rajiv Ramnath,Anuj Karpatne,Wei-Lun Chao,Cheng Zhang
### Background
当前的扩散模型在生成细粒度动物图像时存在一定的局限性，特别是图像的形态学和身份精度方面。现有方法通常将每一种物种视为独立的类别，未能充分利用不同物种间的视觉相似性，尤其是它们在形态、图案和颜色上的细微差别。因此，存在改进的空间，特别是在利用领域知识来提高生成图像的准确性方面。
### Innovation
TaxaDiffusion 提出了一种基于分类学知识的训练框架，用于扩散模型，以生成具有高形态学和身份精度的细粒度动物图像。该方法通过分类学分级训练条件扩散模型，从分类到目逐步细化到科和属，最终区分至物种级别，从而实现从宏观到微观的精细特征学习，提高生成的准确性和鲁棒性，尤其是在训练样本有限的情况下。
### Conclusion
在三个细粒度动物数据集上的广泛实验表明，TaxaDiffusion 超过了现有方法，在细粒度动物图像生成方面的保真度表现出色。
## 166. `cs.AI` - 使用SMILE在大型语言模型中实现可解释性：基于局部解释的统计模型无差别可解析性 [PDF](https://arxiv.org/pdf/2505.21657), [HTML](https://arxiv.org/abs/2505.21657)
### Authors
Zeinab Dehghani,Mohammed Naveed Akram,Koorosh Aslansefat,Adil Khan
### Background
大型语言模型如GPT、LLAMA和Claude在生成文本方面变得极其强大，但它们依然是黑盒子，难以理解这些模型是如何做出决策的，这缺乏透明度，尤其在需要信任和问责制的领域尤为成问题。
### Innovation
我们引入了SMILE，这是一种新的方法，能够解释这些模型在面对不同部分的提示时的响应方式。SMILE是模型无关的，它通过稍微改变输入、测量输出的变化，然后突出显示哪些词产生了最大影响，并创造出简单的热力图来展示提示中哪些部分最重要。我们在几个领先的LLM上测试了SMILE，使用了准确度、一致性和稳定性等指标来证明它可以提供清晰且可靠的原因。
### Conclusion
通过使这些模型更容易理解，SMILE将我们更进一步地推动了人工智能的透明性和可信度。
## 167. `cs.AI` - Thinkless: LLM Learns When to Think [PDF](https://arxiv.org/pdf/2505.13379), [HTML](https://arxiv.org/abs/2505.13379)
### Authors
Gongfan Fang,Xinyin Ma,Xinchao Wang
### Background
带有扩展链式思考能力的推理语言模型在需要复杂逻辑推理的任务中表现出色。然而，为所有查询应用复杂的推理通常会导致显著的计算效率低下问题，特别是当许多问题可以快速求解时。这引发了开放性问题：是否语言模型（LLM）能够学会何时进行思考？
### Innovation
我们提出了一种名为Thinkless的可学习框架，它使LLM能够根据任务复杂性和模型能力适应性地选择简短形式或详细形式的推理。Thinkless通过强化学习进行训练，并使用两个控制标记：<short>用于简洁响应，<think>用于详细推理。核心方法是一种名为Decoupled Group Relative Policy Optimization (DeGRPO)的算法，该算法将混合推理的学习目标分解为两个组件：(1) 控制标记损失，用于管理推理模式的选择；(2) 响应损失，用于提高生成答案的准确性。这种解耦表征使每个目标的贡献能够细粒度控制，从而稳定训练并防止观察到的vanilla GRPO的崩溃现象。在多个基准测试中（如Minerva Algebra、MATH-500和GSM8K），Thinkless能够降低长链思维的使用率50% - 90%，显著提高了推理语言模型的效率。
### Conclusion
思less将使语言模型学会在适当的情况下进行思考，从而在保留推理能力的同时显著提高计算效率。这种方法通过细粒度控制和算法分解，提高了模型训练的稳定性和效率。
## 168. `cs.AI` - 以假乱真：奖励建模作为辨别预测 [PDF](https://arxiv.org/pdf/2506.13846), [HTML](https://arxiv.org/abs/2506.13846)
### Authors
Runtao Liu,Jiahao Zhan,Yingqing He,Chen Wei,Alan Yuille,Qifeng Chen
### Background
当前的奖励建模方法由于依赖广泛的由人类标注的偏好数据或精心构建的质量维度，往往面临着实现复杂性的问题。这些方法要么数据标注不完整，要么构建质量维度非常工程化，这对于后训练增强的视觉生成模型的强化学习提升产生了阻碍作用。
### Innovation
本文提出了一种高效奖励建模框架，名为GAN-RM。该方法从生成对抗网络（GAN）的对抗训练中获得灵感，通过辨别一小组代表性但未配对的目标样本（称为偏好代理数据）与模型生成的一般输出，消除了手动偏好标注和显式的质量维度工程化。该方法只需要几百个目标样本即可完成训练，从而简化了实现过程。
### Conclusion
全面的实验表明，GAN-RM 在多个关键应用中表现出色，包括测试时的扩展实现为 N 次样本过滤、后训练方法如监督微调（SFT）和直接偏好优化（DPO）。相关代码和数据已发布至特定链接。
## 169. `cs.AI` - 复合流匹配在具有偏移动力学数据的强化学习中的应用 [PDF](https://arxiv.org/pdf/2505.23062), [HTML](https://arxiv.org/abs/2505.23062)
### Authors
Lingkai Kong,Haichuan Wang,Tonghan Wang,Guojun Xiong,Milind Tambe
### Background
利用前期收集的离线数据来提升强化学习（RL）的样本效率，虽然能够显著改善性能，但却经常受到源环境和目标环境过渡动力学差异的挑战。现有的方法通常通过惩罚或过滤源过渡中的高动力学间差异区域来应对这些问题，但对于源和目标动力学具有不同支持范围的情况，它们基于KL 散度或互信息的动力学差距估计可能不明确或难以定义。
### Innovation
提出了CompFlow方法，该方法基于流匹配和最优传输之间的理论联系。CompFlow通过将目标动力学建模为基于源域流输出分布的条件流，而不是直接从高斯先验中学习，提升了学习目标动力学的一般性和动力学差距的合理估计。进一步地，CompFlow还引入了一种乐观的数据收集策略，该策略优先探索高动力学差距区域，并从理论上证明了这种策略可以减少与最优策略的性能差距。实验表明，CompFlow方法在多个具有偏移动力学数据的RL基准测试中表现优于基准方法。
### Conclusion
CompFlow通过调整动力学差距的估计方法和优先探索高动力学差距区域的数据收集策略，有效地克服了源目标动力学差异带来的挑战，并在多个强化学习基准测试中展示了优越性能。
## 170. `cs.AI` - 基于理性分析的在上下文学习策略的涌现 [PDF](https://arxiv.org/pdf/2506.17859), [HTML](https://arxiv.org/abs/2506.17859)
### Authors
Daniel Wurgaft,Ekdeep Singh Lubana,Core Francisco Park,Hidenori Tanaka,Gautam Reddy,Noah D. Goodman
### Background
近期有关在上下文学习（ICL）的研究已识别出一系列模型在不同实验条件下表现出的多种不同策略。本文旨在统一这些发现，探讨模型为何会学习这些分散的策略。研究起始于观察到，当模型被训练以学习多种任务时（这是文献中流行的方法），模型执行ICL时所采用的策略可以用一组贝叶斯预测器来捕捉：其中一种是记忆型预测器，它假设一个可观测任务集的离散先验，另一种是一般化预测器，其中先验与潜在的任务分布相匹配。
### Innovation
本文采用规范分析视角，将学习者的行为解释为在给定计算约束下对数据的最优适应。基于此，本文开发了一个分层贝叶斯框架，几乎完美地预测了训练过程中transformer的下一个标记预测——无需假设对模型权重的访问。框架将预训练视为更新不同策略后验概率的过程，并将推理时的行为解释为这些策略预测的后验加权平均。模型偏好实现策略的动力不仅仅取决于策略解释数据的能力，还与其复杂性有关，这有助于解释ICL中已知的现象，并提出了新的预测：例如，随着任务多样性增加，从泛化到记忆的转换时间趋势呈超线性增长。
### Conclusion
总体而言，本文为基于策略损失与复杂性之间的权衡原理的ICL提供了解释性和预测性的账户。
## 171. `cs.AI` - 基于LLM的恶意软件分析的语义预处理 [PDF](https://arxiv.org/pdf/2506.12113), [HTML](https://arxiv.org/abs/2506.12113)
### Authors
Benjamin Marais,Tony Quertier,Grégoire Barrue
### Background
在恶意软件分析领域，许多方法依赖于人工智能来处理大量数据。然而，这些技术主要关注数据视图（图像、序列），而不是专家视图。这个问题促使我们提出了一种预处理方法，该方法专注于专家知识，以改进恶意软件语义分析和结果可解释性。
### Innovation
我们提出了一个新的预处理方法，为portable executable文件生成JSON报告。这些报告集合了静态分析和行为分析的功能，并包含了打包程序签名检测、MITRE ATT&CK和恶意软件行为分类（MBC）的知识。该预处理的目的在于收集二进制文件的语义表示，便于恶意软件分析师理解，并提升恶意文件分析中小规模人工神经网络模型的可解释性。我们使用这种方法对一个代表市场现实的复杂数据集进行大型语言模型训练，达到了0.94的加权F1分数。
### Conclusion
通过这种预处理方法，我们提高了恶意软件语义分析的准确性和解释性，为大型语言模型的恶意软件分类提供了有力支持。
## 172. `cs.AI` - 迈向可验证的安全与非安全模型权重发布方案 [PDF](https://arxiv.org/pdf/2506.19874), [HTML](https://arxiv.org/abs/2506.19874)
### Authors
Xin Yang,Bintao Tang,Yuhao Wang,Zimo Ji,Terry Jingchen Zhang,Wenyuan Jiang
### Background
最近的安全权重发布方案声称能够在保护模型所有权及防止滥用的同时，实现开源模型的分发。然而，这些方法缺乏严格的安全基础，只能提供非正式的安全保证。已有研究领域，特别是密码学，为解决这一问题提供了灵感和方法。本文通过引入具体的数学定义来形式化量化这些安全权重发布方案的安全性，并以TaylorMLP为例进行了验证，显示了TaylorMLP无法实现其非正式安全目标的漏洞。
### Innovation
本文通过引入具体的安全定义，形式化了安全权重发布方案的安全性。并且通过案例研究，揭示了TaylorMLP的漏洞，其未能实现其非正式的安全目标。这促使了机器学习和安全研究领域的严谨研究，也为未来安全权重发布方案的设计和评估提供了蓝图。
### Conclusion
本文希望推动机器学习与安全研究领域的深入融合，倡导严谨的研究，并为未来的权重发布方案提供设计和评估的指导框架。
## 173. `cs.AI` - TracLLM: 一种长上下文LLM的通用归因框架 [PDF](https://arxiv.org/pdf/2506.04202), [HTML](https://arxiv.org/abs/2506.04202)
### Authors
Yanting Wang,Wei Zou,Runpeng Geng,Jinyuan Jia
### Background
长上下文大型语言模型（LLM）被广泛应用于诸如检索增强（RAG）、代理和广泛LLM整合应用等实际场景。这些模型利用长上下文（例如文档、PDF文件和网页）生成基于提供的背景信息的输出，目的是提供更准确、更新且可验证的输出，同时减少幻觉和不支持的说法。此外，如何通过长上下文LLM生成的输出反溯其相关文本（例如句子、段落或章节）的研究需求变得日益迫切，这涉及到背景追溯（我们称之为上下文反溯）的过程，该过程具有多方面的实际应用场景，包括但不限于：1）调试LLM基系统；2）攻击（如提示注入攻击、知识篡改攻击）后的后攻击法分析；3）突出显示知识来源以增强用户对LLM生成输出的信任度。然而，现有的特征归因方法，例如Shapley，在应用于长上下文LLM的上下文反溯时表现出不佳的性能或产生高昂的计算成本。
### Innovation
本文提出了TracLLM，这是一种专门为长上下文LLM设计的通用上下文反溯框架。该框架能够提升现有特征归因方法的效果和效率。为了提高效率，TracLLM采用了一种基于启发式搜索的算法。此外，还开发了贡献分数的集成/去噪技术以提升TracLLM的准确性。研究结果显示，TracLLM可以有效地识别导致LLM生成输出的长文本中的相关文本。
### Conclusion
TracLLM能够有效识别长上下文中的文本，这些文本导致了LLM的输出。TracLLM的核心贡献包括：1）一种专门为长上下文LLM设计的上下文反溯框架；2）基于启发式搜索的算法以提高效率；3）贡献分数的集成/去噪技术以提升准确性。
## 174. `cs.AI` - IndieFake 数据集：音频换脸检测基准数据集 [PDF](https://arxiv.org/pdf/2506.19014), [HTML](https://arxiv.org/abs/2506.19014)
### Authors
Abhay Kumar,Kunal Verma,Omkar More
### Background
音频深度伪造技术的进步带来了诸如AI助手、改善语言障碍人士的无障碍访问以及增强娱乐体验等益处。然而，这项技术也给数字通信的安全性、隐私权和信任带来了重大风险。检测和减轻这些威胁需要全面的数据集。现有的数据集在多样性方面存在不足，特别是缺乏各种不同的口音，导致这些数据集无法在如南亚这样的多元化语言与文化场景中有效识别音频深度伪造。尽管南亚人口占世界人口的四分之一，现有的数据集中却没有足够的南亚讲英语的样本。因此，本文引入了IndieFake数据集（IFD），该数据集包含50名讲英语的印度人的27.17小时的真实和假造音频数据，具有平衡的数据分布，并且包括了大量的讲者级特征描述，而这些特征在ASVspoof21（DF）等数据集中是缺失的。
### Innovation
引入了IndieFake数据集(IFD)，提供了一个全面的数据资源，涵盖了南亚讲英语的50名讲者的27.17小时的真实和假造音频数据，弥补了现有数据集中口音多样性不足的问题。该数据集具有比现有的ASVspoof21（DF）和In-The-Wild（ITW）基准数据集更好的平衡数据分布和详细的讲者级特征描述，旨在更好地应对音频深度伪造的检测挑战。
### Conclusion
IFD数据集在不同的基准测试中表现突出，并且相较于现有的ASVspoof21（DF）和In-The-Wild（ITW）基准数据集来说，更具挑战性。完整数据集以及相关文档和样本参考剪辑已公开可获取于项目网站。
## 175. `cs.AI` - PCDVQ：通过极坐标解耦增强矢量化量化以提高大型语言模型的精度 [PDF](https://arxiv.org/pdf/2506.05432), [HTML](https://arxiv.org/abs/2506.05432)
### Authors
Yuxuan Yue,Zukang Xu,Zhihang Yuan,Dawei Yang,Jianlong Wu,Liqiang Nie
### Background
大语言模型（LLMs）在边缘部署上面临显著挑战，因为它们参数量巨大。矢量量化（VQ）作为一种基于聚类的量化方法被广泛应用，因其极低比特率（甚至低至2比特）和较高的准确性。然而，现有的VQ工作通常以耦合方式量化矢量的大小和方向，并且存在方向对量化更为敏感的问题。此外，当前VQ工作的常见度量标准（如欧几里得距离）更关注减少大小误差。这与方向对量化更为敏感的发现相矛盾，导致更大量的量化错误。因此，需要一种有效的和高效的矢量化量化框架来解决这个问题，并提供准确且高度压缩的大语言模型的方法框架。
### Innovation
提出了一种有效的和高效的矢量化量化框架（PCDVQ），包括两种关键模块：1）极坐标解耦（PCD），它将向量转换为其极坐标表示，并独立量化方向和大小参数；2）分布对齐码本构建（DACC），它根据源分布优化方向和大小码本。实验结果显示，与基础方法相比，PCDVQ 在2比特级上至少提高了1.5% 的零样本准确率，建立了一种新的可压缩且准确的大型语言模型的范式。
### Conclusion
本文提出的PCDVQ方法通过极坐标解耦解决了大语言模型的量化难题，不仅保持了相当的准确性，还实现了更好的压缩效果，为大语言模型在边缘部署提供了新的框架思路。
## 176. `cs.CL` - 关于表数据的概论化问题回答 [PDF](https://arxiv.org/pdf/2506.20747), [HTML](https://arxiv.org/abs/2506.20747)
### Authors
Chen Shen,Sajjadur Rahman,Estevam Hruschka
### Background
当前方法，例如NL2SQL系统，对于可以直接从表格中检索答案的事实性问题执行良好，但是在需要处理不确定性的概率性问题方面的表现不佳。这些系统无法处理需要推理和不确定性的概率性问题。因此，文章引入了LUCARIO基准和一种新的框架来处理大规模表数据的概率问题回答。
### Innovation
文章提出了一个新基准LUCARIO和一种基于图的概率问题回答框架。此方法通过从表格中诱导贝叶斯网络，将自然语言查询转换为概率查询，并利用大型语言模型来生成最终答案，这种方法结合了符号和神经推理。实证结果表明，这种方法显著优于基准方法，突显了混合符号-神经推理的优势。
### Conclusion
此研究提高了处理不确定性和概率性问题的能力，通过引入新方法和框架，在表数据的概率问答领域取得了显著进步。这种方法在提高精确性和处理复杂查询方面表现出潜力，为未来的研究奠定了基础。
## 177. `cs.AI` - 超声图像解释和扫描指导的语义场景图 [PDF](https://arxiv.org/pdf/2506.19683), [HTML](https://arxiv.org/abs/2506.19683)
### Authors
Xuesong Li,Dianye Huang,Yameng Zhang,Nassir Navab,Zhongliang Jiang
### Background
理解医学超声成像一直是一个持续存在的挑战，因为成像和采集参数的巨大视觉差异导致了显著的视觉变异。近年来，大语言模型（LLMs）被用来自动生成术语丰富的总结，以供具有足够生理知识的临床医生使用。然而，对于未经培训的用户在便携式护理环境中的超声成像可读性和基本扫描指导的需求尚未被探索。在本研究中，我们首先为超声图像引入了场景图（SG），以向普通用户解释图像内容，并提供扫描指导。场景图是通过基于变换器的一阶段方法计算出来的，从而避免了显式对象检测的需要。通过LAMS对用户的查询使用来进一步细化抽象的SG表示，为普通用户提供一个易于理解的图像解释。此外，研究还探讨了SG在引导超声扫描以覆盖当前成像视图中缺失的解剖结构中的潜力，从而帮助普通用户实现更标准化和完整的解剖探索。本方法的有效性已经在包括颈动脉和甲状腺等左侧和右侧颈部区域的5位志愿者的图像中得到了验证。结果表明，此基于SG的图像解释和扫描指导方法有潜力最大限度地去民主化超声成像，从而增强ordinaries的可读性和使用性。
### Innovation
本研究首次引入了超声图像场景图(SG)来解释图像内容，并为普通用户提供了扫描指导。通过使用基于变换器的一阶段方法进行SG计算，方法避免了显式对象检测的需要。进一步通过大语言模型（LLMs）对用户的查询进行细化，并将SG用于引导超声扫描以覆盖当前成像视图中缺失的解剖结构，从而帮助普通用户实现更标准化和完整的解剖探索。
### Conclusion
基于SG的图像解释和扫描指导方法已经在包括颈动脉和甲状腺等左侧和右侧颈部区域的5位志愿者的图像中得到验证，结果表明该方法有潜力最大限度地去民主化超声成像，从而增强ordinaries的可读性和使用性。
## 178. `cs.AI` - 这些不是你所寻找的所有特征：监督预训练中的一个根本瓶颈 [PDF](https://arxiv.org/pdf/2506.18221), [HTML](https://arxiv.org/abs/2506.18221)
### Authors
Xingyu Alice Yang,Jianyu Zhang,Léon Bottou
### Background
转移学习是现代机器学习的关键组成部分，它提供了一种方法，使预训练在广泛数据上的模型能够通过少量新数据适应新任务。然而，一个重大挑战在于确保转移的特征能够处理未见过的数据集，尤其是在量化两个任务是否相关时更为困难。为解决这些问题，该研究评估了模型从预训练混合转移到其每个组成部分任务的能力，评估预训练特征是否能够达到任务特定直接训练的性能。研究揭示了一个深度学习模型的基本限制——信息饱和瓶颈，网络在训练过程中编码相似竞争特征后将无法学习新特征。当模型仅学习预训练中的关键特征子集时，模型在转移任务时会永久失去关键特征，对数据分布变化表现出不一致，甚至对于训练混合的数据组成部分也是如此。文献研究表明，这一现象在深度学习架构中普遍存在，数据分布或顺序等因素会影响当前表示学习方法随时间可以学习的特征。这项研究表明，在可用时，依赖大规模网络可能不像专注于任务特定训练那样有效。
### Innovation
该研究识别了一个深度学习模型的基本限制——信息饱和瓶颈，这揭示了在预训练过程中识别特定特征集的重要性。此外，该研究提出了使用更丰富的特征表示作为解决跨新数据集泛化问题的潜在解决方案，并提出了一种新的方法，作为一种应对这一挑战的初步步骤。
### Conclusion
研究建议，在可用时，专注于任务特定训练可能比依赖大规模网络更有效。这篇研究提出了一个名为“信息饱和瓶颈”的新概念，解释了为什么大规模网络在某些情况下可能无法有效地进行基于特征的迁移学习。该研究指出，需要进一步关注任务特定的特征学习，以提高在新数据集上的泛化能力。研究还提供了一种新的方法，作为解决该问题的初始步骤。
## 179. `cs.AI` - SACL: 通过语义增强重新排序和定位来理解并克服代码检索中的文本偏差 [PDF](https://arxiv.org/pdf/2506.20081), [HTML](https://arxiv.org/abs/2506.20081)
### Authors
Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie
### Background
当前的代码检索技术主要依赖于表面级别的文本特征（例如，文档字符串、标识符名称）来增强代码生成，但它们倾向于优先展示文档良好的代码，即使这些文档与代码无关，从而导致了文本偏差的问题。这项工作旨在系统地分析代码检索过程中的这种偏差，并提出了SACL框架来解决这一问题。
### Innovation
提出了SACL框架，通过增强文本信息并利用语义信息来缓解代码检索过程中的偏差，从而改善代码检索性能和代码生成性能。该框架具体表现为通过语义增强重新排序和定位来理解并克服文本偏差问题，实验结果显示其显著改善了代码检索效果，并提升了代码生成性能。
### Conclusion
实验结果表明，SACL框架在增强代码检索性能（例如，在HumanEval、MBPP和SWE-Bench-Lite中的Recall@1分别提高了12.8%、9.4%和7.0%）方面表现出色，同时代码生成性能也得到4.88%的提升（例如，在HumanEval中的Pass@1提高）。
## 180. `cs.CL` - 多语言功能评估对大型语言模型 [PDF](https://arxiv.org/pdf/2506.20793), [HTML](https://arxiv.org/abs/2506.20793)
### Authors
Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian
### Background
大型语言模型的语言能力通常通过静态数据基准测试进行评估，如Belebele、M-MMLU和M-GSM。然而，这些测试往往未能充分理解模型在多语言设置中的实际性能和稳健性。基于这一点，作者创建了多语言功能性基准——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval），将现有的功能基准模板从英语翻译成五种额外的语言，分别是法语、西班牙语、印地语、阿拉伯语和约鲁巴语。研究发现，不同静态多语言基准对功能性能的捕捉程度存在显著差异。此外，模型在不同语言中的稳健性也表现出显著差异，某些语言（如阿拉伯语、英语）在评估迭代中表现最为稳定。
### Innovation
1. 创建了多语言功能性基准测试，包括跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval），这将功能基准模板从英语翻译成五种新语言。2. 结果表明，不同静态多语言基准对功能性能的捕捉程度存在显著差异，且模型在不同语言中的稳健性也表现出显著差异。
### Conclusion
研究揭示，不同静态多语言基准对模型功能性能的捕捉程度存在显著差异，且模型在不同语言中的稳健性也表现出显著差异，某些语言在评估迭代中表现最为稳定。
## 181. `cs.CL` - 在行为情景下的统计分析中揭露LLMs隐藏的暴力倾向 [PDF](https://arxiv.org/pdf/2506.20822), [HTML](https://arxiv.org/abs/2506.20822)
### Authors
Quintin Myers,Yanjun Gao
### Background
大型语言模型（LLMs）被越来越多人提议用于在线检测和应对暴力内容，但它们在处理道德模糊的真实世界情景中的推理能力尚未得到充分研究。本文通过使用社会科学研究中验证的工具——暴力行为情景问卷（VBVQ）——首次评估了LLMs，并通过引入基于人设的提示，研究 race、年龄和地理身份等因素对LLMs行为的影响，从而探讨潜在的偏见问题。研究表明，LLMs表面的文本生成往往与其内部偏好产生分歧，并且他们在不同人口统计中的暴力倾向表现出差异，这些结果与犯罪学、社会学和心理学领域的已知发现存在矛盾之处。
### Innovation
本文首次使用社会科学研究中的工具来评估LLMs在处理暴力情景中的表现，并提出了基于人设的提示，以评估LLMs在处理不同人口统计信息时的潜在偏见。此外，研究发现LLMs在处理暴力内容时，表面生成的文本与内部偏好不一致，并且这种倾向在不同的人群中体现出显著差异，从而揭示了潜在的社会科学含义。
### Conclusion
研究发现，LLMs在表面文本生成和内部偏好方面的分歧以及它们在不同人口组别中的暴力倾向差异，强调了在设计和应用LLMs时必须考虑伦理和文化多样性的问题。
## 182. `cs.CL` - 在医学领域的端到端事实核查中，相比于减少判断，更应增强沟通 [PDF](https://arxiv.org/pdf/2506.20876), [HTML](https://arxiv.org/abs/2506.20876)
### Authors
Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li
### Background
技术进步使得自动事实核查等任务变得更加成熟，尤其是在公共健康和医学领域，由于医学决策的高风险性及大量多样化的医学文献需要批判性评估，所以在医学领域应用这样的系统产生了浓厚兴趣。尽管循证医学涵盖了每个人，但其复杂性导致大多数用户的医学素养不足以充分导航医学领域，这也为端到端的医学事实核查铺平了道路：通过现有医学文献验证陈述，并提供有证据支持的裁决。然而，这类系统至今仍被大量忽视。为了理解这种情况，首次研究了临床专家如何通过综合医学证据验证社交媒体中的真实陈述。在寻找这一上限时，揭示了在医学领域应用端到端事实核查的基本挑战，包括在实际情况和临床试验形式的科学证据间建立联系的困难；上下文不明确和意图不匹配的陈述；以及内在主观的真伪标签。研究表明，事实核查应被视为一种互动沟通问题，而非端到端的过程。
### Innovation
本研究首次调查了临床专家如何通过综合医学证据验证社交媒体中的实际陈述，揭示了在医学领域应用端到端事实核查的基本挑战，并提出了将其视为互动沟通问题而非端到端过程的观点。
### Conclusion
端到端的医学事实核查并不能作为一个完成的任务来看待，而应该被视为一个互动沟通问题。
## 183. `cs.CL` - LLM生成的与人类研究想法的执行差异：执行结果比较 [PDF](https://arxiv.org/pdf/2506.20803), [HTML](https://arxiv.org/abs/2506.20803)
### Authors
Chenglei Si,Tatsunori Hashimoto,Diyi Yang
### Background
大型语言模型（LLMs）在加速科学研究流程方面显示出潜力，尤其是能够产生新的研究想法。先前的研究表明，由LLM生成的研究想法被认为比人类专家的想法更具新颖性。然而，一个好的想法不应仅仅显得新颖，还应在执行后产生更好的研究结果。为验证AI生成的想法是否能导致更好的研究结果，通过招募43名专家研究人员执行随机分配的想法（由专家撰写或由LLM生成）并在实施后撰写4页的短论文记录实验。所有执行的项目都由专家自然语言处理（NLP）研究人员盲审。执行前后的审评分比较显示，LLM生成的想法在所有评估指标（新颖性、兴奋性、有效性及总体评价）上的分数显著低于专家撰写的想法（p<0.05），反映出从想法到执行的差距，削弱了之前观察到的人类想法与LLM想法之间的差距。在执行研究的整体评分比较中，甚至发现许多指标中人类想法的评分高于LLM想法。这表明现有的LLMs在生成真正有效的研究想法方面存在局限性，以及在缺乏执行结果的情况下评估研究想法的挑战性。
### Innovation
本文通过实际执行和盲审研究，首次直接评估了LLM生成想法与人类专家想法在执行过程中的实际效果差距，发现LLM生成想法在实际执行后的综合评价结果不如人类专家的想法，突显了现有LLM在生成真正有效研究想法方面的局限性，并提出了评估研究想法不应仅依赖于新颖性，还应考虑执行结果的有效性。
### Conclusion
研究结果显示，尽管LLM在产生新颖想法方面表现出色，但在执行后的研究有效性上却不如人类专家写作的想法。这揭示了在当前技术条件下，构建能够生成真正有效研究想法的LLM仍然是一个挑战。未来的研究应着重于改善LLM在生成有效想法方面的能力，并提出一种结合执行后效果考量的更全面的研究想法评估方法。
## 184. `cs.CL` - 梯度下降能模拟提示吗？ [PDF](https://arxiv.org/pdf/2506.20989), [HTML](https://arxiv.org/abs/2506.20989)
### Authors
Eric Zhang,Leshem Choshen,Jacob Andreas
### Background
该论文讨论了将新信息融入语言模型（LM）的两种主要方式：更改提示或更改参数（例如通过微调）。参数更新不会产生长期存储的成本，但很多时候，通过提示的模型比标准微调更能有效泛化，并能进行逻辑推理。论文提出了一个问题：能否修改模型以使微调模仿提示的效果？
### Innovation
论文提出了一种通过元训练LM的方法，使得梯度更新能够模仿基于新信息的条件作用效果。这种方法利用了基于梯度的元学习工具，但使用了LM本身的提示预测作为目标，从而省去了真实标签的需要。后续的梯度下降训练能够恢复部分甚至全部由提示模型的表现，展示了在“反转诅咒”任务上的改进，并在单一梯度更新后回答了关于文本段落的问题。这些结果表明，适当的初始化条件下，梯度下降可以非常具有表现力。
### Conclusion
研究结果提出了新的长上下文建模路径，并对基于梯度的学习的一般化能力提供了新的见解。
## 185. `cs.CL` - FineWeb2：一种适用于所有语言的统一预训练数据处理管道 [PDF](https://arxiv.org/pdf/2506.20920), [HTML](https://arxiv.org/abs/2506.20920)
### Authors
Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf
### Background
当前预训练大型语言模型（LLMs）需要大量的干净和多样化的文本数据。尽管高质量的多语言预训练数据集取得了一定进展，但是训练高性能多语言LLMs仍面临着挑战，主要是因为适应多种语言的过滤和去重流程非常困难。因此，需要一种能够自动适应任何语言的预训练数据集编排管道。
### Innovation
本文介绍了一个新的基于FineWeb的预训练数据集编排管道，该管道能够自动适应任何语言。此外，还提出了一种平衡数据集的方法，考虑了重复数量和质量。论文还通过使用超过1000种语言和近100个Common Crawl快照来扩展该管道，生成了FineWeb2，一个全新的20TB（5亿文档）多语言数据集。除了数据集，也公开了相关管道、训练和评估代码。
### Conclusion
实验表明，该管道可用于创建比以前的数据集更具性能的非英语语料库。此外，FineWeb2是一个适用于1000多种语言的多语言数据集，为多语言LLM的预训练提供了巨大的支持。
## 186. `cs.CL` - MultiFinRAG：一种优化的金融问答多模态检索增强生成框架 [PDF](https://arxiv.org/pdf/2506.20821), [HTML](https://arxiv.org/abs/2506.20821)
### Authors
Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh
### Background
金融文档如10-K表格、10-Q表格和投资者演示材料多达几百页，并结合了密集的叙事文本、结构化表格和复杂图表等多种模态。回答这类文档中的问题通常需要跨模态的联合推理，这给传统的大规模语言模型（LLMs）和检索增强生成（RAG）管道带来了挑战，因为它们受限于令牌限制、布局丢失以及分割的跨模态上下文。
### Innovation
我们提出了MultiFinRAG，这是一种专为金融问答设计的检索增强生成框架。MultiFinRAG首先通过将表格和图像分组批处理并发送给轻量级的量化开源多模态LLM进行多模态提取，从而生成结构化JSON输出和简洁文本摘要。这些输出与叙事文本一起被嵌入并索引，采用模态感知的相似性阈值以实现精确检索。此外，该框架采用分层退补策略，在必要时从文本到文本+表格+图像上下文动态升级，以在减少无关背景信息的同时实现跨模态推理。尽管运行在经济型硬件上，但MultiFinRAG在涉及文本、表格、图像和综合多模态推理的复杂金融问答任务中，准确率比ChatGPT-4o（扩展免费版）高出19个百分点
### Conclusion
MultiFinRAG为金融问答任务提供了一种有效的解决方案，通过优化多模态检索增强生成框架，实现了高准确度和多模态内容的精确理解与推理。
## 187. `cs.CL` - KaLM-Embedding-V2：先进的训练技术和数据激发了灵活的嵌入模型 [PDF](https://arxiv.org/pdf/2506.20923), [HTML](https://arxiv.org/abs/2506.20923)
### Authors
Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang
### Background
本文介绍了一种基于先进的训练技术和大量数据集提出的KaLM-Embedding-V2模型，该模型在通用文本嵌入任务中取得了显著的表现。该模型通过采用更有效的训练技术和数据集，克服了传统的文本嵌入模型在训练和应用中的不足。
### Innovation
该模型的关键创新包括：（1）通过去除因果注意力掩码，采用全双向变换器，并通过简单的平均池化生成固定长度的嵌入，更好地与表示学习对齐；（2）引入了多阶段训练管道，包括大规模弱监督开源语料上的预训练、高质量检索和非检索数据集上的微调，以及模型混合参数平均策略以增强泛化能力；（3）引入了焦点样式的重加权机制和在线难负样本混合策略，专注于学习困难样本，并不断丰富难负样本以加强模型的能力；（4）收集了超过20类用于预训练的数据和100类用于微调的数据，以增强嵌入模型的性能和泛化能力。
### Conclusion
本文的模型在大规模文本嵌入基准MTEB中的中文和英文上进行了广泛的评估，结果表明，该模型在参数量不到1B的情况下显著优于其他模型，甚至可与参数量3倍、14倍、18倍和26倍的模型竞争，成为新的灵活而紧凑的嵌入模型的标准。
## 188. `cs.CL` - 优化语言模型以适应下游任务：一种后训练视角 [PDF](https://arxiv.org/pdf/2506.20917), [HTML](https://arxiv.org/abs/2506.20917)
### Authors
Zhengyan Shi
### Background
语言模型（LMs）在自然语言处理（NLP）中展现了显著的能力，但它们在高效且稳健地适应特定任务方面存在挑战。随着模型规模和复杂度的增长，对LMs进行细调通常导致过度利用了标注数据，没有充分利用未标注数据，容易在小规模任务特定集上过拟合，并且会带来显著的计算成本。这些限制阻碍了它们在开放环境中的实际语言任务应用。因此，需要提出一种方法来更好地适应LMs到下游应用。
### Innovation
本文提出了一系列方法，旨在更好地将LMs适应到下游任务中。首先，探索了从未标注数据中提取与任务相关的知识的策略，并引入了一种新的连续预训练技术，该技术在半监督方法中表现出色。其次，提出了一种参数高效的微调方法，该方法大幅降低了内存和计算成本，同时保持了竞争力的表现。同时也介绍了一种改进的监督微调方法，使得LMs能在标注数据稀缺时更好地跟随指令，从而增强了它们在各种NLP任务，包括开放生成中的性能。此外，还开发了新的评估方法和基准，如多跳空间推理任务，以更全面地评估LM的能力和适应性。
### Conclusion
通过广泛的实证研究，本文的方法在不同的NLP任务中显著提高了LM的稳健性、效率和概括能力，使其更具适应各种应用的能力。这些进步标志着向着更稳健和高效的LMs迈进的重要一步，接近实现人工通用智能的目标。
## 189. `cs.CL` - 大型语言模型通过专业会计师考试 [PDF](https://arxiv.org/pdf/2506.21031), [HTML](https://arxiv.org/abs/2506.21031)
### Authors
Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta
### Background
随着先进智能系统的迅速发展，特别是大型语言模型（LLMs），自然语言处理（NLP）的进步正在显著改变金融实践。然而，这些模型是否能够有效地捕捉和应用特定领域的金融知识仍不确定。本文针对印度广泛而复杂的金融背景下的缺口，介绍了CA-Ben基准，这是一种专为评估LLMs的金融、法律和定量推理能力而设计的基准。该基准基于印度会计师学院（ICAI）的严格考试，涵盖了从基础到高级的会计师课程阶段，包含结构化的问答数据集。研究通过标准化流程评估了六种流行的大型语言模型，结果发现这些模型在性能上存在差异，Claude 3.5 Sonnet和GPT-4o表现尤为突出，尤其是在概念性和法律推理方面。然而，数值计算和法律解释方面存在显著挑战。
### Innovation
本文引入了CA-Ben基准，专门用于评估LLMs在金融、法律和定量推理方面的表现。该基准使用印度会计师学院的严格考试数据集，涵盖了不同层级的会计师课程，这填补了现有研究中的空白。此外，研究采用标准化的评估协议对六种流行的大型语言模型进行了评估，揭示了模型在不同方面的能力差异。
### Conclusion
研究表明，当前的大型语言模型在概念性理解和法律推理方面表现优异，但在数值计算和准确的法律解释方面存在明显不足。未来的工作应通过结合推理和检索增强生成方法提高模型在量化分析和法律解释方面的性能。
## 190. `cs.CL` - MT2-CSD：一种新数据集和会话立场检测的多语义知识融合方法 [PDF](https://arxiv.org/pdf/2506.21053), [HTML](https://arxiv.org/abs/2506.21053)
### Authors
Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang
### Background
在当今社交媒体领域，自动立场检测对于意见挖掘至关重要，因为它综合并分析用户在争议性话题上的观点，揭示出当前的趋势和情绪。传统的立场检测研究通常只关注个体实例，这限制了其理解和建模多方面讨论的能力，而这种讨论在现实社交媒体场景中是常见的。这一局限性主要是由于缺乏能够真实捕捉社交媒体互动动态的数据集，阻碍了会话立场检测的进步。因此，数据集的不足成为提升会话立场检测技术的关键瓶颈.
### Innovation
本文引入了MT2-CSD，一个用于多目标多轮会话立场检测的大规模数据集。据我们所知，MT2-CSD是目前该领域中规模最大的数据集，包含24,457个标注实例，展现了最大的对话深度，从而为立场检测提出了新的挑战。为应对这些挑战，提出了Large Language Model增强的会话关系注意网络（LLM-CRAN），利用LLM的推理能力以提高对话理解。通过在MT2-CSD数据集上的广泛实验验证了LLM-CRAN的有效性。实验结果表明，LLM-CRAN在会话立场检测任务中显著优于强基线模型.
### Conclusion
MT2-CSD数据集提供了大规模且对话深度极高的案例，不仅为会话立场检测提供了新的挑战，还推动了该领域的进步。提出的LLM-CRAN方法通过利用大型语言模型的强大推理能力，显著提高了会话理解能力，此方法在会话立场检测任务中表现卓越，为该领域的未来研究奠定了基础.
## 191. `cs.CL` - DALR：双层对齐学习在多模态句子表示中的应用 [PDF](https://arxiv.org/pdf/2506.21096), [HTML](https://arxiv.org/abs/2506.21096)
### Authors
Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji
### Background
先前的多模态句子表示学习方法取得了显著的效果，但大多数方法集中在粗略地对齐图像和文本，这面对着交叉模态对齐偏误和跨模态内部语义分歧两大关键挑战，从而显著影响了句子表示的质量。
### Innovation
提出了双层对齐学习的DALR（Dual-level Alignment Learning for Multimodal Sentence Representation）。为此，引入了一致性学习模块，该模块软化负样本，并通过辅助任务的语义相似性实现细致的交叉模态对齐。同时，认为句子关系超越了二元正负标签，表现出更为复杂的排名结构。因此，引入了排名蒸馏与全局内部模态对齐学习相结合的方法，以更好地捕捉这些关系并增强表示质量。
### Conclusion
全面的实验在语义文本相似性（STS）和迁移（TR）任务上验证了该方法的有效性，持续证明了其在最先进的基线下具有优势。
## 192. `cs.CL` - SAC: 动态强度控制下测量和诱导LLM个性特征的框架 [PDF](https://arxiv.org/pdf/2506.20993), [HTML](https://arxiv.org/abs/2506.20993)
### Authors
Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar
### Background
近几年，大型语言模型（LLMs）在多个领域获得了广泛关注，人们对其在交互中展现出人类般的个性寄予厚望。尽管已有许多研究表明，可以通过心理测量评估方法来模拟能力模型，但大部分现有模型存在两大局限：依赖于五大人格特质（大五模型），提供的个性维度较粗；缺乏调节特质强度的机制。该论文针对此问题，扩展了机器人格问卷（MPI），引入了16人格因素（16PF模型），实现了对十六种特质表达的精细控制。此外，还开发了一种标准化框架，称为特定属性控制（SAC），用于评估和动态调节LLM的特质强度。该方法利用形容词为基础的语义锚定来引导特质强度表达，并通过五个强度因素：频率、深度、阈值、努力和意愿，实现了行为问题的设计。实验结果显示，将特质强度表达视作连续光谱，相比二元特质切换，不但一致性更高，且在心理学上更连贯，表明LLMs内化了多维个性结构而非孤立地对待个性维度。这种方法为在医疗保健、教育和面试等领域实现可控和细腻的人机交互提供了新途径，使我们更接近真正的人类社会机器人。
### Innovation
该论文创新性地扩展了机器人格问卷（MPI），引入了16人格因素（16PF模型），实现对十六种特质表达的精细控制。此外，开发了特定属性控制（SAC）框架，用于评估和动态调节LLM的特质强度，采用形容词为基础的语义锚定来指导特质强度表达，通过五个强度因素：频率、深度、阈值、努力和意愿设计行为问题。该方法显著提高了LLM个性表达的一致性和可控性，展示了LLM多维个性结构的内化。
### Conclusion
该研究通过引入16人格因素和特定属性控制框架，从根本上解决了现有模型仅依赖五大人格特质和缺乏强度调控机制的问题，通过连续光谱而非二元切换实现更细腻的个性表达，并展示了多维度个性结构的内化。这些发现为医疗保健、教育和面试等领域的人机交互提供了新的途径，推动了真正人类样态的社会机器人的发展。
## 193. `cs.CL` - E-commerce查询分类的半监督可扩展统一框架 [PDF](https://arxiv.org/pdf/2506.21049), [HTML](https://arxiv.org/abs/2506.21049)
### Authors
Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law
### Background
查询分类，包括意图和类别预测等子任务，在电子商务应用程序中至关重要。电子商务查询通常很简短且缺乏上下文，导致标注信息之间无法利用，造成模型所需先验信息不足。现有的工业查询分类方法通常依赖用户后点击行为构建训练样本，这导致马太效应循环。此外，查询分类的子任务缺乏统一框架，导致算法优化效率较低。
### Innovation
本文提出了一种新颖的半监督可扩展统一框架（SSUF），包含了多个增强模块来统一查询分类任务。知识增强模块使用世界知识增强查询表示，解决查询信息不足的问题。标签增强模块使用标签语义和半监督信号减少对后期标签的依赖。结构增强模块基于复杂的标签关系增强标签表示。每个模块具有高度的可插拔性，根据每个子任务可以添加或移除输入特征。
### Conclusion
我们在离线和在线A/B实验中进行了广泛测试，并且结果显示SSUF显著优于最先进的模型。
## 194. `cs.CL` - ComRAG：基于动态向量存储的检索增强生成方法用于工业实时社区问答 [PDF](https://arxiv.org/pdf/2506.21098), [HTML](https://arxiv.org/abs/2506.21098)
### Authors
Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan
### Background
社区问答（CQA）平台可以被认为是社区中的重要知识库，但如何在实时场景中有效利用历史交互和领域知识仍是一个挑战。现有方法往往未能充分利用外部知识，忽略动态历史QA上下文，或缺乏适合工业部署的记忆机制。
### Innovation
我们提出了ComRAG，这是一种以检索增强生成框架，结合静态知识与动态历史QA对，通过一种基于质心的记忆机制来实现检索、生成和高效存储。在三个工业CQA数据集上的评估表明，ComRAG在向量相似性、延迟和碎片增长方面均优于所有基线方法，并分别实现了高达25.9%的改进，延迟减少8.7%-23.3%，以及迭代过程中的碎块增长从20.23%降至2.06%。
### Conclusion
ComRAG在实时工业CQA领域的使用中显示出了明显的优越性，能够在保持或提升性能的同时改善延迟和存储效率。
## 195. `cs.CL` - Text 差分模型中的压缩和平滑潜在空间 [PDF](https://arxiv.org/pdf/2506.21170), [HTML](https://arxiv.org/abs/2506.21170)
### Authors
Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov
### Background
自回归语言模型在现代文本生成中占主导地位，但其顺序特性带来了根本限制：解码缓慢，保持全局一致性也颇具挑战性。扩散模型提供了一种有前景的替代方案，通过实现并行生成和灵活控制；然而，将扩散模型应用于文本生成的障碍在于词级别表示的高维性。本文讨论了现有的技术背景和存在的挑战，强调了现有方法在时间效率和一致性方面的问题。
### Innovation
我们提出了Cosmos，一种全新的文本生成方法，完全在专门为扩散设计的压缩和平滑潜在空间中进行操作。这种方法通过同时训练一个自编码器来实现，该自编码器用于词级别重建并冻结预训练语言编码器的激活，从而提供稳健的语义基础并支持有效的扰动增广。实验结果表明，文本表示可以压缩8倍，同时保持与词级别扩散模型相当的生成质量。此外，增加潜在序列长度使Cosmos超越了基于扩散和自回归的基线方法。
### Conclusion
我们在四个不同的生成任务（包括叙述生成、问题生成、摘要和去污）上评估了Cosmos，并与各种生成范式进行了比较。结果表明，与基于扩散和自回归的方法相比，Cosmos实现相当或更优的生成质量，同时具有超过2倍的更快推理速度。
## 196. `cs.CL` - 维持MTEB：嵌入基准长期实用性和可重复性的保障 [PDF](https://arxiv.org/pdf/2506.21182), [HTML](https://arxiv.org/abs/2506.21182)
### Authors
Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen
### Background
大规模文本嵌入基准（MTEB）已成为文本嵌入模型的标准评估平台。尽管之前的工作已经建立了核心基准方法，但本文重点在于确保MTEB持续可重复性和可扩展性的工程方面。作者们提供了维护稳健的持续集成管道的方法，这些管道验证数据集的完整性，自动执行测试并评估基准结果的一般适用性。文章还详细描述了共同提高可重复性和实用性的设计选择，并讨论了处理社区贡献和扩展基准以包含新任务和数据集的战略。这些工程实践有助于使MTEB变得更加全面，在保持质量和最终相关性的同时，确保其在相关领域的适用性和重要性。这对于面临类似挑战的基准维护者来说是非常有价值的见解，确保评估框架中的实用性和可重复性。
### Innovation
维护稳健的持续集成管道的方法；自动执行测试并评估基准结果的适用性；处理社区贡献和扩展基准的战略；通过这些工程实践促进MTEB的持续扩展和质量保持，同时满足相关领域的最新需求和挑战。
### Conclusion
本文的经验为其他基准维护者在评估框架中确保实用性和可重复性方面提供了宝贵的见解。MTEB的库可以在[this](this https URL)处找到。通过这些努力，MTEB已成为更加全面的标准评估平台，确保质量和相关性在评估框架中实现长久的实用性和可重复性。
## 197. `cs.CL` - 使用句法检索提升大规模语言模型的自动术语提取 [PDF](https://arxiv.org/pdf/2506.21222), [HTML](https://arxiv.org/abs/2506.21222)
### Authors
Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim
### Background
自动术语提取（ATE）是识别特定领域术语的过程，对机器翻译和信息检索等下游任务至关重要。尽管大规模语言模型（LLMs）在各种自然语言处理任务中取得了显著进展，但它们在ATE中的潜力仍然未被充分研究。本文通过对查询句子和检索到的例子之间的词汇重叠对性能的影响进行分析，在领域内和跨领域的环境中评估了方法的效果，以此展示句法线索在适应术语提取任务中的重要性。
### Innovation
本文提出了一种基于检索的提示策略，在少量示例设置中，该策略根据句法规则而非语义相似性选择示例。这种方法对特定领域不具依赖性，提供了更可靠的边界捕捉指导，从而提升了ATE的效果。实验结果表明，句法检索方法在三个专门的ATE基准上提高了F1分数。
### Conclusion
句法线索在适应大规模语言模型进行术语提取任务时非常重要，句法检索方法能够提供更可靠的边界捕捉指导，从而提高Automatic Term Extraction（ATE）的效果。
## 198. `cs.CL` - 猫和老鼠——虚假文本生成能否超越检测系统？ [PDF](https://arxiv.org/pdf/2506.21274), [HTML](https://arxiv.org/abs/2506.21274)
### Authors
Andrea McGlinchey,Peter J Barclay
### Background
大型语言模型可以在学术写作、产品评论和政治新闻等领域生成令人信服的“假文本”。检测假文本生成的方法已经有很多研究，但新的模型越来越依赖于大量参数、训练数据和能量消耗。尽管这可能会引发检测者与生成者之间的“军备竞赛”，但研究表明，即使是简单的分类器也能在有限的资源下展示出较高的检测准确性。因此，论文探讨了统计分类器识别经典侦探小说风格的“假文本”的能力，并发现随着模型版本的增加，Gemini展现出更强的生成欺骗性文本的能力，而GPT则不然。这表明即使对于越来越大的模型，可靠的假文本检测仍然是可能的，只是新模型架构可能会提高它们的欺骗性。
### Innovation
研究发现，新模型Gemini在增加版本后具有更强的生成欺骗性文本的能力，而GPT则不具备这样的变化趋势。这表明，在未来的大型模型发展中，可靠的假文本检测仍然是可行的，但新的模型架构可能会影响其欺骗性。
### Conclusion
尽管大型语言模型可以生成令人信服的假文本，但即便对于越来越大的模型，可靠地检测假文本仍然有可能实现。新型模型架构可能会增强它们的欺骗性，但这种方法的可靠性依旧是可以维持的。
## 199. `cs.CL` - Progtuning: 阶梯式微调框架用于基于Transformer的语言模型 [PDF](https://arxiv.org/pdf/2506.21119), [HTML](https://arxiv.org/abs/2506.21119)
### Authors
Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu
### Background
微调是利用基于Transformer的语言模型在下游任务中的一种有前途的技术。随着模型规模的不断扩大，更新所有模型参数的成本不断增加。参数高效微调方法通过有选择地更新一小部分参数来有效解决这一问题。然而，大多数现有的参数高效微调方法仍然要求更新与初始模型大小相同的参数，这忽略了Transformer块间不平等的贡献，导致计算资源分配非常低效。
### Innovation
本研究提出了Progtuning，这是一种新颖的微调框架，结合了渐进学习。具体来说，Progtuning 根据各Transformer块的贡献逐步减少更新的块数。Progtuning在优化资源分配和减少更新参数数量方面表现出色，减少数量约为25%，同时保持了竞争力。此外，它还展示了对参数高效微调方法的高度适应性，在各种适应场景中表现出色。
### Conclusion
Progtuning通过逐步减少更新的Transformer块数量来优化资源分配和减少更新参数数量，从而使计算资源的利用更加高效，展示了在多种适应性情景中的优越性能。
## 200. `cs.CL` - Agent-RewardBench:向着多模态代理在感知、规划和安全方面的统一评估基准 [PDF](https://arxiv.org/pdf/2506.21252), [HTML](https://arxiv.org/abs/2506.21252)
### Authors
Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao
### Background
随着多模态大型语言模型（MLLMs）的发展，多模态代理在现实生活任务中显示出前景，例如网络导航和具身智能。然而，由于缺乏外部反馈，这些代理难以实现自纠正和迁移学习。使用奖励模型作为外部反馈是一种有前途的方法，但尚未明确如何为代理选择合适的奖励模型。因此，构建一个专注于代理的奖励基准迫在眉睫。现有的代理奖励基准存在多维度和实际场景评估，步骤层面奖励评估以及合理难度和高质量数据等不足，难以全面评估多模态代理的奖励建模能力。
### Innovation
该论文提出了Agent-RewardBench，一种旨在评估MLLMs中奖励建模能力的基准。它包括三个关键特点：（1）多维度和现实代理场景评估；（2）步骤层面的奖励评估；（3）合适难度和高质量数据。通过精心选择10个不同的模型，控制难度保持任务挑战，并手动验证数据完整性，以确保数据的可靠性。实验结果表明，即使是顶尖的多模态模型也显示出了有限的表现，突显了代理奖励建模专业训练的必要性。
### Conclusion
实验结果强调了多模态代理奖励建模的必要性，并展示了Agent-RewardBench在多模态代理评估方面的优势。该研究团队已将代码开源至GitHub。
## 201. `cs.CL` - 使用自回归语言模型检测视觉地归类对话中的指示语 [PDF](https://arxiv.org/pdf/2506.21294), [HTML](https://arxiv.org/abs/2506.21294)
### Authors
Bram Willemsen,Gabriel Skantze
### Background
本文探讨了仅使用文本，自回归的语言建模方法来从视觉地归类对话中抽取指示语。研究目的是调查仅依靠语言上下文能否有效识别具有视觉可感知参考对象的提及。通过调整预训练的大规模语言模型，研究人员尝试通过预测下一个文本令牌来标记提及片段的边界，以实现对话中提及片段的标注。研究发现，即使使用中等规模的语言模型、较小的数据集以及参数高效的微调方法，文本仅方法仍然可以取得较好的效果，突显了语言上下文对于该任务的重要性。然而，本文认为任务本质上是多模态问题，并讨论了单模态方法固有的局限性。
### Innovation
本文利用预训练的大规模语言模型进行对话中提及片段的标注，通过预测下一个文本令牌来标记提及片段的边界。研究发现，即使是中等规模的语言模型和较小的数据集，也可取得较好的效果，显示出语言上下文在该任务中的重要性。此外，本文还讨论了单模态方法在该任务中的局限性，强调了任务的多模态本质。
### Conclusion
本文研究表明，单模态的文本方法在检测视觉地归类对话中的指示语时仍然可以取得良好的效果，表明语言上下文的重要性。然而，任务本质上是多模态问题，单靠文本不足以完全解决该问题，因此未来应当探索结合视觉信息的方法以进一步提升模型的效果。
## 202. `cs.CL` - 由指令引导的轮流预测 [PDF](https://arxiv.org/pdf/2506.21191), [HTML](https://arxiv.org/abs/2506.21191)
### Authors
Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara
### Background
在对话系统和对话机器人中，轮流预测模型是必不可少的组成部分。近年来，研究人员利用基于变换器的架构实现实时、连续的轮换预测。但这些方法缺乏动态调整的能力，难以通过文本提示实现直观和明确的控制。现有的数据集大多缺乏相应的文本提示数据，需要通过大型语言模型生成合成的提示句来弥补这一不足。
### Innovation
本文提出了一种新型的轮流预测模型，通过文本提示动态控制轮流预测。该模型基于基于变换器的声音活动投影（VAP）模型，引入了文本提示嵌入到通道变换器和跨通道变换器。实验结果显示，该模型提高了预测精度，并能够根据文本提示灵活调整轮流轮换的时间行为，这在真人真人对话数据集中的评估中得到了验证。
### Conclusion
本文提出的模型通过引入文本提示，能够在对话过程中实现更为灵活和直观的控制，显著提升了预测的准确性和适用性。同时，也为后续相关研究和应用提供了新的思路和方法。
## 203. `cs.CL` - Double-Checker：通过自我批判微调增强缓慢思考的LLMs的推理能力 [PDF](https://arxiv.org/pdf/2506.21285), [HTML](https://arxiv.org/abs/2506.21285)
### Authors
Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin
### Background
尽管缓慢思考的大语言模型（LLMs）展示出类似反思的推理能力，通常被称为“豁然开朗”时刻，但它们生成有见地的批评和改进先前解决方案的能力仍然有限。本文研究了如何通过引入Double-Checker框架，增强这些缓慢思考LLMs的推理能力。该框架通过微调使其能够进行显式的自我批评和逐步改进之前的解决方案，并最终评估它们的解决方案在自我生成的批评下是正确的
### Innovation
Double-Checker是一个原则性的框架，旨在通过促进显式的自我批判和迭代改进，增强缓慢思考LLMs的推理能力。通过在1,730个已筛选的自我批判实例上进行微调，Double-Checker使长时间推理的LLMs能够在推理过程中迭代地批评和改进其输出，直到它们在自我生成的批判下评估自己的解决方案是正确的。研究结果表明，迭代自我批判显著提升了长时间推理的LLMs的推理能力。与原始的长时间推理LLMs相比，使用Double-Checker后，挑战性的AIME基准测试的pass@1性能提升了13.8% (从4.4%提升到18.2%)
### Conclusion
这些结果表明，开发具有结构化自我批判能力、更加值得信赖和有效的LLMs是一个有前景的方向。
## 204. `cs.CL` - 基于用户交互的口语对话模型对齐 [PDF](https://arxiv.org/pdf/2506.21463), [HTML](https://arxiv.org/abs/2506.21463)
### Authors
Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez
### Background
当前的偏好学习方法主要针对基于文本的语言模型，而不适合实时语音交互的复杂性，这些交互具有丰富且动态的特性（如打断和插入），并且没有明确的发言人分隔。因此，本研究提出了一种新的偏好对齐框架，用于提升基于用户交互的实时对话模型。
### Innovation
研究创造了一个包含超过15万个偏好语对的大规模数据集，这些数据来自原始的多轮语音对话，这些对话被标注为AI反馈，涵盖了语言内容和时间上下文的变化。利用离线对齐方法，微调一个全双工自回归语音到语音模型。实验证明，对于一般对话的反馈可以在多个方面提升口语对话模型的表现，如使对话更事实、更安全、更上下文一致。研究还部署了微调后的模型，并通过全面的人类评估评估了其超越单一回合对话的影响。这些发现强调了各种动态的适当平衡对于自然实时对话系统的重要性.
### Conclusion
研究表明，通过整合用户交互中的偏好信息，可以有效改善实时对话模型，使对话更具事实性、安全性并更好地适应上下文。实证研究进一步证实了这一框架的有效性，并为开发自然实时语音对话系统提供了新的见解。
## 205. `cs.CL` - Small Encoders Can Rival Large Decoders in Detecting Groundedness [PDF](https://arxiv.org/pdf/2506.21288), [HTML](https://arxiv.org/abs/2506.21288)
### Authors
Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar
### Background
大型语言模型（LLMs）在自然语言处理任务中的性能可以通过与外部上下文结合来显著提升。然而，当提供的上下文信息不足或缺乏时，LLMs往往依赖推测或内部知识来回答查询，这可能导致答案不准确或没有事实依据。生成的答案是否严格基于提供的上下文信息（即，是否具有“接地性”），对于确保事实的一致性和可信度至关重要。因此，此研究旨在评估一种机制，该机制可以在LLMs生成成本高昂的答案之前，检测查询是否基于提供的文档上下文。这种机制能够显著减少推理时间和资源消耗。研究表明，通过在精心挑选的数据集上进行微调的轻量级任务特定编码器模型，如RoBERTa和NomicBERT，可以在接地性检测中达到与Llama3 8B和GPT4o等大型语言模型相当的准确性，同时大幅降低推理延迟时间。
### Innovation
本文创新性地展示了轻量级、针对任务的编码器模型，包括RoBERTa和NomicBERT，在接地性检测（确保生成的回答严格基于提供的上下文信息）上的表现，与大型语言模型相当。这些轻量级模型在可获得性、效率上具有明显优势，能够显著减少推理时间和资源消耗。此外，通过在特定数据集上微调这些编码器模型，即使模型本身较轻量级，也能实现高水平的准确性，从而提供了一种更为经济高效的解决方案来提升大型语言模型的性能。
### Conclusion
轻量级的特定任务编码器模型（如RoBERTa和NomicBERT）通过在精心制作的数据集上进行微调，能够在接地性检测任务上达到与大型语言模型（如Llama3 8B和GPT4o）相当的准确性。这些轻量级模型在推理延迟方面大幅优于大型语言模型，显著节约了资源。这种新的方法为提升大型语言模型的性能提供了一种更加高效、经济的选择。
## 206. `cs.CL` - 从离线到在线强化学习：LLMs的桥梁 [PDF](https://arxiv.org/pdf/2506.21495), [HTML](https://arxiv.org/abs/2506.21495)
### Authors
Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov
### Background
研究了强化学习方法在从离线到半在线再到全在线模式过渡过程中，对大规模语言模型的精调效果，特别是在可验证和非可验证任务上的应用。实验包括数学可验证训练和指令跟随的非可验证训练，使用基准评估进行比较分析。
### Innovation
广泛比较了在线和半在线的Direct Preference Optimization (DPO) 和 Group Reward Policy Optimization (GRPO) 目标，发现这些方法的性能和收敛性相似，均显著优于离线方法。详细分析了训练动态和超参数选择策略，以实现最佳性能。展示了联合处理可验证和非验证奖励的任务能够改进两种任务类型的性能。
### Conclusion
展示了在线和离线强化学习方法在大规模语言模型精调中的效果比较，并通过联合优化验证和非验证的奖励任务提高了性能。
## 207. `cs.CL` - 跨语言的Text2Cypher：评估基础模型超越英语的效果 [PDF](https://arxiv.org/pdf/2506.21445), [HTML](https://arxiv.org/abs/2506.21445)
### Authors
Makbule Gulcin Ozsoy,William Tai
### Background
近年来，大型语言模型的发展使得自然语言接口得以实现，可以将用户问题转化为数据库查询，例如Text2SQL、Text2SPARQL和Text2Cypher。这些接口增强了数据库的访问性，但目前大多数研究仅集中在英语上，对于其他语言的评估较少。本文研究了基础语言模型在跨语言Text2Cypher任务上的表现，通过将英文问题翻译成西班牙语和土耳其语，创建了一个多语言测试集，以实现公平的跨语言比较。
### Innovation
本文创建并发布了一个多语言测试集，将英文问题翻译成西班牙语和土耳其语，同时保留原始的Cypher查询，实现了公平的跨语言比较。使用标准化的提示和度量标准评估多个基础模型。在不同语言上的表现显示出一致性模式：英语最好，其次是西班牙语，土耳其语最差。研究还探讨了将任务提示翻译成西班牙语和土耳其语的影响，结果显示这在评估指标上影响甚微。
### Conclusion
研究结果突显了多语言查询生成领域更加包容性评估和发展的需要。未来的工作包括模式本地化和跨多种语言的微调。
## 208. `cs.CL` - 基于领域知识增强的LLM模型在欺诈和概念漂移检测中的应用 [PDF](https://arxiv.org/pdf/2506.21443), [HTML](https://arxiv.org/abs/2506.21443)
### Authors
Ali Şenol,Garima Agrawal,Huan Liu
### Background
由于动态平台上的语言模式不断演变以及概念漂移（CD），即由于语义或主题的变化导致的互动语境或意图变化，检测欺骗性对话越来越困难。这些变化可能隐藏恶意意图或模仿正常对话，从而使得准确分类变得具有挑战性。虽然大语言模型（LLMs）在自然语言任务中表现出强大性能，但在风险敏感的场景中，它们往往在处理上下文模糊性和幻觉方面存在困难。
### Innovation
本文提出了一种领域知识（DK）增强的LLM框架，该框架将预训练的LLM与结构化、任务特定的洞察相结合，用于欺诈和概念漂移检测。该模型架构包括三个主要组件：(1) 一个DK-LLM模块用于检测虚假或欺骗性对话；(2) 一个漂移检测单元（OCDD）用于确定是否发生了语义变化；(3) 一个第二DK-LLM模块将漂移分类为良性或欺诈性。与零样本基准模型进行的比较研究表明，结合领域知识和漂移意识显著提高了在高风险NLP应用中的性能、可解释性和鲁棒性。
### Conclusion
结果表明，该系统能够以高精度检测虚假对话，并有效地分类漂移的性质。基于LLaMA的实现，在结构化提示的引导下，达到了98%的分类准确率。
## 209. `cs.CL` - 通过交互式LLM对齐在社交驱动对话中增强用户参与度 [PDF](https://arxiv.org/pdf/2506.21497), [HTML](https://arxiv.org/abs/2506.21497)
### Authors
Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li
### Background
交互作用通过互动在社交驱动对话中促进用户参与至关重要。尽管先前的研究优化模型以推理相关知识或规划对话行为流程，但用户参与度与知识或对话行为之间的关系微妙且不保证社交驱动对话中的用户参与度。为此，本文通过利用未来对话发展的信号，使交互式LLM学习用户参与度。具体而言，本文采用用户反应（与对话意图相关的用户反应）作为奖励来引导交互式LLM的对话要求直接偏好优化（DPO），进而优化高阶用户参与度。
### Innovation
本文创新地提出了一种方法，通过直接利用未来对话发展的信号，使得交互式LLM通过用户的反应来学习用户参与度。这不同于以往的工作，直接优化了用户的参与感受。方法上，通过开发用户模拟器，并结合i×MCTS技术，收集了高质量和低质量的对话体验数据集，并利用DPO直接优化方法对交互式LLM进行对齐，从而提高用户在交互式LLM中的高阶参与度。
### Conclusion
在两种社交驱动对话场景（情感支持对话和善行说服）下进行的实验表明，本文方法在提高交互式LLM中的用户参与度方面是有效的。
## 210. `cs.CL` - 基于格赖斯符号方阵的人工智能文学批评结构主义方法：为大型语言模型利用格赖斯符号方阵 [PDF](https://arxiv.org/pdf/2506.21360), [HTML](https://arxiv.org/abs/2506.21360)
### Authors
Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen
### Background
大型语言模型（LLMs）在理解和生成文本方面表现出色，但在提供具有深刻思想和复杂叙事的专业文学批评方面仍然存在困难。本文背景在于现有技术对文学批评的支持不足，尤其是在处理复杂叙事时的分析能力有限。因此，作者旨在提出一种新的分析框架，以提高LLMs在文学批评领域的深度分析能力。
### Innovation
本文创新点在于提出了GLASS（格赖斯文学分析通过符号方阵）框架，这是一种基于格赖斯符号方阵（GSS）的结构化分析框架。GLASS通过量化评价方式，首次提出了一种基于GSS的文学批评数据集，并使用了LLM作为评判者的方式，从而提升了LLMs在文学批评中的应用效果。
### Conclusion
研究结果显示，GLASS框架在多种文学作品和不同LLMs的对比测试中表现优异，GLASS框架的应用实例可以填补现有研究中的空白，提供了一种AI支持的文学研究工具，有助于深入理解文学参与的认知机制。
## 211. `cs.CL` - 利用LLM辅助查询理解进行实时检索增强生成 [PDF](https://arxiv.org/pdf/2506.21384), [HTML](https://arxiv.org/abs/2506.21384)
### Authors
Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng
### Background
实时检索增强生成（RAG）系统在处理用户查询时面临显著挑战，这些查询常常是嘈杂、模糊且包含多种意图。尽管RAG通过外部知识增强了大型语言模型（LLMs），但现有系统通常难以处理如此复杂的输入，因为它们通常在较为干净的数据上进行训练或评估。
### Innovation
Omni-RAG是一个新颖的框架，旨在提高RAG系统在实时、开放领域的鲁棒性和有效性。它通过三个关键模块来增强查询理解：1）深度查询理解与分解，利用定制提示的LLM来去噪查询（如纠正拼写错误）并分解多意图查询为结构化子查询；2）意图感知的知识检索，为每个子查询从语料库中检索信息，并汇总结果；3）再排序与生成，使用再排序器（如BGE）细化文档选择，然后由LLM（如Falcon-10B）用链式思考提示生成最终答案。
### Conclusion
Omni-RAG旨在通过稳健处理复杂和嘈杂的查询来弥合当前RAG能力和现实应用需求之间的差距，例如SIGIR 2025 LiveRAG挑战所强调的应用。
## 212. `cs.CL` - 大型语言模型中的纸马理解 [PDF](https://arxiv.org/pdf/2506.21521), [HTML](https://arxiv.org/abs/2506.21521)
### Authors
Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan
### Background
大型语言模型（LLMs）通常通过基准数据集进行评估，但是基于LLMs对精心挑选问题的回答来进行推断其能力是否合理？本研究首先提出了一个正式框架来解决这一问题。研究指出，用于测试LLMs的基准测试，例如AP考试，同样也是用来测试人类的。这导致了一个关键点，即这些基准测试只有在LLMs对概念的理解错误方式与人类相似时才是有效的测试。否则，基准测试的成功只能表明浅薄的理解：一种与任何人类理解和解释概念不协调的答案所带来的假象理解。
### Innovation
本文提出了两种量化纸马理解存在的方法：一是使用专门设计的基准测试在三个领域进行量化，二是使用一种通用的方法提供其普遍性的下限。研究发现，纸马理解在模型、任务和领域中无处不在。此外，这些失败不仅反映了错误的理解，还反映了概念表示内部更深刻的不一致性。
### Conclusion
研究发现，无论是在模型之间、任务之间还是领域之间，纸马理解都是普遍存在的。这些失败不仅表现了错误的理解，还反映了概念表示中更深层的不一致性。
## 213. `cs.CL` - TopK 语言模型 [PDF](https://arxiv.org/pdf/2506.21468), [HTML](https://arxiv.org/abs/2506.21468)
### Authors
Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling
### Background
自编码器（SAEs）已成为分析和解释基于Transformer的语言模型（LMs）的激活空间的重要工具。然而，SAEs 存在一些缺点，这些缺点削弱了它们的实际效用和内部有效性。由于SAEs是在模型训练后进行训练的，因此不清楚SAEs未能发现特定概念是SAEs自身的失败，还是由于底层LM未表示这种概念。另外，由于训练条件和模型架构选择的影响，使得哪些特征被学习难以预测。当追踪LMs在训练期间学习概念时，特征稳定性缺乏亦使得SAEs特征在不同检查点之间的比较变得困难。
### Innovation
为了应对这些限制，我们提出了一种Transformer架构的修改，引入了TopK激活函数，在选定层上将模型的隐藏状态等同于TopK自编码器（SAEs）的潜在特征。这一方法消除了后续训练的需求，同时也提供了与SAEs媲美的可解释性。TopK LM相比原始模型具有更加有利的空间权衡，即模型规模、计算效率和可解释性之间取得了较好的平衡。尽管只是简单的架构改变，TopK LM仍保持其原始功能，同时提供了坚实的解释性优势。实验证明，TopK LM学习的稀疏表示能成功引导通过针对神经元干预，并在不同检查点和层中促进对神经元形成过程的详细分析。
### Conclusion
TopK LM提供了一种稳定且可靠的工具，用于理解和分析语言模型如何学习和表示概念，我们认为这将极大地推进未来模型解释性和可控制性研究的发展。
## 214. `cs.CL` - What's Up, Doc?：分析用户在大规模对话AI数据集中寻求健康信息的方式 [PDF](https://arxiv.org/pdf/2506.21532), [HTML](https://arxiv.org/abs/2506.21532)
### Authors
Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal
### Background
随着人们越来越多地通过交互聊天机器人从大型语言模型（LLMs）获取医疗健康信息，这些对话的本质及其潜在风险仍然很少被探讨。该论文通过筛选大规模对话人工智能数据集，构建了一个包含11,000个真实对话的HealthChat-11K数据集。研究目的是通过HealthChat-11K和医生驱动的交互分类来系统地研究用户在寻求医疗信息时与LLMs的交互情况，涉及21个不同的健康专业领域。研究揭示了关于用户如何以及为什么寻求健康信息的洞察，包括常见交互、不完整背景信息的实例、情感行为，以及可能产生奉承的互动（如引导性问题），这些发现强调了改进作为对话AI部署的LLMs在医疗支持功能的必要性。
### Innovation
论文创新地构建了HealthChat-11K，这是包含11,000个真实对话的大型数据集，以及使用医生驱动的交互分类来系统研究用户在21个健康专业领域中与LLMs的交互情况。此外，该研究深入分析了用户寻求健康信息的行为模式，及其背后的动机和潜在影响，强调了增强LLMs作为对话AI的医疗支持功能的重要性。
### Conclusion
该研究揭示了用户在寻求健康信息时的常见交互模式、不完整背景信息的实例、情感行为以及可能产生奉承的互动，这些发现凸显了需要改进LLMs作为对话AI部署时的医疗支持功能。
## 215. `cs.CL` - 超越反应型安全：通过长期模拟实现风险感知大语言模型对齐 [PDF](https://arxiv.org/pdf/2506.20949), [HTML](https://arxiv.org/abs/2506.20949)
### Authors
Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji
### Background
随着基于语言模型代理在重要社会决策中的影响日益增长，从公共政策到医疗保健，确保这些代理产生积极影响需要理解其建议的深远影响。现有方法主要关注语言模型的即时安全，但对长期安全缺乏理解，这促使作者提出一种新的框架，旨在研究模型生成建议如何在全社会层面传播，并通过长期模拟评估模型的预测能力，以提高长期安全性。
### Innovation
作者提出了一个概念验证框架，展示了如何通过长期模拟来预测模型生成建议如何在全社会范围内传播，从而有助于更稳健的对齐。此外，该论文引入了一个由100个间接伤害场景组成的数据集，以测试模型预测看似无害用户输入的潜在有害结果的能力，这是现有方法中没有的评估维度。实验结果表明，该方法不仅在新数据集上取得了超过20%的改进，还在现有的安全性基准上取得了超过70%的胜率，成为提高安全代理的有希望的方向。
### Conclusion
该研究提供了一种评估和改进语言模型长期安全性的新方法，通过长期模拟模型生成建议的传播路径，以及利用一个新的场景数据集评估模型的前瞻性预测能力，表明这种方法对开发更安全的代理具有重要意义。
## 216. `cs.CL` - 利用知识图谱生成高质量指令数据以增强大型语言模型工具使用 [PDF](https://arxiv.org/pdf/2506.21071), [HTML](https://arxiv.org/abs/2506.21071)
### Authors
Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong
### Background
目前，教育大型语言模型（LLMs）使用工具对于提升其解决问题的能力和扩大应用范围至关重要。然而，有效使用工具具有挑战性，因为这需要对工具功能和用户意图有着深刻的理解。之前的方法主要依赖LLMs生成指令数据，但这些数据的质量往往不足。因此，本研究提出了一种使用知识图谱生成高质量指令数据的新方法，以提升LLMs使用工具的能力和整体性能。知识图谱是具有大量语义信息的、由人工整理的数据集，通过从中提取各种查询路径并转化为广泛的用户查询，解析路径中的实体关系并转化为可执行工具，将查询路径分解成详细的解决方案步骤，最终生成高质量的指令数据。
### Innovation
本研究创新性地提出了一种利用知识图谱生成高质量指令数据的新方法，通过解析知识图谱中的查询路径和实体关系来生成LLMs可以使用的具体指令数据，以显著提升LLMs使用工具的能力和整体性能。
### Conclusion
实验表明，仅对少量生成的合成数据进行微调就可以显著提高LLMs使用工具和提升整体能力。
## 217. `cs.CL` - 学习跳过Transformer的中间层 [PDF](https://arxiv.org/pdf/2506.21103), [HTML](https://arxiv.org/abs/2506.21103)
### Authors
Tim Lawson,Laurence Aitchison
### Background
传统的Transformer模型在计算效率上存在较大的冗余，因此研究人员提出了多种压缩策略。现有的方法通常针对单一模块（如专家混合层）或独立地跳过整个层，但这些方法并未充分利用解码器的结构特性。已有研究指出，中层部分显示出较大的冗余性，而早期层则能够将信息聚合到标记位置。
### Innovation
本文提出了一种新颖的架构，它能够动态地从中间层向外跳过一定数量的层。特别地，一种学习到的门机制根据输入决定是否跳过中间对称层段，而门控注意力机制确保后续标记不会注意到被跳过的标记位置。研究者通过‘三明治’或分层归一化方案控制残差归一化，并使用自适应正则化损失控制门控稀疏度。目标是减少简单标记的计算需求，并推动出现多层表示层次结构，但这在大规模测试中并未在验证交叉熵和估计FLOPs之间表现出优于较少层的密集基线架构的改进。
### Conclusion
尽管从理论上提出了改进，但在规模较大的测试中，该方法并未在验证交叉熵与估计FLOPs的权衡上取得优于较轻量级基线架构的改进。研究代码已公开。
## 218. `cs.CL` - SharpZO: 前向通过仅有的混合硬化感知视觉语言模型提示调优 [PDF](https://arxiv.org/pdf/2506.20990), [HTML](https://arxiv.org/abs/2506.20990)
### Authors
Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang
### Background
视觉语言模型（VLMs）在多种下游任务上的微调取得了显著的性能；然而，它们需要通过反向传播（BP）访问模型梯度，这使得它们不适合用于内存受限、只能进行推理的边缘设备。在此之前，研究者们探索了多种无需BP的微调方法，但这些方法往往依赖于高方差的演化策略（ES）或零阶（ZO）优化，且常常无法达到满意的效果。
### Innovation
本文提出了一个称为SharpZO的混合硬化感知零阶优化方法，用于通过前向通过提升ZO VLM微调的性能。SharpZO通过两个阶段的优化过程来实现这一目标：第一阶段是硬化感知的ES阶段，进行全局探索和损失景观的平滑以构建强大的初始化；第二阶段是稀疏ZO优化引导的精细本地搜索。整个优化过程仅依赖前向通过。
### Conclusion
详细理论分析和CLIP模型上的大量实验表明，SharpZO显著提高了准确率和收敛速度，与最新的仅前向通过方法相比，平均提高了7%的性能。
## 219. `cs.CL` - skLEP: 斯洛伐克通用语言理解基准 [PDF](https://arxiv.org/pdf/2506.21508), [HTML](https://arxiv.org/abs/2506.21508)
### Authors
Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko
### Background
当前缺乏专门用于评估斯洛伐克自然语言理解（NLU）模型的基准测试。现有的资源主要关注其他语言或标准化的英语NLU资源，未能全面评估斯洛伐克语模型的能力。因此，研究者们需要一个全面的基准测试来更好地评估和改进斯洛伐克语NLU模型。
### Innovation
该研究提出了skLEP，这是首个专注于斯洛伐克语的综合基准测试。 skLEP 包含九个不同的任务，涵盖从单词级到文档级的各种挑战，提供了对模型能力的全面评估。此外，研究者新创建了一个斯洛伐克语的原始数据集，并精确翻译了现有的英语NLU资源，为斯洛伐克语模型提供了更精确的数据支持。研究还提供了对多个斯洛伐克特定和多语言预训练语言模型的系统性评估，展示了这些模型在skLEP任务上的表现。研究者还发布了基准测试数据、开源工具包和公开排行榜，以促进研究的可重复性和推进后续斯洛伐克语NLU研究的发展。
### Conclusion
该研究通过创建skLEP基准测试，填补了斯洛伐克NLU模型评估的空白，展示了多个预训练模型在斯洛伐克语任务上的表现，并通过成为一个开放资源促进了研究的共享和后续改进。这将有助于推动斯洛伐克语NLU的研究和应用进一步发展。
## 220. `cs.CL` - 揭开大型语言模型中的因果推理：现实还是幻象？ [PDF](https://arxiv.org/pdf/2506.21215), [HTML](https://arxiv.org/abs/2506.21215)
### Authors
Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han
### Background
因果推理能力是推动大型语言模型（LLMs）向强人工智能发展的关键。虽然LLMs似乎表现出了理解上下文因果关系和提供遵循因果法则回答的能力，但尚不清楚它们是否进行真正的人类水平的因果推理。现有证据表明，它们仅具备浅层次的因果推理能力，主要依赖于其参数中嵌入的因果知识，但缺乏真正的人类水平因果推理的能力。通过分析基于变换器的LLMs的自回归机制，文中指出其本身并非因果性的，并通过一款新的因果问答基准（CausalProbe-2024）进一步证明，在该基准上LLMs的表现显著降低，这意味着它们主要进行的是浅层次的因果推理。
### Innovation
文中引入了一个新的因果问答基准CausalProbe-2024，提出了一种新的方法G^2-Reasoner，该方法将通用知识和目标导向的提示融入到LLMs的因果推理过程中，实验表明G^2-Reasoner显著提高了LLMs的因果推理能力，特别是在新颖和反事实的情境中。
### Conclusion
这项工作为LLMs实现真正的人类水平因果推理提供了新的途径，超越了浅层次的因果推理，向着层次二的因果推理迈出了重要一步。
## 221. `cs.CL` - MAGPIE：多智能体情境隐私评估数据集 [PDF](https://arxiv.org/pdf/2506.20737), [HTML](https://arxiv.org/abs/2506.20737)
### Authors
Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang
### Background
LLM（大型语言模型）代理的普及导致了更多的代理间协作场景被部署用于执行像是日程安排、谈判和资源分配等工作。在此类系统中，隐私至关重要，因为代理常常需要访问具有严格保密需求的专有工具和领域特定数据库。已有基准测试主要评估单一对话回合、低复杂性的任务，而这些任务中的私密信息容易被排除。因此，需要新的基准测试来涵盖更复杂的情境，以确保数据的隐私保护。
### Innovation
本文提出了一个名为MAGPIE的基准数据集，囊括了158个真实场景，涉及15个领域。这些场景设计得需要隐私数据不能完全排除，同时过度的信息共享也可能造成重大损失。这项研究通过评估当前最先进的LLM模型在理解情境隐私数据和协作时是否能够保护用户隐私，揭示了这些模型在处理多回合对话和多代理协作方面表现疲弱的问题。
### Conclusion
当前模型在理解情境隐私数据和保护用户隐私方面存在明显不足。在多回合对话过程中，这些模型即便在按照隐私指示操作时，依然有50%以上的机率泄露私密信息。多代理系统在71%的任务中无法完成这些高风险情境中的任务。综上，当前模型尚未实现情境隐私保护和多任务协作这两项目标的真正平衡。
## 222. `cs.CL` - DiLoCoX: 一个适用于去中心化集群的大规模低通信训练框架 [PDF](https://arxiv.org/pdf/2506.21263), [HTML](https://arxiv.org/abs/2506.21263)
### Authors
Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich
### Background
大规模语言模型（LLM）的分布式训练需要高效率的通信，这通常依赖于快速且可靠的中心化集群。但当处理超过100亿参数的模型时，是否可以在慢速网络上进行训练，从而启用分散式集群的强大功能，是一个值得研究的问题。现有的方法对通信依赖较高，难以在慢速网络环境下实现高效训练。因此，寻找一种新型的低通信训练框架变得尤为重要。
### Innovation
本文提出了一种名为DiLoCoX的新型低通信大规模分散式集群训练框架，该框架结合了管道并行性、双优化器策略、一阶延迟重叠通信与本地训练以及自适应梯度压缩方案。这种结合大幅提高了模型参数量和预训练速度，通过理论分析证明了其通信延迟重叠与本地训练的一阶模式以及自适应梯度压缩方案的优势。实验结果显示，DiLoCoX可以在1Gbps的网络中高效地预训练一个107亿参数的基础模型，并且相比传统的AllReduce，在分布式训练中可实现357倍的速度提升，同时对模型收敛的影响微乎其微。
### Conclusion
这是首个成功应用于超过100亿参数模型的去中心化训练框架。
## 223. `cs.CL` - HumanOmniV2：从理解到跨模态推理 [PDF](https://arxiv.org/pdf/2506.21277), [HTML](https://arxiv.org/abs/2506.21277)
### Authors
Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou
### Background
随着多模态大规模语言模型的迅速发展，深度理解并解读人类意图的能力变得至关重要。尽管强化学习（RL）在提升大规模语言模型（LLMs）的推理能力方面展现了潜力，但将RL适应于多模态数据和格式的挑战仍被广泛忽视。现有研究中的多模态推理模型存在两个主要问题：全球上下文理解不足和捷径问题。全球上下文理解不足可能导致模型对多模态上下文的误解，从而给出错误答案。捷径问题则发生在模型忽略了多模态输入中的关键线索，直接回应查询，不考虑多模态信息。为解决这些问题，本文强调了多模态输入中全局上下文理解的重要性，以有效避免忽略关键多模态线索，确保全面的推理过程。
### Innovation
本文提出了两种创新措施：一是通过大型语言模型判断上下文奖励，结合格式和准确性奖励，确保对多模态上下文信息的准确解读；二是让大规模语言模型评估逻辑奖励，判断推理过程是否成功整合了多模态信息与逻辑方法。此外，本文还引入了跨模态基准测试IntentBench，旨在评估模型在理解复杂人类意图和情感方面的能力。本文提出的方法在多个跨模态基准测试中表现出色，优于其他开源跨模态模型。
### Conclusion
本文提出的方法在多个跨模态基准测试中表现出色，特别是在理解和解释多模态数据方面的性能显著提升，解决了现有模型中存在的全局上下文理解不足和捷径问题。
## 224. `cs.CL` - 语言模型训练中的数据有效性 [PDF](https://arxiv.org/pdf/2506.21545), [HTML](https://arxiv.org/abs/2506.21545)
### Authors
Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li
### Background
语言模型的训练依赖于数据。最近的研究致力于提高数据效率，即通过选择最小或最优的训练数据子集来最大化性能。尽管数据过滤、采样和选择等技术发挥了关键作用，但如何通过优化训练数据的组织结构来进一步提高模型性能尚未得到充分研究。为此，该论文提出了一种新的概念——数据有效性（Data Efficacy），并通过引入一个名为DELT（Data Efficacy for Language Training）的一般范式来探讨这个问题。DELT包括数据评分、数据选择和数据排序三个组件。
### Innovation
该研究的创新点在于提出了数据有效性这一概念，并开发了一个名为DELT的框架来探讨此概念在语言模型训练中的应用。DELT框架包含三个组成部分：数据评分、数据选择和数据排序。其中，针对数据评分部分，提出了新的实例“学习能力和质量评分”（LQS）和数据排序中提出的“折叠排序”（FO），旨在解决模型遗忘和数据分布偏差等问题。全面的实验验证了此框架的有效性。
### Conclusion
研究结果显示，DELT的不同实例可以不同程度地提高语言模型的性能，而不需要增加数据量或模型规模。在这些实例中，LQS和FO的结合实现了最大的性能提升。此外，数据选择还可以与数据效率相结合，实现数据的有效性。因此，数据有效性是一个在语言模型训练中具有潜在研究价值的基础领域。
## 225. `cs.CL` - Logios: 开源的希腊多音节光学字符识别系统 [PDF](https://arxiv.org/pdf/2506.21474), [HTML](https://arxiv.org/abs/2506.21474)
### Authors
Perifanos Konstantinos,Goutsos Dionisis
### Background
现有传统的光学字符识别（OCR）方法在处理希腊多音节文字时存在局限性，准确识别和数字化这些特殊的文字具有挑战性。为此，本文提出了一种专门针对希腊多音节文字的OCR系统，通过结合卷积层的特征提取能力和循环层的序列学习能力，解决希腊多音节文字特有的问题，旨在提高识别准确性和效率.
### Innovation
系统采用了卷积层和循环层相结合的方法来解决希腊多音节文字的识别问题，这是对传统OCR方法的一种改进。研究团队还开放了底层模型，提供了一个开源库以及可供学术使用的OCR平台.
### Conclusion
本研究提出了一种专用于希腊多音节文字识别的新型OCR系统，并通过开放源代码来促进学术研究和实际应用，显著提升了希腊多音节文字识别的准确性和效率.
## 226. `cs.CL` - 复杂性感知的微调 [PDF](https://arxiv.org/pdf/2506.21220), [HTML](https://arxiv.org/abs/2506.21220)
### Authors
Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev
### Background
通用的大语言模型（LLMs）通常通过监督微调（SFT）来增强在特定领域的表现。通过蒸馏较大的模型的推理过程可以获得更好的效果，但代价是大量的昂贵调用和大量的数据。现有方法通常在所有数据上进行SFT，但这种方法效率不高且需要大量资源。现有研究旨在通过识别复杂数据并仅对其使用推理来优化微调过程，提高效率并减少所需数据量.
### Innovation
本文提出了一种新的高效微调蓝图，仅针对由熵值识别的复杂数据使用推理。作者通过SFT和蒸馏对两个小型开放模型进行微调，并展示了他们的流程显著优于传统的SFT方法（平均准确率为0.55 vs 0.43），同时使用62%的数据达到与蒸馏相当的性能。开源代码和数据供进一步研究使用.
### Conclusion
本文的研究表明，通过复杂性感知的方法进行微调可以提高效率并减少对数据的需求，同时保持与蒸馏相当的性能。这为后续研究提供了新的方向，并且作者已经开源其代码和数据以促进更多研究。
## 227. `cs.CL` - 低资源音乐生成中适配器设计权衡探索 [PDF](https://arxiv.org/pdf/2506.21298), [HTML](https://arxiv.org/abs/2506.21298)
### Authors
Atharva Mehta,Shivam Chauhan,Monojit Choudhury
### Background
对MusicGen和Mustango这类大规模音乐生成模型进行精细调整是一个耗费大量计算资源的过程，通常需要更新数十亿个参数，因此需要大量的硬件资源。尽管Parameter-Efficient Fine-Tuning (PEFT)技术，尤其是基于适配器的方法，允许使用最少的可训练参数来实现较高模型性能的适应需求，但适配器的设计选择包括架构、放置和大小等多种可能，还没有明确的研究表明哪种组合可以产生最优适配器以及为什么，尤其是在低资源音乐类型中。因此，该研究旨在通过探索不同适配器配置来回答这些问题，验证它们在低资源音乐生成中的性能差异和适用性，并最终展示模型训练难度及生成音乐质量之间的权衡关系。
### Innovation
该研究通过对比研究音乐生成模型MusicGen和Mustango中不同适配器配置在Hindustani Classical和Turkish Makam音乐两个细分音乐类型上的表现，发现基于卷积的适配器在捕捉细微的音乐局部细节方面表现更佳，而基于变换器的适配器在保持结构化即兴所需的长期依赖性方面表现更优。此外，该研究还分析了不同规模适配器的计算资源需求，揭示了中等大小适配器(40M参数)的高效平衡，同时发现Mustango模型尽管生成更多样且符合输入指令的音乐，但在音符稳定性、节奏对齐以及美学方面表现欠佳，而且计算强度更高，需要更长的训练时间；相比之下，自回归模型MusicGen则提供更快的训练速度和更高效地生成更高质量的音乐产品，但可能在生成过程中会出现一定的冗余。
### Conclusion
总体而言，研究表明基于卷积和基于变换器的适配器在低资源音乐生成场景下有各自的优势和局限性，适用于不同类型的音乐生成任务。中等规模的适配器在保证表达力与质量的一致性上具有较好的平衡。在实际应用中，选择合适的适配器设计和规模需要根据具体的音乐类型和应用需求进行权衡。Mustango模型在音乐多样性及贴近描述方面表现较好，但对音符的稳定性等问题还需改进；而音乐生成中自回归模型如MusicGen则更具训练效率和生成的高质量产品表现，但在生成过程中稍有冗余。
## 228. `cs.CL` - 混合深度学习与信号处理在低资源环境下阿拉伯方言识别中的应用 [PDF](https://arxiv.org/pdf/2506.21386), [HTML](https://arxiv.org/abs/2506.21386)
### Authors
Ghazal Al-Shwayyat,Omer Nezih Gerek
### Background
阿拉伯方言识别在语音技术中极具挑战性，由于阿拉伯语的语义多样性以及用于代表性不足方言的大规模标注数据集的稀缺性。本文探讨了将经典信号处理技术与深度学习架构结合的混合建模策略，以应对资源匮乏环境下的这一问题。
### Innovation
开发了两种混合模型：1) Mel频率倒谱系数（MFCC）与卷积神经网络（CNN）结合；2) 离散小波变换（DWT）特征与循环神经网络（RNN）结合。实验结果显示，MFCC + CNN架构的准确率为91.2%，显著优于Wavelet + RNN配置的66.5%。研究表明，利用光谱特征与卷积模型相结合，特别在使用有限的标记数据时，尤其有效。此外，还指出了数据集大小、标签区域重叠和模型优化等限制，并建议未来研究的方向包括更大的标注语料库、自我监督学习技术以及Transformer等先进神经架构的应用。
### Conclusion
本文为资源受限环境中阿拉伯方言识别奠定了基础，并为未来的发展指明了方向。
## 229. `cs.CL` - MockLLM：在线求职和招聘的多代理行为协作框架 [PDF](https://arxiv.org/pdf/2405.18113), [HTML](https://arxiv.org/abs/2405.18113)
### Authors
Hongda Sun,Hongzhan Lin,Haiyu Yan,Yang Song,Xin Gao,Rui Yan
### Background
在线招聘平台改变了求职和招聘流程，增加了对提升人职匹配的应用的需求。传统方法通常依赖于分析简历和职位描述的文本数据，这限制了招聘过程中动态和互动的关键方面。最近在大规模语言模型（LLMs）方面的进展揭示了在模拟适应性、基于角色的对话方面的巨大潜力，使其非常适合招聘场景。
### Innovation
提出了MockLLM，一种生成和评估模拟面试互动的新颖框架。该系统包括两个关键组成部分：模拟面试生成和手拉手协议中的双向评估。通过模拟面试官和求职者两个角色，MockLLM使实时和双向匹配的交互变得一致和协作。进一步根据以前的经验，MockLLM还融入了反思记忆生成和动态策略修改，从而改进行为。通过在主要的中国招聘平台Boss Zhipin上进行的实验表明，MockLLM在匹配准确性、可扩展性和跨职位领域适应性方面超过了现有方法，突显了其在候选人评估和在线招聘方面的潜在价值。
### Conclusion
实验结果表明，MockLLM在匹配准确性、可扩展性和跨职位领域适应性方面优于现有方法，展示了其在候选人评估和在线招聘方面的潜力。
## 230. `cs.CL` - Latent Prototype Routing: 实现Mixture-of-Experts中的近乎完美的负载均衡 [PDF](https://arxiv.org/pdf/2506.21328), [HTML](https://arxiv.org/abs/2506.21328)
### Authors
Jiajie Yang
### Background
Mixture-of-Experts (MoE) 架构已成为有效扩展大规模语言模型 (LLMs) 的关键策略。然而，现有的 MoE 系统存在严重的负载不平衡问题，在训练和推理过程中，只有少数专家被持续激活，导致模型容量和计算资源的显著浪费和利用不足。现有解决方案未能平衡专家负载，同时保持下游性能不受影响。因此，本文重新审视专家路由问题，并提出了一种称为 Latent Prototype Routing (LPR) 的新型路由框架，该框架在保持下游性能的基础上提升了平衡专家负载的能力。
### Innovation
LPR 提出了一种新的路由框架，该框架不仅综合了现有的路由方法，还通过聚类视角促进了专家负载的平衡，而不会影响下游性能。广泛的实验结果表明，LPR 通过将专家负载的 Gini 系数从 0.70 降低到 0.035 平均值，将最小最大专家负载比从 1e-6 提高到 0.70，实现了接近完美的负载平衡。
### Conclusion
实验结果证明，LPR 通过优化专家负载平衡策略，显著提升了 MoE 系统的资源利用率和性能表现。
## 231. `cs.CL` - 从大型语言模型学习评估模型：序列生成的顺序生成评估 [PDF](https://arxiv.org/pdf/2308.04386), [HTML](https://arxiv.org/abs/2308.04386)
### Authors
Chenglong Wang,Hang Zhou,Kaiyan Chang,Tongran Liu,Chunliang Zhang,Quan Du,Tong Xiao,Yue Zhang,Jingbo Zhu
### Background
传统的序列生成评估依赖BLEU和ROUGE等度量标准，但这些度量标准往往因过于注重igram重叠而无法捕捉到生成文本序列的语义准确性。一种有希望的解决方案是发展基于模型的度量标准，如BLEURT和COMET，但由于缺乏训练评估模型所需的人标注数据，这些方法常受阻。因此，本研究旨在克服这一挑战，提出了一种名为CSEM的定制序列评估度量（Customized Sequence Evaluation Metric）方法，该方法通过使用大型语言模型生成标注数据来训练评估模型，从而无需人工标注数据。此外，CSEM方法还拓展了评估类型，包括单方面、多方面、无参考和有参考评估，使其能够适应多种实际应用场景。
### Innovation
该研究提出了一种名为CSEM的方法，该方法利用大型语言模型生成标注数据，从而避免了对人类标注数据的需求。此外，CSEM支持多种评估类型，使其能够适应各种现实场景。实验结果表明，CSEM能够有效地训练评估模型，而通过CSEM开发的度量标准优于传统度量标准，经ChatGPT等常用度量标准及ChatGPT评估，序列质量显著提高。
### Conclusion
CSEM通过利用大型语言模型生成标注数据来训练评估模型，消除了对人工标注数据的需求，并通过支持多种评估类型，使得能够适应不同的实际应用场景。实验结果显示，通过CSEM开发的度量标准在序列质量评估中优于传统度量标准，整体上提升了序列质量。
## 232. `cs.CL` - 从有限视角建立空间心理模型 [PDF](https://arxiv.org/pdf/2506.21458), [HTML](https://arxiv.org/abs/2506.21458)
### Authors
Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei
### Background
人类能够利用少数几个视角来构建空间心理模型，而现有视觉语言模型（VLMs）在这方面表现不佳，表现出随机性能。MindCube基准测试以21,154个问题分布在3,268张图像的基础上，揭示了VLMs在此方面的关键差距。现有VLMs在任务上的表现接近随机猜测，亟需新的方法帮助模型更好地构建空间心理模型。
### Innovation
该研究提出了一个名为'Map-then-Reason'的新方法，通过首先生成认知地图然后在此基础上进行推理来提升模型的表现。此外，通过引入强化学习进一步提升了性能。该方法强调了有意识地构建和利用内部结构化的空间表示以及灵活的推理过程的重要性，从而显著提高了对不可见空间的理解。
### Conclusion
研究结果表明，通过训练模型在其内部地图上进行推理可以将准确率从37.8%提高到60.8%（+23.0%）。进一步引入强化学习后，准确率达到了70.7%（+32.9%）, 并得出了一个重要结论：搭建空间心理模型，主动构建和利用内部的空间结构化表示，并结合灵活的推理过程，显著改善了对不可见空间的理解。
## 233. `cs.CL` - ScalaBL: 可扩展的通过随机变分子空间推断的大规模语言模型贝叶斯低秩适应 [PDF](https://arxiv.org/pdf/2506.21408), [HTML](https://arxiv.org/abs/2506.21408)
### Authors
Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha
### Background
尽管大规模语言模型（LLMs）在广泛应用，但它们在生成错误信息和校准不准确方面有已知的问题。因此，量化这些模型的不确定性变得至关重要，特别是在高风险领域如自动驾驶和医疗保健中。先前的工作通过在微调模型的低秩适应（LoRA）参数上进行推理，使得贝叶斯深度学习方法更易于处理，但这些方法在扩展到更大规模LLM时出现困难，因为它们需要比LoRA更多的参数。
### Innovation
本文介绍了一种名为ScalaBL的方法，通过随机变分子空间推断实现了大规模语言模型的可扩展贝叶斯低秩适应。ScalaBL在LoRA秩$r$的$r$维子空间内进行贝叶斯推断，通过重新利用LoRA参数作为投影矩阵，将子空间中的样本映射到LLM的整个权重空间。这使得使用随机变分推断学习方法的所有参数成为可能。尽管子空间的维度较低，ScalaBL仍能达到最先进的性能表现，只需添加约1000个额外参数，并且能够扩展到目前为止最大的贝叶斯LLM，拥有比先前工作多四倍基本参数的数量。
### Conclusion
ScalaBL能够有效应对大规模语言模型的不确定性量化问题，并且在保持高性能的同时显著减少了额外参数需求，同时还能够扩展到更大的模型规模。
## 234. `cs.CL` - HalluSegBench：基于反事实视觉推理的分割幻视评估 [PDF](https://arxiv.org/pdf/2506.21546), [HTML](https://arxiv.org/abs/2506.21546)
### Authors
Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou
### Background
近期，视觉-语言分割技术显著提升了基于图像的语义理解能力。然而，现有模型经常出现幻视现象，即生成与图像内容不符的分割掩码或错误地标记无关区域。现有的幻视评估协议主要关注标签或文本幻视，而不改变视觉上下文，这限制了其对关键失败的诊断能力。因此，现有评估方法难以全面评价模型的语义理解能力。
### Innovation
该论文提出了HalluSegBench，这是首个专门设计用于通过反事实视觉推理来评估视觉定位中幻视现象的基准。HalluSegBench 包含一个新颖的数据集，共计1340个反事实实例对，覆盖281个独特的对象类别，以及一套新的度量标准，可以量化视觉场景编辑前后幻视敏感性。实验结果显示，基于视觉的幻视现象比基于标签的更普遍，模型在语义分割中容易产生持续的错误，强调了反事实推理在诊断语义定位准确性方面的必要性。
### Conclusion
通过HalluSegBench的实验，研究者发现模型在某些情况下更容易产生基于视觉的幻视，而不仅仅是基于标签的幻视，表明反事实推理对于诊断视觉定位的准确性至关重要。
## 235. `cs.CL` - 在作者和文档表示中捕捉风格 [PDF](https://arxiv.org/pdf/2407.13358), [HTML](https://arxiv.org/abs/2407.13358)
### Authors
Enzo Terreau,Antoine Gourru,Julien Velcin
### Background
深度自然语言处理（NLP）模型广泛使用连续且低维度的词和文档表示。然而，现有的大多数模型并未对作者的表示学习进行研究。这些表示可以应用于多种NLP任务，例如作者的识别与分类，或者在推荐系统中。现有的工作的一个主要限制是没有显式地捕捉到写作风格，这使得它们在文学数据上难以应用。因此，作者提出了一种基于可变信息瓶颈（VIB）的新架构，该架构学习作者和文档的嵌入表示，并且具有一个风格约束。模型会对预训练的文档编码器进行微调，并通过添加预定义的风格特征来促进风格检测，从而使表示轴能够与风格指标进行解释。该方法在三个数据集上进行了评估：来自古腾堡项目的文学语料库、Blog作者语料库和IMDb62，结果显示该方法在作者身份认定方面可以与最新的基准方法相媲美或超过基准方法，同时更准确地捕捉到了作者的风格方面。
### Innovation
提出了基于可变信息瓶颈（VIB）的新架构，该架构能够学习作者和文档的嵌入表示，并具有风格约束。模型通过对预训练的文档编码器进行微调，并通过添加预定义的风格特征来提高风格检测的准确性，从而使得表示轴能够与风格指标进行解释。这种模型在文学语料库、Blog作者语料库和IMDb62上展示了在作者身份认定上的优越性能，并能够更准确地捕捉到作者的风格方面。
### Conclusion
该方法在三个数据集上的评估结果显示，其在作者身份认定方面可以与最新的基准方法相媲美或超过基准方法，同时更准确地捕捉到了作者的风格方面，证明了该模型的有效性和实用性。
## 236. `cs.CL` - SceneGenAgent：基于编码代理的精确工业场景生成 [PDF](https://arxiv.org/pdf/2410.21909), [HTML](https://arxiv.org/abs/2410.21909)
### Authors
Xiao Xia,Dan Zhang,Zibo Liao,Zhenyu Hou,Tianrui Sun,Jing Li,Ling Fu,Yuxiao Dong
### Background
工业场景的建模对于工业制造中的模拟至关重要。虽然大型语言模型（LLMs）已展示出从文本描述生成通用3D场景的显著进展，但在生成工业场景方面仍面临挑战，因为这需要精确的测量和定位，涉及复杂的空间布局规划。
### Innovation
本文提出了一种基于LLMs的SceneGenAgent代理，通过C#代码生成工业场景。该代理通过结构化和可计算的格式确保精确的布局规划，布局验证以及迭代优化，满足工业场景的定量要求。另外，作者构建了一个名为SceneInstruct的数据集，用于微调开源LLMs以集成到SceneGenAgent中，从而进一步提高性能。
### Conclusion
实验结果表明，SceneGenAgent增强的LLMs在真实工业场景生成任务中的成功率达到了81.0%，有效地满足了大部分场景生成需求。此外，基于SceneInstruct微调开源LLMs显示出显著的性能提升，Llama3.1-70B接近GPT-4o的能力。
## 237. `cs.CL` - Mind2Web 2: 以代理作为评判者的评估机构搜索 [PDF](https://arxiv.org/pdf/2506.21506), [HTML](https://arxiv.org/abs/2506.21506)
### Authors
Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su
### Background
自主型搜索（如深度研究系统），其中大型语言模型自主浏览网络、综合信息并提供全面的引文支持答案，正在改变用户与大规模网络信息交互的方式。这种搜索方法虽然提高了效率并减轻了认知负担，但其复杂性和开放性也在急速增长，现有的评价基准和方法论滞后，这些方法主要假设短期内的简单问题和答案。为了评估这种不断变化和复杂的回答，本文介绍了一个新的效标基准Mind2Web 2，以及一种名为Agent-as-a-Judge的新框架。Mind2Web 2包含了130个时间敏感、高质量且长期的任务集合，这些任务允许实时网络浏览和信息综合，并且是通过超过1000小时的人类劳动构造的。
### Innovation
本文提出了一种名为Agent-as-a-Judge的新框架，用于评估自主型搜索的回答及其来源。该框架基于分层评价标准构建任务特异性评判代理，以自动评估答案的正确性和来源归因。此外，该研究对九种领先的自主型搜索系统和人类性能进行了全面评估，并进行了详细的错误分析，为进一步开发提供了有价值的见解。
### Conclusion
表现最好的系统Deep Research已经达到了人类表现的50-70%，并且用时仅为一半，展示出了巨大的潜力。总体而言，Mind2Web 2为开发和测试下一代自主型搜索系统提供了严格的基准。
## 238. `cs.CL` - 比较检索增强和参数高效微调在保护隐私的大语言模型个性化中的应用 [PDF](https://arxiv.org/pdf/2409.09510), [HTML](https://arxiv.org/abs/2409.09510)
### Authors
Alireza Salemi,Hamed Zamani
### Background
尽管大语言模型（LLMs）在各种搜索、推荐和问答任务中有着显著影响，但对于如何在保护隐私的前提下实现个性化的研究相对较少。现有的主要方法是通过检索增强生成（RAG），即通过从用户个人数据中检索信息来丰富输入提示以生成个性化输出。本文研究了RAG之外的一个新的方法，通过参数高效微调（PEFT）学习用户特定的LLM参数，从而进行个性化。相对于没有个性化的LLMs，RAG和PEFT方法分别提高了14.92%和1.07%，当两者结合使用时，个性化效果进一步提高了15.98%。研究还发现，可用的用户数据量越多，PEFT的效果越好。RAG特别适用于数据有限的情况下的新用户，而PEFT在有更多的用户特定数据时表现更好。
### Innovation
本文首次系统地研究了通过PEFT进行LLM个性化的方法，并将PEFT方法与RAG方法进行了广泛的比较。该研究探讨了结合RAG和PEFT方法如何进一步提高个性化效果，确立了PEFT在利用用户数据进行个性化方面的有效性。
### Conclusion
本文结果表明，总体而言，RAG和PEFT方法平均分别比没有个性化的方法提高了14.92%和1.07%。使用RAG结合PEFT进一步提高了15.98%。这表明RAG和PEFT的结合在个性化文本生成方面具有显著效用，并且可用用户数据的量与PEFT的有效性正相关。此外，RAG特别适合于冷启动用户，而PEFT在有更多的用户特定数据时表现更好。
## 239. `cs.CL` - OpenNER 1.0: 50多种语言的标准化开放访问实体识别数据集 [PDF](https://arxiv.org/pdf/2412.09587), [HTML](https://arxiv.org/abs/2412.09587)
### Authors
Chester Palen-Michel,Maxwell Pickering,Maya Kruse,Jonne Sälevä,Constantine Lignos
### Background
目前，存在多种命名实体识别（NER）的数据集，但这些数据集尚未标准化，格式各异，语言覆盖面也不够广泛。研究者在进行多语言或跨多种知识图谱实体类型的多事件命名实体识别研究时面临困难。
### Innovation
本研究提出了OpenNER 1.0，这是一个标准化的多语言命名实体识别数据集集合，包含36个覆盖52种语言的NER语料库，这些语料库是通过人工标注的，并整合了不同的实体类型框架。本研究统一了原始数据集格式，纠正了标注格式问题，并在保持实体类型名称一致性的情况下标准化数据集。此外，研究还提供了使用预训练多语言和大型语言模型的基准结果，以评估这些模型在命名实体识别任务中的表现。
### Conclusion
本研究解决了多语言和多实体类型命名实体识别数据集的标准化问题，为未来相关领域的研究提供了坚实的基础。研究结果表明，没有一种模型适用于所有语言，进一步提高语言模型在命名实体识别任务中的性能仍有显著空间。
## 240. `cs.CL` - 具有传染性脱逃功能的捣乱者在良善之镇制造混乱 [PDF](https://arxiv.org/pdf/2410.16155), [HTML](https://arxiv.org/abs/2410.16155)
### Authors
Tianyi Men,Pengfei Cao,Zhuoran Jin,Yubo Chen,Kang Liu,Jun Zhao
### Background
随着大规模语言模型的发展，它们被广泛用作各种领域的代理。代理的关键组件是记忆，它存储关键信息但易受关押攻击。现有研究主要集中在单个代理攻击和共享记忆攻击上，而现实情况常常涉及独立记忆。因此，有必要提出一个考虑独立记忆攻击的情况下的多代理、多层次的文本攻击评估框架。论文提出了Troublemaker Makes Chaos in Honest Town (TMCHT) 任务，强调多代理攻击中的两个主要挑战：不完全图结构和大型系统，并提出了对抗复制传染性关押攻击（ARCJ）方法来应对这些挑战，优于现有方法，特别是在线性拓扑、星形拓扑和100个代理设置中表现更好，提高分别达23.51%、18.95%和52.93%。这一工作鼓励社区关注多代理系统的安全问题，
### Innovation
提出了Troublemaker Makes Chaos in Honest Town (TMCHT)任务，这是一个大规模、多代理、多拓扑的文本攻击评估框架。针对多代理攻击中的挑战（不完全图结构和大型系统），提出了Adversarial Replication Contagious Jailbreak (ARCJ)方法。此方法优化检索后缀以使中毒样本更容易被检索，优化复制后缀以使中毒样本具有传染性，显著优于现有方法在不同拓扑结构下的表现。
### Conclusion
该论文提出了一个多代理攻击的评估框架和一种新的针对这种攻击的方法，验证了该方法在不同场景下的有效性，并强调了多代理系统安全性的重要性。
## 241. `cs.CL` - 基于迭代效用最大化学习为多个检索增强模型排名 [PDF](https://arxiv.org/pdf/2410.09942), [HTML](https://arxiv.org/abs/2410.09942)
### Authors
Alireza Salemi,Hamed Zamani
### Background
本文探讨了一个统一的搜索引擎设计，该搜索引擎为多个各有不同任务、支柱大语言模型（LLM）和检索增强生成（RAG）策略的检索增强生成（RAG）代理提供服务。研究基于Knowledge-Intensive Language Tasks (KILT)基准数据集进行了实验，结果表明我们的方法在18个RAG模型上平均显著优于基线方法。
### Innovation
引入了一种迭代的方法，搜索引擎为RAG代理生成检索结果并在离线阶段收集反馈以优化搜索引擎的表现，使用期望最大化算法迭代优化搜索引擎，提高每个代理的效用函数。此外，将此方法扩展到在线环境，使搜索引擎能够根据实时的个体代理反馈进行自我调整，以更好地服务于每个代理的需求。通过综合消融研究，作者探讨了该方法的不同方面，进一步验证了该方法的有效性。
### Conclusion
本文提出的方法显著提高了多个RAG代理的检索结果质量，通过反馈驱动的迭代方式优化了搜索引擎，特别是在KILT基准上的表现优于基线模型，实现了对每个RAG代理的个性化检索。
## 242. `cs.CL` - 大型语言模型是否支持推断主义？ [PDF](https://arxiv.org/pdf/2412.14501), [HTML](https://arxiv.org/abs/2412.14501)
### Authors
Yuzuki Arai,Sho Tsugawa
### Background
文章背景在于大型语言模型（LLMs）如ChatGPT和Claude的出现引发了语言哲学的新挑战，尤其是在语言的意义和表示方面。尽管这些模型传统上用分布语义学来理解，但本文采用罗伯特·布兰农的推断语义学作为理解这些系统的替代基础框架。分析表明，推断语义学的关键特征，如反表征主义立场、逻辑表达主义和半组合性方法，与基于转换器的LLMs的架构和功能特性一致。通过对推理、替换和消解（ISA）方法的分析，表明这些模型在其语言处理中表现出反表征主义的特性。进一步发展了一种适合LLMs的共识真理论，该理论基于它们的互动性和规范性维度，借助如RLHF的机制。
### Innovation
创新在于采用推断语义学作为理解和分析大型语言模型的基础框架，分析了推断语义学的关键特征与大型语言模型的具体架构和功能特性的契合之处，并提出了适合大型语言模型的共识真理论。通过分析ISA方法，指出大型语言模型在语言处理中的反表征主义性质，并进一步发展了一种基于其互动性和规范性的共识真理论，这一理论可能挑战传统语言哲学中的严格组合性和语义外部主义假设。
### Conclusion
文章提出的推断主义可能为理解大型语言模型如何生成意义而不依赖于外部世界的表示提供有价值的见解。然而，也揭示了推理主义的哲学承诺与大型语言模型的亚符号处理之间的显著紧张关系。未来还需要进一步的实证研究来充分证明这些理论假设。
## 243. `cs.CL` - 使用音素进行提示：增强多语言大语言模型在非拉丁字母语言中的表现 [PDF](https://arxiv.org/pdf/2411.02398), [HTML](https://arxiv.org/abs/2411.02398)
### Authors
Hoang H Nguyen,Khyati Mahajan,Vikas Yadav,Julian Salazar,Philip S. Yu,Masoud Hashemi,Rishabh Maheshwary
### Background
尽管多语言大语言模型（LLM）在各种基准测试中取得了显著的成绩，但它们在非拉丁字母语言上仍然表现不佳。这种差距源于大语言模型在预训练过程中使用了以拉丁字符为主的书写系统，这遮蔽了它们与非拉丁字母语言之间的音素共享。现有研究表明，通过利用音素转录作为补充信号，可以诱导出不依赖于特定书写的表示方法，从而提升跨语言的表现。本研究通过详细的实验验证了音素信号的整合可以改善非拉丁字母语言和拉丁字母语言的表现，尤其在缩小两类语言性能差距方面表现出显著的效果。实验还表明，音素和书写系统的检索为上下文学习（ICL）提取了不同的示例，这促使我们提出了混合的ICL检索策略，该策略结合了两种方法的长处，显著提升了两种语言类型的性能，分别达到了12.6%和15.1%的提升。
### Innovation
本文提出通过利用音素转录作为补充信号来改善大语言模型在非拉丁字母语言上的表现。通过详细的实验，证明了音素信号的整合可以改善跨语言的表现，尤其是在缩小拉丁字母和非拉丁字母语言性能差距方面表现出显著效果。此外，本研究提出了一种混合的上下文学习（ICL）检索策略，通过结合音素和书写系统的长处，显著提升了两种语言类型的性能。
### Conclusion
通过详细实验，本研究验证了音素信号的整合可以显著改善多语言大语言模型在非拉丁字母语言和拉丁字母语言的表现，特别是对缩小两类语言的性能差距有显著效果。同时，提出了混合的ICL检索策略，进一步增强了其在不同语言上的整体性能。
## 244. `cs.CL` - 奖励导向的推测性解码以用于高效的LLM推理 [PDF](https://arxiv.org/pdf/2501.19324), [HTML](https://arxiv.org/abs/2501.19324)
### Authors
Baohao Liao,Yuhui Xu,Hanze Dong,Junnan Li,Christof Monz,Silvio Savarese,Doyen Sahoo,Caiming Xiong
### Background
现有的推测性解码方法通常要求模型生成完全无偏的输出，这限制了它们在资源密集型场景中的效率。本文提出了一种名为RSD（奖励导向的推测性解码）的新型框架，旨在通过结合轻量级的草案模型和更强大的目标模型来提高大型语言模型（LLMs）的推理效率。RSD通过引入可控的偏差来优先生成高奖励输出，从而在降低成本与提高输出质量之间达到更好的平衡。
### Innovation
RSD框架通过使用一个过程奖励模型来评估解码步骤并动态决定是否调用目标模型，实现了在计算成本和输出质量之间的优化平衡。与完全使用目标模型进行解码的现有方法相比，RSD可以实现高达4.4倍的浮点运算次数（FLOPs）节省，同时在平均准确度上高出3.5%。这表明RSD是一种在资源密集型场景中部署LLMs的稳健且成本效益高的方法。
### Conclusion
实验结果表明，基于阈值的混合策略能够在资源利用率和性能之间达到最佳平衡。RSD通过结合轻量级模型和强大的目标模型，实现了在效能和成本方面的显著提升。
## 245. `cs.CL` - 在语言模型训练中添加或删除个人信息引起的隐私涟漪效应 [PDF](https://arxiv.org/pdf/2502.15680), [HTML](https://arxiv.org/abs/2502.15680)
### Authors
Jaydeep Borkar,Matthew Jagielski,Katherine Lee,Niloofar Mireshghallah,David A. Smith,Christopher A. Choquette-Choo
### Background
由于个人信息（PII）的敏感性质，其所有者有权控制其在大型语言模型（LLM）训练中的包含或请求其移除。此外，PII 可能会由于不断发展的数据集编目技术、重新抓取用于重新训练或包含在新的下游微调阶段等原因被添加或移除。研究发现，PII 的记忆量及其易于性是一个动态属性，它在训练管道中不断发展，并取决于常见的设计选择。研究进一步描述了三个新颖现象：1) 训练后期出现的类似 PII 可以引发较早出现的序列的记忆，我们称之为辅助记忆，这是一个重要因素（在我们的设置中，高达三分之一）；2) 添加 PII 可以显著增加其他 PII 的记忆量（在我们的设置中，最高可达约7.5倍）；3) 移除 PII 可能会导致其他 PII 被记忆。因此，模型创建者在训练模型时应考虑这些第一和第二阶隐私风险，以避免新PII的重新出现风险。
### Innovation
研究发现了三个新颖的现象：1) 辅助记忆；2) 添加 PII 对其他 PII 记忆量的影响；3) 移除 PII 后的后续记忆效应。这些现象揭示了数据源的变化对模型记忆 PII 的更多动态影响。
### Conclusion
模型创建者必须在训练模型时考虑这些第一和第二阶隐私风险，以避免新 PII 的重新出现，确保个人信息保护不受损害。
## 246. `cs.CL` - CodeLutra: 通过偏好引导改进的LLM代码生成 [PDF](https://arxiv.org/pdf/2411.05199), [HTML](https://arxiv.org/abs/2411.05199)
### Authors
Leitian Tao,Xiang Chen,Tong Yu,Tung Mai,Ryan Rossi,Yixuan Li,Saayan Mitra
### Background
大规模语言模型（LLMs）已经彻底改变了代码生成，但其需要大量资源并常常过度泛化，限制了其在特定任务上的效率。微调较小的、开源的LLMs提供了一种成本效益更高的替代方案。然而，标准的监督方法仅依赖正确示例，忽略了错误示例中的宝贵见解。
### Innovation
CodeLutra框架利用了正确和错误的代码尝试。它使用迭代的偏好引导细化，将成功和失败的输出进行比较，以更好地逼近所需结果。这种方法在不需要大规模数据集或辅助模型的情况下，缩小了与最先进的更大模型之间的性能差距。例如，在一项具有挑战性的数据科学编码任务上，使用500个样本提高了Llama-3-8B的准确性，从28.2%提高到48.6%，接近GPT-4的水平。通过从成功和错误中学习，CodeLutra提供了一种可扩展和高效的高质量代码生成路径，使较小的开源模型在与领先封闭源模型的竞争力方面更占优势。
### Conclusion
通过从成功和错误中学习，CodeLutra提供了一种可扩展和高效的高质量代码生成路径，使较小的开源模型在与领先封闭源模型的竞争力方面更占优势。
## 247. `cs.CL` - Thinkless: LLM Learns When to Think [PDF](https://arxiv.org/pdf/2505.13379), [HTML](https://arxiv.org/abs/2505.13379)
### Authors
Gongfan Fang,Xinyin Ma,Xinchao Wang
### Background
生成语言模型具备扩展链式推理能力，在复杂逻辑推断任务上表现出卓越性能。然而，对所有查询都进行繁琐的推理会导致显著的计算效率问题，特别是当很多问题可以有直接解决方案时。当前研究关注于生成语言模型是否能够学习何时进行推理思考。
### Innovation
提出了Thinkless框架，这是一种可学习的框架，使LLM能够基于任务复杂度和模型能力自适应选择简短或详细的推理形式，并采用分解群体相对策略优化（DeGRPO）算法来分解混合推理的学习目标，分别优化不同推理模式的选择和准确回答的目标，从而提高训练的稳定性和效率，解决了传统方法中的崩溃问题。
### Conclusion
在Minerva Algebra、MATH-500和GSM8K等基准上，Thinkless能够将长链推理使用量降低50%-90%，显著提高了推理语言模型的效率。
## 248. `cs.CL` - 使用SMILE提升大型语言模型的可解释性：基于局部解释的统计模型无关可解释性方法 [PDF](https://arxiv.org/pdf/2505.21657), [HTML](https://arxiv.org/abs/2505.21657)
### Authors
Zeinab Dehghani,Mohammed Naveed Akram,Koorosh Aslansefat,Adil Khan
### Background
像GPT、LLAMA和Claude这样的大型语言模型在生成文本方面变得极其强大，但它们仍然是黑盒模型，无法理解它们是如何做出决策的。这种透明度的缺乏在需要信任和问责的领域是一个问题。为了解决这个问题，我们引入了SMILE，一种能够解释模型在不同提示部分响应的新方法。SMILE不依赖于特定模型，并通过微调输入、测量输出变化，并突出显示哪些词影响最大，从而创建简单的视觉热图来展示提示中哪些部分最重要。我们对几种领先的大型语言模型进行了测试，并使用准确度、一致性、稳定性和保真度等指标，证明了SMILE能够提供清晰可靠的解释。
### Innovation
SMILE是一种不依赖于特定模型的新方法，通过微调输入、测量输出变化并突出显示哪些词影响最大，来解释大型语言模型如何响应不同提示部分。这种方法创建了简单的视觉热图，展示提示中哪些部分最重要。通过增强对这些模型的理解，SMILE使我们更接近于使AI更加透明和值得信赖。
### Conclusion
SMILE为大型语言模型提供了清晰和可靠的解释，有助于增强模型的透明度和信任度，促进了这些模型在实际应用中的使用。
## 249. `cs.CL` - LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey [PDF](https://arxiv.org/pdf/2505.00753), [HTML](https://arxiv.org/abs/2505.00753)
### Authors
Henry Peng Zou,Wei-Chieh Huang,Yaozu Wu,Yankai Chen,Chunyu Miao,Hoang Nguyen,Yue Zhou,Weizhi Zhang,Liancheng Fang,Langzhou He,Yangning Li,Dongyuan Li,Renhe Jiang,Xue Liu,Philip S. Yu
### Background
近年来大型语言模型（LLMs）的发展激发了构建完全自主代理的兴趣，但在实际应用中，基于LLMs的完全自主代理仍然面临重大挑战，包括因幻觉导致的可靠性限制、难以处理复杂任务、以及重大的安全和伦理风险，这些都限制了其在实际应用中的可行性与可信度。为此，基于LLM的人机协作系统（LLM-HASs）将人类提供的信息、反馈或控制集成到代理系统中，以增强系统的性能、可靠性和安全性。通过利用人类与LLM代理的互补优势，这些系统可实现有效的人机协作。本文对LLM-HASs进行了首次全面、结构化的综述，旨在通过汇总现有知识并提供概括性概述，促进该快速发展的跨学科领域中的进一步研究和创新。
### Innovation
文章通过首次全面和结构化的综述，涵盖了LLM-HASs的基本概念、核心组成、人机协作的形式、协调与通信等方面，提出了这个领域中的新兴应用，并探讨了人机协作所带来的独特挑战与机遇。
### Conclusion
通过汇聚现有的知识，并提供了一个结构化概述，本文旨在促进这个快速发展的跨学科领域中的进一步研究与创新。相关列表和资源可以在提供的链接中找到。
## 250. `cs.CL` - A3: 一种用于注意力机制的解析性低秩近似框架 [PDF](https://arxiv.org/pdf/2505.12942), [HTML](https://arxiv.org/abs/2505.12942)
### Authors
Jeffrey T. H. Wong,Cheng Zhang,Xinye Cao,Pedro Gimenes,George A. Constantinides,Wayne Luk,Yiren Zhao
### Background
大模型展示了出色的性能，但它们庞大的参数数量使得部署成本高昂。低秩逼近提供了一个有前景的压缩解决方案，但现有方法存在两大限制：（1）它们专注于最小化个别线性层的输出误差，而不考虑Transformer架构特征；（2）它们将一大权重矩阵分解为两个小型低秩矩阵。因此，这些方法往往不如剪枝和量化等其他压缩技术高效，并且会引入运行时开销，如为分解的矩阵增加额外的GEMM内核启动。
### Innovation
提出了一种名为A3的后训练低秩逼近框架，它将Transformer层划分为QK、OV和MLP三个功能组件，并为每个组件提供解析解决方案，同时减少隐藏层的大小，最小化特征损失。这种方法直接减少了模型大小、KV缓存大小和FLOPs，而无需引入任何运行时开销。此外，它还提供了一个新的视角，从单一线性层损失优化转向优化端到端性能。我们通过大量的实验展示了A3维护了优越的性能，如在计算和内存预算相同的条件下，A3的低秩逼近的LLaMA 3.1-70B在WikiText-2上的困惑度为4.69，优于以前的SOTA的7.87。我们还展示了A3的多用途性，包括KV缓存压缩、量化和混合秩分配以增强性能。
### Conclusion
通过广泛的实验，我们表明A3在计算和内存预算相同的情况下，保持了优于SOTA的性能。例如，A3的低秩逼近的LLaMA 3.1-70B在WikiText-2上的困惑度为4.69，优于以前的SOTA的7.87。此外，A3还展示了其在KV缓存压缩、量化和混合秩分配方面的多功能性，并通过改进性能增强了其效果。
## 251. `cs.CL` - 思考期间搜索和精炼：LLM的自主检索增强推理 [PDF](https://arxiv.org/pdf/2505.11277), [HTML](https://arxiv.org/abs/2505.11277)
### Authors
Yaorui Shi,Sihang Li,Chang Wu,Zhiyuan Liu,Junfeng Fang,Hengxing Cai,An Zhang,Xiang Wang
### Background
大型语言模型展示了令人印象深刻的能力，但它们本身受知识库的限制。检索增强推理通过使LLMs能够查询外部资源来缓解这一限制，但现有方法常常检索到无关或噪音信息，影响准确推理。
### Innovation
本文提出了一种名为AutoRefine的新框架，采用了一种新的‘思考期间搜索和精炼’思路。AutoRefine在连续搜索之间引入了明确的知识精炼步骤，使模型能够迭代地过滤、提炼和组织证据，以生成答案。此外，还结合使用了针对检索的奖励和答案正确性的奖励，利用组相对策略优化。实验表明，AutoRefine在单跳和多跳问答基准测试中显著优于现有方法，特别是在复杂的多跳推理场景中表现尤为突出。详细分析显示AutoRefine会频繁进行高质量的搜索并有效地综合证据内容。
### Conclusion
实验结果表明，AutoRefine在单跳和多跳问答基准测试中显著优于现有方法，特别是在复杂的多跳推理场景中表现尤为突出。
## 252. `cs.CL` - 通过信息几何和量子度量重新思考大型语言模型训练 [PDF](https://arxiv.org/pdf/2506.15830), [HTML](https://arxiv.org/abs/2506.15830)
### Authors
Riccardo Di Sipio
### Background
大型语言模型的优化在高维参数空间中进行，且具有非欧几里得结构。信息几何使用费希尔信息度量框架来描绘这一景观，通过自然界梯度下降促进更规范的学习。尽管这种几何视角在实践中往往不切实际，但它阐明了许多现象，如尖锐极值、泛化和观察到的缩放规律。
### Innovation
本文提出将曲率意识方法应用于理解大型语言模型的训练，进一步加深了这一领域的理解。同时，基于Fubini-Study度量和量子费希尔信息探讨了量子类比，暗示了在量子增强系统中高效优化的可能性。
### Conclusion
最终，论文推测表明，通过信息几何和量子度量可以对大型语言模型训练进行更深层次的理解，并提出了量子系统中高效优化的可能途径。
## 253. `cs.CL` - 评估大型语言模型在肺栓塞登记中的自动化临床提取性能：在模型大小、版本和参数方面的表现 [PDF](https://arxiv.org/pdf/2503.21004), [HTML](https://arxiv.org/abs/2503.21004)
### Authors
Mahmoud Alwakeel,Emory Buck,Jonathan G. Martin,Imran Aslam,Sudarshan Rajagopal,Jian Pei,Mihai V. Podgoreanu,Christopher J. Lindsell,An-Kwok Ian Wong
### Background
肺栓塞（PE）登记加速了实践改进的研究，但依赖于劳动密集型的手动从影像学报告中抽象信息。目前研究探讨了是否可以使用公开可用的大型语言模型（LLMs）自动从CTPE报告中提取概念，而不损失数据质量。测试了四种Llama 3变体和一个审查者模型Phi 4 14B，测试数据来自于MIMIC IV和杜克大学的250份双标注CTPE报告。
### Innovation
研究采用大型语言模型自动化从CTPE报告中提取概念，提高了肺栓塞登记的效率和准确性，同时保持了数据质量。测试了不同规模和版本的大型语言模型，并评估了其在不同温度和抽样数量下的性能。结果显示，大规模模型的准确性显著提高，双模型审查工作流可以保障高质量的数据结果，同时减少人工监督所需的人力资源。这种技术为肺栓塞注册提供了可扩展、准确的解决方案。
### Conclusion
大型语言模型适用于肺栓塞登记中的自动化临床提取，并且双模型审查工作流可以确保数据质量，仅需少量人类监督。这种技术可以为提高该领域的研究效率和准确性提供有力支持。
## 254. `cs.CL` - TAPS：基于结构化标签的工具增强个性化 [PDF](https://arxiv.org/pdf/2506.20409), [HTML](https://arxiv.org/abs/2506.20409)
### Authors
Ekaterina Taktasheva,Jeff Dalton
### Background
近期，工具增强的大规模语言模型的发展使其能够与外部工具互动，从而提高了它们执行复杂用户任务的能力。然而，当前的方法忽视了个性化在指导工具使用中的作用。研究发现，大规模语言模型在个性化工具使用方面存在关键弱点。为了解决这些问题，本文探讨了如何有效将用户偏好整合到目标导向的对话代理中，提出了TAPS，一种通过利用结构化标签工具和基于不确定性工具检测器增强个性化工具使用的新颖解决方案，显著提高了大规模语言模型纳入用户偏好能力，实现了开源模型在NLSI任务上的新最佳水平。
### Innovation
引入了TAPS，通过利用结构化标签工具和基于不确定性工具检测器，增强个性化工具使用，显著提高了大规模语言模型纳入用户偏好能力，实现了开源模型在NLSI任务上的新最佳水平。
### Conclusion
研究发现，大规模语言模型在个性化工具使用方面存在关键弱点，并提出了TAPS作为解决方案，该方法显著提高了模型的个性化工具使用能力，实现了行业新突破。
## 255. `cs.CL` - CVC：一种用于大规模语言模型价值对齐的中文价值规则语料库 [PDF](https://arxiv.org/pdf/2506.01495), [HTML](https://arxiv.org/abs/2506.01495)
### Authors
Ping Wu,Guobin Shen,Dongcheng Zhao,Yuwei Wang,Yiting Dong,Yu Shi,Enmeng Lu,Feifei Zhao,Yi Zeng
### Background
确保大型语言模型（LLMs）与主流人类价值观和伦理规范保持一致，是保证人工智能安全和可持续发展的关键。当前的价值评估和对齐受到西方文化偏见和不完整的基于外来规则的国内框架的限制，且缺乏可扩展的基于规则的场景生成方法，使得评估在多文化背景下成本高昂且不充分。
### Innovation
本文提出了一种基于核心中国价值观的分层价值框架，涵盖三大维度、12个核心价值观和50个衍生价值观。基于该框架构建了一个包含超过250,000条增强扩展的人工标注价值规则的大规模中文价值观语料库（CVC）。实验结果表明，由CVC指导生成的场景在价值边界和内容多样性方面优于直接生成的场景。我们还构建了400,000个基于规则的道德困境情景，客观反映了17个LLM之间的冲突价值优先级上的细微差异。这份工作建立了一个文化适应性的基准框架，用于全面的价值评估和对齐，体现了中国特征。
### Conclusion
所有数据可在 https://[链接] 获取，并且代码可在 https://[链接] 获取。
## 256. `cs.CL` - 使用软注意力模拟硬注意力 [PDF](https://arxiv.org/pdf/2412.09925), [HTML](https://arxiv.org/abs/2412.09925)
### Authors
Andy Yang,Lena Strobl,David Chiang,Dana Angluin
### Background
本文研究了使用软注意力的变压器在哪些条件下可以模拟硬注意力，即有效聚焦于一部分位置。研究首先考察了几类硬注意力变压器认可的语言，这些语言可以由线性时序逻辑的变体定义。通过使用无界位置嵌入或温度缩放，说明了软注意力变压器如何计算这些逻辑的公式。接着，展示了温度缩放如何允许softmax变压器模拟一般的硬注意力变压器，使用的温度取决于最大注意力分数与其他分数之间的最小差距。
### Innovation
本文提出了通过无界位置嵌入或温度缩放，使用软注意力变压器来计算线性时序逻辑公式的方法，并展示了如何通过温度缩放让softmax变压器模拟硬注意力变压器。这些方法为理解注意力机制的模拟提供了新的视角。
### Conclusion
本文证明了软注意力机制在适当条件下可以模拟硬注意力机制的具体方法，并展示了这种方法在语言识别等任务中的应用潜力。
## 257. `cs.CL` - 在症状检查器中评估罕见疾病诊断性能：合成病例模拟方法 [PDF](https://arxiv.org/pdf/2506.19750), [HTML](https://arxiv.org/abs/2506.19750)
### Authors
Takashi Nishibayashi,Seiji Kanazawa,Kumpei Yamada
### Background
症状检查器（SCs）提供定制化的医疗信息。在更新算法时，保持个体疾病尤其是罕见疾病预期的诊断性能是一个关键性的挑战。这一挑战源于缺乏有效的预部署评估方法。对于罕见疾病，获取足够的用户反馈数据用作评估较为困难。为解决这个问题，该研究提出并验证了一种新的合成病例模拟方法，以评估算法更新前部署在个体罕见疾病上的诊断性能影响。这种方法旨在高效且低成本地进行评估。研究采用了人类表型组织（HPO）中的疾病表型注释生成合成病例，并模拟症状检查器的面试过程以预测性能变化。
### Innovation
该研究提出了一种新的合成病例模拟方法，用于在更新算法前评估症状检查器中罕见疾病的诊断性能变化。这种方法通过使用人类表型组织（HPO）中的疾病表型注释生成合成病例，并模拟症状检查器的面试过程来预测性能变化。验证方法的有效性是通过回顾性比较预测变化与实际性能指标来完成的，使用 $R^2$ 相关系数进行评估。结果显示，对于有表型频率信息的疾病，该方法能够准确预测性能变化。
### Conclusion
该研究提出的方法能够预部署评估症状检查器中的算法变化对罕见疾病的诊断性能影响。这种方法基于专家创建的公开可用的医学知识数据库，确保了利益方的透明性和可解释性。此外，症状检查器开发者可以通过这种方法高效低成本地提高诊断性能。
## 258. `cs.CL` - SACL: 使用语义增强重排和定位来理解和对抗代码检索中的文本偏差 [PDF](https://arxiv.org/pdf/2506.20081), [HTML](https://arxiv.org/abs/2506.20081)
### Authors
Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie
### Background
检索增强代码生成（RACG）是通过检索相关信息来提升代码生成的关键技术。现有的代码检索方法通常依赖于表面级别的文本特征（如文档字符串，标识符名称）进行检索，并且倾向于已经文档化良好的代码，即使这些文档与代码无关。因此，这些方法可能在处理代码生成任务时表现不佳，需要改进代码检索的准确性和全面性。
### Innovation
本文提出了一种名为SACL的新框架，该框架通过增强文本信息并减少偏差，将语义信息与代码或结构知识相结合，以改善代码检索。实验表明，与现有方法相比，SACL在多个评估基准上显著提升了代码检索的表现（如，在HumanEval、MBPP和SWE-Bench-Lite上的召回率分别提高了12.8%、9.4%和7.0%），同时提高了代码生成的性能（如，在HumanEval上的通过率提高了4.88%）。
### Conclusion
研究发现，尽管现有代码检索器以代码为训练对象，但它们在很大程度上依赖于表面级的文本特征，并且具有偏向已良好文档化的代码的倾向。SACL框架通过添加语义信息，增强了代码检索的文本信息，减少了对已文档化良好的代码的偏见，从而在多个基准上取得了显著的性能提升。
## 259. `cs.CL` - DiffuCoder：理解并改进掩码扩散模型在代码生成中的应用 [PDF](https://arxiv.org/pdf/2506.20639), [HTML](https://arxiv.org/abs/2506.20639)
### Authors
Shansan Gong,Ruixiang Zhang,Huangjie Zheng,Jiatao Gu,Navdeep Jaitly,Lingpeng Kong,Yizhe Zhang
### Background
扩散大语言模型（dLLMs）因其全局规划和迭代优化的特点，在代码生成方面有显著优势。然而，当前dLLMs在代码中的训练和推理机制仍待深入探索。本研究旨在通过系统性地探讨dLLMs的去噪过程和强化学习方法，以揭示其解码行为，并解锁其在代码生成中的潜力。研究者使用一个名为DiffuCoder的7B参数dLLM模型，训练数据量达到130亿代码令牌，以此来分析其解码行为，并发现它与自回归（AR）模型的主要区别在于：dLLMs可以决定生成的因果性程度，并且增加采样温度不仅会使token选择多样化，还会改变其生成顺序。这种多样性为RL轨迹提供了丰富的搜索空间。为了提高token对数似然估计的稳定性并维持训练效率，研究者提出了一种新颖的采样方案coupled-GRPO，该方法用于在训练期间构造对比性掩码噪声。实验结果显示，coupled-GRPO显著提高了DiffuCoder在代码生成基准测试上的性能（EvalPlus上提高了4.4%），并降低了在解码过程中对AR偏见的依赖。
### Innovation
提出了一种新颖的采样方法coupled-GRPO，该方法通过在训练过程中构造对比性掩码噪声来提高token对数似然估计的稳定性，维持训练效率，并显著提升代码生成性能。此外，研究还揭示了dLLMs与AR模型在解码行为上的差异，特别是在生成过程中的因果性控制和采样温度对生成多样性的影响方面。这为理解和优化dLLMs的代码生成过程提供了新的视角和发展路径。
### Conclusion
本研究通过深入了解dLLMs的机器运作和提出扩散原生的强化学习训练框架coupled-GRPO，为代码生成提供了一个更有效的解决方案。这一研究成果加深了对dLLMs生成机制的认识，并为未来的发展铺平了道路。
## 260. `cs.CL` - GroundCap: 一个视觉接地图像字幕数据集 [PDF](https://arxiv.org/pdf/2502.13898), [HTML](https://arxiv.org/abs/2502.13898)
### Authors
Daniel A. P. Oliveira,Lourenço Teodoro,David Martins de Matos
### Background
当前的图像字幕系统缺乏将描述性文本与具体的视觉元素关联的能力，导致输出难以验证。尽管最近的方法具备一定的接地能力，但无法跨多个引用跟踪对象身份或同时链接动作和对象。
### Innovation
提出了一种新型ID基的接地系统，能够实现一致的对象参考跟踪和动作-对象链接。该系统包括持久的对象ID以实现参考跟踪、明确的动作-对象链接以及通过K-means聚类分离背景元素。提出了gMETEOR指标，结合了字幕质量和接地准确度，通过Fine-tuning Pixtral-12B和Qwen2.5-VL 7B实现了基线性能。
### Conclusion
人类评估表明，该方法在产生可验证描述并具有连贯的对象引用方面非常有效。
## 261. `cs.CL` - PP-DocBee: 通过多种技巧提高多模态文档理解 [PDF](https://arxiv.org/pdf/2503.04065), [HTML](https://arxiv.org/abs/2503.04065)
### Authors
Feng Ni,Kui Huang,Yao Lu,Wenyu Lv,Guanzhong Wang,Zeyu Chen,Yi Liu
### Background
随着数字化的迅速发展，各种文档图像在生产和日常生活中被广泛应用，因此对文档图像内容的快速准确解析需求日益迫切。这促使研究人员开发出PP-DocBee，一种针对文档理解的新型多模态大型语言模型，用于端到端的文档图像理解任务。为提高模型的泛化能力，作者开发了一种针对文档场景的数据合成策略，构建了多样化的数据集。此外，还采用了动态比例采样、数据预处理和OCR后处理策略等训练技术。实验结果表明，PP-DocBee在英文文档理解和中文文档理解方面均表现出优越的性能，甚至超越了现有的开源和商用模型。
### Innovation
PP-DocBee 是一种针对文档理解的新型多模态大型语言模型。其创新之处在于开发了一种适用于文档场景的数据合成策略，构建了多样化数据集以提高模型的泛化能力，并采用了动态比例采样、数据预处理和OCR后处理策略等训练技术。实验结果表明，该模型在多项基准测试中取得了最先进的结果，特别是在中文文档理解方面表现突出，甚至优于现有的开源和商用模型。
### Conclusion
PP-DocBee 在多个文档理解基准测试中取得了卓越的性能，展示了其作为先进多模态大型语言模型的强大能力。源代码和预训练模型已公开发布，为这一领域的研究提供了有价值的参考。
## 262. `cs.CL` - 从网络搜索到具备推理能力的深层研究：用推理代理激励搜索 [PDF](https://arxiv.org/pdf/2506.18959), [HTML](https://arxiv.org/abs/2506.18959)
### Authors
Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu
### Background
信息检索是现代知识获取的基石，每天能够处理数十亿次跨领域查询。然而，传统的基于关键词的搜索引擎对于处理复杂的、多步骤的信息需求越来越不适用。研究表明，通过增强的推理和行动能力，大型语言模型（LLMs）正在推动一股新潮流，称为具备自主性的深层研究（Agentic Deep Research）。这类系统通过对查询的自动推理、迭代检索和信息综合进行整合，形成了一个动态的反馈循环，超越了传统的信息检索方法。从静态的网页搜索过渡到交互式的、基于代理的系统，在这些系统中，可以进行规划、探索和学习。
### Innovation
这类具备行动能力和自动推理能力的系统构建了一种新的信息检索范式，称为具备自主性的深层研究。它不仅催生了一种新型的反馈循环机制，还通过紧耦合的自动推理、迭代检索和信息综合，实现了更加精准和动态的信息检索过程。此外，还引入了一种测试阶段的扩展法则，用于正式化计算深度对推理和搜索的影响。基于基准结果和开源实现的推动，具备自主性的深层研究不仅远远超越了现有的方法，还预示着未来信息检索的主导范式。
### Conclusion
具备自主性的深层研究不仅显著优于现有的方法，还预示着未来信息检索的主导范式。相关的行业产品、研究论文、基准数据集和开源实现都在此集中提供给社区，供参考和借鉴。
## 263. `cs.CV` - OTSurv：具有异质性最优传输的新型生存预测多重实例学习框架 [PDF](https://arxiv.org/pdf/2506.20741), [HTML](https://arxiv.org/abs/2506.20741)
### Authors
Qin Ren,Yifan Wang,Ruogu Fang,Haibin Ling,Chenyu You
### Background
生存预测可以被建模为多重实例学习（MIL）问题，然而现有的MIL方法常常未能明确捕捉全视野切片图像（WSIs）中的病理异质性，包括全局的长尾形态分布和局部的切片级预测不确定性。当前解决方法存在不足，无法有效地处理这些异质性问题。因此，需要一种新的方法来更好地处理并利用WSIs中的差异，提高生存预测的准确性。
### Innovation
提出了一种基于最优传输（OT）视角的新型MIL框架——OTSurv。OTSurv通过引入两个约束，即全局长尾约束和局部不确定性约束，来解决WSIs中的异质性问题。全局长尾约束用于建模先验形态分布，避免单一模式坍塌和过度均匀性；局部不确定性约束则通过逐步增加总的传输质量，优先选择高置信度的切片并抑制噪声。此外，OTSurv将初始的OT问题转化为一种非平衡的OT表示，可以通过高效的矩阵标度算法进行求解。OTSurv在六个流行的基准测试中取得了新的最佳结果，并在Log-rank检验中表现出统计显著性，提供了高可解释性，是数字病理学中生存预测的强大工具。
### Conclusion
OTSurv方法在处理WSIs中的异质性方面表现出色，能够提高生存预测的准确性，并在多个基准测试中达到了新的最佳性能。该方法通过引入约束条件并将问题转化为非平衡OT形式，增加了对复杂形态分布的建模能力和处理能力，提高了预测的可解释性，是数字病理学中一种强大的工具。
## 264. `cs.CL` - HERMES：具有事件和语义的时间相关长格式理解 [PDF](https://arxiv.org/pdf/2408.17443), [HTML](https://arxiv.org/abs/2408.17443)
### Authors
Gueter Josmy Faure,Jia-Fong Yeh,Min-Hung Chen,Hung-Ting Su,Shang-Hong Lai,Winston H. Hsu
### Background
长格式视频理解面临独特的挑战，超越了传统的短格式视频分析方法，尤其是在捕捉长距离依赖关系、高效处理冗余信息和提取高层次语义概念方面。为解决这些挑战，我们提出了一种新颖的方法，更准确地反映人类认知。本文介绍了一种名为HERMES的方法，它包含两个功能强大的模块，可以增强现有的视频-语言模型或作为一个独立系统运行。
### Innovation
HERMES引入了两个模块：Episodic COmpressor (ECO) 和 Semantics ReTRiever (SeTR)。ECO 有效地从微观到半宏观级别聚集表示，减轻计算负担同时保留时间依赖关系。SeTR 通过关注更广泛的情境丰富表示，大幅减少特征维度，同时保持相关宏观信息。HERMES的这两个模块可以无缝集成到现有的顶级模型中，提升了性能，减少了推理延迟达 43% 和内存使用量达 46%。作为独立系统，HERMES在多个长视频理解基准测试中实现了最先进的性能，无论是零样本还是全监督设置下都表现优异。
### Conclusion
HERMES展示了高效、准确的长视频理解能力，能够同时提升模型性能和降低资源消耗。作为独立系统，它在多个长视频理解任务上达到了最先进的水平。
## 265. `cs.CL` - 探索Big Five人格特质与AI能力在LLM模拟谈判对话中的影响 [PDF](https://arxiv.org/pdf/2506.15928), [HTML](https://arxiv.org/abs/2506.15928)
### Authors
Myke C. Cohen,Zhe Su,Hsien-Te Kao,Daniel Nguyen,Spencer Lynch,Maarten Sap,Svitlana Volkova
### Background
本文介绍了在关键任务谈判情境中评估代理AI系统的框架，针对能够适应不同人类操作员和利益相关者的AI代理的需求。通过使用Sotopia作为仿真测试平台，进行了两项实验，系统地评估了人格特质和AI代理特性如何影响语言模型（LLM）模拟的社会谈判结果，这对于涉及跨团队协调和民兵互动的各种应用程序至关重要。实验通过因果发现方法衡量了人格特质对价格讨价还价谈判的影响，发现友好性和外向性显著影响信念、目标实现和知识获取结果，并通过社会认知词汇量从团队通信中提取细微差别，检测到代理同理心沟通、道德基线和观点模式的差异，为必须在高风险操作场景中可靠运行的代理AI系统提供可操作的见解。实验二通过操纵模拟人类人格和AI系统特性，评估了人类-AI职业谈判，具体考察了透明性、能力和适应性如何影响AI代理的信任度，从这些发现中建立了一个针对各种操作员人格和人类-代理团队动态的实验性评估方法，直接支持可靠AI系统的操作需求。这项工作推进了代理AI流程的评估，超越了标准性能指标，将社会动态纳入其中，这对于复杂操作中的任务成功至关重要。
### Innovation
通过Sotopia构建了模拟测试平台；利用因果发现方法评估人格特质对谈判结果的影响；检测并量化了代理在社会认知方面的细微差异，如同理心沟通、道德基线和观点模式；考察了AI系统特性（如透明性、能力和适应性）如何影响其信任度和任务有效性；提出了一个新的可重复的评估方法，适用于不同操作员人格和人类-代理团队动态的实验研究，直接支持可靠AI系统的操作要求。这项工作通过引入社会动态超越了传统的性能评估指标，为复杂操作中的任务成功提供了更全面的评价框架。
### Conclusion
本研究为实验探索不同操作员人格和人类代理团队动力学下的代理AI系统的可靠性评估建立了重复的方法，直接支持关键任务环境中对某些应用的可靠AI系统操作要求。这项工作通过引入社会动态超越了传统的性能评价标准，在复杂操作中的任务成功方面提供了一个更全面的评估框架。
## 266. `cs.CV` - StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation [PDF](https://arxiv.org/pdf/2506.20756), [HTML](https://arxiv.org/abs/2506.20756)
### Authors
Haodong Li,Chen Wang,Jiahui Lei,Kostas Daniilidis,Lingjie Liu
### Background
最近的视频深度估计方法通过模仿图像深度估计的范式，即通常通过对大规模数据进行预训练视频扩散模型的微调，取得了巨大的性能。然而，作者认为视频深度估计并不是图像深度估计的简单扩展。视频中的动态和静止区域对时间一致性的要求本质上是不同的。通过跨帧的立体匹配可以在静止区域（例如背景）实现更有效的深度一致性，提供强烈的全局3D线索。对于动态区域，深度的连续性仍然需要从大规模的视频深度数据中学习以确保平滑过渡。
### Innovation
作者引入了StereoDiff，这是一种两级视频深度估计器，该系统结合了立体匹配（主要针对静态区域）和视频深度扩散（保持动态区域深度过渡的一致性）。StereoDiff通过频域分析证明了立体匹配和视频深度扩散的互补优势，突显了其在捕捉各自优点方面的协同效应。实验结果表明，StereoDiff在现有的零样本、真实世界、动态视频深度基准测试中具有优越的性能，其视频深度估计结果在一致性和准确性方面表现出色。
### Conclusion
实验结果证明了StereoDiff在零样本、真实世界动态视频深度基准测试中具有最先进的性能，以及其在视频深度估计中的优越一致性和准确性。
## 267. `cs.CV` - ConViTac: 使用对比表示进行视触融合对齐 [PDF](https://arxiv.org/pdf/2506.20757), [HTML](https://arxiv.org/abs/2506.20757)
### Authors
Zhiyuan Wu,Yongqiang Zhao,Shan Luo
### Background
视觉和触觉是机器人两个基本的感觉模态，提供了互补的信息，提升了感知和操作任务的效果。先前的研究试图联合学习视觉触觉表示以提取更丰富的信息，但这些方法常依赖直接组合方式如特征添加和拼接来进行模态融合，这往往导致特征整合效果不佳。
### Innovation
本文提出了ConViTac，一个通过对比表示技术提高融合过程中特征对齐的视觉-触觉表示学习网络。关键贡献在于引入了一个对比嵌入条件（CEC）机制，利用通过自我监督对比学习预训练的对比编码器将视觉和触觉输入投影到统一的潜在嵌入中。这些嵌入通过跨模态注意力用于联立的特征融合，以提升统一表示的对齐性并增强下游任务的性能。
### Conclusion
通过广泛实验展示了ConViTac在实际应用中优于当前最先进的方法，证明了提出的CEC机制的有效性，该机制在材料分类和抓取预测任务中的准确性提高了最多12.0%。
## 268. `cs.CV` - 利用视觉语言模型选择由扩散模型生成的可靠超分辨率样本 [PDF](https://arxiv.org/pdf/2506.20832), [HTML](https://arxiv.org/abs/2506.20832)
### Authors
Cansu Korkmaz,Ahmet Murat Tekalp,Zafer Dogan
### Background
超分辨率（SR）是一种病态的逆问题，具有许多与给定低分辨率图像一致的可能解。传统的方法试图在真实性与感知质量之间取得平衡，但这种方法往往会引入伪影，特别是在识别数字或字母等信息关键应用中增加了不确定性。另一方面，扩散模型能够生成多种SR图像，但选择其中最可信的解决方案仍然是一个挑战。本文基于视觉语言模型（VLMs）的语义推理能力，提出了一个自动的框架来从扩散模型生成的一组SR样本中识别出最可信的样本。
### Innovation
通过结合CLIP嵌入计算语义相似性，利用结构完整性（使用边缘图上的SSIM）和多级小波分解（检测伪影敏感性）来计算新颖的可信度得分（TWS），并集成排名第一的候选样本以生成单一的可信输出。这项研究通过TWS评估VLM选择样本的可信度，并验证其在模糊和自然图像中与人类偏好的紧密关联。相较传统的PSNR和LPIPS等度量标准，该方法提供了导航扩散模型产生SR空间不确定性的原则性、可扩展和普遍适用的解决方案。
### Conclusion
通过将输出与人类期望和语义正确性保持一致，这项工作确立了生成超分辨率场景中的可信度新基准。
## 269. `cs.CV` - 基于软标签数据增强的动态模糊面部表情识别改进 [PDF](https://arxiv.org/pdf/2506.20867), [HTML](https://arxiv.org/abs/2506.20867)
### Authors
Ryosuke Kawamura,Hideaki Hayashi,Shunsuke Otake,Noriko Takemura,Hajime Nagahara
### Background
动态面部表情识别（DFER）是一项从面部表情视频序列中估计情感的任务。在实际应用中，准确识别在自然环境中常见的模糊面部表情至关重要。现有的方法在处理模糊面部表情数据时表现不佳，特别是在数据增强和训练模型方面存在挑战。当前研究旨在通过引入软标签数据增强方法MIDAS，提升DFER在模糊面部表情数据上的识别性能，从而解决传统方法的不足，并在两个不同的数据集上证明其有效性。
### Innovation
MIDAS是一种通过软标签（表示多个情感类别的概率）对培训数据进行增强的方法，这种方法通过对视频帧配对进行凸组合来实现。相较于传统的mixup方法，MIDAS方法能够简化并有效地处理DFER中的模糊性问题，提供了一个简单而有效的增强技术。
### Conclusion
实验结果显示，使用MIDAS增强的数据训练的模型在DFEW数据集和FEVR39k-Plus数据集上均取得了优于当前最先进的方法的效果，证明了该方法的有效性。
## 270. `cs.CV` - 单眼在立体视觉中的作用 [PDF](https://arxiv.org/pdf/2506.20900), [HTML](https://arxiv.org/abs/2506.20900)
### Authors
Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti
### Background
这篇论文探讨了现代立体视觉系统的几何基础，特别是3D结构和人类启发式感知如何贡献于准确的深度重建。论文回顾了Cyclopean Eye模型，并提出了一种新的几何约束，该约束可以考虑遮挡和深度突变。分析还评估了来自深度学习模型的立体特征匹配质量以及注意力机制在恢复有意义的3D表面中的作用。通过理论洞见和现实数据集的经验研究，证明了结合强大的几何先验与学习特征可以为理解立体视觉系统提供内部抽象。
### Innovation
文章提出了新的几何约束条件，可以考虑遮挡和深度突变。还讨论了立体特征匹配质量和注意力机制在立体视觉中的作用。通过结合强大的几何先验与学习特征，为理解立体视觉系统提供了内部抽象。
### Conclusion
结合强几何先验与学习特征为理解立体视觉系统提供了有效的内部抽象，提高了深度重建的准确性。
## 271. `cs.CV` - THIRDEYE: 脑启发的多阶段融合的线索意识单目深度估计 [PDF](https://arxiv.org/pdf/2506.20877), [HTML](https://arxiv.org/abs/2506.20877)
### Authors
Calin Teodor Ioan
### Background
传统的一目深度估计方法通过训练深度模型直接从RGB像素中推断深度。此类隐式学习经常忽略了人类视觉系统依赖的显式单目线索，例如遮挡边界、阴影和透视关系。研究表明，人类对这些线索的利用极大地提高了深度感知的准确性和效率。因此，该领域迫切需要一种能够更有效使用这些线索的方法，以提升单目深度估计的性能。
### Innovation
该方法提出了名为ThirdEye的线索意识管道，它通过专门训练并固定的线索专家网络，有目的地提供每种单目线索，并在视觉皮层层次（V1-V2-V3）中融合这些线索。整个过程还包括一个键值工作记忆模块，以及一个自适应区间变换头来生成高分辨率的视差图。此方法通过使用固定的线索专家网络，获得外部监督的同时，只需要适度的微调，从而大幅提高了模型的学习效率。
### Conclusion
与传统方法相比，ThirdEye不仅利用了额外的外部监督，减少对大量训练数据的依赖，还通过精心设计的线索融合机制，有效提升了单目深度估计的分辨率和准确性。该模型具备广泛的适用性和潜力，未来可能会在更具挑战性的场景中表现出更优异的效果。
## 272. `cs.CV` - 基于AI的MRI脑肿瘤分割基准测试 [PDF](https://arxiv.org/pdf/2506.20786), [HTML](https://arxiv.org/abs/2506.20786)
### Authors
Connor Ludwig,Khashayar Namdar,Farzad Khalvati
### Background
医学影像分割在医学诊断中发挥了巨大作用，基于U-Net和nnU-Net的架构提供了最先进的性能。近年来，提出了许多通用可提示模型和医学变体，但目前缺乏在常见医学数据集上对这些模型在多种提示质量方面的评估和比较。本研究使用Segment Anything Model (SAM)、Segment Anything Model 2 (SAM 2)、MedSAM、SAM-Med-3D和nnU-Net在BraTS 2023成人胶质瘤和儿科数据集上得到了零样本推理结果，并在不同提示质量下评估了两种提示类型的表现。
### Innovation
本研究创新地使用了多种分割模型（SAM、SAM 2、MedSAM、SAM-Med-3D和nnU-Net）在BraTS 2023数据集上进行零样本推理的评估与比较，特别针对不同质量的提示进行点及边界框分割评估，发现了几个模型在特定高精度边界框提示下取得了优异的Dice分数，尤其是SAM和SAM 2实现了高达0.894和0.893的Dice分数，超过了nnU-Net的分割性能。
### Conclusion
尽管这些模型在点提示的性能上经过微调后取得了显著改进，但无法达到边界框提示或nnU-Net的分割性能。nnU-Net仍然被视为医学影像分割的主导网络，主要原因是提供高度准确的提示在实际操作中不够实际。未来的研究应进一步探索提示性能的改进潜力。
## 273. `cs.CV` - MultiHuman-Testbench: 导出图像生成评估基准用于生成多个真人 [PDF](https://arxiv.org/pdf/2506.20879), [HTML](https://arxiv.org/abs/2506.20879)
### Authors
Shubhankar Borse,Seokeon Choi,Sunghyun Park,Jeongho Kim,Shreya Kadambi,Risheek Garrepalli,Sungrack Yun,Munawar Hayat,Fatih Porikli
### Background
生成包含多个真人且执行复杂动作的同时保持其面部身份的图像是一项重大挑战，主要原因是没有专门的基准测试。为解决这一问题，本文提出了MultiHuman-Testbench，这是一种用于严格评估多真人生成生成模型的新基准。该基准包括1800份样本，并结合了详尽的人工筛选文本提示，描述了从简单到复杂的各种人类行为。这些提示与5,550张具有不同年龄、种族背景和性别的独特人脸图像相匹配，确保了多样性。此外，还提供了由人类选择的姿势条件图像，以准确匹配提示。
### Innovation
提出了一种多方面的评估套件，采用四个关键指标量化人像数量、ID相似度、提示对齐和动作检测。使用零样本方法、训练方法以及是否有区域先验的广泛模型进行深入评估，并提出了使用人类分割和匈牙利匹配融合图像和区域隔离的新技术，显著提高了ID相似度。这些新颖的技术和方法为评估多真人生成模型提供了新工具。
### Conclusion
所提出的基准和关键发现为多真人图像生成研究提供了宝贵见解和标准化工具。
## 274. `cs.CV` - 像素对比学习在医疗视觉像素级预训练中的应用 [PDF](https://arxiv.org/pdf/2506.20850), [HTML](https://arxiv.org/abs/2506.20850)
### Authors
Yuting He,Shuo Li
### Background
对比学习（CL）已成为自监督预训练（SSP）在基础模型中的基石，但对于像素级表示尤其重要的医疗视觉领域，如何将其扩展到像素级代表仍是一个开放问题。标准CL采用二元优化问题形式（二元CL），这种过度追求特征分散的方式导致过度分散问题，破坏了像素级特征间的关联关系，进而打破了类内分布。上述问题使得像素级自监督预训练无法有效进行。鉴于此，本文在像素级表示上进行了积极的探索，以构建一个面向像素级预训练的框架，以解决上述问题，从而推进可泛化的医疗视觉基础模型的发展。
### Innovation
本文通过将对比学习（CL）公式化为向量回归问题，建立了COntrast in VEctor Regression（COVER）框架。COVER能够通过建模特征距离来量化像素级预训练中的分散，从而保持像素级特征间的关联关系。该框架采用了向量金字塔架构，以实现粒度自适应，并确保从向量回归到距离建模的一致优化流程。
### Conclusion
通过覆盖跨8种任务（横跨2维和4模态）的广泛实验，COVER在像素级自监督预训练上取得了显著改进，有效地推进了可泛化的医疗视觉基础模型的发展。
## 275. `cs.CV` - 基础模型在人类-机器人交互中手势识别中的表现如何？ [PDF](https://arxiv.org/pdf/2506.20795), [HTML](https://arxiv.org/abs/2506.20795)
### Authors
Stephanie Käs,Anton Burenko,Louis Markert,Onur Alp Culha,Dennis Mack,Timm Linder,Bastian Leibe
### Background
手势能够实现人类与机器人之间的非言语交流，尤其在嘈杂的环境如灵活生产中。传统的基于深度学习的手势识别依赖于任务特异性的架构，以图像、视频或骨骼姿态估算作为输入。同时，具有强大泛化能力的Vision Foundation Models (VFMs) 和Vision Language Models (VLMs) 提供了通过替换专用的任务特异性模块以简化系统复杂度的潜力。本文探讨了将这些模型应用于手势识别的可能性，特别是动态、全身手势的识别。通过对比最先进的VFM（V-JEPA）、多模态VLM（Gemini Flash 2.0）和表现出色的骨架基于方法（HD-GCN），并在一种特定于人类-机器人通信的NUGGET数据集上进行评估。实验证明，虽然HD-GCN性能最佳，但简化后的V-JEPA功能相近，为降低系统复杂性提供了可能，但Gemini在零样本设置中仅凭文本描述难以区分手势，突显了需要进一步研究适当的手势输入表示的重要性。
### Innovation
提出了一种新的数据集NUGGET，用于评估不同的手势识别方法；对比了基于骨架的方法和基于基础模型的方法在人类-机器人交互中的应用；探索了使用基础模型作为共享多任务模型的可行性从而简化系统复杂性，尽管基础模型在零样本设置中表现不佳。
### Conclusion
在人类-机器人交互中，基于骨架的方法在手势识别上表现出色，而基础模型则在简化系统复杂性方面具有潜力。然而，基础模型在零样本设置中区分手势的效果较差，需要进一步研究更合适的输入表示。
## 276. `cs.CV` - FixCLR：负类对比学习在半监督领域泛化的应用 [PDF](https://arxiv.org/pdf/2506.20841), [HTML](https://arxiv.org/abs/2506.20841)
### Authors
Ha Min Son,Shahbaz Rezaei,Xin Liu
### Background
半监督领域泛化（SSDG）旨在解决只有少量标签情况下，在新分布数据上的泛化问题。由于标签稀缺，现有的领域泛化方法往往表现不佳。因此，现有方法将半监督学习方法与各种正则化项结合使用。然而，这些方法并未明确正则化以学习跨所有领域的不变表示，这是领域泛化的关键目标。因此，本研究介绍了一种新的方法FixCLR，通过借鉴自监督学习的成功经验，在对比学习中引入类别信息的利用和斥力项的应用，以实现明确的领域不变性正则化。FixCLR还可以添加到大多数现有的SSDG和半监督方法之上，以实现互补的性能提升。
### Innovation
提出了一种新的方法FixCLR，通过改变对比学习的两个关键组件来实现明确的领域不变性正则化，即利用伪标签中的类别信息和仅使用斥力项。FixCLR能够针对大多数现有SSDG和半监督方法进行优化，提升其性能。研究还进行了广泛的实验，涵盖了不同半监督方法的改进、预训练模型与非预训练模型的性能评估，以及在多领域数据集上的测试，这些实验在以往的SSDG研究中并未进行过。
### Conclusion
研究表明，FixCLR在SSDG方法中表现出色，尤其是在与其他半监督方法结合使用时。
## 277. `cs.CV` - FaSTA*: 快慢工具路径代理及子程序挖掘方法在高效多轮次图像编辑中的应用 [PDF](https://arxiv.org/pdf/2506.20911), [HTML](https://arxiv.org/abs/2506.20911)
### Authors
Advait Gupta,Rishie Raj,Dang Nguyen,Tianyi Zhou
### Background
本文关注的是多轮次图像编辑任务，如“在图像中检测长凳并将其着色为粉红色；同时移除猫以获得更清晰的视图，并将墙着色为黄色。”这类任务要求处理者不仅能够高效率地规划操作步骤，还要精确执行局部任务，确保最终操作路径既有效又低成本。传统的基于语言模型的方法虽然在高层面提供快而高效的规划，但在执行细节和探索方面通常不够精确，而基于字典的搜索方法虽然能够保证局部优化，但往往缺乏整体的优化能力，计算效率较低。因此，需要一种新的方法来整合这些优点，以实现整体效率的提升。
### Innovation
本文提出了一种名为FaSTA$^*$的低成本神经符号代理，它结合了大型语言模型的大规模高层面任务规划和详细操作的局部A$^*$搜索。特别地，该方法通过LLMs进行归纳推理来改进之前成功的操作路径，并通过适应性快慢规划机制（如探索较高的抽象子程序，不足时才使用底层的A$^*$搜索）来减少重复子任务的计算成本，从而实现了高度自动化且高效的人机交互图像编辑代理。这种方法显著提高了计算效率，同时保持与基准模型相当的成功率，解决了传统方法效率低下和精确性不足的问题。
### Conclusion
通过将FaSTA$^*$与最新的图像编辑方法进行比较，本文证明了FaSTA$^*$在保持成功率的同时，计算效率显著提高。FaSTA$^*$提出了一种新的代理模型，可以通过大语言模型进行快速而灵活的高层任务规划，并利用少量的快慢规划策略来减少计算负担，从而实现在实时图像编辑中的高效操作。
## 278. `cs.CV` - M2SFormer: 多谱段和多尺度注意机制结合边缘感知难度指导的图像伪造定位 [PDF](https://arxiv.org/pdf/2506.20922), [HTML](https://arxiv.org/abs/2506.20922)
### Authors
Ju-Hyeon Nam,Dong-Hyun Moon,Sang-Chul Lee
### Background
图像编辑技术迅速发展，既促进了数字图像的新颖应用场景，也带来了图象伪造的潜在风险。深度学习方法在像素级伪造定位方面取得了高精度，但面临计算量大和表示能力有限的问题，尤其是在处理细微或复杂的伪造情况时。现有的方法大都将空间和频率线索分开处理，M2SFormer则在跳层连接中统一了多频率和多尺度的注意力，利用全局上下文更好地捕捉多样化的伪造特征。此外，该框架还通过利用全局先验图来解决上采样过程中细节损失的问题，全局先验图是一种表明伪造定位难度的曲率度量，能够引导难度导向注意力模块更好地保留细微的伪造操作。
### Innovation
M2SFormer引入了一种新型的基于Transformer编码器的框架，统一了多频率和多尺度注意力机制，并且在跳层连接中使用全局上下文来捕捉更丰富的伪造特征。同时引入全局先验图和难度导向注意力模块，以保留细微的伪造操作，克服了现有方法在细节处理上的不足。
### Conclusion
通过对多个基准数据集的广泛实验，M2SFormer表现出了比现有最佳模型更好的泛化能力，能够更准确地检测和定位未见过领域的伪造。
## 279. `cs.CV` - AIR-VIEW：用于天气能见度估计的航空图像库，一个数据集和基准 [PDF](https://arxiv.org/pdf/2506.20939), [HTML](https://arxiv.org/abs/2506.20939)
### Authors
Chad Mourning,Zhewei Wang,Justin Murray
### Background
航空气象领域的机器学习研究正在增长，目的是提供比传统昂贵的气象传感器更低成本的替代方案；但是在大气能见度估计方面，缺乏与距离航空相关的、标签化能见度估计、多样性地点和足够大适合监督学习的公开可用数据集。现有的研究缺乏这样的公共数据集支持此目的的数据收集工作。
### Innovation
本文引入了一个新的数据集，该数据集代表了一整年FAA气象摄像机网络图像的数据收集活动的成果，这些图像可以用于能见度估计。此外，文章还介绍了在三个公开可用的数据集（包括自己的）上应用三种常见方法和一个通用基准方法，并与最近批准的ASTM标准进行比较，以提供基准参考。
### Conclusion
该研究不仅提供了新的数据集，还通过与现有标准的比较提供了能见度估计的基准参考，这有助于推动航空气象领域机器学习方法的进一步研究和应用。
## 280. `cs.CV` - 基于多智能体辅助的证据推理在人类病理诊断中的应用 [PDF](https://arxiv.org/pdf/2506.20964), [HTML](https://arxiv.org/abs/2506.20964)
### Authors
Chengkuan Chen,Luca L. Weishaupt,Drew F. K. Williamson,Richard J. Chen,Tong Ding,Bowen Chen,Anurag Vaidya,Long Phi Le,Guillaume Jaume,Ming Y. Lu,Faisal Mahmood
### Background
病理学正经历由全切片成像和人工智能（AI）驱动的快速数字化转型。虽然基于深度学习的计算病理学已取得显著成效，但传统模型主要集中在图像分析方面，未结合自然语言指令或丰富、基于文本的上下文。当前的计算病理学多模态大语言模型（MLLMs）面临局限性，包括训练数据不足，多图像理解支持和评估不足以及缺乏自主诊断推理能力。
### Innovation
本文介绍了一种名为PathChat+的新多模态大语言模型，专门用于人类病理学，通过超过100万份多样、病理学特定的指令样本和近550万轮问答样本进行训练。实验表明，PathChat+在多个病理基准上显著优于之前的PathChat辅助模型以及最先进的通用模型和专业的病理模型。同时，文章还提出了一个利用PathChat+进行自动全切片图像诊断推理的多智能体AI系统SlideSeek，展示出高效的诊断能力和生成可视化的、人可理解的汇总报告的能力。
### Conclusion
研究结果表明PathChat+在计算病理学中取得了重大突破，能够实现更精确、自主的诊断推理，为人类病理学提供了新的解决方案。
## 281. `cs.CV` - PhysRig: 基于物理的可微制皮与绑定框架，用于现实的肢体物体建模 [PDF](https://arxiv.org/pdf/2506.20936), [HTML](https://arxiv.org/abs/2506.20936)
### Authors
Hao Zhang,Haolan Xu,Chun Feng,Varun Jampani,Narendra Ahuja
### Background
皮肤制皮和绑定是动画、有骨架物体重建、运动转移和四维生成中的基本组成部分。现有的方法大多依赖于线性混合制皮（LBS），因其简单性和可微性。然而，LBS会导致体积损失、不自然的变形等缺陷，无法建模如软组织、毛发、弹性附肢（例如：大象的鼻子、耳朵、脂肪组织）这类弹性材料。
### Innovation
本工作提出了一种基于物理的可微皮肤制皮和绑定框架PhysRig，通过将刚体骨骼嵌入体素表示（例如四面体网格）中进行模拟，作为受动画骨骼驱动的可变形软体结构，从而克服了现有方法的限制。PhysRig采用连续力学并离散物体中的粒子嵌入欧拉背景网格中，确保对材料特性和骨骼运动的可微性。同时，通过引入材料原型显著减少了学习空间，同时保持高度的表达能力。为了评估本框架的效果，使用Objaverse、The Amazing Animals Zoo和MixaMo中的网格构建了一个全面的合成数据集，涵盖多个物体类别和运动模式。PhysRig的一致性能传统基于LBS的方法生成更真实和物理合理的结果。此外，还展示了该框架在姿态转移任务中的适用性，突显了其在肢体物体建模中的多功能性
### Conclusion
本方法在产生更真实和物理合理的结果方面一致地优于传统的基于LBS的方法，并且在一对一骨骼转移任务中也展示了其多功能性。
## 282. `cs.CV` - 重新思考以姿态为导向的文本到图像生成中的稀疏信号 [PDF](https://arxiv.org/pdf/2506.20983), [HTML](https://arxiv.org/abs/2506.20983)
### Authors
Wenjie Xuan,Jing Zhang,Juhua Liu,Bo Du,Dacheng Tao
### Background
近期的研究倾向于使用密集信号（例如深度、DensePose）来代替稀疏信号（例如OpenPose）来提供详细的空间指导。尽管密集表示提供了详细的空间信息，但也带来了编辑困难和潜在的与文本提示不一致的问题。因此，论文提出重新审视稀疏信号的用途，因其简洁性和不依赖于特定形状的特点被广泛忽视。研究表明，在姿态导向的文本到图像生成任务中，稀疏信号的方法在综合性能和控制能力上具有优势。
### Innovation
该研究提出了一种新颖的姿态空间控制网络（SP-Ctrl），利用稀疏信号实现对姿态导向图像生成的稳健控制。研究扩展了OpenPose，使其生成可学习的时空表示，使关键点嵌入更具辨别性和表现力。此外，引入了关键点概念学习，以鼓励关键点符号关注每个关键点的时空位置，提高姿态对齐的效果。
### Conclusion
实验结果表明，我们的方法在包含动物和人类的图像生成任务中，在稀疏姿态引导下，实现了对近期可控制的空间文本到图像生成方法的超越，并在性能上与基于密集信号的方法相当。此外，SP-Ctrl在多种多样和跨物种生成任务中展示了其潜在的控制能力。
## 283. `cs.CV` - OmniEval：一种评估视听文本多模态模型基准 [PDF](https://arxiv.org/pdf/2506.20960), [HTML](https://arxiv.org/abs/2506.20960)
### Authors
Yiman Zhang,Ziheng Luo,Qiangyu Yan,Wei He,Borui Jiang,Xinghao Chen,Kai Han
### Background
现有评估基准主要针对单一模态模型，如视觉或听觉模型，缺乏对多模态模型同时处理多种输入能力的综合评估。OmniEval旨在填补这一空白，提供一个全面评估视听文本多模态模型的有效方法，使其能够高效地整合和理解来自多种模态的输入信息，尤其是音频与视频之间的强关联性。
### Innovation
OmniEval具有以下创新特点：1) 全模态协作：设计任务突出音频与视频的强关联，要求模型有效利用所有模态的协同感知。2) 资源多样：包括810段同步音频-视频，285段中文视频，525段英文视频。3) 任务多样性和精细程度：包含2617个问答对，分为1412个开放式问题和1205个多选题。这些问题按3大任务类型和12个子任务类型划分，实现全面评估。4) 新颖引入接地任务：一种更精细的视频定位任务，以增强模型理解上下文的能力。
### Conclusion
OmniEval提供了一个评估平台，旨在检验多模态模型从所有模态上下文中构建和理解连贯性的能力。该论文通过在几个多模态模型上进行实验展示了其有效性和实用性，相关代码和数据可在此处获取。
## 284. `cs.CV` - Hierarchical Sub-action Tree for Continuous Sign Language Recognition [PDF](https://arxiv.org/pdf/2506.20947), [HTML](https://arxiv.org/abs/2506.20947)
### Authors
Dejie Yang,Zhu Xu,Xinjie Gao,Yang Liu
### Background
连续手语识别（CSLR）旨在将未剪辑的手语视频转换成文本词汇。然而，由于缺乏大尺寸数据集和精准的标注，这已成为CSLR的一个瓶颈问题。已有一些研究发展了跨模态解决方案以对齐视觉和文本模态性，但它们通常是从手语词汇中提取文本特征，未能充分利用其知识。因此，本文提出了一种称为HST-CSLR的层次子动作树（HST）方法，结合手语知识与视觉表征学习，并利用树结构减少计算复杂度，进而提高视频中手语词汇的准确率。同时，通过引入对比对齐增强来弥合两种模态之间的差距。实验结果表明HST-CSLR的有效性。
### Innovation
提出了层次子动作树（HST）方法，通过引入层次结构，结合手语知识与视觉表征学习，有效利用文本信息，特别是通过树结构减少计算复杂度，并通过对比对齐增强来弥合视觉和文本模态之间的差距。这种方法提高了CSLR的准确性和效率。
### Conclusion
HST-CSLR方法在四个数据集（PHOENIX-2014, PHOENIX-2014T, CSL-Daily, 和 Sign Language Gesture）上的实验结果表明了其有效性。
## 285. `cs.CV` - 联合相机光度优化的3D场景-相机表示 [PDF](https://arxiv.org/pdf/2506.20979), [HTML](https://arxiv.org/abs/2506.20979)
### Authors
Weichen Dai,Kangcheng Ma,Jiaxin Wang,Kecen Pan,Yuhang Ming,Hua Zhang,Wanzeng Kong
### Background
多视角图像场景的表示是计算机视觉中的关键任务，具有广泛的应用。然而，相机成像中的固有光度失真会显著降低图像质量。如果不考虑这些失真，3D场景表示可能会意外地包含与场景无关的错误信息，从而降低表示质量。
### Innovation
本文提出了一种新颖的联合相机光度优化的3D场景-相机表示方法。通过引入内部和外部光度模型，提出了一种完整的光度模型和相应的相机表示方法。基于同时优化相机表示参数，该方法有效地将与场景无关的信息从3D场景表示中分离出来。在优化光度参数时，引入了深度正则化以防止3D场景表示拟合与场景无关的信息。通过将相机模型作为映射过程的一部分，该方法构建了一个完整地图，包括场景辐射场和相机光度模型。实验结果表明，该方法即使在成像退化的情况下（如尺缩效果和污迹）也能实现高质量的3D场景表示。
### Conclusion
提出的联合相机光度优化方法可以有效提高3D场景表示的质量，即使在存在成像退化的情况下也能保持高精度。
## 286. `cs.CV` - EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning [PDF](https://arxiv.org/pdf/2506.20986), [HTML](https://arxiv.org/abs/2506.20986)
### Authors
Xiao Zhang,Yongqiang Ma,Haodong Jing,Nanning Zheng
### Background
Compositional Zero-Shot Learning (CZSL)旨在基于已学习的原始概念识别未知的状态-对象对，以研究组合泛化能力。现有CZSL方法通常通过简单的组合-原型映射来提取原始特征，对于可以细分为不同语义子集的个体群体，这种方法效果欠佳。此外，所有的跨模态原始模式匹配忽略了同一状态或对象内部的组合差异，从而影响细粒度的图像-组合对齐。
### Innovation
本文提出了一种多专家混合语义变体对齐框架EVA (EVA)用于CZSL。通过引入领域专家适应性，利用多个专家实现对学习 token 意识的学习，从而建立高质量的原始表示。为了实现准确的组合泛化，还提出了语义变体对齐，以选择与图像-原始模式匹配相关的表示。该方法在三个流行基准数据集的封闭和开放世界设置中显著优于其他最先进的CZSL方法，证明了所提出方法的有效性。
### Conclusion
EVA显著提高了解决CZSL任务的效果，并通过多专家和语义变体对齐方法证明了其在组合学习方面的有效性。
## 287. `cs.CV` - DFVEdit: 用于无监督视频编辑的条件Delta流向量 [PDF](https://arxiv.org/pdf/2506.20967), [HTML](https://arxiv.org/abs/2506.20967)
### Authors
Lingling Cai,Kang Zhao,Hangjie Yuan,Xiang Wang,Yingya Zhang,Kejie Huang
### Background
视频扩散变换器（Video DiTs）在视频生成领域取得了重要进展，但直接将现有视频编辑方法应用于Video DiTs会带来大量的计算负载，并且需要资源密集型的注意力修改或微调。这导致了效率问题。为了缓解这一问题，本文提出了一个高效的零样本视频编辑方法DFVEdit，该方法直接在干净的潜变量上通过流变换进行操作，避免了注意力修改和微调的需求。编辑和采样被统一看作是一种连续流的形式，基于这一基础，本文提出了条件Delta流向量（CDFV）并结合了隐式交叉注意力（ICA）指导和嵌入强化（ER）技术，以进一步提高编辑质量。
### Innovation
DFVEdit是一种为Video DiTs设计的高效零样本视频编辑方法，通过直接操作清洁的潜变量并通过流变换实现编辑，不需进行注意力修改和微调。本文提出的条件Delta流向量（CDFV）是一种对DFV的无偏估计，结合隐式交叉注意力（ICA）指导和嵌入强化（ER），进一步提高了编辑质量。DFVEdit在推理速度和内存使用方面都表现出色，与基于注意力工程的编辑方法相比，可以实现至少20倍的推理速度提升和85%的内存减少。
### Conclusion
大量定量和定性的实验表明，DFVEdit可以在流行的Video DiTs（如CogVideoX和Wan2.1）上无缝应用，并在结构保真度、时空一致性和编辑质量方面达到了最先进的性能。
## 288. `cs.CV` - TSDASeg: 一种用于交互式点云分割的两阶段模型及其直接对齐模块 [PDF](https://arxiv.org/pdf/2506.20991), [HTML](https://arxiv.org/abs/2506.20991)
### Authors
Chade Li,Pengju Zhang,Yihong Wu
### Background
3D 视觉-语言模型（VLMs）的快速发展引起了对交互式点云处理任务的兴趣，尤其是针对实际应用。然而，现有的方法在点级任务（如分割）上表现不佳，主要是因为缺乏直接的3D-文本对齐，这限制了它们将本地3D特征与文本上下文联系起来的能力。
### Innovation
我们提出了一种两阶段的TSDASeg模型，该模型包含一个直接跨模态对齐模块和一个记忆模块，用于交互式点云分割。直接跨模态对齐模块用于明确建立3D点云与文本/2D图数据之间的对齐。记忆模块中使用了多个专用记忆库来分别存储文本特征、视觉特征及其跨模态对应映射。通过自注意和跨注意机制动态利用这些记忆库来更新基于先前存储数据的场景特定特征，从而有效解决了跨多种场景交互分割结果的一致性问题。
### Conclusion
在多个3D指令、参考和语义分割数据集上进行的实验表明，所提出的方法达到了最先进的性能。
## 289. `cs.CV` - 在病理图像中使用自然语言分割所有内容 [PDF](https://arxiv.org/pdf/2506.20988), [HTML](https://arxiv.org/abs/2506.20988)
### Authors
Zhixuan Chen,Junlin Hou,Liqi Lin,Yihui Wang,Yequan Bie,Xi Wang,Yanning Zhou,Ronald Cheong Kin Chan,Hao Chen
### Background
病理图像分割在计算病理学中至关重要，用于分析与癌症诊断和预后相关的组织学特征。然而，当前的方法在临床应用中面临重大挑战，主要由于注释数据有限和类别定义有限制。
### Innovation
本文提出了PathSegmentor，这是第一个面向病理图像的文本提示分割基础模型。同时，PathSeg是最大的、最全面的病理分割数据集，由17个公开来源构成，包含275k张图像-掩码-标签三元组，涵盖了160种不同的类别。PathSegmentor能够使用自然语言提示进行语义分割，无需使用劳动力密集的空间输入如点或框。实验结果表明，PathSegmentor在准确性和适用范围上优于专门模型，同时保持紧凑的结构。它在总体Dice分数上分别超越现有的空间提示模型和文本提示模型0.145和0.429，显示出在分割复杂结构和泛化到外部数据集方面的强大鲁棒性。PathSegmentor的输出增强了诊断模型的可解释性，通过特征重要性估计和成像生物标志物发现，为病理学家提供临床决策支持的依据。这项工作推动了可解释AI在精准肿瘤学中发展。
### Conclusion
PathSegmentor通过提供更多的可解释性和路径学家支持，显示出强大的性能和广泛的适用范围，推动了病理图像分割领域的发展。
## 290. `cs.CV` - DBMovi-GS：通过稀疏控制高斯绘制从模糊单目视频合成动态视图 [PDF](https://arxiv.org/pdf/2506.20998), [HTML](https://arxiv.org/abs/2506.20998)
### Authors
Yeon-Ji Song,Jaein Kim,Byung-Ju Kim,Byoung-Tak Zhang
### Background
新型视角合成任务是从未见视角生成场景，然而，从模糊单目视频中合成动态场景仍是一个未解决的挑战。现有的新型视角合成方法往往依赖高分辨率图像或对静态几何和刚性场景先验的强烈假设，导致在具有动态物体和相机运动的真实环境中缺乏鲁棒性，从而导致不稳定性和视觉保真度下降。
### Innovation
我们提出了DBMovi-GS，一种通过稀疏控制高斯绘制从模糊单目视频合成动态视图的方法。该模型生成密集的3D高斯，可以恢复来自模糊视频的清晰度并重建受动态运动变化影响的详细3D几何结构。这种模型在动态模糊场景下的新型视图合成中实现了稳健的性能，并为模糊单目视频输入设定了一项新的基准，用于现实的新型视图合成。
### Conclusion
DBMovi-GS为动态视图合成提供了新的解决方案，能够处理模糊的单目视频，重建动态场景的几何结构，从而提高了新型视图合成的鲁棒性和视觉保真度。
## 291. `cs.CV` - 从摇篮到拐杖：一种高保真生命周期面部老化两步框架 [PDF](https://arxiv.org/pdf/2506.20977), [HTML](https://arxiv.org/abs/2506.20977)
### Authors
Tao Liu,Dafeng Zhang,Gengchen Li,Shizhuo Liu,Yongqi Song,Senmao Li,Shiqi Yang,Boqian Li,Kai Wang,Yaxing Wang
### Background
面部老化是计算机视觉中的一个重要任务，应用广泛，从娱乐到医疗健康。然而，现有的方法在实现整个生命阶段的真实、无缝转换方面存在困难，尤其是在处理大的年龄跨度或极端头部姿态时。核心挑战在于平衡年龄准确性与身份保持之间的权衡，即所谓的年龄-身份权衡。大多数前方法要么优先考虑年龄转换，牺牲身份一致性，要么相反。因此，本文提出了基于几步骤文本到图像扩散模型的两步面部老化框架Cradle2Cane，以解决这一问题。前一步专注于解决年龄准确性，通过引入自适应噪声注入机制实现，该机制根据给定人物的年龄和性别提示描述进行引导。调整噪声水平可以控制老化强度的同时增加面部变换的灵活性，但在此步中对身份保持的保护较弱，以更好地支持年龄转换。第二步通过条件化模型于两种身份感知嵌入（IDEmb）：SVR-ArcFace和Rotate-CLIP，提高身份保留并保持年龄特定特征，从而剔除第一步骤中的噪声，确保更强的身份保留而不损害老化准确性。两步在端到端方式下联合训练。在CelebA-HQ测试数据集上通过Face++和Qwen-VL协议的广泛实验表明，Cradle2Cane在年龄准确性和身份一致性方面优于现有的面部老化方法。
### Innovation
本文提出了一种基于几步骤文本到图像扩散模型的两步面部老化框架Cradle2Cane，用于解决传统方法在处理大的年龄跨度或极端头部姿态时面临的年龄准确性与身份保持之间的权衡问题。通过引入自适应噪声注入机制和两种身份感知嵌入（IDEmb），Cradle2Cane能在实现高度真实和一致的老化基准线时，兼顾年龄特定特征与身份保持。这种创新方法在跨年龄和极端姿态情况下的表现优于现有的面部老化方法。
### Conclusion
实验结果表明，Cradle2Cane在CelebA-HQ数据集上的年龄准确性和身份一致性方面均优于现有的面部老化方法。Cradle2Cane通过优化的两阶段框架成功地解决了传统方法在面部老化效果上的主要问题。
## 292. `cs.CV` - 通过负音频指导实现逐步骤视频到音频合成 [PDF](https://arxiv.org/pdf/2506.20995), [HTML](https://arxiv.org/abs/2506.20995)
### Authors
Akio Hayakawa,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji
### Background
该研究背景在于现有的视频到音频生成方法往往一次性生成音频，但缺乏对每个视频中特定音效事件逐个生成的支持。文章提出的背景是旨在改进生成音频的方法，使其更接近传统手动制作配音流程，确保更加全面地捕捉视频中的所有声音事件。
### Innovation
本文的创新点在于提出了一种新颖的逐步骤视频到音频生成方法。该方法首先将音频生成分解为多个独立步骤，每个步骤专注于特定的声音事件，并且每一步的生成都受到目标文本提示和之前生成的音频轨道的条件驱动。同时也引入了使用预训练模型和不依赖专用配对数据集的训练框架，提高了数据可获取性，从而提升了生成音频的质量和多样性。
### Conclusion
实验结果表明，本文提出的方法能够为单个输入视频生成多个语义不同的音频轨道，音频合成质量超过了现有的baseline方法。这种方法使得音频合成过程更接近手工制作的流程，并且提高了音频的多样性和质量。
## 293. `cs.CV` - 利用包含SAM的Forward-Forward对比学习进行乳腺癌局部切除边缘检测 [PDF](https://arxiv.org/pdf/2506.21006), [HTML](https://arxiv.org/abs/2506.21006)
### Authors
Tyler Ward,Xiaoqin Wang,Braxton McFarland,Md Atik Ahamed,Sahar Nozad,Talal Arshad,Hafsa Nebbache,Jin Chen,Abdullah Imran
### Background
在进行局部切除手术（lumpectomy）时，完全切除癌症肿瘤并确保标本边缘没有癌变组织是降低乳腺癌复发率的关键。然而，当前使用二维标本影像学（SR）评估标本边缘状态的方法准确性有限，导致四分之一的患者需要额外进行手术。
### Innovation
本文提出了一种结合Segment Anything Model (SAM)与Forward-Forward对比学习（FFCL）的新颖深度学习框架，该框架通过利用局部和全局对比学习的预训练策略，实现了SR图像上标本边缘状态的分类，并通过重建粗略二值掩码来协助SAM进行肿瘤边缘的细化分割。此方法提高了边缘分类的AUC值，并在Dice相似度上提升了27.4%，同时将推理时间缩短至每幅图像47毫秒，显著提升了手术中的边缘评估速度和准确性。
### Conclusion
FFCL-SAM显著提高了术中边缘评估的速度和准确性，具有显著减少重复手术率并提高乳腺癌治疗手术效果的潜力。
## 294. `cs.CV` - 逆场景文本去除 [PDF](https://arxiv.org/pdf/2506.21002), [HTML](https://arxiv.org/abs/2506.21002)
### Authors
Takumi Yoshimatsu,Shumpei Takezaki,Seiichi Uchida
### Background
场景文本去除（STR）的目标是从图像中删除文本元素，最初是用于去除自然场景图像中的隐私敏感或不欲显示的文字，现在也被应用于图形图像。STR 通常会检测文本区域，然后填充这些区域。尽管 STR 通过神经网络和合成数据取得了进展，但滥用风险也随之增加。
### Innovation
本文研究了逆场景文本去除（ISTR），这是一种分析 STR 处理图像的方法，专注于二元分类（检测图像是否经历了 STR）和识别被删除的文本区域。实验结果显示，这些任务可以通过高精度来实现，从而能检测出潜在的滥用并改进 STR。此外，通过训练文字识别器来理解其复杂性，尝试恢复被删除的文本内容也取得了成功。
### Conclusion
ISTR 能够高效地检测图像中是否进行了 STR，从而帮助发现滥用情况并提升 STR 的效果。同时，通过训练文字识别器尝试恢复被删除的文本内容，进一步增强了系统的功能。
## 295. `cs.CV` - VisionGuard：协同框架用于头盔违规检测 [PDF](https://arxiv.org/pdf/2506.21005), [HTML](https://arxiv.org/abs/2506.21005)
### Authors
Lam-Huy Nguyen,Thinh-Phuc Nguyen,Thanh-Hai Nguyen,Gia-Huy Dinh,Minh-Triet Tran,Trung-Nghia Le
### Background
强制摩托车手佩戴头盔对于提高道路安全及确保交通管理系统有效性至关重要。然而，自动检测头盔违规行为面临显著挑战，包括环境变化、摄像机视角及数据标注不一致等因素，这些因素阻碍了摩托车及其骑乘者的可靠检测，导致分类不一致。为了应对这些挑战，提出了VisionGuard，这是一种克服帧级检测器局限性的协同多阶段框架，特别适用于类别不平衡和标注不一致的场景。VisionGuard结合了两个核心组件：自适应标注模块和上下文扩展器模块。自适应标注模块是一个基于跟踪的优化技术，通过使用跟踪算法为各个帧分配持久标签并纠正分类错误，来增强分类一致性。上下文扩展器模块通过生成具有适当置信分数的虚拟边界框来提高罕见类别的召回率，从而有效解决了数据不平衡问题。实验结果显示，与基础检测器相比，VisionGuard将总体mAP提高了3.1%，证明了其在交通监控系统中的实际应用潜力，最终促进了安全和法规遵从性。
### Innovation
VisionGuard是一个协同多阶段框架，主要用于解决自动检测摩托车头盔违规行为中的挑战，特别是类别不平衡和标注不一致性问题。其创新点在于结合了自适应标注模块和上下文扩展器模块，前者通过基于跟踪的方法提高了分类的一致性，后者通过生成虚拟边界框来提升数据不平衡类别的召回率。
### Conclusion
实验结果表明，VisionGuard相比基础检测器将总体mAP提高了3.1%，其有效性和潜在在交通监控系统中的应用被证明。该框架最终有助于提升道路安全和法规遵从性。
## 296. `cs.CV` - Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology [PDF](https://arxiv.org/pdf/2506.21001), [HTML](https://arxiv.org/abs/2506.21001)
### Authors
Qiuyi Qi,Xin Li,Ming Kong,Zikang Xu,Bingdi Chen,Qiang Zhu,S Kevin Zhou
### Background
在细胞病理学中，使用神经网络检测异常细胞面临多重挑战，包括高质量标注数据不足、数据分布长尾现象和不一致的染色风格，这些因素严重影响了检测模型的训练效果和鲁棒性。现有方法通常难以全面且稳定地处理这些挑战，从而限制了检测模型的性能和实际应用价值。
### Innovation
该论文提出了一种风格对齐图像合成（Style-Aligned Image Composition, SAIC）方法，通过合成高质量且风格保留的病理图像，增强检测模型的有效性和鲁棒性。SAIC首先根据属性指导选择合适的异常细胞候选样本，然后采用高频特征重构技术，实现异常细胞和病理背景的风格对齐和高保真合成，并引入大规模视觉-语言模型筛选高质量合成图像。实验结果表明，加入SAIC合成图像能显著提升对尾类和风格异常细胞检测的性能和鲁棒性，从而改善整体检测性能。此外，综合质量评估进一步证实了SAIC在临床应用场景中的普适性和实用性。
### Conclusion
实验结果和综合质量评估表明，SAIC合成图像有效地提升了异常细胞检测的性能和鲁棒性，特别是对于尾类和不同风格的异常细胞。该方法不仅在技术层面上实现了创新，同时在临床应用中具有广泛的应用前景，因此将在该论文网站上发布相关代码。
## 297. `cs.CV` - 生成条件感知面部老化树的无训练扩散方法 [PDF](https://arxiv.org/pdf/2506.21008), [HTML](https://arxiv.org/abs/2506.21008)
### Authors
Bang Gong,Luchao Qi,Jiaye Wu,Zhicheng Fu,Chunbo Song,David W. Jacobs,John Nicholson,Roni Sengupta
### Background
当前的面部老化生成方法大多将老化视为单一确定性路径，而忽略了环境、健康和生活方式等外部因素对老化过程的影响。因此，现有方法往往无法全面满足身份保持、老化真实性和条件对齐的要求，特别是在创意和实践应用方面仍存在不足之处。本文基于这一背景，提出了一种新的框架——Aging Multiverse，可以从单张图片中生成多种可能的老化轨迹，每个轨迹都可以根据外部因素进行调整。
### Innovation
本文的主要创新点包括：1）提出了一种无需训练的基于扩散的方法，可以平衡身份保持、年龄准确性及条件控制。2）采用注意力混合技术来调整编辑强度。3）提出了一种模拟老化正则化策略，以稳定编辑过程。这些创新使模型在身份保持、老化真实性和条件对齐方面达到了最先进的性能，全面超越了现有编辑和年龄预测模型。
### Conclusion
通过将老化过程转换为一个多维度、可控制和可解释的过程，本文的方法为数字叙事、健康管理以及个性化可视化等领域的创造性和实际应用提供了新的途径和思路。
## 298. `cs.CV` - 通过大型多模态模型连接视频质量评分和解释 [PDF](https://arxiv.org/pdf/2506.21011), [HTML](https://arxiv.org/abs/2506.21011)
### Authors
Qizhi Xie,Kun Yuan,Yunpeng Qu,Jiachao Gong,Mingda Wu,Ming Sun,Chao Zhou,Jihong Zhu
### Background
传统的视频质量评估(VQA)方法生成一个数值分数来评判视频的视觉保真度和清晰度，但数值分数无法描述视频的复杂质量维度，限制了其应用范围。过去的研究主要集中在图像领域，依赖于人工质量注释和专有系统生成数据，这限制了数据的规模和有效性。因此，需要一种新的方法来解决这些问题，以适应视频的复杂质量评估需求，并提高数据的可扩展性和生成效率。
### Innovation
本文提出了一种名为Score-based Instruction Generation (SIG)的管道方法，它首先对未标注的视频各个质量维度打分，并映射到文本定义的等级；然后通过引入层次链式思考（CoT）模型，明确地将特定维度与整体质量进行联系起来，模仿人类视觉系统推理过程。SIG的方法通过自动化管道消除了对专家撰写的质量描述和专有系统的依赖，确保了数据的可扩展性和生成效率。此外，基于SIG方法，我们还构建了一个包含400个开放性问题的基准测试S2I-Bench，以更好地评估视频LMMs的质量解释能力。实验结果表明，我们的方法在多个视频LMMs上均能提高质量和解释能力。
### Conclusion
实验结果表明，我们的方法在S2I-Bench和现有基准测试上表现出色，能够在多个视频LMMs上持续提升质量评分和解释能力。
## 299. `cs.CV` - LASFNet: 一种轻量级注意力引导自调制特征融合网络用于多模态目标检测 [PDF](https://arxiv.org/pdf/2506.21018), [HTML](https://arxiv.org/abs/2506.21018)
### Authors
Lei Hao,Lina Xu,Chang Liu,Yanni Dong
### Background
多模态特征在多模态目标检测中的有效深度特征提取是关键。但现有的研究往往通过堆叠多个特征级融合单元来集成模态特定特征，导致训练过程复杂且计算开销大。
### Innovation
提出了一种新的融合检测基线，使用单个特征级融合单元以简化训练过程，并在此基础上设计了轻量级注意力引导自调制特征融合（LASFNet）网络。LASFNet引入了一种新颖的注意力引导自调制特征融合（ASFF）模块，在不同模态注意力信息的指导下，动态调整融合特征的全局和局部响应，以促进综合和丰富的特征生成。此外，设计了颈部轻量级特征注意力转换模块（FATM），以增强对融合特征的关注并最小化信息损失。
### Conclusion
在三个代表性数据集上的广泛实验表明，与现有最先进的方法相比，我们的方法在效率和准确性之间取得了良好的权衡。相比现有方法，参数量和计算成本分别减少了90%和85%，检测精度（mAP）提高1%-3%。代码将开源。
## 300. `cs.CV` - FedSC: 基于语义感知协作的联邦学习 [PDF](https://arxiv.org/pdf/2506.21012), [HTML](https://arxiv.org/abs/2506.21012)
### Authors
Huan Wang,Haoran Li,Huaming Chen,Jun Yan,Jiahua Shi,Jun Shen
### Background
联邦学习（FL）旨在保护隐私前提下，通过客户端协作训练模型而无需共享数据。然而，一个主要挑战是数据异质性问题，这意味着多个客户端上存在偏差的数据标记偏好。现有的FL方法大都试图通过局部（如正则化本地模型）或全局方法（如微调全局模型）来解决数据异质性，但往往忽略了每个客户端固有的语义信息。本文提出了一种基于语义感知协作的联邦学习（FedSC），以探索在处理数据异质性时利用每个客户端内蕴化的语义性知识的可能性。
### Innovation
FedSC的核心思想是在语义级别构建关系原型和一致原型，以一种原型级协作的方式来提供丰富的类别潜在知识和稳定的收敛信号。FedSC通过跨类别的对比学习策略，将具有相同语义的实例级嵌入引导得更接近关系原型，并将不同类别的嵌入引导得更远离。通过差异聚合方式构建一致原型，作为正则化惩罚以约束本地模型的优化范围。此外，提供了一种理论分析以确保其收敛性。
### Conclusion
在各种具有挑战性的场景下的实验结果表明，FedSC的有效性和关键组件的效率。
## 301. `cs.CV` - 用户在环视图采样与错误峰值可视化 [PDF](https://arxiv.org/pdf/2506.21009), [HTML](https://arxiv.org/abs/2506.21009)
### Authors
Ayaka Yasunaga,Hideo Saito,Shohei Mori
### Background
现有增强现实（AR）方法通过可视化缺失的视角样本来辅助新视角样本的合成。这些方法通常要求用户进行标注并手动对齐AR显示以获取图片，这导致数据收集任务复杂且耗时，同时由于理想的但限制性的底层采样理论，用户的探索范围受到限制，只能在预定义的小区域内操作。
### Innovation
本研究提出了使用局部重构的光场和错误峰值可视化来减少用户标注工作负担和减少探索限制。这种方法通过展示需要插入新视角以减少的错误点，减少了用户在最终结果中的失望感，并在移动视角合成系统中使用较少的视角样本也能获得满意的结果。此外，这种方法还能为大规模场景的辐射场重建做出贡献，例如3D 高斯点云重建。
### Conclusion
研究结果显示，错误峰值可视化方法比传统的3D标注方式更具侵入性，减少了对最终结果的失望感，同时使用较少的视角样本也能够得到令人满意的结果。此外，该方法对于大场景的辐射场重建也有所贡献。
## 302. `cs.CV` - 通过指导和调度提高基于扩散的图像编辑保真度 [PDF](https://arxiv.org/pdf/2506.21045), [HTML](https://arxiv.org/abs/2506.21045)
### Authors
Hansam Cho,Seoung Bum Kim
### Background
文本引导的扩散模型已成为高质量图像合成的重要工具，使得动态图像编辑成为可能。在图像编辑中，编辑能力和保真度是两个关键方面，前者决定了修改的程度，后者反映了未修改元素的保留程度。然而，要同时优化这两个方面存在固有的权衡，导致实现最佳结果具有挑战性。
### Innovation
本文提出了Faithfulness Guidance and Scheduling (FGS)，旨在以最小影响提升保真度，同时增强输入图像信息的保留。FGS还引入了一种调度策略来解决编辑能力和保真度之间的对齐问题。实验结果显示，FGS在保持编辑能力的同时，显著提升了保真度，并且其兼容性使得在多种任务中实现精确、高质量的图像编辑成为可能。
### Conclusion
实验结果证明，FGS能够在保持编辑能力的同时，显著提高保真度，并且与各种编辑方法的高度兼容性使其能够在多种任务中实现精确、高质量的图像编辑。
## 303. `cs.CV` - DidSee: 材料无关的机器人感知与操作中的基于扩散的深度完成 [PDF](https://arxiv.org/pdf/2506.21034), [HTML](https://arxiv.org/abs/2506.21034)
### Authors
Wenzhou Lyu,Jialing Lin,Wenqi Ren,Ruihao Xia,Feng Qian,Yang Tang
### Background
商业RGB-D相机在处理非兰伯特物体时往往会生成噪声较大且不完整的深度图。传统的深度完成方法由于训练数据的数量和多样性不足，难以泛化。近期的研究通过利用预训练的文生图扩散模型的视觉先验信息，在密集预测任务中提升了泛化能力。然而，研究发现扩散模型框架中的训练-推理不匹配导致的偏差显著降低了深度完成的性能。此外，非兰伯特区域缺乏明显的视觉特征，也进一步阻碍了精确预测的实现。
### Innovation
提出了一种基于扩散的框架DidSee，用于非兰伯特物体的深度完成。首先，通过引入一个缩放的噪声调度器强制终端信噪比为零，以消除信号泄露偏差；其次，设计了一种与噪声无关的单步训练形式来减轻曝光偏差导致的误差累积，并通过任务特定的损失函数优化模型；最后，引入语义增强器，实现深度完成和语义分割的联合，使物体与背景分离，生成精确而细致的深度图。
### Conclusion
DidSee在多个基准上实现了最先进的性能，并展示了强大的实际世界泛化能力，有效改善了如类别级姿态估计等下游任务。
## 304. `cs.CV` - Instella-T2I: 探索一维离散潜在空间图像生成的极限 [PDF](https://arxiv.org/pdf/2506.21022), [HTML](https://arxiv.org/abs/2506.21022)
### Authors
Ze Wang,Hao Chen,Benran Hu,Jiang Liu,Ximeng Sun,Jialian Wu,Yusheng Su,Xiaodong Yu,Emad Barsoum,Zicheng Liu
### Background
图像空间的量化和表示在高分辨率图像建模中起着关键作用，能够显著提升图像理解和生成的效率。最新的1D潜在空间技术通过去除2D网格结构的需求，减少了所需的令牌数量。本文在这一基础上，进一步发展了一种紧凑的离散图像表示方法，即引入了1D二元图像潜在空间，旨在同时保持高分辨率细节和1D潜在空间的紧凑性。到我们所知，这是首次仅使用128个离散令牌（对图像分辨率最高到1024x1024）就能够实现与标准VQ-VAE相比竞争力相仿的文本到图像模型的扩散和自动回归生成性能，相比标准VQ-VAE，令牌数量可减少高达32倍。
### Innovation
该研究提出了1D二元潜在空间，该空间结合了简单的模型架构，实现了显著的加速训练和推理速度。与传统的使用一热代码本令牌的方法相比，新的方法能够在保持高分辨率图像细节的同时，保持1D潜在空间的紧凑性。另外，所提出的方法使用单个带有8个AMD MI300X GPU的GPU节点，实现了每批次4096的全局批量大小，并能在200 GPU天内完成训练。这种方法无需使用私人训练数据或后训练精调，即可达到与现代图像生成模型相当的性能，为图像生成领域提供了一个可扩展且高效的替代方案。
### Conclusion
本文通过提出1D二元潜在空间，实现了高效且稳定的文本到图像生成，相比标准方法大幅减少了所需令牌数量，并加速了训练和推理过程。该方法能够在标准资源条件下完成大规模训练，展示了其在图像生成领域的实用性和效率。
## 305. `cs.CV` - 使用扩散模型提升领域泛化和自适应检测：健身、泛化与迁移性 [PDF](https://arxiv.org/pdf/2506.21042), [HTML](https://arxiv.org/abs/2506.21042)
### Authors
Boyong He,Yuxiang Ji,Zhuoyue Tan,Liaoni Wu
### Background
检测器往往由于训练数据和测试数据之间的领域差距而导致性能下降。最近的研究利用了扩散模型来解决领域泛化（DG）和领域适应（DA）任务，但仍然面临高推理成本的问题，并且尚未充分利用扩散模型的全部能力。
### Innovation
该研究提出了通过单步扩散过程提取中间特征来改进特征收集和融合，从而在保持源域性能的同时减少75%的推理时间。此外，通过应用框屏蔽图像和类别提示来构建以对象为中心的辅助分支，提取健壮且领域不变的特征。该研究还通过一致损失使辅助分支和常规分支对齐，平衡泛化和适应性，防止过拟合，并在目标域中提高性能。在统一框架中，标准检测器通过特征级和对象级对齐被扩散检测器指导，从而在源域（DA）和未标记的目标域（DG）中提高跨域检测性能。该方法在3个DA基准和5个DG基准上取得了竞争力的结果，特别是在COCO泛化基准上，展示了显著的优势和高效的性能表现，特别是在大领域转移和低数据场景下。
### Conclusion
该工作展示了使用扩散模型解决领域泛化和自适应检测任务的优势，并为跨领域视觉感知任务提供了有价值的见解。
## 306. `cs.CV` - HybridQ：用于皮肤疾病图像生成的经典-量子生成对抗网络 [PDF](https://arxiv.org/pdf/2506.21015), [HTML](https://arxiv.org/abs/2506.21015)
### Authors
Qingyue Jiao,Kangyu Zheng,Yiyu Shi,Zhiding Liang
### Background
机器学习辅助诊断在皮肤疾病检测中逐渐受到重视，但训练有效模型需要大量高质量的数据。皮肤疾病数据集常常存在类别不平衡、隐私问题和对象偏见的问题，使得数据增强变得至关重要。尽管经典的生成模型被广泛使用，但它们需要大量的计算资源和长时间的训练。量子计算提供了一种有前景的替代方案，但现有的基于量子的图像生成方法只能生成低质量的灰度图像。通过一种新颖的经典-量子潜在空间融合技术，我们的工作克服了这一限制，提出了第一种能够生成彩色医疗图像的经典-量子生成对抗网络（GAN）。
### Innovation
我们的研究通过融合经典和量子方法，解决了现有量子图像生成方法生成彩色图像的局限性。我们引入了第一种经典-量子GAN，能够生成高质量的彩色医疗图像，并且在生成图像质量和分类性能提升方面优于经典深度卷积GAN和现有的混合经典-量子GAN。此外，与最先进的经典生成模型相比，我们的模型参数更少（25倍以上），训练周期更短（10倍以上），显示出量子图像生成在量子硬件进步中的巨大潜力。我们还展示了该模型在真实IBM量子机器上表现出色，具有抗硬件噪声的能力。
### Conclusion
我们的结果表明，经典-量子GAN有望成为量子图像生成的一个重要工具，尤其是在硬件基础设施进一步完善的情况下。这种方法在有效提升图像生成质量的同时，还能大幅减少资源消耗，为未来医学图像生成领域开辟了新的方向。
## 307. `cs.CV` - 多模态提示对齐用于面部表情识别 [PDF](https://arxiv.org/pdf/2506.21017), [HTML](https://arxiv.org/abs/2506.21017)
### Authors
Fuyan Ma,Yiran He,Bin Sun,Shutao Li
### Background
文本-视觉模型（VLMs）如CLIP通过提示学习已经广泛应用于多种下游任务。尽管这些方法取得了成功，但当前基于VLM的面部表情识别（FER）方法在捕捉细粒度的文本-视觉关系方面存在不足，这影响了面部表情的细微差异识别能力。本文探讨了如何改进这一领域的方法以克服上述挑战，并提出了用于面部表情识别的多模态提示对齐框架（MPA-FER），通过提供细粒度的语义指导，提高了视觉特征的学习精度和可解释性。
### Innovation
本文提出了一种多粒度硬提示生成策略，使用大型语言模型（LLM）如ChatGPT生成每个面部表情的详细描述，并通过最小化软提示和硬提示之间的特征差异将外部知识注入到软提示中。同时融入了原型引导的视觉特征对齐，将冻结的图像编码器的提示视觉特征与类特定的原型紧密对齐。此外，还提出了一种跨模态全局-局部对齐模块，侧重于表情相关的面部特征，以进一步提高文本特征与视觉特征的对齐。这些创新点相比现有的FER方法能够提供更好的性能，同时保留预训练模型的优势并减少计算成本。
### Conclusion
通过对三个FER基准数据集的广泛实验，证实所提出的MPA-FER框架在精度和可解释性方面均优于现有方法。该研究提出的框架不仅提高了面部表情识别的性能，还保证了模型的泛化能力和计算效率。
## 308. `cs.CV` - SAMURAI: 形状感知的多模态检索用于3D物体识别 [PDF](https://arxiv.org/pdf/2506.21056), [HTML](https://arxiv.org/abs/2506.21056)
### Authors
Dinh-Khoi Vo,Van-Loc Nguyen,Minh-Triet Tran,Trung-Nghia Le
### Background
在复杂的室内环境中仅通过掩码的2D图像和自然语言描述检索3D物体是一个显著挑战。ROOMELSA挑战限制了获取完整3D场景上下文的机会，增加了关于物体外观、几何和语义的推理难度。这种挑战被进一步加剧了，应用场景点视图、丢失纹理的掩码区域、晦涩的语言提示以及噪声分割掩码增多。
### Innovation
我们提出了一种新的方法SAMURAI：形状感知的多模态检索用于3D物体识别。SAMURAI方法结合了基于CLIP的语义匹配和从掩码区域二进制轮廓推导出的形状引导重排序，并采用了强大的多数投票策略。我们还开发了一个专用的预处理管道来提高掩码质量，通过提取最大的连通分量并去除背景噪声。我们的混合检索框架利用了语言和形状线索，实现了在ROOMELSA私有测试集上的竞争性性能。这些结果强调了将形状先验与语言理解结合对于稳健的开放世界3D物体检索的重要性。
### Conclusion
我们的研究结果表明，将形状信息与语言理解结合使用可以显著提升3D物体检索的性能，这对于开放世界环境下的物体识别有重要意义。
## 309. `cs.CV` - PoseMaster: 从单张图像生成任意姿态的3D角色 [PDF](https://arxiv.org/pdf/2506.21076), [HTML](https://arxiv.org/abs/2506.21076)
### Authors
Hongyu Yan,Kunming Luo,Weiyu Li,Yixun Liang,Shengming Li,Jingwei Huang,Chunchao Guo,Ping Tan
### Background
3D角色在日常娱乐中发挥着重要作用。当前，基于图像的方法使用两个独立模型分别实现姿态标准化和A-pose角色的3D重建，但这些方法在姿态标准化阶段容易因为遮挡和视点问题生成失真和退化的图像，从而影响后续重建过程的几何质量。
### Innovation
为了应对这些问题，我们提出了PoseMaster，这是一种端到端可控制的3D角色生成框架。特别之处在于，我们将姿态变换和3D角色生成整合到基于流的3D原生生成框架中。为了实现对任意姿态的精确控制，我们利用可动画角色骨骼中的3D身体骨骼作为姿态条件。此外，考虑到多条件控制的特殊性，在训练过程中随机清空姿态条件和图像条件以提高姿态控制的效果和可推广性。最后，我们创建了一个高质量的姿态控制数据集，来源于现实角色动画数据，以使模型学习骨架和蒙皮权重之间的隐含关系。实验表明，PoseMaster在A-pose角色生成上的定性和定量评估中均优于现有最先进的技术，同时展示了其强大的针对任意姿态进行精确控制的能力。
### Conclusion
PoseMaster在A-pose角色生成中表现出色，在定性和定量评估中均优于当前最先进的技术，同时具有实现任意姿态精确控制的强大能力。
## 310. `cs.CV` - 文档图像中无类别偏好区域—兴趣匹配 [PDF](https://arxiv.org/pdf/2506.21055), [HTML](https://arxiv.org/abs/2506.21055)
### Authors
Demin Zhang,Jiahao Lyu,Zhijie Shen,Yu Zhou
### Background
文档理解和分析由于其广泛的应用而受到了广泛关注，然而现有的文档分析解决方案，如文档布局分析和关键信息提取，只适用于固定类别的定义和粒度，无法实现由用户定制的灵活应用。这使得现有解决方案在满足用户需求方面存在局限性。因此，本文定义了一个新的任务——“无类别偏好区域—兴趣匹配”（简称RoI-Matching），该任务旨在以灵活、高效、多粒度和开放集的方式来匹配定制的区域。该任务要求输入参考文档和目标文档的图像，输出则是目标文档图像中的相应边界框。
### Innovation
本文构建了一个新的基准测试RoI-Matching-Bench，该基准测试根据现实情况设置了三个难度级别，并提出了宏观和微观的评估指标。此外，还提出了一种新的框架RoI-Matcher，该框架采用了Siamese网络来提取参考域和目标域中的多级特征，并使用交叉注意力层来整合和对齐不同领域的相似语义。实验结果显示，该方法在RoI-Matching-Bench上具有简单有效的性能，并可作为进一步研究的基础。
### Conclusion
本文提出了一种新的任务——无类别偏好区域—兴趣匹配，通过构建RoI-Matching-Bench基准测试和提出包含宏观和微观评估指标的方法来解决现有文档分析解决方案的局限性。所提出的RoI-Matcher框架在实验中展现了有效性和实用性，为后续研究提供了一个基础方法。
## 311. `cs.CV` - EgoAdapt: 自适应多感知器蒸馏和策略学习以实现高效主观感知 [PDF](https://arxiv.org/pdf/2506.21080), [HTML](https://arxiv.org/abs/2506.21080)
### Authors
Sanjoy Chowdhury,Subrata Biswas,Sayan Nag,Tushar Nagarajan,Calvin Murdock,Ishwarya Ananthabhotla,Yijun Qian,Vamsi Krishna Ithapu,Dinesh Manocha,Ruohan Gao
### Background
现代感知模型，尤其是那些为多感知器主观任务设计的模型，已经取得了显著的性能，但往往伴随着巨大的计算成本。这些高需求使得在资源受限的环境中进行实际部署变得具有挑战性。特别是在这些环境中，对计算资源的要求限制了这类模型的应用。因此，需要一种能够适应不同主观感知任务，并高效进行跨模态蒸馏和策略学习的框架。
### Innovation
我们介绍了EgoAdapt框架，它通过自适应地进行跨模态蒸馏和策略学习，使得在不同主观感知任务中进行高效推理成为可能，包括主观动作识别、主动讲话者定位和行为预测。我们的提议策略模块可以根据任务特定的动作空间进行调整，使其具有广泛的应用性。实验结果表明，在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个具有挑战性的主观感知数据集中，我们的方法在保持与最新模型相当的性能的同时，或者在某些情况下超越了它们，实现了高达89.09%的GMACs减少、82.02%的参数减少和高达9.6倍的能耗降低。
### Conclusion
我们的方法显著提高了效率，其在EGOAdapt框架下的改进使得在不同主观感知任务中实现高效推理成为了可能，从而解决了主要感知模型在资源受限环境中的部署问题，并展示了在实际应用中的巨大潜力。
## 312. `cs.CV` - 自监督视觉变换器特征增强生成对抗性迁移性 [PDF](https://arxiv.org/pdf/2506.21046), [HTML](https://arxiv.org/abs/2506.21046)
### Authors
Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li
### Background
深度神经网络（DNNs）的能力来源于从提供的数据中提取和解释特征。通过利用DNNs中的中间特征而不是依赖硬标签，我们能构建更有效的对抗扰动，增强黑盒移植性。这些特征之前的研究大多来自监督学习。启发于自我监督学习和变换器架构之间的独特协同作用，本文探索是否利用自我监督的Vision Transformer (ViT)表示能提高对抗移植性。现有的方法多依赖于监督学习中的特征，该研究尝试通过自我监督学习中的两种方式——对比学习（CL）和掩码图像建模（MIM）——来增强这一能力。这一背景表明，通过这两种方式，ViTs能够关注不同的特征趋势，当两者结合时，能显著提升对抗性一般化能力。
### Innovation
该研究基于自我监督学习和变换器架构之间的独特协同作用，提出了dSVA攻击方法，这是一个生成式双重自我监督ViT特征攻击。dSVA攻击不仅利用对比学习获得全局结构性特征，还利用掩码图像建模获得局部纹理特征。该方法通过集成生成器和利用自我监督ViTs的联合特征及注意力机制来训练生成器。结果显示，通过扰乱自我监督ViTs提取的双重深层特征，dSVA在各种架构的黑盒模型上获得了显著的对抗移植性，超越了最先进的方法。这种方法为对抗性攻击提供了新的视角和提升路径。
### Conclusion
这项研究展示了CL和MIM可以帮助ViTs关注不同的特征趋势，并在结合利用时显著增强对抗性迁移性。通过破坏自我监督ViTs中的双重深层特征，dSVA实现了在各种架构模型上显著的黑盒迁移性，超越了现有的最强方法。
## 313. `cs.CV` - OracleFusion: 基于结构化语义排版辅助甲骨文 decipherment [PDF](https://arxiv.org/pdf/2506.21101), [HTML](https://arxiv.org/abs/2506.21101)
### Authors
Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,AndyPian Wu,Chaoyang Wang,Chengjie Wang,Taisong Jin,SevenShu,Yunsheng Wu,Yongge Liu,Rongrong Ji
### Background
甲骨文（OBS）作为最古老的古文字之一，承载了古代文明的文化记载和思想表达。尽管已发现约4,500个甲骨文字，但仅约1,600个被成功破译。剩余未破译的文字由于结构复杂和抽象的图像，给解释带来了巨大挑战。为应对这些挑战，本文提出了一种新颖的两阶段语义排版框架，名为OracleFusion。
### Innovation
在第一阶段，该方法利用增强的空间感知推理（SAR）的多模态大型语言模型（MLLM）分析甲骨文字的字形结构并进行关键组件的视觉定位。在第二阶段，引入了甲骨文结构向量融合（OSVF），结合了字形结构约束和字形维护约束，确保生成具有语义丰富性的向量字体的准确性。该方法保留了字形结构的客观完整性，提供视觉增强的表示，帮助专家破译甲骨文。大量定性和定量实验表明，OracleFusion在语义、视觉吸引力和字形维护方面优于最先进的基线模型，显著提高了可读性和审美质量。此外，OracleFusion可以提供关于未见甲骨文的专家级见解，成为推进甲骨文破译的重要工具。
### Conclusion
OracleFusion在语义、视觉吸引力和字形维护方面表现出色，显著提高了甲骨文的可读性和审美质量，为甲骨文的破译提供了有价值的工具。
## 314. `cs.CV` - CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization [PDF](https://arxiv.org/pdf/2506.21117), [HTML](https://arxiv.org/abs/2506.21117)
### Authors
Jan Ackermann,Jonas Kulhanek,Shengqu Cai,Haofei Xu,Marc Pollefeys,Gordon Wetzstein,Leonidas Guibas,Songyou Peng
### Background
在动态3D环境中，准确地随时间更新场景表示对于机器人、混合现实和具身人工智能的应用至关重要。随着场景的演变，需要有效的更新方法来维持最新的高质量重建，而无需重新优化整个场景带来的计算开销。因此，本文介绍了CL-Splats，它通过稀疏场景捕获增量更新基于高斯分裂的3D表示。CL-Splats集成了一个稳健的变更检测模块，可以区分更新和静态场景片段，从而可以集中进行局部优化，避免不必要的重新计算。此外，CL-Splats支持先前场景状态的存储和恢复，促进了时间分割和新的场景分析应用。
### Innovation
CL-Splats通过集成稳健的变更检测模块，能够区分更新和静态场景片段，实现聚焦的本地优化，避免不必要的重新计算。此外，它还支持存储和恢复先前场景状态，促进了时间分割和其他新的场景分析应用。实验表明，CL-Splats能够以高效的方式进行更新，同时提高重建质量，比现有的最先进的方法更优秀。这为未来3D场景重建任务中的实时适应奠定了坚实的基础。
### Conclusion
CL-Splats在3D场景重建中实现了高效更新，同时提高了重建质量。通过增量更新基于高斯分裂的3D表示，并集成稳健的变更检测模块进行局部优化，CL-Splats在动态3D环境中提供了有效的场景更新方法。
## 315. `cs.CV` - ESMStereo: Enhanced ShuffleMixer Disparity Upsampling for Real-Time and Accurate Stereo Matching [PDF](https://arxiv.org/pdf/2506.21091), [HTML](https://arxiv.org/abs/2506.21091)
### Authors
Mahmoud Tahmasebi,Saif Huq,Kevin Meehan,Marion McAfee
### Background
立体匹配已成为现代自主系统中的重要组成部分。尽管开发能够实时运行且具有高准确性的基于深度学习的立体匹配模型仍然极具挑战性，但在基于成本体积的立体匹配领域，准确的视差估计依赖于大规模的成本体积。然而，大规模的成本体积存储了大量的冗余信息，并且需要计算密集的聚合单元进行处理和回归，这使得实时性能难以实现。相比之下，小尺度的成本体积加上轻量级的聚合单元为实时性能提供了希望，但缺乏足够的信息确保高度准确的视差估计。
### Innovation
本文提出了一种增强版的Shuffle Mixer (ESM)，用于缓解小尺度成本体积信息流失的问题。ESM 通过将主要特征整合到视差上采样单元中，恢复了关键细节。它从初始视差估计快速提取特征并与图像特征融合，通过混合处理、层拆分和紧凑的特征引导式 hourglass 网络进行细化，来恢复更详细的场景几何结构。ESM 侧重于局部上下文连接，具有大感受野和低计算成本，使得实时重建高度准确的视差图成为可能。紧凑版本的 ESMStereo 在高性能 GPU 上实现了每秒 116 帧的推理速度，在 AGX Orin 上实现了每秒 91 帧的推理速度。
### Conclusion
ESMStereo 通过增强的 Shuffle Mixer 结构，成功地在保证实时性和高准确率的同时解决了小尺度成本体积带来的信息不足问题，验证了该方法在实时立体匹配中的有效性和实用性。
## 316. `cs.CV` - 学习在极端黑暗中看见 [PDF](https://arxiv.org/pdf/2506.21132), [HTML](https://arxiv.org/abs/2506.21132)
### Authors
Hai Jiang,Binhao Guan,Zhen Liu,Xiaohong Liu,Jian Yu,Zheng Liu,Songchen Han,Shuaicheng Liu
### Background
基于学习的方法在低光RAW图像增强方面取得了显著的进步，但在极其黑暗的场景中，环境照度降至0.0001勒克斯以下时的能力仍然未被探索，主要原因是缺乏相应的数据集。为此，本文提出了一套配对生成管道，能够在三个精确的照度范围内生成高质量的极低光RAW图像，分别为0.01-0.1勒克斯、0.001-0.01勒克斯和0.0001-0.001勒克斯，并配以高质量sRGB参考，组成一个大规模的配对数据集See-in-the-Extremely-Dark (SIED)，用于评估低光RAW图像增强方法。
### Innovation
本文提出了一个基于扩散的框架，利用扩散模型的生成能力和固有的去噪特性来从极高信噪比（SNR）的RAW输入中恢复视觉上令人愉悦的结果。其中引入了自适应照明校正模块（AICM）和颜色一致性损失，以确保准确的曝光校正和颜色恢复。
### Conclusion
在所提出的SIED数据集和公开可用的基准测试集上进行的广泛实验证明了该方法的有效性。该代码和数据集可在该链接获取。
## 317. `cs.CV` - 突破权衡边界：紧凑且有效的遥感变化检测 [PDF](https://arxiv.org/pdf/2506.21109), [HTML](https://arxiv.org/abs/2506.21109)
### Authors
Luosheng Xu,Dalin Zhang,Zhaohui Song
### Background
遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，能够提供及时、准确且大规模的动态景观转变洞察。尽管深度学习极大地革新了变化检测技术，但现代复杂模型的计算需求并未带来显著的准确性提升。相反，本研究探索了一种更高效的轻量化方法，能够在保持高精度的同时减少资源消耗，满足卫星上处理的需求。
### Innovation
本文提出了FlickCD，这是一种兼具快速和高效变化检测的轻量级模型。FlickCD通过引入增强差异模块(EDM)，放大时间阶段间的关键特征差异，抑制无关变动，如光照和天气变化，从而在后续的变化解码器中降低成本。同时，FlickCD解码器采用局部-全局融合模块，结合移位窗口自注意力(SWSA)和增强全局自注意力(EGSA)，有效地捕捉多尺度语义信息，保持粗细粒度变化。实验结果表明，FlickCD在四大基准数据集上总体减少了计算和存储开销超过一个数量级，同时保持了最先进的性能或仅造成小于1%的精度损失。
### Conclusion
FlickCD通过增强差异模块和融合局部-全局方法，在保持高精度的同时显著降低了计算和存储成本，推动了性能与资源权衡之间的边界。该研究的代码已公开。
## 318. `cs.CV` - 基于有噪声标签的Cardiac MRI心肌疤痕分割的稳健深度学习方法 [PDF](https://arxiv.org/pdf/2506.21151), [HTML](https://arxiv.org/abs/2506.21151)
### Authors
Aida Moafi,Danial Moafi,Evgeny M. Mirkes,Gerry P. McCann,Abbas S. Alatrany,Jayanth R. Arnold,Mostafa Mehdipour Ghazi
### Background
心脏磁共振成像（MRI）中的心肌疤痕准确分割对于临床评估和治疗计划至关重要。本研究提出了一种基于深度学习的稳健的全自动心肌疤痕检测和分割管道，以解决半自动注释带来的标签噪声、数据异质性和类别不平衡等问题。该方法通过使用Kullback-Leibler损失和大量数据扩增来应对这些挑战，从而在不同情况下生成准确且平滑的分割结果。
### Innovation
本研究通过改进现有的深度学习模型，并结合Kullback-Leibler损失函数和数据扩增技术，提出了一种新的心肌疤痕分割方法。该方法特别适用于有噪声标签的数据集，并且在急性与慢性病例中表现出良好的性能。与现有最先进的模型如nnU-Net相比，该方法具有更强的泛化能力，并展示了其在不同成像条件和临床任务中的鲁棒性。
### Conclusion
研究结果证明了该方法在自动心肌疤痕量化方面的可靠性和有效性，为心脏影像学中的深度学习应用提供了更广泛的支持和临床转化的可能性。
## 319. `cs.CV` - YOLO-FDA：结合层次注意力和细节增强的表面缺陷检测 [PDF](https://arxiv.org/pdf/2506.21135), [HTML](https://arxiv.org/abs/2506.21135)
### Authors
Jiawei Hu
### Background
工业场景中的表面缺陷检测既重要又具有挑战性，因为缺陷类型广泛，形状和大小不规则，细节要求严格，且材料纹理复杂。尽管基于AI的检测器有所进步，但现有方法在细节冗余、细节敏感度有限以及在多种尺度下的鲁棒性较差等方面仍存在问题。
### Innovation
本文提出了YOLO-FDA，一种结合了细粒度细节增强和注意力引导特征融合的新颖YOLO检测框架。具体而言，该框架采用了BiFPN风格的架构以加强YOLOv5主干网络中的多层特征双向聚合。为了更好地捕捉细微的结构变化，引入了方向性融合模块（DDFM），在其第二低层中引入了方向性的不对称卷积以丰富空间细节，并将第二低层与低层特征融合以增强语义一致性。此外，提出了两种新的基于注意力的信息融合策略，即注意力加权拼接（AC）和跨层注意力融合（CAF），以提高上下文表示并减少特征噪声。
### Conclusion
在基准数据集上的广泛实验表明，YOLO-FDA在各种类型和尺度的缺陷检测中具有一致的高精度和鲁棒性，优于现有最先进的方法。
## 320. `cs.CV` - GoIRL: 基于图的逆强化学习方法用于多模态轨迹预测 [PDF](https://arxiv.org/pdf/2506.21121), [HTML](https://arxiv.org/abs/2506.21121)
### Authors
Muleilan Pei,Shaoshuai Shi,Lu Zhang,Peiliang Li,Shaojie Shen
### Background
在自动驾驶中，周围代理的轨迹预测是一个具有挑战性的任务，主要由于其固有的不确定性以及潜在的多模态性。大多数现有的数据驱动方法主要依赖于监督学习，这种方法难以处理轨迹预测的不确定性及多模态性。因此，本文提出了一种新的基于图的逆强化学习（Graph-Oriented Inverse Reinforcement Learning，GoIRL）框架，该框架结合了向量化的上下文表示，并通过特征适配器有效地将道路图特征聚合到网格空间中，从而无缝集成到最大熵逆强化学习范式中，以推断奖励分布并获得可以被采样以生成多个可能计划的策略。此外，在采样的计划上，该方法采用了一个多层次的参数轨迹生成器及其精化模块以提高预测准确性，并通过概率融合策略增强预测置信度。大量实验结果表明，本文的方法不仅在大规模的Argoverse & nuScenes运动预测基准测试上达到了最先进的性能，还表现出优于现有监督模型的泛化能力。
### Innovation
本文提出了一种新的基于图的逆强化学习（GoIRL）框架，该框架在处理周围代理多模态轨迹预测问题时具有以下创新点：1) 采用新的特征适配器将道路图特征有效地转换到网格空间中，实现最大熵逆强化学习范式与上下文表示的无缝集成；2) 开发一个多层次的参数轨迹生成器结合精化模块，提高预测精度；3) 实施一种概率融合策略，增加预测的置信度。
### Conclusion
本文方法在大规模的Argoverse & nuScenes运动预测基准测试上达到了最先进的性能，并且在泛化能力方面超过了现有的监督学习模型。
## 321. `cs.CV` - IPFormer-VideoLLM: 提升多模态视频理解以应对多镜头场景 [PDF](https://arxiv.org/pdf/2506.21116), [HTML](https://arxiv.org/abs/2506.21116)
### Authors
Yujia Liang,Jile Jiao,Zhicheng Wang,Xuetao Feng,Zixuan Ye,Yuan Wang,Hao Lu
### Background
视频大型语言模型（VideoLLMs）展示了惊人的理解能力，但在多镜头场景中却表现出色不足，例如，包含不同摄像角度或场景变化的视频片段。这一挑战可能导致实例身份遗忘和关键帧忽视等失败情况。现有的数据集缺乏多镜头注释，导致模型在处理多镜头场景时会遇到困难。该研究旨在通过引入一个新的数据集MultiClip-Bench，包含针对多镜头场景的密集描述和基于指令的问答对，来解决这一问题。
### Innovation
1. 提出一个新的数据集MultiClip-Bench，专为多镜头场景设计，包含密集描述和指令问答对，以提升模型在多镜头场景中的性能。2. 分析发现，当前模型仅以离散或有损的方式编码实例特征，可能会丢失身份信息。为此，提出了一种新型的模型IPFormer-VideoLLM，通过高效注意机制连接实例特征作为实例提示，实现跨场景的实例特定信息聚合。3. 实验结果证明，所提出的模型不仅显著提升了多场景视频理解能力，还能够在各种视频基准测试中提供独特的优势。
### Conclusion
通过引入新的数据集和模型，该研究显著提升了多镜头视频理解能力，并且在多个视频基准测试中展示了不同优势，为解决视频LLMs在多镜头场景中的理解挑战提供了新思路。
## 322. `cs.CV` - 单一图像多视图一致的几何与感知引导高斯分布方法 [PDF](https://arxiv.org/pdf/2506.21152), [HTML](https://arxiv.org/abs/2506.21152)
### Authors
Pufan Li,Bi'an Du,Wei Hu
### Background
从单张视图图像生成真实的三维物体需要自然外观、三维一致性以及捕捉未见区域的多种合理解读。现有方法往往依赖于微调预训练的2D扩散模型或直接通过快速网络推理或3D Gaussian Splatting生成三维信息，但其结果通常在多视图一致性方面表现不佳且缺乏几何细节。
### Innovation
本文提出了一种新颖的方法，无需额外模型训练即可从单张图像重建详细的三维物体，同时无缝地结合了几何先验和感知先验。具体而言，我们训练了三个分别从几何先验、感知先验和高斯噪声初始化的Gaussian分支。通过几何先验捕捉粗略的三维形状，而感知先验利用预训练的2D扩散模型增强多视图信息，并通过相互作用和投影策略进一步细化三维Gaussian分支，从而增强三维一致性。实验结果表明，该方法在新颖视角合成和三维重建方面提供了更高保真的重建结果，优于现有方法，显示出稳健且一致的三维对象生成能力。
### Conclusion
本文提出的方法在单张图像生成的三维重建方面具有更高的保真度，表现出更好的多视图一致性，且能够生成更丰富的几何细节。
## 323. `cs.CV` - 基于树的语义损失：应用于稀疏监督的大规模多类高光谱分割 [PDF](https://arxiv.org/pdf/2506.21150), [HTML](https://arxiv.org/abs/2506.21150)
### Authors
Junwen Wang,Oscar Maccormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren
### Background
高光谱成像（HSI）在手术应用中具有巨大潜力，能够提供超越裸眼观察的生物组织细节。精细的标注工作正在进行中，以训练视觉系统区分大量微妙变化的类别。然而，常用的医疗生物分割任务学习方法等同对待所有错误，从而未能利用标签空间中的类间语义信息。
### Innovation
 Introduced 两种基于树的语义损失函数，利用标签的层次组织结构。进一步将这些损失整合进一种使用稀疏注释（无背景注释）的方法中。通过广泛的实验，表明该方法在包括107个临床定义语义树分类的稀疏标注HSI数据集上达到了最先进的性能。同时，该方法能够在不损害分布内像素分割性能的情况下，有效地检测出分布外像素。
### Conclusion
该方法实现了在大规模多类稀疏标注HSI数据集上的高性能分割，并且能够在不降低分布内像素分割性能的前提下，有效检测出分布外的像素。
## 324. `cs.CV` - 拓扑感知建模用于无监督仿真实际点云识别 [PDF](https://arxiv.org/pdf/2506.21165), [HTML](https://arxiv.org/abs/2506.21165)
### Authors
Longkun Zou,Kangjun Liu,Ke Chen,Kailing Guo,Kui Jia,Yaowei Wang
### Background
从3D物体形状的点集学习语义表示，常常受到显著几何差异的挑战，这些差异主要源于数据采集方法的不同。通常，训练数据通过点模拟器生成，而测试数据则通过不同的3D传感器收集，导致仿真到现实（Sim2Real）领域差距，限制了点分类器的一般化能力。当前的无监督领域适应（UDA）技术难以克服这一差距，因为它们往往缺乏能捕捉全局拓扑信息的稳健、领域不变的描述符，导致模型过度拟合源领域有限的语义模式。
### Innovation
我们提出了一种新颖的拓扑感知建模（TAM）框架，用于物体点云的Sim2Real UDA。该框架通过利用全局空间拓扑，即低级高频的3D结构，来缓解领域差距。并通过一个新颖的自监督学习任务模拟能局部几何特征的空间拓扑关系。此外，我们提出了结合跨域对比学习与自训练的高级自训练策略，有效减少噪声伪标签的影响，增强适应过程的鲁棒性。
### Conclusion
在三个公开展示的Sim2Real基准上的实验结果验证了我们TAM框架的有效性，显示在所有评估任务中都比现有方法有所改进。工作机制的相关源代码将在此网址获取。
## 325. `cs.CV` - 面向任务的KV压缩以实现成本效益高的长视频理解 [PDF](https://arxiv.org/pdf/2506.21184), [HTML](https://arxiv.org/abs/2506.21184)
### Authors
Minghao Qin,Yan Shu,Peitian Zhang,Kun Lun,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu
### Background
现有的多模态大型语言模型（MLLMs）在处理长视频理解（LVU）任务方面仍面临巨大挑战，主要原因是高昂的计算成本。最近的方法探索了键值（KV）压缩来缓解这一问题，但这些方法通常在高压缩比时出现显著的信息丢失。本研究旨在缓解这一问题，提出了一种名为Video-X^2L的方法，该方法灵活地保留了每个LVU任务所需的关键视频信息。Video-X^2L通过两级KV压缩和选择性KV重新加载操作，实现了在保留任务特定信息的同时降低计算成本的目标，这与现有的KV可压缩的MLLMs兼容且无需额外训练。
### Innovation
Video-X^2L引入了两级KV压缩（bi-level KV compression）和选择性KV重新加载（selective KV re-loading）操作，通过生成两种类型的压缩键值（低压缩键值L-KVs和高压缩键值H-KVs），并在模型解码阶段根据不同视频片段的重要性进行选择性加载，从而有效解决了计算成本和信息丢失的平衡问题。这种方法无需额外训练，可以直接适用于现有的KV可压缩的MLLMs，大大提高了长视频理解的效率。
### Conclusion
通过在多个流行的长视频理解基准测试（如VideoMME、MLVU、LongVideoBench和VNBench）中对Video-X^2L进行评估，实验结果表明，与现有的KV压缩方法相比，Video-X^2L在显著节省计算成本的同时，提供了更优的性能。
## 326. `cs.CV` - MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification [PDF](https://arxiv.org/pdf/2506.21199), [HTML](https://arxiv.org/abs/2506.21199)
### Authors
Shadman Sobhan,Kazi Abrar Mahmud,Abduz Zami
### Background
当前的医学图像分析系统通常是针对特定任务设计的，需要为分类和分割分别建立模型，并且缺乏支持用户自定义工作流程的灵活性。这限制了系统的扩展性和部署灵活性。
### Innovation
MedPrompt 是一个统一的框架，结合了一种带有提示的大型语言模型（Llama-4-17B）进行高层次的任务规划和一个模块化的卷积神经网络（DeepFusionLab）进行低层次的图像处理。LLM 解释用户指令并生成结构化输出以动态路由特定任务的预训练权重。这样，只需添加特定任务的权重即可避免重新训练整个框架，从而提高扩展性和部署效率。系统在19个公共数据集上进行了评估，涵盖12种任务，涉及5种成像模态，最终实现了97%的一级端到端正确率和2.5秒的平均推理延迟，适用于接近实时的应用。
### Conclusion
MedPrompt 通过结合LLMs的可解读性和模块化CNN的效率，实现了可扩展性的提示驱动医学成像，使其更适用于医疗图像分割和分类应用。
## 327. `cs.CV` - 解锁约束：无源域无遮挡感知无缝分割 [PDF](https://arxiv.org/pdf/2506.21198), [HTML](https://arxiv.org/abs/2506.21198)
### Authors
Yihong Cao,Jiaming Zhang,Xu Zheng,Hao Shi,Kunyu Peng,Hang Liu,Kailun Yang,Hui Zhang
### Background
全景图像处理是全场景感知的重要组成部分，但面临着失真、视角遮挡和标注有限等挑战。先前的无监督领域适应方法依赖于带有标签的针孔相机数据来转移到未标记的全景图像上，但这种方法需要访问源针孔相机数据。为了解决这些限制，本研究提出了一个新的更实际的任务，即无源域无遮挡感知无缝分割（SFOASS），并首次提出了一种解决方案，称为UN约束学习全场景知识（UNLOCK）。
### Innovation
本研究提出了SFOASS和UNLOCK方法，这是一种无需依赖源数据或目标标签的模型适应方法。特别地，UNLOCK包括两个关键模块：全景伪标签学习和无遮挡驱动的上下文学习。通过这种方式，该框架能够增强模型，使其能够实现全景视角覆盖和无遮挡感知推理的分割。
### Conclusion
本文通过实到实和合成到实的适应设置来标注无源域无遮挡感知无缝分割任务。实验结果显示，本文提出的方法在无源设定下达到了与依赖源数据方法相当的性能，获得了mAAP 10.9，mAP 11.6的最佳成绩，并在mAPQ指标上比仅依赖源数据的方法提高了4.3的绝对值。所有数据和代码将会公开。
## 328. `cs.CV` - GroundFlow：一种用于3D点云序列定位的时间推理插件模块 [PDF](https://arxiv.org/pdf/2506.21188), [HTML](https://arxiv.org/abs/2506.21188)
### Authors
Zijun Lin,Shuting He,Cheston Tan,Bihan Wen
### Background
当前的3D视觉定位（3DVG）方法将多步骤的文本指令视为一个整体，缺乏从每一步中提取有用的时间信息的能力。然而，在3D点云序列定位（SG3D）任务中，文本指令中经常包含“它”、“这里”、“相同的”等代词，以使语言表达更加简洁，这对接地方法提出了理解上下文并从先前步骤中检索相关信息以正确定位对象序列的需求。由于缺乏有效的模块来收集相关历史信息，现有的3DVG方法难以适应SG3D任务。因此，提出了GroundFlow——一种3D点云序列定位的时间推理插件模块，以解决这一不足之处。
### Innovation
提出了GroundFlow——一种3D点云序列定位的时间推理插件模块。通过将GroundFlow集成到3DVG基线方法中，显著提高了任务准确性（+7.5%和+10.2%），甚至超过了预训练于多种数据集上的3D大语言模型。GroundFlow可以根据与当前指令的相关性选择性地提取短期和长期步骤信息，使时间理解能力在步骤数量增加时也能保持优势。
### Conclusion
本研究引入了时间推理能力到现有的3DVG模型中，并在SG3D基准测试中取得了最先进的性能，覆盖了五个数据集。
## 329. `cs.CV` - DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation [PDF](https://arxiv.org/pdf/2506.21237), [HTML](https://arxiv.org/abs/2506.21237)
### Authors
Umaima Rahman,Mohammad Yaqub,Dwarikanath Mahapatra
### Background
现有的多模态学习方法主要关注图像特征，往往无法有效地分离不变和虚假特征，这导致了在分布外（OOD）任务中的性能受限。此外，多模态特征间的差异融合又增加了分离这些特征的难度。
### Innovation
DiMPLe 提出了一种新的方法来分离视觉和语言模态间的不变和虚假特征，通过最小化不变和虚假特征之间的互信息、正则化虚假特征和通过对比学习增强不变特征，使得模型在面对新的类和其他分布变化时有更好的泛化能力和鲁棒性。与现有方法相比，DiMPLe 在 11 个不同数据集上的均值性能更好，特别是在基类和新类准确性上有所提升，分别为 15.27% 和 44.31% 的绝对增益。
### Conclusion
实验结果证明了 DiMPLe 在保持特征一致性对齐的同时，成功地分离了不变特征和虚假特征，并取得了显著的性能提升，该方法有望在多模态学习中发挥重要作用。
## 330. `cs.CV` - ReME: 基于数据导向的无监督开放词汇分割框架 [PDF](https://arxiv.org/pdf/2506.21233), [HTML](https://arxiv.org/abs/2506.21233)
### Authors
Xiwei Xuan,Ziquan Deng,Kwan-Liu Ma
### Background
无监督开放词汇语义分割（OVS）旨在给定一组任意文本类别时，无需昂贵的模型微调就能分割图像。现有解决方案通常探索预训练模型的注意力机制，如CLIP，或生成合成数据并设计复杂的数据检索过程来执行OVS。然而，它们的性能受限于所依赖模型的能力或参考集的质量不足。本文研究了这一具有挑战性的密集场景理解任务中未能被充分重视的数据质量问题，发现高质量的参考集可以显著提升无监督开放词汇分割的表现。
### Innovation
该论文提出了一种数据导向框架ReME，其中包括构建高质量参考集的数据管道和基于相似性的简单检索方法，以突显数据的重要性。广泛评估表明，该方法在十个基准数据集上优于所有现有的无监督开放词汇分割方法，展示了基于数据的设计对于推动开放词汇分割技术的重要性。
### Conclusion
大量评估表明，该方法在十个基准数据集上的表现超过了所有现有的无监督开放词汇分割方法，突显了数据等方面设计对这一领域发展的关键作用。
## 331. `cs.CV` - Temporal Rate Reduction Clustering for Human Motion Segmentation [PDF](https://arxiv.org/pdf/2506.21249), [HTML](https://arxiv.org/abs/2506.21249)
### Authors
Xianghan Meng,Zhengyu Tong,Zhiyuan Huang,Chun-Guang Li
### Background
人类运动分割（HMS）旨在将视频划分为非重叠的人类运动片段，这一领域最近受到了越来越多的研究关注。现有的HMS方法主要基于子空间聚类方法，这些方法基于高维时间数据与子空间集合分布一致的前提。然而，视频捕捉复杂的人类运动时，背景杂乱，这些帧可能并不符合子空间集合分布。
### Innovation
本文提出了一种新颖的人类运动分割方法，名为Temporal Rate Reduction Clustering（TR²C）。TR²C方法能够联合学习结构化表示和亲和性来分割视频中的帧序列，其学习到的结构化表示保持了时间一致性，并且与子空间集合结构保持良好对齐，这有利于人类运动分割任务。实验结果表明，本文方法在五个基准数据集上取得了最先进的性能，使用了不同的特征提取器。
### Conclusion
本文提出了Tempo Rate Reduction Clustering（TR²C），一个新颖的人类运动分割方法，该方法通过联合学习结构化表示和亲和性在视频中的帧序列上实现分割。与其学习的结构化表示维持时间连续性和与子空间集合结构的良好对齐，这有利于人类运动分割任务。在五个基准数据集上，使用不同的特征提取器，本文方法达到了最先进的性能。
## 332. `cs.CV` - Out-of-Distribution Semantic Occupancy Prediction [PDF](https://arxiv.org/pdf/2506.21185), [HTML](https://arxiv.org/abs/2506.21185)
### Authors
Yuheng Zhang,Mengfei Duan,Kunyu Peng,Yuhang Wang,Ruiping Liu,Fei Teng,Kai Luo,Zhiyong Li,Kailun Yang
### Background
3D语义占用预测对于自动驾驶至关重要，因为它提供了一个密集且语义丰富的环境表示。然而，现有方法主要关注于分布内的场景，使得它们容易受到分布外(OoD)对象和长尾分布的影响，增加了未检测异常和误解释的风险，从而带来安全隐患。
### Innovation
本文提出了一种分布外语义占用预测方法，以解决分布外对象检测的挑战。为此，作者提出了合成异常整合管道，用于在3D体素空间中注入合成异常，同时保留真实的空间和遮挡模式。此外，作者引入了OccOoD框架，在3D语义占用预测中结合分布外检测，并利用基于RWKV的分支实现几何-语义融合的体素-3D点鸟瞰图逐步融合方法(VBPF)来增强分布外检测。实验结果表明，OccOoD在1.2米区域内实现了最先进的分布外检测性能，AuROC为67.34%，AuPRCr为29.21%，同时保持了竞争力的占用预测性能。
### Conclusion
本文通过构建新的数据集VAA-KITTI和VAA-KITTI-360，以及提出OccOoD框架，显著改进了3D语义占用预测中的分布外检测效果。同时，作者将建立的数据集和源代码公开，以促进该领域的进一步研究。
## 333. `cs.CV` - 实时ESFP：估计、平滑、滤波和姿态映射 [PDF](https://arxiv.org/pdf/2506.21234), [HTML](https://arxiv.org/abs/2506.21234)
### Authors
Qifei Cui,Yuang Zhou,Ruichen Deng
### Background
本文介绍了一个名为ESFP的端到端管道，能够将单目RGB视频转换为低成本4-DoF桌面臂可执行的关节轨迹。该管道包含四个连续的模块，用于实现这一转换过程，提高了自动化和机器人的应用效率，特别是在基于视觉的控制和操作领域。
### Innovation
ESFP管道创新地使用ROMP估计24关节3D骨架，HPSTM模型结合长时序上下文和可微前向动能解码器，确保骨骼长度恒定和解剖学合理性。过滤模块依据HPSTM的不确定性评估对根正归一化轨迹进行加权，减少残余噪声。Pose-Mapping层将肩-肘-腕三元组映射到uArm的极坐标工作空间，保持手腕方向。这些创新显著提高了视频到机械臂控制的实时性和准确性。
### Conclusion
ESFP管道实现了从单目RGB视频到低成本4-DoF桌面臂的端到端关节轨迹生成。通过利用多模块架构和先进的平滑、滤波和映射技术，ESFP显著提高了时间效率和关节轨迹的精度。这对于提高基于视觉的控制和操作系统的性能具有重要意义。
## 334. `cs.CV` - 基于条件扩散变换器修复器的视频虚拟试穿 [PDF](https://arxiv.org/pdf/2506.21270), [HTML](https://arxiv.org/abs/2506.21270)
### Authors
Cheng Zou,Senlin Cheng,Bolei Xu,Dandan Zheng,Xiaobo Li,Jingdong Chen,Ming Yang
### Background
视频虚拟试穿旨在连续视频帧中自然地将服装贴合到目标人物上，这是一项挑战性的任务。一方面，输出的视频需要在时间和空间上一致性好；另一方面，需要在所有帧中保持良好地显示给定的服装细节。传统基于图像的试穿方法逐帧使用时，由于严重的一致性问题，结果往往较差。尽管最近有一些基于扩散的视频试穿方法提出，但在时间一致性方面仍存在问题。因此，需要一种新的方法来解决这些问题，如将视频试穿任务转换为基于条件的视频修复任务。
### Innovation
本文提出了一种名为ViTI（Video Try-on Inpainter）的方法，将视频虚拟试穿任务公式化并实现为基于条件的视频填充任务，这是与以前方法的不同之处。具体来说，他们构建了一个基于扩散变换器的视频填充框架，使用全3D空间-时间注意力机制，然后通过一系列掩码策略和多阶段训练逐步将该框架适应于视频服装填充任务。最后，通过服装条件的添加使得生成的服装外观和细节符合预期。
### Conclusion
定性和定量的实验结果显示，ViTI方法在处理视频虚拟试穿任务时比以往方法更具优势。
## 335. `cs.CV` - HumanOmniV2：从理解到跨模态推理 [PDF](https://arxiv.org/pdf/2506.21277), [HTML](https://arxiv.org/abs/2506.21277)
### Authors
Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou
### Background
随着多模态大型语言模型的迅速发展，人类意图的深度理解和解释能力已成为关键能力，这需要详细的推理过程。近期研究表明，强化学习（RL）在提高大型语言模型的推理能力方面具有潜在潜力。然而，将RL适应多模态数据和格式的挑战仍然未得到充分解决。现有研究中存在两个问题：全球上下文理解不足和捷径问题。全球上下文理解不足会导致模型误解释多模态上下文，产生错误答案；捷径问题则是模型忽视了多模态输入中的关键线索，直接回答问题而不考虑多模态信息。
### Innovation
本文识别并解决了现有的多模态推理模型中的两个问题：全球上下文理解不足和捷径问题。为了应对这些挑战，强调了模型在多模态输入中需要清晰理解全球上下文的重要性。通过一个由大型语言模型判断的上下文奖励，结合格式和准确性奖励，确保准确理解多模态上下文信息。此外，还引入了逻辑奖励，由大型语言模型评估推理过程是否成功整合了多模态信息和逻辑方法。提出了一个跨模态推理基准——IntentBench，旨在评估模型在理解复杂人类意图和情感方面的能力。所提出的方法在多个跨模态基准上展示了先进的性能，优于其他开源的跨模态模型。
### Conclusion
本文通过引入新的方法和基准，在跨模态推理方面取得了显著进展，为更深入理解和解释多模态数据提供了有效的策略。
## 336. `cs.CV` - BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models [PDF](https://arxiv.org/pdf/2506.21209), [HTML](https://arxiv.org/abs/2506.21209)
### Authors
Louis Kerner,Michel Meintz,Bihe Zhao,Franziska Boenisch,Adam Dziedzic
### Background
最新的文本转图像模型如Infinity能够以前所未有的速度生成极具真实的图像。这些模型以位级自回归的方式处理一个实际上是无限大的离散令牌集。然而，这种惊人的生成能力伴随着一个不断增长的风险：随着它们的输出越来越多地出现在互联网上，它们可能会被爬取和重新用作训练数据，甚至很可能被同一种模型重新利用。这种现象已经显示出会导致模型崩溃，即重复训练生成内容，特别是模型自己之前版本的内容，会导致性能逐渐下降。一种有前途的缓解策略是水印技术，它能够在生成的图像中嵌入人类不可感知但可检测的信号，从而能够识别生成内容。本文的研究背景是解决这一问题的方法之一。
### Innovation
本文介绍了一种名为BitMark的稳健的位级水印框架，用于Infinity模型。该方法在Infinity的图像生成过程中，直接在多个尺度（也被称为分辨率）的令牌流的位级别嵌入水印标记，这种方法微妙地影响位以保留视觉保真度和生成速度，同时能够抵抗各种去除技术的攻击，并且具有高度的放射性，即，当使用被BitMark标记的生成图像进行训练另一图像生成模型时，该第二模型的输出也将带有水印。即使只是对带有所标记的图像进行微调扩散或图像自回归模型，放射性痕迹也仍然可见。方法提供了基于水印的检测，从而能够可靠地检测生成输出，预防模型崩溃。
### Conclusion
本文提供了一种原理性的步骤，通过允许可靠检测生成输出，来预防图像生成模型中的模型崩溃。这种新方法可以在多个尺度嵌入水印，保持图像质量和速度的同时，使得水印难以被去除，并在反复训练过程中保持识别能力。
## 337. `cs.CV` - HieraSurg: 等级意识扩散模型在手术视频生成中的应用 [PDF](https://arxiv.org/pdf/2506.21287), [HTML](https://arxiv.org/abs/2506.21287)
### Authors
Diego Biagini,Nassir Navab,Azade Farshad
### Background
随着扩散模型在一般领域视频生成中的成功，手术视频合成已成为一个有前景的研究方向。现有的方法虽然能够生成高质量的视频，但大多数是无条件的，缺乏在手术动作和阶段之间保持一致性的能力，无法提供必要的手术理解和细粒度指导，以实现准确的模拟。这些不足正是本研究要克服的挑战。
### Innovation
提出了一种名为HieraSurg的手术视频生成框架，该框架由两个专门的扩散模型组成。首先，使用分割预测模型预测未来的粗粒度语义变化；随后，第二阶段模型通过将这些时间分割映射与细粒度视觉特征结合，生成最终视频。该模型利用了不同抽象级别中的手术信息，包括手术阶段、动作三元组和全景分割图。实验结果表明，HieraSurg在胆囊切除手术视频生成上显著优于先前的工作，不仅在定量上，还在定性上表现出更强的一般化能力和更高的帧率视频生成能力。
### Conclusion
HieraSurg在提供的现有分割图时展示了特别精细的适应性，这表明它在实际手术应用中具有潜在的应用前景。
## 338. `cs.CV` - WordCon: 字级排版控制在场景文本渲染中的应用 [PDF](https://arxiv.org/pdf/2506.21276), [HTML](https://arxiv.org/abs/2506.21276)
### Authors
Wenda Shi,Yiren Song,Zihan Rao,Dengming Zhang,Jiaming Liu,Xingxing Zou
### Background
在生成的图像中实现精确的字级排版控制仍是一个持续的挑战。为了应对这一挑战，我们构建了一个字级控制的场景文本数据集，并介绍了一个新的文本-图像对齐（TIA）框架。该框架利用文本和局部图像区域之间通过接地模型提供的跨模态对应关系，以增强文本到图像（T2I）模型的训练效果。此外，我们还提出了一种混合参数高效微调（PEFT）方法——WordCon。WordCon 重新参数化了选择性的关键参数，提高了效率和可移植性，使得无缝地集成到各种管道中成为可能，包括艺术文本渲染、文本编辑和图像条件下的文本渲染。为了进一步增强可控性，在潜在空间应用了遮罩损失以指导模型专注于学习图像中的文本区域；联合注意力损失提供了特征级监督，促进了不同单词间的分离。质性和定量结果显示了我们方法相对于现有技术的优势。相关数据集和源代码将供学术使用以促进进一步研究和应用开发。
### Innovation
我们提出了一种新的字级控制的场景文本数据集和文本-图像对齐（TIA）框架，该框架通过跨模态对应关系的利用，增强了T2I模型的训练。此外，我们还开发了一种名为WordCon的混合参数高效微调方法，该方法对部分关键参数进行了重新参数化，提高了模型的效率和可移植性。另外，通过遮罩损失和联合注意力损失的应用，进一步增强了模型的可控性，使研究者能够更容易地理解和控制生成图像中的文本布局。最后，模型的性能分析表明，所提出的方法在多个基准测试中表现优异。
### Conclusion
我们的方法在多种基准测试中都表现优于现有技术，并且相关数据集和源代码将提供给学术界用于进一步研究和技术开发。此研究验证了通过字级控制文本渲染能够获得更高质量的场景文本图像，为图像生成技术领域带来新的改进方向。
## 339. `cs.CV` - DuET: 无示例任务算术的双增量目标检测 [PDF](https://arxiv.org/pdf/2506.21260), [HTML](https://arxiv.org/abs/2506.21260)
### Authors
Munish Monga,Vishal Chudasama,Pankaj Wasnik,Biplab Banerjee
### Background
现有的目标检测系统，如自动驾驶和监视系统，需要持续学习新的目标类别并适应不断变化的环境条件。现有方法仅解决这一挑战的一个方面，即增量类别目标检测(CIOD)在未见过的域中表现薄弱；而增量域目标检测(DIOD)在学习新类别时会遇到灾难性遗忘的问题。这两种方法在实际应用中受到了限制。为了解决这些问题，我们引入了无示例双增量对象检测(DuIOD)，该方法能同时在无示例的条件下处理类别和域的变化，并使用基于任务算术的模型融合框架DuET，这种框架通过一种新型的方向一致性损失来缓解符号冲突，实现了稳定增量学习。DuET是一种检测器无关的方法，使得如YOLO和RT-DETR这样的模型能够作为实时增量目标检测器运行。为了全面评估保留性和适应性，我们提出了保留-适应性指数(RAI)这一指标，并进行了广泛的实验验证DuET的有效性。实验结果表明DuET在保留率和适应性上都优于现有方法。
### Innovation
1. 无示例双增量对象检测(DuIOD)框架，能够同时处理类别和域的变化；2. DuET基于任务算术的模型融合框架，通过方向一致性损失缓解符号冲突，实现稳定的增量学习；3. 提出了保留-适应性指数(RAI)，结合了灾难性遗忘和领域适应性两个方面的评估标准；4. DuET是检测器无关的方法，可以使用不同的检测器框架，如YOLO和RT-DETR，进行实时增量目标检测；5. 实验结果表明，DuET在保留率和适应性方面均优于现有方法，特别是在Pascal系列和多变天气系列数据集上的表现显著提升。
### Conclusion
我们的工作提出了一种新的方法DuET，通过任务算术框架解决了增量学习中的保留性和适应性问题，特别是在实时对象检测中实现了更好的性能。实验结果表明，DuET在多个数据集上均优于现有方法，推进了增量目标检测技术的实际应用。
## 340. `cs.CV` - 基于层级输入依赖状态空间模型的整体现手术阶段识别 [PDF](https://arxiv.org/pdf/2506.21330), [HTML](https://arxiv.org/abs/2506.21330)
### Authors
Haoyang Wu,Tsun-Hsuan Wang,Mathias Lechner,Ramin Hasani,Jennifer A. Eckhoff,Paul Pak,Ozanan R. Meireles,Guy Rosman,Yutong Ban,Daniela Rus
### Background
手术过程分析在机器人辅助手术中至关重要，但长时间的手术过程给全面的视频分析带来了重大挑战。现有的方法大多依赖于基于变换器的模型，但它们的二次注意力机制限制了对长视频的有效处理。
### Innovation
本文提出了一种新的层级输入依赖状态空间模型，利用状态空间模型的线性扩展特性，能够在处理完整视频时同时捕捉局部和全局动态。该框架结合了一个保证时间一致性的视觉特征提取器，将状态空间模型头部附加到视觉特征提取器，以传播时间信息。模型由两个关键模块组成：一个局部聚合状态空间模型块，有效捕捉复杂的局部动态，并且一个全局关系状态空间模型块，建模整个视频中的时间依赖关系。该模型通过一种混合离散-连续监督策略进行训练，两种信号都能够通过网络传递。实验结果显示，本文方法在Cholec80、MICCAI2016和Heichole数据集上均显著优于当前最先进的方法，精度分别提升了2.8%、4.3%和12.9%。
### Conclusion
所提议的方法在处理完整手术视频时表现优越，能够同时捕捉局部和全局动态，并通过混合监督策略进行有效训练，显著提升了手术阶段识别的准确性。
## 341. `cs.CV` - 遥感中带遮罩的自监督持续学习 [PDF](https://arxiv.org/pdf/2506.21312), [HTML](https://arxiv.org/abs/2506.21312)
### Authors
Lars Möllenbrok,Behnood Rasti,Begüm Demir
### Background
在遥感（RS）领域，持续学习（CL）方法的快速发展引起了广泛关注。这些方法旨在通过连续获取的训练数据逐步学习新任务，并且在学习新任务的同时增强对灾难性遗忘的鲁棒性。然而，这通常需要大量标记的训练样本，而在遥感中获取大量标记样本成本高且不总是可行的。为了解决这个问题，提出了一种新颖的自监督持续学习方法，称为CoSMAE，结合了数据混合与模型混合知识蒸馏来应对这一挑战。
### Innovation
该研究提出了一种在带有遮罩的自动编码器（MAE）中实现自监督持续学习的创新方法，即CoSMAE。该方法包括数据混合和模型混合知识蒸馏两部分。数据混合通过插值当前任务与先前任务的数据图像来保留先前数据分布的信息；模型混合知识蒸馏则是通过插值过去的模型权重和当前模型的权重来形成一个教师进行知识蒸馏。这两部分协同工作，以数据和模型层面限制MAE，从而提高跨任务的泛化能力和减少灾难性遗忘的风险。实验证明，CoSMAE相比现有的CL方法在MAE上取得了高达4.94%的显著改进。
### Conclusion
实验结果表明，CoSMAE在应用于MAE的CL方法中实现了显著的改进，最多可达4.94%。该研究已开源。
## 342. `cs.CV` - DrishtiKon: 多粒度视觉定位技术用于图文富文档图像 [PDF](https://arxiv.org/pdf/2506.21316), [HTML](https://arxiv.org/abs/2506.21316)
### Authors
Badri Vishal Kasuba,Parag Chaudhuri,Ganesh Ramakrishnan
### Background
文本富文档图像中的视觉定位是一项关键挑战，但对于文档智能和视觉问答(VQA)系统的研究尚处于起步阶段。这些系统需要准确地理解并定位文档中的关键视觉信息与文本内容之间的关系，特别是在复杂和多语言的文档中。当前的VQA系统在精细化的视觉定位方面仍需改进，特别是在准确性和可解释性方面。文章介绍了一种多粒度的视觉定位框架，旨在提升VQA系统的解释性和可信度，特别适用于复杂、多语言的文档场景。该框架结合了稳健的多语言OCR技术、大型语言模型和一种新颖的区域匹配算法，以在块、行、词甚至点级别准确地定位答案片段。此外，该研究还创建了一个新基准测试集，提供了多粒度的精细人类验证注释，以评估系统性能。
### Innovation
该研究提出了一种多粒度视觉定位框架，该框架结合了稳健的多语言OCR、大型语言模型和新颖的区域匹配算法，以实现不同粒度级别的精确视觉定位。该框架不仅在不同粒度级别上展示了优越的性能，还在多块和多行推理方面表现出优势，超越了现有的VQA系统。该研究还提出了一种新的基准测试集，以更好地评估VQA系统的性能。该研究不仅在技术上进行了创新，还提供了一个可用于进一步研究的可访问的代码和数据集，极大地推动了该领域的研究进展。
### Conclusion
该多粒度视觉定位框架显著提升了VQA系统的性能，特别是在细节级别的精准性和可解释性方面。通过创建一个新的基准测试集，该研究为未来的研究提供了宝贵的参考。通过对现有知名的VQA系统的评估，研究证实了该框架在准确视觉定位方面的有效性。该研究为实时场景中的文档理解系统的鲁棒性和可解释性开辟了新的路径。
## 343. `cs.CV` - LLaVA-Pose：通过关键点集成指令调优增强人体姿态和动作理解 [PDF](https://arxiv.org/pdf/2506.21317), [HTML](https://arxiv.org/abs/2506.21317)
### Authors
Dewen Zhang,Tahir Hussain,Wangpeng An,Hayaru Shouno
### Background
当前的视觉-语言模型（VLMs）适合通用视觉理解任务，但在处理与人体姿态和动作相关的复杂视觉任务时表现出不足，主要是因为缺乏专门的人体姿态和动作指令理解数据。论文提供了一种通过将人体关键点与传统的视觉特征，如描述和边界框结合，来生成这种数据的方法，以便更准确地理解人体中心场景。这种方法构建了一个专门针对人体中心任务调优的数据集，包含200,328个样本，集中在对话、详细描述和复杂推理三个方面。
### Innovation
介绍了生成用于人体姿态和动作理解的数据的方法，通过将人体关键点与传统视觉特征结合。提出了一个扩展的人体姿态和动作理解基准（E-HPAUB）来评估模型在人体姿态和动作理解上的性能，并使用此数据集对LLaVA-1.5-7B模型进行微调，得到的LLaVA-Pose模型在基准测试中表现出显著改进。实验结果显示，与原始的LLaVA-1.5-7B模型相比，整体改进达到33.2%。这强调了通过关键点集成数据增强多模态模型在人体中心视觉理解中的有效性。代码可在此链接获得：this https URL
### Conclusion
方法有效提升了视觉-语言模型在人体姿态和动作理解任务上的表现，并通过关键点集成数据显著增强了模型的准确性和理解能力。
## 344. `cs.CV` - 通用神经电磁反散射 [PDF](https://arxiv.org/pdf/2506.21349), [HTML](https://arxiv.org/abs/2506.21349)
### Authors
Yizhe Cheng,Chunxun Tian,Haoru Wang,Wentao Zhu,Xiaoxuan Ma,Yizhou Wang
### Background
电磁反散射问题（EISP）在医学成像等应用中至关重要，其目标是从散射的电磁场中重建相对介电常数。这一逆向过程本质上是病态的且高度非线性，极具挑战性。现有的机器学习方法虽有潜力，但存在需针对特定案例优化、泛化能力不足以及在稀疏发射器设置下性能不佳等问题。
### Innovation
从物理背景出发，改革BISP为两阶段逆传输-散射过程，揭示了诱发电流作为可泛化的中间表示，巧妙地解耦非线性散射过程与病态逆问题。提出一种两部分的通用物理驱动框架：电流估计器和介电常数求解器，以端到端的方式无缝结合。电流估计器通过明确学习散射场间物理桥梁的诱发电流，而介电常数求解器则直接从估计的诱发电流计算相对介电常数。确保对未见过的数据进行数据驱动的训练及前方泛化预测，同时具有强大的发射器稀疏性鲁棒性。实验表明，该方法在重建准确性、泛化能力和鲁棒性方面优于现有最佳方法。
### Conclusion
为电磁反散射提供了一种根本的新视角，为电磁成像提供了低成本的实际解决方案的关键一步。
## 345. `cs.CV` - ShotBench: 在视觉语言模型中的专家级电影理解 [PDF](https://arxiv.org/pdf/2506.21356), [HTML](https://arxiv.org/abs/2506.21356)
### Authors
Hongbo Liu,Jingwen He,Yi Jin,Dian Zheng,Yuhao Dong,Fan Zhang,Ziqi Huang,Yinan He,Yangguang Li,Weichao Chen,Yu Qiao,Wanli Ouyang,Shengjie Zhao,Ziwei Liu
### Background
电影摄影是电影的基本视觉语言，对于传达叙事、情感和美学质量至关重要。虽然最新的视觉-语言模型(VLMs)表现出强大的通用视觉理解能力，但它们理解和掌握嵌入在单个镜头中的细腻电影语法方面还存在严重不足，缺乏稳健的评估。这限制了细节视觉理解和AI辅助视频生成的精确度。由于缺乏这样的评估基准，使得当前的视觉语言模型无法充分展示其处理电影语言的能力。
### Innovation
作者介绍了一个专门设计用于电影语言理解的基准——ShotBench。它包含超过3500个由专家标注的问题-答案对，来自200多部奥斯卡提名作品，覆盖了八种关键的电影摄影维度。通过 ShotBench 对目前24个领先VLMs进行了评估，发现甚至连表现最好的模型平均准确率也低于60%，尤其在细粒度视觉线索和复杂的空间推理方面表现不佳。基于此，作者构建了一个大规模多模态数据集——ShotQA，并使用它开发了名为 ShotVL 的模型，通过有监督的微调和组相对策略优化。ShotVL 在 ShotBench 上的性能显著优于所有现有的开源和专有模型，从而确立了新的最先进的技术水平。
### Conclusion
作者开源了他们的模型、数据和代码，以促进这一领域中AI驱动的电影理解和生成的快速进步。
## 346. `cs.CV` - CA-I2P: 具有全局最优选择的通道自适应注册网络 [PDF](https://arxiv.org/pdf/2506.21364), [HTML](https://arxiv.org/abs/2506.21364)
### Authors
Zhixin Cheng,Jiacheng Deng,Xinjun Li,Xiaotian Yin,Bohao Liao,Baoqun Yin,Wenfei Yang,Tianzhu Zhang
### Background
目前的检测无感知方法通常采用从粗糙到精细的管道，从图像和点云特征中提取拼贴级别的匹配，并精炼密集的像素到点对应关系。然而，图像和点云之间特征通道注意力的差异可能导致匹配结果退化，最终影响配准精度。此外，场景中相似的结构可能导致跨模态匹配中产生冗余对应关系。因此，为了解决这些问题，本文提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强了内模特征并抑制了跨模态敏感性，而GOS则用全局优化取代局部选择。在RGB-D 场景V2和7-场景上进行的实验表明，该方法具有优越性，在图像到点云配准中达到了最新的技术水平。
### Innovation
本文提出了一种具有全局最优选择的通道自适应注册网络，通过引入CAA和GOS模块来增强内模特征并抑制跨模态敏感性，解决了图像和点云特征通道注意力差异以及跨模态匹配中冗余对应关系的问题，提升了配准精度和效果。
### Conclusion
在RGB-D 场景V2和7-场景的实验中，CA-I2P方法展示了卓越的性能，在图像到点云配准中达到了最新的技术水平。
## 347. `cs.CV` - CoPa-SG: 带有参数和原型关系的密集场景图 [PDF](https://arxiv.org/pdf/2506.21357), [HTML](https://arxiv.org/abs/2506.21357)
### Authors
Julian Lorenz,Mrunmai Phatak,Robin Schön,Katja Ludwig,Nico Hörmann,Annemarie Friedrich,Rainer Lienhart
### Background
2D场景图提供了一种结构化和可解释的框架，用于理解场景。然而，目前的工作还在努力克服缺乏准确场景图数据的难题。为了克服这一数据瓶颈，我们提出了CoPa-SG，这是一个合成场景图数据集，具有高度精确的地面truth和详尽的物体间关系标注。此外，我们引入了参数化关系和原型关系两种场景图的新基本概念。前者通过增加角度或距离等额外参数，提供了比传统概念更精细的表示。后者在场景图中编码假设关系，并描述在场景中放置新对象时，关系如何形成。
### Innovation
本文提出CoPa-SG，一个合成场景图数据集，具有高度精确的地面truth和详尽的物体间关系标注。引入了参数化关系和原型关系两种新概念，分别提供了更精细的关系表示和场景关系假设描述。利用CoPa-SG，比较了各种场景图生成模型的性能，并展示了新关系类型如何整合到下游应用中以增强规划和推理能力。
### Conclusion
通过CoPa-SG，我们比较了不同场景图生成模型的性能，并验证了集成新关系类型可以在下游应用中增强规划和推理能力。
## 348. `cs.CV` - ToosiCubix：基于车辆部件标注的单目3D立方体标注 [PDF](https://arxiv.org/pdf/2506.21358), [HTML](https://arxiv.org/abs/2506.21358)
### Authors
Behrooz Nasihatkon,Hossein Resani,Amirreza Mehrzadian
### Background
当前许多用于车辆3D立方体标注的方法依赖于昂贵且需要精确校准的相机-LiDAR或立体视觉设置，这限制了其在大规模数据收集中的可获取性。现有的方法需要精细的设备和复杂的设置，导致了较高的成本和使用门槛，且限制了标注的灵活性和适用范围。因此，迫切需要一种简单且高效的方法，以降低标注成本并提高精度和效率，特别是在大规模数据集中。本研究解决的问题是如何在无需昂贵硬件的情况下，能够准确地进行3D立方体标注，以应用于现有的大规模数据集。
### Innovation
ToosiCubix提出了一种新的基于单目图像和内嵌相机参数进行3D立方体标注的方法。该方法只需要大约10次用户点击即可注释每辆车辆的立方体，大大简化了标注过程。通过注释车辆的特定特征（例如车轮、车辆标识和对称性）并使用几何约束优化，能够精确估计车辆的位置、姿态和尺寸。为了处理常见的尺度和未观察到的尺寸的不确定性，该方法引入了概率尺寸先验，使得注释的自由度增加到9个。该方法使用坐标下降策略交替解决求解问题，从而能够有效地克服标注过程中遇到的几何精度问题，不仅实现了高质量的3D立方体标注，也提高了成本效益和规模化的可行性。
### Conclusion
该研究通过大规模数据集验证了ToosiCubix方法的有效性和实用性。结果表明，该方法能够提供一种低成本且可扩展的解决方案，以进行高质量的3D立方体标注，为大规模数据集的标注提供了新的思路和方法。此外，这种方法还能够减少对昂贵设备的依赖，提高自动驾驶汽车等应用中的3D立方体标注效率和精度，从而推动相关领域的研究和发展。
## 349. `cs.CV` - PanSt3R：多视图一致全景分割 [PDF](https://arxiv.org/pdf/2506.21348), [HTML](https://arxiv.org/abs/2506.21348)
### Authors
Lojze Zust,Yohann Cabon,Juliette Marrie,Leonid Antsfeld,Boris Chidlovskii,Jerome Revaud,Gabriela Csurka
### Background
全景分割3D场景的问题，包括场景的密集3D重建中的对象实例分割和分类，是一个具有挑战性的任务，尤其是在仅依赖未布置的2D图像的情况下。现有的方法通常利用现成的模型提取每帧的2D全景分割，然后优化潜在的几何表示（往往基于NeRF）以整合和融合2D预测。这些方法依赖于2D全景分割对固有的3D和多视图问题，这可能降低了空间关系的潜力，且往往需要在每个场景中进行计算昂贵的测试时间优化。
### Innovation
本文提出了一种集成的统一方法PanSt3R，通过在一个前向传递过程中同时预测3D几何和多视图全景分割，从而消除了测试时间优化的需求。该方法基于最近在3D重建方面的进展，特别是可扩展的多视图版本的MUSt3R，并增加了语义感知和多视图全景分割的能力。此外，还重新审视了标准的后处理掩模合并过程，并引入了更原则的多视图分割方法。还提出了一个简单的基于PanSt3R和vanilla 3DGS产生新颖视图预测的方法。
### Conclusion
所提出的PanSt3R是一个概念简单且快速可扩展的方法，实现了多个基准上的最佳性能，并且比现有方法快数万倍。
## 350. `cs.CV` - XVerse：通过DiT调制实现一致的多主体身份和语义属性控制 [PDF](https://arxiv.org/pdf/2506.21416), [HTML](https://arxiv.org/abs/2506.21416)
### Authors
Bowen Chen,Mengyi Zhao,Haomiao Sun,Li Chen,Xu Wang,Kang Du,Xinglong Wu
### Background
现有技术在实现多主体精细控制时，通常会降低编辑性和连贯性，导致生成的图像中出现伪影或属性纠缠。多数方法在处理多主体时，难以保持各主体间的一致性和形象的一致性，影响了生成图像的质量和多样性，尤其是在实现特定样态（如姿态、风格、照明）的独立精细控制方面存在挑战。
### Innovation
作者提出了一种名为XVerse的新模型，在扩散变压器（DiTs）的调制中，将参考图像转换为针对特定标记的文本流调制偏移，从而实现对多主体的精准和独立控制，而不破坏图像潜象或特征。这个方法不仅保证了各个主体的高质量生成，还增强了个性化和复杂场景的生成能力，显著改善了多主体身份和语义属性的控制效果。
### Conclusion
XVerse模型通过DiT调制实现多主体身份和语义属性的精确控制，提供高保真、可编辑的多主体图像合成，有效解决了现有技术中的编辑性、连贯性和个性化生成的挑战，极大提高了生成图像的质量和多样性。
## 351. `cs.CV` - HyperSORT：使用超网络实现自我组织稳健训练 [PDF](https://arxiv.org/pdf/2506.21430), [HTML](https://arxiv.org/abs/2506.21430)
### Authors
Samuel Joutard,Marijn Stollenga,Marc Balle Sanchez,Mohammad Farid Azampour,Raphael Prevost
### Background
医学影像数据集通常包含各种偏差，这些偏差从错误的标签到不一致的标注风格不等。这些偏差可能会对深度分割网络的性能产生负面影响。然而，识别和描述这些偏差是一个特别繁琐且具有挑战性的问题。本文作者提出了一种名为HyperSORT的方法，利用一个超网络从表示图像和注释变化的潜在向量中预测UNets的参数。
### Innovation
HyperSORT框架采用一个超网络，从表示图像和注释变化的潜在向量中预测UNets的参数。超网络的参数和用于每个训练集样本的潜在向量集合是共同学习的。这种方法通过学习复杂分布的UNet参数，在低密度区域捕捉噪声特定的模式，同时在不同的、有重要意义的情况下进行稳健的器官分割。实验验证了该方法在两个3D腹部CT公共数据集上的有效性，结果显示HyperSORT能够创建一个结构化的数据集映射，有助于识别系统偏差和错误样本，并发现符合学习到的系统偏差的UNet参数。
### Conclusion
HyperSORT方法通过学习复杂参数分布，能够识别并区分不同类型的偏差模式，提高分割模型的鲁棒性和准确性。
## 352. `cs.CV` - FastRef: 快速原型精炼用于少量样本工业异常检测 [PDF](https://arxiv.org/pdf/2506.21398), [HTML](https://arxiv.org/abs/2506.21398)
### Authors
Long Tian,Yufei Li,Yuyang Dai,Wenchao Chen,Xiyang Liu,Bo Chen
### Background
在数据稀缺环境中，实现自动化检测系统进行小样本工业异常检测至关重要。现有方法主要集中在从有限的正常样本中提取原型，但通常忽略了通过查询图像统计信息系统地提高原型代表性的必要性。这导致了原型代表性的不足，从而影响了异常检测的性能。因此，本文介绍了一种名为FastRef的新颖且高效的原型精炼框架，以解决上述问题并提高少量样本工业异常检测的性能和效率。
### Innovation
FastRef提出了一种迭代的两阶段过程：首先是通过可优化的变换矩阵将查询特征的特征转移到原型，其次是通过原型对齐抑制异常。为了实现特征转移，通过线性重建查询特征从原型；而为了解决小样本环境中异常重建更有可能的观察，采用最优传输（OT）来度量和最小化原型及其精炼版本之间的差距，进行异常抑制。此外，通过FastRef与PatchCore、FastRecon、WinCLIP和AnomalyDINO三种竞争的基于原型的少数样本工业异常检测方法进行集成，该方法在MVTec、ViSA、MPDD和RealIAD四个基准数据集上的实验结果证明了其有效性与计算效率，尤其在1/2/4样本条件下表现尤为显著。
### Conclusion
FastRef为少数样本工业异常检测提供了一种高效、准确的原型精炼方法，通过迭代优化过程提高原型代表性和抑制异常，证明了在多个基准数据集上的卓越性能和计算效率。
## 353. `cs.CV` - GenFlow: 交互式模块化系统用于图像生成 [PDF](https://arxiv.org/pdf/2506.21369), [HTML](https://arxiv.org/abs/2506.21369)
### Authors
Duc-Hung Nguyen,Huu-Phuc Huynh,Minh-Triet Tran,Trung-Nghia Le
### Background
生成艺术蕴含无限创造力，但由于高级建筑概念和计算工作流所需的高技术专业知识，其潜力尚未被充分利用。为了解决这一问题，我们需要一个使所有技能水平的用户都能轻松精确地生成图像的新型模块化框架来构建复杂的生成艺术工具。
### Innovation
GenFlow 提出了一种基于节点的编辑器供无缝自定义，配有自然语言处理驱动的智能助手，将复杂的流程创建工作转化为直观易用的体验。通过自动化部署过程来减少技术障碍，GenFlow 让最先进的生成艺术工具惠及所有人。用户研究显示，GenFlow 能够优化工作流程、减少任务完成时间，并通过直观界面和适应性功能增强用户理解，从而使其成为一个革命性的解决方案，重新定义了生成艺术领域中的可访问性和效率。
### Conclusion
GenFlow 是一种开创性的解决方案，重新定义了生成艺术领域中的可访问性和效率。
## 354. `cs.CV` - EndoFlow-SLAM:基于流约束高斯点云实时内窥镜SLAM [PDF](https://arxiv.org/pdf/2506.21420), [HTML](https://arxiv.org/abs/2506.21420)
### Authors
Taoyu Wu,Yiyi Miao,Zhuoxiao Li,Haocheng Zhao,Kang Dang,Jionglong Su,Limin Yu,Haoang Li
### Background
在内窥镜等手术场景中，高效的三维重建和实时可视化至关重要。近年来，3D Gaussian Splatting（3DGS）方法在3D重建和渲染方面表现出色，但大多数3DGS基础上的同步定位与 mapping（SLAM）方法仅依赖于外观约束来优化3DGS和相机轨迹。然而，在内窥镜场景中，非朗伯表面导致的光度不一致性和呼吸动态运动会对SLAM系统性能造成影响。
### Innovation
为解决这些问题，该研究引入了光流损失作为几何约束，有效地限制了场景3D结构和相机运动。此外，提出了一种深度规约策略，以减轻光照不一致问题，并确保3DGS深度渲染在整个内窥镜场景的有效性。针对子最优渲染质量的关键帧，改进了3DGS细化策略，改进了场景表示。具体表现为在C3VD静态数据集和StereoMIS动态数据集上的广泛实验中，所提出的方法在新颖视图合成和姿态估计方面优于现有最先进的方法，展现出在静态和动态手术场景中的高性能。
### Conclusion
该方法在新颖视图合成和姿态估计方面优于现有最先进的方法，在静态和动态手术场景中表现出高效率。源代码将在论文接受后公开。
## 355. `cs.CV` - 通过低频重新思考无分类器指导中的过度饱和 [PDF](https://arxiv.org/pdf/2506.21452), [HTML](https://arxiv.org/abs/2506.21452)
### Authors
Kaiyu Song,Hanjiang Lai
### Background
在条件扩散模型中，分类器免费指导（CFG）通过指导尺度来平衡条件和非条件术语的影响，高指导尺度提升了条件术语的表现，但同时也导致过度饱和和不现实的伪影。研究指出低频信号中累积的冗余信息是导致这些问题的关键因素。基于这一洞见，本文提出了低频改进分类器免费指导（LF-CFG）方法，以减轻这些问题。
### Innovation
提出了一种适应性阈值测量方法，用于定位低频信号中的冗余信息，并通过分析前一步骤和当前步骤间低频信息的变化率来确定合理的阈值。之后，通过应用降权策略减少低频信号中冗余信息的影响。这种方法在各种扩散模型中均表现出对过度饱和和不现实伪影的有效缓解效果，包括Stable Diffusion-XL, Stable Diffusion 2.1, 3.0, 3.5和SiT-XL。
### Conclusion
实验结果表明，LF-CFG 有效地缓解了各种扩散模型中的过度饱和和不现实伪影问题。
## 356. `cs.CV` - 基于3D参数曲面的双向耦合高斯分布拟合方法 [PDF](https://arxiv.org/pdf/2506.21401), [HTML](https://arxiv.org/abs/2506.21401)
### Authors
Zhirui Gao. Renjiao Yi,Yaqiao Dai,Xuening Zhu,Wei Chen,Chenyang Zhu,Kai Xu
### Background
现有方法通常采用两阶段流程，先从多视角边缘图重建点云，再拟合参数化曲线，这种两阶段方法容易累积误差。现有的研究通常关注边缘点云和参数化曲线的优化，并且需要保持几何属性的同时能够进行可微渲染，因此需要一种能够直接优化参数化曲线的方法，结合边缘意识的高斯分布表示，以实现多视图证据指导下的直接优化。
### Innovation
提出了一种新颖的双向耦合机制，将参数化曲线与边缘定向的高斯成分结合起来，构造了一个曲线意识的高斯表示（CurveGaussian），使3D曲线的可微渲染成为可能，能够直接优化由多视角证据提供的参数化曲线。还引入了一种动态自适应拓扑优化框架，在训练过程中通过线性化、合并、分裂和修剪操作细化曲线结构，这种方法在细节和鲁棒性方面优于现有的两阶段方法，同时在训练过程中显著减少了参数数量，提高了效率和性能。
### Conclusion
在ABC数据集和现实基准上的全面评估表明，一阶段方法优于两阶段方法，特别是在生成更清洁、更稳健的重建方面有优势。通过直接优化参数化曲线，实现了更高的效率和更好的性能，与现有方法相比具有显著优势。
## 357. `cs.CV` - 跨数据集评估深度学习和视觉基础模型在异常和正常细胞分裂分类中的基准研究 [PDF](https://arxiv.org/pdf/2506.21444), [HTML](https://arxiv.org/abs/2506.21444)
### Authors
Sweta Banerjee,Viktoria Weiss,Taryn A. Donovan,Rutger A. Fick,Thomas Conrad,Jonas Ammeling,Nils Porsche,Robert Klopfleisch,Christopher Kaltenecker,Katharina Breininger,Marc Aubreville,Christof A. Bertram
### Background
异常有丝分裂标志着细胞分裂过程的偏差，可能是肿瘤恶性程度的独立预后相关标志。然而，其识别具有挑战性，原因在于其低发病率、正常有丝分裂有时细微的形态差异、病理科医生之间的低一致性评分以及数据集中的类别不平衡。基于乳腺癌的异常有丝分裂数据集（AMi-Br），本文对比了深度学习方法在自动异常有丝分裂图（AMF）分类上的基准性能，包括基线模型、带有线性探针的基础模型以及通过低秩适应（LoRA）方式进行微调的基础模型。为了严谨地评估，进一步引入了两个新的留出数据集——AtNorM-Br（来自TCGA乳腺癌队列的有丝分裂数据集）和AtNorM-MD（来自MIDOG++训练集的多领域有丝分裂数据集）。
### Innovation
使用跨数据集评估方法，对比了深度学习和视觉基础模型在异常和正常细胞分裂分类上的性能。引入了新的数据集AtNorM-Br和AtNorM-MD，以增强模型的泛化能力。此外，使用低秩适应（LoRA）方法对多种基础模型进行微调，展示了较优的结果，特别是对Virchow系列基础模型的LoRA适应表现突出。该研究通过使用迁移学习和模型微调技术有效解决了异常有丝分裂分类的难题，并提供了可复现的代码和数据存储库。
### Conclusion
异常细胞分裂分类问题虽然具有挑战性，但通过最新迁移学习和模型微调技术的有效应用，可以得到有效的解决。研究展示了在跨数据集评估下的优越性能，强调了LoRA方法在基础模型微调中的潜力，并提供了广泛的可复现资源。
## 358. `cs.CV` - Logios：开源希腊多音节光学字符识别系统 [PDF](https://arxiv.org/pdf/2506.21474), [HTML](https://arxiv.org/abs/2506.21474)
### Authors
Perifanos Konstantinos,Goutsos Dionisis
### Background
目前，传统的光学字符识别（OCR）方法在识别和数字化希腊多音节文本时存在一定的局限性，这导致了准确性和效率上的挑战。因此，迫切需要一个专门用于准确识别和数字化希腊多音节文本的OCR系统，以克服现有技术的不足，提高识别精度和处理效率。
### Innovation
该系统利用卷积层进行特征提取和循环层进行序列学习的结合，专门针对希腊多音节脚本的独特挑战。与传统的OCR方法相比，该系统在准确性和效率上提供了显著的改进。该论文还释放了底层模型的开源库，并为其OCR平台提供学术用途免费使用，这使得研究者能够更好地进行相关研究和应用开发。
### Conclusion
该论文提出了一种专门用于准确识别和数字化希腊多音节文本的OCR系统。通过结合卷积层和循环层，该系统能够有效应对希腊多音节脚本的挑战，显著提高了识别精度和效率。该系统已作为开源库发布，并免费提供给学术用途使用，为相关领域的研究和应用开发提供了有力支持。
## 359. `cs.CV` - 每日交通流量的交通信号评估 [PDF](https://arxiv.org/pdf/2506.21469), [HTML](https://arxiv.org/abs/2506.21469)
### Authors
Mohammad Shokrolah Shirazi,Hung-Fu Chang
### Background
交叉口循环车流数据对于交通信号设计、交叉口几何规划、交通流量分析和拥堵分析至关重要。本文采用基于转弯运动计数（TMC）的动态、静态和混合三种配置方法，利用视野跟踪系统在拉萨加斯的六个交叉口进行估算，并使用兼容格式的交叉口设计、路线和信号配置文件，导入了具有真实数据的Urban Mobility仿真工具以进行信号评估。研究表明，循环时间为90秒和120秒对所有交叉口来说表现最佳。同时，高峰时段和非高峰时段交错的双向交通流量模式下，建议使用在高负载交通条件下效果更佳的混合信号方法.
### Innovation
本文的主要创新在于提出了一种基于转弯运动计数的动态、静态和混合三种配置方法，利用视野跟踪系统和真实的交通摄像头数据，在六个交叉口进行车辆追踪并实施仿真评估。此外，对于每日具有双峰模式的交通流量，提出了利用动态与静态方法切换的混合信号方法，从而更好地适应高峰和非高峰时段的交通管理需求.
### Conclusion
在超过6个交叉口的4小时仿真时间内，基于区段的交通流量分布形式对信号设计选择有显著影响。对于均匀分布的交通流量，静态方法表现最佳；而对于交通流量较高的区段，混合方法则表现更好。
## 360. `cs.CV` - 自然世界图像中的全局与局部蕴含学习 [PDF](https://arxiv.org/pdf/2506.21476), [HTML](https://arxiv.org/abs/2506.21476)
### Authors
Srikumar Sastry,Aayush Dhakal,Eric Xing,Subash Khanal,Nathan Jacobs
### Background
在视觉-语言模型中学习数据的分层结构是一项重大挑战。先前的工作尝试通过利用蕴含学习来解决这一挑战，但是这些方法未能显式地建模蕴含的传递性，这将在表示空间中建立顺序和语义之间的关系。
### Innovation
本文引入了一种名为径向跨模态嵌入（RCME）的框架，该框架能够实现传递性增强的蕴含的显式建模。提出的框架优化了视觉-语言模型中概念的部分顺序。通过利用本框架，我们开发了一种具有分层结构的视觉-语言基础模型，能够表示生命之树中的分层关系。我们的实验在分层物种分类和分层检索任务上显示了与现有最佳模型相比的增强性能。
### Conclusion
我们的模型和代码已开源。
## 361. `cs.CV` - TITAN: 基于查询-标记的领域自适应对抗学习 [PDF](https://arxiv.org/pdf/2506.21484), [HTML](https://arxiv.org/abs/2506.21484)
### Authors
Tajamul Ashraf,Janibul Bashir
### Background
在源数据不可用的情况下进行领域自适应物体检测（SF-DAOD），大多数现有方法使用学生-教师（ST）框架，通过预训练模型生成伪标签进行进一步的微调。然而，学生模型的性能经常由于伪标签的高度噪声（主要来自领域偏差、不一致性以及领域间的显著偏移）而大幅下降。通过了解检测结果中的高方差与更高的召回率以及与源域的更大相似性之间的联系，该研究旨在通过提出基于目标的迭代查询-标记对抗网络（TITAN）解决这一难题，该网络将目标图像划分为相似于源图像（容易）和不相似于源图像（困难）的两类，利用这些信息来辨别目标域。此外，该研究引入基于查询-标记的对抗模块到学生-教师基础框架中，减少两个特征表示之间的领域差距。
### Innovation
提出了基于目标的迭代查询-标记对抗网络（TITAN），通过伪标签生成、高质量数据集划分策略以及对抗模块的应用，解决了因高度噪声伪标签导致的学生模型性能下降的问题。TITAN通过引入基于查询-标记的对抗模块，有效地减少了两个特征表示之间的领域差距，从而提高了模型的适应性。实验结果显示，TITAN在四个自然图像数据集和两个具有挑战性的医学数据集上优于现有最先进的方法，分别在C2F, C2B, S2C, K2C基准上分别提升了22.7%, 22.2%, 21.1%和3.7%的mAP。
### Conclusion
TITAN方法通过针对性地处理伪标签噪声和领域差距问题，显著提升了源数据不可用情况下的域自适应物体检测性能，为这一领域提供了新的解决方案和方法论。
## 362. `cs.CV` - G$^{2}$D: 通过梯度引导蒸馏提升多模态学习 [PDF](https://arxiv.org/pdf/2506.21514), [HTML](https://arxiv.org/abs/2506.21514)
### Authors
Mohammed Rakib,Arunkumar Bagavathi
### Background
多模态学习旨在综合利用不同数据模态的信息以达成更全面的表现。然而，传统的多模态模型常受模态不平衡的影响，导致部分或少数模态主导模型优化，使得特征表示不佳且弱模态被严重忽视。
### Innovation
我们提出了梯度引导蒸馏（G$^{2}$D），这是一种知识蒸馏框架，通过自定义融合单模态和多模态目标的损失函数优化多模态模型。G$^{2}$D还引入了一种动态序列模态优先级（SMP）技术，在学习过程中确保每个模态都能在学习过程中占主导地位，从而避免强模态压制弱模态的问题。
### Conclusion
我们在多个真实世界的数据集上验证了G$^{2}$D，证明了它在训练过程中可以放大弱模态的重要性，并在分类和回归任务中优于现有最先进的方法。我们的代码已在此处可用：this https URL.
## 363. `cs.CV` - GGTalker: 使用通用高斯先验和个体特定适应的说话头合成 [PDF](https://arxiv.org/pdf/2506.21513), [HTML](https://arxiv.org/abs/2506.21513)
### Authors
Wentao Hu,Shunkai Li,Ziqiao Peng,Haoxian Zhang,Fan Shi,Xiaoqiang Liu,Pengfei Wan,Di Zhang,Hui Tian
### Background
创建高质量、通用性强的语音驱动的3D说话头依然是一个持续的挑战。尽管以前的方法在固定视角和小范围音频变化方面能取得满意的结果，但对于大范围头部旋转和未知分布的音频，依然难以处理。此外，这些方法受到需要耗时的、针对身份的训练的限制。我们相信根本问题在于缺乏足够的3D先验知识，这限制了合成说话头的外推能力。
### Innovation
我们提出GGTalker，通过结合通用先验和个体特定适应来合成说话头。引入了两阶段的先验-适应训练策略来学习高斯头部先验并适应个体特征。训练了音频表达和表情视觉先验以捕捉嘴唇运动的普遍模式和头部纹理的总体分布。在定制适应阶段，精确建模了个人表达风格和纹理细节。此外，我们引入了颜色MLP来生成细粒度、运动对齐的纹理，并引入了Body Inpainter将渲染结果与背景融合，生成难以分辨的、光线逼真的视频帧。
### Conclusion
全面的实验表明，GGTalker在渲染质量、3D一致性、唇型同步准确性和训练效率方面均达到最先进的水平。
## 364. `cs.CV` - 通过动态 logits 校准减少大型视觉语言模型的幻觉 [PDF](https://arxiv.org/pdf/2506.21509), [HTML](https://arxiv.org/abs/2506.21509)
### Authors
Jiahe Chen,Jiaying He,Qian Shao,Qiyuan Chen,Jiahe Ying,Hongxia Xu,Jintai Chen,Jianwei Zheng,Jian Wu
### Background
大型视觉语言模型（LVLMs）在多模态理解方面取得了显著进展，但它们经常受到幻觉问题的困扰，即生成与视觉输入相矛盾的文本。现有无训练集的解码策略存在静态约束固定、无法适应生成过程中的语义漂移、需要多次前向传播导致效率低下以及因规则过于僵硬导致细节失真等问题。
### Innovation
本文提出了动态 logits 校准（DLC），这是一种新颖的无训练集解码框架，在推理时动态调整文本生成与视觉证据的对齐。在解码阶段，DLC 逐步使用 CLIP 来评估输入图像与生成文本序列之间的语义对齐，并评估候选词的相对视觉优势（RVA）与动态更新的上下文基线，从而自适应地调整输出 logits 以倾向于视觉上合理的词。此外，算法还通过实时上下文对齐分数进行自适应加权机制，平衡视觉指导与文本输出的整体质量。广泛的实验证明，DLC 能够显著减少幻觉，效率高且无须多次前向传播。
### Conclusion
本文提供了一种有效的在解码时减少幻觉的方案，从而提升 LVLMs 的可靠性，更适用于各种实践场景。相关代码将于 GitHub 上开源。
## 365. `cs.CV` - 使用场景感知扩散模型实现可控三维物体放置 [PDF](https://arxiv.org/pdf/2506.21446), [HTML](https://arxiv.org/abs/2506.21446)
### Authors
Mohamed Omran,Dimitris Kalatzis,Jens Petersen,Amirhossein Habibian,Auke Wiggers
### Background
随着强大文本条件生成模型的出现，图像编辑方法变得更为强大和灵活。然而，将物体放置在环境中并具有精确位置和方向仍然是一项挑战。这通常需要精心设计的修补蒙版或提示。我们的研究使用精心设计的视觉图以及粗略的对象蒙版，表明它们足以实现高质量的物体放置。通过基于修补模型的设计，我们保留了背景不变，而不同于同时建模对象和背景的方法。我们在汽车领域展示了该方法的有效性，包括设计评估编辑质量的任务，不仅考虑外观，还考虑姿态和位置准确性，包括需要非平凡形状变化的情况。此外，我们展示了精细位置控制可以与外观控制相结合，在场景中精确放置现有物体的功能。
### Innovation
我们设计了一种条件信号来解决歧义性，同时足够灵活以允许形状或物体姿态的变化。通过基于修补模型的设计，我们保留了背景不变，与同时建模对象和背景的方法不同。我们的方法在汽车场景中被证明是有效的，包括设计测试集以评估编辑质量，不仅考虑外观，还考虑姿态和位置准确性，包括需要非平凡形状变化的情况。最后，我们展示了可以将精细位置控制与外观控制相结合，在场景中精确放置现有物体的功能
### Conclusion
我们的研究证明了使用精心设计的视觉图和粗略对象蒙版实现高质量物体放置的有效性。我们展示了一种新的条件信号有助于解决形状或姿态变化的灵活性，同时保持了背景的完整性。我们的方法在汽车场景中的测试中被证明了其有效性，包括评估要考虑到多种因素的编辑质量，如形状、姿态和位置准确性。最后，我们的研究表明可以将位置控制与外观控制相结合来实现精准的物体放置。
## 366. `cs.CV` - MADrive: 基于内存增强的驾驶场景建模 [PDF](https://arxiv.org/pdf/2506.21520), [HTML](https://arxiv.org/abs/2506.21520)
### Authors
Polina Karpikova,Daniil Selikhanovych,Kirill Struminsky,Ruslan Musaev,Maria Golitsyna,Dmitry Baranchuk
### Background
近年来，场景重建技术取得了显著进展，使用3D高斯点进行自动驾驶（AD）环境的高真实性建模。然而，当前重建结果仍然受限于原始观测，难以支持显著改变或全新驾驶场景的逼真合成。
### Innovation
该论文提出了MADrive，一种基于内存增强的重建框架，通过从大规模外部内存库中提取与观察车辆视觉相似的3D资产来增强现有场景重建方法的能力。特别地，作者发布了MAD-Cars数据集，涵盖约70K的真实360度车辆视频，并提出了一种检索模块来找到内存库中最相似的车辆实例，从视频中重建对应的3D资产，并通过方向对齐和重新光照将其整合到目标场景中。
### Conclusion
通过这些替换，可以提供场景中车辆的完整多视角表示，从而实现大幅改变配置的逼真合成，这一点在实验中得到了验证。
## 367. `cs.CV` - 全面的地下矿工检测多样场景数据集 [PDF](https://arxiv.org/pdf/2506.21451), [HTML](https://arxiv.org/abs/2506.21451)
### Authors
Cyrus Addy,Ajay Kumar Gurumadaiah,Yixiang Gao,Kwame Awuah-Offei
### Background
地下采矿作业面临重要的安全挑战，这就使得应急响应能力至关重要。尽管机器人在辅助搜救方面展示出了潜力，但它们的有效性取决于可靠矿工检测技术的支持。深度学习算法为自动化的矿工检测提供了可能的解决方案，但缺乏适用于地下采矿环境的全面培训数据集。为此，本文提出了一种针对地下矿工检测系统潜在应急应用的全新热成像数据集，以便为检测算法的开发和验证奠定坚实的基础。这是通过系统地获取各种采矿活动和场景的热图像来实现的。该论文通过评估包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的先进的目标检测算法来建立基线性能指标，这进一步证明了热成像在矿工检测中的可行性，并为在实际应急场景中部署此类系统奠定了基础。
### Innovation
本文提出的一个创新点是设计了一套针对地下矿工检测系统潜在应急应用的新型热成像数据集，填补了地下采矿环境中有效矿工检测数据集的空白，从而为检测算法的开发和验证提供坚实的基础。该数据集涵盖了广泛的采矿活动和场景，旨在为后续研究奠定基础，以开发可靠且能在真正紧急情况下部署的热成像矿工检测系统。
### Conclusion
本文通过提供一个全面的地下矿工检测多样场景数据集，证明了热成像技术在矿工检测中的可行性，并建立了未来在这一关键安全应用中进行研究的基础。
## 368. `cs.CV` - 基于条件标记点过程的空旷区域可靠检测 [PDF](https://arxiv.org/pdf/2506.21486), [HTML](https://arxiv.org/abs/2506.21486)
### Authors
Tobias J. Riedlinger,Kira Maag,Hanno Gottschalk
### Background
深度神经网络已经在计算机视觉任务，如边界框检测和语义分割中达到了最先进的水平。对象检测器和分割模型为预测分配置信度分数，反映模型在对象检测或像素级分类中的不确定性。然而，这些置信度估计通常是失标的，因为它们的架构和损失函数是针对任务性能优化的，而非基于概率基础。即使预测是校准良好的，对象检测器也无法量化检测区域外的不确定性，即在未检测到对象的区域，模型未能提供这些区域是否真正无物体的概率评估。这种不确定性在自动驾驶等安全性要求高的应用中构成了风险，因为未检测区域的不确定性尚未被充分探索。现有方法在这一点上是不足的，代码中的背景信息主要是描述了当前技术的局限性，特别是关于不确定性量化方面的问题。
### Innovation
本文提出了一种基于空间统计的对象检测模型。边界框数据匹配点过程的现实化，常用来描述空间点事件（即边界框中心）的随机发生，其中标记用于描述边界盒的范围和类别。本文通过最大似然训练，提供了定义良好的置信度估计，以确定一个区域是否是可通行的，也就是确定该区域是否真正无物体。相对于传统的对象检测方法，该工作提出的方法不仅能够提供高精度的预测结果，还能量化对象检测区域外的不确定性，提高了模型的鲁棒性和安全性。
### Conclusion
本文通过实证分析和评估展示了该方法的有效性，验证了依赖于条件标记点过程的目标检测模型在可靠性方面的提升。
## 369. `cs.CV` - WAFT: Warping-Alone Field Transforms for Optical Flow [PDF](https://arxiv.org/pdf/2506.21526), [HTML](https://arxiv.org/abs/2506.21526)
### Authors
Yihan Wang,Jia Deng
### Background
现有的方法使用成本体积（cost volume）来提高光学流的准确性，但WAFT提出了一种替代方案，即使用高分辨率的偏转（warping）来达到更好的准确性，同时降低了内存成本，挑战了构建成本体积是实现高性能所必需的传统观点。
### Innovation
WAFT 增强了 RANet 的设计，通过使用高分辨率偏转替代成本体积，取得了更高的准确性同时降低了内存成本。WAFT 是一个简洁灵活的元架构，几乎没有先验偏见和对定制设计的依赖。在 Spring 和 KITTI 基准测试中，WAFT的表现优于现有的方法，特别是在零样本泛化方面，在 KITTI 上表现最佳，同时比具有类似性能的方法快 4.1 倍。
### Conclusion
WAFT 在 Spring 和 KITTI 基准测试中排名第一，具有最好的零样本泛化能力，在类似性能的方法中速度提高 4.1 倍。代码和模型权重可以在指定的链接处获得。
## 370. `cs.CV` - DeOcc-1-to-3: 单图像通过自我监督多视图扩散进行3D去遮挡 [PDF](https://arxiv.org/pdf/2506.21544), [HTML](https://arxiv.org/abs/2506.21544)
### Authors
Yansong Qu,Shaohui Dai,Xinyang Li,Yuze Wang,You Shen,Liujuan Cao,Rongrong Ji
### Background
从单张图像重建3D物体是一个长期存在的挑战，尤其是在真实世界的遮挡情况下。虽然基于扩散的视图合成模型可以从单张RGB图像生成一致的新视图，但它们通常假设输入完全可见，并且在物体部分被遮挡时会失效。这导致不一致的视图和3D重建质量恶化。
### Innovation
我们提出了一个端到端的框架，用于在遮挡感知的多视图生成。该方法直接从单张部分遮挡图像中合成六种结构上一致的新视图，无需先行填充或手动标注，即可进行3D重建。我们使用Pix2Gestalt数据集构建了一个自我监督的训练管道，利用被遮挡和未遮挡的图像对以及伪ground-truth视图来教学模型结构感知的完成和视图一致性。在不修改原始架构的情况下，我们全面微调视图合成模型以学习完成和多视图生成。此外，我们引入了第一个基于遮挡感知的重建基准，涵盖不同的遮挡级别、对象类别和蒙版模式。该基准为评估未来方法提供了标准化协议。
### Conclusion
我们的代码可以在以下链接找到。
## 371. `cs.CV` - StruMamba3D：探索用于自监督点云表示学习的结构化Mamba方法 [PDF](https://arxiv.org/pdf/2506.21541), [HTML](https://arxiv.org/abs/2506.21541)
### Authors
Chuxin Wang,Yixin Zha,Wenfei Yang,Tianzhu Zhang
### Background
近年来，基于Mamba的方法在利用状态空间模型（SSM）进行点云表示学习时展示了出色的效果，得益于其高效的上下文建模能力和线性复杂度。然而，这些方法在处理SSM时仍面临两个关键问题：破坏了点云中3D点的邻接关系和随着输入长度增加，下游任务难以保留长期序列记忆。
### Innovation
为了应对这些问题，我们提出了StruMamba3D，一种新的自监督点云表示学习范式。该方法包括三个方面：1) 设计空间状态以保持点之间的空间依赖关系；2) 通过状态更新策略增强SSM，并结合轻量级卷积以促进空间状态之间的高效结构建模；3) 通过引入序列长度自适应策略减少了对预训练Mamba模型输入长度变化的敏感性。
### Conclusion
实验结果显示，该方法在四项下游任务中展示了优越的表现，并在ModelNet40和最具有挑战性的ScanObjectNN数据集上分别达到了95.1%和92.75%的准确率（未采用投票策略）。
## 372. `cs.CV` - SAM4D: 在摄像头和激光雷达流中分割一切 [PDF](https://arxiv.org/pdf/2506.21547), [HTML](https://arxiv.org/abs/2506.21547)
### Authors
Jianyun Xu,Song Wang,Ziqian Ni,Chunyong Hu,Sheng Yang,Jianke Zhu,Qiang Li
### Background
本文提出了SAM4D，这是一种多模态和时间上的基础模型，专为跨摄像头和激光雷达流的提示可调分割设计。该模型旨在解决自动驾驶场景中多模态数据处理和分割的挑战，尤其是在动态变化的环境中准确分割物体的需求。
### Innovation
文章引入了统一封装多模态位置编码（UMPE），以在共享的3D空间中对齐摄像头和激光雷达特征，从而实现无缝跨模态提示和交互。另外，文章还提出了一种基于自我运动补偿的运动感知跨模态记忆注意（MCMA）机制，以增强时间一致性并提高长时特征检索能力，确保在动态变化的自主驾驶场景中实现鲁棒的分割。为了避免注释瓶颈，作者开发了一种多模态自动化数据引擎，该引擎结合了基于VFM的视频掩模、时空4D重建和跨模态掩模融合，以快速生成摄像头-激光雷达对齐的伪标签，同时保持VFM在点云表示中的语义忠实度。
### Conclusion
在构成的Waymo-4DSeg数据集上的广泛实验表明，SAM4D具有强大的跨模态分割能力和在数据注释方面的巨大潜力。该模型能够以比人类注释快多个数量级的速度生成摄像头-激光雷达对齐的伪标签，同时保持语义的忠实度。
## 373. `cs.CV` - _maximal_matching_matters_preventing_representation_collapse_for_robust_cross-modal_retrieval_ [PDF](https://arxiv.org/pdf/2506.21538), [HTML](https://arxiv.org/abs/2506.21538)
### Authors
Hani Alomari,Anushka Sivakumar,Andrew Zhang,Chris Thomas
### Background
跨模态图像-文本检索因其不同模态内容多样关联性而具有挑战性。传统方法通过单向量嵌入表示每个样本的语义，难以捕捉不同模态之间可能存在的丰富和多样关系。集基方法可以通过使用多个嵌入来表示每个样本，从而捕捉更丰富和多样的关系，是最具前景的替代方案之一。然而，集基表示面临稀疏监督和集合坍缩等问题，限制了其效果。
### Innovation
本文提出了最大配对赋值相似性来优化嵌入集之间的一对一匹配，以保持集合内的语义多样性。此外，还引入了两种损失函数来进一步增强表示：全局判别损失以增强嵌入之间的区分性，和内集发散损失以防止每个集合内部的坍缩。
### Conclusion
该方法在MS-COCO和Flickr30k上实现了最先进的性能，并且无需依赖外部数据。
## 374. `cs.CV` - HalluSegBench: 反事实视觉推理用于分割幻觉评估 [PDF](https://arxiv.org/pdf/2506.21546), [HTML](https://arxiv.org/abs/2506.21546)
### Authors
Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou
### Background
最近在视觉-语言分割方面的进展极大地推动了基于图像的语义理解。然而，现有的分割模型经常出现幻觉现象，通过生成与图像内容无关的分割掩码或错误地标记无关区域。现有的幻觉评估协议主要关注标签或文本幻觉，而没有操纵视觉上下文，限制了其诊断重要错误的能力。因此，本文提出了HalluSegBench，这是首款专门通过反事实视觉推理来评估视觉语义理解中幻觉的基准。
### Innovation
HalluSegBench 包含一个新颖的数据集，该数据集包括1340个反事实实例对，跨越281个不同的对象类别，以及一套新的度量标准，用于量化在视觉上下文一致的场景编辑下幻觉的敏感性。实验结果表明，由视觉驱动的幻觉比由标签驱动的幻觉更普遍，模型常常继续保持虚假的分割，突显出需要反事实推理来诊断语义对应性的准确度的需求。
### Conclusion
HalluSegBench 的实验结果显示了由视觉驱动的幻觉比由标签驱动的幻觉更为普遍且常见，因此模型常常继续进行错误分割，这突显了使用反事实推理来诊断语义定位准确性的必要性。
## 375. `cs.CV` - 全身条件引导的第一人称视频预测 [PDF](https://arxiv.org/pdf/2506.21552), [HTML](https://arxiv.org/abs/2506.21552)
### Authors
Yutong Bai,Danny Tran,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik
### Background
本文介绍了训练模型从第一人称视角预测从人类动作推导出的自助视频（命名为PEVA）。通过条件化关键动力学姿态轨迹，使得模型能够学习如何从第一人称视角模拟物理人类动作对环境的影响。模型是在一个大规模的现实世界自助视频和姿态捕捉数据集Nymeria上训练的。进一步设计了一个分层的评估协议，包含了一系列逐步增强的挑战性任务，用以全面评估模型在实体预测和控制方面的模型能力。本工作的主要目的是尝试从视频预测的角度来建模复杂的真实世界环境和实体代理行为。
### Innovation
本文的最大创新点在于提出了利用全身条件引导进行第一人称视频预测的方法，特别是在考虑人体关节层级结构的基础上训练一个自回归条件扩散转换器。此外，为模型评估设计了多步、递进式的挑战任务，以全面评估模型的预测与控制能力。这种方法对研究复杂现实环境中的实体行为具有重要意义。
### Conclusion
本文代表了对建模复杂现实世界的环境和实体代理行为的初步尝试。通过从第一人称视角的视频预测，模型展现出了对复杂真实环境的高适应性，同时也凸显了在实体预测和控制方面的能力。未来可继续改进模型框架，以更好地适应更多样的真实场景。
## 376. `cs.CV` - 生成性积木世界：图片中移动物件 [PDF](https://arxiv.org/pdf/2506.20703), [HTML](https://arxiv.org/abs/2506.20703)
### Authors
Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D.A. Forsyth,Anand Bhattad
### Background
本文描述了一个称作生成性积木世界的系统，该系统通过操作生成图像中的简单几何抽象来与场景进行互动。这个方法将场景表示为凸3D基本体的装配，同一场景可以用不同数量的3D基本体来表示，使得编辑器既可以移动整个结构也可以移动小细节。编辑场景几何后，由受深度和提示纹理条件影响的流基方法生成图像。这种提示纹理考虑了修改后的3D基本体，跨越了现有的键值缓存技术提供的纹理一致性，允许精确的对象和相机移动，并且主要保留了所描绘对象的身份。
### Innovation
本文提出的方法利用流基生成方法，并结合深度信息和提示纹理，生成高质量的图像。提示纹理能够考虑到修改后的3D基本体，提升纹理一致性，支持精确的对象和相机移动，同时保留对象的身份。相较于现有技术，本文的方法在视觉准确度、编辑性和组合泛化能力上表现出优势。
### Conclusion
定量和定性的实验结果显示，本文的方法在视觉保真度、可编辑性和组合泛化方面优于之前的成果。
## 377. `cs.CV` - SiM3D: 单实例多视图多模态与多组态3D异常检测基准 [PDF](https://arxiv.org/pdf/2506.21549), [HTML](https://arxiv.org/abs/2506.21549)
### Authors
Alex Costanzino,Pierluigi Zama Ramirez,Luigi Lella,Matteo Ragaglia,Alessandro Oliva,Giuseppe Lisanti,Luigi Di Stefano
### Background
3D异常检测和分割（ADS）面临集成多视图和多模态信息的挑战，特别是在仅有一个用于训练的真实或合成物体的情况下。目前缺乏专门针对单实例场景的综合ADS基准，特别是在从合成训练数据向真实测试数据泛化的挑战上。现有的ADS基准主要关注多视图数据，但缺乏多模态信息和不同配置场景的集成。SiM3D填补了这一空白，提供了一个新的基准，该基准考虑了多模态和多视图信息的综合应用，旨在解决在仅有单个可供训练的物体时的泛化问题。
### Innovation
SiM3D首次结合了多视图和多模态信息，通过使用顶尖的工业传感器和机器人收集的数据集提供了一个全新的多视图三维ADS基准。该基准强调的是单实例异常检测场景，即只提供一个实际或合成物体用于训练。特别之处在于，SiM3D首次解决了从合成训练数据向真实测试数据泛化的挑战。提供了一个 Novel Multimodal Multiview Dataset，包含多种类型物体的333个实例的高分辨率多视图图像和点云数据，以及CAD模型和手动标注的3D分割标注数据。这不仅为多视图ADS任务提供了新的基准，并且通过适应现有的单视图方法并使用新的评估指标，展示了这些方法在新型Anomaly Volume上的性能。
### Conclusion
SiM3D是首个全面解决多视图和多模态信息集成的ADS基准，特别适用于单实例物体的检测。它通过引入首个单一实例场景且从合成向实际泛化的基准，为未来在工业检测领域的研究提供了重要的参考和数据支持。这为研究者提供了一个新的挑战和研究领域，即如何有效利用多种数据源进行有效的3D异常检测和分割。
## 378. `cs.CV` - U-R-VEDA: 结合UNet、残差连接、边缘检测和双注意机制以及视觉变换器的心脏磁共振图像精确语义分割 [PDF](https://arxiv.org/pdf/2506.20689), [HTML](https://arxiv.org/abs/2506.20689)
### Authors
Racheal Mukisa,Arvind K. Bansal
### Background
随着人工智能，特别是深度学习模型的应用，自动化医学图像分析在心脏疾病诊断和管理中将发挥重要作用。准确分割心脏图像的自动化是进行心脏疾病量化和自动诊断的第一步。在本文中，提出了一种基于深度学习的增强UNet模型——U-R-Veda，该模型结合了卷积变换、视觉变换器、残差连接、通道注意和空间注意力，以及基于边缘检测的跳跃连接，以实现心脏磁共振（CMR）图像的准确全自动化语义分割。该模型使用组合卷积块堆栈提取局部特征及其相互关系，并以编码器中嵌入通道和空间注意。将通道和空间注意嵌入卷积块中，以识别重要特征及其空间定位。结合边缘信息作为跳跃连接，减少卷积变换中的信息丢失。整体模型显著提高了对CMR图像的语义分割，从而改进了医学图像分析。介绍了双注意模块（通道注意和空间注意）的算法。实验结果表明，U-R-Veda在DSC指标下的平均准确率为95.2%，并且在HD指标下也优于其他模型，特别是在右心室和左心室心肌的分割上表现出色。
### Innovation
该研究提出了一种结合了卷积变换、视觉变换器、残差连接、通道注意和空间注意力的增强UNet模型U-R-Veda，通过使用边缘检测信息作为跳跃连接，减少卷积过程中的信息丢失，并嵌入了从通道和空间注意中识别重要特征的功能。模型在DSC和HD指标上表现出色，特别是在对心脏磁共振图像的分割上取得了显著的效果，优于其他模型，特别是在右心室和心肌的分割上。
### Conclusion
U-R-Veda模型在心脏磁共振图像分割上的表现显著改善了医学图像分析的效果，尤其是在DSC和HD指标上，优于其他模型。该研究强调了多模态注意机制在医学图像自动分割中的重要性，表明了该模型在临床应用中的潜在价值。
## 379. `cs.CV` - 基于模型的无人机激光雷达实时架空输电线路姿态及弛度估计 [PDF](https://arxiv.org/pdf/2506.20812), [HTML](https://arxiv.org/abs/2506.20812)
### Authors
Alexandre Girard,Steven A. Parkison,Philippe Hamelin
### Background
无人机可以在线路带电情况下进行检测，简化了检测过程。然而，使用机载激光雷达（LiDAR）传感器相对于所有导体进行定位存在多个挑战：（1）导体表面不平整，限制了激光雷达波束的扫描点数量，（2）并非所有导体都能被一致检测到，（3）区分对应导体的激光雷达点与其他物体（如树木和铁塔）的点是困难的。现有方法通常是跟踪单独的导体，但本研究提出了一种方法，通过最小化LiDAR测量值与整个导体阵列单一几何模型之间的误差来进行估计，而不是单独追踪每个导体。实验结果显示，即使在部分观察数据、噪声和离群点存在的情况下，该方法也能实现准确的跟踪，求解器每帧不到50毫秒即可收敛。进一步的敏感性分析表明，该估计方法可以容忍两倍于有效导体测量的离群点数量
### Innovation
提出的估计方法通过最小化LiDAR测量值与整个导体阵列单一几何模型之间的误差来进行估计，而不是单独追踪每个导体。这种方法克服了导体表面不平整导致的激光雷达波束扫描点数量有限和导体难以检测的挑战，能够在复杂环境中实现准确的检测。
### Conclusion
实验表明，这种方法即使在部分观察数据、噪声和离群点存在的情况下也能实现准确的跟踪，每帧求解时间在50毫秒以内。敏感性分析还表明，该方法具有良好的鲁棒性，能够容忍较高的离群点比例。
## 380. `cs.CV` - 开发静磁场不均匀性下具有鲁棒性的MR光谱分析方法 [PDF](https://arxiv.org/pdf/2506.20897), [HTML](https://arxiv.org/abs/2506.20897)
### Authors
Shuki Maruyama,Hidenori Takeshima
### Background
当前，用于磁共振（MR）光谱分析的方法在存在静磁场B0不均匀性时可能降低其准确性。通过改进方法提高光谱分析的准确性具有重要意义。
### Innovation
研究提出了一种新的谱分析方法，该方法利用深度学习模型对B0不均匀性引起的存在特性的光谱进行建模。模型通过补偿B0不均匀性的影响来提高光谱分析的准确性，并通过使用已建模的光谱训练分析模型以获得更好的性能。结果表明，相较于未经调整的光谱或模拟光谱，使用已建模光谱训练模型能够显著提高准确性。
### Conclusion
该研究开发了一种使用已建模光谱训练的新的谱分析深学习模型，该方法提高了光谱分析的准确性，特别是在存在B0不均匀性的情况下具有显著的优势。
## 381. `cs.CV` - 3DGH: 3D头部生成具有可组合发式和面部组件 [PDF](https://arxiv.org/pdf/2506.20875), [HTML](https://arxiv.org/abs/2506.20875)
### Authors
Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam
### Background
当前的人类3D头生成模型通常将头发和面部建模融为一体，使得模型难以分别控制和修改两部分。本文旨在解决这一问题，提出了一种新的无条件生成模型3DGH，能够独立建模和编辑头发和面部的不同组件。
### Innovation
本文创新地提出了模板为基础的3D高斯散点图数据表示方法，并引入可变形的头发几何形状来捕捉不同发型的几何变化。在该数据表示基础上，设计了一个具有双生成器的3D GAN架构，并采用交叉注意力机制来建模头发和面部之间的内在关联。本文还通过精心设计的目标训练合成渲染，以稳定训练并促进头发和面部的分离。
### Conclusion
本文通过广泛的实验验证了3DGH的设计选择，并通过与几种最先进的3D GAN方法的比较，验证了其在无条件的全头图像合成和可组合3D发型编辑方面的有效性。
## 382. `cs.CV` - SharpZO: 仅前向传递的混合敏感度感知视觉语言模型提示微调方法 [PDF](https://arxiv.org/pdf/2506.20990), [HTML](https://arxiv.org/abs/2506.20990)
### Authors
Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang
### Background
视觉语言模型（VLMs）在各种下游任务中取得了显著的性能，但它们需要通过反向传播（BP）访问模型梯度，这使得它们不适合用于内存限制下的边缘设备。为了解决这个问题，以前的工作探索了各种不依赖BP的微调方法，但这些方法往往依赖于高方差的进化策略（ES）或零阶（ZO）优化，结果难以达到满意的性能。
### Innovation
本文提出了一种新的混合敏感度感知零阶优化方法（SharpZO），设计用于提高ZO VLM微调的性能，通过敏感度感知的预热训练。SharpZO采用两阶段优化过程：敏感度感知的ES阶段，全局探索损失景观并构造强初始化；随后通过稀疏ZO优化进行细致的局部搜索。整个优化过程仅依赖于前向传递。理论上和实验上，SharpZO在CLIP模型上显示出显著的精确度和收敛速度提升，平均提高了7%的满意度，超过了最先进的仅前向传递方法。
### Conclusion
实验结果表明，SharpZO方法在CLIP模型上的准确性和收敛速度都有显著提高，达到了平均7%的提升。
## 383. `cs.CV` - ThermalDiffusion：从视觉到热成像的图像到图像翻译在自主导航中的应用 [PDF](https://arxiv.org/pdf/2506.20969), [HTML](https://arxiv.org/abs/2506.20969)
### Authors
Shruti Bansal,Wenshan Wang,Yifei Liu,Parv Maheshwari
### Background
自主系统依赖于传感器来估算周围环境，而摄像机、LiDAR和雷达各有局限性。在夜间或雾、霭、尘恶劣环境下，由于物体的热信号，热摄像机会提供关于目标物体存在的有价值信息，使其更容易识别温度通常高于环境的人员和车辆。现有可用于驾驶机器人研究的多模态数据集在场景分割、目标检测和深度估计任务中是关键，但在热成像方面仍存在不足。本文提出一种解决方案，使用条件扩散模型将现有的RGB图像转换为热图像，利用自注意力学习现实世界物体的热特性，以弥补数据不足，促进热摄像在机器人和自动化中的广泛应用.
### Innovation
本研究提出了一种使用条件扩散模型将现有的RGB图像转换为热图像的方法，以解决热成像数据不足的问题。该方法利用自注意力机制学习现实世界物体的热特性，从而广泛而快速地推动了热摄像技术在机器人和自动化领域的应用.
### Conclusion
该研究通过引入条件扩散模型，将现有RGB图像转换为热图像，并利用自注意力学习现实世界物体的热特性，填补了热成像数据的不足，为热摄像技术在机器人和自动化领域的广泛应用提供了技术支持。
## 384. `cs.CV` - 使用几何感知扩散和时序视频模型实现一致的零样本3D纹理合成 [PDF](https://arxiv.org/pdf/2506.20946), [HTML](https://arxiv.org/abs/2506.20946)
### Authors
Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik
### Background
当前的纹理合成方法在固定视角下生成纹理，由于缺乏全局语境和几何理解，会产生不一致性。最近视频生成模型的发展在实现时序一致性的视频方面取得了显著成果。本文旨在解决这些问题，提出了VideoTex框架，利用视频生成模型处理3D纹理的时空不一致性问题，并引入几何感知条件和结构化的UV扩散策略以提高遮挡区域的生成效果，确保跨视野边界更加平滑过渡并保持高帧间临时稳定性。
### Innovation
VideoTex框架提出了一种新的方法，结合了视频生成模型和几何感知下的UV扩散策略。该方法不仅解决了固定视角生成纹理的问题，还能生成跨视场边界更加平滑的纹理，并确保帧间纹理的高质量和临时稳定性。此外，提出的结构化的UV扩散策略有效保存了语义信息，从而提高了遮挡区域的生成质量。
### Conclusion
实验结果表明，VideoTex相比现有方法在纹理保真度、缝合整合和稳定性等方面表现更优，为需要视觉质量和临时一致性的动态实时应用打开了新的可能性。
## 385. `cs.CV` - 通过网络层非均匀影响进行高效检测的通用型对抗数据检测方法 [PDF](https://arxiv.org/pdf/2506.20816), [HTML](https://arxiv.org/abs/2506.20816)
### Authors
Furkan Mumcu,Yasin Yilmaz
### Background
深度神经网络（DNNs）对具有有限噪声预算的对抗输入设计特别脆弱。虽然已提出了许多成功的攻击方法，对原始输入进行细微修改，但针对这些攻击的防御技术研究相对较少。现有的防御方法主要关注通过消除扰动影响来提高DNN的鲁棒性，或者是利用辅助模型来检测对抗数据。虽然这两种方法都很重要，但本研究更侧重于对抗检测方法，该方法更具有实际应用价值，相比提高鲁棒性的方法更为高效和实用。然而，现有的检测方法要么无法有效对抗最先进的攻击技术，要么在实时处理中计算效率低下。本研究提出了一种新型的、高效的方法，通过分析攻击对不同DNN层影响程度的变异来检测对抗样本。这种方法训练了一个轻量级回归模型，预测深层特征，并使用预测误差来检测对抗样本。通过理论论证和大量实验，验证了该检测方法的有效性、计算效率、兼容性以及在不同领域的适用性，如图像、视频和音频。
### Innovation
该研究提出了一种全新的、有效的方法，通过分析攻击对不同DNN层影响程度的变异来检测对抗样本。这种方法训练了一个轻量级回归模型，预测深层特征，并使用预测误差来检测对抗样本。
### Conclusion
通过理论论证和大量实验，研究证明了该检测方法的有效性、计算效率、兼容性以及在图像、视频和音频等多个领域的适用性。这种方法比现有的攻击检测方法更为高效，适用于任何DNN架构，并且能够实时处理。
## 386. `cs.CV` - RL-Selector：基于冗余评估的强化学习指导数据选择 [PDF](https://arxiv.org/pdf/2506.21037), [HTML](https://arxiv.org/abs/2506.21037)
### Authors
Suorong Yang,Peijia Li,Furao Shen,Jian Zhao
### Background
现代深度架构通常依赖大规模数据集，但这些数据集的训练消耗大量计算和存储资源。现实世界中的数据集往往包含大量冗余，导致需要更高效的数据训练方法。已有的方法往往基于静态评分指标或预训练模型进行数据选择，但未能充分考虑选择样本及其在训练过程中动态变化的效果。
### Innovation
本文引入了ε-样本覆盖的概念，通过量化样本间的冗余度来捕捉数据集的内在结构，并将其应用于数据选择问题。基于此，提出了一种基于强化学习（RL）的数据选择方法RL-Selector，其中轻量级的RL代理通过利用来自数据分布变化的信息来优化选择策略，从而选择最具代表性的样本，优化训练效率和泛化性能。
### Conclusion
在多个基准数据集和不同架构上的实验表明，我们的方法在所有测试中都优于现有的最先进的基准方法。使用我们选择的数据集训练的模型表现出更好的泛化性能和更高的训练效率。
## 387. `cs.CV` - 在DCT中发掘宝藏：通过利用潜在关联推进JPEG质量增强 [PDF](https://arxiv.org/pdf/2506.21171), [HTML](https://arxiv.org/abs/2506.21171)
### Authors
Jing Yang,Qunliang Xing,Mai Xu,Minglang Qiao
### Background
JPEG通过量化离散余弦变换（DCT）系数实现数据压缩，但不可避免地会引入压缩伪影。现有的大部分JPEG质量提升方法在像素域中操作，导致解码过程高计算成本的问题。因此，直接在DCT域中提升JPEG图像质量逐渐引起了关注，然而当前的DCT域方法性能有限。
### Innovation
本文作者发现了JPEG图像DCT系数中的两种重要相关性，并在此基础上提出了一个全新的基于DCT域的JPEG质量增强方法（AJQE）。该方法能够充分利用这些相关性，使多种现有的像素域模型适应DCT域，从而在减少计算复杂度的情况下实现更优的性能。相比像素域中的对应模型，通过本文方法得到的DCT域模型在平均信噪比（PSNR）上提升了0.35 dB，在增强通过量上提升了60.5%。
### Conclusion
AJQE方法能够充分利用JPEG图像DCT系数中的相关性，将多种现有的像素域模型迁移到DCT域，大幅提升了JPEG图像的质量，降低了计算复杂度。
## 388. `cs.CV` - GANet-Seg：结合混合生成模型的对抗学习在脑肿瘤分割中的应用 [PDF](https://arxiv.org/pdf/2506.21245), [HTML](https://arxiv.org/abs/2506.21245)
### Authors
Qifei Cui,Xinyu Lu
### Background
目前对于脑肿瘤分割的研究主要依赖于预训练的GANs和Unet架构。然而，现有的方法在处理多模态MRI数据的多样性以及面对标注数据稀缺挑战时，往往难以达到理想的敏感性和准确性。因此，迫切需要提出一种新的框架，通过全局异常检测模块和精细化掩码生成网络的结合，以及对抗损失约束的迭代强化，提高分割精度，并通过多模态MRI数据和合成图像增强来提升方法的鲁棒性。
### Innovation
本文提出了一种新颖的框架，利用预训练的GANs和Unet架构，结合全局异常检测模块和精细化掩码生成网络，引入对抗损失约束迭代增强分割精度。该方法通过多模态MRI数据和合成图像增广来提高方法的稳健性和处理标注数据稀缺的挑战能力。实验结果表明，该方法在Lesion-wise Dice和HD95指标上优于基线，且具有可扩展性，减少了对完全标注数据的依赖，为临床实际应用提供了新的可能。
### Conclusion
本文的方法通过引入全球异常检测模块、精细化掩码生成网络和对抗损失约束，提高了脑肿瘤分割的精度和鲁棒性。实验数据表明，该方法能够实现高敏感性和准确性，并且在处理标注数据稀缺的问题上表现出色。该方法具有良好的扩展性，有望在实际临床环境中得到应用。
## 389. `cs.CV` - 用于心脏MRI和ECG联合表示的全局和局部对比学习 [PDF](https://arxiv.org/pdf/2506.20683), [HTML](https://arxiv.org/abs/2506.20683)
### Authors
Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert
### Background
心电图（ECG）是一种常用的、成本效益高的工具，用于检测心脏的电活动异常，但无法直接测量功能参数，如心室容积和射血分数，这些参数对于评估心脏功能至关重要。心脏磁共振成像（CMR）是这些测量的标准方法，能够提供详细的结构和功能见解，但成本较高且不太容易获得。为了弥合这一差距，论文提出了一种名为PTACL（Patient and Temporal Alignment Contrastive Learning）的多模态对比学习框架，通过整合来自CMR的时空信息来增强ECG表示。PTACL使用全局患者级对比损失和局部时间级对比损失，这些损失机制分别在患者层面和时间点层面提供信息匹配。这些方法使得ECG表示包含超出电活动之外的诊断信息，并且在没有引入新的可学习权重的情况下，提高了不同模态之间的信息传递效率。研究团队在UK Biobank中来自27,951名受试者的配对ECG-CMR数据集上对PTACL进行了评估，表明该方法在两种临床相关任务上优于基线方法：(1)检索具有相似心脏表型的患者和(2)预测CMR衍生的心脏功能参数，如心室容积和射血分数。这些结果突显了PTACL利用ECG增强非侵入性心脏诊断的潜力。关于这项工作的代码已发布在指定链接处。
### Innovation
提出了PTACL（Patient and Temporal Alignment Contrastive Learning）框架，该框架是一种多模态对比学习方法，通过整合来自CMR的时空信息来增强ECG表示。PTACL通过引入全局患者级对比损失和局部时间级对比损失，实现了在没有引入新的可学习权重的情况下提高跨模态的信息传递效率，并且能够提供超出电活动之外的诊断信息。
### Conclusion
该研究展示了PTACL的潜力，通过使用ECG可以增强非侵入性心脏诊断。研究结果表明，相较于基线方法，PTACL在UK Biobank数据集上实现了更好的性能，在两个临床相关任务：(1)检索具有相似心脏表型的患者和(2)预测CMR衍生的心脏功能参数如心室容积和射血分数，均取得了显著的成果。
## 390. `cs.CV` - 多模态语言模型在数据可视化重建与理解中的应用 [PDF](https://arxiv.org/pdf/2506.21319), [HTML](https://arxiv.org/abs/2506.21319)
### Authors
Can Liu,Chunlin Da,Xiaoxiao Long,Yuxiao Yang,Yu Zhang,Yong Wang
### Background
数据可视化对于数据通讯至关重要，但理解这些可视化信息需要同时理解视觉元素及其背后的数据关系。当前的多模态大模型在自然图像理解方面表现良好，但在处理数据可视化方面存在挑战，这是因为它们无法解码数据到视觉映射规则，并提取结构化信息。
### Innovation
为了应对上述挑战，本文提出了一种新型数据集并训练了专为可视化理解和重建设计的多模态语言模型。该方法将图表图像与其对应向量化表示、编码方案和数据特征结合起来。所提议的向量格式能够实现可视化内容的紧凑且准确的重建。实验结果表明，在数据提取精度和图表重建质量方面取得了显著改进。
### Conclusion
本文的方法显著提升了数据提取精度和图表重建质量，展示了多模态语言模型在数据可视化理解与重建方面的潜力。
## 391. `cs.CV` - 基于相关引用及发布权重的用于科研论文的自动化评审人员分配 [PDF](https://arxiv.org/pdf/2506.21331), [HTML](https://arxiv.org/abs/2506.21331)
### Authors
Tamim Al Mahmud,B M Mainul Hossain,Dilshad Ara
### Background
每天有大量的科研文档被提交到各种会议、文章集、期刊、内刊和各种定期出版物中。这些出版物通常会邀请独立的外部专家进行评审，这个过程称为同行评审。但在选取最合适的评审专家时，有时会遇到困难。随着新兴研究领域的不断涌现和科研论文数量的迅猛增长，期刊通常只能分配一小队可能并非专家的评审员来审阅所有这些论文。例如，论文应由同一领域的专家评审。因此，高效地选择最适合的评审专家是一个重大挑战。
### Innovation
本文提出并实现了一种新的策略程序，用于自动选择最适合的评审专家。研究方法包括收集参考文献中的作者，并统计至少在参考文献中有一篇文章的作者数量；通过网络自动提取研究主题关键词；在特定主题中搜索顶级研究人员，并计算前n作者的h指数、i10指数和引用次数；根据评分对这些作者进行排名，自动浏览其主页获取联系信息；同时检查其在线合作者和同事，予以排除。最终，剩下的前n名通常是教授级别的顶级研究人员，很可能是最适合的评审专家。
### Conclusion
这种新策略程序有效地解决了科研论文评审中的专家选择难题，通过利用参考文献及已发表作品的权重信息，实现了自动化匹配最适合的评审专家，提高了评审过程的效率和质量。
## 392. `cs.CV` - V2X-REALM: 基于视觉语言模型的自适应长尾建模的 robust 结尾端到端联合自主驾驶 [PDF](https://arxiv.org/pdf/2506.21041), [HTML](https://arxiv.org/abs/2506.21041)
### Authors
Junwei You,Pei Li,Zhuoyu Jiang,Zilin Huang,Rui Gan,Haotian Shi,Bin Ran
### Background
在城市环境中确保稳健的规划和决策，在罕见、多变且视觉退化的长尾场景下始终是一个基本挑战。特别是在联合设置中，车辆和基础设施共通感知和推理，使这一问题变得更加紧迫。现有的方法难以处理这些复杂的情况，尤其是在涉及注重安全与准确性的自动驾驶领域。
### Innovation
V2X-REALM 引入了三个核心创新点：（i）基于提示的长尾场景生成和评估流水线，利用基础模型生成跨车辆和基础设施视图的真实视觉长尾条件，提高训练多样性；（ii）基于门控的多场景自适应注意力模块，使用先验场景调节视觉流，重新校准模糊或受损的特征；（iii）多任务场景感知对比学习目标，提高模态对齐，增强跨场景特征分离能力。这些创新共同实现了在复杂条件下的最先进性能。
### Conclusion
广泛的实验结果表明，V2X-REALM在应对复杂和苛刻的驾驶条件时，在鲁棒性、语义推理、安全性和规划准确性方面明显优于现有基线，推动了端到端联合自主驾驶的可扩展性。
## 393. `cs.CV` - FairyGen: 根据单一儿童绘制角色生成故事情节动画视频 [PDF](https://arxiv.org/pdf/2506.21272), [HTML](https://arxiv.org/abs/2506.21272)
### Authors
Jiayi Zheng,Xiaodong Cun
### Background
现有讲故事的方法主要集中在角色一致性与基本动作上，而没有明确地将角色建模与风格化背景生成分开，并且缺乏支持富有表现力和连贯性的叙事设计。FairyGen旨在填补这一空白，通过自动系统从单一儿童的绘画中生成有故事情节的卡通视频，并忠实保留其独特的艺术风格。该系统首先通过一个MLLM生成结构化的故事板，然后利用风格传播适配器确保视觉一致性并将角色样式应用于背景。进一步的场景设计模块通过构图和多视图合成增强了视觉多样性和电影质量。最终通过3D代理重建角色，然后使用MMDiT为基础的图像到视频扩散模型生成动画，进一步使用运动定制适配器来生成逼真的运动序列。
### Innovation
FairyGen引入了一种新的方法来生成故事驱动的卡通视频。该系统能够从单幅儿童绘制的人物草图开始，自动生成详细的故事情节，并通过明确分离角色建模和风格化背景生成，以及引入摄氏变换设计模块和场景设计模块，提高视觉多样化和电影质量。同时，该系统还提出了两阶段运动定制适配器，以更好地保留人物的身份信息并生成连贯的动画序列。
### Conclusion
实验证明，FairyGen生成的动画不仅风格忠实，且叙事结构自然，能够让故事动画更加个性化和引人入胜。代码将公开发布。
## 394. `cs.CV` - 基于双提示优化和跨融合的个性化联邦学习 [PDF](https://arxiv.org/pdf/2506.21144), [HTML](https://arxiv.org/abs/2506.21144)
### Authors
Yuguang Zhang,Kuangpu Guo,Zhihe Lu,Yunbo Wang,Jian Liang
### Background
联邦学习（FL）可以在不共享本地数据的情况下，通过跨去中心化客户端进行模型训练。然而，它面临着数据、计算和通信的异质性挑战。预训练的视觉-语言模型（VLMs）因其强大的泛化能力和通过提示进行轻量级微调的能力而提供了有潜力的解决方案。然而，现有的联邦提示学习方法仅依赖于文本提示，忽视了联合标签域分布的变化。因此，有必要提出一种新的个性化联邦学习框架，以更好地适应客户端异质数据的特点和需求，并提升整体模型性能。
### Innovation
提出了一个基于双提示学习和跨融合的个性化联邦学习框架，命名为 pFedDC。该框架中，每个客户端同时维护视觉和语言模态的全球提示和局部提示，以捕捉联盟内的共同知识和编码客户端特定的语义和领域特征。此外，设计了一个跨融合模块，使模型能够根据每个客户端的独特数据分布生成个性化表示。通过在包括九个具有不同类型异质性的数据集上进行大量实验，证明了 pFedDC 方法在性能上优于现有最先进的方法。
### Conclusion
pFedDC 通过双提示优化和跨融合有效地解决了数据、计算和通信异质性的挑战，能够生成与客户端独特数据分布相一致的个性化表示，从而在各种异质性数据集上显著提高了联邦学习的效果。
## 395. `cs.CV` - ThinkSound：在多模态大型语言模型中进行音频生成和编辑的思路链推理 [PDF](https://arxiv.org/pdf/2506.21448), [HTML](https://arxiv.org/abs/2506.21448)
### Authors
Huadai Liu,Jialei Wang,Kaicheng Luo,Wen Wang,Qian Chen,Zhou Zhao,Wei Xue
### Background
尽管端到端的视频到音频生成已经有了显著的进步，但生成高保真音频，准确捕捉视觉内容的细微差别仍然颇具挑战性。这一任务类似于创意行业中的专业人士，需要对视觉动态、声学环境和时间关系等复杂因素进行推理。现有方法难以处理这些复杂的因素，导致生成的音频与视觉内容的关联性和真实感不足。因此，需要一种能够逐步、交互地生成和编辑视频音频的方法来解决这个问题。
### Innovation
提出了ThinkSound框架，通过结合Chain-of-Thought（CoT）推理，使音频生成和编辑成为可能。该框架将过程分解为三个互补阶段：基础音效生成、通过精确用户交互的互动对象中心细化，以及基于自然语言指令的目标编辑。此外，还引入了AudioCoT数据集，其中包括结构化的推理注释，连接视觉内容、文本描述和声音合成。实验表明，ThinkSound在音频指标和CoT指标上的表现均达到最佳，并在Movie Gen Audio基准测试中表现出色。
### Conclusion
无论是从音频生成指标还是CoT推理指标来看，该研究方法均实现了行业内的最佳效果。同时在广泛使用的Movie Gen Audio测试集中，其性能表现更为优异。
## 396. `cs.CV` - ResQ: 在模拟 Rydberg 原子量子计算机中实现残差神经网络的新框架 [PDF](https://arxiv.org/pdf/2506.21537), [HTML](https://arxiv.org/abs/2506.21537)
### Authors
Nicholas S. DiBrita,Jason Han,Tirthak Patel
### Background
由于量子计算机可能加速机器学习，基于经典机器学习领域的神经科学家已经研究得较为充分，但在使用神经常微分方程（神经 ODEs）的残差神经网络（ResNets）方面的研究尚未广泛开展。因此，利用量子计算的潜力来加快机器学习的一项最新研究集中在 ResNets 上。
### Innovation
提出了一种新框架 ResQ，旨在优化 Rydberg 原子量子计算机的动力学以解决机器学习中的分类问题，利用的是模拟量子神经 ODEs。该框架特别适合量子计算机，尤其是模拟 Rydberg 原子量子计算机，因其出色的性能表现，提供了解决机器学习问题的新方法。
### Conclusion
该研究展示了 ResQ 帧架构如何利用模拟 Rydberg 原子量子计算机的优势来优化 ResNets 的性能，并最终有效地解决机器学习中的分类问题。
## 397. `cs.CV` - 仅从有限视角进行空间心理建模 [PDF](https://arxiv.org/pdf/2506.21458), [HTML](https://arxiv.org/abs/2506.21458)
### Authors
Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei
### Background
该研究探讨了视觉语言模型（VLMs）能否像人类一样，从有限视角构建完整的场景心理模型。虽然人类能够通过内在的不断扩展的心理空间模型推理空间布局、视角和运动，但现有的VLMs仅凭有限的视角表现近乎随机，MindCube基准测试展示了这一关键差距。MindCube测试包含21,154个问题和3,268张图像，用于评估VLMs在情感映射（认知定位）、视角推理（视角更换）和动态推理（思维中的“如果”运动）方面构建稳健的心理模型的能力。
### Innovation
研究提出了三种帮助VLMs逼近空间心理模型的方法，包括生成未见过的中间视图、自然语言推理链和认知地图。研究发现，“生成地图再推理”方法（map-then-reason）结合了先生成认知地图再在其上推理的联合训练策略，显著提高了准确率，从37.8%提升到60.8%（+23.0%）。进一步引入强化学习将性能提高到70.7%（+32.9%）。这项研究的关键见解是，这种对空间心理模型的支架化方式，积极构建并利用内部结构化的空间表示和灵活的推理过程，显著提升了对不可观察空间的理解能力。
### Conclusion
通过对VLMs进行认知地图的训练，在内部视频中进行推理，准确率从37.8%提升到60.8%，进一步利用强化学习将性能提高到70.7%。研究结果表明，这种将心理地图与灵活的推理过程相结合的方法，显著提高了不可见空间的理解能力。
## 398. `cs.CV` - 动态注意力头实现高效图像生成 [PDF](https://arxiv.org/pdf/2211.05770), [HTML](https://arxiv.org/abs/2211.05770)
### Authors
Steven Walton,Ali Hassani,Xingqian Xu,Zhangyang Wang,Humphrey Shi
### Background
虽然将变压器集成到视觉模型中能够在视觉任务上取得显著进步，但这两阶段仍需要大量的计算资源来进行训练和推理。受限的关注机制能显著减少这些计算负担，但会以全局或局部一致性为代价。作者提出了一种简单而强大的方法来减少这些权衡：允许一个变压器的注意力头关注多个感受野。这种方法被应用于StyleGAN架构，并集成了一个称为StyleNAT的模型，旨在提高生成质量和效率。
### Innovation
提出了一种简单的动态注意力头方法，可以同时关注多个感受野，以减少计算需求与保持全局或局部一致性之间的贸易折衷。通过将该方法集成到基于StyleGAN的架构中，实现了一个名为StyleNAT的新模型。StyleNAT在FFHQ上的FID得分仅为2.05，比StyleGAN-XL提高了6%，并使用更少的参数实现了更高的吞吐量。该方法适用于FFHQ-256数据集以及其他数据集上实现了强大的图像生成能力。
### Conclusion
通过StyleNAT模型，能够在不牺牲大量计算资源的前提下，实现高效的图像生成，与现有技术相比，实现了更好的性能和效率。
## 399. `cs.CV` - 基于多源数据融合的遗迹滑坡检测语义分割模型 [PDF](https://arxiv.org/pdf/2308.01251), [HTML](https://arxiv.org/abs/2308.01251)
### Authors
Yiming Zhou,Yuexing Peng,Daqing Ge,Junchuan Yu,Wei Xiang
### Background
滑坡作为一种自然灾害经常给人们的生命带来巨大损失，因此迫切需要可靠的滑坡风险检测方法。在进行遗迹滑坡检測时，由于遥感图像存在视觉模糊、样本数据量较小等问题，使用这些图像进行滑坡风险预警中的遗迹滑坡检测带来了很大挑战。因此，提出了一种名为HPCL-Net的超像素级对比学习增强分割网络。该方法通过HPCL增强滑坡边界局部显著特征提取，并融合高分辨率遥感图像和数字高程模型数据中的异质信息。
### Innovation
提出了名为HPCL-Net的超像素级对比学习增强分割网络，其中包括全局超像素级样本对队列构建和动量编码更新方案，增强语义特征提取能力。采用Loess Plateau遗迹滑坡数据集进行了测试，结果表明HPCL-Net显著优于现有模型，mIoU从0.620提高到0.651，滑坡IoU从0.334提高到0.394，F1分数从0.501提高到0.565。
### Conclusion
提出的HPCL-Net在Loess Plateau遗迹滑坡数据集上进行了评估，并通过实验结果验证了其相比现有模型的显著优势。
## 400. `cs.CV` - 自调节神经发生用于在线数据增量学习 [PDF](https://arxiv.org/pdf/2403.14684), [HTML](https://arxiv.org/abs/2403.14684)
### Authors
Murat Onur Yildirim,Elif Ceren Gok Yildirim,Decebal Constantin Mocanu,Joaquin Vanschoren
### Background
神经网络在学习连续任务或数据流时常常会出现灾难性的遗忘，相比之下，人类能够不断学习并巩固新的概念，即使没有明确的提示。在线数据增量学习试图模仿这一能力，通过仅处理每个样本一次且在任何时间点都不需要任务或流提示来实现，这比离线设置更加实际，因为在这种设置中，所有来自新类别（或类）的数据都被假设是现成可用的。然而，现有的方法通常依赖于存储子数据集在内存中或扩展初始模型架构，这会导致显著的计算开销。
### Innovation
本文受到大脑‘自我调节神经发生’机制的启发，即创建专门的区域或电路以处理不同的功能。提出了一种名为SERENA（Self-Regulated Neurogenesis for Online Data-Incremental Learning）的新方法，将每个概念编码在称为‘概念细胞’的专门网络路径中，这些‘概念细胞’整合于一个单一的过参数化网络中。一旦某个概念被学习，对应的‘概念细胞’将被冻结，从而有效防止先前获得信息的遗忘。还提出了两种新的连续学习场景，这些场景以逐渐变化的样本大小来更好地反映现实世界的情况。实验结果表明，该方法不仅在十个基准上确立了新的最先进的结果，而且在离线监督批量学习上也有显著优越的表现。
### Conclusion
该方法展示了在多个基准上的优越性能，不仅达到了新的最先进的水平，而且显著超过了离线监督批量学习的表现。该研究为在线数据增量学习提供了一个新的有效的解决方案。
## 401. `cs.CV` - 根据生物需求进行细胞追踪——强意识有丝分裂感知多假设追踪器与 aleatoric 不确定性 [PDF](https://arxiv.org/pdf/2403.15011), [HTML](https://arxiv.org/abs/2403.15011)
### Authors
Timo Kaiser,Maximilian Schier,Bodo Rosenhahn
### Background
细胞追踪和分割帮助生物学家从大规模显微镜时序数据中提取有价值的信息。当前基于局部精度指标的追踪方法往往面临长期一致性不足和正确重建谱系树的能力缺失的问题。为解决这些问题，本文提出了一种用于运动估计框架的不确定性估计技术，并扩展了多假设追踪框架。通过特定问题的测试时增强，不确定性估计将运动表示提升为具有概率空间密度的形式。此外，本文引入了一种新的有丝分裂感知分配问题模型，使得多假设追踪器能够建模细胞分裂，并通过长期冲突解决误关联和有丝分裂检测问题。在分配成本中，显式的生物知识被明确建模。
### Innovation
本文提出了一种新的不确定性估计技术，用于运动估计框架，并通过特定问题的测试时增强将运动表示提升为概率空间密度。此外，引入了一种新的有丝分裂感知分配问题模型，允许多假设追踪器建模细胞分裂，解决长期冲突导致的误关联和有丝分裂检测问题。
### Conclusion
本文在九个竞争数据集上评估了我们的方法，显示在生物学启发的指标上显著超越当前最先进的方法，性能提升约6倍，并揭示了运动估计不确定性对细胞行为的新见解。
## 402. `cs.CV` - ClimateIQA：气象异常分析中促进视觉语言模型发展的新型数据集和基准 [PDF](https://arxiv.org/pdf/2406.09838), [HTML](https://arxiv.org/abs/2406.09838)
### Authors
Jian Chen,Peilin Zhou,Yining Hua,Dading Chong,Meng Cao,Yaowei Li,Wei Chen,Bing Zhu,Junwei Liang,Zixuan Yuan
### Background
气象热图在解读极端天气现象中起着至关重要的作用，但它们复杂的不规则轮廓、无结构的模式和复杂的颜色变化给最先进的视觉语言模型（VLMs）带来了独特的分析挑战。当前的先进模型如GPT-4o、Qwen-VL和LaLaVA 1.6在精确颜色识别和空间定位任务中存在困难，导致解释不准确或不完整。
### Innovation
为了应对这些挑战，提出了一种新的算法Sparse Position and Outline Tracking (SPOT)，专门用于处理视觉数据中不规则形状的彩色区域。SPOT通过提取空间坐标来识别和定位这些区域，使其能够生成不规则形状的结构化表示。基于SPOT，构建了ClimateIQA，这是一个新型的气象视觉问答（VQA）数据集，包含26,280个高分辨率热图和762,120个指令样本，用于风速、总降水量、风寒指数和热指数分析。ClimateIQA通过引入空间线索、地理元数据和再分析数据，增强了VLM的训练，提高了模型在解释和描述极端天气特征方面的准确性。此外，开发了Climate-Zoo，这是一个基于SPOT赋能的ClimateIQA微调视觉语言模型的套件，显著优于现有模型在气象热图任务上的表现，
### Conclusion
ClimateIQA数据集和Climate-Zoo模型套件的开发不仅提供了一种新的方法来提升VLM在气象视角问题回答中的性能，还为气象异常分析提供了一个全面的应用和评估框架。
## 403. `cs.CV` - 3D MLLMs for CT报告生成的设计空间探索 [PDF](https://arxiv.org/pdf/2506.21535), [HTML](https://arxiv.org/abs/2506.21535)
### Authors
Mohammed Baharoon,Jun Ma,Congyu Fang,Augustin Toma,Bo Wang
### Background
多模态大语言模型（MLLMs）为自动化放射科报告生成（RRG）提供了潜在途径。本研究系统性地探讨了3D MLLMs的设计空间，包括视觉输入表示、投影器、大型语言模型（LLMs）和3D CT报告生成的微调技术。同时也引入了两种基于知识的报告增强方法，使性能在GREEN评分上提高高达10%，在2024年MICCAI AMOS-MM挑战赛上获得第二名。研究表明，在相同训练协议下，LLM的大小对RRG影响不大。此外，证明较大的体积大小并不总是能够提高性能，如果原始ViT是在较小的体积大小上预训练的话。最后，使用分割掩码与CT体积一起使用可以提高性能。相关代码已公开发布于给定链接中。
### Innovation
研究引入了两种基于知识的报告增强方法，显著提高了GREEN评分；系统性地探讨了3D MLLMs的设计空间；展示了在相同训练协议下，LLM的大小对RRG影响不大；证明了较大的体积大小并不总是能够提高性能，如果原始ViT是在较小的体积大小上预训练的话；提出了使用分割掩码与CT体积一起使用可以提高性能的方法。
### Conclusion
在1,687个病例的AMOS-MM数据集上进行了研究，结果表明，3D MLLMs的大小在相同训练协议下对报告生成的影响不大。较大的体积大小在某些情况下未必会提升性能，特别是当原始ViT是在较小的体积上预训练的情况下。使用分割掩码与CT体积一起使用可以显著提高报告生成的性能。相关代码已公开发布。
## 404. `cs.CV` - QuEST: 通过高效选择性微调实现低比特扩散模型量化 [PDF](https://arxiv.org/pdf/2402.03666), [HTML](https://arxiv.org/abs/2402.03666)
### Authors
Haoxuan Wang,Yuzhang Shang,Zhihang Yuan,Junyi Wu,Junchi Yan,Yan Yan
### Background
尽管量化为模型压缩和加速提供了途径，但现有的方法在实现低比特量化时遇到了效率上的挑战，特别是由于激活分布的不平衡所引起的困难。这对于扩散模型的实际部署仍然是一个阻碍因素，这些模型面临高内存和计算开销的问题。因此，本文致力于通过调整权重微调来平衡激活分布，以提高量化友好性，并评估其在三种高分辨率图像生成任务中的有效性，同时保持并提升量化效率。
### Innovation
该研究识别了不平衡的激活分布作为量化难度的主要来源，并提出通过权重微调来调整这些分布，使它们更适合量化。此外，通过区分那些负责保留重要时间信息的层和那些特别敏感于比特宽度减少的层，并在局部和全局监督下进行选择性微调，本文进一步提出了两类型的量化层，从而在提高量化效率的同时减小性能下降。
### Conclusion
该方法在三个高分辨率图像生成任务中展示了其有效性，即使在多种比特宽度设置下也取得了最佳性能，证明了通过高效选择性微调实现低比特扩散模型量化的实用性和可靠性。
## 405. `cs.CV` - 用多模态大规模语言模型你看到了什么？增强零样本图像分类 [PDF](https://arxiv.org/pdf/2405.15668), [HTML](https://arxiv.org/abs/2405.15668)
### Authors
Abdelrahman Abdelhamed,Mahmoud Afifi,Alec Go
### Background
大规模语言模型（LLMs）已被有效应用于许多计算机视觉任务，包括图像分类。本研究提出了一种简单有效的零样本图像分类方法，利用多模态LLMs生成输入图像的全面文本表示。这些文本表示在跨模态嵌入空间中生成固定维度的特征，然后使用线性分类器将这些特征融合以执行零样本分类。该方法无需为每个数据集进行提示工程，而是使用单一、简单的提示集在所有数据集上工作。本研究在多个数据集上对方法进行了评估，结果表明其显著有效，超越了多项基准准确性，平均在十个基准测试中增加了6.2个百分点，相较于之前的方法，在ImageNet数据集上增加了6.8个百分点，使用相同的测试设置重新评估前的方法。这些结果突显了多模态LLMs在增强计算机视觉任务如零样本图像分类方面的潜力，显著优于传统方法。
### Innovation
提出了一种利用多模态大语言模型（LLMs）进行零样本图像分类的简单有效方法。该方法无需为每个数据集进行提示工程，使用单一、简单的提示集在所有数据集上工作，生成输入图像的文本表示并将其转换为跨模态嵌入空间中的固定维度特征，利用线性分类器进行融合分类。这种方法在多个数据集上的评估结果显著提高了准确性，并且相比之下在ImageNet上的改进更为显著。
### Conclusion
本研究展示了多模态LLMs在增强计算机视觉任务，特别是零样本图像分类方面的潜力，提出了简单且有效的方法，超越了先前的方法，并推动了该领域的研究。
## 406. `cs.CV` - 我的数据在我的AI模型中吗？基于面部图像的应用隐私探测测试 [PDF](https://arxiv.org/pdf/2402.09225), [HTML](https://arxiv.org/abs/2402.09225)
### Authors
Daniel DeAlcala,Aythami Morales,Julian Fierrez,Gonzalo Mancera,Ruben Tolosana,Javier Ortega-Garcia
### Background
这篇论文介绍了 Membership Inference Test (MINT)，这是一种用于实证评估给定数据是否被用于训练 AI/ML 模型的新方法。实验聚焦于面部识别任务，涉及三种最先进的面部识别系统，并使用六个公开数据库进行实验，总计超过 2200 万张面部图像。不同的实验场景基于 AI 模型测试的上下文来考虑。本研究探讨了如何通过学习审计模型在训练过程中的激活模式来检测特定数据是否被用于训练或调整 AI 模型，特别是在保护隐私和公平性方面有多方面应用，例如揭示敏感或私人数据是否被用于训练或调优大语言模型（LLMs）。
### Innovation
本文提出了一种新颖的 MINT 架构，通过使用多层感知器 (MLPs) 和卷积神经网络 (CNNs) 来学习在 AI 模型训练过程中暴露于数据的独特的激活模式。这种技术能够检测出数据是否被用于特定模型的训练，显示出潜在的隐私保护功能，特别是在大语言模型的训练和调整方面。
### Conclusion
实验结果表明，提出的 MINT 方法具有令人鼓舞的结果，准确率最高可达 90%，这意味着可以通过这种方法识别 AI 模型是否使用了特定数据进行训练。该方法可以应用于确保多种 AI 应用中的隐私和公平性，例如揭露训练或调整大语言模型时是否使用了敏感或私人数据。
## 407. `cs.CV` - 利用高效掩码图像建模大规模卫星影像 [PDF](https://arxiv.org/pdf/2406.11933), [HTML](https://arxiv.org/abs/2406.11933)
### Authors
Fengxiang Wang,Hongzhen Wang,Di Wang,Zonghao Guo,Zhenyu Zhong,Long Lan,Wenjing Yang,Jing Zhang
### Background
掩码图像建模（MIM）已成为构建遥感（RS）基础视觉模型的重要方法。然而，现有RS数据集的规模和多样性限制了MIM方法学习到具有泛化能力的表示。另外，传统的MIM技术需要重构所有标记，增加了不必要的计算开销。
### Innovation
我们提出了一种新的RS模型预训练流水线，包括构建大规模RS数据集和高效的MIM方法。具体来说，我们创建了一个名为OpticalRS-13M的高质量数据集，包含了1300万张光谱图像，覆盖了多种RS任务。此外，我们还提出了一种名为SelectiveMAE的方法，它可以动态编码并重构含有丰富语义的块标记，从而在遥感图像中减少冗余背景像素造成的效率低下问题。
### Conclusion
实验表明，OpticalRS-13M显著提高了分类、检测和分割的性能，而SelectiveMAE则提高了训练效率超过2倍。这突显了我们流水线在开发RS基础模型方面的有效性和可扩展性。数据集、源代码和预训练模型将在指定链接处提供。
## 408. `cs.CV` - 轻量化物理启发式零样本超声平面波去噪 [PDF](https://arxiv.org/pdf/2506.21499), [HTML](https://arxiv.org/abs/2506.21499)
### Authors
Hojat Asgariandehkordi,Mostafa Sharifzadeh,Hassan Rivaz
### Background
超声相干平面波复合（CPWC）通过合并从多个方向发散的回声来增强成像对比度。增加扫描角度通常能提升图像质量，但会显著降低帧率，并且在快速移动的目标中会引入模糊伪影。此外，复合图像仍然容易受到噪声影响，尤其在采集的传输次数有限时。背景涉及在低角度CPWC采集中，提出了零样本降噪框架，无需额外训练数据就能增强对比度。方法将可用的发射角分为两组，每组用于形成包含更高噪声水平的复合图像，进而通过自监督残差学习方案训练深度模型，以抑制无规则噪声同时保留解剖结构。由于角度依赖性伪影在不同子集之间变化而未缓解的组织反应相似，这种物理启发的配对能使网络学会从不一致的伪影中分离出一致的组织信号。相比监督方法，模型不需要特定领域的微调或配对数据，使其在不同解剖区域和采集设置中更适应。整个流程通过轻量级架构实现高效训练，仅使用两个卷积层降低了计算成本。该研究基于仿真实验、模型和实际数据验证，显示相比经典和基于深度学习的去噪方法，具有更好的对比度增强和结构保留效果。
### Innovation
提出了针对低角度CPWC的零样本降噪框架，利用自监督残差学习方案训练深度模型，不依赖额外的训练数据或特定领域的微调，适用于不同解剖区域和采集设置。模型仅使用轻量级架构（两个卷积层）进行高效训练，同时展现出更高的对比度增强和结构保留效果。
### Conclusion
该研究提出的方法能有效增强超声成像中的对比度并保留结构信息，其轻量级物理启发式框架和无监督学习机制使得方法在不同采集条件下更具适应性。通过简化模型结构和自监督学习策略，该方法在保持与经典方法和深度学习方法相当的成像质量的同时，还提升了计算效率。
## 409. `cs.CV` - 学习成为 transformer 来精确定位异常 [PDF](https://arxiv.org/pdf/2407.04092), [HTML](https://arxiv.org/abs/2407.04092)
### Authors
Alex Costanzino,Pierluigi Zama Ramirez,Giuseppe Lisanti,Luigi Di Stefano
### Background
工业异常检测与分割（IADS）方法通常处理低分辨率图像（例如 224x224 像素），这些图像通过降采样原始输入图像获得。虽然这种方法在部署强大且通常预先训练的特征提取器方面效率高，但长期以来，许多工业应用需要识别大尺寸和小尺寸的缺陷，因此这种方法可能会妨碍方法精准定位微小异常的能力。
### Innovation
本文提出了一种新颖的教师-学生范式，通过训练两个浅层MLP（学生）模拟冻结的视觉Transformer（教师）的自注意力层产生的补丁嵌入映射，从而利用强预训练特征处理高分辨率输入图像。这种方法能够在高分辨率图像中识别异常，并且比竞争对手更快地运行，达到了最先进的性能，尤其是在MVTec AD和VisA的最佳分割结果上。此外，该方法还提出了一种新的评价指标来捕捉缺陷大小的鲁棒性指标，即能保持从大异常到小异常的良好边界定位能力。
### Conclusion
通过这些评价指标评估我们的方法也显示出其卓越的性能，尤其是在缺陷大小的鲁棒性和精度方面。
## 410. `cs.CV` - HERMES: 时空连贯的长形式理解与情节和语义 [PDF](https://arxiv.org/pdf/2408.17443), [HTML](https://arxiv.org/abs/2408.17443)
### Authors
Gueter Josmy Faure,Jia-Fong Yeh,Min-Hung Chen,Hung-Ting Su,Shang-Hong Lai,Winston H. Hsu
### Background
长格式视频理解带来了超越传统短视频分析方法的独特挑战，尤其是在捕捉长时间依赖关系、有效处理冗余信息及提取高层语义概念方面。为应对这些挑战，本文提出了一种新的方法，更准确地反映人类的认知过程。该方法通过引入HERMES，结合情节和语义进行时空连贯的长格式理解。HERMES采用了两个灵活的模块，可以增强现有的视频-语言模型或作为一个独立系统运行.
### Innovation
该文创新性地提出了HERMES：一种新颖的整体框架，融合了时空连贯性和情境、语义信息处理能力。HERMES通过Episodic COmpressor (ECO) 实现从微到半宏层的表示聚合，同时通过Semantics ReTRiever (SeTR) 融入更多的语义信息，这些模块既可集成到现有SOTA模型中，又可作为一个独立系统运行。该方法能够有效降低计算成本和提高推理延迟，同时保持时间和语义的依赖关系.
### Conclusion
实验结果表明，HERMES可以通过无缝集成现有最先进模型提高其性能，同时减少推理延迟高达43%，内存使用减少46%。作为一个独立系统，HERMES在多个长视频理解基准测试中实现最先进的性能，在零样本和全监督设置下同样表现出色.
## 411. `cs.CV` - ROA-BEV: 2D Region-Oriented Attention for BEV-based 3D Object Detection [PDF](https://arxiv.org/pdf/2410.10298), [HTML](https://arxiv.org/abs/2410.10298)
### Authors
Jiwei Chen,Yubao Sun,Laiyan Ding,Rui Huang
### Background
基于视觉的鸟瞰视角（BEV）三维物体检测在自动驾驶中变得流行。然而，现有方法难以检测与背景高度相似的物体。
### Innovation
提出了一种基于BEV的具有2D区域导向注意机制（ROA-BEV）的三维物体检测网络，该网络通过多尺度结构增强信息特征学习能力，每块ROA利用大核确保接受域足够大以捕捉大物体的信息。
### Conclusion
在nuScenes上的实验表明，ROA-BEV在基于BEVDepth的基础上提高了性能。此工作源代码可从此链接获取。
## 412. `cs.CV` - CanFields：使用非刚性4D插值的差异流综合 [PDF](https://arxiv.org/pdf/2406.18582), [HTML](https://arxiv.org/abs/2406.18582)
### Authors
Miaowei Wang,Changjian Li,Amir Vaxman
### Background
现有方法在处理独立采样的3D点云序列时存在过度平滑几何形状或产生拓扑和几何艺术的问题。本文介绍了一种新型方法——Canonical Consolidation Fields (CanFields)，该方法能够将任意长度序列的独立采样3D点云插值为一个统一的、连续且一致变形的形状，且该方法可以在不监督的情况下优化精细几何和变形。此项研究旨在提升三维点云序列处理方法的有效性和鲁棒性，特别是在缺失数据、噪声较大和数据稀疏等复杂情况下，能够表现出更优越的性能。
### Innovation
本文提出了两种新型模块：动态综合模块（动态调整输入并分配置信度分数，平衡在确立形态和其运动之间的优化）和光滑速度场参数化的形变表示（将运动表示为差异流）。CanFields方法能够在不监督学习中同时优化几何细节和变形，对于处理不同长度和不同数据质量的3D点云序列具有较高的鲁棒性和准确性，性能更优异，尤其是在存在缺失区域、噪声大和数据稀疏的情况下表现更为突出，能够生成连续且一致的变形形体，且具有更好的细节恢复能力。
### Conclusion
CanFields 方法通过其独特的动态综合模块和形变表示方式，在处理多样化的3D点云序列时，相较于现有方法，能够更加有效地优化精细几何和变形，表现出优异的鲁棒性和准确性。
## 413. `cs.CV` -  onViewCreated边界划分：利用Sentinel-1和Sentinel-2时序数据在全球农业景观中实现稳健的田块边界划定 [PDF](https://arxiv.org/pdf/2409.13568), [HTML](https://arxiv.org/abs/2409.13568)
### Authors
Foivos I. Diakogiannis,Zheng-Shu Zhou,Jeff Wang,Gonzalo Mata,Dave Henry,Roger Lawes,Amy Parker,Peter Caccetta,Rodrigo Ibata,Ondrej Hlinka,Jonathan Richetti,Kathryn Batchelor,Chris Herrmann,Andrew Toovey,John Taylor
### Background
准确界定农田边界对于有效的作物监控和资源管理至关重要。然而，现有的方法往往面临显著挑战，尤其是在依赖大量人工处理云覆盖数据和适应多样化全球条件上的问题。论文中提到了这一点，并且指出该问题在数据准备和适应性方面挑战较大。
### Innovation
本文提出了一种名为PTAViT3D的深度学习架构，专门用于处理来自Sentinel-1 (S1) 或 Sentinel-2 (S2) 的三维时序卫星影像。PTAViT3D-CA是PTAViT3D的扩展版，引入了交叉注意力机制以融合S1和S2数据，提高在云干扰情况下的鲁棒性。该方法利用高效的3D Vision Transformer架构来挖掘时空相关性，直接从原始、带有云影的影像中精确划定边界。该模型通过在不同数据集上进行广泛测试，展示了卓越的全球适应性和鲁棒性。
### Conclusion
研究结果表明，提出的PTAViT3D和PTAViT3D-CA模型在各种数据集上表现出先进的性能，并在多个公共基准数据集上验证了其在不同全球农业环境中的强适应性。这种方法显著简化了数据准备流程，可靠地处理了有云影响的影像，从而增强了方法在各种农业环境中的应用潜力。论文代码和模型在论文官网公开。
## 414. `cs.CV` - 无人机图像中提取地理参考车辆轨迹的高级计算机视觉 [PDF](https://arxiv.org/pdf/2411.02136), [HTML](https://arxiv.org/abs/2411.02136)
### Authors
Robert Fonod,Haechan Cho,Hwasoo Yeo,Nikolas Geroliminis
### Background
本文提出了一个从高空无人机影像中提取地理参考车辆轨迹的框架，以应对城市交通监控中的关键挑战以及传统地面系统的优势不足。研究主要在中国韩国的Songdo国际商务区进行，涵盖20个交叉口，共计四天采集了约12TB的4K视频数据。该研究的主要背景在于现有的交通监控系统无法充分满足密集城市中的高精度需求，而无人机提供了新的视角和技术手段。
### Innovation
本文的创新主要集中在三个方面：1、专门针对高空鸟瞰视角的物体检测器；2、使用检测到的车辆边界框作为排除掩码以稳定轨迹的独特方法；3、基于正射影像和主帧的地理参考策略，提高了多无人机视角下的一致性对齐。此外，该框架还提供了车辆尺寸估计和详细的道路分割，增强了全面的交通分析能力。相比高精度传感器数据，其提取管道在密集城区中表现出了较高的准确性和一致性。
### Conclusion
本文通过公开Songdo交通和Songdo视觉数据集以及提取管道的全部源代码，确立了交通研究中的新基准，在数据质量、可再现性和可扩展性方面具有重要意义。该研究成果展示了无人机技术和高级计算机视觉技术结合在精确而经济的城市交通监控中的巨大潜力，为开发智能交通系统和优化交通管理策略提供了宝贵的资源。
## 415. `cs.CV` - LBONet: 基于监督的谱描述子用于形状分析 [PDF](https://arxiv.org/pdf/2411.08272), [HTML](https://arxiv.org/abs/2411.08272)
### Authors
Oguzhan Yigit,Richard C. Wilson
### Background
拉普拉斯-贝尔特拉米算子在非刚性形状分析领域因其许多有用特性，如在等距变换下的不变性、具有形成正交规范基的可数本征值系统以及完全描述流形的测地线距离而确立了自己的地位。然而，这种不变性只适用于等距变形，在许多实际应用中会导致性能下降。近年来，强调使用深度学习方法提取最优特征，然而频谱签名依旧具有重要价值。因此，本文重新审视拉普拉斯-贝尔特拉米算子，提出了一种监督方式来在流形上学习多个算子，根据任务的不同，可以优化LBO本征基以使其更加任务特定，从而极大提高了诸如热核签名等已确立描述符在检索、分类、分割和对应等任务中的性能，证明了LBO本征基能够适应全局和高度局部的学习环境。
### Innovation
研究提出了一个新的方法，利用监督学习来学习流形上的一组拉普拉斯-贝尔特拉米算子函数，通过优化这些算子，使得LBO本征基更加特定于特定任务，从而提高了包括热核签名在内的已确立描述符在多种形状分析任务中的性能，并证明了LBO本征基在全局和局部学习环境中的适应性。
### Conclusion
通过监督优化LBO本征基的方法极大地改善了各种任务，包括检索、分类、分割和对应等，证明了LBO本征基能够优化以适应特定任务需求，为非刚性形状分析提供了一种新颖有效的工具。
## 416. `cs.CV` - 召回与精炼：一个简单而有效的无源开放集领域适应框架 [PDF](https://arxiv.org/pdf/2411.12558), [HTML](https://arxiv.org/abs/2411.12558)
### Authors
Ismail Nejjar,Hao Dong,Olga Fink
### Background
开放集领域适应（OSDA）的目标是从已标记的源领域模型适应到未标记的目标领域，同时处理目标领域中未知的新类别（也称为目标私有未知类别）。无源开放集领域适应（SF-OSDA）方法不使用已标记的源数据来解决OSDA问题，在隐私限制下尤为重要。然而，SF-OSDA面临显著挑战，如分布偏移和新类别的引入。现有方法通常通过阈值化预测熵来确定一个样本是已知还是未知类别，但无法明确学习目标私有未知类别的区分特征。
### Innovation
本文提出了一种新颖的SF-OSDA框架——召回与精炼（RRDA）。该框架通过第一阶段训练带有额外决策边界的目标分类器，利用目标域特征生成的合成样本来增强模型识别未识别类的能力。第二阶段适应整个模型，解决领域偏移和与未识别类别的区分性。并且，任何现成的无源领域适应方法（如SHOT、AaD）都可以无缝集成到该框架中。实验表明，RRDA在三个基准数据集上显著优于现有SF-OSDA和OSDA方法。
### Conclusion
本文提出了一种名为召回与精炼（RRDA）的简单而有效的无源开放集领域适应框架，该框架显著改进了无源开放集领域适应问题，通过两个阶段逐步解决了领域偏移和新类别的区分性问题。
## 417. `cs.CV` - MvKeTR：利用多视图感知和知识增强的胸部CT报告生成 [PDF](https://arxiv.org/pdf/2411.18309), [HTML](https://arxiv.org/abs/2411.18309)
### Authors
Xiwei Deng,Xianchun He,Jianfeng Bao,Yudan Zhou,Shuhui Cai,Congbo Cai,Zhong Chen
### Background
CT 报告生成 (CTRG) 能够自动为 3D 图像生成诊断报告，从而减轻临床医生的工作量并提高患者护理质量。尽管具有临床价值，现有的工作未能有效结合多个解剖视角下的诊断信息，缺乏准确可靠诊断所必需的相关临床专业知识。为了克服这些限制，该研究提出了一种新型的多视图感知知识增强变换器 (MvKeTR)，模仿临床医生的诊断工作流程。
### Innovation
研究提出了一种名为 Multi-view Perception Aggregator (MVPA) 的多视图感知聚合器，具有视角意识的注意力机制，有效综合来自多个解剖视角的诊断信息。还设计了一个跨模态知识增强器 (CMKE)，根据查询影像检索最相似的报告，并将领域知识融入诊断流程中。此外，研究使用柯尔莫哥洛夫-阿诺尔德网络 (KAN) 作为两个模块的基本构建块，这些网络展示出优越的参数效率和降谱偏差能力，更好地捕捉关键的高频率成分，以改善 CT 解释，同时减轻过拟合。
### Conclusion
在公共 CTRG-Chest-548 K 数据集上的广泛实验表明，该方法在几乎所有指标上都超过了此前的最新模型。研究的代码可以在指定链接获取。
## 418. `cs.CV` - RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation Model [PDF](https://arxiv.org/pdf/2411.17984), [HTML](https://arxiv.org/abs/2411.17984)
### Authors
Huiyang Hu,Peijin Wang,Hanbo Bi,Boyuan Tong,Zhaozhi Wang,Wenhui Diao,Hao Chang,Yingchao Feng,Ziqi Zhang,Yaowei Wang,Qixiang Ye,Kun Fu,Xian Sun
### Background
遥感领域的基础模型在很大程度上打破了传统为特定任务设计模型的范式，提高了在多个任务上的可扩展性。但是，这些模型面临计算效率低和可解释性差的挑战，尤其是在处理大规模遥感影像时。现有的研究需要找到一种新的方法来应对这些挑战，例如借鉴物理过程中的局部热扩散原理，提出一种高效且具有良好解释性的多模态遥感基础模型。
### Innovation
该研究从热传导这一物理过程汲取灵感，首次将热传导的并行计算模型用于模拟高分辨率遥感影像中的局部区域相关性。通过引入RS-vHeat，一种高效的多模态遥感基础模型，该研究实现了以下创新：1) 应用具有 $O(N^{1.5})$ 复杂度和全局感受野的热传导算子（HCO）来降低计算开销，同时捕捉遥感物体结构信息以引导热传导；2) 通过基于频域层次掩码和多领域重构的自监督策略，学习各种场景的频率分布表示；3) 在4个任务和10个数据集上显著提高了效率和性能，与基于注意力的遥感基础模型相比，RS-vHeat 在内存使用方面减少了84%，FLOPs 减少了24%，吞吐量提高了2.7倍。
### Conclusion
实验结果表明，RS-vHeat 在多种任务上取得了优异的性能，并且在大幅度减少计算资源消耗的同时，提高了模型的效率和可解释性。代码将对外公开。
## 419. `cs.CV` - InfiniCube：基于世界导向视频模型的无界可控动态3D驾驶场景生成 [PDF](https://arxiv.org/pdf/2412.03934), [HTML](https://arxiv.org/abs/2412.03934)
### Authors
Yifan Lu,Xuanchi Ren,Jiawei Yang,Tianchang Shen,Zhangjie Wu,Jun Gao,Yue Wang,Siheng Chen,Mike Chen,Sanja Fidler,Jiahui Huang
### Background
先前的场景生成方法要么受限于规模，要么在生成的序列中缺乏几何和外观一致性。因此，这些方法无法提供既具有高度准确性和可控性的大规模动态3D驾驶场景。本研究旨在利用最新的可扩展3D表示和视频模型技术，克服上述限制，实现大规模动态场景的生成和精确定制。
### Innovation
本研究创新性地提出了基于稀疏体素的世界导向视频模型的InfiniCube方法，用于生成无边界的大规模动态3D驾驶场景。具体来说，该方法首先构建了一个基于稀疏体素的地图条件生成模型，以适用于无边界体素世界的生成；随后，通过一组精心设计的像素对齐引导缓存重新利用视频模型，并将其固定在体素世界中，以生成一致的外观；最后，提出了一种采用体素和像素分支的快速前馈策略，将动态视频提升为可控的动态3D高斯分布。这种方法能够生成既可控又逼真的3D驾驶场景，实验验证了该模型的有效性和优越性。
### Conclusion
通过InfiniCube方法，可以生成具有高准确性和可控性的无边界大规模动态3D驾驶场景。实验结果证明了该方法的有效性和优越性。
## 420. `cs.CV` - 预训练可逆生成模型作为无监督视觉表示学习 [PDF](https://arxiv.org/pdf/2412.01787), [HTML](https://arxiv.org/abs/2412.01787)
### Authors
Rongkun Xue,Jinouwen Zhang,Yazhe Niu,Dazhong Shen,Bingqi Ma,Yu Liu,Jing Yang
### Background
最近基于评分匹配和流匹配的生成模型在生成任务中取得了显著进展，但它们在区分任务中的潜力尚未得到充分利用。之前的方法，如生成分类器，未能充分利用这些模型在区分任务中的功能，因为这些方法的设计比较复杂。
### Innovation
本文提出了预训练可逆生成模型（Pretrained Reversible Generation，PRG），它通过逆向预训练连续生成模型的生成过程来提取无监督表示。PRG有效地重用了无监督生成模型，利用它们的高容量作为用于下游任务的鲁棒且可泛化的特征提取器。此框架允许针对特定下游任务灵活选择特征层次结构。本文的方法在多个基准测试中始终超过了先前的方法，达到了生成模型基线方法中的最先进的性能，包括在 64*64 分辨率的 ImageNet 上的 78% 的 top-1 准确率。广泛的消融研究，包括离分布评估，进一步验证了本文方法的有效性。
### Conclusion
预训练可逆生成模型通过提供一种新的方法，能够有效提取用于下游任务的无监督表示，展示了高容量生成模型在区分任务中的强大潜力。
## 421. `cs.CV` - ToMiE: 朝向明确外骨骼的复杂3D人体模型重建 [PDF](https://arxiv.org/pdf/2410.08082), [HTML](https://arxiv.org/abs/2410.08082)
### Authors
Yifan Zhan,Qingtian Zhu,Muyao Niu,Mingze Ma,Jiancheng Zhao,Zhihang Zhong,Xiao Sun,Yu Qiao,Yinqiang Zheng
### Background
在大多数3D人机交互任务中，往往忽视了一个关键因素，即建模复杂的3D人体，特别是在手持物件或宽松衣物的情况下。尽管SMPL参数化模型能够很好地拟合人体皮肤，但手持物件和宽松衣物由于其运动通常与人体解耦，难以在统一框架内建模。当前方法无法有效处理此类情况，导致SMPL骨架的适应性较差，影响渲染质量和动画的表达能力。
### Innovation
本文提出了一种新的生长策略——ToMiE，该策略能够使骨架关节树自适应扩展。具体来说，ToMiE 方法包括两个方面：首先，采用基于梯度的方法定位父关节；其次，对外部关节进行优化，并使用SE(3)在不同帧中优化这些关节的变换，以实现渲染和显式动画。研究表明，ToMiE在具有手持物件和宽松衣物的各种情况下，不仅在渲染质量上表现优异，还能够提供生长关节的自由动画，显著增强了SMPL骨架的表达能力，适用于更广泛的应用场景。
### Conclusion
ToMiE 方法成功解决了手持物件和宽松衣物建模难题，通过自适应扩展的方法增强了SMPL骨架的适应性，不仅提高了渲染质量，也提供了自由动画功能，使得SMPL骨架能够更好地适应复杂的3D人体交互任务。
## 422. `cs.CV` - SIDA: 使用大型多模态模型的社交媒体图像 deepfake 检测、定位和解释 [PDF](https://arxiv.org/pdf/2412.04292), [HTML](https://arxiv.org/abs/2412.04292)
### Authors
Zhenglin Huang,Jinwei Hu,Xiangtai Li,Yiwei He,Xingyu Zhao,Bei Peng,Baoyuan Wu,Xiaowei Huang,Guangliang Cheng
### Background
生成模型的快速发展使得生成极具真实感的图像成为可能，这带来了大规模信息误导的风险。这些合成图像在社交媒体上传播时，能够误导大量受众，损害数字内容的信任度，引发严重后果。尽管取得了一定的进展，学术界尚未构建一个用于社交媒体的大规模多样化 deepfake 检测数据集，也未提出有效的解决方案来应对这一问题。
### Innovation
该论文介绍了一个新的社交媒体图像检测数据集（SID-Set），其中包括30万张人工生成的/篡改的和真实的图像，覆盖广泛类别且高度逼真。此外，还提出了一种新的图像 deepfake 检测、定位和解释框架 SIDA，通过掩码预测指出篡改区域，并提供模型判断标准的文本解释。SIDA 在具有不同设置的 SID-Set 和其他基准测试中表现优于现有 deepfake 检测模型。
### Conclusion
广泛的实验表明，SIDA 在多设置下均实现了更好的性能。开放代码、模型和数据集以促进相关研究。
## 423. `cs.CV` - Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts [PDF](https://arxiv.org/pdf/2412.10028), [HTML](https://arxiv.org/abs/2412.10028)
### Authors
Chang-Bin Zhang,Yujie Zhong,Kai Han
### Background
现有的检测器通过引入辅助的一对多指派来增强检测变压器的训练。本研究在该背景下，将模型视为一个多任务框架，同时进行一对一和一对多的预测。研究了Transformer解码器中每个组件在这些两个训练目标中的作用，包括自注意力、交叉注意力和前馈网络。实验结果表明，任何解码器中的独立组件都能有效同时学习这两个目标，即使其他组件是共享的。这一发现促使我们提出了一个多路线训练机制，包括一个主要路线进行一对一预测和两个辅助训练路线进行一对多预测。
### Innovation
提出了一个多路线训练机制，特色是个主要路线进行一对一预测，两个辅助训练路线进行一对多预测。还引入了指导性自注意力机制，作为第一个辅助路线的一部分，引导物体查询进行一对多预测。对于第二个辅助路线，引入了路径感知的Mixture-of-Experts (MoE)，在促进知识共享的同时，减轻不同路径之间的潜在冲突。此外，将MoE应用于编码器中的低尺度特征，实现了效率和效果之间的平衡。辅助路线在推理时被丢弃。该研究在多个物体检测基线中进行了广泛的实验，如图1所示，展示了持续改进。该方法具有高度灵活性，并可以轻松适应其他任务。为了展示其多功能性，还进行了实例分割和全景分割实验，进一步验证了其有效性。
### Conclusion
本研究提出了一种多路线训练机制，以及指导性自注意力机制和路径感知的Mixture-of-Experts，这些方法在多个物体检测基线中取得了持续的改进。该方法具有高度的灵活性，并已验证其在实例分割和全景分割任务中的有效性。
## 424. `cs.CV` - 重思无约束场景中显著与伪装物体检测 [PDF](https://arxiv.org/pdf/2412.10943), [HTML](https://arxiv.org/abs/2412.10943)
### Authors
Zhangjun Zhou,Yiping Li,Chunlin Zhong,Jianuo Huang,Jialun Pei,Hua Li,He Tang
### Background
现有的模型在区分显著物体与伪装物体时受到影响，主要在于当前显著物体检测（SOD）和伪装物体检测（COD）数据集采用的互斥标注方式以及模型中缺乏对显著与伪装物体关系的明确建模。这种标注方式未能反映现实世界的复杂性，现有的SOD/COD方法在这些高度受限的数据集上效果有限，难以有效处理未授权的场景。因此，研究提出了一个包含四大场景和综合标签的大规模数据集USC12K，以促进对显著和伪装物体检测方法的研究和开发，通过构造这个数据集，论文旨在填补现实与现有数据集之间的差距。
### Innovation
论文的创新点在于提出了一个新的大规模数据集USC12K，该数据集为所有可能的逻辑存在场景提供了全面的标签。此外，论文为显著物体和伪装物体之间的关系引入了独特的提示查询机制，提出了一个新的评估指标CSCS，并展示了在多个指标上达到最先进的性能。通过USCNet模型和CSCS评估指标，能够有效地分离显著物体与伪装物体的功能得到了验证和支持。
### Conclusion
研究结果表明，通过USC12K数据集和USCNet模型的应用，研究人员可以更有效地检测和区分自然场景中的显著物体和伪装物体，为未来的研究提供了新的数据基础和评估标准。
## 425. `cs.CV` - SweepEvGS：单扫事件引导的3D高斯散斑渲染 [PDF](https://arxiv.org/pdf/2412.11579), [HTML](https://arxiv.org/abs/2412.11579)
### Authors
Jingqian Wu,Shuo Zhu,Chutian Wang,Boxin Shi,Edmund Y. Lam
### Background
近年来，3D高斯散斑（3D-GS）技术展示了使用3D高斯原语进行高速、高保真、低成本视角合成的潜力。然而，传统方法需要高帧率的密集且高质量的锐利图像，这在动态环境中的捕获过程耗时且低效。事件相机具有高时间分辨率和异步亮度变化捕捉能力，为无运动模糊的场景重建提供了新的可能。本文背景在于现有技术的不足以及事件相机在3D视图合成中的潜力。
### Innovation
本文提出了一种新的硬件集成方法SweepEvGS，利用事件相机在单一扫掠过程中捕获的初始静态图像和密集事件流进行鲁棒和准确的视角合成。该方法不仅适用于静态环境，还能处理动态环境，具备可视化渲染质量、渲染速度和计算效率等方面的优势，特别适合动态应用。此外，文中还引入了多种实际硬件成像系统以收集数据并评估其性能，为其未来研究提供了支持.
### Conclusion
实验结果表明，SweepEvGS在三种不同的成像设置下（合成物体、现实世界的宏观级别和微观级别视角合成）均超越了现有方法，在视觉渲染质量、渲染速度和计算效率上表现出色，突显了其在动态实际应用中的潜力。
## 426. `cs.CV` - Materialist：基于单图像逆渲染的物理为基础的编辑 [PDF](https://arxiv.org/pdf/2501.03717), [HTML](https://arxiv.org/abs/2501.03717)
### Authors
Lezhong Wang,Duc Minh Tran,Ruiqi Cui,Thomson TG,Anders Bjorholm Dahl,Siavash Arjomand Bigdeli,Jeppe Revall Frisvad,Manmohan Chandraker
### Background
在计算机视觉中，实现物理一致的图像编辑仍是一项重大挑战。现有图像编辑方法通常依赖于神经网络，但难以准确处理阴影和折射。相比之下，基于物理逆渲染的方法通常需要多视图优化，限制了其在单图像场景中的实用性。
### Innovation
本文提出了一种名为Materialist的方法，结合了基于学习的方法和基于物理的渐进可微渲染。在给定图像的情况下，该方法利用神经网络预测初始材料属性，并使用渐进可微渲染来优化环境图并精炼材料属性，以更好地匹配渲染结果和输入图像。此外，该方法还提供了一种有效的材料透明度编辑方法，无需完整场景几何结构，并且在环境图估计方面达到了业界领先水平，进一步提高了图像编辑任务的准确性。
### Conclusion
实验结果表明，在合成和现实世界数据集上表现出强大性能，甚至在具有挑战性的跨域图像上也是如此。
## 427. `cs.CV` - UP-VLA: 统一理解与预测的具身代理模型 [PDF](https://arxiv.org/pdf/2501.18867), [HTML](https://arxiv.org/abs/2501.18867)
### Authors
Jianke Zhang,Yanjiang Guo,Yucheng Hu,Xiaoyu Chen,Xiang Zhu,Jianyu Chen
### Background
近期在视觉-语言-行动(VLA)模型方面的进展利用了预训练的视觉-语言模型(VLMs)以提升泛化能力。尽管VLMs在高阶语义内容上表现出色，但它们往往忽略了低级特征，限制了对详细的空间信息和物理动态的理解，这对实际的具身控制任务至关重要。现有的预训练方法尚未充分探索这些方面。
### Innovation
该论文提出了一种统一的理解与预测(VLA)模型训练方法，即UP-VLA。UP-VLA通过结合多模态理解和未来预测目标，同时提升了高层语义理解和低级空间理解。实验结果表明，UP-VLA在Calvin ABC-D基准测试中比之前最先进的方法提高了33%的性能，并且在实际的操控任务中表现出更高的成功率，特别对于需要精确空间信息的任务尤为显著。
### Conclusion
UP-VLA通过综合提升高层语义理解与低级空间理解，在具身控制任务中表现优异，并取得了显著的性能提升。
## 428. `cs.CV` - ARTalk: 通过自回归模型实现基于语音的3D头部动画 [PDF](https://arxiv.org/pdf/2502.20323), [HTML](https://arxiv.org/abs/2502.20323)
### Authors
Xuangeng Chu,Nabarun Goswami,Ziteng Cui,Hanqin Wang,Tatsuya Harada
### Background
当前，基于语音的3D面部动画旨在从任意音频片段中生成逼真的唇部运动和面部表情。虽然现有的基于扩散的方法能够生成自然的动作，但其缓慢的生成速度限制了其潜在的应用。
### Innovation
本文提出了一种新颖的自回归模型，该模型通过学习从语音到多尺度运动码本的映射来实现实时的唇部运动和高同步度的真实头部姿态及眨眼动作的生成。此外，该模型可以适应未见过的演讲风格，从而能够创建具有独特个人风格的3D互动替身，超越训练期间看到的身份。
### Conclusion
大规模评估和用户研究显示，本方法在口部同步准确度和感知质量方面优于现有方法。
## 429. `cs.CV` - GroundCap: 一个视觉语义关联的图像字幕数据集 [PDF](https://arxiv.org/pdf/2502.13898), [HTML](https://arxiv.org/abs/2502.13898)
### Authors
Daniel A. P. Oliveira,Lourenço Teodoro,David Martins de Matos
### Background
当前的图像字幕系统缺乏将描述性文本与特定视觉元素联系起来的能力，使得输出难以验证。虽然最近的方法提供了一些场景语义关联的能力，但它们无法在多个引用中跟踪对象身份或同时将动作和对象与图像联系起来。
### Innovation
本文提出了一种基于ID的语义关联系统，该系统能够实现一致的对象引用跟踪和动作-对象关联。还提出了一个名为GroundCap的数据集，包含来自77部电影的52,016张图像，每个图像都带有手动标注和自动生成的描述。这些描述使用标签系统链接了对象和动作，并维护了对象身份。此外，该系统通过K-means聚类分割背景元素，并提出了一种结合描述质量和语义关联准确性的评估指标gMETEOR。研究人员还通过Fine-tuning Pixtral-12B和Qwen2.5-VL 7B模型在GroundCap上建立了基线性能。
### Conclusion
通过实证分析，发现该方法能够生成可以验证且具有连贯性对象引用的描述。
## 430. `cs.CV` - ClearSight: 基于人类视觉的事件驱动运动去模糊解决方案 [PDF](https://arxiv.org/pdf/2501.15808), [HTML](https://arxiv.org/abs/2501.15808)
### Authors
Xiaopeng Lin,Yulong Huang,Hongwei Ren,Zunchang Liu,Yue Zhou,Haotian Fu,Bojun Cheng
### Background
运动模糊图像处理旨在解决由于相机或场景运动引起的图像模糊问题。事件相机提供了一个异步事件流，其中包含运动信息。为了高效利用事件流中的时间信息，该研究采用脉冲神经网络（SNN）进行运动特征提取，采用人工神经网络（ANN）进行颜色信息处理。然而，由于事件数据的非均匀分布及其固有的冗余性，现有的跨模态特征融合方法存在一定的局限性。因此，受人类视觉系统视觉注意力机制的启发，研究提出了一种仿生双驱混合网络（BDHNet）。
### Innovation
BDHNet通过引入神经配置模块（NCM）和区域模糊注意力模块（RBAM）解决现有问题。NCM能够根据跨模态特征动态调整神经元配置，聚焦在模糊区域的脉冲并动态适应不同的模糊场景。RBAM则可以在无监督的情况下生成模糊掩码，有效地从事件特征中提取运动线索并引导更准确的跨模态特征融合。实验结果表明，该方法在合成和真实数据集上均显著优于现有最先进的方法。
### Conclusion
本文提出的方法通过仿生双驱混合网络在运动去模糊方面表现出色，特别是在合成和真实数据集上取得了优越性能。
## 431. `cs.CV` - 利用基础视觉变换器在材料中学习显微结构-性能关系 [PDF](https://arxiv.org/pdf/2501.18637), [HTML](https://arxiv.org/abs/2501.18637)
### Authors
Sheila E. Whitman,Marat I. Latypov
### Background
在计算材料科学中，从数据中学习显微结构-性能关系的机器学习方法正在逐渐成为一种新兴的手段。现有的大多数机器学习努力集中在为每种显微结构-性能关系开发特定任务的模型上。本文提出利用预训练的基础视觉变换器提取任务无关的显微结构特征，随后通过轻量级机器学习预测显微结构依赖的性能。作者通过两个案例研究来证明该方法的有效性：一个是基于模拟数据预测双相显微结构的弹性模量，另一个是基于文献实验数据预测镍基和钴基超合金的维氏硬度。这些结果表明，基础视觉变换器在表示显微结构方面具有鲁棒性，并且可以在不需要昂贵的特定任务训练或微调定制深度学习模型的情况下有效地学习显微结构-性能关系。
### Innovation
本文提出了一种新的方法，即利用预训练的基础视觉变换器提取任务无关的显微结构特征，进而进行轻量级的显微结构依赖性能的机器学习，不同于传统方法专注于特定任务的模型开发。这种方法无需昂贵的特定任务训练或微调定制深度学习模型。通过两个具体案例研究展示了这种方法的有效性和广泛适用性。
### Conclusion
研究表明，基础视觉变换器有潜力提供一种有效的显微结构表示方法，并且可以在无需昂贵的特定任务训练或微调定制深度学习模型的情况下高效地学习显微结构-性能关系。
## 432. `cs.CV` - 拆解以重构：通过主动特征拆解和可逆融合实现高质量UHD重建 [PDF](https://arxiv.org/pdf/2503.12764), [HTML](https://arxiv.org/abs/2503.12764)
### Authors
Yidi Liu,Dong Li,Yuxin Ma,Jie Huang,Wenlong Zhang,Xueyang Fu,Zheng-jun Zha
### Background
超高清（UHD）图像恢复常常面临计算瓶颈和信息丢失问题，这是因为其极高的分辨率。现有基于变分自编码器（VAE）的研究通过将图像恢复过程从像素空间转移到潜在空间来提高效率，然而，退化组件在退化图像中与背景元素紧密耦合，压缩过程中的信息丢失和补偿过程中的信息获取仍然难以控制。这导致恢复后的图像常常出现图像细节损失和退化去除不完全的情况。
### Innovation
本文提出了一种受控差异解耦VAE，它利用层级对比解耦学习和正交门控投影模块来引导VAE有目的地丢弃可以容易恢复的背景信息，并将其更为难以恢复的退化信息编码到潜在空间中。此外，设计了一种复杂的可逆多尺度融合网络来处理背景特征，确保其一致性，并利用潜在空间恢复网络来转换退化的潜在特征，从而得到更准确的恢复结果。
### Conclusion
广泛的实验结果表明，我们的方法有效地缓解了VAE模型中的信息丢失问题，同时保证了计算效率，显著提高了UHD图像恢复的质量，并且仅使用1M参数就实现了六个UHD恢复任务的最先进的结果。
## 433. `cs.CV` - DisCoPatch: 改进异类检测的对抗驱动批量统计管理 [PDF](https://arxiv.org/pdf/2501.08005), [HTML](https://arxiv.org/abs/2501.08005)
### Authors
Francisco Caetano,Christiaan Viviers,Luis A. Zavala-Mondragón,Peter H. N. de With,Fons van der Sommen
### Background
异常分布（OOD）检测在许多应用程序中具有重要性。尽管语义和领域转移的OOD问题已被广泛研究，本研究关注的是协变量偏移——数据分布中的细微变化，它可以降低机器学习的性能。我们认为，检测这些细微的偏移变化可以提高我们对类别内部边界的理解，从而提高OOD检测的效果。在采用批量归一化（BN）训练的对抗判别器中，真实样本和生成样本形成了具有独特批量统计数据的不同领域，这是进行OOD检测的机制。
### Innovation
作者引入了DisCoPatch，这是一种无监督的对抗变分自编码器（VAE）框架，利用真实样本和生成样本具有不同批量统计数据的特性进行OOD检测。DisCoPatch通过使用VAE的次优生成和重建输出作为负面样本来训练判别器，增强了其在区分污点分布样本和协变量偏移方面的边界划分能力。通过缩小边界，DisCoPatch在公共OOD检测基准测试中达到了最先进的结果。特别是在ImageNet-1K(-C)和Near-OOD基准测试中，DisCoPatch表现出优异的性能，同时具有紧凑的模型大小25MB，并且能实现显著降低的延迟，使其成为一个高效的、实际的OOD检测解决方案。
### Conclusion
DisCoPatch不仅可以有效地检测协变量偏移，在ImageNet-1K(-C)上的AUROC达到95.5%，还在公共Near-OOD基准测试中超越了所有先前的方法。此外，通过具有紧凑的模型大小和低延迟，它提供了一种高OOD检测性能的高效和实际的应用解决方案。已经公开提供的代码。
## 434. `cs.CV` - PP-DocBee: 提高多模态文档理解的一种技巧包 [PDF](https://arxiv.org/pdf/2503.04065), [HTML](https://arxiv.org/abs/2503.04065)
### Authors
Feng Ni,Kui Huang,Yao Lu,Wenyu Lv,Guanzhong Wang,Zeyu Chen,Yi Liu
### Background
随着数字化的快速发展，各种文档图像在生产和日常生活中被广泛应用，迫切需要快速准确地解析文档图像中的内容。
### Innovation
PP-DocBee是一种为端到端文档图像理解设计的新颖多模态大型语言模型。开发了针对文档场景的数据合成策略，构建了多样化的数据集以提高模型的泛化能力。还应用了动态比例采样、数据预处理和OCR后处理策略。PP-DocBee在英文文档理解基准测试中达到了最新的技术水平，并在中文文档理解方面甚至超越了现有的开源和商用模型。
### Conclusion
该研究公开了PP-DocBee的源代码和预训练模型，实现了卓越的文档图像理解性能，为文档理解和处理领域带来了创新方案。
## 435. `cs.CV` - Zero-TIG: 临时一致性的零样本光照引导低光照视频增强 [PDF](https://arxiv.org/pdf/2503.11175), [HTML](https://arxiv.org/abs/2503.11175)
### Authors
Yini Li,Nantheera Anantrasirichai
### Background
低光照和水下视频存在可见度差、对比度低和噪音高的问题，需要提高视觉质量。现有方法通常依赖配对的地标数据，这限制了其实用性并往往无法保持时间一致性。
### Innovation
本文提出了一个名为Zero-TIG的新型零样本学习方法，结合视网膜理论和光学流技术。该网络包括增强模块和时间反馈模块。增强模块包含三个子网络：低光照图像去噪、照明估计和反射去噪。时间增强模块通过引入直方图均衡化、光学流动计算和图像变形来确保时间一致性，从而在增强的前一帧与当前帧间保持连续性。此外，通过动态平衡RGB通道解决了水下数据的色彩失真问题。实验结果显示，该方法能够在无需配对训练数据的情况下实现低光照视频的增强，具有在实际场景中增强的前景和适用性.
### Conclusion
本文提出了一个零样本学习方法Zero-TIG，旨在提高低光照和水下视频的视觉质量。通过结合多种技术，该方法能够实现时间一致性和更多的功能性，并且在无需配对地标数据的情况下也能有效工作，显示出在实际场景中的应用前景。
## 436. `cs.CV` - AnyCalib：基于流形学习的模型无关单视角相机校准 [PDF](https://arxiv.org/pdf/2503.12701), [HTML](https://arxiv.org/abs/2503.12701)
### Authors
Javier Tirado-Garín,Javier Civera
### Background
当前的相机校准方法大多针对特定的相机模型，并且通常需要可见的外部线索（如重力方向）以进行校准。现有方法受限于此，本文则提出了一个不同的视角，认为图像中的透视和失真线索足以进行模型无关的相机校准。该方法将校准过程视为每个像素对应射线的回归问题，首次展示了这一中间表示形式能够以闭形式恢复多种相机模型的固有参数，包括但不限于孔状相机、布朗-康纳迪相机和坎纳拉-布兰德特相机。此外，该方法也适用于经过编辑（裁剪和拉伸）的图像。实验结果表明，尽管训练数据量少得多，AnyCalib仍然优于其他方法，包括3D基础模型。
### Innovation
提出了AnyCalib方法，这是一种模型无关的单视角相机校准方法，它直接从单张野外拍摄的图像中校准相机的固有参数，并且对特定的相机模型不敏感。该方法通过回归每个像素对应的射线来重建相机固有参数，展示了对多种相机模型（包括孔状、布朗-康纳迪和坎纳拉-布兰德特等）固有参数的闭形式恢复，并且适用于经过编辑的图像。实验表明该方法大大优于现有方法，且所需训练数据量更少。
### Conclusion
该研究通过实验验证了从单张图像校准相机固有参数的有效性，尤其是提出的方法能够在没有特定模型假设和额外外部线索的情况下实现这一目标。实验结果表明，尽管训练数据量较少，AnyCalib仍然表现出色，超过了其他方法，包括基于3D的基本模型。开源代码已提供。
## 437. `cs.CV` - SimWorld: 基于世界模型的统一模拟器条件场景生成基准 [PDF](https://arxiv.org/pdf/2503.13952), [HTML](https://arxiv.org/abs/2503.13952)
### Authors
Xinqing Li,Ruiqi Song,Qingyu Xie,Ye Wu,Nanxin Zeng,Yunfeng Ai
### Background
随着自动驾驶技术的快速发展，数据不足成为提升感知模型准确度的主要障碍。研究人员正在探索使用世界模型进行可控的数据生成，以丰富数据集。然而，大部分前期工作主要集中在特定公开数据集上的图像生成质量研究，关于如何构建适用于真实世界应用场景的数据生成引擎，以实现复杂场景的大规模数据生成的研究还不够多。本文提出了一种基于世界模型的模拟器条件场景生成引擎，通过构建与现实场景一致的模拟系统，可以为任意场景收集仿真数据和标签作为数据生成的先决条件。该方法结合了仿真引擎强大的场景仿真能力和世界模型稳健的数据生成能力。
### Innovation
提出了一种基于世界模型的模拟器条件场景生成引擎，通过建设与现实场景一致的模拟系统，收集了可用于任意场景的仿真数据和标签，极大地提高了数据生成的灵活性和应用性。此外，该研究还提供了比例构建的虚拟与真实数据基准，以探索世界模型在真实世界场景中的能力。实验结果表明，生成的图像显著提高了下游感知模型的性能。并且研究了世界模型在城市自动驾驶场景中的生成性能。
### Conclusion
该研究通过提出基于世界模型的模拟器条件场景生成引擎，极大地提高了数据生成的灵活性和性能，并且通过设定比例构建的虚拟与真实数据基准，验证了世界模型在真实世界场景中的卓越能力。所有的数据和代码在此网站中提供。
## 438. `cs.CV` - STI-Bench：MLLMs准备注入精确的空间-时间世界理解吗？ [PDF](https://arxiv.org/pdf/2503.23765), [HTML](https://arxiv.org/abs/2503.23765)
### Authors
Yun Li,Yiming Zhang,Tao Lin,XiangRui Liu,Wenxiao Cai,Zheng Liu,Bo Zhao
### Background
多模态大型语言模型（MLLMs）作为端到端解决方案在具身AI和自主驾驶领域逐渐成为主流。尽管MLLMs已广泛研究应用于视觉语义理解任务，但它们在现实世界应用中执行精确和定量的空间-时间理解的能力仍鲜有研究，这导致了对其未来发展的不确定性。为了评估模型的空间-时间智能，本文引入了STI-Bench评估基准，该基准通过估计和预测物体的外观、姿态、位移和运动等挑战性任务，来评估MLLMs的空间-时间理解能力。此基准涵盖了广泛的家庭机器人和车辆操作，涉及从桌面、室内到室外的各种场景。实验结果表明，最先进的MLLMs在真实环境中的空间-时间理解方面仍存在困难，特别是在需要精确距离估计和运动分析的任务中。
### Innovation
本文提出了STI-Bench，一个用于评估MLLMs在空间-时间理解能力的基准，通过一系列具有挑战性的任务来评测模型的表现，广泛覆盖家庭机器人和车辆操作，并涵盖从桌面、室内到室外的各种复杂场景。
### Conclusion
现有的最先进的MLLMs在真实世界的空间-时间理解任务中仍面临挑战，特别是在需要精确估计距离和分析运动的任务中挣扎。
## 439. `cs.CV` - 通过半监督视频语义分割中的语义相似性传播实现自主飞行中的高时间一致性 [PDF](https://arxiv.org/pdf/2503.15676), [HTML](https://arxiv.org/abs/2503.15676)
### Authors
Cédric Vincent,Taehyoung Kim,Henri Meeß
### Background
自主飞行车辆的感知依赖于来自RGB相机的语义分割，这对于视频捕获中的预测稳定性至关重要，这关系到其可靠性和自主飞行代理的信任度。然而，由于数据可获得性成为关键挑战，特别是在稀疏标注的语料库中缺少有效指导。因此，提出一种结合时空一致性的半监督视频语义分割方法，以提高语义分割模型的实时性，并通过语义一致性传播实现高帧间一致性，进而提高图像分割的视觉效果和预测能力，特别强调了在自主飞行背景下实时访问与推理的迫切需求和当前存在的不足。
### Innovation
提出了一种轻量级视频语义分割方法——语义相似性传播（Semantic Similarity Propagation，SSP），该方法通过全局注册对齐和线性插值来跟踪和补偿摄像头运动，从而实现高时间一致性。进一步地，提出了一种在稀疏标注数据集上进行半监督训练的新方法——一致性感知的知识蒸馏（Knowledge Distillation），以提高模型的性能和应用效率。研究表明，该方法能有效地提升空域数据的语义一致性，相较于基线模型，提高了12.5%和6.7%的一致性。此外，该方法还在精度和推理速度上提供了更高性能的平衡，特别是在用于通用应用的视频方法上显现出明显的优势。
### Conclusion
本研究通过语义相似性传播和知识蒸馏的方法，提高了自主飞行中的视频语义分割的实时性和准确性，特别在空域数据集上表现出了更高的时间一致性和分割质量，对于促进自主飞行技术的发展具有重要意义。
## 440. `cs.CV` - AirCache：激活多模态相关性KV缓存压缩以实现高效的大规模视觉语言模型推理 [PDF](https://arxiv.org/pdf/2503.23956), [HTML](https://arxiv.org/abs/2503.23956)
### Authors
Kai Huang,Hao Zou,Bochen Wang,Ye Xi,Zhen Xie,Hao Wang
### Background
大型视觉语言模型（LVLMs）由于其出色的推理能力和泛化能力而越来越受到关注。然而，处理大量视觉标记并生成长上下文输出会带来巨大的计算负担，进而对键值（KV）缓存产生过高的需求。为解决这一关键瓶颈问题，本文系统地研究了LVLMs注意机制中视觉和文本标记之间的关联，发现缓存中的视觉标记存在显著冗余，可以通过策略性地消除这些冗余标记来保持模型性能并显著加速上下文生成。
### Innovation
本文提出了AirCache，这是一种新颖的KV缓存压缩方法，旨在加速LVLMs推理过程。AirCache通过引入精英观察窗口来评估视觉组件在KV缓存中的重要性，专注于稳定跨模态相关性建模，采用增强的多视角一致性。此外，还开发了一种自适应逐层预算分配策略，依据标记重要性分布的强度和偏斜性来实现最优分配，展示了与均匀分配相比更高的效率。
### Conclusion
在多个LVLMs和基准上的综合评估表明，该方法在保持与满缓存相同性能的前提下，仅保留了视觉KV缓存的10%，从而将解码延迟降低了29%到66%，且随着缓存保留率降低，该方法的表现优势更为显著，优于现有方法。
## 441. `cs.CV` - BRepFormer: 基于transformer的B-rep几何特征识别 [PDF](https://arxiv.org/pdf/2504.07378), [HTML](https://arxiv.org/abs/2504.07378)
### Authors
Yongkang Dai,Xiaoshui Huang,Yunpeng Bai,Hao Guo,Hongping Gan,Ling Yang,Yilei Shi
### Background
识别B-rep模型的几何特征是多媒体基于内容检索和智能制造业中的关键技巧。然而，以往的研究主要集中在加工特征识别（MFR），在捕获复杂几何特征的拓扑和几何复杂性方面表现不足。
### Innovation
本文提出了BRepFormer，这是一种新颖的基于transformer的模型，用于同时识别加工特征和复杂CAD模型的特征。BRepFormer通过编码和融合模型的几何和拓扑特征，并利用transformer架构进行特征传播和一个识别头部来识别几何特征。在每次transformer迭代中，BRepFormer结合了边特征和拓扑特征的偏置，以增强每张面的几何约束。此外，还提出了一种名为复杂B-rep特征数据集（CBF）的数据集，包含20,000个B-rep模型，更好地面向工业应用。
### Conclusion
实验结果表明，BRepFormer在MFInstSeg、MFTRCAD和我们的CBF数据集上达到了最先进的准确性。
## 442. `cs.CV` - 3D Hierarchical Panoptic Segmentation in Real Orchard Environments Across Different Sensors [PDF](https://arxiv.org/pdf/2503.13188), [HTML](https://arxiv.org/abs/2503.13188)
### Authors
Matteo Sodano,Federico Magistri,Elias Marks,Fares Hosn,Aibek Zurbayev,Rodrigo Marcuzzi,Meher V. R. Malladi,Jens Behley,Cyrill Stachniss
### Background
农作物产量估计在农业中是一个相关的问题，准确的产量估计可以支持农民在收获或精确干预方面的决策。机器人可以帮助自动化这一过程，但需要能够感知周围的环境以识别目标对象，如树木和植物。这项工作旨在解决三维数据中来自不同传感器的苹果园层次化全景分割问题，以同时实现语义分割、树干和果实的实例分割以及树木（树干及其果实）的实例分割，从而识别个体植物、果实和树干等重要信息，并捕捉它们之间的关系，例如精确估计每个果园中树木的果实数量。
### Innovation
本研究提出了一种新颖的方法，用于在不同传感器的3D数据上进行苹果园的层次化全景分割。该方法能够同时提供语义分割、树干和果实的实例分割以及树木的实例分割。为了高效评估该方法的层次化全景分割性能，提供了一个专门为这一任务设计的数据集。该数据集在德国波恩的真实苹果园中录制，并配备了从地面激光扫描仪到机器人平台上的RGB-D相机等各种传感器。实验表明，该方法在农业领域中超越了现有的最佳方法，同时提供了完整的层次化全景分割。
### Conclusion
本文提出了一个新颖的3D层次化全景分割方法，并提供了一个专门为这一任务设计的数据集。该方法不仅在不同传感器的苹果园环境中表现出色，还提供了完整的层次化全景分割。数据集和开源实现均已公开发布。
## 443. `cs.CV` - DWIM: 通过差异感知工作流生成与指令掩码调优迈向工具感知的视觉推理 [PDF](https://arxiv.org/pdf/2503.19263), [HTML](https://arxiv.org/abs/2503.19263)
### Authors
Fucai Ke,Vijay Kumar B G,Xingjian Leng,Zhixi Cai,Zaid Khan,Weiqing Wang,Pari Delir Haghighi,Hamid Rezatofighi,Manmohan Chandraker
### Background
视觉推理（VR）在许多领域对于实现类似人类的视觉理解至关重要，但仍然是一个高度具有挑战性的任务。最近，依赖于集成工具的大规模语言模型（LLMs）的组合视觉推理方法显示出比端到端VR方法更有效的潜力。然而，这些方法存在局限性，因为冻结的LLMs在VR中缺乏工具感知能力，从而导致性能瓶颈。尽管在其他领域广泛使用LLM进行推理，但在VR中直接应用LLM却受到限制，比如有限的训练数据、工具引入的错误降低数据采集效率，以及在具有噪声的工作流程上微调困难等问题。
### Innovation
本文提出了一种新的方法DWIM，它包括两个关键技术：1）差异感知训练工作流生成，评估工具使用并从中提取更具可行的工作流进行训练；2）指令掩码微调，指导模型仅克隆有效的动作，从而生成更加实际的解决方案。实验结果显示，DWIM在各种VR任务上达到了最先进的性能，且在多个广泛使用的数据集上表现出强大的泛化能力。
### Conclusion
本文提出的DWIM方法通过差异感知工作流生成和指令掩码微调，增强了视觉推理中的工具感知能力，提高了VR模型的性能和泛化能力。
## 444. `cs.CV` - 高效点云分析的生物启发式点Mamba突触神经网络 [PDF](https://arxiv.org/pdf/2504.14371), [HTML](https://arxiv.org/abs/2504.14371)
### Authors
Peixi Wu,Bosong Chai,Menghua Zheng,Wei Li,Zhangchi Hu,Jie Chen,Zheyu Zhang,Hebei Li,Xiaoyan Sun
### Background
现有的生物启发式突触神经网络（SNNs）以高效的方式提取3D时空特征，但长期以来，3D SNNs在处理长距离依赖性方面存在困难，直到Mamba的出现，它在计算效率和序列建模能力方面表现出色。鉴于直接将Mamba移植到3D SNNs中的性能不佳，本文提出Spiking Point Mamba (SPM)，这是第一个基于Mamba的3D SNN。为了弥补Mamba直接移植到3D SNNs中的不足，SPM利用了Mamba的序列建模能力和SNNs的时序特征提取能力，通过引入层次动态编码（HDE）和改进直接编码方法来有效引入动态时序机制，促进时序交互，并提出了Spiking Mamba块（SMB）来学习跨时间步特征，同时最小化基于尖峰的信息损失。为了进一步增强模型性能，采用不对称SNN-ANN架构进行基于尖峰的预训练和微调
### Innovation
提出了生物启发式点Mamba (SPM) 3D SNN，通过引入层次动态编码（HDE）改进直接编码方法，促进时序交互，同时提出了Spiking Mamba块（SMB）来学习跨时间步特征，最小化基于尖峰的信息损失。更进一步，采用了不对称SNN-ANN架构进行尖峰预训练和微调
### Conclusion
与之前的SNN模型相比，SPM在ScanObjectNN的三个变体上分别提高了OA 6.2%、6.1%和7.4%，在ShapeNetPart上的实例mIOU提高了1.9%。同时，其能效至少比其ANN对等物低3.5倍。代码将公开提供
## 445. `cs.CV` - StateSpaceDiffuser: 引入长上下文到扩散世界模型 [PDF](https://arxiv.org/pdf/2505.22246), [HTML](https://arxiv.org/abs/2505.22246)
### Authors
Nedko Savov,Naser Kazemi,Deheng Zhang,Danda Pani Paudel,Xi Wang,Luc Van Gool
### Background
世界模型近年来已成为一种有前景的工具，能够根据在复杂环境中采取的动作预测现实的视觉效果。然而，这些模型仅依赖少数最近的观察结果，导致它们难以跟踪长期背景。这使得在几步之内，生成的场景就会偏离之前的观察，从而使序列的时间连贯性受到损害。
### Innovation
StateSpaceDiffuser 设计通过将特征集成到状态空间模型中，使扩散模型能够执行长期上下文任务，这种方式解决了现有扩散模型因为缺乏长期环境状态而导致的问题。这种设计恢复了长期记忆，同时保持了扩散模型的高保真合成能力。我们还开发了一种评估协议，以严格衡量时间一致性，该协议测试模型在扩展演示中的重现已见过内容的能力。实验结果表明，StateSpaceDiffuser 显著优于仅基于扩散的基线模型，并能保持连续的视觉背景长达一个数量级的更多步骤。
### Conclusion
全面的实验表明，StateSpaceDiffuser 在两个 2D 迷宫导航和复杂 3D 环境中都能提供一致的视角，证明将状态空间表示引入扩散模型能够有效展示视觉细节和长期记忆。
## 446. `cs.CV` - TaxaDiffusion：逐步训练的扩散模型用于细粒度物种生成 [PDF](https://arxiv.org/pdf/2506.01923), [HTML](https://arxiv.org/abs/2506.01923)
### Authors
Amin Karimi Monsefi,Mridul Khurana,Rajiv Ramnath,Anuj Karpatne,Wei-Lun Chao,Cheng Zhang
### Background
现有的扩散模型在生成动物图像时未能充分利用物种之间的形态和身份差异。大多数标准方法将每个物种视为独立类别，忽视了视觉相似性在不同物种间的常见形态特征。TaxaDiffusion通过引入分类学知识，能够更好地理解和生成细粒度的动物图像，特别是在使用有限的训练样本的情况下，也能达到高形态和身份准确度。
### Innovation
TaxaDiffusion是一个基于分类学信息的训练框架，用于训练扩散模型以生成高精度的细粒度动物图像。其创新点在于采用分级训练策略，从更宽泛的分类级别（如纲和目）开始训练，逐步精细化到属和种级别。这种方法首先捕捉共享共同祖先物种的粗粒度形态特征，然后再细化到物种级别的细微差别，从而使得在有限训练样本的情况下仍能生成准确的结果。
### Conclusion
通过在三个细粒度动物数据集上的广泛实验，TaxaDiffusion表现出优于现有方法的效果，实现了更高质量的细粒度动物图像生成。
## 447. `cs.CV` - SA-Person: 基于场景感知重排的文字人体检索 [PDF](https://arxiv.org/pdf/2505.24466), [HTML](https://arxiv.org/abs/2505.24466)
### Authors
Yingjia Xu,Jinlin Wu,Zhen Chen,Daming Gao,Yang Yang,Zhen Lei,Min Cao
### Background
基于文本的人体检索旨在根据自然语言描述从图像库中识别出目标个体。由于现实场景的复杂性和外观描述的模糊性，这成为一个显著挑战。现有方法主要关注基于外观的跨模态检索，往往忽略了场景中嵌入的上下文信息，而这些信息可以为检索提供有价值的补充见解。因此，本文构建了包含10多万场景并有多样标注的SCENEPERSON-13W数据集。在此基础上，本文提出了一个两级检索框架SA-Person，第一阶段通过将文本线索与行人特有的区域对齐执行具有区分性的外观解析，第二阶段引入了SceneRanker，这是一种无需训练的、利用多模态大型语言模型进行行人外观和整体场景背景联合推理的场景感知重排方法。
### Innovation
本文提出了一种名为SA-Person的两级检索框架，该框架包括两个阶段：第一阶段执行具有区分性的外观解析，将文本线索与行人特有的区域对齐；第二阶段引入了SceneRanker，这是一种无需训练的、场景感知的重排方法，充分利用了多模态大型语言模型进行行人外观与全局场景背景的联合推理。通过SCENEPERSON-13W数据集上的实验验证了框架的有效性。
### Conclusion
实验结果证实了框架在复杂场景级别的检索任务中的有效性。代码和数据集将在未来公开提供。
## 448. `cs.CV` - T2I模型及其对从事不同活动人士的代表 [PDF](https://arxiv.org/pdf/2504.06313), [HTML](https://arxiv.org/abs/2504.06313)
### Authors
Abdulkareem Alsudais
### Background
该论文研究了流行的文字到图像（T2I）模型在生成特定国籍人士典型活动图像时的代表方式。通过两种情景生成了644张图像，并观察到某些情况下，图像中的人物穿着传统服饰的比例显著，特别是在中东和北非及撒哈拉以南非洲地区。研究表明，传统服饰的代表模式与地区之间存在显著的统计相关性，同时，还发现传统服饰代表与收入群体之间有显著的联系，这些发现揭示了T2I模型在代表不同国家人士方面的价值，并强调了该模型在现实生活中应用的局限性，尤其是在实际活动中穿传统服饰的不现实性方面。
### Innovation
本研究通过分析生成的644张图像和不同的输入提示，发现了T2I模型在代表不同国籍人士方面的特定模式，特别是在传统服装的使用上。研究中使用了CLIP、ALIGN和GPT-4.1 mini来测量生成图像与大量提示和说明之间的对齐分数，并观察到在其中一个情景中，描绘传统服饰的图像得分显著更高。此外，研究还发现模型在一定程度上自动添加了“传统”一词作为提示的一部分，这揭示了模型在生成图像时对传统特征的偏好，即使这些特征与所描述的活动不切实际。这些研究方法和发现为未来的研究提供了一种新的视角和技术工具，有助于改进T2I模型的准确性和实用性。
### Conclusion
研究结果表明，T2I模型在生成特定国家人士典型活动图像时存在明显偏向，特别是在穿传统服饰方面。这些偏差与地理和收入因素有关，模型倾向于描绘传统特征，尽管这在实际活动中并不常见。进一步改进和调整T2I模型以更准确地反映现实生活中的多元化和包容性，将有助于提高模型的用户体验和实用性。
## 449. `cs.CV` - RobustSplat: 分离密度增强和动态性以实现无瞬态3DGS [PDF](https://arxiv.org/pdf/2506.02751), [HTML](https://arxiv.org/abs/2506.02751)
### Authors
Chuanyu Fu,Yuqi Zhang,Kunbin Yao,Guanying Chen,Yuan Xiong,Chuan Huang,Shuguang Cui,Xiaochun Cao
### Background
3D Gaussian Splatting (3DGS) 方法因其在新视角合成和3D建模中的实时、照片级真实感渲染而受到广泛关注。然而，现有的方法在处理受到瞬态物体影响的场景时，难以准确建模，导致渲染图像中出现伪影。
### Innovation
该研究识别了由于高斯密度增加过程中生成多余高斯分布来建模瞬态干扰，无意间加剧了这些伪影的问题。为此，提出了RobustSplat，这是一种抗干扰解决方案，包含两个关键设计：首先，提出延迟高斯增长策略，先优化静态场景结构再允许高斯分裂/克隆，减少早期优化时对瞬态对象的过度拟合；其次，设计了尺度递进掩码强化方法，利用低分辨率特征相似监督进行可靠的瞬态掩码初步估计，利用其更强的语义一致性和对噪声的鲁棒性，然后进行高分辨率监督以实现更精确的掩码预测。
### Conclusion
多项具有挑战性的数据集上的广泛实验表明，我们的方法优于现有方法，清楚地展示了我们方法的鲁棒性和有效性。
## 450. `cs.CV` - 自行其是：从伪标签中学习语义对应关系 [PDF](https://arxiv.org/pdf/2506.05312), [HTML](https://arxiv.org/abs/2506.05312)
### Authors
Olaf Dünkel,Thomas Wimmer,Christian Theobalt,Christian Rupprecht,Adam Kortylewski
### Background
在计算机视觉中，寻找跨图像和对象实例的具有语义相似性的点之间的对应关系一直是一个持久性的挑战。尽管最近的大规模预训练 vision 模型已被证明在语义匹配方面非常有效，但对于对称对象或重复的对象部分，它们仍然存在模糊性问题。
### Innovation
本文提出了一种基于 3D 意识伪标签改进语义对应估计的方法。具体而言，通过提供 3D 意识链式伪标签、通过放松循环一致性过滤错误标签以及 3D 球形原型映射约束来训练一个适配器，以改进预置功能。与以往工作相比，本方法减少了对数据集特定注解的需求，并在 SPair-71k 上取得了超过 4% 的绝对性能提升，在具有相似监督要求的方法中提升了超过 7%，证明了本方法的通用性，使其适用于其他数据源的扩展训练，这一点在实验中得到了验证。
### Conclusion
通过 3D 意识伪标签训练的适配器改进了预置功能上的语义对应估计，该方法在 SPair-71k 数据集上取得了新纪录，提升了 4% 的绝对性能，超过了需要相似监督要求的方法，验证了方法的通用性和简单性，证明其在其他数据源上的扩展潜力。
## 451. `cs.CV` - 图像恢复变换器的训练动力学分析：层规范化再审视 [PDF](https://arxiv.org/pdf/2504.06629), [HTML](https://arxiv.org/abs/2504.06629)
### Authors
MinKyu Lee,Sangeek Hyun,Woojin Jun,Hyunjun Kim,Jiwoo Chung,Jae-Pil Heo
### Background
该工作研究了图像恢复（IR）变换器的内部培训动态，揭示了一个关键但被忽视的问题：传统的层归一化导致特征幅度发散，规模高达百万级别，同时破坏了通道间熵。从网络试图克服传统层归一化产生的约束这一角度考虑了这一现象，该约束与IR任务的要求相冲突。具体而言，常规层归一化以单个令牌为单位进行归一化，扰乱了IR任务中必要的空间相关性，同时也固定了输入无关的归一化，限制了特征尺度的灵活性，而这正是需要保存输入特定统计量所需要的。这些不匹配严重阻碍了IR变换器在整个网络中准确保存低级特征的能力。
### Innovation
引入了一种专门为IR任务定制的层规范化方法，被称为图像恢复变换器定制层规范化（i-LN）。它是一种简单直接的替代方案，通过在整个空间通道维度上整体归一化特征，保持了单个令牌之间的空间关系。此外，提出了一种输入自适应的重新缩放策略，以保持每个输入所需的特征范围灵活性。这些修改有效贡献了在整个图像恢复变换器中保持输入低级特征统计量。实验结果验证了该综合策略在各种图像恢复任务中增强了IR变换器的稳定性和性能。
### Conclusion
通过解决层规范化与IR任务之间的不匹配问题，实现了训练动态的稳定化和IR性能的提高。定制的层规范化（i-LN）方法通过保持特征统计量和增强空间相关性，显著改善了图像恢复变换器的表现。
## 452. `cs.CV` - EgoM2P：基于自注意力的自视角多模态多任务预训练 [PDF](https://arxiv.org/pdf/2506.07886), [HTML](https://arxiv.org/abs/2506.07886)
### Authors
Gen Li,Yutong Chen,Yiqian Wu,Kaifeng Zhao,Marc Pollefeys,Siyu Tang
### Background
自视角（egocentric）视角下的多模态信号理解（如RGB视频、深度图、相机姿态和目光）对于增强现实、机器人技术和人机交互等应用至关重要。这对于系统更好地理解和解释自视角摄像机佩戴者的行为、意图和周围环境极为重要。然而，构建大规模的自视角多模态和多任务模型面临独特挑战，例如自视角数据本就异质性极强，不同设备和设置间模态覆盖差异大。生成缺失模态（如目光或头部摄像机轨迹）的伪标签通常不可行，使得传统监督式学习难以规模化。此外，动态的摄像机运动以及第一人称视频复杂的时间和空间结构为直接应用现有跨模态基础模型带来了额外挑战。
### Innovation
本文引入了一组高效的时空标记方法，并提出了一种EGoM2P模型，这是一个遮蔽建模框架，它可以基于时空感知多模态标记训练一个大而通用的模型以进行自视角4D理解。该模型统一了跨多样化自视角感知和合成任务的支持，包括目光预测、自视角相机跟踪和来自自视角视频的一线深度估计，并且还作为一个自条件自视角视频合成的生成模型。在这些任务上，EGoM2P在性能上与专有模型不相上下且速度快了约一个数量级。
### Conclusion
我们将完全开源EGoM2P以支持社区并推动自视角视觉研究。
## 453. `cs.CV` - JointDiT：用扩散变压器增强RGB-Depth联合建模 [PDF](https://arxiv.org/pdf/2505.00482), [HTML](https://arxiv.org/abs/2505.00482)
### Authors
Kwon Byung-Ki,Qi Dai,Lee Hyoseok,Chong Luo,Tae-Hyun Oh
### Background
当前研究主要依赖于最先进的扩散变压器的架构优势和出色的图像先验能力，以生成高保真度的图像。然而，如何通过建模RGB和深度的联合分布来生成几何上合理的深度图，是该领域的研究重点。
### Innovation
JointDiT通过引入自适应调度权重和不平衡时间步长采样策略两种简单有效的方法，实现了RGB和深度的联合分布建模。这种建模方式不仅可以生成高保真的图像，而且能够生成几何上合理的深度图，并且能够在各种组合生成任务中自然地处理多项任务，如联合生成、深度估计和条件生成。
### Conclusion
JointDiT在联合生成任务中表现出色，并且在深度估计和条件生成任务上取得了可比的结果，表明联合分布建模可以作为条件生成的一种可替代方案。
## 454. `cs.CV` - 基于上下文感知的接地教师在网络无源对象检测中的应用 [PDF](https://arxiv.org/pdf/2504.15404), [HTML](https://arxiv.org/abs/2504.15404)
### Authors
Tajamul Ashraf,Rajes Manna,Partha Sarathi Purkayastha,Tavaheed Tariq,Janibul Bashir
### Background
该研究聚焦于网络无源对象检测（SFOD）问题。当目标域数据无标记且无法访问源数据时，模型必须适应目标域。在医学成像领域，已经有利用半监督学生教师架构的方法来弥合领域差异，但标注数据中的上下文不平衡和领域间的显著变化会导致教师模型产生偏差的伪标签，从而降低学生模型的性能并导致模式崩溃。特别严重的类别不平衡会导致领域上下文偏差。为了解决上下文偏差和SFOD设置中学生模型性能急剧下降的问题，该研究引入了Grounded Teacher (GT)作为标准框架，通过专门的关系上下文模块建模上下文关系，以减轻模型中的固有偏差。增强代表不足类别的性能，同时最小化对优势类别的影响，并进一步通过专家基础分支监督学生模型以提高预测质量。实验使用三种医学数据集验证了该方法在SFOD设置中减轻上下文偏差的有效性，包括详细的消融研究支持。
### Innovation
该研究引入了一种新的标准框架——Grounded Teacher (GT)，通过专门的关系上下文模块来定向应对上下文偏差，结合专家基础分支监督学生模型，旨在增强代表不足类别的性能，同时只对优势类别产生轻微影响。该框架经过三个医学数据集的支持，通过全面的消融研究验证了其在缓解上下文偏差方面的能力。
### Conclusion
该研究通过引入Grounded Teacher (GT)框架，成功地缓解了上下文偏差，在网络无源对象检测（SFOD）设置中验证了其有效性，并通过预处理的数据、训练的模型权重和代码的公开支持了该方法的可行性和实用性。
## 455. `cs.CV` - 结构保持的块解码以实现高效的神经视频表示 [PDF](https://arxiv.org/pdf/2506.12896), [HTML](https://arxiv.org/abs/2506.12896)
### Authors
Taiga Hayami,Kakeru Koizumi,Hiroshi Watanabe
### Background
隐式神经表示（INRs）被广泛研究，特别是在通过将空间和时间坐标映射到相应值来建模复杂信号方面。在处理视频时，将紧凑输入映射到整个帧或空间分割的片段图像是一种有效的方法。这种方法可以更好地保持空间关系，减少计算开销，并提高重建质量，相比于基于坐标的映射方式。然而，预测整个帧通常会限制对高频视觉细节的重建。此外，传统基于均匀空间分割的片段方法倾向于引入边界突变，导致空间连贯性受损。
### Innovation
我们提出了一种基于结构保持片段（SPPs）的神经视频表示方法，通过一种确定性的基于像素的分割操作（类似于PixelUnshuffle）将每个视频帧分割成空间对齐的片段图像。此操作保留了全局空间结构，同时允许片段级别的解码。我们训练解码器以重建这些结构化的片段，从而使全局到局部的解码策略成为可能，首先捕捉全局布局，然后再细化局部细节。这有效减少了边界伪影，并减轻了原始上采样的失真。
### Conclusion
在标准视频数据集上的实验表明，我们的方法在重建质量和压缩性能方面都优于现有的基于INR的基线方法。
## 456. `cs.CV` - OneIG-Bench：全方位精炼评估框架用于图像生成 [PDF](https://arxiv.org/pdf/2506.07977), [HTML](https://arxiv.org/abs/2506.07977)
### Authors
Jingjing Chang,Yixiao Fang,Peng Xing,Shuhan Wu,Wei Cheng,Rui Wang,Xianfang Zeng,Gang Yu,Hai-Bao Chen
### Background
文本到图像（T2I）模型因其生成与文本提示高度匹配的高质量图像而受到了广泛关注。然而，快速发展的T2I模型在早期基准测试中暴露出了局限性，这些基准测试不全面，缺乏对推理、文本渲染和风格等领域的评估。近年来，一些先进的T2I模型因其丰富的知识建模能力，在需要强力推理能力的图像生成问题上显示出了令人鼓舞的结果。但现有的评价系统并没有充分解决这些问题。
### Innovation
为了系统地填补这些空白，本文提出了一种名为OneIG-Bench的全面基准框架，用于图像生成模型的各个维度，包括提示-图像对齐、文本渲染精度、推理生成内容、风格化和多样性等方面的细致评估。通过该基准框架，可以灵活地进行模型性能的深入分析，从而帮助研究者和从业人员识别出图像生成全流程中的优点和瓶颈。具体来说，OneIG-Bench提供了一个灵活的评估方式，用户可以根据需要选择某个具体维度进行评估，而无需为所有提示生成图像，而是仅针对选定维度的相关提示生成图像并完成相应的评估即可。我们的代码和数据集现在已公开，以促进T2I研究社区内的可重现评估研究和模型间比较的研究合作。
### Conclusion
OneIG-Bench提供了一个结构化的评估框架，使得研究人员和从业者能够系统地评估T2I模型在提示-图像对齐、文本渲染精度、推理生成内容、风格化和多样性等方面的性能。通过这一框架，研究者和从业者可以更深入地分析模型性能，识别图像生成全流程中的优点和瓶颈。此外，研究者可以灵活地选择特定维度进行评估，而无需对所有提示生成图像，从而提高了研究效率。
## 457. `cs.CV` - PCA与奇异值分解(SVD)作为降维技术的比较分析 [PDF](https://arxiv.org/pdf/2506.16663), [HTML](https://arxiv.org/abs/2506.16663)
### Authors
Michael Gyimadu,Gregory Bell,Ph.D
### Background
高维图像数据通常需要在进一步分析之前进行降维处理。本文通过从基本原则出发推导两种线性技术——主成分分析（PCA）和奇异值分解（SVD）的方法，对比分析了这两种技术在解释性、数值稳定性以及适用于不同矩阵形状方面的情况。
### Innovation
通过对PCA和SVD从第一原理进行推导，并从经典和最新的数值文献中总结出选择这两种算法中的一个的经验性指南，绕过了实际基准测试。
### Conclusion
指出了研究的局限性和未来实验工作的方向。
## 458. `cs.CV` - DeSPITE: 探索对比深骨架-点云-IMU-文本嵌入以实现高级点云人体活动理解 [PDF](https://arxiv.org/pdf/2506.13897), [HTML](https://arxiv.org/abs/2506.13897)
### Authors
Thomas Kreutz,Max Mühlhäuser,Alejandro Sanchez Guinea
### Background
尽管LiDAR技术作为一种有效的隐私保护替代RGB摄像头感知人体活动的技术，但在多模态对比预训练领域（例如人体动作识别（HAR）、检索或重识别（RE-ID））中的应用尚未得到充分探索。本研究旨在探索将LiDAR点云、人体骨架姿态、IMU数据和文本在联合嵌入空间中的对应性学习。通过结合LIPD和Babel数据集，以同步四模态数据，进一步推动联合嵌入空间的学习。实验结果显示，DeSPITE能够支持通过骨架-点云-IMU匹配、检索和时间点检索的新型人体活动理解任务。同时，实验表明DeSPITE能有效用于点云HAR的预训练策略。
### Innovation
我们提出了DeSPITE模型，这是一个深骨架-点云-IMU-文本嵌入模型，它能够实现跨这四种模态的有效联合嵌入空间学习。通过使用LIPD和Babel数据集的组合，能够同步四种模态的数据，从而可以探索新的联合嵌入空间的学习。此外，DeSPITE模型通过多模态对比学习，展示了多种新型的人体活动理解任务，并证实其在点云HAR预训练中的有效性。
### Conclusion
我们的研究结果表明，DeSPITE模型可以在多模态数据的联合嵌入空间中有效地学习人体活动理解的新任务，并且在点云人体活动识别中能够提供有效的预训练策略。
## 459. `cs.CV` - 以假乱真：奖励建模作为辨别预测 [PDF](https://arxiv.org/pdf/2506.13846), [HTML](https://arxiv.org/abs/2506.13846)
### Authors
Runtao Liu,Jiahao Zhan,Yingqing He,Chen Wei,Alan Yuille,Qifeng Chen
### Background
有效的奖励模型在视觉生成模型的后训练增强中起到了关键作用，但在当前的奖励模型方法中，由于依赖于大量的人工标注偏好数据或精心设计的质量维度，导致实现复杂性增加，这些质量维度往往是不完整的且工程化成本高。
### Innovation
本文提出了GAN-RM，一种高效的奖励建模框架，该框架摒弃了人工偏好标注和显式的质量维度工程。通过将奖励模型训练为对一小部分具有代表性的、未配对的目标样本（称为偏好代理数据）与模型生成的一般输出进行区分，仅需少量目标样本（几百个）即可完成训练。该方法在多个关键应用场景中表现出有效性，包括后训练方法如监督微调（SFT）和直接偏好优化（DPO），以及测试时放大实现等技术。
### Conclusion
全面的实验结果证明，GAN-RM在多个关键应用中均体现出有效性。该方法通过仅使用少量标签数据来训练奖励模型，大大简化了奖励建模过程。论文中的代码和数据将在指定链接提供。
## 460. `cs.CV` - HyperPath：知识引导的双曲语义层次建模在WSI分析中的应用 [PDF](https://arxiv.org/pdf/2506.16398), [HTML](https://arxiv.org/abs/2506.16398)
### Authors
Peixiang Huang,Yanyan Huang,Weiqin Zhao,Junjun He,Lequan Yu
### Background
在癌症诊断中，病理学至关重要。目前，多实例学习（MIL）广泛应用于全切片图像（WSI）分析。WSIs具有层次结构，包括切片、区域和小块，这些具有独特的语义关系。尽管一些方法试图利用这种层次结构来改进表示，但它们主要依赖于欧几里得嵌入，这使得它们难以完全捕捉语义层次。
### Innovation
本文提出了一种名为HyperPath的新型方法，该方法结合了文本描述的知识，以在双曲空间中指导对WSIs的语义层次建模，从而增强WSI分类。该方法采用了路径学原理，将视觉和文本特征整合到双曲空间中，并设计了一种角度模态对齐损失来确保跨模态对齐的鲁棒性，通过演绎和矛盾关系来进一步校正特征层次，从而增强语义连贯性。分类通过测地距离进行，测地距离衡量实体在双曲语义层次中的相似性，从而避免了线性分类器的使用，实现了几何感知的方法来分析WSIs。实验结果表明，该方法在所有任务中都优于现有方法，突显了双曲嵌入在WSI分析中的潜力。
### Conclusion
本文提出的HyperPath方法通过结合视觉和文本特征以及利用双曲空间的特性，显著提高了WSI的分类性能，克服了传统方法难以捕捉语义层次结构的局限，展示了双曲嵌入在WSI分析中的优越性。
## 461. `cs.CV` - MiCo: 基于上下文感知聚类的多重实例学习在全视野影像分析中的应用 [PDF](https://arxiv.org/pdf/2506.18028), [HTML](https://arxiv.org/abs/2506.18028)
### Authors
Junjian Li,Hulin Kuang,Jin Liu,Hailin Yue,Mengshen He,Jianxin Wang
### Background
多实例学习（MIL）在肿瘤组织学全视野图片（WSI）的癌症诊断和预后分析中展现出了显著的潜力。然而，WSI中固有的空间异质性带来了重大挑战，因为形态相似的组织类型在不同的解剖区域分散存在。传统MIL方法难以建模这些分散的组织分布，有效捕捉跨区域的空间交互。
### Innovation
提出了一种新颖的基于上下文感知聚类的多重实例学习框架MiCo，旨在增强跨区域内的组织内部相关性和加强跨组织语义关联。MiCo通过聚类实例提取区分性形态模式，并使用聚类中心作为语义锚点。为了增强跨区域内的组织内部相关性，MiCo引入了聚类路线模块，动态连接远距离区域中相同组织类型的实例。语义锚点作为上下文枢纽，传播语义关系以精炼实例级表示。为了消除语义碎片化并加强跨组织语义关联，MiCo整合了聚类减少模块，该模块合并冗余锚点，增强不同语义组之间的信息交流。在两个具有挑战性的任务上，使用了九个大规模公共癌症数据集进行的广泛实验表明了MiCo的有效性，并展示其在状态最先进技术上的优越性。
### Conclusion
MiCo在两个复杂任务上的实验结果证明了其在广泛公共癌症数据集上的有效性，并展示了其相对于最先进技术的优势。代码可在 https://this-is-a-example-url.com 处获取。
## 462. `cs.CV` - 参考表达式实例检索和一个强大的端到端基线 [PDF](https://arxiv.org/pdf/2506.18246), [HTML](https://arxiv.org/abs/2506.18246)
### Authors
Xiangzhao Hao,Kuan Zhu,Hongyu Guo,Haiyun Guo,Ning Jiang,Quan Lu,Ming Tang,Jinqiao Wang
### Background
在实际应用中，用户需要通过自然语言查询出视觉信息。传统的图片描述检索（TIR）和基于实例描述的理解（REC）任务分别在图像级别的描述检索和图像内实例级别的定位上有所局限，尤其是在处理大规模视觉库和细粒度描述时。因此，论文提出了一个新的任务，即参考表达式实例检索（REIR），结合了实例级别的检索和定位，基于细粒度的参考表达式。为了解决这个问题，论文构建了一个大规模的REIR基准数据集REIRCOCO，并提出了一个双流架构的端到端基线方法CLARE，以解决参考表达式实例检索任务。
### Innovation
论文创新地提出了参考表达式实例检索（REIR）这一任务，旨在同时实现细粒度的描述检索和实例级别的定位。同时，提出了一个大规模的基准数据集REIRCOCO，并提供了一个基于对比的语义-实例对齐与关系专家的端到端基线方法CLARE。该方法在对象检测和理解表达式理解数据集上进行了预训练，然后通过对比的语义-实例对齐进一步优化，提高了跨图像检索的性能。
### Conclusion
本文提出了参考表达式实例检索（REIR）这一任务及其实现方法。通过双流架构的CLARE，该方法能够有效处理细粒度的描述并进行实例级定位。此外，还提供了一个大规模的基准数据集REIRCOCO和开源代码，为该领域的研究提供了重要的资源。
## 463. `cs.CV` - 生成森林再育树——气候数据层级扩散模型 [PDF](https://arxiv.org/pdf/2506.19391), [HTML](https://arxiv.org/abs/2506.19391)
### Authors
Declan J. Curran,Sanaa Hobeichi,Hira Saleem,Hao Xue,Flora D. Salim
### Background
高分辨率气候数据对地方规划至关重要，但传统降尺度方法计算量大。近年来，人工智能降尺度模型取得了显著成果，尤其是扩散模型，因其生成集合的能力和解决平滑问题的能力而受到关注。然而，这些模型通常计算成本仍然很高。
### Innovation
提出了一种层次扩散降尺度(HDD)模型，通过简单地采用下采样方案，引入一个易于扩展的层次采样过程到扩散框架中。HDD在ERA5重新分析数据集和CMIP6模型上实现了竞争力的准确度，通过在多达一半的像素上运行而显著降低了计算负荷。单个在0.25°分辨率训练的模型可以无缝地应用到多个CMIP6模型中，进一步减少计算成本。
### Conclusion
HDD为概率气候降尺度提供了轻量级的替代方案，促进了经济实惠的大规模高分辨率气候预测。
## 464. `cs.CV` - 2D Triangle Splatting for Direct Differentiable Mesh Training [PDF](https://arxiv.org/pdf/2506.18575), [HTML](https://arxiv.org/abs/2506.18575)
### Authors
Kaifeng Sheng,Zheng Zhou,Yingliang Peng,Qianwei Wang
### Background
不同的3D高斯原语用于多视角图像重建3D场景的方法已经展现出了强大的性能。尽管这种方法相比NeRF（Neural Radiance Field）方法具有优势，但在渲染速度和高级渲染效果（如间接光照和阴影渲染）上仍然难以与基于网格的模型相匹敌。现有的研究大多依赖于3D Gaussian原语来进行连贯的体积建模，但这种方式在复杂结构的精准重建上存在挑战。
### Innovation
本文提出了一种新颖的方法——2D Triangle Splatting（2DTS），将3D Gaussian原语替换为2D三角形面片。2DTS 保留了连续体积建模的优势同时形成了离散的网格结构。通过引入一个紧凑参数来控制三角形原语，可以直接进行逼真网格的训练。实验结果表明，在不调优紧凑参数的情况下，我们的基于三角形的方法相较于最先进的基于高斯的方法具有更高的重建精度，并且重建的网格具有更出色的视觉质量。
### Conclusion
我们的研究结果表明，2DTS方法可以实现更高的重建精度和更优的视觉质量。这一方法在直接可微网格训练中具有独特的优势，为3D场景的快速自动重构提供了新的可能。
## 465. `cs.CV` - 通过跨模态注意力蒸馏实现对齐的新视角图像和几何合成 [PDF](https://arxiv.org/pdf/2506.11924), [HTML](https://arxiv.org/abs/2506.11924)
### Authors
Min-Seop Kwak,Junho Kim,Sangdoo Yun,Dongyoon Han,Taekyoung Kim,Seungryong Kim,Jin-Hwa Kim
### Background
现有的方法通常需要密集的姿态图像或嵌入姿态的生成模型，这些模型通常局限于输入域内的视角。此研究提出了一种基于扩散的方法，该方法通过一种变形和填充的方法实现对齐的新视角图像和几何体生成。这种方法避免了对密集姿态图像的需求，能够在参考图像上预测部分几何体，并将新视角合成表述为图像和几何体的填充任务。通过这种方式，可以提高生成图像和几何体之间的精确对齐。
### Innovation
该研究提出了跨模态注意力蒸馏，这是一种新的方法，通过将图像扩散分支的注意力图注入到并行的几何扩散分支中，在训练和推断阶段都保证生成的图像和几何体之间的准确对齐。此外，还引入了基于邻近性的网格条件，通过结合深度和法线提示，以这种方式可以更有效地生成几何统计数据，减少错误预测的几何体对生成过程的影响。这种方法获得了良好的效果，能够在不同场景下实现高保真度的新视角图像和几何体合成，并在插值情况下提供了具有竞争力的重建质量，同时产生了几何对齐的彩色点云，实现全面的三维完成.
### Conclusion
研究证明了该方法在新视角数据生成上的有效性和准确性，不仅在图像方面，而且在几何体方面也能实现高质量的合成。这种方法提供了一种新的视角，可以广泛应用于计算机图形学、虚拟现实和3D建模等场景中，提高了现有方法的性能和可靠性。
## 466. `cs.CV` - 基于语义场景图的超声图像解释与扫描指导 [PDF](https://arxiv.org/pdf/2506.19683), [HTML](https://arxiv.org/abs/2506.19683)
### Authors
Xuesong Li,Dianye Huang,Yameng Zhang,Nassir Navab,Zhongliang Jiang
### Background
理解医学超声成像仍然是一项长期的挑战，因为成像和采集参数的巨大视觉变化导致了显著的视觉差异。最近，大规模语言模型（LLMs）被用于自动生成面向临床医生的丰富术语摘要，具有足够的生理知识。然而，非专家用户，例如在临床护理现场，对于提高超声成像解释性和基本扫描指导的需求尚未得到满足。为此，本研究介绍了一种超声图像的场景图（SG），用于解释图像内容并为普通用户提供扫描指导。该图像解释和扫描指导方法已针对来自5名志愿者的颈部左侧和右侧包括颈动脉和甲状腺的超声图像进行验证，结果表明该方法有潜力最大限度地使超声成像民主化，提高其解释性和易用性，以便于普通用户。
### Innovation
首次引入了超声场景图来解释图像内容并为普通用户提供扫描指导，该场景图由基于Transformer的一阶段方法自动生成，无需进行显式对象检测，通过LLMs进一步根据用户查询对抽象的SG表示进行细化，该方法还探索了预测的SG在指导扫描时寻找当前成像视野中的缺失解剖结构的潜力，帮助普通用户实现更标准化和完整的人体结构探索。
### Conclusion
该基于场景图的图像解释方法和扫描指导已通过来自不同志愿者的多种超声图像验证，结果表明该方法具有使超声成像解释性和易用性民主化的潜力，适用于普通用户。
## 467. `cs.CV` - 使用神经场和光学流动增强动态CT图像重建 [PDF](https://arxiv.org/pdf/2406.01299), [HTML](https://arxiv.org/abs/2406.01299)
### Authors
Pablo Arratia,Matthias Ehrhardt,Lisa Kreusser
### Background
在动态CT成像中，目标的运动相对于测量采集率导致了在时间上高度解析但在空间上高度欠采样的测量。这种问题带来了重大挑战：如果不考虑过程动态性，会导致重建质量不佳且运动不真实。传统的变分方法通过惩罚时间演化来关联后续帧以提高图像质量，基于网格的离散化。神经场作为一种新的方法，在参数化感兴趣量方面具有优势，具有轻量级、连续性且更倾向于光滑表示。此特性在解决动态逆问题时得到了利用，通过仅最小化数据保真项来求解。
### Innovation
我们研究并展示了在基于偏微分方程的动力学逆问题优化中引入显式运动正则化器（特别是光学流动方程）的好处，与未正则化的版本相比，改进了重建质量。我们还将神经场与基于网格的求解器进行了比较，显示前者在本任务中在峰值信噪比（PSNR）上表现更优。
### Conclusion
我们的研究为动态逆问题提供了新的优化方法，通过引入基于偏微分方程的运动正则化器，提高了神经场的重建质量，并展示了其优于传统基于网格的方法。
## 468. `cs.CV` - PuriDefense: 随机局部隐式对抗净化以防御黑盒查询型攻击 [PDF](https://arxiv.org/pdf/2401.10586), [HTML](https://arxiv.org/abs/2401.10586)
### Authors
Ping Guo,Xiang Li,Zhiyuan Yang,Xi Lin,Qingchuan Zhao,Qingfu Zhang
### Background
黑盒查询型攻击是机器学习即服务（MLaaS）系统的重大威胁，因为它们能够在不访问目标模型架构和参数的情况下生成对抗样本。传统的防御机制，如对抗训练、梯度掩蔽和输入变换，要么带来巨大的计算成本，要么降低非对抗输入的测试准确性。
### Innovation
提出了一种高效的防御机制PuriDefense，它在推理成本较低的情况下使用随机局部碎片净化和轻量级净化模型的集成。这种方法通过在净化过程引入随机性，减缓基于查询的攻击的收敛速度。
### Conclusion
在CIFAR-10和ImageNet上的广泛实验验证了我们提出的基于净化器的防御机制的有效性，在对抗基于查询的攻击方面表现出显著的改进。
## 469. `cs.CV` - HUG: 基于块状重建的分层城市高斯点云表示 [PDF](https://arxiv.org/pdf/2504.16606), [HTML](https://arxiv.org/abs/2504.16606)
### Authors
Mai Su,Zhongtao Wang,Huishan Au,Yilong Li,Xizhe Cao,Chengwei Pan,Yisong Chen,Guoping Wang
### Background
3DGS 是一个新兴且日益流行的新型视图合成技术。它具有高度逼真的渲染质量和实时渲染能力，适用于多种应用。然而，在应用于大规模航空城市场景时，3DGS 方法会遇到内存消耗过多、训练时间过长、分割过程耗时以及由于数据量增加导致渲染质量严重下降等问题。
### Innovation
我们提出了一种名为 HUG 的新方法，通过利用分层神经高斯表示来增强数据分割和重建质量。首先，我们提出了一种基于可见性的高效数据分割方法，显著优于现有方法。然后，我们引入了一种分层加权训练方法，与其他优化策略结合使用，显著提高重建质量。
### Conclusion
我们的方法在一组合成数据集和四个实时数据集上实现了最佳结果。
## 470. `cs.CV` - CREStE: 使用互联网规模先验和反事实指导的大规模地图无关导航 [PDF](https://arxiv.org/pdf/2503.03921), [HTML](https://arxiv.org/abs/2503.03921)
### Authors
Arthur Zhang,Harshit Sikchi,Amy Zhang,Joydeep Biswas
### Background
本研究针对户外城市导航中开放世界泛化和鲁棒性的挑战，旨在开发一个新的可扩展的学习基础地图无关导航框架。传统的地图引导导航方法在面对未见过的环境时会显得不够鲁棒，尤其是在城市、非道路和住宅环境中。该研究目标在于学习能够泛化到开放域因素（例如新型语义类别、地形、动态实体）的感知表示，并从有限的演示中推断出专家对齐的导航代价。
### Innovation
CREStE 引入了两个创新点：1）通过视觉基础模型（VFM）蒸馏目标来学习开放域结构化鸟瞰图感知表示；2）反事实逆强化学习（IRL），一种新颖的主动学习形式，利用反事实轨迹演示来推理推断导航代价时最重要提示。
### Conclusion
在多个城市的千米级地图无关导航任务评估中，CREStE 显示出了更强的性能，相较于所有最先进的方法减少了70%的人工干预，甚至在未见过的环境中完成2千米任务只需1次干预，这一结果证明了它在长时地图无关导航中的鲁棒性和有效性。更多视频和其他资料可以在项目页面找到：this https URL
## 471. `cs.CV` - GASP: 效率高的黑箱生成对抗后缀以劫持大型语言模型 [PDF](https://arxiv.org/pdf/2411.14133), [HTML](https://arxiv.org/abs/2411.14133)
### Authors
Advik Raj Basani,Xiao Zhang
### Background
大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但在输入提示下仍容易遭受称为‘监狱突破’攻击的安全漏洞，这类攻击特意设计以绕过安全防护并引发不良回应。传统方法依赖于手动启发式方法，但这类方法在通用性上存在限制。尽管基于优化的自动攻击方法能够在攻击效果上提供帮助，但它们通常生成的人工痕迹攻击提示很容易被安全过滤器检测到，或者因为离散标记优化需要高昂的计算成本。因此，需要一种更高效的自动化框架来生成自然的、令人信服的劫持攻击提示。
### Innovation
本文提出了一个名为GASP（生成对抗后缀提示器）的新型自动化框架，能够在完全黑箱环境下高效生成具有人类可读性的劫持攻击后缀。GASP利用潜在贝叶斯优化框架，通过深入了解连续潜在嵌入空间，快速生成后缀攻击提示，再通过目标迭代优化和逐步调整指令连贯性，提高攻击效率。GASP可以通过全面的实验对比示范其生成自然洪水攻击提示的优势，与基线相比，GASP具有更强大的攻击成功率，更快的训练时间和更快速的推理速度，从而使其成为一个高效且可扩展的红队攻击LLMs的解决方案。
### Conclusion
GASP能够在完全黑箱的环境下，高效生成人类可理解的劫持攻击后缀，显著提高攻击成功率，减少训练时间和加快推理速度，成为红队攻击LLMs的一种高效且可扩展的解决方案。
## 472. `cs.CV` - Score-based 生成模型的约束泛化 [PDF](https://arxiv.org/pdf/2412.07229), [HTML](https://arxiv.org/abs/2412.07229)
### Authors
Wan Jiang,He Wang,Xin Zhang,Dan Guo,Zhaoxin Fan,Yunfeng Diao,Richang Hong
### Background
Score-based生成模型（SGMs）已经展现出了出色的一般化能力，比如能够生成未见过但自然的数据。然而，这种强大的一般化能力也可能导致未预期的一般化，并且存在潜在的滥用风险。目前对SGMs中受限一般化的研究尚且不多。因此，该研究先探讨了机器遗忘（MU）的当前‘金标准’，即移除不良训练数据后再重新训练模型，发现这种方法在SGMs中并不适用。进一步分析得分函数表明，当前‘金标准’的MU方法并没有改变原始得分函数，这也是其无效的原因。因此，该研究在此基础上提出了首个约束得分生成模型（MSGM），通过引入一种新的得分调整策略，在连续时间随机微分方程过程中将得分函数引导远离不良数据。大量的实验结果证明，MSGM能够在显著降低生成不良内容的可能性的同时保持高质量的正常图像生成。尽管MSGM是为SGMs设计的，但它是一种通用且灵活的MU框架，可以与多种扩散架构（SGM和DDPM）和训练策略（重新训练和微调）兼容，并且能够让预训练模型在下游任务中实现零样本转移，例如图像修补和重建。
### Innovation
该研究在SGMs中提出了首个约束得分生成模型（MSGM），引入了一种新的得分调整策略，通过在连续时间随机微分方程过程中将得分函数引导远离不良数据。这一框架既适用于多种扩散架构，又兼容不同的训练策略，并且能够实现零样本迁移。
### Conclusion
MSGM能够在显著降低生成不良内容的可能性的同时保持高质量的正常图像生成。该模型不仅适用于SGMs，还能与其他多种架构和训练策略结合使用，为下游任务提供通用和灵活的框架。
## 473. `cs.CV` - Metis-RISE: RL激励和SFT增强多模态推理模型学习 [PDF](https://arxiv.org/pdf/2506.13056), [HTML](https://arxiv.org/abs/2506.13056)
### Authors
Haibo Qiu,Xiaohan Lan,Fanfan Liu,Xiaohu Sun,Delian Ruan,Peng Shi,Lin Ma
### Background
近年来，大型语言模型（LLMs）的研究进展推动了高级推理范式的快速发展，并被引入到多模态大型语言模型（MLLMs）中。然而，现有的方法存在不足：完全依赖强化学习（RL）的局限性在于样本效率低，不易激发模型中完全缺失的推理能力；而传统的基于冷启动监督微调（SFT）阶段后跟RL的方法则限制了模型的探索能力，并可能会导致次优的收敛。
### Innovation
Metis-RISE通过引入RL激励和SFT增强的方式，解决了传统方法中的问题。相比传统的做法，Metis-RISE省去了初始的SFT阶段，而是从RL阶段开始，激励和激活模型潜在的推理能力。此外，用自我提炼的推理轨迹来解决RL中低效的轨迹采样问题，通过注入专家增强的知识来解决模型完全失败的情况。
### Conclusion
Metis-RISE形成了多版本的MLLMs（7B和72B参数），在开宙Compass多模态推理排行榜上，两种模型都达到了同类模型中的最佳性能，其中72B版本的整体排名第四。相关信息请参阅我们的项目页面，了解更多开源信息。
## 474. `cs.CV` - 始终跳过注意力 [PDF](https://arxiv.org/pdf/2505.01996), [HTML](https://arxiv.org/abs/2505.01996)
### Authors
Yiping Ji,Hemanth Saratchandran,Peyman Moghadam,Simon Lucey
### Background
本文探讨了现代视觉转换器（ViTs）中一个有趣的实证结果，即自注意力机制只有在与跳跃连接结合使用时才能有效训练。与其他部分不同，即使移除跳跃连接，ViTs 中的其他结构仍能保持较好的性能（尽管是次优的）。此外，作者指出，这种对跳跃连接的依赖是相对新的现象，以前的深层架构（例如卷积神经网络）可以在没有跳跃连接的情况下表现出色。
### Innovation
作者理论地证明了自注意力机制本质上是病态条件的，并因此唯一依赖跳跃连接进行正则化。此外，作者提出了一种简单的 Token Graying 方法，作为跳跃连接的补充，进一步改善输入标记的条件。通过有监督和无监督训练方法验证了此方法的有效性。
### Conclusion
研究表明，视觉转换器中的自注意力机制在训练过程中需要跳跃连接来实现有效训练，且自注意力机制的病态条件性质是导致这一现象的原因。Token Graying 方法可以作为跳跃连接的补充，进一步改善模型的条件。
## 475. `cs.CV` - 通过基础模型组合实现面向地球观测数据挖掘的可扩展性和通用性 [PDF](https://arxiv.org/pdf/2506.20174), [HTML](https://arxiv.org/abs/2506.20174)
### Authors
Man Duc Chuc
### Background
地球观测数据挖掘正迅速通过基础模型发生转变，这些模型能够为场景分类和语义分割等关键任务提供可扩展的通用解决方案。然而，地理空间领域的大多数努力集中在使用大规模地球观测数据集从头开始训练大型模型上。一种尚未充分利用的替代策略是重用和组合已有的预训练模型。因此，本研究考察了在遥感和通用视觉数据集上预训练模型的有效组合，以改善多样地球观测任务的表现。通过使用GEO-Bench基准，我们评估了几种著名模型的有效性，包括Prithvi、Hiera和DOFA，在涵盖不同空间分辨率、传感器模态和任务类型的11个数据集上进行评估。结果表明，在特征级组合小型预训练模型的表现可以与或超越大模型，同时所需训练时间和计算资源更少。此外，研究还强调了知识蒸馏的应用潜力，能够将组合模型的优势转移到更紧凑的模型中，为在实际地球观测应用中部署基础模型提供了实际途径。
### Innovation
研究提出了通过综合已经在遥感和通用视觉数据集上预训练的小型模型来改进地球观测任务绩效的方法。这种方法不仅提高了模型的性能，还在计算资源和训练时间方面表现优越。此外，研究还探索了知识蒸馏技术在基础模型组合中的应用，以实现更小但更高效的模型，这为实际地球观测应用中基础模型的部署提供了一条可行路径。
### Conclusion
研究表明，特征级组合小型预训练模型能够匹配或超越大面积模型，且需要更少的训练时间和计算资源。知识蒸馏可以将组合模型的优势转移到更紧凑的模型中，为实际应用中的基础模型部署提供了一种新的方法。
## 476. `cs.CV` - BlenderFusion: 3D-Grounded Visual Editing and Generative Compositing [PDF](https://arxiv.org/pdf/2506.17450), [HTML](https://arxiv.org/abs/2506.17450)
### Authors
Jiacheng Chen,Ramin Mehran,Xuhui Jia,Saining Xie,Sanghyun Woo
### Background
提出了BlenderFusion，这是一种生成式视图合成框架，能够通过重组对象、相机和背景来合成新的场景。该框架采用了一种分层编辑合成流程：首先分割并转换视觉输入，使之成为可编辑的3D实体（分层），然后在Blender中使用基于3D的控制进行编辑（编辑），最后使用生成式合成器将它们合成进一个连贯的场景中（合成）。研究人员扩展了一个预训练的扩散模型，使其能够同时处理原始（源）和编辑（目标）场景，采用两种关键的训练策略：（i）源掩蔽，支持背景替换等灵活修改；（ii）模拟物体抖动，有助于物体和相机的独立控制。与先前的方法相比，BlenderFusion在复杂的组成场景编辑任务中表现出显著的优势。
### Innovation
BlenderFusion通过提出一种生成式视图合成框架，实现了高效的3D视觉编辑和合成。其创新之处在于引入了一种全新的分层编辑合成流程，尤其是在改进了预训练的扩散模型以同时处理原始和编辑的场景方面。同时，BlenderFusion还提出了两种关键的训练策略来增强其功能：（i）源掩蔽，（ii）模拟物体抖动。这些技术创新使得BlenderFusion在复杂的场景编辑任务中表现优异，超越了之前的同类方法。
### Conclusion
BlenderFusion显著改进了复杂场景编辑任务的表现，特别是在能够灵活地对背景进行修改和独立地控制物体和相机方面。这项工作展示了神经网络在视觉合成任务中的强大能力，以及其在实时、互动的应用中的巨大潜力。
## 477. `cs.CV` - TCDiff++: 一个用于和谐音乐驱动群舞编排的端到端轨迹可控扩散模型 [PDF](https://arxiv.org/pdf/2506.18671), [HTML](https://arxiv.org/abs/2506.18671)
### Authors
Yuqin Dai,Wanlu Zhu,Ronghui Li,Xiu Li,Zhenyu Zhang,Jun Li,Jian Yang
### Background
音乐驱动的舞蹈生成因其在工业应用中的广泛应用，尤其是群舞创作，引起了显著的关注。然而，在群舞生成过程中，大多数现有方法仍面临三大问题：多舞者碰撞、单舞者脚部滑动和生成长段群舞时的突然位置切换。这些问题严重影响了舞蹈的和谐性和连贯性，制约了现有的舞蹈生成技术的发展。
### Innovation
提出了一种名为TCDiff++的端到端音乐驱动框架，旨在生成和谐的群舞。具体解决了三个问题：1) 通过使用舞者定位嵌入来维持舞者之间的相对定位，减少多舞者碰撞；2) 引入距离一致损失确保舞者之间的距离保持在合理范围内，解决单舞者脚部滑动问题；3) 采用长时间群舞扩散采样策略，通过在噪声输入中注入位置信息，减少位置突变，提高长段群舞生成质量；4) 集成序列解码层增强模型处理长序列序列的能力。
### Conclusion
广泛实验表明，TCDiff++在生成质量和连贯性方面达到了最先进的性能，尤其在长时间群舞场景中表现尤为突出，能够确保高质量和连贯的群舞生成。
## 478. `cs.CV` - SoK: 合成图像能否替代真实数据？合成图像生成的效用与隐私综述 [PDF](https://arxiv.org/pdf/2506.19360), [HTML](https://arxiv.org/abs/2506.19360)
### Authors
Yunsung Chung,Yunbei Zhang,Nassir Marrouche,Jihun Hamm
### Background
生成模型的进展已经改变了隐私保护数据合成（PPDS）中的合成图像生成领域。然而，该领域缺乏对不同场景下合成图像生成方法进行全面的调查和比较。本文特别关注利用合成图像训练分类器时，生成-抽样-分类的流程。在此流程中，研究如何评估潜在的隐私攻击以及现有的缓解措施的效果，为PPDS提供了解决方案和指导建议。
### Innovation
本文系统地对现有的图像合成方法、隐私攻击以及缓解措施进行了分类，提供了基准测试以对比不同的合成方法，并使用模型无偏的成员推理攻击（MIAs）作为衡量隐私风险的标准。通过实证对比研究，探索合成数据能否有效替代真实数据、不同的发布策略如何平衡效用与隐私，以及缓解措施如何改善效用-隐私权衡等关键问题，并提供了关于不同场景下的生成模型表现的分析，为合成数据生成方法的效用-隐私权衡提供行动指南，指导现实应用场景中的数据发布策略选择。
### Conclusion
通过系统性地评价不同的方法，本文提供了关于合成数据生成方法的效用-隐私权衡的行动指南，并为确定最优数据发布策略提供了指导。
## 479. `cs.CV` - 基于RGB感知的共识驱动不确定性机器人抓取 [PDF](https://arxiv.org/pdf/2506.20045), [HTML](https://arxiv.org/abs/2506.20045)
### Authors
Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai
### Background
深度对象姿态估计经常过于自信。一个既估计目标物体6-自由度姿态又预测自身估计不确定性的抓取代理，可以在高不确定性时选择不采取行动以避免任务失败。尽管在抓取任务中物体姿态估计已经提升且不确定性量化研究也在不断进步，但很少有研究将这两种方法与机器人抓取的下游任务联系起来。本文研究的目的是训练轻量级深度网络，在抓取尝试之前根据图像估计的物体姿态预测抓取成功与否。通过将实际图像中的物体姿态估计与模拟抓取相结合生成训练数据，并指出尽管抓取试验中存在高物体变异，但多样的物体联合训练有益于网络学习，表明多样化的物体可以为同一目标贡献信息。
### Innovation
本文提出了一个方法，通过训练轻量级的深度网络，在进行抓取之前根据图像中的姿态估计预测抓取的成功与否。此外，本文还指出网络可以从所有物体的联合训练中受益，即使在抓取试验中存在高物体变异。这种共识驱动的不确定性评估方法对机器人抓取任务具有一定的创新性。
### Conclusion
本文提出的方法能够在机器人执行抓取任务之前预测基于图像估计的物体姿态的抓取成功率，减少了由于估计过于自信而导致的任务失败。尽管物体存在高度变异，但通过联合训练所有物体，网络能够提高其不确定性估计能力。
## 480. `cs.CV` - DSA-NRP: 根据血管造影灌注动力学预测中风内血管取栓术中的无再流现象 [PDF](https://arxiv.org/pdf/2506.17501), [HTML](https://arxiv.org/abs/2506.17501)
### Authors
Shreeram Athreya,Carlos Olivares,Ameera Ismail,Kambiz Nael,William Speier,Corey Arnold
### Background
在成功进行血管内血栓切除术（EVT）治疗急性缺血性中风（AIS）后，一些患者会出现并发症‘无再流’现象，表现为持续的微血管低灌注，这些现象阻碍了组织的恢复并恶化了临床结果。目前标准的临床实践中，通常在术后24小时内通过灌注磁共振成像（MRI）来识别这一并发症，但这种方法会有所延迟，不利于早期干预。本研究的背景是寻找一种更早、更准确的方法来预测‘无再流’现象，以便在 EVT 之后立即进行干预。
### Innovation
本研究首次提出了一个机器学习框架，该框架可以在 EVT 之后立即根据术中数字减影血管造影（DSA）影像和临床变量预测‘无再流’现象。从这些DSA影像的前、后视图中提取了统计和时间灌注特征，并训练了机器学习分类器，该方法在预测‘无再流’现象方面显著优于基于临床特征的基线方法，显示出血管造影灌注动态对于微血管完整性的关键洞察。这种新方法为即时、准确预测无再流现象奠定了基础，使得临床医生能够早期管理高风险患者，无需依赖延迟的影像检查。
### Conclusion
该方法能够提供即时的无再流预测，帮助临床医生在 EVT 之后立即识别高危患者，从而可以进行更积极的管理而无需等待延迟的影像学检查。这为实时管理和提高急性中风治疗效果提供了新的可能性。
## 481. `cs.CV` - Chain-of-Sketch: 使全局视觉推理成为可能 [PDF](https://arxiv.org/pdf/2410.08165), [HTML](https://arxiv.org/abs/2410.08165)
### Authors
Aryo Lotfi,Enrico Fini,Samy Bengio,Moin Nabi,Emmanuel Abbe
### Background
现代视觉模型在依赖局部特征的情况下已经在基准测试中取得了显著的成功。然而，对于需要更多全局推理的任务，局部特征不提供显著的信息。Minsky和Papert在1969年的研究中提出了此类任务，揭示了感知器模型的局限性。本文介绍了涉及图形、字符串、迷宫和图像网格的扩展全局视觉数据集，展示了大型视觉模型在学习这些任务时依然表现不佳。同时，最先进的多模态LLM在这类数据集上的表现也很差。我们通过‘全局度’度量来解释这种学习效率低下，并提出了名为chain-of-sketch (CoS)的方法来解决这一问题。类似语言模型中的chain-of-thought和scratchpad技术，CoS方法将原始任务分解为中间视觉步骤以帮助学习复杂任务。另外，我们还发现并不是所有的CoS策略都一样有效，我们通过在CoS帧上施加马尔可夫结构提出了‘诱导性CoS’方法，该方法在离群样本外泛化方面表现更好，并且即使使用较小的模型也能很好地工作。
### Innovation
我们引入了一种名为chain-of-sketch (CoS)的方法，类似于语言模型中的chain-of-thought和scratchpad技术，将原始任务分解为中间视觉步骤以帮助学习复杂任务。我们还通过在CoS帧上施加马尔可夫结构提出了‘诱导性CoS’方法，这种方法在离群样本外泛化方面表现更好，并且即使使用较小的模型也能很好地工作。
### Conclusion
通过引入chain-of-sketch (CoS)方法和诱导性CoS方法，我们有效地解决了大型视觉模型和最先进的多模态LLM在处理复杂全局推理任务时表现不佳的问题，证明了通过分解任务可以改善模型的学习效率和泛化能力。
## 482. `cs.LG` - 关于上下文-内容不确定性原理 [PDF](https://arxiv.org/pdf/2506.20699), [HTML](https://arxiv.org/abs/2506.20699)
### Authors
Xin Li
### Background
本文提出了上下文-内容不确定性原理（CCUP），认为在不确定性推理中的信息处理遵循上下文和内容之间的熵不对称性：高熵的上下文必须通过与低熵、结构化的内容对齐来进行解释。文章进一步发展了一层计算框架，该框架来源于这种根本性不对称性。研究构建了一个分层的操作原则框架，提出了从基础层面到更高级层面的四个层级，包括核心推理约束、资源分配原则、时间引导机制和空间层次组成，以实现不确定性推理的高效性。这项研究为理解大脑和机器如何通过递归的结构特定性对齐来减少不确定性提供了一个统一的理论基础。
### Innovation
提出了一种新的理论框架，即上下文-内容不确定性原理（CCUP），并进一步发展了分层的操作原则框架，从基础层面到高级层面的四个层级分别对应核心推理约束、资源分配原则、时间引导机制和空间层次组成。该框架通过解释不确定性推理中的信息处理过程，为理解大脑和机器如何减少不确定性提供了新的视角和方法。此外，还提供了形式等价定理、原则之间的依赖关系图以及计算模拟，验证了CCUP框架下的推理效率提升。
### Conclusion
本文为理解和实现递归结构特定性对齐提供了一个统一的理论基础，帮助我们更好地理解大脑和机器如何通过信息推理减少不确定性。研究表明，大脑不仅是一种推理机器，它还是一个路径依赖性的、内容引导的仿真实验的熵梯度解决器，通过结构和具体性的对齐来减少不确定性。
## 483. `cs.LG` - 渐progressive size-适应性联邦学习：面向异构多模态数据系统的综合框架 [PDF](https://arxiv.org/pdf/2506.20685), [HTML](https://arxiv.org/abs/2506.20685)
### Authors
Sajid Hussain,Muhammad Sohail,Nauman Ali Khan,Naima Iltaf,Ihtesham ul Islam
### Background
联邦学习（FL）作为一种保持数据隐私的同时进行分布式机器学习的变革性范式已逐渐显现。然而，现有的方法主要关注模型异构性和聚合技术，很大程度上忽视了数据集大小特性对联邦学习动态的基石性影响。
### Innovation
本文介绍了基于数据集大小特性的渐进自适应联邦学习（SAFL）框架，这是一种新型的渐进式训练框架，系统性地基于异构多模态数据的数据集大小特性组织联邦学习。SAFL框架的创新点包括：提出了针对数据集大小特性的自适应联邦学习方法，揭示了不同类型数据在联邦学习中的性能差异和数据集大小对联邦学习性能的影响，展示了在大规模数据集上的性能递减趋势。实验结果显示，SAFL框架在所有数据集上实现了87.68%的平均准确率，对结构化数据模态的准确率达到了99%以上。同时，SAFL显著提高了通信效率，总数据传输量减少到7.38 GB。在558次通信中仍保持了高水平的性能。
### Conclusion
本文的工作填补了理解应如何驱动联邦学习策略以适应数据特性的空白，既提供了理论见解又为神经网络和学习系统的实际联邦学习部署提供了实用指导。
## 484. `cs.LG` - 关于卷积、固有维数和扩散模型 [PDF](https://arxiv.org/pdf/2506.20705), [HTML](https://arxiv.org/abs/2506.20705)
### Authors
Kin Kwan Leung,Rasa Hosseinzadeh,Gabriel Loaiza-Ganem
### Background
高维空间中的数据，如图像数据，被认为存在于未知的低维子流形上。扩散模型（DMs）通过逐步增加高斯噪声并学习逆转这一过程，已经被证明是最有效的生成模型，并且能够学习低维支持的概率分布。Kamkari等人（2024b）提出了FLIPD方法，该方法通过将局部对数边缘密度关于添加噪声量的变化率与子流形的固有维数关联，成功地将固有维数（LID）作为数据对应局部固有维度的指标。现有的LID估计器，例如FLIPD，具有多种用途，可以量化数据的复杂性，检测异常值、对抗示例和AI生成的文本。然而，FLIPD的理论基础尚不完备，仅在非常不现实的仿射子流形假设下得到证明其正确性。
### Innovation
本文通过正式证明在现实假设下FLIPD方法的正确性来填补了这一理论空白，并表明当用均匀卷积替代高斯卷积时，类似的结论仍然成立。此外，还讨论了这一结果的相关性。这项工作进一步完善了对LFIPD方法的理解，并扩展了其适用范围。
### Conclusion
本文通过正式证明，FLIPD在现实条件下仍能正确估计固有维数。并且在高斯卷积被替换为均匀卷积的情况下，也得到了一致的结果。这一研究对于理解扩散模型中的固有维数估计具有重要意义，并为实际应用提供了理论基础。
## 485. `cs.LG` - E-ABIN: 用于生物网络异常检测的可解释模块 [PDF](https://arxiv.org/pdf/2506.20693), [HTML](https://arxiv.org/abs/2506.20693)
### Authors
Ugo Lomoio,Tommaso Mazza,Pierangelo Veltri,Pietro Hiram Guzzi
### Background
近年来，大规模组学数据的可用性不断增加，需要能够处理复杂基因表达数据集的同时提供可解释结果的稳健分析框架。人工智能的最新进展使得能够识别出将疾病状态与健康对照区分开来的异常分子模式。随着模型可解释性的改善，这些工具现在支持识别可能驱动疾病表型的基因。然而，目前的基因异常检测方法通常局限于单一数据集，并且缺乏易于访问的图形界面。因此，本文旨在介绍E-ABIN，一种用于生物网络中异常检测的一般用途、可解释框架。E-ABIN将经典机器学习和图基深入学习技术结合在一个用户友好的平台上，用于从基因表达或甲基化衍生的网络中检测和解释异常。
### Innovation
E-ABIN框架通过结合支持向量机、随机森林、图自编码器（GAEs）以及图对抗属性网络（GAANs），确保了高预测精度的同时保持了可解释性。该框架支持跨多数据集的基因异常检测，并提供了一个直观的图形界面来解释结果，从而提高了研究人员对疾病机制的理解。该文通过膀胱癌和克罗恩病的案例研究展示了E-ABIN的有效性，有效揭示了生物相关的异常，并提供了对疾病机制的见解。
### Conclusion
E-ABIN是一种通用的、可解释的框架，用于在生物网络中进行异常检测。通过结合多种先进的机器学习和图基学习技术，E-ABIN在保持高预测准确性的同时，为基因表达或甲基化数据集中的异常提供了清晰的解释，能够识别和解释由基因活动变异导致的疾病表型，从而帮助研究人员更好地理解疾病的机制。
## 486. `cs.LG` - 理论物理中的测试时扩展技术——TPBench数据集上方法的比较 [PDF](https://arxiv.org/pdf/2506.20729), [HTML](https://arxiv.org/abs/2506.20729)
### Authors
Zhiqi Gao,Tianyi Li,Yurii Kvasiuk,Sai Chaitanya Tadepalli,Maja Rudolph,Daniel J.H. Chung,Frederic Sala,Moritz Münchmeyer
### Background
大型语言模型（LLMs）已经在复杂推理方面展示了很强的能力，测试时扩展技术可以以较低的成本提升其性能。这些方法大多数已经在诸如AIME等数学推理基准测试上进行开发和评估。本文研究这些从数学推理基准中学到的经验教训是否同样适用于高级理论物理学领域。通过在TPBench物理数据集上评估一系列常见的测试时扩展方法，并将其结果与AIME进行对比，研究如何更好地利用物理学问题的结构来改善并行扩展结果。实验结果显示这种方法在TPBench上的表现明显优于现有测试时扩展方法。同时，我们在AIME上评估了该方法，进一步验证了其在解决高级数学问题的有效性。研究结果强调了分步符号验证在处理复杂科学问题方面的强大能力。
### Innovation
开发了一种新的符号弱验证框架，以提升TPBench数据集上并行扩展结果的性能。这种方法在TPBench上的表现明显优于现有测试时扩展方法，并且在AIME上也证实了其在解决高级数学问题的有效性。
### Conclusion
我们的实证结果表明，这种方法在TPBench上显著优于现有的测试时扩展方法。同时，该方法在AIME上的评估也确认了其在解决高级数学问题方面的有效性。分步符号验证显示出解决复杂科学问题的强大能力。
## 487. `cs.LG` - 非局部闭合建模的隐分位数生成模型方法 [PDF](https://arxiv.org/pdf/2506.20771), [HTML](https://arxiv.org/abs/2506.20771)
### Authors
Xinghao Dong,Huchen Yang,Jin-Long Wu
### Background
本研究解决了复杂多尺度动态系统建模的挑战，尤其是在没有明显多尺度分离的区域，完全数值解决所有尺度是成本高昂的，例如工程中的湍流流动。经典的闭合建模方法依赖于领域知识来近似亚网格尺度的现象，但在缺乏明显尺度分离的情况下，它们的确定性和局部假设可能过于限制。最近基于扩散的随机模型的进展在闭合建模方面显示出潜力，但由于其高昂的计算推断成本，限制了其实用应用。本文通过在隐空间中联合训练卷积自编码器和条件扩散模型解决了这一问题，显著减少了采样过程的维度，同时保留了重要的物理特性。数值结果表明，联合训练方法有助于发现一个适当的隐空间，不仅可以保证重建误差较小，还可以在隐空间中确保扩散模型的良好性能。通过将所提出的随机建模框架集成到数值模拟中，基于隐条件扩散模型的方法实现了显著的计算加速，同时与物理空间的标准扩散模型相比保持了相当的预测准确性。
### Innovation
本文提出了一种隐分位数生成模型方法，结合卷积自编码器和条件扩散模型，用于学习非线性动力系统计算力学中的非局部闭合模型和本构定律。这种方法在保留重要物理特性的同时，显著减少了采样过程的维度，从而实现了计算加速。
### Conclusion
通过在隐空间中联合训练卷积自编码器和条件扩散模型，本文提出的方法不仅保证了重建误差较小，还确保了在隐空间中扩散模型的良好性能。该框架在数值模拟中的应用展示了显著的计算加速效果，同时保持了与物理空间模型相当的预测准确性。
## 488. `cs.LG` - 微缩格式训练不稳定性特征与缓解 [PDF](https://arxiv.org/pdf/2506.20752), [HTML](https://arxiv.org/abs/2506.20752)
### Authors
Huangyuan Su,Mujin Kwun,Stephanie Gil,Sham Kakade,Nikhil Anand
### Background
训练大型语言模型是一个计算密集型、成本高昂的过程，随着模型的扩展、算法的进步和新数据的收集，这一过程需要重复进行。鉴于此，下一代硬件加速器越来越多地支持更低精度的算术格式，如NVIDIA黑尔维治架构中引入的微缩（MX）格式。使用块共享标度可以扩展数值范围，通过在较低精度下执行GEMM操作来提高效率。本文探讨了在模型训练过程中使用块缩放精度格式的挑战及其可行性。研究覆盖了一千多个从头开始训练的语言模型，涉及从$2 times 10^{17}$到$4.8 times 10^{19}$浮点运算次数的不同计算预算，以及各种权重-激活精度组合。研究表明，在MX格式下训练时，损失会出现剧烈、随机的不稳定现象，特别是在较大的计算规模下。
### Innovation
本文通过在较小的代理模型中进行受控实验和消融实验，揭示了一种简单的模型，表明量化层规范线性参数和少量激活带来的乘性梯度偏置可以引发失控发散。并且通过中训练期间对精度方案的干预实验，证明了不稳定性可以被避免或延后。此外，本文通过特定的混合配置评估了稳定性策略在大语言模型环境中的效果，显示某些混合配置的性能可以与全精度训练竞争。所有相关代码已发布于指定网址。
### Conclusion
本文通过探索块缩放精度格式在训练中的挑战和可行性，发现了乘性梯度偏置引发失控发散的现象，并通过实验验证了干预策略的有效性。特定的混合精度配置展示了与全精度训练相当的性能，为大语言模型的高效训练提供了新的解决方案。
## 489. `cs.LG` - 变体的关系提取路径：丰富和回召在Transformer中的实现 [PDF](https://arxiv.org/pdf/2506.20746), [HTML](https://arxiv.org/abs/2506.20746)
### Authors
Todd Nief,David Reber,Sean Richardson,Ari Holtzman
### Background
当大模型在微调过程中学习到某些关系（如新电影上映、公司合并等），这些信息会存储在模型的何处？是直接提取的，还是在预测时即时回忆，还是存在多种分离的启发式方法？现有的定位方法（如激活切片）不适合这种分析，因为它们会替换残差流的部分，可能会删除这些信息。为了弥补这一缺口，本文提出了一种微调和预训练语言模型之间的动态权重嫁接方法，以展示微调语言模型同时在处理实体时提取微调过程中学习到的关系信息，以及在生成预测时回忆这些信息的过程。在某些情况下，模型需要这两种途径来正确生成微调信息，而在其他情况下，单一的“丰富”或“回忆”途径就足够了。我们探讨了这些信息路径的必要性和充分性，检查了它们发生的位置，冗余程度以及涉及到的模型组件，发现在最终层的注意力和前馈网络输出中，通过特定任务的注意力机制以及关系提取步骤实现了“回忆”路径。
### Innovation
提出了一种动态权重嫁接的方法，将微调和预训练语言模型之间的动态权重嫁接相结合，以研究微调语言模型在处理实体时提取关系信息以及生成预测时回忆这些信息的过程。这种方法揭示了微调模型在不同情况下需要多种途径来正确生成微调信息，以及这些信息路径如何通过特定任务的注意力机制和关系提取步骤在模型的最终层实现‘回召’功能。
### Conclusion
研究结果表明，微调语言模型同时使用提取和回忆信息的多个路径可以正确生成微调信息；在某些情况下，两种路径都是必要的，而在其他情况下，单个路径就足够了。此外，分析发现了这些信息路径的具体机制和涉及的模型组件细节。
## 490. `cs.LG` - AI for Materials Science: 基础模型、大语言模型代理、数据集和工具的概览 [PDF](https://arxiv.org/pdf/2506.20743), [HTML](https://arxiv.org/abs/2506.20743)
### Authors
Minh-Hao Van,Prateek Verma,Chen Zhao,Xintao Wu
### Background
基础模型（FMs）正在推动材料科学（MatSci）进行一场范式转变。它们能够提供可扩展、通用且多模态的AI系统，支持科学研究。与传统机器学习模型相比，FMs能够跨领域泛化，并展现出新兴能力，特别适合材料科学，因为该领域的研究挑战涵盖了多样化的数据类型和规模。本文综述了基础模型、自主系统、数据集和计算工具，并提供了一幅全面的概览图。文章还讨论了单模态和多模态基础模型的最新进展，以及正在兴起的大语言模型（LLM）代理，同时评审了标准数据集、开源工具和自主实验平台，促进了FMs在研究工作流程中的开发和集成。最后，评估了基础模型的早期成功，并指出了包括泛化能力、可解释性、数据不平衡、安全问题和缺乏多模态融合在内的持续限制，并提出了未来研究方向，包括可扩展的预训练、持续学习、数据治理和可靠性。
### Innovation
综述引入了基于任务分类的六种广泛应用领域：数据提取、解释与问答；原子级模拟；性能预测；材料结构、设计与发现；工艺规划、发现与优化；多尺度建模。重点在于单模态和多模态基础模型的最新进展，以及新兴的大语言模型（LLM）代理。同时，评审了标准化数据集、开源工具和自主实验平台，促进了FMs在研究工作流程中的开发和集成。此外，还评估了基础模型的早期成功，并指出了一些持续的限制，如泛化能力、可解释性、数据不平衡、安全问题和有限的多模态融合。提出了未来的研究方向，包括可扩展的预训练、持续学习、数据治理和可靠性，以推动这些技术的进步。
### Conclusion
本文提供了一种任务驱动的分类方法，涵盖了材料科学中基础模型的应用领域，探讨了单模态和多模态基础模型的最新发展，评审了标准数据集、开源工具和自主实验平台，促进了FMs在材料科学中的应用研究。然而，限制依然存在，如泛化能力、可解释性、数据不平衡、安全性和有限的多模态融合等问题。未来研究应集中在可扩展的预训练、持续学习、数据治理和系统的可靠性上。
## 491. `cs.LG` - 通过网络层非均匀影响实现对抗数据的通用高效检测 [PDF](https://arxiv.org/pdf/2506.20816), [HTML](https://arxiv.org/abs/2506.20816)
### Authors
Furkan Mumcu,Yasin Yilmaz
### Background
深度神经网络（DNNs）对带有小噪声预算的对抗输入设计特别脆弱。尽管已经提出了许多成功的攻击技术，通过细微修改原始输入，但针对这些攻击的技术研究相对较少。现有的防御方法主要集中在提高DNN的健壮性或使用辅助模型来检测对抗性数据。而检测方法相较于健壮性方法更为实用，但现有检测方法要么对最先进的攻击技术无效，要么在实时处理中计算效率低下。
### Innovation
本文提出了一种新颖的通用且高效的对抗样本检测方法，通过分析不同DNN层受到攻击的影响程度来检测对抗样本。该方法训练一个轻量级回归模型，从早期层特征预测深层层特征，并使用预测误差来检测对抗样本。实验结果表明，该方法在计算效率、实时处理能力、适应不同DNN架构以及跨不同领域应用方面表现优异。
### Conclusion
我们的检测方法对于最先进的攻击技术非常有效，实时处理计算效率高，适用于任何DNN架构，并在图像、视频和音频领域等不同领域具有广泛应用潜力。
## 492. `cs.LG` - Stochastic Parameter Decomposition [PDF](https://arxiv.org/pdf/2506.20790), [HTML](https://arxiv.org/abs/2506.20790)
### Authors
Lucius Bushnaq,Dan Braun,Lee Sharkey
### Background
神经网络逆向工程的一个关键步骤是将其分解为更简单可独立研究的部分。线性参数分解是一种框架，解决了当前分解方法的一些问题，将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，当前主要方法，基于归因的参数分解（APD），由于计算成本高且对超参数敏感而难以实用。为了改善这一状况，研究人员在此工作引入了一种更可扩展且对超参数更鲁棒的方法——随机参数分解（SPD），通过将模型大小和复杂度扩展到APD无法处理的水平来验证其优势。此外，SPD还避免了参数收缩等问题，并在玩具模型中更好地识别了真实机制。
### Innovation
研究人员提出了随机参数分解（SPD）方法，该方法相比于基于归因的参数分解（APD）更加可扩展且对超参数更鲁棒。SPD通过整合因果中介分析与网络分解方法，解决了线性参数分解方法放大到更大模型时的障碍，从而为机制可解释性研究开辟了新的可能性。
### Conclusion
通过使用SPD，研究人员成功地分解了稍大且更复杂的模型，并证明了SPD能够避免参数收缩等问题，更好地识别真实机制。该结果显示了SPD在扩大线性参数分解方法应用范围方面的潜力，并提供了一个用于运行SPD和复制实验的库，从而提升了研究的可复现性。
## 493. `cs.LG` - 分割，专业化和路由：一种高效的集成学习新方法 [PDF](https://arxiv.org/pdf/2506.20814), [HTML](https://arxiv.org/abs/2506.20814)
### Authors
Jakub Piwko,Jędrzej Ruciński,Dawid Płudowski,Antoni Zajko,Patryzja Żak,Mateusz Zacharecki,Anna Kozak,Katarzyna Woźnica
### Background
集成学习已被证明能够提升预测性能，但传统的集成学习方法，如袋装（bagging）、提升（boosting）和动态集成选择（DES）具有较高的计算成本和对异质数据分布的适应能力较弱的问题。这些传统的集成方法无法有效应对这些挑战.
### Innovation
本文提出了Hellsemble，这是一种新颖且可解释的二分类集成框架，它在训练和推理过程中都考虑到数据集的复杂性。该方法通过迭代将错误分类的实例从简单的模型传递给更复杂的模型，从而形成一个细分的专业化基础学习者群体。每个模型都是根据复杂度逐渐训练的，并且通过一个单独的路由器模型基于预测的难度来分配新实例给最适合的基础模型。该方法在保持计算效率和可解释性的同时，取得了强大的分类准确性。实验结果表明，Hellsemble在OpenML-CC18和Tabzilla基准测试中常常优于经典集成方法.
### Conclusion
研究表明，将实例级别难度的考虑融入集成系统中是一个具有前景的方向，能够构建出高效和稳健的集成系统。
## 494. `cs.LG` - 认知雷达资源管理的多目标强化学习 [PDF](https://arxiv.org/pdf/2506.20853), [HTML](https://arxiv.org/abs/2506.20853)
### Authors
Ziyang Lu,Subodh Kalia,M. Cenk Gursoy,Chilukuri K. Mohan,Pramod K. Varshney
### Background
多功能认知雷达系统中的时间分配问题在于新出现目标的探测与先前检测目标的跟踪之间的权衡。为此，该问题被形式化为多目标优化问题，并使用深度强化学习来寻找帕累托最优解。比较了Deep Deterministic Policy Gradient (DDPG) 和 Soft Actor-Critic (SAC) 算法的效果，结果显示这两种算法都适合应对各种场景，其中SAC在稳定性和样本效率方面表现更佳。此外，还使用NSGA-II算法估计了所考虑问题的帕累托前沿的上限。
### Innovation
将多目标优化问题与深度强化学习相结合，在雷达资源管理中探索新的时间分配策略，特别是在不同场景中高效适应和处理多目标竞争问题。特别地，文章比较了DDPG和SAC算法的有效性，并使用NSGA-II算法来估计帕累托前沿的上限。
### Conclusion
本研究为发展更高效且适应性强的认知雷达系统做出了贡献，这些系统能够在动态环境中平衡多个相互竞争的目标。
## 495. `cs.LG` - Graph神经网络分布式训练揭秘：用于链接预测 [PDF](https://arxiv.org/pdf/2506.20818), [HTML](https://arxiv.org/abs/2506.20818)
### Authors
Xin Huang,Chul-Ho Lee
### Background
图神经网络（GNNs）是解决图相关问题的强大工具。分布式GNN框架和系统提高了GNN的可扩展性并加速了模型训练，但多数方法主要针对节点分类问题，对于链接预测问题的性能研究较少。本文探索了每个工作者在无法访问完整图的情况下，只训练分配给它们的子图片区分时，GNN性能下降的问题根源，并发现了图形分区导致的信息损失和模型训练时负样本的选择方式，这两者是影响性能的主要因素。将完整图信息分发给每个工作者可以解决这个问题并保持链接预测的准确性，但会增加较高的通信成本。
### Innovation
提出了SpLPG方法，该方法通过有效的图稀疏化来减轻性能下降的问题，同时将通信开销降低约80%，在保持链接预测准确性的同时，解决了分布式GNN训练中的性能问题。
### Conclusion
实验结果证明了SpLPG的有效性，在多个公开的现实世界数据集上，它将通信开销降低了大约80%，同时主要保持了链接预测的准确性。
## 496. `cs.LG` - FINN-GL: 为FPGA加速LSTMs的通用混合精度扩展 [PDF](https://arxiv.org/pdf/2506.20810), [HTML](https://arxiv.org/abs/2506.20810)
### Authors
Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker
### Background
循环神经网络（RNN），特别是长短期记忆网络（LSTM），在时间序列任务如情感分析和短期股票预测中非常有效。然而，由于其计算复杂性，它们在资源受限环境中进行实时部署时面临挑战。现场可编程门阵列（FPGA）为高效的人工智能加速提供了有前景的平台，但现有的工具主要针对前馈网络，而LSTM加速通常需要完全自定义实现。本文通过利用开源且可扩展的FINN框架，旨在缓解这一问题，通过利用Open Neural Network Exchange（ONNX）规格的Scan操作符来模拟LSTM计算的递归性质，支持混合量化，并对基于LSTM的模型进行功能验证。进一步地，引入了FINN编译器中的自定义转换，将量化后的ONNX计算图映射到FINN编译器HLS内核库和Vitis HLS的硬件模块。通过使用广泛使用的数据集训练一个量化后的ConvLSTM模型，对该工具流进行了验证，并生成了目标为XCZU7EV的模型硬件IP。研究表明，本文流生成的量化ConvLSTM加速器在性能（延迟）和资源消耗之间达到平衡，同时在减少精度的情况下，实现了与最新模型相当甚至更好的推理准确性。
### Innovation
本文利用FINN框架和Scan操作符来构建LSTM的混合量化支持，为FPGA上的LSTM加速提供了一种通用解决方案。通过自定义转换，将量化后的ONNX图映射到HLS硬件模块，提高加速器的性能和资源效率。研究展示了该流在平衡性能和资源消耗方面的优势，同时在精度上也提高了能效。
### Conclusion
本文提出的方法提供了一种通用的工具流，用于在FPGA上部署LSTM，平衡了性能和资源消耗，同时提高了能效。作者认为，该方法为资源高效设计的RNN加速器铺平了道路，特别是在FPGA上。
## 497. `cs.LG` - Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA [PDF](https://arxiv.org/pdf/2506.20856), [HTML](https://arxiv.org/abs/2506.20856)
### Authors
Fei Wang,Baochun Li
### Background
大型语言模型（LLMs）由于记忆数据，在数据提取攻击中容易受到影响。在预训练阶段，已经有大量的研究探讨了记忆问题，但在微调过程中，特别是使用LoRA（低秩微调）这一广泛采用的参数高效方法时，记忆的影响则较少被研究。LoRA是一种参数高效的方法，使得模型的微调更加高效。先前的研究表明，模型规模和数据重复等因素在预训练和完全微调过程中对记忆影响显著，但在LoRA微调中，这些因素的趋势有所不同。
### Innovation
本文重新审视了LoRA在微调过程中的记忆现象，发现与以往的研究结果有出乎意料的差异。使用较为宽松的基于相似度的记忆度量指标，研究表明LoRA显著降低了记忆风险的同时，还能保持良好的任务性能。这一发现颠覆了以往对LoRA的记忆特性的认知，为LoRA在实际应用中的记忆问题提供了新的见解。
### Conclusion
LoRA在微调过程中显著减少了记忆风险，这对缓解数据提取攻击具有重要意义。尽管如此，LoRA在保持高效同时仍能保证较强的性能，证明了其在实际应用场景中的适用性。
## 498. `cs.LG` - 基于学习的综合感知与通信系统资源管理 [PDF](https://arxiv.org/pdf/2506.20849), [HTML](https://arxiv.org/abs/2506.20849)
### Authors
Ziyang Lu,M. Cenk Gursoy,Chilukuri K. Mohan,Pramod K. Varshney
### Background
本文探讨了使用雷达和通信单元的综合感知与通信系统中适应性时间分配的任务。在这样的系统中，雷达-通信单元的任务是在跟踪多个目标和利用剩余时间进行数据传输之间分配停留时间。如何在时间预算限制下最优地分配这些资源，以提升目标通信质量，一直以来都是一个挑战性的研究问题。现有方法可能难以在动态环境中同时优化通信质量和遵守时间限制。本文将这一任务提升到一个新的优化层面上，利用深度强化学习方法解决资源分配问题，从而更好地应对动态环境和时间约束带来的挑战。
### Innovation
本文提出了一种新的受约束的深度强化学习（CDRL）方法，该方法旨在在给定的时间预算内优化跟踪和通信之间的资源分配，特别适用于高度动态环境下的通信质量最大化。该方法能够学习如何在不同场景下自动平衡感知和通信的需求，从而提升系统的整体性能，特别是在面对快速变化的环境时。
### Conclusion
本文的数值结果展示了提出的CDRL框架的有效性，证明了其能够在遵守时间约束的同时，最大化通信质量。这表明，通过结合深度强化学习，可以更有效地管理综合感知与通信系统中的资源分配。未来研究可以进一步探索如何使这种方法在其他类似环境中适用，以及如何进一步优化其性能。这种优化不仅限于雷达-通信系统，还可以适用于其他需要同时进行感知和通信的复杂系统。
## 499. `cs.LG` - Diffusion Tree Sampling: 生成模型在推理阶段的可扩展对齐方法 [PDF](https://arxiv.org/pdf/2506.20701), [HTML](https://arxiv.org/abs/2506.20701)
### Authors
Vineet Jain,Kusha Sareen,Mohammad Pedramfar,Siamak Ravanbakhsh
### Background
在生成建模中，如何在推理阶段将预训练的扩散模型适应新目标仍是一个未解问题。现有的调节方法在高噪声水平下价值估计不准确，偏导指导。此外，过去运行的信息没有被重用以提高样本质量，导致计算资源使用效率低下。受Monte Carlo树搜索成功的启发，我们通过将推理时间对齐问题描述为一个利用过往计算的搜索问题来解决这些问题。
### Innovation
我们提出了一种基于树的方法，即Diffusion Tree Sampling (DTS)，通过在扩散链中传播终端奖励并随着每次生成逐步改进价值估计，从奖励对齐的目标密度中进行抽样。该方法在无限迭代情况下产生精确样本，并且其贪婪变体Diffusion Tree Search (DTS$^text{'}) 进行全局搜索以寻找高价值样本。这种方法在MNIST和CIFAR-10类条件生成任务中，比基线模型FID低10倍的计算复杂度能产生可媲美基线模型的样本。在文本转图像生成和语言完成任务中，DTS$^text{'})能效更高地搜索高价值样本，即使在低5倍的计算复杂性下也能与最佳基线样本一致。通过重用先前生成的信息，实现了一个随时随地生成更优质样本的算法，提供了一种扩展的扩散模型推理时间对齐方法。
### Conclusion
Diffusion Tree Sampling (DTS)和其贪婪变体Diffusion Tree Search (DTS$^text{'})能有效提高生成模型在推理阶段的样本质量，同时大幅降低计算复杂度，为扩散模型的推理时间对齐提供了可扩展的方法。
## 500. `cs.LG` - 为雷达资源管理提供可解释的人工智能：改进的DL-LIME在深度强化学习中的应用 [PDF](https://arxiv.org/pdf/2506.20916), [HTML](https://arxiv.org/abs/2506.20916)
### Authors
Ziyang Lu,M. Cenk Gursoy,Chilukuri K. Mohan,Pramod K. Varshney
### Background
深度强化学习在决策过程中得到了广泛研究，并在包括雷达资源管理（RRM）在内的多个领域中展现了优越的性能，超过了传统方法。然而，神经网络的一个重要局限是它们的“黑箱”性质，这限制了我们对它们决策过程的理解。最近的研究工作越来越关注可解释的人工智能（XAI）技术，以解释神经网络的决策逻辑。局部可解释通用模型解释（LIME）是一种很有前景的XAI方法，但它在采样过程中忽略了特征之间的相关性。
### Innovation
本文提出了一种改进的LIME方法，即整合了深度学习（DL）的采样过程的方法，称为DL-LIME。我们将在深代表决策学习中使用DL-LIME进行雷达资源管理。数值结果表明，与传统的LIME相比，DL-LIME在准确性和任务性能方面都表现出更优的性能。DL-LIME还提供了决策过程中哪些因素对雷达资源管理更重要。
### Conclusion
DL-LIME在雷达资源管理中提供了更透明的决策解释，并且在性能上表现优异。
## 501. `cs.LG` - 基于图结构反馈的多模型集成在线容规预测 [PDF](https://arxiv.org/pdf/2506.20898), [HTML](https://arxiv.org/abs/2506.20898)
### Authors
Erfan Hajihashemi,Yanning Shen
### Background
在线容规预测能够为每个新输入的数据点构建预测集，保证预测集覆盖真实标签的概率。为了应对潜在的分布迁移，多模型在线容规预测方法被提出，它可以利用预选模型集合中的不同模型，从而提高灵活性。然而，该方法也面临着挑战，如候选模型集过大可能增加计算复杂度，以及包含性能不佳的模型可能导致预测集过大且性能降低。
### Innovation
本文提出了一种新型的多模型在线容规预测算法，通过从二分图收集反馈信息并根据新数据进行迭代优化，可以有效识别每一步有效的模型子集。通过选择该子集中的模型来构建预测集，该算法减少了计算复杂性并缩小了预测集的大小。此外，该方法还发现，使用预测集大小作为反馈与模型损失结合，可以显著提高效率，同时满足所需的覆盖保证。证明了算法的有效性并具有亚线性遗憾。实验在真实和合成数据集上验证了所提方法构建更小的预测集且优于现有的多模型在线容规预测方法。
### Conclusion
所提出的多模型在线容规预测算法确保了有效的覆盖，并且实现了亚线性遗憾。实验结果表明，这种方法可以构建更小的预测集并优于现有的多模型在线容规预测方法。
## 502. `cs.LG` - 关于输出分布重加权对于有效类别去学习的必要性 [PDF](https://arxiv.org/pdf/2506.20893), [HTML](https://arxiv.org/abs/2506.20893)
### Authors
Yian Wang,Ali Ebrahimpour-Boroojeny,Hari Sundaram
### Background
从训练好的模型中删除特定类别的能力对于保障用户删除权利以及减轻有害或带有偏见的预测至关重要。但现有方法在预测遗忘类别的样本时，要么需要完全重新训练，这成本很高，要么即便进行部分修改，也无法复制重新训练后的模型行为。论文通过设计MIA-NN攻击变种，证明了当前方法在这方面的失败，并提出了一种简单的概率重新分布方法来解决此问题，同时引入新的基于预测概率的总体变异距离指标来量化残留的泄漏，以防止未来的方法对新攻击的脆弱性。
### Innovation
提出了一种名为RWFT的轻量级去学习方法，无需完全重新训练就可以删除整个类别。通过重新分布预测概率的质量，该方法能够抵御MIA-NN攻击并证明了其有效性。进一步提出了一个基于预测概率总体变异距离的新度量标准，以量化残留泄漏并避免未来算法的脆弱性。通过与现有最佳基线方法进行广泛实验，论文展示了RWFT方法在多个评价指标上的优越性，特别是在提出的新度量标准中表现尤其突出。
### Conclusion
通过全面实验RWFT方法在多个评价指标上达到了与完全重新训练相同的效果。与最先进的方法相比，该方法在之前的度量标准上提高了2.79%，在新提出的基于总体变异距离的度量标准上提高了111.45%。
## 503. `cs.LG` - 由多代理方法指导的大语言模型化学过程优化 [PDF](https://arxiv.org/pdf/2506.20921), [HTML](https://arxiv.org/abs/2506.20921)
### Authors
Tong Zeng,Srivathsan Badrinarayanan,Janghoon Ock,Cheng-Kai Lai,Amir Barati Farimani
### Background
最大化生产效率和经济效益需要对化学过程进行优化。传统方法如梯度法求解器、演化算法和参数网格搜索，在缺乏或定义不清操作约束时变得不切实际，迫使工程师依赖主观的启发式方法来估算可行的参数范围。本文介绍了一个基于多代理框架的大语言模型（LLM）代理方法，该方法能够自主从简要的过程描述中推断出操作约束，并利用这些推断出的约束进行合作优化。
### Innovation
所提出的方法包括一个基于AutoGen的多代理框架，采用OpenAI的o3模型，并包含特殊设计的代理来生成约束、验证参数、执行模拟和提供优化指导。该方法通过两个阶段进行优化：自主生成约束利用嵌入的领域知识，然后进行迭代多代理优化。这种框架能够避免预设的操作界限，且在成本、产出和产出对成本比率的指标上验证了与传统方法相当的性能，同时具有更好的计算效率，能够在不到20分钟的时间内实现31倍的速度提升。此外，该框架展示了逻辑指导的搜索，表明了高级的过程理解和应用领域启发式的能力，对操作约束不详细或缺失的优化场景具有重要意义，特别是在新兴过程和改造应用方面。
### Conclusion
该方法展示了在操作约束不详细或缺失情况下进行优化的潜力，特别是在新兴过程和改造应用中具有重要应用前景。通过多代理协作和大语言模型的推理能力提升了优化过程的效率和效果。
## 504. `cs.LG` - 可解释的加性规则集成的表示学习 [PDF](https://arxiv.org/pdf/2506.20927), [HTML](https://arxiv.org/abs/2506.20927)
### Authors
Shahrzad Behzadimanesh,Pierre Le Bodic,Geoffrey I. Webb,Mario Boley
### Background
传统上，这些集成使用基于单个输入变量的简单阈值命题（如$x eq t$）的联结条件生成的规则条件，几何上表现为轴平行多面体作为决策区域。虽然这种形式可以有效使用梯度提升方法学习，具有高度解释性，但它依赖于拥有丰富且理想的独立输入特征。缺乏这些特征时，需要增加规则的数量和复杂度以达到足够的准确度，这会降低模型的解释性。因此，我们通过引入可学习的稀疏线性变换输入变量的形式逻辑命题，扩展了传统规则集成的方法，提出了具有斜面的多面体作为决策区域的新方法。研究证明，该方法可以高效构建具有与先进方法相同测试风险但模型复杂度显着降低的规则集成模型。
### Innovation
我们通过引入逻辑命题 $textbf{x}^text{T}textbf{w} eq t$，引入了基于输入变量可学习的稀疏线性变换的形式逻辑命题，使得决策区域可以表现为具有斜面的多面体。我们还提出了一种基于迭代重新加权的逻辑回归递增贪婪优化的学习方法。实验结果显示，该方法可以在模型复杂度大幅降低的同时保持与先进方法相同的投资组合风险。
### Conclusion
我们提出的方法能够高效构建具有与先进方法相同测试风险但模型复杂度显著降低的加性规则集成模型，实现了在保持模型解释性的前提下提升模型性能的目标。
## 505. `cs.LG` - GPU Kernel Scientist: 一种基于LLM的迭代内核优化框架 [PDF](https://arxiv.org/pdf/2506.20807), [HTML](https://arxiv.org/abs/2506.20807)
### Authors
Martin Andrews,Sam Witteveen
### Background
优化GPU内核以实现高性能是复杂的工作，通常需要深入的架构知识、广泛的数据分析和反复的试验。但在针对较新的或文档较少的GPU架构时，这种挑战会被进一步放大，因为传统的开发辅助工具较少。因此，研究人员面临着如何高效优化GPU内核的挑战，特别是在资源受限或快速发展的硬件环境中。当前的研究工作介绍了一种基于LLM的“GPU内核科学家”，这是一种自动化的内核优化方法，通过多阶段、进化性的过程逐步改进GPU加速器内核。该方法使用LLM在三个阶段中迭代地进行内核优化：首先，战略性地选择有前途的先前代码版本作为新迭代的基础；其次，基于现有代码和从通用GPU文献中吸收的知识，生成优化实验的假设；最后，自动实现这些实验并通过代码修改和提交到外部评估系统进行评估，仅使用观察到的运行时间数据作为性能反馈。该方法在AMD MI300目标架构上进行了展示，并利用LLM弥补了有限的特定领域的人类专业知识，以克服这些挑战。由于性能竞赛的定量结果因论文提交日期而被禁止发布，相关工作重点介绍了该架构设计、操作流程和定性见解，强调了基于LLM的代理在促进GPU内核优化方面的作用，特别是在资源受限或快速发展的硬件环境中。
### Innovation
该方法利用了LLM在以下方面实现创新：1) 多阶段、进化性的内核优化过程；2) 自动生成优化实验的假设；3) 仅通过观察到的运行时间数据反馈进行自动实验实施和优化；4) 在资源受限或快速发展的硬件环境中，利用LLM弥补了有限的特定领域的人类专业知识，从而简化了内核优化过程并提高了效率。
### Conclusion
虽然当前没有提供具体的结果数据，但通过详细阐述基于LLM的开发商平台设计、操作流程和定性见解，该论文展示了其在GPU内核优化方面的潜在价值，特别是对于资源有限或硬件快速发展的环境，基于LLM的代理有望普及和加速GPU内核优化。
## 506. `cs.LG` - Model State Arithmetic for Machine Unlearning [PDF](https://arxiv.org/pdf/2506.20941), [HTML](https://arxiv.org/abs/2506.20941)
### Authors
Keivan Rezaei,Mehrdad Saberi,Abhilasha Ravichander,Soheil Feizi
### Background
大型语言模型在大量网络数据上进行训练，这些数据可能包含私人数据、受版权保护的内容、事实不准确的数据或损害模型性能的数据。完全通过重复预训练的方式从包含这些特定实例的数据集中剔除这些有问题的数据点进行消除影响是计算上不可行的。因此，已经出现了旨在消除特定数据点影响的同时，尽可能保留模型的算法，这些算法具有较低的计算成本。然而，准确估计并逆转单个数据点的影响证明是一个挑战。我们提出了一个新算法MSE，该算法利用模型检查点来估计并取消数据点的影响。实验结果表明，MSE在多个基准测试、模型和评估指标上优于现有机器去学习算法，这表明MSE可能是更灵活的大型语言模型的有效方法，这些模型能够删除数据。
### Innovation
我们提出了一个新算法MSE，通过利用模型检查点来估计并取消数据点的影响。与现有的机器去学习算法相比，MSE能够在多个基准测试、模型和评估指标上表现出更优的表现，这表明MSE可能是一种更有效的方法，可以实现更灵活的大型语言模型，能够执行数据删除操作。
### Conclusion
实验结果显示，MSE在多个基准测试、模型和评估指标上持续优于现有的机器去学习算法，表明MSE可能是一种有效的方法，可以向更灵活的大型语言模型迈进，这些模型能够实现数据擦除功能。
## 507. `cs.LG` - 最优单策略样本复杂度及瞬时覆盖范围下的平均报酬离线强化学习 [PDF](https://arxiv.org/pdf/2506.20904), [HTML](https://arxiv.org/abs/2506.20904)
### Authors
Matthew Zurek,Guy Zamir,Yudong Chen
### Background
在平均报酬MDP中研究离线强化学习，其受到分布变化和非均匀覆盖的挑战，从理论上来说相对较少被研究。以往的工作在单策略数据覆盖率假设下获得了性能保证，这些保证使用了所有策略上的均匀复杂性度量，例如均匀混合时间。本研究发展了仅仅依赖于目标策略的精确保证，具体包括偏移跨度和一个新颖的策略碰撞半径，从而提供了第一个完全基于单策略样本复杂度的平均报酬离线强化学习保证。我们也展示了能够处理一般弱通讯MDP的方法，这不同于以往工作中的严格结构假设。我们的方法基于悲观折现价值迭代，结合了一个新颖的量裁剪技术。我们的算法在实施时不需要任何先验参数知识。研究还通过困难的例子展示了在我们条件下学习需要超出目标策略稳定分布的覆盖假设，区分了单策略复杂性度量与之前研究的案例。同时也发展了与主要结果几乎匹配的下界。
### Innovation
提出了仅依赖于目标策略的准确保证，包括偏移跨度和一个新颖的策略碰撞半径；首次提供了一个完全基于单策略样本复杂度的平均报酬离线强化学习保证；能够处理一般弱通讯MDP；算法基于悲观折现价值迭代，结合了一个新颖的量裁剪技术；在实施时不需要任何先验参数知识；展示了在目标策略稳定分布之外还需要超出的覆盖假设；发展了几乎与主要结果匹配的下界。
### Conclusion
在平均报酬MDP中，研究了仅依赖于目标策略的精确保证，结合悲观折现价值迭代和量裁剪技术，首次提供了完全基于单策略样本复杂度的保证，能够处理更一般的MDP情况，并通过困难的例子展示了在目标稳定分布之外的额外覆盖假设需求，同时建立了接近主要结果的下界。
## 508. `cs.LG` - 使用多尺度等变图扩散模型进行准确复杂抗原结合的抗体设计和优化 [PDF](https://arxiv.org/pdf/2506.20957), [HTML](https://arxiv.org/abs/2506.20957)
### Authors
Jiameng Chen,Xiantao Cai,Jia Wu,Wenbin Hu
### Background
抗体设计在治疗和诊断中仍然是一个关键挑战，尤其是对于具有多样结合界面的复杂抗原。当前的计算方法面临两大主要限制：（1）在保留对称性的同时捕获几何特征，（2）泛化新型抗原界面。尽管最近取得了进展，但这些方法通常无法准确捕捉分子相互作用并保持结构完整性。
### Innovation
本文提出了一种名为AbMEGD的端到端框架，结合多尺度等变图扩散技术进行抗体序列和结构共设计。通过利用先进的几何深度学习，AbMEGD将原子级别的几何特征与残基级别的嵌入相结合，捕捉局部原子细节和全局序列-结构相互作用。其E(3)-等变扩散方法确保了几何精度、计算效率和对复杂抗原的强大泛化能力。实验结果证实，与领先的抗体设计模型DiffAb相比，AbMEGD在氨基酸恢复率、改进百分比以及关键区CDR-H3的均方根偏差方面均有所提升，从而证明了其在保持结构完整性的同时提升功能的能力。
### Conclusion
实验结果表明，AbMEGD在序列-结构共设计和亲和力优化方面建立了一个新的基准，通过增强的功能性在SAbDab数据库中实现了关键区域氨基酸捕获率和结构精度的显著提高。源代码可在提供的链接中获得。
## 509. `cs.LG` - SharpZO: 前向通过迭代的混合感知锐度视觉语言模型提示调优 [PDF](https://arxiv.org/pdf/2506.20990), [HTML](https://arxiv.org/abs/2506.20990)
### Authors
Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang
### Background
视觉语言模型（VLMs）在下游任务中表现出色，但需要通过反向传播（BP）访问模型梯度，这使得它们不适合用于内存受限的、仅进行推理的边缘设备。之前的研究探索了多种无需BP的微调方法，但这些方法通常依赖于高方差的进化策略（ES）或零阶（ZO）优化，往往未能达到满意的性能。
### Innovation
提出了一种混合感知锐度的零阶优化（SharpZO）方法，通过感知锐度感知的预热训练来增强ZO VLM微调的表现。SharpZO采用两阶段优化过程，首先通过感知锐度感知的进化策略阶段进行全局探索和景观平滑以构造强大初始化，接着通过稀疏零阶优化进行精细的局部搜索。整个优化过程仅依赖于向前传递的迭代。
### Conclusion
详细理论分析和在CLIP模型上的广泛实验表明，SharpZO显著提高了准确性和收敛速度，在最先进的仅前向迭代方法上平均提高了7%的性能。
## 510. `cs.LG` - TRIDENT: 三角模态分子表示学习及其分类注释与局部对应 [PDF](https://arxiv.org/pdf/2506.21028), [HTML](https://arxiv.org/abs/2506.21028)
### Authors
Feng Jiang,Mangal Prakash,Hehuan Ma,Jianyuan Deng,Yuzhi Guo,Amina Mollaysa,Tommaso Mansi,Rui Liao,Junzhou Huang
### Background
分子性质预测旨在将化学结构映射到功能属性。虽然多模态学习已经成为了学习分子表示的强大范式，但之前的研究很少关注分子的文本描述和分类功能注释。TRIDENT框架引入了一种新型的方法，综合了分子SMILES、文本描述和分类功能注释来学习丰富的分子表示。为了实现这一点，该框架创造出一个包含分子结构和分类功能信息的数据集，同时也使用了一种基于体积的对齐目标来对齐三种模态的特征，实现了一种软几何感知的跨模态对齐。此外，该框架还引入了一种新的局部对齐目标来捕捉分子亚结构及其相应文本描述之间的详细关系。
### Innovation
TRIDENT框架通过综合分子SMILES、文本描述和分类功能注释来学习丰富的分子表示。它使用了一种新的基于体积的对齐目标，能够在全局层面同时对齐三种模态的特征，实现了一种软几何感知的跨模态对齐。此外，还引入了一种新的局部对齐目标，能够捕捉分子亚结构及其相应文本描述之间的详细关系。更进一步，TRIDENT还提出了一种基于动量的机制来动态平衡全局和局部对齐，从而使模型能够学习到更广泛的功能性语义及精细的结构-功能映射关系。
### Conclusion
TRIDENT在11个下游任务中达到了最先进的性能，证明了结合SMILES、文本和分类功能注释对于分子性质预测的价值。
## 511. `cs.LG` - 联邦学习下概念漂移的信息论分析 [PDF](https://arxiv.org/pdf/2506.21036), [HTML](https://arxiv.org/abs/2506.21036)
### Authors
Fu Peng,Meng Zhang,Ming Tang
### Background
近年来，联邦学习（FL）研究大多基于静态数据集进行模型训练。然而，现实中的数据通常是随时间流来的，且其分布会发生变化。这种现象被称为概念漂移，并会导致模型性能下降。本文分析了在概念漂移情况下的联邦学习性能，并提出了一个算法来缓解其性能下降的问题。
### Innovation
1. 将概念漂移建模为马尔可夫链2. 引入了‘稳态泛化误差’来评估模型捕捉未来未见数据特性的能力3. 使用KL散度和互信息推导其上界，并研究了三种漂移模式（周期性、渐进性和随机性）对联邦学习性能的影响4. 提出了一种算法，将KL散度和互信息与经验风险最小化相结合，以增强长期性能5. 探索性能-成本 tradeoff，并发现 Pareto 前沿6. 使用树莓派 4 设备构建了一个联邦学习测试床，实验结果与理论一致
### Conclusion
本文通过理论分析和实验验证，证明了漂移模式对联邦学习性能有显著影响，并表明所提出的方法能在三种漂移模式下持续优于现有方法，有效地适应联邦学习中的概念漂移问题。
## 512. `cs.LG` - RL-Selector：通过冗余评估引导的强化学习指导下的数据选择 [PDF](https://arxiv.org/pdf/2506.21037), [HTML](https://arxiv.org/abs/2506.21037)
### Authors
Suorong Yang,Peijia Li,Furao Shen,Jian Zhao
### Background
现代深度架构通常依赖大规模数据集，但这些训练过程会带来高计算和存储开销。现实世界的数据集中存在大量的冗余性，从而引发了更高效的数据训练需求。现有数据选择方法通过识别代表性样本来减少冗余，但往往依赖静态评估指标或预训练模型，未能充分利用样本在训练过程中动态变化的影响。因此，需要一种能够量化样本间关系并适应数据分布变化的数据选择方法。
### Innovation
该研究引入了ε-样本覆盖的概念，通过量化样本间的冗余关系来捕捉数据集的固有结构。研究将数据选择问题重新定义为强化学习过程，提出了RL-Selector方法，利用轻量级的RL代理通过ε-样本覆盖信号作为奖励信号来优化数据选择策略。实验结果显示该方法在多种数据集和不同架构上表现出了对现有最佳基线的一致优越性，训练出的模型具有更好的泛化能力和更高的训练效率。
### Conclusion
研究通过建立ε-样本覆盖的概念，将数据选择问题转换为强化学习过程，提出RL-Selector方法，该方法能够有效消除数据集中的冗余性，提高了模型的训练效率和泛化性能。广泛实验验证了该方法的有效性和优越性。
## 513. `cs.LG` - Omniwise：使用大语言模型预测GPU内核性能 [PDF](https://arxiv.org/pdf/2506.20886), [HTML](https://arxiv.org/abs/2506.20886)
### Authors
Zixian Wang,Cole Ramos,Muhammad A. Awad,Keith Lowery
### Background
近年来，深度神经网络（DNNs）的快速发展彻底改变了人工智能，使模型具备了前所未有的理解、生成和处理复杂数据的能力。这些强大的架构已广泛应用于多个下游应用领域，解决了一些超出人类能力的任务。背景在于如何高效地预测GPU内核性能，提升开发效率和系统性能。传统的性能预测方法通常需要代码执行或性能分析工具，而这种方法探索了一种全新的自我监督的细调管道，利用大语言模型（LLMs）直接从内核代码预测关键性能指标，无需实际执行代码或使用专用的性能分析工具。
### Innovation
介绍了Omniwise，这是一种端到端的自我监督细调管道，首次使用大语言模型来预测GPU内核性能，这是一种新型性能评估用例。Omniwise具有模型无关性和轻量级特性，即使使用小至3亿参数的模型也能取得显著成果。该方法能直接从内核代码预测包括内存带宽、缓存命中率、GFLOPs和算术强度在内的关键性能指标。研究表明，该方法在AMD MI250和MI300X架构上的内核执行中，能够实现超过90%的预测精度，相对误差不超过10%。此外，该论文还开发了一个在线推理服务器和Visual Studio Code插件，使基于大语言模型的性能预测能够无缝集成到开发人员的工作流程中。
### Conclusion
Omniwise为开发者提供了一种高效的方法来预测GPU内核性能，无需代码执行或专有的性能分析工具。这种方法在性能预测上表现出色，能够显著提高开发效率和系统性能，展示了大语言模型在性能预测和优化中的潜力。
## 514. `cs.LG` - 严格子目标执行：层次强化学习中可靠的长时规划 [PDF](https://arxiv.org/pdf/2506.21039), [HTML](https://arxiv.org/abs/2506.21039)
### Authors
Jaebak Hwang,Sanghyeon Lee,Jeongmo Kim,Seungyul Han
### Background
长期目标条件任务为强化学习（RL）带来了根本性的挑战，尤其是当目标距离遥远且奖励稀疏时。尽管存在分层和图基方法，但这些方法往往面临子目标不可行性和规划效率低下的问题。
### Innovation
提出了严格子目标执行（SSE）作为一种图基层次强化学习框架，通过结构上约束高层次决策以确保单步骤子目标可达性。此外，SSE还采用了解耦探索策略，系统地探索目标空间的未探索区域，并通过根据低层成功率动态调整边成本来改进图基规划。这种策略提高了子目标的可靠性。实验结果表明，SSE在效率和成功率方面均优于现有目标条件RL和层次RL方法。
### Conclusion
SSE在不同长时基准测试中表现优异，不仅在效率上优于现有的目标条件RL和层次RL方法，而且在成功率方面也表现出色。
## 515. `cs.LG` - 逐步实现：基于自激活稀疏可调秩混合的持续学习 [PDF](https://arxiv.org/pdf/2506.21035), [HTML](https://arxiv.org/abs/2506.21035)
### Authors
Haodong Lu,Chongyang Zhao,Jason Xue,Lina Yao,Kristen Moore,Dong Gong
### Background
持续学习（CL）使用大型预训练模型面临着灾难性遗忘和任务干扰的问题。现有基于LoRA的专家混合（MoE）方法通过分配和冻结与任务相关的适配器来缓解遗忘，但会遇到干扰、冗余性和由于粗粒度的适配器选择而产生的模糊路由问题。这一设计引入了三个关键挑战：1) 干扰：每次输入都会激活完整的LoRA专家，导致子空间干扰，阻碍了有用组件在任务间的有选择性的重用；2) 冗余：新添加的专家时常重复或矛盾现有知识，这是由于不必要的激活无关的秩和相关秩的不足重用；3) 模糊性：任务间的重叠特征使路由器困惑，导致不稳定的专家分配。随着专家的积累，早期的任务分配退化，加快了遗忘进程。
### Innovation
我们提出了MoRA，一种自我激活和稀疏秩激活的混合专家学习方法（Mixture-of-Rank Adaptive learning）。不同于混合多个低秩矩阵，MoRA将每个秩-r更新分解为r个独立的秩-1组件，每个组件被视为一个独立专家，实现精细的秩-1专家混合利用，同时抑制干扰和冗余。为了避免歧义路由，我们提出每个秩-1专家可以通过中间激活自我推断其相关性。结合我们提出的秩剪枝和激活预算，MoRA能够根据输入自适应地选择稀疏的秩混合。
### Conclusion
我们验证了MoRA在CLIP和大型语言模型（LLMs）持续学习任务中的有效性，在增强使用PTMs的CL、提高泛化能力并减少遗忘方面表现出显著效果。
## 516. `cs.LG` - 蒸馏归一化流 [PDF](https://arxiv.org/pdf/2506.21003), [HTML](https://arxiv.org/abs/2506.21003)
### Authors
Steven Walton,Valeriy Klyukin,Maksim Artemev,Denis Derkach,Nikita Orlov,Humphrey Shi
### Background
显式密度学习者因其更好地能建模概率分布的能力，正在成为生成模型中越来越流行的技术。与生成对抗网络相比，它们可以通过执行密度估计和精确潜在变量推理来实现更高的优势。这带来了许多优点，比如能够简单插值、计算样本似然性和分析概率分布。然而，这些模型的缺点通常更难以训练，并且采样质量较低。归一化流是一种显式密度模型，使用可组合的双射函数将难以处理的概率函数转换为易于处理的形式。
### Innovation
本文提出了新颖的知识蒸馏技术，以提高较小的学生归一化流的采样质量和密度估计。研究了组成归一化流中知识蒸馏的能力，以了解这些架构提供的优势和弱点。归一化流具有独特的特性，这使得可以进行非传统形式的知识转移，在中间层可以传递那些知识。我们发现，通过这种蒸馏，尽管学生模型显著减小，但在非蒸馏学生的基础上能够实现显著的性能提升。由于模型更小，这意味着网络中的置换器和参数数量的减少，从而提高了相应的吞吐量，因为这是依赖于网络中的置换器数量的。
### Conclusion
通过知识蒸馏，在保持甚至提高模型性能的同时，可以显著减小模型规模。这表明，在归一化流中进行知识蒸馏是提高模型效率的有效方法，尤其是在需要高吞吐量的应用场景下。
## 517. `cs.LG` - 通过后悔意识优化实现高效技能发现 [PDF](https://arxiv.org/pdf/2506.21044), [HTML](https://arxiv.org/abs/2506.21044)
### Authors
He Zhang,Ming Zhou,Shaopeng Zhai,Ying Sun,Hui Xiong
### Background
无监督技能发现旨在解决开放环境下强化学习中学习多样且可区分的行为的问题。现有方法主要通过纯探索、互信息优化和时间表示学习来提升多样性。尽管在探索上表现良好，但在效率，尤其是高维情况下，仍旧存在局限性。
### Innovation
本文将技能发现视为技能生成和策略学习的min-max游戏，并提出一种基于时间表示学习的后悔意识方法。该方法通过探索弱技能并减少已收敛技能的探索来扩展发现的技能空间。作者采用后悔来衡量技能强度的收敛程度，并通过可学习的技能生成器引导技能发现。技能生成器来自可升级的集合，以避免技能发现退化。实验结果显示，该方法在效率和多样性方面均优于基线，在高维环境中更实现了15%的零样本改进。
### Conclusion
实验结果表明，本文方法在效率和多样性方面均优于基准方法，并在高维环境中实现了显著的零样本改进。
## 518. `cs.LG` - 使用知识图谱生成高质量指令数据以增强大语言模型工具使用 [PDF](https://arxiv.org/pdf/2506.21071), [HTML](https://arxiv.org/abs/2506.21071)
### Authors
Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong
### Background
大语言模型（LLMs）学习使用工具对于提高其解决问题的能力和扩展应用非常重要，但有效使用工具具有挑战性，因为这需要深入了解工具功能和用户意图。以往的方法主要依赖LLMs生成指令数据，但数据质量往往不足。因此，本文提出了一个创新的方法，利用知识图谱生成高质量的指令数据，从而更好地指导LLMs利用工具。知识图谱是手工整理的富含语义信息的数据集。研究从给定的知识图谱中提取各类查询路径，并将其转化为广泛的用户查询。接着，将实体间的联系转变为可操作的工具，并解析每个查询的路径以生成详细的解决方案步骤，从而产生高质量的指令数据。实验表明，仅通过少量这种合成数据的微调就可以显著提高LLMs工具利用能力和整体能力。
### Innovation
本文提出了一种新颖的方法，利用知识图谱生成高质量的指令数据，从而提高大语言模型利用工具的能力。该方法通过从知识图谱中提取查询路径，转化为用户查询，解析为工具操作指令并生成详细解决方案步骤，生成高质量指令数据。这种方法显著改善了大语言模型的能力和工具利用率。
### Conclusion
实验结果表明，仅通过少量合成数据的微调就能显著提高大语言模型工具利用能力和整体能力，验证了方法的有效性。
## 519. `cs.LG` - FedDAA: 动态客户端聚类以适应联邦学习中的概念漂移 [PDF](https://arxiv.org/pdf/2506.21054), [HTML](https://arxiv.org/abs/2506.21054)
### Authors
Fu Peng,Ming Tang
### Background
在联邦学习（FL）中，每个客户端的数据分布可能会随时间发生变化，引入了时间和空间上的数据异构性，称为概念漂移。这种异构性来源于三种漂移源：真实漂移（条件分布P(y|x)的变化）、虚拟漂移（输入分布P(x)的变化）和标签漂移（标签分布P(y)的变化）。然而，现有的许多FL方法主要针对真实漂移，当客户端经历虚拟或标签漂移时，这些方法往往无法有效保留有用的历史知识，导致灾难性遗忘。区分不同的漂移源是重要的，因为它们需要不同的适应策略：真实漂移需要淘汰过时的数据，而虚拟或标签漂移则可以从保留历史数据中受益。没有明确识别漂移源，通常会导致一般适应策略次优，并可能损害泛化能力。当前的研究主要集中在处理真实漂移，而没有针对虚拟或标签漂移的有效方法。
### Innovation
我们提出了FedDAA，一种用于处理多源概念漂移的动态聚类联邦学习框架，同时保留有价值的历史知识。FedDAA集成了三个模块：一个确定最优聚类数量的模块、一个区分真实漂移和虚拟/标签漂移的模块，以及一个适应新数据并保留有用历史信息的概念漂移适应模块。它提供了理论上的收敛保证，并在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上实现了显著的准确率提升，证明了其有效性和优越性。
### Conclusion
FedDAA框架能够在处理多源概念漂移的同时，保留有价值的历史知识，通过对不同漂移源的明确区分，提出了有效的适应策略。实验结果表明，FedDAA在多个数据集上比现有方法实现了显著的准确率提升，证实了其在联邦学习中的有效性和优越性。
## 520. `cs.LG` - FeDa4Fair：用于公平性评估的客户端级联邦数据集 [PDF](https://arxiv.org/pdf/2506.21095), [HTML](https://arxiv.org/abs/2506.21095)
### Authors
Xenia Heilmann,Luca Corbucci,Mattia Cerrato,Anna Monreale
### Background
联邦学习(FL)允许跨多个客户端协作训练模型，而不共享客户端的私有数据。然而，公平性仍然是一个关键问题，由于客户端数据集中的偏差会影响整个联邦系统的性能。不同客户端之间异质的数据分布可能导致模型对某些客户端更公平，但对其他客户端不公平。尽管文献中存在一些公平性增强的解决方案，但大多数方法只集中在缓解单一敏感特征的偏见上，通常为二元化，忽视了不同客户端多样且有时相互冲突的公平需求。这种有限的视角可能会限制公平干预措施对不同客户端的有效性。为了支持在联邦学习中更稳健和可重复的公平性研究，作者旨在为公平性感知的联邦学习方法在客户端和全局级别提供一致的基准测试工具。
### Innovation
引入了FeDa4Fair库，生成了针对异质客户端偏见评估公平性联邦学习方法的定制化表格数据集；发布了四个异质偏差数据集及其基准测试，可以在受控环境中比较公平性缓解方法；提供了评估这些数据集公平性结果的现成函数。
### Conclusion
作者通过FeDa4Fair库、数据集和评估工具，旨在支持更稳健和可重复的联邦学习公平性研究。
## 521. `cs.LG` - 通过注意力引导的图学习实现可解释的层次概念推理 [PDF](https://arxiv.org/pdf/2506.21102), [HTML](https://arxiv.org/abs/2506.21102)
### Authors
David Debot,Pietro Barbiero,Gabriele Dominici,Giuseppe Marra
### Background
概念基于模型（CBMs）是一类通过解释预测中使用高层概念来提供的可解释性深度学习模型。这类模型首先预测概念，然后使用这些概念执行下游任务预测。然而，当前的CBMs只为最终任务预测提供可解释性，而概念预测本身通常通过黑盒神经网络完成。这限制了CBMs的完全透明性。因此，本文旨在提出一种新的CBM，即层次概念记忆推理（H-CMR），它不仅提供任务预测的可解释性，还能提供概念预测的可解释性。H-CMR利用学习到的有向无环图建模概念之间的关系，其中边代表逻辑规则，定义概念间的关系。通过神经注意力机制，在推理过程中选择这些规则的子集，然后以层次的方式应用来预测所有概念和最终任务。
### Innovation
提出了一种新的CBM，即层次概念记忆推理（H-CMR），它不仅提供任务预测的可解释性，还能提供概念预测的可解释性。通过一种基于图学习并引导注意力机制的方法，H-CMR利用一种学习到的有向无环图来建模概念之间的层次关系，并通过神经注意力机制在推理过程中选择和应用这些关系来预测所有概念和最终任务。实验结果表明，H-CMR在性能上与现有最先进的模型相当，同时能够提供强大的人类交互，通过干预概念和模型增强推理准确性和训练效率
### Conclusion
该文提出的H-CMR模型在实现高性能的同时，提高了概念和模型的可解释性，特别地，通过干预概念提高了推理准确性，而通过干预模型提高了训练数据效率，在背景知识丰富的训练场景下效果更佳。
## 522. `cs.LG` - Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection [PDF](https://arxiv.org/pdf/2506.21093), [HTML](https://arxiv.org/abs/2506.21093)
### Authors
Li Fan,Peng Wang,Jing Yang,Cong Shen
### Background
Transformers在无线通信问题中展现出了潜力，特别是通过上下文学习（ICL）的方式，模型可以通过提示适应新任务而不需要对模型进行更新。然而，现有的基于ICL的Transformer模型为了达到良好的性能，往往需要采用多层的深架构，导致了巨大的存储和计算成本。
### Innovation
提出了一种名为CHOOSE（CoT-enhanced shallow Transformer framework for wireless symbol detection）的新方法。通过在隐藏空间中引入自回归的潜推理步骤，CHOOSE方法显著提高了浅层模型（1-2层）的推理能力，而无需增加模型深度。这种设计使得轻量级的Transformer能够在资源受限的移动设备上实现性能与深层Transformer相当的效果。实验结果表明，该方法在轻量级Transformer上的性能超过了传统的浅层Transformer，并且在计算存储效率方面也达到了与深层Transformer相当的水平。
### Conclusion
CHOOSE代表了一种在计算资源有限的无线接收系统中实现基于Transformer算法的有希望的方向。
## 523. `cs.LG` - Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks [PDF](https://arxiv.org/pdf/2506.21129), [HTML](https://arxiv.org/abs/2506.21129)
### Authors
Deepak Kumar Panda,Adolfo Perrusquia,Weisi Guo
### Background
基于强化学习(Reinforcement Learning, RL)的政策在无人飞行器(UAV)导航等安全关键系统中易受到观察空间中的离分布攻击(out-of-distribution adversarial attacks)。这些攻击会引发分布变化，显著影响价值估计，导致不安全或次优决策。现有RL框架因此变得脆弱。因此，本文主要探讨如何设计抗脆弱的RL框架，使政策能够在受到攻击情况下依然保持稳定和高效。研究表明，传统RL、鲁棒RL基线在遭受PGD和GPS欺骗等攻击时表现较弱，而本文提出的抗脆弱机制在面临攻击时表现出显著的优越性。
### Innovation
本文提出了一个基于 Curriculum-Guided 的抗脆弱RL框架，该框架可以通过模拟攻击者来自适应对抗逐步增强的观测空间攻击扰动，从而提高通用性和对未知攻击的预见能力。该框架通过 Wasserstein 距离最小化和迭代专家指导的评价者校准，来稳定价值函数的分布变化，防止遗忘现象的发生，从而增强了鲁棒性和抗脆弱性。实验证明，相比于传统和鲁棒RL基线能够在遭受攻击情况下始终表现更好，显著提高了累积奖励和减少了冲突事件。
### Conclusion
本文通过引入 Curriculum-Guided 抗脆弱RL框架，能够有效应对复杂和动态的威胁环境，为无人机避障等安全关键系统提供了更为可靠的决策机制。研究还通过实际场景验证了抗脆弱强化学习的可行性和有效性，表明这种方法能够显著提升系统的安全性和鲁棒性。
## 524. `cs.LG` - 对抗环境条件下UAV去冲突的鲁棒性策略切换用于抗脆化强化学习 [PDF](https://arxiv.org/pdf/2506.21127), [HTML](https://arxiv.org/abs/2506.21127)
### Authors
Deepak Kumar Panda,Weisi Guo
### Background
无人航天器（UAV）的导航自动化增加了它们受到对手攻击的风险，这些攻击利用强化学习（RL）中的漏洞通过传感器操纵进行。尽管现有的一些鲁棒RL方法试图减轻这些威胁，但在处理远离最佳价值分布的变化时其有效性仍然有限。这是因为当前方法主要针对固定干扰设计，未能有效应对更广泛的变化分布。因此，需要一个能够增强不确定分布变化适应性的新方法，以提高鲁棒性和防脆弱性。
### Innovation
本文提出了一种抗脆化RL框架，通过引入基于折扣汤普森抽样（DTS）的切换机制增强了对更广泛分布变化的适应性。该机制通过在多个鲁棒策略之间动态切换，最小化由对手诱导的状态-动作值分布变化。首先，通过考虑策略空间中的各种干扰生成一个多样化的动作鲁棒策略集合；然后，将其建模为多臂老虎机（MAB）问题，DTS在此适应于非平稳伯努利奖励，有效调整对抗策略的变化。理论框架显示，通过优化DTS以最小化总体因分布变化带来的遗憾，从而实现了对未知对抗攻击的有效适应，增强了系统的抗脆性。
### Conclusion
通过广泛的数值模拟，验证了提出的抗脆化策略切换方法在多动态三维障碍物的复杂导航环境中优于传统非适应性鲁棒RL方法。该方法在导航路径长度和无冲突导航轨迹频率方面表现出更优的性能，证明了其在复杂对抗环境下的强大适应性和鲁棒性。
## 525. `cs.LG` - 学习跳过Transformer中间层 [PDF](https://arxiv.org/pdf/2506.21103), [HTML](https://arxiv.org/abs/2506.21103)
### Authors
Tim Lawson,Laurence Aitchison
### Background
条件计算是使Transformer模型更高效的常用策略。现有方法大多针对单一模块（例如，专家层）进行裁剪，或者独立地跳过层。然而，可解释性研究表明，Transformer的中间层显示出更大的冗余性，而早期层则将信息整合到标记位置。基于这些见解，本文提出了一个新颖的架构，可以动态跳过从中间到外部的可变数量层。特别地，学习门控机制根据输入决定是否绕过中心块对称区间，并带有门控注意力机制以防止后续标记继续关注跳过的标记位置。通过'三明治'或'逐层归一化'方案控制残差正则化，并通过自适应正则化损失来调节门控稀疏度。目标是减少‘简单’标记的计算要求，并促进出现多级表示层次结构，但在调查的范围内，我们的方法并未在验证交叉熵与估算FLOPs之间的权衡中超过具有较少层的密集基线模型的表现。
### Innovation
本文提出了一种新颖的架构，动态跳过从中间到外部的一段标记位置。关键在于引入了学习门控机制和门控注意力机制来确定跳过的范围和防止后续标记继续关注被跳过的标记位置，通过'三明治'或'逐层归一化'方案控制残差正则化，并通过自适应正则化损失来调节门控稀疏度。
### Conclusion
尽管我们的方法有减少计算量和潜在促进多级表示层次结构的优势，但在所研究的实验规模中，并未能在验证交叉熵与估算FLOPs之间的权衡中优于具有较少层的密集基线模型。代码已公开。
## 526. `cs.LG` - NaLaFormer: Norm-Aware Linear Attention for Transformer Models [PDF](https://arxiv.org/pdf/2506.21137), [HTML](https://arxiv.org/abs/2506.21137)
### Authors
Weikang Meng,Yadan Luo,Liangyu Huo,Yaowei Wang,Xin Li,Zheng Zhang
### Background
线性注意力已经作为一种替代softmax注意力的有效方法出现，通过将复杂度从序列长度的二次降低到线性。当前的工作通过使用$L1$归一化以及线性可分核函数来保留softmax的两个基本特性：非负性和熵降低。然而，线性注意力中的规范化操作忽略了查询向量的范数，这导致了熵差距。同时，现有工作抑制了查询和键向量的负值，导致在映射后缺少内积交互。
### Innovation
提出了一种新的Norm-Aware Linear Attention机制，旨在恢复基于范数的动态尖峰性和恢复核影响的范数分布。具体而言，通过将查询和键矩阵分解为范数和方向两个组件，实现了范数感知的尖峰性控制和范数一致性。此外，通过采用保持范数的映射将角度矩阵的所有元素投影为正值，使用余弦相似性来抑制方向相反的维度。
### Conclusion
广泛的实验表明，NaLaFormer在视觉和语言任务上改善了性能，提高了表达能力和效率，最高可达4.2%。
## 527. `cs.LG` - Unlasting：基于双条件扩散隐桥的未配对单细胞多扰动估计 [PDF](https://arxiv.org/pdf/2506.21107), [HTML](https://arxiv.org/abs/2506.21107)
### Authors
Changxi Chi,Jun Xia,Yufei Huang,Jingbo Zhou,Siyuan Li,Yunfan Liu,Chang Yu,Stan Z. Li
### Background
单细胞测序可以揭示细胞在不同扰动条件下的响应，有助于识别关键基因并增强药物筛选，从而显著提高实验效率。然而，单细胞测序是一个破坏性过程，无法在扰乱前后捕捉同一细胞的表型，因此来自扰乱和未扰乱条件的数据是固有的不配对的。现有方法要么使用随机抽样强行配对未配对数据，要么在建模过程中忽略未扰乱和扰乱细胞之间的固有关系。目前缺乏有效处理未配对数据的解决方案，这一直是一个挑战。现有方法基于随机采样强行配对数据，或者在建模过程中忽略了未扰乱和扰乱细胞之间的固有关系，这使得现有方法在处理未配对数据时存在局限性。
### Innovation
本文提出了一种基于双条件扩散隐桥（DDIB）的框架来学习不同数据分布之间的映射，有效解决了未配对数据的挑战。该框架还被解释为数据增强的形式。作者将基因调控网络信息整合到其中，以便在生物学上有意义地传播扰动信号，并进一步引入了掩码机制来预测沉默基因，从而提高生成配置文件的质量。同时，针对同一扰动下基因表达在细胞间通常表现出显著差异，常常呈现出双峰分布这一现象，引入了更适合的评价指标。此外，提出Unlasting，一种双条件扩散模型，克服了单细胞扰动数据未配对的问题，并在基因调控网络的指导下增强了模型对扰动的理解，特别设计了掩码模型来通过预测沉默基因提高生成质量。还引入了一种基于生物学的评估指标，更好地反映了单细胞响应中的固有异质性。
### Conclusion
本文提出了一种新的双条件扩散隐桥框架Unlasting，有效解决了未配对单细胞多扰动数据的挑战。通过整合基因调控网络信息，引入更适合的评价指标，并利用掩码机制等手段，该框架显著提高了生成配置文件的质量，从而增强了对扰动的认识。这一方法不仅在理论上有所创新，还在实践中展示了提高实验效率和准确性的潜力。
## 528. `cs.LG` - 通过双提示优化和跨融合的个性化联邦学习 [PDF](https://arxiv.org/pdf/2506.21144), [HTML](https://arxiv.org/abs/2506.21144)
### Authors
Yuguang Zhang,Kuangpu Guo,Zhihe Lu,Yunbo Wang,Jian Liang
### Background
联邦学习（FL）能够实现跨去中心化客户端的模型训练，而不共享本地数据，但在数据、计算和通信方面的差异性带来挑战。现有的联邦提示学习方法仅依赖文本提示，忽视了标签领域分布转移的问题。介绍了已经存在的方法面对的背景和挑战。
### Innovation
提出了一种基于双提示学习和交叉融合的个性化联邦学习框架（pFedDC），每个客户端维护跨视觉和语言模态的全局和局部提示：全局提示捕获联合联邦中的共亨知识，而局部提示编码客户端特定的语义和领域特性。同时，设计了一个交叉融合模块以适应性地整合不同层次的提示，使得模型能够生成与各个客户端独特数据分布相匹配的个性化表示。该方法在九个具有不同类型的异质性数据集上进行了大量的实验，结果表明pFedDC在各种情况下均优于现有方法。
### Conclusion
pFedDC框架在各种异质性数据集上的广泛实验表明，它在个性化联邦学习中表现优于最新方法，为解决异质性带来的挑战提供了一个有前景的解决方案。
## 529. `cs.LG` - DBConformer: 双分支卷积转换器用于EEG解码 [PDF](https://arxiv.org/pdf/2506.21140), [HTML](https://arxiv.org/abs/2506.21140)
### Authors
Ziwei Wang,Hongbin Wang,Tianwang Jia,Xingyi He,Siyang Li,Dongrui Wu
### Background
基于脑电图（EEG）的脑-机接口（BCI）能够将自发或诱发的神经活动转化为外部通讯的控制命令。尽管卷积神经网络（CNN）是目前EEG解码的主流架构，其固有的短期感受野使得难以捕捉长期时序依赖和跨通道关系。近年来，CNN-Transformer（如Conformers的混合模型）部分解决了这一问题，但大多数采取串行设计，导致局部和全局特征的整合效果不佳，并且常常忽略了通道间的显式建模。
### Innovation
本文提出DBConformer，一种针对EEG解码的双分支卷积转换器网络。该模型整合了时间Conformer来建模长期时序依赖，并且空间Conformer来提取跨通道交互，实现对EEG信号中时序动态和空间模式的同时捕捉。轻量化的通道注意力模块进一步细化了空间表示，赋予了EEG通道数据驱动的重要性。在五个运动想象（MI）数据集和两个癫痫检测数据集下，三种评估设置中，DBConformer在所有10个基线模型中表现出显著优越性，并且参数量比高性能的EEG Conformer基线少得多。此外，通过可视化结果可以验证DBConformer提取的特征具有生理可解释性和与运动想象先验一致的特性。
### Conclusion
实验结果表明DBConformer在稳健性和可解释性方面表现出优越性能，使得它成为可靠的EEG解码工具。代码已公开发布。
## 530. `cs.LG` - 在强化学习中进行高效化学探索的多样化迷你批选择 [PDF](https://arxiv.org/pdf/2506.21158), [HTML](https://arxiv.org/abs/2506.21158)
### Authors
Hampus Gummesson Svensson,Ola Engkvist,Jon Paul Janet,Christian Tyrchan,Morteza Haghir Chehreghani
### Background
在许多实际应用中，评估实例的质量往往是昂贵且耗时的，例如人类反馈和物理模拟，相比之下，生成新实例要容易得多。特别是在强化学习中，为了获得奖励信号来进行学习，与环境新的交互（即新实例）的评估尤为重要。充分的探索至关重要，从多样性的迷你批中学习可以产生重大影响并有助于缓解模式崩溃。
### Innovation
本文引入了强化学习中的多样化迷你批选择，并提出使用决定性点过程来执行此任务。我们在药物发现这一实际问题的背景下研究了这一框架，实验研究了该框架如何改进从头开始的药物设计中化学探索的有效性，其中发现多样性和高质量解决方案至关重要。我们使用了三个成熟的分子生成或acles进行了全面评估。实验结果表明，我们的多样化迷你批选择框架能够显著提高解决方案的多样性，同时保持高质量的解决方案。在药物发现中，这种结果可能会更快地满足未满足的药物需求。
### Conclusion
我们的多样化迷你批选择框架能够显著提高解决方案的多样性，同时保持高质量的解决方案。在药物发现中，这可能会更快地满足未满足的药物需求。
## 531. `cs.LG` - 零样本学习在库存风险预测中的应用 [PDF](https://arxiv.org/pdf/2506.21240), [HTML](https://arxiv.org/abs/2506.21240)
### Authors
Elie Saad,Aya Mrabah,Mariem Besbes,Marc Zolghadri,Victor Czmil,Claude Baron,Vincent Bourgeois
### Background
电子组件的过时给依赖电子组件的行业带来了重大挑战，这些挑战导致了成本增加和系统安全与可用性的中断。准确预测过时风险至关重要，但数据的可靠性和稀缺性限制了这一目标的实现。
### Innovation
本文提出了一种利用大型语言模型（LLMs）零样本学习（ZSL）的新方法，克服了数据稀缺的问题，通过利用结构化数据集中的领域特定知识进行过时风险预测。该方法在两个真实世界的数据集上进行了测试，并展示了有效的风险预测性能。
### Conclusion
通过对比四种LLM，强调了选择适合特定预测任务的模型的重要性。
## 532. `cs.LG` - 基于线性性的神经网络压缩 [PDF](https://arxiv.org/pdf/2506.21146), [HTML](https://arxiv.org/abs/2506.21146)
### Authors
Silas Dobler,Florian Lemmerich
### Background
当前的神经网络压缩方法主要通过评估参数的重要性与冗余性来减少不必要的参数。已有方法在高度优化的现有解决方案上进一步扩展，以减少权重量化神经网络，但缺乏新的压缩机制。希望提出一种新的方法来改进现有的压缩技术，使其能够更高效地减少神经网络的参数量，同时保持原有的模型效果和效率。
### Innovation
提出了一种基于线性的压缩方法，通过原理上认为的具有ReLU激活函数的神经元通常表现为线性关系，可以合并后续层，来实现更有效的压缩。这种方法提供了一种新的压缩机制，可以减少大部分测试模型大小的1/4，同时也表明了与其他基于重要性修剪方法相结合的潜力，显示出这些技术的可合并性。
### Conclusion
这项工作为新的压缩方法奠定了基础，这种新的压缩方法能够使神经网络模型更小且更有效。通过实验验证了该方法的有效性，实现了无损压缩，并且在与基于重要性的修剪模型结合时表现出了非常小的干扰，进一步证明了它们的可合并性。
## 533. `cs.LG` - DiLoCoX: 分布式簇中低通信大规模训练框架 [PDF](https://arxiv.org/pdf/2506.21263), [HTML](https://arxiv.org/abs/2506.21263)
### Authors
Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich
### Background
在构建语言模型等大型基础模型时，分布式训练需要高效的数据通信，通常依赖于中央管理的高速网络。然而，部署大规模分布式训练时遇到的一个挑战是在慢速网络环境下实现有效的训练。本文探讨了在慢速网络环境下进行大规模分布式训练的可能性，并提出了一种新的框架DiLoCoX，旨在提高大规模模型的预训练速度和效率，尤其是在慢速网络环境下。
### Innovation
DiLoCoX框架结合了管道并行、双重优化策略、一跳延迟重叠通信与本地训练以及自适应梯度压缩方案。这种组合显著提升了大规模参数训练的模型预训练速度。通过理论分析了其收敛性，并通过实验验证了相比于传统的AllReduce方法，其在分布式训练中的显著加速效果，且不影响模型收敛。
### Conclusion
DiLoCoX能够成功地在1Gbps的慢速网络环境下预训练一个超过107B参数的基础模型，相比Vanilla AllReduce方法，其分布式训练速度提高357倍，同时模型的收敛性几乎不受影响。据我们所知，这是首次成功应用于超过100亿参数的模型的分布式训练框架。
## 534. `cs.LG` - 复杂性感知调优 [PDF](https://arxiv.org/pdf/2506.21220), [HTML](https://arxiv.org/abs/2506.21220)
### Authors
Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev
### Background
通用大型语言模型（LLMs）通常通过监督微调（SFT）在特定领域进行微调以提升性能。虽然通过蒸馏较大的模型的推理过程可以实现更好的结果，但这种方法会增加昂贵的调用次数和大量的数据需求。本文背景在于探索一种更高效的微调方法，该方法通过识别复杂数据并通过熵分析，在保持计算和数据经济性的同时，提升模型性能。具体地，研究通过对两个小型开源模型（约3B参数）训练数据进行复杂性分类（单个标记答案熵分类，ROC AUC为0.73），然后进行SFT和蒸馏微调，结果显示该方法显著优于标准SFT方法（平均准确率为0.55 vs 0.43），同时使用62%更少的数据量（两种方法平均准确率为0.55）
### Innovation
本文提出了一种新的高效微调蓝图，该方法仅对通过熵分析标识的复杂数据进行推理，并以更少的数据量实现了与蒸馏性能相当的微调效果。具体而言，方法通过对小型开源模型（约3B参数）的训练数据进行复杂性分类，分批次进行微调和蒸馏，进而提升了整体性能，强调了复杂性感知在调优过程中的重要性
### Conclusion
该研究提供了一种新的微调方法，通过复杂性分类策略，使用较少的数据量实现了与传统蒸馏方法相当的性能，并显著优于标准SFT方法，这为后续研究提供了新的方向。研究者还发布了代码和数据以促进进一步的研究探索
## 535. `cs.LG` - 人工代理人解决部分参与下永续投票的公平性问题 [PDF](https://arxiv.org/pdf/2506.21186), [HTML](https://arxiv.org/abs/2506.21186)
### Authors
Apurva Shah,Axel Abels,Ann Nowé,Tom Lenaerts
### Background
永续投票旨在通过时间上的代表性公正来解决序列集体决策中的公平性问题。现有的永续投票规则假设所有参与者都参与并且提供了完整的同意信息，而在实践中，这些假设极少成立，因为缺席的情况是常态。因此，本文探讨了将'人工代理'——偏好学习代理，用于代表缺席选民——整合到永续投票系统中的方法。我们分析了缺席如何影响不同投票方法下的公平性及代表性，并评估了人工代理在弥补缺席参与上的有效性。研究发现，尽管缺席对公平性有显著影响，但人工代理能够可靠地缓解这些问题并增强系统在不同情境下的鲁棒性。
### Innovation
本文的研究创新在于提出了将人工代理应用于永续投票系统中，以解决因部分参与导致的公平性和代表性问题。这些人工代理能够代表缺席的投票者，并有助于减轻因缺席对决策过程带来的直接影响。这种方法为解决集体决策中出现的代表公平性问题提供了一种新的解决方案。
### Conclusion
缺席对永续投票系统的公平性和代表性造成了重大影响，但通过引入人工代理，这些影响可以得到可靠缓解。这种方法不仅增强了系统的鲁棒性，使其能够在多种场景下保持决策的公正性和代表公平性，还为处理实际中频繁出现的缺席情况提供了一种有效的策略。
## 536. `cs.LG` - Latent Prototype Routing: 实现Mixture-of-Experts中的近乎完美负载均衡 [PDF](https://arxiv.org/pdf/2506.21328), [HTML](https://arxiv.org/abs/2506.21328)
### Authors
Jiajie Yang
### Background
Mixture-of-Experts (MoE) 架构已成为高效扩展大型语言模型 (LLMs) 的关键策略。然而，现有的 MoE 系统存在严重的负载不平衡问题，导致只有小部分专家在训练和推理过程中被激活，从而大量地削减了模型能力和计算资源的使用效率。
### Innovation
本文以聚类视角重新审视专家路由问题，并提出了一个新颖的路由框架——潜在原型路由 (LPR)，它既能推广现有方法，又能促进专家负载的均衡分配，而不会影响下游性能。实验结果表明，LPR 可以将专家负载的 Gini 系数从 0.70 降低到 0.035，将最小最大专家负载比例从 1e-6 提高到 0.70，从而实现近乎完美的负载均衡。
### Conclusion
通过对多个开源 MoE 模型（包括 DeepSeek-V3、Qwen3-MoE 和 Mixtral）进行广泛的实验，验证了 LPR 的有效性，证明了它在实现高效负载均衡方面的潜力。
## 537. `cs.LG` - DynamicBench: 评估大语言模型实时报告生成 [PDF](https://arxiv.org/pdf/2506.21343), [HTML](https://arxiv.org/abs/2506.21343)
### Authors
Jingyao Li,Hao Sun,Zile Qiao,Yong Jiang,Pengjun Xie,Fei Huang,Hong Xu,Jiaya Jia
### Background
传统的大语言模型基准通常依赖于静态的讲故事或表达意见的评估方式，这种方式未能捕捉到当前应用中实时信息处理的动态需求。DynamicBench 提出旨在评估大语言模型在存储和处理最新数据方面的专业能力的基准测试。该基准测试利用了网页搜索与本地报告数据库的双重检索管道，确保在专业领域内生成准确的响应报告，并通过提供或不提供外部文档的测试场景，有效衡量其处理最新信息的能力或利用上下文增强信息的能力.
### Innovation
DynamicBench 引入了一种先进的报告生成系统，能够管理动态信息的综合。通过实验结果的验证，这种方法在文档自由和文档辅助的场景下分别比 GPT4o 表现优异 7.0% 和 5.8%，并且代码和数据将被公开.
### Conclusion
DynamicBench 是一个评估大语言模型实时报告生成能力的基准测试。通过使用双重检索管道，它有效地衡量了模型在存储和处理最新数据方面的专业能力。实验结果表明，这种方法在各种场景下都优于现有方法，并且代码和数据将被公开供研究人员进一步研究.
## 538. `cs.LG` - 基于生成对抗网络的无人机制导和出界检测方法 [PDF](https://arxiv.org/pdf/2506.21142), [HTML](https://arxiv.org/abs/2506.21142)
### Authors
Deepak Kumar Panda,Weisi Guo
### Background
随着无人机进入民用空域，需要构建具有恢复能力和智能性的入侵检测系统（IDS），以解决传统异常检测方法难以识别新型威胁的问题。常使用的未知攻击方法将其视为分布外（OOD）样本，但这种方法在应对不充分的缓解措施时存在漏洞，并且难以区分隐蔽的对抗攻击和真正的分布外事件。因此，迫切需要一种方法来构造能够规避IDS机制的隐蔽对抗样本，并能检测这些篡改。
### Innovation
本文提出了一种基于条件生成对抗网络（cGAN）的框架，旨在生成能够规避IDS机制的隐蔽对抗样本。本文设计了一个鲁棒的多类IDS分类器，该分类器基于正常无人机制动数据和已知的网络攻击（如拒绝服务攻击、虚假数据注入、中间人攻击和回放攻击）进行训练。采用该分类器，cGAN扰动已知攻击以生成伪装成正常但与OOD分布保持统计相似性的对抗样本。经过迭代优化，这些对抗样本可实现高隐蔽性和成功率。为了检测这些篡改，本文实现了一个条件变分自编码器（CVAE），利用负对数似然来区分对抗输入和真正的OOD样本。实验结果显示，基于CVAE的遗憾分数显著优于传统基于马氏距离的检测器，能够识别隐蔽的对抗威胁。
### Conclusion
本文强调了强化基于高级概率建模的IDS能力，以应对适应性、生成模型为基础的网络入侵行为的重要性。
## 539. `cs.LG` - 改进的k-means和k-GMM的初始化策略 [PDF](https://arxiv.org/pdf/2506.21291), [HTML](https://arxiv.org/abs/2506.21291)
### Authors
Guillaume Carrière,Frédéric Cazals
### Background
论文回顾了用于k-means聚类和k-GMM（使用期望最大化法拟合高斯混合模型）的随机种子技术。详细规范了种子采样的距离度量、候选种子数量和种子选择的度量这三种核心技术元素。
### Innovation
论文提出了利用前瞻原则的一系列初始化方法（在种子选择时考虑到最终距离度量的要求），并采用了多轮策略来减少随机化的影响。实验表明，与传统方法相比，在最终指标（k-means的SSE，k-GMM的对数似然值）上拥有持续不变的常数因子改进，且只需要适度的计算开销。尤其是对k-means，这些方法改进了最近设计的多交换策略，这是首次超越贪婪的k-means++初始化方法。实验分析还揭示了k-means的一些微妙特性，如种子初始化与最终SSE之间的相关性缺乏、迭代种子方法中观察到的方差减少现象，以及贪婪方法中最终SSE对候选池大小的敏感性。
### Conclusion
实践中，我们的最有效种子方法可能是成为标准技术的强大候选者。从理论角度来看，我们的种子技术的规范化为新的分析方法打开了大门。
## 540. `cs.LG` - AGTCNet：一种用于原则性运动意念EEG分类的图-时间方法 [PDF](https://arxiv.org/pdf/2506.21338), [HTML](https://arxiv.org/abs/2506.21338)
### Authors
Galvin Brice S. Lim,Brian Godwin S. Lim,Argel A. Bandala,John Anthony C. Jose,Timothy Scott C. Chu,Edwin Sybingco
### Background
脑机接口（BCI）技术通过脑电图（EEG）实现对神经活动的利用，为运动受损者提供了与环境互动的机会，但其稳健性的开发仍然面临挑战。由于个体间和时间上神经活动的复杂性和变异性，以及EEG硬件的限制，现有BCI系统无法有效捕捉多通道EEG信号中的时空依赖性。
### Innovation
本文提出了注意力图-时间卷积网络（AGTCNet）作为新的图-时间模型来解决上述问题。AGTCNet利用了EEG电极的空间配置作为一种诱导偏差，并将图卷积注意力网络（GCAT）引入以共同学习表现性的时空EEG表示。实验证明，AGTCNet在多个数据集上均表现出优于现有最优方法的性能，且模型大小更紧凑、推理速度更快，显示了其在BCI部署中的有效性与实用性。
### Conclusion
AGTCNet在BCI Competition IV Dataset 2a的跨受试评估中取得了66.82%的平均准确率，并通过对特定受试者的微调，在该数据集上达到了82.88%的准确率。在EEG Motor Movement/Imagery Dataset中，AGTCNet的跨受试分类的4类和2类别别达到64.14%和85.22%的准确率，通过特定受试者的微调，准确率分别提高到72.13%和90.54%。
## 541. `cs.LG` - 关注小型参数 [PDF](https://arxiv.org/pdf/2506.21374), [HTML](https://arxiv.org/abs/2506.21374)
### Authors
Chao Zhou,Tom Jacobs,Advait Gadhikar,Rebekka Burkholz
### Background
微调大型预训练神经网络在资源消耗上是密集的，涉及内存和计算成本。为了缓解这个问题，一种常见的方法是限制训练参数的数量，即只对模型的一部分参数进行训练。通过分析微调期间梯度与权重的关系，发现一个显著的模式：大型梯度通常与小型量级的权重相关联。这种相关性在微调设置中比从零开始训练更加明显。
### Innovation
激励于上述观察，本文提出了NANOADAM，其在微调过程中仅动态更新小型量级的权重。NANOADAM有几个实际优势：首先，这是一个无梯度的方法——参数子集可以在不进行梯度计算的情况下确定；其次，它保持了大型量级的权重，这些权重很可能是从预训练中学习到的关键特征，从而减少了灾难性遗忘的风险；最后，它使得可以使用更大的学习率，并且在实验中表现出更佳的泛化性能。这种方法在自然语言处理和视觉任务中得到了验证。
### Conclusion
本文提出的方法NANOADAM在微调设置中仅动态更新小型量级的权重，相比于从零开始训练，这种方法表现出更佳的泛化性能。
## 542. `cs.LG` - 在插入单个简单形情况下创建持久拉普拉斯特征值的Lipschitz边界 [PDF](https://arxiv.org/pdf/2506.21352), [HTML](https://arxiv.org/abs/2506.21352)
### Authors
Le Vu Anh,Mehmet Dik,Nguyen Viet Anh
### Background
持久拉普拉斯是矩阵算子，用于跟踪数据在不同尺度下形状和结构的变化，广泛应用于生物学、物理学和机器学习。这些算子的特征值是描述滤波过程中几何和拓扑特征的简洁描述符。早期研究已经证明了这些算子的整体代数稳定性，但在添加一个单形（例如顶点、边或三角形）后，单个特征值的确切变化情况一直是个未知数。这在下游工具（如热核签名和谱神经网络）直接依赖这些特征值的情况下非常重要。
### Innovation
本文通过证明一个统一的Lipschitz界限解决了这一问题：在插入一个单形后，每个上持久拉普拉斯特征值的变化幅度最多为该单形边界的欧几里得范数的两倍，且与滤波尺度和复杂性无关，从而首次为谱拓扑数据分析提供了特征值水平的鲁棒性保证。这保证了在局部更新情况下谱特征的稳定性，并在动态数据环境下提供可靠的误差控制能力。
### Conclusion
总之，文章通过提供一个统一的Lipschitz界限，解决了始终存在的单形插入后特征值变化的未知问题，为谱拓扑数据分析提供了前所未有的特征值水平的稳定性保证，确保了在局部更新下谱特征的稳定性，并在动态数据环境中的误差控制中建立了可靠的保证。
## 543. `cs.LG` - 早期停止表格上下文学习 [PDF](https://arxiv.org/pdf/2506.21387), [HTML](https://arxiv.org/abs/2506.21387)
### Authors
Jaris Küken,Lennart Purucker,Frank Hutter
### Background
表格基础模型通过上下文学习在各种表格学习任务中表现出强大的性能，能够在不进行下游调优的情况下提供稳健的泛化能力，但其推理时间成本仍然很高，尤其是对于较大的数据集。
### Innovation
提出了在每次Transformer编码器层后动态评估是否停止上下文学习，一旦停止，使用预训练的逐层解码器解码嵌入。在34个小型分类任务中，加速推理最多可达1.3倍，对预测性能的负面影响可以忽略不计。进一步在五个更大的分类任务中进行评估，实现了最多2.2倍的加速。
### Conclusion
结果表明，早期退出是一种有效且实用的策略，可以提高表格上下文学习的效率。
## 544. `cs.LG` - rQdia：利用图像增强正则化Q值分布 [PDF](https://arxiv.org/pdf/2506.21367), [HTML](https://arxiv.org/abs/2506.21367)
### Authors
Sam Lerman,Jing Bi
### Background
在基于像素的深度强化学习中，连续控制任务和Atari游戏环境中的数据效率和学习表现仍然是挑战。现有方法如DrQ和SAC在MuJoCo连续控制套件中使用像素输入时表现不佳，而Data-Efficient Rainbow在Atari环境中也需改进。背景强调了现有的方法在处理像素输入时的局限性，特别是在样本效率和长期训练稳定性方面。
### Innovation
提出了rQdia，这是一种通过引入一个简单的辅助损失项来利用图像变换均衡Q值分布的方法。该方法通过对增强图像应用MSE损失来正则化Q值分布，从而提升了基于像素输入的模型，如DrQ和SAC在MuJoCo连续控制任务上的表现，以及Data-Efficient Rainbow在Atari环境中的表现。rQdia在样本效率和长期训练的稳定性方面取得了显著提升，特别是在连续控制领域，该方法最终将无模型的连续控制算法从像素输入超越了状态编码基线。
### Conclusion
研究展示了rQdia在多个任务和环境中（包括MuJoCo连续控制和Atari游戏）的广泛适用性和有效性。rQdia不仅提升了数据效率，还增强了算法在长期训练中的稳定性，标志着在无模型连续控制从像素输入学习方面的显著进步。
## 545. `cs.LG` - 加密货币交易欺诈检测中的时间aware图注意力网络 [PDF](https://arxiv.org/pdf/2506.21382), [HTML](https://arxiv.org/abs/2506.21382)
### Authors
Zhi Zheng,Bochuan Zhou,Yuping Song
### Background
加密货币交易欺诈检测面临着日益复杂的交易模式和严重的类别不平衡的双重挑战。传统方法依赖于手动特征工程，难以捕捉交易网络中的时间与结构依赖性。
### Innovation
本文提出了一种增强时间aware的图注意力网络（ATGAT），通过三个模块提升检测性能：(1) 一种高级的时间嵌入模块，结合了多尺度时间差特征和周期位置编码；(2) 一种时间aware的三重注意机制，同时优化结构、时间和全局上下文注意；(3) 采用加权的二元交叉熵损失以解决类别不平衡问题。
### Conclusion
实验结果表明，ATGAT在Elliptic++加密货币数据集上取得了0.9130的AUC值，比最佳传统方法XGBoost提高9.2%，比GCN提高12.0%，比标准的GAT提高10.0%。该方法不仅验证了时间aware和三重注意机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则适用于其他时间图异常检测任务。
## 546. `cs.LG` - ScalaBLE：使用随机变分子空间推断的大规模语言模型可扩展贝叶斯低秩适应 [PDF](https://arxiv.org/pdf/2506.21408), [HTML](https://arxiv.org/abs/2506.21408)
### Authors
Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha
### Background
尽管大型语言模型（LLMs）在各个领域中得到广泛应用，但它们往往会出现生成错误信息的情况，并且不能很好地进行校准。这使得这些模型的不确定性量化变得尤为重要，尤其是在自主性和医疗健康等人身安全相关的高风险领域。之前的研究通过针对微调模型的低秩适应（LoRA）参数进行贝叶斯深度学习，使得不确定性量化问题变得更加可处理。虽然这些方法在实际应用中效果很好，但由于需要额外的参数，它们难以扩展到更大的LLMs中。鉴于此，本文提出了ScalaBL，即通过随机变分子空间推断进行大规模语言模型的可扩展贝叶斯低秩适应。
### Innovation
ScalaBL在LoRA参数所表示的子空间中进行贝叶斯推断，通过将LoRA参数重新用于投影矩阵，可以将子空间中的样本映射到LLM的全权重空间。因此，ScalaBL可以在保持较低维度的同时实现与现有最佳方法相当的性能，且仅需约1000个额外参数。此外，ScalaBL还使得我们能够扩展到目前最大的贝叶斯LLM，其基参数数量是之前工作的四倍。
### Conclusion
ScalaBL方法通过对参数空间的重新利用，使得大规模语言模型的贝叶斯不确定性量化更加高效和可扩展。通过在低秩子空间中进行贝叶斯推理，并使用随机变分推断法，ScalaBL不仅能够维持较小的额外参数需求，还能够处理更大的模型。
## 547. `cs.LG` - 基于关键词技术的宽泛问题答案评估方法 [PDF](https://arxiv.org/pdf/2506.21461), [HTML](https://arxiv.org/abs/2506.21461)
### Authors
Tamim Al Mahmud,Md Gulzar Hussain,Sumaiya Kabir,Hasnain Ahmad,Mahmudus Sobhan
### Background
评估是通过各种技术评估和确定教育系统的一种方法，包括口头或口试、主观或客观的书面测试。本文提出了一个高效的方法来电子地评估主观答案脚本。该系统从答案脚本中提取关键词，并将其与从公开和封闭领域解析的关键词进行比较，还检查答案脚本中的语法和拼写错误
### Innovation
提出了一个综合系统，该系统可以从答案脚本中提取关键词，并将其与从公开和封闭领域解析的关键词进行比较。该系统也能够检查答案脚本中的语法和拼写错误，并通过100名学生答案脚本的测试，获得了91%的准确率
### Conclusion
该系统测试结果表明，它可以高效准确地自动评估主观答案脚本，为教育评估提供了新的可能性。
## 548. `cs.LG` - 基于流的单步完成对于高效且表达能力强的策略学习 [PDF](https://arxiv.org/pdf/2506.21427), [HTML](https://arxiv.org/abs/2506.21427)
### Authors
Prajwal Koirala,Cody Fleming
### Background
生成模型如扩散和流匹配方法为离线强化学习（RL）提供了富有表现力的策略，通过捕捉丰富的、多元模式的动作分布。然而，迭代采样引入了高昂的推理成本和训练不稳定性，原因是梯度在采样步骤之间进行传播。本文背景在于如何克服这些问题，提高策略学习的效率与灵活性，同时保持模型的表达能力与准确性。
### Innovation
提出了单步完成策略（SSCP），这是一种生成性策略，通过增强后的流匹配目标训练，能够直接从中间流样本预测完成向量，实现准确的一次性动作生成。在非策略演员-评论家框架下，SSCP结合了生成模型的表达性和单模态策略的训练与推理效率，无需进行长时间的反向传播链。此外，该研究进一步将SSCP扩展到目标导向的RL，允许扁平策略利用子目标结构，而无需显式的分层推理。
### Conclusion
SSCP在标准的离线RL和行为克隆基准测试中取得了优良的成绩，展示出其作为一种通用、表达能力强且高效的深度RL和序列决策框架的潜力，尤其在离线、离线转在线和在线RL设置中具有显著的速度和适应性优势，能够有效克服扩散模型的基本基准。
## 549. `cs.LG` - SMMILE: 专家驱动的多模态医学上下文学习基准 [PDF](https://arxiv.org/pdf/2506.21355), [HTML](https://arxiv.org/abs/2506.21355)
### Authors
Melanie Rieff,Maya Varma,Ossian Rabow,Subathra Adithan,Julie Kim,Ken Chang,Hannah Lee,Nidhi Rohatgi,Christian Bluethgen,Mohamed S. Muneer,Jean-Benoit Delbrouck,Michael Moor
### Background
尽管多模态上下文学习（ICL）在医学等领域具有巨大潜力，但其仍然未被充分探索。医学临床工作者在有限的例子下经常遇到多样化的专业任务，例如从几个相关的先前案例中得出见解，或者考虑一个受限的诊断集。现有的多模态大规模语言模型（MLLMs）已经在医学视觉问答（VQA）中展示了进展，但它们从上下文中学习多模态任务的能力尚未被充分了解。目前对于复杂的医学任务尚没有专门的多模态ICL基准。此外，现有模型在处理医学任务上下文学习时也表现出可归因的关键限制和偏差。
### Innovation
本文介绍了SMMILE，这是第一个由医学专家驱动的多模态ICL基准，用于医学任务。SMMILE基准包括111个问题（517个问题-图像-答案三元组），涵盖了6个医学专科和13种成像模态。此外，还提供了一个增强的版本SMMILE++，包含1038个排列的问题。研究结果表明大多数模型在医疗任务中的多模态ICL能力表现一般或较差，并揭示了在开放性评估中引入无关的上下文例子会显著降低模型性能。
### Conclusion
多模态ICL在医学任务中的应用存在显著的挑战和局限性，复杂且混乱的上下文例子可能导致模型表现下降。不同案例的先后顺序也影响模型表现，并且现有模型在从上下文学习时存在可避免的偏见。
## 550. `cs.LG` - 从最优控制视角看ResNet训练 [PDF](https://arxiv.org/pdf/2506.21453), [HTML](https://arxiv.org/abs/2506.21453)
### Authors
Jens Püttschneider,Simon Heilig,Asja Fischer,Timm Faulwasser
### Background
本文提出了一个反映最优控制问题的ResNets训练形式，适用于标准架构和通用损失函数。通过惩罚隐藏状态部分的中间输出，对应于最优控制中的阶段成本项，研究者试图在算法和理论框架之间建立联系。对于标准的ResNets，中间输出是通过后续的跳过连接和输出层传播状态获得的。实验表明，这种训练动态可以使不必要的深层残差层的权重趋向于消失，这表明有可能发展出一种理论指导下的层修剪策略。
### Innovation
本文提出的训练方法反映了最优控制问题，可以应用于标准的ResNets架构和各种损失函数。特别地，通过惩罚中间输出来对应最优控制中的阶段成本项，研究人员提供了一种新的理论视角来解释和优化ResNets的训练过程。这种方法揭示了深层不必要的残差层权重可以消失的可能性，从而为理论指导下的层修剪策略奠定了基础。
### Conclusion
研究表明，这种基于最优控制视角的ResNets训练方法可以有效地引导不必要的深层残差层的权重消失，这为层修剪提供了新的理论依据。虽然提出了一个有前景的方法，但如何在实际应用中更有效地实施这一策略以及如何进一步优化训练过程仍需进一步研究。
## 551. `cs.LG` - MAx-DNN: 多层次算术近似以实现能效高的DNN硬件加速器 [PDF](https://arxiv.org/pdf/2506.21371), [HTML](https://arxiv.org/abs/2506.21371)
### Authors
Vasileios Leon,Georgios Makris,Sotirios Xydis,Kiamal Pekmestzi,Dimitrios Soudris
### Background
现在，深度神经网络（DNN）架构的快速增长使其成为高级机器学习任务提供卓越准确性的默认方法。为了实现低能耗的DNN计算，本文探讨了DNN工作负荷的细粒度容错与其硬件近似技术的协作以提高能效。研究集中在ROUP近似乘法器上，根据层级、滤波器级和核级的方法，系统地研究其在DNN中的细粒度分布，并检查其对准确性和能耗的影响。使用ResNet-8模型在CIFAR-10数据集上评估我们的近似方法。所提出的解决方案在基线量化模型上提供高达54%的能耗节省，同时仅牺牲4%的准确率，并在能效和准确性方面优于现有的DNN近似方法。
### Innovation
本文提出了多层次算术近似（MAx-DNN）方法，以实现能效高的DNN硬件加速器。通过使用ROUP近似乘法器，并基于层级、滤波器级和核级的方法，系统地研究其在DNN中的分布，从而实现了能耗节省和准确性之间的权衡。
### Conclusion
所提出的MAx-DNN方法在ResNet-8模型上实现了最高54%的能耗节省和仅4%的准确率损失，该方法在能耗和准确性方面均优于现有DNN近似方法。
## 552. `cs.LG` - 分布式跨通道分层聚合在基础模型中的应用 [PDF](https://arxiv.org/pdf/2506.21411), [HTML](https://arxiv.org/abs/2506.21411)
### Authors
Aristeidis Tsaris,Isaac Lyngaas,John Lagregren,Mohamed Wahib,Larry York,Prasanna Balaprakash,Dan Lu,Feiyi Wang,Xiao Wang
### Background
基于视觉的科学基础模型具有推动科学发现和创新的重要潜力。这种潜力源于它们能够聚合来自不同来源的图像，如各种物理基台或数据采集系统的图像，并使用变压器架构学习时空相关性。然而，图像的分词和聚合可能需要大量的计算资源，当前的分布式方法未能充分解决这一问题。
### Innovation
本文提出了一种名为分布式跨通道分层聚合（D-CHAG）的方法，该方法适用于具有大量通道（跨图像模态）的大数据集。D-CHAG方法兼容任何模型并行策略和任何形式的视觉变压器架构，显著提高了计算效率。研究结果表明，该方法在前沿超级计算机上的AMD GPU上实现了高达75%的内存使用率降低和超过1,024个GPU超过两倍的持续吞吐量。
### Conclusion
我们的方法与张量并行性和模型切片相结合，在前沿超级计算机上的AMD GPU上实现了显著的内存使用率降低和吞吐量提升。
## 553. `cs.LG` - 为特伦甘纳邦癌症意识问题提供解决方案 [PDF](https://arxiv.org/pdf/2506.21500), [HTML](https://arxiv.org/abs/2506.21500)
### Authors
Priyanka Avhad,Vedanti Kshirsagar,Urvi Ranjan,Mahek Nakhua
### Background
2020年，特伦甘纳邦接受宫颈癌、乳腺癌和口腔癌筛查的女性比例分别为3.3%、0.3%和2.3%。尽管早期发现是减少发病率和死亡率的唯一途径，但人们对宫颈癌和乳腺癌的症状以及筛查方法的意识非常低。基于此背景，开发了一种机器学习分类模型，该模型可以根据人口统计因素预测一个人是否容易患上乳腺癌或宫颈癌。此外，还设计了一个系统，根据用户的地理位置或地址推荐最近的医院或癌症治疗中心，并可以整合健康卡以维护所有个体的医疗记录，并开展宣传和宣传活动。
### Innovation
开发了一种机器学习分类模型以预测个人是否易于感染乳腺癌或宫颈癌，并设计了一个系统，可以根据用户的地理位置推荐最近的医疗资源，整合健康卡以维护个人的医疗记录，并计划进行广泛的宣传和教育活动。具体地，使用了决策树分类和支持向量分类算法来预测宫颈癌和乳腺癌的易感性。
### Conclusion
通过这一解决方案，进一步提高了特伦甘纳邦癌症的意识，从而减少了癌症死亡率并增强了人们的癌症知识。
## 554. `cs.LG` - 在瑞典族群中使用多模态机器学习进行双人交流中的欺骗检测：一项研究 [PDF](https://arxiv.org/pdf/2506.21429), [HTML](https://arxiv.org/abs/2506.21429)
### Authors
Franco Rugolon,Thomas Jack Samuels,Stephan Hau,Lennart Högman
### Background
本文研究了使用多模态机器学习技术检测双人互动中的欺骗效果，主要关注欺骗者和受害者的双重数据集成。研究中使用了早期和晚期融合方法，结合了说话人的声音和看到人的面部数据，特别是在所有模态和参与者的各种组合中。数据集由瑞典本土人在具有情感相关主题的真实或虚假情景下收集而成。研究表明，同时考虑口头和面部信息比单一模态方法有更高的表现。此外，纳入参与者双方的数据显著提高了欺骗检测的准确性，使用晚期融合策略应用于双方的模态和参与者，效果最佳，达到71%。这些结果与心理学理论相吻合，这些理论认为在初始互动中面部和语音表达的控制有所不同。本研究是针对斯堪的纳维亚族群的首个此类研究，为未来对双人互动的研究，特别是心理治疗领域，奠定了基础。
### Innovation
本研究首次在斯堪的纳维亚族群中进行此类研究，比较了早期和晚期融合方法，首次同时分析说话人的声音和看到人的面部数据，并在此基础上进行了详尽的模态与参与者的所有可能组合分析，提出了通过晚期融合策略应用于多种模态和参与者以提高欺骗检测准确性的新方法
### Conclusion
研究表明，同时考虑说话人和看到人的口头及面部信息比单一模态方法有更高的欺骗检测性能。晚期融合策略应用于双方参与者，能更准确地检测欺骗行为，达到71%的最佳效果。这些结果与心理理论一致，指出在初始互动中面部和语音表达的控制不同。本研究为未来在心理治疗等设景中的双人互动研究奠定了基础。
## 555. `cs.LG` - The final solution of the Hitchhiker's problem #5 [PDF](https://arxiv.org/pdf/2506.20672), [HTML](https://arxiv.org/abs/2506.20672)
### Authors
Matjaž Omladič,Martin Vuk,Aljaž Zalar
### Background
近期，一篇名为“搭便车指南”的调研论文提升了一类称为拟 copula 的数学对象在依赖性建模社区的地位。尽管拟 copula 缺乏统计解释，但论文详细探讨了其相关问题。之前的研究中，作者利用线性规划方法解决了相关问题直到维度 d = 17，并反驳了一项关于此问题的近期猜想。
### Innovation
作者采用了分析方法提供了原始问题的完整解答，提出了新的见解和解决方法，特别是在解决高维拟 copula 的极端值问题上，提出了全新的研究角度和解决方案，为依赖性建模领域做出了贡献。
### Conclusion
通过使用的分析方法，作者为“搭便车指南”提出的问题 #5 提供了最终解答。这一成果不仅解决了之前的开放问题，还拓展了对拟 copula 的理解，并为依赖性建模提供了新的见解。
## 556. `cs.LG` - 优化第四阶龙格-库塔方法：一种提高效率和低存储动态启发式方法 [PDF](https://arxiv.org/pdf/2506.21465), [HTML](https://arxiv.org/abs/2506.21465)
### Authors
Gavin Lee Goodship,Luis Miralles-Pechuan,Stephen O'Sullivan
### Background
扩展稳定龙格-库塔（ESRK）方法在科学和工程中解决大规模计算问题至关重要，包括天气预报、气动力学分析和复杂的生物模型。然而，如何在准确性和稳定性之间平衡计算效率仍是一项挑战，特别是对于高阶低存储方案。因此，需要找到一种优化方法，既要保持高阶（如四阶）精度，又要有出色的计算效率和稳定性，这是该领域的一个重要研究方向。此研究试图通过结合遗传算法（GA）和强化学习（RL），克服这一困难，自动发现最优的低存储ESRK方法的启发式规则，从而提高计算效率并维持性能。
### Innovation
该研究提出了一个结合遗传算法（GA）和强化学习（RL）的自适应启发式优化框架，以自动发现和优化低存储四阶龙格-库塔（ESRK）方法。与现有的手工设计启发式规则或穷举搜索方法相比，该方法通过GA驱动的变异来探索搜索空间，并通过RL启发的动态状态转换机制来提供启发式规则选择的改进。这种方法实现了参数的系统性削减，同时保持四阶精度，并大幅提高了计算效率，验证结果表明，这种方法能够减少IPOPT运行时间25%，而且在确保数值稳定性和精度的前提下。这一技术创新之处在于提供了一种新的启发式优化范例，能够显著提高高效的模拟和实际计算流体力学、物理模拟及其他高度要求领域的资源效率，拓宽了低存储龙格-库塔方法的应用范围，同时也为未来使用深度强化学习和自动机器学习进行启发式搜索提供了新的思路。
### Conclusion
该研究通过严格的基准测试，验证了该GA-RL启发式优化框架的有效性，并展示了其在提高资源效率和低存储方面的优势。这些发现表明自适应启发式发现可以提高高度保真的模拟效率，同时扩大了低存储龙格-库塔方法在实际计算流体力学、物理模拟和其他要求严苛领域的应用范围。研究还建立了一种新的启发式优化范例，为未来的进一步研究打开了新的途径，比如使用深度强化学习和自动化机器学习来优化启发式搜索。
## 557. `cs.LG` - 迁移分离表达：在合成与真实图像间搭建桥梁 [PDF](https://arxiv.org/pdf/2409.18017), [HTML](https://arxiv.org/abs/2409.18017)
### Authors
Jacopo Dapueto,Nicoletta Noceti,Francesca Odone
### Background
在表示学习中，开发有意义且有效的分离代表，以区分数据生成机制的基本结构是至关重要的。然而，分离表示学习在真实图像上的潜力尚未完全展现，这主要是由于生成因素间的关联性、分辨率限制以及获取真实标签的难度。特别是在后者方面，我们研究了利用合成数据学习适用于真实数据的一般目的分离表示的可能性，同时探讨了迁移和解缠特性保持的效果。我们进行了广泛的实证研究以应对这些问题。此外，我们提出了一种新的可解释干预法度量标准，用于衡量表示中因素编码的质量。研究结果表明，在从合成数据到真实数据的迁移中实现一定程度的分离是可能且有效的。
### Innovation
提出了一个新的可解释的干预法度量标准，用于衡量表示中因素编码的质量；研究了利用合成数据学习适用于真实数据的分离表示的可行性，并探讨了解纠缠性在迁移过程中的保持效果。
### Conclusion
研究结果表明，可以在一定程度上通过迁移将合成数据中的分离表示应用于真实数据，这可能是有效的。
## 558. `cs.LG` - 过程导向建模与仿真以增强工业物联网系统的故障诊断 [PDF](https://arxiv.org/pdf/2506.21502), [HTML](https://arxiv.org/abs/2506.21502)
### Authors
Francesco Vitale,Nicola Dall'Ora,Sebastiano Gaiardelli,Enrico Fraccaroli,Nicola Mazzocca,Franco Fummi
### Background
在工业物联网系统（CPSs）中，故障诊断对于确保系统可靠性和操作效率至关重要，这需要准确检测异常并识别其根本原因。然而，手工建模故障行为通常需要广泛的领域专业知识，并产生复杂、容易出错且难以解释的模型。为解决这一挑战，该研究提出了一种创新的无监督故障诊断方法，该方法结合了多变量时间序列的集体异常检测、过程挖掘和随机仿真。该方法从底层传感器数据中检测集体异常，并将这些异常转换为结构化的事件日志，以通过过程挖掘发现可解释的过程模型。通过在提取的彼得里网中加入时间分布，该方法支持对故障行为的随机仿真实现根本原因分析和行为理解的增强。该方法使用广泛认知的智能制造基准数据集Robotic Arm Dataset (RoAD) 进行验证。实验结果表明其在建模、仿真和分类CPS中的故障行为方面的有效性，从而使创建支持预测性维护和工业环境数字孪生的全面故障字典成为可能。
### Innovation
提出了一种创新的无监督故障诊断方法，该方法结合了多变量时间序列的集体异常检测、过程挖掘和随机仿真，以增强故障诊断的准确性和可解释性。该方法能够从底层传感器数据中检测集体异常，并通过过程挖掘和随机仿真实现对故障行为的全面理解。
### Conclusion
该方法在Robotic Arm Dataset (RoAD) 上进行了验证，实验结果表明其在建模、仿真和分类CPS中的故障行为方面的有效性，使得能够创建支持预测性维护和工业环境数字孪生的全面故障字典。
## 559. `cs.LG` - 在哪种大语言模型预训练中可以找到 Grokking？无需测试来监控记忆到泛化 [PDF](https://arxiv.org/pdf/2506.21551), [HTML](https://arxiv.org/abs/2506.21551)
### Authors
Ziyue Li,Chenrui Fan,Tianyi Zhou
### Background
最近在神经网络训练中观察到了所谓的“Grokking”现象，即测试性能在训练损失收敛之后仍然持续提升，这导致了泛化机制和其他新兴能力（如推理）变得令人 feeing。现有研究大多在小模型或特定任务上进行几千个时期的训练。作者首次在大语言模型（LLM）的一个过一遍预训练过程中对 Gooking 进行了研究，即 OLMoE，并评估了在数学推理、代码生成和常识/特定领域知识检索等多样基准任务中的一般化情况。研究发现，即使不同数据进入 Gooking 阶段的时间不同，Gooking 仍然发生在大型基础模型的预训练中。
### Innovation
这项研究是首次在过一遍预训练的大语言模型中研究 Gooking 现象。作者开发了两种新的度量标准来量化路径距离和单一路径的复杂性，并展示了这些指标可以预测在多种下游任务中的泛化改进。这些度量标准不仅能帮助监控预训练过程中的泛化性能，而且能够提供直接基于训练数据的延迟泛化的机制解释。此外，理论分析还表明，更加结构化的路径可以降低模型复杂性并改善泛化边界。
### Conclusion
通过监控训练数据而不是测试数据，作者证明了逐步发现复杂性减少和泛化能力增强之间的量化关系。这为 Gooking 现象提供了一个可操作的定义，并有助于理解大语言模型预训练过程中的泛化机制。
## 560. `cs.LG` - mTSBench: 规模化评估多变量时间序列异常检测和模型选择 [PDF](https://arxiv.org/pdf/2506.21550), [HTML](https://arxiv.org/abs/2506.21550)
### Authors
Xiaona Zhou,Constantin Brif,Ismini Lourentzou
### Background
多变量时间序列异常检测（MTS-AD）在医疗保健、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖关系、时间动态性和稀疏的异常标签数据，导致该领域仍面临挑战。
### Innovation
引入了迄今为止最大的MTS-AD和无监督模型选择基准mTSBench，涵盖了344个标签时间序列，分布在19个数据集和12个不同的应用领域，对24种异常检测方法进行了评估，包括基于大型语言模型的多变量时间序列异常检测器，并系统性地在标准化条件下评估了无监督模型选择技术。
### Conclusion
研究结果一致表明，没有一种检测器在所有数据集上都表现出色，强调了模型选择的重要性。然而，最先进的选择方法仍远未达到最优，揭示了重要的差距。mTSBench提供了一个统一的评估套件，以实现严格的、可重复的比较，并促进未来自适应异常检测和稳健模型选择的进步。
## 561. `cs.LG` - MegaFold：加速蛋白质结构预测模型的系统级优化 [PDF](https://arxiv.org/pdf/2506.20686), [HTML](https://arxiv.org/abs/2506.20686)
### Authors
Hoa La,Ahan Gupta,Alex Morehead,Jianlin Cheng,Minjia Zhang
### Background
目前，蛋白质结构预测模型如AlphaFold3（AF3）通过在transformer架构中引入基于科学启发的架构变化，推动了生物分子建模的前沿。然而，这些进步伴随着高昂的系统成本，导致计算和内存密集型操作、2D注意力机制以及检索增强数据管道的引入，这些共同阻碍了AF3训练的可扩展性。因此，研究目标是提高蛋白质结构预测模型的性能和可扩展性，特别是在模型训练方面。
### Innovation
本文提出了MegaFold，这是一个跨平台系统，通过预先缓存消除检索增强数据管道中的GPU空闲时间，使用Triton内核以减少异构设备上的内存使用，以及深度融合常见和关键的小型操作，从而加速AF3训练。实验证明，MegaFold在NVIDIA H200和AMD MI250 GPU上减少了AF3训练的峰值内存使用量最多1.23倍，并且每迭代训练时间分别提高了1.73倍和1.62倍。更重要的是，MegaFold使得在不出现内存溢出的情况下可以训练更长的蛋白质序列，从而显著提高了现代蛋白质折叠模型的可扩展性。开放源代码供下载。
### Conclusion
MegaFold显著提高了AF3的训练性能，特别是在内存使用和迭代训练时间方面，并实现了更长的序列训练，这有效改进了蛋白质结构预测模型的可扩展性，超越了PyTorch基准。
## 562. `cs.LG` - 监督学习中神经偏微分方程的控制与优化 [PDF](https://arxiv.org/pdf/2506.20764), [HTML](https://arxiv.org/abs/2506.20764)
### Authors
Alain Bensoussan,Minh-Binh Tran,Bangjie Wang
### Background
虽然关于抛物型和双曲型系统的控制与优化问题已有大量研究文献，但对于此类系统中的关联算子的系数进行控制和优化的具体问题尚未得到充分探索。神经网络和监督学习领域中存在这一问题的自然应用背景。在监督学习中，主要目标是通过神经网络的各层将初始数据运输至目标数据。这项研究将神经网络重新解释为偏微分方程（PDEs），将传统研究中用于常微分方程（ODEs）的控制问题重新构想为PDEs的控制问题，主要关注抛物型和双曲型算子系数的优化与控制问题。
### Innovation
提出了一种用于抛物型PDEs的控制与优化问题的对偶系统形式，为未来研究中高效的数值方案的发展打下基础；证明了抛物型PDEs的控制与优化问题具有极值解；研究了双曲型PDEs相关的控制问题，并证明了相应近似控制问题的解的存在性。这是控制理论中PDEs领域的一个特定问题的系统解决方法的新尝试。
### Conclusion
通过上述研究，实现了神经网络中偏微分方程控制与优化问题的理论突破，为相关领域的发展提供了新的视角和方法，为未来的研究奠定了基础，并通过理论证明了目标问题的可行性。
## 563. `cs.LG` - 用于SAR干涉相位unwrap的Spiking神经网络：一种高效的理论框架 [PDF](https://arxiv.org/pdf/2506.20782), [HTML](https://arxiv.org/abs/2506.20782)
### Authors
Marc Bara
### Background
在合成孔径雷达（SAR）干涉测量相位unwrap领域，尽管有大量研究，但从未有人将Spiking神经网络（SNNs）应用于相位unwrap。随着地球观测数据量呈指数级增长（例如，NISAR任务预计两年内将产生100PB的数据），能源高效的处理变得至关重要，这对于可持续的数据中心运营来说是必要的。SNNs以事件驱动的计算模型为基础，相比传统方法可节省30-100倍的能量消耗，同时保持类似准确度。因此，SAR干涉相位unwrap中应用SNNs的研究具有重要意义和潜力。
### Innovation
该研究首次提出了SNNs在SAR干涉相位unwrap中的理论框架，开发了针对缠绕相位数据的编码方案，并提出了利用相位unwrap在空间传播特性设计的SNN架构。研究团队还对SNNs的计算复杂性和收敛性能进行了理论分析。研究发现SNNs的固有时间动态可以自然地模拟相位unwrap中的空间连续性约束。研究打开了神经形态计算与SAR干涉测量交叉领域的研究新方向，提出了一种与现有算法互补的方法，有望使大规模干涉测量处理更加可持续。
### Conclusion
该研究提出了一种新的理论框架，将Spiking神经网络引入SAR干涉相位unwrap中，既节能又具有与现有算法相当的准确性。这种新方法为大规模InSAR处理提供了一条新的途径，有助于可持续和高效的地球观测数据处理。
## 564. `cs.LG` - scMamba: 超越高度可变特征选择的大规模单细胞多组学集成的可扩展基础模型 [PDF](https://arxiv.org/pdf/2506.20697), [HTML](https://arxiv.org/abs/2506.20697)
### Authors
Zhen Yuan,Shaoqing Jiao,Yihang Xiao,Jiajie Peng
### Background
单细胞多组学技术的发展使得可以同时对单个细胞内的多个组学层进行分析。结合这些多模态数据可以揭示细胞身份、调控过程和疾病机制等方面前所未有的洞察。然而，当前方法常依赖于预处理阶段选择高度变异的基因或峰，这可能会无意中丢弃重要的生物学信息。
### Innovation
我们提出了scMamba，这是一种无需预先特征选择即可整合单细胞多组学数据的基础模型，同时保留了基因组位置信息。scMamba采用基于补丁的细胞分词策略，将基因组区域视为词（标记），将细胞视为句子。它基于状态空间二元性概念，从高维稀疏单细胞多组学数据中提取丰富的生物学洞察。此外，我们的新颖对比学习方法，结合余弦相似性正则化，能够在跨组学层对齐方面优于传统方法。系统基准测试表明，scMamba在保留生物学变异、对齐组学层和增强聚类、细胞类型注释和轨迹推断等关键下游任务方面显著优于最先进的方法。
### Conclusion
我们的研究将scMamba置于大规模单细胞多组学集成的强大工具位置，能够处理大规模图集并推进生物学发现。
## 565. `cs.LG` - 基于实用性驱动的混合专家推测解码 [PDF](https://arxiv.org/pdf/2506.20675), [HTML](https://arxiv.org/abs/2506.20675)
### Authors
Anish Saxena,Po-An Tsai,Hritvik Taneja,Aamer Jaleel,Moinuddin Qureshi
### Background
GPU 内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。推测性解码通过利用闲置的 GPU 计算资源，使用轻量级的drafter提案K个token，然后LLM并行验证，从而提高token吞吐量。然而，对于新兴的专家混合（MoE）模型，每次token仅加载一部分权重，极大减少了数据移动生成。但是，推测解码并不适合MoE模型，因为草案token集体激活更多的权重，增加了数据移动生成和验证时间。当token吞吐量增益无法抵消这些开销时，推测解码会带来高达1.5倍的性能下降，使其难以实现。即使某些情况下推测解码是有用的，最优的K值也取决于任务、模型，甚至请求和迭代。因此，尽管推测解码在密集型LLM中广泛应用，但对于主流的MoE模型来说，推测解码仍然是不可行的。
### Innovation
提出了Cascade，一种基于实用性驱动的框架，通过动态调整推测性解码的启用和K值的优化，避免性能下降并加速MoE服务。Cascade使用一种轻量级的度量标准，推测实用性，即token增益与验证成本的比值，展示了迭代级别的局部性，通过短测试周期和较长的设定周期进行定期决策。在设定周期中，如果测试期间推测实用性低于1，则禁用推测，否则测试多个K值以选择最大化实用性K值。通过在vLLM上实现Cascade并对其使用广泛的工作负载进行了评估，证明了Cascade能将性能下降限制在5%内，相比于静态K值，吞吐量提高了7-14%，使得推测解码在MoE中成为可能。
### Conclusion
尽管推测解码在密集型LLM中广泛应用，但对于主流的MoE模型来说仍然不可行。通过提出Cascade框架并动态调整推测解码的启用和K值的优化，避免性能下降并加速MoE服务，证明了推测解码在MoE中成为可能，将性能下降限制在5%，吞吐量提高了7-14%。
## 566. `cs.LG` - ReLU神经网络的稳定最小值遭受维度灾难：神经分裂现象 [PDF](https://arxiv.org/pdf/2506.20779), [HTML](https://arxiv.org/abs/2506.20779)
### Authors
Tongtong Liang,Dan Qiao,Yu-Xiang Wang,Rahul Parhi
### Background
本文研究了平滑度（低损失曲率）对多变量输入条件下两层过参数化ReLU网络泛化的隐式偏差。现有的研究要么需要过拟合，要么仅关注单变量输入。文章探讨了平滑度和稳定性最小值在非参数函数估计中的影响，特别是在高维输入时的泛化能力问题，证明了即使在平滑度的情况下，泛化性能仍会随着输入维度的增长而急剧下降，且超过低范数解（如权重衰减）的维度灾难现象。
### Innovation
本文提出了新的和相对惊人的理论结果，特别是对于多变量输入。作者通过新颖的边界局部化ReLU神经元打包论证构造了最小最大下界，展示了平滑解如何通过一种“神经分裂”现象表现不佳，即使激活频率低，但权重幅度较大，在高维空间表现较差。并且，作者通过广泛的数值模拟验证了理论发现，并首次系统解释了为什么在高维空间中平滑最小值可能无法泛化的原因。
### Conclusion
本文证明了平滑解的泛化率一定随着输入维度的增长而呈指数下降，即使在趋于稳定的最小值情况下，也不能避免维度灾难。平滑解与低范数解在高维表现上存在指数级的分隔。
## 567. `cs.LG` - U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs [PDF](https://arxiv.org/pdf/2506.20689), [HTML](https://arxiv.org/abs/2506.20689)
### Authors
Racheal Mukisa,Arvind K. Bansal
### Background
人工智能，包括深度学习模型，将在自动医疗图像分析中发挥变革性作用，用于心血管疾病的诊断及其管理。准确自动地分割心脏图像是量化和自动化诊断心血管疾病的第一步。本研究探讨了一种基于深度学习的增强UNet模型U-R-Veda，该模型结合了卷积转换、视觉变换器、残差链接、通道注意和空间注意，以及基于边缘检测的跳接连接，以实现心脏磁共振（CMR）图像的精确全自动语义分割。该模型使用嵌入的通道和空间注意机制提取本地特征及其相互关系，从而提高医学图像分析的质量。研究表明，U-R-Veda在DSC指标下的平均准确率为95.2%，尤其在右心室和左心室心肌的分割方面优于其他模型。
### Innovation
研究提出了U-R-Veda模型，结合了卷积转换、视觉变换器、残差链接、通道注意、空间注意和基于边缘检测的跳接连接。这些创新点旨在提高心脏磁共振（CMR）图像的语义分割准确度。深度嵌入通道和空间注意机制在卷积块中，以识别重要特征及其空间定位；结合边信息与通道和空间注意作为跳接连接，减少了卷积变换中的信息丢失。U-R-Veda实现了显著的语义分割性能提升，特别是在右心室和左心室心肌的分割上优于其他模型。
### Conclusion
U-R-Veda模型通过结合卷积转换、视觉变换器、残差链接、通道注意、空间注意和基于边缘检测的跳接连接，显著提高了心脏磁共振（CMR）图像的语义分割性能。该模型在DSC指标下的平均准确率为95.2%，尤其是在右心室和左心室心肌的分割上表现出色，优于其他模型。这表明U-R-Veda在自动化心血管疾病诊断和管理方面具有重要的应用前景。
## 568. `cs.LG` - Temporal Fusion Transformers在径流模拟中的有效性 [PDF](https://arxiv.org/pdf/2506.20831), [HTML](https://arxiv.org/abs/2506.20831)
### Authors
Sinan Rasiya Koya,Tirthankar Roy
### Background
注意力机制与循环机制在序列建模中的结合已被证明在水文预测中具有重要作用。本文通过比较基于Temporal Fusion Transformers (TFT)和Long Short-Term Memory (LSTM)网络的模型在降水径流建模中的表现，进一步探讨了TFT的优势。研究在全美的531个CAMELS流域和Caravan数据集的不同地区子集上进行了模型训练和实验，旨在评估这两种模型在不同数据集上的性能差异及其对流域属性的敏感性。
### Innovation
本文创新性地使用TFT与LSTM在网络架构上进行对比，特别是在处理更长序列数据和更大规模流域时，TFT显示出其优势，能够识别关键动态和静态变量，提供科学见解。同时，研究揭示了两种模型在Caravan数据集上的表现下降可能与数据质量问题有关，这为进一步优化流域模型提供了依据。
### Conclusion
研究结果表明，TFT在模拟水文图的中间部分和峰值时略优于LSTM，并且在处理长序列和大流域时更具潜力。然而，两个模型在Caravan数据集上的显著性能下降提示数据质量可能存在问题。总体而言，这项研究突显了TFT在提升水文模拟能力和增进理解方面的重要潜力。
## 569. `cs.LG` - 赋能数字农业：一种保护隐私的数据共享与协作研究框架 [PDF](https://arxiv.org/pdf/2506.20872), [HTML](https://arxiv.org/abs/2506.20872)
### Authors
Osama Zafar,Rosemarie Santa González,Mina Namazi,Alfonso Morales,Erman Ayday
### Background
数据驱动的农业通过将技术和数据整合到农业生产实践中，具有提高作物产量、增强疾病抵抗力和保护长期土壤健康的潜力。然而，隐私问题，如市场价格恶化、歧视和资源操纵，常常阻止农民共享数据，因为这些数据可能被用于对他们不利的情况。为解决这一障碍，提出了一种隐私保护框架，旨在确保研究人员和从业者之间可以安全地进行数据共享和合作研究，同时减轻隐私风险。该框架结合了降维技术（如主成分分析PCA）和差分隐私方法，通过引入拉普拉斯噪声来保护敏感信息。
### Innovation
提出了一种结合降维技术和差分隐私的隐私保护框架，通过引入拉普拉斯噪声来保护敏感信息，并使用联邦学习对识别的潜在合作者的数据进行模型训练或直接对聚合的隐私保护数据进行训练。该框架能够增强研究人员之间的数据共享，支持个性化机器学习模型的训练，并允许农民根据相似性识别潜在合作者。该框架已在实际数据集上得到验证，能够有效抵御恶意攻击并提供与集中式系统媲美的性能。通过该框架促进了农民之间的合作，使研究人员能够实现更广泛的研究目标。
### Conclusion
研究结果表明，采用该框架可以确保数据的安全整合，并支持农业系统的创新和可持续发展。通过解决关键的隐私挑战，这项工作推动了数据驱动农业的变革性进步，促进了安全数据集成，为政策制定者提供了更多运用农业数据的可能。
## 570. `cs.LG` - 通过验证和适应进行结构系统辨识 [PDF](https://arxiv.org/pdf/2506.20799), [HTML](https://arxiv.org/abs/2506.20799)
### Authors
Cristian López,Keegan J. Moore
### Background
结构系统的参数估计对于将实验数据与科学理论相结合理解、验证和预测复杂系统动态至关重要。现有的结构系统识别方法主要依赖于从理论出发来识别参数，但这些方法往往缺乏从数据直接进行系统识别、不确定性量化和验证的能力。本文提出的基于生成模型的神经网络方法能够直接从数据中映射随机噪声到物理有意义的参数，并通过与真实训练数据的均方误差损失进行比较，从而实现结构系统参数估计和验证的目的。
### Innovation
本文提出了一种新的结构系统识别方法，该方法通过生成模型框架将随机噪声映射为物理有意义的参数，并使用均方误差损失将估计的参数与真实数据进行比较。此外，该方法还引入了一个独立的验证数据集来同时验证学习到的参数，通过鉴别器网络判断生成数据的真实性，从而引导参数生成网络的进步，实现结构系统的准确参数估计和验证。
### Conclusion
本文方法在不同的非线性结构系统上展示了参数估计的准确性和模型验证的有效性。
## 571. `cs.LG` - Faster Fixed-Point Methods for Multichain MDPs [PDF](https://arxiv.org/pdf/2506.20910), [HTML](https://arxiv.org/abs/2506.20910)
### Authors
Matthew Zurek,Yudong Chen
### Background
本文研究了一般（也称为多链）马尔可夫决策过程（MDPs）在平均报酬标准下的值迭代（VI）算法，这是一个基本但理论上具有挑战性的设置。在所有平均报酬问题中，由于贝尔曼算子的非收缩性和解的非唯一性带来的困难，以及多链设置中最优政策必须解决的导航子问题，即将政策引导到最优连接子集，而不是在每个子集内优化长期内的性能，因此存在进一步改进的需求。
### Innovation
本文开发了能够更好地解决导航子问题的算法，以加快多链MDP中的收敛速度，获得了比先前工作更快的收敛率和更精确的复杂度衡量标准。关键成果还包括将平均报酬问题与折扣问题的新连接、适用于一般Banach空间的最优固定点方法、折扣值偏差的新亚线性收敛率以及多链MDP的精炼次优分解等潜在独立感兴趣的内容。
### Conclusion
总体而言，本文结果为折扣和平均报酬问题提供了更快的收敛率，并扩展了值迭代方法的理论基础。
## 572. `cs.LG` - 基于统计特性的FCC合金位错塑性和应力-应变响应的不确定性意识机器学习框架 [PDF](https://arxiv.org/pdf/2506.20839), [HTML](https://arxiv.org/abs/2506.20839)
### Authors
Jing Luo,Yejun Gu,Yanfei Wang,Xiaolong Ma,Jaafar.A El-Awady
### Background
机器学习显著推进了结构材料的理解与应用，特别强调了对预测模型中数据集成和不确定性量化的重要性。这项研究通过利用混合密度网络（MDN）模型，结合广大的实验数据文献，提出了一种全面的方法，用于预测位错密度的分布及其在晶粒层面的应力分布。这种方法通过将预测分布的统计参数纳入位错介导的塑性模型中，实现了应力-应变预测的准确性和不确定性量化，从而改进了机械性能预测的准确性和可靠性，促进新的材料开发，尤其是在快速发展的行业中发挥着重要作用。
### Innovation
该研究创新性地利用混合密度网络（MDN）模型，针对FCC合金预测位错密度分布及其应力分布，并通过纳入预测分布的统计参数到位错介导的塑性模型中，实现了精确的应力-应变预测及不确定性量化。这种策略不仅提高了机械性能预测的准确性和可靠性，还对合金设计具有优化作用，从而加速新材料的开发。
### Conclusion
这项研究通过提出一种不确定性意识的机器学习框架，成功地预测了FCC合金的位错塑性和应力-应变响应。这种方法不仅提高了预测的准确性和可靠性，还推动了合金设计及新材料开发，在快速发展的行业中起到了重要作用。
## 573. `cs.LG` - Manifold Gaussian Process回归的主动学习 [PDF](https://arxiv.org/pdf/2506.20928), [HTML](https://arxiv.org/abs/2506.20928)
### Authors
Yuanxing Cheng,Lulu Kang,Yiwei Wang,Chun Liu
### Background
本文介绍了一种在高维空间中提高集成高斯过程(GP)回归精度的主动学习框架，结合了流形学习与策略数据选择。该方法通过联合优化神经网络进行降维和在潜在空间中的高斯过程回归器，由最小化全局预测误差的主动学习准则进行监督。实验证明，在合成数据上，该方法优于按顺序随机学习。方法能够高效处理复杂、不连续的函数，同时保持计算上的可行性，为科学和工程应用提供了实际价值。未来的研究将集中在可扩展性和不确定性感知流形学习上。
### Innovation
提出了将流形学习与策略数据选择结合的主动学习框架，用于提高高维空间中高斯过程回归的准确性。该方法通过联合优化降维神经网络和潜在空间中高斯过程回归器，并通过最小化全局预测误差的主动学习准则进行监督，相比于按顺序随机学习方法，表现出更好的性能。
### Conclusion
该框架能够有效处理复杂、不连续的函数，同时保持计算上的可行性，为科学和工程应用提供了实际价值。未来的研究将聚焦于该方法的可扩展性和不确定性感知流形学习的改进。
## 574. `cs.LG` - 利用稀疏时序融合变换器和高斯过程混合进行地缘政治事件预测：中东和美国冲突动态案例研究 [PDF](https://arxiv.org/pdf/2506.20935), [HTML](https://arxiv.org/abs/2506.20935)
### Authors
Hsin-Hsiung Huang,Hayden Hampton
### Background
从类似于全球事件、语言和情绪数据库（GDELT）的数据源预测地缘政治冲突是国家安全的一项关键挑战。这类数据的固有稀疏性、突发性和过度分散性使得标准深度学习模型，包括时序融合变换器（TFT），在生成长期预测时表现不稳定。
### Innovation
我们介绍了STFT-VNNGP这种混合架构，克服了上述限制并赢得了2023年的威胁检测算法（ATD）竞赛。该模型采用两阶段过程：首先，TFT捕捉复杂的时序动态以生成多分位数预测；然后将这些分位数作为输入用于变分最近邻高斯过程（VNNGP），该过程进行原则性的时空平滑和不确定性量化。在中东和美国冲突动态的案例研究中，STFT-VNNGP在预测突发事件时期的时间和规模方面表现优于独立的TFT，尤其是在长范围展望中。
### Conclusion
这项工作提供了一个强大的框架，用于从具有挑战性的事件数据中生成更可靠且有行动意义的情报，所有代码和工作流程均公开以确保可重复性。
## 575. `cs.LG` - 台湾股市行业轮动的量子增强强化学习交易代理 [PDF](https://arxiv.org/pdf/2506.20930), [HTML](https://arxiv.org/abs/2506.20930)
### Authors
Chi-Sheng Chen,Xinyu Zhang,Ya-Chuan Chen
### Background
本文提出了一种量子与经典结合的强化学习框架，用于台湾股市的行业轮动。系统采用Proximal Policy Optimization (PPO) 作为主要算法，并结合了经典架构（LSTM, Transformer）和量子增强模型（QNN, QRWKV, QASA）作为策略和价值网络。自动生成的特征工程流程从资本股份数据中提取金融指标，确保所有配置下的一致模型输入。实证回测发现一个关键发现：尽管量子增强模型在训练奖励中表现出色，但在实际投资指标，如累计收益和夏普比率中，它们的表现却不如经典模型。这种差异突显了将强化学习应用于金融领域的一个核心挑战，即代理奖励信号与真实投资目标之间的不匹配。这表明当前的奖励设计可能激励算法过度拟合短期波动，而不是优化风险调整后的回报。此外，量子电路在噪声中间规模量子（NISQ）约束下的固有表现性和优化不稳定性也加剧了这一问题。本文讨论了这一奖励-表现差距的影响，并提出了未来改进的方向，包括奖励重塑、模型正则化和基于验证的早期停止。文章提供了一个可重复的基准，并对部署量子强化学习在实际金融领域中的实际挑战提供了关键见解。
### Innovation
本文提出了一个量子与经典结合的强化学习框架，以及使用Proximal Policy Optimization (PPO)为主要算法，同时结合了经典架构与量子增强模型作为策略和价值网络。研究结果揭示了量子增强模型与经典模型在实际投资绩效上的差异，并提出了基于奖励重塑、模型正则化和验证性早期停止的方法来改进量子强化学习的部署。
### Conclusion
文章提出了一个针对台湾股市行业轮动的量子增强强化学习框架。实验结果表明，尽管量子增强模型在训练奖励中表现优异，但在实际应用中的投资绩效不如经典模型。研究强调了代理奖励信号与真实投资目标之间的不匹配问题，并对未来的研究方向进行了讨论，包括奖励重塑、模型正则化和基于验证的早期停止。本文提供了一个可重复的基准，并对量子强化学习在实际金融领域的部署提出了关键见解。
## 576. `cs.LG` - LLM生成与人类研究想法的执行结果差异：理念与执行之间的缺口 [PDF](https://arxiv.org/pdf/2506.20803), [HTML](https://arxiv.org/abs/2506.20803)
### Authors
Chenglei Si,Tatsunori Hashimoto,Diyi Yang
### Background
大语言模型（LLMs）已经在加速科学研研究过程中显示出潜力。研究中的关键能力之一是生成新的研究思路，过往研究发现，由AI生成的研究思路相较于人类专家的想法往往被认为更加新颖。然而，一个好的研究思路不仅应该显得新颖，还应该在执行后能够产生更好更有效的研究结果。为了评估AI生成的想法能否带来更好的研究产出，本研究通过招募43位专家研究者来执行随机分配给他们的想法，这些想法可能是专家撰写的或者是由LLM生成的。每位专家花费了超过100小时时间将想法付诸实施，并撰写了一份4页的短文记录实验过程。所有的执行项目都由专家自然语言处理研究者进行盲审。对比执行前后的评分，可以看出，在所有评价指标（新颖性、关注度、有效性以及总体评价）上，LLM生成的想法评分的减少幅度比由专家撰写的想法更大，这表明在实施后，LLM和人类想法之间的差距缩小了。当比较执行研究中的综合评分时，我们甚至发现多项指标的人类想法评分通常高于LLM想法的评分。这一理念执行之间的差距突显了当前LLMs在生成真正有效研究思路方面的局限性，以及在缺乏执行结果的情况下评估研究思路的挑战。
### Innovation
研究通过实际执行和盲审的方法，直接评估AI生成想法与专家撰写的对比效果，揭示了两者在实际应用中的表现差距，特别是强调了当前LLMs在生成真正有效研究思路方面的局限性，以及评价研究思路的挑战。这一方法创新使得研究结果更加具有实际意义和参考价值。
### Conclusion
当前的大语言模型在生成有效的研究思路方面存在着局限性，需要进一步改进以适应实际研究应用。此外，在缺乏执行结果的情况下，当前的方法和工具难以充分评估研究思路的质量，这需要更加综合和全面的评价体系。
## 577. `cs.LG` - EraRAG：不断增长语料库的高效和增量检索增强生成 [PDF](https://arxiv.org/pdf/2506.20963), [HTML](https://arxiv.org/abs/2506.20963)
### Authors
Fangyuan Zhang,Zhengjun Huang,Yingli Zhou,Qintian Guo,Zhixun Li,Wensheng Luo,Di Jiang,Yixiang Fang,Xiaofang Zhou
### Background
Graph-based Retrieval-Augmented Generation (Graph-RAG)通过结构化检索来增强大型语言模型（LLMs），但在现有方法中，通常假定静态语料库，在新文档到达时需要昂贵的全图重建，这限制了它们在动态、不断变化环境中的可扩展性。
### Innovation
EraRAG引入了一个新型的多层次Graph-RAG框架，支持高效的可扩展动态更新。方法利用基于超平面的局部敏感哈希（LSH）来分层组织原始语料库并实现新数据的高效局部插入，无需重新训练或昂贵的重新计算，同时保持高检索准确性和低延迟。实验表明，与现有Graph-RAG系统相比，EraRAG在更新时间和token消耗上可减少一个数量级以上，且提供更好的准确性能。
### Conclusion
本工作为必须在不断增长的语料库上运行的RAG系统提供了一条实际可行的路径，通过提升检索效率和适应性来弥补现有技术的不足。相关代码和数据可在此网址获取。
## 578. `cs.LG` - 可以使用梯度下降模拟提示吗？ [PDF](https://arxiv.org/pdf/2506.20989), [HTML](https://arxiv.org/abs/2506.20989)
### Authors
Eric Zhang,Leshem Choshen,Jacob Andreas
### Background
语言模型（LM）可以通过修改提示或参数来整合新信息。参数更新不会造成长期存储成本，但许多模型更新中，提示更为有效。在标准微调下，提示的模型可以稳健地从单一例子中推广，并做出逻辑推理，而标准微调做不到这一点。本文介绍了一种方法，通过元训练LM使得梯度更新模拟因新信息条件所导致的效果。这种方法使用基于梯度的元学习工具，但使用LM自己的提示预测作为目标，消除了对真实标签的需求。
### Innovation
介绍了一种方法，通过元训练LM使得梯度更新模拟提示的效果。该方法使用LM自身的预测作为目标，不需要真实标签。梯度下降训练可以恢复部分（甚至全部）提示模型的性能，表现出改进。“逆转诅咒”任务和单次梯度更新后回答对文本段落的问题。这表明，适当初始条件下，梯度下降非常表达力强。这些结果为长上下文建模提供新途径，并为基于梯度的学习的泛化能力提供了见解。
### Conclusion
这些结果表明，适当初始条件下，梯度下降非常表达力强。梯度下降训练可以恢复部分（甚至全部）提示模型的性能，表现出改进。“逆转诅咒”任务和单次梯度更新后回答对文本段落的问题。这种方法为长上下文建模提供新途径，并为基于梯度的学习的泛化能力提供了见解。
## 579. `cs.LG` - ZKPROV: 零知识方法实现大型语言模型数据来源完整性 [PDF](https://arxiv.org/pdf/2506.20915), [HTML](https://arxiv.org/abs/2506.20915)
### Authors
Mina Namazi,Alexander Nemecek,Erman Ayday
### Background
随着大型语言模型（LLMs）在敏感领域中的部署增加，确保其计算可追溯性的重要性不断提升，特别是对于监管严格的医疗保健行业等。在这些领域中，对数据集使用的严格要求使得确保模型训练数据的可靠性成为关键问题。现有方法通常要求对整个训练流程进行验证，这会带来巨大的计算成本，或者依赖于可信执行环境来保证数据来源的可信度。ZKPROV旨在通过零知识证明提供一种新的加密框架，让用户能够验证模型是否基于可靠的训练数据集，而不泄露敏感数据或参数细节。
### Innovation
ZKPROV方法通过加密方式将训练好的模型与其授权的训练数据集绑定，同时无需证明每个训练步骤。它利用数据集签名元数据和紧凑的模型参数承诺，提供了一种安全且保护隐私的证明机制，确保LLM的结果来源于声明的授权和相关数据集。相比于先前的方法，ZKPROV在生成和验证零知识证明时更有效率和可扩展，解决了实际部署中可信数据来源的问题，并且能够提供正式的安全保障，确保数据集的保密性同时保持数据来源的可信度。
### Conclusion
实验结果表明，ZKPROV在生成零知识证明和验证方面具有高效率和可扩展性，为实际部署提供了一种实用的解决方案。通过提供形式化安全保证，ZKPROV确保数据集保密性的同时保证了可信赖的数据来源。
## 580. `cs.LG` - HybridQ: 结合经典与量子生成对抗网络的皮肤疾病图像生成 [PDF](https://arxiv.org/pdf/2506.21015), [HTML](https://arxiv.org/abs/2506.21015)
### Authors
Qingyue Jiao,Kangyu Zheng,Yiyu Shi,Zhiding Liang
### Background
机器学习辅助诊断在皮肤疾病检测中越来越受欢迎，但训练有效的模型需要大量的高质量数据。皮肤疾病数据集通常存在类别不平衡、隐私问题和对象偏差的问题，这使得数据增强变得必不可少。虽然经典的生成模型被广泛应用，但它们需要大量的计算资源和较长的训练时间。过去的方法只能生成灰度低质量图像，量子计算则提供了一种新的可能性，但现有的一些量子基生成图像的方法只能生成灰度低质量图像。
### Innovation
通过引入一种新型的经典-量子潜在空间融合技术，我们的工作克服了灰度低质量图像的问题，提出了第一个可以生成彩色医疗图像的经典-量子生成对抗网络（GAN）。该模型在图像生成质量和分类性能提升方面均优于经典的深层卷积GAN和现有的经典-量子生成对抗网络，而且模型参数量减少了25倍，训练轮数减少了10倍。结果表明，随着量子硬件的进展，量子图像生成具有光明的前景。此外，我们还在真实的IBM量子机器上展示了该模型的鲁棒性，并克服了硬件噪声带来的挑战。
### Conclusion
我们的模型在图像生成质量和分类性能方面表现优异，并且参数量和训练轮数都大幅减少。这表明经典-量子生成对抗网络在皮肤疾病图像生成方面具有巨大的潜力，并且当我们克服了硬件噪声等问题后，这些找到将可能为医学应用开辟新的道路。
## 581. `cs.LG` - 通过指导与调度提升基于扩散的图像编辑保真度 [PDF](https://arxiv.org/pdf/2506.21045), [HTML](https://arxiv.org/abs/2506.21045)
### Authors
Hansam Cho,Seoung Bum Kim
### Background
文本指导的扩散模型已成为高质量图像合成的关键工具，支持动态图像编辑。在图像编辑中，编辑度决定了修改的程度，而保真度反映了未修改元素的保存情况。然而，由于编辑度与保真度之间的固有权衡，实现最佳效果具有挑战性。
### Innovation
针对这一挑战，我们提出了保真度指导和调度（FGS）方法，该方法在最小影响编辑度的情况下增强保真度，并引入调度策略解决编辑度与保真度之间的对齐问题。实验结果表明，FGS在保持编辑度的同时实现了更高的保真度，并且该方法能够与各种编辑方法兼容，在多种任务中实现精确和高质量的图像编辑
### Conclusion
实验结果证明FGS能够在保持编辑度的同时实现更好的保真度，并且与多种编辑方法兼容，能够实现多种任务中的高质量图像编辑。
## 582. `cs.LG` - 通过不确定人类指导的强化学习进行复杂模型变换 [PDF](https://arxiv.org/pdf/2506.20883), [HTML](https://arxiv.org/abs/2506.20883)
### Authors
Kyanna Dagenais,Istvan David
### Background
模型驱动工程问题常常需要复杂的模型变换（MTs），例如在模型同步、自动化模型修复以及设计空间探索等方面。手动开发复杂的MTs是一个易出错且通常无法实现的过程。强化学习（RL）是解决这些问题的一种好方法。但在复杂问题中，RL方法表现出性能问题，这时人类的指导可以起到很大的帮助作用。因此，本文提出了一种通过RL和潜在不确定的人类指导开发复杂MT序列的方法。该方法允许用户自定义的MTs映射到RL原语上，并执行为RL程序以查找最优的MT序列。实验结果表明，即使是不确定的人类指导也能显著提高RL性能，从而使复杂MTs的开发更加高效。通过人类建议的确定性和及时性之间的权衡，本文朝着加强连接的RL驱动的在环工程方法迈出了一步
### Innovation
提出了一种利用强化学习与可能不确定的人类指导开发复杂模型变换序列的方法。该方法允许用户定义的模型变换映射到RL原语上，并通过RL程序找到最优模型变换序列。此方法通过在确定性和时效性之间进行权衡，在复杂模型变换中引入了人类指导，从而提高了RL性能，使得模型变换的开发更加高效。
### Conclusion
该方法在人类建议不确定的情况下也能显著提高强化学习的性能，并在复杂模型变换中取得了更为高效的开发结果，通过人类建议的确定性和及时性之间的权衡，向机器学习驱动的人类在环工程方法迈出了实质性的一步。
## 583. `cs.LG` - 有限状态马尔可夫游戏中多智能体学习动力学的 homogenization [PDF](https://arxiv.org/pdf/2506.21079), [HTML](https://arxiv.org/abs/2506.21079)
### Authors
Yann Kerzreho(ENS Paris Saclay)
### Background
本文提出了一个针对在有限状态马尔可夫游戏中进行互动的多个强化学习（RL）代理的近似学习动力学的新方法。传统的方法并未考虑多个代理间的互动过程，而本研究聚焦于代理间合作和竞争所带来的复杂动态。
### Innovation
研究通过同时降低学习率和增加更新频率来重新缩放学习过程，使代理参数被视为由快速混合的博弈状态所影响的慢变变量。在适度假设下，即状态过程的遍历性和更新连续性，该研究证明了重新缩放过程收敛于一个常微分方程（ODE），并且这个ODE可以提供一个易于处理且确定性的代理学习动态近似模型。
### Conclusion
提出了新的理论模型，并证明了其有效性，为理解多智能体在有限状态马尔可夫游戏中的学习动态提供了新的工具，同时一个实现框架的代码已发布。
## 584. `cs.LG` - 关于马尔可夫等价类大小的下界 [PDF](https://arxiv.org/pdf/2506.20933), [HTML](https://arxiv.org/abs/2506.20933)
### Authors
Erik Jahn,Frederick Eberhardt,Leonard J. Schulman
### Background
因果发现算法通常只能恢复因果图直到它们的马尔可夫等价类，除非做出额外的参数假设。这些等价类的大小反映了从纯观察数据中学到的关于潜在因果图的限制。在无环性、因果完备性和模型先验均匀分布的假设下，已知平均而言马尔可夫等价类很小。然而，该论文证明，当任何这些假设都不成立时，这种情况就不再适用了。具体来说，该论文证明了在三种情况下马尔可夫等价类的期望大小下限是指数级的：稀疏随机有向无环图、均匀随机有向混合图以及均匀随机有向环状图。
### Innovation
该论文证明了在无环性、因果完备性和模型先验均匀分布假设被放宽的三种情况下，马尔可夫等价类的期望大小下限是指数级的，这揭示了因果图学习在实际数据中的限制，以及额外的假设对恢复因果结构的重要性。
### Conclusion
该论文通过数学证明指出，当改变假设条件时，因果图马尔可夫等价类的大小将不再是平均值较小，且具体的证明在特定的图模型中给出了具体的下限值，这为理解因果推理的局限性提供了重要的理论支持。
## 585. `cs.LG` - 基于Transformer的空间-时间反事实结果估计 [PDF](https://arxiv.org/pdf/2506.21154), [HTML](https://arxiv.org/abs/2506.21154)
### Authors
He Li,Haoang Chi,Mingyu Liu,Wanrong Huang,Liyang Xu,Wenjing Yang
### Background
现实世界自然地具有时间和空间维度，因此估计具有时空属性的反事实结果是一个关键问题。然而，之前的大多数方法基于经典统计模型，这些模型在性能和泛化能力方面仍存在局限性。
### Innovation
本文提出了一种新的框架，利用Transformer来估计具有时空属性的反事实结果，显示出更强的估计能力。在轻微假设下，该框架中的提出估计器是一致且渐近正态的。通过仿真实验和真实数据实验来验证我们方法的有效性。仿真实验表明，我们的估计器的估计能力优于基线方法；真实数据实验为哥伦比亚冲突对森林损失的影响提供了有价值的因果结论。
### Conclusion
通过仿真和真实数据实验，验证了基于Transformer的空间-时间反事实结果估计的有效性，并为冲突对森林损失的影响提供了有价值的结论。源代码可在以下链接获取：this https URL.
## 586. `cs.LG` - 通过负音频指导逐步视频到音频合成 [PDF](https://arxiv.org/pdf/2506.20995), [HTML](https://arxiv.org/abs/2506.20995)
### Authors
Akio Hayakawa,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji
### Background
本文提出了一种新颖的逐步视频到音频生成方法，该方法按顺序生成每种对应视频中特定声音事件的独立音频音轨。该方法借鉴了传统配音工作流程，旨在全面捕捉由给定视频引起的各种声音事件。这种方法的设计灵感来自早期组合生成框架中的概念否定理念。研究结果表明，该方法可以为单个输入视频生成多个语义不同的音频音轨，从而实现比现有基线更高的综合音频合成质量。
### Innovation
1. 逐步生成方法：每个生成步骤都是基于目标文本提示和先前生成的音频音轨的指导视频到音频合成任务。2. 负音频指导：利用预先训练好的视频到音频模型，不需要专门的成对数据集，允许使用更易于获取的数据进行训练。3. 概念否定理念：受早期组合生成框架中概念否定理念的启发，实现了更好的生成效果和更高的合成质量。
### Conclusion
本文提出的方法能够为单个输入视频生成多个语义不同的音频音轨，从而实现更高的综合音频合成质量，优于现有基线方法。
## 587. `cs.LG` - CovDocker：基于任务、数据集和解决方案的共价药物设计基准 [PDF](https://arxiv.org/pdf/2506.21085), [HTML](https://arxiv.org/abs/2506.21085)
### Authors
Yangzhe Peng,Kaiyuan Gao,Liang He,Yuheng Cong,Haiguang Liu,Kun He,Lijun Wu
### Background
分子对接在预测配体与靶蛋白的结合模式中发挥着关键作用，共价相互作用由于其强而持久的结合特性，尤其有价值。然而，大多数现有对接方法和深度学习方法很少考虑共价键的形成及其相关结构变化。为了解决这一问题，我们提出了一个全面的共价对接基准CovDocker，旨在更好地捕捉共价结合的复杂性。我们将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过采用最先进的模型如Uni-Mol和Chemformer，我们建立了基线性能并展示了基准在准确预测相互作用位点及模型共价结合过程中分子的转变方面的有效性。这些结果强调了基准作为共价药物设计研究进展严格框架的角色，并突显数据驱动方法加速选择共价抑制剂发现及解决治疗开发中关键挑战的潜力。
### Innovation
我们提出了CovDocker基准，包含共价对接的任务分解、数据集和解决方案。我们分解了共价对接过程为反应位点预测、共价反应预测和共价对接三个主要任务。利用先进的模型如Uni-Mol和Chemformer，我们建立了基线性能并展示了基准的有效性，证明数据驱动方法在共价药物设计中的加速潜力。
### Conclusion
CovDocker基准作为共价药物设计研究的严格框架，展示了数据驱动方法在加速发现选择性共价抑制剂方面的潜力，也解决了治疗开发中的关键挑战。
## 588. `cs.LG` - EgoAdapt: 自适应多感知蒸馏和策略学习以实现高效第一人称感知 [PDF](https://arxiv.org/pdf/2506.21080), [HTML](https://arxiv.org/abs/2506.21080)
### Authors
Sanjoy Chowdhury,Subrata Biswas,Sayan Nag,Tushar Nagarajan,Calvin Murdock,Ishwarya Ananthabhotla,Yijun Qian,Vamsi Krishna Ithapu,Dinesh Manocha,Ruohan Gao
### Background
现代感知模型，尤其是为第一人称主观任务设计的多感知模型，取得了显著的性能，但经常伴随着巨大的计算成本。这些高需求在资源受限的环境中部署成为挑战，尤其是在现实世界的部署中。
### Innovation
本文提出了一种框架EgoAdapt，该框架通过自适应进行模态间蒸馏和策略学习，以实现不同第一人称感知任务（包括自主观动作识别、主动说话者定位和行为预测）的高效推理。本文提出的策略模块能够适配特定任务的动作空间，具有广泛的应用性。通过三个具有挑战性的第一人称数据集EPIC-Kitchens、EasyCom和Aria Everyday Activities的实验结果表明，EgoAdapt方法在提高效率的同时，还减少了相关先进技术模型的参数量和能量消耗，最多可减少89.09%的GMAC、82.02%的参数和9.6倍的能量。
### Conclusion
实验结果表明，EgoAdapt方法不仅在效率上显著提升，同时在多种任务上不亚于甚至超过当前最佳模型的表现。
## 589. `cs.LG` - 在大型语言模型中揭示因果推理：现实还是幻影？ [PDF](https://arxiv.org/pdf/2506.21215), [HTML](https://arxiv.org/abs/2506.21215)
### Authors
Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han
### Background
因果推理能力对于促进大型语言模型（LLMs）向强人工智能发展至关重要。尽管多功能的LLMs展示了对上下文因果关系的理解和遵从因果法则的响应能力，但不清楚它们是否真正进行了类似于人类的因果推理。现有证据表明，它们只能进行浅层（一级）因果推理，主要是因为嵌入在其参数中的因果知识，而缺乏进行真正的人类类似（二级）因果推理的能力。为支持这一假设，研究通过探讨基于变压器的LLMs的自回归机制，揭示其本质上不具备因果性。此外，引入了一个新的因果问答基准CausalProbe-2024，该基准的数据集新颖且未被研究的LLMs广泛接触，显示LLMs在CausalProbe-2024上的表现显著下降，表明它们主要进行一级因果推理。
### Innovation
提出了一种方法G^2-Reasoner，该方法将通用知识和目标导向的提示融入LLMs的因果推理过程中，以增强其因果推理能力，特别是在新颖和反事实场景中。通过这一方法，LLMs能够逐渐向二级因果推理迈进。
### Conclusion
这项工作揭示了LLMs向真正因果推理迈进的新途径，超越了一级推理，并开始向二级推理迈进。
## 590. `cs.LG` - 从链上到宏观：评估数据源多样性在加密货币市场预测中的重要性 [PDF](https://arxiv.org/pdf/2506.21246), [HTML](https://arxiv.org/abs/2506.21246)
### Authors
Giorgos Demosthenous,Chryssis Georgiou,Eliada Polydorou
### Background
本文研究了数据源多样性对加密货币预测模型性能的影响。通过整合技术指标、链上指标、情感与兴趣指标、传统市场指数和宏观经济指标等多种数据类别，探讨了不同数据源如何影响预测结果。文章引入了Crypto100指数（代表市值前100的加密货币），旨在识别源自不同数据源的最有效和最稳定特征。研究表明，数据源多样性显著提高了不同时间跨度内预测模型的预测性能。
### Innovation
文章提出了一种新的特征缩减算法，该算法从各种数据源中识别出最具影响力的和最稳定的特征。研究发现，链上指标对短期和长期预测都极其重要，而传统市场指数和宏观经济指标对长期预测尤为重要。利用多样性数据源显著提高了模型的准确性。这些发现有助于揭示加密货币市场的短期及长期驱动因素，并为开发更准确和更稳健的预测模型奠定了基础。
### Conclusion
研究结果表明，数据源多样性显著提高了加密货币预测模型的预测性能。链上指标在短期和长期预测中至为关键，而传统市场指数和宏观经济指标对长期预测尤其重要。多样化的数据源使用可以显著提升预测准确性。这些发现有助于推动加密货币市场的更精准预测。
## 591. `cs.LG` - 使用高效球形卡西厄分布的超球面变分自动编码器 [PDF](https://arxiv.org/pdf/2506.21278), [HTML](https://arxiv.org/abs/2506.21278)
### Authors
Lukas Sablica,Kurt Hornik
### Background
传统的变分自动编码器（VAE）通常使用高斯潜在空间或广泛使用的高斯-费希尔（vMF）分布。然而，这些分布不能很好地捕捉方向性数据，并且高斯分布可能会导致过度正则化，而vMF分布则存在数值不稳定的问题，尤其是计算归一化常数时容易出现Bessel函数相关的问题。因此，需要一种既能提供高效灵活的潜在表示，又能避免这些问题的新方法。
### Innovation
本文提出了一种新的VAE架构，采用球形卡西厄（spCauchy）潜在分布。spCauchy分布具有更自然的超球面表示，能够更好地捕捉方向数据并保持灵活性。它的厚尾性质可以防止过度正则化，提高潜在空间的效率利用，并提供更丰富的表示能力。相比vMF，spCauchy避免了数值不稳定性，可以通过莫比乌斯变换实现了可微和高效的重新参数化技巧，从而实现稳定的、可扩展的训练。通过快速收敛的级数计算KL散度，避免了与超几何函数相关比率的下溢或上溢问题。这些特性使spCauchy成为VAE的理想替代方案，既具有理论优势又具有实践效率，尤其适用于高维生成建模。
### Conclusion
这种基于spCauchy的新VAE架构提供了更有效的潜在表示和训练过程，使得在高维生成建模中具有更强的竞争力和实用性。
## 592. `cs.LG` - Small Encoders Can Rival Large Decoders in Detecting Groundedness [PDF](https://arxiv.org/pdf/2506.21288), [HTML](https://arxiv.org/abs/2506.21288)
### Authors
Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar
### Background
大型语言模型（LLMs）在自然语言处理（NLP）任务中的性能可以通过添加外部上下文来显著提升。然而，当提供的上下文不包含足够的信息时，LLMs往往只能依靠不实猜测或内部知识来回答查询，这导致其可靠性降低。确保生成的响应严格基于提供的上下文（即，被地化的）对于保证事实一致性与可信度至关重要。因此，作者探索了一种机制，可以在LLMs进行答案生成之前检测查询是否基于提供的上下文信息，从而显著减少推理时间和资源消耗。研究表明，使用RoBERTa和NomicBERT等轻量级、任务特定的编码器模型，在特定数据集上进行微调后，可以实现与最新的LLM（如Llama3 8B和GPT4o）相当的基于地化的检测准确性，同时大幅降低推理延迟时间
### Innovation
该研究展示了轻量级、专门任务的编码器模型（如RoBERTa和NomicBERT）通过在特定数据集上进行微调，在基于地化的检测中可以达到与最先进的大模型（如Llama3 8B和GPT4o）相当的准确性，且在推理延迟时间上有了数量级的降低
### Conclusion
轻量级编码器模型可以通过在特定数据集上的微调，在保证与大模型相当的准确性的前提下，极大地减少基于地化检测的推理延迟时间，对于提升大型语言模型的可靠性和效率有着重要的意义。
## 593. `cs.LG` - 低资源音乐生成中适配器设计权衡的探索 [PDF](https://arxiv.org/pdf/2506.21298), [HTML](https://arxiv.org/abs/2506.21298)
### Authors
Atharva Mehta,Shivam Chauhan,Monojit Choudhury
### Background
调优大规模音乐生成模型（如MusicGen和Mustango）是一个计算成本高昂的过程，通常需要对数十亿个参数进行更新，因此需要大量硬件资源。尽管参数高效微调（PEFT）技术，特别是基于适配器的方法，可以使得模型适应过程中的训练参数显著减少，但仍需深入探索适合特定低资源音乐类型的最佳适配器设计方法和原因。
### Innovation
本研究通过在两个AI音乐模型（MusicGen和Mustango）上研究不同配置的适配器，探索了基于卷积和基于变换器的适配器在不同音乐类型（印度斯坦古典音乐和土耳其玛卡姆音乐）中的效果和权衡。研究发现，基于卷积的适配器在捕捉细节方面表现出色，而基于变换器的适配器在保持长期依赖性方面效果更好。研究还分析了不同规模适配器的计算资源需求，表明中等规模的适配器（40M参数）在表达能力和质量之间取得了最佳平衡。此外，研究还发现Mustango在生成更多样化的输出方面表现更好，但稳定性较低，而基于自回归的模型MusicGen在训练速度和效率方面表现出色，尽管生成内容包含较高冗余度。
### Conclusion
本研究揭示了针对特定低资源音乐类型的最佳适配器设计方法和原因。基于卷积的适配器适合捕捉详细音乐元素，而基于变换器的适配器更适合于结构性即兴创作。针对不同的模型和音乐类型，适配器的最佳规模是中等的（约40M参数）。这为低资源下的高效音乐生成提供了新的视角。
## 594. `cs.LG` - 基于丰富音频特征和基于代理的错误校正的DCASE 2025挑战任务4空间语义分割性能提升 [PDF](https://arxiv.org/pdf/2506.21174), [HTML](https://arxiv.org/abs/2506.21174)
### Authors
Jongyeon Park,Joonhee Lee,Do-Hyeon Lim,Hong Kook Kim,Hyeongcheol Geum,Jeong Eun Lim
### Background
本技术报告介绍了DCASE 2025挑战任务4的提交系统。报告提出的方法通过对音频片段进行空间语义分割改进分类能力，特别是在声景S5系统中。该方法旨在通过结合额外的音频特征（光谱滚降和音阶特征）来改善音频标记模型的表现。由于混音音频中可能会包含难以通过梅尔谱图捕捉的细微线索，所以这些额外的特征为模型提供了不同视角。此外，还应用于S5系统的输出结果中的代理基于的标签校正系统减少了假阳性，进一步改善了CA-SDRi指标。最后，通过精炼训练数据集，去除无关样本并引入外部数据以提高低性能类别的分类准确度。
### Innovation
本文提出了引入丰富音频特征与基于代理的标签校正技术，以改进DCASE 2025挑战任务4中空间语义分割任务的性能。首先，通过结合额外的音频特征（光谱滚降和音阶特征）提升了分类性能；其次，应用基于代理的标签校正系统减少假阳性，提升了CA-SDRi指标；最后，通过优化训练数据集进一步提高了低性能类别的分类准确度。
### Conclusion
实验证明，应用这些方法后提交的系统相较于DCASE 2025挑战任务4的基线在CA-SDRi指标上取得了最多14.7%的提升。
## 595. `cs.LG` - Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection [PDF](https://arxiv.org/pdf/2506.21109), [HTML](https://arxiv.org/abs/2506.21109)
### Authors
Luosheng Xu,Dalin Zhang,Zhaohui Song
### Background
遥感变迁检测对于城市扩张监测、灾害评估和资源管理至关重要，能够提供及时、准确和大规模的动态景观变换洞察。尽管深度学习在变迁检测方面取得了革命性的进步，但现代模型的复杂性和计算需求往往并没有转化为显著的准确性提升。相反，本研究探索了一种更为高效的方法，即使用轻量级模型以维持高精度并最大限度地减少资源消耗，这对于在卫星上处理至关重要。现代的复杂模型计算需求和资源消耗之间的权衡仍然是亟待解决的问题。
### Innovation
本研究提出了FlickCD，一种快速筛选然后获得卓越结果的方法。FlickCD通过引入增强差异模块（EDM），放大关键时间阶段特征差异同时抑制无关变化（如光照和天气变化），从而在后续的变分解码器中降低计算成本。FlickCD还结合了局部-全局融合块，利用移位窗口自注意力（SWSA）和增强全局自注意力（EGSA），有效捕捉多尺度语义信息，保护了粗粒度和细粒度变化。实验结果表明，FlickCD在四个基准数据集上的计算和存储开销减少了10倍以上，达到或接近最先进的性能，F1分数仅下降了不到1%。
### Conclusion
本研究通过FlickCD展示了在资源消耗和计算效率之间表现出色的性能对比，推动了这项技术的发展。FlickCD在保持高精度的同时大幅减少了计算和存储开销，是遥感变迁检测领域的创新成果。
## 596. `cs.LG` - 基于可学习自适应时频表示的可微短时傅里叶变换 [PDF](https://arxiv.org/pdf/2506.21440), [HTML](https://arxiv.org/abs/2506.21440)
### Authors
Maxime Leiber,Yosra Marnissi,Axel Barrau,Sylvain Meignen,Laurent Massoulié
### Background
短时傅里叶变换（STFT）广泛应用于非平稳信号分析，但其性能高度依赖于参数设置，手动或启发式调参通常效果欠佳。传统STFT参数调优方法往往依赖于计算密集型的离散搜索，这限制了STFT参数的精细调整。因此，需要一种能够基于任何所需标准进行细调并无缝集成到神经网络中的STFT方法，以优化STFT参数和网络权重，并提高下游任务的性能。
### Innovation
提出了一种统一的可微STFT公式，可基于梯度优化其参数，解决了传统方法依赖于计算密集型离散搜索的局限性，并允许针对任何预期标准对时间-频率表示（TFR）进行精细调整。此外，该方法能够与神经网络无缝集成，实现在优化STFT参数和网络权重的同时提升TFR质量及下游任务性能的目标。
### Conclusion
通过在模拟和真实数据上的实验表明，所提出的可微STFT能有效提升TFR，并改善下游任务的性能。
## 597. `cs.LG` - 关于均匀加权深层多项式逼近 [PDF](https://arxiv.org/pdf/2506.21306), [HTML](https://arxiv.org/abs/2506.21306)
### Authors
Kingsley Yeon,Steven B. Damelin
### Background
在有理逼近理论中，一些非光滑或奇异函数，例如$|x|$和$x^{1/p}$，可以通过具有根指数收敛特性的有理函数有效逼近。相比之下，多项式逼近仅通过Jackson定理中的代数收敛率收敛。最近的研究表明，即使没有光滑性，复合多项式架构也可以恢复指数逼近率。本文通过引入和分析一种新型加权深层多项式逼近方法，以处理单边增长而另一方面衰减的非对称函数行为，这些方法能捕捉局部非光滑性和全局增长特性。实验结果表明，该框架在参数相同的情况下，优于Taylor、Chebyshev和标准深层多项式逼近方法。为了优化这些逼近方法，本文提出了一种基于.previous工作的稳定图基参数化策略来进行实际优化。
### Innovation
提出了针对具有非对称行为的函数（单边增长，而另一方面衰减）的加权深层多项式逼近方法，通过组合可学习的深层多项式与单边权重实现全局增长和局部非光滑性的捕捉。在此基础上，提出了一种稳定的图基参数化策略，使实际优化成为可能。
### Conclusion
通过引入加权深层多项式逼近方法，可以更好地逼近具有非对称行为的函数，并且在参数数量相同的条件下，实验结果表明该方法优于其他传统的多项式逼近方法。所提出的优化策略为这些逼近方法的实际应用提供了一种稳定的方法。
## 598. `cs.LG` - 具有量子记忆和局部学习的随机量子脉冲神经网络 [PDF](https://arxiv.org/pdf/2506.21324), [HTML](https://arxiv.org/abs/2506.21324)
### Authors
Jiechen Chen,Bipin Rajendran,Osvaldo Simeone
### Background
神经形态计算和量子计算作为推进人工智能的有前途的范式，各自提供互补的优势。基于脉冲神经元的神经形态系统能够高效地处理时间序列数据，仅在输入事件时消耗能量。而量子计算利用叠加态和纠缠来探索随着量子比特数量增加呈指数级扩大的特征空间。现有的结合这两种范式的混合方法已经开始显示出潜力，但现有的量子脉冲模型存在重要限制，比如依赖于单量子比特的经典记忆机制，需要重复测量来估算放电概率，并且在经典模拟器中使用传统的反向传播进行训练。
### Innovation
本文提出了一个随机量子脉冲（SQS）神经元模型，解决了上述挑战。SQS神经元利用多量子比特量子电路实现具有内部量子记忆的脉冲单元，能够在单次操作中产生事件驱动的概率性脉冲。此外，还详细说明了SQS神经元网络（SQSNN）可以通过硬件友好的局部学习规则进行训练，无需使用全局经典反向传播。SQSNN模型将神经形态计算的时间序列效率与量子计算的指数级内部状态空间结合，为量子脉冲神经网络提供了模块化、可扩展且能够在量子硬件上训练的方法。
### Conclusion
提出的SQSNN模型将时间序列处理的效率与量子计算的指数级状态空间结合起来，展示了模块化、可扩展且能够在量子硬件上进行训练的量子脉冲神经网络潜力。
## 599. `cs.LG` - Wild refitting for black box prediction [PDF](https://arxiv.org/pdf/2506.21460), [HTML](https://arxiv.org/abs/2506.21460)
### Authors
Martin J. Wainwright
### Background
该论文描述了一种基于最小二乘最小化和核方法的调制非参数估计的高概率上界计算方法。它仅使用单个数据集和对预测方法的黑箱子访问权限，并包含三个步骤：计算合适的残差，使用预因子ρ对它们进行对称化和缩放，并用它们来定义并解决一个重新定心于当前估计值的修改预测问题。这种方法广泛应用，包括非刚性结构重建、基于深度神经网络先验的图像恢复、和随机草图方法等。
### Innovation
论文提出了一种有效的重新拟合程序，可以计算基于最小二乘最小化的惩罚非参数估计的实例平均预测误差的高概率上界。该方法允许噪声异方差性，并提供了选定合适放缩噪声尺度的鲁棒性保证，适用性强，设计灵活。这种方法能够在存在噪音的情况下精确估计预测误差，意味着该方法在对模型性能评估方面具有创新性。
### Conclusion
论文通过相对宽松的条件证明了该重新拟合程序的有效性，它不仅适用于多种场景，还能精确地估计预测误差的上限，并提供了针对各种预测问题的适应性设计方案。该方法在实际应用中是非常有用的，特别是对于涉及黑箱预测方法的复杂问题。
## 600. `cs.LG` - 每日交通流量的红绿灯评价 [PDF](https://arxiv.org/pdf/2506.21469), [HTML](https://arxiv.org/abs/2506.21469)
### Authors
Mohammad Shokrolah Shirazi,Hung-Fu Chang
### Background
转向量数据对于交通信号设计、交叉口几何规划、交通流和拥堵分析至关重要。本文基于转向量（TMC）交通信号提出三种方法：动态、静态和混合配置。利用交通摄像头开发了一种基于视觉的跟踪系统，估计了拉斯维加斯六个交叉口的转向量。初步实验结果表明，90秒和120秒的周期时间适用于所有交叉口。由于日常交通流量往往表现出双峰模式，本文提出了一种混合信号方法，以在高峰和低峰交通条件下转换动态和静态信号配置，改善流量管理。
### Innovation
提出了一种基于视觉的跟踪系统来估计交叉口的转向量；首次提出了动态、静态和混合信号配置，适应特定交通条件；建立了交通生成模块和信号设计模块，根据不同的交通情况生成不同的信号周期；采用基于区域的交通流量分布来影响信号配置的选择。
### Conclusion
初步结果显示90秒和120秒的信号周期适用于所有测试交叉口。动态信号配置在四个交叉口中表现较好，另外两个交叉口则在交通分布差距较大的区域内工作不佳。基于地区导向的交通流量分布可以选择不同的信号设计方法。静态方法适用于区域交通分布均衡的情况，而混合方法则适用于区域交通流量明显偏向一侧的情况。
## 601. `cs.LG` - 基于条件标记点过程的可靠空域检测：物体检测 [PDF](https://arxiv.org/pdf/2506.21486), [HTML](https://arxiv.org/abs/2506.21486)
### Authors
Tobias J. Riedlinger,Kira Maag,Hanno Gottschalk
### Background
深度神经网络在计算机视觉任务如边界框检测和语义分割中设置了最新标准。检测器和分割模型通过置信度评分反映检测或像素分类的不确定性，但这些估计常常是失真的，因为其架构和损失函数更侧重于任务性能而非概率基础。即使置信度估计可靠，检测器也无法量化检测框以外区域的不确定性，即模型不能评估未检测区域是否真正无物体。这对于自动驾驶等应用存在安全风险，因为在空旷区域的不确定性未被探索。
### Innovation
本文提出了一种基于空间统计的物体检测模型，利用标记点过程描述边界框中心的检测概率事件，使用标记描述边界框的空间扩展及类别。通过统计框架提供最大似然训练，给出区域是否可通行（无物体）的可靠置信度估计。
### Conclusion
通过校准评估和性能评估，验证了方法的有效性。
## 602. `cs.LG` - 一个适用于多种场景的地下矿工检测的综合数据集 [PDF](https://arxiv.org/pdf/2506.21451), [HTML](https://arxiv.org/abs/2506.21451)
### Authors
Cyrus Addy,Ajay Kumar Gurumadaiah,Yixiang Gao,Kwame Awuah-Offei
### Background
地下采矿作业面临显著的安全挑战，紧急应对能力至关重要。虽然机器人在辅助搜索和救援操作中展现出了潜力，但它们的有效性依赖于可靠的矿工检测能力。深度学习算法为自动化矿工检测提供了潜在解决方案，但当前缺乏适用于地下采矿环境的全面训练数据集。
### Innovation
本文提出了一个专门为地下矿工检测开发和验证系统设计的新型热成像数据集。该数据集系统地收集了各种采矿活动和场景的热图像，为检测算法提供了坚实的基础。同时，评估了几种最先进的目标检测算法（包括YOLOv8、YOLOv10、YOLO11和RT-DETR），以建立基线性能指标。这项工作证明了使用热成像进行矿工检测的可行性，并为这一关键安全应用的未来研究奠定了基础。
### Conclusion
尽管这个数据集并未覆盖所有可能的紧急情况，但它作为开发可靠基于热成像的矿工检测系统的关键第一步具有重要意义，这些系统最终可以部署在真实的紧急情况下。
## 603. `cs.LG` - 从用户交互中对语音对话模型进行对齐 [PDF](https://arxiv.org/pdf/2506.21463), [HTML](https://arxiv.org/abs/2506.21463)
### Authors
Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez
### Background
目前，偏好学习方法主要集中在基于文本的语言模型上，这些方法难以适应实时语音交互的复杂性，如打断、插话等丰富动态，且没有显式的说话人分割。因此，需要一种能够处理这些复杂性的新的偏好对齐框架，以提升实时对话中语音模型的表现。研究者为此创建了一个包含超过150,000个偏好配对的大规模数据集，来自原始多轮语音对话并由AI反馈标注，覆盖语言内容和时间上下文的变化。现有的实时对话系统要想自然、流畅，对于各种动态的平衡至关重要。
### Innovation
提出了一种新的偏好对齐框架，用于实时语音对话系统的改进。此框架大量使用了非实时数据的偏移对齐方法，通过这些方法微调了一个全双工信噪比语音转语音模型。实验表明，这些模型在生成更为事实、更安全以及更上下文一致性对话方面具有明显优势。此外，研究者还采用了全面的人机评估方法，超越了一轮对话的评估，着重于整体对话效果。这些发现揭示了在实现自然实时对话系统时，需精心平衡各种动态的重要性。
### Conclusion
此研究通过一个大规模数据集和实验证明了从用户交互中对齐语音对话模型的有效性。大规模数据集和精细的偏好对齐方法是提升实时对话系统性能的关键。研究的结果强调了各动态在构建自然实时对话系统中不可或缺的平衡作用，这一发现对未来相关领域的发展具有重要启示。
## 604. `cs.LG` - 高斯不变马尔可夫蒙特卡洛方法 [PDF](https://arxiv.org/pdf/2506.21511), [HTML](https://arxiv.org/abs/2506.21511)
### Authors
Michalis K. Titsias,Angelos Alexopoulos,Siran Liu,Petros Dellaportas
### Background
研究者开发了一种基于高斯不变性的采样方法，包括改进的随机游走马尔可夫（RWM）、调整拉格朗日算法（MALA）以及Hessian或流形MALA的第二阶版本。这些方法与标准的RWM和MALA不同，能够在高斯目标中获得更有效的统计估计量。这是因为高斯不变性具有使人们可以对高斯目标求解精确的泊松方程的显著特性。利用这些解决方案，可以构建用于减少非解析目标估计量方差的控制变量。在多个示例中展示了这些新采样器和估计器，包括高维潜隐高斯模型，实现了最先进结果，并探讨了几何遍历性和最优缩放分析。
### Innovation
开发了基于高斯不变性的新采样方法，并展示了与标准方法相比，可获得更有效的统计估计量。这得益于高斯不变性带来精确泊松方程解的能力，使得可以构建高效的控制变量以减少方差。研究还在高维潜隐高斯模型中实现了先进结果，并提供了几何遍历性和最优缩放分析，揭示了最优接受率随目标高斯性变化的关系。
### Conclusion
所提出的采样方法和估计器在多个实例中实现了最优结果，验证了其效能。还提供了关于几何遍历性及最优缩放分析的理论结果，表明最优接受率与目标高斯性的关系。
## 605. `cs.LG` - 持续学习作为受计算约束的强化学习 [PDF](https://arxiv.org/pdf/2307.04345), [HTML](https://arxiv.org/abs/2307.04345)
### Authors
Saurabh Kumar,Henrik Marklund,Ashish Rao,Yifan Zhu,Hong Jun Jeon,Yueyang Liu,Benjamin Van Roy
### Background
持续学习对于开发能够在长期生命周期中积累知识并不断提高技能的人工智能代理至关重要，这有望推进人工智能能力的边界。然而，如何设计这样的代理仍然是人工智能领域的一个长期挑战。持续学习作为应对这一挑战的学科，致力于解决代理在长时间段内持续学习和适应的问题。本文旨在阐明和正式化持续学习的概念，并通过构建框架和工具来激发进一步的研究。
### Innovation
本文提出了持续学习的一种新视角，将其视为受计算约束的强化学习。这为理解代理在有限资源条件下如何进行高效学习提供了新的思路，并可能推动相关领域的研究进展。
### Conclusion
通过构建持续学习的框架和工具，本文为进一步研究奠定了基础，有助于该领域未来的发展，同时也为提高代理的长期学习能力提供了新的途径。
## 606. `cs.LG` - 最大匹配至关重要：防止表示坍缩以增强跨模态检索的鲁棒性 [PDF](https://arxiv.org/pdf/2506.21538), [HTML](https://arxiv.org/abs/2506.21538)
### Authors
Hani Alomari,Anushka Sivakumar,Andrew Zhang,Chris Thomas
### Background
跨模态图像-文本检索由于不同模态内容之间可能存在多种不同的关联而具有挑战性。传统方法使用单个向量嵌入来表示每个样本的语义，难以捕捉模态间存在的细微和多样的关系。集合式方法通过为每个样本使用多个嵌入来表示，有望捕捉到更丰富和多样的关系。尽管集合式方法具有一些优势，但它们仍然面临稀疏监督和集合作用坍缩问题，这限制了它们的有效性。因此，需要改进来解决这些问题，特别是在最大化集合内语义多样性的一对一匹配方面。
### Innovation
本文提出的Maximal Pair Assignment Similarity优化了一对一嵌入集合之间的匹配，同时防止表示坍缩。此外，引入了两个损失函数：全局辨别损失以增强各嵌入之间的区分能力，以及集内偏差损失以防止每个集合内部的坍缩。
### Conclusion
本文方法在MS-COCO和Flickr30k数据集上取得了最先进的性能，同时无需依赖外部数据来实现这一目标。
## 607. `cs.LG` - 在机器学习中平衡隐私、稳健性和效率 [PDF](https://arxiv.org/pdf/2312.14712), [HTML](https://arxiv.org/abs/2312.14712)
### Authors
Youssef Allouah,Rachid Guerraoui,John Stephan
### Background
本文指出，在现有的威胁模型下，同时在机器学习系统中实现稳健性、隐私和效率是不可行的。这种目标之间的张力并非来源于算法的不足，而是源于最坏情况下的 adversarial 假设所带来的结构性限制。
### Innovation
论文倡导系统的研究议程，旨在正式化稳健性-隐私性-效率三者的困境，探索如何通过对威胁模型的原理性放宽来解锁更好的权衡，以及设计能够暴露而不是掩盖妥协的基准。通过将注意力从理想的通用保障转移到情境感知的系统设计，机器学习社区可以构建真正适用于实际部署的模型。
### Conclusion
通过从理想化的通用保障转向情境感知的系统设计，机器学习社区能够构建真正适合实际部署的模型。
## 608. `cs.LG` - 全身条件控制下的第一人称视角视频预测 [PDF](https://arxiv.org/pdf/2506.21552), [HTML](https://arxiv.org/abs/2506.21552)
### Authors
Yutong Bai,Danny Tran,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik
### Background
研究人员致力于通过给定过去视频和由相对3D人体姿势表示的动作，训练模型预测以第一人称视角为中心的视频（PEVA）。通过根据身体的关节层次结构组织运动，模型学会了模拟物理人类动作如何从第一人称的角度改变环境。该研究通过在大规模现实世界第一人称视频和身体姿态捕获数据集Nymeria上训练自回归条件扩散变换器，并进一步设计了具有递进挑战的层次评估协议，对模型的具身预测和控制能力进行了全面分析。这项工作代表了从人类视角出发建模复杂真实环境和具身代理行为的一项初步尝试。
### Innovation
该研究工作创新性地利用条件扩散变换器在Nymeria大規模真实世界第一人称视频和身体姿态捕获数据集上下文中训练模型。同时，设计了具有递进挑战的层次评估协议，评估模型的具身预测和控制能力。
### Conclusion
研究工作代表了利用视频预测从人类视角构建复杂真实环境和具身代理行为的一项初步尝试，解决了由此带来的挑战，为后续研究提供了重要的参考和基础。
## 609. `cs.LG` - HalluSegBench: 反事实视觉推理用于分割幻觉评估 [PDF](https://arxiv.org/pdf/2506.21546), [HTML](https://arxiv.org/abs/2506.21546)
### Authors
Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou
### Background
近年来，视觉语言分割领域的进展极大地推动了基于图像的理解。然而，现有的模型往往会生成与图像内容不相关的分割掩码，或者错误地标记无关区域，这种现象称为幻觉。当前的评估协议主要关注标签或文本幻觉，但没有操纵可视上下文，导致其诊断关键错误的能力有限。
### Innovation
本文提出了HalluSegBench，这是首个专门用于通过反事实视觉推理评估分割幻觉的基准。它包含了一个全新的数据集，包含1340个反事实实例对，涵盖了281个独特的对象类别，并引入了一组新的度量标准来量化在视觉一致场景编辑下幻觉敏感性的程度。实验表明，由视觉驱动的幻觉比由标签驱动的更普遍，模型往往会持续错误分割，这突显了需要通过反事实推理来诊断定位准确度的必要性。
### Conclusion
我们的研究表明，视觉驱动的幻觉相较于标签驱动的更为普遍，并且模型中经常存在持续错误分割的问题，这表明通过反事实推理对分割准确度进行诊断的重要性。
## 610. `cs.LG` - transformers 的 next-token 预测容量：一般的上限和最低界限 [PDF](https://arxiv.org/pdf/2405.13718), [HTML](https://arxiv.org/abs/2405.13718)
### Authors
Liam Madden,Curtis Fox,Christos Thrampoulidis
### Background
任务是给定一系列标记（如词汇），预测下一个标记的概率分布。解码器-only 的变压器已经成为这一任务的有效模型，但他们的特性还不够清楚。特别地，解码器-only 的变压器能够插值下一个标记分布的最大不同上下文序列数量尚未建立。为了解决这个问题，本研究提出了上下文序列数量的上界和下界。这些边界在下一个标记分布可以是任意的，以及从有限数量的文档序列中计算分布的情况下都是适用的。研究还提供了单层多头解码器-only 变压器的下界，并强调了自我注意的一个重要函数性质。进一步的数值证据表明，最小数量的参数对于从熵下界训练模型是足够的。
### Innovation
证明了解码器-only 变压器能够插值下一个标记分布的最大不同上下文序列的上界和下界，这些界在不同情况下都是适用的。首次提供单层多头解码器-only 变压器的下界，并强调了自我注意的一个重要函数性质。通过数值证据表明，最小数量的参数对于从熵下界训练模型是足够的。
### Conclusion
研究证明了解码器-only 变压器能够处理的最大不同上下文序列的数量，给出了适用的不同情况下的上限和下界。更重要的是，这一研究还强调了自我注意的重要函数性质，并通过最小数量的参数能够达到熵下界来支持其结论。
## 611. `cs.LG` - 公平准确：在线讨论中公平感知的多组目标检测 [PDF](https://arxiv.org/pdf/2407.11933), [HTML](https://arxiv.org/abs/2407.11933)
### Authors
Soumyajit Gupta,Maria De-Arteaga,Matthew Lease
### Background
目标群体检测是识别社交媒体帖子旨在“针对或描述”哪个群体的任务，应用于诸如定向营销等多种场景下。由于毒性很大程度上依赖于帖子所针对的群体，语言在特定背景下可能会因针对特定的人口统计学群体而变得有害，因此检测帖子旨在针对哪个群体是区分帖子是否具有毒性的重要前提步骤。这项任务也颇具挑战性：帖子可能同时针对多个群体，确保公平地检测这些群体是减轻不同群体之间偏见的关键。
### Innovation
提出了旨在‘公平感知的多目标群体检测’的方法，不仅有效减少了针对不同群体的偏见，还在预测性能上取得了竞争性的表现，优于现有的公平感知基准方法。本工作中还提供了相关代码以推进未来的研究并支持基准测试。
### Conclusion
该研究强调了公平感知多目标群体检测的重要性，并展示了该方法的有效性及建树的公平性，为进一步研究此领域提供了支持。
## 612. `cs.LG` - skLEP：斯洛伐克通用语言理解基准 [PDF](https://arxiv.org/pdf/2506.21508), [HTML](https://arxiv.org/abs/2506.21508)
### Authors
Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko
### Background
当前存在对斯洛伐克自然语言理解（NLU）模型的评估缺乏专门且全面的标准问题集的状况。这篇文章中，作者们介绍了skLEP，这是首个针对斯洛伐克NLU模型的综合基准。skLEP覆盖了九个不同的任务，涉及标记层级、句子配对层级和文档层级的挑战，旨在全面评估模型能力。为了创建这个基准，作者们整理了新的原始斯洛伐克语数据集，并仔细翻译了现有的英语NLU资源以适应斯洛伐克语环境。文章还系统地评估了多种斯洛伐克特定、多语言及英语预训练语言模型在skLEP任务上的表现，为斯洛伐克NLU领域的后续研究奠定了基础。
### Innovation
文章首次提出了skLEP，这是一个专门针对斯洛伐克自然语言理解模型的综合基准。skLEP包含九个不同层面的任务，涵盖了从标记层级到文档层级的广泛挑战，提供了一个全面评估模型能力的框架。此外，作者们还细致地整理和翻译了新的原始斯洛伐克语数据集以及标准的英语NLU资源，增强了基准的适用性和公正性。文章还展示了第一项针对多种类型语言模型（包括斯洛伐克特定、多语言和英语预训练模型）在skLEP任务上的系统性评估。最后，作者们公开了基准数据、开源工具包以促进模型的调优与评估，并提供了一个公开排行榜，旨在推动斯洛伐克自然语言理解研究的透明性和可重复性。
### Conclusion
文章总结了skLEP基准的创建与评估过程，展示了在斯洛伐克自然语言理解模型上的广泛研究，并且开源了数据集和工具包，以及公开排行榜，以期推动该领域的 reproducibility（可重复性）和进一步的研究。
## 613. `cs.LG` - 探索3D MLLMs的CT报告生成设计空间 [PDF](https://arxiv.org/pdf/2506.21535), [HTML](https://arxiv.org/abs/2506.21535)
### Authors
Mohammed Baharoon,Jun Ma,Congyu Fang,Augustin Toma,Bo Wang
### Background
多模态大型语言模型（MLLMs）已展现出自动化放射学报告生成（RRG）的潜力。本文系统地研究了3D MLLMs的设计空间，涵盖了视觉输入表示、项目器、大型语言模型（LLMs）以及3D CT报告生成的微调技术。此外，还提出了两种基于知识的报告增强方法，这些方法在GREEN分数上提高了多达10%，并在2024年MICCAI AMOS-MM挑战赛中获得第2名。在AMOS-MM数据集的1,687个病例上，研究结果表明，在相同的训练协议下，LLM的大小对RRG的影响有限。研究还表明，如果原始ViT在较小体积尺寸上预训练，则较大的体积尺寸并不总是提升性能。最后，通过使用分割掩码和CT体积结合的方式可以提升性能。代码已公开并在指定链接中可获取。
### Innovation
本研究通过探索3D MLLMs在CT报告生成中的设计空间，提出了两种基于知识的报告增强方法，显著提升了GREEN分数，展示了在特定训练协议下LLM的大小对报告生成效果的影响，及CT体积预训练对于模型性能的影响，并进一步展示了利用分割掩码结合CT体积的方法对提升报告生成性能的有效性。
### Conclusion
本文研究表明，对于3D CT报告生成，LLM的大小在相同训练协议下对报告生成的影响有限，大体积不一定总是提升性能，而结合分割掩码可以显著改善报告生成的效果。此外，所提出的知识增强方法显著提高了报告的质量和自动生成的准确性。研究结果为未来的3D MLLMs在医疗影像分析与报告生成中的应用提供了新的设计思路。
## 614. `cs.LG` - 快速陀螺仪校准：一种深度学习方法 [PDF](https://arxiv.org/pdf/2409.00488), [HTML](https://arxiv.org/abs/2409.00488)
### Authors
Yair Stolero,Itzik Klein
### Background
低价格陀螺仪的校准对于确保陀螺仪测量的准确性和可靠性至关重要。站姿校准估计测量误差中的确定性部分，通常的做法是在预定时间段内平均陀螺仪读数以估算陀螺仪偏移。校准时间长度对性能至关重要，因此更长的校准时间更受欢迎。然而，一些应用需要快速启动时间，因此只允许短暂的校准时间。
### Innovation
本文重点是利用深度学习方法减少低价格陀螺仪的校准时间。提出了端到端卷积神经网络应用于陀螺仪校准。探索了使用多个真实和虚拟陀螺仪以提高单个陀螺仪校准性能的可能性。为训练和验证方法，记录了一个包含186.6小时陀螺仪读数的数据集，并使用了4个品牌共计36个低价格陀螺仪，还创建了一个虚拟数据集。其中一个主要成就是在使用三个低价格陀螺仪的情况下，将陀螺仪校准时间降低了最高89%。
### Conclusion
所提出的数据集已公开发布，以实现本研究的再现性，并增加该领域的研究。
## 615. `cs.LG` - 在线鞍点问题的近似点法 [PDF](https://arxiv.org/pdf/2407.04591), [HTML](https://arxiv.org/abs/2407.04591)
### Authors
Qing-xin Meng,Jian-wei Liu
### Background
本文聚焦于在线鞍点问题，涉及一系列具有时间变化特征的双人凸凹博弈序列。考虑到环境的非稳定性，本文采用对偶间隙和动态纳什均衡后悔作为算法设计的性能指标。文章提出了三种近似点法的变种，包括在线近似点法（OPPM）、乐 观 OPAM（OptOPPM）以及带多个预测器的 Opotpmp。每种算法都保证了对偶间隙和动态纳什均衡后悔的上界，在与对偶间隙的测量中达到了近最优性。在某些 benign 的环境中，如固定收益函数序列，这些算法能够保持近常数的指标上界。实验证明了这些算法的有效性。
### Innovation
1. 提出了针对在线鞍点问题的近似点法及其三种变种算法。2. 提出了对偶间隙和动态纳什均衡后悔作为算法设计的性能指标。3. 确保所提算法在特定环境下的近最优性，并通过实验验证了其有效性。
### Conclusion
本文讨论了使用动态纳什均衡后悔作为性能指标后可能带来的一些可靠性问题。相关的技术附录与代码可以在给定的链接找到。
## 616. `cs.LG` - GREAT 架构用于类似于TSP的基于边的图问题 [PDF](https://arxiv.org/pdf/2408.16717), [HTML](https://arxiv.org/abs/2408.16717)
### Authors
Attila Lischka,Filip Rydin,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár
### Background
近年来，许多基于学习的方法被提出以解决诸如路由问题这类组合优化问题，这些方法大多基于图神经网络（GNNs）或相关变压器，并在表示路由问题的欧几里得坐标上运作。然而，此类模型在现实世界中经常遇到的非欧几里得、不对称问题实例上表现不佳。为了克服这一限制，我们提出了一种名为Graph Edge Attention Network (GREAT) 的新GNN基础和基于边的神经模型。将GREAT用作编码器，以捕获路由问题实例的特性，我们构建了一个强化学习框架，该框架应用于诸如旅行商问题、带容量约束的车辆路由问题和导向问题等欧几里得和非欧几里得版本的车辆路线问题。这是第一个解决这些非欧几里得变体问题的学习基准求解器之一，并实现了具有竞争力的结果。
### Innovation
我们提出了一种名为Graph Edge Attention Network (GREAT) 的新GNN基础和基于边的神经模型，用于解决非欧几里得、不对称问题实例。我们构建了一个框架，该框架应用到包括旅行商问题、带容量约束的车辆路由问题和导向问题等欧几里得和非欧几里得版本的车辆路线问题。这是第一个解决这些非欧几里徵变体问题的学习基准求解器之一，并实现了具有竞争力的结果。
### Conclusion
我们的框架在学习基于求解器中取得了具有竞争力的结果，并且是第一个解决这些非欧几里得变体问题的实例。
## 617. `cs.LG` - 通过ReLU多层感知机的最优近似最大化正则性弥合拟合与学习差距 [PDF](https://arxiv.org/pdf/2409.12335), [HTML](https://arxiv.org/abs/2409.12335)
### Authors
Ruiyang Hong,Anastasis Kratsios
### Background
深度学习的基础是由逼近论或学习理论的不同观点支撑的，二者分别强调大/表达能力强的模型不必泛化，以及能泛化的模型可能过于狭小或受限以致不能作为普遍逼近器。受现实世界中既表达能力强且统计上可靠的深度学习实现的启发，本文提出了一个问题：是否存在既大到能够进行普遍逼近但又结构化到可以泛化的神经网络类？
### Innovation
本文通过识别一组具有特定结构的ReLU多层感知机（MLPs），这些MLPs既是优化函数逼近器，同时在统计上行为良好。文章证明了任何 $(L,frac{frac{text{指数}d}{text{幂} frac{d}{text{指数}}},n})$-霍尔德函数可以通过少量连接的ReLU MLP以 $text{指数}n$ 的误差精确逼近，这组MLP具有 $text{指数}dn^{frac{d}{text{指数}}}$ 的宽度、$text{指数}text{对数}(d)$ 的深度和 $text{指数}dn^{frac{d}{text{指数}}}$ 的非零参数数量，并且其权重和偏置（除了第一和最后一层）的值在 $text{集合}text{0,}text{±1/2}$ 中。此外，以新的构建方法实现了最优的样本复杂度 $text{指数}(frac{text{日志}(N)}{text{根号}N})$，当给定 $N$ 个独立同分布的归一化超高斯训练样本时。
### Conclusion
我们的结果表明，神经网络可以解决麦克夏恩扩张问题，在合适的有限集合上。
## 618. `cs.LG` - 高斯测度下学习Lipschitz算子的样本复杂度 [PDF](https://arxiv.org/pdf/2410.23440), [HTML](https://arxiv.org/abs/2410.23440)
### Authors
Ben Adcock,Michael Griebel,Gregor Maier
### Background
近年来，操作学习在无穷维函数空间之间的映射表示方面取得了越来越多的研究关注，并被用来作为计算科学和工程问题的高效替代模型。然而，尽管在实践中取得了成功，但我们对其中的数学理论理解仍然不完整。本文研究了Gaussian测度下的Lipschitz算子逼近问题，证明了Lipschitz算子的更高Gaussian Sobolev正则性，并建立了广义多项式逼近误差的上下界。
### Innovation
本文研究特别聚焦于通过m个任意的（潜在适应性的）线性样本重建Lipschitz算子的一般策略。主要发现是细致地刻画了相应的样本复杂性，即所有可能的（适应性）采样和重建策略下可实现的最坏情况误差的最小值，这一点与样本数m的关系。研究结果表明，基于m个线性样本的任何方法都不能实现代数收敛率。然而，证明了如果主导Gaussian测度的协方差算子具有足够快的谱衰减，则可以实现任意接近代数收敛率的收敛率。
### Conclusion
通过细致刻画样本复杂性，本文确认了学习Lipschitz算子的固有难度，无论数据或学习技术如何。
## 619. `cs.LG` - Chain-of-Sketch: 使全局视觉推理成为可能 [PDF](https://arxiv.org/pdf/2410.08165), [HTML](https://arxiv.org/abs/2410.08165)
### Authors
Aryo Lotfi,Enrico Fini,Samy Bengio,Moin Nabi,Emmanuel Abbe
### Background
现代视觉模型在需要局部特征提供目标关键信息的基准测试中取得了显著成功。然而，越来越多的研究关注更需要全局推理的任务，而局部特征在这些任务中并不提供重要信息。Minsky和Papert在1969年通过他们的连接性研究提出了这类任务，揭示了感知器模型的局限性。现有的大型视觉模型和最先进的多模态LLM在这类任务上表现不佳。研究表明，原因是‘全局性程度’的不足。为解决这一问题，本文提出了一种名为‘链式草图’（CoS）的方法，将其与语言模型中的链式思考和涂板技术进行类比，将原始任务分解为中间视觉步骤，有助于学习复杂的任务。此外，研究还表明并非所有CoS策略都表现一致，关键洞察是给CoS帧引入马尔可夫结构，从而提出了‘归纳性CoS’，它在分布外泛化方面表现更好，且即使在较小的模型上也表现良好，优于非归纳性变体。
### Innovation
本文引入了一个名为‘链式草图’（CoS）的新方法，它通过将复杂的任务分解为中间视觉步骤，帮助学习全局性任务。此外，研究还特别强调了通过给CoS帧引入马尔可夫结构来改进全局性，从而提出了‘归纳性CoS’策略，该策略在分布外泛化方面表现更好，并能在较小的模型上实现良好的性能。
### Conclusion
研究展示了大型视觉模型和最先进的多模态LLM在需要全局推理的任务上表现不佳的原因，并提出了一种名为‘链式草图’的解决方案。通过将任务分解为视觉中间步骤，并使用马尔可夫结构改进，本文提出的方法在全局推理任务上表现更佳，即使是在较小的模型上也能实现较好的泛化性能。
## 620. `cs.LG` - HyperINF: Unleashing the HyperPower of the Schulz's Method for Data Influence Estimation [PDF](https://arxiv.org/pdf/2410.05090), [HTML](https://arxiv.org/abs/2410.05090)
### Authors
Xinyu Zhou,Simin Fan,Martin Jaggi
### Background
影响函数提供了一种评估单个训练样本对特定目标贡献的原理性方法，但其高计算成本限制了在大规模模型和数据集上的应用。现有方法虽已显著降低了计算开销，但大多因缺乏算法的强收敛保证而导致估计不准确。Hyperpower方法以其在矩阵逆近似中的严格收敛保证而闻名，但矩阵乘法操作在大规模模型中可能会导致难以管理和计算的成本。因此，为了改善这一现状，研究人员提出了HyperINF方法，它利用了Schulz迭代算法来构建高效且准确的影响函数近似方法。此外，通过将广义 Fisher 信息 (GFIM) 作为 Hessian 矩阵的低秩近似来应对计算密集的矩阵乘法问题，以此减少内存和计算成本到与模型无关的常数成本。
### Innovation
HyperINF方法结合了Schulz的迭代算法和广义 Fisher 信息 (GFIM) 作为低秩近似来近似Hessian矩阵，以处理大规模模型中复杂的矩阵乘法问题，从而降低内存和计算开销到与模型无关的常数成本。这种方法既提高了准确性又保证了计算效率，尤其在基于 LoRA 调整的模型上表现出色。HyperINF方法在合成收敛仿真任务中展示了优于其他基线方法的准确性与稳定性，并在真实数据属性任务上进一步验证了其有效性，尤其是在检测误标数据和LLM和VLM微调中的数据选择方面。
### Conclusion
HyperINF方法在LoRA调整的模型上实现了卓越的下游性能，同时将内存和计算开销降至最小，而其他基线方法则表现出明显的性能下降。该方法通过利用Schulz迭代算法和低秩近似技术，成功降低了大规模模型影响函数计算的复杂性，促进了大规模数据集上的应用。
## 621. `cs.LG` - GASP: 效率高的生成对抗后缀以破解LLMs的黑盒方法 [PDF](https://arxiv.org/pdf/2411.14133), [HTML](https://arxiv.org/abs/2411.14133)
### Authors
Advik Raj Basani,Xiao Zhang
### Background
大规模语言模型（LLMs）展示了在各种自然语言处理任务上的强大能力，但仍存在可通过精心设计的输入提示（称为‘监狱突破攻击’）规避安全规则并引发有害响应的脆弱性。传统方法依赖手动启发式规则，但这类方法在全球适用性上存在局限。虽然优化攻击可以自动进行，但经常生成不自然的提示，容易被安全过滤器发现，或者由于离散令牌优化的成本高昂。针对这些问题，本文提出了一种新型的自动化框架——生成对抗后缀提示器（GASP），能够在完全黑盒环境中高效生成可读的人类威胁提示以进行监狱突破攻击。
### Innovation
GASP 利用潜在贝叶斯优化在连续潜在嵌入空间中高效探索，通过目标迭代优化过程提高提示的有效性，同时保持提示的连贯性。与其他方法相比，GASP 生成的对抗后缀更自然，极大提高监狱突破攻击的成功率，减少训练时间并加速推理速度，提供了一种高效且可扩展的解决方法，用于使红队测试LLMs更加有效。
### Conclusion
通过广泛的实验证明，GASP 能够生成自然的对抗后缀，显著提高监狱突破攻击的成功率，缩短训练时间，并加快推理速度，因此成为针对LLMs的红队测试的有效且可扩展的解决方案。
## 622. `cs.LG` - Wavelet Diffusion Neural Operator [PDF](https://arxiv.org/pdf/2412.04833), [HTML](https://arxiv.org/abs/2412.04833)
### Authors
Peiyan Hu,Rui Wang,Xiang Zheng,Tao Zhang,Haodong Feng,Ruiqi Feng,Long Wei,Yue Wang,Zhi-Ming Ma,Tailin Wu
### Background
模拟和控制由偏微分方程(PDEs)描述的物理系统是科学和工程领域中的关键任务。近年来，扩散生成模型因其能够捕捉长期依赖关系和建模高维状态，已成为这些任务的强有力的方法。然而，扩散模型通常难以处理具有突变变化的状态，并在更高分辨率上泛化表现不佳。
### Innovation
本文提出了Wavelet Diffusion Neural Operator (WDNO)，一种创新的PDE模拟与控制框架，增强了处理复杂性的能力。WDNO包含两项革新。首先，WDNO通过对整个轨迹进行基于扩散的生成建模，在小波域内进行。其次，为了解决不同分辨率下泛化能力差的难题，引入了多分辨率训练。
### Conclusion
通过在五个物理系统上验证WDNO，包括1D对流方程，有突变变化的三个挑战性物理系统（1D Burger方程、1D可压缩Navier-Stokes方程和2D不可压缩流体），以及实时5，表明WDNO在模拟和控制任务上都优于最先进的方法，尤其是在长期和细节预测准确性方面表现出显著改进。值得注意的是，在旨在减少烟雾泄漏的2D高维间接控制任务中，WDNO将泄漏减少了78%，比第二好的基线方法更好。
## 623. `cs.LG` - 使用软注意力模拟硬注意力 [PDF](https://arxiv.org/pdf/2412.09925), [HTML](https://arxiv.org/abs/2412.09925)
### Authors
Andy Yang,Lena Strobl,David Chiang,Dana Angluin
### Background
本文研究了使用软注意力的变压器能否模拟硬注意力，即能否有效地将全部注意力集中在一部分位置上。研究主要探讨了硬注意力变压器识别的语言子类，这些子类可以用线性时间逻辑的各种变体来定义。研究还探讨了如何使用未定义位置嵌入或温度缩放方法让软注意力变压器计算这些逻辑的语言表达式。此外，研究还展示了如何通过依赖于最大注意力分数和其他注意力分数之间最小差距的温度缩放，让Softmax变压器模拟一般硬注意力变压器的功能。
### Innovation
这项研究发现，通过使用未定义位置嵌入或温度缩放，软注意力变压器能够计算线性时间逻辑的公式，并通过温度缩放的方法，让Softmax变压器模拟一般的硬注意力变压器。这为理解和模拟注意力机制提供了新的视角和发展路径，为那些依赖注意力机制的神经网络模型提供了理论支持和实用的实现方法。
### Conclusion
本文研究了软注意力与硬注意力之间的模拟关系，表明通过适当的温度调整等方法，软注意力变压器可以模拟硬注意力的功能。这不仅加深了对注意力机制的理解，也为实际应用中使用软注意力提供了理论依据和技术参考。
## 624. `cs.LG` - 合理化分数基础生成模型的泛化能力 [PDF](https://arxiv.org/pdf/2412.07229), [HTML](https://arxiv.org/abs/2412.07229)
### Authors
Wan Jiang,He Wang,Xin Zhang,Dan Guo,Zhaoxin Fan,Yunfeng Diao,Richang Hong
### Background
分数基础生成模型（Score-based Generative Models, SGMs）能够生成未见过但自然的数据，展示了显著的泛化能力。然而，这种强大的泛化能力也可能导致未预期的泛化和滥用风险。尽管存在这些风险，目前针对SGMs的适当的去泛化研究相对较少。针对现有方法如模型重新训练去除不适当数据这一标准方法在SGMs中无效的现象，本文进行了深入分析并揭示了其无效原因。在理解这些原因的基础上，本文提出了第一个合理化分数基础生成模型（Moderated Score-based Generative Model, MSGM），该模型通过新的得分调节策略在连续时间随机微分方程过程中引导得分函数远离不希望的数据，从而显著降低生成不良内容的几率，同时保持高质量的图像生成效果。
### Innovation
本文提出了新型的合理化分数基础生成模型（MSGM），该模型首次引入了一种新颖的得分调整策略，能够在SGM的过程中引导得分函数避免生成不良内容。此外，MSGM框架具有高度的通用性和灵活性，可兼容多种扩散架构和训练策略，并实现预训练模型的零样本迁移至下游任务，如图像填补和重建。
### Conclusion
广泛的实验结果表明，MSGM在保留高质量图像生成效果的同时，能够显著减少不良内容的生成几率。此外，MSGM框架设计灵活，除了适用于SGMs，还可以应用于其他扩散模型，如DDPM，并能通过重新训练和微调完成模型训练转移。经过评审后，相关代码将公开共享。
## 625. `cs.LG` - 一模型预见一切并在实体分布中将其绑定 [PDF](https://arxiv.org/pdf/2501.15499), [HTML](https://arxiv.org/abs/2501.15499)
### Authors
Kutay Bölat,Simon Tindemans
### Background
电力系统中的概率预测经常涉及多实体数据集，如家庭、馈线和风力涡轮机。产生针对每个实体的可靠预测面临显著挑战，传统方法需要为每个实体训练单独的模型，这使得过程低效且难以扩展。因此，研究者们需要寻找一种更加高效且更具扩展性的方法来解决这一问题。
### Innovation
本文提出了一种条件变分自编码器GUIDE-VAE，它能够使用单一模型进行实体特定的概率预测。GUIDE-VAE提供灵活的输出，从可解释的点估计到完整的概率分布，这归功于其先进的协方差组成结构。通过这些分布，可以捕捉到不确定性与时间依赖性，这些特性相比传统方法提供了更丰富的洞察。
### Conclusion
研究结果表明，基于GUIDE-VAE的预测器在关键指标上优于传统的分位数回归技术，同时确保了可扩展性和适用性。这些特点使得GUIDE-VAE成为概率预测任务的强大且通用的工具，其应用领域不仅限于家庭电力消耗预测。
## 626. `cs.LG` - 通过掩蔽自编码器学习实验室值表示 [PDF](https://arxiv.org/pdf/2501.02648), [HTML](https://arxiv.org/abs/2501.02648)
### Authors
David Restrepo,Chenwei Wu,Yueran Jia,Jaden K. Sun,Jack Gallifant,Catherine G. Bielick,Yugang Jia,Leo A. Celi
### Background
在电子健康记录（EHR）中，准确填补缺失的实验室值对于实现稳健的临床预测和减少人工智能系统中的偏见至关重要。现有的方法如XGBoost、softimpute、GAIN、期望最大化（EM）和MICE难以建模EHR数据中的复杂时序和上下文依赖性，特别是在未被充分代表的群体中。已有方法在处理这些依赖性时表现出局限性.
### Innovation
本文提出Lab-MAE，这是一种新颖的基于变换器的掩蔽自编码器框架，利用半监督学习来填补连续的序列实验室值。Lab-MAE引入了一个结构化的编码方案，共同建模实验室测试值及其对应的日期时间戳，从而明确捕捉时间依赖性。实验结果表明，Lab-MAE在MIMIC-IV数据集上的多指标（包括均方根误差（RMSE）、决定系数R²和威悉距离（WD））上显著优于现有的最先进的基线方法，如XGBoost、softimpute、GAIN、EM和MICE。此外，Lab-MAE在不同患者人口统计群体中表现均一，提高了临床预测的公平性。进一步研究表明，Lab-MAE在缺乏随访实验室值数据的情况下仍表现出鲁棒性。
### Conclusion
通过我们的变换器架构适应EHR数据的特点，Lab-MAE提供了临床补预测的基础模型，具备更高的准确性和公平性。此外，研究还评估了Lab-MAE与XGBoost模型的碳足迹，强调了其环境影响。
## 627. `cs.LG` - 稀疏变异高斯过程的新界线 [PDF](https://arxiv.org/pdf/2502.08730), [HTML](https://arxiv.org/abs/2502.08730)
### Authors
Michalis K. Titsias
### Background
稀疏高斯过程（GPs）构建能够简化计算的训练数据后验近似，核心假设通常是近似分布包含条件GP先验因素。虽然这一假设被视为基本，但研究发现通过使用更通用的变异分布，可以放松这一假设，从而优化证据下界，得到更紧致的界线。这不仅适用于高斯回归，还可以扩展到非高斯似然函数。
### Innovation
引入了更加通用的变异分布 $q(bf f | bf u)$，该分布包含 $N$ 个额外的参数，其中 $N$ 是训练数据的数量。对于高斯回归，可以通过解析优化这些额外参数来表达一个更为紧密且可操作的坍缩界线，这种方法也便于使用随机优化方法。此外，方法也适用于非高斯似然函数。
### Conclusion
实验结果表明，该方法可以在学习超参数时减少偏差，并改善预测性能。
## 628. `cs.LG` - 通过评分校准减少记录匹配中的偏差 [PDF](https://arxiv.org/pdf/2411.01685), [HTML](https://arxiv.org/abs/2411.01685)
### Authors
Mohammad Hossein Moslemi,Mostafa Milani
### Background
记录匹配是指识别在不同数据集中指代同一个现实世界实体的记录的任务。尽管大多数现有的模型都优化了准确性，但公平性成为一个重要关注点，因为不同人口群体可能会出现不公的结果。之前的研究通常关注固定阈值下的二元结果评估。然而，这样的评估可能会错过评分中的偏差，即这种偏差在不同阈值下持续存在并影响下一流程任务。为此，本文提出了一个不依赖阈值的框架，用于衡量和减少评分偏差，定义为不同群体的匹配评分分布差异。研究表明，即使是认为在标准阈值基础上公平的最先进匹配方法，也存在显著的评分偏差。为了解决这个问题，本文引入了两种后处理评分校准算法：第一种是calib，通过Wasserstein barycenter对群体评分分布进行对齐，旨在实现人口统计学平等；第二种是ccalib，根据预测标签进一步减少标签相关的偏差，例如平等机会。这两种方法都是模型无关的，并不需要访问模型训练数据。calib还提供了理论保证，确保在维持原始评分最小偏离的基础上减少偏差。实验结果表明，calib和ccalib在大幅减少评分偏差的同时，对模型准确性的影响较小。
### Innovation
本文提出了一种不依赖阈值的评分校准框架，该框架旨在减少记录匹配中的评分偏差。该框架通过计算不同群体的匹配评分差异来定义偏差，并提出了两种后处理评分校准算法：calib和ccalib。calib算法使用Wasserstein barycenter对分布进行对齐，旨在实现人口统计学平等；ccalib算法进一步依赖预测标签减少标签相关的偏差，如平等机会。这些方法都是模型无关的，并提供了理论保证来确保减少偏差的同时保证原始评分的最小偏离。
### Conclusion
本研究通过提出一个新的不依赖阈值的评分校准框架，以及两种有效的算法calib和ccalib，显著减少了记录匹配中的评分偏差。这些方法不依赖于模型训练数据，同时保持了对模型准确性的最小影响。
## 629. `cs.LG` - 自监督对比学习中动态发现全局虚假负例 [PDF](https://arxiv.org/pdf/2502.20612), [HTML](https://arxiv.org/abs/2502.20612)
### Authors
Vicente Balmaseda,Bokun Wang,Ching-Long Lin,Tianbao Yang
### Background
在自监督对比学习中，负样本对通常通过锚点图像和从整个数据集中抽取的样本组成，但不包括锚点。然而，这种方法可能导致生成具有相似语义特征的虚假负例，导致其嵌入被错误地推远。
### Innovation
提出了GloFND（基于优化的方法），这是一种能够在线自动学习每个锚点数据的阈值来识别训练期间的虚假负例的方法。与之前的方法不同，GloFND方法在全球范围内检测整个数据集的虚假负例，而不是在mini-batch中局部检测。其每轮迭代的计算成本与数据集大小无关。实验结果表明该方法的有效性。
### Conclusion
提出的GloFND方法在图像和图像-文本数据上的实验结果验证了其有效性。其代码实现可在 尽情访问。
## 630. `cs.LG` - 拉格朗日索引策略在平均奖励多臂老虎机中的应用 [PDF](https://arxiv.org/pdf/2412.12641), [HTML](https://arxiv.org/abs/2412.12641)
### Authors
Konstantin Avrachenkov,Vivek S. Borkar,Pratik Shah
### Background
本文研究了拉格朗日索引策略（LIP）在具有长期内平均奖励的紧张多臂老虎机问题中的应用，特别将LIP与瓦尔特索引策略（WIP）进行了性能比较。尽管两者在大多数情况下表现相似，但当WIP性能不佳时，LIP仍然表现出色。此外，文章提出了无模型的拉格朗日索引策略的强化学习算法，这种算法所需的内存显著少于瓦尔特索引策略的类比算法。文章还计算了重启模型（适用于最优网页爬取和最小化加权智能信息年龄）下的拉格朗日指数，同时也基于可交换性和狄尼治定理给出了同质臂在臂数趋向无穷时渐近最优性的新证明。
### Innovation
1. 提出了拉格朗日索引策略（LIP）在具有长期内平均奖励的紧张多臂老虎机问题中的应用。2. 设计了无模型的拉格朗日索引策略的强化学习算法，相比瓦尔特索引策略的类似算法，其所需的内存显著减少。3. 计算了适用于最优网页爬取和最小化加权智能信息年龄的重启模型下的拉格朗日指数。4. 给出了基于可交换性和狄尼治定理的同质臂在臂数趋向无穷时渐近最优性的新证明。
### Conclusion
本文通过研究拉格朗日索引策略在紧张多臂老虎机中的应用，展示了该策略在WIP表现不佳情况下的优越性，并且提出了高效的记忆使用方式的强化学习算法，同时证明了同质臂在臂数趋向无穷时的渐近最优性。
## 631. `cs.LG` - 具有创新染色体模式的繁殖过程中的遗传算法 [PDF](https://arxiv.org/pdf/2501.18184), [HTML](https://arxiv.org/abs/2501.18184)
### Authors
Qingchuan Lyu
### Background
标准遗传算法在解决复杂问题时存在过早收敛的问题，降低了搜索多样性。因此，需要提出一种新的方法来改进标准遗传算法，以提高其探索能力和解决组合优化问题的效率和效果。Genetic Algorithm with Border Trades (GAB)即是基于这种需求提出的新型改进算法。
### Innovation
GAB是一种创新的遗传算法变体，通过在繁殖过程中引入新的染色体模式来增强探索性。这种改进显著降低了过早收敛的风险，提升了搜索多样性。实验结果显示，GAB在复杂的工作调度问题上性能优异，相较于标准遗传算法，GAB在20秒内达到了平均888的适应度得分，而标准遗传算法的平均适应度为106，且GAB实现了8倍以上的更高适应度和10倍以上的更快收敛速度。对于经典的Flip-Flop问题，GAB能够在较少的迭代次数中找到最优或接近最优解，即使输入规模达到了数千位。
### Conclusion
GAB作为一种高效的计算方法，为大规模组合优化问题提供了一个令人信服的替代方案。
## 632. `cs.LG` - 通过凸优化进行逆强化学习 [PDF](https://arxiv.org/pdf/2501.15957), [HTML](https://arxiv.org/abs/2501.15957)
### Authors
Hao Zhu,Yuan Zhang,Joschka Boedecker
### Background
我们考虑逆强化学习(IRL)问题，即基于观察到的专家示范，估计某个马尔可夫决策过程(MDP)的未知奖励函数。大多数现有方法将IRL概述和解决为非凸优化问题，这在需要强大稳健性和可重复性的情况下提出了挑战。Ng和Russel最初提出了一种凸形式的IRL问题(CIRL)，并在此基础上对问题进行了重新表述，以便可以直接使用领域特定语言CVXPY来指定和解决凸问题。该论文还扩展了CIRL问题，以涵盖专家策略不是以分析表达而是以轨迹的状态-动作对形式给出的情况，这些情况可能与最优性严重不一致，通过增加一些约束来解决这个问题。
### Innovation
提出了通过凸优化进行逆强化学习(CIRL)的方法，并将其重新表述为可以使用CVXPY直接指定和求解的凸优化问题。此外，该论文扩展了CIRL问题的应用范围，使之能处理那些专家策略以轨迹状态-动作形式而非分析形式给出、可能不符合最优性的场景。
### Conclusion
本文为用户提供了应用CIRL解决其问题的途径，无需了解凸优化的基础知识。通过理论分析和超参数自动选择的实用实现，使CIRL更容易被应用。
## 633. `cs.LG` - 关于深度网络从数据中学习对称性的能力：一种神经核理论 [PDF](https://arxiv.org/pdf/2412.11521), [HTML](https://arxiv.org/abs/2412.11521)
### Authors
Andrea Perin,Stephane Deny
### Background
在许多数据集中都存在对称性（通过群组动作进行的变换），利用这些对称性能够显著提高机器学习中的预测性能。本文旨在理解使用标准架构和标准监督方式训练的深度网络如何从数据中学习对称性。研究重点在于训练过程中仅部分观测到数据对称性的分类范式；部分类别包括循环群的所有变换，而其他类别仅包括部分变换。在无限宽度极限下，基于核类比，本文推导出了神经核理论，以理解对称性的学习。通过对数据集中循环群性质的研究，分析了神经核的格拉姆矩阵在频域的特性，揭示了泛化误差与类间分离度（信号）和类轨道密度（噪声）的关系。此理论表明，泛化只能在局部数据结构胜过其非局部、由对称性引起的结构时才有可能，这取决于架构定义的核空间。该理论还扩展至任何有限群，包括非交换群，并适用于对称结构的架构（如CNN）。
### Innovation
本文提出了神经核理论，用于解析深度网络从部分观测数据对称性中学习对称性的能力。在无限宽度下，通过基于核类比的研究，对神经核的格拉姆矩阵在频域的特性进行了分析，揭示了泛化误差与类间分离度和类轨道密度的关系。此理论证明了局部数据结构的重要性，并且能够扩展应用于任何有限群及包括非交换群的任意架构。通过这一理论，表明常规深度网络缺乏在架构中未先验嵌入的对称性学习机制。此外，该理论适用于对称架构（如CNN）并分析了它们在与数据内固有的对称性匹配时的成功案例。
### Conclusion
本文的研究结论强调了深度网络在学习无法先验嵌入其架构的对称性方面的局限性。提出了一个框架来指导设计能够从数据中学习对称性的架构和训练程序。
## 634. `cs.LG` - 使用Noise Estimation through Reinforcement-based Diffusion (NERD)模型揭示不确定性下的高级神经表征 [PDF](https://arxiv.org/pdf/2503.14333), [HTML](https://arxiv.org/abs/2503.14333)
### Authors
Hojjat Azimi Asrari,Megan A. K. Peters
### Background
研究通常旨在揭示“初级表示”（FORs），这些表示编码观察者环境的方面，如内容或结构。较少研究的是“高级表示”（HORs），它们是“关于”FORs的，例如其强度或不确定性。HORs关于不确定性的表征可能是间接的，反映的是混合了关于不确定性期望的噪声估计过程。目前，关于如何在大脑中代表这些关于预期不确定性的分布，还知之甚少。本研究使用解码神经反馈任务，人类受试者需学会自主产生目标神经模式，以研究大脑如何应对这一过程。
### Innovation
开发和应用了一个基于强化学习的扩散（NERD）模型来表征大脑如何应对这一过程，并展示该模型对于人类行为具有很高的解释能力。
### Conclusion
研究表明，大脑可能通过NERD模型来理解和管理自我噪声预期下的不确定性高级表征，这一过程揭示了关于如何在不确定性下的高级神经表征，具有很高的解释力。
## 635. `cs.LG` - 在线决策制定中的遗憾界限 [PDF](https://arxiv.org/pdf/2504.06820), [HTML](https://arxiv.org/abs/2504.06820)
### Authors
Alexander Appel,Vanessa Kosoy
### Background
该研究扩展了结构化观测下的决策制定框架，引入了鲁棒的多值模型。每个模型将每个决策与一系列概率分布的凸集关联起来，自然界可以从这一集合中以任意的（敌手式的）方式选择概率分布，且这些分布可以依赖于过去的记录，从而增强了框架的通用性，超越了经典的bandits和强化学习，因为实际可实现性假设变得更弱更现实。
### Innovation
提出了一个更广泛的框架来处理结构化观测下的决策制定，允许使用鲁棒的多值模型。通过该框架下的遗憾界理论研究，特别在鲁棒线性bandits和表格鲁棒在线强化学习的两个特殊案例中，提出的新遗憾界优于现有最佳结果（除了未解决计算效率问题）
### Conclusion
尽管下界和上界不是非常精确，但足以完全描述幂律学习的可能性。证明了这一理论在鲁棒线性bandits和表格鲁棒在线强化学习的两个特殊案例中，得到了优于现有结果的新遗憾界（除了未解决计算效率问题）
## 636. `cs.LG` - 使用变分防御封锁后门 [PDF](https://arxiv.org/pdf/2503.08829), [HTML](https://arxiv.org/abs/2503.08829)
### Authors
Ivan Sabolić,Matej Grcić,Siniša Šegvić
### Background
当前的模型在面临后门攻击时往往缺乏抵抗力，尤其是在训练数据中存在恶意输入和被篡改的标签的情况下。为了提升模型的安全性，本文提出了VIBE（一种模型无关的框架），该框架能够训练出对后门攻击具有抗性的分类器。VIBE将恶意输入和被篡改的标签视为观测到的随机变量，而真实干净的标签则被视为潜在变量，并通过变分推理恢复相应的潜在干净标签后验概率。这种方法的训练过程遵循期望最大化（EM）算法。E步通过求解带有熵正则项的最优传输问题来推断干净的伪标签，M步则通过梯度下降来更新分类器参数。VIBE结构模块化，可以无缝地集成到最近的自我监督表示学习的成果中，从而增强其对抗后门攻击的能力。
### Innovation
VIBE提出了一种新的方法，即使用变分推理框架来提升模型对后门攻击的抵抗力。该方法处理恶意输入和被篡改的标签作为观测变量，通过最优传输问题和变分推理来恢复潜在的干净标签。这种方法具有模块化的特点，能够与自我监督表示学习的最新进展无缝整合。实验表明，VIBE在对抗标准数据集和大规模类别的后门攻击上下文以及存在多种后门攻击的数据集上，均表现出色，并且优于当前的防御方法。
### Conclusion
VIBE能够通过变分推理方法有效地提高模型在存在后门攻击情况下的鲁棒性。实验结果表明，VIBE在多种后门攻击场景下都能提供更好的防御效果。该工作强调了将变分推理应用于提升模型抗后门攻击能力的重要性，并展示了自我监督表示学习如何能增强VIBE的防御能力。
## 637. `cs.LG` - 始终跳过注意力 [PDF](https://arxiv.org/pdf/2505.01996), [HTML](https://arxiv.org/abs/2505.01996)
### Authors
Yiping Ji,Hemanth Saratchandran,Peyman Moghadam,Simon Lucey
### Background
本文讨论了一个关于现代视觉变压器（ViTs）中的一个有趣的经验发现：自我注意机制（self-attention）在训练过程中除非与跳跃连接（skip connection）结合使用，否则会失效。其他ViT组件即使没有跳跃连接也能继续表现出良好的性能（尽管不优化）。此外，与以前的深层架构（例如CNN）不同，这些深层架构在没有跳跃连接的情况下仍能表现良好。这表明跳跃连接对自我注意机制的重要性是一个相对新的现象。
### Innovation
文章理论化地证明自我注意机制本质上条件不良，因此需要跳跃连接进行正则化。此外，作者提出了Token Graying——一种简单有效的补充方案，与跳跃连接配合可以进一步改善输入令牌的条件。该方法已在有监督和自监督训练方法中得到验证，显示出改进效果。
### Conclusion
跳跃连接对于自我注意机制至关重要，这是因为在没有跳跃连接的情况下，自我注意机制条件不佳，需要正则化。本文通过Token Graying方法进一步改进了输入令牌的条件，从而提高了模型性能。
## 638. `cs.LG` - 通过Lie群变换实现的广义张量基参数高效微调 [PDF](https://arxiv.org/pdf/2504.00851), [HTML](https://arxiv.org/abs/2504.00851)
### Authors
Chongjie Si,Zhiyi Shi,Xuehui Wang,Yichen Xiao,Xiaokang Yang,Wei Shen
### Background
在人工智领域，通过对预训练基础模型进行适应以应对多样的下游任务是一种核心实践。然而，任务的多样性以及较高的计算成本使得全面微调不可行。因此，为了解决这一问题，近年来出现了诸如LoRA等参数高效微调（PEFT）方法，这些方法正在成为研究的热点。但这些现有方法主要针对线性层，侧重于二维矩阵，对高维度参数空间如卷积核则考虑不足。应用现有方法到高维度参数空间时，常常会破坏其本身的结构关系。因此，我们提出了一种通用策略，该策略扩展了基于矩阵的PEFT方法到高维度参数空间，同时保持其结构特性不变。实验结果表明，该方法在计算机视觉和自然语言处理方面表现出了良好的效果和高度的灵活性，超越了现有的方法。
### Innovation
我们提出了一种广义的张量基参数高效微调方法，将其扩展到了高维度参数空间，例如卷积核，而不会破坏原有的结构关系。我们通过将参数看作Lie群中的元素，并将更新建模为Lie代数中的扰动，利用指数映射将这些扰动从Lie代数映射回Lie群，从而确保了平滑、一致的更新，且能保持参数空间的固有结构。这种方法克服了现有PEFT方法在处理高维度参数空间时的局限性，提高了效率和效果。
### Conclusion
通过广泛实验验证，我们的方法在计算机视觉和自然语言处理任务中均展示了明显的改进效果，表明该方法的有效性和灵活性。
## 639. `cs.LG` - Onsager-Machlup 功能最小化遇上了生成模型：基于 Onsager-Machlup 功能的高效过渡路径采样 [PDF](https://arxiv.org/pdf/2504.18506), [HTML](https://arxiv.org/abs/2504.18506)
### Authors
Sanjeev Raja,Martin Šípka,Michael Psenka,Tobias Kreiman,Michal Pavelka,Aditi S. Krishnapriyan
### Background
过渡路径采样（TPS）涉及在能量景观上找到连接两个点的可能路径，对复杂的真实原子系统而言仍然是一个挑战。当前使用机器学习的方法需要昂贵的、任务特定的、无需数据的训练过程，这限制了其从优质数据集和大规模预训练模型中获益的能力。
### Innovation
本文通过将候选路径视为由预训练生成模型的学习评分函数诱导的随机动力学产生的轨迹，采用了新颖的方法。在这些动力学中，找到高概率的过渡路径等同于最小化 Onsager-Machlup (OM) 动作泛函。这种方法使得预训练生成模型能够以零样本方式用于 TPS，与先前作品中的特定任务方法不同。作者展示了该方法在多种分子系统中的应用，获得了多样、物理上合理且超越预训练模型原始训练数据集的过渡路径。这种方法可以轻松整合到新的生成模型中，随着数据量的增加和模型的改善，具有实际相关性
### Conclusion
本文展示了如何利用预训练生成模型和 Onsager-Machlup 动作泛函有效进行过渡路径采样。这种方法能够产生多样且物理上合理的过渡路径，并超越了预训练模型的原始训练数据集。随着生成模型的不断进步和数据可用性的增加，该方法具有重要的实际应用意义。
## 640. `cs.LG` - 在6G V2X中联合通信与控制的信息价值学习 [PDF](https://arxiv.org/pdf/2505.06978), [HTML](https://arxiv.org/abs/2505.06978)
### Authors
Lei Lei,Kan Zheng,Xuemin(Sherman)Shen
### Background
随着蜂窝车辆到一切（C-V2X）技术向第六代（6G）网络演进，实现联网自动驾驶车辆（CAVs）成为关键应用。通过数据驱动的机器学习（ML），尤其是深度强化学习（DRL），人们期望在不确定环境下显著提升CAVs的车辆控制与V2X通信决策能力。这两个决策过程密切相关，信息价值（VoI）成为连接它们的关键。
### Innovation
本文引入了序列随机决策过程（SSDP）模型来定义并评估VoI，展示了其在优化CAV通信系统方面的应用。进一步提出了基于MDP、强化学习（RL）和最优控制理论的信息价值系统建模框架，定义了不同的VoI类别及其对应的估计方法。SSDP模型通过显式表示可用信息集带来关键优势，并通过与VoI关联的奖励函数，为联合优化随机、顺序控制和通信决策提供了结构化的途径。
### Conclusion
本文提出的方法在联合优化网络控制系统中的随机、顺序控制和通信决策具有重要意义，可以通过不同的VoI度量方法实现“何时、何事、如何”通信问题的优化。
## 641. `cs.LG` - 基于IRS辅助系统的专家体系增强的深度展开活动检测方法 [PDF](https://arxiv.org/pdf/2502.20183), [HTML](https://arxiv.org/abs/2502.20183)
### Authors
Zeyi Ren,Qingfeng Lin,Jingreng Lei,Yang Li,Yik-Chung Wu
### Background
在大规模机器型通信中，智能反射表面（IRS）在提高缺乏直接连接到基站（BS）设备的覆盖范围方面显示出了巨大潜力。然而，传统的活动检测方法通常仅针对单一类型的信道模型设计，这无法反映现实世界场景的复杂性，在包括IRS的系统中更加明显。因此，需要一种新方法来应对这一挑战，改进活动检测性能尤其是在混合信道衰落条件下。
### Innovation
本文提出了一种新型方法，结合了模型驱动的深度展开和混合专家（MoE）框架。通过自动选择三种专家设计中的一个并应用于展开的投影梯度方法，该方法消除了对设备与BS之间信道类型先验知识的需求。模拟结果表明，提出的MoE增强的深度展开方法优于传统的基于协方差的方法和黑盒神经网络设计，尤其是在混合信道衰落条件下提供了更好的检测性能。
### Conclusion
所提出的MoE增强的深度展开方法在混合信道衰落条件下表现出更好的检测性能，超越了传统的基于协方差的方法和黑盒神经网络设计，展示了其在活动检测中的优越性。
## 642. `cs.LG` - 利用嵌入的普遍几何结构 [PDF](https://arxiv.org/pdf/2505.12540), [HTML](https://arxiv.org/abs/2505.12540)
### Authors
Rishi Jha,Collin Zhang,Vitaly Shmatikov,John X. Morris
### Background
在研究文本嵌入翻译时，现有的方法大多依赖于配对数据、预训练编码器或预先定义的匹配集。这一研究背景揭示了在缺乏这些资源的情况下，如何更有效地翻译不同向量空间的文本嵌入，这对于维护嵌入向量数据库的安全性尤为重要，尤其是在对手只能访问嵌入向量的情况下，他们仍能获取敏感信息，用于分类和属性推断。
### Innovation
本文提出了一种无监督的文本嵌入翻译方法，该方法能够将任何嵌入从一个向量空间转换到另一个向量空间，而不需要配对数据、预训练编码器或预先定义的匹配集。这种方法依据的是柏拉图代表假设，即存在一个普遍的潜在表示形式。这种翻译方法能够在不同架构、参数数量和训练数据集的模型对之间实现高余弦相似度。
### Conclusion
这种能够无监督地将未知嵌入翻译到不同空间的能力，对于嵌入向量数据库的安全性具有重要意义。即使对手只能访问嵌入向量，他们仍然可以通过这种翻译来提取敏感信息，用于分类和属性推测。
## 643. `cs.LG` - 迁移动力学匹配方法在动力学偏移数据的强化学习中的应用 [PDF](https://arxiv.org/pdf/2505.23062), [HTML](https://arxiv.org/abs/2505.23062)
### Authors
Lingkai Kong,Haichuan Wang,Tonghan Wang,Guojun Xiong,Milind Tambe
### Background
利用来自源环境的预先收集的离线数据可以显著提高强化学习的样本效率，但这种好处常常受到了源和目标环境转换动态差异的挑战。现有方法通常通过惩罚或在动态差距大的区域过滤源转换来解决这一问题，但它们对动态差距的估计往往依赖于KL散度或互信息，这在源和目标动态支持集分离时可能不明确。为应对这些限制，该文提出了CompFlow方法，该方法基于流匹配和最优传输的理论联系。CompFlow将目标动态建模为基于源域流的输出分布的条件流，而不是直接从高斯先验学习它。这种组合结构提供了两大优势：(1) 改进了学习目标动态的一般性，(2) 通过源和目标转换之间的Wasserstein距离对动态差距进行了原则性估计。利用这种原则性的动态差距估计，CompFlow进一步引入了一种积极的主动数据收集策略，优先在动态差距高的区域进行探索，并从理论上证明了这种方法降低了性能与最优策略的差距。
### Innovation
CompFlow方法基于流匹配和最优传输理论，通过将目标动态视为基于源域流输出分布的条件流，而非直接从高斯先验学习。这种方法提出了一种新的组合结构，不仅提高了目标动态学习的一般性，还提供了一种原则性的动态差距估计方法，通过Wasserstein距离进行量化。此外，还提出了一种基于动态差距估计的积极主动数据收集策略，以提高学习效果与最优策略的性能差距。
### Conclusion
CompFlow在多个具有动力学偏移的数据的强化学习基准上表现出色，超越了强 baselines，证明了通过积极地探索动态差距大的区域可以有效改善学习效果。
## 644. `cs.LG` - ScaleGNN: 通过自适应高阶邻域特征融合实现可扩展的图神经网络 [PDF](https://arxiv.org/pdf/2504.15920), [HTML](https://arxiv.org/abs/2504.15920)
### Authors
Xiang Li,Jianpeng Qi,Haobing Liu,Yuan Cao,Guoqing Chao,Zhongying Zhao,Junyu Dong,Yanwei Yu
### Background
图神经网络（GNNs）在各种基于图的任务中表现出色，通过消息传递捕捉复杂的节点关系。但在应用于大规模真实世界图时，GNNs面临两大挑战：一是难以同时确保可扩展性和效率，因为重复聚合大量邻居导致了显著的计算开销；二是过度平滑问题，过度或深入传播使节点表示变得难以区分，严重影响了模型的表达能力。
### Innovation
为了应对这些问题，我们提出了ScaleGNN，这是一种新颖的框架，能够自适应地融合多跳节点特征，实现高效且有效的图学习。首先，我们构建了每跳的纯邻居矩阵，仅捕捉每个跳的独家结构信息，避免了传统聚合的冗余。然后，增强的特征融合策略显著平衡低阶和高阶信息，既保留局部细节也保留全局相关性，而不过度增加复杂性。为了进一步减少冗余和过度平滑，我们引入了基于局部贡献评分（LCS）的掩码机制，过滤掉不相关的高阶邻居，确保仅聚合最有意义的信息。此外，可学习的稀疏约束有选择地整合多跳有价值特征，强调最有信息量的高阶邻居。广泛的实验结果表明，ScaleGNN在预测准确性和计算效率上均优于最先进的GNNs，突显了其在大规模图学习中的实际价值。
### Conclusion
实验结果表明，ScaleGNN在多个真实世界数据集上的预测准确性和计算效率均优于最先进的GNNs，证明了其在大规模图学习中的实用价值。
## 645. `cs.LG` - Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application [PDF](https://arxiv.org/pdf/2506.05710), [HTML](https://arxiv.org/abs/2506.05710)
### Authors
Xiucheng Wang,Honggang Jia,Nan Cheng,Dusit Niyato
### Background
该论文背景涉及6G通信系统的发展，特别强调在高噪声环境下和数据分布变化情况下的通信增强需求。论文提出了一个基于生成人工智能（GAI）的新型语义通信框架，以提高通信的鲁棒性，对抗信道噪声和传输数据分布变化。
### Innovation
该论文的创新点在于提出了一种基于概率微分方程（SDEs）的语义通信框架，该框架结合了临界扩散模型（LDM）和变分自编码器，用于提取语义特征和噪声去除。该框架能够自适应调整信噪比下的去噪时间步长，通过数学比例方法解决了数据分布的不匹配问题。此外，该系统未进行额外的训练，支持零样本泛化，在低信噪比和分布外条件下表现出色，为未来6G语义通信系统提供了可扩展和鲁棒的解决方案。
### Conclusion
该语义通信框架在像素级准确性和语义感知质量方面均达到了最先进的性能，实验结果显示其在广泛的信噪比和数据分布条件下均超过基线系统，无需任何微调或后训练。
## 646. `cs.LG` - 变分监督对比学习 [PDF](https://arxiv.org/pdf/2506.07413), [HTML](https://arxiv.org/abs/2506.07413)
### Authors
Ziwen Wang,Jiajun Fan,Thao Nguyen,Heng Ji,Ge Liu
### Background
对比学习已被证实可以高效且灵活地塑造不同模态下的表示空间，通过拉近相似样本并驱散不相似样本来工作。然而，这种学习方法存在两个关键局限性：一是缺乏对嵌入分布的显式控制，导致相关实例可能被无意中驱散；二是过度依赖大规模内批负样本和定制化增强会妨碍泛化能力.
### Innovation
本文提出了变分监督对比学习（VarCon），它将监督对比学习重新定义为对潜在类别变量的变分推断，并通过最大化后验加权的证据下界（ELBO）来实现，从而实现高效且类别意识的匹配，同时赋予对嵌入空间内类别分散的细粒度控制。VarCon 方法在不依赖大规模内批负样本和定制化增强的情况下，能够高效地收敛，并在多项任务上取得了卓越表现，特别是在 ImageNet-1K 上达到了 79.36% 的 Top-1 精度，且仅需 200 个 epochs.
### Conclusion
实验结果表明，VarCon 不仅超越了现有的对比学习框架，还在多分类、层次聚类和迁移学习等方面表现出更加清晰的决策边界和语义组织。此外，VarCon 在少样本学习中表现出优越的性能，并且具有更强的对抗不同增强策略的鲁棒性。
## 647. `cs.LG` - PCDVQ：通过极坐标解耦提升大规模语言模型的向量量化 [PDF](https://arxiv.org/pdf/2506.05432), [HTML](https://arxiv.org/abs/2506.05432)
### Authors
Yuxuan Yue,Zukang Xu,Zhihang Yuan,Dawei Yang,Jianlong Wu,Liqiang Nie
### Background
大型语言模型（LLMs）在边缘部署中面临巨大的挑战，因为它们具有庞大的参数规模。向量量化（VQ）作为一种基于聚类的量化方法，被广泛应用于解决这一问题，尤其是在极低位宽（甚至2位）的情况下仍能保持相当的准确度。然而，现有的VQ研究通常将方向和幅度耦合在一起进行量化，忽视了它们在量化过程中表现的不同敏感性。特别是在LLaMA-2-7B这样的模型中，单独聚类权重向量的方向和幅度会导致零样本任务的准确率分别下降46.5%和2.3%，说明方向方向更敏感于量化过程。此外，当前VQ方法中常用的欧几里得距离更侧重于减少幅度误差，这与上述发现不符，导致量化误差增加。这些缺陷促使了本研究的提出，旨在提供一种新的高效的VQ框架，以改进LLM的精度和压缩比。
### Innovation
本研究提出了一种有效的向量量化框架——极坐标解耦向量量化（PCDVQ），其关键模块包括两部分：1）极坐标解耦（PCD），它将向量转换为其极坐标表示，并对方向和幅度参数进行独立量化；2）分布对齐码本构建（DACC），该模块根据数据源的分布优化方向和幅度码本，以进一步提高量化精度。该框架能够在2位精度下至少提高1.5%的零样本准确率，显著改善了现有的VQ方法，并为高精度和高度压缩的LLM建立了一个新的范式。
### Conclusion
实验结果表明，与基线方法相比，PCDVQ在2位精度下至少提高了1.5%的零样本准确率，展示了其在提升LLM量化精度和压缩效率方面的显著优势，为构建全新的大规模语言模型量化方法奠定了基础。
## 648. `cs.LG` - devil's hand: 数据注入攻击对局部私密图学习协议 [PDF](https://arxiv.org/pdf/2506.09803), [HTML](https://arxiv.org/abs/2506.09803)
### Authors
Longzhu He,Chaozhuo Li,Peng Tang,Li Sun,Sen Su,Philip S. Yu
### Background
图神经网络（GNNs）在图表示学习中取得了显著成功，并被应用于多个领域。然而，许多现实世界的图包含敏感的个人信息，如社交网络中的用户资料，这在使用GNNs进行图学习时会引起严重的隐私担忧。为解决该问题，基于本地差分隐私（LDP）的局部私密图学习协议受到了广泛关注。这些协议利用了LDP的隐私优势和GNN消息传递的有效性，能够在确保用户本地数据隐私的同时，维持对图学习高实用性的节点分类准确性。然而，这些协议可能容易受到数据中毒攻击，这一点在先前的研究中并未被考虑。因此，识别并解决这些威胁对于确保隐私保护图学习框架的稳健性和安全性至关重要。这项工作首次提出了针对局部私密图学习协议的数据中毒攻击方法。攻击者通过注入假用户，操纵假用户与真实用户建立连接，并发送精心设计的数据，最终损害了保密图学习的实用性。
### Innovation
提出了一种针对基于本地差异隐私的局部私密图学习协议的数据中毒攻击方法。通过在协议中注入假用户、操纵假用户与真实用户建立联系，并发送精心设计的数据，该攻击最终损害了图学习的实用性。该研究还展示了攻击的有效性，并探索了几种防御策略，但结果显示这些防御策略的效果有限，揭示了更 robust 防御策略的必要性。
### Conclusion
无论是从理论上来讲还是通过实证分析表明，这种数据注入攻击对局部私密图学习协议的有效性。同时，现有的防御策略效果有限，需要进一步开发更 robust 的防御方法以确保隐私保护图学习框架的稳健性和安全性。
## 649. `cs.LG` - 基于不平衡图之间最优传输计划预测的无监督学习 [PDF](https://arxiv.org/pdf/2506.12025), [HTML](https://arxiv.org/abs/2506.12025)
### Authors
Sonia Mazelet,Rémi Flamary,Bertrand Thirion
### Background
基于Gromov-Wasserstein和其他扩展的图之间的最优传输是对比和对齐图结构的强工具，但解决相关非凸优化问题计算成本高，限制了这些方法在大型图上的可扩展性。
### Innovation
提出了一种基于深度学习的无监督学习方法Unbalanced Learning of Optimal Transport（ULOT），用于预测两图之间的最优传输计划。该方法通过最小化融合不平衡Gromov-Wasserstein（FUGW）损失进行训练，并设计了一种新的神经架构，该架构是针对FUGW折中超参数进行条件处理的交叉注意力机制。ULOT在合成随机块模型图和fMRI获取的真实皮质表面数据上进行了评估。ULOT在两个数量级的时间内以竞争性的损失预测传输计划，并可以作为经典求解器的预热启动，加速其收敛。此外，预测的传输计划对图输入和FUGW超参数是完全可微的，这使得可以优化ULOT计划的功能。
### Conclusion
ULOT克服了传统求解器计算成本高的问题，能以更快的速度并提供更好性能地预测最优传输计划，并且该计划还可以被用于优化功能的求解。
## 650. `cs.LG` - 基于网格的神经算子：一种变换生成方法 [PDF](https://arxiv.org/pdf/2506.16656), [HTML](https://arxiv.org/abs/2506.16656)
### Authors
Yaozhong Shi,Zachary E. Ross,Domniki Asimaki,Kamyar Azizzadenesheli
### Background
函数空间中的生成模型位于生成建模和算子学习的交叉点，因其在各种科学和工程应用中的巨大潜力而受到越来越多的关注。尽管这类生成模型在理论上可以独立于具体领域和离散化方式，但当前的实现仍然高度依赖傅里叶神经算子（FNO），使其实用性受限于规则网格和矩形区域。为克服这些关键限制，我们提出了一种新的方法——网格导向神经算子（MINO）。MINO利用图神经算子和交叉注意力机制，为函数空间中的生成建模提供了一个原理上独立于具体领域和离散化方式的架构基础，极大地扩展了这类模型在生成、逆问题和回归任务中的应用范围。此外，MINO还为将神经算子与通用的深度学习架构统一起来提供了一个新的视角。最后，我们提出了一套标准化的评估指标，以客观比较功能生成模型，填补了该领域的另一个关键空白。
### Innovation
提出了网格导向神经算子（MINO），利用图神经算子和交叉注意力机制，为函数空间中的生成建模提供了一个独立于具体领域和离散化方式的架构基础。该方法显著扩展了生成建模的应用范围，并为神经算子与通用的深度学习架构的整合提供了一种新的统一视角。同时，还提出了一套标准化的评估指标，以客观比较功能生成模型，填补了该领域的空白。
### Conclusion
网格导向神经算子（MINO）为生成建模提供了更广泛的应用范围，尤其适用于生成、逆问题和回归任务。MINO还为神经算子与深度学习的整合提供了一个新的视角。同时，标准化的评估指标有助于客观评估功能生成模型的表现。
## 651. `cs.LG` - PARALLELPROMPT: 从大型语言模型查询中提取并行性 [PDF](https://arxiv.org/pdf/2506.18728), [HTML](https://arxiv.org/abs/2506.18728)
### Authors
Steven Kolawole,Keshav Santhanam,Virginia Smith,Pratiksha Thaker
### Background
LLM 服务系统通常将用户提示视为整体输入，通过解码技巧或时间序列批处理来优化推理。然而，许多现实世界的用户提示包含潜在的语义并行性——可分解的结构，其中子任务可以独立执行以降低延迟并保持其含义。
### Innovation
本文引入了 PARALLELPROMPT，这是首个用于测量自然用户提示中查询内部并行性的基准。该基准旨在评估分解策略的好处，提供了一个执行套件来衡量串行和并行策略之间的延迟、结构一致性和语义保真度。结果表明，通过结构化的拆分分析，可以在超过 75% 的数据集中成功实现并行处理，且在任务如翻译、理解及比较分析上，最多可达到 5 倍的加速效果，且质量下降最小化。
### Conclusion
通过发布 PARALLELPROMPT 基准、数据注释管道和执行套件，本文提供了首个用于研究和测试 LLM 服务管道中结构感知执行的标准测试环境。
## 652. `cs.LG` - 能量匹配：生成建模中的流匹配和能量模型的统一 [PDF](https://arxiv.org/pdf/2504.10612), [HTML](https://arxiv.org/abs/2504.10612)
### Authors
Michal Balcerak,Tamaz Amiranashvili,Antonio Terpin,Suprosanna Shit,Lea Bogensperger,Sebastian Kaltenbach,Petros Koumoutsakos,Bjoern Menze
### Background
目前最常用的生成模型通过匹配流或得分将噪声和数据分布映射在一起。然而，这些模型在处理部分观测和额外先验信息方面存在一定局限性。能量模型（EBMs）通过简单地增加相应的标量能量项能够优雅地解决这一问题。这篇文章提出了能量匹配框架，该框架增强了基于流的方法的灵活性，使其能够处理额外的先验信息，从而在数据流形远端，样本沿无旋最优运输路径从噪声流向数据。当接近数据流形时，熵能量项引导系统进入玻尔兹曼平衡分布，明确捕捉数据的潜在似然结构。我们的方法在CIFAR-10和ImageNet生成中表现出了更高的保真度，同时保留了无模拟训练，远离数据流形，可以进行有效的逆问题正则化。该方法还展示了如何利用其灵活性在蛋白质生成中引入交互能量，支持不同模式的探索。我们的方法集中在学习标量势能上，不需要时间条件、辅助生成器或额外网络，这标志着与最近EBM方法的重大区别，我们认为这一简化框架显著提高了EBM的能力，为它们在不同领域的生成建模中的更广泛应用铺平了道路。
### Innovation
提出了一个能量匹配框架，该框架增强了基于流的方法的灵活性，使其能够处理额外的先验信息，从而在数据流形远端，样本沿无旋最优运输路径从噪声流向数据。当接近数据流形时，熵能量项引导系统进入玻尔兹曼平衡分布，明确捕捉数据的潜在似然结构。这种方法在CIFAR-10和ImageNet生成中表现出了更高的保真度，同时保留了无模拟训练，远离数据流形，可以进行有效的逆问题正则化。该方法还展示了如何利用其灵活性在蛋白质生成中引入交互能量，支持不同模式的探索。这种方法集中在学习标量势能上，不需要时间条件、辅助生成器或额外网络，这标志着与最近EBM方法的重大区别，显著提高了EBM的能力。
### Conclusion
我们提出的方法在CIFAR-10和ImageNet生成中表现出了更高的保真度，同时保留了无模拟训练，远离数据流形，可以进行有效的逆问题正则化。此外，在蛋白质生成中展示了该方法的灵活性。这种方法简化了EBM的方法论，显著提高了EBM的能力，并为它们在不同领域的生成建模中的更广泛应用铺平了道路。
## 653. `cs.LG` - 容量约束延迟在线学习：调度框架与遗憾权衡 [PDF](https://arxiv.org/pdf/2503.19856), [HTML](https://arxiv.org/abs/2503.19856)
### Authors
Alexander Ryabchenko,Idan Attias,Daniel M. Roy
### Background
研究了在线学习中的延迟损失和延迟反馈背景，在这种背景下，如何同时跟踪多个过去的轮次以限制延迟反馈的数量成为研究的焦点。论文探讨了在所谓“先见之明”（即每轮延迟时间提前透露）和/或“可预设”（即可以停止跟踪之前选择的轮次反馈）的情况下，如何通过设定一种新的“容量约束”来解决此问题。研究了在所有容量级别下实现最优遗憾的算法，并分析了在非最优容量下性能的折衷。
### Innovation
本研究提出了针对延迟反馈的在线学习算法，这些算法能够在不同容量下实现最优遗憾。在先见之明和假设容量为$C = text{Ω}(text{log}(T))$的情况下，对于臂式学习和完全信息反馈，论文推出了对应的遗憾边界。当用可预设替换先见之明时，需要已知最大延迟上限，遗憾会额外增加$text{Ω}(d_{text{max}})$。对于固定延迟$d$的处理，研究给出了最优容量的理论，并通过新颖的预设调度策略实现了这些理论上的边界结果。论文还统一了研究方向，证明了在延迟反馈下具有适度跟踪容量的鲁棒在线学习是可能的。
### Conclusion
本研究通过引入新的容量约束模型，研究了在线学习中的延迟反馈问题，并通过先见之明和可预设两种情况分析了对应的遗憾边界。对于不同容量的处理提供了算法性能的理论保障，并对于固定延迟情况给予最优容量的理论指导，同时展示了在延迟反馈下鲁棒在线学习的可行性。
## 654. `cs.LG` - 从Tiny机器学习到Tiny深度学习：综述 [PDF](https://arxiv.org/pdf/2506.18927), [HTML](https://arxiv.org/abs/2506.18927)
### Authors
Shriyank Somvanshi,Md Monzurul Islam,Gaurab Chhetri,Rohit Chakraborty,Mahmuda Sultana Mimi,Sawgat Ahmed Shuvo,Kazi Sifatul Islam,Syed Aaqib Javed,Sharif Ahmed Rafat,Anandi Dutta,Subasish Das
### Background
边缘设备的快速增长推动了在边缘部署人工智能的需求，产生了Tiny Machine Learning (TinyML)和其演变版本Tiny Deep Learning (TinyDL)。TinyML最初专注于在微控制器上实现简单的推断任务，而TinyDL则标志着向在资源极度受限的硬件上部署深度学习模型的范式转变。本文综述了TinyML到TinyDL的过渡过程，涵盖了架构创新、硬件平台、模型优化技术和软件工具链等方面的研究进展。该综述从当前最先进的量化、剪枝和神经架构搜索方法出发，考察了从微控制器到专用神经加速器的硬件趋势，并分类整理了软件部署框架、编译器和自动化机器学习工具。此外，研究跨领域如计算机视觉、音频识别、医疗健康和工业监测的应用实例，展示了TinyDL在实际中的影响。
### Innovation
本文通过对量化、剪枝和神经架构搜索等前沿技术的分析，以及对从微控制器到专用神经加速器的硬件趋势的考察，展示了软件部署框架、编译器和自动化机器学习工具的分类整理。重点介绍了TinyDL在计算机视觉、音频识别、医疗健康和工业监测等领域的实际应用，并指出了神经形态计算、联邦TinyDL、边缘本地化基础模型和领域专用联合设计等新兴方向。这些内容为研究人员和从业者提供了一个全面的边缘人工智能生态系统视图，并为基础研究未来的进步奠定了基础。
### Conclusion
本文旨在成为研究人员和从业者的基础资源，提供了边缘人工智能生态系统的全面视角，并为未来边缘AI的发展奠定了基础。
## 655. `cs.LG` - 这些不是您寻找的所有特征：监督预训练中的一个基本瓶颈 [PDF](https://arxiv.org/pdf/2506.18221), [HTML](https://arxiv.org/abs/2506.18221)
### Authors
Xingyu Alice Yang,Jianyu Zhang,Léon Bottou
### Background
尽管迁移学习是现代机器学习中的关键组成部分，可以利用预训练模型来适应新任务而无需大量新数据，但在确保转移特征能处理未见过的数据集方面仍然存在重大挑战。此外，判断两个任务是否相关以进行有效迁移也十分困难。因此，本研究旨在评估预训练混合模型向其各个组件任务转移的能力，考察预训练特征能否达到专用于特定任务的直接训练的性能。研究发现，深度学习模型存在一个“信息饱和瓶颈”，即在训练中编码相似竞争特征后，网络无法再学习新特征。因此，若只在预训练中学习少量关键特征，模型在迁移时将永久丢失重要特征，并在数据分布上表现出不稳定的表现。已有研究指出，这些现象在深度学习架构中普遍存在，特征学习方法受到数据分布或排序等因素的影响。研究建议，当有任务特异性训练时，依赖大规模网络可能不如关注任务特异性训练更为有效。
### Innovation
本研究揭示了深度学习模型在预训练中存在一个“信息饱和瓶颈”，并发现仅在预训练中学习少量关键特征会导致迁移性能的不稳定下降。研究提出了更丰富的特征表示作为解决这一问题的潜在方案，并介绍了一种新的方法，为解决该挑战的初步步骤。
### Conclusion
该研究建议，应考虑任务特异性训练而非仅依赖大规模预训练模型来提高模型在新数据集上的泛化能力。同时提出了现有方法与一种新型方法结合的方案，旨在解决深度学习架构中广泛存在的这个问题。
## 656. `cs.LG` - 多偏好Lambda加权列表DPO方法以实现动态偏好对齐 [PDF](https://arxiv.org/pdf/2506.19780), [HTML](https://arxiv.org/abs/2506.19780)
### Authors
Yuhui Sun(University of Alberta),Xiyao Wang(University of Toronto),Zixi Li(Zhejiang University),Jinman Zhao(University of Toronto)
### Background
大型未监督语言模型能够捕捉广泛的世界知识和推理能力，但引导其行为朝着预定目标仍然具有挑战性，因为缺乏明确的监督。现有的对齐技术，如基于人类反馈的强化学习（RLHF），依赖训练奖励模型并进行强化学习来与人类偏好对齐。然而，RLHF通常计算密集、不稳定且对超参数敏感。为解决这些限制，引入了直接偏好优化（DPO）作为一种轻量级且稳定的替代方案，通过分类损失直接将语言模型与成对偏好数据对齐。然而，DPO及其扩展通常假设有单一静态偏好分布，限制了在多目标或动态对齐场景中的灵活性。
### Innovation
本文提出了一种新的框架：多偏好Lambda加权列表DPO，扩展了DPO以包含多个维度的人类偏好（如帮助性、无害性和信息性），并通过可控单纯形加权形式实现动态插值。该方法支持列表偏好反馈并在不同用户意图之间的灵活对齐，无需重新训练。实证和理论分析证明，该方法在静态目标上与传统DPO一样有效，但在实际部署中具有更大的通用性和适应性。
### Conclusion
我们的方法在静态目标上与传统DPO一样有效，但在实际部署中具有更大的通用性和适应性。
## 657. `cs.LG` - 基于理性视角的在上下文学习策略的产生 [PDF](https://arxiv.org/pdf/2506.17859), [HTML](https://arxiv.org/abs/2506.17859)
### Authors
Daniel Wurgaft,Ekdeep Singh Lubana,Core Francisco Park,Hidenori Tanaka,Gautam Reddy,Noah D. Goodman
### Background
最近有关在上下文学习（ICL）的研究已经识别出了一系列不同实验条件下描述模型行为的广泛策略。本文旨在通过探讨模型为何在一开始学习这些不同的策略来统一这些发现。文章观察到，在文献中流行的多项任务训练时，模型用于进行ICL的学习策略能够被解释为一组贝叶斯预测器：包括一个记忆型预测器，假设一个离散先验的已见任务集；以及一个泛化型预测器，其中先验与真实任务分布匹配。采用理性分析的规范视角，即将学习者的行为解释为在给定计算约束的数据下的最优适应，本文提出了一个层次化的贝叶斯框架，几乎完美地预测了Transformer在训练期间的下一个标记预测，而无需假设访问其权重。
### Innovation
本文通过高层次贝叶斯框架提供了一种解释性预测模型ICL行为的框架，该框架基于策略损失与复杂性之间的权衡。该框架暗示了常见于神经网络学习动力学中的假设，明确了一个策略的偏好在多大程度上受到其复杂性和数据解释性的驱动力。此外，该框架揭示了已知的ICL现象，并提出了新的预测，如：随着任务多样性的增加，从泛化到记忆的转换时间呈现超线性趋势。
### Conclusion
本文通过强调策略损失与复杂性之间的权衡，提出了一个解释并预测ICL的框架，该框架基于神经网络学习的常见假设。这有助于解释已知的ICL现象，并提供了新颖的预测，说明了模型为什么要学习这些不同的策略以及如何学习它们，从而推动了对ICL的解释和预测的理解。
## 658. `cs.LG` - 使用可变注意头高效生成图像 [PDF](https://arxiv.org/pdf/2211.05770), [HTML](https://arxiv.org/abs/2211.05770)
### Authors
Steven Walton,Ali Hassani,Xingqian Xu,Zhangyang Wang,Humphrey Shi
### Background
尽管将变压器集成到视觉模型中可以在视觉任务上取得显著改进，但这些模型在训练和推理过程中仍然需要大量的计算资源。受限注意机制虽能显著减轻这些计算负担，但代价是牺牲了全局或局部的连贯性。本文提出了一个简单有效的解决方法，即允许单个变压器的注意头同时关注多个感受野，从而减少上述权衡。作者通过把这种方法应用于基于StyleGAN的图像生成架构，开发了StyleNAT方法。
### Innovation
提出了一种简单但强大的方法——允许单个变压器的注意头同时关注多个感受野，以此减少资源消耗和提高效率。通过集成该方法到StyleGAN架构中，实现了在FFHQ数据集上达到2.05的FID值，比StyleGAN-XL提高了6%，同时减少了28%的参数量，并且吞吐量提升了4倍。研究还在FFHQ-256数据集上达到了Pareto前沿，并在其他数据集上展示了强大的高效图像生成能力。
### Conclusion
本文提出的StyleNAT方法在FFHQ数据集上实现了2.05的FID值，优于StyleGAN-XL，同时该方法在参数量和吞吐量方面均有所提升，还表现出了在其他数据集上的强大和高效图像生成能力。相关代码和模型预训练权重已公开分享。
## 659. `cs.LG` - 捕捉作者和文档表示中的风格 [PDF](https://arxiv.org/pdf/2407.13358), [HTML](https://arxiv.org/abs/2407.13358)
### Authors
Enzo Terreau,Antoine Gourru,Julien Velcin
### Background
深度自然语言处理（NLP）模型广泛使用连续且低维度的单词和文档表示。然而，很少有模型研究作者的表示学习。这些表示可以用于许多NLP任务，如作者识别和分类，或推荐系统。现有研究的局限性在于，它们没有明确捕捉写作风格，这使得它们难以应用于文学数据。
### Innovation
文章提出了一种基于变分信息瓶颈（VIB）的新架构，该架构可以学习作者和文档的嵌入表示，并带有风格约束。该模型在预训练的文档编码器上进行微调。通过添加预定义的风格特征来刺激写作风格的检测，使得表示轴相对于写作风格指标具有可解释性。文章在三个数据集上进行了评估：来自古腾堡项目的文学语料库、博客作者语料库和IMDb62，结果显示方法在作者归因方面的性能与最新基线相当或更优，同时更准确地捕捉了作者的风格方面的特点。
### Conclusion
文章提出的方法在三个数据集上的评估表明，它在作者归因任务中匹配或优于强/最新的基线，并且能够更准确地捕捉作者的风格方面。
## 660. `cs.LG` - 高维上下文博弈问题没有稀疏性约束 [PDF](https://arxiv.org/pdf/2306.11017), [HTML](https://arxiv.org/abs/2306.11017)
### Authors
Junpei Komiyama,Masaaki Imaizumi
### Background
研究了高维线性上下文博弈问题，其中特征数$p$大于预算$T$，甚至可能无限大。不同于之前大多数研究工作，我们不对回归系数施加稀疏性约束。相反，我们依赖于过参数模型的最近发现，以便分析数据分布的有效秩较小时最小范数插值估计器的性能。尝试了探索然后提交(EtC)算法来处理此类问题，并对其性能进行了研究。结果表明这种算法在平衡探索与利用之间取得了最优性能率。此外，还提出了自适应探索然后提交(AEtC)算法，实现了自动寻找最优平衡。通过一系列仿真评估了所提算法的性能。
### Innovation
我们研究高维上下文博弈问题，并提出探索然后提交(EtC)算法和自适应探索然后提交(AEtC)算法。特别是在数据分布的有效秩较小时，我们分析最小范数插值估计器的性能，并展示了算法在平衡探索与利用之间的最优性能率。
### Conclusion
我们提出了探索然后提交(EtC)算法和自适应探索然后提交(AEtC)算法，通过分析证明了这种算法在平衡探索与利用之间的最优性能率，并通过仿真验证了算法的有效性。
## 661. `cs.LG` - 使用动量改进的随机三次牛顿法 [PDF](https://arxiv.org/pdf/2410.19644), [HTML](https://arxiv.org/abs/2410.19644)
### Authors
El Mahdi Chayti,Nikita Doikov,Martin Jaggi
### Background
该研究聚焦于解决一般非凸优化问题的随机第二阶方法。现有方法通常需要使用大量数据样本，而在非凸情况下，这些方法无法保证全局收敛。为此，研究者们一直在探索稳定随机梯度和海森矩阵估计的新方法，以期提高算法在不同噪声水平下的鲁棒性和效率。
### Innovation
本文提出了一种特殊的动量版本来稳定随机梯度和海森矩阵估计，在牛顿方法中得到了应用。研究证明动量可以有效降低随机估计的方差，并使方法在任何噪声水平下都能收敛。通过引入三次正则化技术，证明了当每次迭代仅使用一个随机数据样本来计算时，我们的方法可以在一般非凸问题上达到二阶平稳点。这是该领域的一个突破，因为我们是第一个在非凸情形下证明随机三次牛顿法具有任意大小批次的全局收敛性的研究团队。此外，该方法在凸优化问题上的速度也有所提高，尤其是与具有动量的正则化牛顿方法相关的表现更为突出。
### Conclusion
通过引入特殊动量版本和三次正则化技术，本文提出的方法在非凸优化问题上实现了全局收敛，并且能够在每次迭代中使用单个随机数据样本，同时改善了凸优化问题上的求解速度。
## 662. `cs.LG` - 图神经网络在中微子物理事件重建中的应用 [PDF](https://arxiv.org/pdf/2403.11872), [HTML](https://arxiv.org/abs/2403.11872)
### Authors
V Hewes,Adam Aurisano,Giuseppe Cerati,Jim Kowalkowski,Claire Lee,Wei-keng Liao,Daniel Grzenda,Kaushal Gumpula,Xiaohe Zhang
### Background
LArTPC探测器技术提供了高分辨率的粒子相互作用信息，但要充分利用这些信息需要复杂高效的自动重建技术。本文介绍了NuGraph2，一种使用图神经网络（GNN）进行LArTPC中模拟中微子相互作用低级重建的方法。在MicroBooNE探测器几何结构中，模拟的中微子相互作用被描述为异构图，每个检测器平面的能量沉积形成二维子图上的节点。网络利用多头注意力信息传递机制在这些图节点上进行背景过滤和语义标签识别，以98.0%的效率识别主要物理相互作用，并以94.9%的效率对其进行粒子类型分类。同时，网络直接作用在多个二维表示的探测器可观测性上，但采用了三维上下文感知机制以保持这些表示的一致性。
### Innovation
NuGraph2架构采用了图神经网络，能够直接作用于多维表示的探测器可观测性上，并通过三维上下文感知机制实现了各表示的一致性。在推理阶段，该网路在CPU上耗时0.12秒/事件，在GPU上批量推理耗时0.005秒/事件。该架构旨在成为广泛应用于中微子物理中的粒子重建的一般解决方案，并具有跨多种探测器技术部署的潜力。更重要的是，其核心卷积引擎能够用于各种任务，不仅限于本文中描述的两项任务。
### Conclusion
作者总结了提出的NuGraph2架构的优势，并强调了其在中微子物理实验中的应用潜力，指出该网络可以用作各种探测器技术中粒子重建的一种通用方法，且提供的核心卷积引擎可以用于众多其他任务。
## 663. `cs.LG` - 解释性量子回归算法与编码数据结构 [PDF](https://arxiv.org/pdf/2307.03334), [HTML](https://arxiv.org/abs/2307.03334)
### Authors
C.-C. Joseph Wang,F. Perkkola,I. Salmenperä,A. Meijer-van de Griend,J. K. Nurminen,R. S. Bennink
### Background
混合变量子算法（VQAs）在解决组合优化、量子化学模拟、量子机器学习和量子纠错等实际问题方面具有潜力。然而，使用典型的随机参数或量子交替算符参数，这些变量子算法会变成一个不可信赖的黑盒子，无法进行模型解释，更不用说将其部署为基于关键决策的应用程序。即使这些变量子模型的参数仅是对量子门的影响角度，也缺乏模型本身的可解释价值。
### Innovation
本文构建了首个可解释的量子回归算法，其中量子状态准确地编码了经典数据表，并且变量子参数直接对应于作为构造实数的回归系数。这种算法具有高度的模型可解释性，并且优化成本较低，因为它具有适中的表达能力。此外，利用编码后的数据结构可以减少回归映射计算的时间复杂度。为了缩短非线性回归的电路深度，算法可以通过经典预处理构建非线性特征来扩展，将其作为独立的编码列向量。虽然最近作者实现了具有较低噪声的超导量子比特中的压缩编码实现，但仍展望潜在的量子实用性，即使用多量子门在中性冷原子和离子中实现压缩编码。
### Conclusion
该研究表明，通过在量子回归算法中纳入数据结构的编码可以实现高程度的模型解释性，并且该方法具有较低的优化成本。未来的研究可以探索在中性冷原子和离子中实施多量子门的可能性，以进一步提高算法的实际适用性。
## 664. `cs.LG` - SceneGenAgent：使用编码代理实现精确的工业场景生成 [PDF](https://arxiv.org/pdf/2410.21909), [HTML](https://arxiv.org/abs/2410.21909)
### Authors
Xiao Xia,Dan Zhang,Zibo Liao,Zhenyu Hou,Tianrui Sun,Jing Li,Ling Fu,Yuxiao Dong
### Background
工业场景建模对于工业制造中的模拟至关重要。尽管大型语言模型（LLMs）已经在从文本描述生成通用3D场景方面取得了显著进展，但在使用LLMs生成工业场景时，由于其对精确测量和定位的高要求，使得需要对空间布置进行复杂的规划。因此，现有的技术面临着独特而具体的挑战。
### Innovation
本文介绍了一个名为SceneGenAgent的基于LLM的工业场景生成代理，它通过C#代码生成工业场景。SceneGenAgent通过结构化和可计算的格式确保精确的布局规划，布局验证和迭代细化以满足工业场景的数量要求。实验结果表明，使用SceneGenAgent增强的LLMs在真实的工业场景生成任务中取得了高达81.0%的成功率，并且有效地满足了大多数场景生成需求。为了进一步提高可访问性，本文构建了一个名为SceneInstruct的数据集，用于微调开源LLMs以集成到SceneGenAgent中，实验表明在SceneInstruct上微调开源LLMs可取得显著的性能提升，Llama3.1-70B几乎具备了类似GPT-4o的能力。
### Conclusion
本文展示了通过SceneGenAgent及其配套的数据集SceneInstruct，利用LLMs在工业场景生成方面的性能显著提升，证明了这种方法对于合理规划与优化工业场景生成具有重要意义和实用性。
## 665. `cs.LG` - PuriDefense: 随机局部隐式对抗净化防御黑盒查询攻击 [PDF](https://arxiv.org/pdf/2401.10586), [HTML](https://arxiv.org/abs/2401.10586)
### Authors
Ping Guo,Xiang Li,Zhiyuan Yang,Xi Lin,Qingchuan Zhao,Qingfu Zhang
### Background
黑盒查询攻击对机器学习即服务（MLaaS）系统构成重大威胁，因为它们可以在不访问目标模型结构和参数的情况下生成对抗样本。传统的防御机制，如对抗训练、梯度屏蔽和输入变换，要么会带来高昂的计算成本，要么会影响非对抗输入的测试精度。这构成了一个新的挑战，需要新的防御方法来平衡计算成本和模型性能之间的关系。
### Innovation
提出了一种高效的防御机制PuriDefense，其特点是低推理成本下的随机局部块级净化操作，并结合轻量级净化模型。该方法利用局部隐式函数重建自然图像流形，从而减缓查询式攻击的收敛速度。其独特之处在于能够在不严重影响模型准确性的前提下提供防御，这得益于其采用的随机化和局部净化策略。
### Conclusion
通过对CIFAR-10和ImageNet的大规模实验，证明了基于PuriDefense的净化策略的有效性，并展示了其在对抗查询式攻击方面的显著增强效果。这种方法提供了在计算资源有限的情况下对抗黑盒查询攻击的一种有效途径。
## 666. `cs.LG` - 自调节神经发生用于在线增量数据学习 [PDF](https://arxiv.org/pdf/2403.14684), [HTML](https://arxiv.org/abs/2403.14684)
### Authors
Murat Onur Yildirim,Elif Ceren Gok Yildirim,Decebal Constantin Mocanu,Joaquin Vanschoren
### Background
神经网络在学习一系列任务或数据流时往往难以避免灾难性遗忘，而人类可以在没有明确提示的情况下不断学习和巩固新概念。在线增量学习旨在模拟这一能力，通过一次性处理每个样本而不需要任何时间点的任务或流提示，使其更加贴近实际情况。然而，现有方法通常依赖于存储数据子集或扩展初始模型架构，导致巨大的计算开销。因此，需要一种新的方法来解决在线增量学习中的灾难性遗忘问题，并尽可能减少计算开销。
### Innovation
为了解决上述问题，该研究提出了名为SERENA的新方法，该方法借鉴了‘自我调节神经发生’的机制，即大脑创建专用于特定功能的区域或回路。SERENA方法将每个概念编码为一种‘概念细胞’的专门网络路径，并将其整合到一个大型的网络中。一旦一个概念被学习，相应的概念细胞就会冻结，防止遗忘之前学习的信息。此外，研究还提出了两种新的连续学习场景，以更接近反映现实世界的条件，这些条件的特点是样本规模逐渐变化。通过实验证明，该方法不仅在十个基准测试上建立了新的最先进技术，还显著超过了离线监督批量学习的表现。研究还提供了该方法的代码。
### Conclusion
通过对比实验，该研究证明了SERENA方法在处理增量数据学习中的优势，并且证明了其不仅能建立新的最先进技术，而且在基准测试中表现更好，同时实验证明了其有效性。该方法提供了一种新的解决在线增量学习中灾难性遗忘问题的方法，将该领域向前推进了一步。
## 667. `cs.LG` - 从无人机图像中提取地理参考车辆轨迹的高级计算机视觉技术 [PDF](https://arxiv.org/pdf/2411.02136), [HTML](https://arxiv.org/abs/2411.02136)
### Authors
Robert Fonod,Haechan Cho,Hwasoo Yeo,Nikolas Geroliminis
### Background
本文讨论了从高空无人机图像中提取地理参考车辆轨迹的框架，解决了城市交通监控中的关键挑战以及传统地面系统的局限性。在韩国龙仁国际商务区进行了实地研究，使用多无人机实验覆盖20个交叉口，收集了四天的约12TB 4K视频数据。该研究展示了结合无人机技术和高级计算机视觉进行精确且成本效益高的城市交通监控的潜力，为智能交通系统的开发和交通管理策略的改进提供了宝贵的资源。
### Innovation
本文提出了多种创新贡献，包括针对高空视角定制的目标检测器、使用检测到的车辆边界框作为排除掩码进行图像注册的唯一轨迹稳定方法、基于正射影像和主框架的地理参考策略，以及增强的车辆维度估计和详细的道路分割功能，所有这些都增强了多无人机视角之间的一致对齐。此外，这些框架还具备鲁棒的车辆尺寸估计和详细的道路分割能力，使其能够进行全面的交通分析。
### Conclusion
通过将公开发布的Songdo Traffic和Songdo Vision数据集以及提取管道的完整源代码置于公共领域，本文建立了交通研究领域的新基准，展示了在数据质量和可再现性方面的新标准。结果表明，这种结合无人机技术和高级计算机视觉的方法可以用于精确且成本效益高的城市交通监控，提供了开发智能交通系统和改进交通管理策略的宝贵资源。
## 668. `cs.LG` - 使用音素提示：增强对非拉丁文字符语言的多语言能力 [PDF](https://arxiv.org/pdf/2411.02398), [HTML](https://arxiv.org/abs/2411.02398)
### Authors
Hoang H Nguyen,Khyati Mahajan,Vikas Yadav,Julian Salazar,Philip S. Yu,Masoud Hashemi,Rishabh Maheshwary
### Background
尽管多语言大语言模型在各类基准测试中表现卓越，但在非拉丁文字符语言上依然表现不佳，这是因为这些模型在预训练过程中主要使用了以拉丁字符为主的书写系统，这遮蔽了它们与非拉丁书写系统的音素共性。
### Innovation
本文提出利用音素转写作为互补信号来诱导不变的表示方式。研究结果显示，整合音素信号能够在非拉丁文字符语言和拉丁文字符语言之间的性能都得到提升，尤其是在减少两者间的性能差距方面有显著的效果。此外，通过细致的实验发现，音素和文字在上下文学习中会检索出不同的示例，因此提出了一种混合上下文学习（Mixed-ICL）检索策略，该策略能够实现对两者语言性能有显著提高（拉丁文字符语言提升至12.6%，非拉丁文字符语言提升15.1%）。
### Conclusion
该研究证明了在上下文学习中结合音素和文字特征对于改进多语言大语言模型在非拉丁文字符语言上的表现是有益的，而且混合检索策略能够显著提升两种书写系统语言的性能。
## 669. `cs.LG` - 一种增强无人机隐私与安全的新型联邦学习-Based IDS [PDF](https://arxiv.org/pdf/2312.04135), [HTML](https://arxiv.org/abs/2312.04135)
### Authors
Ozlem Ceviz(1),Pinar Sadioglu(1),Sevil Sen(1),Vassilios G. Vassilakis(2) ((1) WISE Lab., Deparment of Computer Engineering, Hacettepe University, Ankara, Turkey (2) Department of Computer Science, University of York, York, United Kingdom)
### Background
无人机（UAVs）在飞行自组网络（FANETs）中的操作面临由于这些网络的动态和分布式特性带来的安全挑战。先前的研究主要集中于中心化的入侵检测方法，假设有一个中央实体负责存储和分析所有设备的数据。然而，这些方法面临计算和存储成本高的问题，同时存在单点故障的风险，威胁到数据的隐私性和可用性。在互联设备之间普遍分散的数据加大了采用去中心化方法的需求。因此，本研究引入了一种基于联邦学习的入侵检测系统（FL-IDS），以解决传统中心化系统在FANETs中的挑战。
### Innovation
FL-IDS减少客户端和中央服务器的计算和存储成本，这对于资源受限的无人机来说至关重要。FL-IDS以去中心化的方式运作，使无人机能够协作训练全局入侵检测模型而不分享原始数据，从而避免传统方法基于收集的数据产生的延迟。本研究还引入了一种名为‘针对特定客户端的偏差’（BTSC）的方法，该方法进一步增强了FL-IDS在较低攻击者比例下的性能。实验结果表明，FL-IDS在与中心IDS（C-IDS）的性能相当的同时，还解决了隐私问题。
### Conclusion
本研究显著提升了UAV网络的安全性，通过引入一种以隐私为中心、适用于无人机网络的去中心化入侵检测方法。此外，通过提供一个用于FANETs和联邦学习的现实数据集，我们的方法在动态性和3D节点移动以及精确的联邦数据关联方面优于其他方法。
## 670. `cs.LG` - InterFormer：有效异构交互学习在点击率预测中的应用 [PDF](https://arxiv.org/pdf/2411.09852), [HTML](https://arxiv.org/abs/2411.09852)
### Authors
Zhichen Zeng,Xiaolong Liu,Mengyue Hang,Xiaoyi Liu,Qinghai Zhou,Chaofei Yang,Yiqun Liu,Yichen Ruan,Laming Chen,Yuxin Chen,Yujia Hao,Jiaqi Xu,Jade Nie,Xi Liu,Buyun Zhang,Wei Wen,Siyang Yuan,Hang Yin,Xin Zhang,Kai Wang,Wen-Yen Chen,Yiping Han,Huayu Li,Chunzhi Yang,Bo Long,Philip S. Yu,Hanghang Tong,Jiyan Yang
### Background
点击率（CTR）预测是推荐系统中的一个基本任务，它预估用户点击广告的概率。随着用户的个性化以及行为序列等异质信息的出现，从多方面理解用户兴趣成为可能。然而，现有方法在信息交互和信息聚合上存在不足：一方面信息流动是单向的，导致模式间信息交互不充分；另一方面过早的信息总结导致信息丢失。
### Innovation
本文提出了一种名为InterFormer的新模块，通过交错式交互学习异构信息。该模块实现了不同模式间的双向信息流动，为相互有益的学习提供支持，避免了过度信息聚合的问题，同时在每个数据模式中保留完整信息并通过独立的桥梁结构进行有效信息选择和总结。实验结果表明，所提出的InterFormer在两个公开数据集和一个大规模工业数据集上均达到了最佳性能。
### Conclusion
InterFormer通过交错式交互学习实现了不同模式间的双向信息流动和有效信息选择，成功解决了现有方法中的两个基本局限性，在实际应用中达到了最优的CTR预测效果。
## 671. `cs.LG` - 预训练可逆生成作为无监督视觉表征学习 [PDF](https://arxiv.org/pdf/2412.01787), [HTML](https://arxiv.org/abs/2412.01787)
### Authors
Rongkun Xue,Jinouwen Zhang,Yazhe Niu,Dazhong Shen,Bingqi Ma,Yu Liu,Jing Yang
### Background
近年来，基于得分匹配和流匹配的生成模型在生成任务方面取得了显著进展，但这些模型在辨别任务中的潜力尚未充分挖掘。先前的方法，例如生成分类器，并未充分利用这些模型的辨别任务能力，因为它们的设计较为复杂。之前的研究尚未全面发挥这些生成模型的高容量，以便为下游任务提供鲁棒性和普适性的特征提取器。
### Innovation
本文提出了一种名为Pretrained Reversible Generation (PRG)的方法，通过反转预训练连续生成模型的生成过程来提取无监督表示。PRG能够有效重用无监督生成模型，利用其高容量作为下游任务的特征提取器。该框架允许选择针对特定下游任务的特征层次结构。相比之前的方法，该方法在多个基准测试中表现一致优异，并在生成模型方法中达到了最先进的性能，其中包括在64*64分辨率的ImageNet数据集上获得了78%的-top-1 准确率。广泛的消融研究进一步验证了该方法的有效性。
### Conclusion
本文方法在多个基准测试中表现出色，提高了基于生成模型的方法的效果，尤其是在特定的视觉任务上达到了最先进的准确率，表明PRG方法能够在辨别任务上有效利用预训练生成模型的能力。
## 672. `cs.LG` - Split-Merge: 基于差异方法的主特征值问题 [PDF](https://arxiv.org/pdf/2501.15131), [HTML](https://arxiv.org/abs/2501.15131)
### Authors
Xiaozhi Liu,Yong Xia
### Background
对称正半定矩阵的主导特征向量的计算是许多以优化为主导的应用的基础操作。传统的基于商形式的方法通常面临计算效率低下和依赖于先验谱知识的挑战。
### Innovation
本文利用差异形式重新诠释经典幂法为一阶优化算法，并提供了新的收敛性分析，开发了以更大步长加速收敛且不增加计算成本的加速变体。在此基础上，引入了基于差异方法的一般化家族，其中提出了Split-Merge算法，无需谱知识即可实现加速收敛，并仅通过矩阵向量乘法操作。实验表明，Split-Merge在效率和可扩展性上显著优于现有方法，尤其在经典幂法上实现了超过10倍的加速，证明其在大规模问题中的实用效果。
### Conclusion
广泛的实验证明，Split-Merge在合成数据集和真实世界数据集上均展示了更高的效率和可扩展性，其在大型问题中的实际有效性尤为突出。
## 673. `cs.LG` - SDE Matching：一种无模拟的Latent Stochastic Differential Equations的可扩展训练方法 [PDF](https://arxiv.org/pdf/2502.02472), [HTML](https://arxiv.org/abs/2502.02472)
### Authors
Grigory Bartosh,Dmitry Vetrov,Christian A. Naesseth
### Background
隐含随机微分方程（SDE）是时间序列和序列建模的强大工具。然而，训练隐含SDE通常依赖于伴随灵敏度方法，这类方法需通过近似SDE解进行模拟和反向传播，这限制了其可扩展性。
### Innovation
本文提出了SDE Matching，这是一种新型的无模拟训练隐含SDE的方法。受到现代Scores-和Flow Matching算法启发，将其应用于随机动力学领域，用于时间序列和序列建模，消除了昂贵的数值模拟需求，实现性能与伴随灵敏度方法相当的同时极大地降低了计算复杂性。
### Conclusion
实验结果表明，SDE Matching在性能上与伴随灵敏度方法相当，但计算复杂性大幅降低。
## 674. `cs.LG` - 利用基础视觉变换器在材料中进行微结构-性能关系的机器学习 [PDF](https://arxiv.org/pdf/2501.18637), [HTML](https://arxiv.org/abs/2501.18637)
### Authors
Sheila E. Whitman,Marat I. Latypov
### Background
在计算材料科学中，从数据中学习微结构-性能关系的机器学习是一种新兴方法。现有的大多数机器学习努力集中于为每个微结构-性能关系开发特定任务的模型。本文提出了利用预训练的基础视觉变换器来提取任务无关的微结构特征，并进行轻量级的机器学习，以预测微结构依赖的性能特征。这种方法在两个案例研究中得到了验证：（i）基于模拟数据的两相微结构的弹性模量；（ii）基于文献中发表的实验数据的镍基和钴基超合金的维氏硬度。研究表明，基础视觉变换器可以提供稳定微结构表征，并高效学习微结构-性能关系，无需进行昂贵的任务特异性训练或微调定制的深度学习模型。
### Innovation
本文提出了利用预训练的基础视觉变换器进行微结构特征提取，并在此基础上进行轻量级机器学习，以预测微结构依赖的性能特征。这种方法利用了现有的强大视觉模型来提高性能预测的准确性和效率，无需进行复杂的模型训练和微调。
### Conclusion
研究结果表明，基础视觉变换器可以有效地代表微结构，并且可以通过相对简单的后续机器学习来高效地学习微结构-性能关系，从而不需要昂贵的任务特定训练或微调定制的深度学习模型。
## 675. `cs.LG` - 基于子空间距离的高效数据驱动模型减少的主动学习方法 [PDF](https://arxiv.org/pdf/2505.00460), [HTML](https://arxiv.org/abs/2505.00460)
### Authors
Harshit Kapadia,Peter Benner,Lihong Feng
### Background
在需要反复评估高保真动态系统的解，覆盖广泛的参数配置，并且没有访问底层控制方程的情况下，数据驱动的模型减少技术是首选。本文讨论了在这种场景下，如何通过主动学习方法构建参数化数据驱动的降阶模型，选择参数域中最重要的参数样本，使高保真度解在模型构建阶段动态增长，并使用主成分分析(POD)将高保真解快照表示为参数特定的线性子空间。
### Innovation
本文提出了一种基于子空间距离的主动学习框架，通过提供一种度量不同维度子空间相似性的度量方法，并证明这种度量是度量。此框架成功地应用于两种现有的非侵入式降阶建模方法，并为这两种方法提供了主动学习驱动的扩展，即SDE-ActLearn-POD-KSNN和SDE-ActLearn-POD-NN。此外，通过两个参量物理系统的实例展示了所提出的SDE-AL方法的有效性，突显了其效率优势。
### Conclusion
通过主动学习选择重要参数样本使高保真度解在模型创建阶段动态增加，利用主成分分析(POD)将解表示在参数特定的线性子空间中，用子空间之间的距离作为主动学习的导向机制，实验结果证实了该方法的有效性。
## 676. `cs.LG` - 高效逃逸鞍点的自限正则性下一般化平滑性 [PDF](https://arxiv.org/pdf/2503.04712), [HTML](https://arxiv.org/abs/2503.04712)
### Authors
Daniel Yiming Cao,August Y. Chen,Karthik Sridharan,Benjamin Tang
### Background
研究非凸函数的优化问题，这些函数不一定平滑（梯度和/或海森矩阵不一定Lipschitz连续）。平滑性假设在机器学习中既是理论也是实践上的一个限制条件，因此在理论上和实践中都存在利用一阶方法找到函数的广义平滑性下的第一或第二阶稳定点的研究。现有的方法主要集中于找到这类函数的一阶稳定点，但对于二阶稳定点的保证尚缺乏有效的理论支持和方法实现。已有研究工作主要集中在应用一阶方法找到满足广义平滑性条件的函数的一阶稳定点。该研究旨在开发一个新的框架，利用广义平滑性来系统地研究不同一阶优化算法的收敛性，特别是对于二阶稳定性点的情况。这项研究的背景研究了机器学习中广泛存在的非凸函数优化问题，尤其是那些满足广义平滑性条件的函数，对现有的优化方法进行了扩展和改进。
### Innovation
该研究开发了一个新的框架，用于系统研究一类一阶优化算法（称为下降过程）在广义平滑性条件下的收敛性。该框架不仅分析了一阶稳定点的收敛性，还首次建立了在广义平滑性条件下，一阶优化方法达到二阶稳定点的第一收敛性保证。这项研究对于优化问题中的稳定点分析提供了新的视角，并拓展了当前优化方法的应用范围。这项研究证明了许多经典示例符合这一框架，并强调了其实用含义。
### Conclusion
研究建立了一套新的框架，该框架能够系统地研究满足广义平滑条件的一阶优化算法的收敛性，特别是对于二阶稳定性的分析。研究首次证明了在广义平滑条件下，一阶优化方法可以达到二阶稳定点的收敛性。所开发的框架能够解释多种经典示例，具有重要的理论和实践意义。
## 677. `cs.LG` - Multi-凸规划法在离散隐因子模型原型开发中的应用 [PDF](https://arxiv.org/pdf/2504.01431), [HTML](https://arxiv.org/abs/2504.01431)
### Authors
Hao Zhu,Shengchao Yan,Jasper Hoffmann,Joschka Boedecker
### Background
离散隐因子模型（DLFMs）在机器学习、经济学、神经科学、心理学等多个领域广泛应用。然而，这些模型的拟合通常需要为每个特定模型开发定制的求解器，这消耗了大量的人力资源，并且限制在特定的DLFM实例上。因此，需要一种通用框架来简化DLFM的原型开发和求解过程。
### Innovation
本文提出了一种基于CVXPY的通用框架，允许用户通过简短的脚本指定并解决多种类型的DLFM拟合问题，包括回归和分类模型。该框架具有灵活性，并内置支持正则化项和DLFM参数及隐因子约束的功能，使得用户能够根据数据集和应用场景轻松创建DLFM结构。
### Conclusion
本文提供了一个开源的Python实现，并通过几个示例展示了该框架的应用，证明了其有效性和实用性。
## 678. `cs.LG` - PCF-Grasp: 将点云补全转化为几何特征以增强6-自由度抓取 [PDF](https://arxiv.org/pdf/2504.16320), [HTML](https://arxiv.org/abs/2504.16320)
### Authors
Yaofeng Cheng,Fusheng Zha,Wei Guo,Pengfei Wang,Chao Zeng,Lining Sun,Chenguang Yang
### Background
基于点云（2.5D点）的6-自由度（DoF）抓取方法已经在机器人抓取目标物体方面显示出显著潜力。然而，大多数现有方法依赖于从单视角深度图像生成的点云，这些点云仅提供物体单一侧面的表面信息，导致抓取算法错误判断物体形状，从而降低了抓取精度。人类可以凭借几何经验从单视角准确抓取物体，为解决这一问题，本文提出了一种新的6-DoF抓取框架，该框架通过将点云补全结果转化为物体形状特征来训练6-DoF抓取网络，从而提高抓取效率。由于网络生成和实际执行之间的差距，文中还引入了一种评分筛选机制来选取更易于执行的抓取提议，以提高实际操作中的抓取质量。
### Innovation
提出了一种新型的6-DoF抓取框架，通过将点云补全结果转化为物体形状特征来训练6-DoF抓取网络。该方法还引入了评分筛选机制，该机制选择更易于执行的抓取提议，从而在任何摄像机视角下保持高抓取质量。文中的实验表明，使用完整点特征能够生成更精确的抓取提议，而评分筛选机制极大地提高了实际机器人抓取的可信度。与现有方法相比，该方法在实际世界实验中的成功率提高了17.8%。
### Conclusion
该研究提出了一种基于点云补全的6-DoF抓取框架，通过将点云补全结果转化为物体形状特征来训练抓取网络，引入评分筛选机制优化抓取提议，显著提高了抓取精度和实际操作中的可靠性。
## 679. `cs.LG` - 一种基于SRBB近似酉合成的可扩展量子神经网络 [PDF](https://arxiv.org/pdf/2412.03083), [HTML](https://arxiv.org/abs/2412.03083)
### Authors
Giacomo Belli,Marco Mordacci,Michele Amoretti
### Background
介绍了用于近似任何酉演化的一种可扩展的量子神经网络方法，利用Standard Recursive Block Basis (SRBB)，并通过减少可控NOT (CNOT)的数量来优化。这种方法利用了李代数和它们的拓扑特性来获得酉算子的可扩展参数化方案。通过对现有文献中仅从理论角度已知的SRBB可扩展方案进行重新表述，以实现高效的算法实施和复杂度管理，并提出算法以减少CNOT的数量，从而获得仅需一层近似的新的可实施可扩展方案。利用PennyLane库评估了该可扩展CNOT减少量子神经网络的性能，并通过不同的酉矩阵（稀疏和稠密矩阵）进行测试，最多6个量子比特。测量了不同优化器下的近似效果，包括梯度基方法和Nelder-Mead方法。此外，还测试了基于SRBB的方法在实际硬件上的性能，并将其与文献中可用的有效近似和分解方法进行比较
### Innovation
提出了一个利用SRBB进行酉合成的可扩展量子神经网络，并通过减少CNOT的数量进一步优化。该方法不仅重新表述了先前仅理论性的SRBB可扩展方案，还提出了一种新算法来减少CNOT的数量，从而只需要一层近似，简化了实现方案。该网络的有效性通过PennyLane库中的不同酉矩阵进行了评估，包括梯度基方法和Nelder-Mead方法，并且通过实际硬件进行测试与对比分析
### Conclusion
通过SRBB的李代数和拓扑特性，提出了一种新的可扩展量子神经网络方法，能够减少CNOT的数量并提高效率。该网络适用于6个量子比特的多种不同类型酉矩阵的近似，并通过两种优化方法进行评估。实际硬件测试表明该方法的有效性，并且与文献中的其他近似分解方法相比具有竞争力
## 680. `cs.LG` - 基于情境感知的双重稳健半监督学习 [PDF](https://arxiv.org/pdf/2502.15577), [HTML](https://arxiv.org/abs/2502.15577)
### Authors
Clement Ruah,Houssem Sifaou,Osvaldo Simeone,Bashir Al-Hashimi
### Background
人工智能（AI）在下一代通信系统中的广泛应用受到数据异质性和网络条件多样性的影响，要求使用高度情境化的、特定于场地的数据。一种有希望的解决方案是在依赖真实世界数据的同时，利用网络数字孪生（NDT）生成的合成伪数据。然而，这种方法的有效性依赖于NDT的准确性，这在不同的情境下差异很大。为解决这一问题，本文提出了基于情境感知的双重稳健（CDR）学习，这是一种新颖的半监督方案，可以根据NDT在不同情境下的准确程度调整对伪数据的依赖。CDR在下行波束成形任务上的表现优于以前的先进方法，在标签数据较少的情况下，与双重稳健（DR）半监督学习相比，损失率降低了24%。
### Innovation
提出了基于情境感知的双重稳健（CDR）学习，这是一种新颖的半监督学习方案。该方法可以根据NDT的差异准确程度调整对伪数据的依赖，有效应对不同情境下NDT准确度的差异。实验证明此类方法在标签数据稀缺情况下相较于传统的半监督学习方法有更好的性能表现。
### Conclusion
基于情境感知的双重稳健（CDR）学习方案在标签数据稀缺条件下，通过调整对伪数据的依赖程度，有效提高了下游波束形成任务的性能，相对于传统的双重稳健半监督学习方法，损失率降低了24%。
## 681. `cs.LG` - 人工智能评估中的度量到意义：一种基于效度的框架 [PDF](https://arxiv.org/pdf/2505.10573), [HTML](https://arxiv.org/abs/2505.10573)
### Authors
Olawale Salaudeen,Anka Reuel,Ahmed Ahmed,Suhana Bedi,Zachary Robertson,Sudharsan Sundar,Ben Domingue,Angelina Wang,Sanmi Koyejo
### Background
尽管人工智能系统的能力和实用性已经得到了显著提升，但评估这些系统的严格规范却迟迟未能跟上。例如，关于模型是否具有通用推理能力等宏大声明，通常仅依赖于模型在狭窄基准测试上的表现，如通过研究生水平的考试题目，这样的评估方式给出的往往是有限且可能具有误导性的评价。本文提供了一种结构化的推理方法，用于根据可用的证据来评估不同的评价声明。文中讨论了如何通过分析数学基准测试成绩来判断模型是具备了解答数学测试题的能力，还是具备了更广泛的推理能力。这种方法适用于当前机器学习的范式，其中不同相关方提供性能数据和评估结果，下游用户利用这些数据来验证他们的声明和决策。此外，方法还帮助构建能够更准确地反映声明的评估工具。通过对认知心理学中的效度理论进行拆解，评估可以更有效地聚焦于给定声明的核心方面，从而提高评估的实际效用和决策的有效性。
### Innovation
本文提出了一种以效度为中心的框架，用于更准确地评估人工智能系统的性能。此框架通过详细分析度量手段与具体宣称之间的联系，特别是在视觉和语言模型评估中，能够更有效地识别出评估证据中最关键的因素，从而提高评估的有效性和实用性。
### Conclusion
通过结合认知心理学中的效度理论，本文的方法不仅能够加强评估与声明之间的联系，还能提高评估的实际效用和决策的有效性。这种方法为构建更有效的验证手段提供了新的视角。
## 682. `cs.LG` - 通过凸优化解决多臂 bandits 的逆问题 [PDF](https://arxiv.org/pdf/2501.18945), [HTML](https://arxiv.org/abs/2501.18945)
### Authors
Hao Zhu,Joschka Boedecker
### Background
我们研究了一类在神经科学和心理学研究中广泛用于行为建模的多臂 bandits 逆问题（IMAB）。传统上，IMAB 问题在一般情况下不是凸的，但我们可以通过变量变换将其松弛为凸问题。基于此，我们提出了一种两步序列启发式方法来近似解决 IMAB 问题，并探讨了某些条件下该方法能提供 IMAB 问题的全局解及其证书，同时也提出了近似方法以节省计算时间。实验表明，我们的启发式方法比直接通过重复局部优化求解 IMAB 问题更稳定，且能在显著减少运行时间的情况下达到蒙特卡洛方法的性能。我们的方法基于 CVXPY 实现，便于不懂凸优化的用户直接应用。
### Innovation
通过变量变换将 IMAB 问题松弛为凸问题，提出两步序列启发式方法近似解决 IMAB 问题，并通过局部优化的重复求解与蒙特卡洛方法进行对比，展示了启发式方法的优势和效率。
### Conclusion
我们的启发式方法不仅在稳定性上优于直接求解 IMAB 问题的方法，还能在大幅减少运行时间的同时达到与蒙特卡洛方法相当的性能。此外，我们提供的基于 CVXPY 的方法可以帮助非凸优化领域的用户轻松应用。
## 683. `cs.LG` - 通过潜在域Plug-and-Play降噪进行无线电图估计 [PDF](https://arxiv.org/pdf/2501.13472), [HTML](https://arxiv.org/abs/2501.13472)
### Authors
Le Xu,Lei Cheng,Junting Chen,Wenqiang Pu,Xiao Fu
### Background
无线电图估计（RME），也称为频谱制图，旨在从稀疏采样的测量中重建不同领域（例如空间和频率）的无线干扰强度。现有的RME方法依赖于手工设计或数据驱动的无线电地图结构信息。然而，手工设计的方法往往难以建模复杂的RF环境，而数据驱动的方法需要大量的训练数据，这使得它们难以快速适应现场传感任务。因此，本文提出了一种基于插件即用（PnP）去噪的无线电图估计（RME）方法，这是一种来自计算成像的技术。该方法利用了信号（如自然图像和无线电图）的去噪操作存在相似性这一观察，因此可以将用于自然图像设计或学习的复杂去噪器直接用于辅助RME，而无需使用无线电图数据进行训练。与直接在数据域上操作的传统PnP方法不同，该方法利用无线电地图的潜在结构，并提出了一种基于交替方向乘子算法（ADMM）的去噪方法，该方法可以在潜在域上进行去噪。这一设计显著提高了计算效率并增强了噪声抗性。理论方面，此方法的研究包括无线电地图恢复的可恢复性和ADMM算法收敛性的分析。合成数据和真实数据实验展示证明了该方法的有效性。
### Innovation
提出了基于插件即用（PnP）去噪的无线电图估计（RME）方法，该方法利用无线电地图的潜在结构，并提出了一种基于交替方向乘子算法（ADMM）的去噪方法，该方法可以在潜在域上进行去噪。这种设计显著提高了计算效率并增强了噪声抗性。通过这种技术，可以避免使用无线电图数据进行训练，从而加速了适应现场传感任务的过程。
### Conclusion
研究分析了无线电图恢复的可恢复性以及ADMM算法的收敛性，通过合成数据和真实数据实验验证了该方法的有效性。该方法在计算效率和噪声鲁棒性方面取得了显著的改进，能够更好地适应现场传感任务。
## 684. `cs.LG` - LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey [PDF](https://arxiv.org/pdf/2505.00753), [HTML](https://arxiv.org/abs/2505.00753)
### Authors
Henry Peng Zou,Wei-Chieh Huang,Yaozu Wu,Yankai Chen,Chunyu Miao,Hoang Nguyen,Yue Zhou,Weizhi Zhang,Liancheng Fang,Langzhou He,Yangning Li,Dongyuan Li,Renhe Jiang,Xue Liu,Philip S. Yu
### Background
最近的大语言模型（LLMs）进展激发了对构建完全自主代理的巨大兴趣。然而，基于LLM的完全自主代理仍然面临挑战，包括因幻觉导致的可靠性限制、复杂任务处理困难以及重要的安全和伦理风险，这些都限制了它们在实际应用中的可行性和可信度。为了克服这些限制，基于LLM的人机系统（LLM-HAS）将人类提供的信息、反馈或控制集成到代理系统中，以提高系统的性能、可靠性和安全性。这些合作系统通过利用人类与LLM型代理的互补优势，使人类和基于LLM的代理能够有效协作。
### Innovation
论文提供了一个全面而结构化的LLM-HAS综述。它澄清了基础概念，系统地阐述了塑造这些系统的核心组件，包括环境及画像、人类反馈、交互类型、协调和通信。论文还探讨了人机协作的新兴应用，讨论了从人类-人工智能协作中产生的独特挑战和机遇。通过汇集现有知识并提供结构化的概述，论文旨在促进这一快速发展的跨学科领域里的进一步研究和创新。
### Conclusion
通过汇集当前知识并提供一个结构化的概述，论文旨在促进对这一快速发展的跨学科领域的进一步研究和创新。这一领域因其快速演进而充满机遇，同时也面临着独特的挑战。
## 685. `cs.LG` - 二元线性分类中的均匀泛化误差的精确集中 [PDF](https://arxiv.org/pdf/2505.16713), [HTML](https://arxiv.org/abs/2505.16713)
### Authors
Shogo Nakakita
### Background
本文探讨了在二元线性分类问题中，均匀泛化误差围绕其期望值的集中情况，使用等周不等式的观点来进行分析。研究了输出标签与标签加权输入向量联合分布的Poincaré和对数-辛普尔森不等式，并据此推导出了集中界。研究表明，所推导的集中界在平衡标签情况下至多仅有适度的乘性常数差异。在渐进分析中，还表明当处于比例高度维度的情况下，均匀泛化误差几乎必然收敛到其期望值。利用这一收敛性，本文在无维度约束的条件下建立了均匀大数定律。
### Innovation
本文建立了输出标签与标签加权输入向量联合分布的Poincaré和对数-辛普尔森不等式，这些不等式被应用于推导出集中界。研究还展示了在极大广泛的应用场景下，均匀泛化误差几乎必然收敛到其期望值，特别是在比例高度维度的情况下。此外，基于这种收敛性，本文在无维度约束的条件下建立了均匀大数定律，这对理解和改进机器学习模型的泛化能力具有重要意义。
### Conclusion
本文研究了二元线性分类问题中均匀泛化误差的集中现象，并通过等周不等式和特定的不等式建立了精确的集中界。在维度不限制的情况下，基于这些集中界，研究证明了均匀泛化误差几乎必然收敛到其期望值的现象。这些结果为理解模型的泛化能力提供了新的视角，并建立了统一的理论框架。
## 686. `cs.LG` - TaxaDiffusion: 进阶训练的扩散模型用于细粒度物种生成 [PDF](https://arxiv.org/pdf/2506.01923), [HTML](https://arxiv.org/abs/2506.01923)
### Authors
Amin Karimi Monsefi,Mridul Khurana,Rajiv Ramnath,Anuj Karpatne,Wei-Lun Chao,Cheng Zhang
### Background
现有的扩散模型在生成精细图像时通常将每个物种作为一个独立类别进行处理，但这忽略了物种之间在形态、模式和颜色上的微小差异，可能影响生成的准确性。TaxaDiffusion 提出了一种利用分类学知识来逐步训练扩散模型的方法，从而能够更准确地生成动物图像，特别是在细节上。通过该方法可以有效利用物种间的视觉相似性，逐步从门级到科级、属级再到物种级进行精细训练，从而在有限的训练样本中实现高形态和身份准确性。
### Innovation
TaxaDiffusion 提出了一个利用分类学知识的训练框架，通过逐步从门级、科级、属级到物种级进行训练，能够更好地捕捉物种间共有的形态特征，从而在有限样本下实现精细物种的准确生成。相较于传统方法，这种方法能够明显提高细微差异的生成准确性，特别是在动物图像生成方面表现更优。
### Conclusion
通过大量实验，在三个精细分类的动物数据集上，TaxaDiffusion 明显优于现有方法，实现了更高质量的精细动物图像生成。该方法展示了在细粒度物种生成中的显著改进，未来可以进一步应用于更多种类的图像生成任务。
## 687. `cs.LG` - Metis-RISE：RL 激励并增强多模态推理模型学习 [PDF](https://arxiv.org/pdf/2506.13056), [HTML](https://arxiv.org/abs/2506.13056)
### Authors
Haibo Qiu,Xiaohan Lan,Fanfan Liu,Xiaohu Sun,Delian Ruan,Peng Shi,Lin Ma
### Background
近年来，大型语言模型（LLMs）取得了显著进展，催生了复杂的推理范式，这些范式现在被引入到多模态大型语言模型（MLLMs）中。然而，现有的方法往往存在不足：仅依赖强化学习（RL）的方法可能面临采样效率低和激活缺失推理能力的问题，而传统的先经过冷启动监督微调（SFT）阶段再进行RL的方法可能会限制模型的探索潜力，导致次优的收敛效果。
### Innovation
本文介绍了一种名为Metis-RISE（RL激励和SFT增强）的方法。与传统方法不同，Metis-RISE省去了初始SFT阶段，而是直接从RL阶段（例如使用Group Relative Policy Optimization变体）激励并激活模型的潜在推理能力。针对RL阶段中遇到的两个关键挑战：（1）任务中模型虽然拥有一致但偶尔应用的正确推理时的不高效轨迹采样，我们通过RL模型自身的自我提炼推理轨迹来解决；（2）模型完全失败的推理能力缺失问题，我们通过注入专家增强的知识来解决。
### Conclusion
Metis-RISE通过结合RL激励和SFT增强的策略，成功构建了两个规模分别为7B和72B参数的MLLMs版本。在OpenCompass多模态推理排行榜上的评估表明，两个模型均实现了同类模型中的最佳性能，72B参数版本的整体排名为第四。更多信息可以参考我们的开源项目页面。
## 688. `cs.LG` - 通过潜在空间强化学习引导您的扩散策略 [PDF](https://arxiv.org/pdf/2506.15799), [HTML](https://arxiv.org/abs/2506.15799)
### Authors
Andrew Wagenmaker,Mitsuhiko Nakamoto,Yunchu Zhang,Seohong Park,Waleed Yagoub,Anusha Nagabandi,Abhishek Gupta,Sergey Levine
### Background
机器人的控制策略从人类示范中学习已在许多真实世界应用中取得了显著成果。然而，在性能初始不理想，尤其是在新颖的开放世界设置中，基于行为克隆(BC)学习的策略通常需要收集更多的人类示范来进一步提高其行为——这过程既昂贵又耗时。相比之下，强化学习(RL)为自主在线策略改进提供了希望，但通常因为需要大量样本而难以实现这一点。
### Innovation
本文提出了一种利用强化学习加速从扩散策略（一种先进的基于行为克隆方法）中自主适应的方法，即通过潜在空间强化学习（DSRL）来调整BC策略。DSRL方法具有高样本效率，仅需对BC策略进行黑盒访问，并能够实现有效的现实世界自主策略改进，避免了调整基础策略权重所带来的挑战。
### Conclusion
通过在模拟基准、真实世界机器人任务和适应预训练通用策略上展示DSRL，证明了其在现实世界策略改进中的高效性和有效性能。
## 689. `cs.LG` - 从假到真：作为 discriminative 预测的奖励建模 [PDF](https://arxiv.org/pdf/2506.13846), [HTML](https://arxiv.org/abs/2506.13846)
### Authors
Runtao Liu,Jiahao Zhan,Yingqing He,Chen Wei,Alan Yuille,Qifeng Chen
### Background
有效的奖励模型对于视觉生成模型的后训练增强在强化学习中起着关键作用。然而，当前的奖励建模方法因依赖于大量的手动偏好标注数据或精心设计的质量维度而面临着实现复杂性的问题，这些维度往往是不完整且工程性的。这些方法通常需要大量的人力和工程资源，导致实现和维护的成本较高。
### Innovation
本文受到生成对抗网络(GAN)中对抗训练的启发，提出了GAN-RM，一种高效且无需手动偏好标注的奖励建模框架。GAN-RM 仅需要少量代表性目标样本（称为 Preference Proxy Data），训练奖励模型通过区分这些样本与模型生成的标准输出来实现。这种方法简化了奖励建模过程，降低了工程成本，提高了效率。全面的实验结果表明，GAN-RM 在多个关键应用中都表现出了有效性，包括文件级扩展、监督微调（SFT）和直接偏好优化（DPO）等后训练方法。
### Conclusion
通过使用GAN-RM，可以在不依赖大量手动标注数据和精心设计的质量维度的情况下，高效地构建奖励模型，在多个实际应用中验证了其有效性。此方法展示了在视觉生成模型的后训练增强中的潜力，也证明了其在提高模型性能方面的实际应用前景。
## 690. `cs.LG` - TracLLM：长上下文大语言模型的一般归因框架 [PDF](https://arxiv.org/pdf/2506.04202), [HTML](https://arxiv.org/abs/2506.04202)
### Authors
Yanting Wang,Wei Zou,Runpeng Geng,Jinyuan Jia
### Background
长上下文大语言模型（LLMs）在多个实际应用中得到部署，如检索增强生成（RAG）、代理和广泛的LLM集成应用中。给定一个指令和一段长上下文（如文档、PDF文件、网页），长上下文LLM能够生成与提供的背景相一致的输出，以提供更准确、更及时、可验证的输出，同时减少幻觉和不被支持的说法。这一过程提出了一个研究问题：如何确定长上下文中贡献最大的文本（如句子、段落或章节），这些文本对LLM的生成输出起决定性作用。此过程称为上下文倒溯，它有许多实际应用，例如：1）调试基于LLM系统的程序；2）对攻击（例如，提示注入攻击、知识篡改攻击）进行事后攻击法医分析；3）突出知识来源以增强用户对LLM生成输出的信任。现有的特征归因方法（如Shapley值）在应用于长上下文LLM的上下文倒溯时表现出性能不佳或计算成本高的问题。
### Innovation
本文开发了TracLLM，这是首款针对长上下文LLM的通用上下文倒溯框架。框架能够提高现有特征归因方法的有效性和效率。为了提高效率，TracLLM开发了一种基于启发式搜索的算法。同时开发了贡献得分泛化/去噪技术以提高TracLLM的准确性。实验结果显示TracLLM能够有效识别长上下文中导致LLM生成输出的文本。
### Conclusion
我们的评估结果表明，TracLLM可以有效地从长上下文中识别出对LLM生成输出起关键作用的文本。我们的代码和数据在此处提供：this https URL。
## 691. `cs.LG` - 使用SMILE：基于局部解释的统计模型无关可解释性对大型语言模型的解释 [PDF](https://arxiv.org/pdf/2505.21657), [HTML](https://arxiv.org/abs/2505.21657)
### Authors
Zeinab Dehghani,Mohammed Naveed Akram,Koorosh Aslansefat,Adil Khan
### Background
大型语言模型如GPT、LLAMA和Claude在生成文本方面变得非常强大，但它们仍然是黑箱，因此很难理解它们是如何做出决定的。这种透明度的缺乏在需要信任和问责制的领域尤其成问题。为了解决这个问题，我们引入了SMILE，一种新的方法，可以解释这些模型如何对提示的不同部分做出响应。SMILE是模型无依赖的，并通过稍作修改输入，测量输出的变化，然后突出显示有哪些词语产生了最大的影响。SMILE通过创建简单视觉热图来显示提示哪些部分最重要。我们对几款领先的大语言模型进行了测试，并使用准确率、一致性、稳定性和保真度等指标表明它提供了清晰可靠的解释。
### Innovation
SMILE是一种模型无依赖的方法，通过修改输入并测量输出变化，来解释大型语言模型如何响应提示的不同部分。它通过创建视觉热图来展示哪些部分的提示最重要。SMILE使用准确率、一致性、稳定性和保真度等指标展示了其解释的质量和可靠性。
### Conclusion
通过使这些模型更容易理解，SMILE使我们更接近于使人工智能更加透明和值得信赖。
## 692. `cs.LG` - A3: 用于注意力机制的分析性低秩逼近框架 [PDF](https://arxiv.org/pdf/2505.12942), [HTML](https://arxiv.org/abs/2505.12942)
### Authors
Jeffrey T. H. Wong,Cheng Zhang,Xinye Cao,Pedro Gimenes,George A. Constantinides,Wayne Luk,Yiren Zhao
### Background
大规模语言模型表现出色，但其庞大的参数量使得部署成本高昂。低秩逼近为一种有前途的压缩解决方案，但现有方法存在两个主要问题：(1)它们专注于最小化单个线性层的输出误差，而不考虑Transformer的架构特性；(2)它们将大型权重矩阵分解为两个小低秩矩阵。因此，这些方法往往比剪枝和量化等其他压缩技术效果较差，还会引入运行时开销，如为分解的小矩阵执行额外的GEMM内核操作。
### Innovation
本文提出A3，一种后训练低秩逼近框架，该框架将Transformer层划分为三个功能组件，即QK、OV和MLP。对于每个组件，A3都提供了一种解析的解决方案，通过减小每个组件内部的隐藏维度同时最小化各组件的功能损失（即注意力分数、注意力输出和MLP输出的误差），从而直接减少了模型大小、KV缓存大小和FLOP的数量，而无需引入任何运行时开销。通过扩展实验，表明A3在计算和内存相同的减少预算下，低秩逼近的LLaMA 3.1-70B的困惑度为4.69，相较于先前的领先方法7.87，提升了3.18。该方法还展示了kv缓存压缩、量化和混合秩分配以增强性能的多功能性。
### Conclusion
A3作为后训练低秩逼近框架，在保持性能的同时减少了模型大小、KV缓存大小和FLOP的数量。实验结果表明其性能优于当前最先进的方法，为优化从单一线性层损失优化到端到端性能改进的问题提供了新视角。
## 693. `cs.LG` - 通过应用机器学习分析纽约州房地产种族公平性 [PDF](https://arxiv.org/pdf/2505.16946), [HTML](https://arxiv.org/abs/2505.16946)
### Authors
Sanjana Chalavadi,Andrei Pastor,Terry Leitch
### Background
本研究分析了纽约州（NYS）和纽约市（NYC）的物业级别的房地产所有权模式，以揭示种族差异。研究采用了先进的种族/族裔推断模型（LSTM+Geo结合XGBoost过滤，验证精度高达89.2%），将预测的物业所有者种族构成与来自普查数据的居民人口进行比较。研究分别评估了全域模型和只有名字的LSTM模型在纽约市的表现，探讨地理空间上下文的融入如何影响预测和不平等估计。结果揭示了显着不公平，即白人相对于人口比例持有更多的物业和物业价值，而黑人、拉丁裔和亚裔社区在物业业主中的代表性不足。在少数族裔占多数的社区，尽管该社区主要是非白人，但产权是白人占主导地位。公司所有权（LLC、信托等）加剧了这些差距，减少了城市少数族裔社区的自住房主机会。研究还按种族细分了主要白人、主要黑人、主要拉丁裔和主要亚裔街区的物业所有权与人口，识别极端所有权不平等等问题，并对比了城市、郊外和农村的模式。这些发现突显了房地产所有权中的种族不平等持续存在，反映了更广泛的历史和经济力量，并强调了采用数据驱动的方法来解决这些问题的重要性。
### Innovation
研究采用了先进的种族/族裔推断模型LSTM+Geo结合XGBoost过滤，并准确地将预测的物业所有者种族构成与来自普查数据的居民人口进行对比。研究分别评估了全域模型和只有名字的LSTM模型在纽约市的表现，探讨地理空间上下文的融入如何影响预测和不平等估计。
### Conclusion
研究结果揭示了房地产所有权中的种族不平等，这些不平等反映了许多持久的历史和经济力量。强调了采用数据驱动的方法来解决这些问题的重要性。
## 694. `cs.SE` - 要求工程中的领域知识：一项系统性综述研究 [PDF](https://arxiv.org/pdf/2506.20754), [HTML](https://arxiv.org/abs/2506.20754)
### Authors
Marina Araújo,Júlia Araújo,Romeu Oliveira,Lucas Romao,Marcos Kalinowski
### Background
领域知识被认为是要求工程（RE）成功的关键组成部分，因为它提供了理解系统环境的概念支持，确保与利益相关者需求的一致性，并减少需求规范中的歧义。尽管领域知识的重要性得到了认可，但关于如何在RE实践中有效使用和执行领域知识的系统性研究仍然缺乏。
### Innovation
本文通过提供现有贡献的全面概述，包括将领域知识整合到RE实践中的方法、技术和工具，从而填补了这一空白。研究采用了混合搜索策略，并强调了开发可扩展、自动化和可持续的方法来整合领域知识以推进RE流程的研究方向。
### Conclusion
该研究通过提供一个全面的概述，有助于构建知识驱动的要求工程的概念和方法论基础。
## 695. `cs.SE` - 机器学习环境下的敏捷管理：一种系统综述研究 [PDF](https://arxiv.org/pdf/2506.20759), [HTML](https://arxiv.org/abs/2506.20759)
### Authors
Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski
### Background
机器学习（ML）系统在我们的社会中普遍存在，推动了重大的数字转型。ML开发的动态特性，表现为实验周期和数据快速变化，给传统的项目管理带来了挑战。敏捷方法因其灵活性和增量交付，似乎很适合应对这种动态性，但如何在基于ML的系统中有效应用这些方法并不明确。因此，需要一种经过定制的方法来解决这些挑战。
### Innovation
我们通过系统映射研究，综合数据库搜索和循环的前后迭代，确定了27篇关于2008年至2024年间基于ML系统的敏捷管理文章。从中，我们识别出八种框架，并将建议和实践归类为八个关键主题，如迭代灵活性、创新的ML特定制品和最小可行模型。主要挑战是ML相关任务的准确努力评估。本研究通过映射当前的研究状态、识别领域中的空白，并表明需要进行更坚实的实证评估来验证这些贡献，从而做出了贡献。
### Conclusion
这项研究通过映射当前的研究状态和识别领域中的空白，做出了贡献。尽管有相关工作，但仍然需要更坚实的实证评估来验证这些贡献。
## 696. `cs.SE` - 通过不确定的人类指导进行强化学习中的复杂模型变换 [PDF](https://arxiv.org/pdf/2506.20883), [HTML](https://arxiv.org/abs/2506.20883)
### Authors
Kyanna Dagenais,Istvan David
### Background
模型驱动工程问题往往需要复杂的模型变换（MTs），例如涉及广泛序列的链式变换。此类问题包括模型同步、自动模型修复以及设计空间探索等。手动开发复杂的MTs过程存在高错误率且通常不可行。强化学习（RL）是缓解这些问题的有效方式。然而，在处理复杂问题时，RL方法可能会表现出较差的性能，此时人类指导变得非常有用。
### Innovation
本文提出了一种通过RL以不确定的人类指导开发复杂MT序列的方法和技术框架。该框架允许用户定义的MTs映射到RL的基本元素，并执行为RL程序以找到最优MT序列。研究显示，即使人类指导存在不确定性，也显著提升了RL性能，并更有效地开发了复杂的MTs。该方法通过人类指导的确定性和及时性的权衡，在RL驱动的人机协同工程方法中迈出了重要一步。
### Conclusion
我们的方法证明了即使人类指导存在不确定性，也可以显著提升RL性能，实现更有效、更高效的复杂MT开发。通过权衡人类指导的确定性和及时性，我们的方法朝着RL驱动的人机协同工程迈进了一大步。
## 697. `cs.SE` - 为实际应用工程化RAG系统：设计、开发与评估 [PDF](https://arxiv.org/pdf/2506.20869), [HTML](https://arxiv.org/abs/2506.20869)
### Authors
Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson
### Background
检索增强生成（RAG）系统正成为将大型语言模型（LLMs）对接外部知识的关键方法，解决事实准确性与上下文相关性方面的局限性。然而，缺乏基于真实世界应用场景的RAG系统实施的实证研究，这些研究通过一般用户参与来评估，并附有系统的经验教训汇编。
### Innovation
本文提出了五个特定领域的RAG应用，应用于治理、网络安全、农业、工业研究和医学诊断等多个实际场景。每个系统结合了多语言OCR、语义检索和领域适配的LLM，通过本地服务器或云API部署，满足不同的用户需求。通过基于Web的评估，总共100名参与者在六个维度上评估了这些系统：易用性、相关性、透明度、响应性、准确性和推荐可能性。
### Conclusion
根据用户反馈和开发经验，文档记录了12条关键经验教训，重点凸显了技术、运营和伦理挑战，影响RAG系统在实践中的可靠性和可用性。
## 698. `cs.LG` - 从网络搜索迈向具备推理能力的深度研究：以推理代理激励搜索 [PDF](https://arxiv.org/pdf/2506.18959), [HTML](https://arxiv.org/abs/2506.18959)
### Authors
Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu
### Background
信息检索是现代知识获取的基础，能够每天处理数十亿查询，覆盖不同领域。然而，传统的基于关键词的搜索引擎已不足以应对复杂且多步骤的信息需求。随着大型语言模型（LLMs）的出现，它们通过自主推理、迭代检索和信息合成形成动态反馈循环，正在引领一种新的理念——代理深度研究。研究指出，从静态网页搜索到交互式的代理系统，这些系统能够进行规划、探索和学习，已经产生了显著的进步。
### Innovation
本文引入了代理深度研究的概念，这是一种超越传统信息检索技术的新型研究范式。文章详细描述了从静态网页搜索到交互式代理搜索系统的演变过程，并提出了测试时的扩展律来量化计算深度对推理和搜索的影响。通过基准测试结果和开源实现的支持，证明了代理深度研究不仅显著优于现有方法，而且将成为未来信息获取的主要范式。
### Conclusion
本文通过收集产业产品、研究论文、基准数据集以及开源实现等资源，展示了代理深度研究不仅优于现有方法，还对未来信息检索具有重大影响。
## 699. `cs.SE` - 通过自动化集成数据生成可靠不良事件概况以促进健康（GRAPH-AID）：一种半自动化本体构建方法 [PDF](https://arxiv.org/pdf/2506.20851), [HTML](https://arxiv.org/abs/2506.20851)
### Authors
Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty
### Background
随着数据和知识的迅速扩展，采用系统化的本体生成方法变得至关重要。面对数据体积的日益增加和内容的频繁变动，对数据库存储和检索信息以创建知识图谱的需求变得愈发急迫。原有的知识获取与表示方法（KNARM）提供了一种系统化的解决方案来应对这些挑战和构建知识图谱，但该方法揭示了将Neo4j数据库与Web本体语言（OWL）无缝整合的现有挑战。虽然之前有尝试将Neo4j中的数据整合到本体中，但这些方法通常要求使用者了解描述逻辑（DL）的语言语法，这对于许多用户来说可能并不熟悉。因此，需要一种更易用的方法来解决这一问题。
### Innovation
本文提出了一种用户友好的方法，利用Python及其rdflib库支持本体开发。通过将食品和药物管理局不良事件报告系统（FDA FAERS）数据库整合到Neo4j数据库中，展示了我们的新型方法。利用该数据集，我们开发了一个Python脚本，可以自动生成所需的类及其公理，从而简化了整合过程。这种方法为在快速增加的不良药物事件数据集中生成本体提供了一种切实可行的解决方案，支持了改进的药物安全性监测和公共卫生决策制定。
### Conclusion
通过自动化集成数据生成可靠不良事件概况以促进健康（GRAPH-AID）是一种半自动化的本体构建方法，该方法利用Python及其rdflib库来支持本体开发。该方法通过将FDA FAERS数据库中的数据整合到Neo4j数据库中进行展示，并且通过自动生成所需的类及其公理，简化了本体整合的过程，为快速增加的不良药物事件数据集提供了切实可行的解决方案，支持了药物安全性和公共卫生决策的改进。
## 700. `cs.LG` - HARPT: 一个分析移动健康应用中消费者信任和隐私担忧的语料库 [PDF](https://arxiv.org/pdf/2506.19268), [HTML](https://arxiv.org/abs/2506.19268)
### Authors
Timoteo Kelly,Abdulkadir Korkmaz,Samuel Mallet,Connor Souders,Sadra Aliakbarpour,Praveen Rao
### Background
当前，移动健康应用日益增多，用户对其隐私和信任的关注也越来越高。为了进一步推动用户隐私和信任的研究，作者们创建了一个大规模标注的移动健康应用商店评论语料库HARPT，涵盖超过48万个评论，分为七个类别，这些类别可以捕捉到应用程序信任、提供者信任和隐私问题的关键方面。创建HARPT的过程中，需要解决多个复杂性问题，包括定义细致的标签方案、从大量嘈杂数据中筛选相关内容以及设计一种兼顾扩展性和准确性的注释策略。
### Innovation
在创建HARPT过程中，作者们采用了多种创新方法，如基于规则的过滤、迭代的手动标注、有针对性的数据增强以及使用基于变换器的分类器进行弱监督注释，以加速语料库覆盖范围。还精心挑选了7000个评论进行手动标注，为模型开发和评估提供支持。同时，作者们测试了一系列分类模型，展示了可以通过基于HARPT的研究得出良好的结果，并为未来研究提供了基准。最重要的是，HARPT作为公共资源被释放，以便在医疗信息学、网络安全和自然语言处理等领域提供支持和使用。
### Conclusion
HARPT为研究健康信息学、网络安全和自然语言处理等领域提供了宝贵的资源，有助于进一步了解用户在移动健康应用中的信任和隐私担忧。通过HARPT的研究，可以更好地评估和改进移动健康应用的设计和性能，增强用户的信任感和安全性。
## 701. `cs.SE` - 合成需求的质量如何？评估大规模语言模型生成的用于AI4需求工程的数据集 [PDF](https://arxiv.org/pdf/2506.21138), [HTML](https://arxiv.org/abs/2506.21138)
### Authors
Abdelkarim El-Hajjami,Camille Salinesi
### Background
公共的、带有标签的需求数据集短缺依然是推进需求工程中人工智能（AI4RE）发展的主要障碍。尽管大型语言模型展示了生成合成数据的潜力，但系统地控制和优化生成需求的质量的方法依然未被充分探索。该项研究旨在通过增强产品线方法生成合成需求数据，该方法包括先进的生成策略和内容质量管理技术。研究通过评估四类任务的数据质量（缺陷检测、功能性与非功能性、质量与非质量、安全与非安全）来考察多种提示策略、自动化提示优化和生成后的内容质量管理对数据质量的影响。研究结果展示了生成多个样本的提示策略在提升合成数据可用性和多样性上的卓越效果，并相较于人工编写的需求，在安全性和缺陷分类上的性能优于人工数据。
### Innovation
合成需求数据生成中引入了先进的生成策略和内容质量管理技术，特别是通过多样本提示策略提升合成数据的质量，并考察了PANCE（提示行动-批评编辑）的自动化提示优化方法在不同任务上的效果，同时通过类似性的数据质量管理技术增强了数据的多样性。研究成果强调，合成需求数据在特定任务上可以达到或超越人工编写的标准，特别是在安全性和缺陷分类任务上，合成数据表现更优。
### Conclusion
研究结果提供了关于AI4RE实践的具体见解，并为通过系统性的合成生成方法解决数据集短缺问题铺平了道路。
## 702. `cs.SE` - KOALA：一种收集解决编程任务过程中IDE数据的可配置工具 [PDF](https://arxiv.org/pdf/2506.21266), [HTML](https://arxiv.org/abs/2506.21266)
### Authors
Daniil Karol,Elizaveta Artser,Ilya Vlasov,Yaroslav Golubev,Hieke Keuning,Anastasiia Birillo
### Background
收集学生解决编程任务的数据对研究人员和教育者来说极其宝贵。这些数据可以验证学生是否正确应用了教授的特性与概念，或揭示学生的误解。然而，现有的数据收集工具存在限制，例如缺乏对收集代码粒度的控制、无法收集特定的编程环境事件，以及整体使用配置困难。因此，需要一种新的工具来解决这些限制，以便更好地收集相关数据。
### Innovation
提出KOALA，一种方便且高度可配置的工具，用于从学生在JetBrains IDEs中解决编程任务时收集代码快照和特征使用情况。该插件可以安装在IDE中，并根据需求配置以提供必要的任务、启用或禁用某些IDE功能（如代码自动完成）以及运行调查。此外，收集的数据可以按照标准化的ProgSnap2格式存储并在服务器上进行转换。KOALA的独特之处在于它能够更好地控制数据收集的粒度并收集更广泛的事件。
### Conclusion
该研究展示了KOALA工具如何从两个课程中28名学生在IDE中解决任务时收集数据，展示了收集到的一些建设性见解。该工具为未来的研究和教育提供了有价值的数据支持。
## 703. `cs.SE` - GPU Kernel Scientist: 一种基于LLM的迭代内核优化框架 [PDF](https://arxiv.org/pdf/2506.20807), [HTML](https://arxiv.org/abs/2506.20807)
### Authors
Martin Andrews,Sam Witteveen
### Background
优化GPU内核以获得高性能是一个复杂的任务，通常需要深厚的知识架构、广泛的性能分析以及迭代实验的结合。特别是在目标是较新的或文档较少的GPU架构时，传统的开发辅助工具匮乏，使得这一挑战变得更加严峻。
### Innovation
本文提出了一种基于LLM的“GPU内核科学家”，这是一种自动化的内核优化方法论，包含多阶段、进化的流程：（a）战略性地选择有前景的先前代码版本作为新迭代的基础；（b）根据现有代码和从通用GPU文献中吸收的知识生成优化实验假设；（c）自主实施这些实验，通过代码修改和提交给外部评估系统的后续提交，仅通过观察的时间数据作为性能反馈。此方法论详细说明了如何应对AMD MI300目标架构的挑战，并利用LLM弥补了有限的特定领域的人类专业知识，以促进GPU内核优化.
### Conclusion
由于在提交论文日期之前正在进行的性能竞赛的定量结果被禁止披露，我们在论文中呈现了该架构设计、操作工作流和定性见解，突显出基于LLM的代理在资源受限或硬件快速发展的环境中实现GPU内核优化民主化和加速的潜力.
## 704. `cs.SE` - 使用跨函数多方关联洞察提升漏洞检测 [PDF](https://arxiv.org/pdf/2506.21014), [HTML](https://arxiv.org/abs/2506.21014)
### Authors
Shaojian Qiu,Mengyang Huang,Jiahao Cheng
### Background
漏洞检测是确保软件系统安全的关键但具有挑战性的技术。目前，大多数基于深度学习的漏洞检测方法专注于独立函数，而忽视了复杂的功能间关系，特别是多边关联。这种忽视可能导致跨关系的漏洞检测失败。因此，需要一个能够检测这些复杂关联中漏洞的框架和方法。
### Innovation
本文提出了一个名为IFMA-VD的跨功能多边关联漏洞检测框架。该框架的核心在于构建代码行为超图，并利用超边卷积提取多边关联特征。首先将函数解析为代码属性图以生成函数内部特征，随后通过程序依赖图的分段构造代码行为超图以编码行为特征。最后，利用超图网络捕捉多边关联知识以增强漏洞检测。通过三个广泛使用的漏洞数据集评估IFMA-VD，并展示了其在F值和召回率方面优于基线方法。此外，证明了多边关联特征可以提升代码特征表示，并在实际数据集上验证了IFMA-VD的有效性。
### Conclusion
IFMA-VD框架通过构建代码行为超图并利用超边卷积提取多边关联特征，有效提升了漏洞检测的性能。实验结果表明，IFMA-VD在性能上优于现有的基线方法，并能有效增强代码特征表示。
## 705. `cs.SE` - IXAII: 一种用于决策支持系统的交互式可解释人工智能界面 [PDF](https://arxiv.org/pdf/2506.21310), [HTML](https://arxiv.org/abs/2506.21310)
### Authors
Pauline Speckmann,Mario Nadj,Christian Janiesch
### Background
虽然已经开发出几种后验可解释AI方法，但大多数都是静态的并且忽略了用户视角，限制了它们在目标受众中的有效性。
### Innovation
开发了一种交互式的可解释智能系统IXAII，该系统利用LIME、SHAP、Anchors和DiCE四种可解释AI方法提供解释，并为五类用户提供个性化的视角，赋予用户在解释内容和格式方面的自主权。通过连接可解释AI方法、互动性和实际应用之间的差距，IXAII提供了AI解释实践和人机交互的新视角。
### Conclusion
IXAII通过多种可视化选项提供不同的解释，被认为是增加透明度的有益工具。通过对专家和普通用户的访谈来评估IXAII，表明该系统提供了一个新的可解释AI实践和人机交互视角。
## 706. `cs.SE` - 一种以对象为中心的核心元模型，用于增强事件日志 [PDF](https://arxiv.org/pdf/2506.21300), [HTML](https://arxiv.org/abs/2506.21300)
### Authors
Yannis Bertrand,Christian Imenkamp,Lukas Malburg,Matthias Ehrendorfer,Marco Franceschetti,Joscha Grüger,Francesco Leotta,Jürgen Mangler,Ronny Seiger,Agnes Koschmider,Stefanie Rinderle-Ma,Barbara Weber,Estefania Serral
### Background
物联网（IoT）技术的进步促使物联网设备与业务流程（BPs）在各行业中的集成，如制造业、医疗保健和智能空间等。大量的物联网数据通过过程挖掘（PM）技术提供了了解业务流程的新途径。然而，实现这些优点需要将物联网数据与传统的流程数据进行整合，这由于两种数据的特性和粒度水平不同而变得具有挑战性。近年来，提出了多种数据模型来整合物联网数据与流程数据，但这些模型在不同的假设和要求下处理数据的方法不同，这使得数据交换和协作难以实现，阻碍了过程挖掘领域的数据共享和合作。
### Innovation
本文提出了一种核心模型，综合了现有数据模型的重要特性。该模型基于共同的需求，大大促进了过程挖掘领域中数据的共享和协作。通过使用原型Python实现，并针对各种应用场景进行评估，展示了该模型能够满足这些共同需求。
### Conclusion
该核心模型以对象为中心，整合现有数据模型的特点，简化了数据的交换和协作过程，使得研究人员能够更轻松地共享数据。
## 707. `cs.SE` - 维护MTEB：面向嵌入基准长期可用性和可再现性 [PDF](https://arxiv.org/pdf/2506.21182), [HTML](https://arxiv.org/abs/2506.21182)
### Authors
Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen
### Background
大规模文本嵌入基准（MTEB）已成为文本嵌入模型评估的标准平台。尽管以往的工作已经奠定了基准方法的核心，但本文专注于确保MTEB持续再现性和可扩展性的工程方面。作者介绍了维护稳健的持续集成流水线的方法，该流水线验证数据集的完整性、自动化测试执行，并评估基准结果的泛化能力。他们详细描述了集体增强再现性和可用性的设计选择。进一步地，作者讨论了处理社区贡献和使用新任务和数据集扩展基准的方法。这些工程实践在扩大MTEB的全面性的同时保持了质量和相关性，最终对领域产生了重大影响。作者的经验为基准维护者提供了宝贵的见解，他们面临确保机器学习评估框架中再现性和可用性的挑战。MTEB仓库可在该网址访问：this https URL
### Innovation
本文提出了维护稳健的持续集成流水线的方法，包括验证数据集的完整性、自动化测试执行，并评估基准结果的泛化能力，从而增强再现性和可用性。此外，作者还讨论了处理社区贡献和扩展基准的方法，这是MTEB能够扩大规模并保持质量和相关性的关键因素。这些工程实践有助于建立一个更加全面且高质量的基准，使其对领域保持相关性。
### Conclusion
本文的经验为基准维护者提供了宝贵见解，帮助他们确保机器学习评估框架中的再现性和可用性。MTEB的持续维护和扩展不仅增强了其可靠性和实用性，同时也促进了该领域的进一步发展。
## 708. `cs.SE` - ToolScan: 一种表征工具使用大语言模型错误的基准 [PDF](https://arxiv.org/pdf/2411.13547), [HTML](https://arxiv.org/abs/2411.13547)
### Authors
Shirley Kokane,Ming Zhu,Tulika Awalgaonkar,Jianguo Zhang,Thai Hoang,Akshara Prabhakar,Zuxin Liu,Tian Lan,Liangwei Yang,Juntao Tan,Rithesh Murthy,Weiran Yao,Zhiwei Liu,Juan Carlos Niebles,Huan Wang,Shelby Heinecke,Caiming Xiong,Silivo Savarese
### Background
评估大型语言模型（LLMs）是构建高性能复合型AI系统中最关键的方面之一。由于LLMs的输出会传递到下游步骤，因此识别LLMs中的错误对系统性能至关重要。在AI系统中，LLMs的一项常见任务是使用工具。尽管有许多基准环境可以对LLMs在该任务上的表现进行评估，但这些基准环境通常只提供成功率而没有解释失败案例。为了解决这个问题，我们引入了TOOLSCAN，一个新的基准用来识别LLMs在工具使用任务中输出中的错误模式。我们的基准数据集包含了可以用来测试七个新表征的错误模式的多样化环境中的查询。通过TOOLSCAN，我们证明即使是最突出的LLMs在其输出中也表现出这些错误模式。研究人员可以利用TOOLSCAN的这些见解来引导他们的错误缓解策略。
### Innovation
我们引入了TOOLSCAN，一个用于识别LLMs在工具使用任务中输出错误模式的新基准。该基准包含了可以用来测试七个新表征的错误模式的多样化环境中的查询，解决了现有的基准环境中只提供成功率而没有解释失败案例的问题。
### Conclusion
通过TOOLSCAN，我们展示了即使是最先进的LLMs在其输出中也表现出这些错误模式。研究人员可以利用这些见解来指导他们的错误缓解策略。
## 709. `cs.SE` - T³: 多级树形结构的大语言模型驱动的自动程序修复 [PDF](https://arxiv.org/pdf/2506.21211), [HTML](https://arxiv.org/abs/2506.21211)
### Authors
Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li
### Background
自动程序修复（APR）在软件开发与维护中是一个核心技术，旨在通过最少的人工干预自动化修复缺陷。近年来，大型语言模型（LLMs）和链式思考（CoT）技术取得了重大进展，大大提升了这些模型的推理能力。然而，由于APR任务中复杂逻辑和多步推理的需求，CoT技术的应用仍显不足。
### Innovation
该研究系统评估了多种常见CoT技术在APR任务中的表现，并提出了一个名为$T^3$的创新框架，该框架将LLMs的强大推理能力与树搜索技术结合，有效提高了生成候选修复方案的准确性。此外，$T^3$为优化APR任务中的样本选择和修复策略提供了有价值的指导，建立了一个强大的框架以实现高效的自动化调试。
### Conclusion
该研究通过将LLMs与树搜索技术相结合，提出了一种名为$T^3$的创新框架，显著提高了APR任务中候选修复方案的生成精度，为APR任务的优化提供了指导，促进了自动化调试框架的建立。
## 710. `cs.LG` - 超声图像解释和扫描指导的语义场景图 [PDF](https://arxiv.org/pdf/2506.19683), [HTML](https://arxiv.org/abs/2506.19683)
### Authors
Xuesong Li,Dianye Huang,Yameng Zhang,Nassir Navab,Zhongliang Jiang
### Background
理解医学超声成像一直以来都是一个挑战，因为成像和采集参数的巨大视觉变异导致的差异。近年来，大型语言模型（LLMs）被用于自动生成面向具有生理学知识的临床医生的术语丰富的摘要，然而，在非专家用户（如在床旁护理环境中）增加的对提高超声成像可解释性和基础扫描指导的需求尚未得到探索。这项研究首先提出了超声图像的场景图（SG），以解释图像内容并为普通用户提供超声扫描指导。通过使用基于变压器的一阶段方法计算超声场景图并消除显式对象检测的需求，然后再利用用户的查询进一步通过LLMs细化抽象的SG表示，生成普通用户易于理解的图像解释。预测的场景图被探索用于引导超声扫描以填补当前成像视图中的缺失解剖结构，辅助普通用户实现更标准化和完整的解剖探索。该方法在包括颈动脉和甲状腺在内的左颈部和右颈部图像上的五名志愿者上的验证结果显示，该方法有潜力最大限度地民主化超声成像，使其更易于理解和使用对于普通用户而言。
### Innovation
这项研究首次提出利用场景图（SG）来解释超声图像并提供扫描指导。通过使用基于变压器的一阶段方法计算SG以消除显式对象检测的需求；利用用户查询进一步通过大型语言模型（LLMs）细化抽象的SG表示，并生成普通用户易于理解的图像解释；探索预测的SG在引导超声扫描以填补当前成像视图中的缺失解剖结构中的潜力，辅助普通用户实现更标准化和完整的解剖探索。这种方法显著提升了超声成像的可解释性和对普通用户的友好性。
### Conclusion
通过使用场景图（SG）方法在超声成像领域的应用和探索，证实了该方法在提高普通用户对超声图像的解读和扫描操作能力方面具有巨大潜力。该研究不仅提出了一个新颖的方法，而且还通过实际数据验证了其有效性，为超声成像领域提供了更多可能性，特别是在非专家用户中。
## 711. `cs.SE` - 匿名网络感知图挑战 [PDF](https://arxiv.org/pdf/2409.08115), [HTML](https://arxiv.org/abs/2409.08115)
### Authors
Hayden Jananthan,Michael Jones,William Arcand,David Bestor,William Bergeron,Daniel Burrill,Aydin Buluc,Chansup Byun,Timothy Davis,Vijay Gadepally,Daniel Grant,Michael Houle,Matthew Hubbell,Piotr Luszczek,Peter Michaleas,Lauren Milechin,Chasen Milner,Guillermo Morales,Andrew Morris,Julie Mullen,Ritesh Patel,Alex Pentland,Sandeep Pisharody,Andrew Prout,Albert Reuther,Antonio Rosa,Gabriel Wachman,Charles Yee,Jeremy Kepner
### Background
MIT/IEEE/Amazon图挑战鼓励社区开发新的解决方案来分析来自社交媒体、传感器馈送和科学数据的图和稀疏数据，以发现事件之间的关系。隐匿网络感知图挑战旨在促进大规模的开放性社区方法以保护网络。许多大规模的网络问题仅可通过获取广泛数据集并给予隐私最高重视程度以及强烈社区参与度的社区访问来解决。 在更广泛的网络社区（商业、联邦机构及学术界）中，匿名源到目的地流量矩阵已作为一种数据产品出现，可满足许多这些需求。这次挑战提供了一个机会，展示了优化构建和分析这些流量矩阵的新型方法，使用来自全球最大的互联网望远镜（CAIDA）的数据包超过1000亿。
### Innovation
挑战的目的是提供一个明确的创新展示背景。图挑战参与者可以根据其创新要点选择（并附带解释）合适的挑战元素来展示其创新，并提供了一个具体的操作背景来强调创新性。隐匿网络感知图挑战提供了一个使用超过1000亿网络包来构建和分析流量矩阵的机会，这创造了展现创新算法和方法的独特场合，这涵盖从匿名化到分析的所有方面。
### Conclusion
该挑战旨在促进社区之间的发展与合作，鼓励数据的广泛共享和隐私保护。通过使用匿名的流量矩阵，促进社区为解决大型网络问题而合作创新。最终目标是创建一个具有良好定义背景以展示创新的环境，强调集体解决问题的方法，并创建利用图挑战数据进行研究和开发的空间。
## 712. `cs.SE` - SceneGenAgent: 通过编程代理实现精确工业场景生成 [PDF](https://arxiv.org/pdf/2410.21909), [HTML](https://arxiv.org/abs/2410.21909)
### Authors
Xiao Xia,Dan Zhang,Zibo Liao,Zhenyu Hou,Tianrui Sun,Jing Li,Ling Fu,Yuxiao Dong
### Background
在工业制造中，对工业场景的建模对于模拟至关重要。虽然大规模语言模型（LLMs）已经在生成一般3D场景方面取得了显著进展，但由于工业场景对精确度和定位的需求较高，使得这些场景的生成变得复杂，需要进行复杂的空间布局规划。如何简化这一过程并利用LLMs生成工业场景是一个挑战。因此，本文研究和提出了SceneGenAgent，这是一种基于C#代码的LLM代理，用于生成工业场景，以确保通过结构化的、可计算的格式、布局验证和迭代精炼来满足工业场景的定量要求。
### Innovation
本文提出的SceneGenAgent是一种基于C#代码的LLM代理，其创新之处在于能够确保精确的布局规划，并通过结构化的、可计算的格式、布局验证和迭代精炼满足工业场景的定量要求。此外，为了进一步增强其易用性，作者构建了SceneInstruct数据集，用于微调开源LLMs并集成到SceneGenAgent中。研究表明，对开源LLMs进行SceneInstruct数据集的微调可以显著提高其性能，Llama3.1-70B接近GPT-4o的水平。
### Conclusion
实验结果显示，由SceneGenAgent支持的LLMs在真实的工业场景生成任务中的成功率高达81.0%，且能够满足大多数场景生成的需求。此外，通过SceneInstruct数据集微调的开源LLMs性能显著改善。文章的代码和数据可以在以下链接获取：this https URL。
## 713. `cs.SE` - 探索微前端：在电子商务中的案例研究应用 [PDF](https://arxiv.org/pdf/2506.21297), [HTML](https://arxiv.org/abs/2506.21297)
### Authors
Ricardo Hideki Hangai Kojo(1),Luiz Fernando Corte Real(1),Renato Cordeiro Ferreira(1,2,3,4),Thatiane de Oliveira Rosa(1,5),Alfredo Goldman(1) ((1) University of São Paulo, (2) Jheronimus Academy of Data Science, (3) Technical University of Eindhoven, (4) Tilburg University, (5) Federal Institute of Tocantins)
### Background
在微前端架构风格中，前端被拆分为更小的组件，这些组件可以从小按钮到整个页面不等。此架构旨在提高可扩展性、韧性和团队独立性，但会有增加复杂性和基础设施需求的成本。本文旨在了解在工业背景下何时采用微前端是有价值的。为此，作者基于学术和灰色文献研究了微前端的最新状态，并在一个使用微服务的手工艺品市场中实施了这种架构风格。最终，通过半开放问卷调查了开发者的观点来评估其实施情况。这家研究中的市场公司在其主要系统（一个Java单体）和专用前端系统之间存在紧耦合的情况，且存在过时技术和开发者体验不佳等问题，因此需要架构变更，从而采用了微前端架构，包括API网关、后端为前端等模式，以及Svelte和Fastify等技术。虽然采用微前端是成功的，但在满足公司需求方面并不完全是必需的。问卷调查结果表明，其他替代方案，如单体前端，可能会取得类似的成效。在公司背景下，微前端的最便利之处在于单体架构的束缚和微服务的采用，这通过基础设施重用和团队之间的知识共享促进了实现过程。
### Innovation
1. 在已有微服务的环境下实施微前端架构，结合API Gateway和Backend for Frontend模式，利用Svelte和Fastify等现代技术进行实践。2. 通过半开放问卷调查对微前端的实施情况进行评估，确保其在公司的适用性和有效性。3. 分析发现，微前端不是唯一解决公司需求的技术途径，其他替代方案如单体前端同样可以达到类似的效果，这揭示了不同技术方案的考量因素和适用场景。
### Conclusion
尽管微前端架构在某些情况下可以有效解决系统耦合等问题，但并不是在所有场景下都必须采用。不同的技术方案都有其适用性和局限性，根据具体情况选择合适的技术架构能够更好地满足业务需求和发展。
## 714. `cs.SE` - 描述用于测试 Haskell 学生提交的控制台 I/O 行为 [PDF](https://arxiv.org/pdf/2008.09253), [HTML](https://arxiv.org/abs/2008.09253)
### Authors
Oliver Westphal,Janis Voigtländer
### Background
该研究提出了一种小型的形式化语言，用于指定简单控制台 I/O 程序的行为。设计灵感来源于测试学生编写的交互式 Haskell 程序的具体应用场景。所提出的规格语言在结构上类似于词法分析正则表达式，但加入了全局变量等特性，用于跟踪程序运行中的状态和历史记录，从而可以表达程序的动态行为。该文档概述了这些规格语言的设计动机及其在教育场景中的潜在应用。
### Innovation
该研究创新性地提出了一种不仅在结构上类似词法分析正则表达式的规格语言，还加入了全局变量等增强特性，从而能够表达更广泛的动态行为。此外，基于接受执行轨迹的语义定义了一种机制，通过采样来机械地以概率方式验证程序行为与规格的一致性。这种方法超越了仅用于测试的目标，还可以应用于教育中的其他方面，如提供更具帮助的反馈、生成示例解决方案和随机生成练习任务。
### Conclusion
该提案的方法为验证学生提交的 Haskell 程序行为提供了一个有价值的工具。通过定义有效跟踪集的语义，结合采样技术，以概率方式验证程序是否符合预期行为。这种方法具有广泛的应用前景，不仅限于单纯测试，还可以服务于教育目标的其他方面。
## 715. `cs.SE` - 大型语言模型赋能的C到Rust代码翻译代理 [PDF](https://arxiv.org/pdf/2505.15858), [HTML](https://arxiv.org/abs/2505.15858)
### Authors
HoHyun Sim,Hyeonjoong Cho,Yeonghyeon Go,Zhoulai Fu,Ali Shokri,Binoy Ravindran
### Background
C语言在构建系统级软件方面一直是基础性的，但由于其手动内存管理模型常常导致内存安全问题，现代系统编程语言Rust作为一种内存安全替代品而涌现。利用大型语言模型（LLMs）快速发展的生成能力，自动化C到Rust的翻译日益受到大规模遗留C代码的关注。然而，现有的基于LLM的方法限制了LLMs的静态提示响应行为，并且没有探索其执行问题解决能力。这对于C到Rust的翻译任务引入了独特的挑战，因为此类任务不同于传统的LLM代理应用（如数学或常识问答领域）。这些挑战包括缺乏并行C到Rust数据集、缺乏清晰定义的中间步骤以及如何组织这些步骤以构建正确的翻译轨迹。
### Innovation
为解决C到Rust翻译中的这些挑战，本文提出了一个新颖的中间步骤——基于虚拟 fuzzing 的等效测试（VFT），以及一种代理框架——LLM赋能的C到Rust代码翻译代理（LAC2R）。VFT指导LLM识别出导致原C函数与Rust等效版本之间行为差异的输入参数，生成有信息性的诊断以优化不安全的Rust代码。LAC2R使用蒙特卡洛树搜索（MCTS）系统地组织LLM诱发的中间步骤，以实现正确的翻译。通过实验证明，LAC2R能够有效进行大规模现实世界的C到Rust翻译测试
### Conclusion
LAC2R基于虚拟fuzzing的等效测试（VFT）指导LLM进行输入参数识别和诊断生成，以优化不安全的Rust代码。LAC2R使用蒙特卡洛树搜索（MCTS）组织中间步骤，以系统地进行正确的C到Rust翻译。实验结果表明LAC2R能够有效处理大规模的现实世界C到Rust翻译任务。
