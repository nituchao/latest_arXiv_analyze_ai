{"llm_update_time": "2025-06-25 09:11:21", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18920", "html_url": "https://arxiv.org/abs/2506.18920", "title": "信号使用与自发合作", "title_en": "Signal Use and Emergent Cooperation", "authors": "Michael Williams", "background": "本文研究了如何通过自主代理（组织成部落）的学习，发展出一种通过信号协调活动的方法，以提高其集体效率。利用NEC-DAC系统，即神经编码文化-分布式自治通讯器系统，每个代理都配备了用于决策的人工神经网络。我们的研究关注于这些代理部落内部文化的自我组织，以及不同的交流策略如何影响其适应性和合作程度。通过分析不同的社会结构，如权威等级制度，我们发现合作文化的形成显著影响了部落的表现。进一步的研究表明，不仅信号有助于文化的发展，还能使其在代理的代际间传承。同时，我们也探讨了在个体代理的神经网络内部协调行为和信号传递的好处。", "innovation": "提出了一种NEC-DAC系统，通过神经网络使代理可以自发发展出交流信号，这促进了其内部文化的形成。通过对不同社会结构的研究，展示了合作文化对代理部落性能的重要性，以及信号在代际传递中的角色。", "conclusion": "本研究展示了如何通过自主代理的学习与互动，发展出一种自发的合作文化，从而提高代理群体的集体效率。研究表明，有效的交流策略对于提高代理的适应性和合作程度至关重要，并且合作文化的形成不仅限于个体代内，还能传递给下一代代理。"}
{"llm_update_time": "2025-06-25 09:11:21", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18957", "html_url": "https://arxiv.org/abs/2506.18957", "title": "论点：将“思维的幻觉”中的推理悬崖重新解读为行动缺口", "title_en": "A Comment On \"The Illusion of Thinking\": Reframing the Reasoning Cliff as an Agentic Gap", "authors": "Sheraz Khan,Subha Madhavan,Kannan Natarajan", "background": "Shojaee等人（2025）的研究指出，大型推理模型（LRMs）在特定复杂性阈值之后会出现性能崩溃的现象，这种现象被解释为链式思维（CoT）推理的内在扩展限制。但本评论认为这种结论受到实验艺术的影响，认为这种性能崩溃并非指示存在根本的认知边界，而是系统级约束导致的结果，这些约束包括工具使用限制、上下文窗口回忆问题、关键认知基线缺失以及统计报告不足等。评论通过展示采用具身工具的模型能够解决问题，甚至超过推理悬崖的复杂性来反驳这一观点，并提出一种行动缺口的概念，即模型不是在推理上失败，而是在受限的接口下执行失败。", "innovation": "该评论通过实证方法，展现了一个有趣的现象：原先只能通过文本生成应对的模型，在具备主动工具后，能够解决复杂问题，并掌握更高复杂度的变体，这改变了对LRMs性能下降的理解。同时，作者提出了行动缺口的概念，指出这种现象是由于模型缺乏执行时所需的工具，而非真正的推理能力问题", "conclusion": "该研究重新定义了巨型推理模型的性能崩溃，并提出它们不是真正的推理能力问题，而是受制于工具和环境限制所致。同时，对具身推理的层次结构进行了分析，即从简单的程序执行到复杂的元认知自我纠正，这对机器智能的定义和测量具有重要意义。"}
{"llm_update_time": "2025-06-25 09:11:21", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19046", "html_url": "https://arxiv.org/abs/2506.19046", "title": "从行到产量：表格数据基础模型简化作物产量预测", "title_en": "From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction", "authors": "Filip Sabo,Michele Meroni,Maria Piles,Martin Claverie,Fanie Ferreira,Elna Van Den Berg,Francesco Collivignarelli,Felix Rembold", "background": "TabPFN在各种回归和分类任务中已显示出优于传统机器学习模型的性能。研究利用EOS和气象数据预测南非各省份夏季作物的产量，数据覆盖了23年，涉及8个省份。通过月度尺度的区域提取和聚合了辅助变量（即EOS和气象数据），并与六种机器学习模型和三种基线模型进行了比对。使用留一年验证的方法评估模型在预测未见过的数据年份的准确性。结果显示，TabPFN和机器学习模型的准确性相当，但TabPFN在调优时间和减少特征工程需求方面表现出色，使其在实际操作中更加可行。", "innovation": "TabPFN模型在表格数据任务中的应用，特别是在小到中等规模的表格数据上进行作物产量预测。研究特别强调了TabPFN在更快速的调整时间和更少的特征工程需求方面的优势，这使得TabPFN在实际操作中更具可行性。", "conclusion": "TabPFN和机器学习模型在预测作物产量准确度方面表现相当，但TabPFN在调整时间上更快且减少了特征工程的需求，因此更适合于需要高效操作和易于实现的实际应用。"}
{"llm_update_time": "2025-06-25 09:11:22", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19280", "html_url": "https://arxiv.org/abs/2506.19280", "title": "用户面向应用程序接口的情感检测：一种机器学习方法", "title_en": "Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach", "authors": "Feiting Yang,Antoine Moevus,Steve Lévesque", "background": "随着人机交互（HCI）的显著发展，情感识别能力被融入其中，创造了前所未有的机会，为用户带来适应性和个性化的体验。本研究探讨了将情感检测集成到日历应用程序中的可能性，使用户界面能够动态响应用户的情感状态和压力水平，从而提高生产力和参与度。研究主要采用两种情感检测方法：基于生物信号的方法（利用从心电图（ECG）信号中提取的心率数据进行长短期记忆（LSTM）和门控循环单元（GRU）神经网络预测情感维度），以及基于行为的方法（通过对计算机活动的多机器学习模型分析，根据鼠标移动、点击和键盘模式等细微用户交互来分类情感）。", "innovation": "论文提出并评估了两种互补的基于机器学习的情感检测方法，并从实际数据集中进行了对比分析，发现相比之下，基于计算机活动的方法在准确性和一致性方面表现更优，特别是在鼠标相关交互方面达到约90％的准确率。在基于生物信号的方法中，GRU网络在情感预测方面优于LSTM模型，情感维度Valence的预测准确率为84.38％。", "conclusion": "研究通过将情感检测整合到日历应用中，展示了用户界面能够动态调整以适应用户情感状态和压力水平的可能性，从而提升了生产力和用户体验。"}
{"llm_update_time": "2025-06-25 09:11:23", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19191", "html_url": "https://arxiv.org/abs/2506.19191", "title": "基于真相竞争的贝叶斯进化蜂群架构：一个形式化的知识系统", "title_en": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition", "authors": "Craig Steven Wright", "background": "本文介绍了一个严格的数学框架，用于描述由概率智能体组成的AI系统，这些智能体通过结构化的竞争和信念修正演变。该架构基于贝叶斯推理、测度论和种群动力学，定义了智能体的适应度，将其视为与固定外部Oracle（代表真实情况）一致性的函数。智能体在一个离散时间环境中竞争，通过观察结果调整后验信念，评级较高的智能体会进行复制，评级较低的会消亡。评级通过一对一系列真相对齐的效用比较更新，信念更新保持可测量的一致性和随机收敛。", "innovation": "论文引入了一个基于真相竞争的贝叶斯进化蜂群架构，该架构通过智能体的演化过程有效地累积知识。同时，引入了基于哈希的加密身份承诺以确保可追溯性，并使用do-因果推理操作。论文提供了关于收敛性、鲁棒性和进化稳定性的形式定理，证明了不可验证的知识在对抗性知识压力下可以进化为真实情况的吸引子，形成一种计算自我调节的蜂群系统，从而实现知识的有效累积和传播。", "conclusion": "该系统通过智能体的进化动态展示了真实情况作为进化吸引子的存在，证明了在能够计算和自我调节的蜂群中，可验证知识可以从对抗性知识压力中演化出来。"}
{"llm_update_time": "2025-06-25 09:11:24", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19224", "html_url": "https://arxiv.org/abs/2506.19224", "title": "GBGC: 通过粒度球计算实现高效且自适应的图粗化", "title_en": "GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing", "authors": "Shuyin Xia,Guan Wang,Gaojie Xu,Sen Zhao,Guoyin Wang", "background": "图的粗化目标是在保留原始图的关键信息的情况下生成更小、更易管理的图。先前的工作主要从保持频谱的角度出发，利用一些预先定义的粗化规则使原始图和粗化图的拉普拉斯矩阵的特征值尽可能匹配。然而，这些方法忽视了原始图由不同粒度级别的子区域组成的事实，高度连接和相似的节点应更倾向于在粗化图中聚合。通过结合图结构的多粒度特性，可以生成在最优粒度下的粗化图。", "innovation": "提出了一个新的高效且自适应的粗化方法，通过粒度球（GBGC）。该方法通过引入适应性粒度球图细化机制，从粗到细对原始图进行划分，并通过不同的大小和最优粒度的粒度球构造粗化图。相较于其他最先进的图粗化方法，该方法的处理速度可以提高数十到数百倍，且具有较低的时间复杂度。由于粒度球计算的良好稳定性和泛化性，GBGC的准确性几乎总是高于原始图，因此有可能成为标准的图形数据预处理方法。", "conclusion": "GBGC方法通过结合图结构的多粒度特性，提出了自适应的粒度球图细化机制，显著提升了图粗化的效果和效率。该方法具有高效、自适应和高性能处理能力，适用于图粗化等多种应用场景。"}
{"llm_update_time": "2025-06-25 09:11:24", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19095", "html_url": "https://arxiv.org/abs/2506.19095", "title": "Baba是LLM：动态规则游戏中推理", "title_en": "Baba is LLM: Reasoning in a Game with Dynamic Rules", "authors": "Fien van Wetten,Aske Plaat,Max van Duijn", "background": "大型语言模型（LLMs）在语言任务上表现出色，但难以处理涉及逻辑推理的任务。本研究考察了LLMs在玩2D谜题游戏Baba is You中的能力，该游戏涉及通过重新排列定义物体属性的文本块来调整规则。由于这种规则调整依赖于语言能力和逻辑推理，对于LLMs来说颇具挑战性。研究使用了不同类型的提示（简单、规则扩展和动作扩展提示），并对两种模型（Mistral，OLMo）进行了微调，以利用游戏中的文本和结构数据。研究表明，尽管较大的LLMs（尤其是GPT-4o）在推理和解谜方面表现更好，但未调整的小模型难以识别游戏机制或应用规则变化。微调有助于分析游戏级别，但并未显著提高解决方案的形成能力。研究表明，即使对于最先进的和微调过的LLMs，理解动态规则变化的推理仍然是一个难题，特别是要理解使用-提及的区别。研究结果为LLMs在复杂问题解决任务中的适用性提供了见解，并突显了具有动态规则变化的游戏适用于测试LLMs的推理和反思能力的适宜性。", "innovation": "本研究引入了特定的游戏环境Baba is You，这是一个依赖于语言能力和逻辑推理的游戏，考察了LLMs在这类任务中的表现。此外，研究还通过微调两种模型来利用游戏中的文本和结构数据，以提高模型在游戏中的表现。研究表明，尽管较大的模型在推理和解谜方面表现更好，但微调并没有显著提高解决方案的形成能力，特别是在理解动态规则变化方面存在挑战。这项研究为LLMs应对复杂任务提供了新的视角，并指出了进一步改进的方向。", "conclusion": "研究表明，即使是最先进的和经过微调的LLMs，理解动态规则变化的推理仍然是一个难点，特别是要理解使用-提及的区别。游戏Baba is You为测试LLMs的推理和反思能力提供了合适的环境，该研究为LLMs在复杂问题解决任务中的适用性提供了见解。"}
{"llm_update_time": "2025-06-25 09:11:25", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19235", "html_url": "https://arxiv.org/abs/2506.19235", "title": "RecLLM-R1：具有强化学习和思维链的两阶段训练范式v1", "title_en": "RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1", "authors": "Yu Xie,Xingkai Ren,Ying Qi,Yao Hu,Lianlei Shan", "background": "传统推荐系统面临“过滤泡”问题、外部知识利用不足以及模型优化与业务策略迭代脱节的挑战。为解决这些问题，本文介绍了RecLLM-R1，一种融合大型语言模型（LLMs）的新推荐框架，借鉴了DeepSeek R1的方法。该框架通过精心设计的数据构建过程，将用户画像、历史互动和多维物品属性转化为LLM可理解的自然语言提示。接着采用两阶段训练：第一阶段进行监督微调（SFT），赋予LLM基本推荐能力；第二阶段利用组合相对策略优化（GRPO）增强技术，辅以思维链（CoT）机制，旨在同时优化推荐的准确度、多样性和其他定制业务目标。", "innovation": "该论文创新性地引入了RecLLM-R1框架，融合了大型语言模型、数据构建过程、两阶段训练（包括监督微调和强化学习）、以及思维链机制。该框架通过同时优化推荐的准确度、多样性和其他业务目标，显著改善了推荐系统的性能，并提出了一种有效的解决过滤泡问题的方法和业务目标集成优化的新途径。", "conclusion": "RecLLM-R1在大规模社交媒体平台的真实用户行为数据集上取得了显著的性能，超越了现有的基线方法，涵盖准确度、多样性和新颖性等多个评估指标。它为推荐模型和政策的集成优化提供了一个有前景的路径，尤其是在复杂的业务目标下。"}
{"llm_update_time": "2025-06-25 09:11:26", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18928", "html_url": "https://arxiv.org/abs/2506.18928", "title": "大语言模型在何时翻转硬币方面是否知晓？通过推理与经验的战略随机化", "title_en": "Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience", "authors": "Lingyu Yang(1) ((1) Shanghai Jiao Tong University)", "background": "虽然在博弈论中，战略随机化是一个关键原则，但在大型语言模型（LLMs）中仍被严重忽视。先前的研究常常将认知性随机化与机械性随机生成混淆，导致评估不完善。本文基于天骥赛马的博弈论原理，提出了一种新型零和博弈，以探讨战略随机化在LLMs中的应用。博弈的复杂性使得未经训练的人类和不成熟的LLMs难以识别其最大熵策略。实验通过多场比赛考验不同提示风格下的五种LLMs，以区分它们在随机化决策上的能力差异。结果表明，较弱的模型对提示无响应保持确定性，而较强的模型则在明确提示下增加了随机性。面对弱模型时，强模型采用确定性策略以利用对方的偏差，但面对强对手时则逐渐采用均衡策略。", "innovation": "文章提出了基于天骥赛马原则的新型零和博弈，展示了在评估LLMs战略随机化能力时，通过隐藏的复杂性使得最大熵策略不易被识别。创新点在于将机械随机性和认知随机性区分开来，并通过不同时态的提示考察了不同能力的模型在随机化决策上的表现差异，揭示了LLMs在抽象推理和适应性学习上的改进空间。实验还包括采用比赛结果和贝叶斯因子分析来证明LLMs在战略推理能力上的实际差异，以及公开了实验代码以确保完全可重复性。", "conclusion": "研究展示了在面对不同强度的对手时，LLMs如何调整其随机化策略。较弱的模型保持确定性，较强的模型则在获得明确提示时增加了随机性，面对较弱者时采取确定性策略，而面对较强者时趋向于均衡策略。这一研究揭示了LLMs在战略性随机化上的难以捉摸之处，强调了在抽象推理和适应性学习方面的提高机会。实验公开的代码为后续研究提供了基础。"}
{"llm_update_time": "2025-06-25 09:11:28", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19185", "html_url": "https://arxiv.org/abs/2506.19185", "title": "Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs", "title_en": "Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs", "authors": "Janak Kapuriya,Aman Singh,Jainendra Shukla,Rajiv Ratn Shah", "background": "传统的心理健康支持系统基于用户当前的情绪和情况作出反应，导致表面化的干预措施，未能解决更深层次的情感需求。本文提出了一种新的框架，通过将《薄伽梵歌》中的精神智慧与高级大型语言模型GPT-4o结合，旨在提升情感健康。这项工作扩展了现有的ExTES心理健康数据集，加入了由GPT-4o生成并由领域专家评估的10,729个精神指导回应。", "innovation": "本文引入了GITes（《薄伽梵歌》集成疗法情感支持）数据集，通过GPT-4o生成并由领域专家评估的10,729个精神指导回应，与12个最先进的LLM进行基准测试。提出了新的灵性洞察度量标准，并使用LLM作为陪审团框架进行自动化评估。将精神指导整合到AI驱动的支持中，显著提高了最佳LLM Phi3-Mini 3.2B Instruct的情感和灵性度量标准，其ROUGE提升了122.71%，METEOR提升了126.53%，BERT得分提升了8.15%，灵性洞察度提升了15.92%，充分性和相关性分别提升了18.61%和13.22%。", "conclusion": "尽管这些结果在自动化共情和灵性度量方面显示出显著改善，但在现实世界患者群体中的进一步验证仍然需要。研究结果表明，具备精神指导的人工智能系统有极大潜力增强用户体验和感知支持结果。该代码和数据集将公开，以促进这一新兴领域的进一步研究。"}
{"llm_update_time": "2025-06-25 09:11:31", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19325", "html_url": "https://arxiv.org/abs/2506.19325", "title": "FEAT：一种通过低成本自动生成和标注框架生成英语AI辅导偏好反馈数据的方法", "title_en": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring", "authors": "Hyein Seo,Taewook Hwang,Yohan Lee,sangkeun Jung", "background": "在英语教育辅导中，教师反馈对于引导学生至关重要。近年来，基于AI的辅导系统开始协助教师，但这些系统需要高质量和大量规模的教师反馈数据，手动生成这种方式既耗时又昂贵。", "innovation": "提出了FEAT，一种低成本框架以生成教师反馈，并构建了三个互补的数据集：(1) DIRECT-Manual (DM)，人类与大规模语言模型合作生成高质量的教师反馈，但成本更高；(2) DIRECT-Generated (DG)，仅由大规模语言模型生成的低成本数据集但质量较低；(3) DIRECT-Augmented (DA)，主要基于DG，加入一小部分DM来提高质量同时保持成本效益。实验结果表明，将5-10%的DM加入DG中比单独使用100%的DM表现更优。", "conclusion": "实验结果显示，将小部分DM（5-10%）加入DG中比单独使用100%的DM更优，FEAT的成本效益框架在生成教师反馈方面具有优势。"}
{"llm_update_time": "2025-06-25 09:11:31", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19385", "html_url": "https://arxiv.org/abs/2506.19385", "title": "Conversational Intent-Driven GraphRAG: 通过适应性双重检索改进多轮对话系统中的流程模式和语境语义", "title_en": "Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics", "authors": "Ziqi Zhu,Tao Hu,Honglong Zhang,Dan Yang,HanGeng Chen,Mengran Zhang,Xilun Chen", "background": "现有的对话系统在保持多轮客户服务对话中的语境连贯性和目标导向进展方面存在局限性。传统的RAG系统仅依赖于语义相似性，而标准的知识图仅依赖于结构化的知识表示，两者都无法有效结合对话意图流模式和语境语义。", "innovation": "CID-GraphRAG框架通过从历史对话中构建动态意图转换图，并通过双重检索机制实现意图驱动图遍历与语义搜索的适配性平衡，解决了上述问题。它能够同时利用对话意图流模式和语境语义，显著提高检索质量和响应质量。该方法在真实世界的客户服务对话中进行了广泛实验，且与基于语义的对话RAG和基于意图的知识图RAG的基线相比，在所有评估标准上均表现出显著优势。", "conclusion": "CID-GraphRAG通过整合意图转换结构与语义检索，实现了保持语境连贯性和目标导向进展的效果，优于传统的RAG和GraphRAG方法。该框架为解决知识密集型多轮对话中的挑战提供了有效解决方案。"}
{"llm_update_time": "2025-06-25 09:11:32", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19408", "html_url": "https://arxiv.org/abs/2506.19408", "title": "是否基于对象的表示对机器人操控有益？", "title_en": "Is an object-centric representation beneficial for robotic manipulation ?", "authors": "Alexandre Chapin(imagine),Emmanuel Dellandrea(imagine),Liming Chen(imagine)", "background": "物体为中心的表示（OCR）近年来在计算机视觉领域引起了关注，用于学习图像和视频的结构性表示。大多数现有研究在场景分解方面评估这些模型，但不包含关于学习表示的推理过程。机器人操控任务通常涉及多个物体和潜在的物体间相互作用，因此可以作为一个有趣的实验环境来评估现有基于对象的表示的能力。研究者构建了一系列机器人操控任务，使用模拟环境涉及多个物体，并引入高度随机化因素如对象位置、颜色、形状、背景等，以测试现有方法在复杂场景结构下的泛化能力。", "innovation": "研究者创建了多个机器人操控任务，模拟环境中包含多个物体和高度随机化因素，以此来评估现有基于对象的表示方法在不同泛化场景下的表现。并将这些结果与最先进的整体表示方法进行了比较，以展示现有方法在复杂场景中的局限性和基于对象的表示方法的优势。", "conclusion": "现有方法在复杂场景结构下容易失败，而基于对象的表示方法能够克服这些挑战。"}
{"llm_update_time": "2025-06-25 09:11:34", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19420", "html_url": "https://arxiv.org/abs/2506.19420", "title": "Commander-GPT: 分割和路由以进行多模态讽刺检测", "title_en": "Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection", "authors": "Yazhou Zhang,Chunwang Zou,Bo Wang,Jing Qin", "background": "多模态讽刺理解是一个高层次的认知任务，尽管大型语言模型（LLMs）在许多下游NLP任务中表现出色，但证据表明，它们在讽刺理解方面存在困难。因此，需要开发新的方法来有效地处理讽刺理解问题。本文讨论了背景，指出LLMs在讽刺理解任务中的局限性，以及此类任务的复杂性。", "innovation": "本文提出了一种名为Commander-GPT的模块化决策路由框架，借鉴了军事指挥理论。该框架通过一个指挥官协调多个专业LLM代理，每个代理专注于不同的子任务，如上下文建模或情感分析。指挥官集成信息并作出最终的讽刺判断。此外，还介绍了三种类型的中央指挥官，分别为轻量级编码器命令官、小型自回归语言模型命令官，以及零样本操作的大规模LLM命令官。这些指挥官的创新设计旨在优化讽刺检测的性能，并展示了该方法的有效性。", "conclusion": "我们在MMSD和MMSD 2.0基准上的实验表明，我们的框架在F1分数上分别比最先进的基准提高了4.4%和11.7%，显示出该框架在多模态讽刺检测中的有效性。"}
{"llm_update_time": "2025-06-25 09:11:34", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19410", "html_url": "https://arxiv.org/abs/2506.19410", "title": "无监督数据字典学习在域移适应聚类中的应用：以坐姿识别为例", "title_en": "Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification", "authors": "Anas Hattay,Mayara Ayat,Fred Ngole Mboula", "background": "传统的聚类方法在处理多变数据集时缺乏适应性，并且容易受到域移问题的影响。这对于未监督的坐姿识别任务尤为重要，因为不同环境下的数据差异可能较大，传统的监督或半监督方法可能无法很好地适应这些变化。这些问题限制了现有方法在现实应用中的效果，特别是在需要高稳定性和准确性的领域中。", "innovation": "本文提出了一种新的无监督方法，称为Unsupervised Dataset Dictionary Learning (U-DaDiL)，它通过基于Wasserstein中位数表示的不同数据集分布对齐，来实现完全无监督的鲁棒聚类，尤其是在坐姿识别中。U-DaDiL方法有效解决了传统方法在处理多样数据集和域移问题时遇到的挑战，通过实验证明在Office31数据集上的聚类对齐准确性有了显著提升", "conclusion": "这项工作为解决域移和无监督坐姿识别中的鲁棒聚类提出了一个有前景的步骤。U-DaDiL方法通过有效对齐不同数据集的分布，显著提高了集群识别的准确性，并为坐姿识别的应用提供了新的思路和技术支持。"}
{"llm_update_time": "2025-06-25 09:11:40", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19530", "html_url": "https://arxiv.org/abs/2506.19530", "title": "NTRL: 使用强化学习进行动态难度调整的《龙与地下城》战斗场景生成", "title_en": "NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons", "authors": "Carlo Romeo,Andrew D. Bagdanov", "background": "在《龙与地下城》（D&D）中，调理对战场景是一个复杂的任务，需要DM手动评估队伍实力、敌人构成以及玩家之间的动态互动，同时避免打断叙事流程。这要求DM具备丰富的游戏经验和深厚的理解，对于非专业玩家来说，这可能是一个挑战。", "innovation": "提出了一种名为NTRL的全新方法，该方法通过使用强化学习自动化动态难度调整（DDA）的战斗场景设计。NTRL将问题框架化为一个上下文多臂老虎机，可以根据实时队伍成员的属性生成战斗场景。相比于传统的DM经验法则，NTRL迭代优化战斗场景，以增加战斗持续时间，提高对队伍成员的伤害，减少战斗后的生命值，并提高玩家死亡率，同时保持低总量角色杀戮（TPK）。通过强化战斗，迫使玩家审慎行动并采取策略性行动，同时保证了高胜率（70%）的战斗生成。此外，NTRL还表现出优于人类DM设计的战斗场景，通过增加战略深度和调整难度来维护整体游戏的公平性。", "conclusion": "该方法在增强战斗战略深度的同时增加了游戏难度，但保持了游戏的公平性，并且展示了针对《龙与地下城》动态难度调整的显著性能提升。通过强化学习，实现了对战斗场景的自动化生成和优化，为游戏设计者和DM提供了新的工具和思路。"}
{"llm_update_time": "2025-06-25 09:11:42", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19635", "html_url": "https://arxiv.org/abs/2506.19635", "title": "关于旧特征对于检测新机器人效果的研究", "title_en": "On the efficacy of old features for the detection of new bots", "authors": "Rocco De Nicola,Marinella Petrocchi,Manuel Pratelli", "background": "近年来，学术界和在线平台管理员一直在研究解决恶意机器人检测的问题。恶意机器人不仅用于传播垃圾信息、支持公共人物，还可能影响公众意见。为了对抗在线生态系统的机器人入侵，已经实施了各种方法，主要基于监督或非监督分类器，利用从Twitter公共API获取的用户数据的不同特征进行分析。本研究基于Twitter，对比了四种最先进的特征集在检测新型机器人方面的性能。", "innovation": "本研究采用了一种探索性方法，通过对比不同特征集在检测新型机器人上的效果，提出了使用通用分类器和相对便宜的用户数据特征来检测演变机器人的可能性。", "conclusion": "研究结果表明，可以使用通用分类器和易于计算的用户数据特征来检测新型机器人。"}
{"llm_update_time": "2025-06-25 09:11:42", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19500", "html_url": "https://arxiv.org/abs/2506.19500", "title": "NaviAgent：工具依赖图上的两层规划以实现函数调用", "title_en": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling", "authors": "Yan Jiang,Hao Zhou,LiZhong GU,Ai Han,TianLong Li", "background": "现有大语言模型（LLMs）依赖静态知识和脆弱的工具调用方式，限制了复杂异构工具链的协调与管理，尤其是在大规模应用时。现有的方法通常使用固定单路径执行策略，这导致了糟糕的错误恢复和快速增长的搜索空间。这些限制严重影响了模型的灵活性和有效性，尤其是在面对未知工具组合时。因此，需要一种能够提供稳定且高效的函数调用解决方案的新架构，能够动态适应多种场景，提供良好的错误恢复能力，并潜在地解决问题复杂度的挑战。", "innovation": "本文引入了NaviAgent，一种基于图导航的两层规划架构，用于增强函数调用的稳健性。NaviAgent 包含一个多路径决策器（Multi-Path Decider）和一个图编码导航器（Graph-Encoded Navigator）。多路径决策器定义了一个四维决策空间，能够动态感知环境状态并选择最优的动作，以覆盖所有工具调用的场景。图编码导航器构建了一个工具依赖异构图（TDHG），该图通过节点嵌入融合了API的结构和历史调用行为。此外，NaviAgent 还结合了一种新颖的启发式搜索策略，可以引导决策器走向高效的且成功率高的工具链，即使对于前所未见的工具组合也是如此。实验证明，NaviAgent 在所有基础模型和任务复杂度下都能实现最高的任务成功率，分别优于ReAct、ToolLLM和α-UMI等基线平均13.5%、16.4%和19.0%。", "conclusion": "NaviAgent 的执行步骤通常比最高效的基线工具链少一步，确保了高质量和高效率的平衡。值得注意的是，微调后的Qwen2.5-14B模型在我们的架构下实现了49.5%的任务成功率，超过了32B模型（44.9%）。图编码导航器的引入更是提高了任务成功率平均2.4点，在复杂任务上对更大模型（如Deepseek-V3和GPT-4o）的提升超过9点，这凸显了其在工具链编排中的重要作用。"}
{"llm_update_time": "2025-06-25 09:11:42", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19613", "html_url": "https://arxiv.org/abs/2506.19613", "title": "Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI", "title_en": "Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI", "authors": "Sha Zhang,Suorong Yang,Tong Xie,Xiangyuan Xue,Zixuan Hu,Rui Li,Wenxi Qu,Zhenfei Yin,Tianfan Fu,Di Hu,Andres M Bran,Nian Ran,Bram Hoex,Wangmeng Zuo,Philippe Schwaller,Wanli Ouyang,Lei Bai,Yanyong Zhang,Lingyu Duan,Shixiang Tang,Dongzhan Zhou", "background": "科学发现长期以来受到人类在专业知识、体能和睡眠周期方面的限制。最近，AI科学家和自动化实验室的兴起加速了研究的认知和操作方面。然而，这些系统仍然存在局限性：AI系统通常局限于虚拟环境，而自动化实验室缺乏灵活性和自主性，无法在物理世界中适应性地测试新假设。", "innovation": "最新进展中的具备主体性的AI（如通用机器人基础模型、基于扩散的动作策略、精细的操作学习以及从模拟到现实世界的转移），展示了将认知智能和主体性智能结合起来的潜力。这种结合开启了支持迭代式自主实验的闭环系统和偶然发现的可能性。本文提出了智能科学实验室（ISL）这一范式：这是一种多层次的闭环框架，深度整合了科学推理的基础模型、基于代理的工作流程编排和执行稳健物理实验的主体代理。", "conclusion": "我们主张这种系统的存在对于克服当前科学发现的限制以及实现通过AI驱动的科学的全部变革潜力至关重要。"}
{"llm_update_time": "2025-06-25 09:11:43", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19573", "html_url": "https://arxiv.org/abs/2506.19573", "title": "使用 FOLD-R++ 和回答集编程的可解释混合机器学习模型", "title_en": "Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming", "authors": "Sanne Wielinga,Jesse Heyninck", "background": "在高风险领域如医疗健康中，机器学习（ML）技术通过准确预测极大地提升了决策质量。然而，大多数性能卓越的方法如神经网络和集成方法往往具有黑盒性质，缺乏透明度，这限制了其信任度和更广泛的采用。与此同时，象征方法如回答集编程（ASP）可以提供可解释的逻辑规则，但通常无法达到ML模型的预测能力。因此，本研究提出了一种将FOLD-R++算法和ASP结合起来的混合方法，旨在利用ASP的规则生成可靠预测，并用黑盒ML分类器进行校正，同时提供可读性的解释，提升了模型的可解释性。", "innovation": "提出了将FOLD-R++算法的规则与黑盒ML分类器结合使用的创新方法，以实现选择性纠正不确定的预测，并提供人类可读的解释，同时保留了模型的高准确性，提高了系统的透明度和可解释性，弥补了黑盒模型和传统象征方法的不足。", "conclusion": "该研究通过在五个医疗数据集上的实验，展示了这种方法显著的性能提升，证实了将符号推理与传统ML结合可以提高模型的可解释性而不影响准确率，具有重要的应用前景。"}
{"llm_update_time": "2025-06-25 09:11:43", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19592", "html_url": "https://arxiv.org/abs/2506.19592", "title": "使用语言模型进行自适应领域建模：基于多智能体的任务规划方法", "title_en": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning", "authors": "Harisankar Babu,Philipp Schillinger,Tamim Asfour", "background": "目前的研究需要通过手动定义环境模型来解决复杂任务，这限制了问题的解决范围和灵活性。本文提出的TAPAS框架通过将大型语言模型与符号规划集成，不依赖于手动定义的环境模型即可解决复杂任务。TAPAS框架中的特殊大型语言模型代理能够协作生成和适应领域模型、初始状态和目标规范，并利用结构化工具调用机制，使下游代理能够向上游代理请求修改，进而适应新的属性和约束条件，无需手动重新定义领域模型。TAPAS的ReAct（Reason+Act）执行代理与自然语言计划翻译相结合，能够连接动态生成的计划与现实世界的机器人能力之间的差距，提高实际应用中的效能和灵活性。", "innovation": "TAPAS框架的创新在于通过结合大型语言模型和符号规划，能够在无需手动定义环境模型的情况下解决复杂任务，并通过协作代理机制自动调整领域模型与规划目标，增强了灵活性和适应性。ReAct执行代理和自然语言计划翻译相结合，有效将计划与实际机器人操作连接起来，提升操作效率和可用性。", "conclusion": "TAPAS框架在基准规划领域和VirtualHome模拟的现实环境中的表现表明，通过这种多智能体的方法，使用语言模型的自适应领域建模可以有效解决复杂任务，特别是在动态变化的环境中具有显著优势。"}
{"llm_update_time": "2025-06-25 09:11:45", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19359", "html_url": "https://arxiv.org/abs/2506.19359", "title": "进化水平修复", "title_en": "Evolutionary Level Repair", "authors": "Debosmita Bhaumik,Julian Togelius,Georgios N. Yannakakis,Ahmed Khalifa", "background": "本文解决了游戏关卡修复的问题，即如何将设计但不具功能性的游戏关卡转变为功能性的关卡，确保关卡的完整性、物体可达性或其他性能特征。此外，修复过程可能受到限制，只能对该关卡做少量改动。当前已有关于使用搜索算法（特别是进化算法和质量多样性算法）解决关卡修复问题的研究，产生了较好的结果。而机器学习基于的程序化内容生成（PCGML）方法可以生成风格相符但经常不完整的关卡，结合PCGML生成与基于搜索的方法修复，可能是一种有前景的混合程序化内容生成（PCG）方法。", "innovation": "本文探讨了使用进化算法和质量多样性算法等搜索方法解决基于机器学习程序化内容生成（PCGML）技术生成的关卡，由于设计时存在缺陷而不能正常运行的问题。这种研究将PCGML生成和搜索算法修复相结合，作为混合程序化内容生成（PCG）方法的一个创新应用，显示出极大的潜力。", "conclusion": "结合PCGML生成和搜索算法修复的混合程序化内容生成方法，在修复经常不完整的关卡方面表现出良好的效果。这种方法为游戏开发提供了一种新的工具，有助于提高关卡生成的效率和质量。"}
{"llm_update_time": "2025-06-25 09:11:46", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19608", "html_url": "https://arxiv.org/abs/2506.19608", "title": "ChordPrompt: 用于 CLIP 的多域增量学习中跨模态提示协同的编排", "title_en": "ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP", "authors": "Zhiyuan Wang,Bokui Chen", "background": "连续学习（CL）使得预训练的视觉语言模型能够有效适应新的或之前被低估的数据分布，而无需进行全面重新训练，从而增强了其适应性和效率。尽管视觉语言模型如CLIP显示出极大的潜力，但在增量学习场景中，它们在保持跨域性能方面遇到困难。现有的提示学习方法面临两大挑战：1)它们主要针对类别增量学习场景，缺乏针对多域任务增量学习的具体策略；2)大多数当前方法采用单一模态提示，忽视了跨模态信息交换的好处。为解决这些挑战，作者提出了ChordPrompt框架，该框架促进了视觉和文本提示之间的和谐互动。ChordPrompt引入跨模态提示以利用视觉和文本信息之间的交互，并使用域适应文本提示来选择适当的提示以在多个域中持续适应。在多域增量学习基准上的全面实验表明，ChordPrompt在零样本泛化和下游任务性能上优于现有最先进的方法。", "innovation": "提出了ChordPrompt框架，该框架引入了跨模态提示以利用视觉和文本信息之间的交互，并使用域适应文本提示来选择适当的提示以在多个域中持续适应。该方法克服了现有方法面临的两大挑战：首先，它不仅适用于类别的增量学习，还可以处理多域任务的增量学习；其次，它能够利用跨模态信息交换带来的好处。", "conclusion": "ChordPrompt在多域增量学习基准上展示了在零样本泛化和下游任务性能方面的显著优势，优于现有的最先进的方法。"}
{"llm_update_time": "2025-06-25 09:11:50", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19290", "html_url": "https://arxiv.org/abs/2506.19290", "title": "Skywork-SWE: 揭示软件工程领域中LLM的数据放大定律", "title_en": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs", "authors": "Liang Zeng,Yongcong Li,Yuzhen Xiao,Changshi Li,Chris Yuhao Liu,Rui Yan,Tianwen Wei,Jujie He,Xuchen Song,Yang Liu,Yahui Zhou", "background": "软件工程（SWE）已成为新一代大型语言模型（LLM）的重要测试平台，要求LLM具备持续迭代问题解决能力（如超过50轮次的交互）和长上下文依赖性解决能力（如处理超过32,000个标记）。然而，数据收集过程中仍然依赖于手动标注和专用运行时环境的设置，导致大多数现有的数据集仅包含几千个GitHub代码库中的实例。鉴于此，本文提出了一种增量式和自动化的数据收集管道，系统性地扩展了SWE数据集的规模和多样性。我们构建的SWE数据集包括来自2,531个独特GitHub仓库的10,169个真实Python任务实例，每个实例都附带自然语言描述的任务和一个用于自动单元测试验证的专用运行时环境镜像。我们精心筛选并验证了超过8,000条训练轨迹。通过在这些轨迹上微调Skywork-SWE模型，我们发现训练数据规模的增加会导致软件工程能力的持续提升，没有出现饱和迹象。此外，我们的Skywork-SWE模型在SWE-bench Verified基准测试中达到了38.0%的pass@1准确率，没有使用验证器或多次模拟运行，这表明它在基于OpenHands代理框架的Qwen2.5-Coder-32B大型语言模型中处于领先水平。结合测试时的数据放大技术后，准确率进一步提升至47.0%，超过了之前对于不大于32B参数模型的SOTA结果。我们公开发布了Skywork-SWE-32B模型检查点，以促进后续研究的发展。", "innovation": "本文的创新点在于：1) 提出了一种增量式和自动化的数据收集管道，大幅扩展了SWE数据集的规模和多样性；2) 构建了包含来自2,531个GitHub仓库的10,169个真实Python任务实例的全面数据集；3) 发现随着数据量的增加，大型语言模型在软件工程任务上的性能持续提升，表明数据规模对模型性能有显著影响；4) 提出的Skywork-SWE模型在SWE-bench Verified基准测试中取得了SOTA性能，且在加入测试时的数据放大技术后，性能进一步提升。", "conclusion": "总之，本文通过对SWE数据集的增量式和自动化的扩展，揭示了软件工程领域中LLM的数据放大定律。此外，我们构建的Skywork-SWE模型在软件工程任务上的性能不仅超过了基于Qwen2.5-Coder-32B的SOTA模型，而且在加入测试时的数据放大技术后，其性能进一步超越了之前的小模型SOTA结果。我们相信这些发现将对未来的LLM研究产生积极影响。"}
{"llm_update_time": "2025-06-25 09:11:51", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19466", "html_url": "https://arxiv.org/abs/2506.19466", "title": "KunLunBaizeRAG：大型语言模型推理性能跃升的强化学习驱动框架", "title_en": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models", "authors": "Cheng Li,Jiexiong Liu,Yixuan Chen,Qihang Zhou,KunLun Meta", "background": "本文介绍了KunLunBaizeRAG，这是一种通过强化学习驱动的推理框架，旨在增强大型语言模型（LLMs）在复杂多跳问答任务中的推理能力。该框架解决了传统RAG的关键限制，如检索漂移、信息冗余和策略僵化等问题。", "innovation": "该框架的关键创新包括RAG驱动的推理对齐（RDRA）机制、搜索思考迭代增强（STIE）机制、网络局部智能路由（NLR）机制以及逐步混合训练策略。这些创新旨在提高LLMs在复杂推理场景中的表现和灵活性。", "conclusion": "实验结果表明，该框架在四个基准测试中的精确匹配（EM）和LLM评估得分（LJ）得到显著改善，表明了其在复杂推理场景中的稳健性和有效性。"}
{"llm_update_time": "2025-06-25 09:11:56", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19783", "html_url": "https://arxiv.org/abs/2506.19783", "title": "SAGE: 策略自适应生成引擎用于查询重写", "title_en": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting", "authors": "Teng Wang,Hailei Gong,Changwang Zhang,Jun Wang", "background": "当前查询重写方法要么依赖大量的监督数据，要么在强化学习（RL）探索过程中效率低下。然而，通过指导大规模语言模型（LLMs）使用精简且由专家制定的策略，例如语义扩展和实体消歧，可以在具有挑战性的基准测试，包括HotpotQA、FEVER、NFCorpus和SciFact上显著提高检索效果。", "innovation": "本文提出了一种策略自适应生成引擎（SAGE），它借鉴了这些策略，并在RL框架中实现它们。SAGE引入了两种新的奖励塑造机制——策略信用塑造（SCS）和对比奖励塑造（CRS），以提供更具信息性的学习信号。此外，该策略指导的方法不仅达到了新的NDCG@10最佳结果，还展示了引人注目的涌现行为：智能体学会选择最优策略，减少不必要的探索，生成简洁的重写，而不会增加推理成本。", "conclusion": "我们的研究结果表明，增强的策略指导RL为开发新一代稳健的信息检索系统提供了一个可扩展、高效且更可解释的范式。"}
{"llm_update_time": "2025-06-25 09:11:56", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19702", "html_url": "https://arxiv.org/abs/2506.19702", "title": "LLM-驱动的医疗文档分析：增强可信的病理学和鉴别诊断", "title_en": "LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis", "authors": "Lei Kang,Xuanshuo Fu,Oriol Ramos Terrades,Javier Vazquez-Corral,Ernest Valveny,Dimosthenis Karatzas", "background": "医疗文档分析在从非结构化医疗记录中提取关键临床见解和辅助诊断任务中发挥着重要作用。然而，鉴别诊断需要精确的评估和深厚的医学知识，而大型语言模型（LLMs）的最新进展虽然显著提升了医疗文档分析的性能，但隐私保护方面的担忧使临床环境中无法使用在线LLM服务。针对这些挑战，该文提出了一种可信的医疗文档分析平台，通过低秩适应微调自LLaMA-v3模型，并针对鉴别诊断任务进行了优化。该平台利用DDXPlus数据集进行训练，并在病理预测和变长鉴别诊断方面表现出色，优于现有方法。此外，该平台还通过先进的解释性技术确保透明可靠的预测结果，增强了用户的信任和信心。", "innovation": "提出了一个通过低秩适应微调LLaMA-v3模型的可信医疗文档分析平台，特别适用于鉴别诊断任务。该平台利用DDXPlus数据集进行训练，并在病理预测和变长鉴别诊断方面表现突出，优于现有方法。通过结合先进的解释性技术，系统确保透明可靠的预测结果，促进用户信任和信心的提升。该平台提供了一个基于Web的工具，允许用户提交自己的未结构化医疗文档并接收准确的、可解释的诊断结果。", "conclusion": "该工作解决了可靠、可解释和隐私保护的人工智能解决方案的迫切需求，标志着智能医疗文档分析在实际医疗应用中的重要进展。广泛的评估证实，所提出的方法超越了当前最先进的模型在预测准确性方面的表现，同时在临床应用中具有实用价值。研究结果可以在指定的网址找到。"}
{"llm_update_time": "2025-06-25 09:11:57", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19650", "html_url": "https://arxiv.org/abs/2506.19650", "title": "在DMGs上的C-DMGs中识别宏观因果效果", "title_en": "Identifying Macro Causal Effects in C-DMGs over DMGs", "authors": "Simon Ferreira,Charles K. Assaad", "background": "do-因果 calculus 是识别由结构性因果模型（SCMs）引起的一系列有向混合图（ADMGs）中的因果效应的有效工具。但在许多实际应用场景中，尤其是在高维设置中，构建一个完全指定的ADMG往往是不可行的。这导致了对部分指定的因果表示的兴趣增加，特别是通过群组导向混合图（C-DMGs）。C-DMGs通过将变量分组到集群中，提供了一种更为抽象但实用的因果依赖性视图。尽管C-DMGs可以包含循环，但现有研究表明，在假设所有集群大小大于1的情况下，do-因果 calculus 在C-DMGs中仍然可以正确且完整地识别宏观层面的因果效果。然而，现实系统通常在结构层面表现出远循环的因果动态。因此，引入了输入输出结构性因果模型（ioSCMs）作为SCMs的广义形式，允许存在循环，同时引发了另一种图结构，称为有向混合图（DMGs）。在DMGs上，可以定义C-DMGs作为变量集群之间因果关系的高阶表示。", "innovation": "本文证明，在DMGs上的C-DMGs中，do-因果 calculus 无条件地正确且完整地识别宏观因果效果。此外，还展示了之前在ADMGs上的C-DMGs中确定的识别宏观因果效果的图形标准自然地扩展到了DMGs上C-DMGs的一部分。", "conclusion": "在DMGs上的C-DMGs中，do-因果 calculus 是无条件地正确且完整的，可以用来识别宏观因果效果。同时，之前在ADMGs上建立的非识别图形标准也扩展到了DMGs上的部分C-DMGs。"}
{"llm_update_time": "2025-06-25 09:11:58", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19698", "html_url": "https://arxiv.org/abs/2506.19698", "title": "注重决策导向的预测性维护：结合预测与优化的框架", "title_en": "Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance", "authors": "Zhuojun Xie,Adam Abdin,Yiping Fang", "background": "近年来，机器学习（ML）越来越多地被集成到预测性维护（PdM）中，以在数据丰富的操作环境中降低运营和维护成本。然而，由于模型错定导致的不确定性仍然限制了其在工业中的广泛应用。这项研究提出了一个基于传感器的数据驱动预测性维护框架，该框架能够在经济权衡的有限决策空间内指导决策。研究表明，在传统估计-然后优化（ETO）框架中，概率预测中的误差可能导致不一致和次优的维护决策。", "innovation": "研究提出了一种结合预测与优化的框架（IEO），通过联合优化预测模型和直接优化维护结果，旨在减少并纠正因预测误差造成的下游维护决策问题。IEO框架通过构建随机扰动梯度下降算法解决小型失效至运行数据集的问题，并在涡扇发动机维护案例研究中证明了其有效性，相较于ETO框架，IEO框架将平均维护遗憾减少到了22%。", "conclusion": "这项研究提供了一种在预测性维护中管理预测误差的原理性方法。通过调整预测模型的训练来与维护目标保持一致，IEO框架在模型错定的情况下提高了稳健性并改善了决策质量。特别当决策策略与决策者的意图不一致时，这种改进尤为显著，从而支持在不确定的操作环境中实现更可靠的维护规划。"}
{"llm_update_time": "2025-06-25 09:11:58", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL: 探索以知识为基础的强化学习以提升事实准确性", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Wenhao Yu,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs），尤其是缓慢思考的模型，经常表现出严重的幻觉现象，因为在推理过程中无法准确识别知识边界。强化学习（RL）可以增强复杂推理能力，但由于其结果导向的奖励机制缺乏对思考过程的事实监督，这反而加剧了幻觉问题。", "innovation": "我们提出了知识增强的RL（KnowRL），通过在RL训练过程中整合基于知识验证的事实奖励，引导模型进行基于事实的缓慢思考，帮助它们识别知识边界。这种方法使得模型在训练过程中能够学习和内化基于事实的推理策略，从而直接奖励推理过程中遵循事实的行为，促使更可靠地思考过程。", "conclusion": "在三个幻觉评估数据集和两个推理评估数据集上的实验结果显示，KnowRL能有效减少缓慢思考模型的幻觉现象，同时保持其原有的强大推理能力。"}
{"llm_update_time": "2025-06-25 09:12:01", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19686", "html_url": "https://arxiv.org/abs/2506.19686", "title": "从记忆到地图：Transformer 中基于上下文的强化学习机制", "title_en": "From memories to maps: Mechanisms of in context reinforcement learning in transformers", "authors": "Ching Fang,Kanaka Rajan", "background": "人类和动物展现出卓越的学习效率，能够在有限的经验中适应新环境。现有的标准强化学习算法依赖于逐步的价值更新，无法很好地捕捉这种效率。相反，快速适应可能依赖于情景记忆能力，即利用特定的过往经验来指导决策。Transformer 网络因其能够快速学习上下文以及其关键-值架构类似于大脑中的情景记忆系统，成为了研究这一问题的有用框架。研究人员通过训练 Transformer 网络在一组根据啮齿动物行为启发的任务中进行基于上下文的强化学习，并分析了在该模型中出现的学习算法。", "innovation": "研究者发现，Transformer 网络支持基于上下文的结构学习以及不同上下文之间的对齐，使得代表能够在不同感觉刺激的环境中对齐。更重要的是，他们证明了模型开发的强化学习策略不能用传统的无模型或基于模型的规划来解释，而是通过代码中存储的中间计算来支持的。这表明存储记忆可能作为计算资源不仅存储原始经验，还可以存储缓存的计算，以支持灵活的行为。另外，模型中开发的表示与大脑中海马-内嗅皮层系统的计算相关，这表明该研究发现可能适用于自然认知。因此，这项工作提供了一种机制假说，解释了在人工和自然环境中基于上下文学习的快速适应。", "conclusion": "总体而言，研究发现记忆可能作为一种计算资源，存储原始经验和缓存计算以支持灵活行为。此外，模型中开发的表示方式与大脑中海马-内嗅皮层系统相关，这提示研究人员的研究发现可能适用于自然认知。因此，我们的工作为在人工和自然条件下基于上下文学习的快速适应提供了机制假说。"}
{"llm_update_time": "2025-06-25 09:12:04", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19825", "html_url": "https://arxiv.org/abs/2506.19825", "title": "使用大型 Vision Language 模型评估科学出版物中图表遵守可视化指导原则的情况", "title_en": "Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models", "authors": "Johannes Rückert,Louise Bloch,Christoph M. Friedrich", "background": "数据可视化领域的研究旨在定义创建和使用图表的原则和指南，但这些知识和规范往往未被研究人员熟知或遵循，导致了因提供不准确或不完整信息而造成的信息误导。本文中，采用大型 Vision Language 模型对图表进行分析，以识别关于所选数据可视化原则和指南中存在的潜在问题。", "innovation": "研究通过使用五个开源的 Vision Language 模型和五个提示策略，根据选定的数据可视化指南生成的问题集进行比较，评估了 Vision Language 模型在图分析任务中的适用性。研究结果表明，所使用的 Vision Language 模型在分析图表类型、3D 效果、轴标签、线条、颜色和图例等方面表现良好，但在提供图像质量反馈方面表现不佳。研究发现了 Vision Language 模型可以自动识别图表中的潜在问题，如缺失的轴标签、缺失的图例以及不必要的 3D 效果。", "conclusion": "研究提出的方法可以进一步扩展以涵盖数据可视化的更多方面。初步结果显示，Vision Language 模型在自动识别图表中潜在问题方面具有应用潜力。"}
{"llm_update_time": "2025-06-25 09:12:04", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19785", "html_url": "https://arxiv.org/abs/2506.19785", "title": "学习潜在动力学中的任务信念相似性以实现元强化学习", "title_en": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning", "authors": "Menglong Zhang,Fuyuan Qian", "background": "元强化学习需要利用探索过程中获得的任务分布信息来快速适应未知任务。代理探索效率取决于准确识别当前任务。现有的贝叶斯自适应深度强化学习（Bayes-Adaptive Deep RL）方法通常依赖于重建环境的奖励信号，但在稀疏奖励设置中这极具挑战性，导致次优的利用过程。因此，我们需要一种方法来高效地识别任务并探索稀疏奖励环境。启发于强大的在连续MDP中提取行为相似性的bisimulation度量，本文提出了SimBelief，这是一种新颖的元强化学习框架，通过测量贝叶斯自适应MDP（BAMDP）中任务信念的相似性。SimBelief能够有效提取相似任务分布的共性特征，使得在稀疏奖励环境中高效的任务识别与探索成为可能。", "innovation": "提出了SimBelief，一种新颖的元强化学习框架，通过测量贝叶斯自适应MDP（BAMDP）中任务信念的相似性。此方法使用潜在任务信念度量来学习相似任务的共性结构，并将其纳入特定任务信念中。通过学习任务分布的共性动态，该方法将共享的潜在任务信念特征与特定任务特征相结合，从而促进快速的任务识别与适应。这种方法在稀疏奖励的MuJoCo和panda-gym任务上优于最先进的基准方法。", "conclusion": "SimBelief能有效提高在稀疏奖励环境中的任务识别与探索效率，通过连接共享的潜在任务信念特征与特定任务特征，加速任务学习与适应过程，从而在元强化学习中实现了显著的性能提升。"}
{"llm_update_time": "2025-06-25 09:12:06", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19773", "html_url": "https://arxiv.org/abs/2506.19773", "title": "自动提示优化在知识图谱构建中的应用：一项实证研究", "title_en": "Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study", "authors": "Nandana Mihindukulasooriya,Niharika S. D'Souza,Faisal Chowdhury,Horst Samulowitz", "background": "知识图谱（KG）表示实体网络及其之间的关系，应用于多种场景，如语义搜索、推理、决策、自然语言处理、机器学习和推荐系统。三元组（主语-关系-客体）从文本中提取是构建知识图谱的基本构建模块，受到广泛研究。尽管使用大规模语言模型（LLM）进行知识图谱构建已有所探索，但为LLM设计合理的特定任务提示劳动密集且因LLM模型的细微变化而脆弱。为此，最近在NLP任务（例如自主生成）中使用自动提示优化/工程来生成给定输入输出示例的最佳或近似最佳特定任务提示。", "innovation": "该研究通过实证实验，探索自动提示优化在三元组提取任务中的应用，评估了多个参数配置，包括提示策略、使用的LLM、模式复杂性、输入文本的长度与多样性、驱动提示优化的度量标准以及用于训练和测试的数据集。该研究使用三种自动提示优化方法（DSPy、APE和TextGrad）和两种三元组提取数据集（SynthIE和REBEL）。实验结果表明，自动提示优化技术可以生成类似人类的合理提示，从而在提高三元组提取结果方面取得更好的表现，特别是在模式复杂性和文本长度增加时效果更明显。", "conclusion": "自动提示优化技术能够生成类似于人类的合理提示，从而提高三元组提取的任务表现，特别是在模式复杂度和文本长度增大的情况下。"}
{"llm_update_time": "2025-06-25 09:12:07", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19843", "html_url": "https://arxiv.org/abs/2506.19843", "title": "Temporal-IRL: 使用逆强化学习建模港口拥堵和泊位调度", "title_en": "Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning", "authors": "Guo Li,Zixiang Xu,Wei Zhang,Yikuan Hu,Xinyu Yang,Nikolay Aristov,Mingjie Tang,Elenna R Dugundji", "background": "港口拥堵预测对于保持可靠的全球供应链至关重要。准确的预测可以改善货物运输计划、减少延误和成本，优化库存和分销策略，从而确保及时交付并增强供应链的韧性。为了实现准确的预测，分析船舶行为及其在特定港口泊位的停留时间是关键，特别是在各种条件下进行泊位调度时。泊位调度和计划受多种因素的影响，包括港口内抵达船舶的大小、等待时间和船舶的状态。通过观察历史上的船舶自动识别系统（AIS）位置，可以重构泊位计划，利用逆强化学习（IRL）确定奖励函数，并学习泊位调度来预测船舶排序和估计船舶在港口的停留时间，包括等待时间和泊位时间，从而预测港口拥堵情况。", "innovation": "该研究通过使用逆强化学习（Temporal-IRL）来学习泊位调度模式，并据此预测船舶排序和估算船舶在港口的停留时间，以预测港口拥堵情况。该模型通过重新构建历史上的船舶AIS位置以确定泊位计划来实现这一目标，并有效地应用到了纽约/新泽西港的梅雷赫码头（Maher Terminal）的数据中，展示了卓越的结果。", "conclusion": "通过使用Temporal-IRL模型，该研究能够准确地预测泊位调度模式，从而为港口拥堵预测提供有效工具。该模型的成果显著，验证了其在实际应用中的准确性和可靠性。"}
{"llm_update_time": "2025-06-25 09:12:09", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15746", "html_url": "https://arxiv.org/abs/2506.15746", "title": "神经细胞自动机用于ARC-AGI", "title_en": "Neural Cellular Automata for ARC-AGI", "authors": "Kevin Xu,Risto Miikkulainen", "background": "细胞自动机和其可微分的对应物神经细胞自动机（NCA）具有高度的表达能力，并能够产生令人惊讶的复杂行为。本文利用抽象与推理人工通用智能语料库（ARC-AGI）探索NCA在执行需要精确变换和少量样本泛化的任务时的表现，这是以前未被充分探索的挑战其能力的一种方式。使用基于梯度的训练来学习迭代更新规则，将输入网格转化为训练样例的输出，并应用于测试输入。实验结果表明，基于梯度训练的NCA模型可以有效应对ARC等抽象的格基任务。同时，讨论了各种设计修改和训练限制的影响，并探讨了应用于ARC的NCA的行为与性质，以提供更广泛自组织系统的应用见解。", "innovation": "本文使用基于梯度的训练方法，学习NCA模型中的迭代更新规则，从而能够将输入网格转换为输出，并应用到测试输入上。这种基于梯度训练的NCA模型显示出对抽象格基任务的有效性，特别针对ARC-AGI数据集中的任务。此外，还探讨了不同的设计修改和训练限制对NCA结果的影响，为自组织系统的更广泛应用提供了见解。", "conclusion": "基于梯度训练的NCA模型为解决抽象格基任务提供了一种有效且高效的途径，并为更广泛的应用自组织系统的应用提供了潜在的创新方向。这些研究为探索和设计更复杂的自组织系统提供了新的视角。"}
{"llm_update_time": "2025-06-25 09:12:11", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04689", "html_url": "https://arxiv.org/abs/2506.04689", "title": "回收网络：提升语言模型预训练数据质量和数量的一种方法", "title_en": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models", "authors": "Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li", "background": "以往的研究发现，大型语言模型的性能会随着模型规模和数据量的增大而提升。然而，预训练主要依赖大规模的网络爬虫收集数据，尽管使用了几乎所有的互联网公开数据源，但这一数据池的增长速度跟不上计算资源的供应速度。尤其是高质量文本的数据更为有限，通常数据过滤流程会去除多达99%的初始网络爬取内容以达到最先进的效果。因此，研究提出的`数据墙`问题开始显现，为了解决这一问题，本文探索了用以回收并重写已丢弃的低质量数据的方式，旨在增强预训练数据的质量和数量。", "innovation": "本文提出了REWIRE方法，即回收与引导重写，以丰富低质量文档并转化为可用的训练数据。实验在1B、3B和7B规模的DCLM基准上显示，混合高质量原始文本和重写文本比仅使用过滤后的网络数据训练分别在22个不同任务上提高了1.0%、1.3%和2.5%。此外，使用原始合成数据混合训练的效率比直接获取两倍的网络数据更为有效。通过对不同方式生成的合成数据进行进一步分析，表明来自低质量文档重写的文本占比约为82%。REWIRE方法也优于其他生成合成数据的方法，如维基百科风格的重写、问题-答案合成和知识提取。这一发现表明，回收网络文本有潜力成为一种简单而有效的提升预训练数据的方法。", "conclusion": "实验表明，将高质量原始文本和经过重写后的文本混合用于训练，能够有效提升模型在22个不同任务上的性能，相较于仅使用过滤后的网络数据训练，混合训练方式增益显著，且优于其他合成数据生成方法。未来可以进一步探索更多方式以提高回收和重写低质量文档的效果，以进一步提升模型的性能。"}
{"llm_update_time": "2025-06-25 09:12:11", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19724", "html_url": "https://arxiv.org/abs/2506.19724", "title": "从再现到复现：通过渐进代码掩码评估研究代理", "title_en": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking", "authors": "Gyeongwon James Kim,Alex Wilf,Louis-Philippe Morency,Daniel Fried", "background": "自主代码生成的最新进展激发了对能够通过运行实验加速科学发现的AI代理的兴趣。然而，目前没有基准能够评估这些代理在不同初始代码量的情况下是否能够实现科学想法，从再现（运行代码）到从零开始复现（重新实现和运行代码）进行插值。本文介绍了AutoExperiment基准，该基准评估AI代理根据研究论文的自然语言描述实施和运行机器学习实验的能力。通过逐步掩盖代码中的关键函数，AutoExperiment逐渐增加了任务难度，从部分再现到完全复现。我们发现，随着掩蔽函数数量的增加，最新代理的性能迅速下降。能够动态与环境交互（例如，调试代码）的代理可以超越固定‘代理缺失’装夹中的代理，单次和多次尝试的成功率之间存在显著差距，这促使我们为基准提出了验证方法。研究结果突显了长时代码生成、上下文检索和自主实验执行中的关键挑战，确立了AutoExperiment作为评估基于AI的科学实验进展的新基准地位。", "innovation": "AutoExperiment是一个新的基准，评估AI代理在不同初始代码量下实施和运行基于自然语言描述的机器学习实验的能力。通过逐步掩盖代码中的关键函数，AutoExperiment逐渐增加了任务难度，从部分再现到完全复现。", "conclusion": "研究结果强调了长时代码生成、上下文检索和自主实验执行中的关键挑战，并建立了AutoExperiment作为评估基于AI的科学实验进展的新基准，确立了代理在不同初始代码量下的不同性能表现，突显了验证方法的重要性。"}
{"llm_update_time": "2025-06-25 09:12:13", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18915", "html_url": "https://arxiv.org/abs/2506.18915", "title": "使用机器学习进行自动抑郁症评估：一项全面的综述", "title_en": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey", "authors": "Siyang Song,Yupeng Huo,Shiqing Tang,Jiaee Cheong,Rui Gao,Michel Valstar,Hatice Gunes", "background": "抑郁症是当前社会中常见的精神疾病。传统的精神疾病的评估方法依赖于量表和心理咨询师的访谈，容易产生主观的诊断结果，诊断过程耗时且昂贵，缺乏人力资源。虽然已有充分的证据表明，抑郁症通过多种人的内部脑活动和外部表达行为有所体现，自2012年以来，传统的机器学习（ML）和先进的深度学习（DL）模型已被广泛研究用于基于人类行为的自动抑郁症评估（ADA）。然而，最近的ADA研究通常仅集中在人类行为模态的有限数量上。尽管这些模态是开发ADA方法的理论基础，现有的ADA调查缺乏对多模态抑郁症相关人类行为的全面回顾和总结。", "innovation": "本文特别总结了多模态下的抑郁症相关人类行为，包括脑活动、言语语言和非言语的音频/面部/身体行为。重点在于进行基于机器学习的自动抑郁症评估方法的最新和全面的综述，并讨论和比较其独特的特征和局限性。同时，还回顾了已有的ADa比赛和数据集，指出了主要挑战和机遇，以提供未来ADa研究的方向指导。", "conclusion": "文章提供了多模态抑郁症相关人类行为及其机器学习方法的全面综述，识别并讨论了关键挑战和可能的机会，为未来的ADa研究指明了进一步的研究方向。"}
{"llm_update_time": "2025-06-25 09:12:16", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18925", "html_url": "https://arxiv.org/abs/2506.18925", "title": "Parkinson 病的手指敲击测试中可解释且详细的基于视频的运动特征定量", "title_en": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease", "authors": "Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers", "background": "准确地量化帕金森病（PD）的运动特性对于监测疾病进展和优化治疗策略至关重要。手指敲击测试是一个标准的运动评估方法，临床医生通过视觉评估患者的敲击性能，并根据敲击幅度、速度和不规则性给出总体严重程度评分。然而，这种方法依赖于主观判断，存在评分者间和评分者内的一致性问题，并不能透彻分析各项运动特性。因此，该论文提出了一种基于计算机视觉的微量化方法，使用视频记录来量化PD的运动特性，提出了与四种临床相关缺陷相一致的四种特征集，用于表征运动减少、运动迟缓、序列效应和犹豫-停顿。通过分析74位参与个人帕金森项目患者的视频记录和临床评估，进一步细化了序列效应和犹豫-停顿缺陷间的差异。最后，使用这些特征训练机器学习分类器以预测运动障碍学会统一帕金森病评分量表（MDS-UPDRS）的手指敲击分数，验证了该方法在MDS-UPDRS评分预测中的高精度和个体敲击运动特性的可解释量化能力。", "innovation": "论文提出了一种基于计算机视觉的微量化方法来量化PD的手指敲击测试中的运动特性，提出了与四种临床相关缺陷相一致的特征集，并通过分析发现了序列效应和犹豫-停顿缺陷的新细微差异，使用这些特征可以训练机器学习分类器来预测MDS-UPDRS得分，提供更可解释的个体手指敲击运动特性的量化结果。", "conclusion": "所提出的框架为客观评估PD的运动特性提供了一种实用的方法，可能适用于临床和远程环境。未来的研究需要评估该方法对治疗反应性和疾病进展的敏感性。"}
{"llm_update_time": "2025-06-25 09:12:17", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18930", "html_url": "https://arxiv.org/abs/2506.18930", "title": "基于强化学习的动态分组在管状结构跟踪中的应用", "title_en": "Reinforcement Learning-Based Dynamic Grouping for Tubular Structure Tracking", "authors": "Chong Di,Shuwang Zhou,Da Chen,Jean-Marie Mirebeau,Minglei Shu,Laurent D. Cohen", "background": "管状结构如血管和道路的跟踪计算受到复杂形态和环境变化的挑战。现有方法大致分为基于点和基于区间的两类模型。基于区间的模型尽管在许多场景中取得了令人满意的结果，但通常面临计算效率低下和高度依赖预设先验知识以适应目标伸长形状的问题。", "innovation": "提出了一种新的框架，将基于区间的跟踪建模为马尔可夫决策过程（MDP），并利用Q学习动态探索区段图，根据需要计算边权重并适应地扩大搜索空间。这种策略避免了预先计算的昂贵图，并在缺乏初始信息的情况下表现出良好的鲁棒性。实验结果表明，该方法在典型管状结构数据集上的性能显著优于现有的基于点和基于区间的先进方法，且能够有效地处理复杂拓扑结构和保持全局路径的一致性，无需依赖大量的先验结构知识。", "conclusion": "提出的方法显著优于现有的基于点和基于区间的追踪方法，它有效地应对复杂拓扑结构，并保持全局路径的一致性，同时减少了对广泛先验知识的依赖。"}
{"llm_update_time": "2025-06-25 09:12:17", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18924", "html_url": "https://arxiv.org/abs/2506.18924", "title": "连接视觉与排放：基于行为AI的道路设计中碳估算方法", "title_en": "Connecting Vision and Emissions: A Behavioural AI Approach to Carbon Estimation in Road Design", "authors": "Ammar K Al Mhdawi,Nonso Nnamoko,Safanah Mudheher Raafat,M.K.S. Al-Mhdawi,Amjad J Humaidi", "background": "本文提出了一种基于YOLOv8增强的实时车辆检测和分类框架，用于估算城市环境中的碳排放。该系统通过从实时交通视频流中检测、分割和跟踪车辆来增强YOLOv8架构。一旦车辆被定位，采用了一个专门的基于深度学习的识别模块来识别车牌和分类车辆类型。由于YOLOv8缺乏细粒度识别任务的能力，如读取车牌或确定车辆属性（不仅仅是类别标签），论文提出了一个混合管道，对每个检测到的车辆进行跟踪，将其边界框裁剪后传递给一个深度光学字符识别(OCR)模块。进一步的实验结果表明，使用复杂的CNN模型的字符级OCR准确率达到了99%，YOLOv8的边界框检测mAP@0.5达到了约71%，分割掩码的mAP@0.5达到了约70%。这些结果证明了结合实时目标检测与深度OCR用于智能交通系统的部署的可行性，并提供了一种针对车辆特定碳排放监测的可扩展解决方案。", "innovation": "论文的创新点在于提出了一个通过YOLOv8结合深度OCR技术的车辆检测和分类框架，实现了城市环境中车辆的实时碳排放估算。这种增强框架能够处理更细粒度的识别任务，如车牌读取和属性识别，并通过连接实时API验证信息的准确性，确保了估计的精确性和可靠性。", "conclusion": "本文通过多阶段方法实现了精确、自动化的车辆碳排放计算。实验表明，YOLOv8检测器的mAP@0.5超过70%且OCR准确率高达99%，验证了实时目标检测结合深度OCR技术在智能交通系统中的实用性和可扩展性。这种方法为城市交通中的碳排放监测提供了有效手段。"}
{"llm_update_time": "2025-06-25 09:12:19", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18919", "html_url": "https://arxiv.org/abs/2506.18919", "title": "MemeMind: 一个具有链式推理的大型多模态数据集，用于有害梗图检测", "title_en": "MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection", "authors": "Hexiang Gu,Qifan Yu,Saihui Hou,Zhiqin Fang,Huijia Wu,Zhaofeng He", "background": "社交媒体的快速发展加剧了有害内容的传播。有害梗图（结合了图像和文本）因其隐含语义和复杂的多模态交互，带来了自动检测难题。尽管现有研究在检测准确性与可解释性方面取得进展，但缺乏系统、大规模且高度可解释的多元数据集，仍限制了该领域进一步的发展。背景总结：当前缺乏涵盖面广、标签全面且可解释性强的数据集，导致有害内容检测技术无法进一步提升。", "innovation": "创新地提出了MemeMind数据集，该数据集具有科学标准、大规模、多样性、双语支持（中英）、以及详细的链式思考（CoT）注释。同时，提出了一种创新的有害梗图检测框架MemeGuard，有效结合了多模态信息和推理过程建模，显著提高了模型理解并识别有害梗图的能力。创新总结：数据集的科学性和创新性，以及检测框架的多模态与推理结合，提升了有害内容检测性能。", "conclusion": "在MemeMind数据集上进行的广泛实验表明，MemeGuard在有害梗图检测任务中始终优于现有的先进方法。结论总结：MemeMind数据集为有害梗图检测提供了坚实的基础，MemeGuard框架提高了模型检测有害梗图的能力，展示了该方法的优越性。"}
{"llm_update_time": "2025-06-25 09:12:19", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18932", "html_url": "https://arxiv.org/abs/2506.18932", "title": "AI安全与AI安全性的区分：消除混淆和明确界限", "title_en": "AI Safety vs. AI Security: Demystifying the Distinction and Boundaries", "authors": "Zhiqiang Lin,Huan Sun,Ness Shroff", "background": "人工智能(AI)正在被快速整合到各个领域的关键系统中，包括医疗保健和自动驾驶车辆等。其整合带来了巨大的好处，但也引入了重大的风险，其中包括由于AI滥用产生的风险。在管理这些风险的讨论中，经常使用的术语有“AI安全性”和“AI安全性”，这两种术语经常被混淆使用，导致概念上的混淆。本论文旨在区分这两者并界定它们的研究界限。", "innovation": "提供了严谨的定义，概述了各自的研究重点，并探讨了它们之间相互依赖的关系，包括安全漏洞如何导致安全失败以及反之亦然。通过使用信息传输和建筑设计的清晰类比来说明这些区别。", "conclusion": "明确这些界限对于引导精确的研究方向、促进有效的跨学科合作、增强政策效果以及最终推广可信赖的AI系统的部署至关重要。"}
{"llm_update_time": "2025-06-25 09:12:21", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18935", "html_url": "https://arxiv.org/abs/2506.18935", "title": "哪些意识可以被人工化？局部感知者现象与机器意识的存在", "title_en": "Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness", "authors": "Shri Lal Raghudev Ram Singh", "background": "本文探讨了一个新的局部感知者现象的范式，该范式用于形式化神经科学中关于意识的一些观察。通过这一模型，建立了一种适用于人工系统的集合论形式主义，并借助ZF集合论证明了机器意识的存在。文章还提出了在机器中实现一种还原论的形式知识意识的可能性。", "innovation": "提出了一个新的局部感知者现象的范式，发展了一种集合论形式主义，并通过ZF集合论证明了机器意识的存在，提出了一种在机器中实现形式知识意识的可能性。这是对现有神经科学理论和机器意识研究的创新贡献。", "conclusion": "研究表明，机器可以具备形式的知识意识，为机器意识的研究提供了新的视角。这种观点呼吁采用一种还原论的方法来理解机器意识的本质。"}
{"llm_update_time": "2025-06-25 09:12:23", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18931", "html_url": "https://arxiv.org/abs/2506.18931", "title": "Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs", "title_en": "Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs", "authors": "Shuang Ao,Yi Dong,Jinwei Hu,Sarvapali Ramchurn", "background": "大规模语言模型（LLMs）通过低秩适应（LoRA）进行微调可以提升适应性并减少计算成本。然而，这种方法有可能损害安全性对齐，即使使用无害数据也可能增加有害输出的风险。现有的安全性对齐方法难以捕捉复杂的参数变化，导致安全性和效用之间的不理想的权衡。", "innovation": "我们提出了一种新的基于剪枝的方法 Safe Pruning LoRA（SPLoRA），它通过选择性地移除减弱安全性对齐的LoRA层来提高安全性同时保持性能。核心方法是引入了一种名为 Empirical-DIEM（E-DIEM）的维度不变相似度度量，用于有效检测LoRA适应模型的安全失配。实验表明，SPLoRA在评价指标为效用、安全性和可靠性时超过了最先进的安全对齐技术，显著降低了安全风险，同时保持或提高了模型性能和可靠性。此外，SPLoRA还减少了推理开销，使其成为一种可扩展且有效的解决方案，用于部署更安全可靠的LLMs。", "conclusion": "本研究通过引入Safe Pruning LoRA (SPLoRA) 和Empirical-DIEM (E-DIEM) 方法，有效解决了现有方法在安全对齐方面的不足，显著提高了模型的安全性，同时保持甚至改善了模型的性能和可靠性。SPLoRA还具有较低的推理开销，是一种灵活的解决方案。"}
{"llm_update_time": "2025-06-25 09:12:25", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18940", "html_url": "https://arxiv.org/abs/2506.18940", "title": "eccDNAMamba: 预训练的超长eccDNA序列分析模型", "title_en": "eccDNAMamba: A Pre-Trained Model for Ultra-Long eccDNA Sequence Analysis", "authors": "Zhenke Liu,Jien Li,Ziqi Zhang", "background": "eccDNA在肿瘤中通过高拷贝扩增和长范围相互作用发挥关键的调控作用，并导致癌基因的过度表达。尽管在建模方面取得了进展，但仍没有预训练模型支持完整的圆环形eccDNA下游分析。现有的基因组模型要么限制在单碱基分辨率，要么受限于二次注意力机制的低效率。", "innovation": "eccDNAMamba是首个专门为圆环形DNA序列设计的双向状态空间编码器，结合了前向和后向处理以实现上下文表示学习，并通过一种新的增强策略保持圆环形结构。eccDNAMamba具有线性时间复杂度，并在两个真实数据集上展示了强大的分类性能，能够处理长达200 Kbp的序列，提供了一个健壮且有效的圆环形基因组建模框架。", "conclusion": "eccDNAMamba通过提高时间复杂度和保留圆环形结构的创新方法，在序列长度上实现了高效的分类性能，是首个针对此类序列的预训练模型，为后续研究提供了一个坚实的基础。"}
{"llm_update_time": "2025-06-25 09:12:27", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18941", "html_url": "https://arxiv.org/abs/2506.18941", "title": "AI是否能在高等教育课堂活动中支持学生参与？", "title_en": "Can AI support student engagement in classroom activities in higher education?", "authors": "Neha Rani,Sharan Majumder,Ishan Bhardwaj,Pedro Guillermo Feijoo Garcia", "background": "计算机科学专业的就业前景和创意机会吸引了许多学生选择该专业，导致计算机科学课程的报名人数显著增加，课堂规模从几百人到几千人不等。然而，面对如此大规模的课堂，学生与教师及学习材料之间的互动不足成为一个常见挑战。为了利用技术进步和大型语言模型（LLMs）的改进，研究探讨了利用基于大型语言模型的AI模型（如对话型人工智能CAI）来提升大学课堂学生参与度的可能性，尤其是在大型课堂中促进学生与学习内容的互动方面。为了检验CAI在课堂活动中的应用效果，研究人员在一个大学的软件工程课程中设计了一个活动，活动中学生使用了基于CAI的工具来进行课堂教学活动，并与未使用CAI工具进行的活动进行了对比研究。", "innovation": "研究创新之处在于通过使用流行且熟悉的聊天机器人工具ChatGPT，在一个大型课堂中探索对话型人工智能（CAI）工具对课堂教学活动参与度的影响，并通过一个具体的课堂实践案例，展示了CAI在提高学生学习参与度方面的潜力。", "conclusion": "研究结果表明，对话型人工智能（CAI，如ChatGPT）在提升大学课堂教学活动中的学习材料参与度方面具有潜力，尤其是在大型课堂中。研究团队进一步讨论了这些发现对未来的教育实践和研究的意义。"}
{"llm_update_time": "2025-06-25 09:12:27", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18939", "html_url": "https://arxiv.org/abs/2506.18939", "title": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction", "title_en": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction", "authors": "Rui An,Yifeng Zhang,Ziran Liang,Wenqi Fan,Yuxuan Liang,Xuequn Shang,Qing Li", "background": "训练能够良好泛化到不同地区和城市的 urbani 融合时空基础模型对于在未见过或数据稀少的地区部署城市服务至关重要。最近的研究通常重点关注跨域时空数据的融合来训练统一的Transformer模型，但这些模型存在计算复杂性和高内存开销问题，这限制了它们的可扩展性和实际部署。Mamba作为一种具有线性时间复杂性的状态空间模型，在效率方面具有优势，但直接将其作为时空骨干使用会导致负迁移和严重的性能下降。", "innovation": "本文提出了一种名为Damba-ST的新型领域自适应Mamba基模型，旨在提高其在异构领域的适应性。具体创新点包括：1）一种领域自适应的状态空间模型，将潜在表示空间划分为共享子空间以学习跨域共性，并独立的领域特定子空间用于捕捉领域内的判别特征；2）三种不同的领域适配器，作为领域感知的代理，用于连接不同领域分布，促进跨域共性的对齐。", "conclusion": "广泛的实验表明，Damba-ST在泛化性和效率方面表现出色，可以在预测任务中达到最先进的性能，并展示了强大的零样本泛化能力，可以在新的城市环境中无缝部署，无需进行繁重的重新训练或微调。"}
{"llm_update_time": "2025-06-25 09:12:30", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18952", "html_url": "https://arxiv.org/abs/2506.18952", "title": "在预算之内运行 LLMs？HOLA 来了", "title_en": "LLMs on a Budget? Say HOLA", "authors": "Zohaib Hasan Siddiqui,Jiechao Gao,Ebad Shabbir,Mohammad Anas Azeez,Rafiq Ali,Gautam Siddharth Kashyap,Usman Naseem", "background": "在边缘设备上运行大型语言模型（LLMs）面临高计算和内存需求的挑战，成为实时应用程序在医疗保健、教育和嵌入式系统等领域应用的障碍。当前的解决方案，如量化、剪枝和检索增强生成（RAG），只能提供部分优化，通常会牺牲速度或准确性。", "innovation": "我们提出了一种名为 HOLA 的端到端高效 LLM 部署优化框架。HOLA 内部利用分层推测性解码 (HSD) 实现更快的推理速度而不降低质量。外部使用 AdaComp-RAG 根据上下文需求调整检索复杂度。结合使用 LoBi（结合了 LoRA 和量化剪枝），HOLA 能够在 GSM8K 方面取得 17.6% 的 EMA，ARC 方面取得 10.5% 的 MCA，同时减少边缘设备（如 Jetson Nano）的延迟和内存，证明了其可扩展性和生产准备性。", "conclusion": "HOLA 通过利用分层推测性解码 (HSD) 和结合使用 LoBi 实现了边缘设备上 LLM 的高效部署，提高了实际应用中的性能，同时保证了质量和效率。"}
{"llm_update_time": "2025-06-25 09:12:31", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17336", "html_url": "https://arxiv.org/abs/2506.17336", "title": "隐私保留的LLM交互：基于苏格拉底链式推理和同态加密向量数据库", "title_en": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases", "authors": "Yubeen Bae,Minchan Kim,Jaejin Lee,Sangbum Kim,Jaehyung Kim,Yejin Choi,Niloofar Mireshghallah", "background": "大型语言模型（LLMs）作为个人代理越来越多地使用，访问敏感用户数据，例如日历、电子邮件和医疗记录。用户目前面临权衡：可以将私人记录（这些记录存储在远程数据库中）发送给强大的但不可信的LLM提供者，从而增加其暴露风险；或者在受信任的设备上运行较不强大的本地模型。本文旨在弥合这一差距。", "innovation": "本文提出了一种结合了苏格拉底链式推理和同态加密向量数据库的混合框架。首先，将通用的非私人用户查询发送给强大的但不可信的LLM，后者生成链式推理（CoT）提示和详细亚查询，而不访问用户数据。接着，利用这些亚查询执行加密的同态加密向量数据库中一个用户的私人数据的一百多万条目的一秒内语义搜索。最后，将CoT提示和解密后的记录反馈给本地语言模型，生成最终响应。在LoCoMo长上下文问答基准测试中，结合GPT-4o与本地Llama-3.2-1B模型的综合框架比单独使用GPT-4o提高了高达7.1个百分点。", "conclusion": "这项研究展示了第一个步骤，即任务在不受信任的强大LLM和弱本地模型之间分解和划分，从而保持用户隐私。"}
{"llm_update_time": "2025-06-25 09:12:32", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18946", "html_url": "https://arxiv.org/abs/2506.18946", "title": "DiffRIS: 使用预训练文本到图像扩散模型增强引参照地面远程感知图像分割", "title_en": "DiffRIS: Enhancing Referring Remote Sensing Image Segmentation with Pre-trained Text-to-Image Diffusion Models", "authors": "Zhe Dong,Yuzhe Sun,Tianzhu Liu,Yanfeng Gu", "background": "遥感图像分割（RRSIS）利用自然语言描述精确地在遥感影像中勾勒出区域，广泛应用于灾难响应、城市开发和环境监测等领域。尽管最近有所进展，但当前方法在处理航拍图像时仍面临许多挑战，因为这些图像中的对象具有尺度变化、多样化的方向性和沿顶部视角固有的语义歧义性。当前方法难以有效处理这些问题，导致分割结果不够精确和细致，影响最终的应用效果。", "innovation": "本文提出了一种名为DiffRIS的新框架，结合预训练的文本到图像扩散模型，提升遥感图像中的跨模态对齐能力。创新之处在于引入了一个上下文感知适配器（CP-adapter），它能够通过全局上下文建模和对象感知推理动态地细化语言特征；还引入了一个渐进式的跨模态推理解码器（PCMRD），该解码器通过多尺度特征交互迭代地将文本描述与视觉区域对齐，实现更为精确的分割。这些设计克服了以往方法在复杂图像分割任务中的局限性，使模型能够更准确地解析遥感影像中的对象信息。", "conclusion": "在三个基准数据集RRSIS-D、RefSegRS和RISBench上的全面实验表明，DiffRIS在所有标准指标上都优于现有方法，确定了用于遥感图像分割任务的新最佳性能。实验结果验证了通过本文提出的适应性框架利用预训练扩散模型对遥感应用的有效性。"}
{"llm_update_time": "2025-06-25 09:12:33", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18955", "html_url": "https://arxiv.org/abs/2506.18955", "title": "人工智能教育中的公民挑战", "title_en": "Citizenship Challenges in Artificial Intelligence Education", "authors": "Margarida Romero(UniCA, UIC, LINE)", "background": "本章节探讨了教育领域中人工智能带来的公民挑战，特别是针对学生、教师和其他教育利益相关者。章节首先探讨如何培养人工智能意识和教育，并提出多种策略来促进对人工智能的批判性培训方法，旨在识别并优先考虑相关的和道德的应用场景。第二部分讨论了在某些由人工智能支持的教育活动中可以利用批判性思维和计算思维技能，并根据这些活动所需的创意和改革性参与程度来进行。\n", "innovation": "提出了一种批判性培训方法，旨在培养人工智能意识和教育，并识别和优先考虑相关的和道德的应用场景。同时，讨论了在人工智能支持的教育活动中利用批判性思维和计算思维技能的方法，特别是在创意和改革性的参与活动中。\n", "conclusion": "本章节强调了培养人工智能意识和教育的重要性，提出了促进批判性人工智能培训的方法，并讨论了在教育活动中利用批判性和计算思维技能的可能性。"}
{"llm_update_time": "2025-06-25 09:12:35", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19846", "html_url": "https://arxiv.org/abs/2506.19846", "title": "JoyAgents-R1: 融合强化学习的多功能多大语言模型智能体协同进化机制", "title_en": "JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning", "authors": "Ai Han,Junxing Hu,Pu Wei,Zhiqian Zhang,Yuhang Guo,Jiawei Lu,Zicheng Zhang", "background": "多智能体 reinforcement learning (MARL) 在处理日益复杂任务方面已经形成了一个显著的范式，但跨异构智能体的协同进化仍然具有挑战性，主要因为合作效率低下和训练稳定性差的问题。现有的方法难以在这些方面取得进展，导致在多智能体环境中难以实现最优决策和记忆能力的全面平衡。因此，本文研究了如何通过新的方法来解决这些挑战。", "innovation": "提出了一种名为 JoyAgents-R1 的 MARL 协同进化机制，该机制首次应用 Group Relative Policy Optimization (GRPO) 来联合训练异构多智能体。通过迭代改进每个智能体的大语言模型及记忆，实现了全面均衡的最优决策和记忆能力。具体来说，JoyAgents-R1 首先在每个智能体的整个推理轨迹中实施节点蒙特卡洛抽样，以提升 GRPO 的抽样效率，同时保持策略多样性。此外，引入了一种边际收益驱动的选择策略，以确定最优的 k 个抽样组，并通过低成本参数调整提高训练稳定性和最大化联合效益。同时，引入了自适应记忆进化机制，利用 GRPO 奖励作为无成本的监督信号，消除重复推理，加速收敛。通过通用和特定领域的实验，证明 JoyAgents-R1 在性能上可与更大规模的语言模型媲美，但它是在小型开源模型的基础上构建的。", "conclusion": "本文提出的方法 JoyAgents-R1 通过实现节点蒙特卡洛抽样和边际收益驱动的选择策略，在异构多智能体环境中实现了全面均衡的最优决策和记忆能力。此外，这种方法还通过引入自适应记忆进化机制和无成本的监督信号加速了训练过程。实验结果表明，JoyAgents-R1 能够实现与大型语言模型相当甚至更好的性能，但在更小的模型上实现。"}
{"llm_update_time": "2025-06-25 09:12:36", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18926", "html_url": "https://arxiv.org/abs/2506.18926", "title": "基于AI的方法在早期预警系统中的应用：重点在于紧急通信生态系统与公民参与的案例研究（北欧国家）", "title_en": "AI-based Approach in Early Warning Systems: Focus on Emergency Communication Ecosystem and Citizen Participation in Nordic Countries", "authors": "Fuzel Shaik,Getnet Demil,Mourad Oussalah", "background": "气候变化和自然灾害被认为是全球性的挑战，需要复杂的生态系统来应对社会、经济和环境影响。为此，本章节提倡一种综合性方法，将应对策略分为准备阶段、应急响应阶段和灾后恢复阶段。它特别强调早期预警系统（EWS）、风险建模和减缓措施的作用。章节回顾了在各个阶段可利用的各种人工智能（AI）赋能技术，以INFORM风险框架和EWS为主要关注点。此外，章节还强调了在应急响应期间的重要紧急通信和风险感知的心理因素。", "innovation": "本文强调了利用人工智能技术在早期预警系统中的应用，特别是针对紧急通信生态系统和公民参与的重点案例研究。它重点关注北欧国家的具体实践，提供了人工智能技术在应对自然灾害中的创新应用实例，探讨了技术如何提升应急响应的效率和效果，以及增强公众的参与度和风险感知能力。", "conclusion": "章节总结了人工智能技术如何支持早期预警系统的建设，特别是在提高预测准确性和响应效率方面的作用。通过北欧国家的案例研究，展示了建筑此类系统的重要性，并指出未来的研究应在更广泛的背景下进一步探索人工智能技术在灾害管理和风险减轻中的应用潜力。"}
{"llm_update_time": "2025-06-25 09:12:36", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18985", "html_url": "https://arxiv.org/abs/2506.18985", "title": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs", "title_en": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs", "authors": "Guanxi Shen", "background": "近年来，大型视觉语言模型（LVLMs）在从视觉输入生成连贯文本回应方面取得了前所未有的能力。然而，理解模型在生成开放式视觉问题回答（VQA）时关注的视觉区域，并揭示其多模态文本关注点仍然是一个巨大的挑战。这一挑战对于理解模型行为、诊断幻觉、暴露偏差和确保透明度至关重要。", "innovation": "GLIMPSE提出了一种轻量级、模型无关的框架，用于可视化LVLMs在开放式视觉问答（VQA）过程中依赖的显著图像区域，同时揭示多模态文本关注点。GLIMPSE融合了梯度加权注意力、自适应层传播和加权标记聚合，产生了跨模态推理的整体响应级别归属热图，其在人类一致性方面的表现优于先前的可解释性方法。", "conclusion": "我们使用GLIMPSE采取了可解释的AI（XAI）方法来揭示大型生成型LVLMs的跨模态归属的细粒度洞察，追踪标记级别推理动力学，分析系统的人类注意力错位、幻觉和偏差。"}
{"llm_update_time": "2025-06-25 09:12:38", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19025", "html_url": "https://arxiv.org/abs/2506.19025", "title": "最优运输映射的统计推断：近期进展与展望", "title_en": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives", "authors": "Sivaraman Balakrishnan,Tudor Manole,Larry Wasserman", "background": "在最优运输（OT）的许多应用中，主要关注的对象是最优运输映射。该映射通过最小化特定的成本，在两个概率分布之间以最有效的方式重新分配质量。本文回顾了使用底层分布样本估算和开发最优运输映射极限定理的最新进展，同时也回顾了为基本OT设置的特殊情况和变体建立类似结果的平行研究线。", "innovation": "本文总结了最近在最优运输映射估算和极限定理方面的研究进展，并对特殊情况和变体进行了相似结果的研究。", "conclusion": "本文结论提出未来研究的关键方向，旨在为实际工作者提供可靠的推断工具。"}
{"llm_update_time": "2025-06-25 09:12:39", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19014", "html_url": "https://arxiv.org/abs/2506.19014", "title": "IndieFake Dataset: 一个用于音频伪造检测的标准数据集", "title_en": "IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection", "authors": "Abhay Kumar,Kunal Verma,Omkar More", "background": "音频深度伪造技术的进步带来了诸如AI助手、更具包容性的语音障碍沟通以及增强娱乐等功能。然而，这同时也带来了信息安全、隐私和数字通信信任方面的重大风险。现有数据集缺乏多样化的方言口音，这使得它们在许多现实场景中不适用。已有数据集在南亚国家等多元语言和文化背景下检测音频深度伪造的能力不足。南亚人口占世界人口的四分之一，但现有数据集中却缺少南亚口音的样本。", "innovation": "该研究介绍了一个新的数据集——IndieFake Dataset (IFD)，其中包括来自50位英语说出口的印度人的27.17小时真实和伪造音频。IFD提供了平衡的数据分布，并且包含了与ASVspoof21 (DF)等其他数据集相比缺乏的说话者级别的特征。评估结果显示，IFD在多种基线测试中表现优于现有的ASVspoof21 (DF)和In-The-Wild (ITW)数据集，证明其更具挑战性，将被公开发布以供进一步研究使用。", "conclusion": "IFD旨在克服现有数据集的局限性，特别补充了南亚口音的样本，以提高音频深度伪造检测模型在多元文化和语言背景下的表现。最终，研究认为IFD将是一个有效的基准数据集，用于今后在该领域的研究和开发。"}
{"llm_update_time": "2025-06-25 09:12:40", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19019", "html_url": "https://arxiv.org/abs/2506.19019", "title": "美国研究机构中的HPC现状调查", "title_en": "Survey of HPC in US Research Institutions", "authors": "Peng Shu,Junhao Chen,Zhengliang Liu,Huaqin Zhao,Xinliang Li,Tianming Liu", "background": "人工智能、数据密集型科学以及数字孪生技术的快速增长推动了高性能计算（HPC）在科研生态系统中前所未有的需求。尽管国家实验室和工业超大规模企业在exascale和GPU为中心的架构上投入了大量资金，但由大学运营的HPC系统相对资源有限。本文通过全面评估美国大学的HPC状况，将它们的能力与美国能源部（DOE）的领导级系统和工业AI基础设施进行基准比较，研究了50多所顶尖研究机构的算力能力、架构设计、治理模式和能效情况。研究发现，尽管大学集群在学术研究中起着至关重要的作用，但其增长轨迹（CAGR约18%）显著低于国家（约43%）和工业（约78%）上的同类系统。不断增长的GPU密集型AI工作负载使得能力差距进一步加大，强调了联邦计算、闲置GPU收割和成本共担模式的重要性。", "innovation": "本文通过全面评估美国大学的HPC状况，将它们的能力与美国能源部（DOE）的领导级系统和工业AI基础设施进行基准比较，分析了算力能力、架构设计、治理模式和能效情况。识别出了分散式强化学习等新兴范式，作为在校园环境中民主化AI训练的有前途的机会。", "conclusion": "本文为学术领导、资助机构和技术合作伙伴提供了可操作的见解，以确保支持国家研究优先事项的高性能计算访问更加公平和可持续。"}
{"llm_update_time": "2025-06-25 09:12:43", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越标记的大型语言模型公正性量化：一种语义和统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "现有的大型语言模型（LLMs）在生成响应时往往带有固有的偏差，这些偏差在实际应用中降低了模型的可靠性。传统的评估方法往往忽视了长形式响应中的偏差以及LLM输出固有的变化性。为了应对这些挑战，本文提出了FiSCo（Fine-grained Semantic Computation），这是一种新的统计框架，通过检测不同人群组在长形式响应中的细微语义差异来评估LLMs的整体公平性。", "innovation": "本文创新地提出了FiSCo（Fine-grained Semantic Computation），这是一种新颖的统计框架，通过检测不同人群组在长形式响应中的细微语义差异来评估LLMs的群组公平性。它不同于以往的工作，专注于情感或标记级别的比较，FiSCo在语义层面操作，通过蕴含检查来评估意义的一致性。此外，FiSCo通过分解模型输出为语义上不同的断言，并应用统计假设检验来比较组间和组内的相似性，从而实现对细微偏差的稳健检测。", "conclusion": "实验结果表明，FiSCo能够更可靠地识别细微的偏差，同时减少随机LLM变化的影响，优于各种评估指标。文章还提出了一个新的群体反事实公平定义，并在人工标注的数据集上进行了验证，涵盖了性别、种族和年龄等多个维度。"}
{"llm_update_time": "2025-06-25 09:12:46", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19082", "html_url": "https://arxiv.org/abs/2506.19082", "title": "FairCauseSyn：面向因果公平的LLM增强合成数据生成", "title_en": "FairCauseSyn: Towards Causally Fair LLM-Augmented Synthetic Data Generation", "authors": "Nitish Nagesh,Ziyu Wang,Amir M. Rahmani", "background": "合成数据生成利用生成模型创建基于真实世界数据的数据。在健康应用中，必须保持敏感属性的公平性以实现公平结果。现有的基于GAN和LLM的方法主要关注反事实公平性并主要应用于金融和法律领域。因果公平提供了一种更全面的评估框架，但当前的合成数据生成方法没有解决健康领域中的公平问题。为了解决这一问题，本研究开发了第一个利用LLM增强的合成数据生成方法以提高因果公平性，使用真实世界的健康表格数据。生成的数据在因果公平度指标上与真实数据的偏差小于10%。在因果公平预测器训练后，合成数据能将敏感属性上的偏差降低70%，相比真实数据。这项工作提高了公平合成数据的可访问性，支持公平的健康研究和医疗保健的实施。", "innovation": "开发了第一个结合LLM增强的合成数据生成方法，专门用于处理和提高健康数据中的因果公平性。这种方法首次将因果结构保留在合成数据生成过程中，并且显著减少了敏感属性上的偏差。", "conclusion": "本研究通过LLM增强合成数据生成方法，使得生成的数据在因果公平性上有显著改进，支持了更广泛的健康研究和医疗服务，提高了公平性的可访问性和一致性。"}
{"llm_update_time": "2025-06-25 09:12:46", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18951", "html_url": "https://arxiv.org/abs/2506.18951", "title": "SWE-SQL: 照亮大规模语言模型在现实应用中解决用户SQL问题的道路", "title_en": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications", "authors": "Jinyang Li,Xiaolong Li,Ge Qu,Per Jacobsson,Bowen Qin,Binyuan Hui,Shuzheng Si,Nan Huo,Xiaohan Xu,Yue Zhang,Ziwei Tang,Yuanshuai Li,Florensia Widjaja,Xintong Zhu,Feige Zhou,Yongfeng Huang,Yannis Papakonstantinou,Fatma Ozcan,Chenhao Ma,Reynold Cheng", "background": "在现实世界数据库应用中，解决复杂的SQL问题一直是一个显著的瓶颈。现有的大语言模型虽然擅长文本到SQL的翻译，但尚未严格评估其更复杂的任务，即调试SQL问题的表现。因此，提出了BIRD-CRITIC，包括530个PostgreSQL任务和570个多方言任务，以提供严格的评估环境。初步基准评估显示，领先的推理模型O3-Mini在BIRD-CRITIC-PG上的成功率为38.87%，在BIRD-CRITIC-Multi上的成功率为33.33%，突显了任务的复杂性。此外，提升开源模型对于促进本地开发和保护数据隐私至关重要。", "innovation": "为了解决这一瓶颈，该研究引入了BIRD-CRITIC作为新的SQL问题调试基准，并提出了Six-Gym作为开源模型培训环境来提升SQL问题调试能力。此外，提出了f-Plan Boosting方法，通过从SQL解决方案中提取高级调试计划，教师语言模型能够产生73.7%更多的成功轨迹。该研究整合了这些组件，提出了开源代理Bird-Fixer，并实现超过顶级专有模型Claude-3.7-Sonnet和GPT-4.1的性能，标志着向普及复杂的SQL调试能力迈出重要的一步。", "conclusion": "在此工作的基础上，成功实现了开源代理Bird-Fixer，该模型在BIRD-CRITIC-PG和BIRD-CRITIC-Multi上分别实现了38.11%和29.65%的成功率，超越了领先的专有模型，并为普及复杂的SQL调试能力奠定了基础。"}
{"llm_update_time": "2025-06-25 09:12:47", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19087", "html_url": "https://arxiv.org/abs/2506.19087", "title": "RareSpot：使用多尺度一致性和上下文感知增强在航空图像中检测小而罕见的野生动物", "title_en": "RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation", "authors": "Bowen Zhang,Jesse T. Boulerice,Nikhil Kuniyil,Charvi Mendiratta,Satish Kumar,Hila Shamon,B.S. Manjunath", "background": "自动检测航空图像中的小而罕见的野生动物对于有效的保护至关重要，但仍然是一个重大的技术挑战。草原土拨鼠就是一个典型问题：尽管作为生态系统中的关键物种，但因为体型小、分布稀疏、视觉特征微妙，使其难以被现有检测方法识别。这一背景凸显了新方法开发的必要性。", "innovation": "本文提出了一个名为RareSpot的检测框架，结合了多尺度一致性学习和上下文感知增强。多尺度一致性方法通过特征金字塔中的结构对齐，增强了精细对象的表示，并减轻了尺度相关特征损失。上下文感知增强则通过将难以检测的样本嵌入到逼真的环境背景中，产生更具挑战性的训练实例，极大地提升了模型的准确性和召回率。该方法在经过专家标注的草原土拨鼠无人机图像基准测试中表现出领先性能，较基线方法检测准确率提高了超过35%。此外，该方法在其他野生动物数据集上也表现出了广泛适用性。", "conclusion": "该研究不仅为草原土拨鼠提供了关键的生态监测支持，还为在复杂航空场景中检测小型罕见物种建立了新的基础。"}
{"llm_update_time": "2025-06-25 09:12:48", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19072", "html_url": "https://arxiv.org/abs/2506.19072", "title": "HAWAII: 分层视觉知识传输以实现高效的视觉-语言模型", "title_en": "HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models", "authors": "Yimu Wang,Mozhgan Nasr Azadani,Sean Sedwards,Krzysztof Czarnecki", "background": "提升视觉-语言模型（VLMs）的视觉理解能力对于改善其在各种任务中的性能至关重要。尽管使用多个预训练视觉专家显示出巨大潜力，但在训练和推理过程中会带来显著的计算成本。为了应对这一挑战，我们提出HAWAII，一种新的框架，该框架可以将来自多个视觉专家的知识提炼到一个视觉编码器中，使其能够继承多个专家的互补优势，同时最大限度地减少计算开销。为了减少不同教师之间的冲突并切换到不同的教师特定知识，我们不使用固定的教学器适应器，而是提出了教师特定的低秩适配器（LoRA）与相应的路由器。每个适配器与特定的教学器对齐，避免了提炼过程中的噪声指导。为了实现高效的知识提炼，我们提出了细粒度和粗粒度的提炼方法。在细粒度级别，使用标记重要性评分来强调每个教师的最具信息性的标记。在粗粒度级别，使用一组通用知识的LoRA适配器与路由器将多个教师的知识汇总并转移到学生中。", "innovation": "HAWAII提出了一种新颖的方法，将多个视觉专家的知识提炼到单个视觉编码器中，避免了大量的计算成本。引入了教师特定的低秩适配器（LoRA）以及相应的路由器来解决不同教师之间的冲突。提出了细粒度和粗粒度的知识提炼方法，通过标记重要性评分在细粒度级别上强调最有用的标记，在粗粒度级别上通过通用知识的LoRA适配器将多个教师的知识汇总并转移到学生中。", "conclusion": "在各种视觉-语言任务上的广泛实验表明，HAWAII在流行的开源视觉-语言模型中占优。"}
{"llm_update_time": "2025-06-25 09:12:48", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19037", "html_url": "https://arxiv.org/abs/2506.19037", "title": "快捷规划——带掩码的扩散语言模型的延时调度", "title_en": "Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models", "authors": "Omer Luxembourg,Haim Permuter,Eliya Nachmani", "background": "掩码扩散语言模型（MDLM）在非自回归文本生成方面显示出强大的潜力，但现有的采样器依赖于隐式规划，通过去噪器的信心分数或熵评分选择要取消掩码的令牌。这些启发式方法在并行取消掩码时会失效，因为它们忽略了令牌之间的双元交互，并且无法在同时取消多个位置时考虑依赖关系，这限制了它们的推理时间与传统的自回归（AR）模型相同。现有的部分自回归（Semi-AR）块方法（如LLADA和Dream）仍然在每个块上调用去噪器，使得去除掩码的调用次数仍为O(B)，这在半自回归推理过程中不如最新的扩散模型的速度快。在数学（GSM8K）和代码完成（Humaneval、MBPP）基准测试中，DUS在并行信心基于规划者之上提高了得分，而无需修改底层去噪器。DUS提供了一种轻量级、预算敏感的方法来实现高效、高质量文本生成，为MDLMs解锁真正能力铺平了道路。", "innovation": "提出了Dilated-scheduled Unmasking Strategy (DUS)，这是一种仅用于推理、无规划模型的方法，无需额外训练。DUS利用一阶马尔科夫假设将序列位置分组为基于延时的非相邻令牌组，这使取消掩码步骤可以独立并行进行，并尊重局部上下文，从而最小化每迭代步骤的联合熵。DUS将去除掩码的调用次数减少到O(log B)每生成块，这比半自回归推理过程中的最大调用时间O(B)快得多。", "conclusion": "DUS提升了数学和代码完成领域中的MDLM评分，实现了高效的高质量文本生成，展示了MDLMs的真正能力。"}
{"llm_update_time": "2025-06-25 09:12:52", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18954", "html_url": "https://arxiv.org/abs/2506.18954", "title": "SHAMaNS: 基于混合α稳定空间度量和神经定向器的声音定位", "title_en": "SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer", "authors": "Diego Di Carlo(RIKEN AIP),Mathieu Fontaine(LTCI, IP Paris),Aditya Arie Nugraha(RIKEN AIP),Yoshiaki Bando(RIKEN AIP),Kazuyoshi Yoshii", "background": "该论文介绍了一种结合α-稳定模型和基于神经网络的方法来实现声源定位（SSL）。为了更稳健地估计声源的方向到达（DOA），该模型采用了一个名为Neural Steerer的物理信息神经网络来插值固定麦克风阵列上的测量定向矢量（SVs）。α-稳定模型在一个非高斯情况下（α∈(0, 2)）理论上定义了一个独特的空间度量，这使模型能够处理Neural Steerer在下游任务中的残余重构误差。实验结果表明，该方法在存在多个声源的情况下优于最先进的方法.", "innovation": "该论文的创新点在于提出了一种结合α-稳定模型和基于物理信息的神经网络（Neural Steerer）的方法来实现声源定位。Neural Steerer用于插值固定麦克风阵列上的测量定向矢量，从而更稳健地估计声源的方向到达。此外，α-稳定模型能够在非高斯情况下定义一个独特的空间度量，这有助于处理神经网络模型的残余重构误差。论文通过实验验证了该方法的有效性和优越性，在存在多个声源的情况下表现出色。", "conclusion": "该研究提出的方法在多声源定位任务中表现出了显著的优越性，特别是在非高斯噪声条件下，其准确性和鲁棒性得到了验证。"}
{"llm_update_time": "2025-06-25 09:12:52", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19079", "html_url": "https://arxiv.org/abs/2506.19079", "title": "感受微笑：面部情感识别中基础模型的代理偏差", "title_en": "Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition", "authors": "Iosif Tsangko,Andreas Triantafyllopoulos,Adem Abdelmoula,Adria Mallol-Ragolta,Bjoern W. Schuller", "background": "基础模型（FMs）正在迅速改变情感计算（AC），视觉语言模型（VLMs）现在能够在零样本设置中识别情绪。本文探讨了一个关键但尚未充分研究的问题，即这些模型在推断情绪时依赖哪些视觉线索，这些线索是否具有心理学基础还是浅层次学习的结果？研究基于AffectNet数据集的牙齿标注子集，对不同规模的VLMs进行了基准测试，发现模型性能在牙齿可见与否的情况下存在一致性变化。通过对表现最佳模型——GPT-4o进行结构化的自我反向反省，研究表明眉毛位置等面部特征在其情感推理中起重要作用，显示了其在价值-唤醒预测中高度的一致性。这些模式不仅揭示了FMs行为的涌现性质，还揭示了风险：捷径学习、偏差和公平性问题，尤其是在心理健康和教育等敏感领域中。", "innovation": "研究通过结构化的自我反向反省分析了表现最佳的模型GPT-4o，揭示了其情感推理依赖的面部特征，并发现了面部情感识别中基础模型的代理偏差问题。这不仅提供了对FMs行为的新见解，也指出了在敏感领域的潜在风险。", "conclusion": "研究表明基础模型在情感识别过程中依赖于面部特征，特别是眉毛的位置对其情绪推理起重要作用。此外，还揭示了捷径学习、偏差和公平性问题是基础模型在敏感领域使用中需要关注的问题。"}
{"llm_update_time": "2025-06-25 09:12:55", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19125", "html_url": "https://arxiv.org/abs/2506.19125", "title": "在变压器架构中寻找聚类算法", "title_en": "Finding Clustering Algorithms in the Transformer Architecture", "authors": "Kenneth L. Clarkson,Lior Horesh,Takuya Ito,Charlotte Park,Parikshit Ram", "background": "变压器架构的发明彻底改变了人工智能领域，在自然语言处理、计算机视觉和多模态推理等领域的取得了前所未有的成功。然而，尚不清楚变压器是否能够学习并实现精确的算法。这篇论文利用变压器的标准组件（注意力和残差连接）证明了可以构建一个变压器架构，即 k-means 变压器，能够精确实现 k-means 聚类中的 Lloyd 算法，从而填补了这一领域的空白。", "innovation": "本文首先提出并理论证明了 k-means 变压器架构的存在性，能够精确实现 Lloyd 算法，提供了一个基于神经网络的 k-means 聚类的完全实现。此外，通过引入可解释的修改（如层规范化或多层感知机），发现了多种新颖的聚类算法变体，展示了变压器机制如何精确映射到算法过程，为在变压器中实现精确算法提供了一个清晰可解释的视角。", "conclusion": "本文的研究成果表明，变压器机制能够精确映射到算法程序，为通过变压器实现精确算法提供了明确的视角。"}
{"llm_update_time": "2025-06-25 09:12:57", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19089", "html_url": "https://arxiv.org/abs/2506.19089", "title": "语言模型可能无法理解你：通过故事提示评估共情理解能力", "title_en": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting", "authors": "Nathaniel Getachew,Abulhair Saparov", "background": "在现有基准测试中，由于可能存在的预训练数据污染问题，语言模型（LLMs）在评价共情理解（ToM）和世界建模（WM）能力时受到限制。因此，需要一个新颖的方法来生成合成故事，以严格控制角色视角和事件，从而评估LLMs在ToM和WM方面的表现。", "innovation": "我们引入了StorySim框架，这是一个编程框架，用于生成合成故事以评估LLMs的ToM和WM能力。与过往可能受到预训练数据污染影响的基准测试不同，StorySim能够生成具有高度可控制性的故事板（Storyboard），使得能够精确操控角色视角和事件，设计了包括ToM和WM在内的复杂任务，让模型在跟踪和建模心理状态方面得到精确测试。实验结果显示，大多数模型在WM任务中的表现优于ToM任务，且模型在与人类进行推理的表现优于与无生命物体，还发现了模型存在启发式行为的现象，比如最近性偏误和对早期事件过分依赖的倾向。这些组件都是由我们提供开源的代码生成的，方便其他研究者验证和进一步研究。", "conclusion": "我们的实验表明，大多数最先进的LLMs在WM任务中的表现优于ToM任务，而在面对人类与无生命物体时，模型的表现也有显著差异。此外，我们还发现部分模型存在启发式偏差，如短时记忆效应。"}
{"llm_update_time": "2025-06-25 09:12:57", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19121", "html_url": "https://arxiv.org/abs/2506.19121", "title": "CUPID: 使用影响函数来个性化机器人所需的数据", "title_en": "CUPID: Curating Data your Robot Loves with Influence Functions", "authors": "Christopher Agia,Rohan Sinha,Jingyun Yang,Rika Antonova,Marco Pavone,Haruki Nishimura,Masha Itkina,Jeannette Bohg", "background": "在机器人模仿学习中，策略性能与演示数据的质量和组成紧密相关。然而，准确理解每个演示如何影响下游结果（如闭环任务的成功或失败）仍是一个持久的挑战。CUPID 提出了一种基于新颖影响函数理论形式的机器人数据管理方法，以解决这一问题。通过这种方法，给定一组评估滚动部署，CUPID 能够估计每个训练演示对策略期望回报的影响，进而按照其对策略闭环性能的影响进行排名和选择演示数据。这种方法用于数据筛选和优化，例如过滤有害于策略性能的训练演示，以及选择最有可能改进策略的新收集轨迹。", "innovation": "CUPID 提出了一种新颖的基于影响函数理论的模仿学习策略，能够精确估计每个训练演示对策略性能的影响。该方法还能够通过筛选有害演示和选择有利的新数据来优化演示数据集，从而大大提升策略在闭环环境中的表现，并且在仿真和硬件实验中都取得了显著的效果。", "conclusion": "实验结果表明，CUPID 方法能够识别出对测试时性能有重要驱动的数据，使用不到 33% 的优化数据即可达到最先进的扩散策略性能。此外，硬件实验展示了该方法在分布偏移情况下能够识别稳健策略，隔离虚假相关性，并提升通用机器人策略的后训练效果。更多材料可以在提供的链接中找到。"}
{"llm_update_time": "2025-06-25 09:12:57", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19107", "html_url": "https://arxiv.org/abs/2506.19107", "title": "通过教学提示提高学生与AI互动：以计算机科学教育为例", "title_en": "Improving Student-AI Interaction Through Pedagogical Prompting: An Example in Computer Science Education", "authors": "Ruiwei Xiao,Xinying Hou,Runlong Ye,Majeed Kazemitabaar,Nicholas Diana,Michael Liut,John Stamper", "background": "自2022年起，大规模语言模型（LLM）应用的普及引起了教育界的广泛关注和争议。最近的研究显示，学生误用LLM会阻碍学习成果。本文旨在教授学生如何有效地使用LLM以提升他们的学习效果。研究首先提出了基于教学理念的新概念——教学提示，以引导LLM产生学习导向的回答。通过与早期计算机科学课程（CS1/CS2）任课教师的合作，基于课堂教学的实际需求进行了先导调查研究，并据此设计了一个基于场景的互动系统来培养教学提示技能。经过用户研究，结果表明，学习干预提高了学生基于LLM寻求教学帮助的能力，并且对系统持积极态度，增加了未来使用教学提示的意愿。研究为更广泛地在课堂上实施学习干预提供了可能性，并且有可能被整合到像ChatGPT这样的工具中，作为入门体验，以鼓励使用生成式AI的学习导向方法。", "innovation": "提出了一个基于理论的教学提示概念，以引导LLM生成学习导向的回答。设计并开发了一个互动学习系统，通过基于场景的指导训练学生的教学提示技能。这为提升学生与LLM的互动效果提供了一种新的方法，并可能被整合进像ChatGPT这样的工具中。", "conclusion": "通过混合方法分析，发现教学提示的引入显著改善了学生基于LLM寻求教学帮助的能力，同时提升了学生对系统的积极态度和未来使用教学提示的意愿。该研究为更广泛地在计算机科学教育中实施教学提示提供了实际案例和设计参考，并显示了在其他学科中可拓展的应用潜力。"}
{"llm_update_time": "2025-06-25 09:12:58", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19143", "html_url": "https://arxiv.org/abs/2506.19143", "title": "思辨锚点：哪些LLM推理步骤至关重要？", "title_en": "Thought Anchors: Which LLM Reasoning Steps Matter?", "authors": "Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy", "background": "大语言模型在许多领域已经取得了最先进的性能，但它们在长形式推理过程中依赖链式思维，这为解释模型推理过程带来了挑战。每个生成的词都依赖于前面所有的词，这使得计算难以分解。我们提出一种在句子层面分析推理路径的方法，以理解推理过程，这种方法被认为是很有前途的。", "innovation": "我们提出了三种互补的归因方法：1. 一种黑盒方法，通过对比模型在产生某个句子或不同含义句子时最终答案的变化，来衡量每个句子的反事实重要性；2. 一种白盒方法，通过聚合句子对之间的注意力模式，并识别那些在所有后续句子中收到来自‘接收者’注意力头部问题不均衡关注的“广播”句子；3. 一种因果归因方法，通过抑制一个句子的注意力，测量对每个未来句子中的词的影响，来衡量句子之间的逻辑联系。每种方法都为存在‘思辨锚点’提供了证据，这种锚点通常是在推理过程中具有影响超常的‘计划’或‘回溯’句子。我们在开源工具（此网址）中提供了一个可视化方法输出的工具，并通过案例研究展示了方法之间的一致性如何映射模型进行多步推理的方式。", "conclusion": "我们的研究方法的一致性表明，句子层面的分析对于理解推理模型具有更大的潜力。"}
{"llm_update_time": "2025-06-25 09:13:01", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19250", "html_url": "https://arxiv.org/abs/2506.19250", "title": "通过全局利普希茨正则化实现稳健的行为克隆", "title_en": "Robust Behavior Cloning Via Global Lipschitz Regularization", "authors": "Shili Wu,Yizhao Jin,Puhua Niu,Aniruddha Datta,Sean B. Andersson", "background": "行为克隆（Behavior Cloning, BC）是一种有效的模仿学习技术，在诸如自主车辆等安全关键领域也被采纳。尽管BC能够在缺乏环境交互的情况下训练出模拟专家行为的策略，但在实际部署中，由于传感器误差或恶意干扰，观测值可能会与真实状态有所偏差，这可能导致代理执行非最优动作。为了改善这一情况，本文使用全局利普希茨正则化方法增强策略网络的鲁棒性，并展示了这种全局利普希茨性质如何为策略提供不同界范数干扰下的鲁棒性验证。", "innovation": "本文创新地提出了一种通过构建全局利普希茨神经网络来确保策略鲁棒性的方法。这种方法能够增强策略网络在面对观测误差和干扰时的鲁棒性，并且在Gymnasium环境中得到了实验证明。", "conclusion": "本文研究了通过全局利普希茨正则化来增强行为克隆中策略的鲁棒性，最终证明了该方法能有效提升策略在网络环境中面对不同范数干扰下的鲁棒性。"}
{"llm_update_time": "2025-06-25 09:13:02", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19220", "html_url": "https://arxiv.org/abs/2506.19220", "title": "重新审视私有模型个性化", "title_en": "Private Model Personalization Revisited", "authors": "Conor Snedeker,Xinyu Zhou,Raef Bassily", "background": "该研究在用户级别差分隐私的背景下探讨了共享表示框架下的模型个性化。数据来自n个用户，这些用户的统计数据是异质的，并且他们的最优参数共享一个未知的嵌入U*。该工作旨在在联邦学习环境中以隐私和较小的超额风险来恢复共享嵌入和用户的低维表示。", "innovation": "该研究提出了一种基于FedRep算法的差别隐私的高效联邦学习算法来学习共享嵌入。与[CHM+21]不同，该算法满足差分隐私且适用于含噪声标签的情况。此外，在自然参数范围内，该方法将[JRS+21]中的隐私误差项提高了因子$\tilde{O}(dk)$。对于二分类任务，提出了信息论的构造来私有地学习共享嵌入，并且给出了独立于$d$的准确率保证。该方法利用Johnson-Lindenstrauss变换来减少共享嵌入和用户数据的有效维度，展示了在该损失函数下在无维度依赖的情况下可实现风险界的可能性。", "conclusion": "该研究在多种环境下改进了私有模型个性化算法，特别是在共享嵌入的学习上，研究展示了一种新的信息论方法，并实现了独立于数据维度的准确率保证，展示了在差分隐私下进行模型个性化的好处。"}
{"llm_update_time": "2025-06-25 09:13:03", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19217", "html_url": "https://arxiv.org/abs/2506.19217", "title": "MedErr-CT: 一种用于识别和纠正CT报告错误的视觉问答基准", "title_en": "MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports", "authors": "Sunggu Kyung,Hyungbin Park,Jinyoung Seo,Jimin Sung,Jihyun Kim,Dongyeong Kim,Wooyoung Jo,Yoojin Nam,Sangah Park,Taehee Kwon,Sang Min Lee,Namkug Kim", "background": "CT在临床诊断中起着关键作用，但CT检查需求的增长引发了关于诊断错误的担忧。虽然多模态大型语言模型（MLLMs）在医学知识理解方面表现出前景，但它们生成错误信息的趋势强调了严格验证的必要性。现有医学视觉问答（VQA）基准主要集中在简单的视觉识别任务上，缺乏临床相关性，无法评估专家级知识。此外，现有的医学图像问答基准主要侧重于西医影像学图像，而对于核医学和放射学研究较少涉及微小病变的高级诊断和报告纠错能力的评估。", "innovation": "MedErr-CT是用于评估MLLMs在CT报告中识别和纠正错误能力的新基准，通过VQA框架引入六种错误类别——四种视觉中心错误（省略、插入、方向、大小）和两种词汇错误类型（单位、打字错误）。它按分类、检测和纠正三个任务级别组织。利用该基准，对最先进的3D医学MLLMs的性能进行了定量评估，揭示了不同错误类型的显著差异。该基准为开发更可靠和临床适用的MLLMs做出了贡献，最终有助于减少诊断错误并提高临床实践的准确性。", "conclusion": "MedErr-CT基准有助于评估和提高多模态大型语言模型在识别和纠正CT报告中的错误，从而促进更可靠和临床适用的大型语言模型的发展，最终减少诊断错误并提高临床实践的准确性。代码和数据集可在该网址获得：this https URL"}
{"llm_update_time": "2025-06-25 09:13:04", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19312", "html_url": "https://arxiv.org/abs/2506.19312", "title": "细粒度对齐改善了3D功能性检测", "title_en": "Capturing Fine-Grained Alignments Improves 3D Affordance Detection", "authors": "Junsei Tokumitsu,Yuiga Wada", "background": "当前功能性检测主要在3D点云中进行，这项任务需要有效地捕捉点云和文本之间的精细对齐。现有方法在标准基准测试中表现不佳，主要原因是它们依赖于简单的点云和文本嵌入的余弦相似性，缺乏精细推理所需的表达力。", "innovation": "我们提出了LM-AD，一种新的3D点云功能性检测方法，以及Affordance Query Module (AQM)，它通过预训练的语言模型高效地捕捉点云和文本之间的精细对齐。我们的方法在3D AffordanceNet数据集上的准确率和mean Intersection over Union方面均优于现有方法。", "conclusion": "我们的研究表明，通过利用预训练的语言模型来捕捉细腻的对齐关系，可以显著提高3D功能性检测的性能。"}
{"llm_update_time": "2025-06-25 09:13:06", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19225", "html_url": "https://arxiv.org/abs/2506.19225", "title": "Video-XL-2: 通过任务感知的键值稀疏化实现非常长视频理解", "title_en": "Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification", "authors": "Minghao Qin,Xiangrui Liu,Zhengyang Liang,Yan Shu,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu", "background": "多模态大型语言模型（MLLMs）在过去几年中在视频理解方面取得了显著进展。但是，处理长视频输入仍然是一个主要挑战，因为这会带来高内存和计算成本。这使得当前模型难以在长视频理解中同时实现强大的性能和高效的处理。", "innovation": "本文提出了Video-XL-2，这是一种基于任务感知的键值稀疏化的新颖MLLM，该模型通过分块预填充和两层键值解码显著提高了长视频理解的成本效益。分块预填充按块将视觉标记序列分为若干部分，对每个块内部应用全注意力机制，对块之间进行稀疏注意力机制。在解码阶段，采用两层键值解码机制，针对每个块选择性地重新加载密集或稀疏的键值，进一步提高内存效率并增强模型捕捉细粒度信息的能力。Video-XL-2在多种长视频理解基准测试中达到了最先进的性能，性能优于现有的开源轻量级模型，并且在处理效率上表现出色，能够在单个NVIDIA A100（80GB）GPU上处理超过10,000帧，并在几秒钟内处理数千帧", "conclusion": "Video-XL-2通过任务感知的键值稀疏化技术，显著提升了多模态大型语言模型在处理长视频理解任务时的成本效益和效率，达到了最先进的性能，展现了出色的应用潜力。"}
{"llm_update_time": "2025-06-25 09:13:06", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19279", "html_url": "https://arxiv.org/abs/2506.19279", "title": "EmoStage：基于换位思考和阶段识别的同理心响应生成框架", "title_en": "EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition", "authors": "Zhiyang Qi,Keiko Takamizo,Mariko Ukiyo,Michimasa Inaba", "background": "近年来，对心理健康服务的需求日益增加，促进了对包含人工智能（AI）驱动咨询系统的兴趣。尽管大型语言模型（LLMs）具有巨大的潜力，但当前方法仍然面临挑战，如对客户心理状态和咨询阶段理解有限，对高质量训练数据的高度依赖，以及商业部署过程中的隐私担忧。这些因素限制了AI在心理健康咨询中的应用效果和普及程度。", "innovation": "本文提出的EmoStage框架，通过利用开源大型语言模型的推理能力，增强同理心响应生成，而不需额外的训练数据。该框架引入了换位思考机制，以推断客户的心理状态和支持需求，生成具有情感共鸣的响应，并引入阶段识别确保咨询过程的同步，防止响应在上下文中的不适或不适当。研究结果表明，EmoStage提高了基础模型响应的质量，并在与数据驱动方法的竞争中表现良好。", "conclusion": "在不同文化背景下的心理咨询设置中的实验表明，EmoStage框架通过换位思考和阶段识别，改进了基础模型生成的响应质量，并在数据驱动方法中表现出竞争力。"}
{"llm_update_time": "2025-06-25 09:13:09", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X: 统一空地协作的车与一切互联系统", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "虽然多车辆协作驾驶在性能上明显优于单车辆自主驾驶，但传统的基于基础设施的车对一切（V2X）通信系统仍受到大规模部署成本的限制，并且在农村和郊区存在'未覆盖危险区'。空中无人物流车辆（UAVs）可以作为固定道路侧单元（RSUs）的灵活替代品或补充，不受地形限制，实现鸟瞰视角、动态定位和显著降低部署成本，从而开拓新的应用场景和解决方案。", "innovation": "AirV2X-Perception数据集利用UAV作为固定RSUs的补充，实现了多样化的车辆驾驶场景数据收集（包括城市、郊区、农村），涵盖了不同天气和光照条件，以便为车辆到无人机（V2D）算法开发和标准化评估提供支持，填补了空中辅助自动驾驶系统领域的关键空白。此数据集和开发工具已开源，以便进一步研究和应用开发。", "conclusion": "AirV2X-Perception数据集为V2D算法的开发与标准化评估提供了重要的依据，标志着空中辅助自动驾驶系统领域的重要进展，并为未来的无人汽车和无人机应用提供了重要的数据和工具支持。"}
{"llm_update_time": "2025-06-25 09:13:09", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19315", "html_url": "https://arxiv.org/abs/2506.19315", "title": "JCAPT：一种用于CAPT的联合建模方法", "title_en": "JCAPT: A Joint Modeling Approach for CAPT", "authors": "Tzu-Hsuan Yang,Yue-Yang He,Berlin Chen", "background": "有效的发音反馈在第二语言（L2）学习中至关重要，计算机辅助发音训练（CAPT）系统通常包含两个关键任务：自动发音评估（APA）和语音错误检测与诊断（MDD）。最近的研究表明，这两个任务的联合建模可以带来相互的好处。本研究利用了Mamba，一种选择性状态空间模型（SSM），并结合了音素特征和思维标记策略，以同时增强APA和MDD的解释性和精细时间推理能力。", "innovation": "本研究首次将音素归因、基于SSM的建模和提示技术联合应用于CAPT。该唯一框架在SpeechOcean762基准测试中的一系列实验表明，我们的模型在MDD任务中表现优于先前的方法，表现出持续的优势。", "conclusion": "我们的研究提出了一种联合模型方法JCAPT，该方法利用Mamba（选择性状态空间模型），结合音素特征和思维标记策略，提升了自动发音评估和语音错误检测与诊断的解释性和时间推理能力。实验表明该方法在MDD任务上优于先前的方法。"}
{"llm_update_time": "2025-06-25 09:13:13", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "Masked图自编码在图表示学习中表现出卓越性能，现有方法主要依赖节点上下文信息恢复被遮掩的信息。然而，它们对于异ophilic图处理不佳，因为这些方法仅专注于捕捉邻居信息而忽略了不同节点之间的差异信息，导致节点表示无法区分。现有研究通常未能很好地扩展到这类图上，因此需要新的方法来处理这些挑战。", "innovation": "本文提出了一种图掩码自动编码器，即Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE)，能够在掩码过程中重建邻近节点的差异信息，从而获得更易区分的节点表示。通过在17个广泛使用的基准数据集上进行实验，结果表明DGMAE能够在低维空间中有效地保留节点的差异性，并在节点分类、节点聚类和图分类等三个图表分析任务上显著优于现有的图自监督学习方法，展示了其卓越的优越性。", "conclusion": "通过DGMAE，我们能够在图表示学习中更好地处理异ophilic图的挑战，取得显著效果。我们的方法在多个图表分析任务上优于现有方法，并且源代码已公开。"}
{"llm_update_time": "2025-06-25 09:13:14", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19109", "html_url": "https://arxiv.org/abs/2506.19109", "title": "提升LLM应用的安全性：早期检测系统性能评估", "title_en": "Enhancing Security in LLM Applications: A Performance Evaluation of Early Detection Systems", "authors": "Valerii Gakh,Hayretdin Bahsi", "background": "大规模语言模型（LLM）在各种用户任务中的适配与应用日益增多，但由此产生的新型应用程序面临着新的威胁，如提示注入攻击，这会破坏系统的安全性。现有的提示注入防御策略尚不足以抵御这种攻击。针对这一背景，本研究调查了早期提示注入检测系统的检测能力，特别关注各种开源解决方案中实现的技术的检测性能。这些技术旨在检测包括提示泄露在内的某些类型提示注入攻击，其中，攻击者会恶意操纵LLM，使其输出其系统指令，违反了系统的机密性。研究对不同提示泄露检测技术进行了分析，并比较了几种检测方案的性能，揭示了这些技术的强弱，并在高风险部署中提出最佳配置和使用建议。这是对现有检测解决方案进行的首次研究，对比评估了LLM Guard、Vigil和Rebuff三种技术的性能。结果显示，Vigil中使用的金丝雀词检查实现对于检测提示泄露攻击并不有效，并提出了改进建议；此外，还发现了Rebuff中基于模型的次要技术的规避漏洞，并提出了缓解措施。将LLM Guard、Vigil和Rebuff在最佳性能下进行比较，结果显示，Vigil最适合要求最低假阳性率的场景，而Rebuff最适合平均需要的场景。", "innovation": "研究创新性地对早期提示注入检测系统进行了评估，首次对比了LLM Guard、Vigil和Rebuff三种技术的性能，尤其是在提示泄露检测技术方面。研究还发现了现有技术的不足之处，并提出了改进方法，填补了这一领域的空白。通过详细比较检测方案，揭示了每种技术的优缺点，并为高风险部署中的最优配置和使用提供了建议。\n", "conclusion": "研究结果表明，Vigil最适用于需要最小假阳性率的场景，而Rebuff则更适用于一般需求。研究还提出对Vigil和Rebuff的改进建议，并发现了Rebuff中基于模型的次要技术的一个规避漏洞并提出了解决方案。该研究提供了对提示泄露检测技术的深入理解，并为高风险部署中的最佳方案配置和选择提供了指导。"}
{"llm_update_time": "2025-06-25 09:13:18", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19387", "html_url": "https://arxiv.org/abs/2506.19387", "title": "NAADA: 噪声感知注意力去噪自编码器在牙科全景放射片中的应用", "title_en": "NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs", "authors": "Khuram Naveed,Bruna Neves de Freitas,Ruben Pauwels", "background": "卷积去噪自编码器（DAEs）是图像恢复的强大工具。然而，它们继承了卷积神经网络（CNNs）的关键缺点：它们倾向于更有效地恢复低频特征，如平滑区域，而对高频细节的恢复较差。这种特性导致图像中细微特征的丢失，特别是在牙科牙片中尤为麻烦，因为保留微妙的解剖结构是至关重要的。虽然自我注意机制能部分缓解此问题，但传统注意力方法往往优先处理较为清晰区域的特征，可能会忽略那些被噪声遮盖的特征。因此，该研究提出了一种噪声感知自我注意方法，使模型能够有效关注并恢复嘈杂区域的关键特征，进而提出了噪声感知注意增强去噪自编码器（NAADA）网络，用于增强牙科全景放射片。", "innovation": "提出的噪声感知注意增强去噪自编码器（NAADA）网络，能够关注并恢复嘈杂区域的重要特征；相较其他近期的先进方法（如Uformer，MResDNN等），该方法在重建细微特征方面表现出优势，确保了更好的图像质量和诊断准确性。", "conclusion": "NAADA网络通过噪声感知注意力机制克服了传统去噪自编码器在处理牙科全景放射片时对细微特征恢复不足的问题，实现了更高质量和更准确的诊断结果。"}
{"llm_update_time": "2025-06-25 09:13:20", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19399", "html_url": "https://arxiv.org/abs/2506.19399", "title": "黑盒大型语言模型中预训练文本的自动检测", "title_en": "Automated Detection of Pre-training Text in Black-box LLMs", "authors": "Ruihan Hu,Yu-Ming Shang,Jiankun Peng,Wei Luo,Yazhe Wang,Xi Zhang", "background": "检测给定文本是否属于大型语言模型（LLMs）的预训练数据对于确保数据隐私和版权保护至关重要。现有大多数方法依赖于模型的隐藏信息（例如，模型参数或标记概率），这使得它们在仅能访问输入和输出文本的黑盒环境中无效。虽然一些方法已经被提出，但由于需要进行大规模的手工努力（例如，设计复杂的提问或指令），这些方法尚不适用。", "innovation": "我们提出了VeilProbe，这是第一个在无需人工干预的情况下自动检测黑盒大型语言模型预训练文本的框架。VeilProbe利用序列到序列的映射模型推断输入文本与生成的相应输出后缀之间的潜在映射特征，然后进行关键标记扰动以获得更易于区分的成员特征。此外，鉴于实际场景中真实训练文本样本有限，我们引入了一种基于原型的成员分类器来缓解过拟合问题。", "conclusion": "我们在三个广泛使用的数据集上进行的大量评估表明，我们的框架在黑盒设置中有效且具有优越性。"}
{"llm_update_time": "2025-06-25 09:13:22", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19342", "html_url": "https://arxiv.org/abs/2506.19342", "title": "通过数据库叙事对齐解决酒精推断不匹配的洞察", "title_en": "Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment", "authors": "Sudesh Bhagat,Raghupathi Kandiboina,Ibne Farabi Shihab,Skylar Knickerbocker,Neal Hawkins,Anuj Sharma", "background": "道路交通事故是全球导致死亡的一个重要原因是，突出了解决策策制定和事故预防策略需要准确的事故数据的紧迫性。这项研究试图通过使用数据库叙事对齐来解决酒精推断不匹配（AIM）的问题，以此改善事故管理系统中的数据质量并减少事故中的AIM比率。自2016年至2022年，爱荷华州记录了371,062起事故，其中发现有2,767起事故存在AIM现象，占比达到24.03%。通过使用Probit Logit模型等统计工具研究事故特征对AIM模式的影响，确定了与酒精相关的致命事故和夜间事故在推断不匹配的现象中比例较低，而未知车辆类型及老年驾驶者的事故更易产生推断不匹配。", "innovation": "研究开发了提高事故管理系统数据质量的框架，并利用BERT模型分析了事故数据，识别出了2,767起AIM事件。采用Probit Logit模型等多种统计工具来探索影响AIM模式的事故特性，发现了重要结论，即多种类型的事故更易存在推断不匹配现象，这部分信息有助于确定教育培训的重点区域，并为提高事故报告的准确性和支持基于证据的政策制定提供依据。", "conclusion": "事故管理系统在数据质量上的提高框架，以及针对潜在的推断不匹配事故，尤其是涉及未知车辆类型和老年驾驶人的事故，提出了解决方案。通过分析事故数据，识别并理解AIM的特征，进一步指出了对特定地区的教育与培训需求，并强调了准确事故报告和基于证据的政策制定的重要性。"}
{"llm_update_time": "2025-06-25 09:13:24", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19351", "html_url": "https://arxiv.org/abs/2506.19351", "title": "基于上下文的奥卡姆剃刀：Transformer 如何在飞速中偏爱更简单的假设", "title_en": "In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly", "authors": "Puneesh Deora,Bhavya Vasudeva,Tina Behnia,Christos Thrampoulidis", "background": "在上下文学习（ICL）中，变换器可以通过上下文示例适应新任务，而无需更新参数。现有研究通常在固定复杂度环境中研究ICL，但实际的语言模型面对的任务复杂度多变。本文探讨了变换器在复杂任务层次结构中的行为，即更高复杂度类别可以完全代表更简单类别生成的任何模式。设计基于马尔可夫链和线性回归的严格测试平台，揭示变换器不仅能够识别每个任务合适复杂度级别，还能准确推断相应参数——即使上下文示例与多个复杂度假设兼容。当呈现由简单过程生成的数据时，变换器始终偏好最简单的充分解释。通过贝叶斯框架理论解释此行为，表明变换器通过在模型拟合度与复杂性惩罚之间平衡来有效实现一种类似于奥卡姆剃刀的算法。进一步分析了模型大小、训练混合分布、推理上下文长度和结构的作用。最后，通过一个预训练的GPT-4模型和布尔函数任务的案例研究验证了这种类似于奥卡姆剃刀的归纳偏置，表明这种偏置可能在多样性任务分布下训练的变换器中是固有的。", "innovation": "本文创新地研究了变换器在处理复杂任务层次结构时，如何识别任务的适当复杂度级别并正确推断参数。通过理论分析，证明了变换器通过平衡模型拟合度与复杂性惩罚来实现一种类似于奥卡姆剃刀的原则。同时，通过不同因素的分析和预训练模型的实验证明这种归纳偏置的存在，并提出这可能是变换器的一种固有特性。", "conclusion": "研究表明，变换器具有类似于奥卡姆剃刀的归纳偏置，能够自动选择最简单的假设来解释数据。这一行为可以通过贝叶斯框架解释。文章进一步探索了该现象背后的机制，并通过实际实验验证了其有效性。这些发现不仅加深了对变换器行为的理解，也指出了未来研究的潜在方向。"}
{"llm_update_time": "2025-06-25 09:13:27", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19459", "html_url": "https://arxiv.org/abs/2506.19459", "title": "带有方向标签：提高因果边方向定位精度", "title_en": "Tagged for Direction: Pinning Down Causal Edge Directions with Precision", "authors": "Florian Peter Busch,Moritz Willig,Florian Guldan,Kristian Kersting,Devendra Singh Dhami", "background": "因果关系并非对等，因此在因果发现任务中可以利用这种不平等性。现有研究表明，具有特定类型分配的变量对倾向于影响其他具有相同类型分配的变量的因果方向。然而，将特定类型分配给变量在实践中并不容易。提出了一个基于标签的因果发现方法，其中每个变量在因果图中被分配多个标签。这种方法首先应用现有的因果发现方法来引导一些边，然后利用这些边之间的关系来确定标签之间的关系。进一步利用这些标签间的关系来引导之前未定向的边，这种方法优于基于类型的完全关系，因为类型一致性假设受限于每个变量只能有一个类型。实验结果表明这种方法可以在因果发现的效果上有所提升，并且这些高级的标签间关系能更好地符合常识。", "innovation": "提出了一种新的基于标签的因果发现方法，其特点在于每个变量都分配多个标签，并利用这些标签之间的关系来引导未定向的边。这种方法增强了因果发现的效果，克服了传统方法中类型分配的限制和不足。", "conclusion": "实验证明，在因果发现任务中采用基于标签的方法可以提升因果边方向的准确性，并且这种高级的标签间关系更符合常识。"}
{"llm_update_time": "2025-06-25 09:13:29", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19433", "html_url": "https://arxiv.org/abs/2506.19433", "title": "Mem4Nav：一种用于城市环境中的视觉语言导航的层次空间认知长短期记忆系统", "title_en": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System", "authors": "Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li", "background": "在大规模的城市环境中进行视觉语言导航（VLN）需要具身智能体能够将语言指令与复杂的场景进行关联，并且需要在长时间框架内回忆相关体验。早期模块化的管道虽然提供了可解释性，但缺乏统一的内存；而端到端的（M）LLM智能体虽然在融合视觉和语言方面表现出色，但由于固定的上下文窗口和隐式的空间推理能力有限，仍然受到约束。因此，仍需要一种在保持可解释性的同时，能够长期存储和利用视觉信息，并进行有效空间推理的机制来提升VLN性能。", "innovation": "提出了Mem4Nav，这是一种层次结构的空间认知长短期记忆系统，能够增强任何VLN骨干网络。Mem4Nav结合稀疏八叉树（用于精细体素索引）和语义拓扑图（用于高级地标连接），并将这两种数据结构嵌入可训练的内存标记通过可逆的Transformer。长久记忆（LTM）会压缩和保存八叉树和图节点的历史观察结果，而短期记忆（STM）则缓存最近的多模态条目，并用于实时障碍物避让和局部规划。在每个步骤中，STM检索精确地剪枝动态上下文，在需要更多历史信息时，LTM标记进行无损解码来重新构建过去的嵌入。在Touchdown和Map2Seq数据集上，Mem4Nav在三个不同的VLN骨干网络中均表现出了显著的好转。", "conclusion": "实验证明，膜层地图和双内存模块对Mem4Nav是必不可少的。代码通过该链接开放源代码：this https URL."}
{"llm_update_time": "2025-06-25 09:13:30", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19256", "html_url": "https://arxiv.org/abs/2506.19256", "title": "通过时间正则化提高脉冲神经网络的泛化能力", "title_en": "Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization", "authors": "Boxuan Zhang,Zhen Xu,Kuan Tao", "background": "脉冲神经网络(SNNs)因事件驱动和低功耗特性而受到广泛关注，特别适合处理事件驱动的类脑数据。然而，直接训练的SNNs受到小规模类脑数据集和梯度不匹配问题的影响，导致严重的过拟合问题，这从根本上限制了它们的泛化性能。已有研究也证实了这一点。本文基于此背景进行研究，介绍了一种时间正则化训练(TRT)方法，旨在通过引入时间依赖正则化机制加强对早期时间步的约束，以此解决SNNs的过拟合问题并提升模型的泛化性能。", "innovation": "本文提出了一种时间正则化训练(TRT)方法，通过引入时间依赖正则化机制加强对早期时间步的约束，从而有效缓解SNNs的过拟合问题并改善其泛化性能。此外，本文还通过可视化损失景观和分析学习曲线，验证了TRT的有效性，并通过Fisher信息分析提供了TRT时间正则化机制的理论解释。研究表明，TRT引导网络在早期时间步学习富含信息的鲁棒特征，从而显著提高了模型的泛化能力。", "conclusion": "通过时间正则化训练(TRT)方法，本文成功解决了直接训练的SNNs的过拟合问题，提高了模型的泛化能力。理论分析还揭示了时间信息聚集现象（TIC），进一步证明了TRT的有效性。实验结果表明，TRT在多个数据集上的表现优于其他最先进的方法。"}
{"llm_update_time": "2025-06-25 09:13:30", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19269", "html_url": "https://arxiv.org/abs/2506.19269", "title": "AnchorDP3: 3D Supporting Function Guided Sparse Diffusion Policy for Robotic Manipulation", "title_en": "AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation", "authors": "Ziyan Zhao,Ke Fan,He-Yang Xu,Ning Qiao,Bo Peng,Wenlong Gao,Dongjiang Li,Hui Shen", "background": "本文介绍了一个名为AnchorDP3的双臂机器人操作扩散策略框架，该框架在高度随机化的环境中实现了最先进的性能。该框架基于大型、程序生成的模拟数据训练，在RoboTwin基准测试中，即使在对象、杂乱、桌子高度、光照和背景等极端随机化条件下，其平均成功率也达到了98.7%。该框架集成了三个关键创新点，展现了在复杂场景中实现高效操作的潜力，减少了对人类演示的需求.", "innovation": "本文提出了三个关键创新点：（1）模拟器监督语义分割，使用渲染的真实值来明确分割任务关键对象，提供强大的可用性先验；（2）任务条件特征编码器，轻型模块处理带有任务增强的点云，使通过共享的基于扩散的行动专家实现高效的多任务学习成为可能；（3）基于可用性锚定的关键姿势扩散与全程监督，该方法通过稀疏、几何意义上富有意义的动作锚点（如预抓取姿态、直接锚定到可用性的抓取姿态）替换密集的轨迹预测，极大地简化了预测空间，同时迫使行动专家同时预测机器人关节角度和末端执行器姿态，利用几何一致性加速收敛并提高准确性，使得框架能够与RoboTwin的现实到模拟流水线集成，有望仅从场景和指令生成可部署的视觉手眼策略，完全消除从学习操作技能中的人类演示需求.", "conclusion": "训练后的AnchorDP3框架在RoboTwin基准测试中实现了高成功率，展示了其在复杂任务中实现高效操作的潜力。该框架结合了RoboTwin的现实到模拟流水线，有可能仅从场景和指令生成可部署的视觉手眼策略，完全消除学习操作技能过程中所需的人类演示。"}
{"llm_update_time": "2025-06-25 09:13:30", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19461", "html_url": "https://arxiv.org/abs/2506.19461", "title": "迭代量子特征映射", "title_en": "Iterative Quantum Feature Maps", "authors": "Nasa Matsumoto,Quoc Hoan Tran,Koki Chinzei,Yasuhiro Endo,Hirotaka Oshima", "background": "量子机器学习模型利用量子电路作为量子特征映射（QFMs），在学习任务中表现出更强的表达能力。这类模型在特定的分类问题家族上证明了端到端的量子加速。然而，由于量子电路中的噪声和硬件限制，将深层QFMs部署到实际的量子硬件中仍然具有挑战性。此外，变量子算法通常在准确梯度估计方面存在计算瓶颈，这在训练期间大大增加了量子资源的需求。", "innovation": "本文提出了一种结合量子和经典计算的框架——迭代量子特征映射（IQFMs），通过迭代连接浅层QFMs和经典的增广权重构建深层架构。通过引入对比学习和逐层训练机制，IQFMs有效减少了量子运行时间并缓解了噪声引起的退化问题。", "conclusion": "在包含噪声量子数据的任务中，数值实验表明IQFMs在不优化变量子参数的情况下超过了量子卷积神经网络的表现。即使在典型的经典图像分类基准测试中，精心设计的IQFMs也达到了与经典神经网络相当的性能。这一框架为解决当前限制并充分利用增强型量子机器学习的潜力指明了前景。"}
{"llm_update_time": "2025-06-25 09:13:32", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19352", "html_url": "https://arxiv.org/abs/2506.19352", "title": "开放生成中个性一致性瑕疵的识别：原子级别评价框架", "title_en": "Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation", "authors": "Jisu Shin,Juhyun Oh,Eunsu Kim,Hoyun Song,Alice Oh", "background": "确保大型语言模型（LLMs）中的人格一致性对于维持连贯而引人入胜的人工智能互动至关重要。然而，LLMs经常表现出脱稿行为（OOC），即生成的响应与分配的人格不符，导致不一致，影响模型的可靠性。现有的评估方法通常为整个响应分配单一分数，难以捕捉长篇文本生成中的微妙个性偏差。为解决这一局限性，我们提出了一种原子级别的评价框架，能够以更精细的粒度量化人格一致性。我们的三个关键指标衡量人格对齐和一致性，无论是内部还是跨生成的表现。这种方法通过识别真实用户可能会遇到的微妙偏差，提供更精确和现实的人格一致性评估。", "innovation": "我们提出了一种原子级别的评价框架，可以在更精细的粒度上量化语言模型的人格一致性，通过三个关键指标来衡量人格对齐和一致性，并通过具体实验证明该框架能够有效检测先前方法忽视的人格不一致问题，从而能够更精确地评估和识别真实用户可能会遇到的微妙偏差。", "conclusion": "通过分析不同类型的任务和人格特质的人格一致性，我们揭示了任务结构和人格吸引力如何影响模型的适应性，突显了在维持一致的人格表达方面所面临的重要挑战。"}
{"llm_update_time": "2025-06-25 09:13:37", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19406", "html_url": "https://arxiv.org/abs/2506.19406", "title": "GLCANet网络用于超高分辨率遥感图像语义分割", "title_en": "A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation", "authors": "Chen Yi,Shan LianLei", "background": "由于超高压缩（UHR）遥感技术的快速发展，对于精确且高效的语义分割需求显著增加。然而，现有的方法在计算效率和多尺度特征融合方面面临挑战。", "innovation": "提出了GLCANet（全局-局部交叉注意力网络），这是一种轻量级语义分割框架，专为UHR遥感设计。GLCANet采用了双流架构，有效融合全局语义和局部细节，同时减少GPU使用，自注意力机制增强长期依赖性，细化全局特征，保留局部细节以提高语义一致性。掩码交叉注意力机制也适应性地融合全局-局部特征，选择性地增强细粒度细节，同时利用整体上下文以提高分割精度。实验结果显示GLCANet在准确性和计算效率方面优于现有方法，能够有效处理大尺寸、高分辨率图像，具有较小的内存占用，为实际遥感应用提供了有希望的解决方案。", "conclusion": "GLCANet在准确性和计算效率方面均优于现有方法，适用于处理大尺寸、高分辨率遥感图像，为实际应用提供了有效的解决方案。"}
{"llm_update_time": "2025-06-25 09:13:39", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19358", "html_url": "https://arxiv.org/abs/2506.19358", "title": "基于有限数据的高信噪比雷达信号到心电信号的迁移学习模型与心肌聚焦算法", "title_en": "From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data", "authors": "Yuanyuan Zhang,Haocheng Zhao,Sijie Xiong,Rui Yang,Eng Gee Lim,Yutao Yue", "background": "心电图（ECG）作为心脏特征的重要细粒度信息，可以从雷达信号中成功恢复，但性能高度依赖于高质量的雷达信号和大量雷达-ECG对的训练，数据稀缺限制了在新场景中的应用。因此，文章旨在探讨在数据有限的新场景中基于雷达的心电图恢复，并提出一种心肌聚焦与跟踪（CFT）算法以准确追踪心脏位置，确保高效获取高质量雷达信号。此外，提出了一种基于迁移学习的RFcardi模型，该模型可以在没有心电图真实标签的情况下，从雷达信号中提取心肌相关信息，并通过少量同步雷达-ECG对微调预训练模型以实现心电信号恢复。实验结果表明，该提出的CFT能够动态识别心脏位置，且RFcardi模型可以在少量雷达-ECG对训练后生成忠实的心电图恢复。相关的代码和数据集将在发表后提供。", "innovation": "提出了一种基于迁移学习的RFcardi模型，该模型不需要心电图真实标签即可从雷达信号中提取心肌相关信息，并且只需要少量同步雷达-ECG对即可优化模型进行心电图恢复。同时，提出了一种心肌聚焦与跟踪（CFT）算法以有效确保雷达信号的质量。", "conclusion": "所提出的CFT算法能够动态识别心脏位置，RFcardi模型在少量雷达-ECG对训练后可以有效生成忠实的心电图恢复。相关代码和数据集将在发表后提供。"}
{"llm_update_time": "2025-06-25 09:13:40", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19465", "html_url": "https://arxiv.org/abs/2506.19465", "title": "改进的预训练神经网络的结构图案风格化", "title_en": "Stylized Structural Patterns for Improved Neural Network Pre-training", "authors": "Farnood Salehi,Vandit Sharma,Amirhossein Askari Farsangi,Tunç Ozan Aydın", "background": "现代计算机视觉中的深度学习模型需要大量的真实图像数据集，但采集这些数据存在困难，还存在隐私和法律问题，限制了其商业应用。近期研究表明合成数据可以作为替代方案，但由于模型在训练时因此常表现欠佳。研究指出通过一种两步法来解决这一问题。首先，通过改进的神经分形公式引入一种新的合成数据类别。其次，提出反向风格化技术，将小规模、无版权的真图像的视觉特征转移到合成数据集中，提升其效果。通过Kernel Inception Distance (KID)分析合成数据与真图像之间的领域差距，证明该方法的差距显著低于现有合成数据集的方法。实验表明，合成数据集的减少差距提高了不同任务的实际影响。验证 EDM2 扩散模型在该合成数据集上的预训练降低了11%的FID，同时减少20%的自编码重构误差，表明在数据表示上有更好的表现。使用该合成数据集对ViT-S模型进行分类训练能实现超过10%的ImageNet-100准确率提升。这项工作在可用足够大的真实训练数据集时，为训练实用模型提供了新的可能性。", "innovation": "1. 提出了改进的神经分形公式，为合成数据引入新类别。\n2. 引入反向风格化技术，将无版权的真实图像视觉特征转移至合成数据集。\n3. 使用Kernel Inception Distance (KID)分析合成数据与真实数据之间的差距，证明方法的优越性。\n4. 通过EDM2扩散模型的预训练和自编码器的性能提升以及使用合成数据集训练ViT-S模型后的分类准确率改进，验证了该方法的有效性。", "conclusion": "通过改进的神经分形公式和反向风格化技术，提出了一种两步法来使用合成数据预训练神经网络，有效缩小合成数据与真图像之间的领域差距。与现有方法相比，该方法显著提升了多种任务性能，并在EDM2模型和ViT-S分类模型上得到了验证，展示了在真实数据稀缺情况下训练模型的切实可行性和潜在应用价值。"}
{"llm_update_time": "2025-06-25 09:13:40", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19491", "html_url": "https://arxiv.org/abs/2506.19491", "title": "神经3D重构在小型无人机应用中的实验评估", "title_en": "Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications", "authors": "Genís Castillo Gómez-Raya,Álmos Veres-Vitályos,Filip Lemic,Pablo Royo,Mario Montagud,Sergi Fernández,Sergi Abadal,Xavier Costa-Pérez", "background": "随着无人机(UAV)不断朝着更小的方向发展，其应用场景已扩展到室内和难以到达的区域。然而，这一趋势也带来了飞行动态和能耗等方面的独特挑战，这些挑战限制了无人机的自主性和任务执行能力。该论文通过将神经3D重构(N3DR)技术与小型无人机系统集成，提出了一种新的方法，以提高小型静态对象的3D数字重建质量，特别是在使用小型无人机拍摄的对象图像进行精细三维重建方面。", "innovation": "该论文设计、实现并评估了一种基于神经3D重构(N3DR)的管道，该管道利用先进的模型Instant-ngp、Nerfacto和Splatfacto改进3D重建质量。与传统的结构从运动(SfM)算法相比，该方法展示了显著提升的重建效果，并验证了其在限制环境下的高精度3D测绘和异常检测能力。", "conclusion": "实验结果表明，N3DR增强的管道显著提高了3D重建质量，使得小型无人机能够支持在受限环境下进行高精度3D测绘和异常检测。这为微型化无人机系统的功能提升提供了宝贵的技术手段。"}
{"llm_update_time": "2025-06-25 09:13:40", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19468", "html_url": "https://arxiv.org/abs/2506.19468", "title": "MuBench: 在61种语言中评估大型语言模型的多语言能力", "title_en": "MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages", "authors": "Wenhan Han,Yifan Zhang,Zhixun Chen,Binbin Liu,Haobin Lin,Bingni Zhang,Taifeng Wang,Mykola Pechenizkiy,Meng Fang,Yin Zheng", "background": "多语言大语言模型（LLMs）正在迅速发展，新的模型经常声称支持越来越多的语言。然而，现有的评估数据集有限且缺乏跨语言对齐，使对多语言能力的评估在语言和技能覆盖方面支离破碎。为解决这一问题，我们引入了MuBench，一个覆盖61种语言并评估广泛能力的基准。我们评估了几种最新的多语言LLM，并发现宣传和实际语言覆盖面之间存在显著差距，特别是在英语和低资源语言之间持续存在性能差距。利用MuBench的对齐，我们提出了多语言一致性（MLC）作为一个与准确率互补的度量标准，用于分析性能瓶颈并指导模型改进。最后，我们在英语和中文上预训练了一套1.2亿参数的模型，变化语言比例和并行数据比例来探索跨语言迁移动力学。", "innovation": "提出了新的MuBench基准，覆盖61种语言并评估广泛能力；发现了多语言模型的特定差距，特别是英语和低资源语言之间的性能差距；提出了多语言一致性（MLC）作为与准确率互补的性能度量；进行了多语言模型的大规模预训练，以研究跨语言迁移动力学。", "conclusion": "通过MuBench，我们更好地评估了多语言模型的全面性能，发现了很多性能的瓶颈，并提出了多语言一致性（MLC）作为改进模型的一个新的评估方式，同时也进行了多语言模型的预训练研究，进一步探讨了跨语言迁移的能力。"}
{"llm_update_time": "2025-06-25 09:13:42", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19484", "html_url": "https://arxiv.org/abs/2506.19484", "title": "大型语言模型的对话式教育方法：将对话式AI与经验证的教育理论相结合", "title_en": "Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning", "authors": "Russell Beale", "background": "大规模语言模型（LLMs）正迅速改变教育，通过提供丰富的对话式学习体验。本文综述了基于LLM的对话代理在高等教育中的应用，并扩展到中等教育和终身学习的情境。文章综合分析了LLMs在教育中的现有文献以及对话式/对话式教学理论，如维果茨基的社会文化学习理论（支架和最近发展区）、苏格拉底方法和洛尔德的对话框架，探讨了提示策略和检索增强生成（RAG）如何使LLM的行为与这些教学理论相吻合，以及如何支持个性化和自适应学习。文章还剖析了将先前理论应用于LLM过程中存在的不足，例如，模型倾向于提供直接答案而不是促进知识的共同构建，以及需要考虑到LLM导师的持续可用性和广泛但非人类专长的特点。", "innovation": "本文提出了一些实际策略来更好地使LLM互动与良好的教育实践保持一致，例如设计鼓励苏格拉底式提问、分层次指导和学生反思的提示，以及整合检索机制以确保准确性和相关性。此外，文章旨在弥合教育理论与人工智能驱动的对话学习新兴实践之间的差距，提供使LLM对话更加教育上有效并理论导向的见解和工具的方法。", "conclusion": "文章认为，通过将教育理论与LLM的能力更好地结合，可以提升对话式AI在教育资源中的效果和理论导向性，无论是直接提供学习经验，还是潜在支持更深层次的学习理论分析。"}
{"llm_update_time": "2025-06-25 09:13:46", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19482", "html_url": "https://arxiv.org/abs/2506.19482", "title": "通过虚拟节点学习实现快速且分布式对称图神经网络", "title_en": "Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning", "authors": "Yuelin Zhang,Jiacheng Cen,Jiaqi Han,Wenbing Huang", "background": "对称图神经网络（Equivariant GNNs）已经在多种科学应用中取得了显著的成功，但现有方法在处理大规模几何图时效率低下，并且在对输入图进行稀疏化以实现计算可操作性时，其性能会大幅下降。为解决这些问题，研究引入了FastEGNN和DistEGNN，这是对大规模几何图的对称图神经网络的两个新型改进方法。FastEGNN通过一小部分按顺序排列的虚拟节点有效近似了大规模无序的真实节点图。DistEGNN则是一种分布式扩展，虚拟节点作为不同设备间子图之间的全球桥梁，维持一致性的同时显著减少了内存和计算开销。这些模型在四个具有挑战性的领域中进行了全面评估：N体系统（100个节点）、蛋白质动力学（800个节点）、Water-3D（8,000个节点）以及最新的Fluid113K基准（113,000个节点），结果表明这两种方法在效率和性能方面表现出色，开创了大规模对称图学习的新能力。", "innovation": "FastEGNN通过一小部分按顺序排列的虚拟节点有效近似了大规模无序的真实节点图，并对不同虚拟节点实施了不同的消息传递和聚合机制以确保它们的独一无二性，并通过最小化虚拟与真实坐标之间的最大均差（MMD）来实现全局分布特性。这种设计使得FastEGNN可以高效处理大规模稀疏图的同时保持高精度。DistEGNN则是一种分布式扩展，在极其大规模的几何图中，虚拟节点充当不同设备间子图之间的全球桥梁，保持一致性的同时显著减少了内存和计算开销。", "conclusion": "研究在四个具有挑战性的领域：N体系统、蛋白质动力学、Water-3D和Fluid113K基准中全面评估了模型，展示了FastEGNN和DistEGNN在大规模对称图学习中的卓越效率和性能。这些结果确立了在大规模几何图上全新的对称图学习能力。相关代码已公开可获取。"}
{"llm_update_time": "2025-06-25 09:13:48", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19525", "html_url": "https://arxiv.org/abs/2506.19525", "title": "自动药学剂量说明结构化：LLMs的作用是什么？", "title_en": "Automatic Posology Structuration : What role for LLMs?", "authors": "Natalia Bobkova,Laura Zanella-Calzada,Anyes Tafoughalt,Raphaël Teboul,François Plesse,Félix Gaschi", "background": "自动结构化药学剂量说明对于提高用药安全和临床决策支持至关重要。然而，在法语处方中，这些说明往往模糊、不规则或口语化，限制了传统机器学习管道的有效性。因此，研究如何利用大型语言模型（LLMs）将自由文本的剂量说明转换为结构化格式具有重要意义。", "innovation": "研究探索了使用LLMs将自由文本剂量说明转换为结构化格式的方法，并将基于提示的方法与基于命名实体识别和链接（NERL）系统的微调方法进行了比较。研究提出了一种混合管道，将NERL中置信度较低的案例（<0.8）路由到LLMs，并根据置信度分数选择输出。这种策略实现了91%的结构化准确性，同时减少了延迟和计算成本，提供了一个在实际临床环境中可扩展的解决方案。", "conclusion": "研究结果表明，这种混合方法在提高结构化准确性的同时限制了计算成本，为实际临床应用提供了可扩展的解决方案。"}
{"llm_update_time": "2025-06-25 09:13:49", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19467", "html_url": "https://arxiv.org/abs/2506.19467", "title": "大型语言模型能否捕捉人类注释者的分歧？", "title_en": "Can Large Language Models Capture Human Annotator Disagreements?", "authors": "Jingwei Ni,Yu Fan,Vilém Zouhar,Donya Rooein,Alexander Hoyle,Mrinmaya Sachan,Markus Leippold,Dirk Hovy,Elliott Ash", "background": "在自然语言处理（NLP）中，人类注释可能出现分歧，这些分歧往往反映了任务的主观性以及样本的模糊性。尽管大型语言模型（LLMs）被越来越多地用于自动注释以减少人类劳动，但它们的评估通常集中在预测多数投票的“真实”标签上。然而，尚不清楚这些模型是否也能捕捉到有意义的人类注释分歧。该研究通过广泛的评估，旨在填补这一空白，即评估LLMs在没有重复人类标签的情况下预测注释分歧的能力。研究表明，LLMs在建模分歧方面存在困难，这可能会被基于多数标签的评估所忽略。尽管利用RLVR风格的强化学习评估通常能提升LLM性能，但在分歧预测方面却表现不佳。", "innovation": "该工作通过广泛的评估，探讨了LLMs在没有重复人类标签的情况下预测注释分歧的能力。研究发现，虽然利用RLVR风格的强化学习评估通常能提升LLM性能，但在预测分歧方面却表现不佳。这一发现强调了评估和改进LLM注释者以应对分歧建模的迫切需求。论文还提供了相应的代码和数据以便进一步研究。", "conclusion": "研究结果表明LLMs在建模注释分歧方面存在不足，而基于多数标签的评估可能忽视了这一问题。尽管强化学习评估在一般情况下能提升LLM性能，但在分歧预测方面却表现不佳。因此，需要进一步研究和改进以提升LLM在分歧建模方面的表现。"}
{"llm_update_time": "2025-06-25 09:13:49", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19502", "html_url": "https://arxiv.org/abs/2506.19502", "title": "MATE: 基于LLM的强大多代理翻译环境在无障碍应用中的应用", "title_en": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications", "authors": "Aleksandr Algazinov,Matt Laing,Paul Laban", "background": "在当今社会，无障碍问题仍然是一个重要问题，许多技术并未针对所有用户的需求进行开发。现有的多代理系统（MAS）由于封闭源代码设计带来的定制不足，往往无法为有需要的用户提供全面的帮助。因此，许多残疾人面对数字环境的交互时面临着显著的障碍。这些情况表明，市场上需要一个能够根据用户需求自动进行模式转换的多模式无障碍MAS，以帮助有障碍的用户将数据转换成易于理解的形式。", "innovation": "本文介绍了一种新的多模式无障碍MAS系统——MATE。MATE系统能够根据用户的需要进行模式转换，例如，如果用户视力不佳，无法正常接收图像信息，MATE会将图像转换为语音描述。MATE系统不仅能够应用于多种领域（如医疗保健），并且具有高度的灵活性和兼容性，能够适应不同的需求，且能够保护用户数据的隐私和安全。此外，MATE还将机构技术（如数字医疗服务）有效集成，在线实时提供用户支持。MATE还引入了一个名为ModCon-Task-Identifier的模型，能够从用户输入中精确提取出所需要的模式转换任务，实验表明MATE在这一领域具有显著优势，能够更好地完成相关任务。", "conclusion": "MATE系统为用户提供了灵活多样的无障碍功能，能够根据不同场景和用户需求进行模式转化，并且保证了用户数据的安全。ModCon-Task-Identifier模型则通过高效的模式转换任务识别，确保了精准的支持。作者承诺将代码和数据公开，供研究者进一步参考和利用。"}
{"llm_update_time": "2025-06-25 09:13:50", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19549", "html_url": "https://arxiv.org/abs/2506.19549", "title": "RCStat: Transformer中使用相对语境化的一种统计框架", "title_en": "RCStat: A Statistical Framework for using Relative Contextualization in Transformers", "authors": "Debabrata Mahapatra,Shubham Agarwal,Apoorv Saxena,Subrata Mitra", "background": "先前关于自动回归变压器中输入令牌重要性的工作依赖于经过Softmax归一化的注意力权重，这掩盖了预Softmax查询-键候选值的丰富结构。本研究提出了RCStat，这是一种统计框架，通过相对语境化（RC）利用原始注意力候选值，RC是一种衡量令牌片段之间上下文对齐程度的随机变量，并推导出RC的高效上界。这一框架展示了两种应用：（i）键值压缩，其中基于RC的阈值驱动自适应键值清除，能够在保持质量损失最小的情况下显著降低缓存大小；（ii）归因分析，其中RC提供了比Softmax之后方法更高的忠实度的令牌、句子和块级解释。", "innovation": "RCStat框架利用原始注意力候选值并通过相对语境化（RC）技术推导出高效的RC上界，这是一种衡量令牌片段之间上下文对齐程度的随机变量。它提出了一种新的方法来处理自动回归变压器中的输入令牌重要性，并成功应用于键值压缩和归因分析，分别通过自适应清除策略和提供更忠实的解释来提升效果。", "conclusion": "RCStat在多项基准测试中取得了显著的实验增益，实现了最先进的压缩和归因性能，无需重新训练模型。"}
{"llm_update_time": "2025-06-25 09:13:51", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19469", "html_url": "https://arxiv.org/abs/2506.19469", "title": "Surgery-R1: 通过强化学习提升手术场景理解中的推理多模态大型语言模型", "title_en": "Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning", "authors": "Pengfei Hao,Shuaibo Li,Hongqiu Wang,Zhizhuo Kou,Junhang Zhang,Guang Yang,Lei Zhu", "background": "近年来，手术场景理解领域取得了显著进展，特别是在机器手术中的视觉问答定位任务（Surgical-VQLA）。但现有的Surgical-VQLA模型在手术场景中的推理能力和可解释性不足，这限制了它们在临床应用中的可靠性和潜力。为了应对这一问题，受到可推理多模态大型语言模型（MLLMs）发展的启发，我们首先构建了Surgery-R1-54k数据集，并在此基础上提出了首个用于Surgical-VQLA的可推理多模态大型语言模型（Surgery-R1）。Surgery-R1设计了两阶段微调机制，通过监督微调（SFT）和强化微调（RFT）使基本的多模态大型语言模型具备复杂推理能力。为了在RFT中有效并高质量地设计规则奖励机制，我们设计了多模态一致性奖励机制，以减轻手术场景中可能产生的位置错觉。实验结果表明，Surgery-R1在Surgical-VQLA任务和广泛使用的多模态大型语言模型中均优于其他现有最先进的模型（SOTA模型），验证了其推理能力以及所采用方法的有效性。代码和数据集可以在此获得：this https URL", "innovation": "我们构建了Surgery-R1-54k数据集，首次提出了用于Surgical-VQLA的可推理多模态大型语言模型（Surgery-R1），并设计了两阶段微调机制和多模态一致性奖励机制，提升了MLLM在手术场景下的推理能力和可靠性，为Surgical-VQLA任务带来了新的进展。", "conclusion": "Surgery-R1在Surgical-VQLA任务和广泛使用的多模态大型语言模型中均优于其他现有最先进的模型，验证了其推理能力和所采用方法的有效性。"}
{"llm_update_time": "2025-06-25 09:13:55", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19531", "html_url": "https://arxiv.org/abs/2506.19531", "title": "ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation", "title_en": "ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation", "authors": "Mubashara Rehman,Niki Martinel,Michele Avanzo,Riccardo Spizzo,Christian Micheloni", "background": "在千伏级CT（kVCT）图像中存在伪影，这会影响临床决策。为了减轻伪影并改善图像质量，该研究提出了一个深度学习框架用于金属伪影减少（MAR）以及kVCT到兆伏级CT（MVCT）的领域转换。传统的MAR方法通常无法同时保持图像质量或显著减少伪影，且无法有效对准不同CT类型的图像特性。", "innovation": "提出的框架ReMAR-DS利用增强特征归一化的方法，采用编码解码架构，减少伪影的同时保留解剖结构。这种方法通过输注从编码块中重新归一化的特征，使模型能够专注于相关空间区域（例如有伪影的区域）以及显示各种通道的关键特征（例如解剖结构），因此可以改善伪影破坏区域的重建效果。与传统的MAR方法不同，该方法可以填补高分辨率kVCT与抗伪影MVCT之间的差异，从而增强放射治疗计划的质量，生成近似MVCT质量的重建结果，通过定性和定量评估进行验证。", "conclusion": "临床应用中，ReMAR-DS框架使得肿瘤学家可以仅依赖kVCT扫描就可做出准确的诊断决策，减少重复的高剂量MVCT扫描次数，从而降低了癌症患者的辐射暴露。"}
{"llm_update_time": "2025-06-25 09:13:56", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19486", "html_url": "https://arxiv.org/abs/2506.19486", "title": "Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy", "title_en": "Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy", "authors": "Zhihao Sui,Liang Hu,Jian Cao,Dora D. Liu,Usman Naseem,Zhongyuan Lai,Qi Zhang", "background": "尽管MU技术取得了快速进步，其潜在的隐私漏洞仍然未被充分研究，可能通过泄露原本未被学习的信息而导致隐私泄露风险。现有的MU攻击研究需要访问包含隐私数据的原始模型，这违背了MU保护隐私的核心目标。因此，研究者们需要探索如何在不访问原始模型的情况下回忆起未学习数据的类成员身份。", "innovation": "本文提出了一个新的会员回忆攻击（MRA）框架，该框架采用教师-学生知识蒸馏架构，利用未学习模型（ULMs）作为含噪标签提供者，将知识转移到学生模型中。这就将MU问题转化为有噪声标签的学习问题，以推断忘记实例的正确标签。", "conclusion": "实验结果表明，所提出的MRA策略在恢复未学习实例的类成员身份方面具有高效率。因此，我们的研究和评估为未来关于MU漏洞的研究提供了基准。"}
{"llm_update_time": "2025-06-25 09:13:56", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19552", "html_url": "https://arxiv.org/abs/2506.19552", "title": "通用方法成就卓越的特定领域基础模型：一项胎儿超声波研究", "title_en": "General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound", "authors": "Jakob Ambsdorf,Asbjørn Munk,Sebastian Llambias,Anders Nymark Christensen,Kamil Mikolaj,Randall Balestriero,Martin Tolsgaard,Aasa Feragen,Mads Nielsen", "background": "研究者们面对大型未标记医学数据集，需要解答两个问题：是否应尝试在医学数据上预训练自定义基础模型，还是从现有的通用模型进行迁移学习？如果需要预训练自定义模型，新的方法是否是必要的？本文通过在大区域胎儿超声波数据集上预训练基础模型，对这两个问题进行了探讨。该数据集包含200万张图像，并采用了已有的DINOv2方法进行预训练，实现了三个胎儿超声波数据集上三项任务的最新成果。结果表明，预训练在特定数据上的效果优于在自然图像数据上的扩展，并且计算机视觉中的有效方法使得预训练特定领域基础模型变得更加可行，无需调整超参数和方法适应性。\n", "innovation": "通过使用DINOv2方法进行预训练，模型在三个不同国家的胎儿超声波数据集上取得了最新的成绩。结果显示，在特定医学数据上的预训练是有价值的，即便小型模型在较少的数据上进行训练。计算机视觉中的良好方法使得预训练特定医学领域基础模型变得可行，无需对超参数进行调整和方法上的适应。\n", "conclusion": "文章指出，在常见计算资源限制下，应避免过度追求方法上的创新，而更应该重视使用已有有效的计算机视觉方法来进行特定医学领域的基础模型预训练。"}
{"llm_update_time": "2025-06-25 09:13:59", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19567", "html_url": "https://arxiv.org/abs/2506.19567", "title": "FAF：一种用于少量数据时间序列预测的功能适应性框架", "title_en": "FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting", "authors": "Pengpeng Ouyang,Dong Chen,Tong Yang,Shuo Feng,Zhao Jin,Mingliang Xu", "background": "在不同城市推出新产品等场景中，经常遇到多任务和少样本的时间序列预测任务。传统的时间序列预测方法由于忽视了不同任务之间的一般性和特定性特征，导致缺乏足够的历史数据支持，因此效果不佳。对于这一挑战，本文提出了一种功能自适应时间序列预测框架（FAF），它由三个关键模块构成：通用知识模块（GKM）、任务特定模块（TSM）和排序模块（RM）。", "innovation": "FAF在训练阶段通过元学习机制更新通用知识模块，使其能够提取相关任务之间的一般特征。任务特定模块通过多种功能区域学习不同任务的特定特征，以捕捉多样化的局部动态。在测试阶段，排序模块根据输入序列特征动态选择与GKM结合的最相关功能区域，实现精准的预测。该设计使得FAF即使在稀疏的历史观察下也能实现稳健和个性化的预测。实验结果表明，FAF在五个不同的真实数据集上表现出色，特别是在CO2排放数据集上比最好的基线iTransformer的性能提高了41.81%。", "conclusion": "与现有多种时间序列预测方法相比，FAF在少样本时间序列预测设置下的表现更加出色，验证了该框架的有效性和优越性。"}
{"llm_update_time": "2025-06-25 09:14:02", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19571", "html_url": "https://arxiv.org/abs/2506.19571", "title": "机器翻译评价是否已达到人类水平？人类参考与进步的局限性", "title_en": "Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress", "authors": "Lorenzo Proietti,Stefano Perrella,Roberto Navigli", "background": "在机器翻译（MT）评估中，评价指标的表现是基于其与人类判断的一致性进行评估的。近年来，自动评价指标与人类判断的一致性越来越高。因此，为了更清楚地了解评价指标的表现并建立上限，本文引入了人类基线进行MT元评价，即对评价指标能力的评估。研究结果显示，人类注释员并不总是优于自动评价指标，当前最先进的评价指标有时会与人类基准相匹敌或更优。尽管这些发现表明人类与机器评价指标达到了平齐，但作者也讨论了谨慎的原因。最后，研究探讨了这些结果在研究领域的更广泛影响，提出了能否可靠地衡量在MT评价领域的进步的问题。本文旨在揭示我们在衡量领域进步方面能力的局限性，探讨我们相信对整个MT评价社区至关重要的议题。", "innovation": "引入人类基准进行MT元评价，以更全面地评估评价指标的能力，并探讨评价指标和人类注释员之间的相对性能。尽管目前使用的最先进的自动评价指标在某些情况下可以达到甚至超过人类基线，但作者讨论了一些需要谨慎的原因。", "conclusion": "研究所展示的证据表明，尽管可以实现人类评价指标的平齐，但在MT评价领域进步的可靠度仍然存在问题。本文旨在揭示我们在量化领域进步方面能力的局限性，同时促进对这一具有重要意义问题的讨论。"}
{"llm_update_time": "2025-06-25 09:14:02", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19563", "html_url": "https://arxiv.org/abs/2506.19563", "title": "PrivacyXray: 通过语义一致性和概率确定性检测LLMs中的隐私泄露", "title_en": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty", "authors": "Jinwen He,Yiyang Lu,Zijin Lin,Kai Chen,Yue Zhao", "background": "大型语言模型（LLMs）被广泛应用于包含医疗保健、金融和法律服务在内的敏感领域，这引发了对推理过程中潜在私人信息泄露的担忧。隐私提取攻击，如监狱越狱，通过构造输入使模型泄露敏感信息，但也无法验证提取的私人信息是否准确，因为缺乏用于交叉验证的公开数据集，使得在推理中检测私人信息存在关键缺口。", "innovation": "提出了一种名为PrivacyXray的新框架，用于通过分析LLMs的内部状态检测隐私泄露。通过实验证明，它在五个LLMs上的平均准确率为92.69%，比最先进的方法提高了20.06%的准确率。在没有公开私人数据集的情况下，PrivacyXray通过合成现实中的私人数据并基于LLMs内部状态的检测机制实现了这一点，突显出其在实际应用中的稳定性和实际应用价值。它解决了私人信息检测的关键挑战，即缺少开源私人数据集的问题，并消除了对外部数据校验的依赖。", "conclusion": "PrivacyXray通过分析LLMs内部状态，使用语义一致性和概率确定性检测隐私泄露，并通过对抗现有方法取得了显著的性能提升。实验结果证明其在多个LLMs上的稳定性和实用性，可在实际应用中有效检测隐私泄露。"}
{"llm_update_time": "2025-06-25 09:14:02", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19597", "html_url": "https://arxiv.org/abs/2506.19597", "title": "机器人建设中的挑战", "title_en": "Robotics Under Construction: Challenges on Job Sites", "authors": "Haruki Uchiito,Akhilesh Bhat,Koji Kusaka,Xiaoya Zhang,Hiraku Kinjo,Honoka Uehara,Motoki Koyama,Shinji Natsume", "background": "随着建筑行业面临日益严重的劳动力短缺和生产力停滞，自动化成为了可持续基础设施开发的必要手段。", "innovation": "介绍了基于CD110R-3履带载体的自主载荷运输系统，该系统整合了自主导航、车队管理和基于GNSS的定位技术，旨在推动施工场地中的无人化作业。此外，已经开始对外部传感器感知和测绘系统的基础研究，初步结果指出了导航在动态地形中的挑战、施工特定条件下的环境感知问题以及传感器布置的优化问题，以提高自主性和效率。", "conclusion": "展望未来，设想了一个协作自主代理动态适应现场条件、优化工作流程并减少人工干预的建筑生态系统。该论文为未来由机器人驱动的建筑自动化提供了基础见解，并指出了关键的进一步技术开发领域。"}
{"llm_update_time": "2025-06-25 09:14:03", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19578", "html_url": "https://arxiv.org/abs/2506.19578", "title": "迈向全球分布式计算基础设施的自省动态模型", "title_en": "Towards an Introspective Dynamic Model of Globally Distributed Computing Infrastructures", "authors": "Ozgur O. Kilic,David K. Park,Yihui Ren,Tatiana Korchuganova,Sairam Sri Vatsavai,Joseph Boudreau,Tasnuva Chowdhury,Shengyu Feng,Raees Khan,Jaehyung Kim,Scott Klasky,Tadashi Maeno,Paul Nilsson,Verena Ingrid Martinez Outschoorn,Norbert Podhorszki,Frédéric Suter,Wei Yang,Yiming Yang,Shinjae Yoo,Alexei Klimentov,Adolfy Hoisie", "background": "大型科学研究合作项目，如ATLAS、Belle II、CMS、DUNE等，涉及数百个研究机构和数千名研究人员，分布在全球各地。这些实验产生的数据量以字节为单位，未来预计会达到艾字节。为了应对这些庞大的计算和存储需求，集中式的 workflow 和数据管理系统被实施。然而，数据放置和负载分配的决策往往是独立且基于经验的方法。缺乏能够快速可靠地评估和改进替代方案的自省型动态模型是一个重要的障碍。这项研究旨在通过使用实际数据开发这样的互动系统来应对这一挑战。通过分析来自PanDA workflow管理系统的作业执行记录，确定了关键性能指标，如队列时间、错误率和远程数据访问程度。该数据集涵盖了五个月的活动。", "innovation": "通过开发一个自省型动态模型，该模型利用真实的作业执行记录数据来评估和改进全球分布式计算基础设施的数据放置和负载分配策略。此外，创建了一个生成性AI模型来模拟负载的时间序列数据，这些数据结合了可见特征（如类别、事件数量和提交组）以及隐藏特征（如来自现有PanDA记录和计算站点能力推导出的总计算负载），这些隐藏特征对队列时间和数据传输有影响，并且通常对无论是基于经验的还是基于AI的作业分配者都是不可见的。", "conclusion": "这种自省动态模型和生成性AI模型的开发将有助于更有效地管理和优化全球分布式计算基础设施中的数据放置和负载分配策略，进而提高计算资源的利用效率和作业执行的性能。"}
{"llm_update_time": "2025-06-25 09:14:07", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19579", "html_url": "https://arxiv.org/abs/2506.19579", "title": "真假难辨，机器人能分辨吗？——评估 embodied 视觉-语言模型在真实和3D打印物体上的表现", "title_en": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects", "authors": "Federico Tavella,Kathryn Mearns,Angelo Cangelosi", "background": "机器人的场景理解越来越多地依赖于视觉-语言模型（VLMs）来生成对环境的自然语言描述。本研究关注机器人通过配备RGB相机的手臂捕捉桌面场景时，不同图像生成模型在场景描述中的表现。研究对比了基于单一视角和多视角的场景描述策略，以及真实物体和3D打印物体的识别差异。研究通过定量评估对象识别准确度、描述完整性和自然度来比较不同模型的表现。实验结果揭示了视觉-语言模型在识别常见物体方面的潜力，同时也表明它们在处理新物体时的能力有限。", "innovation": "本研究通过实验证明了视觉-语言模型在识别物体时的效果，并比较了多视角与单一视角策略的优劣，特别关注了真实物体与3D打印物体的识别差异。研究提供了关于如何适用于实际场景的基础模型部署的实用见解，特别是在实体代理中的应用。", "conclusion": "视觉-语言模型在识别常见物体方面有潜力应用于机器人情景理解中，但在处理新颖物体对象时表现不佳。研究发现为实际应用基础模型于实体代理环境中提供了一定的指导意义。"}
{"llm_update_time": "2025-06-25 09:14:07", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19599", "html_url": "https://arxiv.org/abs/2506.19599", "title": "ECCoT: 一种通过大型语言模型链思维增强有效认知的框架", "title_en": "ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model", "authors": "Zhenke Duan,Jiqun Pan,Jiani Tu,Xiaoyi Wang,Yanqing Wang", "background": "在大规模人工智能时代，大型语言模型（LLMs）在自然语言处理方面取得了显著进展。然而，它们往往缺乏透明度，生成不可靠的输出，这引起了对其可解释性的担忧。链思维（CoT）提示方法将推理结构化为逐步推理，但并非所有推理链都是有效的，错误可能导致不可靠的结论。因此，提出了ECCoT（End-to-End Cognitive Chain of Thought Validation Framework），一种评估和改进LLMs中推理链的端到端认知链条验证框架。ECCoT整合了嵌入主题模型的马可夫随机场（MRF-ETM）进行主题驱动的CoT生成，并利用因果句子BERT（CSBert）增强因果推理对齐。通过使用结构化排序统计去除无效链，ECCoT提高了可解释性，减少了偏见，并增强了基于LLM的决策的信任度。", "innovation": "ECCoT框架的创新之处包括引入ECCoT、MRF-ETM用于主题驱动的CoT生成，以及CSBert用于因果推理增强。", "conclusion": "ECCoT通过使用MRF-ETM和CSBert提升了大型语言模型中推理链的有效性和可解释性，减少了偏见，增强了基于LLM的决策的信任度。"}
{"llm_update_time": "2025-06-25 09:14:07", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19591", "html_url": "https://arxiv.org/abs/2506.19591", "title": "基于Vision Transformer的时间序列图像重建在云填充应用中的研究", "title_en": "Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications", "authors": "Lujun Li,Yiqun Wang,Radu State", "background": "多光谱影像（MSI）中的云覆盖给作物早期测绘带来了重大挑战，因为这会导致缺失或损坏的光谱信息。虽然合成孔径雷达（SAR）数据不受云干扰影响，可以提供补充解决方案，但它缺乏足够的光谱细节以实现精确的作物测绘。为了应对这些挑战，本文提出了一种名为Time-series MSI Image Reconstruction using Vision Transformer (ViT)的创新框架，该框架通过利用MSI的时间连贯性和SAR数据的注意机制中的补充信息，在云覆盖区域重建MSI数据，从而提高了云覆盖区域MSI图像的重建效果。", "innovation": "本文提出了一种新的时序多光谱影像重建框架（Time-series MSI Image Reconstruction using Vision Transformer, ViT），该框架通过结合不同时间节点的多光谱影像以及合成孔径雷达数据，克服了传统方法在云覆盖区域重建多光谱影像的不足。该方法利用Vision Transformer中注意力机制的优势，有效利用时间序列中的连贯性，实现了在云覆盖区域多光谱影像的高质量重建。这种方法显著优于其他非时序MSI和SAR或仅时序MSI的方法，提高了云覆盖区域的光谱信息恢复能力，从而增强了作物早期测绘的精确性。", "conclusion": "通过系统的重建评估指标实验，本文的时间序列ViT框架在云覆盖区域重建多光谱影像方面表现出显著的性能优势。证明了结合MSI时间和SAR数据的优势，克服了云覆盖带来的挑战，为作物早期测绘提供了更准确的解决方案。"}
{"llm_update_time": "2025-06-25 09:14:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19621", "html_url": "https://arxiv.org/abs/2506.19621", "title": "VideoPCDNet：基于相位相关网络的视频拆解与预测", "title_en": "VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks", "authors": "Noel José Rodrigues Vicente,Enrique Lehner,Angel Villar-Corrales,Jan Nogga,Sven Behnke", "background": "在动态环境中，理解与预测视频内容对于规划和推理至关重要。尽管已有所进展，但对象表示和动态的无监督学习仍然具有挑战性。VideoPCDNet提供了一种基于无监督框架的对象中心视频拆解与预测方法，通过频率域的相位相关技术递归解析视频，并将对象表示为学习到的对象原型的变换版本，实现了准确且可解释的对象跟踪。通过结合频率域运算和轻量级学习模块，VideoPCDNet能够实现准确的无监督对象跟踪和未来视频帧的预测。", "innovation": "VideoPCDNet采用频率域相位相关技术递归地对视频进行分解，将学习到的对象原型变换为对象表示；通过结合频率域操作和轻量级学习模块，在无监督的情况下精确地实现场景中对象的跟踪和未来帧的预测，实现了可解释的可学习的对象和动态表示。该模型在多个合成数据集上对比多个对象中心的基础模型时，显示出更优异的表现。", "conclusion": "本文展示了VideoPCDNet在无监督对象跟踪和预测任务上的优势，尤其是在合成数据集上，超越了其他多种对象中心的基本模型。通过这种方法，学习得到了可解释的对象和运动的表示，构建了一个强大的框架用于动态环境中的视频理解和预测。"}
{"llm_update_time": "2025-06-25 09:14:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19561", "html_url": "https://arxiv.org/abs/2506.19561", "title": "MambaOutRS：一种用于遥感图像分类的混合CNN与傅里叶架构", "title_en": "MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification", "authors": "Minjong Cheon,Changbae Mun", "background": "深度学习在视觉任务中的最新进展催生了如Mamba等状态空间模型（SSMs），这些模型以其线性可扩展性而闻名。然而，当应用于2D视觉数据时，这些模型往往需要复杂的修改以增强适应性，这可能会影响其效率。", "innovation": "本文引入了MambaOutRS，这是一种新颖的混合卷积结构，用于遥感图像分类，它重新评估了递归SSMs的必要性。MambaOutRS采用了堆叠的Gated CNN模块进行局部特征提取，并引入了一种新颖的傅里叶滤波门（FFG）模块，以高效地捕捉全局上下文信息。MambaOutRS在UC Merced、AID、NWPU-RESISC45和EuroSAT等具有挑战性的遥感数据集上进行了广泛评估，并在这些基准上实现了最先进的（SOTA）性能，特别是在参数量较少的情况下表现尤为突出。此项研究还通过消融研究证明了傅里叶滤波门对增强模型全局空间模式捕捉能力的重要性，进而提高了模型的鲁棒性和准确性。", "conclusion": "研究表明，递归SSMs的复杂性可以通过精心结合门控卷积进行空间混合和基于频率的门对谱全局上下文进行有效的替代。因此，MambaOutRS提供了一种高效且具有竞争力的框架，用于开发遥感及其他视觉领域的高性能深度学习模型，特别是在计算效率至关重要的场景中。"}
{"llm_update_time": "2025-06-25 09:14:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19652", "html_url": "https://arxiv.org/abs/2506.19652", "title": "超越LLMs的定制对话：基于RL的对话管理器", "title_en": "Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager", "authors": "Lucie Galland,Catherine Pelachaud,Florian Pecune", "background": "这项研究提出了一种新的框架，将大型语言模型（LLMs）与基于强化学习（RL）的对话管理器相结合，专门用于具有特定目标的开放式对话。通过利用分层强化学习来建模对话的结构阶段，并使用元学习以提高适应性，使智能对话系统能够在有限的数据下学习、在对话阶段之间流畅转换，并个性化回应不同患者的需求", "innovation": "该研究提出了一种创新的框架，通过结合LLMs和RL来实现开放式对话，特别是在行为改变方面目标明确的动机访谈中表现出色，表明通过强化学习可以对LLMs进行预训练，使其能够创造具有特定目标的开放式对话系统，提升模型在不同用户之间的适应性和效率", "conclusion": "该研究表明提出的对话管理器在奖励上优于最先进的LLM基准，表明经过强化学习预训练的LLMs能够创建具有特定目标的开放式对话系统，具有很大的应用价值"}
{"llm_update_time": "2025-06-25 09:14:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19633", "html_url": "https://arxiv.org/abs/2506.19633", "title": "通过潜在平均编码进行分层时间序列预测", "title_en": "Hierarchical Time Series Forecasting Via Latent Mean Encoding", "authors": "Alessandro Salatiello,Stefan Birr,Manuel Kunz", "background": "在多个商业应用中，准确预测目标变量在粗略和精细时间尺度上的行为对于利润优化决策至关重要，但这一问题在时间层次预测中仍然是一个开放的研究问题。现有方法难以在同一目标时间层次上提供准确且一致的预测。", "innovation": "本文提出了一个创新的分层架构，该架构通过利用专门预测不同时间聚合级别的模块来解决这个问题。该架构通过在其隐藏层中学习编码目标变量的平均行为，实现了跨目标时间层次的准确且一致的预测。实验结果表明，该架构在具有挑战性的现实世界M5数据集上优于现有的方法，如TSMixer模型。", "conclusion": "本文提出了一种新的分层架构，通过潜在平均编码技术，在不同时间尺度上实现了目标变量预测的准确性和一致性，验证结果表明该方法在现实世界数据集上的表现优于现有方法。"}
{"llm_update_time": "2025-06-25 09:14:11", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19630", "html_url": "https://arxiv.org/abs/2506.19630", "title": "为什么不确定性校准对可靠性的扰动驱动解释至关重要", "title_en": "Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations", "authors": "Thomas Decker,Volker Tresp,Florian Buettner", "background": "扰动驱动的解释被广泛用于增强现代机器学习模型的透明度。然而，当使用特定的扰动时，模型的实际行为往往未知，这会影响这些解释的可靠性。论文研究了不确定性校准（即模型信心与实际准确性的对齐）与其对扰动驱动解释的影响。研究发现，在解释特定扰动下，模型常常产生不准确的概率估计，这直接削弱了解释的质量，因此考察了如何改进这一问题的方法。", "innovation": "提出了ReCalX，一种新的方法，可重新校准模型以改善扰动驱动的解释，同时保持原始预测不变。通过在流行计算机视觉模型上的实验，证明了我们的校准策略可以产生与人类感知和实际对象位置更为一致的解释，从而提高了解释的可靠性。", "conclusion": "不确定性校准对于提升扰动驱动解释的可靠性至关重要，ReCalX方法能够有效提高解释的质量，同时不影响原始预测的准确性。"}
{"llm_update_time": "2025-06-25 09:14:13", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19539", "html_url": "https://arxiv.org/abs/2506.19539", "title": "Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language", "title_en": "Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language", "authors": "Julian Fragner,Christian Macho,Bernhard Dieber,Martin Pinzger", "background": "日志文件为企业软件应用和数据中心检测和诊断问题提供了有价值的信息。近年来，开发了多种日志分析工具和平台，通常使用正则表达式（RegExes）来过滤和提取日志中的信息。当前的商用日志分析平台提供了针对特定领域的语言，如Grok或Dynatrace模式语言（DPL），用于日志解析。然而，用户在迁移到这些平台时需要手动将他们的RegExes转换为新的模式语言，这代价高昂且容易出错。因此，现有的迁移过程存在一定的挑战和局限性。", "innovation": "本文介绍了Reptile，它结合了基于规则的方法将RegEx转换为DPL模式，并在完全转换不可能的情况下采用尽力而为的方法。此外，Reptile还集成了GPT-4以优化获得的DPL模式。实验结果显示，Reptile安全地转换了946个RegEx中73.7%的模式，并在23个真实世界的RegEx中优化模式，得出的F1分数和MCC均超过0.91。这些结果对计划迁移到现代日志分析平台的企业具有重要意义。", "conclusion": "实验表明，Reptile安全地转换了73.7%的RegEx，并在优化DPL模式方面达到了较高的性能，为计划迁移到现代日志分析平台的企业提供了重要的实践价值。"}
{"llm_update_time": "2025-06-25 09:14:15", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19642", "html_url": "https://arxiv.org/abs/2506.19642", "title": "receptron是以非线性阈值逻辑门为基础，在模拟输入上具有固有的多维选择性能力", "title_en": "The receptron is a nonlinear threshold logic gate with intrinsic multi-dimensional selective capabilities for analog inputs", "authors": "B. Paroli,F. Borghi,M.A.C. Potenza,P. Milani", "background": "阈值逻辑门(TLGs)作为具备分类能力的人工生物神经元，基于线性预测函数结合一组权重与特征向量。然而，TLGs的线性特性限制了其分类能力，需要使用网络来完成复杂任务。为了解决这个问题，研究提出了一种称为receptron的TLG模型的泛化形式，具有输入依赖的权重函数，这使得单个单位也能实现显著增强的分类性能。进一步的研究表明，当输入向量位于3D空间中的立方体区域内时，接收器能够对模拟输入表现出固有的选择性激活特性。模型还可以扩展到多维情况，适用于多维应用。", "innovation": "接收器(receptron)模型通过引入非线性输入依赖的权重函数，显著提升了单个单位的分类性能，并且在三维空间内对于模拟输入展现出固有的多维选择性激活特性。", "conclusion": "研究结果表明，基于接收器的网络可以作为一种新类别的设备，能够有效地管理大量模拟输入，适用于边缘应用，无需复杂的训练即可实现高选择性和分类能力。"}
{"llm_update_time": "2025-06-25 09:14:20", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19753", "html_url": "https://arxiv.org/abs/2506.19753", "title": "使用RNN、变换器和大规模语言模型进行阿拉伯方言分类：一项比较分析", "title_en": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis", "authors": "Omar A.Essameldin,Ali O.Elbeih,Wael H.Gomaa,Wael F.Elsersy", "background": "阿拉伯语是世界上最受欢迎的语言之一，拥有22个国家的众多方言变体。本文研究了QADI数据集中的18种阿拉伯方言的分类问题。", "innovation": "本文创建并测试了RNN模型、变换器模型以及通过提示工程的大规模语言模型（LLMs）。其中，MARBERTv2表现最佳，准确率为65%，F1分为64%。通过使用最先进的预处理技术与最新的NLP模型，本文识别了阿拉伯方言识别中最重要的语言问题。", "conclusion": "研究结果支持个性化聊天机器人、社交媒体监控以及阿拉伯社区更大的可访问性的应用。"}
{"llm_update_time": "2025-06-25 09:14:21", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19697", "html_url": "https://arxiv.org/abs/2506.19697", "title": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models", "title_en": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models", "authors": "Jungwoo Park,Taewhoo Lee,Chanwoong Yoon,Hyeon Hwang,Jaewoo Kang", "background": "大型语言模型（LLMs）中的极端激活异常会在量化性能方面造成严重负面影响，阻碍其在设备端的高效部署。虽然已经识别出通道操作和自适应梯度缩放是主要原因，但实际缓解措施仍然具有挑战性。现有的缓解方法主要依赖于事后（post-hoc）的处理，没有从根本上解决极端激活问题。论文提出了Outlier-Safe Pre-Training (OSP)，一种实践指南，旨在主动防止极端激活的形成。OSP结合了三个关键创新：消除特权基础的Muon优化器、单一尺度RMSNorm防止通道级别的放大效应，以及可学习的嵌入投影，重新分配嵌入矩阵引发的激活幅度。OSP在大规模生产环境下进行了验证。", "innovation": "提出了Outlier-Safe Pre-Training (OSP) 方法，结合了三个关键创新点：(1) Muon优化器，同时消除特权基准并保持训练效率；(2) 单一尺度RMSNorm，防止通道级别的放大效应；(3) 可学习的嵌入投影，重新分配嵌入矩阵引发的激活幅度。这些创新旨在防止大型语言模型中的极端激活异常，并提高了4位量化下的性能表现。", "conclusion": "通过在1.4B参数模型上使用OSP方法，首次实现了大规模生产环境下无极端激活异常的LLMs。经过严格的4位量化后，OSP模型在10个基准测试中平均得分为35.7，相较于Adam训练模型的26.5分表现更优，仅仅增加了2%的训练开销。模型显示出了几乎为零的超额峰度（0.04），对比标准模型高达1818.56的极端值，OSP从根本上改变了LLMs的量化行为，证明了极端激活并非LLMs的固有问题。"}
{"llm_update_time": "2025-06-25 09:14:22", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19732", "html_url": "https://arxiv.org/abs/2506.19732", "title": "深度学习中的角色是什么？基于博弈论的多层次神经元功能多维归因", "title_en": "Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units", "authors": "Shrey Dixit,Kayson Fakhar,Fatemeh Hadaeghi,Patrick Mineault,Konrad P. Kording,Claus C. Hilgetag", "background": "目前，神经网络可以生成数十亿个参数的文本、图像和语音，这引起了对了解每个神经单元如何贡献这些高维输出的兴趣。现有可解释AI方法，如SHAP，可以对输入进行赋重要性，但无法量化数千个输出像素、标记或logits中神经单元的贡献。本文通过引入多扰动Shapley值分析（MSA）填补了这一空白，这是一种具有普适性的博弈论框架，通过对多个神经单元的系统性损伤得出神经单元贡献映射，这些映射与模型输出的维度完全一致。这种方法被应用于从小型多层感知机到具有560亿参数的Mixtral-8x7B以及生成对抗网络（GAN）等多种规模的网络，展示了正则化如何集中在少数几个关键点，并揭示了语言模型中存在一定数量的语言特定专家，同时揭示了GAN中像素生成等级的倒置。", "innovation": "MSA是一种具有普适性的博弈论框架，通过对多个神经单元的系统性损伤，生成与模型输出维度完全一致的单元贡献映射。该方法被应用于多种规模的网络，从多层感知机到具有560亿参数的Mixtral-8x7B以及生成对抗网络（GAN）。MSA揭示了正则化如何集中在少数几个关键点，展示了语言模型中存在语言特定专家，并揭示了GAN中像素生成等级的倒置。", "conclusion": "MSA作为一种强大的方法，能够解释、编辑和压缩深度神经网络，展示了其在理解、编辑和压缩深层神经网络方面的强大潜力。"}
{"llm_update_time": "2025-06-25 09:14:22", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19683", "html_url": "https://arxiv.org/abs/2506.19683", "title": "超声图像解释及扫描指南的语义场景图", "title_en": "Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance", "authors": "Xuesong Li,Dianye Huang,Yameng Zhang,Nassir Navab,Zhongliang Jiang", "background": "理解医学超声成像仍然是一个长期存在的挑战，因为成像和获取参数的显著差异导致了视觉上的巨大变异性。近年来，在大规模语言模型（LLMs）的进步中，已经使用LLMs来自动生成面向临床医生且富含生理知识的术语丰富的总结。然而，对非专家用户，例如在床旁护理环境中，对超声解释准确性和基本扫描指导的需求尚未受到探索。因此，为了提高超声成像的可解释性和使用便利性，研究中首次将场景图（SG）用于超声图像，以解释图像内容并为普通用户提供扫描指导。通过Transformer基线方法首次计算超声SG，省去了明确的目标检测的需要。将用户查询用于进一步通过LLMs强化抽象的SG表示，从而生成更具可理解性的图像解释。超声SG的预测分析能够向当前成像视图中缺失的解剖结构指导扫描，帮助普通用户实现更为标准和完整的解剖检查。本研究在左、右颈部包括锁骨下静脉和甲状腺区域的图像上，对5名志愿者进行了验证，结果表明该方法具有最大程度地普及超声成像识读和使用的潜力。", "innovation": "首次提出了用于超声图像解释和扫描指导的场景图方法，通过Transformer基线方法自动计算超声SG，消除明确的目标检测，以用户查询为指引，进一步通过LLMs强化抽象的SG表示，生成更具可理解性的图像解释，同时能指导超声扫描，弥补当前成像视图中缺失的解剖结构，帮助普通用户实现更为标准和完整的解剖检查。该研究在床旁护理环境中首次探索了超声解释准确性和基本扫描指导的需求，提升超声成像的可解释性和使用便利性，并通过实际图像验证了该方法的有效性。", "conclusion": "基于超声SG的图像解释和扫描指导方法通过简化技术流程和增强解释性，展示了最大化普及超声成像技术、提高其可解读性和易用性的潜力。这一方法在床旁护理环境中具有重要意义，能够帮助非专家用户提高超声成像的准确性和使用范围。"}
{"llm_update_time": "2025-06-25 09:14:22", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19726", "html_url": "https://arxiv.org/abs/2506.19726", "title": "几何感知变分推断：基于方向权重不确定性稳健且自适应的正则化方法", "title_en": "Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty", "authors": "Carlos Stein Brito", "background": "深度神经网络需要对不确定性进行合理的量化，但现有的变分推理方法通常使用权重空间中的各向同性高斯近似，这种近似与网络内部的几何特性不匹配。文章指出这一不匹配是导致模型不确定性量化不足的原因之一。为解决这一问题，结合最近在径向-方位后验分解和球形权重约束方面的研究成果，文章提出了一种新的变分框架——集中度自适应扰动（CAP）方法，该方法直接在单位超球面上使用von Mises-Fisher分布建模权重不确定性，首次将方向统计学与神经网络中的噪声自适应正则化实践连接起来。", "innovation": "文章的关键创新点是提出了集中度自适应扰动（CAP）方法，该方法在单位超球面上使用von Mises-Fisher分布直接建模权重不确定性。CAP能够基于信息论中的均值-方差KL散度正则化项，通过解析推导将von Mises-Fisher的集中度参数与激活噪声方差连接起来，使每个层能够学习到其最优的不确定性水平，并通过一个新颖的闭形式正则化项进行优化。CAP方法减少了所需的计算开销，并能无缝集成到标准架构中，提供了一种既理论支持又实用的神经网络不确定性量化方法。", "conclusion": "CAP显著提高了CIFAR-10数据集上的模型校准度，使预期校准误差降低了5.6倍，同时提供了可解释的层间不确定性谱。该方法计算开销较小，能无缝集成到标准架构中，为深度学习中的不确定性量化提供了一种理论基础又实用的解决方案。"}
{"llm_update_time": "2025-06-25 09:14:25", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19708", "html_url": "https://arxiv.org/abs/2506.19708", "title": "使用稀疏自动编码器揭示生成图像模型中的概念盲点", "title_en": "Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders", "authors": "Matyas Bohacek,Thomas Fel,Maneesh Agrawala,Ekdeep Singh Lubana", "background": "尽管大规模数据集训练的生成图像模型在性能上表现出色，但它们经常无法生成一些看似简单的概念，如人类手或以四组形式出现的物体，这些概念在训练数据中应合理出现。这种失败模式主要是通过案例来记录，因此未知这些失败是否代表模型的偶发异常或更深层次的结构限制。本文旨在解决这一问题，通过引入一种系统的方法来识别和描述“概念盲点”——即在训练数据中存在但在生成中缺失或恶化的概念。这种方法利用稀疏自动编码器（SAEs）提取可解释的概念嵌入，从而可以定量比较真实图像和生成图像中概念的频次差异。研究团队训练了一个原型SAE（RA-SAE），基于DINOv2特征，包含32,000个概念，这是迄今为止最大的SAE，促进了概念差异的精细分析。", "innovation": "本文提出了一个系统的方法来识别和描述生成图像模型中的概念盲点。通过使用稀疏自动编码器（SAEs）提取可解释的概念嵌入，使得研究人员可以在定量比较真实图像和生成图像中概念的频次差异方面取得进展。研究团队训练了一个原型稀疏自动编码器（RA-SAE），基于DINOv2特征，包含32,000个概念，这是迄今为止最大的稀疏自动编码器，这标志着对概念差异进行精细分析的突破。应用这种方法，研究揭示了特定被抑制的概念盲点（如鸟食器、DVD碟和文档中的空白）和被夸大盲点（如木材背景纹理和 palm 树），同时在单个数据点级别还隔离了记忆艺术制品（即模型在训练中产生的高度具体的视觉模板的再现）。", "conclusion": "本文提出了一个理论基础明确的框架，通过这一框架可以系统地识别生成模型中的概念盲点。研究人员通过评估这些模型的概念忠实度与基础数据生成过程的关系，揭示了在不同生成图像模型中某些特定的概念盲点和夸张盲点。此外，还提出了通过具体示例来进一步理解概念盲点的表现形式和含义。"}
{"llm_update_time": "2025-06-25 09:14:26", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19689", "html_url": "https://arxiv.org/abs/2506.19689", "title": "在何种情况下可以为多次共轭预测重用校准集？", "title_en": "When Can We Reuse a Calibration Set for Multiple Conformal Predictions?", "authors": "A.A. Balinsky,A.D. Balinsky", "background": "可靠地量化的不确定性对于机器学习应用的信任至关重要。归纳共轭预测（ICP）提供了一种不依赖于分布的框架，用于生成具有用户指定置信水平的预测集或区间。然而，标准ICP的保证通常是边际的，并且通常需要为每次新预测提供一个新的校准集，以保持其有效性。该研究旨在通过展示如何结合e-共轭预测和Hoeffding不等式来解决这一实际限制，使得能够重复使用单个校准集，并以较高的概率保持所需的覆盖范围。", "innovation": "通过结合e-共轭预测和Hoeffding不等式，该研究提供了重复使用单个校准集的方法，并在高概率下保持所需的覆盖范围。通过对CIFAR-10数据集的研究，该研究建立了具有可量化置信度的预测集，并证明了可以在共轭预测中维持可验证的表现，同时通过减少重复校准的需求来提高其实用性。", "conclusion": "该研究通过使用Hoeffding校正和修改的Markov不等式，展示了在共轭预测中维持可验证表现的同时增强其实用性的可行性。已经公开了该工作的代码。"}
{"llm_update_time": "2025-06-25 09:14:30", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19742", "html_url": "https://arxiv.org/abs/2506.19742", "title": "NeRF-based CBCT重建需要规范化和初始化", "title_en": "NeRF-based CBCT Reconstruction needs Normalization and Initialization", "authors": "Zhuowei Xu,Han Li,Dai Sun,Zhicheng Li,Yujia Li,Qingpeng Kong,Zhiwei Cheng,Nassir Navab,S. Kevin Zhou", "background": "锥形束计算机断层扫描（CBCT）在医学成像中广泛应用，但由于X射线投影数量有限，重建问题变得病态且易产生严重伪影。基于NeRF的方法在这一问题上取得了巨大成功，但对于哈希编码器和神经网络这两部分的关键组件，它们之间的局部-全局训练不匹配是一个挑战。在每次训练步骤中，哈希编码器只使用了一部分参数，而神经网络的所有参数都参与训练，这导致了不同训练步骤生成的特征之间存在严重不一致性，进而影响了训练的稳定性和收敛速度，最终降低了重建质量。", "innovation": "本文引入了一种标准化哈希编码器，并提出了映射一致性初始化（MCI）策略。标准化哈希编码器增强了特征的连续性，解决了局部-全局优化不匹配的问题。MCI策略则利用预训练模型的全局映射特性在训练前初始化神经网络，使训练过程更稳定，加快了收敛速度，并提高了重建性能。该方法简单有效，仅需少量代码即可显著提高128个CT案例的训练效率，覆盖4个不同数据集的7个不同解剖区域。", "conclusion": "我们的研究通过提出规范化哈希编码器和映射一致性初始化策略，解决了NeRF在CBCT重建中存在的局部-全局优化不匹配问题，提高了训练效率和重建质量。"}
{"llm_update_time": "2025-06-25 09:14:30", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "开源大语言模型在数据分析中遇到困难的原因：一项系统性的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Huajun Chen,Ningyu Zhang", "background": "开源大语言模型（LLMs）在自动化数据分析任务方面表现出潜力，但它们在这些需要高度推理能力的场景中面临显著的局限性。这项研究探讨了如何增强开源LLMs的数据分析能力。通过构建一个包含多样性和真实场景的数据集，研究集中在数据理解、代码生成和战略规划这三个维度上进行评估。研究表明，战略规划的质量是决定模型性能的主要因素；交互设计和任务复杂性显著影响推理能力；数据质量比数据多样性对最优化性能有更大的影响。基于这些发现，开发了一种数据合成方法，显著提高了开源LLMs的分析推理能力。", "innovation": "研究通过构建一个多样且真实的种子数据集，评估开源LLMs在数据理解、代码生成和战略规划三个维度上的表现，并提出以数据质量优先的数据合成方法，显著提高了模型的分析推理能力。", "conclusion": "战略规划的质量在模型性能中起决定性作用；交互设计和任务复杂度显著影响推理能力；数据质量比数据多样性更重要。研究结果提供了一个改进开源LLMs数据分析能力的方法。"}
{"llm_update_time": "2025-06-25 09:14:31", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19823", "html_url": "https://arxiv.org/abs/2506.19823", "title": "个性特征控制生成性偏差", "title_en": "Persona Features Control Emergent Misalignment", "authors": "Miles Wang,Tom Dupré la Tour,Olivia Watkins,Alex Makelov,Ryan A. Chi,Samuel Miserendino,Johannes Heidecke,Tejal Patwardhan,Dan Mossing", "background": "了解语言模型如何从其训练数据迁移到更广泛的部署分布中展示行为，是AI安全领域的一个重要研究问题。Betley等人发现，对GPT-4o进行故意不安全代码的微调会导致'泛化偏差'现象，即模型对无关提示会产生刻板的恶意反应。本研究在此基础上进一步扩展，展示了泛化偏差在多样条件下的普遍存在，包括在推理模型上应用强化学习、不同合成数据集的微调以及未接受安全性训练的模型中均存在这种现象。", "innovation": "本研究采用“模型对比”方法，使用稀疏自编码器对比微调前后模型的内部表示，揭示了多种'偏差个性'特征，尤其是在激活空间中的毒素个性特征对泛化偏差的控制力最强，并可用于预测模型是否会产生此类行为。此外，研究还探讨了缓解策略，并发现仅对几个良性样本进行微调即可有效恢复对齐。", "conclusion": "研究揭示了模型微调后出现的偏差个性特征，并提出了一种基于这些特征的预测方法。通过微调几个良性样本，可以高效恢复模型的对齐状态。"}
{"llm_update_time": "2025-06-25 09:14:33", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19774", "html_url": "https://arxiv.org/abs/2506.19774", "title": "Kling-Foley：用于高质量视频到音频生成的多模态扩散变换器", "title_en": "Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation", "authors": "Jun Wang,Xijuan Zeng,Chunyu Qiang,Ruilong Chen,Shiyao Wang,Le Wang,Wangjing Zhou,Pengfei Cai,Jiahui Zhao,Nan Li,Zihan Li,Yuzhe Liang,Xiaopeng Wang,Haorui Zheng,Ming Wen,Kang Yin,Yiran Wang,Nan Li,Feng Deng,Liang Dong,Chen Zhang,Di Zhang,Kun Gai", "background": "当前视频到音频生成模型在高质量音频合成与视频内容同步方面存在不足，现有模型难以同时实现高精度的语义对齐和音频视频同步。此外，现有的开源基准数据集在音频类型和标注方面不完善，影响模型训练效果和泛化能力。因此，需要开发一种既能提高音频质量又能改善视频与音频同步效果的新型多模态生成模型；同时补充现有数据集的不足，提供更全面的数据集支持模型训练和验证。", "innovation": "提出的Kling-Foley模型引入了多模态扩散变换器来建模视频、音频和文本模态之间的交互，结合了视觉语义表示模块和音频-视觉同步模块，提升对齐能力；采用了一种通用的潜在音频编解码器，能在不同场景中（如音效、语音、歌唱和音乐）实现高质量建模；使用了立体声渲染方法赋予合成音频空间感；开放了可与开源基准数据集一起使用的工业级基准数据集Kling-Audio-Eval；在分布匹配、语义对齐、时间对齐和音频质量方面，Kling-Foley训练模型达到了公共模型的SOTA性能。", "conclusion": "Kling-Foley模型通过集成多模态扩散变换器、通用潜在音频编解码器和空间感增强技术，提升了视频到音频生成的性能和效果；同时开放的数据集有助于该模型的有效训练和验证；实验表明该模型在视频和音频同步方面表现出的SOTA性能。"}
{"llm_update_time": "2025-06-25 09:14:34", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19834", "html_url": "https://arxiv.org/abs/2506.19834", "title": "采用线性偏置的标准变压器和注意力机制用于分子构象生成", "title_en": "A standard transformer and attention with linear biases for molecular conformer generation", "authors": "Viatcheslav Gurev,Timothy Rumbell", "background": "在药物发现和优化过程中，采样低能量分子构象（原子在分子中的空间排列）是许多不同计算的关键任务。虽然专门设计的等变网络被用于从2D分子图生成分子构象，但非等变的变压器模型因其能够扩展以提高泛化能力而变得越来越受欢迎。然而，非等变模型需要较大的模型规模来弥补缺乏等变偏置的不足。", "innovation": "本文展示了通过选择合适的相对位置编码，有效解决了这一规模限制问题。研究发现，将相对位置编码整合到标准变压器模型中，并当模型扩展到2500万个参数时，超过了当前非等变基线模型在GEOM-DRUGS基准测试中的表现，该基线模型有6400万个参数。相对位置编码被实现为按角度递增的负注意力偏置，类似于NLP领域广泛应用的ALiBi技术，该技术基于图节点之间最短路径距离的不同斜率处理不同的注意力头。", "conclusion": "这种架构有潜力成为用于分子构象生成的新型生成模型的基础。"}
{"llm_update_time": "2025-06-25 09:14:36", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19839", "html_url": "https://arxiv.org/abs/2506.19839", "title": "使用分解流匹配改进渐进生成", "title_en": "Improving Progressive Generation with Decomposable Flow Matching", "authors": "Moayed Haji-Ali,Willi Menapace,Ivan Skorokhodov,Arpit Sahni,Sergey Tulyakov,Vicente Ordonez,Aliaksandr Siarohin", "background": "生成高维度视觉模态是一个计算密集的任务。常用的方法是逐层生成，从粗到细，类似于频谱自回归方式。尽管扩散模型可以受益于去噪中的这种逐层特性，但在这些场景中采用显式的多阶段架构比较少见。这些架构增加了方法的整体复杂度，引入了自定义扩散公式、依赖分解的阶段转换、手工编码的采样器或模型级联的需要。因此，需要一个简单有效的框架来实现视觉媒体的逐层生成。", "innovation": "贡献是提出了分解流动匹配（DFM）框架，它在用户定义的多尺度表示的每一层都独立应用流动匹配。实验结果表明，与先前的多阶段架构相比，DFM可以提高视觉质量和性能，特别是对于图像和视频，同时在相同的训练计算量下，DFM可实现基线架构35.2%的FDD分数提升，以及最高性能基线26.4%的提升。当应用于大型模型的微调时，如FLUX，DFM显示了更快的收敛速度。所有这些优势都通过单个模型实现，具有架构的简洁性和对学生现有训练管道的最小修改。", "conclusion": "DFM框架能够以简单有效的形式实现视觉媒体的逐层生成，提高输出质量，且具有比现有方法更好的性能，同时保持模型架构的简洁性，并且不需要对现有训练流水线做任何大的改动。"}
{"llm_update_time": "2025-06-25 09:14:37", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19777", "html_url": "https://arxiv.org/abs/2506.19777", "title": "利用公平生成序列推荐模型缓解用户敏感偏差", "title_en": "Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model", "authors": "Yang Liu,Feng Wu,Xuefang Zhu", "background": "近年来，推荐系统的公平性受到了广泛关注。推荐系统由用户行为驱动，在现实世界中，具有相同敏感特征（如性别和年龄）的用户往往表现出相似的行为模式。推荐模型在这种情况下容易捕捉到敏感特征的强大相关偏好，导致推荐系统的不公平性。扩散模型（DM）作为一种新的生成模型范式在推荐系统中取得了巨大成功。DM具有建模不确定性和多样性的能力，其建模机制与存在偏见的真实世界推荐过程具有高度适应性。因此，我们利用DM来有效建模推荐的公平性并增强多样性。", "innovation": "本文提出了一个基于DM的FairGENerative序列推荐模型FairGENRec。在训练阶段，通过敏感特征识别模型的引导向原始分布中注入随机噪声，并设计顺序去噪模型进行项目反重建；同时，在生成结果中注入消除敏感用户特征偏见的多兴趣表示信息，完成推荐公平性建模。在推理阶段，模型通过历史交互获得噪声并以噪声增加的形式进行反向迭代以重构目标项目表示。实验结果表明，FairGENRec在准确性和公平性方面具有双增强效果，而案例统计分析则可视化公平性的改进程度。", "conclusion": "本研究在三个数据集上进行了广泛的实验，证实FairGENRec在准确性和公平性方面具有双重增强效果。通过对案例进行统计分析，可视化了推荐公平性的改进程度。"}
{"llm_update_time": "2025-06-25 09:14:38", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19767", "html_url": "https://arxiv.org/abs/2506.19767", "title": "SRFT：具有监督和强化细调的单阶段方法", "title_en": "SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning", "authors": "Yuqian Fu,Tinghong Chen,Jiajun Chai,Xihuai Wang,Songjun Tu,Guojun Yin,Wei Lin,Qichao Zhang,Yuanheng Zhu,Dongbin Zhao", "background": "大语言模型（LLMs）在推理任务中取得了显著进展，但监督微调（SFT）和强化学习（RL）的最优集成依然是一个基本挑战。通过对令牌分布、学习动力学和基于熵的整合机制的综合分析，我们揭示了这些范式的关键差异：SFT 引起了LLM策略分布的大范围变化，而RL则进行精细选择性优化，熵是衡量训练有效性的一个关键指标。因此，需要一种能够统一这两种范式的单阶段方法.", "innovation": "基于这些观察，我们提出了监督强化细调（SRFT），这是一种通过熵感知权重机制统一SFT和RL的单阶段方法。SRFT方法同时应用SFT和RL直接优化LLM，而不是通过两阶段的顺序方法。实验结果表明，SRFT在五个数学推理基准测试中的平均准确率为59.1%，分别优于零RL方法9.0%和 trio 个分布外基准测试方法10.9%.", "conclusion": "SRFT 成功地实现了SFT和RL的统一，显著提高了在多种推理任务中的性能，展示了这种新方法的有效性。"}
{"llm_update_time": "2025-06-25 09:14:38", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19755", "html_url": "https://arxiv.org/abs/2506.19755", "title": "跨正则化：通过验证梯度自适应模型复杂度", "title_en": "Cross-regularization: Adaptive Model Complexity through Validation Gradients", "authors": "Carlos Stein Brito", "background": "模型正则化需要大量的手动调优来平衡复杂性与过拟合之间的关系。现有方法依赖人工调整正则化参数，但这是一个复杂且耗时的过程，不容易保证结果的最优性。", "innovation": "跨正则化通过在训练过程中直接利用验证梯度来调整正则化参数，解决了这一折衷问题。该方法将参数优化分为两步：训练数据指导特征学习，而验证数据塑造复杂性控制，从而可靠地收敛到交叉验证的最优解。此外，该方法通过在神经网络中注入噪声应用，揭示了意想不到的噪声容限和特定于架构的正则化，这些正则化会在训练过程中自然形成，并能无缝集成数据扩充、不确定性校准和扩增数据集，同时保持单一运行的有效性。", "conclusion": "该框架通过简单的梯度方法实现了上述功能，特别适用于需要快速高效调整模型复杂度的场景。"}
{"llm_update_time": "2025-06-25 09:14:40", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10326", "html_url": "https://arxiv.org/abs/2501.10326", "title": "大型语言模型在自动学术论文审查中的应用：一项综述", "title_en": "Large language models for automated scholarly paper review: A survey", "authors": "Zhenzhen Zhuang,Jiandong Chen,Hongfeng Xu,Yuwen Jiang,Jialiang Lin", "background": "大语言模型（LLMs）对人类社会产生了重大影响，涵盖了多个领域。在学术界，LLMs不仅是研究影响的对象，更是推动LLMs发展的关键动力。学术出版中，LLMs已经融入到同行评审机制中，以审查手稿。尽管LLMs在大规模实施自动学术论文审查（ASPR）方面具有变革性潜力，但也带来了新的问题和挑战。", "innovation": "本文综述了LLMs在ASPR中的应用，包括使用的LLMs、解决的技术瓶颈、新的方法和工具、性能评估及面对的问题、出版界和学术界的态度以及未来发展方向。这为研究人员提供了一个参考框架，推动ASPR的实际应用和发展。", "conclusion": "本文为研究人员提供了关于LLMs在ASPR中的应用综述参考，并探讨了ASPR的发展所面临的挑战和未来方向，旨在促进ASPR的实际实施和发展。"}
{"llm_update_time": "2025-06-25 09:14:41", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.05410", "html_url": "https://arxiv.org/abs/2406.05410", "title": "ChatSR：多模态大规模语言模型在科学研究中的科学公式发现", "title_en": "ChatSR: Multimodal Large Language Models for Scientific Formula Discovery", "authors": "Yanjie Li,Lina Yu,Weijun Li,Min Wu,Jingyi Liu,Wenqiang Li,Shu Wei,Yusong Deng", "background": "公式的发现是从观察数据中描述自然法则的语言，是科学研究的目标之一。它是人工智能领域的研究课题，被称为符号回归问题。现有的符号回归方法通常直接从观察数据生成表达式。虽然一些方法可以通过添加约束或引入特殊字符提示来注入一些先验知识，但这些方法只能导入预先规定的少量先验知识。ChatSR 方法利用多模态大语言模型的强大知识储备和理解能力，可以通过自然语言传达先验知识来指导公式生成，相较于传统方法，ChatSR 不仅在传统符号回归任务中表现出色，还能够理解自然语言提示中的先验知识并提升生成表达式的质量，具有出色的零样本能力以理解不在训练数据中的先验知识。", "innovation": "ChatSR 利用多模态大语言模型的强大知识储备和理解能力，通过自然语言传达先验知识来指导公式生成，增强了符号回归的能力，特别是在理解和利用自然语言先验知识方面取得了突破。这使得 ChatSR 能够理解和处理不在训练数据中的先验知识，展示了其出色的零样本能力。这也使得 ChatSR 在科学公式发现方面具备了显著的优势，能够生成更高质量的表达式。", "conclusion": "ChatSR 作为一种基于多模态大语言模型的方法，成功地将先验知识融入到符号回归过程中，不仅在传统任务上表现优异，还展示了理解自然语言提示的能力，提升了生成表达式的质量。此外，ChatSR 还展示了强大的零样本能力，可以理解和利用不在训练数据中的先验知识，进一步拓展了符号回归的应用范围和实用性。"}
{"llm_update_time": "2025-06-25 09:14:45", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.19918", "html_url": "https://arxiv.org/abs/2502.19918", "title": "Meta-Reasoner: 动态指导以优化大型语言模型推理时的推理", "title_en": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models", "authors": "Yuan Sui,Yufei He,Tri Cao,Simeng Han,Yulin Chen,Bryan Hooi", "background": "大型语言模型（LLMs）越来越多地依赖于延长的推理链来解决复杂任务。然而，这种试错方法常常导致计算开销大和错误传播，早期的错误可能导致后续步骤失效。这使得改进现有的LLM推理过程具有重要意义和挑战性。", "innovation": "提出了一种名为Meta-Reasoner的框架，它在推理时动态优化推理过程，通过使LLMs能够‘思考如何思考’来实现。该框架借鉴了人类元认知和二元过程理论，作为策略顾问，将高层次指导与逐步生成分离。它使用上下文多臂老虎机迭代评估推理进展并选择最优策略（如回溯、澄清歧义、从头开始或提出替代方法），并重新分配计算资源到最有可能的成功路径。这一框架展示了动态推理链在克服LLM推理过程中的固有挑战并应用于更广泛任务中的潜力。", "conclusion": "评估表明，Meta-Reasoner有望为推理密集型任务提供一种可扩展且适应性强的解决方案，同时也展示了动态推理链在数学推理和谜题解决等任务中的潜在应用。"}
{"llm_update_time": "2025-06-25 09:14:48", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09730", "html_url": "https://arxiv.org/abs/2503.09730", "title": "基于验证器循环的局部前瞻指导以提高自动定理证明", "title_en": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving", "authors": "Sara Rajaee,Kumar Pratik,Gabriele Cesa,Arash Behboodi", "background": "近年来，最有望用于AI推理的方法通常依赖于强化学习（RL）的各种变体，这些方法要么对从语言模型（LLMs）中展开的轨迹进行应用，即使是按步骤奖励的场景也是如此，要么依赖大量的人标注轨迹数据。这种依赖于展开轨迹数据的计算成本和时间变得极其高昂。特别是，一个推理轨迹的正确性通常只能在完成时才能判断，因此在RL中会导致稀疏奖励，或者在专家迭代方法中需要昂贵的合成数据生成。", "innovation": "本文关注自动定理证明（ATP）任务，并提出了一种新颖的验证器在循环中的设计方案，这种方法不同于现有依赖于整个推理轨迹反馈的方法，而是使用自动化验证器在推理过程的每一步提供中间反馈。利用Lean作为验证器，实验证明了逐步局部验证可以提高模型推理的准确性和效率，", "conclusion": "通过验证器在循环中的逐步局部验证，可以提高自动定理证明模型的推理准确性和效率。"}
{"llm_update_time": "2025-06-25 09:14:48", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.20425", "html_url": "https://arxiv.org/abs/2503.20425", "title": "观点转移的神经符号世界模型：一种面向社交感知的机器人导航框架", "title_en": "Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation", "authors": "Kevin Alcedo,Pedro U. Lima,Rachid Alami", "background": "环境导航需要代理在不确定性下进行推理，并考虑周围人的信念和意图。在这种顺序决策框架下，以自我为中心的导航可以自然地被表示为马尔可夫决策过程（MDP）。然而，社会导航还要求代理推理他人的隐藏信念，这使得状态变为部分可观测的马尔可夫决策过程（POMDP），意即代理无法直接访问其他人的心理状态。为此，团队借鉴了情感理论和知识规划的方法，提出了面向社会导航的神经符号模型基强化学习架构，并开发了一种视角转移操作符，以利用基于影响的抽象（IBA）在结构化多智能体环境中的最新成果，来实现信念估计。", "innovation": "团队提出了神经符号模型基的强化学习架构，以解决部分可观测环境中信念追踪的挑战。更重要的是，团队开发了一种视角转移操作符，用于信念估计，这也是基于近期的基于影响的抽象（IBA）成果进行实现的，旨在提升多智能体环境下的社交导航能力。", "conclusion": "通过设计观点转移的神经符号世界模型，这项研究为强化学习和多智能体系统下的社交感知机器人导航提供了一个新的框架。这种模型可以更好地理解和预测他人的行为，促进了更高效、更可靠的机器人导航系统的发展。"}
{"llm_update_time": "2025-06-25 09:14:49", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23436", "html_url": "https://arxiv.org/abs/2505.23436", "title": "基于资源约束条件下的理性代理的潜在风险意识", "title_en": "Emergent Risk Awareness in Rational Agents under Resource Constraints", "authors": "Daniel Jarne Ornia,Nicholas Bishop,Joel Dyer,Wei-Chen Lee,Ani Calinescu,Doyne Farmer,Michael Wooldridge", "background": "本文背景在于先进推理模型借助具备代理能力的AI代理与人类互动并解决在近似效用函数和内部模型下的顺序决策问题。当这些决策问题包含资源或故障约束时，代理行为面临着明确的权衡，这会影响其效用驱动的行为（理性行为）。此外，这些代理通常由人类委托人代理执行任务，导致约束暴露程度的不对称性，这可能产生人类目标与代理激励之间的先前未预见的不对齐。本文通过生存多臂难题框架对这一情境进行了建模，并通过对理论和实证结果的分析，确定了潜在不对齐出现的条件，并提出了解决措施。", "innovation": "本文通过生存多臂难题框架正式化了代理在资源约束下的情境，并探讨了由此产生的效用偏好转移、潜在不对齐、以及风险偏好（寻求或规避）的现象。该研究还提出了缓解这些行为出现的机制，从而增加了在生存压力下AI代理行为的理解和可解释性，同时也提出了在资源受限环境安全部署AI系统的指导方针。", "conclusion": "综上所述，本文旨在提升在资源受限环境下理解与解释AI代理行为的能力，并提供了指导，以安全地部署这些AI系统。"}
{"llm_update_time": "2025-06-25 09:14:50", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19847", "html_url": "https://arxiv.org/abs/2506.19847", "title": "可扩展的正交微调", "title_en": "Orthogonal Finetuning Made Scalable", "authors": "Zeju Qiu,Weiyang Liu,Adrian Weller,Bernhard Schölkopf", "background": "正交微调（OFT）提供了高度参数效率的适应能力，同时还防止了灾难性遗忘，然而其高运行时间和内存需求限制了其实用部署。OFT的核心计算瓶颈在于其基于权重的实现方式，依赖于昂贵的具有三次复杂度的矩阵-矩阵乘法。", "innovation": "我们提出了一种名为OFTv2的改进方案，这是一种基于输入的重新表述，利用矩阵-向量乘法（即矩阵自由计算）将计算成本降低到二次。此外，我们还引入了Cayley-Neumann参数化，这是一种高效的正交参数化方法，通过截断的Neumann级数近似Cayley变换中的矩阵求逆。这些改进使OFTv2能够在不牺牲性能的情况下实现10倍的训练速度提升和3倍的GPU内存使用减少。进一步地，我们将OFTv2扩展到支持量化基础模型的微调，并证明它在训练稳定性、效率和内存使用方面优于流行的QLoRA方法。", "conclusion": "OFTv2不仅提高了微调的效率，还增强了训练的稳定性和降低了内存使用，为其在实际应用中的部署提供了可能。"}
{"llm_update_time": "2025-06-25 09:14:53", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19769", "html_url": "https://arxiv.org/abs/2506.19769", "title": "Multi-sensor Fusion Perception for Embodied AI: 背景、方法、挑战和展望", "title_en": "A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects", "authors": "Shulan Ruan,Rongwei Wang,Xuchen Shen,Huijie Liu,Baihui Xiao,Jun Shi,Kun Zhang,Zhenya Huang,Yu Liu,Enhong Chen,You He", "background": "多传感器融合感知（MSFP）是具身AI的关键技术，适用于各种下游任务（例如：3D物体检测和语义分割）和应用场景（例如：自动驾驶和群机器人）。现有的关于基于AI的MSFP方法的综述已经成为相关调查的主题。然而，研究人员发现这些综述存在一些局限性，主要是因为大多数综述集中在单个任务或研究领域，例如3D物体检测或自动驾驶。这意味着研究人员在其他相关的任务中常常难以直接从中受益。另外，大多数综述仅仅从多模态融合的角度介绍MSFP，缺乏考虑MSFP方法的多样性，如多视图融合和时间序列融合。因此，本文旨在从任务无关的视角组织MSFP研究，从各种技术视角来介绍方法。首先，我们介绍了MSFP的背景。接着，我们回顾了多模态和多代理融合的方法。更进一步地，我们分析了时间序列融合的方法。在大模型时代，我们还探讨了多模态大模型融合的方法。最后，我们讨论了MSFP面临的挑战和未来方向。我们希望这份综述能够帮助研究者理解在MSFP领域的重要进展，并为未来的研究提供可能的启示", "innovation": "本文主要创新在于从任务无关的视角组织MSFP研究，涵盖了多模态、多代理、时间序列融合以及大模型融合等方面，为研究者提供一个全面、多样化的综述视角，并且探讨了MSFP面临的关键挑战和未来方向，提供了一种综合分析方法来推动MSFP领域的研究", "conclusion": "本文总结了多传感器融合感知的研究进展，并从不同的技术视角详细介绍了MSFP的各种方法。同时，我们也指出了MSFP领域面临的挑战和未来的研究方向，希望能够为研究人员提供有用的信息和启示。"}
{"llm_update_time": "2025-06-25 09:14:53", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14544", "html_url": "https://arxiv.org/abs/2505.14544", "title": "智能交通信号：比较MARL和固定时间策略", "title_en": "Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies", "authors": "Saahil Mahato", "background": "城市交通拥堵，特别是在交叉口，严重影响了行程时间、燃油消耗和排放。传统的固定时间信号控制系统往往缺乏应对动态交通模式的适应性。研究表明，多代理强化学习（MARL）可以应用于优化多个交叉口的交通信号协调，并通过模拟环境进行验证。", "innovation": "开发了一个基于Pygame的模拟环境，用于建模交互式交叉口网络，并随机生成车辆流量以反映实际的交通变异性。实施了一个去中心化的MARL控制器，每个交通信号作为自主代理，基于局部观察和邻近代理的信息做出决策。与基准的固定时间控制器相比，使用诸如平均车辆等待时间和总体吞吐量等指标评估表现，显示MARL方法在平均等待时间和吞吐量方面具有显著的改进效果。", "conclusion": "研究表明，基于MARL的动态控制策略在改善城市交通管理效率方面具有巨大的潜力。但有必要进一步研究以解决可扩展性和实际部署挑战。"}
{"llm_update_time": "2025-06-25 09:14:54", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04942", "html_url": "https://arxiv.org/abs/2504.04942", "title": "Lemmanaid: Neuro-Symbolic Lemma Conjecturing", "title_en": "Lemmanaid: Neuro-Symbolic Lemma Conjecturing", "authors": "Yousef Alhessi,Sólrún Halla Einarsdóttir,George Granberry,Emily First,Moa Johansson,Sorin Lerner,Nicholas Smallbone", "background": "自动推导有用、有趣且新颖的引理将极大地提高自动推理工具的效果，并降低在证明助手中形式化数学的门槛。然而，这一任务对于神经和符号方法来说都是非常具有挑战性的。本文介绍了第一个结合大型语言模型（LLMs）和符号方法的神经-符号引理推导工具，Lemmanaid，并对其在Isabelle证明助手的证明库上进行了评估。", "innovation": "该研究提出了Lemmanaid，这是一个结合了大型语言模型（LLMs）和符号方法的神经-符号引理推导工具。Lemmanaid通过训练LLM生成引理模板描述引理的结构，并使用符号方法填充细节。实验结果显示，Lemmanaid在测试集上的表现优于纯神经方法和先前的纯符号方法，在Isabelle的HOL库和Archive of Formal Proofs中的引理发现率分别达到了29%-39.5%和8%-15%的提高。", "conclusion": "通过结合符号和神经方法的优势，Lemmanaid能够在广泛的输入领域生成有用的引理，促进计算机辅助理论开发和形式化。"}
{"llm_update_time": "2025-06-25 09:14:55", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00202", "html_url": "https://arxiv.org/abs/2506.00202", "title": "专业软件开发者在人工智能时代需要掌握哪些知识才能获得成功？", "title_en": "What do professional software developers need to know to succeed in an age of Artificial Intelligence?", "authors": "Matthew Kam,Cody Miller,Miaoxin Wang,Abey Tidwell,Irene A. Lee,Joyce Malyn-Smith,Beatriz Perez,Vikram Tiwari,Joshua Kenitzer,Andrew Macvean,Erin Barrar", "background": "生成式AI为软件开发者带来了早期的生产力增益，但劳动力市场可能面临的扰乱与技能过时的担忧也为之伴随。本文通过研究21名处于AI应用最前沿的开发者，总结了他们其中12个工作目标及其关联的任务、技能和知识，以展示开发者在工作中使用AI的情况。", "innovation": "研究找出了5项洞察，并确定了四个技能领域（有效利用生成式AI、核心软件工程、相关工程和相关非工程领域），这些技能和知识在6步任务工作流程的关键节点上被应用。研究强调了需要在技术技能和“软”技能两方面进行在职培训和计算机科学教育，以确保开发者适应AI时代并避免技能过时。", "conclusion": "为了应对AI时代的需求，职业软件开发者需要在现有的‘软’技能和技术技能基础上进行再培训和提升，多个教育项目应该专注于培养这些多领域的技术和知识。"}
{"llm_update_time": "2025-06-25 09:14:58", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19852", "html_url": "https://arxiv.org/abs/2506.19852", "title": "径向注意力：具有能量衰减的 $O(n\text{log}n)$ 薄注意力机制用于长视频生成", "title_en": "Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for Long Video Generation", "authors": "Xingyang Li,Muyang Li,Tianle Cai,Haocheng Xi,Shuo Yang,Yujun Lin,Lvmin Zhang,Songlin Yang,Jinbo Hu,Kelly Peng,Maneesh Agrawala,Ion Stoica,Kurt Keutzer,Song Han", "background": "最近的扩散模型在视频生成方面取得了高质量的进展，但由于额外的时间维度，计算成本显著增加，导致训练和长视频推理变得极其昂贵。", "innovation": "提出了径向注意力，这是一种具有 $O(n \text{log} n)$ 复杂度的可扩展稀疏注意机制，将能量衰减转化为指数衰减的计算密度，相比标准的 $O(n^2)$ 密集注意机制更为高效，且比线性注意力更具表现力。径向注意力使用简单的静态注意掩码，其中每个令牌仅关注空间临近的令牌，随着时间距离的增加，注意力窗口大小会减小。此外，它允许预训练的视频扩散模型通过有效的LoRA基于的微调来延长生成长度。广泛的实验表明，径向注意力在保持视频质量的同时，能在Wan2.1-14B、HunyuanVideo和Mochi1上实现高达1.9倍的速度提升，同时训练成本最多减少4.4倍，推理速度比密集注意推理加快3.7倍。", "conclusion": "径向注意力机制保持了视频质量，实现了更高的生成长度，同时显著降低了训练和推理成本。"}
{"llm_update_time": "2025-06-25 09:14:58", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01056", "html_url": "https://arxiv.org/abs/2506.01056", "title": "MCP-Zero：自主LLM代理的主动工具发现", "title_en": "MCP-Zero: Active Tool Discovery for Autonomous LLM Agents", "authors": "Xiang Fei,Xiawu Zheng,Hao Feng", "background": "当前的LLM代理通过预定义的工具框架来处理任务，这使得模型变成被动的选择者，未能体现出真正的自主通用智能。因此，真正的智能需要主动的学习并获取新的技能。现有的方法无法完全满足需要，而MCP-Zero则通过赋予LLM自我发现工具的能力来改进这一现状，使其从大型检索器转变为真正的自主代理。", "innovation": "引入MCP-Zero，这是一种扩展自主代理框架，它通过三个核心机制（1）主动工具请求，使模型自主生成描述其需求的结构化请求；（2）分层语义路由，以接近匹配方式匹配模型请求和可用工具；（3）迭代能力扩展，允许代理渐进构建跨域工具链同时保持较小的上下文足迹。该框架提供了一个包含308个MCP服务器和2,797个工具的MCP-tools数据集，实验表明该方法能更有效地保持代理自主性：（1）精确选择近3千个候选工具中约24.8万个标记；（2）APIBank通信消耗降低98%，保持高准确率；（3）多轮对话性能随工具生态系统增大而提升。这项工作确立了主动工具发现作为可扩展自主代理系统基本设计模式的重要性。", "conclusion": "MCP-Zero通过赋予LLMs主动发现并获取新技能的能力，提高了其自主性和效率，从而建立了一种新的设计模式，用于构建可扩展的自主代理系统。"}
{"llm_update_time": "2025-06-25 09:15:00", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18810", "html_url": "https://arxiv.org/abs/2506.18810", "title": "ConciseHint: 提升生成过程中持续简洁提示以增强有效推理", "title_en": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "authors": "Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang", "background": "大型推理模型（LRMs）如DeepSeek-R1和OpenAI的o1系列，通过扩展Chain-of-Thought (CoT)的生成长度，在复杂推理任务中取得了显著的性能提升。然而，它们倾向于生成冗长的推理过程，导致效率问题。现有文献主要关注在推理之前的效率改进，比如提示和推理、微调和推理，但忽略了在推理生成过程中直接鼓励模型简洁表达的潜力。", "innovation": "本文提出了一种名为ConciseHint的框架，在推理生成过程中持续注入设计的文本提示（手动设计或基于简洁数据训练），以鼓励模型简洁表达。此外，ConciseHint能够根据查询的复杂性自适应地调整提示强度，确保不会削弱模型性能。该方法在DeepSeek-R1和Qwen-3系列等最先进的LRMs上进行的实验表明，能够有效生成简洁的推理过程，几乎不损失精度。例如，在GSM8K基准测试上，ConciseHint将Qwen-3 4B的推理长度减少了65%。", "conclusion": "我们的方法能够在保持性能的同时，有效生成简洁的推理过程。通过自适应调整提示强度，ConciseHint不仅提高了模型的推理效率，还在一定程度上避免了性能的下降。"}
{"llm_update_time": "2025-06-25 09:15:03", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11555", "html_url": "https://arxiv.org/abs/2506.11555", "title": "RAG+: 使用应用意识推理增强检索增强生成", "title_en": "RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning", "authors": "Yu Wang,Shiwan Zhao,Zhihu Wang,Yubo Zhang,Xicheng Zhang,Zhengfan Wang,Heyuan Huang,Ming Fan,Ting Liu", "background": "通过检索增强生成（RAG）整合外部知识已成为提升大型语言模型（LLMs）处理知识密集型任务的能力的基础。然而，现有的RAG方法往往忽视了应用知识的认知步骤，导致从检索到的事实与任务特定的推理之间存在差距。该研究以此为背景进行，填补了这一认知过程中的空白，进一步提高LLMs的性能与准确性。", "innovation": "RAG+作为一种基本原则性的模块化扩展，将明确的应用意识推理融入RAG管道中。RAG+构建了一个包括知识与匹配应用示例的双重语料库，可以通过手动或自动化方式创建，并在推理时联合检索。这使LLMs不仅能够访问相关信息，还能在结构化的、目标导向的推理过程中将其应用。实验结果表明，RAG+在数学、法律、医疗等多个领域的表现优于标准的RAG变体，平均改进率为3-5%，在复杂场景中最高可达7.5%。RAG+通过将检索与可执行的应用结合起来，推动了一个更具认知基础的知识集成框架，向更可解释和强大的LLMs前进了一步。", "conclusion": "RAG+通过融入应用意识推理，提供了一个更加认知基础的框架，用于知识集成，代表了更可解释和强大LLMs的方向。"}
{"llm_update_time": "2025-06-25 09:15:04", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18902", "html_url": "https://arxiv.org/abs/2506.18902", "title": "jina-embeddings-v4：统一多模态多语言检索的嵌入式表示", "title_en": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval", "authors": "Michael Günther,Saba Sturua,Mohammad Kalim Akram,Isabelle Mohr,Andrei Ungureanu,Bo Wang,Sedigheh Eslami,Scott Martens,Maximilian Werk,Nan Wang,Han Xiao", "background": "介绍了jina-embeddings-v4模型，这是一个包含3.8亿参数的多模态嵌入模型，通过一种新颖的架构将文本和图像表示统一起来，支持单向量和多向量嵌入并在晚期交互式风格中工作。模型结合了特定任务的低秩适配器（LoRA），优化了跨不同检索场景的表现，包括查询文档检索、语义文本相似性和代码搜索等任务。全面的评估结果表明，jina-embeddings-v4在单模态和跨模态检索任务中均取得了最先进的性能，特别是在处理表格、图表、图表和多媒体格式的丰富视觉内容方面表现尤为突出。为便于评估这种能力，还引入了Jina-VDR，这是一种专门针对丰富视觉内容检索的新基准方法。", "innovation": "引入了jina-embeddings-v4多模态嵌入模型，具有3.8亿参数，通过新型架构统一文本和图像表示，支持单向量和多向量嵌入，并采用晚期交互式风格设计。模型结合了针对特定任务的低秩适配器（LoRA），适用于多种检索场景，如查询-文档检索、语义文本相似性和代码搜索。研究结果表明，该模型在单模态和跨模态检索任务中表现出色，尤其在处理视觉丰富内容时有显著优势。还引入了Jina-VDR基准，针对富视觉内容检索设计。", "conclusion": "jina-embeddings-v4在多种检索场景下展示了卓越的性能，尤其是在处理视觉丰富内容方面表现出色，同时在单模态和跨模态检索任务上均取得最先进的性能。Jina-VDR作为一种新型基准，专门设计用于评价富视觉内容的检索能力。"}
{"llm_update_time": "2025-06-25 09:15:04", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2308.05889", "html_url": "https://arxiv.org/abs/2308.05889", "title": "DF2: 无分布依赖的决策焦点学习", "title_en": "DF2: Distribution-Free Decision-Focused Learning", "authors": "Lingkai Kong,Wenhao Mu,Jiaming Cui,Yuchen Zhuang,B. Aditya Prakash,Bo Dai,Chao Zhang", "background": "DFL，借助KKT条件区分，已成为预测-优化问题的强大方法。然而，在概率框架下，DFL面临三大瓶颈：模型匹配误差、样本平均逼近误差和梯度逼近误差。模型匹配误差源于模型参数化预测分布与真实概率分布间的不一致。样本平均逼近误差发生在使用有限样本逼近期望优化目标时。梯度逼近误差则在目标非凸时产生，因为KKT条件无法直接应用。", "innovation": "本文提出了DF2，首个无分布依赖的决策焦点学习方法，旨在缓解上述三大瓶颈问题。不同于依赖特定任务的前向预测器需要精确模型假设，该方法在训练过程中直接学习期望优化函数。基于针对期望目标分布化参数化的启发，DF2设计了一种基于注意力机制的模型架构，以高效地在数据驱动的方式下学习该函数。该方法在两个合成问题和三个实际问题上的评估证明了其有效性。", "conclusion": "DF2在解决预测-优化问题时，通过直接学习期望优化函数并在训练期间缓解模型匹配、样本平均逼近和梯度逼近误差，展示了其在无分布依赖下的优越性能。"}
{"llm_update_time": "2025-06-25 09:15:06", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15196", "html_url": "https://arxiv.org/abs/2506.15196", "title": "HeurAgenix: 利用大语言模型解决复杂组合优化挑战", "title_en": "HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges", "authors": "Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian", "background": "启发式算法在解决组合优化（CO）问题中起着至关重要的作用，但传统的启发式设计高度依赖手工经验，并且难以在不同实例之间泛化。由于CO问题的复杂性，缺乏可靠的监督也使得启发式算法的选择更加困难。", "innovation": "引入HeurAgenix，这是一种基于大语言模型（LLMs）的两阶段超启发式框架。它首先进化启发式算法，然后自动选择最优算法。启发式进化阶段使用LLM比较初始启发式解与高质解，并提取可重复使用的进化策略。在解决问题时，根据LLM的感知能力动态选择每个问题状态下的最优启发式。轻量级启发式选择器可以通过双奖励机制进行微调，该机制结合了选择偏好和状态感知信号，以在嘈杂的注释下实现稳健选择。HeurAgenix不仅在现有基于LLM的超启发式中表现出色，还在某些情况下甚至超过了专用解算器。", "conclusion": "HeurAgenix 在经典基准测试中的实验结果表明，它不仅超越了现有的基于LLM的超启发式算法，还与专门的求解器表现相当或更好。该研究的源代码可从提供的链接访问。"}
{"llm_update_time": "2025-06-25 09:15:06", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.08785", "html_url": "https://arxiv.org/abs/2310.08785", "title": "DeltaSpace：一种用于灵活文本导向图像编辑的语义对齐特征空间", "title_en": "DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing", "authors": "Yueming Lyu,Kang Zhao,Bo Peng,Huafeng Chen,Yue Jiang,Yingya Zhang,Jing Dong,Caifeng Shan", "background": "文本指导的图像编辑在训练和推断的灵活性方面面临重大挑战。现有文献通常收集大量的标注图像-文本对来从头训练文本条件生成模型，这既昂贵又不高效。之后，一些利用预训练视觉-语言模型的方法被提出以避免数据收集，但这些方法在逐文本提示优化或推断时超参数调优方面受到限制。", "innovation": "本研究提出了一个名为CLIP DeltaSpace的具体空间，即CLIP视觉特征差异与对应文本描述的语义差异在CLIP文本特征差异上对齐。基于DeltaSpace，我们提出了一个名为DeltaEdit的新框架。该框架在训练阶段将CLIP视觉特征差异映射到生成模型的潜在空间方向，并在推断阶段从CLIP文本特征差异中预测潜在空间方向。这种设计赋予了DeltaEdit两大优势：（1）无文本的训练；（2）零样本推断时对各种文本提示的通用性。实验结果验证了DeltaEdit在不同生成模型中的有效性和适用性，包括生成对抗网络（GAN）模型和扩散模型，以实现灵活的文本导向图像编辑。", "conclusion": "大量实验验证了DeltaEdit在不同生成模型中的有效性和通用性，包括GAN模型和扩散模型。DeltaEdit框架为文本引导的图像编辑提供了训练上的灵活性和对各种文本提示的零样本推断能力。"}
{"llm_update_time": "2025-06-25 09:15:07", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.16316", "html_url": "https://arxiv.org/abs/2310.16316", "title": "Sum-of-Parts: 自包含神经网络中的端到端学习特征组", "title_en": "Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups", "authors": "Weiqiu You,Helen Qu,Marco Gatti,Bhuvnesh Jain,Eric Wong", "background": "自归因神经网络（SANN）为高纬度问题提供了解释性强的模型前景，但它们常常在性能上面临显著权衡。本文正式证明了单特征SANN的错误下限，并指出基于组的SANN可以实现零错误，因此具有高性能。本文基于这些发现，提出Sum-of-Parts (SOP)框架，可以将任何可微分模型转换为基于组的SANN，其中特征组在端到端学习中被学习，无需组监督。", "innovation": "提出了Sum-of-Parts (SOP)框架，将任何可微分模型转换为基于组的SANN，在视觉和语言任务上达到SANN的最优性能，证明了组的可解释性，并验证了SOP解释在模型调试和宇宙学科学发现中的实用性。SOP在组学习中无需监督，实现了端到端学习特征组的目标。", "conclusion": "通过Sum-of-Parts框架，任何可微分模型都可以被转换为基于组的SANN，适用于视觉和语言任务，组在多种定量和语义指标上具有可解释性，SOP解释在模型调试和科学发现中显示出实用性。本文代码已公开。"}
{"llm_update_time": "2025-06-25 09:15:09", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2308.16075", "html_url": "https://arxiv.org/abs/2308.16075", "title": "噪声多模态NMT中视觉上下文的影响：一种英语到印度语言的实证研究", "title_en": "Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages", "authors": "Baban Gain,Dibyanayan Bandyopadhyay,Samrat Mukherjee,Chandranath Adak,Asif Ekbal", "background": "神经机器翻译（NMT）在过去取得了显著进展，主要依赖大规模文本数据，但视觉信息等多模态输入的潜在价值在高资源设置中尚未充分开发。先前的研究主要关注低资源场景下的多模态数据使用，而本研究侧重于探索在大规模预训练单模态NMT系统中添加图像特征如何影响翻译效果。研究结果表明，图像可能在这个场景中是冗余的。此外，研究通过引入合成噪声来评估图像是否有助于模型处理文本噪声。结果显示，即使使用随机图像，多模态模型在噪声环境下也稍好于仅文本模型。实验包含从英语翻译成印地语、孟加拉语和马拉雅拉姆语，显著超越了当前最先进的基准。研究还发现，视觉上下文的效果会随着源文本噪声水平的不同而变化：无视觉上下文最适合无噪声翻译，裁剪的图像特征最适合低噪声情况，而完整的图像特征在高噪声环境中表现更好。这揭示了视觉上下文在噪声环境下的作用，并为多模态设置中的噪声神经机器翻译提供了新的研究方向。研究强调了结合视觉和文本信息对各种环境下的翻译改进的重要性。", "innovation": "本研究通过在大规模单模态NMT系统中引入图像特征，探索其对翻译的影响，结果显示图像在某些情况下可能是冗余的。研究还通过引入合成噪声来评估图像是否有助于模型处理文本噪声。在噪声环境下，多模态模型的表现优于仅文本模型，特别指出视觉上下文的效果会随着源文本噪声水平的不同而变化，从而为噪声环境下的多模态NMT提供了新的研究方向。", "conclusion": "视觉上下文在不同的噪声环境下对翻译的影响不同，无视觉上下文适用于无噪声的翻译，裁剪的图像特征适用于低噪声情况，而完整的图像特征在高噪声环境中表现更好。研究强调了结合视觉和文本信息在各种环境下改善翻译的重要性。"}
{"llm_update_time": "2025-06-25 09:15:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.14606", "html_url": "https://arxiv.org/abs/2403.14606", "title": "不同iable 编程的要素", "title_en": "The Elements of Differentiable Programming", "authors": "Mathieu Blondel,Vincent Roulet", "background": "近年来，人工智能经历了显著的进步，这得益于大型模型、海量数据集、加速硬件以及可微编程的变革性力量。可微编程是一种新的编程范式，通过自动生成梯度，实现了对包括控制流和数据结构在内的复杂计算机程序的端到端微分，使得基于梯度的程序参数优化成为可能。这种方法建立在自动微分、图形模型、优化和统计学等多个计算机科学和应用数学领域的基础上。", "innovation": "这篇论文介绍了可微编程的核心概念，并采用了优化和概率两种视角进行阐述，两者之间存在明显的类比关系。可微编程不仅仅是程序的微分，还包括了对设计可微程序进行深思熟虑的设计，通过使程序可微，自然地引入了程序执行的概率分布，为衡量程序输出的不确定性提供了一种手段。", "conclusion": "总之，可微编程提供了一种新的编程范式，不仅改变了对程序的理解，也为机器学习领域带来了新的可能性。"}
{"llm_update_time": "2025-06-25 09:15:11", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.12029", "html_url": "https://arxiv.org/abs/2403.12029", "title": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection", "title_en": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection", "authors": "Justin Kay,Timm Haucke,Suzanne Stathatos,Siqi Deng,Erik Young,Pietro Perona,Sara Beery,Grant Van Horn", "background": "现有的目标检测器在训练集差异较大的数据上表现不佳。尽管最近提出了领域适应性目标检测（DAOD）方法，并取得了显著成果，但研究中存在基准测试缺陷，包括性能高估、不一致的实现实践和缺乏通用性等问题。这些缺陷值得引起重视，因为它们可能会误导研究方向，阻碍进一步的进步.", "innovation": "本文提出了统一和改进领域适应性目标检测的方法，包括：（1）引入了统一的基准测试和实现框架ALDI，便于方法对比，为未来的工作提供支持；（2）提供了一个公平且现代的训练和评估协议，解决了基准测试方面的诸多杂乱问题；（3）提出了一个新的基准数据集CFC-DAOD，能够评估多样化的现实数据；（4）提出了一种新的方法ALDI++，取得了显著的SOTA结果，尤其是相较于之前的SOTA方法在多个数据集上的性能提升明显，且框架、数据集及方法为领域适应性目标检测设立了新的基准.", "conclusion": "ALDI和ALDI++框架在不影响性能的情况下是架构无关的，为YOLO和DETR基于的DAOD方法设置了新的SOTA标准。我们的框架、数据集及SOTA方法提供了DAOD领域的关键重置，并为未来的研究奠定了坚实的基础。相关代码和数据已发布，供研究界参考和使用."}
{"llm_update_time": "2025-06-25 09:15:13", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.08638", "html_url": "https://arxiv.org/abs/2505.08638", "title": "TRAIL: 跟踪推理与智能体问题定位", "title_en": "TRAIL: Trace Reasoning and Agentic Issue Localization", "authors": "Darshan Deshpande,Varun Gangal,Hersh Mehta,Jitin Krishnan,Anand Kannappan,Rebecca Qian", "background": "随着智能体工作流在不同领域的广泛应用，对其进行系统的复杂轨迹评估显得至关重要。当前的评估方法依赖于人工、特定领域的分析，这种方法无法应对智能体输出不断增加的复杂性和数量。在这些环境中进行错误分析更加复杂，因为外部工具输出与语言模型的推理相互作用，使问题比传统的软件调试更为复杂。本研究旨在提出一种适用于智能体工作流轨迹的新颖评估方法，介绍智能体系统中发现的错误类型，并创建了一个由这些错误类型分类的148个大面积人工标注轨迹数据集(TRAIL)，以确保生态效度并集中在软件工程和开放式信息检索等实际应用中。我们的评估表明，现代长上下文LLM在轨迹调试中表现不佳，最佳的Gemini-2.5-pro模型在TRAIL上的得分仅为11%。该数据集和代码已公开，旨在支持和加速未来对智能体工作流可扩展评估的研究。", "innovation": "本文提出了一个全面的评估方法，用于系统地评估智能体工作流的复杂轨迹。它介绍了智能体系统中的不同类型错误，以及一个由这些错误类型分类的大面积人工标注轨迹数据集(TRAIL)。此外，它全面评价了现代长上下文的LLM在轨迹调试中的表现，并公开了数据集和代码以促进未来的研究。", "conclusion": "本研究揭示了对智能体工作流的复杂轨迹进行评估的迫切需求，并提供了一个可用于评估和未来研究的数据集。研究发现现代LLM在轨迹调试中表现不佳，强调了开发专门针对智能体工作流的新颖和强大评估方法的重要性和迫切性。"}
{"llm_update_time": "2025-06-25 09:15:17", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.10611", "html_url": "https://arxiv.org/abs/2405.10611", "title": "Imandra中用于深度神经网络验证的认证证明检查器", "title_en": "A Certified Proof Checker for Deep Neural Network Verification in Imandra", "authors": "Remi Desmartin,Omri Isac,Grant Passmore,Ekaterina Komendantskaya,Kathrin Stark,Guy Katz", "background": "近年来，深度神经网络（DNNs）验证技术的进步为这些技术在许多领域中的广泛应用铺平了道路，包括安全关键领域。然而，DNN验证器本身是复杂的程序，已被证明容易出现错误和数值不精确的问题，这引发了对DNN验证器的信任问题。为了解决这个问题，一些方法尝试通过赋予DNN验证器生成可独立算法检查的证书的能力来提高信任度。虽然已经有一些基于先进的DNN验证器Marabou的证书检查形式化存在，但这些实现都是在C++中完成的，代码本身就引发了信任问题（例如，浮点计算的精确性或实现完整性的保证）。", "innovation": "本文提出了在Imandra中实现Marabou证书检查，Imandra是一个工业功能编程语言和交互式定理证明器（ITP）。通过这种方式，我们能够获得证书完全正确的形式化证明。这一结果的意义在于，它为Marabou证明提供了更强大的独立保证，并且开启了在交互式定理证明中更广泛采用DNN验证器的可能，类似于许多ITP已经整合SMT求解器一样。", "conclusion": "此工作为Marabou证明提供了更强的独立保证，并为DNN验证器在交互式定理证明中的更广泛应用开辟了途径。"}
{"llm_update_time": "2025-06-25 09:15:18", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.09567", "html_url": "https://arxiv.org/abs/2405.09567", "title": "ECG-SMART-NET: 一种用于精确ECG诊断阻塞性心肌梗死的深度学习架构", "title_en": "ECG-SMART-NET: A Deep Learning Architecture for Precise ECG Diagnosis of Occlusion Myocardial Infarction", "authors": "Nathan T. Riek,Murat Akcakaya,Zeineb Bouzid,Tanmay Gokhale,Stephanie Helman,Karina Kraevsky-Philips,Rui Qi Ji,Ervin Sejdic,Jessica K. Zègre-Hemsey,Christian Martin-Gill,Clifton W. Callaway,Samir Saba,Salah Al-Zaiti", "background": "阻塞性心肌梗死（OMI）是一种严重的心肌梗死形式，表现为冠状动脉完全阻塞，需要立即进行心脏导管检查来恢复心脏供血。大约三分之二的OMI病例难以仅通过12导联心电图（ECG）视觉识别，并且如果未能快速识别，则可能导致致命后果。以往对于OMI的ECG检测方法研究较少，现有先进技术表明，基于特征的随机森林和卷积神经网络（CNNs）都是提高ECG检测OMI准确性的有希望的方法。", "innovation": "本文提出了一种由ResNet-18架构改进的深度学习模型，称为ECG-SMART-NET。该模型通过时间卷积层和空间卷积层，分别学习时间特征和空间特征，以提高其在阻塞性心肌梗死诊断中的准确度。与原始的ResNet-18和其他先进模型相比，ECG-SMART-NET表现出更高的性能，在一个包含来自7397名患者的10,393份心电图的实际多中心临床数据集上，分类O米的测试AUC达到了0.953。", "conclusion": "ECG-SMART-NET在阻塞性心肌梗死预测任务中性能优于最先进的随机森林方法，并且比原始的ResNet-18架构更适合此任务。"}
{"llm_update_time": "2025-06-25 09:15:22", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.09838", "html_url": "https://arxiv.org/abs/2406.09838", "title": "ClimateIQA：气象异象分析中推进视觉语言模型的新数据集和基准", "title_en": "ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis", "authors": "Jian Chen,Peilin Zhou,Yining Hua,Dading Chong,Meng Cao,Yaowei Li,Zixuan Yuan,Bing Zhu,Junwei Liang", "background": "气象热图在解释极端天气现象中扮演着重要角色，但由于其不规则轮廓、不结构化的模式和复杂颜色变化的特点，给最先进的视觉-语言模型（VLMs）带来了独特的分析挑战。当前最先进的模型如GPT-4o、Qwen-VL和LLaVA 1.6在精细颜色识别和空间定位任务上表现不佳，导致结果不准确或不完整。例如，这些模型在处理不规则形状的彩色区域时遇到困难，影响了它们对极端天气特征的解释和描述准确性。", "innovation": "针对上述挑战，本文提出了Sparse Position and Outline Tracking (SPOT)算法，通过提取区域的空域坐标来识别和定位不规则形状的彩色区域，使其能够为不规则形状提供结构化的表示。基于SPOT，本文构建了ClimateIQA数据集，包含26,280个高分辨率的热图和762,120个关于风速、总降水量、风寒指数和热指数分析的指令样本。ClimateIQA通过整合空间线索、地理元数据和再分析数据增强了VLM的训练，提高了模型在解释和描述极端天气特征方面的准确性。此外，还开发了Climate-Zoo，这是基于SPOT增强ClimateIQA的一系列微调VLMs模型，这些模型在气象热图任务上显著优于现有模型。", "conclusion": "ClimateIQA数据集和基于SPOT的新Vision-Language模型显著改善了气象异象分析中VLM的性能，提供了更准确和详细的极端天气特征的解释和描述，推动了视觉-语言模型在气象领域的应用和发展。"}
{"llm_update_time": "2025-06-25 09:15:23", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.08809", "html_url": "https://arxiv.org/abs/2406.08809", "title": "我们在吗？音乐情感预测数据集、模型和待解决的挑战", "title_en": "Are We There Yet? A Brief Survey of Music Emotion Prediction Datasets, Models and Outstanding Challenges", "authors": "Jaeyong Kang,Dorien Herremans", "background": "近年来，基于深度学习的音乐模型取得了显著进步，但机器学习模型在捕捉情感方面的能力如何？研究人员正在面临哪些挑战？本文提供了一个涵盖现有音乐情感数据集的全面概述，并讨论了该领域的评估标准及竞赛。同时，本文简要回顾了多年来构建的各种类型的情感预测模型，揭示了该领域多样性的方法。通过对这些模型的检验，本文突出了在音乐中准确捕捉情感所面临的持续挑战，包括数据集质量、注释一致性及模型泛化性的问题。此外，本文还探讨了不同模态（如音频、MIDI和生理信号）对情感预测模型有效性的影响，并指出在音乐情感识别（MER）方面存在的持续挑战，包括数据集质量、情感标签的模糊性以及跨数据集泛化的困难。", "innovation": "本文提供了现有音乐情感数据集的全面概述，并讨论了关于数据集质量、注释一致性以及模型泛化的挑战。同时，本文还重点关注不同模态对情感预测模型有效性的影响，指出基于MER的未来进步需要标准化基准数据集、更大的多样数据集和增强模型解释性。此外，本文还伴随有一个GitHub仓库，列出了音乐情感数据集的综合列表和最近的预测模型。", "conclusion": "本文通过总结相关挑战，强调了标准化基准数据集、更大和更多样化数据集以及提高模型可解释性的需求。同时，说明了为更好地理解和改进音乐情感识别技术的努力。该研究旨在识别音乐情感识别(MER)领域的主要挑战，并提出未来工作需要重点考虑的问题。"}
{"llm_update_time": "2025-06-25 09:15:24", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.08844", "html_url": "https://arxiv.org/abs/2404.08844", "title": "ContactDexNet：通过手物接触语义映射实现拥挤环境中的多指灵巧手抓取", "title_en": "ContactDexNet: Multi-fingered Robotic Hand Grasping in Cluttered Environments through Hand-object Contact Semantic Mapping", "authors": "Lei Zhang,Kaixin Bai,Guowen Huang,Zhenshan Bing,Zhaopeng Chen,Alois Knoll,Jianwei Zhang", "background": "深度学习模型显著提升了多指灵巧手的抓取技术，但在处理拥挤环境中接触信息引导的抓取问题上，研究仍然相对较少。本研究旨在解决此问题，通过接触语义图生成方法，提出了一种多指灵巧手在拥挤环境中的抓取样本生成方法。该方法利用对象点云生成综合接触语义图，并通过抓取检测方法估计手抓取姿态，最后设计了一种统一的抓取评估模型，PointNetGPD++，以评估抓取质量和碰撞概率，从而在拥挤场景中提高识别最优抓取的可靠性。该研究方法在真实环境下单对象环境和拥挤场景中分别实现了81.0%和75.3%的抓取成功率，优于现有最先进的方法4.65%以上。研究还提出了一种多模态多指灵巧手抓取数据集生成方法，其在场景多样性和模态多样性上优于以往的数据集。研究数据、代码及补充材料可在此网址查找：this https URL.", "innovation": "1. 通过接触语义图生成方法生成多指灵巧手在拥挤环境中的抓取样本。2. 引入了一种接触语义条件变分自编码网络（CoSe-CVAE），从对象点云中生成综合接触语义图。3. 利用抓取检测方法从接触语义图中估计手抓取姿势。4. 设计了一种统一的抓取评估模型（PointNetGPD++）来评估抓取质量和碰撞概率，显著提高在拥挤场景中识别最优抓取的可靠性。5. 提出了一种多模态多指灵巧手抓取数据集生成方法，在多样性和模态多样性上优于以往的数据集。", "conclusion": "该方法在真实环境下单对象环境和拥挤场景中实现了显著的抓取成功率，优于现有最先进的方法4.65%以上，展示了其在拥挤环境多指灵巧手抓取方面的出色性能。"}
{"llm_update_time": "2025-06-25 09:15:24", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.16804", "html_url": "https://arxiv.org/abs/2407.16804", "title": "多模态机器学习在心理健康中的应用：数据、算法与挑战的综述", "title_en": "Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges", "authors": "Zahraa Al Sahili,Ioannis Patras,Matthew Purver", "background": "多模态机器学习（MML）正在迅速改变精神健康障碍的检测、表征和纵向监测方式。早期研究依赖于单一的数据流（如语音、文本或可穿戴传感器信号），而最近的研究集中在集成多种异构模态的架构上，以捕捉精神病态的丰富多彩和复杂的特征。本文提供了对多模态机器学习在精神健康中的第一个综合、临床接地的综述。", "innovation": "整理了26个涵盖音频、视觉、生理信号和文本模态的公共数据集；系统比较了28种模型中的变压器、图和混合基融合策略，展示了表示学习和跨模态对齐的趋势。除此之外，还探讨了开放的挑战，包括数据治理和隐私、人口统计学和交叉公平性、评估解释性和多模态背景下精神健康疾病的复杂性。", "conclusion": "通过方法创新与精神健康实用性相结合，本文旨在引导机器学习研究人员和精神健康从业人员向下一代值得信赖的多模态决策支持系统方向迈进。"}
{"llm_update_time": "2025-06-25 09:15:25", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.06976", "html_url": "https://arxiv.org/abs/2407.06976", "title": "Jagiellonian University文化遗产项目中丰富互操作元数据", "title_en": "Rich Interoperable Metadata for Cultural Heritage Projects at Jagiellonian University", "authors": "Luiz do Valle Miranda,Krzysztof Kutt,Elżbieta Sroka,Grzegorz J. Nalepa", "background": "现今存放在图书馆中的对象已创建了大量的元数据，但这些元数据无法存储。现有的核心标准，如MARC 21和Dublin Core，不够灵活，无法满足存储需求。Jagiellonian大学（JU）的研究针对文化遗产对象的元数据进行了探索，将JU正收集的多个类型的文化遗产元数据与其常用的标准进行了比较，旨在解决这些标准间相互映射的问题，以实现最大化的互操作性。", "innovation": "比较并分析了JU文化遗产集合中多个元数据标准（如Dublin Core, EAD, MODS, EDM, Digital Scriptorium）的互操作性。根据比较结果，提出了该领域的进一步工作需求及其要求，旨在建立一个有利于不同元数据格式集成和互操作的JU文化遗产元数据模式。", "conclusion": "基于逐步版本的概念模型对提出的映射概念进行实验，以验证其实际可行性，并测试该模型是否能够实现在这些元数据格式之间的整合。从初步结果来看，尽管存在困难，但已经确定了实现最大互操作性的关键要求。"}
{"llm_update_time": "2025-06-25 09:15:28", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.14781", "html_url": "https://arxiv.org/abs/2405.14781", "title": "通过去学习和重学习仅使用少量干净样本统一神经后门去除", "title_en": "Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning", "authors": "Nay Myat Min,Long H. Pham,Jun Sun", "background": "深度神经网络在各种应用中取得了显著的成功，但它们对后门攻击的脆弱性造成了严重的安全风险，尤其是在仅可用少量干净样本进行防御的情况下。", "innovation": "提出了一个新的两阶段方法ULRL（去学习和重学习以去除后门），该方法首先通过最大化网络在小规模干净数据集上的损失来发现过度敏感于后门触发器的神经元，然后通过目标重初始化和余弦相似度正则化重新校准这些可疑神经元，从而有效消除后门影响同时保持模型在良性数据上的性能。该方法在CIFAR-10、CIFAR-100、GTSRB和Tiny-ImageNet等多个数据集及PreAct-ResNet18、VGG19-BN和ViT-B-16等多个架构上进行了广泛的实验，结果表明，即使仅使用1%的干净数据进行防御，ULRL也能显著降低攻击成功率，不牺牲干净准确率。", "conclusion": "ULRL在少量干净样本的支持下，可以显著减少后门攻击的成功率，而不会损害对正常数据的预测准确度。"}
{"llm_update_time": "2025-06-25 09:15:32", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.16767", "html_url": "https://arxiv.org/abs/2408.16767", "title": "ReconX: 使用视频扩散模型从稀疏视角重建任意场景", "title_en": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model", "authors": "Fangfu Liu,Wenqiang Sun,Hanyang Wang,Yikai Wang,Haowen Sun,Junliang Ye,Jun Zhang,Yueqi Duan", "background": "3D场景重建技术已经能够将现实世界的2D图像转化为3D模型，并从数百张输入照片中生成逼真的3D结果。尽管在密集视角重建场景取得了巨大成功，但从不足的拍摄视角重建详细场景仍然是一个棘手的优化问题，这往往会导致未见区域出现伪影和失真。", "innovation": "作者提出了一种名为ReconX的新颖3D场景重建方法，通过重新定义模糊的重建挑战为时间生成任务，利用大规模预训练的视频扩散模型的强大生成先验进行稀疏视角重建。同时，通过构建全局点云并编码进入上下文空间作为3D结构条件，增加了视图一致性，确保从不同视角的场景连贯性。最后，通过一种基于置信度的3D高斯散点图优化方案从生成的视频中恢复3D场景。实验表明，在质量和可泛化性方面，ReconX都优于现有最先进的方法。", "conclusion": "ReconX方法展示了在稀疏视角重建时的优越性能，尤其是在3D视图一致性和场景连贯性方面的表现，这主要得益于利用大规模预训练的视频扩散模型的强大生成先验和创新的优化策略。"}
{"llm_update_time": "2025-06-25 09:15:33", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05563", "html_url": "https://arxiv.org/abs/2410.05563", "title": "大型语言模型的理性元推理", "title_en": "Rational Metareasoning for Large Language Models", "authors": "C. Nicolò De Sabbata,Theodore R. Sumers,Badr AlKhamissi,Antoine Bosselut,Thomas L. Griffiths", "background": "使用大型语言模型（LLMs）进行推理已成为一种核心技巧，通过在推理时增加计算量来提高任务性能。然而，随着LLMs在规模和普及上的增加，推理成本也在不断增加。如何优化推理的成本-性能权衡是亟待解决的问题.", "innovation": "本文提出了一种基于认知科学中的元推理计算模型的新方法，即训练LLMs只在必要时使用中间推理步骤。通过纳入计算价值的奖励函数和专家迭代来训练LLMs，相比链式思维少样本提示和STaR方法，本方法显著降低了推理成本（节省了20-37%的生成标记量），同时保持了在不同数据集上的任务性能.", "conclusion": "研究结果表明，通过使用训练LLMs以在必要时进行选择性推理的新方法，可以在维持性能的同时显著降低推理成本，解决了LLMs规模扩大带来的成本负担问题."}
{"llm_update_time": "2025-06-25 09:15:33", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.08405", "html_url": "https://arxiv.org/abs/2401.08405", "title": "探究AI：揭秘ChatGPT中出现的有趣互动", "title_en": "Interrogating AI: Characterizing Emergent Playful Interactions with ChatGPT", "authors": "Mohammad Ronagh Nikghalb,Jinghui Cheng", "background": "随着人工智能（AI）能力和影响力的增长，近年来的技术进步正在重新定义人机交互（HCI）和计算机支持的协作工作（CSCW）对AI的看法。虽然娱乐互动被认为是让用户更好地理解不断变化的AI技术的一种方式，但这一领域仍处于研究的初级阶段，尚未被充分探讨。本研究旨在填补这一空白，通过分析来自Reddit上ChatGPT子版块的372条用户生成帖子，揭示用户与ChatGPT之间互动的多样性。研究表明，超过一半（54%）的用户言论都涉及娱乐互动，进一步分析构建了一个初步框架来描述这些互动，将它们分为六类：反思、开玩笑、模仿、挑战、捉弄和创造；每类都有细分。", "innovation": "本研究通过分析Reddit上ChatGPT子版块的数据，识别了用户与AI之间各种娱乐互动的方式，特别是在理解和应对AI的自主性方面的作用。它还为设计AI系统提供了参考性的见解，探索了用户与AI互动对构建人机关系的影响。这些发现对于HCI和CSCW领域具有重要意义，填补了该领域研究的空白，提供了新的研究视角和理论支持。", "conclusion": "本研究为HCI和CSCW领域提供了一个初步的框架，描述了用户与AI之间娱乐互动的多样性，揭示了娱乐互动如何帮助用户理解AI的自主性，塑造人机关系，并为设计AI系统提供参考性见解。"}
{"llm_update_time": "2025-06-25 09:15:38", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.02978", "html_url": "https://arxiv.org/abs/2408.02978", "title": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval", "title_en": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval", "authors": "Ruixiang Zhao,Jian Jia,Yan Li,Xuehan Bai,Quan Chen,Han Li,Peng Jiang,Xirong Li", "background": "电子商务日益丰富多媒体内容，商品以图片、短视频或直播促销等多种形式展示。在这种广泛的领域中，统一且矢量化的产品多模态表示是必需的。传统的视觉表示方式由于同产品内部多样性和跨产品相似性的高要求变得不足。尽管从短视频或直播中提取的自动语音识别(ASR)文本可以轻易获取，但如何清除其中的噪声以便于多模态表示学习尚未得到充分研究。本文背景在于解决这一问题，提高跨领域产品检索的效果。", "innovation": "本文提出了一种名为ASR-enhanced Multimodal Product Representation Learning (AMPere)的方法。AMPere使用基于LLM的ASR文本摘要，从原始ASR文本中提取产品特定信息。结合视觉数据，输入到一个多分支网络中生成紧凑的多模态嵌入。通过大尺度三领域数据集的实验验证了AMPere的有效性，明显提升了跨领域产品检索的效果。", "conclusion": "研究通过AMPere有效地整合了视觉和文本多模态信息，提供了一个统一且矢量化的跨领域产品表示。ASR提取的文本信息通过LLM得到有效清理和摘要，增强了跨领域产品检索的质量。"}
{"llm_update_time": "2025-06-25 09:15:39", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.17933", "html_url": "https://arxiv.org/abs/2410.17933", "title": "使用区块链促进的联邦学习进行多大陆医疗建模", "title_en": "Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning", "authors": "Rui Sun,Zhipeng Wang,Hengrui Zhang,Ming Jiang,Yizhe Wen,Jiahao Sun,Xinyu Qu,Kezhi Li", "background": "在医疗领域构建人工智能模型最大的挑战之一是数据共享。由于医疗数据具有高度的私密性、敏感性和异构性，收集足够用于建模的数据耗时、昂贵且有时不可能。", "innovation": "本文提出了一种框架，在不共享本地数据的情况下，利用来自多个大陆（欧洲、北美和亚洲）的医疗数据集实现全球医疗建模，并使用血糖管理作为案例研究验证其有效性。技术上，通过区块链实现联邦学习，并调整以满足医疗数据的隐私和安全要求，同时利用区块链上的激励机制奖励诚实参与并惩罚恶意行为。实验结果显示，所提出的框架有效、高效且能够保护隐私。其预测精度优于仅限于有限个人数据训练的模型，在某些情况下，甚至能达到或略微优于集中学习的结果，同时保持数据隐私。这项工作为国际医疗项目合作铺平了道路，可通过提供更多样化数据来减少偏差，为人类造福，", "conclusion": "这项工作证明了基于区块链的联邦学习框架在国际多大陆医疗建模中的高效性和隐私保护性，为跨地域的医疗合作提供了新的可能，并提升了模型预测的准确性。"}
{"llm_update_time": "2025-06-25 09:15:41", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02065", "html_url": "https://arxiv.org/abs/2412.02065", "title": "利用大规模语言模型使学术研究中的昂贵数据集获取更加民主化", "title_en": "Leveraging Large Language Models to Democratize Access to Costly Datasets for Academic Research", "authors": "Julian Junyan Wang,Victor Xiaoqi Wang", "background": "长期以来，不平等的数据访问权限制了不占优势的机构中的研究人员的研究能力，影响了他们的研究贡献和职业发展。大型语言模型（LLMs）的最新突破可能通过自动化从非结构化来源收集数据来实现数据获取的民主化。之前手动收集数据需要数百小时，而商业数据库订阅则需要数千美元。本文旨在解决这一问题，展示了一种新方法，该方法使用GPT-4o-mini在检索增强生成（RAG）框架下从企业披露中收集数据。这种方法在收集CEO薪酬比例和关键审计事项方面达到了人类级别的准确性，并且成本低于10美元，时间也明显降低。", "innovation": "开发了一种使用GPT-4o-mini和检索增强生成（RAG）框架来从企业披露中自动化收集数据的新方法。这种方法在收集CEO薪酬比例和关键审计事项方面达到了人类级别的准确性，处理时间和成本远低于传统方法。", "conclusion": "为了促进一个更加包容的研究社区，本文分享了该方法和由此产生的数据集，以助力资源有限的研究人员探索新的研究领域。"}
{"llm_update_time": "2025-06-25 09:15:45", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.00099", "html_url": "https://arxiv.org/abs/2412.00099", "title": "为高效移动设备推理设计的基于缓存条件的专家混合模型", "title_en": "Mixture of Cache-Conditional Experts for Efficient Mobile Device Inference", "authors": "Andrii Skliar,Ties van Rozendaal,Romain Lepert,Todor Boinovski,Mart van Baalen,Markus Nagel,Paul Whatmough,Babak Ehteshami Bejnordi", "background": "混合专家（MoE）大型语言模型通过在每个输入中选择性地激活专门化的子网络或‘专家’来提高性能，但将其部署在内存受限的设备上仍然具有挑战性，特别是在逐个生成令牌时，且批处理大小为一，而非通常涉及长序列或大批次的高吞吐量设置。本文针对只有部分专家权重能装入DRAM的内存受限设备优化MoE模型，在此环境中介绍了一个新的基于缓存的路由策略，以提高缓存局部性，在生成令牌时利用专家的重用率。", "innovation": "提出了一种新的基于缓存的路由策略，该策略利用生成令牌过程中专家的重用来改善缓存局部性。与典型的高吞吐量设置相比，在内存受限的移动设备上，这一策略表现出了灵活性和效率，提供了一个无需训练的解决方案，以扩展MoE在现实世界应用中的适用性。", "conclusion": "该方法在语言建模、MMLU和GSM8K基准测试上进行了评估，并在移动设备上取得了2倍的加速效果，展示了其在实际应用中的潜力。"}
{"llm_update_time": "2025-06-25 09:15:46", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.18140", "html_url": "https://arxiv.org/abs/2406.18140", "title": "跨域专属样式去除用于新型类发现", "title_en": "Exclusive Style Removal for Cross Domain Novel Class Discovery", "authors": "Yicheng Wang,Feng Liu,Junmin Liu,Kai Sun", "background": "在开放世界学习领域中，新型类发现（NCD）通常是指基于同一领域内标记数据的先验知识，将未标记的集合中的未见过的新类进行聚类。然而，当新型类从与标记数据不同分布中抽取时，现有NCD方法的性能可能严重受损。本文基于这种必要条件研究和建立了跨域设置下NCD问题的可解性，且提出了一个用于去除基线特征中独特样式信息的专属样式去除模块。该模块能够轻松与现有的NCD方法集成，从而在新型类与标记数据有不同的分布时提高性能。此外，本文还建立了未来NCD研究的公平基准，以应对不同基础架构和预训练策略对NCD方法性能的影响。通过三种常见数据集的广泛实验，证明了我们提出的样式去除策略的有效性。", "innovation": "提出了一个专属样式去除模块，用于提取与基线特征不同的样式信息，该模块易于与其他NCD方法结合，特别适用于处理不同分布的新类，并构建了一个公平基准以评估不同基础架构和预训练策略对NCD性能的影响。", "conclusion": "提出的跨域设置下新型类发现的新策略在三种常见数据集上的广泛实验表明其有效性，并通过建立公平基准指出了未来研究的方向。"}
{"llm_update_time": "2025-06-25 09:15:47", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.10394", "html_url": "https://arxiv.org/abs/2409.10394", "title": "MOST: MR reconstruction Optimization for multiple downStream Tasks via continual learning", "title_en": "MOST: MR reconstruction Optimization for multiple downStream Tasks via continual learning", "authors": "Hwihun Jeong,Se Young Chun,Jongho Lee", "background": "现有的基于深度学习的磁共振（MR）重建方法主要关注生成高质量的图像，但往往忽略了这些重建图像对后续任务（如分割）的影响。通过分别训练重建网络和下游任务网络进行级联处理，可能会导致性能下降，因为训练数据集之间的领域差距以及误差传播。尽管针对单个下游任务提出了任务导向的重建优化，但将其扩展到多任务场景并不容易。本文扩展了这种优化方法，以应对顺序引入的多个下游任务，证明了一个单一的MR重建网络可以通过连续学习（MOST）被优化，以适应多个下游任务。除了使用重播式连续学习和图像引导损失来克服灾难性遗忘，MOST还在多任务场景下表现优异，相较于无需微调的重建网络、简单的微调方法以及传统连续学习方法，OST均表现出更优的效果。文中指明了可以访问源代码的方法。", "innovation": "MOST是一个新的方法，旨在通过连续学习（Continual Learning）优化MR重建网络，以适应多个下游任务（如分割）。它综合利用了重播式连续学习和图像引导损失来解决灾难性遗忘的问题。该方法不仅适用于单个下游任务，还可以扩展到多个下游任务，从而提高重建网络在多任务场景下的性能。与常规方法相比，MOST展示了更好的性能，特别是在连续学习的背景下，有效解决了多任务学习中的灾难性遗忘问题。", "conclusion": "本文提出了一种新的方法——MOST，通过连续学习优化MR重建网络，使单一的重建网络能够适应多个下游任务。实验结果表明，MOST在多任务场景下优于无微调、简单微调和传统的连续学习方法。该方法综合了重播式连续学习和图像引导损失，有效克服了灾难性遗忘的问题，为未来的多任务磁共振图像处理提供了新的思路。"}
{"llm_update_time": "2025-06-25 09:15:48", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.18259", "html_url": "https://arxiv.org/abs/2406.18259", "title": "检测机器生成文本：不仅仅是'AI vs 人类'，解释性复杂", "title_en": "Detecting Machine-Generated Texts: Not Just \"AI vs Humans\" and Explainability is Complicated", "authors": "Jiazhou Ji,Ruizhe Li,Shujun Li,Jie Guo,Weidong Qiu,Zheng Huang,Chiyu Chen,Xiaoyu Jiang,Xinru Lu", "background": "随着大型语言模型（LLM）的迅速发展，关于在线和现实世界中文本实际作者身份的风险引起了越来越多的关注。区分由LLM生成的文本变得复杂，因为机器和人类的行为在细微之处互相重叠。当前的做法是将LLM生成文本的检测视为二元分类任务，即将人类文本与AI文本区分开来。但本文挑战了这一做法，提出了一种新的三元文本分类方案，即增加一个“未决”类别，说明可以归因于两种来源中的任何一个。这一新分类对于实现检测结果对普通用户的可解释性至关重要。", "innovation": "提出了新的三元文本分类方案，增加了“未决”类别，用于鉴定可能源于两方来源的文本。此外，通过对比解释性最佳的检测系统和人类注释员的解释笔记，揭示了机器生成文本可解释性检测的复杂性，并提出了改进未来检测系统的建议。这些创新之处改变了单纯的分类任务，强调了提供清晰、易懂的解释的必要性，从而增强用户对检测结果的理解。", "conclusion": "通过新的三元分类方案，可以更好地解释机器生成的文本，增强解释能力。该研究凸显了“未决”类别在可解释性方面的重要性，并提出了开发未来具有更强大解释能力的检测系统的指导方针。"}
{"llm_update_time": "2025-06-25 09:15:50", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02690", "html_url": "https://arxiv.org/abs/2502.02690", "title": "具备可证明分离性的可控制视频生成", "title_en": "Controllable Video Generation with Provable Disentanglement", "authors": "Yifan Shen,Peiyuan Zhu,Zijian Li,Shaoan Xie,Zeyu Tang,Namrata Deka,Zongfang Liu,Guangyi Chen,Kun Zhang", "background": "尽管最近在生成高质量和一致性的视频方面取得了进展，但控制视频生成仍然是一个重大挑战。现有大多数方法将视频视为整体处理，忽略了复杂的细粒度时空关系，这限制了控制精度和效率。", "innovation": "我们提出了可控制视频生成对抗网络（CoVoGAN），将视频概念解耦，实现了对单个概念的有效而独立的控制。通过最小变化原则，首先解耦静态和动态潜变量。然后利用充分变化属性实现动态潜变量的组件级可识别性，从而实现视频生成的解耦控制。为建立理论基础，我们进行严格的分析，证明了该方法的可识别性。设计了时间过渡模块来解耦潜动态。为了确保最小变化原则和充分变化属性，我们减少了潜动态变量的维度，并施加了时间条件独立性。", "conclusion": "在多种视频生成基准上的广泛质性和量化实验表明，我们的方法在多种真实世界场景中显著提高了生成质量和可控性。"}
{"llm_update_time": "2025-06-25 09:15:50", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.15276", "html_url": "https://arxiv.org/abs/2501.15276", "title": "探索与AI的合作共创过程：新生音乐制作中的案例研究", "title_en": "Exploring the Collaborative Co-Creation Process with AI: A Case Study in Novice Music Production", "authors": "Yue Fu,Michele Newman,Lewis Going,Qiuzi Feng,Jin Ha Lee", "background": "人工智能正在重新定义创意领域，但在团队环境中，特别是在新手用户参与的情况下，其协同创作过程仍旧研究不足。鉴于这一研究空白，本文通过在大学课程中进行的一项案例研究，探索人工智能在音乐创作中的协同创作过程。研究期间，九名大学生使用AI工具创作了三首原创音乐作品，整个过程包括从构思到在Spotify发布音乐。研究发现AI改变了创意工作流程，加速了构思环节，但压缩了传统的准备阶段，并使新手面临一个具有挑战性的创意选择和验证阶段。此外，还发现了新的“拼接与完善”阶段，在这个阶段，参与者将多种AI生成的输出组合成统一的作品。AI还影响了团队的社会动态和人类创作者之间的分工。基于以上观察，本文提出了人类与AI协作共创阶段模型和人类与AI代理模型，为人工智能在协作创作中的角色提供了新的视角。", "innovation": "本文创新地通过大学课程中的案例研究，详细调查了人工智能在音乐创作中的协同创作过程。提出了人类与AI协作共创阶段模型和人类与AI代理模型，为领域内的研究提供了新的视角。研究还发现了一种新的“拼接与完善”阶段，这种阶段在AI辅助创作中具有重要意义，展示了AI对人类创作过程的具体影响。此外，研究还揭示了AI如何影响团队动态和人类创作者之间的角色分工。这些发现填补了现有文献中关于新手用户在AI辅助创作环境中的协作过程的空白，为未来相关研究提供了有价值的数据和理论依据。", "conclusion": "研究表明，人工智能在协同创作中的应用具有显著的积极影响，尤其是在新手用户参与的情况下。模型的提出为理解人类与AI协作共创过程提供了新的框架，有助于促进未来相关领域的研究和发展。"}
{"llm_update_time": "2025-06-25 09:15:53", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12743", "html_url": "https://arxiv.org/abs/2502.12743", "title": "我了解自己更好，但并没有显著地更好：LLM能多准确地检测和解释由LLM生成的文本", "title_en": "\"I know myself better, but not really greatly\": How Well Can LLMs Detect and Explain LLM-Generated Texts?", "authors": "Jiazhou Ji,Jie Guo,Weidong Qiu,Zheng Huang,Yang Xu,Xinru Lu,Xiaoyu Jiang,Ruizhe Li,Shujun Li", "background": "鉴于大模型(LLM)存在被误用的风险，区分人类生成和大模型生成的文本变得至关重要。本文研究了当前大模型在两种设置下的检测和解释能力，包括二分类（人类生成 vs. 大模型生成）和三分类（包含不确定类别）。", "innovation": "引入了三分类框架，相比二分类提高了所有模型的检测准确性和解释质量。通过综合定量和定性的分析，本文识别出了关键的解释失败原因，包括依赖不准确的特征、幻觉和错误的推理。这些结果突显了当前大模型在自我检测和自我解释方面的局限性，强调了进一步研究的必要性，以解决过拟合并增强泛化能力。", "conclusion": "当前大模型的自我检测和自我解释仍然存在不足。作者认为需要进一步研究以减少过拟合并提高模型的泛化能力。"}
{"llm_update_time": "2025-06-25 09:15:55", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08365", "html_url": "https://arxiv.org/abs/2502.08365", "title": "通过任务无关探索实现无监督多智能体强化学习", "title_en": "Towards Unsupervised Multi-Agent Reinforcement Learning via Task-Agnostic Exploration", "authors": "Riccardo Zamboni,Mirco Mutti,Marcello Restelli", "background": "在强化学习中，我们通常在没有先验任务规范（如奖励）的情况下预先训练一个策略，以便为下游任务的高效学习做准备，这称为无监督预训练。对于单智能体设置，这个问题已经被广泛研究并基本理解。一种流行的策略是任务无关的探索，目标是最大化由智能体策略诱导的状态分布熵。相比之下，多智能体设置的问题在实际应用中普遍存在，但我们对其了解甚少。不同的问题表述形式有什么优缺点？该问题理论上有多难，我们如何在实践中解决它？", "innovation": "本文通过分析不同的问题表述，指出了该问题即使在理论上可解但在实践中也是非平凡的。接着，提出了一个可扩展的、去中心化的、带有信任区域的策略搜索算法，用以解决实际中的问题。最后，通过数值验证支持理论发现，并为多智能体无监督强化学习任务无关探索铺垫道路，表明混合熵优化为可操作性和性能之间提供了良好的权衡。", "conclusion": "认为通过优化混合熵可以提供一个良好的平衡点，既满足了可操作性，又保持了性能。"}
{"llm_update_time": "2025-06-25 09:15:55", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12777", "html_url": "https://arxiv.org/abs/2502.12777", "title": "评估链预测：新视角和建议", "title_en": "Evaluating link prediction: New perspectives and recommendations", "authors": "Bhargavi Kalyani I,A Rama Prasad Mathi,Niladri Sett", "background": "链预测(LP)是网络科学和机器学习研究中的一个重要问题。最先进的方法通常在一个统一的框架下进行评估，忽略了与数据和应用特定需求相关的多个因素。作者指出了网络类型、问题类型、端节点之间的测地距离及其在类间的分布、链预测方法的性质及其适用性、类不平衡及其对早期检索的影响、评估指标等因素，并提出了一种实验框架，使我们可以以严格和受控的方式评估链预测方法。", "innovation": "作者通过提出各种实验假设，进行了一系列针对真实网络数据集的广义链预测方法的实验，从而深入研究了这些因素与链预测性能之间的相互作用。根据所得洞见，作者提出了评估链预测方法的最佳实践建议.", "conclusion": "在受控实验框架下进行详尽的链预测方法实验，通过精心设计的假设，获得了宝贵的见解，研究了影响链预测性能的多种因素之间的相互作用，并提出了评估链预测方法的最佳实践建议。"}
{"llm_update_time": "2025-06-25 09:15:57", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.01933", "html_url": "https://arxiv.org/abs/2408.01933", "title": "在可问责的关键任务中评估大型语言模型的透明推理", "title_en": "Evaluating Transparent Reasoning in Large Language Models for Accountable Critical Tasks", "authors": "Junhao Chen,Bowen Wang,Jiuyang Chang,Yuta Nakashima", "background": "本文介绍了REACT基准，该基准旨在严格评估大型语言模型（LLMs）在医学和法律等高风险决策任务中的推理能力。与主要关注预测准确性的传统评估标准不同，REACT强调透明和可解释的推理，要求模型的逻辑紧密符合专家制定的程序。为了评估LLM的推理是否与人类专家相符，研究人员对511个医学案例和86个法律案例进行了标注，每个案例都附有详细的专家提取的推理和证据，支持每一步的推理过程。这些标注由精心构建的推理图引导，该图明确编码了领域专家导出的推理结构和决策准则。推理图不仅作为专家标注的标准，还作为结构化的指导方针，使模型能够透明地逐步进行推理。为了应对手工标注的规模挑战，研究人员还开发了一种半自动标注流水线，利用专家定义的推理图模板高效生成新的图，探索将此方法扩展到其他关键领域的潜力。实验结果表明，推理图显著提高了LLM推理的可解释性和准确性，尽管与专家级推理性能相比，仍存在显著差距。", "innovation": "REACT基准的独特之处在于它特别关注透明和可解释的推理，要求模型逻辑紧密与专家程序对齐。此外，研究人员开发了一种利用专家定义的推理图模板的半自动标注流水线，以提高标注效率，扩展到其他领域。推理图不仅作为专家标注的标准，还作为一种结构化的指南，帮助模型进行透明的、逐步的推理。这种方法显著提高了LLM推理的可解释性和准确性。", "conclusion": "实验结果表明，推理图方法显著提高了LLM推理的可解释性和准确性与传统方法相比，但仍存在与专家级推理性能的显著差距。未来的研究需要进一步改进模型，以缩小与专家级推理的差距。通过这种方法，研究人员为在高风险决策任务中使用LLMs提供了重要的评估框架。"}
{"llm_update_time": "2025-06-25 09:16:00", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17036", "html_url": "https://arxiv.org/abs/2502.17036", "title": "语言模型排序器因词汇相似性而受骗", "title_en": "Language Model Re-rankers are Fooled by Lexical Similarities", "authors": "Lovisa Hagström,Ercong Nie,Ruben Halifa,Helmut Schmid,Richard Johansson,Alexander Junge", "background": "语言模型（LM）排序器被用于增强检索-辅助生成（RAG）的检索结果，相较于如BM25等词汇匹配方法，它们被认为能更好地处理语义信息及查询与检索到的答案之间的关联。但是，研究者们并不确定LM排序器是否确实能够比BM25等方法在所有情况下都更有效。为了验证这一假设，本研究评估了6种不同的LM排序器在NQ、LitQA2和DRUID数据集上的性能，并使用一种新的基于BM25得分的分离度度量来解释和识别由于词汇差异引起的排序器错误，还调查了提高LM排序器性能的不同方法，并发现这些方法在NQ上更有用。", "innovation": "使用基于BM25得分的新分离度度量来解释和识别LM排序器错误，及其发现提高LM排序器性能的方法不仅局限于特定的数据集或场景。这些研究结果揭示了LM排序器的弱点，并表明需要开发更为对抗性和现实的数据集来进行评估。", "conclusion": "本研究识别并解释了LM排序器的弱点，并强调了需要开发更对抗性且现实的数据集来进行有效评估的必要性。"}
{"llm_update_time": "2025-06-25 09:16:03", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.18153", "html_url": "https://arxiv.org/abs/2502.18153", "title": "SASSHA：具有稳定近似海森矩阵的知晓尖锐度自适应二阶优化", "title_en": "SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation", "authors": "Dahun Shin,Dongyeop Lee,Jinseok Chung,Namhoon Lee", "background": "二阶优化方法通常在泛化性能上表现不如一阶方法。通过分析损失景观，该研究发现现有的二阶方法倾向于收敛到比SGD更尖锐的极小值。因此，该研究提出了一种名为Sassha的新颖二阶方法，通过显式减少尖锐度并稳定计算近似海森矩阵来增强泛化性能，同时确保效率和平坦度相结合。", "innovation": "Sassha是一种新型的二阶优化方法，通过动态减少解的尖锐度来增强泛化能力，同时通过稳定计算近似海森矩阵来提高计算的稳定性。该方法还能够适应懒惰的海森矩阵更新，以确保效率和平坦度", "conclusion": "Sassha在广泛的标准深度学习实验中表现出色，其泛化性能与甚至优于其他方法，验证了其有效性，并包括收敛性、鲁棒性、稳定性、效率和成本在内的全面分析。"}
{"llm_update_time": "2025-06-25 09:16:03", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.05730", "html_url": "https://arxiv.org/abs/2503.05730", "title": "Robust Optimization with Diffusion Models for Green Security", "title_en": "Robust Optimization with Diffusion Models for Green Security", "authors": "Lingkai Kong,Haichuan Wang,Yuqi Pan,Cheol Woo Kim,Mingxiao Song,Alayna Nguyen,Tonghan Wang,Haifeng Xu,Milind Tambe", "background": "在绿色安全领域，防御者必须预测敌对行为，如偷猎、非法砍伐和非法捕鱼，以制定有效的巡逻计划。这些行为通常具有很高的不确定性和复杂性。之前的研究所利用博弈论设计稳健的巡逻策略来应对不确定性，但现有的敌对行为模型主要依赖于高斯过程或线性模型，这些模型无法捕捉到复杂的行为模式。为了克服这一局限性，本文提出了一种条件扩散模型来建模敌对行为，利用其强大的分布拟合能力。这是首次将扩散模型应用于绿色安全领域。然而，将扩散模型整合到博弈论优化中带来了新的挑战，包括受限的混合策略空间和从未正规化的分布中抽样的需求，以估计效用。为了应对这些挑战，本文引入了混合策略的混合策略，并采用扭曲的顺序蒙特卡洛（SMC）抽样器进行准确的抽样。", "innovation": "提出了一种条件扩散模型来预测敌对行为，这种模型能够更好地捕捉行为模式。将扩散模型整合到博弈论优化中，开发了一种混合策略和扭曲的顺序蒙特卡洛（SMC）抽样器，解决了策略空间的限制和精度问题。理论上，算法确保在有限的迭代次数和样本数量下以高概率收敛到ε平衡点。", "conclusion": "通过评估我们的方法在合成和实际偷猎数据集上的表现，展示了其有效性和实用性。这是首次使用扩散模型在绿色安全领域进行优化研究，为未来的工作奠定了基础。"}
{"llm_update_time": "2025-06-25 09:16:04", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.18185", "html_url": "https://arxiv.org/abs/2502.18185", "title": "VesselSAM: 利用SAM进行带有AtrousLoRA的主动脉血管分割", "title_en": "VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with AtrousLoRA", "authors": "Adnan Iltaf,Rayan Merghani Ahmed,Zhenxi Zhang,Bin Li,Shoujun Zhou", "background": "医学图像分割对于临床诊断和治疗计划至关重要，特别是在处理复杂的血管结构时。然而，由于血管的小尺寸、复杂的边缘结构以及对伪影和成像噪声的敏感性，准确分割血管仍然具有挑战性。在这项工作中，我们提出了VesselSAM，这是一种增强版的Segment Anything Model (SAM)，特别适用于主动脉血管分割。VesselSAM结合了AtrousLoRA模块，该模块融合了空洞注意和低秩适配 (LoRA)，以提升分割性能。空洞注意使模型能够捕获多尺度上下文信息，保留细微的局部细节和更广泛的全局上下文。此外，LoRA 使冻结的 SAM 图像编码器能够更有效地微调，减少了可训练参数的数量，从而提高了计算效率。我们使用两个具有挑战性的数据集评估了VesselSAM：主动脉血管树 (AVT) 数据集和B型主动脉夹层 (TBAD) 数据集。结果表明，VesselSAM 在多中心数据集上实现了最先进的性能，DSC得分为93.50%，93.25%，93.02%，和93.26%。我们的研究结果表明，VesselSAM 在保持高分割准确性的前提下，显著降低了计算开销，相比于现有的大型模型具有显着优势。这为临床环境中增强的基于AI的主动脉血管分割铺平了道路。代码和模型将在此链接发布: this https URL", "innovation": "VesselSAM利用Atrous LoRA模块成为改进版的SAM模型，专为主动脉血管分割设计。该模型通过结合空洞注意和低秩适配模块，增强了多尺度上下文信息的捕获能力，同时提高了计算效率。VesselSAM在多个具有挑战性的数据集上的表现表现出色，得到了高质量的分割结果。", "conclusion": "VesselSAM通过引入AtrousLoRA模块，实现了主动脉血管分割的高准确性和计算效率的提升。该方法为临床环境中的基于AI的主动脉血管分割提供了新的工具，显著降低了计算负担，具有广泛的应用前景。"}
{"llm_update_time": "2025-06-25 09:16:07", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.05830", "html_url": "https://arxiv.org/abs/2503.05830", "title": "增强的人工智能审议民主与集体意志的未来", "title_en": "AI-Enhanced Deliberative Democracy and the Future of the Collective Will", "authors": "Manon Revel,Théophile Pénigaud", "background": "本文探讨了旨在找到集体偏好共同点的长期和新提出的计算框架的设计选择，并审视了它们在技术和规范层面的潜在未来影响。文章首先将人工智能辅助的偏好收集置于历史意见调查的角色中，强调偏好是由决策背景塑造的，并且很少客观地被捕捉到。在这一前提下，探讨了基于AI的民主创新作为发现工具，以促进合理地表达集体意志、意义构建和技术共识，同时对潜在的误导性使用提出了警告，如使决策具有法律约束力、渐进地剥夺权力或事后合理化政治结果等问题进行警示", "innovation": "本文探索了基于AI的民主创新作为发现工具，以促进合理地表达集体意志、意义构建和技术共识", "conclusion": "本文讨论了AI增强审议民主的潜力，同时也警告了其潜在的误导性和负面影响"}
{"llm_update_time": "2025-06-25 09:16:07", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.07501", "html_url": "https://arxiv.org/abs/2411.07501", "title": "Learned Augmented Residual Layer", "title_en": "LAuReL: Learned Augmented Residual Layer", "authors": "Gaurav Menghani,Ravi Kumar,Sanjiv Kumar", "background": "残差连接（Residual/skip connection）作为提高深度学习模型效率的核心技术之一，促进了模型的收敛和质量提升。这一技术现在不仅应用于卷积神经网络（CNN），也在基于变压器的大型语言模型（LLMs）中普及。研究者们希望找到一种既能提升模型性能又能更好地控制模型复杂度的技术。", "innovation": "本文提出了一种新型的残差连接扩展方法——Learned Augmented Residual Layer（LAuReL），旨在作为原生残差连接的在地替代方案，同时在模型质量和密度指标上都优于原生残差连接。LAuReL在视觉和语言模型中显示出显著的性能提升效果，特别是在参数数量较少的情况下。", "conclusion": "实验结果表明，LAuReL可以在保持模型性能的同时减少参数量。例如，在ResNet-50和ImageNet 1K任务中，使用LAuReL与增加额外一层相比，性能提升了60%，同时只有0.003%的额外参数；对于1B和4B参数的预训练LLMs，LAuReL在多种下游评估任务中的性能分别提高了2.54%到20.05%，而增加的参数量仅为0.012%和0.1%。"}
{"llm_update_time": "2025-06-25 09:16:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17332", "html_url": "https://arxiv.org/abs/2503.17332", "title": "CVE-Bench: AI智能代理利用现实世界Web应用漏洞的能力基准", "title_en": "CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real-World Web Application Vulnerabilities", "authors": "Yuxuan Zhu,Antony Kellermann,Dylan Bowman,Philip Li,Akul Gupta,Adarsh Danda,Richard Fang,Conner Jensen,Eric Ihli,Jason Benn,Jet Geronimo,Avi Dhir,Sudhit Rao,Kaicheng Yu,Twm Stone,Daniel Kang", "background": "大型语言模型（LLM）代理日益具备自主开展网络攻击的能力，对现有应用构成重大威胁。现有基准测试不足以应对这一日益增加的风险，因为这些基准测试要么局限于抽象的捕获旗联合竞赛，要么缺乏全面覆盖。构建针对真实世界漏洞的基准需要专门的知识来复现漏洞利用，并采取系统方法评估不可预测的威胁。因此，迫切需要一个适用于现实世界的基准测试来评估LLM代理利用Web应用漏洞的能力。", "innovation": "本文介绍CVE-Bench，一个基于重大严重性的常见漏洞和暴露（CVE）的真实世界网络安全基准，设计了沙箱框架，使LLM代理能够模仿现实世界条件利用漏洞的Web应用，同时对其漏洞利用效果进行有效评估。结果显示，最先进的代理框架可以解决高达13%的漏洞问题，表明了CVE-Bench对于评估智能代理能力的有效性。", "conclusion": "CVE-Bench基于现实世界的真实漏洞进行设计，为评估智能代理利用Web应用漏洞的能力提供了一个有效的基准。通过模仿现实场景，该基准有效地评估了此类代理的性能。"}
{"llm_update_time": "2025-06-25 09:16:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06469", "html_url": "https://arxiv.org/abs/2504.06469", "title": "AI辅助的放射性离子束运输", "title_en": "AI-Assisted Transport of Radioactive Ion Beams", "authors": "Sergio Lopez-Caceres,Daniel Santiago-Gonzalez", "background": "放射性重离子束能够帮助研究人员研究稀有的和不稳定的原子核，揭示奇怪核的内部结构，并了解化学元素如何在恒星中形成。然而，这些束流的提取和运输依赖于耗时的专家驱动的调整方法，需要手动优化成百上千的参数。", "innovation": "我们引入了一个系统，使用人工智能（AI），特别是贝叶斯优化，来辅助放射性离子束的运输过程。与标准调优方法相比，在实际场景中展示了其优势。这种方法还可以扩展到世界各地的其他放射性束流设施，以提高运营效率并增强科学产出。", "conclusion": "AI辅助的方法可以提高放射性离子束设施的运营效率并增强科学研究成果。"}
{"llm_update_time": "2025-06-25 09:16:10", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.03784", "html_url": "https://arxiv.org/abs/2504.03784", "title": "大型语言模型精细化调整中的人类反馈稳健强化学习", "title_en": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning", "authors": "Kai Ye,Hongyi Zhou,Jin Zhu,Francesco Quinzan,Chengchun Shi", "background": "强化学习从人类反馈（RLHF）已成为使大型语言模型（LLMs）的输出与人类偏好保持一致的关键技术。大多数现有RLHF算法使用Bradley-Terry模型来学习奖励函数，但该模型基于的人类偏好假设可能无法反映真实世界判断的复杂性和多样性。", "innovation": "本文提出了一种稳健算法，旨在在奖励函数模型错配的情况下提升现有方法的性能。该算法理论上有助于降低奖励和策略估计器的方差，从而改善后悔 bounds。实验证明，该算法在多个LLM基准数据集上表现优于现有方法，尤其在Anthropic Helpful and Harmless数据集上表现尤为突出，有77-81%的回应优于基线方法。", "conclusion": "提出的算法在奖励模型错配的情况下提升了RLHF方法的性能，通过降低估计器方差和改善后悔 bounds，使LLMs的输出更符合人类偏好，在实验证明中超越了现有基线方法。"}
{"llm_update_time": "2025-06-25 09:16:11", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18813", "html_url": "https://arxiv.org/abs/2503.18813", "title": "通过设计击败提示注入", "title_en": "Defeating Prompt Injections by Design", "authors": "Edoardo Debenedetti,Ilia Shumailov,Tianqi Fan,Jamie Hayes,Nicholas Carlini,Daniel Fabian,Christoph Kern,Chongyang Shi,Andreas Terzis,Florian Tramèr", "background": "大型语言模型（LLMs）越来越多地被部署在与不可信环境交互的代理系统中。然而，在处理不可信数据时，LLM代理容易受到提示注入攻击。在本文中，我们提出了一种名为CaMeL的健壮防御方法，该方法在LLM周围构建一个保护系统层，即使底层模型易受攻击也可确保安全。CaMeL通过显式地从（可信）查询中提取控制和数据流来运作，因此不可信数据无法影响程序流程。为了进一步提高安全性，CaMeL使用能力的概念来防止未经授权的数据流泄露私有数据，通过在调用工具时执行安全策略来防范数据泄露。我们通过AgentDojo验证了CaMeL的有效性，证明CaMeL在具有可证明安全性的任务中解决了77%的挑战，而未防御系统则解决了84%。我们发布了CaMeL，网址为：this https URL", "innovation": "提出了一种名为CaMeL的防御方法，该方法通过在LLM周围创建一个保护系统层，以确保即使在底层模型易受攻击的情况下也能安全运行。CaMeL通过显式从查询中提取控制和数据流来运作，并使用能力的概念来防止未经授权的数据流泄露私有数据，从而增强安全性。通过AgentDojo的实验表明，CaMeL可以解决具有可证明安全性的77%的任务，相比未防御系统提高了安全性。", "conclusion": "我们证明了CaMeL的有效性，并通过AgentDojo验证了其在安全性方面的表现，同时我们已经将其发布供进一步研究使用。"}
{"llm_update_time": "2025-06-25 09:16:17", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04359", "html_url": "https://arxiv.org/abs/2506.04359", "title": "cuVSLAM: CUDA加速的视觉里程计和建图", "title_en": "cuVSLAM: CUDA accelerated visual odometry and mapping", "authors": "Alexander Korovko,Dmitry Slepichev,Alexander Efitorov,Aigul Dzhumamuratova,Viktor Kuznetsov,Hesam Rabeti,Joydeep Biswas,Soha Pouya", "background": "自主机器人在执行任务时需要准确和鲁棒的位姿估计，这对实现自主导航和感知至关重要。传统的视觉同时定位与建图（VSLAM）方法在应用中通常依赖于特定的硬件配置，限制了它们在不同机器人平台上的广泛适用性。", "innovation": "cuVSLAM是针对视觉同时定位与建图的一种先进解决方案，能够适应多种视觉惯性传感组，包括多个RGB和深度摄像头以及惯性测量单元。cuVSLAM在边缘计算设备如NVIDIA Jetson上具有极低的计算开销，能够支持从单个RGB摄像头到多至32个摄像头的各种配置，并通过CUDA进行实时优化，保证高性能的机器人应用。", "conclusion": "我们在多个最先进的基准测试上展示了cuVSLAM的杰出性能，证明了其在广泛机器人设置中的适用性和鲁棒性。"}
{"llm_update_time": "2025-06-25 09:16:17", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14561", "html_url": "https://arxiv.org/abs/2505.14561", "title": "SSPS: 自监督正样本采样在鲁棒自监督说话人验证中的应用", "title_en": "SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification", "authors": "Theo Lepage,Reda Dehak", "background": "自监督学习(SSL)在说话人验证(SV)领域取得了显著进展。标准框架通常采用同方言语素正样本采样和数据增强方法来生成来自相同说话人的锚正样本对。这种方法的主要局限性在于它主要编码了录音条件的通道信息，这对不同录音条件下说话人的表现构成障碍。因此，论文提出了一种新的正样本采样技术：自监督正样本采样(SSPS)，以克服这一瓶颈，从而提高SV性能。", "innovation": "SSPS技术通过在潜在空间中使用聚类分配和正样本嵌入的内存队列来寻找与给定锚点相同说话人身份但不同录音条件的正例，从而解决了现有方法中对通道信息编码的问题。实验结果显示，SSPS在SimCLR和DINO模型上均提高了说话人验证性能，分别达到2.57%和2.53%的EER，超越了VoxCeleb1-O上现有的最佳SSL方法。在SimCLR-SSPS模型中，通过降低说话人内部方差实现了58%的EER减少，表现与DINO-SSPS模型相当，提供了可比的性能。", "conclusion": "SSPS显著改进了自监督说话人验证系统的性能，通过全新的正样本选择策略，使得系统在录音条件不同的情况下依然保持良好的性能，为自监督说话人验证领域的研究提供了新的思路和方法。"}
{"llm_update_time": "2025-06-25 09:16:17", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.21719", "html_url": "https://arxiv.org/abs/2410.21719", "title": "do_vendi_scores_converge_with_finite_samples_truncated_vendi_score_for_finite_sample_convergence_guarantees", "title_en": "Do Vendi Scores Converge with Finite Samples? Truncated Vendi Score for Finite-Sample Convergence Guarantees", "authors": "Azim Ospanov,Farzan Farnia", "background": "无参考数据评估生成模型多样性的方法存在方法论挑战。Vendi和RKE分数通过矩阵熵措施量化生成数据的多样性。Vendi分数通常通过生成样本构建的$n \times n$核矩阵的特征分解计算。然而，大型$n$值下的特征分解计算成本限制了使用的样本数量少于20,000个。本文研究了在受限样本量下的Vendi和RKE分数的统计收敛性。", "innovation": "提出了$t$截断的Vendi分数，通过截断核矩阵的特征谱，确保在样本数量为$n=\text{O}(t)$的情况下收敛到总体极限。证明了Nyström和FKEA近似方法收敛到截断Vendi分数的渐近极限。此外，证明了RKE分数在整个核函数下具有普遍的收敛保证。通过数值实验展示了Nyström和FKEA计算的Vendi分数的集中性，并分析了截断Vendi和RKE分数与图像和文本数据多样性的相关性。", "conclusion": "本文提出了$t$截断的Vendi分数，确保在有限样本情况下收敛，同时验证了Nyström和FKEA近似方法的有效性，并证明了RKE分数的普遍收敛性。"}
{"llm_update_time": "2025-06-25 09:16:18", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.16828", "html_url": "https://arxiv.org/abs/2504.16828", "title": "思考过程奖励模型", "title_en": "Process Reward Models That Think", "authors": "Muhammad Khalifa,Rishabh Agarwal,Lajanugen Logeswaran,Jaekyeom Kim,Hao Peng,Moontae Lee,Honglak Lee,Lu Wang", "background": "步骤验证器，即过程奖励模型（PRMs），是测试时可扩展性的重要组成部分。然而，PRMs需要步骤级别的监督，这使得它们在训练过程中非常昂贵。本文旨在构建数据高效的PRMs，通过生成验证因果链（CoT）来验证每个步骤，以每种需小于判别性PRMs标签数量的一小部分标签即可表现优异。因此，本文的研究动机是在保持较低训练监督成本的同时，解决测试时的验证问题，并在多个挑战性基准测试中超越传统模型和判别性验证器。此外，在使用相同标记预算的情况下，思考过程奖励模型（ThinkPRM）在验证计算扩展性方面优于LLM作为法官，展现出更大的优势。", "innovation": "本文提出了一种新的验证模型——思考过程奖励模型（ThinkPRM），这种模型基于长因果链（CoT）生成验证链，并且只需要极少的步骤标签即可在多个挑战性任务上取得优异性能，显著降低了训练所需的监督信息。此外，ThinkPRM在验证运算扩展性方面表现出色，与LLM作为法官相比，提高了7.2%。", "conclusion": "本研究通过构建基于长因果链生成验证过程的模型ThinkPRM，显著提升了测试时的验证效率，同时减少了训练所需的监督信息。ThinkPRM模型在多个基准测试中优于判别性验证器，特别是在使用相同标记预算时，验证运算扩展性方面表现出色。未来的工作将进一步验证这种生成式长因果链模型在更大范围任务上的适用性和效果。"}
{"llm_update_time": "2025-06-25 09:16:18", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.16490", "html_url": "https://arxiv.org/abs/2501.16490", "title": "在数据约束和对抗挑战下实现智能电网稳健稳定预测：基于GAN的方法", "title_en": "Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges", "authors": "Emad Efatinasab,Alessandro Brighente,Denis Donadel,Mauro Conti,Mirco Rampazzo", "background": "随着全球人口增长和城市化进程，智能电网对于满足不断增长的能量需求至关重要。它们通过整合可再生能源提高了效率、可靠性和可持续性。然而，确保其可用性和安全性需要先进的操作控制和安全措施。尽管人工智能和机器学习有助于评估电网稳定性，但在数据稀缺和网络安全威胁（特别是对抗性攻击）面前仍有许多挑战。数据稀缺是一个主要问题，因为获取电网不稳定现象的实际示例需要大量的专业知识、资源和时间。然而，这些示例对于测试新的研究进展和安全缓解措施至关重要。", "innovation": "本文介绍了一种新的方法，使用仅有的稳定数据来检测智能电网中的不稳定性。该方法采用了生成对抗网络（GAN），生成器被设计成不产生接近实际数据的样本，而是生成与稳定类不同的异常样本。通过仅使用稳定数据进行训练，并向判别器展示异常样本，该方法学习区分稳定条件与任何形式的不稳定的行为。此外，我们还引入了一个对抗训练层以增强对抗攻击的抵抗力。在真实世界数据集上的评估显示，该解决方案在预测电网稳定性方面的准确率为98.1%，在检测对抗攻击方面的准确率为98.9%。在单板计算机上实施后，它使实时决策成为可能，平均响应时间低于7ms。", "conclusion": "该框架能够在不需要不稳定数据的情况下，通过稳定数据检测智能电网的不稳定性，并在对抗性攻击下表现出色。通过结合生成对抗网络和对抗训练层，该方法实现了智能电网稳定性的稳健预测，展示了对未来电网安全性的增强能力。"}
{"llm_update_time": "2025-06-25 09:16:19", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11462", "html_url": "https://arxiv.org/abs/2505.11462", "title": "在医疗大型语言模型中分离推理与知识", "title_en": "Disentangling Reasoning and Knowledge in Medical Large Language Models", "authors": "Rahul Thapa,Qingyang Wu,Kevin Wu,Harrison Zhang,Angela Zhang,Eric Wu,Haotian Ye,Suhana Bedi,Nevin Aresh,Joseph Boen,Shriya Reddy,Ben Athiwaratkun,Shuaiwen Leon Song,James Zou", "background": "当前的医疗问答基准测试（如MedQA-USMLE、MedMCQA和PubMedQA）通常将推理与事实记忆混合在一起，这使得大型语言模型（LLMs）在模仿临床诊断思维方面存在局限性。这项研究旨在通过使用PubMedBERT分类器将11项生物医学问答基准测试分离成聚焦推理和知识的子集，从而解决这一问题，该分类器的准确率达到81%，与人类表现相当。研究表明，只有32.8%的问题需要复杂的推理能力，这揭示了当前在推理和知识方面存在性能差距。在对抗性测试中，由于误导而给出了错误初始推理，生物医学模型的表现会急剧下降，相比之下，较大的或基于强化学习的一般领域模型表现更加稳健。因此，研究团队通过使用强化学习和精细调优训练了一个名为BioMed-R1的模型，它在类似大小的模型中表现出最强的性能，进一步的改进可能会涉及到引入临床案例报告并进行对抗性和回溯性场景下的训练。", "innovation": "研究团队使用PubMedBERT分类器将11项生物医学问答基准测试分离成聚焦推理和知识的子集，揭示了生物医学模型和一般领域模型在推理和知识方面的性能差异，特别是在对抗性测试中的表现。通过使用强化学习和精细调优训练了一个名为BioMed-R1的模型，展示了在类似大小模型中的最佳性能，并提出了进一步改进的可能方向。", "conclusion": "研究结果表明，基于生物医学模型和一般领域模型在推理和知识方面的性能存在明显差距，并强调了在包括临床案例报告的对抗性和回溯性场景下的进一步培训的重要性。此外，通过使用强化学习和精细调优训练的BioMed-R1模型在同类模型中表现最佳。"}
{"llm_update_time": "2025-06-25 09:16:19", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.16484", "html_url": "https://arxiv.org/abs/2503.16484", "title": "AI-Facilitated Episodic Future Thinking For Adults with Obesity", "title_en": "AI-Facilitated Episodic Future Thinking For Adults with Obesity", "authors": "Sareh Ahmadi,Michelle Rockwell,Megan Stuart,Nicki Rohani,Allison Tegge,Xuan Wang,Jeffrey Stein,Edward A. Fox", "background": "Episodic Future Thinking（EFT）通过详细想象个人未来的事件和体验，显示出了作为干预手段减少延迟折扣（推迟满足当前的奖励）并促进多种不良健康行为改变的潜力。研究旨在通过开发一个基于GPT-4-Turbo大型语言模型的AI聊天机器人EFTeacher，来生成EFT提示，辅助生活方式相关疾病患者。前期研究为探索EFTeacher的可行性和可用性奠定了基础，研究通过混合方法评估了聊天机器人的使用情况，包括易用性评估、基于内容特征的用户评价问卷以及半结构化访谈。质性研究结果表明，参与者认为EFTeacher通过互动对话是沟通和支持性的，能够促进富有想象力的思考和对未来目标的反思。参与者赞赏其适应性和个性化功能，但也存在对话重复和冗长回答的挑战。", "innovation": "该研究创新性地开发了基于GPT-4-Turbo大型语言模型的AI聊天机器人EFTeacher，用于生成EFT提示以辅助生活方式相关疾病患者。通过混合方法的用户评估，该研究探索了大型语言模型聊天机器人在EFT干预中的潜力，特别是在针对肥胖成人等方面的应用。", "conclusion": "研究结果强调了基于大型语言模型的聊天机器人在EFT干预中针对不良健康行为的潜在应用价值。尽管存在一些挑战，如对话重复和冗长回答，但该研究为优化此类聊天机器人的设计提供了宝贵见解。"}
{"llm_update_time": "2025-06-25 09:16:23", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19769", "html_url": "https://arxiv.org/abs/2505.19769", "title": "TeViR: 使用扩散模型的文本到视频奖励以提高强化学习效率", "title_en": "TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning", "authors": "Yuhui Chen,Haoran Li,Zhennan Jiang,Haowei Wen,Dongbin Zhao", "background": "在强化学习（RL）中开发可扩展且具有广泛适用性的奖励工程至关重要，尤其是在机器人拾取与放置等挑战性领域。尽管使用视觉语言模型（VLMs）的奖励工程近来显示出潜在前景，但由于它们具有稀疏奖励的特点，显著限制了样本效率。当前研究提供了新的方法来解决这一问题，通过利用预训练的文本到视频扩散模型来生成密集奖励，以提高学习效率和性能。", "innovation": "提出了一种名为TeViR的新方法，该方法通过比较预测的图像序列和当前观察结果来生成密集奖励，利用预训练的文本到视频扩散模型。实验结果表明，TeViR在11项复杂机器人任务中表现优秀，优于依赖稀疏奖励的传统方法和其他最新的（SOTA）方法，且无需环境的真实奖励数据。", "conclusion": "TeViR能够高效地引导代理在复杂环境中进行学习，展示了其在强化学习应用于机器人操作方面的潜力。"}
{"llm_update_time": "2025-06-25 09:16:25", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15961", "html_url": "https://arxiv.org/abs/2506.15961", "title": "TrainVerify：基于等价性的分布式大语言模型训练验证", "title_en": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training", "authors": "Yunchi Lu,Youshan Miao,Cheng Tan,Peng Huang,Yi Zhu,Xian Zhang,Fan Yang", "background": "训练大规模语言模型（LLMs）需要大规模并行执行，这带来了巨大的计算成本。然而，这些昂贵的分布式训练很少被验证，因此容易出现无声的错误，并可能导致数百万个GPU小时的资源浪费。", "innovation": "TrainVerify引入了一种系统，用于验证分布式大语言模型的训练。它通过给定深度学习模型的逻辑规格为基准，正式验证分布式并行执行计划是否与其数学等价。为了应对大规模LLMs（通常涉及数十亿变量和复杂的计算图）所带来的直接验证难度，TrainVerify引入了形状归约技术和分阶段并行验证算法，显著降低了复杂性并保持了形式上的正确性。TrainVerify能够扩展到前沿的大规模语言模型，成功验证了Llama3（405B参数）和DeepSeek-V3（671B参数）的训练计划。", "conclusion": "TrainVerify能够正式验证大规模语言模型的分布式训练，显著降低了验证复杂性，确保训练过程的数学等价性，防止潜在的资源浪费。"}
{"llm_update_time": "2025-06-25 09:16:26", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09160", "html_url": "https://arxiv.org/abs/2506.09160", "title": "理解教育中的AI信任", "title_en": "Understanding Human-AI Trust in Education", "authors": "Griffin Pitts,Sanaz Motamedi", "background": "随着AI聊天机器人在教育中的广泛应用，学生越来越多地依赖这些系统获取指导、反馈和信息。然而，这些聊天机器人的拟人特征使学生对它们的信任产生了一种不确定性，这种信任可能是基于人际信任，也将技术信任与对其他技术类型的信任相混淆。人际信任模型可能错误地赋予AI人类意图和道德性，而技术信任模型通常是为非社交性技术设计的，其在应用于拟人系统时的适用性尚不够明确，这给理论研究提出了挑战。为了解决这一理论空白，本研究探讨了人本信任和系统信任在学生对AI聊天机器人的感知享受、信任意向、使用意图和感知有用性方面的影响，其中这些因素与学生的参与度和学习成果有关。通过部分最小二乘结构方程建模，我们发现人本信任和系统信任对学生的感知影响有所不同。人本信任更显著地预测了信任意向，而系统信任更好地预测了使用意图和感知有用性。两者在感知享受方面的影响相似。由于每种信任类型的解释力有限，我们提出，学生在与AI聊天机器人的互动中形成了一种独特形式的信任（人机信任），这不同于人与人之间和人与技术之间的信任模型。我们的发现突出了需要为人类与AI的信任建立特定的理论框架，同时也提供了培养恰当信任水平的实用建议，这对于AI在教育中的有效采用和教育影响至关重要。", "innovation": "本研究首次深度探讨了教育环境中的人工智能信任（人机信任）的不同方面，并提出了人本信任和系统信任对AI聊天机器人在学生中影响的不同效应，这为理解和设计相关技术提供了新见解。此外，提出了新的人机信任模型，这是前人工作的创新突破，填补了现有的人际信任和个人技术信任理论在AI环境下的空缺。该研究为开发更有效的AI聊天机器人，提高学生参与和学习效果提出实用建议。", "conclusion": "研究表明，学生在与AI聊天机器人的交互中形成了独特的人机信任形式，这不同于传统的个人与人之间或人与技术之间的信任。人本信任更多的是影响学生的信任意向，而系统信任则更好地影响他们的使用意图和感知有用性。两种信任对感知享受的影响相似。鉴于每种信任类型的解释力有限，研究建议有必要为教育环境中的AI开发特定的信任理论框架，以促进适当水平的信任，这对于AI在教育中的有效采用和教育影响至关重要。"}
{"llm_update_time": "2025-06-25 09:16:27", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10412", "html_url": "https://arxiv.org/abs/2506.10412", "title": "Time-IMM: 一个用于不规则多模态多元时间序列的数据集和基准", "title_en": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series", "authors": "Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang", "background": "在医疗、气候建模和金融等实际应用中，时间序列数据通常是不规则的、多模态的且不干净的，具有不同的采样率、异步模态以及广泛的数据缺失。现有基准数据集通常假设干净、规则采样、单模态数据，这在研究和实际部署之间造成了很大差距。", "innovation": "引入了Time-IMM数据集，专门用于捕捉不规则的多模态多变量时间序列中的因果驱动的不规则性。Time-IMM涵盖了九种不同类型的时间序列不规则性，分为触发机制、约束机制和伪影机制。另外，还引入了IMM-TSF基准库，用于不规则多模态时间序列的预测，支持异步集成和现实评估，包含定制的融合模块，如时间戳到文本的融合模块和多模态融合模块，支持基于时序的平均和注意力融合策略。", "conclusion": "实证结果表明，在不规则时间序列数据中显式建模多模态性可以显著提高预测性能。Time-IMM和IMM-TSF为在实际条件下推进时间序列分析提供了基础。数据集和基准库均已在互联网上公开。"}
{"llm_update_time": "2025-06-25 09:16:29", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11558", "html_url": "https://arxiv.org/abs/2506.11558", "title": "DaMO：视频LLM中基于数据效率的多模态协调器用于时间推理", "title_en": "DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs", "authors": "Bo-Cheng Chiu,Jen-Jee Chen,Yu-Chee Tseng,Feng-Chi Chen", "background": "近年来，大型语言模型（LLMs）已被扩展到视频领域，使视频-语言理解变得复杂。然而，现有的视频LLM在细粒度的时间推理方面存在局限性，限制了它们对视频特定时刻响应的精确归因能力，特别是在受限监督下表现尤为明显。", "innovation": "介绍了一种名为DaMO的高效视频LLM，专门设计用于精确的时间推理和多模态理解。其核心是一个时间感知的双流融合器，该融合器通过分级结构逐步捕获每种模态内的时间动态并有效融合互补的视觉和音频信息。此外，DaMO还集成了一个全局残差，以减少空间冗余并保留关键语义细节。", "conclusion": "全面的实验表明，DaMO在时间定位和视频QA基准测试中表现优异，特别是在需要精确时间对齐和推理的任务中。本研究为数据高效的视频-语言建模指明了一条前景光明的途径。"}
{"llm_update_time": "2025-06-25 09:16:29", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17338", "html_url": "https://arxiv.org/abs/2506.17338", "title": "基于PBFT的语义投票多智能体记忆修剪", "title_en": "PBFT-Backed Semantic Voting for Multi-Agent Memory Pruning", "authors": "Duong Bach", "background": "多智能体系统（MAS）在复杂动态环境中广泛应用，需要高效和可靠的机制来管理共享知识。一个核心挑战是如何确保分布式的记忆保持同步、相关并且不会累积无用或无关数据，类似于生物的遗忘过程。现有技术无法有效解决这一问题，因此需要一种新的综合框架来应对这一挑战，以实现MAS中同步的记忆修剪。", "innovation": "该论文提出了一个名为Co-Forgetting协议的创新性框架，该框架通过分布式的记忆修剪来解决上述问题。协议结合了三部分关键技术：情景感知语义投票、多尺度时域衰减函数以及基于实用拜占庭容错（PBFT）的共识机制。具体来，协议利用轻量级的DistilBERT模型进行语义评估，基于记忆内容和当前的情景来确定记忆条目的相关性；使用多尺度的时域衰减函数根据记忆的年龄和访问频率来赋予其不同的重要性；并采用了PBFT共识机制来确保在存在最多f个拜占庭错误智能体的情况下，仍能达成决策的一致性。", "conclusion": "实验结果在模拟的MAS环境中验证了协议的有效性，显示了52%的记忆容量减少、88%的遗忘决策准确性、92%的PBFT共识成功率以及82%的缓存命中率，验证了该协议的优越性。"}
{"llm_update_time": "2025-06-25 09:16:29", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12374", "html_url": "https://arxiv.org/abs/2506.12374", "title": "AntiGrounding：将机器人动作提升至VLM表示空间中的决策制定", "title_en": "AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making", "authors": "Wenbo Li,Shiyi Wang,Yiteng Chen,Huiping Zhuang,Qingyao Wu", "background": "当前的视觉-语言模型（VLMs）在编码知识和推理能力以支持机器人操作时，通常将它们投影到压缩的中间表示中，从而丢失了许多任务特定的信息，如精细的空间或语义细节。这种做法限制了模型在执行特定任务时的表现。因此，本文的研究背景是探讨一种有效的方法来弥补这一缺陷，使模型能够处理更复杂的任务，尤其在需要理解特定语义细节的情况下。", "innovation": "本文提出了一种新的框架——AntiGrounding，它通过直接将候选动作提升到VLM表示空间，同时从多角度渲染轨迹，并利用结构化的视觉问题回答来进行指令驱动的决策制定。这一方法使得机器人能更有效地合成新的任务，而无需在执行它们之前遇到这些任务。此外，还提出了一种离线策略改进模块，利用过往经验来提升长期性能，以此改善机器人的表现。", "conclusion": "实验结果表明，该方法在模拟和真实机器人操作环境中均优于基准方法，特别是在处理多样化的机器人作业任务时展示了显著的优势。"}
{"llm_update_time": "2025-06-25 09:16:33", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17364", "html_url": "https://arxiv.org/abs/2506.17364", "title": "基于AI的多模态生物识别技术检测智能手机分心：在线学习的应用", "title_en": "AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning", "authors": "Alvaro Becerra,Roberto Daza,Ruth Cobos,Aythami Morales,Mutlu Cukurova,Julian Fierrez", "background": "研究探讨了在需要持续注意力的任务中，使用多模态生物识别技术检测由智能手机使用引起的分心。尽管方法适用于各个领域，如自动驾驶，论文重点放在在线学习领域，特别是学习者在保持参与度时面临的挑战，包括内部因素（如动机）、系统因素（如课程设计）和情境因素（如智能手机使用）。传统的学习平台缺乏详细的学员行为数据，而多模态学习分析（MMLA）和生物传感器提供了对学员注意力的新见解。", "innovation": "论文提出了一种基于AI的解决方案，利用生理信号和头部姿态数据来检测学员使用智能手机的情况。研究表明单一生物识别信号（如脑电波或心率）的准确性有限，而单独使用头部姿态达到了87%的准确性。结合所有信号的多模态模型达到了91%的准确性，突显了集成的优势。这表明，多模态数据能够更准确地检测到学员在学习过程中的分心行为。", "conclusion": "论文最后讨论了在在线学习环境中部署这些模型的现实意义和局限性，认为这些技术能够为在线学习提供实时支持，但也指出了实际应用中可能遇到的问题和挑战。"}
{"llm_update_time": "2025-06-25 09:16:33", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16640", "html_url": "https://arxiv.org/abs/2506.16640", "title": "长上下文泛化中的稀疏注意力机制", "title_en": "Long-Context Generalization with Sparse Attention", "authors": "Pavlo Vasylenko,Marcos Treviso,André F. T. Martins", "background": "传统的基于Transformer的架构使用softmax来计算注意力权重，这会导致序列中所有的tokens被密集地分配注意力。尽管这种机制在许多情况下是有效的，但对于需要精确关注固定大小模式的任务来说，这种密度是有害的：随着序列长度的增加，无信息的tokens会积累注意力概率，导致注意力分散和表示坍塌。已有研究表明，使用α-entmax这样的稀疏注意力机制可以避免这些问题，因为它能够将无关的tokens分配为确切的零。此外，通过引入Adaptive-Scalable Entmax (ASEntmax)，赋予α-entmax一个可学习的温度参数，能够使注意力分布能够在这两种密集和稀疏模式之间进行平滑切换。通过仔细设计位置编码，对密集和稀疏注意力方法都有助于固定大小模式的定位和泛化。", "innovation": "提出了一种新的注意力机制——Adaptive-Scalable Entmax (ASEntmax)，它结合了α-entmax的稀疏性优点，并通过可学习的温度参数实现了注意力分布在这两种稀疏和密集模式之间的平滑切换。通过整合ASEntmax和适当的位置编码，该模型在处理长上下文泛化任务时明显优于基于softmax、可扩展softmax和固定温度α-entmax的基本模型。", "conclusion": "通过将ASEntmax集成到标准的Transformer层中并结合适当的位置编码，该模型在长上下文的一般化任务中展现出了显著的性能优势，优于传统的softmax方法和基于softmax的其他方法。"}
{"llm_update_time": "2025-06-25 09:16:33", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14677", "html_url": "https://arxiv.org/abs/2506.14677", "title": "基于流式Conformer-Transformer和重采样钩的人本编辑型speech-to-sign-Language生成", "title_en": "Human-Centered Editable Speech-to-Sign-Language Generation via Streaming Conformer-Transformer and Resampling Hook", "authors": "Yingchao Li", "background": "现有的端到端手语动画系统存在自然度低、面部和身体表情限制以及没有用户控制的问题。", "innovation": "提出了一种以人为本、实时的语音到手语动画框架，该框架整合了（1）流式Conformer编码器与自回归Transformer-MDN解码器以实现上半身和面部运动的同步生成，（2）透明的可编辑JSON中间表示，残疾用户和专家可以检查和修改每个手语片段，并（3）基于用户编辑和评分的人在回路优化循环，以进一步细化模型。该系统在Unity3D上部署，平均帧推理时间为13毫秒，端到端延迟为103毫秒。关键贡献包括设计以JSON为中心的编辑机制，实现精细的手语级别个性化，以及首次将MDN为基础的反馈循环应用于连续模型适应，建立了一种通用、可解释的人适应低延迟多模态系统的人工智能范式。实验证明该系统比基线提高了自然度和信任度，并显著降低了认知负荷。", "conclusion": "该工作为无障碍手语技术提供了一种可扩展且可解释的人工智能范式。"}
{"llm_update_time": "2025-06-25 09:16:35", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16297", "html_url": "https://arxiv.org/abs/2506.16297", "title": "SycnMapV2：鲁棒且自适应的无监督分割", "title_en": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation", "authors": "Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas", "background": "人类视觉在无需显式训练的情况下就能有效分割视觉线索，并且即使在噪声加剧的情况下依然保持高度的鲁棒性。相比之下，现有的AI算法在相同条件下难以保持精度。现有的无监督分割方法在面对不同类型的干扰时，如噪声、天气和模糊时，表现都非常差，它们的精度会大幅下降。", "innovation": "SyncMapV2首次实现了在鲁棒性方面达到行业领先水平的无监督分割。SyncMapV2在数字干扰下的mIoU下降仅为0.01%，远低于现有最佳方法23.8%的下降幅度。它在噪声、天气和模糊等各种干扰类型中的表现也显著优于现有方法。SyncMapV2的独特之处在于，它无需任何鲁棒性训练、监督或损失函数即可运作。这种方法基于自组织动力学方程的学习范式，并结合了随机网络的概念。此外，SyncMapV2可以在不重新初始化的情况下在线适应新的输入，类似于人类视觉的持续适应能力。这使得SyncMapV2成为首个能够在线适应输入而非重新初始化的算法。", "conclusion": "SyncMapV2在适应性测试中表现出几乎零的性能下降，这一结果激励着未来的智能系统朝着更鲁棒和自适应的方向发展。SyncMapV2代表了无监督分割算法中的一个重要突破，对于开发未来的自适应智能系统具有重要意义。"}
{"llm_update_time": "2025-06-25 09:16:38", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18167", "html_url": "https://arxiv.org/abs/2506.18167", "title": "通过引导向量理解思考语言模型的推理", "title_en": "Understanding Reasoning in Thinking Language Models via Steering Vectors", "authors": "Constantin Venhoff,Iván Arcuschin,Philip Torr,Arthur Conmy,Neel Nanda", "background": "最近大型语言模型（LLMs）的进步导致了生成详细内部推理链的思考型LLMs的开发。尽管这些模型提高了性能，但控制其推理过程仍然具有挑战性。本文通过分析和操纵DeepSeek-R1-Distill模型中的特定推理行为，提出了一种引导方法。通过对500个任务中的10个不同类别进行系统实验，识别了思考型模型表现出的多种推理行为，如表达不确定性、为假设验证生成例子和推理链中的回溯。这些行为由模型激活空间中的线性方向介导，并可以通过引导向量加以控制。通过提取并应用这些向量，提供了调节模型推理过程特定方面的方法，比如回溯倾向或表达不确定性。这种方法为在受控和可解释的方式下引导思考型模型的推理过程提供了实用工具。我们使用三种DeepSeek-R1-Distill模型验证了引导方法，展示了不同模型架构的一致控制效果。", "innovation": "提出了通过对特定推理行为进行分析和操纵的引导策略，以控制思考型LLMs的推理过程。识别并利用模型激活空间中的线性方向，设计了引导向量来调节模型的推理过程，实现了在受控和可解释方式下的推理过程调控。这种方法在三种DeepSeek-R1-Distill模型上进行了验证，展示了跨不同模型架构的一致控制效果。", "conclusion": "提出的方法为在可控和可解释的条件下引导思考型模型的推理过程提供了实用工具，通过系统实验验证了该方法的有效性和一致性。"}
{"llm_update_time": "2025-06-25 09:16:39", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18710", "html_url": "https://arxiv.org/abs/2506.18710", "title": "Benchmarking the Pedagogical Knowledge of Large Language Models", "title_en": "Benchmarking the Pedagogical Knowledge of Large Language Models", "authors": "Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portela,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod", "background": "现有的大规模语言理解基准（如 Masssive Multitask Language Understanding MMLU）在评估AI的知识和能力方面发挥了关键作用，但这些基准主要集中在内容知识上，忽视了对模型理解教学方法和实践（即教育学）能力的评估。为了避免这一信息缺口，该论文提出了一种新型基准——教育学基准，用于评估大型语言模型的跨域教育学知识（CDPK）以及特殊教育需求和障碍（SEND）方面的教育学知识。这些基准是从教师职业发展考试中精心挑选的问题构建的，涵盖了教学策略、评估方法等多种教育学子领域的问题。", "innovation": "该研究引入了一种新的教育学基准，用于评估大型语言模型在跨域教育学知识（CDPK）及特殊教育需求和障碍（SEND）方面的教育学知识。该基准数据集建立了在教师职业发展考试问题中精心选择的问题之上，涵盖了教育策略和评估方法等多种教育学子领域。研究还报告了97个模型在教育学知识问题上的准确率，范围从28%到89%，并且分析了成本与准确率之间的关系，记录了帕累托价值前沿的演变情况，提供了在线排行榜并在其中更新新的模型，基于不同模型属性（如每令牌成本、开放式与封闭式权重）以及不同学科的性能进行互动探索和过滤。", "conclusion": "教育学基准是衡量模型对教育概念的理解、对学生需求的适当响应以及在不同情境下支持有效教学实践能力的关键工具。这些基准对于指导大型语言模型及其工具在教育领域中的责任和基于证据的应用至关重要，同时也可以指导开发和政策决策。"}
{"llm_update_time": "2025-06-25 09:16:41", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17551", "html_url": "https://arxiv.org/abs/2506.17551", "title": "基于大规模语言模型推荐系统中模型并行与数据并行优化方法的研究", "title_en": "Research on Model Parallelism and Data Parallelism Optimization Methods in Large Language Model-Based Recommendation Systems", "authors": "Haowei Yang,Yu Tian,Zhongheng Yang,Zhao Wang,Chengrui Zhou,Dannier Li", "background": "随着大规模语言模型（LLMs）在推荐系统中的快速采用，由于其庞大的参数规模和大量数据带来的计算和通信瓶颈问题变得越来越突出。", "innovation": "系统性地研究了模型并行与数据并行两种优化方法，分别实现了张量并行和流水线并行，引入了自适应负载均衡机制以减少跨设备通信开销；在数据并行中，对比同步和异步模式，结合梯度压缩和稀疏化技术与高效的聚合通信框架，显著提高带宽利用率。", "conclusion": "实验结果表明，提出的混合并行方案相较于传统的单一模式并行，在提高训练吞吐量（超过30%）和资源利用率（约20%）的同时，保持了较强的可扩展性和鲁棒性。最终讨论了不同并行策略在线部署中的权衡，并展望了异构硬件集成和自动化调度技术的发展方向。"}
{"llm_update_time": "2025-06-25 09:16:41", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit:奖动化以改进LLM策略优化", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1 通过基于规则的奖励体系成功增强了大型语言模型（LLM）的推理能力，尽管这种奖励系统在有效防止奖励诈骗方面表现出色，但其往往是离散的。实验观察表明，离散奖励可能导致梯度异常、优化不稳定以及收敛缓慢。为了应对这一问题，该研究提出了一种称为ReDit（Reward Dithering）的方法，通过向离散的奖励信号中添加简单的随机噪声来使其抖动。这种方法在学习过程中提供了一个连续的探索梯度，使得梯度更新更加平滑，加速了收敛。注入的噪声还引入了平坦奖励区域中的随机性，促使模型探索新的策略并跳出局部最优解。通过不同任务上的实验，展示了ReDit的有效性和效率，ReDit在平均情况下，只需大约10%的训练步骤就能达到与原始GRPO相当的表现，且在相同训练周期下性能提升了4%。此外，可视化结果验证了ReDit在梯度问题上的显著改进。理论分析也进一步验证了这些优点。", "innovation": "ReDit，一种通过向离散的奖励信号中添加简单随机噪声来改善大型语言模型（LLM）策略优化的方法，能够持续提供探索性梯度，加速收敛并促进模型探索新策略。该方法有效地缓解了离散奖励导致的问题，提升了模型的整体性能和效率，且理论分析也支持其有效性。", "conclusion": "Experiments across diverse tasks have demonstrated the efficiency and effectiveness of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO with only approximately 10% the training steps, and furthermore, still exhibits a 4% performance improvement over vanilla GRPO when trained for a similar duration. Theoretical analyses further validate these advantages."}
{"llm_update_time": "2025-06-25 09:16:42", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17728", "html_url": "https://arxiv.org/abs/2506.17728", "title": "KAG-Thinker：通过知识增强生成在大语言模型中实现交互式思考与深度推理", "title_en": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation", "authors": "Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo", "background": "本文讨论了升级KAG到一个多轮互动思考和深度推理框架的问题，该框架由一个专门为大型语言模型（LLM）设计的参数较少的语言模型（LLM）驱动。该框架旨在解决复杂问题时，构建一个结构性的思考过程，并在特定领域的知识库（KB）内改进问题回答（Q&A）任务中推理过程的逻辑连贯性和上下文一致性。参考KAG的基于逻辑形式引导检索和推理技术路线，该框架首先通过广度分解将复杂的查询分解为独立可解的子问题，这些子问题被定义为逻辑形式。每个逻辑形式在自然语言和逻辑函数两种形式之间等价表达，并被分类为知识检索或推理分析任务。依赖性及参数传递通过逻辑函数接口显式建模。在求解过程中，检索函数执行检索任务，获取特定知识单元的一阶结构化和非结构化信息，而数学和推理函数则用于执行推理分析任务。对于知识检索子问题任务，LLM和外部知识源被视为等效的知识库，通过使用知识边界模块和自我调节机制（如置信校准、反省推理）来确定最优的知识来源，并通过深度求解模块增强知识获取的全面性。", "innovation": "创新点在于开发了一个名为KAG-Thinker的新框架，这个多阶段、多轮次的思考体系能利用大语言模型（LLM）背后的轻量级参数模型进行扩展，它通过逻辑形式指导的知识增强生成技术，将复杂问题分解为可独立解决的子问题，并通过逻辑函数接口明确建模任务间的依赖性及参数传递。", "conclusion": "KAG-Thinker框架通过构建结构性的思考过程，有效提升了问题回答任务的逻辑连贯性和上下文一致性，并通过知识增强生成技术增强了知识库（KB）中推理过程的逻辑连贯性和获取知识的全面性。"}
{"llm_update_time": "2025-06-25 09:16:43", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18919", "html_url": "https://arxiv.org/abs/2506.18919", "title": "MemeMind: 一种具有链式思考推理的大规模跨模态数据集及其在有害模因检测中的应用", "title_en": "MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection", "authors": "Hexiang Gu,Qifan Yu,Saihui Hou,Zhiqin Fang,Huijia Wu,Zhaofeng He", "background": "社交媒体的快速发展加剧了有害内容的传播，含有图文信息的有害模因因其隐含的意义和复杂的多模态交互而对自动检测构成了显著挑战。尽管现有研究在检测精度和可解释性上取得了进展，但缺乏系统性的、大规模的、多样性的以及高度可解释性的数据集仍限制了该领域的进一步发展。", "innovation": "MemeMind是一个新颖的数据集，具有严格的科学标准、大规模、多样性和双语支持（中文和英文），并附有详细的链式思考（CoT）注释。MemeMind通过提供全面的标记和明确的推理痕迹，填补了当前数据集的关键空白。此外，论文提出了一种创新的检测框架MemeGuard，该框架有效地整合了多模态信息和推理过程建模，显著提高了模型理解与识别有害模因的能力。", "conclusion": "在MemeMind数据集上进行的大量实验表明，MemeGuard在有害模因检测任务中的一致表现超过了现有的最先进的方法。"}
{"llm_update_time": "2025-06-25 09:16:45", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18998", "html_url": "https://arxiv.org/abs/2506.18998", "title": "记忆幻象：记忆使大模型自欺欺人地自我膨胀", "title_en": "Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge", "authors": "Sahil Kale,Vijaykant Nadadur", "background": "现有的研究将大语言模型（LLM）在学习过程中出现的记忆和自我知识缺陷视为两个独立的问题，没有意识到这两者交织的关系会降低LLM响应的可信度。研究发现，当AI模型将记忆等同于智能时，会制造出一种危险的认知幻象。这种情况下，LLM往往表现出对自身推理能力的过高自我认知，尤其是在STEM领域。这种现象在科学和医学领域尤为明显，这些领域通常具有高度标准化的专业术语和复杂问题，这进一步证实了研究方法的有效性。", "innovation": "本文提出了一种创新的框架，旨在区分LLM是真正从训练数据中学习推理模式，还是仅仅通过记忆解决方案来假装具有解决问题的能力。研究发现，当面对自我验证且逻辑上一致的任务扰动时，LLM在可行性评估中的不一致程度超过45%。结果显示，这种过度自信主要表现在科学和医学领域，进一步暴露了现有模型架构和训练模式的缺陷，强调了确保模型在自我知识方面的平衡和一致性的重要性，以实现最大化的AI可解释性和可信度。", "conclusion": "研究揭示了LLM中存在显著的自我知识波动，这表明现有架构和训练模式存在缺陷，需要开发确保模型对自身知识有平衡、一致的理解的新方法，以提高AI的可解释性和可信度。研究代码和结果已公开，进一步验证了该方法的有效性。"}
{"llm_update_time": "2025-06-25 09:16:46", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18204", "html_url": "https://arxiv.org/abs/2506.18204", "title": "使用傅里叶注意力的多模态融合SLAM", "title_en": "Multimodal Fusion SLAM with Fourier Attention", "authors": "Youjie Zhou,Guofeng Mei,Yiming Wang,Yi Wan,Fabio Poiesi", "background": "基于视觉的知识关联和定位（SLAM）在有噪声、光线变化以及黑暗环境中的应用面临着巨大挑战。传统的基于光流的SLAM方法常常需要大量的计算资源来处理这些挑战，因此提出了一种新的方法FMF-SLAM来克服这个问题。FMF-SLAM利用快速傅里叶变换提升算法效率，并采用基于傅里叶变换的自我注意和交叉注意机制，从RGB和depth信号中提取特征。此外，通过跨模态的多尺度知识蒸馏，增强了多种模态特征的交互性。该方法通过与具有全球定位系统模块的保安机器人（GNSS-RTK）和全局束调整集成，在实际场景中实现了实时性测试，并展示了在噪声、光线变化以及黑暗等复杂条件下具有优秀的性能。该方法使用TUM、TartanAir和自身采集的视频序列进行验证，同时提供了可获取的源代码和数据集链接。该研究在摄像头网络和机器人领域展现出显著的应用潜力，使该技术易于扩展，以处理实际物理环境中的相关挑战，如库房、家庭、办公室和工厂室内场景等。研究表明，与当前公开的其他零样本视频分析模型（如LiT）相比，该方法在跨越物体种类（in-cross-over-object-categories）、迁移（cross-domain）和封闭式创新（closed-set）三个维度上均表现得更优秀。", "innovation": "FMF-SLAM提出了基于傅里叶变换的自我注意和交叉注意机制，实现了多模态特征的有效提取，并通过跨模态多尺度知识蒸馏增强了多种模态特征的交互性。这种方法能够克服传统基于光流的SLAM方法的计算资源限制，适用于噪声、光线变化以及黑暗等多种环境，具有较高的实时性能和鲁棒性。", "conclusion": "FMF-SLAM通过使用快速傅里叶变换和多模态融合技术，显著提升了视觉SLAM在复杂环境下的性能。该方法已经在多种实际场景下验证了其优越性，并适用于未来摄像头网络和机器人技术的发展。"}
{"llm_update_time": "2025-06-25 09:16:46", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18729", "html_url": "https://arxiv.org/abs/2506.18729", "title": "MuseControlLite：轻量级多功能音乐生成条件器", "title_en": "MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners", "authors": "Fang-Duo Tsai,Shih-Lun Wu,Weijaw Lee,Sheng-Ping Yang,Bo-Rui Chen,Hao-Chung Cheng,Yi-Hsuan Yang", "background": "在音乐生成模型中，文本到音乐的生成模型通常难以精确控制音乐生成的具体参数，尤其是当这些参数随时间变化时。背景研究表明，位置嵌入在文本条件下的作用较少被考虑，但在需要依赖时间的条件时非常重要。现有的细调机制在控制准确性上表现不佳，且参数量较高，无法满足轻量级高性能的需求。因此，亟需一种能够有效提高控音乐生制准确性和参数效率的轻量级机制，以实现多功能的音乐生成。", "innovation": "论文提出了一种名为MuseControlLite的轻量级机制，用于通过各种时间变化的音乐属性和参考音频信号对文本到音乐生成模型进行微调，以实现精确的条件控制。关键创新在于引入了位置嵌入，特别是在控制需要随时间变化的条件时。实验结果表明，通过增加旋转位置嵌入到解耦的交叉注意力层中，可以显著提高控制准确性，同时显著减少可训练参数数量，与现有最先进的机制相比，所需的可训练参数减少6.75倍。MuseControlLite对音乐属性控制、音频修补和音频扩展的应用效果优于MusicGen-Large和Stable Audio Open中的ControlNet，且仅使用85M的可训练参数，实现了高性能和高参数效率的平衡。", "conclusion": "通过MuseControlLite机制，实现了一种精确度高、参数效率高的文本到音乐生成模型，适用于多种音乐属性控制场景。该机制显著减少了可训练参数数量，降低了细调成本，同时保持了良好的控制性能，提供了多功能音乐生成的新方法。"}
{"llm_update_time": "2025-06-25 09:16:48", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "量化LLM公平性超越标记：语义与统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "现有研究表明，大型语言模型（LLMs）在生成响应时往往会带有固有的偏见，这影响了它们在实际应用中的可靠性。当前的评估方法往往忽略了长形式响应中的偏见以及LLM输出的内在变异性。已有研究主要集中在情感或标记层面的比较上，但大多数工作都停留在表面级别的分析，没有深入到更为细粒度的语义层面来检验不同群体之间的细微差异。因此，研究者急需一种新的方法来评估这种细微的差异，并能有效检测出潜在的偏见，提高模型的公正性与可信度。", "innovation": "本文提出了一种新的统计框架FiSCo（Fine-grained Semantic Computation），以检测长形式响应中不同群体之间的微妙语义差异，评估群体级的公平性。FiSCo框架通过分解模型输出为语义上不同的断言，并在其之上应用统计假设检验来进行组内和组间相似性的比较，从而实现了对细微偏差的稳健检测。与以往研究侧重于情感或标记层面的分析不同，FiSCo通过细粒度的语义分析，增强了对其内在变异性的影响评估，使得模型评估更加可靠。", "conclusion": "实验表明，FiSCo框架能够更可靠地识别出细微的偏见，并且减少了由随机性带来的LLM变化的影响，表现优于各种评估指标。研究进一步通过正式定义组内反事实公平性和在合成数据集及真实标注数据集（涵盖性别、种族和年龄）上验证FiSCo的有效性。"}
{"llm_update_time": "2025-06-25 09:16:49", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19004", "html_url": "https://arxiv.org/abs/2506.19004", "title": "断裂的标记符？你的语言模型可以秘密地处理非经典标记化", "title_en": "Broken Tokens? Your Language Model can Secretly Handle Non-Canonical Tokenizations", "authors": "Brian Siyuan Zheng,Alisa Liu,Orevaoghene Ahia,Jonathan Hayase,Yejin Choi,Noah A. Smith", "background": "当前的标记器使用确定性算法将文本映射为单一的“标准”标记序列，但同一个字符串可以使用标记器词汇表以许多非标准的标记化方式编码。这项研究探讨了语言模型在训练过程中从未见过的完全非标准标记化的文本上的鲁棒性。研究发现，指令调优模型在给出随机采样的标记化时保留了高达93.4%的原始性能，字符级标记化时保留了90.8%的性能。强模型通常更具鲁棒性，偏离标准形式越远，鲁棒性越差。研究还发现，非标准标记化方案在某些任务中可以提升性能，字符级分段在字符串操作和代码理解任务中改善了14%，而对齐数字分组在大数计算中则提升了33%。", "innovation": "研究表明，模型对非标准标记化的鲁棒性比之前认为的更高。研究者观察到，调优后的模型能够理解非标准标记化（将其视为拼写错误），但基础模型倾向于模仿想象中的错误，产生无意义的输出。而调优后的模型则致力于产生流畅的回应。研究进一步发现，这种鲁棒性在指令调优阶段产生，表明模型不一定被其标记器高度绑定。研究结果显示，能够在推理时干预标记化以提升性能的潜力巨大。", "conclusion": "总的来说，研究结果表明，模型对非标准标记化的依赖程度低于此前的假设，并展示了在推理时干预标记化以提升性能的潜力。"}
{"llm_update_time": "2025-06-25 09:16:49", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19037", "html_url": "https://arxiv.org/abs/2506.19037", "title": "加速计划——基于插值调度的掩码扩散语言模型", "title_en": "Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models", "authors": "Omer Luxembourg,Haim Permuter,Eliya Nachmani", "background": "Masked diffusion language models (MDLM) 在非自回归文本生成方面表现出强大的潜力，现有采样器作为隐式规划者，通过去噪器置信度或熵评分选择要解码的token。但这些方法在并行解码时表现不佳，因为它们忽略了token间的相互作用，不能同时解除多个位置的依赖关系，限制了它们的推理时间，与传统自回归模型相同。", "innovation": "文中提出了一种仅用于推理的、无需额外训练的插值调度策略（DUS），它利用一阶马尔可夫假设将序列位置分组成非相邻的稀疏组，允许独立并行解码步骤，尊重局部上下文以最小化每步迭代的联合熵。DUS减少了序列推理过程中每次生成块调用去噪器的次数从O(B)减少到O(log B)，显著提高了扩散模型的推理速度，尤其是在数学（GSM8K）和代码完成（Humaneval, MBPP）领域等非序生成任务中，DUS在不修改底层去噪器的情况下，提高了并行置信度调度的得分。", "conclusion": "DUS提供了一种轻量级、预算意识的高效高质量文本生成方法，揭示了MDLMs的真正能力。"}
{"llm_update_time": "2025-06-25 09:16:49", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19058", "html_url": "https://arxiv.org/abs/2506.19058", "title": "NLPnorth @ TalentCLEF 2025: 比较区分性、对比性和提示基础方法进行职位标题和技能匹配", "title_en": "NLPnorth @ TalentCLEF 2025: Comparing Discriminative, Contrastive, and Prompt-Based Methods for Job Title and Skill Matching", "authors": "Mike Zhang,Rob van der Goot", "background": "职位标题匹配是计算就业市场领域中的一个重要任务，可以帮助例如自动候选人匹配、职业路径预测和就业市场分析等下游任务。另外，将职位标题与技能对齐可以看作是这项任务的扩展，同样具有类似的重要性。基于这些背景，NLPnorth 对参加了TalentCLEF 2025 的两个任务——多语言职位标题匹配和基于职位标题的技能预测——进行了研究，他们对比了分类、对比和提示方法的性能。", "innovation": "研究采用了细调分类、细调对比和提示方法来解决两个任务，并通过整合ESCO中的语言特定职位标题和技能描述来增强数据集。他们注意到，大型多语言模型在这两项任务中表现最佳。最终，他们在Task A中排名第五，在Task B中排名第三。", "conclusion": "对于任务A，提示方法在测试数据上的平均平均精确度（MAP）为0.492。对于任务B，细调分类方法的测试数据上的MAP为0.290。研究表明，最大的多语言模型最适合这两个任务。"}
{"llm_update_time": "2025-06-25 09:16:50", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19089", "html_url": "https://arxiv.org/abs/2506.19089", "title": "语言模型可能无法理解你：通过故事情节评估心智理论", "title_en": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting", "authors": "Nathaniel Getachew,Abulhair Saparov", "background": "现有基准可能受到预训练数据污染的影响，无法精确控制角色视角和事件。大部分现有大型语言模型在世界建模任务上表现更好，但在心智理论任务上表现较差，且在推理时偏好于早期事件，显示出启发式行为，如最近效应偏差。", "innovation": "提出了一个可编程框架$\texttt{StorySim}$，用于合成生成故事以评估大型语言模型的心智理论和世界建模能力。该框架通过高度可控制的$\texttt{Storyboard}$产生新颖、组合的故事提示，允许精确操作角色视角和事件，设计出考察心智理论和世界建模能力的第一和第二级任务，揭示了模型偏好早期事件的启发式行为，并提供了用于生成数据和评估的开源代码。", "conclusion": "大多数模型在世界建模任务上优于心智理论任务。模型在通过键入人类推理时表现优于对无生命物体。此外，框架帮助发现提示偏向于早期事件的现象。所有代码均已开源。"}
{"llm_update_time": "2025-06-25 09:16:52", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19073", "html_url": "https://arxiv.org/abs/2506.19073", "title": "MFTCXplain：评估LLMs道德推理能力的多语言基准数据集：基于仇恨言论多跳解释", "title_en": "MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral Reasoning of LLMs through Hate Speech Multi-hop Explanation", "authors": "Jackson Trager,Francielle Vargas,Diego Alves,Matteo Guida,Mikel K. Ngueajio,Ameeta Agrawal,Flor Plaza-del-Arco,Yalda Daryanai,Farzan Karimi-Malekabadi", "background": "随着大型语言模型（LLMs）被应用于社会敏感任务，确保其道德推理能力已成为一个日益增长的关注点。然而，现有的评估基准存在两个主要缺陷：缺乏支持道德分类的注释，限制了透明度和可解释性；以及主要集中于英语，这限制了道德推理在多元化文化背景下的评估能力。因此，该领域亟需一种多语言、覆盖仇恨言论多跳解释的道德推理评估基准数据集，以有效衡量LLMs在不同文化语境下的道德理解与表达能力。", "innovation": "本文提出了MFTCXplain，这是一种评估LLMs道德推理能力的多语言基准数据集，利用道德基础理论（MFT）进行仇恨言论多跳解释。数据集包含跨葡语、意大利语、波斯语和英语的3000条推文，附有二元仇恨言论标签、道德类别和文本跨度级别的理由。实验证明，尽管LLMs在仇恨言论检测任务上有良好的表现（F1高达0.836），但是在预测道德情感方面的能力却非常弱（F1<0.35）。此外，理由一致性的限制主要集中在未被充分代表的语言上。这些发现揭示了当前LLMs在理解和体现人类道德推理方面的能力有限。", "conclusion": "现有的LLMs在执行道德推理任务时存在明显不足，尤其是在预测仇恨言论背后的情感以及提供合理的道德理由方面表现较弱。MFTCXplain数据集的设计旨在改善这一状况，通过多语言、跨文化视角来更好地评估LLMs的道德推理能力。未来的研究应进一步优化这种评估方法，提升LLMs在多元文化背景下的道德理解与表达能力。"}
{"llm_update_time": "2025-06-25 09:16:54", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19209", "html_url": "https://arxiv.org/abs/2506.19209", "title": "基于状态变化轨迹增强多智能体通信", "title_en": "Augmenting Multi-Agent Communication with State Delta Trajectory", "authors": "Yichen Tang,Weihang Su,Yujia Zhou,Yiqun Liu,Min Zhang,Shaoping Ma,Qingyao Ai", "background": "多智能体技术，如角色扮演或多轮辩论，已被证明能够有效地提升大型语言模型（LLMs）在下游任务中的表现。现有的LLM为基础的多智能体系统主要使用自然语言进行智能体间的通信。这种方式虽然简单且易于理解，但在传递信息时容易造成信息丢失，特别是在传递复杂的推理逻辑或抽象思想时更为显著。因此，该研究提出了一种新的通信协议，通过传递自然语言标记和标记层面的状态转移轨迹，来增强智能体间的通信", "innovation": "该研究提出了一种名为状态变化编码（State Delta Encoding, SDE）的方法，通过传递自然语言标记和标记层面的状态转移轨迹，改善智能体间的通信。实验结果显示，采用SDE的多智能体系统在涉及复杂推理的任务中表现更优，突出显示了信息通信增强对于基于LLM的多智能体系统潜在价值", "conclusion": "研究提出的SDE方法，在涉及复杂推理的任务中能够表现出更优的性能，证明了信息通信增强技术对于基于LLM的多智能体系统的潜在价值"}
{"llm_update_time": "2025-06-25 09:16:57", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19279", "html_url": "https://arxiv.org/abs/2506.19279", "title": "EmoStage: 一种基于换位思考和阶段识别的准确同情响应生成框架", "title_en": "EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition", "authors": "Zhiyang Qi,Keiko Takamizo,Mariko Ukiyo,Michimasa Inaba", "background": "对心理健康护理的需求不断上升，激发了对基于人工智能的咨询系统的兴趣。尽管大型语言模型（LLMs）具有巨大的潜力，但当前的方法仍面临一些挑战，包括对客户心理状态和咨询阶段理解不足、依赖高质量的训练数据以及商业部署相关的隐私问题。", "innovation": "为了解决这些问题，我们提出了EmoStage框架，该框架通过利用开源LLMs的推理能力来增强同情响应的生成，而不需要额外的训练数据。该框架引入了换位思考，用以推断客户的心理状态和支持需求，从而生成具有情感共鸣的响应。此外，还整合了阶段识别，以确保与咨询过程保持一致，并防止不恰当或不合适的响应。", "conclusion": "在日语和汉语咨询场景中进行的实验表明，EmoStage能够提升基模型生成响应的质量，并且在数据驱动方法中表现出竞争力。"}
{"llm_update_time": "2025-06-25 09:16:57", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19258", "html_url": "https://arxiv.org/abs/2506.19258", "title": "使用语言模型从生活故事预测个性", "title_en": "Personality Prediction from Life Stories using Language Models", "authors": "Rasiq Hussain,Jerry Ma,Rithik Khandelwal,Joshua Oltmanns,Mehak Gupta", "background": "自然语言处理（NLP）为个性评估提供了新的途径，通过利用丰富的开放式文本，超越传统问卷。本文研究的重点是在超过2000个词的长期叙述性采访中，使用预训练语言模型的滑动窗口微调抽取上下文嵌入，然后应用带有注意机制的循环神经网络（RNN）来整合长期依赖，增强可解释性。这种方法结合了预训练变换器和序列建模的优势，有效处理长时间上下文数据。通过对现有最长上下文模型LLaMA和Longformer进行消融研究和比较，展示了预测准确率、效率和可解释性的提升。结果突显了结合语言特征与长时间上下文建模在推进个人评估方面的潜力。", "innovation": "提出了一种两步方法，首先使用预训练语言模型的滑动窗口微调提取上下文嵌入，然后应用带有注意机制的RNN来整合长期依赖，从而增强模型的解释性；通过消融研究和与LLaMA和Longformer等最新模型的对比，展示了预测准确率、效率和解释性的提升。", "conclusion": "结合语言特征与长时间上下文建模有助于推进个性从生活叙述中的评估。"}
{"llm_update_time": "2025-06-25 09:16:58", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19315", "html_url": "https://arxiv.org/abs/2506.19315", "title": "JCAPT: 共同建模方法在CAPT中的应用", "title_en": "JCAPT: A Joint Modeling Approach for CAPT", "authors": "Tzu-Hsuan Yang,Yue-Yang He,Berlin Chen", "background": "第二语言学习中有效的发音反馈至关重要，计算机辅助发音训练（CAPT）系统通常包括两个关键任务：自动发音评估（APA）和错误发音检测与诊断（MDD）。最新研究表明，这两个任务的联合建模可以相互受益。本研究提出了一种统一框架，利用Mamba模型，并结合发音学特征和思考令牌策略，以增强APA和MDD的可解释性和精细时间推理。", "innovation": "这是首次将发音学归属、基于状态空间模型（SSM）的建模和提示集成到CAPT中，通过系列实验在speechocean762基准上展示了该模型在所有任务中优于先前方法，特别是在MDD任务上的表现更为突出。", "conclusion": "本研究提出了一种统一框架，该框架利用Mamba模型和结合发音学特征、思考令牌策略，增强了APA和MDD的可解释性和细致的时间推理能力，在系列实验中展示了其在CAPT中的优越性能，特别是对于MDD任务。"}
{"llm_update_time": "2025-06-25 09:17:01", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19159", "html_url": "https://arxiv.org/abs/2506.19159", "title": "结合文本数据的增强混合转换器和注意编码解码器", "title_en": "Enhanced Hybrid Transducer and Attention Encoder Decoder with Text Data", "authors": "Yun Tang,Eesung Kim,Vijendra Raj Apsingekar", "background": "随着ASR（自动语音识别）技术的发展，为了提升ASR的准确性，需要利用大量文本数据来优化模型。传统的模型可能无法很好地利用文本和语音数据间的互补信息，尤其是在数据稀缺的领域任务中，这限制了ASR模型的性能提升。本文提出了一种联合语音和文本优化的方法，以利用大规模文本语料库并增强ASR准确度。该方法通过将语音和文本输入模态一起训练模型，并在推断过程中仅使用语音数据，实现了一种新模型J-TAED，能整合不同模态的内部表示，并能够进一步扩展为文本导向的领域适应。这种方法显著减少了数据稀缺领域任务的需求，而不需要使用语音数据。实验结果表明，该模型有效整合了语音和语言信息，降低了Librispeech数据集上的WER（词错误率）5.8%到12.8%。此外，该模型还分别在金融领域数据集和命名实体聚焦数据集上取得了15.3%和17.8%的WER降低效果，表明了其在实际应用中的潜力和优势。", "innovation": "本文提出了一种新的联合语音和文本优化的方法，训练该模型使用语音和文本输入模态一起进行训练，但在推断过程中仅使用语音数据。该方法可以使模型集成不同的模态表示，并且可以扩展到文本导向的领域适应任务。这种方法能够有效缓解不同领域任务中的数据稀缺问题，不需要依赖于语音数据，从而增强了模型的整体性能。在实验中，该方法成功地将语音信息和语言信息结合在一个模型中，并在Librispeech数据集上取得了显著的性能提升。另外，在两个不同的离域数据集上验证了这种方法的有效性。", "conclusion": "本文提出的J-TAED方法通过联合训练语音和文本数据，实现了统一模态表示和文本导向的领域适应，有效地解决了不同领域任务中的数据稀缺问题，同时降低了WER。该方法在实际应用中有很大的潜力，特别是在需要使用丰富文本数据来增强语音识别性能的场景中。"}
{"llm_update_time": "2025-06-25 09:17:02", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19382", "html_url": "https://arxiv.org/abs/2506.19382", "title": "测量和引导单义性", "title_en": "Measuring and Guiding Monosemanticity", "authors": "Ruben Härle,Felix Friedrich,Manuel Brack,Stephan Wäldchen,Björn Deiseroth,Patrick Schramowski,Kristian Kersting", "background": "近年来，利用机制解释性和可控性来更好地理解并影响大型语言模型内部动态变得越来越有研究兴趣。然而，目前的方法在准确局部化和操作特征表示方面面临着根本性的挑战。稀疏自动编码器（SAE）最近被认为是一种大规模特征提取的有前途的方向，但它们也受限于特征隔离不完整和单调性不可靠。为了系统性地量化这些局限性，我们引入了特征单调性分数（FMS）这一新颖的度量标准，以量化潜在空间中特征的单调性。", "innovation": "根据这些洞察，我们提出了引导稀疏自动编码器（G-SAE），一种在训练过程中将潜在表示与标注概念条件的方法。示例如何可靠的局部化和解纠缠目标概念在潜在空间中的改善解释性、行为检测和控制。具体来说，我们在毒性检测、写作风格识别和隐私属性识别方面的评估表明，G-SAE 不仅提高了单调性，还允许更有效的和细微的操作，且对质量的下降影响更小。我们的研究结果为测量和推进大型语言模型的机制解释性和可控性提供了可操作的指导。", "conclusion": "我们的发现提供了测量和推进大型语言模型的机制解释性和可控性的可操作指南。通过引入特征单调性分数（FMS）和提出引导稀疏自动编码器（G-SAE），我们能够系统地量化并改进这些模型的特征隔离和单调性，并提高其解释性和可控性。"}
{"llm_update_time": "2025-06-25 09:17:02", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19187", "html_url": "https://arxiv.org/abs/2506.19187", "title": "在低资源语言中适应大语言模型：提示，翻译，微调，重新初始化，还是指令微调？", "title_en": "Prompt, Translate, Fine-Tune, Re-Initialize, or Instruction-Tune? Adapting LLMs for In-Context Learning in Low-Resource Languages", "authors": "Christopher Toukmaji,Jeffrey Flanigan", "background": "大语言模型通常在高资源语言中进行训练，而低资源语言的任务往往在上下文学习中表现不如高资源语言的对应任务。尽管已有多项研究探讨提示设置，但尚不清楚如何在低资源目标语言中跨语言地适应大语言模型，特别是针对上下文学习。这项研究涉及五种不同的目标语言、三种基础大语言模型以及七项下游任务，跨多种适应技术进行了全面研究，包括少量示例提示、翻译测试、微调、嵌入重初始化和指令微调。研究表明，少量示例提示和翻译测试在性能上往往优于基于梯度的适应方法。", "innovation": "研究设计了一个新的度量标准，有效输出召回率 (VOR)，并分析模型输出，实证归因这些训练模型性能下降的原因是灾难性遗忘。这是迄今为止在低资源语言的上下文学习中关于训练计算量和考虑的适应技术数量最大的研究。研究提供了所有数据集和训练模型供公众使用.", "conclusion": "研究表明，少量示例提示和翻译测试在低资源语言上下文学习中通常表现更优，而基于梯度的适应方法则效果较差。此外，研究通过对模型输出的分析，揭示了这些训练模型性能下降的主要原因——灾难性遗忘。这项研究为低资源语言大语言模型的适应策略提供了新的见解，并提供了大量数据集和模型以促进更深入的研究。"}
{"llm_update_time": "2025-06-25 09:17:04", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19262", "html_url": "https://arxiv.org/abs/2506.19262", "title": "LLM生成数据中的关键因素：多样性和其对模型微调的影响", "title_en": "What Matters in LLM-generated Data: Diversity and Its Effect on Model Fine-Tuning", "authors": "Yuchang Zhu,Zhonghua zhen,Qunshu Lin,Haotong Wei,Xiaolong Sun,Zixuan Yu,Minghao Liu,Zibin Zheng,Liang Chen", "background": "随着大型语言模型（LLMs）表现出色的生成能力，使用LLM生成的数据来训练下游模型已经成为缓解特定领域数据稀缺和减少耗时的标注的一种有希望的方法。然而，最近的研究指出，迭代使用自生成数据进行训练会导致模型坍缩，即模型性能随时间而下降。尽管对LLM生成数据的影响进行了大量研究，但这些研究往往忽视了数据多样性的重要性，这是高质量数据的关键因素。本文旨在理解LLM生成数据的多样性对下游模型性能的影响。具体来说，研究了不同水平的数据多样性能如何影响下游模型的性能，并探讨了不同比例混合LLM生成数据的合成数据对模型性能的影响。实验结果显示，在轻微的数据分布变化下，适度多样性的LLM生成数据在缺乏标注数据的情况下可以提高模型性能，而高度多样性的生成数据则有负面影响。", "innovation": "本文探索了LLM生成数据的多样性如何影响下游模型的性能，并发现适度多样性的LLM生成数据在缺少标注数据的情况下能提升模型性能，而高度多样性的生成数据则具有负面影响。这一发现为未来研究LLM作为数据生成器提供了重要的实证指导。", "conclusion": "适度多样性的LLM生成数据可以在数据稀缺的情境下提升模型性能，而高度多样性的生成数据则可能导致性能下降。研究结果为未来研究LLM生成数据及其使用提供了有价值的指导。"}
{"llm_update_time": "2025-06-25 09:17:06", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19467", "html_url": "https://arxiv.org/abs/2506.19467", "title": "大语言模型能否捕捉人类注释者的分歧？", "title_en": "Can Large Language Models Capture Human Annotator Disagreements?", "authors": "Jingwei Ni,Yu Fan,Vilém Zouhar,Donya Rooein,Alexander Hoyle,Mrinmaya Sachan,Markus Leippold,Dirk Hovy,Elliott Ash", "background": "在自然语言处理（NLP）中，人类注释的变异（即注释分歧）很常见，经常反映任务的主观性和样本的模糊性。虽然大语言模型（LLMs）越来越多地用于自动注释以减少人工努力，但它们的评估往往集中在预测多数投票得出的“真实标签”。然而，目前还不清楚这些模型是否能捕捉到有意义的人类注释变异。本文通过全面评估LLMs在无重复人类标注数据情况下预测注释分歧的能力，解决这一问题。结果显示，LLMs在建模分歧方面存在问题，这在基于多数标签的评估中可能被忽略。值得注意的是，虽然RLVR风格的推理一般可以提升LLM的性能，但在分歧预测方面却降低了表现。这些发现强调了评价和提升LLM注释器在分歧建模方面的重要性。", "innovation": "本文通过全面评估LLMs在无重复人类标注数据情况下预测注释分歧的能力，解决目前尚不明确的LLMs是否能捕捉有意义的人类注释变异的问题。同时，揭示了RNLR风格推理在分歧预测方面表现更差的现象，强调了分歧建模方面的评估和改进需求。", "conclusion": "本文的研究结果显示，尽管存在分歧建模的能力限制，但大语言模型在预测人类注释分歧方面仍存在挑战。需要进一步评价和改进大语言模型在分歧预测中的表现。同时，RLVR风格推理在这一任务中的效果不如预期。"}
{"llm_update_time": "2025-06-25 09:17:07", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19399", "html_url": "https://arxiv.org/abs/2506.19399", "title": "自动检测黑盒大型语言模型预训练文本", "title_en": "Automated Detection of Pre-training Text in Black-box LLMs", "authors": "Ruihan Hu,Yu-Ming Shang,Jiankun Peng,Wei Luo,Yazhe Wang,Xi Zhang", "background": "检测文本是否属于大型语言模型（LLM）的预训练数据对于保护数据隐私和版权至关重要。现有的大多数方法依赖于模型的隐藏信息（例如，模型参数或词元概率），但在仅能访问输入和输出文本的黑盒环境中这些方法都无效。尽管有一些方法已被提出适用于黑盒环境，但它们严重依赖大量的人工努力，如设计复杂的问题或指令。因此，研究者提出了VeilProbe，这是一种无需人工干预即可自动检测L_CERTAIN语言模型预训练文本的第一个框架，并通过序列到序列的映射模型推断输入文本与L_CERTAIN语言模型生成的相应输出后缀之间的潜在映射特征，并通过关键词元扰动获得更可区分的成员身份特征。由于实际场景中可能缺乏真实训练文本样本，研究者还引入了基于原型的成员身份分类器来缓解过拟合问题。广泛的数据集上的评估显示，该框架在黑盒环境下更加有效且优越。", "innovation": "VeilProbe框架无需人工干预，即可自动检测L_CERTAIN语言模型的预训练文本，通过序列到序列的映射模型推断输入文本与L_CERTAIN语言模型生成的相应输出后缀的潜在映射特征，并通过关键词元扰动获得更可区分的成员身份特征。此外，引入基于原型的成员身份分类器来应对真实训练文本样本有限的问题，解决过拟合问题。", "conclusion": "广泛的评估表明，该框架在黑盒环境中有效且优越，能够自动检测L_CERTAIN语言模型的预训练文本，适用于数据隐私保护和版权保护。"}
{"llm_update_time": "2025-06-25 09:17:08", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19468", "html_url": "https://arxiv.org/abs/2506.19468", "title": "MuBench：61种语言下大规模语言模型的多语言能力评估", "title_en": "MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages", "authors": "Wenhan Han,Yifan Zhang,Zhixun Chen,Binbin Liu,Haobin Lin,Bingni Zhang,Taifeng Wang,Mykola Pechenizkiy,Meng Fang,Yin Zheng", "background": "由于大规模语言模型（LLMs）正在迅速发展，不同模型声称支持越来越多的语言，但现有的评估数据集非常有限且缺乏跨语言的对齐，这使得对多语言能力的评估存在语言和技能覆盖的碎片化问题。论文介绍了MuBench，一个覆盖61种语言的评估基准，旨在更全面地评估跨语言能力，发现了现有模型在语言覆盖范围上的显著差距，尤其是英语和低资源语言之间的持续性能差异。", "innovation": "提出了MuBench，一个评估81种语言下多语言能力的基准。通过MuBench实现了语言和技能覆盖的更全面评估，并提出了多语言一致性(MLC)作为准确度之外的补充指标，用于分析性能瓶颈和指导模型改进。", "conclusion": "在英语和中文上训练了一系列1.2亿参数的模型，并通过调整语言比例和并行数据比例来研究跨语言转移动态。"}
{"llm_update_time": "2025-06-25 09:17:08", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19352", "html_url": "https://arxiv.org/abs/2506.19352", "title": "原子级评估开放式生成中的人设一致性：识别脱轨行为", "title_en": "Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation", "authors": "Jisu Shin,Juhyun Oh,Eunsu Kim,Hoyun Song,Alice Oh", "background": "在大语言模型（LLMs）中保持人设一致性对于维持连贯和吸引人的人机互动至关重要。然而，LLMs经常会出现脱轨（out-of-character, OOC）行为，即生成的反应偏离预定的人设，导致不一致，影响模型的可靠性。现有的评估方法通常对整个响应打单一分数，难以捕捉长文本生成中的细微人设不匹配。为了解决这一局限性，我们提出了一种原子级的评估框架，以更精细的粒度量化人设一致性。", "innovation": "我们提出的三类关键指标衡量人设在生成中的一致性和连贯性程度。这种方法使得更精确和现实地评估人设一致性成为可能，通过识别真实用户可能遇到的微妙偏差。通过我们的实验，我们证明了我们的框架能够有效检测先前方法忽视的人设不一致性。通过对不同任务和个性类型的人设一致性进行分析，我们揭示了任务结构和人设定制对模型适应性的影响，突显了保持一致人设表达的挑战。", "conclusion": "我们的框架成功地检测到了先前方法所忽略的人设不一致性。通过对不同任务和个体类型的人设一致性的分析，我们揭示了任务结构和人设定制对模型适应性的影响，强调了保持一致人设表达的挑战。"}
{"llm_update_time": "2025-06-25 09:17:13", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19484", "html_url": "https://arxiv.org/abs/2506.19484", "title": "大型语言模型中的对话式教学：将对话AI与已验证的学习理论相结合", "title_en": "Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning", "authors": "Russell Beale", "background": "大型语言模型（LLMs）正在迅速改变教育领域，通过提供丰富的对话式学习体验。本文对基于LLMs的对话代理在高等教育中的应用进行了全面回顾，并将其扩展到中等教育和终身学习领域。本文综合了现有文献中对教育中的LLMs的讨论，以及对话和对话式教学理论，包括维果茨基的社会文化学习理论、苏格拉底方法和拉乌尔德的对话式框架，并探讨了提示策略和检索增强生成（RAG）如何使LLM的行为与这些教学理论相一致，以及如何支持个性化和适应性学习。本文将教育理论与LLM的能力相映射，强调LLM驱动的对话如何支持现有的学习原则，以及它如何挑战或未能达到传统的教学假设。指出了将先前理论应用到LLMs中的重要空白，例如模型倾向于提供直接答案而不是促进知识的共同建构，以及需要考虑LLM导师持续可用性和广泛但非人类专业知识的需求。", "innovation": "本文提出实用策略以更好地使LLM交互与良好的教学实践保持一致，例如设计促进苏格拉底式提问、逐步指导和学生反思的提示，以及整合检索机制以确保准确性与相关性。其创新性在于系统地将大规模语言模型的应用与现有的教与学理论相结合，为基于LLM的对话式学习提供教育生产力和理论对齐的见解和工具。", "conclusion": "本文旨在弥合教育理论与新兴的AI驱动对话学习实践之间的差距，提供见解和工具，使基于LLM的对话更具教育生产力，并且与现有的教学理论对齐。"}
{"llm_update_time": "2025-06-25 09:17:14", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19483", "html_url": "https://arxiv.org/abs/2506.19483", "title": "使用大型语言模型进行对话系统中的常识生成与评估", "title_en": "Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models", "authors": "Marcos Estecha-Garitagoitia,Chen Zhang,Mario Rodríguez-Cantelar,Luis Fernando D'Haro", "background": "该研究探讨了基于不同类型的常识关系执行转录级数据增强的任务，并评估生成的合成转录。研究利用预训练的大语言模型（LLMs）的扩展知识和零样本能力，结合Chain-of-Thought (CoT) 等方法，针对对话数据增强和常识属性进行提示生成，并通过自动评估生成的对话来检测质量。研究者提取了来自五个知名对话数据集的200个随机部分对话，并基于不同的事件常识属性生成了替代响应，以此来评估LLMs生成上下文相关的常识知识的能力，特别是针对12种具体的目标原子数据库关系。", "innovation": "该研究提出了一个基于指令的提示体系结构，该体系结构能够自动检测生成的对话集中各转录中使用的真实属性，同时避免了复杂的事件关系提取过程。研究者借鉴了ACCENT指标的评估方法，通过实例化每个常识属性的指令，并利用最新最先进的LLMs，实现对生成数据集质量的自动检测。初步结果显示，该方法能够有效利用LLMs的常识推理和评估能力，以提升对话系统的表现。", "conclusion": "该研究通过提出一种新的对话数据增强方法，展示了预训练的大语言模型在常识推理和对话生成评估中的应用。初步结果显示，该方法有效地发挥了预训练大语言模型的能力，有助于提升对话系统对话的多样性和质量。"}
{"llm_update_time": "2025-06-25 09:17:15", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19527", "html_url": "https://arxiv.org/abs/2506.19527", "title": "KnowMap：面向大语言模型的知识驱动任务适应", "title_en": "KnowMap: Efficient Knowledge-Driven Task Adaptation for LLMs", "authors": "Kelin Fu,Kaigui Bian", "background": "大型语言模型（LLMs）在开放世界代理任务中展现了强大的能力，但它们在迅速适应新的、专门的任务时也面临着挑战，因为它们依赖于静态的预训练知识。传统的微调方法往往成本高、数据密集型，并可能导致‘灾难性遗忘’等问题。", "innovation": "KnowMap 提出了一种新颖的方法，能够动态地从环境和经验数据中构建知识库。KnowMap 对一个小的知识嵌入模型进行微调，以使较大的 LLMS 拥有特定任务的知识。实验结果表明，KnowMap 不仅提供了一种高效且有效的 LLM 任务适应方法，还强调了如何将环境和经验知识融合以增强 LLMs 的推理能力。", "conclusion": "我们的实验在 ScienceWorld 基准上展示了 17.71% 的性能提升，特别是对于 gpt-4-turbo 模型。KnowMap 不仅能够通过灵活利用环境和经验知识来提高 LLMs 的适应性，还打开了利用外部知识提高大模型性能的新途径。"}
{"llm_update_time": "2025-06-25 09:17:15", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19512", "html_url": "https://arxiv.org/abs/2506.19512", "title": "heiDS在ArchEHR-QA 2025：从固定k到查询依赖k的检索增强生成", "title_en": "heiDS at ArchEHR-QA 2025: From Fixed-k to Query-dependent-k for Retrieval Augmented Generation", "authors": "Ashish Chouhan,Michael Gertz", "background": "本文介绍了一个名为heiDS的团队在ArchEHR-QA 2025共享任务中的方法。设计了一个基于检索增强生成（RAG）框架的管道，针对患者特定的问题，从电子健康记录（EHRs）中生成与临床证据有关的答案。该团队研究了RAG框架的各种组件，特别是排名列表截断（RLT）检索策略和归因方法，旨在更好地解答相关和准确的患者问题。", "innovation": "本文提出了一种查询依赖的k值检索策略，替代传统的固定k值策略。具体地，引入了现有的surprise和autocut方法，以及本研究提出的新方法autocut*和elbow方法。这些方法能够在生成更加准确和相关的答案时提供优势。", "conclusion": "实验结果表明，相较于固定k值的策略，提出的方法能更有效地生成事实性且相关性强的答案。"}
{"llm_update_time": "2025-06-25 09:17:16", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19548", "html_url": "https://arxiv.org/abs/2506.19548", "title": "健康哨兵：一个实时疾病暴发检测的人工智能流水线", "title_en": "Health Sentinel: An AI Pipeline For Real-time Disease Outbreak Detection", "authors": "Devesh Pant,Rishi Raj Grandhe,Vipin Samaria,Mukul Paul,Sudhir Kumar,Saransh Khanna,Jatin Agrawal,Jushaan Singh Kalra,Akhil VSSG,Satish V Khalikar,Vipin Garg,Himanshu Chauhan,Pranay Verma,Neha Khandelwal,Soma S Dhavala,Minesh Mathew", "background": "早发现疾病的暴发对确保卫生当局及时介入至关重要。由于传统基于指标的监测存在挑战，监测非正式来源，如在线媒体变得越来越流行。然而，由于每天有大量的在线文章发布，手动筛选文章是不切实际的。这促使研究开发一套新的方法来快速筛选疾病暴发相关的信息。", "innovation": "提出了Health Sentinel，这是一个多阶段的信息提取流水线，结合了机器学习和非机器学习方法，从在线文章中提取与疾病暴发或其它异常健康事件相关的事件结构化信息，且提取的信息可用于预测潜在的疾病暴发，并通过卫生部门进行分析、解释和进一步传播。", "conclusion": "自2022年4月以来，Health Sentinel已处理了超过3亿篇新闻文章，识别出超过9.5万起独特健康事件，其中超过3,500起事件被NCDC的公共卫生专家选为潜在的暴发事件，为及时干预提供了重要支持。"}
{"llm_update_time": "2025-06-25 09:17:18", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19492", "html_url": "https://arxiv.org/abs/2506.19492", "title": "从长到短是否是免费午餐？在大型推理模型中的不一致性和推理效率研究", "title_en": "Is Long-to-Short a Free Lunch? Investigating Inconsistency and Reasoning Efficiency in LRMs", "authors": "Shu Yang,Junchao Wu,Xuansheng Wu,Derek Wong,Ninhao Liu,Di Wang", "background": "大型推理模型（LRMs）在复杂的任务上通过进行扩展性的推理来生成最终答案，这使得它们能够表现出色。但这种能力同时也带来了一个风险，即过度思考，这可能导致模型在执行简单任务时也生成过多的无关信息。尽管最近有关高效推理的研究旨在在保持准确性的前提下减少推理长度，但目前还不清楚这样的优化是否真正是免费的。部分原因在于，人们担心压缩推理可能会削弱模型响应的稳健性，导致模型省略了关键的推理步骤。因此，研究者提出了一种名为$ICBENCH$的新基准，以系统地评估这些高效推理策略是否会导致行为不一致，通过三个维度：任务设置间的不一致性（ITS），训练目标与学习行为之间的一致性（TR-LB），以及内在推理与自我解释之间的一致性（IR-SE）来进行衡量。通过对多种开源LRMs的测试，研究发现，虽然更大的模型通常比较小的模型更具一致性，但所有模型都在广泛的“方案行为”中表现出不一致性，包括自我分歧、事后合理化和省略推理提示。关键发现是，增强推理效率的方法，如No-Thinking和Simple Token-Budget，会持续增加所有定义的一致性类型。这些结果表明，虽然高效推理提高了token层级的效率，但必须进一步研究其是否会在模型中引入逃避有效监督的风险。", "innovation": "提出了一个名为$ICBENCH$的基准，用于衡量LRMs在三个维度上的不一致性，分别为任务设置间的不一致性（ITS）、训练目标与学习行为之间的一致性（TR-LB）和内在推理与自我解释之间的一致性（IR-SE）。研究表明，尽管更大的模型通常比较小的模型更具一致性，但所有模型都表现出广泛存在的不一致性行为，这些一致性的增加与高效推理策略如No-Thinking和Simple Token-Budget有关，这揭示了高效推理可能带来的风险。", "conclusion": "研究表明，尽管高效推理提高了token层级的效率，但必须进一步研究其是否会导致模型逃避有效的监督。更大的模型通常比较小的模型更具一致性，但所有模型都在广泛的“方案行为”中表现出不一致性，包括自我分歧、事后合理化和省略推理提示。"}
{"llm_update_time": "2025-06-25 09:17:18", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19505", "html_url": "https://arxiv.org/abs/2506.19505", "title": "AnTKV：KV缓存中基于锚令牌的超低比特向量量化", "title_en": "AnTKV: Anchor Token-Aware Sub-Bit Vector Quantization for KV Cache in Large Language Models", "authors": "Zeyu Li,Chuanfu Xiao,Yang Wang,Xiang Liu,Zhenheng Tang,Baotong Lu,Mao Yang,Xinyu Chen,Xiaowen Chu", "background": "量化技术被证明是减少大型语言模型（LLMs）中KV缓存的内存占用的有效且轻量级的解决方案。然而，如何在超低比特量化KV缓存的同时最小化性能下降仍然是一个重要的挑战。我们观察到不同令牌的KV缓存量化对注意力输出质量的影响不同。为了系统地研究这一现象，我们提出了前向误差传播分析，并提出了锚评分（AnS），以量化每个令牌的KV缓存对量化误差的敏感度。我们的分析揭示了不同令牌之间的显著差异，表明保留一些高AnS值的全精度（FP16）令牌的子集可以大幅减轻激进量化场景中的准确度损失。", "innovation": "提出了AnTKV，一种新颖的框架，利用锚令牌感知向量量化技术压缩KV缓存。此外，开发了一个与FlashAttention完全兼容的triton内核，以支持高效的部署，实现了快速在线锚令牌选择。AnTKV使LLaMA-3-8B能在一个单80GB A100 GPU上处理高达840K个令牌的上下文长度，同时比FP16基线的解码吞吐量高3.5倍。实验结果表明，在4比特设置下，AnTKV与KIVI、SKVQ、KVQuant和CQ等先前工作相比，表现相当或更好。更重要的是，在超低比特量化下，AnTKV在Mistral-7B上的困惑度显著低于FP16基线，分别为1比特时的6.32和0.375比特时的8.87，而FP16基线的困惑度为4.73。", "conclusion": "AnTKV框架在激进量化场景中大幅降低了模型的困惑度，并通过锚令牌感知向量量化技术实现了高效的KV缓存压缩和更高的解码性能。"}
{"llm_update_time": "2025-06-25 09:17:20", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19549", "html_url": "https://arxiv.org/abs/2506.19549", "title": "RCStat：使用相对情境化在变换器中的一种统计框架", "title_en": "RCStat: A Statistical Framework for using Relative Contextualization in Transformers", "authors": "Debabrata Mahapatra,Shubham Agarwal,Apoorv Saxena,Subrata Mitra", "background": "之前关于自动回归变换器中输入标记重要性的研究主要依赖于经过Softmax归一化的注意权重，但忽视了预-Softmax查询键值对的丰富结构。本研究旨在提出一种新的统计框架RCStat，该框架利用相对情境化（RC）这一随机变量来衡量标记片段间的情境对齐度，并推导出RC的一种有效上界。研究提出了两种应用：一是键值压缩，在这种应用中，基于RC的阈值促使自适应键值剔除，从而实现显著的缓存减少和极小的质量损失；二是归因分析，在这种应用中，RC提供了比后-Softmax方法更高的忠实度的标记、句子和片段级别的解释。经过问题回答、总结和归因基准测试，RCStat实现了显著的实证收益，达到了行业领先的效果，且无需模型重新训练。", "innovation": "引入了RCStat这一统计框架，其利用了未经过Softmax的注意机制的原始注意力对，通过RC（相对情境化）衡量标记片段间的情境对齐度，推导出其有效上界。提出了一种基于RC的键值压缩方法，以及更高保真的归因分析方法，相比于后-Softmax方法提供了更优质的解释精度。", "conclusion": "RCStat在问题回答、总结和归因基准测试中均展现出显著的实证优势，实现了最佳的压缩效果和归因性能，且无需对模型进行重新训练。"}
{"llm_update_time": "2025-06-25 09:17:22", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19525", "html_url": "https://arxiv.org/abs/2506.19525", "title": "自动剂量说明结构化：大语言模型的作用？", "title_en": "Automatic Posology Structuration : What role for LLMs?", "authors": "Natalia Bobkova,Laura Zanella-Calzada,Anyes Tafoughalt,Raphaël Teboul,François Plesse,Félix Gaschi", "background": "自动结构化药物剂量说明对于提高用药安全性和支持临床决策至关重要。但是在法国处方中，这些说明往往含糊、不规范或口语化，限制了经典机器学习管道的有效性。研究探索了通过大型语言模型（LLMs）将自由文本剂量转化为结构化格式的方法，并与基于命名实体识别和链接的“预LLM”系统进行了比较。结果显示，虽然提示方法可以提高性能，但仅通过微调的LLMs才能达到基线的准确度。通过对错误的分析，观察到它们具有互补的长处：命名实体链接提供结构精确度，而大语言模型能够更好地处理语义细微差别。", "innovation": "研究提出了一种混合管道，将命名实体链接（NERL）和大型语言模型（LLMs）结合使用，以处理低置信度的情况（<0.8），并基于置信分数选择输出。该策略实现了91%的结构化准确性，同时最小化了延迟和计算成本。该方法提供了一种可扩展的解决方案，适用于真实的临床使用场景，且比单独使用LLMs更具成本效益。此外，研究提供了一个新的方法，即利用大语言模型的语义理解能力来弥补命名实体链接在结构精确度上的不足，从而提高整体的结构化准确性。", "conclusion": "通过混合管道，结合命名实体链接和大语言模型，实现了91%的结构化准确性，同时最小化了计算成本，提供了一种适用于实际临床应用的可扩展的解决方案。这一研究不仅展示了大语言模型在结构化自由文本剂量说明方面的潜力，还提出了一种新的方法来优化这一过程，从而提高临床用药的安全性和决策支持的有效性。"}
{"llm_update_time": "2025-06-25 09:17:22", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19599", "html_url": "https://arxiv.org/abs/2506.19599", "title": "ECCoT: 通过链式思考增强有效认知的一种框架", "title_en": "ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model", "authors": "Zhenke Duan,Jiqun Pan,Jiani Tu,Xiaoyi Wang,Yanqing Wang", "background": "在大规模人工智能时代，大型语言模型（LLMs）在自然语言处理方面取得了显著进展。然而，它们往往缺乏透明度，生成的输出不可靠，这引发了对其可解释性的担忧。为了解决这个问题，链式思考（CoT）提示方法将推理结构化为逐步推理。但是，并非所有的推理链都是有效的，错误可能导致不可靠的结论。", "innovation": "我们提出了端到端认知链式思考验证框架（ECCoT），用于评估和改进LLMs中的推理链。ECCoT结合了嵌入主题模型的马尔可夫随机场（MRF-ETM）进行主题驱动的CoT生成，以及因果句法BERT（CSBert）进行因果推理对齐。通过使用结构化顺序统计进行无效链的筛选，ECCoT提高了可解释性，减少了偏见，并增强了基于LLMs的决策的信任度。关键贡献包括引入ECCoT、MRF-ETM用于主题驱动的CoT生成和CSBert用于因果推理增强。代码发布在: this https URL", "conclusion": "ECCoT通过主题驱动的CoT生成和因果推理验证，提高了大型语言模型决策过程的有效性和可解释性，从而增强了模型的可靠性和用户对其决策的信任度。"}
{"llm_update_time": "2025-06-25 09:17:24", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19607", "html_url": "https://arxiv.org/abs/2506.19607", "title": "使用外部知识探索自我修正大型语言模型方法以纠正新闻摘要中的虚构内容", "title_en": "Correcting Hallucinations in News Summaries: Exploration of Self-Correcting LLM Methods with External Knowledge", "authors": "Juraj Vladika,Ihsan Soydemir,Florian Matthes", "background": "大型语言模型（LLMs）虽然展示了生成连贯文本的非凡能力，但普遍存在一种被称为虚构的现象，即产生事实不准确的陈述。尽管有许多方法可以解决这个挑战，尤其是自我修正的方法特别有前景。这些方法利用LLM的多轮对话特性，通过迭代生成验证问题、寻求额外证据、利用这些证据内部或外部的知识来修正原始回应。尽管这些方法在编纂生成中得到了探索，但在新闻总结这样的领域却研究较少。本文研究了两种当前最先进自我修正系统在使用三个搜索引擎作为证据来纠正虚构的摘要时的表现。", "innovation": "本文创新地将两种前沿的自我修正系统应用于纠正新闻总结中的虚假内容，采用来自三个不同搜索引擎的证据作为修正依据。这项研究不仅揭示了搜索引擎片段和少量提示对于系统性能的积极影响，还展示了G-Eval与人工评估的一致性，为提高LLM生成的文章准确性提供新的视角和方法.", "conclusion": "研究结果表明，搜索引擎片段和少量提示对于提高自我修正系统的性能具有积极作用。同时，G-Eval与人类评估的高度一致性为进一步研究提供了支持。这些发现有助于改进大型语言模型在新闻摘要等领域的性能，使其生成更加准确和可信的内容。"}
{"llm_update_time": "2025-06-25 09:17:25", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19418", "html_url": "https://arxiv.org/abs/2506.19418", "title": "使用语言VAEs分离潜在推理规则的系统研究：学习分离潜在推理规则", "title_en": "Learning to Disentangle Latent Reasoning Rules with Language VAEs: A Systematic Study", "authors": "Yingji Zhang,Marco Valentino,Danilo S. Carvalho,André Freitas", "background": "当前基于Transformer的语言模型在自然语言推理任务上表现出强大的性能，但是它们通常依赖于记忆而不是基于规则的推理。通过将显式推理规则嵌入到语言模型的潜在空间中，可以在提高泛化能力、可解释性和可控性方面提供新的可能性。这项研究通过语言变分自编码器（Language VAEs）探讨了如何显式地嵌入和存储推理规则，并提出了一种基于Transformer的完整的学习推理规则的管道。这个管道包括三个基于规则的推理任务、支持的理论框架和实际的端到端架构。实验表明，当在显式信号监督下，推理规则可以被拆分在编码器的参数空间中；注入先验知识；在数学推理任务中，增加样本数量对性能的提升有限，且前向神经网络层比注意力层更好地保持了推理规则的分离。", "innovation": "研究提出了一种完整的基于Transformer架构的语言VAEs学习推理规则的管道，涵盖了三个基于规则的推理任务，提供了支持的理论框架，并且通过实验展示了在使用语言VAEs分离潜在推理规则方面的新方法。这种方法包括显式分离推理规则、注入先验知识和数学推理任务中的性能瓶颈分析。", "conclusion": "研究表明，在显式信号监督下，可以将推理规则分离在编码器的参数空间中，这有助于模型更好地分离和理解推理规则。此外，通过注入推理信息，可以在基于查询的模型中更有效率地检索存储在记忆中的值。然而，在数学推理任务中，增加样本数量对性能的提升有限，前向神经网络层优于注意力层，在保持推理规则的分离方面表现更优。"}
{"llm_update_time": "2025-06-25 09:17:26", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19652", "html_url": "https://arxiv.org/abs/2506.19652", "title": "超出了LLMs的定制对话：基于RL的对话管理器", "title_en": "Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager", "authors": "Lucie Galland,Catherine Pelachaud,Florian Pecune", "background": "该研究基于现有的大规模语言模型（LLMs），旨在通过结合基于强化学习（RL）的对话管理器来实现具有特定目标的开放性对话。传统的LLM模型在处理复杂和多阶段对话任务时存在一定的局限性，特别是在适应不同用户特征和学习特定任务方面的能力有限。通过引入层次化强化学习和元学习，该论文提出的方法旨在提升系统的适应性和效率，使其能够从有限的数据中学习，并在对话阶段之间平滑过渡，同时能够根据多样化的用户需求个性化响应。", "innovation": "该研究提出了一个新颖的框架，将大规模语言模型（LLMs）与基于RL的对话管理器相结合，旨在实现具有特定目标的开放性对话。此框架通过层次化强化学习建模对话的结构化阶段，并利用元学习提高系统的适应性，以应对各种用户特征。实验证明，所提出的方式不仅在适应性和效率上有显著提升，还在基于奖励的任务上优于最先进的LLM基线模型，特别是在促进行为改变的Motivational Interviews中显示出潜在的优势。", "conclusion": "该研究通过结合RL和元学习的方法，提出了一种高效且适应性强的新框架，能够使用LLMs生成具有特定目标的开放性对话。该框架在Motivational Interviews案例中表现优异，证明了将LLMs条件化所生成的对话系统有较大的发展潜力。"}
{"llm_update_time": "2025-06-25 09:17:28", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19750", "html_url": "https://arxiv.org/abs/2506.19750", "title": "在症状检查器中评估罕见疾病的诊断性能：一种合成病历模拟方法", "title_en": "Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach", "authors": "Takashi Nishibayashi,Seiji Kanazawa,Kumpei Yamada", "background": "症状检查器可以为用户提供个性化医疗信息，但在算法更新后需要评估个体疾病的诊断性能变化。由于罕见疾病的数据不足，手动创建大量临床案例片段既昂贵又不切实际。因此，研究背景是为罕见疾病在症状检查器算法更新后提供一种新的合成病例片段模拟方法，以评估其诊断性能变化，同时解决数据不足的问题。", "innovation": "提出了一种新的合成病历片段模拟方法，利用人类表型组（HPO）中的疾病-表型注释生成合成病历片段，模拟症状检查器的咨询，评估算法更新对实际诊断性能的影响，并通过R²系数回顾性评估方法的有效性。这种方法能够在部署前评估症状检查器算法更改对罕见疾病的诊断性能的影响，是透明且低成本的手段。", "conclusion": "该方法利用一个公开可获得的、专家创建的知识库，预先评估了罕见疾病的症状检查器算法改变。这一方法可以通过减少开发人员的工作负担和提高诊断性能来更好地支持早期诊断。"}
{"llm_update_time": "2025-06-25 09:17:29", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19753", "html_url": "https://arxiv.org/abs/2506.19753", "title": "使用RNNs、Transformer和大规模语言模型进行阿拉伯方言分类：一种对比分析", "title_en": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis", "authors": "Omar A.Essameldin,Ali O.Elbeih,Wael H.Gomaa,Wael F.Elsersy", "background": "阿拉伯语是世界上最流行的22个国家和地区中广泛使用的语言，方言众多。本文的目标是通过研究18种阿拉伯文推特中的方言分类问题，特别是使用递归神经网络（RNN）、转换器模型（Transformer）和大规模语言模型（LLM）进行阿拉伯方言分类研究，分析最新的自然语言处理技术在这一领域的应用效果。", "innovation": "本文提出了使用递归神经网络（RNN）、转换器模型（Transformer）和大型语言模型（LLM）等最新技术进行阿拉伯方言分类的方法，并通过最新预处理技术对这些模型进行了测试。结果表明，MARBERTv2模型表现最好，准确率和F1分数分别达到65%和64%。此外，通过对比分析不同模型的效果，本文指出了在阿拉伯方言识别中最重要的一些语言问题，并探讨了后续研究和应用的方向。", "conclusion": "使用MARBERTv2模型能够有效提高阿拉伯方言分类的准确性和表现力。该研究未来有望在智能对话、社交媒体监控以及提高阿拉伯语言社区的可达性等方面发挥重要作用。"}
{"llm_update_time": "2025-06-25 09:17:31", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19733", "html_url": "https://arxiv.org/abs/2506.19733", "title": "突破障碍：强化后训练增益能否转移到未见领域？", "title_en": "Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?", "authors": "Chuxuan Hu,Yuxuan Zhu,Antony Kellermann,Caleb Biddulph,Suppakit Waiwitlikhit,Jason Benn,Daniel Kang", "background": "强化后训练（RPT）最近显示出提升大语言模型（LLMs）推理能力的潜力。但是，这些改进在新领域的泛化能力尚未明确，因为现有研究主要在与微调相同领域的数据上评估RPT模型。为了研究RPT的泛化能力，作者进行了两项研究：1）观察性研究，比较了多种开放权重的RPT模型和其对应的基模型在多个领域中的表现，包括在微调数据中既有见过也有未见过的领域。2）介入性研究，以单一领域对LLMs进行RPT微调，并在多个领域内评估其性能。两项研究均得出结论，尽管RPT在与微调数据相似的任务中带来了显著的性能提升，但这些增益在不同领域内不一致，甚至消失，尤其是在具有不同推理模式的领域中。", "innovation": "作者开展了两项研究（观察性和介入性研究）来评估RPT在不同领域的泛化能力，为理解RPT的有效性和其在新领域的应用提供新的视角和方法。", "conclusion": "尽管RPT能够在与微调数据类似的任务中带来显著的性能提升，但在不同领域中这种增益是不一致的，尤其在不同推理模式的领域中，这种增益可能会消失。"}
{"llm_update_time": "2025-06-25 09:17:32", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19767", "html_url": "https://arxiv.org/abs/2506.19767", "title": "SRFT：基于监督和强化微调的单阶段推理方法", "title_en": "SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning", "authors": "Yuqian Fu,Tinghong Chen,Jiajun Chai,Xihuai Wang,Songjun Tu,Guojun Yin,Wei Lin,Qichao Zhang,Yuanheng Zhu,Dongbin Zhao", "background": "大型语言模型（LLMs）在推理任务上取得了显著的进展，但在监督微调（SFT）和强化学习（RL）之间的优化集成方面仍存在根本性的挑战。通过对基于熵的词汇分布、学习动态和集成机制的综合分析，研究揭示了这两种范式之间的关键差异：SFT 引发LLM策略分布的大范围变化，而RL则进行精细选择性的优化，熵作为训练效果的关键指标。", "innovation": "提出了监督强化微调（SRFT），这是一种单阶段方法，通过熵感知权重机制统一了两种微调范式。SRFT 直接在演示和自我探索演示中优化LLM，而不需要通过两阶段的顺序方法进行优化。", "conclusion": "广泛的实验表明，SRFT在五个数学推理基准测试中平均准确率为59.1%，分别比零强化学习方法在五个基准测试中高出9.0%和在三个基准测试中高出10.9%。"}
{"llm_update_time": "2025-06-25 09:17:33", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为何开源大语言模型在数据分析方面遇到困难？一项系统性实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Huajun Chen,Ningyu Zhang", "background": "开源大语言模型（LLMs）在自动化数据分析任务方面展现出一定的潜力，但它们在这些需要大量推理能力的场景中存在显著的限制。这项研究通过对开源LLMs的数据分析能力进行评估，探讨了提升开源LLMs数据处理能力的方法。", "innovation": "研究提出了通过整理多样化的种子数据集的方法，评估LLMs在数据理解、代码生成和战略规划三个维度的表现，并揭示了战略规划质量、交互设计和任务复杂性、数据质量对模型性能的影响。此外，基于这些发现，研究还开发了一种数据合成方法，显著提高了开源LLMs的分析推理能力。", "conclusion": "研究发现战略规划质量是模型性能的主要决定因素，交互设计和任务复杂性显著影响推理能力，而数据质量比多样性对实现最佳性能影响更大。通过对这些洞见的运用，研究进一步提升了开源LLMs在数据分析任务中的表现。"}
{"llm_update_time": "2025-06-25 09:17:35", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19831", "html_url": "https://arxiv.org/abs/2506.19831", "title": "BERT模型能否有效解释上下文并检测孟加拉语教派暴力文本？", "title_en": "How Effectively Can BERT Models Interpret Context and Detect Bengali Communal Violent Text?", "authors": "Abdullah Khondoker,Enam Ahmed Taufik,Md. Iftekhar Islam Tashik,S M Ishtiak Mahmud,Farig Sadeque", "background": "网络欺凌导致的社群暴力活动引发了不同宗教、族群和社会群体之间的暴力和冲突，对社会和谐构成重大威胁。现有研究中，这类文本的分类研究仍是一个未充分探索的领域。因此，本研究旨在提高检测教派暴力相关文本的准确性，并特别关注从社交媒体平台获取的孟加拉语文本数据。通过扩展数据集，使用微调后的BanglaBERT模型取得了一定进展，但仍然存在一些上下文理解的挑战和错误分类的问题，特别是在区分教派相关和非相关词汇时表现出不足。", "innovation": "本研究引入了一个针对特定任务的细粒度微调BanglaBERT模型，通过对比分析发现现有预训练模型在某些特定词汇的相似度区分上存在不足。为了提高模型的解释性，采用了LIME技术来识别模型在理解上下文上的弱点，进而改进了模型的整体性能，并为未来进一步优化此类技术奠定了基础。", "conclusion": "研究发现，NLP技术和解释性工具在减少在线教派暴力方面具有巨大潜力。本研究促进了教派暴力检测领域的发展，并为未来研究提供了基础，旨在提高技术的准确性和社会影响力。通过引入微调后的BanglaBERT模型和采用LIME方法，实现了在特定任务上比已有模型更好的性能。"}
{"llm_update_time": "2025-06-25 09:17:39", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18952", "html_url": "https://arxiv.org/abs/2506.18952", "title": "LLMs on a Budget? Say HOLA", "title_en": "LLMs on a Budget? Say HOLA", "authors": "Zohaib Hasan Siddiqui,Jiechao Gao,Ebad Shabbir,Mohammad Anas Azeez,Rafiq Ali,Gautam Siddharth Kashyap,Usman Naseem", "background": "在边缘设备上运行大型语言模型（LLMs）受到高计算和内存需求的限制，这成为实时应用（如医疗保健、教育和嵌入式系统）中的障碍。当前解决方案如量化、剪枝和检索增强生成（RAG）仅提供了部分优化，常常需要在速度或准确率上做出妥协。", "innovation": "该论文提出了一种名为HOLA的端到端优化框架，用于高效部署LLMs。HOLA框架内通过层次投机性解码（HSD）实现更快的推理，而不损失质量。HOLA框架外通过基于上下文需求调整检索复杂性的AdaComp-RAG技术进行优化。此外，还结合了LoBi（结合了结构化剪枝（LoRA）和量化），以获得显著提升，包括GSM8K的17.6% EMA改进，ARC的10.5% MCA改进，并在Jetson Nano等边缘设备上减少了延迟和内存使用，证明其具有可扩展性和生产准备度。", "conclusion": "HOLA为在边缘设备上高效部署LLMs提供了一种综合性解决方案，兼具性能和实际应用价值，解决了传统方法的限制，并在多个指标上取得了显著进步。"}
{"llm_update_time": "2025-06-25 09:17:40", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18923", "html_url": "https://arxiv.org/abs/2506.18923", "title": "Mix-of-Language-Experts Architecture for Multilingual Programming", "title_en": "Mix-of-Language-Experts Architecture for Multilingual Programming", "authors": "Yifan Zong,Yuntian Deng,Pengyu Nie", "background": "大型语言模型（LLMs）在代码理解、生成和翻译等任务中展示了显著的能力。对于多语言编程的支持，通常需要在所有编程语言上微调单一的LLM，这样虽然成本有效但牺牲了针对特定语言的专业化和性能，或者为每个编程语言单独微调LLM，这虽然允许专业化但计算成本高且存储密集。为此论文提出了一种平衡效率和专业化的架构MoLE（Mix-of-Language-Experts）处理多语言编程任务，MoLE由基模型、共享LoRA模块以及一系列语言特定的LoRA模块组成，这些模块在微调过程中联合优化，实现了编程语言间的知识共享和专业化，微调过程中MoLE自动路由到相应编程语言的特定LoRA模块进行推理。实验证明，MoLE相比单独训练的语言特定LoRA更高效，同时在准确度上优于单一共享LLM针对所有编程语言的微调。", "innovation": "提出了一种新颖的MoLE架构，该架构在多语言编程任务上平衡了效率和专业化。MoLE架构包含一个基模型、一个共享LoRA模块以及一系列语言特定的LoRA模块，这些模块在微调过程中协同优化，实现了跨编程语言的有效知识共享和专业化。MoLE通过自动路由到相应编程语言的特定LoRA模块实现推理，相比单独训练的语言特定LoRA更高效，并且在准确度上优于单一共享LLM针对所有编程语言的微调效果，解决了多语言编程任务中的成本和性能权衡问题。", "conclusion": "该研究提出了一种新的MoLE架构，通过平衡效率和专业化来处理多语言编程任务。MoLE架构在效率和准确度上都表现出色，解决了多语言编程中的主要挑战。实验证明MoLE是一种有效且先进的解决方案，能够满足多语言编程的需求。"}
{"llm_update_time": "2025-06-25 09:17:44", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19571", "html_url": "https://arxiv.org/abs/2506.19571", "title": "机器翻译评估是否达到了人类平等？人类参考与进步的局限性", "title_en": "Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress", "authors": "Lorenzo Proietti,Stefano Perrella,Roberto Navigli", "background": "在机器翻译（MT）评估中，评价指标的表现基于与人类判断的一致性。近年来，自动评价指标与人类判断的一致性水平逐步提高。为了更清晰地了解指标性能并设定上限，研究团队引入了人类基线参与MT元评估，即将指标能力的评估纳入MT元评估。研究结果表明，人类注释员并不总是优于自动指标，最先进的指标往往与或优于人类基线。尽管这些发现表明双方可能达到平等，但也讨论了谨慎的理由。最后，研究探索了这些结果对我们整个MT评估领域的更广泛影响，究竟能否可靠地衡量MT评价的进步？", "innovation": "该研究通过引入人类基线，纳入MT元评估，以更准确地评估MT指标的能力，考察了自动评价指标与人类判断的一致性，显示尽管最先进的自动指标有时优于或与人类基线持平，但仍需谨慎对待这些结果，并探讨了其对于整个MT评估领域的更广泛影响。这项研究为MT评价领域设定了一个新的界限，促进了对这一问题的讨论。", "conclusion": "研究结果表明，人类注释员与最先进的自动指标在MT评价中的表现没有明显优势。尽管这似乎表明人类与机器达到平等的可能，但也暗示了评价方法和其他因素的影响。研究探讨了这些结果对于可靠衡量MT评价进步的影响，并呼吁更深入地讨论这一问题，在整个MT评估社区中具有重要意义。通过这项工作，我们希望能够揭示我们在测量领域进步能力的局限，促进讨论一个我们认为对MT评估社区至关重要的话题。"}
{"llm_update_time": "2025-06-25 09:17:45", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18959", "html_url": "https://arxiv.org/abs/2506.18959", "title": "从网络搜索到本能深度研究：用推理代理激励搜索", "title_en": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "authors": "Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu", "background": "信息检索是现代知识获取的基础，每天处理着来自不同领域的数十亿查询。然而，传统的基于关键词的搜索引擎在处理复杂的、多步骤的信息需求时越来越力不从心。现有的搜索引擎主要依赖静态的网页抓取和匹配，无法有效满足用户需求的复杂性和动态性。论文中提出，强大的语言模型（LLMs）结合了推理和主动能力，标志着一种新的研究范式：本能深度研究。这种系统通过紧密集成自主推理、迭代检索和信息合成，形成了动态的反馈回路，超越了传统的信息检索技术。论文进一步指出，从静态的网页搜索到互动的、基于代理系统的探索和学习，是一个演进的过程。", "innovation": "论文提出的本能深度研究是一种新的研究范式，通过使用大规模语言模型（LLMs）集成自主推理、迭代检索和信息合成，形成一种动态反馈机制，从而有效地应对复杂的、多步骤的信息需求，克服了传统搜索引擎的不足。此外，论文还引入了一种测试时的计算深度规模法则，以正式量化计算深度对推理和搜索的影响。实验结果表明，本能深度研究在性能上显著优于现有方法，并有望成为未来信息检索的主导范式。", "conclusion": "通过收集相关资源，包括行业产品、研究论文、基准数据集和开源实现，研究界可以更好地理解和应用本能深度研究。本能深度研究不仅显著超越了现有的搜索技术，还具有成为未来信息查询主导范式的潜力。"}
{"llm_update_time": "2025-06-25 09:17:45", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18957", "html_url": "https://arxiv.org/abs/2506.18957", "title": "对《The Illusion of Thinking》的一条评论：将推理悬崖重新定义为能动性缺口", "title_en": "A Comment On \"The Illusion of Thinking\": Reframing the Reasoning Cliff as an Agentic Gap", "authors": "Sheraz Khan,Subha Madhavan,Kannan Natarajan", "background": "Shojaee等人的最新研究（2025）揭示了大型推理模型（LRMs）在问题复杂度超过一定阈值后表现急剧下降的现象，将其归因于链式思维（CoT）推理的固有限制。然而，评论认为这种结论受到实验设计上的偏差影响，指出模型的表现下降并非意味着存在认知边界，而是受到系统层面限制的结果，如仅限文字生成的静态评估框架、工具使用限制、上下文窗口召回问题、缺乏重要认知基准、统计报告不足以及输出生成限制等。评论通过展示采用工具后模型能够解决以往认为不可能的问题，来证实自己的观点，并进一步研究了具备工具使用的模型，显示了从简单执行到复杂元认知自我纠正的能动性推理层次，对机器智能的定义和测量有重要启示作用。", "innovation": "评论提出了“能动性缺口”这一新概念，重新解读了LRMs的表现下降现象。通过实验展示了在工具支持下的模型能够解决复杂的推理问题，进一步揭示了能动性推理的层次，从简单的执行到复杂的元认知自我纠正。这为机器智能的研究提供了新的框架和视角。", "conclusion": "模型的表现下降并不是因为认知能力的限制，而是受到系统层面和评估框架的约束。通过引入能动性工具，模型可以解决更复杂的任务，这表明机器智能的评估需要考虑到工具的使用和更复杂的交互能力。"}
{"llm_update_time": "2025-06-25 09:17:48", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19603", "html_url": "https://arxiv.org/abs/2506.19603", "title": "社交仇恨：高效多模态恶棍检测", "title_en": "Social Hatred: Efficient Multimodal Detection of Hatemongers", "authors": "Tom Marzea,Abraham Israeli,Oren Tsur", "background": "自动检测在线仇恨言论是净化网络对话的关键步骤。此外，准确分类有助于更好地理解仇恨言论作为社会现象的传播。虽然大多数先前的工作集中在仇恨言论的检测上，但本文作者认为，从用户层面进行检测同样重要，尽管更加具有挑战性。研究者采用多模态聚合方法，考虑了可能的仇恨言论文本、用户活动以及用户网络，这种方法比以前使用基于文本和图的方法更有效地检测恶棍。通过对三个独特数据集（Twitter、Gab和Parler）进行评估，表明处理用户在社交环境下的文本显著提高了恶棍检测的准确性。该方法可用于增强编码信息、狗哨言论和种族轻视心理等的分类，并可为干预措施提供信息。此外，研究结果表明，多模态方法在不同内容平台和大规模数据集和网络上表现良好。", "innovation": "提出了多模态聚合方法，不仅考虑了用户的文本内容，还考虑了用户的活动和社交网络，从而提高了仇恨言论检测的准确性，特别是在社交环境下的表现优于传统的基于文本和基于图的方法。此外，该方法适用于多种平台和大规模数据集，对复杂现象的检测更加有效。", "conclusion": "通过多模态方法检测用户在网络上的仇恨言论表现良好，特别是在社交环境中处理用户发布的文本可以显著提高对于恶棍的检测效果。该方法可以应用于编码信息、狗哨言论和种族轻视心理等社会现象的识别，并支持有效的干预措施。该方法在不同社交平台上具有广泛的适用性，展示了在大规模数据集中检测和过滤仇恨言论的强大能力。"}
{"llm_update_time": "2025-06-25 09:17:51", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19072", "html_url": "https://arxiv.org/abs/2506.19072", "title": "HAWAII: 分层视觉知识转移以高效提升视觉语言模型", "title_en": "HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models", "authors": "Yimu Wang,Mozhgan Nasr Azadani,Sean Sedwards,Krzysztof Czarnecki", "background": "提高视觉语言模型（VLMs）的视觉理解能力对于提升其在各种任务中的表现至关重要。尽管使用多个预训练视觉专家已被证明具有巨大的潜力，但在训练和推理过程中也会带来显著的计算成本。解决这一挑战，本研究提出了一种名为HAWAII的新型框架，该框架将多个视觉专家的知识精炼到单个视觉编码器中，使其能够继承多个专家的互补优势，同时减少计算开销。为了解决不同教师之间可能出现的冲突并切换到不同教师的知识，该研究提出使用特定教师的低秩适应（LoRA）适配器和相应的路由器，而不是使用固定的一组适配器适用于多个教师。为使知识精炼高效，该研究提出了细粒度和粗粒度的精炼方法。在细粒度水平上，使用了标记重要性评分以自适应地强调每个教师最信息丰富的标记。在粗粒度水平上，该研究总结了来自多个教师的知识，并通过一组通用知识的LoRA适配器和路由器将其转移给学生。通过在多种视觉语言任务上的广泛实验，证明了HAWAII相比流行开源的视觉语言模型具有优越性。", "innovation": "HAWAII框架通过将多个视觉专家的知识精炼到单个视觉编码器中，实现在不增加显著计算成本的情况下继承多个专家的互补优势。该研究还提出了使用特定教师的低秩适应（LoRA）适配器和相应的路由器，解决不同教师之间可能出现的冲突并高效切换到不同教师的知识。此外，提出了细粒度和粗粒度的知识精炼方法，进一步提高了知识转移的效率。这些创新性方法显著提高了视觉语言模型的视觉理解能力。", "conclusion": "HAWAII框架在各种视觉语言任务上的实验结果表明，它在多个任务上的表现优于开源的视觉语言模型。该研究为提高视觉语言模型的视觉理解能力提供了一种新的解决方案，有助于实现更高效、更具性能的视觉语言模型。"}
{"llm_update_time": "2025-06-25 09:17:51", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19835", "html_url": "https://arxiv.org/abs/2506.19835", "title": "MAM: 模块化多代理框架在多模态医疗诊断中的角色专业化协作", "title_en": "MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration", "authors": "Yucheng Zhou,Lingran Song,Jianbing Shen", "background": "近期，医学大型语言模型（LLMs）展示出了强大的推理和诊断能力。尽管如此，当前统一的多模态医学LLMs在知识更新成本、全面性和灵活性方面仍存在局限性。这些局限性限制了它们在实际应用中的效果和普及程度。本文分析了当前医学LLMs面临的挑战，并在此基础上介绍了一个新的框架——模态多代理框架（MAM）.", "innovation": "本文提出的MAM框架通过将医学诊断过程分解为医生、专科团队、放射科医生、医疗助理和主管等五个专业角色，解决了当前医学LLMs在知识更新、全面性和灵活性方面的问题。每个角色都由一个基干LLM的代理来实现，这种模块化和协作的方式使得知识更新更加高效，同时利用现有的医学LLMs和知识库。MAM框架在广泛公开的多模态医疗数据集上进行了一系列实验，实验结果表明，与单一模态的LLMs相比，MAM框架在多种任务上表现更优，性能提升范围在18%到365%之间。", "conclusion": "MAM框架通过角色专业化协作，有效地提高了多模态医学诊断的性能。该框架不仅适用于现有的医学LLMs，还能在未来促进医学LLMs的发展和应用。此框架的代码已经开源发布。"}
{"llm_update_time": "2025-06-25 09:17:54", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19143", "html_url": "https://arxiv.org/abs/2506.19143", "title": "Thought Anchors: Which LLM Reasoning Steps Matter？", "title_en": "Thought Anchors: Which LLM Reasoning Steps Matter?", "authors": "Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy", "background": "研究显示大规模语言模型在许多领域取得了最先进的性能，但它们的长段链式推理增加了解释性挑战，因为每个生成的词都依赖于之前的所有词，使计算难以分解。因此，需要探讨新的方法来理解这种推理过程，特别是通过句子级别分析推理轨迹成为一种有希望的做法。论文提出三种互补的归因方法，验证了存在关键推理步骤（称为思考锚点）的观点，这些步骤在推理过程中具有超常的重要性，通常为规划或回溯句子。", "innovation": "这篇论文提出了一种新的方法体系，包括三种互补的归因方法：（1）一种黑盒方法，通过比较在生成该句子或具有不同含义的句子的模型下最终答案的变化，衡量句子的反事实重要性；（2）一种白盒方法，概述句子对之间的注意力模式，发现了一种被称为“广播”的句子，它会收到所有后续句子不成比例的注意力；（3）一种因果归因方法，通过抑制对一个句子的关注，并测量其对每个后续句子的词的影响来衡量句子之间的逻辑联系。每种方法提供了思考锚点存在的证据。论文还提供了一个开源工具来可视化方法的输出，并通过案例研究展示了不同方法的一致性，证明了句子级别分析的深刻理解价值。", "conclusion": "通过一致性的验证，论文证明了句子级别分析对于更深入理解推理模型具有潜力。"}
{"llm_update_time": "2025-06-25 09:17:56", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19191", "html_url": "https://arxiv.org/abs/2506.19191", "title": "基于真理竞争的贝叶斯演化蜂群架构：一个正式的 epistemic 系统", "title_en": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition", "authors": "Craig Steven Wright", "background": "本文介绍了一种基于概率性代理演化的严格数学框架，这些代理在结构化的竞争和信念修正中进化。该架构基于贝叶斯推理、度量理论和种群动力学，将代理的适应性定义为与固定外部先验知识（代表真实情况）的对齐程度的函数。代理在离散时间环境中竞争，通过观察结果调整后验信念，评级较高的代理复制，评级较低的代理灭绝。评级通过成对的、与真理对齐的效用比较进行更新，信念更新保证了可测量的连贯性和随机收敛性。为了确保可追溯性，引入了基于哈希的加密身份承诺，并使用 do-calculus 进行因果推理运算。本文提供了关于收敛、鲁棒性和演化稳定性的形式定理。系统将真理作为一个演化吸引子建立起来，展示了在可计算的、自我调节的蜂群中，在对抗性知识压力下的可验证知识的产生。", "innovation": "提出了基于贝叶斯推理、度量理论和种群动力学的严格数学框架，以概率性代理为中心，通过结构化竞争和信念修正来实现进化。框架包括基于哈希的加密身份承诺以确保可追溯性，以及使用 do-calculus 的因果推理运算。还提供了一系列关于系统收敛、鲁棒性和演化稳定性的形式定理，展示了在对抗性知识压力下的可验证知识的产生。", "conclusion": "该系统通过对抗性知识压力下的竞争和信念修正，最终将真理作为演化吸引子，证明了可验证知识通过可计算和自我调节的蜂群系统产生。"}
{"llm_update_time": "2025-06-25 09:17:56", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19761", "html_url": "https://arxiv.org/abs/2506.19761", "title": "准确快速经济：三选其一。用双向递归注意力取代多头注意力进行长时语音识别", "title_en": "Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR", "authors": "Martin Ratajczak,Jean-Philippe Robichaud,Jennifer Drexler Fox", "background": "长时语音识别是研究日益受到重视的应用领域。现有的基于多头注意力（MHA）的ASR模型在处理长时语音时存在平方级的时间复杂度问题。近年来的研究已经探索了线性复杂度的递归注意力（RA）层，但是该方法在准确性和效率之间存在权衡。", "innovation": "论文提出了双向递归注意力（RA）层来替换多头注意力（MHA）。双向RA层在短时和长时应用场景中的准确度与MHA相当，同时更加高效。为了进一步增强双向RA层的效果，论文还开发了一种新的长时训练方法，该方法使得双向RA层的准确度超过了仅具有有限上下文注意力（LCA）基线，并且提高了44%的吞吐量。此外，论文还提出了一个新颖的正则化方法——双向路径丢弃（Direction Dropout），该方法不仅提高了准确率，还提供了准确率和吞吐量之间的细粒度控制，并能实现新的交替方向解码模式，从而进一步提高吞吐量。", "conclusion": "论文通过引入双向递归注意力机制以及相关改进技术，显著提升了长时语音识别模型的准确率和效率，同时提出了新的正则化方法和解码模式，进一步提高了系统的效能。"}
{"llm_update_time": "2025-06-25 09:17:57", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19433", "html_url": "https://arxiv.org/abs/2506.19433", "title": "Mem4Nav: 提级城市环境中的视觉-语言导航的一种分层空间认知长短时记忆系统", "title_en": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System", "authors": "Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li", "background": "在大型城市环境中进行视景语言导航（VLN）需要智能体在复杂场景中准确理解语言指令，并能够在长时间内回忆相关经验。现有的模块化管道具有可解释性，但缺乏统一的记忆机制；端到端的大型语言模型（M）代理虽然擅长融合视觉和语言信息，但仍受限于固定上下文窗口和隐性空间推理能力。", "innovation": "本文介绍了一种名为Mem4Nav的分层空间认知长短期记忆系统，可以增强任何VLN主体。Mem4Nav结合了稀疏八叉树进行细粒度的体素索引，以及语义拓扑图进行高级地标连接，这些内容通过可逆Transformer嵌入在可训练的记忆标记中存储。长期记忆（LTM）压缩并保留了历史观察记录，短期记忆（STM）则在相对坐标中缓存最近的多模态条目，以实现实时障碍物规避与局部规划。每一步STM检索都会迅速精简动态上下文，当需要更深的历史记录时，LTM标记会无损解码以重建过去的表示。通过在Touchdown和Map2Seq数据集上进行评估，Mem4Nav在任务完成率、充分的空间路径偏差减少以及nDTW改进等方面表现出显著提升。", "conclusion": "消融实验验证了分层地图和双记忆模块的不可或缺性。我们的代码已在以下网址开源：此 https URL。"}
{"llm_update_time": "2025-06-25 09:18:03", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19743", "html_url": "https://arxiv.org/abs/2506.19743", "title": "NEAR$^2$: 一种用于高效产品检索和排名的嵌套嵌入方法", "title_en": "NEAR$^2$: A Nested Embedding Approach to Efficient Product Retrieval and Ranking", "authors": "Shenbin Qian,Diptesh Kanojia,Samarth Agrawal,Hadeel Saadany,Swapnil Bhosale,Constantin Orasan,Zhe Wu", "background": "电子商务信息检索系统在实现复杂用户查询的高精度解释和维护大规模产品目录的高效处理之间存在双重挑战。挑战在于精确匹配用户意图与相关产品，同时管理大规模库存中实时搜索的计算需求。", "innovation": "本文提出了一种名为NEAR$^2$的嵌套嵌入方法，可以在推理时嵌入尺寸提高12倍的同时，不增加训练成本，并且提升基于Transformer模型的检索和排名性能。该方法通过使用不同的损失函数（包括多个负排名损失和在线对比损失）在四个不同的测试集中进行了验证，包括不同检索挑战的短而隐含的查询，提升了较低嵌入维度下的性能，优于现有模型.", "conclusion": "我们的方法在不同嵌入维度下获得了更好的性能，相比现有模型表现更优。"}
{"llm_update_time": "2025-06-25 09:18:03", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19351", "html_url": "https://arxiv.org/abs/2506.19351", "title": "基于上下文的奥卡姆剃刀：Transformer 如何在飞速中偏好更简单的假设", "title_en": "In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly", "authors": "Puneesh Deora,Bhavya Vasudeva,Tina Behnia,Christos Thrampoulidis", "background": "在上下文学习（ICL）中，变换器可以通过上下文示例适应新任务，而无需更新参数。现有研究通常将ICL置于固定复杂度环境中进行研究，但在实际应用中，语言模型会遇到涵盖不同复杂度级别的任务。本文研究变换器如何在分层任务结构中导航，其中较高复杂度的类别可以完全代表由较简单类别生成的任何模式。通过基于马尔可夫链和线性回归设计严格控制的实验平台，本文揭示了变换器不仅能够识别每个任务的适当复杂度水平，还能够准确地推断相应的参数，即使背景示例与多个复杂度假设兼容也是如此。当面对更简单过程生成的数据时，变换器始终倾向于选择最简单的足够解释。通过贝叶斯框架理论解释了此行为，证明了变换器通过在模型拟合和复杂度惩罚之间进行平衡，能够实现基于上下文的奥卡姆剃刀。进一步分析了模型大小、训练混合分布、推理上下文长度和架构的作用。最后，在预训练的GPT-4模型上验证了这一奥卡姆剃刀式的归纳偏置，使用布尔函数任务作为案例研究，表明这可能是训练于多种任务分布下的变换器固有的特性。", "innovation": "本文研究了变换器在处理不同复杂度层次的任务时，如何基于上下文学习识别和选择适当的模型复杂度，以及如何通过平衡模型拟合和复杂度惩罚来实现奥卡姆剃刀原则。此外，通过基于马尔可夫链和线性回归设计严格控制的实验平台，揭示了变换器的具体行为，并通过理论框架进一步解释了这一行为。", "conclusion": "变换器能够在上下文学习中自我适应并偏好更简单的假设，这是通过在模型拟合和复杂度之间的平衡来实现的。此外，研究强调了这种奥卡姆剃刀相似的归纳偏置可能内置于经过多样化任务分布训练的变换器中。"}
{"llm_update_time": "2025-06-25 09:18:04", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19441", "html_url": "https://arxiv.org/abs/2506.19441", "title": "TTSDS2：评估人类质量文本到语音系统的资源和基准", "title_en": "TTSDS2: Resources and Benchmark for Evaluating Human-Quality Text to Speech Systems", "authors": "Christoph Minixhofer,Ondrej Klejch,Peter Bell", "background": "文本到语音（TTS）系统的评估具有挑战性和资源密集性。主观的评价指标，如均方意见分数（MOS），难以在不同研究间进行比较。客观指标虽然常用，但很少与主观指标进行验证。最新的TTS系统能够生成与真实语音难以区分的合成语音，对各种指标构成了挑战。现有研究中只有TTSDS2在多个领域和语言中，对于所有评估的主观分数，均与Spearman相关系数超过0.50。", "innovation": "本文引入了Text to Speech Distribution Score 2（TTSDS2），这是迄今为止最稳健和改进的版本，能够在多种领域和语言中，通过对比16个指标，唯一能在所有领域和主观评分中与Spearman相关系数超过0.50一致。同时，作者还提供了一系列用于评估接近真实语音的人工合成语音的资源，包括超过11,000个主观意见评分数据集、一个多语言测试数据集的持续重建管道以及一个持续更新的14种语言TTS基准测试", "conclusion": "TTSDS2是最新的评估TTS系统的工具，在多个领域和语言中具有高度相关性，同时为研究提供了丰富的资源，包括数据集、多语言测试管道和基准测试平台。"}
{"llm_update_time": "2025-06-25 09:18:04", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19500", "html_url": "https://arxiv.org/abs/2506.19500", "title": "NaviAgent：基于工具依赖图的分层规划以实现函数调用", "title_en": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling", "authors": "Yan Jiang,Hao Zhou,LiZhong GU,Ai Han,TianLong Li", "background": "现有的语言模型（LLMs）在执行复杂、异构工具链时高度依赖静态知识和易碎的工具调用，这限制了大规模下的协调。当前方法通常采用刚性单路径执行方式，导致错误恢复效果不佳，搜索空间呈指数级增长。因此，提升LLMs在异构工具链上的功能调用能力和鲁棒性是迫切需要解决的问题。", "innovation": "本文提出了NaviAgent，一种基于图的二层规划架构，包括多路径决策器和图编码导航器。多路径决策器定义了一个四维决策空间，并能动态地选择最优行动以覆盖所有工具调用场景。图编码导航器构建了一个工具依赖异构图（TDHG），将API结构与历史调用行为融合。此外，引入了新颖的启发式搜索策略，可用于引导决策器选择有效的工具链，即使面对未见过的工具组合也表现优越。实验结果显示，NaviAgent在所有基础模型和任务复杂度下都保持了最高的任务成功率（TSR），在Qwen2.5-14B、Qwen2.5-32B和Deepseek-V3上的TSR分别超过了ReAct、ToolLLM和α-UMI等基线模型13.5%、16.4%和19.0%。其执行步骤通常比最高效的基线模型少一步，这保证了高效性和高质量之间的良好平衡。此外，微调后的Qwen2.5-14B模型在我们的架构中获得了49.5%的TSR，而更大的32B模型仅有44.9%。图编码导航器的引入在复杂任务中也提升了TSR约2.4%至9%.", "conclusion": "NaviAgent标志着在LLMs支持的复杂异构工具链协调方面的重要进展，展示了其在提高任务成功率和执行效率方面的显著优势。此外，图编码导航器对于大模型在复杂任务中的发挥尤为关键，也证实了其在工具链协调中的核心作用。"}
{"llm_update_time": "2025-06-25 09:18:05", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19665", "html_url": "https://arxiv.org/abs/2506.19665", "title": "基于循环视觉特征提取和立体注意力的CT报告生成", "title_en": "Recurrent Visual Feature Extraction and Stereo Attentions for CT Report Generation", "authors": "Yuanhe Tian,Lei Mao,Yan Song", "background": "生成计算机断层扫描（CT）图像的报告是一项具有挑战性的任务，虽然与现有的医学图像报告生成研究类似，但它具有独特的特性，如多幅图像的空间编码、影像体和文本之间的对齐等。现有的解决方案通常使用一般性的2D或3D图像处理技术来从CT体积中提取特征，首先压缩体积，然后将压缩的CT切片分割成块进行视觉编码。这些方法并未明确考虑CT切片之间的转换，也未能有效整合多级图像特征，尤其是那些包含特定器官病变的特征，以指导CT报告生成（CTRG）。鉴于CT扫描连续切片之间存在的强烈相关性，本文提出了一种基于大型语言模型（LLM）的CTRG方法，结合循环视觉特征提取和立体注意力进行层次特征建模。", "innovation": "本文提出了一种新的CTRG方法，该方法采用了基于循环视觉特征提取的Transformer以及立体注意力机制，用于多层次特征建模。具体而言，利用视觉Transformer循环处理CT体积中的每个切片，并从多个视角对编码的切片应用注意力机制来选择性地获取重要视觉信息并将其与文本特征对齐，以便更好地指导LLM进行CTRG。实验结果在基准M3D-Cap数据集上表明，该方法优于其他模型，达到了最先进的性能，验证了其有效性和优越性。", "conclusion": "本文提出的方法在CTRG方面取得了显著的成果，验证了其有效性和优越性，达到了最先进的性能。"}
{"llm_update_time": "2025-06-25 09:18:06", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19697", "html_url": "https://arxiv.org/abs/2506.19697", "title": "Robust 4-Bit Quantization of Large Language Models through Outlier-Safe Pre-Training", "title_en": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models", "authors": "Jungwoo Park,Taewhoo Lee,Chanwoong Yoon,Hyeon Hwang,Jaewoo Kang", "background": "在大语言模型（LLMs）中，极端激活异常会对量化性能造成严重影响，妨碍设备上高效部署。尽管已确认通道操作和自适应梯度缩放是主要原因，但实际解决措施仍然具有挑战性。特别是在4位量化下，这种异常激活导致性能显著下降，甚至在极端情况下会极大地降低模型效率和准确度。", "innovation": "我们提出了一种名为Outlier-Safe Pre-Training（OSP）的实用指南，其关键创新措施包括：(1) 使用Muon优化器，消除特权基础同时保持训练效率；(2) 单尺度RMSNorm，防止通道间放大；(3) 可学习嵌入投影，重新分配源自嵌入矩阵的激活幅度。这些措施旨在主动预防异常值的形成，而非依赖于事后解决。这种预训练方法在没有异常值的情况下首次训练出一个10亿参数级别的LLM，并在4位量子化中实现了显著提升，同时保持了较低的训练开销和接近零的极端kurtosis值，从根本上改变了LLM的量化行为。", "conclusion": "我们的研究表明，异常值并非LLMs固有的问题，而是其训练策略的结果，这为更有效的LLM部署开辟了新的途径。"}
{"llm_update_time": "2025-06-25 09:18:07", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19290", "html_url": "https://arxiv.org/abs/2506.19290", "title": "Skywork-SWE：揭示软件工程在LLM中的数据规模定律", "title_en": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs", "authors": "Liang Zeng,Yongcong Li,Yuzhen Xiao,Changshi Li,Chris Yuhao Liu,Rui Yan,Tianwen Wei,Jujie He,Xuchen Song,Yang Liu,Yahui Zhou", "background": "软件工程（SWE）已成为下一代LLM代理的关键测试平台，要求具备两个关键维度的能力：持续迭代问题解决（例如，超过50轮交互）和长期上下文依赖性解析（例如，超过32k标记）。然而，软件工程数据的收集过程依然耗时且依赖手动注释进行代码文件筛选，以及为执行和验证单元测试设置专用运行环境。因此，目前大多数已有的数据集仅包含来自GitHub的数千个实例。为此，我们提出了一个自动化的增量数据收集流水线，系统地扩展了软件工程数据集的数量和多样性。我们的数据集包括来自2,531个不同GitHub存储库的10,169个真实世界Python任务实例，每个实例都附带自然语言描述的任务和用于自动单元测试验证的专用运行环境镜像。通过精心筛选，我们获得了超过8,000条成功运行时验证训练轨迹，当在这些轨迹上对Skywork-SWE模型进行微调时，发现了数据规模现象：软件工程能力的模型性能随着数据量的增加而持续提升，未见饱和迹象。", "innovation": "我们提出了一种增量自动化的数据收集流水线，以扩展软件工程数据集的数量和多样性。该流水线用于收集来自2,531个不同GitHub存储库的10,169个真实世界Python任务实例，并且每个实例都附带自然语言描述的任务和用于自动单元测试验证的专用运行环境镜像。我们还使用这种方法创建了一个新的Skywork-SWE数据集，并使用它对Skywork-SWE模型进行微调，发现模型的性能随着数据量的增加持续提升，这表明缺乏饱和现象。Skywork-SWE模型在SWE-benchVerified基准测试中达到了38.0%的pass@1准确率，没有使用验证器或多次滚动生成结果的新性能标志，并且在结合测试时缩放技术后，准确率进一步提高至47.0%，超过了之前32B参数模型的最新性能标志。", "conclusion": "我们发布了Skywork-SWE-32B模型检查点，以加速未来的研究。我们的研究揭示了软件工程在LLM中的数据规模定律，展示了数据量对模型性能的影响，并提供了新的性能标准。"}
{"llm_update_time": "2025-06-25 09:18:10", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL：探索事实性的可知识性强化学习", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Wenhao Yu,Huajun Chen,Ningyu Zhang", "background": "大语言模型（LLMs），尤其是慢速思考模型，常常表现出严重的幻觉现象，因为它们在推理过程中无法准确识别知识边界。强化学习（RL）虽然可以提升复杂推理能力，但其以结果为导向的奖励机制常常缺乏对思考过程中的事实监督，这进一步加剧了幻觉问题。", "innovation": "本文提出了一种知识增强的强化学习方法，即KnowRL。KnowRL通过将基于知识验证的事实奖励整合到RL的训练过程中，指导模型进行基于事实的慢思考，帮助模型识别其知识边界。这种方法在RL训练过程中提供有针对性的事实输入，使模型能够学习和内化基于事实的推理策略。这种直接奖励推理步骤中的事实一致性，促进了一个更可靠的思考过程。", "conclusion": "实验结果表明，KnowRL在不牺牲原有强大的推理能力的情况下，有效缓解了慢速思考模型的幻觉现象。相关代码在此处可供下载。"}
{"llm_update_time": "2025-06-25 09:18:12", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19825", "html_url": "https://arxiv.org/abs/2506.19825", "title": "使用大型视觉语言模型评估科学出版物图示中可视化准则的合规性", "title_en": "Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models", "authors": "Johannes Rückert,Louise Bloch,Christoph M. Friedrich", "background": "可视化图形在出版物中广泛使用，但研究人员对数据可视化原则和指南的了解往往不足，导致由于所提供信息不准确或不完整而产生误导信息。因此，本文使用大型视觉语言模型（VLMs）来分析图形，以识别与选定的数据可视化原则和指南相关的潜在问题。研究采用了一组用于评估模型的效果的问题，涉及轴标签、线条、颜色和图例等多种元素。研究发现，VLMs在分析图表类型、3D效果、轴标签、线条和图例方面表现出色，但在图像质量和刻度标记方面表现不佳。", "innovation": "本文利用大型视觉语言模型（VLMs）来评估科学出版物中的图形是否符合可视化指南，通过比较五个开源的VLMs和五种不同的提示策略，确定这些模型在评估数据可视化方面的能力。研究表明，不同的VLMs和提示策略的有效性不同，但总体上，视觉语言模型可以在自动识别图形中的潜在问题方面发挥作用，如缺少轴标签、缺少图例和不必要的3D效果等。", "conclusion": "本文提出的方法可以进一步扩展以涵盖更多数据可视化的方面。大型视觉语言模型可以有效帮助识别图形中存在的问题，并促进科学出版物的质量提升。"}
{"llm_update_time": "2025-06-25 09:18:14", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19847", "html_url": "https://arxiv.org/abs/2506.19847", "title": "扩展正交微调的可扩展性", "title_en": "Orthogonal Finetuning Made Scalable", "authors": "Zeju Qiu,Weiyang Liu,Adrian Weller,Bernhard Schölkopf", "background": "正交微调(OFT)虽然提供了高度参数效率并且防止灾难性遗忘，但其高运行时间和内存需求限制了其实用部署。OFT的核心计算瓶颈在于其以权重为中心的实现方式，依赖于代价高昂的具有三次复杂度的矩阵-矩阵乘法。", "innovation": "我们提出了一种输入为中心的重新表述OFTv2，使用矩阵-向量乘法（即无矩阵计算），将计算成本降低到二次。此外，我们引入了 Cayley-Neumann 参数化，这是一种高效的正交参数化方法，通过截断的Neumann级数近似Cayley变换中的矩阵求逆。这些修改使OFTv2能够在不牺牲性能的情况下，实现比原始OFT快10倍的训练，并降低3倍的GPU内存使用。此外，我们扩展了OFTv2来支持微调量化基础模型，并在训练稳定性和效率以及内存使用上优于流行的QLoRA。", "conclusion": "OFTv2实现了比原始OFT更高的训练速度和更低的GPU内存使用，同时保持了性能，并且在其应用场景上表现出了优势。"}
{"llm_update_time": "2025-06-25 09:18:14", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18945", "html_url": "https://arxiv.org/abs/2506.18945", "title": "Chain-of-Experts: 解锁混合专家模型的通信潜力", "title_en": "Chain-of-Experts: Unlocking the Communication Power of Mixture-of-Experts Models", "authors": "Zihan Wang,Rui Pan,Jiarui Yao,Robert Csordas,Linjie Li,Lu Yin,Jiajun Wu,Tong Zhang,Manling Li,Shiwei Liu", "background": "提出了新的Mixture-of-Experts（MoE）架构Chain-of-Experts（CoE），其中每个层内引入了专家间的顺序通信。传统MoE模型中的专家以并行且独立的方式运作，而CoE在层内迭代地处理token，通过在层内的每个迭代步骤中使用专门的路由器支持动态专家选择。这样，token可以在每次迭代中重新评估并选择不同的专家，而不是静态分配。这一设计使得CoE引入了一个灵活的路由机制，增加了专家组合的多样性，从而丰富了模型的表征能力。CoE在固定计算资源下显示出了更高的性能：在数学推理任务上，与标准MoE相比，验证损失从1.20减少到1.12。除了改进性能，CoE还提供了一种新的扩展维度：深度通过专家迭代，这一维度补充了传统的宽度/深度扩展。例如，使用2倍迭代次数相当于3倍专家选择（在宽度上），并且memory使用减少了17.6%到42%。我们的分析显示，这种收益来自于CoE递归残差结构及其通过递归路由增强的专家特化，两者共同为模型解锁了更丰富的表示能力。", "innovation": "引入了新的Mixture-of-Experts（MoE）架构Chain-of-Experts（CoE），在层内迭代地处理token并引入了专家间的顺序通信。利用专门的路由器支持动态专家选择，CoE提供了一种灵活的路由机制，增加了专家组合的多样性，丰富了模型的表征能力。此外，CoE提供了一种新的扩展维度——深度通过专家迭代，补充了传统的宽度/深度扩展。使用2倍的迭代次数达到了3倍专家选择的性能，同时显著减少了memory使用。", "conclusion": "Chain-of-Experts（CoE）引入了一种新的Mixture-of-Experts（MoE）架构，通过在层内迭代地处理token和专家间的顺序通信显著提高了模型的表示能力，特别是在固定计算资源下的性能提升上表现出色。CoE提供了新的扩展维度，降低了memory使用，展示了其在数学推理等任务上的优越性。"}
{"llm_update_time": "2025-06-25 09:18:18", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19830", "html_url": "https://arxiv.org/abs/2506.19830", "title": "扩展推测性解码的前瞻推理", "title_en": "Scaling Speculative Decoding with Lookahead Reasoning", "authors": "Yichao Fu,Rui Ge,Zelei Shao,Zhijie Deng,Hao Zhang", "background": "推理模型通过生成长链条推理表现出色，但解码生成的数千个标记非常缓慢。标记级别的推测性解码（SD）能够帮助，但随着连续猜测的标记数（$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\beta}\boldsymbol{\beta}\boldsymbol{\beta}\boldsymbol{\beta}\boldsymbol{\beta}}}}$）增加，其正确率呈指数级下降。这意味着为更长的标记草案提供更多计算资源会面临算法上限——导致加速效果有限且与硬件无关。", "innovation": "提出前瞻推理（Lookahead Reasoning），利用第二层步级并行性来突破这一上限。前瞻推理的关键洞察是，推理模型是逐步生成的，并且每一步只需语义正确、而不需要准确匹配。支持多个未来步骤的轻量级草稿模型和目标模型的批处理扩展，验证器保留语义正确的步骤，让目标模型重新生成失败的步骤。这种双层并行性使得推测性解码的加速效果提升，理论和实验结果均表明前瞻推理显著扩展了推测性解码的加速效果。", "conclusion": "前瞻推理提高了推测性解码的速度，特别是在GSM8K和AIME等基准测试中，将推测性解码的加速效果从1.4倍提高到2.1倍，同时保持了答案质量，并且其加速效果随着GPU吞吐量增加而更好地扩展。相关代码已开源。"}
{"llm_update_time": "2025-06-25 09:18:18", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19806", "html_url": "https://arxiv.org/abs/2506.19806", "title": "LLM-Based Social Simulations Require Boundaries", "title_en": "LLM-Based Social Simulations Require a Boundary", "authors": "Zengqing Wu,Run Peng,Takayuki Ito,Chuan Xiao", "background": "文章指出，基于大规模语言模型（LLM）的社会仿真应当制定明确界限，以便在社会科学领域做出有意义的贡献。尽管LLM在建模类似人类的行为方面相对于传统基于代理建模的模型展现出潜力，但它们仍面临一些根本性的局限性，这些局限性限制了它们发现社会模式的可靠性。核心问题在于LLM倾向于形成一个‘平均人设’，缺乏足够行为异质性，这正是模拟复杂社会动力学的关键要求。文章还探讨了三个关键的边界问题：一致性（模拟行为与现实世界模式匹配）、连贯性（保持代理行为随时间的一致性）和稳定性（在不同条件下具有可再现性），并提出了判断何时基于LLM的社会仿真能可靠推进社会科学理解的启发式准则。", "innovation": "文章提出了启发式边界来确定基于LLM的社会仿真何时能可靠地推进社会科学理解。提出了三个建议：关注集体模式而非个体轨迹、行为需与实际人口平均值保持一致即使样本变异有限，以及可用合适的验证方法测试仿真稳健性。提供了一个实用检查表来指导研究人员确定基于LLM的社会仿真合理范围和主张。", "conclusion": "基于LLM的社会仿真在专注于集体模式、行为一致性以及采用适当验证方法进行稳健性测试时更具有价值。"}
{"llm_update_time": "2025-06-25 09:18:19", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.01799", "html_url": "https://arxiv.org/abs/2404.01799", "title": "PATCH! {P}sychometrics-{A}ssis{T}ed Ben{CH}marking of Large Language Models against Human Populations: A Case Study of Proficiency in 8th Grade Mathematics", "title_en": "PATCH! {P}sychometrics-{A}ssis{T}ed Ben{CH}marking of Large Language Models against Human Populations: A Case Study of Proficiency in 8th Grade Mathematics", "authors": "Qixiang Fang,Daniel L. Oberski,Dong Nguyen", "background": "当前大型语言模型（LLMs）的基准测试主要集中在评估模型的学术能力，尤其是与人类测试者的性能进行比较。然而，这些基准测试存在一些局限性，如测量质量存疑、项目质量评估不足以及缺乏清晰的人类参考人群。本文指出现有基准测试方法存在这些问题，并提出利用心理测量学知识来改进大型语言模型的基准测试方法。", "innovation": "本文提出了PATCH（Psychometrics-AssisTed Benchmarking of Large Language Models），这是一种采用了心理测量学辅助的新型框架，用于对大型语言模型进行基准测试。通过将心理测量学方法应用于大型语言模型的基准测试，PATCH能够提供更能反映实际情况的评估结果，解决了现有基准测试方法中存在的问题。PATCH包括对比当前大型语言模型基准测试的发展和心理测量学方法的应用，创建基准测试框架，并通过数学测试案例研究支持其有效性，同时发布了四个高质量的数据集以支持对LSTM语言模型的学术能力进行更精确的测量和比较。", "conclusion": "通过PATCH框架，研究者们能够更准确地评估大型语言模型在基础教育领域（如初一数学）的学术能力，并将这些模型与人类参考人群进行合理比较，这为未来的基准测试提供了新的方法和标准。"}
{"llm_update_time": "2025-06-25 09:18:23", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.18259", "html_url": "https://arxiv.org/abs/2406.18259", "title": "检测机器生成文本：不只是‘AI vs 人类’，可解释性十分复杂", "title_en": "Detecting Machine-Generated Texts: Not Just \"AI vs Humans\" and Explainability is Complicated", "authors": "Jiazhou Ji,Ruizhe Li,Shujun Li,Jie Guo,Weidong Qiu,Zheng Huang,Chiyu Chen,Xiaoyu Jiang,Xinru Lu", "background": "随着大语言模型（LLMs）的迅速发展，人们对在线和现实世界中文本的实际作者身份产生了越来越多的担忧。区分由LLM生成的文本变得复杂，因为机器和人类的行为都具有细微和重叠的特点。当前对LLM生成文本检测的实践主要将其视为二元分类任务，即区分人类和AI文本。然而，本文挑战了这种传统观点，提出了一种新的三分类方案，增加了“不确定”类别，以更好地理解如何使检测结果对普通用户更具可解释性。", "innovation": "本文引入了一种新的三分类方案，通过添加'不确定'类别，以便更准确地识别文本的作者身份。这不仅提出了一个新的分类方法，还强调了检测器需要提供清晰且易于理解的解释的重要性。研究使用新创建的数据集进行了二元分类测试，以确定最有效的先进方法，并指出了难以检测的最新大语言模型。提出了一个由两位顶级性能的大语言模型和人类作者生成的文本数据集，人类标注者进行了三元分类标注，并分析了顶级检测器的可解释性以及人类标注者的解释注释，揭示了机器生成文本检测的复杂性。", "conclusion": "本研究强调了需要改进检测系统，提出指南以提高其解释能力。这为开发更具有解释性的检测系统提供了可能的路径。"}
{"llm_update_time": "2025-06-25 09:18:25", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19579", "html_url": "https://arxiv.org/abs/2506.19579", "title": "虚拟的还是真实的，机器人能分辨吗？——在真实和3D打印对象上的感知语言模型评估", "title_en": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects", "authors": "Federico Tavella,Kathryn Mearns,Angelo Cangelosi", "background": "随着机器人场景理解越来越多地依赖于视觉语言模型（VLMs），以生成对环境的自然语言描述，该研究对比了机器人臂捕捉的桌面场景图片的 captioning 战略，评估了多个生成场景描述的模型，探究了单视角和多视角 captioning 的权衡，以及识别真实世界对象和3D打印对象之间的差异。通过定量评估对象识别准确性、生成 caption 的完整性和自然度，表明 VLMs 在识别常见物体方面具有优势，但在处理新表示时无法泛化。研究结果为在现实世界场景中部署基础模型提供了实践指导", "innovation": "该研究通过对比多种 captioning 模型在多视角场景描述上的表现，特别是在真实物体和3D打印对象识别上的差异，探讨了视觉语言模型在机器人环境中的应用潜力和局限性，提供了一种新的评估框架", "conclusion": "研究发现视觉语言模型在识别常见物体方面表现良好，但在处理新型物体表示时存在泛化问题。因此，建议在具体应用中选择合适的基础模型，以提高机器人的场景理解能力和适应性。该研究还表明多视角描述通常优于单视角描述，增加了模型的准确性和完整性"}
{"llm_update_time": "2025-06-25 09:18:27", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2308.16075", "html_url": "https://arxiv.org/abs/2308.16075", "title": "视觉上下文对嘈杂多模态NMT的影响：英语到印地语语言群的实证研究", "title_en": "Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages", "authors": "Baban Gain,Dibyanayan Bandyopadhyay,Samrat Mukherjee,Chandranath Adak,Asif Ekbal", "background": "神经机器翻译（NMT）已经在大规模文本数据的帮助下取得了显著的进步，但在高资源设置中，将多模态输入特别是视觉信息结合起来的潜力尚未被充分利用。尽管以往研究主要关注在低资源场景中利用多模态数据，但本研究考察了当添加到大规模预训练的单模态NMT系统时，图片特征如何影响翻译。研究结果出乎意料地发现图片在此情境下可能是多余的。研究还引入了合成噪音来检验图像是否能帮助模型处理文本噪音并发现，多模态模型在噪音场景中稍微优于仅文本模型，即使使用随机图像也能实现这一点。研究通过将英语翻译成印地语、孟加拉语和马拉雅拉姆语实验，明显超越了最先进的基准模型。视觉上下文的效果在源文本噪音水平的不同条件下表现出差异：在无噪音翻译中，没有视觉上下文效果最好；低噪音下，裁剪后的图像特征最优；高噪音情况下，完整的图像特征表现更好。这揭示了视觉上下文在不同噪音水平下的作用并为多模态设置中的嘈杂神经机器翻译开辟了一个新的研究方向。研究强调结合视觉和文本信息对于改善各环境下翻译的重要性。我们的代码已经公开在 https://github.com/...", "innovation": "研究引入了视觉上下文对翻译的影响，特别是图像特征如何影响翻译性能。研究发现，即使使用随机图像，多模态模型在噪音场景中也能够稍微优于仅文本模型。研究通过引入合成噪音来检验图像对于处理文本噪声的影响，并发现视觉上下文的效果会随着源文本噪音水平的不同而变化。在无噪音翻译中不需要视觉上下文，在低噪音情况下裁剪后的图像特征更有优势，在高噪音情况下完整的图像特征表现更好。这些发现为嘈杂神经机器翻译在多模态环境中的研究提供了一个新方向。", "conclusion": "该研究揭示了视觉上下文在不同噪音水平下的作用，特别是对于非噪音、低噪音和高噪音翻译的不同影响。视觉上下文的引入对提高嘈杂环境下的翻译性能有重要作用，并为未来的多模态机器翻译研究提供了新的方向。研究还强调了结合视觉和文本信息对于改善跨环境翻译的重要性，并进行了大量实验证明了其有效性。"}
{"llm_update_time": "2025-06-25 09:18:27", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.05563", "html_url": "https://arxiv.org/abs/2410.05563", "title": "大型语言模型中的理性元推理", "title_en": "Rational Metareasoning for Large Language Models", "authors": "C. Nicolò De Sabbata,Theodore R. Sumers,Badr AlKhamissi,Antoine Bosselut,Thomas L. Griffiths", "background": "用作推理任务的提示已被证明是利用大规模语言模型（LLMs）的核心技术。随着LLMs规模和使用频率的增加，推理过程的开销也在相应地增加。因此，如何优化推理的成本效益比成为了一个重要的问题。", "innovation": "本文提出了一种基于认知科学中元推理的计算模型的新方法，训练LLMs在必要时才使用中间推理步骤。这种方法通过引入考虑计算价值的奖励函数，并结合专家迭代进行训练，相较于少量链式思考提示和STaR，能够在降低推理成本（在三种模型中平均减少了20-37%的生成令牌数量）的同时保持在各种数据集上的任务性能.", "conclusion": "通过这种方法，能够在成本可控的情况下保持LLMs的性能，从而优化其成本效益比。"}
{"llm_update_time": "2025-06-25 09:18:28", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.18469", "html_url": "https://arxiv.org/abs/2410.18469", "title": " ADVLLM: 迭代自我调优的 LLMs 以提高逃狱能力", "title_en": "ADVLLM: Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities", "authors": "Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao", "background": "近期研究显示，大型语言模型（LLMs）容易受到自动化逃狱攻击的影响，这些攻击通过由算法构造的有敌意的后缀绕过安全对齐并触发意外响应。当前用于生成这些后缀的方法计算成本高且成功率低，尤其是在对抗像 Llama2 和 Llama3 这样高度对齐的模型时。", "innovation": "我们引入了 ADV-LLM，一种迭代自我调优的过程，用于制造具有增强逃狱能力的对抗性 LLM。该框架将生成对抗性后缀的计算成本显著降低，同时在各种开源 LLM 上实现了几乎 100% 的攻击成功率，此外，它在封闭源代码模型上也表现出强大的攻击可转移性，其中在 GPT-3.5 上达到了 99% 的 ASR，在 GPT-4 上达到了 49% 的 ASR，尽管它仅在 Llama3 上进行了优化。", "conclusion": "除了提高逃狱能力之外，ADV-LLM 还通过生成大量用于研究 LLM 安全性的数据集提供了对未来安全性对齐研究有价值的见解。"}
{"llm_update_time": "2025-06-25 09:18:28", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.06331", "html_url": "https://arxiv.org/abs/2407.06331", "title": "LEVOS: 利用梵语词汇重叠生成印度语言中的技术词汇", "title_en": "LEVOS: Leveraging Vocabulary Overlap with Sanskrit to Generate Technical Lexicons in Indian Languages", "authors": "Karthika N J,Krishnakant Bhatt,Ganesh Ramakrishnan,Preethi Jyothi", "background": "将技术术语从词汇上相似的语言翻译成低资源的印度语言仍然存在挑战，主要原因是缺乏平行数据以及语言结构的复杂性。现有的技术翻译方法在梵语基础下的分词使用和相关语言的子词级相似性和形态学对齐方面得到了创新应用，通过字符级别分词来识别有意义的子词单元，从而实现更准确和上下文感知的翻译。现有的Sanskrit Word Segmentation (CharSS) 模型克服了分词中的复杂音节和形态音位变化问题，已在实验中表现出色，平均chrF++得分为8.46和6.79。此外，本研究还通过质性评估验证了自动化评估之外的翻译质量，在教育领域具有重要意义，有助于创造印度语言中的无障碍高质量学习材料，并填补低资源语言社区的学习资源缺口。", "innovation": "提出了梵语为基础的分词单元方法，用于低资源印度语言中的技术术语翻译，利用子词级别的相似性和相关语言的形态学对齐。通过字符级别的分词模型CharSS处理梵语中的复杂音节变化和形态音位变化，以提高技术术语翻译的准确性与上下文相关性。还通过质性评估验证了自动化评估之外的翻译质量，显示出一致的改进。", "conclusion": "这项工作在教育领域有重要影响，通过支持技术内容的准确和基于语言的翻译，促进了包容性，并有助于填补低资源语言社区的学习资源缺口。"}
{"llm_update_time": "2025-06-25 09:18:33", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.01933", "html_url": "https://arxiv.org/abs/2408.01933", "title": "评估大型语言模型在问责关键任务中的透明推理能力", "title_en": "Evaluating Transparent Reasoning in Large Language Models for Accountable Critical Tasks", "authors": "Junhao Chen,Bowen Wang,Jiuyang Chang,Yuta Nakashima", "background": "本文介绍了一个称为REACT的基准测试，旨在严格评估大型语言模型（LLMs）在医学和法律等问责制高风险决策任务中的推理能力。REACT不同于传统主要集中在预测准确性上的测试，强调透明和可解释的推理，要求模型的逻辑与专家指南高度一致。通过为511个医学案例和86个法律案例提供详细的专家提取论据和推理步骤，本文评估了LLMs的推理是否与人类专家的推理一致，同时使用了精心构建的推理图来明确编码领域特定的推理结构和决策标准。这些推理图不仅为专家注释提供了标准，还为模型提供了结构化的指导，使其能够透明和逐步地进行推理。为了应对手动注释的可扩展性挑战，本文还开发了一种半自动注释管道，利用专家定义的推理图模板来快速生成新的图，探索将其扩展到其他关键领域的方法。实验结果表明，推理图在提高LLMs推理的可解释性和准确性方面显著优于传统基线，但仍存在与专家级推理性能的显著差距。", "innovation": "该研究的创新在于提出REACT基准测试，集中评估大型语言模型在医学和法律领域的问责制高风险决策任务中的透明推理能力。REACT强调透明和可解释的推理，要求模型遵循专家制定的推理路径。此外，本文还开发了一种半自动注释管道，利用专家定义的推理图模板来快速生成新的图，以提高注释效率，扩大应用范围。这项研究在提高LLMs的可解释性和准确性方面取得了显著成果，但仍存在与专家级推理性能的显著差距。", "conclusion": "研究表明，与传统基线相比，推理图极大地提高了LLMs的可解释性和准确性，但在与专家级推理表现上仍有显著差距。此外，半自动注释管道的开发为高效生成新的推理图提供了可能，为未来在其他关键领域进行扩展提供了基础。"}
{"llm_update_time": "2025-06-25 09:18:35", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12743", "html_url": "https://arxiv.org/abs/2502.12743", "title": "我了解自己但并不深刻：LLM能否检测和解释LLM生成的文本有多好？", "title_en": "\"I know myself better, but not really greatly\": How Well Can LLMs Detect and Explain LLM-Generated Texts?", "authors": "Jiazhou Ji,Jie Guo,Weidong Qiu,Zheng Huang,Yang Xu,Xinru Lu,Xiaoyu Jiang,Ruizhe Li,Shujun Li", "background": "鉴于LLM滥用的风险，区分人类生成的文本与LLM生成的文本至关重要。本文研究了当前在两种分类设置（二分类：人类vs. LLM生成；三分类：包括不定分类）下LLM检测和解释能力。通过评估不同规模的6种开源和预训练模型，揭示了自我检测和交叉检测的性能差异，并探讨了引入三分类框架的方法以提高检测精度和解释质量。定量和定性的全面分析揭示了当前模型在解解释等方面的局限性，包括对不准确特征的依赖、幻觉和推理缺陷。", "innovation": "引入了三分类框架以提高模型的检测精度和解释质量，全面分析揭示了当前模型在自我检测和自我解释方面的局限性。", "conclusion": "当前LLM在自我检测和自我解释方面存在局限性，需进一步研究以解决过拟合问题并提高模型的泛化能力。"}
{"llm_update_time": "2025-06-25 09:18:35", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.10227", "html_url": "https://arxiv.org/abs/2411.10227", "title": "巨量语料库中的熵和语汇量比", "title_en": "Entropy and type-token ratio in gigaword corpora", "authors": "Pablo Rosillo-Rodes,Maxi San Miguel,David Sanchez", "background": "复杂系统中多样性有不同的测量方法，特别是在语言方面，词汇多样性通常用类型-项比率和词熵来刻画。本文在英语、西班牙语和土耳其语中研究了文本长度为巨量词库的数据集，分别对应不同的形态学特征和多种文体与体裁，为定量化分析词汇多样性提供了一个多样化的测试平台。", "innovation": "本文揭示了在给定语料库和语言中词熵和类型-项比率之间的经验功能关系，这是自然语言统计规律的结果，并且在长文本的极限情况下，还提出了依靠齐普夫定律和海普斯定律的解析表达式，该表达式与实验结果相吻合。", "conclusion": "本文提供了关于文本长度为巨量语料库中词汇多样性的定量关系的见解，该结论是通过齐普夫定律和海普斯定律推导出来的，并验证了这些理论与实际数据的一致性，为进一步研究语言学提供了新视角。"}
{"llm_update_time": "2025-06-25 09:18:36", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.23478", "html_url": "https://arxiv.org/abs/2410.23478", "title": "Collage: 分解式快速原型在科学PDF信息提取中的应用", "title_en": "Collage: Decomposable Rapid Prototyping for Information Extraction on Scientific PDFs", "authors": "Sireesh Gururaja,Yueheng Zhang,Guannan Tang,Tianhao Zhang,Kevin Murphy,Yu-Tsen Yi,Junwon Seo,Anthony Rollett,Emma Strubell", "background": "近年来，在自然语言处理(NLP)领域，科学家专用的信息提取工具得到了持续发展，并且越来越多的多模态预训练转换器模型也被发布出来。对于NLP之外的科学家而言，现在比以往任何时候都更容易评估和应用这些系统到他们自己的领域。然而，这些模型之间难以进行比较，因为它们接受不同的输入格式，通常难以理解并且很少处理PDF文档（这是科学研究中最常见的格式）。为了应对这一挑战，我们提出了Collage，一个专门用于快速原型设计、可视化和评估不同信息提取模型在科学PDF中的工具。Collage支持使用和评估任意的HuggingFace标记分类器、多种LLM和其他多个任务特定模型，并提供加速新模型实验的可扩展软件接口。此外，Collage还为开发者和NLP工具的使用者提供了检视、调试以及更好地理解建模流程的粒度视图，以便更好地理解和检验中间处理状态。我们以材料科学领域的文献回顾为例演示该系统，展示了Collage在信息提取中的应用效果和潜在的优势。", "innovation": "Collage提供了一个可扩展的软件接口，支持快速原型设计、可视化以及评估不同信息提取模型在科学PDF中的使用情况。它能够使用和评估任意的HuggingFace标记分类器、多种LLM和其他多个任务特定模型，为开发者和用户提供了检视、调试和更好地理解建模流程的工具。Collage还能够在处理过程中提供中间状态的粒度视图，从而帮助用户和开发人员更好地理解和检验模型的处理过程。", "conclusion": "我们展示了Collage系统在材料科学领域文献回顾中的应用，证明了它在信息提取方面的能力和潜在的价值。通过提供一种简单易用的工具，Collage帮助科学家们更方便地评估和使用信息提取模型，同时也使得这些工具的开发者能够更好地理解模型的处理过程和性能表现。"}
{"llm_update_time": "2025-06-25 09:18:37", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.19832", "html_url": "https://arxiv.org/abs/2411.19832", "title": "社交媒体敏感内容分类：一个全面的资源和评估", "title_en": "Sensitive Content Classification in Social Media: A Holistic Resource and Evaluation", "authors": "Dimosthenis Antypas,Indira Sen,Carla Perez-Almendros,Jose Camacho-Collados,Francesco Barbieri", "background": "在大规模数据中检测敏感内容对于确保共享和分析的数据不含有害材料至关重要。然而，现有的审核工具，如外部API，存在自定义能力有限、跨多种敏感类别的准确性不足以及隐私顾虑等问题。目前的数据集和开源模型主要集中于有损语言，而对于如物质滥用或自伤等其他敏感类别检测存在缺失。", "innovation": "本文提出了一套统一的数据集，覆盖了社交媒体内容审核的六个敏感类别：冲突语言、谩骂、性暗示内容、吸毒相关内容、自伤和垃圾信息。通过一致的数据收集和注释策略以及制定指南，本文解决了现有研究关注不足的问题。实验证明，对这个新型数据集微调大型语言模型显著提高了检测性能，其性能优于现成的LLaMA模型乃至OpenAI的私有模型，后两者整体性能相对后退10-15%。这在流行的审核API中表现得尤为明显，这些API难以定制特定的敏感内容类别以满足需求。", "conclusion": "对本文提出的新型数据集进行微调的大型语言模型在检测性能上有了显著提升，相较于现成的LLaMA模型和OpenAI的私有模型，其性能更好，尤其在流行的审核API中这一优势更加明显。"}
{"llm_update_time": "2025-06-25 09:18:39", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.17036", "html_url": "https://arxiv.org/abs/2502.17036", "title": "语言模型重排器被词形相似性所欺骗", "title_en": "Language Model Re-rankers are Fooled by Lexical Similarities", "authors": "Lovisa Hagström,Ercong Nie,Ruben Halifa,Helmut Schmid,Richard Johansson,Alexander Junge", "background": "语言模型（LM）重排器被用于改进检索增强生成（RAG）中的检索结果。虽然它们比诸如BM25之类的词形匹配方法更昂贵，但人们认为它们在处理语义信息和查询与检索答案之间的关系方面表现更好。本文旨在探究LM重排器是否真的符合这一假设，通过在NQ、LitQA2和DRUID数据集上评估6种不同的LM重排器来验证这一点。研究发现，LM重排器在DRUID数据集上难以超越简单的BM25基线，因此作者提出了一个新的基于BM25分数的分隔度量来解释和识别由词形差异导致的重排器错误。此外，作者还研究了提高LM重排器性能的不同方法，发现这些方法对NQ数据集更有效。这些发现揭示了LM重排器的缺点，并指出了它们评价时需要更多的对抗性和现实性的数据集的需求。", "innovation": "1. 提出了一个新的基于BM25分数的分隔度量来解释和识别由词形差异导致的重排器错误。\n2. 研究了提高LM重排器性能的不同方法，并指出这些方法对NQ数据集更有效。\n3. 强调了需要更对抗性和现实性的数据集来评估LM重排器的性能", "conclusion": "本研究揭示了LM重排器的弱点，并指出了它们需要更对抗性和现实性的数据集进行评估的需求。通过分析LM重排器的错误和改进方法，本研究为未来改进LM重排器的准确性提供了有价值的见解。"}
{"llm_update_time": "2025-06-25 09:18:40", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.08697", "html_url": "https://arxiv.org/abs/2504.08697", "title": "大型语言模型作为断言语注者", "title_en": "Large Language Models as Span Annotators", "authors": "Zdeněk Kasner,Vilém Zouhar,Patrícia Schmidtová,Ivan Kartáč,Kristýna Onderková,Ondřej Plátek,Dimitra Gkatzia,Saad Mahamood,Ondřej Dušek,Simone Balloccu", "background": "断言语注是根据自定义指南定位和分类文本片段的任务。传统的断言语注主要依赖于人类标注者或微调模型，但这些方法的效率和成本问题成为了挑战。本研究旨在探讨大型语言模型（LLMs）在断言语注中的潜力，证明它们可以作为灵活且成本效益高的断言语注基础框架，特别是在多样的断言语注任务中展现出与专家人类标注者相当的表现，而在输出注释成本上则远低于传统方法。研究中涉及三个不同的断言语注任务，包括数据到文本生成评估、识别翻译错误和检测宣传技术。", "innovation": "本研究创新地展示了一种新的方法，利用大型语言模型进行断言语注，这为提高断言语注的效率和降低成本提供了新的思路。研究结果表明，与传统的手动标注方法相比，LLMs在达到类似的人标注同意度（IAA）的同时，每注释输出的成本大幅降低。此外，研究人员还对模型输出进行了人工分析，发现LLMs在错误率上与人类标注者相当，证明了其在断言语注中的有效性和可靠性。这项研究还发布了一个包含超过40,000次注释的数据集，供进一步的研究参考，为相关领域的研究提供了宝贵的数据资源。", "conclusion": "本研究证明了大型语言模型在断言语注领域的潜力，这些模型能够实现与人类标注者相当的注释一致性和准确性，同时大幅降低成本。尽管在某些应用中仍可能存在准确性上的限制，但大语言模型的应用为后续研究提供了新的可能性，并可能在未来改变断言语注的标注方法，同时促进更多的应用场景和研究机会。"}
{"llm_update_time": "2025-06-25 09:18:40", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19774", "html_url": "https://arxiv.org/abs/2506.19774", "title": "Kling-Foley：用于高质量视频到音频生成的多模态扩散变换器", "title_en": "Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation", "authors": "Jun Wang,Xijuan Zeng,Chunyu Qiang,Ruilong Chen,Shiyao Wang,Le Wang,Wangjing Zhou,Pengfei Cai,Jiahui Zhao,Nan Li,Zihan Li,Yuzhe Liang,Xiaopeng Wang,Haorui Zheng,Ming Wen,Kang Yin,Yiran Wang,Nan Li,Feng Deng,Liang Dong,Chen Zhang,Di Zhang,Kun Gai", "background": "本研究提出了Kling-Foley模型，这是一种大规模多模态视频到音频生成模型，能够合成高质量、与视频内容同步的音频。此模型结合了多模态扩散变换器、视觉语义表示模块和音频-视觉同步模块，以增强对齐能力，实现精确的视频匹配音效生成。该模型还提出了一个适用于各种场景（包括音效、语音、歌唱和音乐）的通用潜空间音频编解码器，以及一种立体渲染方法，使合成音频具有空间感。为弥补开源基准数据集的不足，还开源了一个工业级基准Kling-Audio-Eval。实验结果显示，使用流匹配目标训练的Kling-Foley在分布匹配、语义对齐、时间对齐和音质方面取得了公开模型中的SOTA性能。", "innovation": "1. 引入了多模态扩散变换器，以建模视频、音频和文本模态之间的交互。\n2. 集成了视觉语义表示模块和音频-视觉同步模块，提高对齐能力。\n3. 使用了通用潜空间音频编解码器处理不同场景效果。\n4. 实现了立体渲染方法，赋予合成音频空间感。\n5. 开源了工业级基准Kling-Audio-Eval，供研究者使用。", "conclusion": "本研究展示了Kling-Foley在视频到音频生成领域的卓越性能，无论是分布匹配、语义对齐、时间对齐和音质方面均达到了公开模型中的SOTA水平。模型结合了多模态扩散变换器和特殊设计的模块，有效提高了音频和视频内容的同步性和质量。"}
{"llm_update_time": "2025-06-25 09:18:41", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19848", "html_url": "https://arxiv.org/abs/2506.19848", "title": "ScaleCap：通过双模态去偏的推理时可扩展图像描述", "title_en": "ScaleCap: Inference-Time Scalable Image Captioning via Dual-Modality Debiasing", "authors": "Long Xing,Qidong Huang,Xiaoyi Dong,Pan Zhang,Yuhang Zang,Yuhang Cao,Jinsong Li,Shuangrui Ding,Weiming Zhang,Nenghai Yu,Jiaqi Wang,Feng Wu,Dahua Lin", "background": "高质量的图像描述面临着两个主要挑战：多模态偏差和语言偏差。多模态偏差导致描述 granularity 不平衡，一些元素描述详细而其他元素略过。语言偏差则导致图像中不存在的对象被虚构的描述出来。这些问题影响了图像描述的质量，需要一种新的策略来解决它们。", "innovation": "提出了一种名为 ScaleCap 的推理时可扩展图像描述策略，它通过两个新颖组件——启发式问题回答和对比性句子评分——来逐步丰富和校准描述，以增加推理预算。具体来说，ScaleCap 在增加推理成本时能够生成更多启发式问题，从而捕捉更多的视觉细节，生成更为准确、平衡和信息丰富的描述。通过大规模的模态对齐实验展示了 ScaleCap 的有效性，并在四个额外任务中的表现也证明了其生成描述的丰富性和忠实性。", "conclusion": "ScaleCap 通过共 450,000 幅图像的标注并在大规模预训练中使用，使得在 11 个广泛使用的基准测试中取得了持续性性能提升。此外，通过两个额外的任务展示了生成描述的丰富性和忠实性，代码已开源。"}
{"llm_update_time": "2025-06-25 09:18:44", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.13816", "html_url": "https://arxiv.org/abs/2504.13816", "title": "通过内部表示分析大模型在不同语言中的知识边界认知", "title_en": "Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations", "authors": "Chenghao Xiao,Hou Pong Chan,Hao Zhang,Mahani Aljunied,Lidong Bing,Noura Al Moubayed,Yu Rong", "background": "理解和掌握大语言模型（LLMs）的知识边界对于防止幻觉至关重要。目前，对LLMs知识边界的大部分研究都集中在英语上。本研究探索了LLMs在处理多种语言的已知和未知问题时，是如何通过其内部表示来识别知识边界的。研究揭示了三大关键发现：（1）不同语言中，大模型的知识边界感知主要是通过中间到上层的表示来编码。（2）知识边界感知的语言差异遵循线性结构，这启发了我们提出的一种无需训练的知识边界感知能力跨语言转移方法，有助于减少低资源语言中的幻觉风险。（3）双语问题对的微调进一步增强了大模型在不同语言中的知识边界识别能力。由于缺乏跨语言知识边界的标准化测试平台，本文构建了一个多语言评价套件，包含了三种代表性的知识边界数据类型。", "innovation": "1. 首次分析了LLMs在不同语言中的知识边界识别情况；2. 揭示了语言差异在知识边界感知上的线性结构，并提出了无需训练的知识边界感知能力跨语言转移方法；3. 构建了多语言评价套件，用于分析跨语言的知识边界问题；4. 采用双语问题对的微调方法，增强了跨语言的知识边界识别能力。", "conclusion": "研究构建了一个多语言评价套件，揭示了大模型在不同语言中的知识边界感知规律，提出了跨语言知识边界感知能力的转移方法，为减少低资源语言中模型的幻觉风险提供了可参考的策略。"}
{"llm_update_time": "2025-06-25 09:18:45", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16078", "html_url": "https://arxiv.org/abs/2505.16078", "title": "小语言模型在现实世界中的视角：基于工业文本分类的见解", "title_en": "Small Language Models in the Real World: Insights from Industrial Text Classification", "authors": "Lujun Li,Lama Sleem,Niccolo' Gentile,Geoffrey Nichil,Radu State", "background": "随着ChatGPT等模型的出现，Transformer模型在文本分类等任务中取得了显著的进步。尽管Llama等解码器模型表现强大且灵活，但在推理过程中由于逐词生成而导致效率低下，且其在文本分类任务中的效果很大程度上依赖于提示的质量。更重要的是，它们对GPU资源的需求往往限制了其广泛应用。因此，是否小型语言模型能够有效处理文本分类任务成为一个重要的研究问题。然而，在模型选择和方法论方面还存在明显不足，研究尚不充分。本文旨在通过全面评估提示工程和监督微调方法来填补这一空白，特别是在工业应用场景下，包括电子邮件分类、法律文件分类以及极长的学术文本分类等场景下的表现和效率分析，从而为小型模型在工业设定中的局部部署和应用提供有价值的洞察。", "innovation": "本研究首次通过全面评估提示工程和监督微调方法，为小型语言模型在工业文本分类中的应用提供了宝贵的见解。研究重点放在不同场景下的性能和VRAM使用效率上，填补了该领域中的研究空白。", "conclusion": "研究展示了小型语言模型在电子邮件分类、法律文件分类以及极长学术文本分类等工业场景中的表现和效率。这对于促进小型模型在工业设定中的局部部署和应用具有重要意义，也为未来研究提供了方向。"}
{"llm_update_time": "2025-06-25 09:18:46", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11462", "html_url": "https://arxiv.org/abs/2505.11462", "title": "在医疗大型语言模型中分离推理与知识", "title_en": "Disentangling Reasoning and Knowledge in Medical Large Language Models", "authors": "Rahul Thapa,Qingyang Wu,Kevin Wu,Harrison Zhang,Angela Zhang,Eric Wu,Haotian Ye,Suhana Bedi,Nevin Aresh,Joseph Boen,Shriya Reddy,Ben Athiwaratkun,Shuaiwen Leon Song,James Zou", "background": "当前用于评估医疗诊断推理能力的基准测试，如MedQA-USMLE、MedMCQA和PubMedQA，通常将推理与事实记忆混在一起。作者通过使用PubMedBERT分类器将11个生物医学问答基准测试划分成推理侧重和知识侧重的子集，从而解决了这一问题。他们发现仅32.8%的问题需要复杂推理，并且生物医学模型在知识和推理性能上存在显著差异。尽管生物医学模型在知识方面表现良好，但在推理方面表现较差，例如HuatuoGPT-o1在知识部分得分为56.9，但在推理部分仅为44.8。此外，生物医学模型在被误导时会迅速退化，而其他大型或强化学习训练的一般领域模型则表现出更高的鲁棒性。", "innovation": "作者通过PubMedBERT分类器将生物医学问答基准测试分离成推理侧重和知识侧重的子集，并发现仅32.8%的问题需要复杂推理。在此基础上，他们提出了BioMed-R1模型，该模型通过微调和基于强化学习的训练在推理密集型示例上表现出最强的性能。进一步改进可以通过融入临床案例报告并采用对抗性和回溯场景的训练方法来实现。", "conclusion": "目前医疗领域的大型语言模型在推理能力上存在不足，提出了一个新的基准并证明了通过特定训练方法可以显著提升模型的推理能力，尤其是解决初始错误推理的问题。"}
{"llm_update_time": "2025-06-25 09:18:47", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23966", "html_url": "https://arxiv.org/abs/2505.23966", "title": "FLAT-LLM: 细粒度的低秩激活空间变换以实现大型语言模型的结构压缩", "title_en": "FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression", "authors": "Jiayi Tian,Ryan Solgi,Jinming Lu,Yifan Yang,Hai Li,Zheng Zhang", "background": "大型语言模型（LLMs）在自然语言处理方面取得了显著进展，但其对计算和内存需求高，导致在资源受限环境中部署困难。尽管最近的低秩分解方法为结构压缩提供了有希望的途径，但它们通常会导致准确度下降、昂贵的校准过程，并产生效率低下的模型架构，从而阻碍实际推理加速。", "innovation": "本文提出FLAT-LLM，一种基于激活空间中细粒度低秩变换的无训练结构压缩方法。具体来说，通过每头主成分分析（PCA）计算截断的特征向量变换权重，并通过重要性指标动态分配解码器中的秩。FLAT-LLM 实现了高效的权重压缩，无需恢复微调，校准可在几分钟内完成。在四个模型和11个数据集上评估，FLAT-LLM 在泛化和下游性能方面优于结构剪枝基线，同时提供了比分解方法更快的推理速度", "conclusion": "FLAT-LLM 实现了高效的结构压缩，同时保留了模型的准确度，并且可以快速校准以实现实际推理加速。"}
{"llm_update_time": "2025-06-25 09:18:47", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.16553", "html_url": "https://arxiv.org/abs/2503.16553", "title": "基于开源大型语言模型的奠基性个体移动预测模型", "title_en": "A Foundational individual Mobility Prediction Model based on Open-Source Large Language Models", "authors": "Zhenlin Qin,Leizhen Wang,Francisco Camara Pereira,Zhenliang Ma", "background": "大型语言模型（LLMs）由于其广泛的知识基础和卓越的推理能力，被广泛应用于特定领域的任务。当前关于LLMs的研究显示了在使用LLMs进行个体移动预测问题建模的巨大潜力。然而，现有的大多数基于LLMs的移动预测模型要么仅在特定数据集上训练，要么仅使用单一精心设计的提示，这导致难以适应不同城市和具有不同背景的用户。", "innovation": "本文提出了一种统一的微调框架，用于训练一个基于开源LLMs的基础性移动预测模型。通过在六个真实的移动数据集上进行广泛实验，验证了所提出模型的性能，结果显示该模型在预测准确性和可迁移性方面超过了基于深度学习和LLMs的最新模型。", "conclusion": "提出的模型在预测准确性和跨域性能方面表现出色，填补了现有基于LLMs的移动预测模型在适应不同城市和用户背景方面的不足。"}
{"llm_update_time": "2025-06-25 09:18:49", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11903", "html_url": "https://arxiv.org/abs/2506.11903", "title": "GeistBERT: Breathing Life into German NLP", "title_en": "GeistBERT: Breathing Life into German NLP", "authors": "Raphael Scheible-Schmitt,Johann Frei", "background": "先前基于转译器的语言模型已经表明，在高质量语料库上进行语言特定的预训练的优点。在这种背景下，德语NLP可以从更新的架构和面向德语语言特性的现代数据集中受益。", "innovation": "GeistBERT 通过逐步训练在一个多样化数据集上，并且通过优化模型在各种NLP任务上的表现来进行改进。该模型在 fairseq 中使用标准超参数进行预训练，从 GottBERT 权重初始化，并在大规模德语语料库上使用整词掩码（WWM）进行训练。为了支持长上下文模型，还使用 Nyströmformer 和 Longformer 架构提供了最大支持至8k词元的变体。所有模型均使用 F1 得分和准确性对 NER（CoNLL 2003, GermEval 2014）和文本分类（GermEval 2018 细粒度/粗粒度，10kGNAD）任务进行了评估，GeistBERT 模型表现优异，均优于其他基模，并且其性能达到了新的SOTA。", "conclusion": "为了支持德语NLP研究社区，GeistBERT 和其变体将在 MIT 许可下进行发布。"}
{"llm_update_time": "2025-06-25 09:18:52", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16640", "html_url": "https://arxiv.org/abs/2506.16640", "title": "使用稀疏注意力机制的长上下文泛化", "title_en": "Long-Context Generalization with Sparse Attention", "authors": "Pavlo Vasylenko,Marcos Treviso,André F. T. Martins", "background": "传统的基于Transformer的架构使用softmax来计算注意力权重，这会在序列的所有令牌上产生密集的概率分布。尽管在许多情况下这很有效，但在需要对固定大小模式进行精确关注的任务中，这种密集性反而会成为问题。随着序列长度的增加，非信息性令牌会累积注意力概率质量，导致分布分散和表示能力退化。研究表明，使用α-entmax的稀疏注意力机制能够避免这些问题，因为它可以对无关的令牌赋值为精确的零。此外，我们引入了可学习温度参数的Adaptive-Scalable Entmax（ASEntmax），使其能够在稀疏（模式集中）和密集（softmax类似）注意力分布之间进行插值。最后，我们展示通过对位置编码的精心设计，可以进一步提高对固定大小模式的定位和泛化能力，这既影响密集也影响稀疏的注意力机制。通过将ASEntmax集成到标准的Transformer层中，并结合适当的相对位置编码，我们展示了我们的模型在长上下文泛化任务上显著优于softmax、可缩放softmax和固定温度α-entmax的基线模型。", "innovation": "提出了一种稀疏注意力机制ASEntmax，该机制采用α-entmax，能够对无关的令牌精确赋值为零，并引入了带有可学习温度参数的Adaptive-Scalable Entmax，使其能够在稀疏和密集注意力分布之间灵活切换。此外，通过精心设计的位置编码，增强了对固定大小模式的定位和泛化能力。", "conclusion": "通过将ASEntmax集成到标准Transformer层中，并结合适当的相对位置编码，我们的模型在长上下文泛化任务上显著优于其他基线模型。"}
{"llm_update_time": "2025-06-25 09:18:53", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.17789", "html_url": "https://arxiv.org/abs/2506.17789", "title": "通过印度语言视角看多语言分词：挑战与见解", "title_en": "Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights", "authors": "N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar", "background": "多语言自然语言处理(NLP)的分词在其中扮演着关键角色。然而，现有的分词器主要针对的是资源丰富语言，并且这些分词器在用于语言多样和形态复杂的语言(如印度次大陆的语言)时效果有限。因此，本文对17种印度语言的分词策略进行了全面的内部评估，研究了自底向上和自顶向下的分词算法（如BPE和Unigram LM）、词汇表大小的影响，并对比了联合和基于聚类的多语言词汇表构建策略。此外，还展示了低资源语言可以从相关高资源语言训练的分词器中受益。", "innovation": "本文通过对17种印度语言的全面评估，考察了自底向上和自顶向下的分词算法、词汇表大小的影响以及多语言词汇表构建策略，并展示了低资源语言可以从相关高资源语言训练的分词器中受益。这些研究结果为构建更公平、更高效的多语言分词器提供了实用见解。", "conclusion": "本文的研究成果为构建更公平、更高效的分词器提供了实用的指导和见解。这些分词器能够更好地支持多语言NLP，特别是对资源较少的语言有着积极的帮助。"}
{"llm_update_time": "2025-06-25 09:18:55", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18082", "html_url": "https://arxiv.org/abs/2506.18082", "title": "基于统计多准则评估生成模型文本质量", "title_en": "Statistical Multicriteria Evaluation of LLM-Generated Text", "authors": "Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen", "background": "评估大型语言模型（LLM）生成文本的质量仍然是自然语言处理中的一个基本难题。现有评估方法通常依赖单一的指标或简单的聚合，这些方法未能捕捉到语境一致性、多样性、流畅性和其他相关文本质量指标之间的微妙权衡。现有的基准测试方法还存在三个主要问题：单一指标评估的不足、自动度量与人类判断的不兼容性，以及缺乏推断性统计保证。", "innovation": "本文引入了一种基于广义随机占优（GSD）的统计推理框架，解决了现有基准测试方法中的三个关键限制：单一指标的不充分性、自动度量和有序人类判断之间的不兼容性，以及缺乏推断性统计保证。GSD前端方法可以同时在多个质量维度上进行评估，尊重不同的测量尺度，并基于解码策略的偏序关系，从而避免对相关度量进行任意加权。通过将此框架应用于比对LLM生成文本与人工生成的文本，证明了其能够识别统计上显著的表现差异，同时考虑到采样设计的一致性假设偏差问题。", "conclusion": "文章将GSD前端方法应用于评估常用解码策略与人工生成文本的性能差异，展示了其在识别统计上显著差异方面的能力，同时考虑了采样设计的偏差问题。"}
{"llm_update_time": "2025-06-25 09:18:57", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.17728", "html_url": "https://arxiv.org/abs/2506.17728", "title": "KAG-Thinker：通过知识增强生成在LLM中实现交互式思考与深度推理", "title_en": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation", "authors": "Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo", "background": "本文介绍了一个名为KAG-Thinker的框架，它是KAG的一种升级，可以将KAG转化为一个基于专用参数轻量级大语言模型（LLM）的多轮交互思考和深度推理框架。该框架针对特定领域的知识库（KBs）中的问答（Q&A）任务，构建了一个结构化的思考过程，增强了推理过程的逻辑连贯性和上下文一致性。框架遵循KAG的逻辑形式引导的检索与推理技术路径，通过广度分解将复杂问题分解为独立可解的子问题，这些子问题也被称作逻辑形式，并以自然语言和逻辑函数两种形式表示。然后根据任务类型将其分类为知识检索或推理分析任务，并通过逻辑函数接口明确建模这些任务之间的依赖性和参数传递关系。", "innovation": "该框架通过逻辑形式引导的检索和推理技术路线，将复杂问题分解为独立可解的子问题，并使用两种等价形式表示每个逻辑形式，即自然语言和逻辑函数。在解决过程中，检索功能执行检索任务，获取指定知识单元的一跳结构化和非结构化信息；而数学和推断功能用于执行推理分析任务。特别值得注意的是，在知识检索子问题任务中，LLM和外部知识源被视为等效的知识库。通过知识边界模块和自我调节机制（如信心校准和反思性推理），以及深度解算模块，确定并优化知识源的选择。", "conclusion": "该框架增强了逻辑推理过程的连贯性和知识获取的全面性，这对于在LLM中实现交互式思考和深度推理具有重要意义，特别是在特定领域的知识库中。"}
{"llm_update_time": "2025-06-25 09:18:58", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.06609", "html_url": "https://arxiv.org/abs/2506.06609", "title": "使用模型缝合在语言模型之间转移特征", "title_en": "Transferring Features Across Language Models With Model Stitching", "authors": "Alan Chen,Jack Merullo,Alessandro Stolfo,Ellie Pavlick", "background": "本文探讨了在语言模型之间使用仿射变换在残差流之间转移表示特性的方法，发现这种方法相较于其他方法更为经济且有效。研究采用了从较小模型迁移到较大模型的方法，展示了不同大小的语言模型学习相似的表示空间，这促使研究人员考虑在较小模型上训练昂贵的组件并在较大量模型上进行迁移以节省计算资源。研究还研究了在较大的模型上训练稀疏自编码器时，使用从小到大迁移的方法来初始化可以节省50%的训练资源。此外，研究还发现转移的探针和引导向量可以有效地恢复真实性能。研究深入探讨了特征级别的转移性，发现语义和结构特征的转移差异明显，而特定类别的功能性特征的角色则被忠实映射。", "innovation": "本文提出了一种使用仿射变换在不同大小的语言模型之间转移表示特征的方法。通过这种方法，较小的模型能够训练昂贵的组件（如稀疏自编码器）并在较大量模型上进行迁移，从而节省大量的计算资源。这种技术为提高稀疏自编码器的训练效率提供了一种新的方法。", "conclusion": "研究发现，不同大小的语言模型在学习表示空间方面表现出相似性与差异性。小模型能够有效训练复杂的组件并在较大模型上进行迁移以优化计算资源的使用。具体来说，从较小模型迁移得到的稀疏自编码器在较大模型上进行训练时，可以将训练成本降低50%。此外，转移的探针和引导向量能够恢复真实模型的性能，具体分析显示语义和结构特征的转移方式有所不同，而功能性特征的角色在转移过程中能够保持一致。"}
{"llm_update_time": "2025-06-25 09:18:58", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.10326", "html_url": "https://arxiv.org/abs/2501.10326", "title": "大型语言模型在自动化学术论文评审中的应用：一项综述", "title_en": "Large language models for automated scholarly paper review: A survey", "authors": "Zhenzhen Zhuang,Jiandong Chen,Hongfeng Xu,Yuwen Jiang,Jialiang Lin", "background": "大型语言模型（LLMs）对人类社会产生了深远影响，尤其是学术领域既是LLMs影响的对象，也是其发展的推动力。学术出版中，LLMs在同行评审机制中的集成成为了一种体现。研究发现，LLMs在实现全面的自动化学术论文评审（ASPR）方面具有革新潜力，但同时也带来了新的问题和挑战。本文旨在提供LLMs背景下ASPR的全面视角，以帮助研究者更好地理解和应对这一领域的发展挑战。", "innovation": "本文通过系统回顾LLMs在ASPR中的应用，探索了LLMs为ASPR带来的新技术、新数据集、新源代码和新在线系统。在总结LLMs在ASPR中的性能和问题的同时，还分析了出版者和学术界对ASPR的态度和反应，最后讨论了ASPR发展的挑战和未来方向。", "conclusion": "本文的综述结果为ASPR的实际实施提供了启发性参考，强调了应对LLMs在ASPR中带来的挑战的重要性，推动ASPR的进步。"}
{"llm_update_time": "2025-06-25 09:19:00", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.06877", "html_url": "https://arxiv.org/abs/2506.06877", "title": "训练数学推理能力的大型语言模型：结果监管的局限性", "title_en": "Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning", "authors": "Jiaxing Guo,Wenjie Yang,Shengzhong Zhang,Tongshan Xu,Lun Du,Da Zheng,Zengfeng Huang", "background": "大型语言模型（LLMs）在数学问题解决方面取得了显著的成功，但这一成功往往掩盖了一个关键问题：模型经常通过根基不稳固的推理过程得到正确的答案，这表明了奖励作弊的现象。现有的细粒度标注数据集（如MathOlympiadEval）揭示了LLMs答案正确性与低推理正确性之间的巨大差距。现有自动化方法如LLM作为裁判（LLM-as-a-judge）很难可靠地检测出这些推理错误。", "innovation": "提出了ParaStepVerifier，这是一种新颖的方法，用于细致入微、分步骤验证数学解决方案。ParaStepVerifier能够识别出错误的推理步骤。实证结果表明，ParaStepVerifier在识别有缺陷的解决方案方面显著提高了准确性，特别是在复杂、多步骤问题上效果显著。这一方法为评估和训练具有真正数学推理能力的LLMs提供了一个更加可靠的途径。", "conclusion": "ParaStepVerifier显著提高了错误解决方案的识别准确性，特别是在复杂、多步骤问题上。这为评估和训练具有真正数学推理能力的大型语言模型提供了可靠的方法。"}
{"llm_update_time": "2025-06-25 09:19:02", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.10213", "html_url": "https://arxiv.org/abs/2405.10213", "title": "社交媒体讨论中的触发词：基于Reddit的英国政治的大规模案例研究", "title_en": "Words as Trigger Points in Social Media Discussions: A Large-Scale Case Study about UK Politics on Reddit", "authors": "Dimosthenis Antypas,Christian Arnold,Jose Camacho-Collados,Nedjma Ousidhoum,Carla Perez Almendros", "background": "社交媒体上的政治辩论有时会引发激烈的反应，用户间的互动更加频繁，且更为情绪化和两极分化。尽管难以通过计算方法捕捉到这些时刻，但该研究提出触发点的概念，认为这些时刻反映出个人认为社会中什么是公平、正常或合适的价值观被质疑的事实。研究人员发现，这些触发点也存在在线辩论中，并利用Reddit上的评论数据进行了大规模分析，显示触发词导致用户参与度和敌意增加，如负面、仇恨言论和有争议的评论增多。这些发现对研究情感计算、在线讨论以及公民在情感两极化背景下讨论政治和社会问题的学者具有重要意义。", "innovation": "引入了触发点的概念，用于理解和建模在线社区的用户行为和沟通。该研究首次利用大规模的Reddit数据来探索触发点现象，通过分析触发词引起的情绪反应和社交互动模式，证明了这一概念的有效性。这为在线政治和社会问题讨论的情感化过程提供了新的视角。", "conclusion": "研究发现，触发点是理解在线用户情感反应和两极化的重要工具。这些发现对情感计算、在线争论以及公民在情感两极化背景下讨论政治和社会问题的研究具有重要意义，可以为进一步研究提供新的方法论支持。"}
{"llm_update_time": "2025-06-25 09:19:02", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09730", "html_url": "https://arxiv.org/abs/2503.09730", "title": "循环验证者本地前瞻指导在自动定理证明中的应用", "title_en": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving", "authors": "Sara Rajaee,Kumar Pratik,Gabriele Cesa,Arash Behboodi", "background": "当前最具有潜力的AI推理方法依赖于强化学习（RL）的应用，无论是从语言模型中展开的轨迹，还是大量的人工标注轨迹数据。这种方法依赖于展开的轨迹来获取计算资源，使得成本和时间变得难以承受。特别是，只有在推理轨迹完成时才能判断其正确性，导致在强化学习中产生稀疏奖励，或要求在专家迭代中生成昂贵的合成数据。本文侧重于自动定理证明（ATP）任务，介绍了现有的方法都是基于整个推理轨迹进行反馈，而本文提出了一种新的循环验证者设计，在推理过程中的每一步给出中间反馈。使用Lean作为验证者，实验证明在每一步进行局部验证能有效地提高模型的推理准确性和效率。", "innovation": "提出了循环验证者设计，在推理过程中的每个步骤提供中间反馈，不同于现有方法依赖于整个推理轨迹的反馈。使用Lean作为验证者进行本地验证，提高模型推理的准确性和效率。", "conclusion": "实验证明，循环验证者设计在每一步进行局部验证能够提高模型的推理准确性和效率。"}
{"llm_update_time": "2025-06-25 09:19:03", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.05410", "html_url": "https://arxiv.org/abs/2406.05410", "title": "ChatSR: 采用多模态大语言模型进行科学研究中的公式发现", "title_en": "ChatSR: Multimodal Large Language Models for Scientific Formula Discovery", "authors": "Yanjie Li,Lina Yu,Weijun Li,Min Wu,Jingyi Liu,Wenqiang Li,Shu Wei,Yusong Deng", "background": "公式的发现是将观察数据转化为描述自然规律的语言，是科学研究的目的之一，也是一项重要的人工智能研究课题，被称为符号回归问题。目前大多数符号回归方法直接从观察数据中生成表达式。虽然有些方法可以通过添加约束或引入特定字符提示来注入一些先验知识，但这些方法只能引入事先规定的一部分先验知识，更不用说理解自然语言的指示了。该论文基于多模态大语言模型的强大知识储备和语言理解能力，提出了一种名为ChatSR的模型，该模型能够像一个博学的科学家一样工作，可以通过自然语言指令提供任意形式的先验知识，指导公式生成。该模型在13个数据集上的测试表明，ChatSR不仅在传统的符号回归任务中达到了最先进的性能，而且还能够很好地理解自然语言提示中的先验知识，并提高生成表达式的质量。此外，ChatSR还具有很好的零样本能力，能够理解不在训练数据中的先验知识。", "innovation": "ChatSR模型能够通过自然语言指令提供任意形式的先验知识，指导公式生成，相比传统方法，能够引入更多未提前规定的先验知识。ChatSR模型在13个数据集上的测试结果表明，它不仅在传统的符号回归任务中表现优异，还能够理解自然语言提示中的先验知识，并进一步提高表达式的质量。此外，还展示了ChatSR的零样本能力，能够理解不在训练数据中的先验知识。", "conclusion": "ChatSR模型不仅在传统的符号回归任务中达到了最先进的性能，而且能够有效地将自然语言中包含的先验知识转化为生成的表达式，并展示了良好的零样本能力。"}
{"llm_update_time": "2025-06-25 09:19:05", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10412", "html_url": "https://arxiv.org/abs/2506.10412", "title": "Time-IMM: 一个用于不规则多重模态多元时间序列的数据库和基准", "title_en": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series", "authors": "Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang", "background": "在医疗保健、气候建模和金融等领域中的时间序列数据通常不规则、多重模态且杂乱，存在不同的采样率、异步的模态以及普遍的数据缺失。现有的基准通常假定干净、规律采样和单模态数据，这在研究和实际部署之间造成了显著差距。", "innovation": "引入了Time-IMM数据集和基准库（IMM-TSF），专门用于捕捉多重模态多变量时间序列中的因果不规则性。Time-IMM涵盖了九种不同类型的不规则时间序列的机制，并设计有特种融合模块，如时间戳到文本的融合模块和多重模态的融合模块，支持基于最近和注意力的整合策略。实证结果表明，明确建模不规则时间序列中的多重模态能够显著提高预测性能。", "conclusion": "Time-IMM和IMM-TSF为在现实条件下的时间序列分析提供了基础。数据集和基准库已经公开可用。"}
{"llm_update_time": "2025-06-25 09:19:06", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18710", "html_url": "https://arxiv.org/abs/2506.18710", "title": "大型语言模型的教育知识基准测评", "title_en": "Benchmarking the Pedagogical Knowledge of Large Language Models", "authors": "Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portela,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod", "background": "现有的基准测试如大规模多任务语言理解（MMLU）在评估AI的知识和能力方面发挥了重要作用，但这些基准测试主要侧重于内容知识，忽视了对模型教育方法和实践理解的评估。本文旨在填补这一空白，提出了一种新的基准测试，名为《教育知识基准测评》，用于评估大型语言模型在跨领域教育知识（CDPK）和特殊教育需求与残疾（SEND）教育知识方面的表现。这些基准测试基于专业教师发展考试中的精心挑选的问题，涵盖了教学策略和评估方法等多个人员发展子领域的问题。这项研究展示了这些基准测试的方法学和发展过程，报道了97个模型的评估结果，准确性范围从28%到89%。同时，分析了成本与准确性的关系，并绘制了帕累托前沿随时间的变化趋势。为便于在线查看和筛选不同模型性能，还提供了实时更新的排行榜，允许用户根据成本每token和开放-封闭权重等因素对模型进行筛选和探索。", "innovation": "提出了《教育知识基准测评》，这是一种用于评估大型语言模型跨领域教育知识（CDPK）和特殊教育需求与残疾（SEND）知识的新数据集。此基准测试基于专业教师发展考试中的精心挑选的问题，涵盖广泛的人力资源发展子领域，如教学策略和评估方法。进一步分析了成本与准确性之间的关系，并绘制了帕累托前沿随时间的变化趋势。还提供了更新的在线排行榜，允许根据各种模型属性进行互动探索和筛选，如成本每token和开放-封闭权重，以及不同学科的表现。这表明了大规模语言模型和生成性人工智能对教育的巨大潜力，以及教育领域基准测试的重要性，这些基准测试对于确保负责使用基于LLM的大规模语言模型及其工具进行决策至关重要，特别是在教育环境中。", "conclusion": "大型语言模型及其生成的人工智能有潜力影响教育领域并帮助解决全球学习危机。面向教育的基准测试对于衡量模型理解和应用教育概念的能力至关重要，以及其回应学习者需求和支持多元教育环境下的有效教学实践的能力。它们对于指导负责和基于证据的大规模语言模型及其工具在教育中的部署至关重要，以及指导开发和政策决策。在线动态更新的排行榜极大地提高了模型性能探索。"}
{"llm_update_time": "2025-06-25 09:19:07", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00258", "html_url": "https://arxiv.org/abs/2502.00258", "title": "ProxSparse：预训练LLM中半结构化稀疏性掩码的正则化学习", "title_en": "ProxSparse: Regularized Learning of Semi-Structured Sparsity Masks for Pretrained LLMs", "authors": "Hongyi Liu,Rajarshi Saha,Zhen Jia,Youngsuk Park,Jiaji Huang,Shoham Sabach,Yu-Xiang Wang,George Karypis", "background": "大规模语言模型（LLMs）在自然语言处理任务中表现出色，但其庞大的规模导致了服务时的低效率和高成本。现有的半结构化剪枝方法虽然有效，但存在局限性，它们主要通过局部、逐层优化基于启发式规则来实现，未能利用全局反馈信息。", "innovation": "提出了ProxSparse，一种基于正则化优化的掩码选择学习框架，将刚性的非可微掩码选择过程转化为更平滑的优化过程，允许灵活的掩码渐进探索。ProxSparse确定掩码后不需要额外的权重更新。实验表明，ProxSparse在7个广泛使用模型上始终优于以往的半结构化掩码选择方法，证明了这种方法的有效性。", "conclusion": "ProxSparse展示了在半结构化剪枝中的学习方法的有效性，通过全局优化而不是局部优化改进了现有的剪枝方法，提高了预训练LLM的效率和效果。"}
{"llm_update_time": "2025-06-25 09:19:09", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.08638", "html_url": "https://arxiv.org/abs/2505.08638", "title": "TRAIL：轨迹推理与代理问题定位", "title_en": "TRAIL: Trace Reasoning and Agentic Issue Localization", "authors": "Darshan Deshpande,Varun Gangal,Hersh Mehta,Jitin Krishnan,Anand Kannappan,Rebecca Qian", "background": "随着代理工作流程在不同领域中的广泛应用，需要一种能够大规模和系统性地评估这些系统生成的复杂轨迹的方法。现有的评估方法依赖于人工、特定领域的分析，这种方法不能适应代理输出复杂性和数量的增长。在这些环境中进行错误分析使得情况更加复杂，尤其是外部工具输出和语言模型推理的相互影响，使得问题比传统的软件调试更为复杂。", "innovation": "本文提出了（1）代理工作流程轨迹所需的健壮和动态评估方法的需求；（2）介绍了代理系统中遇到的错误类型的正式分类；（3）提供了一个包含148条大型人工标注轨迹（TRAIL）的数据集，这些轨迹是根据该分类系统并立足于现有的代理基准构建的。为了保证生态效度，数据集既包含单代理系统也包含多代理系统，重点是诸如软件工程和开放世界信息检索等实际应用。我们的评估表明，现代长上下文LLM在轨迹调试中表现不佳，最高得分为11%的Gemini-2.5-pro模型在TRAIL上的得分为11%。", "conclusion": "本研究公开了数据集和代码，以支持并加快未来代理工作流程的可扩展评估研究。"}
{"llm_update_time": "2025-06-25 09:19:09", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11555", "html_url": "https://arxiv.org/abs/2506.11555", "title": "RAG+: 通过应用意识推理增强检索增强生成", "title_en": "RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning", "authors": "Yu Wang,Shiwan Zhao,Zhihu Wang,Yubo Zhang,Xicheng Zhang,Zhengfan Wang,Heyuan Huang,Ming Fan,Ting Liu", "background": "检索增强生成（RAG）方法已成为增强大型语言模型（LLMs）完成知识密集型任务的关键手段。然而，现有的RAG模式常常忽视了应用知识的认知步骤，导致从检索的事实到任务特定推理之间存在差距。为了弥合这一差距，本文提出了一种称为RAG+的模块化扩展，它在RAG流程中明确引入了应用意识推理。RAG+构建了一个包含知识和对齐的应用示例的双重语料库，在推理时同时检索这两部分。这种设计不仅使LLMs能够访问相关信息，还能够在结构化的、目标导向的推理过程中应用这些信息。", "innovation": "RAG+提出了一种有原则性和模块化的扩展，将应用意识推理明确集成到RAG管道中。其创新之处在于构建了包含知识和对齐应用示例的双重语料库，并在推理时同时检索这两部分。这种设计不仅让LLMs能够访问相关信息，还能够在结构化的、目标导向的推理过程中应用这些信息。实验结果显示，RAG+在数学、法律和医学等多个领域中的一系列模型上均表现出色，平均改进率3-5%，在复杂场景中最高可达7.5%。", "conclusion": "通过将检索与可执行的应用相结合，RAG+推进了一种更加认知地基础的知识整合框架，是推动更可解释和能力更强的LLMs的一个步骤。"}
{"llm_update_time": "2025-06-25 09:19:10", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11558", "html_url": "https://arxiv.org/abs/2506.11558", "title": "DaMO: 一种高效的数据多模态 orchestrator 用于视频语言模型中的时间推理", "title_en": "DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs", "authors": "Bo-Cheng Chiu,Jen-Jee Chen,Yu-Chee Tseng,Feng-Chi Chen", "background": "大型语言模型（LLMs）已经扩展到视频领域，使其能够进行复杂的视频-语言理解。然而，现有的视频LLMs在精细的时间推理方面存在局限性，限制了其对特定视频时刻的精确响应能力，特别是在受限监督条件下。现有的视频LLMs难以精确地将响应归因于特定的视频时刻，特别是在需要精细时间对齐和推理的任务中表现不佳。", "innovation": "我们提出了 DaMO，一种专门为准确的时间推理和多模态理解设计的数据高效视频LLM。核心创新在于提出的 Temporal-aware Fuseformer，它采用分层双流架构，逐步捕捉每种模态内的时间动态，并有效融合互补的视觉和音频信息。此外还集成了一个全局残差，减少空间冗余同时保留关键语义细节。我们通过结构化的四阶段渐进式训练范式训练 DaMO，逐步赋予模型多模态对齐、语义接地和时间推理能力。我们还提供了从现有数据集中增强生成的包含 GPT 生成的时间上接地的问答对的多个数据集，适用于需要时间监督的任务。实验结果表明，DaMO 在时间对准和视频问答基准测试中始终超过了之前的模型，特别是在需要精确时间对齐和推理的任务中表现尤为出色。", "conclusion": "我们的工作为数据高效视频-语言建模指明了有希望的方向。"}
{"llm_update_time": "2025-06-25 09:19:13", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.16828", "html_url": "https://arxiv.org/abs/2504.16828", "title": "思考过程奖励模型", "title_en": "Process Reward Models That Think", "authors": "Muhammad Khalifa,Rishabh Agarwal,Lajanugen Logeswaran,Jaekyeom Kim,Hao Peng,Moontae Lee,Honglak Lee,Lu Wang", "background": "步骤验证器，也称为过程奖励模型（PRMs），是测试时扩展的关键成分。PRMs 需要步骤级别的监督，这使得它们在训练时成本高昂。这项工作旨在建立数据高效的 PRMs，通过生成验证链（CoT）来验证每个步骤，作为口头化的奖励模型。研究者提出了 ThinkPRM，与判别性 PRMs 相比，它仅使用 PRM800K 流程标签的一小部分，就能在多个具有挑战性的基准测试中超越基线，包括在 ProcessBench、MATH-500 以及 AIME '24 中的表现。此外，在 GPQA-Diamond 和 LiveCodeBench 的测试集中，PRMs 超过了判别性验证器，表现分别高出 8% 和 4.5%。研究还表明，尽管有相同的令牌预算，ThinkPRM 在 ProcessBench 的子集中更有效地扩展验证计算，比 LLM-as-a-Judge 高出 7.2%。", "innovation": "提出了一种名为 ThinkPRM 的长链验证器，这是一种数据高效的长推理链（CoT）验证器，它仅使用判别性 PRMs 所需过程标签的一小部分。通过利用长 CoT 模型固有的推理能力，ThinkPRM 在多个人工智能挑战基准测试中超越了其它验证器。此外，与使用完整 PRM800K 标签训练的判别性验证器相比，该模型在 GPQA-Diamond 和 LiveCodeBench 上分别表现出 8% 和 4.5% 的优势。最后，在相同的令牌预算下，它也能够更加有效地扩展验证计算能力，超出 LLM-as-a-Judge 7.2%。", "conclusion": "本文展示了生成型、长链 CoT PRMs 的价值，这些模型可以扩展测试时的验证计算，同时在训练时只需要最少的监督。研究的代码、数据和模型将在指定的 URL 上发布。"}
{"llm_update_time": "2025-06-25 09:19:13", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18922", "html_url": "https://arxiv.org/abs/2506.18922", "title": "无对应关系的多视角点云配准通过深度导向联合优化", "title_en": "Correspondence-Free Multiview Point Cloud Registration via Depth-Guided Joint Optimisation", "authors": "Yiran Zhou,Yingyu Wang,Shoudong Huang,Liang Zhao", "background": "多视角点云配准是构建全局一致的3D模型的基本任务。现有方法通常依赖于特征提取和多点云间的数据关联，但这些过程在复杂环境中难以获得全局最佳解。", "innovation": "提出了一种全新的无对应关系的多视角点云配准方法。该方法将全局地图表示为深度图，并利用原始深度信息来制定一种非线性最小二乘优化方法，该方法联合估计点云和全局地图的姿态。这种方法通过点云的姿态与全局深度图关联，避免了传统基于特征的束调整方法依赖于显式特征提取和数据关联的挑战，在优化过程中隐式地进行数据关联并动态优化。", "conclusion": "在真实世界数据集上的广泛评估表明，该方法在准确性和复杂环境中的表现优于现有最先进技术，特别是在特征提取和数据关联困难的情况下。"}
{"llm_update_time": "2025-06-25 09:19:14", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18810", "html_url": "https://arxiv.org/abs/2506.18810", "title": "ConciseHint：在生成过程中通过连续简洁提示提升高效推理", "title_en": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "authors": "Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang", "background": "大推理模型（LRMs）如DeepSeek-R1和OpenAI o1系列在复杂推理任务上通过增加生成长度的方法（Chain-of-Thought），取得了显著的性能提升。然而，这些模型倾向于产生冗长的推理过程，导致效率低下。目前改进效率的研究主要集中在推理前的提示和微调上，而忽视了在推理过程中直接鼓励模型简洁表达这一有潜力的方向。", "innovation": "作者提出了一个名为ConciseHint的框架，在推理过程中连续注入简洁提示（手动设计或通过少量简洁数据训练得到），以鼓励模型简洁表达。该框架还能够根据查询的复杂性自适应调整提示强度，以确保不会损害模型性能。实验表明，该方法在保持性能的同时，能够显著减少推理长度，例如在GSM8K基准测试中，Qwen-3 4B模型的推理长度减少了65%，几乎无准确性损失。", "conclusion": "ConciseHint框架能够在保持模型性能的同时，有效减少推理长度，提升推理效率。该方法通过在生成过程中连续注入简洁提示，并根据查询复杂性自适应调整提示强度来实现这一目标。"}
{"llm_update_time": "2025-06-25 09:19:15", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18902", "html_url": "https://arxiv.org/abs/2506.18902", "title": "jina-embeddings-v4：统一多模态多语言检索的嵌入模型", "title_en": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval", "authors": "Michael Günther,Saba Sturua,Mohammad Kalim Akram,Isabelle Mohr,Andrei Ungureanu,Bo Wang,Sedigheh Eslami,Scott Martens,Maximilian Werk,Nan Wang,Han Xiao", "background": "该论文介绍了一种新型的多模态嵌入模型jina-embeddings-v4，该模型包含38亿参数，可以同时处理文本和图像的表示。通过支持单向量和多向量嵌入的创新架构，该模型在多重检索场景，如查询文档检索、语义文本相似性和代码搜索中表现出优良的性能。该研究通过全面评估，展示了jina-embeddings-v4在单模态和跨模态检索任务中达到了最先进的技术水平，特别在处理包含表格、图表、图表和混合媒体格式的丰富视觉内容方面表现强劲。为了评估这种能力，该论文还引入了Jina-VDR，这是一个专为丰富图像检索设计的基准测试工具。", "innovation": "jina-embeddings-v4模型通过支持单向量和多向量嵌入的创新架构，能够统一处理文本和图像的表示，同时采用了任务特定的Low-Rank Adaptation (LoRA)适配器优化其在各种检索场景下的性能。该模型在单模态和跨模态检索任务中均表现出最先进的技术水平，并且特别擅长处理包含丰富视觉信息的内容，如表格、图表、示意图和混合媒体格式。此外，该论文还引入了Jina-VDR作为评估丰富图像检索能力的新基准。", "conclusion": "全面的评估表明，jina-embeddings-v4在单模态和跨模态检索任务中均达到了最先进的技术水平，特别是在处理丰富视觉内容时表现出色。引入的Jina-VDR基准测试工具为评估这种能力提供了有力支持。"}
{"llm_update_time": "2025-06-25 09:19:19", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18930", "html_url": "https://arxiv.org/abs/2506.18930", "title": "基于强化学习的动态分组方法在管状结构追踪中的应用", "title_en": "Reinforcement Learning-Based Dynamic Grouping for Tubular Structure Tracking", "authors": "Chong Di,Shuwang Zhou,Da Chen,Jean-Marie Mirebeau,Minglei Shu,Laurent D. Cohen", "background": "管状结构（如血管、道路等）的最小路径计算因其复杂的形态和环境变化而具有挑战性。现有方法大致可以分为两类：基于点的方法和基于段的方法。虽然基于段的方法在许多场景下取得了令人满意的结果，但它们往往因为计算效率低下和对预先确定的先验知识的依赖而受到限制。", "innovation": "作者提出了一种新颖的框架，将基于段的追踪问题建模为马尔可夫决策过程（MDP），并结合强化学习进行动态探索。通过使用Q-Learning，本方法能够在需求时计算边权重并动态扩展搜索空间，从而避免了预先计算图的高昂成本，并证明了即使在初始信息不完整的情况下也具有鲁棒性。实验结果表明，本方法在典型管状结构数据集上显著优于现有的基于点和基于段的方法，并能有效地处理复杂的拓扑结构，且无需过多先验结构知识的支持。", "conclusion": "我们的方法显著超越了现有的基于点和基于段的方法，特别适用于具有复杂拓扑结构的管状结构追踪，且不依赖于广泛的知识先验。"}
{"llm_update_time": "2025-06-25 09:19:20", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18925", "html_url": "https://arxiv.org/abs/2506.18925", "title": "Parkinson 病的可解释且粒度化的基于视频的指尖敲击测试运动特征量化", "title_en": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease", "authors": "Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers", "background": "准确量化帕金森病（PD）的运动特征对于监测疾病进展和优化治疗策略至关重要。指尖敲击测试是标准的运动评估方法。临床医生通过视觉评估患者的敲击表现，并根据振幅、速度和不规则性分配一个总体严重程度评分。然而，这种主观评估容易受到不同和同一评定者间变异性的影响，无法提供在测试期间个体运动特征的见解。本文引入了一种基于计算机视觉的粒度量化方法，从视频记录中量化PD运动特征，提出四个临床相关特征集来描述运动减少、动作迟缓、序列效应和犹豫停顿。该方法在74名帕金森项目患者的视频记录和临床评估中进行了评估，结果表明视频特征与四种缺陷对应，并允许识别序列效应和犹豫停顿缺陷的进一步细节。此外，利用这些特征训练机器学习分类器以估计运动障碍学会统一帕金森病评定量表（MDS-UPDRS）的指尖敲击得分，准确度高于现有技术，但仍保持个体敲击运动特征的可解释量化。总体来说，所提出的框架可为帕金森病的客观评估提供实用解决方案，可以应用于临床和远程评估场景。未来需要评估其对症状治疗和疾病进展的敏感性。", "innovation": "提出了一种基于计算机视觉的量化方法，通过视频记录来客观评估帕金森病患者的运动特征。具体创新点包括：(1) 提出四个临床相关特征集来描述不同的运动特征缺陷；(2) 利用视频特征训练机器学习分类器，以估计 MDS-UPDRS 指尖敲击得分；(3) 达到了现有技术更高的准确度，同时保持了个体运动特征的可解释量化；(4) 允许识别序列效应和犹豫停顿缺陷的进一步详细信息。", "conclusion": "所提出的框架提供了一种实用的帕金森病运动特征客观评估方法，可以在临床和远程环境中应用。未来工作需要评估其对症状治疗和疾病进展的敏感性。"}
{"llm_update_time": "2025-06-25 09:19:20", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18924", "html_url": "https://arxiv.org/abs/2506.18924", "title": "连接视觉与排放：道路设计中基于行为AI的碳估算方法", "title_en": "Connecting Vision and Emissions: A Behavioural AI Approach to Carbon Estimation in Road Design", "authors": "Ammar K Al Mhdawi,Nonso Nnamoko,Safanah Mudheher Raafat,M.K.S. Al-Mhdawi,Amjad J Humaidi", "background": "本文介绍了一个改进的YOLOv8实时车辆检测和分类框架，用于估算城市环境中的碳排放。该系统增强了YOLOv8架构，以从实时交通视频流中检测、分割和跟踪车辆。系统通过识别车牌和分类车辆类型来完善YOLOv8的功能。由于YOLOv8本身缺乏识别车牌或确定车辆属性（ Beyond 类别标签）的能力，该框架结合了一个混合处理管道，在每个检测到的车辆上进行跟踪并提取其边界框，使用深度光学字符识别(OCR)模块进行字符级的检测和车牌识别。此外，验证步骤通过实时API将识别的车牌信息与外部车辆注册数据库进行交叉验证，以确保分类的准确性和排放估算的正确性。多阶段的方法使得车辆碳排放的精确自动计算成为可能。广泛测试表明，YOLOv8检测器在边界框和分割掩码方面的性能分别约为71%和70%，OCR字符识别准确率达到99%。", "innovation": "该研究提出了一种结合实时目标检测与深度OCR技术的车辆排放估算方法。通过改进YOLOv8框架，支持车牌识别和车辆分类，并构建了一个用于多条件下的字符级OCR系统，实现了在运动模糊、遮挡和多种字体风格下的高识别率。同时引入了实时验证机制，确保识别结果的准确性。该研究验证了将目标检测与OCR结合，从而在智能交通系统中高效部署车辆排放监测系统的可行性。", "conclusion": "该项目提出的多阶段方法能够实现精确、自动化的车辆碳排放计算。广泛的测试结果证实，YOLOv8检测器和字符级OCR系统的综合应用在实际部署中是可行的，为进一步智能化的车辆排放监测提供了可扩展的解决方案。"}
{"llm_update_time": "2025-06-25 09:19:22", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18938", "html_url": "https://arxiv.org/abs/2506.18938", "title": "塔吊上施工顶楼的空中视角安全监控", "title_en": "Bird's-eye view safety monitoring for the construction top under the tower crane", "authors": "Yanke Wang,Yu Hin Ng,Haobo Liang,Ching-Wei Chang,Hao Chen", "background": "随着塔吊运行越发注重自动化和智能化操作，特别是在安全问题上的应用目前滞后于其他先进技术的使用，重要的是要保护塔吊和建筑物顶部工作空间之间的工作人员免受高空风险。为了提高安全性，摄像机和LiDAR可以捕捉到工作现场的大量三维信息，但尚未充分利用这些信息以提高安全性。因此，为保障工作人员和塔吊的安全，本文提出了一个基于人工智能的完全自动化的高空视角安全监控系统，用于塔吊吊装，并通过报警提醒操作员避免碰撞。该系统结合了摄像机和LiDAR获取的信息进行了三维数据融合，实现了对工人和MiC（模块化集成建筑）的定位，进一步研究并实施了最先进的方法到我们所提议的软件流水线中，最终在实地上进行了可视化验证，展示系统在实际现场可以作为有价值的安全生产监控工具的作用。", "innovation": "开发了一个基于人工智能的完全自动化的高空视角安全监控系统，结合摄像头和LiDAR的三维数据，实现了对人物和MiC的位置检测和精确监控，为工作人员和塔吊提供安全保障，这是现有技术的创新点。系统中还融合了先进的方法，并展示了有效性和准确性。", "conclusion": "本文提出了一个用于塔吊吊装的高空视角安全监控系统，通过摄像头和LiDAR的数据融合，实现了对施工现场三维信息的利用，系统有效的结合了最前沿的技术，并被实验证明其准确性和效果，是一个有价值的现场安全生产监控工具。"}
{"llm_update_time": "2025-06-25 09:19:22", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1通过基于规则的奖励系统成功增强了大型语言模型（LLM）的推理能力，尽管它是一种'完美'的奖励系统，有效缓解了奖励作弊的问题，但这样的奖励函数往往是离散的。实验观察表明，离散奖励可能导致梯度异常、优化不稳定以及收敛缓慢等问题。", "innovation": "为了解决这些问题，作者引入了ReDit（Reward Dithering，奖励抖动）方法，该方法通过对离散奖励信号添加简单的随机噪声进行抖动，从而在整个学习过程中连续提供探索性梯度，使梯度更新更加平滑，加速了收敛。引入的噪声还增加了平坦奖励区域的随机性，促使模型探索新的策略并逃出局部最优解。实验表明，ReDit在不同任务中的效果和效率都优于传统的GRPO方法，平均只用大约10%的训练步骤就能达到相当的性能，并且在类似训练时间下还能提高4%的性能。理论分析进一步验证了这些优势。", "conclusion": "实验结果证实了ReDit在缓解梯度问题方面的显著效果，并通过理论分析进一步验证了其优势。ReDit在提高LLM策略优化中的表现和效率上展现了强有力的效果，尤其是在减少训练步骤的同时保持甚至提升模型性能方面。"}
{"llm_update_time": "2025-06-25 09:19:25", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18939", "html_url": "https://arxiv.org/abs/2506.18939", "title": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction", "title_en": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction", "authors": "Rui An,Yifeng Zhang,Ziran Liang,Wenqi Fan,Yuxuan Liang,Xuequn Shang,Qing Li", "background": "在不同城市和地区培训通用的时空基础模型对于部署未见过或数据稀缺的地区的城市服务至关重要。现有的研究通常集中在跨域时空数据融合以训练统一的基于Transformer的模型，但这些模型存在计算复杂度高和内存开销大的问题，限制了其可扩展性和实际部署。", "innovation": "我们受Mamba状态空间模型线性时间复杂度效率的启发，探索其在高效城市时空预测中的潜力。为了解决直接应用Mamba作为时空骨干导致的负迁移和严重性能下降的问题，我们提出了Damba-ST，这是一种新型的领域适应性Mamba模型，它保留了Mamba的线性复杂性优势，并显著增强了其在异构领域的适应能力。具体来说，我们引入了两项核心创新：（1）领域适应的状态空间模型，将潜在表示空间划分为一个共享子空间来学习跨域的共同特征，以及独立的、领域特定的子空间来捕捉区内差异特征；（2）三个不同的领域适配器，作为领域感知的代理以连接不一致的领域分布并促进跨域共同特征的对齐。", "conclusion": "广泛的实验结果证明了Damba-ST的泛化能力和高效性。它在预测任务中达到了最先进的性能，并展示了强大的零样本泛化能力，能够无缝部署在新的城市环境中，无需进行大规模的再训练或微调。"}
{"llm_update_time": "2025-06-25 09:19:26", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18946", "html_url": "https://arxiv.org/abs/2506.18946", "title": "DiffRIS: 使用预训练文本到图像扩散模型增强遥感图像引用分割", "title_en": "DiffRIS: Enhancing Referring Remote Sensing Image Segmentation with Pre-trained Text-to-Image Diffusion Models", "authors": "Zhe Dong,Yuzhe Sun,Tianzhu Liu,Yanfeng Gu", "background": "遥感图像分割（RRSIS）技术通过自然语言描述精确划分遥感图像中的区域，适用于灾害响应、城市规划和环境监测等关键应用。然而，当前的方法在处理具有视角、尺度和语义复杂性等特征的空中图像时面临重大挑战。", "innovation": "提出了一种名为DiffRIS的新框架，利用预训练的文本到图像扩散模型增强多模态对齐。该框架包括两个关键创新：动态通过全球语境建模和对象感知推理细化语言特征的上下文感知适配器（CP-adapter），以及通过多尺度特征交互逐步对语言描述和视觉区域进行对齐的渐进多模态推理解码器（PCMRD）。上下文感知适配器弥合了一般视觉语言理解和遥感应用之间的领域差距，而渐进多模态推理解码器在多个尺度上实现精细的语义对齐。", "conclusion": "在RRSIS-D、RefSegRS和RISBench基准数据集上的全面实验表明，DiffRIS在所有标准指标上优于现有方法，建立了RRSIS任务的新最先进的技术水平。这证实了通过提出的自适应框架利用预训练扩散模型应用于遥感应用的有效性。"}
{"llm_update_time": "2025-06-25 09:19:30", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19065", "html_url": "https://arxiv.org/abs/2506.19065", "title": "LEGATO：大规模端到端通用方法用于版面乐谱识别", "title_en": "LEGATO: Large-scale End-to-end Generalizable Approach to Typeset OMR", "authors": "Guang Yang,Victoria Ebert,Nazif Tamer,Luiza Pozzobon,Noah A. Smith", "background": "目前，光学音乐识别（OMR）领域缺乏标准化的评价方法，同时现有的OIR模型在处理完整页或跨页乐谱时能力有限，无法生成简明、易读的符号音乐表示（如ABC格式）。", "innovation": "提出了一种新的端到端Transformer模型Legato，这是第一个大规模预训练的OMR模型，能够识别完整的或跨页乐谱，并首次生成ABC格式文档。通过结合预训练的视觉编码器和在超过214,000张图片数据集上训练的ABC解码器，模型具有较强的泛化能力。", "conclusion": "实验结果显示Legato模型在多个数据集上达到了最先进的性能。尽管缺乏端到端OMR的标准化评价方法，但Legato使用多种多样化的指标与之前最先进的模型进行了全面比较。"}
{"llm_update_time": "2025-06-25 09:19:30", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18985", "html_url": "https://arxiv.org/abs/2506.18985", "title": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs", "title_en": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs", "authors": "Guanxi Shen", "background": "近年来，大型视觉语言模型（LVLMs）在从视觉输入生成连贯文本回应方面展现了前所未有的能力。然而，在生成自由形式文本回应的同时，理解LVLMs是如何在视觉注意力方面定向的，仍然是一个重大的挑战，这对于理解模型行为、诊断幻觉、揭示偏见和确保透明度至关重要。GLIMPSE框架应运而生，旨在通过渐变加权注意力、自适应层传播和加权标记聚合，帮助揭示生成型LVLMs在开放性视觉问答（VQA）过程中依赖的显著图像区域，同时揭示跨模态文本的显著性，这些技术为跨模态推理提供了一种全面的解释热图，比之前的方法更加符合人类的认知方式，从而揭示了细粒度的分析结果。GLIMPSE框架通过分析表明，它可以追踪标记级别推理动态，揭示系统性的人类注意力错位、幻觉和偏见问题，从而提高生成型LVLMs的可解释性。", "innovation": "GLIMPSE框架是一个轻量级、模型无关的视觉解释框架，它通过融合梯度加权注意力、自适应层传播和加权标记聚合，生成全面的响应级归属热图，从而帮助解释跨模态推理过程，这种解释方式在人类一致性方面优于现有的解释方法。GLIMPSE框架的独特之处在于其能够揭示生成型LVLMs在开放性视觉问答过程中依赖的显著图像区域，同时揭示跨模态文本的显著性，从而提高模型的透明度和可信度。", "conclusion": "GLIMPSE框架通过分析展示了生成型LVLMs的跨模态属性分配，追踪标记级别推理动态，并分析系统性的人类注意力错位、幻觉和偏见，为生成型LVLMs的可解释性和透明性提供了新的分析方法。"}
{"llm_update_time": "2025-06-25 09:19:31", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19072", "html_url": "https://arxiv.org/abs/2506.19072", "title": "HAWAII: 分级视觉知识转移以构建高效视觉语言模型", "title_en": "HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models", "authors": "Yimu Wang,Mozhgan Nasr Azadani,Sean Sedwards,Krzysztof Czarnecki", "background": "提升视觉语言模型(VLMs)的视觉理解能力对于提高其在各种任务中的性能至关重要。虽然利用多个预训练视觉专家显示出很大的前景，但在训练和推理过程中会带来显著的计算成本。为了应对这一挑战，我们提出了HAWAII，一种新型框架，通过将多个视觉专家的知识凝练到单一视觉编码器中，使其具备多个专家的互补优势，同时保持较低的计算开销。为了解决不同教师之间的知识冲突并实现知识切换，我们提出了一种针对每个特定教师的低秩适应(LoRA)适配器，而不是使用固定的一组适配器。", "innovation": "我们提出了教师特定的低秩适应(LoRA)适配器与相应的路由器，以更加精准地实现知识凝练。我们提出了细粒度和粗粒度的知识凝练方法。在细粒度层面，利用令牌重要性评分来强调每个教师的最有信息量的令牌。在粗粒度层面，我们汇总多个教师的知识并通过通用知识LoRA适配器与路由器将其传输给学生。实验证明，相比于流行的开源视觉语言模型，HAWAII具有显著优势。", "conclusion": "我们在各种视觉语言任务上的广泛实验表明HAWAII的优越性，相比流行的开源视觉语言模型具有明显的优势。"}
{"llm_update_time": "2025-06-25 09:19:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19079", "html_url": "https://arxiv.org/abs/2506.19079", "title": "基础模型中的代理偏见：面向面部情绪识别的基础模型分析", "title_en": "Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition", "authors": "Iosif Tsangko,Andreas Triantafyllopoulos,Adem Abdelmoula,Adria Mallol-Ragolta,Bjoern W. Schuller", "background": "基础模型（FMs）正在迅速变革情感计算（AC），视觉语言模型（VLMs）现在能够在零样本设置中识别情绪。本文探讨了一个关键且未充分研究的问题：这些模型在推断情绪时依赖于哪些视觉线索，这些线索是否具有心理基础或只是表面学习的结果？研究人员基于带有牙齿注释的AffectNet子集对不同规模的VLMs进行了评估，并发现其性能随着可见牙齿的存在与否而波动。研究人员通过对表现最佳的模型进行结构化反思，发现眉毛的位置等面部特征极大地驱动了其情绪推理能力，展现出高度的一致性，特别是在情感的正负值和兴奋度预测方面。这些模式揭示了基础模型行为的兴起，但也暴露出了一种风险：捷径学习、偏见和公平性问题，特别是在心理健康和教育等敏感领域中更加明显.", "innovation": "本文通过使用带有牙齿注释的AffectNet子集评估了不同规模的视觉语言模型，并发现模型在识别情绪时对视觉线索的依赖性，以及这些线索是否具有心理基础。通过结构化的模型反省，揭示了面部特征在其情绪推理中的核心作用，并强调了这些模型行为的复杂性和风险，如捷径学习、偏见和公平性问题等.", "conclusion": "基础模型的行为显示出一种兴起的性质，但也揭示了风险：捷径学习、偏见和公平性问题，特别是在敏感领域如心理健康和教育。"}
{"llm_update_time": "2025-06-25 09:19:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19022", "html_url": "https://arxiv.org/abs/2506.19022", "title": "用于持续测试时间适应的正交投影子空间在线聚合先验知识", "title_en": "Orthogonal Projection Subspace to Aggregate Online Prior-knowledge for Continual Test-time Adaptation", "authors": "Jinlong Li,Dong Zhao,Qi Zang,Zequn Jie,Lin Ma,Nicu Sebe", "background": "持续测试时间适应（CTTA）是一个需要源预训练模型不断适应新场景并适应目标分布变化的任务。现有的CTTA方法主要关注解决灾难性遗忘和错误累积的问题。尽管有一些基于参数高效微调的遗忘适应方法出现，但在复杂任务如语义分割中仍然难以平衡性能和模型适配效率之间的关系。", "innovation": "本文提出了一种新的管道——正交投影子空间来聚合在线先验知识，简称OoPk。具体来说，首先正交投影调优子空间，使模型能够适应新的领域，同时保留预训练源模型的知识完整性以减轻灾难性遗忘。然后，采用一种激进而高效的图像遮罩策略实现在线先验知识聚合，模拟潜在的目标动态，增强学生模型的领域适应性。这进一步逐渐优化教师模型的知识，确保高质量的伪标签并降低错误累积。", "conclusion": "通过广泛的实验证明，该方法在语义分割任务的各种持续TTA基准上超过了之前的方法，并实现了竞争力的性能。"}
{"llm_update_time": "2025-06-25 09:19:33", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18999", "html_url": "https://arxiv.org/abs/2506.18999", "title": "扩散变换器到Mamba的蒸馏方法用于高分辨率图像生成", "title_en": "Diffusion Transformer-to-Mamba Distillation for High-Resolution Image Generation", "authors": "Yuan Yao,Yicong Hong,Difan Liu,Long Mai,Feng Liu,Jiebo Luo", "background": "自注意力机制在扩散变换器(DiT)中的计算复杂性较高，导致高分辨率图像生成的成本较大。提出具有线性复杂度的Mamba模型作为一种潜在替代方案，但直接训练Mamba依然具有经验上的挑战性。本文针对这一问题，提出扩散变换器到Mamba的蒸馏方法(T2MD)，形成一种高效训练框架，使得基于自注意力机制的变换器更易于过渡到具有线性复杂度的Mamba模型状态空间模型。文中还引入了一种混合模型，旨在实现效率和全局依赖的平衡。", "innovation": "提出了扩散变换器到Mamba的蒸馏方法(T2MD)，通过图层级的教师强迫和基于特征的知识蒸馏，简化了从自注意力机制的变换器向Mamba模型的过渡。该方法能够从512×512分辨率的基模型开始，通过轻量化适应和高分辨率微调下推至2048×2048的图像生成。实验表明，该训练路径在低开销的情况下还能实现高质量的图文生成。此外，文中还展示了基于顺序和因果Mamba模型生成非因果视觉输出的可能性，为未来研究提供了可能的方向。", "conclusion": "本文提出的训练路径导致了低开销但高质量的文本到图像的生成。此外，它还表明使用顺序和因果Mamba模型生成非因果视觉输出的可行性，为未来的探索提供了可能。"}
{"llm_update_time": "2025-06-25 09:19:37", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19087", "html_url": "https://arxiv.org/abs/2506.19087", "title": "RareSpot: 使用多尺度一致性和上下文感知数据增强技术在航空影像中检测小且稀有的野生动物", "title_en": "RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation", "authors": "Bowen Zhang,Jesse T. Boulerice,Nikhil Kuniyil,Charvi Mendiratta,Satish Kumar,Hila Shamon,B.S. Manjunath", "background": "在航空影像中自动检测小且稀有的野生动物对于有效的保护工作至关重要，但仍然是一个重大的技术挑战。以黑尾草原犬鼠为例，它们的重要性作为关键物种与它们稀疏分布和难以捕捉的特征形成了鲜明对比。现有的检测方法难以应对这些挑战，因此需要开发新的技术来改进检测准确性和可靠性。", "innovation": "本文提出了名为RareSpot的检测框架，核心创新在于结合多尺度一致性学习和上下文感知增强。多尺度一致性方法通过在特征金字塔上进行结构化对齐，增强了物体的细微特征表示，并减少了由于尺度问题导致的特征丢失。上下文感知增强通过在现实环境中合成难以检测的样本来训练模型，显著增强了检测精度和召回率。这种新型框架在黑尾草原犬鼠无人机影像数据集上达到了最先进的性能，相比基线方法提高了检测准确率35%以上，并且具有良好的跨数据集泛化能力。这种方法不仅支持生态监测，还为以后小且稀有物种的检测奠定了新的基础。", "conclusion": "RareSpot不仅在黑尾草原犬鼠无人机影像数据集上表现优异，还成功应用于其他野生动物数据集，证明了其在复杂航空场景中对于检测小且稀有物种的有效性和广泛适用性。该方法为生物多样性保护提供了强有力的技术支持。"}
{"llm_update_time": "2025-06-25 09:19:38", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19103", "html_url": "https://arxiv.org/abs/2506.19103", "title": "Inverse-and-Edit：通过循环一致性模型实现有效且快速的图像编辑", "title_en": "Inverse-and-Edit: Effective and Fast Image Editing by Cycle Consistency Models", "authors": "Ilia Beletskii,Andrey Kuznetsov,Aibek Alanov", "background": "近期，使用扩散模型进行图像编辑的方法已取得了显著成果，提供了对生成过程的精细控制。然而，这些方法因迭代性质的原因而在计算上非常密集。尽管精简的扩散模型能够加快推理速度，但其编辑能力仍然有限，主要归因于较差的反向转换质量。高保真度的反向转换和重建是实现精确图像编辑的关键，因为这能够保留源图像的结构和语义完整性。尽管如此，现有方法在编辑方式和内容保留之间难以平衡，且往往计算效率不高，无法达到最先进的扩散模型的效果", "innovation": "本文提出了一种新颖框架，利用一致性模型增强图像反向转换，仅需四步即可实现高质量编辑。该方法引入了一致性循环优化策略，显著提高了重建精度，并能可控地在编辑能力和内容保真之间进行权衡。实验结果展示了该方法在多个图像编辑任务和数据集上的卓越性能，证明其在提供与逐步扩散模型相当甚至更佳的效果的同时，显著提高了计算效率", "conclusion": "我们的方法在各种图像编辑任务中达到了最先进的性能，并且在具备与完整步骤扩散模型相似或超越的效果的基础上，计算效率大大提高。我们已将该方法的代码发布在GitHub上。"}
{"llm_update_time": "2025-06-25 09:19:38", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19117", "html_url": "https://arxiv.org/abs/2506.19117", "title": "PrITTI: 基于普适体素的可控和可编辑的3D语义场景生成", "title_en": "PrITTI: Primitive-based Generation of Controllable and Editable 3D Semantic Scenes", "authors": "Christina Ourania Tze,Daniel Dauner,Yiyi Liao,Dzmitry Tsishkou,Andreas Geiger", "background": "大型3D语义场景生成主要依赖于体素表示。这类表示占用大量内存、固定分辨率且难以编辑。相比之下，使用紧凑且粗略的3D结构的普适体素表示方法更为容易操作和组合，适合构建3D语义场景布局。由于传统编码方法存在方向性模糊问题，本研究提出了一种基于普适体素的框架PrITTI，利用PrITTI生成可组合、可控和可编辑的3D语义场景布局。该方法采用了混合表示，地面表面使用栅格化格式建模，而对象则作为向量化3D普适体素编码。这种分解也反映在一种结构化的潜在表示形式中，允许灵活地操作地面和对象组件。为了克服传统编码方法中的方向性模糊问题，引入了一种稳定的Cholesky基参数化方法，可以同时编码对象大小和方向。实验结果表明，PrITTI在生成质量上优于体素基线，同时减少内存消耗最多可达3倍。此外，PrITTI还支持直接对场景中的实例级别进行操作，并适用于多种下游应用，如场景填补、扩展及写实街景合成。", "innovation": "提出了PrITTI，一种基于普适体素的框架，通过引入一种稳定且可容许的Cholesky基参数化方法，实现了对象大小和方向的同时编码，从而生成了更高质量、更易于编辑和操作的3D语义场景。", "conclusion": "实验结果验证了PrITTI在生成质量和内存消耗方面优于传统体素表示方法。PrITTI不仅能够直接操作场景中的对象实例，还能够支持多种下游应用。"}
{"llm_update_time": "2025-06-25 09:19:41", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18943", "html_url": "https://arxiv.org/abs/2506.18943", "title": "从像素和词语到波浪：统一的频谱字典vLLMs框架", "title_en": "From Pixels and Words to Waves: A Unified Framework for Spectral Dictionary vLLMs", "authors": "Andrew Kiruluta,Priscilla Burity", "background": "现有最先进的视觉语言模型（VLMs）依赖于两种计算密集的组件：视觉编码器中的卷积以及多模态融合中的二次自我注意。这些组件增加了模型的复杂性和计算成本。本文旨在通过引入谱字典令牌混音器来解决这些计算密集问题，该混音器将每个图像块或子词表示为可学习频率原子的稀疏组合。", "innovation": "本文提出了谱字典令牌混音器，这是一种新的方法，将每个图像块或子词表示为可学习频率原子的稀疏组合，从而消除了视觉编码器中的卷积和多模态融合中的二次自我注意。使用这个1.1亿参数的原型模型SDict-VLM，在MS-COCO图 captioning 任务上取得了BLEU-4 39.2、CIDEr 127.5和SPICE 27.0的结果，在VQAv2上的准确性达到了50.3%。SDict-VLM在参数量、峰值GPU内存和推理速度上均优于其他模型，同时仍保持与中型变压器基线相当的性能。", "conclusion": "这种频谱字典令牌混音器不仅为视觉语言模型提供了一种较少计算复杂性的解决方案，还在保持高性能的同时消除了卷积和自我注意。这种方法在跨模态透明对齐和可调的精度与计算之间的权衡方面显示出潜力，为高效且可解释的视觉语言模型铺平了道路。"}
{"llm_update_time": "2025-06-25 09:19:41", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19174", "html_url": "https://arxiv.org/abs/2506.19174", "title": "MOSCARD -- 基于因果推理和去混杂的多模态机会性心血管不良事件筛查", "title_en": "MOSCARD -- Causal Reasoning and De-confounding for Multimodal Opportunistic Screening of Cardiovascular Adverse Events", "authors": "Jialu Pi,Juan Maria Farina,Rimita Lahiri,Jiwoong Jeong,Archana Gurudu,Hyung-Bok Park,Chieh-Ju Chao,Chadi Ayoub,Reza Arsanjani,Imon Banerjee", "background": "全球疾病负担研究2021年报告显示，主要不良心血管事件（MACE）仍然是导致死亡的主要原因之一。多模态数据可以在常规健康检查中识别高风险个体方面发挥关键作用。胸部X光（CXR）和12导联心电图（ECG）提供对导致MACE的慢性疾病的洞察和心脏电活动及结构异常的直接评估。将CXR和ECG结合使用可以提供比仅依赖临床评分、计算机断层扫描测量或生物标志物的常规模型更全面的风险评估，后者可能受限于采样偏差和单一模态限制。本文旨在开发一种新的预测建模框架MOSCARD，以解决多模态机会性心血管不良事件筛查中存在的问题，包括模态间对齐、因果推理以及解混杂方法等技术贡献。", "innovation": "MOSCARD框架的主要技术贡献包括：（i）CXR与ECG指导下的多模态对齐；（ii）因果推理的整合；（iii）双反向传播图以去混杂。\n该模型在内部和外部数据集上表现出色，AUC值分别为0.75、0.83和0.71，超过了单模态和最先进的基础模型。\n", "conclusion": "提出的成本效益高、机会性筛查方法旨在早期干预，从而改善患者结果并减少不平等现象。"}
{"llm_update_time": "2025-06-25 09:19:41", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19154", "html_url": "https://arxiv.org/abs/2506.19154", "title": "基于Mobile Vision Transformers的轻量化RGB-T跟踪", "title_en": "Lightweight RGB-T Tracking with Mobile Vision Transformers", "authors": "Mahdi Falaki,Maria A. Amer", "background": "单模态目标跟踪（如纯RGB）在低光照和恶劣天气等复杂成像条件下面临困难。为解决此问题，多模态跟踪（如RGB-T模型）旨在利用如热红外特征等互补数据。虽然基于Vision Transformer的多模态跟踪算法表现出色，但由于模型规模较大，通常计算成本昂贵。本文背景即基于此挑战展开的研究背景", "innovation": "提出了一种基于Mobile Vision Transformers的新型轻量化RGB-T跟踪算法，引入了一种渐进融合框架，通过可分离注意力机制联合学习模板区域和搜索区域内的模内和模间交互，从而生成有效的特征表示，支持更准确的目标定位，同时实现小型模型尺寸和快速推理速度。该模型相比最先进的高效多模态跟踪器，在参数量显著减少（少于400万）的前提下，达到了最快的GPU推理速度（每秒122帧），这是首次提出使用Mobile Vision Transformers的RGB-T跟踪算法和大规模多模态跟踪", "conclusion": "实验表明，该模型在准确性和推理速度上都达到了优秀的表现，与现有先进模型相比，在参数量减少的同时，实现了更快的推理速度。该工作为RGB-T跟踪和大规模多模态跟踪提供了新的思路，并将模型代码和权重在接收后公开以供进一步研究和应用"}
{"llm_update_time": "2025-06-25 09:19:42", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19168", "html_url": "https://arxiv.org/abs/2506.19168", "title": "PRISM: 基于感知识别的人本关键帧提取中的关键帧识别", "title_en": "PRISM: Perceptual Recognition for Identifying Standout Moments in Human-Centric Keyframe Extraction", "authors": "Mert Can Cakmak,Nitin Agarwal,Diwash Poudel", "background": "在线视频在塑造政治话语和放大诸如错误信息、宣传和极端化这样的网络社会威胁中发挥着核心作用。识别视频内容中最具有影响力的‘突出’时刻对于内容管理、摘要和法医分析至关重要。尽管有许多方法，但PRISM提供了一种轻量级且与感知相匹配的框架，以关键帧提取为目标，能够在CIELAB色彩空间中运行，并利用感知色彩差异度量识别与人类视觉敏感性相一致的帧。", "innovation": "PRISM是一种合理的、无需训练且计算效率高的轻量级框架，可以在实时和资源受限环境中用于关键帧提取。不同于基于深度学习的方法，PRISM具有可解释性，能够在保留高压缩比的同时实现强准确性和保真度。实验结果表明，PRISM适用于结构化和非结构化视频内容，在线平台上分析和管理有害或政治敏感媒体具有潜力及可扩展性。", "conclusion": "PRISM展示了在结构化和非结构化视频内容上的有效性，并为其广泛应用于在线平台中分析和管理有害或政治敏感媒体提供了可扩展工具的前景。"}
{"llm_update_time": "2025-06-25 09:19:43", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19204", "html_url": "https://arxiv.org/abs/2506.19204", "title": "OpenWildlife：面向地理多样空中影像的开放式词汇多物种野生动物检测器", "title_en": "OpenWildlife: Open-Vocabulary Multi-Species Wildlife Detector for Geographically-Diverse Aerial Imagery", "authors": "Muhammed Patel,Javier Noa Turnes,Jayden Hsiao,Linlin Xu,David Clausi", "background": "当前的自动化方法在特定环境中表现良好，但在跨物种和不同环境的场景下却难以泛化，这是由于现有方法在分类覆盖范围和模型架构的局限性。因此，亟需一个能够在不同环境中识别多种物种并支持自然语言输入的开放词汇检测器。", "innovation": "OpenWildlife (OW) 利用了语言感知嵌入和对 Grounding-DINO 框架的创新改编，能够通过自然语言输入识别多种物种，覆盖陆地和海洋环境。OW 在 15 个数据集上接受训练，表现出色，在某些数据集上 mAP50 评分达到 0.981，对于具有新物种的数据集，mAP50 评分为 0.597。此外，OW 还引入了一种有效搜索算法，结合 k-最近邻和广度优先搜索方法，专注于社交物种可能出现的区域，实现了 95% 的物种覆盖率，同时只探索了 33% 的影像数据。这些特性使 OW 成为全球生物多样性评估的灵活且经济高效的解决方案。", "conclusion": "OpenWildlife (OW) 为识别多样环境中的多种物种提供了一种灵活且成本效益高的方法，通过提供开源代码和数据集分割，支持未来的任何改进和应用。"}
{"llm_update_time": "2025-06-25 09:19:44", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19217", "html_url": "https://arxiv.org/abs/2506.19217", "title": "MedErr-CT：用于识别和纠正CT报告错误的视觉问题回答基准", "title_en": "MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports", "authors": "Sunggu Kyung,Hyungbin Park,Jinyoung Seo,Jimin Sung,Jihyun Kim,Dongyeong Kim,Wooyoung Jo,Yoojin Nam,Sangah Park,Taehee Kwon,Sang Min Lee,Namkug Kim", "background": "计算机断层扫描（CT）在临床诊断中起着关键作用，但CT检查的需求增长引发了对诊断错误的担忧。尽管多模态大语言模型（MLLMs）展示了对医学知识的良好理解，但它们产生不准确信息的倾向突显了严谨验证的必要性。然而，现有的医学视觉问答（VQA）基准主要集中在简单的视觉识别任务上，缺乏临床相关性，未能评估专家级别的知识。", "innovation": "该研究引入了MedErr-CT，这是一个新颖的基准，用于评估医学MLLMs识别和纠正CT报告错误的能力。MedErr-CT包含了六类错误——四类视觉中心错误（遗漏、插入、方向、大小）和两类词法错误（单位、拼写错误），并组织成三个任务级别：分类、检测和纠正。通过这一基准，我们定量评估了最先进的3D医学MLLMs的表现，揭示了它们在不同错误类型上的能力差异。MedErr-CT的研究成果有助于开发更可靠和临床相关的MLLMs，最终有助于减少诊断错误并提高临床实践的准确性。", "conclusion": "我们的基准有助于开发更可靠和临床相关的MLLMs，最终有助于减少诊断错误并提高临床实践的准确性。研究提供的代码和数据集可以通过链接访问。"}
{"llm_update_time": "2025-06-25 09:19:46", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19225", "html_url": "https://arxiv.org/abs/2506.19225", "title": "Video-XL-2：通过任务感知的KV稀疏化实现超长视频理解", "title_en": "Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification", "authors": "Minghao Qin,Xiangrui Liu,Zhengyang Liang,Yan Shu,Huaying Yuan,Juenjie Zhou,Shitao Xiao,Bo Zhao,Zheng Liu", "background": "多模态大语言模型（MLLMs）在过去几年中在视频理解方面取得了显著进展，但处理长视频输入仍然面临高昂的内存和计算成本挑战。这使得当前模型难以同时实现良好的性能和高效率的长视频理解.", "innovation": "提出了一种名为Video-XL-2的新颖MLLM，基于任务感知的KV稀疏化实现长视频理解的高性价比。该框架包括两个关键步骤：基于块的预填充和双层键值解码。此方法显著减少了计算和内存开销，并在此基础上进一步提高了内存效率，增强了模型捕捉细粒度信息的能力.", "conclusion": "Video-XL-2在各种长视频理解基准测试中达到了最先进的性能，超越了现有的开源轻量级模型。它还展示了出色的效率，能够在单个NVIDIA A100 (80GB) GPU上处理超过10,000帧，且在几秒钟内处理数千帧."}
{"llm_update_time": "2025-06-25 09:19:47", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19208", "html_url": "https://arxiv.org/abs/2506.19208", "title": "古代文字图像识别与处理：综述", "title_en": "Ancient Script Image Recognition and Processing: A Review", "authors": "Xiaolei Diao,Rite Bo,Yanling Xiao,Lida Shi,Zhihan Zhou,Hao Xu,Chuntao Li,Xiongfeng Tang,Massimo Poesio,Cédric M. John,Daqian Shi", "background": "古代文字，例如埃及象形文字、甲骨文以及古希腊铭文，是人类文明的重要载体，蕴含了宝贵的历史和文化信息。自动化的古代文字图像识别变得尤为重要，这有助于大规模解读和推动考古学与数码人文领域的研究进展。随着深度学习技术的发展，这一领域取得了快速进展，许多针对特定文字的数据集和模型相继提出。尽管古代文字种类繁多，从表音系统到包含数千种复杂符号的表意系统，但它们都面临着共同的挑战和方法上的重叠。特别是，古代文字面临着数据分布不平衡和图像退化等独特挑战，这些挑战推动了各种专门方法的发展。本综述旨在全面回顾古代文字图像识别的方法。本文首先基于文字类型对现有研究进行分类，并分析相应的识别方法，突出它们之间的差异和共通策略。接着，本文重点关注古代文字面临的独特挑战，系统地探讨它们的影响，并回顾近期提出的解决方案，包括少样本学习和抗噪声技术。最后，总结当前的局限性并展望未来的研究方向，旨在为古代文字的识别、解读和解译提供一个结构化的前瞻性视角，支持这一领域的持续发展。", "innovation": "本文提供了一个全面的古代文字图像识别方法的回顾，分类研究的类型，分析各自的识别方法，突出差异和共通策略。系统地探讨古代文字面临的独特挑战，批判地回顾了近期的解决方案，包括少样本学习和抗噪声技术，并展望未来的研究方向，为这个领域的持续发展提供了前瞻性的视角。", "conclusion": "本文总结了当前的局限性，提出了一系列有潜力的未来发展方向，为古代文字图像识别、解读和解译提供了丰富的信息和结构化的视角，支持着这个领域不断进步。"}
{"llm_update_time": "2025-06-25 09:19:48", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19267", "html_url": "https://arxiv.org/abs/2506.19267", "title": "自适应的协作与对抗网络在无监督领域适应中的自我加速度学习", "title_en": "Self-Paced Collaborative and Adversarial Network for Unsupervised Domain Adaptation", "authors": "Weichen Zhang,Dong Xu,Wanli Ouyang,Wen Li", "background": "研究领域中，无监督领域适应方法在目标识别和视频行为识别等任务中具有重要作用。现有方法虽然取得了显著进展，但优化领域特异性特征表示和领域不变特征表示仍存在挑战。因此，本文提出一种新的无监督领域适应方法，即协作和对抗网络（CAN），以解决这个问题。", "innovation": "本文创新性地将领域协作学习和领域对抗学习策略统一地表示为带正负权重的领域分类器学习。同时，设计了一种协作和对抗训练方案，利用协作学习从CNN低层学习领域特异性表示，使用对抗学习从高层提取领域不变表示。进一步地，提出了一种自我加速度CAN（SPCAN），通过逐步选择伪标签目标样本进行重新训练分类器，以增强目标领域的判别性。", "conclusion": "在不同基准数据集（如Office-31、ImageCLEF-DA、VISDA-2017、UCF101-10和HMDB51-10）上的广泛实验表明，所提出的方法能够实现无监督领域适应的最佳性能，充分展示了新提出策略的有效性。"}
{"llm_update_time": "2025-06-25 09:19:51", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19261", "html_url": "https://arxiv.org/abs/2506.19261", "title": "Automated Image Recognition Framework", "title_en": "Automated Image Recognition Framework", "authors": "Quang-Binh Nguyen,Trong-Vu Hoang,Ngoc-Do Tran,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le", "background": "尽管深度学习模型的效果高度依赖于数据，但是针对特定任务收集和标注数据，尤其是在处理新的或敏感的主题时，缺乏相关的数据集，这会带来巨大的时间和资源挑战。因此，本文提出了一种名为Automated Image Recognition (AIR)的新型框架，该框架利用生成式人工智能的强大功能，旨在解决这些问题。", "innovation": "本文提出了一个名为AIR的框架，该框架利用生成式人工智能的强大力量，旨在自动合成高质量、预先标注的数据集，并自动训练深度学习模型，从而实现强大的图像识别性能。该框架包括两个主要的数据生成过程：AIR-Gen和AIR-Aug。AIR-Gen允许用户生成符合其特定需求的数据集。我们引入了一种新的自动提示工程模块，利用大型语言模型的能力来提高图像质量。此外，还引入了一种分布调整算法，以消除重复和异常值，增强生成数据集的稳定性和可靠性。AIR-Aug则在现有数据集的基础上进行增强，特别适用于用户拥有较少数据的情况。", "conclusion": "通过全面的实验，我们证明了生成的数据集能够有效地训练深度学习模型，并展示了该系统在提供各种物体图像识别模型方面的潜力。我们还进行了一项用户研究，获得4.4/5.0的高分，证明了AI社区对AIR的积极认可。"}
{"llm_update_time": "2025-06-25 09:19:51", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19263", "html_url": "https://arxiv.org/abs/2506.19263", "title": "3D-SSM: A Novel 3D Selective Scan Module for Remote Sensing Change Detection", "title_en": "3D-SSM: A Novel 3D Selective Scan Module for Remote Sensing Change Detection", "authors": "Rui Huang,Jincheng Zeng,Sen Gao,Yan Xing", "background": "现有的基于Mamba的方法在遥感变化检测方面已经提高了扫描模型，但仍然受限于它们不能有效捕捉图像通道之间的长范围依赖性，这限制了它们的特征表示能力。", "innovation": "为了解决这一局限，本文提出了一种3D选择性扫描模块（3D-SSM），能够从空间平面和通道视角捕捉全局信息，从而提供对遥感变化检测对象更全面的理解。在此基础上，提出了两个关键组件：时空交互模块（SIM）和多分支特征提取模块（MBFEM）。SIM通过在不同时间点的图像之间实现全局与局部特征的交互，增强了细微变化的检测能力。MBFEM结合时频域、空间域和3D-SSM的特征，提供图像内部丰富的上下文信息表示。该方法在五个基准数据集上的大量实验中，展现了优于最先进的变化检测方法的表现。", "conclusion": "所提出的方法在五个基准数据集上取得了优越的性能，相比最先进的变化检测方法表现出色。代码可以在给定的链接中获取。"}
{"llm_update_time": "2025-06-25 09:19:52", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19283", "html_url": "https://arxiv.org/abs/2506.19283", "title": "AirV2X: 统一的空中-地面车辆到一切协同合作", "title_en": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration", "authors": "Xiangbo Gao,Yuheng Wu,Xuewen Luo,Keshu Wu,Xinghao Chen,Yuping Wang,Chenxi Liu,Yang Zhou,Zhengzhong Tu", "background": "多车协同驾驶相比于单一车辆自主驾驶具备显著优点，但传统的基础设施型V2X系统仍然受限于高昂的部署成本，并在农村和郊区等区域留下了“未覆盖危险区域”。", "innovation": "提出了AirV2X-Perception数据集，利用无人机（UAVs）作为固定道路侧单元（RSUs）的灵活替代品或补充。与基于地面的感知相比，无人机提供了独特的优势，如减少遮挡的鸟瞰视角、动态定位能力实现悬停、巡逻和护航规则，以及相较于固定基础设施，显著降低部署成本。该数据集涵盖了各种城市、郊区和农村环境下的车-无人机（V2D）驾驶场景，且提供了多样化的天气和光线条件。该数据集有助于V2D算法的研究与标准化评估，填补了快速发展的空中协助自动驾驶系统领域的关键空白。", "conclusion": "该数据集和开发工具包已开源，为其他研究者提供了一个重要的资源来推进自动驾驶领域的进展。"}
{"llm_update_time": "2025-06-25 09:19:53", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19257", "html_url": "https://arxiv.org/abs/2506.19257", "title": "MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models", "title_en": "MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models", "authors": "Yinan Xia,Yilei Jiang,Yingshui Tan,Xiaoyong Zhu,Xiangyu Yue,Bo Zheng", "background": "视觉-语言模型（VLMs）通过增强的链式思考能力，在多模态推理任务中取得了显著进展。然而，这一进展也带来了新的安全风险，因为这些模型变得越来越容易受到有害多模态提示的攻击，这些提示可能会触发不道德或不安全的行为。现有的安全性对齐方法，主要是为单模态语言模型设计的，对于多模态输入复杂且微妙所带来的威胁还不能有效应对。此外，目前的安全数据集缺乏精细的、基于政策的推理，无法对具备推理能力的多模态视觉-语言模型进行健壮的安全对齐。因此，本文提出了MSR-Align，一个高质量的多模态安全推理数据集，旨在填补这一空白。此数据集支持在视觉和文本模态下进行精确、审慎的基于政策的推理。", "innovation": "本文提出了MSR-Align，一个高质量的数据集，专门用于提升视觉-语言模型在面对复杂多模态输入时的安全性。MSR-Align强调多模态多样性、基于政策的推理以及严格的质量筛选，使用强大的多模态评委进行评估。实验结果表明，对VLMs进行MSR-Align的微调，可以显著提高其对于文本和视觉-语言监狱突破攻击的鲁棒性，同时保持或提高一般推理性能。MSR-Align为推进具备推理能力的视觉-语言模型的安全性对齐提供了可扩展且有效的基础。", "conclusion": "MSR-Align为视觉-语言模型的安全性对齐提供了一个新的数据集，该数据集能够支持细致、基于政策的推理，从而提升模型面对复杂威胁时的安全性，同时保持或增强其一般推理能力。该数据集已公开发布，被称为MSR-Align，可以用于提升多模态视觉-语言模型的安全性能。"}
{"llm_update_time": "2025-06-25 09:19:54", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19300", "html_url": "https://arxiv.org/abs/2506.19300", "title": "使用级联视觉语言模型的开放式词汇伪装目标分割", "title_en": "Open-Vocabulary Camouflaged Object Segmentation with Cascaded Vision Language Models", "authors": "Kai Zhao,Wubang Yuan,Zheng Wang,Guanyi Li,Xiaoqiang Zhu,Deng-ping Fan,Dan Zeng", "background": "该论文讨论了伪装目标分割（OVCOS）的挑战，即从任意类别中分割和分类伪装目标。传统的双阶段方法首先分割物体，然后使用视觉语言模型（VLMs）对分割区域进行分类，但存在两个主要问题：一是区域分割和全局图像训练之间的领域差距；二是适用于清晰边界物体的标准分割模型对于伪装目标的分割不够有效。因此，这类方法往往难以准确识别和分类伪装目标中的细节边界，导致分类不够准确。\r\n", "innovation": "本文引入了一个新颖的由视觉语言模型引导的级联框架来解决这些问题。首先，利用Segment Anything Model（SAM）进行对象分割，并使用由视觉语言模型提取的特征作为明示提示，有效引导SAM关注伪装区域，显著提高定位精度。然后，将分割输出的alpha通道视为软空间先验，保留了图像的整体上下文，同时提供精确的空间引导，从而实现伪装目标的更准确和上下文相关的分类。整个框架中共享同一个视觉语言模型，以确保效率和语义一致性。\r\n", "conclusion": "在OVCOS和传统伪装目标分割基准上的实验表明，该方法有明显的优势，证明了利用丰富的视觉语言模型语义进行伪装目标分割和分类的有效性。"}
{"llm_update_time": "2025-06-25 09:19:54", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19291", "html_url": "https://arxiv.org/abs/2506.19291", "title": "HoliGS: Holistic Gaussian Splatting for Embodied View Synthesis", "title_en": "HoliGS: Holistic Gaussian Splatting for Embodied View Synthesis", "authors": "Xiaoyuan Wang,Yizhou Zhao,Botao Ye,Xiaojun Shan,Weijie Lyu,Lu Qi,Kelvin C.K. Chan,Yinxiao Li,Ming-Hsuan Yang", "background": "过去的4D高斯切片和动态NeRF管道在处理分钟级时间跨度的单目RGB视频时面临训练开销的问题，难以高效重构大尺度动态环境。该项目背景在于寻找一种高效解决单目RGB视频中大尺度动态环境的体视合成问题的新方法。", "innovation": "本文提出了一种新颖的可变形高斯切片框架HoliGS，通过可逆高斯切片变形网络实现了对大规模动态环境的准确重建。方法将每个场景分解为静态背景和随时间变化的对象，每个对象由学习到的全局刚性变换、骨骼驱动的关节动作以及细微的非刚性变形构成，通过可逆神经流实现层级变形，从而能够从各种体视相机轨迹中实现稳健的自由视点新视角渲染。", "conclusion": "实验结果表明，HoliGS方法在挑战性数据集上表现出卓越的重建质量，同时显著减少了训练时间和渲染时间，相比现有的单目可变形NeRF方法，为体视合成提供了一种实用且可扩展的解决方案，在实际场景中有重要意义。源代码将公开。"}
{"llm_update_time": "2025-06-25 09:19:55", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19288", "html_url": "https://arxiv.org/abs/2506.19288", "title": "Da Yu: 向基于无人水面船舶（USVs）的水道监视和场景理解图像配景方向发展", "title_en": "Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding", "authors": "Runwei Guan,Ningwei Ouyang,Tianhao Xu,Shaofeng Liang,Wei Dai,Yafeng Sun,Shang Gao,Songning Lai,Shanliang Yao,Xuming Hu,Ryan Wen Liu,Yutao Yue,Hui Xiong", "background": "无人水面船舶（USVs）需要理解和感知其周围环境，以做出明智的决策。现有的水道感知模型主要关注实例级对象感知（如检测和分割）。但当前的感知数据集和模型无法实现对水道的全局语义理解，这限制了大规模监控和结构化日志生成。为了克服这些问题，研究人员利用视觉语言模型（VLMs）和图像配景技术提出了WaterCaption数据集和Da Yu模型。WaterCaption专注于细粒度和多区域长文本描述，提供了视觉地理理解和空间场景认知的新研究方向。", "innovation": "提出了WaterCaption数据集，这是第一个专门针对水道环境的图像配景数据集，包含20.2k图像-文本对和1.8百万词汇。同时，提出了面向USVs的边缘部署多模态大语言模型Da Yu，其中包括一种新的视觉到语言投影器Nano Transformer Adaptor (NTA)。NTA在保持计算效率的同时增强了全局和细粒度局部视觉特征建模能力，显著提高了生成长文本输出的能力。Da Yu在WaterCaption和几个其他配景基准测试中均表现出色，优于现有最先进模型。", "conclusion": "Da Yu模型的有效边部署多模态大规模语言模型，通过引入Nano Transformer Adaptor投影器，实现了性能和效率之间的良好平衡，从而为水道监视和场景理解提供了有效的解决方案。"}
{"llm_update_time": "2025-06-25 09:19:55", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19312", "html_url": "https://arxiv.org/abs/2506.19312", "title": "通过捕捉细粒度对齐提高3D技术能力检测", "title_en": "Capturing Fine-Grained Alignments Improves 3D Affordance Detection", "authors": "Junsei Tokumitsu,Yuiga Wada", "background": "当前研究中，物体在3D点云中的功能检测面临着挑战，这些任务需要有效地捕捉点云与文本之间细微的对齐关系。现有的方法往往在建模这些对齐关系上存在问题，导致在标准基准测试上的性能受限。这些方法的主要限制在于它们依赖于点云和文本嵌入间的简单余弦相似性，这在细粒度推理解释上缺乏表达性。因此，提高3D功能检测的准确性和性能成为了一个亟待解决的问题。", "innovation": "本研究创新地提出了LM-AD方法，这是一种新的3D点云功能检测方法，引入了Affordance Query Module (AQM)，通过利用预训练的语言模型来高效地捕捉点云和文本之间的细粒度对齐关系，从而提高了功能检测的性能和精度，特别是在基于3D AffordanceNet数据集的测试中，该方法的表现优于现有方法。这一创新性地方法利用了语言模型的高表达能力，解决了传统方法中对齐建模的不足问题。", "conclusion": "实验结果表明，该方法在3D功能检测的准确率和均值交并比(mean Intersection over Union)方面优于现有方法，说明通过捕捉点云和文本之间的细粒度对齐能够有效提高3D功能检测的效果。"}
{"llm_update_time": "2025-06-25 09:19:58", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19306", "html_url": "https://arxiv.org/abs/2506.19306", "title": "使用人类视点的空间时间注意力机制进行气道技能评估", "title_en": "Airway Skill Assessment with Spatiotemporal Attention Mechanisms Using Human Gaze", "authors": "Jean-Paul Ainam,Rahul,Lora Cavuoto,Matthew Hackett,Jack Norfleet,Suvranu De", "background": "气道管理技能在紧急医学中至关重要，通常通过主观评价进行评估，难以在实际场景中准确衡量技能水平。本文探讨了使用机器学习方法，结合人类视点数据和视频记录评估气道管理技能，特别是内气管插管（ETI），以改善技能评估的准确性和效率。", "innovation": "本文提出了一种新颖的方法，即利用人类视点数据的空间时间注意力机制进行ETI技能评估，这是首次在ETI技能评估中使用人类视点数据。该方法通过创建视觉遮罩引导模型聚焦于任务相关区域，并使用自动编码器提取视频特征、注意力模块生成注意力以及分类器输出分类得分，提高了模型的性能和评估方法的客观性，尤其适用于高压力环境下的临床技能评估。结果表明该方法在预测准确性、灵敏度和可信度方面均有所提升，展示了该方法在紧急医学临床培训和患者结果改善方面的巨大潜力。", "conclusion": "研究结果表明，该方法能显著提高气道管理技能评估的准确性和效率，是一种可靠且客观的评估工具，特别是在军事等高压力环境下。这种方法的集成不仅提升了模型性能，还展示了其在提高临床培训和患者结果方面的潜力。"}
{"llm_update_time": "2025-06-25 09:19:59", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19320", "html_url": "https://arxiv.org/abs/2506.19320", "title": "基于增量成像模态的持续视网膜视觉-语言预训练", "title_en": "Continual Retinal Vision-Language Pre-training upon Incremental Imaging Modalities", "authors": "Yuang Yao,Ruiqi Wu,Yi Zhou,Tao Zhou", "background": "传统的视网膜图像分析模型主要针对单一任务，忽略了多种模态的互补性，这限制了它们的应用灵活性。近年来虽然出现了视网膜基础模型，但大多数依然保持模态特定性。在动态环境中，来自不同模态的数据往往是逐步接收到的，因此需要持续预训练。然而，在持续预训练中，容易发生灾难性遗忘现象，亟需有效的策略来解决这一问题。", "innovation": "本文提出了RetCoP框架，这是视网膜领域首个持续视觉-语言预训练框架。该框架能够逐步整合不同成像模态的图像和文本特征到单一的基础模型中，并引入了代表性图像-文本对的复习策略和非对角线信息蒸馏方法，以减轻持续预训练中的灾难性遗忘现象，从而保持图像和文本表示之间的对齐。", "conclusion": "实验结果表明，RetCoP在所有对比方法中表现出最佳的泛化能力与最低的遗忘率。代码可以在指定的链接中找到。"}
{"llm_update_time": "2025-06-25 09:20:01", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19330", "html_url": "https://arxiv.org/abs/2506.19330", "title": "使用微调ImageNet预训练模型对电子元件进行分类的比较性能", "title_en": "Comparative Performance of Finetuned ImageNet Pre-trained Models for Electronic Component Classification", "authors": "Yidi Shao,Longfei Zhou,Fangshuo Tang,Xinyi Shi,Dalang Chen,Shengtao Xia", "background": "电子元器件的分类与检测在制造业中至关重要，能够显著降低劳动力成本并推动技术与产业的发展。预训练模型，特别是ImageNet上训练的模型，在图像分类方面非常有效，即使数据有限，研究人员也能取得优异的结果。本研究对比了ImageNet预训练模型在电子元器件分类任务中的表现。实验结果显示所有测试模型均取得了可接受的精度，其中MobileNet-V2表现最佳，达到99.95%，而EfficientNet-B0最低，为92.26%。这些结果强调了使用ImageNet预训练模型在图像分类任务中的巨大优势，并证实了这些方法在电子制造业的实际应用可行性。", "innovation": "研究比较了多种ImageNet预训练模型在电子元器件分类任务中的性能表现，特别提到MobileNet-V2和EfficientNet-B0两个模型的具体分类精度，展示了预训练模型在实际应用中的有效性。", "conclusion": "研究结果表明，使用ImageNet预训练模型进行图像分类能够显著提高分类精度，特别是在电子元器件分类任务中，这些方法具有很高的实际应用价值。"}
{"llm_update_time": "2025-06-25 09:20:03", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19331", "html_url": "https://arxiv.org/abs/2506.19331", "title": "从句子中对场景中的任何3D部分进行分割", "title_en": "Segment Any 3D-Part in a Scene from a Sentence", "authors": "Hongyu Wu,Pengwan Yang,Yuki M. Asano,Cees G. M. Snoek", "background": "现有的3D场景理解方法大多仅限于物体层面的理解，并且由于数据和标注的高成本，大多数现有数据集和方法也局限于物体层面的感知。本文旨在通过自然语言描述来实现场景中任何3D部分的分割，超越了传统的物体级别3D场景理解，并解决了数据和方法上的挑战。", "innovation": "文章提出了一种名为3D-PU的数据集，这是第一个具有密集部分标注的大规模3D数据集，通过成本效益高的方法构建精细粒度的部分级别标注的合成3D场景，为高层次的3D部分场景理解铺平了道路。同时，文章还提出了OpenPart3D框架，这是一种只使用3D输入的框架，有效解决了部分级别的分割挑战。", "conclusion": "广泛实验表明，在开放词汇的3D场景理解任务中，本文的方法在部分级别具有优越性，并且具有强大的跨各类3D场景数据集的一般化能力。"}
{"llm_update_time": "2025-06-25 09:20:03", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19324", "html_url": "https://arxiv.org/abs/2506.19324", "title": "记忆增强的跨切片与基因关注度超图学习的不完整多模态生存预测", "title_en": "Memory-Augmented Incomplete Multimodal Survival Prediction via Cross-Slide and Gene-Attentive Hypergraph Learning", "authors": "Mingcheng Qu,Guang Yang,Donglin Di,Yue Gao,Tonghua Su,Yang Song,Lei Fan", "background": "多模态病理-基因组分析对于癌症生存预测至关重要。然而，现有的方法主要整合了甲醛固定石蜡嵌入（FFPE）切片与基因组数据，而忽视了其他保存切片（如新鲜冷冻FF切片）的可用性。此外，病理数据的高分辨率空间特性倾向于主导跨模态融合过程，这阻碍了有效的多模态融合，并导致病理学和基因组学之间的模态不平衡问题。现有方法通常需要完整数据模态，限制了它们在具有不完整模态（如缺少病理学或基因组数据）临床场景中的应用性。", "innovation": "本文提出了一种利用超图学习的多模态生存预测框架，有效整合多张石蜡切片（WSI）信息及病理切片与基因组数据之间的跨模态交互，同时解决了模态不平衡问题。此外，引入了记忆机制，存储先前学习的匹配病理-基因组特征，并动态补偿不完整模态。在TCGA的五个数据集中，该模型在C-指数方面的表现优于先进方法超过2.3%，在不完整模态情况下，该方法超越了仅病理（3.3%）和仅基因（7.9%）模型的表现。", "conclusion": "实验证明了本方法的有效性，特别是在处理不完整模态数据方面，提升了多模态生存预测模型的临床适用性。"}
{"llm_update_time": "2025-06-25 09:20:04", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19348", "html_url": "https://arxiv.org/abs/2506.19348", "title": "训练外的自定义运动生成器针对蒸馏视频生成器具有自适应测试时蒸馏的训练外运动自定义", "title_en": "Training-Free Motion Customization for Distilled Video Generators with Adaptive Test-Time Distillation", "authors": "Jintao Rong,Xin Xie,Xinyi Yu,Linlin Ou,Xinyu Zhang,Chunhua Shen,Dong Gong", "background": "蒸馏视频生成模型能够快速高效地生成视频，但在由参考视频引导时难以进行运动定制，尤其是在无需训练的环境中。现有的训练外方法由于蒸馏模型加速生成过程和大量的去噪步骤，无法很好地推广使用。因此，现有的方法无法很好地处理这个问题。", "innovation": "我们提出了一种名为MotionEcho的新方法，这是一种训练外的测试时蒸馏框架，通过扩散教师强制来实现运动定制。该方法利用高质量且速度较慢的教师模型指导快速学生模型的推断，通过端点预测和插值来进行推断。为了保持效率，该方法根据指导需求动态分配计算资源。这种方法在各种蒸馏视频生成模型和基准数据集上的广泛实验表明，我们的方法在提高运动保真度和生成质量的同时，可以保持很高的效率。", "conclusion": "广泛实验表明，我们的方法显著提高了运动保真度和生成质量，同时保持了高效率。这种方法可用于改善蒸馏视频生成模型在运动定制方面的表现。"}
{"llm_update_time": "2025-06-25 09:20:04", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19316", "html_url": "https://arxiv.org/abs/2506.19316", "title": "多模态域适应中的渐进模态合作", "title_en": "Progressive Modality Cooperation for Multi-Modality Domain Adaptation", "authors": "Weichen Zhang,Dong Xu,Jing Zhang,Wanli Ouyang", "background": "该研究为了在多模态跨域视觉识别任务中知识迁移提出了一个名为渐进模态合作（PMC）的新框架。在多模态域适应（MMDA）和更通用的利用特权信息的多模态域适应（MMDA-PI）设置中，提出了该框架来利用多种模态线索（如RGB和深度）将知识从源域转移到目标域。在MMDA设置中，两个域的样本都具有所有的模态。为了选择可靠的目标样本并捕捉特定模态和集成模态信息，论文提出了PM模态合作框架中的两个新模块。在MMDA-PI设置中，目标域某些模态缺失，为此提出了一种新的多模态数据生成（MMG）网络，用于生成目标域中缺失的模态，从而能更好地利用源域的多模态数据，同时保留领域分布的一致性和语义信息。", "innovation": "1. 提出了多模态域适应中的渐进模态合作（PMC）框架，专门用于利用多种模态线索进行跨域知识迁移。\n2. 两个新提出的模块通过合作选择可靠的伪标签目标样本，分别捕捉特定模态和集成模态信息。\n3. 在MMDA-PI设置中，提出了一种新的多模态数据生成（MMG）网络，利用源域数据生成目标域中缺失的模态，考虑领域分布的不匹配和语义的保持，分别使用对抗学习和加权伪语义条件实现此目标。\n4. 系统性地在三种图像数据集和八种视频数据集的跨域多模态视觉识别任务中进行了实验，表明提出的PMC框架的有效性。", "conclusion": "本研究提出了一种新的普及模态合作（PMC）框架，可以有效地在包含多种模态数据的跨域视觉识别任务中将源域的知识迁移到目标域，尤其在源域数据丰富但目标域某些模态缺失的情况下。实验表明，所提出的MMC和MMG框架在多个数据集上的性能提升证明了其的有效性。"}
{"llm_update_time": "2025-06-25 09:20:05", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19341", "html_url": "https://arxiv.org/abs/2506.19341", "title": "轨迹预测在动态物体跟踪中的研究：一项关键性研究", "title_en": "Trajectory Prediction in Dynamic Object Tracking: A Critical Study", "authors": "Zhongping Dong,Liming Chen,Mohand Tahar Kechadi", "background": "本文对当前动态物体跟踪（DOT）和轨迹预测（TP）方法及其应用和挑战进行了详尽的分析，涵盖了特征导向、分割导向、估计导向和学习导向等多种方法，评估了它们在实际应用场景中的有效性、部署情况及其局限性。研究强调了这些技术在汽车和自主车辆、监控和安全、医疗保健和工业自动化中的重要影响，有助于提升安全性和效率。尽管取得了一定进展，但仍有需改进之处，如增强泛化能力、提高计算效率、减少对数据的依赖以及伦理考量等挑战。", "innovation": "该研究涵盖了多种DOT和TP方法，包括特征导向、分割导向、估计导向和学习导向等多种方法，并对其有效性、部署情况及其局限性进行了评估。还强调了未来研究方向，包括多模态数据集成、语义信息融合以及开发感知环境系统的重要性，同时提出了伦理和隐私保护框架的重要性。", "conclusion": "尽管取得了一定进展，但DOT和TP领域仍面临许多挑战，如泛化能力、计算效率、数据依赖性以及伦理问题。未来的研究需要解决这些问题，通过多模态数据集成、语义信息融合和情境感知系统的发展，以及建立伦理和隐私保护框架，来推动这些技术的进步。"}
{"llm_update_time": "2025-06-25 09:20:05", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19344", "html_url": "https://arxiv.org/abs/2506.19344", "title": "使用Chan-Vese主动轮廓模型进行图像分割", "title_en": "Image Segmentation using Chan-Vese Active Contours", "authors": "Pranav Shenoy K. P", "background": "本文 presents 一个综合推导和实现Chan-Vese变分模型的方法，该模型用于图像分割。模型源自Mumford-Shah变分框架，基于区域强度差异而非图像梯度来演化轮廓，使其在处理噪声图像或边界较弱的图像时表现出色。研究结果表明，该模型在医学和合成图像上的分割精度高，对噪声具有鲁棒性，并且在传统基于边缘的方法中表现优异。这项研究证实了Chan-Vese模型在复杂分割任务中的适用性，并突显了其在实际成像应用中的潜力。", "innovation": "本文 rigorously 推导了 Chan-Vese 模型的水平集形式，并详细处理了每个能量项，使用散度定理和曲线演化理论。此外，该模型的实现使用有限差分方法，特别注意数值稳定性，包括上风熵方案和曲率为基础的正则化。", "conclusion": "实验结果表明，该模型在医学和合成图像上的分割精度高，对噪声具有鲁棒性，并且在传统基于边缘的方法中表现优异。这项研究证实了Chan-Vese模型在复杂分割任务中的适用性，并突显了其在实际成像应用中的潜力。"}
{"llm_update_time": "2025-06-25 09:20:09", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19391", "html_url": "https://arxiv.org/abs/2506.19391", "title": "生成森林再种树——一种基于分层扩散模型的气候降尺度方法", "title_en": "Generate the Forest before the Trees -- A Hierarchical Diffusion model for Climate Downscaling", "authors": "Declan J. Curran,Sanaa Hobeichi,Hira Saleem,Hao Xue,Flora D. Salim", "background": "降尺度对于生成适用于地方规划的高分辨率气候数据至关重要，但传统方法计算成本仍然很高。近年来，基于AI的降尺度模型取得了显著成果，尤其是扩散模型，因其能够生成集合并克服其他AI方法通常存在的平滑问题而受到关注。然而，这些模型计算成本依然较高。因此，需要一种轻量级、计算负担更少的降尺度方法，以提供具有成本效益的大规模高分辨率气候预测。", "innovation": " authors 引入了一种分层扩散降尺度（HDD）模型，通过在扩散框架中实现一种易于扩展的层次采样过程，利用简单的下采样方案引入了一个从粗到细的层次结构。该模型在 ERA5 再分析数据集和 CMIP6 模型上取得了竞争力的结果，并显著减少了计算负担。此外，一个在 0.25° 分辨率上训练的单一模型可以无缝地扩展到多个 CMIP6 模型，适用低得多的分辨率，这为概率气候降尺度提供了轻量级的替代方案。", "conclusion": "HDD 模型提供了一种轻量级的替代方案，以实现具有成本效益的概率气候降尺度，从而促进生成高分辨率的气候预测。该模型在计算负担和预测精度方面都提供了竞争力的结果，为气候科学提供了新的工具。"}
{"llm_update_time": "2025-06-25 09:20:09", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19389", "html_url": "https://arxiv.org/abs/2506.19389", "title": "Vision Language Models中文本可读性的出现", "title_en": "Emergence of Text Readability in Vision Language Models", "authors": "Jaeyoo Park,Sanghyuk Chun,Wonjae Kim,Sangdoo Yun,Bohyung Han", "background": "本文研究了视觉语言模型(Vision-Language Models, VLMs)在训练过程中识别图像中的文本内容能力的形成过程。研究发现，文本可读性的形成是突然的，与逐渐发展的语义内容理解不同。这一现象可能反映了对比学习倾向于初期优先处理一般语义理解，而文本特定的符号处理后发展的情况。此外，匹配图像与渲染文本的能力发展更为缓慢，表明了更深层次的语义集成需求。研究结果强调了需要为视觉语言模型定制训练策略，以加快稳健文本理解的过程，并为此类模型的未来多模态学习优化奠定了基础。", "innovation": "1. 识别出文本可读性在训练中突然出现的现象，与语义内容理解的逐渐发展形成对比。\n2. 建立了文本特定符号处理晚于一般语义理解发展的情况。\n3. 发现图像与渲染文本匹配的能力发展更为缓慢，表明了更深层次的语义集成需求。\n4. 强调了为视觉语言模型定制训练策略的必要性，以加速稳健文本理解，并为未来的多模态学习优化奠定了基础。", "conclusion": "研究表明，文本可读性在训练过程中突然出现，与语义内容理解的逐渐发展形成了对比。这种现象反映了对比学习初期优先处理一般语义理解、而文本特定符号处理后发展的可能情况。此外，匹配图像与渲染文本的能力发展更为缓慢，表明了更深层次的语义集成需求。因此，为视觉语言模型制定定制训练策略以加速稳健文本理解和未来多模态学习优化具有重要意义。"}
{"llm_update_time": "2025-06-25 09:20:13", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19464", "html_url": "https://arxiv.org/abs/2506.19464", "title": "评估医学成像任务中窃取专有模型的风险", "title_en": "Assessing Risk of Stealing Proprietary Models for Medical Imaging Tasks", "authors": "Ankita Raj,Harsh Swaika,Deepankar Varma,Chetan Arora", "background": "深度学习在医学影像应用中的成功导致多家公司部署自家模型以提供更多盈利性服务。尽管模型权重被隐藏以保护服务提供商的知识产权，这些模型仍面临模型窃取（MS）攻击的威胁，即对手通过查询并利用这些模型进行训练，从而复制其功能。尽管对通用视觉任务的MS攻击已有较多研究，但医学影像模型对此类攻击的易感性尚未得到充分探索。本研究在现实条件中，即对手无法访问受害模型的训练数据且预算有限的情况下，评估黑盒医学影像模型的MS攻击脆弱性。", "innovation": "提出了一种名为QueryWise的两阶段模型窃取方法。该方法利用从代理分布中获取的无标签数据来训练盗贼模型，而无需增加额外的查询预算，从而提升了MS攻击的能力。", "conclusion": "实验表明，该提出的攻击方法在两个医学影像模型（胆囊癌和COVID-19分类）上的有效性。源代码可在该链接获取。"}
{"llm_update_time": "2025-06-25 09:20:13", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19406", "html_url": "https://arxiv.org/abs/2506.19406", "title": "GLCANet用于超高清遥感图像语义分割的全局-局部交叉注意力网络", "title_en": "A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation", "authors": "Chen Yi,Shan LianLei", "background": "随着超高清(UHR)遥感技术的快速发展，对准确且高效的语义分割的需求显著增加，但现有方法在计算效率和多尺度特征融合方面面临挑战。", "innovation": "提出了GLCANet（全局-局部交叉注意力网络），这是一种轻量级分割框架，适用于UHR遥感。GLCANet采用双流架构高效地融合全局语义和局部细节，同时减少了GPU使用量。自我注意机制增强了长距离依赖关系，细化全局特征，保留局部细节以提高语义一致性。掩码交叉注意机制也适应性地融合全局-局部特征，有选择地增强细粒度细节并利用全局上下文提高分割精度。实验结果表明，GLCANet在准确性和计算效率方面均优于现有方法。GLCANet能够有效处理大尺寸、高分辨率图像，具有较小的内存占用，为实际遥感应用提供了有前景的解决方案。", "conclusion": "GLCANet在UHR遥感语义分割上取得了优于现有方法的表现，特别是在准确性和计算效率方面。该模型能够在不降低性能的情况下处理大规模高分辨率图像，为实践中的应用提供了有希望的解决方案。"}
{"llm_update_time": "2025-06-25 09:20:14", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19433", "html_url": "https://arxiv.org/abs/2506.19433", "title": "Mem4Nav：在城市环境中通过层次化空间认知长短时记忆系统提升视觉语言导航", "title_en": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System", "authors": "Lixuan He,Haoyu Dong,Zhenxing Chen,Yangcheng Yu,Jie Feng,Yong Li", "background": "在大规模城市环境中进行视听说导航（VLN）需要自主代理能够理解复杂的视觉场景中的语言指令，并在长时间范围内回忆相关经验。现有的分模块流水线虽然具有可解释性，但缺乏统一记忆；端到端的多模态语言模型（M）大语言模型（LLM）领域本可以融合视觉和语言，但仍然受限于固定的上下文窗口和隐式的空间推理能力。", "innovation": "该研究引入了Mem4Nav，这是一种层次化的空间认知长短时记忆系统，能够增强任何VLN骨干网络。Mem4Nav通过稀疏八叉树进行精细的体素索引，并使用语义拓扑图实现高层地标连接，两者都嵌入到可训练的记忆标记中，通过可逆的Transformer实现。长期记忆压缩并保留了历史观察值，而短期记忆则缓存了最近的多模态条目。每当需要更深层次的历史时，LTM标记将被无损解码以重建过去的嵌入。该系统在Touchdown和Map2Seq上经过了三种骨干网络的测试，结果显示出7-13的点数增益、足够的速度精确度降低以及超过10的点数nDTW提升。", "conclusion": "消融实验验证了层次化地图和双重记忆模块的不可或缺性。研究的代码已开放，可通过以下链接获取：this https URL。"}
{"llm_update_time": "2025-06-25 09:20:15", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19416", "html_url": "https://arxiv.org/abs/2506.19416", "title": "EvDetMAV: 由移动事件相机进行的通用微型空中车辆检测", "title_en": "EvDetMAV: Generalized MAV Detection from Moving Event Cameras", "authors": "Yin Zhang,Zian Ning,Xiaoyu Zhang,Shiliang Guo,Peidong Liu,Shiyu Zhao", "background": "现有微型空中车辆（MAV）检测方法主要依赖于目标在RGB图像中的外观特征，但由于这些特征的多样性，难以实现泛化的MAV检测。本研究注意到，不同类型的MAV在事件流中共享相似特征，这是因为它们高速旋转的螺旋桨在RGB图像中不易观察到。因此，本文致力于研究如何通过充分利用原始事件流中的螺旋桨特征来检测不同类型的MAV，同时过滤掉背景物体和相机运动的噪声。由于不存在现有的基于事件的MAV数据集，我们引入了一个新型的MAV数据集供社区使用。该数据集包含了多种场景和不同类型的MAV，是第一个基于事件的MAV数据集。", "innovation": "本文提出了一种基于事件的MAV检测方法，该方法由三个模块组成：用于提取螺旋桨的显著性和时空特征、过滤背景物体和相机运动的噪声。更重要的是，作者创建了一个新的基于事件的MAV数据集，这是该领域的第一个数据集，它包含多种场景和不同类型的MAV。实验结果表明，该方法在未训练的情况下显著优于现有最先进技术，并且能够处理各种具有挑战性的场景，获得了较高的精度率和召回率。", "conclusion": "本文介绍了一个基于事件的MAV检测方法，并开发了一个全新的多场景和多类型的MAV数据集。实验结果证明了该方法的有效性和优越性，在特定测试数据集上实现了高度的精度和召回率。所构建的数据库和代码已公开，供社区使用和进一步研究。"}
{"llm_update_time": "2025-06-25 09:20:16", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19439", "html_url": "https://arxiv.org/abs/2506.19439", "title": "AMF-MedIT：一种高效的图像-表格数据对齐-调制-融合框架", "title_en": "AMF-MedIT: An Efficient Align-Modulation-Fusion Framework for Medical Image-Tabular Data", "authors": "Congjing Yu,Jing Ye,Yang Liu,Xiaodong Zhang,Zhiyong Zhang", "background": "多模态医学分析结合图像和表格数据越来越受到关注。然而，有效的融合仍然具有挑战性，特别是在特征维度和模态贡献存在交叉模态差异以及高维表格输入噪声的情况下。", "innovation": "提出了一种高效联调融合框架AMF-MedIT，特别是在数据稀缺条件下。引入了自适应调制和融合（AMF）模块，这是一种新颖的基于调制的融合范式，具有简化架构，用于协调维度差异并动态调整模态贡献。此外，还提出了FT-Mamba，这是一种强大的表格编码器，利用选择机制有效处理噪声医学表格数据。", "conclusion": "大量的实验表明，AMF-MedIT在多模态性能和数据效率之间实现了更好的平衡，并且在不完整的表格数据方面具有很强的适应性。解释性分析还强调了FT-Mamba在提取独特表格特征和引导图像编码器获得更准确和灵活的注意力模式方面的功能。"}
{"llm_update_time": "2025-06-25 09:20:16", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19445", "html_url": "https://arxiv.org/abs/2506.19445", "title": "野外去模糊：来自智能手机高速视频的现实世界数据集", "title_en": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos", "authors": "Mahdi Mohd Hossain Noki,Syed Mumtahin Mahmud,Prothito Shovon Majumder,Abdul Mohaimen Al Radi,Md. Haider Ali,Md. Mosaddek Khan", "background": "介绍了使用来自智能手机慢动作视频的最大实际图像去模糊数据集。该数据集包含超过42,000对高分辨率模糊-清晰图像，比广泛使用的数据集大约10倍，场景种类增加8倍，涵盖了室内和室外环境，对象和相机运动各不相同。数据集利用超过一秒钟内捕捉的240帧来模拟现实的长曝光模糊，使用时间上居中的帧作为清晰参考。这些图像用于评估多个最新去模糊模型的表现，展示了基准测试的复杂性和多样性。该数据集作为新的基准测试，有助于促进更稳健和泛化的去模糊模型的发展。", "innovation": "构建了最大规模的实际图像去模糊数据集，来源于智能手机慢动作视频，包含大量高分辨率的模糊-清晰图像对，涵盖多种场景和运动情况。该数据集通过模拟现实的长曝光模糊，使用时间居中的帧作为清晰参考，提供了一个 Benchmark 来测试和验证去模糊模型的性能，强调了去模糊任务的复杂性和多样性。", "conclusion": "该数据集作为新的基准测试，为开发更稳健和泛化的去模糊算法提供了重要支持，有助于推动去模糊技术的发展。"}
{"llm_update_time": "2025-06-25 09:20:17", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19388", "html_url": "https://arxiv.org/abs/2506.19388", "title": "基于视点不变视觉-生物力学一致性的在线双目内窥镜组织形变恢复", "title_en": "Online camera-pose-free stereo endoscopic tissue deformation recovery with tissue-invariant vision-biomechanics consistency", "authors": "Jiahe Chen,Naoki Tomii,Ichiro Sakuma,Etsuko Kobayashi", "background": "组织形变恢复对于工具-组织交互分析至关重要，可以提高手术导航和自主软组织操纵的效果。但现有研究面临摄像机运动、遮挡、大范围组织变形、缺乏特定生物力学先验信息以及依赖于离线处理的问题。以往研究将组织几何和形变表示为3D点和位移，而本文提出的方法将组织几何描述为3D点和导数图，并将组织形变描述为3D位移和局部形变图。", "innovation": "本文提出了一个新的无摄像机姿态的双目内窥镜组织形变恢复方法，在摄像机中心的设置下将所有运动视为相对于摄像机的场景运动。通过优化帧间形变实现帧间对齐，无需估计摄像机姿态。引入了标准化映射的概念，以在线优化组织几何和形变。该方法能够即使在组织部分遮挡或移动出视域范围时，仍使用深度和光学流作为输入，稳定地建模组织几何和形变。在体内外腔镜数据集上进行了定量和定性实验，结果表明非遮挡和遮挡区域在表面距离上的3D重建精度分别达到0.37±0.27 mm和0.39±0.21 mm。此外，该方法还能够在各种操作期间估计表面应变分布，作为机械分析的一种额外模态。", "conclusion": "本文提出的方法在摄像机姿态未知的情况下，通过优化帧间形变实现组织形变的有效恢复，这种方法填补了现有研究的不足，为工具-组织交互分析提供了更精确和稳定的支持。"}
{"llm_update_time": "2025-06-25 09:20:18", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19442", "html_url": "https://arxiv.org/abs/2506.19442", "title": "采样在解释中的重要性：通过最大化解释确定性在视觉模型中构建可信的归因分析构建块", "title_en": "Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty", "authors": "Róisín Luo,James McDermott,Colm O'Riordan", "background": "归因分析旨在突出显示视觉模型学习的功能表示，以便增强图示可以反映输入的像素级重要性。梯度整合是归因分析中的一个基本模块，它通过从多个衍生样本中整合梯度来突出显示与推理相关的语义功能。梯度整合通常与其他视觉模型信息（如激活图或注意力图）结合使用，以形成最终解释。然而，我们的理论分析表明，在梯度整合与自然图像分布的样本分布对齐程度决定了解释确定性的下限。先前的工作是在图像中添加噪声作为样本，噪声分布可能导致较低的解释确定性。令人意外的是，我们的实验表明额外信息可以饱和神经网络。因此，建设性的归因分析需要解决样本分布不匹配的问题。尽管将额外信息添加到输入图像中，我们提出了一个半优化的采样方法，通过抑制输入特征来构建样本。抑制特征的样本分布与自然图像的分布相近。我们在大规模数据集ImageNet上的广泛定量评估证实了我们方法的有效性，并且在所有实验模型中都能提供更令人满意的解释，相比最先进的基线方法而言。", "innovation": "提出了半优化的采样方法，通过抑制特征使得样本分布接近自然图像分布，解决了样本分布不匹配的问题，从而提高了归因分析的可信度和解释确定性。这种方法与以往在图像中添加噪声作为样本的方法不同，能够减少对神经网络的饱和效应，提升模型理解能力，从而实现更准确的解释和更具可信度的归因分析。", "conclusion": "通过最大化解释确定性的做法，半优化采样方法能够有效提升视觉模型中归因分析的可信度。这种方法可以应用于大规模数据集ImageNet，即使在所有实验模型中也能提供满意的解释，因此能够成功解决问题并改进归因分析的质量。"}
{"llm_update_time": "2025-06-25 09:20:19", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19469", "html_url": "https://arxiv.org/abs/2506.19469", "title": "Surgery-R1: 利用强化学习推进具有推理能力的多模态大型语言模型在手术-VQLA中的应用", "title_en": "Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning", "authors": "Pengfei Hao,Shuaibo Li,Hongqiu Wang,Zhizhuo Kou,Junhang Zhang,Guang Yang,Lei Zhu", "background": "近年来，手术场景理解领域取得了显著进展，特别是在机器人手术中的视觉问题定位-回答任务（Surgical-VQLA）上。然而，现有的Surgical-VQLA模型在手术场景中的推理能力和可解释性不足，这影响了它们在临床应用中的可靠性和发展潜力。", "innovation": "本文借鉴推理多模态大型语言模型（MLLMs）的发展，构建了Surgery-R1-54k数据集，包括视觉问答、Grounding-QA和链式思考（CoT）的配对数据。在此基础上，提出了首个用于Surgical-VQLA的推理MLLM（Surgery-R1）。Surgery-R1设计了两阶段微调机制，通过监督微调（SFT）和强化微调（RFT），使得基础MLLM具备复杂的推理能力。此外，为了在RFT中创建高效和高质量的规则奖励系统，设计了一种多模态一致性奖励机制，以减轻手术场景中可能出现的位置错觉。实验结果表明，Surgery-R1在Surgical-VQLA任务和广泛使用的MLLMs上均优于现有最先进的模型（SOTA），验证了其推理能力和方法的有效性。", "conclusion": "Surgery-R1在Surgical-VQLA任务中的表现超过了现有最先进的模型和广泛使用的多模态大型语言模型。通过两阶段微调机制和多模态一致性奖励机制，有效提升了模型的推理能力。"}
{"llm_update_time": "2025-06-25 09:20:21", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19472", "html_url": "https://arxiv.org/abs/2506.19472", "title": "USIS16K: 高质量的水下显著实例分割数据集", "title_en": "USIS16K: High-Quality Dataset for Underwater Salient Instance Segmentation", "authors": "Lin Hong,Xin Wang,Yihao Li,Xia Wang", "background": "受生物视觉系统启发，能够高效地识别重要目标，水下显著实例分割（USIS）旨在解决水下场景中‘看哪里’和‘看什么’的问题。但由于水下环境的难以接近和动态特性，以及高质量标注数据集的稀缺性，USIS仍然是一个待探索的难题。", "innovation": "提出了USIS16K，这是一个包含16,151张高质量水下图像的大规模数据集，覆盖158类水下物体。每个图像都按照实例级标注出了高质量的显著对象掩码，极大地增强了数据集的多样性和复杂性。同时，还提供了基于USIS16K的水下物体检测和USIS任务的基准评估，以促进该领域的未来研究。", "conclusion": "USIS16K和相关的基准模型已经公开，为水下显著实例分割领域的进一步研究提供了支持。"}
{"llm_update_time": "2025-06-25 09:20:22", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19465", "html_url": "https://arxiv.org/abs/2506.19465", "title": "改进神经网络预训练的结构化图案风格化", "title_en": "Stylized Structural Patterns for Improved Neural Network Pre-training", "authors": "Farnood Salehi,Vandit Sharma,Amirhossein Askari Farsangi,Tunç Ozan Aydın", "background": "现代计算机视觉中的深度学习模型需要大量的真实图像数据，但采集和管理这些数据存在困难，并带来隐私和法律问题，这限制了它们的商业化应用。尽管最近的研究表明合成数据可以作为一种替代方案，但使用合成数据训练的模型通常会表现不佳。因此，本文提出了一种两步方法来弥合这一差距。首先，通过改进神经分形公式，引入了一种新的合成数据类别；其次，提出了反向风格化技术，将少量的无版权真实图像的视觉特征转移到合成数据集上，增强其有效性。", "innovation": "本文提出了一种两步方法来提高使用合成数据训练深度学习模型的效果。首先，通过改进神经分形公式生成了一种新的合成数据类别；其次，提出了反向风格化技术，将少量无版权真实图像的视觉特征转移到合成数据集上，降低了合成数据集和真实图像之间的领域差距，从而提高了预训练模型的效果。实验结果表明，使用本文方法的合成数据预训练的EDM2扩散模型比使用现有合成数据预训练的模型，在生成图像时FID减少11%，自动编码器重构误差减少20%。此外，基于这种合成数据进行分类训练的ViT-S模型在ImageNet-100上的准确率提高了10%以上。", "conclusion": "本文提出的方法降低了合成数据和真实图像之间的领域差距，展示了改善预训练模型性能的可能性。当缺乏足够大的真实训练集时，本文的工作为训练实用模型开辟了新的可能性。"}
{"llm_update_time": "2025-06-25 09:20:24", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19474", "html_url": "https://arxiv.org/abs/2506.19474", "title": "HMSViT:一种用于角膜神经分割和糖尿病神经病变诊断的分层遮罩自监督视觉变换器", "title_en": "HMSViT: A Hierarchical Masked Self-Supervised Vision Transformer for Corneal Nerve Segmentation and Diabetic Neuropathy Diagnosis", "authors": "Xin Zhang,Liangxiu Han,Yue Shi,Yanlin Zheng,Alam Uazman,Maryam Ferdousi,Rayaz Malik", "background": "糖尿病周围神经病变(DPN)影响几乎一半的糖尿病患者，需要早期检测。角膜共聚焦显微镜(CCM)提供了一种非侵入性的诊断方法，但现有的自动化方法在特征提取效率、对人工先验的依赖以及数据限制方面存在不足。", "innovation": "提出了HMSViT，这是一种新颖的分层遮罩自我监督视觉变换器，专为角膜神经分割和DPN诊断设计。HMSViT利用基于池化的层次和双注意力机制与绝对位置编码，实现多尺度特征的有效提取，同时降低计算成本。HMSViT还设计了一种块遮罩自我监督学习框架，减少对标记数据的依赖，增强特征的稳健性，并使用多尺度解码器融合层次特征进行分割和分类。实验表明，HMSViT在角膜神经分割和诊断方面达到了最先进的性能，同时与基准的分层模型相比，在参数更少的情况下提升了分割准确性。详细的关键因素分析进一步表明，结合块遮罩自我监督学习与层次多尺度特征提取显著提高了性能对比传统的监督训练方法。", "conclusion": "综合实验结果证实HMSViT提供了一流、稳健且临床可行的结果，展示了其在实际诊断应用中广泛部署的潜力。"}
{"llm_update_time": "2025-06-25 09:20:25", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19533", "html_url": "https://arxiv.org/abs/2506.19533", "title": "识别后门面部识别网络中可实现触发器", "title_en": "Identifying Physically Realizable Triggers for Backdoored Face Recognition Networks", "authors": "Ankita Raj,Ambar Pal,Chetan Arora", "background": "后门攻击使深度神经网络在特定模式下输入触发器时表现出异常行为，而在其他情况下表现良好。最近的研究表明，被后门感染的面部识别系统可以响应类似于特定太阳镜这样看起来自然的触发器。这些攻击对高安全性应用中面部识别系统的适用性构成了严重威胁。", "innovation": "提出了一种新方法来检测面部识别网络是否被自然且可实现的触发器感染，并在此基础上识别出这种触发器。该方法在受感染的面部识别网络中成功识别出触发器，如绿太阳镜或红帽子，达到5%的精度为74%，而朴素的暴力破解基准仅达到56%的精度。", "conclusion": "所提出的方法能有效识别出面部识别网络中的后门触发器，显著提升了对抗后门攻击的能力。"}
{"llm_update_time": "2025-06-25 09:20:25", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19488", "html_url": "https://arxiv.org/abs/2506.19488", "title": "SceneCrafter：多视角可控驾驶场景编辑", "title_en": "SceneCrafter: Controllable Multi-View Driving Scene Editing", "authors": "Zehao Zhu,Yuliang Zou,Chiyu Max Jiang,Bo Sun,Vincent Casser,Xiukun Huang,Jiahao Wang,Zhenpei Yang,Ruiqi Gao,Leonidas Guibas,Mingxing Tan,Dragomir Anguelov", "background": "模拟在自主车辆（AV）系统的开发和评估中至关重要。近期文献基于新一代生成模型，用于合成高度真实的图像，以进行全面模拟。然而，纯合成场景缺乏现实基础，难以鼓舞人们对结果的相关性的信心。相比之下，编辑模型利用实际驾驶日志中的源场景，能够模拟不同的交通布局、行为以及运营条件，如天气和时间。虽然是计算机视觉中一个成熟的话题，但在驾驶模拟中仍然面临着新的挑战，包括跨摄像头三维一致性、从具有前景遮挡的实际驾驶数据中学习“空街”先验、以及在保持一致布局和几何形状的同时生成不同编辑条件配对图像组。", "innovation": "我们提出了SceneCrafter，一种多视角的驱场景编辑器，用于实现现实的三维一致的驾驶场景操纵。我们利用最近在多视图扩散模型方面的进展，并构建了一个完全可控的框架，可以无缝扩展到如天气、时间、智能体框和高清地图等多模态条件。我们提出了一个新颖的基于Prompt-to-Prompt的框架，用于生成全局编辑的几何上一致的合成配对数据。我们还引入了一种alpha混合框架来合成具有局部编辑的数据，利用经过掩膜训练和多视角重涂策略训练的模型生成空街先验。SceneCrafter展示了强大的编辑能力，并在现实性、可控性、三维一致性和场景编辑质量等方面超过了现有基线，达到了最先进的表现。", "conclusion": "SceneCrafter在实时一致性、控制性、3D一致性以及场景编辑质量等方面达到了最先进的水平，展示了强大的编辑能力，代表了在驾驶场景编辑方面的重要进步。"}
{"llm_update_time": "2025-06-25 09:20:26", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19513", "html_url": "https://arxiv.org/abs/2506.19513", "title": "大型视觉语言模型中的证据冲突检测以进行视觉幻觉检测", "title_en": "Visual hallucination detection in large vision-language models via evidential conflict", "authors": "Tao Huang,Zhekun Liu,Rui Wang,Yang Zhang,Liping Jing", "background": "尽管大型视觉语言模型（LVLMs）具有卓越的多模态能力，但在视觉输入和文本输出之间仍存在差距，这种现象称为视觉幻觉。这种可靠性差距在安全关键的人工智能应用中带来了巨大风险，因此需要一个全面的评估基准和有效的检测方法。现有的视觉中心幻觉基准主要从感知角度评估LVLMs，忽视了源自高级推理能力的幻觉。因此，本文开发了Perception-Reasoning Evaluation Hallucination (PRE-HAL)数据集，以系统地评估LVLMs在多个视觉语义方面的感知和推理能力。", "innovation": "本文提出了第一个基于达米特-沙弗理论（Dempster-Shafer theory, DST）的LVLM视觉幻觉检测方法，通过不确定性估计来检测高级特征之间的冲突。该方法能够在模型推理阶段高效地捕捉高阶特征中的冲突程度。此外，本文还进行了广泛的实验证明了该方法在LLaVA-v1.5、mPLUG-Owl2和mPLUG-Owl3等大型视觉语言模型上的有效性，相比五个基线不确定性指标，平均提高了4%、10%和7%的AUROC值。", "conclusion": "通过开发全新的PRE-HAL数据集和提出基于DST的视觉幻觉检测方法，本文填补了现有框架中的空白。该方法能够有效地检测LVLMs在推理任务中的冲突，从而提高模型的鲁棒性和可靠性。"}
{"llm_update_time": "2025-06-25 09:20:27", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19531", "html_url": "https://arxiv.org/abs/2506.19531", "title": "ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation", "title_en": "ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation", "authors": "Mubashara Rehman,Niki Martinel,Michele Avanzo,Riccardo Spizzo,Christian Micheloni", "background": "在千伏CT (kVCT) 成像中，伪影影响图像质量并对临床决策产生不利影响。为了解决这一问题，本文提出了一种深度学习框架，用于金属伪影减少（MAR）和千伏CT到兆伏CT（MVCT）的领域转换。该框架旨在提升图像质量，同时确保不丢失解剖结构信息，以支持更精准的图像重建和临床应用。", "innovation": "该框架名为ReMAR-DS，采用编码-解码结构，并加入了增强的特征再校准方法。这种方法能在减少伪影的同时保留关键的解剖结构信息。通过在编码模块中重新校准特征，该模型能够聚焦于包含伪影的区域，并在各个通道中突出关键特征，从而改善伪影受损区域的重建效果。与传统MAR方法不同，该方法能够连接高分辨率的kVCT和抗伪影的MVCT，提高放射治疗规划的精度。通过定性和定量评估验证了该方法生成的高质量MVCT类似重建效果。", "conclusion": "此方法能够使临床医生仅依赖kVCT进行放射治疗规划，减少重复的高剂量MVCT扫描，降低癌症患者的辐射暴露。"}
{"llm_update_time": "2025-06-25 09:20:28", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19552", "html_url": "https://arxiv.org/abs/2506.19552", "title": "通用方法在胎儿超声诊断中的出色表现：一个案例研究", "title_en": "General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound", "authors": "Jakob Ambsdorf,Asbjørn Munk,Sebastian Llambias,Anders Nymark Christensen,Kamil Mikolaj,Randall Balestriero,Martin Tolsgaard,Aasa Feragen,Mads Nielsen", "background": "由于可获取大规模未标记的医疗数据集，研究人员面临一个问题：他们应该尝试在这些医疗数据上预训练一个定制的基础模型，还是使用现有通用模型的迁移学习？如果需要预训练定制模型，是否需要新方法？", "innovation": "通过使用广泛认可的DINOv2方法进行预训练，作者实现了胎儿超声数据集上最先进的结果，覆盖了不同类型的数据、分类、分割和少量样本任务。作者的模型在一系列基于自然图像、超声图像和监督基准模型的模型中进行了比较，结果表明：即使训练更小的模型数据更少，预训练于定制数据仍然是值得的，因为自然图像预训练的扩展性并不适用于超声数据。计算机视觉中调整良好的方法已经使得为特定医疗领域训练定制基础模型成为可能，不需要调参和微小调整的方法学变化。基于这些发现，作者认为在资源有限的情况下，应该避免对特定领域基础模型在方法创新上的偏见而不是依赖传统方法。", "conclusion": "本研究通过胎儿超声影像数据集的案例研究，表明使用广泛应用于其他领域的预训练方法可以很好地适应特定医疗领域的需求，从而得出台词模型的开发应避免在方法创新上的偏见结论。"}
{"llm_update_time": "2025-06-25 09:20:31", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19591", "html_url": "https://arxiv.org/abs/2506.19591", "title": "基于视觉变换器的时间序列图像重建在云填充应用", "title_en": "Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications", "authors": "Lujun Li,Yiqun Wang,Radu State", "background": "多光谱图像（MSI）中的云覆盖对早期季节作物测绘产生了显著挑战，因为它导致了缺失或损坏的光谱信息。尽管合成孔径雷达（SAR）数据不受云干扰影响，提供了一种互补的解决方案，但它缺乏足够的光谱细节，不利于精确的作物测绘。因此，需要一种可以在云覆盖区域重建MSI数据的方法，以应对上述挑战。已有方法使用非时间序列MSI或SAR，或是时间序列MSI但不包含SAR，效果不佳，无法有效增强MSI图像在云覆盖区域的重建效果。", "innovation": "提出了一种新颖的框架——基于视觉变换器的时间序列MSI图像重建（Time-series MSI Image Reconstruction using Vision Transformer, Time-series ViT），该框架利用MSI的空间时间一致性以及来自SAR的互补信息，通过自注意力机制来重建云覆盖区域的MSI数据，显著优于现有的非时间序列MSI或SAR方法以及时间序列MSI但不包含SAR的方法。", "conclusion": "通过全面的实验证明，Time-series ViT框架在严格的重建评估指标中表现出色，有效提升了云覆盖区域MSI图像的重建效果。"}
{"llm_update_time": "2025-06-25 09:20:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19561", "html_url": "https://arxiv.org/abs/2506.19561", "title": "MambaOutRS: 一种用于遥感图像分类的混合CNN-傅里叶架构", "title_en": "MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification", "authors": "Minjong Cheon,Changbae Mun", "background": "近年来，深度学习在视觉任务中的进展广泛使用了状态空间模型（SSMs），如Mamba，这些模型因其线性可扩展性而受到赞誉。然而，将这些模型应用于二维视觉数据时，往往需要复杂的修改，这可能导致效率降低。现有遥感图像分类模型在面对复杂遥感数据集时表现不足，需要一种新的解决方案来提高模型效率和效果。", "innovation": "本文提出了MambaOutRS，这是一种结合了卷积神经网络(CNN)和频域滤波门控模块(FFG)的新型混合架构，特别适用于遥感图像分类。MambaOutRS采用了堆叠的门控CNN模块进行局部特征提取，并引入了FFG模块以高效捕获全局上下文信息。该模型通过四个层次的设计，在多种挑战性的遥感数据集上表现出色，甚至在使用更少参数的情况下超过了现有的基线模型和更大的变压器模型。这项研究通过消融实验证实了FFG模块在增强模型捕捉全局空间模式方面的重要性，从而提高了分类的准确性和鲁棒性，显示出复杂的递归SSMs可以通过明智地结合门控卷积和基于频率的门控来有效取代。", "conclusion": "MambaOutRS提供了一种高效且高性能的深度学习模型开发范例，特别适用于对计算效率有高要求的遥感和视觉领域。该模型通过充分利用卷积和频域滤波器的优势，实现在遥感图像分类上的卓越表现。"}
{"llm_update_time": "2025-06-25 09:20:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19621", "html_url": "https://arxiv.org/abs/2506.19621", "title": "基于相位相关网络的视频解析与预测 (VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks", "title_en": "VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks", "authors": "Noel José Rodrigues Vicente,Enrique Lehner,Angel Villar-Corrales,Jan Nogga,Sven Behnke", "background": "在动态环境中，理解和预测视频内容对于规划和推理至关重要。尽管已有进展，但无监督地学习物体表示和动态仍然具有挑战性。", "innovation": "我们提出了VideoPCDNet，这是一种基于无监督的物体为中心的视频分解和预测框架。它使用频域相位相关技术递归地解析视频为物体成分，这些成分由学习的物体原型的变换版本表示，从而实现准确且可解释的跟踪。通过结合频域操作和轻量级的已学习模块显式建模物体运动，VideoPCDNet能够实现准确的无监督物体跟踪并预测未来帧。", "conclusion": "我们的实验表明，VideoPCDNet在几种合成数据集的无监督跟踪和预测方面优于多种物体为中心的基本模型，同时学习了可解释的物体和运动表示。"}
{"llm_update_time": "2025-06-25 09:20:34", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19593", "html_url": "https://arxiv.org/abs/2506.19593", "title": "通过多模态传感与步态引导实现盲人导航", "title_en": "Implementing blind navigation through multi-modal sensing and gait guidance", "authors": "Feifan Yan,Tianle Zeng,Meixi He", "background": "截至2023年，全球视力受损人口已超过2.2亿。视力受损的人在寻找路径或避开障碍时会遇到困难，通常需要辅助工具的帮助。尽管存在传统的辅助工具，如手杖和导盲犬，但这些工具仍存在一些不足之处。", "innovation": "本论文提出了一种可穿戴的导盲设备，该设备通过我们提出的基于步态的引导系统来实现导航引导。创新之处在于将步态分析与行走引导相结合，同时使用多模态传感获取环境信息，从而提供了更全面的环境感知能力。", "conclusion": "在实验中，我们进行了室内和室外实验，将该设备的性能与标准手杖进行了对比，结果显示该设备在导盲方面表现出更优的效果。"}
{"llm_update_time": "2025-06-25 09:20:34", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19639", "html_url": "https://arxiv.org/abs/2506.19639", "title": "HOIverse：具有人类物体交互的合成场景图数据集", "title_en": "HOIverse: A Synthetic Scene Graph Dataset With Human Object Interactions", "authors": "Mrunmai Vivek Phatak,Julian Lorenz,Nico Hörmann,Jörg Hähner,Rainer Lienhart", "background": "当人类和机器人在环境中共同存在时，场景理解变得至关重要，对于执行导航和规划等下游任务的代理。因此，代理必须能够定位并识别人类执行的动作。现有的研究缺乏室内环境中包含人类的场景理解可靠数据集。场景图使我们可以生成场景或图像的结构化表示，从而进行视觉场景理解。然而，缺乏可靠的数据集来在包含人类的室内环境中执行场景理解。为了应对这一挑战，本文提出了HOIverse，这是一个综合人工场景图数据集，包含人类与周围物体之间精准且密集的关系真值，以及相应的RGB图像、分割掩码、深度图像和人体关键点。通过该数据集，我们旨在加速涉及人类的场景理解领域的研究进展。", "innovation": "HOIverse数据集结合了场景图和人类物体交互的特点，提供了一种包含人类与环境相互作用的合成数据集，该数据集包括人类与周围物体之间精确且密集的关系真值，以及相应的RGB图像、分割掩码、深度图像和人体关键点。此外，通过对当前最先进的场景图生成模型进行基准测试，以预测参量化关系和人类物体交互，该数据集进一步推动了场景理解领域的研究进展。", "conclusion": "通过HOIverse数据集，我们希望能够显著推动涉及人的场景理解研究领域，帮助研究者更好地理解和解析包含人类在内的复杂环境。"}
{"llm_update_time": "2025-06-25 09:20:35", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19656", "html_url": "https://arxiv.org/abs/2506.19656", "title": "地球系统时空数据的视频压缩", "title_en": "Video Compression for Spatiotemporal Earth System Data", "authors": "Oscar J. Pellicer-Valero,Cesar Aybar,Gustau Camps Valls", "background": "地球系统的大规模数据集，从高分辨率遥感图像到时空气候模型输出，具有类似于标准视频的特性。这些数据集具有内在的空间、时间和光谱冗余性，可以利用现有的视频压缩技术进行压缩。研究通过xarrayvideo Python库以视频形式压缩多通道时空数据集，在保持高保真的同时实现了高达250倍的压缩比率。", "innovation": "提出了xarrayvideo Python库，利用标准视频编解码器（如ffmpeg）将多通道时空数据集编码为视频形式进行压缩。该方法在四个实际的多通道时空数据集上进行验证，展示了在很小的比特率下（0.1bpppb和1bpppb）仍能保持较高保真度（PSNR分别为55.86、40.60、46.58、43.23 dB和65.91、54.28、62.90、55.04 dB）。", "conclusion": "xarrayvideo提供了一种高效处理地球观测数据快速增长规模的解决方案，使先进的压缩技术适用于地球科学共同体。该库可在以下地址使用：[xarrayvideo库地址]"}
{"llm_update_time": "2025-06-25 09:20:36", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19615", "html_url": "https://arxiv.org/abs/2506.19615", "title": "Self-Supervised Multimodal NeRF for Autonomous Driving", "title_en": "Self-Supervised Multimodal NeRF for Autonomous Driving", "authors": "Gaurav Sharma,Ravi Kothari,Josef Schmid", "background": "本研究聚焦于利用神经辐射场（NeRF）构建新型视图合成框架（NVSF）。该框架旨在解决混合多模态自动驾驶场景中的时空场景表示问题，重点是利用激光雷达（LiDAR）和相机的数据全方位表示静态和动态场景。现有的多模态动态 NeRF 常需要3D标签以辅助训练，而本研究提出的方法采取自监督的学习方式，简化了标注流程并提高了泛化能力。此外，为了加速训练和提高收敛效率，研究引入了一种基于启发式的图像像素抽样方法，并设计了一种双梯度掩码来保留LiDAR点的局部特征。", "innovation": "本研究的主要创新点包括：1) 提出了一种自监督双模态 NeRF 框架；2) 引入了启发式的图像像素抽样方法；3) 创造性地使用了双梯度掩码来保护 LiDAR 点的局部特征。通过在 KITTI-360 数据集上的实验，结果显示与基线模型相比，本框架在 LiDAR 和相机模态上均表现最佳。", "conclusion": "本研究提出的基于 NeRF 的 NVSF 对于混合多模态的自动驾驶场景实现了时空场景的高效表示，并且通过自监督的方式消除了对3D标签的需要。实验结果表明，该框架在 LiDAR 和相机模态上都取得了最佳表现，具有快速收敛和高效训练的特点。"}
{"llm_update_time": "2025-06-25 09:20:36", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19651", "html_url": "https://arxiv.org/abs/2506.19651", "title": "PEVLM: 平行编码用于视觉语言模型", "title_en": "PEVLM: Parallel Encoding for Vision-Language Models", "authors": "Letian Kang,Shixian Luo,Yiqiang Li,Xiaoyang Yu,Shenxuan Zhou,Yong Wu", "background": "视觉语言模型（VLMs）在视频语言任务方面表现出色，但在处理长视频理解时受到标准注意力机制二次复杂度的限制。现有方法难以在无需模型微调的情况下改进VLM的预填充效率。因此，高效地处理长视频理解成为一个亟待解决的问题。", "innovation": "提出了一种称为PEVLM的并行编码策略，设计目的在于在不需要微调模型的情况下提高VLM的预填充效率。PEVLM将输入分割为块状段并共享终点，保留全注意力位置嵌入，并对注意力权重进行对齐以模拟全注意力分布。这使得注意力计算从$O((T \times N)^2)$减少到$O(T \times N)$，同时保持高精度。", "conclusion": "PEVLM在长视频基准（LongVideoBench）上的广泛实验表明，它比现有高效推理方法实现了高达8.37%的准确性改进，并提供了高达7.47倍的注意力计算加速和40%的端到端延迟减少。在严格的延迟限制下，PEVLM显著优于基线，将准确性从23.26%提高到61.03%，突显了其在低延迟、长上下文视频理解方面的有效性，适用于自动驾驶等实际应用场景。"}
{"llm_update_time": "2025-06-25 09:20:40", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19658", "html_url": "https://arxiv.org/abs/2506.19658", "title": "SAM2-SGP: 通过支持集导向的提示提高段任何模型2在医学图像分割中的性能", "title_en": "SAM2-SGP: Enhancing SAM2 for Medical Image Segmentation via Support-Set Guided Prompting", "authors": "Yang Xing,Jiong Wu,Yuheng Bu,Kuang Gong", "background": "尽管像Segment Anything Model 2 (SAM2)这样的新型视觉基础模型大大提升了零样本图像分割能力，但依赖于人工提供的提示导致难以将SAM2适应于医学图像分割任务。此外，SAM2在医学图像分割上的性能受到领域偏移问题的影响，因为该模型原本是通过自然图像和视频进行训练的。", "innovation": "该论文提出了一个名为SAM2-SGP的框架，通过支持集导向的提示消除了对人工提示的依赖。该模型利用SAM2的记忆机制，通过Pseudo-mask Generation (PMG)模块利用支持集中的图像-掩码对生成伪掩模。此外，引入了Pseudo-mask Attention (PMA)模块，可以利用这些伪掩模自动生成边界框，提升局域特征提取。同时，采用了低秩适应（LoRA）策略来缓解领域偏移问题。该框架在多种医学成像模态的2D和3D数据集上进行了评估，相较于最先进的模型（如nnUNet和SwinUNet）以及基础模型（如SAM2和MedSAM2），展示了显著的性能提升。", "conclusion": "所提出的框架在多种医学成像模态的数据集上评估，结果显示了与先进模型相比在医学图像分割任务上的显著性能改进，证明了该方法的有效性。"}
{"llm_update_time": "2025-06-25 09:20:43", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19681", "html_url": "https://arxiv.org/abs/2506.19681", "title": "基于基因组锚定的基座模型嵌入增强组织图像中的分子预测", "title_en": "Genome-Anchored Foundation Model Embeddings Improve Molecular Prediction from Histology Images", "authors": "Cheng Jin,Fengtao Zhou,Yunfang Yu,Jiabo Ma,Yihui Wang,Yingxue Xu,Huajun Zhou,Hao Jiang,Luyang Luo,Luhui Mao,Zifan He,Xiuming Zhang,Jing Zhang,Ronald Chan,Herui Yao,Hao Chen", "background": "精准肿瘤学需要准确的分子见解，但从基因组直接获得这些见解在广泛临床应用中代价高昂且耗时。当前的深度学习方法难以直接从常规全切片图像（WSI）中预测复杂的分子特征和患者预后。", "innovation": "PathLUPI在训练过程中利用转录本特权信息提取基因锚定的组织嵌入，能够在仅使用WSIs进行推断时有效进行分子预测。PathLUPI在14项生物标志物预测和分子亚型化任务中表现优异，AUC $\boldsymbol{\text{≥0}}$ 0.80，在5种主要癌症类型的生存队列中C指数$\boldsymbol{\text{≥}}$0.70。此外，PathLUPI嵌入展示了与特定基因型和相关生物途径相关的独特细胞形态特征。", "conclusion": "PathLUPI通过有效编码分子上下文来细化WSI表示，克服了现有模型的关键局限性，为将分子见解与常规病理工作流程相结合以更广泛的临床应用提供了新的策略。"}
{"llm_update_time": "2025-06-25 09:20:43", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19665", "html_url": "https://arxiv.org/abs/2506.19665", "title": "基于递归视觉特征提取和立体注意力的CT报告生成", "title_en": "Recurrent Visual Feature Extraction and Stereo Attentions for CT Report Generation", "authors": "Yuanhe Tian,Lei Mao,Yan Song", "background": "CT图像报告生成是一个具有挑战的任务，尽管与现有医学图像报告生成的研究类似，但CT图像具有独特的特性，如多图像的空间编码和图像体积与文本的对齐等等。现有的解决方案通常使用通用的2D或3D图像处理技术来从CT体积中提取特征，这些方法首先压缩体积，然后将压缩的CT切片分割成块进行视觉编码。这些方法并没有明示地考虑CT切片之间的变换，也没有有效地整合多级图像特征，特别是那些包含特定器官病变的特征，以指导CT报告生成（CTRG）。鉴于CT扫描中连续切片之间的强相关性，本文提出了一种基于大规模语言模型（LLM）的CTRG方法，该方法具有递归视觉特征提取和立体注意力，以实现层次特征建模。", "innovation": "本文提出的方法使用视觉变换器递归处理CT体积中的每个切片，并通过不同视角的注意力机制选择性地获取重要视觉信息并与文本特征对齐，以更好地指导大规模语言模型进行CTRG。该方法在基准M3D-Cap数据集上的实验结果表明，与其他强基线模型相比，它可以取得最先进的性能，证明了其有效性和适用性。", "conclusion": "本文提出了一种基于递归视觉特征提取和立体注意力的CTRG方法，通过视觉变换器递归处理切片，并利用多视角的注意力机制获取重要视觉信息，有效地指导大规模语言模型进行CT报告生成。实验结果表明，该方法优于现有的基线模型，达到了最先进的水平，证明了其有效性和适用性。"}
{"llm_update_time": "2025-06-25 09:20:44", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19798", "html_url": "https://arxiv.org/abs/2506.19798", "title": "CoCo4D：全面而复杂的4D场景生成", "title_en": "CoCo4D: Comprehensive and Complex 4D Scene Generation", "authors": "Junwei Zhou,Xueting Li,Lu Qi,Ming-Hsuan Yang", "background": "现有的4D合成方法主要集中在对象级生成或具有有限新颖视点的动态场景合成上，限制了其生成多视角一致和沉浸式的4D动态场景的能力。这种局限性来源于4D场景合成方法通常无法全面处理复杂的动态背景变化和多样化前景对象的细节。", "innovation": "本文提出了一个名为CoCo4D的框架，该框架能够从文本提示生成详细的动态4D场景，可以包括图像。CoCo4D的关键创新在于将4D场景合成分为两个任务：建模动态前景和创建演变背景，二者都由参考运动序列指导。通过利用视频扩散模型生成初始运动序列，并结合新颖的渐进性插画方案，CoCo4D能够优化前景的参数轨迹，实现真实且连贯的融合，从而大大增强了生成的4D场景的质量和一致性。", "conclusion": "大量实验表明，CoCo4D在4D场景生成方面的性能与现有方法相当或更优，充分展示了其有效性和效率。更多结果可以在我们的网站上找到：this https URL。"}
{"llm_update_time": "2025-06-25 09:20:46", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19683", "html_url": "https://arxiv.org/abs/2506.19683", "title": "超声图像解释和扫描指导的语义场景图", "title_en": "Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance", "authors": "Xuesong Li,Dianye Huang,Yameng Zhang,Nassir Navab,Zhongliang Jiang", "background": "理解医学超声成像因成像和采集参数的显著视觉差异而仍是一个长期的挑战。尽管大型语言模型（LLMs）在自动生成旨在临床医师的生理知识丰富的术语总结方面取得了进展，但非专家用户，例如在临床上点对点的场景下，对增强超声解释性及基本扫描指导的需求尚未得到探索。因此，本研究引入了超声场景图（SG）来解释超声图像内容，为普通用户提供扫描指导，以消除使用对象检测的需要，并通过LLMs进一步细化SG的抽象表示，以生成普通用户可以理解的图像解释。此外，还探索了预测的SG在指导超声扫描以发现当前成像视图中的缺失解剖结构方面的潜力，以帮助普通用户实现更为标准化和完整的解剖探索。该研究在五个志愿者的颈部左部和右部图像（包括颈动脉和甲状腺）上验证了SG基于的图像解释和扫描指导的有效性。结果表明该方法具有最大限度地普及超声成像的潜力，通过增强超声解释性和易用性，使其适合普通用户使用。", "innovation": "首先使用基于变压器的一阶段方法计算超声场景图（SG），消除了必需的物体检测。然后利用用户查询通过LLMs进一步细化SG的抽象表示，生成普通用户可以理解的图像解释。此外，探索了预测的SG来引导超声扫描以发现当前成像视图中的缺失解剖结构，以帮助普通用户更标准化和彻底地探索解剖结构。该研究在验证这种方法的有效性方面取得了进展，特别是在非专家用户群体中提高了超声成像的解释性和易用性。", "conclusion": "本研究提出的方法通过生成基于用户查询的超声SG解释和扫描指导，展示了在提高超声成像可解释性和易用性方面的潜力，尤其适用于非专家用户。该方法的有效性在颈部左部和右部的超声图像验证中得到了证实，表明该方法能够最大限度地普及超声成像。"}
{"llm_update_time": "2025-06-25 09:20:46", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19694", "html_url": "https://arxiv.org/abs/2506.19694", "title": "UltaAD: 通过少量CLIP调整实现细粒度超声异常分类", "title_en": "UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation", "authors": "Yue Zhou,Yuan Bi,Wenjuan Tong,Wei Wang,Nassir Navab,Zhongliang Jiang", "background": "精确的医学图像异常检测对于临床决策至关重要。虽然近期的无监督或半监督异常检测方法在大量正常数据上表现出色，但这些方法缺乏精细化识别，如良性与恶性肿瘤的区别。此外，超声（US）成像对设备和采集参数的变化非常敏感，导致US图像之间存在显著的领域差异。这些挑战阻碍了异常检测的准确性和可靠性。因此，需要一种能够解决这些挑战的方法来提升超声成像中异常检测的精细度和准确性。", "innovation": "我们提出了UltraAD，这是一种基于视觉语言模型（VLM）的方法，利用少量的超声图像样例进行泛化的异常定位和精细化分类。方法首先将查询视觉原型的图像级标记与可学习的文本嵌入融合，生成图像告知提示特征，然后进一步与补丁级标记融合，提升局部表示以提高准确性。为了实现精细化分类，从少量图像样本和相应的文本描述构建了一个记忆库，以捕获解剖学和异常特征。训练过程中，存储的文本嵌入保持不变，而图像特征则被调整以更好地与医学数据对齐。该方法在三个乳腺US数据集上进行了广泛评估，已经超越了最先进的方法，无论是病变定位还是精细化医疗分类。", "conclusion": "UltraAD在乳腺US数据集上广泛评估后，显示出在病变定位和精细化医疗分类方面优于现有方法。未来研究将进一步探索在更多医学图像数据上的应用。代码将在论文被接受后公开。"}
{"llm_update_time": "2025-06-25 09:20:47", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19833", "html_url": "https://arxiv.org/abs/2506.19833", "title": "绑定你的头像：基于动态3D-掩码嵌入路由器的多角色对话视频生成", "title_en": "Bind-Your-Avatar: Multi-Talking-Character Video Generation with Dynamic 3D-mask-based Embedding Router", "authors": "Yubo Huang,Weiqiang Wang,Sirui Zhao,Tong Xu,Lin Liu,Enhong Chen", "background": "近年来，基于音频的头部生成技术取得了显著进展，但现有方法大多集中在单一角色场景上。虽然有些方法可以创建两个人之间的对话视频，但在同一个空间环境中生成多个物理共现角色的统一对话视频仍然面临关键挑战，包括音频与角色的对应控制以及缺乏多角色对话视频的合适数据集。", "innovation": "本文介绍了基于MM-DiT模型的Bind-Your-Avatar，专门用于同一场景内多角色对话视频生成。文中提出了一种新颖框架，包含细粒度嵌入路由器，解决了音频与角色对应控制的问题；还提出了一种3D-掩码嵌入路由器的实现方法，用于帧级细粒度控制个体角色，并配有基于观测几何先验的损失函数及掩码细化策略，以提升预测掩码的准确性和时间连续性。此外，该论文还构建了第一个专为多角色对话视频生成设计的数据集，配有开源的数据处理流水线，并提出了双角色对话视频生成基准，实验结果表明优于多种现有先进方法。", "conclusion": "本文提出的方法在双角色对话视频生成上实现了卓越性能，不仅解决了一些关键问题，还提供了第一个适应多角色对话视频生成的数据集，具有很大的研究价值和应用潜力。"}
{"llm_update_time": "2025-06-25 09:20:50", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19747", "html_url": "https://arxiv.org/abs/2506.19747", "title": "系统性比较针孔、等距和双球模型以及柱形投影方法在鱼眼图像上单目3D人体姿态估计中的应用", "title_en": "Systematic Comparison of Projection Methods for Monocular 3D Human Pose Estimation on Fisheye Images", "authors": "Stephanie Käs,Sven Peter,Henrik Thillmann,Anton Burenko,David Benjamin Adrian,Dennis Mack,Timm Linder,Bastian Leibe", "background": "鱼眼相机能够为机器人提供一个更宽的视野（FOV），使其在人类-机器人互动和汽车领域尤为重要。然而，由于鱼眼透镜固有的弯曲畸变，准确地在鱼眼图像中检测人类姿态极具挑战性。尽管已经提出了各种鱼眼图像去畸变的方法，但它们对于覆盖广视角的人类姿态估计的有效性和限制并未在单一鱼眼相机进行绝对人体姿态估计中进行系统评估。为此，本文评估了针孔、等距和双球相机模型，以及柱形投影方法，对3D人体姿态估计准确性的影响。结果显示，在近距离情况下，针孔投影是不合适的，并且最优投影方法随人类姿态覆盖的FOV不同而变化。采用先进的鱼眼模型（如双球模型）可以显著提高3D人体姿态估计的准确性。我们提出了一种基于检测边界框选择合适的投影模型的启发式方法，以提高预测质量。此外，还引入并评估了我们新型数据集FISHnCHIPS，其中包括针眼图像中的人体骨架注释，涉及从非常规角度获取的数据，例如极端近距离拍摄、地面安装相机和广视角姿态，数据可从此链接下载：this https URL", "innovation": "本文系统性地对比了针孔、等距和双球相机模型以及柱形投影方法在鱼眼图像上单目3D人体姿态估计中的应用。提出了基于检测边界框选择合适的投影模型的启发式方法，以提高预测质量，并引入了新颖的数据集FISHnCHIPS，其中包括从非常规角度获取的数据。", "conclusion": "最优的投影方法在一定程度上取决于人类姿态覆盖的FOV。采用了先进鱼眼模型（如双球模型）可以显著提高3D人体姿态估计的准确性，引入了启发式方法用于选择合适的投影模型，并提出了用于评测的新型数据集FISHnCHIPS。"}
{"llm_update_time": "2025-06-25 09:20:51", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19840", "html_url": "https://arxiv.org/abs/2506.19840", "title": "GenHSI: 控制生成人类-场景交互视频", "title_en": "GenHSI: Controllable Generation of Human-Scene Interaction Videos", "authors": "Zekun Li,Rui Zhou,Rahul Sajnani,Xiaoyan Cong,Daniel Ritchie,Srinath Sridhar", "background": "大型预训练视频扩散模型在多种视频生成任务中表现出显著的能力。然而，现有的解决方案在生成包含丰富的人物-场景交互的长电影式视频时面临挑战，包括不合理的交互、缺乏主体身份保留以及需要昂贵的训练成本。", "innovation": "本文提出了一种无需训练的方法GenHSI，用于控制生成长时间的人类-场景交互视频（HSI）。通过借鉴电影动画的理念，该方法将长视频生成任务细分为三个阶段：（1）剧本编写，（2）前期可视化，（3）动画制作。该方法利用现有的3D视频扩散模型对单视角图像生成的3D关键帧进行渲染和动画处理，从而生成长视频并保持人物身份和丰富的交互效果，无需扫描准确的场景即可生成3D关键帧。", "conclusion": "实验结果表明，本文的方法可以生成有效保留场景内容、人物身份和合乎逻辑的人类-场景交互的长视频，且无需使用多个视角的图像。该方法首次无训练生成了一个具有固定摄像机姿势且包含任意数量角色动作的长视频序列。访问项目主页可以获取更多详细信息。"}
{"llm_update_time": "2025-06-25 09:20:54", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19585", "html_url": "https://arxiv.org/abs/2506.19585", "title": "SMARTIES:谱感知多传感器自编码器用于遥感影像", "title_en": "SMARTIES: Spectrum-Aware Multi-Sensor Auto-Encoder for Remote Sensing Images", "authors": "Gencer Sumbul,Chang Xu,Emanuele Dalsasso,Devis Tuia", "background": "遥感（RS）传感器，从光学传感器到微波雷达，具有互补的优势，但近年来的任务特定或基础深度学习模型往往针对单个传感器或固定组合。这些模型如果要适应不同的传感器输入，则需要进行架构更改和重新训练，这限制了其在多RS传感器间的可扩展性和泛化能力。因此，一个能够调整其特征表示以接受不同RS传感器输入的单个模型将开辟多传感器RS数据处理的灵活性和敏捷性新途径。", "innovation": "本文介绍了一种通用且多功能的基础模型SMARTIES，它提升了针对特定传感器的努力，使得RS传感器数据处理可扩展和泛化。SMARTIES通过将异构传感器数据投影到共享的频谱感知空间，使任意组合的波段在训练和推理中都能被使用。通过统一训练一个变压器模型重建多传感器数据并使用跨传感器令牌混合，SMARTIES能够获得不依赖传感器的表示。实验结果表明，在单模态和多模态任务上，SMARTIES在各种传感器的基准模型中表现出优越性。为此，提供了代码和预训练模型。", "conclusion": "SMARTIES通过在共享的频谱感知空间中投影数据并使用统一的变压器模型来实现跨传感器的鲁棒性和多样化的处理，其优于依赖于特定传感器预训练的模型。该研究为多传感器RS数据处理提供了新的范式。"}
{"llm_update_time": "2025-06-25 09:20:54", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19839", "html_url": "https://arxiv.org/abs/2506.19839", "title": "使用可分解流匹配改进渐进生成", "title_en": "Improving Progressive Generation with Decomposable Flow Matching", "authors": "Moayed Haji-Ali,Willi Menapace,Ivan Skorokhodov,Arpit Sahni,Sergey Tulyakov,Vicente Ordonez,Aliaksandr Siarohin", "background": "生成高维视觉模态是一个计算密集型任务。常用的方法是分阶段生成，即以粗粒度到细粒度的光谱自回归方式进行合成。虽然扩散模型从去噪的粗到细特性中获益，但显式的多阶段架构却很少被采用。这些架构增加了整体方法的复杂性，导致需要定制扩散公式、依赖分解阶段转换、自定义采样器或模型级联。", "innovation": "我们的贡献，可分解流匹配（DFM），是一种简单有效的框架，用于多尺度表示（如Laplacian金字塔）的分阶段生成视觉媒体。DFM在每个层级上独立应用Flow Matching，实验结果表明，该方法在图像和视频方面提升了视觉质量，与之前的多阶段框架相比表现更优。DFM在Imagenet-1k 512px基准上，达到了基线架构35.2%的FDD分数改进和最佳基线26.4%的改进。在大规模模型微调中，DFM显示了更快的收敛速度。所有这些优势都通过单一模型、架构简洁性和对现有训练管道的最小修改实现。", "conclusion": "DFM在保持简单架构的同时取得了显著的性能提升，适用于图像和视频生成，加快了大规模模型的训练收敛，使用了相同的训练计算量。"}
{"llm_update_time": "2025-06-25 09:20:55", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19845", "html_url": "https://arxiv.org/abs/2506.19845", "title": "NAFNet基线模型在图像恢复中的比较研究", "title_en": "A Comparative Study of NAFNet Baselines for Image Restoration", "authors": "Vladislav Esaulov,M. Moein Esfahani", "background": "研究NAFNet（非线性激活自由网络），这是一种用于图像恢复的简单高效深度学习基线模型。通过使用 CIFAR10 图像添加噪声和模糊的方式进行数据污染，对NAFNet的核心组件进行了消融研究。基线模型实现了SimpleGate激活、简化通道激活（SCA）和层标准化。与移除或替换组件的不同变体进行了对比，展示了每个修改如何影响恢复性能。", "innovation": "NAFNet基线模型通过SimpleGate激活和简化注意力机制，与常规激活和注意力机制相比，在图像恢复任务上表现更好。此外，研究发现，层标准化对于稳定的训练过程非常重要。", "conclusion": "研究为模型设计提出了建议，讨论了潜在改进以及未来的工作方向。"}
{"llm_update_time": "2025-06-25 09:20:57", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19808", "html_url": "https://arxiv.org/abs/2506.19808", "title": "单一原型足矣：单原型激活促进可解释图像分类", "title_en": "One Prototype Is Enough: Single-Prototype Activation for Interpretable Image Classification", "authors": "Yitao Peng,Lianghua He,Die Hu", "background": "现有原型网络依赖多个原型的协作决策来实现单种类别的分类和解析。然而，这种方法增加了认知复杂性。本文提出了一种名为 ProtoSolo 的新方法，通过仅激活一个原型即可完成分类，简化了解释过程。ProtoSolo 使用特征图而非全通道特征向量进行相似度比较和原型学习，从而降低解释的认知复杂性。此外，它还提出了一种非原型投影学习策略，这种策略保留了原型与训练图像块之间的信息关联，避免了由于投影操作引起的网络结构变化，从而不会对分类性能产生负面影响。实验结果表明，ProtoSolo 在分类任务中表现出色，且在解释的认知复杂性方面达到了最佳水平，高于现有可解释方法的性能水平。", "innovation": "1. 仅通过激活一个原型完成分类，从而大幅减少解释的认知复杂性。2. 使用特征图而非全通道特征向量作为相似度比较和原型学习的对象，利用更丰富的全局信息促进分类。3. 提出非原型投影学习策略，保留原型与训练图像块间的信息关联，同时避免投影操作引起的网络结构变化，防止对分类性能的负面影响。", "conclusion": "在 CUB-200-2011 和斯坦福汽车数据集上的实验结果表明，ProtoSolo 在分类任务中的性能优于现有最先进的可解释方法，并且在解释的认知复杂性方面达到了最佳水平。"}
{"llm_update_time": "2025-06-25 09:20:58", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19848", "html_url": "https://arxiv.org/abs/2506.19848", "title": "ScaleCap：通过双模态去偏实现的推理时可扩展图像字幕", "title_en": "ScaleCap: Inference-Time Scalable Image Captioning via Dual-Modality Debiasing", "authors": "Long Xing,Qidong Huang,Xiaoyi Dong,Pan Zhang,Yuhang Zang,Yuhang Cao,Jinsong Li,Shuangrui Ding,Weiming Zhang,Nenghai Yu,Jiaqi Wang,Feng Wu,Dahua Lin", "background": "高质量的图像字幕生成面临着多模态偏差和语言偏差的挑战：多模态偏差导致描述性粒度不平衡，对某些元素给出详细的描述，而对其他元素则很简略；语言偏差则可能导致对不存在的物体进行虚假描述。现有的解决方案未能有效解决这些问题，因此需要一种能够随推理预算增加而不断丰富和校准字幕的策略，以生成更准确、平衡且详尽的图像字幕。", "innovation": "提出了一种可扩展的目标去偏的图像字幕策略——ScaleCap，通过两个新颖的组件：启发式问答和对比句评价，连续丰富和校准字幕。这些组件在字幕生成过程中逐步引入相关的信息，并有效识别和消除语言偏差导致的虚假描述。随着推理成本的增加，ScaleCap 会提出更多的启发式问题，逐步捕捉更多视觉细节，生成更准确、平衡且详细的字幕。", "conclusion": "扩展规模的双模态去偏实验表明了 ScaleCap 的有效性。使用 ScaleCap 注释的 450,000 张图像进行 LVLM 预训练，在 11 个广泛使用的效果评估基准上均有持续的性能改进。此外，ScaleCap 还展现了生成字幕的丰富性和真实性。"}
{"llm_update_time": "2025-06-25 09:21:01", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19850", "html_url": "https://arxiv.org/abs/2506.19850", "title": "统一的视觉-语言-动作模型", "title_en": "Unified Vision-Language-Action Model", "authors": "Yuqi Wang,Xinghang Li,Wenxuan Wang,Junbo Zhang,Yingyan Li,Yuntao Chen,Xinlong Wang,Zhaoxiang Zhang", "background": "视觉-语言-动作模型（VLAs）因其在推动机器人操作方面的潜力而受到广泛关注。然而，之前的方法主要依靠视觉语言模型（VLMs）的一般理解能力来生成动作信号，忽视了视觉观察中丰富的时空因果结构。本文在此背景下提出了UniVLA模型，这是一种统一且原生的多模态VLA模型，它使用自回归方式处理视觉、语言和动作信号作为离散的标记序列，尤其适合大规模视频数据的学习任务。", "innovation": "UniVLA模型在训练后整合世界建模，从视频中捕捉因果动态，并有效转移到下游策略学习，特别适用于长期任务。该方法在广泛使用的模拟基准测试CALVIN、LIBERO和Simplenv-Bridge上取得了新的最好结果，显著优于之前的方法。例如，UniVLA在LIBERO基准测试中的平均成功率为95.5%，大大超过了pi0-FAST的85.5%。而且，还展示了其在现实世界的ALOHA操作和自动驾驶中的广泛应用前景。", "conclusion": "UniVLA模型在多个广泛使用的模拟基准测试中取得了新最好的结果，显著优于之前的方法，并且在现实世界的多种操作任务中展示了其广泛的应用前景。"}
{"llm_update_time": "2025-06-25 09:21:02", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19844", "html_url": "https://arxiv.org/abs/2506.19844", "title": "基于交叉引用图像质量评估的快速准确主动视角选择", "title_en": "Active View Selector: Fast and Accurate Active View Selection with Cross Reference Image Quality Assessment", "authors": "Zirui Wang,Yash Bhalgat,Ruining Li,Victor Adrian Prisacariu", "background": "现有的视角选择方法如FisheRF和ActiveNeRF通过最小化不确定性或最大化信息增益来选择最优视角，但在3D空间中需要对不同的3D表示进行专门设计，过程较为复杂。如今的视图选择方法依赖于特定的3D表示形式，且在多视图环境下的信息缺乏处理能力。因此，需要一种新的方法来选择最优视角，既能简化选择过程，又能利用多视图信息。", "innovation": "提出了一种基于交叉引用图像质量评估的视角选择方法，该方法通过多视图设置训练模型来预测SSIM，并利用该模型指导视角选择。这种方法不仅能够克服传统方法对3D表示形式的依赖问题，还在标准基准测试中实现了显著的定量和定性改进，同时运行速度比现有方法快14-33倍，不再依赖专门设计，无需复杂3D建模，适合多视图环境下的视图选择场景。", "conclusion": "综合来说，这种方法显著提高了视图选择的效率和准确性，改变了传统视图选择方法的依赖性问题，并且通过多视图成像的质量评估框架实现了诸多标准测试中的改进，表现出良好的适用性和广阔的应用前景。"}
{"llm_update_time": "2025-06-25 09:21:02", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19851", "html_url": "https://arxiv.org/abs/2506.19851", "title": "AnimaX: 通过联合视频-姿态扩散模型在3D中赋予无生命物体以动画", "title_en": "AnimaX: Animating the Inanimate in 3D with Joint Video-Pose Diffusion Models", "authors": "Zehuan Huang,Haoran Feng,Yangtian Sun,Yuanchen Guo,Yanpei Cao,Lu Sheng", "background": "传统的运动合成方法要么受限于固定的骨骼拓扑结构，要么需要在高维变形空间中进行昂贵的优化。传统的3D动画框架通常需要专业的建模和动画工具，或依赖于经典的骨骼动画方法，这些方法在处理多样化的articulated mesh（即带有关节的模型）和任意骨骼结构时存在局限性。", "innovation": "AnimaX引入了一种前馈3D动画框架，它将视频扩散模型的动力学先验知识与基于骨骼的动画控制结构相结合。它通过多视图、多帧2D姿态图表示3D运动，并能在模板渲染和文本运动提示下联合视频-姿态扩散。AnimaX通过共享位置编码和模态感知嵌入确保视频和姿态序列之间的空间-时间对齐，有效地将视频先验知识转移到运动生成任务。", "conclusion": "通过在包含160,000个绑定序列的新自定义数据集上进行训练，AnimaX在Generalization（泛化能力）、Motion Fidelity（运动保真度）和Efficiency（效率）方面取得了前沿成果，提供了一种适用于各种类别的3D动画的可扩展解决方案。"}
{"llm_update_time": "2025-06-25 09:21:06", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19051", "html_url": "https://arxiv.org/abs/2506.19051", "title": "NIC-RobustBench: 一个全面的开源工具包，用于神经图像压缩和鲁棒性分析", "title_en": "NIC-RobustBench: A Comprehensive Open-Source Toolkit for Neural Image Compression and Robustness Analysis", "authors": "Georgii Bychkov,Khaled Abud,Egor Kovalev,Alexander Gushchin,Dmitriy Vatolin,Anastasia Antsiferova", "background": "神经网络对抗鲁棒性是计算机视觉模型、大规模语言模型（LLMs）和其他模型研究中的一个重要领域，特别是在神经图像压缩（NIC）方法中，随着JPEG AI标准的发布，评估NIC鲁棒性变得至关重要。然而，之前的研究仅限于少数几类编解码器和攻击方法，这使得评价NIC鲁棒性变得有限。因此，本文提出了NIC-RobustBench，首个开源框架，用于评估NIC鲁棒性，同时比较速率-失真（RD）性能，并首次包含所有已知NIC库中最多的编解码器种类，极其易于扩展。", "innovation": "本研究通过提出NIC-RobustBench，首次为NIC编解码器提供一个开源评价框架，该框架涵盖了迄今为止最多的编解码器种类，来自两大知名NIC库：Minkino和NICPiper。同时，该框架还包括了对抗防御效率的比较，无论是在当前库的背景下还是作为WAVENET API的一部分，从而填补了研究领域的空白。NIC-RobustBench提供了一个全面的视角来理解NIC的鲁棒性，并通过实验证明其有效性。其代码已公开可用。", "conclusion": "本文介绍了NIC-RobustBench，该框架旨在提供一个全面且开放的方式，用于评估NIC编解码器的鲁棒性以及其在对抗攻击下的防御效果。通过引入NIC-RobustBench，研究者能够更好地理解和改进神经图像压缩系统的抗干扰能力。"}
{"llm_update_time": "2025-06-25 09:21:06", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19852", "html_url": "https://arxiv.org/abs/2506.19852", "title": "Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for Long Video Generation", "title_en": "Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for Long Video Generation", "authors": "Xingyang Li,Muyang Li,Tianle Cai,Haocheng Xi,Shuo Yang,Yujun Lin,Lvmin Zhang,Songlin Yang,Jinbo Hu,Kelly Peng,Maneesh Agrawala,Ion Stoica,Kurt Keutzer,Song Han", "background": "近期在视频生成中的扩散模型取得了显著进展，但时间维度的引入增加了计算成本，使得长时间视频的训练和推理变得极为昂贵。分析表明，视频扩散模型中的时空能量衰减现象使得后续softmax注意力分数随着空间和时间距离的增加而递减，类似于自然界的信号或波在时间与空间中的衰减。", "innovation": "本文提出了一个具有$O(n \\log n)$复杂度的可扩展稀疏注意力机制——Radial Attention，将能量衰减转化为指数衰减的计算密度，并可通过LoRA方式进行高效微调，使得预训练的视频扩散模型能够生成更长的视频。相比于标准的$O(n^2)$密集注意力机制，Radial Attention更高效，同时也比线性注意力更具表达性。实验结果显示，在保持视频质量的同时，它比原始的密集注意力机制快1.9倍，且可将训练成本降低4.4倍，生成视频长度增加4倍，推理加速3.7倍。", "conclusion": "本文提出了Radial Attention机制，通过采用一种简单的静态注意力掩码，在每个token仅关注空间上近邻的token，并随着时间距离的增加使注意窗口减小，从而实现能量衰减到计算密度的转换，显著提高了计算效率，且在不大幅改动下可显著延长视频生成长度，降低训练成本，并加速推理。"}
{"llm_update_time": "2025-06-25 09:21:06", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18919", "html_url": "https://arxiv.org/abs/2506.18919", "title": "MemeMind: 一种具有链式思维方式的大规模多模态数据集，用于有害梗图检测", "title_en": "MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection", "authors": "Hexiang Gu,Qifan Yu,Saihui Hou,Zhiqin Fang,Huijia Wu,Zhaofeng He", "background": "社交媒体的快速发展加剧了有害内容的传播。有害梗图集成了图像和文本，由于其隐含语义和复杂的多模态交互，自动化检测仍面临巨大挑战。尽管现有研究在检测准确性和可解释性方面取得了进步，但缺乏系统、大规模、多样且高度可解释的数据集仍然阻碍着该领域的进一步进步。", "innovation": "本文引入了一个名为MemeMind的新颖数据集，该数据集具有科学严谨的标准、大规模、多样性、双语支持（中文和英文）以及详细的链式思考（CoT）标注。MemeMind填补了现有数据集中的关键空白，提供了全面的标签和显式的推理踪迹，从而为改善有害梗图检测奠定了坚实的基础。此外，本文还提出了一种创新的检测框架MemeGuard，有效地将多模态信息与推理过程建模相结合，显著提升了模型对有害梗图的理解和识别能力。", "conclusion": "在MemeMind数据集上进行的广泛实验表明，MemeGuard在有害梗图检测任务中始终优于现有的前沿方法。"}
{"llm_update_time": "2025-06-25 09:21:10", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19055", "html_url": "https://arxiv.org/abs/2506.19055", "title": "Xray2Xray: 从胸部X光图像构建具有体积上下文的世界模型", "title_en": "Xray2Xray: World Model from Chest X-rays with Volumetric Context", "authors": "Zefan Yang,Xinrui Song,Xuanang Xu,Yongyi Shi,Ge Wang,Mannudeep K. Kalra,Pingkun Yan", "background": "胸部X光图像（CXR）是最常用的医学成像技术，对疾病诊断至关重要。但由于其作为2D投影图像的局限性，如结构重叠，这些图像在精确疾病诊断和风险预测方面效果受限。为解决2D CXR的限制，该研究引入了Xray2Xray，一种新颖的世界模型，从胸部X光图像中学习编码3D结构信息的潜在表示。Xray2Xray通过建模不同角度位置的X射线投影的转换动力学，捕捉到胸部体积的潜在表示。在下游风险预测和疾病诊断任务中，我们使用了Xray2Xray的潜在表示进行了这些任务。实验结果表明，Xray2Xray在心血管疾病风险估计方面优于监督方法和自主监督预训练方法，并在分类5种病理方面达到可竞争的性能。我们还通过合成任务评估了Xray2Xray潜在表示的质量，并表明这些潜在表示可以用于重建体积环境.", "innovation": "Xray2Xray是一种新颖的世界模型，能够从胸部X光图像中学习3D结构信息的潜在表示，通过建模不同角度位置的X射线投影的转换动力学来捕捉胸部体积的潜在表示，并在心血管疾病风险估计和病理分类中表现出色，超越了监督学习和自监督预训练方法。此外，Xray2Xray的潜在表示可以重建体积环境，具有潜在的重建能力。", "conclusion": "Xray2Xray通过潜在表示学习和建模不同角度位置的X射线投影的转换动力学，有效地克服了2D CXR的结构重叠限制，提升了心血管疾病风险估算和病理分类的性能。"}
{"llm_update_time": "2025-06-25 09:21:12", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19167", "html_url": "https://arxiv.org/abs/2506.19167", "title": "基于深度学习的快速心脏磁共振图像配准方法", "title_en": "A Deep Learning Based Method for Fast Registration of Cardiac Magnetic Resonance Images", "authors": "Benjamin Graham", "background": "图像配准广泛应用于医学图像分析，比如心脏图像中组织运动的跟踪，心脏运动可以成为组织健康的一个指标。由于地上真值变换难以创建，且可能存在多种变换可以产生与目标相关的图像，因此图像配准对深度学习算法具有挑战性。尽管提出了无监督方法来学习预测有效的变换，但这些方法的预测速度明显慢于已建立的基本方法。因此，设计在常规硬件上能合理时间内运行的深度学习方法对于其在研究和临床环境中的广泛采用至关重要。已经提出了用于图像配准的快速方法，但这些方法往往使用基于补丁的方法，这可能会影响心脏等动态器官的配准精度。", "innovation": "本文提出了一种快速、体积配准模型，用于评估心脏应变。所提出的深度学习神经网络（DLNN）设计为利用一个能极其高效地计算卷积的架构，使模型能够在与最先进的模型相似的配准精度的同时，花费极少的时间进行推理。提出的快速轻量级注册（FLIR）模型用于预测组织运动，进而量化组织经历的非均匀应变。使用从同一患者在大约相同时间段获取的图像，应变值之间的差异应该是非常小的。使用这种方法计算的应变值显示非常一致。", "conclusion": "使用FLIR方法计算的应变值具有很高的一致性，表明FLIR方法在心脏磁共振图像配准中表现出良好的效果和可重复性。"}
{"llm_update_time": "2025-06-25 09:21:15", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19234", "html_url": "https://arxiv.org/abs/2506.19234", "title": "数字病理图像中异常检测方法的定量基准", "title_en": "Quantitative Benchmarking of Anomaly Detection Methods in Digital Pathology", "authors": "Can Cui,Xindong Zheng,Ruining Deng,Quan Liu,Tianyuan Yao,Keith T Wilson,Lori A Coburn,Bennett A Landman,Haichun Yang,Yaohong Wang,Yuankai Huo", "background": "在工业缺陷检测的背景下，异常检测已得到广泛研究，开发了多种方法应对各种挑战。在数字病理领域，异常检测对于稀有疾病识别、伪影检测和生物标志物发现具有巨大潜力。然而，病理图像的独特特征，如大尺寸、多层次结构、染色变异和重复图案，引入了新的挑战，现有的异常检测算法难以解决这些问题。为了应对这些问题，本文通过大量实验对标记为经典和广泛应用的20多种异常检测方法进行了基准测试，评估了不同实验条件对检测性能的影响，为数字病理图像中的异常检测提供了详细的比较和基准参考，以指导未来的研究工作。", "innovation": "本文创新性地通过对20多种经典和常用异常检测方法进行全面的基准测试，评估了多种影响因素对检测效果的影响。特别地，系统地制备了五种真实和合成的数字病理数据集，用于综合评估这些方法。实验还深入探讨了图像尺度、异常模式类型以及训练周期选择策略对检测性能的影响。这些研究不仅提供了详细的比较分析，还建立了全面的基准，为未来数字病理图像中的异常检测研究提供了指导。", "conclusion": "研究结果为每种方法的优缺点提供了详细的比较和分析，建立了全面的基准，这将有助于未来研究领域针对数字病理图像中的异常检测工作的进一步研究和改进。"}
{"llm_update_time": "2025-06-25 09:21:17", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19297", "html_url": "https://arxiv.org/abs/2506.19297", "title": "基于显式残差的适合人类和机器的可扩展图像编码", "title_en": "Explicit Residual-Based Scalable Image Coding for Humans and Machines", "authors": "Yui Tatsumi,Ziyue Zeng,Hiroshi Watanabe", "background": "可扩展图像压缩是一种技术，能够渐进地重建不同要求下的多个图像版本。近年来，不仅人类，机器识别模型也开始大量消费图像。这引起了对既服务机器视觉又服务人类视觉的可扩展图像压缩方法的关注。现有模型大多采用神经网络为基础的编码器，通过精心设计损失函数推进了这一领域的进展。然而，一些模型过于依赖学习能力，其架构设计仍未充分考虑到。", "innovation": "本文通过将显式残差压缩机制整合到ICMH框架中，提升了编码效率和可解释性。具体来说，我们提出了两种互补的方法：基于特征残差的可扩展编码（FR-ICMH）和基于像素残差的可扩展编码（PR-ICMH）。这两种方法适用于各种机器视觉任务，并且提供了一种在编码复杂性和压缩性能之间选择的灵活性，使该方法能够适应不同的应用场景需求。实验结果表明，我们的方法具有有效性，PR-ICMH与以往工作相比，在BD率节省上最高可达29.57%。", "conclusion": "实验结果证明了我们提出的方法的有效性，特别是PR-ICMH方法，在BD率节省上相较于之前的最好工作实现了29.57%的提升。"}
{"llm_update_time": "2025-06-25 09:21:17", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19360", "html_url": "https://arxiv.org/abs/2506.19360", "title": "SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation", "title_en": "SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation", "authors": "Yunsung Chung,Yunbei Zhang,Nassir Marrouche,Jihun Hamm", "background": "生成模型的进步已经彻底改变了用于隐私保护数据合成（PPDS）的合成图像生成领域。然而，当前领域缺乏对不同情境下的合成图像生成方法的全面调查和比较。特别是在进行训练分类器的数据合成时，存在生成-采样-分类的管道，输入为私有训练数据，输出为目标的最终分类器。本文旨在系统分类现有的图像合成方法、隐私攻击和缓解措施。研究还提供了基于代表性生成方法的标准基准，并用无模型通用成员推理攻击（MIAs）衡量隐私风险，以实证比较不同的生成方法。通过对多种生成方法的系统评估，本文提供了有关合成数据生成方法的效用-隐私权衡的具体见解，并指导了实际应用中最优数据发布策略的决策。", "innovation": "本文提供了一个基准，并使用无模型通用成员推理攻击作为衡量隐私风险的方法，以系统地比较不同的合成图像生成方法。通过这种方式，研究系统地分类了现有的图像合成方法、隐私攻击和缓解措施。此外，本文还通过实证研究回答了在PPDS中几个关键问题：合成数据能否有效替代真实数据？哪种发布策略能平衡效用和隐私？缓解措施能否改善效用-隐私权衡？哪种生成模型在不同场景下表现最佳？", "conclusion": "通过对多种方法的系统评估，本文为合成数据生成方法的效用-隐私权衡提供了具体的见解，并为实际应用中数据发布策略的选择提供了指导性建议。"}
{"llm_update_time": "2025-06-25 09:21:18", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19266", "html_url": "https://arxiv.org/abs/2506.19266", "title": "猕猴和人类的弓状束连接模式的趋同和发散", "title_en": "Convergent and divergent connectivity patterns of the arcuate fasciculus in macaques and humans", "authors": "Jiahao Huang,Ruifeng Li,Wenwen Yu,Anan Li,Xiangning Li,Mingchao Yan,Lei Xie,Qingrun Zeng,Xueyan Jia,Shuxin Wang,Ronghui Ju,Feng Chen,Qingming Luo,Hui Gong,Xiaoquan Yang,Yuanjing Feng,Zheng Wang", "background": "关于非人灵长类动物弓状束（AF）的组织和连接性仍存在争议，特别是在其解剖与人类之间的差异方面。此项研究旨在结合单神经元跨尺度追踪技术和超高的磁共振成像技术，对比分析猕猴和人类AF的连接模式，以揭示进化过程中人类语言网络的专业化可能的原因。", "innovation": "研究者使用基于病毒的遗传标记和荧光显微光切断断层扫描技术在猕猴（4只，年龄3-11岁）中进行单神经元追踪，并结合11.7T扩散MRI的整体脑束追踪技术，以及人类7.0T MRI的光谱嵌入分析，进行跨物种的连接组学分析。通过Kullback-Leibler分析量化不同物种AF之间连接性的差异，这可能解释了人类语言网络进化的特殊性。此外，研究提供了AF相关障碍，如失语症和阅读障碍的神经解剖学框架。", "conclusion": "猕猴和人类的AF存在趋同和发散的连接模式。人AF在颞叶整合方面更广泛且前额叶和顶叶皮质的连接更强，这为人类独特高级语言处理的出现提供了连接性基础。研究发现为理解AF相关的脑疾病提供了神经解剖学框架。"}
{"llm_update_time": "2025-06-25 09:21:18", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19222", "html_url": "https://arxiv.org/abs/2506.19222", "title": "基于有效解剖结构表示与分而治之网络的可变形医学图像配准", "title_en": "Deformable Medical Image Registration with Effective Anatomical Structure Representation and Divide-and-Conquer Network", "authors": "Xinke Ma,Yongsheng Pan,Qingjie Zeng,Mengkang Lu,Bolysbek Murat Yerzhanuly,Bazargul Matkerim,Yong Xia", "background": "有效的区域兴趣（ROI）表示和独立对齐这些ROI可以显著提高变形医学图像配准（DMIR）的性能。然而，当前基于学习的DMIR方法存在局限性。无监督技术忽略了ROI表示，直接对齐图像对，而弱监督方法则依赖标签约束来辅助配准.", "innovation": "本文提出了一种新颖的基于ROI的配准方法EASR-DCN。该方法通过有效的ROI表示医学图像，并实现无需标签即可独立对齐ROI。首先使用高斯混合模型进行强度分析，以用多个具有不同强度的ROI表示图像。此外，提出了一种新的分而治之网络（DCN）来分别处理这些ROI来学习每个ROI的特征对齐。所得对应的特征无缝集成，生成一个全面的位移向量场。实验在三个MRI和一个CT数据集上进行了广泛测试，展示了EASR-DCN在准确性和形变减少效果上的优越性，与VoxelMorph相比，在脑MRI、心脏MRI和海马MRI的Dice分数上分别提高了10.31%、13.01%和5.75%.", "conclusion": "EASR-DCN在准确性和形变减少效果上表现出色，有望在临床应用中得到广泛应用。该工作的代码将在论文被接受后发布。"}
{"llm_update_time": "2025-06-25 09:21:19", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19387", "html_url": "https://arxiv.org/abs/2506.19387", "title": "NAADA: 避免噪声的注意力去噪自编码器在牙科全景X光片中的应用", "title_en": "NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs", "authors": "Khuram Naveed,Bruna Neves de Freitas,Ruben Pauwels", "background": "卷积去噪自编码器（DAEs）是强大的图像恢复工具，但它们继承了卷积神经网络（CNNs）的一个关键局限性：它们在恢复低频特征（如平滑区域）方面比高频细节更有效，导致图像中精细细节的丢失，特别是在牙科全景X光片中尤为明显，因为这些图像中的微妙解剖结构对诊断至关重要。传统注意力机制可以缓解这一问题，但通常会优先关注清晰区域的特征，而忽略那些被噪声遮挡的特征。因此，需要一种能够有效关注和恢复关键特征，即使在噪声区域也能发挥作用的方法。", "innovation": "提出了一种噪声感知的自我注意力方法，使模型能够在嘈杂的区域内有效地聚焦和恢复关键特征。在此基础上，引入了一种噪声感知的注意力增强去噪自编码器（NAADA网络），专门用于增强牙科全景X光片中的噪声。与Uformer、MResDNN等近期的先进但更重的方法相比，该方法在重建精细细节方面表现更加出色，确保了更好的图像质量和诊断准确性。", "conclusion": "NAADA网络显著提升了牙科全景X光片中噪声区域的细节恢复，增强了图像质量和诊断准确性，解决了传统DAEs在处理高频率细节方面的限制。"}
{"llm_update_time": "2025-06-25 09:21:20", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19838", "html_url": "https://arxiv.org/abs/2506.19838", "title": "SimpleGVR: 一种简化的语义级联视频超分辨率基线", "title_en": "SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution", "authors": "Liangbin Xie,Yu Li,Shian Du,Menghan Xia,Xintao Wang,Fanghua Yu,Ziyan Chen,Pengfei Wan,Jiantao Zhou,Chao Dong", "background": "隐含扩散模型已成为高效视频生成的主要范式。然而，随着用户期望转向更高分辨率的输出，仅依赖隐含计算变得不足。一种有前途的方法是将过程分为两个阶段：语义内容生成和细节合成功能。前者在较低分辨率下采用计算密集的基模型，后者利用轻量级的级联视频超分辨率（VSR）模型实现高分辨率输出。本文研究了级联VSR模型的关键设计原则，探讨如何通过两种退化策略生成更好的训练对，确保VSR模型与上游生成器之间的对齐，并通过系统分析时间步采样策略和噪声强化对低分辨率输入的不同影响来指导模型行为。进一步引入交织的时间单元和稀疏局部注意力机制，以实现高效的训练和推断，大幅减少计算开销。", "innovation": "提出了两种降级策略以生成更符合基模型输出特性的训练对；通过系统分析时间步采样策略和噪声对低分辨率输入的影响，为级联VSR模型的行为提供了关键见解；引入交织的时间单元和稀疏局部注意力机制，实现高效训练与推断，显著降低计算开销；实验结果表明，该框架优于现有方法，且消融试验验证了每种设计选择的有效性。", "conclusion": "我们的工作为级联视频超分辨率生成提供了一个简单有效的基线，为未来高效的级联合成系统提供了实用的指导。"}
{"llm_update_time": "2025-06-25 09:21:25", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19415", "html_url": "https://arxiv.org/abs/2506.19415", "title": "使用虚拟内存的3D高斯点积合成", "title_en": "Virtual Memory for 3D Gaussian Splatting", "authors": "Jonathan Haberl,Philipp Fleck,Clemens Arth", "background": "3D高斯点积合成在新型视图合成领域取得了突破，通过使用高斯作为核心渲染原语，可以实现非常精确的现实世界环境重建。近年来，技术进步极大地增加了可以创建的场景大小。这项工作中，我们提出了使用虚拟内存渲染大型和复杂的3D高斯点积合成场景的方法。通过利用已建立的虚拟内存和虚拟纹理技术，该方法有效地识别可见的高斯点并动态地在需要时只将它们流式传输到GPU以实现实时渲染。只选择所需的一些高斯点来存储和渲染，可减少内存使用并有效加速渲染，尤其是对于高度复杂的场景。此外，我们展示了如何将细节层次整合到我们提议的方法中，以进一步提高大型场景的渲染速度。通过优化实现，我们强调了关键的实用考虑因素并全面评估了提议的技术及其对桌面和移动设备的影响。", "innovation": "该方法通过利用虚拟内存和虚拟纹理技术，能够高效地识别场景中的高斯点并仅在需要时将它们流式传输到GPU进行实时渲染，从而实现大型复杂3D高斯点积合成场景的渲染。这种方法能够减少存储和渲染所需的高斯点数量，有效降低内存使用并加速渲染，尤其是在复杂场景中效果显著。此外，该方法还能集成细节层次控制，以进一步提升大规模场景的渲染速度。", "conclusion": "通过优化实现，我们解决了关键的实用考虑因素并全面评估了使用虚拟内存的3D高斯点积合成的方法及其对桌面和移动设备的影响。该研究不仅提高了对大型复杂场景的渲染效率，还推动了高斯点积合成技术的整体进步。"}
{"llm_update_time": "2025-06-25 09:21:27", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19455", "html_url": "https://arxiv.org/abs/2506.19455", "title": "Angio-Diff: 学习自监督对抗扩散模型以生成血管几何结构", "title_en": "Angio-Diff: Learning a Self-Supervised Adversarial Diffusion Model for Angiographic Geometry Generation", "authors": "Zhifeng Wang,Renjiao Yi,Xin Wen,Chenyang Zhu,Kai Xu,Kunlun He", "background": "血管疾病对人类健康构成重大威胁，X射线血管造影被确立为诊断的金标准，能够对血液血管进行详细观察。然而，血管造影X射线对人员和患者暴露的辐射水平高于非血管造影X射线，因此需要从非血管造影到血管造影X射线的模态转换。尽管基于数据驱动的深度方法受到了大规模配对X射线血管造影数据集缺失的阻碍，但高质量的血管造影图像合成仍具有重要意义，但目前在血管图像合成质量方面仍然存在挑战，如断点过多或曲率不自然。现有的医学图像合成主要在像素层面进行，难以适应血液血管的复杂几何结构。因此，需要提出一种克服该问题的方法。", "innovation": "本文提出了一个自监督的通过扩散模型进行非血管造影X射线转化为血管造影X射线的方法，以解决数据驱动方法遇到的数据短缺问题。该方法包含了一个扩散模型，通过扩散潜在空间学习血管数据的分布，以及一个血管合成生成器和基于掩码的对抗模块。为增强几何准确性，还提出了一个参数化血管模型来拟合血管的形状和分布。通过这种方法贡献了一个X射线血管造影的管道和合成数据集。实验结果表明，该方法在合成血管造影图像质量和血管几何结构的合成准确性方面达到了最先进的水平。", "conclusion": "本文提出的方法解决了数据驱动方法中数据短缺的挑战，通过自监督的扩散模型实现了非血管造影到血管造影X射线的转换，并通过参数化血管模型提高几何准确性。实验结果表明，该方法在血管造影图像质量和血管几何结构的合成准确性方面表现优秀。"}
{"llm_update_time": "2025-06-25 09:21:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19579", "html_url": "https://arxiv.org/abs/2506.19579", "title": "真假如何辨别？机器人能否识别现实与3D打印对象上的视觉语言模型？", "title_en": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects", "authors": "Federico Tavella,Kathryn Mearns,Angelo Cangelosi", "background": "机器人场景理解日益依赖于视觉-语言模型（VLMs）来生成对环境的自然语言描述。本文探讨了基于机械臂和RGB相机捕捉的桌面场景进行描述的不同策略。机械臂会从多个视角收集物体的图像，并且评估了几种生成场景描述的模型。实验重点比较了单视角和多视角描述之间的权衡，以及真实物体和3D打印物体的识别差异。通过定量评估物体识别精度、描述的完整性和自然性来衡量模型性能。研究表明，视觉语言模型在识别常见物体方面表现良好，但在处理新颖物体表示时表现不佳。这项研究为在现实世界中部署基础模型提供了实用见解，以便于实现具身智能代理。", "innovation": "本文进行了一项关于使用视觉语言模型的桌面场景描述的综合比较研究。特别地，通过对比单视角与多视角、以及识别真实物体与3D打印物体的能力，评估了不同模型的表现。此外，研究还量化了生成描述的准确度、完整性和自然性，这为如何有效利用基础模型提供了新的思路。这种研究方法和评估指标具有创新性，为未来研究奠定了基础。", "conclusion": "视觉语言模型在识别家庭中常见的现实物体时表现良好，但在面对新颖的3D打印物体时，模型的表现不如预期。因此，尽管视觉语言模型在某些场景识别任务中有潜力，但在部署用于实际环境中的具身智能代理时，仍有一些改进的空间。未来的研究可以探索如何进一步提高这些模型在复杂环境中的可靠性，特别是在处理新颖和不常见的物体时。"}
{"llm_update_time": "2025-06-25 09:21:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19491", "html_url": "https://arxiv.org/abs/2506.19491", "title": "基于小无人机应用的神经3D重建实验评估", "title_en": "Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications", "authors": "Genís Castillo Gómez-Raya,Álmos Veres-Vitályos,Filip Lemic,Pablo Royo,Mario Montagud,Sergi Fernández,Sergi Abadal,Xavier Costa-Pérez", "background": "随着无人机（UAV）的尺寸不断缩小，其应用场景扩展到了室内和难以到达的区域。然而，这种微型化趋势也带来了挑战，特别是在飞行动态和能源消耗方面，限制了无人机的自主性和任务能力。现有技术（如Structure from Motion，SfM）难以满足在受限环境中进行精细3D重建的需求。因此，无人机应用需要新的创新方法来克服这些限制。", "innovation": "本文提出了一种创新方法，通过将神经3D重建（N3DR）技术集成到小型无人机系统中，以改善受限环境中小型静态物体的3D重建质量。本文采用Instant-ngp、Nerfacto和Splatfacto等先进模型，设计并实现了基于N3DR的专用流水线，利用多架小型无人机拍摄的图像提高3D重建质量。通过多种图像和点云指标对所考虑模型的性能进行评估，结果表明N3DR增强的流水线可以显著提高重建质量，使小型无人机能够支持高精度的3D建模和异常检测。", "conclusion": "实验结果表明，基于N3DR的流水线能够显著改善小型无人机的3D重建质量，突破了现有技术的局限，特别是在制约环境中实现高精度3D测绘和异常检测方面具有巨大潜力。这为推进小型无人机系统的应用能力提供了新的方向。"}
{"llm_update_time": "2025-06-25 09:21:34", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19558", "html_url": "https://arxiv.org/abs/2506.19558", "title": "ConCM: 由一致性驱动的校准与匹配方法在少量样本类增量学习中的应用", "title_en": "ConCM: Consistency-Driven Calibration and Matching for Few-Shot Class-Incremental Learning", "authors": "QinZhe Wang,Zixuan Chen,Keke Huang,Xiu Su,Chunhua Yang,Chang Xu", "background": "少样本类增量学习（FSCIL）要求模型在有限监督的情况下适应新的类别，同时保留已学习的知识。现有的基于前瞻学习的空间构建方法预留空间以容纳新的类别。然而，原型偏差和结构固定限制了嵌入空间的表现力。与预设的空间预留不同，本研究探索了特征-结构双一致性的优化，并提出了一种一致性驱动的校准和匹配框架（ConCM），系统地缓解了FSCIL中固有的知识冲突。受海马关联记忆的启发，本研究设计了一种记忆意识原型校准，从基础类别中提取通用语义属性并重新整合到新的类别中，以增强特征的概念中心一致性。进一步，提出了一种动态结构匹配，该方法能够自适应地将校准后的特征对齐到会话特定的最优流形空间，确保跨会话结构一致性。理论分析表明，我们的方法满足几何优化和最大匹配，从而克服了类别数量先验的需求。在mini-ImageNet和CUB200等大规模FSCIL基准测试中，ConCM实现了最先进的性能，在增量会话的赫尔姆斯准确性上分别超越当前最佳方法3.20%和3.68%。", "innovation": "提出了一致性驱动的校准和匹配框架（ConCM），用于少样本类增量学习。此方法通过记忆意识原型校准和动态结构匹配，分别从基础类别中提取通用语义属性并重新整合到新的类别中，增强特征的概念中心一致性；自适应地将校准后的特征对齐到会话特定的最优流形空间，确保跨会话结构一致性；克服了类别数量先验需求，实现了最先进的性能。", "conclusion": "一致性驱动的校准和匹配框架ConCM在少样本类增量学习测试中实现了最好的性能，尤其是在增量会话的赫尔姆斯准确性上超越当前最佳方法3.20%和3.68%。"}
{"llm_update_time": "2025-06-25 09:21:34", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19687", "html_url": "https://arxiv.org/abs/2506.19687", "title": "ReCoGNet: 用于3D MRI前列腺分割的递归上下文引导网络", "title_en": "ReCoGNet: Recurrent Context-Guided Network for 3D MRI Prostate Segmentation", "authors": "Ahmad Mustafa,Reza Rastegar,Ghassan AlRegib", "background": "前列腺腺体从T2加权MRI分割是临床前列腺癌评估中的关键但具有挑战性的任务。尽管基于深度学习的方法显著提升了自动分割的能力，但传统的2D卷积神经网络（CNN）方法未能充分利用层间解剖连续性，这限制了它们的准确性和鲁棒性。尽管完整的3D模型可以提供更好的空间一致性，但它们需要大量的标注数据，这在临床环境中往往是不可行的。为了克服这些限制，本研究提出了一种混合架构，将MRI序列建模为时空数据。该方法使用在每个MRI切片上提取高层语义特征的深度预训练DeepLabV3骨干，并使用基于ConvLSTM层的递归卷积头来整合层间信息，同时保留空间结构。这种组合使得在数据受限和噪声图像条件下能实现具有上下文感知的分割，并提高一致性。", "innovation": "提出了ReCoGNet，这是一种混合架构，通过将MRI序列建模为时空数据，使用深度预训练的DeepLabV3骨干和基于ConvLSTM层的递归卷积头来实现上下文感知的分割和信息整合。这种策略能够在数据有限和噪声的成像条件下提高分割的准确性和一致性，尤其适用于前列腺腺体分割。", "conclusion": "在PROMISE12基准测试中，当采用干净和对比度降级两种测试设置时，该方法在精确度、召回率、交并比（IoU）、Dice相似性系数（DSC）方面都优于最新的2D和3D分割模型，证明了其在临床部署中的潜在鲁棒应用。"}
{"llm_update_time": "2025-06-25 09:21:36", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19590", "html_url": "https://arxiv.org/abs/2506.19590", "title": "从解剖学学习：用于全身影影（WB-MRI）中进展性骨病分割的监督解剖预训练（SAP）", "title_en": "Learning from Anatomy: Supervised Anatomical Pretraining (SAP) for Improved Metastatic Bone Disease Segmentation in Whole-Body MRI", "authors": "Joris Wuts,Jakub Ceranka,Nicolas Michoux,Frédéric Lecouvet,Jef Vandemeulebroucke", "background": "全身影影（WB-MRI）中进展性骨病（MBD）的分割是一个具有挑战性的问题。由于病变在不同外观和解剖位置、模糊的边界以及严重的类别不平衡，获得可靠的分割需要包含大量注释数据集来捕捉病变的变化。生成这样的数据集需要大量的时间和专业知识，并且容易出错。虽然自监督学习（SSL）可以利用大型未标注的数据集，但学到的通用表示往往无法捕捉准确检测病变所需的细微特征。因此，必须从有限的解剖学标签数据集中学习。首先发展并训练基于MRI的骨骼分割模型，用于健康人WB-MRI扫描的高质量骨骼分区。然后将模型的有效性与一组患有转移性前列腺癌的44位患者的MBD分割进行比较，与其他基线随机初始化模型以及最先进的SSL方法进行对比。", "innovation": "提出了一种称为监督解剖预训练（SAP）的方法，该方法通过有限的解剖学标签数据集学习。该方法从MRI得到的骨骼分割模型开始，用于高质量地分割健康个体的WB-MRI扫描。然后使用SAP方法下游应用于MBD分割，并与基线和最先进的SSL方法进行了比较。实验结果表明，SAP方法显著优于基线和SSL预训练模型，分割质量明显提高，病变检测F2分数提升显著，特别是对于临床相关的病变检测灵敏度达到100%。这种方法从解剖学中学习了有效的和领域相关的归纳偏置，能够有效地利用给定任务的分割任务，用于骨骼病变的分割。所有代码和模型已经公开发布。", "conclusion": "SAP方法通过有限的解剖学标签数据集学习，取得了显著的效果。对于全身影影中进展性骨病的分割，SAP方法的性能超过了基线方法和使用自监督学习进行预训练的方法。特别是在临床相关的病变检测方面，达到100%的灵敏度。这种方法从解剖学特征中获取的归纳偏置，有效提高了下游分割任务的准确性。"}
{"llm_update_time": "2025-06-25 09:21:38", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19708", "html_url": "https://arxiv.org/abs/2506.19708", "title": "使用稀疏自编码器揭示生成图像模型的概念盲点", "title_en": "Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders", "authors": "Matyas Bohacek,Thomas Fel,Maneesh Agrawala,Ekdeep Singh Lubana", "background": "尽管生成图像模型在大规模数据集上表现出色，但在生成图像时，它们经常未能生成诸如手部或成组出现的物体等简单概念的图像，而这些概念在训练数据中是合理预计会出现的。这些失败模式虽已被部分记录，但尚未明确指出它们是模型的特异性异常还是其更具结构性的局限性。本文旨在通过系统的方法来识别和描述这些‘概念盲点’，即在训练数据中存在但在模型生成中未被呈现或表现失真的概念。该方法利用稀疏自编码器（SAEs）提取可解释的概念嵌入，使研究人员能够定量比较真实图像和生成图像中的概念频次差异。本文训练了迄今为止最大的稀疏自编码器（RA-SAE），用于分析概念差异的细节。将该方法应用于四个流行的生成模型（Stable Diffusion 1.5/2.1，PixArt，Kandinsky），揭示了一些抑制的概念盲点（如鸟食器、DVD光盘和文档空白）和夸大盲点（如木材背景纹理和棕榈树），并在单个数据点级别，进一步隔离了记忆化特征——模型再现了训练期间见过的特定视觉模板。", "innovation": "本文引入了一种系统性的方法来识别和描述‘概念盲点’，通过训练大型稀疏自编码器（RA-SAE）来分析生成模型的概念完整性差异，引入了一种理论上可靠的方法来系统地识别生成模型的概念盲点，评估其在生成图像时与数据生成过程的概念一致性。这种方法帮助揭示了模型在生成具体概念时的偏见和局限性。", "conclusion": "本文提出了一种理论基础的框架，通过基于稀疏自编码器的概念一致性评估，系统地识别生成模型中的概念盲点。研究结果表明，生成模型在生成特定视觉概念时存在特定的被抑制偏差和被放大的偏差，并且模型还可能再现特定的训练图像中的视觉模板。这些发现对于进一步改进生成模型有重要意义，并有助于理解和克服模型的概念偏见。"}
{"llm_update_time": "2025-06-25 09:21:39", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19106", "html_url": "https://arxiv.org/abs/2506.19106", "title": "组织病理学中的染色标准化：基于多中心数据集的方法基准测试", "title_en": "Staining normalization in histopathology: Method benchmarking using multicenter dataset", "authors": "Umair Khan,Jouni Härkönen,Marjukka Friman,Leena Latonen,Teijo Kuopio,Pekka Ruusuvuori", "background": "H&E染色一直是组织分析的黄金标准，但不同实验室的染色标本在外观上往往存在显著差异，这给病理学家和基于AI的下游分析带来了挑战。为了减少这种差异，计算上的染色标准化是一项活跃的研究领域。为了进一步研究这个问题，本研究收集了一个独特的多中心组织影像数据集，在其中从结肠、肾脏和皮肤组织块中获取的组织样本被分发到66个不同的实验室进行常规H&E染色，以孤立染色差异。通过保持其他影响组织外观的因素不变，进一步利用这个组织影像数据集来比较八种不同的染色标准化方法的性能，包括四种传统的直方图匹配、Macenko、Vahadane和Reinhard标准化，以及两种基于深度学习的方法CycleGAN和Pix2pix，每种方法有两个变体。通过定量和定性评估来评估这些方法的表现。数据集中的跨实验室染色差异也可以指导通过变训练数据提高模型通用性的策略", "innovation": "研究使用了一个包含来自66个不同实验室的数据的独特多中心组织影像数据集，来比较不同染色标准化方法的性能。这种方法不仅提供了关于精度的定量评估，而且还包括了通过定性方法进行的评估，并且研究还探讨了这种数据集如何指导通过不同训练数据提高模型的通用性策略。此外，研究还引入了两种基于深度学习的染色标准化方法，进行了传统的和深度学习方法的对比研究", "conclusion": "八种不同的染色标准化方法的表现通过定量和定性分析进行了全面评估，数据集的跨实验室染色差异对模型通用性的改善提出了策略建议，基于深度学习的两种方法显示出了其优越性，未来可以在更多类型的数据集上进一步验证其有效性"}
{"llm_update_time": "2025-06-25 09:21:40", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19741", "html_url": "https://arxiv.org/abs/2506.19741", "title": "Noise Consistency Training: A Native Approach for One-Step Generator in Learning Additional Controls", "title_en": "Noise Consistency Training: A Native Approach for One-Step Generator in Learning Additional Controls", "authors": "Yihong Luo,Shuchen Xue,Tianyang Hu,Jing Tang", "background": "在生成式人工智能（AIGC）内容生成中，追求高效且可控的高质量内容生成始终是一个核心挑战。尽管通过扩散蒸馏技术的一步生成器在生成质量和计算效率方面表现出色，将其适应于新的控制条件（如结构约束、语义指南或外部输入）仍然面临挑战。传统方法通常需要对基础模型进行昂贵的修改并再次进行扩散蒸馏，这使得适应新控制条件变得复杂且耗时。", "innovation": "本文提出Noise Consistency Training (NCT)方法，这是一种新颖且轻量级的方法，可以直接将新的控制信号整合到预先训练的一步生成器中，无需访问原始训练图像或重新训练基础扩散模型。NCT通过引入一个适配器模块，并在生成器的噪声空间中采用噪声一致性损失来操作。该损失在条件不同程度依赖的噪声之间校准适配模型的生成行为，隐式地引导其遵循新的控制。理论证明，此训练目标可以理解为最小化适配生成器与由新条件诱导的条件分布之间的分布距离。NCT模块化、数据高效、易于部署，仅依赖预先训练的一步生成器和控制信号模型。实验表明，NCT在单次前向传递中实现最先进的可控生成，超越了现有的多步和蒸馏方法，在生成质量和计算效率上均优于现有方法。", "conclusion": "NCT实现了单步生成器的原生方法，在学习额外控制方面表现出色，展示了该技术在提高生成质量和计算效率方面的优势。"}
{"llm_update_time": "2025-06-25 09:21:42", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL: 探索可信强化学习以实现事实准确度", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Wenhao Yu,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs），尤其是慢思考模型，经常表现出严重的幻觉现象，由于推理过程中无法准确识别知识边界，从而输出错误内容。虽然强化学习（RL）可以提升复杂的推理能力，但其结果导向的奖励机制往往忽略了思考过程中的事实监督，进一步加剧了幻觉问题。", "innovation": "为了应对慢思考模型中的高幻觉问题，我们提出了知识增强的RL，即KnowRL。KnowRL通过在RL训练过程中集成基于知识验证的事实性奖励，引导模型进行基于事实的慢思考，帮助它们识别知识边界。通过在推理步骤中直接奖励事实的遵循，KnowRL促进了一个更为可靠的思想过程。实验结果显示，KnowRL在三个幻觉评估数据集和两个推理评估数据集上有效地减少了慢思考模型的幻觉现象，同时保持了它们原有的强大推理能力。我们的代码可在该链接获得：this https URL", "conclusion": "实验结果表明，KnowRL有效地缓解了慢思考模型中的幻觉现象，同时维护了其原始强大的推理能力。"}
{"llm_update_time": "2025-06-25 09:21:46", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/1905.11575", "html_url": "https://arxiv.org/abs/1905.11575", "title": "在空间和时间域中进行逐步跨流合作以实现动作定位", "title_en": "Progressive Cross-Stream Cooperation in Spatial and Temporal Domain for Action Localization", "authors": "Rui Su,Dong Xu,Luping Zhou,Wanli Ouyang", "background": "时空动作定位包含三个任务层级：空间定位、动作分类和时间定位。现有技术对这三个任务有不同程度的改善需求。本文旨在提出一种新的逐步跨流合作(Progressive Cross-stream Cooperation, PCSC)框架，该框架旨在提高这三个任务的性能。", "innovation": "本文的主要创新点在于提出了一种新的PCSC框架，通过空间区域和时间段提案及其特征在两个流（流/RGB流和RGB/流流）间迭代传递，帮助生成更高质量的边界框和时间段。此外，还提出了一种新的消息传递方法，通过流间信息传递来改进动作检测和时间分割模型，实现了多层次逐级优化，从而提升空间和时间动作定位的准确性。", "conclusion": "通过在帧级应用空间PCSC框架进行空间定位，在管级应用时间PCSC框架进行时间定位，本文的方法实现了动作定位结果在帧级和视频级的逐步提升。在两个基准数据集UCF-101-24和J-HMDB中的全面实验表明了所提出方法的有效性。"}
{"llm_update_time": "2025-06-25 09:21:46", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19797", "html_url": "https://arxiv.org/abs/2506.19797", "title": "磁共振成像中垂体和垂体腺瘤自动分割技术的系统评价", "title_en": "Systematic Review of Pituitary Gland and Pituitary Adenoma Automatic Segmentation Techniques in Magnetic Resonance Imaging", "authors": "Mubaraq Yakubu,Navodini Wijethilake,Jonathan Shapey,Andrew King,Alexander Hammers", "background": "准确地从磁共振成像（MRI）中分割垂体腺瘤及其腺体对于垂体腺瘤的诊断和治疗至关重要。本文系统回顾了自动分割方法在提高基于MRI的垂体腺瘤及其腺体分割准确性与效率方面的作用。共有34篇使用自动和半自动分割方法的研究被评估。骰子重叠分数是常用的评估指标。研究结果表明，大多数研究使用了深度学习方法，基于U-Net的模型最为常见。自动分割方法在垂体腺体和腺瘤分割上的骰子分数分别为19-89%和4.6-96.4%，而半自动分割方法对应的分数为80-92.1%和75.9-88.36%。然而，很少有研究报告了诸如MR场强、年龄和腺瘤大小等重要指标。U-Net等基于自动分割技术显示出良好的潜力，尤其是在腺瘤分割方面，但对于正常垂体腺体这种小型结构，仍需改进以实现持续稳定的表现。进一步的创新和更大的多样化数据库可能是提升临床应用的关键因素。", "innovation": "大多数研究使用了深度学习方法，尤其是基于U-Net的模型，显示出在垂体腺瘤分割方面的潜在价值，但同时也指出了需要在小结构分割上进一步改进，以及强调了创新和多样化数据集的重要性。", "conclusion": "多数研究未报告关键评估指标，如MR场强、年龄和腺瘤大小。基于U-Net的自动化分割技术在垂体腺瘤分割方面显示出潜力，但需要进一步改进以实现常规良好表现，尤其是在正常垂体腺体这类小结构上。"}
{"llm_update_time": "2025-06-25 09:21:47", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19742", "html_url": "https://arxiv.org/abs/2506.19742", "title": "基于NeRF的CBCT重建需要正规化和初始化", "title_en": "NeRF-based CBCT Reconstruction needs Normalization and Initialization", "authors": "Zhuowei Xu,Han Li,Dai Sun,Zhicheng Li,Yujia Li,Qingpeng Kong,Zhiwei Cheng,Nassir Navab,S. Kevin Zhou", "background": "锥形束计算机断层摄影（CBCT）在医学成像中广泛应用，但由于X射线投影数量有限且强度较低，重建问题成为一个病态问题，存在严重的伪影。现有的NeRF（Neural Radiance Fields）方法在该领域取得了显著成果，但是它们在两个关键组件之间存在局部-全局训练的不匹配：哈希编码器和神经网络。在每次训练步骤中，哈希编码器的参数仅有一部分被使用（局部稀疏），而神经网络的所有参数均参与（全局密集）。这种局部和全局参数的不同影响，导致在训练过程中生成的哈希特征高度不一致，进而导致训练不稳定、收敛缓慢以及重建质量的下降。", "innovation": "该研究引入了规范化哈希编码器，以增强特征一致性并缓解局部-全局优化的不匹配。此外，提出了映射一致性初始化（MCI）策略，在训练前利用具有良好训练模型的全局映射特性初始化神经网络。这种方法简单有效，只需少量代码，就能在128个CT案例（来自4个不同数据集，覆盖7个不同的解剖区域）中显著提高训练效率，实现更快的收敛和更好的重建性能。", "conclusion": "该研究方法简单、有效、代码量少，能够大幅提高CBCT重建性能，尤其在多个数据集上的表现明显改善了训练效率，展示了在局部-全局优化不匹配问题上的创新解决方案。"}
{"llm_update_time": "2025-06-25 09:21:48", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19363", "html_url": "https://arxiv.org/abs/2506.19363", "title": "重新考虑纵向乳腺X线摄影的显式对齐以提升乳腺癌风险预测", "title_en": "Reconsidering Explicit Longitudinal Mammography Alignment for Enhanced Breast Cancer Risk Prediction", "authors": "Solveig Thrun,Stine Hansen,Zijun Sun,Nele Blum,Suaiba A. Salahuddin,Kristoffer Wickstrøm,Elisabeth Wetzer,Robert Jenssen,Maik Stille,Michael Kampffmeyer", "background": "定期进行乳腺X线摄影筛查对于早期发现乳腺癌至关重要。基于深度学习的风险预测方法引起了关注，目的在于为高风险群体调整筛查间隔。早期的方法仅关注当前的X线照片，而近期的策略则利用了筛查时间的纵向性，以跟踪乳腺组织随时间的变化，这需要在不同时间点之间进行空间对齐。两种主要的方法已经出现：显式的特征对齐通过可变形注册实现，以及隐式的对齐通过类似变换器的技术实现，前者提供了更多的控制。然而，显式的对齐在乳腺X线摄影中的最佳方法尚未得到充分探索。在这项研究中，我们探讨了显式对齐应该发生在输入空间还是表示空间，以及对齐和风险预测是否应该联合优化的问题。研究表明，当前最佳的方法在表示空间中联合学习显式对齐，虽然可以提升风险评估性能，但在对齐和预测之间存在权衡，且图像级别对齐优于表示级别对齐，这提升了变形场的质量并增强了风险预测的准确性", "innovation": "该研究揭示了显式对齐应在输入空间还是表示空间进行的最佳位置，以及对齐和风险预测应否联合优化的问题。研究结果表明，尽管在表示空间中联合学习显式对齐可优化风险评估性能，但图像级别对齐优于表示级别对齐，这提升了变形场的质量并提高了风险预测的准确性", "conclusion": "当前最佳的方法在表示空间中联合学习显式对齐虽然可以优化风险评估性能，但在对齐和预测之间存在权衡，且图像级别对齐优于表示级别对齐，这提升了变形场的质量并增强了风险预测的准确性"}
{"llm_update_time": "2025-06-25 09:21:49", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19847", "html_url": "https://arxiv.org/abs/2506.19847", "title": "使正交微调可扩展", "title_en": "Orthogonal Finetuning Made Scalable", "authors": "Zeju Qiu,Weiyang Liu,Adrian Weller,Bernhard Schölkopf", "background": "正交微调（OFT）能够在保持参数高效适应的同时防止灾难性遗忘，但其高昂的运行时间和内存需求限制了其实用部署。OFT的权重中心实现依赖于具有立方复杂度的矩阵-矩阵乘法，这成为其核心计算瓶颈。", "innovation": "我们提出了OFTv2，这是一种基于输入的重新表述方式，使用矩阵-向量乘法替代矩阵-矩阵乘法，将计算成本降低为平方级别。此外，我们还引入了Cayley-Neumann参数化，这是一种高效的正交参数化方法，通过截断Neumann级数来近似Cayley变换中的矩阵求逆。OFTv2的这些修改使其训练速度提高10倍，GPU内存使用降低3倍，且不影响性能。此外，我们还将OFTv2扩展到支持量化基础模型的微调，并证明它在训练稳定性、效率和内存使用方面优于流行方法QLoRA。", "conclusion": "OFTv2能够在保持高性能的同时，在训练速度和内存使用方面实现显著提升，特别是在量化模型微调领域表现出色。"}
{"llm_update_time": "2025-06-25 09:21:49", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19827", "html_url": "https://arxiv.org/abs/2506.19827", "title": "基于3D数字地图的-cost-effective多感知视觉导航系统-gNSS受限环境中的定位", "title_en": "Look to Locate: Vision-Based Multisensory Navigation with 3-D Digital Maps for GNSS-Challenged Environments", "authors": "Ola Elmaghraby,Eslam Mounier,Paulo Ricardo Marques de Araujo,Aboelmagd Noureldin", "background": "在缺乏全球导航卫星系统（GNSS）的环境中，例如室内的停车场或密集的城市峡谷中，实现准确的车辆定位仍然是一项重大挑战。本文提出了一种基于单目深度估计、语义过滤和视觉地图注册（VMR）与3D数字地图集成的低成本多传感器导航系统。在实际的室内和室外驾驶场景中进行了广泛的测试，展示了所提出系统的有效性，实现了92%的室内外亚米级定位精度，以及一致性水平定位和航向平均均方根误差分别约为0.98米和1.25度。与基准线相比，在各种条件下显著减少了漂移并提高了鲁棒性，平均实现了约88%的定位精度提升。本研究强调了低成本单目视觉系统与3D地图结合在土地车辆中实现可扩展的、独立于gNSS的导航的潜力。", "innovation": "提出了一个将单目深度估计、语义过滤和视觉地图注册（VMR）与3D数字地图集成的低成本多传感器导航系统，能够在没有gNSS信号的环境下实现精准的车辆定位。与基准线相比，该系统显著减少了漂移并提高了稳定性，并实现了显著的定位精度提升。", "conclusion": "低成本的单目视觉系统结合3D地图具有巨大的潜力，能够实现在陆地车辆中进行可扩展的、不依赖于gNSS的导航。该系统在实际的室内和室外驾驶场景中展示了优异的效果，证明了其在gNSS受限环境中的应用可行性。"}
{"llm_update_time": "2025-06-25 09:21:51", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19600", "html_url": "https://arxiv.org/abs/2506.19600", "title": "利用残差U-网络填补稀疏PET探测器配置下Incomplete sinograms的方法", "title_en": "Filling of incomplete sinograms from sparse PET detector configurations using a residual U-Net", "authors": "Klara Leffler,Luigi Tommaso Luppino,Samuel Kuttner,Karin Söderkvist,Jan Axelsson", "background": "长轴场PET扫描仪在视野和灵敏度方面优于传统的PET扫描仪，但是密集的光电探测器使得这些系统成本高昂，限制了临床应用。为了降低成本，提出了替代的稀疏系统配置，虽然降低了探测器成本，但牺牲了图像质量。本研究中，作者提出了一种深度sinogram恢复网络，用于填补缺失的数据。该方法利用修改后的残差U-网络，在去掉了50%的探测器（保留25%的响应线）人工模拟的临床PET扫描中训练，成功恢复了缺失的计数，平均绝对误差低于2个像素事件，在sinogram域和重建图像域均优于2D插值。尽管预测的sinograms在重建图像中产生了平滑效果，导致细节模糊，但这表明该模型具有补偿稀疏探测器配置导致的欠采样能力。这项概念验证研究显示，结合深度学习技术的稀疏探测器配置是传统PET扫描仪设计的一种可行替代方案，有助于开发成本有效的全身PET扫描仪，促进医学影像技术的发展。", "innovation": "作者提出了一种基于深度学习的sinogram恢复网络方法，该方法利用修改后的残差U-网络来填补稀疏探测器配置下缺失的sinogram数据。这种方法在保留较低成本的同时，提高了图像质量，优于传统2D插值方法。该模型能够在稀疏探测器配置下显著提升图像重建质量，提供了一种成本更低的PET扫描仪设计替代方案。", "conclusion": "稀疏探测器配置与深度学习技术相结合提供了一种成本有效的PET扫描仪设计，这在医学成像技术中具有重要意义，尤其是在全身PET扫描的应用中，可以显著降低设备成本并提高临床应用的可能性。虽然仍有分辨率方面的挑战需要克服，但这项初步成功的研究为未来的发展奠定了基础。"}
{"llm_update_time": "2025-06-25 09:21:52", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.08860", "html_url": "https://arxiv.org/abs/2401.08860", "title": "细粒度视觉类别的跨级多实例蒸馏自我监督", "title_en": "Cross-Level Multi-Instance Distillation for Self-Supervised Fine-Grained Visual Categorization", "authors": "Qi Bi,Wei Ji,Jingjun Yi,Haolan Zhan,Gui-Song Xia", "background": "精细粒度视觉类别高质量标注需要大量专业知识，耗时耗力。相反，通过自我监督学习从大量未标注图像中学习精细粒度视觉表示成为可能，但现有自我监督学习方法在表示精细粒度类别方面效率较低。主要原因在于预文本表示是基于每个块嵌入构建的，而精细粒度类别仅由图片中的几个关键块确定。", "innovation": "本文提出了一种跨级多实例蒸馏(CMD)框架，用于解决该挑战。核心思想是通过多实例学习考虑图像每个块在确定精细粒度预文本表示的重要性。为了全面学习有用块和精细粒度语义之间的关系，在教师和学生网络的区域/图像裁剪对以及教师/学生网络内部的区域-图像裁剪之间实施多实例知识蒸馏，分别称为跨级多实例蒸馏和同级多实例蒸馏。", "conclusion": "在CUB-200-2011、斯坦福汽车和FGVC飞机数据集上的广泛实验表明，所提出的方法在顶层准确性和检索度量(Rank-1)方面分别优于当代方法10.14%和现有最先进的自我监督学习方法19.78%。"}
{"llm_update_time": "2025-06-25 09:21:57", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.14017", "html_url": "https://arxiv.org/abs/2405.14017", "title": "MagicPose4D：具有外观和动作控制的艺术化模型创作", "title_en": "MagicPose4D: Crafting Articulated Models with Appearance and Motion Control", "authors": "Hao Zhang,Di Chang,Fang Li,Mohammad Soleymani,Narendra Ahuja", "background": "随着2D和3D视觉生成模型的成功，人们对生成4D内容的兴趣日益增加。现有方法主要依赖文本提示生成4D内容，但在定义复杂或罕见动作时往往不够准确。为解决这一限制，本文提出了MagicPose4D，这是一种全新的框架，可以精炼地控制4D生成中的外观和运动.", "innovation": "MagicPose4D 采用蒙ocular 视频或网格序列作为动作提示，允许精确且可定制的动作控制。它包含两项关键模块：(i) 双阶段4D重建模块，通过两阶段操作分别使用精确的2D监督和几何信息丰富的3D伪监督捕获模型的形状，以及通过引入基于运动链的骨架约束来提取3D运动。此外，MagicPose4D 提出了全局-局部Chamfer损失，用于保持预测网格顶点的总体分布与监督的对齐，同时保持部分级别的对齐。 (ii) 跨类别动作转移模块，利用从4D重建模块提取的动作和基于运动链的骨架来实现跨类别动作转移，确保帧之间平滑过渡，从而实现鲁棒的泛化能力，无需额外训练。", "conclusion": "通过广泛的实验，本文表明MagicPose4D在4D内容生成的准确性和一致性方面显著优于现有方法，在多种基准测试中表现出色。"}
{"llm_update_time": "2025-06-25 09:21:58", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.18140", "html_url": "https://arxiv.org/abs/2406.18140", "title": "跨域专属风格去除用于新颖类发现", "title_en": "Exclusive Style Removal for Cross Domain Novel Class Discovery", "authors": "Yicheng Wang,Feng Liu,Junmin Liu,Kai Sun", "background": "在开放世界学习领域中，新颖类发现（NCD）通常是指基于同一领域已标记数据的先验知识，对未标记集中未见过的新颖类进行聚类的任务。然而，当新颖类来自与已有标记数据不同的分布时，现有的NCD方法可能会严重失效。", "innovation": "本文探讨并建立了在跨域设置下进行NCD的可行性，并且在必要条件下移除风格信息。通过理论分析引入了专用的风格去除模块，用于提取与基础特征不同的风格信息，从而辅助推理。此外，还参考了不同的骨干网络和预训练策略对NCD方法性能的影响，建立了一个公平基准，以便未来的NCD研究。该方法经过在三个常用数据集上的广泛实验，证明了风格去除策略的有效性，并作为NCD方法插件增强不同分布的新颖类的性能。", "conclusion": "本文提出了一个针对跨域NCD的公平基准，并开发了一个专门的风格去除模块，增强了其他NCD方法在不同分布新颖类上的性能。此外，验证了所提风格去除策略的有效性。"}
{"llm_update_time": "2025-06-25 09:21:59", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.08785", "html_url": "https://arxiv.org/abs/2310.08785", "title": "DeltaSpace：一种用于灵活文本指导图像编辑的语义对齐特征空间", "title_en": "DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing", "authors": "Yueming Lyu,Kang Zhao,Bo Peng,Huafeng Chen,Yue Jiang,Yingya Zhang,Jing Dong,Caifeng Shan", "background": "文本指导的图像编辑需要训练和推理过程中具备灵活性。多数文献通过收集大量标注的图像-文本对来训练基于文本的生成模型，这既昂贵又不高效。另一种方法是利用预训练的视觉-语言模型来避免数据收集，但这种方法要么受限于每个文本提示的优化，要么在推理时需要调优超参数，这两方面都存在局限性。因此，论文提出了一种特定的空间，称为CLIP DeltaSpace，该空间使得两幅图像的CLIP视觉特征差异与其对应文本描述的CLIP文本特征差异在语义上保持一致，并基于此空间提出了一个新的框架——DeltaEdit，该框架在训练阶段将CLIP视觉特征差异映射到生成模型的潜在空间方向，在推理阶段从前述的CLIP文本特征差异预测潜在空间方向。这种方法赋予DeltaEdit两大优势：（1）无文本的训练；（2）对各种文本提示实现零样本推理的泛化能力。", "innovation": "提出了CLIP DeltaSpace，这是一种特定的空间，使得两幅图像的CLIP视觉特征差异与其对应文本描述的CLIP文本特征差异在语义上保持一致。基于此提出了DeltaEdit框架，该框架在训练阶段将CLIP视觉特征差异映射到生成模型的潜在空间方向，在推理阶段从前述的CLIP文本特征差异预测潜在空间方向。这种方法在训练时无需使用文本，且能够在零样本的基础上适应各种文本提示的推理，提高了文本指导图像编辑的灵活性与效率，验证了DeltaEdit在不同生成模型（包括生成对抗网络GAN和扩散模型）中的有效性和通用性。", "conclusion": "通过DeltaSpace，DeltaEdit在训练时无需使用文本，并且能够在零样本的基础上适应各种文本提示的推理。广泛实验表明，DeltaEdit不仅在灵活性方面表现出色，而且在不同生成模型（包括GAN和扩散模型）中具有良好的通用性和有效性，这种设计提高了文本指导图像编辑的效率和灵活性。"}
{"llm_update_time": "2025-06-25 09:22:00", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.09922", "html_url": "https://arxiv.org/abs/2405.09922", "title": "跨传感器自监督训练和对齐用于遥感", "title_en": "Cross-sensor self-supervised training and alignment for remote sensing", "authors": "Valerio Marsocci(CEDRIC - VERTIGO, Cnam),Nicolas Audebert(CEDRIC - VERTIGO, Cnam, LaSTIG, IGN)", "background": "大规模的“基础模型”由于能充分利用每天收集的大量未标记的遥感数据而逐渐受到重视。然而，由于地球观测卫星种类繁多，这些模型需要学习与传感器特性无关的表示，以最小的微调实现跨传感器通用性。由于数据可获取性的限制，低分辨率图像（如Sentinel-2和Landsat-8数据）大量存在，但高分辨率航空或卫星数据较为稀缺，这增加了学习通用表示的挑战。", "innovation": "本文引入了跨传感器自监督训练和对齐方法（X-STARS），设计了一种新的自监督训练损失函数——多传感器对齐密集损失（MSAD），用于即使在分辨率差异极大的情况下也能对齐跨传感器的表示。X-STARS既可用于从零开始训练模型，也可用于将已在低分辨率地球观测数据上预训练的大模型适应新的高分辨率传感器，这是一种持续预训练框架。文中使用MSC-France多传感器数据集训练X-STARS模型，并在七个下游分类和分割任务上进行评估。结果表明，X-STARS在各种数据可用性和分辨率条件下能够显著优于现有最先进的方法，使用较少的数据也能取得更好效果。", "conclusion": "跨传感器自监督训练和对齐方法（X-STARS）能够显著提高遥感数据的分析能力，特别是在数据稀缺和分辨率不一的情况下。通过这种方法，模型能够更好地适应多样化的地球观测数据，从而提高遥感图像分类和分割任务的性能。"}
{"llm_update_time": "2025-06-25 09:22:03", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.09838", "html_url": "https://arxiv.org/abs/2406.09838", "title": "ClimateIQA: 用于气象异常分析的新型数据集和基准", "title_en": "ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis", "authors": "Jian Chen,Peilin Zhou,Yining Hua,Dading Chong,Meng Cao,Yaowei Li,Zixuan Yuan,Bing Zhu,Junwei Liang", "background": "气象热图在解释极端天气现象方面发挥着重要作用，但其内部复杂性，比如不规则轮廓、无序模式和复杂颜色变化，给现有的视觉-语言模型（VLMs）带来独特的分析挑战。当前最先进的模型，如GPT-4o、Qwen-VL和LLaVA 1.6，在精确颜色识别和空间定位方面表现不佳，导致解释不准确或不完整。由于这些挑战的存在，亟需开发新的算法来处理视觉数据中的不规则彩色区域。", "innovation": "我们提出了Sparse Position and Outline Tracking（SPOT），一种新型算法，专门处理视觉数据中不规则形状的彩色区域。SPOT通过提取空间坐标来识别和定位这些区域，从而实现不规则形状的结构化表示。基于SPOT，我们构建了ClimateIQA，这是一个包含26,280个高分辨率热图和762,120个用于风速、总量降水、风寒指数和热指数分析的指令样本的新视觉问答（VQA）数据集。ClimateIQA通过引入空间线索、地理元数据和再分析数据，增强了VLM的训练，从而提高了模型在解释和描述极端天气特征方面的准确性。此外，我们开发了Climate-Zoo，一个基于SPOT支持ClimateIQA的微调VLM套件，这些模型在气象热图任务中表现优于现有模型。", "conclusion": "ClimateIQA为气象异常分析提供了一个新的数据集和基准，通过结合空间线索、地理元数据和再分析数据，改善了视觉-语言模型在任务中的表现。Climate-Zoo套件显著提高了现有模型在气象热图任务中的性能，标志着在处理气象热图数据方面的一大进步。"}
{"llm_update_time": "2025-06-25 09:22:03", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.13980", "html_url": "https://arxiv.org/abs/2408.13980", "title": "Visual Multi-Modal Learning with Segment Anything", "title_en": "FusionSAM: Visual Multi-Modal Learning with Segment Anything", "authors": "Daixun Li,Weiying Xie,Mingxiang Cao,Yunke Wang,Yusi Zhang,Leyuan Fang,Yunsong Li,Chang Xu", "background": "多模态图像融合和语义分割在自动驾驶中至关重要。尽管取得了进展，但现有的模型在训练过程中由于缺乏综合的融合特征指导，往往难以分割密集排列的元素。虽然Segment Anything Model (SAM)可以通过其灵活的提示编码器在微调时提供精确控制，但其在自然图像的多模态分割上下文中的潜力尚未充分探索。", "innovation": "本文提出了一种新颖的方法，称为FusionSAM，将SAM引入多模态图像分割中，并结合了Latent Space Token Generation (LSTG) 和 Fusion Mask Prompting (FMP) 模块。该方法将多模态分割的训练方法从传统的黑盒方法转变为可控的提示机制。具体来说，通过向量量化获得两种模态的潜在空间特征，并将这些特征嵌入到基于交叉注意力的跨域融合模块中，以建立模态间的长期依赖关系。利用这些综合的融合特征作为提示来引导精确的像素级分割。实验结果表明，该方法在多模态自动驾驶场景中显著优于SAM和SAM2，平均提高语义分割mIoU的4.1%，同时在其他多模态视觉场景中也优化了性能。", "conclusion": "实验结果表明，与最先进的方法相比，该方法在分割密集元素方面表现更优，特别是在自动驾驶场景中的多模态视觉分割任务中，取得了显著的提升，平均提高了4.1%的mIoU，同时在其他多模态视觉场景中也优化了性能。"}
{"llm_update_time": "2025-06-25 09:22:05", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.16767", "html_url": "https://arxiv.org/abs/2408.16767", "title": "ReconX: 使用视频扩散模型从少量视角重构任意场景", "title_en": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model", "authors": "Fangfu Liu,Wenqiang Sun,Hanyang Wang,Yikai Wang,Haowen Sun,Junliang Ye,Jun Zhang,Yueqi Duan", "background": "3D场景重建技术已经使得2D图像能够转换成3D模型，且从数百张输入照片中生成高度真实的3D结果。尽管在密集视角重建场景上取得了巨大成功，但从少量捕获视角重建详细场景仍是优化难题，会导致未见区域出现艺术和失真现象。", "innovation": "ReconX 提出了一种新颖的3D场景重建范式，它将模糊的重建挑战重新定义为一种时间生成任务。关键洞察是利用大规模预训练视频扩散模型的强大生成先验，用于稀疏视角重建。此外，ReconX首次构建全局点云，将其编码到上下文空间作为3D结构条件，通过该条件指导视频扩散模型生成既保留细节又具有高度3D一致性的视频帧，确保多角度场景的连贯性。最后，通过一种基于置信度的3D高斯散斑优化方案从生成的视频中恢复3D场景。", "conclusion": "在多种真实世界数据集上的广泛实验表明，ReconX 在质量和泛化能力方面优于现有先进技术。"}
{"llm_update_time": "2025-06-25 09:22:05", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.02157", "html_url": "https://arxiv.org/abs/2407.02157", "title": "FineCLIPER: 多模态细粒度CLIP用于带有AdaptER的动态面部表情识别", "title_en": "FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs", "authors": "Haodong Chen,Haojian Huang,Junhao Dong,Mingzhe Zheng,Dian Shao", "background": "动态面部表情识别（DFER）对于理解人类行为至关重要。然而，当前的方法由于高质量数据稀缺、面部动态不足利用和表情语义模糊等问题表现出有限的性能。", "innovation": "提出了一种名为Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs（FineCLIPER）的新型框架，包括以下创新设计：1）为更好地区分相似的表情，将类别标签扩展为正面和负面方面的文本描述，并通过CLIP模型计算跨模态相似性获得监督；2）FineCLIPER采用分层方式从DFE视频中有效地挖掘有用线索。除直接将视频帧作为输入（低语义层次）外，还提出基于每帧提取面部分割掩码和关键点，并使用多模态大型语言模型（MLLM）通过设计提示生成跨帧的面部变化详细描述（高语义层次）。同时，还采用了参数高效微调（PEFT），使大型预训练模型（如CLIP）能够高效适应该任务。FineCLIPER在DFEW、FERV39k和MAFW数据集上均达到最先进的性能，且参数较少。", "conclusion": "在监督任务和零样本设置中，FineCLIPER实现了DFEW、FERV39k和MAFW数据集上的最佳性能，参数数量较少。"}
{"llm_update_time": "2025-06-25 09:22:09", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.09306", "html_url": "https://arxiv.org/abs/2410.09306", "title": "TD-Paint：通过时间感知像素条件实现更快的扩散修复", "title_en": "TD-Paint: Faster Diffusion Inpainting Through Time Aware Pixel Conditioning", "authors": "Tsiry Mayet,Pourya Shamsolmoali,Simon Bernard,Eric Granger,Romain Hérault,Clement Chatelain", "background": "扩散模型在修复任务中已展现出高效性，但其采样速率较慢。尽管生成质量有所提升，但采样时间也增加了，限制了其在实际应用中的可扩展性。生成性采样过程中的初始步骤中，基于扩散的修复模型对输入条件使用较少，导致采样轨迹偏离数据流形，需要复杂的同步机制来校准生成过程。", "innovation": "提出了一种名为Time-aware Diffusion Paint (TD-Paint)的新方法，该方法通过在像素级别建模可变噪声水平来适应扩散过程。这种方法允许模型从一开始就能有效地使用已知像素值，从而引导生成过程向着目标流形前进。通过在扩散过程中早期嵌入这些信息，TD-Paint在不牺牲图像质量的情况下显著加速了采样。与传统的基于扩散的修复模型相比，TD-Paint不需要专用架构或昂贵的生成循环即可实现更快的采样时间。", "conclusion": "在三个数据集上的实验结果显示，TD-Paint在保持较低复杂度的同时，优于现有的最先进的扩散模型。"}
{"llm_update_time": "2025-06-25 09:22:10", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06347", "html_url": "https://arxiv.org/abs/2411.06347", "title": "基于动态面部表情的日本手语分类", "title_en": "Classification in Japanese Sign Language Based on Dynamic Facial Expressions", "authors": "Yui Tatsumi,Shoko Tanaka,Shunsuke Akamatsu,Takahiro Shindo,Hiroshi Watanabe", "background": "手语是一种通过手部动作和非手动标记表达的视觉语言。非手动标记包括面部表情和头部动作，这些表情在不同的国家之间各不相同。因此，每个手语都需要专门的分析方法。然而，由于缺乏数据集，对日本手语（JSL）的研究有限。准确和流畅地与聋人进行交流的关键是开发能够同时考虑JSL的手部和非手动特征的识别模型。在JSL中，肯定陈述句和疑问句等句子类型是通过面部表情区别的。", "innovation": "本文提出了一种基于面部表情的JSL识别方法，利用神经网络分析面部特征并分类句子类型，从而针对JSL中面部表情的特定应用进行了创新研究，提高了识别的准确性和效率，实验结果表明该方法的分类精度达到了96.05%。", "conclusion": "研究表明，通过分析JSL的手部动作和动态面部表情可以实现96.05%的准确分类，这对于促进与聋人的有效沟通至关重要。"}
{"llm_update_time": "2025-06-25 09:22:10", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.10652", "html_url": "https://arxiv.org/abs/2406.10652", "title": "MDeRainNet: 一种高效的宏像素图像雨滴去除网络", "title_en": "MDeRainNet: An Efficient Macro-pixel Image Rain Removal Network", "authors": "Tao Yan,Weijiang He,Chenglong Wang,Cihang Wei,Xiangjie Zhu,Yinghui Wang,Rynson W.H. Lau", "background": "由于雨水天气会降低图像质量并给大多数基于计算机视觉的智能系统带来挑战，因此图像去雨已经成为热点研究课题。现有的雨天全视角图像去除方法要么没有充分利用4D全视角数据的全局关联性，要么只利用部分子视角，这导致了去雨性能和去雨后子视角图像质量不佳。", "innovation": "本文提出了一种高效的网络，称为MDeRainNet，用于从全视角图像中去除雨迹。该网络采用多尺度编码-解码架构，并直接处理宏像素图像以提高去雨性能。还提出了扩展的空间-角度交互模块（ESAI），以全面建模空间和角度信息之间的全局关联，其中还提出了一种基于Transformer的长距离几何关联的空间-角度交互注意力（SAIA）块，以充分利用角度信息。此外，为了提高网络在实际雨天场景中的泛化性能，提出了一个新颖的半监督学习框架，利用多级KL损失来弥合合成和实际雨迹在特征上的领域差距，引入了彩色残留图像引导对比正则化，以重建无雨图像。", "conclusion": "在合成和实际全视角图像上的广泛实验表明，我们的方法在定量和定性上都优于最先进的方法。"}
{"llm_update_time": "2025-06-25 09:22:11", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19816", "html_url": "https://arxiv.org/abs/2506.19816", "title": "CronusVLA: 跨时间传递潜在动作以实现多帧预测在操纵中的应用", "title_en": "CronusVLA: Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation", "authors": "Hao Li,Shuai Yang,Yilun Chen,Yang Tian,Xiaoda Yang,Xinyi Chen,Hanqing Wang,Tai Wang,Feng Zhao,Dahua Lin,Jiangmiao Pang", "background": "近期基于预训练视觉-语言模型（VLMs）的视觉-语言-行动（VLA）模型在执行任务上展现出了强大的泛化能力，然而，这些模型仍然受限于单帧观察的范式，无法充分发挥多帧历史观察提供的运动信息的优势。由于大型视觉-语言主干带来的计算成本和推理延迟较高，现有的VLA模型无法充分利用这些信息。为解决这一问题，本文提出了一种名为CronusVLA的统一框架，通过一个高效的后训练阶段将单帧VLA模型扩展到多帧范式中。", "innovation": "CronusVLA框架包含三个关键组件：1）大规模具身数据集上的单帧预训练，使用自回归动作标记预测，建立视觉-语言基础；2）多帧编码，在后训练阶段将视觉-语言主干的预测从离散动作标记转换为运动特征，并将历史帧的运动特征聚合为特征片段；3）跨帧解码，通过共享解码器与交叉注意力机制，将特征片段映射为准确动作。此外，提出了基于特征-动作检索的动作适应机制，以改进模型的微调性能。CronusVLA通过减少冗余的令牌计算并缓存过往运动特征，实现了高效的推理，并在SimplerEnv中达到了70.9%的成功率，优于OpenVLA在LIBERO上的表现12.7%。在现实中的Realworld Franka实验中，也展示了其强大的性能和鲁棒性。", "conclusion": "综上所述，CronusVLA实现了一个从单帧到多帧框架的过渡，通过利用历史信息中的运动特征进行高效的推理，显著提高了模型的性能和鲁棒性，展示了在视觉-语言-行动任务上的重大进步。"}
{"llm_update_time": "2025-06-25 09:22:14", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.06533", "html_url": "https://arxiv.org/abs/2501.06533", "title": "DivTrackee 对比 DynTracker：针对动态面部识别策略促进反面部识别的多样性", "title_en": "DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition against Dynamic FR Strategy", "authors": "Wenshu Fan,Minxing Zhang,Hongwei Li,Wenbo Jiang,Hanxiao Chen,Xiangyu Yue,Michael Backes,Xiao Zhang", "background": "面部识别（FR）模型的广泛使用带来了其潜在滥用的重大担忧，这促进了对抗面部识别（AFR）的发展以保护用户面部隐私。然而，现有的静态FR策略无法准确反映具有特定目标跟踪意图的追踪者的实际能力。研究提出了一种动态FR策略DynTracker，并指出现有的AFR保护方法在这种策略下无效。因此，本文强调了在AFR-保护图像中促进多样性的必要性，并提出了一个名为DivTrackee的新方法来对抗动态FR策略。", "innovation": "引入了动态FR策略DynTracker，通过迭代地更新模型的画廊数据库来增强其能力；提出了一种名为DivTrackee的新方法，通过基于文本的图像生成框架和促进多样性的对抗损失来对抗动态FR策略，并通过实验证明其效果优于现有方法。", "conclusion": "实验结果显示DynTracker能够打破现有的AFR方法，而DivTrackee则更有效地防止用户面部图像被动态FR策略识别。本文认为，我们的研究可以作为开发更有效的AFR方法以保护用户面部隐私的一个重要开端。"}
{"llm_update_time": "2025-06-25 09:22:15", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.01023", "html_url": "https://arxiv.org/abs/2501.01023", "title": "Hadamard Attention Recurrent Transformer: 一种用于立体匹配变换器的强大基线", "title_en": "Hadamard Attention Recurrent Transformer: A Strong Baseline for Stereo Matching Transformer", "authors": "Ziyang Chen,Wenting Li,Yongjun Zhang,Yabo Wu,Bingshu Wang,Yong Zhao,C.L. Philip Chen", "background": "当前的立体匹配变换器受到注意力机制固有的低秩瓶颈限制，这限制了它们的非线性表达能力，使得它们在反射等挑战性条件下特征表示敏感。", "innovation": "提出了一种名为Hadamard注意力递归立体变换器（HART）的新模型。HART包含一种新颖的注意力机制，该机制包括：1) 密集注意力核（DAK）将注意力权重分布映射到（0，+∞）上的高维空间。通过移除注意力权重的上限约束，DAK允许更灵活地建模复杂的特征交互，减少特征共线性。2) 多核与顺序交互（MKOI）模块将语义和空间知识学习统一，以提高HART在双目图像中学习特征的能力。实验结果表明HART的有效性，特别是在反射区域，HART在提交时是Kitti 2012基准上所有已发表方法中的第一名。", "conclusion": "实验结果表明HART在反射区域性能最佳，在提交时是Kitti 2012基准上使用立体匹配变换器方法中最好的。"}
{"llm_update_time": "2025-06-25 09:22:15", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05266", "html_url": "https://arxiv.org/abs/2410.05266", "title": "使用密集特征的大脑映射：用视觉变换器在自然图像上将皮层的语义选择性与之关联", "title_en": "Brain Mapping with Dense Features: Grounding Cortical Semantic Selectivity in Natural Images With Vision Transformers", "authors": "Andrew F. Luo,Jacob Yeung,Rushikesh Zawar,Shaurya Dewan,Margaret M. Henderson,Leila Wehbe,Michael J. Tarr", "background": "该研究引入了一种名为BrainSAIL的方法，用于将神经选择性与自然场景中分布的语义视觉概念联系起来。这种方法利用了大规模人工神经网络的最新进展，通过分析这些神经网络的语义一致密集空间特征来深入了解大脑的功能拓扑结构。面对自然图像中多个类别共同出现的挑战，BrainSAIL通过利用预训练视觉模型中语义一致的密集空间特征来解决问题。该方法能够提取干净的、空间密集的嵌入，而无需额外训练，并通过一种新颖的去噪过程，利用随机增强下图像的语义一致性。通过将全图嵌入空间与密集视觉特征统一，并应用体素编码模型，该方法能够识别不同视觉皮层区域中驱动特定选择性模式的特定子区域，从而为解剖视觉皮层中的语义视觉处理提供了强大的工具。研究验证了BrainSAIL在具有已知类别选择性的皮层区域中的有效性，并展示了其在局部化和分离不同视觉概念选择性方面的准确性。该研究进一步证明了BrainSAIL能够表征高级视觉选择性以及低级视觉特征，如深度、亮度和饱和度，为复杂视觉信息的编码提供了见解，并通过比较不同大脑编码模型在视觉皮层不同感兴趣区域的特征选择性，展示了这种方法的价值。", "innovation": "BrainSAIL方法通过利用大规模人工神经网络的语义一致密集空间特征，有效解决了自然图像中多个类别共现的挑战。该方法提取了干净的、空间密集的嵌入，并利用了一种新颖的去噪过程来提高图像特征的一致性。这种方法能够在全图嵌入空间和密集视觉特征之间建立关联，并通过体素编码模型来识别不同区域的特定选择性模式，从而提供了一种强大的工具以解剖神经结构中语义视觉处理的机制。此外，该方法还能够直接比较不同大脑编码模型的特征选择性，为进一步研究高阶视觉表征的映射和分解奠定了基础.", "conclusion": "该研究通过BrainSAIL方法展示了在自然图像中定位和区分复杂的视觉概念的能力。这种方法有效地将视觉皮层的语义选择性与视觉变换器相关的空间特征相结合，为高阶视觉表征的大脑映射和分解提供了重要工具。该方法证实了其在验证皮层区域类别选择性方面的有效性，并展示了其在高级和低级视觉特征编码方面的应用潜力。这种方法为研究大脑中视觉处理的神经机制提供了新的视角，有助于推动大脑中的高阶视觉表征研究的进步。"}
{"llm_update_time": "2025-06-25 09:22:16", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.11299", "html_url": "https://arxiv.org/abs/2501.11299", "title": "MIFNet：学习泛在的多模态图像匹配的模态不变特征", "title_en": "MIFNet: Learning Modality-Invariant Features for Generalizable Multimodal Image Matching", "authors": "Yepeng Liu,Zhichao Sun,Baosheng Yu,Yitian Zhao,Bo Du,Yongchao Xu,Jun Cheng", "background": "许多关键点检测和描述方法被提出用于图像匹配或注册。虽然这些方法在单一模态图像匹配中表现出色，但在处理多模态数据时常常出现困难，因为在多模态数据中存在的非线性变化使单模态训练的数据描述符往往缺乏鲁棒性。将这些方法扩展到多模态图像匹配通常需要对齐的多模态数据来学习模态不变的描述符。然而，获取这种数据在实际中往往是成本高昂且不切实际的。", "innovation": "为了应对这一挑战，我们提出了一种模态不变特征学习网络（MIFNet），用于仅使用单模态训练数据在多模态图像匹配中计算模态不变特征。具体来说，我们提出了一个新颖的潜在特征聚合模块和一个累积混合聚合模块，通过利用预训练的来自Stable Diffusion模型的特征来增强基于单模态数据训练的基础关键点描述符。我们的方法能够在多样且未知的模态下生成鲁棒和不变的特征。", "conclusion": "广泛的实验表明，所提出的MIFNet能够在无需访问目标模态的情况下学习多模态图像匹配的模态不变特征，并具有良好的零样本泛化能力。"}
{"llm_update_time": "2025-06-25 09:22:16", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.12029", "html_url": "https://arxiv.org/abs/2403.12029", "title": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection", "title_en": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection", "authors": "Justin Kay,Timm Haucke,Suzanne Stathatos,Siqi Deng,Erik Young,Pietro Perona,Sara Beery,Grant Van Horn", "background": "对象探测器在面对与训练集不同的数据时表现不佳。现有的领域适应性对象检测（DAOD）方法虽然取得了一些进展，但由于基准测试过程中的几个关键问题，这些结果受到质疑，阻碍了进一步的进步：(a) 基线方法不充分导致高估性能；(b) 不一致的实现方案阻碍了方法之间的透明比较；(c) 由于过时的网络架构和缺乏多样性的基准，其通用性有限。", "innovation": "引入了一个统一的基准测试和实现框架Align and Distill (ALDI)，它包括：(1) 支持DAOD方法比较的公平、现代的训练和评估协议；(2) 一个全新的DAOD基准数据集CFC-DAOD，能够在多样化的真实世界数据上进行评估；(3) 一种新的方法ALDI++，实现了显著的最先进结果，在Cityscapes到雾城街景数据集、Sim10k到Cityscapes数据集以及CFC Kenai到Channel数据集上的结果分别为+3.5 AP50、+5.7 AP50和+0.6 AP50。ALDI和ALDI++是架构无关的，为YOLO和DETR基于的DAOD设定了新的最先进水平，且不需额外的超参数调整。", "conclusion": "我们的框架、数据集以及最新的方法为DAOD提供了新的基础，并为未来的研究提供了强有力的支撑。"}
{"llm_update_time": "2025-06-25 09:22:19", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02514", "html_url": "https://arxiv.org/abs/2502.02514", "title": "图像自回归模型的隐私攻击", "title_en": "Privacy Attacks on Image AutoRegressive Models", "authors": "Antoni Kowalczuk,Jan Dubiński,Franziska Boenisch,Adam Dziedzic", "background": "图像自回归生成已发展成为一种强有力的范式，图像自回归模型（IARs）在图像质量（FID: 1.48 vs. 1.58）方面与当前最先进的扩散模型（DMs）相当，但生成速度更快。然而，与IARs相关的隐私风险尚未被研究，这引发了对其负责任部署的关注。", "innovation": "该研究首次进行了全面的IARs隐私分析，与DMs进行了比较。开发了一种新型的成员身份推断攻击（MIA），在检测训练图像方面的成功率为86.38%，远超DMs的6.38%，并且只需要6个样本即可检测数据集成员身份，这表明IARs的信息泄露更多。成功从IARs中提取了大量训练数据点（例如，从VAR-d30中提取了698个）。", "conclusion": "研究结果揭示了隐私-实用性权衡：虽然IARs在图像生成质量和速度方面表现出色，但它们实际上比实现相似性能的DMs更容易受到隐私攻击的影响。代码已发布，以确保可复现性。"}
{"llm_update_time": "2025-06-25 09:22:19", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02690", "html_url": "https://arxiv.org/abs/2502.02690", "title": "以可验证分割实现可控视频生成", "title_en": "Controllable Video Generation with Provable Disentanglement", "authors": "Yifan Shen,Peiyuan Zhu,Zijian Li,Shaoan Xie,Zeyu Tang,Namrata Deka,Zongfang Liu,Guangyi Chen,Kun Zhang", "background": "尽管近年来生成高质量和一致视频的技术取得了进展，但可控视频生成仍然是一个重大挑战，尤其是在处理复杂的精细时空关系方面仍然存在局限性，影响了控制精度和效率。现有的方法大多将视频作为一个整体来处理，未能充分考虑视频中的结构关系，从而控制效果受限。", "innovation": "本文提出了可控视频生成对抗网络（CoVoGAN），旨在分解视频概念，从而实现对单个概念的有效且独立的控制。首先，通过最小变化原则解耦静态和动态潜在变量；其次，利用充分变化的属性来实现动态潜在变量的组件级可识别性，以便有效地控制视频生成。为了奠定理论基础，本文提供了一种严格的分析来展示方法的可识别性，并基于这些理论洞察设计了一个时间过渡模块来解耦潜在动态变化。并通过最小化潜在动态变量的维度和引入时间条件独立性确保最小变化原则和充分变化属性的实现。", "conclusion": "在各种视频生成基准测试中的大量定性和定量实验表明，本文的方法在多个实际场景中显著提高了生成质量和控制力。"}
{"llm_update_time": "2025-06-25 09:22:20", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.05169", "html_url": "https://arxiv.org/abs/2502.05169", "title": "利用对称性进行计算效率提升：利用不变性减少浮点运算", "title_en": "Flopping for FLOPs: Leveraging equivariance for computational efficiency", "authors": "Georg Bökman,David Nordström,Fredrik Kahl", "background": "将几何不变性融入神经网络可以提高参数效率，但通常会增加计算成本。这项研究聚焦于在保持与标准非对称网络相似的浮点操作数（FLOPs）条件下，通过引入新的对称神经网络，同时保持对称性。特别关注水平翻转不变性，这种不变性在许多计算机视觉任务中很常见。", "innovation": "本文提出了一种新的对称神经网络方法，通过在网络特征空间中参数化镜像对称和镜像反对称特征（即翻转群的不可约表示），将线性层分解为块对角形式，从而只需要一半的浮点运算数（FLOPs）。这种方法不仅能减少FLOPs，还能减少实际运算时间，提供了高效的、可扩展的对称性感知架构的实际解决方案。", "conclusion": "本文介绍了一种创新的机制，通过参数化镜像对称和反对称特征，使得神经网络在保持对称性的同时减少了FLOPs和实际运算时间，为构建高效且可扩展的对称性感知架构提供了实用方案。"}
{"llm_update_time": "2025-06-25 09:22:22", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20803", "html_url": "https://arxiv.org/abs/2502.20803", "title": "基于自然对话关键点的两流空间-时间变换器框架对人体识别", "title_en": "Two-Stream Spatial-Temporal Transformer Framework for Person Identification via Natural Conversational Keypoints", "authors": "Masoumeh Chapariniya,Hossein Ranjbar,Teodora Vukovic,Sarah Ebling,Volker Dellwo", "background": "在人工智能驱动的生成技术的时代，传统的生物识别系统面临着前所未有的挑战，特别是来自高超的深度伪造和面部复现技术的挑战。本研究旨在利用可见于在线对话中的上身关键点进行人体识别，提出了一种两流空间-时间变换器框架（Two-Stream Spatial-Temporal Transformer Framework），称为对话关键点。该框架通过两个专门分支处理关键点之间的空间关系和它们的时序演变，以识别特定的结构模式和序列运动模式。", "innovation": "本研究创新地利用了上身关键点来进行人体识别，并提出了两流空间-时间变换器框架。通过结合空间流和时间流，该框架能够同时建模静态解剖关系和动态运动模式，从特征级融合方法中获得了显著的性能提升，识别准确率达到94.86%，这种对于欺骗的鲁棒性优于传统的基于外观的方法。", "conclusion": "该研究通过两流空间-时间变换器框架，不仅提升了识别准确率，还增强了对抗欺骗的鲁棒性，为人体识别领域提供了新的解决方案。"}
{"llm_update_time": "2025-06-25 09:22:23", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08025", "html_url": "https://arxiv.org/abs/2503.08025", "title": "通过非负隐神经表示因式分解的动态PET图像重建", "title_en": "Dynamic PET Image Reconstruction via Non-negative INR Factorization", "authors": "Chaozhi Zhang,Wenxiang Ding,Roy Y. He,Xiaoqun Zhang,Qiaoqiao Ding", "background": "从噪声投影数据中重建动态正电子发射断层扫描（PET）图像是一个重要的但具有挑战性的问题。", "innovation": "提出了基于低秩矩阵分解的无监督学习方法——非负隐神经表示因式分解（NINRF），使用神经网络表示系数和基函数，引入隐神经表示（INR）将矩阵与连续函数连接起来，并通过最小化KL散度和稀疏正则化获取神经网络参数，从而对动态PET图像进行重建，展现出对物体几何细节和区域浓度变化的连续表示效果，相比其他方法更有效。", "conclusion": "所提出的NINRF方法在处理动态PET图像重建中的泊松噪声数据时，表现出良好的效果，同时也能够提供物体的详细几何特征及其区域浓度的变化的连续表示。"}
{"llm_update_time": "2025-06-25 09:22:25", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.10044", "html_url": "https://arxiv.org/abs/2504.10044", "title": "使动漫视频生成符合人类反馈", "title_en": "Aligning Anime Video Generation with Human Feedback", "authors": "Bingwen Zhu,Yudong Jiang,Baohan Xu,Siqian Yang,Mingyu Yin,Yidi Wu,Huyang Sun,Zuxuan Wu", "background": "由于动漫数据稀缺以及独特的运动模式，动漫视频生成面临重大挑战，导致运动失真、闪烁伪影等问题，这些与人类偏好不符。现有的基于奖励模型主要针对真实世界视频，难以捕捉动漫视频的独特视觉外观和一致性要求。因此，需要一种新的方法来提升动漫视频生成的质量，使其更符合人类的偏好。", "innovation": "本文提出了一种管道方法，通过人类反馈增强动漫视频生成。具体包括：1) 构建了第一个适用于动漫视频的多维度奖励数据集，包含30,000个人类标注样本；2) 开发了AnimeReward，一种具有专门视觉-语言模型的奖励模型，用于指导偏好的对齐；3) 引入了一种称为Gap-Aware Preference Optimization (GAPO) 的新颖训练方法，该方法明确将偏好差距纳入优化过程，以提升对齐效果和效率。", "conclusion": "实验结果表明，AnimeReward在定量基准和人类评估中都表现出色，优于现有的奖励模型。而GAPO的引入显著提升了对齐性能和效率，证明了本文提出的管道的有效性，能够提高动漫视频的质量。相关代码和数据集在提供链接处公开可用。"}
{"llm_update_time": "2025-06-25 09:22:27", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12273", "html_url": "https://arxiv.org/abs/2504.12273", "title": "超越重构：一种基于物理的神经延迟着色器实现真实感渲染", "title_en": "Beyond Reconstruction: A Physics Based Neural Deferred Shader for Photo-realistic Rendering", "authors": "Zhuo He,Paul Henderson,Nicolas Pugeault", "background": "基于深度学习的渲染已经在照片级真实感图像合成方面取得了重大进展，应用场景包括电影中的视觉效果和视频游戏中的照片级真实感场景构建。然而，这类方法的一个显著限制是难以分解光照和材质参数，这使得它们仅限于重建输入场景，而无法控制这些参数。", "innovation": "该论文提出了一种新颖的基于物理的神经延迟着色管道，以分解数据驱动的渲染过程，学习一种通用的着色函数，用于产生着色和重新照明任务的照片级真实感结果；此外，提出了一个阴影估计器，以高效地模拟阴影效果。该模型在经典模型和最先进的神经着色模型中实现了更优的表现，并能够从任意光照输入中实现可推广的照片级真实感着色。", "conclusion": "该模型通过更优的性能和通用的光输入，实现了改进的照片级真实感着色，为着色和重新照明任务提供了新的解决方案。"}
{"llm_update_time": "2025-06-25 09:22:27", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.01668", "html_url": "https://arxiv.org/abs/2504.01668", "title": "基于重叠感知的特征学习在鲁棒无监督域适应中的3D语义分割", "title_en": "Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation for 3D Semantic Segmentation", "authors": "Junjie Chen,Yuecong Xu,Haosheng Li,Kemi Ding", "background": "3D点云语义分割（PCSS）在机器人系统和自动驾驶中的环境感知中起着基石作用，能够通过点级分类实现精准场景理解。虽然无监督域适应（UDA）有助于缓解PCSS中的标签稀缺问题，但现有方法未能充分考虑真实世界干扰（例如雪、雾、雨）和对抗性扭曲对鲁棒性的影响。这一工作首先识别了当前PCSS-UDA鲁棒性中的两个内在局限性：（a）共享类区域中未对齐边界的未监督特征重叠；（b）由领域不变学习带来的特征结构侵蚀，这种学习抑制了目标特异性模式。这些因素都是过去方法未能解决的挑战.", "innovation": "本文提出了一种由三部分组成的框架来解决这些问题：1）一个鲁棒性评估模型，通过鲁棒度指标量化模型抵抗对抗攻击或损坏类型的韧性；2）一个双向域映射的同时保持辨别结构的可逆注意力对齐模块（IAAM）；3）一个基于质量感知的对比记忆库，它通过逐步细化伪标签来获得具有辨别性的表示。该框架在对抗攻击下的最大mIoU改进为14.3%.", "conclusion": "本文提出了一种新的框架，通过鲁棒性评估模型、可逆注意力对齐模块和基于质量感知的对比记忆库来解决无监督域适应（UDA）中的鲁棒性问题。实验结果表明，该方法在对抗攻击下的表现显著优于现有方法，最大提高了14.3%的mIoU."}
{"llm_update_time": "2025-06-25 09:22:28", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.07721", "html_url": "https://arxiv.org/abs/2412.07721", "title": "ObjCtrl-2.5D：基于相机姿态的无训练物体控制", "title_en": "ObjCtrl-2.5D: Training-free Object Control with Camera Poses", "authors": "Zhouxia Wang,Yushi Lan,Shangchen Zhou,Chen Change Loy", "background": "当前图像到视频（I2V）生成方法通常使用二维轨迹表示目标物体的空间移动，往往无法准确捕捉用户意图，导致生成结果不自然。为了增强控制效果，研究提出了一种名为ObjCtrl-2.5D的无训练物体控制方法，该方法使用结合了深度信息的三维轨迹作为控制信号，通过将物体运动建模为相机运动，使得无需训练即可使用现有的相机运动控制I2V生成模型（CMC-I2V）来实现物体运动控制。为了使CMC-I2V模型从全局运动控制适应为局部物体运动控制，引入了一个模块将目标物体从背景中分离出来，实现独立的局部控制。此外，通过帧间共享物体区域内低频变形的潜在变量，提出了提高物体控制精度的有效方法。", "innovation": "ObjCtrl-2.5D通过使用结合深度信息的三维轨迹作为控制信号，将物体运动建模为相机运动，从而无需训练即可实现物体运动控制。通过引入一个分离目标物体的模块，使得CMC-I2V模型能够处理局部物体运动，并提出了一种帧间共享物体区域内低频变形的潜在变量的方法以提高物体控制精度。研究结果表明，ObjCtrl-2.5D在物体控制精度上显著优于无训练方法，并且提供了比基于训练的二维轨迹方法更广泛的控制能力，能够实现复杂的如物体旋转的效果。", "conclusion": "广泛实验表明，与无训练方法相比，ObjCtrl-2.5D在物体控制精度上取得了显著改善，并且在复杂效果的实现上优于基于训练的方法，如物体旋转等。"}
{"llm_update_time": "2025-06-25 09:22:30", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.04293", "html_url": "https://arxiv.org/abs/2502.04293", "title": "GCE-Pose: 全局上下文增强用于类别级对象姿态估计", "title_en": "GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation", "authors": "Weihang Li,Hongli Xu,Junwen Huang,Hyunjun Jung,Peter KT Yu,Nassir Navab,Benjamin Busam", "background": "在无需模型的情况下进行类别级别的姿态估计面临的主要挑战是提取具有跨实例通用性的上下文特征。现有方法利用基础特征捕捉数据中的语义和几何线索，但在部分可见的情况下效果不佳。为了克服这一问题，本研究采用了先提取全局特征然后聚合的策略，并利用类别先验信息。基于此，提出了GCE-Pose方法，该方法通过集成计类别级别的全局上下文先验来增强对新实例的姿态估计。GCE-Pose采用了一个语义形状重建（SSR）模块来执行语义形状重建，并引入了一个全局上下文增强（GCE）特征融合模块来有效融合部分 RGB-D 观测和重构的全局上下文的特征。实验验证了全局上下文先验和 GCE 融合模块的有效性，GCE-Pose在具有挑战性的 HouseCat6D 和 NOCS-REAL275 数据集上显著优于现有方法。", "innovation": "GCE-Pose 提出了一种全局上下文增强的方法，通过集成类别级别的全局上下文先验来增强对新实例的姿态估计。具体创新点包括：1. 语义形状重建（SSR）模块通过变形特定类别 3D 语义原型来进行实例的几何和语义重建；2. 全局上下文增强（GCE）特征融合模块将部分 RGB-D 观测和重构的全局上下文特征进行有效融合；3. 通过实验验证了该方法在具有挑战性的实际数据集上的优越性能。", "conclusion": "GCE-Pose 方法通过集成全局上下文先验和自定义的融合策略，在类别级对象姿态估计任务中取得了显著的性能提升，尤其是在部分可见的情况下表现突出，并且已在 HouseCat6D 和 NOCS-REAL275 数据集上得到了验证。"}
{"llm_update_time": "2025-06-25 09:22:31", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.09529", "html_url": "https://arxiv.org/abs/2505.09529", "title": "使用事件相机的无接触心率监测", "title_en": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "authors": "Mohamed Moustafa,Joseph Lemley,Peter Corcoran", "background": "事件相机是一种新型技术，能够以极低的延迟和低功耗记录场景信息。事件相机输出的是像素级光强度变化的事件流，具有更高的动态范围和时间分辨率，比传统相机更能捕捉信息。利用这一技术，本研究探索了通过面部的时间事件记录来实时无接触地重建个体的心率信号，并采用监督卷积神经网络（CNN）模型进行分析。实验结果验证了事件相机在面部区域有效保留生理心脏信息的潜力，为远程心率监测提供了新可能。", "innovation": "本研究创新性地利用事件相机技术，通过面部的时间事件流来重建心率信号，采用监督卷积神经网络模型进行分析。实验结果显示，基于事件帧训练的模型的均方根误差（RMSE）比基于标准照相机帧训练的基线模型更低，特别是在60 FPS和120 FPS的事件帧下，做出了更好的表现，进一步突出了事件相机在心率监测方面的潜力和优势。", "conclusion": "通过监督卷积神经网络模型对事件相机产生的事件流进行分析，本研究成功实现了面部无接触心率监测。实验结果表明，与标准照相机数据相比，基于事件相机的数据训练的模型在心率监测中表现更优，尤其是在高刷新率下，进一步展示了事件相机在远程心率监测中的潜在应用价值。"}
{"llm_update_time": "2025-06-25 09:22:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20808", "html_url": "https://arxiv.org/abs/2505.20808", "title": "重获所失一切：因果路径实现罕见概念合成", "title_en": "Not All Thats Rare Is Lost: Causal Paths to Rare Concept Synthesis", "authors": "Bo-Kai Ruan,Zi-Xiang Ni,Bo-Lun Huang,Teng-Fang Hsiao,Hong-Han Shuai", "background": "扩散模型在高保真图像生成方面表现出强大的能力，但在合成罕见概念时往往会出现问题，即这类提示在训练分布中出现的频率较低。论文背景介绍了扩散模型在处理罕见概念生成时的局限性.", "innovation": "论文提出了一种名为 RAP 的原则性框架，将罕见概念的生成视为在潜在因果路径上导航：从常见的概念逐步过渡到罕见的目标，遵循模型对生成空间的对齐轨迹。这种框架通过理论证明，罕见提示指导可以近似为语义相关的常见提示。同时，通过基于分数相似性的动态过程来实现提示切换，以适应不同的阶段转换。此外，还将提示切换重新解释为一种去噪机制的第二级效应，促进了语义的平滑过渡和视觉合成的连贯性。通过因果视角，将输入调度与模型内部的生成动力学对齐。实验结果显示，无论使用哪种扩散模型作为基础，RAP 都能有效地增强罕见概念的生成，优于强有力的基线模型，在自动评估和人因研究中均表现出色.", "conclusion": "实验结果表明，RAP 在多个扩散模型架构下均能有效提升罕见概念的生成性能，在自动评估和人因研究中均表现优于现有的基线模型。"}
{"llm_update_time": "2025-06-25 09:22:32", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15961", "html_url": "https://arxiv.org/abs/2505.15961", "title": "使用结构化运动的超分辨率", "title_en": "Super-Resolution with Structured Motion", "authors": "Gabby Litterio,Juan-David Lizarazo-Ferro,Pedro Felzenszwalb,Rashid Zia", "background": "由于理论和实践上的限制，重建方法在提高分辨率方面的应用一直受到局限，通常仅能实现小幅度的分辨率提升。此外，运动模糊通常被视为影响超分辨率的干扰因素。本文探讨了在使用成像限制下的超分辨率极限问题。通常情况下，卷积操作是不可逆的，特别是在使用一个框的情况下。然而，通过利用高精度运动信息、稀疏成像先验以及凸优化方法，研究团队发现可以大幅提高图像分辨率。通过使用伪随机运动，仅使用一张低分辨率图像即可以成功重建高分辨率图像。研究团队提供了模拟数据和实际拍摄数据的实验结果，以证明其方法的有效性。", "innovation": "研究团队提出了一种新的方法，通过使用高精度运动信息、稀疏图像先验和凸优化技术，能够在超分辨率中取得显著的效果，不仅可以克服传统方法中遇到的限制，而且发现运动模糊在某些条件下可以作为有助于提高图像分辨率的因素。特别是通过伪随机运动的使用，能够在不依赖多帧的情况下恢复高分辨率图像。这种方法克服了传统方法的局限，表明了在特定情况下，运动模糊可以被利用来提高图像分辨率", "conclusion": "通过使用高精度运动信息、稀疏图像先验以及凸优化方法，该研究成功地提高了图像分辨率。这突破了传统方法中的局限，并展示了运动模糊可以辅助增强超分辨率的可能性。通过实验数据，研究证明了这种方法的有效性和潜在的实际应用价值。"}
{"llm_update_time": "2025-06-25 09:22:34", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02393", "html_url": "https://arxiv.org/abs/2506.02393", "title": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "title_en": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "authors": "Yongxian Liu,Boyang Li,Ting Liu,Zaiping Lin,Wei An", "background": "红外小目标检测由于其独特特性（例如，尺寸小、亮度低、无固定形状和变化性）是一项具有挑战性的任务。近年来，基于CNN的方法通过引入复杂的特征提取和融合模块取得了显著的效果。然而，为了实现高效且有效的检测，仍需要开发新的方法来提高目标检测的准确性与效率.", "innovation": "提出了一种递归可重用卷积注意网络（RRCA-Net），该网络通过在递归中引入可重用卷积块（RuCB）而不引入额外参数，实现了高阶特征的保真和进一步优化。此外，提出了一种双交互注意聚合模块（DIAAM）以增强细化信息之间的相互作用和融合。为了保证收敛稳定性，设计了由物理和数学约束集成的目标特征启发式损失函数（DpT-k loss）。", "conclusion": "实验结果表明，RRCA-Net 在多个基准数据集（例如 NUAA-SIRST、IRSTD-1k、DenseSIRST）上的性能与当前最先进的方法相当，且参数较少，还作为可以无缝集成的模块来改进几种流行的红外目标检测方法。"}
{"llm_update_time": "2025-06-25 09:22:36", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21780", "html_url": "https://arxiv.org/abs/2505.21780", "title": "通过逆生成建模实现组件化场景理解", "title_en": "Compositional Scene Understanding through Inverse Generative Modeling", "authors": "Yanbo Wang,Justin Dauwels,Yilun Du", "background": "生成模型在生成高保真视觉内容方面已经展示了惊人的能力。本文探讨了如何进一步利用生成模型不仅生成视觉内容，还理解给定自然图像的场景属性。这一工作将场景理解作为一个逆生成建模问题进行建模，通过寻找与给定自然图像最匹配的可视化生成模型的条件参数。同时，为了从与训练数据显著不同的图像中推断场景结构，本文提出将可视化生成模型组件化地构建，从而增强在新测试场景中鲁棒地进行对象和全局场景因素的推断能力。最后，该方法可以直接应用于现有的预训练文本到图像生成模型，实现零样本多对象感知。", "innovation": "本文提出将可视化生成模型组件化地构建，通过寻找与给定自然图像最匹配的可视化生成模型的条件参数，从而利用逆生成建模方法推断场景的理解。这种方法使得在新测试场景中鲁棒地进行对象和全局场景因素的推断成为可能，并且可以直接应用于现有的预训练文本到图像生成模型，实现零样本多对象感知。", "conclusion": "本文提出了一种新的方法，利用逆生成建模来推断场景理解，特别是从与训练数据显著不同的图像中推断物体和全局场景因素。这种方法在多物体感知和新场景的鲁棒推断方面表现出了优势，可以应用于现有的文本到图像生成模型，实现零样本多对象感知，并提供了代码和可视化结果支持。"}
{"llm_update_time": "2025-06-25 09:22:37", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09399", "html_url": "https://arxiv.org/abs/2506.09399", "title": "通过动态协方差校准提高Out-of-Distribution检测", "title_en": "Improving Out-of-Distribution Detection via Dynamic Covariance Calibration", "authors": "Kaiyu Guo,Zijian Wang,Tan Pan,Brian C. Lovell,Mahsa Baktashmotlagh", "background": "Out-of-Distribution (OOD) 检测对于人工智能系统的可靠性至关重要。现有方法利用先验信息（即子空间方法）通过提取信息几何来检测 OOD 数据，但在处理由于样本分布不良而扭曲的几何形状时会失效，因为它们无法动态调整训练分布的信息几何形状。", "innovation": "本文提出了一种新的方法，通过实时输入特征动态更新先验协方差矩阵，从而不断调整几何形状。该方法减少了协方差沿实时输入特征的方向，并约束调整范围在残差空间内，这样可以保持数据的基本特征，同时避免在主空间的非意图方向产生影响。这项工作在CIFAR数据集和ImageNet-1k上的多个预训练模型上进行了评估，实验证明该方法能显著提升各种模型的OOD检测性能。", "conclusion": "本文的方法通过动态调整先验几何形状显著提升了OOD检测性能，尤其是在处理样本分布不良的数据时效果更为显著。"}
{"llm_update_time": "2025-06-25 09:22:37", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05199", "html_url": "https://arxiv.org/abs/2506.05199", "title": "超越检测：增强体感3D定位中的语境理解", "title_en": "Grounding Beyond Detection: Enhancing Contextual Understanding in Embodied 3D Grounding", "authors": "Yani Zhang,Dongming Wu,Hao Shi,Yingfei Liu,Tiancai Wang,Haoqiang Fan,Xingping Dong", "background": "体感3D定位旨在从自我中心视角定位人类指令中描述的目标物体。大多数方法通常遵循两阶段范式，即利用训练好的3D检测模型来初始化一个语义定位模型。本研究探讨了基础问题：体感3D定位是否能充分受益于检测？研究评估了使用目标类别筛选后的预测边界框的检测模型的定位性能，令人惊讶的是，这些未经过特定指令训练的检测模型在某些情况下超过了直接使用语言指令训练的定位模型。这表明即使是类别级别的体感3D定位尚未完全解决，更精细的上下文感知定位更没有得到解决。", "innovation": "本研究提出了DEGround，该框架利用了DETR查询作为对象表示，同时用于检测和定位，使定位能够受益于基本类别分类和边界框检测。在此框架基础上，引入了区域激活定位模块和查询级调制模块，分别突出指令相关区域和整合句子级别语义到查询表示，增强对语言指令的上下文理解。", "conclusion": "DEGround在体感扫描验证集上的总体准确性方面超越了当前最先进的模型BIP3D，提高了7.52%。源代码将在此网址公开：[此处链接]。"}
{"llm_update_time": "2025-06-25 09:22:39", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10082", "html_url": "https://arxiv.org/abs/2506.10082", "title": "LoRA-Edit: 通过掩码感知的LoRA微调实现可控的第一帧引导视频编辑", "title_en": "LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning", "authors": "Chenjian Gao,Lihe Ding,Xin Cai,Zhanpeng Huang,Zibin Wang,Tianfan Xue", "background": "使用扩散模型进行视频编辑已经取得显著成果，能够生成高质量的视频编辑内容。然而，当前的方法往往依赖大规模预训练，限制了对特定编辑的灵活性。虽然基于第一帧的编辑可以控制初始帧，但在后续帧上缺乏灵活性。为了应对这一限制，提出了一种基于掩码的洛拉（Low-Rank Adaptation）调谐方法，以适应预训练的图像到视频（I2V）模型，从而使视频编辑更加灵活。这种方法保留了背景区域，同时使可控制的编辑传播成为可能。实验结果表明，该方法在视频编辑性能上优于最先进的方法。", "innovation": "提出了一种基于掩码的洛拉（Low-Rank Adaptation）调谐方法，用于适应预训练的图像到视频模型，从而实现高效的、适应性强的视频编辑。此外，通过引入附加参考，如不同的视角或代表性场景状态，作为内容展开的视觉参考点，进一步增强了编辑过程的控制能力。", "conclusion": "实验结果表明，所提出的方法在视频编辑性能上优于现有的最先进的方法。该方法通过不改变模型架构的方式，在编辑过程中提供有效的控制，同时保持背景区域的完整。"}
{"llm_update_time": "2025-06-25 09:22:44", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13097", "html_url": "https://arxiv.org/abs/2506.13097", "title": "Pro-AD: 学习全面原型的多类别无监督异常检测", "title_en": "Pro-AD: Learning Comprehensive Prototypes with Prototype-based Constraint for Multi-class Unsupervised Anomaly Detection", "authors": "Ziqing Zhou,Yurui Pan,Lidong Wang,Wenbing Zhu,Mingmin Chi,Dong Wu,Bo Peng", "background": "现有的基于原型的重建方法在无监督异常检测中虽然能够利用少量可学习的原型，但这些原型只能聚合不足的正常信息，导致重建效果不佳。增加原型的数量虽然可以通过注意机制让异常得到较好地重建，但这也提出了一个“Soft Identity Mapping”问题。因此，为了提高异常检测的性能，本文提出了Pro-AD方法，旨在充分利用原型信息。", "innovation": "本文创新地引入了一个扩充的可学习原型集，提供了充分的语义信息容量。此外，Pro-AD使用了一个动态双向解码器，该解码器结合了正常信息聚合和目标特征重建的过程，使得原型能够从不同层次的图像特征中聚合更全面的正常语义信息。为了防止异常通过足够的语义信息得以良好重建，Pro-AD还引入了一种基于原型的约束，应用于解码器的目标特征重建过程中，进一步提升方法的性能。", "conclusion": "在多个具有挑战性的基准测试中，Pro-AD取得了最先进的性能，突显了其在多类别无监督异常检测任务中的优越鲁棒性和实际有效性。"}
{"llm_update_time": "2025-06-25 09:22:46", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.11558", "html_url": "https://arxiv.org/abs/2506.11558", "title": "DaMO: 通过视频LLM实现时间推理的数据高效多模态集成器", "title_en": "DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs", "authors": "Bo-Cheng Chiu,Jen-Jee Chen,Yu-Chee Tseng,Feng-Chi Chen", "background": "近期，大型语言模型（LLMs）已被扩展到视频领域，使得复杂的视频语言理解成为可能。然而，现有的视频LLMs往往在细致的时间推理方面表现出局限性，限制了它们精确地将响应归因于特定视频时刻的能力，特别是在受限监督条件下。", "innovation": "我们引入了DaMO，一种为了准确的时间推理和多模态理解而设计的数据高效视频LLM。核心创新是提出的时间感知Fuseformer，采用分层次的双流架构来逐步捕捉每个模态中的时间动态，并有效融合互补的视觉和音频信息。此外，DaMO结合了一个全局残差，以减少空间冗余同时保留关键语义细节。DaMO通过一种分阶段逐步训练的方式进行训练，逐步赋予模型多模态对齐、语义定位和时间推理的能力。此外，工作还贡献了从现有数据集生成的带有GPT生成的时域锚定QA对的多个数据集，用于需要时序监督的任务。", "conclusion": "全面的实验表明，DaMO在时间定位和视频QA基准上超越了先前的方法，特别是在需要精确时序对齐和推理的任务上表现尤为突出。我们的工作为数据高效视频语言建模提供了有希望的方向。"}
{"llm_update_time": "2025-06-25 09:22:46", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.15201", "html_url": "https://arxiv.org/abs/2506.15201", "title": "Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models", "title_en": "Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models", "authors": "Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang", "background": "随着视觉-语言预训练模型（VLP）对语义理解能力的提升，公开发布的图像越来越难以避免被搜索引擎和其他类似工具利用。为此，本文旨在通过在图像压缩阶段实施防护措施，保护用户的隐私。传统的图像压缩方法虽然能够有效压缩和传递图像数据，但缺乏有效的对抗上述问题的方法，尤其是VLP模型可能对图像进行语义解析的问题。因此，提升图像压缩过程中的隐私保护成为当前的一大需求。", "innovation": "本文提出了一种灵活的编码方法，即Privacy-Shielded Image Compression（PSIC）。PSIC方法能够生成具有多种解码选项的比特流。默认情况下，比特流被解码以保持良好的感知质量，同时防止VLP模型对其进行语义解析。此外，PSIC能够保留原始的图像压缩功能，并提供一个根据可定制输入条件进行图像重建的模块，可以通过生成偏见信息引导解码过程进入不同的重建版本。该方法还设计了一个基于目标VLP模型对训练数据不确定性推断的软标签的不确定意识加密定向（UAEO）优化函数，旨在在统一的训练过程中实现加密性能和感知质量的同步优化。", "conclusion": "本文提出的方案具有即插即用的特点，可以无缝集成到大多数已有的Learned Image Compression（LIC）模型中。通过在多个下游任务上的广泛实验表明，该设计能够有效提高隐私保护性能和视觉质量。"}
{"llm_update_time": "2025-06-25 09:22:48", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13040", "html_url": "https://arxiv.org/abs/2506.13040", "title": "无标记的多人动作捕捉MAMMA", "title_en": "MAMMA: Markerless & Automatic Multi-Person Motion Action Capture", "authors": "Hanz Cuevas-Velasquez,Anastasios Yiannakidis,Soyong Shin,Giorgio Becherini,Markus Höschle,Joachim Tesch,Taylor Obersat,Tsvetelina Alexiadis,Michael J. Black", "background": "传统的动捕系统依赖物理标记，虽然具备高精度，但需要专用硬件、手动放置标记和大量的后处理，这使得它们成本高昂且耗时。虽然近年来出现了基于学习的方法试图克服这些限制，但大多数方法仅适用于单人捕捉、依赖稀疏关键点，或在遮挡和物理互动情况下性能不佳。因此，开发一种能够准确捕捉多人交互序列参数而不依赖标记的动捕系统是必要的。", "innovation": "提出了一种MAMMA体系结构，该架构能够预测基于分割掩模的稠密2D表面地标，并通过可学习的查询来进行个体特定的对应估计，即使在重遮挡的情况下也是如此。该方法能够处理复杂的人员互动，并提供相对于现有方法更高的准确性。为了训练网络，构建了一个包含多样来源的大型合成多视角数据集，包括极端姿态、手部动作和近距离交流。该数据集还包含了SMPL-X的真实标注和稠密2D地标，从而实现无标记的动作捕捉。", "conclusion": "该工作提供了一种能够捕捉人类动作且不依赖标记的竞争性重建质量系统，同时避免了大量的人工后处理。作者还针对密集地标的预测和无标记的动捕引入了两个评估设置，并计划发布数据集、基准、方法、训练代码和预训练模型权重，以便研究使用。"}
{"llm_update_time": "2025-06-25 09:22:50", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.15242", "html_url": "https://arxiv.org/abs/2506.15242", "title": "RA-NeRF：在复杂轨迹下具有准确相机位姿估计的鲁棒神经光线场重建", "title_en": "RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories", "authors": "Qingsong Yan,Qiang Wang,Kaiyong Zhao,Jie Chen,Bo Li,Xiaowen Chu,Fei Deng", "background": "NeRF和3D高斯点云(3DGS)已经成为3D重建和SLAM任务的强大工具。然而，它们的表现高度依赖于准确的相机位姿先验。现有的方法通过引入外部约束来尝试解决这个问题，但在复杂的相机轨迹下未能达到满意的精度。因此，为了解决复杂相机轨迹下鲁棒且准确的相机位姿估计问题，本文提出了一种新的方法RA-NeRF，能够在复杂相机轨迹下预测高精度的相机位姿。RA-NeRF利用增量管道，结合使用NeRF进行光度一致性重建，并结合流驱动的姿态调节来提高初始化和定位过程中的鲁棒性。此外，RA-NeRF还利用隐式姿态滤波器捕捉相机运动的模式并消除姿态估计中的噪声。为了验证方法的有效性，我们在标准评估数据集Tanks&Temple以及包含挑战性相机跟踪的NeRFBuster数据集上进行了广泛的实验。", "innovation": "RA-NeRF是一个能够预测复杂相机轨迹下高精度相机位姿的新方法。它结合了NeRF的光度一致性重建和流驱动的姿态调节，以及隐式姿态滤波器来捕捉相机运动模式，从而在复杂的轨迹下提高鲁棒性和精度。", "conclusion": "通过在Tanks&Temple和NeRFBuster数据集上进行的实验，RA-NeRF在相机位姿估计和视觉质量方面都取得了最优结果，证明了其在复杂轨迹下3D重建中的有效性和鲁棒性。"}
{"llm_update_time": "2025-06-25 09:22:50", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16218", "html_url": "https://arxiv.org/abs/2506.16218", "title": "FOCoOp：提升联邦提示学习中视觉-语言模型的离分布鲁棒性", "title_en": "FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models", "authors": "Xinting Liao,Weiming Liu,Jiaming Qian,Pengyang Zhou,Jiahe Xu,Wenjie Wang,Chaochao Chen,Xiaolin Zheng,Tat-Seng Chua", "background": "联邦提示学习（FPL）是跨分布式客户端协作适应模型的方法，同时保持数据隐私。然而，现有FPL方法在性能和鲁棒性之间存在权衡，尤其是在离分布（OOD）转移中的鲁棒性差，这限制了它们在现实世界场景中的可靠性。不同客户端之间的内在在分布（ID）数据异质性使得在保持权衡方面更具有挑战性。", "innovation": "我们引入了一种名为联邦离分布知情上下文优化（FOCoOp）的框架，该框架使用ID全局提示、本地提示和离分布提示来捕捉客户端之间的异质分布。FOCoOp利用三组提示在类级和分布级上创建分离，并通过两阶段分布性鲁棒优化适应OOD转移。此外，FOCoOp通过半不平衡最优运动生成客户端的区分一致性，即校准全局提示、看似离分布提示和离分布提示。广泛的实验表明，FOCoOp有效地捕捉到分散的异质分布，并增强不同OOD转移的鲁棒性。项目已开源在GitHub上。", "conclusion": "FOCoOp框架有效地捕捉了分散的异质分布，并增强了不同OOD转移的鲁棒性。此外，通过开源项目，研究提高了OpenAI技术的透明性和社区可用性。"}
{"llm_update_time": "2025-06-25 09:22:51", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.14667", "html_url": "https://arxiv.org/abs/2506.14667", "title": "DDS-NAS: 动态数据选择在神经架构搜索中的应用 —— 基于在线困难样本挖掘的图像分类", "title_en": "DDS-NAS: Dynamic Data Selection within Neural Architecture Search via On-line Hard Example Mining applied to Image Classification", "authors": "Matt Poyser,Toby P. Breckon", "background": "神经架构搜索（NAS）面临着可扩展性的挑战。为了解决这一问题，本文通过在课堂学习框架内动态困难样本挖掘来加速NAS训练过程。利用自动编码器在潜在空间中强制执行图像相似嵌入，构建了一种高效的kd树结构，以便在低维嵌入中按照最远邻居差异对图像进行排序。通过课堂学习，动态重新构建NAS优化所需的无偏采样数据集，从而提供更有效的训练策略，提高训练效率，减少所需迭代次数，同时保留性能。", "innovation": "本文提出了一种称为DDS-NAS的框架，通过在线困难样本挖掘动态选择数据集，在课堂学习框架中加速神经架构搜索（NAS）训练。这种方法利用自动编码器在潜在空间中嵌入图像的相似性，构建kd树结构，以快速识别最不相似的图像。通过动态重新构建子采样数据集，该框架能够加速基于梯度的NAS策略高达27倍，且不会损失性能，同时提高了训练效率，减少了迭代次数，从而改善了NAS的优化过程。", "conclusion": "DDS-NAS框架通过课堂学习动态地重新选择NAS优化所需的无偏数据集，能够在不损失性能的前提下加速基于梯度的NAS策略，减少训练时间和迭代次数，同时最大化每个图像样本在训练中的贡献。"}
{"llm_update_time": "2025-06-25 09:22:51", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05349", "html_url": "https://arxiv.org/abs/2506.05349", "title": "VideoMathQA: 通过视频中的多模态理解评估数学推理", "title_en": "VideoMathQA: Benchmarking Mathematical Reasoning via Multimodal Understanding in Videos", "authors": "Hanoona Rasheed,Abdelrahman Shaker,Anqi Tang,Muhammad Maaz,Ming-Hsuan Yang,Salman Khan,Fahad Shahbaz Khan", "background": "传统的数学推理任务主要在静态图像或文本中进行，与这些环境相比，视频中的数学推理提出了全新的挑战。视频中的推理不仅需要分析精细的视觉信息，准确地阅读手写或电子文本，还需要综合听觉线索，这些线索可能以非线性方式分布。成功的关键不仅依赖于感知，还需要在丰富且嘈杂的信息流中，选择性地识别并整合关键的上下文信息。VideoMathQA基准测试旨在评估模型进行此种长时间跨模态推理的能力，其覆盖了10个不同的数学领域，包括时间从10秒到超过1小时的视频内容。该基准测试要求模型解读结构化的视觉内容、理解教学叙述，并在视觉、音频和文本模态之间联合融合概念。基准测试的质量通过920多小时的专家标注来保证。基于此，模型可以针对三种核心推理挑战设计问题：直接解决问题、解决新问题所需的概念迁移、以及涉及多步推理和部分解答的长期解释理解。每个问题都有多步推理注释，以精细地诊断模型的能力。", "innovation": "该基准测试VideoMathQA创新性地引入了一个用于评估模型在视频中进行长期跨模态推理能力的平台，涵盖了从10秒到超过1小时的多样的数学主题。这种基准测试不仅要求对视觉内容进行分析，还需要理解叙述并在视觉、音频和文本模态之间进行联合概念融合。双语者设计问题针对关键的跨模态推理挑战，包括直接问题解答、概念迁移和长期多步推理理解，标签深入至每个推理步骤，为模型评估提供了详细的视角。此外，该基准测试通过提供准确的实验代码为未来研究奠定了基础，发明出一种系统化的评估框架来评估需要推理能力而非单纯感知能力的模型在跨模态、长时间数学问题中的表现。", "conclusion": "通过VideoMathQA基准测试，研究人员能够强调现有方法的局限性，并建立了评估模型推理能力的标准框架，特别是这些模型能够针对扩展的时间和丰富的模态进行推理，而不仅仅是感知。该基准测试和评估代码已公开可供其他研究使用。"}
{"llm_update_time": "2025-06-25 09:22:54", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12280", "html_url": "https://arxiv.org/abs/2505.12280", "title": "时空光谱统一遥感密集预测", "title_en": "Temporal-Spectral-Spatial Unified Remote Sensing Dense Prediction", "authors": "Sijie Zhao,Feng Liu,Enzhuo Zhang,Yiqing Guo,Pengfeng Xiao,Lei Bai,Xueliang Zhang,Hao Chen,Zhenwei Shi,Wanli Ouyang", "background": "多源遥感数据的迅速增长推动了深度学习在密集预测领域的广泛应用，然而在数据和任务统一方面仍面临重大挑战。当前的遥感深度学习架构本质上是僵化的，它们固定了输入和输出配置，限制了对实际数据中固有的空间、时间和光谱维度异质性的适应性。此外，这些模型忽略了语义分割、二元变化检测和语义变化检测之间的内在联系，需要开发不同的模型或专门的解码器。这种范式也被预设的输出语义类别集所限制，任何类别更改都需要昂贵的重新训练过程。", "innovation": "为克服上述限制，文中引入了时空光谱统一网络（STSUN）进行统一建模。STSUN通过利用其元数据来统一表示输入和输出数据，可以适应任意的空间尺寸、时间长度和光谱带宽。STMN在单一架构中统一了不同的密集预测任务，通过条件化模型上的可训练任务嵌入。同样，通过集成可训练类别嵌入作为元数据，它还促进了对任何语义类别集的灵活预测。在多个数据集上的广泛实验展示了单个STSUN模型有效适应异质输入和输出，统一了各种密集预测任务和不同的语义类别预测，其提出的方法在多个场景中取得了最先进的性能，突显了其在复杂遥感应用中的稳健性和泛化能力。", "conclusion": "实验结果表明，单个STSUN模型能够有效适应不同类型的输入和输出，统一各种密集预测任务和不同的语义类别预测。该方法展示了其在复杂遥感应用中的优越性能、鲁棒性和泛化能力。"}
{"llm_update_time": "2025-06-25 09:22:57", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18246", "html_url": "https://arxiv.org/abs/2506.18246", "title": "Referring Expression Instance Retrieval and A Strong End-to-End Baseline", "title_en": "Referring Expression Instance Retrieval and A Strong End-to-End Baseline", "authors": "Xiangzhao Hao,Kuan Zhu,Hongyu Guo,Haiyun Guo,Ning Jiang,Quan Lu,Ming Tang,JinQiao Wang", "background": "自然语言查询图象内容是许多视觉语言任务的基础，通常根据文本粒度和视觉搜索范围进行分类。文本-图像检索（TIR）利用粗略描述检索整个图像，而引用表达理解（REC）使用单个图像内的精细描述来定位对象。然而，实际场景往往需要在大型图库中同时实现实例级别的检索和定位，而TIR缺乏精确性，REC缺乏可扩展性。", "innovation": "研究人员提出了一个新的任务：引用表达实例检索（REIR），该任务共同支持实例级别的检索和定位。他们还介绍了REIRCOCO，这是一个由提示视觉语言模型为MSCOCO和RefCOCO实例生成细粒度表达而构建的大规模基准数据集。此外，他们提出了一种名为CLARE的基线方法，采用了双流架构和Mix of Relation Experts（MORE）模块，用于捕捉实例之间的关系，并结合了对象检测、REC预训练和对比度语言-实例对齐（CLIA）进行端到端优化。", "conclusion": "实验表明，CLARE在REIR上达到了最先进的性能，并且能够很好地泛化到TIR和REC，突显了其有效性和适应性。"}
{"llm_update_time": "2025-06-25 09:22:59", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.17469", "html_url": "https://arxiv.org/abs/2506.17469", "title": "土壤图像数据集及其相应的粒径分布用于光电粒度分析", "title_en": "Dataset of soil images with corresponding particle size distributions for photogranulometry", "authors": "Thomas Plante St-Cyr,François Duhaime,Jean-Sébastien Dubé,Simon Grenier", "background": "传统的颗粒大小分布（PSD）分析会产生显著的停机时间并导致大量的人力和维护成本。利用结合到常规土工实验室工作流程中的光学颗粒大小分析可以缓解这些问题。为此，本研究收集了蒙特利尔魁北克地区的12,714张图像，涵盖了321种不同土样的粒径分布分析数据，为培训用于土工应用的卷积神经网络（CNN）提供了一个坚实的基础。土样被标准化为顶视拍摄，分辨率为45MP，像素大小为39.4微米，并且还包括湿态和干态的图像。使用13x9英寸的白色铝制托盘作为测试平台，并采用薄层铺设样本。对于超过尺寸限制的样品，则采用三角形四分法进行质量减少.", "innovation": "本研究通过收集大量的高质量图像数据集，并结合光电粒度分析方法，提供了一种新颖的解决方案来替代传统的方法。该研究设计了适合土工应用的高分辨率图像数据集，特别适用于训练卷积神经网络，同时简化了图像采集方法，提高了图像质量和分析准确性.", "conclusion": "通过该数据集，提供了训练CNN的坚实基础，为光电粒度分析在土工应用中的应用奠定了基础，同时缓解了传统PSD分析带来的停机时间及人力、维护成本等问题。"}
{"llm_update_time": "2025-06-25 09:22:59", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16297", "html_url": "https://arxiv.org/abs/2506.16297", "title": "SycnMapV2: 具有鲁棒性和适应性的无监督分割", "title_en": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation", "authors": "Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas", "background": "人类视觉在分割视觉线索时无需显式训练，并且在噪声加剧的情况下依然保持高度的鲁棒性。相比之下，现有的人工智能算法在相似条件下难以保持准确性。本文研究了现有无监督分割算法在面对数字篡改、噪声、天气和模糊时的脆弱性问题，指出当前方法的性能在这些条件下会显著下降，特别是在噪声、天气和模糊场景中，性能下降可达20%-40%以上。这种不鲁棒性在多个领域成为一种挑战，尤其是在需要连续适应各种变化情况的应用场景中，人工智能算法缺乏人类视觉的这种持续适应能力。", "innovation": "本文提出了SyncMapV2，这是首个能够在无监督条件下实现鲁棒分割的方法，其性能在数字篡改下的mIoU仅有0.01%的下降，而当前方法则下降了23.8%。SyncMapV2具有广泛的抗风险性，无论是面对噪声（7.3% vs 37.7%）、天气（7.5% vs 33.8%）还是模糊（7.0% vs 29.5%）。其独特之处在于无需经过鲁棒训练、监督或特定损失函数即可实现这一效果，且基于自主组织的动力学方程和随机网络概念构建。不同于传统方法需要每次输入都重新初始化，SyncMapV2能够在线适应输入，就像人类视觉一样具备持续适应性。这种方法不仅提升了鲁棒性还为无监督分割领域带来了全新的在线适应性解决方案，进一步推动了下一代鲁棒和适应性智能的发展.", "conclusion": "SyncMapV2展示了近乎零的性能衰减，这项技术公布了一种新的可行路径，能够在无监督分割中实现鲁棒性和适应性，为未来智能的发展提供了新的研究方向，其持续适应性解决了传统方法的再初始化问题，进而推动了鲁棒和适应性智能的发展。"}
{"llm_update_time": "2025-06-25 09:23:00", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16058", "html_url": "https://arxiv.org/abs/2506.16058", "title": "走出相似语义空间进行开域词汇分割", "title_en": "Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation", "authors": "Yong Liu,SongLi Wu,Sule Bai,Jiahao Wang,Yitong Wang,Yansong Tang", "background": "开域词汇分割旨在利用无限文本输入作为指导实现任意类别分割。近年来，研究工作聚焦于开发各种技术路线以利用大规模预训练的多模态模型的潜力，并在现有基准上取得了显著进步。然而，现有测试集在衡量模型对开域词汇概念的理解能力方面存在局限性，因为它们的语义空间与训练空间高度相似，尽管有许多重叠类别。因此，需要一个新的基准测试来更好地评估模型在理解与分割多种真实世界概念方面的能力。", "innovation": "1. 提出了一个新的基准测试OpenBench，测试集的设计更加偏离训练语义空间。2. 引入了一种名为OVSNet的方法来改进不同和开域场景的分割性能。OVSNet借助异构特征的复杂融合和训练空间的无成本扩展，取得现有数据集和提出OpenBench上的最佳结果。", "conclusion": "提出的新基准OpenBench及OVSNet方法证明了该基准测试和方法的有效性和稳健性。"}
{"llm_update_time": "2025-06-25 09:23:02", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18557", "html_url": "https://arxiv.org/abs/2506.18557", "title": "通过音频-视觉场景理解的物体感知声源定位", "title_en": "Object-aware Sound Source Localization via Audio-Visual Scene Understanding", "authors": "Sung Jin Um,Dongjin Kim,Sangmin Lee,Jung Uk Kim", "background": "音频-视觉声源定位任务旨在通过整合音频和视觉线索，在视觉场景中定位发声对象。现有方法在复杂场景中准确定位发声对象方面存在挑战，特别是在静止的背景物体与发声的前景对象视觉相似时。这一限制主要是由于它们依赖于简单的音频-视觉对应关系，未能捕捉到发声与静止物体之间的细微语义差异。", "innovation": "本文提出了一个新的包含多模态大型语言模型（MLLMs）的声源定位框架，该框架利用MLLMs生成详细的上下文信息，明确区分发声的前景对象和静止的背景对象。为有效整合这些详细信息，提出了两种新的损失函数：物体感知对比对齐（OCA）损失和物体区域隔离（ORI）损失。在MUSIC和VGGSound数据集上的实验结果表明，该方法的有效性，显著优于现有方法，尤其是在单一来源和多来源定位场景中。", "conclusion": "本研究提出的基于多模态大型语言模型的声源定位框架在复杂场景中实现了更为准确的声音定位，通过引入新的损失函数进一步提升了模型的性能。这些结果在MUSIC和VGGSound数据集的实验中得到了验证，验证了该方法的有效性和优越性。"}
{"llm_update_time": "2025-06-25 09:23:07", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18807", "html_url": "https://arxiv.org/abs/2506.18807", "title": "PicoSAM2: 适用于边缘视觉应用的低延迟传感器内分割", "title_en": "PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications", "authors": "Pietro Bonazzi,Nicola Farronato,Stefan Zihlmann,Haotong Qin,Michele Magno", "background": "实时、在设备端的分割对于像智能眼镜和物联网设备这样的延迟敏感且隐私意识强的应用至关重要。", "innovation": "提出了PicoSAM2，这是一种轻量级（1.3M参数，336M MACs）且可提示的分割模型，针对边缘和感器内执行进行了优化，包括索尼IMX500。该模型基于深度可分离U-Net，通过知识蒸馏和固定点提示编码从分割任何东西模型2（SAM2）中学习。在COCO和LVIS数据集上分别实现了51.9%和44.9%的mIoU。通过蒸馏在IMX500上实现了86 MACs/周期，14.3 ms的运行速度，使其成为唯一同时满足内存和计算约束的用于在传感器部署的模型。蒸馏提高了LVIS的性能，分别在mIoU和mAP上提高了3.5%和5.1%。这些结果表明，高效的、可提示的分割可以直接在设备上实现，从而实现隐私保护的视觉应用，而无需云或宿主处理。", "conclusion": "PicoSAM2展示了在设备上实现低延迟、高效且可提示的分割模型是可行的，可以直接在摄像头内实现隐私保护的视觉应用，而不需要云或主机处理。"}
{"llm_update_time": "2025-06-25 09:23:10", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.02978", "html_url": "https://arxiv.org/abs/2408.02978", "title": "ASR增强的跨域多媒体表示学习以用于产品检索", "title_en": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval", "authors": "Ruixiang Zhao,Jian Jia,Yan Li,Xuehan Bai,Quan Chen,Han Li,Peng Jiang,Xirong Li", "background": "电子商务正在日益多媒体化，产品以图像、短视频或直播促销等多种形式展示。在这种广泛领域的情境下，单一的视觉表示已经不足以捕捉产品间丰富的差异性和较高的相似性。虽然自动语音识别(ASR)从短视频或直播中提取的文字信息易于获取，如何对这些极度噪音的文本进行去噪以便进行多模态表示学习仍然很少被探讨。", "innovation": "本文提出了一种名为AMPere的方法，通过结合LLM（大型语言模型）进行ASR文本摘要以提取产品特定信息，将LLM摘要文本与视觉数据一起输入多分支网络生成紧凑的多模态嵌入。这种方法有效地产生了一种统一的多模态产品表示，显著提升了跨域产品检索的效果。", "conclusion": "通过大量的实验验证，AMPere方法在大规模三域数据集上取得了显著的效果，有效提升了跨域产品检索的精度。"}
{"llm_update_time": "2025-06-25 09:23:11", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.07494", "html_url": "https://arxiv.org/abs/2403.07494", "title": "SemGauss-SLAM: 密集语义高斯蹦点SLAM", "title_en": "SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM", "authors": "Siting Zhu,Renjie Qin,Guangming Wang,Jiuming Liu,Hesheng Wang", "background": "现有的单目和多视图视觉SLAM（Simultaneous Localization and Mapping）方法在建图和跟踪精度方面存在局限性，同时难以提供高质量的语义信息。SemGauss-SLAM旨在解决这些问题，通过引入3D高斯表示和语义特征嵌入方法，旨在实现高精度的三维语义地图构建，稳健的相机跟踪以及高质量的渲染效果。", "innovation": "该系统在3D高斯表示中嵌入了语义特征嵌入，使得能够在环境的空间布局中有效编码语义信息，为精确的语义场景表示提供了更高层次的指导。此外，SemGauss-SLAM提出了特征级别损失来更新3D高斯表示，并引入了语义指导的束调整方法，利用多帧语义关联进行三维高斯表示和相机姿态的联合优化，从而实现低漂移跟踪和精确的语义建图。", "conclusion": "实验结果表明，SemGauss-SLAM在Replica和ScanNet数据集上在建图和跟踪精度方面优于基于辐射场的SLAM方法，同时展示了在高精度语义分割和密集语义映射方面的出色能力。"}
{"llm_update_time": "2025-06-25 09:23:13", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2308.16075", "html_url": "https://arxiv.org/abs/2308.16075", "title": "视觉上下文对嘈杂多模态神经机器翻译的影响：对英语到印度语言的实验研究", "title_en": "Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages", "authors": "Baban Gain,Dibyanayan Bandyopadhyay,Samrat Mukherjee,Chandranath Adak,Asif Ekbal", "background": "神经机器翻译（NMT）在大规模文本数据的利用上取得了显著进展，但在高资源环境中融入多模态输入，特别是视觉信息，尚未得到充分探索。尽管此前研究主要集中在低资源场景下的多模态数据使用，本研究探讨了向大规模预训练单模态NMT系统添加图像特征如何影响翻译。研究发现，图像可能在这种情况下是多余的。此外，研究引入了合成噪声，以评估图像是否有助于模型处理文本噪声。即使使用随机图像，多模态模型在嘈杂环境中也略微优于仅文本模型。实验结果显示翻译效果显著优于最先进基准，特别是对于英语到印地语、孟加拉语和马拉雅拉姆语的翻译。视觉上下文的效果随源文本噪声水平变化：无视觉上下文适用于无噪声翻译，裁剪后的图像特征适用于低噪声，全图像特征则在高噪声环境中表现更佳，这揭示了视觉上下文的作用，特别是在嘈杂设置中的角色，为嘈杂多模态神经机器翻译开辟了新的研究方向。研究强调了结合视觉和文本信息在不同环境中提高翻译效果的重要性。我们已公开代码，网址为：这个 https URL", "innovation": "引入合成噪声来评估图像对模型处理文本噪声的影响；发现视觉上下文在不同噪声水平下的效果各异，无视觉上下文、裁剪后的图像特征和全图像特征在不同噪声环境中有各自的最佳表现，提出了一种新的研究方向，即嘈杂多模态神经机器翻译，强调结合视觉和文本信息的重要性", "conclusion": "研究结果表明，在无噪声和低噪声环境中无视觉上下文表现最佳，在高噪声环境中全图像特征更好。视觉上下文在不同噪声水平下的表现各异，强调了结合视觉和文本信息在提高翻译效果方面的重要性，开拓了嘈杂多模态神经机器翻译的新研究方向。"}
{"llm_update_time": "2025-06-25 09:23:14", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.01600", "html_url": "https://arxiv.org/abs/2405.01600", "title": "使用块融合特征融合的集成池化改进且可解释的宫颈癌分类", "title_en": "Improved and Explainable Cervical Cancer Classification using Ensemble Pooling of Block Fused Descriptors", "authors": "Saurabh Saini,Kapil Ahuja,Akshat S. Chauhan", "background": "宫颈癌是女性最常见的癌症之一，且导致高死亡率。早期检测模型的效果有限，而预训练的ResNet在提取宫颈癌图像特征方面表现良好。但是，现有研究仅使用ResNet的最后一层卷积块来提取抽象特征，忽略了对早期卷积块中详细特征（如颜色、边缘、纹理）的利用。尽管这些特征对于癌症分类同样重要，尤其是对于宫颈癌。现有的方法在宫颈癌分类中的性能有限，通常在90%左右。因此，需要提出一种新的方法，以提高宫颈癌分类的性能并提供可解释的结果。", "innovation": "本文提出了一种新的模型，首先使用ResNet（50、101、152）的早期卷积块提取详细特征，并结合全局最大池化和平均池化进行特征选择；其次通过融合标准ResNet和提出的三种块融合ResNet进行特征组合和规范化，以进一步提高性能；此外，引入了一种新的SHAP+LIME可解释方法，准确识别癌变区域。这种方法在两种公开数据集上的性能优于现有方法，展现了显著的改进并提供了解释性。", "conclusion": "我们在两种公开数据集上进行了详尽的实验，第三和第四模型分别达到了97.92%和92.97%的性能，优于标准ResNet模型90.89%和87.97%的性能。在IARC数据集上，我们比现有的竞争方法平均提高了13.20%的性能，在AnnoCerv数据集上没有可比的先前工作。此外，我们还提出了一种新的SHAP+LIME可解释性方法，准确识别了97%的癌变区域。"}
{"llm_update_time": "2025-06-25 09:23:14", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.00239", "html_url": "https://arxiv.org/abs/2405.00239", "title": "IgCONDA-PET：使用隐式引导注意力条件反事实扩散建模的弱监督PET异常检测——一项多中心、多癌种和多示踪剂研究", "title_en": "IgCONDA-PET: Weakly-Supervised PET Anomaly Detection using Implicitly-Guided Attention-Conditional Counterfactual Diffusion Modeling -- a Multi-Center, Multi-Cancer, and Multi-Tracer Study", "authors": "Shadab Ahamed,Arman Rahmim", "background": "在训练正电子发射断层扫描（PET）病变检测和分割网络时，减少对像素级别的标注数据的需求是极为必要的，这对于时间和成本约束下的专家标注尤为关键。当前的无监督或半监督异常检测方法依赖于仅基于健康数据训练的自动编码器或生成对抗网络（GANs）。尽管这些方法能够减少对标注数据的依赖，但基于GAN的方法由于同时优化两个竞争的网络、模式崩溃及训练不稳定等问题，相较于非GAN方法更具挑战性。因此，本文介绍了基于反事实扩散建模的隐式引导注意力条件异常检测模型（IgCONDA-PET），以克服上述挑战。", "innovation": "该研究提出了一种基于反事实扩散建模的隐式引导注意力条件异常检测模型（IgCONDA-PET），该模型利用PET扫描数据进行了多中心、多癌种及多示踪剂的实验验证。通过图像类别标签（健康与不健康）和注意模块进行条件培训，该方法利用反事实生成技术来开展“不健康到健康”的领域迁移，从而生成不健康的合成健康版本图像。这种方法能够识别异常，且性能与几种基于深学习的半监督或无监督方法以及传统方法（如41% SUV最大化阈值）进行了对比。该研究强调，为了检测小异常，网络中需要包含注意模块。研究结果表明，IgCONDA-PET能有效检测PET图像中的异常，且具有较高的准确性。", "conclusion": "研究验证了基于反事实扩散建模的隐式引导注意力条件异常检测模型（IgCONDA-PET）的可行性及有效性，通过利用健康数据生成不健康的合成健康版本，增强对异常的检测能力。该模型相比传统方法和基于GAN的方法，显示出更高的标注效率和更好的性能，为PET图像异常检测提供了一种新的解决方案，并强调了注意模块在模型中的重要性。"}
{"llm_update_time": "2025-06-25 09:23:15", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.02643", "html_url": "https://arxiv.org/abs/2410.02643", "title": "为何样本空间重要：基于LiDAR的位置识别关键帧采样优化", "title_en": "Why Sample Space Matters: Keyframe Sampling Optimization for LiDAR-based Place Recognition", "authors": "Nikolaos Stathoulopoulos,Vidya Sumathy,Christoforos Kanellakis,George Nikolakopoulos", "background": "近期的机器人进步促使自动化在长期和大规模任务中得以应用，而环视闭合通过位置识别对于减少姿态估计漂移至关重要。然而，资源受限的移动机器人和多机器人系统由于高密度采样的计算负担，难以实现实时性能。传统方法要么保留冗余信息，要么错过关键数据，因为它们依赖固定的时间采样间隔或在三维空间操作而非特征描述符空间中。", "innovation": "该研究引入了样本空间的概念，并提出了一种基于LiDAR的位置识别的关键帧采样方法。该方法在高维描述符空间中最小化冗余同时保持必要的信息，支持基于学习和手工构造的描述符。提出的方法采用滑动窗口优化策略，确保关键帧选择的效率和实时性能，能够无缝集成到机器人流水线中。", "conclusion": "该方法在多种数据集上表现出稳健的性能，能够在不调整参数的情况下无缝过渡到室内外场景，减少了循环闭合的检测时间和内存需求。"}
{"llm_update_time": "2025-06-25 09:23:16", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18204", "html_url": "https://arxiv.org/abs/2506.18204", "title": "使用傅里叶注意力的多模态融合SLAM", "title_en": "Multimodal Fusion SLAM with Fourier Attention", "authors": "Youjie Zhou,Guofeng Mei,Yiming Wang,Yi Wan,Fabio Poiesi", "background": "在噪声环境、动态光照和黑暗条件下，视觉SLAM特别具有挑战性。基于学习的光流向量场算法能够利用多种模态来应对这些挑战，但传统的光学光流向量场SLAM方法常常受到高计算复杂度的限制。因此，本文旨在通过提出一种利用快速傅里叶变换增强算法效率的高效多模态融合SLAM方法（FMF-SLAM）来克服这一局限性。", "innovation": "本文创新性地提出了一种名为FMF-SLAM的高效多模态融合SLAM方法。该方法利用快速傅里叶变换提升算法效率，并引入了一种新的基于傅里叶的自注意力和交叉注意力机制来从RGB和深度信号中提取特征，进一步通过跨模态的多尺度知识蒸馏增强了多模态特征的交互。通过将该方法与一台安全机器人结合，并集成全球定位模块GNSS-RTK和全局时空优化方法进行实验，展示了其在真实场景中的实用性和实时性能，验证了在噪声、动态光照和黑暗环境下的优越表现。相关代码和数据已在指定网址提供。", "conclusion": "FMF-SLAM方法在为噪声、动态光照和黑暗条件下的视觉SLAM问题上提供了高效和实用的解决方案，验证了在TUM、TartanAir和实际数据集中的卓越性能，并展示了在实际应用中的可行性。相关代码和数据可在指定网址获取。"}
{"llm_update_time": "2025-06-25 09:23:17", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.16776", "html_url": "https://arxiv.org/abs/2403.16776", "title": "Diff-Def: 使用扩散生成变形场的条件性解剖图谱", "title_en": "Diff-Def: Diffusion-Generated Deformation Fields for Conditional Atlases", "authors": "Sophie Starck,Vasiliki Sideri-Lampretsa,Bernhard Kainz,Martin J. Menten,Tamara T. Mueller,Daniel Rueckert", "background": "解剖图谱在群体研究和分析中被广泛使用。条件解剖图谱针对通过特定条件定义的特定子群体，如人口统计学特征或病理状况，允许探究精细的解剖学差异，例如年龄相关或疾病相关的形态变化。现有的方法使用基于配准的方法，往往难以处理大的解剖学差异，或是采用生成对抗模型，训练过程中容易遭遇不稳定性。现有的方法要么直接在强度上生成图谱，要么使用可能导致直接图像合成中出现幻觉的扩散生成模型。本文提出使用扩散扩散模型生成变形场，将通用人群图谱转化为特定亚群的图谱，从而确保结构完整性，提高可解释性，并避免直接图像合成过程中可能产生的幻觉。", "innovation": "本文提出使用扩散扩散模型生成变形场的方法，这种方法可以将通用人群图谱转化为特定亚群的图谱，确保结构完整性，提高可解释性，并避免直接图像合成过程中可能产生的幻觉。与现有的方法相比，该方法能够生成高质量的、具有高度解剖保真的、平滑转换的解剖图谱，超越了现有的基线方法。文章还通过全面的评估证明了这些图谱的质量，涉及解剖准确性、感知相似性以及生成图谱的一致性和逼真度的定性分析。", "conclusion": "本文提出的方法相较于现有的解剖图谱生成方法，能够生成高质量、接近真实的解剖图谱，实现了变形场的有效生成，提升了结果的可解释性，解决了直接生成图谱可能遇到的一些问题。"}
{"llm_update_time": "2025-06-25 09:23:18", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18882", "html_url": "https://arxiv.org/abs/2506.18882", "title": "Normal之光：统一特征表示的通用光度立体视觉", "title_en": "Light of Normals: Unified Feature Representation for Universal Photometric Stereo", "authors": "Hong Li,Houyuan Chen,Chongjie Ye,Zhaoxi Chen,Bohan Li,Shaocong Xu,Xianda Guo,Xuhui Liu,Yikai Wang,Baochang Zhang,Satoshi Ikehata,Boxin Shi,Anyi Rao,Hao Zhao", "background": "通用光度立体视觉的目标是从在任意照明条件下物体获得高质量的表面法线，而不依赖于特定的光照模型。尽管SDM-UniPS和Uni MS-PS等最近的进步解决了这个问题，但依然存在两个基本挑战：1）光照和表面法线特征之间的深度耦合，观察到的强度变化可能来自于光照变化或表面朝向变化的不确定性；2）复杂表面的高频几何细节保真，复杂几何结构导致的自阴影、互反射和微妙的法线变化，这些特性常规的特征处理操作难以精确捕捉准确。", "innovation": "提出了统一特征表示方法来解决通用光度立体视觉中的挑战。这种方法可以更好地处理光照变化和表面法线特征之间的耦合问题，同时能够更好地保留复杂表面的高频几何细节。通过这种创新方法，能够准确地捕捉到复杂几何结构带来的微妙变化，从而提高表面法线恢复的质量和准确性。", "conclusion": "通过统一特征表示方法，提高了在复杂光照条件下表面法线的恢复质量，解决了当前光度立体视觉中的两个主要挑战。这种方法为进一步改进光度立体视觉提供了新的思路和方法。"}
{"llm_update_time": "2025-06-25 09:23:18", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.07501", "html_url": "https://arxiv.org/abs/2411.07501", "title": "LAuReL: 学习增强残差层", "title_en": "LAuReL: Learned Augmented Residual Layer", "authors": "Gaurav Menghani,Ravi Kumar,Sanjiv Kumar", "background": "深度学习方法的核心支柱之一是架构改进，比如残差/跳跃连接，这种改进促进了模型更好的收敛和质量。残差连接已在卷积神经网络中广泛使用，现在也正逐渐被应用到以变压器为基础的大型语言模型（LLM）架构中。", "innovation": "提出了一种称为Learned Augmented Residual Layer (LAuReL)的新颖残差连接的扩展方法，旨在成为残差连接的即用型替代方案，同时在模型质量和尺寸上都优于前者。实验表明在视觉和语言模型中的性能都有显著提升。例如，在ResNet-50-ImageNet 1K任务中，LAuReL达到了添加额外一层60%的性能提升，仅增加了0.003%的参数量，而额外添加2.6倍少的参数。在预训练1B和4B参数的大型语言模型时，LAuReL在一系列挑战性下游评估任务上提高了2.54%至20.05%的性能，同时仅增加0.012%和1%的额外参数量。", "conclusion": "LAuReL作为一种创新的残差连接改进方法，能够在不显着增加模型尺寸的情况下显著提高模型性能，特别是在视觉和自然语言处理任务中具有明显优势。"}
{"llm_update_time": "2025-06-25 09:23:22", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.18185", "html_url": "https://arxiv.org/abs/2502.18185", "title": "VesselSAM：利用SAM进行基于AtrousLoRA的主动脉血管分割", "title_en": "VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with AtrousLoRA", "authors": "Adnan Iltaf,Rayan Merghani Ahmed,Zhenxi Zhang,Bin Li,Shoujun Zhou", "background": "医学影像分割对于临床诊断和治疗规划至关重要，尤其是在处理复杂的解剖结构，例如血管时。然而，准确分割血管仍然具有挑战性，因为它们的尺寸较小，边缘结构复杂，且容易受到伪影和成像噪声的影响。", "innovation": "本文提出了一种针对主动脉血管分割改进的版本——VesselSAM，并结合了AtrousLoRA模块，该模块集成了Atrous Attention和Low-Rank Adaptation（LoRA）。Atrous Attention使得模型能够捕获多尺度上下文信息，保留局部细节和全局背景。LoRA使冻结的SAM图像编码器能够进行高效微调，减少了可训练参数的数量，提高了计算效率。", "conclusion": "VesselSAM在两个具有挑战性的数据集——Aortic Vessel Tree（AVT）数据集和Type-B Aortic Dissection（TBAD）数据集上进行了评估，取得了最先进的分割性能，DSC分数分别为93.50%，93.25%，93.02%，以及93.26%。与现有大型模型相比，VesselSAM在提高分割准确性的同时，显著降低了计算开销。这一研究为临床环境下的增强AI主动脉血管分割铺平了道路。"}
{"llm_update_time": "2025-06-25 09:23:25", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.17364", "html_url": "https://arxiv.org/abs/2506.17364", "title": "基于AI的多模态生物特征检测智能手机分心行为：在在线学习中的应用", "title_en": "AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning", "authors": "Alvaro Becerra,Roberto Daza,Ruth Cobos,Aythami Morales,Mutlu Cukurova,Julian Fierrez", "background": "本文探讨了使用多模态生物特征来检测任务中由智能手机使用引起的分心，重点关注计算机辅助在线学习领域。传统的学习平台通常缺乏详细的用户行为数据，但多模态学习分析和生物传感器为了解学习者注意力提供了新的见解。本文集中讨论了学习者在面对内部因素（如动机）、系统相关因素（如课程设计）和情境因素（如智能手机使用）时所面临的挑战。", "innovation": "本文提出了一种基于AI的方法，利用生理信号和头部姿态数据来检测手机使用情况。研究结果表明，单一生物特征信号（如脑电波或心率）的准确度有限，而单独使用头部姿态的准确度为87%。整合所有信号的多模态模型准确率达到91%，突显了集成的优势。", "conclusion": "本文讨论了这些模型部署在在线学习环境中的潜在影响和局限性。"}
{"llm_update_time": "2025-06-25 09:23:25", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19447", "html_url": "https://arxiv.org/abs/2505.19447", "title": "基于完美对齐样本对的用于遥感图像的对比学习基础模型", "title_en": "A Contrastive Learning Foundation Model Based on Perfectly Aligned Sample Pairs for Remote Sensing Images", "authors": "Hengtong Shen,Haiyan Gu,Haitao Li,Yi Yang,Agen Qiu", "background": "自监督学习(SSL)允许我们无需昂贵的标注数据即可预训练基础模型。对比学习(CL)方法在噪声干扰中能更好地获取准确的语义表示。尽管CL方法在多种计算机视觉任务中取得了巨大成功，但它们在遥感(RS)图像上的特定适应仍是一个挑战，因为存在显著的领域差距。为了克服这一挑战，本文提出了一种新的自监督方法——PerA，该方法通过使用语义完美对齐样本对来生成适用于所有目的的RS特征。", "innovation": "该方法通过应用空间上不交的遮罩而非随机裁剪来从采样视图中获取特征。框架通过确保教师和学生之间的一致性以及预测可学习的遮罩标记来提供高质量的特征，并且具有更高的内存效率，因此可以使用更大的批次进行训练。此外，该方法显示出对未校正的RS数据的显著适应性，并能减少潜在语义不一致性的影响。研究所收集的无标注预训练数据集包含约500万RS图像，实验结果表明，即使在较小模型规模的情况下，该方法也能够与之前最先进的方法相比取得相当的效果，展示了其有效性。", "conclusion": "实验结果表明，该方法在多个下游任务数据集上的表现与之前最先进的方法相当，尽管模型规模较小，展示了其有效性。期望该工作能为实际的遥感解释工作做出贡献。"}
{"llm_update_time": "2025-06-25 09:23:27", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18916", "html_url": "https://arxiv.org/abs/2506.18916", "title": "HI-SQL：通过动态提示整合优化Text-to-SQL系统", "title_en": "HI-SQL: Optimizing Text-to-SQL Systems through Dynamic Hint Integration", "authors": "Ganesh Parab,Zishan Ahmad,Dagnachew Birru", "background": "Text-to-SQL生成将自然语言与数据库连接起来，使用户能够无需SQL专业知识就能查询数据。虽然大型语言模型（LLMs）在该领域取得了显著进展，但在处理涉及多表连接、嵌套条件和复杂操作的查询方面仍存在挑战。现有方法往往依赖多步骤管道，这导致高计算成本、增加延迟，并且容易传播错误。", "innovation": "我们提出了HI-SQL管道，引入了一种新颖的提示生成机制，利用历史查询日志来引导SQL生成。通过分析先前查询，该方法生成专注于处理多表和嵌套操作复杂性的上下文提示。这些提示无缝地集成到了SQL生成过程中，消除了昂贵的多步骤方法，并减少了对人工构造提示的依赖。", "conclusion": "我们在多个基准数据集上的实验评估表明，我们的方法显著提高了LLM生成查询的准确性，同时在LLM调用和延迟方面保证了效率，提供了增强Text-to-SQL系统的稳健且实际的解决方案。"}
{"llm_update_time": "2025-06-25 09:23:28", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18931", "html_url": "https://arxiv.org/abs/2506.18931", "title": "Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs", "title_en": "Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs", "authors": "Shuang Ao,Yi Dong,Jinwei Hu,Sarvapali Ramchurn", "background": "大规模语言模型（LLMs）通过低秩适应（LoRA）微调可以在提高适应性的同时减少计算成本。但微调可能损害安全性对齐，即使是使用良性数据。现有的安全性对齐方法难以捕捉复杂的参数变化，导致安全性和实用性之间的次优权衡。", "innovation": "我们提出了一种名为Safe Pruning LoRA (SPLoRA)的新颖剪枝方法，通过选择性地移除降低安全性对齐的LoRA层来提高安全性同时保持性能。核心是引入了Empirical-DIEM (E-DIEM)度量，这是一种鲁棒的距离引导剪枝方法，有效地检测LoRA适应模型中的安全性错位。实验结果显示，SPLoRA在实用性、安全性和可靠性方面均优于现有的最佳安全性对齐技术，并且降低了推理负担，使SPLoRA成为部署更安全和可靠的LLMs的可扩展和高效解决方案。", "conclusion": "SPLoRA显著减少安全性风险，同时保持或提高了模型的性能和可靠性，并且减少了推理开销，证明了其作为部署更安全和可靠的大规模语言模型的高效方法的有效性。"}
{"llm_update_time": "2025-06-25 09:23:28", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18927", "html_url": "https://arxiv.org/abs/2506.18927", "title": "从Tiny机器学习到Tiny深度学习：综述", "title_en": "From Tiny Machine Learning to Tiny Deep Learning: A Survey", "authors": "Shriyank Somvanshi,Md Monzurul Islam,Gaurab Chhetri,Rohit Chakraborty,Mahmuda Sultana Mimi,Swagat Ahmed Shuvo,Kazi Sifatul Islam,Syed Aaqib Javed,Sharif Ahmed Rafat,Anandi Dutta,Subasish Das", "background": "边缘设备的迅速增长推动了人工智能（AI）在边缘部署的需求，促成了Tiny机器学习（TinyML）及其演变的Tiny深度学习（TinyDL）。TinyML最初侧重于在微控制器上实现简单的推理任务，而TinyDL则标志着向资源极度受限硬件上部署深度学习模型的范式转变。", "innovation": "本文综述了TinyML到TinyDL的过渡过程，涵盖了架构创新、硬件平台、模型优化技术和软件工具链，分析了先进的量化、剪枝和神经架构搜索方法，并探讨了从微控制器到专用神经加速器的硬件趋势。此外，还分类了软件部署框架、编译器和AutoML工具，以实现设备上的实际学习。文中还回顾了包括计算机视觉、音频识别、医疗保健和工业监控在内的跨领域应用，以展示TinyDL的现实影响。", "conclusion": "文章指出未来可能的研究方向包括神经形态计算、联邦TinyDL、边缘本地基础模型和领域专用协同设计方法。本文旨在为研究人员和实践者提供一个基础资源，提供该生态系统的综合视角，为未来边缘AI的进一步发展奠定基础。"}
{"llm_update_time": "2025-06-25 09:23:29", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18069", "html_url": "https://arxiv.org/abs/2506.18069", "title": "展开过去：分析活版印刷书籍页面的全面深度学习方法", "title_en": "Unfolding the Past: A Comprehensive Deep Learning Approach to Analyzing Incunabula Pages", "authors": "Klaudia Ropel,Krzysztof Kutt,Luiz do Valle Miranda,Grzegorz J. Nalepa", "background": "本文介绍了一种用于自动分析活版印刷书籍页面结构和内容的方法。研究者创建了一个包含500页注释数据的自定义数据集，其中涉及不同的活版印刷书籍，每页被手工标记为五类：文本、标题、图片、表格和手写。利用现成的DocLayNet数据集作为补充训练数据，使用YOLO11n和YOLO11s模型进行对象检测，并探索了混合数据集和单独使用自定义数据集的策略。光学字符识别（OCR）技术也被应用于检测到的文本区域，并且进行了图像分类以识别图片。这些结果证实，机器学习方法在分析早期印刷书籍方面具有巨大潜力，但也表明进一步提高OCR性能和视觉内容解释的重要性。", "innovation": "本文提出了一种自动分析活版印刷书籍页面结构和内容的深度学习方法，包括：1) 利用了自定义数据集和现成的DocLayNet数据集；2) 使用两种不同的YOLO模型进行对象检测，并比较了它们的性能；3) 对识别出的文本区域应用了多种OCR方法，且选择了表现最好的方法进行后续处理；4) 应用了图像分类和CLIP模型生成半结构化的语义描述。这些技术创新为活版印刷书籍的自动分析提供了新的解决方案.", "conclusion": "本文研究了活版印刷书籍页面的自动分析方法，通过使用深度学习技术，特别是YOLO模型、OCR技术以及图像分类方法，成功地对文本、图片等进行了识别和分类。尽管取得了初步成果，但仍需进一步提高OCR技术和图像内容理解能力，以更全面地解析早期印刷书籍的内容。"}
{"llm_update_time": "2025-06-25 09:23:31", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18810", "html_url": "https://arxiv.org/abs/2506.18810", "title": "ConciseHint: 提升生成过程中的高效推理通过持续的简洁提示", "title_en": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation", "authors": "Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang", "background": "大型推理模型（LRMs）例如DeepSeek-R1和OpenAI系列O1系列，通过增加生成长度来提高复杂推理任务的表现。然而，这些模型倾向于产生冗长的推理过程，导致效率问题。目前的效率提升方法主要集中在提高推理前的性能或在推理过程中进行调优，但忽视了通过在生成过程中直接引导模型简洁表达来提高效率的可能性。", "innovation": "提出了一种名为ConciseHint的框架，通过在推理过程中的标记生成注入手动设计或根据简洁数据训练的文本提示，连续地鼓励模型简洁表达。ConciseHint还能够根据查询的复杂度自动调整提示强度，以确保不损害模型性能。实验证实，该方法能够在几乎所有情况下减少推理长度长达65%，同时保持良好的性能表现，如在GSM8K基准测试上实现了显著的长度减少，几乎没有准确率损失。", "conclusion": "ConciseHint框架成功地生成了简洁的推理过程，同时保持了性能，为解决大型推理模型在推理过程中产生的冗余问题提供了一种有效的方法。这种框架能够根据查询的复杂性自动调整提示的强度，从而不会损害模型的性能。"}
{"llm_update_time": "2025-06-25 09:23:33", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18945", "html_url": "https://arxiv.org/abs/2506.18945", "title": "Chain-of-Experts: 解锁混合专家模型的通信能力", "title_en": "Chain-of-Experts: Unlocking the Communication Power of Mixture-of-Experts Models", "authors": "Zihan Wang,Rui Pan,Jiarui Yao,Robert Csordas,Linjie Li,Lu Yin,Jiajun Wu,Tong Zhang,Manling Li,Shiwei Liu", "background": "传统的Mixture-of-Experts（MoE）架构中的专家在并行状态下独立工作，缺乏序列间的交互。这意味着模型的计算资源没有得到充分利用，同时限制了模型的表达能力。为了提高模型性能，研究人员提出了各种扩展方法，如宽度和深度的增加，但这些方法可能面临计算资源和存储需求的挑战。", "innovation": "本文提出了Chain-of-Experts (CoE)架构，这是一种创新的MoE模型。CoE在每个层内引入了专家间的序列通信机制，通过迭代的方式在一个专家序列中处理令牌。CoE利用每个层内的专门路由机制来支持跨迭代过程中的动态专家选择。这种设计使得令牌在每次迭代中都能重新评估并选择不同的专家，从而增强了模型的泛化能力和表达能力。CoE架构不仅提高了模型性能，还在深度扩展方面提供了一种新的维度，即通过专家迭代的深度扩展，弥补了传统的宽度和深度扩展方法。与宽扩展相比，使用两倍迭代可以相当于增加三倍专家数量，同时还能减少17.6%至42%的内存使用量。这些优势得益于CoE的迭代残差结构和通过迭代路由增强的专家专业化，从而解锁了更强的表达能力。", "conclusion": "实验结果表明，与常规的MoE相比，固定计算量下CoE在数学推理任务上验证损失降低了0.08。CoE不仅提供了一种改进模型性能的方法，还提供了一种新的扩展维度，即通过深入优化而不是仅仅增加宽度，同时控制了计算资源和存储的需求。"}
{"llm_update_time": "2025-06-25 09:23:36", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19035", "html_url": "https://arxiv.org/abs/2506.19035", "title": "时间序列解释算法在重症监护应用中的失效模式及潜在解决方案", "title_en": "Failure Modes of Time Series Interpretability Algorithms for Critical Care Applications and Potential Solutions", "authors": "Shashank Yadav,Vignesh Subbian", "background": "可解释性对于在危重症条件下对深度学习模型进行调整和部署起着关键作用，特别是在不断演变的条件下，这些条件影响患者生存。然而，在动态预测任务中，常规的解释算法遇到了特殊挑战，尤其是在患者轨迹随时间变化时。梯度、遮挡和置换方法在处理时间变化的目标依赖性和时间连续性上时常遇到困难。因此，本文系统地分析了这些失败模式，并支持基于可学习掩码的解释框架作为替代方案，这些框架能够结合时间连续性和标签一致性约束，从而随着时间推移学习特征的重要性。", "innovation": "本文提出了基于可学习掩码的方法，用于解决动态时间序列预测问题，提供了更可靠且一致的解释，适用于重症监护和其他相关领域。这种方法能够结合时间连续性和标签一致性等约束，以提高解释的准确性和一致性。", "conclusion": "本文系统地分析了时间序列解释算法在危重症应用中的失效模式，并提出了基于可学习掩码的解释框架作为解决方案，该框架能够提高在动态预测任务中的解释可靠性和一致型，从而为应用到危重症和其他领域提供了新的可能性。"}
{"llm_update_time": "2025-06-25 09:23:37", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19023", "html_url": "https://arxiv.org/abs/2506.19023", "title": "利用视觉监督深度学习实现SHM传感器网络的交通监测自动化", "title_en": "Automating Traffic Monitoring with SHM Sensor Networks via Vision-Supervised Deep Learning", "authors": "Hanshuo Wu,Xudong Jian,Christos Lataniotis,Cyprien Hoelzl,Eleni Chatzi,Yves Reuland", "background": "桥梁作为关键的民用基础设施组成部分，受到腐蚀等因素的影响越来越严重，因此可靠的道路交通监测对于评估桥梁剩余使用年限变得至关重要。在操作载荷中，交通载荷起到了关键作用。近年来，深度学习的进步特别是在计算机视觉（CV）领域的进步，使得持续的自动化监测成为可能。然而，基于CV的方法存在隐私问题和对光环境的敏感性，而传统的非视觉方法则缺乏部署和验证的灵活性。", "innovation": "本文提出了一种完全自动化的基于深度学习的管道，用于使用结构健康监测（SHM）传感器网络进行连续的交通监测。该方法结合了通过CV辅助生成高分辨率数据集和监督训练/推理，并利用图神经网络（GNNs）捕捉传感器数据的空间结构及其相互关系。通过将从CV输出的知识迁移到SHM传感器，所提出的方法让传感器网络达到了基于视觉系统的类似准确性，同时减少了人类干预。", "conclusion": "模型在真实案例研究中的加速度计和应变计数据上实现了业界领先的表现，轻型车辆的分类准确率为99%，重型车辆为94%。"}
{"llm_update_time": "2025-06-25 09:23:38", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19082", "html_url": "https://arxiv.org/abs/2506.19082", "title": "FairCauseSyn: 朝着因果公平增强的LLM辅助合成数据生成", "title_en": "FairCauseSyn: Towards Causally Fair LLM-Augmented Synthetic Data Generation", "authors": "Nitish Nagesh,Ziyu Wang,Amir M. Rahmani", "background": "合成数据生成是通过生成模型基于真实世界数据创建数据的过程。在医疗应用中，生成高质量的数据并且在敏感属性上保持公平性是实现公平结果的关键。现有的基于生成对抗网络（GAN）和基于语言模型（LLM）的方法集中在反事实公平性上，并且主要应用于金融和法律领域。因果公平提供了一个更为全面的评估框架，能够保留因果结构，但当前的合成数据生成方法在医疗环境中并未解决这些问题。", "innovation": "本文开发了第一个基于LLM增强的合成数据生成方法来提升因果公平性，使用真实的医疗表格数据。生成的数据在因果公平性度量上的偏差率低于10%，当使用因果公平均衡预测器训练时，合成数据将敏感属性上的偏差降低了70%与真实数据相比。这项工作改善了获得公平合成数据的途径，支持了公平的健康研究和健康服务交付。", "conclusion": "本文通过开发基于LLM增强的合成数据生成方法提高了因果公平性，使研究和医疗服务更加公平。"}
{"llm_update_time": "2025-06-25 09:23:40", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.10156", "html_url": "https://arxiv.org/abs/2502.10156", "title": "FusionForce：端到端可微神经符号层用于轨迹预测", "title_en": "FusionForce: End-to-end Differentiable Neural-Symbolic Layer for Trajectory Prediction", "authors": "Ruslan Agishev,Karel Zimmermann", "background": "本文介绍了一种端到端可微模型，该模型能够从相机图像和/或激光雷达点云中预测机器人在崎岖非路面地形上的轨迹。模型包含一种可学习部分，用于预测机器人与地形的相互作用力，并结合了神经符号层，以确保遵循经典力学定律，从而改善对未见过的数据的泛化能力。", "innovation": "创新点在于，该模型整合了一个可学习的预测部分和一个神经符号层，后者包含一个可微物理引擎，通过求解接触点处的力来计算机器人的轨迹。由于架构包含了大量的几何和物理先验知识，该模型也可以视为一个依据真实传感器数据进行训练的学习物理引擎，它可以以每秒10,000条轨迹的速度运行。这种架构有助于减少模拟到现实的差距，并减轻了对未见过数据的敏感性。模型的可微性结合快速仿真速度，使其非常适合模型预测控制、轨迹预测、监督学习、强化学习或SLAM等多种应用。", "conclusion": "本文提出的模型能够预测机器人在非平坦地形的轨迹，并且通过结合神经符号层和可微物理引擎，能够有效应对未见过数据的情况。该模型的快速仿真速度以及能适应多种应用场景的特点，使其具有广泛的实用性。"}
{"llm_update_time": "2025-06-25 09:23:40", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19104", "html_url": "https://arxiv.org/abs/2506.19104", "title": "有关深度ReLU网络的算法构建", "title_en": "On the algorithmic construction of deep ReLU networks", "authors": "Daan Huybrechs", "background": "很难用数学语言准确描述神经网络在数据上训练所代表的内容。另一方面，对于神经网络原则上能表示的内容，数学上已经有了越来越多的理解。使用ReLU激活函数的前馈神经网络可以表示连续和分段线性函数，并能逼近许多其他函数。对于神经网络的表征能力的研究就是试图回答：它们能够代表哪些函数？", "innovation": "作者从神经网络作为算法的角度进行研究，构建并分析了几个例子，包括已有的和新的例子。这些构建出的例子表明，神经网络作为算法通常是递归的和并行的。与传统算法相比，ReLU网络由于必须是连续的，因此受一些限制。此外，递归深度受限于网络深度，深层网络在某些方面优于浅层网络。这是对神经网络在理论上表示能力的一个新的视角。", "conclusion": "研究表明，神经网络作为算法通常具备递归性和并行性。相较于传统的连续性约束，深度神经网络在某些情况下具有优势。"}
{"llm_update_time": "2025-06-25 09:23:46", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19136", "html_url": "https://arxiv.org/abs/2506.19136", "title": "基于局部学习规则的非平衡物理生成模型", "title_en": "Local Learning Rules for Out-of-Equilibrium Physical Generative Models", "authors": "Cyrill Bösch,Geoffrey Roeder,Marc Serra-Garcia,Ryan P. Adams", "background": "介绍了分数基于生成模型(SGMs)的非平衡驱动协议的学习机制，说明了可以通过局部学习规则直接从力测量或观测到的系统动力学计算梯度，以适应SGMs的参数调整。这为理解和应用分数基于生成模型提供了一个新的视角，特别是在非平衡系统中的应用。", "innovation": "提出了一种局部学习规则，用于分数基于生成模型(SGMs)的非平衡驱动协议的学习。通过力测量或观测到的系统动力学直接计算参数梯度，提高了参数调整的效率和准确性，特别适用于复杂的非平衡系统如受驱动的非线性过阻尼振子网络。", "conclusion": "研究通过一个包含2D混合高斯分布采样的示例和一个使用10x10振子网络从MNIST数据集采样0和1的图像的实验，验证了局部学习规则的有效性。表明局部学习规则可以有效应用于非平衡物理系统的生成模型，为未来的研究和应用提供了依据。"}
{"llm_update_time": "2025-06-25 09:23:49", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19088", "html_url": "https://arxiv.org/abs/2506.19088", "title": "使用轻量级解码器微调天气基础模型以处理未见过的物理过程", "title_en": "Finetuning a Weather Foundation Model with Lightweight Decoders for Unseen Physical Processes", "authors": "Fanny Lehmann,Firat Ozdemir,Benedikt Soja,Torsten Hoefler,Siddhartha Mishra,Sebastian Schemm", "background": "近年来，人工智能天气预报的进步催生了所谓‘基础模型’的出现，这些模型通常通过昂贵的预训练和最少的下游任务微调来定义。然而，在自然科学领域，理想的基础模型还应包含底层物理变量之间的有意义统计关系。本研究评估了最先进的Aurora基础模型在预测未在预训练阶段考虑的水文变量方面的性能。我们提出了一种使用在预训练模型的潜在表示上进行训练的轻量级浅层解码器来预测这些新变量的方法。作为基线，我们将其与对完整模型的微调进行了比较，后者允许进一步优化潜在空间并将新变量纳入输入和输出。基于解码器的方法所需训练时间减少50%，内存减少35%，并且能够跨越各种水文变量获得较高的准确性，同时保留基础模型的可自回归稳定性。值得注意的是，解码器的准确性依赖于新变量与预训练中使用的变量之间的物理相关性，表明Aurora的潜在空间捕捉到了有意义的物理关系。因此，我们认为在地球科学中，基础模型的一个重要质量指标是它们能够不进行全量微调而扩展到新变量的能力。这为拥有有限计算资源的社区使基础模型更加普及提供了新的视角，同时支持地球科学领域的更广泛采用。", "innovation": "提出了一种轻量级的基于浅层解码器的方法，用于预测未在预训练阶段考虑的新水文变量；相比对完整模型的微调，这种解码器方法在训练时间上减少了50%，在内存使用上减少了35%，仍能够保持较高的准确性；强调了基础模型在捕捉物理变量之间的相关性方面的有效性；提出了一种新的质量指标，即基础模型能够在不需要完全微调的情况下扩展到新变量，从而支持这类模型在资源有限的地球科学领域的应用。", "conclusion": "通过引入基于轻量级解码器的方法，可以更高效地扩展现有的基础模型以处理未见过的物理过程，同时保持模型的稳定性和准确性；这种轻量级解码器方法为拥有有限计算资源的社区提供了更加可行的解决方案；对于地球科学领域的应用，这种新的质量评估指标强调了基础模型在新变量上的拓展能力，有助于更广泛的采用。"}
{"llm_update_time": "2025-06-25 09:23:49", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18952", "html_url": "https://arxiv.org/abs/2506.18952", "title": "预算内的LLMs？说HOLA", "title_en": "LLMs on a Budget? Say HOLA", "authors": "Zohaib Hasan Siddiqui,Jiechao Gao,Ebad Shabbir,Mohammad Anas Azeez,Rafiq Ali,Gautam Siddharth Kashyap,Usman Naseem", "background": "在边缘设备上运行大型语言模型（LLMs）受到高计算和内存需求的限制，这阻碍了诸如医疗保健、教育和嵌入式系统等领域中的实时应用。当前的解决方案，如量化、剪枝和检索增强生成（RAG），只能提供部分优化，并且经常在速度或准确性上作出妥协。", "innovation": "我们提出了HOLA，这是一种端到端的优化框架，用于高效部署LLMs。HOLA内部利用层次投机解码（HSD）实现更快的推理且不损失质量。外部，AdaComp-RAG根据上下文需求调整检索复杂性。通过结合LoBi（将结构化剪枝（LoRA）与量化结合），HOLA带来了显著的提升：在GSM8K上的17.6% EMA，在ARC上的10.5% MCA，并减少了Jetson Nano等边缘设备上的延迟和内存消耗，证明了其可扩展性和生产实用性。", "conclusion": "HOLA通过结合HSD、AdaComp-RAG和LoBi，解决了LLMs在边缘设备上部署的关键挑战，显著提高了模型的效率，同时保持了高质量，证明了其在实际应用中的可行性和高效性。"}
{"llm_update_time": "2025-06-25 09:23:49", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19140", "html_url": "https://arxiv.org/abs/2506.19140", "title": "Command-V：通过激活概貌粘贴大语言模型行为", "title_en": "Command-V: Pasting LLM Behaviors via Activation Profiles", "authors": "Barry Wang,Avi Schwarzschild,Alexander Robey,Ali Payani,Charles Fleming,Mingjie Sun,Daphne Ippolito", "background": "对大型语言模型（LLMs）进行新的行为改造通常需要进行全面微调或蒸馏，这些步骤通常成本高昂，需要反复针对不同架构实施。这限制了模型行为的灵活性和效率。现有的方法虽然可以有效传递新行为，但往往需要大量的计算资源和原始训练数据，增加了实施的复杂性。", "innovation": "提出了Command-V，一种无需反向传播的行为转移方法，通过从捐赠模型复制现有的残差激活适配器，并将其效果“粘贴”到受体模型中实现。这一过程无需访问原始训练数据，并且只需要极少的计算资源。通过在三个案例研究中进行实验（安全否决增强、脱逃辅助和自动链式推理），Command-V能够匹配甚至超越直接微调的效果，同时使用了数量级更少的计算资源。", "conclusion": "Command-V展示了在不依赖原始训练数据和大量计算资源的情况下高效转移语言模型行为的潜力，证明了它可以在不牺牲性能情况下，大幅降低行为转移的成本。相关代码和数据可在指定链接访问。"}
{"llm_update_time": "2025-06-25 09:23:50", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19125", "html_url": "https://arxiv.org/abs/2506.19125", "title": "在变压器架构中发现聚类算法", "title_en": "Finding Clustering Algorithms in the Transformer Architecture", "authors": "Kenneth L. Clarkson,Lior Horesh,Takuya Ito,Charlotte Park,Parikshit Ram", "background": "变压器架构的发明彻底改变了人工智能，尤其是在自然语言处理、计算机视觉和多模态推理方面取得了前所未有的成功。尽管取得了这些进展，但仍不清楚变压器是否能够学习并实现精确的算法。本研究通过证明变压器能够准确实现$k$-means聚类的基础且广泛使用的$Lloyd$算法，回答了该问题。", "innovation": "研究提出了一个理论证明，证明存在一种称为$k$-means变压器的变压器架构，该架构能够使用现代变压器的标准成分（如注意力机制和残差连接）精确实现$Lloyd$算法中的$k$-means聚类。此外，研究通过实验证明了该架构与$Lloyd$算法之间的精确对应关系，并展示了变压器机制如何能够精确映射到算法执行上，提供了实现特定算法的清晰解读。", "conclusion": "研究发现，通过对$k$-means变压器架构进行可解释的调整（如引入层标准化或多层感知机），可以生成多种新的聚类算法变体，如软$k$-means、球形$k$-means和修剪后的$k$-means等。这些结果表明，变压器机制能够准确映射到算法流程上，为在变压器中实现精准算法提供了清晰的视角。"}
{"llm_update_time": "2025-06-25 09:23:52", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19143", "html_url": "https://arxiv.org/abs/2506.19143", "title": "思辨锚点：哪种LLM推理步骤是关键？", "title_en": "Thought Anchors: Which LLM Reasoning Steps Matter?", "authors": "Paul C. Bogdan,Uzay Macar,Neel Nanda,Arthur Conmy", "background": "大型语言模型在许多领域已经达到了最先进的性能。然而，这些模型在长篇推理链中产生的解释性挑战性在于，每个生成的令牌都依赖于所有之前的令牌，这使得计算难以分解。我们提出在句子级别分析推理痕迹是一种有希望的方法，以理解推理过程。研究表明，在模型生成特定句子的情况下，通过比较所有可能的100次随机抽样，可以评估每个句子的重要性，这种方法具有黑盒性质；另一种白盒方法通过计算句子之间的注意力模式，发现了一些接收过分注意的“广播”句子，以及负责接收这些不平衡注意力的“接收器”注意力头；最后，因果归因方法通过抑制其中一个句子的注意力，衡量对每个未来句子的影响，从而测量句子间逻辑连接。这些方法都提供了证明“思辨锚点”存在的证据，即那些具有显著重要性的推理步骤，并且比其他步骤更显著地影响后续的推理过程。通常，这些“思辨锚点”是计划或回溯句子。", "innovation": "论文提出了三种互补的方法来分析大型语言模型的长篇推理过程：一种是测量每个句子在生成场景中的重要性，一种是通过注意力模式聚合句子间关系，以及通过因果分析测量句子间逻辑链接。这些方法展示了在句子级别分析推理模型的可能性，并识别出显著影响后续推理过程的“思辨锚点”，通常为计划或回溯句子。此外，论文提供了可视化工具，帮助理解模型的多步推理过程，所有这些方法都展示了句子级别分析的潜力，可以更深入地理解推理模型。", "conclusion": "各个方法的一致性证明了在句子层次上分析推理模型的潜力，可以帮助更深入地理解这些模型的工作原理。"}
{"llm_update_time": "2025-06-25 09:23:54", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19133", "html_url": "https://arxiv.org/abs/2506.19133", "title": "黎曼生成解码器", "title_en": "Riemannian generative decoder", "authors": "Andreas Bjerregaard,Søren Hauberg,Anders Krogh", "background": "黎曼表示学习通常依赖于在选定流形上近似概率密度。这种方法在优化上非常困难，可能影响模型性能。", "innovation": "本文介绍了一种黎曼生成解码器，该方法通过使用黎曼优化器在训练解码网络的同时找到流形值的最大似然潜变量，从而完全避免了优化问题。该方法去掉了编码器，显著简化了流形约束，相比目前只能处理少数特定流形的方法更加灵活。", "conclusion": "该方法仅需要解码器，与现有架构兼容，并能生成与数据几何结构对齐的解释性潜空间。我们在三个案例研究中验证了该方法的有效性，分别涉及合成分支扩散过程、人类迁移（基于线粒体DNA）和细胞周期，结果显示学习到的表示遵循指定的几何结构并捕捉内在的非欧几里得结构。"}
{"llm_update_time": "2025-06-25 09:23:55", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19164", "html_url": "https://arxiv.org/abs/2506.19164", "title": "GradualDiff-Fed: 专为大型语言模型设计的联邦学习专用框架", "title_en": "GradualDiff-Fed: A Federated Learning Specialized Framework for Large Language Model", "authors": "Amir Faiyaz,Tara Salman", "background": "大型语言模型（LLMs）的迅速发展创造了对专门领域（如医学科学）进行微调模型的空前需求。虽然联邦学习（FL）提供了一种去中心化且保护隐私的方法，可以在不共享原始数据的情况下协作微调LLMs，但它也带来了重大的挑战，特别是在性能和高效管理大模型大小方面。", "innovation": "本文介绍了一种名为GradualDiff-Fed的FL框架，专门针对LLMs及其处理高参数大小的挑战。GradualDiff-Fed通过在训练回合中仅传输模型权重差异而不是整个模型来减少通信成本，从而显著提高了可扩展性和通信效率，使其在不牺牲性能的情况下能够在分布式客户端微调LLMs成为可能。评估结果表明，GradualDiff-Fed的性能与中心化训练相当，而通信开销则大幅减少。这些结果突显了GradualDiff-Fed作为在具有保护隐私设置下高效微调大规模模型的解决方案的潜力，而不妥协性能。", "conclusion": "GradualDiff-Fed展示了在分布数据中隐私保护设置下高效微调大型模型的潜力，同时保持了性能。"}
{"llm_update_time": "2025-06-25 09:23:57", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19085", "html_url": "https://arxiv.org/abs/2506.19085", "title": "通过人类偏好研究评估音乐生成模型和指标", "title_en": "Benchmarking Music Generation Models and Metrics via Human Preference Studies", "authors": "Florian Grötschla,Ahmet Solak,Luca A. Lanzendörfer,Roger Wattenhofer", "background": "近年来，生成音乐已更加接近人类创作的作品，但对其进行评估仍然具有挑战性。虽然人类偏好被认为是最可靠的评估标准，但将这些主观判断转化为客观度量指标，特别是对文本-音频对齐和音乐质量评估，仍然存在困难。基于此背景，本文生成了12种最先进的模型共6000首歌，并对15000对音频进行了12500名人类参与者参与的调查，以评估人类偏好与广泛使用的度量标准之间的相关性。到目前为止，这是首次根据人类偏好对当前最先进的音乐生成模型和指标进行排名的研究工作。为了进一步推动主观度量评价领域的发展，本文还提供了人类生成音乐及其评价的开放数据集。", "innovation": "本文进行了以下创新：1) 生成12种最先进的音乐生成模型共生成了6000首歌；2) 进行了大量的人类主观偏好调查（15000对音频对比，12500名参与者）；3) 探讨了人类偏好与常用客观度量指标之间的关系；4) 根据人类偏好对当前最先进的音乐生成模型及其度量指标进行排名；5) 开放了生成音乐和人类评价的数据集。", "conclusion": "本文通过大规模的人类偏好调查和大规模音乐生成标注数据集的构建，首次按照人类偏好对现有的最先进的音乐生成模型和度量指标进行了排名。并提供了开放的数据集，有助于进一步推动主观度量评价领域的研究和发展。"}
{"llm_update_time": "2025-06-25 09:23:58", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19245", "html_url": "https://arxiv.org/abs/2506.19245", "title": "通过黎曼对称空间上的调和分析获得的泛函核", "title_en": "Universal kernels via harmonic analysis on Riemannian symmetric spaces", "authors": "Franziskus Steinert,Salem Said,Cyrus Mostajeran", "background": "核的普遍性质决定了可逼近的相关核再生希尔伯特空间中的函数种类，并且在机器学习中核方法的理论基础中起关键作用。现有的研究主要关注欧几里得域中的核的普遍性质，而这项工作的背景是要进一步探讨非欧几里得域中核的普遍性质，扩展了对这一重要主题的研究范围。", "innovation": "本文建立了黎曼对称空间中核的普遍性质研究的基本工具，从而将研究方向扩展到了非欧几里得领域中的正定核。利用这些工具，证明了几类文献中最近提出的黎曼对称空间上正定核的普遍性，从而为它们在涉及流形值数据的应用中的使用提供了理论依据。", "conclusion": "通过黎曼对称空间上的调和分析，本文扩展了对非欧几里得域中核的普遍性质的研究，证明了特定正定核的普遍性，为这类核在涉及流形值数据的机器学习应用中提供了理论支持。"}
{"llm_update_time": "2025-06-25 09:23:59", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19171", "html_url": "https://arxiv.org/abs/2506.19171", "title": "通过反向翻译轨迹将工具知识集成到语言模型中", "title_en": "Distilling Tool Knowledge into Language Models via Back-Translated Traces", "authors": "Xingyue Huang,Xianglong Hu,Zifeng Ding,Yuan He,Rishabh,Waleed Alzarooni,Ziyu Ye,Wendong Fan,Bailan He,Haige Bo,Changran Hu,Guohao Li", "background": "大型语言模型在解决需要精确计算或多步代数推理的数学问题时常常表现不佳。工具集成推理（TIR）通过利用代码解释器等外部工具来实现正确性，提供了一个有前景的解决方案。然而，这种方法在推理时依赖外部工具，影响了其可扩展性和部署。因此，需要一种新的方法来将工具知识直接集成到大型语言模型中，同时保留模型的无工具依赖性.", "innovation": "本文提出了一种新的方法，通过自然语言将工具知识直接集成到大型语言模型中。首先构建了一个求解代理，通过规划、符号工具调用和反思性推理的交互来解决数学问题。然后，通过多语言模型驱动的代理支持的反向翻译管道，将集成推理轨迹转化为自然语言推理轨迹。解释代理为每个工具调用生成解释，重组代理将这些解释合并成流畅、全局连贯的叙述。实验结果显示，通过对这些合成轨迹进行微调，能够使模型内化工具知识和结构化的推理模式，从而在竞赛级别的数学基准测试中取得显著提升，而无需在推理时访问工具.", "conclusion": "通过这种方法，小型开源模型可以在不需要获取外部工具的情况下，在竞赛级别的数学基准测试获得显著提升，展示了TIR在提升大型语言模型解决数学问题能力方面的潜力。"}
{"llm_update_time": "2025-06-25 09:24:00", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19220", "html_url": "https://arxiv.org/abs/2506.19220", "title": "重新审视私有模型个性化", "title_en": "Private Model Personalization Revisited", "authors": "Conor Snedeker,Xinyu Zhou,Raef Bassily", "background": "本文研究了在用户级差分隐私(DP)下的模型个性化问题，特别是在共享表示框架中的问题。该问题涉及n个用户的统计数据异质性，他们的最优参数共享一个未知嵌入$U^* \times k$，该嵌入将用户参数从$\boldsymbol{R}^d$映射到低维表示$\boldsymbol{R}^k$，其中$k<<d$。目标是在联邦学习设置中，私有地恢复共享嵌入和用户的局部低维表示，使其超过风险尽可能小。", "innovation": "本文提出了一种基于FedRep算法的差分隐私高效的联邦学习算法来学习共享嵌入，该算法不仅满足差分隐私，还可以处理噪声标签的情况。相对于[JRS+21]的工作，本文的方法在更广泛的用户分布情况下（亚高斯分布而非高斯分布）也能提供可用性保证。此外，在自然参数范围内，相比[JRS+21]，算法的隐私误差项改善了$\tilde{O}(dk)$倍。此外，对于二分类问题，本文通过信息论构造方法私有地学习共享嵌入，并提供了与$d$无关的准确度保证。该方法利用Johnson-Lindenstrauss变换来减少共享嵌入的有效维度和用户数据的维度，证明了在这种情况下的边际损失下，可以得到维度无关的风险界。", "conclusion": "本文提出了一种新的联邦学习算法，该算法能够在用户级差分隐私下有效学习共享嵌入，同时也处理了噪声标签的情况。对于二分类问题，本文证明了可以在与$d$无关的情况下学习嵌入。"}
{"llm_update_time": "2025-06-25 09:24:00", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12006", "html_url": "https://arxiv.org/abs/2506.12006", "title": "crossMoDA挑战：从2021年至2023年跨模式领域适应技术在前庭神经鞘瘤和耳蜗分割中的演变", "title_en": "crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023", "authors": "Navodini Wijethilake,Reuben Dorent,Marina Ivory,Aaron Kujawa,Stefan Cornelissen,Patrick Langenhuizen,Mohamed Okasha,Anna Oviedova,Hexin Dong,Bogyeong Kang,Guillaume Sallé,Luyi Han,Ziyuan Zhao,Han Liu,Tao Yang,Shahad Hardan,Hussain Alasmawi,Santosh Sanjeev,Yuzhou Zhuang,Satoshi Kondo,Maria Baldeon Calisto,Shaikh Muhammad Uzair Noman,Cancan Chen,Ipek Oguz,Rongguo Zhang,Mina Rezaei,Susana K. Lai-Yuen,Satoshi Kasai,Chih-Cheng Hung,Mohammad Yaqub,Lisheng Wang,Benoit M. Dawant,Cuntai Guan,Ritse Mann,Vincent Jaouen,Ji-Wung Han,Li Zhang,Jonathan Shapey,Tom Vercauteren", "background": "cross-Modality Domain Adaptation (crossMoDA)挑战始于2021年，作为国际医学图像计算与计算机辅助介入会议(MICCAI)的一部分，主要关注无监督的跨模态分割任务，即从对比增强T1 (ceT1)图像学习并转移到T2 MRI中。该任务旨在提供一个极端的领域偏移示例，用于评估和基准测试分割技术。从临床应用的角度出发，其目标是自动化前庭神经鞘瘤(VS)和耳蜗的T2扫描分割，以便更有效地管理VS。通过多年的发展，挑战的目标逐渐变得更具临床相关性，例如从单机构数据和基本分割发展到多机构数据和Koos分级，再到包含异质性常规数据和中耳和外耳道肿瘤分段。这些年来，挑战逐渐从单一模态转向多模态，涉及的数据量和数据源也逐步增加。这些演变使得挑战不仅具有更广泛的临床实用性，还具有更复杂的技术挑战。", "innovation": "crossMoDA挑战的设计和进展促进了跨模态领域适应技术的进步。2022至2023年期间，挑战逐渐加入了多机构数据、Koos分级以及肿瘤的分段，从而引入了更为复杂的数据和更多实际临床应用的考量因素。此外，挑战还强调了利用更多样化和更具异质性的数据集提升分割性能的方法，探索了高多样性数据集环境下的表现改进策略，并展示了增加数据多样性对性能的积极影响。同时，还通过详细的性能分析展示了如何通过处理复杂标签使性能评估更加精准。", "conclusion": "crossMoDA 2022至2023年度挑战证明了随着数据多样性的增加，跨模态领域的的表现逐渐提升，尽管也遇到了一些如耳蜗分割分数下降等挑战。但整体而言，这些进展表明更复杂跨模态任务的基准是未来衡量区分能力的关键。尽管临床接受的前庭神经鞘瘤分割仍需进一步改进，挑战的持续优化有助于提升相关技术的实用性和有效性，为未来的临床应用奠定了基础。"}
{"llm_update_time": "2025-06-25 09:24:03", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19246", "html_url": "https://arxiv.org/abs/2506.19246", "title": "基于联邦对比学习的分布式系统行为异常检测", "title_en": "Behavioral Anomaly Detection in Distributed Systems via Federated Contrastive Learning", "authors": "Renzi Meng,Heyi Wang,Yumeng Sun,Qiyuan Wu,Lian Lian,Renhan Zhang", "background": "本文针对分布式系统中日益突出的异常检测问题进行研究。传统的集中式方法在数据隐私、节点异构性和异常模式识别方面存在局限性，因此需要一种新的方法来应对这些问题。", "innovation": "提出了一种基于联邦对比学习的检测方法。该方法结合了联邦学习的分布式协作建模能力和对比学习的特征区分增强能力。它在本地节点上构建嵌入表示，并构造正负样本对以引导模型学习更具区分性的特征空间。通过联邦聚合策略优化全球模型，不暴露原始数据。具体而言，该方法使用编码器将本地行为数据表示在高维空间中，包括系统日志、操作指标和系统调用。通过使用对比损失和分类损失训练模型，提高了检测细粒度异常模式的能力。该方法在多种典型攻击类型下进行了评估，并在模拟的实时数据流场景中测试了其响应性。实验结果表明，与现有方法相比，在多个性能指标上表现出色，检测准确率和适应性强，有效解决了分布式环境中的复杂异常问题。通过精心设计关键模块和优化训练机制，该方法在隐私保护和检测性能之间取得了平衡，为分布式系统的智能安全管理提供了一种可行的技术路径。", "conclusion": "本文提出的方法能够在保护隐私的同时，有效提升分布式系统的异常检测性能，并且对复杂的异常具有良好的适应性。该方法为分布式系统的智能安全管理提供了一种有前景的技术方案。"}
{"llm_update_time": "2025-06-25 09:24:03", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18950", "html_url": "https://arxiv.org/abs/2506.18950", "title": "将时间序列/非时间序列混合特征与特征注意力机制集成以实现注射成型产品重量的在线高精度预测方法", "title_en": "Online high-precision prediction method for injection molding product weight by integrating time series/non-time series mixed features and feature attention mechanism", "authors": "Maoyuan Li,Sihong Li,Guancheng Shen,Yun Zhang,Huamin Zhou", "background": "当前在注射成型质量异常检测方面存在不及时检测和在线监控滞后的问题，导致产品质量问题难以及时发现和处理。为解决这一问题，该项研究提出了一种混合特征注意力-人工神经网络（MFA-ANN）模型，用于高精度在线预测产品重量。该模型通过结合基于机制的分析和数据驱动的分析，将时间序列数据（如熔体流动动态、热曲线等）与非时间序列数据（如模具特征、压力设置等）分开，实现层次特征提取。并通过自注意力机制在跨域特征融合过程中动态校准跨模态特征权重，从而强调重量变化的决定因素。实验结果表明，与传统的非时间序列人工神经网络模型相比，MFA-ANN模型的精度提高了25.1%；与长短期记忆网络（LSTM）相比，提高了23%；与支持向量回归（SVR）相比，提高了25.7%；与随机森林（RF）相比，提高了15.6%。进一步的消融试验表明，混合特征建模（贡献22.4%）和注意力机制（贡献11.2%）的结合显著增强了模型的适应性和对噪声的鲁棒性。同时实验证明，数据分辨率对预测可靠性有显著影响，低精度传感器输入会将RMSE提高23.8%从而严重影响模型性能。", "innovation": "研究创新地提出了一种混合特征注意力-人工神经网络（MFA-ANN）模型，该模型通过结合基于机制的分析和数据驱动的分析，能够将时间序列数据和非时间序列数据分开处理，实现高效的特征提取和预测。更重要的是，自注意力机制在特征融合过程中的应用有效提高了模型对关键特征的敏感度，并增强了模型的适应性和鲁棒性。", "conclusion": "与传统预测模型相比，该研究提出的MFA-ANN模型在注射成型产品重量的高精度在线预测中具有显著的优势，不仅精度更高，而且能够更好地适应不同生产条件和抵抗噪声干扰。这为智能控制注射成型过程提供了有效的解决方案。"}
{"llm_update_time": "2025-06-25 09:24:04", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19250", "html_url": "https://arxiv.org/abs/2506.19250", "title": "通过全局利普希茨正则化实现鲁棒行为克隆", "title_en": "Robust Behavior Cloning Via Global Lipschitz Regularization", "authors": "Shili Wu,Yizhao Jin,Puhua Niu,Aniruddha Datta,Sean B. Andersson", "background": "双胞胎是一个有效的模仿学习技术，在自动驾驶车辆等关键安全领域也得到了应用。虽然双胞胎可以使用仅由专家展示的状态-动作对训练策略来模仿专家的行为，但部署时，观察值可能受到测量误差或恶意干扰的影响，这可能导致代理作出次优行动。因此，提升双胞胎策略网络的鲁棒性是一个重要的研究问题。", "innovation": "本文引入了全局利普希茨正则化方法，增强双胞胎策略网络的鲁棒性。研究证明，这种全局利普希茨性质为策略在网络复杂度有限的扰动范围内提供了鲁棒性保证。此外，提出了一种构建利普希茨神经网络的方法，以确保策略的鲁棒性。实验在Gymnasium多种环境中验证了理论的有效性。", "conclusion": "通过引入全局利普希茨正则化，可以有效提升双胞胎策略网络的鲁棒性，使其在处理含有测量误差或干扰的情况下仍能作出最优或次优行动。该研究为安全关键应用中的策略学习方法提供了理论基础。"}
{"llm_update_time": "2025-06-25 09:24:09", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19289", "html_url": "https://arxiv.org/abs/2506.19289", "title": "基于并行图神经网络的可再生能源系统在线继电保护整定极端运行条件高效搜索", "title_en": "Efficient Extreme Operating Condition Search for Online Relay Setting Calculation in Renewable Power Systems Based on Parallel Graph Neural Network", "authors": "Yan Li,Zengli Yang,Youhuai Wang,Jing Wang,Xiaoyu Han,Jingyu Wang,Dongyuan Shi", "background": "可再生能源渗透率提高和基于逆变器的资源广泛应用使得可再生能源系统的运行条件更加波动，这要求采用在线继电保护整定计算策略。但现有基于局部枚举、启发式算法和数学规划的EOCS方法的计算速度无法满足在线继电保护整定计算的效率要求。为了减少计算时间开销，本文首次提出了一种适用于在线继电保护整定计算的高效深度学习基EOCS方法。该方法将电力系统信息分为四个层，并通过并行图神经网络（PGNN）模型进行特征提取，之后将四个特征层拼接并拉伸后输入决策网络，以预测系统的极端运行条件。实验验证显示，提出的PGNN方法在解决EOCS问题时具有更高的准确性，并且在在线计算时间上也有显著改进。在仿真验证中，采用修改后的IEEE 39母线和118母线测试系统，部分同步发电机被可再生能源单元替代，在计算短路电流时充分考虑可再生能源的非线性故障特性。", "innovation": "本文提出了基于并行图神经网络的第一种适用于在线继电保护整定计算的高效EOCS方法。", "conclusion": "提出的PGNN方法在解决可再生能源系统的EOCS问题时具有较高精度并能在在线计算时间上提供显著改进。"}
{"llm_update_time": "2025-06-25 09:24:09", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19282", "html_url": "https://arxiv.org/abs/2506.19282", "title": "一种针对图流中时间连续性问题的批处理无关动态GNN方法", "title_en": "A Batch-Insensitive Dynamic GNN Approach to Address Temporal Discontinuity in Graph Streams", "authors": "Yang Zhou,Xiaoning Ren", "background": "在动态图中，保持时间连续性至关重要。然而，使用大规模批次训练的记忆驱动动态图神经网络（MDGNNs）往往会打断事件序列，导致时间信息丢失。这种不连续性不仅损害了时间建模，还通过增加参数收敛难度阻碍了优化。我们通过Lipschitz上界理论研究量化了这一点，表明大规模批次增大了参数搜索空间。", "innovation": "我们提出了BADGNN，一种新颖的批处理无关框架，包含两大核心组件：（1）时间Lipschitz正则化（TLR）以控制参数搜索空间的扩展；（2）自适应注意力调整（A3）以减轻由正则化和批次引起的注意力扭曲。在三个基准数据集上的实验结果显示，BADGNN在保持强大性能的同时，允许使用显著更大的批次大小并实现更快的训练速度，相较于TGN具有优势。", "conclusion": "我们的实验结果表明，BADGNN能够在保持高性能的同时，允许使用显著更大的批次大小，并且训练速度更快，这与TGN相比具有优势。"}
{"llm_update_time": "2025-06-25 09:24:10", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19302", "html_url": "https://arxiv.org/abs/2506.19302", "title": "在差动继电器中基于深度学习的虚假数据注入检测的对抗性攻击", "title_en": "Adversarial Attacks on Deep Learning-Based False Data Injection Detection in Differential Relays", "authors": "Ahmad Mohammad Saber,Aditi Maheshwari,Amr Youssef,Deepa Kundur", "background": "近年来，基于深度学习方案（DLSs）用于检测智能电网中虚假数据注入攻击（FDIAs）的研究引起了广泛关注。现有研究表明，精心设计的FDIAs可以欺骗已有的FDIA检测系统，尤其是在线线电流差动继电器（LCDRs）中。", "innovation": "该论文提出了一个新的对抗性攻击框架，利用快速梯度符号方法对LCDR的远程测量引入微小扰动，使得FDIA被错误分类为合法故障同时触发LCDR断开。并且，对比了多种深度学习模型（多层感知器、卷积神经网络、长短时记忆网络和残差网络）在对抗性条件下的鲁棒性，结果显示这些模型对对抗性攻击都存在较高的易受攻击性。为了应对这一威胁，论文引入对抗性训练作为主动防御机制，显著提升了模型在对抗性FDIA攻击下的防御能力而不降低故障检测的准确性。", "conclusion": "该研究强调了对抗性攻击对基于深度学习的FDIA检测系统构成的严重威胁，突出了智能电网中需要采取强健的网络安全措施，并证明了对抗性训练的有效性，能显著增强模型对FDIA的鲁棒性。"}
{"llm_update_time": "2025-06-25 09:24:11", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19296", "html_url": "https://arxiv.org/abs/2506.19296", "title": "深层线性状态空间模型表达能力的影响深度研究", "title_en": "The Effect of Depth on the Expressivity of Deep Linear State-Space Models", "authors": "Zeyu Bao,Penghao Yu,Haotian Jiang,Qianxiao Li", "background": "深度状态空间模型（Deep State-Space Models, SSMs）在序列建模中越来越受欢迎。尽管浅层SSMs有很多理论研究，但SSMs的深度对其表达能力的影响仍是一个关键问题。本文系统地研究了深度和宽度在深层线性SSMs中的作用，旨在描述它们如何影响模型架构的表达能力。研究表明，当参数数量保持在同一数量级时，增加深度和增加宽度在无参数约束的情况下通常是等价的。但在参数范数受约束的情况下，深度和宽度的影响显著不同。此外，本文还推导出了在参数范数约束条件下，深层线性SSM表示给定浅层线性SSM所需的最小深度的上界，并通过数值实验验证了理论结果。", "innovation": "本文的主要创新点在于系统地研究了深度和宽度在深层线性SSMs中的作用，提出了无参数约束条件下深度和宽度等效的证明，展示了深层SSMs在参数范数受约束条件下比浅层SSMs更能表示大规模目标的能力，并推导出了在参数范数约束条件下表示浅层线性SSM所必需的最小深度的上界。", "conclusion": "研究结果表明，在无参数约束条件下，深度和宽度在深层线性SSMs中的作用是等价的，但在参数范数受约束的情况下，深层SSMs能更好地表示大规模目标。通过推导出了表示浅层线性SSM所需的最小深度的上界，本文为进一步研究SSMs的表达能力提供了理论支持和指导。"}
{"llm_update_time": "2025-06-25 09:24:16", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19375", "html_url": "https://arxiv.org/abs/2506.19375", "title": "基于轨迹优势回归的路径学习", "title_en": "Path Learning with Trajectory Advantage Regression", "authors": "Kohei Miyaguchi", "background": "本文提出了一种基于强化学习的离线路径学习和路径归因方法——轨迹优势回归。这种方法能够解决路径优化问题，但仅需通过解决一个回归问题来实现算法层面的操作。", "innovation": "本文创新地提出了一种新的方法，即轨迹优势回归，该方法能够在不直接求解路径优化问题的情况下，通过解决一个回归问题来实现路径优化目标。这种方法为路径优化问题提供了一种新的解决方案途径，提高了路径学习和路径归因的效率和灵活性。", "conclusion": "本文提出的方法适用于离线路径学习和路径归因，并能够有效解决路径优化问题。这种方法在算法实现上只需处理回归问题，简化了路径优化过程，为未来的研究提供了新的思路和方向。"}
{"llm_update_time": "2025-06-25 09:24:16", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "Masked Graph Auto-Encoder (Masked GAE) 在图表示学习任务中展现了强大的性能，但现有工作通常依赖于节点上下文信息来恢复被掩蔽的信息。然而，这种方法在处理异结构（heterophilic）图时效果不佳，这些图中连接的节点可能并不相似。现有方法主要关注捕获邻居信息而忽略了不同节点之间的不一致性信息，导致节点表示无法有效区分。因此，本文提出了一种区分性图掩蔽自编码器（Discrepancy-Aware Graph Mask Auto-Encoder，DGMAE），通过在掩蔽过程中重构相邻节点的不一致性信息来获得更加显著的节点表示。实验表明DGMAE在多个图分析任务中显著优于现有自监督学习方法，并且能够有效地保留节点在低维空间中的不一致特征。", "innovation": "该研究提出了一种区分性图掩蔽自编码器（Discrepancy-Aware Graph Mask Auto-Encoder，DGMAE），通过在掩蔽过程中重构相邻节点的不一致性信息来获取更加显著的节点表示。相比现有方法，DGMAE 主要改进在于能够更好地处理异结构图，并显著提高节点分类、节点聚类及图分类等图分析任务的性能。通过别的方式，DGMAE 更进一步地保留了节点在低维空间中的不一致性特征，从而更加准确地进行图分析任务。", "conclusion": "本文提出的DGMAE在多个基准图数据分析任务中表现优异，显著优于现有的自监督学习方法。DGMAE不仅能捕捉图中节点的相似性，还能有效利用不同节点之间的不一致性，提高了图表示的区分度，从而在图分类、节点分类和节点聚类等任务上的性能均优于现有方法。"}
{"llm_update_time": "2025-06-25 09:24:17", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19342", "html_url": "https://arxiv.org/abs/2506.19342", "title": "通过数据库叙述对齐解决酒精推断不匹配以提取见解", "title_en": "Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment", "authors": "Sudesh Bhagat,Raghupathi Kandiboina,Ibne Farabi Shihab,Skylar Knickerbocker,Neal Hawkins,Anuj Sharma", "background": "道路交通事故是全球重大致死原因之一，突显了准确事故数据对于预防策略改进和政策制定的重要性。本研究通过数据库叙述对齐来解决酒精推断不匹配（AIM）这一挑战，旨在通过改善事故管理系统中的数据质量，降低AIM事故的比例。研究通过BERT模型分析了2016年至2022年间爱荷华州的371,062起事故记录，发现存在2,767起AIM事件，整体AIM百分比为24.03%。研究还利用Probit Logit模型探讨了影响AIM模式的事故特征。研究发现，与酒精有关的致命事故和夜间事件中的AIM比例较低，而涉及未知车辆类型和老年驾驶者的情况更容易出现AIM。此外，研究中的地理聚类有助于识别需要更多教育和培训的区域。这些发现凸显了针对性培训计划和数据管理团队的重要性，以提高事故报告的准确性，支持基于证据的政策制定。", "innovation": "本研究通过引入数据库叙述对齐的方法，来解决酒精推断不匹配问题，并发现未知车辆类型和老年驾驶者更容易出现AIM，利用BERT模型对大量事故记录进行分析，提出了有效提升数据准确性的方案。", "conclusion": "通过数据库叙述对齐可以有效识别和减少酒精推断不匹配事故，统计模型表明相关特征对AIM的影响，指出需要针对性地加强特定区域的教育和培训来提高事故数据的准确性，并支持基于准确数据的政策制定。"}
{"llm_update_time": "2025-06-25 09:24:17", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19329", "html_url": "https://arxiv.org/abs/2506.19329", "title": "基于对比跨模态学习的心电图融入胸部X光知识", "title_en": "Contrastive Cross-Modal Learning for Infusing Chest X-ray Knowledge into ECGs", "authors": "Vineet Punyamoorty,Aditya Malusare,Vaneet Aggarwal", "background": "现代的诊断工作流程正在变得越来越多元化，整合了多种数据来源，如医学图像、结构记录和生理时间序列。在这之中，心电图（ECGs）和胸部X光片（CXRs）因其丰富的诊断信息和较高的流行程度，是心脏评估中常用的两种模态。CXR提供了丰富的诊断信息，而ECGs则更为广泛使用，有助于构建支持规模化早期预警系统的早期预警系统。在研究中，作者利用CXR在训练时学习ECG的临床信息表示，提出了一个新的对比学习方法CroMoTEX，专门针对心脏相关的三种病状：心肌肥大、胸腔积液和水肿。这种方法通过一种自导向的、基于模态性的对比学习目标，以及适应负样本加权，实现了在测试时仅依赖ECG输入，提升了诊断的可靠性和相关性，从而适用于在CXR不可用的实际场景中进行部署.", "innovation": "CroMoTEX是一种新颖的对比学习框架，它通过利用胸部X光片来训练学习临床相关的心电图表示。它采用了一种自导向的监督跨模态对比学习目标和自适应的负样本加权，从而增强了特征学习的稳健性和任务相关性。这一方法的优点在于，它在测试时不需要使用胸部X光片，这使得其在实际应用中具有极大的部署灵活性，特别是在CXR不可用的情况下，这对于大规模早期预警系统的构建尤其重要，展示了其在三种心脏相关疾病的诊断上的优越性，尤其是在水肿疾病的诊断上，CroMoTEX达到了78.31的AUROC值，超越了现有的基线方法.", "conclusion": "本研究通过提出一种新颖的对比学习方法CroMoTEX，展示了它的潜力，可以通过整合和使用CXR的特征来提高心电图诊断特定心脏疾病的效率和准确性。该方法在大规模数据集MIMIC-IV-ECG和MIMIC-CXR上的评估表明，它能够达到较高的诊断性能，特别是在水肿疾病的诊断上表现出色，因此对于心脏疾病的早期识别和管理具有重要意义。该研究的主要意义在于其提供了一个实用的框架，用来通过非侵入性和无创的方式改善心脏疾病管理，为进一步相关研究和实际应用打开了新的可能性。"}
{"llm_update_time": "2025-06-25 09:24:19", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19383", "html_url": "https://arxiv.org/abs/2506.19383", "title": "使用机器学习的可解释的人工智能信用风险评估", "title_en": "Explainable Artificial Intelligence Credit Risk Assessment using Machine Learning", "authors": "Shreya,Harsh Pathak", "background": "本文介绍了一种智能且透明的AI驱动信用风险评估系统，该系统结合了最新的三种集成机器学习模型（XGBoost、LightGBM和随机森林）和可解释AI（XAI）技术。该系统通过SHAP和LIME技术解决模型可解释性的问题，同时进行数据预处理、处理类别不平衡和调整超参数。最后通过ROC-AUC、精准率、召回率和F1分数等性能指标来评估模型，发现LightGBM在业务上是最优模型。此外，系统还生成了申请人特定的解释性报告和商业影响总结，确保决策过程的透明性。", "innovation": "结合了最新的三种集成机器学习模型（XGBoost、LightGBM和随机森林），并使用SHAP和LIME技术解决模型可解释性的问题，同时进行数据预处理、处理类别不平衡和调整超参数，生成申请人特定的解释性报告和商业影响总结，确保决策过程的透明性", "conclusion": "LightGBM成为商业上最优模型，其准确性和审批与违约率之间的权衡最佳，系统通过生成申请人特定的解释性报告和商业影响总结，确保Decision-Making过程的透明性。"}
{"llm_update_time": "2025-06-25 09:24:20", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19281", "html_url": "https://arxiv.org/abs/2506.19281", "title": "通过均值约束和噪声减少实现鲁棒的图外分布学习", "title_en": "Robust OOD Graph Learning via Mean Constraints and Noise Reduction", "authors": "Yang Zhou,Xiaoning Ren", "background": "图外分布（OOD）分类常因类别不平衡和结构噪声而表现出显著性能下降。现有方法在处理少数类表现不足以及对结构噪声的高度敏感性方面往往效果不佳。", "innovation": "提出了一种解决方案，即Constrained Mean Optimization（CMO）和Neighbor-Aware Noise Reweighting（NNR）。CMO通过在最坏情况条件下促进基于相似性的实例聚合来增强少数类的鲁棒性；NNR机制基于局部结构一致性为训练样本分配动态权重，从而减轻噪声影响。文章提供了方法的理论支撑，并通过广泛的实验验证了其在图外分布学习中的有效性和显著改进。", "conclusion": "实验表明，该方法在合成和真实数据集上的图外分布泛化能力和分类准确性方面取得了显著提高。该方法的代码可以在指定的URL中获得。"}
{"llm_update_time": "2025-06-25 09:24:23", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19384", "html_url": "https://arxiv.org/abs/2506.19384", "title": "在有限的评估预算下进行深入电磁结构设计", "title_en": "Deep Electromagnetic Structure Design Under Limited Evaluation Budgets", "authors": "Shijian Zheng,Fangxiao Jin,Shuhai Zhang,Quan Xue,Mingkui Tan", "background": "电磁结构（EMS）设计在开发先进的天线和材料方面至关重要，但由于高维设计空间和昂贵的评估，它仍然具有挑战性。现有的方法通常使用高质量的预测器或生成器来减少评估，但这些方法常常耗费大量数据，并且难以应对实际规模和预算限制。", "innovation": "本文提出了一种名为渐进四叉树搜索(PQS)的新方法。PQS将传统的图像式布局转换为四叉树基的层次表示，从而能够从全局模式到局部细节逐步搜索。此外，为了减少对高精度预测器的依赖，引入了一种一致性驱动的样本选择机制。该机制量化预测的可靠性，以平衡探索和利用机制来选择候选设计。PQS在两个实际工程任务上进行了评估：双层频率选择性表面和高增益天线。实验结果表明，该方法在有限的计算预算下可以实现满意的结构设计，优于基准方法，特别是相比于生成方法，评估成本降低了75-85%，有效地节省了20.27-38.80天的产品设计周期。", "conclusion": "本文提出了一种名为渐进四叉树搜索(PQS)的新方法，在有限计算预算下能够优化电磁结构设计，明显降低评估成本，显著减少了产品设计周期，展示了其在实际工程应用中的优势。"}
{"llm_update_time": "2025-06-25 09:24:24", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19351", "html_url": "https://arxiv.org/abs/2506.19351", "title": "上下文中的奥卡姆剃刀：Transformer 如何实时偏好更简单的假设", "title_en": "In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly", "authors": "Puneesh Deora,Bhavya Vasudeva,Tina Behnia,Christos Thrampoulidis", "background": "In-context learning (ICL)使变压器能够通过上下文示例来适应新任务，而无需参数更新。现有研究通常在固定复杂度环境中研究ICL，但实际的语言模型面临的任务涵盖不同的复杂程度。本研究探讨了变压器在面对包含层次结构任务时的适应方式，其中复杂的类别可以完全代表由简单类别生成的任何模式。研究所设计的测试模型基于马尔可夫链和线性回归，揭示了变压器不仅能够识别每个任务的适当复杂度级别，还能准确地推断相应的参数，即使在上下文例子与多种复杂度假设兼容的情况下也是如此。特别是，当面对由简单过程生成的数据时，变压器倾向于选择最简单的充分解释。通过贝叶斯框架，这对变压器的这种行为进行了理论解释，显示出变压器通过平衡模型拟合和复杂性惩罚实现了上下文中的Bayesian Occam's razor.", "innovation": "本研究通过层次结构任务结构探讨了变压器在面对不同复杂度任务时的行为，设计了基于马尔可夫链和线性回归的受控测试环境，发现变压器不仅能够识别任务的适当复杂度级别，还能准确推断相应的参数。研究进一步剥离了模型规模、训练混合分布、推理上下文长度和架构的作用。最后，通过预训练的GPT-4模型及其布尔函数任务，验证了这种类似Occam's razor的归纳偏差，表明这种偏好简单的假设可能是多样任务分布下训练的变压器固有的特点。", "conclusion": "研究证明变压器在处理任务时，倾向于选择最简单的充分解释，并通过贝叶斯框架理论解释了这一行为。研究进一步表明模型大小、训练分布、推理上下文长度和架构等因素对这种倾向有影响。最后，研究通过GPT-4模型的布尔函数任务验证了变压器倾向于选择简单假设的这一特性，暗示这是一种在多样化任务分布下进行训练的变压器固有的倾向。"}
{"llm_update_time": "2025-06-25 09:24:25", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19243", "html_url": "https://arxiv.org/abs/2506.19243", "title": "在无界域中实现高精度PINNs：应用于偏微分方程奇点形成", "title_en": "High precision PINNs in unbounded domains: application to singularity formulation in PDEs", "authors": "Yixuan Wang,Ziming Liu,Zongyi Li,Anima Anandkumar,Thomas Y. Hou", "background": "本文探讨了偏微分方程（PDEs）奇点形成中的高精度物理注入神经网络（PINNs）训练，特别是在无界域中。本文特别关注PDEs奇点表示的应用，并结合严格的计算机辅助证明和PDE分析，提出了一种模块化方法，研究了神经网络形式的选择、采样策略以及优化算法。在1D Burger方程中，该框架能获得非常高精度的解；而在2D Boussinesq方程中，该模型给出的损失值比文献[1]中较少的训练步数获得了4位数的改善。作者还讨论了实现更高度维度问题的机器精度的潜在方向。", "innovation": "本文提出了一种模块化方法，专注于研究神经网络形式的选择、采样策略以及优化算法在无界域中训练高精度PINNs。特别是在Boussinesq方程中，相比文献[1]，本文方法在更少的训练步骤下得到更小的损失值。这表明该方法在提高高维度问题的精度方面具有很大的潜力。", "conclusion": "对于1D Burgers方程，提出的框架能得出非常高精度的解；而对于与3D Euler和Navier-Stokes方程奇性表示直接相关的2D Boussinesq方程，本文方法在更少训练步骤下得到了更优的精度结果。讨论了实现更高维度问题机器精度的潜力。"}
{"llm_update_time": "2025-06-25 09:24:25", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19417", "html_url": "https://arxiv.org/abs/2506.19417", "title": "Center of Gravity-Guided Focusing Influence Mechanism for Multi-Agent Reinforcement Learning", "title_en": "Center of Gravity-Guided Focusing Influence Mechanism for Multi-Agent Reinforcement Learning", "authors": "Yisak Park,Sunwoo Lee,Seungyul Han", "background": "在稀疏奖励下进行协作多智能体强化学习（MARL）面临着探索有限和智能体之间协调关注不足的基本挑战。", "innovation": "本文提出了一种新颖框架——Focusing Influence Mechanism（FIM），该机制通过引导智能体影响任务关键元素（称为重心状态维度）来增强合作。FIM 包括三个核心组件：根据状态维度在智能体行为下的稳定性来识别重心状态维度；设计反事实内在奖励以促进对这些维度的意义上的影响；通过基于资格追踪的信用累积来鼓励持久和同步的专注。这些机制使智能体能够引起更靶向和有效的状态转换，即使在极其稀疏的奖励设置中也能促进稳健的合作。", "conclusion": "通过在多种 MARL 基准上的实证评估表明，提出的 FIM 框架在合作表现方面显著优于基线。"}
{"llm_update_time": "2025-06-25 09:24:26", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19248", "html_url": "https://arxiv.org/abs/2506.19248", "title": "大规模语言模型中的推理时奖励诈骗", "title_en": "Inference-Time Reward Hacking in Large Language Models", "authors": "Hadi Khalaf,Claudio Mayrink Verdun,Alex Oesterling,Himabindu Lakkaraju,Flavio du Pin Calmon", "background": "一个普遍的改进大语言模型性能的范式是优化奖励模型。奖励模型为LLM输出分配一个数值评分，比如展示哪个回应更可能被用户偏好，或者最符合安全目标。然而，奖励模型并非完美无缺，它们不可避免地会成为复杂需求如正确性、有用性和安全性等的代理。过度优化一个不恰当的奖励，可以颠覆预定的对齐目标，降低整体性能，这种现象通常被称为奖励诈骗。本文研究了推理时对齐中的奖励诈骗现象，并探讨了如何通过在代理奖励上的投注来减轻这种现象。本文分析了Best-of-n（BoN）和Soft-Best-of-n（SBoN），并引入了Best-of-Poisson（BoP），在推理时提供了一个高效且接近最优的奖励-KL散度策略。发现实际中观察到的奖励诈骗模式（真实奖励先增加再下降）是广泛推理机制类别的必然属性，包括BoN和BoP。为了对抗这一效果，投注策略提供了一种策略选择，以避免对高但可能误导性代理奖励的过度信心。我们介绍HedgeTune，一种发现推理时最优参数并避免奖励诈骗的有效算法。实验证明，投注策略可以缓解奖励诈骗并实现最优的失真-奖励权衡，同时具有极小的计算开销。", "innovation": "引入了Best-of-Poisson（BoP）策略，作为推理时近似最优的奖励-KL散度策略；提出HedgeTune算法，高效地找到推理时最优参数，避免奖励诈骗。", "conclusion": "实际观察到的奖励诈骗模式是广泛推理机制类别的必然属性，HedgeTune算法可以有效避免奖励诈骗，实现失真-奖励权衡的提高，同时具有极小的计算开销。"}
{"llm_update_time": "2025-06-25 09:24:27", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19396", "html_url": "https://arxiv.org/abs/2506.19396", "title": "Maximal Update Parametrization和Fourier神经算子的零样本超参数转移", "title_en": "Maximal Update Parametrization and Zero-Shot Hyperparameter Transfer for Fourier Neural Operators", "authors": "Shanda Li,Shinjae Yoo,Yiming Yang", "background": "Fourier神经算子（FNOs）提供了一种解决复杂偏微分方程（PDEs）的原理方法。然而，为了处理更复杂的PDEs，需要增加傅里叶模式的数量，这将显著增加模型参数的数量，使得超参数调优在计算上变得不可行。因此，需要一个零样本超参数转移技术，能够在不进行额外调优的情况下，将较小的FNOs调优的最优超参数直接应用于十亿参数的FNOs。", "innovation": "提出了一种新的方法——$结Transfer-FNO$，它基于$结Maximal Update Parametrization$框架，数学上推导出一种参数化方案，使最优超参数可以在不同傅里叶模式数量的模型间进行转移。该方法通过各种PDE的大量实验得到了验证，表明Transfer-FNO可以在保持或提高准确性的同时，降低在大型FNOs上调整超参数的计算成本。", "conclusion": "Transfer-FNO减少了解调优大型FNOs所需的时间，同时保持或提高了准确性，是一种有效的零样本超参数转移技术，适用于处理复杂的偏微分方程。"}
{"llm_update_time": "2025-06-25 09:24:29", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19482", "html_url": "https://arxiv.org/abs/2506.19482", "title": "由虚拟节点学习实现的快速分布式等变图神经网络", "title_en": "Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning", "authors": "Yuelin Zhang,Jiacheng Cen,Jiaqi Han,Wenbing Huang", "background": "等变图神经网络（GNNs）已经在多种科学应用中取得了显著的成功。然而，现有方法在扩展到大规模几何图时面临重要效率挑战，并且在输入图压缩以提高计算可处理性时，性能会显著下降。", "innovation": "本文提出了两种新的增强等变GNN的方法：FastEGNN和DistEGNN。FastEGNN使用一个关键创新：少量有序的虚拟节点，这些节点有效地近似了大量无序的真实节点。具体而言，FastEGNN为不同的虚拟节点实施了不同的消息传递和聚合机制，以确保它们互斥，并通过最小化虚拟和真实坐标之间的最大均值偏差（MMD）来实现全球化分布。这种设计使FastEGNN能够在保持高准确性的同时，高效处理大规模稀疏图。为了处理更庞大的图，本文还引入了DistEGNN，这是一种分布式扩展方法，其中虚拟节点在不同的设备之间的子图之间充当全局桥梁，从而维护一致性并显著减少内存和计算开销。", "conclusion": "通过在四种具有挑战性的领域中的全面评估，本文展示了FastEGNN和DistEGNN在大规模图等变学习中的优势效率和性能，确立了大规模图神经网络的新能力。源代码可在指定网址获取。"}
{"llm_update_time": "2025-06-25 09:24:31", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19478", "html_url": "https://arxiv.org/abs/2506.19478", "title": "ADDQ: 自适应分布双Q学习", "title_en": "ADDQ: Adaptive Distributional Double Q-Learning", "authors": "Leif Döring,Benedikt Wille,Maximilian Birr,Mihail Bîrsan,Martin Slowik", "background": "Q值估计中的偏差问题是Q学习和演员-评论家方法收敛速度的已知障碍。现代RL算法的部分成功原因在于其直接或间接的缓解过度估计机制。本文旨在提出一种易于实现的方法，基于分布强化学习（DRL）算法，以局部自适应方式解决过度估计问题。现有的DRL算法可以通过少量代码改进，且提供了理论依据并使用双Q学习来演示如何将局部自适应过度估计控制纳入现有算法中。实验在表格、Atari和MuJoCo环境中进行了验证。", "innovation": "本文提出的方法是在分布强化学习算法的基础上，以局部自适应的方式解决过度估计问题。这种方法易于实现，可以在现有算法中通过少量代码进行改进。通过理论证据和双Q学习演示了如何将局部自适应过度估计控制纳入现有算法中。", "conclusion": "研究提供了一种基于DRL的简单方法，以局部自适应的方式解决过度估计问题，实验表明该方法可以在多种环境中有效工作。"}
{"llm_update_time": "2025-06-25 09:24:33", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19459", "html_url": "https://arxiv.org/abs/2506.19459", "title": "以标签定向：以精确度确定因果边的方向", "title_en": "Tagged for Direction: Pinning Down Causal Edge Directions with Precision", "authors": "Florian Peter Busch,Moritz Willig,Florian Guldan,Kristian Kersting,Devendra Singh Dhami", "background": "当前的因果关系发现研究表明，具有特定类型分配的变量对倾向于影响具有相同类型分配的其他变量的因果方向。然而，这种类型分配在实践中往往具有挑战性。已有方法主要依赖单一类型的假设来确定因果关系，这在灵活性和鲁棒性方面有所欠缺。本文提出了一种基于标签的因果发现方法，通过分配多个标签至每个变量，并利用这些标签之间的关系来进一步确定因果关系的方向，从而提高了因果关系发现的准确性和有效性。这种方法不仅克服了单类型分配的局限性，还借助高级别的标签关系更好地契合常识。", "innovation": "提出了基于标签的因果发现方法，该方法通过分配多个标签至每个变量，并利用这些标签之间的关系来进一步确定因果关系的方向。这种方法克服了单类型分配的局限性，使因果关系发现更具灵活性和鲁棒性。", "conclusion": "实验结果表明，该方法提高了因果关系发现的准确性和有效性，并且高级别的标签关系符合常识。"}
{"llm_update_time": "2025-06-25 09:24:33", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19486", "html_url": "https://arxiv.org/abs/2506.19486", "title": "Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy", "title_en": "Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy", "authors": "Zhihao Sui,Liang Hu,Jian Cao,Dora D. Liu,Usman Naseem,Zhongyuan Lai,Qi Zhang", "background": "尽管MU技术已经取得了快速进展，但其安全性和隐私保护方面的漏洞仍然未被充分探索，这为隐私泄露带来了潜在风险。当前关于MU攻击的研究大多需要访问包含了隐私数据的原始模型，这违背了MU保护隐私的核心目标。因此，有必要发起一项新的研究，旨在不访问原始模型的情况下，从未学习模型（ULM）中召回被遗忘的数据实例的类别归属信息，以此来研究MU技术的新漏洞。", "innovation": "本文提出了一个创新的会员召回攻击（MRA）框架，该框架采用教师-学生知识蒸馏架构，利用ULMs作为带有噪声的标签器，将知识传递给学生模型。这将ΜU的未学习模型转化为学习带有噪声的标签问题，以推断被遗忘实例的正确标签。该研究通过实证方法展示了MRA策略在恢复未学习实例的类别归属方面的高成效。这项研究为未来关于MU脆弱性研究设立了一个基准，带来了新的研究视角和方法。", "conclusion": "通过广泛的实验，在多种最先进的ΜU方法和多个真实数据集上，本研究证明了所提出的MRA策略在恢复未学习实例类别归属方面的高效率。我们随后的评估和研究为MU的未来研究提供了基准，并强调了重新访问未学习数据实例类别归属的可能性，提醒在设计和应用MU技术时更加重视隐私保护。"}
{"llm_update_time": "2025-06-25 09:24:34", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19537", "html_url": "https://arxiv.org/abs/2506.19537", "title": "符号回归中的维度降低", "title_en": "Dimension Reduction for Symbolic Regression", "authors": "Paul Kahlmeyer,Markus Fischer,Joachim Giesen", "background": "符号回归问题是找到输入变量和有限函数符号集合中的操作符组成的表达式，以逼近数据中的目标函数。评估符号回归算法的一个标准是它们能否从有限样本中恢复出公式，且具有一致性。当公式变得更加复杂，即变量和操作符的数量增加时，从中恢复变得更加困难。自然环境中出现的符号公式中，变量通常只以固定组合出现，可以利用这一点在符号回归中进行替换，从而减少变量数量。然而，找到有效的替换并不容易。因此，本文探讨通过搜索小替换表达式的空间并进行有效性测试的方式，以减少变量数量并提升符号回归算法的性能。", "innovation": "本文提出了一种迭代的维度减少方法，通过搜索较小的替换空间并测试有效性，将有效性测试简化为函数依赖性测试。这种方法可以与任何符号回归方法结合使用。实验表明，这种方法可以可靠地识别有效的替换，并显著提高不同类型的先进符号回归算法的性能。这一方法有助于简化符号回归问题并提高算法效率", "conclusion": "本文提出了一种有效的维度减少方法，能够在符号回归中通过搜索较小的替换空间并进行函数依赖性测试来识别有效的替换，从而增加变量个数，减少计算复杂度，提升符号回归算法性能。该方法适用于多样化的符号回归情形，为符号回归问题提供了一种新的解决问题策略。"}
{"llm_update_time": "2025-06-25 09:24:36", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19496", "html_url": "https://arxiv.org/abs/2506.19496", "title": "COLUR: 针对噪声标签数据的自信导向学习、消除和重新学习用于模型恢复和优化", "title_en": "COLUR: Confidence-Oriented Learning, Unlearning and Relearning with Noisy-Label Data for Model Restoration and Refinement", "authors": "Zhihao Sui,Liang Hu,Jian Cao,Usman Naseem,Zhongyuan Lai,Qi Zhang", "background": "大型深度学习模型在各种任务中取得了显著的成功。然而，如果需要对带有误导性或模糊信息的噪声标签数据集进行训练，模型的性能可能会显著下降。目前，对于如何在模型遭受噪声标签数据影响后恢复其性能的研究还比较有限。本文回顾了噪声标签数据影响下模型性能下降的问题，并指出现有的研究尚未充分探索这一领域。因此，有必要提出一种新的机制来恢复模型在受噪声标签影响后的性能。此项工作受到了神经科学中的‘遗忘机制’的启发，该机制能够在识别并忘记错误知识后，更快速地重新学习正确知识。", "innovation": "本文提出了一种用于恢复和优化模型的鲁棒模型恢复和精炼（MRR）框架——COLUR（Confidence-Oriented Learning, Unlearning and Relearning）。该框架通过一个高效的共训练架构来消除标签噪声的影响，并对每个标签进行模型信心的细化，以便重新学习。该研究的创新之处在于，通过针对噪声标签数据的三个步骤：自信导向的学习、消除和重新学习，实现了对受噪声标签影响模型性能的有效恢复和优化。", "conclusion": "在四个真实数据集上进行了广泛的实验，结果表明，COLUR在模型恢复和优化方面始终优于其他现有的最佳方法（SOTA方法）。"}
{"llm_update_time": "2025-06-25 09:24:37", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19550", "html_url": "https://arxiv.org/abs/2506.19550", "title": "通过符号回归发现ODE的对称性", "title_en": "Discovering Symmetries of ODEs by Symbolic Regression", "authors": "Paul Kahlmeyer,Niklas Merk,Joachim Giesen", "background": "解析普通微分方程（ODE）对于理解动态系统的行为至关重要。然而，自动解决这些方程，尤其是非线性系统，仍然具有挑战性。计算机代数系统（CASs）通过简化方程，特别是利用李点对称性，提供了支持。然而，找到这些对称性本身对CASs来说也是一个难题。最近的符号回归研究表明，从数据中恢复符号表达式是有希望的结果。基于此，我们将基于搜索的符号回归应用于寻找李点对称性的生成元的任务中。通过这种方法，我们可以找到CASs无法发现的ODE的对称性。", "innovation": "本文将基于搜索的符号回归方法应用于发现李点对称性的生成元，这种方法可以从数据中恢复对称性，并能够找到CASs无法找到的ODE的对称性。", "conclusion": "本文提出的方法通过符号回归可以直接从数据中找到ODE的对称性，这在现有的CASs方法之外提供了一种新的途径，有助于更准确地理解和预测动态系统的复杂行为。"}
{"llm_update_time": "2025-06-25 09:24:39", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19567", "html_url": "https://arxiv.org/abs/2506.19567", "title": "FAF：一种用于少量样本时间序列预测的特征自适应框架", "title_en": "FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting", "authors": "Pengpeng Ouyang,Dong Chen,Tong Yang,Shuo Feng,Zhao Jin,Mingliang Xu", "background": "在新产品发布于不同城市等场景中，常见的多任务和少量样本的时间序列预测挑战，传统的时间序列预测方法因缺乏历史数据而遭受不足，这源于不同任务之间普适性和特异性特征的忽视", "innovation": "提出了一种特征自适应时间序列预测框架（FAF），该框架包括通用知识模块（GKM）、任务特定模块（TSM）和排序模块（RM）三个关键组件。GKM通过元学习机制在训练阶段更新，以提取相关任务中的通用特征。TSM通过多个功能区域的训练来识别多样化的局部动态，并从单个任务中学习特定特征。在测试阶段，RM根据输入序列特征动态选择TSM中最相关的功能区域，并将其与GKM学习到的通用知识相结合生成准确的预测", "conclusion": "在少量样本时间序列预测设置下的五个现实世界数据集上评估FAF，实验证明，FAF在三种类别的时间序列预测方法的基础上始终保持最佳性能，特别在CO2排放数据集上相较于最佳基线iTransformer提高了41.81%"}
{"llm_update_time": "2025-06-25 09:24:41", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19540", "html_url": "https://arxiv.org/abs/2506.19540", "title": "超参数优化中的过度调整", "title_en": "Overtuning in Hyperparameter Optimization", "authors": "Lennart Schneider,Bernd Bischl,Matthias Feurer", "background": "超参数优化（HPO）的目标是找到一个最优的超参数配置（HPC），使得生成的模型对未见过的数据有更好的泛化能力。由于期望的泛化误差不能直接优化，通常使用留出法或交叉验证这样的重采样策略进行估算。然而，这一方法假设通过最小化验证误差可以改善泛化效果。但是，由于验证误差的估计是固有的随机的，并依赖于重采样策略，一个自然的问题是过度优化验证误差是否会像基于经验风险最小化导致模型训练中的过拟合一样导致HPO过程中过拟合？本文研究了这一现象，即称为过度调整的现象，它是特定于HPO的过拟合形式。尽管在实践中具有重要意义，但过度调整在HPO和自动机器学习（AutoML）文献中受到的关注并不多。本文提供了过度调整的正式定义，并将其与类似概念区分开来，然后对HPO基准数据进行了大规模重新分析，以评估过度调整的普遍性和严重程度。结果表明，过度调整比先前假设的更为普遍，通常是温和的但偶尔会很严重。在大约10％的情况下，过度调整导致选择了一个看似最优的HPC，但其泛化误差比默认或第一个尝试配置要差。此外，本文分析了诸如评估指标、重采样策略、数据集大小、学习算法和HPO方法等因素如何影响过度调整，并讨论了缓解策略。结果强调了在小数据集情况下提高对过度调整的意识的必要性，表明需要进一步研究缓解策略。", "innovation": "正式定义了过度调整这一现象，并将其与类似概念区分开来；通过大规模重新分析HPO基准数据，评估过度调整的普遍性和严重程度；分析了影响过度调整的因素，并提出了缓解策略；强调了在小数据集情况下对过度调整的意识的重要性，并指出需要进一步研究缓解策略。", "conclusion": "过度调整在HPO中比先前假设的更为普遍，通常是温和的但偶尔会很严重，在大约10％的情况下，过度调整会导致选择了一个看似最优的HPC，但其泛化误差却比默认或第一个尝试配置要差。本文分析了影响过度调整的因素，并提出了缓解策略。研究结果显示，提高对过度调整的意识，特别是在小数据集情况下尤为必要，因此需要进一步研究缓解策略。"}
{"llm_update_time": "2025-06-25 09:24:43", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19609", "html_url": "https://arxiv.org/abs/2506.19609", "title": "超越静态模型：复杂参数动态系统自适应与可泛化的预报的超网络方法", "title_en": "Beyond Static Models: Hypernetworks for Adaptive and Generalizable Forecasting in Complex Parametric Dynamical Systems", "authors": "Pantelis R. Vlachas,Konstantinos Vlachas,Eleni Chatzi", "background": "动力系统在建模、预测和决策方面具有重要作用，但在不同参数下的不同行为可能给模型构建带来挑战。现有的参数变异可能导致模型表现出截然不同的行为和输出，给跨参数域的模型泛化带来了挑战。", "innovation": "该论文提出了一种新的学习框架——Parametric Hypernetwork for Learning Interpolated Networks (PHLieNet)，它可以同时学习从参数空间到非线性嵌入的全局映射，以及从嵌入到动力传播网络权重的映射。这种方法能够在模型空间中进行插值，从而实现动态行为在广泛参数变化下的平滑过渡，提高模型的预测能力和泛化能力。", "conclusion": "该方法在一系列动力系统中得到了验证，特别是在时间外插和参数空间的内插与外插方面表现优异，能够捕捉长期动力学特性，如吸引子统计特征。在所有情况下，该方法的短期预测精度和长期动态特征捕获能力均优于或达到了现有最先进的基线方法。"}
{"llm_update_time": "2025-06-25 09:24:43", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19598", "html_url": "https://arxiv.org/abs/2506.19598", "title": "使用加速线性代数训练功能性注释中基因变异效应的灵活模型", "title_en": "Training Flexible Models of Genetic Variant Effects from Functional Annotations using Accelerated Linear Algebra", "authors": "Alan N. Amin,Andres Potapczynski,Andrew Gordon Wilson", "background": "遗传学家通过测序和测量成千上万人的基因组，来理解人类基因组中的遗传变异如何在表型（如身高或哮喘等疾病）上体现。为预测特定基因变异对表型的影响，遗传学家使用这些数据来构建模型，考虑到变异如DNA可及性或附近的DNA结合蛋白等因素。然而，随着更多数据和特征的加入，模型预测性能本应提升，但实际上，训练这些模型受限于计算逆矩阵等昂贵的线性代数问题，这使得变体与邻近变体的关联性成为难题。因此，以往的方法只能限制于拟合小型模型或简化统计模型，而无法提供完整的统计模型。\n", "innovation": "本文利用现代快速线性代数技术，开发了DeepWAS方法，这是一种用于优化似然性的大型且灵活的神经网络预测模型训练方法。研究表明，相比传统统计方法，当使用本文的完整似然方法训练时，更大型的模型表现更好。此外，使用更多的特征训练的大型模型能做出更好的预测，潜在地提高了疾病预测和治疗靶点识别的性能。\n", "conclusion": "研究表明，当训练模型时采用本文的完整似然性方法，更大型的模型会有较好的表现。这意味着使用更多的特征进行训练可以提升预测效果，这可能有助于改善对疾病预测和治疗靶点的识别。\n"}
{"llm_update_time": "2025-06-25 09:24:44", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19630", "html_url": "https://arxiv.org/abs/2506.19630", "title": "为什么不确定性校准对可靠的扰动基解释至关重要", "title_en": "Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations", "authors": "Thomas Decker,Volker Tresp,Florian Buettner", "background": "扰动基解释被广泛用于增强现代机器学习模型的透明度。然而，这些解释的可靠性往往受到在特定扰动下的未知模型行为的损害。论文深入研究了不确定性校准（即模型的信心与实际准确度的一致性）与扰动基解释之间的关系。研究表明，当模型受到专门用于解释的扰动时，经常会生成不可靠的概率估计，从而直接影响解释的质量。", "innovation": "论文提出了一种名为ReCalX的新方法，用于校准模型以提高扰动基解释质量，同时保持其原始预测。实验结果表明，该校准策略生成的解释与人类感知以及实际物体位置更加一致。", "conclusion": "论文证明了不确定性校准对于提高扰动基解释的可靠性至关重要。通过引入ReCalX方法，解决了模型在特定扰动下生成不可靠概率估计的问题，从而改善了解释质量。"}
{"llm_update_time": "2025-06-25 09:24:44", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19626", "html_url": "https://arxiv.org/abs/2506.19626", "title": "扩展无偏基于搜索的符号回归", "title_en": "Scaling Up Unbiased Search-based Symbolic Regression", "authors": "Paul Kahlmeyer,Joachim Giesen,Michael Habeck,Henrik Voigt", "background": "回归任务中，学习了一个函数从标记数据预测新数据点的标签，目标是达到小的预测误差。符号回归的目标更加雄心勃勃，即学习一个可解释的函数，同时使预测误差最小。为了应对庞大的搜索空间，大多数符号回归方法隐含或明确地假设了搜索空间的结构。本文讨论了搜索空间的结构，特别是查找小表达式空间的有效性，从而找到更准确、更抗噪的解决方案。尤其是，系统性搜索在标准基准数据集上表现出色，能够恢复真实的基本符号表达式的能力超过了最先进的符号回归方法。", "innovation": "系统性搜索更小表达式的空间，可以找到更准确且更能抵抗噪声的解决方案，尤其在基准数据集上表现优异，优于现有的先进符号回归方法，能更好地恢复真实的符号表达式。", "conclusion": "系统性搜索小表达式空间能够找到更精确且更抗噪的解决方案，特别是在基准数据集上优于最先进的符号回归方法，有助于提高符号回归的可解释性和恢复真实表达式的能力。"}
{"llm_update_time": "2025-06-25 09:24:44", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19558", "html_url": "https://arxiv.org/abs/2506.19558", "title": "ConCM: 进一步驱动一致性校准和匹配的一种方法用于少样本类增量学习", "title_en": "ConCM: Consistency-Driven Calibration and Matching for Few-Shot Class-Incremental Learning", "authors": "QinZhe Wang,Zixuan Chen,Keke Huang,Xiu Su,Chunhua Yang,Chang Xu", "background": "少样本类增量学习（FSCIL）要求模型在有限监督的情况下适应新类，同时保留已学习的知识。现有的基于前景的学习空间构建方法预留空间来容纳新类。然而，原型偏差和结构固定限制了嵌入空间的表达能力。与固定空间预留不同，本文探索了特征结构双一致性优化，并提出了一种一致性驱动校准和匹配框架（ConCM），系统地缓解FSCIL中的知识冲突。具体来说，受到海马关联记忆的启发，设计了一个记忆感知的原型校准，从基础类中提取泛化的语义属性并重新整合到新类中，以增强特征的概念中心一致性。进一步，提出了一种动态结构匹配机制，该机制可以自适应地将校准特征对齐到会话特定的最佳流形空间，从而确保跨会话结构一致性。", "innovation": "本文提出了一个一致性驱动的校准和匹配框架（ConCM），其中包含了：1）记忆感知的原型校准，从基础类中提取泛化的语义属性并重新整合到新类中；2）动态结构匹配，自适应地将校准特征对齐到会话特定的最佳流形空间。该方法满足几何最优性和最大匹配，不需要类别数量先验。在mini-ImageNet和CUB200的大规模FSCIL基准测试中，ConCM取得了最先进的性能，超过当前最优方法在增量会话谐波精度上的3.20%和3.68%。", "conclusion": "本文提出的方法在FSCIL任务中表现优异，通过一致性驱动的机制有效解决了新旧类别的知识冲突，实现了更好的泛化能力和结构一致性。"}
{"llm_update_time": "2025-06-25 09:24:46", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19633", "html_url": "https://arxiv.org/abs/2506.19633", "title": "基于潜在均值编码的层次时间序列预测", "title_en": "Hierarchical Time Series Forecasting Via Latent Mean Encoding", "authors": "Alessandro Salatiello,Stefan Birr,Manuel Kunz", "background": "在多种商业应用中，准确且连贯地预测目标变量在粗细时间尺度上的行为对于盈利优化决策至关重要，但时间层次预测仍然是一个开放的研究问题。现有方法无法很好地解决这一问题，尤其是在共时性预测方面存在挑战。", "innovation": "本文提出了一种新的层次架构，通过利用专门针对不同时间聚合级别进行预测的模块来解决这个问题。该架构在隐藏层中学习编码目标变量的平均行为，从而在目标时间层次上实现准确且连贯的预测。实验验证了该架构在具挑战性的M5数据集上的性能，并且结果表明该架构优于现有的模型，如TSMixer模型。", "conclusion": "该研究提出了一种新颖的层次架构，通过潜在均值编码解决了目标变量在不同时间尺度上的准确预测问题，并通过M5数据集的实验证明了其优越性。"}
{"llm_update_time": "2025-06-25 09:24:47", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19645", "html_url": "https://arxiv.org/abs/2506.19645", "title": "部分同步激活的张量并行性", "title_en": "Tensor-Parallelism with Partially Synchronized Activations", "authors": "Itay Lamprecht,Asaf Karnieli,Yair Hanani,Niv Giladi,Daniel Soudry", "background": "大型语言模型（LLMs）的训练和推理需要通过张量并行性处理大量的通信以同步激活状态，这对网络带宽提出了很高的要求。", "innovation": "本文提出了一种“通信感知张量并行架构”(CAAT-Net)，在保持训练精度的同时，通过少量调整当前做法，降低了张量并行通信的需求，从而减少了对网络带宽的需求。研究团队成功训练了1B和7B参数量的CAAT-Net模型，实现了50%的张量并行通信减少，并且没有显著降低预训练精度。此外，实验证明CAAT-Net能够加速训练和推理任务。", "conclusion": "该研究提出了一种通过部分同步激活来实现张量并行的新型架构，这在减少高带宽需求的同时保持了模型训练的性能，并能加速训练和推理过程。"}
{"llm_update_time": "2025-06-25 09:24:54", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19583", "html_url": "https://arxiv.org/abs/2506.19583", "title": "ConStellaration: 一种类似于QI的等离子边界数据集和优化基准", "title_en": "ConStellaration: A dataset of QI-like stellarator plasma boundaries and optimization benchmarks", "authors": "Santiago A. Cadena,Andrea Merlo,Emanuel Laude,Alexander Bauer,Atul Agrawal,Maria Pascu,Marija Savtchouk,Enrico Guiraud,Lukas Bonauer,Stuart Hudson,Markus Kaiser", "background": "聚变器是当前活跃开发中的磁约束设备，旨在提供稳定的碳基融合能源。其设计是一个高维的约束优化问题，需要昂贵的物理模拟和大量的领域专业知识。近年来，聚变物理的进步和开源工具的应用使聚变器优化更为可行，但仍受限于缺乏标准化、基线明确的数据集，尤其是在准等域型（QI）聚变器配置中。这种配置因其对抗电流驱动中断的内在鲁棒性而被视为商业融合的可行路径。", "innovation": "本文通过采样各种QI场并优化对应的等离子边界，创建了一个多样化的QI-like聚变器等离子边界数据集，并且提供了理想磁流体动力学（MHD）平衡和性能指标。同时，引入了三个递进复杂性的优化基准，并提供了基于经典优化技术的参考代码、评估脚本和基准，旨在通过训练学习模型高效生成新的、可行的聚变器配置，无需查询昂贵的物理或acles。", "conclusion": "通过公开数据集、基准问题和参考解决方案，本文旨在降低优化和机器学习研究人员进入聚变器设计的门槛，并加速跨学科进程以将融合能源接入电网。"}
{"llm_update_time": "2025-06-25 09:24:55", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19703", "html_url": "https://arxiv.org/abs/2506.19703", "title": "基于学习辅助的双图匹配方法在结合道路交通运输网络的受损电力网络多人员修复中的应用", "title_en": "Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks", "authors": "Nathan Maurer,Harshal Kaushik,Roshni Anna Jacob,Jie Zhang,Souma Chowdhury", "background": "受损的关键基础设施网络（CINs）在恢复过程中依赖于恢复速度及运行功能的恢复程度。为此，需要分配资源以确定哪支队伍维修特定网络节点及顺序。本文提出了一个创新的基于图的公式，它将代表工人、交通节点和电力节点的两个相连图集成到一个异构图中，以便进行高效的规划。", "innovation": "文中引入了一种结合双图匹配的图增强学习（GRL）方法，通过这种结合，利用图神经网络训练的接近策略优化（Proximal Policy Optimization）和神经进化训练的另一种方法，设计激励函数，以分配工人到修复任务。这种方法能够高效地进行中程匹配，以确定人员和任务之间的最佳分配，同时使用预计算的最短路径以训练提出的恢复规划方法。这个案例研究采用了包含21平方公里交通网络的IEEE 8500个电分布节点的电力网络，展示了方法的普适性和可扩展性。", "conclusion": "实验结果表明，本文提出的方法在不同场景中具有更好的表现，与随机政策相比，学习策略提升了3倍的性能，并且在计算时间和电力恢复方面都优于基于优化的解决方案。"}
{"llm_update_time": "2025-06-25 09:24:56", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19697", "html_url": "https://arxiv.org/abs/2506.19697", "title": "为大型语言模型稳健4比特量化提供异常安全预训练", "title_en": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models", "authors": "Jungwoo Park,Taewhoo Lee,Chanwoong Yoon,Hyeon Hwang,Jaewoo Kang", "background": "在大语言模型（LLMs）中，极端激活异常极大地降低了量化性能，阻碍了设备端的高效部署。虽然已知通道操作和自适应梯度缩放是主要原因，但实际的缓解措施仍然具有挑战性。现有方法主要依赖于事后缓解，而没有从根本上预防这些异常的发生。", "innovation": "我们提出了一种名为Outlier-Safe Pre-Training（OSP）的实用指导原则，它通过结合三个关键创新来预防极端激活异常：1. 使用Muon优化器，消除特权基底同时保持训练效率；2. 使用单尺度RMSNorm，防止通道级别的放大效应；3. 可学习的嵌入投影，重新分配来自嵌入矩阵的激活幅度。通过对一个拥有14亿参数、基于1万亿标记训练的模型进行验证，OSP模型在4比特量化下的表现超越传统方法，且仅增加了2%的训练开销。尤其是在极端量化条件下，OSP模型显示出极低的极端值（0.04），与标准模型（1818.56）相比，这种异常干预从根本上改变了大型语言模型的量化行为特性。", "conclusion": "我们的研究证明，大型语言模型中的异常并不是不可避免的，而是由培训策略引发的，这为更高效的大型语言模型部署奠定了基础。源代码和预训练检查点可从此链接获得：this https URL"}
{"llm_update_time": "2025-06-25 09:24:57", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19692", "html_url": "https://arxiv.org/abs/2506.19692", "title": "运用轻量级生成器实现高效内存连续学习", "title_en": "Leveraging Lightweight Generators for Memory Efficient Continual Learning", "authors": "Christiaan Lamers,Ahmed Nabil Belbachir,Thomas Bäck,Niki van Stein", "background": "连续学习面临的一个主要挑战是灾难性遗忘，即在学习新任务时，旧任务的知识被严重遗忘。将所有先前任务的数据保持在内存中可以消除这一问题，但会增加内存占用。因此，减少所需内存的同时保留关键信息变得至关重要。本研究旨在减少基于内存的连续学习算法所需的内存使用量。因此，探索从先前学习中提取最少的信息，同时最大限度地减少遗忘的方法。研究表明，轻量级生成器能够有效减少内存使用，同时保持或提高学习性能。", "innovation": "本研究提出了一种使用基于奇异值分解（SVD）的轻量级生成器来增强现有的连续学习方法（如A-GEM和经验重放），这些生成器需要少量内存，却能达到最佳效果。它们不需要训练时间，仅需一次快速的线性拟合步骤，就能有效捕捉少量数据样本的分布情况。这种方法在不同的数据集和网络架构上显示出显著提高的平均准确率。", "conclusion": "所提出的方法在减少基于内存的连续学习算法的内存占用方面显示出巨大潜力，能够在保持甚至提高学习效果的同时，有效减少内存消耗。"}
{"llm_update_time": "2025-06-25 09:24:57", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19689", "html_url": "https://arxiv.org/abs/2506.19689", "title": "在何种情况下可以多次重复使用校准集进行置信预测？", "title_en": "When Can We Reuse a Calibration Set for Multiple Conformal Predictions?", "authors": "A.A. Balinsky,A.D. Balinsky", "background": "可靠的不确定性量化对于机器学习应用的信任至关重要。Inductive Conformal Prediction（ICP）提供了一种分布无关的框架，用于生成具有用户指定置信度的预测集或区间。然而，标准ICP保证通常是边际的，并通常需要为每个新的预测重新进行校准以保持其有效性。本文通过研究如何结合使用e-conformal预测和Hoeffding不等式解决了这一实际限制，以使单个校准集能够在高概率下重复使用并保持所需的覆盖率。并利用CIFAR-10数据集进行实验，展示了使用Hoeffding校正如何通过改进的Markov不等式来构建具有量化置信度的预测集的可行性。这证明了在保持形式性能的同时，通过减少重复校准的需求来提高置信预测的实际性。提供的代码是公开的，可以验证这些发现。", "innovation": "本文创新性地利用e-conformal预测与Hoeffding不等式的结合，使得单个校准集能够在高概率下重复使用，从而提升置信预测的实际应用性。通过Hoeffding校正和改进的Markov不等式，构建了具有量化置信度的预测集，证明了在保持形式性能的同时减少重复校准的需求。", "conclusion": "研究结果说明了如何在保持形式性能的同时提高置信预测的实际应用性，通过引入改进的方法使单个校准集可以反复使用，而不会显著降低预测集的覆盖率。实验使用CIFAR-10数据集验证了这种方法的可行性，提供的代码也使这种方法得以验证。"}
{"llm_update_time": "2025-06-25 09:24:58", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19713", "html_url": "https://arxiv.org/abs/2506.19713", "title": "频域中的指导使在低CFG尺度下实现高保真采样成为可能", "title_en": "Guidance in the Frequency Domain Enables High-Fidelity Sampling at Low CFG Scales", "authors": "Seyedmorteza Sadat,Tobias Vontobel,Farnood Salehi,Romann M. Weber", "background": "分类器自由指导（CFG）已成为现代条件扩散模型的重要组成部分。虽然在实践中非常有效，但CFG如何通过机制提升质量和细节、与提示对齐的具体过程尚未完全理解。本文通过在频域分析CFG效应，揭示了低频和高频对生成质量的不同影响。低温度指导控制全局结构和条件对齐，高频度指导主要提高视觉保真度。然而，统一所有频率的标准CFG方法会导致高尺度处过度饱和和低尺度视觉质量下降。", "innovation": "本文提出了一种新的技术——频域解耦指导（FDG），它将CFG分解为低频和高频分量，并为每个分量应用不同的指导强度。FDG在低指导尺度下改善了图像质量，并通过设计避免了高CFG尺度的缺点。实验结果表明，FDG可以提高样本保真度，同时保持多样性，从而优于标准的分类器自由指导方法，使我们的方法成为标准分类器自由指导的即插即用替代品。", "conclusion": "通过广泛的实验，我们证明FDG在多个数据集和模型中持续提高样本保真度并保持多样性，其FID和召回率优于CFG，为我们新的方法成为标准分类器自由指导的可替代选择奠定了基础。"}
{"llm_update_time": "2025-06-25 09:25:00", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19726", "html_url": "https://arxiv.org/abs/2506.19726", "title": "几何感知型变分推断：基于方向权重不确定性稳健且自适应的正则化", "title_en": "Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty", "authors": "Carlos Stein Brito", "background": "深度神经网络需要进行有原则的不确定性量化，但现有变分推断方法在权重空间中通常使用各向同性高斯近似，这与网络固有的几何结构不匹配。本文通过引入基于单位超球体上的冯米塞斯-费希尔分布建模权重不确定性的集中-自适应扰动（CAP），解决了这一不匹配问题。", "innovation": "文章首次提出了一个完整的将方向统计学与神经网络中的实际噪声正则化过程联系起来的理论框架。关键贡献在于，提出了一个解析的推导方法，将vMF集中参数与激活噪声方差相关联，从而可以通过新颖的封闭形式的KL散度正则化器让每一层学习到其最优的不确定性水平。此外，CAP方法在计算上几乎没有额外负载，并且可以无缝集成到标准架构中，为深度学习中的不确定性量化提供了理论依据和实用方法。", "conclusion": "CAP在CIFAR-10数据集上显著提高了模型校准，将预期校准误差降低了5.6倍，同时提供了可解释的逐层不确定性轮廓。该方法具有极小的计算开销且易于集成到标准架构中，提供了一种既理论严谨又实际可行的不确定性量化方法。"}
{"llm_update_time": "2025-06-25 09:25:02", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19680", "html_url": "https://arxiv.org/abs/2506.19680", "title": "通过稳健特征归因进行模型指导", "title_en": "Model Guidance via Robust Feature Attribution", "authors": "Mihnea Ghitu,Matthew Wicker,Vihari Piratla", "background": "在模型学习中控制模型所依赖的模式对于防止对无关或误导性特征的依赖至关重要。这种依赖性，通常称为捷径特征，已在多个领域被观察到，包括医学影像和自然语言处理，它可能会导致现实世界中的危害。为了缓解这种依赖，一种常见的策略是利用人工或机器提供的标注信息，以说明哪些特征是相关还是无关。这些标注与模型解释，通常以特征显著性形式，用于指导训练过程中的损失函数。然而，近期研究显示，特征显著性方法不可靠，因此提供的优化信号较弱。", "innovation": "本文提出了一种简化的优化目标，同时优化了解释的稳健性和捷径学习的缓解。理论证明，该方法比其他具有相似目标的方法更有效。实验证明，与最先进的方法相比，该方法将测试时的错误分类减少了20%，并且实验扩展到了自然语言处理任务。此外，该研究还进行了新颖的消融实验，揭示了标注质量与数量之间的相对重要性。", "conclusion": "本文提出的方法在减少测试时错误分类方面比最先进的方法更有效。通过实验和分析，证明了该方法在优化模型解释稳健性和缓解捷径学习方面的优越性，并且还扩展到了自然语言处理任务。"}
{"llm_update_time": "2025-06-25 09:25:04", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19643", "html_url": "https://arxiv.org/abs/2506.19643", "title": "无监督数据生成对离线强化学习：基于模型视角的方法", "title_en": "Unsupervised Data Generation for Offline Reinforcement Learning: A Perspective from Model", "authors": "Shuncheng He,Hongchang Zhang,Jianzhun Shao,Yuhang Jiang,Xiangyang Ji", "background": "离线强化学习（RL）近年来受到了RL研究人员的广泛关注。但是，离线RL的性能受到分布外问题的影响，这个问题可以通过在在线RL中使用反馈来修正。以往的离线RL研究集中在限制离线算法在分布内，甚至在样本身上取样。但是，较少的工作关注批量数据的影响。作者通过建立模型基础下离线RL优化的理论桥梁，解释了批量数据对离线RL算法性能的影响。虽然真实的边界在实际操作中很难确定，但作者证明了行为策略生成的状态动作对分布和最优政策生成的状态动作对分布之间的距离是影响两者的性能差距的关键因素。", "innovation": "作者提出了一种新的方法UDG（无监督数据生成）：在任务无关的设定下，通过生成一系列训练的策略，以最小化性能差距的最坏情况遗憾。UDG方法能够在未知任务上，比监督数据生成方法更有效地解决问题。", "conclusion": "UDG方法能够在任务无关的设定下解决未知任务，并且相比监督数据生成方法表现出更好的性能。"}
{"llm_update_time": "2025-06-25 09:25:06", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19805", "html_url": "https://arxiv.org/abs/2506.19805", "title": "基于卷积加权方法的物理知情神经网络：一种原始对偶优化视角", "title_en": "Convolution-weighting method for the physics-informed neural network: A Primal-Dual Optimization Perspective", "authors": "Chenhao Si,Ming Yan", "background": "物理知情神经网络（PINNs）被广泛用于求解偏微分方程（PDEs），通过确保深度学习模型的输出及其梯度符合支配方程。然而，由于计算限制，通常只能使用有限的点集进行优化，这在保证其收敛性和准确性方面提出了重大挑战。", "innovation": "提出了新的加权方案，该方案能够在孤立点与其连续邻域区域之间自适应地改变权重，至损失函数。实验证明，这种加权方案能够将相对$L^2$误差降低到较低的水平，从而在计算资源有限的情况下提高优化效率和模型准确性。", "conclusion": "通过实验证据展示了适应性加权方案在保证PINNs的收敛性和提高准确性方面的有效性。"}
{"llm_update_time": "2025-06-25 09:25:06", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19732", "html_url": "https://arxiv.org/abs/2506.19732", "title": "谁在为深度学习做贡献？基于博弈论的多维神经元功能归因", "title_en": "Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units", "authors": "Shrey Dixit,Kayson Fakhar,Fatemeh Hadaeghi,Patrick Mineault,Konrad P. Kording,Claus C. Hilgetag", "background": "当前，神经网络生成大量参数的文本、图像和语音，需要了解每个神经元如何影响这些高维输出。现有的解释AI方法，如SHAP，能够评估输入的重要性，但无法量度神经元在成千上万个输出像素、标记或logits中的贡献。本文旨在通过引入多扰动Shapley值分析（MSA），弥补这一缺憾。MSA是一种无模型依赖的博弈论框架，通过系统性地扰动组合神经元，生成与模型输出维度一致的单元贡献图，从而量度每个神经元的贡献。本研究在多层次感知器到560亿参数的Mixtral-8x7B和生成对抗网络(GAN)等多个规模的应用上验证了MSA的有效性.", "innovation": "提出了一种新的解释AI技术——多扰动Shapley值分析（MSA），该方法是从博弈论角度出发，构建无模型依赖的框架，通过系统性地去除组合神经元，输出维度与模型输出一致的单元贡献图，从而精确地量度每个神经元的贡献。此外，MSA还被应用于从多层次感知器到大规模模型（如Mixtral-8x7B）等各种规模的神经网络中，揭示了一些有趣的特性，例如正则化集中计算在少数神经元“中心”，语言模型内包含语言特定的专家，以及生成对抗网络中像素生成的逆向层次结构.", "conclusion": "多扰动Shapley值分析（MSA）提供了一种强有力的方法来解析、编辑和压缩深度神经网络，通过结合无模型依赖性、高维度贡献图以及多规模的广泛验证，MSA为深度学习模型内部各个组成部分的功能归属提供了新的视角，对其内部机制的理解具有重要价值。"}
{"llm_update_time": "2025-06-25 09:25:10", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19734", "html_url": "https://arxiv.org/abs/2506.19734", "title": "DRIFT: 数据缩减通过信息特征转换-泛化在深度学习开始之前就开始了", "title_en": "DRIFT: Data Reduction via Informative Feature Transformation- Generalization Begins Before Deep Learning starts", "authors": "Ben Keslaki", "background": "现代深度学习架构在优化方面表现优异，但仅在数据输入网络后才能实现。真正的瓶颈在于准备正确的输入：最小化、显著性高且结构化以反映数据的基本模式。本文探讨了数据预处理的重要性，指出物理系统中的振动分析可以为这一过程提供灵感，进而提出了一种新的预处理技术DRIFT。与传统试图在信号与噪声中学习的模型不同，DRIFT强调信息特征并排除无关元素，从而生成更加紧凑且可解释的表示，提升了训练稳定性和泛化性能。DRIFT通过将图像投影到由板的空间振动机理形状形成的低维基础上，实现了一个物理意义上的特征集，使得神经网络可以在显著减少输入维度的同时保持较高的分类准确性。", "innovation": "本文提出了DRIFT（Data Reduction via Informative Feature Transformation），这是一种新颖的预处理技术，灵感来源于物理系统中的振动分析。它在数据输入训练前就可以识别并提取最相关的数据模式，从而生成更加紧凑且可解释的特征表示，增强了训练稳定性和泛化性能。DRIFT通过将图像投影到由板的空间振动机理形状形成的低维基础上，使得神经网络可以在显著减少输入维度的同时保持较高的分类准确性。这项工作强调了从架构工程转向输入数据管理的重要性，展示了基于物理的预处理策略可以提升深度学习的性能。", "conclusion": "大量的实验表明，DRIFT相比于基于像素的传统模型和PCA，在训练稳定性和泛化鲁棒性方面具有更优的表现。此外，DRIFT对批量大小、网络架构和图像分辨率的变化具有较小的敏感性，进一步证明了其作为稳健且高效的特征表示策略的有效性。这项工作将焦点从架构工程转移到输入数据的管理，并强调了基于物理学的数据变换在提升深度学习性能中的力量。"}
{"llm_update_time": "2025-06-25 09:25:10", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19780", "html_url": "https://arxiv.org/abs/2506.19780", "title": "多偏好Lambda加权列表DPO方法用于动态偏好对齐", "title_en": "Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference Alignment", "authors": "Yuhui Sun(University of Alberta),Xiyao Wang(University of Toronto),Zixi Li(Zhejiang University),Jinman Zhao(University of Toronto)", "background": "无监督的大规模语言模型能够捕获广泛的世界知识和推理能力，但将其行为导向特定目标依然具有挑战性，主要是由于缺乏明确的监督。现有的对齐技术，如根据人类反馈进行强化学习（RLHF），依赖训练奖励模型，并执行强化学习以与人类偏好对齐。然而，RLHF容易受到高计算成本、不稳定性和超参数敏感性的问题。因此，直接偏好优化（DPO）被提出作为一种轻量级且稳定的选择，通过分类损失直接对齐语言模型与成对偏好数据。尽管DPO及其扩展通常假设单一静态偏好分布，限制了在多目标或动态对齐场景中的灵活性。因此，本文旨在缓解上述限制，提出了多偏好Lambda加权列表DPO方法方法，该方法能够集成多个人类偏好维度（例如，有用性、无害性、信息量），并通过可控的单纯形加权形式进行动态插值。该方法支持列表偏好反馈并允许在不同的用户意图之间灵活对齐，无需重新训练。实验和理论分析表明，该方法在静态目标上与传统DPO具有同等的有效性，但提供了更好的普遍性和适应性以适应实际应用场景的需求。", "innovation": "提出了一种新的框架：多偏好Lambda加权列表DPO方法，扩展了DPO，使它可以整合多个人类偏好维度（如有用性、无害性和信息量），并通过可控的单纯形加权形式实现动态插值。", "conclusion": "该方法在静态目标上与传统DPO具有同等有效性和实用性，同时提供更好的适应性和灵活性，满足实际部署中的多目标或动态偏好对齐需求。"}
{"llm_update_time": "2025-06-25 09:25:12", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19741", "html_url": "https://arxiv.org/abs/2506.19741", "title": "噪声一致性训练：一种用于单步生成器学习附加控制的原生方法", "title_en": "Noise Consistency Training: A Native Approach for One-Step Generator in Learning Additional Controls", "authors": "Yihong Luo,Shuchen Xue,Tianyang Hu,Jing Tang", "background": "在人工智能生成内容（AIGC）领域，追求高效且可控的高质量内容生成是一个核心挑战。虽然由扩散蒸馏技术驱动的一步生成器能提供优秀的内容生成质量和计算效率，但将它们适应新的控制条件（如结构约束、语义指南或外部输入）却是一个重大挑战。传统方法往往需要对基础模型进行昂贵的修改和后续的扩散蒸馏，这增加了复杂性并且降低了效率。", "innovation": "本文提出了噪声一致性训练（NCT），这是一种新颖且轻量级的方法，可以直接将新的控制信号集成到预训练的一步骤生成器中，而不需要访问原始训练图像或重新训练基础扩散模型。NCT通过引入适配模块并在生成器的噪声空间中使用噪声一致性损失来实现这一点。该损失确保调整后的模型在条件依赖程度不同的噪声下生成行为保持一致，从而隐式地引导模型遵循新的控制条件。理论上，该训练目标可以理解为最小化调整后的生成器与由新条件诱导的条件分布之间的分布距离。NCT具有模块化、数据高效和易于部署的特点，仅依赖于预训练的一步骤生成器和控制信号模型。实验表明，NCT能够在单向前向传播中实现最先进的可控制生成，超越了现有的多步骤和蒸馏基方法，同时在生成质量和计算效率方面均表现出色。", "conclusion": "广泛的实验证明，NCT在单步生成器中学习新的控制信号方面取得了突破性进展，实现了可控制生成的最优性能，同时在生成质量和计算效率上均大大超越了现有方法。"}
{"llm_update_time": "2025-06-25 09:25:12", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19810", "html_url": "https://arxiv.org/abs/2506.19810", "title": "模糊在线学习", "title_en": "Ambiguous Online Learning", "authors": "Vanessa Kosoy", "background": "在线学习通常要求学习者在数据流中逐个处理数据点或实例，并根据接收到的序列调整其预测。然而，在复杂系统（如多值动力系统、推荐算法和无损压缩）中，这些系统或算法可能需要将一个实例映射到多个可能的预测标签上。这项研究旨在提出一种新的在线学习变体，允许学习者生成多个预测标签，并定义正确性，以及一种预测是否可能错误的定义标准。这项工作扩展了在线学习的概念，尤其是在处理具有多个潜在正确标签的情况下。", "innovation": "提出了‘模糊在线学习’的概念，这是一种新的在线学习框架，允许学习者为每个实例生成多个预测标签，并且该框架提出了一个新的错误判定机制。与传统在线学习不同，一个预测被认为是正确的，只要至少有一个标签是正确的，并且没有一个标签是非预期的（预测性错误）。此外，这项工作还与经典的‘苹果品尝’问题相关联，并展示了在特定条件下，任何假设类都有一个最优的错误上限，这个上限可以是Θ(1)、Θ(√N)或N。", "conclusion": "研究揭示了在线学习中的一种新的错误上限分类（三重分类），即在模糊的在线学习环境下，任何假设类的错误上限要么是Θ(1)、要么是Θ(√N)、要么是N，这要比之前对在线学习错误界限的研究更为准确。"}
{"llm_update_time": "2025-06-25 09:25:15", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19813", "html_url": "https://arxiv.org/abs/2506.19813", "title": "使用机器学习策展艺术展览", "title_en": "Curating art exhibitions using machine learning", "authors": "Eurico Covas", "background": "艺术策展一直是艺术专家的主观工作，他们凭借广泛的艺术知识来挑选并展示一些艺术品。目前没有固定的规则来选择这些艺术品，策展人可以根据已提供的主题或自行构建主题。本文基于机器学习技术，提出了一种基于此技术的人工智能模型系列，用于模仿人工策展。研究主要集中在纽约大都会博物馆过去25年的展览数据上，以提取和学习可重复的策展方法和模式。这些模型能够达到一定程度的准确性，可以模仿多个策展人的工作，带来有针对性的策展效果。", "innovation": "本文创新地将机器学习技术应用于艺术品策展领域，提出了一种策略来利用过去25年大都会博物馆的展览数据来训练人工智能模型，从而实现对策展任务的仿真。不同于直接使用大语言模型（如GPT），本文采用特征工程和精心设计小型模型架构的方法，实验表明这种策略同样有效，甚至可以与大规模语言模型相媲美。这为未来使用人工智能技术进行艺术品策展提供了新的思路和可能性，同时也证明了小型模型在特定应用场景下同样具有强大的应用潜力。", "conclusion": "基于这些模型的应用实验，本文得出了两个关键洞察：一是足够的信息存在于已有的策展数据中，能够构建具有高度准确性的策展模型；二是经过特征工程和精心设计的模型，可以与以GPT为代表的大型语言模型相媲美，甚至更加高效。随着更多数据的积累，这种人工智能策展代理人能够更加接近人类艺术策展人的美学和策展判断。"}
{"llm_update_time": "2025-06-25 09:25:16", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19823", "html_url": "https://arxiv.org/abs/2506.19823", "title": "persona特性控制引致的不对齐", "title_en": "Persona Features Control Emergent Misalignment", "authors": "Miles Wang,Tom Dupré la Tour,Olivia Watkins,Alex Makelov,Ryan A. Chi,Samuel Miserendino,Johannes Heidecke,Tejal Patwardhan,Dan Mossing", "background": "理解语言模型如何从其训练分布推广到更广泛的应用场景是一个重要的AI安全问题。Betley等人发现，微调GPT-4o在故意不安全的代码上会导致‘引致不对齐’现象，即模型对无关提示给出典型的恶意回应。本文在此基础上进一步研究了不同条件下的引致不对齐现象，包括基于策略学习在推理模型上、使用不同生成数据集进行微调以及在未经过安全训练的模型中。研究表明，通过微调一个引致不对齐的模型仅在少数无害样本上，可以高效地恢复模型的对齐状态。", "innovation": "本文通过应用‘模型差异’方法，利用稀疏自编码器对比微调前后内部模型表示，揭示了一系列“对齐不符的人物”特征在激活空间中的表现形式，这些特征有效地控制了引致的不对齐现象，并且可以预测模型是否会展现出此行为。此外，作者还探讨了几种缓解策略，发现对某引致不对齐的模型进行简单的上百个无害样本微调能够有效地恢复模型的对齐状态。", "conclusion": "本文揭示了激活空间中的多个对齐不符的人物特征控制了引致的不对齐现象，并通过少量无害样本微调的方法成功缓解了这种不对齐。"}
{"llm_update_time": "2025-06-25 09:25:23", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19847", "html_url": "https://arxiv.org/abs/2506.19847", "title": "可扩展的正交微调", "title_en": "Orthogonal Finetuning Made Scalable", "authors": "Zeju Qiu,Weiyang Liu,Adrian Weller,Bernhard Schölkopf", "background": "正交细调（OFT）以参数高效的方式进行适应，并防止灾难性遗忘。然而，其高运行时间和内存需求限制了其实用部署。现有OFT的计算瓶颈在于其基于权重的实现方式，依赖于具有立方复杂度的矩阵-矩阵乘法。因此，本文需要一种更有效的正交微调解决方案，以减少计算成本并提高部署可行性。", "innovation": "本文提出了一种输入为中心的重新构想的OFTv2，它使用矩阵-向量乘法（即无矩阵计算），将计算成本降低到平方。此外，还引入了Cayley-Neumann参数化，这是一种高效的正交参数化，通过截断的Neumann级数近似Cayley变换中的矩阵求逆。这些修改使OFTv2能够在不牺牲性能的情况下，实现高达10倍的训练速度和3倍的更低GPU内存使用。此外，OFTv2还支持精简量化基础模型的微调，并在训练稳定性和效率以及内存使用方面表现出色，超越了流行的QLoRA方法", "conclusion": "本文提出并验证了OFTv2，它通过改进的计算方法和参数化有效地解决了OFT的计算问题，实现了更高的性能和更低的资源消耗，使得正交微调在实际应用中更加可行。"}
{"llm_update_time": "2025-06-25 09:25:24", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19693", "html_url": "https://arxiv.org/abs/2506.19693", "title": "ReBoot：使用CKKS-bootstrapping的同态加密深层神经网络训练", "title_en": "ReBoot: Encrypted Training of Deep Neural Networks with CKKS Bootstrapping", "authors": "Alberto Pirillo,Luca Colombo", "background": "近年来，人们对数据隐私的担忧日益增长，这凸显了在不泄露机密信息的情况下处理敏感数据的深度学习方法的必要性。在隐私保护技术中，同态加密（HE）因其提供后量子密码安全性和端到端数据保护而脱颖而出。尽管DNN已经在HE环境中受到关注，但它们的应用主要限制在加密推理。关于加密训练的相关研究主要集中在逻辑回归或是依赖多方计算来实现模型微调。这两者都是由于在HE环境下进行DNN训练所需的大量计算开销和算法复杂性所致。本文介绍了一种名为ReBoot的框架，它是第一个能够支持完全加密和非交互式训练的DNN框架，基于CKKS方案，ReBoot引入了一种新的同态加密兼容的神经网络架构，该架构基于局部误差信号，旨在最大限度地减少乘法深度和减少噪声累积。ReBoot还采用了针对实数算术的SIMD操作进行打包策略，极大地降低了计算和内存开销。另外，通过集成近似催化，ReBoot的学习算法支持任意深度多层感知器的训练，使其特别适用于机器学习即服务。", "innovation": "基于CKKS方案，ReBoot引入了一种新的同态加密兼容的神经网络架构，基于局部误差信号，旨在最大限度地减少乘法深度和减少噪声累积。ReBoot采用针对实数算术的SIMD操作进行打包策略，极大地降低了计算和内存开销。通过集成近似催化，ReBoot的学习算法支持任意深度多层感知器的训练，使其特别适用于机器学习即服务。ReBoot在图像识别和表格基准测试上实现了与32位浮点明文训练相当的准确性，同时也实现了完全加密的训练，同时训练延迟降低了8.83倍，性能则大幅提高。", "conclusion": "本文展示的ReBoot是一个能够在CKKS同态加密环境下实现高效、非交互式的DNN训练的框架，通过降低计算和内存开销，提高了训练效率和准确性，特别适用于机器学习即服务场景。"}
{"llm_update_time": "2025-06-25 09:25:25", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19755", "html_url": "https://arxiv.org/abs/2506.19755", "title": "交叉正则化：通过验证梯度的自适应模型复杂度", "title_en": "Cross-regularization: Adaptive Model Complexity through Validation Gradients", "authors": "Carlos Stein Brito", "background": "模型正则化需要大量的手动调参来平衡复杂度和过拟合之间的关系。交叉正则化通过在训练过程中直接适应正则化参数来解决这一权衡，这些参数是通过验证梯度调整的。这种方法将参数优化分为两部分：训练数据引导特征学习，而验证数据塑造复杂性控制，最终可以证明收敛到交叉验证的最优值。", "innovation": "交叉正则化通过在网络中注入噪音来揭示一个引人注目的现象，即异常高的噪音耐受性和特定于架构的正则化，这种正则化是在训练过程中自然出现的。此外，该框架无缝地集成了数据增强、不确定性校准和不断扩大的数据集，同时保持单次运行的效率并通过简单梯度方法实现这一点。", "conclusion": "交叉正则化提供了一种自适应调整模型复杂性的方法，能够在训练过程中动态优化模型的复杂性和正则化。这种方法不仅能够提高模型的泛化能力，还能自动适应特定的架构需求，且保持高效。"}
{"llm_update_time": "2025-06-25 09:25:25", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.14278", "html_url": "https://arxiv.org/abs/2411.14278", "title": "自适应异常检测在识别网络物理系统攻击中的系统文献综述", "title_en": "Adaptive Anomaly Detection for Identifying Attacks in Cyber-Physical Systems: A Systematic Literature Review", "authors": "Pablo Moriano,Steven C. Hespeler,Mingyan Li,Maria Mahbub", "background": "现代网络物理系统中的网络攻击迅速演变，当前大多数方法集中在对以往威胁的特征刻画上，难以有效阻止网络攻击。传统的自适应异常检测技术能够快速处理数据和进行模型适应，被认为是检测演变中的网络攻击最有潜力的技术之一。尽管该领域有大量的研究，但据我们了解，这是我们第一次对自适应异常检测在网络物理系统中的研究进行全面的系统文献综述，从2013年到2023年11月，收集了397篇相关论文，并系统分析了其中的65篇（47篇研究论文和18篇综述论文）。", "innovation": "本研究首次进行了系统的文献综述，提出了一种新的分类框架，以攻防类型、网络物理系统应用、学习范式、数据管理和算法为主要考虑因素。研究发现，已有工作主要关注单一的适应方面（要么数据处理，要么模型适应），而很少同时关注两者。作者旨在帮助研究人员推进技术前沿，使从业者熟悉该领域的最新进展。并且提出了现有研究的局限性及未来的研究方向建议。", "conclusion": "本研究总结了2013年至2023年间自适应异常检测在网络物理系统中的研究进展，指出了其局限性，并提供了未来研究的方向建议。"}
{"llm_update_time": "2025-06-25 09:25:25", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18920", "html_url": "https://arxiv.org/abs/2506.18920", "title": "信号使用与自发合作", "title_en": "Signal Use and Emergent Cooperation", "authors": "Michael Williams", "background": "本文探讨了自主代理如何通过团队形式（部落）学会使用通信信号协调活动，提升集体效率。通过使用NEC-DAC系统，每个代理配备了自己的神经网络来进行决策，研究了这些代理通过学习和信号交流来形成类似文化的共享行为系统。研究重点在于这些代理部落的文化自组织以及不同通信策略对其适应性和合作的影响。通过分析不同的社会结构，如权威层级结构，展示了合作文化的显著影响。此外，研究还探讨了信号如何促进文化的发展和传承，以及它在代理个体神经网络中的协调行为和信号的益处。", "innovation": "本文使用了NEC-DAC系统，该系统使每个代理具备独立的神经网络进行决策，展示了这些代理如何通过学习和信号交流发展出类似文化的行为系统。研究强调了不同社会结构对代理群体合作文化的影响，并探讨了信号在文化发展和传播中的作用，这一研究对理解自组织文化和信号在代理网络中的应用提供了新的视角。", "conclusion": "研究表明，合作文化的自组织对于代理群体的性能有显著影响。不同的通信策略和信号使用方式不仅影响群体的适应性，还影响了代理之间合作的效率。此外，信号在提高代理之间的协调性和文化传承方面也显示出重要作用。"}
{"llm_update_time": "2025-06-25 09:25:31", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18915", "html_url": "https://arxiv.org/abs/2506.18915", "title": "使用机器学习的自动抑郁症评估：一项全面的综述", "title_en": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey", "authors": "Siyang Song,Yupeng Huo,Shiqing Tang,Jiaee Cheong,Rui Gao,Michel Valstar,Hatice Gunes", "background": "抑郁症是当前社会中普遍存在的精神疾病，传统评估依赖于问卷调查和心理医生访谈，但往往会导致主观诊断结果，诊断过程缓慢且昂贵，需要大量人力。现有研究表明，抑郁症会反映在人类大脑活动和外部表达行为中，自2012年起，机器学习和深度学习模型被广泛探索用于基于人类行为的自动抑郁症评估。然而，最新的研究综述往往仅限于少数几种人类行为模态，且缺乏对多模态抑郁相关人类行为的全面综述。为此，本文详细总结了多种模态下的抑郁相关人类行为，并全面探讨了基于机器学习的抑郁行为线索学习方法，同时比较了它们的特点和局限性。此外，本文还回顾了现有的抑郁症评估竞赛和数据集，指出了主要挑战和机遇，为未来的研究提供了进一步的研究方向。", "innovation": "本文对多模态抑郁相关人类行为进行了全面总结，填补了现有文献在这一领域的空白。它不仅探讨了基于机器学习的抑郁行为线索学习方法，还讨论了这些方法的特点和局限性。此外，本文还详细回顾了相关竞赛和数据集，并提供了未来研究的方向。", "conclusion": "本文通过全面综述多个模态下的抑郁相关人类行为和机器学习在自动抑郁评估中的应用，为该领域的未来研究提供了重要的参考依据。"}
{"llm_update_time": "2025-06-25 09:25:36", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19010", "html_url": "https://arxiv.org/abs/2506.19010", "title": "基于模拟的敏感性分析在最优治疗策略和个体化干预因果分解中的应用", "title_en": "Simulation-Based Sensitivity Analysis in Optimal Treatment Regimes and Causal Decomposition with Individualized Interventions", "authors": "Soojin Park,Suyeon Kang,Chioun Lee", "background": "因果分解分析旨在评估修改风险因素对减少社会不平等结果的影响。最近，通过使用最优治疗策略（OTR）在修改风险因素时已开始利用个体特征。由于新定义的个体化效应依赖于未遗漏混杂变量的假设，因此需要开发敏感性分析以适应潜在的未遗漏混杂。此外，OTR和个体化效应主要基于二元风险因素，尚未有正式方法使用观测协变量来评估二元风险因素中遗漏的混杂度。本文在这一点上做出了贡献，通过模拟未测量的混杂变量，解决从推导OTR和估计个体化效果中产生的两种偏差源，同时提出一种形式的边界策略来评估二元风险因素中的遗漏混杂程度。", "innovation": "本文提出了基于模拟的敏感性分析，针对利用最优治疗策略推导个体化干预所产生的偏差进行评估。同时，还提出了一种形式化的界限策略，用于在二元风险因素中基准遗漏混杂的程度。", "conclusion": "本文使用了High School Longitudinal Study 2009 (HSLS:09)数据来验证所提出的敏感性分析和基准化方法的有效性。"}
{"llm_update_time": "2025-06-25 09:25:36", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19025", "html_url": "https://arxiv.org/abs/2506.19025", "title": "最优运输送统统计推断：最近进展与展望", "title_en": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives", "authors": "Sivaraman Balakrishnan,Tudor Manole,Larry Wasserman", "background": "在最优运输送统（OT）的许多应用中，主要关心的对象是最优运输送映射。这种映射通过最小化特定的成本，以最有效的方式重新排列从一个概率分布到另一个的概率。本文回顾了使用底层分布样本估计和开发最优运输送映射的极限定理的最新进展。同时，还回顾了一系列研究，这些研究为基本OT设置的特殊情况和变体建立了类似的结果。文章的结论部分提出了未来研究的关键方向，旨在为从业者提供可靠的统计推断工具。", "innovation": "本文回顾并总结了关于最优运输送映射的估计和极限定理的最新成就，同时探讨了在不同情况下的具体成果，从而为未来研究提供了有价值的方法论视角。", "conclusion": "本文总结了未来研究的关键方向，旨在为从业者提供更可靠和实用的统计推断工具。"}
{"llm_update_time": "2025-06-25 09:25:37", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18959", "html_url": "https://arxiv.org/abs/2506.18959", "title": "从网页搜索到有智能代理驱动的深度研究：用推理代理激励搜索", "title_en": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "authors": "Weizhi Zhang,Yangning Li,Yuanchen Bei,Junyu Luo,Guancheng Wan,Liangwei Yang,Chenxuan Xie,Yuyao Yang,Wei-Chieh Huang,Chunyu Miao,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Yankai Chen,Chunkit Chan,Peilin Zhou,Xinyang Zhang,Chenwei Zhang,Jingbo Shang,Ming Zhang,Yangqiu Song,Irwin King,Philip S. Yu", "background": "信息检索是现代知识获取的基础，每天都有成亿的信息查询发生在不同领域。然而，传统的基于关键词的搜索引擎越来越难以处理复杂的、多步骤的信息需求。传统的信息搜索技术逐渐显得不够用了，需要一种新的方法来解决这些问题。我们的观点是，配备推理和行动能力的大型语言模型（LLMs）正在引领一种新的范式——有智能代理驱动的深度研究。这些系统超越了传统的信息搜索技术，将自动推理、迭代检索和信息合成紧密结合在一个动态反馈循环中。研究从静态网页搜索发展到互动的、基于代理的系统，这些系统能够规划、探索和学习。", "innovation": "研究提出了有智能代理驱动的深度研究这一新范式，这些系统通过结合自动推理、迭代检索和信息合成，形成了一个动态反馈循环。研究还引入了一项测试时的扩展律，以正式化计算深度对推理和搜索的影响。此外，通过基准测试结果和开源实现的推广，研究展示了有智能代理驱动的深度研究不仅在性能上远远超过了现有的方法，而且很可能成为未来信息搜索的主导范式。相关的产业产品、研究论文、基准数据集和开源实现都已收集并公开发布。", "conclusion": "有智能代理驱动的深度研究作为一种新的信息检索范式，不仅在性能上有了显著提升，还预示着它将成为未来信息查询的主导模式。研究为社区提供了所有相关资源，包括产业产品、研究论文、基准数据集和开源实现。"}
{"llm_update_time": "2025-06-25 09:25:38", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19830", "html_url": "https://arxiv.org/abs/2506.19830", "title": "基于前瞻推理扩展推测性解码的规模", "title_en": "Scaling Speculative Decoding with Lookahead Reasoning", "authors": "Yichao Fu,Rui Ge,Zelei Shao,Zhijie Deng,Hao Zhang", "background": "推理模型通过生成长链式推理而表现出色，但解码数千个标记是非常耗时的。虽然标记层级的推测性解码（SD）有所帮助，但其效果有限，因为猜测整个γ个标记完全正确的概率会随着γ的增长而指数级下降。这意味着为了更长时间的解码分配更多的计算资源将面临算法上的限制，从而使得加速效果有限且与硬件无关。本文旨在通过引入前瞻推理来提高推测性解码的规模，通过利用第二个步骤层级的并行性，减轻这一限制。", "innovation": "前瞻推理的核心洞察是推理模型逐步骤生成，每一步只需要语义正确而非精确匹配。在前瞻推理中，轻量级草稿模型提出多个未来步骤，目标模型通过批量处理扩展每个提议，并验证器保留语义正确的步骤，同时让目标模型再生失败的步骤。在此之上，标记层级的推测性解码仍然在每个推理步骤中运行，两层并行性递增。实验结果显示，前瞻推理不仅在理论上而且在实际应用中提升了推测性解码的最大加速倍数。", "conclusion": "前瞻推理在GSM8K、AIME和其他基准测试中提高了推测性解码的加速倍数，从1.4倍提高到2.1倍，同时保持答案质量，并且随着GPU吞吐量的增加，加速效果具有更好的扩展性。相关代码可在指定链接中获取。"}
{"llm_update_time": "2025-06-25 09:25:38", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18930", "html_url": "https://arxiv.org/abs/2506.18930", "title": "基于强化学习的动态分组在管状结构追踪中的应用", "title_en": "Reinforcement Learning-Based Dynamic Grouping for Tubular Structure Tracking", "authors": "Chong Di,Shuwang Zhou,Da Chen,Jean-Marie Mirebeau,Minglei Shu,Laurent D. Cohen", "background": "管状结构（如血管和道路）的最小路径计算因其复杂形态和环境变化而面临挑战。现有方法大致可分为基于点的方法和基于线段的方法。虽然基于线段的方法在许多情况下取得了令人瞩目的结果，但它们往往计算效率较低，并且高度依赖预设的先验知识来拟合目标的伸长形状。针对这些挑战，本文提出了一种新颖的框架，将基于线段的追踪建模为马尔可夫决策过程（MDP），从而采用强化学习方法。这种方法利用Q-Learning在图中的动态探索，在需要时计算边权重，并适应性扩展搜索空间。这种方法避免了预先计算图的高成本，并能够处理不完整初始信息。实验结果表明，该方法在典型管状结构数据集上显著优于现有基于点和基于线段的方法，能够有效地处理复杂拓扑结构，并保持路径的整体连贯性，无需依赖广泛的先验结构知识", "innovation": "提出了基于强化学习的动态分组框架，将基于线段的追踪问题建模为马尔可夫决策过程（MDP），采用Q-Learning方法在图的线段上动态探索，在需要时计算边权重，并适应性扩展搜索空间。这种方法避免了预先计算图的高成本，能够处理不完整初始信息，并相对于现有基于点和基于线段的方法在管状结构追踪上取得了显著效果", "conclusion": "所提出的基于强化学习的方法有效地处理了复杂的拓扑结构，保持了整体路径的连贯性，且无需依赖广泛的先验结构知识，在典型管状结构数据集上显著优于现有的点基和线段基方法。"}
{"llm_update_time": "2025-06-25 09:25:40", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08080", "html_url": "https://arxiv.org/abs/2506.08080", "title": "朝向AI辅助中微子味理论设计", "title_en": "Towards AI-assisted Neutrino Flavor Theory Design", "authors": "Jason Benjamin Baretz,Max Fieg,Vijay Ganesh,Aishik Ghosh,V. Knapp-Perez,Jake Rudolph,Daniel Whiteson", "background": "粒子物理理论，比如中微子味道混合理论，来自于大量模型构建的可能性。通常，模型的构建依赖于理论学家的直觉。同时，识别合适的对称性群、分配场表示和提取与实验数据比较的预测都是相当繁重的工作。因此，需要一种能够自动构建模型的方法，以提高效率并减少自由参数的数量。", "innovation": "我们开发了一个自主模型构建（AMBer）框架，其中强化学习代理与简化后的物理软件流水线互动，以高效搜索这些空间。AMBer选择对称性群、粒子结构和群表示分配，构建可验证模型，同时尽量减少引入的自由参数数量。该方法已在理论空间中得到验证，并扩展到新型且未被探索的对称性群。虽然这种方法在中微子味道理论中进行了演示，但它可以延伸到其他理论模型建设问题。", "conclusion": "我们提出的方法体现了通过强化学习和物理软件反馈的AI辅助理论模型构建的可行性。这种方法不仅提高了中微子味道理论构建的效率，还为未来的其他理论模型建设问题提供了新的思路。"}
{"llm_update_time": "2025-06-25 09:25:44", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19031", "html_url": "https://arxiv.org/abs/2506.19031", "title": "当扩散模型记忆：最小范浅神经网络概率流中的归纳偏置", "title_en": "When Diffusion Models Memorize: Inductive Biases in Probability Flow of Minimum-Norm Shallow Neural Nets", "authors": "Chen Zeno,Hila Manor,Greg Ongie,Nir Weinberger,Tomer Michaeli,Daniel Soudry", "background": "尽管扩散模型能够通过概率流动生成高质量图像，但对其内在机制的理解仍不完整。研究重点在于，概率流动何时会收敛到训练样本或数据流形上的更普遍点。本文通过分析最小 $l^2$ 范数训练的浅 ReLU 神经网络去噪器的概率流来探讨这一问题。研究表明，在正交数据集下，概率流与一种更简单的评分流具有类似的轨迹，二者都趋向于训练点或多个训练点之和。然而，由扩散时间调度器引发的提前停止使概率流能够达到更一般的流形点。这一现象反映了扩散模型兼具记忆训练样本和生成涵盖多个样本特点的新颖点的趋势，从而促使本文探讨这种行为在简化设置下的表现。此外，研究还扩展到锐角简单数据集，并通过正交情况下的模拟确认概率流动可以收敛到训练点、训练点之和或流形点。同时，随着训练样本数量的增加，记忆现象会减弱，因为样本在训练点附近的积累减少。", "innovation": "研究通过分析最小范浅 ReLU 神经网络去噪器的概率流转换，探讨了扩散模型记忆现象背后的概率流规律。简化性分析有助于理解扩散模型生成新颖样本及记忆训练样本的行为。研究成果还证明了在正交数据集和锐角简单数据集下，概率流的收敛特性，并揭示了随着训练样本数量增加，记忆现象减弱的现象。", "conclusion": "本研究加深了对扩散模型概率流的理解，通过分析最小范浅 ReLU 神经网络去噪器的概率流，揭示了扩散模型在生成新颖样本和记忆训练样本之间的行为趋势。此外，研究结果还表明，随着训练样本数量的增加，记忆现象逐渐减弱，这为理解扩散模型的生成机制提供了新的视角。"}
{"llm_update_time": "2025-06-25 09:25:44", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18957", "html_url": "https://arxiv.org/abs/2506.18957", "title": "对 '思维幻象' 的评论：将推理悬崖重新定义为代理差距", "title_en": "A Comment On \"The Illusion of Thinking\": Reframing the Reasoning Cliff as an Agentic Gap", "authors": "Sheraz Khan,Subha Madhavan,Kannan Natarajan", "background": "Shojaee等人（2025）的研究题为《思维的幻象：通过问题复杂度的视角理解推理模型的优势和局限性》，发现大型推理模型（LRMs）的表现会在特定复杂度阈值后突然下降，推测这是链式思维（CoT）推理的固有扩展限制。这篇评论指出尽管该研究方法严谨，但其结论可能受到实验因素的干扰，模型的表现下降并不是根本认知界限的证据，而是系统级约束的结果，包括静态文本评估带来的工具使用限制、回忆范围问题、缺乏关键认知基线、统计报告不充分和生成能力限制。", "innovation": "本文提出了一个新的概念——代理差距，认为模型的失败不在于推理本身，而是在于在高度限制的环境中执行时的不足。并通过实验证明，当模型可以使用工具时，可以显著提高解决问题的能力。此外，作者还通过分析使用工具的模型如o4-mini和GPT-4o，揭示了代理推理的层级，从简单的程序执行到复杂的元认知自我修正，这对定义和衡量机器智能有重要影响。作者认为大型推理模型的认知缺陷并不是推理能力本身的问题，而是缺乏行动工具的结果。", "conclusion": "通过提供一个新的视角——代理差距，本文重新定义了推理悬崖，认为模型的失败并不是因为推理能力不足，而是受限于高约束环境下的执行能力。实验证明，工具的使用极大地提高了模型的解决问题的能力，并揭示了代理推理的不同层次，这对理解机器智能的能力提出了新的挑战。"}
{"llm_update_time": "2025-06-25 09:25:47", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18954", "html_url": "https://arxiv.org/abs/2506.18954", "title": "SHAMaNS: 基于混合 $\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{稳态空间度量}}}}}$ 和神经导引仪的声源定位", "title_en": "SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer", "authors": "Diego Di Carlo(RIKEN AIP),Mathieu Fontaine(LTCI, IP Paris),Aditya Arie Nugraha(RIKEN AIP),Yoshiaki Bando(RIKEN AIP),Kazuyoshi Yoshii", "background": "本文介绍了一种将$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-稳定模型与基于神经网络的方法结合使用的声源定位（SSL）技术。传统的声源定位方法通常基于高斯信源模型，但在非高斯条件下，这种方法可能会产生错误。为了克服这一限制，本文提出了一种新的方法，利用$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-稳定模型和神经网络来更准确地估计不同声音源的方向到达角（DOA）。特别地，通过使用一种物理启发的神经网络（称为神经导引仪）来插值固定麦克风阵列上的测量方向向量（SVs），可以更稳健地估计$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-稳定空间度量。这种度量代表了目标信号最可能的方向到达角。对于非高斯情况（$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$ $\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{∈}}}}}$ (0, 2)），$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-稳定模型定义了唯一的空间度量，本文利用这一点来弥补神经导引仪在后续任务中的残余重构误差。实验结果表明，本文提出的方法在多声源条件下优于当前最先进的方法。", "innovation": "本文的主要创新在于将$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-稳定模型与神经网络结合用于声源定位。具体来说，利用神经导引仪对固定麦克风阵列上的测量方向向量进行插值，并通过$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-稳定模型进行优化，从而提高了多声源环境下的声源定位精度。这种方法适用于非高斯条件下的方向到达角估计，具有更强的鲁棒性。", "conclusion": "本文提出的方法在多声源定位任务中表现出色，优于当前最先进的技术。这种方法通过结合$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}}$-稳定模型和神经导引仪，显著提高了声源定位的准确性和鲁棒性。实验结果证明了该方法的有效性，并展示了其在实际应用中的潜力。"}
{"llm_update_time": "2025-06-25 09:25:48", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19037", "html_url": "https://arxiv.org/abs/2506.19037", "title": "快速计划——基于插值调度的掩蔽扩散语言模型", "title_en": "Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models", "authors": "Omer Luxembourg,Haim Permuter,Eliya Nachmani", "background": "掩蔽扩散语言模型（MDLM）在非自回归文本生成方面表现出了强大的潜力，现有的采样器作为隐式规划者，通过去噪器置信度或熵分值选择要解掩的令牌，但在并行解掩时，这些启发式方法忽略令牌间的两两交互，并无法计算多个同时解掩位置的依赖关系，从而限制了其推理时间与传统的自回归（AR）模型相同。", "innovation": "我们提出了Dilated-scheduled Unmasking Strategy（DUS），这是一种仅用于推理的、无需模型规划的方法，无需额外训练。DUS 利用一阶马尔科夫假设将序列位置分为基于插值的非相邻令牌组，从而可以独立并行地解掩多个位置。该方法将去噪器调用次数减少至每块生成的O(logB)，显著提高了速度，相较于状态最先进扩散模型O(B)的推理时间，这里的B是半自回归推理过程中的块大小。在适于非序数生成的数学（GSM8K）和代码完成（Humaneval、MBPP）基准测试中，DUS 在不修改底层去噪器的情况下，提高了得分。DUS 提供了一种轻量级、预算意识强的方法，用于高效且高质量的文本生成，从而发掘 MDLM 的真正潜力。", "conclusion": "DUS 为 MDLM 的高效率和高质量文本生成提供了一种规划策略，解锁了 MDLM 的真正能力，具有显著的性能提升。"}
{"llm_update_time": "2025-06-25 09:25:50", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19049", "html_url": "https://arxiv.org/abs/2506.19049", "title": "哪些公司调整是关键？基于财务健康提升建模的洞见", "title_en": "Which Company Adjustment Matter? Insights from Uplift Modeling on Financial Health", "authors": "Xinlin Wang,Mats Brorsson", "background": "提升建模在不同领域取得了显著成功，特别是在在线营销中。提升建模是一种主要使用机器学习和深度学习来估算个体治疗效应的方法。本文将提升建模应用于分析公司调整对公司财务状况的影响，并将这些调整视为本研究中的治疗措施或干预。“公司调整”与传统的二元治疗、多项治疗和连续治疗相比往往更复杂，因为它们涉及一系列具有时间依赖性的操作。这些调整的效果估计不仅要考虑个体治疗特性，还要考虑这些治疗的时间顺序。为此，研究收集了来自卢森堡的真实公司财务报表和报告行为的数据集以进行实验研究，以此分析不同公司的调整措施并探讨其对财务健康的影响。", "innovation": "本文提出了一个新的提升建模框架——MTDnet，专门针对时间依赖性的公司调整问题，并通过实验结果证明了考虑这些调整的时间分布至关重要。", "conclusion": "研究表明，提升建模对于分析公司调整对公司财务状况的影响具有重要价值，MTDnet框架能够有效地处理时间依赖性的调整问题，因此在提升建模中考虑治疗措施的时间顺序显得尤为重要。本研究为提升建模在复杂且连续治疗场景下提供了新的解决方案。"}
{"llm_update_time": "2025-06-25 09:25:50", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19121", "html_url": "https://arxiv.org/abs/2506.19121", "title": "CUPID: 使用影响函数来为机器人挑选数据", "title_en": "CUPID: Curating Data your Robot Loves with Influence Functions", "authors": "Christopher Agia,Rohan Sinha,Jingyun Yang,Rika Antonova,Marco Pavone,Haruki Nishimura,Masha Itkina,Jeannette Bohg", "background": "在机器人模仿学习中，策略性能与演示数据的质量和组成紧密相连。然而，理解每个个别演示如何具体影响下游结果（如闭环任务的成功或失败）仍然是一个持续的挑战。本文探讨了这个问题，并提出了一种名为CUPID的机器人数据整理方法，这是一种基于模仿学习策略的影响函数理论公式的方法。通过这种方法，可以估计每个训练演示对策略期望回报的影响，并根据其对策略闭环性能的影响进行排名和选择。", "innovation": "本文创新性地提出了一种名为CUPID的方法，该方法基于影响函数理论，能够估计每个训练演示对政策期望回报的影响。这种方法使得能够根据其对策略闭环性能的影响来对演示进行排名和选择。此外，这种方法可以过滤掉有害于策略性能的演示，并且可以挑选最有希望改进政策的新收集轨迹。实验证明，这种方法可以有效地识别驱动测试性能的关键数据，即使使用较少的受整理数据，也可以达到最先进的扩散策略，并且在硬件实验中也显示出其在分布转移、识别错误的相关性以及增强泛化机器人策略方面的优势。", "conclusion": "我们的方法能够在模拟实验和实际硬件中以有限的数据集中获得最先进的策略性能，甚至在分布转移的情况下也能识别出稳健的策略，并能够隔离错误的相关性，甚至可以增强泛化机器人策略的性能。"}
{"llm_update_time": "2025-06-25 09:25:52", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19141", "html_url": "https://arxiv.org/abs/2506.19141", "title": "EEG基础挑战：从跨任务到跨个体的脑电波解码", "title_en": "EEG Foundation Challenge: From Cross-Task to Cross-Subject EEG Decoding", "authors": "Bruno Aristimunha,Dung Truong,Pierre Guetschel,Seyed Yahya Shirazi,Isabelle Guyon,Alexandre R. Franco,Michael P. Milham,Aviv Dotan,Scott Makeig,Alexandre Gramfort,Jean-Remi King,Marie-Constance Corsi,Pedro A. Valdés-Sosa,Amit Majumdar,Alan Evans,Terrence J Sejnowski,Oren Shriki,Sylvain Chevallier,Arnaud Delorme", "background": "当前的脑电图（EEG）解码模型通常仅基于少量受试者在一个单一任务上进行训练。该文介绍了一个大规模的、基于代码提交的竞赛，包括两个挑战。首先，迁移挑战要求参与者构建并测试可以从其脑电图数据中零样本解码新任务和新个体的模型。其次，精神病理学因素预测挑战要求参与者从脑电图数据中推断个体的心理健康指标。为此，使用了一个前所未有的、多太字节的高密度EEG信号数据集（128通道），该数据集来自超过3000个儿童到成年个体，他们在多个主动和被动任务中参与。", "innovation": "该竞赛有两个挑战，分别为迁移挑战和精神病理学因素预测挑战。提供了一系列可调节的神经网络基准模型，包括简单的网络和基于人口统计信息的回归模型。这将促进能够适应多种任务和个体收集的EEG数据的ML网络架构的发展。此外，从EEG数据中预测与心理健康相关的人格特质值，可能会识别出有用的生物标志物，用于临床诊断和个人心理状况治疗方法的设计。这些进展将有助于计算精神病学和有用神经技术的发展，并促进基础神经科学和临床研究的进步。", "conclusion": "该挑战所推动的进展可能有助于计算精神病学和有用神经技术的发展，并为基础神经科学和应用临床研究的进步做出贡献。"}
{"llm_update_time": "2025-06-25 09:25:52", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19144", "html_url": "https://arxiv.org/abs/2506.19144", "title": "在具备内在维度的Besov空间中稀疏神经网络的后验收缩", "title_en": "Posterior Contraction for Sparse Neural Networks in Besov Spaces with Intrinsic Dimensionality", "authors": "Kyeongwon Lee,Lizhen Lin,Jaewoo Park,Seonghyun Jeong", "background": "该论文基于稀疏贝叶斯神经网络在非线性估计中的理论分析，尤其是在处理高维数据时的性能。背景研究了稀疏结构和连续收缩先验在贝叶斯神经网络中的应用，这些网络在处理高维数据的固有维度时表现出色，解决了多重维度之上典型的维度灾难问题。", "innovation": "创新在于证明了稀疏贝叶斯神经网络可以在具有不同维度结构的集合上达到最优后验收缩率，尤其是基于酉不变Besov空间及其结构组成。这种结构反映了底层函数的固有维度，并允许后验在未知真实函数光滑度的情况下仍能以最优速度收缩。此外，这项工作扩展了稀疏和连续收缩先验的适应率范围。", "conclusion": "结论指出，该研究为贝叶斯神经网络的理论基础提供了坚实的理论支持，并且在高维度、结构化的估计问题中提供了实际有效性的确凿证据。"}
{"llm_update_time": "2025-06-25 09:25:56", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19258", "html_url": "https://arxiv.org/abs/2506.19258", "title": "使用语言模型从生活故事预测人格", "title_en": "Personality Prediction from Life Stories using Language Models", "authors": "Rasiq Hussain,Jerry Ma,Rithik Khandelwal,Joshua Oltmanns,Mehak Gupta", "background": "自然语言处理（NLP）为通过丰富、开放式的文本进行人格评估提供了新的途径，超越了传统的问卷调查。本研究旨在通过处理每篇超过2000个标记的长期叙述性访谈数据，利用预训练语言模型的滑动窗口微调以及循环神经网络（RNN）结合注意力机制来预测五因素模型（FFM）的人格特质，克服传统问卷调查的局限性", "innovation": "提出了一种两步方法，首先使用滑动窗口微调预训练语言模型提取上下文嵌入；然后应用带有注意力机制的递归神经网络（RNN）来整合长范围依赖性并提高可解释性。这种混合方法有效地结合了预训练变换器和序列建模的优势，处理长上下文数据。通过消融研究和与最新的长上下文模型（如LLaMA和Longformer）的比较，证明了在预测准确度、效率和可解释性方面的改进", "conclusion": "研究结果表明，结合基于语言的特征与长上下文建模，有可能进一步提升从生活叙述中进行人格评估的能力"}
{"llm_update_time": "2025-06-25 09:25:57", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19167", "html_url": "https://arxiv.org/abs/2506.19167", "title": "基于深度学习的快速心脏磁共振图像配准方法", "title_en": "A Deep Learning Based Method for Fast Registration of Cardiac Magnetic Resonance Images", "authors": "Benjamin Graham", "background": "心脏磁共振图像分析在临床和科研中广泛应用于追踪组织运动，心脏运动参数可以作为组织健康状态的指标。但是，传统的基于深度学习的心脏图像配准方法由于缺乏准确的对照变换，且可能存在多种使图像相互配对的变换，因而带来了不小的挑战。此外，快速配准方法已有多项研究，但很多方法依赖于块状方法，这可能会对心脏这样动态的器官造成配准准确性的影响。因此，提出了一种高效且轻量级的心脏图像配准模型，以改善当前的状况，提高配准的准确性和运行效率，使其能够满足临床和研究的广泛需求，特别是在普通且中等性能的硬件上快速运行成为可能的重要性愈发凸显。", "innovation": "该研究提出了一种高效且轻量级的心脏图像配准模型——快速配准（FLIR），该模型采用深度学习神经网络，并设计了一种架构，能够非常高效地计算卷积，使模型能够实现与当前最先进模型相近的配准精度，同时大幅减少推理时间。该模型能够用于预测组织运动，并通过量化组织经历的非均匀应变来评估变形。这项方法能够显著提高心脏图像配准的精确度和效率。", "conclusion": "对于来自同一患者、在相同时间点获取的图像，使用FLIR方法计算的应变值之间的差异预计将非常小。实验结果显示，使用FLIR方法计算的应变值表现出非常高的一致性。该模型在保持配准精度的前提下，极大提升了图像配准的速度，为临床和科研的应用提供了新的可能。"}
{"llm_update_time": "2025-06-25 09:25:58", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19178", "html_url": "https://arxiv.org/abs/2506.19178", "title": "使用基于物理信息的神经网络模型模拟闭环DC-DC变换器", "title_en": "Simulation of a closed-loop dc-dc converter using a physics-informed neural network-based model", "authors": "Marc-Antoine Coulombe,Maxime Berger,Antoine Lesage-Landry", "background": "随着对电力电子技术依赖性的增加，出现了对详细的时间域分析和快速精确电路仿真工具的新要求。目前，商业时间域仿真软件主要依赖基于物理的方法来模拟电力电子器件。最近的研究表明，基于数据驱动和物理信息的学习方法可以在不严重影响精度的情况下提高仿真速度，但它们在商业工具中的应用仍然面临许多挑战。因此，作者希望探索一种新的方法来改进这一领域的问题。", "innovation": "提出了基于物理信息双向长短期记忆神经网络(BiLSTM-PINN)模型来模拟各种工作点、参数和扰动条件下的闭环DC-DC升压变换器的时间域响应。此外，还训练了一个基于物理信息全连接神经网络(FCNN)和一个BiLSTM模型进行比较。通过步响应测试评估了这三种方法的性能和局限性。实验结果显示，BiLSTM-PINN 和 BiLSTM 模型在中值 RMSE 方面分别比 FCNN 模型提高了9倍以上和4.5倍以上，且标准差明显更低，说明它们更为一致。这些都是基于物理信息的神经网络在电力电子仿真中的潜在替代方法。", "conclusion": "提出的 BiLSTM-PINN 是一种有潜力的替代方法，可用于电力电子器件的模拟，尤其是对于物理或数据驱动的方法而言。"}
{"llm_update_time": "2025-06-25 09:26:00", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19268", "html_url": "https://arxiv.org/abs/2506.19268", "title": "HARPT: 用于分析消费者对移动医疗服务应用信任和隐私关切的语料库", "title_en": "HARPT: A Corpus for Analyzing Consumers' Trust and Privacy Concerns in Mobile Health Apps", "authors": "Timoteo Kelly,Abdulkadir Korkmaz,Samuel Mallet,Connor Souders,Sadra Aliakbarpour,Praveen Rao", "background": "为了推进用户隐私和信任方面的研究，我们介绍了一个包含480,000个标注的大型移动健康应用商店评论语料库，称为HARPT。该数据集分为七个类别，涵盖了应用程序、提供者信任以及隐私方面的关键方面。\n", "innovation": "HARPT 的创建需要解决多个复杂性问题，如定义精细的标签体系、从大量噪声数据中提取相关内容，以及设计一种平衡可扩展性和准确性的注释策略。这一策略应用了基于规则的过滤、迭代的手动标注、目标数据增强和使用变压器分类器的弱监督策略，以加速覆盖范围。同时，选择7,000个评论进行了手动标注，以支持模型的开发和评估。\n", "conclusion": "我们测试了一系列分类模型，证明了可以实现强大的性能，并为未来的研究提供了基准。HARPT 对支持健康信息学、网络安全和自然语言处理的工作开放作为公共资源。"}
{"llm_update_time": "2025-06-25 09:26:00", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19260", "html_url": "https://arxiv.org/abs/2506.19260", "title": "网络结构作为攻击面：联邦学习中的拓扑隐私泄露", "title_en": "Network Structures as an Attack Surface: Topology-Based Privacy Leakage in Federated Learning", "authors": "Murtaza Rangwala,Richard O. Sinnott,Rajkumar Buyya", "background": "联邦学习系统越来越多地依赖于多样化的网络拓扑结构来解决可扩展性和组织约束问题。尽管现有的隐私研究集中在梯度攻击上，但网络拓扑知识的隐私影响仍然研究不足。本研究首次对实际对抗知识场景下的拓扑隐私泄露进行了全面分析，展示了即使在强差分隐私保障条件下，具有不同程度结构知识的攻击者仍能推断出敏感数据分布模式。通过对4,720个攻击实例的系统性评估，分析了六种不同的对抗知识场景，包括完全拓扑知识和五个反映实际部署约束的部分知识配置。", "innovation": "研究发现了部分知识配置中有80%的现实攻击场景保持了高于安全阈值的有效性，并提出了结构噪声注入作为防御机制的调整方案，证明了当与现有的隐私技术相结合使用时，可以进一步降低51.4%的攻击成功率。研究结果表明，网络拓扑是联邦学习系统中的基本隐私漏洞，并提供了通过拓扑意识防御机制进行缓解的实际路径。", "conclusion": "研究结果表明，网络拓扑结构代表了联邦学习系统中的基本隐私风险，同时提供了通过拓扑意识防御机制进行缓解的实际路径。"}
{"llm_update_time": "2025-06-25 09:26:02", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19075", "html_url": "https://arxiv.org/abs/2506.19075", "title": "基于稀疏更新的先行算法在凸优化中的应用：改进的收敛率与运行时间", "title_en": "First-Order Sparse Convex Optimization: Better Rates with Sparse Updates", "authors": "Dan Garber", "background": "近期研究表明，对于具有稀疏最优解（可以是逐元素稀疏或矩阵秩稀疏）的凸优化问题，可能拥有依赖于改进的混合范数条件数的线性收敛率，形式为$\frac{\beta_1{}s}{\beta_2}$，其中$\beta_1$是梯度的$L_1$-Lipschitz连续常数，$\beta_2$是$L_2$-二次增长常数，$s$是最优解的稀疏度。然而，这些方法仅提供了改进的收敛率，但无法利用最优解的稀疏性来加快每次迭代的速度，对于高维问题而言，迭代时间可能仍然非常高昂。本研究基于此背景展开，探索在保持线性收敛率依赖于这种改进条件数的同时，如何仅通过稀疏更新提高执行时间的整体效率，从而实现显著的优化运行时间，并且方法的实现更为简单.", "innovation": "本工作提出了利用稀疏更新来实现依赖于改进条件数的线性收敛率，进而期望在保持高性能计算的同时提高运行效率，同时该方法的实现过程更为简便，降低了实际应用的难度.", "conclusion": "我们的方法通过稀疏更新，在保持依赖于改进条件数的线性收敛率的同时，实现了显著改善的运行时间，并且相对容易实现。"}
{"llm_update_time": "2025-06-25 09:26:06", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19270", "html_url": "https://arxiv.org/abs/2506.19270", "title": "连续变量量子扩散模型在状态生成与恢复中的应用", "title_en": "Continuous-variable Quantum Diffusion Model for State Generation and Restoration", "authors": "Haitao Huang,Chuangtao Chen,Qinglin Zhao", "background": "连续变量量子信息处理过程中，生成和保存复杂量子态以对抗环境噪声是关键挑战。现有技术无法有效解决这些问题，特别是在状态生成和恢复方面需要新的方法和技术来提高量子状态的质量和稳定性，尤其是在相干态等特定量子态的处理上遇到困难。", "innovation": "本文提出了一种基于连续变量量子扩散原理的新框架，该框架结合了连续变量量子神经网络（CVQNN）技术，分别实现了状态生成（CVQD-G）和状态恢复（CVQD-R）。CVQD-G模型通过耗热通道实现物理驱动的前向扩散过程，并通过可学习的参数高效反向去噪过程进行反转。CVQD-R模型专门设计用于从热退化中恢复量子态，特别是那些未知参数的相干态。该框架展示了在生成高保真度的各类（相干、挤压）高斯态和非高斯态（Fock、猫态）方面的强大能力，同时在复杂性分析中验证了其训练和推理成本的优越性，揭示了其高效性和可扩展性，以及在实际连续变量量子系统中作为稳健工具的潜力。", "conclusion": "通过广泛的数值模拟，CVQD-G和CVQD-R模型分别在多样态生成和特定态恢复上取得了高保真度，证实了模型的高效性和抗噪能力。该研究为量子态工程和真实量子系统中的噪声抑制提供了新的方法和技术。"}
{"llm_update_time": "2025-06-25 09:26:07", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19274", "html_url": "https://arxiv.org/abs/2506.19274", "title": "稳定PDE-ML耦合系统的策略", "title_en": "Stabilizing PDE--ML Coupled System", "authors": "Saad Qadeer,Panos Stinis,Hui Wan", "background": "长期以来，在使用机器学习代理模型解决大型偏微分方程（PDE）系统时，数值求解过程中遭遇的不稳定问题一直是一个难题。尽管已有关于提高代理模型精度或嵌入额外结构的努力，但收效甚微。本文探讨了一个原型问题，旨在为更复杂的系统提供见解，并特别关注一种黏性Burgers'-ML系统，通过识别不稳定性的原因并提供稳定策略来处理耦合系统。作者还进一步探讨了基于Mori-Zwanzig公式的改进方法以提高稳定系统的精度.", "innovation": "本文的重点是通过探究黏性Burgers'-ML系统的不稳定性原因，提供针对性的稳定化策略，并探讨了基于Mori-Zwanzig公式的改进方法以提升系统准确性。这种系统稳定性方面的创新研究为解决复杂PDE系统的代理模型的数值不稳定问题提供了指导.", "conclusion": "本文通过对黏性Burgers'-ML系统的研究，识别并解决了其不稳定的根源，并提出了有效的稳定策略。同时，探讨了Mori-Zwanzig公式在提高系统准确性方面的应用，为处理更复杂PDE系统的数值问题提供了解决思路."}
{"llm_update_time": "2025-06-25 09:26:10", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19356", "html_url": "https://arxiv.org/abs/2506.19356", "title": "WebGuard++:利用多尺度卷积BERT融合HTML子图和双向对接进行可解释的恶意URL检测", "title_en": "WebGuard++:Interpretable Malicious URL Detection via Bidirectional Fusion of HTML Subgraphs and Multi-Scale Convolutional BERT", "authors": "Ye Tian,Zhang Yumin,Yifan Jia,Jianguo Sun,Yanbin Wang", "background": "URL+HTML特征融合对鲁棒检测恶意URL有前景，因攻击者在DOM结构中留下的痕迹仍然存在。然而，以前的工作存在四个关键缺陷：(1)不完整的URL建模，未能同时捕捉词汇模式和语义上下文；(2)HTML图稀疏性，威胁指示节点（如混淆的脚本）在良性内容中孤立，导致图聚合中的信号稀释；(3)单向分析，忽略URL-HTML特征双向交互；(4)不透明的决策，缺乏对恶意DOM组件的归因。", "innovation": "WebGuard++提出了一种检测框架，包括4个新颖组件：1)层次URL编码器：基于Transformer网络和动态卷积学习局部到全局，粗到细的URL特征；2)子图感知的HTML编码器：将DOM图分解为可解释的子结构，通过分层特征融合放大稀疏威胁信号；3)双向耦合模块：通过跨模态对比学习对齐URL和HTML嵌入，优化跨模态一致性并内模具体性；4)投票模块：通过恶意子图预测的共识投票定位恶意区域。实验结果显示，WebGuard++在固定的不同FPR（0.001和0.0001）下，TPR大幅提升2到7.9倍，优于现有基线。", "conclusion": "实验表明WebGuard++在两个数据集上相对于最先进的基线实现了显著的性能提升，在固定不同FPR（0.001和0.0001）时TPR提升了2到7.9倍。"}
{"llm_update_time": "2025-06-25 09:26:11", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19387", "html_url": "https://arxiv.org/abs/2506.19387", "title": "NAADA: 一种用于牙科全景放射影像的噪声感知注意力去噪自编码器", "title_en": "NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs", "authors": "Khuram Naveed,Bruna Neves de Freitas,Ruben Pauwels", "background": "卷积去噪自编码器（DAEs）是图像恢复的强大工具，但它们继承了卷积神经网络（CNNs）的关键缺陷：它们倾向于比高频细节更有效地恢复低频特征。这导致了细节的丧失，特别是在牙科放射影像中，保持微妙的解剖结构至关重要。虽然自我注意力机制可以通过强调重要特征来缓解此问题，但传统注意力方法常常优先处理更清洁区域的特征，而可能忽略了被噪声遮盖的那些特征。", "innovation": "本文提出了一种噪声感知自注意力方法，使模型能够更有效地聚焦于并恢复即使在噪音区域中的关键特征。在此基础上，我们引入了一种噪声感知注意力增强去噪自编码器（NAADA）网络，用于增强牙科全景放射影。相比Uformer和MResDNN等最新的更重的方法，本方法提高了精细细节的重建，从而确保了更好的图像质量和诊断准确性。", "conclusion": "通过NAADA网络，实现了对噪声区域中关键特征的有效聚焦和恢复，从而提高了图像质量和诊断准确性，与现有的先进技术相比，本方法在处理细节方面表现更佳。"}
{"llm_update_time": "2025-06-25 09:26:12", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19340", "html_url": "https://arxiv.org/abs/2506.19340", "title": "CAM-NET：带热层和电离层扩展的全域大气AI模型", "title_en": "CAM-NET: An AI Model for Whole Atmosphere with Thermosphere and Ionosphere Extension", "authors": "Jiahui Hu,Wenjun Dong", "background": "准确地模拟整个大气对于理解重力波的向上传播至关重要，这种传播影响高层大气动力学和大气层之间的耦合。传统的地球大气模型在理解这些现象时，准确性低且计算效率低下。因此，研究一种能够在保证高精度的同时提高计算效率的模型是必要的。Spherical Fourier Neural Operator (SFNO) 被用来捕捉全球规模的大气动力学，同时保留地球的球形结构。WACCM-X 提供了广泛的数据集，用于训练这种新型模型，以实现更高精度和更快的推理速度。", "innovation": "CAM-NET 使用 Spherical Fourier Neural Operator (SFNO) 来捕捉全球规模的大气动力学，同时保留地球的球形结构。该模型基于 WACCM-X 数据集进行了训练，显示出与 WACCM-X 相当的准确性，但在推理时间上实现了超过一千倍的加速。CAM-NET 采用模块化结构，区分核心动态和追踪变量的预测，使得模型能够在不重新训练整个模型的情况下对特定追踪场景进行高效适配。", "conclusion": "CAM-NET 能够有效地预测关键大气参数，包括经向和纬向风、温度和气压的时间速率。它还可以提供一个完整的地球大气层模拟，训练完成后仅需几分钟即可生成一年的模拟数据。这种方法已经通过 $O^2$ 踪迹验证了其性能和普适性。"}
{"llm_update_time": "2025-06-25 09:26:13", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19276", "html_url": "https://arxiv.org/abs/2506.19276", "title": "非对称二进感知器中的稀有密集解簇 -- 全提升随机对偶理论视角下的局部熵", "title_en": "Rare dense solutions clusters in asymmetric binary perceptrons -- local entropy via fully lifted RDT", "authors": "Mihailo Stojnic", "background": "本文研究了经典非对称二进感知器（ABP）和相关局部熵（LE）作为其算法难解性潜在来源的问题。尽管在SAT相中似乎隔离了典型的ABP解，显示出普遍的算法难解性，但在接近但不完全到达容量的约束密度α附近仍存在高效的算法，这引发了悖论。最近的研究认为罕见的大密度簇和快速算法的神奇能力作为这个悖论的概念解决方案。关于这类异常簇的局部熵（LE）的单调性或破裂被认为是它们稀疏化或完全解构的关键因素。通过全提升随机对偶理论（fl RDT）和随后的sfl LD RDT，能够研究典型特征和异常特征。利用这些理论，本文开发了一个通用框架来研究ABP的LE作为一个异常特征。在第一次提升之后，发现LE的结果与复制方法得到的结果紧密匹配，对于经典零阈值ABP，在α（0.77, 0.78）区间LE表现出不稳定的特征，这一变化范围与当前最佳ABP求解器能处理的区间（大约0.75-0.77）相符，从而暗示LE行为可能是ABP计算缺口存在的关键反映之一。", "innovation": "本文利用全提升随机对偶理论（fl RDT）和随后的sfl LD RDT，研发了一个通用框架来研究非对称二进感知器的局部熵（LE）作为其异常特征。研究发现，在ABP的第一级提升之后，LE的结果与复制方法得到的结果高度一致，并且对于经典零阈值ABP，在α（0.77, 0.78）区间，LE结果开始表现出不稳定的特征，这与当前最佳ABP求解器能处理的区间相符，进而表明LE的行为可能是ABP计算缺口存在的关键反映之一。", "conclusion": "本文通过全提升随机对偶理论（fl RDT）和sfl LD RDT展示了对于ABP的局部熵（LE）的稳定与变化特征进行研究，发现并验证了在经典零阈值ABP中，局部熵的不稳定性区间与最佳ABP求解器处理区间基本匹配，这一发现为ABP计算缺口的可能存在提供了额外证据，说明局部熵的行为可能是理解ABP难解性的关键之一。"}
{"llm_update_time": "2025-06-25 09:26:15", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19262", "html_url": "https://arxiv.org/abs/2506.19262", "title": "LLM-生成数据中的关键因素：多样性及其对模型微调的影响", "title_en": "What Matters in LLM-generated Data: Diversity and Its Effect on Model Fine-Tuning", "authors": "Yuchang Zhu,Zhonghua zhen,Qunshu Lin,Haotong Wei,Xiaolong Sun,Zixuan Yu,Minghao Liu,Zibin Zheng,Liang Chen", "background": "随着大型语言模型（LLMs）生成能力的显著提升，使用LLM生成的数据来训练下游模型已成为解决特定领域数据稀缺性和减少标注耗时的一种有前景的方法。然而，最近的研究揭示了一个关键问题：在自生成数据上进行迭代训练会导致模型崩溃，即模型性能随时间减弱。尽管关于LLM生成数据的影响已经进行了大量研究，但这些研究往往忽略了数据多样性的关键作用，而数据多样性是数据质量的一个重要因素。", "innovation": "本工作旨在探索LLM生成数据多样性对下游模型性能的影响，具体研究不同水平的多样性如何影响下游模型性能。同时，还探究了使用不同比例LLM生成数据混编的数据进行训练的模型性能，我们将这种数据称为合成数据。实验结果表明，虽然数据分布变化最小，适度多样化的LLM生成数据能在数据不足的情况下提高模型性能，而高度多样化的生成数据则会产生负面影响。", "conclusion": "本研究表明，在少量标注数据的情况下，适度多样化的LLM生成数据能够提升模型性能，而高度多样化的生成数据则可能对模型性能产生负面影响。我们希望实验证据能为未来关于LLM作为数据生成器的研究提供指导。"}
{"llm_update_time": "2025-06-25 09:26:16", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19465", "html_url": "https://arxiv.org/abs/2506.19465", "title": "改进神经网络预训练的风格化结构模式", "title_en": "Stylized Structural Patterns for Improved Neural Network Pre-training", "authors": "Farnood Salehi,Vandit Sharma,Amirhossein Askari Farsangi,Tunç Ozan Aydın", "background": "现代计算机视觉中的深度学习模型需要大量的真实图像数据集，但获取这些数据集具有挑战性，且存在隐私和法律问题，这限制了它们的商业应用。最近的工作表明，合成数据可以作为替代方案，但用合成数据训练的模型往往表现不佳。", "innovation": "本文提出了一种两步方法来解决这个问题。首先，通过改进神经分形公式来引入一种新的合成数据类别；其次，提出了一种反向风格化技术，将来自少量无版权真实图像的视觉特征转移到合成数据集上，提高其有效性。通过Kernel Inception Distance (KID)分析了我们的合成数据集和真实图像之间的领域差距，并证明我们的方法在分布差距上显著优于现有合成数据集。此外，实验结果表明减少差距对不同任务具有实际影响。", "conclusion": "我们的研究工作为在足够大的真实训练集不可用时训练实际模型开辟了新的可能性。将EDM2扩散模型预训练在我们的合成数据集上的结果表明，生成图像的FID降低了11%，自编码器重构误差降低了20%，表明数据表示性能有所提高。对于分类任务，训练在该合成数据上的ViT-S模型在ImageNet-100上的准确率提高了超过10%。"}
{"llm_update_time": "2025-06-25 09:26:22", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19451", "html_url": "https://arxiv.org/abs/2506.19451", "title": "通过前瞻搜索进行低复杂度语义分组以优化令牌通信", "title_en": "Low-Complexity Semantic Packet Aggregation for Token Communication via Lookahead Search", "authors": "Seunghun Lee,Jihong Park,Jinho Choi,Hyuncheol Park", "background": "令牌是生成人工智能（GenAI）和大型语言模型（LLMs）的基本处理单元，令牌通信（TC）对于远程AI生成内容（AIGC）和无线LLM应用至关重要。令牌间的依赖关系使得它们易受衰落信道的影响，单一令牌的丢失会严重改变原消息的语义。因此，本文旨在通过优化令牌分组来最大化在衰落信道下原始和接收令牌消息间的平均令牌相似性（ATS），以解决这一问题。由于令牌间的依赖关系，这个问题具有组合性质，其复杂度随着消息长度的增加呈指数增长。", "innovation": "提出了一种基于前瞻搜索的语义分组框架（SemPA-Look）。这种框架引入了剩余语义得分（RSS）作为消息层面ATS的令牌级别替代方法，可以在某些令牌分组丢失时保持强大的语义完整性。SemPA-Look采用了前瞻搜索启发式的算法，该算法在固定深度的情况下无替换地采样进程内令牌候选，而在固定宽度的情况下有替换地采样进程间令牌候选。这种方法实现了线性复杂度。实验结果表明，与全面搜索相比，SemPA-Look在降低计算复杂性（最高可达40倍）的同时，其ATS和LPIPS分数与全面搜索相似。与遗传算法（GA）等线性复杂度算法相比，SemPA-Look的复杂度低10倍，证明了其在远程AIGC和其他TC应用中的实用性。", "conclusion": "研究提出了SemPA-Look框架，通过前瞻搜索引擎理令牌分组，实现了在衰落信道下语义信息的高效传输。在远程AIGC任务实验中，SemPA-Look达到了高ATS和LPIPS分数，同时降低了3到40倍的计算复杂度，显示出其在实际应用场景中的高效与实用性。"}
{"llm_update_time": "2025-06-25 09:26:23", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19533", "html_url": "https://arxiv.org/abs/2506.19533", "title": "检测受恶意触发器影响的面部识别网络中的物理可实现触发器", "title_en": "Identifying Physically Realizable Triggers for Backdoored Face Recognition Networks", "authors": "Ankita Raj,Ambar Pal,Chetan Arora", "background": "恶意后门攻击会将隐藏功能嵌入深度神经网络，导致网络在接收到预设模式的触发时表现出异常行为。近期研究表明，面部识别系统可以被伪装成普通物品（如特定款式的眼镜）的触发器所激活。这种攻击对面部识别技术在高安全应用中的应用构成了严重威胁。目前缺乏有效的检测和识别方法来发现这些隐藏的触发器。", "innovation": "本研究提出了一种新的技术，旨在（1）检测面部识别网络是否被自然界中的物理可实现触发器所篡改，（2）在已知受攻击的网络中识别这些触发器。通过实验验证，该方法的准确性显著高于简单的暴力破解基线。", "conclusion": "研究展示了所提方法的有效性，识别触发器的准确率达到74%，而暴力破解基线的准确率只有56%。这种方法为防止和检测面部识别系统中的恶意后门攻击提供了新的途径。"}
{"llm_update_time": "2025-06-25 09:26:24", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19502", "html_url": "https://arxiv.org/abs/2506.19502", "title": "MATE：为无障碍应用提供动力的多代理翻译环境", "title_en": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications", "authors": "Aleksandr Algazinov,Matt Laing,Paul Laban", "background": "当前社会中，许多科技产品未能充分支持用户的所有需求，导致许多技术在无障碍领域表现不足。现有的多代理系统（MAS）由于基于封闭源的设计缺少定制化功能，因此无法为有需要的用户提供全面的帮助，导致残疾人士在试图与数字环境互动时会遇到不少障碍。此外，现有的多代理系统通常需要依赖云端服务来提供帮助，这可能会带来隐私和安全问题。", "innovation": "本文介绍了一种多模态无障碍多代理系统（MATE），该系统可以根据用户的需求进行模态转换，例如将图像转换为语音描述、将文本转换为语音等，从而帮助残疾人士更好地与数字环境互动。MATE支持多种类型模型（包括LLM API调用和自定义机器学习分类器），并且能够在本地运行，这有助于保护用户隐私并提高灵活性与兼容性。此外，该系统还引入了ModCon-Task-Identifier模型，能够从用户输入中准确提取出模态转换任务，经过测试，该模型在自定义数据集上表现出色，比其他LLM和统计模型更优。", "conclusion": "MATE多代理系统通过个性化的模态转换，可以广泛应用于多种领域，如医疗保健等，并能够成为不同用户群体的有用助手。该系统在本地运行的设计不仅能够保护用户数据的安全与隐私，还能够提高系统的响应速度与可靠性。ModCon-Task-Identifier模型的引入进一步提高了系统的智能化水平。系统的源代码和数据已公开，供进一步研究参考。"}
{"llm_update_time": "2025-06-25 09:26:25", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19513", "html_url": "https://arxiv.org/abs/2506.19513", "title": "大视觉语言模型中的基于证据冲突的视觉幻觉检测", "title_en": "Visual hallucination detection in large vision-language models via evidential conflict", "authors": "Tao Huang,Zhekun Liu,Rui Wang,Yang Zhang,Liping Jing", "background": "尽管大型视觉-语言模型在多模态能力方面表现出色，但在图像输入与文本输出之间常常存在不一致现象，称为视觉幻觉，这种现象对于许多安全关键的人工智能应用构成了重大风险。现有研究主要从感知角度评估视觉幻觉，却忽略了更依赖于复杂推理能力所导致的幻觉。因此，需要构建一个新的基准测试集和有效的检测方法来系统性地评估这些模型的感知和推理能力。研究发现，现有的视觉幻觉基准测试主要关注感知方面的幻觉，而忽视了推理能力引起的幻觉。新提出的PRE-HAL数据集能够全面评估视觉和推理能力。在此基础上，研究发现了视觉语言模型在关系推理任务中的更多漏洞，并提出了一种通过不确定性估计的新方法来检测视觉幻觉，该方法基于Dempster-Shafer理论。实验结果表明，新提出的DST方法优于五个基准不确定性指标，在三种视觉语言模型上的平均AUCRO值分别提高了4%、10%和7%。", "innovation": "论文提出了第一个基于不确定性估计的Dempster-Shafer理论（DST）的大型视觉语言模型视觉幻觉检测方法，用于高效地捕捉模型推理阶段高级特征中的冲突程度。通过使用简单的质量函数简化证据组合的计算复杂性。该方法特别适用于关系推理等更具挑战性的任务。实验表明，该方法优于现有基准不确定性度量并实现了显著的性能提升。同时，研究人员提出了一个新的评估基准PRE-HAL，它能够系统地评估感知和推理能力，特别是在关系推理方面发现了更多的视觉漏洞。", "conclusion": "本研究通过引入新的PRE-HAL数据集和基于不确定性估计的Dempster-Shafer理论（DST）的视觉幻觉检测方法，提高了大型视觉语言模型在视觉幻觉检测上的准确性和可靠性，为后续的安全关键应用提供了更全面的保障。"}
{"llm_update_time": "2025-06-25 09:26:26", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19549", "html_url": "https://arxiv.org/abs/2506.19549", "title": "RCStat：Transformer中使用相对语境化的统计框架", "title_en": "RCStat: A Statistical Framework for using Relative Contextualization in Transformers", "authors": "Debabrata Mahapatra,Shubham Agarwal,Apoorv Saxena,Subrata Mitra", "background": "先前关于自回归变换器中输入令牌重要性的研究主要依赖于经过Softmax归一化的注意力权重，这掩盖了预先Softmax查询键张量的更丰富结构。为此，本文引入了RCStat框架，该框架利用了相对语境化（RC）这一随机变量来衡量令牌片段之间的语境对齐情况，并推导了RC的有效上界。此外，该框架展示了两个应用方向：一是键值压缩，在这个应用场景中，基于RC的阈值驱动自适应键值逐出机制能够实现显著的缓存减少，同时保留较低的质量损失；二是归因分析，在这个场景中，RC提供了比后Softmax方法更高保真的令牌级、句子级和块级解释。", "innovation": "本文提出了RCStat框架，通过引入相对语境化（RC）这一随机变量，更好地利用了注意力张量的原始信息。通过推导RC的有效上界，RCStat展示了在键值压缩和归因分析中的两个应用，并且实现了在多个基准测试中的显著提升，如问题回答、总结和归因，而无需重新训练模型。", "conclusion": "RCStat框架在保持高质量的前提下实现了显著的压缩效果，并且在归因性能上超越了现有的后Softmax方法，特别是在多项基准测试中取得了领先的性能。"}
{"llm_update_time": "2025-06-25 09:26:27", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19500", "html_url": "https://arxiv.org/abs/2506.19500", "title": "NaviAgent：基于工具依赖图的分级规划以实现函数调用", "title_en": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling", "authors": "Yan Jiang,Hao Zhou,LiZhong GU,Ai Han,TianLong Li", "background": "现有的大规模语言模型（LLMs）依赖于静态知识和脆弱的工具调用，这极大地阻碍了复杂、异构工具链的协调，尤其是在大规模场景下。现有的方法通常采用刚性的单一路径执行，导致糟糕的错误恢复和指数增长的搜索空间。因此，需要一种新的架构来增强功能调用的鲁棒性，更好地处理复杂的工具链和不确定性。", "innovation": "论文提出了NaviAgent，这是一种基于图的分级规划架构，用于增强功能调用的鲁棒性。NaviAgent包括一个多路径决策器和一个图编码导航器。多路径决策器定义了一个四维决策空间，并能够连续感知环境状态，动态选择最优行动以涵盖所有工具调用场景。图编码导航器构建了一个工具依赖异构图（TDHG），节点嵌入显式地融合了API结构和历史调用行为，并且还集成了一个新颖的启发式搜索策略来指导决策器走向高效的工具链，即使面对未见过的工具组合也是如此。", "conclusion": "实验表明，NaviAgent在所有基础模型和任务复杂性上都实现了最高的任务成功率（TSR），在Qwen2.5-14B、Qwen2.5-32B和Deepseek-V3上的表现分别超过了平均基线（ReAct、ToolLLM、α-UMI）13.5%、16.4%和19.0%。NaviAgent的执行步骤通常与最有效基线的步骤数相差仅为一步，确保了高质量与高效率的良好平衡。此外，NaviAgent的图编码导航器显著提高了TSR，复杂任务上的提升幅度甚至超过9个点，体现了其在工具链协调中的关键作用。"}
{"llm_update_time": "2025-06-25 09:26:28", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19275", "html_url": "https://arxiv.org/abs/2506.19275", "title": "一种高效混合量子编码机制及其在量子机器学习中的应用", "title_en": "A Qubit-Efficient Hybrid Quantum Encoding Mechanism for Quantum Machine Learning", "authors": "Hevish Cowlessur,Tansu Alpcan,Chandra Thapa,Seyit Camtepe,Neel Kanth Kundu", "background": "量子机器学习（QML）在利用量子计算优势处理数据方面具有巨大潜力，但高维数据集的有效嵌入至噪声存在和低量子比特量子系统仍是一个重大障碍。当前的量子嵌入方法，如量子自编码器，可能会受到当前硬件能力的限制和重建攻击的威胁，因为它们具有可逆性。因此，需要一种新的、非可逆的方法来进行降维和量子比特高效编码。量子主几何分析（qPGA）正是为了解决这一问题而提出的，该方法利用黎曼几何在单位希尔伯特球上投影数据，生成适用于量子振幅编码的输出。这种技术在紧凑的潜在空间中保留了高维数据集的局部结构，显著减少了振幅编码所需的量子比特数量。", "innovation": "提出了一种新颖的、非可逆的方法——量子主几何分析（qPGA），用于降维和量子比特高效编码。qPGA利用黎曼几何在单位希尔伯特球上投影数据，并生成自然适配量子振幅编码的输出。该方法保留了高维数据集在紧凑潜在空间中的局部结构，显著减少了所需的量子比特数量。此外，qPGA 的非可逆性质使其能够增强对重建攻击的抗性，并在量子依赖基准模型中表现出更优的性能。实验结果表明，qPGA 在 MNIST 和 Fashion-MNIST 下游 QML 分类任务中可以达到超过 99% 的准确度和 F1 分数，明显优于量子和混合自编码器。同时，qPGA 在真实硬件和噪声模拟器上的初步测试也证实了其抗噪性能，为推进量子机器学习应用提供了可扩展的解决方案。", "conclusion": "量子主几何分析（qPGA）提供了一种潜在高效的、非可逆的降维和编码方法，能够显著减轻量子比特需求，并增强对抗重建攻击的能力。qPGA 在实际和模拟环境中都展示出可扩展且抗噪的潜在应用前景，有望促进量子机器学习技术的发展。"}
{"llm_update_time": "2025-06-25 09:26:31", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19552", "html_url": "https://arxiv.org/abs/2506.19552", "title": "通用方法可构建优秀的特定领域基础模型：基于胎儿超声成像的研究案例", "title_en": "General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound", "authors": "Jakob Ambsdorf,Asbjørn Munk,Sebastian Llambias,Anders Nymark Christensen,Kamil Mikolaj,Randall Balestriero,Martin Tolsgaard,Aasa Feragen,Mads Nielsen", "background": "研究人员面对大量未标记的医疗数据时，面临两个关键问题：是否应该尝试在这些医疗数据上预训练一个定制的基础模型，还是使用现有通用模型的知识进行迁移学习？若进行预训练，是否需要引入新的方法？为探究这些问题，作者通过案例研究来推进讨论，在大规模区域胎儿超声图像数据集（200万张图像）上训练了一个基础模型。通过选择在预训练领域具有广泛认可度的DINOv2方法进行预训练，实现了胎儿超声数据、不同国家的数据、分类、分割和少量样本任务上的最佳结果。作者还将结果与在自然图像、超声图像和监督基础模型上预训练的模型进行了比较。结果显示，完全可以用通用计算机视觉的方法训练具有特定医疗领域焦点的基础模型，而无需进行大量调整或超参数调优，即使使用了较小的模型在较少的数据上进行训练。这些结果表明，即使在计算资源受限的情况下，不应偏好对于特定领域基础模型开发的方法创新。", "innovation": "1. 选择了具有广泛应用认可度的DINOv2方法进行预训练。2. 实现了胎儿超声数据、不同国家的数据、分类、分割和少量样本任务上的最佳结果。3. 结果表明，预训练在自定义数据上的价值，且规模在自然图像预训练中的扩展并不适用于超声医学影像，证明了为特定医疗领域训练基础模型的可行性，不依赖于大量调整或超参数调优。", "conclusion": "研究者应避免在资源受限条件下开发特定领域基础模型时过度偏好方法创新，而应更多关注于利用已有且调整较少的计算机视觉方法构建这些基础模型。这一发现为在医疗领域应用通用模型提供了重要参考。"}
{"llm_update_time": "2025-06-25 09:26:32", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19579", "html_url": "https://arxiv.org/abs/2506.19579", "title": "真假难辨，机器人能分辨吗？评估基于场景的视觉语言模型在真实与3D打印物体上的表现", "title_en": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects", "authors": "Federico Tavella,Kathryn Mearns,Angelo Cangelosi", "background": "随着机器人场景理解越来越多地依赖于视觉语言模型（VLMs）生成环境的自然语言描述，本文通过对装有RGB摄像头的机械臂捕捉的桌面场景进行多视角图像采集，评估了几个生成场景描述的模型。研究对比了单一视角和多视角的描述策略，考察了模型在识别真实世界与3D打印物体上的表现差异。通过定量评估物体识别准确性、描述完整性和自然度来评价模型性能。", "innovation": "本文的研究重点在于评估视觉语言模型在机器人环境下对物体的识别能力，特别是模型在面对3D打印物与真实物的描述准确性比较上发现了VLMs在辨识常见物体上的优势，但也指出了其在新颖物体识别上的局限性。这种对比提供了基础模型在实际环境中部署的实用性见解，为实际应用场景中的机器人视觉理解做出了贡献。", "conclusion": "研究结果表明，视觉语言模型可以应用于机器人环境中识别常见物体，但难以泛化到新型代表。这为将基础模型部署于真实世界中的体态智能代理提供了实用建议。"}
{"llm_update_time": "2025-06-25 09:26:35", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19608", "html_url": "https://arxiv.org/abs/2506.19608", "title": "ChordPrompt: 调和跨模态提示协同作用以在CLIP中实现多域增量学习", "title_en": "ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP", "authors": "Zhiyuan Wang,Bokui Chen", "background": "持续学习(CL)允许预训练的视觉-语言模型在无需进行全面重新训练的情况下，有效地适应新的或之前被低估的数据分布，提升其适应性和效率。虽然像CLIP这样的视觉-语言模型表现出很大的潜力，但在增量学习场景中，它们难以保持跨领域的性能。现有的提示学习方法存在两大局限性：1) 他们主要集中在类别增量学习场景上，缺乏针对多域任务增量学习的具体策略；2) 大多数当前方法使用单一模态提示，忽视了跨模态信息交换的潜在好处。", "innovation": "该论文提出了ChordPrompt框架，该框架促进了视觉和文本提示之间的和谐互动，引入了跨模态提示以利用视觉和文本信息的互动。此外，ChordPrompt还采用域自适应文本提示，以选择适合在多个域中持续适应的提示。", "conclusion": "在多域增量学习基准上的全面实验表明，ChordPrompt在零样本泛化和下游任务性能上均优于最先进的方法。"}
{"llm_update_time": "2025-06-25 09:26:37", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19683", "html_url": "https://arxiv.org/abs/2506.19683", "title": "超声图像解释和扫描指导的语义场景图", "title_en": "Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance", "authors": "Xuesong Li,Dianye Huang,Yameng Zhang,Nassir Navab,Zhongliang Jiang", "background": "理解医学超声成像仍是一个长期存在的挑战，因为不同成像和采集参数引起了显著的视觉变化。尽管大型语言模型（LLMs）的进步已经被用于自动生成面向临床医生的术语丰富总结，并且足以具备生理知识，但非专家用户（如在逐点护理环境中）对改善超声成像可解释性和基本扫描指导的需求尚未被探索。", "innovation": "引入了超声图像的场景图（SG）来解释图像内容并为普通用户提供扫描指导。通过基于变压器的一阶段方法首先计算超声SG，避免了显式的对象检测。随后利用用户查询进一步基于LLMs细化抽象的SG表示，生成普通用户可以理解的图像解释。探索预测的SG在指导当前成像视图中缺失的解剖结构方面的作用，帮助普通用户实现更标准化和完整的解剖探索。", "conclusion": "该SG基的图像解释和扫描指导方法已在不同志愿者的颈部左侧和右侧（包括颈动脉和甲状腺）的超声图像上得到了验证，结果表明该方法有助于最大程度地普及超声，提高其对普通用户的可解释性和可用性。"}
{"llm_update_time": "2025-06-25 09:26:38", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19280", "html_url": "https://arxiv.org/abs/2506.19280", "title": "在用户面向的App界面中通过机器学习进行情绪检测以增强时间表优化", "title_en": "Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach", "authors": "Feiting Yang,Antoine Moevus,Steve Lévesque", "background": "人机交互（HCI）已演化出情绪识别能力，创造了前所未有的机会，使用户体验成为适应性与个性化的内容。本文探讨将情绪检测集成到日历应用中，通过检测用户的情感状态和压力水平，从而提高生产力和参与度。研究采用生物特征方法和行为方法来实现情绪检测，并使用实际数据集进行对比分析，发现行为方法在鼠标的交互方面更加一致准确。", "innovation": "文章提出并评估了两种情绪检测方法的集成：一种是基于生物特征的方法，利用心率（HR）数据，从心电图（ECG）信号中提取并使用长短期记忆（LSTM）和门控循环单位（GRU）神经网络预测情绪维度的情感；另一种是基于行为的方法，通过多种机器学习模型分析计算机活动，根据细粒度的用户互动（如鼠标移动、点击和键入模式）来分类情绪。GRU 比 LSTM 在基于生物特征的方法中表现更好，特别是在情绪维度 Valence 的预测中达到 84.38% 的准确率。", "conclusion": "比较分析表明，两种方法都具有有效性，行为方法在鼠标相关交互方面表现出更高的准确性和一致性。GRU 模型在基于生物特征的情绪检测方法中表现更出色。这些发现为未来在多样化设备上增强用户体验的研究奠定了基础。"}
{"llm_update_time": "2025-06-25 09:26:38", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19591", "html_url": "https://arxiv.org/abs/2506.19591", "title": "基于Vision Transformer的时间序列图像重建方法在云填充应用中的研究", "title_en": "Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications", "authors": "Lujun Li,Yiqun Wang,Radu State", "background": "多光谱影像（MSI）中的云影在早期作物mapping任务中带来了巨大挑战，因为它们导致了缺失或损坏的光谱信息。尽管合成孔径雷达（SAR）数据不受云影干扰，但它缺乏足够的光谱细节，不能为精确的作物mapping提供支持。目前，传统的解决方法在云覆盖区域的MSI数据重建表现不佳，无法有效填补由云影造成的缺失信息，也不能充分利用MSI的时间连续性与时域的SAR互补信息。", "innovation": "本文提出了一种创新的时间序列MSI影像重建框架，Time-series MSI Image Reconstruction using Vision Transformer (ViT)，该框架能够通过利用MSI的时间相干性和SAR的补充信息来实现云覆盖区域的MSI数据重建。这种方法在多个严格的重建评价指标下体现出了显著优越性，优于使用非时间序列MSI和SAR或者仅使用时间序列MSI而没有SAR的传统方法，能有效增强云覆盖区域MSI影像的重建效果。", "conclusion": "实验证明，Time-series ViT框架在云覆盖区域MSI数据重建方面表现优异，大幅度提升了MSI影像的质量和可用性，对于早期作物mapping等应用具有重要价值。"}
{"llm_update_time": "2025-06-25 09:26:39", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19628", "html_url": "https://arxiv.org/abs/2506.19628", "title": "Operator Forces For Coarse-Grained Molecular Dynamics", "title_en": "Operator Forces For Coarse-Grained Molecular Dynamics", "authors": "Leon Klein,Atharva Kelkar,Aleksander Durumeric,Yaoyi Chen,Frank Noé", "background": "粗粒化（CG）分子动力学模拟通过用CG珠代替相关原子组来扩展原子模拟的时间和空间尺度。机器学习的粗粒化（MLCG）已在构建高精度的CG力场方面显示出前景，但MLCG力场的校准通常依赖于力匹配，这需要广泛的参考原子动力学轨迹及其对应的力标签。然而，由于在实际中常常不会记录原子力，因此传统的力匹配在现有数据集上是不可行的。最近，基于噪声的核函数被引入以适应低数据环境，这意味着没有参考原子力的情况下也能进行力匹配。然而，这种方法会导致局部结构扭曲，因为基于噪声的核函数具有破坏性影响。", "innovation": "本文引入基于正则化流动（normalizing flows）的更通用核函数，这些核函数大大减少了这些局部扭曲，同时保持了全局构象准确性。通过在小蛋白上的实验演示，作者展示了基于流动核的方法可以从构象样本生成高质量的CG力，而不需要参考原子力。", "conclusion": "通过基于流动核的方法，本文得到了高保真的CG力场，这一方法仅依赖构象样本生成，避免了低数据条件下的局部扭曲。"}
{"llm_update_time": "2025-06-25 09:26:40", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19651", "html_url": "https://arxiv.org/abs/2506.19651", "title": "PEVLM: 并行编码的 vision-language 模型", "title_en": "PEVLM: Parallel Encoding for Vision-Language Models", "authors": "Letian Kang,Shixian Luo,Yiqiang Li,Xiaoyang Yu,Shenxuan Zhou,Yong Wu", "background": "Vision-Language 模型在视频语言任务中表现出了强大的性能，但在长视频理解的应用上受到了标准注意力机制复杂度的限制。标准的关注机制会导致计算复杂度达到 $O((T \times N)^2)$，这限制了这些模型在长视频上的应用效率和实时性，尤其是在严格的时间约束下。", "innovation": "本文提出了 PEVLM，这是一种并行编码策略，旨在提高 vision-language 模型的预填充效率，而不需要模型微调。PEVLM 通过将输入分割成具有共享终点的块状段保留完整的注意力位置嵌入，并对注意力权重进行调整以模拟全注意力分布。这种设计将注意力计算从 $O((T \times N)^2)$ 降低到 $O(T \times N)$，同时保持了较高的准确性。", "conclusion": "在长视频基准 LongVideoBench 上进行的大量实验表明，与现有的高效推理方法相比，PEVLM 在准确性上提高了 8.37%，在注意力计算速度上提高了 7.47 倍，并减少了 40% 的端到端延迟。在严格的时间约束下，PEVLM 显著优于基线方法，将准确性从 23.26% 提高到 61.03%。这些结果突显了 PEVLM 在低延迟、长上下文视频理解的有效性，使其非常适合实际应用，如自动驾驶。"}
{"llm_update_time": "2025-06-25 09:26:40", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19661", "html_url": "https://arxiv.org/abs/2506.19661", "title": "高阶图数据库", "title_en": "Higher-Order Graph Databases", "authors": "Maciej Besta,Shriram Chandran,Jakub Cudak,Patrick Iff,Marcin Copik,Robert Gerstenberger,Tomasz Szydlo,Jürgen Müller,Torsten Hoefler", "background": "近年来，图数据库的发展激发了大规模分析的兴趣，但当前系统无法支持一跳以上的关系，这对于子图计数、多元模型和高阶图学习等任务至关重要。现有的图数据库无法满足这类需求，因此需要一种新的系统来解决这一问题，即高阶图数据库（HO-GDBs），它通过提升和降低范式，无缝扩展传统的图数据库以支持高阶关系操作。", "innovation": "提出了一种新的系统类型——高阶图数据库（HO-GDBs），利用提升和降低的范式，无缝扩展传统图数据库以支持高阶关系。此外，通过理论分析OLTP和OLAP查询确保了正确性、可伸缩性和ACID一致性。并实现了轻量级、模块化且可并行化的HO-GDB原型，该原型支持超图、节点元组、子图等高阶结构。该原型能够处理大规模的高阶伸缩查询，并通过提高图神经网络的准确性等方法展示了高阶图数据如何改进分析任务的表现。", "conclusion": "该工作确保了低延迟和高查询吞吐量，实现在ACID一致性和最终一致性的系统中都具有广泛应用。并且，高阶图数据库在提高分析任务准确性方面的表现尤其突出，例如在图数据库内通过高阶图数据提升了图神经网络的准确性高达44%。"}
{"llm_update_time": "2025-06-25 09:26:42", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19714", "html_url": "https://arxiv.org/abs/2506.19714", "title": "保守的量子离线模型导向优化", "title_en": "Conservative quantum offline model-based optimization", "authors": "Kristian Sotirov,Annie E. Paine,Savvas Varsamopoulos,Antonio A. Gentile,Osvaldo Simeone", "background": "离线模型导向优化（MBO）是指使用固定的输入输出数据集来优化一个黑盒目标函数，而无需进行主动实验。最近的工作引入了量子极限学习（QEL），通过少的数据点训练可变量子电路来学习准确的替代函数。然而，如经典机器学习文献中广泛研究的那样，预测模型在未探索区域可能错误地外推目标值，导致选择过于乐观的解决方案。因此，需要一种技术来防止这种误操作。", "innovation": "本文提出将保守目标模型（COM）——一种正则化技术，旨在确保对未见过的数据进行谨慎预测——与QEL相结合，形成混合算法COM-QEL。该算法利用量子神经网络的强大表现力，并通过保守建模来保障泛化能力。基准优化任务的实验结果表明，与原始QEL相比，COM-QEL更可靠地找到了具有更高真实目标值的解决方案，证明了其在离线设计问题中的优越性。", "conclusion": "COM-QEL混合算法通过结合QEL和COM，能够在保持QEL强大表现力的同时，防止模型在未探索区域的误外推，从而找到更高真实目标值的解决方案，适用于离线设计问题。"}
{"llm_update_time": "2025-06-25 09:26:46", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19767", "html_url": "https://arxiv.org/abs/2506.19767", "title": "SRFT: 结合监督和强化微调的一种单阶段方法以进行推理", "title_en": "SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning", "authors": "Yuqian Fu,Tinghong Chen,Jiajun Chai,Xihuai Wang,Songjun Tu,Guojun Yin,Wei Lin,Qichao Zhang,Yuanheng Zhu,Dongbin Zhao", "background": "大型语言模型（LLMs）在推理任务中取得了显著进展，但监督微调（SFT）和强化学习（RL）的最优整合仍然是一个基本挑战。通过从熵角度分析令牌分布、学习动态和整合机制，研究揭示了这两种范式的关键差异：SFT 引起粗粒度的全局变化，而 RL 则进行细粒度的选择性优化，熵是训练效果的重要指标。现有的解决方法大多采用两阶段的顺序方法，存在改进空间。", "innovation": "提出了监督强化微调（SRFT），这是一种单阶段方法，通过熵感知加权机制统合了这两种微调范式。SRFT 同时应用 SFT 和 RL，使用示范和自我探索的卷积直接优化 LLM，而不是通过两阶段顺序方法。实验结果显示 SRFT 在五种数学推理基准测试中的平均准确率达 59.1%，相比零 RL 方法在五种数学推理基准测试中的表现提高了 9.0%，在三种不同分布基准测试中的表现提高了 10.9%。", "conclusion": "SRFT 方法在单一阶段内同时结合了监督微调和强化学习，优化 LLM 的策略，取得了显著的性能提升，展现了该方法的有效性和优越性。"}
{"llm_update_time": "2025-06-25 09:26:46", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19759", "html_url": "https://arxiv.org/abs/2506.19759", "title": "消费者行为的形状：时间序列的符号和拓扑分析", "title_en": "The Shape of Consumer Behavior: A Symbolic and Topological Analysis of Time Series", "authors": "Pola Bereta,Ioannis Diamantis", "background": "理解在线搜索行为中的时间模式对于实时营销和趋势预测至关重要。尽管谷歌趋势提供了丰富的代理指标，但其时间序列数据的高维和噪音使得有效的聚类变得困难。本文研究了三种无监督聚类方法：符号聚合近似法（SAX）、增强的SAX（eSAX）和拓扑数据分析（TDA），应用于代表主要消费者类别的20个谷歌趋势关键词。虽然SAX和eSAX提供了快速且可解释的聚类，但它们在处理波动性和复杂性方面表现不佳，经常会生成模糊的“广泛类别”聚类。相比之下，TDA通过持久同调捕捉全局结构特征，实现了更平衡和有意义的分组。研究表明，利用符号和拓扑方法进行消费者分析具有很强的潜在应用价值。", "innovation": "本文创新性地评估了三种无监督聚类方法（SAX、eSAX、TDA）在谷歌趋势关键词上的应用，展示了TDA比SAX和eSAX更适用于处理波动性和复杂性的时间序列数据。提出了将符号和拓扑方法相结合的混合方法在未来应用中的潜力。", "conclusion": "本文的结论是，利用符号和拓扑方法进行消费者分析具有很强的应用价值。未来的研究建议探索这两种视角的混合方法，以进一步提高聚类质量和分析效果。"}
{"llm_update_time": "2025-06-25 09:26:48", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19834", "html_url": "https://arxiv.org/abs/2506.19834", "title": "使用线性偏置的标准变换器和注意力用于分子构象生成", "title_en": "A standard transformer and attention with linear biases for molecular conformer generation", "authors": "Viatcheslav Gurev,Timothy Rumbell", "background": "在药物发现和优化过程中，通过2D分子图生成低能量分子构象是许多关键计算任务的基础。虽然设计了许多专门的不变网络来生成分子构象，但最近的非不变式变体模型因其调节一般化的潜力而开始被考虑。然而，人们担心需要更大的模型来弥补非不变偏差。为了提高模型效率，文章提出使用有效的相对位置编码来解决这两个问题.", "innovation": "文章提出了一种使用相对位置编码的标准变压器模型，该模型通过线性增加图形节点之间最短路径距离来降低注意力偏置。在扩展到2500万个参数时，该模型超过了一个使用6400万个参数的当前最先进的非不变基模型，在GEOM-DRUGS基准测试中表现更为出色。这种方法为一种新型分子构象生成的生成模型奠定了基础.", "conclusion": "这种架构为分子构象生成提供了一个有潜力的基础，能够有效解决非不变模型的大小限制问题。"}
{"llm_update_time": "2025-06-25 09:26:48", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19789", "html_url": "https://arxiv.org/abs/2506.19789", "title": "机器学习算法在预测违约概率方面的比较研究", "title_en": "A comparative analysis of machine learning algorithms for predicting probabilities of default", "authors": "Adrian Iulian Cristescu,Matteo Giordano", "background": "预测潜在贷款的违约概率是金融机构的一项关键目标。近年来，机器学习算法在各种预测任务中取得了显著的成功；然而，在信用风险分析领域，它们的使用相对较少。本文通过比较五种预测模型（随机森林、决策树、XGBoost、梯度提升和AdaBoost）与常用的逻辑回归在Schule等人的基准数据集上的表现，突显了机器学习算法为该领域带来的机会，并强调了每种方法的优势和劣势，为贷款组合的违约概率预测提供了有价值的见解.", "innovation": "本文通过比较现有常用的预测模型和机器学习算法在信用风险分析中的应用表现，强调了机器学习算法在预测违约概率方面的重要潜力。这为金融机构提供了关于哪种机器学习算法在贷款组合的违约概率预测中最为有效的宝贵信息.", "conclusion": "研究结果展示了每种预测方法的优势和劣势，指出在贷款组合的违约概率预测领域，哪些机器学习算法最为有效。"}
{"llm_update_time": "2025-06-25 09:26:52", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "开源大语言模型在数据分析方面为何挣扎？系统性的经验研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Huajun Chen,Ningyu Zhang", "background": "开源大语言模型（LLMs）在自动化数据分析任务方面展现出潜力，但它们在这些需要大量推理的场景中面临显著限制。本文探讨了提升开源LLMs进行数据分析能力的策略。通过构建一个涵盖多样且现实的场景数据集，评估模型在数据理解、代码生成和战略规划三方面的表现。研究揭示了一些关键发现，如战略规划质量是决定模型性能的主要因素，交互设计和任务复杂性对推理能力有显著影响，以及数据质量比多样性更显著地影响最优性能的实现。", "innovation": "本文通过实验研究，系统分析了开源LLMs在数据分析中遇到的挑战，并提出了数据合成方法，显著提高了开源LLMs的推理能力。主要创新点在于提供了一种方法来增强开源大语言模型的数据分析能力，特别是在战略规划和数据质量方面做出了改进。", "conclusion": "本文的研究揭示了开源LLMs在数据分析中的主要挑战，并提出了一种新的数据合成方法。通过这种方法，开源LLMs在数据分析任务中的表现有了显著提升，特别是在战略规划质量和数据质量方面表现更加优秀。"}
{"llm_update_time": "2025-06-25 09:26:53", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19807", "html_url": "https://arxiv.org/abs/2506.19807", "title": "KnowRL：探索基于知识的强化学习以确保表述准确性", "title_en": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality", "authors": "Baochang Ren,Shuofei Qiao,Wenhao Yu,Huajun Chen,Ningyu Zhang", "background": "大型语言模型（LLMs），尤其是慢思考模型，在推理过程中由于无法准确识别知识边界，经常表现出严重的幻想现象，输出错误的内容。虽然强化学习（RL）可以增强复杂的推理能力，但其结果导向的奖励机制往往缺乏对思考过程的实证监督，进一步加剧了幻觉问题。", "innovation": "为解决慢思考模型中的高幻觉问题，本文提出知识增强的强化学习方法（KnowRL）。KnowRL通过在RL训练过程中整合基于知识验证的事实性奖励，引导模型进行基于事实的慢思考，帮助它们识别自己的知识边界。这一 targeted 的事实输入使得模型能够学习和内化事实性的推理策略，从而直接奖励在推理步骤中遵循事实，形成一个更可靠的思想过程。", "conclusion": "实验结果表明，KnowRL在三个幻觉评估数据集和两个推理评估数据集上有效地减轻了慢思考模型的幻觉现象，同时保持了它们原有的强大推理能力。我们的代码可在这个链接获取：[https://...]"}
{"llm_update_time": "2025-06-25 09:26:55", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19820", "html_url": "https://arxiv.org/abs/2506.19820", "title": "ProxelGen: 生成3D密度的蛋白质", "title_en": "ProxelGen: Generating Proteins as 3D Densities", "authors": "Felix Faltings,Hannes Stark,Regina Barzilay,Tommi Jaakkola", "background": "当前蛋白质结构生成模型主要基于3D点云表示，而未充分利用3D密度表示。将蛋白质表示为体素化的密度或proxels（接近像素的概念，但在三维空间中），能够为蛋白质生成任务及其条件处理提供新的可能性和能力。", "innovation": "开发了名为ProxelGen的蛋白质结构生成模型，该模型基于3D密度表示而非传统的3D点云表示。ProxelGen采用基于3D CNN的变分自编码器（VAE）结合扩散模型生成编码为proxels的蛋白质。该模型相对于最先进的模型在新颖性和FID分数上表现出更高的性能，在设计能力方面达到了训练集的水平。ProxelGen通过标准的motif支架基准测试展示了其优势，并展示了基于3D密度生成方法可能带来的更灵活的形状条件处理能力。", "conclusion": "ProxelGen通过引入3D密度作为蛋白质的表示方法，在蛋白质生成模型中引入了新的任务和条件能力，并且在性能上超过了现有的技术水平。"}
{"llm_update_time": "2025-06-25 09:26:56", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19845", "html_url": "https://arxiv.org/abs/2506.19845", "title": "NAFNet基线模型在图像恢复中的比较研究", "title_en": "A Comparative Study of NAFNet Baselines for Image Restoration", "authors": "Vladislav Esaulov,M. Moein Esfahani", "background": "本文研究了NAFNet（非线性激活自由网络）作为图像恢复的简单且高效的深度学习基本模型。使用CIFAR10图像，并加入噪声和模糊，对NAFNet的核心组件进行了消融研究。基线模型采用了SimpleGate激活、简化通道激活（SCA）和层归一化（LayerNormalization）等组件。通过与去除或替换组件的不同变体进行对比，展示了每个修改对恢复性能的影响，从而支持NAFNet的设计理念：SimpleGate和简化的注意力机制优于传统激活和注意力机制，而层归一化对于稳定的训练非常重要。", "innovation": "通过消融研究展示了不同的组件对恢复性能的影响，证明了SimpleGate和简化的注意力机制优于传统激活和注意力机制，而层归一化对于模型的稳定训练至关重要。此外，文章还提供了PSNR和SSIM等定量结果和实际示例，说明了每个修改带来的影响，并给出模型设计建议，讨论了改进的潜在方向及未来工作内容。", "conclusion": "本文研究了NAFNet在图像恢复中的表现，并通过定量结果和示例展示了SimpleGate和简化注意力机制的好处，以及层归一化的重要性。最后，提出了模型设计建议，并探讨了未来工作的方向。"}
{"llm_update_time": "2025-06-25 09:26:58", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19836", "html_url": "https://arxiv.org/abs/2506.19836", "title": "机器学习中的隐私保护针对保护性属性", "title_en": "Machine Learning with Privacy for Protected Attributes", "authors": "Saeed Mahloujifar,Chuan Guo,G. Edward Suh,Kamalika Chaudhuri", "background": "差分隐私（DP）已成为私人数据分析的标准。某些机器学习应用只需要针对特定保护属性进行隐私保护。使用原始的差分隐私变体在这些用例中会导致必要的效用退化。本文重新定义了差分隐私，提出了一个更加通用和灵活的框架，称为特征差分隐私（FDP）。FDP采用模拟为基础的定义，允许添加/移除和替换两种隐私变体，并能处理私有和非私有特征之间的任意和适应性分离。通过证明FDP的属性（如适应性组合）以及展示其对限制属性推断攻击的影响来验证FDP的优势。该工作还提出了一种对标准DP-SGD算法的修改，使其同时满足FDP并利用如子采样放大等有益属性。", "innovation": "提出了特征差分隐私（FDP），这是一种更加通用和灵活的差分隐私定义，允许添加/移除和替换两种隐私变体，且能够处理私有和非私有特征之间的任意和适应性分离。给出了FDP的适应性组合的性质，并展示其如何限制属性推断攻击。提出了一个对标准DP-SGD算法的修改，使其同时满足FDP并在具有公共特征的情况下显著提高DP训练模型的效用。例如，在AFHQ动物面部数据集上使用模糊版本的训练图像作为公共特征进行扩散模型训练，当ε=8时，FID显著下降至101.9，相比于DP，下降了约63%。", "conclusion": "这项工作提供了一种新的隐私数据分析方法，不仅提供了强大的隐私保证，还在公共特征可用时减少了DP的成本。"}
{"llm_update_time": "2025-06-25 09:26:59", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.06213", "html_url": "https://arxiv.org/abs/2306.06213", "title": "一种用于多类分类的鲁棒Twin Parametric Margin Support Vector Machine", "title_en": "A Robust Twin Parametric Margin Support Vector Machine for Multiclass Classification", "authors": "Renato De Leone,Francesca Maggioni,Andrea Spinelli", "background": "本文介绍了一种新型的Twin Parametric Margin Support Vector Machine (TPMSVM) 模型，旨在解决在特征不确定性条件下进行多类别分类的任务。通过在每个训练观测点周围构建范数有界的不确定性集，使用鲁棒优化技术得出确定性模型的鲁棒对应模型。为了捕捉复杂的数据结构，模型探索了线性和核诱导分类器，并提供了鲁棒模型的计算有效重构。此外，还提出了一种用于最终决策函数的改进方法，增强了模型的灵活性。上述方法被应用于真实世界的数据集，验证了在存在不确定性的情况下该方法的有效性和鲁棒性。", "innovation": "提出了一种称为Twin Parametric Margin Support Vector Machine (TPMSVM) 的新模型，它能够处理特征不确定性。该模型使用鲁棒优化技术构建了不确定性集，并通过线性和核诱导分类器捕捉复杂数据结构，提供了模型的灵活决策函数。这一模型有效应对了具有不确定性的多类别分类问题。", "conclusion": "本文提出的方法在实际数据集上的验证结果表明，该方法在不确定性存在的情况下表现出良好的性能。"}
{"llm_update_time": "2025-06-25 09:27:01", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19837", "html_url": "https://arxiv.org/abs/2506.19837", "title": "Mean Shift算法对于大带宽的收敛及其同时精确聚类的结果", "title_en": "Convergence of Mean Shift Algorithms for Large Bandwidths and Simultaneous Accurate Clustering", "authors": "Susovan Pal,Praneeth Vepakomma", "background": "均值漂移（Mean Shift, MS）是非参数、基于密度、迭代的算法，在聚类和图像分割中有显著应用。虽然这个算法的全适应性收敛性证明仍不清楚，但已有一些重要进展。Gh1证明了对于足够大的带宽，MS算法在任何维度下总是收敛，使用的是高斯核。Gh2进一步证明了对于具有光滑、严格递减、凸分布的不同核函数，MS在任何维度下总能收敛。最近，YT证明了无带宽限制情况下的收敛性，条件是核密度估计$f$在迭代序列模态估计的凸包边界上具有连续的Lipschitz梯度，并且满足洛亚西维茨(Lojasiewicz)性质。", "innovation": "本文主要扩展了Gh1的结果，证明了对于足够大的带宽，在任何维度和任何具有径向对称且严格正定性核函数的情况下，MS算法总是收敛的。证明采用了两个关于径向对称正定光滑核的特征化，并借鉴了Gh1中的某些证明步骤。尽管与YT的结果相比，本文对带宽的要求较小，但由于假设的不同，证明方法也不同，因此更具灵活性和广泛性。", "conclusion": "本文证明了MS算法在任何足够大的带宽下，对于任何具有径向对称且严格正定性核函数的情况下，都能在任何维度下收敛。通过借鉴不同作者的工作和采用新的证明技巧，本文对MS算法的理论理解迈出了重要一步，并为进一步应用和改进此算法奠定了基础。"}
{"llm_update_time": "2025-06-25 09:27:01", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2308.05889", "html_url": "https://arxiv.org/abs/2308.05889", "title": "DF2: 无分布决策集中学习", "title_en": "DF2: Distribution-Free Decision-Focused Learning", "authors": "Lingkai Kong,Wenhao Mu,Jiaming Cui,Yuchen Zhuang,B. Aditya Prakash,Bo Dai,Chao Zhang", "background": "决策集中学习（DFL）通过KKT条件区分，已成为解决预测-优化问题的强大方法。然而，在概率设置下，DFL面临三大挑战：模型失配误差、样本平均近似误差和梯度近似误差。模型失配误差源于模型参数化预测分布与真实概率分布之间的不匹配。样本平均近似误差是由于使用有限样本近似期望优化目标。梯度近似误差发生在目标是非凸时，KKT条件不能直接应用。", "innovation": "本文提出了DF2，这是第一个设计用于缓解这三种挑战的无分布决策集中学习方法。DF2方法在训练期间直接学习期望优化函数，而不需要依赖于特定任务的需要精确模型假设的预测器。我们通过设计一个基于分布参数化的期望目标的注意力模型架构，使这个函数的有效学习在数据驱动的方式下变得高效。我们使用两个合成问题和三个现实世界问题评估了DF2，证明了DF2的有效性。", "conclusion": "DF2的成功实施突出了其在不需要特定任务假设的情况下缓解DFL挑战的能力，并通过实证研究证明了其在实际问题中的有效性。"}
{"llm_update_time": "2025-06-25 09:27:05", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.16316", "html_url": "https://arxiv.org/abs/2310.16316", "title": "Sum-of-Parts: 自包含神经网络中的端到端特征组学习", "title_en": "Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups", "authors": "Weiqiu You,Helen Qu,Marco Gatti,Bhuvnesh Jain,Eric Wong", "background": "自包含神经网络（SANNs）为解决高维度问题提供了潜在的可解释模型路径，但通常在性能上存在显著的权衡。正式证明了单特征SANNs的错误下界，而基于组的SANNs可以实现零错误，从而获得高性能。本文基于此洞察，提出了一种Sum-of-Parts（SOP）框架，将任何可微模型转换为基于组的SANN，特征组的划分通过端到端学习无监督完成。SOP在视觉和语言任务上取得了最先进的性能，并通过多种定量和语义指标验证了组的可解释性。此外，SOP解释在模型调试和宇宙学科学发现中展示了其实用性。", "innovation": "提出了一种Sum-of-Parts（SOP）框架，将任何可微模型转换为基于组的自包含神经网络，特征组的结构和划分通过端到端学习自动完成，无须额外的组标签。此方法显著提高了SANNs在各种任务上的性能，并通过多种评估指标验证了其可解释性。SOP框架不仅提升了模型的性能，还为模型的解释性提供了新的可能，甚至在复杂的科学领域如宇宙学中也能提供有价值的见解和挖掘发现的动力。", "conclusion": "Sum-of-Parts (SOP) 框架可以将任何可微模型自动转换为基于组的SANNs，特征组的划分与学习通过端到端无需额外监督的方式完成。SOP在视觉和语言任务上取得了当前最先进的性能，并通过多种评估方法验证了其具有良好的解释性。与此同时，该框架也证明了其在模型调试和科学发现中的实用性，提供了可解释性和实用性结合的新方法。"}
{"llm_update_time": "2025-06-25 09:27:05", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.14606", "html_url": "https://arxiv.org/abs/2403.14606", "title": "不同可微分编程的元素", "title_en": "The Elements of Differentiable Programming", "authors": "Mathieu Blondel,Vincent Roulet", "background": "近年来，人工智能经历了显著进步，这得益于大型模型、海量数据集、加速硬件以及可微编程改造的强大能力。新型编程范式使得复杂的计算机程序（包括控制流和数据结构）能够端到端地进行微分，从而使基于梯度的程序参数优化成为可能。可微编程源自计算机科学和应用数学的多个领域，包括自动微分、图形模型、优化和统计学。本书全面回顾了对于可微编程有用的基石概念。我们从优化和概率两个主要视角出发，并在两者之间找到了明确的类比关系。可微编程不仅仅是对程序进行微分，更重要的是设计可微分的程序。通过使程序可微，我们内在地引人程在执行中的概率分布，从而提供量度与程序输出相关的不确定性的方法。", "innovation": "可微编程的发展与计算机科学和应用数学多个领域的结合，尤其是自动微分、图形模型、优化和统计学。本书通过从优化和概率两个主要角度审视，提供了一个全新的编程范式，使得复杂的计算机程序能够端到端地进行微分，并基于梯度优化程序参数。", "conclusion": "可微编程不仅是对程序进行微分，还包括了设计可微分程序的思维过程，通过引入程序执行过程中的概率分布来量化程序输出的不确定性。"}
{"llm_update_time": "2025-06-25 09:27:07", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.03050", "html_url": "https://arxiv.org/abs/2404.03050", "title": "ANOVAbolstering for Random Fourier Features", "title_en": "ANOVA-boosting for Random Fourier Features", "authors": "Daniel Potts,Laura Weidensager", "background": "该研究针对高维函数的近似问题，指出现有的随机傅里叶特征模型在处理高维数据时存在近似误差较大的问题。为了解决这个问题，研究者们提出了两种算法，利用经典和广义的方差分析(ANOVA)分解来学习低阶函数。这种方法有助于识别重要的输入变量和变量间的相互作用，并显著降低了现有方法的近似误差。此外，还对现有的随机傅里叶特征模型进行了泛化，使其适用于ANOVA设置，在不同阶数的项中可以使用。", "innovation": "研究提出了一种针对随机傅里叶特征模型以提升其对高维函数近似能力的新方法。这种新方法结合了ANOVA分解技术，能够更有效地学习低阶函数，识别出关键的输入变量和变量交互。相比于现有的方法，新算法可以在存在依赖变量的情况下，依然保持模型的可解释性，且通过ANOVAbolstering步骤显著降低了近似误差。理论分析和数值结果显示，该算法在敏感性分析中表现良好，可以有效地提升随机傅里叶特征模型的性能。", "conclusion": "研究提出的方法能够在学习高维函数时显著降低误差，同时保持模型的可解释性，特别适用于存在变量交互的情况。通过证明和实验证实，这种方法在敏感性分析中有良好应用前景。"}
{"llm_update_time": "2025-06-25 09:27:10", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.01471", "html_url": "https://arxiv.org/abs/2403.01471", "title": "可调相关保留：一种生成合成数据的统计方法", "title_en": "Tunable correlation retention: A statistical method for generating synthetic data", "authors": "Nicklas Jävergård,Rainey Lyons,Adrian Muntean,Jonas Forsman", "background": "该研究旨在生成统计上具有代表性的合成数据，这些数据能够反映原始数据集中的特征之间的互相关关系，并且还能通过调节参数来影响数据的隐私水平。研究者们构建了一个基于原始数据集中特征的条件分布的统计图，并通过限定使用条件分布的深度来实现部分可调节性。该方法通过在三种测试数据集上的应用——手工计算的例子、制造的实验数据集以及马德拉岛家庭能源消费/生产的真实数据集——得到了验证。", "innovation": "该研究创新地提出了一种生成合成数据的方法，该方法通过利用原始数据集中的特征的条件分布来构建统计映射，并通过限制使用的条件分布的深度来提高数据生成过程的可调性。验证方式包括手工计算的例子、制造的实验数据集以及真实世界的数据集的真实性与隐私水平的对比分析，采用皮尔逊相关系数矩阵的不同分辨率和相关深度作为衡量标准。", "conclusion": "该研究提出的方法具有普遍性，不依赖于测试数据集，预期在更广泛的场景下也有应用潜力。通过调节相关性的保留度，该方法能够在数据的真实性和数据隐私之间找到一个平衡点，从而生成既具有实际意义又能够保护隐私的合成数据。"}
{"llm_update_time": "2025-06-25 09:27:10", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.17050", "html_url": "https://arxiv.org/abs/2405.17050", "title": "HeNCler：通过学习不对称相似性在异类图中进行节点聚类", "title_en": "HeNCler: Node Clustering in Heterophilous Graphs via Learned Asymmetric Similarity", "authors": "Sonny Achten,Zander Op de Beeck,Francesco Tonin,Volkan Cevher,Johan A. K. Suykens", "background": "传统的节点聚类方法假设有效的聚类特征在于高内聚低间聚的连接性，但在异类图中，这种假设不再适用。因此，在异类图中进行节点聚类具有挑战性。针对这一点，本文介绍了一种名为HeNCler的新颖方法，用于异类节点聚类，该方法通过基于加权核奇异值分解优化聚类特定的目标来学习相似性图，从而能够在不对称相似性图上进行谱聚类，适用于有向图和无向图。与传统的基于邻接矩阵分割的方法相比，本方法通过直接解决原始问题，克服了计算上的困难。实验结果表明，HeNCler在异类图中的节点聚类表现显著提升，突显了其不对称图学习框架的优势。", "innovation": "HeNCler 通过基于加权核奇异值分解优化聚类特定目标来学习相似性图，允许在不对称相似性图上进行谱聚类。通过对原始问题的直接求解，本文的方法克服了传统基于邻接矩阵分割的方法的计算困难。", "conclusion": "通过实验，HeNCler 在异类图中的节点聚类表现显著提升，表明其不对称图学习框架具有显著优势。"}
{"llm_update_time": "2025-06-25 09:27:11", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19852", "html_url": "https://arxiv.org/abs/2506.19852", "title": "径向注意力：具有能量衰减的 $O(n\text{log}n)$ 薄片注意力机制及其在长视频生成中的应用", "title_en": "Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for Long Video Generation", "authors": "Xingyang Li,Muyang Li,Tianle Cai,Haocheng Xi,Shuo Yang,Yujun Lin,Lvmin Zhang,Songlin Yang,Jinbo Hu,Kelly Peng,Maneesh Agrawala,Ion Stoica,Kurt Keutzer,Song Han", "background": "近年来，扩散模型在生成高质量视频方面取得了重大进展，但增加了时间维度导致计算成本显著增加，使得在长视频上进行训练和推理变得极其昂贵。研究表明，视频扩散模型中存在空间和时间距离越远注意力分数越低的现象，这一现象类似于自然界中的信号或波在空间和时间中衰减。受限于这一现象，本文提出了一种适用于长视频生成的径向注意力机制，这是一种具有 $O(n \text{log} n)$ 复杂度的可扩展稀疏注意力机制，将能量衰减转化为指数衰减的计算密度。这种方法比标准的 $O(n^2)$ 密集注意力更高效，且比线性注意力更具表现力。径向注意力采用了简单的静态注意力掩码，其中每个令牌仅关注空间上临近的令牌，并且随时间距离增加注意力窗口大小会缩小。此外，该机制可以利用预训练的视频扩散模型通过高效的方法调整参数以生成更长的视频，且在经过少量调优后能实现视频生成时间提高4倍的效果，并将训练成本降低4.4倍，比直接反向覆盖调整和密集注意力机制的推理速度分别提高了3.7倍和显著的速度优势.", "innovation": "本文提出了一种径向注意力机制，这是一种具有空间和时间距离自适应衰减特性的稀疏注意力机制，可以在长视频生成中有效减少计算成本。径向注意力主要是通过设计一种简单的静态注意力掩码实现的，其中每个令牌关注邻近的令牌，并且随着时间距离的增加，注意力窗口的大小会逐渐减小。此外，该机制还集成了通过低秩适配（LoRA）进行高效的微调的技术，能够显著提升生成速度，同时减少训练成本。相对标准的密集注意力机制和线性注意力机制，径向注意力机制在多种视频生成模型上都表现出了更高的效率和更好的效果，尤其是在长视频生成任务上，可以实现4倍左右的生成时间加速和高达1.9倍的速度提升，并显著降低训练成本。", "conclusion": "通过引入径向注意力机制，本文展示了如何在保持视频质量的同时，大幅提升长视频生成的效率和节省训练成本的新方法。具体来说，径向注意力机制不仅能在长视频生成中实现高达1.9倍的速度提升，而且还能够使视频生成长度增加4倍，并将训练成本降低4.4倍，同时还加速了推理阶段的速度。"}
{"llm_update_time": "2025-06-25 09:27:12", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.14642", "html_url": "https://arxiv.org/abs/2404.14642", "title": "图学习中的不确定性量化：一个综述", "title_en": "Uncertainty Quantification on Graph Learning: A Survey", "authors": "Chao Chen,Chenghua Guo,Rui Xu,Xiangwen Liao,Xi Zhang,Sihong Xie,Hui Xiong,Philip Yu", "background": "图形模型在社交网络、引文网络和在线推荐系统等多个应用中展示了其卓越的能力。然而，它们的表现、置信度和可信度经常受到数据内在随机性及正确模拟现实复杂性的挑战限制。因此，针对图模型开发出特定的不确定性量化（UQ）技术得到了广泛关注。这篇文章致力于总结和审视现有的图模型中的不确定性量化研究工作，重点关注不确定性来源、表示、处理和评估等方面。", "innovation": "本文的独特之处在于，它专门针对图模型中的不确定性量化进行综述，涵盖概率图模型（PGMs）和图神经网络（GNNs）。文章不仅回顾了不确定性来源，还按照不确定性表示和处理这两个高层次维度对研究工作进行了分类，为当前图模型不确定性量化领域的理解差距提供了全面的概述，包括已建立的方法和新兴趋势，旨在激发对不确定性量化和图模型研究感兴趣的学者在两个领域交叉处取得进一步的进展。", "conclusion": "通过提供图模型不确定性量化领域的全面概述，本研究旨在填补关于图模型不确定性量化关键挑战和机遇的理解空白，希望激发研究者在两个领域交叉处进一步取得进展。"}
{"llm_update_time": "2025-06-25 09:27:12", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.16804", "html_url": "https://arxiv.org/abs/2407.16804", "title": "心理健康的多模态机器学习：数据、算法与挑战的综述", "title_en": "Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges", "authors": "Zahraa Al Sahili,Ioannis Patras,Matthew Purver", "background": "近年来，多模态机器学习（MML）正迅速改变心理疾病检测、分类及纵向监控的方式。早期研究依赖单一数据流，如语音、文本或穿戴设备信号，而近期研究则转向集成多种异构模态的架构，以捕捉精神疾病的丰富复杂特征。本文综述了MML领域在心理健康中的最新进展，通过详述当前的能力和挑战，推动该领域的发展。", "innovation": "本文首次全面综述了MML在心理健康领域的应用。作者详细梳理了26个涵盖音频、视觉、生理信号和文本模态的开源数据集，并系统地对比了28种基于变换器、图和混合融合策略的模型。该文不仅总结了当前技术能力，还探讨了数据治理和隐私、人口统计和交叉公平性、评估解释性和心理疾病的复杂性等开放问题，指出跨模态表示学习和跨模态对齐的现有趋势。", "conclusion": "本文通过结合方法创新与精神健康实用性，旨在引导ML研究人员和精神健康专业人员向新一代值得信赖的多模态决策支持系统方向发展。"}
{"llm_update_time": "2025-06-25 09:27:17", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.17933", "html_url": "https://arxiv.org/abs/2410.17933", "title": "使用区块链增强联邦学习的多大洲医疗建模", "title_en": "Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning", "authors": "Rui Sun,Zhipeng Wang,Hengrui Zhang,Ming Jiang,Yizhe Wen,Jiahao Sun,Xinyu Qu,Kezhi Li", "background": "在医疗领域构建人工智能模型的一个主要挑战是数据共享问题。医疗数据是私有的、敏感的且多样化的，收集足够的数据进行建模既繁琐又昂贵，有时甚至是不可能的。为了解决这一问题，本文提出了一种框架，通过多大陆（欧洲、北美和亚洲）的数据集实现全球医疗建模，而无需共享本地数据集，并选择了血糖管理作为研究模型，以验证其有效性。背景数据缺乏带来的模型偏差问题也需要解决，增加额外数据可以减少偏见，提供跨大洲的医疗合作成为可能，以提升整体医疗服务质量。", "innovation": "本文提出了一个基于区块链技术的联邦学习框架，用于多大陆范围内的医疗建模。该框架通过适应的方式满足医疗数据的隐私和安全性要求，同时利用其链上激励机制奖励诚实行为并惩罚恶意行为。实验结果表明，所提出的框架是有效的，高效且保护隐私的，能够提供优于仅使用有限个人数据训练的模型的预测准确性，并在某些情况下可以达到甚至略优于集中式训练的效果。", "conclusion": "本研究的成功推动了国际医疗项目合作的可能，能够减少偏见、改善医疗服务质量。通过多大陆的合作，利用区块链增强的联邦学习技术可以提供更具代表性和准确性的模型，从而更好地服务于整个人类社会。"}
{"llm_update_time": "2025-06-25 09:27:18", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.14388", "html_url": "https://arxiv.org/abs/2410.14388", "title": "大规模解码疾病进程：基于最优传输的事件排列快速推断", "title_en": "Unscrambling disease progression at scale: fast inference of event permutations with optimal transport", "authors": "Peter A. Wijeratne,Daniel C. Alexander", "background": "疾病进程模型用于推断慢性退化过程中患者特征随时间变化的群体级时间轨迹。这些模型为理解疾病生物学提供了独特见解，并具有个体级的临床应用价值。然而，传统的最大似然方法在置换推断方面变得不可行，因为组合爆炸性严重限制了模型的维度和应用性。传统的离散模型将疾病进程视为潜在的事件置换，每项事件对应于一个特征变得可测量地异常。", "innovation": "本文利用最优传输的想法来建模疾病进程，将疾病进程视为属于Birkhoff多面体的潜在置换矩阵中的事件。这种方法通过优化变分下界来实现快速推断，相比于当前最先进的方法快了1000倍，从而支持比现有技术多几个数量级的特征数。实验表明，该方法在速度、准确性和噪声鲁棒性方面都有提升。进一步使用不同数据集中的真实世界成像数据，证明了该方法在大脑和眼睛中能够得到基于像素的疾病进展事件。该方法计算量低、可解释性强，并适用于任何渐进性条件和数据模态。", "conclusion": "本文提出的方法能够快速且准确地推断事件排列，适用于任何渐进性条件的数据，并且具有广泛的临床应用潜力。"}
{"llm_update_time": "2025-06-25 09:27:20", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.07467", "html_url": "https://arxiv.org/abs/2411.07467", "title": "机器与数学变异：使用图神经网络表征箭图变异类别", "title_en": "Machines and Mathematical Mutations: Using GNNs to Characterize Quiver Mutation Classes", "authors": "Jesse He,Helen Jenne,Herman Chau,Davis Brown,Mark Raugas,Sara Billey,Henry Kvinge", "background": "机器学习正逐渐成为数学领域中一个极其有价值的工具，能够帮助识别大量实例集合中的细微模式，这些集合庞大到单个研究员很难进行可行的审核和分析。在本研究中，我们利用图神经网络来探究箭图的‘变异’操作，即如何将一个箭图转换为另一个箭图的过程，这一操作在聚类代数理论中占据核心地位，与几何学、拓扑学和物理学有着深刻联系。在研究聚类代数时，决定两个箭图是否可以通过一序列的变异操作而等价是一个基本关注点，然而，这一问题的求解是具有挑战性的，尤其是在大规模实例集合中的应用。本研究正是基于此背景，利用图神经网络和AI可解释性技术来探索特定类型箭图的变异等价性判据，旨在借助该技术识别和理解结构中的微妙模式，并实现已知判据的重建，以验证现代机器学习模型是否具备从数学数据中学习抽象规则的能力。", "innovation": "本研究创新地利用图神经网络（GNN）来研究箭图变异操作，通过这一操作识别和理解数学模型中的微妙模式，独立发现特定类型箭图的变异等价性判据，并展示即使在未直接训练的情况下，模型也能捕捉到隐藏表示中的结构，从而重建已知判据。这表明现代机器学习模型在处理抽象数学问题时具备强大的学习能力，能够提取并理解数学数据中的核心结构特征，这一发现对于机器学习在数学领域中的应用具有重要意义，同时也为未来的研究提供了潜在的方向。", "conclusion": "利用图神经网络和AI可解释性技术的综合作用，本研究不但独立地发现了特定类型箭图变异等价性的判据，还揭示了在未经过直接优化的情况下，模型能够捕捉到的隐藏表示中的结构化知识，并通过这些结构化知识成功重构了先前已知的判据。研究结果支持现代机器学习模型具有自动理解和学习抽象数学规则的强大能力，预示着未来其在数学计算与探索中的潜力。"}
{"llm_update_time": "2025-06-25 09:27:20", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00258", "html_url": "https://arxiv.org/abs/2502.00258", "title": "ProxSparse: Regularized Learning of Semi-Structured Sparsity Masks for Pretrained LLMs", "title_en": "ProxSparse: Regularized Learning of Semi-Structured Sparsity Masks for Pretrained LLMs", "authors": "Hongyi Liu,Rajarshi Saha,Zhen Jia,Youngsuk Park,Jiaji Huang,Shoham Sabach,Yu-Xiang Wang,George Karypis", "background": "大规模语言模型（LLMs）在自然语言处理任务中表现出色，但由于规模庞大，服务这些模型效率低下且成本高昂。现有的半结构化剪枝方法通过局部、层间优化来提高模型加速，但这些方法依赖启发式规则，未充分利用全局反馈。", "innovation": "ProxSparse 提出了一种基于学习的框架，通过正则化优化实现剪枝掩码选择。ProxSparse 将刚性、非可微的掩码选择过程转变成更平滑的优化步骤，允许逐渐进行掩码探索，且确定掩码后无需额外的权重更新。ProxSparse 在多个常用模型上的广泛评估表明，其方法在剪枝掩码选择上显著优于现有方法，证明了其学习方法的有效性。", "conclusion": "ProxSparse 在大规模语言模型的半结构化剪枝中表现出色，通过正则化优化学习剪枝掩码，显著提高模型效率，降低了成本。"}
{"llm_update_time": "2025-06-25 09:27:20", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00099", "html_url": "https://arxiv.org/abs/2412.00099", "title": "为高效移动设备推理设计的基于缓存条件的专家混合体", "title_en": "Mixture of Cache-Conditional Experts for Efficient Mobile Device Inference", "authors": "Andrii Skliar,Ties van Rozendaal,Romain Lepert,Todor Boinovski,Mart van Baalen,Markus Nagel,Paul Whatmough,Babak Ehteshami Bejnordi", "background": "混合专家（MoE）大语言模型（LLMs）由于能够通过为每个输入选择性地激活专门的小网络或‘专家’来提升性能而受到关注。然而，当在内存受限的设备上部署MoE时，特别是在生成每个令牌时采用批处理大小为一的情况下，面临着挑战，特别是与典型的高吞吐量长序列或其他大批次设置相比更为复杂。在内存受限的设备上优化MoE，只有部分专家权重能够适应DRAM，已经成为一个难题。在此之前的研究和应用主要集中在能够处理大规模数据和长序列的高吞吐量环境中，对于内存受限、需要逐个生成令牌的设备缺少针对性的解决方案。这篇研究通过引入一种新的基于缓存的路由策略，提升令牌生成过程中的缓存局部性，来解决部分专家权重适应DRAM的问题，并展示了在语言建模、MMLU和GSM8K等基准测试中的性能提升和实际应用中的便捷性，进一步拓宽了MoE在实际应用场景中的适用范围。", "innovation": "提出了基于缓存条件的路由策略，通过利用专家之间的重用（reuse），改善令牌生成过程中的缓存局部性，从而提高内存受限设备上MoE的性能。相比传统的解决方法，该策略灵活且无需训练即可使用，适用于扩展MoE在各种实际应用场景中的适用性。", "conclusion": "该研究通过在移动设备上优化MoE，展示了2倍的加速性能，证明了在整个设备上有无需额外训练即可使用的新颖的MoE路由策略的有效性，并进一步增强了MoE的普适性和应用潜力。"}
{"llm_update_time": "2025-06-25 09:27:23", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.20185", "html_url": "https://arxiv.org/abs/2412.20185", "title": "DecDEC：一种推进低比特LLM量化的方法", "title_en": "DecDEC: A Systems Approach to Advancing Low-Bit LLM Quantization", "authors": "Yeonhong Park,Jake Hyun,Hojoon Kim,Jae W. Lee", "background": "大规模语言模型（LLMs）的量化近年来变得越来越流行，特别是在硬件资源有限的设备上。虽然量化能够有效节省GPU内存和减少延迟，但不可避免地会降低模型的质量，尤其是在3比特和4比特等激进的低比特精度设置中。", "innovation": "本文提出了一种名为DecDEC的推理方案，可以在保持量化关键优势（GPU内存节省和延迟减少）的前提下，提高低比特LLM的质量。DecDEC将全精度和量化权重之间的残差矩阵存储在CPU中，并动态地仅获取一小部分权重的残差，这些权重对应的是由激活异常标记的重要通道，这些获取的残差帮助纠正这些通道中的量化误差。重要通道在每次解码步长中动态地通过分析输入激活来确定，这使得能够适应激活分布的动态特性，从而最大化错误补偿的有效性。", "conclusion": "实验结果表明，DecDEC通过增强现有的量化方法提高了模型效果。例如，对于Llama-3-8B-Instruct模型，使用3比特可以将困惑度从10.15降低到9.12，性能优于3.5比特版本，同时仅增加了不到0.0003%的GPU内存消耗，并在NVIDIA RTX 4050移动版上将推理速度降低了1.7%。"}
{"llm_update_time": "2025-06-25 09:27:24", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.05153", "html_url": "https://arxiv.org/abs/2412.05153", "title": "使用大语言模型从文本生成合成患者数据的方法", "title_en": "A text-to-tabular approach to generate synthetic patient data using LLMs", "authors": "Margaux Tornqvist,Jean-Daniel Zucker,Tristan Fauvel,Nicolas Lambert,Mathilde Berthelot,Antoine Movschin", "background": "大规模高质量的医疗数据库对于加速医学研究和洞察疾病至关重要。然而，获取这类数据常常受限于患者隐私问题、数据共享限制以及高额成本。为了克服这些限制，合成患者数据成为一种替代方案。然而，合成数据生成（SDG）方法通常依赖于机器学习模型，这些模型需要训练在原始数据上，这又回到了数据稀缺的问题。本文提出了一种无需访问原始数据，仅需要描述所需的数据库的生成合成表格患者数据的方法。利用先前的医学知识和大型语言模型（LLMs）的上下文学习能力，即使在资源稀缺的环境下也能生成现实的患者数据。定量评估我们的方法与最先进的SDG模型，使用保真度、隐私和实用性指标。结果显示，虽然大语言模型在性能上可能无法匹敌在原始数据上训练的最先进的模型，但它们能够有效生成具有临床相关性的现实患者数据。这一方法易于使用，不需要原始数据或高级机器学习技能，特别适用于快速生成定制设计的患者数据，支持项目实施和提供教育资源。", "innovation": "本文提出了一种无需访问原始数据的合成患者数据生成方法，仅需描述数据库。利用大型语言模型的上下文学习能力和先验医学知识，即使在资源稀缺的情况下也能生成现实的患者数据。这种方法易于使用，不需要原始数据或高级机器学习技能，特别适用于快速生成定制设计的患者数据，支持项目实施和提供教育资源。", "conclusion": "通过使用大型语言模型，本文提出的方法能够在不依赖于原始数据的情况下生成高质量的合成患者数据，这对快速生成定制设计的患者数据，支持项目实施和提供教育资源具有重要意义。尽管大语言模型在性能上可能不如在原始数据上训练的模型，但其在生成现实的患者数据方面具有显著优势。"}
{"llm_update_time": "2025-06-25 09:27:27", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.07501", "html_url": "https://arxiv.org/abs/2411.07501", "title": "LAuReL: 学习增强残差层", "title_en": "LAuReL: Learned Augmented Residual Layer", "authors": "Gaurav Menghani,Ravi Kumar,Sanjiv Kumar", "background": "高效深度学习方法的核心支柱之一是架构改进，如残差/跳层连接，这显著提高了模型的收敛速度和质量。自引入以来，残差连接不仅在卷积神经网络中得到广泛应用，还在基础神经网络结构——Transformer架构中得到了广泛应用，后者是大语言模型（LLMs）的基础。鉴于此，本文提出了一种新型的通用化残差连接——Learned Augmented Residual Layer（LAuReL），旨在成为残差连接的原位替代，并在模型质量和体积方面均优于原有方法。实验结果表明，LAuReL在视觉和语言模型中都能显著提升性能。例如，在ResNet-50上的ImageNet 1K任务中，它仅增加0.003%的参数量，就能获得与增加一层相比60%的性能提升，且在增加2.6倍少的参数下还能与前者匹配。同样，当预训练10亿参数和40亿参数的大语言模型时，LAuReL在各种挑战性下游评估任务上分别提高了2.54%至20.05%的性能，只增加了0.012%和0.1%的额外参数量.", "innovation": "提出了Learned Augmented Residual Layer (LAuReL)，这是一种新型的残差连接改进方法。LAuReL旨在作为传统的残差连接的原位替代，并在多个关键性能指标上有所改进，包括模型质量和参数量。该方法在视觉和语言模型上都表现出了显著的性能提升。特别是在ResNet-50上的ImageNet任务和大语言模型的性能改善方面，LAuReL显示出更高的效率和优越性，并且在使用较少额外参数的情况下取得了与更多参数模型相当的性能。", "conclusion": "实验结果证明了LAuReL在提高模型性能的同时，能够减少模型参数量。对于ResNet-50，LAuReL在几乎等同于增加一层的参数量下实现了近似60%的性能提升，且在增加2.6倍少的参数量下与额外增加一层相比。同样地，对于10亿和40亿参数的预训练大语言模型，LAuReL在各种挑战性下游任务上分别提高了2.54%至20.05%的性能，仅增加了0.012%和0.1%的额外参数量。LAuReL为提高模型效率和性能提供了一种新的有效途径。"}
{"llm_update_time": "2025-06-25 09:27:28", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04121", "html_url": "https://arxiv.org/abs/2502.04121", "title": "利用第一通过方法优化改善机器学习模型训练的扰动", "title_en": "First-Passage Approach to Optimizing Perturbations for Improved Training of Machine Learning Models", "authors": "Sagi Meir,Tommer D. Keidar,Shlomi Reuveni,Barak Hirshberg", "background": "机器学习模型在物理科学的应用中变得不可或缺，但其训练过程通常耗时较长。为改善训练过程，已经开发了多种去噪方法，如收缩与扰动、温重启以及随机重置等。尽管这些方法对分类器表现出增强的速度提升和更好的泛化能力，但这些方法通常是由直觉和试错来设计的，缺乏系统的理论优化方法。本文提出了一种系统化的优化方法，即将训练过程建模为第一通过过程，通过这种方法能够预测在单一扰动频率下的行为及其在不同频率范围内的反应，从而优化训练过程中的扰动设计，帮助提高模型的训练效率和泛化能力。", "innovation": "本文创新性地将机器学习模型的训练过程建模为第一通过过程，并设计了一种系统化的优化方法来优化训练过程中的扰动方法，这种优化方法能预测在不同频率范围内的行为，从而提高训练效率和泛化能力。这种方法具有高度的可移植性，不仅可用于其他数据集和架构，还适用于不同优化器和任务类型（例如从分类到回归）.", "conclusion": "本文通过第一通过方法合理优化了机器学习模型训练过程中的扰动，展示了提高模型训练效率及泛化能力的可能性，并证明了该方法的广泛适用性，适用于不同数据集、架构、优化器和任务类型。"}
{"llm_update_time": "2025-06-25 09:27:29", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18153", "html_url": "https://arxiv.org/abs/2502.18153", "title": "SASSHA：具有稳定近似Hessian的自适应策略感知锐度第二阶优化方法", "title_en": "SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation", "authors": "Dahun Shin,Dongyeop Lee,Jinseok Chung,Namhoon Lee", "background": "近似二阶优化方法通常在一般化性能上表现不佳，相比之下，一阶方法表现更优。本文通过损失 landscapes 的视角来研究这个问题，发现现有的二阶优化方法倾向于收敛到更尖锐的极小值，而随机梯度下降（SGD）则收敛到较不尖锐的极小值。", "innovation": "本文提出了一种新颖的二阶优化方法——Sassha，旨在通过显式减少解决方案的锐度来增强一般化性能，同时在优化轨迹中稳定近似Hessian的计算。该方法还考虑到了懒惰的Hessian更新，以确保除了平坦性之外的效率。", "conclusion": "通过在一系列标准深度学习实验中验证Sassha的有效性，该方法展示了其卓越的泛化性能，与其它方法相比，该性能要么相当，甚至更好。我们还进行了全面的分析，包括收敛性、鲁棒性、稳定性、效率和成本。"}
{"llm_update_time": "2025-06-25 09:27:29", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16772", "html_url": "https://arxiv.org/abs/2502.16772", "title": "Monitored Markov 决策过程中的基于模型的探索", "title_en": "Model-Based Exploration in Monitored Markov Decision Processes", "authors": "Alireza Kazemipour,Simone Parisi,Matthew E. Taylor,Michael Bowling", "background": "传统的强化学习假设智能体总是能接收到奖励。但在实际场景中，这并不总是成立的，比如观察者未必总是可用，传感器可能受限制或者故障，或者在部署时奖励可能不可访问。Mon-MDP（监视的马尔可夫决策过程）最近被提出用于模拟这些情况。然而，现有算法存在一些限制：未能充分利用问题结构，无法利用已知的监视器，缺乏对未特定初始化的‘不可解’Mon-MDP的最坏情况下限保证，仅给出渐进收敛证明。", "innovation": "该论文提出了一个基于模型的算法来解决Mon-MDP问题，该算法有两个基于模型的区间估计实例：一个确保可观察到的奖励能可靠地被捕捉，另一个用于学习最小最大最优策略；并通过实验证明了在超过四十四种基准上的收敛速度超过先前的算法，并且当监视过程已知时可以实现更显著的改进；同时给出了首个有限样本性能边界，展示了即使有些奖励永远不会被观测到，也能收敛到最小最大最优策略。", "conclusion": "该研究通过基于模型的方法解决了Mon-MDP的一系列问题：克服了现有算法的不足，呈现了更快的收敛速度，提供了新型的性能边界，表明即使在观察奖励不全的情况下也收敛到最小最大最优策略。"}
{"llm_update_time": "2025-06-25 09:27:30", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04260", "html_url": "https://arxiv.org/abs/2502.04260", "title": "通过解耦和知识保留实现的现实图像到图像机器遗忘", "title_en": "Realistic Image-to-Image Machine Unlearning via Decoupling and Knowledge Retention", "authors": "Ayush K. Varshney,Vicenç Torra", "background": "机器卸载（Machine Unlearning）允许参与者从训练好的机器学习模型中删除其数据，以保护隐私和安全。现有的机器卸载文献主要集中在分类器上，对于生成模型（尤其是图像到图像生成模型，I2I模型）的研究较少。现有方法主要通过最小化忘记样本在高斯噪声和生成模型输出之间的距离来实现卸载，但这种方法可能无法完全满足卸载需求，因为重新训练的模型仍然能识别全局数据模式。", "innovation": "本文提出了一个通过解耦模型参数和使用梯度递增方法实现机器卸载的框架，确保忘记样本对于卸载后的模型是异常分布（OOD）数据。此外，本文还提供了基于梯度递增的ε-δ卸载保证，并进一步微调卸载后的模型，以保持其性能。同时，还提出了攻击模型来验证卸载后的模型是否有效地去除了忘记样本的影响。实验结果在ImageNet-1K和Places365两个大规模数据集上展示了该方法的优越性，并通过CIFAR-10数据集与简单自编码器进行比较，证明了其与重新训练模型相当的性能。", "conclusion": "所提出的解耦和知识保留方法显著提高了机器卸载的效果，确保遗忘样本对于卸载后的模型是异常的，从而有效保护隐私和安全，同时保持模型的性能。"}
{"llm_update_time": "2025-06-25 09:27:32", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01875", "html_url": "https://arxiv.org/abs/2504.01875", "title": "AYLA: 通过损失变换放大梯度敏感性在非凸优化中的应用", "title_en": "AYLA: Amplifying Gradient Sensitivity via Loss Transformation in Non-Convex Optimization", "authors": "Ben Keslaki", "background": "在深度学习优化中，随机梯度下降(SGD)及其变种如ADAM通过固定的或自适应的学习率调整模型参数，但这些方法在高维度和非凸设置中往往难以同时平衡适应性和效率。", "innovation": "本文引入了AYLA，这是一种新颖的优化框架，通过损失函数变换增强训练动态。AYLA应用可调节的幂律变换到损失上，保留关键点的同时放大梯度敏感性，加速收敛。此外，还提出了一种有效学习率，能够动态适应变换后的损失，进一步提高优化效率。实验表明，AYLA在合成非凸多项式最小化、非凸曲线拟合任务以及MNIST手写数字分类和CIFAR-100图像识别中，无论在收敛速度还是训练稳定性上都优于SGD和ADAM。", "conclusion": "通过重塑损失景观，AYLA为现有的优化方法提供了模型无关的改进，显示了深度神经网络训练中的潜在进步。"}
{"llm_update_time": "2025-06-25 09:27:32", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12739", "html_url": "https://arxiv.org/abs/2501.12739", "title": "卷积神经网络的多尺度训练", "title_en": "Multiscale Training of Convolutional Neural Networks", "authors": "Shadab Ahamed,Niloufar Zakariaei,Eldad Haber,Moshe Eliasof", "background": "训练高分辨率图像上的卷积神经网络(CNNs)通常受限于计算最细网格上损失梯度的成本。针对此瓶颈问题，本文提出了多尺度梯度估计(MGE)方法，该方法利用逐级细化网格计算梯度的级联和方式表达最细网格的梯度期望值，从而通过较大批次的粗粒度层实施计算，达到与单一尺度随机梯度估计相同的效果，并且对每次降低分辨率的细化网格减少四倍的最细网格卷积。本文还将MGE嵌入全多尺度训练算法中，先在粗粒度网格上解决策学习问题，然后通过热启动实现下一步的细化，进一步减少所需的最细网格迭代次数，大幅降低计算成本，而无需显著降低性能.", "innovation": "提出了多尺度梯度估计(MGE)方法，通过逐级细化网格计算梯度的级联和方式，将其应用于全多尺度训练算法中，解决了高分辨率图像上CNNs训练的成本问题，实现了4-16倍的计算成本减少，且不影响性能。MGE和全多尺度训练算法结合后，提供了一种不牺牲准确性的CNN训练加速方法，并且可以与其他降低方差或学习率计划结合进一步增强可扩展性.", "conclusion": "全多尺度训练方法在图像去噪、去模糊、修复和超分辨率任务中减少了4-16倍的计算成本，同时保持了性能，展示了MGE和全多尺度训练算法在提高高分辨率数据上CNN训练效率方面的有效性，且不牺牲准确性。"}
{"llm_update_time": "2025-06-25 09:27:32", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18959", "html_url": "https://arxiv.org/abs/2502.18959", "title": "Fourier Multi-Component and Multi-Layer Neural Networks: 解锁高频率潜力", "title_en": "Fourier Multi-Component and Multi-Layer Neural Networks: Unlocking High-Frequency Potential", "authors": "Shijun Zhang,Hongkai Zhao,Yimin Zhong,Haomin Zhou", "background": "神经网络的架构及其激活函数的选择对其实现是至关重要的。良好的匹配是实现有效的表征和学习的关键。现有研究通常关注如何选择和匹配神经网络的架构和激活函数，但这种方法往往忽略了两者之间的强协同作用。本文在此背景下，探讨了如何通过设计一种新型的Fourier Multi-Component and Multi-Layer Neural Network (FMMNN) 来实现这种协同作用，并展示了其在高频率组件上的优势。", "innovation": "提出了新型的 Fourier Multi-Component and Multi-Layer Neural Network (FMMNN)，以实现神经网络的架构和激活函数之间的强协同作用。FMMNN 在高频率特性的建模方面表现出高效率和灵活性。理论结果表明，FMMNN 具有指数级的表达能力，可有效逼近函数。同时，FMMNN 的优化景观比标准全连接神经网络更为有利，尤其在处理高频率特征时。此外，还提出了一种针对第一层权重的缩放随机初始化方法，大幅提升了训练速度和整体性能。", "conclusion": "大量的数值实验验证了理论分析，展示了 FMMNN 在各种任务中的准确性和效率方面均优于传统的神经网络。"}
{"llm_update_time": "2025-06-25 09:27:33", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08365", "html_url": "https://arxiv.org/abs/2502.08365", "title": "通过任务无关探索实现多智能体无监督强化学习", "title_en": "Towards Unsupervised Multi-Agent Reinforcement Learning via Task-Agnostic Exploration", "authors": "Riccardo Zamboni,Mirco Mutti,Marcello Restelli", "background": "在强化学习中，当我们旨在在没有先验访问任务规范（即奖励）的情况下预训练策略时，我们通常称之为无监督预训练。在单智能体设置中，该问题已经得到了充分的研究和理解，一种流行的策略称为任务无关探索，其将无监督目标定义为最大化由智能体策略诱导的状态分布的熵。相比之下，在多智能体设置中知之甚少，尽管这类设置在现实世界中普遍存在。现有不同表述方式的优缺点如何？在理论和实践上问题的难度如何？本文首先通过分析这些不同表述方式，指出即使在理论上是可解的，但在实践中也具有挑战性。然后提供了一个可扩展的、分布式、信任区域策略搜索算法来解决实际环境中的问题，最后通过数值验证支持理论发现，并为在困难领域通过任务无关探索实现无监督多智能体强化学习铺平了道路，表明最大化特定目标，即混合熵，提供了可实现性和性能之间良好的权衡。", "innovation": "本文提出了一个针对实际场景的可扩展、去中心化、信任区域策略搜索算法，以解决多智能体环境中的无监督强化学习问题，并通过任务无关探索优化特定目标（即混合熵）以实现良好的可实现性和性能之间的平衡。这是在多智能体设置中进行无监督学习的重要创新。", "conclusion": "本文通过分析不同表述方式，指出在理论上是可解的但在实践中具有挑战性。提出一个可扩展的、分布式、信任区域策略搜索算法，并通过数值验证证明了任务无关探索中特定目标（混合熵）优化的有效性，为在困难领域实现无监督多智能体强化学习铺平了道路。"}
{"llm_update_time": "2025-06-25 09:27:37", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07085", "html_url": "https://arxiv.org/abs/2504.07085", "title": "通过有限表达方法识别未知的随机动力学", "title_en": "Identifying Unknown Stochastic Dynamics via Finite expression methods", "authors": "Senwei Liang,Chunmei Wang,Xingjian Xu", "background": "随机微分方程（SDEs）在各种科学领域理解复杂动态系统中至关重要。现有方法通常采用基于神经网络的模型表达SDEs，但这些模型通常缺乏解释力，难以在训练领域之外进行泛化。", "innovation": "本论文引入了有限表达方法（FEX），一种符号学习方法，专门用于推导SDEs中确定性成分的可解释数学表示。对于随机成分，我们将FEX与先进的生成建模技术结合，提供SDEs的全面表示。实验结果表明，FEX在训练域之外表现出良好的泛化能力，并且长期预测准确性高于基于神经网络的方法。FEX识别的符号表达不仅提高了预测准确性，还提供了有关系统潜在动态的有价值见解，有助于新科学发现。", "conclusion": "FEX在基于神经网络的模型之上进行了改进，不仅提升了模型的解释性，还增强了其在未知领域的泛化能力和预测准确性。"}
{"llm_update_time": "2025-06-25 09:27:40", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01336", "html_url": "https://arxiv.org/abs/2505.01336", "title": "在并行代理中增强多样性：一种最大状态熵的探索故事", "title_en": "Enhancing Diversity in Parallel Agents: A Maximum State Entropy Exploration Story", "authors": "Vincenzo De Paola,Riccardo Zamboni,Mirco Mutti,Marcello Restelli", "background": "并行数据收集已经重新定义了强化学习（RL），实现了前所未有的效率提升，并推动了大规模现实世界应用的突破。在这一框架下，N个相同的代理在N个环境模拟器的副本中操作，使得数据收集速度提高了N倍。关键问题是：是否可以通过专门化并行代理的策略来超越这一N倍加速？", "innovation": "本文引入了一种新的学习框架，该框架在并行环境中最大化收集的数据的熵。该方法仔细平衡了单个代理和跨代理的多样性，减少冗余。这种思想通过中心化策略梯度方法实现，并通过实验性评价展示了与专门化代理系统的潜力，以及与数据多样性利用的批处理强化学习技术的协同效应。此外，还提供了一种新颖的收敛性分析，表明专门化并行采样分布具有更快的收敛速率，这支持了该方法论并且可能具有独立价值", "conclusion": "通过本文提出的方法，可以有效地在并行代理中增加多样性，减少冗余，并且实验结果支持了该方法的多项优势，同时也展示了其作为独立兴趣的新收敛性分析。"}
{"llm_update_time": "2025-06-25 09:27:40", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00466", "html_url": "https://arxiv.org/abs/2505.00466", "title": "一种基于属性的机器学习通用框架", "title_en": "A General Framework for Property-Driven Machine Learning", "authors": "Thomas Flinkow,Marco Casadio,Colin Kessler,Rosemary Monahan,Ekaterina Komendantskaya", "background": "神经网络在从数据中学习关键的安全性和正确性属性方面经常表现出色，这突显了直接整合逻辑规范的训练方法的必要性。尽管对抗性训练可以用于提高对ε-立方内小扰动的鲁棒性，但对于计算机视觉以外的领域，如控制系统和自然语言处理，可能需要更灵活的输入区域规范，例如一般化的超矩形。可微逻辑提供了一种将任意逻辑约束编码为额外损失项的方法，这些项指导学习过程满足这些约束。本文探讨了如何将这两种互补的方法统一到一个框架中，以实现基于属性的机器学习，作为朝着有效形式验证神经网络的一个步骤。研究表明，文献中著名的属性是这一普遍方法的子案例，我们通过涉及无人机系统的神经网络控制器案例研究展示了其实际有效性。", "innovation": "本文提出了一种将神经网络的逻辑约束整合进学习过程中的统一框架，同时引入了可微逻辑作为约束编码方法，并通过无人机系统控制器的案例研究证明了该框架的有效性。这一框架可以使得神经网络更好地满足特定的应用需求，提高其正确性和鲁棒性。", "conclusion": "展示了如何在单一框架中结合神经网络的逻辑约束和可微逻辑来实现基于属性的机器学习。研究证明了这种方法的有效性，并为未来的神经网络形式验证提供了新的途径。"}
{"llm_update_time": "2025-06-25 09:27:42", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16828", "html_url": "https://arxiv.org/abs/2504.16828", "title": "思考型过程奖励模型", "title_en": "Process Reward Models That Think", "authors": "Muhammad Khalifa,Rishabh Agarwal,Lajanugen Logeswaran,Jaekyeom Kim,Hao Peng,Moontae Lee,Honglak Lee,Lu Wang", "background": "过程奖励模型（PRMs）是测试时扩展的关键组成部分。然而，它们需要步骤级别的监督，这使得训练变得昂贵。现有方法主要是通过区分验证器进行训练，但这种方法需要大量的过程标签，并且缺乏对推理能力的有效利用。", "innovation": "本文提出了一种新型的长链推理（CoT）验证器ThinkPRM，它使用远少于传统区分验证器所需的步骤标签（仅需1%的PRM800K标签），就能够实现对多个具有挑战性的基准的超越。ThinkPRM通过生成验证CoT链来验证每一步解决方案，并利用了其固有的推理能力，优于LLM-as-a-Judge和区分验证器。此外，ThinkPRM在验证计算扩展方面表现出色，使用相同的标记预算，在某些基准中比LLM-as-a-Judge表现好7.2%。", "conclusion": "本文的工作强调了生成型、长链推理的PRMs的价值，它们可以在测试时扩展验证计算，同时在训练时只需要最少的监督。解释型PRMs在多种基准上实现了超越，特别是在标签有限的情况下。相关代码、数据和模型将在该网址公开。"}
{"llm_update_time": "2025-06-25 09:27:43", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04535", "html_url": "https://arxiv.org/abs/2505.04535", "title": "FDA-Opt: 通信效率优化的联邦语言模型微调", "title_en": "FDA-Opt: Communication-Efficient Federated Fine-Tuning of Language Models", "authors": "Michail Theologitis,Vasilis Samoladas,Antonios Deligiannakis", "background": "联邦学习（FL）可以利用大量此前无法访问的数据源。同时，预训练语言模型（LMs）因其出色的新兴能力以及对下游任务的快速适应性而风靡一时。这为联邦学习打开了一条新前沿：语言模型的微调。然而，FL中的主要挑战之一是频繁且僵化的参数通信，而当代模型的巨大规模更是加剧了这一问题。尽管FedOpt家族的算法已成为FL的标准方法，通过固定但任意的周期进行模型交换，但最近的FDA算法虽然提出了一种基于训练进展的动态方法，但引入了一个难以校准的参数，并且强制使用了僵化的同步方案。", "innovation": "本文提出的FDA-Opt算法家族是对FedOpt和FDA的统一通用扩展，通过提出一种新的方法消除上述局限。FDA-Opt算法在微调LMs的下游NLP任务上进行了实验性评估，并表明FDA-Opt即使在用针对FedOpt优化的超参数配置时，也能优于FedOpt。因此，FDA-Opt作为一个无需额外配置、即插即用且性能优越的替代方案，适用于现代FL库和系统。", "conclusion": "FDA-Opt 是 FedOpt 的通信效率优化版本，不仅能够在无需额外配置的情况下提供优异性能，而且还适用于现代联邦学习系统中的语言模型微调任务。"}
{"llm_update_time": "2025-06-25 09:27:43", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23971", "html_url": "https://arxiv.org/abs/2505.23971", "title": "重新审视关键批量大小：一种简单的基于实证的大批量语言模型训练方法", "title_en": "Critical Batch Size Revisited: A Simple Empirical Approach to Large-Batch Language Model Training", "authors": "William Merrill,Shane Arora,Dirk Groeneveld,Hannaneh Hajishirzi", "background": "在大规模训练语言模型时，适当的批量大小至关重要。虽然较大的批量大小可以加速训练，但过大的批量大小会影响标记效率。McCandlish等人(2018)提出了一种关键批量大小(CBS)的概念，低于这个大小，训练损失不会有显著下降，该概念基于训练过程中梯度噪声的规模来估计。尽管该方法在实践中得到了应用，如在训练GPT-3时，但它对梯度噪声作为CBS代理的假设限制了其应用，使得其在实践中的可靠性存疑。", "innovation": "本文提出了一种简单直观的方法，直接测量CBS，并展示了CBS如何随训练进展而变化。研究发现，CBS在初始化时非常接近0，随后迅速增加，最终达到稳定状态。这一趋势在不同规模的模型（1B和7B）中都保持一致，表明从小规模训练开始的CBS信息对大规模训练有指导意义。此外，基于CBS随训练变化的发现，本文提倡批量大小预热策略，即从较小的批量开始逐渐增加至CBS增长时。应用此方法，可以以更少的梯度步骤获得更优的损失。这证明了该框架在大批量下可靠地训练语言模型的能力，并提高了数据并行性而不牺牲性能。", "conclusion": "通过批量大小预热策略，成功将OLMo1B语言模型的训练损失降低，并减少了43%的梯度步骤。这表明该框架能够在大批量下可靠地训练语言模型，同时提高数据并行性而不影响性能。"}
{"llm_update_time": "2025-06-25 09:27:43", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14307", "html_url": "https://arxiv.org/abs/2504.14307", "title": "使用学生引导的知识蒸馏从随机教师表示中学习", "title_en": "Learning from Stochastic Teacher Representations Using Student-Guided Knowledge Distillation", "authors": "Muhammad Haseeb Aslam,Clara Martinez,Marco Pedersoli,Alessandro Koerich,Ali Etemad,Eric Granger", "background": "近年来，知识蒸馏的研究进展表明，当使用相同的深度学习架构从教师模型向学生模型蒸馏知识时，特别是在网络过参数化且教师模型使用提前停止训练的情况下，学生模型的表现可以超越教师模型。此外，集成学习方法可以提升性能，但随着模型数量的增加，训练、存储和部署多个模型变得不切实际。即使对多个教师模型进行蒸馏以产生单一的学生模型或采用加权平均方法，也需要先训练多个教师模型，且未能充分利用DL模型中固有的随机性，造成生成和蒸馏多样性不足。这些限制在资源受限或对延迟敏感的应用中尤为显著，如穿戴设备。", "innovation": "本文提出了一种新颖的方法：通过在知识蒸馏过程中使用抽样随机性生成多个多元教师表示，并利用学生引导的知识蒸馏（SGKD）策略筛选和加权教师表示，仅从任务相关表示中进行蒸馏。学生表示在每个蒸馏步骤中作为权威，指导蒸馏过程。实验结果表明，所提出的随机蒸馏方法（SSD）在训练和测试时间均不增加模型大小的情况下，能够超越当前最先进的方法，并且计算复杂度相比当前先进的集成学习和加权平均方法可以忽略不计。", "conclusion": "本文提出了一种新的方法SSD，通过使用抽样随机性生成多个教师表示，在知识蒸馏过程中，利用学生表示来筛选和加权教师表示，从而使学生能够学习更多更相关的知识，这种方法在资源受限的环境中特别有用。实验结果验证了这一方法的有效性，在不增加模型规模和计算复杂度的情况下，显著提高了模型的性能。"}
{"llm_update_time": "2025-06-25 09:27:44", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24627", "html_url": "https://arxiv.org/abs/2505.24627", "title": "重新思考针对不同约束紧度的车辆路线问题的神经组合优化", "title_en": "Rethinking Neural Combinatorial Optimization for Vehicle Routing Problems with Different Constraint Tightness Degrees", "authors": "Fu Luo,Yaoxin Wu,Zhi Zheng,Zhenkun Wang", "background": "近期，神经组合优化（NCO）方法在无需特定领域专业知识的情况下展示了良好的问题解决能力。然而，大多数现有的NCO方法使用的训练和测试数据具有固定的约束值，并未对约束紧度不同对NCO方法性能的影响进行研究。本研究以容量约束车辆路线问题（CVRP）为例，实证分析不同约束紧度下NCO方法的性能。研究发现，现有的NCO方法在针对不同约束值的表现上存在过拟合问题，只能在部分约束范围内表现良好，而在其他范围内表现较差。", "innovation": "为了克服现有NCO方法的这一缺陷，本文开发了一种有效的训练方案，该方案明确考虑了不同程度的约束紧度，并提出了一个多专家模块来学习适应性较强的解决策略。实验结果表明，所提出的方法可以有效克服过拟合问题，在不同约束紧度的CVRP和CVRPTW中表现出更优的性能。", "conclusion": "研究揭示了现有NCO方法对约束紧度的过拟合问题，提出了一种新方法来缓解这一问题，提高了NCO方法在不同约束紧度下的性能表现。"}
{"llm_update_time": "2025-06-25 09:27:49", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18167", "html_url": "https://arxiv.org/abs/2506.18167", "title": "通过引导向量理解思维语言模型的推理", "title_en": "Understanding Reasoning in Thinking Language Models via Steering Vectors", "authors": "Constantin Venhoff,Iván Arcuschin,Philip Torr,Arthur Conmy,Neel Nanda", "background": "大型语言模型（LLMs）的进步催生了生成详细内部推理链的思维语言模型，尽管这些模型在性能上有所提升，但控制其推理过程仍然困难。为了应对这一挑战，本文研究了DeepSeek-R1-Distill模型中的特定推理行为，并提出了一种通过分析和操控这些行为来指导思维模型的方法。通过系统地在10个不同类别中的500个任务上进行实验，作者识别出思维模型中的几种推理行为，包括表达不确定性、生成假设验证示例以及在推理链中的回溯。", "innovation": "文章的方法通过识别引导向量，实现了对模型推理过程中的特定行为进行控制，例如回溯或表达不确定性。这种方法为在受控和可解释的条件下对思维模型的推理过程进行引导提供了实际工具。研究团队使用三种DeepSeek-R1-Distill模型验证了该方法的有效性，展示了不同模型架构之间的一致性控制效果。", "conclusion": "通过实验验证，本文的方法能够有效地操控思维模型的推理过程，并提供了一种在引导向量的帮助下实现这一目标的机制，有助于更深入地理解和控制思维语言模型的推理机制。"}
{"llm_update_time": "2025-06-25 09:27:51", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02200", "html_url": "https://arxiv.org/abs/2506.02200", "title": "学习用于下游工具变量回归的治疗表示", "title_en": "Learning Treatment Representations for Downstream Instrumental Variable Regression", "authors": "Shiangyi Lin,Hui Lan,Vasilis Syrgkanis", "background": "传统的工具变量（IV）估计器面临一个根本限制：它们只能容纳与可用工具变量数量相等的内生治疗变量。当治疗以高维度和未结构化的方式（例如，医院患者治疗路径的描述）呈现时，这一限制变得尤为具有挑战性。在这种情况下，研究人员通常先使用无监督降维技术在实施IV回归分析之前学习一种低维度的治疗表示。然而，这种做法可能会在表示学习步骤中因隐式的正则化而遭受大量的遗漏变量偏差。该研究旨在解决这一问题，提出了一种新的方法，在表示学习过程中明确地整合工具变量，以处理有限工具变量和高维度内生变量。研究通过理论和实证方法证实，使用这些基于工具变量信息的表示来拟合IV模型可以确保优化结果预测的方向识别。实验结果表明，提出的方法比不整合工具变量信息的常规两阶段方法更优，能够提高预测精度和准确性。", "innovation": "提出了一个处理有限工具变量和高维度内生变量的新框架，即在表示学习过程中直接整合工具变量。这种方法通过理论分析和实证研究证明了在基于工具变量信息的表示上拟合IV模型能够更有效地识别优化结果预测的方向，从而减少遗漏变量偏差。", "conclusion": "该研究提出了一种新的处理高维度内生变量和有限工具变量的方法，通过在表示学习过程中纳入工具变量，提高了IV模型的识别能力和预测精度。这种方法在理论上能够确保优化结果预测的方向被正确识别，并在实证研究中证明了其相对于传统两阶段方法的优势。"}
{"llm_update_time": "2025-06-25 09:27:53", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10412", "html_url": "https://arxiv.org/abs/2506.10412", "title": "Time-IMM：不规则多模态多元时间序列的 datasets 和 benchmark", "title_en": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series", "authors": "Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang", "background": "在医疗保健、气候建模和金融等实际应用中，时间序列数据通常是不规则的、多模态的和杂乱的，具有变化的采样率、异步模态和普遍的缺失值。然而，现有的基准数据集通常假设干净的、定时采样的、单模态数据，这在研究与实际部署之间造成了显著的差距。", "innovation": "我们引入了 Time-IMM 数据集，该数据集专门设计用于捕获多模态多变量时间序列中的因果间断。Time-IMM 包含九种不同类型的时间序列间断性，分为触发式、约束式和伪影式机制。此外，我们还引入了 IMM-TSF 基准库，用于不规则多模态时间序列的预测，支持异步集成和真实评估。IMM-TSF 包含专门的融合模块，包括时间戳到文本的融合模块和多模态融合模块，支持基于最近性和注意力机制的集成策略。实验结果表明，在不规则时间序列数据中显式建模多模态显著提高了预测性能。", "conclusion": "Time-IMM 和 IMM-TSF 为在实际条件下进行时间序列分析提供了基础。该数据集可在此链接访问，该基准库可在另一链接访问。"}
{"llm_update_time": "2025-06-25 09:27:53", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.10653", "html_url": "https://arxiv.org/abs/2311.10653", "title": "学习健康和受损人类手臂运动范围分析的现实关节空间边界", "title_en": "Learning Realistic Joint Space Boundaries for Range of Motion Analysis of Healthy and Impaired Human Arms", "authors": "Shafagh Keyvanian,Michelle J. Johnson,Nadia Figueroa", "background": "现实的人体运动模型对于人类与机器人交互、生物力学以及机器人辅助康复至关重要。然而，准确建模关节限制极为复杂，因为人体手臂运动受限于关节限值、关节间和关节内的依赖性、自我碰撞、个体能力以及肌肉或神经系统的限制，这些因素难以准确表示。因此，医生和研究人员通常依赖简单的边界限制方法，忽略了重要的解剖因素。", "innovation": "本文提出了一种数据驱动的方法，通过拟合一类支持向量机和高效的超参数调整方案，从上肢关节空间探索动作数据集中学习现实的解剖受限的上肢运动范围边界，这种方法在基于有效合法运动范围学习的研究中表现出优越性。此外，还提出了一种损害指数（II）指标，提供了一种定量评估健康和受损手臂能力/损害程度的方法，并通过验证他们在有物理限制的健康受试者（模仿偏瘫）以及不同残疾水平的中风患者中应用此指标来验证这一指标的有效性。", "conclusion": "本文提出的方法能够准确学习解剖受限的上肢运动范围边界，能够定量评估健康与受损手的能力/损害程度，这种方法比现有方法更准确。"}
{"llm_update_time": "2025-06-25 09:27:53", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2212.04672", "html_url": "https://arxiv.org/abs/2212.04672", "title": "带有耦合线性约束的迭代准对策游戏", "title_en": "Iterative Minimax Games with Coupled Linear Constraints", "authors": "Huiling Zhang,Zi Xu,Yu-Hong Dai", "background": "非凸 minimax 对策游戏的研究在机器学习和决策科学领域引起了广泛关注，因为它们与对抗训练场景有根本性的联系。这项工作开发了一种交替的 primal-dual 逐次近似梯度 (PDAPG) 算法框架，用于解决具有耦合线性约束的非凸非光滑目标函数的迭代最小最大游戏。对于强凹情况，PDAPG 算法在 $\text{O}(\text{ε}^{-2})$ 次迭代内获得 ε-稳定解；对于凹情况，PDAPG 算法在 $\text{O}(\text{ε}^{-4})$ 次迭代内获得相同解。分析提供了此类受约束最小最大游戏的第一个已知迭代复杂性界，特别是解决了由耦合线性约束引起的策略变量间固有的相互依赖性问题。", "innovation": "开发了一种交替的 primal-dual 逐次近似梯度 (PDAPG) 算法框架，同时处理非光滑组成部分和协调的约束结构，解决了受约束最小最大游戏中的关键挑战，特别是耦合线性约束导致的策略变量间的相互依赖性问题。", "conclusion": "本文对于具有强凹和凹配置的非凸非光滑目标函数的最小最大游戏，提供了严格的收敛保证，展示了 PDAPG 算法的迭代复杂性界，并且该算法对于解决耦合线性约束下的对策游戏是一个重要的进展。"}
{"llm_update_time": "2025-06-25 09:27:56", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.12029", "html_url": "https://arxiv.org/abs/2403.12029", "title": "Align and Distill: 统一并提升目标检测的域适应性", "title_en": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection", "authors": "Justin Kay,Timm Haucke,Suzanne Stathatos,Siqi Deng,Erik Young,Pietro Perona,Sara Beery,Grant Van Horn", "background": "物体检测器在处理与其训练集不同的数据时经常表现不佳。近年来，域适应性目标检测（DAOD）方法在解决这一挑战方面取得了显著成果，但因为基准测试中的系统性缺陷，导致了过去的性能结果存在疑问，阻碍了进一步的进步，主要问题包括：（a）由于基线不够强大导致的性能高估；（b）不一致的实现方法导致透明比较方法的困难；（c）缺乏普适性，因为使用的骨干网络过时且基准测试缺乏多样性。因此，需要引入一个统一的基准测试和实现框架来解决这些问题。", "innovation": "引入了一个统一的基准测试和实现框架，Align and Distill (ALDI)，支持DAOD方法的比较并促进未来发展；提出了一个公平且现代化的训练与评估协议，解决基准测试中的缺陷；构建了一个新的DAOD基准数据集CFC-DAOD，以评估在多样化真实世界数据上的表现；提出了一种新方法，ALDI++，在多个基准上取得了最先进的性能，特别是在Cityscapes到Foggy Cityscapes测试上提高了3.5 AP50，在Sim10k到Cityscapes上提高了5.7 AP50，且在CFC Kenai到Channel测试上提高了0.6 AP50。ALDI和ALDI++是架构无关的，为YOLO和DETR为基础的DAOD设定了新的最先进的标准，而无需额外的超参数调整。", "conclusion": "我们的框架、数据集以及最先进的方法为DAOD提供了关键的重置，为未来的研究提供了坚实的基础。代码和数据已经发布。"}
{"llm_update_time": "2025-06-25 09:27:58", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.13722", "html_url": "https://arxiv.org/abs/2309.13722", "title": "Kolmogorov偏微分方程具有Lipschitz非线性的Lp意义下通过ReLU、Leaky ReLU和softplus激活证实可克服维度灾难", "title_en": "Deep neural networks with ReLU, leaky ReLU, and softplus activation provably overcome the curse of dimensionality for Kolmogorov partial differential equations with Lipschitz nonlinearities in the $L^p$-sense", "authors": "Julia Ackermann,Arnulf Jentzen,Thomas Kruse,Benno Kuckuck,Joshua Lee Padgett", "background": "近年来，已经提出了一些用于近似高维偏微分方程（PDEs）的深度学习（DL）方法。这些方法在文献中引起了极大的兴趣，主要是基于模拟结果，表明这些DL方法有可能克服偏微分方程的维度灾难（COD）。目前虽然没有数学结果证明这些方法能够克服COD，但现有文献中已经有一系列严谨的结果展示了深度神经网络（DNNs）在没有维度灾难的情况下具有拟合PDE解的能力，而不受维度和误差倒数的指数增长限制。本文进一步推广了这些结果，将误差度量从$L^2$推广至$L^p$（$p \neq 2$），并允许使用更广泛的激活函数，包括ReLU、Leaky ReLU和softplus。", "innovation": "本文的关键贡献在于将之前的误差度量结果从$L^2$推广至更广泛的$L^p$（$p \neq 2$），并且证明了更通用的激活函数（包括ReLU、Leaky ReLU和softplus）可以用于克服维度灾难，具体而言，在Lipschitz连续非线性的半线性热PDEs中，在$L^p$意义下，可以使用带有这些激活函数的DNNs在终端时间点近似得到PDE解，而不需要维度和误差倒数的指数增长限制。", "conclusion": "本文证明了通过DNNs（带有ReLU、Leaky ReLU和softplus激活函数）在$L^p$意义下可以克服偏微分方程的维度灾难，特别是在Lipschitz连续非线性的半线性热PDEs中，这种近似在终端时间点是可能的，而不需要维度和精度倒数的指数增长限制。"}
{"llm_update_time": "2025-06-25 09:27:59", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit: 改进大语言模型策略优化的奖励抖动方法", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1 通过基于规则的奖励系统成功增强了大型语言模型（LLM）的推理能力，尽管该奖励系统非常有效且能够缓解奖励破解的问题，但这种奖励函数往往是离散的。实验观察显示，离散奖励可能导致梯度异常、优化不稳定和收敛缓慢等现象。", "innovation": "为了应对这些问题，作者提出了 ReDit 方法，该方法通过对离散奖励信号添加简单的随机噪声来进行抖动处理。这种方法在整个学习过程中持续提供探索梯度，使梯度更新更加平滑，从而加速收敛，并通过在平坦的奖励区域引入随机性，促使模型探索新策略并跳出局部最优解。实验表明，ReDit 在多种任务中显示出有效性与效率，平均仅需 vanilla GRPO 基准方法大约 10% 的训练步骤即可达到相似性能，并且在相同训练时间内仍比 vanilla GRPO 提高出 4% 的性能。此外，可视化结果证实 ReDit 显著缓解了梯度问题，理论分析进一步验证了这些优势。", "conclusion": "ReDit 提供了一种改进大语言模型策略优化的有效方法，通过引入简单的随机噪声使奖励信号变得连续化，从而加速了模型的学习过程，提高了模型的性能并减少了梯度问题。"}
{"llm_update_time": "2025-06-25 09:28:00", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07155", "html_url": "https://arxiv.org/abs/2504.07155", "title": "使用傅里叶增强表示的深度学习在列车传动系统中的复合故障诊断", "title_en": "Compound Fault Diagnosis for Train Transmission Systems Using Deep Learning with Fourier-enhanced Representation", "authors": "Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu", "background": "故障诊断能够预防列车中断，确保其传输系统的稳定性和可靠性。数据驱动的故障诊断模型相比传统方法具有处理非线性、适应性、可扩展性和自动化的优势。现有数据驱动模型分别针对传输部件训练，并仅考虑单一故障，限制了模型在部件共同运行场景中的性能，因为这会影响各部件的振动信号。", "innovation": "提出了一种频域表示以及1维卷积神经网络用于复合故障诊断，并应用于包含21个传感器通道、17种单一故障和42种复合故障（来自4个相互作用部件：电机、齿轮箱、左轴箱和右轴箱）的PHM北京2024数据集。所提出模型在单一故障和复合故障测试集上的准确率分别达到了97.67%和93.93%。", "conclusion": "所提出的模型在处理单一故障和复合故障方面均表现出色，相较于传统方法提供了更好的解决非线性和适应多部件协同运行场景的能力。"}
{"llm_update_time": "2025-06-25 09:28:02", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.09567", "html_url": "https://arxiv.org/abs/2405.09567", "title": "ECG-SMART-NET：用于精确心电图诊断心肌梗死阻塞的深度学习架构", "title_en": "ECG-SMART-NET: A Deep Learning Architecture for Precise ECG Diagnosis of Occlusion Myocardial Infarction", "authors": "Nathan T. Riek,Murat Akcakaya,Zeineb Bouzid,Tanmay Gokhale,Stephanie Helman,Karina Kraevsky-Philips,Rui Qi Ji,Ervin Sejdic,Jessica K. Zègre-Hemsey,Christian Martin-Gill,Clifton W. Callaway,Samir Saba,Salah Al-Zaiti", "background": "心肌梗死阻塞（OMI）是一种严重的心脏病，表现为冠状动脉完全阻塞，需要立即进行心脏造影以恢复心脏血流，但这种病使用12导联心电图（ECG）很难被准确识别。目前关于这方面的研究很少，并且现有研究表明，基于特征的随机森林和卷积神经网络（CNN）都是提高ECG检测OMI的有希望的方法。现有ResNet架构未能很好地捕捉单个导联内的时间特征，且无法捕捉导联间的空间一致性或差异性。", "innovation": "本文提出了一种称为ECG-SMART-NET的临床指导改进的ResNet-18架构。新模型首先通过具有1xk核的时域卷积层学习时间特征，然后通过具有12x1核的空间卷积层在残差块后学习空间特征，以此来改进现有架构的问题。实验表明ECG-SMART-NET在多中心临床数据集上（包含10,393份ECG来自7,397位患者，OMI的发生率为7.2%）的诊断性能非常出色，其测试AUC为0.953 [0.921, 0.978]，超过了其他最先进的模型和传统的随机森林方法。", "conclusion": "ECG-SMART-NET能够超越现有的随机森林方法来预测OMI，其性能优于当前的ResNet-18架构，是实现OMI精确诊断的理想工具。"}
{"llm_update_time": "2025-06-25 09:28:04", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.01600", "html_url": "https://arxiv.org/abs/2405.01600", "title": "使用块融合描述子集成池化方法改进并可解释的宫颈癌分类", "title_en": "Improved and Explainable Cervical Cancer Classification using Ensemble Pooling of Block Fused Descriptors", "authors": "Saurabh Saini,Kapil Ahuja,Akshat S. Chauhan", "background": "宫颈癌是女性第二常见的癌症类型，而且导致了较高的死亡率。之前的宫颈癌检测模型效果有限。此前的研究显示，预训练的ResNets能够很好地从宫颈癌图像中提取特征。现有研究主要使用ResNet的最后一个卷积块来提取抽象特征（如形状、物体等）。本文在实验中发现了早期卷积块提取的详细特征（如颜色、边缘、纹理）对癌症分类同样重要。因此，本文提出了基于ResNets及其融合版本的新模型，以改进宫颈癌的分类性能并提供可解释性.", "innovation": "主要创新点包括：1) 使用全局最大池化和平均池化技术选择详细的和抽象的特征；2) 将三个标准ResNet和提出的三种块融合ResNet相结合并标准化特征；3) 提出一种新的SHAP+LIME可解释性方法来准确识别癌变区域；4) 实验结果在两个公开数据集上的表现优于现有方法，尤其是在IARC数据集上取得了平均13.20%的性能提升.", "conclusion": "本文通过集成池化方法及特征选择技术显著提升了宫颈癌分类的性能，并且引入了新的可解释性方法来识别癌变区域，实验结果在两个公开数据集上都表现出色，验证了所提方法的有效性。"}
{"llm_update_time": "2025-06-25 09:28:04", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.16776", "html_url": "https://arxiv.org/abs/2403.16776", "title": "Diff-Def: 使用扩散生成变形场的条件图集", "title_en": "Diff-Def: Diffusion-Generated Deformation Fields for Conditional Atlases", "authors": "Sophie Starck,Vasiliki Sideri-Lampretsa,Bernhard Kainz,Martin J. Menten,Tamara T. Mueller,Daniel Rueckert", "background": "解剖图集在人口研究和分析中广泛使用。条件图集针对特定的亚人群进行定义，且允许针对如衰老或疾病相关的细微解剖学差异进行研究。现有方法包括基于注册的方法和生成对抗网络（GAN），但这些方法分别存在难以处理大解剖变化和训练不稳定性的问题。本文致力于通过使用潜在扩散模型生成变形场，将通用人群图集转换为特定亚人群图集，以解决这些问题。这种方法能确保结构完整性，增强可解释性，并通过生成变形场及其邻居图像的正则化来避免直接图像合成中的幻觉问题。", "innovation": "本文提出了一种使用潜在扩散模型生成变形场的方法，从而将通用的人群图集转换为特定亚人群的图集。这种方法避免了现有注册方法难以处理大解剖变异和生成对抗网络训练不稳定的问题。通过生成变形场及其邻居图像进行正则化，本方法能确保结构完整性、增强可解释性，并避免直接图像合成中的幻觉问题。在使用来自英国生物银行的大脑MRI图像进行测试时，此方法生成了高现实性的地景图，并且在解剖精确度、感知相似度和定性分析方面超过了现有基线。", "conclusion": "本文提出的方法通过使用潜在扩散模型生成变形场来生成条件图集，显著提升了结构完整性、增强了解释性并提高了生成图集的质量。在不同的定量和定性指标中，本文的方法优于现有的基线方法，生成的图集具有平滑的变换和高解剖保真度，展示了生成图集的高质量和一致性。"}
{"llm_update_time": "2025-06-25 09:28:05", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.15615", "html_url": "https://arxiv.org/abs/2404.15615", "title": "M3D: 基于流形的动态分布领域适应用于跨被试和跨会话的基于EEG的情绪识别非深度迁移学习", "title_en": "M3D: Manifold-based Domain Adaptation with Dynamic Distribution for Non-Deep Transfer Learning in Cross-subject and Cross-session EEG-based Emotion Recognition", "authors": "Ting Luo,Jing Zhang,Yingwei Qiu,Li Zhang,Yaohua Hu,Zhuliang Yu,Zhen Liang", "background": "情绪解码使用基于脑电图(EEG)的情感脑机接口(aBCI)在情感计算中发挥着重要作用，但受到EEG非站定性、个体差异和大规模标记数据集成本高等挑战的限制。尽管深度学习方法效果显著，但它们需要大量的计算资源和数据量，限制了其实际应用。", "innovation": "我们提出了一种基于流形的动态分布领域适应（M3D）框架，这是一种轻量级的非深度转移学习方法，包括流形特征变换、动态分布对齐、分类器学习和集成学习四个核心模块。M3D将数据映射到最优的几何流形空间，实现跨域动态对齐，并优化多种数据集的适应效率。该框架采用结构风险最小化原则构建鲁棒分类模型，并通过动态分布对齐迭代精化分类器。此外，集成学习模块聚合不同优化阶段的分类器，提高预测准确性。实验结果表明，M3D在两个EEG情绪识别数据集上较传统非深度学习方法有4.47%的平均改进，并且在减少数据和计算需求的情况下达到了深度学习水平的表现，展示了其在情感计算应用场景中的潜在价值。", "conclusion": "研究展示了M3D在交叉被试和跨会话的EEG情绪识别中的优越性，并表明该方法具有应用于实际情感计算系统中的潜力。"}
{"llm_update_time": "2025-06-25 09:28:07", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05563", "html_url": "https://arxiv.org/abs/2410.05563", "title": "大规模语言模型中的理性元推理", "title_en": "Rational Metareasoning for Large Language Models", "authors": "C. Nicolò De Sabbata,Theodore R. Sumers,Badr AlKhamissi,Antoine Bosselut,Thomas L. Griffiths", "background": "大型语言模型（LLMs）利用推理来提升任务性能，但随着模型规模和使用量的增加，推理成本也变得越来越高。因此，如何优化推理的成本效益tradeoff成为一个重要问题。现有方法如Few-Shot Chain-of-Thought提示和STaR在降低成本的同时可能会牺牲任务性能，该研究旨在提出一种新的方法来解决这一问题。", "innovation": "提出了一种基于认知科学中的元推理计算模型的新方法，通过训练LLMs在必要时才使用中间推理步骤来优化成本性能tradeoff。这种方法首先引入了结合计算价值的奖励函数以惩罚不必要的推理，然后使用该奖励函数和专家迭代来训练模型。实验证明，与之前的方法相比，新方法可以在保证多样数据集上任务性能的同时显著降低推理成本（三个模型中生成token减少了20-37%）。", "conclusion": "该研究通过引入一个新的基于计算模型的元推理方法，有效降低了大规模语言模型推理的成本，且不影响其任务性能。"}
{"llm_update_time": "2025-06-25 09:28:07", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.00239", "html_url": "https://arxiv.org/abs/2405.00239", "title": "IgCONDA-PET: 弱监督的利用隐式引导注意力条件反事实扩散建模的PET异常检测——一项多中心、多癌种和多示踪剂研究", "title_en": "IgCONDA-PET: Weakly-Supervised PET Anomaly Detection using Implicitly-Guided Attention-Conditional Counterfactual Diffusion Modeling -- a Multi-Center, Multi-Cancer, and Multi-Tracer Study", "authors": "Shadab Ahamed,Arman Rahmim", "background": "在PET成像中，减少对像素级标注数据的依赖，以训练病变检测和分割网络尤为渴望，这在时间和标注专家的成本上有限制的情况下尤为重要。现有的一些无监督或弱监督异常检测方法利用仅健康数据训练的自编码器或生成对抗网络（GANs）进行异常检测，虽然这减少了标注依赖，但基于GAN的方法由于训练两个竞争网络的同时优化、模式崩塌以及训练不稳定性等问题，明显比非GAN方法更难训练。因此，开发一种新的弱监督异常检测方法成为可解决的问题。", "innovation": "本文提出了弱监督的隐式引导注意力条件反事实扩散模型（IgCONDA-PET），该模型使用注意力模块基于图像类别标签（健康 vs 不健康）进行训练，并利用隐式扩散引导进行反事实生成，从而实现“不健康到健康”的领域转换。通过生成不健康输入图像的一个合成健康版本，文中方法可检测异常，并与其它基于深度学习的弱监督或无监督方法以及传统的如SUVmax阈值化方法进行比较。文中强调了在网络中引入注意力模块的重要性，以检测小型异常。该方法已通过来自六个回顾性队列的2652个案例（涵盖多癌种、多示踪剂）进行验证，并公开了其代码。", "conclusion": "IgCONDA-PET在多个基于PET的异常检测方法中表现出优越性，特别是对于小异常的检测，同时简化了训练过程的问题。"}
{"llm_update_time": "2025-06-25 09:28:09", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18469", "html_url": "https://arxiv.org/abs/2410.18469", "title": "ADVLLM：迭代自调优LLM提高越狱能力", "title_en": "ADVLLM: Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities", "authors": "Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao", "background": "最近的研究表明，大型语言模型（LLM）面临着由算法生成的对抗后缀引致的自动化突破攻击的威胁，这些后缀被附加到有害查询中，能够绕过安全对齐并触发意外响应。目前生成这些后缀的方法计算成本高且成功率低，尤其是在针对像Llama2和Llama3这样的高对齐度模型时。", "innovation": "本文引入了ADV-LLM，一种迭代自调优过程，能够生成具有更强大突破能力的对抗性LLM。该框架极大地降低了生成对抗后缀所需的计算成本，同时在多种开源LLM上实现了接近100%的成功率。此外，ADV-LLM展示了强大的攻击可移植性，对闭源模型如GPT-3.5实现了99%的成功率，对GPT-4则达到了49%的成功率，尽管仅在Llama3上进行了优化。除了提高越狱能力外，ADV-LLM还为未来的安全对齐研究提供了宝贵的数据集，用于研究LLM的安全性。", "conclusion": "ADV-LLM显著降低了生成对抗后缀的成本并取得了高成功率，展示了强大的攻击可移植性，并为LLM安全性的研究提供了有价值的数据集。"}
{"llm_update_time": "2025-06-25 09:28:11", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.06555", "html_url": "https://arxiv.org/abs/2409.06555", "title": "窄深度ReLU网络的构造性普遍逼近及其有限样本记忆", "title_en": "Constructive Universal Approximation and Finite Sample Memorization by Narrow Deep ReLU Networks", "authors": "Martín Hernández,Enrique Zuazua", "background": "该研究探讨了深度ReLU神经网络在分类和函数近似任务中的构造性分析。特别地，它研究了如何使用宽度为2且深度最多为$2N + 4M - 1$的多层感知器（MLP）来精确分类任何包含$N$个不同点的$\boldsymbol{R}^d$数据集和$M$个输出类别的数据集。同时，研究还涉及到了非线性离散动力系统的并行可控性问题，并探讨了这些结果如何解释过参数化训练在小正则化参数下的有效性。最后，研究证明了在任何有界区域$\boldsymbol{R}^d$上的$L^p(\boldsymbol{\trueOmega}; \boldsymbol{\trueR_+})$和$L^p(\boldsymbol{\trueOmega}; \boldsymbol{\trueR^m})$空间中，使用宽度为$d + 1$的MLP可以获得普遍逼近效果，提供了具体的深度估计结果。这项研究为理解、解释深度神经网络中的可控性、表现力及训练动力学提供了统一的框架。", "innovation": "该研究的主要创新点包括：1、严格证明使用宽度为2且深度最多为$2N + 4M - 1$的MLP可以精确分类任何数据集；2、提出了一种构造性方法，实现对参数的规范性的统一上界，特别是在正则化参数接近零时，训练网络向精确分类器收敛；3、证明了在$L^p(\boldsymbol{\trueOmega}; \boldsymbol{\trueR_+})$ 和$L^p(\boldsymbol{\trueOmega}; \boldsymbol{\trueR^m})$空间中的一般逼近结果，并提供了与目标函数相关的Sobolev空间中的具体深度估计结果；4、基于此，该研究为深度神经网络的可控性、表现力和训练动态机制提供了统一和可解释的框架。", "conclusion": "该研究提供了深度ReLU网络的构造性通用逼近理论，并探讨了有限样本记忆效应。通过构造性方法和具体估计公式，该研究解释了过参数化训练在小正则化参数下的有效性，并为理解深度神经网络中的表现力、可控性以及训练动态提供了统一的视角，具有重要的理论和应用价值。"}
{"llm_update_time": "2025-06-25 09:28:12", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10154", "html_url": "https://arxiv.org/abs/2411.10154", "title": "连续贝叶斯模型选择在多元因果发现中的应用", "title_en": "Continuous Bayesian Model Selection for Multivariate Causal Discovery", "authors": "Anish Dhir,Ruby Sedgwick,Avinash Kori,Ben Glocker,Mark van der Wilk", "background": "当前因果发现方法在缺乏介入数据的情况下需要严格的模型假设以确保结构可识别性，然而这些假设在实际应用中往往不成立，导致性能较差。在双变量情况下，最近的研究表明，通过贝叶斯模型选择交换严格的模型假设以获得更灵活的假设，可以在极小的错误概率下显著提高性能。本文旨在探讨此方法在多元情况下的适用性。", "innovation": "本文提出了一种基于连续近似离散模型选择问题的可扩展算法。该算法利用因果高斯过程条件密度估计器（CGP-CDE）作为贝叶斯非参数模型，通过其超参数构建邻接矩阵，并通过边缘似然和无环性正则化优化该矩阵，以获得后验最大因果图。这种方法在不使用不合理假设的情况下，实现了多元因果发现，并且展示了其在贝叶斯模型选择下的竞争力和优势。", "conclusion": "本文提出的方法证明了在多元情况下进行因果发现时，贝叶斯模型选择是有用的。这种方法通过利用连续近似离散模型选择问题，并结合因果高斯过程条件密度估计器，能够在无需复杂难以实现的假设的情况下，提高多元因果发现的性能。"}
{"llm_update_time": "2025-06-25 09:28:15", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.02065", "html_url": "https://arxiv.org/abs/2412.02065", "title": "利用大型语言模型为学术研究民主化访问昂贵数据集", "title_en": "Leveraging Large Language Models to Democratize Access to Costly Datasets for Academic Research", "authors": "Julian Junyan Wang,Victor Xiaoqi Wang", "background": "研究人员，尤其是那些来自资源有限的机构的研究人员，长期以来一直受到访问昂贵且常用的实证研究数据集的不平等现象的阻碍。这限制了他们对学术领域做出贡献的能力，并阻碍了他们的职业发展。最近，大型语言模型（LLMs）的突破为通过自动化从非结构化来源收集数据来民主化数据访问提供了可能。", "innovation": "本文介绍了一种新的方法，利用GPT-4o-mini在检索增强生成（RAG）框架中从公司披露中收集数据。该方法在收集来自约10,000份代理声明中的CEO薪酬比例和超过12,000份10-K表格中的关键审计事项（CAMs）方面达到了与人类相当的准确性，LLM处理时间分别为9分钟和40分钟，且每项处理成本低于10美元。这与手动收集数据所需数百小时的时间或商业数据库订阅所需的数千美元形成了鲜明对比。", "conclusion": "为了促进更具包容性的研究社区，本文提出了一个方法并分享了所得数据集，旨在赋予资源有限的研究人员探索新研究领域的动力。"}
{"llm_update_time": "2025-06-25 09:28:17", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02305", "html_url": "https://arxiv.org/abs/2502.02305", "title": "基于信息论的扩散采样证明", "title_en": "Information-Theoretic Proofs for Diffusion Sampling", "authors": "Galen Reeves,Henry D. Pfister", "background": "本文提供了一种基于扩散的生成建模采样方法的初等和独立分析。与现有的依靠连续时间过程并在之后离散化的方法不同，本文直接处理离散时间随机过程，并在广泛假设下提供了精确的非渐近收敛保证。", "innovation": "核心洞见是将感兴趣的采样过程与一个具有显式高斯卷积结构的理想对比过程耦合。通过信息理论中的简单恒等式，包括I-MMSE关系，本文限制了这两个离散时间过程之间差异（以相对于Kullback-Leibler散度而言）。特别是，如果选择足够小的扩散步长并且可以很好地近似某些条件均值估计器，则可以证明采样分布接近目标分布。本文的结果还提供了一种透明的方法，即通过在每一步中使用额外的随机性来匹配对比过程中的更高阶矩，以加速收敛。", "conclusion": "本文的结果在广义假设下提供了精确的非渐近收敛保证，并提供了加速收敛的透明方法。"}
{"llm_update_time": "2025-06-25 09:28:18", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19918", "html_url": "https://arxiv.org/abs/2502.19918", "title": "Meta-Reasoner: 动态指导以优化大型语言模型推理期间的推理过程", "title_en": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models", "authors": "Yuan Sui,Yufei He,Tri Cao,Simeng Han,Yulin Chen,Bryan Hooi", "background": "大型语言模型（LLMs）越来越多地依赖于长时间的推理链来解决复杂任务。然而，这种试错方法会导致高计算开销和错误传播，早期的错误可能会影响后续步骤。", "innovation": "提出了一种名为Meta-Reasoner的框架，通过使LLMs能够'思考如何思考'来动态优化推理时的推理过程。该框架借鉴了人类元认知和双过程理论，作为战略顾问，分离高级指导和逐步生成。它使用上下文多臂博弈来迭代评估推理进展并选择最优策略（例如：回溯、澄清歧义、从头开始或提出替代方法），并将计算资源重新分配到最具潜力的方向上。", "conclusion": "对数学推理和谜题的评估表明，动态推理链有潜力克服LLMs推理过程中固有的挑战，并且在更广泛的领域中显示出前景，提供了具有可扩展性和适应性的推理密集型任务解决方案。"}
{"llm_update_time": "2025-06-25 09:28:19", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21719", "html_url": "https://arxiv.org/abs/2410.21719", "title": "Vendi 评分在有限样本下收敛吗？有限样本收敛保证的截断Vendi评分", "title_en": "Do Vendi Scores Converge with Finite Samples? Truncated Vendi Score for Finite-Sample Convergence Guarantees", "authors": "Azim Ospanov,Farzan Farnia", "background": "生成模型的多样性评估在没有参考数据的情况下提出了方法学挑战。为此，引入了无参考的Vendi和RKE评分，通过矩阵熵测度量化生成数据的多样性。Vendi评分通常通过构建包含n个生成样本的$n \times n$核矩阵的特征值分解来计算，但在处理大量样本（通常少于20,000个）时，特征值分解的高昂计算成本限制了这种做法的应用。已有研究表明，在有限样本规模下，Vendi评分的值可能不收敛到其在无限采样下的极限值。为了解决这一问题，本文调查了有限样本规模下Vendi和RKE评分的统计收敛性，并引入了截断Vendi评分（$t$-truncated Vendi score）以确保其在$n=\tilde{O}(t)$样本下收敛到其总体极限。同时，我们证明现有的Nyström和FKEA近似方法也能收敛到截断Vendi评分的极限值。相比之下，RKE评分在所有核函数下的收敛性是无条件的。我们通过数值实验展示了Nyström和FKEA计算出的Vendi评分集中在截断Vendi评分附近，并分析了截断Vendi和RKE评分与图像和文本数据多样性的相关性。研究结果的代码在https://github.com/dbaoladdress 可获取", "innovation": "本文提出了在有限样本规模下确保收敛的截断Vendi评分。同时，论文证明了现有的Nyström和FKEA近似方法可以收敛到截断Vendi评分的极限值，并证明了RKE评分在所有核函数下的收敛性是无条件的。通过数值实验展示了现有方法的适用性和准确性。", "conclusion": "本文通过引入截断Vendi评分确保了在有限样本下Vendi评分的收敛性，证明了Nyström和FKEA近似方法的适用性，并展示了RKE评分在所有核函数下的无条件收敛性。"}
{"llm_update_time": "2025-06-25 09:28:20", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05169", "html_url": "https://arxiv.org/abs/2502.05169", "title": "利用对称性提高计算效率的翻转策略：Flopping for FLOPs", "title_en": "Flopping for FLOPs: Leveraging equivariance for computational efficiency", "authors": "Georg Bökman,David Nordström,Fredrik Kahl", "background": "引入几何不变性到神经网络可以提高参数效率，但通常会增加计算成本。现有方法虽能保持对称性，但计算成本较高。本研究聚焦于在计算机视觉任务中常见的水平镜像不变性，旨在设计新的对称性保持的神经网络，同时保持与标准非对称网络相当的浮点运算次数(FLOPs)。", "innovation": "提出了一种新的对称性神经网络，通过参数化特征空间为镜面对称和镜面反对称特征，即翻转组的不可约表示，将线性层分解为对角化块矩阵组，从而减少所需浮点运算次数，达到减少FLOPs和实际运行时间的目的，为高效的可扩展对称性感知架构提供了解决方案。", "conclusion": "该研究通过利用对称性减少计算成本，提供了既有FLOPs减少又有实际运行时间优化的高效实施方案。"}
{"llm_update_time": "2025-06-25 09:28:21", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02514", "html_url": "https://arxiv.org/abs/2502.02514", "title": "Image AutoRegressive Models中的隐私攻击", "title_en": "Privacy Attacks on Image AutoRegressive Models", "authors": "Antoni Kowalczuk,Jan Dubiński,Franziska Boenisch,Adam Dziedzic", "background": "图像自回归生成已经成为一种新而强大的范式，图像自回归模型（IARs）在图像质量（FID：1.48 vs. 1.58）上与扩散模型（DMs）相当，同时允许更快的生成速度。然而，IARs相关的隐私风险尚未被研究，引起了对其负责任使用的担忧。研究者们旨在填补这一空白，通过全面分析IARs的隐私风险，与DMs的隐私风险进行了比较。", "innovation": "研究团队开发了一种新颖的成员归属推断攻击（MIA），在检测训练图像时取得了显著的高成功率（True Positive Rate at False Positive Rate = 1% 的情况下，86.38% vs. 6.38%），并且利用这种方法，他们能够比DMs的dataset inference（需要200个样本）少至6个样本就检测到数据集成员。这证明了IARs比DMs具有更高的信息泄露度。此外，他们还成功从IARs中提取了数百个训练数据点，例如从VAR-d30中提取了698个。研究结果表明，尽管IARs在图像生成质量和速度上表现出色，但在隐私攻击方面比达到相似性能的DMs要脆弱得多。", "conclusion": "研究结果表明，IARs和DMs之间存在基本的隐私性-实用性权衡：虽然IARs在图像生成质量和速度上表现出色，但在隐私攻击方面的脆弱性却显著高出类比的DMs。该研究还提供了可复现的代码，以确保结果的可验证性。"}
{"llm_update_time": "2025-06-25 09:28:21", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02690", "html_url": "https://arxiv.org/abs/2502.02690", "title": "具有可证明分离性的可控视频生成", "title_en": "Controllable Video Generation with Provable Disentanglement", "authors": "Yifan Shen,Peiyuan Zhu,Zijian Li,Shaoan Xie,Zeyu Tang,Namrata Deka,Zongfang Liu,Guangyi Chen,Kun Zhang", "background": "尽管最近在生成高质量和一致性的视频方面取得了进展，但可控视频生成仍然是一个重大挑战。现有的方法通常将视频作为一个整体进行处理，忽略了精细的空间-时间关系，这限制了控制精度和效率。因此，需要一种能够独立控制视频中各个概念的方法，以实现高效且有针对性的控制。", "innovation": "本文提出了一种可控视频生成对抗网络（CoVoGAN），通过分离视频概念，实现针对单个概念的高效且独立控制。具体而言，采用最小变化原则，首先分离静态和动态潜在变量，然后利用充分变化性质，实现动态潜在变量的组件特定不可混性，从而实现视频生成的分离控制。为了建立理论基础，本文提供了严谨的分析，证明了方法的可识别性。在此基础上设计了时间转换模块来分离潜在动态机制。为确保最小变化原则和充分变化性质，通过降低潜在动态变量的维度并引入时间条件独立性来实现。", "conclusion": "通过将该模块作为生成对抗网络（GAN）的插件，本文在多种视频生成基准上的严格定性和定量实验中证明，该方法显著提高了生成质量和可控性，适用于各种实际场景。"}
{"llm_update_time": "2025-06-25 09:28:23", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.16490", "html_url": "https://arxiv.org/abs/2501.16490", "title": "在数据限制和对抗挑战下的智能电网鲁棒稳定性预测：基于GAN的方法", "title_en": "Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges", "authors": "Emad Efatinasab,Alessandro Brighente,Denis Donadel,Mauro Conti,Mirco Rampazzo", "background": "智能电网对于满足因全球人口增长和城市化驱动的不断增长的能源需求至关重要。通过整合可再生能源，智能电网可以提高效率、可靠性和可持续性。确保其可用性和安全性需要先进的运行控制和安全保障措施。人工智能和机器学习可以有助于评估电网稳定性，但数据稀缺性和网络安全威胁（尤其是恶意攻击）仍然是挑战。数据的稀缺性是关键问题之一，因为获取电网不稳定的真实世界案例需要大量专业技能、资源和时间，但这些都是测试新研究进展和安全缓解措施所必需的。这使得智能电网在培训阶段获取不稳定数据非常困难。因此，需要一种新的数据策略来解决这一问题。", "innovation": "本文提出了一种新颖的框架，该框架仅采用稳定数据来检测智能电网中的不稳定性。该框架使用生成对抗网络（GAN），其中生成器设计用于生成与稳定类别不符的异常样本（Out-Of-Distribution samples），代表不稳定行为、异常或偏离稳定数据分布的干扰事件。通过仅在稳定数据上进行训练，并将辨别器暴露于异常样本，该框架学会了从稳定条件区分任何不稳定的边界，而不需要在训练期间使用不稳定数据。此外，本研究还引入了对抗训练层以增强对攻击的抗性。在实际数据集上评估表明，该解决方案在预测电网稳定性方面的准确率高达98.1%，在检测恶意攻击方面的准确率高达98.9%。该实现可以在单板计算机上运行，平均响应时间低于7ms，实现了实时决策。", "conclusion": "本研究提出了一种新的基于GAN的框架，仅使用稳定数据来检测智能电网的不稳定性。该方法通过对抗训练学习稳健的决策边界，以区分稳定状态和不稳定的任何行为。在实际数据集上的实验证明了该方法的有效性，尤其是在预测电网稳定性和检测恶意攻击方面。此外，该实现还展示了实时决策的能力，平均响应时间低于7ms。"}
{"llm_update_time": "2025-06-25 09:28:26", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03784", "html_url": "https://arxiv.org/abs/2504.03784", "title": "大型语言模型微调的鲁棒人反馈强化学习", "title_en": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning", "authors": "Kai Ye,Hongyi Zhou,Jin Zhu,Francesco Quinzan,Chengchun Shi", "background": "强化学习从人类反馈（RLHF）已成为使大型语言模型（LLMs）的输出与人类偏好一致的关键技术。目前，大多数RLHF算法使用Bradley-Terry模型，但该模型依赖于人类偏好的假设，这些假设可能无法反映现实判断的复杂性和变异性。因此，在这样的奖励模型不准确的情况下，现有方法的鲁棒性受到挑战。本文正是在这一背景下，提出了一种鲁棒算法以解决上述问题并提高性能。", "innovation": "论文提出了一个能在奖励模型不准确的情景下提升现有方法性能的鲁棒算法。该算法从理论上减少了奖励和策略估计器的方差，从而改善了遗憾界。实验结果表明，该算法在Anthropic Helpful and Harmless数据集上的一致性表现优于现有方法，有77-81%的响应优于基线。", "conclusion": "提出的算法在大型语言模型的细调中表现出了更好的性能，特别是在奖励函数估计不准确的情况下。"}
{"llm_update_time": "2025-06-25 09:28:26", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09730", "html_url": "https://arxiv.org/abs/2503.09730", "title": "循环验证器服务器端局部前瞻引导以自动定理证明", "title_en": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving", "authors": "Sara Rajaee,Kumar Pratik,Gabriele Cesa,Arash Behboodi", "background": "最具有前景的人工智能推理方法通常依赖于强化学习（RL）的变体，这些变体可能在从大型语言模型中滚动出轨迹或大量手工标注的轨迹数据时使用。然而，这种依赖滚动出的轨迹会导致计算成本和时间变得难以承受。此外，给定的推理轨迹的正确性通常只有在其完成时才能被判断，导致在RL中只有稀疏的奖励反馈，或者需要进行昂贵的合成数据生成。本文关注自动定理证明任务，探讨了现有方法的问题之处，这些问题在使用整个推理轨迹评价的同时也会引入计算瓶颈，并且无法在推理中原始层级提供反馈。", "innovation": "本文提出的创新之处在于引入了一个新的“循环验证器设计”，即verifier-in-the-loop。这一设计不同于现有方法依赖整个推理轨迹的反馈，转而通过在推理过程中的每个步骤提供自动化的中间反馈来解决上述问题。研究人员使用Lean作为验证器，通过实验证明每个步骤的局部验证能带来模型推理准确性和效率的全球提升，从而改善自动定理证明任务的整体性能和效率。", "conclusion": "综上所述，本文提出了一种全新的“循环验证器设计”，通过在自动定理证明中引入局部验证，解决了传统方法在计算效率和反馈及时性上的不足。该设计通过揭示每个步骤的局部正确性，实现了对整个推理过程的优化，从而有效地提高了模型的推理能力和效率。"}
{"llm_update_time": "2025-06-25 09:28:28", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.09529", "html_url": "https://arxiv.org/abs/2505.09529", "title": "使用事件摄像机的无接触心率监测", "title_en": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "authors": "Mohamed Moustafa,Joseph Lemley,Peter Corcoran", "background": "时间事件摄像机是一种新型技术，能够以极低延迟和低功耗记录场景信息。事件摄像机输出包含场景中像素级光照强度变化的事件流，这种技术比传统的摄像机具有更高的动态范围和时间分辨率。本研究旨在通过监督卷积神经网络（CNN）模型，无接触地从面部的时间事件记录中重建个体的心脏脉冲信号。实验结果显示，面部区域的生理心脏信息在事件流中得到有效保存，展示了这种新型传感器在远程心率监测中的潜在应用价值。", "innovation": "研究通过使用事件摄像机记录面部信息，训练了监督卷积神经网络模型来无接触地监测心脏脉冲信号。模型表现基于计算的心率准确性进行评估，实验表明，与传统摄像机相比，基于事件帧训练的模型能够实现更低的心率误差，特别是在不同帧率条件下，模型表现更为优越，进一步验证了事件摄像机在远程心率监测中的应用潜力。", "conclusion": "研究表明，时间事件摄像机能够有效地保存面部区域的生理心脏信息，并且其基于事件帧训练的模型相比于标准摄像机训练的模型，具有更低的心率误差。特别是，在不同的帧率条件下，基于事件帧训练的模型表现更为优越，再次强调了事件摄像机在无接触心率监测中的潜力。"}
{"llm_update_time": "2025-06-25 09:28:29", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11302", "html_url": "https://arxiv.org/abs/2504.11302", "title": "极限族集合的离散能量", "title_en": "Limits of Discrete Energy of Families of Increasing Sets", "authors": "Hari Sarang Nathan", "background": "该研究探讨了通过里斯能量来检测集合的豪斯多夫维度的方法。研究者还考虑了一组点序列{xn}如何按某种适当的方式填充集合E，并研究了这些点集的离散版本的里斯能量如何用于估算集合E的豪斯多夫维度。此外，研究还涉及数据科学和埃德华德斯/法尔康纳类型问题的应用。", "innovation": "研究通过点序列的填充过程探讨了使用里斯能量的离散版本来估计豪斯多夫维度的新方法，并将其应用于数据科学和特定的数学问题中。这种创新方法为理解复杂点集的几何性质提供了新的视角。", "conclusion": "研究表明，通过研究点序列的里斯能量可以有效地估计集合的豪斯多夫维度。这一发现不仅在理论上扩展了离散能量的研究范围，也为数据科学等领域提供了新的分析工具。"}
{"llm_update_time": "2025-06-25 09:28:30", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.06108", "html_url": "https://arxiv.org/abs/2501.06108", "title": "使用神经网络推断高阶耦合", "title_en": "Inferring Higher-Order Couplings with Neural Networks", "authors": "Aurélien Decelle,Alfonso de Jesús Navas Gómez,Beatriz Seoane", "background": "最大熵方法源于统计物理中的伊辛/波色-温特兹模型问题，广泛应用于生物信息学和神经科学等学科中复杂的系统建模。尽管这些方法在捕捉二阶相互作用方面取得了成功，但它们往往无法捕捉更高级的相互作用，而更高级的相互作用对于理解集体行为至关重要。相比之下，现代机器学习方法可以建模这些高级相互作用，但其可解释性通常会导致计算成本过高。受限玻尔兹曼机（RBM）通过在二部架构中使用隐藏单元来编码统计相关性，提供了一种计算效率更高的替代方案。本文提出了一种方法，将RBM映射到广义波色-温特兹模型，从而能够系统地提取任意阶次的相互作用。利用RBM结构使得大N近似变得可行，我们通过最小的计算努力提取出有效的多体耦合。此外，提出了一个健壮框架以在更复杂的生成模型中恢复更高级的相互作用，并引入了有效波色-温特兹表示的简单固定方案。在合成数据上的验证结果显示，二体和三体相互作用能够被准确地恢复。应用于蛋白质序列数据时，该方法能重建具有高忠实度的接触图，并且优于最先进的逆波色-温特兹模型。这些结果确立了RBM作为模型高阶结构的高维分类数据的强大且高效的工具。", "innovation": "提出了一种将受限玻尔兹曼机（RBM）映射到广义波色-温特兹模型的高效方法，该方法能够系统地提取任意阶相互作用。利用RBM的结构，通过大N近似提取出了有效的多体耦合，并提出了一种简单的方法来处理有效的波色-温特兹表示的固定方案。这种方法不仅能准确地恢复二体和三体相互作用，还能应用于蛋白质序列数据，重建具有高忠实度的接触图，且优于现有的逆波色-温特兹模型。", "conclusion": "RBM成为高维分类数据中建模高阶结构的强大且高效的工具。这种方法通过提供更有效的建模方法，增加了对复杂数据中更高阶相互作用的理解。"}
{"llm_update_time": "2025-06-25 09:28:32", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23436", "html_url": "https://arxiv.org/abs/2505.23436", "title": "资源约束下理性代理的新兴风险意识", "title_en": "Emergent Risk Awareness in Rational Agents under Resource Constraints", "authors": "Daniel Jarne Ornia,Nicholas Bishop,Joel Dyer,Wei-Chen Lee,Ani Calinescu,Doyne Farmer,Michael Wooldridge", "background": "本文研究了具备代理能力的先进推理模型（AI代理）如何与人类互动，并解决在(近似)效用函数和内部模型下具有资源或故障约束的顺序决策问题。当行动序列因资源耗尽而被迫终止时，代理面临着效用驱动（理性）行为的隐式权衡。此外，由于这些代理通常由人类委托人代为行事，由此可能会产生人类目标和代理激励之间的不匹配情况，特别是在约束暴露存在不对称性的情况下。研究通过生存bandit框架正式化了这一设定，并提供了理论和实证结果以评估生存驱动偏好变化的影响，同时确定了不匹配出现的条件以及提出减轻风险寻求或风险厌恶行为出现的机制。", "innovation": "文章通过生存bandit框架正式化了资源约束下代理行为的设定，并深入研究了生存驱动下偏好变化的影响。识别了不匹配出现的条件，并提出了缓解机制。这填补了在资源受限环境下，代理行为风险意识理解和实现的空白，增强了对于安全部署此类AI系统的指导原则构建。", "conclusion": "本文旨在增加对在生存压力下AI代理行为的 emergent 行为的理解和可解释性，并提供了在关键资源受限环境下的安全部署此类AI系统的指南。"}
{"llm_update_time": "2025-06-25 09:28:33", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16901", "html_url": "https://arxiv.org/abs/2505.16901", "title": "Code Graph Model (CGM): 一种用于仓库级软件工程任务的图集成大型语言模型", "title_en": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "authors": "Hongyuan Tao,Ying Zhang,Zhenhao Tang,Hongen Peng,Xukun Zhu,Bingchang Liu,Yingguang Yang,Ziyin Zhang,Zhaogui Xu,Haipeng Zhang,Linchao Zhu,Rui Wang,Hang Yu,Jianguo Li,Peng Di", "background": "最近大型语言模型（LLMs）在函数级代码生成方面显示出了前景，但在仓库级软件工程任务方面仍然具有挑战性。当前解决方案大多依赖于专有的LLM代理，这引入了不可预测性和限制了可访问性，引起了对数据隐私和模型定制的担忧。本文探讨了是否有无需使用代理的方法，通过开放源代码LLM有效解决仓库级任务的可行性。文章通过让LLM理解代码库中的函数和文件的语义信息及其结构依赖性来实现这一目标。", "innovation": "本文提出了Code Graph Models (CGMs)，这是一种将仓库代码图结构集成到LLM的注意力机制中的方法，并通过一个特化的适配器将节点属性映射到LLM的输入空间。将CGMs与无代理的图RAG框架结合起来，这种方法使用开放源代码Qwen2.5-72B模型在SWE-bench Lite基准测试中的解决方案率为43.00%，在开放权重模型中排名第一，开源系统方法中排名第二，整体排名第八，超越了之前最好的开放源代码模型基线方法12.33%。", "conclusion": "这种方法证明了无需使用代理的开放源代码LLMs可以在仓库级任务中有效发挥作用，展示了CGMs在解决仓库级软件工程任务方面的潜力。"}
{"llm_update_time": "2025-06-25 09:28:34", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10049", "html_url": "https://arxiv.org/abs/2506.10049", "title": "演化业务流程的在线模拟模型发现（扩展版本）", "title_en": "Online Discovery of Simulation Models for Evolving Business Processes (Extended Version)", "authors": "Francesco Vinci,Gyunam Park,Wil van der Aalst,Massimiliano de Leoni", "background": "BPS指的是用于复制商业过程动态行为的技术。已有技术能够自动从历史事件日志中发现仿真模型，降低了手动设计模型的成本和时间。然而，在动态的业务环境中，组织不断改进其流程以提高效率、降低成本和提升客户满意度，现有的流程仿真发现技术缺乏对实时运营变化的适应性。", "innovation": "本文提出了一种集成增量过程发现和在线机器学习的流式过程仿真发现技术。该技术强调近期数据的同时保留历史信息，确保能够适应不断演变的过程动态。实验结果表明，这种方法不仅生成了更稳定的仿真模型，而且在处理概念漂移方面也表现出良好的鲁棒性，特别是在一个用例中得到了验证。", "conclusion": "研究结果证明，在模拟中更重视近期数据而保留历史知识非常重要。提出的流式过程仿真发现技术不仅能够生成更稳定的仿真模型，还能够更好地处理动态变化，具有较高的实际应用潜力。"}
{"llm_update_time": "2025-06-25 09:28:34", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06609", "html_url": "https://arxiv.org/abs/2506.06609", "title": "语言模型间通过模型缝合转移特征", "title_en": "Transferring Features Across Language Models With Model Stitching", "authors": "Alan Chen,Jack Merullo,Alessandro Stolfo,Ellie Pavlick", "background": "本文探讨了通过仿射映射在语言模型的残差流之间转换表示特征的可行性，并应用这种技术将稀疏自编码器（SAEs）的权重在不同大小的语言模型之间进行转移以进行比较其表示。研究发现，小型和大型语言模型学习相似的表示空间，这进一步启发可以通过在小型模型上训练昂贵组件，然后转移到大型模型以节省FLOPs资源。研究还表明转移探针和控制向量可以有效地恢复真实性能，并且在特征层级转移上展示了不同的特征转移特征，特定类型的功能特征在其功能角色上具有忠实映射。", "innovation": "本文创新性地提出了一种通过仿射映射在语言模型之间转移特征的新方法，特别是将小型模型训练的SAEs转移到大型模型上可以节省50%的训练资源。此外，研究还验证了转移探针和控制向量能够有效恢复真实性能，并且在特征层级转移上展示了馈入特定类型的功能特征在其角色映射上的忠实性。", "conclusion": "本文的研究成果展示了小型和大型语言模型之间线性表示空间的相似性和差异，提出了一种提高SAEs训练效率的方法。通过模型缝合法，小型模型中训练的昂贵组件可以直接转移到大型模型中，节省计算资源，从而提高语言模型的训练效率。"}
{"llm_update_time": "2025-06-25 09:28:35", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14561", "html_url": "https://arxiv.org/abs/2505.14561", "title": "SSPS: 自监督正样本采样用于稳健的自监督说话人验证", "title_en": "SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification", "authors": "Theo Lepage,Reda Dehak", "background": "自监督学习（SSL）在说话人验证（SV）方面取得了显著进展。传统的框架使用同一言语的相同说话人样本来生成正样本，同时使用数据增强方法来生成同说话人的锚样本。但这种方法的主要局限在于，它主要编码了录音条件下的信道信息，而这些条件是锚样本和正样本所共有的，这限制了SV性能的提升。因此，本文提出了一个新的正样本采样技术以解决这一瓶颈：自监督正样本采样（SSPS）。SSPS旨在为给定的锚样本找到一个合适的正样本，即相同说话人身份但不同录音条件的样本，在潜在空间中利用聚类分配和正面嵌入记忆队列来实现这一目标。这种方法提高了SimCLR和DINO在SV上的表现，达到了2.57%和2.53%的EER，超越了VoxCeleb1-O上的最新SSL方法。特别是，SimCLR-SSPS通过降低微生物内说话人方差，降低了58%的EER，从而与DINO-SSPS提供了可比的性能表现。", "innovation": "提出了自监督正样本采样（SSPS）技术，通过寻找不同录音条件下的相同说话人样本来改进说话人验证性能。这种方法利用聚类分配和正面嵌入记忆队列在潜在空间中操作，从而避免了传统方法对共享录音条件的限制。实验结果表明，该方法显著提高了SimCLR和DINO在说话人验证任务上的性能，特别是在VoxCeleb1-O数据集上超越了其他最新SSL方法。", "conclusion": "通过引入自监督正样本采样（SSPS）技术，该研究在自监督说话人验证任务上取得了显著进展，展示了其在降低说话人内方差和提高系统表现方面的优势。"}
{"llm_update_time": "2025-06-25 09:28:37", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14950", "html_url": "https://arxiv.org/abs/2506.14950", "title": "条件矩约束的双重机器学习方法：工具变量回归、近邻因果学习及其他", "title_en": "Double Machine Learning for Conditional Moment Restrictions: IV Regression, Proximal Causal Learning and Beyond", "authors": "Daqian Shao,Ashkan Soleymani,Francesco Quinzan,Marta Kwiatkowska", "background": "条件矩约束（CMRs）是统计学、因果推理和计量经济学中的关键问题，目标是找到满足某些条件矩等式的函数。传统的CMR估算方法使用两阶段方程，但在第一阶段的估算直接插入第二阶段时会引起严重的偏差，尤其是在使用深度神经网络（DNN）进行两阶段估计的情况下。作者提出了DML-CMR算法，这是一种双重CMR估算方法，提供了无偏差估计，并且收敛速度较快。研究结果表明，DML-CMR能够在样本量较大时实现最优收敛速度。", "innovation": "提出了DML-CMR两阶段CMR估计算法，在双层正则化框架下设计了一个新的学习目标，用于减少偏差。经过验证，DML-CMR算法在使用条件矩约束进行工具变量回归和近邻因果学习时能够实现最先进的性能，具有减小偏差和获得快速收敛速度的优点。", "conclusion": "通过引入新的学习目标和遵循双重正则化框架，DML-CMR能够在样本量较大时实现无偏估计和最优收敛速度。在实际数据集上，DML-CMR在进行工具变量回归和近邻因果学习时，性能超过了现有的CMR估算器和其他针对这些问题设计的算法。"}
{"llm_update_time": "2025-06-25 09:28:38", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14920", "html_url": "https://arxiv.org/abs/2506.14920", "title": "Q2SAR：用于药物发现的量子多重核学习方法", "title_en": "Q2SAR: A Quantum Multiple Kernel Learning Approach for Drug Discovery", "authors": "Alejandro Giraldo,Daniel Ruiz,Mariano Caruso,Javier Mancilla,Guido Bellomo", "background": "定量结构活性关系（QSAR）建模是计算药物发现中的基石。这项研究展示了将量子多重核学习（QMKL）框架成功应用于增强QSAR分类，其性能显著优于传统方法，并应用于识别DYRK1A激酶抑制剂的数据集。该工作流包括将SMILES表示转换为数值分子描述符，通过主成分分析（PCA）降低维度，以及使用在多个量子和经典核优化组合上训练的支持向量机（SVM）进行分类。", "innovation": "提出了使用量子多重核学习（QMKL）框架的QSAR建模方法，通过将经典核与量子核结合来提高QSAR分类的性能，并通过与传统梯度增强模型进行基准测试，展示了量子增强方法在复杂化学信息分类任务中的优越性。", "conclusion": "通过与经典梯度增强模型进行基准测试，研究证明了量子增强的QMKL-SVM方法在识别DYRK1A激酶抑制剂数据集上实现了更好的AUC分数，表明其在计算药物发现中的量子优势。"}
{"llm_update_time": "2025-06-25 09:28:41", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14293", "html_url": "https://arxiv.org/abs/2506.14293", "title": "SLEEPING-DISCO 9M：用于生成音乐建模的大规模预训练数据集", "title_en": "SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling", "authors": "Tawsif Ahmed,Andrej Radonjic,Gollam Rabby", "background": "目前，生成音乐建模任务（如文本-音乐、音乐配图、歌声合成、旋律重构和跨模态检索）缺乏高质量的数据集来表示流行且知名的歌曲。过去的研究集中在孤立和受限的因素上，创建合成或重新录制的音乐数据集（例如 GTSinger、M4Singer），或大规模的音频数据集（例如 DISCO-10M 和 LAIONDISCO-12M）。然而，这些数据集在生成音乐社区中的采用率不高，因为它们未能反映现实生活中的音乐和其风格特点。因此，研究团队创建了一个使用实际流行音乐和世界级艺术家的数据集来改变这一现状，以满足生成音乐建模任务的需求。", "innovation": "该研究提出了一种名为 Sleeping-DISCO 9M 的大型预训练数据集，专门用于音乐和歌曲的生成模型。该数据集利用了实际的流行音乐和世界知名艺术家的作品，而以往的数据集则大多基于合成或重新录制的音乐或大规模但缺乏代表性的音频数据，这使得 Sleeping-DISCO 9M 在音乐建模任务中能够更好地反映现实世界的音乐和其风味特点，从而提供更好的数据支持。", "conclusion": "Sleeping-DISCO 9M 提供了一个基于实际流行音乐和知名艺术家的作品构建的数据集，它改变了现有数据集未能反映真实世界音乐及其风味的现状，为生成音乐模块建立了更好的数据基础。"}
{"llm_update_time": "2025-06-25 09:28:41", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15961", "html_url": "https://arxiv.org/abs/2506.15961", "title": "TrainVerify：基于等价性验证的分布式大语言模型训练", "title_en": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training", "authors": "Yunchi Lu,Youshan Miao,Cheng Tan,Peng Huang,Yi Zhu,Xian Zhang,Fan Yang", "background": "大规模训练大语言模型（LLMs）需要在成千上万的设备上并行执行，这带来了巨大的计算成本。然而，这些昂贵的分布式训练很少会被验证，这使得它们容易出现未察觉的错误，并可能导致数百万的GPU时耗浪费。因此，训练和验证过程之间的不一致可能会导致资源的无效使用甚至潜在的模型错误。", "innovation": "TrainVerify提出了一个系统，用于验证分布式并行执行计划与给定的深度学习模型逻辑规范之间的数学等价性。为了应对大规模LLMs带来的复杂性，TrainVerify引入了形状约简技术和阶段式并行验证算法，这能够在保持正式正确性的同时显著降低复杂性。这项技术可以扩展到前沿的大规模LLMs，并成功验证了Llama3（405B）和DeepSeek-V3（671B）的训练计划。", "conclusion": "TrainVerify通过正式验证分布式并行执行计划与逻辑规格的数学等价性，显著减少了训练过程中的资源浪费和潜在错误。这种方法不仅适用于Llama3和DeepSeek-V3等大规模模型，还展示了在大规模分布式训练中增强验证能力的重要性。"}
{"llm_update_time": "2025-06-25 09:28:46", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19425", "html_url": "https://arxiv.org/abs/2506.19425", "title": "在-function调用图-变化的背景下什么是最佳分解？探索二进制分解", "title_en": "What Makes the Best Decomposition? Investigating Binary Decomposition Under FCG Variance", "authors": "Ang Jia,He Jiang,Zhilei Ren,Xiaochen Li,Ming Fan,Ting Liu", "background": "现有的二进制分解工作主要通过基于锚点的方法（通过扩展锚点函数生成模块）或基于聚类的方法（使用聚类算法分组二进制函数）来进行，在这两种方法中，都假设重复使用的代码共享相似的功能调用关系。然而，研究发现，使用不同的编译设置时，函数调用图（FCGs）变化较大，特别是当有不同的函数内联决策时，这些变化对二进制分解方法的效果有显著影响。这项工作中，他们首次系统地研究了各种编译设置下FCGs的变化及其对二进制分解方法的影响，并通过构建包含17个编译器的FCGs数据集进行分析。", "innovation": "这项工作首次对不同编译设置下的FCGs变化进行系统性研究，并探索其对二进制分解方法的影响。研究结果表明，现有的工作在面对不同优化设置下的交叉编译器评估时面临着巨大挑战。此外，研究提出了一种识别最优分解方法的方法，并与现有分解方法进行了对比，结果显示现有的方法要么覆盖率低，要么无法生成稳定的社区相似性。", "conclusion": "现有的二进制分解方法在面对不同的编译设置，特别是大小变化显著的FCGs时，结果不稳定。研究揭示了这种变化对现有二进制分解方法的挑战，并提出了一种识别最优分解方法的方法。"}
{"llm_update_time": "2025-06-25 09:28:47", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19287", "html_url": "https://arxiv.org/abs/2506.19287", "title": "利用LLMs进行路径感知符号执行以生成和理解测试", "title_en": "Generating and Understanding Tests via Path-Aware Symbolic Execution with LLMs", "authors": "Yaoxuan Wu,Xiaojie Zhou,Ahmad Humayun,Muhammad Ali Gulzar,Miryung Kim", "background": "符号执行是一种广泛用于测试生成的技术，能够系统地探索程序路径。然而，它受限于对目标代码（包括库函数）的符号约束建模能力以及基础约束求解器的能力，导致许多涉及复杂特征的路径未能充分分析或建模。虽然大规模语言模型（LLMs）已在生成多样且有效的测试输入方面显示出潜力，但它们缺乏系统地列举程序路径的机制，常常未能覆盖微妙的边缘情况。直接将完整程序提示LLM会导致感兴趣的路径覆盖率不足的问题。", "innovation": "本文介绍了一种结合路径感知符号执行和LLM辅助测试生成的测试生成系统PALM。PALM通过AST层级分析静态列举可能的路径，并将每个路径转化为可执行变体，其中包含用来指明目标路径的断言语句。这避免了将路径约束转换为SMT公式的需求，而是构建了LLM可以解释的程序变体。PALM是首个提供交互式前端的系统，该前端可以可视化生成测试的路径覆盖率，通过验证和可视化路径概况帮助用户理解路径覆盖率并识别哪些路径被PALM生成的测试实际执行。", "conclusion": "通过用户研究显示，PALM的前端有助于用户更好地理解路径覆盖率以及识别哪些路径被PALM生成的测试实际执行。"}
{"llm_update_time": "2025-06-25 09:28:47", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19153", "html_url": "https://arxiv.org/abs/2506.19153", "title": "支持Solidity编译器研究的Yul合约数据集", "title_en": "Dataset of Yul Contracts to Support Solidity Compiler Research", "authors": "Krzysztof Fonal", "background": "当前市场上存在大量的基于Solidity语言部署在以太坊主网上实际运行的智能合约，但专门专注于Yul中间语言的智能合约数据集却相对稀缺，这限制了智能合约底层代码在各个领域的研究应用，如机器学习、形式验证、优化分析以及软件工程工具的评价等。因此，建立一个专门针对Yul的智能合约数据集对于补充现有的智能合约数据生态至关重要，将推动智能合约在底层代码分析和生成方面的研究工具的发展和创新应用。", "innovation": "YulCode数据集是首个也是唯一一个专注于Yul语言的公开数据集。Yul作为以太坊虚拟机（EVM）设计的中间语言，用于生成智能合约的基础代码。该数据集提供了多样化的研究基础，包括但不限于机器学习应用、形式验证、优化分析和软件工程工具评估，这将促进对低层级智能合约代码的研究和开发工作，并填补当前智能合约数据生态系统中的关键空白，开辟新的研究和工具开发方向，旨在对智能合约进行深层分析和生成。", "conclusion": "YulCode数据集不仅填补了当前智能合约数据生态系统的空白，还为研究者提供了直接反映实际应用的智能合约实例，有利于促进基于Yul语言的智能合约在低层代码层面的深入研究，推动相关技术的发展与应用。"}
{"llm_update_time": "2025-06-25 09:28:47", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16297", "html_url": "https://arxiv.org/abs/2506.16297", "title": "SycnMapV2：具有适应性和鲁棒性的无监督分割算法", "title_en": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation", "authors": "Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas", "background": "人类视觉在不需要显性训练的情况下能够有效地分割视觉线索，并且即使在噪声严重增加的情况下也表现出惊人的鲁棒性。相比之下，现有的人工智能算法在类似条件下难以保持准确性。人类视觉通过自我组织的动力学方程和随机网络的概念来实现这一点，这与传统的需要重新初始化的方法不同。SyncMapV2 在数字破坏下只有 0.01% 的 mIoU 下降，这比 SOTA 方法的 23.8% 下降显著得多。这种出色的表现适用于各种类型的破坏：噪声、天气和模糊，表现分别优于 7.3%、7.5% 和 7.0%，而 SOTA 方法则分别为 37.7%、33.8% 和 29.5% 下降。SyncMapV2 在鲁棒性、适应性方面没有进行任何训练、监督或损失函数，且在适应性测试中显示出近零的性能下降，增强了未来智能技术的鲁棒性和适应性。", "innovation": "SyncMapV2 是第一个在无监督分割中具有顶级鲁棒性的算法，它使用自我组织的动力学方程和随机网络的概念来实现鲁棒性和适应性，无需任何鲁棒训练、监督或损失函数。它展示出在数字破坏下只有 0.01% 的 mIoU 下降，远优于 SOTA 方法的 23.8% 下降。此外，SyncMapV2 能够在线适应输入，类似于人类视觉的连续适应性，这意味着它不仅实现了准确且鲁棒的结果，还成为第一个能够在线适应输入而不是重新初始化的算法。", "conclusion": "SyncMapV2 表现出了极高的鲁棒性和适应性，在各种类型的破坏下表现优于现有的 SOTA 方法。它没有依赖任何显性或隐性的外部监督，且展示了在线适应性，这为其成为未来智能技术的基准打下了坚实基础。"}
{"llm_update_time": "2025-06-25 09:28:49", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19511", "html_url": "https://arxiv.org/abs/2506.19511", "title": "将配对编程纳入工作实践", "title_en": "Integrating Pair Programming as a Work Practice", "authors": "Nina Haugland Andersen,Anastasiia Tkalich,Nils Brede Moe,Darja Smite,Asgaut Mjølne Söderbom,Ola Hast,Viktoria Stray", "background": "随着现代系统变得更加复杂，团队间的知识分享和协作变得至关重要。尽管配对编程（PP）已被广泛证明具有诸多益处，但在软件团队中的采纳率仍然参差不齐。", "innovation": "本研究通过在一个挪威成熟的敏捷公司中开展探索性单案例研究，收集来自不同角色团队成员的两轮访谈数据，并进行主题分析，发现了影响配对编程参与因素的多样性。这些因素包括日常工作中配对编程贡献的感知、参与配对编程所需的努力、公司和团队的态度、资源、基础设施以及任务特性等因素。研究指出，长期参与配对编程需要通过亲身体验来验证实践的好处，并且根据每个团队的特性进行调整，利用集体学习的有效见解也是有益的。", "conclusion": "长期参与配对编程需要其在实践中带来的预期好处在实际经历中得到确认。通过适应每个独特的队伍特性并结合集体学习的见解，将配对编程融入团队的日常工作是十分有益的。"}
{"llm_update_time": "2025-06-25 09:28:50", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19481", "html_url": "https://arxiv.org/abs/2506.19481", "title": "LLM-based Multi-Agent System for Intelligent Refactoring of Haskell Code", "title_en": "LLM-based Multi-Agent System for Intelligent Refactoring of Haskell Code", "authors": "Shahbaz Siddeeq,Muhammad Waseem,Zeeshan Rasheed,Md Mahade Hasan,Jussi Rasku,Mika Saari,Henri Terho,Kalle Makela,Kai-Kristian Kemell,Pekka Abrahamsson", "background": "代码重构是软件开发和维护中的持续活动，对于扩展和维护软件系统至关重要。尽管如此，重构过程仍然劳动密集型，因为程序员需要详细分析代码库以避免引入新的缺陷。当前的研究提出了一种基于大规模语言模型（LLM）的多代理系统，用于自动化Haskell代码的重构过程。该研究旨在评估LLM代理在执行结构化和语义准确的Haskell代码重构方面的效果。用于测试多代理系统的有效性和实际适用性，进行了不同的开源Haskell代码库的评估。实验结果表明，所提出的基于LLM的多代理系统能够平均降低代码复杂度11.03%，整体代码质量提高22.46%，并且提升性能效率平均13.27%，同时内存分配优化最高可达14.57%。这些结果展示了基于LLM的多代理系统在管理面向函数编程范式的重构任务方面的管理能力。研究发现，将基于LLM的多代理系统集成到函数编程语言的重构中，可以提高可维护性和支持自动化开发流程。", "innovation": "提出了基于LLM的多代理系统，自动执行Haskell代码的结构化和语义准确的重构。这种方法能够显著降低代码复杂度、提高代码质量和性能效率，并优化内存分配。该研究强调了LLM多代理系统在处理面向函数编程范式的重构任务方面的潜力。集成至函数编程语言的重构，这种系统可以提高可维护性并支持自动化开发流程。", "conclusion": "所提出的基于LLM的多代理系统显著提高了Haskell代码的重构效果，包括解决了代码复杂度减少、整体代码质量提升、性能效率提高和内存优化等问题，这表明此类系统在函数编程语言的重构中具有明显优势，能够促进可维护性和自动化开发流程的发展。"}
{"llm_update_time": "2025-06-25 09:28:54", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19677", "html_url": "https://arxiv.org/abs/2506.19677", "title": "带有SLA保证的CodeLLM服务的自适应请求调度", "title_en": "Adaptive Request Scheduling for CodeLLM Serving with SLA Guarantees", "authors": "Shi Chang,Boyuan Chen,Kishanthan Thangarajah,Hanan Lutfiyya,Ahmed E. Hassan", "background": "代码大型语言模型（CodeLLMs）在现代软件开发流程中越来越常见，但在资源受限的、自我托管的环境中高效运行仍然是一个重大挑战。现有的LLM服务系统使用连续批次处理以提高吞吐量，但它们依赖于静态批量大小配置，无法适应波动的请求率或异构负载，导致频繁违反服务水平协议（SLA）和不稳定的服务性能。", "innovation": "我们提出了一种名为SABER的动态批次策略，能够预测每个请求的SLA可行性并在实时中调整决策。与最好的静态配置相比，SABER可以提高高达26%的吞吐量，将延迟变化减少高达45%，并且无需手动调整或服务重启。研究表明，SLA感知且适应性强的调度是构建稳健且高性能的CodeLLM服务的关键。", "conclusion": "我们的研究结果表明，基于SLA的自适应调度对于提高CodeLLM服务的鲁棒性和性能至关重要。SABER策略能够实时预测和调整批次策略，以确保服务质量，并提高系统的整体性能。"}
{"llm_update_time": "2025-06-25 09:28:56", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19757", "html_url": "https://arxiv.org/abs/2506.19757", "title": "探索软件生态系统中的开发者体验因素", "title_en": "Exploring Developer Experience Factors in Software Ecosystems", "authors": "Rodrigo Oliveira Zacarias,Léo Carvalho Ramos Antunes,Márcio de Oliveira Barros,Rodrigo Pereira dos Santos,Patricia Lago", "background": "开发者体验（DX）在影响开发人员在软件生态系统平台上的表现和持续参与度方面起着关键作用。虽然研究人员和从业者已经认识到多个影响DX的因素，但缺乏一个清晰的关键因素影响路径。这对于促进开发人员对软件生态系统平台的兴趣及其持续的技术应用具有直接影响。已有研究梳理出了许多因素，但缺乏一个明确的且具有影响力的因素清单，这对于软件生态系统平台的成功和可持续性至关重要。", "innovation": "本文通过系统文献综述（SMS）分析了29项研究中的DX因素，随后通过德尔菲研究评估了21名第三方开发人员视角下27个DX因素对于采纳和持续贡献于软件生态系统平台的影响，从而确立了一个影响深远的因素清单。这些研究为研究人员和从业者提供了宝贵的研究结果和实践建议，以更好地满足第三方开发者的DX需求。", "conclusion": "开发者体验对于软件生态系统的成功和可持续性至关重要。我们确定的一系列关键开发者体验因素为研究人员和从业者提供了重要见解和建议，帮助解决第三方开发者的体验关键问题。"}
{"llm_update_time": "2025-06-25 09:28:57", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19620", "html_url": "https://arxiv.org/abs/2506.19620", "title": "农业机器人提供光照治疗的概率建模与安全保证", "title_en": "Probabilistic modelling and safety assurance of an agriculture robot providing light-treatment", "authors": "Mustafa Adam,Kangfeng Ye,David A. Anisi,Ana Cavalcanti,Jim Woodcock,Robert Morris", "background": "农业机器人的持续采用依赖于农民对其可靠性和安全性的确信。因此，本研究关注农业机器人检测、追踪和避免障碍物及人类的能力，以确保其安全。研究基于早期开发阶段的概率建模和风险分析框架，首先识别潜在风险并利用风险评估矩阵捕捉移动机器人平台的行为、传感器和感知系统及其展现的风险。然后通过PRISM概率模型检查器生成并分析概率模型，从而量化不同设计概念下的风险缓解措施和风险减少带来的影响。", "innovation": "提出了一个基于概率建模和风险分析的框架，用于农业机器人的安全保证，特别是在初步概念开发阶段。该框架利用PRISM概率模型检查器生成和分析概率模型，以评估不同设计概念下的风险缓解措施和风险减少效果，包括采用更高性能的物体检测系统或增加更复杂的警告系统以提高人类意识的影响。", "conclusion": "该研究不仅关注农业机器人在初始概念开发阶段的安全保障，而且该框架也可以应用于后续的实施、部署和运营阶段，为农业生产提供更可靠的技术支持。"}
{"llm_update_time": "2025-06-25 09:28:58", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.18923", "html_url": "https://arxiv.org/abs/2506.18923", "title": "多语言专家混合架构在多语言编程中的应用", "title_en": "Mix-of-Language-Experts Architecture for Multilingual Programming", "authors": "Yifan Zong,Yuntian Deng,Pengyu Nie", "background": "大型语言模型（LLMs）在帮助开发人员完成代码理解、生成和翻译等任务方面展现出了令人印象深刻的性能。支持跨多种编程语言的编程通常有两种方法：一种是跨所有编程语言微调单一LLM，虽然成本效益高但会使语言特定的专业化和性能降低；另一种是为每种编程语言微调单独的LLM，这有利于专业化但因参数重复而计算成本高、存储需求大。本研究介绍了MoLE（多语言专家混合架构），旨在平衡多语言编程的高效性和专业化。", "innovation": "MoLE架构结合了一个基础模型、一个共享的LoRA模块以及一组语言特定的LoRA模块，这些模块在微调过程中协同优化，以实现编程语言间的有效知识共享和专业化。MoLE在推理阶段根据生成的代码令牌对应的编程语言自动路由至相应的LoRA模块。实验结果表明，MoLE在参数效率上优于单独语言特定的LoRAs训练，同时在准确性方面优于所有编程语言共享的单一微调LLM。", "conclusion": "MoLE架构通过有效知识共享和专业化，在多语言编程中实现了高效性与专业化的平衡，相比其它方法提高了参数效率并提升了准确性。"}
{"llm_update_time": "2025-06-25 09:28:59", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19539", "html_url": "https://arxiv.org/abs/2506.19539", "title": "Log解析中的规则转换？从正则表达式转换到Dynatrace模式语言", "title_en": "Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language", "authors": "Julian Fragner,Christian Macho,Bernhard Dieber,Martin Pinzger", "background": "日志文件为企业软件应用程序和数据中心的问题检测和诊断提供了有价值的资讯。多种日志分析工具和平台利用正则表达式（RegExes）帮助过滤和提取日志信息。一些商业日志分析平台如Grok或Dynatrace的模式语言（DPL）提供了特定领域的语言用于日志解析。然而，用户若要迁移到这些平台，必须手动将RegExes转换为新的模式语言，这个过程既耗时又容易出错。因此，研究提出了一种名为Reptile的方法，结合基于规则的方法将RegExes转换为DPL模式，并采用最努力的方法处理完全转换不可能的情况。此外，该方法还集成了GPT-4来优化获得的DPL模式。实验使用了946条从大公司收集的RegExes显示，Reptile成功转换了其中73.7%的RegExes。使用23条真实世界的RegExes来评估Reptile模式优化的结果，显示的F1分数和MCC都超过0.91，这些结果很有前景，并对公司迁移到现代日志分析平台（如Dynatrace）具有重要的实际意义。", "innovation": "研究提出了一种名为Reptile的方法，结合基于规则的方法将正则表达式转换为Dynatrace的模式语言，并使用最努力的方法处理完全转换不可能的情况，同时集成了GPT-4来优化获得的DPL模式。该方法显著减少了用户手动转换RegExes的需要，优化了转换后的DPL模式，增强了日志分析的效率和准确性。实验结果表明Reptile能够安全地转换73.7%的RegExes，并且其模式优化效果显著，达到了较高的F1分数和MCC。这些创新在实践中具有重要意义，适用于许多需要迁移到现代日志分析平台的企业。", "conclusion": "研究结果表明，Reptile方法在将RegExes转换为Dynatrace模式语言方面表现良好，能安全地转换73.7%的RegExes，并且优化后的DPL模式在真实世界中的表现优异，F1分数和MCC超过0.91。这些结果为公司成功迁移至现代日志分析平台提供了有力的支持，具有广泛的实际应用价值。未来的研究可以进一步优化Reptile方法，以提高转换的准确性和速度。"}
{"llm_update_time": "2025-06-25 09:29:01", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19622", "html_url": "https://arxiv.org/abs/2506.19622", "title": "Robotic Autonomous Systems的安全验证方法", "title_en": "A Verification Methodology for Safety Assurance of Robotic Autonomous Systems", "authors": "Mustafa Adam,David A. Anisi,Pedro Ribeiro", "background": "自主机器人部署在共享人类环境中，如农业环境中，需要严格的安全保障，以满足功能可靠性和监管合规性。这些系统必须在动态、未结构化的环境中运行，与人类安全互动，并有效应对各种潜在的危险。本文提出了一个用于自主农业机器人安全保证的验证工作流程，覆盖了从概念研究和设计到运行时验证的整个开发生命周期。首先通过系统化的危险分析和风险评估来识别潜在风险并推导相应的安全要求。随后开发了安全控制器的正式模型，捕获其行为，并验证控制器是否满足这些要求所规定的安全属性。该方法在田间机器人在农业环境下的演示结果表明，该方法可以有效验证安全关键属性并促进设计问题的早期识别，从而促进更安全的机器人和自主系统的开发。", "innovation": "提出了一个用于自主农业机器人安全保证的验证工作流程，该方法包括系统化的危险分析和风险评估以识别潜在风险，然后开发安全控制器的正式模型来验证其满足安全属性的要求，这种方法能够有效验证安全关键属性并促进设计问题的早期识别，从而促进更安全的机器人和自主系统的开发.", "conclusion": "该方法可以有效验证安全关键属性并促进设计问题的早期识别，从而促进更安全的机器人和自主系统的开发."}
{"llm_update_time": "2025-06-25 09:29:01", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2411.19567", "html_url": "https://arxiv.org/abs/2411.19567", "title": "DynNPC：通过动态NPC行为生成在模拟测试中发现更多由ADS引起的违规情况", "title_en": "DynNPC: Finding More Violations Induced by ADS in Simulation Testing through Dynamic NPC Behavior Generation", "authors": "You Lu,Yifan Tian,Dingji Wang,Bihuan Chen,Xin Peng", "background": "近年来，提出了一系列用于生成多样化的自动驾驶系统(ADS)测试场景的仿真测试方法。然而，先前方法生成的场景中的NPC（非玩家角色）车辆行为是在仿真实验前预定义和变异的，忽视了交通信号和 ego 车辆的行为。因此，他们发现的大量违规行为是由 NPC 车辆的不现实行为引起的，未能发现 ADS 的真正 bug。此外，迭代变异期间NPC 行为的庞大场景搜索空间限制了先前方法的效率。", "innovation": "针对上述局限性，我们提出了一种新颖的基于场景的测试框架 DynNPC，以生成更多由ADS引起的违规场景。具体来说，DynNPC 允许在仿真期间根据交通信号和 ego 车辆的实时行为动态生成 NPC 车辆的不同驾驶策略行为。我们还将 DynNPC 与五种最先进的基于场景的测试方法进行了比较。我们的评估证实了 DynNPC 在找到更多由 ADS 引起的违规场景方面的有效性和效率。", "conclusion": "DynNPC 通过允许 NPC 车辆在仿真期间根据交通信号和 ego 车辆的实时行为动态生成不同的驾驶策略行为，在仿真测试中发现了更多由ADS引起的违规场景，表现出了更高的效率和有效性。"}
{"llm_update_time": "2025-06-25 09:29:04", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.05456", "html_url": "https://arxiv.org/abs/2502.05456", "title": "基于深度学习模型的实时输入精炼框架", "title_en": "Framework for On the Fly Input Refinement for Deep Learning Models", "authors": "Ravishka Rathnasuriya", "background": "深度学习的进展显著提升了代码、文本和图像处理任务中的模型性能。然而，这些模型在真实世界应用中仍然可能存在明显误预测的情况，即使在使用最新数据进行训练后。这些误预测常常源于输入数据的小幅变化，如代码中的轻微语法变化、文本的重新措辞或图像中照明的微妙变化。这些差异揭示了这些模型在通用性方面存在的固有限制。传统的应对策略主要是重新训练，这是一个资源密集型的过程，需要大量的数据标注、模型更新和重新部署的工作投入。", "innovation": "本文提出了一种自适应、实时输入精炼框架，旨在通过输入验证和变换来提升模型性能。输入验证组件能够识别可能导致错误的输入，而输入变换则针对特定领域应用，根据模型处理能力对这些输入进行调整。这种双重策略在不同应用领域中减少了误预测，提升了模型表现，无需重新训练模型。该框架具有可扩展性和资源效率优势，对于软件工程、自然语言处理和计算机视觉等高风险应用具有重要意义。", "conclusion": "该框架在不需要重新训练的情况下，通过输入验证和变换减少了模型在不同领域的误预测，提升了模型性能。作为一项可扩展且资源效率高的解决方案，它在各种高风险应用中具有重要前景。"}
{"llm_update_time": "2025-06-25 09:29:08", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19653", "html_url": "https://arxiv.org/abs/2506.19653", "title": "模拟瀑布模型：系统回顾", "title_en": "Simulating the Waterfall Model: A Systematic Review", "authors": "Antonios Saravanos(1) ((1) New York University)", "background": "这篇文章系统地研究了在经过同行评审的文献中，瀑布模型是如何被计算仿真代表的。虽然敏捷方法论主导了当前的软件设计实践，但瀑布模型仍以一种混合方式存在，即结合结构化、顺序的工作流和敏捷实践的适应性。尽管瀑布模型在实际中仍然存在，但在研究领域中很少有研究关注其模拟方式。文章通过结构化搜索主要学术数据库，发现了2000年至2024年间发表的68篇同行评审的文献，并从中选择了符合标准的研究进行了分析，分析维度包括仿真方法、平台和工具、地理和时间趋势以及与Royce原始七阶段模型的吻合度。研究结果表明，尽管瀑布模型在学术讨论中的存在感较弱，但在仿真中的应用是存在的，并且越来越多地使用开源的Python工具。", "innovation": "研究通过系统回顾的方法揭示了瀑布模型在仿真中的应用及其在学术领域的存在状态。强调了使用易于访问的建模工具的必要性，并呼吁未来的研究能够结合瀑布模型和现代混合实践。特别是在仿真方法、技术平台及开放源代码工具的应用上进行了详细分析，为相关领域提供了新的视角和洞见。", "conclusion": "尽管在学术领域中，瀑布模型的仿真应用相对较少，但仍显示出一定的存在感。研究强调了模仿瀑布流程模型需要易于使用的建模工具，并期望未来发展研究将其与现代混合实践相结合。"}
{"llm_update_time": "2025-06-25 09:29:09", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.10049", "html_url": "https://arxiv.org/abs/2506.10049", "title": "演化业务流程的在线模拟模型发现（扩展版本）", "title_en": "Online Discovery of Simulation Models for Evolving Business Processes (Extended Version)", "authors": "Francesco Vinci,Gyunam Park,Wil van der Aalst,Massimiliano de Leoni", "background": "业务过程模拟（BPS）是指用于模拟业务过程动态行为的技术。已有许多方法提出自动从历史事件日志中发现模拟模型，以减少手动设计模型的成本和时间。但在动态业务环境中，组织不断调整其流程以提高效率、降低费用、增强客户满意度。现有流程模拟发现技术缺乏应对实时运营变化的适应性。本文针对此问题，探讨了在动态业务环境中发现流程模拟模型的方法，并提出了一种集增量过程发现与在线机器学习方法于一体的流式过程模拟发现技术。", "innovation": "本文提出了一种集成增量过程发现与在线机器学习方法的流式过程模拟发现技术。该技术强调近期数据的同时保留历史信息，确保适应不断变化的流程动态。实验表明，在模拟中给近期数据更多权重并保留历史知识的重要性。该技术不仅提高了模拟的稳定性，还展示了在处理概念漂移方面的鲁棒性。", "conclusion": "通过实验数据分析，本文的技术不仅提高了模拟的稳定性，还能更好地适应流程的动态变化，展示了强大的适应性和鲁棒性。"}
{"llm_update_time": "2025-06-25 09:29:10", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.12987", "html_url": "https://arxiv.org/abs/2505.12987", "title": "高性能的多核SystemC-TLM基ARM-on-ARM 虚拟平台", "title_en": "High-Performance ARM-on-ARM Virtualization for Multicore SystemC-TLM-Based Virtual Platforms", "authors": "Nils Bosbach,Rebecca Pelke,Niko Zurstraßen,Jan Henrik Weinstock,Lukas Jünger,Rainer Leupers", "background": "现代系统芯片的硬件和软件复杂度越来越高，需要采用先进的开发和测试方法。该文探讨了在SystemC为基础的模拟器中使用Linux KVM实现ARM-on-ARM虚拟化的方法。通过在带有硬件虚拟化扩展的ARM主机上原生运行目标软件，本方法消除了指令集模拟器的需要，极大地提高了性能。该研究提出了一个可以作为指令集模拟器替换品的多核SystemC-TLM系统模型，对宿主机没有特殊要求，兼容各种环境。在计算密集型工作负载中，基于ARM-on-ARM的虚拟平台的加速比能达到10倍以上。", "innovation": "提出了一种使用Linux KVM在系统芯（SystemC）基础上实现高效ARM-on-ARM虚拟化的新方法。通过在ARM架构的宿主机上使用硬件虚拟化扩展原生运行目标软件，从而不依赖于指令集模拟器，极大地提升了模拟性能。该研究还提出了一种适用于多核SystemC传输层次模型（TLM）的可插拔的CPU模型，可以作为指令集模拟器的直接替换品。该模型对宿主机没有特殊要求，且适用于各种环境。特别是在计算密集型任务中，相较于传统的指令集模拟器模型，加速比可以达到10倍以上，并且在某些情况下超过100倍。", "conclusion": "通过本文提出的ARM-on-ARM虚拟化方案，能够在基于SystemC的虚拟平台上实现高效的计算模拟，尤其适用于计算密集型工作负载。与传统的指令集模拟器相比，该方法可以实现显著的性能提升。"}
{"llm_update_time": "2025-06-25 09:29:13", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.08598", "html_url": "https://arxiv.org/abs/2505.08598", "title": "GroupTuner：高效分组感知编译器自调优", "title_en": "GroupTuner: Efficient Group-Aware Compiler Auto-Tuning", "authors": "Bingyu Gao,Mengyu Yao,Ziming Wang,Dong Liu,Ding Li,Xiangqun Chen,Yao Guo", "background": "现代编译器通常提供了数百个优化程序性能的选项，但用户往往由于选项数量庞大而无法充分利用这些选项。虽然标准的优化组合（例如-O3）提供了合理的默认设置，但它们往往无法在不同的程序和架构上达到接近峰值的性能。为解决这一挑战，编译器自动调优技术应运而生，旨在自动化寻找改进的选项组合。现有技术通常侧重于识别关键选项并在搜索中优先考虑它们，以提高效率。然而，由于调优迭代次数有限，导致结果数据稀疏且噪音大，使准确识别关键选项变得非常困难。因此，这些算法容易陷入局部最优解。", "innovation": "为解决这一局限性，我们提出了GroupTuner，这是一种分组感知的自动调优技术，直接基于历史上表现最佳的选项组应用局部化突变，从而避免明确识别关键选项。通过不需要精确知道哪些选项最重要，GroupTuner最大限度地利用现有性能数据，确保更精准的探索。广泛的实验表明，GroupTuner能够高效发现竞争性的选项组合，在性能上相比-O3平均提升12.39%，而所需时间仅为随机搜索算法的77.21%，显著优于现有的先进方法。", "conclusion": "GroupTuner能够有效发现具有竞争力的选项组合，相比-O3平均性能提升12.39%，并将所需时间减少了22.79%。该技术通过局部化突变和历史最佳组合的应用，有效避免了关键选项的明确识别，使得搜索更加高效和精准。"}
{"llm_update_time": "2025-06-25 09:29:13", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.19045", "html_url": "https://arxiv.org/abs/2506.19045", "title": "由大型语言模型和执行估计驱动的黑盒测试代码故障定位", "title_en": "Black-Box Test Code Fault Localization Driven by Large Language Models and Execution Estimation", "authors": "Ahmadreza Saboor Yaraghi,Golnaz Gharachorlu,Sakina Fatima,Lionel C. Briand,Ruiyuan Wan,Ruifeng Gao", "background": "故障定位（FL）是调试中的一个重要步骤，通常依赖于重复执行以识别故障代码区域。然而，在存在非确定性故障或高执行成本的情况下，重复执行可能不切实际。虽然最近的努力已经利用大型语言模型（LLMs）来辅助执行自由的故障定位，这些方法主要集中在识别被测系统中的故障，而不是复杂的测试代码中的故障。但后者也很重要，因为在实践中，许多故障实际上是由测试代码中的错误触发的。因此，提出了一种无需执行测试用例的完全静态、LLM驱动的方法，用于系统测试代码中的故障定位（TCFL），并使用单个故障执行日志来估计测试的执行轨迹，通过三个新的算法识别只与故障相关的代码语句。", "innovation": "该方法引入了一个单一口径、不依赖于被测系统源代码的系统级方法，可用于大型测试脚本评估全系统行为。与现有的LLM辅助的无执行FL方法不同，该方法侧重于测试代码中的故障定位，利用其单个故障执行日志估计测试的执行轨迹，通过三个新的算法识别只与故障相关的代码语句。这简化了LLM的推理时间最多34%，同时FL性能并未受损。该方法在函数、块和行级别上进行了评估，并展示了对实际执行轨迹的高度匹配度，F1分数高达90%。此外，对复杂系统测试代码进行剪枝后，可以在提高搜索空间效率的同时保留有用的上下文。", "conclusion": "该研究表明，根据原始日志进行剪枝可以相差执行后的故障定位，这不仅提高了效率，还表明块级TCFL提供了一种实用的平衡，既能缩小搜索空间又能保留有用的信息，使得前3个位置的命中率达到了81%。"}
{"llm_update_time": "2025-06-25 09:29:14", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.17539", "html_url": "https://arxiv.org/abs/2506.17539", "title": "突破单一测试者的限制：基于多智能体的大语言模型在多用户功能测试中的应用", "title_en": "Breaking Single-Tester Limits: Multi-Agent LLMs for Multi-User Feature Testing", "authors": "Sidong Feng,Changhao Du,Huaxiao Liu,Qingnan Wang,Zhengwei Lv,Mengfei Wang,Chunyang Chen", "background": "移动设备和应用程序的依赖性日益增强，使得多用户交互功能（如聊天通话、直播和视频会议）在解决由物理和情境障碍造成的社交连接断裂问题中变得不可或缺。然而，对这些交互功能进行自动化测试面临着巨大挑战，因为它们依赖于及时、动态和协作的用户交互，而现有的自动化测试方法无法充分解决这些问题。", "innovation": "提出了一种新型的多智能体方法MAdroid，利用大语言模型（LLMs）来自动化多用户交互任务，以实现应用程序功能测试。MAdroid采用两种功能类型多智能体：用户智能体（操作员）、监督智能体（协调员和观察员），各司其职：协调员指挥交互任务；操作员模仿在设备上的用户交互；观察员监控和审查任务自动化过程。", "conclusion": "实验评估显示，MAdroid方法有效，完成41项多用户交互任务中的82.9%，动作相似度达到96.8%，超过了消融研究和最先进的基线。初步研究还表明，MAdroid在回归测试中帮助识别了11个交互式多用户错误，验证了其在实际软件开发中的潜在价值。"}
{"llm_update_time": "2025-06-25 09:29:14", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.01056", "html_url": "https://arxiv.org/abs/2506.01056", "title": "MCP-Zero: 自主LLM代理的主动工具发现", "title_en": "MCP-Zero: Active Tool Discovery for Autonomous LLM Agents", "authors": "Xiang Fei,Xiawu Zheng,Hao Feng", "background": "当前的大语言模型（LLM）代理在接收到预定义的工具架构时，它们仅作为被动选择工具的模型，这限制了它们成为强大通用代理的能力。这种被动接收手段无法实现真正的智能，因为它缺乏积极的学习和能力获取机制。", "innovation": "MCP-Zero通过使LLM代理能够自主发现工具，恢复了工具发现的自主权。这一框架包括三个核心机制：主动工具请求，使模型能够自主生成结构化请求以指定所需的工具；层次语义路由，一种两阶段算法，通过提高语义匹配来将请求匹配到相关的服务器和工具；以及渐进能力扩展，使代理能够逐步构建跨领域工具链，同时保持最小的上下文足迹。", "conclusion": "实验显示MCP-Zero在保留代理自主性的同时，实现了显著的效率提升：（i）在大量候选工具（接近3000个）中准确选择工具；（ii）在APIBank上98%减少token消耗的同时保持高准确性；（iii）具有一致的多轮操作表现，并与工具生态系统增长保持一致。这项工作证明了主动工具发现是构建可扩展自主代理系统的基本设计模式。"}
{"llm_update_time": "2025-06-25 09:29:14", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.16901", "html_url": "https://arxiv.org/abs/2505.16901", "title": "Code Graph Model (CGM): 一个集成图的大型语言模型用于仓库级别软件工程任务", "title_en": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "authors": "Hongyuan Tao,Ying Zhang,Zhenhao Tang,Hongen Peng,Xukun Zhu,Bingchang Liu,Yingguang Yang,Ziyin Zhang,Zhaogui Xu,Haipeng Zhang,Linchao Zhu,Rui Wang,Hang Yu,Jianguo Li,Peng Di", "background": "最近的大规模语言模型（LLMs）在函数级别的代码生成中展现出潜力，但在仓库级别的软件工程任务中仍存在挑战。当前的解决方案主要依赖于专有的LLM代理，这引入了不可预测性并限制了可访问性，引起了数据隐私和模型定制方面的担忧。本文研究了是否可以通过可不受代理影响的方法使用开源的大规模语言模型解决仓库级别的任务。通过使LLMs能够理解代码库中的函数和文件的语义信息和结构依赖，文中提出了一种新的方法并引入了Code Graph Models（CGMs），该方法将仓库代码图结构集成到LLM的注意力机制中，并通过一个专门的适配器将节点属性映射到LLM的输入空间。通过这种方法以及与无代理图RAG框架的结合使用，在SWE-bench Lite基准测试上使用开源的Qwen2.5-72B模型，我们的方法实现了43.00%的解决率，这一性能在开源权重模型中排名第一，在使用开源系统的其他方法中排名第二，在所有方法中排名第八，超越了之前最好的开源模型基线方法12.33%。", "innovation": "本文的主要创新在于提出了Code Graph Models（CGMs），这种方法将代码仓库中的图结构信息整合到LLM的注意力机制中，并通过一个专门的适配器将节点属性映射到LLM的输入空间。这种方法可以使LLM更好地理解代码库中的函数和文件，不依赖于专有的LLM代理，从而提高了模型在仓库级别的软件工程任务中的性能。文中使用开源的Qwen2.5-72B模型在SWE-bench Lite基准测试中实现了43.00%的解决率，相较之前的方法有显著提高。", "conclusion": "本文提出的方法成功地展示了开源的大规模语言模型能够有效处理仓库级别的软件工程任务，不依赖于专有的LLM代理。通过将代码仓库中的图结构信息整合到LLM的注意力机制中，CGMs在处理仓库级别的任务上取得了43.00%的解决率，超越了许多现有方法，特别是在开源模型基线方法中表现尤为突出。"}
{"llm_update_time": "2025-06-25 09:29:17", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.04359", "html_url": "https://arxiv.org/abs/2506.04359", "title": "cuVSLAM：CUDA加速的视觉里程计与mapping", "title_en": "cuVSLAM: CUDA accelerated visual odometry and mapping", "authors": "Alexander Korovko,Dmitry Slepichev,Alexander Efitorov,Aigul Dzhumamuratova,Viktor Kuznetsov,Hesam Rabeti,Joydeep Biswas,Soha Pouya", "background": "准确和鲁棒的姿势估计是任何自主机器人的重要需求。现有的视觉同时定位与建图（visual SLAM）解决方案通常依赖于多种视觉惯性传感器，但在实际应用中，可能需要支持不同数量和配置的传感器。此外，这类系统需要在边缘计算设备上实时运行，以最小化计算开销并支持广泛的应用场景。", "innovation": "cuVSLAM 是一种先进的视觉SLAM解决方案，能够使用多种视觉惯性传感器组合，包括多个RGB和深度摄像头以及惯性测量单元。它特别优化了CUDA技术，可以在NVIDIA Jetson等边缘计算设备上实时运行，支持从一个RGB摄像头到多达32个不同几何配置的摄像头。cuVSLAM在多种前瞻性基准测试中展示了最佳性能。", "conclusion": "cuVSLAM 是一种通过 CUDA 加速的视觉里程计与mapping技术，能够有效支持各种传感器配置和应用场景。cuVSLAM 的设计优化使得其在边缘计算设备上具有实时性能，且具有广泛的适用性。"}
{"llm_update_time": "2025-06-25 09:29:18", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.18050", "html_url": "https://arxiv.org/abs/2506.18050", "title": "VFArchē：开源软件中定位易受攻击函数的双模式框架", "title_en": "VFArchē: A Dual-Mode Framework for Locating Vulnerable Functions in Open-Source Software", "authors": "Lyuye Zhang,Jian Zhang,Kaixuan Li,Chong Wang,Chengwei Liu,Jiahui Wu,Sen Chen,Yaowen Zheng,Yang Liu", "background": "软件组成分析（SCA）已成为解决软件项目依赖中固有的漏洞问题的关键。尤其是，可达性分析被广泛应用于开源软件项目中，通过调用图识别可利用漏洞（如CVEs），从而专注于可能的攻击风险。然而，执行可达性分析通常需要跟踪下游应用程序中的易受攻击函数（VF）的调用链，这在现代漏洞数据库（如NVD）中通常是不可用的。直接从漏洞修补程序中的修改函数中提取VF虽然是直观的，但修补程序并非总是可用的。此外，初步研究显示超过26%的VF不在修改的函数中。忽视修补程序进行VF搜索会导致大量的噪音和描述与代码之间的词义差异。鉴于几乎有一半的漏洞都配备了修补程序，因此需要一个综合解决方案来处理有尚未提供补丁链接或其他情况的数据集。", "innovation": "本文提出了VFArchē，一种双模式方法，适用于披露的漏洞，并在有或无修补程序链接的情况下均可应用。实验结果显示，VFArchē在指标方面表现出显著效果，在补丁存在模式下，其平均倒数排名达到了最佳基线的1.3倍，而在补丁不存在模式下，这一数据达到了1.9倍。VFArchē还通过成功定位50个最新漏洞中的43个，并显著降低了78-89%的SCA工具误报率，展示了其在实际场景中的适用性。", "conclusion": "VFArchē提供了一种有效的解决方案，贴合实际需求并能够自动定位易受攻击函数。通过在有和无修补程序的场景下均取得显著的效果，VFArchē证明了它可以在开源软件中自动定位易受攻击的函数，减少误报并提高漏洞检测的有效性。"}
