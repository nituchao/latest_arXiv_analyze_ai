# 1. `cs.AI` - CALM: 基于上下文模拟逻辑与多模态 [PDF](https://arxiv.org/pdf/2506.14936), [HTML](https://arxiv.org/abs/2506.14936)
## Authors
Maxwell J. Jacobson,Corey J. Maley,Yexiang Xue
## Background
经典的二值逻辑系统无法捕捉人类决策的细微差别。它们还需要在多模态环境中进行人为的地引导，这可以是临时的、僵化的和脆弱的。神经网络擅长从多模态数据中提取丰富的上下文信息，但在可解释的结构化推理方面存在不足。
## Innovation
CALM 将符号推理与神经生成相结合，使其能够在基于真实世界多模态数据的上下文中做出敏感性决策。该系统通过将逻辑与神经感知相结合，填补了逻辑和神经感知之间的差距，从而实现了能够跨越多模态输入的类比逻辑。符号谓词通过神经网络计算得到的模拟真值并通过符号推理模块进行约束来评价。
## Conclusion
CALM 展示了在多模态环境中实现逻辑结构推理和符合人类偏好的潜力。它为需要逻辑精准性和解释性的逻辑和需要神经网络多模态信息处理的下一代人工智能系统的建立奠定了基础。
# 2. cs.AI - MEAL: 一个多代理连续强化学习基准 [PDF](https://arxiv.org/pdf/2506.14990), [HTML](https://arxiv.org/abs/2506.14990)
## Authors
Tristan Tomilin,Luka van den Boogaard,Samuel Garcin,Bram Grooten,Meng Fang,Mykola Pechenizkiy
## Background
强化学习算法的发展和分析依赖于基准测试，而环境的可用性对研究有很大影响。特别是在合作多代理设置中的连续学习仍然是一个欠探索的领域。现有的基准测试在CPU上运行环境，导致计算瓶颈并限制了任务序列的长度。为了填补这一空白，作者引入了MEAL（多代理环境中的自适应学习），这是首个针对连续多代理强化学习(CMARL)的基准测试框架，利用JAX进行GPU加速，可以在标准台式机上在几个小时内完成100个任务序列的学习。
## Innovation
MEAL是首个针对CMARL的基准测试框架，使用JAX和GPU加速，能够在标准台式机上运行100个任务序列，极大地提升了计算效率。现有的连续学习和多代理学习方法在简单环境中表现良好，但在更复杂需要持续协调和适应的环境中失败。通过消融研究确定了关键的建筑和算法特性。
## Conclusion
MEAL的引入解决了现有连续学习和多代理学习基准测试的局限性，推动了CMARL领域的发展。
# 3. cs.AI - 截断的凝聚策略优化 [PDF](https://arxiv.org/pdf/2506.15050), [HTML](https://arxiv.org/abs/2506.15050)
## Authors
Tiantian Fan,Lingjun Liu,Yu Yue,Jiaze Chen,Chengyi Wang,Qiying Yu,Chi Zhang,Zhiqi Lin,Ruofei Zhu,Yufeng Yuan,Xiaochen Zuo,Bole Ma,Mofan Zhang,Gaohong Liu,Ru Zhang,Haotian Zhou,Cong Xie,Ruidong Zhu,Zhi Zhang,Xin Liu,Mingxuan Wang,Lin Yan,Yonghui Wu
## Background
近期，测试时缩放大型语言模型（LLMs）通过生成长链条的思考（CoT）表现出在科学和专业任务中的出色推理能力。强化学习（RL），如近端策略优化（PPO）及其变体，作为开发这些推理模型的关键组件，通过试错学习。然而，PPO 由于其内在的按政策学习性质及响应长度的增加，变得耗时。
## Innovation
我们提出了一种新的近端策略优化的扩展版本T-PPO。它通过简化策略更新和长度限制的响应生成来提高训练效率。我们提出了优势估计扩展通用方法（EGAE），在保留策略学习完整性的前提下进行优势估计，并设计了计算优化的机制独立优化策略和价值模型。通过有选择地过滤提示和截断的标记，此机制减少了冗余计算并加速了训练过程，而不会牺牲收敛性能。
## Conclusion
我们在2024年AIME上使用32B基模型展示了T-PPO的效果和有效性。实验结果显示，T-PPO可以将推理LLMs的训练效率提高2.5倍，并优于现有竞争对手。
# 4. cs.AI - HeurAgenix：利用LLMs解决复杂组合优化挑战 [PDF](https://arxiv.org/pdf/2506.15196), [HTML](https://arxiv.org/abs/2506.15196)
## Authors
Xianliang Yang,Ling Zhang,Haolong Qian,Lei Song,Jiang Bian
## Background
启发式算法在解决组合优化问题中起着关键作用，但传统设计高度依赖人工专业知识，难以在不同实例之间泛化。文章介绍了HeurAgenix，一种由大型语言模型（LLMs）驱动的两阶段超启发式框架，能够自行演化启发式方法并自动选择最优启发式方法。启发式的演化阶段中，HeurAgenix通过LLM比较种子启发式解决方案与高质量解决方案，并提取可重用的演化策略。在问题求解阶段，它会根据LLM的感知能力动态选择最有可能解决问题状态的启发式方法。为了增强系统的灵活性，该选择器可以是最先进的LLM或经过微调的轻量级模型，以降低推理成本。由于组合优化问题的复杂性导致可靠监督信号稀缺，作者通过双重奖励机制对轻量级启发式选择器进行微调，该机制同时利用选择偏好和状态感知信号，从而在嘈杂的注释下实现稳健的选择。
## Innovation
HeurAgenix使用大型语言模型（LLMs）作为两阶段的超启发式框架，包括启发式演化和自动选择两个阶段。该框架可以自动生成启发式方法，并通过LLM自动选择最适合当前问题状态的启发式方法。文中提出了一种双重奖励机制来微调轻量级启发式选择器，使其在嘈杂的注释下也能实现稳健的选择。实验结果显示，HeurAgenix不仅优于现有的LLM基超启发式方法，还能够匹配或超越专门的求解器。此外，选择器可以是先进的LLM或者是经过微调的轻量级模型，以降低推理成本。
## Conclusion
通过引入HeurAgenix，该研究展示了如何利用大型语言模型来自动化启发式方法的生成和选择过程，从而有效解决组合优化问题。实验结果证明，该方法不仅能获得比传统和现有方法更好的性能，而且还能满足不同场景下的高性能需求。
# 5. cs.AI - 多智能体强化学习在自主多卫星地球观测中的应用：一个现实案例研究 [PDF](https://arxiv.org/pdf/2506.15207), [HTML](https://arxiv.org/abs/2506.15207)
## Authors
Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Jimmy Cao,Ryszard Kowalczyk
## Background
低地球轨道（LEO）卫星的指数增长已经彻底改变了地球观测（EO）任务，解决了气候监控、灾害管理等方面的问题。然而，多卫星系统中的自主协调仍然是一个基本挑战。传统的优化方法难以处理动态EO任务的实时决策需求，因此需要使用强化学习（RL）和多智能体强化学习（MARL）。
## Innovation
本文通过使用MARL框架，研究基于RL的自主EO任务规划。该研究通过近似现实的卫星仿真环境，评估了先进的MARL算法（包括PPO、IPPO、MAPPO和HAPPO）的训练稳定性和性能。研究重点解决了能量和数据存储限制、卫星观察的不确定性以及在部分可观测条件下的分散协调等关键挑战。结果显示，MARL能够在多卫星协调中有效平衡成像和资源整合，同时应对非平稳性和奖励依赖性。
## Conclusion
此研究为自主卫星操作提供了基础，并为动态、分散的EO任务提供了实用指导，有助于改进分散EO任务中的策略学习。
# 6. cs.AI - 通过无人机及船舶合作实现具有不确定性的海洋MEC的联合计算卸载和资源分配 [PDF](https://arxiv.org/pdf/2506.15225), [HTML](https://arxiv.org/abs/2506.15225)
## Authors
Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han
## Background
近年来，海洋物联网（MIoT）的计算需求迅速增加，基于无人机（UAVs）和船舶的多接入边缘计算（MEC）能够满足MIoT的需求。然而，具有不确定性的海洋工作任务带来了高效的计算卸载和资源分配的重大挑战。本文集中在通过无人机和船舶的合作来解决海洋计算卸载和资源分配问题，尤其是在考虑不确定任务的情况下。
## Innovation
本文提出了一个基于无人机和船舶协作的联合计算卸载和资源分配框架，利用李亚普诺夫优化处理不可预测的任务到达和计算资源的可用性变化。通过将长期约束转化为短期约束，得到一系列规模较小的优化问题。考虑无人机和船舶之间异构的动作和资源，将小规模优化问题重新表述为马尔可夫游戏（MG），并提出了一种异构代理软演员-评论家算法来逐步更新各类神经网络，有效解决MG问题。最后，通过仿真实验验证了该方法在处理计算卸载和资源分配方面的有效性。
## Conclusion
通过设计基于无人机和船舶合作的联合计算卸载和资源分配框架，利用李亚普诺夫优化和马尔可夫游戏理论，提出了一个有效的异构代理软演员-评论家算法，实现了对具有不确定性的海洋任务的有效处理。
# 7. cs.AI - 视觉导航中的高效且通用的环境理解 [PDF](https://arxiv.org/pdf/2506.15377), [HTML](https://arxiv.org/abs/2506.15377)
## Authors
Ruoyu Wang,Xinshu Li,Chen Wang,Lina Yao
## Background
Visual Navigation是体 тип人工智能中的核心任务，使代理能够根据给定的目标导航复杂的环境。许多导航任务需要建模从先前时间步骤积累的序列数据。现有方法在处理这一任务时表现良好，但它们通常同时处理所有历史观察，忽略数据内部关联结构，这可能限制了进一步提高任务性能的潜力。
## Innovation
本文通过考察导航任务的独特特征，基于因果关系引入了一个因果框架，提出了因果感知导航(Causality-Aware Navigation, CAN)。CAN集成了因果理解模块，提升了代理对环境的理解能力。实验结果表明，该方法在各种任务和仿真环境中均能稳定超越基线方法。详细的消融研究表明，因果理解模块在强化学习和监督学习的设置中均能有效泛化，且没有额外的计算开销。
## Conclusion
我们的方法在多个任务和仿真环境中的一致表现及因果理解模块的有效性验证了其在视觉导航任务中的优越性，特别在提高环境理解方面显示出潜力。
# 8. cs.AI - 使用基于大语言模型的推理和行动代理管理复杂故障分析工作流 [PDF](https://arxiv.org/pdf/2506.15567), [HTML](https://arxiv.org/abs/2506.15567)
## Authors
Aline Dobrovsky,Konstantin Schekotihin,Christian Burmer
## Background
故障分析（FA）是一个高度复杂且知识密集的过程。随着FA实验室中AI组件的集成，可以自动化各种任务，如图像中缺陷的检测、从多种数据源检索类似案例以及从标注图像生成报告。然而，部署的AI模型数量增加后，挑战在于将这些组件组织成协调且高效的流程，使其能够无缝集成到FA过程中。
## Innovation
本文研究并实施了一种基于大型语言模型（LLM）的规划代理（LPA），以帮助FA工程师解决分析案例。LPA将LLM与高级规划能力和外部工具利用结合，实现了复杂查询的自主处理、从外部系统检索相关数据以及生成易读的响应。评估结果显示，代理在支持FA任务方面具有操作有效性与可靠性。
## Conclusion
研究结果表明，基于大型语言模型的规划代理能够有效支持FA工程师的工作流程，提高分析效率和准确性。
# 9. cs.AI - 动态路由博弈中状态表示对LLM代理行为的影响 [PDF](https://arxiv.org/pdf/2506.15624), [HTML](https://arxiv.org/abs/2506.15624)
## Authors
Lyle Goodyear,Rachel Guo,Ramesh Johari
## Background
大语言模型（LLMs）在动态环境中显示出作为决策者的潜力，但由于其无状态性，需要通过自然语言构建历史状态表示。之前的针对LLM代理的游戏研究在编码游戏历史时采取了非系统、零散的方法，这不仅遮蔽了状态表示对代理行为的影响，还限制了研究之间的可比性。本文探讨了一个统一框架，用于系统地构建提示LLM代理在重复多代理游戏中的自然语言状态表示。
## Innovation
本文提出了一个框架来明确地定义和系统地构建自然语言状态表示， characterization through three axes: 行动信息性、奖励信息性和提示风格（自然语言压缩）。即使在理论和人类试验中，选择了一个相对简单的动态自私路由博弈，也发现了自然语言状态表示对LLM代理行为的关键依赖性。特别是，给代理提供简要的历史而非完整的历史、提供后悔信息而非原始支付信息、以及有限的其他行为信息的表示方法更接近于博弈论预测，且有更稳定的博弈表现。而其他代表方法可能会出现远离均衡、动态博弈表现时间上的高变异性，或者两者皆有。
## Conclusion
研究指出，适当的状态表示可以减少代理行为与博弈论均衡预测的偏差，有助于在动态博弈中实现更稳定的游戏表现。未来研究可以进一步探索不同类型的状态表示对不同博弈类型的影响。
# 10. cs.AI - 人工智能政策模块：培养计算机科学学生在人工智能伦理与政策方面的技能 [PDF](https://arxiv.org/pdf/2506.15639), [HTML](https://arxiv.org/abs/2506.15639)
## Authors
James Weichert,Daniel Dunlap,Mohammed Farghally,Hoda Eldardiry
## Background
随着人工智能（AI）在个人和专业场景中的进一步嵌入，不仅需要关注AI伦理，还需要通过AI政策来治理和监管AI技术。目前的大学计算机课程未能充分准备未来的AI从业者应对实施抽象伦理原则和规范性政策偏好至AI系统设计与开发的需求。我们相信，技术导向的AI工程师也需要熟悉‘AI政策景观’并能够将伦理原则转化为实践。为了应对这些新期望，我们开发了一个AI政策模块，将其引入计算机科学（CS）课程中，旨在增加对AI政策的讨论。基于2024年秋季成功的试点项目，本文介绍了更新和扩大的AI政策模块，包括一个关于‘AI监管’的作业。我们通过预模块和后模块调查评估了学生对AI伦理与政策的态度变化。
## Innovation
开发了一个更新和扩大的AI政策模块，包括一个关于‘AI监管’的作业。该模块旨在通过增加对AI政策的讨论来提高计算机科学学生的技能。评估结果显示，学生在完成模块后对AI伦理问题更加关注，并对讨论AI监管表示出更大的信心。此外，强调了‘政策’在解决伦理挑战中的作用，突出了AI对齐边界的探索工具的有效性和趣味性。
## Conclusion
经过模块训练后，学生对AI伦理问题的关注增加，并表示对讨论AI监管更具信心。AI监管作业特别强调了在实际应用中将伦理原则转化为操作的重要性和有效性。
